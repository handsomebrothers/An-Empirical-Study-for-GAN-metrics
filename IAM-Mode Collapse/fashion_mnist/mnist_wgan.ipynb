{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:5[D loss: 0.999912] [G loss: 1.000173]\n",
      "epoch:0 step:10[D loss: 0.999925] [G loss: 1.000180]\n",
      "epoch:0 step:15[D loss: 0.999923] [G loss: 1.000182]\n",
      "epoch:0 step:20[D loss: 0.999923] [G loss: 1.000173]\n",
      "epoch:0 step:25[D loss: 0.999924] [G loss: 1.000170]\n",
      "epoch:0 step:30[D loss: 0.999922] [G loss: 1.000171]\n",
      "epoch:0 step:35[D loss: 0.999924] [G loss: 1.000177]\n",
      "epoch:0 step:40[D loss: 0.999927] [G loss: 1.000176]\n",
      "epoch:0 step:45[D loss: 0.999928] [G loss: 1.000172]\n",
      "epoch:0 step:50[D loss: 0.999919] [G loss: 1.000171]\n",
      "epoch:0 step:55[D loss: 0.999922] [G loss: 1.000169]\n",
      "epoch:0 step:60[D loss: 0.999922] [G loss: 1.000164]\n",
      "epoch:0 step:65[D loss: 0.999926] [G loss: 1.000155]\n",
      "epoch:0 step:70[D loss: 0.999924] [G loss: 1.000152]\n",
      "epoch:0 step:75[D loss: 0.999929] [G loss: 1.000156]\n",
      "epoch:0 step:80[D loss: 0.999929] [G loss: 1.000135]\n",
      "epoch:0 step:85[D loss: 0.999932] [G loss: 1.000132]\n",
      "epoch:0 step:90[D loss: 0.999938] [G loss: 1.000124]\n",
      "epoch:0 step:95[D loss: 0.999941] [G loss: 1.000118]\n",
      "epoch:0 step:100[D loss: 0.999943] [G loss: 1.000116]\n",
      "epoch:0 step:105[D loss: 0.999946] [G loss: 1.000111]\n",
      "epoch:0 step:110[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:0 step:115[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:0 step:120[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:0 step:125[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:0 step:130[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:0 step:135[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:0 step:140[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:0 step:145[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:0 step:150[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:0 step:155[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:0 step:160[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:165[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:0 step:170[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:175[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:180[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:185[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:190[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:195[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:0 step:200[D loss: 0.999970] [G loss: 1.000062]\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[3.10626801 3.42111285 2.78680449 3.82874183 2.07361867 7.50253921\n",
      " 3.18752044 3.96365857 3.92189276 4.51443416]\n",
      "##########\n",
      "epoch:0 step:205[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:210[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:0 step:215[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:220[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:225[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:0 step:230[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:0 step:235[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:0 step:240[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:0 step:245[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:0 step:250[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:0 step:255[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:0 step:260[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:0 step:265[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:0 step:270[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:0 step:275[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:0 step:280[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:0 step:285[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:0 step:290[D loss: 0.999987] [G loss: 1.000095]\n",
      "epoch:0 step:295[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:0 step:300[D loss: 0.999990] [G loss: 1.000089]\n",
      "epoch:0 step:305[D loss: 0.999985] [G loss: 1.000092]\n",
      "epoch:0 step:310[D loss: 0.999981] [G loss: 1.000100]\n",
      "epoch:0 step:315[D loss: 0.999999] [G loss: 1.000093]\n",
      "epoch:0 step:320[D loss: 0.999982] [G loss: 1.000116]\n",
      "epoch:0 step:325[D loss: 0.999984] [G loss: 1.000111]\n",
      "epoch:0 step:330[D loss: 0.999976] [G loss: 1.000108]\n",
      "epoch:0 step:335[D loss: 0.999970] [G loss: 1.000116]\n",
      "epoch:0 step:340[D loss: 0.999971] [G loss: 1.000116]\n",
      "epoch:0 step:345[D loss: 0.999962] [G loss: 1.000110]\n",
      "epoch:0 step:350[D loss: 0.999973] [G loss: 1.000109]\n",
      "epoch:0 step:355[D loss: 0.999969] [G loss: 1.000107]\n",
      "epoch:0 step:360[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:0 step:365[D loss: 0.999980] [G loss: 1.000108]\n",
      "epoch:0 step:370[D loss: 0.999974] [G loss: 1.000109]\n",
      "epoch:0 step:375[D loss: 0.999959] [G loss: 1.000106]\n",
      "epoch:0 step:380[D loss: 0.999968] [G loss: 1.000118]\n",
      "epoch:0 step:385[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:0 step:390[D loss: 0.999969] [G loss: 1.000116]\n",
      "epoch:0 step:395[D loss: 0.999972] [G loss: 1.000117]\n",
      "epoch:0 step:400[D loss: 0.999967] [G loss: 1.000113]\n",
      "##############\n",
      "[2.62660812 2.77561946 2.34711312 3.5438329  1.5712086  7.06273616\n",
      " 2.21589757 3.47549726 3.40977565 4.69631875]\n",
      "##########\n",
      "epoch:0 step:405[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:0 step:410[D loss: 0.999966] [G loss: 1.000104]\n",
      "epoch:0 step:415[D loss: 0.999971] [G loss: 1.000104]\n",
      "epoch:0 step:420[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:0 step:425[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:0 step:430[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:0 step:435[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:0 step:440[D loss: 0.999972] [G loss: 1.000096]\n",
      "epoch:0 step:445[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:0 step:450[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:0 step:455[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:0 step:460[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:0 step:465[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:0 step:470[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:0 step:475[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:0 step:480[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:0 step:485[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:0 step:490[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:0 step:495[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:0 step:500[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:0 step:505[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:0 step:510[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:515[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:520[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:525[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:0 step:530[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:0 step:535[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:540[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:0 step:545[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:550[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:555[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:560[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:565[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:570[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:575[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:580[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:585[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:590[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:595[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:600[D loss: 0.999970] [G loss: 1.000072]\n",
      "##############\n",
      "[2.66400058 2.86126202 2.17071495 3.46500414 1.53820679 7.17907312\n",
      " 2.23347643 3.48474607 3.33189375 4.45169594]\n",
      "##########\n",
      "epoch:0 step:605[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:610[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:615[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:620[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:625[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:0 step:630[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:635[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:640[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:645[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:650[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:655[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:660[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:665[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:670[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:675[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:680[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:685[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:690[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:695[D loss: 0.999977] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:700[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:705[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:0 step:710[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:0 step:715[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:720[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:725[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:0 step:730[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:735[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:0 step:740[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:745[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:0 step:750[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:755[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:0 step:760[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:0 step:765[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:770[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:775[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:780[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:0 step:785[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:790[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:795[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:800[D loss: 0.999971] [G loss: 1.000067]\n",
      "##############\n",
      "[2.05719893 2.55648264 1.93660002 3.36100387 1.11533054 6.46903467\n",
      " 1.86435458 3.25078712 3.03096372 4.66941562]\n",
      "##########\n",
      "epoch:0 step:805[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:810[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:815[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:820[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:825[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:0 step:830[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:0 step:835[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:840[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:845[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:0 step:850[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:855[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:860[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:865[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:870[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:0 step:875[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:880[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:0 step:885[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:890[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:895[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:900[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:905[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:910[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:915[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:920[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:925[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:930[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:0 step:935[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:940[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:945[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:950[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:955[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:960[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:965[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:970[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:0 step:975[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:980[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:0 step:985[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:990[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:995[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1000[D loss: 0.999973] [G loss: 1.000073]\n",
      "##############\n",
      "[2.36382773 2.66583607 1.82318288 3.36513024 1.17557481 6.8163758\n",
      " 1.95009165 3.2321571  3.02779145 4.28331665]\n",
      "##########\n",
      "epoch:0 step:1005[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1010[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1015[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1020[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:1025[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:0 step:1030[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:1035[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:1040[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:0 step:1045[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1050[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1055[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:0 step:1060[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1065[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1070[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1075[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1080[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1085[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:1090[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1095[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1100[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:0 step:1105[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1110[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1115[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:1120[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:1125[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:1130[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1135[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:1140[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:1145[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1150[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:1155[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1160[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1165[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1170[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:1175[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:1180[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:1185[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:0 step:1190[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1195[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:0 step:1200[D loss: 0.999968] [G loss: 1.000054]\n",
      "##############\n",
      "[2.31565389 2.42246525 1.79762991 3.3278383  1.09029985 6.56880239\n",
      " 1.68964955 3.13074896 2.93134568 3.97279084]\n",
      "##########\n",
      "epoch:0 step:1205[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:0 step:1210[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:0 step:1215[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:1220[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1225[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1230[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:1235[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1240[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1245[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1250[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:1255[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1260[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:1265[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:0 step:1270[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1275[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:0 step:1280[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1285[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:1290[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:0 step:1295[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1300[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1305[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:1310[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:0 step:1315[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:1320[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1325[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:1330[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1335[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:1340[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:1345[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1350[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:1355[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:1360[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1365[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1370[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:1375[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1380[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:1385[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:1390[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1395[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:0 step:1400[D loss: 0.999970] [G loss: 1.000071]\n",
      "##############\n",
      "[2.24687084 2.48940143 1.85413693 3.33293331 1.14434657 6.17916258\n",
      " 1.88392038 3.32491186 3.05816194 4.54015508]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1405[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1410[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:1415[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:1420[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:1425[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1430[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1435[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:1440[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1445[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:1450[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1455[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:0 step:1460[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:1465[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:1470[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:1475[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:1480[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:0 step:1485[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:1490[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1495[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1500[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1505[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1510[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:1515[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:1520[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:1525[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:0 step:1530[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:1535[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1540[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1545[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:1550[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:1555[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1560[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:0 step:1565[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:1570[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1575[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1580[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:1585[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:1590[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:1595[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1600[D loss: 0.999970] [G loss: 1.000062]\n",
      "##############\n",
      "[2.29396422 2.45623923 1.87766773 3.4434756  1.17359051 6.24006808\n",
      " 1.94758979 3.16561893 3.08041533 4.72778959]\n",
      "##########\n",
      "epoch:0 step:1605[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1610[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1615[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:0 step:1620[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1625[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1630[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:1635[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:0 step:1640[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:0 step:1645[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1650[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1655[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1660[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:0 step:1665[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1670[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:1675[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1680[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:0 step:1685[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:0 step:1690[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:0 step:1695[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:1700[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:1705[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1710[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1715[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:0 step:1720[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:1725[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:1730[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1735[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1740[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:1745[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1750[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1755[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:1760[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1765[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:1770[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1775[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1780[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1785[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:1790[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1795[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:1800[D loss: 0.999971] [G loss: 1.000071]\n",
      "##############\n",
      "[2.39826628 2.49303857 2.14208549 3.72136243 1.26331197 6.45741016\n",
      " 2.02985341 3.3285779  3.24694151 5.06590506]\n",
      "##########\n",
      "epoch:0 step:1805[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:0 step:1810[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:1815[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1820[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:1825[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1830[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1835[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1840[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1845[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1850[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1855[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:1860[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1865[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:1870[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:1875[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1880[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1885[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:1890[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:1895[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:1900[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1905[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:1910[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1915[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:0 step:1920[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:1925[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1930[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:1935[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1940[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:0 step:1945[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1950[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1955[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1960[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:1965[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:0 step:1970[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1975[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1980[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1985[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:1990[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:1995[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:2000[D loss: 0.999973] [G loss: 1.000062]\n",
      "##############\n",
      "[2.50279462 2.70812535 2.25715144 3.43774926 1.39797369 6.32697812\n",
      " 2.13136947 3.43068387 3.4265297  5.26744336]\n",
      "##########\n",
      "epoch:0 step:2005[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:2010[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2015[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:2020[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:2025[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2030[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:2035[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:2040[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:2045[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:2050[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:2055[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2060[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2065[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2070[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:2075[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:2080[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:2085[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2090[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2095[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2100[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2105[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2110[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2115[D loss: 0.999975] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:2120[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:2125[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2130[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:2135[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:2140[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:0 step:2145[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2150[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:2155[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:2160[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:2165[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:0 step:2170[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:2175[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:0 step:2180[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2185[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:2190[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:2195[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:0 step:2200[D loss: 0.999976] [G loss: 1.000068]\n",
      "##############\n",
      "[2.58934297 2.89429248 2.35668477 3.60765616 1.54229664 6.73528623\n",
      " 2.11796541 3.60113135 3.51717179 5.55269517]\n",
      "##########\n",
      "epoch:0 step:2205[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:2210[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:2215[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:2220[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:2225[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:2230[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:0 step:2235[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:2240[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:0 step:2245[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2250[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:0 step:2255[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:2260[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:2265[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:2270[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:2275[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:0 step:2280[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2285[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:2290[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:2295[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:0 step:2300[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:0 step:2305[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:0 step:2310[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:0 step:2315[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:0 step:2320[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2325[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:2330[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2335[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:2340[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:2345[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:2350[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:0 step:2355[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:2360[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:2365[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:2370[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:2375[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:2380[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:2385[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:2390[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:0 step:2395[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2400[D loss: 0.999970] [G loss: 1.000073]\n",
      "##############\n",
      "[2.62722386 2.94920331 2.41821343 3.47095164 1.59455069 6.77969074\n",
      " 2.22514741 3.55791905 3.56423483 4.6499974 ]\n",
      "##########\n",
      "epoch:0 step:2405[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:2410[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2415[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:2420[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:2425[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:2430[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:2435[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2440[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:0 step:2445[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:0 step:2450[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2455[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:2460[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:0 step:2465[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2470[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2475[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:2480[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2485[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2490[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2495[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:0 step:2500[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:0 step:2505[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:2510[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:2515[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2520[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:0 step:2525[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:0 step:2530[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2535[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:2540[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:0 step:2545[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:2550[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:2555[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2560[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:2565[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:0 step:2570[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:0 step:2575[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2580[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:0 step:2585[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:2590[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:0 step:2595[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:2600[D loss: 0.999974] [G loss: 1.000063]\n",
      "##############\n",
      "[2.67049258 2.77530815 2.48330912 3.60495894 1.5852115  6.72635648\n",
      " 2.28383995 3.41585748 3.55795282 4.49416078]\n",
      "##########\n",
      "epoch:0 step:2605[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:0 step:2610[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:2615[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:2620[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2625[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:2630[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2635[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2640[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:0 step:2645[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2650[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:2655[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:2660[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:0 step:2665[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2670[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:0 step:2675[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:2680[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:2685[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:2690[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2695[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:0 step:2700[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:2705[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:2710[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:2715[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:2720[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:2725[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:0 step:2730[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2735[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:0 step:2740[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:0 step:2745[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:0 step:2750[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:2755[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:0 step:2760[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:2765[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:2770[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:0 step:2775[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:2780[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2785[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:0 step:2790[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:0 step:2795[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:2800[D loss: 0.999975] [G loss: 1.000066]\n",
      "##############\n",
      "[2.58671409 2.68309425 2.4653898  3.82357824 1.54403878 7.00981895\n",
      " 2.20668511 3.53983445 3.53872612 4.36337952]\n",
      "##########\n",
      "epoch:0 step:2805[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:2810[D loss: 0.999974] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:2815[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2820[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:2825[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:2830[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:2835[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2840[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:2845[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:2850[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:2855[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:2860[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2865[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:2870[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:0 step:2875[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:2880[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:2885[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2890[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:2895[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:2900[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:0 step:2905[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:2910[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:0 step:2915[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:0 step:2920[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2925[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2930[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:0 step:2935[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:0 step:2940[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:0 step:2945[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:0 step:2950[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:2955[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:0 step:2960[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:2965[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2970[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2975[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:0 step:2980[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:2985[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:0 step:2990[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:0 step:2995[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:3000[D loss: 0.999972] [G loss: 1.000073]\n",
      "##############\n",
      "[2.70336467 2.90374896 2.55141026 3.68950614 1.63773073 6.40850999\n",
      " 2.27762365 3.6420329  3.57834649 4.64185927]\n",
      "##########\n",
      "epoch:0 step:3005[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:3010[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:3015[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:3020[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:3025[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:0 step:3030[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:3035[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:3040[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:3045[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:3050[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:3055[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:0 step:3060[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:0 step:3065[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:0 step:3070[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:0 step:3075[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:3080[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3085[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:0 step:3090[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:0 step:3095[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:0 step:3100[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:3105[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:3110[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:3115[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:3120[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:3125[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:0 step:3130[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:0 step:3135[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:0 step:3140[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:0 step:3145[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:0 step:3150[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:0 step:3155[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3160[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:3165[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:0 step:3170[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:3175[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:3180[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:0 step:3185[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:3190[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:0 step:3195[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:0 step:3200[D loss: 0.999976] [G loss: 1.000058]\n",
      "##############\n",
      "[2.76504491 2.96348822 2.5251512  3.78440383 1.73396144 6.63143109\n",
      " 2.36102987 3.54585368 3.60847271 4.80587389]\n",
      "##########\n",
      "epoch:0 step:3205[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:3210[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:3215[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:0 step:3220[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:3225[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:3230[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:3235[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:3240[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:3245[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:3250[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:3255[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:0 step:3260[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:0 step:3265[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:0 step:3270[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:3275[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:3280[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:3285[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:0 step:3290[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:0 step:3295[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:0 step:3300[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3305[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3310[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:3315[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:3320[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:3325[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:0 step:3330[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:3335[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:3340[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:3345[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:0 step:3350[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:3355[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:0 step:3360[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:3365[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:3370[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:3375[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:3380[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:3385[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:3390[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:3395[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:0 step:3400[D loss: 0.999975] [G loss: 1.000057]\n",
      "##############\n",
      "[2.84409585 2.81818905 2.53469722 3.58116921 1.75365722 6.86558185\n",
      " 2.33232085 3.58338545 3.68641811 4.84527039]\n",
      "##########\n",
      "epoch:0 step:3405[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:0 step:3410[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:0 step:3415[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:3420[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:3425[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3430[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:0 step:3435[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:3440[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:3445[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3450[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:0 step:3455[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:3460[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:3465[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:3470[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:3475[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:3480[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:0 step:3485[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:3490[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:3495[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:0 step:3500[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:3505[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:3510[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:0 step:3515[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:3520[D loss: 0.999978] [G loss: 1.000063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:3525[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:3530[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:0 step:3535[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:3540[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:0 step:3545[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:0 step:3550[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:3555[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:3560[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:3565[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:3570[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:3575[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3580[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:3585[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:3590[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:0 step:3595[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:3600[D loss: 0.999976] [G loss: 1.000076]\n",
      "##############\n",
      "[2.8619727  2.88900522 2.50992985 3.91407898 1.79498601 7.08687957\n",
      " 2.40547555 3.67497396 3.68634061 5.09832342]\n",
      "##########\n",
      "epoch:0 step:3605[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:3610[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:0 step:3615[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:0 step:3620[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:3625[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:3630[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3635[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:0 step:3640[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:0 step:3645[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:3650[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:0 step:3655[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:3660[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:3665[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:3670[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:0 step:3675[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:3680[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:3685[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:3690[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:0 step:3695[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:0 step:3700[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:0 step:3705[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:0 step:3710[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:3715[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:3720[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:3725[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:3730[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:0 step:3735[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3740[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:3745[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:3750[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:3755[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:3760[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:0 step:3765[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:3770[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:0 step:3775[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:3780[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:3785[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:3790[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:3795[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:3800[D loss: 0.999974] [G loss: 1.000069]\n",
      "##############\n",
      "[2.86106217 2.98553072 2.66612714 3.83773941 1.76668114 6.85603043\n",
      " 2.40679515 3.70860151 3.75717675 4.7156212 ]\n",
      "##########\n",
      "epoch:0 step:3805[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:0 step:3810[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:3815[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:3820[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3825[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:3830[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:3835[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:3840[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3845[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:3850[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:0 step:3855[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:0 step:3860[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:3865[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:0 step:3870[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:3875[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:0 step:3880[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:3885[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:0 step:3890[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:0 step:3895[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:3900[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:3905[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:0 step:3910[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:3915[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:3920[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:0 step:3925[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:3930[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:0 step:3935[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3940[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:3945[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:3950[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:3955[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3960[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:3965[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:0 step:3970[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:3975[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:3980[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:0 step:3985[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:3990[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:0 step:3995[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:4000[D loss: 0.999971] [G loss: 1.000067]\n",
      "##############\n",
      "[2.76749732 2.85209369 2.62405886 3.76416298 1.7410212  6.75394227\n",
      " 2.45912076 3.67925577 3.68963301 4.82760778]\n",
      "##########\n",
      "epoch:0 step:4005[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:4010[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:4015[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:4020[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:0 step:4025[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:4030[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:4035[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:4040[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:4045[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:4050[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:4055[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:4060[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:0 step:4065[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:4070[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:4075[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:4080[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:4085[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:4090[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:0 step:4095[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:4100[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:4105[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:4110[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:4115[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:4120[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:4125[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:0 step:4130[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:4135[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:4140[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:4145[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:0 step:4150[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:4155[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:4160[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:0 step:4165[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:4170[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:0 step:4175[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:0 step:4180[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:4185[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:4190[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:0 step:4195[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:0 step:4200[D loss: 0.999975] [G loss: 1.000077]\n",
      "##############\n",
      "[2.7467124  3.00127647 2.50738815 3.72066372 1.69079927 6.77789634\n",
      " 2.41048205 3.60007751 3.6853478  5.91525313]\n",
      "##########\n",
      "epoch:0 step:4205[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:0 step:4210[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:0 step:4215[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:4220[D loss: 0.999973] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:4225[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:0 step:4230[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:4235[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:0 step:4240[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:4245[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:0 step:4250[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:4255[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:4260[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:0 step:4265[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:0 step:4270[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:0 step:4275[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:4280[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:4285[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:4290[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:4295[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:0 step:4300[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:0 step:4305[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:0 step:4310[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:0 step:4315[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:0 step:4320[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:0 step:4325[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:0 step:4330[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:4335[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:0 step:4340[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:4345[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:4350[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:0 step:4355[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:4360[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:0 step:4365[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:4370[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:0 step:4375[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:4380[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:0 step:4385[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:4390[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:4395[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:0 step:4400[D loss: 0.999978] [G loss: 1.000066]\n",
      "##############\n",
      "[2.72183417 2.95352608 2.48333218 3.79377616 1.73383592 6.81777073\n",
      " 2.42199958 3.76685978 3.65296831 4.92194241]\n",
      "##########\n",
      "epoch:0 step:4405[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:4410[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:0 step:4415[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:0 step:4420[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:0 step:4425[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:0 step:4430[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:4435[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:4440[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:4445[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:4450[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:4455[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:4460[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:0 step:4465[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:0 step:4470[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:4475[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:4480[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:0 step:4485[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:4490[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:0 step:4495[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:0 step:4500[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:0 step:4505[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:4510[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:4515[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:0 step:4520[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:0 step:4525[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:4530[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:0 step:4535[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:0 step:4540[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:0 step:4545[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:4550[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:4555[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:0 step:4560[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:4565[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:4570[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:4575[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:4580[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:4585[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:0 step:4590[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:4595[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:0 step:4600[D loss: 0.999976] [G loss: 1.000067]\n",
      "##############\n",
      "[2.85880284 3.16222416 2.6385713  3.80326348 1.76641983 7.31564821\n",
      " 2.51256903 3.77501347 3.72722784 5.19850711]\n",
      "##########\n",
      "epoch:0 step:4605[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:4610[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:4615[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:4620[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:4625[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:4630[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:4635[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:4640[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:0 step:4645[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:0 step:4650[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:4655[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:0 step:4660[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:4665[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:4670[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:0 step:4675[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:4680[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:4685[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:1 step:4690[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:1 step:4695[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:1 step:4700[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:4705[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:1 step:4710[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:1 step:4715[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:4720[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:4725[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:1 step:4730[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:4735[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:1 step:4740[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:1 step:4745[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:4750[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:1 step:4755[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:1 step:4760[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:1 step:4765[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:1 step:4770[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:1 step:4775[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:1 step:4780[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:1 step:4785[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:4790[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:1 step:4795[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:4800[D loss: 0.999977] [G loss: 1.000074]\n",
      "##############\n",
      "[2.64866309 2.99965538 2.5175468  3.68693309 1.66500964 6.94452862\n",
      " 2.32465908 3.79014305 3.66679626 5.7235382 ]\n",
      "##########\n",
      "epoch:1 step:4805[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:1 step:4810[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:4815[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:1 step:4820[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:1 step:4825[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:1 step:4830[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:1 step:4835[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:1 step:4840[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:1 step:4845[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:4850[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:4855[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:4860[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:1 step:4865[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:1 step:4870[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:1 step:4875[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:4880[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:1 step:4885[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:1 step:4890[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:1 step:4895[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:1 step:4900[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:4905[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:4910[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:4915[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:1 step:4920[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:1 step:4925[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:4930[D loss: 0.999968] [G loss: 1.000081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:4935[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:4940[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:4945[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:4950[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:4955[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:4960[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:1 step:4965[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:4970[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:1 step:4975[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:4980[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:4985[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:4990[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:4995[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:1 step:5000[D loss: 0.999979] [G loss: 1.000065]\n",
      "##############\n",
      "[2.64900851 2.95861138 2.71612817 3.74145402 1.70084973 7.04294418\n",
      " 2.46700895 3.80143312 3.63539723 4.7062934 ]\n",
      "##########\n",
      "epoch:1 step:5005[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:1 step:5010[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:1 step:5015[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:1 step:5020[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:5025[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:1 step:5030[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:1 step:5035[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:1 step:5040[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:1 step:5045[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:1 step:5050[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:1 step:5055[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:1 step:5060[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:1 step:5065[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:1 step:5070[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:1 step:5075[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:1 step:5080[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:1 step:5085[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:5090[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:1 step:5095[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:5100[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:5105[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:5110[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:5115[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:5120[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:1 step:5125[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:5130[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:5135[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:5140[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:5145[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:1 step:5150[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:5155[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:5160[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:5165[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:1 step:5170[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:5175[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:1 step:5180[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:1 step:5185[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:1 step:5190[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:1 step:5195[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:5200[D loss: 0.999973] [G loss: 1.000067]\n",
      "##############\n",
      "[2.67255518 2.93341264 2.49654672 4.05917917 1.74569604 7.224121\n",
      " 2.49104175 3.92845885 3.69821884 5.3257996 ]\n",
      "##########\n",
      "epoch:1 step:5205[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:1 step:5210[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:5215[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:1 step:5220[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:1 step:5225[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:1 step:5230[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:1 step:5235[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:1 step:5240[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:5245[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:5250[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:1 step:5255[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:5260[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:1 step:5265[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:5270[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:1 step:5275[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:5280[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:1 step:5285[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:1 step:5290[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:5295[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:5300[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:5305[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:5310[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:5315[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:5320[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:1 step:5325[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:1 step:5330[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:5335[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:1 step:5340[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:5345[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:1 step:5350[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:1 step:5355[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:1 step:5360[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:5365[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:1 step:5370[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:5375[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:5380[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:1 step:5385[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:5390[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:5395[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:5400[D loss: 0.999973] [G loss: 1.000066]\n",
      "##############\n",
      "[2.65351395 2.96393661 2.61327542 3.96551241 1.69272513 7.38251613\n",
      " 2.54300807 3.86568512 3.66151118 4.55268523]\n",
      "##########\n",
      "epoch:1 step:5405[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:5410[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:1 step:5415[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:1 step:5420[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:1 step:5425[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:5430[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:1 step:5435[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:1 step:5440[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:5445[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:1 step:5450[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:1 step:5455[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:1 step:5460[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:1 step:5465[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:5470[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:5475[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:5480[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:1 step:5485[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:1 step:5490[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:5495[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:5500[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:5505[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:1 step:5510[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:1 step:5515[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:1 step:5520[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:1 step:5525[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:1 step:5530[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:5535[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:5540[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:5545[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:1 step:5550[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:5555[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:5560[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:1 step:5565[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:5570[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:1 step:5575[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:1 step:5580[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:1 step:5585[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:1 step:5590[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:5595[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:1 step:5600[D loss: 0.999978] [G loss: 1.000067]\n",
      "##############\n",
      "[2.65976134 2.86466391 2.66281905 3.76545661 1.74390585 7.19939231\n",
      " 2.44267085 3.79993212 3.69193988 5.04501655]\n",
      "##########\n",
      "epoch:1 step:5605[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:5610[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:1 step:5615[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:5620[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:5625[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:1 step:5630[D loss: 0.999976] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:5635[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:1 step:5640[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:1 step:5645[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:5650[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:1 step:5655[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:5660[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:5665[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:1 step:5670[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:1 step:5675[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:1 step:5680[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:1 step:5685[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:1 step:5690[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:1 step:5695[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:1 step:5700[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:5705[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:5710[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:5715[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:1 step:5720[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:5725[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:1 step:5730[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:1 step:5735[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:1 step:5740[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:1 step:5745[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:5750[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:5755[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:5760[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:1 step:5765[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:5770[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:1 step:5775[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:1 step:5780[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:5785[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:1 step:5790[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:5795[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:1 step:5800[D loss: 0.999976] [G loss: 1.000072]\n",
      "##############\n",
      "[2.63357018 2.88670914 2.62999761 3.98738139 1.78498066 7.24555273\n",
      " 2.40820481 3.90106283 3.66165126 5.08157231]\n",
      "##########\n",
      "epoch:1 step:5805[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:1 step:5810[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:1 step:5815[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:1 step:5820[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:5825[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:1 step:5830[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:1 step:5835[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:1 step:5840[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:1 step:5845[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:1 step:5850[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:1 step:5855[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:1 step:5860[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:5865[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:1 step:5870[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:5875[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:5880[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:1 step:5885[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:1 step:5890[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:1 step:5895[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:1 step:5900[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:5905[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:5910[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:1 step:5915[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:5920[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:1 step:5925[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:1 step:5930[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:5935[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:1 step:5940[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:5945[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:1 step:5950[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:1 step:5955[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:5960[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:5965[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:5970[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:1 step:5975[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:1 step:5980[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:1 step:5985[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:1 step:5990[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:1 step:5995[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:1 step:6000[D loss: 0.999974] [G loss: 1.000072]\n",
      "##############\n",
      "[2.70557136 3.00021627 2.58949518 3.93902748 1.73846058 7.54208682\n",
      " 2.45684967 3.9515951  3.68234218 5.94512708]\n",
      "##########\n",
      "epoch:1 step:6005[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:1 step:6010[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:1 step:6015[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:1 step:6020[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:6025[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:1 step:6030[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:1 step:6035[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:1 step:6040[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:6045[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:1 step:6050[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:1 step:6055[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:6060[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:1 step:6065[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:6070[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:1 step:6075[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:1 step:6080[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:1 step:6085[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:1 step:6090[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:1 step:6095[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:1 step:6100[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:6105[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:1 step:6110[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:1 step:6115[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:6120[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:6125[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:6130[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:1 step:6135[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:6140[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:6145[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:1 step:6150[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:1 step:6155[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:6160[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:1 step:6165[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:1 step:6170[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:1 step:6175[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:1 step:6180[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:6185[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:6190[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:1 step:6195[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:1 step:6200[D loss: 0.999981] [G loss: 1.000042]\n",
      "##############\n",
      "[2.65214745 2.84278276 2.71115922 3.85918367 1.76735538 7.1663729\n",
      " 2.48434231 3.94514741 3.74441828 4.52951534]\n",
      "##########\n",
      "epoch:1 step:6205[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:1 step:6210[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:1 step:6215[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:1 step:6220[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:1 step:6225[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:1 step:6230[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:1 step:6235[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:6240[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:6245[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:6250[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:1 step:6255[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:6260[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:1 step:6265[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:1 step:6270[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:1 step:6275[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:6280[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:6285[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:1 step:6290[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:1 step:6295[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:1 step:6300[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:1 step:6305[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:1 step:6310[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:1 step:6315[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:6320[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:6325[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:6330[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:1 step:6335[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:1 step:6340[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:1 step:6345[D loss: 0.999982] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:6350[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:1 step:6355[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:6360[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:6365[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:1 step:6370[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:1 step:6375[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:1 step:6380[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:1 step:6385[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:1 step:6390[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:6395[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:1 step:6400[D loss: 0.999977] [G loss: 1.000057]\n",
      "##############\n",
      "[2.66214225 2.8612123  2.65845824 3.93805722 1.81519926 7.28475555\n",
      " 2.54052245 3.9189375  3.76912817 4.43376352]\n",
      "##########\n",
      "epoch:1 step:6405[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:1 step:6410[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:1 step:6415[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:6420[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:1 step:6425[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:1 step:6430[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:1 step:6435[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:1 step:6440[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:1 step:6445[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:1 step:6450[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:1 step:6455[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:6460[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:6465[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:1 step:6470[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:1 step:6475[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:1 step:6480[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:6485[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:6490[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:1 step:6495[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:1 step:6500[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:1 step:6505[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:1 step:6510[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:1 step:6515[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:6520[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:1 step:6525[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:1 step:6530[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:1 step:6535[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:6540[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:6545[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:1 step:6550[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:6555[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:1 step:6560[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:1 step:6565[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:6570[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:1 step:6575[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:1 step:6580[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:1 step:6585[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:1 step:6590[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:1 step:6595[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:1 step:6600[D loss: 0.999980] [G loss: 1.000056]\n",
      "##############\n",
      "[2.5905762  2.78343558 2.5135736  3.82496919 1.7532097  7.20443694\n",
      " 2.40094901 3.92673456 3.70846378 5.06176386]\n",
      "##########\n",
      "epoch:1 step:6605[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:1 step:6610[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:1 step:6615[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:6620[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:1 step:6625[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:1 step:6630[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:1 step:6635[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:1 step:6640[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:1 step:6645[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:6650[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:1 step:6655[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:1 step:6660[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:6665[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:1 step:6670[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:6675[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:6680[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:1 step:6685[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:1 step:6690[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:6695[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:1 step:6700[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:1 step:6705[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:6710[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:1 step:6715[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:1 step:6720[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:1 step:6725[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:1 step:6730[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:6735[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:1 step:6740[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:1 step:6745[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:1 step:6750[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:1 step:6755[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:6760[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:6765[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:6770[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:1 step:6775[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:6780[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:1 step:6785[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:1 step:6790[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:1 step:6795[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:1 step:6800[D loss: 0.999977] [G loss: 1.000082]\n",
      "##############\n",
      "[2.62011213 2.82628646 2.60804313 3.90805933 1.75052693 7.26199492\n",
      " 2.36936597 3.83757279 3.74868198 4.79433102]\n",
      "##########\n",
      "epoch:1 step:6805[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:1 step:6810[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:1 step:6815[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:1 step:6820[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:1 step:6825[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:1 step:6830[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:1 step:6835[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:1 step:6840[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:6845[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:1 step:6850[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:1 step:6855[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:6860[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:1 step:6865[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:6870[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:1 step:6875[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:6880[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:1 step:6885[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:1 step:6890[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:1 step:6895[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:1 step:6900[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:6905[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:1 step:6910[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:1 step:6915[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:6920[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:1 step:6925[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:1 step:6930[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:6935[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:6940[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:1 step:6945[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:6950[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:1 step:6955[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:6960[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:1 step:6965[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:6970[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:1 step:6975[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:6980[D loss: 1.000003] [G loss: 1.000049]\n",
      "epoch:1 step:6985[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:1 step:6990[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:1 step:6995[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:1 step:7000[D loss: 0.999978] [G loss: 1.000065]\n",
      "##############\n",
      "[2.5742961  2.67595678 2.49445476 3.8385657  1.73751166 7.1155254\n",
      " 2.41240362 3.82533982 3.68003067 4.77292995]\n",
      "##########\n",
      "epoch:1 step:7005[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:7010[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:7015[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:1 step:7020[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:1 step:7025[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:7030[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:7035[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:1 step:7040[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:7045[D loss: 0.999980] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:7050[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:1 step:7055[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:7060[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:7065[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:1 step:7070[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:1 step:7075[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:1 step:7080[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:1 step:7085[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:1 step:7090[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:1 step:7095[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:7100[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:7105[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:1 step:7110[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:7115[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:7120[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:1 step:7125[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:7130[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:1 step:7135[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:1 step:7140[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:7145[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:1 step:7150[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:1 step:7155[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:1 step:7160[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:1 step:7165[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:1 step:7170[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:7175[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:1 step:7180[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:7185[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:1 step:7190[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:1 step:7195[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:7200[D loss: 0.999976] [G loss: 1.000067]\n",
      "##############\n",
      "[2.54393322 2.71258709 2.4338789  3.76125286 1.70424365 7.22110093\n",
      " 2.38099892 3.78724046 3.75021553 5.11204502]\n",
      "##########\n",
      "epoch:1 step:7205[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:1 step:7210[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:1 step:7215[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:7220[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:1 step:7225[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:7230[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:1 step:7235[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:1 step:7240[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:1 step:7245[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:1 step:7250[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:1 step:7255[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:7260[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:7265[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:1 step:7270[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:1 step:7275[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:1 step:7280[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:1 step:7285[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:1 step:7290[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:1 step:7295[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:7300[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:7305[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:1 step:7310[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:7315[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:7320[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:1 step:7325[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:1 step:7330[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:1 step:7335[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:1 step:7340[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:1 step:7345[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:1 step:7350[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:7355[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:7360[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:7365[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:7370[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:7375[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:1 step:7380[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:1 step:7385[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:1 step:7390[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:1 step:7395[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:1 step:7400[D loss: 0.999982] [G loss: 1.000047]\n",
      "##############\n",
      "[2.56874006 2.73735977 2.55014043 3.57262749 1.75714203 7.28053497\n",
      " 2.41134985 3.91277306 3.76037374 5.42027428]\n",
      "##########\n",
      "epoch:1 step:7405[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:1 step:7410[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:1 step:7415[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:7420[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:1 step:7425[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:1 step:7430[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:1 step:7435[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:1 step:7440[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:1 step:7445[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:1 step:7450[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:1 step:7455[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:1 step:7460[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:1 step:7465[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:1 step:7470[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:7475[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:7480[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:7485[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:7490[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:7495[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:1 step:7500[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:1 step:7505[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:1 step:7510[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:1 step:7515[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:7520[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:1 step:7525[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:1 step:7530[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:1 step:7535[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:7540[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:1 step:7545[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:1 step:7550[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:1 step:7555[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:7560[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:1 step:7565[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:7570[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:1 step:7575[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:1 step:7580[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:1 step:7585[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:1 step:7590[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:1 step:7595[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:1 step:7600[D loss: 0.999978] [G loss: 1.000061]\n",
      "##############\n",
      "[2.61253391 2.75921256 2.45677356 3.88758839 1.73404614 7.51631842\n",
      " 2.51111837 3.78910727 3.77397749 6.02506491]\n",
      "##########\n",
      "epoch:1 step:7605[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:7610[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:1 step:7615[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:1 step:7620[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:7625[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:7630[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:1 step:7635[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:1 step:7640[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:1 step:7645[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:7650[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:1 step:7655[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:1 step:7660[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:1 step:7665[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:7670[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:7675[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:1 step:7680[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:1 step:7685[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:1 step:7690[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:1 step:7695[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:1 step:7700[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:7705[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:7710[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:1 step:7715[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:7720[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:1 step:7725[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:1 step:7730[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:1 step:7735[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:1 step:7740[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:1 step:7745[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:7750[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:7755[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:1 step:7760[D loss: 0.999973] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:7765[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:1 step:7770[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:1 step:7775[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:1 step:7780[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:1 step:7785[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:7790[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:7795[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:1 step:7800[D loss: 0.999975] [G loss: 1.000058]\n",
      "##############\n",
      "[2.48305024 2.66988645 2.43212746 3.75667891 1.62941684 7.33302187\n",
      " 2.40513761 3.76499419 3.69727069 4.67640807]\n",
      "##########\n",
      "epoch:1 step:7805[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:7810[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:1 step:7815[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:7820[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:1 step:7825[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7830[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:1 step:7835[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:7840[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:7845[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:1 step:7850[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:1 step:7855[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:7860[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:1 step:7865[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:1 step:7870[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:1 step:7875[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:1 step:7880[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:7885[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:1 step:7890[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:1 step:7895[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:1 step:7900[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:1 step:7905[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:1 step:7910[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:7915[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:1 step:7920[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:7925[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:1 step:7930[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:1 step:7935[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:7940[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:1 step:7945[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:7950[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:7955[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:7960[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:1 step:7965[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:1 step:7970[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:1 step:7975[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:7980[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:1 step:7985[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:1 step:7990[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:1 step:7995[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:1 step:8000[D loss: 0.999986] [G loss: 1.000062]\n",
      "##############\n",
      "[2.54306366 2.64044832 2.34919332 3.76721076 1.66211246 7.07463531\n",
      " 2.45166929 3.63855321 3.7563715  5.02241947]\n",
      "##########\n",
      "epoch:1 step:8005[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:1 step:8010[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:1 step:8015[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:1 step:8020[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:1 step:8025[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:1 step:8030[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:8035[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:1 step:8040[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:1 step:8045[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:8050[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:1 step:8055[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:8060[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:8065[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:1 step:8070[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:8075[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:8080[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:1 step:8085[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:1 step:8090[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:1 step:8095[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:1 step:8100[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:1 step:8105[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:1 step:8110[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:8115[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:1 step:8120[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:1 step:8125[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:8130[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:1 step:8135[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:1 step:8140[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:8145[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:1 step:8150[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:1 step:8155[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:1 step:8160[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:8165[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:8170[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:1 step:8175[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:1 step:8180[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:1 step:8185[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:1 step:8190[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:1 step:8195[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:1 step:8200[D loss: 0.999981] [G loss: 1.000062]\n",
      "##############\n",
      "[2.49944993 2.59752892 2.29636047 3.84874481 1.70254792 7.40207801\n",
      " 2.31807448 3.61066574 3.69978299 4.56183852]\n",
      "##########\n",
      "epoch:1 step:8205[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:1 step:8210[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:1 step:8215[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:1 step:8220[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:8225[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:1 step:8230[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:1 step:8235[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:1 step:8240[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:1 step:8245[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:1 step:8250[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:1 step:8255[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:1 step:8260[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:8265[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:1 step:8270[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:1 step:8275[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:8280[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:1 step:8285[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:1 step:8290[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:8295[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:1 step:8300[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:1 step:8305[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:1 step:8310[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:1 step:8315[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:1 step:8320[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:1 step:8325[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:1 step:8330[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:8335[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:1 step:8340[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:1 step:8345[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:8350[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:8355[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:1 step:8360[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:1 step:8365[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:1 step:8370[D loss: 0.999999] [G loss: 1.000079]\n",
      "epoch:1 step:8375[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:1 step:8380[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:1 step:8385[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:1 step:8390[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:1 step:8395[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:1 step:8400[D loss: 0.999980] [G loss: 1.000056]\n",
      "##############\n",
      "[2.52543978 2.72071864 2.33258628 3.67229409 1.71143076 7.34520053\n",
      " 2.32111395 3.67587318 3.77113021 4.87213685]\n",
      "##########\n",
      "epoch:1 step:8405[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:8410[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:1 step:8415[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:1 step:8420[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:1 step:8425[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:8430[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:8435[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:1 step:8440[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:1 step:8445[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:8450[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:1 step:8455[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:1 step:8460[D loss: 0.999984] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:8465[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:1 step:8470[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:1 step:8475[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:8480[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:8485[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:8490[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:1 step:8495[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:1 step:8500[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:1 step:8505[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:8510[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:1 step:8515[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:1 step:8520[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:1 step:8525[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:1 step:8530[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:1 step:8535[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:8540[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:8545[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:1 step:8550[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:1 step:8555[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:8560[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:1 step:8565[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:1 step:8570[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:1 step:8575[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:1 step:8580[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:1 step:8585[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:1 step:8590[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:1 step:8595[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:8600[D loss: 0.999980] [G loss: 1.000053]\n",
      "##############\n",
      "[2.54675364 2.64801304 2.29486587 3.8228813  1.69442726 7.72632417\n",
      " 2.41482515 3.76665634 3.74541753 4.45748888]\n",
      "##########\n",
      "epoch:1 step:8605[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:1 step:8610[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:1 step:8615[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:1 step:8620[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:1 step:8625[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:1 step:8630[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:1 step:8635[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:1 step:8640[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:1 step:8645[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:1 step:8650[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:1 step:8655[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:1 step:8660[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:1 step:8665[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:1 step:8670[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:1 step:8675[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:1 step:8680[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:1 step:8685[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:1 step:8690[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:1 step:8695[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:1 step:8700[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:1 step:8705[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:1 step:8710[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:1 step:8715[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:1 step:8720[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:1 step:8725[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:1 step:8730[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:1 step:8735[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:8740[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:1 step:8745[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:1 step:8750[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:8755[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:1 step:8760[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:1 step:8765[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:1 step:8770[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:1 step:8775[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:1 step:8780[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:1 step:8785[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:1 step:8790[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:1 step:8795[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:1 step:8800[D loss: 0.999978] [G loss: 1.000055]\n",
      "##############\n",
      "[2.49397166 2.61515139 2.43403005 3.89446942 1.70348129 7.34349787\n",
      " 2.49544274 3.68264521 3.73147993 5.22144277]\n",
      "##########\n",
      "epoch:1 step:8805[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:1 step:8810[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:1 step:8815[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:1 step:8820[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:1 step:8825[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:1 step:8830[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:1 step:8835[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:1 step:8840[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:1 step:8845[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:1 step:8850[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:1 step:8855[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:1 step:8860[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:1 step:8865[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:1 step:8870[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:1 step:8875[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:1 step:8880[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:1 step:8885[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:1 step:8890[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:1 step:8895[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:1 step:8900[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:1 step:8905[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:8910[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:1 step:8915[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:1 step:8920[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:1 step:8925[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:1 step:8930[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:1 step:8935[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:8940[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:1 step:8945[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:1 step:8950[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:1 step:8955[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:1 step:8960[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:8965[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:1 step:8970[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:1 step:8975[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:1 step:8980[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:1 step:8985[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:1 step:8990[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:1 step:8995[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:1 step:9000[D loss: 0.999975] [G loss: 1.000064]\n",
      "##############\n",
      "[2.54266419 2.71607389 2.34284747 3.62021721 1.6491296  7.26483924\n",
      " 2.29745138 3.77664353 3.79493737 4.97478694]\n",
      "##########\n",
      "epoch:1 step:9005[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:1 step:9010[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:1 step:9015[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:1 step:9020[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:1 step:9025[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:1 step:9030[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:1 step:9035[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:1 step:9040[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:1 step:9045[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:9050[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:1 step:9055[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:1 step:9060[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:1 step:9065[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:1 step:9070[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:1 step:9075[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:1 step:9080[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:1 step:9085[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:1 step:9090[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:1 step:9095[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:1 step:9100[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:1 step:9105[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:1 step:9110[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:1 step:9115[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:1 step:9120[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:1 step:9125[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:9130[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:1 step:9135[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:1 step:9140[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:9145[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:1 step:9150[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:1 step:9155[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:1 step:9160[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:9165[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:1 step:9170[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:1 step:9175[D loss: 0.999973] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:9180[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:1 step:9185[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:1 step:9190[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:1 step:9195[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:1 step:9200[D loss: 0.999978] [G loss: 1.000056]\n",
      "##############\n",
      "[2.47505975 2.57142545 2.29657741 3.92250017 1.61995556 7.41039692\n",
      " 2.26269977 3.67940561 3.67871729 4.96668899]\n",
      "##########\n",
      "epoch:1 step:9205[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:1 step:9210[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:9215[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:1 step:9220[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:9225[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:1 step:9230[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:1 step:9235[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:1 step:9240[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:9245[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:9250[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:1 step:9255[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:1 step:9260[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:1 step:9265[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:1 step:9270[D loss: 0.999992] [G loss: 1.000061]\n",
      "epoch:1 step:9275[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:9280[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:1 step:9285[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:9290[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:1 step:9295[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:1 step:9300[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:1 step:9305[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:1 step:9310[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:9315[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:9320[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:9325[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:1 step:9330[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:1 step:9335[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:1 step:9340[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:1 step:9345[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:1 step:9350[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:1 step:9355[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:1 step:9360[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:1 step:9365[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:1 step:9370[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:2 step:9375[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:2 step:9380[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:2 step:9385[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:9390[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:2 step:9395[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:2 step:9400[D loss: 0.999974] [G loss: 1.000086]\n",
      "##############\n",
      "[2.49792662 2.55599183 2.18197609 3.91047828 1.64918967 7.66692085\n",
      " 2.24199781 3.62164317 3.68853891 4.82650881]\n",
      "##########\n",
      "epoch:2 step:9405[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:2 step:9410[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:2 step:9415[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:2 step:9420[D loss: 1.000007] [G loss: 1.000045]\n",
      "epoch:2 step:9425[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:2 step:9430[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:2 step:9435[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:9440[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:2 step:9445[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:2 step:9450[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:2 step:9455[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:2 step:9460[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:2 step:9465[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:2 step:9470[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:2 step:9475[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:2 step:9480[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:9485[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:2 step:9490[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:2 step:9495[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:2 step:9500[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:9505[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:2 step:9510[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:9515[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:2 step:9520[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:2 step:9525[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:9530[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:9535[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:2 step:9540[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:2 step:9545[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:2 step:9550[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:2 step:9555[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:2 step:9560[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:2 step:9565[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:2 step:9570[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:2 step:9575[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:2 step:9580[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:2 step:9585[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:2 step:9590[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:9595[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:2 step:9600[D loss: 0.999974] [G loss: 1.000078]\n",
      "##############\n",
      "[2.46885885 2.54770399 2.20290907 3.75439069 1.64326222 7.45677452\n",
      " 2.33607058 3.68950853 3.72023923 5.03517417]\n",
      "##########\n",
      "epoch:2 step:9605[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:2 step:9610[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:2 step:9615[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:2 step:9620[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:2 step:9625[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:9630[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:2 step:9635[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:2 step:9640[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:2 step:9645[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:9650[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:9655[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:2 step:9660[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:2 step:9665[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:2 step:9670[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:2 step:9675[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:2 step:9680[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:2 step:9685[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:2 step:9690[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:9695[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:2 step:9700[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:2 step:9705[D loss: 0.999980] [G loss: 1.000024]\n",
      "epoch:2 step:9710[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:2 step:9715[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:2 step:9720[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:2 step:9725[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:2 step:9730[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:2 step:9735[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:2 step:9740[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:2 step:9745[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:2 step:9750[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:2 step:9755[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:2 step:9760[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:2 step:9765[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:2 step:9770[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:2 step:9775[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:2 step:9780[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:2 step:9785[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:2 step:9790[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:2 step:9795[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:2 step:9800[D loss: 0.999981] [G loss: 1.000058]\n",
      "##############\n",
      "[2.54016051 2.71008847 2.29393521 3.88967833 1.72157102 7.48445489\n",
      " 2.39565845 3.6291089  3.76829539 4.92465697]\n",
      "##########\n",
      "epoch:2 step:9805[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:2 step:9810[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:2 step:9815[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:2 step:9820[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:2 step:9825[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:2 step:9830[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:2 step:9835[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:2 step:9840[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:2 step:9845[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:2 step:9850[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:2 step:9855[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:2 step:9860[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:2 step:9865[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:2 step:9870[D loss: 0.999977] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:9875[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:2 step:9880[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:2 step:9885[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:2 step:9890[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:2 step:9895[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:9900[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:2 step:9905[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:2 step:9910[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:2 step:9915[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:2 step:9920[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:2 step:9925[D loss: 0.999991] [G loss: 1.000075]\n",
      "epoch:2 step:9930[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:9935[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:2 step:9940[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:2 step:9945[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:2 step:9950[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:2 step:9955[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:2 step:9960[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:2 step:9965[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:2 step:9970[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:2 step:9975[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:2 step:9980[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:2 step:9985[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:2 step:9990[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:2 step:9995[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:2 step:10000[D loss: 0.999970] [G loss: 1.000068]\n",
      "##############\n",
      "[2.57617273 2.57600086 2.21404345 3.83455507 1.6853895  7.3870364\n",
      " 2.40061665 3.72101789 3.75585043 5.17620183]\n",
      "##########\n",
      "epoch:2 step:10005[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:2 step:10010[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:2 step:10015[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:2 step:10020[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:2 step:10025[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:2 step:10030[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:2 step:10035[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:2 step:10040[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:2 step:10045[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:2 step:10050[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:2 step:10055[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:2 step:10060[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:2 step:10065[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:2 step:10070[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:10075[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:2 step:10080[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:2 step:10085[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:2 step:10090[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:2 step:10095[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:2 step:10100[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:2 step:10105[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:2 step:10110[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:2 step:10115[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:2 step:10120[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:2 step:10125[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:2 step:10130[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:2 step:10135[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:2 step:10140[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:2 step:10145[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:10150[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:2 step:10155[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:2 step:10160[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:2 step:10165[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:2 step:10170[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:2 step:10175[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:2 step:10180[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:2 step:10185[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:2 step:10190[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:2 step:10195[D loss: 0.999999] [G loss: 1.000068]\n",
      "epoch:2 step:10200[D loss: 0.999970] [G loss: 1.000060]\n",
      "##############\n",
      "[2.50787209 2.53819169 2.21920116 3.75906807 1.64187399 7.18812537\n",
      " 2.34095417 3.60452411 3.71338583 4.85603207]\n",
      "##########\n",
      "epoch:2 step:10205[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:2 step:10210[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:2 step:10215[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:2 step:10220[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:2 step:10225[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:2 step:10230[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:2 step:10235[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:2 step:10240[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:2 step:10245[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:2 step:10250[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:2 step:10255[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:2 step:10260[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:2 step:10265[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:2 step:10270[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:2 step:10275[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:2 step:10280[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:2 step:10285[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:2 step:10290[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:2 step:10295[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:2 step:10300[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:2 step:10305[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:2 step:10310[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:2 step:10315[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:2 step:10320[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:2 step:10325[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:2 step:10330[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:10335[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:2 step:10340[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:2 step:10345[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:2 step:10350[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:2 step:10355[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:2 step:10360[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:2 step:10365[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:2 step:10370[D loss: 0.999982] [G loss: 1.000092]\n",
      "epoch:2 step:10375[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:2 step:10380[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:2 step:10385[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:2 step:10390[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:2 step:10395[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:2 step:10400[D loss: 0.999975] [G loss: 1.000083]\n",
      "##############\n",
      "[2.50941317 2.6126725  2.20492716 3.7645619  1.64395706 7.26921262\n",
      " 2.43475948 3.54560036 3.69546225 5.04371568]\n",
      "##########\n",
      "epoch:2 step:10405[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:2 step:10410[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:2 step:10415[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:2 step:10420[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:2 step:10425[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:2 step:10430[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:2 step:10435[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:2 step:10440[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:2 step:10445[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:2 step:10450[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:2 step:10455[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:2 step:10460[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:2 step:10465[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:2 step:10470[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:2 step:10475[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:2 step:10480[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:2 step:10485[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:2 step:10490[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:2 step:10495[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:2 step:10500[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:2 step:10505[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:2 step:10510[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:2 step:10515[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:2 step:10520[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:2 step:10525[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:2 step:10530[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:2 step:10535[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:10540[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:2 step:10545[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:2 step:10550[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:2 step:10555[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:2 step:10560[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:2 step:10565[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:2 step:10570[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:2 step:10575[D loss: 0.999992] [G loss: 1.000051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:10580[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:10585[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:2 step:10590[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:2 step:10595[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:10600[D loss: 0.999981] [G loss: 1.000064]\n",
      "##############\n",
      "[2.46293303 2.44673514 2.29456279 3.92889384 1.60962069 7.33440477\n",
      " 2.28787544 3.81557576 3.69224321 4.780931  ]\n",
      "##########\n",
      "epoch:2 step:10605[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:2 step:10610[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:2 step:10615[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:2 step:10620[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:10625[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:2 step:10630[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:2 step:10635[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:2 step:10640[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:2 step:10645[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:10650[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:2 step:10655[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:2 step:10660[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:2 step:10665[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:2 step:10670[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:2 step:10675[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:2 step:10680[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:2 step:10685[D loss: 1.000007] [G loss: 1.000041]\n",
      "epoch:2 step:10690[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:2 step:10695[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:10700[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:2 step:10705[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:2 step:10710[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:2 step:10715[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:2 step:10720[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:2 step:10725[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:2 step:10730[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:2 step:10735[D loss: 1.000000] [G loss: 1.000040]\n",
      "epoch:2 step:10740[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:10745[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:2 step:10750[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:2 step:10755[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:2 step:10760[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:2 step:10765[D loss: 0.999954] [G loss: 1.000092]\n",
      "epoch:2 step:10770[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:2 step:10775[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:10780[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:2 step:10785[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:2 step:10790[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:2 step:10795[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:2 step:10800[D loss: 0.999974] [G loss: 1.000066]\n",
      "##############\n",
      "[2.49463348 2.56229945 2.28464524 4.0181722  1.64154748 7.52612655\n",
      " 2.35994303 3.78819973 3.71436832 5.22221681]\n",
      "##########\n",
      "epoch:2 step:10805[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:2 step:10810[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:2 step:10815[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:2 step:10820[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:2 step:10825[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:2 step:10830[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:2 step:10835[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:2 step:10840[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:2 step:10845[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:2 step:10850[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:2 step:10855[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:2 step:10860[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:2 step:10865[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:2 step:10870[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:2 step:10875[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:2 step:10880[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:2 step:10885[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:2 step:10890[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:10895[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:2 step:10900[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:10905[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:2 step:10910[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:2 step:10915[D loss: 0.999994] [G loss: 1.000067]\n",
      "epoch:2 step:10920[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:2 step:10925[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:2 step:10930[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:2 step:10935[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:2 step:10940[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:2 step:10945[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:10950[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:2 step:10955[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:2 step:10960[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:2 step:10965[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:2 step:10970[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:2 step:10975[D loss: 1.000021] [G loss: 1.000042]\n",
      "epoch:2 step:10980[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:2 step:10985[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:2 step:10990[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:2 step:10995[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:2 step:11000[D loss: 0.999973] [G loss: 1.000063]\n",
      "##############\n",
      "[2.55178895 2.50007373 2.28501649 3.81622078 1.67189284 7.04681251\n",
      " 2.33882442 3.80167373 3.67005024 4.76338587]\n",
      "##########\n",
      "epoch:2 step:11005[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:2 step:11010[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:2 step:11015[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:2 step:11020[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:2 step:11025[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:2 step:11030[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:2 step:11035[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:2 step:11040[D loss: 0.999987] [G loss: 1.000084]\n",
      "epoch:2 step:11045[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:2 step:11050[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:11055[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:2 step:11060[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:11065[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:2 step:11070[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:2 step:11075[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:2 step:11080[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:2 step:11085[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:2 step:11090[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:2 step:11095[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:2 step:11100[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:2 step:11105[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:2 step:11110[D loss: 1.000001] [G loss: 1.000046]\n",
      "epoch:2 step:11115[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:11120[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:2 step:11125[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:2 step:11130[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:2 step:11135[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:2 step:11140[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:2 step:11145[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:2 step:11150[D loss: 1.000000] [G loss: 1.000063]\n",
      "epoch:2 step:11155[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:2 step:11160[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:2 step:11165[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:2 step:11170[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:2 step:11175[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:2 step:11180[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:2 step:11185[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:2 step:11190[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:2 step:11195[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:2 step:11200[D loss: 0.999965] [G loss: 1.000074]\n",
      "##############\n",
      "[2.54085386 2.66410147 2.30698694 3.79938272 1.68595083 7.29356151\n",
      " 2.31095608 3.69303944 3.78025139 4.97297449]\n",
      "##########\n",
      "epoch:2 step:11205[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:2 step:11210[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:2 step:11215[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:2 step:11220[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:2 step:11225[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:2 step:11230[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:2 step:11235[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:2 step:11240[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:2 step:11245[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:2 step:11250[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:2 step:11255[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:2 step:11260[D loss: 0.999972] [G loss: 1.000086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:11265[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:2 step:11270[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:2 step:11275[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:2 step:11280[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:2 step:11285[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:2 step:11290[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:2 step:11295[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:2 step:11300[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:2 step:11305[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:2 step:11310[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:2 step:11315[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:2 step:11320[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:2 step:11325[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:11330[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:2 step:11335[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:2 step:11340[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:2 step:11345[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:2 step:11350[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:2 step:11355[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:2 step:11360[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:2 step:11365[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:2 step:11370[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:2 step:11375[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:2 step:11380[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:2 step:11385[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:2 step:11390[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:2 step:11395[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:2 step:11400[D loss: 0.999969] [G loss: 1.000066]\n",
      "##############\n",
      "[2.44641283 2.59428581 2.2098493  3.79767316 1.62474034 7.14699301\n",
      " 2.34908136 3.59487656 3.73876219 4.70708319]\n",
      "##########\n",
      "epoch:2 step:11405[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:2 step:11410[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:2 step:11415[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:2 step:11420[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:2 step:11425[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:2 step:11430[D loss: 1.000002] [G loss: 1.000072]\n",
      "epoch:2 step:11435[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:2 step:11440[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:2 step:11445[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:2 step:11450[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:2 step:11455[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:2 step:11460[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:2 step:11465[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:2 step:11470[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:11475[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:2 step:11480[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:2 step:11485[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:2 step:11490[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:2 step:11495[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:2 step:11500[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:2 step:11505[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:2 step:11510[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:2 step:11515[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:2 step:11520[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:2 step:11525[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:2 step:11530[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:2 step:11535[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:2 step:11540[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:2 step:11545[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:2 step:11550[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:2 step:11555[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:2 step:11560[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:2 step:11565[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:2 step:11570[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:2 step:11575[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:2 step:11580[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:2 step:11585[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:2 step:11590[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:2 step:11595[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:2 step:11600[D loss: 0.999971] [G loss: 1.000078]\n",
      "##############\n",
      "[2.494856   2.51125077 2.26369021 3.84375976 1.64914041 7.32905839\n",
      " 2.27257463 3.88665903 3.6482161  5.08268541]\n",
      "##########\n",
      "epoch:2 step:11605[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:2 step:11610[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:2 step:11615[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:2 step:11620[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:2 step:11625[D loss: 0.999998] [G loss: 1.000075]\n",
      "epoch:2 step:11630[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:2 step:11635[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:2 step:11640[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:2 step:11645[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:2 step:11650[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:2 step:11655[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:2 step:11660[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:2 step:11665[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:2 step:11670[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:2 step:11675[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:2 step:11680[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:2 step:11685[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:11690[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:2 step:11695[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:2 step:11700[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:2 step:11705[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:2 step:11710[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:2 step:11715[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:2 step:11720[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:2 step:11725[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:2 step:11730[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:2 step:11735[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:2 step:11740[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:2 step:11745[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:2 step:11750[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:2 step:11755[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:2 step:11760[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:2 step:11765[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:2 step:11770[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:2 step:11775[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:2 step:11780[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:2 step:11785[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:2 step:11790[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:11795[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:2 step:11800[D loss: 0.999982] [G loss: 1.000072]\n",
      "##############\n",
      "[2.55450529 2.56678653 2.33189619 4.02575577 1.74419352 7.3985821\n",
      " 2.51613903 3.90386756 3.81302963 5.13973619]\n",
      "##########\n",
      "epoch:2 step:11805[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:2 step:11810[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:2 step:11815[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:2 step:11820[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:2 step:11825[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:2 step:11830[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:2 step:11835[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:2 step:11840[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:2 step:11845[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:2 step:11850[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:2 step:11855[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:2 step:11860[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:2 step:11865[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:11870[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:2 step:11875[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:2 step:11880[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:2 step:11885[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:11890[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:2 step:11895[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:2 step:11900[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:2 step:11905[D loss: 1.000001] [G loss: 1.000064]\n",
      "epoch:2 step:11910[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:2 step:11915[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:2 step:11920[D loss: 0.999992] [G loss: 1.000057]\n",
      "epoch:2 step:11925[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:2 step:11930[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:2 step:11935[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:2 step:11940[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:2 step:11945[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:2 step:11950[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:2 step:11955[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:2 step:11960[D loss: 0.999974] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:11965[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:2 step:11970[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:2 step:11975[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:2 step:11980[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:2 step:11985[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:2 step:11990[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:2 step:11995[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:2 step:12000[D loss: 0.999978] [G loss: 1.000064]\n",
      "##############\n",
      "[2.50833478 2.52929648 2.34310495 3.82099892 1.66216245 7.37449414\n",
      " 2.48828285 3.68378058 3.78305474 4.37035586]\n",
      "##########\n",
      "epoch:2 step:12005[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:2 step:12010[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:2 step:12015[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:2 step:12020[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:2 step:12025[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:2 step:12030[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:2 step:12035[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:2 step:12040[D loss: 0.999994] [G loss: 1.000069]\n",
      "epoch:2 step:12045[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:2 step:12050[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:2 step:12055[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:2 step:12060[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:2 step:12065[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:2 step:12070[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:2 step:12075[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:2 step:12080[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:2 step:12085[D loss: 0.999966] [G loss: 1.000104]\n",
      "epoch:2 step:12090[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:2 step:12095[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:2 step:12100[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:2 step:12105[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:2 step:12110[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:2 step:12115[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:2 step:12120[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:2 step:12125[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:2 step:12130[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:2 step:12135[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:2 step:12140[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:2 step:12145[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:2 step:12150[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:2 step:12155[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:2 step:12160[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:2 step:12165[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:2 step:12170[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:2 step:12175[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:2 step:12180[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:2 step:12185[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:2 step:12190[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:2 step:12195[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:2 step:12200[D loss: 0.999978] [G loss: 1.000086]\n",
      "##############\n",
      "[2.56614546 2.4993195  2.26644371 3.88774321 1.67551696 7.28021556\n",
      " 2.57837307 3.67862488 3.76996223 5.19449205]\n",
      "##########\n",
      "epoch:2 step:12205[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:2 step:12210[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:2 step:12215[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:2 step:12220[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:2 step:12225[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:2 step:12230[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:2 step:12235[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:2 step:12240[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:2 step:12245[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:2 step:12250[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:2 step:12255[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:2 step:12260[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:2 step:12265[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:2 step:12270[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:2 step:12275[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:2 step:12280[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:2 step:12285[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:2 step:12290[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:2 step:12295[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:2 step:12300[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:2 step:12305[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:2 step:12310[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:2 step:12315[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:2 step:12320[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:2 step:12325[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:12330[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:2 step:12335[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:12340[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:2 step:12345[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:2 step:12350[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:2 step:12355[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:2 step:12360[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:2 step:12365[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:2 step:12370[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:2 step:12375[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:2 step:12380[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:2 step:12385[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:2 step:12390[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:12395[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:2 step:12400[D loss: 0.999974] [G loss: 1.000097]\n",
      "##############\n",
      "[2.49563205 2.46778983 2.1388636  3.76686644 1.56673754 7.34685515\n",
      " 2.34497862 3.73812145 3.71971503 4.31295101]\n",
      "##########\n",
      "epoch:2 step:12405[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:2 step:12410[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:2 step:12415[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:2 step:12420[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:2 step:12425[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:2 step:12430[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:2 step:12435[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:12440[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:2 step:12445[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:2 step:12450[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:2 step:12455[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:2 step:12460[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:2 step:12465[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:2 step:12470[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:2 step:12475[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:2 step:12480[D loss: 0.999976] [G loss: 1.000099]\n",
      "epoch:2 step:12485[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:2 step:12490[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:2 step:12495[D loss: 1.000003] [G loss: 1.000039]\n",
      "epoch:2 step:12500[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:2 step:12505[D loss: 0.999994] [G loss: 1.000070]\n",
      "epoch:2 step:12510[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:2 step:12515[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:2 step:12520[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:12525[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:2 step:12530[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:2 step:12535[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:2 step:12540[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:2 step:12545[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:2 step:12550[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:2 step:12555[D loss: 0.999990] [G loss: 1.000073]\n",
      "epoch:2 step:12560[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:2 step:12565[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:2 step:12570[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:2 step:12575[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:2 step:12580[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:2 step:12585[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:2 step:12590[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:2 step:12595[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:2 step:12600[D loss: 0.999965] [G loss: 1.000092]\n",
      "##############\n",
      "[2.53709039 2.49244858 2.16949946 4.12117445 1.58109129 7.46092532\n",
      " 2.39038187 3.80026822 3.7180857  4.52686203]\n",
      "##########\n",
      "epoch:2 step:12605[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:2 step:12610[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:2 step:12615[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:2 step:12620[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:12625[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:2 step:12630[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:2 step:12635[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:2 step:12640[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:2 step:12645[D loss: 0.999978] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:12650[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:2 step:12655[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:2 step:12660[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:2 step:12665[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:2 step:12670[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:2 step:12675[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:2 step:12680[D loss: 0.999999] [G loss: 1.000062]\n",
      "epoch:2 step:12685[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:2 step:12690[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:2 step:12695[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:2 step:12700[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:2 step:12705[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:2 step:12710[D loss: 0.999984] [G loss: 1.000092]\n",
      "epoch:2 step:12715[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:2 step:12720[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:2 step:12725[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:2 step:12730[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:2 step:12735[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:2 step:12740[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:2 step:12745[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:2 step:12750[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:2 step:12755[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:2 step:12760[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:2 step:12765[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:12770[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:2 step:12775[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:2 step:12780[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:12785[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:2 step:12790[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:12795[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:2 step:12800[D loss: 0.999964] [G loss: 1.000081]\n",
      "##############\n",
      "[2.58720493 2.59982965 2.27971484 3.92002356 1.70181112 7.20306219\n",
      " 2.29134614 4.02810919 3.73439827 5.35138704]\n",
      "##########\n",
      "epoch:2 step:12805[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:2 step:12810[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:2 step:12815[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:2 step:12820[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:2 step:12825[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:2 step:12830[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:2 step:12835[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:2 step:12840[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:2 step:12845[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:2 step:12850[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:2 step:12855[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:2 step:12860[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:2 step:12865[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:2 step:12870[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:2 step:12875[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:2 step:12880[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:2 step:12885[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:2 step:12890[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:2 step:12895[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:2 step:12900[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:2 step:12905[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:2 step:12910[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:2 step:12915[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:2 step:12920[D loss: 1.000001] [G loss: 1.000047]\n",
      "epoch:2 step:12925[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:2 step:12930[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:2 step:12935[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:2 step:12940[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:2 step:12945[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:2 step:12950[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:2 step:12955[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:2 step:12960[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:2 step:12965[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:2 step:12970[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:2 step:12975[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:2 step:12980[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:2 step:12985[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:2 step:12990[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:2 step:12995[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:2 step:13000[D loss: 0.999985] [G loss: 1.000070]\n",
      "##############\n",
      "[2.51508465 2.47658942 2.2044916  3.83325836 1.6335655  7.70466843\n",
      " 2.39356254 3.95357413 3.67709751 4.57861974]\n",
      "##########\n",
      "epoch:2 step:13005[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:2 step:13010[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:2 step:13015[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:2 step:13020[D loss: 0.999989] [G loss: 1.000086]\n",
      "epoch:2 step:13025[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:13030[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:13035[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:2 step:13040[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:2 step:13045[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:13050[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:2 step:13055[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:2 step:13060[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:2 step:13065[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:2 step:13070[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:13075[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:2 step:13080[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:2 step:13085[D loss: 1.000002] [G loss: 1.000051]\n",
      "epoch:2 step:13090[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:2 step:13095[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:2 step:13100[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:2 step:13105[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:2 step:13110[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:2 step:13115[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:2 step:13120[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:2 step:13125[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:2 step:13130[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:13135[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:2 step:13140[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:2 step:13145[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:2 step:13150[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:13155[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:2 step:13160[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:2 step:13165[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:2 step:13170[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:2 step:13175[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:2 step:13180[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:2 step:13185[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:2 step:13190[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:2 step:13195[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:2 step:13200[D loss: 0.999978] [G loss: 1.000067]\n",
      "##############\n",
      "[2.58892652 2.67188743 2.25537911 3.97472534 1.64704959 7.43095326\n",
      " 2.38550604 3.80930483 3.7231491  4.87472618]\n",
      "##########\n",
      "epoch:2 step:13205[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:2 step:13210[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:2 step:13215[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:2 step:13220[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:2 step:13225[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:2 step:13230[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:2 step:13235[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:2 step:13240[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:2 step:13245[D loss: 1.000002] [G loss: 1.000055]\n",
      "epoch:2 step:13250[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:2 step:13255[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:2 step:13260[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:2 step:13265[D loss: 0.999981] [G loss: 1.000095]\n",
      "epoch:2 step:13270[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:2 step:13275[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:2 step:13280[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:2 step:13285[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:2 step:13290[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:2 step:13295[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:2 step:13300[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:2 step:13305[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:2 step:13310[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:2 step:13315[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:2 step:13320[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:2 step:13325[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:2 step:13330[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:2 step:13335[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:2 step:13340[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:2 step:13345[D loss: 0.999990] [G loss: 1.000084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:13350[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:2 step:13355[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:2 step:13360[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:2 step:13365[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:2 step:13370[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:2 step:13375[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:2 step:13380[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:2 step:13385[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:2 step:13390[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:2 step:13395[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:2 step:13400[D loss: 0.999982] [G loss: 1.000089]\n",
      "##############\n",
      "[2.68149971 2.58177673 2.46497157 4.08119324 1.67573517 7.6230228\n",
      " 2.49509232 3.87563108 3.82836804 5.50056269]\n",
      "##########\n",
      "epoch:2 step:13405[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:2 step:13410[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:2 step:13415[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:2 step:13420[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:2 step:13425[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:2 step:13430[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:2 step:13435[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:2 step:13440[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:2 step:13445[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:2 step:13450[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:2 step:13455[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:2 step:13460[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:2 step:13465[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:2 step:13470[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:13475[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:2 step:13480[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:2 step:13485[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:2 step:13490[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:2 step:13495[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:2 step:13500[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:2 step:13505[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:2 step:13510[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:2 step:13515[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:2 step:13520[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:2 step:13525[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:2 step:13530[D loss: 1.000012] [G loss: 1.000039]\n",
      "epoch:2 step:13535[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:2 step:13540[D loss: 1.000004] [G loss: 1.000085]\n",
      "epoch:2 step:13545[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:2 step:13550[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:2 step:13555[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:2 step:13560[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:2 step:13565[D loss: 1.000013] [G loss: 1.000050]\n",
      "epoch:2 step:13570[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:2 step:13575[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:2 step:13580[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:2 step:13585[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:2 step:13590[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:2 step:13595[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:2 step:13600[D loss: 0.999981] [G loss: 1.000075]\n",
      "##############\n",
      "[2.64287603 2.60736831 2.31193784 3.83750642 1.71246864 7.36443232\n",
      " 2.56321073 3.92902622 3.83831209 4.94629841]\n",
      "##########\n",
      "epoch:2 step:13605[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:2 step:13610[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:2 step:13615[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:2 step:13620[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:2 step:13625[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:2 step:13630[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:2 step:13635[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:2 step:13640[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:2 step:13645[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:2 step:13650[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:2 step:13655[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:2 step:13660[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:2 step:13665[D loss: 0.999994] [G loss: 1.000079]\n",
      "epoch:2 step:13670[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:2 step:13675[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:2 step:13680[D loss: 0.999986] [G loss: 1.000082]\n",
      "epoch:2 step:13685[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:2 step:13690[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:2 step:13695[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:2 step:13700[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:2 step:13705[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:2 step:13710[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:2 step:13715[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:2 step:13720[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:2 step:13725[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:2 step:13730[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:2 step:13735[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:2 step:13740[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:2 step:13745[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:2 step:13750[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:2 step:13755[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:2 step:13760[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:2 step:13765[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:2 step:13770[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:2 step:13775[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:2 step:13780[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:2 step:13785[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:2 step:13790[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:2 step:13795[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:2 step:13800[D loss: 0.999973] [G loss: 1.000093]\n",
      "##############\n",
      "[2.54742725 2.62936123 2.29474745 3.86462646 1.73250341 7.66654178\n",
      " 2.50750197 3.87985323 3.7569937  5.02546691]\n",
      "##########\n",
      "epoch:2 step:13805[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:2 step:13810[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:2 step:13815[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:2 step:13820[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:2 step:13825[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:13830[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:2 step:13835[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:2 step:13840[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:2 step:13845[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:13850[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:2 step:13855[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:2 step:13860[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:2 step:13865[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:2 step:13870[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:2 step:13875[D loss: 1.000012] [G loss: 1.000044]\n",
      "epoch:2 step:13880[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:2 step:13885[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:2 step:13890[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:13895[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:2 step:13900[D loss: 0.999985] [G loss: 1.000087]\n",
      "epoch:2 step:13905[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:2 step:13910[D loss: 1.000022] [G loss: 0.999996]\n",
      "epoch:2 step:13915[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:2 step:13920[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:2 step:13925[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:2 step:13930[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:2 step:13935[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:2 step:13940[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:13945[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:2 step:13950[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:2 step:13955[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:2 step:13960[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:2 step:13965[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:2 step:13970[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:2 step:13975[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:2 step:13980[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:2 step:13985[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:2 step:13990[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:2 step:13995[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:2 step:14000[D loss: 0.999977] [G loss: 1.000071]\n",
      "##############\n",
      "[2.57151104 2.48900108 2.25292323 3.93560709 1.65308616 7.34360858\n",
      " 2.42820717 3.8575226  3.7518264  5.15783926]\n",
      "##########\n",
      "epoch:2 step:14005[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:2 step:14010[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:2 step:14015[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:2 step:14020[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:2 step:14025[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:2 step:14030[D loss: 0.999975] [G loss: 1.000066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:14035[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:2 step:14040[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:2 step:14045[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:2 step:14050[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:2 step:14055[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:3 step:14060[D loss: 1.000007] [G loss: 1.000037]\n",
      "epoch:3 step:14065[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:14070[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:3 step:14075[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:3 step:14080[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:3 step:14085[D loss: 1.000006] [G loss: 1.000063]\n",
      "epoch:3 step:14090[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:3 step:14095[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:3 step:14100[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:3 step:14105[D loss: 1.000021] [G loss: 1.000043]\n",
      "epoch:3 step:14110[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:3 step:14115[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:3 step:14120[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:3 step:14125[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:3 step:14130[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:3 step:14135[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:3 step:14140[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:3 step:14145[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:3 step:14150[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:3 step:14155[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:3 step:14160[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:3 step:14165[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:3 step:14170[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:3 step:14175[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:3 step:14180[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:3 step:14185[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:3 step:14190[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:3 step:14195[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:3 step:14200[D loss: 0.999975] [G loss: 1.000075]\n",
      "##############\n",
      "[2.66189636 2.60268191 2.34687469 3.96739414 1.71679214 6.95648595\n",
      " 2.45769311 3.92133458 3.84234612 4.86746989]\n",
      "##########\n",
      "epoch:3 step:14205[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:3 step:14210[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:3 step:14215[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:3 step:14220[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:3 step:14225[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:3 step:14230[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:3 step:14235[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:3 step:14240[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:3 step:14245[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:14250[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:3 step:14255[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:3 step:14260[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:3 step:14265[D loss: 0.999985] [G loss: 1.000097]\n",
      "epoch:3 step:14270[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:3 step:14275[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:3 step:14280[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:3 step:14285[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:3 step:14290[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:3 step:14295[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:3 step:14300[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:3 step:14305[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:3 step:14310[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:3 step:14315[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:3 step:14320[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:3 step:14325[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:3 step:14330[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:3 step:14335[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:3 step:14340[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:3 step:14345[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:3 step:14350[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:3 step:14355[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:3 step:14360[D loss: 0.999984] [G loss: 1.000093]\n",
      "epoch:3 step:14365[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:3 step:14370[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:3 step:14375[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:3 step:14380[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:14385[D loss: 0.999994] [G loss: 1.000071]\n",
      "epoch:3 step:14390[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:3 step:14395[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:3 step:14400[D loss: 0.999992] [G loss: 1.000058]\n",
      "##############\n",
      "[2.61147749 2.65300188 2.4151781  4.10531429 1.67579981 7.28781485\n",
      " 2.38787522 3.94856682 3.84405883 4.62489726]\n",
      "##########\n",
      "epoch:3 step:14405[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:3 step:14410[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:3 step:14415[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:3 step:14420[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:3 step:14425[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:3 step:14430[D loss: 1.000007] [G loss: 1.000048]\n",
      "epoch:3 step:14435[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:3 step:14440[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:3 step:14445[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:3 step:14450[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:3 step:14455[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:3 step:14460[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:3 step:14465[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:3 step:14470[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:3 step:14475[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:3 step:14480[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:3 step:14485[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:3 step:14490[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:3 step:14495[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:3 step:14500[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:3 step:14505[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:3 step:14510[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:3 step:14515[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:3 step:14520[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:3 step:14525[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:3 step:14530[D loss: 0.999987] [G loss: 1.000093]\n",
      "epoch:3 step:14535[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:3 step:14540[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:3 step:14545[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:3 step:14550[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:3 step:14555[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:3 step:14560[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:3 step:14565[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:3 step:14570[D loss: 0.999980] [G loss: 1.000093]\n",
      "epoch:3 step:14575[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:3 step:14580[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:3 step:14585[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:3 step:14590[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:3 step:14595[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:3 step:14600[D loss: 0.999983] [G loss: 1.000071]\n",
      "##############\n",
      "[2.52632597 2.60913264 2.43852197 3.97780576 1.68582418 7.41300834\n",
      " 2.43865214 3.90014652 3.8498163  5.30117249]\n",
      "##########\n",
      "epoch:3 step:14605[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:3 step:14610[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:3 step:14615[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:3 step:14620[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:3 step:14625[D loss: 0.999967] [G loss: 1.000104]\n",
      "epoch:3 step:14630[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:3 step:14635[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:3 step:14640[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:14645[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:14650[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:3 step:14655[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:3 step:14660[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:3 step:14665[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:3 step:14670[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:3 step:14675[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:14680[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:3 step:14685[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:3 step:14690[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:3 step:14695[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:3 step:14700[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:3 step:14705[D loss: 0.999985] [G loss: 1.000082]\n",
      "epoch:3 step:14710[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:3 step:14715[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:3 step:14720[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:3 step:14725[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:3 step:14730[D loss: 0.999969] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:14735[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:3 step:14740[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:3 step:14745[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:3 step:14750[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:3 step:14755[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:3 step:14760[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:3 step:14765[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:3 step:14770[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:3 step:14775[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:3 step:14780[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:3 step:14785[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:3 step:14790[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:3 step:14795[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:3 step:14800[D loss: 0.999986] [G loss: 1.000077]\n",
      "##############\n",
      "[2.58743949 2.53968211 2.34442057 3.98264171 1.67911601 7.48757326\n",
      " 2.5029764  3.99985626 3.78713664 4.86912087]\n",
      "##########\n",
      "epoch:3 step:14805[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:3 step:14810[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:3 step:14815[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:3 step:14820[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:3 step:14825[D loss: 1.000001] [G loss: 1.000060]\n",
      "epoch:3 step:14830[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:3 step:14835[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:3 step:14840[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:3 step:14845[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:3 step:14850[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:3 step:14855[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:3 step:14860[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:3 step:14865[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:3 step:14870[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:3 step:14875[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:14880[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:3 step:14885[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:3 step:14890[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:3 step:14895[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:3 step:14900[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:3 step:14905[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:3 step:14910[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:3 step:14915[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:3 step:14920[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:3 step:14925[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:3 step:14930[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:3 step:14935[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:14940[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:3 step:14945[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:3 step:14950[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:3 step:14955[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:3 step:14960[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:14965[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:3 step:14970[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:3 step:14975[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:3 step:14980[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:3 step:14985[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:3 step:14990[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:3 step:14995[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:3 step:15000[D loss: 0.999982] [G loss: 1.000067]\n",
      "##############\n",
      "[2.52796501 2.45775363 2.29091441 3.81190205 1.66613746 7.51968333\n",
      " 2.59813505 4.00702033 3.69495763 4.83665588]\n",
      "##########\n",
      "epoch:3 step:15005[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:3 step:15010[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:3 step:15015[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:3 step:15020[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:3 step:15025[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:3 step:15030[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:3 step:15035[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:3 step:15040[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:3 step:15045[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:3 step:15050[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:15055[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:3 step:15060[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:3 step:15065[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:3 step:15070[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:3 step:15075[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:15080[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:3 step:15085[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:3 step:15090[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:3 step:15095[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:3 step:15100[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:3 step:15105[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:3 step:15110[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:3 step:15115[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:3 step:15120[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:3 step:15125[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:3 step:15130[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:3 step:15135[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:3 step:15140[D loss: 0.999988] [G loss: 1.000129]\n",
      "epoch:3 step:15145[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:3 step:15150[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:3 step:15155[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:3 step:15160[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:15165[D loss: 1.000007] [G loss: 1.000020]\n",
      "epoch:3 step:15170[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:3 step:15175[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:3 step:15180[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:15185[D loss: 0.999968] [G loss: 1.000099]\n",
      "epoch:3 step:15190[D loss: 0.999974] [G loss: 1.000101]\n",
      "epoch:3 step:15195[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:3 step:15200[D loss: 0.999975] [G loss: 1.000079]\n",
      "##############\n",
      "[2.62397054 2.5474049  2.34393828 3.6436137  1.7132386  8.25158739\n",
      " 2.50648343 3.88411274 3.85371629 4.80740443]\n",
      "##########\n",
      "epoch:3 step:15205[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:3 step:15210[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:3 step:15215[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:3 step:15220[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:3 step:15225[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:3 step:15230[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:3 step:15235[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:3 step:15240[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:3 step:15245[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:3 step:15250[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:3 step:15255[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:3 step:15260[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:3 step:15265[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:3 step:15270[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:3 step:15275[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:3 step:15280[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:3 step:15285[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:15290[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:3 step:15295[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:3 step:15300[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:3 step:15305[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:15310[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:3 step:15315[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:3 step:15320[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:3 step:15325[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:3 step:15330[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:3 step:15335[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:3 step:15340[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:3 step:15345[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:3 step:15350[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:3 step:15355[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:3 step:15360[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:3 step:15365[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:3 step:15370[D loss: 1.000015] [G loss: 1.000022]\n",
      "epoch:3 step:15375[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:3 step:15380[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:15385[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:3 step:15390[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:3 step:15395[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:3 step:15400[D loss: 0.999984] [G loss: 1.000048]\n",
      "##############\n",
      "[2.54235599 2.58025899 2.33855798 3.86053777 1.69440382 7.46092139\n",
      " 2.55181649 4.01966722 3.75668352 4.66662542]\n",
      "##########\n",
      "epoch:3 step:15405[D loss: 1.000003] [G loss: 1.000046]\n",
      "epoch:3 step:15410[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:3 step:15415[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:3 step:15420[D loss: 0.999998] [G loss: 1.000043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:15425[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:3 step:15430[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:3 step:15435[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:15440[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:3 step:15445[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:3 step:15450[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:3 step:15455[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:3 step:15460[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:3 step:15465[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:3 step:15470[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:3 step:15475[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:3 step:15480[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:3 step:15485[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:3 step:15490[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:3 step:15495[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:3 step:15500[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:3 step:15505[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:3 step:15510[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:3 step:15515[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:3 step:15520[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:3 step:15525[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:3 step:15530[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:3 step:15535[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:3 step:15540[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:3 step:15545[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:3 step:15550[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:3 step:15555[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:3 step:15560[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:3 step:15565[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:3 step:15570[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:3 step:15575[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:3 step:15580[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:3 step:15585[D loss: 0.999969] [G loss: 1.000100]\n",
      "epoch:3 step:15590[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:3 step:15595[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:3 step:15600[D loss: 1.000006] [G loss: 1.000056]\n",
      "##############\n",
      "[2.5328255  2.4654238  2.35420869 4.22678376 1.67792994 7.50891918\n",
      " 2.51578909 4.03196164 3.79642475 4.93202166]\n",
      "##########\n",
      "epoch:3 step:15605[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:3 step:15610[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:3 step:15615[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:3 step:15620[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:3 step:15625[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:3 step:15630[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:3 step:15635[D loss: 0.999996] [G loss: 1.000105]\n",
      "epoch:3 step:15640[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:3 step:15645[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:3 step:15650[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:3 step:15655[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:3 step:15660[D loss: 0.999986] [G loss: 1.000093]\n",
      "epoch:3 step:15665[D loss: 0.999998] [G loss: 1.000044]\n",
      "epoch:3 step:15670[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:3 step:15675[D loss: 0.999964] [G loss: 1.000102]\n",
      "epoch:3 step:15680[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:3 step:15685[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:3 step:15690[D loss: 0.999980] [G loss: 1.000102]\n",
      "epoch:3 step:15695[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:3 step:15700[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:3 step:15705[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:3 step:15710[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:3 step:15715[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:3 step:15720[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:3 step:15725[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:3 step:15730[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:3 step:15735[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:3 step:15740[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:3 step:15745[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:3 step:15750[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:3 step:15755[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:3 step:15760[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:3 step:15765[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:3 step:15770[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:3 step:15775[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:3 step:15780[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:3 step:15785[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:3 step:15790[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:3 step:15795[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:3 step:15800[D loss: 0.999981] [G loss: 1.000075]\n",
      "##############\n",
      "[2.61701917 2.5045353  2.3329639  3.8607616  1.69169539 7.6125807\n",
      " 2.69090534 3.95097381 3.82250957 5.26246183]\n",
      "##########\n",
      "epoch:3 step:15805[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:3 step:15810[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:3 step:15815[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:3 step:15820[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:3 step:15825[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:3 step:15830[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:3 step:15835[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:3 step:15840[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:3 step:15845[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:3 step:15850[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:3 step:15855[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:3 step:15860[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:3 step:15865[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:3 step:15870[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:3 step:15875[D loss: 0.999977] [G loss: 1.000107]\n",
      "epoch:3 step:15880[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:3 step:15885[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:3 step:15890[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:3 step:15895[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:3 step:15900[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:3 step:15905[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:3 step:15910[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:3 step:15915[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:3 step:15920[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:3 step:15925[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:3 step:15930[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:3 step:15935[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:3 step:15940[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:3 step:15945[D loss: 0.999972] [G loss: 1.000120]\n",
      "epoch:3 step:15950[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:3 step:15955[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:3 step:15960[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:3 step:15965[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:3 step:15970[D loss: 0.999987] [G loss: 1.000097]\n",
      "epoch:3 step:15975[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:3 step:15980[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:3 step:15985[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:3 step:15990[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:3 step:15995[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:3 step:16000[D loss: 0.999984] [G loss: 1.000093]\n",
      "##############\n",
      "[2.5721627  2.46863701 2.28332261 3.83378698 1.65050081 7.20193046\n",
      " 2.51017639 3.9126575  3.75349747 4.78317597]\n",
      "##########\n",
      "epoch:3 step:16005[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:3 step:16010[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:3 step:16015[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:3 step:16020[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:3 step:16025[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:3 step:16030[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:3 step:16035[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:3 step:16040[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:3 step:16045[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:3 step:16050[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:16055[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:3 step:16060[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:3 step:16065[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:3 step:16070[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:3 step:16075[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:3 step:16080[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:3 step:16085[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:3 step:16090[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:3 step:16095[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:3 step:16100[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:3 step:16105[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:3 step:16110[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:3 step:16115[D loss: 1.000027] [G loss: 1.000033]\n",
      "epoch:3 step:16120[D loss: 0.999986] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:16125[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:3 step:16130[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:3 step:16135[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:3 step:16140[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:3 step:16145[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:16150[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:3 step:16155[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:3 step:16160[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:3 step:16165[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:3 step:16170[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:3 step:16175[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:3 step:16180[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:3 step:16185[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:3 step:16190[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:3 step:16195[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:16200[D loss: 0.999981] [G loss: 1.000067]\n",
      "##############\n",
      "[2.6641266  2.45602449 2.34161351 4.00416106 1.6929407  7.55748822\n",
      " 2.51965643 4.00377761 3.86311946 4.85388125]\n",
      "##########\n",
      "epoch:3 step:16205[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:3 step:16210[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:3 step:16215[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:3 step:16220[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:3 step:16225[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:3 step:16230[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:3 step:16235[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:3 step:16240[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:3 step:16245[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:3 step:16250[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:3 step:16255[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:3 step:16260[D loss: 0.999990] [G loss: 1.000073]\n",
      "epoch:3 step:16265[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:3 step:16270[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:3 step:16275[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:3 step:16280[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:3 step:16285[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:16290[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:3 step:16295[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:3 step:16300[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:3 step:16305[D loss: 0.999972] [G loss: 1.000094]\n",
      "epoch:3 step:16310[D loss: 1.000004] [G loss: 1.000055]\n",
      "epoch:3 step:16315[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:3 step:16320[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:3 step:16325[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:3 step:16330[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:16335[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:3 step:16340[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:3 step:16345[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:3 step:16350[D loss: 1.000007] [G loss: 1.000076]\n",
      "epoch:3 step:16355[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:3 step:16360[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:3 step:16365[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:3 step:16370[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:3 step:16375[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:3 step:16380[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:3 step:16385[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:3 step:16390[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:3 step:16395[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:3 step:16400[D loss: 0.999983] [G loss: 1.000079]\n",
      "##############\n",
      "[2.70905323 2.55065223 2.31874572 3.85622985 1.64755644 8.6670826\n",
      " 2.45411136 3.95783486 3.80092694 4.54099581]\n",
      "##########\n",
      "epoch:3 step:16405[D loss: 0.999994] [G loss: 1.000075]\n",
      "epoch:3 step:16410[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:3 step:16415[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:3 step:16420[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:3 step:16425[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:3 step:16430[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:3 step:16435[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:3 step:16440[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:3 step:16445[D loss: 0.999982] [G loss: 1.000088]\n",
      "epoch:3 step:16450[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:3 step:16455[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:3 step:16460[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:3 step:16465[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:3 step:16470[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:3 step:16475[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:3 step:16480[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:3 step:16485[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:3 step:16490[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:16495[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:16500[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:3 step:16505[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:16510[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:3 step:16515[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:16520[D loss: 0.999994] [G loss: 1.000070]\n",
      "epoch:3 step:16525[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:3 step:16530[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:3 step:16535[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:3 step:16540[D loss: 0.999981] [G loss: 1.000092]\n",
      "epoch:3 step:16545[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:3 step:16550[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:3 step:16555[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:3 step:16560[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:3 step:16565[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:3 step:16570[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:3 step:16575[D loss: 0.999970] [G loss: 1.000105]\n",
      "epoch:3 step:16580[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:3 step:16585[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:3 step:16590[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:3 step:16595[D loss: 0.999966] [G loss: 1.000109]\n",
      "epoch:3 step:16600[D loss: 0.999974] [G loss: 1.000059]\n",
      "##############\n",
      "[2.58253709 2.53546476 2.44466264 4.20497417 1.72162846 7.44741706\n",
      " 2.50913124 3.97199322 3.84025863 4.74068949]\n",
      "##########\n",
      "epoch:3 step:16605[D loss: 0.999986] [G loss: 1.000099]\n",
      "epoch:3 step:16610[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:3 step:16615[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:3 step:16620[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:3 step:16625[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:3 step:16630[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:3 step:16635[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:3 step:16640[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:3 step:16645[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:3 step:16650[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:16655[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:3 step:16660[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:3 step:16665[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:3 step:16670[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:3 step:16675[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:3 step:16680[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:3 step:16685[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:3 step:16690[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:3 step:16695[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:3 step:16700[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:3 step:16705[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:3 step:16710[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:3 step:16715[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:3 step:16720[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:3 step:16725[D loss: 0.999993] [G loss: 1.000070]\n",
      "epoch:3 step:16730[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:3 step:16735[D loss: 0.999992] [G loss: 1.000057]\n",
      "epoch:3 step:16740[D loss: 1.000015] [G loss: 1.000052]\n",
      "epoch:3 step:16745[D loss: 0.999963] [G loss: 1.000099]\n",
      "epoch:3 step:16750[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:3 step:16755[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:3 step:16760[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:3 step:16765[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:3 step:16770[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:3 step:16775[D loss: 0.999996] [G loss: 1.000076]\n",
      "epoch:3 step:16780[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:3 step:16785[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:3 step:16790[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:3 step:16795[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:3 step:16800[D loss: 0.999979] [G loss: 1.000094]\n",
      "##############\n",
      "[2.59601623 2.49801384 2.35552891 3.96259573 1.67893121 7.5412699\n",
      " 2.48562355 3.90658276 3.85540875 5.43806576]\n",
      "##########\n",
      "epoch:3 step:16805[D loss: 0.999988] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:16810[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:3 step:16815[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:3 step:16820[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:3 step:16825[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:3 step:16830[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:3 step:16835[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:3 step:16840[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:3 step:16845[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:3 step:16850[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:3 step:16855[D loss: 0.999991] [G loss: 1.000075]\n",
      "epoch:3 step:16860[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:3 step:16865[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:3 step:16870[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:3 step:16875[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:3 step:16880[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:3 step:16885[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:3 step:16890[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:16895[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:3 step:16900[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:3 step:16905[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:3 step:16910[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:3 step:16915[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:3 step:16920[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:3 step:16925[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:3 step:16930[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:3 step:16935[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:3 step:16940[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:3 step:16945[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:3 step:16950[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:3 step:16955[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:3 step:16960[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:3 step:16965[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:3 step:16970[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:3 step:16975[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:3 step:16980[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:3 step:16985[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:3 step:16990[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:3 step:16995[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:3 step:17000[D loss: 0.999995] [G loss: 1.000100]\n",
      "##############\n",
      "[2.54397249 2.36568168 2.24658181 4.23544846 1.67504438 7.41377849\n",
      " 2.41634122 3.93829285 3.85361828 4.58801131]\n",
      "##########\n",
      "epoch:3 step:17005[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:3 step:17010[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:3 step:17015[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:3 step:17020[D loss: 0.999998] [G loss: 1.000060]\n",
      "epoch:3 step:17025[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:3 step:17030[D loss: 1.000016] [G loss: 1.000027]\n",
      "epoch:3 step:17035[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:3 step:17040[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:3 step:17045[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:3 step:17050[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:3 step:17055[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:3 step:17060[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:3 step:17065[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:3 step:17070[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:3 step:17075[D loss: 0.999996] [G loss: 1.000025]\n",
      "epoch:3 step:17080[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:3 step:17085[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:3 step:17090[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:3 step:17095[D loss: 0.999978] [G loss: 1.000098]\n",
      "epoch:3 step:17100[D loss: 0.999993] [G loss: 1.000083]\n",
      "epoch:3 step:17105[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:3 step:17110[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:3 step:17115[D loss: 1.000003] [G loss: 1.000005]\n",
      "epoch:3 step:17120[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:3 step:17125[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:3 step:17130[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:3 step:17135[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:3 step:17140[D loss: 0.999985] [G loss: 1.000090]\n",
      "epoch:3 step:17145[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:3 step:17150[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:3 step:17155[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:3 step:17160[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:3 step:17165[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:3 step:17170[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:3 step:17175[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:3 step:17180[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:3 step:17185[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:3 step:17190[D loss: 0.999986] [G loss: 1.000097]\n",
      "epoch:3 step:17195[D loss: 0.999983] [G loss: 1.000092]\n",
      "epoch:3 step:17200[D loss: 0.999968] [G loss: 1.000079]\n",
      "##############\n",
      "[2.70810787 2.37411492 2.32927956 3.94915581 1.68934541 7.01671901\n",
      " 2.50385085 3.833532   3.85597789 4.90330875]\n",
      "##########\n",
      "epoch:3 step:17205[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:3 step:17210[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:3 step:17215[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:3 step:17220[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:3 step:17225[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:3 step:17230[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:3 step:17235[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:3 step:17240[D loss: 0.999983] [G loss: 1.000102]\n",
      "epoch:3 step:17245[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:3 step:17250[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:3 step:17255[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:3 step:17260[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:3 step:17265[D loss: 0.999979] [G loss: 1.000093]\n",
      "epoch:3 step:17270[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:3 step:17275[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:3 step:17280[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:3 step:17285[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:3 step:17290[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:3 step:17295[D loss: 0.999981] [G loss: 1.000093]\n",
      "epoch:3 step:17300[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:3 step:17305[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:3 step:17310[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:3 step:17315[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:3 step:17320[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:3 step:17325[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:3 step:17330[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:3 step:17335[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:3 step:17340[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:3 step:17345[D loss: 0.999983] [G loss: 1.000086]\n",
      "epoch:3 step:17350[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:3 step:17355[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:3 step:17360[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:3 step:17365[D loss: 1.000004] [G loss: 1.000060]\n",
      "epoch:3 step:17370[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:3 step:17375[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:3 step:17380[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:3 step:17385[D loss: 0.999960] [G loss: 1.000117]\n",
      "epoch:3 step:17390[D loss: 0.999973] [G loss: 1.000099]\n",
      "epoch:3 step:17395[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:3 step:17400[D loss: 0.999966] [G loss: 1.000095]\n",
      "##############\n",
      "[2.65301459 2.45658053 2.17959432 3.78942782 1.66539259 7.36665313\n",
      " 2.45386719 3.87032986 3.82554311 4.78856788]\n",
      "##########\n",
      "epoch:3 step:17405[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:3 step:17410[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:3 step:17415[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:3 step:17420[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:3 step:17425[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:3 step:17430[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:3 step:17435[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:3 step:17440[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:17445[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:3 step:17450[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:3 step:17455[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:3 step:17460[D loss: 0.999992] [G loss: 1.000057]\n",
      "epoch:3 step:17465[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:17470[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:3 step:17475[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:3 step:17480[D loss: 0.999991] [G loss: 1.000086]\n",
      "epoch:3 step:17485[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:3 step:17490[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:3 step:17495[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:3 step:17500[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:3 step:17505[D loss: 0.999979] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:17510[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:3 step:17515[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:3 step:17520[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:3 step:17525[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:3 step:17530[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:3 step:17535[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:3 step:17540[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:3 step:17545[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:3 step:17550[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:3 step:17555[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:3 step:17560[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:3 step:17565[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:3 step:17570[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:3 step:17575[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:3 step:17580[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:3 step:17585[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:3 step:17590[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:3 step:17595[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:3 step:17600[D loss: 0.999997] [G loss: 1.000038]\n",
      "##############\n",
      "[2.59362398 2.37066866 2.46523366 3.91340513 1.70316443 7.37029923\n",
      " 2.5393123  4.01415355 3.82809202 5.13964713]\n",
      "##########\n",
      "epoch:3 step:17605[D loss: 1.000020] [G loss: 1.000025]\n",
      "epoch:3 step:17610[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:3 step:17615[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:3 step:17620[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:3 step:17625[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:3 step:17630[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:3 step:17635[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:3 step:17640[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:3 step:17645[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:3 step:17650[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:3 step:17655[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:3 step:17660[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:3 step:17665[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:3 step:17670[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:3 step:17675[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:3 step:17680[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:3 step:17685[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:3 step:17690[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:3 step:17695[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:3 step:17700[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:3 step:17705[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:3 step:17710[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:3 step:17715[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:3 step:17720[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:17725[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:3 step:17730[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:3 step:17735[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:3 step:17740[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:3 step:17745[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:3 step:17750[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:3 step:17755[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:3 step:17760[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:3 step:17765[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:3 step:17770[D loss: 0.999992] [G loss: 1.000037]\n",
      "epoch:3 step:17775[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:3 step:17780[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:3 step:17785[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:3 step:17790[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:3 step:17795[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:3 step:17800[D loss: 0.999975] [G loss: 1.000076]\n",
      "##############\n",
      "[2.63433195 2.40786194 2.32250048 3.80852921 1.63947551 7.69071666\n",
      " 2.64041517 4.01002548 3.81135299 4.57318117]\n",
      "##########\n",
      "epoch:3 step:17805[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:3 step:17810[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:3 step:17815[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:3 step:17820[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:3 step:17825[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:3 step:17830[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:3 step:17835[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:3 step:17840[D loss: 1.000012] [G loss: 1.000007]\n",
      "epoch:3 step:17845[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:3 step:17850[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:3 step:17855[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:3 step:17860[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:3 step:17865[D loss: 0.999991] [G loss: 1.000092]\n",
      "epoch:3 step:17870[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:3 step:17875[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:3 step:17880[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:3 step:17885[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:3 step:17890[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:3 step:17895[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:3 step:17900[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:3 step:17905[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:3 step:17910[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:3 step:17915[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:3 step:17920[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:3 step:17925[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:3 step:17930[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:3 step:17935[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:3 step:17940[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:3 step:17945[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:3 step:17950[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:3 step:17955[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:3 step:17960[D loss: 1.000017] [G loss: 1.000014]\n",
      "epoch:3 step:17965[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:3 step:17970[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:3 step:17975[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:3 step:17980[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:3 step:17985[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:3 step:17990[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:3 step:17995[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:3 step:18000[D loss: 0.999972] [G loss: 1.000103]\n",
      "##############\n",
      "[2.6077794  2.38622172 2.28102439 3.69067367 1.62253137 7.34937811\n",
      " 2.44448786 3.91194916 3.76412326 4.65800805]\n",
      "##########\n",
      "epoch:3 step:18005[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:3 step:18010[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:3 step:18015[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:3 step:18020[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:3 step:18025[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:3 step:18030[D loss: 0.999983] [G loss: 1.000091]\n",
      "epoch:3 step:18035[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:3 step:18040[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:3 step:18045[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:3 step:18050[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:3 step:18055[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:3 step:18060[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:3 step:18065[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:3 step:18070[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:3 step:18075[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:3 step:18080[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:3 step:18085[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:3 step:18090[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:3 step:18095[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:3 step:18100[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:3 step:18105[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:3 step:18110[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:3 step:18115[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:3 step:18120[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:3 step:18125[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:3 step:18130[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:3 step:18135[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:3 step:18140[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:3 step:18145[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:3 step:18150[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:18155[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:3 step:18160[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:3 step:18165[D loss: 1.000000] [G loss: 0.999983]\n",
      "epoch:3 step:18170[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:18175[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:3 step:18180[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:3 step:18185[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:3 step:18190[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:3 step:18195[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:3 step:18200[D loss: 0.999969] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.60499166 2.31618409 2.26649432 3.92765489 1.62697946 7.24537948\n",
      " 2.47297053 3.84221951 3.72201234 4.7831049 ]\n",
      "##########\n",
      "epoch:3 step:18205[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:3 step:18210[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:3 step:18215[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:3 step:18220[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:3 step:18225[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:3 step:18230[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:3 step:18235[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:3 step:18240[D loss: 0.999970] [G loss: 1.000106]\n",
      "epoch:3 step:18245[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:3 step:18250[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:3 step:18255[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:3 step:18260[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:3 step:18265[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:3 step:18270[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:3 step:18275[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:3 step:18280[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:3 step:18285[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:3 step:18290[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:18295[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:3 step:18300[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:18305[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:3 step:18310[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:3 step:18315[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:3 step:18320[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:3 step:18325[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:3 step:18330[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:18335[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:3 step:18340[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:3 step:18345[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:3 step:18350[D loss: 0.999969] [G loss: 1.000098]\n",
      "epoch:3 step:18355[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:3 step:18360[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:3 step:18365[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:3 step:18370[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:3 step:18375[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:18380[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:3 step:18385[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:3 step:18390[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:3 step:18395[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:3 step:18400[D loss: 0.999975] [G loss: 1.000081]\n",
      "##############\n",
      "[2.67423406 2.437581   2.25581596 4.13810254 1.66867026 7.39733493\n",
      " 2.43915364 3.91482931 3.78239776 4.80614971]\n",
      "##########\n",
      "epoch:3 step:18405[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:3 step:18410[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:3 step:18415[D loss: 0.999995] [G loss: 1.000058]\n",
      "epoch:3 step:18420[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:3 step:18425[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:3 step:18430[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:3 step:18435[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:18440[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:3 step:18445[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:3 step:18450[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:3 step:18455[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:3 step:18460[D loss: 0.999995] [G loss: 1.000069]\n",
      "epoch:3 step:18465[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:3 step:18470[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:3 step:18475[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:3 step:18480[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:3 step:18485[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:3 step:18490[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:3 step:18495[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:3 step:18500[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:3 step:18505[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:3 step:18510[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:3 step:18515[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:3 step:18520[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:3 step:18525[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:18530[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:3 step:18535[D loss: 0.999989] [G loss: 1.000070]\n",
      "epoch:3 step:18540[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:3 step:18545[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:3 step:18550[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:3 step:18555[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:18560[D loss: 1.000005] [G loss: 1.000064]\n",
      "epoch:3 step:18565[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:3 step:18570[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:3 step:18575[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:3 step:18580[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:3 step:18585[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:3 step:18590[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:3 step:18595[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:3 step:18600[D loss: 0.999988] [G loss: 1.000058]\n",
      "##############\n",
      "[2.62992425 2.37301198 2.26932612 3.82918465 1.63803137 7.22707557\n",
      " 2.43598413 3.86223408 3.77326537 5.02437212]\n",
      "##########\n",
      "epoch:3 step:18605[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:3 step:18610[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:3 step:18615[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:3 step:18620[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:3 step:18625[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:3 step:18630[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:3 step:18635[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:3 step:18640[D loss: 0.999999] [G loss: 1.000068]\n",
      "epoch:3 step:18645[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:3 step:18650[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:3 step:18655[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:3 step:18660[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:3 step:18665[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:3 step:18670[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:3 step:18675[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:3 step:18680[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:3 step:18685[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:3 step:18690[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:18695[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:3 step:18700[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:3 step:18705[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:3 step:18710[D loss: 1.000001] [G loss: 1.000020]\n",
      "epoch:3 step:18715[D loss: 0.999952] [G loss: 1.000092]\n",
      "epoch:3 step:18720[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:3 step:18725[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:3 step:18730[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:3 step:18735[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:18740[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:4 step:18745[D loss: 0.999993] [G loss: 1.000080]\n",
      "epoch:4 step:18750[D loss: 0.999962] [G loss: 1.000108]\n",
      "epoch:4 step:18755[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:4 step:18760[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:4 step:18765[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:4 step:18770[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:4 step:18775[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:4 step:18780[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:4 step:18785[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:4 step:18790[D loss: 1.000018] [G loss: 1.000036]\n",
      "epoch:4 step:18795[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:4 step:18800[D loss: 0.999957] [G loss: 1.000099]\n",
      "##############\n",
      "[2.64734463 2.396598   2.3269196  4.0446812  1.67982778 7.63571693\n",
      " 2.56831347 3.91533195 3.86654192 5.28802386]\n",
      "##########\n",
      "epoch:4 step:18805[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:4 step:18810[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:4 step:18815[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:4 step:18820[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:4 step:18825[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:4 step:18830[D loss: 0.999983] [G loss: 1.000096]\n",
      "epoch:4 step:18835[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:4 step:18840[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:4 step:18845[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:4 step:18850[D loss: 1.000002] [G loss: 1.000070]\n",
      "epoch:4 step:18855[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:4 step:18860[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:4 step:18865[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:4 step:18870[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:4 step:18875[D loss: 0.999969] [G loss: 1.000111]\n",
      "epoch:4 step:18880[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:4 step:18885[D loss: 0.999977] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:18890[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:4 step:18895[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:4 step:18900[D loss: 1.000001] [G loss: 1.000047]\n",
      "epoch:4 step:18905[D loss: 0.999960] [G loss: 1.000115]\n",
      "epoch:4 step:18910[D loss: 1.000016] [G loss: 1.000021]\n",
      "epoch:4 step:18915[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:4 step:18920[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:4 step:18925[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:4 step:18930[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:4 step:18935[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:4 step:18940[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:4 step:18945[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:4 step:18950[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:4 step:18955[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:4 step:18960[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:4 step:18965[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:4 step:18970[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:4 step:18975[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:4 step:18980[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:4 step:18985[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:4 step:18990[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:4 step:18995[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:4 step:19000[D loss: 0.999986] [G loss: 1.000099]\n",
      "##############\n",
      "[2.54784561 2.43362016 2.25699576 3.98637781 1.6227847  6.85226202\n",
      " 2.54916469 3.91209786 3.78044912 4.83063618]\n",
      "##########\n",
      "epoch:4 step:19005[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:4 step:19010[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:4 step:19015[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:4 step:19020[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:4 step:19025[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:4 step:19030[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:4 step:19035[D loss: 0.999960] [G loss: 1.000112]\n",
      "epoch:4 step:19040[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:4 step:19045[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:4 step:19050[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:4 step:19055[D loss: 1.000000] [G loss: 1.000072]\n",
      "epoch:4 step:19060[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:4 step:19065[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:4 step:19070[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:4 step:19075[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:4 step:19080[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:4 step:19085[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:4 step:19090[D loss: 1.000001] [G loss: 1.000033]\n",
      "epoch:4 step:19095[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:4 step:19100[D loss: 0.999938] [G loss: 1.000140]\n",
      "epoch:4 step:19105[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:4 step:19110[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:4 step:19115[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:4 step:19120[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:4 step:19125[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:4 step:19130[D loss: 1.000009] [G loss: 1.000002]\n",
      "epoch:4 step:19135[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:4 step:19140[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:4 step:19145[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:4 step:19150[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:4 step:19155[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:4 step:19160[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:19165[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:4 step:19170[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:4 step:19175[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:4 step:19180[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:4 step:19185[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:4 step:19190[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:4 step:19195[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:4 step:19200[D loss: 0.999976] [G loss: 1.000060]\n",
      "##############\n",
      "[2.63612742 2.39363872 2.40310625 3.57840521 1.6209505  7.22259223\n",
      " 2.4997652  3.89387161 3.83014388 5.352847  ]\n",
      "##########\n",
      "epoch:4 step:19205[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:4 step:19210[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:4 step:19215[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:4 step:19220[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:4 step:19225[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:4 step:19230[D loss: 1.000015] [G loss: 1.000010]\n",
      "epoch:4 step:19235[D loss: 0.999934] [G loss: 1.000149]\n",
      "epoch:4 step:19240[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:4 step:19245[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:4 step:19250[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:4 step:19255[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:4 step:19260[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:4 step:19265[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:4 step:19270[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:4 step:19275[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:4 step:19280[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:4 step:19285[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:4 step:19290[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:4 step:19295[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:4 step:19300[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:4 step:19305[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:4 step:19310[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:4 step:19315[D loss: 0.999994] [G loss: 1.000081]\n",
      "epoch:4 step:19320[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:4 step:19325[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:4 step:19330[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:4 step:19335[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:4 step:19340[D loss: 0.999955] [G loss: 1.000110]\n",
      "epoch:4 step:19345[D loss: 0.999964] [G loss: 1.000107]\n",
      "epoch:4 step:19350[D loss: 0.999969] [G loss: 1.000105]\n",
      "epoch:4 step:19355[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:4 step:19360[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:4 step:19365[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:4 step:19370[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:4 step:19375[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:4 step:19380[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:4 step:19385[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:4 step:19390[D loss: 1.000002] [G loss: 1.000050]\n",
      "epoch:4 step:19395[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:4 step:19400[D loss: 0.999986] [G loss: 1.000034]\n",
      "##############\n",
      "[2.60597696 2.43959371 2.30838075 4.05458001 1.61962145 8.10782856\n",
      " 2.54895731 3.80417986 3.83169178 5.19847139]\n",
      "##########\n",
      "epoch:4 step:19405[D loss: 1.000000] [G loss: 1.000032]\n",
      "epoch:4 step:19410[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:4 step:19415[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:4 step:19420[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:4 step:19425[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:4 step:19430[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:4 step:19435[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:4 step:19440[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:4 step:19445[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:4 step:19450[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:4 step:19455[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:4 step:19460[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:4 step:19465[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:4 step:19470[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:4 step:19475[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:4 step:19480[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:4 step:19485[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:4 step:19490[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:4 step:19495[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:4 step:19500[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:4 step:19505[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:4 step:19510[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:4 step:19515[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:4 step:19520[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:4 step:19525[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:4 step:19530[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:4 step:19535[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:4 step:19540[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:4 step:19545[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:4 step:19550[D loss: 1.000010] [G loss: 1.000041]\n",
      "epoch:4 step:19555[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:4 step:19560[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:4 step:19565[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:4 step:19570[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:4 step:19575[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:4 step:19580[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:4 step:19585[D loss: 0.999974] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:19590[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:4 step:19595[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:4 step:19600[D loss: 0.999994] [G loss: 1.000037]\n",
      "##############\n",
      "[2.54733821 2.35983908 2.21812965 4.03505531 1.5948654  7.74828084\n",
      " 2.30704925 3.98108234 3.82573181 4.97552468]\n",
      "##########\n",
      "epoch:4 step:19605[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:4 step:19610[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:4 step:19615[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:4 step:19620[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:4 step:19625[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:4 step:19630[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:4 step:19635[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:4 step:19640[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:4 step:19645[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:4 step:19650[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:4 step:19655[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:4 step:19660[D loss: 1.000000] [G loss: 1.000052]\n",
      "epoch:4 step:19665[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:4 step:19670[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:4 step:19675[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:4 step:19680[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:4 step:19685[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:4 step:19690[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:4 step:19695[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:4 step:19700[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:4 step:19705[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:4 step:19710[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:4 step:19715[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:4 step:19720[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:4 step:19725[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:4 step:19730[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:4 step:19735[D loss: 0.999963] [G loss: 1.000097]\n",
      "epoch:4 step:19740[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:4 step:19745[D loss: 0.999966] [G loss: 1.000108]\n",
      "epoch:4 step:19750[D loss: 0.999983] [G loss: 1.000096]\n",
      "epoch:4 step:19755[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:4 step:19760[D loss: 1.000001] [G loss: 1.000075]\n",
      "epoch:4 step:19765[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:4 step:19770[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:4 step:19775[D loss: 0.999988] [G loss: 1.000096]\n",
      "epoch:4 step:19780[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:4 step:19785[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:4 step:19790[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:4 step:19795[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:4 step:19800[D loss: 0.999989] [G loss: 1.000065]\n",
      "##############\n",
      "[2.57313773 2.33987857 2.24801484 3.84499787 1.58758684 7.31594445\n",
      " 2.52818375 3.93876231 3.83714124 4.83791544]\n",
      "##########\n",
      "epoch:4 step:19805[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:4 step:19810[D loss: 0.999974] [G loss: 1.000113]\n",
      "epoch:4 step:19815[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:4 step:19820[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:4 step:19825[D loss: 0.999972] [G loss: 1.000137]\n",
      "epoch:4 step:19830[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:4 step:19835[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:4 step:19840[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:4 step:19845[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:4 step:19850[D loss: 1.000006] [G loss: 1.000012]\n",
      "epoch:4 step:19855[D loss: 0.999963] [G loss: 1.000109]\n",
      "epoch:4 step:19860[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:4 step:19865[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:4 step:19870[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:4 step:19875[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:4 step:19880[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:4 step:19885[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:4 step:19890[D loss: 0.999986] [G loss: 1.000118]\n",
      "epoch:4 step:19895[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:4 step:19900[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:4 step:19905[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:4 step:19910[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:4 step:19915[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:4 step:19920[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:4 step:19925[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:4 step:19930[D loss: 0.999991] [G loss: 1.000077]\n",
      "epoch:4 step:19935[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:4 step:19940[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:4 step:19945[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:4 step:19950[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:4 step:19955[D loss: 0.999962] [G loss: 1.000099]\n",
      "epoch:4 step:19960[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:4 step:19965[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:4 step:19970[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:4 step:19975[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:4 step:19980[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:4 step:19985[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:4 step:19990[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:4 step:19995[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:4 step:20000[D loss: 0.999977] [G loss: 1.000078]\n",
      "##############\n",
      "[2.60211936 2.34558961 2.29597086 4.01180453 1.61157853 7.35157123\n",
      " 2.59700033 3.92056046 3.88714479 5.16270769]\n",
      "##########\n",
      "epoch:4 step:20005[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:4 step:20010[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:4 step:20015[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:4 step:20020[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:4 step:20025[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:4 step:20030[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:4 step:20035[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:4 step:20040[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:4 step:20045[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:4 step:20050[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:4 step:20055[D loss: 1.000024] [G loss: 0.999984]\n",
      "epoch:4 step:20060[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:4 step:20065[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:4 step:20070[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:4 step:20075[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:4 step:20080[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:4 step:20085[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:4 step:20090[D loss: 1.000005] [G loss: 1.000011]\n",
      "epoch:4 step:20095[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:4 step:20100[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:4 step:20105[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:4 step:20110[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:4 step:20115[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:4 step:20120[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:4 step:20125[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:4 step:20130[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:4 step:20135[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:4 step:20140[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:4 step:20145[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:4 step:20150[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:4 step:20155[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:4 step:20160[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:4 step:20165[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:4 step:20170[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:4 step:20175[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:4 step:20180[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:4 step:20185[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:4 step:20190[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:4 step:20195[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:4 step:20200[D loss: 0.999983] [G loss: 1.000083]\n",
      "##############\n",
      "[2.66823678 2.33689858 2.34559466 3.98329985 1.61054775 7.2087078\n",
      " 2.49714213 3.86023613 3.87887516 5.20615328]\n",
      "##########\n",
      "epoch:4 step:20205[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:4 step:20210[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:4 step:20215[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:4 step:20220[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:4 step:20225[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:4 step:20230[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:4 step:20235[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:4 step:20240[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:4 step:20245[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:4 step:20250[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:4 step:20255[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:4 step:20260[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:4 step:20265[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:4 step:20270[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:4 step:20275[D loss: 0.999963] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:20280[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:4 step:20285[D loss: 1.000006] [G loss: 1.000052]\n",
      "epoch:4 step:20290[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:4 step:20295[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:4 step:20300[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:4 step:20305[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:4 step:20310[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:4 step:20315[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:4 step:20320[D loss: 0.999980] [G loss: 1.000122]\n",
      "epoch:4 step:20325[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:4 step:20330[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:4 step:20335[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:4 step:20340[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:4 step:20345[D loss: 1.000020] [G loss: 1.000056]\n",
      "epoch:4 step:20350[D loss: 1.000015] [G loss: 1.000009]\n",
      "epoch:4 step:20355[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:4 step:20360[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:4 step:20365[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:4 step:20370[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:4 step:20375[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:4 step:20380[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:4 step:20385[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:4 step:20390[D loss: 1.000001] [G loss: 1.000041]\n",
      "epoch:4 step:20395[D loss: 0.999956] [G loss: 1.000102]\n",
      "epoch:4 step:20400[D loss: 0.999969] [G loss: 1.000081]\n",
      "##############\n",
      "[2.65413753 2.37568618 2.32427905 4.00606498 1.61156287 7.79836188\n",
      " 2.61091104 3.81190923 3.85208016 4.9487611 ]\n",
      "##########\n",
      "epoch:4 step:20405[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:4 step:20410[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:4 step:20415[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:4 step:20420[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:4 step:20425[D loss: 1.000004] [G loss: 1.000038]\n",
      "epoch:4 step:20430[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:4 step:20435[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:4 step:20440[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:4 step:20445[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:4 step:20450[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:4 step:20455[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:4 step:20460[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:4 step:20465[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:4 step:20470[D loss: 1.000003] [G loss: 1.000095]\n",
      "epoch:4 step:20475[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:4 step:20480[D loss: 0.999991] [G loss: 1.000080]\n",
      "epoch:4 step:20485[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:4 step:20490[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:4 step:20495[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:4 step:20500[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:4 step:20505[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:4 step:20510[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:4 step:20515[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:4 step:20520[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:4 step:20525[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:4 step:20530[D loss: 1.000014] [G loss: 1.000049]\n",
      "epoch:4 step:20535[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:4 step:20540[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:4 step:20545[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:4 step:20550[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:4 step:20555[D loss: 0.999964] [G loss: 1.000112]\n",
      "epoch:4 step:20560[D loss: 1.000021] [G loss: 1.000051]\n",
      "epoch:4 step:20565[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:4 step:20570[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:4 step:20575[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:4 step:20580[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:4 step:20585[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:4 step:20590[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:4 step:20595[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:4 step:20600[D loss: 0.999977] [G loss: 1.000088]\n",
      "##############\n",
      "[2.69098725 2.40046981 2.40453882 3.72413355 1.70149069 7.41724331\n",
      " 2.58301978 3.94058356 3.97455369 5.35547951]\n",
      "##########\n",
      "epoch:4 step:20605[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:4 step:20610[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:4 step:20615[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:4 step:20620[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:4 step:20625[D loss: 0.999986] [G loss: 1.000087]\n",
      "epoch:4 step:20630[D loss: 1.000004] [G loss: 1.000070]\n",
      "epoch:4 step:20635[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:4 step:20640[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:4 step:20645[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:4 step:20650[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:4 step:20655[D loss: 1.000030] [G loss: 0.999985]\n",
      "epoch:4 step:20660[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:4 step:20665[D loss: 1.000010] [G loss: 1.000083]\n",
      "epoch:4 step:20670[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:4 step:20675[D loss: 1.000013] [G loss: 1.000075]\n",
      "epoch:4 step:20680[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:4 step:20685[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:4 step:20690[D loss: 0.999960] [G loss: 1.000063]\n",
      "epoch:4 step:20695[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:4 step:20700[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:4 step:20705[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:4 step:20710[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:4 step:20715[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:4 step:20720[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:4 step:20725[D loss: 0.999973] [G loss: 1.000099]\n",
      "epoch:4 step:20730[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:4 step:20735[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:4 step:20740[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:4 step:20745[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:4 step:20750[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:4 step:20755[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:4 step:20760[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:4 step:20765[D loss: 1.000012] [G loss: 1.000031]\n",
      "epoch:4 step:20770[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:4 step:20775[D loss: 0.999985] [G loss: 1.000102]\n",
      "epoch:4 step:20780[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:4 step:20785[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:4 step:20790[D loss: 0.999974] [G loss: 1.000113]\n",
      "epoch:4 step:20795[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:4 step:20800[D loss: 1.000010] [G loss: 1.000036]\n",
      "##############\n",
      "[2.65748946 2.36695028 2.33726154 3.63958943 1.59592284 8.18265734\n",
      " 2.40924039 3.86156872 3.82531078 4.75492741]\n",
      "##########\n",
      "epoch:4 step:20805[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:4 step:20810[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:4 step:20815[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:4 step:20820[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:4 step:20825[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:4 step:20830[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:4 step:20835[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:4 step:20840[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:4 step:20845[D loss: 0.999999] [G loss: 1.000060]\n",
      "epoch:4 step:20850[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:4 step:20855[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:4 step:20860[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:4 step:20865[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:4 step:20870[D loss: 0.999990] [G loss: 1.000076]\n",
      "epoch:4 step:20875[D loss: 0.999996] [G loss: 1.000025]\n",
      "epoch:4 step:20880[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:4 step:20885[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:4 step:20890[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:4 step:20895[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:4 step:20900[D loss: 0.999988] [G loss: 1.000069]\n",
      "epoch:4 step:20905[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:4 step:20910[D loss: 1.000006] [G loss: 1.000066]\n",
      "epoch:4 step:20915[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:4 step:20920[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:4 step:20925[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:4 step:20930[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:4 step:20935[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:4 step:20940[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:4 step:20945[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:4 step:20950[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:4 step:20955[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:4 step:20960[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:4 step:20965[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:4 step:20970[D loss: 0.999971] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:20975[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:4 step:20980[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:4 step:20985[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:4 step:20990[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:4 step:20995[D loss: 1.000001] [G loss: 1.000053]\n",
      "epoch:4 step:21000[D loss: 0.999977] [G loss: 1.000072]\n",
      "##############\n",
      "[2.68153194 2.40176561 2.30420674 3.60428704 1.61013816 7.25364998\n",
      " 2.51674547 3.78800112 3.91154231 4.21497094]\n",
      "##########\n",
      "epoch:4 step:21005[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:4 step:21010[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:4 step:21015[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:21020[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:4 step:21025[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:4 step:21030[D loss: 1.000018] [G loss: 1.000020]\n",
      "epoch:4 step:21035[D loss: 1.000014] [G loss: 1.000101]\n",
      "epoch:4 step:21040[D loss: 0.999944] [G loss: 1.000127]\n",
      "epoch:4 step:21045[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:4 step:21050[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:4 step:21055[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:4 step:21060[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:4 step:21065[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:4 step:21070[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:4 step:21075[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:4 step:21080[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:4 step:21085[D loss: 0.999989] [G loss: 1.000116]\n",
      "epoch:4 step:21090[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:4 step:21095[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:4 step:21100[D loss: 0.999957] [G loss: 1.000115]\n",
      "epoch:4 step:21105[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:4 step:21110[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:4 step:21115[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:4 step:21120[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:4 step:21125[D loss: 0.999952] [G loss: 1.000083]\n",
      "epoch:4 step:21130[D loss: 1.000004] [G loss: 1.000051]\n",
      "epoch:4 step:21135[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:4 step:21140[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:4 step:21145[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:4 step:21150[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:4 step:21155[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:4 step:21160[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:4 step:21165[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:4 step:21170[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:4 step:21175[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:4 step:21180[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:4 step:21185[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:4 step:21190[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:4 step:21195[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:4 step:21200[D loss: 0.999982] [G loss: 1.000060]\n",
      "##############\n",
      "[2.70307999 2.43852006 2.38663767 3.87141008 1.64620729 7.49349525\n",
      " 2.5623927  4.01358273 3.9306468  4.97159409]\n",
      "##########\n",
      "epoch:4 step:21205[D loss: 1.000010] [G loss: 1.000034]\n",
      "epoch:4 step:21210[D loss: 0.999972] [G loss: 1.000105]\n",
      "epoch:4 step:21215[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:4 step:21220[D loss: 0.999983] [G loss: 1.000099]\n",
      "epoch:4 step:21225[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:4 step:21230[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:4 step:21235[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:4 step:21240[D loss: 1.000022] [G loss: 1.000024]\n",
      "epoch:4 step:21245[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:4 step:21250[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:4 step:21255[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:4 step:21260[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:4 step:21265[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:4 step:21270[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:4 step:21275[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:4 step:21280[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:4 step:21285[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:4 step:21290[D loss: 0.999987] [G loss: 1.000098]\n",
      "epoch:4 step:21295[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:4 step:21300[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:4 step:21305[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:4 step:21310[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:4 step:21315[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:4 step:21320[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:4 step:21325[D loss: 0.999966] [G loss: 1.000105]\n",
      "epoch:4 step:21330[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:4 step:21335[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:4 step:21340[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:4 step:21345[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:4 step:21350[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:4 step:21355[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:4 step:21360[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:4 step:21365[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:4 step:21370[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:4 step:21375[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:4 step:21380[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:4 step:21385[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:4 step:21390[D loss: 1.000004] [G loss: 1.000042]\n",
      "epoch:4 step:21395[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:4 step:21400[D loss: 0.999987] [G loss: 1.000066]\n",
      "##############\n",
      "[2.7250919  2.44870989 2.28709152 4.04400897 1.67677973 7.50195491\n",
      " 2.47542325 3.82984075 3.94141711 4.93407691]\n",
      "##########\n",
      "epoch:4 step:21405[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:4 step:21410[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:4 step:21415[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:4 step:21420[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:4 step:21425[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:4 step:21430[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:4 step:21435[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:4 step:21440[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:4 step:21445[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:4 step:21450[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:4 step:21455[D loss: 1.000011] [G loss: 1.000006]\n",
      "epoch:4 step:21460[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:4 step:21465[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:4 step:21470[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:4 step:21475[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:4 step:21480[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:4 step:21485[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:4 step:21490[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:4 step:21495[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:4 step:21500[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:4 step:21505[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:4 step:21510[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:4 step:21515[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:4 step:21520[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:4 step:21525[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:4 step:21530[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:4 step:21535[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:4 step:21540[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:4 step:21545[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:4 step:21550[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:4 step:21555[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:4 step:21560[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:4 step:21565[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:4 step:21570[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:4 step:21575[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:4 step:21580[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:4 step:21585[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:4 step:21590[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:4 step:21595[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:4 step:21600[D loss: 0.999995] [G loss: 1.000046]\n",
      "##############\n",
      "[2.6372195  2.36889772 2.27440561 3.88101016 1.57449605 7.67933799\n",
      " 2.69550845 4.05399826 3.85070999 5.26399141]\n",
      "##########\n",
      "epoch:4 step:21605[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:4 step:21610[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:4 step:21615[D loss: 1.000015] [G loss: 1.000026]\n",
      "epoch:4 step:21620[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:4 step:21625[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:4 step:21630[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:4 step:21635[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:4 step:21640[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:4 step:21645[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:4 step:21650[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:4 step:21655[D loss: 0.999990] [G loss: 1.000051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:21660[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:4 step:21665[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:4 step:21670[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:4 step:21675[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:4 step:21680[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:4 step:21685[D loss: 0.999989] [G loss: 1.000092]\n",
      "epoch:4 step:21690[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:4 step:21695[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:4 step:21700[D loss: 0.999999] [G loss: 1.000060]\n",
      "epoch:4 step:21705[D loss: 0.999999] [G loss: 1.000078]\n",
      "epoch:4 step:21710[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:4 step:21715[D loss: 1.000015] [G loss: 1.000084]\n",
      "epoch:4 step:21720[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:4 step:21725[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:4 step:21730[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:4 step:21735[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:4 step:21740[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:4 step:21745[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:4 step:21750[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:4 step:21755[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:4 step:21760[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:4 step:21765[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:4 step:21770[D loss: 1.000000] [G loss: 1.000044]\n",
      "epoch:4 step:21775[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:4 step:21780[D loss: 0.999957] [G loss: 1.000097]\n",
      "epoch:4 step:21785[D loss: 0.999986] [G loss: 1.000099]\n",
      "epoch:4 step:21790[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:4 step:21795[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:4 step:21800[D loss: 0.999993] [G loss: 1.000066]\n",
      "##############\n",
      "[2.71187821 2.4071762  2.2567327  4.14953247 1.64624136 6.95276975\n",
      " 2.60978187 3.95397865 3.9257742  4.55375207]\n",
      "##########\n",
      "epoch:4 step:21805[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:4 step:21810[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:4 step:21815[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:4 step:21820[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:4 step:21825[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:4 step:21830[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:4 step:21835[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:4 step:21840[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:4 step:21845[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:4 step:21850[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:4 step:21855[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:4 step:21860[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:4 step:21865[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:4 step:21870[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:4 step:21875[D loss: 0.999997] [G loss: 1.000074]\n",
      "epoch:4 step:21880[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:4 step:21885[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:4 step:21890[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:4 step:21895[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:4 step:21900[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:4 step:21905[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:4 step:21910[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:4 step:21915[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:4 step:21920[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:4 step:21925[D loss: 0.999980] [G loss: 1.000094]\n",
      "epoch:4 step:21930[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:4 step:21935[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:4 step:21940[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:4 step:21945[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:4 step:21950[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:4 step:21955[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:4 step:21960[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:4 step:21965[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:4 step:21970[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:4 step:21975[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:4 step:21980[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:4 step:21985[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:4 step:21990[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:4 step:21995[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:4 step:22000[D loss: 0.999980] [G loss: 1.000058]\n",
      "##############\n",
      "[2.68097957 2.34930984 2.1417731  3.661745   1.61254426 7.52834556\n",
      " 2.49210522 3.94881211 3.86579857 4.90331719]\n",
      "##########\n",
      "epoch:4 step:22005[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:4 step:22010[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:4 step:22015[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:4 step:22020[D loss: 0.999999] [G loss: 1.000044]\n",
      "epoch:4 step:22025[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:4 step:22030[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:4 step:22035[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:4 step:22040[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:4 step:22045[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:4 step:22050[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:4 step:22055[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:4 step:22060[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:4 step:22065[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:4 step:22070[D loss: 1.000000] [G loss: 1.000023]\n",
      "epoch:4 step:22075[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:4 step:22080[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:4 step:22085[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:4 step:22090[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:4 step:22095[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:4 step:22100[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:4 step:22105[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:4 step:22110[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:4 step:22115[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:4 step:22120[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:4 step:22125[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:4 step:22130[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:4 step:22135[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:4 step:22140[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:4 step:22145[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:4 step:22150[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:4 step:22155[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:4 step:22160[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:4 step:22165[D loss: 0.999998] [G loss: 1.000024]\n",
      "epoch:4 step:22170[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:4 step:22175[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:4 step:22180[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:4 step:22185[D loss: 0.999994] [G loss: 1.000067]\n",
      "epoch:4 step:22190[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:4 step:22195[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:4 step:22200[D loss: 0.999992] [G loss: 1.000069]\n",
      "##############\n",
      "[2.75163773 2.25566266 2.25106288 3.91884205 1.57590838 7.41316004\n",
      " 2.52948671 3.96543015 3.79300964 4.87168981]\n",
      "##########\n",
      "epoch:4 step:22205[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:4 step:22210[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:4 step:22215[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:4 step:22220[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:4 step:22225[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:4 step:22230[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:4 step:22235[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:4 step:22240[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:4 step:22245[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:4 step:22250[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:4 step:22255[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:4 step:22260[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:4 step:22265[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:4 step:22270[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:4 step:22275[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:4 step:22280[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:4 step:22285[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:4 step:22290[D loss: 0.999953] [G loss: 1.000139]\n",
      "epoch:4 step:22295[D loss: 1.000006] [G loss: 1.000032]\n",
      "epoch:4 step:22300[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:4 step:22305[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:4 step:22310[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:4 step:22315[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:4 step:22320[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:4 step:22325[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:4 step:22330[D loss: 0.999981] [G loss: 1.000094]\n",
      "epoch:4 step:22335[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:4 step:22340[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:4 step:22345[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:4 step:22350[D loss: 0.999995] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:22355[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:4 step:22360[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:4 step:22365[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:4 step:22370[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:4 step:22375[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:4 step:22380[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:4 step:22385[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:4 step:22390[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:4 step:22395[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:4 step:22400[D loss: 0.999969] [G loss: 1.000088]\n",
      "##############\n",
      "[2.75121418 2.35316055 2.34987849 4.06474829 1.63837731 7.38454308\n",
      " 2.66711511 3.91405109 4.00117993 4.58629467]\n",
      "##########\n",
      "epoch:4 step:22405[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:4 step:22410[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:4 step:22415[D loss: 0.999993] [G loss: 1.000069]\n",
      "epoch:4 step:22420[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:4 step:22425[D loss: 0.999997] [G loss: 1.000067]\n",
      "epoch:4 step:22430[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:4 step:22435[D loss: 0.999985] [G loss: 1.000099]\n",
      "epoch:4 step:22440[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:4 step:22445[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:4 step:22450[D loss: 1.000019] [G loss: 1.000044]\n",
      "epoch:4 step:22455[D loss: 0.999947] [G loss: 1.000069]\n",
      "epoch:4 step:22460[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:4 step:22465[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:4 step:22470[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:4 step:22475[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:4 step:22480[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:4 step:22485[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:4 step:22490[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:4 step:22495[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:4 step:22500[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:4 step:22505[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:4 step:22510[D loss: 1.000009] [G loss: 1.000031]\n",
      "epoch:4 step:22515[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:4 step:22520[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:4 step:22525[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:4 step:22530[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:4 step:22535[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:4 step:22540[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:4 step:22545[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:4 step:22550[D loss: 1.000006] [G loss: 1.000071]\n",
      "epoch:4 step:22555[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:4 step:22560[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:4 step:22565[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:4 step:22570[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:4 step:22575[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:4 step:22580[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:4 step:22585[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:4 step:22590[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:4 step:22595[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:4 step:22600[D loss: 0.999979] [G loss: 1.000084]\n",
      "##############\n",
      "[2.74205304 2.33691738 2.23170165 3.9952379  1.61434465 7.7715055\n",
      " 2.71042238 4.04129403 3.91516814 4.99982788]\n",
      "##########\n",
      "epoch:4 step:22605[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:4 step:22610[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:4 step:22615[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:4 step:22620[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:4 step:22625[D loss: 1.000002] [G loss: 1.000039]\n",
      "epoch:4 step:22630[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:4 step:22635[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:4 step:22640[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:4 step:22645[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:4 step:22650[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:4 step:22655[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:4 step:22660[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:4 step:22665[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:4 step:22670[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:4 step:22675[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:4 step:22680[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:4 step:22685[D loss: 0.999964] [G loss: 1.000104]\n",
      "epoch:4 step:22690[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:4 step:22695[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:4 step:22700[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:4 step:22705[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:4 step:22710[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:4 step:22715[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:4 step:22720[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:4 step:22725[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:4 step:22730[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:4 step:22735[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:4 step:22740[D loss: 1.000011] [G loss: 1.000008]\n",
      "epoch:4 step:22745[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:4 step:22750[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:4 step:22755[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:4 step:22760[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:4 step:22765[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:4 step:22770[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:4 step:22775[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:4 step:22780[D loss: 0.999997] [G loss: 1.000060]\n",
      "epoch:4 step:22785[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:4 step:22790[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:4 step:22795[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:4 step:22800[D loss: 0.999985] [G loss: 1.000074]\n",
      "##############\n",
      "[2.70060472 2.2910901  2.21379633 3.41732984 1.57819916 7.31494043\n",
      " 2.5038643  3.94677243 3.8356101  4.48357915]\n",
      "##########\n",
      "epoch:4 step:22805[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:4 step:22810[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:4 step:22815[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:4 step:22820[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:4 step:22825[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:4 step:22830[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:4 step:22835[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:4 step:22840[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:4 step:22845[D loss: 1.000004] [G loss: 1.000029]\n",
      "epoch:4 step:22850[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:4 step:22855[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:4 step:22860[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:4 step:22865[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:4 step:22870[D loss: 1.000000] [G loss: 1.000049]\n",
      "epoch:4 step:22875[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:4 step:22880[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:4 step:22885[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:4 step:22890[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:4 step:22895[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:4 step:22900[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:4 step:22905[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:4 step:22910[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:4 step:22915[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:4 step:22920[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:4 step:22925[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:4 step:22930[D loss: 0.999962] [G loss: 1.000108]\n",
      "epoch:4 step:22935[D loss: 0.999992] [G loss: 1.000092]\n",
      "epoch:4 step:22940[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:4 step:22945[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:4 step:22950[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:22955[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:4 step:22960[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:4 step:22965[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:4 step:22970[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:4 step:22975[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:4 step:22980[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:4 step:22985[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:4 step:22990[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:4 step:22995[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:4 step:23000[D loss: 0.999973] [G loss: 1.000065]\n",
      "##############\n",
      "[2.72978452 2.2914801  2.35522904 4.07195825 1.60862192 7.64619071\n",
      " 2.48989943 3.9471103  3.91715602 4.42909743]\n",
      "##########\n",
      "epoch:4 step:23005[D loss: 0.999996] [G loss: 1.000072]\n",
      "epoch:4 step:23010[D loss: 0.999991] [G loss: 1.000011]\n",
      "epoch:4 step:23015[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:4 step:23020[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:4 step:23025[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:4 step:23030[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:4 step:23035[D loss: 1.000009] [G loss: 1.000052]\n",
      "epoch:4 step:23040[D loss: 0.999972] [G loss: 1.000083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:23045[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:4 step:23050[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:4 step:23055[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:4 step:23060[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:4 step:23065[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:4 step:23070[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:4 step:23075[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:4 step:23080[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:4 step:23085[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:4 step:23090[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:4 step:23095[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:4 step:23100[D loss: 1.000014] [G loss: 1.000006]\n",
      "epoch:4 step:23105[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:4 step:23110[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:4 step:23115[D loss: 1.000027] [G loss: 0.999988]\n",
      "epoch:4 step:23120[D loss: 0.999992] [G loss: 1.000013]\n",
      "epoch:4 step:23125[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:4 step:23130[D loss: 0.999999] [G loss: 1.000044]\n",
      "epoch:4 step:23135[D loss: 0.999958] [G loss: 1.000083]\n",
      "epoch:4 step:23140[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:4 step:23145[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:4 step:23150[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:4 step:23155[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:4 step:23160[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:4 step:23165[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:4 step:23170[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:4 step:23175[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:4 step:23180[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:4 step:23185[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:4 step:23190[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:4 step:23195[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:4 step:23200[D loss: 0.999972] [G loss: 1.000068]\n",
      "##############\n",
      "[2.73520842 2.35499333 2.40344147 3.85300835 1.63109166 7.84232044\n",
      " 2.62502568 3.8280165  3.9874151  4.20429351]\n",
      "##########\n",
      "epoch:4 step:23205[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:4 step:23210[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:4 step:23215[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:4 step:23220[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:4 step:23225[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:4 step:23230[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:4 step:23235[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:4 step:23240[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:4 step:23245[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:4 step:23250[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:4 step:23255[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:4 step:23260[D loss: 1.000021] [G loss: 0.999996]\n",
      "epoch:4 step:23265[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:4 step:23270[D loss: 0.999979] [G loss: 1.000100]\n",
      "epoch:4 step:23275[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:4 step:23280[D loss: 1.000015] [G loss: 0.999998]\n",
      "epoch:4 step:23285[D loss: 1.000000] [G loss: 1.000056]\n",
      "epoch:4 step:23290[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:4 step:23295[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:4 step:23300[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:4 step:23305[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:4 step:23310[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:4 step:23315[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:4 step:23320[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:4 step:23325[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:4 step:23330[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:4 step:23335[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:4 step:23340[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:4 step:23345[D loss: 0.999989] [G loss: 1.000079]\n",
      "epoch:4 step:23350[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:4 step:23355[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:4 step:23360[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:4 step:23365[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:4 step:23370[D loss: 0.999981] [G loss: 1.000098]\n",
      "epoch:4 step:23375[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:4 step:23380[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:4 step:23385[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:4 step:23390[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:4 step:23395[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:4 step:23400[D loss: 0.999978] [G loss: 1.000055]\n",
      "##############\n",
      "[2.64918749 2.24199834 2.15589393 3.68235414 1.49542863 9.27426719\n",
      " 2.59688223 3.86942489 3.81715079 5.17193522]\n",
      "##########\n",
      "epoch:4 step:23405[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:4 step:23410[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:4 step:23415[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:4 step:23420[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:4 step:23425[D loss: 1.000005] [G loss: 1.000039]\n",
      "epoch:5 step:23430[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:5 step:23435[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:5 step:23440[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:5 step:23445[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:5 step:23450[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:5 step:23455[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:5 step:23460[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:5 step:23465[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:5 step:23470[D loss: 0.999997] [G loss: 1.000062]\n",
      "epoch:5 step:23475[D loss: 0.999996] [G loss: 1.000072]\n",
      "epoch:5 step:23480[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:5 step:23485[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:5 step:23490[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:5 step:23495[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:5 step:23500[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:5 step:23505[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:5 step:23510[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:5 step:23515[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:5 step:23520[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:23525[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:5 step:23530[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:5 step:23535[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:5 step:23540[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:5 step:23545[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:5 step:23550[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:5 step:23555[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:5 step:23560[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:5 step:23565[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:5 step:23570[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:5 step:23575[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:5 step:23580[D loss: 0.999993] [G loss: 1.000037]\n",
      "epoch:5 step:23585[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:5 step:23590[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:23595[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:5 step:23600[D loss: 0.999974] [G loss: 1.000079]\n",
      "##############\n",
      "[2.72398473 2.38243818 2.30832625 3.8807824  1.64014361 7.33882261\n",
      " 2.56503373 3.91000456 3.84274586 5.30187014]\n",
      "##########\n",
      "epoch:5 step:23605[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:5 step:23610[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:5 step:23615[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:5 step:23620[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:5 step:23625[D loss: 1.000012] [G loss: 1.000014]\n",
      "epoch:5 step:23630[D loss: 1.000016] [G loss: 0.999987]\n",
      "epoch:5 step:23635[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:5 step:23640[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:5 step:23645[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:5 step:23650[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:5 step:23655[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:5 step:23660[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:5 step:23665[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:5 step:23670[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:5 step:23675[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:5 step:23680[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:5 step:23685[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:5 step:23690[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:5 step:23695[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:5 step:23700[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:5 step:23705[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:5 step:23710[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:5 step:23715[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:5 step:23720[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:5 step:23725[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:5 step:23730[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:5 step:23735[D loss: 0.999993] [G loss: 1.000081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:23740[D loss: 0.999979] [G loss: 1.000108]\n",
      "epoch:5 step:23745[D loss: 0.999954] [G loss: 1.000139]\n",
      "epoch:5 step:23750[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:5 step:23755[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:5 step:23760[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:5 step:23765[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:5 step:23770[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:5 step:23775[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:5 step:23780[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:5 step:23785[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:5 step:23790[D loss: 0.999951] [G loss: 1.000100]\n",
      "epoch:5 step:23795[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:5 step:23800[D loss: 0.999998] [G loss: 1.000032]\n",
      "##############\n",
      "[2.61230321 2.20188598 2.27608887 3.93422798 1.48299087 7.93259874\n",
      " 2.54140051 3.9527118  3.87768426 5.15370013]\n",
      "##########\n",
      "epoch:5 step:23805[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:5 step:23810[D loss: 0.999949] [G loss: 1.000078]\n",
      "epoch:5 step:23815[D loss: 1.000021] [G loss: 1.000012]\n",
      "epoch:5 step:23820[D loss: 0.999997] [G loss: 1.000057]\n",
      "epoch:5 step:23825[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:5 step:23830[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:5 step:23835[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:5 step:23840[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:5 step:23845[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:5 step:23850[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:5 step:23855[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:5 step:23860[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:5 step:23865[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:5 step:23870[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:5 step:23875[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:5 step:23880[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:5 step:23885[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:5 step:23890[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:5 step:23895[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:5 step:23900[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:5 step:23905[D loss: 1.000019] [G loss: 0.999992]\n",
      "epoch:5 step:23910[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:5 step:23915[D loss: 0.999965] [G loss: 1.000123]\n",
      "epoch:5 step:23920[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:5 step:23925[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:5 step:23930[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:5 step:23935[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:5 step:23940[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:5 step:23945[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:5 step:23950[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:5 step:23955[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:5 step:23960[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:5 step:23965[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:5 step:23970[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:5 step:23975[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:5 step:23980[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:5 step:23985[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:5 step:23990[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:5 step:23995[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:5 step:24000[D loss: 0.999989] [G loss: 1.000072]\n",
      "##############\n",
      "[2.69175762 2.2257166  2.14894278 3.52241066 1.52531248 7.52801216\n",
      " 2.48109408 3.80707837 3.91615235 5.96410944]\n",
      "##########\n",
      "epoch:5 step:24005[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:5 step:24010[D loss: 1.000000] [G loss: 1.000067]\n",
      "epoch:5 step:24015[D loss: 0.999999] [G loss: 1.000054]\n",
      "epoch:5 step:24020[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:5 step:24025[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:5 step:24030[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:5 step:24035[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:5 step:24040[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:5 step:24045[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:5 step:24050[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:5 step:24055[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:5 step:24060[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:5 step:24065[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:5 step:24070[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:5 step:24075[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:5 step:24080[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:5 step:24085[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:5 step:24090[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:5 step:24095[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:5 step:24100[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:5 step:24105[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:5 step:24110[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:24115[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:5 step:24120[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:5 step:24125[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:5 step:24130[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:5 step:24135[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:5 step:24140[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:5 step:24145[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:5 step:24150[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:5 step:24155[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:5 step:24160[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:5 step:24165[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:5 step:24170[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:5 step:24175[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:5 step:24180[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:5 step:24185[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:5 step:24190[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:5 step:24195[D loss: 0.999982] [G loss: 1.000099]\n",
      "epoch:5 step:24200[D loss: 0.999968] [G loss: 1.000081]\n",
      "##############\n",
      "[2.64583998 2.26825341 2.18464406 3.92316786 1.59572803 6.92489738\n",
      " 2.59221225 3.804776   3.88772347 4.65980562]\n",
      "##########\n",
      "epoch:5 step:24205[D loss: 0.999965] [G loss: 1.000111]\n",
      "epoch:5 step:24210[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:5 step:24215[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:5 step:24220[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:5 step:24225[D loss: 0.999997] [G loss: 1.000073]\n",
      "epoch:5 step:24230[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:5 step:24235[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:5 step:24240[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:5 step:24245[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:5 step:24250[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:5 step:24255[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:5 step:24260[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:5 step:24265[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:5 step:24270[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:5 step:24275[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:5 step:24280[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:5 step:24285[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:5 step:24290[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:5 step:24295[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:5 step:24300[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:5 step:24305[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:5 step:24310[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:5 step:24315[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:5 step:24320[D loss: 0.999979] [G loss: 1.000106]\n",
      "epoch:5 step:24325[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:5 step:24330[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:5 step:24335[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:5 step:24340[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:5 step:24345[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:5 step:24350[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:5 step:24355[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:5 step:24360[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:5 step:24365[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:5 step:24370[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:5 step:24375[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:5 step:24380[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:5 step:24385[D loss: 0.999974] [G loss: 1.000030]\n",
      "epoch:5 step:24390[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:5 step:24395[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:5 step:24400[D loss: 0.999982] [G loss: 1.000047]\n",
      "##############\n",
      "[2.68191511 2.20747527 2.19323022 3.76847466 1.65174332 7.57864311\n",
      " 2.53974138 3.96762934 3.94298264 7.14868929]\n",
      "##########\n",
      "epoch:5 step:24405[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:5 step:24410[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:5 step:24415[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:5 step:24420[D loss: 0.999973] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:24425[D loss: 0.999989] [G loss: 1.000094]\n",
      "epoch:5 step:24430[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:5 step:24435[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:5 step:24440[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:5 step:24445[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:5 step:24450[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:5 step:24455[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:5 step:24460[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:5 step:24465[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:5 step:24470[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:5 step:24475[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:5 step:24480[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:5 step:24485[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:5 step:24490[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:5 step:24495[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:5 step:24500[D loss: 1.000019] [G loss: 0.999994]\n",
      "epoch:5 step:24505[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:5 step:24510[D loss: 0.999990] [G loss: 1.000118]\n",
      "epoch:5 step:24515[D loss: 0.999964] [G loss: 1.000121]\n",
      "epoch:5 step:24520[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:5 step:24525[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:5 step:24530[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:5 step:24535[D loss: 1.000009] [G loss: 1.000004]\n",
      "epoch:5 step:24540[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:5 step:24545[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:5 step:24550[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:5 step:24555[D loss: 0.999971] [G loss: 1.000118]\n",
      "epoch:5 step:24560[D loss: 0.999992] [G loss: 1.000082]\n",
      "epoch:5 step:24565[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:5 step:24570[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:5 step:24575[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:5 step:24580[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:5 step:24585[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:5 step:24590[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:5 step:24595[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:5 step:24600[D loss: 0.999967] [G loss: 1.000089]\n",
      "##############\n",
      "[2.72970444 2.27756767 2.32480292 3.78888736 1.60796027 8.06756189\n",
      " 2.64383222 3.76904423 3.90798777 4.75158024]\n",
      "##########\n",
      "epoch:5 step:24605[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:5 step:24610[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:5 step:24615[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:5 step:24620[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:5 step:24625[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:5 step:24630[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:5 step:24635[D loss: 0.999941] [G loss: 1.000117]\n",
      "epoch:5 step:24640[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:5 step:24645[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:5 step:24650[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:5 step:24655[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:5 step:24660[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:5 step:24665[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:5 step:24670[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:5 step:24675[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:5 step:24680[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:5 step:24685[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:5 step:24690[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:5 step:24695[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:5 step:24700[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:5 step:24705[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:5 step:24710[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:5 step:24715[D loss: 1.000013] [G loss: 1.000051]\n",
      "epoch:5 step:24720[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:5 step:24725[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:5 step:24730[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:5 step:24735[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:5 step:24740[D loss: 0.999999] [G loss: 1.000089]\n",
      "epoch:5 step:24745[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:5 step:24750[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:5 step:24755[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:5 step:24760[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:5 step:24765[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:5 step:24770[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:5 step:24775[D loss: 1.000010] [G loss: 0.999985]\n",
      "epoch:5 step:24780[D loss: 0.999952] [G loss: 1.000110]\n",
      "epoch:5 step:24785[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:5 step:24790[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:5 step:24795[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:5 step:24800[D loss: 0.999979] [G loss: 1.000058]\n",
      "##############\n",
      "[2.7258717  2.28877969 2.29488072 3.95605782 1.57298625 7.21483477\n",
      " 2.62670197 3.89670045 3.91791316 5.26393297]\n",
      "##########\n",
      "epoch:5 step:24805[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:5 step:24810[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:5 step:24815[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:5 step:24820[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:5 step:24825[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:5 step:24830[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:5 step:24835[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:5 step:24840[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:5 step:24845[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:5 step:24850[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:5 step:24855[D loss: 0.999954] [G loss: 1.000062]\n",
      "epoch:5 step:24860[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:5 step:24865[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:5 step:24870[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:5 step:24875[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:5 step:24880[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:5 step:24885[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:5 step:24890[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:5 step:24895[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:5 step:24900[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:5 step:24905[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:5 step:24910[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:5 step:24915[D loss: 0.999993] [G loss: 1.000081]\n",
      "epoch:5 step:24920[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:5 step:24925[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:5 step:24930[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:5 step:24935[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:5 step:24940[D loss: 1.000001] [G loss: 1.000082]\n",
      "epoch:5 step:24945[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:5 step:24950[D loss: 1.000007] [G loss: 1.000039]\n",
      "epoch:5 step:24955[D loss: 1.000025] [G loss: 0.999996]\n",
      "epoch:5 step:24960[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:5 step:24965[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:5 step:24970[D loss: 1.000014] [G loss: 1.000020]\n",
      "epoch:5 step:24975[D loss: 0.999939] [G loss: 1.000136]\n",
      "epoch:5 step:24980[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:5 step:24985[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:5 step:24990[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:5 step:24995[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:5 step:25000[D loss: 0.999982] [G loss: 1.000098]\n",
      "##############\n",
      "[2.73878898 2.31101835 2.23578766 3.98131612 1.61356445 7.4608155\n",
      " 2.56005981 3.8711425  3.87282866 5.05761509]\n",
      "##########\n",
      "epoch:5 step:25005[D loss: 0.999995] [G loss: 1.000111]\n",
      "epoch:5 step:25010[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:5 step:25015[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:5 step:25020[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:5 step:25025[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:5 step:25030[D loss: 1.000026] [G loss: 1.000031]\n",
      "epoch:5 step:25035[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:5 step:25040[D loss: 1.000005] [G loss: 1.000019]\n",
      "epoch:5 step:25045[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:5 step:25050[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:5 step:25055[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:5 step:25060[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:5 step:25065[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:5 step:25070[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:5 step:25075[D loss: 0.999986] [G loss: 1.000093]\n",
      "epoch:5 step:25080[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:5 step:25085[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:5 step:25090[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:5 step:25095[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:5 step:25100[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:5 step:25105[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:5 step:25110[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:5 step:25115[D loss: 0.999969] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:25120[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:5 step:25125[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:5 step:25130[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:5 step:25135[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:5 step:25140[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:5 step:25145[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:5 step:25150[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:5 step:25155[D loss: 1.000019] [G loss: 1.000032]\n",
      "epoch:5 step:25160[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:5 step:25165[D loss: 0.999989] [G loss: 1.000084]\n",
      "epoch:5 step:25170[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:5 step:25175[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:5 step:25180[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:5 step:25185[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:5 step:25190[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:5 step:25195[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:5 step:25200[D loss: 0.999971] [G loss: 1.000111]\n",
      "##############\n",
      "[2.72921875 2.24303318 2.32280318 3.91274241 1.52822562 7.64592033\n",
      " 2.58094695 3.94113056 3.92618561 4.82843496]\n",
      "##########\n",
      "epoch:5 step:25205[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:5 step:25210[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:5 step:25215[D loss: 0.999979] [G loss: 1.000119]\n",
      "epoch:5 step:25220[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:5 step:25225[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:5 step:25230[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:5 step:25235[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:5 step:25240[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:5 step:25245[D loss: 0.999970] [G loss: 1.000125]\n",
      "epoch:5 step:25250[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:5 step:25255[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:5 step:25260[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:5 step:25265[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:5 step:25270[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:5 step:25275[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:5 step:25280[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:5 step:25285[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:25290[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:5 step:25295[D loss: 0.999995] [G loss: 1.000102]\n",
      "epoch:5 step:25300[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:5 step:25305[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:5 step:25310[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:5 step:25315[D loss: 1.000019] [G loss: 1.000022]\n",
      "epoch:5 step:25320[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:5 step:25325[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:5 step:25330[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:5 step:25335[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:5 step:25340[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:5 step:25345[D loss: 1.000000] [G loss: 0.999990]\n",
      "epoch:5 step:25350[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:5 step:25355[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:5 step:25360[D loss: 0.999971] [G loss: 1.000111]\n",
      "epoch:5 step:25365[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:5 step:25370[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:5 step:25375[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:25380[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:5 step:25385[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:5 step:25390[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:5 step:25395[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:5 step:25400[D loss: 0.999970] [G loss: 1.000080]\n",
      "##############\n",
      "[2.6330779  2.29164303 2.19660554 3.93282473 1.5270072  7.42932701\n",
      " 2.60830842 3.8620436  3.81780989 4.58937558]\n",
      "##########\n",
      "epoch:5 step:25405[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:5 step:25410[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:5 step:25415[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:5 step:25420[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:5 step:25425[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:5 step:25430[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:5 step:25435[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:5 step:25440[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:5 step:25445[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:5 step:25450[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:25455[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:5 step:25460[D loss: 1.000005] [G loss: 1.000066]\n",
      "epoch:5 step:25465[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:5 step:25470[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:5 step:25475[D loss: 1.000001] [G loss: 1.000082]\n",
      "epoch:5 step:25480[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:5 step:25485[D loss: 1.000025] [G loss: 1.000041]\n",
      "epoch:5 step:25490[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:5 step:25495[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:5 step:25500[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:5 step:25505[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:5 step:25510[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:5 step:25515[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:5 step:25520[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:5 step:25525[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:5 step:25530[D loss: 0.999994] [G loss: 1.000074]\n",
      "epoch:5 step:25535[D loss: 0.999999] [G loss: 1.000075]\n",
      "epoch:5 step:25540[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:5 step:25545[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:5 step:25550[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:5 step:25555[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:5 step:25560[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:5 step:25565[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:5 step:25570[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:5 step:25575[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:5 step:25580[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:5 step:25585[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:5 step:25590[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:5 step:25595[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:5 step:25600[D loss: 0.999977] [G loss: 1.000058]\n",
      "##############\n",
      "[2.77229193 2.2514754  2.26569986 3.85433316 1.61311875 8.14157761\n",
      " 2.5669048  3.99084221 3.95969528 5.89080359]\n",
      "##########\n",
      "epoch:5 step:25605[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:5 step:25610[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:5 step:25615[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:5 step:25620[D loss: 0.999997] [G loss: 1.000003]\n",
      "epoch:5 step:25625[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:5 step:25630[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:5 step:25635[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:5 step:25640[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:5 step:25645[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:5 step:25650[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:5 step:25655[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:5 step:25660[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:5 step:25665[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:5 step:25670[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:5 step:25675[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:5 step:25680[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:5 step:25685[D loss: 0.999976] [G loss: 1.000017]\n",
      "epoch:5 step:25690[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:5 step:25695[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:5 step:25700[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:5 step:25705[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:5 step:25710[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:5 step:25715[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:5 step:25720[D loss: 1.000008] [G loss: 1.000083]\n",
      "epoch:5 step:25725[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:5 step:25730[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:5 step:25735[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:5 step:25740[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:5 step:25745[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:5 step:25750[D loss: 1.000018] [G loss: 0.999993]\n",
      "epoch:5 step:25755[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:5 step:25760[D loss: 0.999982] [G loss: 1.000087]\n",
      "epoch:5 step:25765[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:5 step:25770[D loss: 0.999951] [G loss: 1.000166]\n",
      "epoch:5 step:25775[D loss: 0.999982] [G loss: 1.000095]\n",
      "epoch:5 step:25780[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:5 step:25785[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:5 step:25790[D loss: 1.000002] [G loss: 1.000046]\n",
      "epoch:5 step:25795[D loss: 1.000010] [G loss: 1.000038]\n",
      "epoch:5 step:25800[D loss: 0.999971] [G loss: 1.000076]\n",
      "##############\n",
      "[2.69396692 2.25725048 2.37487104 4.07201929 1.57232417 7.30539618\n",
      " 2.56286216 3.93527247 3.93680044 4.94185142]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:25805[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:5 step:25810[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:5 step:25815[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:5 step:25820[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:5 step:25825[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:5 step:25830[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:5 step:25835[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:5 step:25840[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:5 step:25845[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:5 step:25850[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:5 step:25855[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:5 step:25860[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:5 step:25865[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:5 step:25870[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:5 step:25875[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:5 step:25880[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:5 step:25885[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:5 step:25890[D loss: 1.000017] [G loss: 1.000058]\n",
      "epoch:5 step:25895[D loss: 1.000005] [G loss: 1.000035]\n",
      "epoch:5 step:25900[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:5 step:25905[D loss: 1.000032] [G loss: 1.000037]\n",
      "epoch:5 step:25910[D loss: 0.999997] [G loss: 1.000067]\n",
      "epoch:5 step:25915[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:5 step:25920[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:5 step:25925[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:5 step:25930[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:5 step:25935[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:5 step:25940[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:5 step:25945[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:5 step:25950[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:5 step:25955[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:5 step:25960[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:5 step:25965[D loss: 1.000007] [G loss: 1.000021]\n",
      "epoch:5 step:25970[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:5 step:25975[D loss: 1.000007] [G loss: 1.000072]\n",
      "epoch:5 step:25980[D loss: 0.999942] [G loss: 1.000123]\n",
      "epoch:5 step:25985[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:5 step:25990[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:5 step:25995[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:5 step:26000[D loss: 0.999963] [G loss: 1.000078]\n",
      "##############\n",
      "[2.61198694 2.24342742 2.13294188 3.88490255 1.5593569  7.45639737\n",
      " 2.45445014 3.89596588 3.8955601  5.48809298]\n",
      "##########\n",
      "epoch:5 step:26005[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:5 step:26010[D loss: 0.999995] [G loss: 1.000075]\n",
      "epoch:5 step:26015[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:5 step:26020[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:5 step:26025[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:5 step:26030[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:5 step:26035[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:5 step:26040[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:5 step:26045[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:5 step:26050[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:5 step:26055[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:5 step:26060[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:5 step:26065[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:5 step:26070[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:5 step:26075[D loss: 0.999984] [G loss: 1.000094]\n",
      "epoch:5 step:26080[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:5 step:26085[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:5 step:26090[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:5 step:26095[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:5 step:26100[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:5 step:26105[D loss: 0.999998] [G loss: 1.000059]\n",
      "epoch:5 step:26110[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:5 step:26115[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:5 step:26120[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:5 step:26125[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:5 step:26130[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:5 step:26135[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:5 step:26140[D loss: 1.000018] [G loss: 1.000040]\n",
      "epoch:5 step:26145[D loss: 0.999976] [G loss: 1.000100]\n",
      "epoch:5 step:26150[D loss: 0.999995] [G loss: 1.000065]\n",
      "epoch:5 step:26155[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:5 step:26160[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:5 step:26165[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:5 step:26170[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:5 step:26175[D loss: 1.000010] [G loss: 1.000038]\n",
      "epoch:5 step:26180[D loss: 1.000002] [G loss: 1.000068]\n",
      "epoch:5 step:26185[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:5 step:26190[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:5 step:26195[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:5 step:26200[D loss: 0.999974] [G loss: 1.000064]\n",
      "##############\n",
      "[2.56974819 2.22191061 2.17789056 3.86849236 1.52226883 6.87313835\n",
      " 2.68702579 3.83820304 3.81015095 4.69342806]\n",
      "##########\n",
      "epoch:5 step:26205[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:5 step:26210[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:5 step:26215[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:5 step:26220[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:5 step:26225[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:5 step:26230[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:5 step:26235[D loss: 0.999972] [G loss: 1.000094]\n",
      "epoch:5 step:26240[D loss: 0.999981] [G loss: 1.000100]\n",
      "epoch:5 step:26245[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:5 step:26250[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:5 step:26255[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:5 step:26260[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:5 step:26265[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:5 step:26270[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:5 step:26275[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:5 step:26280[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:5 step:26285[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:5 step:26290[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:5 step:26295[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:5 step:26300[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:5 step:26305[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:5 step:26310[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:5 step:26315[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:5 step:26320[D loss: 0.999969] [G loss: 1.000096]\n",
      "epoch:5 step:26325[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:5 step:26330[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:5 step:26335[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:5 step:26340[D loss: 1.000002] [G loss: 0.999991]\n",
      "epoch:5 step:26345[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:5 step:26350[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:5 step:26355[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:5 step:26360[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:5 step:26365[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:26370[D loss: 1.000004] [G loss: 1.000067]\n",
      "epoch:5 step:26375[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:5 step:26380[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:5 step:26385[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:5 step:26390[D loss: 1.000001] [G loss: 1.000085]\n",
      "epoch:5 step:26395[D loss: 0.999989] [G loss: 1.000097]\n",
      "epoch:5 step:26400[D loss: 0.999992] [G loss: 1.000070]\n",
      "##############\n",
      "[2.75387156 2.25339634 2.24509819 3.69407437 1.58667933 7.49356222\n",
      " 2.5205319  3.8785202  3.86680367 5.03512316]\n",
      "##########\n",
      "epoch:5 step:26405[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:5 step:26410[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:5 step:26415[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:5 step:26420[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:5 step:26425[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:5 step:26430[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:5 step:26435[D loss: 0.999979] [G loss: 1.000108]\n",
      "epoch:5 step:26440[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:5 step:26445[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:5 step:26450[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:26455[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:5 step:26460[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:5 step:26465[D loss: 1.000004] [G loss: 1.000007]\n",
      "epoch:5 step:26470[D loss: 0.999984] [G loss: 1.000098]\n",
      "epoch:5 step:26475[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:5 step:26480[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:5 step:26485[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:5 step:26490[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:5 step:26495[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:5 step:26500[D loss: 0.999976] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:26505[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:5 step:26510[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:5 step:26515[D loss: 0.999961] [G loss: 1.000113]\n",
      "epoch:5 step:26520[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:5 step:26525[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:5 step:26530[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:5 step:26535[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:5 step:26540[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:5 step:26545[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:5 step:26550[D loss: 1.000006] [G loss: 1.000037]\n",
      "epoch:5 step:26555[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:5 step:26560[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:5 step:26565[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:5 step:26570[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:5 step:26575[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:5 step:26580[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:5 step:26585[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:5 step:26590[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:5 step:26595[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:5 step:26600[D loss: 0.999986] [G loss: 1.000054]\n",
      "##############\n",
      "[2.72842366 2.31314454 2.26131002 4.08340595 1.639417   7.74872775\n",
      " 2.47801128 3.86805099 3.91905946 5.22082962]\n",
      "##########\n",
      "epoch:5 step:26605[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:5 step:26610[D loss: 1.000030] [G loss: 1.000005]\n",
      "epoch:5 step:26615[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:5 step:26620[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:5 step:26625[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:5 step:26630[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:5 step:26635[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:5 step:26640[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:5 step:26645[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:5 step:26650[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:5 step:26655[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:5 step:26660[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:5 step:26665[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:5 step:26670[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:5 step:26675[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:5 step:26680[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:5 step:26685[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:5 step:26690[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:5 step:26695[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:5 step:26700[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:5 step:26705[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:5 step:26710[D loss: 1.000007] [G loss: 1.000027]\n",
      "epoch:5 step:26715[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:5 step:26720[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:5 step:26725[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:5 step:26730[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:5 step:26735[D loss: 1.000000] [G loss: 1.000088]\n",
      "epoch:5 step:26740[D loss: 1.000006] [G loss: 1.000056]\n",
      "epoch:5 step:26745[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:5 step:26750[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:5 step:26755[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:5 step:26760[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:5 step:26765[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:5 step:26770[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:26775[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:5 step:26780[D loss: 0.999973] [G loss: 1.000098]\n",
      "epoch:5 step:26785[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:5 step:26790[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:5 step:26795[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:5 step:26800[D loss: 0.999983] [G loss: 1.000063]\n",
      "##############\n",
      "[2.77486209 2.29707309 2.24540799 3.88857159 1.65693309 7.30735921\n",
      " 2.57454687 3.98780717 3.99777833 5.97814265]\n",
      "##########\n",
      "epoch:5 step:26805[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:5 step:26810[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:5 step:26815[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:5 step:26820[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:5 step:26825[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:5 step:26830[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:5 step:26835[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:5 step:26840[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:5 step:26845[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:5 step:26850[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:5 step:26855[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:5 step:26860[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:5 step:26865[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:5 step:26870[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:5 step:26875[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:5 step:26880[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:5 step:26885[D loss: 0.999988] [G loss: 1.000027]\n",
      "epoch:5 step:26890[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:5 step:26895[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:5 step:26900[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:5 step:26905[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:5 step:26910[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:5 step:26915[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:5 step:26920[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:5 step:26925[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:5 step:26930[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:5 step:26935[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:5 step:26940[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:5 step:26945[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:5 step:26950[D loss: 0.999984] [G loss: 1.000103]\n",
      "epoch:5 step:26955[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:5 step:26960[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:5 step:26965[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:5 step:26970[D loss: 1.000014] [G loss: 1.000055]\n",
      "epoch:5 step:26975[D loss: 1.000006] [G loss: 1.000033]\n",
      "epoch:5 step:26980[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:5 step:26985[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:5 step:26990[D loss: 0.999958] [G loss: 1.000097]\n",
      "epoch:5 step:26995[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:5 step:27000[D loss: 0.999972] [G loss: 1.000086]\n",
      "##############\n",
      "[2.61082747 2.22954558 2.32981512 3.94856492 1.51946804 7.67063757\n",
      " 2.46932924 3.98989653 3.81283883 4.7368728 ]\n",
      "##########\n",
      "epoch:5 step:27005[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:5 step:27010[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:5 step:27015[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:5 step:27020[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:5 step:27025[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:5 step:27030[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:5 step:27035[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:5 step:27040[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:5 step:27045[D loss: 1.000008] [G loss: 1.000040]\n",
      "epoch:5 step:27050[D loss: 0.999985] [G loss: 1.000019]\n",
      "epoch:5 step:27055[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:5 step:27060[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:5 step:27065[D loss: 0.999972] [G loss: 1.000104]\n",
      "epoch:5 step:27070[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:5 step:27075[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:5 step:27080[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:5 step:27085[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:5 step:27090[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:5 step:27095[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:5 step:27100[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:5 step:27105[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:5 step:27110[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:5 step:27115[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:5 step:27120[D loss: 0.999990] [G loss: 1.000079]\n",
      "epoch:5 step:27125[D loss: 0.999974] [G loss: 1.000099]\n",
      "epoch:5 step:27130[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:5 step:27135[D loss: 1.000031] [G loss: 1.000036]\n",
      "epoch:5 step:27140[D loss: 0.999960] [G loss: 1.000043]\n",
      "epoch:5 step:27145[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:5 step:27150[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:5 step:27155[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:5 step:27160[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:5 step:27165[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:5 step:27170[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:5 step:27175[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:5 step:27180[D loss: 0.999977] [G loss: 1.000094]\n",
      "epoch:5 step:27185[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:5 step:27190[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:5 step:27195[D loss: 0.999989] [G loss: 1.000095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:27200[D loss: 0.999966] [G loss: 1.000098]\n",
      "##############\n",
      "[2.75378776 2.31531947 2.3076482  3.87753858 1.59561934 7.61511492\n",
      " 2.53141874 4.08675631 3.96991654 5.44336595]\n",
      "##########\n",
      "epoch:5 step:27205[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:5 step:27210[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:5 step:27215[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:5 step:27220[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:5 step:27225[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:5 step:27230[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:5 step:27235[D loss: 0.999985] [G loss: 1.000100]\n",
      "epoch:5 step:27240[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:5 step:27245[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:5 step:27250[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:5 step:27255[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:5 step:27260[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:5 step:27265[D loss: 0.999955] [G loss: 1.000079]\n",
      "epoch:5 step:27270[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:5 step:27275[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:5 step:27280[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:5 step:27285[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:5 step:27290[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:5 step:27295[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:5 step:27300[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:5 step:27305[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:5 step:27310[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:5 step:27315[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:5 step:27320[D loss: 0.999963] [G loss: 1.000124]\n",
      "epoch:5 step:27325[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:5 step:27330[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:5 step:27335[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:5 step:27340[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:5 step:27345[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:5 step:27350[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:5 step:27355[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:5 step:27360[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:5 step:27365[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:5 step:27370[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:5 step:27375[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:5 step:27380[D loss: 0.999977] [G loss: 1.000102]\n",
      "epoch:5 step:27385[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:5 step:27390[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:5 step:27395[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:5 step:27400[D loss: 0.999993] [G loss: 1.000052]\n",
      "##############\n",
      "[2.71965027 2.30788673 2.26587821 3.75615593 1.54358264 7.44203694\n",
      " 2.45037812 3.93733186 3.9174646  5.07554914]\n",
      "##########\n",
      "epoch:5 step:27405[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:5 step:27410[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:5 step:27415[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:5 step:27420[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:5 step:27425[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:5 step:27430[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:5 step:27435[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:5 step:27440[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:5 step:27445[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:5 step:27450[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:5 step:27455[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:5 step:27460[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:5 step:27465[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:5 step:27470[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:5 step:27475[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:5 step:27480[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:5 step:27485[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:5 step:27490[D loss: 1.000000] [G loss: 1.000078]\n",
      "epoch:5 step:27495[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:5 step:27500[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:5 step:27505[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:5 step:27510[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:5 step:27515[D loss: 1.000001] [G loss: 1.000076]\n",
      "epoch:5 step:27520[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:5 step:27525[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:5 step:27530[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:5 step:27535[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:5 step:27540[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:5 step:27545[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:5 step:27550[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:5 step:27555[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:5 step:27560[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:5 step:27565[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:5 step:27570[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:5 step:27575[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:5 step:27580[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:5 step:27585[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:5 step:27590[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:5 step:27595[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:5 step:27600[D loss: 0.999970] [G loss: 1.000087]\n",
      "##############\n",
      "[2.60346954 2.23797818 2.28491789 3.77401226 1.47039429 6.63580769\n",
      " 2.5100805  3.73283484 3.86141796 6.43815102]\n",
      "##########\n",
      "epoch:5 step:27605[D loss: 0.999997] [G loss: 1.000070]\n",
      "epoch:5 step:27610[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:5 step:27615[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:5 step:27620[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:5 step:27625[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:5 step:27630[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:5 step:27635[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:5 step:27640[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:5 step:27645[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:5 step:27650[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:5 step:27655[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:5 step:27660[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:5 step:27665[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:5 step:27670[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:5 step:27675[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:5 step:27680[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:5 step:27685[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:5 step:27690[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:27695[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:5 step:27700[D loss: 1.000006] [G loss: 1.000042]\n",
      "epoch:5 step:27705[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:5 step:27710[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:5 step:27715[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:5 step:27720[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:5 step:27725[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:5 step:27730[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:5 step:27735[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:5 step:27740[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:5 step:27745[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:5 step:27750[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:5 step:27755[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:5 step:27760[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:5 step:27765[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:5 step:27770[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:5 step:27775[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:5 step:27780[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:5 step:27785[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:5 step:27790[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:5 step:27795[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:5 step:27800[D loss: 1.000011] [G loss: 1.000033]\n",
      "##############\n",
      "[2.62521879 2.27703306 2.27804326 3.74428043 1.43685876 7.51728599\n",
      " 2.40130046 3.73643961 3.82122823 4.64788105]\n",
      "##########\n",
      "epoch:5 step:27805[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:5 step:27810[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:5 step:27815[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:5 step:27820[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:5 step:27825[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:5 step:27830[D loss: 0.999995] [G loss: 1.000038]\n",
      "epoch:5 step:27835[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:5 step:27840[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:5 step:27845[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:5 step:27850[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:5 step:27855[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:5 step:27860[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:5 step:27865[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:5 step:27870[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:5 step:27875[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:5 step:27880[D loss: 0.999980] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:27885[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:5 step:27890[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:5 step:27895[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:5 step:27900[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:5 step:27905[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:5 step:27910[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:5 step:27915[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:5 step:27920[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:5 step:27925[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:27930[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:5 step:27935[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:5 step:27940[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:5 step:27945[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:5 step:27950[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:5 step:27955[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:5 step:27960[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:5 step:27965[D loss: 1.000008] [G loss: 1.000044]\n",
      "epoch:5 step:27970[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:5 step:27975[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:5 step:27980[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:5 step:27985[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:5 step:27990[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:5 step:27995[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:5 step:28000[D loss: 0.999980] [G loss: 1.000075]\n",
      "##############\n",
      "[2.70685541 2.24327634 2.34203498 3.76309538 1.57321303 8.28443372\n",
      " 2.5169103  3.88490901 3.90795292 4.88296638]\n",
      "##########\n",
      "epoch:5 step:28005[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:5 step:28010[D loss: 1.000038] [G loss: 1.000004]\n",
      "epoch:5 step:28015[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:5 step:28020[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:5 step:28025[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:5 step:28030[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:5 step:28035[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:5 step:28040[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:5 step:28045[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:5 step:28050[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:5 step:28055[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:5 step:28060[D loss: 0.999965] [G loss: 1.000101]\n",
      "epoch:5 step:28065[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:5 step:28070[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:5 step:28075[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:5 step:28080[D loss: 0.999983] [G loss: 1.000094]\n",
      "epoch:5 step:28085[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:5 step:28090[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:5 step:28095[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:5 step:28100[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:5 step:28105[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:5 step:28110[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:6 step:28115[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:6 step:28120[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:6 step:28125[D loss: 1.000008] [G loss: 1.000054]\n",
      "epoch:6 step:28130[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:6 step:28135[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:6 step:28140[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:6 step:28145[D loss: 0.999998] [G loss: 1.000044]\n",
      "epoch:6 step:28150[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:6 step:28155[D loss: 0.999992] [G loss: 1.000083]\n",
      "epoch:6 step:28160[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:6 step:28165[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:6 step:28170[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:6 step:28175[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:6 step:28180[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:6 step:28185[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:6 step:28190[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:6 step:28195[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:6 step:28200[D loss: 0.999979] [G loss: 1.000078]\n",
      "##############\n",
      "[2.66690212 2.19270842 2.20359127 3.89888863 1.53658502 7.46762532\n",
      " 2.39519034 3.75503338 3.83807633 5.17788088]\n",
      "##########\n",
      "epoch:6 step:28205[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:6 step:28210[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:6 step:28215[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:6 step:28220[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:6 step:28225[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:6 step:28230[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:6 step:28235[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:6 step:28240[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:6 step:28245[D loss: 1.000004] [G loss: 1.000068]\n",
      "epoch:6 step:28250[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:6 step:28255[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:6 step:28260[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:6 step:28265[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:6 step:28270[D loss: 1.000016] [G loss: 0.999980]\n",
      "epoch:6 step:28275[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:6 step:28280[D loss: 0.999970] [G loss: 1.000108]\n",
      "epoch:6 step:28285[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:6 step:28290[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:6 step:28295[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:6 step:28300[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:6 step:28305[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:6 step:28310[D loss: 1.000004] [G loss: 1.000042]\n",
      "epoch:6 step:28315[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:6 step:28320[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:6 step:28325[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:6 step:28330[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:6 step:28335[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:6 step:28340[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:6 step:28345[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:6 step:28350[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:6 step:28355[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:6 step:28360[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:6 step:28365[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:6 step:28370[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:6 step:28375[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:6 step:28380[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:6 step:28385[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:6 step:28390[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:6 step:28395[D loss: 0.999997] [G loss: 1.000088]\n",
      "epoch:6 step:28400[D loss: 0.999964] [G loss: 1.000101]\n",
      "##############\n",
      "[2.72205107 2.34397994 2.27163791 3.77118138 1.59130044 7.96996709\n",
      " 2.31425644 3.8850188  3.92700015 7.14868929]\n",
      "##########\n",
      "epoch:6 step:28405[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:6 step:28410[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:6 step:28415[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:6 step:28420[D loss: 1.000019] [G loss: 1.000006]\n",
      "epoch:6 step:28425[D loss: 0.999977] [G loss: 1.000098]\n",
      "epoch:6 step:28430[D loss: 1.000021] [G loss: 1.000018]\n",
      "epoch:6 step:28435[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:6 step:28440[D loss: 1.000035] [G loss: 0.999992]\n",
      "epoch:6 step:28445[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:6 step:28450[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:6 step:28455[D loss: 1.000058] [G loss: 0.999969]\n",
      "epoch:6 step:28460[D loss: 1.000015] [G loss: 1.000032]\n",
      "epoch:6 step:28465[D loss: 0.999959] [G loss: 1.000113]\n",
      "epoch:6 step:28470[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:6 step:28475[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:6 step:28480[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:6 step:28485[D loss: 1.000000] [G loss: 1.000008]\n",
      "epoch:6 step:28490[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:6 step:28495[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:6 step:28500[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:6 step:28505[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:6 step:28510[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:6 step:28515[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:6 step:28520[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:6 step:28525[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:6 step:28530[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:6 step:28535[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:6 step:28540[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:6 step:28545[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:6 step:28550[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:6 step:28555[D loss: 1.000015] [G loss: 1.000048]\n",
      "epoch:6 step:28560[D loss: 0.999958] [G loss: 1.000097]\n",
      "epoch:6 step:28565[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:28570[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:6 step:28575[D loss: 0.999986] [G loss: 1.000040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:28580[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:6 step:28585[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:6 step:28590[D loss: 1.000004] [G loss: 1.000034]\n",
      "epoch:6 step:28595[D loss: 0.999992] [G loss: 1.000082]\n",
      "epoch:6 step:28600[D loss: 0.999989] [G loss: 1.000062]\n",
      "##############\n",
      "[2.6932167  2.24972451 2.36440291 3.68128567 1.51641353 6.86780021\n",
      " 2.49142164 3.86791509 3.85746388 4.74645484]\n",
      "##########\n",
      "epoch:6 step:28605[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:6 step:28610[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:6 step:28615[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:6 step:28620[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:6 step:28625[D loss: 1.000000] [G loss: 1.000046]\n",
      "epoch:6 step:28630[D loss: 0.999965] [G loss: 1.000118]\n",
      "epoch:6 step:28635[D loss: 1.000018] [G loss: 0.999981]\n",
      "epoch:6 step:28640[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:6 step:28645[D loss: 0.999971] [G loss: 1.000109]\n",
      "epoch:6 step:28650[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:6 step:28655[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:6 step:28660[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:6 step:28665[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:6 step:28670[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:6 step:28675[D loss: 0.999985] [G loss: 1.000106]\n",
      "epoch:6 step:28680[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:6 step:28685[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:6 step:28690[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:6 step:28695[D loss: 1.000005] [G loss: 1.000002]\n",
      "epoch:6 step:28700[D loss: 1.000003] [G loss: 1.000054]\n",
      "epoch:6 step:28705[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:6 step:28710[D loss: 0.999937] [G loss: 1.000119]\n",
      "epoch:6 step:28715[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:6 step:28720[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:6 step:28725[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:6 step:28730[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:6 step:28735[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:6 step:28740[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:6 step:28745[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:6 step:28750[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:6 step:28755[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:6 step:28760[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:6 step:28765[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:6 step:28770[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:6 step:28775[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:6 step:28780[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:6 step:28785[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:6 step:28790[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:6 step:28795[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:6 step:28800[D loss: 0.999965] [G loss: 1.000074]\n",
      "##############\n",
      "[2.67907897 2.30680089 2.28173774 3.55633355 1.59842602 7.62622748\n",
      " 2.61801707 3.93897909 3.94286357 8.14868929]\n",
      "##########\n",
      "epoch:6 step:28805[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:6 step:28810[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:6 step:28815[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:6 step:28820[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:6 step:28825[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:6 step:28830[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:6 step:28835[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:6 step:28840[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:6 step:28845[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:28850[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:6 step:28855[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:6 step:28860[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:6 step:28865[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:6 step:28870[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:6 step:28875[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:6 step:28880[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:6 step:28885[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:6 step:28890[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:6 step:28895[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:6 step:28900[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:6 step:28905[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:6 step:28910[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:6 step:28915[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:6 step:28920[D loss: 0.999990] [G loss: 1.000078]\n",
      "epoch:6 step:28925[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:6 step:28930[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:6 step:28935[D loss: 1.000001] [G loss: 1.000041]\n",
      "epoch:6 step:28940[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:6 step:28945[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:6 step:28950[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:6 step:28955[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:6 step:28960[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:6 step:28965[D loss: 0.999940] [G loss: 1.000093]\n",
      "epoch:6 step:28970[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:6 step:28975[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:6 step:28980[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:6 step:28985[D loss: 0.999979] [G loss: 1.000093]\n",
      "epoch:6 step:28990[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:6 step:28995[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:6 step:29000[D loss: 0.999988] [G loss: 1.000040]\n",
      "##############\n",
      "[2.66920445 2.17860765 2.19666884 3.91008752 1.61926809 7.62566269\n",
      " 2.5238195  4.1434667  3.89475105 5.11550983]\n",
      "##########\n",
      "epoch:6 step:29005[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:6 step:29010[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:6 step:29015[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:6 step:29020[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:6 step:29025[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:6 step:29030[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:6 step:29035[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:6 step:29040[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:6 step:29045[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:6 step:29050[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:6 step:29055[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:6 step:29060[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:6 step:29065[D loss: 1.000005] [G loss: 1.000043]\n",
      "epoch:6 step:29070[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:6 step:29075[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:6 step:29080[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:29085[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:6 step:29090[D loss: 0.999966] [G loss: 1.000102]\n",
      "epoch:6 step:29095[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:6 step:29100[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:6 step:29105[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:6 step:29110[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:6 step:29115[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:6 step:29120[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:6 step:29125[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:6 step:29130[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:6 step:29135[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:6 step:29140[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:6 step:29145[D loss: 0.999972] [G loss: 1.000123]\n",
      "epoch:6 step:29150[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:6 step:29155[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:6 step:29160[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:6 step:29165[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:6 step:29170[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:6 step:29175[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:6 step:29180[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:6 step:29185[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:6 step:29190[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:6 step:29195[D loss: 0.999991] [G loss: 1.000112]\n",
      "epoch:6 step:29200[D loss: 0.999962] [G loss: 1.000077]\n",
      "##############\n",
      "[2.5927838  2.11648049 2.25226381 3.83673882 1.49315032 7.66704622\n",
      " 2.39522022 3.86428658 3.86182523 7.14868929]\n",
      "##########\n",
      "epoch:6 step:29205[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:6 step:29210[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:6 step:29215[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:6 step:29220[D loss: 1.000004] [G loss: 1.000005]\n",
      "epoch:6 step:29225[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:6 step:29230[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:6 step:29235[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:6 step:29240[D loss: 1.000012] [G loss: 1.000057]\n",
      "epoch:6 step:29245[D loss: 0.999984] [G loss: 1.000107]\n",
      "epoch:6 step:29250[D loss: 0.999933] [G loss: 1.000095]\n",
      "epoch:6 step:29255[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:6 step:29260[D loss: 0.999979] [G loss: 1.000079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:29265[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:6 step:29270[D loss: 0.999951] [G loss: 1.000073]\n",
      "epoch:6 step:29275[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:6 step:29280[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:6 step:29285[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:6 step:29290[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:6 step:29295[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:6 step:29300[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:6 step:29305[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:6 step:29310[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:6 step:29315[D loss: 0.999966] [G loss: 1.000107]\n",
      "epoch:6 step:29320[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:6 step:29325[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:6 step:29330[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:6 step:29335[D loss: 0.999996] [G loss: 1.000040]\n",
      "epoch:6 step:29340[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:6 step:29345[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:6 step:29350[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:6 step:29355[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:6 step:29360[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:6 step:29365[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:6 step:29370[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:6 step:29375[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:6 step:29380[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:6 step:29385[D loss: 1.000000] [G loss: 1.000053]\n",
      "epoch:6 step:29390[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:6 step:29395[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:6 step:29400[D loss: 1.000012] [G loss: 1.000005]\n",
      "##############\n",
      "[2.74660091 2.24898327 2.32884705 3.97720022 1.58356817 7.20401255\n",
      " 2.50727544 4.05244936 3.99358592 5.7556445 ]\n",
      "##########\n",
      "epoch:6 step:29405[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:6 step:29410[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:6 step:29415[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:6 step:29420[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:6 step:29425[D loss: 1.000018] [G loss: 1.000037]\n",
      "epoch:6 step:29430[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:6 step:29435[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:6 step:29440[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:6 step:29445[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:6 step:29450[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:6 step:29455[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:6 step:29460[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:6 step:29465[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:6 step:29470[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:6 step:29475[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:6 step:29480[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:6 step:29485[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:6 step:29490[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:6 step:29495[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:6 step:29500[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:6 step:29505[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:6 step:29510[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:6 step:29515[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:6 step:29520[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:6 step:29525[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:6 step:29530[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:6 step:29535[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:6 step:29540[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:6 step:29545[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:29550[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:6 step:29555[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:6 step:29560[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:6 step:29565[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:6 step:29570[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:6 step:29575[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:6 step:29580[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:6 step:29585[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:6 step:29590[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:6 step:29595[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:6 step:29600[D loss: 0.999987] [G loss: 1.000066]\n",
      "##############\n",
      "[2.70762822 2.21100638 2.14084347 3.98652067 1.52172855 7.33145537\n",
      " 2.272357   3.86924034 3.84696278 5.26530092]\n",
      "##########\n",
      "epoch:6 step:29605[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:6 step:29610[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:6 step:29615[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:6 step:29620[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:6 step:29625[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:6 step:29630[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:6 step:29635[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:6 step:29640[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:6 step:29645[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:6 step:29650[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:6 step:29655[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:6 step:29660[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:6 step:29665[D loss: 0.999960] [G loss: 1.000129]\n",
      "epoch:6 step:29670[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:6 step:29675[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:6 step:29680[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:29685[D loss: 0.999987] [G loss: 1.000088]\n",
      "epoch:6 step:29690[D loss: 0.999989] [G loss: 1.000087]\n",
      "epoch:6 step:29695[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:6 step:29700[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:6 step:29705[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:6 step:29710[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:6 step:29715[D loss: 1.000033] [G loss: 1.000010]\n",
      "epoch:6 step:29720[D loss: 1.000048] [G loss: 0.999964]\n",
      "epoch:6 step:29725[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:6 step:29730[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:6 step:29735[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:6 step:29740[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:6 step:29745[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:6 step:29750[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:6 step:29755[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:6 step:29760[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:6 step:29765[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:6 step:29770[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:6 step:29775[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:6 step:29780[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:6 step:29785[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:6 step:29790[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:6 step:29795[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:6 step:29800[D loss: 0.999976] [G loss: 1.000089]\n",
      "##############\n",
      "[2.67196352 2.21337267 2.17822758 3.81207966 1.56155133 7.44614243\n",
      " 2.45280688 3.72608896 3.85262329 5.81931569]\n",
      "##########\n",
      "epoch:6 step:29805[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:6 step:29810[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:6 step:29815[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:6 step:29820[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:6 step:29825[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:6 step:29830[D loss: 1.000005] [G loss: 1.000022]\n",
      "epoch:6 step:29835[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:6 step:29840[D loss: 1.000034] [G loss: 1.000046]\n",
      "epoch:6 step:29845[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:6 step:29850[D loss: 0.999983] [G loss: 1.000086]\n",
      "epoch:6 step:29855[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:6 step:29860[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:6 step:29865[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:6 step:29870[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:6 step:29875[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:6 step:29880[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:6 step:29885[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:6 step:29890[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:6 step:29895[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:6 step:29900[D loss: 1.000020] [G loss: 1.000022]\n",
      "epoch:6 step:29905[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:6 step:29910[D loss: 1.000008] [G loss: 1.000066]\n",
      "epoch:6 step:29915[D loss: 0.999944] [G loss: 1.000089]\n",
      "epoch:6 step:29920[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:6 step:29925[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:6 step:29930[D loss: 1.000015] [G loss: 1.000070]\n",
      "epoch:6 step:29935[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:6 step:29940[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:6 step:29945[D loss: 0.999988] [G loss: 1.000084]\n",
      "epoch:6 step:29950[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:6 step:29955[D loss: 1.000002] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:29960[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:6 step:29965[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:6 step:29970[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:6 step:29975[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:6 step:29980[D loss: 1.000017] [G loss: 1.000036]\n",
      "epoch:6 step:29985[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:6 step:29990[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:6 step:29995[D loss: 1.000024] [G loss: 1.000018]\n",
      "epoch:6 step:30000[D loss: 1.000057] [G loss: 0.999969]\n",
      "##############\n",
      "[2.78923994 2.18247173 2.23067999 4.04037935 1.59022081 7.45561175\n",
      " 2.58278806 3.99882366 3.99775029 8.14868929]\n",
      "##########\n",
      "epoch:6 step:30005[D loss: 0.999957] [G loss: 1.000066]\n",
      "epoch:6 step:30010[D loss: 0.999944] [G loss: 1.000077]\n",
      "epoch:6 step:30015[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:6 step:30020[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:6 step:30025[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:6 step:30030[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:6 step:30035[D loss: 1.000006] [G loss: 1.000057]\n",
      "epoch:6 step:30040[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:6 step:30045[D loss: 0.999987] [G loss: 1.000093]\n",
      "epoch:6 step:30050[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:6 step:30055[D loss: 1.000020] [G loss: 0.999979]\n",
      "epoch:6 step:30060[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:6 step:30065[D loss: 1.000011] [G loss: 1.000016]\n",
      "epoch:6 step:30070[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:6 step:30075[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:6 step:30080[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:6 step:30085[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:6 step:30090[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:6 step:30095[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:6 step:30100[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:6 step:30105[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:6 step:30110[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:6 step:30115[D loss: 0.999920] [G loss: 1.000155]\n",
      "epoch:6 step:30120[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:6 step:30125[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:6 step:30130[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:6 step:30135[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:6 step:30140[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:6 step:30145[D loss: 0.999989] [G loss: 1.000079]\n",
      "epoch:6 step:30150[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:6 step:30155[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:6 step:30160[D loss: 1.000024] [G loss: 1.000049]\n",
      "epoch:6 step:30165[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:6 step:30170[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:6 step:30175[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:6 step:30180[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:6 step:30185[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:6 step:30190[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:6 step:30195[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:6 step:30200[D loss: 0.999966] [G loss: 1.000092]\n",
      "##############\n",
      "[2.71704809 2.19965985 2.20693877 3.79301949 1.60942108 7.660681\n",
      " 2.62521429 3.99616756 3.91953432 4.67180711]\n",
      "##########\n",
      "epoch:6 step:30205[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:6 step:30210[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:6 step:30215[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:6 step:30220[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:6 step:30225[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:6 step:30230[D loss: 0.999966] [G loss: 1.000104]\n",
      "epoch:6 step:30235[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:6 step:30240[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:6 step:30245[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:6 step:30250[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:6 step:30255[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:6 step:30260[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:6 step:30265[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:6 step:30270[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:6 step:30275[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:6 step:30280[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:6 step:30285[D loss: 0.999993] [G loss: 1.000043]\n",
      "epoch:6 step:30290[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:6 step:30295[D loss: 1.000005] [G loss: 1.000015]\n",
      "epoch:6 step:30300[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:6 step:30305[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:6 step:30310[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:6 step:30315[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:6 step:30320[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:6 step:30325[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:6 step:30330[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:6 step:30335[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:6 step:30340[D loss: 1.000020] [G loss: 1.000010]\n",
      "epoch:6 step:30345[D loss: 0.999981] [G loss: 1.000094]\n",
      "epoch:6 step:30350[D loss: 0.999989] [G loss: 1.000083]\n",
      "epoch:6 step:30355[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:6 step:30360[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:6 step:30365[D loss: 1.000009] [G loss: 1.000039]\n",
      "epoch:6 step:30370[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:6 step:30375[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:6 step:30380[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:6 step:30385[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:6 step:30390[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:6 step:30395[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:6 step:30400[D loss: 0.999981] [G loss: 1.000087]\n",
      "##############\n",
      "[2.72211599 2.33506921 2.28599547 4.05136128 1.57922185 7.89889991\n",
      " 2.5667127  4.02558475 3.99849068 5.36716972]\n",
      "##########\n",
      "epoch:6 step:30405[D loss: 1.000072] [G loss: 0.999995]\n",
      "epoch:6 step:30410[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:6 step:30415[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:6 step:30420[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:6 step:30425[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:6 step:30430[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:6 step:30435[D loss: 1.000011] [G loss: 1.000000]\n",
      "epoch:6 step:30440[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:6 step:30445[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:6 step:30450[D loss: 0.999985] [G loss: 1.000100]\n",
      "epoch:6 step:30455[D loss: 0.999988] [G loss: 1.000089]\n",
      "epoch:6 step:30460[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:6 step:30465[D loss: 0.999948] [G loss: 1.000115]\n",
      "epoch:6 step:30470[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:6 step:30475[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:6 step:30480[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:6 step:30485[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:6 step:30490[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:6 step:30495[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:6 step:30500[D loss: 0.999968] [G loss: 1.000109]\n",
      "epoch:6 step:30505[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:6 step:30510[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:6 step:30515[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:6 step:30520[D loss: 0.999992] [G loss: 1.000021]\n",
      "epoch:6 step:30525[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:6 step:30530[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:6 step:30535[D loss: 0.999994] [G loss: 1.000063]\n",
      "epoch:6 step:30540[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:6 step:30545[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:6 step:30550[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:6 step:30555[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:6 step:30560[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:6 step:30565[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:6 step:30570[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:6 step:30575[D loss: 0.999982] [G loss: 1.000119]\n",
      "epoch:6 step:30580[D loss: 0.999963] [G loss: 1.000113]\n",
      "epoch:6 step:30585[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:6 step:30590[D loss: 1.000012] [G loss: 1.000077]\n",
      "epoch:6 step:30595[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:6 step:30600[D loss: 0.999968] [G loss: 1.000059]\n",
      "##############\n",
      "[2.77697852 2.22238483 2.22310276 3.82505239 1.63911273 7.24619756\n",
      " 2.56072433 3.64701067 3.96666867 5.19185683]\n",
      "##########\n",
      "epoch:6 step:30605[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:6 step:30610[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:6 step:30615[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:6 step:30620[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:6 step:30625[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:6 step:30630[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:6 step:30635[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:6 step:30640[D loss: 0.999973] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:30645[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:6 step:30650[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:6 step:30655[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:6 step:30660[D loss: 0.999985] [G loss: 1.000113]\n",
      "epoch:6 step:30665[D loss: 0.999925] [G loss: 1.000127]\n",
      "epoch:6 step:30670[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:6 step:30675[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:6 step:30680[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:6 step:30685[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:6 step:30690[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:6 step:30695[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:6 step:30700[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:30705[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:6 step:30710[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:6 step:30715[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:6 step:30720[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:6 step:30725[D loss: 1.000001] [G loss: 1.000008]\n",
      "epoch:6 step:30730[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:6 step:30735[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:6 step:30740[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:6 step:30745[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:6 step:30750[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:6 step:30755[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:6 step:30760[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:6 step:30765[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:6 step:30770[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:6 step:30775[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:6 step:30780[D loss: 0.999961] [G loss: 1.000108]\n",
      "epoch:6 step:30785[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:6 step:30790[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:6 step:30795[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:6 step:30800[D loss: 0.999993] [G loss: 1.000055]\n",
      "##############\n",
      "[2.7328498  2.26827875 2.2707421  3.98445913 1.6079459  7.51791339\n",
      " 2.48352541 3.75941927 3.93001112 4.72945978]\n",
      "##########\n",
      "epoch:6 step:30805[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:6 step:30810[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:6 step:30815[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:6 step:30820[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:6 step:30825[D loss: 0.999951] [G loss: 1.000132]\n",
      "epoch:6 step:30830[D loss: 1.000007] [G loss: 1.000059]\n",
      "epoch:6 step:30835[D loss: 1.000000] [G loss: 1.000044]\n",
      "epoch:6 step:30840[D loss: 0.999962] [G loss: 1.000116]\n",
      "epoch:6 step:30845[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:6 step:30850[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:6 step:30855[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:6 step:30860[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:6 step:30865[D loss: 0.999999] [G loss: 1.000054]\n",
      "epoch:6 step:30870[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:30875[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:6 step:30880[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:6 step:30885[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:6 step:30890[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:6 step:30895[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:6 step:30900[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:6 step:30905[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:6 step:30910[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:6 step:30915[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:6 step:30920[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:6 step:30925[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:6 step:30930[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:6 step:30935[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:6 step:30940[D loss: 1.000013] [G loss: 1.000007]\n",
      "epoch:6 step:30945[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:6 step:30950[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:30955[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:6 step:30960[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:6 step:30965[D loss: 1.000002] [G loss: 1.000042]\n",
      "epoch:6 step:30970[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:6 step:30975[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:6 step:30980[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:6 step:30985[D loss: 0.999995] [G loss: 1.000081]\n",
      "epoch:6 step:30990[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:6 step:30995[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:6 step:31000[D loss: 0.999969] [G loss: 1.000090]\n",
      "##############\n",
      "[2.69035606 2.21713945 2.27191221 3.93960228 1.52643057 7.15575786\n",
      " 2.46993855 3.89472263 3.97084997 5.18156633]\n",
      "##########\n",
      "epoch:6 step:31005[D loss: 1.000003] [G loss: 1.000013]\n",
      "epoch:6 step:31010[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:6 step:31015[D loss: 1.000023] [G loss: 0.999995]\n",
      "epoch:6 step:31020[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:6 step:31025[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:6 step:31030[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:6 step:31035[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:6 step:31040[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:6 step:31045[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:6 step:31050[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:6 step:31055[D loss: 1.000018] [G loss: 1.000065]\n",
      "epoch:6 step:31060[D loss: 0.999995] [G loss: 1.000025]\n",
      "epoch:6 step:31065[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:6 step:31070[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:6 step:31075[D loss: 1.000007] [G loss: 1.000072]\n",
      "epoch:6 step:31080[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:6 step:31085[D loss: 1.000025] [G loss: 1.000068]\n",
      "epoch:6 step:31090[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:6 step:31095[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:6 step:31100[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:6 step:31105[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:6 step:31110[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:6 step:31115[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:6 step:31120[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:6 step:31125[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:6 step:31130[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:6 step:31135[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:6 step:31140[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:6 step:31145[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:6 step:31150[D loss: 0.999953] [G loss: 1.000125]\n",
      "epoch:6 step:31155[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:6 step:31160[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:6 step:31165[D loss: 0.999959] [G loss: 1.000091]\n",
      "epoch:6 step:31170[D loss: 1.000010] [G loss: 1.000027]\n",
      "epoch:6 step:31175[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:6 step:31180[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:6 step:31185[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:6 step:31190[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:6 step:31195[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:6 step:31200[D loss: 0.999991] [G loss: 1.000033]\n",
      "##############\n",
      "[2.75392321 2.28003621 2.25015324 3.83226763 1.60758219 7.76368583\n",
      " 2.61583839 3.89965698 3.96322649 5.745939  ]\n",
      "##########\n",
      "epoch:6 step:31205[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:6 step:31210[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:6 step:31215[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:6 step:31220[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:6 step:31225[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:6 step:31230[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:6 step:31235[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:6 step:31240[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:6 step:31245[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:6 step:31250[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:6 step:31255[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:6 step:31260[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:6 step:31265[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:6 step:31270[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:6 step:31275[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:6 step:31280[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:31285[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:6 step:31290[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:6 step:31295[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:6 step:31300[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:6 step:31305[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:6 step:31310[D loss: 0.999967] [G loss: 1.000104]\n",
      "epoch:6 step:31315[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:6 step:31320[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:6 step:31325[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:6 step:31330[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:6 step:31335[D loss: 0.999992] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:31340[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:6 step:31345[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:6 step:31350[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:6 step:31355[D loss: 0.999983] [G loss: 1.000092]\n",
      "epoch:6 step:31360[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:6 step:31365[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:6 step:31370[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:6 step:31375[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:6 step:31380[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:6 step:31385[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:6 step:31390[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:6 step:31395[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:6 step:31400[D loss: 1.000001] [G loss: 1.000040]\n",
      "##############\n",
      "[2.73454211 2.25973052 2.12445421 3.98185686 1.60368268 7.65072274\n",
      " 2.43589781 3.90961354 3.9410623  5.54847353]\n",
      "##########\n",
      "epoch:6 step:31405[D loss: 1.000005] [G loss: 1.000061]\n",
      "epoch:6 step:31410[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:6 step:31415[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:6 step:31420[D loss: 1.000008] [G loss: 1.000093]\n",
      "epoch:6 step:31425[D loss: 1.000005] [G loss: 1.000077]\n",
      "epoch:6 step:31430[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:6 step:31435[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:6 step:31440[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:6 step:31445[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:6 step:31450[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:6 step:31455[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:6 step:31460[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:6 step:31465[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:6 step:31470[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:6 step:31475[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:6 step:31480[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:6 step:31485[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:6 step:31490[D loss: 0.999996] [G loss: 1.000051]\n",
      "epoch:6 step:31495[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:6 step:31500[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:6 step:31505[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:6 step:31510[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:6 step:31515[D loss: 1.000009] [G loss: 0.999994]\n",
      "epoch:6 step:31520[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:6 step:31525[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:6 step:31530[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:6 step:31535[D loss: 0.999958] [G loss: 1.000118]\n",
      "epoch:6 step:31540[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:6 step:31545[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:6 step:31550[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:6 step:31555[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:6 step:31560[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:6 step:31565[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:6 step:31570[D loss: 0.999964] [G loss: 1.000115]\n",
      "epoch:6 step:31575[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:6 step:31580[D loss: 1.000006] [G loss: 0.999995]\n",
      "epoch:6 step:31585[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:6 step:31590[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:6 step:31595[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:6 step:31600[D loss: 0.999998] [G loss: 1.000057]\n",
      "##############\n",
      "[2.69940814 2.13634196 2.08564884 3.99336739 1.52007701 7.40018439\n",
      " 2.35779956 3.95865493 3.85680927 5.3032    ]\n",
      "##########\n",
      "epoch:6 step:31605[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:6 step:31610[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:6 step:31615[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:6 step:31620[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:6 step:31625[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:6 step:31630[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:6 step:31635[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:6 step:31640[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:6 step:31645[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:6 step:31650[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:6 step:31655[D loss: 1.000004] [G loss: 1.000004]\n",
      "epoch:6 step:31660[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:6 step:31665[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:6 step:31670[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:6 step:31675[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:6 step:31680[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:6 step:31685[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:6 step:31690[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:6 step:31695[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:6 step:31700[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:6 step:31705[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:6 step:31710[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:6 step:31715[D loss: 1.000004] [G loss: 1.000054]\n",
      "epoch:6 step:31720[D loss: 1.000011] [G loss: 1.000021]\n",
      "epoch:6 step:31725[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:6 step:31730[D loss: 0.999998] [G loss: 1.000073]\n",
      "epoch:6 step:31735[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:6 step:31740[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:6 step:31745[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:6 step:31750[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:6 step:31755[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:6 step:31760[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:6 step:31765[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:6 step:31770[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:6 step:31775[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:6 step:31780[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:6 step:31785[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:6 step:31790[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:6 step:31795[D loss: 1.000018] [G loss: 1.000031]\n",
      "epoch:6 step:31800[D loss: 0.999985] [G loss: 1.000039]\n",
      "##############\n",
      "[2.75914871 2.3059587  2.3168565  3.71956476 1.61956446 7.87537467\n",
      " 2.58872256 3.96275843 4.04469222 5.35391907]\n",
      "##########\n",
      "epoch:6 step:31805[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:6 step:31810[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:6 step:31815[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:6 step:31820[D loss: 1.000011] [G loss: 1.000048]\n",
      "epoch:6 step:31825[D loss: 0.999957] [G loss: 1.000045]\n",
      "epoch:6 step:31830[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:6 step:31835[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:6 step:31840[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:6 step:31845[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:6 step:31850[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:6 step:31855[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:6 step:31860[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:6 step:31865[D loss: 1.000018] [G loss: 0.999993]\n",
      "epoch:6 step:31870[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:6 step:31875[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:6 step:31880[D loss: 1.000014] [G loss: 1.000039]\n",
      "epoch:6 step:31885[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:6 step:31890[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:6 step:31895[D loss: 0.999970] [G loss: 1.000039]\n",
      "epoch:6 step:31900[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:6 step:31905[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:6 step:31910[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:6 step:31915[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:6 step:31920[D loss: 0.999989] [G loss: 1.000089]\n",
      "epoch:6 step:31925[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:6 step:31930[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:6 step:31935[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:6 step:31940[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:6 step:31945[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:6 step:31950[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:6 step:31955[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:6 step:31960[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:6 step:31965[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:6 step:31970[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:6 step:31975[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:6 step:31980[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:6 step:31985[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:6 step:31990[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:6 step:31995[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:6 step:32000[D loss: 0.999970] [G loss: 1.000085]\n",
      "##############\n",
      "[2.64801881 2.31173848 2.31562005 3.90758293 1.47765665 7.37382207\n",
      " 2.47386809 3.83828632 3.89644687 4.92589547]\n",
      "##########\n",
      "epoch:6 step:32005[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:32010[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:6 step:32015[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:6 step:32020[D loss: 0.999981] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:32025[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:6 step:32030[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:6 step:32035[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:6 step:32040[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:6 step:32045[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:6 step:32050[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:6 step:32055[D loss: 1.000007] [G loss: 1.000079]\n",
      "epoch:6 step:32060[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:6 step:32065[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:6 step:32070[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:6 step:32075[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:6 step:32080[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:6 step:32085[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:6 step:32090[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:6 step:32095[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:6 step:32100[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:6 step:32105[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:6 step:32110[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:6 step:32115[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:32120[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:6 step:32125[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:6 step:32130[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:6 step:32135[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:6 step:32140[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:6 step:32145[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:6 step:32150[D loss: 0.999981] [G loss: 1.000091]\n",
      "epoch:6 step:32155[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:32160[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:6 step:32165[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:6 step:32170[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:6 step:32175[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:6 step:32180[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:6 step:32185[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:6 step:32190[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:6 step:32195[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:6 step:32200[D loss: 0.999988] [G loss: 1.000070]\n",
      "##############\n",
      "[2.67472746 2.11523821 2.135893   3.75845894 1.51365326 7.19763231\n",
      " 2.3778862  3.77261523 3.87628284 5.21142699]\n",
      "##########\n",
      "epoch:6 step:32205[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:6 step:32210[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:6 step:32215[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:6 step:32220[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:6 step:32225[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:6 step:32230[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:6 step:32235[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:6 step:32240[D loss: 0.999995] [G loss: 1.000030]\n",
      "epoch:6 step:32245[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:6 step:32250[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:6 step:32255[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:6 step:32260[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:6 step:32265[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:6 step:32270[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:6 step:32275[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:6 step:32280[D loss: 1.000027] [G loss: 1.000034]\n",
      "epoch:6 step:32285[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:32290[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:32295[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:6 step:32300[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:6 step:32305[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:6 step:32310[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:6 step:32315[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:6 step:32320[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:6 step:32325[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:6 step:32330[D loss: 1.000003] [G loss: 1.000079]\n",
      "epoch:6 step:32335[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:6 step:32340[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:6 step:32345[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:6 step:32350[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:6 step:32355[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:6 step:32360[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:6 step:32365[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:6 step:32370[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:32375[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:6 step:32380[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:32385[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:6 step:32390[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:6 step:32395[D loss: 0.999960] [G loss: 1.000123]\n",
      "epoch:6 step:32400[D loss: 0.999976] [G loss: 1.000052]\n",
      "##############\n",
      "[2.64683013 2.12326117 2.21576952 3.86368477 1.5006612  7.19580482\n",
      " 2.4336474  3.81319023 3.91271655 5.60274436]\n",
      "##########\n",
      "epoch:6 step:32405[D loss: 1.000009] [G loss: 1.000066]\n",
      "epoch:6 step:32410[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:6 step:32415[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:6 step:32420[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:6 step:32425[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:6 step:32430[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:6 step:32435[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:6 step:32440[D loss: 0.999955] [G loss: 1.000108]\n",
      "epoch:6 step:32445[D loss: 1.000013] [G loss: 1.000016]\n",
      "epoch:6 step:32450[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:6 step:32455[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:6 step:32460[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:6 step:32465[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:6 step:32470[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:6 step:32475[D loss: 0.999969] [G loss: 1.000042]\n",
      "epoch:6 step:32480[D loss: 1.000011] [G loss: 1.000023]\n",
      "epoch:6 step:32485[D loss: 1.000005] [G loss: 1.000058]\n",
      "epoch:6 step:32490[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:6 step:32495[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:6 step:32500[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:6 step:32505[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:6 step:32510[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:6 step:32515[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:6 step:32520[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:6 step:32525[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:6 step:32530[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:6 step:32535[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:6 step:32540[D loss: 0.999948] [G loss: 1.000109]\n",
      "epoch:6 step:32545[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:6 step:32550[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:6 step:32555[D loss: 1.000016] [G loss: 1.000035]\n",
      "epoch:6 step:32560[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:6 step:32565[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:6 step:32570[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:6 step:32575[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:6 step:32580[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:6 step:32585[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:6 step:32590[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:6 step:32595[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:6 step:32600[D loss: 0.999964] [G loss: 1.000075]\n",
      "##############\n",
      "[2.68729704 2.11665272 2.16990897 3.9367822  1.58381183 7.46554312\n",
      " 2.49815015 3.95581203 3.92237713 5.30121686]\n",
      "##########\n",
      "epoch:6 step:32605[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:6 step:32610[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:6 step:32615[D loss: 1.000039] [G loss: 0.999998]\n",
      "epoch:6 step:32620[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:6 step:32625[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:6 step:32630[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:6 step:32635[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:6 step:32640[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:6 step:32645[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:6 step:32650[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:6 step:32655[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:6 step:32660[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:6 step:32665[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:6 step:32670[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:6 step:32675[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:6 step:32680[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:6 step:32685[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:6 step:32690[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:6 step:32695[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:6 step:32700[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:6 step:32705[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:6 step:32710[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:6 step:32715[D loss: 0.999975] [G loss: 1.000101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:32720[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:6 step:32725[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:6 step:32730[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:6 step:32735[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:6 step:32740[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:6 step:32745[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:6 step:32750[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:6 step:32755[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:6 step:32760[D loss: 0.999969] [G loss: 1.000096]\n",
      "epoch:6 step:32765[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:6 step:32770[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:6 step:32775[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:6 step:32780[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:6 step:32785[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:6 step:32790[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:6 step:32795[D loss: 0.999971] [G loss: 1.000117]\n",
      "epoch:7 step:32800[D loss: 1.000006] [G loss: 1.000035]\n",
      "##############\n",
      "[2.62200889 2.09951803 2.18058847 3.84148383 1.46154356 7.15288734\n",
      " 2.49850169 3.85316126 3.87536359 5.04132315]\n",
      "##########\n",
      "epoch:7 step:32805[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:7 step:32810[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:7 step:32815[D loss: 0.999984] [G loss: 1.000028]\n",
      "epoch:7 step:32820[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:7 step:32825[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:7 step:32830[D loss: 0.999998] [G loss: 1.000068]\n",
      "epoch:7 step:32835[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:7 step:32840[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:7 step:32845[D loss: 1.000071] [G loss: 0.999977]\n",
      "epoch:7 step:32850[D loss: 1.000008] [G loss: 1.000047]\n",
      "epoch:7 step:32855[D loss: 0.999954] [G loss: 1.000075]\n",
      "epoch:7 step:32860[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:7 step:32865[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:7 step:32870[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:7 step:32875[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:7 step:32880[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:7 step:32885[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:7 step:32890[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:7 step:32895[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:7 step:32900[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:7 step:32905[D loss: 1.000011] [G loss: 1.000029]\n",
      "epoch:7 step:32910[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:7 step:32915[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:7 step:32920[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:7 step:32925[D loss: 0.999993] [G loss: 1.000076]\n",
      "epoch:7 step:32930[D loss: 0.999992] [G loss: 1.000093]\n",
      "epoch:7 step:32935[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:7 step:32940[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:7 step:32945[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:7 step:32950[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:7 step:32955[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:7 step:32960[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:7 step:32965[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:7 step:32970[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:7 step:32975[D loss: 0.999989] [G loss: 1.000081]\n",
      "epoch:7 step:32980[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:7 step:32985[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:7 step:32990[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:32995[D loss: 1.000009] [G loss: 1.000013]\n",
      "epoch:7 step:33000[D loss: 0.999967] [G loss: 1.000120]\n",
      "##############\n",
      "[2.68455262 2.14736294 2.19392171 3.9106146  1.54526217 7.46172577\n",
      " 2.31832145 4.00058056 3.89494714 5.11496588]\n",
      "##########\n",
      "epoch:7 step:33005[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:7 step:33010[D loss: 1.000018] [G loss: 0.999956]\n",
      "epoch:7 step:33015[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:7 step:33020[D loss: 0.999971] [G loss: 1.000096]\n",
      "epoch:7 step:33025[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:7 step:33030[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:7 step:33035[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:7 step:33040[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:7 step:33045[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:7 step:33050[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:7 step:33055[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:7 step:33060[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:7 step:33065[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:7 step:33070[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:7 step:33075[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:7 step:33080[D loss: 0.999995] [G loss: 1.000074]\n",
      "epoch:7 step:33085[D loss: 0.999950] [G loss: 1.000111]\n",
      "epoch:7 step:33090[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:7 step:33095[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:7 step:33100[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:7 step:33105[D loss: 1.000022] [G loss: 0.999991]\n",
      "epoch:7 step:33110[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:7 step:33115[D loss: 1.000009] [G loss: 1.000069]\n",
      "epoch:7 step:33120[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:7 step:33125[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:7 step:33130[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:7 step:33135[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:7 step:33140[D loss: 1.000060] [G loss: 1.000008]\n",
      "epoch:7 step:33145[D loss: 1.000000] [G loss: 1.000020]\n",
      "epoch:7 step:33150[D loss: 1.000006] [G loss: 1.000012]\n",
      "epoch:7 step:33155[D loss: 1.000053] [G loss: 0.999992]\n",
      "epoch:7 step:33160[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:7 step:33165[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:7 step:33170[D loss: 0.999999] [G loss: 1.000029]\n",
      "epoch:7 step:33175[D loss: 1.000000] [G loss: 0.999972]\n",
      "epoch:7 step:33180[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:7 step:33185[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:7 step:33190[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:7 step:33195[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:7 step:33200[D loss: 1.000012] [G loss: 1.000049]\n",
      "##############\n",
      "[2.62010032 2.19338216 2.14807249 3.71742384 1.44977063 7.12189079\n",
      " 2.51624092 3.84837389 3.84802021 4.98562764]\n",
      "##########\n",
      "epoch:7 step:33205[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:7 step:33210[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:7 step:33215[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:7 step:33220[D loss: 1.000005] [G loss: 1.000037]\n",
      "epoch:7 step:33225[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:7 step:33230[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:7 step:33235[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:7 step:33240[D loss: 0.999969] [G loss: 1.000137]\n",
      "epoch:7 step:33245[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:7 step:33250[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:7 step:33255[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:7 step:33260[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:7 step:33265[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:7 step:33270[D loss: 1.000013] [G loss: 1.000058]\n",
      "epoch:7 step:33275[D loss: 0.999978] [G loss: 1.000113]\n",
      "epoch:7 step:33280[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:7 step:33285[D loss: 1.000003] [G loss: 1.000016]\n",
      "epoch:7 step:33290[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:7 step:33295[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:7 step:33300[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:7 step:33305[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:7 step:33310[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:7 step:33315[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:7 step:33320[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:7 step:33325[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:7 step:33330[D loss: 1.000029] [G loss: 0.999978]\n",
      "epoch:7 step:33335[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:7 step:33340[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:7 step:33345[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:7 step:33350[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:7 step:33355[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:7 step:33360[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:7 step:33365[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:7 step:33370[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:7 step:33375[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:7 step:33380[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:7 step:33385[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:7 step:33390[D loss: 1.000010] [G loss: 1.000033]\n",
      "epoch:7 step:33395[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:7 step:33400[D loss: 0.999962] [G loss: 1.000095]\n",
      "##############\n",
      "[2.63434147 2.21086071 2.16867061 3.7313373  1.51823109 7.66219944\n",
      " 2.51701282 3.89174475 3.84028608 5.68636705]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:33405[D loss: 0.999962] [G loss: 1.000116]\n",
      "epoch:7 step:33410[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:7 step:33415[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:7 step:33420[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:7 step:33425[D loss: 0.999976] [G loss: 1.000034]\n",
      "epoch:7 step:33430[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:7 step:33435[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:7 step:33440[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:7 step:33445[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:7 step:33450[D loss: 0.999958] [G loss: 1.000106]\n",
      "epoch:7 step:33455[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:7 step:33460[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:7 step:33465[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:7 step:33470[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:7 step:33475[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:7 step:33480[D loss: 0.999999] [G loss: 1.000055]\n",
      "epoch:7 step:33485[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:7 step:33490[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:7 step:33495[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:7 step:33500[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:7 step:33505[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:7 step:33510[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:7 step:33515[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:7 step:33520[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:7 step:33525[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:7 step:33530[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:7 step:33535[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:7 step:33540[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:7 step:33545[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:7 step:33550[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:7 step:33555[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:7 step:33560[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:7 step:33565[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:7 step:33570[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:7 step:33575[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:7 step:33580[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:7 step:33585[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:7 step:33590[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:7 step:33595[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:7 step:33600[D loss: 0.999980] [G loss: 1.000062]\n",
      "##############\n",
      "[2.6370565  2.17389827 2.15717623 3.59596356 1.52870691 8.04134124\n",
      " 2.49278142 3.97231258 3.8594098  5.30076025]\n",
      "##########\n",
      "epoch:7 step:33605[D loss: 1.000027] [G loss: 0.999990]\n",
      "epoch:7 step:33610[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:7 step:33615[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:7 step:33620[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:7 step:33625[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:7 step:33630[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:7 step:33635[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:7 step:33640[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:7 step:33645[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:7 step:33650[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:7 step:33655[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:7 step:33660[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:7 step:33665[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:7 step:33670[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:7 step:33675[D loss: 0.999970] [G loss: 1.000096]\n",
      "epoch:7 step:33680[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:7 step:33685[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:7 step:33690[D loss: 1.000002] [G loss: 1.000066]\n",
      "epoch:7 step:33695[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:7 step:33700[D loss: 0.999961] [G loss: 1.000115]\n",
      "epoch:7 step:33705[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:7 step:33710[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:7 step:33715[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:7 step:33720[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:7 step:33725[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:7 step:33730[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:7 step:33735[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:7 step:33740[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:7 step:33745[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:7 step:33750[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:7 step:33755[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:7 step:33760[D loss: 0.999969] [G loss: 1.000105]\n",
      "epoch:7 step:33765[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:7 step:33770[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:7 step:33775[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:7 step:33780[D loss: 0.999997] [G loss: 1.000018]\n",
      "epoch:7 step:33785[D loss: 1.000025] [G loss: 0.999997]\n",
      "epoch:7 step:33790[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:7 step:33795[D loss: 0.999997] [G loss: 1.000070]\n",
      "epoch:7 step:33800[D loss: 0.999985] [G loss: 1.000055]\n",
      "##############\n",
      "[2.7306635  2.09363063 2.17283903 3.90653589 1.56198527 7.33990382\n",
      " 2.60128078 3.96042729 3.94985297 5.0612066 ]\n",
      "##########\n",
      "epoch:7 step:33805[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:7 step:33810[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:7 step:33815[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:7 step:33820[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:7 step:33825[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:7 step:33830[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:7 step:33835[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:7 step:33840[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:7 step:33845[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:7 step:33850[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:7 step:33855[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:7 step:33860[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:7 step:33865[D loss: 0.999993] [G loss: 1.000077]\n",
      "epoch:7 step:33870[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:7 step:33875[D loss: 0.999984] [G loss: 1.000086]\n",
      "epoch:7 step:33880[D loss: 1.000000] [G loss: 1.000123]\n",
      "epoch:7 step:33885[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:7 step:33890[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:7 step:33895[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:7 step:33900[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:7 step:33905[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:7 step:33910[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:7 step:33915[D loss: 0.999940] [G loss: 1.000100]\n",
      "epoch:7 step:33920[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:7 step:33925[D loss: 1.000010] [G loss: 1.000049]\n",
      "epoch:7 step:33930[D loss: 1.000006] [G loss: 1.000067]\n",
      "epoch:7 step:33935[D loss: 0.999957] [G loss: 1.000104]\n",
      "epoch:7 step:33940[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:7 step:33945[D loss: 0.999988] [G loss: 1.000099]\n",
      "epoch:7 step:33950[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:7 step:33955[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:7 step:33960[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:7 step:33965[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:7 step:33970[D loss: 0.999959] [G loss: 1.000132]\n",
      "epoch:7 step:33975[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:7 step:33980[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:7 step:33985[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:7 step:33990[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:7 step:33995[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:7 step:34000[D loss: 1.000025] [G loss: 1.000000]\n",
      "##############\n",
      "[2.65703858 2.14769522 2.2235199  3.8073203  1.49805026 7.26529907\n",
      " 2.48520413 3.76796991 3.9941771  5.17972643]\n",
      "##########\n",
      "epoch:7 step:34005[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:7 step:34010[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:7 step:34015[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:7 step:34020[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:7 step:34025[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:7 step:34030[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:7 step:34035[D loss: 0.999995] [G loss: 1.000095]\n",
      "epoch:7 step:34040[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:7 step:34045[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:7 step:34050[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:7 step:34055[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:7 step:34060[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:7 step:34065[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:7 step:34070[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:7 step:34075[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:7 step:34080[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:7 step:34085[D loss: 1.000020] [G loss: 1.000021]\n",
      "epoch:7 step:34090[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:7 step:34095[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:7 step:34100[D loss: 0.999994] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:34105[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:7 step:34110[D loss: 1.000053] [G loss: 1.000014]\n",
      "epoch:7 step:34115[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:7 step:34120[D loss: 0.999943] [G loss: 1.000093]\n",
      "epoch:7 step:34125[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:7 step:34130[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:34135[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:7 step:34140[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:7 step:34145[D loss: 1.000026] [G loss: 0.999946]\n",
      "epoch:7 step:34150[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:7 step:34155[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:7 step:34160[D loss: 0.999993] [G loss: 1.000037]\n",
      "epoch:7 step:34165[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:7 step:34170[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:7 step:34175[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:7 step:34180[D loss: 0.999951] [G loss: 1.000082]\n",
      "epoch:7 step:34185[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:7 step:34190[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:7 step:34195[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:7 step:34200[D loss: 0.999979] [G loss: 1.000053]\n",
      "##############\n",
      "[2.60184118 2.13004357 2.18732737 3.52935723 1.48202445 7.26242575\n",
      " 2.37856025 3.70023294 3.93414118 5.05708267]\n",
      "##########\n",
      "epoch:7 step:34205[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:7 step:34210[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:7 step:34215[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:7 step:34220[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:7 step:34225[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:7 step:34230[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:7 step:34235[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:7 step:34240[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:7 step:34245[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:7 step:34250[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:7 step:34255[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:7 step:34260[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:7 step:34265[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:7 step:34270[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:7 step:34275[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:7 step:34280[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:7 step:34285[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:7 step:34290[D loss: 0.999934] [G loss: 1.000093]\n",
      "epoch:7 step:34295[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:7 step:34300[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:7 step:34305[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:7 step:34310[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:7 step:34315[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:7 step:34320[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:7 step:34325[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:7 step:34330[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:7 step:34335[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:7 step:34340[D loss: 1.000054] [G loss: 0.999994]\n",
      "epoch:7 step:34345[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:7 step:34350[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:7 step:34355[D loss: 0.999947] [G loss: 1.000082]\n",
      "epoch:7 step:34360[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:7 step:34365[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:7 step:34370[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:7 step:34375[D loss: 1.000013] [G loss: 1.000066]\n",
      "epoch:7 step:34380[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:7 step:34385[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:7 step:34390[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:7 step:34395[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:7 step:34400[D loss: 1.000045] [G loss: 1.000010]\n",
      "##############\n",
      "[2.62864508 2.22461152 2.18735666 3.77736588 1.48055562 6.92164288\n",
      " 2.62649263 3.67463903 3.86686163 4.98456098]\n",
      "##########\n",
      "epoch:7 step:34405[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:7 step:34410[D loss: 1.000005] [G loss: 1.000044]\n",
      "epoch:7 step:34415[D loss: 0.999969] [G loss: 1.000038]\n",
      "epoch:7 step:34420[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:7 step:34425[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:7 step:34430[D loss: 0.999998] [G loss: 1.000028]\n",
      "epoch:7 step:34435[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:7 step:34440[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:7 step:34445[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:7 step:34450[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:7 step:34455[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:7 step:34460[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:7 step:34465[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:7 step:34470[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:7 step:34475[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:7 step:34480[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:7 step:34485[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:7 step:34490[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:7 step:34495[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:7 step:34500[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:7 step:34505[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:7 step:34510[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:7 step:34515[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:7 step:34520[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:34525[D loss: 1.000058] [G loss: 1.000005]\n",
      "epoch:7 step:34530[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:7 step:34535[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:7 step:34540[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:7 step:34545[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:7 step:34550[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:7 step:34555[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:7 step:34560[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:7 step:34565[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:7 step:34570[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:7 step:34575[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:7 step:34580[D loss: 0.999950] [G loss: 1.000093]\n",
      "epoch:7 step:34585[D loss: 1.000013] [G loss: 1.000047]\n",
      "epoch:7 step:34590[D loss: 0.999946] [G loss: 1.000063]\n",
      "epoch:7 step:34595[D loss: 1.000004] [G loss: 1.000068]\n",
      "epoch:7 step:34600[D loss: 0.999976] [G loss: 1.000049]\n",
      "##############\n",
      "[2.70086144 2.11631457 2.24762495 4.0842134  1.48297447 9.27426719\n",
      " 2.43065425 3.90482909 3.91519383 5.37679114]\n",
      "##########\n",
      "epoch:7 step:34605[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:7 step:34610[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:7 step:34615[D loss: 1.000040] [G loss: 1.000003]\n",
      "epoch:7 step:34620[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:7 step:34625[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:7 step:34630[D loss: 1.000003] [G loss: 1.000060]\n",
      "epoch:7 step:34635[D loss: 0.999963] [G loss: 1.000097]\n",
      "epoch:7 step:34640[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:7 step:34645[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:7 step:34650[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:7 step:34655[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:7 step:34660[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:7 step:34665[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:7 step:34670[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:7 step:34675[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:7 step:34680[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:7 step:34685[D loss: 1.000043] [G loss: 1.000004]\n",
      "epoch:7 step:34690[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:7 step:34695[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:7 step:34700[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:7 step:34705[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:7 step:34710[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:7 step:34715[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:7 step:34720[D loss: 1.000004] [G loss: 1.000067]\n",
      "epoch:7 step:34725[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:7 step:34730[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:7 step:34735[D loss: 1.000012] [G loss: 1.000033]\n",
      "epoch:7 step:34740[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:7 step:34745[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:7 step:34750[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:7 step:34755[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:7 step:34760[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:7 step:34765[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:7 step:34770[D loss: 0.999992] [G loss: 1.000004]\n",
      "epoch:7 step:34775[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:7 step:34780[D loss: 0.999999] [G loss: 1.000054]\n",
      "epoch:7 step:34785[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:7 step:34790[D loss: 0.999961] [G loss: 1.000112]\n",
      "epoch:7 step:34795[D loss: 1.000001] [G loss: 1.000015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:34800[D loss: 0.999983] [G loss: 1.000064]\n",
      "##############\n",
      "[2.65449857 2.14774171 2.18717592 3.60388605 1.45579204 6.05978679\n",
      " 2.45458062 4.00499393 3.91755522 7.14868929]\n",
      "##########\n",
      "epoch:7 step:34805[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:7 step:34810[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:7 step:34815[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:7 step:34820[D loss: 0.999997] [G loss: 1.000026]\n",
      "epoch:7 step:34825[D loss: 0.999993] [G loss: 1.000002]\n",
      "epoch:7 step:34830[D loss: 1.000008] [G loss: 1.000064]\n",
      "epoch:7 step:34835[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:7 step:34840[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:7 step:34845[D loss: 1.000016] [G loss: 1.000039]\n",
      "epoch:7 step:34850[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:7 step:34855[D loss: 1.000056] [G loss: 0.999981]\n",
      "epoch:7 step:34860[D loss: 0.999931] [G loss: 1.000123]\n",
      "epoch:7 step:34865[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:7 step:34870[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:7 step:34875[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:7 step:34880[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:34885[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:7 step:34890[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:7 step:34895[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:7 step:34900[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:7 step:34905[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:7 step:34910[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:7 step:34915[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:7 step:34920[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:7 step:34925[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:7 step:34930[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:7 step:34935[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:7 step:34940[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:7 step:34945[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:7 step:34950[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:7 step:34955[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:7 step:34960[D loss: 0.999998] [G loss: 1.000006]\n",
      "epoch:7 step:34965[D loss: 0.999968] [G loss: 1.000097]\n",
      "epoch:7 step:34970[D loss: 0.999935] [G loss: 1.000140]\n",
      "epoch:7 step:34975[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:7 step:34980[D loss: 1.000013] [G loss: 0.999995]\n",
      "epoch:7 step:34985[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:7 step:34990[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:7 step:34995[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:7 step:35000[D loss: 0.999973] [G loss: 1.000084]\n",
      "##############\n",
      "[2.64348056 2.15667938 2.2427414  3.84215859 1.54382917 8.13538847\n",
      " 2.45098694 3.95166029 4.02320256 5.49966671]\n",
      "##########\n",
      "epoch:7 step:35005[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:7 step:35010[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:7 step:35015[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:7 step:35020[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:7 step:35025[D loss: 1.000009] [G loss: 1.000017]\n",
      "epoch:7 step:35030[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:7 step:35035[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:7 step:35040[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:7 step:35045[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:7 step:35050[D loss: 1.000015] [G loss: 1.000027]\n",
      "epoch:7 step:35055[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:7 step:35060[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:7 step:35065[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:7 step:35070[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:7 step:35075[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:7 step:35080[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:7 step:35085[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:7 step:35090[D loss: 1.000085] [G loss: 0.999996]\n",
      "epoch:7 step:35095[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:7 step:35100[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:7 step:35105[D loss: 1.000011] [G loss: 0.999992]\n",
      "epoch:7 step:35110[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:7 step:35115[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:7 step:35120[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:7 step:35125[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:7 step:35130[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:7 step:35135[D loss: 1.000000] [G loss: 1.000091]\n",
      "epoch:7 step:35140[D loss: 0.999979] [G loss: 1.000155]\n",
      "epoch:7 step:35145[D loss: 0.999967] [G loss: 1.000107]\n",
      "epoch:7 step:35150[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:7 step:35155[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:7 step:35160[D loss: 1.000009] [G loss: 1.000032]\n",
      "epoch:7 step:35165[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:7 step:35170[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:7 step:35175[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:7 step:35180[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:7 step:35185[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:7 step:35190[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:7 step:35195[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:7 step:35200[D loss: 0.999963] [G loss: 1.000079]\n",
      "##############\n",
      "[2.59933643 2.17162826 2.1160352  3.8695185  1.44762378 6.87760948\n",
      " 2.31541417 3.61743926 3.8661057  4.90142776]\n",
      "##########\n",
      "epoch:7 step:35205[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:7 step:35210[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:7 step:35215[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:7 step:35220[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:7 step:35225[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:7 step:35230[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:7 step:35235[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:7 step:35240[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:7 step:35245[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:7 step:35250[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:7 step:35255[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:7 step:35260[D loss: 0.999994] [G loss: 1.000095]\n",
      "epoch:7 step:35265[D loss: 1.000004] [G loss: 1.000064]\n",
      "epoch:7 step:35270[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:7 step:35275[D loss: 1.000027] [G loss: 1.000070]\n",
      "epoch:7 step:35280[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:7 step:35285[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:7 step:35290[D loss: 1.000027] [G loss: 0.999953]\n",
      "epoch:7 step:35295[D loss: 1.000020] [G loss: 1.000070]\n",
      "epoch:7 step:35300[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:7 step:35305[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:7 step:35310[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:7 step:35315[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:7 step:35320[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:7 step:35325[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:7 step:35330[D loss: 1.000029] [G loss: 1.000036]\n",
      "epoch:7 step:35335[D loss: 1.000035] [G loss: 0.999990]\n",
      "epoch:7 step:35340[D loss: 0.999948] [G loss: 1.000108]\n",
      "epoch:7 step:35345[D loss: 1.000068] [G loss: 0.999996]\n",
      "epoch:7 step:35350[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:7 step:35355[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:7 step:35360[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:7 step:35365[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:7 step:35370[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:7 step:35375[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:7 step:35380[D loss: 1.000041] [G loss: 0.999986]\n",
      "epoch:7 step:35385[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:7 step:35390[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:7 step:35395[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:7 step:35400[D loss: 0.999966] [G loss: 1.000078]\n",
      "##############\n",
      "[2.63118996 2.21389402 2.1885932  4.00655574 1.51532962 8.0494923\n",
      " 2.54173656 3.74983583 3.89457677 5.20118883]\n",
      "##########\n",
      "epoch:7 step:35405[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:7 step:35410[D loss: 0.999972] [G loss: 1.000094]\n",
      "epoch:7 step:35415[D loss: 0.999943] [G loss: 1.000115]\n",
      "epoch:7 step:35420[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:7 step:35425[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:7 step:35430[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:7 step:35435[D loss: 0.999954] [G loss: 1.000095]\n",
      "epoch:7 step:35440[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:7 step:35445[D loss: 1.000006] [G loss: 1.000035]\n",
      "epoch:7 step:35450[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:7 step:35455[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:7 step:35460[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:7 step:35465[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:7 step:35470[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:7 step:35475[D loss: 1.000015] [G loss: 1.000053]\n",
      "epoch:7 step:35480[D loss: 1.000003] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:35485[D loss: 1.000037] [G loss: 0.999985]\n",
      "epoch:7 step:35490[D loss: 0.999996] [G loss: 1.000064]\n",
      "epoch:7 step:35495[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:7 step:35500[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:7 step:35505[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:7 step:35510[D loss: 1.000016] [G loss: 0.999999]\n",
      "epoch:7 step:35515[D loss: 1.000017] [G loss: 1.000023]\n",
      "epoch:7 step:35520[D loss: 0.999906] [G loss: 1.000186]\n",
      "epoch:7 step:35525[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:7 step:35530[D loss: 0.999939] [G loss: 1.000112]\n",
      "epoch:7 step:35535[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:7 step:35540[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:7 step:35545[D loss: 1.000017] [G loss: 1.000033]\n",
      "epoch:7 step:35550[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:7 step:35555[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:7 step:35560[D loss: 1.000021] [G loss: 1.000017]\n",
      "epoch:7 step:35565[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:7 step:35570[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:7 step:35575[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:7 step:35580[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:7 step:35585[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:7 step:35590[D loss: 0.999993] [G loss: 1.000091]\n",
      "epoch:7 step:35595[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:7 step:35600[D loss: 0.999958] [G loss: 1.000098]\n",
      "##############\n",
      "[2.64748803 2.19407663 2.04661773 3.81622447 1.52871183 6.79067993\n",
      " 2.27673811 3.82351037 3.93979426 4.91336634]\n",
      "##########\n",
      "epoch:7 step:35605[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:7 step:35610[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:7 step:35615[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:7 step:35620[D loss: 1.000003] [G loss: 1.000047]\n",
      "epoch:7 step:35625[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:7 step:35630[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:7 step:35635[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:7 step:35640[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:7 step:35645[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:7 step:35650[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:7 step:35655[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:7 step:35660[D loss: 1.000018] [G loss: 1.000063]\n",
      "epoch:7 step:35665[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:7 step:35670[D loss: 0.999984] [G loss: 1.000135]\n",
      "epoch:7 step:35675[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:7 step:35680[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:7 step:35685[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:7 step:35690[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:7 step:35695[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:7 step:35700[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:7 step:35705[D loss: 1.000039] [G loss: 0.999994]\n",
      "epoch:7 step:35710[D loss: 1.000026] [G loss: 0.999939]\n",
      "epoch:7 step:35715[D loss: 0.999936] [G loss: 1.000060]\n",
      "epoch:7 step:35720[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:7 step:35725[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:7 step:35730[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:7 step:35735[D loss: 0.999945] [G loss: 1.000101]\n",
      "epoch:7 step:35740[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:7 step:35745[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:7 step:35750[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:7 step:35755[D loss: 1.000025] [G loss: 1.000001]\n",
      "epoch:7 step:35760[D loss: 1.000011] [G loss: 1.000074]\n",
      "epoch:7 step:35765[D loss: 0.999949] [G loss: 1.000084]\n",
      "epoch:7 step:35770[D loss: 1.000037] [G loss: 1.000018]\n",
      "epoch:7 step:35775[D loss: 0.999973] [G loss: 1.000098]\n",
      "epoch:7 step:35780[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:7 step:35785[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:7 step:35790[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:7 step:35795[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:7 step:35800[D loss: 0.999980] [G loss: 1.000052]\n",
      "##############\n",
      "[2.74496418 2.13314683 2.16044327 3.6330345  1.57954709 7.63699694\n",
      " 2.41903638 3.63237939 3.97239206 4.84279211]\n",
      "##########\n",
      "epoch:7 step:35805[D loss: 1.000013] [G loss: 1.000048]\n",
      "epoch:7 step:35810[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:7 step:35815[D loss: 0.999995] [G loss: 1.000074]\n",
      "epoch:7 step:35820[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:7 step:35825[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:7 step:35830[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:7 step:35835[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:7 step:35840[D loss: 1.000084] [G loss: 0.999913]\n",
      "epoch:7 step:35845[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:7 step:35850[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:7 step:35855[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:7 step:35860[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:7 step:35865[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:7 step:35870[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:7 step:35875[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:7 step:35880[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:7 step:35885[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:7 step:35890[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:7 step:35895[D loss: 0.999992] [G loss: 1.000076]\n",
      "epoch:7 step:35900[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:7 step:35905[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:7 step:35910[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:7 step:35915[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:7 step:35920[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:7 step:35925[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:7 step:35930[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:7 step:35935[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:7 step:35940[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:7 step:35945[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:7 step:35950[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:7 step:35955[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:7 step:35960[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:7 step:35965[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:7 step:35970[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:7 step:35975[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:7 step:35980[D loss: 1.000018] [G loss: 1.000004]\n",
      "epoch:7 step:35985[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:7 step:35990[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:7 step:35995[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:7 step:36000[D loss: 0.999962] [G loss: 1.000067]\n",
      "##############\n",
      "[2.64330342 2.1550735  2.21224111 3.94919429 1.5796618  7.49695801\n",
      " 2.54926702 3.90660566 4.04454319 5.87534155]\n",
      "##########\n",
      "epoch:7 step:36005[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:7 step:36010[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:7 step:36015[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:7 step:36020[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:7 step:36025[D loss: 0.999987] [G loss: 1.000010]\n",
      "epoch:7 step:36030[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:7 step:36035[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:7 step:36040[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:7 step:36045[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:7 step:36050[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:7 step:36055[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:7 step:36060[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:7 step:36065[D loss: 1.000016] [G loss: 0.999990]\n",
      "epoch:7 step:36070[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:7 step:36075[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:7 step:36080[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:7 step:36085[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:7 step:36090[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:7 step:36095[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:7 step:36100[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:7 step:36105[D loss: 0.999964] [G loss: 1.000132]\n",
      "epoch:7 step:36110[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:7 step:36115[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:7 step:36120[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:7 step:36125[D loss: 1.000025] [G loss: 0.999978]\n",
      "epoch:7 step:36130[D loss: 0.999962] [G loss: 1.000028]\n",
      "epoch:7 step:36135[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:7 step:36140[D loss: 0.999951] [G loss: 1.000094]\n",
      "epoch:7 step:36145[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:7 step:36150[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:7 step:36155[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:7 step:36160[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:7 step:36165[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:7 step:36170[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:7 step:36175[D loss: 0.999962] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:36180[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:7 step:36185[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:7 step:36190[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:7 step:36195[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:7 step:36200[D loss: 0.999971] [G loss: 1.000066]\n",
      "##############\n",
      "[2.72263891 2.0993904  2.14135722 3.70221773 1.53685963 7.18033434\n",
      " 2.54680334 3.99874145 3.92056492 5.50063016]\n",
      "##########\n",
      "epoch:7 step:36205[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:7 step:36210[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:7 step:36215[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:7 step:36220[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:7 step:36225[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:7 step:36230[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:7 step:36235[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:7 step:36240[D loss: 1.000005] [G loss: 1.000056]\n",
      "epoch:7 step:36245[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:7 step:36250[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:7 step:36255[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:7 step:36260[D loss: 0.999989] [G loss: 1.000076]\n",
      "epoch:7 step:36265[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:7 step:36270[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:7 step:36275[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:7 step:36280[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:7 step:36285[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:7 step:36290[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:7 step:36295[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:7 step:36300[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:7 step:36305[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:7 step:36310[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:7 step:36315[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:7 step:36320[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:7 step:36325[D loss: 0.999976] [G loss: 1.000100]\n",
      "epoch:7 step:36330[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:7 step:36335[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:7 step:36340[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:7 step:36345[D loss: 1.000020] [G loss: 1.000027]\n",
      "epoch:7 step:36350[D loss: 0.999992] [G loss: 1.000018]\n",
      "epoch:7 step:36355[D loss: 0.999995] [G loss: 0.999999]\n",
      "epoch:7 step:36360[D loss: 0.999943] [G loss: 1.000086]\n",
      "epoch:7 step:36365[D loss: 1.000018] [G loss: 1.000039]\n",
      "epoch:7 step:36370[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:7 step:36375[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:7 step:36380[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:7 step:36385[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:7 step:36390[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:7 step:36395[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:7 step:36400[D loss: 0.999981] [G loss: 1.000062]\n",
      "##############\n",
      "[2.59583953 2.08562358 2.08004964 3.55435936 1.47766491 7.40894402\n",
      " 2.35066123 3.73611798 3.87455893 5.0647806 ]\n",
      "##########\n",
      "epoch:7 step:36405[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:7 step:36410[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:7 step:36415[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:7 step:36420[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:7 step:36425[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:7 step:36430[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:7 step:36435[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:7 step:36440[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:7 step:36445[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:7 step:36450[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:7 step:36455[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:7 step:36460[D loss: 0.999951] [G loss: 1.000065]\n",
      "epoch:7 step:36465[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:7 step:36470[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:7 step:36475[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:7 step:36480[D loss: 0.999993] [G loss: 1.000107]\n",
      "epoch:7 step:36485[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:7 step:36490[D loss: 0.999969] [G loss: 1.000120]\n",
      "epoch:7 step:36495[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:7 step:36500[D loss: 0.999987] [G loss: 0.999999]\n",
      "epoch:7 step:36505[D loss: 1.000007] [G loss: 1.000033]\n",
      "epoch:7 step:36510[D loss: 0.999935] [G loss: 1.000070]\n",
      "epoch:7 step:36515[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:7 step:36520[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:7 step:36525[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:7 step:36530[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:7 step:36535[D loss: 1.000021] [G loss: 1.000002]\n",
      "epoch:7 step:36540[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:7 step:36545[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:7 step:36550[D loss: 1.000000] [G loss: 1.000007]\n",
      "epoch:7 step:36555[D loss: 0.999955] [G loss: 1.000063]\n",
      "epoch:7 step:36560[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:7 step:36565[D loss: 1.000003] [G loss: 1.000059]\n",
      "epoch:7 step:36570[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:7 step:36575[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:7 step:36580[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:7 step:36585[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:7 step:36590[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:7 step:36595[D loss: 1.000027] [G loss: 1.000008]\n",
      "epoch:7 step:36600[D loss: 1.000045] [G loss: 0.999934]\n",
      "##############\n",
      "[2.66646648 2.28891359 2.18281723 3.86416752 1.48786691 6.61314731\n",
      " 2.52346116 3.86130782 4.00074377 5.16404461]\n",
      "##########\n",
      "epoch:7 step:36605[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:7 step:36610[D loss: 0.999936] [G loss: 1.000110]\n",
      "epoch:7 step:36615[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:7 step:36620[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:7 step:36625[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:7 step:36630[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:7 step:36635[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:7 step:36640[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:7 step:36645[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:7 step:36650[D loss: 1.000017] [G loss: 0.999978]\n",
      "epoch:7 step:36655[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:7 step:36660[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:7 step:36665[D loss: 0.999981] [G loss: 1.000116]\n",
      "epoch:7 step:36670[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:7 step:36675[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:7 step:36680[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:7 step:36685[D loss: 1.000019] [G loss: 0.999989]\n",
      "epoch:7 step:36690[D loss: 1.000028] [G loss: 1.000006]\n",
      "epoch:7 step:36695[D loss: 0.999954] [G loss: 1.000103]\n",
      "epoch:7 step:36700[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:7 step:36705[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:7 step:36710[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:7 step:36715[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:7 step:36720[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:7 step:36725[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:7 step:36730[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:7 step:36735[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:7 step:36740[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:7 step:36745[D loss: 0.999998] [G loss: 1.000001]\n",
      "epoch:7 step:36750[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:7 step:36755[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:7 step:36760[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:36765[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:7 step:36770[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:7 step:36775[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:7 step:36780[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:7 step:36785[D loss: 0.999999] [G loss: 1.000047]\n",
      "epoch:7 step:36790[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:7 step:36795[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:7 step:36800[D loss: 0.999979] [G loss: 1.000062]\n",
      "##############\n",
      "[2.66056646 2.11165105 2.1416556  3.77123326 1.39054532 6.98204045\n",
      " 2.34328926 3.7120155  3.92594792 5.06715323]\n",
      "##########\n",
      "epoch:7 step:36805[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:7 step:36810[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:7 step:36815[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:7 step:36820[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:7 step:36825[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:7 step:36830[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:7 step:36835[D loss: 1.000012] [G loss: 1.000020]\n",
      "epoch:7 step:36840[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:7 step:36845[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:7 step:36850[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:36855[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:7 step:36860[D loss: 0.999981] [G loss: 1.000027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:36865[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:7 step:36870[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:7 step:36875[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:7 step:36880[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:7 step:36885[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:7 step:36890[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:7 step:36895[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:7 step:36900[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:7 step:36905[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:7 step:36910[D loss: 0.999993] [G loss: 1.000006]\n",
      "epoch:7 step:36915[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:7 step:36920[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:7 step:36925[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:7 step:36930[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:7 step:36935[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:7 step:36940[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:7 step:36945[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:7 step:36950[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:7 step:36955[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:7 step:36960[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:7 step:36965[D loss: 1.000010] [G loss: 1.000045]\n",
      "epoch:7 step:36970[D loss: 1.000005] [G loss: 0.999976]\n",
      "epoch:7 step:36975[D loss: 0.999994] [G loss: 1.000014]\n",
      "epoch:7 step:36980[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:7 step:36985[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:7 step:36990[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:7 step:36995[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:7 step:37000[D loss: 1.000004] [G loss: 1.000031]\n",
      "##############\n",
      "[2.60416629 2.08321391 2.25524811 3.49479237 1.35600018 6.57472788\n",
      " 2.38386837 3.84682145 3.92795038 5.4962667 ]\n",
      "##########\n",
      "epoch:7 step:37005[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:7 step:37010[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:7 step:37015[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:7 step:37020[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:7 step:37025[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:7 step:37030[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:7 step:37035[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:7 step:37040[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:7 step:37045[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:7 step:37050[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:7 step:37055[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:7 step:37060[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:7 step:37065[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:7 step:37070[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:7 step:37075[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:7 step:37080[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:7 step:37085[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:7 step:37090[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:7 step:37095[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:7 step:37100[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:7 step:37105[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:7 step:37110[D loss: 0.999971] [G loss: 1.000098]\n",
      "epoch:7 step:37115[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:7 step:37120[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:7 step:37125[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:7 step:37130[D loss: 1.000010] [G loss: 1.000026]\n",
      "epoch:7 step:37135[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:7 step:37140[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:7 step:37145[D loss: 0.999994] [G loss: 1.000099]\n",
      "epoch:7 step:37150[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:7 step:37155[D loss: 1.000022] [G loss: 0.999979]\n",
      "epoch:7 step:37160[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:7 step:37165[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:7 step:37170[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:7 step:37175[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:7 step:37180[D loss: 0.999950] [G loss: 1.000068]\n",
      "epoch:7 step:37185[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:7 step:37190[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:7 step:37195[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:7 step:37200[D loss: 0.999980] [G loss: 1.000049]\n",
      "##############\n",
      "[2.61924003 2.08988811 2.26697162 3.4933791  1.43666701 7.56094455\n",
      " 2.39841432 3.86734188 3.90370035 4.95980598]\n",
      "##########\n",
      "epoch:7 step:37205[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:7 step:37210[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:7 step:37215[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:7 step:37220[D loss: 1.000008] [G loss: 1.000036]\n",
      "epoch:7 step:37225[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:7 step:37230[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:7 step:37235[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:7 step:37240[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:7 step:37245[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:7 step:37250[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:7 step:37255[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:7 step:37260[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:7 step:37265[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:37270[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:7 step:37275[D loss: 1.000027] [G loss: 0.999991]\n",
      "epoch:7 step:37280[D loss: 1.000036] [G loss: 0.999942]\n",
      "epoch:7 step:37285[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:7 step:37290[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:7 step:37295[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:7 step:37300[D loss: 0.999947] [G loss: 1.000147]\n",
      "epoch:7 step:37305[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:7 step:37310[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:7 step:37315[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:7 step:37320[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:7 step:37325[D loss: 1.000035] [G loss: 0.999980]\n",
      "epoch:7 step:37330[D loss: 0.999945] [G loss: 1.000080]\n",
      "epoch:7 step:37335[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:7 step:37340[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:7 step:37345[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:7 step:37350[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:7 step:37355[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:7 step:37360[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:7 step:37365[D loss: 1.000006] [G loss: 1.000032]\n",
      "epoch:7 step:37370[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:7 step:37375[D loss: 1.000011] [G loss: 0.999993]\n",
      "epoch:7 step:37380[D loss: 0.999999] [G loss: 1.000024]\n",
      "epoch:7 step:37385[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:7 step:37390[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:7 step:37395[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:7 step:37400[D loss: 0.999977] [G loss: 1.000077]\n",
      "##############\n",
      "[2.69255633 2.18363621 2.29049014 4.01138551 1.56870723 7.43807686\n",
      " 2.5840331  3.92385481 4.06620202 5.58752539]\n",
      "##########\n",
      "epoch:7 step:37405[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:7 step:37410[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:7 step:37415[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:7 step:37420[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:7 step:37425[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:7 step:37430[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:7 step:37435[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:7 step:37440[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:7 step:37445[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:7 step:37450[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:7 step:37455[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:7 step:37460[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:7 step:37465[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:7 step:37470[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:7 step:37475[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:7 step:37480[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:8 step:37485[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:8 step:37490[D loss: 0.999937] [G loss: 1.000112]\n",
      "epoch:8 step:37495[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:8 step:37500[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:8 step:37505[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:8 step:37510[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:8 step:37515[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:8 step:37520[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:8 step:37525[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:8 step:37530[D loss: 0.999995] [G loss: 1.000069]\n",
      "epoch:8 step:37535[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:8 step:37540[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:8 step:37545[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:8 step:37550[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:8 step:37555[D loss: 0.999977] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:37560[D loss: 0.999983] [G loss: 1.000095]\n",
      "epoch:8 step:37565[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:8 step:37570[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:8 step:37575[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:8 step:37580[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:8 step:37585[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:8 step:37590[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:8 step:37595[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:8 step:37600[D loss: 0.999972] [G loss: 1.000088]\n",
      "##############\n",
      "[2.67841068 2.17351627 2.27101202 3.86592043 1.48140773 9.27426719\n",
      " 2.36282847 3.74345769 4.04768511 5.74852532]\n",
      "##########\n",
      "epoch:8 step:37605[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:8 step:37610[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:8 step:37615[D loss: 0.999997] [G loss: 1.000073]\n",
      "epoch:8 step:37620[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:8 step:37625[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:8 step:37630[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:8 step:37635[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:8 step:37640[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:8 step:37645[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:8 step:37650[D loss: 1.000024] [G loss: 0.999996]\n",
      "epoch:8 step:37655[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:8 step:37660[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:8 step:37665[D loss: 0.999974] [G loss: 1.000117]\n",
      "epoch:8 step:37670[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:8 step:37675[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:8 step:37680[D loss: 1.000000] [G loss: 1.000015]\n",
      "epoch:8 step:37685[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:8 step:37690[D loss: 1.000005] [G loss: 1.000005]\n",
      "epoch:8 step:37695[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:8 step:37700[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:8 step:37705[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:8 step:37710[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:8 step:37715[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:8 step:37720[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:8 step:37725[D loss: 1.000007] [G loss: 1.000041]\n",
      "epoch:8 step:37730[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:8 step:37735[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:8 step:37740[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:8 step:37745[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:8 step:37750[D loss: 0.999968] [G loss: 1.000101]\n",
      "epoch:8 step:37755[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:8 step:37760[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:8 step:37765[D loss: 0.999962] [G loss: 1.000115]\n",
      "epoch:8 step:37770[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:8 step:37775[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:8 step:37780[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:8 step:37785[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:8 step:37790[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:8 step:37795[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:8 step:37800[D loss: 1.000033] [G loss: 0.999953]\n",
      "##############\n",
      "[2.65449034 2.1405592  2.29089733 3.9037852  1.43882105 7.27389152\n",
      " 2.46451941 3.6975868  3.8870088  5.32563829]\n",
      "##########\n",
      "epoch:8 step:37805[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:8 step:37810[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:8 step:37815[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:8 step:37820[D loss: 0.999967] [G loss: 1.000040]\n",
      "epoch:8 step:37825[D loss: 1.000023] [G loss: 0.999974]\n",
      "epoch:8 step:37830[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:8 step:37835[D loss: 0.999963] [G loss: 1.000107]\n",
      "epoch:8 step:37840[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:8 step:37845[D loss: 0.999952] [G loss: 1.000091]\n",
      "epoch:8 step:37850[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:8 step:37855[D loss: 0.999977] [G loss: 1.000099]\n",
      "epoch:8 step:37860[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:8 step:37865[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:8 step:37870[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:8 step:37875[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:8 step:37880[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:8 step:37885[D loss: 0.999960] [G loss: 1.000121]\n",
      "epoch:8 step:37890[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:8 step:37895[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:8 step:37900[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:8 step:37905[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:8 step:37910[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:8 step:37915[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:8 step:37920[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:8 step:37925[D loss: 0.999984] [G loss: 1.000095]\n",
      "epoch:8 step:37930[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:8 step:37935[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:8 step:37940[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:8 step:37945[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:8 step:37950[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:8 step:37955[D loss: 0.999994] [G loss: 1.000086]\n",
      "epoch:8 step:37960[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:8 step:37965[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:8 step:37970[D loss: 0.999975] [G loss: 1.000102]\n",
      "epoch:8 step:37975[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:8 step:37980[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:8 step:37985[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:8 step:37990[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:8 step:37995[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:8 step:38000[D loss: 0.999988] [G loss: 1.000051]\n",
      "##############\n",
      "[2.71817573 2.09393609 2.1439983  3.69004174 1.50437773 8.60223197\n",
      " 2.31163458 3.8176181  4.01303667 6.03216888]\n",
      "##########\n",
      "epoch:8 step:38005[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:8 step:38010[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:8 step:38015[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:8 step:38020[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:8 step:38025[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:8 step:38030[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:8 step:38035[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:8 step:38040[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:8 step:38045[D loss: 0.999987] [G loss: 1.000081]\n",
      "epoch:8 step:38050[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:8 step:38055[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:8 step:38060[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:8 step:38065[D loss: 0.999978] [G loss: 1.000105]\n",
      "epoch:8 step:38070[D loss: 1.000007] [G loss: 1.000047]\n",
      "epoch:8 step:38075[D loss: 1.000019] [G loss: 1.000024]\n",
      "epoch:8 step:38080[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:8 step:38085[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:8 step:38090[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:8 step:38095[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:8 step:38100[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:8 step:38105[D loss: 1.000018] [G loss: 1.000010]\n",
      "epoch:8 step:38110[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:8 step:38115[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:8 step:38120[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:8 step:38125[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:8 step:38130[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:8 step:38135[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:8 step:38140[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:8 step:38145[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:8 step:38150[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:8 step:38155[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:8 step:38160[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:8 step:38165[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:8 step:38170[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:8 step:38175[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:8 step:38180[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:8 step:38185[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:8 step:38190[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:8 step:38195[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:8 step:38200[D loss: 0.999966] [G loss: 1.000083]\n",
      "##############\n",
      "[2.70804178 2.13301789 2.27851224 3.55031728 1.52288415 7.82897504\n",
      " 2.5195243  3.78362623 4.03122429 4.62707203]\n",
      "##########\n",
      "epoch:8 step:38205[D loss: 0.999998] [G loss: 1.000039]\n",
      "epoch:8 step:38210[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:8 step:38215[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:8 step:38220[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:8 step:38225[D loss: 1.000007] [G loss: 0.999982]\n",
      "epoch:8 step:38230[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:8 step:38235[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:8 step:38240[D loss: 0.999978] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:38245[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:8 step:38250[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:8 step:38255[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:8 step:38260[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:8 step:38265[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:8 step:38270[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:8 step:38275[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:8 step:38280[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:8 step:38285[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:8 step:38290[D loss: 1.000005] [G loss: 1.000058]\n",
      "epoch:8 step:38295[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:8 step:38300[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:8 step:38305[D loss: 1.000019] [G loss: 1.000038]\n",
      "epoch:8 step:38310[D loss: 1.000006] [G loss: 0.999984]\n",
      "epoch:8 step:38315[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:8 step:38320[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:8 step:38325[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:8 step:38330[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:8 step:38335[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:8 step:38340[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:8 step:38345[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:8 step:38350[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:8 step:38355[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:8 step:38360[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:8 step:38365[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:8 step:38370[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:8 step:38375[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:8 step:38380[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:8 step:38385[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:8 step:38390[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:8 step:38395[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:8 step:38400[D loss: 0.999972] [G loss: 1.000077]\n",
      "##############\n",
      "[2.70704716 2.08289221 2.20297968 3.55334522 1.55519296 7.58260069\n",
      " 2.43206059 3.84136441 3.8970177  5.29767271]\n",
      "##########\n",
      "epoch:8 step:38405[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:8 step:38410[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:8 step:38415[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:8 step:38420[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:8 step:38425[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:8 step:38430[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:8 step:38435[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:8 step:38440[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:8 step:38445[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:8 step:38450[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:8 step:38455[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:8 step:38460[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:8 step:38465[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:8 step:38470[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:8 step:38475[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:8 step:38480[D loss: 0.999976] [G loss: 1.000120]\n",
      "epoch:8 step:38485[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:8 step:38490[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:8 step:38495[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:8 step:38500[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:8 step:38505[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:8 step:38510[D loss: 0.999970] [G loss: 1.000097]\n",
      "epoch:8 step:38515[D loss: 1.000045] [G loss: 1.000000]\n",
      "epoch:8 step:38520[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:8 step:38525[D loss: 0.999997] [G loss: 1.000077]\n",
      "epoch:8 step:38530[D loss: 0.999980] [G loss: 1.000103]\n",
      "epoch:8 step:38535[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:8 step:38540[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:8 step:38545[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:8 step:38550[D loss: 0.999992] [G loss: 1.000086]\n",
      "epoch:8 step:38555[D loss: 1.000011] [G loss: 1.000034]\n",
      "epoch:8 step:38560[D loss: 0.999996] [G loss: 1.000030]\n",
      "epoch:8 step:38565[D loss: 0.999973] [G loss: 1.000170]\n",
      "epoch:8 step:38570[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:8 step:38575[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:8 step:38580[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:8 step:38585[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:8 step:38590[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:8 step:38595[D loss: 1.000002] [G loss: 1.000008]\n",
      "epoch:8 step:38600[D loss: 0.999961] [G loss: 1.000056]\n",
      "##############\n",
      "[2.57799106 2.03475023 2.21965855 3.54976758 1.48585038 6.84608786\n",
      " 2.49187342 3.865782   3.9440091  5.63093314]\n",
      "##########\n",
      "epoch:8 step:38605[D loss: 0.999968] [G loss: 1.000118]\n",
      "epoch:8 step:38610[D loss: 1.000024] [G loss: 1.000051]\n",
      "epoch:8 step:38615[D loss: 1.000022] [G loss: 1.000068]\n",
      "epoch:8 step:38620[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:8 step:38625[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:8 step:38630[D loss: 0.999969] [G loss: 1.000105]\n",
      "epoch:8 step:38635[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:8 step:38640[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:8 step:38645[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:8 step:38650[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:8 step:38655[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:8 step:38660[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:8 step:38665[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:8 step:38670[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:8 step:38675[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:8 step:38680[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:8 step:38685[D loss: 1.000002] [G loss: 1.000055]\n",
      "epoch:8 step:38690[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:8 step:38695[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:8 step:38700[D loss: 0.999932] [G loss: 1.000131]\n",
      "epoch:8 step:38705[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:8 step:38710[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:8 step:38715[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:8 step:38720[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:8 step:38725[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:8 step:38730[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:8 step:38735[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:8 step:38740[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:8 step:38745[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:8 step:38750[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:8 step:38755[D loss: 0.999997] [G loss: 1.000085]\n",
      "epoch:8 step:38760[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:8 step:38765[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:8 step:38770[D loss: 1.000009] [G loss: 1.000027]\n",
      "epoch:8 step:38775[D loss: 0.999945] [G loss: 1.000097]\n",
      "epoch:8 step:38780[D loss: 0.999999] [G loss: 1.000056]\n",
      "epoch:8 step:38785[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:8 step:38790[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:8 step:38795[D loss: 1.000015] [G loss: 1.000017]\n",
      "epoch:8 step:38800[D loss: 0.999973] [G loss: 1.000042]\n",
      "##############\n",
      "[2.68879192 2.17755993 2.14561382 3.82065171 1.51116165 6.90056968\n",
      " 2.46873939 3.85226208 4.02962233 4.77860433]\n",
      "##########\n",
      "epoch:8 step:38805[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:8 step:38810[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:8 step:38815[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:8 step:38820[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:8 step:38825[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:8 step:38830[D loss: 1.000000] [G loss: 1.000035]\n",
      "epoch:8 step:38835[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:8 step:38840[D loss: 1.000003] [G loss: 1.000030]\n",
      "epoch:8 step:38845[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:8 step:38850[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:8 step:38855[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:8 step:38860[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:8 step:38865[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:8 step:38870[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:8 step:38875[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:8 step:38880[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:8 step:38885[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:8 step:38890[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:8 step:38895[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:8 step:38900[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:8 step:38905[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:8 step:38910[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:8 step:38915[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:8 step:38920[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:8 step:38925[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:8 step:38930[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:8 step:38935[D loss: 0.999963] [G loss: 1.000075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:38940[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:8 step:38945[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:8 step:38950[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:8 step:38955[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:8 step:38960[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:8 step:38965[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:8 step:38970[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:8 step:38975[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:8 step:38980[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:8 step:38985[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:8 step:38990[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:8 step:38995[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:8 step:39000[D loss: 0.999980] [G loss: 1.000071]\n",
      "##############\n",
      "[2.63803482 2.13334495 2.14110001 3.41481186 1.46689951 7.21166236\n",
      " 2.30609721 3.8876781  3.9283269  4.84315344]\n",
      "##########\n",
      "epoch:8 step:39005[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:8 step:39010[D loss: 0.999999] [G loss: 1.000086]\n",
      "epoch:8 step:39015[D loss: 0.999942] [G loss: 1.000096]\n",
      "epoch:8 step:39020[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:8 step:39025[D loss: 1.000047] [G loss: 0.999956]\n",
      "epoch:8 step:39030[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:8 step:39035[D loss: 1.000033] [G loss: 0.999986]\n",
      "epoch:8 step:39040[D loss: 0.999951] [G loss: 1.000062]\n",
      "epoch:8 step:39045[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:8 step:39050[D loss: 1.000018] [G loss: 1.000006]\n",
      "epoch:8 step:39055[D loss: 1.000005] [G loss: 1.000058]\n",
      "epoch:8 step:39060[D loss: 0.999998] [G loss: 1.000104]\n",
      "epoch:8 step:39065[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:8 step:39070[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:8 step:39075[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:8 step:39080[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:8 step:39085[D loss: 1.000015] [G loss: 1.000086]\n",
      "epoch:8 step:39090[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:8 step:39095[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:8 step:39100[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:8 step:39105[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:8 step:39110[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:8 step:39115[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:8 step:39120[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:8 step:39125[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:8 step:39130[D loss: 1.000009] [G loss: 1.000019]\n",
      "epoch:8 step:39135[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:8 step:39140[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:8 step:39145[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:8 step:39150[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:8 step:39155[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:8 step:39160[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:8 step:39165[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:8 step:39170[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:8 step:39175[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:8 step:39180[D loss: 0.999998] [G loss: 1.000016]\n",
      "epoch:8 step:39185[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:8 step:39190[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:8 step:39195[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:8 step:39200[D loss: 0.999987] [G loss: 1.000049]\n",
      "##############\n",
      "[2.7168372  2.13896031 2.28277193 3.79404324 1.57397586 8.07152068\n",
      " 2.38494    3.85342468 3.97636296 5.3440267 ]\n",
      "##########\n",
      "epoch:8 step:39205[D loss: 1.000005] [G loss: 1.000017]\n",
      "epoch:8 step:39210[D loss: 1.000019] [G loss: 1.000015]\n",
      "epoch:8 step:39215[D loss: 0.999954] [G loss: 1.000077]\n",
      "epoch:8 step:39220[D loss: 0.999950] [G loss: 1.000123]\n",
      "epoch:8 step:39225[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:8 step:39230[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:8 step:39235[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:8 step:39240[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:8 step:39245[D loss: 0.999996] [G loss: 0.999991]\n",
      "epoch:8 step:39250[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:8 step:39255[D loss: 0.999995] [G loss: 1.000010]\n",
      "epoch:8 step:39260[D loss: 1.000015] [G loss: 0.999988]\n",
      "epoch:8 step:39265[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:8 step:39270[D loss: 1.000028] [G loss: 1.000032]\n",
      "epoch:8 step:39275[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:8 step:39280[D loss: 0.999963] [G loss: 1.000109]\n",
      "epoch:8 step:39285[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:8 step:39290[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:8 step:39295[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:8 step:39300[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:8 step:39305[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:8 step:39310[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:8 step:39315[D loss: 0.999975] [G loss: 1.000131]\n",
      "epoch:8 step:39320[D loss: 1.000014] [G loss: 1.000057]\n",
      "epoch:8 step:39325[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:8 step:39330[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:8 step:39335[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:8 step:39340[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:8 step:39345[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:8 step:39350[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:8 step:39355[D loss: 0.999995] [G loss: 1.000022]\n",
      "epoch:8 step:39360[D loss: 1.000007] [G loss: 1.000017]\n",
      "epoch:8 step:39365[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:8 step:39370[D loss: 1.000060] [G loss: 1.000002]\n",
      "epoch:8 step:39375[D loss: 0.999944] [G loss: 1.000099]\n",
      "epoch:8 step:39380[D loss: 0.999945] [G loss: 1.000081]\n",
      "epoch:8 step:39385[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:8 step:39390[D loss: 0.999953] [G loss: 1.000092]\n",
      "epoch:8 step:39395[D loss: 1.000024] [G loss: 1.000013]\n",
      "epoch:8 step:39400[D loss: 0.999988] [G loss: 1.000057]\n",
      "##############\n",
      "[2.63783986 2.15232448 2.20697705 3.69975015 1.52555154 7.25867462\n",
      " 2.39763634 3.93099924 4.0458976  4.74919679]\n",
      "##########\n",
      "epoch:8 step:39405[D loss: 0.999997] [G loss: 1.000083]\n",
      "epoch:8 step:39410[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:8 step:39415[D loss: 1.000030] [G loss: 1.000029]\n",
      "epoch:8 step:39420[D loss: 0.999958] [G loss: 1.000111]\n",
      "epoch:8 step:39425[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:8 step:39430[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:8 step:39435[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:8 step:39440[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:8 step:39445[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:8 step:39450[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:8 step:39455[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:8 step:39460[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:8 step:39465[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:8 step:39470[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:8 step:39475[D loss: 1.000004] [G loss: 1.000070]\n",
      "epoch:8 step:39480[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:8 step:39485[D loss: 0.999967] [G loss: 1.000119]\n",
      "epoch:8 step:39490[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:8 step:39495[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:8 step:39500[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:8 step:39505[D loss: 1.000017] [G loss: 0.999965]\n",
      "epoch:8 step:39510[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:8 step:39515[D loss: 1.000007] [G loss: 1.000048]\n",
      "epoch:8 step:39520[D loss: 0.999944] [G loss: 1.000100]\n",
      "epoch:8 step:39525[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:8 step:39530[D loss: 1.000043] [G loss: 1.000011]\n",
      "epoch:8 step:39535[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:8 step:39540[D loss: 1.000012] [G loss: 1.000061]\n",
      "epoch:8 step:39545[D loss: 1.000001] [G loss: 1.000012]\n",
      "epoch:8 step:39550[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:8 step:39555[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:8 step:39560[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:8 step:39565[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:8 step:39570[D loss: 1.000003] [G loss: 1.000030]\n",
      "epoch:8 step:39575[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:8 step:39580[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:8 step:39585[D loss: 1.000003] [G loss: 1.000046]\n",
      "epoch:8 step:39590[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:8 step:39595[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:8 step:39600[D loss: 0.999991] [G loss: 1.000042]\n",
      "##############\n",
      "[2.65817647 2.12105659 2.28173919 3.9166959  1.52671788 7.02740592\n",
      " 2.31985857 4.02156915 3.97176719 5.37239267]\n",
      "##########\n",
      "epoch:8 step:39605[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:8 step:39610[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:8 step:39615[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:8 step:39620[D loss: 1.000004] [G loss: 1.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:39625[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:8 step:39630[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:8 step:39635[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:8 step:39640[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:8 step:39645[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:8 step:39650[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:8 step:39655[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:8 step:39660[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:8 step:39665[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:8 step:39670[D loss: 0.999946] [G loss: 1.000127]\n",
      "epoch:8 step:39675[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:8 step:39680[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:8 step:39685[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:8 step:39690[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:8 step:39695[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:8 step:39700[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:8 step:39705[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:8 step:39710[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:8 step:39715[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:8 step:39720[D loss: 0.999994] [G loss: 1.000099]\n",
      "epoch:8 step:39725[D loss: 1.000002] [G loss: 1.000014]\n",
      "epoch:8 step:39730[D loss: 0.999989] [G loss: 1.000081]\n",
      "epoch:8 step:39735[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:8 step:39740[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:8 step:39745[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:8 step:39750[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:8 step:39755[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:8 step:39760[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:8 step:39765[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:8 step:39770[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:8 step:39775[D loss: 1.000063] [G loss: 0.999961]\n",
      "epoch:8 step:39780[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:8 step:39785[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:8 step:39790[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:8 step:39795[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:8 step:39800[D loss: 0.999969] [G loss: 1.000078]\n",
      "##############\n",
      "[2.66131804 2.07791214 2.2046917  3.96499357 1.53049287 6.92023251\n",
      " 2.45670094 3.86469041 3.98547973 5.02197296]\n",
      "##########\n",
      "epoch:8 step:39805[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:8 step:39810[D loss: 0.999946] [G loss: 1.000097]\n",
      "epoch:8 step:39815[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:8 step:39820[D loss: 1.000004] [G loss: 1.000077]\n",
      "epoch:8 step:39825[D loss: 1.000010] [G loss: 1.000072]\n",
      "epoch:8 step:39830[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:8 step:39835[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:8 step:39840[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:8 step:39845[D loss: 0.999993] [G loss: 1.000010]\n",
      "epoch:8 step:39850[D loss: 1.000016] [G loss: 1.000048]\n",
      "epoch:8 step:39855[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:8 step:39860[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:8 step:39865[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:8 step:39870[D loss: 0.999996] [G loss: 1.000066]\n",
      "epoch:8 step:39875[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:8 step:39880[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:8 step:39885[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:8 step:39890[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:8 step:39895[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:8 step:39900[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:8 step:39905[D loss: 0.999986] [G loss: 1.000093]\n",
      "epoch:8 step:39910[D loss: 0.999973] [G loss: 1.000105]\n",
      "epoch:8 step:39915[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:8 step:39920[D loss: 0.999981] [G loss: 1.000095]\n",
      "epoch:8 step:39925[D loss: 0.999991] [G loss: 1.000069]\n",
      "epoch:8 step:39930[D loss: 0.999991] [G loss: 1.000094]\n",
      "epoch:8 step:39935[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:8 step:39940[D loss: 0.999981] [G loss: 1.000110]\n",
      "epoch:8 step:39945[D loss: 0.999998] [G loss: 1.000114]\n",
      "epoch:8 step:39950[D loss: 0.999993] [G loss: 1.000089]\n",
      "epoch:8 step:39955[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:8 step:39960[D loss: 1.000020] [G loss: 1.000071]\n",
      "epoch:8 step:39965[D loss: 0.999961] [G loss: 1.000149]\n",
      "epoch:8 step:39970[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:8 step:39975[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:8 step:39980[D loss: 1.000021] [G loss: 1.000018]\n",
      "epoch:8 step:39985[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:8 step:39990[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:8 step:39995[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:8 step:40000[D loss: 0.999979] [G loss: 1.000079]\n",
      "##############\n",
      "[2.7321177  2.24251104 2.2753451  3.74937848 1.49919479 6.68804538\n",
      " 2.41122524 3.88073396 4.12458336 5.67712047]\n",
      "##########\n",
      "epoch:8 step:40005[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:8 step:40010[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:8 step:40015[D loss: 1.000004] [G loss: 1.000074]\n",
      "epoch:8 step:40020[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:8 step:40025[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:8 step:40030[D loss: 1.000018] [G loss: 1.000086]\n",
      "epoch:8 step:40035[D loss: 0.999957] [G loss: 1.000136]\n",
      "epoch:8 step:40040[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:8 step:40045[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:8 step:40050[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:8 step:40055[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:8 step:40060[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:8 step:40065[D loss: 0.999993] [G loss: 1.000086]\n",
      "epoch:8 step:40070[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:8 step:40075[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:8 step:40080[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:8 step:40085[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:8 step:40090[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:8 step:40095[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:8 step:40100[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:8 step:40105[D loss: 0.999970] [G loss: 1.000097]\n",
      "epoch:8 step:40110[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:8 step:40115[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:8 step:40120[D loss: 0.999944] [G loss: 1.000116]\n",
      "epoch:8 step:40125[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:8 step:40130[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:8 step:40135[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:8 step:40140[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:8 step:40145[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:8 step:40150[D loss: 0.999999] [G loss: 1.000049]\n",
      "epoch:8 step:40155[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:8 step:40160[D loss: 0.999989] [G loss: 1.000107]\n",
      "epoch:8 step:40165[D loss: 0.999941] [G loss: 1.000148]\n",
      "epoch:8 step:40170[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:8 step:40175[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:8 step:40180[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:8 step:40185[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:8 step:40190[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:8 step:40195[D loss: 1.000009] [G loss: 1.000023]\n",
      "epoch:8 step:40200[D loss: 1.000022] [G loss: 0.999992]\n",
      "##############\n",
      "[2.68904353 2.20214811 2.2058525  3.6658105  1.55133787 7.94091192\n",
      " 2.3281998  3.85563894 3.97844435 5.20800981]\n",
      "##########\n",
      "epoch:8 step:40205[D loss: 1.000025] [G loss: 0.999988]\n",
      "epoch:8 step:40210[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:8 step:40215[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:8 step:40220[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:8 step:40225[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:8 step:40230[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:8 step:40235[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:8 step:40240[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:8 step:40245[D loss: 1.000006] [G loss: 1.000028]\n",
      "epoch:8 step:40250[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:8 step:40255[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:8 step:40260[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:8 step:40265[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:8 step:40270[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:8 step:40275[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:8 step:40280[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:8 step:40285[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:8 step:40290[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:8 step:40295[D loss: 0.999979] [G loss: 1.000116]\n",
      "epoch:8 step:40300[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:8 step:40305[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:8 step:40310[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:8 step:40315[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:8 step:40320[D loss: 0.999983] [G loss: 1.000036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:40325[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:8 step:40330[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:8 step:40335[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:8 step:40340[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:8 step:40345[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:8 step:40350[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:8 step:40355[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:8 step:40360[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:8 step:40365[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:8 step:40370[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:40375[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:8 step:40380[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:8 step:40385[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:8 step:40390[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:8 step:40395[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:8 step:40400[D loss: 0.999975] [G loss: 1.000054]\n",
      "##############\n",
      "[2.64510706 2.18285313 2.31429316 3.82095691 1.59993198 6.53405399\n",
      " 2.35964413 3.70526675 4.06644348 4.84454893]\n",
      "##########\n",
      "epoch:8 step:40405[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:8 step:40410[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:8 step:40415[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:8 step:40420[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:8 step:40425[D loss: 1.000053] [G loss: 0.999996]\n",
      "epoch:8 step:40430[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:8 step:40435[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:8 step:40440[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:8 step:40445[D loss: 1.000011] [G loss: 1.000025]\n",
      "epoch:8 step:40450[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:8 step:40455[D loss: 1.000007] [G loss: 1.000064]\n",
      "epoch:8 step:40460[D loss: 0.999936] [G loss: 1.000120]\n",
      "epoch:8 step:40465[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:8 step:40470[D loss: 0.999999] [G loss: 1.000028]\n",
      "epoch:8 step:40475[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:8 step:40480[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:8 step:40485[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:8 step:40490[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:8 step:40495[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:8 step:40500[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:8 step:40505[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:8 step:40510[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:8 step:40515[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:8 step:40520[D loss: 1.000009] [G loss: 1.000005]\n",
      "epoch:8 step:40525[D loss: 1.000080] [G loss: 0.999954]\n",
      "epoch:8 step:40530[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:8 step:40535[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:8 step:40540[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:8 step:40545[D loss: 0.999991] [G loss: 1.000020]\n",
      "epoch:8 step:40550[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:8 step:40555[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:8 step:40560[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:8 step:40565[D loss: 1.000015] [G loss: 1.000050]\n",
      "epoch:8 step:40570[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:8 step:40575[D loss: 0.999954] [G loss: 1.000076]\n",
      "epoch:8 step:40580[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:8 step:40585[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:8 step:40590[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:8 step:40595[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:8 step:40600[D loss: 0.999978] [G loss: 1.000063]\n",
      "##############\n",
      "[2.70286439 2.08448004 2.24389288 3.75542793 1.57818878 6.92290122\n",
      " 2.4623936  3.87483075 4.10960538 5.02107707]\n",
      "##########\n",
      "epoch:8 step:40605[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:8 step:40610[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:8 step:40615[D loss: 1.000002] [G loss: 1.000033]\n",
      "epoch:8 step:40620[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:8 step:40625[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:8 step:40630[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:8 step:40635[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:8 step:40640[D loss: 0.999952] [G loss: 1.000103]\n",
      "epoch:8 step:40645[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:8 step:40650[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:8 step:40655[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:8 step:40660[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:8 step:40665[D loss: 1.000036] [G loss: 1.000003]\n",
      "epoch:8 step:40670[D loss: 0.999979] [G loss: 1.000020]\n",
      "epoch:8 step:40675[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:8 step:40680[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:8 step:40685[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:8 step:40690[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:8 step:40695[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:8 step:40700[D loss: 1.000006] [G loss: 1.000037]\n",
      "epoch:8 step:40705[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:8 step:40710[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:8 step:40715[D loss: 0.999938] [G loss: 1.000110]\n",
      "epoch:8 step:40720[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:8 step:40725[D loss: 1.000028] [G loss: 1.000007]\n",
      "epoch:8 step:40730[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:8 step:40735[D loss: 0.999981] [G loss: 1.000103]\n",
      "epoch:8 step:40740[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:8 step:40745[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:8 step:40750[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:8 step:40755[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:8 step:40760[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:8 step:40765[D loss: 0.999975] [G loss: 1.000114]\n",
      "epoch:8 step:40770[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:8 step:40775[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:8 step:40780[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:8 step:40785[D loss: 0.999996] [G loss: 1.000039]\n",
      "epoch:8 step:40790[D loss: 0.999973] [G loss: 1.000120]\n",
      "epoch:8 step:40795[D loss: 0.999966] [G loss: 1.000109]\n",
      "epoch:8 step:40800[D loss: 0.999974] [G loss: 1.000067]\n",
      "##############\n",
      "[2.68931863 2.10530583 2.06452581 3.60832814 1.5548338  6.89359792\n",
      " 2.49420742 4.03772978 4.05337553 4.99651247]\n",
      "##########\n",
      "epoch:8 step:40805[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:8 step:40810[D loss: 0.999971] [G loss: 1.000102]\n",
      "epoch:8 step:40815[D loss: 0.999964] [G loss: 1.000126]\n",
      "epoch:8 step:40820[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:8 step:40825[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:8 step:40830[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:8 step:40835[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:8 step:40840[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:8 step:40845[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:8 step:40850[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:8 step:40855[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:8 step:40860[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:8 step:40865[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:8 step:40870[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:8 step:40875[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:8 step:40880[D loss: 0.999999] [G loss: 1.000063]\n",
      "epoch:8 step:40885[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:8 step:40890[D loss: 0.999998] [G loss: 1.000035]\n",
      "epoch:8 step:40895[D loss: 0.999994] [G loss: 0.999997]\n",
      "epoch:8 step:40900[D loss: 1.000003] [G loss: 1.000026]\n",
      "epoch:8 step:40905[D loss: 1.000042] [G loss: 0.999972]\n",
      "epoch:8 step:40910[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:8 step:40915[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:8 step:40920[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:8 step:40925[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:8 step:40930[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:8 step:40935[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:8 step:40940[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:8 step:40945[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:8 step:40950[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:8 step:40955[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:8 step:40960[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:8 step:40965[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:8 step:40970[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:8 step:40975[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:8 step:40980[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:8 step:40985[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:8 step:40990[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:8 step:40995[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:8 step:41000[D loss: 0.999982] [G loss: 1.000082]\n",
      "##############\n",
      "[2.77237895 2.20216952 2.18665676 3.81462325 1.44484218 7.65124289\n",
      " 2.31992605 3.7876355  4.06446567 4.96202669]\n",
      "##########\n",
      "epoch:8 step:41005[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:8 step:41010[D loss: 0.999991] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:41015[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:8 step:41020[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:8 step:41025[D loss: 1.000021] [G loss: 1.000015]\n",
      "epoch:8 step:41030[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:8 step:41035[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:8 step:41040[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:8 step:41045[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:8 step:41050[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:8 step:41055[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:8 step:41060[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:8 step:41065[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:8 step:41070[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:8 step:41075[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:8 step:41080[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:8 step:41085[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:8 step:41090[D loss: 0.999972] [G loss: 1.000114]\n",
      "epoch:8 step:41095[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:8 step:41100[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:8 step:41105[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:8 step:41110[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:8 step:41115[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:8 step:41120[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:8 step:41125[D loss: 0.999955] [G loss: 1.000089]\n",
      "epoch:8 step:41130[D loss: 1.000006] [G loss: 1.000050]\n",
      "epoch:8 step:41135[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:8 step:41140[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:8 step:41145[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:8 step:41150[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:8 step:41155[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:8 step:41160[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:8 step:41165[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:8 step:41170[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:8 step:41175[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:8 step:41180[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:8 step:41185[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:8 step:41190[D loss: 1.000026] [G loss: 1.000057]\n",
      "epoch:8 step:41195[D loss: 0.999927] [G loss: 1.000076]\n",
      "epoch:8 step:41200[D loss: 0.999979] [G loss: 1.000040]\n",
      "##############\n",
      "[2.67159856 2.21300303 2.15756195 3.67708501 1.48983344 6.47959495\n",
      " 2.41409965 3.91631514 4.0114737  4.75940158]\n",
      "##########\n",
      "epoch:8 step:41205[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:8 step:41210[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:8 step:41215[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:8 step:41220[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:8 step:41225[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:8 step:41230[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:8 step:41235[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:8 step:41240[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:8 step:41245[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:8 step:41250[D loss: 1.000015] [G loss: 1.000037]\n",
      "epoch:8 step:41255[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:8 step:41260[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:8 step:41265[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:8 step:41270[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:8 step:41275[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:8 step:41280[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:8 step:41285[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:8 step:41290[D loss: 0.999967] [G loss: 1.000126]\n",
      "epoch:8 step:41295[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:8 step:41300[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:8 step:41305[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:8 step:41310[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:8 step:41315[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:8 step:41320[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:8 step:41325[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:8 step:41330[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:41335[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:8 step:41340[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:8 step:41345[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:8 step:41350[D loss: 0.999970] [G loss: 1.000127]\n",
      "epoch:8 step:41355[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:8 step:41360[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:8 step:41365[D loss: 0.999971] [G loss: 1.000103]\n",
      "epoch:8 step:41370[D loss: 1.000019] [G loss: 0.999982]\n",
      "epoch:8 step:41375[D loss: 0.999979] [G loss: 1.000108]\n",
      "epoch:8 step:41380[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:8 step:41385[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:8 step:41390[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:8 step:41395[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:8 step:41400[D loss: 0.999964] [G loss: 1.000084]\n",
      "##############\n",
      "[2.6694523  2.22714189 2.1771469  3.72209984 1.49034043 7.3419435\n",
      " 2.16480584 3.88383354 3.92260086 5.03389106]\n",
      "##########\n",
      "epoch:8 step:41405[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:8 step:41410[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:8 step:41415[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:8 step:41420[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:8 step:41425[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:8 step:41430[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:8 step:41435[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:8 step:41440[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:8 step:41445[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:8 step:41450[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:8 step:41455[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:8 step:41460[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:8 step:41465[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:8 step:41470[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:8 step:41475[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:8 step:41480[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:8 step:41485[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:8 step:41490[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:8 step:41495[D loss: 0.999974] [G loss: 1.000108]\n",
      "epoch:8 step:41500[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:8 step:41505[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:8 step:41510[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:8 step:41515[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:8 step:41520[D loss: 0.999984] [G loss: 1.000090]\n",
      "epoch:8 step:41525[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:8 step:41530[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:8 step:41535[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:8 step:41540[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:8 step:41545[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:8 step:41550[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:8 step:41555[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:8 step:41560[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:8 step:41565[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:8 step:41570[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:8 step:41575[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:8 step:41580[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:8 step:41585[D loss: 1.000002] [G loss: 1.000068]\n",
      "epoch:8 step:41590[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:8 step:41595[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:8 step:41600[D loss: 0.999967] [G loss: 1.000061]\n",
      "##############\n",
      "[2.71284757 2.17429402 2.16401783 3.83947688 1.55630404 6.72181272\n",
      " 2.25401488 4.05220288 4.06331492 4.66612118]\n",
      "##########\n",
      "epoch:8 step:41605[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:8 step:41610[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:8 step:41615[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:8 step:41620[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:8 step:41625[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:8 step:41630[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:8 step:41635[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:8 step:41640[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:8 step:41645[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:8 step:41650[D loss: 1.000009] [G loss: 1.000087]\n",
      "epoch:8 step:41655[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:8 step:41660[D loss: 0.999949] [G loss: 1.000106]\n",
      "epoch:8 step:41665[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:8 step:41670[D loss: 0.999970] [G loss: 1.000097]\n",
      "epoch:8 step:41675[D loss: 0.999974] [G loss: 1.000127]\n",
      "epoch:8 step:41680[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:8 step:41685[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:8 step:41690[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:8 step:41695[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:8 step:41700[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:8 step:41705[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:8 step:41710[D loss: 0.999975] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:41715[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:8 step:41720[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:8 step:41725[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:8 step:41730[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:8 step:41735[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:8 step:41740[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:8 step:41745[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:8 step:41750[D loss: 1.000017] [G loss: 0.999952]\n",
      "epoch:8 step:41755[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:8 step:41760[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:8 step:41765[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:8 step:41770[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:8 step:41775[D loss: 1.000010] [G loss: 1.000038]\n",
      "epoch:8 step:41780[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:8 step:41785[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:8 step:41790[D loss: 0.999986] [G loss: 1.000016]\n",
      "epoch:8 step:41795[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:8 step:41800[D loss: 0.999973] [G loss: 1.000090]\n",
      "##############\n",
      "[2.67237587 2.1781639  2.16350751 3.60906557 1.51583521 7.53858613\n",
      " 2.30677404 3.72606305 3.96200916 5.05084485]\n",
      "##########\n",
      "epoch:8 step:41805[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:8 step:41810[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:8 step:41815[D loss: 1.000016] [G loss: 1.000039]\n",
      "epoch:8 step:41820[D loss: 1.000009] [G loss: 1.000003]\n",
      "epoch:8 step:41825[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:8 step:41830[D loss: 0.999980] [G loss: 1.000104]\n",
      "epoch:8 step:41835[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:8 step:41840[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:8 step:41845[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:8 step:41850[D loss: 0.999988] [G loss: 1.000020]\n",
      "epoch:8 step:41855[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:8 step:41860[D loss: 0.999995] [G loss: 0.999983]\n",
      "epoch:8 step:41865[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:8 step:41870[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:8 step:41875[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:8 step:41880[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:8 step:41885[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:8 step:41890[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:8 step:41895[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:8 step:41900[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:8 step:41905[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:8 step:41910[D loss: 1.000003] [G loss: 1.000015]\n",
      "epoch:8 step:41915[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:8 step:41920[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:8 step:41925[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:8 step:41930[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:8 step:41935[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:8 step:41940[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:8 step:41945[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:8 step:41950[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:8 step:41955[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:8 step:41960[D loss: 0.999991] [G loss: 1.000080]\n",
      "epoch:8 step:41965[D loss: 0.999939] [G loss: 1.000123]\n",
      "epoch:8 step:41970[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:8 step:41975[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:8 step:41980[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:8 step:41985[D loss: 1.000029] [G loss: 1.000019]\n",
      "epoch:8 step:41990[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:8 step:41995[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:8 step:42000[D loss: 0.999989] [G loss: 1.000025]\n",
      "##############\n",
      "[2.60031728 2.09426449 2.20253112 3.62592502 1.42977326 7.54493176\n",
      " 2.32263384 3.74532535 3.93591731 4.88349703]\n",
      "##########\n",
      "epoch:8 step:42005[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:8 step:42010[D loss: 1.000031] [G loss: 0.999956]\n",
      "epoch:8 step:42015[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:8 step:42020[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:8 step:42025[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:8 step:42030[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:8 step:42035[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:8 step:42040[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:8 step:42045[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:8 step:42050[D loss: 1.000002] [G loss: 1.000049]\n",
      "epoch:8 step:42055[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:8 step:42060[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:8 step:42065[D loss: 1.000056] [G loss: 0.999924]\n",
      "epoch:8 step:42070[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:8 step:42075[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:8 step:42080[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:8 step:42085[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:8 step:42090[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:8 step:42095[D loss: 0.999950] [G loss: 1.000093]\n",
      "epoch:8 step:42100[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:8 step:42105[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:8 step:42110[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:8 step:42115[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:8 step:42120[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:8 step:42125[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:8 step:42130[D loss: 0.999995] [G loss: 1.000002]\n",
      "epoch:8 step:42135[D loss: 1.000000] [G loss: 1.000053]\n",
      "epoch:8 step:42140[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:8 step:42145[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:8 step:42150[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:8 step:42155[D loss: 1.000014] [G loss: 1.000007]\n",
      "epoch:8 step:42160[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:8 step:42165[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:9 step:42170[D loss: 1.000020] [G loss: 1.000023]\n",
      "epoch:9 step:42175[D loss: 1.000001] [G loss: 1.000008]\n",
      "epoch:9 step:42180[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:9 step:42185[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:9 step:42190[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:9 step:42195[D loss: 0.999990] [G loss: 1.000082]\n",
      "epoch:9 step:42200[D loss: 0.999964] [G loss: 1.000084]\n",
      "##############\n",
      "[2.74562356 2.12851379 2.26173186 3.77883843 1.5405672  7.4128735\n",
      " 2.41746329 3.76645691 4.04298065 5.98282837]\n",
      "##########\n",
      "epoch:9 step:42205[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:9 step:42210[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:9 step:42215[D loss: 0.999998] [G loss: 1.000077]\n",
      "epoch:9 step:42220[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:9 step:42225[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:9 step:42230[D loss: 1.000028] [G loss: 0.999987]\n",
      "epoch:9 step:42235[D loss: 0.999985] [G loss: 1.000010]\n",
      "epoch:9 step:42240[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:9 step:42245[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:9 step:42250[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:9 step:42255[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:9 step:42260[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:9 step:42265[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:9 step:42270[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:9 step:42275[D loss: 0.999989] [G loss: 1.000082]\n",
      "epoch:9 step:42280[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:9 step:42285[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:9 step:42290[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:9 step:42295[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:9 step:42300[D loss: 0.999965] [G loss: 1.000137]\n",
      "epoch:9 step:42305[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:9 step:42310[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:9 step:42315[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:9 step:42320[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:9 step:42325[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:9 step:42330[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:9 step:42335[D loss: 1.000005] [G loss: 1.000089]\n",
      "epoch:9 step:42340[D loss: 0.999945] [G loss: 1.000113]\n",
      "epoch:9 step:42345[D loss: 0.999978] [G loss: 1.000114]\n",
      "epoch:9 step:42350[D loss: 0.999977] [G loss: 1.000144]\n",
      "epoch:9 step:42355[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:9 step:42360[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:9 step:42365[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:9 step:42370[D loss: 1.000028] [G loss: 1.000008]\n",
      "epoch:9 step:42375[D loss: 1.000051] [G loss: 0.999922]\n",
      "epoch:9 step:42380[D loss: 0.999912] [G loss: 1.000198]\n",
      "epoch:9 step:42385[D loss: 0.999946] [G loss: 1.000093]\n",
      "epoch:9 step:42390[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:9 step:42395[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:9 step:42400[D loss: 0.999984] [G loss: 1.000080]\n",
      "##############\n",
      "[2.677503   2.13941681 2.1517271  3.85749038 1.48561105 7.25089805\n",
      " 2.22248456 3.89181821 3.93637829 5.28018404]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:42405[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:9 step:42410[D loss: 1.000006] [G loss: 1.000012]\n",
      "epoch:9 step:42415[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:9 step:42420[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:9 step:42425[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:9 step:42430[D loss: 0.999995] [G loss: 1.000079]\n",
      "epoch:9 step:42435[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:9 step:42440[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:9 step:42445[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:9 step:42450[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:9 step:42455[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:9 step:42460[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:9 step:42465[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:9 step:42470[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:9 step:42475[D loss: 0.999973] [G loss: 1.000140]\n",
      "epoch:9 step:42480[D loss: 0.999955] [G loss: 1.000165]\n",
      "epoch:9 step:42485[D loss: 0.999952] [G loss: 1.000128]\n",
      "epoch:9 step:42490[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:9 step:42495[D loss: 1.000007] [G loss: 1.000015]\n",
      "epoch:9 step:42500[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:9 step:42505[D loss: 0.999953] [G loss: 1.000108]\n",
      "epoch:9 step:42510[D loss: 1.000007] [G loss: 1.000112]\n",
      "epoch:9 step:42515[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:9 step:42520[D loss: 0.999978] [G loss: 1.000120]\n",
      "epoch:9 step:42525[D loss: 0.999950] [G loss: 1.000185]\n",
      "epoch:9 step:42530[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:9 step:42535[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:9 step:42540[D loss: 1.000051] [G loss: 0.999950]\n",
      "epoch:9 step:42545[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:9 step:42550[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:9 step:42555[D loss: 0.999964] [G loss: 1.000110]\n",
      "epoch:9 step:42560[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:9 step:42565[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:9 step:42570[D loss: 0.999926] [G loss: 1.000159]\n",
      "epoch:9 step:42575[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:9 step:42580[D loss: 0.999949] [G loss: 1.000084]\n",
      "epoch:9 step:42585[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:9 step:42590[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:9 step:42595[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:9 step:42600[D loss: 1.000004] [G loss: 1.000027]\n",
      "##############\n",
      "[2.62459537 2.13988968 2.20275756 3.51215408 1.51785519 7.20244661\n",
      " 2.16828507 3.96898755 3.91117171 5.87516916]\n",
      "##########\n",
      "epoch:9 step:42605[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:9 step:42610[D loss: 0.999973] [G loss: 1.000124]\n",
      "epoch:9 step:42615[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:9 step:42620[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:9 step:42625[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:9 step:42630[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:9 step:42635[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:9 step:42640[D loss: 1.000014] [G loss: 1.000015]\n",
      "epoch:9 step:42645[D loss: 1.000015] [G loss: 1.000025]\n",
      "epoch:9 step:42650[D loss: 0.999954] [G loss: 1.000129]\n",
      "epoch:9 step:42655[D loss: 0.999973] [G loss: 1.000127]\n",
      "epoch:9 step:42660[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:9 step:42665[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:9 step:42670[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:9 step:42675[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:9 step:42680[D loss: 0.999970] [G loss: 1.000108]\n",
      "epoch:9 step:42685[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:9 step:42690[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:9 step:42695[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:9 step:42700[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:9 step:42705[D loss: 0.999955] [G loss: 1.000121]\n",
      "epoch:9 step:42710[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:9 step:42715[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:9 step:42720[D loss: 0.999973] [G loss: 1.000099]\n",
      "epoch:9 step:42725[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:9 step:42730[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:9 step:42735[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:9 step:42740[D loss: 0.999961] [G loss: 1.000105]\n",
      "epoch:9 step:42745[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:9 step:42750[D loss: 1.000020] [G loss: 1.000028]\n",
      "epoch:9 step:42755[D loss: 0.999988] [G loss: 1.000097]\n",
      "epoch:9 step:42760[D loss: 0.999960] [G loss: 1.000141]\n",
      "epoch:9 step:42765[D loss: 0.999904] [G loss: 1.000163]\n",
      "epoch:9 step:42770[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:9 step:42775[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:9 step:42780[D loss: 0.999944] [G loss: 1.000110]\n",
      "epoch:9 step:42785[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:9 step:42790[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:9 step:42795[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:9 step:42800[D loss: 0.999978] [G loss: 1.000080]\n",
      "##############\n",
      "[2.61816099 2.14501634 2.16977881 3.68355543 1.42783797 7.00668186\n",
      " 2.28039096 3.63663538 3.8916194  5.06741438]\n",
      "##########\n",
      "epoch:9 step:42805[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:9 step:42810[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:9 step:42815[D loss: 0.999997] [G loss: 1.000067]\n",
      "epoch:9 step:42820[D loss: 0.999996] [G loss: 1.000068]\n",
      "epoch:9 step:42825[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:9 step:42830[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:9 step:42835[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:9 step:42840[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:9 step:42845[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:9 step:42850[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:9 step:42855[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:9 step:42860[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:9 step:42865[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:9 step:42870[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:9 step:42875[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:9 step:42880[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:9 step:42885[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:9 step:42890[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:9 step:42895[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:9 step:42900[D loss: 0.999999] [G loss: 1.000084]\n",
      "epoch:9 step:42905[D loss: 0.999952] [G loss: 1.000091]\n",
      "epoch:9 step:42910[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:9 step:42915[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:9 step:42920[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:9 step:42925[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:9 step:42930[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:9 step:42935[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:9 step:42940[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:9 step:42945[D loss: 0.999994] [G loss: 1.000063]\n",
      "epoch:9 step:42950[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:9 step:42955[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:9 step:42960[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:9 step:42965[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:9 step:42970[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:9 step:42975[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:9 step:42980[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:9 step:42985[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:9 step:42990[D loss: 0.999988] [G loss: 1.000086]\n",
      "epoch:9 step:42995[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:9 step:43000[D loss: 0.999967] [G loss: 1.000078]\n",
      "##############\n",
      "[2.69498169 2.10345106 2.28315259 3.84781369 1.53942269 7.46862962\n",
      " 2.39936048 3.97487557 4.06137211 5.12113039]\n",
      "##########\n",
      "epoch:9 step:43005[D loss: 1.000018] [G loss: 1.000005]\n",
      "epoch:9 step:43010[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:9 step:43015[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:9 step:43020[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:9 step:43025[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:9 step:43030[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:9 step:43035[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:9 step:43040[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:9 step:43045[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:9 step:43050[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:9 step:43055[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:9 step:43060[D loss: 0.999977] [G loss: 1.000105]\n",
      "epoch:9 step:43065[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:9 step:43070[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:9 step:43075[D loss: 0.999973] [G loss: 1.000111]\n",
      "epoch:9 step:43080[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:9 step:43085[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:9 step:43090[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:9 step:43095[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:9 step:43100[D loss: 0.999990] [G loss: 1.000063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:43105[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:9 step:43110[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:9 step:43115[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:9 step:43120[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:9 step:43125[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:9 step:43130[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:9 step:43135[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:9 step:43140[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:9 step:43145[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:9 step:43150[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:9 step:43155[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:9 step:43160[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:9 step:43165[D loss: 1.000009] [G loss: 1.000061]\n",
      "epoch:9 step:43170[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:9 step:43175[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:9 step:43180[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:9 step:43185[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:9 step:43190[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:9 step:43195[D loss: 1.000010] [G loss: 1.000004]\n",
      "epoch:9 step:43200[D loss: 1.000034] [G loss: 1.000022]\n",
      "##############\n",
      "[2.65942484 2.12257777 2.20988548 3.5662985  1.51829155 7.42338633\n",
      " 2.18376717 3.79520664 3.94875252 5.2396749 ]\n",
      "##########\n",
      "epoch:9 step:43205[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:9 step:43210[D loss: 1.000006] [G loss: 1.000050]\n",
      "epoch:9 step:43215[D loss: 0.999997] [G loss: 1.000070]\n",
      "epoch:9 step:43220[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:9 step:43225[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:9 step:43230[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:9 step:43235[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:9 step:43240[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:9 step:43245[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:9 step:43250[D loss: 0.999984] [G loss: 1.000144]\n",
      "epoch:9 step:43255[D loss: 0.999940] [G loss: 1.000150]\n",
      "epoch:9 step:43260[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:9 step:43265[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:9 step:43270[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:9 step:43275[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:9 step:43280[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:9 step:43285[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:9 step:43290[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:9 step:43295[D loss: 1.000003] [G loss: 1.000052]\n",
      "epoch:9 step:43300[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:9 step:43305[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:9 step:43310[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:9 step:43315[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:9 step:43320[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:9 step:43325[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:9 step:43330[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:9 step:43335[D loss: 0.999979] [G loss: 1.000092]\n",
      "epoch:9 step:43340[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:9 step:43345[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:9 step:43350[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:9 step:43355[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:9 step:43360[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:9 step:43365[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:9 step:43370[D loss: 1.000016] [G loss: 1.000008]\n",
      "epoch:9 step:43375[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:9 step:43380[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:9 step:43385[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:9 step:43390[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:9 step:43395[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:9 step:43400[D loss: 0.999996] [G loss: 1.000032]\n",
      "##############\n",
      "[2.59341202 2.19231146 2.27744971 3.63539405 1.53500692 6.89142246\n",
      " 2.24153578 3.74894859 3.91177372 5.91447141]\n",
      "##########\n",
      "epoch:9 step:43405[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:9 step:43410[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:9 step:43415[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:9 step:43420[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:9 step:43425[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:9 step:43430[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:9 step:43435[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:9 step:43440[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:9 step:43445[D loss: 1.000007] [G loss: 1.000023]\n",
      "epoch:9 step:43450[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:9 step:43455[D loss: 0.999971] [G loss: 1.000127]\n",
      "epoch:9 step:43460[D loss: 0.999920] [G loss: 1.000125]\n",
      "epoch:9 step:43465[D loss: 0.999959] [G loss: 1.000113]\n",
      "epoch:9 step:43470[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:9 step:43475[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:9 step:43480[D loss: 1.000053] [G loss: 1.000005]\n",
      "epoch:9 step:43485[D loss: 0.999967] [G loss: 1.000030]\n",
      "epoch:9 step:43490[D loss: 0.999947] [G loss: 1.000065]\n",
      "epoch:9 step:43495[D loss: 1.000010] [G loss: 1.000057]\n",
      "epoch:9 step:43500[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:9 step:43505[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:9 step:43510[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:9 step:43515[D loss: 1.000023] [G loss: 0.999989]\n",
      "epoch:9 step:43520[D loss: 0.999932] [G loss: 1.000105]\n",
      "epoch:9 step:43525[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:9 step:43530[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:9 step:43535[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:9 step:43540[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:9 step:43545[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:9 step:43550[D loss: 0.999960] [G loss: 1.000104]\n",
      "epoch:9 step:43555[D loss: 0.999961] [G loss: 1.000109]\n",
      "epoch:9 step:43560[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:9 step:43565[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:9 step:43570[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:9 step:43575[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:9 step:43580[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:9 step:43585[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:9 step:43590[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:9 step:43595[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:9 step:43600[D loss: 0.999972] [G loss: 1.000061]\n",
      "##############\n",
      "[2.66786164 2.17142565 2.23813602 3.95319787 1.54270754 7.95032893\n",
      " 2.17092311 3.78746616 3.9976546  7.14673616]\n",
      "##########\n",
      "epoch:9 step:43605[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:9 step:43610[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:9 step:43615[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:9 step:43620[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:9 step:43625[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:9 step:43630[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:9 step:43635[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:9 step:43640[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:9 step:43645[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:9 step:43650[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:9 step:43655[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:9 step:43660[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:9 step:43665[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:9 step:43670[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:9 step:43675[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:9 step:43680[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:9 step:43685[D loss: 1.000005] [G loss: 1.000032]\n",
      "epoch:9 step:43690[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:9 step:43695[D loss: 1.000031] [G loss: 0.999969]\n",
      "epoch:9 step:43700[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:9 step:43705[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:9 step:43710[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:9 step:43715[D loss: 1.000006] [G loss: 0.999993]\n",
      "epoch:9 step:43720[D loss: 1.000001] [G loss: 1.000047]\n",
      "epoch:9 step:43725[D loss: 0.999947] [G loss: 1.000090]\n",
      "epoch:9 step:43730[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:9 step:43735[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:9 step:43740[D loss: 0.999979] [G loss: 1.000100]\n",
      "epoch:9 step:43745[D loss: 0.999988] [G loss: 1.000158]\n",
      "epoch:9 step:43750[D loss: 0.999928] [G loss: 1.000088]\n",
      "epoch:9 step:43755[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:9 step:43760[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:9 step:43765[D loss: 0.999966] [G loss: 1.000040]\n",
      "epoch:9 step:43770[D loss: 1.000078] [G loss: 0.999962]\n",
      "epoch:9 step:43775[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:9 step:43780[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:9 step:43785[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:9 step:43790[D loss: 0.999990] [G loss: 1.000006]\n",
      "epoch:9 step:43795[D loss: 0.999981] [G loss: 1.000042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:43800[D loss: 0.999976] [G loss: 1.000058]\n",
      "##############\n",
      "[2.63562153 2.17459745 2.28896409 3.92992691 1.49464007 6.78366924\n",
      " 2.31102421 3.88213431 4.04750161 4.88380519]\n",
      "##########\n",
      "epoch:9 step:43805[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:9 step:43810[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:9 step:43815[D loss: 1.000011] [G loss: 1.000055]\n",
      "epoch:9 step:43820[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:9 step:43825[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:9 step:43830[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:9 step:43835[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:9 step:43840[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:9 step:43845[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:9 step:43850[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:9 step:43855[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:9 step:43860[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:9 step:43865[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:9 step:43870[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:9 step:43875[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:9 step:43880[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:9 step:43885[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:9 step:43890[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:9 step:43895[D loss: 1.000017] [G loss: 1.000071]\n",
      "epoch:9 step:43900[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:9 step:43905[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:9 step:43910[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:9 step:43915[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:9 step:43920[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:9 step:43925[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:9 step:43930[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:9 step:43935[D loss: 0.999986] [G loss: 1.000086]\n",
      "epoch:9 step:43940[D loss: 0.999966] [G loss: 1.000108]\n",
      "epoch:9 step:43945[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:9 step:43950[D loss: 0.999961] [G loss: 1.000105]\n",
      "epoch:9 step:43955[D loss: 1.000050] [G loss: 1.000000]\n",
      "epoch:9 step:43960[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:9 step:43965[D loss: 0.999979] [G loss: 1.000129]\n",
      "epoch:9 step:43970[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:9 step:43975[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:9 step:43980[D loss: 0.999992] [G loss: 1.000094]\n",
      "epoch:9 step:43985[D loss: 1.000011] [G loss: 1.000091]\n",
      "epoch:9 step:43990[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:9 step:43995[D loss: 0.999919] [G loss: 1.000133]\n",
      "epoch:9 step:44000[D loss: 0.999999] [G loss: 1.000095]\n",
      "##############\n",
      "[2.63337383 2.13563275 2.24846979 3.47900292 1.5484741  7.19277954\n",
      " 2.25891048 3.76694788 3.95485338 4.61457873]\n",
      "##########\n",
      "epoch:9 step:44005[D loss: 0.999952] [G loss: 1.000134]\n",
      "epoch:9 step:44010[D loss: 0.999974] [G loss: 1.000099]\n",
      "epoch:9 step:44015[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:9 step:44020[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:9 step:44025[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:9 step:44030[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:9 step:44035[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:9 step:44040[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:9 step:44045[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:9 step:44050[D loss: 1.000019] [G loss: 0.999991]\n",
      "epoch:9 step:44055[D loss: 0.999962] [G loss: 1.000162]\n",
      "epoch:9 step:44060[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:9 step:44065[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:9 step:44070[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:9 step:44075[D loss: 0.999933] [G loss: 1.000093]\n",
      "epoch:9 step:44080[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:9 step:44085[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:9 step:44090[D loss: 1.000032] [G loss: 1.000002]\n",
      "epoch:9 step:44095[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:9 step:44100[D loss: 1.000011] [G loss: 1.000047]\n",
      "epoch:9 step:44105[D loss: 0.999984] [G loss: 1.000101]\n",
      "epoch:9 step:44110[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:9 step:44115[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:9 step:44120[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:9 step:44125[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:9 step:44130[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:9 step:44135[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:9 step:44140[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:9 step:44145[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:9 step:44150[D loss: 1.000007] [G loss: 1.000030]\n",
      "epoch:9 step:44155[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:9 step:44160[D loss: 0.999989] [G loss: 1.000090]\n",
      "epoch:9 step:44165[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:9 step:44170[D loss: 0.999973] [G loss: 1.000109]\n",
      "epoch:9 step:44175[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:9 step:44180[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:9 step:44185[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:9 step:44190[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:9 step:44195[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:9 step:44200[D loss: 1.000004] [G loss: 1.000057]\n",
      "##############\n",
      "[2.56705173 2.16481325 2.19904296 3.63078868 1.48129185 6.90329837\n",
      " 2.19275134 3.76065898 3.97652637 5.1754258 ]\n",
      "##########\n",
      "epoch:9 step:44205[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:9 step:44210[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:9 step:44215[D loss: 0.999969] [G loss: 1.000144]\n",
      "epoch:9 step:44220[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:9 step:44225[D loss: 1.000029] [G loss: 1.000020]\n",
      "epoch:9 step:44230[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:9 step:44235[D loss: 0.999993] [G loss: 1.000081]\n",
      "epoch:9 step:44240[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:9 step:44245[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:9 step:44250[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:9 step:44255[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:9 step:44260[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:9 step:44265[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:9 step:44270[D loss: 1.000008] [G loss: 1.000048]\n",
      "epoch:9 step:44275[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:9 step:44280[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:9 step:44285[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:9 step:44290[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:9 step:44295[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:9 step:44300[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:9 step:44305[D loss: 1.000002] [G loss: 1.000014]\n",
      "epoch:9 step:44310[D loss: 0.999999] [G loss: 1.000065]\n",
      "epoch:9 step:44315[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:9 step:44320[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:9 step:44325[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:9 step:44330[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:9 step:44335[D loss: 1.000005] [G loss: 1.000055]\n",
      "epoch:9 step:44340[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:9 step:44345[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:9 step:44350[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:9 step:44355[D loss: 1.000011] [G loss: 1.000068]\n",
      "epoch:9 step:44360[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:9 step:44365[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:9 step:44370[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:9 step:44375[D loss: 1.000012] [G loss: 1.000021]\n",
      "epoch:9 step:44380[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:9 step:44385[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:9 step:44390[D loss: 0.999954] [G loss: 1.000075]\n",
      "epoch:9 step:44395[D loss: 0.999983] [G loss: 1.000095]\n",
      "epoch:9 step:44400[D loss: 0.999988] [G loss: 1.000087]\n",
      "##############\n",
      "[2.62877854 2.1328548  2.20313031 3.57675043 1.50779987 7.12857767\n",
      " 2.08835113 3.86484974 3.96355737 5.45713522]\n",
      "##########\n",
      "epoch:9 step:44405[D loss: 0.999998] [G loss: 1.000074]\n",
      "epoch:9 step:44410[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:9 step:44415[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:9 step:44420[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:9 step:44425[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:9 step:44430[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:9 step:44435[D loss: 0.999974] [G loss: 1.000103]\n",
      "epoch:9 step:44440[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:9 step:44445[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:9 step:44450[D loss: 0.999999] [G loss: 1.000084]\n",
      "epoch:9 step:44455[D loss: 1.000016] [G loss: 1.000011]\n",
      "epoch:9 step:44460[D loss: 1.000026] [G loss: 1.000167]\n",
      "epoch:9 step:44465[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:9 step:44470[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:9 step:44475[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:9 step:44480[D loss: 0.999975] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:44485[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:9 step:44490[D loss: 0.999996] [G loss: 0.999997]\n",
      "epoch:9 step:44495[D loss: 0.999953] [G loss: 1.000056]\n",
      "epoch:9 step:44500[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:9 step:44505[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:9 step:44510[D loss: 1.000086] [G loss: 0.999920]\n",
      "epoch:9 step:44515[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:9 step:44520[D loss: 0.999963] [G loss: 1.000128]\n",
      "epoch:9 step:44525[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:9 step:44530[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:9 step:44535[D loss: 1.000003] [G loss: 1.000044]\n",
      "epoch:9 step:44540[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:9 step:44545[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:9 step:44550[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:9 step:44555[D loss: 0.999977] [G loss: 1.000104]\n",
      "epoch:9 step:44560[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:9 step:44565[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:9 step:44570[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:9 step:44575[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:9 step:44580[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:9 step:44585[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:9 step:44590[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:9 step:44595[D loss: 0.999963] [G loss: 1.000119]\n",
      "epoch:9 step:44600[D loss: 0.999985] [G loss: 1.000064]\n",
      "##############\n",
      "[2.63691916 2.15596631 2.17873293 3.65049985 1.46984381 7.43538355\n",
      " 2.31190447 3.80636575 3.93036547 4.1480401 ]\n",
      "##########\n",
      "epoch:9 step:44605[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:9 step:44610[D loss: 0.999949] [G loss: 1.000121]\n",
      "epoch:9 step:44615[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:9 step:44620[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:9 step:44625[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:9 step:44630[D loss: 0.999970] [G loss: 1.000131]\n",
      "epoch:9 step:44635[D loss: 0.999995] [G loss: 1.000085]\n",
      "epoch:9 step:44640[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:9 step:44645[D loss: 1.000047] [G loss: 1.000060]\n",
      "epoch:9 step:44650[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:9 step:44655[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:9 step:44660[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:9 step:44665[D loss: 1.000018] [G loss: 1.000019]\n",
      "epoch:9 step:44670[D loss: 0.999976] [G loss: 1.000002]\n",
      "epoch:9 step:44675[D loss: 0.999954] [G loss: 1.000092]\n",
      "epoch:9 step:44680[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:9 step:44685[D loss: 0.999975] [G loss: 1.000099]\n",
      "epoch:9 step:44690[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:9 step:44695[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:9 step:44700[D loss: 0.999996] [G loss: 1.000110]\n",
      "epoch:9 step:44705[D loss: 1.000007] [G loss: 1.000081]\n",
      "epoch:9 step:44710[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:9 step:44715[D loss: 0.999977] [G loss: 1.000198]\n",
      "epoch:9 step:44720[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:9 step:44725[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:9 step:44730[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:9 step:44735[D loss: 1.000005] [G loss: 1.000013]\n",
      "epoch:9 step:44740[D loss: 0.999951] [G loss: 1.000106]\n",
      "epoch:9 step:44745[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:9 step:44750[D loss: 1.000004] [G loss: 1.000123]\n",
      "epoch:9 step:44755[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:9 step:44760[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:9 step:44765[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:9 step:44770[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:9 step:44775[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:9 step:44780[D loss: 0.999948] [G loss: 1.000089]\n",
      "epoch:9 step:44785[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:9 step:44790[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:9 step:44795[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:9 step:44800[D loss: 0.999987] [G loss: 1.000053]\n",
      "##############\n",
      "[2.6056198  2.23444391 2.33131155 3.79044567 1.53484852 9.27426719\n",
      " 2.38378683 3.94344847 3.99243364 4.72281577]\n",
      "##########\n",
      "epoch:9 step:44805[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:9 step:44810[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:9 step:44815[D loss: 1.000008] [G loss: 1.000031]\n",
      "epoch:9 step:44820[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:9 step:44825[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:9 step:44830[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:9 step:44835[D loss: 1.000019] [G loss: 1.000077]\n",
      "epoch:9 step:44840[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:9 step:44845[D loss: 0.999974] [G loss: 1.000137]\n",
      "epoch:9 step:44850[D loss: 0.999993] [G loss: 1.000097]\n",
      "epoch:9 step:44855[D loss: 0.999984] [G loss: 1.000093]\n",
      "epoch:9 step:44860[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:9 step:44865[D loss: 0.999941] [G loss: 1.000110]\n",
      "epoch:9 step:44870[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:9 step:44875[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:9 step:44880[D loss: 1.000035] [G loss: 0.999979]\n",
      "epoch:9 step:44885[D loss: 1.000034] [G loss: 1.000004]\n",
      "epoch:9 step:44890[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:9 step:44895[D loss: 1.000008] [G loss: 1.000012]\n",
      "epoch:9 step:44900[D loss: 0.999939] [G loss: 1.000089]\n",
      "epoch:9 step:44905[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:9 step:44910[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:9 step:44915[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:9 step:44920[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:9 step:44925[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:9 step:44930[D loss: 1.000019] [G loss: 1.000008]\n",
      "epoch:9 step:44935[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:9 step:44940[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:9 step:44945[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:9 step:44950[D loss: 0.999993] [G loss: 1.000076]\n",
      "epoch:9 step:44955[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:9 step:44960[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:9 step:44965[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:9 step:44970[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:9 step:44975[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:9 step:44980[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:9 step:44985[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:9 step:44990[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:9 step:44995[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:9 step:45000[D loss: 0.999977] [G loss: 1.000066]\n",
      "##############\n",
      "[2.64837895 2.22664996 2.22208854 3.83308957 1.47693672 9.27426719\n",
      " 2.46315134 3.94741079 3.96914357 5.20048346]\n",
      "##########\n",
      "epoch:9 step:45005[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:9 step:45010[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:9 step:45015[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:9 step:45020[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:9 step:45025[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:9 step:45030[D loss: 1.000016] [G loss: 1.000016]\n",
      "epoch:9 step:45035[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:9 step:45040[D loss: 1.000005] [G loss: 1.000066]\n",
      "epoch:9 step:45045[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:9 step:45050[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:9 step:45055[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:9 step:45060[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:9 step:45065[D loss: 0.999999] [G loss: 1.000065]\n",
      "epoch:9 step:45070[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:9 step:45075[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:9 step:45080[D loss: 1.000001] [G loss: 0.999977]\n",
      "epoch:9 step:45085[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:9 step:45090[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:9 step:45095[D loss: 0.999992] [G loss: 1.000061]\n",
      "epoch:9 step:45100[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:9 step:45105[D loss: 0.999991] [G loss: 1.000079]\n",
      "epoch:9 step:45110[D loss: 1.000063] [G loss: 0.999988]\n",
      "epoch:9 step:45115[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:9 step:45120[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:9 step:45125[D loss: 0.999974] [G loss: 1.000110]\n",
      "epoch:9 step:45130[D loss: 1.000002] [G loss: 1.000056]\n",
      "epoch:9 step:45135[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:9 step:45140[D loss: 0.999993] [G loss: 1.000089]\n",
      "epoch:9 step:45145[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:9 step:45150[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:9 step:45155[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:9 step:45160[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:9 step:45165[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:9 step:45170[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:9 step:45175[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:9 step:45180[D loss: 0.999962] [G loss: 1.000088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:45185[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:9 step:45190[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:9 step:45195[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:9 step:45200[D loss: 1.000025] [G loss: 0.999975]\n",
      "##############\n",
      "[2.67238801 2.16502902 2.28181327 3.67572724 1.49298421 7.03151387\n",
      " 2.46133926 4.01710367 3.96518522 5.30324302]\n",
      "##########\n",
      "epoch:9 step:45205[D loss: 0.999945] [G loss: 1.000145]\n",
      "epoch:9 step:45210[D loss: 1.000021] [G loss: 1.000078]\n",
      "epoch:9 step:45215[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:9 step:45220[D loss: 1.000003] [G loss: 1.000058]\n",
      "epoch:9 step:45225[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:9 step:45230[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:9 step:45235[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:9 step:45240[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:9 step:45245[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:9 step:45250[D loss: 1.000017] [G loss: 1.000036]\n",
      "epoch:9 step:45255[D loss: 1.000006] [G loss: 1.000011]\n",
      "epoch:9 step:45260[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:9 step:45265[D loss: 0.999982] [G loss: 1.000088]\n",
      "epoch:9 step:45270[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:9 step:45275[D loss: 0.999978] [G loss: 1.000095]\n",
      "epoch:9 step:45280[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:9 step:45285[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:9 step:45290[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:9 step:45295[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:9 step:45300[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:9 step:45305[D loss: 0.999937] [G loss: 1.000108]\n",
      "epoch:9 step:45310[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:9 step:45315[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:9 step:45320[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:9 step:45325[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:9 step:45330[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:9 step:45335[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:9 step:45340[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:9 step:45345[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:9 step:45350[D loss: 1.000031] [G loss: 0.999988]\n",
      "epoch:9 step:45355[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:9 step:45360[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:9 step:45365[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:9 step:45370[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:9 step:45375[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:9 step:45380[D loss: 0.999998] [G loss: 1.000009]\n",
      "epoch:9 step:45385[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:9 step:45390[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:9 step:45395[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:9 step:45400[D loss: 0.999972] [G loss: 1.000078]\n",
      "##############\n",
      "[2.57482162 2.09196055 2.19435123 3.75215318 1.43134217 6.97720722\n",
      " 2.11848646 3.84932868 3.92725413 4.80642811]\n",
      "##########\n",
      "epoch:9 step:45405[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:9 step:45410[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:9 step:45415[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:9 step:45420[D loss: 0.999985] [G loss: 1.000105]\n",
      "epoch:9 step:45425[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:9 step:45430[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:9 step:45435[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:9 step:45440[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:9 step:45445[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:9 step:45450[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:9 step:45455[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:9 step:45460[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:9 step:45465[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:9 step:45470[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:9 step:45475[D loss: 1.000042] [G loss: 0.999981]\n",
      "epoch:9 step:45480[D loss: 1.000022] [G loss: 1.000031]\n",
      "epoch:9 step:45485[D loss: 0.999946] [G loss: 1.000089]\n",
      "epoch:9 step:45490[D loss: 0.999975] [G loss: 1.000028]\n",
      "epoch:9 step:45495[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:9 step:45500[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:9 step:45505[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:9 step:45510[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:9 step:45515[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:9 step:45520[D loss: 0.999965] [G loss: 1.000049]\n",
      "epoch:9 step:45525[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:9 step:45530[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:9 step:45535[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:9 step:45540[D loss: 1.000003] [G loss: 0.999998]\n",
      "epoch:9 step:45545[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:9 step:45550[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:9 step:45555[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:9 step:45560[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:9 step:45565[D loss: 1.000003] [G loss: 1.000010]\n",
      "epoch:9 step:45570[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:9 step:45575[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:9 step:45580[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:9 step:45585[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:9 step:45590[D loss: 1.000002] [G loss: 1.000077]\n",
      "epoch:9 step:45595[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:9 step:45600[D loss: 0.999963] [G loss: 1.000061]\n",
      "##############\n",
      "[2.60450491 2.13302484 1.96543803 3.7689679  1.45953412 7.84223959\n",
      " 2.29840676 3.65660046 3.97728181 5.24715332]\n",
      "##########\n",
      "epoch:9 step:45605[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:9 step:45610[D loss: 1.000015] [G loss: 1.000047]\n",
      "epoch:9 step:45615[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:9 step:45620[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:9 step:45625[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:9 step:45630[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:9 step:45635[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:9 step:45640[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:9 step:45645[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:9 step:45650[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:9 step:45655[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:9 step:45660[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:9 step:45665[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:9 step:45670[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:9 step:45675[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:9 step:45680[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:9 step:45685[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:9 step:45690[D loss: 0.999959] [G loss: 1.000145]\n",
      "epoch:9 step:45695[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:9 step:45700[D loss: 0.999960] [G loss: 1.000121]\n",
      "epoch:9 step:45705[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:9 step:45710[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:9 step:45715[D loss: 1.000050] [G loss: 0.999960]\n",
      "epoch:9 step:45720[D loss: 0.999926] [G loss: 1.000125]\n",
      "epoch:9 step:45725[D loss: 0.999997] [G loss: 1.000007]\n",
      "epoch:9 step:45730[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:9 step:45735[D loss: 1.000031] [G loss: 1.000012]\n",
      "epoch:9 step:45740[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:9 step:45745[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:9 step:45750[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:9 step:45755[D loss: 0.999937] [G loss: 1.000105]\n",
      "epoch:9 step:45760[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:9 step:45765[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:9 step:45770[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:9 step:45775[D loss: 1.000025] [G loss: 1.000021]\n",
      "epoch:9 step:45780[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:9 step:45785[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:9 step:45790[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:9 step:45795[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:9 step:45800[D loss: 0.999988] [G loss: 1.000093]\n",
      "##############\n",
      "[2.50181394 2.04184626 2.10904752 3.60594627 1.37594808 7.17369783\n",
      " 2.26973358 3.79142815 3.89500294 4.9706917 ]\n",
      "##########\n",
      "epoch:9 step:45805[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:9 step:45810[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:9 step:45815[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:9 step:45820[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:9 step:45825[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:9 step:45830[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:9 step:45835[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:9 step:45840[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:9 step:45845[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:9 step:45850[D loss: 0.999986] [G loss: 1.000108]\n",
      "epoch:9 step:45855[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:9 step:45860[D loss: 1.000001] [G loss: 1.000061]\n",
      "epoch:9 step:45865[D loss: 0.999930] [G loss: 1.000090]\n",
      "epoch:9 step:45870[D loss: 0.999975] [G loss: 1.000083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:45875[D loss: 1.000083] [G loss: 0.999917]\n",
      "epoch:9 step:45880[D loss: 0.999931] [G loss: 1.000039]\n",
      "epoch:9 step:45885[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:9 step:45890[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:9 step:45895[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:9 step:45900[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:9 step:45905[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:9 step:45910[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:9 step:45915[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:9 step:45920[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:9 step:45925[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:9 step:45930[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:9 step:45935[D loss: 0.999994] [G loss: 1.000079]\n",
      "epoch:9 step:45940[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:9 step:45945[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:9 step:45950[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:9 step:45955[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:9 step:45960[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:9 step:45965[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:9 step:45970[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:9 step:45975[D loss: 0.999988] [G loss: 1.000123]\n",
      "epoch:9 step:45980[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:9 step:45985[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:9 step:45990[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:9 step:45995[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:9 step:46000[D loss: 0.999973] [G loss: 1.000060]\n",
      "##############\n",
      "[2.61499588 2.15934404 2.20137984 3.72162377 1.45176003 6.97519016\n",
      " 2.21705131 3.91871016 3.9778857  5.08899519]\n",
      "##########\n",
      "epoch:9 step:46005[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:9 step:46010[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:9 step:46015[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:9 step:46020[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:9 step:46025[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:9 step:46030[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:9 step:46035[D loss: 0.999977] [G loss: 1.000128]\n",
      "epoch:9 step:46040[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:9 step:46045[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:9 step:46050[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:9 step:46055[D loss: 1.000015] [G loss: 1.000006]\n",
      "epoch:9 step:46060[D loss: 1.000066] [G loss: 0.999925]\n",
      "epoch:9 step:46065[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:9 step:46070[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:9 step:46075[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:9 step:46080[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:9 step:46085[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:9 step:46090[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:9 step:46095[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:9 step:46100[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:9 step:46105[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:9 step:46110[D loss: 0.999943] [G loss: 1.000176]\n",
      "epoch:9 step:46115[D loss: 0.999956] [G loss: 1.000066]\n",
      "epoch:9 step:46120[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:9 step:46125[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:9 step:46130[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:9 step:46135[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:9 step:46140[D loss: 1.000006] [G loss: 1.000014]\n",
      "epoch:9 step:46145[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:9 step:46150[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:9 step:46155[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:9 step:46160[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:9 step:46165[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:9 step:46170[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:9 step:46175[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:9 step:46180[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:9 step:46185[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:9 step:46190[D loss: 0.999994] [G loss: 1.000048]\n",
      "epoch:9 step:46195[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:9 step:46200[D loss: 1.000005] [G loss: 1.000047]\n",
      "##############\n",
      "[2.57302635 2.12530612 2.24125914 3.83742057 1.38534845 8.41964173\n",
      " 2.29688288 3.67969102 3.92884388 5.29179808]\n",
      "##########\n",
      "epoch:9 step:46205[D loss: 1.000011] [G loss: 1.000095]\n",
      "epoch:9 step:46210[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:9 step:46215[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:9 step:46220[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:9 step:46225[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:9 step:46230[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:9 step:46235[D loss: 1.000001] [G loss: 1.000024]\n",
      "epoch:9 step:46240[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:9 step:46245[D loss: 1.000000] [G loss: 0.999988]\n",
      "epoch:9 step:46250[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:9 step:46255[D loss: 1.000008] [G loss: 1.000023]\n",
      "epoch:9 step:46260[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:9 step:46265[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:9 step:46270[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:9 step:46275[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:9 step:46280[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:9 step:46285[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:9 step:46290[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:9 step:46295[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:9 step:46300[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:9 step:46305[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:9 step:46310[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:9 step:46315[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:9 step:46320[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:9 step:46325[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:9 step:46330[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:9 step:46335[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:9 step:46340[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:9 step:46345[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:9 step:46350[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:9 step:46355[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:9 step:46360[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:9 step:46365[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:9 step:46370[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:9 step:46375[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:9 step:46380[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:9 step:46385[D loss: 0.999945] [G loss: 1.000131]\n",
      "epoch:9 step:46390[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:9 step:46395[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:9 step:46400[D loss: 0.999973] [G loss: 1.000102]\n",
      "##############\n",
      "[ 2.6545037   2.14520362  2.21393593  3.83830433  1.40096039 10.27426719\n",
      "  2.25646258  3.842808    3.96863063  5.18135439]\n",
      "##########\n",
      "epoch:9 step:46405[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:9 step:46410[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:9 step:46415[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:9 step:46420[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:9 step:46425[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:9 step:46430[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:9 step:46435[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:9 step:46440[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:9 step:46445[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:9 step:46450[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:9 step:46455[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:9 step:46460[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:9 step:46465[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:9 step:46470[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:9 step:46475[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:9 step:46480[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:9 step:46485[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:9 step:46490[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:9 step:46495[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:9 step:46500[D loss: 1.000015] [G loss: 1.000025]\n",
      "epoch:9 step:46505[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:9 step:46510[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:9 step:46515[D loss: 0.999983] [G loss: 1.000100]\n",
      "epoch:9 step:46520[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:9 step:46525[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:9 step:46530[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:9 step:46535[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:9 step:46540[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:9 step:46545[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:9 step:46550[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:9 step:46555[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:9 step:46560[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:9 step:46565[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:9 step:46570[D loss: 0.999969] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:46575[D loss: 1.000003] [G loss: 0.999994]\n",
      "epoch:9 step:46580[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:9 step:46585[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:9 step:46590[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:9 step:46595[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:9 step:46600[D loss: 0.999967] [G loss: 1.000075]\n",
      "##############\n",
      "[2.58565253 2.12043111 2.10599812 3.51215691 1.43954274 6.89283837\n",
      " 2.34041827 3.7837465  3.99434519 6.07656385]\n",
      "##########\n",
      "epoch:9 step:46605[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:9 step:46610[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:9 step:46615[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:9 step:46620[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:9 step:46625[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:9 step:46630[D loss: 0.999994] [G loss: 1.000071]\n",
      "epoch:9 step:46635[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:9 step:46640[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:9 step:46645[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:9 step:46650[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:9 step:46655[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:9 step:46660[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:9 step:46665[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:9 step:46670[D loss: 1.000086] [G loss: 0.999899]\n",
      "epoch:9 step:46675[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:9 step:46680[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:9 step:46685[D loss: 1.000020] [G loss: 1.000052]\n",
      "epoch:9 step:46690[D loss: 0.999954] [G loss: 1.000113]\n",
      "epoch:9 step:46695[D loss: 1.000045] [G loss: 1.000001]\n",
      "epoch:9 step:46700[D loss: 0.999954] [G loss: 1.000048]\n",
      "epoch:9 step:46705[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:9 step:46710[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:9 step:46715[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:9 step:46720[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:9 step:46725[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:9 step:46730[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:9 step:46735[D loss: 1.000003] [G loss: 1.000083]\n",
      "epoch:9 step:46740[D loss: 1.000007] [G loss: 1.000035]\n",
      "epoch:9 step:46745[D loss: 1.000012] [G loss: 1.000009]\n",
      "epoch:9 step:46750[D loss: 1.000020] [G loss: 1.000074]\n",
      "epoch:9 step:46755[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:9 step:46760[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:9 step:46765[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:9 step:46770[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:9 step:46775[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:9 step:46780[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:9 step:46785[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:9 step:46790[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:9 step:46795[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:9 step:46800[D loss: 0.999974] [G loss: 1.000064]\n",
      "##############\n",
      "[2.60894788 2.10543825 2.27386017 3.86756123 1.48200421 7.55617321\n",
      " 2.29251289 3.92281632 3.98619776 6.07287345]\n",
      "##########\n",
      "epoch:9 step:46805[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:9 step:46810[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:9 step:46815[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:9 step:46820[D loss: 1.000005] [G loss: 1.000026]\n",
      "epoch:9 step:46825[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:9 step:46830[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:9 step:46835[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:9 step:46840[D loss: 1.000000] [G loss: 1.000057]\n",
      "epoch:9 step:46845[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:9 step:46850[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:10 step:46855[D loss: 1.000001] [G loss: 1.000037]\n",
      "epoch:10 step:46860[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:10 step:46865[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:10 step:46870[D loss: 0.999997] [G loss: 1.000064]\n",
      "epoch:10 step:46875[D loss: 0.999960] [G loss: 1.000106]\n",
      "epoch:10 step:46880[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:10 step:46885[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:10 step:46890[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:10 step:46895[D loss: 1.000024] [G loss: 0.999970]\n",
      "epoch:10 step:46900[D loss: 1.000085] [G loss: 0.999913]\n",
      "epoch:10 step:46905[D loss: 1.000057] [G loss: 0.999916]\n",
      "epoch:10 step:46910[D loss: 0.999941] [G loss: 1.000077]\n",
      "epoch:10 step:46915[D loss: 0.999952] [G loss: 1.000059]\n",
      "epoch:10 step:46920[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:10 step:46925[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:10 step:46930[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:10 step:46935[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:10 step:46940[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:10 step:46945[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:10 step:46950[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:10 step:46955[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:10 step:46960[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:10 step:46965[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:10 step:46970[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:10 step:46975[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:10 step:46980[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:10 step:46985[D loss: 1.000017] [G loss: 1.000038]\n",
      "epoch:10 step:46990[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:10 step:46995[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:10 step:47000[D loss: 0.999969] [G loss: 1.000067]\n",
      "##############\n",
      "[2.57422142 2.1421484  2.21696946 3.48008104 1.44973248 7.80453061\n",
      " 2.30921788 3.90457849 4.03030745 5.03212908]\n",
      "##########\n",
      "epoch:10 step:47005[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:10 step:47010[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:10 step:47015[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:10 step:47020[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:10 step:47025[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:10 step:47030[D loss: 0.999991] [G loss: 1.000092]\n",
      "epoch:10 step:47035[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:10 step:47040[D loss: 0.999949] [G loss: 1.000101]\n",
      "epoch:10 step:47045[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:10 step:47050[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:10 step:47055[D loss: 0.999996] [G loss: 1.000078]\n",
      "epoch:10 step:47060[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:10 step:47065[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:10 step:47070[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:10 step:47075[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:10 step:47080[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:10 step:47085[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:10 step:47090[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:10 step:47095[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:10 step:47100[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:10 step:47105[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:10 step:47110[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:10 step:47115[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:10 step:47120[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:10 step:47125[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:10 step:47130[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:10 step:47135[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:10 step:47140[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:10 step:47145[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:10 step:47150[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:10 step:47155[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:10 step:47160[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:10 step:47165[D loss: 1.000001] [G loss: 1.000069]\n",
      "epoch:10 step:47170[D loss: 1.000014] [G loss: 1.000031]\n",
      "epoch:10 step:47175[D loss: 0.999924] [G loss: 1.000134]\n",
      "epoch:10 step:47180[D loss: 0.999999] [G loss: 1.000065]\n",
      "epoch:10 step:47185[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:10 step:47190[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:10 step:47195[D loss: 1.000059] [G loss: 0.999959]\n",
      "epoch:10 step:47200[D loss: 0.999974] [G loss: 1.000075]\n",
      "##############\n",
      "[2.54219269 2.0575386  2.2121319  3.34300782 1.46287644 7.27841496\n",
      " 2.27415567 3.89749517 3.9783098  4.8001788 ]\n",
      "##########\n",
      "epoch:10 step:47205[D loss: 0.999992] [G loss: 1.000096]\n",
      "epoch:10 step:47210[D loss: 1.000016] [G loss: 1.000039]\n",
      "epoch:10 step:47215[D loss: 0.999944] [G loss: 1.000112]\n",
      "epoch:10 step:47220[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:10 step:47225[D loss: 1.000008] [G loss: 1.000037]\n",
      "epoch:10 step:47230[D loss: 0.999980] [G loss: 0.999988]\n",
      "epoch:10 step:47235[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:10 step:47240[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:10 step:47245[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:10 step:47250[D loss: 0.999984] [G loss: 1.000084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:47255[D loss: 0.999974] [G loss: 1.000099]\n",
      "epoch:10 step:47260[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:10 step:47265[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:10 step:47270[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:10 step:47275[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:10 step:47280[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:10 step:47285[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:10 step:47290[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:10 step:47295[D loss: 0.999985] [G loss: 1.000098]\n",
      "epoch:10 step:47300[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:10 step:47305[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:10 step:47310[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:10 step:47315[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:10 step:47320[D loss: 0.999995] [G loss: 1.000017]\n",
      "epoch:10 step:47325[D loss: 1.000004] [G loss: 1.000052]\n",
      "epoch:10 step:47330[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:10 step:47335[D loss: 0.999984] [G loss: 1.000106]\n",
      "epoch:10 step:47340[D loss: 0.999987] [G loss: 1.000109]\n",
      "epoch:10 step:47345[D loss: 0.999918] [G loss: 1.000131]\n",
      "epoch:10 step:47350[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:10 step:47355[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:10 step:47360[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:10 step:47365[D loss: 1.000043] [G loss: 0.999974]\n",
      "epoch:10 step:47370[D loss: 0.999981] [G loss: 1.000123]\n",
      "epoch:10 step:47375[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:10 step:47380[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:10 step:47385[D loss: 1.000002] [G loss: 1.000059]\n",
      "epoch:10 step:47390[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:10 step:47395[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:10 step:47400[D loss: 0.999997] [G loss: 1.000041]\n",
      "##############\n",
      "[2.53147547 2.22351423 2.27254541 3.97025937 1.46142187 7.25962328\n",
      " 2.4084192  4.04162051 4.04401612 4.72149406]\n",
      "##########\n",
      "epoch:10 step:47405[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:10 step:47410[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:10 step:47415[D loss: 0.999977] [G loss: 1.000114]\n",
      "epoch:10 step:47420[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:10 step:47425[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:10 step:47430[D loss: 1.000018] [G loss: 0.999990]\n",
      "epoch:10 step:47435[D loss: 1.000016] [G loss: 1.000037]\n",
      "epoch:10 step:47440[D loss: 1.000047] [G loss: 0.999976]\n",
      "epoch:10 step:47445[D loss: 0.999969] [G loss: 1.000173]\n",
      "epoch:10 step:47450[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:10 step:47455[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:10 step:47460[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:10 step:47465[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:10 step:47470[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:10 step:47475[D loss: 0.999973] [G loss: 1.000098]\n",
      "epoch:10 step:47480[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:10 step:47485[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:10 step:47490[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:10 step:47495[D loss: 0.999991] [G loss: 1.000012]\n",
      "epoch:10 step:47500[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:10 step:47505[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:10 step:47510[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:10 step:47515[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:10 step:47520[D loss: 0.999989] [G loss: 1.000070]\n",
      "epoch:10 step:47525[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:10 step:47530[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:10 step:47535[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:10 step:47540[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:10 step:47545[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:10 step:47550[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:10 step:47555[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:10 step:47560[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:10 step:47565[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:10 step:47570[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:10 step:47575[D loss: 1.000003] [G loss: 0.999999]\n",
      "epoch:10 step:47580[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:10 step:47585[D loss: 1.000009] [G loss: 1.000045]\n",
      "epoch:10 step:47590[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:10 step:47595[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:10 step:47600[D loss: 0.999969] [G loss: 1.000088]\n",
      "##############\n",
      "[2.58514566 2.15237434 2.15412765 3.77975052 1.43918226 7.50956768\n",
      " 2.19068247 3.90205813 3.94768298 5.21626719]\n",
      "##########\n",
      "epoch:10 step:47605[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:10 step:47610[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:10 step:47615[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:10 step:47620[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:10 step:47625[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:10 step:47630[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:10 step:47635[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:10 step:47640[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:10 step:47645[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:10 step:47650[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:10 step:47655[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:10 step:47660[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:10 step:47665[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:10 step:47670[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:10 step:47675[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:10 step:47680[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:10 step:47685[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:10 step:47690[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:10 step:47695[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:10 step:47700[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:10 step:47705[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:10 step:47710[D loss: 1.000017] [G loss: 1.000042]\n",
      "epoch:10 step:47715[D loss: 0.999988] [G loss: 1.000018]\n",
      "epoch:10 step:47720[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:10 step:47725[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:10 step:47730[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:10 step:47735[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:10 step:47740[D loss: 0.999995] [G loss: 1.000067]\n",
      "epoch:10 step:47745[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:10 step:47750[D loss: 0.999980] [G loss: 1.000020]\n",
      "epoch:10 step:47755[D loss: 0.999966] [G loss: 1.000113]\n",
      "epoch:10 step:47760[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:10 step:47765[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:10 step:47770[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:10 step:47775[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:10 step:47780[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:10 step:47785[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:10 step:47790[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:10 step:47795[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:10 step:47800[D loss: 0.999986] [G loss: 1.000055]\n",
      "##############\n",
      "[2.58673598 2.15908689 2.21848227 3.9919629  1.50583466 7.36917648\n",
      " 2.37628557 3.79511206 4.01326573 5.30490005]\n",
      "##########\n",
      "epoch:10 step:47805[D loss: 0.999995] [G loss: 1.000058]\n",
      "epoch:10 step:47810[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:10 step:47815[D loss: 0.999973] [G loss: 1.000106]\n",
      "epoch:10 step:47820[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:10 step:47825[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:10 step:47830[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:10 step:47835[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:10 step:47840[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:10 step:47845[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:10 step:47850[D loss: 1.000023] [G loss: 1.000038]\n",
      "epoch:10 step:47855[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:10 step:47860[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:10 step:47865[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:10 step:47870[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:10 step:47875[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:10 step:47880[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:10 step:47885[D loss: 1.000009] [G loss: 1.000077]\n",
      "epoch:10 step:47890[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:10 step:47895[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:10 step:47900[D loss: 0.999960] [G loss: 1.000106]\n",
      "epoch:10 step:47905[D loss: 0.999943] [G loss: 1.000085]\n",
      "epoch:10 step:47910[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:10 step:47915[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:10 step:47920[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:10 step:47925[D loss: 0.999981] [G loss: 1.000102]\n",
      "epoch:10 step:47930[D loss: 0.999984] [G loss: 1.000094]\n",
      "epoch:10 step:47935[D loss: 1.000023] [G loss: 1.000069]\n",
      "epoch:10 step:47940[D loss: 0.999943] [G loss: 1.000101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:47945[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:10 step:47950[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:10 step:47955[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:10 step:47960[D loss: 0.999999] [G loss: 1.000046]\n",
      "epoch:10 step:47965[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:10 step:47970[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:10 step:47975[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:10 step:47980[D loss: 1.000006] [G loss: 1.000060]\n",
      "epoch:10 step:47985[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:10 step:47990[D loss: 0.999945] [G loss: 1.000080]\n",
      "epoch:10 step:47995[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:10 step:48000[D loss: 1.000005] [G loss: 1.000037]\n",
      "##############\n",
      "[2.62778598 2.14020595 2.2921343  3.8125499  1.53981566 7.03840288\n",
      " 2.28694858 3.90633242 4.0331224  5.34320273]\n",
      "##########\n",
      "epoch:10 step:48005[D loss: 0.999951] [G loss: 1.000074]\n",
      "epoch:10 step:48010[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:10 step:48015[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:10 step:48020[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:10 step:48025[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:10 step:48030[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:10 step:48035[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:10 step:48040[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:10 step:48045[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:10 step:48050[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:10 step:48055[D loss: 1.000035] [G loss: 0.999991]\n",
      "epoch:10 step:48060[D loss: 0.999995] [G loss: 1.000010]\n",
      "epoch:10 step:48065[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:10 step:48070[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:10 step:48075[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:10 step:48080[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:10 step:48085[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:10 step:48090[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:10 step:48095[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:10 step:48100[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:10 step:48105[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:10 step:48110[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:10 step:48115[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:10 step:48120[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:10 step:48125[D loss: 0.999995] [G loss: 1.000053]\n",
      "epoch:10 step:48130[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:10 step:48135[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:10 step:48140[D loss: 1.000026] [G loss: 1.000022]\n",
      "epoch:10 step:48145[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:10 step:48150[D loss: 1.000033] [G loss: 0.999989]\n",
      "epoch:10 step:48155[D loss: 1.000001] [G loss: 1.000031]\n",
      "epoch:10 step:48160[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:10 step:48165[D loss: 1.000072] [G loss: 0.999947]\n",
      "epoch:10 step:48170[D loss: 0.999972] [G loss: 1.000008]\n",
      "epoch:10 step:48175[D loss: 0.999959] [G loss: 1.000053]\n",
      "epoch:10 step:48180[D loss: 0.999957] [G loss: 1.000120]\n",
      "epoch:10 step:48185[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:10 step:48190[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:10 step:48195[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:10 step:48200[D loss: 0.999996] [G loss: 1.000006]\n",
      "##############\n",
      "[2.5333215  2.22259464 2.14762304 3.93581505 1.38483411 7.42905982\n",
      " 2.32162733 3.8140736  3.95894757 5.17569033]\n",
      "##########\n",
      "epoch:10 step:48205[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:10 step:48210[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:10 step:48215[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:10 step:48220[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:10 step:48225[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:10 step:48230[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:10 step:48235[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:10 step:48240[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:10 step:48245[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:10 step:48250[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:10 step:48255[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:10 step:48260[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:10 step:48265[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:10 step:48270[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:10 step:48275[D loss: 1.000006] [G loss: 0.999998]\n",
      "epoch:10 step:48280[D loss: 0.999946] [G loss: 1.000078]\n",
      "epoch:10 step:48285[D loss: 0.999951] [G loss: 1.000081]\n",
      "epoch:10 step:48290[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:10 step:48295[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:10 step:48300[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:10 step:48305[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:10 step:48310[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:10 step:48315[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:10 step:48320[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:10 step:48325[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:10 step:48330[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:10 step:48335[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:10 step:48340[D loss: 1.000011] [G loss: 1.000003]\n",
      "epoch:10 step:48345[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:10 step:48350[D loss: 1.000012] [G loss: 1.000000]\n",
      "epoch:10 step:48355[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:10 step:48360[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:10 step:48365[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:10 step:48370[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:10 step:48375[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:10 step:48380[D loss: 1.000024] [G loss: 1.000008]\n",
      "epoch:10 step:48385[D loss: 0.999950] [G loss: 1.000066]\n",
      "epoch:10 step:48390[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:10 step:48395[D loss: 0.999999] [G loss: 1.000031]\n",
      "epoch:10 step:48400[D loss: 0.999979] [G loss: 1.000045]\n",
      "##############\n",
      "[2.58316146 2.02179294 2.12093151 4.07713042 1.44055392 7.51840507\n",
      " 2.22877319 3.69024981 3.93637134 5.37363802]\n",
      "##########\n",
      "epoch:10 step:48405[D loss: 1.000013] [G loss: 1.000073]\n",
      "epoch:10 step:48410[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:10 step:48415[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:10 step:48420[D loss: 0.999953] [G loss: 1.000078]\n",
      "epoch:10 step:48425[D loss: 1.000012] [G loss: 1.000048]\n",
      "epoch:10 step:48430[D loss: 0.999990] [G loss: 1.000132]\n",
      "epoch:10 step:48435[D loss: 0.999956] [G loss: 1.000063]\n",
      "epoch:10 step:48440[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:10 step:48445[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:10 step:48450[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:10 step:48455[D loss: 1.000062] [G loss: 0.999974]\n",
      "epoch:10 step:48460[D loss: 1.000091] [G loss: 0.999859]\n",
      "epoch:10 step:48465[D loss: 1.000010] [G loss: 1.000055]\n",
      "epoch:10 step:48470[D loss: 0.999928] [G loss: 1.000071]\n",
      "epoch:10 step:48475[D loss: 0.999981] [G loss: 1.000032]\n",
      "epoch:10 step:48480[D loss: 0.999959] [G loss: 1.000049]\n",
      "epoch:10 step:48485[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:10 step:48490[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:10 step:48495[D loss: 1.000001] [G loss: 1.000035]\n",
      "epoch:10 step:48500[D loss: 0.999998] [G loss: 1.000076]\n",
      "epoch:10 step:48505[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:10 step:48510[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:10 step:48515[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:10 step:48520[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:10 step:48525[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:10 step:48530[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:10 step:48535[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:10 step:48540[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:10 step:48545[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:10 step:48550[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:10 step:48555[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:10 step:48560[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:10 step:48565[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:10 step:48570[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:10 step:48575[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:10 step:48580[D loss: 1.000041] [G loss: 1.000036]\n",
      "epoch:10 step:48585[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:10 step:48590[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:10 step:48595[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:10 step:48600[D loss: 0.999977] [G loss: 1.000073]\n",
      "##############\n",
      "[2.72711048 2.0739134  2.15172287 3.58951812 1.43067964 7.66123288\n",
      " 2.38385166 3.908656   4.02190333 5.10452833]\n",
      "##########\n",
      "epoch:10 step:48605[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:10 step:48610[D loss: 1.000007] [G loss: 1.000019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:48615[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:10 step:48620[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:10 step:48625[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:10 step:48630[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:10 step:48635[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:10 step:48640[D loss: 1.000015] [G loss: 1.000090]\n",
      "epoch:10 step:48645[D loss: 0.999942] [G loss: 1.000103]\n",
      "epoch:10 step:48650[D loss: 1.000014] [G loss: 1.000049]\n",
      "epoch:10 step:48655[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:10 step:48660[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:10 step:48665[D loss: 1.000002] [G loss: 0.999974]\n",
      "epoch:10 step:48670[D loss: 1.000035] [G loss: 1.000019]\n",
      "epoch:10 step:48675[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:10 step:48680[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:10 step:48685[D loss: 1.000007] [G loss: 1.000075]\n",
      "epoch:10 step:48690[D loss: 0.999938] [G loss: 1.000146]\n",
      "epoch:10 step:48695[D loss: 0.999991] [G loss: 1.000099]\n",
      "epoch:10 step:48700[D loss: 0.999951] [G loss: 1.000112]\n",
      "epoch:10 step:48705[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:10 step:48710[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:10 step:48715[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:10 step:48720[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:10 step:48725[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:10 step:48730[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:10 step:48735[D loss: 1.000013] [G loss: 0.999984]\n",
      "epoch:10 step:48740[D loss: 1.000048] [G loss: 1.000022]\n",
      "epoch:10 step:48745[D loss: 0.999935] [G loss: 1.000105]\n",
      "epoch:10 step:48750[D loss: 0.999950] [G loss: 1.000102]\n",
      "epoch:10 step:48755[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:10 step:48760[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:10 step:48765[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:10 step:48770[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:10 step:48775[D loss: 0.999980] [G loss: 1.000137]\n",
      "epoch:10 step:48780[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:10 step:48785[D loss: 0.999996] [G loss: 1.000093]\n",
      "epoch:10 step:48790[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:10 step:48795[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:10 step:48800[D loss: 0.999971] [G loss: 1.000119]\n",
      "##############\n",
      "[2.53995896 2.12611247 2.06932359 3.53284004 1.44841405 7.49961418\n",
      " 2.28276919 3.69895953 3.92425776 5.16030565]\n",
      "##########\n",
      "epoch:10 step:48805[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:10 step:48810[D loss: 0.999963] [G loss: 1.000052]\n",
      "epoch:10 step:48815[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:10 step:48820[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:10 step:48825[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:10 step:48830[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:10 step:48835[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:10 step:48840[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:10 step:48845[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:10 step:48850[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:10 step:48855[D loss: 0.999927] [G loss: 1.000159]\n",
      "epoch:10 step:48860[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:10 step:48865[D loss: 0.999960] [G loss: 1.000112]\n",
      "epoch:10 step:48870[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:10 step:48875[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:10 step:48880[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:10 step:48885[D loss: 0.999997] [G loss: 1.000071]\n",
      "epoch:10 step:48890[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:10 step:48895[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:10 step:48900[D loss: 1.000047] [G loss: 1.000016]\n",
      "epoch:10 step:48905[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:10 step:48910[D loss: 1.000004] [G loss: 1.000065]\n",
      "epoch:10 step:48915[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:10 step:48920[D loss: 0.999954] [G loss: 1.000119]\n",
      "epoch:10 step:48925[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:10 step:48930[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:10 step:48935[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:10 step:48940[D loss: 0.999965] [G loss: 1.000101]\n",
      "epoch:10 step:48945[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:10 step:48950[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:10 step:48955[D loss: 1.000018] [G loss: 1.000068]\n",
      "epoch:10 step:48960[D loss: 1.000019] [G loss: 1.000069]\n",
      "epoch:10 step:48965[D loss: 0.999997] [G loss: 1.000016]\n",
      "epoch:10 step:48970[D loss: 0.999982] [G loss: 1.000097]\n",
      "epoch:10 step:48975[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:10 step:48980[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:10 step:48985[D loss: 0.999990] [G loss: 1.000006]\n",
      "epoch:10 step:48990[D loss: 1.000028] [G loss: 0.999962]\n",
      "epoch:10 step:48995[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:10 step:49000[D loss: 0.999983] [G loss: 1.000023]\n",
      "##############\n",
      "[2.58067393 2.1011094  2.19340285 3.72254957 1.47451393 6.75896403\n",
      " 2.21721408 3.76270289 3.92515782 4.80709393]\n",
      "##########\n",
      "epoch:10 step:49005[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:10 step:49010[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:10 step:49015[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:10 step:49020[D loss: 0.999985] [G loss: 1.000108]\n",
      "epoch:10 step:49025[D loss: 0.999955] [G loss: 1.000127]\n",
      "epoch:10 step:49030[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:10 step:49035[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:10 step:49040[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:10 step:49045[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:10 step:49050[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:10 step:49055[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:10 step:49060[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:10 step:49065[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:10 step:49070[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:10 step:49075[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:10 step:49080[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:10 step:49085[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:10 step:49090[D loss: 0.999980] [G loss: 1.000097]\n",
      "epoch:10 step:49095[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:10 step:49100[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:10 step:49105[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:10 step:49110[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:10 step:49115[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:10 step:49120[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:10 step:49125[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:10 step:49130[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:10 step:49135[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:10 step:49140[D loss: 1.000005] [G loss: 1.000061]\n",
      "epoch:10 step:49145[D loss: 1.000080] [G loss: 0.999994]\n",
      "epoch:10 step:49150[D loss: 0.999974] [G loss: 1.000007]\n",
      "epoch:10 step:49155[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:10 step:49160[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:10 step:49165[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:10 step:49170[D loss: 1.000016] [G loss: 0.999965]\n",
      "epoch:10 step:49175[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:10 step:49180[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:10 step:49185[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:10 step:49190[D loss: 1.000005] [G loss: 1.000048]\n",
      "epoch:10 step:49195[D loss: 1.000003] [G loss: 1.000107]\n",
      "epoch:10 step:49200[D loss: 0.999949] [G loss: 1.000098]\n",
      "##############\n",
      "[2.64739696 2.10715097 2.29487687 3.54067162 1.4931588  8.84994587\n",
      " 2.24529257 3.77517655 4.00521267 5.40800287]\n",
      "##########\n",
      "epoch:10 step:49205[D loss: 0.999941] [G loss: 1.000127]\n",
      "epoch:10 step:49210[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:10 step:49215[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:10 step:49220[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:10 step:49225[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:10 step:49230[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:10 step:49235[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:10 step:49240[D loss: 1.000005] [G loss: 1.000038]\n",
      "epoch:10 step:49245[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:10 step:49250[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:10 step:49255[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:10 step:49260[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:10 step:49265[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:10 step:49270[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:10 step:49275[D loss: 1.000014] [G loss: 1.000053]\n",
      "epoch:10 step:49280[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:10 step:49285[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:10 step:49290[D loss: 1.000004] [G loss: 1.000032]\n",
      "epoch:10 step:49295[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:10 step:49300[D loss: 0.999972] [G loss: 1.000106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:49305[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:10 step:49310[D loss: 0.999951] [G loss: 1.000121]\n",
      "epoch:10 step:49315[D loss: 1.000006] [G loss: 1.000075]\n",
      "epoch:10 step:49320[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:10 step:49325[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:10 step:49330[D loss: 1.000024] [G loss: 1.000062]\n",
      "epoch:10 step:49335[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:10 step:49340[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:10 step:49345[D loss: 1.000013] [G loss: 0.999988]\n",
      "epoch:10 step:49350[D loss: 1.000048] [G loss: 1.000020]\n",
      "epoch:10 step:49355[D loss: 0.999942] [G loss: 1.000089]\n",
      "epoch:10 step:49360[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:10 step:49365[D loss: 0.999931] [G loss: 1.000103]\n",
      "epoch:10 step:49370[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:10 step:49375[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:10 step:49380[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:10 step:49385[D loss: 0.999994] [G loss: 1.000076]\n",
      "epoch:10 step:49390[D loss: 0.999970] [G loss: 1.000103]\n",
      "epoch:10 step:49395[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:10 step:49400[D loss: 1.000077] [G loss: 1.000009]\n",
      "##############\n",
      "[2.51578192 2.21213789 2.21580068 3.84624688 1.48036582 7.55297894\n",
      " 2.22741335 3.88749772 3.97384391 5.46191837]\n",
      "##########\n",
      "epoch:10 step:49405[D loss: 1.000002] [G loss: 1.000026]\n",
      "epoch:10 step:49410[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:10 step:49415[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:10 step:49420[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:10 step:49425[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:10 step:49430[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:10 step:49435[D loss: 1.000012] [G loss: 1.000013]\n",
      "epoch:10 step:49440[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:10 step:49445[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:10 step:49450[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:10 step:49455[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:10 step:49460[D loss: 0.999987] [G loss: 1.000029]\n",
      "epoch:10 step:49465[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:10 step:49470[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:10 step:49475[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:10 step:49480[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:10 step:49485[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:10 step:49490[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:10 step:49495[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:10 step:49500[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:10 step:49505[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:10 step:49510[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:10 step:49515[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:10 step:49520[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:10 step:49525[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:10 step:49530[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:10 step:49535[D loss: 0.999977] [G loss: 1.000116]\n",
      "epoch:10 step:49540[D loss: 1.000019] [G loss: 1.000026]\n",
      "epoch:10 step:49545[D loss: 1.000026] [G loss: 1.000009]\n",
      "epoch:10 step:49550[D loss: 0.999948] [G loss: 1.000087]\n",
      "epoch:10 step:49555[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:10 step:49560[D loss: 0.999989] [G loss: 1.000019]\n",
      "epoch:10 step:49565[D loss: 0.999945] [G loss: 1.000161]\n",
      "epoch:10 step:49570[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:10 step:49575[D loss: 1.000024] [G loss: 1.000018]\n",
      "epoch:10 step:49580[D loss: 1.000004] [G loss: 1.000031]\n",
      "epoch:10 step:49585[D loss: 0.999938] [G loss: 1.000083]\n",
      "epoch:10 step:49590[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:10 step:49595[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:10 step:49600[D loss: 1.000008] [G loss: 1.000047]\n",
      "##############\n",
      "[2.55382172 2.18943173 2.24410676 4.24736368 1.43854362 7.09441844\n",
      " 2.30348179 4.00236226 3.97775726 5.59842803]\n",
      "##########\n",
      "epoch:10 step:49605[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:10 step:49610[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:10 step:49615[D loss: 1.000014] [G loss: 0.999999]\n",
      "epoch:10 step:49620[D loss: 0.999964] [G loss: 1.000036]\n",
      "epoch:10 step:49625[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:10 step:49630[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:10 step:49635[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:10 step:49640[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:10 step:49645[D loss: 0.999994] [G loss: 1.000048]\n",
      "epoch:10 step:49650[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:10 step:49655[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:10 step:49660[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:10 step:49665[D loss: 0.999999] [G loss: 1.000075]\n",
      "epoch:10 step:49670[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:10 step:49675[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:10 step:49680[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:10 step:49685[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:10 step:49690[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:10 step:49695[D loss: 0.999969] [G loss: 1.000032]\n",
      "epoch:10 step:49700[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:10 step:49705[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:10 step:49710[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:10 step:49715[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:10 step:49720[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:10 step:49725[D loss: 0.999993] [G loss: 1.000119]\n",
      "epoch:10 step:49730[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:10 step:49735[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:10 step:49740[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:10 step:49745[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:10 step:49750[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:10 step:49755[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:10 step:49760[D loss: 1.000013] [G loss: 0.999996]\n",
      "epoch:10 step:49765[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:10 step:49770[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:10 step:49775[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:10 step:49780[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:10 step:49785[D loss: 0.999951] [G loss: 1.000103]\n",
      "epoch:10 step:49790[D loss: 0.999991] [G loss: 1.000088]\n",
      "epoch:10 step:49795[D loss: 1.000019] [G loss: 1.000124]\n",
      "epoch:10 step:49800[D loss: 0.999898] [G loss: 1.000172]\n",
      "##############\n",
      "[2.57777657 2.19774683 2.28450443 3.69096539 1.51802862 7.21544414\n",
      " 2.41949673 3.9083767  4.06362387 5.07727598]\n",
      "##########\n",
      "epoch:10 step:49805[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:10 step:49810[D loss: 1.000012] [G loss: 1.000041]\n",
      "epoch:10 step:49815[D loss: 1.000007] [G loss: 1.000092]\n",
      "epoch:10 step:49820[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:10 step:49825[D loss: 1.000069] [G loss: 1.000029]\n",
      "epoch:10 step:49830[D loss: 0.999994] [G loss: 1.000069]\n",
      "epoch:10 step:49835[D loss: 0.999938] [G loss: 1.000077]\n",
      "epoch:10 step:49840[D loss: 0.999998] [G loss: 1.000059]\n",
      "epoch:10 step:49845[D loss: 0.999966] [G loss: 1.000116]\n",
      "epoch:10 step:49850[D loss: 0.999956] [G loss: 1.000116]\n",
      "epoch:10 step:49855[D loss: 0.999988] [G loss: 1.000033]\n",
      "epoch:10 step:49860[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:10 step:49865[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:10 step:49870[D loss: 1.000005] [G loss: 1.000037]\n",
      "epoch:10 step:49875[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:10 step:49880[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:10 step:49885[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:10 step:49890[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:10 step:49895[D loss: 0.999990] [G loss: 1.000128]\n",
      "epoch:10 step:49900[D loss: 0.999940] [G loss: 1.000117]\n",
      "epoch:10 step:49905[D loss: 0.999948] [G loss: 1.000126]\n",
      "epoch:10 step:49910[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:10 step:49915[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:10 step:49920[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:10 step:49925[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:10 step:49930[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:10 step:49935[D loss: 0.999982] [G loss: 1.000109]\n",
      "epoch:10 step:49940[D loss: 0.999971] [G loss: 1.000107]\n",
      "epoch:10 step:49945[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:10 step:49950[D loss: 1.000005] [G loss: 1.000062]\n",
      "epoch:10 step:49955[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:10 step:49960[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:10 step:49965[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:10 step:49970[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:10 step:49975[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:10 step:49980[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:10 step:49985[D loss: 1.000032] [G loss: 0.999995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:49990[D loss: 0.999956] [G loss: 1.000115]\n",
      "epoch:10 step:49995[D loss: 0.999944] [G loss: 1.000081]\n",
      "epoch:10 step:50000[D loss: 0.999984] [G loss: 1.000054]\n",
      "##############\n",
      "[2.62273107 2.15732321 2.17405736 3.74621388 1.49361683 7.95003282\n",
      " 2.11240795 3.79376149 3.91014167 5.19549527]\n",
      "##########\n",
      "epoch:10 step:50005[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:10 step:50010[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:10 step:50015[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:10 step:50020[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:10 step:50025[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:10 step:50030[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:10 step:50035[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:10 step:50040[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:10 step:50045[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:10 step:50050[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:10 step:50055[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:10 step:50060[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:10 step:50065[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:10 step:50070[D loss: 1.000007] [G loss: 1.000034]\n",
      "epoch:10 step:50075[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:10 step:50080[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:10 step:50085[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:10 step:50090[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:10 step:50095[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:10 step:50100[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:10 step:50105[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:10 step:50110[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:10 step:50115[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:10 step:50120[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:10 step:50125[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:10 step:50130[D loss: 0.999982] [G loss: 1.000093]\n",
      "epoch:10 step:50135[D loss: 0.999957] [G loss: 1.000114]\n",
      "epoch:10 step:50140[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:10 step:50145[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:10 step:50150[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:10 step:50155[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:10 step:50160[D loss: 1.000019] [G loss: 1.000028]\n",
      "epoch:10 step:50165[D loss: 1.000021] [G loss: 1.000044]\n",
      "epoch:10 step:50170[D loss: 0.999956] [G loss: 1.000058]\n",
      "epoch:10 step:50175[D loss: 0.999975] [G loss: 1.000020]\n",
      "epoch:10 step:50180[D loss: 1.000011] [G loss: 0.999992]\n",
      "epoch:10 step:50185[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:10 step:50190[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:10 step:50195[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:10 step:50200[D loss: 0.999965] [G loss: 1.000073]\n",
      "##############\n",
      "[2.66833477 2.24310633 2.24606623 3.81938851 1.51039474 7.17867897\n",
      " 2.42773246 3.95564668 4.028047   5.97771011]\n",
      "##########\n",
      "epoch:10 step:50205[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:10 step:50210[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:10 step:50215[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:10 step:50220[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:10 step:50225[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:10 step:50230[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:10 step:50235[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:10 step:50240[D loss: 0.999963] [G loss: 1.000125]\n",
      "epoch:10 step:50245[D loss: 0.999945] [G loss: 1.000161]\n",
      "epoch:10 step:50250[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:10 step:50255[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:10 step:50260[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:10 step:50265[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:10 step:50270[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:10 step:50275[D loss: 1.000019] [G loss: 1.000049]\n",
      "epoch:10 step:50280[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:10 step:50285[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:10 step:50290[D loss: 0.999948] [G loss: 1.000114]\n",
      "epoch:10 step:50295[D loss: 1.000048] [G loss: 0.999973]\n",
      "epoch:10 step:50300[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:10 step:50305[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:10 step:50310[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:10 step:50315[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:10 step:50320[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:10 step:50325[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:10 step:50330[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:10 step:50335[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:10 step:50340[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:10 step:50345[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:10 step:50350[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:10 step:50355[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:10 step:50360[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:10 step:50365[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:10 step:50370[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:10 step:50375[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:10 step:50380[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:10 step:50385[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:10 step:50390[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:10 step:50395[D loss: 1.000055] [G loss: 1.000010]\n",
      "epoch:10 step:50400[D loss: 1.000018] [G loss: 1.000037]\n",
      "##############\n",
      "[2.71769064 2.19079403 2.14160388 4.17120682 1.59537096 7.31005562\n",
      " 2.41319384 3.80273692 4.06287553 6.01853192]\n",
      "##########\n",
      "epoch:10 step:50405[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:10 step:50410[D loss: 0.999939] [G loss: 1.000097]\n",
      "epoch:10 step:50415[D loss: 0.999942] [G loss: 1.000121]\n",
      "epoch:10 step:50420[D loss: 1.000075] [G loss: 0.999993]\n",
      "epoch:10 step:50425[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:10 step:50430[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:10 step:50435[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:10 step:50440[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:10 step:50445[D loss: 0.999957] [G loss: 1.000105]\n",
      "epoch:10 step:50450[D loss: 0.999965] [G loss: 1.000118]\n",
      "epoch:10 step:50455[D loss: 0.999992] [G loss: 1.000091]\n",
      "epoch:10 step:50460[D loss: 0.999948] [G loss: 1.000150]\n",
      "epoch:10 step:50465[D loss: 1.000002] [G loss: 1.000103]\n",
      "epoch:10 step:50470[D loss: 1.000024] [G loss: 1.000028]\n",
      "epoch:10 step:50475[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:10 step:50480[D loss: 0.999956] [G loss: 1.000075]\n",
      "epoch:10 step:50485[D loss: 1.000020] [G loss: 1.000032]\n",
      "epoch:10 step:50490[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:10 step:50495[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:10 step:50500[D loss: 1.000052] [G loss: 0.999972]\n",
      "epoch:10 step:50505[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:10 step:50510[D loss: 0.999942] [G loss: 1.000100]\n",
      "epoch:10 step:50515[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:10 step:50520[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:10 step:50525[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:10 step:50530[D loss: 0.999967] [G loss: 1.000096]\n",
      "epoch:10 step:50535[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:10 step:50540[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:10 step:50545[D loss: 0.999986] [G loss: 1.000100]\n",
      "epoch:10 step:50550[D loss: 0.999997] [G loss: 1.000027]\n",
      "epoch:10 step:50555[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:10 step:50560[D loss: 1.000024] [G loss: 1.000023]\n",
      "epoch:10 step:50565[D loss: 0.999960] [G loss: 1.000051]\n",
      "epoch:10 step:50570[D loss: 0.999980] [G loss: 1.000023]\n",
      "epoch:10 step:50575[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:10 step:50580[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:10 step:50585[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:10 step:50590[D loss: 1.000016] [G loss: 1.000021]\n",
      "epoch:10 step:50595[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:10 step:50600[D loss: 0.999989] [G loss: 1.000030]\n",
      "##############\n",
      "[2.5530221  2.16235147 2.22360019 3.95508645 1.51072764 7.11707663\n",
      " 2.20826256 3.80454125 3.97888739 4.77073519]\n",
      "##########\n",
      "epoch:10 step:50605[D loss: 1.000005] [G loss: 0.999996]\n",
      "epoch:10 step:50610[D loss: 1.000007] [G loss: 0.999971]\n",
      "epoch:10 step:50615[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:10 step:50620[D loss: 1.000042] [G loss: 1.000034]\n",
      "epoch:10 step:50625[D loss: 0.999959] [G loss: 1.000103]\n",
      "epoch:10 step:50630[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:10 step:50635[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:10 step:50640[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:10 step:50645[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:10 step:50650[D loss: 1.000070] [G loss: 0.999878]\n",
      "epoch:10 step:50655[D loss: 1.000000] [G loss: 1.000005]\n",
      "epoch:10 step:50660[D loss: 1.000040] [G loss: 0.999962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:50665[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:10 step:50670[D loss: 0.999948] [G loss: 1.000100]\n",
      "epoch:10 step:50675[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:10 step:50680[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:10 step:50685[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:10 step:50690[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:10 step:50695[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:10 step:50700[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:10 step:50705[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:10 step:50710[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:10 step:50715[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:10 step:50720[D loss: 1.000023] [G loss: 1.000034]\n",
      "epoch:10 step:50725[D loss: 0.999956] [G loss: 1.000051]\n",
      "epoch:10 step:50730[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:10 step:50735[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:10 step:50740[D loss: 1.000001] [G loss: 1.000032]\n",
      "epoch:10 step:50745[D loss: 1.000062] [G loss: 0.999938]\n",
      "epoch:10 step:50750[D loss: 1.000016] [G loss: 0.999982]\n",
      "epoch:10 step:50755[D loss: 0.999940] [G loss: 1.000036]\n",
      "epoch:10 step:50760[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:10 step:50765[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:10 step:50770[D loss: 0.999994] [G loss: 1.000048]\n",
      "epoch:10 step:50775[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:10 step:50780[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:10 step:50785[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:10 step:50790[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:10 step:50795[D loss: 0.999964] [G loss: 1.000122]\n",
      "epoch:10 step:50800[D loss: 0.999977] [G loss: 1.000090]\n",
      "##############\n",
      "[2.6200264  2.07908509 2.21674746 3.94838623 1.49305187 7.15246454\n",
      " 2.29501061 3.69894498 4.011739   5.41827441]\n",
      "##########\n",
      "epoch:10 step:50805[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:10 step:50810[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:10 step:50815[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:10 step:50820[D loss: 0.999986] [G loss: 1.000082]\n",
      "epoch:10 step:50825[D loss: 1.000014] [G loss: 1.000002]\n",
      "epoch:10 step:50830[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:10 step:50835[D loss: 0.999996] [G loss: 1.000016]\n",
      "epoch:10 step:50840[D loss: 0.999952] [G loss: 1.000121]\n",
      "epoch:10 step:50845[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:10 step:50850[D loss: 1.000002] [G loss: 0.999991]\n",
      "epoch:10 step:50855[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:10 step:50860[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:10 step:50865[D loss: 0.999946] [G loss: 1.000093]\n",
      "epoch:10 step:50870[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:10 step:50875[D loss: 1.000033] [G loss: 0.999982]\n",
      "epoch:10 step:50880[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:10 step:50885[D loss: 0.999989] [G loss: 1.000090]\n",
      "epoch:10 step:50890[D loss: 1.000035] [G loss: 1.000017]\n",
      "epoch:10 step:50895[D loss: 0.999932] [G loss: 1.000108]\n",
      "epoch:10 step:50900[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:10 step:50905[D loss: 0.999961] [G loss: 1.000102]\n",
      "epoch:10 step:50910[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:10 step:50915[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:10 step:50920[D loss: 1.000010] [G loss: 1.000007]\n",
      "epoch:10 step:50925[D loss: 0.999954] [G loss: 1.000033]\n",
      "epoch:10 step:50930[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:10 step:50935[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:10 step:50940[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:10 step:50945[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:10 step:50950[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:10 step:50955[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:10 step:50960[D loss: 1.000010] [G loss: 1.000043]\n",
      "epoch:10 step:50965[D loss: 0.999956] [G loss: 1.000066]\n",
      "epoch:10 step:50970[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:10 step:50975[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:10 step:50980[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:10 step:50985[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:10 step:50990[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:10 step:50995[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:10 step:51000[D loss: 0.999990] [G loss: 1.000042]\n",
      "##############\n",
      "[2.64342716 2.16482278 2.1657941  3.6675297  1.48054495 7.64212364\n",
      " 2.17260013 3.79275239 3.95041656 7.14868929]\n",
      "##########\n",
      "epoch:10 step:51005[D loss: 0.999953] [G loss: 1.000110]\n",
      "epoch:10 step:51010[D loss: 1.000006] [G loss: 1.000012]\n",
      "epoch:10 step:51015[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:10 step:51020[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:10 step:51025[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:10 step:51030[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:10 step:51035[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:10 step:51040[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:10 step:51045[D loss: 0.999980] [G loss: 1.000135]\n",
      "epoch:10 step:51050[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:10 step:51055[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:10 step:51060[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:10 step:51065[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:10 step:51070[D loss: 1.000035] [G loss: 1.000035]\n",
      "epoch:10 step:51075[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:10 step:51080[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:10 step:51085[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:10 step:51090[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:10 step:51095[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:10 step:51100[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:10 step:51105[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:10 step:51110[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:10 step:51115[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:10 step:51120[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:10 step:51125[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:10 step:51130[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:10 step:51135[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:10 step:51140[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:10 step:51145[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:10 step:51150[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:10 step:51155[D loss: 0.999949] [G loss: 1.000102]\n",
      "epoch:10 step:51160[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:10 step:51165[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:10 step:51170[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:10 step:51175[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:10 step:51180[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:10 step:51185[D loss: 0.999999] [G loss: 1.000055]\n",
      "epoch:10 step:51190[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:10 step:51195[D loss: 1.000004] [G loss: 1.000050]\n",
      "epoch:10 step:51200[D loss: 0.999992] [G loss: 1.000102]\n",
      "##############\n",
      "[2.55391278 2.07582988 2.08322766 3.65990295 1.45740746 6.88461017\n",
      " 2.41917271 3.73506766 3.92807031 5.00941715]\n",
      "##########\n",
      "epoch:10 step:51205[D loss: 0.999924] [G loss: 1.000111]\n",
      "epoch:10 step:51210[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:10 step:51215[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:10 step:51220[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:10 step:51225[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:10 step:51230[D loss: 0.999988] [G loss: 1.000020]\n",
      "epoch:10 step:51235[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:10 step:51240[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:10 step:51245[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:10 step:51250[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:10 step:51255[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:10 step:51260[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:10 step:51265[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:10 step:51270[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:10 step:51275[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:10 step:51280[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:10 step:51285[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:10 step:51290[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:10 step:51295[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:10 step:51300[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:10 step:51305[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:10 step:51310[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:10 step:51315[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:10 step:51320[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:10 step:51325[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:10 step:51330[D loss: 1.000011] [G loss: 1.000048]\n",
      "epoch:10 step:51335[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:10 step:51340[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:10 step:51345[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:10 step:51350[D loss: 0.999966] [G loss: 1.000084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:51355[D loss: 0.999976] [G loss: 1.000120]\n",
      "epoch:10 step:51360[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:10 step:51365[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:10 step:51370[D loss: 1.000003] [G loss: 1.000055]\n",
      "epoch:10 step:51375[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:10 step:51380[D loss: 1.000026] [G loss: 0.999994]\n",
      "epoch:10 step:51385[D loss: 0.999948] [G loss: 1.000082]\n",
      "epoch:10 step:51390[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:10 step:51395[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:10 step:51400[D loss: 0.999951] [G loss: 1.000090]\n",
      "##############\n",
      "[2.5418762  2.04430366 2.18450936 3.86986303 1.46964079 7.82962894\n",
      " 2.34601274 3.86175302 3.93718916 6.09395494]\n",
      "##########\n",
      "epoch:10 step:51405[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:10 step:51410[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:10 step:51415[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:10 step:51420[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:10 step:51425[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:10 step:51430[D loss: 1.000007] [G loss: 1.000027]\n",
      "epoch:10 step:51435[D loss: 1.000003] [G loss: 1.000079]\n",
      "epoch:10 step:51440[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:10 step:51445[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:10 step:51450[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:10 step:51455[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:10 step:51460[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:10 step:51465[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:10 step:51470[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:10 step:51475[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:10 step:51480[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:10 step:51485[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:10 step:51490[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:10 step:51495[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:10 step:51500[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:10 step:51505[D loss: 1.000022] [G loss: 1.000026]\n",
      "epoch:10 step:51510[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:10 step:51515[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:10 step:51520[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:10 step:51525[D loss: 1.000036] [G loss: 1.000001]\n",
      "epoch:10 step:51530[D loss: 0.999948] [G loss: 1.000134]\n",
      "epoch:10 step:51535[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:11 step:51540[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:11 step:51545[D loss: 0.999965] [G loss: 1.000095]\n",
      "epoch:11 step:51550[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:11 step:51555[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:11 step:51560[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:11 step:51565[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:11 step:51570[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:11 step:51575[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:11 step:51580[D loss: 0.999997] [G loss: 1.000093]\n",
      "epoch:11 step:51585[D loss: 1.000039] [G loss: 1.000047]\n",
      "epoch:11 step:51590[D loss: 0.999947] [G loss: 1.000118]\n",
      "epoch:11 step:51595[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:11 step:51600[D loss: 0.999961] [G loss: 1.000104]\n",
      "##############\n",
      "[2.58355731 2.07997481 2.16793064 4.2113748  1.47697393 6.92648948\n",
      " 2.14949997 3.89643183 4.02545309 4.80526674]\n",
      "##########\n",
      "epoch:11 step:51605[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:11 step:51610[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:11 step:51615[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:11 step:51620[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:11 step:51625[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:11 step:51630[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:11 step:51635[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:11 step:51640[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:11 step:51645[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:11 step:51650[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:11 step:51655[D loss: 1.000001] [G loss: 1.000008]\n",
      "epoch:11 step:51660[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:11 step:51665[D loss: 0.999980] [G loss: 1.000120]\n",
      "epoch:11 step:51670[D loss: 0.999984] [G loss: 1.000106]\n",
      "epoch:11 step:51675[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:11 step:51680[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:11 step:51685[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:11 step:51690[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:11 step:51695[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:11 step:51700[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:11 step:51705[D loss: 1.000034] [G loss: 1.000047]\n",
      "epoch:11 step:51710[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:11 step:51715[D loss: 0.999999] [G loss: 1.000081]\n",
      "epoch:11 step:51720[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:11 step:51725[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:11 step:51730[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:11 step:51735[D loss: 0.999962] [G loss: 1.000148]\n",
      "epoch:11 step:51740[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:11 step:51745[D loss: 1.000019] [G loss: 0.999984]\n",
      "epoch:11 step:51750[D loss: 0.999958] [G loss: 1.000114]\n",
      "epoch:11 step:51755[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:11 step:51760[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:11 step:51765[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:11 step:51770[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:11 step:51775[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:11 step:51780[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:11 step:51785[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:11 step:51790[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:11 step:51795[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:11 step:51800[D loss: 0.999968] [G loss: 1.000081]\n",
      "##############\n",
      "[2.51583876 2.10708093 2.25070184 3.84100681 1.45169369 7.43763246\n",
      " 2.39956954 3.85269243 3.92200756 5.79319765]\n",
      "##########\n",
      "epoch:11 step:51805[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:11 step:51810[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:11 step:51815[D loss: 0.999983] [G loss: 1.000095]\n",
      "epoch:11 step:51820[D loss: 0.999984] [G loss: 1.000089]\n",
      "epoch:11 step:51825[D loss: 0.999941] [G loss: 1.000127]\n",
      "epoch:11 step:51830[D loss: 0.999957] [G loss: 1.000111]\n",
      "epoch:11 step:51835[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:11 step:51840[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:11 step:51845[D loss: 0.999998] [G loss: 1.000069]\n",
      "epoch:11 step:51850[D loss: 1.000028] [G loss: 0.999978]\n",
      "epoch:11 step:51855[D loss: 0.999983] [G loss: 1.000111]\n",
      "epoch:11 step:51860[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:11 step:51865[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:11 step:51870[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:11 step:51875[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:11 step:51880[D loss: 1.000024] [G loss: 1.000061]\n",
      "epoch:11 step:51885[D loss: 0.999939] [G loss: 1.000170]\n",
      "epoch:11 step:51890[D loss: 1.000023] [G loss: 1.000025]\n",
      "epoch:11 step:51895[D loss: 1.000065] [G loss: 0.999960]\n",
      "epoch:11 step:51900[D loss: 0.999905] [G loss: 1.000158]\n",
      "epoch:11 step:51905[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:11 step:51910[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:11 step:51915[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:11 step:51920[D loss: 0.999984] [G loss: 1.000015]\n",
      "epoch:11 step:51925[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:11 step:51930[D loss: 1.000024] [G loss: 0.999987]\n",
      "epoch:11 step:51935[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:11 step:51940[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:11 step:51945[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:11 step:51950[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:11 step:51955[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:11 step:51960[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:11 step:51965[D loss: 0.999976] [G loss: 1.000025]\n",
      "epoch:11 step:51970[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:11 step:51975[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:11 step:51980[D loss: 0.999971] [G loss: 1.000133]\n",
      "epoch:11 step:51985[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:11 step:51990[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:11 step:51995[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:11 step:52000[D loss: 1.000005] [G loss: 1.000017]\n",
      "##############\n",
      "[2.54791831 2.24346793 2.23173235 3.82125379 1.44956083 6.41399131\n",
      " 2.48748287 3.97286633 4.03972628 4.79777815]\n",
      "##########\n",
      "epoch:11 step:52005[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:11 step:52010[D loss: 0.999989] [G loss: 1.000087]\n",
      "epoch:11 step:52015[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:11 step:52020[D loss: 1.000030] [G loss: 0.999983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:52025[D loss: 0.999985] [G loss: 1.000102]\n",
      "epoch:11 step:52030[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:11 step:52035[D loss: 0.999912] [G loss: 1.000162]\n",
      "epoch:11 step:52040[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:11 step:52045[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:11 step:52050[D loss: 1.000012] [G loss: 1.000031]\n",
      "epoch:11 step:52055[D loss: 1.000001] [G loss: 1.000043]\n",
      "epoch:11 step:52060[D loss: 0.999945] [G loss: 1.000133]\n",
      "epoch:11 step:52065[D loss: 0.999949] [G loss: 1.000070]\n",
      "epoch:11 step:52070[D loss: 1.000020] [G loss: 1.000044]\n",
      "epoch:11 step:52075[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:11 step:52080[D loss: 0.999939] [G loss: 1.000114]\n",
      "epoch:11 step:52085[D loss: 1.000014] [G loss: 1.000039]\n",
      "epoch:11 step:52090[D loss: 0.999939] [G loss: 1.000109]\n",
      "epoch:11 step:52095[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:11 step:52100[D loss: 0.999932] [G loss: 1.000156]\n",
      "epoch:11 step:52105[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:11 step:52110[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:11 step:52115[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:11 step:52120[D loss: 1.000045] [G loss: 0.999967]\n",
      "epoch:11 step:52125[D loss: 1.000032] [G loss: 1.000007]\n",
      "epoch:11 step:52130[D loss: 1.000002] [G loss: 1.000098]\n",
      "epoch:11 step:52135[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:11 step:52140[D loss: 0.999929] [G loss: 1.000110]\n",
      "epoch:11 step:52145[D loss: 0.999949] [G loss: 1.000157]\n",
      "epoch:11 step:52150[D loss: 0.999955] [G loss: 1.000122]\n",
      "epoch:11 step:52155[D loss: 0.999946] [G loss: 1.000140]\n",
      "epoch:11 step:52160[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:11 step:52165[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:11 step:52170[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:11 step:52175[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:11 step:52180[D loss: 1.000030] [G loss: 0.999968]\n",
      "epoch:11 step:52185[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:11 step:52190[D loss: 1.000006] [G loss: 0.999984]\n",
      "epoch:11 step:52195[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:11 step:52200[D loss: 0.999992] [G loss: 1.000055]\n",
      "##############\n",
      "[2.53840929 2.12294537 2.13477411 3.66939071 1.41339969 7.21444389\n",
      " 2.36698191 3.85338738 3.9713728  5.61315479]\n",
      "##########\n",
      "epoch:11 step:52205[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:11 step:52210[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:11 step:52215[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:11 step:52220[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:11 step:52225[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:11 step:52230[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:11 step:52235[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:11 step:52240[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:11 step:52245[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:11 step:52250[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:11 step:52255[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:11 step:52260[D loss: 0.999943] [G loss: 1.000137]\n",
      "epoch:11 step:52265[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:11 step:52270[D loss: 0.999952] [G loss: 1.000128]\n",
      "epoch:11 step:52275[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:11 step:52280[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:11 step:52285[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:11 step:52290[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:11 step:52295[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:11 step:52300[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:11 step:52305[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:11 step:52310[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:11 step:52315[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:11 step:52320[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:11 step:52325[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:11 step:52330[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:11 step:52335[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:11 step:52340[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:11 step:52345[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:11 step:52350[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:11 step:52355[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:11 step:52360[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:11 step:52365[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:11 step:52370[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:11 step:52375[D loss: 1.000014] [G loss: 1.000028]\n",
      "epoch:11 step:52380[D loss: 0.999999] [G loss: 1.000012]\n",
      "epoch:11 step:52385[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:11 step:52390[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:11 step:52395[D loss: 0.999998] [G loss: 1.000051]\n",
      "epoch:11 step:52400[D loss: 0.999968] [G loss: 1.000068]\n",
      "##############\n",
      "[2.53356164 2.14881286 2.17499674 3.84068324 1.49292607 7.29380321\n",
      " 2.09368382 3.93617246 3.98786301 5.58398678]\n",
      "##########\n",
      "epoch:11 step:52405[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:11 step:52410[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:11 step:52415[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:11 step:52420[D loss: 0.999958] [G loss: 1.000123]\n",
      "epoch:11 step:52425[D loss: 1.000027] [G loss: 1.000073]\n",
      "epoch:11 step:52430[D loss: 1.000015] [G loss: 1.000032]\n",
      "epoch:11 step:52435[D loss: 0.999941] [G loss: 1.000117]\n",
      "epoch:11 step:52440[D loss: 0.999951] [G loss: 1.000123]\n",
      "epoch:11 step:52445[D loss: 0.999977] [G loss: 1.000106]\n",
      "epoch:11 step:52450[D loss: 0.999949] [G loss: 1.000102]\n",
      "epoch:11 step:52455[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:11 step:52460[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:11 step:52465[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:11 step:52470[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:11 step:52475[D loss: 1.000025] [G loss: 1.000006]\n",
      "epoch:11 step:52480[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:11 step:52485[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:11 step:52490[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:11 step:52495[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:11 step:52500[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:11 step:52505[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:11 step:52510[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:11 step:52515[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:11 step:52520[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:11 step:52525[D loss: 1.000008] [G loss: 1.000040]\n",
      "epoch:11 step:52530[D loss: 0.999939] [G loss: 1.000140]\n",
      "epoch:11 step:52535[D loss: 1.000014] [G loss: 1.000062]\n",
      "epoch:11 step:52540[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:11 step:52545[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:11 step:52550[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:11 step:52555[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:11 step:52560[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:11 step:52565[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:11 step:52570[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:11 step:52575[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:11 step:52580[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:11 step:52585[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:11 step:52590[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:11 step:52595[D loss: 0.999952] [G loss: 1.000120]\n",
      "epoch:11 step:52600[D loss: 0.999975] [G loss: 1.000075]\n",
      "##############\n",
      "[2.63053836 2.17538979 2.16178827 3.81129692 1.47093744 7.20928428\n",
      " 2.14007708 3.93188288 3.96889133 5.90569169]\n",
      "##########\n",
      "epoch:11 step:52605[D loss: 0.999990] [G loss: 1.000101]\n",
      "epoch:11 step:52610[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:11 step:52615[D loss: 1.000036] [G loss: 0.999998]\n",
      "epoch:11 step:52620[D loss: 1.000097] [G loss: 1.000041]\n",
      "epoch:11 step:52625[D loss: 0.999949] [G loss: 1.000109]\n",
      "epoch:11 step:52630[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:11 step:52635[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:11 step:52640[D loss: 1.000010] [G loss: 1.000001]\n",
      "epoch:11 step:52645[D loss: 1.000005] [G loss: 0.999990]\n",
      "epoch:11 step:52650[D loss: 1.000017] [G loss: 0.999988]\n",
      "epoch:11 step:52655[D loss: 0.999952] [G loss: 1.000057]\n",
      "epoch:11 step:52660[D loss: 1.000021] [G loss: 0.999990]\n",
      "epoch:11 step:52665[D loss: 1.000030] [G loss: 1.000081]\n",
      "epoch:11 step:52670[D loss: 1.000059] [G loss: 0.999982]\n",
      "epoch:11 step:52675[D loss: 0.999918] [G loss: 1.000111]\n",
      "epoch:11 step:52680[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:11 step:52685[D loss: 0.999985] [G loss: 1.000125]\n",
      "epoch:11 step:52690[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:11 step:52695[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:11 step:52700[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:11 step:52705[D loss: 0.999982] [G loss: 1.000106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:52710[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:11 step:52715[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:11 step:52720[D loss: 0.999960] [G loss: 1.000112]\n",
      "epoch:11 step:52725[D loss: 0.999997] [G loss: 1.000074]\n",
      "epoch:11 step:52730[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:11 step:52735[D loss: 1.000001] [G loss: 1.000003]\n",
      "epoch:11 step:52740[D loss: 0.999980] [G loss: 1.000115]\n",
      "epoch:11 step:52745[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:11 step:52750[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:11 step:52755[D loss: 0.999971] [G loss: 1.000112]\n",
      "epoch:11 step:52760[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:11 step:52765[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:11 step:52770[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:11 step:52775[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:11 step:52780[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:11 step:52785[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:11 step:52790[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:11 step:52795[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:11 step:52800[D loss: 0.999994] [G loss: 1.000040]\n",
      "##############\n",
      "[2.60104666 2.1473444  2.24481943 3.76865152 1.50746822 8.54218238\n",
      " 2.24657329 3.73168479 4.03319195 5.36780126]\n",
      "##########\n",
      "epoch:11 step:52805[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:11 step:52810[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:11 step:52815[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:11 step:52820[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:11 step:52825[D loss: 1.000024] [G loss: 1.000017]\n",
      "epoch:11 step:52830[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:11 step:52835[D loss: 0.999994] [G loss: 1.000081]\n",
      "epoch:11 step:52840[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:11 step:52845[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:11 step:52850[D loss: 1.000028] [G loss: 1.000023]\n",
      "epoch:11 step:52855[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:11 step:52860[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:11 step:52865[D loss: 1.000016] [G loss: 1.000027]\n",
      "epoch:11 step:52870[D loss: 0.999955] [G loss: 1.000109]\n",
      "epoch:11 step:52875[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:11 step:52880[D loss: 1.000002] [G loss: 1.000016]\n",
      "epoch:11 step:52885[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:11 step:52890[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:11 step:52895[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:11 step:52900[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:11 step:52905[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:11 step:52910[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:11 step:52915[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:11 step:52920[D loss: 1.000000] [G loss: 0.999989]\n",
      "epoch:11 step:52925[D loss: 0.999954] [G loss: 1.000125]\n",
      "epoch:11 step:52930[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:11 step:52935[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:11 step:52940[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:11 step:52945[D loss: 0.999996] [G loss: 1.000008]\n",
      "epoch:11 step:52950[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:11 step:52955[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:11 step:52960[D loss: 1.000008] [G loss: 0.999999]\n",
      "epoch:11 step:52965[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:11 step:52970[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:11 step:52975[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:11 step:52980[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:11 step:52985[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:11 step:52990[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:11 step:52995[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:11 step:53000[D loss: 0.999960] [G loss: 1.000056]\n",
      "##############\n",
      "[2.49817305 2.0450241  2.08611418 3.70508878 1.35903738 6.80073398\n",
      " 2.2622113  3.65867095 3.93195759 5.49190761]\n",
      "##########\n",
      "epoch:11 step:53005[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:11 step:53010[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:11 step:53015[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:11 step:53020[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:11 step:53025[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:11 step:53030[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:11 step:53035[D loss: 0.999990] [G loss: 1.000086]\n",
      "epoch:11 step:53040[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:11 step:53045[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:11 step:53050[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:11 step:53055[D loss: 1.000004] [G loss: 1.000052]\n",
      "epoch:11 step:53060[D loss: 0.999999] [G loss: 1.000046]\n",
      "epoch:11 step:53065[D loss: 1.000024] [G loss: 1.000044]\n",
      "epoch:11 step:53070[D loss: 0.999943] [G loss: 1.000086]\n",
      "epoch:11 step:53075[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:11 step:53080[D loss: 1.000010] [G loss: 1.000029]\n",
      "epoch:11 step:53085[D loss: 1.000012] [G loss: 1.000007]\n",
      "epoch:11 step:53090[D loss: 1.000031] [G loss: 1.000020]\n",
      "epoch:11 step:53095[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:11 step:53100[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:11 step:53105[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:11 step:53110[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:11 step:53115[D loss: 1.000029] [G loss: 1.000074]\n",
      "epoch:11 step:53120[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:11 step:53125[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:11 step:53130[D loss: 1.000006] [G loss: 1.000043]\n",
      "epoch:11 step:53135[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:11 step:53140[D loss: 1.000029] [G loss: 1.000053]\n",
      "epoch:11 step:53145[D loss: 1.000004] [G loss: 1.000078]\n",
      "epoch:11 step:53150[D loss: 1.000043] [G loss: 1.000000]\n",
      "epoch:11 step:53155[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:11 step:53160[D loss: 0.999943] [G loss: 1.000073]\n",
      "epoch:11 step:53165[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:11 step:53170[D loss: 1.000012] [G loss: 1.000019]\n",
      "epoch:11 step:53175[D loss: 0.999935] [G loss: 1.000063]\n",
      "epoch:11 step:53180[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:11 step:53185[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:11 step:53190[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:11 step:53195[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:11 step:53200[D loss: 0.999982] [G loss: 1.000079]\n",
      "##############\n",
      "[2.61543189 2.08303686 2.11779502 3.70731239 1.43893468 6.8492875\n",
      " 2.10192057 3.78937418 3.90441732 4.52208406]\n",
      "##########\n",
      "epoch:11 step:53205[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:11 step:53210[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:11 step:53215[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:11 step:53220[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:11 step:53225[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:11 step:53230[D loss: 0.999947] [G loss: 1.000096]\n",
      "epoch:11 step:53235[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:11 step:53240[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:11 step:53245[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:11 step:53250[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:11 step:53255[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:11 step:53260[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:11 step:53265[D loss: 1.000063] [G loss: 0.999976]\n",
      "epoch:11 step:53270[D loss: 0.999932] [G loss: 1.000104]\n",
      "epoch:11 step:53275[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:11 step:53280[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:11 step:53285[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:11 step:53290[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:11 step:53295[D loss: 0.999956] [G loss: 1.000122]\n",
      "epoch:11 step:53300[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:11 step:53305[D loss: 0.999988] [G loss: 1.000039]\n",
      "epoch:11 step:53310[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:11 step:53315[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:11 step:53320[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:11 step:53325[D loss: 0.999997] [G loss: 1.000103]\n",
      "epoch:11 step:53330[D loss: 0.999953] [G loss: 1.000067]\n",
      "epoch:11 step:53335[D loss: 0.999995] [G loss: 1.000090]\n",
      "epoch:11 step:53340[D loss: 0.999934] [G loss: 1.000095]\n",
      "epoch:11 step:53345[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:11 step:53350[D loss: 0.999998] [G loss: 1.000096]\n",
      "epoch:11 step:53355[D loss: 1.000061] [G loss: 1.000043]\n",
      "epoch:11 step:53360[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:11 step:53365[D loss: 0.999917] [G loss: 1.000160]\n",
      "epoch:11 step:53370[D loss: 0.999972] [G loss: 1.000132]\n",
      "epoch:11 step:53375[D loss: 0.999958] [G loss: 1.000114]\n",
      "epoch:11 step:53380[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:11 step:53385[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:11 step:53390[D loss: 0.999966] [G loss: 1.000093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:53395[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:11 step:53400[D loss: 1.000009] [G loss: 1.000010]\n",
      "##############\n",
      "[2.59384245 2.10049981 2.126568   3.89785894 1.46865297 6.54510455\n",
      " 2.13169702 3.66479978 4.01502978 4.88693716]\n",
      "##########\n",
      "epoch:11 step:53405[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:11 step:53410[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:11 step:53415[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:11 step:53420[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:11 step:53425[D loss: 1.000077] [G loss: 0.999972]\n",
      "epoch:11 step:53430[D loss: 0.999982] [G loss: 1.000014]\n",
      "epoch:11 step:53435[D loss: 0.999934] [G loss: 1.000074]\n",
      "epoch:11 step:53440[D loss: 1.000009] [G loss: 1.000020]\n",
      "epoch:11 step:53445[D loss: 0.999977] [G loss: 1.000022]\n",
      "epoch:11 step:53450[D loss: 0.999996] [G loss: 1.000068]\n",
      "epoch:11 step:53455[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:11 step:53460[D loss: 1.000045] [G loss: 1.000004]\n",
      "epoch:11 step:53465[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:11 step:53470[D loss: 1.000022] [G loss: 1.000059]\n",
      "epoch:11 step:53475[D loss: 0.999990] [G loss: 1.000091]\n",
      "epoch:11 step:53480[D loss: 0.999992] [G loss: 1.000101]\n",
      "epoch:11 step:53485[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:11 step:53490[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:11 step:53495[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:11 step:53500[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:11 step:53505[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:11 step:53510[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:11 step:53515[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:11 step:53520[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:11 step:53525[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:11 step:53530[D loss: 1.000010] [G loss: 0.999976]\n",
      "epoch:11 step:53535[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:11 step:53540[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:11 step:53545[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:11 step:53550[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:11 step:53555[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:11 step:53560[D loss: 1.000018] [G loss: 0.999953]\n",
      "epoch:11 step:53565[D loss: 1.000001] [G loss: 0.999991]\n",
      "epoch:11 step:53570[D loss: 1.000047] [G loss: 0.999971]\n",
      "epoch:11 step:53575[D loss: 0.999947] [G loss: 1.000070]\n",
      "epoch:11 step:53580[D loss: 0.999934] [G loss: 1.000141]\n",
      "epoch:11 step:53585[D loss: 1.000039] [G loss: 1.000040]\n",
      "epoch:11 step:53590[D loss: 1.000013] [G loss: 1.000004]\n",
      "epoch:11 step:53595[D loss: 0.999939] [G loss: 1.000075]\n",
      "epoch:11 step:53600[D loss: 0.999975] [G loss: 1.000080]\n",
      "##############\n",
      "[2.5053389  2.02833613 2.04022879 3.6227763  1.39317021 7.42482614\n",
      " 2.3501831  3.80547814 3.94306934 4.8614784 ]\n",
      "##########\n",
      "epoch:11 step:53605[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:11 step:53610[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:11 step:53615[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:11 step:53620[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:11 step:53625[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:11 step:53630[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:11 step:53635[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:11 step:53640[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:11 step:53645[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:11 step:53650[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:11 step:53655[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:11 step:53660[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:11 step:53665[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:11 step:53670[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:11 step:53675[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:11 step:53680[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:11 step:53685[D loss: 0.999991] [G loss: 1.000017]\n",
      "epoch:11 step:53690[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:11 step:53695[D loss: 0.999993] [G loss: 1.000076]\n",
      "epoch:11 step:53700[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:11 step:53705[D loss: 1.000000] [G loss: 1.000105]\n",
      "epoch:11 step:53710[D loss: 0.999958] [G loss: 1.000123]\n",
      "epoch:11 step:53715[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:11 step:53720[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:11 step:53725[D loss: 1.000020] [G loss: 0.999982]\n",
      "epoch:11 step:53730[D loss: 0.999960] [G loss: 1.000053]\n",
      "epoch:11 step:53735[D loss: 0.999997] [G loss: 1.000066]\n",
      "epoch:11 step:53740[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:11 step:53745[D loss: 0.999991] [G loss: 1.000088]\n",
      "epoch:11 step:53750[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:11 step:53755[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:11 step:53760[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:11 step:53765[D loss: 0.999980] [G loss: 1.000101]\n",
      "epoch:11 step:53770[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:11 step:53775[D loss: 0.999949] [G loss: 1.000134]\n",
      "epoch:11 step:53780[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:11 step:53785[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:11 step:53790[D loss: 1.000059] [G loss: 0.999939]\n",
      "epoch:11 step:53795[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:11 step:53800[D loss: 1.000001] [G loss: 0.999997]\n",
      "##############\n",
      "[2.5569032  2.11539043 2.0593127  3.91943643 1.42596755 7.48652366\n",
      " 2.15066566 3.79507286 3.94536278 5.42785562]\n",
      "##########\n",
      "epoch:11 step:53805[D loss: 0.999989] [G loss: 1.000099]\n",
      "epoch:11 step:53810[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:11 step:53815[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:11 step:53820[D loss: 0.999956] [G loss: 1.000135]\n",
      "epoch:11 step:53825[D loss: 1.000002] [G loss: 1.000068]\n",
      "epoch:11 step:53830[D loss: 1.000045] [G loss: 1.000086]\n",
      "epoch:11 step:53835[D loss: 0.999941] [G loss: 1.000128]\n",
      "epoch:11 step:53840[D loss: 0.999929] [G loss: 1.000146]\n",
      "epoch:11 step:53845[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:11 step:53850[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:11 step:53855[D loss: 1.000056] [G loss: 0.999946]\n",
      "epoch:11 step:53860[D loss: 1.000011] [G loss: 1.000028]\n",
      "epoch:11 step:53865[D loss: 0.999953] [G loss: 1.000067]\n",
      "epoch:11 step:53870[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:11 step:53875[D loss: 0.999965] [G loss: 1.000120]\n",
      "epoch:11 step:53880[D loss: 1.000008] [G loss: 1.000073]\n",
      "epoch:11 step:53885[D loss: 0.999969] [G loss: 1.000118]\n",
      "epoch:11 step:53890[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:11 step:53895[D loss: 0.999966] [G loss: 1.000125]\n",
      "epoch:11 step:53900[D loss: 0.999985] [G loss: 1.000101]\n",
      "epoch:11 step:53905[D loss: 0.999994] [G loss: 1.000075]\n",
      "epoch:11 step:53910[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:11 step:53915[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:11 step:53920[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:11 step:53925[D loss: 0.999975] [G loss: 1.000113]\n",
      "epoch:11 step:53930[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:11 step:53935[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:11 step:53940[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:11 step:53945[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:11 step:53950[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:11 step:53955[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:11 step:53960[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:11 step:53965[D loss: 0.999991] [G loss: 1.000082]\n",
      "epoch:11 step:53970[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:11 step:53975[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:11 step:53980[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:11 step:53985[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:11 step:53990[D loss: 0.999996] [G loss: 1.000058]\n",
      "epoch:11 step:53995[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:11 step:54000[D loss: 0.999993] [G loss: 1.000111]\n",
      "##############\n",
      "[2.55859819 2.14529689 2.20871089 3.71080566 1.41830172 8.67171406\n",
      " 2.17908311 3.69881654 3.92836742 4.80810485]\n",
      "##########\n",
      "epoch:11 step:54005[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:11 step:54010[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:11 step:54015[D loss: 1.000071] [G loss: 1.000067]\n",
      "epoch:11 step:54020[D loss: 0.999974] [G loss: 1.000121]\n",
      "epoch:11 step:54025[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:11 step:54030[D loss: 1.000004] [G loss: 1.000026]\n",
      "epoch:11 step:54035[D loss: 0.999996] [G loss: 1.000078]\n",
      "epoch:11 step:54040[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:11 step:54045[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:11 step:54050[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:11 step:54055[D loss: 0.999973] [G loss: 1.000100]\n",
      "epoch:11 step:54060[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:11 step:54065[D loss: 0.999970] [G loss: 1.000083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:54070[D loss: 1.000029] [G loss: 1.000021]\n",
      "epoch:11 step:54075[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:11 step:54080[D loss: 0.999952] [G loss: 1.000091]\n",
      "epoch:11 step:54085[D loss: 1.000043] [G loss: 1.000033]\n",
      "epoch:11 step:54090[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:11 step:54095[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:11 step:54100[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:11 step:54105[D loss: 1.000003] [G loss: 1.000020]\n",
      "epoch:11 step:54110[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:11 step:54115[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:11 step:54120[D loss: 1.000074] [G loss: 0.999972]\n",
      "epoch:11 step:54125[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:11 step:54130[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:11 step:54135[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:11 step:54140[D loss: 0.999943] [G loss: 1.000148]\n",
      "epoch:11 step:54145[D loss: 1.000012] [G loss: 1.000010]\n",
      "epoch:11 step:54150[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:11 step:54155[D loss: 1.000005] [G loss: 0.999987]\n",
      "epoch:11 step:54160[D loss: 0.999993] [G loss: 1.000069]\n",
      "epoch:11 step:54165[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:11 step:54170[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:11 step:54175[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:11 step:54180[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:11 step:54185[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:11 step:54190[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:11 step:54195[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:11 step:54200[D loss: 0.999996] [G loss: 1.000067]\n",
      "##############\n",
      "[2.53840693 2.26833136 2.1810444  3.92676263 1.49292594 9.27426719\n",
      " 2.27173333 4.00511167 3.92800888 5.96881635]\n",
      "##########\n",
      "epoch:11 step:54205[D loss: 1.000018] [G loss: 1.000007]\n",
      "epoch:11 step:54210[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:11 step:54215[D loss: 1.000035] [G loss: 1.000068]\n",
      "epoch:11 step:54220[D loss: 1.000049] [G loss: 1.000002]\n",
      "epoch:11 step:54225[D loss: 0.999992] [G loss: 1.000120]\n",
      "epoch:11 step:54230[D loss: 1.000073] [G loss: 0.999951]\n",
      "epoch:11 step:54235[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:11 step:54240[D loss: 0.999946] [G loss: 1.000096]\n",
      "epoch:11 step:54245[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:11 step:54250[D loss: 1.000007] [G loss: 1.000006]\n",
      "epoch:11 step:54255[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:11 step:54260[D loss: 1.000005] [G loss: 1.000064]\n",
      "epoch:11 step:54265[D loss: 1.000018] [G loss: 1.000077]\n",
      "epoch:11 step:54270[D loss: 0.999868] [G loss: 1.000189]\n",
      "epoch:11 step:54275[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:11 step:54280[D loss: 0.999952] [G loss: 1.000103]\n",
      "epoch:11 step:54285[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:11 step:54290[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:11 step:54295[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:11 step:54300[D loss: 1.000019] [G loss: 0.999992]\n",
      "epoch:11 step:54305[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:11 step:54310[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:11 step:54315[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:11 step:54320[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:11 step:54325[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:11 step:54330[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:11 step:54335[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:11 step:54340[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:11 step:54345[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:11 step:54350[D loss: 1.000007] [G loss: 1.000029]\n",
      "epoch:11 step:54355[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:11 step:54360[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:11 step:54365[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:11 step:54370[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:11 step:54375[D loss: 0.999994] [G loss: 1.000070]\n",
      "epoch:11 step:54380[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:11 step:54385[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:11 step:54390[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:11 step:54395[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:11 step:54400[D loss: 1.000012] [G loss: 1.000039]\n",
      "##############\n",
      "[2.58144622 2.22857191 2.25055229 4.19803992 1.42563309 8.5148971\n",
      " 2.30738045 3.79779934 3.96312379 5.49542262]\n",
      "##########\n",
      "epoch:11 step:54405[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:11 step:54410[D loss: 1.000021] [G loss: 1.000055]\n",
      "epoch:11 step:54415[D loss: 1.000036] [G loss: 0.999962]\n",
      "epoch:11 step:54420[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:11 step:54425[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:11 step:54430[D loss: 0.999986] [G loss: 1.000086]\n",
      "epoch:11 step:54435[D loss: 0.999950] [G loss: 1.000133]\n",
      "epoch:11 step:54440[D loss: 0.999974] [G loss: 1.000101]\n",
      "epoch:11 step:54445[D loss: 0.999958] [G loss: 1.000116]\n",
      "epoch:11 step:54450[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:11 step:54455[D loss: 0.999947] [G loss: 1.000044]\n",
      "epoch:11 step:54460[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:11 step:54465[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:11 step:54470[D loss: 0.999950] [G loss: 1.000047]\n",
      "epoch:11 step:54475[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:11 step:54480[D loss: 0.999960] [G loss: 1.000111]\n",
      "epoch:11 step:54485[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:11 step:54490[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:11 step:54495[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:11 step:54500[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:11 step:54505[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:11 step:54510[D loss: 1.000017] [G loss: 1.000079]\n",
      "epoch:11 step:54515[D loss: 0.999950] [G loss: 1.000118]\n",
      "epoch:11 step:54520[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:11 step:54525[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:11 step:54530[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:11 step:54535[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:11 step:54540[D loss: 1.000001] [G loss: 1.000048]\n",
      "epoch:11 step:54545[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:11 step:54550[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:11 step:54555[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:11 step:54560[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:11 step:54565[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:11 step:54570[D loss: 1.000009] [G loss: 1.000043]\n",
      "epoch:11 step:54575[D loss: 1.000002] [G loss: 1.000059]\n",
      "epoch:11 step:54580[D loss: 1.000035] [G loss: 1.000049]\n",
      "epoch:11 step:54585[D loss: 0.999889] [G loss: 1.000141]\n",
      "epoch:11 step:54590[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:11 step:54595[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:11 step:54600[D loss: 0.999985] [G loss: 1.000047]\n",
      "##############\n",
      "[2.62377025 2.14333317 2.16615929 3.63604835 1.48718663 7.675768\n",
      " 2.28019811 3.61263429 3.94074655 5.20181124]\n",
      "##########\n",
      "epoch:11 step:54605[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:11 step:54610[D loss: 1.000007] [G loss: 0.999994]\n",
      "epoch:11 step:54615[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:11 step:54620[D loss: 1.000007] [G loss: 1.000074]\n",
      "epoch:11 step:54625[D loss: 0.999948] [G loss: 1.000150]\n",
      "epoch:11 step:54630[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:11 step:54635[D loss: 1.000007] [G loss: 1.000034]\n",
      "epoch:11 step:54640[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:11 step:54645[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:11 step:54650[D loss: 0.999999] [G loss: 1.000031]\n",
      "epoch:11 step:54655[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:11 step:54660[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:11 step:54665[D loss: 0.999994] [G loss: 1.000022]\n",
      "epoch:11 step:54670[D loss: 1.000014] [G loss: 0.999991]\n",
      "epoch:11 step:54675[D loss: 1.000008] [G loss: 0.999992]\n",
      "epoch:11 step:54680[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:11 step:54685[D loss: 0.999916] [G loss: 1.000150]\n",
      "epoch:11 step:54690[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:11 step:54695[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:11 step:54700[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:11 step:54705[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:11 step:54710[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:11 step:54715[D loss: 1.000004] [G loss: 1.000012]\n",
      "epoch:11 step:54720[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:11 step:54725[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:11 step:54730[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:11 step:54735[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:11 step:54740[D loss: 1.000019] [G loss: 1.000003]\n",
      "epoch:11 step:54745[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:11 step:54750[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:11 step:54755[D loss: 0.999990] [G loss: 1.000036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:54760[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:11 step:54765[D loss: 1.000012] [G loss: 1.000002]\n",
      "epoch:11 step:54770[D loss: 0.999966] [G loss: 1.000033]\n",
      "epoch:11 step:54775[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:11 step:54780[D loss: 0.999984] [G loss: 1.000104]\n",
      "epoch:11 step:54785[D loss: 0.999984] [G loss: 1.000011]\n",
      "epoch:11 step:54790[D loss: 0.999995] [G loss: 1.000079]\n",
      "epoch:11 step:54795[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:11 step:54800[D loss: 0.999965] [G loss: 1.000083]\n",
      "##############\n",
      "[2.56309907 2.10802268 2.10122587 3.81610835 1.41339609 7.3795594\n",
      " 2.18081292 3.86432966 3.97347174 5.04886756]\n",
      "##########\n",
      "epoch:11 step:54805[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:11 step:54810[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:11 step:54815[D loss: 1.000013] [G loss: 1.000003]\n",
      "epoch:11 step:54820[D loss: 1.000044] [G loss: 0.999953]\n",
      "epoch:11 step:54825[D loss: 0.999948] [G loss: 1.000073]\n",
      "epoch:11 step:54830[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:11 step:54835[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:11 step:54840[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:11 step:54845[D loss: 1.000021] [G loss: 1.000015]\n",
      "epoch:11 step:54850[D loss: 0.999955] [G loss: 1.000114]\n",
      "epoch:11 step:54855[D loss: 0.999930] [G loss: 1.000085]\n",
      "epoch:11 step:54860[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:11 step:54865[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:11 step:54870[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:11 step:54875[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:11 step:54880[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:11 step:54885[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:11 step:54890[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:11 step:54895[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:11 step:54900[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:11 step:54905[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:11 step:54910[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:11 step:54915[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:11 step:54920[D loss: 1.000005] [G loss: 0.999976]\n",
      "epoch:11 step:54925[D loss: 1.000014] [G loss: 1.000047]\n",
      "epoch:11 step:54930[D loss: 1.000014] [G loss: 1.000013]\n",
      "epoch:11 step:54935[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:11 step:54940[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:11 step:54945[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:11 step:54950[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:11 step:54955[D loss: 0.999999] [G loss: 1.000005]\n",
      "epoch:11 step:54960[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:11 step:54965[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:11 step:54970[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:11 step:54975[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:11 step:54980[D loss: 0.999983] [G loss: 1.000112]\n",
      "epoch:11 step:54985[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:11 step:54990[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:11 step:54995[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:11 step:55000[D loss: 0.999979] [G loss: 1.000071]\n",
      "##############\n",
      "[2.63869451 2.09864877 2.20478284 3.66571475 1.40856038 7.51716554\n",
      " 2.40727711 3.85701867 3.9713676  5.55115755]\n",
      "##########\n",
      "epoch:11 step:55005[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:11 step:55010[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:11 step:55015[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:11 step:55020[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:11 step:55025[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:11 step:55030[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:11 step:55035[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:11 step:55040[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:11 step:55045[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:11 step:55050[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:11 step:55055[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:11 step:55060[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:11 step:55065[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:11 step:55070[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:11 step:55075[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:11 step:55080[D loss: 1.000044] [G loss: 0.999985]\n",
      "epoch:11 step:55085[D loss: 1.000030] [G loss: 0.999984]\n",
      "epoch:11 step:55090[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:11 step:55095[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:11 step:55100[D loss: 0.999938] [G loss: 1.000118]\n",
      "epoch:11 step:55105[D loss: 0.999993] [G loss: 1.000118]\n",
      "epoch:11 step:55110[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:11 step:55115[D loss: 0.999999] [G loss: 1.000049]\n",
      "epoch:11 step:55120[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:11 step:55125[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:11 step:55130[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:11 step:55135[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:11 step:55140[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:11 step:55145[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:11 step:55150[D loss: 0.999979] [G loss: 1.000097]\n",
      "epoch:11 step:55155[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:11 step:55160[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:11 step:55165[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:11 step:55170[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:11 step:55175[D loss: 1.000010] [G loss: 0.999997]\n",
      "epoch:11 step:55180[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:11 step:55185[D loss: 0.999995] [G loss: 1.000067]\n",
      "epoch:11 step:55190[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:11 step:55195[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:11 step:55200[D loss: 0.999961] [G loss: 1.000076]\n",
      "##############\n",
      "[2.59729135 2.15167737 2.20011915 3.81173027 1.44266733 7.83367204\n",
      " 2.21619623 3.81944691 3.95762346 5.00810335]\n",
      "##########\n",
      "epoch:11 step:55205[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:11 step:55210[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:11 step:55215[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:11 step:55220[D loss: 1.000009] [G loss: 1.000091]\n",
      "epoch:11 step:55225[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:11 step:55230[D loss: 0.999976] [G loss: 1.000108]\n",
      "epoch:11 step:55235[D loss: 1.000003] [G loss: 1.000034]\n",
      "epoch:11 step:55240[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:11 step:55245[D loss: 1.000017] [G loss: 1.000046]\n",
      "epoch:11 step:55250[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:11 step:55255[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:11 step:55260[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:11 step:55265[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:11 step:55270[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:11 step:55275[D loss: 0.999992] [G loss: 1.000086]\n",
      "epoch:11 step:55280[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:11 step:55285[D loss: 1.000045] [G loss: 0.999931]\n",
      "epoch:11 step:55290[D loss: 0.999954] [G loss: 1.000074]\n",
      "epoch:11 step:55295[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:11 step:55300[D loss: 0.999943] [G loss: 1.000107]\n",
      "epoch:11 step:55305[D loss: 1.000027] [G loss: 1.000023]\n",
      "epoch:11 step:55310[D loss: 0.999961] [G loss: 1.000097]\n",
      "epoch:11 step:55315[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:11 step:55320[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:11 step:55325[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:11 step:55330[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:11 step:55335[D loss: 1.000023] [G loss: 0.999990]\n",
      "epoch:11 step:55340[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:11 step:55345[D loss: 1.000024] [G loss: 1.000020]\n",
      "epoch:11 step:55350[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:11 step:55355[D loss: 0.999955] [G loss: 1.000115]\n",
      "epoch:11 step:55360[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:11 step:55365[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:11 step:55370[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:11 step:55375[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:11 step:55380[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:11 step:55385[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:11 step:55390[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:11 step:55395[D loss: 1.000002] [G loss: 1.000033]\n",
      "epoch:11 step:55400[D loss: 0.999963] [G loss: 1.000091]\n",
      "##############\n",
      "[2.61238505 2.19568513 2.21184722 3.8958971  1.45177957 7.49904549\n",
      " 2.30945733 3.70352568 4.02957966 6.33405365]\n",
      "##########\n",
      "epoch:11 step:55405[D loss: 0.999941] [G loss: 1.000159]\n",
      "epoch:11 step:55410[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:11 step:55415[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:11 step:55420[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:11 step:55425[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:11 step:55430[D loss: 0.999960] [G loss: 1.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:55435[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:11 step:55440[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:11 step:55445[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:11 step:55450[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:11 step:55455[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:11 step:55460[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:11 step:55465[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:11 step:55470[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:11 step:55475[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:11 step:55480[D loss: 0.999954] [G loss: 1.000120]\n",
      "epoch:11 step:55485[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:11 step:55490[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:11 step:55495[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:11 step:55500[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:11 step:55505[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:11 step:55510[D loss: 1.000024] [G loss: 1.000022]\n",
      "epoch:11 step:55515[D loss: 0.999944] [G loss: 1.000106]\n",
      "epoch:11 step:55520[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:11 step:55525[D loss: 1.000002] [G loss: 1.000054]\n",
      "epoch:11 step:55530[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:11 step:55535[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:11 step:55540[D loss: 1.000014] [G loss: 1.000015]\n",
      "epoch:11 step:55545[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:11 step:55550[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:11 step:55555[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:11 step:55560[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:11 step:55565[D loss: 0.999972] [G loss: 1.000021]\n",
      "epoch:11 step:55570[D loss: 0.999959] [G loss: 1.000126]\n",
      "epoch:11 step:55575[D loss: 1.000062] [G loss: 1.000015]\n",
      "epoch:11 step:55580[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:11 step:55585[D loss: 0.999955] [G loss: 1.000103]\n",
      "epoch:11 step:55590[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:11 step:55595[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:11 step:55600[D loss: 0.999967] [G loss: 1.000050]\n",
      "##############\n",
      "[2.55446485 2.12175447 2.15481731 3.6944334  1.43659893 7.72060584\n",
      " 2.1623538  3.62596543 3.90908957 5.63611164]\n",
      "##########\n",
      "epoch:11 step:55605[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:11 step:55610[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:11 step:55615[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:11 step:55620[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:11 step:55625[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:11 step:55630[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:11 step:55635[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:11 step:55640[D loss: 0.999953] [G loss: 1.000103]\n",
      "epoch:11 step:55645[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:11 step:55650[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:11 step:55655[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:11 step:55660[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:11 step:55665[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:11 step:55670[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:11 step:55675[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:11 step:55680[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:11 step:55685[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:11 step:55690[D loss: 0.999990] [G loss: 0.999998]\n",
      "epoch:11 step:55695[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:11 step:55700[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:11 step:55705[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:11 step:55710[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:11 step:55715[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:11 step:55720[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:11 step:55725[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:11 step:55730[D loss: 1.000009] [G loss: 1.000050]\n",
      "epoch:11 step:55735[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:11 step:55740[D loss: 1.000023] [G loss: 1.000027]\n",
      "epoch:11 step:55745[D loss: 1.000005] [G loss: 0.999982]\n",
      "epoch:11 step:55750[D loss: 0.999990] [G loss: 1.000082]\n",
      "epoch:11 step:55755[D loss: 1.000032] [G loss: 1.000019]\n",
      "epoch:11 step:55760[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:11 step:55765[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:11 step:55770[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:11 step:55775[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:11 step:55780[D loss: 0.999984] [G loss: 1.000097]\n",
      "epoch:11 step:55785[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:11 step:55790[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:11 step:55795[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:11 step:55800[D loss: 0.999992] [G loss: 1.000040]\n",
      "##############\n",
      "[2.65349586 2.13974137 2.25293019 4.00057281 1.44111095 7.98890219\n",
      " 2.30663987 3.64524978 4.04517844 5.13467409]\n",
      "##########\n",
      "epoch:11 step:55805[D loss: 0.999978] [G loss: 1.000023]\n",
      "epoch:11 step:55810[D loss: 0.999997] [G loss: 1.000062]\n",
      "epoch:11 step:55815[D loss: 1.000001] [G loss: 1.000063]\n",
      "epoch:11 step:55820[D loss: 0.999965] [G loss: 1.000042]\n",
      "epoch:11 step:55825[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:11 step:55830[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:11 step:55835[D loss: 0.999948] [G loss: 1.000080]\n",
      "epoch:11 step:55840[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:11 step:55845[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:11 step:55850[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:11 step:55855[D loss: 0.999985] [G loss: 1.000098]\n",
      "epoch:11 step:55860[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:11 step:55865[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:11 step:55870[D loss: 1.000008] [G loss: 0.999992]\n",
      "epoch:11 step:55875[D loss: 1.000003] [G loss: 1.000013]\n",
      "epoch:11 step:55880[D loss: 0.999970] [G loss: 1.000096]\n",
      "epoch:11 step:55885[D loss: 0.999971] [G loss: 1.000133]\n",
      "epoch:11 step:55890[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:11 step:55895[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:11 step:55900[D loss: 0.999996] [G loss: 1.000066]\n",
      "epoch:11 step:55905[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:11 step:55910[D loss: 1.000013] [G loss: 1.000001]\n",
      "epoch:11 step:55915[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:11 step:55920[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:11 step:55925[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:11 step:55930[D loss: 0.999945] [G loss: 1.000084]\n",
      "epoch:11 step:55935[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:11 step:55940[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:11 step:55945[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:11 step:55950[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:11 step:55955[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:11 step:55960[D loss: 1.000036] [G loss: 0.999977]\n",
      "epoch:11 step:55965[D loss: 0.999965] [G loss: 1.000132]\n",
      "epoch:11 step:55970[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:11 step:55975[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:11 step:55980[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:11 step:55985[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:11 step:55990[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:11 step:55995[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:11 step:56000[D loss: 0.999983] [G loss: 1.000088]\n",
      "##############\n",
      "[2.53542891 2.14629702 2.26726794 4.25230925 1.48392708 7.96338498\n",
      " 2.26291986 3.7459074  3.96923733 5.31539389]\n",
      "##########\n",
      "epoch:11 step:56005[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:11 step:56010[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:11 step:56015[D loss: 0.999998] [G loss: 1.000078]\n",
      "epoch:11 step:56020[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:11 step:56025[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:11 step:56030[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:11 step:56035[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:11 step:56040[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:11 step:56045[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:11 step:56050[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:11 step:56055[D loss: 1.000006] [G loss: 1.000054]\n",
      "epoch:11 step:56060[D loss: 0.999948] [G loss: 1.000078]\n",
      "epoch:11 step:56065[D loss: 0.999978] [G loss: 1.000129]\n",
      "epoch:11 step:56070[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:11 step:56075[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:11 step:56080[D loss: 1.000006] [G loss: 0.999964]\n",
      "epoch:11 step:56085[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:11 step:56090[D loss: 0.999946] [G loss: 1.000071]\n",
      "epoch:11 step:56095[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:11 step:56100[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:11 step:56105[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:11 step:56110[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:11 step:56115[D loss: 0.999978] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:56120[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:11 step:56125[D loss: 0.999946] [G loss: 1.000089]\n",
      "epoch:11 step:56130[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:11 step:56135[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:11 step:56140[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:11 step:56145[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:11 step:56150[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:11 step:56155[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:11 step:56160[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:11 step:56165[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:11 step:56170[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:11 step:56175[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:11 step:56180[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:11 step:56185[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:11 step:56190[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:11 step:56195[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:11 step:56200[D loss: 0.999963] [G loss: 1.000083]\n",
      "##############\n",
      "[2.62876825 2.06558811 2.17446007 3.74380268 1.44373177 8.2117201\n",
      " 2.39088514 3.71595334 4.02880766 3.68945611]\n",
      "##########\n",
      "epoch:11 step:56205[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:11 step:56210[D loss: 1.000005] [G loss: 1.000007]\n",
      "epoch:11 step:56215[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:11 step:56220[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:12 step:56225[D loss: 1.000024] [G loss: 1.000046]\n",
      "epoch:12 step:56230[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:12 step:56235[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:12 step:56240[D loss: 0.999953] [G loss: 1.000061]\n",
      "epoch:12 step:56245[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:12 step:56250[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:12 step:56255[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:12 step:56260[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:12 step:56265[D loss: 0.999970] [G loss: 1.000137]\n",
      "epoch:12 step:56270[D loss: 1.000011] [G loss: 1.000140]\n",
      "epoch:12 step:56275[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:12 step:56280[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:12 step:56285[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:12 step:56290[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:12 step:56295[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:12 step:56300[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:12 step:56305[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:12 step:56310[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:12 step:56315[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:12 step:56320[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:12 step:56325[D loss: 0.999962] [G loss: 1.000108]\n",
      "epoch:12 step:56330[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:12 step:56335[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:12 step:56340[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:12 step:56345[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:12 step:56350[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:12 step:56355[D loss: 1.000013] [G loss: 1.000007]\n",
      "epoch:12 step:56360[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:12 step:56365[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:12 step:56370[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:12 step:56375[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:12 step:56380[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:12 step:56385[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:12 step:56390[D loss: 1.000040] [G loss: 0.999999]\n",
      "epoch:12 step:56395[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:12 step:56400[D loss: 1.000044] [G loss: 1.000018]\n",
      "##############\n",
      "[2.67214682 2.12728484 2.27660237 3.95571913 1.51913276 9.27426719\n",
      " 2.53154676 3.81577677 3.91569697 5.51460848]\n",
      "##########\n",
      "epoch:12 step:56405[D loss: 0.999947] [G loss: 1.000112]\n",
      "epoch:12 step:56410[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:12 step:56415[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:12 step:56420[D loss: 1.000024] [G loss: 1.000036]\n",
      "epoch:12 step:56425[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:12 step:56430[D loss: 0.999942] [G loss: 1.000128]\n",
      "epoch:12 step:56435[D loss: 0.999912] [G loss: 1.000169]\n",
      "epoch:12 step:56440[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:12 step:56445[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:12 step:56450[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:12 step:56455[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:12 step:56460[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:12 step:56465[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:12 step:56470[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:12 step:56475[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:12 step:56480[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:12 step:56485[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:12 step:56490[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:12 step:56495[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:12 step:56500[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:12 step:56505[D loss: 0.999989] [G loss: 1.000093]\n",
      "epoch:12 step:56510[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:12 step:56515[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:12 step:56520[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:12 step:56525[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:12 step:56530[D loss: 1.000007] [G loss: 1.000046]\n",
      "epoch:12 step:56535[D loss: 1.000063] [G loss: 0.999980]\n",
      "epoch:12 step:56540[D loss: 1.000027] [G loss: 1.000085]\n",
      "epoch:12 step:56545[D loss: 0.999947] [G loss: 1.000121]\n",
      "epoch:12 step:56550[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:12 step:56555[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:12 step:56560[D loss: 1.000021] [G loss: 1.000004]\n",
      "epoch:12 step:56565[D loss: 1.000011] [G loss: 1.000050]\n",
      "epoch:12 step:56570[D loss: 1.000035] [G loss: 0.999993]\n",
      "epoch:12 step:56575[D loss: 0.999924] [G loss: 1.000177]\n",
      "epoch:12 step:56580[D loss: 0.999974] [G loss: 1.000145]\n",
      "epoch:12 step:56585[D loss: 1.000001] [G loss: 0.999989]\n",
      "epoch:12 step:56590[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:12 step:56595[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:12 step:56600[D loss: 0.999972] [G loss: 1.000057]\n",
      "##############\n",
      "[2.59843939 2.14006292 2.31448559 3.78123258 1.51454549 8.24267376\n",
      " 2.39535147 3.78230548 4.03147534 5.46169565]\n",
      "##########\n",
      "epoch:12 step:56605[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:12 step:56610[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:12 step:56615[D loss: 1.000011] [G loss: 0.999986]\n",
      "epoch:12 step:56620[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:12 step:56625[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:12 step:56630[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:12 step:56635[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:12 step:56640[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:12 step:56645[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:12 step:56650[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:12 step:56655[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:12 step:56660[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:12 step:56665[D loss: 1.000019] [G loss: 1.000020]\n",
      "epoch:12 step:56670[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:12 step:56675[D loss: 0.999944] [G loss: 1.000112]\n",
      "epoch:12 step:56680[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:12 step:56685[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:12 step:56690[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:12 step:56695[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:12 step:56700[D loss: 1.000019] [G loss: 0.999988]\n",
      "epoch:12 step:56705[D loss: 0.999965] [G loss: 1.000121]\n",
      "epoch:12 step:56710[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:12 step:56715[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:12 step:56720[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:12 step:56725[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:12 step:56730[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:12 step:56735[D loss: 0.999969] [G loss: 1.000109]\n",
      "epoch:12 step:56740[D loss: 1.000012] [G loss: 1.000028]\n",
      "epoch:12 step:56745[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:12 step:56750[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:12 step:56755[D loss: 0.999983] [G loss: 1.000105]\n",
      "epoch:12 step:56760[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:12 step:56765[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:12 step:56770[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:12 step:56775[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:12 step:56780[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:12 step:56785[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:12 step:56790[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:12 step:56795[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:12 step:56800[D loss: 0.999970] [G loss: 1.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.67041787 2.21221149 2.35315256 3.92050442 1.50464767 8.51000851\n",
      " 2.35859438 3.9470644  4.01918728 6.27366533]\n",
      "##########\n",
      "epoch:12 step:56805[D loss: 0.999997] [G loss: 1.000083]\n",
      "epoch:12 step:56810[D loss: 1.000020] [G loss: 1.000051]\n",
      "epoch:12 step:56815[D loss: 1.000006] [G loss: 1.000077]\n",
      "epoch:12 step:56820[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:12 step:56825[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:12 step:56830[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:12 step:56835[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:12 step:56840[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:12 step:56845[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:12 step:56850[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:12 step:56855[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:12 step:56860[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:12 step:56865[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:12 step:56870[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:12 step:56875[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:12 step:56880[D loss: 1.000006] [G loss: 0.999999]\n",
      "epoch:12 step:56885[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:12 step:56890[D loss: 0.999944] [G loss: 1.000096]\n",
      "epoch:12 step:56895[D loss: 0.999983] [G loss: 1.000020]\n",
      "epoch:12 step:56900[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:12 step:56905[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:12 step:56910[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:12 step:56915[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:12 step:56920[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:12 step:56925[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:12 step:56930[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:12 step:56935[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:12 step:56940[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:12 step:56945[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:12 step:56950[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:12 step:56955[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:12 step:56960[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:12 step:56965[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:12 step:56970[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:12 step:56975[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:12 step:56980[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:12 step:56985[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:12 step:56990[D loss: 0.999997] [G loss: 1.000038]\n",
      "epoch:12 step:56995[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:12 step:57000[D loss: 1.000001] [G loss: 1.000061]\n",
      "##############\n",
      "[2.62320132 2.08157651 2.24491949 3.84146024 1.46769951 7.76839271\n",
      " 2.4040286  3.83418579 3.99531352 5.39029664]\n",
      "##########\n",
      "epoch:12 step:57005[D loss: 0.999909] [G loss: 1.000122]\n",
      "epoch:12 step:57010[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:12 step:57015[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:12 step:57020[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:12 step:57025[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:12 step:57030[D loss: 1.000070] [G loss: 0.999888]\n",
      "epoch:12 step:57035[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:12 step:57040[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:12 step:57045[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:12 step:57050[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:12 step:57055[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:12 step:57060[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:12 step:57065[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:12 step:57070[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:12 step:57075[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:12 step:57080[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:12 step:57085[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:12 step:57090[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:12 step:57095[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:12 step:57100[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:12 step:57105[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:12 step:57110[D loss: 0.999977] [G loss: 1.000106]\n",
      "epoch:12 step:57115[D loss: 1.000007] [G loss: 1.000056]\n",
      "epoch:12 step:57120[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:12 step:57125[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:12 step:57130[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:12 step:57135[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:12 step:57140[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:12 step:57145[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:12 step:57150[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:12 step:57155[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:12 step:57160[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:12 step:57165[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:12 step:57170[D loss: 0.999940] [G loss: 1.000074]\n",
      "epoch:12 step:57175[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:12 step:57180[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:12 step:57185[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:12 step:57190[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:12 step:57195[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:12 step:57200[D loss: 0.999956] [G loss: 1.000095]\n",
      "##############\n",
      "[2.61557752 2.05322574 2.30054869 3.99752463 1.54318354 7.68691778\n",
      " 2.47833922 3.93360731 3.97411955 5.03225985]\n",
      "##########\n",
      "epoch:12 step:57205[D loss: 1.000003] [G loss: 1.000039]\n",
      "epoch:12 step:57210[D loss: 1.000026] [G loss: 1.000000]\n",
      "epoch:12 step:57215[D loss: 0.999990] [G loss: 1.000011]\n",
      "epoch:12 step:57220[D loss: 1.000033] [G loss: 1.000022]\n",
      "epoch:12 step:57225[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:12 step:57230[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:12 step:57235[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:12 step:57240[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:12 step:57245[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:12 step:57250[D loss: 0.999945] [G loss: 1.000088]\n",
      "epoch:12 step:57255[D loss: 1.000020] [G loss: 1.000024]\n",
      "epoch:12 step:57260[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:12 step:57265[D loss: 1.000011] [G loss: 1.000025]\n",
      "epoch:12 step:57270[D loss: 0.999958] [G loss: 1.000127]\n",
      "epoch:12 step:57275[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:12 step:57280[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:12 step:57285[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:12 step:57290[D loss: 0.999998] [G loss: 1.000065]\n",
      "epoch:12 step:57295[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:12 step:57300[D loss: 0.999948] [G loss: 1.000129]\n",
      "epoch:12 step:57305[D loss: 1.000016] [G loss: 1.000123]\n",
      "epoch:12 step:57310[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:12 step:57315[D loss: 0.999939] [G loss: 1.000096]\n",
      "epoch:12 step:57320[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:12 step:57325[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:12 step:57330[D loss: 1.000037] [G loss: 0.999924]\n",
      "epoch:12 step:57335[D loss: 1.000013] [G loss: 1.000006]\n",
      "epoch:12 step:57340[D loss: 0.999999] [G loss: 0.999966]\n",
      "epoch:12 step:57345[D loss: 1.000020] [G loss: 0.999968]\n",
      "epoch:12 step:57350[D loss: 0.999998] [G loss: 1.000119]\n",
      "epoch:12 step:57355[D loss: 1.000092] [G loss: 0.999978]\n",
      "epoch:12 step:57360[D loss: 0.999940] [G loss: 1.000086]\n",
      "epoch:12 step:57365[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:12 step:57370[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:12 step:57375[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:12 step:57380[D loss: 0.999955] [G loss: 1.000054]\n",
      "epoch:12 step:57385[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:12 step:57390[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:12 step:57395[D loss: 0.999964] [G loss: 1.000102]\n",
      "epoch:12 step:57400[D loss: 0.999965] [G loss: 1.000076]\n",
      "##############\n",
      "[2.6369993  2.09497271 2.32262194 3.62261668 1.4649049  7.51334937\n",
      " 2.45266635 3.76512986 3.96769993 5.62109151]\n",
      "##########\n",
      "epoch:12 step:57405[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:12 step:57410[D loss: 1.000026] [G loss: 0.999988]\n",
      "epoch:12 step:57415[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:12 step:57420[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:12 step:57425[D loss: 1.000028] [G loss: 1.000045]\n",
      "epoch:12 step:57430[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:12 step:57435[D loss: 0.999958] [G loss: 1.000056]\n",
      "epoch:12 step:57440[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:12 step:57445[D loss: 0.999925] [G loss: 1.000119]\n",
      "epoch:12 step:57450[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:12 step:57455[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:12 step:57460[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:12 step:57465[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:12 step:57470[D loss: 0.999966] [G loss: 1.000084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:57475[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:12 step:57480[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:12 step:57485[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:12 step:57490[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:12 step:57495[D loss: 1.000010] [G loss: 1.000021]\n",
      "epoch:12 step:57500[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:12 step:57505[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:12 step:57510[D loss: 1.000017] [G loss: 1.000027]\n",
      "epoch:12 step:57515[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:12 step:57520[D loss: 0.999989] [G loss: 1.000094]\n",
      "epoch:12 step:57525[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:12 step:57530[D loss: 1.000023] [G loss: 1.000057]\n",
      "epoch:12 step:57535[D loss: 0.999994] [G loss: 1.000107]\n",
      "epoch:12 step:57540[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:12 step:57545[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:12 step:57550[D loss: 1.000015] [G loss: 1.000024]\n",
      "epoch:12 step:57555[D loss: 0.999943] [G loss: 1.000136]\n",
      "epoch:12 step:57560[D loss: 0.999998] [G loss: 1.000016]\n",
      "epoch:12 step:57565[D loss: 0.999998] [G loss: 1.000024]\n",
      "epoch:12 step:57570[D loss: 1.000035] [G loss: 1.000017]\n",
      "epoch:12 step:57575[D loss: 0.999954] [G loss: 1.000075]\n",
      "epoch:12 step:57580[D loss: 0.999941] [G loss: 1.000123]\n",
      "epoch:12 step:57585[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:12 step:57590[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:12 step:57595[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:12 step:57600[D loss: 0.999994] [G loss: 1.000042]\n",
      "##############\n",
      "[2.62058636 2.13747385 2.26749601 3.76876718 1.44836972 7.15411927\n",
      " 2.44297526 4.00316865 4.03807568 4.94152588]\n",
      "##########\n",
      "epoch:12 step:57605[D loss: 0.999988] [G loss: 1.000025]\n",
      "epoch:12 step:57610[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:12 step:57615[D loss: 0.999948] [G loss: 1.000104]\n",
      "epoch:12 step:57620[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:12 step:57625[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:12 step:57630[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:12 step:57635[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:12 step:57640[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:12 step:57645[D loss: 0.999982] [G loss: 1.000103]\n",
      "epoch:12 step:57650[D loss: 0.999958] [G loss: 1.000072]\n",
      "epoch:12 step:57655[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:12 step:57660[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:12 step:57665[D loss: 0.999943] [G loss: 1.000111]\n",
      "epoch:12 step:57670[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:12 step:57675[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:12 step:57680[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:12 step:57685[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:12 step:57690[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:12 step:57695[D loss: 1.000020] [G loss: 1.000022]\n",
      "epoch:12 step:57700[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:12 step:57705[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:12 step:57710[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:12 step:57715[D loss: 0.999945] [G loss: 1.000087]\n",
      "epoch:12 step:57720[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:12 step:57725[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:12 step:57730[D loss: 1.000026] [G loss: 0.999956]\n",
      "epoch:12 step:57735[D loss: 1.000022] [G loss: 1.000028]\n",
      "epoch:12 step:57740[D loss: 0.999946] [G loss: 1.000074]\n",
      "epoch:12 step:57745[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:12 step:57750[D loss: 1.000026] [G loss: 1.000008]\n",
      "epoch:12 step:57755[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:12 step:57760[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:12 step:57765[D loss: 1.000003] [G loss: 1.000029]\n",
      "epoch:12 step:57770[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:12 step:57775[D loss: 1.000012] [G loss: 1.000001]\n",
      "epoch:12 step:57780[D loss: 0.999967] [G loss: 1.000024]\n",
      "epoch:12 step:57785[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:12 step:57790[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:12 step:57795[D loss: 0.999984] [G loss: 1.000094]\n",
      "epoch:12 step:57800[D loss: 1.000005] [G loss: 1.000076]\n",
      "##############\n",
      "[2.623933   2.01648421 2.13974287 3.77139629 1.43874276 7.7891438\n",
      " 2.26355811 3.79652968 3.9935499  5.39515402]\n",
      "##########\n",
      "epoch:12 step:57805[D loss: 0.999948] [G loss: 1.000066]\n",
      "epoch:12 step:57810[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:12 step:57815[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:12 step:57820[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:12 step:57825[D loss: 1.000041] [G loss: 1.000040]\n",
      "epoch:12 step:57830[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:12 step:57835[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:12 step:57840[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:12 step:57845[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:12 step:57850[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:12 step:57855[D loss: 1.000013] [G loss: 1.000002]\n",
      "epoch:12 step:57860[D loss: 0.999955] [G loss: 1.000034]\n",
      "epoch:12 step:57865[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:12 step:57870[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:12 step:57875[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:12 step:57880[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:12 step:57885[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:12 step:57890[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:12 step:57895[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:12 step:57900[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:12 step:57905[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:12 step:57910[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:12 step:57915[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:12 step:57920[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:12 step:57925[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:12 step:57930[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:12 step:57935[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:12 step:57940[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:12 step:57945[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:12 step:57950[D loss: 0.999993] [G loss: 1.000083]\n",
      "epoch:12 step:57955[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:12 step:57960[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:12 step:57965[D loss: 1.000024] [G loss: 1.000055]\n",
      "epoch:12 step:57970[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:12 step:57975[D loss: 0.999952] [G loss: 1.000115]\n",
      "epoch:12 step:57980[D loss: 0.999966] [G loss: 1.000110]\n",
      "epoch:12 step:57985[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:12 step:57990[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:12 step:57995[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:12 step:58000[D loss: 0.999987] [G loss: 1.000062]\n",
      "##############\n",
      "[2.63114373 2.1502775  2.25066272 3.70879351 1.47191735 7.48612614\n",
      " 2.39551698 3.68660684 4.02848954 5.69483695]\n",
      "##########\n",
      "epoch:12 step:58005[D loss: 0.999976] [G loss: 1.000007]\n",
      "epoch:12 step:58010[D loss: 1.000009] [G loss: 1.000095]\n",
      "epoch:12 step:58015[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:12 step:58020[D loss: 0.999997] [G loss: 1.000099]\n",
      "epoch:12 step:58025[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:12 step:58030[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:12 step:58035[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:12 step:58040[D loss: 1.000034] [G loss: 1.000046]\n",
      "epoch:12 step:58045[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:12 step:58050[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:12 step:58055[D loss: 0.999989] [G loss: 1.000085]\n",
      "epoch:12 step:58060[D loss: 0.999942] [G loss: 1.000130]\n",
      "epoch:12 step:58065[D loss: 1.000009] [G loss: 1.000051]\n",
      "epoch:12 step:58070[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:12 step:58075[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:12 step:58080[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:12 step:58085[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:12 step:58090[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:12 step:58095[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:12 step:58100[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:12 step:58105[D loss: 1.000005] [G loss: 1.000017]\n",
      "epoch:12 step:58110[D loss: 1.000098] [G loss: 0.999927]\n",
      "epoch:12 step:58115[D loss: 0.999976] [G loss: 1.000010]\n",
      "epoch:12 step:58120[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:12 step:58125[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:12 step:58130[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:12 step:58135[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:12 step:58140[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:12 step:58145[D loss: 1.000049] [G loss: 0.999991]\n",
      "epoch:12 step:58150[D loss: 0.999946] [G loss: 1.000071]\n",
      "epoch:12 step:58155[D loss: 1.000050] [G loss: 0.999975]\n",
      "epoch:12 step:58160[D loss: 0.999975] [G loss: 1.000103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:58165[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:12 step:58170[D loss: 0.999946] [G loss: 1.000094]\n",
      "epoch:12 step:58175[D loss: 1.000022] [G loss: 0.999996]\n",
      "epoch:12 step:58180[D loss: 0.999922] [G loss: 1.000095]\n",
      "epoch:12 step:58185[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:12 step:58190[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:12 step:58195[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:12 step:58200[D loss: 0.999977] [G loss: 1.000060]\n",
      "##############\n",
      "[2.56538593 2.07312568 2.12116403 3.79626168 1.40321518 7.81857638\n",
      " 2.2350235  3.66176217 3.984986   5.15620579]\n",
      "##########\n",
      "epoch:12 step:58205[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:12 step:58210[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:12 step:58215[D loss: 1.000021] [G loss: 0.999985]\n",
      "epoch:12 step:58220[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:12 step:58225[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:12 step:58230[D loss: 0.999940] [G loss: 1.000114]\n",
      "epoch:12 step:58235[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:12 step:58240[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:12 step:58245[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:12 step:58250[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:12 step:58255[D loss: 1.000028] [G loss: 1.000020]\n",
      "epoch:12 step:58260[D loss: 0.999951] [G loss: 1.000059]\n",
      "epoch:12 step:58265[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:12 step:58270[D loss: 1.000029] [G loss: 1.000061]\n",
      "epoch:12 step:58275[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:12 step:58280[D loss: 1.000015] [G loss: 1.000031]\n",
      "epoch:12 step:58285[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:12 step:58290[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:12 step:58295[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:12 step:58300[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:12 step:58305[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:12 step:58310[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:12 step:58315[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:12 step:58320[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:12 step:58325[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:12 step:58330[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:12 step:58335[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:12 step:58340[D loss: 0.999941] [G loss: 1.000131]\n",
      "epoch:12 step:58345[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:12 step:58350[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:12 step:58355[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:12 step:58360[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:12 step:58365[D loss: 0.999987] [G loss: 1.000011]\n",
      "epoch:12 step:58370[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:12 step:58375[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:12 step:58380[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:12 step:58385[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:12 step:58390[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:12 step:58395[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:12 step:58400[D loss: 0.999968] [G loss: 1.000071]\n",
      "##############\n",
      "[2.69044905 2.12964873 2.20708844 3.8305437  1.48390234 7.41913932\n",
      " 2.35686363 3.83591907 4.0193272  5.91992617]\n",
      "##########\n",
      "epoch:12 step:58405[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:12 step:58410[D loss: 1.000002] [G loss: 0.999968]\n",
      "epoch:12 step:58415[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:12 step:58420[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:12 step:58425[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:12 step:58430[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:12 step:58435[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:12 step:58440[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:12 step:58445[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:12 step:58450[D loss: 1.000023] [G loss: 1.000029]\n",
      "epoch:12 step:58455[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:12 step:58460[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:12 step:58465[D loss: 0.999935] [G loss: 1.000122]\n",
      "epoch:12 step:58470[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:12 step:58475[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:12 step:58480[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:12 step:58485[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:12 step:58490[D loss: 1.000014] [G loss: 1.000017]\n",
      "epoch:12 step:58495[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:12 step:58500[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:12 step:58505[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:12 step:58510[D loss: 1.000008] [G loss: 1.000069]\n",
      "epoch:12 step:58515[D loss: 1.000033] [G loss: 1.000138]\n",
      "epoch:12 step:58520[D loss: 0.999926] [G loss: 1.000139]\n",
      "epoch:12 step:58525[D loss: 0.999933] [G loss: 1.000120]\n",
      "epoch:12 step:58530[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:12 step:58535[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:12 step:58540[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:12 step:58545[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:12 step:58550[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:12 step:58555[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:12 step:58560[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:12 step:58565[D loss: 1.000041] [G loss: 1.000081]\n",
      "epoch:12 step:58570[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:12 step:58575[D loss: 0.999957] [G loss: 1.000116]\n",
      "epoch:12 step:58580[D loss: 0.999968] [G loss: 1.000117]\n",
      "epoch:12 step:58585[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:12 step:58590[D loss: 1.000006] [G loss: 1.000007]\n",
      "epoch:12 step:58595[D loss: 0.999993] [G loss: 0.999986]\n",
      "epoch:12 step:58600[D loss: 0.999999] [G loss: 1.000034]\n",
      "##############\n",
      "[2.5637005  2.10353894 2.19597829 3.82139615 1.34526811 9.27426719\n",
      " 2.11213639 3.55524939 3.93310392 5.40530958]\n",
      "##########\n",
      "epoch:12 step:58605[D loss: 0.999949] [G loss: 1.000059]\n",
      "epoch:12 step:58610[D loss: 1.000026] [G loss: 0.999997]\n",
      "epoch:12 step:58615[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:12 step:58620[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:12 step:58625[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:12 step:58630[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:12 step:58635[D loss: 0.999985] [G loss: 1.000087]\n",
      "epoch:12 step:58640[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:12 step:58645[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:12 step:58650[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:12 step:58655[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:12 step:58660[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:12 step:58665[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:12 step:58670[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:12 step:58675[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:12 step:58680[D loss: 0.999937] [G loss: 1.000161]\n",
      "epoch:12 step:58685[D loss: 0.999984] [G loss: 1.000168]\n",
      "epoch:12 step:58690[D loss: 0.999968] [G loss: 1.000146]\n",
      "epoch:12 step:58695[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:12 step:58700[D loss: 0.999995] [G loss: 1.000126]\n",
      "epoch:12 step:58705[D loss: 0.999991] [G loss: 1.000091]\n",
      "epoch:12 step:58710[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:12 step:58715[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:12 step:58720[D loss: 1.000014] [G loss: 1.000056]\n",
      "epoch:12 step:58725[D loss: 0.999955] [G loss: 1.000048]\n",
      "epoch:12 step:58730[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:12 step:58735[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:12 step:58740[D loss: 0.999941] [G loss: 1.000104]\n",
      "epoch:12 step:58745[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:12 step:58750[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:12 step:58755[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:12 step:58760[D loss: 0.999954] [G loss: 1.000112]\n",
      "epoch:12 step:58765[D loss: 1.000011] [G loss: 0.999948]\n",
      "epoch:12 step:58770[D loss: 1.000068] [G loss: 1.000017]\n",
      "epoch:12 step:58775[D loss: 1.000003] [G loss: 1.000039]\n",
      "epoch:12 step:58780[D loss: 0.999947] [G loss: 1.000071]\n",
      "epoch:12 step:58785[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:12 step:58790[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:12 step:58795[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:12 step:58800[D loss: 0.999959] [G loss: 1.000068]\n",
      "##############\n",
      "[2.58451434 2.15742616 2.12818606 3.81124421 1.44119631 6.64652061\n",
      " 2.47597919 3.98324387 4.01644578 5.17297182]\n",
      "##########\n",
      "epoch:12 step:58805[D loss: 1.000017] [G loss: 1.000046]\n",
      "epoch:12 step:58810[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:12 step:58815[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:12 step:58820[D loss: 0.999944] [G loss: 1.000110]\n",
      "epoch:12 step:58825[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:12 step:58830[D loss: 0.999972] [G loss: 1.000086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:58835[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:12 step:58840[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:12 step:58845[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:12 step:58850[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:12 step:58855[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:12 step:58860[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:12 step:58865[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:12 step:58870[D loss: 0.999987] [G loss: 1.000081]\n",
      "epoch:12 step:58875[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:12 step:58880[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:12 step:58885[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:12 step:58890[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:12 step:58895[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:12 step:58900[D loss: 1.000012] [G loss: 1.000054]\n",
      "epoch:12 step:58905[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:12 step:58910[D loss: 1.000013] [G loss: 1.000058]\n",
      "epoch:12 step:58915[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:12 step:58920[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:12 step:58925[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:12 step:58930[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:12 step:58935[D loss: 1.000090] [G loss: 0.999890]\n",
      "epoch:12 step:58940[D loss: 1.000062] [G loss: 0.999923]\n",
      "epoch:12 step:58945[D loss: 0.999955] [G loss: 1.000138]\n",
      "epoch:12 step:58950[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:12 step:58955[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:12 step:58960[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:12 step:58965[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:12 step:58970[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:12 step:58975[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:12 step:58980[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:12 step:58985[D loss: 1.000033] [G loss: 1.000021]\n",
      "epoch:12 step:58990[D loss: 0.999951] [G loss: 1.000059]\n",
      "epoch:12 step:58995[D loss: 1.000005] [G loss: 1.000010]\n",
      "epoch:12 step:59000[D loss: 0.999971] [G loss: 1.000069]\n",
      "##############\n",
      "[2.48876018 2.10263411 2.14500384 3.64264158 1.37728445 7.21233177\n",
      " 2.39369208 3.74482059 3.97106083 5.12867258]\n",
      "##########\n",
      "epoch:12 step:59005[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:12 step:59010[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:12 step:59015[D loss: 1.000001] [G loss: 1.000066]\n",
      "epoch:12 step:59020[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:12 step:59025[D loss: 0.999943] [G loss: 1.000118]\n",
      "epoch:12 step:59030[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:12 step:59035[D loss: 0.999985] [G loss: 1.000125]\n",
      "epoch:12 step:59040[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:12 step:59045[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:12 step:59050[D loss: 1.000010] [G loss: 1.000008]\n",
      "epoch:12 step:59055[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:12 step:59060[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:12 step:59065[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:12 step:59070[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:12 step:59075[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:12 step:59080[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:12 step:59085[D loss: 0.999982] [G loss: 1.000111]\n",
      "epoch:12 step:59090[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:12 step:59095[D loss: 1.000013] [G loss: 1.000036]\n",
      "epoch:12 step:59100[D loss: 0.999992] [G loss: 1.000088]\n",
      "epoch:12 step:59105[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:12 step:59110[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:12 step:59115[D loss: 1.000026] [G loss: 1.000007]\n",
      "epoch:12 step:59120[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:12 step:59125[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:12 step:59130[D loss: 0.999986] [G loss: 1.000092]\n",
      "epoch:12 step:59135[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:12 step:59140[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:12 step:59145[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:12 step:59150[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:12 step:59155[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:12 step:59160[D loss: 1.000007] [G loss: 1.000030]\n",
      "epoch:12 step:59165[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:12 step:59170[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:12 step:59175[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:12 step:59180[D loss: 1.000041] [G loss: 0.999986]\n",
      "epoch:12 step:59185[D loss: 1.000050] [G loss: 1.000053]\n",
      "epoch:12 step:59190[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:12 step:59195[D loss: 0.999992] [G loss: 1.000145]\n",
      "epoch:12 step:59200[D loss: 0.999923] [G loss: 1.000138]\n",
      "##############\n",
      "[2.58477234 2.12484038 2.13541022 3.86366409 1.48002142 9.27426719\n",
      " 2.17357825 3.59847419 4.01962899 4.87086743]\n",
      "##########\n",
      "epoch:12 step:59205[D loss: 0.999989] [G loss: 1.000096]\n",
      "epoch:12 step:59210[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:12 step:59215[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:12 step:59220[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:12 step:59225[D loss: 1.000004] [G loss: 1.000012]\n",
      "epoch:12 step:59230[D loss: 1.000015] [G loss: 0.999970]\n",
      "epoch:12 step:59235[D loss: 0.999971] [G loss: 1.000027]\n",
      "epoch:12 step:59240[D loss: 0.999920] [G loss: 1.000110]\n",
      "epoch:12 step:59245[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:12 step:59250[D loss: 1.000009] [G loss: 1.000036]\n",
      "epoch:12 step:59255[D loss: 1.000003] [G loss: 1.000039]\n",
      "epoch:12 step:59260[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:12 step:59265[D loss: 1.000058] [G loss: 1.000014]\n",
      "epoch:12 step:59270[D loss: 0.999939] [G loss: 1.000105]\n",
      "epoch:12 step:59275[D loss: 0.999955] [G loss: 1.000127]\n",
      "epoch:12 step:59280[D loss: 0.999989] [G loss: 1.000089]\n",
      "epoch:12 step:59285[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:12 step:59290[D loss: 0.999998] [G loss: 1.000016]\n",
      "epoch:12 step:59295[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:12 step:59300[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:12 step:59305[D loss: 0.999985] [G loss: 1.000098]\n",
      "epoch:12 step:59310[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:12 step:59315[D loss: 0.999921] [G loss: 1.000099]\n",
      "epoch:12 step:59320[D loss: 1.000021] [G loss: 1.000045]\n",
      "epoch:12 step:59325[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:12 step:59330[D loss: 0.999994] [G loss: 1.000102]\n",
      "epoch:12 step:59335[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:12 step:59340[D loss: 0.999994] [G loss: 1.000010]\n",
      "epoch:12 step:59345[D loss: 0.999961] [G loss: 1.000107]\n",
      "epoch:12 step:59350[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:12 step:59355[D loss: 1.000001] [G loss: 1.000034]\n",
      "epoch:12 step:59360[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:12 step:59365[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:12 step:59370[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:12 step:59375[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:12 step:59380[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:12 step:59385[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:12 step:59390[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:12 step:59395[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:12 step:59400[D loss: 0.999972] [G loss: 1.000049]\n",
      "##############\n",
      "[2.50423793 2.10722136 2.12871832 3.78771993 1.46308093 7.35095548\n",
      " 2.28219226 3.72425856 3.94635668 5.85547187]\n",
      "##########\n",
      "epoch:12 step:59405[D loss: 0.999929] [G loss: 1.000153]\n",
      "epoch:12 step:59410[D loss: 0.999979] [G loss: 1.000030]\n",
      "epoch:12 step:59415[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:12 step:59420[D loss: 0.999988] [G loss: 1.000094]\n",
      "epoch:12 step:59425[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:12 step:59430[D loss: 0.999945] [G loss: 1.000085]\n",
      "epoch:12 step:59435[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:12 step:59440[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:12 step:59445[D loss: 1.000003] [G loss: 0.999974]\n",
      "epoch:12 step:59450[D loss: 0.999966] [G loss: 1.000122]\n",
      "epoch:12 step:59455[D loss: 0.999956] [G loss: 1.000070]\n",
      "epoch:12 step:59460[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:12 step:59465[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:12 step:59470[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:12 step:59475[D loss: 1.000000] [G loss: 1.000097]\n",
      "epoch:12 step:59480[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:12 step:59485[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:12 step:59490[D loss: 1.000046] [G loss: 0.999909]\n",
      "epoch:12 step:59495[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:12 step:59500[D loss: 0.999958] [G loss: 1.000118]\n",
      "epoch:12 step:59505[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:12 step:59510[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:12 step:59515[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:12 step:59520[D loss: 0.999955] [G loss: 1.000111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:59525[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:12 step:59530[D loss: 1.000023] [G loss: 1.000030]\n",
      "epoch:12 step:59535[D loss: 0.999939] [G loss: 1.000166]\n",
      "epoch:12 step:59540[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:12 step:59545[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:12 step:59550[D loss: 1.000033] [G loss: 0.999942]\n",
      "epoch:12 step:59555[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:12 step:59560[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:12 step:59565[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:12 step:59570[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:12 step:59575[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:12 step:59580[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:12 step:59585[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:12 step:59590[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:12 step:59595[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:12 step:59600[D loss: 0.999984] [G loss: 1.000058]\n",
      "##############\n",
      "[2.6270263  2.17220006 2.26580986 3.82969302 1.53077427 7.71254218\n",
      " 2.39705857 3.6955271  4.09207915 5.29655816]\n",
      "##########\n",
      "epoch:12 step:59605[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:12 step:59610[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:12 step:59615[D loss: 0.999994] [G loss: 1.000063]\n",
      "epoch:12 step:59620[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:12 step:59625[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:12 step:59630[D loss: 0.999968] [G loss: 1.000112]\n",
      "epoch:12 step:59635[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:12 step:59640[D loss: 0.999986] [G loss: 1.000018]\n",
      "epoch:12 step:59645[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:12 step:59650[D loss: 0.999931] [G loss: 1.000130]\n",
      "epoch:12 step:59655[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:12 step:59660[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:12 step:59665[D loss: 1.000028] [G loss: 1.000002]\n",
      "epoch:12 step:59670[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:12 step:59675[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:12 step:59680[D loss: 0.999977] [G loss: 1.000026]\n",
      "epoch:12 step:59685[D loss: 0.999995] [G loss: 1.000086]\n",
      "epoch:12 step:59690[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:12 step:59695[D loss: 1.000003] [G loss: 0.999999]\n",
      "epoch:12 step:59700[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:12 step:59705[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:12 step:59710[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:12 step:59715[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:12 step:59720[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:12 step:59725[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:12 step:59730[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:12 step:59735[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:12 step:59740[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:12 step:59745[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:12 step:59750[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:12 step:59755[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:12 step:59760[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:12 step:59765[D loss: 1.000038] [G loss: 1.000038]\n",
      "epoch:12 step:59770[D loss: 1.000005] [G loss: 1.000064]\n",
      "epoch:12 step:59775[D loss: 0.999958] [G loss: 1.000142]\n",
      "epoch:12 step:59780[D loss: 0.999950] [G loss: 1.000114]\n",
      "epoch:12 step:59785[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:12 step:59790[D loss: 1.000034] [G loss: 1.000032]\n",
      "epoch:12 step:59795[D loss: 0.999957] [G loss: 1.000056]\n",
      "epoch:12 step:59800[D loss: 0.999980] [G loss: 1.000050]\n",
      "##############\n",
      "[2.61729159 2.16518147 2.1714555  3.94254072 1.42586732 7.6119014\n",
      " 2.44694263 3.8253509  3.98911644 5.37885332]\n",
      "##########\n",
      "epoch:12 step:59805[D loss: 1.000002] [G loss: 0.999995]\n",
      "epoch:12 step:59810[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:12 step:59815[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:12 step:59820[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:12 step:59825[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:12 step:59830[D loss: 0.999966] [G loss: 1.000127]\n",
      "epoch:12 step:59835[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:12 step:59840[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:12 step:59845[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:12 step:59850[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:12 step:59855[D loss: 1.000007] [G loss: 1.000025]\n",
      "epoch:12 step:59860[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:12 step:59865[D loss: 0.999943] [G loss: 1.000135]\n",
      "epoch:12 step:59870[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:12 step:59875[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:12 step:59880[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:12 step:59885[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:12 step:59890[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:12 step:59895[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:12 step:59900[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:12 step:59905[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:12 step:59910[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:12 step:59915[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:12 step:59920[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:12 step:59925[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:12 step:59930[D loss: 1.000038] [G loss: 1.000037]\n",
      "epoch:12 step:59935[D loss: 0.999953] [G loss: 1.000063]\n",
      "epoch:12 step:59940[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:12 step:59945[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:12 step:59950[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:12 step:59955[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:12 step:59960[D loss: 0.999946] [G loss: 1.000109]\n",
      "epoch:12 step:59965[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:12 step:59970[D loss: 1.000008] [G loss: 1.000011]\n",
      "epoch:12 step:59975[D loss: 1.000004] [G loss: 1.000006]\n",
      "epoch:12 step:59980[D loss: 0.999935] [G loss: 1.000091]\n",
      "epoch:12 step:59985[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:12 step:59990[D loss: 0.999981] [G loss: 1.000126]\n",
      "epoch:12 step:59995[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:12 step:60000[D loss: 0.999980] [G loss: 1.000046]\n",
      "##############\n",
      "[2.5971491  2.18655005 2.18472546 3.97292895 1.39454172 7.24335002\n",
      " 2.37122058 3.73258132 4.04062717 5.05759706]\n",
      "##########\n",
      "epoch:12 step:60005[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:12 step:60010[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:12 step:60015[D loss: 0.999991] [G loss: 1.000017]\n",
      "epoch:12 step:60020[D loss: 1.000010] [G loss: 1.000046]\n",
      "epoch:12 step:60025[D loss: 0.999969] [G loss: 1.000107]\n",
      "epoch:12 step:60030[D loss: 1.000035] [G loss: 1.000057]\n",
      "epoch:12 step:60035[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:12 step:60040[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:12 step:60045[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:12 step:60050[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:12 step:60055[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:12 step:60060[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:12 step:60065[D loss: 0.999973] [G loss: 1.000028]\n",
      "epoch:12 step:60070[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:12 step:60075[D loss: 0.999996] [G loss: 1.000085]\n",
      "epoch:12 step:60080[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:12 step:60085[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:12 step:60090[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:12 step:60095[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:12 step:60100[D loss: 0.999959] [G loss: 1.000062]\n",
      "epoch:12 step:60105[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:12 step:60110[D loss: 0.999997] [G loss: 1.000031]\n",
      "epoch:12 step:60115[D loss: 1.000059] [G loss: 0.999957]\n",
      "epoch:12 step:60120[D loss: 0.999943] [G loss: 1.000164]\n",
      "epoch:12 step:60125[D loss: 0.999959] [G loss: 1.000046]\n",
      "epoch:12 step:60130[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:12 step:60135[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:12 step:60140[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:12 step:60145[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:12 step:60150[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:12 step:60155[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:12 step:60160[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:12 step:60165[D loss: 0.999976] [G loss: 1.000123]\n",
      "epoch:12 step:60170[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:12 step:60175[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:12 step:60180[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:12 step:60185[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:12 step:60190[D loss: 1.000002] [G loss: 1.000024]\n",
      "epoch:12 step:60195[D loss: 0.999975] [G loss: 1.000112]\n",
      "epoch:12 step:60200[D loss: 0.999953] [G loss: 1.000120]\n",
      "##############\n",
      "[2.63165465 2.06302069 2.36052148 3.92996352 1.42701171 7.33414408\n",
      " 2.3765697  3.8592585  4.10149504 7.14868929]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:60205[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:12 step:60210[D loss: 1.000027] [G loss: 1.000012]\n",
      "epoch:12 step:60215[D loss: 0.999965] [G loss: 1.000103]\n",
      "epoch:12 step:60220[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:12 step:60225[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:12 step:60230[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:12 step:60235[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:12 step:60240[D loss: 1.000004] [G loss: 1.000024]\n",
      "epoch:12 step:60245[D loss: 0.999965] [G loss: 1.000141]\n",
      "epoch:12 step:60250[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:12 step:60255[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:12 step:60260[D loss: 1.000037] [G loss: 1.000013]\n",
      "epoch:12 step:60265[D loss: 0.999975] [G loss: 1.000030]\n",
      "epoch:12 step:60270[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:12 step:60275[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:12 step:60280[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:12 step:60285[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:12 step:60290[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:12 step:60295[D loss: 0.999944] [G loss: 1.000057]\n",
      "epoch:12 step:60300[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:12 step:60305[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:12 step:60310[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:12 step:60315[D loss: 0.999953] [G loss: 1.000094]\n",
      "epoch:12 step:60320[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:12 step:60325[D loss: 1.000028] [G loss: 0.999984]\n",
      "epoch:12 step:60330[D loss: 1.000024] [G loss: 0.999970]\n",
      "epoch:12 step:60335[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:12 step:60340[D loss: 0.999948] [G loss: 1.000078]\n",
      "epoch:12 step:60345[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:12 step:60350[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:12 step:60355[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:12 step:60360[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:12 step:60365[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:12 step:60370[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:12 step:60375[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:12 step:60380[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:12 step:60385[D loss: 0.999943] [G loss: 1.000094]\n",
      "epoch:12 step:60390[D loss: 1.000023] [G loss: 1.000034]\n",
      "epoch:12 step:60395[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:12 step:60400[D loss: 0.999977] [G loss: 1.000076]\n",
      "##############\n",
      "[2.5189596  2.12674995 2.19579436 3.94975704 1.36806709 7.22430419\n",
      " 1.97421884 3.72165459 3.87937749 5.28009904]\n",
      "##########\n",
      "epoch:12 step:60405[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:12 step:60410[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:12 step:60415[D loss: 1.000021] [G loss: 1.000036]\n",
      "epoch:12 step:60420[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:12 step:60425[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:12 step:60430[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:12 step:60435[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:12 step:60440[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:12 step:60445[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:12 step:60450[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:12 step:60455[D loss: 0.999983] [G loss: 1.000096]\n",
      "epoch:12 step:60460[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:12 step:60465[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:12 step:60470[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:12 step:60475[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:12 step:60480[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:12 step:60485[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:12 step:60490[D loss: 0.999984] [G loss: 1.000017]\n",
      "epoch:12 step:60495[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:12 step:60500[D loss: 1.000016] [G loss: 1.000038]\n",
      "epoch:12 step:60505[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:12 step:60510[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:12 step:60515[D loss: 0.999983] [G loss: 1.000102]\n",
      "epoch:12 step:60520[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:12 step:60525[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:12 step:60530[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:12 step:60535[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:12 step:60540[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:12 step:60545[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:12 step:60550[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:12 step:60555[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:12 step:60560[D loss: 0.999933] [G loss: 1.000136]\n",
      "epoch:12 step:60565[D loss: 1.000029] [G loss: 0.999977]\n",
      "epoch:12 step:60570[D loss: 1.000029] [G loss: 1.000045]\n",
      "epoch:12 step:60575[D loss: 0.999956] [G loss: 1.000066]\n",
      "epoch:12 step:60580[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:12 step:60585[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:12 step:60590[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:12 step:60595[D loss: 0.999982] [G loss: 1.000095]\n",
      "epoch:12 step:60600[D loss: 0.999997] [G loss: 0.999979]\n",
      "##############\n",
      "[2.54362066 2.07749705 2.12144312 3.81299859 1.41002044 7.47547006\n",
      " 2.22730869 3.71966175 3.92184959 5.7810561 ]\n",
      "##########\n",
      "epoch:12 step:60605[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:12 step:60610[D loss: 0.999967] [G loss: 1.000035]\n",
      "epoch:12 step:60615[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:12 step:60620[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:12 step:60625[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:12 step:60630[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:12 step:60635[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:12 step:60640[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:12 step:60645[D loss: 1.000025] [G loss: 0.999976]\n",
      "epoch:12 step:60650[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:12 step:60655[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:12 step:60660[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:12 step:60665[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:12 step:60670[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:12 step:60675[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:12 step:60680[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:12 step:60685[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:12 step:60690[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:12 step:60695[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:12 step:60700[D loss: 1.000026] [G loss: 1.000008]\n",
      "epoch:12 step:60705[D loss: 0.999941] [G loss: 1.000106]\n",
      "epoch:12 step:60710[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:12 step:60715[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:12 step:60720[D loss: 0.999943] [G loss: 1.000096]\n",
      "epoch:12 step:60725[D loss: 1.000003] [G loss: 1.000063]\n",
      "epoch:12 step:60730[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:12 step:60735[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:12 step:60740[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:12 step:60745[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:12 step:60750[D loss: 1.000032] [G loss: 0.999979]\n",
      "epoch:12 step:60755[D loss: 0.999948] [G loss: 1.000053]\n",
      "epoch:12 step:60760[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:12 step:60765[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:12 step:60770[D loss: 0.999954] [G loss: 1.000061]\n",
      "epoch:12 step:60775[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:12 step:60780[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:12 step:60785[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:12 step:60790[D loss: 0.999971] [G loss: 1.000101]\n",
      "epoch:12 step:60795[D loss: 0.999996] [G loss: 1.000041]\n",
      "epoch:12 step:60800[D loss: 0.999957] [G loss: 1.000059]\n",
      "##############\n",
      "[2.57282564 2.10861764 2.21189532 3.5798596  1.48124113 7.46052694\n",
      " 2.36866468 3.83161218 4.02626784 6.76998698]\n",
      "##########\n",
      "epoch:12 step:60805[D loss: 1.000034] [G loss: 1.000013]\n",
      "epoch:12 step:60810[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:12 step:60815[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:12 step:60820[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:12 step:60825[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:12 step:60830[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:12 step:60835[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:12 step:60840[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:12 step:60845[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:12 step:60850[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:12 step:60855[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:12 step:60860[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:12 step:60865[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:12 step:60870[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:12 step:60875[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:12 step:60880[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:12 step:60885[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:12 step:60890[D loss: 0.999988] [G loss: 1.000030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:60895[D loss: 1.000026] [G loss: 1.000013]\n",
      "epoch:12 step:60900[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:12 step:60905[D loss: 0.999987] [G loss: 1.000001]\n",
      "epoch:13 step:60910[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:13 step:60915[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:13 step:60920[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:13 step:60925[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:13 step:60930[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:13 step:60935[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:13 step:60940[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:13 step:60945[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:13 step:60950[D loss: 1.000017] [G loss: 1.000018]\n",
      "epoch:13 step:60955[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:13 step:60960[D loss: 0.999953] [G loss: 1.000124]\n",
      "epoch:13 step:60965[D loss: 0.999980] [G loss: 1.000017]\n",
      "epoch:13 step:60970[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:13 step:60975[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:13 step:60980[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:13 step:60985[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:13 step:60990[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:13 step:60995[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:13 step:61000[D loss: 0.999972] [G loss: 1.000088]\n",
      "##############\n",
      "[2.48082613 2.07195477 2.27009477 3.82059329 1.46873013 7.15746665\n",
      " 2.23672986 3.74655011 3.96847218 6.40310772]\n",
      "##########\n",
      "epoch:13 step:61005[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:13 step:61010[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:13 step:61015[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:13 step:61020[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:13 step:61025[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:13 step:61030[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:13 step:61035[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:13 step:61040[D loss: 0.999986] [G loss: 1.000104]\n",
      "epoch:13 step:61045[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:13 step:61050[D loss: 0.999951] [G loss: 1.000092]\n",
      "epoch:13 step:61055[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:13 step:61060[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:13 step:61065[D loss: 0.999945] [G loss: 1.000128]\n",
      "epoch:13 step:61070[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:13 step:61075[D loss: 0.999968] [G loss: 1.000130]\n",
      "epoch:13 step:61080[D loss: 0.999967] [G loss: 1.000097]\n",
      "epoch:13 step:61085[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:13 step:61090[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:13 step:61095[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:13 step:61100[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:13 step:61105[D loss: 0.999997] [G loss: 1.000066]\n",
      "epoch:13 step:61110[D loss: 1.000002] [G loss: 1.000038]\n",
      "epoch:13 step:61115[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:13 step:61120[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:13 step:61125[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:13 step:61130[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:13 step:61135[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:13 step:61140[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:13 step:61145[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:13 step:61150[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:13 step:61155[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:13 step:61160[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:13 step:61165[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:13 step:61170[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:13 step:61175[D loss: 1.000000] [G loss: 1.000040]\n",
      "epoch:13 step:61180[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:13 step:61185[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:13 step:61190[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:13 step:61195[D loss: 1.000019] [G loss: 1.000058]\n",
      "epoch:13 step:61200[D loss: 0.999904] [G loss: 1.000150]\n",
      "##############\n",
      "[2.61732643 2.11665653 2.16129975 3.50021175 1.50759459 8.51294541\n",
      " 2.23211621 3.64929416 4.07240934 5.76239153]\n",
      "##########\n",
      "epoch:13 step:61205[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:13 step:61210[D loss: 0.999939] [G loss: 1.000112]\n",
      "epoch:13 step:61215[D loss: 1.000055] [G loss: 0.999991]\n",
      "epoch:13 step:61220[D loss: 1.000042] [G loss: 1.000004]\n",
      "epoch:13 step:61225[D loss: 1.000001] [G loss: 1.000082]\n",
      "epoch:13 step:61230[D loss: 0.999981] [G loss: 0.999989]\n",
      "epoch:13 step:61235[D loss: 0.999971] [G loss: 1.000030]\n",
      "epoch:13 step:61240[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:13 step:61245[D loss: 1.000007] [G loss: 0.999981]\n",
      "epoch:13 step:61250[D loss: 1.000036] [G loss: 1.000023]\n",
      "epoch:13 step:61255[D loss: 1.000040] [G loss: 0.999929]\n",
      "epoch:13 step:61260[D loss: 1.000028] [G loss: 0.999994]\n",
      "epoch:13 step:61265[D loss: 0.999940] [G loss: 1.000255]\n",
      "epoch:13 step:61270[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:13 step:61275[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:13 step:61280[D loss: 1.000002] [G loss: 0.999974]\n",
      "epoch:13 step:61285[D loss: 0.999948] [G loss: 1.000073]\n",
      "epoch:13 step:61290[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:13 step:61295[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:13 step:61300[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:13 step:61305[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:13 step:61310[D loss: 0.999948] [G loss: 1.000127]\n",
      "epoch:13 step:61315[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:13 step:61320[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:13 step:61325[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:13 step:61330[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:13 step:61335[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:13 step:61340[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:13 step:61345[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:13 step:61350[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:13 step:61355[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:13 step:61360[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:13 step:61365[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:13 step:61370[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:13 step:61375[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:13 step:61380[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:13 step:61385[D loss: 0.999978] [G loss: 1.000107]\n",
      "epoch:13 step:61390[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:13 step:61395[D loss: 0.999989] [G loss: 1.000118]\n",
      "epoch:13 step:61400[D loss: 0.999985] [G loss: 1.000054]\n",
      "##############\n",
      "[2.55281461 2.03012271 2.0906465  3.69155705 1.48971181 7.45160182\n",
      " 2.24820144 3.80024077 3.9400929  5.85755647]\n",
      "##########\n",
      "epoch:13 step:61405[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:13 step:61410[D loss: 0.999994] [G loss: 1.000017]\n",
      "epoch:13 step:61415[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:13 step:61420[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:13 step:61425[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:13 step:61430[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:13 step:61435[D loss: 0.999964] [G loss: 1.000044]\n",
      "epoch:13 step:61440[D loss: 1.000016] [G loss: 1.000036]\n",
      "epoch:13 step:61445[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:13 step:61450[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:13 step:61455[D loss: 0.999955] [G loss: 1.000103]\n",
      "epoch:13 step:61460[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:13 step:61465[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:13 step:61470[D loss: 0.999988] [G loss: 1.000108]\n",
      "epoch:13 step:61475[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:13 step:61480[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:13 step:61485[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:13 step:61490[D loss: 1.000004] [G loss: 1.000046]\n",
      "epoch:13 step:61495[D loss: 1.000021] [G loss: 1.000022]\n",
      "epoch:13 step:61500[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:13 step:61505[D loss: 0.999919] [G loss: 1.000124]\n",
      "epoch:13 step:61510[D loss: 0.999944] [G loss: 1.000100]\n",
      "epoch:13 step:61515[D loss: 0.999996] [G loss: 1.000080]\n",
      "epoch:13 step:61520[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:13 step:61525[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:13 step:61530[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:13 step:61535[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:13 step:61540[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:13 step:61545[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:13 step:61550[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:13 step:61555[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:13 step:61560[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:13 step:61565[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:13 step:61570[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:13 step:61575[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:13 step:61580[D loss: 0.999978] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:61585[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:13 step:61590[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:13 step:61595[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:13 step:61600[D loss: 0.999975] [G loss: 1.000051]\n",
      "##############\n",
      "[2.63057876 2.13664956 2.10420859 3.69890293 1.48521483 6.36422202\n",
      " 2.33145697 3.86504009 3.95078381 5.54470594]\n",
      "##########\n",
      "epoch:13 step:61605[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:13 step:61610[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:13 step:61615[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:13 step:61620[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:13 step:61625[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:13 step:61630[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:13 step:61635[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:13 step:61640[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:13 step:61645[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:13 step:61650[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:13 step:61655[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:13 step:61660[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:13 step:61665[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:13 step:61670[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:13 step:61675[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:13 step:61680[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:13 step:61685[D loss: 0.999994] [G loss: 1.000012]\n",
      "epoch:13 step:61690[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:13 step:61695[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:13 step:61700[D loss: 0.999998] [G loss: 0.999993]\n",
      "epoch:13 step:61705[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:13 step:61710[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:13 step:61715[D loss: 0.999965] [G loss: 1.000115]\n",
      "epoch:13 step:61720[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:13 step:61725[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:13 step:61730[D loss: 1.000020] [G loss: 1.000020]\n",
      "epoch:13 step:61735[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:13 step:61740[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:13 step:61745[D loss: 1.000006] [G loss: 1.000001]\n",
      "epoch:13 step:61750[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:13 step:61755[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:13 step:61760[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:13 step:61765[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:13 step:61770[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:13 step:61775[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:13 step:61780[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:13 step:61785[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:13 step:61790[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:13 step:61795[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:13 step:61800[D loss: 0.999963] [G loss: 1.000127]\n",
      "##############\n",
      "[2.60821911 2.11829556 2.1894784  4.02656615 1.53167562 7.12202309\n",
      " 2.28253415 3.87795794 4.00379525 5.32290401]\n",
      "##########\n",
      "epoch:13 step:61805[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:13 step:61810[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:13 step:61815[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:13 step:61820[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:13 step:61825[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:13 step:61830[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:13 step:61835[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:13 step:61840[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:13 step:61845[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:13 step:61850[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:13 step:61855[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:13 step:61860[D loss: 1.000025] [G loss: 1.000012]\n",
      "epoch:13 step:61865[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:13 step:61870[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:13 step:61875[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:13 step:61880[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:13 step:61885[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:13 step:61890[D loss: 1.000043] [G loss: 0.999972]\n",
      "epoch:13 step:61895[D loss: 1.000005] [G loss: 1.000072]\n",
      "epoch:13 step:61900[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:13 step:61905[D loss: 0.999986] [G loss: 1.000140]\n",
      "epoch:13 step:61910[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:13 step:61915[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:13 step:61920[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:13 step:61925[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:13 step:61930[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:13 step:61935[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:13 step:61940[D loss: 1.000040] [G loss: 1.000010]\n",
      "epoch:13 step:61945[D loss: 0.999957] [G loss: 1.000040]\n",
      "epoch:13 step:61950[D loss: 1.000011] [G loss: 1.000080]\n",
      "epoch:13 step:61955[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:13 step:61960[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:13 step:61965[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:13 step:61970[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:13 step:61975[D loss: 1.000019] [G loss: 1.000033]\n",
      "epoch:13 step:61980[D loss: 0.999987] [G loss: 1.000091]\n",
      "epoch:13 step:61985[D loss: 0.999924] [G loss: 1.000174]\n",
      "epoch:13 step:61990[D loss: 0.999999] [G loss: 1.000220]\n",
      "epoch:13 step:61995[D loss: 0.999931] [G loss: 1.000131]\n",
      "epoch:13 step:62000[D loss: 0.999959] [G loss: 1.000096]\n",
      "##############\n",
      "[2.53346172 2.12140262 2.25712006 3.81815972 1.44762121 7.51220047\n",
      " 2.26229185 3.72663205 4.0153075  7.14868929]\n",
      "##########\n",
      "epoch:13 step:62005[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:13 step:62010[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:13 step:62015[D loss: 1.000001] [G loss: 1.000015]\n",
      "epoch:13 step:62020[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:13 step:62025[D loss: 0.999945] [G loss: 1.000104]\n",
      "epoch:13 step:62030[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:13 step:62035[D loss: 0.999997] [G loss: 1.000009]\n",
      "epoch:13 step:62040[D loss: 1.000010] [G loss: 1.000069]\n",
      "epoch:13 step:62045[D loss: 0.999952] [G loss: 1.000112]\n",
      "epoch:13 step:62050[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:13 step:62055[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:13 step:62060[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:13 step:62065[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:13 step:62070[D loss: 1.000015] [G loss: 1.000046]\n",
      "epoch:13 step:62075[D loss: 1.000001] [G loss: 1.000036]\n",
      "epoch:13 step:62080[D loss: 0.999965] [G loss: 1.000134]\n",
      "epoch:13 step:62085[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:13 step:62090[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:13 step:62095[D loss: 1.000008] [G loss: 0.999980]\n",
      "epoch:13 step:62100[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:13 step:62105[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:13 step:62110[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:13 step:62115[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:13 step:62120[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:13 step:62125[D loss: 1.000034] [G loss: 1.000008]\n",
      "epoch:13 step:62130[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:13 step:62135[D loss: 0.999947] [G loss: 1.000113]\n",
      "epoch:13 step:62140[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:13 step:62145[D loss: 0.999989] [G loss: 1.000095]\n",
      "epoch:13 step:62150[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:13 step:62155[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:13 step:62160[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:13 step:62165[D loss: 0.999987] [G loss: 1.000018]\n",
      "epoch:13 step:62170[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:13 step:62175[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:13 step:62180[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:13 step:62185[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:13 step:62190[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:13 step:62195[D loss: 1.000035] [G loss: 1.000018]\n",
      "epoch:13 step:62200[D loss: 0.999947] [G loss: 1.000111]\n",
      "##############\n",
      "[2.63387835 2.19491351 2.28457127 3.77731795 1.55551681 7.5705384\n",
      " 2.32772058 3.83015893 4.07043954 5.22346248]\n",
      "##########\n",
      "epoch:13 step:62205[D loss: 0.999962] [G loss: 1.000138]\n",
      "epoch:13 step:62210[D loss: 0.999989] [G loss: 1.000022]\n",
      "epoch:13 step:62215[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:13 step:62220[D loss: 1.000018] [G loss: 0.999993]\n",
      "epoch:13 step:62225[D loss: 0.999984] [G loss: 1.000020]\n",
      "epoch:13 step:62230[D loss: 0.999970] [G loss: 1.000028]\n",
      "epoch:13 step:62235[D loss: 1.000040] [G loss: 1.000002]\n",
      "epoch:13 step:62240[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:13 step:62245[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:13 step:62250[D loss: 0.999975] [G loss: 1.000038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:62255[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:13 step:62260[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:13 step:62265[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:13 step:62270[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:13 step:62275[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:13 step:62280[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:13 step:62285[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:13 step:62290[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:13 step:62295[D loss: 0.999994] [G loss: 1.000056]\n",
      "epoch:13 step:62300[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:13 step:62305[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:13 step:62310[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:13 step:62315[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:13 step:62320[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:13 step:62325[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:13 step:62330[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:13 step:62335[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:13 step:62340[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:13 step:62345[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:13 step:62350[D loss: 1.000004] [G loss: 1.000042]\n",
      "epoch:13 step:62355[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:13 step:62360[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:13 step:62365[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:13 step:62370[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:13 step:62375[D loss: 0.999967] [G loss: 1.000040]\n",
      "epoch:13 step:62380[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:13 step:62385[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:13 step:62390[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:13 step:62395[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:13 step:62400[D loss: 0.999955] [G loss: 1.000066]\n",
      "##############\n",
      "[2.59537872 2.15764347 2.15675305 3.75974682 1.48879808 7.62844228\n",
      " 2.10516007 3.97173806 4.0176967  7.14799875]\n",
      "##########\n",
      "epoch:13 step:62405[D loss: 1.000008] [G loss: 1.000006]\n",
      "epoch:13 step:62410[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:13 step:62415[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:13 step:62420[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:13 step:62425[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:13 step:62430[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:13 step:62435[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:13 step:62440[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:13 step:62445[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:13 step:62450[D loss: 1.000028] [G loss: 1.000031]\n",
      "epoch:13 step:62455[D loss: 1.000015] [G loss: 0.999997]\n",
      "epoch:13 step:62460[D loss: 1.000019] [G loss: 1.000003]\n",
      "epoch:13 step:62465[D loss: 0.999926] [G loss: 1.000095]\n",
      "epoch:13 step:62470[D loss: 0.999925] [G loss: 1.000127]\n",
      "epoch:13 step:62475[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:13 step:62480[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:13 step:62485[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:13 step:62490[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:13 step:62495[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:13 step:62500[D loss: 0.999983] [G loss: 1.000014]\n",
      "epoch:13 step:62505[D loss: 0.999971] [G loss: 1.000030]\n",
      "epoch:13 step:62510[D loss: 1.000015] [G loss: 1.000056]\n",
      "epoch:13 step:62515[D loss: 1.000009] [G loss: 1.000047]\n",
      "epoch:13 step:62520[D loss: 0.999940] [G loss: 1.000105]\n",
      "epoch:13 step:62525[D loss: 0.999905] [G loss: 1.000118]\n",
      "epoch:13 step:62530[D loss: 0.999938] [G loss: 1.000097]\n",
      "epoch:13 step:62535[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:13 step:62540[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:13 step:62545[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:13 step:62550[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:13 step:62555[D loss: 0.999980] [G loss: 1.000119]\n",
      "epoch:13 step:62560[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:13 step:62565[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:13 step:62570[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:13 step:62575[D loss: 0.999974] [G loss: 1.000099]\n",
      "epoch:13 step:62580[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:13 step:62585[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:13 step:62590[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:13 step:62595[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:13 step:62600[D loss: 0.999973] [G loss: 1.000064]\n",
      "##############\n",
      "[2.54967073 2.16274887 2.27251758 3.86694562 1.45770068 7.53168794\n",
      " 2.39224658 3.82640263 3.8929272  5.18330016]\n",
      "##########\n",
      "epoch:13 step:62605[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:13 step:62610[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:13 step:62615[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:13 step:62620[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:13 step:62625[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:13 step:62630[D loss: 0.999953] [G loss: 1.000044]\n",
      "epoch:13 step:62635[D loss: 1.000022] [G loss: 1.000089]\n",
      "epoch:13 step:62640[D loss: 0.999916] [G loss: 1.000103]\n",
      "epoch:13 step:62645[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:13 step:62650[D loss: 0.999995] [G loss: 1.000065]\n",
      "epoch:13 step:62655[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:13 step:62660[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:13 step:62665[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:13 step:62670[D loss: 0.999954] [G loss: 1.000074]\n",
      "epoch:13 step:62675[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:13 step:62680[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:13 step:62685[D loss: 0.999986] [G loss: 1.000006]\n",
      "epoch:13 step:62690[D loss: 1.000003] [G loss: 0.999998]\n",
      "epoch:13 step:62695[D loss: 0.999986] [G loss: 1.000153]\n",
      "epoch:13 step:62700[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:13 step:62705[D loss: 1.000025] [G loss: 1.000042]\n",
      "epoch:13 step:62710[D loss: 0.999927] [G loss: 1.000129]\n",
      "epoch:13 step:62715[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:13 step:62720[D loss: 1.000047] [G loss: 0.999972]\n",
      "epoch:13 step:62725[D loss: 1.000044] [G loss: 1.000054]\n",
      "epoch:13 step:62730[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:13 step:62735[D loss: 1.000035] [G loss: 0.999969]\n",
      "epoch:13 step:62740[D loss: 1.000049] [G loss: 1.000004]\n",
      "epoch:13 step:62745[D loss: 0.999928] [G loss: 1.000177]\n",
      "epoch:13 step:62750[D loss: 0.999886] [G loss: 1.000178]\n",
      "epoch:13 step:62755[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:13 step:62760[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:13 step:62765[D loss: 0.999946] [G loss: 1.000087]\n",
      "epoch:13 step:62770[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:13 step:62775[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:13 step:62780[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:13 step:62785[D loss: 1.000011] [G loss: 1.000023]\n",
      "epoch:13 step:62790[D loss: 1.000024] [G loss: 1.000022]\n",
      "epoch:13 step:62795[D loss: 1.000108] [G loss: 0.999986]\n",
      "epoch:13 step:62800[D loss: 0.999951] [G loss: 1.000048]\n",
      "##############\n",
      "[2.60335489 2.1906602  2.25640498 4.04496339 1.51650654 7.9180051\n",
      " 2.2587697  3.91436722 3.99035676 5.00169732]\n",
      "##########\n",
      "epoch:13 step:62805[D loss: 0.999916] [G loss: 1.000074]\n",
      "epoch:13 step:62810[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:13 step:62815[D loss: 0.999982] [G loss: 1.000000]\n",
      "epoch:13 step:62820[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:13 step:62825[D loss: 0.999995] [G loss: 1.000018]\n",
      "epoch:13 step:62830[D loss: 1.000047] [G loss: 0.999970]\n",
      "epoch:13 step:62835[D loss: 0.999947] [G loss: 1.000085]\n",
      "epoch:13 step:62840[D loss: 1.000022] [G loss: 0.999999]\n",
      "epoch:13 step:62845[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:13 step:62850[D loss: 0.999996] [G loss: 1.000051]\n",
      "epoch:13 step:62855[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:13 step:62860[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:13 step:62865[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:13 step:62870[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:13 step:62875[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:13 step:62880[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:13 step:62885[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:13 step:62890[D loss: 1.000024] [G loss: 1.000007]\n",
      "epoch:13 step:62895[D loss: 0.999980] [G loss: 1.000023]\n",
      "epoch:13 step:62900[D loss: 0.999961] [G loss: 1.000138]\n",
      "epoch:13 step:62905[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:13 step:62910[D loss: 1.000025] [G loss: 1.000029]\n",
      "epoch:13 step:62915[D loss: 0.999995] [G loss: 1.000064]\n",
      "epoch:13 step:62920[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:13 step:62925[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:13 step:62930[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:13 step:62935[D loss: 1.000007] [G loss: 1.000019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:62940[D loss: 1.000027] [G loss: 1.000024]\n",
      "epoch:13 step:62945[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:13 step:62950[D loss: 0.999941] [G loss: 1.000138]\n",
      "epoch:13 step:62955[D loss: 1.000003] [G loss: 1.000111]\n",
      "epoch:13 step:62960[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:13 step:62965[D loss: 1.000047] [G loss: 1.000028]\n",
      "epoch:13 step:62970[D loss: 1.000020] [G loss: 0.999986]\n",
      "epoch:13 step:62975[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:13 step:62980[D loss: 0.999956] [G loss: 1.000069]\n",
      "epoch:13 step:62985[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:13 step:62990[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:13 step:62995[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:13 step:63000[D loss: 0.999961] [G loss: 1.000066]\n",
      "##############\n",
      "[2.65125038 2.10290366 2.2732124  3.6733138  1.44966913 7.11331504\n",
      " 2.30320327 3.93634943 3.96654525 5.40849108]\n",
      "##########\n",
      "epoch:13 step:63005[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:13 step:63010[D loss: 1.000024] [G loss: 1.000027]\n",
      "epoch:13 step:63015[D loss: 1.000024] [G loss: 0.999983]\n",
      "epoch:13 step:63020[D loss: 0.999932] [G loss: 1.000126]\n",
      "epoch:13 step:63025[D loss: 0.999995] [G loss: 1.000073]\n",
      "epoch:13 step:63030[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:13 step:63035[D loss: 0.999972] [G loss: 1.000031]\n",
      "epoch:13 step:63040[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:13 step:63045[D loss: 1.000016] [G loss: 0.999967]\n",
      "epoch:13 step:63050[D loss: 1.000012] [G loss: 0.999996]\n",
      "epoch:13 step:63055[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:13 step:63060[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:13 step:63065[D loss: 1.000019] [G loss: 0.999990]\n",
      "epoch:13 step:63070[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:13 step:63075[D loss: 1.000007] [G loss: 1.000079]\n",
      "epoch:13 step:63080[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:13 step:63085[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:13 step:63090[D loss: 0.999993] [G loss: 1.000026]\n",
      "epoch:13 step:63095[D loss: 1.000052] [G loss: 1.000040]\n",
      "epoch:13 step:63100[D loss: 0.999989] [G loss: 0.999995]\n",
      "epoch:13 step:63105[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:13 step:63110[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:13 step:63115[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:13 step:63120[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:13 step:63125[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:13 step:63130[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:13 step:63135[D loss: 0.999979] [G loss: 1.000100]\n",
      "epoch:13 step:63140[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:13 step:63145[D loss: 0.999944] [G loss: 1.000166]\n",
      "epoch:13 step:63150[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:13 step:63155[D loss: 0.999992] [G loss: 1.000084]\n",
      "epoch:13 step:63160[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:13 step:63165[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:13 step:63170[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:13 step:63175[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:13 step:63180[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:13 step:63185[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:13 step:63190[D loss: 0.999956] [G loss: 1.000111]\n",
      "epoch:13 step:63195[D loss: 1.000009] [G loss: 1.000083]\n",
      "epoch:13 step:63200[D loss: 1.000128] [G loss: 0.999967]\n",
      "##############\n",
      "[2.63278913 2.06302691 2.37190709 3.88584137 1.54454518 9.27357666\n",
      " 2.40190376 3.72543515 4.08251001 5.63697954]\n",
      "##########\n",
      "epoch:13 step:63205[D loss: 0.999934] [G loss: 1.000129]\n",
      "epoch:13 step:63210[D loss: 0.999963] [G loss: 1.000048]\n",
      "epoch:13 step:63215[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:13 step:63220[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:13 step:63225[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:13 step:63230[D loss: 0.999997] [G loss: 1.000026]\n",
      "epoch:13 step:63235[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:13 step:63240[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:13 step:63245[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:13 step:63250[D loss: 0.999959] [G loss: 1.000191]\n",
      "epoch:13 step:63255[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:13 step:63260[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:13 step:63265[D loss: 0.999993] [G loss: 1.000093]\n",
      "epoch:13 step:63270[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:13 step:63275[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:13 step:63280[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:13 step:63285[D loss: 0.999995] [G loss: 1.000035]\n",
      "epoch:13 step:63290[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:13 step:63295[D loss: 0.999991] [G loss: 1.000078]\n",
      "epoch:13 step:63300[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:13 step:63305[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:13 step:63310[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:13 step:63315[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:13 step:63320[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:13 step:63325[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:13 step:63330[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:13 step:63335[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:13 step:63340[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:13 step:63345[D loss: 0.999996] [G loss: 1.000039]\n",
      "epoch:13 step:63350[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:13 step:63355[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:13 step:63360[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:13 step:63365[D loss: 1.000002] [G loss: 1.000058]\n",
      "epoch:13 step:63370[D loss: 0.999980] [G loss: 1.000158]\n",
      "epoch:13 step:63375[D loss: 0.999964] [G loss: 1.000121]\n",
      "epoch:13 step:63380[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:13 step:63385[D loss: 1.000023] [G loss: 1.000182]\n",
      "epoch:13 step:63390[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:13 step:63395[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:13 step:63400[D loss: 1.000007] [G loss: 0.999994]\n",
      "##############\n",
      "[2.62728854 2.06902621 2.23687391 4.02803336 1.54053101 7.35936452\n",
      " 2.38511343 3.80843952 3.93193829 5.00371723]\n",
      "##########\n",
      "epoch:13 step:63405[D loss: 1.000083] [G loss: 0.999925]\n",
      "epoch:13 step:63410[D loss: 0.999972] [G loss: 0.999969]\n",
      "epoch:13 step:63415[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:13 step:63420[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:13 step:63425[D loss: 1.000010] [G loss: 0.999996]\n",
      "epoch:13 step:63430[D loss: 0.999942] [G loss: 1.000127]\n",
      "epoch:13 step:63435[D loss: 0.999957] [G loss: 1.000047]\n",
      "epoch:13 step:63440[D loss: 0.999979] [G loss: 1.000111]\n",
      "epoch:13 step:63445[D loss: 1.000010] [G loss: 1.000023]\n",
      "epoch:13 step:63450[D loss: 0.999907] [G loss: 1.000162]\n",
      "epoch:13 step:63455[D loss: 1.000009] [G loss: 1.000113]\n",
      "epoch:13 step:63460[D loss: 0.999956] [G loss: 1.000120]\n",
      "epoch:13 step:63465[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:13 step:63470[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:13 step:63475[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:13 step:63480[D loss: 1.000006] [G loss: 0.999996]\n",
      "epoch:13 step:63485[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:13 step:63490[D loss: 1.000016] [G loss: 1.000040]\n",
      "epoch:13 step:63495[D loss: 0.999945] [G loss: 1.000102]\n",
      "epoch:13 step:63500[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:13 step:63505[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:13 step:63510[D loss: 0.999991] [G loss: 1.000017]\n",
      "epoch:13 step:63515[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:13 step:63520[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:13 step:63525[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:13 step:63530[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:13 step:63535[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:13 step:63540[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:13 step:63545[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:13 step:63550[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:13 step:63555[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:13 step:63560[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:13 step:63565[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:13 step:63570[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:13 step:63575[D loss: 1.000044] [G loss: 0.999969]\n",
      "epoch:13 step:63580[D loss: 0.999967] [G loss: 1.000039]\n",
      "epoch:13 step:63585[D loss: 0.999997] [G loss: 1.000123]\n",
      "epoch:13 step:63590[D loss: 0.999958] [G loss: 1.000134]\n",
      "epoch:13 step:63595[D loss: 0.999977] [G loss: 1.000122]\n",
      "epoch:13 step:63600[D loss: 1.000001] [G loss: 1.000051]\n",
      "##############\n",
      "[2.64185944 2.09575717 2.17120731 4.12496842 1.50895454 8.1178627\n",
      " 2.20927632 3.73840008 4.01710801 5.41502023]\n",
      "##########\n",
      "epoch:13 step:63605[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:13 step:63610[D loss: 0.999955] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:63615[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:13 step:63620[D loss: 1.000030] [G loss: 0.999996]\n",
      "epoch:13 step:63625[D loss: 0.999972] [G loss: 1.000100]\n",
      "epoch:13 step:63630[D loss: 1.000029] [G loss: 0.999987]\n",
      "epoch:13 step:63635[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:13 step:63640[D loss: 0.999947] [G loss: 1.000068]\n",
      "epoch:13 step:63645[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:13 step:63650[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:13 step:63655[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:13 step:63660[D loss: 1.000009] [G loss: 1.000035]\n",
      "epoch:13 step:63665[D loss: 0.999996] [G loss: 1.000051]\n",
      "epoch:13 step:63670[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:13 step:63675[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:13 step:63680[D loss: 0.999951] [G loss: 1.000110]\n",
      "epoch:13 step:63685[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:13 step:63690[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:13 step:63695[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:13 step:63700[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:13 step:63705[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:13 step:63710[D loss: 0.999953] [G loss: 1.000118]\n",
      "epoch:13 step:63715[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:13 step:63720[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:13 step:63725[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:13 step:63730[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:13 step:63735[D loss: 1.000006] [G loss: 0.999990]\n",
      "epoch:13 step:63740[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:13 step:63745[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:13 step:63750[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:13 step:63755[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:13 step:63760[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:13 step:63765[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:13 step:63770[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:13 step:63775[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:13 step:63780[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:13 step:63785[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:13 step:63790[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:13 step:63795[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:13 step:63800[D loss: 1.000005] [G loss: 1.000054]\n",
      "##############\n",
      "[2.62402963 2.07745204 2.26414299 3.79768906 1.55405526 7.54738487\n",
      " 2.27731904 3.80481973 4.05160133 5.74190189]\n",
      "##########\n",
      "epoch:13 step:63805[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:13 step:63810[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:13 step:63815[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:13 step:63820[D loss: 0.999993] [G loss: 1.000007]\n",
      "epoch:13 step:63825[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:13 step:63830[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:13 step:63835[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:13 step:63840[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:13 step:63845[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:13 step:63850[D loss: 1.000035] [G loss: 1.000013]\n",
      "epoch:13 step:63855[D loss: 0.999954] [G loss: 1.000050]\n",
      "epoch:13 step:63860[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:13 step:63865[D loss: 0.999998] [G loss: 1.000012]\n",
      "epoch:13 step:63870[D loss: 1.000031] [G loss: 1.000034]\n",
      "epoch:13 step:63875[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:13 step:63880[D loss: 1.000019] [G loss: 1.000039]\n",
      "epoch:13 step:63885[D loss: 0.999940] [G loss: 1.000115]\n",
      "epoch:13 step:63890[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:13 step:63895[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:13 step:63900[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:13 step:63905[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:13 step:63910[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:13 step:63915[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:13 step:63920[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:13 step:63925[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:13 step:63930[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:13 step:63935[D loss: 0.999990] [G loss: 1.000090]\n",
      "epoch:13 step:63940[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:13 step:63945[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:13 step:63950[D loss: 1.000017] [G loss: 1.000052]\n",
      "epoch:13 step:63955[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:13 step:63960[D loss: 1.000012] [G loss: 1.000053]\n",
      "epoch:13 step:63965[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:13 step:63970[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:13 step:63975[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:13 step:63980[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:13 step:63985[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:13 step:63990[D loss: 1.000034] [G loss: 1.000016]\n",
      "epoch:13 step:63995[D loss: 1.000039] [G loss: 0.999971]\n",
      "epoch:13 step:64000[D loss: 0.999925] [G loss: 1.000089]\n",
      "##############\n",
      "[2.68620497 2.25276425 2.30285595 3.79159402 1.60713805 7.32754969\n",
      " 2.19982344 3.82829919 4.11878708 5.35974337]\n",
      "##########\n",
      "epoch:13 step:64005[D loss: 1.000018] [G loss: 1.000038]\n",
      "epoch:13 step:64010[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:13 step:64015[D loss: 0.999987] [G loss: 1.000084]\n",
      "epoch:13 step:64020[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:13 step:64025[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:13 step:64030[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:13 step:64035[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:13 step:64040[D loss: 1.000001] [G loss: 1.000062]\n",
      "epoch:13 step:64045[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:13 step:64050[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:13 step:64055[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:13 step:64060[D loss: 0.999950] [G loss: 1.000100]\n",
      "epoch:13 step:64065[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:13 step:64070[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:13 step:64075[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:13 step:64080[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:13 step:64085[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:13 step:64090[D loss: 1.000036] [G loss: 0.999964]\n",
      "epoch:13 step:64095[D loss: 0.999902] [G loss: 1.000118]\n",
      "epoch:13 step:64100[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:13 step:64105[D loss: 1.000010] [G loss: 1.000042]\n",
      "epoch:13 step:64110[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:13 step:64115[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:13 step:64120[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:13 step:64125[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:13 step:64130[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:13 step:64135[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:13 step:64140[D loss: 0.999952] [G loss: 1.000059]\n",
      "epoch:13 step:64145[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:13 step:64150[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:13 step:64155[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:13 step:64160[D loss: 1.000019] [G loss: 1.000010]\n",
      "epoch:13 step:64165[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:13 step:64170[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:13 step:64175[D loss: 1.000019] [G loss: 0.999958]\n",
      "epoch:13 step:64180[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:13 step:64185[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:13 step:64190[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:13 step:64195[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:13 step:64200[D loss: 0.999994] [G loss: 1.000039]\n",
      "##############\n",
      "[2.61896829 2.09688952 2.16128494 3.42255756 1.47019104 8.61298274\n",
      " 2.29637635 3.74895513 3.93164657 5.9436261 ]\n",
      "##########\n",
      "epoch:13 step:64205[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:13 step:64210[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:13 step:64215[D loss: 1.000022] [G loss: 1.000028]\n",
      "epoch:13 step:64220[D loss: 1.000062] [G loss: 0.999871]\n",
      "epoch:13 step:64225[D loss: 0.999940] [G loss: 1.000090]\n",
      "epoch:13 step:64230[D loss: 0.999976] [G loss: 1.000034]\n",
      "epoch:13 step:64235[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:13 step:64240[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:13 step:64245[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:13 step:64250[D loss: 0.999967] [G loss: 1.000035]\n",
      "epoch:13 step:64255[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:13 step:64260[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:13 step:64265[D loss: 1.000044] [G loss: 0.999940]\n",
      "epoch:13 step:64270[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:13 step:64275[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:13 step:64280[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:13 step:64285[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:13 step:64290[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:13 step:64295[D loss: 0.999962] [G loss: 1.000097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:64300[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:13 step:64305[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:13 step:64310[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:13 step:64315[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:13 step:64320[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:13 step:64325[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:13 step:64330[D loss: 1.000007] [G loss: 1.000042]\n",
      "epoch:13 step:64335[D loss: 1.000009] [G loss: 0.999985]\n",
      "epoch:13 step:64340[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:13 step:64345[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:13 step:64350[D loss: 1.000005] [G loss: 1.000047]\n",
      "epoch:13 step:64355[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:13 step:64360[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:13 step:64365[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:13 step:64370[D loss: 0.999980] [G loss: 1.000095]\n",
      "epoch:13 step:64375[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:13 step:64380[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:13 step:64385[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:13 step:64390[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:13 step:64395[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:13 step:64400[D loss: 0.999972] [G loss: 1.000087]\n",
      "##############\n",
      "[2.64633638 2.1526103  2.13203924 3.82573947 1.48639755 7.29705655\n",
      " 2.37389583 3.83539117 3.97341131 5.22626573]\n",
      "##########\n",
      "epoch:13 step:64405[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:13 step:64410[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:13 step:64415[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:13 step:64420[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:13 step:64425[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:13 step:64430[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:13 step:64435[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:13 step:64440[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:13 step:64445[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:13 step:64450[D loss: 1.000041] [G loss: 1.000029]\n",
      "epoch:13 step:64455[D loss: 1.000022] [G loss: 1.000054]\n",
      "epoch:13 step:64460[D loss: 0.999956] [G loss: 1.000121]\n",
      "epoch:13 step:64465[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:13 step:64470[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:13 step:64475[D loss: 1.000043] [G loss: 1.000040]\n",
      "epoch:13 step:64480[D loss: 0.999930] [G loss: 1.000110]\n",
      "epoch:13 step:64485[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:13 step:64490[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:13 step:64495[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:13 step:64500[D loss: 0.999996] [G loss: 1.000058]\n",
      "epoch:13 step:64505[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:13 step:64510[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:13 step:64515[D loss: 0.999998] [G loss: 1.000066]\n",
      "epoch:13 step:64520[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:13 step:64525[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:13 step:64530[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:13 step:64535[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:13 step:64540[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:13 step:64545[D loss: 1.000000] [G loss: 1.000046]\n",
      "epoch:13 step:64550[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:13 step:64555[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:13 step:64560[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:13 step:64565[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:13 step:64570[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:13 step:64575[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:13 step:64580[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:13 step:64585[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:13 step:64590[D loss: 1.000006] [G loss: 1.000055]\n",
      "epoch:13 step:64595[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:13 step:64600[D loss: 1.000003] [G loss: 1.000043]\n",
      "##############\n",
      "[2.60196347 2.14555867 2.41768462 3.58962744 1.51543731 9.27357666\n",
      " 2.39130575 3.90799291 3.99921171 5.51818143]\n",
      "##########\n",
      "epoch:13 step:64605[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:13 step:64610[D loss: 0.999937] [G loss: 1.000119]\n",
      "epoch:13 step:64615[D loss: 0.999996] [G loss: 1.000105]\n",
      "epoch:13 step:64620[D loss: 0.999941] [G loss: 1.000045]\n",
      "epoch:13 step:64625[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:13 step:64630[D loss: 0.999957] [G loss: 1.000045]\n",
      "epoch:13 step:64635[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:13 step:64640[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:13 step:64645[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:13 step:64650[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:13 step:64655[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:13 step:64660[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:13 step:64665[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:13 step:64670[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:13 step:64675[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:13 step:64680[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:13 step:64685[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:13 step:64690[D loss: 1.000000] [G loss: 1.000012]\n",
      "epoch:13 step:64695[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:13 step:64700[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:13 step:64705[D loss: 0.999997] [G loss: 0.999990]\n",
      "epoch:13 step:64710[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:13 step:64715[D loss: 1.000020] [G loss: 0.999996]\n",
      "epoch:13 step:64720[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:13 step:64725[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:13 step:64730[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:13 step:64735[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:13 step:64740[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:13 step:64745[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:13 step:64750[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:13 step:64755[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:13 step:64760[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:13 step:64765[D loss: 1.000010] [G loss: 0.999991]\n",
      "epoch:13 step:64770[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:13 step:64775[D loss: 1.000094] [G loss: 0.999911]\n",
      "epoch:13 step:64780[D loss: 0.999983] [G loss: 0.999930]\n",
      "epoch:13 step:64785[D loss: 1.000016] [G loss: 0.999992]\n",
      "epoch:13 step:64790[D loss: 0.999953] [G loss: 1.000064]\n",
      "epoch:13 step:64795[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:13 step:64800[D loss: 0.999995] [G loss: 1.000046]\n",
      "##############\n",
      "[2.57281743 2.11411705 2.24808403 3.93692945 1.38687239 7.11856545\n",
      " 2.42034185 3.81501367 3.95458883 5.52757201]\n",
      "##########\n",
      "epoch:13 step:64805[D loss: 0.999998] [G loss: 0.999991]\n",
      "epoch:13 step:64810[D loss: 0.999952] [G loss: 1.000056]\n",
      "epoch:13 step:64815[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:13 step:64820[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:13 step:64825[D loss: 0.999924] [G loss: 1.000146]\n",
      "epoch:13 step:64830[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:13 step:64835[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:13 step:64840[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:13 step:64845[D loss: 0.999992] [G loss: 1.000004]\n",
      "epoch:13 step:64850[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:13 step:64855[D loss: 1.000006] [G loss: 0.999964]\n",
      "epoch:13 step:64860[D loss: 1.000011] [G loss: 0.999986]\n",
      "epoch:13 step:64865[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:13 step:64870[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:13 step:64875[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:13 step:64880[D loss: 1.000028] [G loss: 1.000018]\n",
      "epoch:13 step:64885[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:13 step:64890[D loss: 1.000047] [G loss: 0.999898]\n",
      "epoch:13 step:64895[D loss: 1.000046] [G loss: 0.999993]\n",
      "epoch:13 step:64900[D loss: 0.999922] [G loss: 1.000103]\n",
      "epoch:13 step:64905[D loss: 1.000017] [G loss: 1.000003]\n",
      "epoch:13 step:64910[D loss: 1.000032] [G loss: 0.999936]\n",
      "epoch:13 step:64915[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:13 step:64920[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:13 step:64925[D loss: 1.000032] [G loss: 1.000023]\n",
      "epoch:13 step:64930[D loss: 1.000060] [G loss: 0.999999]\n",
      "epoch:13 step:64935[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:13 step:64940[D loss: 0.999998] [G loss: 1.000067]\n",
      "epoch:13 step:64945[D loss: 0.999983] [G loss: 1.000131]\n",
      "epoch:13 step:64950[D loss: 0.999910] [G loss: 1.000150]\n",
      "epoch:13 step:64955[D loss: 0.999929] [G loss: 1.000096]\n",
      "epoch:13 step:64960[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:13 step:64965[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:13 step:64970[D loss: 0.999988] [G loss: 1.000033]\n",
      "epoch:13 step:64975[D loss: 0.999985] [G loss: 0.999992]\n",
      "epoch:13 step:64980[D loss: 0.999975] [G loss: 1.000028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:64985[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:13 step:64990[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:13 step:64995[D loss: 1.000009] [G loss: 1.000046]\n",
      "epoch:13 step:65000[D loss: 0.999970] [G loss: 1.000053]\n",
      "##############\n",
      "[2.57116556 2.13275251 2.28263771 4.03434876 1.42285422 7.4296143\n",
      " 2.32520376 3.80212082 3.93755513 5.25275287]\n",
      "##########\n",
      "epoch:13 step:65005[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:13 step:65010[D loss: 1.000003] [G loss: 1.000042]\n",
      "epoch:13 step:65015[D loss: 0.999983] [G loss: 1.000106]\n",
      "epoch:13 step:65020[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:13 step:65025[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:13 step:65030[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:13 step:65035[D loss: 0.999995] [G loss: 1.000021]\n",
      "epoch:13 step:65040[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:13 step:65045[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:13 step:65050[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:13 step:65055[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:13 step:65060[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:13 step:65065[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:13 step:65070[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:13 step:65075[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:13 step:65080[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:13 step:65085[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:13 step:65090[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:13 step:65095[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:13 step:65100[D loss: 1.000000] [G loss: 1.000116]\n",
      "epoch:13 step:65105[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:13 step:65110[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:13 step:65115[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:13 step:65120[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:13 step:65125[D loss: 1.000014] [G loss: 1.000015]\n",
      "epoch:13 step:65130[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:13 step:65135[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:13 step:65140[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:13 step:65145[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:13 step:65150[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:13 step:65155[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:13 step:65160[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:13 step:65165[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:13 step:65170[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:13 step:65175[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:13 step:65180[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:13 step:65185[D loss: 0.999969] [G loss: 1.000109]\n",
      "epoch:13 step:65190[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:13 step:65195[D loss: 0.999961] [G loss: 1.000115]\n",
      "epoch:13 step:65200[D loss: 0.999972] [G loss: 1.000130]\n",
      "##############\n",
      "[2.5357616  2.16560133 2.35358232 4.24355969 1.48755726 7.56051834\n",
      " 2.34408373 3.97233455 4.0374649  4.86892122]\n",
      "##########\n",
      "epoch:13 step:65205[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:13 step:65210[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:13 step:65215[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:13 step:65220[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:13 step:65225[D loss: 1.000005] [G loss: 1.000044]\n",
      "epoch:13 step:65230[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:13 step:65235[D loss: 0.999929] [G loss: 1.000150]\n",
      "epoch:13 step:65240[D loss: 0.999962] [G loss: 1.000109]\n",
      "epoch:13 step:65245[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:13 step:65250[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:13 step:65255[D loss: 1.000003] [G loss: 1.000119]\n",
      "epoch:13 step:65260[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:13 step:65265[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:13 step:65270[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:13 step:65275[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:13 step:65280[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:13 step:65285[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:13 step:65290[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:13 step:65295[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:13 step:65300[D loss: 0.999951] [G loss: 1.000118]\n",
      "epoch:13 step:65305[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:13 step:65310[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:13 step:65315[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:13 step:65320[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:13 step:65325[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:13 step:65330[D loss: 1.000047] [G loss: 0.999961]\n",
      "epoch:13 step:65335[D loss: 1.000010] [G loss: 1.000054]\n",
      "epoch:13 step:65340[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:13 step:65345[D loss: 0.999953] [G loss: 1.000094]\n",
      "epoch:13 step:65350[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:13 step:65355[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:13 step:65360[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:13 step:65365[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:13 step:65370[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:13 step:65375[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:13 step:65380[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:13 step:65385[D loss: 1.000043] [G loss: 1.000009]\n",
      "epoch:13 step:65390[D loss: 1.000005] [G loss: 1.000025]\n",
      "epoch:13 step:65395[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:13 step:65400[D loss: 0.999972] [G loss: 1.000055]\n",
      "##############\n",
      "[2.68831927 2.20980139 2.34874249 3.47896239 1.54956548 7.71152824\n",
      " 2.3576557  3.77149062 3.97811202 5.19182222]\n",
      "##########\n",
      "epoch:13 step:65405[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:13 step:65410[D loss: 0.999991] [G loss: 1.000084]\n",
      "epoch:13 step:65415[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:13 step:65420[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:13 step:65425[D loss: 1.000006] [G loss: 1.000065]\n",
      "epoch:13 step:65430[D loss: 1.000003] [G loss: 1.000041]\n",
      "epoch:13 step:65435[D loss: 0.999971] [G loss: 1.000125]\n",
      "epoch:13 step:65440[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:13 step:65445[D loss: 1.000021] [G loss: 1.000019]\n",
      "epoch:13 step:65450[D loss: 0.999950] [G loss: 1.000084]\n",
      "epoch:13 step:65455[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:13 step:65460[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:13 step:65465[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:13 step:65470[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:13 step:65475[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:13 step:65480[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:13 step:65485[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:13 step:65490[D loss: 1.000009] [G loss: 1.000071]\n",
      "epoch:13 step:65495[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:13 step:65500[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:13 step:65505[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:13 step:65510[D loss: 1.000006] [G loss: 1.000027]\n",
      "epoch:13 step:65515[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:13 step:65520[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:13 step:65525[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:13 step:65530[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:13 step:65535[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:13 step:65540[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:13 step:65545[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:13 step:65550[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:13 step:65555[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:13 step:65560[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:13 step:65565[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:13 step:65570[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:13 step:65575[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:13 step:65580[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:13 step:65585[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:13 step:65590[D loss: 1.000010] [G loss: 1.000022]\n",
      "epoch:14 step:65595[D loss: 1.000015] [G loss: 1.000032]\n",
      "epoch:14 step:65600[D loss: 0.999931] [G loss: 1.000117]\n",
      "##############\n",
      "[2.51077086 2.16528201 2.2642434  3.71506493 1.45752485 8.09366404\n",
      " 2.35617629 3.71302715 3.98075597 5.20700411]\n",
      "##########\n",
      "epoch:14 step:65605[D loss: 0.999982] [G loss: 1.000022]\n",
      "epoch:14 step:65610[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:14 step:65615[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:14 step:65620[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:14 step:65625[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:14 step:65630[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:14 step:65635[D loss: 0.999980] [G loss: 1.000118]\n",
      "epoch:14 step:65640[D loss: 1.000028] [G loss: 1.000040]\n",
      "epoch:14 step:65645[D loss: 0.999893] [G loss: 1.000214]\n",
      "epoch:14 step:65650[D loss: 0.999948] [G loss: 1.000079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:65655[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:14 step:65660[D loss: 0.999991] [G loss: 1.000016]\n",
      "epoch:14 step:65665[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:14 step:65670[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:14 step:65675[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:14 step:65680[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:14 step:65685[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:14 step:65690[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:14 step:65695[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:14 step:65700[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:14 step:65705[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:14 step:65710[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:14 step:65715[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:14 step:65720[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:14 step:65725[D loss: 0.999970] [G loss: 1.000116]\n",
      "epoch:14 step:65730[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:14 step:65735[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:14 step:65740[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:14 step:65745[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:14 step:65750[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:14 step:65755[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:14 step:65760[D loss: 1.000009] [G loss: 1.000046]\n",
      "epoch:14 step:65765[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:14 step:65770[D loss: 1.000016] [G loss: 1.000052]\n",
      "epoch:14 step:65775[D loss: 1.000014] [G loss: 1.000050]\n",
      "epoch:14 step:65780[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:14 step:65785[D loss: 0.999939] [G loss: 1.000091]\n",
      "epoch:14 step:65790[D loss: 1.000012] [G loss: 1.000031]\n",
      "epoch:14 step:65795[D loss: 1.000053] [G loss: 0.999956]\n",
      "epoch:14 step:65800[D loss: 1.000000] [G loss: 1.000018]\n",
      "##############\n",
      "[2.64376692 2.11502699 2.28422265 3.80995826 1.55451617 7.56799149\n",
      " 2.45460725 3.7666615  4.04551452 4.94346611]\n",
      "##########\n",
      "epoch:14 step:65805[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:14 step:65810[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:14 step:65815[D loss: 1.000026] [G loss: 0.999989]\n",
      "epoch:14 step:65820[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:14 step:65825[D loss: 0.999982] [G loss: 1.000015]\n",
      "epoch:14 step:65830[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:14 step:65835[D loss: 0.999947] [G loss: 1.000061]\n",
      "epoch:14 step:65840[D loss: 0.999978] [G loss: 1.000099]\n",
      "epoch:14 step:65845[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:14 step:65850[D loss: 0.999958] [G loss: 1.000059]\n",
      "epoch:14 step:65855[D loss: 1.000031] [G loss: 0.999990]\n",
      "epoch:14 step:65860[D loss: 1.000013] [G loss: 0.999999]\n",
      "epoch:14 step:65865[D loss: 0.999947] [G loss: 1.000070]\n",
      "epoch:14 step:65870[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:14 step:65875[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:14 step:65880[D loss: 0.999975] [G loss: 1.000112]\n",
      "epoch:14 step:65885[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:14 step:65890[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:14 step:65895[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:14 step:65900[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:14 step:65905[D loss: 1.000041] [G loss: 1.000028]\n",
      "epoch:14 step:65910[D loss: 0.999974] [G loss: 1.000103]\n",
      "epoch:14 step:65915[D loss: 0.999968] [G loss: 1.000111]\n",
      "epoch:14 step:65920[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:14 step:65925[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:14 step:65930[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:14 step:65935[D loss: 0.999996] [G loss: 1.000079]\n",
      "epoch:14 step:65940[D loss: 0.999957] [G loss: 1.000129]\n",
      "epoch:14 step:65945[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:14 step:65950[D loss: 0.999949] [G loss: 1.000178]\n",
      "epoch:14 step:65955[D loss: 0.999986] [G loss: 1.000017]\n",
      "epoch:14 step:65960[D loss: 0.999949] [G loss: 1.000067]\n",
      "epoch:14 step:65965[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:14 step:65970[D loss: 0.999975] [G loss: 1.000032]\n",
      "epoch:14 step:65975[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:14 step:65980[D loss: 1.000003] [G loss: 1.000026]\n",
      "epoch:14 step:65985[D loss: 0.999932] [G loss: 1.000133]\n",
      "epoch:14 step:65990[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:14 step:65995[D loss: 1.000013] [G loss: 1.000004]\n",
      "epoch:14 step:66000[D loss: 0.999965] [G loss: 1.000069]\n",
      "##############\n",
      "[2.55019327 2.0353484  2.21692782 3.6989355  1.42711549 7.95512077\n",
      " 2.13061697 3.6876689  3.91272742 5.09159901]\n",
      "##########\n",
      "epoch:14 step:66005[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:14 step:66010[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:14 step:66015[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:14 step:66020[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:14 step:66025[D loss: 0.999995] [G loss: 1.000030]\n",
      "epoch:14 step:66030[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:14 step:66035[D loss: 0.999973] [G loss: 1.000136]\n",
      "epoch:14 step:66040[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:14 step:66045[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:14 step:66050[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:14 step:66055[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:14 step:66060[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:14 step:66065[D loss: 1.000020] [G loss: 1.000014]\n",
      "epoch:14 step:66070[D loss: 1.000047] [G loss: 0.999946]\n",
      "epoch:14 step:66075[D loss: 1.000026] [G loss: 1.000002]\n",
      "epoch:14 step:66080[D loss: 0.999943] [G loss: 1.000137]\n",
      "epoch:14 step:66085[D loss: 0.999966] [G loss: 1.000102]\n",
      "epoch:14 step:66090[D loss: 0.999960] [G loss: 1.000099]\n",
      "epoch:14 step:66095[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:14 step:66100[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:14 step:66105[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:14 step:66110[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:14 step:66115[D loss: 1.000016] [G loss: 0.999993]\n",
      "epoch:14 step:66120[D loss: 1.000005] [G loss: 0.999984]\n",
      "epoch:14 step:66125[D loss: 0.999962] [G loss: 1.000140]\n",
      "epoch:14 step:66130[D loss: 1.000029] [G loss: 0.999967]\n",
      "epoch:14 step:66135[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:14 step:66140[D loss: 0.999945] [G loss: 1.000133]\n",
      "epoch:14 step:66145[D loss: 0.999928] [G loss: 1.000113]\n",
      "epoch:14 step:66150[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:14 step:66155[D loss: 0.999944] [G loss: 1.000123]\n",
      "epoch:14 step:66160[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:14 step:66165[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:14 step:66170[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:14 step:66175[D loss: 1.000029] [G loss: 1.000013]\n",
      "epoch:14 step:66180[D loss: 1.000016] [G loss: 1.000086]\n",
      "epoch:14 step:66185[D loss: 1.000009] [G loss: 1.000084]\n",
      "epoch:14 step:66190[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:14 step:66195[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:14 step:66200[D loss: 0.999971] [G loss: 1.000123]\n",
      "##############\n",
      "[2.52880412 2.1009539  2.17508123 3.66632916 1.45691065 7.17143797\n",
      " 2.16221785 3.74885946 3.901161   5.42663433]\n",
      "##########\n",
      "epoch:14 step:66205[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:14 step:66210[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:14 step:66215[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:14 step:66220[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:14 step:66225[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:14 step:66230[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:14 step:66235[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:14 step:66240[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:14 step:66245[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:14 step:66250[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:14 step:66255[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:14 step:66260[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:14 step:66265[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:14 step:66270[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:14 step:66275[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:14 step:66280[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:14 step:66285[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:14 step:66290[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:14 step:66295[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:14 step:66300[D loss: 0.999956] [G loss: 1.000123]\n",
      "epoch:14 step:66305[D loss: 0.999981] [G loss: 1.000007]\n",
      "epoch:14 step:66310[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:14 step:66315[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:14 step:66320[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:14 step:66325[D loss: 1.000015] [G loss: 1.000052]\n",
      "epoch:14 step:66330[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:14 step:66335[D loss: 0.999967] [G loss: 1.000086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:66340[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:14 step:66345[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:14 step:66350[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:14 step:66355[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:14 step:66360[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:14 step:66365[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:14 step:66370[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:14 step:66375[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:14 step:66380[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:14 step:66385[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:14 step:66390[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:14 step:66395[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:14 step:66400[D loss: 1.000028] [G loss: 0.999959]\n",
      "##############\n",
      "[2.51833091 2.06715792 2.13466906 3.75012261 1.49460743 7.26087464\n",
      " 2.4035739  3.90241435 3.92070802 7.14868929]\n",
      "##########\n",
      "epoch:14 step:66405[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:14 step:66410[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:14 step:66415[D loss: 1.000005] [G loss: 1.000043]\n",
      "epoch:14 step:66420[D loss: 0.999972] [G loss: 1.000094]\n",
      "epoch:14 step:66425[D loss: 0.999905] [G loss: 1.000106]\n",
      "epoch:14 step:66430[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:14 step:66435[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:14 step:66440[D loss: 0.999999] [G loss: 0.999989]\n",
      "epoch:14 step:66445[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:14 step:66450[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:14 step:66455[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:14 step:66460[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:14 step:66465[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:14 step:66470[D loss: 0.999949] [G loss: 1.000107]\n",
      "epoch:14 step:66475[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:14 step:66480[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:14 step:66485[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:14 step:66490[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:14 step:66495[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:14 step:66500[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:14 step:66505[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:14 step:66510[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:14 step:66515[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:14 step:66520[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:14 step:66525[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:14 step:66530[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:14 step:66535[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:14 step:66540[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:14 step:66545[D loss: 1.000013] [G loss: 0.999976]\n",
      "epoch:14 step:66550[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:14 step:66555[D loss: 1.000032] [G loss: 1.000042]\n",
      "epoch:14 step:66560[D loss: 0.999951] [G loss: 1.000121]\n",
      "epoch:14 step:66565[D loss: 0.999952] [G loss: 1.000065]\n",
      "epoch:14 step:66570[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:14 step:66575[D loss: 1.000029] [G loss: 0.999982]\n",
      "epoch:14 step:66580[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:14 step:66585[D loss: 1.000017] [G loss: 0.999954]\n",
      "epoch:14 step:66590[D loss: 0.999988] [G loss: 1.000130]\n",
      "epoch:14 step:66595[D loss: 0.999948] [G loss: 1.000117]\n",
      "epoch:14 step:66600[D loss: 0.999960] [G loss: 1.000065]\n",
      "##############\n",
      "[2.63080796 2.03517275 2.09101484 3.7391638  1.49415912 7.4647225\n",
      " 2.34773841 4.02454298 3.97106103 6.02220919]\n",
      "##########\n",
      "epoch:14 step:66605[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:14 step:66610[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:14 step:66615[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:14 step:66620[D loss: 1.000005] [G loss: 1.000037]\n",
      "epoch:14 step:66625[D loss: 0.999990] [G loss: 1.000073]\n",
      "epoch:14 step:66630[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:14 step:66635[D loss: 1.000005] [G loss: 1.000071]\n",
      "epoch:14 step:66640[D loss: 1.000010] [G loss: 1.000012]\n",
      "epoch:14 step:66645[D loss: 0.999943] [G loss: 1.000110]\n",
      "epoch:14 step:66650[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:14 step:66655[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:14 step:66660[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:14 step:66665[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:14 step:66670[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:14 step:66675[D loss: 1.000049] [G loss: 1.000044]\n",
      "epoch:14 step:66680[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:14 step:66685[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:14 step:66690[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:14 step:66695[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:14 step:66700[D loss: 1.000044] [G loss: 0.999944]\n",
      "epoch:14 step:66705[D loss: 1.000005] [G loss: 0.999997]\n",
      "epoch:14 step:66710[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:14 step:66715[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:14 step:66720[D loss: 1.000011] [G loss: 1.000068]\n",
      "epoch:14 step:66725[D loss: 1.000015] [G loss: 1.000053]\n",
      "epoch:14 step:66730[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:14 step:66735[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:14 step:66740[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:14 step:66745[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:14 step:66750[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:14 step:66755[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:14 step:66760[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:14 step:66765[D loss: 0.999949] [G loss: 1.000139]\n",
      "epoch:14 step:66770[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:14 step:66775[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:14 step:66780[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:14 step:66785[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:14 step:66790[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:14 step:66795[D loss: 1.000020] [G loss: 0.999999]\n",
      "epoch:14 step:66800[D loss: 1.000049] [G loss: 0.999910]\n",
      "##############\n",
      "[2.62631718 2.1612554  2.34717015 3.71068359 1.53236001 7.84205055\n",
      " 2.61191498 3.88510436 4.07922145 5.46939073]\n",
      "##########\n",
      "epoch:14 step:66805[D loss: 0.999936] [G loss: 1.000110]\n",
      "epoch:14 step:66810[D loss: 0.999960] [G loss: 1.000124]\n",
      "epoch:14 step:66815[D loss: 0.999933] [G loss: 1.000120]\n",
      "epoch:14 step:66820[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:14 step:66825[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:14 step:66830[D loss: 0.999982] [G loss: 1.000110]\n",
      "epoch:14 step:66835[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:14 step:66840[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:14 step:66845[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:14 step:66850[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:14 step:66855[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:14 step:66860[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:14 step:66865[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:14 step:66870[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:14 step:66875[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:14 step:66880[D loss: 1.000031] [G loss: 0.999990]\n",
      "epoch:14 step:66885[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:14 step:66890[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:14 step:66895[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:14 step:66900[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:14 step:66905[D loss: 1.000089] [G loss: 0.999934]\n",
      "epoch:14 step:66910[D loss: 0.999979] [G loss: 0.999994]\n",
      "epoch:14 step:66915[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:14 step:66920[D loss: 1.000002] [G loss: 0.999981]\n",
      "epoch:14 step:66925[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:14 step:66930[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:14 step:66935[D loss: 1.000001] [G loss: 1.000009]\n",
      "epoch:14 step:66940[D loss: 1.000016] [G loss: 1.000021]\n",
      "epoch:14 step:66945[D loss: 0.999982] [G loss: 1.000012]\n",
      "epoch:14 step:66950[D loss: 0.999998] [G loss: 1.000041]\n",
      "epoch:14 step:66955[D loss: 1.000011] [G loss: 0.999998]\n",
      "epoch:14 step:66960[D loss: 0.999956] [G loss: 1.000048]\n",
      "epoch:14 step:66965[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:14 step:66970[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:14 step:66975[D loss: 1.000011] [G loss: 1.000032]\n",
      "epoch:14 step:66980[D loss: 1.000006] [G loss: 1.000018]\n",
      "epoch:14 step:66985[D loss: 0.999992] [G loss: 0.999996]\n",
      "epoch:14 step:66990[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:14 step:66995[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:14 step:67000[D loss: 0.999976] [G loss: 1.000043]\n",
      "##############\n",
      "[2.56581317 2.09214769 2.3556143  3.7235041  1.53633476 8.01398573\n",
      " 2.38822823 3.92818802 4.03472721 5.20926647]\n",
      "##########\n",
      "epoch:14 step:67005[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:14 step:67010[D loss: 0.999978] [G loss: 1.000057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:67015[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:14 step:67020[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:14 step:67025[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:14 step:67030[D loss: 1.000000] [G loss: 1.000065]\n",
      "epoch:14 step:67035[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:14 step:67040[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:14 step:67045[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:14 step:67050[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:14 step:67055[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:14 step:67060[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:14 step:67065[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:14 step:67070[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:14 step:67075[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:14 step:67080[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:14 step:67085[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:14 step:67090[D loss: 1.000006] [G loss: 1.000035]\n",
      "epoch:14 step:67095[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:14 step:67100[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:14 step:67105[D loss: 1.000028] [G loss: 0.999972]\n",
      "epoch:14 step:67110[D loss: 0.999935] [G loss: 1.000077]\n",
      "epoch:14 step:67115[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:14 step:67120[D loss: 0.999976] [G loss: 1.000114]\n",
      "epoch:14 step:67125[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:14 step:67130[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:14 step:67135[D loss: 1.000018] [G loss: 1.000027]\n",
      "epoch:14 step:67140[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:14 step:67145[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:14 step:67150[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:14 step:67155[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:14 step:67160[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:14 step:67165[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:14 step:67170[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:14 step:67175[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:14 step:67180[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:14 step:67185[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:14 step:67190[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:14 step:67195[D loss: 1.000054] [G loss: 1.000010]\n",
      "epoch:14 step:67200[D loss: 0.999953] [G loss: 1.000123]\n",
      "##############\n",
      "[2.64368742 2.15934083 2.33985693 3.8595273  1.53504237 7.43361239\n",
      " 2.29660058 3.83845952 4.06180767 5.05276304]\n",
      "##########\n",
      "epoch:14 step:67205[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:14 step:67210[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:14 step:67215[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:14 step:67220[D loss: 1.000036] [G loss: 0.999970]\n",
      "epoch:14 step:67225[D loss: 1.000109] [G loss: 0.999881]\n",
      "epoch:14 step:67230[D loss: 0.999940] [G loss: 1.000089]\n",
      "epoch:14 step:67235[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:14 step:67240[D loss: 1.000014] [G loss: 1.000020]\n",
      "epoch:14 step:67245[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:14 step:67250[D loss: 0.999987] [G loss: 0.999979]\n",
      "epoch:14 step:67255[D loss: 0.999952] [G loss: 1.000072]\n",
      "epoch:14 step:67260[D loss: 1.000019] [G loss: 1.000021]\n",
      "epoch:14 step:67265[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:14 step:67270[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:14 step:67275[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:14 step:67280[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:14 step:67285[D loss: 0.999952] [G loss: 1.000070]\n",
      "epoch:14 step:67290[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:14 step:67295[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:14 step:67300[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:14 step:67305[D loss: 1.000010] [G loss: 1.000029]\n",
      "epoch:14 step:67310[D loss: 0.999943] [G loss: 1.000138]\n",
      "epoch:14 step:67315[D loss: 0.999942] [G loss: 1.000073]\n",
      "epoch:14 step:67320[D loss: 1.000053] [G loss: 1.000056]\n",
      "epoch:14 step:67325[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:14 step:67330[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:14 step:67335[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:14 step:67340[D loss: 0.999980] [G loss: 0.999999]\n",
      "epoch:14 step:67345[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:14 step:67350[D loss: 0.999996] [G loss: 1.000039]\n",
      "epoch:14 step:67355[D loss: 0.999933] [G loss: 1.000110]\n",
      "epoch:14 step:67360[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:14 step:67365[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:14 step:67370[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:14 step:67375[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:14 step:67380[D loss: 1.000041] [G loss: 0.999994]\n",
      "epoch:14 step:67385[D loss: 0.999966] [G loss: 1.000028]\n",
      "epoch:14 step:67390[D loss: 0.999976] [G loss: 1.000126]\n",
      "epoch:14 step:67395[D loss: 0.999921] [G loss: 1.000133]\n",
      "epoch:14 step:67400[D loss: 0.999965] [G loss: 1.000047]\n",
      "##############\n",
      "[2.60062807 2.14893155 2.32957339 3.97519615 1.46654464 7.48191551\n",
      " 2.4512548  3.80119501 4.06837569 6.42217143]\n",
      "##########\n",
      "epoch:14 step:67405[D loss: 0.999980] [G loss: 1.000105]\n",
      "epoch:14 step:67410[D loss: 1.000048] [G loss: 1.000011]\n",
      "epoch:14 step:67415[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:14 step:67420[D loss: 0.999949] [G loss: 1.000119]\n",
      "epoch:14 step:67425[D loss: 1.000010] [G loss: 1.000074]\n",
      "epoch:14 step:67430[D loss: 0.999918] [G loss: 1.000181]\n",
      "epoch:14 step:67435[D loss: 0.999939] [G loss: 1.000122]\n",
      "epoch:14 step:67440[D loss: 0.999952] [G loss: 1.000114]\n",
      "epoch:14 step:67445[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:14 step:67450[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:14 step:67455[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:14 step:67460[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:14 step:67465[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:14 step:67470[D loss: 1.000022] [G loss: 0.999983]\n",
      "epoch:14 step:67475[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:14 step:67480[D loss: 1.000051] [G loss: 1.000088]\n",
      "epoch:14 step:67485[D loss: 0.999932] [G loss: 1.000085]\n",
      "epoch:14 step:67490[D loss: 0.999962] [G loss: 1.000028]\n",
      "epoch:14 step:67495[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:14 step:67500[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:14 step:67505[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:14 step:67510[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:14 step:67515[D loss: 1.000054] [G loss: 0.999960]\n",
      "epoch:14 step:67520[D loss: 0.999964] [G loss: 1.000042]\n",
      "epoch:14 step:67525[D loss: 1.000031] [G loss: 1.000033]\n",
      "epoch:14 step:67530[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:14 step:67535[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:14 step:67540[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:14 step:67545[D loss: 0.999960] [G loss: 1.000123]\n",
      "epoch:14 step:67550[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:14 step:67555[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:14 step:67560[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:14 step:67565[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:14 step:67570[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:14 step:67575[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:14 step:67580[D loss: 0.999992] [G loss: 1.000032]\n",
      "epoch:14 step:67585[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:14 step:67590[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:14 step:67595[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:14 step:67600[D loss: 1.000017] [G loss: 0.999994]\n",
      "##############\n",
      "[2.54916304 2.09757574 2.21809805 3.63452596 1.43367903 7.46667098\n",
      " 2.24408024 3.86901312 3.97636219 5.71400835]\n",
      "##########\n",
      "epoch:14 step:67605[D loss: 0.999942] [G loss: 1.000122]\n",
      "epoch:14 step:67610[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:14 step:67615[D loss: 0.999951] [G loss: 1.000060]\n",
      "epoch:14 step:67620[D loss: 0.999979] [G loss: 1.000019]\n",
      "epoch:14 step:67625[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:14 step:67630[D loss: 0.999966] [G loss: 1.000035]\n",
      "epoch:14 step:67635[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:14 step:67640[D loss: 1.000054] [G loss: 0.999970]\n",
      "epoch:14 step:67645[D loss: 0.999969] [G loss: 1.000042]\n",
      "epoch:14 step:67650[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:14 step:67655[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:14 step:67660[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:14 step:67665[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:14 step:67670[D loss: 0.999987] [G loss: 1.000013]\n",
      "epoch:14 step:67675[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:14 step:67680[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:14 step:67685[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:14 step:67690[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:14 step:67695[D loss: 0.999972] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:67700[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:14 step:67705[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:14 step:67710[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:14 step:67715[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:14 step:67720[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:14 step:67725[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:14 step:67730[D loss: 0.999955] [G loss: 1.000078]\n",
      "epoch:14 step:67735[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:14 step:67740[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:14 step:67745[D loss: 1.000023] [G loss: 0.999925]\n",
      "epoch:14 step:67750[D loss: 1.000044] [G loss: 1.000026]\n",
      "epoch:14 step:67755[D loss: 0.999955] [G loss: 1.000106]\n",
      "epoch:14 step:67760[D loss: 0.999959] [G loss: 1.000175]\n",
      "epoch:14 step:67765[D loss: 0.999946] [G loss: 1.000134]\n",
      "epoch:14 step:67770[D loss: 0.999954] [G loss: 1.000065]\n",
      "epoch:14 step:67775[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:14 step:67780[D loss: 1.000018] [G loss: 1.000003]\n",
      "epoch:14 step:67785[D loss: 0.999954] [G loss: 1.000050]\n",
      "epoch:14 step:67790[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:14 step:67795[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:14 step:67800[D loss: 1.000031] [G loss: 0.999939]\n",
      "##############\n",
      "[2.52114384 2.13971795 2.30871694 3.55643226 1.46837324 7.66807863\n",
      " 2.43273536 3.87931658 4.04611616 5.06879793]\n",
      "##########\n",
      "epoch:14 step:67805[D loss: 0.999945] [G loss: 1.000112]\n",
      "epoch:14 step:67810[D loss: 0.999970] [G loss: 1.000032]\n",
      "epoch:14 step:67815[D loss: 0.999920] [G loss: 1.000117]\n",
      "epoch:14 step:67820[D loss: 1.000002] [G loss: 1.000122]\n",
      "epoch:14 step:67825[D loss: 1.000002] [G loss: 1.000064]\n",
      "epoch:14 step:67830[D loss: 1.000017] [G loss: 1.000074]\n",
      "epoch:14 step:67835[D loss: 0.999898] [G loss: 1.000171]\n",
      "epoch:14 step:67840[D loss: 1.000042] [G loss: 1.000022]\n",
      "epoch:14 step:67845[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:14 step:67850[D loss: 0.999939] [G loss: 1.000130]\n",
      "epoch:14 step:67855[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:14 step:67860[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:14 step:67865[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:14 step:67870[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:14 step:67875[D loss: 1.000005] [G loss: 1.000044]\n",
      "epoch:14 step:67880[D loss: 0.999989] [G loss: 1.000106]\n",
      "epoch:14 step:67885[D loss: 1.000191] [G loss: 0.999884]\n",
      "epoch:14 step:67890[D loss: 0.999984] [G loss: 0.999971]\n",
      "epoch:14 step:67895[D loss: 0.999933] [G loss: 1.000121]\n",
      "epoch:14 step:67900[D loss: 0.999914] [G loss: 1.000100]\n",
      "epoch:14 step:67905[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:14 step:67910[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:14 step:67915[D loss: 0.999994] [G loss: 1.000010]\n",
      "epoch:14 step:67920[D loss: 0.999939] [G loss: 1.000079]\n",
      "epoch:14 step:67925[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:14 step:67930[D loss: 1.000018] [G loss: 1.000021]\n",
      "epoch:14 step:67935[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:14 step:67940[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:14 step:67945[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:14 step:67950[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:14 step:67955[D loss: 0.999933] [G loss: 1.000121]\n",
      "epoch:14 step:67960[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:14 step:67965[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:14 step:67970[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:14 step:67975[D loss: 0.999941] [G loss: 1.000086]\n",
      "epoch:14 step:67980[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:14 step:67985[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:14 step:67990[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:14 step:67995[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:14 step:68000[D loss: 0.999961] [G loss: 1.000064]\n",
      "##############\n",
      "[2.42660383 2.11424789 2.23283263 3.61402456 1.42349054 6.93607054\n",
      " 2.18303598 3.81412091 3.85646694 4.91490166]\n",
      "##########\n",
      "epoch:14 step:68005[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:14 step:68010[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:14 step:68015[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:14 step:68020[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:14 step:68025[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:14 step:68030[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:14 step:68035[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:14 step:68040[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:14 step:68045[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:14 step:68050[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:14 step:68055[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:14 step:68060[D loss: 0.999957] [G loss: 1.000141]\n",
      "epoch:14 step:68065[D loss: 0.999945] [G loss: 1.000064]\n",
      "epoch:14 step:68070[D loss: 0.999986] [G loss: 1.000164]\n",
      "epoch:14 step:68075[D loss: 1.000031] [G loss: 0.999994]\n",
      "epoch:14 step:68080[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:14 step:68085[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:14 step:68090[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:14 step:68095[D loss: 0.999951] [G loss: 1.000073]\n",
      "epoch:14 step:68100[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:14 step:68105[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:14 step:68110[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:14 step:68115[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:14 step:68120[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:14 step:68125[D loss: 1.000019] [G loss: 1.000018]\n",
      "epoch:14 step:68130[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:14 step:68135[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:14 step:68140[D loss: 1.000037] [G loss: 1.000027]\n",
      "epoch:14 step:68145[D loss: 1.000006] [G loss: 0.999991]\n",
      "epoch:14 step:68150[D loss: 0.999954] [G loss: 1.000056]\n",
      "epoch:14 step:68155[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:14 step:68160[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:14 step:68165[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:14 step:68170[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:14 step:68175[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:14 step:68180[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:14 step:68185[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:14 step:68190[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:14 step:68195[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:14 step:68200[D loss: 0.999997] [G loss: 1.000069]\n",
      "##############\n",
      "[2.56525219 2.14739825 2.25033361 3.54167213 1.43287098 7.19756793\n",
      " 2.09124888 3.83145426 3.95232986 8.14868929]\n",
      "##########\n",
      "epoch:14 step:68205[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:14 step:68210[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:14 step:68215[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:14 step:68220[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:14 step:68225[D loss: 0.999975] [G loss: 1.000025]\n",
      "epoch:14 step:68230[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:14 step:68235[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:14 step:68240[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:14 step:68245[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:14 step:68250[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:14 step:68255[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:14 step:68260[D loss: 0.999965] [G loss: 1.000119]\n",
      "epoch:14 step:68265[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:14 step:68270[D loss: 1.000002] [G loss: 1.000088]\n",
      "epoch:14 step:68275[D loss: 1.000009] [G loss: 1.000028]\n",
      "epoch:14 step:68280[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:14 step:68285[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:14 step:68290[D loss: 0.999953] [G loss: 1.000094]\n",
      "epoch:14 step:68295[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:14 step:68300[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:14 step:68305[D loss: 1.000069] [G loss: 0.999945]\n",
      "epoch:14 step:68310[D loss: 1.000051] [G loss: 0.999988]\n",
      "epoch:14 step:68315[D loss: 0.999950] [G loss: 1.000149]\n",
      "epoch:14 step:68320[D loss: 1.000019] [G loss: 1.000012]\n",
      "epoch:14 step:68325[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:14 step:68330[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:14 step:68335[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:14 step:68340[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:14 step:68345[D loss: 1.000004] [G loss: 1.000006]\n",
      "epoch:14 step:68350[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:14 step:68355[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:14 step:68360[D loss: 0.999968] [G loss: 1.000014]\n",
      "epoch:14 step:68365[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:14 step:68370[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:14 step:68375[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:14 step:68380[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:14 step:68385[D loss: 0.999987] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:68390[D loss: 1.000015] [G loss: 1.000018]\n",
      "epoch:14 step:68395[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:14 step:68400[D loss: 0.999973] [G loss: 1.000075]\n",
      "##############\n",
      "[2.53492238 2.05491881 2.11592548 3.77798821 1.41099367 6.48675441\n",
      " 2.0656208  3.66790058 3.94096729 5.67103939]\n",
      "##########\n",
      "epoch:14 step:68405[D loss: 1.000009] [G loss: 1.000071]\n",
      "epoch:14 step:68410[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:14 step:68415[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:14 step:68420[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:14 step:68425[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:14 step:68430[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:14 step:68435[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:14 step:68440[D loss: 0.999999] [G loss: 1.000051]\n",
      "epoch:14 step:68445[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:14 step:68450[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:14 step:68455[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:14 step:68460[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:14 step:68465[D loss: 1.000013] [G loss: 1.000066]\n",
      "epoch:14 step:68470[D loss: 0.999946] [G loss: 1.000131]\n",
      "epoch:14 step:68475[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:14 step:68480[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:14 step:68485[D loss: 0.999950] [G loss: 1.000048]\n",
      "epoch:14 step:68490[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:14 step:68495[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:14 step:68500[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:14 step:68505[D loss: 0.999941] [G loss: 1.000097]\n",
      "epoch:14 step:68510[D loss: 0.999962] [G loss: 1.000043]\n",
      "epoch:14 step:68515[D loss: 1.000010] [G loss: 1.000028]\n",
      "epoch:14 step:68520[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:14 step:68525[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:14 step:68530[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:14 step:68535[D loss: 1.000059] [G loss: 0.999942]\n",
      "epoch:14 step:68540[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:14 step:68545[D loss: 0.999946] [G loss: 1.000096]\n",
      "epoch:14 step:68550[D loss: 1.000014] [G loss: 0.999977]\n",
      "epoch:14 step:68555[D loss: 1.000034] [G loss: 0.999990]\n",
      "epoch:14 step:68560[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:14 step:68565[D loss: 1.000014] [G loss: 1.000055]\n",
      "epoch:14 step:68570[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:14 step:68575[D loss: 0.999931] [G loss: 1.000122]\n",
      "epoch:14 step:68580[D loss: 0.999944] [G loss: 1.000094]\n",
      "epoch:14 step:68585[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:14 step:68590[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:14 step:68595[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:14 step:68600[D loss: 1.000059] [G loss: 0.999935]\n",
      "##############\n",
      "[2.53218148 2.10901596 2.22995905 4.27557665 1.39789363 7.86352729\n",
      " 2.27507467 3.58454211 4.02925867 5.6354792 ]\n",
      "##########\n",
      "epoch:14 step:68605[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:14 step:68610[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:14 step:68615[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:14 step:68620[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:14 step:68625[D loss: 1.000050] [G loss: 0.999932]\n",
      "epoch:14 step:68630[D loss: 0.999959] [G loss: 1.000124]\n",
      "epoch:14 step:68635[D loss: 0.999989] [G loss: 1.000148]\n",
      "epoch:14 step:68640[D loss: 0.999910] [G loss: 1.000120]\n",
      "epoch:14 step:68645[D loss: 1.000011] [G loss: 1.000032]\n",
      "epoch:14 step:68650[D loss: 1.000026] [G loss: 1.000035]\n",
      "epoch:14 step:68655[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:14 step:68660[D loss: 0.999966] [G loss: 1.000035]\n",
      "epoch:14 step:68665[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:14 step:68670[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:14 step:68675[D loss: 1.000014] [G loss: 1.000045]\n",
      "epoch:14 step:68680[D loss: 0.999972] [G loss: 1.000172]\n",
      "epoch:14 step:68685[D loss: 0.999921] [G loss: 1.000080]\n",
      "epoch:14 step:68690[D loss: 1.000044] [G loss: 1.000040]\n",
      "epoch:14 step:68695[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:14 step:68700[D loss: 1.000016] [G loss: 1.000061]\n",
      "epoch:14 step:68705[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:14 step:68710[D loss: 1.000010] [G loss: 1.000015]\n",
      "epoch:14 step:68715[D loss: 1.000000] [G loss: 1.000086]\n",
      "epoch:14 step:68720[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:14 step:68725[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:14 step:68730[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:14 step:68735[D loss: 0.999981] [G loss: 1.000033]\n",
      "epoch:14 step:68740[D loss: 1.000042] [G loss: 0.999963]\n",
      "epoch:14 step:68745[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:14 step:68750[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:14 step:68755[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:14 step:68760[D loss: 0.999928] [G loss: 1.000137]\n",
      "epoch:14 step:68765[D loss: 1.000039] [G loss: 0.999932]\n",
      "epoch:14 step:68770[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:14 step:68775[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:14 step:68780[D loss: 0.999948] [G loss: 1.000068]\n",
      "epoch:14 step:68785[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:14 step:68790[D loss: 1.000045] [G loss: 0.999921]\n",
      "epoch:14 step:68795[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:14 step:68800[D loss: 0.999935] [G loss: 1.000085]\n",
      "##############\n",
      "[2.51024153 2.10431565 2.20928815 3.94636257 1.45963776 7.79672904\n",
      " 2.38277738 3.92331484 4.01056782 5.81515932]\n",
      "##########\n",
      "epoch:14 step:68805[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:14 step:68810[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:14 step:68815[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:14 step:68820[D loss: 1.000001] [G loss: 1.000031]\n",
      "epoch:14 step:68825[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:14 step:68830[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:14 step:68835[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:14 step:68840[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:14 step:68845[D loss: 1.000002] [G loss: 1.000080]\n",
      "epoch:14 step:68850[D loss: 0.999929] [G loss: 1.000093]\n",
      "epoch:14 step:68855[D loss: 0.999987] [G loss: 1.000088]\n",
      "epoch:14 step:68860[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:14 step:68865[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:14 step:68870[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:14 step:68875[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:14 step:68880[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:14 step:68885[D loss: 0.999953] [G loss: 1.000113]\n",
      "epoch:14 step:68890[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:14 step:68895[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:14 step:68900[D loss: 1.000096] [G loss: 0.999876]\n",
      "epoch:14 step:68905[D loss: 0.999915] [G loss: 1.000204]\n",
      "epoch:14 step:68910[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:14 step:68915[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:14 step:68920[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:14 step:68925[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:14 step:68930[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:14 step:68935[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:14 step:68940[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:14 step:68945[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:14 step:68950[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:14 step:68955[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:14 step:68960[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:14 step:68965[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:14 step:68970[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:14 step:68975[D loss: 0.999992] [G loss: 1.000037]\n",
      "epoch:14 step:68980[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:14 step:68985[D loss: 1.000020] [G loss: 0.999991]\n",
      "epoch:14 step:68990[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:14 step:68995[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:14 step:69000[D loss: 0.999980] [G loss: 1.000054]\n",
      "##############\n",
      "[2.50192785 2.04546304 2.25690943 3.73823252 1.43154687 7.43777397\n",
      " 2.42981122 3.73106902 3.98031305 5.48966304]\n",
      "##########\n",
      "epoch:14 step:69005[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:14 step:69010[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:14 step:69015[D loss: 1.000025] [G loss: 1.000042]\n",
      "epoch:14 step:69020[D loss: 1.000069] [G loss: 0.999908]\n",
      "epoch:14 step:69025[D loss: 0.999969] [G loss: 1.000016]\n",
      "epoch:14 step:69030[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:14 step:69035[D loss: 1.000038] [G loss: 1.000040]\n",
      "epoch:14 step:69040[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:14 step:69045[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:14 step:69050[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:14 step:69055[D loss: 0.999961] [G loss: 1.000093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:69060[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:14 step:69065[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:14 step:69070[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:14 step:69075[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:14 step:69080[D loss: 0.999946] [G loss: 1.000086]\n",
      "epoch:14 step:69085[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:14 step:69090[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:14 step:69095[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:14 step:69100[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:14 step:69105[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:14 step:69110[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:14 step:69115[D loss: 0.999996] [G loss: 1.000055]\n",
      "epoch:14 step:69120[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:14 step:69125[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:14 step:69130[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:14 step:69135[D loss: 0.999965] [G loss: 1.000105]\n",
      "epoch:14 step:69140[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:14 step:69145[D loss: 1.000023] [G loss: 0.999962]\n",
      "epoch:14 step:69150[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:14 step:69155[D loss: 0.999927] [G loss: 1.000097]\n",
      "epoch:14 step:69160[D loss: 1.000007] [G loss: 1.000115]\n",
      "epoch:14 step:69165[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:14 step:69170[D loss: 0.999951] [G loss: 1.000049]\n",
      "epoch:14 step:69175[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:14 step:69180[D loss: 0.999996] [G loss: 1.000012]\n",
      "epoch:14 step:69185[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:14 step:69190[D loss: 0.999935] [G loss: 1.000121]\n",
      "epoch:14 step:69195[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:14 step:69200[D loss: 1.000057] [G loss: 0.999967]\n",
      "##############\n",
      "[2.59594945 2.12578513 2.11450329 3.6701101  1.5168492  8.22716069\n",
      " 2.28421679 3.98219856 4.05610576 5.98967914]\n",
      "##########\n",
      "epoch:14 step:69205[D loss: 0.999997] [G loss: 1.000073]\n",
      "epoch:14 step:69210[D loss: 1.000046] [G loss: 0.999931]\n",
      "epoch:14 step:69215[D loss: 0.999984] [G loss: 0.999995]\n",
      "epoch:14 step:69220[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:14 step:69225[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:14 step:69230[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:14 step:69235[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:14 step:69240[D loss: 1.000005] [G loss: 1.000032]\n",
      "epoch:14 step:69245[D loss: 0.999953] [G loss: 1.000063]\n",
      "epoch:14 step:69250[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:14 step:69255[D loss: 0.999931] [G loss: 1.000079]\n",
      "epoch:14 step:69260[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:14 step:69265[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:14 step:69270[D loss: 1.000011] [G loss: 1.000006]\n",
      "epoch:14 step:69275[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:14 step:69280[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:14 step:69285[D loss: 1.000014] [G loss: 1.000047]\n",
      "epoch:14 step:69290[D loss: 0.999983] [G loss: 1.000010]\n",
      "epoch:14 step:69295[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:14 step:69300[D loss: 0.999999] [G loss: 1.000098]\n",
      "epoch:14 step:69305[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:14 step:69310[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:14 step:69315[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:14 step:69320[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:14 step:69325[D loss: 0.999989] [G loss: 0.999989]\n",
      "epoch:14 step:69330[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:14 step:69335[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:14 step:69340[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:14 step:69345[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:14 step:69350[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:14 step:69355[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:14 step:69360[D loss: 1.000002] [G loss: 1.000072]\n",
      "epoch:14 step:69365[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:14 step:69370[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:14 step:69375[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:14 step:69380[D loss: 0.999952] [G loss: 1.000115]\n",
      "epoch:14 step:69385[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:14 step:69390[D loss: 1.000013] [G loss: 1.000007]\n",
      "epoch:14 step:69395[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:14 step:69400[D loss: 1.000049] [G loss: 0.999960]\n",
      "##############\n",
      "[2.59541627 2.06682991 2.16408591 3.77058131 1.47887968 7.41026329\n",
      " 2.21291548 3.84818845 3.94475589 5.9057197 ]\n",
      "##########\n",
      "epoch:14 step:69405[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:14 step:69410[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:14 step:69415[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:14 step:69420[D loss: 0.999996] [G loss: 1.000064]\n",
      "epoch:14 step:69425[D loss: 0.999952] [G loss: 1.000024]\n",
      "epoch:14 step:69430[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:14 step:69435[D loss: 0.999921] [G loss: 1.000081]\n",
      "epoch:14 step:69440[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:14 step:69445[D loss: 1.000008] [G loss: 1.000016]\n",
      "epoch:14 step:69450[D loss: 1.000039] [G loss: 1.000009]\n",
      "epoch:14 step:69455[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:14 step:69460[D loss: 1.000040] [G loss: 1.000058]\n",
      "epoch:14 step:69465[D loss: 0.999956] [G loss: 1.000034]\n",
      "epoch:14 step:69470[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:14 step:69475[D loss: 1.000000] [G loss: 0.999986]\n",
      "epoch:14 step:69480[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:14 step:69485[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:14 step:69490[D loss: 1.000010] [G loss: 1.000005]\n",
      "epoch:14 step:69495[D loss: 0.999939] [G loss: 1.000063]\n",
      "epoch:14 step:69500[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:14 step:69505[D loss: 0.999952] [G loss: 1.000118]\n",
      "epoch:14 step:69510[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:14 step:69515[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:14 step:69520[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:14 step:69525[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:14 step:69530[D loss: 0.999951] [G loss: 1.000166]\n",
      "epoch:14 step:69535[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:14 step:69540[D loss: 0.999959] [G loss: 1.000035]\n",
      "epoch:14 step:69545[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:14 step:69550[D loss: 0.999970] [G loss: 1.000025]\n",
      "epoch:14 step:69555[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:14 step:69560[D loss: 0.999935] [G loss: 1.000094]\n",
      "epoch:14 step:69565[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:14 step:69570[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:14 step:69575[D loss: 0.999938] [G loss: 1.000100]\n",
      "epoch:14 step:69580[D loss: 1.000020] [G loss: 0.999987]\n",
      "epoch:14 step:69585[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:14 step:69590[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:14 step:69595[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:14 step:69600[D loss: 0.999963] [G loss: 1.000052]\n",
      "##############\n",
      "[2.6656961  2.15631883 2.27255119 3.60095918 1.48848992 8.49191824\n",
      " 2.4022013  3.84073212 4.04602214 5.50017214]\n",
      "##########\n",
      "epoch:14 step:69605[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:14 step:69610[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:14 step:69615[D loss: 1.000037] [G loss: 0.999971]\n",
      "epoch:14 step:69620[D loss: 0.999948] [G loss: 1.000074]\n",
      "epoch:14 step:69625[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:14 step:69630[D loss: 1.000060] [G loss: 0.999983]\n",
      "epoch:14 step:69635[D loss: 0.999932] [G loss: 1.000090]\n",
      "epoch:14 step:69640[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:14 step:69645[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:14 step:69650[D loss: 0.999970] [G loss: 1.000112]\n",
      "epoch:14 step:69655[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:14 step:69660[D loss: 1.000001] [G loss: 0.999988]\n",
      "epoch:14 step:69665[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:14 step:69670[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:14 step:69675[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:14 step:69680[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:14 step:69685[D loss: 0.999990] [G loss: 1.000014]\n",
      "epoch:14 step:69690[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:14 step:69695[D loss: 1.000005] [G loss: 1.000022]\n",
      "epoch:14 step:69700[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:14 step:69705[D loss: 0.999953] [G loss: 1.000066]\n",
      "epoch:14 step:69710[D loss: 0.999975] [G loss: 1.000020]\n",
      "epoch:14 step:69715[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:14 step:69720[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:14 step:69725[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:14 step:69730[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:14 step:69735[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:14 step:69740[D loss: 0.999957] [G loss: 1.000124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:69745[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:14 step:69750[D loss: 1.000073] [G loss: 0.999983]\n",
      "epoch:14 step:69755[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:14 step:69760[D loss: 1.000022] [G loss: 1.000067]\n",
      "epoch:14 step:69765[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:14 step:69770[D loss: 1.000015] [G loss: 1.000026]\n",
      "epoch:14 step:69775[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:14 step:69780[D loss: 0.999977] [G loss: 1.000106]\n",
      "epoch:14 step:69785[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:14 step:69790[D loss: 0.999944] [G loss: 1.000121]\n",
      "epoch:14 step:69795[D loss: 0.999944] [G loss: 1.000120]\n",
      "epoch:14 step:69800[D loss: 0.999981] [G loss: 1.000053]\n",
      "##############\n",
      "[2.53049833 2.0430605  2.13470046 3.7248452  1.38230837 8.33317869\n",
      " 2.09691794 3.89044399 3.82711301 5.9777738 ]\n",
      "##########\n",
      "epoch:14 step:69805[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:14 step:69810[D loss: 0.999998] [G loss: 1.000120]\n",
      "epoch:14 step:69815[D loss: 0.999955] [G loss: 1.000114]\n",
      "epoch:14 step:69820[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:14 step:69825[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:14 step:69830[D loss: 0.999969] [G loss: 1.000097]\n",
      "epoch:14 step:69835[D loss: 0.999968] [G loss: 1.000101]\n",
      "epoch:14 step:69840[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:14 step:69845[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:14 step:69850[D loss: 0.999983] [G loss: 1.000008]\n",
      "epoch:14 step:69855[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:14 step:69860[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:14 step:69865[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:14 step:69870[D loss: 0.999951] [G loss: 1.000135]\n",
      "epoch:14 step:69875[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:14 step:69880[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:14 step:69885[D loss: 1.000001] [G loss: 1.000072]\n",
      "epoch:14 step:69890[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:14 step:69895[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:14 step:69900[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:14 step:69905[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:14 step:69910[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:14 step:69915[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:14 step:69920[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:14 step:69925[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:14 step:69930[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:14 step:69935[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:14 step:69940[D loss: 1.000004] [G loss: 1.000100]\n",
      "epoch:14 step:69945[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:14 step:69950[D loss: 0.999996] [G loss: 0.999986]\n",
      "epoch:14 step:69955[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:14 step:69960[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:14 step:69965[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:14 step:69970[D loss: 0.999991] [G loss: 1.000007]\n",
      "epoch:14 step:69975[D loss: 0.999945] [G loss: 1.000082]\n",
      "epoch:14 step:69980[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:14 step:69985[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:14 step:69990[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:14 step:69995[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:14 step:70000[D loss: 0.999971] [G loss: 1.000076]\n",
      "##############\n",
      "[2.4900321  2.08480225 2.20214368 4.05842708 1.42651338 7.47078559\n",
      " 2.34839707 3.88965297 3.94026869 6.21078439]\n",
      "##########\n",
      "epoch:14 step:70005[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:14 step:70010[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:14 step:70015[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:14 step:70020[D loss: 1.000009] [G loss: 1.000009]\n",
      "epoch:14 step:70025[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:14 step:70030[D loss: 0.999956] [G loss: 1.000109]\n",
      "epoch:14 step:70035[D loss: 0.999966] [G loss: 1.000152]\n",
      "epoch:14 step:70040[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:14 step:70045[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:14 step:70050[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:14 step:70055[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:14 step:70060[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:14 step:70065[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:14 step:70070[D loss: 0.999975] [G loss: 1.000104]\n",
      "epoch:14 step:70075[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:14 step:70080[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:14 step:70085[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:14 step:70090[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:14 step:70095[D loss: 1.000019] [G loss: 1.000037]\n",
      "epoch:14 step:70100[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:14 step:70105[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:14 step:70110[D loss: 1.000022] [G loss: 1.000037]\n",
      "epoch:14 step:70115[D loss: 1.000005] [G loss: 1.000064]\n",
      "epoch:14 step:70120[D loss: 1.000017] [G loss: 1.000047]\n",
      "epoch:14 step:70125[D loss: 0.999976] [G loss: 0.999998]\n",
      "epoch:14 step:70130[D loss: 1.000009] [G loss: 0.999990]\n",
      "epoch:14 step:70135[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:14 step:70140[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:14 step:70145[D loss: 0.999978] [G loss: 1.000028]\n",
      "epoch:14 step:70150[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:14 step:70155[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:14 step:70160[D loss: 1.000002] [G loss: 1.000075]\n",
      "epoch:14 step:70165[D loss: 1.000020] [G loss: 1.000018]\n",
      "epoch:14 step:70170[D loss: 1.000022] [G loss: 0.999975]\n",
      "epoch:14 step:70175[D loss: 1.000038] [G loss: 1.000069]\n",
      "epoch:14 step:70180[D loss: 0.999931] [G loss: 1.000057]\n",
      "epoch:14 step:70185[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:14 step:70190[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:14 step:70195[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:14 step:70200[D loss: 0.999962] [G loss: 1.000042]\n",
      "##############\n",
      "[2.55106957 2.14219138 2.24195762 4.02997187 1.47002723 8.63241118\n",
      " 2.36850894 4.00019188 4.06504118 5.39967379]\n",
      "##########\n",
      "epoch:14 step:70205[D loss: 0.999971] [G loss: 1.000037]\n",
      "epoch:14 step:70210[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:14 step:70215[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:14 step:70220[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:14 step:70225[D loss: 1.000018] [G loss: 0.999970]\n",
      "epoch:14 step:70230[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:14 step:70235[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:14 step:70240[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:14 step:70245[D loss: 1.000037] [G loss: 0.999996]\n",
      "epoch:14 step:70250[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:14 step:70255[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:14 step:70260[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:14 step:70265[D loss: 1.000012] [G loss: 1.000020]\n",
      "epoch:14 step:70270[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:14 step:70275[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:15 step:70280[D loss: 1.000026] [G loss: 1.000019]\n",
      "epoch:15 step:70285[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:15 step:70290[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:15 step:70295[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:15 step:70300[D loss: 0.999985] [G loss: 1.000018]\n",
      "epoch:15 step:70305[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:15 step:70310[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:15 step:70315[D loss: 0.999980] [G loss: 1.000020]\n",
      "epoch:15 step:70320[D loss: 1.000031] [G loss: 1.000044]\n",
      "epoch:15 step:70325[D loss: 0.999998] [G loss: 1.000119]\n",
      "epoch:15 step:70330[D loss: 0.999969] [G loss: 1.000114]\n",
      "epoch:15 step:70335[D loss: 0.999875] [G loss: 1.000156]\n",
      "epoch:15 step:70340[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:15 step:70345[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:15 step:70350[D loss: 0.999996] [G loss: 1.000055]\n",
      "epoch:15 step:70355[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:15 step:70360[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:15 step:70365[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:15 step:70370[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:15 step:70375[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:15 step:70380[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:15 step:70385[D loss: 1.000013] [G loss: 1.000071]\n",
      "epoch:15 step:70390[D loss: 0.999966] [G loss: 1.000039]\n",
      "epoch:15 step:70395[D loss: 0.999982] [G loss: 1.000104]\n",
      "epoch:15 step:70400[D loss: 0.999952] [G loss: 1.000070]\n",
      "##############\n",
      "[2.52093356 2.07830317 2.15007972 3.62899576 1.514011   7.329646\n",
      " 2.25614451 4.02024929 3.96099103 6.7029797 ]\n",
      "##########\n",
      "epoch:15 step:70405[D loss: 1.000020] [G loss: 1.000003]\n",
      "epoch:15 step:70410[D loss: 0.999988] [G loss: 1.000113]\n",
      "epoch:15 step:70415[D loss: 0.999952] [G loss: 1.000105]\n",
      "epoch:15 step:70420[D loss: 0.999991] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:70425[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:15 step:70430[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:15 step:70435[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:15 step:70440[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:15 step:70445[D loss: 0.999959] [G loss: 1.000105]\n",
      "epoch:15 step:70450[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:15 step:70455[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:15 step:70460[D loss: 1.000010] [G loss: 1.000010]\n",
      "epoch:15 step:70465[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:15 step:70470[D loss: 0.999991] [G loss: 1.000003]\n",
      "epoch:15 step:70475[D loss: 1.000093] [G loss: 0.999831]\n",
      "epoch:15 step:70480[D loss: 1.000004] [G loss: 1.000073]\n",
      "epoch:15 step:70485[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:15 step:70490[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:15 step:70495[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:15 step:70500[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:15 step:70505[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:15 step:70510[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:15 step:70515[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:15 step:70520[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:15 step:70525[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:15 step:70530[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:15 step:70535[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:15 step:70540[D loss: 0.999986] [G loss: 1.000082]\n",
      "epoch:15 step:70545[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:15 step:70550[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:15 step:70555[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:15 step:70560[D loss: 1.000010] [G loss: 1.000072]\n",
      "epoch:15 step:70565[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:15 step:70570[D loss: 0.999898] [G loss: 1.000182]\n",
      "epoch:15 step:70575[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:15 step:70580[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:15 step:70585[D loss: 1.000051] [G loss: 0.999938]\n",
      "epoch:15 step:70590[D loss: 1.000008] [G loss: 1.000034]\n",
      "epoch:15 step:70595[D loss: 0.999954] [G loss: 1.000128]\n",
      "epoch:15 step:70600[D loss: 0.999976] [G loss: 1.000048]\n",
      "##############\n",
      "[2.52194392 2.01887546 2.0596278  3.59024183 1.4319043  6.94233406\n",
      " 2.32626098 3.78342987 3.87171841 5.49691083]\n",
      "##########\n",
      "epoch:15 step:70605[D loss: 0.999926] [G loss: 1.000036]\n",
      "epoch:15 step:70610[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:15 step:70615[D loss: 1.000005] [G loss: 0.999972]\n",
      "epoch:15 step:70620[D loss: 1.000046] [G loss: 0.999989]\n",
      "epoch:15 step:70625[D loss: 0.999942] [G loss: 1.000120]\n",
      "epoch:15 step:70630[D loss: 0.999993] [G loss: 1.000079]\n",
      "epoch:15 step:70635[D loss: 1.000056] [G loss: 0.999992]\n",
      "epoch:15 step:70640[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:15 step:70645[D loss: 0.999942] [G loss: 1.000057]\n",
      "epoch:15 step:70650[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:15 step:70655[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:15 step:70660[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:15 step:70665[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:15 step:70670[D loss: 1.000016] [G loss: 0.999968]\n",
      "epoch:15 step:70675[D loss: 0.999950] [G loss: 1.000092]\n",
      "epoch:15 step:70680[D loss: 1.000052] [G loss: 0.999952]\n",
      "epoch:15 step:70685[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:15 step:70690[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:15 step:70695[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:15 step:70700[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:15 step:70705[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:15 step:70710[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:15 step:70715[D loss: 0.999947] [G loss: 1.000104]\n",
      "epoch:15 step:70720[D loss: 0.999998] [G loss: 1.000090]\n",
      "epoch:15 step:70725[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:15 step:70730[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:15 step:70735[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:15 step:70740[D loss: 0.999999] [G loss: 1.000028]\n",
      "epoch:15 step:70745[D loss: 0.999953] [G loss: 1.000093]\n",
      "epoch:15 step:70750[D loss: 0.999987] [G loss: 1.000110]\n",
      "epoch:15 step:70755[D loss: 1.000029] [G loss: 1.000046]\n",
      "epoch:15 step:70760[D loss: 0.999956] [G loss: 1.000137]\n",
      "epoch:15 step:70765[D loss: 0.999910] [G loss: 1.000237]\n",
      "epoch:15 step:70770[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:15 step:70775[D loss: 0.999951] [G loss: 1.000100]\n",
      "epoch:15 step:70780[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:15 step:70785[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:15 step:70790[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:15 step:70795[D loss: 0.999999] [G loss: 1.000010]\n",
      "epoch:15 step:70800[D loss: 0.999995] [G loss: 1.000057]\n",
      "##############\n",
      "[2.58580114 2.03964691 2.08017845 3.95253372 1.45281468 7.71641868\n",
      " 2.08129278 3.86153429 4.01102381 5.88407328]\n",
      "##########\n",
      "epoch:15 step:70805[D loss: 0.999980] [G loss: 1.000016]\n",
      "epoch:15 step:70810[D loss: 1.000013] [G loss: 1.000061]\n",
      "epoch:15 step:70815[D loss: 1.000096] [G loss: 0.999848]\n",
      "epoch:15 step:70820[D loss: 0.999995] [G loss: 1.000003]\n",
      "epoch:15 step:70825[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:15 step:70830[D loss: 0.999927] [G loss: 1.000111]\n",
      "epoch:15 step:70835[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:15 step:70840[D loss: 0.999946] [G loss: 1.000132]\n",
      "epoch:15 step:70845[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:15 step:70850[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:15 step:70855[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:15 step:70860[D loss: 1.000019] [G loss: 1.000060]\n",
      "epoch:15 step:70865[D loss: 1.000040] [G loss: 1.000027]\n",
      "epoch:15 step:70870[D loss: 1.000041] [G loss: 1.000027]\n",
      "epoch:15 step:70875[D loss: 0.999967] [G loss: 1.000034]\n",
      "epoch:15 step:70880[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:15 step:70885[D loss: 1.000001] [G loss: 1.000095]\n",
      "epoch:15 step:70890[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:15 step:70895[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:15 step:70900[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:15 step:70905[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:15 step:70910[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:15 step:70915[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:15 step:70920[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:15 step:70925[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:15 step:70930[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:15 step:70935[D loss: 1.000008] [G loss: 1.000047]\n",
      "epoch:15 step:70940[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:15 step:70945[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:15 step:70950[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:15 step:70955[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:15 step:70960[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:15 step:70965[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:15 step:70970[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:15 step:70975[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:15 step:70980[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:15 step:70985[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:15 step:70990[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:15 step:70995[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:15 step:71000[D loss: 0.999979] [G loss: 1.000094]\n",
      "##############\n",
      "[2.57544865 2.02150917 2.24102998 3.80695953 1.52561362 7.76968177\n",
      " 2.27126062 3.77841845 3.97184749 5.88153017]\n",
      "##########\n",
      "epoch:15 step:71005[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:15 step:71010[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:15 step:71015[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:15 step:71020[D loss: 0.999984] [G loss: 0.999995]\n",
      "epoch:15 step:71025[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:15 step:71030[D loss: 0.999984] [G loss: 1.000001]\n",
      "epoch:15 step:71035[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:15 step:71040[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:15 step:71045[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:15 step:71050[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:15 step:71055[D loss: 0.999993] [G loss: 1.000070]\n",
      "epoch:15 step:71060[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:15 step:71065[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:15 step:71070[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:15 step:71075[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:15 step:71080[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:15 step:71085[D loss: 1.000021] [G loss: 1.000005]\n",
      "epoch:15 step:71090[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:15 step:71095[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:15 step:71100[D loss: 1.000024] [G loss: 1.000001]\n",
      "epoch:15 step:71105[D loss: 0.999942] [G loss: 1.000101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:71110[D loss: 1.000005] [G loss: 0.999977]\n",
      "epoch:15 step:71115[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:15 step:71120[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:15 step:71125[D loss: 1.000005] [G loss: 1.000032]\n",
      "epoch:15 step:71130[D loss: 1.000038] [G loss: 0.999948]\n",
      "epoch:15 step:71135[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:15 step:71140[D loss: 0.999941] [G loss: 1.000132]\n",
      "epoch:15 step:71145[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:15 step:71150[D loss: 0.999984] [G loss: 1.000009]\n",
      "epoch:15 step:71155[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:15 step:71160[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:15 step:71165[D loss: 0.999994] [G loss: 1.000097]\n",
      "epoch:15 step:71170[D loss: 1.000062] [G loss: 0.999930]\n",
      "epoch:15 step:71175[D loss: 0.999917] [G loss: 1.000120]\n",
      "epoch:15 step:71180[D loss: 0.999960] [G loss: 1.000113]\n",
      "epoch:15 step:71185[D loss: 0.999957] [G loss: 1.000109]\n",
      "epoch:15 step:71190[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:15 step:71195[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:15 step:71200[D loss: 0.999968] [G loss: 1.000069]\n",
      "##############\n",
      "[2.56401224 1.95952862 2.16784938 3.86044109 1.54110603 7.87698864\n",
      " 2.28620557 3.95889191 3.94146817 5.71828868]\n",
      "##########\n",
      "epoch:15 step:71205[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:15 step:71210[D loss: 0.999999] [G loss: 1.000063]\n",
      "epoch:15 step:71215[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:15 step:71220[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:15 step:71225[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:15 step:71230[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:15 step:71235[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:15 step:71240[D loss: 0.999984] [G loss: 1.000099]\n",
      "epoch:15 step:71245[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:15 step:71250[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:15 step:71255[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:15 step:71260[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:15 step:71265[D loss: 1.000079] [G loss: 0.999995]\n",
      "epoch:15 step:71270[D loss: 0.999984] [G loss: 1.000009]\n",
      "epoch:15 step:71275[D loss: 1.000004] [G loss: 1.000116]\n",
      "epoch:15 step:71280[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:15 step:71285[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:15 step:71290[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:15 step:71295[D loss: 0.999994] [G loss: 1.000013]\n",
      "epoch:15 step:71300[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:15 step:71305[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:15 step:71310[D loss: 1.000034] [G loss: 0.999992]\n",
      "epoch:15 step:71315[D loss: 0.999939] [G loss: 1.000080]\n",
      "epoch:15 step:71320[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:15 step:71325[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:15 step:71330[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:15 step:71335[D loss: 1.000014] [G loss: 1.000008]\n",
      "epoch:15 step:71340[D loss: 0.999941] [G loss: 1.000096]\n",
      "epoch:15 step:71345[D loss: 1.000021] [G loss: 1.000025]\n",
      "epoch:15 step:71350[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:15 step:71355[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:15 step:71360[D loss: 1.000060] [G loss: 1.000074]\n",
      "epoch:15 step:71365[D loss: 1.000030] [G loss: 1.000004]\n",
      "epoch:15 step:71370[D loss: 0.999916] [G loss: 1.000118]\n",
      "epoch:15 step:71375[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:15 step:71380[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:15 step:71385[D loss: 1.000039] [G loss: 0.999935]\n",
      "epoch:15 step:71390[D loss: 0.999993] [G loss: 1.000043]\n",
      "epoch:15 step:71395[D loss: 0.999943] [G loss: 1.000068]\n",
      "epoch:15 step:71400[D loss: 0.999974] [G loss: 1.000094]\n",
      "##############\n",
      "[2.42250628 2.0493404  2.19945662 3.7393215  1.37320567 8.17262792\n",
      " 2.25029866 3.68178375 3.89769325 8.14868929]\n",
      "##########\n",
      "epoch:15 step:71405[D loss: 0.999987] [G loss: 1.000081]\n",
      "epoch:15 step:71410[D loss: 0.999983] [G loss: 1.000142]\n",
      "epoch:15 step:71415[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:15 step:71420[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:15 step:71425[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:15 step:71430[D loss: 0.999957] [G loss: 1.000103]\n",
      "epoch:15 step:71435[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:15 step:71440[D loss: 0.999989] [G loss: 1.000097]\n",
      "epoch:15 step:71445[D loss: 0.999977] [G loss: 1.000110]\n",
      "epoch:15 step:71450[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:15 step:71455[D loss: 0.999919] [G loss: 1.000153]\n",
      "epoch:15 step:71460[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:15 step:71465[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:15 step:71470[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:15 step:71475[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:15 step:71480[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:15 step:71485[D loss: 1.000009] [G loss: 0.999993]\n",
      "epoch:15 step:71490[D loss: 0.999983] [G loss: 1.000014]\n",
      "epoch:15 step:71495[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:15 step:71500[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:15 step:71505[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:15 step:71510[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:15 step:71515[D loss: 1.000016] [G loss: 1.000067]\n",
      "epoch:15 step:71520[D loss: 0.999986] [G loss: 0.999989]\n",
      "epoch:15 step:71525[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:15 step:71530[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:15 step:71535[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:15 step:71540[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:15 step:71545[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:15 step:71550[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:15 step:71555[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:15 step:71560[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:15 step:71565[D loss: 1.000003] [G loss: 1.000075]\n",
      "epoch:15 step:71570[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:15 step:71575[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:15 step:71580[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:15 step:71585[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:15 step:71590[D loss: 1.000025] [G loss: 1.000097]\n",
      "epoch:15 step:71595[D loss: 0.999939] [G loss: 1.000067]\n",
      "epoch:15 step:71600[D loss: 0.999961] [G loss: 1.000071]\n",
      "##############\n",
      "[2.47361497 2.11931635 2.29716362 4.089685   1.49621217 8.30958145\n",
      " 2.12927021 3.7526184  3.91319957 6.07626261]\n",
      "##########\n",
      "epoch:15 step:71605[D loss: 0.999992] [G loss: 1.000084]\n",
      "epoch:15 step:71610[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:15 step:71615[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:15 step:71620[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:15 step:71625[D loss: 1.000016] [G loss: 1.000003]\n",
      "epoch:15 step:71630[D loss: 0.999941] [G loss: 1.000075]\n",
      "epoch:15 step:71635[D loss: 1.000002] [G loss: 1.000067]\n",
      "epoch:15 step:71640[D loss: 1.000003] [G loss: 1.000014]\n",
      "epoch:15 step:71645[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:15 step:71650[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:15 step:71655[D loss: 0.999979] [G loss: 1.000018]\n",
      "epoch:15 step:71660[D loss: 0.999974] [G loss: 1.000029]\n",
      "epoch:15 step:71665[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:15 step:71670[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:15 step:71675[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:15 step:71680[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:15 step:71685[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:15 step:71690[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:15 step:71695[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:15 step:71700[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:15 step:71705[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:15 step:71710[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:15 step:71715[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:15 step:71720[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:15 step:71725[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:15 step:71730[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:15 step:71735[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:15 step:71740[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:15 step:71745[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:15 step:71750[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:15 step:71755[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:15 step:71760[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:15 step:71765[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:15 step:71770[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:15 step:71775[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:15 step:71780[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:15 step:71785[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:15 step:71790[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:15 step:71795[D loss: 0.999982] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:71800[D loss: 1.000004] [G loss: 1.000072]\n",
      "##############\n",
      "[2.55454833 2.12078751 2.17452879 4.06954292 1.49108856 7.87538206\n",
      " 2.07001575 3.77157454 3.87490254 5.3705125 ]\n",
      "##########\n",
      "epoch:15 step:71805[D loss: 0.999988] [G loss: 1.000124]\n",
      "epoch:15 step:71810[D loss: 0.999951] [G loss: 1.000066]\n",
      "epoch:15 step:71815[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:15 step:71820[D loss: 0.999997] [G loss: 1.000054]\n",
      "epoch:15 step:71825[D loss: 1.000030] [G loss: 0.999961]\n",
      "epoch:15 step:71830[D loss: 1.000030] [G loss: 1.000029]\n",
      "epoch:15 step:71835[D loss: 0.999932] [G loss: 1.000075]\n",
      "epoch:15 step:71840[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:15 step:71845[D loss: 0.999974] [G loss: 1.000013]\n",
      "epoch:15 step:71850[D loss: 1.000006] [G loss: 1.000066]\n",
      "epoch:15 step:71855[D loss: 1.000089] [G loss: 0.999991]\n",
      "epoch:15 step:71860[D loss: 0.999949] [G loss: 1.000031]\n",
      "epoch:15 step:71865[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:15 step:71870[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:15 step:71875[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:15 step:71880[D loss: 1.000114] [G loss: 0.999922]\n",
      "epoch:15 step:71885[D loss: 1.000118] [G loss: 0.999859]\n",
      "epoch:15 step:71890[D loss: 1.000016] [G loss: 1.000010]\n",
      "epoch:15 step:71895[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:15 step:71900[D loss: 0.999938] [G loss: 1.000094]\n",
      "epoch:15 step:71905[D loss: 0.999945] [G loss: 1.000071]\n",
      "epoch:15 step:71910[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:15 step:71915[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:15 step:71920[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:15 step:71925[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:15 step:71930[D loss: 0.999952] [G loss: 1.000039]\n",
      "epoch:15 step:71935[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:15 step:71940[D loss: 0.999973] [G loss: 1.000030]\n",
      "epoch:15 step:71945[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:15 step:71950[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:15 step:71955[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:15 step:71960[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:15 step:71965[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:15 step:71970[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:15 step:71975[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:15 step:71980[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:15 step:71985[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:15 step:71990[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:15 step:71995[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:15 step:72000[D loss: 0.999978] [G loss: 1.000053]\n",
      "##############\n",
      "[2.57302604 2.07615799 2.08707735 3.70603464 1.45046017 7.92506009\n",
      " 2.34453426 4.07989771 4.03903259 5.70237744]\n",
      "##########\n",
      "epoch:15 step:72005[D loss: 1.000025] [G loss: 1.000107]\n",
      "epoch:15 step:72010[D loss: 0.999955] [G loss: 1.000047]\n",
      "epoch:15 step:72015[D loss: 0.999996] [G loss: 1.000064]\n",
      "epoch:15 step:72020[D loss: 0.999968] [G loss: 1.000121]\n",
      "epoch:15 step:72025[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:15 step:72030[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:15 step:72035[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:15 step:72040[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:15 step:72045[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:15 step:72050[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:15 step:72055[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:15 step:72060[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:15 step:72065[D loss: 1.000037] [G loss: 1.000030]\n",
      "epoch:15 step:72070[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:15 step:72075[D loss: 1.000043] [G loss: 1.000004]\n",
      "epoch:15 step:72080[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:15 step:72085[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:15 step:72090[D loss: 1.000020] [G loss: 0.999995]\n",
      "epoch:15 step:72095[D loss: 1.000054] [G loss: 1.000004]\n",
      "epoch:15 step:72100[D loss: 0.999942] [G loss: 1.000082]\n",
      "epoch:15 step:72105[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:15 step:72110[D loss: 0.999972] [G loss: 1.000127]\n",
      "epoch:15 step:72115[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:15 step:72120[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:15 step:72125[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:15 step:72130[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:15 step:72135[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:15 step:72140[D loss: 0.999990] [G loss: 1.000018]\n",
      "epoch:15 step:72145[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:15 step:72150[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:15 step:72155[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:15 step:72160[D loss: 1.000045] [G loss: 0.999935]\n",
      "epoch:15 step:72165[D loss: 0.999991] [G loss: 1.000192]\n",
      "epoch:15 step:72170[D loss: 1.000025] [G loss: 0.999965]\n",
      "epoch:15 step:72175[D loss: 0.999976] [G loss: 1.000009]\n",
      "epoch:15 step:72180[D loss: 1.000019] [G loss: 1.000026]\n",
      "epoch:15 step:72185[D loss: 0.999952] [G loss: 1.000071]\n",
      "epoch:15 step:72190[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:15 step:72195[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:15 step:72200[D loss: 0.999978] [G loss: 1.000099]\n",
      "##############\n",
      "[2.63608646 2.18471915 2.18167013 3.55365044 1.49643713 7.60737528\n",
      " 2.40399279 3.93909292 4.09517008 5.22776245]\n",
      "##########\n",
      "epoch:15 step:72205[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:15 step:72210[D loss: 1.000058] [G loss: 0.999980]\n",
      "epoch:15 step:72215[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:15 step:72220[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:15 step:72225[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:15 step:72230[D loss: 1.000035] [G loss: 0.999974]\n",
      "epoch:15 step:72235[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:15 step:72240[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:15 step:72245[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:15 step:72250[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:15 step:72255[D loss: 1.000004] [G loss: 1.000041]\n",
      "epoch:15 step:72260[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:15 step:72265[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:15 step:72270[D loss: 1.000045] [G loss: 0.999912]\n",
      "epoch:15 step:72275[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:15 step:72280[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:15 step:72285[D loss: 0.999998] [G loss: 0.999985]\n",
      "epoch:15 step:72290[D loss: 1.000024] [G loss: 1.000010]\n",
      "epoch:15 step:72295[D loss: 0.999928] [G loss: 1.000143]\n",
      "epoch:15 step:72300[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:15 step:72305[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:15 step:72310[D loss: 1.000060] [G loss: 0.999956]\n",
      "epoch:15 step:72315[D loss: 0.999928] [G loss: 1.000073]\n",
      "epoch:15 step:72320[D loss: 1.000011] [G loss: 1.000006]\n",
      "epoch:15 step:72325[D loss: 1.000079] [G loss: 0.999948]\n",
      "epoch:15 step:72330[D loss: 0.999971] [G loss: 1.000039]\n",
      "epoch:15 step:72335[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:15 step:72340[D loss: 0.999990] [G loss: 1.000010]\n",
      "epoch:15 step:72345[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:15 step:72350[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:15 step:72355[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:15 step:72360[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:15 step:72365[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:15 step:72370[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:15 step:72375[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:15 step:72380[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:15 step:72385[D loss: 1.000037] [G loss: 0.999965]\n",
      "epoch:15 step:72390[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:15 step:72395[D loss: 1.000027] [G loss: 0.999980]\n",
      "epoch:15 step:72400[D loss: 0.999954] [G loss: 1.000106]\n",
      "##############\n",
      "[2.56232618 2.04838129 2.24101413 3.51044343 1.47175885 7.84740519\n",
      " 2.29082706 3.87738241 3.90933033 5.67773892]\n",
      "##########\n",
      "epoch:15 step:72405[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:15 step:72410[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:15 step:72415[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:15 step:72420[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:15 step:72425[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:15 step:72430[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:15 step:72435[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:15 step:72440[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:15 step:72445[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:15 step:72450[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:15 step:72455[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:15 step:72460[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:15 step:72465[D loss: 0.999962] [G loss: 1.000095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:72470[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:15 step:72475[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:15 step:72480[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:15 step:72485[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:15 step:72490[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:15 step:72495[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:15 step:72500[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:15 step:72505[D loss: 0.999946] [G loss: 1.000115]\n",
      "epoch:15 step:72510[D loss: 0.999966] [G loss: 1.000107]\n",
      "epoch:15 step:72515[D loss: 1.000025] [G loss: 1.000033]\n",
      "epoch:15 step:72520[D loss: 0.999945] [G loss: 1.000121]\n",
      "epoch:15 step:72525[D loss: 0.999966] [G loss: 1.000114]\n",
      "epoch:15 step:72530[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:15 step:72535[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:15 step:72540[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:15 step:72545[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:15 step:72550[D loss: 0.999932] [G loss: 1.000100]\n",
      "epoch:15 step:72555[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:15 step:72560[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:15 step:72565[D loss: 1.000021] [G loss: 1.000037]\n",
      "epoch:15 step:72570[D loss: 1.000079] [G loss: 1.000024]\n",
      "epoch:15 step:72575[D loss: 0.999917] [G loss: 1.000144]\n",
      "epoch:15 step:72580[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:15 step:72585[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:15 step:72590[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:15 step:72595[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:15 step:72600[D loss: 0.999932] [G loss: 1.000120]\n",
      "##############\n",
      "[2.58877259 2.11247361 2.24895187 3.80216402 1.50690866 7.12534832\n",
      " 2.4028072  3.91633765 3.99090231 5.2411971 ]\n",
      "##########\n",
      "epoch:15 step:72605[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:15 step:72610[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:15 step:72615[D loss: 1.000021] [G loss: 1.000004]\n",
      "epoch:15 step:72620[D loss: 0.999968] [G loss: 1.000118]\n",
      "epoch:15 step:72625[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:15 step:72630[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:15 step:72635[D loss: 0.999932] [G loss: 1.000138]\n",
      "epoch:15 step:72640[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:15 step:72645[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:15 step:72650[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:15 step:72655[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:15 step:72660[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:15 step:72665[D loss: 1.000024] [G loss: 0.999975]\n",
      "epoch:15 step:72670[D loss: 0.999946] [G loss: 1.000057]\n",
      "epoch:15 step:72675[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:15 step:72680[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:15 step:72685[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:15 step:72690[D loss: 1.000010] [G loss: 1.000017]\n",
      "epoch:15 step:72695[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:15 step:72700[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:15 step:72705[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:15 step:72710[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:15 step:72715[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:15 step:72720[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:15 step:72725[D loss: 0.999992] [G loss: 1.000086]\n",
      "epoch:15 step:72730[D loss: 0.999949] [G loss: 1.000116]\n",
      "epoch:15 step:72735[D loss: 0.999990] [G loss: 1.000089]\n",
      "epoch:15 step:72740[D loss: 1.000070] [G loss: 0.999985]\n",
      "epoch:15 step:72745[D loss: 1.000058] [G loss: 0.999954]\n",
      "epoch:15 step:72750[D loss: 0.999933] [G loss: 1.000130]\n",
      "epoch:15 step:72755[D loss: 1.000045] [G loss: 1.000152]\n",
      "epoch:15 step:72760[D loss: 0.999896] [G loss: 1.000258]\n",
      "epoch:15 step:72765[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:15 step:72770[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:15 step:72775[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:15 step:72780[D loss: 0.999913] [G loss: 1.000118]\n",
      "epoch:15 step:72785[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:15 step:72790[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:15 step:72795[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:15 step:72800[D loss: 1.000005] [G loss: 1.000007]\n",
      "##############\n",
      "[2.54167354 2.05955111 2.28451579 3.98571616 1.5267787  7.40055046\n",
      " 2.38843038 3.50716869 4.02094578 5.54863049]\n",
      "##########\n",
      "epoch:15 step:72805[D loss: 0.999945] [G loss: 1.000110]\n",
      "epoch:15 step:72810[D loss: 1.000048] [G loss: 1.000004]\n",
      "epoch:15 step:72815[D loss: 1.000004] [G loss: 1.000067]\n",
      "epoch:15 step:72820[D loss: 0.999911] [G loss: 1.000157]\n",
      "epoch:15 step:72825[D loss: 1.000026] [G loss: 1.000119]\n",
      "epoch:15 step:72830[D loss: 1.000036] [G loss: 0.999963]\n",
      "epoch:15 step:72835[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:15 step:72840[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:15 step:72845[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:15 step:72850[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:15 step:72855[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:15 step:72860[D loss: 1.000071] [G loss: 0.999972]\n",
      "epoch:15 step:72865[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:15 step:72870[D loss: 0.999944] [G loss: 1.000099]\n",
      "epoch:15 step:72875[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:15 step:72880[D loss: 0.999878] [G loss: 1.000229]\n",
      "epoch:15 step:72885[D loss: 0.999957] [G loss: 1.000109]\n",
      "epoch:15 step:72890[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:15 step:72895[D loss: 0.999962] [G loss: 1.000114]\n",
      "epoch:15 step:72900[D loss: 1.000001] [G loss: 0.999967]\n",
      "epoch:15 step:72905[D loss: 1.000019] [G loss: 0.999996]\n",
      "epoch:15 step:72910[D loss: 0.999972] [G loss: 1.000022]\n",
      "epoch:15 step:72915[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:15 step:72920[D loss: 1.000023] [G loss: 0.999971]\n",
      "epoch:15 step:72925[D loss: 0.999915] [G loss: 1.000099]\n",
      "epoch:15 step:72930[D loss: 1.000013] [G loss: 1.000008]\n",
      "epoch:15 step:72935[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:15 step:72940[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:15 step:72945[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:15 step:72950[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:15 step:72955[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:15 step:72960[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:15 step:72965[D loss: 0.999987] [G loss: 1.000108]\n",
      "epoch:15 step:72970[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:15 step:72975[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:15 step:72980[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:15 step:72985[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:15 step:72990[D loss: 1.000033] [G loss: 1.000034]\n",
      "epoch:15 step:72995[D loss: 1.000041] [G loss: 0.999939]\n",
      "epoch:15 step:73000[D loss: 0.999913] [G loss: 1.000169]\n",
      "##############\n",
      "[2.62430699 2.155011   2.29170128 4.09665051 1.55220608 8.59925371\n",
      " 2.51944162 3.83586398 4.00711519 6.50562527]\n",
      "##########\n",
      "epoch:15 step:73005[D loss: 1.000029] [G loss: 0.999962]\n",
      "epoch:15 step:73010[D loss: 0.999886] [G loss: 1.000132]\n",
      "epoch:15 step:73015[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:15 step:73020[D loss: 1.000009] [G loss: 1.000030]\n",
      "epoch:15 step:73025[D loss: 1.000035] [G loss: 1.000010]\n",
      "epoch:15 step:73030[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:15 step:73035[D loss: 0.999965] [G loss: 1.000007]\n",
      "epoch:15 step:73040[D loss: 1.000006] [G loss: 1.000078]\n",
      "epoch:15 step:73045[D loss: 0.999984] [G loss: 0.999983]\n",
      "epoch:15 step:73050[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:15 step:73055[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:15 step:73060[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:15 step:73065[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:15 step:73070[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:15 step:73075[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:15 step:73080[D loss: 0.999934] [G loss: 1.000128]\n",
      "epoch:15 step:73085[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:15 step:73090[D loss: 1.000029] [G loss: 1.000054]\n",
      "epoch:15 step:73095[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:15 step:73100[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:15 step:73105[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:15 step:73110[D loss: 0.999917] [G loss: 1.000076]\n",
      "epoch:15 step:73115[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:15 step:73120[D loss: 0.999966] [G loss: 1.000025]\n",
      "epoch:15 step:73125[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:15 step:73130[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:15 step:73135[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:15 step:73140[D loss: 1.000064] [G loss: 0.999972]\n",
      "epoch:15 step:73145[D loss: 1.000002] [G loss: 0.999937]\n",
      "epoch:15 step:73150[D loss: 1.000040] [G loss: 1.000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:73155[D loss: 1.000013] [G loss: 1.000037]\n",
      "epoch:15 step:73160[D loss: 0.999941] [G loss: 1.000069]\n",
      "epoch:15 step:73165[D loss: 1.000008] [G loss: 1.000077]\n",
      "epoch:15 step:73170[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:15 step:73175[D loss: 0.999966] [G loss: 1.000110]\n",
      "epoch:15 step:73180[D loss: 0.999984] [G loss: 1.000106]\n",
      "epoch:15 step:73185[D loss: 0.999995] [G loss: 1.000078]\n",
      "epoch:15 step:73190[D loss: 1.000038] [G loss: 0.999925]\n",
      "epoch:15 step:73195[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:15 step:73200[D loss: 1.000005] [G loss: 1.000011]\n",
      "##############\n",
      "[2.57496737 2.04658001 2.12636258 3.63305596 1.50077893 8.48337018\n",
      " 2.32398994 3.57198972 3.92166092 5.8246993 ]\n",
      "##########\n",
      "epoch:15 step:73205[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:15 step:73210[D loss: 1.000020] [G loss: 1.000017]\n",
      "epoch:15 step:73215[D loss: 1.000014] [G loss: 1.000043]\n",
      "epoch:15 step:73220[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:15 step:73225[D loss: 0.999939] [G loss: 1.000125]\n",
      "epoch:15 step:73230[D loss: 0.999950] [G loss: 1.000066]\n",
      "epoch:15 step:73235[D loss: 1.000025] [G loss: 0.999986]\n",
      "epoch:15 step:73240[D loss: 1.000062] [G loss: 0.999955]\n",
      "epoch:15 step:73245[D loss: 1.000064] [G loss: 0.999876]\n",
      "epoch:15 step:73250[D loss: 1.000027] [G loss: 1.000092]\n",
      "epoch:15 step:73255[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:15 step:73260[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:15 step:73265[D loss: 0.999939] [G loss: 1.000118]\n",
      "epoch:15 step:73270[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:15 step:73275[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:15 step:73280[D loss: 1.000043] [G loss: 0.999944]\n",
      "epoch:15 step:73285[D loss: 0.999959] [G loss: 1.000163]\n",
      "epoch:15 step:73290[D loss: 0.999969] [G loss: 1.000025]\n",
      "epoch:15 step:73295[D loss: 0.999968] [G loss: 1.000111]\n",
      "epoch:15 step:73300[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:15 step:73305[D loss: 0.999947] [G loss: 1.000130]\n",
      "epoch:15 step:73310[D loss: 1.000004] [G loss: 1.000026]\n",
      "epoch:15 step:73315[D loss: 0.999984] [G loss: 1.000095]\n",
      "epoch:15 step:73320[D loss: 1.000003] [G loss: 1.000141]\n",
      "epoch:15 step:73325[D loss: 0.999932] [G loss: 1.000114]\n",
      "epoch:15 step:73330[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:15 step:73335[D loss: 0.999994] [G loss: 1.000091]\n",
      "epoch:15 step:73340[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:15 step:73345[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:15 step:73350[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:15 step:73355[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:15 step:73360[D loss: 1.000051] [G loss: 0.999981]\n",
      "epoch:15 step:73365[D loss: 0.999954] [G loss: 1.000157]\n",
      "epoch:15 step:73370[D loss: 0.999922] [G loss: 1.000088]\n",
      "epoch:15 step:73375[D loss: 1.000009] [G loss: 1.000081]\n",
      "epoch:15 step:73380[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:15 step:73385[D loss: 1.000001] [G loss: 1.000081]\n",
      "epoch:15 step:73390[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:15 step:73395[D loss: 1.000007] [G loss: 1.000034]\n",
      "epoch:15 step:73400[D loss: 1.000036] [G loss: 0.999988]\n",
      "##############\n",
      "[2.59707494 2.14153182 2.29961912 4.00555309 1.52665938 8.43381112\n",
      " 2.23799444 3.83570754 4.02422276 7.14868929]\n",
      "##########\n",
      "epoch:15 step:73405[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:15 step:73410[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:15 step:73415[D loss: 0.999989] [G loss: 0.999993]\n",
      "epoch:15 step:73420[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:15 step:73425[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:15 step:73430[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:15 step:73435[D loss: 1.000003] [G loss: 1.000104]\n",
      "epoch:15 step:73440[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:15 step:73445[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:15 step:73450[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:15 step:73455[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:15 step:73460[D loss: 0.999994] [G loss: 1.000142]\n",
      "epoch:15 step:73465[D loss: 0.999973] [G loss: 1.000027]\n",
      "epoch:15 step:73470[D loss: 0.999949] [G loss: 1.000062]\n",
      "epoch:15 step:73475[D loss: 1.000001] [G loss: 1.000073]\n",
      "epoch:15 step:73480[D loss: 0.999963] [G loss: 1.000115]\n",
      "epoch:15 step:73485[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:15 step:73490[D loss: 0.999986] [G loss: 1.000013]\n",
      "epoch:15 step:73495[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:15 step:73500[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:15 step:73505[D loss: 1.000080] [G loss: 0.999895]\n",
      "epoch:15 step:73510[D loss: 0.999935] [G loss: 1.000066]\n",
      "epoch:15 step:73515[D loss: 0.999955] [G loss: 1.000108]\n",
      "epoch:15 step:73520[D loss: 1.000069] [G loss: 0.999948]\n",
      "epoch:15 step:73525[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:15 step:73530[D loss: 0.999996] [G loss: 1.000082]\n",
      "epoch:15 step:73535[D loss: 0.999934] [G loss: 1.000115]\n",
      "epoch:15 step:73540[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:15 step:73545[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:15 step:73550[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:15 step:73555[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:15 step:73560[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:15 step:73565[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:15 step:73570[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:15 step:73575[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:15 step:73580[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:15 step:73585[D loss: 0.999987] [G loss: 1.000095]\n",
      "epoch:15 step:73590[D loss: 1.000073] [G loss: 0.999897]\n",
      "epoch:15 step:73595[D loss: 0.999925] [G loss: 1.000097]\n",
      "epoch:15 step:73600[D loss: 1.000010] [G loss: 0.999985]\n",
      "##############\n",
      "[2.55787943 2.12480072 2.21989704 3.63440401 1.47013051 7.43680099\n",
      " 2.07699861 3.68471166 3.90170666 5.165795  ]\n",
      "##########\n",
      "epoch:15 step:73605[D loss: 1.000016] [G loss: 0.999983]\n",
      "epoch:15 step:73610[D loss: 0.999956] [G loss: 1.000051]\n",
      "epoch:15 step:73615[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:15 step:73620[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:15 step:73625[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:15 step:73630[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:15 step:73635[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:15 step:73640[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:15 step:73645[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:15 step:73650[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:15 step:73655[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:15 step:73660[D loss: 0.999943] [G loss: 1.000123]\n",
      "epoch:15 step:73665[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:15 step:73670[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:15 step:73675[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:15 step:73680[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:15 step:73685[D loss: 0.999982] [G loss: 1.000087]\n",
      "epoch:15 step:73690[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:15 step:73695[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:15 step:73700[D loss: 1.000004] [G loss: 1.000048]\n",
      "epoch:15 step:73705[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:15 step:73710[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:15 step:73715[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:15 step:73720[D loss: 0.999968] [G loss: 1.000119]\n",
      "epoch:15 step:73725[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:15 step:73730[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:15 step:73735[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:15 step:73740[D loss: 1.000001] [G loss: 1.000025]\n",
      "epoch:15 step:73745[D loss: 0.999960] [G loss: 1.000108]\n",
      "epoch:15 step:73750[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:15 step:73755[D loss: 0.999946] [G loss: 1.000069]\n",
      "epoch:15 step:73760[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:15 step:73765[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:15 step:73770[D loss: 1.000012] [G loss: 1.000017]\n",
      "epoch:15 step:73775[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:15 step:73780[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:15 step:73785[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:15 step:73790[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:15 step:73795[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:15 step:73800[D loss: 0.999989] [G loss: 1.000038]\n",
      "##############\n",
      "[2.59482891 1.99206293 2.31472923 3.52847791 1.51054966 7.67520785\n",
      " 2.30189334 3.86771924 3.96387764 5.70274577]\n",
      "##########\n",
      "epoch:15 step:73805[D loss: 0.999960] [G loss: 1.000108]\n",
      "epoch:15 step:73810[D loss: 0.999950] [G loss: 1.000109]\n",
      "epoch:15 step:73815[D loss: 0.999964] [G loss: 1.000026]\n",
      "epoch:15 step:73820[D loss: 1.000011] [G loss: 1.000049]\n",
      "epoch:15 step:73825[D loss: 1.000018] [G loss: 1.000055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:73830[D loss: 1.000010] [G loss: 1.000033]\n",
      "epoch:15 step:73835[D loss: 0.999940] [G loss: 1.000075]\n",
      "epoch:15 step:73840[D loss: 1.000008] [G loss: 1.000013]\n",
      "epoch:15 step:73845[D loss: 1.000077] [G loss: 0.999973]\n",
      "epoch:15 step:73850[D loss: 0.999938] [G loss: 1.000105]\n",
      "epoch:15 step:73855[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:15 step:73860[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:15 step:73865[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:15 step:73870[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:15 step:73875[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:15 step:73880[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:15 step:73885[D loss: 1.000071] [G loss: 0.999937]\n",
      "epoch:15 step:73890[D loss: 0.999947] [G loss: 1.000133]\n",
      "epoch:15 step:73895[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:15 step:73900[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:15 step:73905[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:15 step:73910[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:15 step:73915[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:15 step:73920[D loss: 0.999982] [G loss: 1.000020]\n",
      "epoch:15 step:73925[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:15 step:73930[D loss: 1.000022] [G loss: 1.000001]\n",
      "epoch:15 step:73935[D loss: 0.999983] [G loss: 1.000004]\n",
      "epoch:15 step:73940[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:15 step:73945[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:15 step:73950[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:15 step:73955[D loss: 0.999980] [G loss: 1.000094]\n",
      "epoch:15 step:73960[D loss: 1.000032] [G loss: 1.000096]\n",
      "epoch:15 step:73965[D loss: 1.000037] [G loss: 0.999931]\n",
      "epoch:15 step:73970[D loss: 1.000022] [G loss: 1.000081]\n",
      "epoch:15 step:73975[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:15 step:73980[D loss: 0.999952] [G loss: 1.000062]\n",
      "epoch:15 step:73985[D loss: 0.999990] [G loss: 1.000117]\n",
      "epoch:15 step:73990[D loss: 0.999948] [G loss: 1.000111]\n",
      "epoch:15 step:73995[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:15 step:74000[D loss: 0.999974] [G loss: 1.000069]\n",
      "##############\n",
      "[2.63041446 2.16573558 2.30323466 4.0391705  1.51424593 7.73609614\n",
      " 2.36787268 3.83160165 4.05364492 7.14868929]\n",
      "##########\n",
      "epoch:15 step:74005[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:15 step:74010[D loss: 0.999995] [G loss: 1.000053]\n",
      "epoch:15 step:74015[D loss: 1.000029] [G loss: 1.000004]\n",
      "epoch:15 step:74020[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:15 step:74025[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:15 step:74030[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:15 step:74035[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:15 step:74040[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:15 step:74045[D loss: 1.000069] [G loss: 0.999995]\n",
      "epoch:15 step:74050[D loss: 1.000007] [G loss: 1.000019]\n",
      "epoch:15 step:74055[D loss: 0.999940] [G loss: 1.000056]\n",
      "epoch:15 step:74060[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:15 step:74065[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:15 step:74070[D loss: 0.999923] [G loss: 1.000114]\n",
      "epoch:15 step:74075[D loss: 1.000013] [G loss: 1.000018]\n",
      "epoch:15 step:74080[D loss: 1.000009] [G loss: 0.999992]\n",
      "epoch:15 step:74085[D loss: 1.000098] [G loss: 0.999871]\n",
      "epoch:15 step:74090[D loss: 0.999937] [G loss: 1.000087]\n",
      "epoch:15 step:74095[D loss: 0.999989] [G loss: 1.000031]\n",
      "epoch:15 step:74100[D loss: 0.999948] [G loss: 1.000082]\n",
      "epoch:15 step:74105[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:15 step:74110[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:15 step:74115[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:15 step:74120[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:15 step:74125[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:15 step:74130[D loss: 1.000024] [G loss: 0.999985]\n",
      "epoch:15 step:74135[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:15 step:74140[D loss: 1.000013] [G loss: 0.999979]\n",
      "epoch:15 step:74145[D loss: 0.999982] [G loss: 1.000116]\n",
      "epoch:15 step:74150[D loss: 0.999938] [G loss: 1.000069]\n",
      "epoch:15 step:74155[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:15 step:74160[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:15 step:74165[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:15 step:74170[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:15 step:74175[D loss: 1.000024] [G loss: 0.999931]\n",
      "epoch:15 step:74180[D loss: 0.999934] [G loss: 1.000058]\n",
      "epoch:15 step:74185[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:15 step:74190[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:15 step:74195[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:15 step:74200[D loss: 0.999965] [G loss: 1.000070]\n",
      "##############\n",
      "[2.53758205 2.00809171 2.13147377 4.09610457 1.36601708 9.27426719\n",
      " 2.22128617 3.7141973  3.85092868 5.21063043]\n",
      "##########\n",
      "epoch:15 step:74205[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:15 step:74210[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:15 step:74215[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:15 step:74220[D loss: 0.999972] [G loss: 1.000130]\n",
      "epoch:15 step:74225[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:15 step:74230[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:15 step:74235[D loss: 0.999988] [G loss: 1.000001]\n",
      "epoch:15 step:74240[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:15 step:74245[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:15 step:74250[D loss: 0.999932] [G loss: 1.000112]\n",
      "epoch:15 step:74255[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:15 step:74260[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:15 step:74265[D loss: 0.999990] [G loss: 1.000103]\n",
      "epoch:15 step:74270[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:15 step:74275[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:15 step:74280[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:15 step:74285[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:15 step:74290[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:15 step:74295[D loss: 0.999991] [G loss: 1.000024]\n",
      "epoch:15 step:74300[D loss: 1.000015] [G loss: 1.000006]\n",
      "epoch:15 step:74305[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:15 step:74310[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:15 step:74315[D loss: 1.000017] [G loss: 1.000068]\n",
      "epoch:15 step:74320[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:15 step:74325[D loss: 0.999943] [G loss: 1.000082]\n",
      "epoch:15 step:74330[D loss: 0.999988] [G loss: 1.000084]\n",
      "epoch:15 step:74335[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:15 step:74340[D loss: 0.999981] [G loss: 1.000024]\n",
      "epoch:15 step:74345[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:15 step:74350[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:15 step:74355[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:15 step:74360[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:15 step:74365[D loss: 0.999963] [G loss: 1.000109]\n",
      "epoch:15 step:74370[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:15 step:74375[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:15 step:74380[D loss: 0.999992] [G loss: 1.000016]\n",
      "epoch:15 step:74385[D loss: 0.999960] [G loss: 1.000111]\n",
      "epoch:15 step:74390[D loss: 0.999987] [G loss: 1.000013]\n",
      "epoch:15 step:74395[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:15 step:74400[D loss: 0.999969] [G loss: 1.000054]\n",
      "##############\n",
      "[2.5501936  2.18941373 2.31418804 3.61956245 1.47914631 7.65596175\n",
      " 2.31821981 3.69424498 4.01948428 6.28105759]\n",
      "##########\n",
      "epoch:15 step:74405[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:15 step:74410[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:15 step:74415[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:15 step:74420[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:15 step:74425[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:15 step:74430[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:15 step:74435[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:15 step:74440[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:15 step:74445[D loss: 1.000048] [G loss: 0.999982]\n",
      "epoch:15 step:74450[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:15 step:74455[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:15 step:74460[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:15 step:74465[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:15 step:74470[D loss: 1.000004] [G loss: 1.000071]\n",
      "epoch:15 step:74475[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:15 step:74480[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:15 step:74485[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:15 step:74490[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:15 step:74495[D loss: 1.000010] [G loss: 1.000015]\n",
      "epoch:15 step:74500[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:15 step:74505[D loss: 0.999943] [G loss: 1.000086]\n",
      "epoch:15 step:74510[D loss: 0.999984] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:74515[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:15 step:74520[D loss: 0.999930] [G loss: 1.000141]\n",
      "epoch:15 step:74525[D loss: 0.999989] [G loss: 1.000008]\n",
      "epoch:15 step:74530[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:15 step:74535[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:15 step:74540[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:15 step:74545[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:15 step:74550[D loss: 1.000001] [G loss: 1.000005]\n",
      "epoch:15 step:74555[D loss: 1.000006] [G loss: 1.000068]\n",
      "epoch:15 step:74560[D loss: 0.999949] [G loss: 1.000142]\n",
      "epoch:15 step:74565[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:15 step:74570[D loss: 1.000050] [G loss: 1.000006]\n",
      "epoch:15 step:74575[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:15 step:74580[D loss: 0.999951] [G loss: 1.000062]\n",
      "epoch:15 step:74585[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:15 step:74590[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:15 step:74595[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:15 step:74600[D loss: 0.999978] [G loss: 1.000048]\n",
      "##############\n",
      "[2.56495909 2.18973069 2.09835226 3.76194292 1.44003762 8.37212169\n",
      " 2.29964146 3.66672646 3.96782587 5.97992157]\n",
      "##########\n",
      "epoch:15 step:74605[D loss: 1.000020] [G loss: 0.999970]\n",
      "epoch:15 step:74610[D loss: 1.000037] [G loss: 1.000044]\n",
      "epoch:15 step:74615[D loss: 1.000014] [G loss: 1.000025]\n",
      "epoch:15 step:74620[D loss: 0.999958] [G loss: 1.000151]\n",
      "epoch:15 step:74625[D loss: 1.000073] [G loss: 0.999997]\n",
      "epoch:15 step:74630[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:15 step:74635[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:15 step:74640[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:15 step:74645[D loss: 0.999980] [G loss: 1.000021]\n",
      "epoch:15 step:74650[D loss: 0.999972] [G loss: 1.000106]\n",
      "epoch:15 step:74655[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:15 step:74660[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:15 step:74665[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:15 step:74670[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:15 step:74675[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:15 step:74680[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:15 step:74685[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:15 step:74690[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:15 step:74695[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:15 step:74700[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:15 step:74705[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:15 step:74710[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:15 step:74715[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:15 step:74720[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:15 step:74725[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:15 step:74730[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:15 step:74735[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:15 step:74740[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:15 step:74745[D loss: 1.000019] [G loss: 0.999979]\n",
      "epoch:15 step:74750[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:15 step:74755[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:15 step:74760[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:15 step:74765[D loss: 0.999972] [G loss: 1.000041]\n",
      "epoch:15 step:74770[D loss: 0.999960] [G loss: 1.000097]\n",
      "epoch:15 step:74775[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:15 step:74780[D loss: 1.000026] [G loss: 1.000001]\n",
      "epoch:15 step:74785[D loss: 0.999935] [G loss: 1.000116]\n",
      "epoch:15 step:74790[D loss: 0.999994] [G loss: 1.000026]\n",
      "epoch:15 step:74795[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:15 step:74800[D loss: 0.999989] [G loss: 1.000073]\n",
      "##############\n",
      "[2.52688218 2.03924851 2.20829654 3.48554114 1.34131367 8.20241808\n",
      " 2.18394472 3.79087875 3.96622251 5.57049251]\n",
      "##########\n",
      "epoch:15 step:74805[D loss: 1.000029] [G loss: 0.999974]\n",
      "epoch:15 step:74810[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:15 step:74815[D loss: 1.000015] [G loss: 1.000038]\n",
      "epoch:15 step:74820[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:15 step:74825[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:15 step:74830[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:15 step:74835[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:15 step:74840[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:15 step:74845[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:15 step:74850[D loss: 1.000003] [G loss: 1.000056]\n",
      "epoch:15 step:74855[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:15 step:74860[D loss: 1.000031] [G loss: 1.000081]\n",
      "epoch:15 step:74865[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:15 step:74870[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:15 step:74875[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:15 step:74880[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:15 step:74885[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:15 step:74890[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:15 step:74895[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:15 step:74900[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:15 step:74905[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:15 step:74910[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:15 step:74915[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:15 step:74920[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:15 step:74925[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:15 step:74930[D loss: 1.000018] [G loss: 1.000015]\n",
      "epoch:15 step:74935[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:15 step:74940[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:15 step:74945[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:15 step:74950[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:15 step:74955[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:15 step:74960[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:16 step:74965[D loss: 1.000025] [G loss: 1.000042]\n",
      "epoch:16 step:74970[D loss: 0.999954] [G loss: 1.000115]\n",
      "epoch:16 step:74975[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:16 step:74980[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:16 step:74985[D loss: 0.999960] [G loss: 1.000063]\n",
      "epoch:16 step:74990[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:16 step:74995[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:16 step:75000[D loss: 0.999964] [G loss: 1.000054]\n",
      "##############\n",
      "[2.57629897 2.11830539 2.17036541 4.21467415 1.45951531 7.78342719\n",
      " 2.34986186 3.81164984 3.96562998 6.09466173]\n",
      "##########\n",
      "epoch:16 step:75005[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:16 step:75010[D loss: 1.000081] [G loss: 0.999935]\n",
      "epoch:16 step:75015[D loss: 0.999970] [G loss: 1.000140]\n",
      "epoch:16 step:75020[D loss: 0.999955] [G loss: 1.000106]\n",
      "epoch:16 step:75025[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:16 step:75030[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:16 step:75035[D loss: 0.999947] [G loss: 1.000080]\n",
      "epoch:16 step:75040[D loss: 0.999958] [G loss: 1.000097]\n",
      "epoch:16 step:75045[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:16 step:75050[D loss: 1.000011] [G loss: 0.999994]\n",
      "epoch:16 step:75055[D loss: 0.999928] [G loss: 1.000132]\n",
      "epoch:16 step:75060[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:16 step:75065[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:16 step:75070[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:16 step:75075[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:16 step:75080[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:16 step:75085[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:16 step:75090[D loss: 0.999963] [G loss: 1.000127]\n",
      "epoch:16 step:75095[D loss: 0.999955] [G loss: 1.000144]\n",
      "epoch:16 step:75100[D loss: 0.999945] [G loss: 1.000082]\n",
      "epoch:16 step:75105[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:16 step:75110[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:16 step:75115[D loss: 0.999980] [G loss: 1.000101]\n",
      "epoch:16 step:75120[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:16 step:75125[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:16 step:75130[D loss: 1.000004] [G loss: 1.000046]\n",
      "epoch:16 step:75135[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:16 step:75140[D loss: 0.999956] [G loss: 1.000112]\n",
      "epoch:16 step:75145[D loss: 1.000025] [G loss: 1.000026]\n",
      "epoch:16 step:75150[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:16 step:75155[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:16 step:75160[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:16 step:75165[D loss: 1.000038] [G loss: 0.999979]\n",
      "epoch:16 step:75170[D loss: 1.000027] [G loss: 0.999936]\n",
      "epoch:16 step:75175[D loss: 1.000054] [G loss: 0.999876]\n",
      "epoch:16 step:75180[D loss: 0.999996] [G loss: 0.999972]\n",
      "epoch:16 step:75185[D loss: 0.999926] [G loss: 1.000130]\n",
      "epoch:16 step:75190[D loss: 0.999950] [G loss: 1.000089]\n",
      "epoch:16 step:75195[D loss: 0.999971] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:75200[D loss: 0.999989] [G loss: 1.000047]\n",
      "##############\n",
      "[2.65398538 2.17197079 2.2667775  3.84086551 1.5574952  6.9794918\n",
      " 2.45738696 3.89778642 4.13275702 5.04637482]\n",
      "##########\n",
      "epoch:16 step:75205[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:16 step:75210[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:16 step:75215[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:16 step:75220[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:16 step:75225[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:16 step:75230[D loss: 1.000048] [G loss: 0.999948]\n",
      "epoch:16 step:75235[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:16 step:75240[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:16 step:75245[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:16 step:75250[D loss: 0.999998] [G loss: 1.000072]\n",
      "epoch:16 step:75255[D loss: 0.999976] [G loss: 1.000114]\n",
      "epoch:16 step:75260[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:16 step:75265[D loss: 0.999974] [G loss: 1.000030]\n",
      "epoch:16 step:75270[D loss: 1.000022] [G loss: 0.999991]\n",
      "epoch:16 step:75275[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:16 step:75280[D loss: 0.999938] [G loss: 1.000127]\n",
      "epoch:16 step:75285[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:16 step:75290[D loss: 0.999998] [G loss: 1.000016]\n",
      "epoch:16 step:75295[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:16 step:75300[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:16 step:75305[D loss: 1.000053] [G loss: 0.999983]\n",
      "epoch:16 step:75310[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:16 step:75315[D loss: 1.000006] [G loss: 1.000028]\n",
      "epoch:16 step:75320[D loss: 1.000005] [G loss: 1.000096]\n",
      "epoch:16 step:75325[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:16 step:75330[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:16 step:75335[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:16 step:75340[D loss: 0.999959] [G loss: 1.000053]\n",
      "epoch:16 step:75345[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:16 step:75350[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:16 step:75355[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:16 step:75360[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:16 step:75365[D loss: 1.000014] [G loss: 1.000019]\n",
      "epoch:16 step:75370[D loss: 0.999948] [G loss: 1.000077]\n",
      "epoch:16 step:75375[D loss: 0.999937] [G loss: 1.000088]\n",
      "epoch:16 step:75380[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:16 step:75385[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:16 step:75390[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:16 step:75395[D loss: 1.000002] [G loss: 1.000010]\n",
      "epoch:16 step:75400[D loss: 0.999944] [G loss: 1.000106]\n",
      "##############\n",
      "[2.57632513 2.0757859  2.16188986 3.9587518  1.53150859 7.65879493\n",
      " 2.31130429 3.82758572 4.06645097 5.62080004]\n",
      "##########\n",
      "epoch:16 step:75405[D loss: 0.999998] [G loss: 1.000080]\n",
      "epoch:16 step:75410[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:16 step:75415[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:16 step:75420[D loss: 0.999951] [G loss: 1.000060]\n",
      "epoch:16 step:75425[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:16 step:75430[D loss: 0.999997] [G loss: 0.999989]\n",
      "epoch:16 step:75435[D loss: 1.000026] [G loss: 1.000030]\n",
      "epoch:16 step:75440[D loss: 1.000021] [G loss: 1.000013]\n",
      "epoch:16 step:75445[D loss: 1.000041] [G loss: 0.999949]\n",
      "epoch:16 step:75450[D loss: 1.000034] [G loss: 1.000041]\n",
      "epoch:16 step:75455[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:16 step:75460[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:16 step:75465[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:16 step:75470[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:16 step:75475[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:16 step:75480[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:16 step:75485[D loss: 0.999992] [G loss: 1.000021]\n",
      "epoch:16 step:75490[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:16 step:75495[D loss: 1.000029] [G loss: 0.999970]\n",
      "epoch:16 step:75500[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:16 step:75505[D loss: 0.999936] [G loss: 1.000088]\n",
      "epoch:16 step:75510[D loss: 1.000002] [G loss: 1.000034]\n",
      "epoch:16 step:75515[D loss: 0.999938] [G loss: 1.000082]\n",
      "epoch:16 step:75520[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:16 step:75525[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:16 step:75530[D loss: 0.999944] [G loss: 1.000077]\n",
      "epoch:16 step:75535[D loss: 1.000004] [G loss: 1.000033]\n",
      "epoch:16 step:75540[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:16 step:75545[D loss: 1.000025] [G loss: 1.000015]\n",
      "epoch:16 step:75550[D loss: 1.000003] [G loss: 1.000083]\n",
      "epoch:16 step:75555[D loss: 1.000029] [G loss: 1.000072]\n",
      "epoch:16 step:75560[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:16 step:75565[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:16 step:75570[D loss: 0.999972] [G loss: 1.000107]\n",
      "epoch:16 step:75575[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:16 step:75580[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:16 step:75585[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:16 step:75590[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:16 step:75595[D loss: 0.999999] [G loss: 1.000068]\n",
      "epoch:16 step:75600[D loss: 0.999967] [G loss: 1.000059]\n",
      "##############\n",
      "[2.56565378 2.0750034  2.12201863 3.7475462  1.45038786 7.88498899\n",
      " 2.22464068 3.98755747 3.85723442 5.32025742]\n",
      "##########\n",
      "epoch:16 step:75605[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:16 step:75610[D loss: 0.999936] [G loss: 1.000117]\n",
      "epoch:16 step:75615[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:16 step:75620[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:16 step:75625[D loss: 1.000006] [G loss: 1.000033]\n",
      "epoch:16 step:75630[D loss: 1.000001] [G loss: 0.999986]\n",
      "epoch:16 step:75635[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:16 step:75640[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:16 step:75645[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:16 step:75650[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:16 step:75655[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:16 step:75660[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:16 step:75665[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:16 step:75670[D loss: 0.999956] [G loss: 1.000113]\n",
      "epoch:16 step:75675[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:16 step:75680[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:16 step:75685[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:16 step:75690[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:16 step:75695[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:16 step:75700[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:16 step:75705[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:16 step:75710[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:16 step:75715[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:16 step:75720[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:16 step:75725[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:16 step:75730[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:16 step:75735[D loss: 0.999982] [G loss: 1.000106]\n",
      "epoch:16 step:75740[D loss: 0.999993] [G loss: 1.000094]\n",
      "epoch:16 step:75745[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:16 step:75750[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:16 step:75755[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:16 step:75760[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:16 step:75765[D loss: 1.000013] [G loss: 1.000057]\n",
      "epoch:16 step:75770[D loss: 1.000061] [G loss: 0.999947]\n",
      "epoch:16 step:75775[D loss: 0.999983] [G loss: 1.000001]\n",
      "epoch:16 step:75780[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:16 step:75785[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:16 step:75790[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:16 step:75795[D loss: 0.999975] [G loss: 0.999998]\n",
      "epoch:16 step:75800[D loss: 1.000019] [G loss: 1.000026]\n",
      "##############\n",
      "[2.60538643 2.1358311  2.26621044 4.04674542 1.55811096 7.62127342\n",
      " 2.43507055 3.77038765 4.08654904 5.87525453]\n",
      "##########\n",
      "epoch:16 step:75805[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:16 step:75810[D loss: 0.999995] [G loss: 1.000030]\n",
      "epoch:16 step:75815[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:16 step:75820[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:16 step:75825[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:16 step:75830[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:16 step:75835[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:16 step:75840[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:16 step:75845[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:16 step:75850[D loss: 1.000006] [G loss: 1.000095]\n",
      "epoch:16 step:75855[D loss: 1.000020] [G loss: 1.000049]\n",
      "epoch:16 step:75860[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:16 step:75865[D loss: 0.999944] [G loss: 1.000144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:75870[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:16 step:75875[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:16 step:75880[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:16 step:75885[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:16 step:75890[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:16 step:75895[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:16 step:75900[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:16 step:75905[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:16 step:75910[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:16 step:75915[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:16 step:75920[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:16 step:75925[D loss: 1.000001] [G loss: 1.000080]\n",
      "epoch:16 step:75930[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:16 step:75935[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:16 step:75940[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:16 step:75945[D loss: 1.000062] [G loss: 0.999962]\n",
      "epoch:16 step:75950[D loss: 1.000002] [G loss: 1.000086]\n",
      "epoch:16 step:75955[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:16 step:75960[D loss: 1.000016] [G loss: 1.000095]\n",
      "epoch:16 step:75965[D loss: 0.999963] [G loss: 1.000151]\n",
      "epoch:16 step:75970[D loss: 0.999972] [G loss: 1.000119]\n",
      "epoch:16 step:75975[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:16 step:75980[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:16 step:75985[D loss: 0.999997] [G loss: 1.000017]\n",
      "epoch:16 step:75990[D loss: 0.999999] [G loss: 0.999995]\n",
      "epoch:16 step:75995[D loss: 1.000085] [G loss: 0.999901]\n",
      "epoch:16 step:76000[D loss: 0.999967] [G loss: 1.000003]\n",
      "##############\n",
      "[2.61089573 2.10079587 2.14225225 3.66780898 1.55958017 7.63051928\n",
      " 2.37622314 3.99474478 3.92824879 5.03716404]\n",
      "##########\n",
      "epoch:16 step:76005[D loss: 1.000020] [G loss: 1.000064]\n",
      "epoch:16 step:76010[D loss: 0.999952] [G loss: 1.000085]\n",
      "epoch:16 step:76015[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:16 step:76020[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:16 step:76025[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:16 step:76030[D loss: 1.000000] [G loss: 1.000074]\n",
      "epoch:16 step:76035[D loss: 0.999943] [G loss: 1.000168]\n",
      "epoch:16 step:76040[D loss: 1.000018] [G loss: 1.000020]\n",
      "epoch:16 step:76045[D loss: 1.000065] [G loss: 1.000064]\n",
      "epoch:16 step:76050[D loss: 0.999873] [G loss: 1.000223]\n",
      "epoch:16 step:76055[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:16 step:76060[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:16 step:76065[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:16 step:76070[D loss: 1.000013] [G loss: 1.000006]\n",
      "epoch:16 step:76075[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:16 step:76080[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:16 step:76085[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:16 step:76090[D loss: 1.000049] [G loss: 0.999980]\n",
      "epoch:16 step:76095[D loss: 1.000031] [G loss: 1.000023]\n",
      "epoch:16 step:76100[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:16 step:76105[D loss: 0.999952] [G loss: 1.000085]\n",
      "epoch:16 step:76110[D loss: 1.000080] [G loss: 0.999973]\n",
      "epoch:16 step:76115[D loss: 0.999896] [G loss: 1.000214]\n",
      "epoch:16 step:76120[D loss: 0.999923] [G loss: 1.000138]\n",
      "epoch:16 step:76125[D loss: 0.999973] [G loss: 1.000134]\n",
      "epoch:16 step:76130[D loss: 1.000004] [G loss: 1.000125]\n",
      "epoch:16 step:76135[D loss: 0.999960] [G loss: 1.000173]\n",
      "epoch:16 step:76140[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:16 step:76145[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:16 step:76150[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:16 step:76155[D loss: 0.999961] [G loss: 1.000115]\n",
      "epoch:16 step:76160[D loss: 1.000021] [G loss: 0.999970]\n",
      "epoch:16 step:76165[D loss: 1.000037] [G loss: 1.000000]\n",
      "epoch:16 step:76170[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:16 step:76175[D loss: 0.999951] [G loss: 1.000098]\n",
      "epoch:16 step:76180[D loss: 0.999991] [G loss: 1.000106]\n",
      "epoch:16 step:76185[D loss: 1.000021] [G loss: 0.999971]\n",
      "epoch:16 step:76190[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:16 step:76195[D loss: 0.999931] [G loss: 1.000093]\n",
      "epoch:16 step:76200[D loss: 0.999962] [G loss: 1.000125]\n",
      "##############\n",
      "[2.60200443 2.08487094 2.28897496 3.83851687 1.55869622 7.3199932\n",
      " 2.38371408 3.60762761 3.99103608 5.74350793]\n",
      "##########\n",
      "epoch:16 step:76205[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:16 step:76210[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:16 step:76215[D loss: 0.999997] [G loss: 1.000060]\n",
      "epoch:16 step:76220[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:16 step:76225[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:16 step:76230[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:16 step:76235[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:16 step:76240[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:16 step:76245[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:16 step:76250[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:16 step:76255[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:16 step:76260[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:16 step:76265[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:16 step:76270[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:16 step:76275[D loss: 1.000036] [G loss: 1.000098]\n",
      "epoch:16 step:76280[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:16 step:76285[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:16 step:76290[D loss: 1.000060] [G loss: 0.999976]\n",
      "epoch:16 step:76295[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:16 step:76300[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:16 step:76305[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:16 step:76310[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:16 step:76315[D loss: 0.999950] [G loss: 1.000083]\n",
      "epoch:16 step:76320[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:16 step:76325[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:16 step:76330[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:16 step:76335[D loss: 1.000005] [G loss: 1.000052]\n",
      "epoch:16 step:76340[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:16 step:76345[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:16 step:76350[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:16 step:76355[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:16 step:76360[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:16 step:76365[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:16 step:76370[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:16 step:76375[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:16 step:76380[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:16 step:76385[D loss: 1.000002] [G loss: 1.000057]\n",
      "epoch:16 step:76390[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:16 step:76395[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:16 step:76400[D loss: 0.999983] [G loss: 1.000076]\n",
      "##############\n",
      "[2.61481073 2.01978682 2.26318424 3.8631996  1.50022781 7.93233512\n",
      " 2.29623671 3.76574901 3.92808665 5.25123781]\n",
      "##########\n",
      "epoch:16 step:76405[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:16 step:76410[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:16 step:76415[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:16 step:76420[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:16 step:76425[D loss: 0.999997] [G loss: 1.000010]\n",
      "epoch:16 step:76430[D loss: 0.999950] [G loss: 1.000071]\n",
      "epoch:16 step:76435[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:16 step:76440[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:16 step:76445[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:16 step:76450[D loss: 1.000008] [G loss: 1.000010]\n",
      "epoch:16 step:76455[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:16 step:76460[D loss: 1.000012] [G loss: 1.000014]\n",
      "epoch:16 step:76465[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:16 step:76470[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:16 step:76475[D loss: 1.000029] [G loss: 1.000019]\n",
      "epoch:16 step:76480[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:16 step:76485[D loss: 1.000023] [G loss: 0.999997]\n",
      "epoch:16 step:76490[D loss: 1.000022] [G loss: 1.000023]\n",
      "epoch:16 step:76495[D loss: 0.999954] [G loss: 1.000041]\n",
      "epoch:16 step:76500[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:16 step:76505[D loss: 1.000028] [G loss: 1.000013]\n",
      "epoch:16 step:76510[D loss: 1.000022] [G loss: 0.999963]\n",
      "epoch:16 step:76515[D loss: 0.999964] [G loss: 1.000113]\n",
      "epoch:16 step:76520[D loss: 0.999919] [G loss: 1.000109]\n",
      "epoch:16 step:76525[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:16 step:76530[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:16 step:76535[D loss: 1.000009] [G loss: 1.000069]\n",
      "epoch:16 step:76540[D loss: 0.999992] [G loss: 1.000092]\n",
      "epoch:16 step:76545[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:16 step:76550[D loss: 0.999972] [G loss: 1.000040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:76555[D loss: 1.000010] [G loss: 1.000013]\n",
      "epoch:16 step:76560[D loss: 0.999960] [G loss: 1.000051]\n",
      "epoch:16 step:76565[D loss: 1.000130] [G loss: 0.999891]\n",
      "epoch:16 step:76570[D loss: 1.000057] [G loss: 0.999916]\n",
      "epoch:16 step:76575[D loss: 1.000023] [G loss: 1.000054]\n",
      "epoch:16 step:76580[D loss: 0.999925] [G loss: 1.000097]\n",
      "epoch:16 step:76585[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:16 step:76590[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:16 step:76595[D loss: 1.000029] [G loss: 0.999989]\n",
      "epoch:16 step:76600[D loss: 0.999983] [G loss: 1.000023]\n",
      "##############\n",
      "[2.64150826 2.10812203 2.28715694 3.75211179 1.53763962 7.79862312\n",
      " 2.3507204  3.75860209 4.01921194 5.57603075]\n",
      "##########\n",
      "epoch:16 step:76605[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:16 step:76610[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:16 step:76615[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:16 step:76620[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:16 step:76625[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:16 step:76630[D loss: 1.000016] [G loss: 1.000014]\n",
      "epoch:16 step:76635[D loss: 0.999941] [G loss: 1.000108]\n",
      "epoch:16 step:76640[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:16 step:76645[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:16 step:76650[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:16 step:76655[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:16 step:76660[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:16 step:76665[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:16 step:76670[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:16 step:76675[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:16 step:76680[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:16 step:76685[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:16 step:76690[D loss: 1.000018] [G loss: 1.000059]\n",
      "epoch:16 step:76695[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:16 step:76700[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:16 step:76705[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:16 step:76710[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:16 step:76715[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:16 step:76720[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:16 step:76725[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:16 step:76730[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:16 step:76735[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:16 step:76740[D loss: 0.999948] [G loss: 1.000104]\n",
      "epoch:16 step:76745[D loss: 1.000001] [G loss: 0.999989]\n",
      "epoch:16 step:76750[D loss: 0.999982] [G loss: 1.000113]\n",
      "epoch:16 step:76755[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:16 step:76760[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:16 step:76765[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:16 step:76770[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:16 step:76775[D loss: 1.000033] [G loss: 0.999984]\n",
      "epoch:16 step:76780[D loss: 0.999984] [G loss: 1.000146]\n",
      "epoch:16 step:76785[D loss: 0.999948] [G loss: 1.000132]\n",
      "epoch:16 step:76790[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:16 step:76795[D loss: 1.000033] [G loss: 1.000063]\n",
      "epoch:16 step:76800[D loss: 0.999934] [G loss: 1.000178]\n",
      "##############\n",
      "[2.59919194 2.15294799 2.18058463 3.73991594 1.47674205 7.35196463\n",
      " 2.24246    3.87931479 3.96622438 5.2835161 ]\n",
      "##########\n",
      "epoch:16 step:76805[D loss: 1.000007] [G loss: 1.000068]\n",
      "epoch:16 step:76810[D loss: 0.999955] [G loss: 1.000126]\n",
      "epoch:16 step:76815[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:16 step:76820[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:16 step:76825[D loss: 1.000017] [G loss: 0.999969]\n",
      "epoch:16 step:76830[D loss: 0.999969] [G loss: 0.999991]\n",
      "epoch:16 step:76835[D loss: 0.999992] [G loss: 1.000013]\n",
      "epoch:16 step:76840[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:16 step:76845[D loss: 1.000003] [G loss: 1.000050]\n",
      "epoch:16 step:76850[D loss: 1.000060] [G loss: 1.000078]\n",
      "epoch:16 step:76855[D loss: 1.000037] [G loss: 0.999946]\n",
      "epoch:16 step:76860[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:16 step:76865[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:16 step:76870[D loss: 0.999933] [G loss: 1.000108]\n",
      "epoch:16 step:76875[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:16 step:76880[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:16 step:76885[D loss: 1.000074] [G loss: 0.999937]\n",
      "epoch:16 step:76890[D loss: 0.999988] [G loss: 0.999982]\n",
      "epoch:16 step:76895[D loss: 1.000035] [G loss: 1.000028]\n",
      "epoch:16 step:76900[D loss: 0.999981] [G loss: 1.000030]\n",
      "epoch:16 step:76905[D loss: 0.999940] [G loss: 1.000087]\n",
      "epoch:16 step:76910[D loss: 1.000034] [G loss: 1.000070]\n",
      "epoch:16 step:76915[D loss: 0.999950] [G loss: 1.000070]\n",
      "epoch:16 step:76920[D loss: 1.000007] [G loss: 1.000059]\n",
      "epoch:16 step:76925[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:16 step:76930[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:16 step:76935[D loss: 0.999960] [G loss: 1.000051]\n",
      "epoch:16 step:76940[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:16 step:76945[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:16 step:76950[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:16 step:76955[D loss: 1.000025] [G loss: 0.999993]\n",
      "epoch:16 step:76960[D loss: 0.999951] [G loss: 1.000053]\n",
      "epoch:16 step:76965[D loss: 0.999949] [G loss: 1.000150]\n",
      "epoch:16 step:76970[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:16 step:76975[D loss: 0.999971] [G loss: 1.000111]\n",
      "epoch:16 step:76980[D loss: 0.999945] [G loss: 1.000127]\n",
      "epoch:16 step:76985[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:16 step:76990[D loss: 1.000002] [G loss: 1.000070]\n",
      "epoch:16 step:76995[D loss: 1.000068] [G loss: 0.999935]\n",
      "epoch:16 step:77000[D loss: 0.999947] [G loss: 1.000047]\n",
      "##############\n",
      "[2.50898135 2.16232402 2.23501073 3.9193929  1.50207151 7.2449462\n",
      " 2.39696914 3.90997935 4.04395273 5.95247795]\n",
      "##########\n",
      "epoch:16 step:77005[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:16 step:77010[D loss: 1.000024] [G loss: 1.000084]\n",
      "epoch:16 step:77015[D loss: 1.000027] [G loss: 0.999935]\n",
      "epoch:16 step:77020[D loss: 1.000000] [G loss: 1.000023]\n",
      "epoch:16 step:77025[D loss: 1.000003] [G loss: 0.999994]\n",
      "epoch:16 step:77030[D loss: 1.000016] [G loss: 0.999981]\n",
      "epoch:16 step:77035[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:16 step:77040[D loss: 0.999941] [G loss: 1.000093]\n",
      "epoch:16 step:77045[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:16 step:77050[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:16 step:77055[D loss: 0.999956] [G loss: 1.000063]\n",
      "epoch:16 step:77060[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:16 step:77065[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:16 step:77070[D loss: 1.000001] [G loss: 1.000071]\n",
      "epoch:16 step:77075[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:16 step:77080[D loss: 1.000017] [G loss: 1.000008]\n",
      "epoch:16 step:77085[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:16 step:77090[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:16 step:77095[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:16 step:77100[D loss: 0.999945] [G loss: 1.000128]\n",
      "epoch:16 step:77105[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:16 step:77110[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:16 step:77115[D loss: 0.999938] [G loss: 1.000105]\n",
      "epoch:16 step:77120[D loss: 1.000023] [G loss: 1.000037]\n",
      "epoch:16 step:77125[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:16 step:77130[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:16 step:77135[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:16 step:77140[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:16 step:77145[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:16 step:77150[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:16 step:77155[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:16 step:77160[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:16 step:77165[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:16 step:77170[D loss: 0.999966] [G loss: 1.000123]\n",
      "epoch:16 step:77175[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:16 step:77180[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:16 step:77185[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:16 step:77190[D loss: 0.999966] [G loss: 1.000121]\n",
      "epoch:16 step:77195[D loss: 0.999983] [G loss: 1.000089]\n",
      "epoch:16 step:77200[D loss: 0.999921] [G loss: 1.000191]\n",
      "##############\n",
      "[2.53801387 2.00963011 2.12857835 3.78320403 1.48547006 7.26016211\n",
      " 2.21681659 3.55089389 3.87459388 5.05910091]\n",
      "##########\n",
      "epoch:16 step:77205[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:16 step:77210[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:16 step:77215[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:16 step:77220[D loss: 0.999971] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:77225[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:16 step:77230[D loss: 1.000023] [G loss: 0.999991]\n",
      "epoch:16 step:77235[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:16 step:77240[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:16 step:77245[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:16 step:77250[D loss: 1.000016] [G loss: 1.000049]\n",
      "epoch:16 step:77255[D loss: 1.000026] [G loss: 1.000185]\n",
      "epoch:16 step:77260[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:16 step:77265[D loss: 0.999947] [G loss: 1.000117]\n",
      "epoch:16 step:77270[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:16 step:77275[D loss: 0.999975] [G loss: 1.000017]\n",
      "epoch:16 step:77280[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:16 step:77285[D loss: 1.000041] [G loss: 0.999993]\n",
      "epoch:16 step:77290[D loss: 0.999958] [G loss: 1.000033]\n",
      "epoch:16 step:77295[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:16 step:77300[D loss: 1.000047] [G loss: 1.000032]\n",
      "epoch:16 step:77305[D loss: 1.000079] [G loss: 0.999939]\n",
      "epoch:16 step:77310[D loss: 0.999850] [G loss: 1.000189]\n",
      "epoch:16 step:77315[D loss: 0.999960] [G loss: 1.000156]\n",
      "epoch:16 step:77320[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:16 step:77325[D loss: 0.999937] [G loss: 1.000107]\n",
      "epoch:16 step:77330[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:16 step:77335[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:16 step:77340[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:16 step:77345[D loss: 0.999988] [G loss: 0.999985]\n",
      "epoch:16 step:77350[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:16 step:77355[D loss: 0.999960] [G loss: 1.000022]\n",
      "epoch:16 step:77360[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:16 step:77365[D loss: 1.000005] [G loss: 0.999999]\n",
      "epoch:16 step:77370[D loss: 0.999940] [G loss: 1.000062]\n",
      "epoch:16 step:77375[D loss: 1.000004] [G loss: 1.000068]\n",
      "epoch:16 step:77380[D loss: 0.999915] [G loss: 1.000106]\n",
      "epoch:16 step:77385[D loss: 1.000003] [G loss: 1.000031]\n",
      "epoch:16 step:77390[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:16 step:77395[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:16 step:77400[D loss: 0.999989] [G loss: 1.000054]\n",
      "##############\n",
      "[2.57161546 2.09667201 2.18381306 4.25004898 1.4687954  7.27002954\n",
      " 2.19913185 3.66920423 3.92859087 5.47645904]\n",
      "##########\n",
      "epoch:16 step:77405[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:16 step:77410[D loss: 0.999993] [G loss: 1.000117]\n",
      "epoch:16 step:77415[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:16 step:77420[D loss: 0.999948] [G loss: 1.000153]\n",
      "epoch:16 step:77425[D loss: 0.999990] [G loss: 1.000205]\n",
      "epoch:16 step:77430[D loss: 1.000036] [G loss: 1.000052]\n",
      "epoch:16 step:77435[D loss: 0.999902] [G loss: 1.000128]\n",
      "epoch:16 step:77440[D loss: 1.000133] [G loss: 1.000011]\n",
      "epoch:16 step:77445[D loss: 0.999880] [G loss: 1.000320]\n",
      "epoch:16 step:77450[D loss: 0.999938] [G loss: 1.000096]\n",
      "epoch:16 step:77455[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:16 step:77460[D loss: 1.000094] [G loss: 0.999933]\n",
      "epoch:16 step:77465[D loss: 0.999928] [G loss: 1.000027]\n",
      "epoch:16 step:77470[D loss: 0.999911] [G loss: 1.000153]\n",
      "epoch:16 step:77475[D loss: 1.000009] [G loss: 0.999991]\n",
      "epoch:16 step:77480[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:16 step:77485[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:16 step:77490[D loss: 0.999988] [G loss: 0.999996]\n",
      "epoch:16 step:77495[D loss: 1.000077] [G loss: 0.999976]\n",
      "epoch:16 step:77500[D loss: 0.999997] [G loss: 1.000132]\n",
      "epoch:16 step:77505[D loss: 1.000014] [G loss: 0.999995]\n",
      "epoch:16 step:77510[D loss: 1.000095] [G loss: 1.000019]\n",
      "epoch:16 step:77515[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:16 step:77520[D loss: 0.999909] [G loss: 1.000077]\n",
      "epoch:16 step:77525[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:16 step:77530[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:16 step:77535[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:16 step:77540[D loss: 0.999941] [G loss: 1.000090]\n",
      "epoch:16 step:77545[D loss: 1.000093] [G loss: 0.999960]\n",
      "epoch:16 step:77550[D loss: 0.999991] [G loss: 0.999991]\n",
      "epoch:16 step:77555[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:16 step:77560[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:16 step:77565[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:16 step:77570[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:16 step:77575[D loss: 0.999955] [G loss: 1.000112]\n",
      "epoch:16 step:77580[D loss: 0.999972] [G loss: 1.000122]\n",
      "epoch:16 step:77585[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:16 step:77590[D loss: 1.000007] [G loss: 1.000019]\n",
      "epoch:16 step:77595[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:16 step:77600[D loss: 0.999975] [G loss: 1.000012]\n",
      "##############\n",
      "[2.50503284 2.21017218 2.10261668 3.52852417 1.51415485 9.27426719\n",
      " 2.42849758 3.70515782 3.94058682 5.47188784]\n",
      "##########\n",
      "epoch:16 step:77605[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:16 step:77610[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:16 step:77615[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:16 step:77620[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:16 step:77625[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:16 step:77630[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:16 step:77635[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:16 step:77640[D loss: 0.999996] [G loss: 1.000140]\n",
      "epoch:16 step:77645[D loss: 0.999914] [G loss: 1.000267]\n",
      "epoch:16 step:77650[D loss: 0.999918] [G loss: 1.000215]\n",
      "epoch:16 step:77655[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:16 step:77660[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:16 step:77665[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:16 step:77670[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:16 step:77675[D loss: 0.999980] [G loss: 1.000145]\n",
      "epoch:16 step:77680[D loss: 0.999934] [G loss: 1.000154]\n",
      "epoch:16 step:77685[D loss: 1.000124] [G loss: 0.999762]\n",
      "epoch:16 step:77690[D loss: 1.000000] [G loss: 1.000021]\n",
      "epoch:16 step:77695[D loss: 0.999965] [G loss: 1.000027]\n",
      "epoch:16 step:77700[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:16 step:77705[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:16 step:77710[D loss: 0.999986] [G loss: 1.000087]\n",
      "epoch:16 step:77715[D loss: 0.999983] [G loss: 1.000089]\n",
      "epoch:16 step:77720[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:16 step:77725[D loss: 1.000042] [G loss: 0.999976]\n",
      "epoch:16 step:77730[D loss: 0.999935] [G loss: 1.000089]\n",
      "epoch:16 step:77735[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:16 step:77740[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:16 step:77745[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:16 step:77750[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:16 step:77755[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:16 step:77760[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:16 step:77765[D loss: 0.999933] [G loss: 1.000133]\n",
      "epoch:16 step:77770[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:16 step:77775[D loss: 1.000065] [G loss: 0.999985]\n",
      "epoch:16 step:77780[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:16 step:77785[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:16 step:77790[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:16 step:77795[D loss: 0.999965] [G loss: 1.000022]\n",
      "epoch:16 step:77800[D loss: 0.999985] [G loss: 1.000054]\n",
      "##############\n",
      "[2.55835722 2.07763474 2.11004227 3.51923087 1.48861998 7.38699317\n",
      " 2.25202291 3.75244068 3.86991948 5.99060525]\n",
      "##########\n",
      "epoch:16 step:77805[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:16 step:77810[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:16 step:77815[D loss: 0.999950] [G loss: 1.000067]\n",
      "epoch:16 step:77820[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:16 step:77825[D loss: 1.000037] [G loss: 1.000065]\n",
      "epoch:16 step:77830[D loss: 0.999907] [G loss: 1.000120]\n",
      "epoch:16 step:77835[D loss: 1.000043] [G loss: 1.000040]\n",
      "epoch:16 step:77840[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:16 step:77845[D loss: 0.999911] [G loss: 1.000091]\n",
      "epoch:16 step:77850[D loss: 1.000026] [G loss: 1.000064]\n",
      "epoch:16 step:77855[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:16 step:77860[D loss: 1.000010] [G loss: 1.000086]\n",
      "epoch:16 step:77865[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:16 step:77870[D loss: 1.000000] [G loss: 1.000080]\n",
      "epoch:16 step:77875[D loss: 1.000010] [G loss: 1.000000]\n",
      "epoch:16 step:77880[D loss: 0.999947] [G loss: 1.000067]\n",
      "epoch:16 step:77885[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:16 step:77890[D loss: 1.000013] [G loss: 0.999974]\n",
      "epoch:16 step:77895[D loss: 0.999929] [G loss: 1.000082]\n",
      "epoch:16 step:77900[D loss: 1.000044] [G loss: 1.000027]\n",
      "epoch:16 step:77905[D loss: 1.000032] [G loss: 1.000066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:77910[D loss: 1.000008] [G loss: 0.999944]\n",
      "epoch:16 step:77915[D loss: 0.999906] [G loss: 1.000178]\n",
      "epoch:16 step:77920[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:16 step:77925[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:16 step:77930[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:16 step:77935[D loss: 1.000010] [G loss: 1.000098]\n",
      "epoch:16 step:77940[D loss: 1.000016] [G loss: 0.999951]\n",
      "epoch:16 step:77945[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:16 step:77950[D loss: 0.999920] [G loss: 1.000114]\n",
      "epoch:16 step:77955[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:16 step:77960[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:16 step:77965[D loss: 0.999940] [G loss: 1.000045]\n",
      "epoch:16 step:77970[D loss: 0.999990] [G loss: 1.000104]\n",
      "epoch:16 step:77975[D loss: 0.999955] [G loss: 1.000075]\n",
      "epoch:16 step:77980[D loss: 1.000023] [G loss: 1.000037]\n",
      "epoch:16 step:77985[D loss: 0.999948] [G loss: 1.000044]\n",
      "epoch:16 step:77990[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:16 step:77995[D loss: 0.999997] [G loss: 1.000007]\n",
      "epoch:16 step:78000[D loss: 1.000019] [G loss: 0.999974]\n",
      "##############\n",
      "[2.54385333 2.05798815 2.17235376 3.74228897 1.46504231 7.78525977\n",
      " 2.23601605 3.52223534 3.90447057 7.14730822]\n",
      "##########\n",
      "epoch:16 step:78005[D loss: 1.000022] [G loss: 1.000101]\n",
      "epoch:16 step:78010[D loss: 0.999933] [G loss: 1.000095]\n",
      "epoch:16 step:78015[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:16 step:78020[D loss: 1.000028] [G loss: 1.000013]\n",
      "epoch:16 step:78025[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:16 step:78030[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:16 step:78035[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:16 step:78040[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:16 step:78045[D loss: 0.999992] [G loss: 1.000113]\n",
      "epoch:16 step:78050[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:16 step:78055[D loss: 0.999878] [G loss: 1.000112]\n",
      "epoch:16 step:78060[D loss: 0.999991] [G loss: 1.000101]\n",
      "epoch:16 step:78065[D loss: 0.999946] [G loss: 1.000112]\n",
      "epoch:16 step:78070[D loss: 0.999969] [G loss: 1.000115]\n",
      "epoch:16 step:78075[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:16 step:78080[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:16 step:78085[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:16 step:78090[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:16 step:78095[D loss: 0.999949] [G loss: 1.000111]\n",
      "epoch:16 step:78100[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:16 step:78105[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:16 step:78110[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:16 step:78115[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:16 step:78120[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:16 step:78125[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:16 step:78130[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:16 step:78135[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:16 step:78140[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:16 step:78145[D loss: 1.000000] [G loss: 1.000126]\n",
      "epoch:16 step:78150[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:16 step:78155[D loss: 0.999980] [G loss: 1.000018]\n",
      "epoch:16 step:78160[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:16 step:78165[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:16 step:78170[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:16 step:78175[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:16 step:78180[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:16 step:78185[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:16 step:78190[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:16 step:78195[D loss: 0.999955] [G loss: 1.000052]\n",
      "epoch:16 step:78200[D loss: 0.999992] [G loss: 1.000053]\n",
      "##############\n",
      "[2.55556959 2.20284498 2.18933044 4.03505686 1.53940475 7.50628316\n",
      " 2.35322697 3.717978   4.0140269  4.90366869]\n",
      "##########\n",
      "epoch:16 step:78205[D loss: 1.000010] [G loss: 0.999999]\n",
      "epoch:16 step:78210[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:16 step:78215[D loss: 1.000004] [G loss: 1.000061]\n",
      "epoch:16 step:78220[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:16 step:78225[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:16 step:78230[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:16 step:78235[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:16 step:78240[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:16 step:78245[D loss: 1.000004] [G loss: 1.000012]\n",
      "epoch:16 step:78250[D loss: 0.999964] [G loss: 1.000050]\n",
      "epoch:16 step:78255[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:16 step:78260[D loss: 1.000007] [G loss: 1.000025]\n",
      "epoch:16 step:78265[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:16 step:78270[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:16 step:78275[D loss: 1.000045] [G loss: 0.999945]\n",
      "epoch:16 step:78280[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:16 step:78285[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:16 step:78290[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:16 step:78295[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:16 step:78300[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:16 step:78305[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:16 step:78310[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:16 step:78315[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:16 step:78320[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:16 step:78325[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:16 step:78330[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:16 step:78335[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:16 step:78340[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:16 step:78345[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:16 step:78350[D loss: 0.999960] [G loss: 1.000104]\n",
      "epoch:16 step:78355[D loss: 1.000010] [G loss: 1.000029]\n",
      "epoch:16 step:78360[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:16 step:78365[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:16 step:78370[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:16 step:78375[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:16 step:78380[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:16 step:78385[D loss: 1.000024] [G loss: 0.999983]\n",
      "epoch:16 step:78390[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:16 step:78395[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:16 step:78400[D loss: 0.999965] [G loss: 1.000069]\n",
      "##############\n",
      "[2.56498664 2.15796848 2.20682526 3.78147652 1.54025949 7.83666984\n",
      " 2.49549215 3.64130195 4.00219031 5.79260065]\n",
      "##########\n",
      "epoch:16 step:78405[D loss: 1.000028] [G loss: 1.000039]\n",
      "epoch:16 step:78410[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:16 step:78415[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:16 step:78420[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:16 step:78425[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:16 step:78430[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:16 step:78435[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:16 step:78440[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:16 step:78445[D loss: 1.000016] [G loss: 0.999964]\n",
      "epoch:16 step:78450[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:16 step:78455[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:16 step:78460[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:16 step:78465[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:16 step:78470[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:16 step:78475[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:16 step:78480[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:16 step:78485[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:16 step:78490[D loss: 0.999996] [G loss: 1.000041]\n",
      "epoch:16 step:78495[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:16 step:78500[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:16 step:78505[D loss: 1.000055] [G loss: 0.999959]\n",
      "epoch:16 step:78510[D loss: 1.000088] [G loss: 0.999903]\n",
      "epoch:16 step:78515[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:16 step:78520[D loss: 1.000051] [G loss: 0.999910]\n",
      "epoch:16 step:78525[D loss: 0.999931] [G loss: 1.000104]\n",
      "epoch:16 step:78530[D loss: 1.000074] [G loss: 0.999981]\n",
      "epoch:16 step:78535[D loss: 1.000008] [G loss: 0.999999]\n",
      "epoch:16 step:78540[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:16 step:78545[D loss: 0.999989] [G loss: 1.000026]\n",
      "epoch:16 step:78550[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:16 step:78555[D loss: 1.000008] [G loss: 0.999988]\n",
      "epoch:16 step:78560[D loss: 0.999948] [G loss: 1.000058]\n",
      "epoch:16 step:78565[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:16 step:78570[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:16 step:78575[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:16 step:78580[D loss: 0.999961] [G loss: 1.000162]\n",
      "epoch:16 step:78585[D loss: 0.999949] [G loss: 1.000106]\n",
      "epoch:16 step:78590[D loss: 0.999978] [G loss: 1.000057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:78595[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:16 step:78600[D loss: 1.000008] [G loss: 1.000060]\n",
      "##############\n",
      "[2.55143192 2.03319408 2.21844027 3.92478701 1.41912739 7.67008127\n",
      " 2.22651231 3.64941849 3.86116227 5.20844101]\n",
      "##########\n",
      "epoch:16 step:78605[D loss: 0.999910] [G loss: 1.000106]\n",
      "epoch:16 step:78610[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:16 step:78615[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:16 step:78620[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:16 step:78625[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:16 step:78630[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:16 step:78635[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:16 step:78640[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:16 step:78645[D loss: 1.000042] [G loss: 0.999993]\n",
      "epoch:16 step:78650[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:16 step:78655[D loss: 0.999972] [G loss: 1.000111]\n",
      "epoch:16 step:78660[D loss: 0.999944] [G loss: 1.000090]\n",
      "epoch:16 step:78665[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:16 step:78670[D loss: 1.000002] [G loss: 1.000073]\n",
      "epoch:16 step:78675[D loss: 0.999952] [G loss: 1.000065]\n",
      "epoch:16 step:78680[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:16 step:78685[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:16 step:78690[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:16 step:78695[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:16 step:78700[D loss: 1.000035] [G loss: 0.999975]\n",
      "epoch:16 step:78705[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:16 step:78710[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:16 step:78715[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:16 step:78720[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:16 step:78725[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:16 step:78730[D loss: 1.000082] [G loss: 0.999961]\n",
      "epoch:16 step:78735[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:16 step:78740[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:16 step:78745[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:16 step:78750[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:16 step:78755[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:16 step:78760[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:16 step:78765[D loss: 1.000017] [G loss: 0.999975]\n",
      "epoch:16 step:78770[D loss: 1.000040] [G loss: 1.000006]\n",
      "epoch:16 step:78775[D loss: 0.999957] [G loss: 1.000102]\n",
      "epoch:16 step:78780[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:16 step:78785[D loss: 0.999888] [G loss: 1.000165]\n",
      "epoch:16 step:78790[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:16 step:78795[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:16 step:78800[D loss: 0.999971] [G loss: 1.000070]\n",
      "##############\n",
      "[2.57989601 2.14643482 2.21557709 4.14412859 1.4651622  7.79734558\n",
      " 2.31064846 3.81075979 3.99783103 5.34519462]\n",
      "##########\n",
      "epoch:16 step:78805[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:16 step:78810[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:16 step:78815[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:16 step:78820[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:16 step:78825[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:16 step:78830[D loss: 1.000000] [G loss: 1.000046]\n",
      "epoch:16 step:78835[D loss: 0.999957] [G loss: 1.000034]\n",
      "epoch:16 step:78840[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:16 step:78845[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:16 step:78850[D loss: 1.000006] [G loss: 1.000000]\n",
      "epoch:16 step:78855[D loss: 1.000017] [G loss: 1.000012]\n",
      "epoch:16 step:78860[D loss: 1.000020] [G loss: 0.999967]\n",
      "epoch:16 step:78865[D loss: 0.999932] [G loss: 1.000068]\n",
      "epoch:16 step:78870[D loss: 0.999960] [G loss: 1.000048]\n",
      "epoch:16 step:78875[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:16 step:78880[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:16 step:78885[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:16 step:78890[D loss: 1.000008] [G loss: 1.000003]\n",
      "epoch:16 step:78895[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:16 step:78900[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:16 step:78905[D loss: 1.000036] [G loss: 0.999988]\n",
      "epoch:16 step:78910[D loss: 0.999959] [G loss: 1.000049]\n",
      "epoch:16 step:78915[D loss: 1.000007] [G loss: 0.999999]\n",
      "epoch:16 step:78920[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:16 step:78925[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:16 step:78930[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:16 step:78935[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:16 step:78940[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:16 step:78945[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:16 step:78950[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:16 step:78955[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:16 step:78960[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:16 step:78965[D loss: 0.999981] [G loss: 1.000030]\n",
      "epoch:16 step:78970[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:16 step:78975[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:16 step:78980[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:16 step:78985[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:16 step:78990[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:16 step:78995[D loss: 0.999936] [G loss: 1.000151]\n",
      "epoch:16 step:79000[D loss: 1.000025] [G loss: 1.000091]\n",
      "##############\n",
      "[2.50523329 2.03397713 2.19938244 3.87265327 1.39053462 7.69853996\n",
      " 2.38606541 3.77179224 3.94706505 5.78683259]\n",
      "##########\n",
      "epoch:16 step:79005[D loss: 0.999942] [G loss: 1.000084]\n",
      "epoch:16 step:79010[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:16 step:79015[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:16 step:79020[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:16 step:79025[D loss: 0.999984] [G loss: 1.000006]\n",
      "epoch:16 step:79030[D loss: 1.000018] [G loss: 1.000018]\n",
      "epoch:16 step:79035[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:16 step:79040[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:16 step:79045[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:16 step:79050[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:16 step:79055[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:16 step:79060[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:16 step:79065[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:16 step:79070[D loss: 0.999950] [G loss: 1.000088]\n",
      "epoch:16 step:79075[D loss: 0.999940] [G loss: 1.000092]\n",
      "epoch:16 step:79080[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:16 step:79085[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:16 step:79090[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:16 step:79095[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:16 step:79100[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:16 step:79105[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:16 step:79110[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:16 step:79115[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:16 step:79120[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:16 step:79125[D loss: 0.999943] [G loss: 1.000073]\n",
      "epoch:16 step:79130[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:16 step:79135[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:16 step:79140[D loss: 1.000008] [G loss: 1.000038]\n",
      "epoch:16 step:79145[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:16 step:79150[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:16 step:79155[D loss: 1.000051] [G loss: 0.999998]\n",
      "epoch:16 step:79160[D loss: 0.999989] [G loss: 0.999989]\n",
      "epoch:16 step:79165[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:16 step:79170[D loss: 0.999992] [G loss: 0.999982]\n",
      "epoch:16 step:79175[D loss: 0.999946] [G loss: 1.000081]\n",
      "epoch:16 step:79180[D loss: 1.000033] [G loss: 1.000033]\n",
      "epoch:16 step:79185[D loss: 0.999935] [G loss: 1.000113]\n",
      "epoch:16 step:79190[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:16 step:79195[D loss: 0.999989] [G loss: 1.000088]\n",
      "epoch:16 step:79200[D loss: 0.999959] [G loss: 1.000101]\n",
      "##############\n",
      "[2.59241219 2.09476444 2.1281905  3.53957299 1.44672895 9.27329063\n",
      " 2.26764565 3.70021109 3.82460415 5.47229302]\n",
      "##########\n",
      "epoch:16 step:79205[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:16 step:79210[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:16 step:79215[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:16 step:79220[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:16 step:79225[D loss: 1.000027] [G loss: 0.999993]\n",
      "epoch:16 step:79230[D loss: 0.999895] [G loss: 1.000106]\n",
      "epoch:16 step:79235[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:16 step:79240[D loss: 1.000013] [G loss: 1.000054]\n",
      "epoch:16 step:79245[D loss: 0.999993] [G loss: 0.999959]\n",
      "epoch:16 step:79250[D loss: 0.999940] [G loss: 1.000104]\n",
      "epoch:16 step:79255[D loss: 1.000015] [G loss: 1.000004]\n",
      "epoch:16 step:79260[D loss: 0.999979] [G loss: 1.000053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:79265[D loss: 0.999942] [G loss: 1.000063]\n",
      "epoch:16 step:79270[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:16 step:79275[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:16 step:79280[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:16 step:79285[D loss: 1.000009] [G loss: 1.000005]\n",
      "epoch:16 step:79290[D loss: 0.999942] [G loss: 1.000115]\n",
      "epoch:16 step:79295[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:16 step:79300[D loss: 0.999932] [G loss: 1.000133]\n",
      "epoch:16 step:79305[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:16 step:79310[D loss: 1.000047] [G loss: 1.000025]\n",
      "epoch:16 step:79315[D loss: 0.999984] [G loss: 0.999998]\n",
      "epoch:16 step:79320[D loss: 0.999985] [G loss: 0.999999]\n",
      "epoch:16 step:79325[D loss: 0.999997] [G loss: 1.000082]\n",
      "epoch:16 step:79330[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:16 step:79335[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:16 step:79340[D loss: 0.999954] [G loss: 1.000145]\n",
      "epoch:16 step:79345[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:16 step:79350[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:16 step:79355[D loss: 0.999946] [G loss: 1.000124]\n",
      "epoch:16 step:79360[D loss: 0.999978] [G loss: 1.000103]\n",
      "epoch:16 step:79365[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:16 step:79370[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:16 step:79375[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:16 step:79380[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:16 step:79385[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:16 step:79390[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:16 step:79395[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:16 step:79400[D loss: 0.999983] [G loss: 1.000032]\n",
      "##############\n",
      "[2.54795903 2.05601105 2.26765683 3.69539977 1.5045185  7.15739949\n",
      " 2.31344324 3.7635031  3.93819615 5.2503971 ]\n",
      "##########\n",
      "epoch:16 step:79405[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:16 step:79410[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:16 step:79415[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:16 step:79420[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:16 step:79425[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:16 step:79430[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:16 step:79435[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:16 step:79440[D loss: 1.000019] [G loss: 1.000039]\n",
      "epoch:16 step:79445[D loss: 0.999949] [G loss: 1.000108]\n",
      "epoch:16 step:79450[D loss: 0.999972] [G loss: 1.000025]\n",
      "epoch:16 step:79455[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:16 step:79460[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:16 step:79465[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:16 step:79470[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:16 step:79475[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:16 step:79480[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:16 step:79485[D loss: 0.999987] [G loss: 1.000019]\n",
      "epoch:16 step:79490[D loss: 0.999937] [G loss: 1.000152]\n",
      "epoch:16 step:79495[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:16 step:79500[D loss: 1.000007] [G loss: 1.000038]\n",
      "epoch:16 step:79505[D loss: 0.999999] [G loss: 1.000005]\n",
      "epoch:16 step:79510[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:16 step:79515[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:16 step:79520[D loss: 0.999996] [G loss: 0.999993]\n",
      "epoch:16 step:79525[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:16 step:79530[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:16 step:79535[D loss: 1.000017] [G loss: 1.000016]\n",
      "epoch:16 step:79540[D loss: 1.000008] [G loss: 1.000001]\n",
      "epoch:16 step:79545[D loss: 0.999933] [G loss: 1.000187]\n",
      "epoch:16 step:79550[D loss: 0.999945] [G loss: 1.000090]\n",
      "epoch:16 step:79555[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:16 step:79560[D loss: 1.000010] [G loss: 0.999993]\n",
      "epoch:16 step:79565[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:16 step:79570[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:16 step:79575[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:16 step:79580[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:16 step:79585[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:16 step:79590[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:16 step:79595[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:16 step:79600[D loss: 0.999982] [G loss: 1.000038]\n",
      "##############\n",
      "[2.55275217 2.05252769 2.30193462 3.65025214 1.50609823 6.50398\n",
      " 2.32083533 3.61124569 3.93643525 7.14868929]\n",
      "##########\n",
      "epoch:16 step:79605[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:16 step:79610[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:16 step:79615[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:16 step:79620[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:16 step:79625[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:16 step:79630[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:16 step:79635[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:16 step:79640[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:16 step:79645[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:17 step:79650[D loss: 1.000042] [G loss: 1.000000]\n",
      "epoch:17 step:79655[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:17 step:79660[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:17 step:79665[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:17 step:79670[D loss: 0.999964] [G loss: 1.000051]\n",
      "epoch:17 step:79675[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:17 step:79680[D loss: 1.000020] [G loss: 0.999950]\n",
      "epoch:17 step:79685[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:17 step:79690[D loss: 1.000019] [G loss: 1.000012]\n",
      "epoch:17 step:79695[D loss: 1.000030] [G loss: 1.000029]\n",
      "epoch:17 step:79700[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:17 step:79705[D loss: 0.999951] [G loss: 1.000093]\n",
      "epoch:17 step:79710[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:17 step:79715[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:17 step:79720[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:17 step:79725[D loss: 0.999940] [G loss: 1.000091]\n",
      "epoch:17 step:79730[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:17 step:79735[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:17 step:79740[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:17 step:79745[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:17 step:79750[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:17 step:79755[D loss: 1.000030] [G loss: 1.000029]\n",
      "epoch:17 step:79760[D loss: 0.999918] [G loss: 1.000117]\n",
      "epoch:17 step:79765[D loss: 0.999955] [G loss: 1.000118]\n",
      "epoch:17 step:79770[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:17 step:79775[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:17 step:79780[D loss: 1.000006] [G loss: 1.000073]\n",
      "epoch:17 step:79785[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:17 step:79790[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:17 step:79795[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:17 step:79800[D loss: 0.999945] [G loss: 1.000080]\n",
      "##############\n",
      "[2.65845738 2.13640044 2.2801806  3.7165238  1.46513613 7.43127314\n",
      " 2.44228385 3.67073298 3.9394153  5.70260738]\n",
      "##########\n",
      "epoch:17 step:79805[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:17 step:79810[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:17 step:79815[D loss: 1.000026] [G loss: 1.000013]\n",
      "epoch:17 step:79820[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:17 step:79825[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:17 step:79830[D loss: 0.999969] [G loss: 1.000110]\n",
      "epoch:17 step:79835[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:17 step:79840[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:17 step:79845[D loss: 1.000009] [G loss: 1.000052]\n",
      "epoch:17 step:79850[D loss: 0.999967] [G loss: 1.000121]\n",
      "epoch:17 step:79855[D loss: 0.999918] [G loss: 1.000154]\n",
      "epoch:17 step:79860[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:17 step:79865[D loss: 0.999999] [G loss: 0.999992]\n",
      "epoch:17 step:79870[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:17 step:79875[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:17 step:79880[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:17 step:79885[D loss: 0.999959] [G loss: 1.000097]\n",
      "epoch:17 step:79890[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:17 step:79895[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:17 step:79900[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:17 step:79905[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:17 step:79910[D loss: 0.999987] [G loss: 1.000094]\n",
      "epoch:17 step:79915[D loss: 1.000008] [G loss: 1.000045]\n",
      "epoch:17 step:79920[D loss: 0.999964] [G loss: 1.000112]\n",
      "epoch:17 step:79925[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:17 step:79930[D loss: 0.999977] [G loss: 1.000116]\n",
      "epoch:17 step:79935[D loss: 0.999973] [G loss: 1.000134]\n",
      "epoch:17 step:79940[D loss: 0.999959] [G loss: 1.000110]\n",
      "epoch:17 step:79945[D loss: 0.999983] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:79950[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:17 step:79955[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:17 step:79960[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:17 step:79965[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:17 step:79970[D loss: 0.999995] [G loss: 1.000019]\n",
      "epoch:17 step:79975[D loss: 1.000007] [G loss: 0.999992]\n",
      "epoch:17 step:79980[D loss: 0.999965] [G loss: 1.000022]\n",
      "epoch:17 step:79985[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:17 step:79990[D loss: 1.000001] [G loss: 1.000085]\n",
      "epoch:17 step:79995[D loss: 1.000005] [G loss: 1.000048]\n",
      "epoch:17 step:80000[D loss: 0.999953] [G loss: 1.000119]\n",
      "##############\n",
      "[2.56124952 2.12097974 2.23315034 3.96442254 1.46348244 7.81159019\n",
      " 2.34219259 3.89897124 3.94906212 5.22677349]\n",
      "##########\n",
      "epoch:17 step:80005[D loss: 0.999940] [G loss: 1.000199]\n",
      "epoch:17 step:80010[D loss: 0.999963] [G loss: 1.000045]\n",
      "epoch:17 step:80015[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:17 step:80020[D loss: 1.000021] [G loss: 0.999981]\n",
      "epoch:17 step:80025[D loss: 0.999965] [G loss: 1.000043]\n",
      "epoch:17 step:80030[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:17 step:80035[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:17 step:80040[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:17 step:80045[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:17 step:80050[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:17 step:80055[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:17 step:80060[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:17 step:80065[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:17 step:80070[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:17 step:80075[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:17 step:80080[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:17 step:80085[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:17 step:80090[D loss: 1.000029] [G loss: 1.000001]\n",
      "epoch:17 step:80095[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:17 step:80100[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:17 step:80105[D loss: 0.999945] [G loss: 1.000079]\n",
      "epoch:17 step:80110[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:17 step:80115[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:17 step:80120[D loss: 0.999996] [G loss: 1.000080]\n",
      "epoch:17 step:80125[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:17 step:80130[D loss: 0.999995] [G loss: 1.000078]\n",
      "epoch:17 step:80135[D loss: 1.000000] [G loss: 1.000108]\n",
      "epoch:17 step:80140[D loss: 0.999943] [G loss: 1.000090]\n",
      "epoch:17 step:80145[D loss: 0.999922] [G loss: 1.000106]\n",
      "epoch:17 step:80150[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:17 step:80155[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:17 step:80160[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:17 step:80165[D loss: 1.000026] [G loss: 0.999956]\n",
      "epoch:17 step:80170[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:17 step:80175[D loss: 0.999950] [G loss: 1.000071]\n",
      "epoch:17 step:80180[D loss: 1.000017] [G loss: 1.000022]\n",
      "epoch:17 step:80185[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:17 step:80190[D loss: 0.999950] [G loss: 1.000058]\n",
      "epoch:17 step:80195[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:17 step:80200[D loss: 0.999962] [G loss: 1.000076]\n",
      "##############\n",
      "[2.55839937 2.24989121 2.3011786  3.80334154 1.51772799 7.51754853\n",
      " 2.36952853 3.87942498 3.94994762 5.64300277]\n",
      "##########\n",
      "epoch:17 step:80205[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:17 step:80210[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:17 step:80215[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:17 step:80220[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:17 step:80225[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:17 step:80230[D loss: 1.000069] [G loss: 0.999970]\n",
      "epoch:17 step:80235[D loss: 1.000008] [G loss: 1.000051]\n",
      "epoch:17 step:80240[D loss: 1.000012] [G loss: 1.000085]\n",
      "epoch:17 step:80245[D loss: 0.999912] [G loss: 1.000113]\n",
      "epoch:17 step:80250[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:17 step:80255[D loss: 0.999985] [G loss: 1.000128]\n",
      "epoch:17 step:80260[D loss: 0.999926] [G loss: 1.000099]\n",
      "epoch:17 step:80265[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:17 step:80270[D loss: 1.000016] [G loss: 1.000019]\n",
      "epoch:17 step:80275[D loss: 0.999964] [G loss: 1.000041]\n",
      "epoch:17 step:80280[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:17 step:80285[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:17 step:80290[D loss: 1.000017] [G loss: 1.000006]\n",
      "epoch:17 step:80295[D loss: 1.000000] [G loss: 0.999990]\n",
      "epoch:17 step:80300[D loss: 0.999983] [G loss: 1.000016]\n",
      "epoch:17 step:80305[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:17 step:80310[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:17 step:80315[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:17 step:80320[D loss: 0.999957] [G loss: 1.000041]\n",
      "epoch:17 step:80325[D loss: 1.000006] [G loss: 0.999967]\n",
      "epoch:17 step:80330[D loss: 0.999984] [G loss: 1.000005]\n",
      "epoch:17 step:80335[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:17 step:80340[D loss: 0.999994] [G loss: 1.000009]\n",
      "epoch:17 step:80345[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:17 step:80350[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:17 step:80355[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:17 step:80360[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:17 step:80365[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:17 step:80370[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:17 step:80375[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:17 step:80380[D loss: 1.000007] [G loss: 1.000067]\n",
      "epoch:17 step:80385[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:17 step:80390[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:17 step:80395[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:17 step:80400[D loss: 0.999972] [G loss: 1.000055]\n",
      "##############\n",
      "[2.62242082 2.18816802 2.2470028  3.89085791 1.49529877 7.58691465\n",
      " 2.32899836 3.80563039 4.03682792 5.67491946]\n",
      "##########\n",
      "epoch:17 step:80405[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:17 step:80410[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:17 step:80415[D loss: 0.999962] [G loss: 1.000044]\n",
      "epoch:17 step:80420[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:17 step:80425[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:17 step:80430[D loss: 1.000031] [G loss: 0.999998]\n",
      "epoch:17 step:80435[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:17 step:80440[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:17 step:80445[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:17 step:80450[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:17 step:80455[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:17 step:80460[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:17 step:80465[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:17 step:80470[D loss: 1.000033] [G loss: 1.000006]\n",
      "epoch:17 step:80475[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:17 step:80480[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:17 step:80485[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:17 step:80490[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:17 step:80495[D loss: 1.000024] [G loss: 0.999984]\n",
      "epoch:17 step:80500[D loss: 0.999943] [G loss: 1.000106]\n",
      "epoch:17 step:80505[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:17 step:80510[D loss: 0.999961] [G loss: 1.000047]\n",
      "epoch:17 step:80515[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:17 step:80520[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:17 step:80525[D loss: 0.999964] [G loss: 1.000050]\n",
      "epoch:17 step:80530[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:17 step:80535[D loss: 1.000009] [G loss: 1.000064]\n",
      "epoch:17 step:80540[D loss: 0.999945] [G loss: 1.000132]\n",
      "epoch:17 step:80545[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:17 step:80550[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:17 step:80555[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:17 step:80560[D loss: 1.000004] [G loss: 1.000017]\n",
      "epoch:17 step:80565[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:17 step:80570[D loss: 1.000001] [G loss: 1.000021]\n",
      "epoch:17 step:80575[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:17 step:80580[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:17 step:80585[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:17 step:80590[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:17 step:80595[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:17 step:80600[D loss: 0.999997] [G loss: 1.000031]\n",
      "##############\n",
      "[2.57483696 2.20354852 2.35028648 3.97130615 1.50702012 7.43072008\n",
      " 2.38480412 3.84032105 3.99539604 6.87689619]\n",
      "##########\n",
      "epoch:17 step:80605[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:17 step:80610[D loss: 1.000012] [G loss: 1.000039]\n",
      "epoch:17 step:80615[D loss: 0.999979] [G loss: 1.000053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:80620[D loss: 0.999937] [G loss: 1.000123]\n",
      "epoch:17 step:80625[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:17 step:80630[D loss: 1.000032] [G loss: 1.000024]\n",
      "epoch:17 step:80635[D loss: 1.000055] [G loss: 1.000033]\n",
      "epoch:17 step:80640[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:17 step:80645[D loss: 0.999980] [G loss: 1.000158]\n",
      "epoch:17 step:80650[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:17 step:80655[D loss: 0.999919] [G loss: 1.000157]\n",
      "epoch:17 step:80660[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:17 step:80665[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:17 step:80670[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:17 step:80675[D loss: 0.999996] [G loss: 1.000013]\n",
      "epoch:17 step:80680[D loss: 1.000047] [G loss: 0.999990]\n",
      "epoch:17 step:80685[D loss: 0.999941] [G loss: 1.000034]\n",
      "epoch:17 step:80690[D loss: 1.000035] [G loss: 0.999987]\n",
      "epoch:17 step:80695[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:17 step:80700[D loss: 0.999929] [G loss: 1.000094]\n",
      "epoch:17 step:80705[D loss: 0.999949] [G loss: 1.000071]\n",
      "epoch:17 step:80710[D loss: 0.999951] [G loss: 1.000069]\n",
      "epoch:17 step:80715[D loss: 0.999969] [G loss: 1.000117]\n",
      "epoch:17 step:80720[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:17 step:80725[D loss: 1.000031] [G loss: 1.000002]\n",
      "epoch:17 step:80730[D loss: 1.000080] [G loss: 1.000119]\n",
      "epoch:17 step:80735[D loss: 0.999940] [G loss: 1.000115]\n",
      "epoch:17 step:80740[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:17 step:80745[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:17 step:80750[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:17 step:80755[D loss: 1.000036] [G loss: 0.999964]\n",
      "epoch:17 step:80760[D loss: 1.000038] [G loss: 0.999986]\n",
      "epoch:17 step:80765[D loss: 0.999984] [G loss: 0.999970]\n",
      "epoch:17 step:80770[D loss: 0.999970] [G loss: 1.000108]\n",
      "epoch:17 step:80775[D loss: 1.000028] [G loss: 1.000062]\n",
      "epoch:17 step:80780[D loss: 1.000026] [G loss: 1.000063]\n",
      "epoch:17 step:80785[D loss: 0.999925] [G loss: 1.000122]\n",
      "epoch:17 step:80790[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:17 step:80795[D loss: 1.000034] [G loss: 0.999988]\n",
      "epoch:17 step:80800[D loss: 0.999926] [G loss: 1.000142]\n",
      "##############\n",
      "[2.53361833 2.06327819 2.26277214 3.70928948 1.45776204 7.42650398\n",
      " 2.34887879 3.69309582 3.99669887 5.94479372]\n",
      "##########\n",
      "epoch:17 step:80805[D loss: 0.999965] [G loss: 1.000019]\n",
      "epoch:17 step:80810[D loss: 0.999978] [G loss: 1.000113]\n",
      "epoch:17 step:80815[D loss: 0.999978] [G loss: 1.000106]\n",
      "epoch:17 step:80820[D loss: 0.999973] [G loss: 1.000132]\n",
      "epoch:17 step:80825[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:17 step:80830[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:17 step:80835[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:17 step:80840[D loss: 1.000053] [G loss: 0.999945]\n",
      "epoch:17 step:80845[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:17 step:80850[D loss: 1.000005] [G loss: 1.000082]\n",
      "epoch:17 step:80855[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:17 step:80860[D loss: 0.999944] [G loss: 1.000101]\n",
      "epoch:17 step:80865[D loss: 0.999981] [G loss: 1.000130]\n",
      "epoch:17 step:80870[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:17 step:80875[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:17 step:80880[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:17 step:80885[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:17 step:80890[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:17 step:80895[D loss: 0.999991] [G loss: 1.000075]\n",
      "epoch:17 step:80900[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:17 step:80905[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:17 step:80910[D loss: 0.999968] [G loss: 1.000126]\n",
      "epoch:17 step:80915[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:17 step:80920[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:17 step:80925[D loss: 0.999998] [G loss: 1.000059]\n",
      "epoch:17 step:80930[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:17 step:80935[D loss: 1.000041] [G loss: 1.000013]\n",
      "epoch:17 step:80940[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:17 step:80945[D loss: 1.000045] [G loss: 0.999940]\n",
      "epoch:17 step:80950[D loss: 0.999941] [G loss: 1.000093]\n",
      "epoch:17 step:80955[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:17 step:80960[D loss: 1.000019] [G loss: 1.000036]\n",
      "epoch:17 step:80965[D loss: 0.999939] [G loss: 1.000099]\n",
      "epoch:17 step:80970[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:17 step:80975[D loss: 1.000051] [G loss: 0.999998]\n",
      "epoch:17 step:80980[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:17 step:80985[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:17 step:80990[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:17 step:80995[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:17 step:81000[D loss: 0.999956] [G loss: 1.000094]\n",
      "##############\n",
      "[2.5395275  2.03577639 2.24396114 4.13440413 1.43877664 8.46774983\n",
      " 2.41878383 3.80189068 3.96996289 6.28704347]\n",
      "##########\n",
      "epoch:17 step:81005[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:17 step:81010[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:17 step:81015[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:17 step:81020[D loss: 1.000031] [G loss: 0.999942]\n",
      "epoch:17 step:81025[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:17 step:81030[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:17 step:81035[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:17 step:81040[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:17 step:81045[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:17 step:81050[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:17 step:81055[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:17 step:81060[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:17 step:81065[D loss: 1.000006] [G loss: 1.000063]\n",
      "epoch:17 step:81070[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:17 step:81075[D loss: 0.999933] [G loss: 1.000088]\n",
      "epoch:17 step:81080[D loss: 0.999987] [G loss: 1.000000]\n",
      "epoch:17 step:81085[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:17 step:81090[D loss: 0.999978] [G loss: 1.000107]\n",
      "epoch:17 step:81095[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:17 step:81100[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:17 step:81105[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:17 step:81110[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:17 step:81115[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:17 step:81120[D loss: 0.999948] [G loss: 1.000165]\n",
      "epoch:17 step:81125[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:17 step:81130[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:17 step:81135[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:17 step:81140[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:17 step:81145[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:17 step:81150[D loss: 0.999887] [G loss: 1.000156]\n",
      "epoch:17 step:81155[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:17 step:81160[D loss: 0.999998] [G loss: 1.000084]\n",
      "epoch:17 step:81165[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:17 step:81170[D loss: 1.000015] [G loss: 1.000028]\n",
      "epoch:17 step:81175[D loss: 0.999987] [G loss: 1.000099]\n",
      "epoch:17 step:81180[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:17 step:81185[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:17 step:81190[D loss: 1.000066] [G loss: 0.999967]\n",
      "epoch:17 step:81195[D loss: 0.999962] [G loss: 1.000111]\n",
      "epoch:17 step:81200[D loss: 0.999954] [G loss: 1.000132]\n",
      "##############\n",
      "[2.49443659 1.98063661 1.96803187 3.74409802 1.39876112 7.51629102\n",
      " 2.14729159 3.57574053 3.83699511 4.98853319]\n",
      "##########\n",
      "epoch:17 step:81205[D loss: 0.999968] [G loss: 1.000030]\n",
      "epoch:17 step:81210[D loss: 0.999950] [G loss: 1.000111]\n",
      "epoch:17 step:81215[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:17 step:81220[D loss: 0.999980] [G loss: 1.000122]\n",
      "epoch:17 step:81225[D loss: 1.000096] [G loss: 0.999980]\n",
      "epoch:17 step:81230[D loss: 0.999936] [G loss: 1.000014]\n",
      "epoch:17 step:81235[D loss: 1.000018] [G loss: 1.000014]\n",
      "epoch:17 step:81240[D loss: 0.999963] [G loss: 1.000028]\n",
      "epoch:17 step:81245[D loss: 1.000002] [G loss: 1.000006]\n",
      "epoch:17 step:81250[D loss: 1.000091] [G loss: 0.999930]\n",
      "epoch:17 step:81255[D loss: 1.000060] [G loss: 0.999929]\n",
      "epoch:17 step:81260[D loss: 1.000076] [G loss: 0.999919]\n",
      "epoch:17 step:81265[D loss: 0.999875] [G loss: 1.000107]\n",
      "epoch:17 step:81270[D loss: 0.999913] [G loss: 1.000115]\n",
      "epoch:17 step:81275[D loss: 0.999947] [G loss: 1.000091]\n",
      "epoch:17 step:81280[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:17 step:81285[D loss: 0.999945] [G loss: 1.000065]\n",
      "epoch:17 step:81290[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:17 step:81295[D loss: 1.000021] [G loss: 1.000047]\n",
      "epoch:17 step:81300[D loss: 0.999920] [G loss: 1.000138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:81305[D loss: 0.999977] [G loss: 1.000019]\n",
      "epoch:17 step:81310[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:17 step:81315[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:17 step:81320[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:17 step:81325[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:17 step:81330[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:17 step:81335[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:17 step:81340[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:17 step:81345[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:17 step:81350[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:17 step:81355[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:17 step:81360[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:17 step:81365[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:17 step:81370[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:17 step:81375[D loss: 1.000020] [G loss: 1.000065]\n",
      "epoch:17 step:81380[D loss: 0.999952] [G loss: 1.000065]\n",
      "epoch:17 step:81385[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:17 step:81390[D loss: 0.999997] [G loss: 1.000013]\n",
      "epoch:17 step:81395[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:17 step:81400[D loss: 0.999993] [G loss: 1.000059]\n",
      "##############\n",
      "[2.64146704 2.15052236 2.23748811 3.88349408 1.50362452 7.63152\n",
      " 2.37878458 3.80374127 4.06136971 5.5535944 ]\n",
      "##########\n",
      "epoch:17 step:81405[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:17 step:81410[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:17 step:81415[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:17 step:81420[D loss: 0.999991] [G loss: 1.000020]\n",
      "epoch:17 step:81425[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:17 step:81430[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:17 step:81435[D loss: 0.999980] [G loss: 1.000143]\n",
      "epoch:17 step:81440[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:17 step:81445[D loss: 1.000007] [G loss: 1.000085]\n",
      "epoch:17 step:81450[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:17 step:81455[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:17 step:81460[D loss: 1.000035] [G loss: 0.999990]\n",
      "epoch:17 step:81465[D loss: 1.000086] [G loss: 0.999967]\n",
      "epoch:17 step:81470[D loss: 1.000068] [G loss: 0.999913]\n",
      "epoch:17 step:81475[D loss: 0.999903] [G loss: 1.000162]\n",
      "epoch:17 step:81480[D loss: 0.999915] [G loss: 1.000242]\n",
      "epoch:17 step:81485[D loss: 0.999940] [G loss: 1.000127]\n",
      "epoch:17 step:81490[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:17 step:81495[D loss: 0.999951] [G loss: 1.000122]\n",
      "epoch:17 step:81500[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:17 step:81505[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:17 step:81510[D loss: 0.999993] [G loss: 1.000037]\n",
      "epoch:17 step:81515[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:17 step:81520[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:17 step:81525[D loss: 1.000015] [G loss: 0.999993]\n",
      "epoch:17 step:81530[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:17 step:81535[D loss: 1.000057] [G loss: 1.000005]\n",
      "epoch:17 step:81540[D loss: 1.000008] [G loss: 0.999981]\n",
      "epoch:17 step:81545[D loss: 0.999957] [G loss: 0.999997]\n",
      "epoch:17 step:81550[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:17 step:81555[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:17 step:81560[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:17 step:81565[D loss: 0.999985] [G loss: 1.000012]\n",
      "epoch:17 step:81570[D loss: 1.000043] [G loss: 1.000005]\n",
      "epoch:17 step:81575[D loss: 0.999881] [G loss: 1.000149]\n",
      "epoch:17 step:81580[D loss: 1.000046] [G loss: 1.000026]\n",
      "epoch:17 step:81585[D loss: 1.000003] [G loss: 1.000065]\n",
      "epoch:17 step:81590[D loss: 0.999979] [G loss: 1.000025]\n",
      "epoch:17 step:81595[D loss: 0.999999] [G loss: 1.000070]\n",
      "epoch:17 step:81600[D loss: 0.999955] [G loss: 1.000088]\n",
      "##############\n",
      "[2.56375259 2.204737   2.25180712 3.8958884  1.56473395 7.4959863\n",
      " 2.24711041 3.85166755 4.05315161 5.49350049]\n",
      "##########\n",
      "epoch:17 step:81605[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:17 step:81610[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:17 step:81615[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:17 step:81620[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:17 step:81625[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:17 step:81630[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:17 step:81635[D loss: 0.999993] [G loss: 1.000026]\n",
      "epoch:17 step:81640[D loss: 1.000051] [G loss: 0.999975]\n",
      "epoch:17 step:81645[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:17 step:81650[D loss: 1.000025] [G loss: 0.999971]\n",
      "epoch:17 step:81655[D loss: 0.999970] [G loss: 1.000102]\n",
      "epoch:17 step:81660[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:17 step:81665[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:17 step:81670[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:17 step:81675[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:17 step:81680[D loss: 1.000032] [G loss: 1.000021]\n",
      "epoch:17 step:81685[D loss: 0.999919] [G loss: 1.000101]\n",
      "epoch:17 step:81690[D loss: 1.000010] [G loss: 1.000003]\n",
      "epoch:17 step:81695[D loss: 1.000101] [G loss: 0.999946]\n",
      "epoch:17 step:81700[D loss: 0.999993] [G loss: 1.000015]\n",
      "epoch:17 step:81705[D loss: 0.999964] [G loss: 1.000009]\n",
      "epoch:17 step:81710[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:17 step:81715[D loss: 0.999943] [G loss: 1.000087]\n",
      "epoch:17 step:81720[D loss: 1.000007] [G loss: 1.000046]\n",
      "epoch:17 step:81725[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:17 step:81730[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:17 step:81735[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:17 step:81740[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:17 step:81745[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:17 step:81750[D loss: 1.000001] [G loss: 1.000041]\n",
      "epoch:17 step:81755[D loss: 1.000008] [G loss: 1.000086]\n",
      "epoch:17 step:81760[D loss: 0.999930] [G loss: 1.000130]\n",
      "epoch:17 step:81765[D loss: 0.999952] [G loss: 1.000118]\n",
      "epoch:17 step:81770[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:17 step:81775[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:17 step:81780[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:17 step:81785[D loss: 1.000011] [G loss: 0.999960]\n",
      "epoch:17 step:81790[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:17 step:81795[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:17 step:81800[D loss: 0.999988] [G loss: 1.000039]\n",
      "##############\n",
      "[2.56539243 2.07049827 2.14024372 3.77492575 1.49129152 7.61072458\n",
      " 2.53056176 3.76579944 4.07894814 5.21720125]\n",
      "##########\n",
      "epoch:17 step:81805[D loss: 1.000024] [G loss: 1.000032]\n",
      "epoch:17 step:81810[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:17 step:81815[D loss: 1.000010] [G loss: 1.000036]\n",
      "epoch:17 step:81820[D loss: 1.000022] [G loss: 1.000019]\n",
      "epoch:17 step:81825[D loss: 0.999956] [G loss: 1.000053]\n",
      "epoch:17 step:81830[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:17 step:81835[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:17 step:81840[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:17 step:81845[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:17 step:81850[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:17 step:81855[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:17 step:81860[D loss: 0.999956] [G loss: 1.000054]\n",
      "epoch:17 step:81865[D loss: 1.000037] [G loss: 0.999985]\n",
      "epoch:17 step:81870[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:17 step:81875[D loss: 1.000060] [G loss: 1.000040]\n",
      "epoch:17 step:81880[D loss: 0.999995] [G loss: 1.000162]\n",
      "epoch:17 step:81885[D loss: 0.999973] [G loss: 1.000223]\n",
      "epoch:17 step:81890[D loss: 0.999952] [G loss: 1.000110]\n",
      "epoch:17 step:81895[D loss: 0.999931] [G loss: 1.000162]\n",
      "epoch:17 step:81900[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:17 step:81905[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:17 step:81910[D loss: 0.999985] [G loss: 1.000015]\n",
      "epoch:17 step:81915[D loss: 1.000015] [G loss: 1.000005]\n",
      "epoch:17 step:81920[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:17 step:81925[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:17 step:81930[D loss: 1.000053] [G loss: 1.000024]\n",
      "epoch:17 step:81935[D loss: 1.000018] [G loss: 0.999970]\n",
      "epoch:17 step:81940[D loss: 1.000143] [G loss: 1.000010]\n",
      "epoch:17 step:81945[D loss: 0.999994] [G loss: 0.999991]\n",
      "epoch:17 step:81950[D loss: 1.000027] [G loss: 0.999967]\n",
      "epoch:17 step:81955[D loss: 0.999923] [G loss: 1.000127]\n",
      "epoch:17 step:81960[D loss: 0.999947] [G loss: 1.000102]\n",
      "epoch:17 step:81965[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:17 step:81970[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:17 step:81975[D loss: 0.999990] [G loss: 1.000007]\n",
      "epoch:17 step:81980[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:17 step:81985[D loss: 1.000037] [G loss: 1.000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:81990[D loss: 1.000076] [G loss: 1.000012]\n",
      "epoch:17 step:81995[D loss: 0.999908] [G loss: 1.000145]\n",
      "epoch:17 step:82000[D loss: 1.000040] [G loss: 1.000087]\n",
      "##############\n",
      "[2.54164547 2.20435221 2.12665536 3.56369615 1.50233788 7.73176712\n",
      " 2.22384259 3.59146558 3.955552   7.14868929]\n",
      "##########\n",
      "epoch:17 step:82005[D loss: 0.999870] [G loss: 1.000224]\n",
      "epoch:17 step:82010[D loss: 0.999960] [G loss: 1.000105]\n",
      "epoch:17 step:82015[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:17 step:82020[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:17 step:82025[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:17 step:82030[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:17 step:82035[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:17 step:82040[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:17 step:82045[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:17 step:82050[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:17 step:82055[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:17 step:82060[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:17 step:82065[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:17 step:82070[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:17 step:82075[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:17 step:82080[D loss: 0.999941] [G loss: 1.000098]\n",
      "epoch:17 step:82085[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:17 step:82090[D loss: 1.000001] [G loss: 1.000047]\n",
      "epoch:17 step:82095[D loss: 0.999983] [G loss: 1.000112]\n",
      "epoch:17 step:82100[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:17 step:82105[D loss: 0.999963] [G loss: 1.000122]\n",
      "epoch:17 step:82110[D loss: 0.999980] [G loss: 1.000186]\n",
      "epoch:17 step:82115[D loss: 1.000003] [G loss: 1.000092]\n",
      "epoch:17 step:82120[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:17 step:82125[D loss: 1.000026] [G loss: 1.000143]\n",
      "epoch:17 step:82130[D loss: 0.999942] [G loss: 1.000175]\n",
      "epoch:17 step:82135[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:17 step:82140[D loss: 1.000014] [G loss: 1.000000]\n",
      "epoch:17 step:82145[D loss: 1.000061] [G loss: 0.999967]\n",
      "epoch:17 step:82150[D loss: 0.999932] [G loss: 1.000067]\n",
      "epoch:17 step:82155[D loss: 1.000007] [G loss: 0.999995]\n",
      "epoch:17 step:82160[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:17 step:82165[D loss: 1.000000] [G loss: 1.000081]\n",
      "epoch:17 step:82170[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:17 step:82175[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:17 step:82180[D loss: 1.000035] [G loss: 1.000050]\n",
      "epoch:17 step:82185[D loss: 1.000013] [G loss: 1.000067]\n",
      "epoch:17 step:82190[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:17 step:82195[D loss: 1.000154] [G loss: 0.999967]\n",
      "epoch:17 step:82200[D loss: 0.999982] [G loss: 1.000077]\n",
      "##############\n",
      "[2.51536989 2.13652133 2.28178482 3.93501879 1.48803951 7.83644764\n",
      " 2.19927135 3.90016205 4.01077751 5.32178779]\n",
      "##########\n",
      "epoch:17 step:82205[D loss: 0.999934] [G loss: 1.000102]\n",
      "epoch:17 step:82210[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:17 step:82215[D loss: 0.999929] [G loss: 1.000087]\n",
      "epoch:17 step:82220[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:17 step:82225[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:17 step:82230[D loss: 1.000052] [G loss: 0.999971]\n",
      "epoch:17 step:82235[D loss: 0.999901] [G loss: 1.000161]\n",
      "epoch:17 step:82240[D loss: 0.999926] [G loss: 1.000139]\n",
      "epoch:17 step:82245[D loss: 1.000006] [G loss: 1.000064]\n",
      "epoch:17 step:82250[D loss: 1.000010] [G loss: 1.000027]\n",
      "epoch:17 step:82255[D loss: 0.999967] [G loss: 1.000113]\n",
      "epoch:17 step:82260[D loss: 0.999970] [G loss: 1.000100]\n",
      "epoch:17 step:82265[D loss: 0.999988] [G loss: 1.000098]\n",
      "epoch:17 step:82270[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:17 step:82275[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:17 step:82280[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:17 step:82285[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:17 step:82290[D loss: 0.999996] [G loss: 1.000058]\n",
      "epoch:17 step:82295[D loss: 0.999994] [G loss: 1.000103]\n",
      "epoch:17 step:82300[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:17 step:82305[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:17 step:82310[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:17 step:82315[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:17 step:82320[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:17 step:82325[D loss: 0.999960] [G loss: 1.000120]\n",
      "epoch:17 step:82330[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:17 step:82335[D loss: 0.999955] [G loss: 1.000125]\n",
      "epoch:17 step:82340[D loss: 1.000018] [G loss: 1.000003]\n",
      "epoch:17 step:82345[D loss: 0.999992] [G loss: 0.999984]\n",
      "epoch:17 step:82350[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:17 step:82355[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:17 step:82360[D loss: 1.000050] [G loss: 0.999990]\n",
      "epoch:17 step:82365[D loss: 0.999999] [G loss: 1.000088]\n",
      "epoch:17 step:82370[D loss: 0.999949] [G loss: 1.000151]\n",
      "epoch:17 step:82375[D loss: 1.000042] [G loss: 1.000018]\n",
      "epoch:17 step:82380[D loss: 0.999921] [G loss: 1.000095]\n",
      "epoch:17 step:82385[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:17 step:82390[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:17 step:82395[D loss: 1.000055] [G loss: 0.999993]\n",
      "epoch:17 step:82400[D loss: 0.999989] [G loss: 1.000023]\n",
      "##############\n",
      "[2.5033003  2.10112599 2.14531507 3.80579986 1.42750004 7.85077106\n",
      " 2.21950131 3.75296879 3.9111923  5.17518872]\n",
      "##########\n",
      "epoch:17 step:82405[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:17 step:82410[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:17 step:82415[D loss: 0.999998] [G loss: 1.000010]\n",
      "epoch:17 step:82420[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:17 step:82425[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:17 step:82430[D loss: 0.999982] [G loss: 1.000027]\n",
      "epoch:17 step:82435[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:17 step:82440[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:17 step:82445[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:17 step:82450[D loss: 0.999959] [G loss: 1.000125]\n",
      "epoch:17 step:82455[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:17 step:82460[D loss: 0.999950] [G loss: 1.000167]\n",
      "epoch:17 step:82465[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:17 step:82470[D loss: 0.999992] [G loss: 1.000061]\n",
      "epoch:17 step:82475[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:17 step:82480[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:17 step:82485[D loss: 1.000006] [G loss: 0.999997]\n",
      "epoch:17 step:82490[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:17 step:82495[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:17 step:82500[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:17 step:82505[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:17 step:82510[D loss: 1.000017] [G loss: 1.000063]\n",
      "epoch:17 step:82515[D loss: 0.999996] [G loss: 0.999996]\n",
      "epoch:17 step:82520[D loss: 0.999954] [G loss: 1.000150]\n",
      "epoch:17 step:82525[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:17 step:82530[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:17 step:82535[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:17 step:82540[D loss: 1.000008] [G loss: 1.000032]\n",
      "epoch:17 step:82545[D loss: 1.000026] [G loss: 1.000052]\n",
      "epoch:17 step:82550[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:17 step:82555[D loss: 1.000037] [G loss: 1.000005]\n",
      "epoch:17 step:82560[D loss: 1.000009] [G loss: 1.000014]\n",
      "epoch:17 step:82565[D loss: 0.999922] [G loss: 1.000096]\n",
      "epoch:17 step:82570[D loss: 1.000018] [G loss: 0.999993]\n",
      "epoch:17 step:82575[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:17 step:82580[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:17 step:82585[D loss: 1.000040] [G loss: 1.000001]\n",
      "epoch:17 step:82590[D loss: 1.000002] [G loss: 1.000124]\n",
      "epoch:17 step:82595[D loss: 0.999915] [G loss: 1.000104]\n",
      "epoch:17 step:82600[D loss: 0.999965] [G loss: 1.000070]\n",
      "##############\n",
      "[2.493181   2.20346082 2.24807598 3.85825676 1.55836572 7.33379097\n",
      " 2.49390728 3.85985017 4.03383723 5.26693678]\n",
      "##########\n",
      "epoch:17 step:82605[D loss: 1.000042] [G loss: 1.000022]\n",
      "epoch:17 step:82610[D loss: 1.000092] [G loss: 0.999888]\n",
      "epoch:17 step:82615[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:17 step:82620[D loss: 1.000113] [G loss: 1.000009]\n",
      "epoch:17 step:82625[D loss: 1.000059] [G loss: 0.999953]\n",
      "epoch:17 step:82630[D loss: 0.999908] [G loss: 1.000101]\n",
      "epoch:17 step:82635[D loss: 0.999950] [G loss: 1.000151]\n",
      "epoch:17 step:82640[D loss: 0.999920] [G loss: 1.000153]\n",
      "epoch:17 step:82645[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:17 step:82650[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:17 step:82655[D loss: 0.999989] [G loss: 1.000031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:82660[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:17 step:82665[D loss: 1.000017] [G loss: 1.000033]\n",
      "epoch:17 step:82670[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:17 step:82675[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:17 step:82680[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:17 step:82685[D loss: 1.000007] [G loss: 1.000073]\n",
      "epoch:17 step:82690[D loss: 1.000089] [G loss: 1.000045]\n",
      "epoch:17 step:82695[D loss: 0.999991] [G loss: 0.999983]\n",
      "epoch:17 step:82700[D loss: 0.999983] [G loss: 1.000096]\n",
      "epoch:17 step:82705[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:17 step:82710[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:17 step:82715[D loss: 0.999989] [G loss: 0.999984]\n",
      "epoch:17 step:82720[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:17 step:82725[D loss: 0.999989] [G loss: 1.000019]\n",
      "epoch:17 step:82730[D loss: 1.000019] [G loss: 1.000076]\n",
      "epoch:17 step:82735[D loss: 1.000040] [G loss: 1.000012]\n",
      "epoch:17 step:82740[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:17 step:82745[D loss: 0.999998] [G loss: 1.000084]\n",
      "epoch:17 step:82750[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:17 step:82755[D loss: 1.000025] [G loss: 1.000031]\n",
      "epoch:17 step:82760[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:17 step:82765[D loss: 1.000002] [G loss: 1.000040]\n",
      "epoch:17 step:82770[D loss: 1.000062] [G loss: 0.999928]\n",
      "epoch:17 step:82775[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:17 step:82780[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:17 step:82785[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:17 step:82790[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:17 step:82795[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:17 step:82800[D loss: 0.999973] [G loss: 1.000060]\n",
      "##############\n",
      "[2.56774266 2.0678413  2.16619618 4.01016039 1.42852208 7.56156516\n",
      " 2.33267672 3.83232463 3.99762424 5.75438883]\n",
      "##########\n",
      "epoch:17 step:82805[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:17 step:82810[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:17 step:82815[D loss: 0.999980] [G loss: 1.000097]\n",
      "epoch:17 step:82820[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:17 step:82825[D loss: 0.999978] [G loss: 1.000025]\n",
      "epoch:17 step:82830[D loss: 1.000003] [G loss: 1.000020]\n",
      "epoch:17 step:82835[D loss: 0.999944] [G loss: 1.000078]\n",
      "epoch:17 step:82840[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:17 step:82845[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:17 step:82850[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:17 step:82855[D loss: 0.999975] [G loss: 1.000022]\n",
      "epoch:17 step:82860[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:17 step:82865[D loss: 1.000058] [G loss: 0.999900]\n",
      "epoch:17 step:82870[D loss: 1.000059] [G loss: 0.999848]\n",
      "epoch:17 step:82875[D loss: 1.000087] [G loss: 0.999898]\n",
      "epoch:17 step:82880[D loss: 0.999943] [G loss: 1.000082]\n",
      "epoch:17 step:82885[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:17 step:82890[D loss: 1.000012] [G loss: 1.000062]\n",
      "epoch:17 step:82895[D loss: 0.999927] [G loss: 1.000142]\n",
      "epoch:17 step:82900[D loss: 0.999995] [G loss: 1.000144]\n",
      "epoch:17 step:82905[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:17 step:82910[D loss: 0.999958] [G loss: 1.000146]\n",
      "epoch:17 step:82915[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:17 step:82920[D loss: 0.999984] [G loss: 0.999997]\n",
      "epoch:17 step:82925[D loss: 1.000006] [G loss: 0.999986]\n",
      "epoch:17 step:82930[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:17 step:82935[D loss: 0.999932] [G loss: 1.000070]\n",
      "epoch:17 step:82940[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:17 step:82945[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:17 step:82950[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:17 step:82955[D loss: 1.000059] [G loss: 0.999966]\n",
      "epoch:17 step:82960[D loss: 0.999958] [G loss: 1.000171]\n",
      "epoch:17 step:82965[D loss: 0.999939] [G loss: 1.000079]\n",
      "epoch:17 step:82970[D loss: 0.999960] [G loss: 1.000048]\n",
      "epoch:17 step:82975[D loss: 1.000008] [G loss: 1.000026]\n",
      "epoch:17 step:82980[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:17 step:82985[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:17 step:82990[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:17 step:82995[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:17 step:83000[D loss: 0.999971] [G loss: 1.000073]\n",
      "##############\n",
      "[2.53010021 2.03948563 2.12574174 4.09621121 1.53172274 7.38688892\n",
      " 2.15803871 3.83707418 3.96740645 5.28166559]\n",
      "##########\n",
      "epoch:17 step:83005[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:17 step:83010[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:17 step:83015[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:17 step:83020[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:17 step:83025[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:17 step:83030[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:17 step:83035[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:17 step:83040[D loss: 1.000054] [G loss: 0.999980]\n",
      "epoch:17 step:83045[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:17 step:83050[D loss: 0.999931] [G loss: 1.000085]\n",
      "epoch:17 step:83055[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:17 step:83060[D loss: 1.000007] [G loss: 1.000028]\n",
      "epoch:17 step:83065[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:17 step:83070[D loss: 1.000049] [G loss: 1.000028]\n",
      "epoch:17 step:83075[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:17 step:83080[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:17 step:83085[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:17 step:83090[D loss: 1.000019] [G loss: 1.000033]\n",
      "epoch:17 step:83095[D loss: 0.999932] [G loss: 1.000112]\n",
      "epoch:17 step:83100[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:17 step:83105[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:17 step:83110[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:17 step:83115[D loss: 1.000018] [G loss: 1.000002]\n",
      "epoch:17 step:83120[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:17 step:83125[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:17 step:83130[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:17 step:83135[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:17 step:83140[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:17 step:83145[D loss: 0.999940] [G loss: 1.000086]\n",
      "epoch:17 step:83150[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:17 step:83155[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:17 step:83160[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:17 step:83165[D loss: 1.000021] [G loss: 0.999938]\n",
      "epoch:17 step:83170[D loss: 0.999962] [G loss: 1.000128]\n",
      "epoch:17 step:83175[D loss: 0.999970] [G loss: 1.000116]\n",
      "epoch:17 step:83180[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:17 step:83185[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:17 step:83190[D loss: 1.000054] [G loss: 0.999974]\n",
      "epoch:17 step:83195[D loss: 1.000052] [G loss: 1.000015]\n",
      "epoch:17 step:83200[D loss: 0.999927] [G loss: 1.000098]\n",
      "##############\n",
      "[2.53728275 2.10851012 2.22428534 4.11860165 1.5177654  7.73426914\n",
      " 2.19636098 3.79420029 3.99800301 5.78983583]\n",
      "##########\n",
      "epoch:17 step:83205[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:17 step:83210[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:17 step:83215[D loss: 1.000008] [G loss: 1.000095]\n",
      "epoch:17 step:83220[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:17 step:83225[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:17 step:83230[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:17 step:83235[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:17 step:83240[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:17 step:83245[D loss: 1.000003] [G loss: 1.000018]\n",
      "epoch:17 step:83250[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:17 step:83255[D loss: 1.000003] [G loss: 1.000069]\n",
      "epoch:17 step:83260[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:17 step:83265[D loss: 0.999965] [G loss: 1.000121]\n",
      "epoch:17 step:83270[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:17 step:83275[D loss: 0.999950] [G loss: 1.000079]\n",
      "epoch:17 step:83280[D loss: 1.000006] [G loss: 1.000052]\n",
      "epoch:17 step:83285[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:17 step:83290[D loss: 0.999944] [G loss: 1.000084]\n",
      "epoch:17 step:83295[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:17 step:83300[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:17 step:83305[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:17 step:83310[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:17 step:83315[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:17 step:83320[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:17 step:83325[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:17 step:83330[D loss: 1.000010] [G loss: 1.000007]\n",
      "epoch:17 step:83335[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:17 step:83340[D loss: 0.999991] [G loss: 1.000108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:83345[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:17 step:83350[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:17 step:83355[D loss: 0.999992] [G loss: 1.000124]\n",
      "epoch:17 step:83360[D loss: 0.999933] [G loss: 1.000064]\n",
      "epoch:17 step:83365[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:17 step:83370[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:17 step:83375[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:17 step:83380[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:17 step:83385[D loss: 1.000001] [G loss: 1.000046]\n",
      "epoch:17 step:83390[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:17 step:83395[D loss: 1.000034] [G loss: 0.999988]\n",
      "epoch:17 step:83400[D loss: 0.999993] [G loss: 1.000083]\n",
      "##############\n",
      "[2.55635022 2.14763083 2.21528423 4.10403109 1.49271436 7.15178394\n",
      " 2.27965787 3.88939694 4.02351721 5.90419641]\n",
      "##########\n",
      "epoch:17 step:83405[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:17 step:83410[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:17 step:83415[D loss: 0.999985] [G loss: 1.000125]\n",
      "epoch:17 step:83420[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:17 step:83425[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:17 step:83430[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:17 step:83435[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:17 step:83440[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:17 step:83445[D loss: 1.000077] [G loss: 0.999904]\n",
      "epoch:17 step:83450[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:17 step:83455[D loss: 1.000027] [G loss: 1.000083]\n",
      "epoch:17 step:83460[D loss: 0.999969] [G loss: 1.000024]\n",
      "epoch:17 step:83465[D loss: 0.999916] [G loss: 1.000166]\n",
      "epoch:17 step:83470[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:17 step:83475[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:17 step:83480[D loss: 0.999964] [G loss: 1.000104]\n",
      "epoch:17 step:83485[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:17 step:83490[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:17 step:83495[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:17 step:83500[D loss: 1.000038] [G loss: 0.999985]\n",
      "epoch:17 step:83505[D loss: 0.999950] [G loss: 1.000108]\n",
      "epoch:17 step:83510[D loss: 1.000029] [G loss: 0.999997]\n",
      "epoch:17 step:83515[D loss: 1.000060] [G loss: 0.999982]\n",
      "epoch:17 step:83520[D loss: 0.999935] [G loss: 1.000099]\n",
      "epoch:17 step:83525[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:17 step:83530[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:17 step:83535[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:17 step:83540[D loss: 1.000049] [G loss: 0.999937]\n",
      "epoch:17 step:83545[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:17 step:83550[D loss: 0.999926] [G loss: 1.000026]\n",
      "epoch:17 step:83555[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:17 step:83560[D loss: 0.999997] [G loss: 1.000084]\n",
      "epoch:17 step:83565[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:17 step:83570[D loss: 0.999988] [G loss: 1.000110]\n",
      "epoch:17 step:83575[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:17 step:83580[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:17 step:83585[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:17 step:83590[D loss: 1.000006] [G loss: 1.000072]\n",
      "epoch:17 step:83595[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:17 step:83600[D loss: 0.999992] [G loss: 1.000015]\n",
      "##############\n",
      "[2.5426806  2.12243985 2.07906788 3.87174512 1.4836751  8.0360559\n",
      " 2.26299165 3.75897392 3.96468625 5.1418799 ]\n",
      "##########\n",
      "epoch:17 step:83605[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:17 step:83610[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:17 step:83615[D loss: 0.999993] [G loss: 1.000010]\n",
      "epoch:17 step:83620[D loss: 1.000015] [G loss: 1.000020]\n",
      "epoch:17 step:83625[D loss: 1.000025] [G loss: 0.999963]\n",
      "epoch:17 step:83630[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:17 step:83635[D loss: 0.999979] [G loss: 1.000120]\n",
      "epoch:17 step:83640[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:17 step:83645[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:17 step:83650[D loss: 1.000006] [G loss: 1.000019]\n",
      "epoch:17 step:83655[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:17 step:83660[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:17 step:83665[D loss: 0.999959] [G loss: 1.000115]\n",
      "epoch:17 step:83670[D loss: 1.000025] [G loss: 1.000010]\n",
      "epoch:17 step:83675[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:17 step:83680[D loss: 1.000024] [G loss: 1.000081]\n",
      "epoch:17 step:83685[D loss: 1.000048] [G loss: 1.000028]\n",
      "epoch:17 step:83690[D loss: 0.999969] [G loss: 1.000032]\n",
      "epoch:17 step:83695[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:17 step:83700[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:17 step:83705[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:17 step:83710[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:17 step:83715[D loss: 1.000006] [G loss: 1.000018]\n",
      "epoch:17 step:83720[D loss: 0.999940] [G loss: 1.000066]\n",
      "epoch:17 step:83725[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:17 step:83730[D loss: 0.999941] [G loss: 1.000070]\n",
      "epoch:17 step:83735[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:17 step:83740[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:17 step:83745[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:17 step:83750[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:17 step:83755[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:17 step:83760[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:17 step:83765[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:17 step:83770[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:17 step:83775[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:17 step:83780[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:17 step:83785[D loss: 0.999950] [G loss: 1.000084]\n",
      "epoch:17 step:83790[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:17 step:83795[D loss: 1.000008] [G loss: 1.000048]\n",
      "epoch:17 step:83800[D loss: 0.999966] [G loss: 1.000111]\n",
      "##############\n",
      "[2.58446571 2.0288927  2.32934213 3.82956515 1.49821929 6.94548774\n",
      " 2.37874917 3.73326699 4.09561284 5.551409  ]\n",
      "##########\n",
      "epoch:17 step:83805[D loss: 1.000063] [G loss: 0.999978]\n",
      "epoch:17 step:83810[D loss: 1.000002] [G loss: 0.999972]\n",
      "epoch:17 step:83815[D loss: 1.000022] [G loss: 1.000076]\n",
      "epoch:17 step:83820[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:17 step:83825[D loss: 0.999930] [G loss: 1.000067]\n",
      "epoch:17 step:83830[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:17 step:83835[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:17 step:83840[D loss: 1.000010] [G loss: 1.000050]\n",
      "epoch:17 step:83845[D loss: 0.999949] [G loss: 1.000060]\n",
      "epoch:17 step:83850[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:17 step:83855[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:17 step:83860[D loss: 0.999934] [G loss: 1.000110]\n",
      "epoch:17 step:83865[D loss: 1.000000] [G loss: 1.000102]\n",
      "epoch:17 step:83870[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:17 step:83875[D loss: 0.999946] [G loss: 1.000113]\n",
      "epoch:17 step:83880[D loss: 0.999964] [G loss: 1.000136]\n",
      "epoch:17 step:83885[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:17 step:83890[D loss: 1.000020] [G loss: 1.000039]\n",
      "epoch:17 step:83895[D loss: 0.999971] [G loss: 1.000024]\n",
      "epoch:17 step:83900[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:17 step:83905[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:17 step:83910[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:17 step:83915[D loss: 0.999947] [G loss: 1.000043]\n",
      "epoch:17 step:83920[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:17 step:83925[D loss: 1.000024] [G loss: 0.999990]\n",
      "epoch:17 step:83930[D loss: 0.999999] [G loss: 0.999976]\n",
      "epoch:17 step:83935[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:17 step:83940[D loss: 0.999967] [G loss: 1.000116]\n",
      "epoch:17 step:83945[D loss: 0.999944] [G loss: 1.000095]\n",
      "epoch:17 step:83950[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:17 step:83955[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:17 step:83960[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:17 step:83965[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:17 step:83970[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:17 step:83975[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:17 step:83980[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:17 step:83985[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:17 step:83990[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:17 step:83995[D loss: 0.999972] [G loss: 1.000125]\n",
      "epoch:17 step:84000[D loss: 0.999916] [G loss: 1.000104]\n",
      "##############\n",
      "[2.51009255 2.10937827 2.21080338 3.98125886 1.46964345 8.46854418\n",
      " 2.35518833 3.77995035 3.94332203 5.95830347]\n",
      "##########\n",
      "epoch:17 step:84005[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:17 step:84010[D loss: 0.999980] [G loss: 1.000096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:84015[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:17 step:84020[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:17 step:84025[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:17 step:84030[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:17 step:84035[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:17 step:84040[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:17 step:84045[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:17 step:84050[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:17 step:84055[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:17 step:84060[D loss: 1.000010] [G loss: 1.000004]\n",
      "epoch:17 step:84065[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:17 step:84070[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:17 step:84075[D loss: 1.000019] [G loss: 1.000010]\n",
      "epoch:17 step:84080[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:17 step:84085[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:17 step:84090[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:17 step:84095[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:17 step:84100[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:17 step:84105[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:17 step:84110[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:17 step:84115[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:17 step:84120[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:17 step:84125[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:17 step:84130[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:17 step:84135[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:17 step:84140[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:17 step:84145[D loss: 0.999958] [G loss: 1.000097]\n",
      "epoch:17 step:84150[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:17 step:84155[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:17 step:84160[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:17 step:84165[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:17 step:84170[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:17 step:84175[D loss: 1.000013] [G loss: 0.999992]\n",
      "epoch:17 step:84180[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:17 step:84185[D loss: 1.000087] [G loss: 0.999818]\n",
      "epoch:17 step:84190[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:17 step:84195[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:17 step:84200[D loss: 0.999963] [G loss: 1.000060]\n",
      "##############\n",
      "[2.53341525 2.15608227 2.20035093 4.0858909  1.46370232 7.6035092\n",
      " 2.30818365 3.98408092 3.93007935 5.31487743]\n",
      "##########\n",
      "epoch:17 step:84205[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:17 step:84210[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:17 step:84215[D loss: 0.999997] [G loss: 1.000076]\n",
      "epoch:17 step:84220[D loss: 0.999958] [G loss: 1.000122]\n",
      "epoch:17 step:84225[D loss: 0.999947] [G loss: 1.000091]\n",
      "epoch:17 step:84230[D loss: 1.000003] [G loss: 1.000105]\n",
      "epoch:17 step:84235[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:17 step:84240[D loss: 1.000011] [G loss: 0.999958]\n",
      "epoch:17 step:84245[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:17 step:84250[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:17 step:84255[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:17 step:84260[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:17 step:84265[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:17 step:84270[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:17 step:84275[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:17 step:84280[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:17 step:84285[D loss: 1.000025] [G loss: 1.000032]\n",
      "epoch:17 step:84290[D loss: 0.999952] [G loss: 1.000073]\n",
      "epoch:17 step:84295[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:17 step:84300[D loss: 0.999993] [G loss: 1.000026]\n",
      "epoch:17 step:84305[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:17 step:84310[D loss: 0.999987] [G loss: 1.000015]\n",
      "epoch:17 step:84315[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:17 step:84320[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:17 step:84325[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:17 step:84330[D loss: 1.000007] [G loss: 1.000076]\n",
      "epoch:18 step:84335[D loss: 1.000060] [G loss: 1.000013]\n",
      "epoch:18 step:84340[D loss: 1.000020] [G loss: 0.999989]\n",
      "epoch:18 step:84345[D loss: 0.999982] [G loss: 1.000006]\n",
      "epoch:18 step:84350[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:18 step:84355[D loss: 0.999932] [G loss: 1.000147]\n",
      "epoch:18 step:84360[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:18 step:84365[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:18 step:84370[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:18 step:84375[D loss: 1.000003] [G loss: 1.000033]\n",
      "epoch:18 step:84380[D loss: 1.000054] [G loss: 0.999998]\n",
      "epoch:18 step:84385[D loss: 1.000036] [G loss: 0.999972]\n",
      "epoch:18 step:84390[D loss: 0.999905] [G loss: 1.000107]\n",
      "epoch:18 step:84395[D loss: 0.999985] [G loss: 0.999990]\n",
      "epoch:18 step:84400[D loss: 0.999960] [G loss: 1.000063]\n",
      "##############\n",
      "[2.56695056 2.17219471 2.24604559 3.76105313 1.49935035 7.65368366\n",
      " 2.3612917  3.68481292 4.05057613 5.19876443]\n",
      "##########\n",
      "epoch:18 step:84405[D loss: 1.000042] [G loss: 0.999962]\n",
      "epoch:18 step:84410[D loss: 1.000014] [G loss: 0.999983]\n",
      "epoch:18 step:84415[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:18 step:84420[D loss: 0.999954] [G loss: 1.000067]\n",
      "epoch:18 step:84425[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:18 step:84430[D loss: 1.000003] [G loss: 0.999982]\n",
      "epoch:18 step:84435[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:18 step:84440[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:18 step:84445[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:18 step:84450[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:18 step:84455[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:18 step:84460[D loss: 1.000027] [G loss: 1.000008]\n",
      "epoch:18 step:84465[D loss: 0.999983] [G loss: 1.000129]\n",
      "epoch:18 step:84470[D loss: 0.999943] [G loss: 1.000112]\n",
      "epoch:18 step:84475[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:18 step:84480[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:18 step:84485[D loss: 0.999986] [G loss: 1.000086]\n",
      "epoch:18 step:84490[D loss: 1.000042] [G loss: 0.999950]\n",
      "epoch:18 step:84495[D loss: 0.999929] [G loss: 1.000157]\n",
      "epoch:18 step:84500[D loss: 1.000019] [G loss: 1.000083]\n",
      "epoch:18 step:84505[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:18 step:84510[D loss: 1.000003] [G loss: 1.000088]\n",
      "epoch:18 step:84515[D loss: 1.000023] [G loss: 1.000039]\n",
      "epoch:18 step:84520[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:18 step:84525[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:18 step:84530[D loss: 1.000040] [G loss: 1.000002]\n",
      "epoch:18 step:84535[D loss: 1.000084] [G loss: 0.999845]\n",
      "epoch:18 step:84540[D loss: 1.000023] [G loss: 0.999903]\n",
      "epoch:18 step:84545[D loss: 1.000023] [G loss: 0.999971]\n",
      "epoch:18 step:84550[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:18 step:84555[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:18 step:84560[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:18 step:84565[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:18 step:84570[D loss: 0.999932] [G loss: 1.000153]\n",
      "epoch:18 step:84575[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:18 step:84580[D loss: 1.000007] [G loss: 1.000009]\n",
      "epoch:18 step:84585[D loss: 0.999950] [G loss: 1.000079]\n",
      "epoch:18 step:84590[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:18 step:84595[D loss: 1.000035] [G loss: 0.999996]\n",
      "epoch:18 step:84600[D loss: 1.000018] [G loss: 0.999945]\n",
      "##############\n",
      "[2.50876126 2.15316336 2.32884451 4.00127363 1.46167515 7.56141502\n",
      " 2.47398006 3.68114357 3.99175621 6.28611644]\n",
      "##########\n",
      "epoch:18 step:84605[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:18 step:84610[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:18 step:84615[D loss: 1.000006] [G loss: 1.000124]\n",
      "epoch:18 step:84620[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:18 step:84625[D loss: 0.999954] [G loss: 1.000154]\n",
      "epoch:18 step:84630[D loss: 0.999956] [G loss: 1.000133]\n",
      "epoch:18 step:84635[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:18 step:84640[D loss: 1.000084] [G loss: 0.999973]\n",
      "epoch:18 step:84645[D loss: 1.000084] [G loss: 0.999987]\n",
      "epoch:18 step:84650[D loss: 1.000006] [G loss: 1.000103]\n",
      "epoch:18 step:84655[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:18 step:84660[D loss: 0.999980] [G loss: 1.000012]\n",
      "epoch:18 step:84665[D loss: 0.999949] [G loss: 1.000045]\n",
      "epoch:18 step:84670[D loss: 0.999985] [G loss: 1.000001]\n",
      "epoch:18 step:84675[D loss: 1.000022] [G loss: 1.000045]\n",
      "epoch:18 step:84680[D loss: 1.000035] [G loss: 0.999947]\n",
      "epoch:18 step:84685[D loss: 1.000051] [G loss: 0.999925]\n",
      "epoch:18 step:84690[D loss: 1.000133] [G loss: 0.999910]\n",
      "epoch:18 step:84695[D loss: 0.999921] [G loss: 1.000091]\n",
      "epoch:18 step:84700[D loss: 0.999874] [G loss: 1.000106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:84705[D loss: 0.999954] [G loss: 1.000053]\n",
      "epoch:18 step:84710[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:18 step:84715[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:18 step:84720[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:18 step:84725[D loss: 0.999998] [G loss: 0.999991]\n",
      "epoch:18 step:84730[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:18 step:84735[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:18 step:84740[D loss: 0.999976] [G loss: 1.000026]\n",
      "epoch:18 step:84745[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:18 step:84750[D loss: 0.999932] [G loss: 1.000090]\n",
      "epoch:18 step:84755[D loss: 0.999936] [G loss: 1.000081]\n",
      "epoch:18 step:84760[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:18 step:84765[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:18 step:84770[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:18 step:84775[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:18 step:84780[D loss: 0.999982] [G loss: 1.000027]\n",
      "epoch:18 step:84785[D loss: 0.999965] [G loss: 1.000037]\n",
      "epoch:18 step:84790[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:18 step:84795[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:18 step:84800[D loss: 0.999984] [G loss: 1.000048]\n",
      "##############\n",
      "[2.4973068  2.06871254 2.29184235 3.65520833 1.45648068 7.18972236\n",
      " 2.33050319 3.83750336 3.96061647 6.42271022]\n",
      "##########\n",
      "epoch:18 step:84805[D loss: 0.999997] [G loss: 1.000078]\n",
      "epoch:18 step:84810[D loss: 1.000012] [G loss: 1.000052]\n",
      "epoch:18 step:84815[D loss: 0.999999] [G loss: 1.000125]\n",
      "epoch:18 step:84820[D loss: 0.999962] [G loss: 1.000124]\n",
      "epoch:18 step:84825[D loss: 0.999925] [G loss: 1.000170]\n",
      "epoch:18 step:84830[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:18 step:84835[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:18 step:84840[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:18 step:84845[D loss: 1.000095] [G loss: 0.999860]\n",
      "epoch:18 step:84850[D loss: 0.999968] [G loss: 1.000109]\n",
      "epoch:18 step:84855[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:18 step:84860[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:18 step:84865[D loss: 1.000056] [G loss: 0.999990]\n",
      "epoch:18 step:84870[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:18 step:84875[D loss: 0.999922] [G loss: 1.000090]\n",
      "epoch:18 step:84880[D loss: 1.000027] [G loss: 1.000021]\n",
      "epoch:18 step:84885[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:18 step:84890[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:18 step:84895[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:18 step:84900[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:18 step:84905[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:18 step:84910[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:18 step:84915[D loss: 0.999957] [G loss: 1.000186]\n",
      "epoch:18 step:84920[D loss: 1.000123] [G loss: 0.999910]\n",
      "epoch:18 step:84925[D loss: 1.000097] [G loss: 1.000035]\n",
      "epoch:18 step:84930[D loss: 0.999989] [G loss: 0.999995]\n",
      "epoch:18 step:84935[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:18 step:84940[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:18 step:84945[D loss: 0.999925] [G loss: 1.000138]\n",
      "epoch:18 step:84950[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:18 step:84955[D loss: 1.000015] [G loss: 0.999977]\n",
      "epoch:18 step:84960[D loss: 0.999976] [G loss: 1.000002]\n",
      "epoch:18 step:84965[D loss: 0.999993] [G loss: 1.000033]\n",
      "epoch:18 step:84970[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:18 step:84975[D loss: 0.999936] [G loss: 1.000113]\n",
      "epoch:18 step:84980[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:18 step:84985[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:18 step:84990[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:18 step:84995[D loss: 1.000008] [G loss: 1.000023]\n",
      "epoch:18 step:85000[D loss: 0.999978] [G loss: 1.000049]\n",
      "##############\n",
      "[2.51238721 2.14918695 2.20664574 3.75199303 1.46602086 7.78093804\n",
      " 2.24973869 3.81092021 3.96607125 5.72635179]\n",
      "##########\n",
      "epoch:18 step:85005[D loss: 0.999946] [G loss: 1.000108]\n",
      "epoch:18 step:85010[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:18 step:85015[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:18 step:85020[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:18 step:85025[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:18 step:85030[D loss: 1.000004] [G loss: 1.000021]\n",
      "epoch:18 step:85035[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:18 step:85040[D loss: 0.999922] [G loss: 1.000164]\n",
      "epoch:18 step:85045[D loss: 1.000005] [G loss: 0.999951]\n",
      "epoch:18 step:85050[D loss: 1.000017] [G loss: 0.999993]\n",
      "epoch:18 step:85055[D loss: 0.999964] [G loss: 1.000143]\n",
      "epoch:18 step:85060[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:18 step:85065[D loss: 1.000013] [G loss: 1.000036]\n",
      "epoch:18 step:85070[D loss: 1.000011] [G loss: 1.000010]\n",
      "epoch:18 step:85075[D loss: 1.000015] [G loss: 0.999985]\n",
      "epoch:18 step:85080[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:18 step:85085[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:18 step:85090[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:18 step:85095[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:18 step:85100[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:18 step:85105[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:18 step:85110[D loss: 1.000004] [G loss: 1.000031]\n",
      "epoch:18 step:85115[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:18 step:85120[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:18 step:85125[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:18 step:85130[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:18 step:85135[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:18 step:85140[D loss: 0.999950] [G loss: 1.000145]\n",
      "epoch:18 step:85145[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:18 step:85150[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:18 step:85155[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:18 step:85160[D loss: 0.999967] [G loss: 1.000117]\n",
      "epoch:18 step:85165[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:18 step:85170[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:18 step:85175[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:18 step:85180[D loss: 0.999960] [G loss: 1.000130]\n",
      "epoch:18 step:85185[D loss: 0.999935] [G loss: 1.000132]\n",
      "epoch:18 step:85190[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:18 step:85195[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:18 step:85200[D loss: 0.999994] [G loss: 1.000021]\n",
      "##############\n",
      "[2.46459463 2.07820894 2.17082632 4.10280058 1.41343069 8.00424039\n",
      " 2.35418042 3.5962681  3.97534875 5.64964888]\n",
      "##########\n",
      "epoch:18 step:85205[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:18 step:85210[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:18 step:85215[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:18 step:85220[D loss: 0.999981] [G loss: 1.000091]\n",
      "epoch:18 step:85225[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:18 step:85230[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:18 step:85235[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:18 step:85240[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:18 step:85245[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:18 step:85250[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:18 step:85255[D loss: 0.999940] [G loss: 1.000142]\n",
      "epoch:18 step:85260[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:18 step:85265[D loss: 1.000026] [G loss: 1.000024]\n",
      "epoch:18 step:85270[D loss: 1.000012] [G loss: 1.000051]\n",
      "epoch:18 step:85275[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:18 step:85280[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:18 step:85285[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:18 step:85290[D loss: 0.999979] [G loss: 1.000014]\n",
      "epoch:18 step:85295[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:18 step:85300[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:18 step:85305[D loss: 1.000011] [G loss: 1.000001]\n",
      "epoch:18 step:85310[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:18 step:85315[D loss: 1.000014] [G loss: 1.000067]\n",
      "epoch:18 step:85320[D loss: 0.999946] [G loss: 1.000201]\n",
      "epoch:18 step:85325[D loss: 0.999964] [G loss: 1.000113]\n",
      "epoch:18 step:85330[D loss: 1.000001] [G loss: 1.000143]\n",
      "epoch:18 step:85335[D loss: 0.999960] [G loss: 1.000130]\n",
      "epoch:18 step:85340[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:18 step:85345[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:18 step:85350[D loss: 1.000022] [G loss: 0.999995]\n",
      "epoch:18 step:85355[D loss: 1.000032] [G loss: 0.999949]\n",
      "epoch:18 step:85360[D loss: 1.000055] [G loss: 0.999962]\n",
      "epoch:18 step:85365[D loss: 0.999944] [G loss: 1.000188]\n",
      "epoch:18 step:85370[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:18 step:85375[D loss: 1.000015] [G loss: 1.000052]\n",
      "epoch:18 step:85380[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:18 step:85385[D loss: 0.999956] [G loss: 1.000107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:85390[D loss: 0.999998] [G loss: 0.999990]\n",
      "epoch:18 step:85395[D loss: 0.999949] [G loss: 1.000110]\n",
      "epoch:18 step:85400[D loss: 1.000017] [G loss: 1.000055]\n",
      "##############\n",
      "[2.53919658 2.13351566 2.17355431 3.91300132 1.44723944 7.67152821\n",
      " 2.45003729 3.99263904 4.00559928 5.89655163]\n",
      "##########\n",
      "epoch:18 step:85405[D loss: 0.999976] [G loss: 1.000114]\n",
      "epoch:18 step:85410[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:18 step:85415[D loss: 1.000087] [G loss: 1.000065]\n",
      "epoch:18 step:85420[D loss: 0.999932] [G loss: 1.000123]\n",
      "epoch:18 step:85425[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:18 step:85430[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:18 step:85435[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:18 step:85440[D loss: 1.000001] [G loss: 1.000037]\n",
      "epoch:18 step:85445[D loss: 1.000014] [G loss: 1.000018]\n",
      "epoch:18 step:85450[D loss: 0.999929] [G loss: 1.000069]\n",
      "epoch:18 step:85455[D loss: 1.000064] [G loss: 1.000000]\n",
      "epoch:18 step:85460[D loss: 1.000045] [G loss: 1.000088]\n",
      "epoch:18 step:85465[D loss: 1.000080] [G loss: 1.000017]\n",
      "epoch:18 step:85470[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:18 step:85475[D loss: 0.999916] [G loss: 1.000161]\n",
      "epoch:18 step:85480[D loss: 1.000019] [G loss: 1.000096]\n",
      "epoch:18 step:85485[D loss: 0.999957] [G loss: 1.000153]\n",
      "epoch:18 step:85490[D loss: 0.999914] [G loss: 1.000168]\n",
      "epoch:18 step:85495[D loss: 1.000012] [G loss: 1.000054]\n",
      "epoch:18 step:85500[D loss: 1.000063] [G loss: 0.999986]\n",
      "epoch:18 step:85505[D loss: 0.999973] [G loss: 1.000105]\n",
      "epoch:18 step:85510[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:18 step:85515[D loss: 1.000020] [G loss: 1.000017]\n",
      "epoch:18 step:85520[D loss: 1.000015] [G loss: 1.000012]\n",
      "epoch:18 step:85525[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:18 step:85530[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:18 step:85535[D loss: 1.000030] [G loss: 1.000003]\n",
      "epoch:18 step:85540[D loss: 0.999935] [G loss: 1.000147]\n",
      "epoch:18 step:85545[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:18 step:85550[D loss: 1.000052] [G loss: 0.999992]\n",
      "epoch:18 step:85555[D loss: 0.999914] [G loss: 1.000219]\n",
      "epoch:18 step:85560[D loss: 0.999946] [G loss: 1.000128]\n",
      "epoch:18 step:85565[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:18 step:85570[D loss: 1.000003] [G loss: 1.000074]\n",
      "epoch:18 step:85575[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:18 step:85580[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:18 step:85585[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:18 step:85590[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:18 step:85595[D loss: 0.999963] [G loss: 1.000121]\n",
      "epoch:18 step:85600[D loss: 0.999958] [G loss: 1.000074]\n",
      "##############\n",
      "[2.43112537 2.10329408 2.23817438 3.85621242 1.43062484 7.55240211\n",
      " 2.46469259 3.92651759 3.99673447 5.69534166]\n",
      "##########\n",
      "epoch:18 step:85605[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:18 step:85610[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:18 step:85615[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:18 step:85620[D loss: 1.000007] [G loss: 1.000034]\n",
      "epoch:18 step:85625[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:18 step:85630[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:18 step:85635[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:18 step:85640[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:18 step:85645[D loss: 0.999974] [G loss: 1.000131]\n",
      "epoch:18 step:85650[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:18 step:85655[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:18 step:85660[D loss: 0.999975] [G loss: 1.000101]\n",
      "epoch:18 step:85665[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:18 step:85670[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:18 step:85675[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:18 step:85680[D loss: 1.000024] [G loss: 0.999987]\n",
      "epoch:18 step:85685[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:18 step:85690[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:18 step:85695[D loss: 1.000005] [G loss: 1.000001]\n",
      "epoch:18 step:85700[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:18 step:85705[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:18 step:85710[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:18 step:85715[D loss: 0.999967] [G loss: 1.000029]\n",
      "epoch:18 step:85720[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:18 step:85725[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:18 step:85730[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:18 step:85735[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:18 step:85740[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:18 step:85745[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:18 step:85750[D loss: 0.999978] [G loss: 1.000024]\n",
      "epoch:18 step:85755[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:18 step:85760[D loss: 0.999996] [G loss: 1.000082]\n",
      "epoch:18 step:85765[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:18 step:85770[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:18 step:85775[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:18 step:85780[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:18 step:85785[D loss: 0.999988] [G loss: 1.000027]\n",
      "epoch:18 step:85790[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:18 step:85795[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:18 step:85800[D loss: 0.999968] [G loss: 1.000008]\n",
      "##############\n",
      "[2.53425876 2.15646566 2.2340181  3.9888194  1.45878149 7.8851828\n",
      " 2.37677479 3.900542   3.90268643 5.34936572]\n",
      "##########\n",
      "epoch:18 step:85805[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:18 step:85810[D loss: 0.999938] [G loss: 1.000139]\n",
      "epoch:18 step:85815[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:18 step:85820[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:18 step:85825[D loss: 0.999935] [G loss: 1.000086]\n",
      "epoch:18 step:85830[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:18 step:85835[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:18 step:85840[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:18 step:85845[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:18 step:85850[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:18 step:85855[D loss: 1.000041] [G loss: 0.999999]\n",
      "epoch:18 step:85860[D loss: 1.000003] [G loss: 1.000066]\n",
      "epoch:18 step:85865[D loss: 0.999931] [G loss: 1.000091]\n",
      "epoch:18 step:85870[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:18 step:85875[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:18 step:85880[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:18 step:85885[D loss: 1.000020] [G loss: 1.000003]\n",
      "epoch:18 step:85890[D loss: 0.999941] [G loss: 1.000080]\n",
      "epoch:18 step:85895[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:18 step:85900[D loss: 0.999985] [G loss: 1.000001]\n",
      "epoch:18 step:85905[D loss: 1.000011] [G loss: 1.000047]\n",
      "epoch:18 step:85910[D loss: 1.000061] [G loss: 1.000029]\n",
      "epoch:18 step:85915[D loss: 0.999901] [G loss: 1.000100]\n",
      "epoch:18 step:85920[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:18 step:85925[D loss: 0.999943] [G loss: 1.000047]\n",
      "epoch:18 step:85930[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:18 step:85935[D loss: 1.000106] [G loss: 0.999910]\n",
      "epoch:18 step:85940[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:18 step:85945[D loss: 1.000050] [G loss: 0.999954]\n",
      "epoch:18 step:85950[D loss: 0.999938] [G loss: 1.000018]\n",
      "epoch:18 step:85955[D loss: 0.999933] [G loss: 1.000073]\n",
      "epoch:18 step:85960[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:18 step:85965[D loss: 1.000003] [G loss: 1.000044]\n",
      "epoch:18 step:85970[D loss: 0.999980] [G loss: 0.999961]\n",
      "epoch:18 step:85975[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:18 step:85980[D loss: 0.999999] [G loss: 1.000021]\n",
      "epoch:18 step:85985[D loss: 0.999956] [G loss: 1.000023]\n",
      "epoch:18 step:85990[D loss: 0.999967] [G loss: 1.000042]\n",
      "epoch:18 step:85995[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:18 step:86000[D loss: 0.999963] [G loss: 1.000048]\n",
      "##############\n",
      "[2.51176017 2.08799019 2.1575945  3.63869752 1.42118541 7.40920066\n",
      " 2.13257844 3.6044803  3.83680633 8.14868929]\n",
      "##########\n",
      "epoch:18 step:86005[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:18 step:86010[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:18 step:86015[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:18 step:86020[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:18 step:86025[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:18 step:86030[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:18 step:86035[D loss: 0.999972] [G loss: 1.000030]\n",
      "epoch:18 step:86040[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:18 step:86045[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:18 step:86050[D loss: 0.999965] [G loss: 1.000121]\n",
      "epoch:18 step:86055[D loss: 0.999975] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:86060[D loss: 1.000042] [G loss: 1.000005]\n",
      "epoch:18 step:86065[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:18 step:86070[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:18 step:86075[D loss: 0.999975] [G loss: 1.000103]\n",
      "epoch:18 step:86080[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:18 step:86085[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:18 step:86090[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:18 step:86095[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:18 step:86100[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:18 step:86105[D loss: 1.000010] [G loss: 0.999983]\n",
      "epoch:18 step:86110[D loss: 0.999940] [G loss: 1.000103]\n",
      "epoch:18 step:86115[D loss: 1.000013] [G loss: 0.999971]\n",
      "epoch:18 step:86120[D loss: 1.000130] [G loss: 0.999900]\n",
      "epoch:18 step:86125[D loss: 0.999947] [G loss: 1.000047]\n",
      "epoch:18 step:86130[D loss: 1.000013] [G loss: 1.000067]\n",
      "epoch:18 step:86135[D loss: 0.999930] [G loss: 1.000113]\n",
      "epoch:18 step:86140[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:18 step:86145[D loss: 1.000018] [G loss: 1.000005]\n",
      "epoch:18 step:86150[D loss: 1.000062] [G loss: 0.999976]\n",
      "epoch:18 step:86155[D loss: 1.000003] [G loss: 1.000010]\n",
      "epoch:18 step:86160[D loss: 1.000065] [G loss: 0.999905]\n",
      "epoch:18 step:86165[D loss: 1.000010] [G loss: 1.000085]\n",
      "epoch:18 step:86170[D loss: 0.999941] [G loss: 1.000137]\n",
      "epoch:18 step:86175[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:18 step:86180[D loss: 0.999891] [G loss: 1.000174]\n",
      "epoch:18 step:86185[D loss: 0.999909] [G loss: 1.000175]\n",
      "epoch:18 step:86190[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:18 step:86195[D loss: 0.999956] [G loss: 1.000129]\n",
      "epoch:18 step:86200[D loss: 1.000018] [G loss: 1.000125]\n",
      "##############\n",
      "[2.59258282 2.01294    2.10158094 3.74865251 1.41358617 9.27426719\n",
      " 2.18749145 3.76323074 3.89582813 5.21562981]\n",
      "##########\n",
      "epoch:18 step:86205[D loss: 0.999981] [G loss: 1.000018]\n",
      "epoch:18 step:86210[D loss: 1.000008] [G loss: 0.999926]\n",
      "epoch:18 step:86215[D loss: 1.000077] [G loss: 0.999844]\n",
      "epoch:18 step:86220[D loss: 1.000067] [G loss: 1.000022]\n",
      "epoch:18 step:86225[D loss: 0.999929] [G loss: 1.000127]\n",
      "epoch:18 step:86230[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:18 step:86235[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:18 step:86240[D loss: 0.999927] [G loss: 1.000160]\n",
      "epoch:18 step:86245[D loss: 0.999930] [G loss: 1.000025]\n",
      "epoch:18 step:86250[D loss: 1.000018] [G loss: 0.999935]\n",
      "epoch:18 step:86255[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:18 step:86260[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:18 step:86265[D loss: 0.999997] [G loss: 1.000021]\n",
      "epoch:18 step:86270[D loss: 0.999990] [G loss: 1.000007]\n",
      "epoch:18 step:86275[D loss: 0.999973] [G loss: 1.000034]\n",
      "epoch:18 step:86280[D loss: 0.999992] [G loss: 1.000086]\n",
      "epoch:18 step:86285[D loss: 0.999946] [G loss: 1.000054]\n",
      "epoch:18 step:86290[D loss: 0.999960] [G loss: 1.000153]\n",
      "epoch:18 step:86295[D loss: 0.999991] [G loss: 1.000022]\n",
      "epoch:18 step:86300[D loss: 0.999978] [G loss: 1.000123]\n",
      "epoch:18 step:86305[D loss: 0.999988] [G loss: 1.000069]\n",
      "epoch:18 step:86310[D loss: 0.999930] [G loss: 1.000135]\n",
      "epoch:18 step:86315[D loss: 0.999954] [G loss: 1.000051]\n",
      "epoch:18 step:86320[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:18 step:86325[D loss: 1.000031] [G loss: 1.000001]\n",
      "epoch:18 step:86330[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:18 step:86335[D loss: 1.000007] [G loss: 1.000071]\n",
      "epoch:18 step:86340[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:18 step:86345[D loss: 1.000039] [G loss: 0.999957]\n",
      "epoch:18 step:86350[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:18 step:86355[D loss: 0.999945] [G loss: 1.000053]\n",
      "epoch:18 step:86360[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:18 step:86365[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:18 step:86370[D loss: 0.999955] [G loss: 1.000050]\n",
      "epoch:18 step:86375[D loss: 0.999946] [G loss: 1.000060]\n",
      "epoch:18 step:86380[D loss: 1.000052] [G loss: 0.999929]\n",
      "epoch:18 step:86385[D loss: 0.999985] [G loss: 0.999992]\n",
      "epoch:18 step:86390[D loss: 1.000023] [G loss: 1.000021]\n",
      "epoch:18 step:86395[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:18 step:86400[D loss: 0.999961] [G loss: 1.000079]\n",
      "##############\n",
      "[2.52771199 2.0813301  2.01365829 3.80820212 1.45381041 7.98524347\n",
      " 2.36709635 3.8440517  4.03408587 6.28848352]\n",
      "##########\n",
      "epoch:18 step:86405[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:18 step:86410[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:18 step:86415[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:18 step:86420[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:18 step:86425[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:18 step:86430[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:18 step:86435[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:18 step:86440[D loss: 1.000033] [G loss: 0.999988]\n",
      "epoch:18 step:86445[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:18 step:86450[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:18 step:86455[D loss: 0.999945] [G loss: 1.000112]\n",
      "epoch:18 step:86460[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:18 step:86465[D loss: 0.999986] [G loss: 1.000006]\n",
      "epoch:18 step:86470[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:18 step:86475[D loss: 1.000060] [G loss: 0.999903]\n",
      "epoch:18 step:86480[D loss: 0.999957] [G loss: 1.000035]\n",
      "epoch:18 step:86485[D loss: 0.999978] [G loss: 1.000028]\n",
      "epoch:18 step:86490[D loss: 0.999944] [G loss: 1.000187]\n",
      "epoch:18 step:86495[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:18 step:86500[D loss: 1.000025] [G loss: 1.000072]\n",
      "epoch:18 step:86505[D loss: 1.000043] [G loss: 0.999983]\n",
      "epoch:18 step:86510[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:18 step:86515[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:18 step:86520[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:18 step:86525[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:18 step:86530[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:18 step:86535[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:18 step:86540[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:18 step:86545[D loss: 1.000000] [G loss: 1.000001]\n",
      "epoch:18 step:86550[D loss: 1.000006] [G loss: 1.000000]\n",
      "epoch:18 step:86555[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:18 step:86560[D loss: 1.000004] [G loss: 1.000108]\n",
      "epoch:18 step:86565[D loss: 0.999962] [G loss: 1.000144]\n",
      "epoch:18 step:86570[D loss: 1.000017] [G loss: 1.000052]\n",
      "epoch:18 step:86575[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:18 step:86580[D loss: 0.999963] [G loss: 1.000123]\n",
      "epoch:18 step:86585[D loss: 0.999978] [G loss: 1.000108]\n",
      "epoch:18 step:86590[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:18 step:86595[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:18 step:86600[D loss: 1.000009] [G loss: 1.000010]\n",
      "##############\n",
      "[2.55300877 2.15740205 2.13604159 4.02661227 1.44645155 7.5797044\n",
      " 2.30404353 3.85419303 3.96159018 4.98478804]\n",
      "##########\n",
      "epoch:18 step:86605[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:18 step:86610[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:18 step:86615[D loss: 1.000005] [G loss: 1.000027]\n",
      "epoch:18 step:86620[D loss: 1.000006] [G loss: 1.000065]\n",
      "epoch:18 step:86625[D loss: 1.000075] [G loss: 1.000114]\n",
      "epoch:18 step:86630[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:18 step:86635[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:18 step:86640[D loss: 0.999958] [G loss: 1.000069]\n",
      "epoch:18 step:86645[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:18 step:86650[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:18 step:86655[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:18 step:86660[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:18 step:86665[D loss: 1.000012] [G loss: 0.999971]\n",
      "epoch:18 step:86670[D loss: 1.000023] [G loss: 1.000041]\n",
      "epoch:18 step:86675[D loss: 1.000031] [G loss: 1.000084]\n",
      "epoch:18 step:86680[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:18 step:86685[D loss: 0.999982] [G loss: 1.000127]\n",
      "epoch:18 step:86690[D loss: 0.999898] [G loss: 1.000186]\n",
      "epoch:18 step:86695[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:18 step:86700[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:18 step:86705[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:18 step:86710[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:18 step:86715[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:18 step:86720[D loss: 1.000035] [G loss: 0.999986]\n",
      "epoch:18 step:86725[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:18 step:86730[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:18 step:86735[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:18 step:86740[D loss: 0.999978] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:86745[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:18 step:86750[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:18 step:86755[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:18 step:86760[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:18 step:86765[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:18 step:86770[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:18 step:86775[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:18 step:86780[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:18 step:86785[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:18 step:86790[D loss: 0.999996] [G loss: 1.000067]\n",
      "epoch:18 step:86795[D loss: 1.000049] [G loss: 1.000045]\n",
      "epoch:18 step:86800[D loss: 0.999902] [G loss: 1.000254]\n",
      "##############\n",
      "[2.50158115 2.04491676 2.18687449 3.66383214 1.36260774 7.0777831\n",
      " 2.18385813 3.76153389 3.91600303 5.27695131]\n",
      "##########\n",
      "epoch:18 step:86805[D loss: 0.999954] [G loss: 1.000091]\n",
      "epoch:18 step:86810[D loss: 1.000028] [G loss: 1.000120]\n",
      "epoch:18 step:86815[D loss: 0.999949] [G loss: 1.000140]\n",
      "epoch:18 step:86820[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:18 step:86825[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:18 step:86830[D loss: 1.000095] [G loss: 0.999919]\n",
      "epoch:18 step:86835[D loss: 0.999895] [G loss: 1.000106]\n",
      "epoch:18 step:86840[D loss: 0.999996] [G loss: 1.000003]\n",
      "epoch:18 step:86845[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:18 step:86850[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:18 step:86855[D loss: 1.000040] [G loss: 0.999962]\n",
      "epoch:18 step:86860[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:18 step:86865[D loss: 0.999983] [G loss: 1.000130]\n",
      "epoch:18 step:86870[D loss: 1.000020] [G loss: 1.000034]\n",
      "epoch:18 step:86875[D loss: 0.999917] [G loss: 1.000173]\n",
      "epoch:18 step:86880[D loss: 1.000074] [G loss: 1.000065]\n",
      "epoch:18 step:86885[D loss: 1.000003] [G loss: 1.000031]\n",
      "epoch:18 step:86890[D loss: 0.999907] [G loss: 1.000100]\n",
      "epoch:18 step:86895[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:18 step:86900[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:18 step:86905[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:18 step:86910[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:18 step:86915[D loss: 1.000073] [G loss: 0.999979]\n",
      "epoch:18 step:86920[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:18 step:86925[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:18 step:86930[D loss: 0.999937] [G loss: 1.000163]\n",
      "epoch:18 step:86935[D loss: 0.999998] [G loss: 1.000070]\n",
      "epoch:18 step:86940[D loss: 0.999936] [G loss: 1.000100]\n",
      "epoch:18 step:86945[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:18 step:86950[D loss: 1.000037] [G loss: 1.000073]\n",
      "epoch:18 step:86955[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:18 step:86960[D loss: 1.000014] [G loss: 1.000040]\n",
      "epoch:18 step:86965[D loss: 0.999949] [G loss: 1.000077]\n",
      "epoch:18 step:86970[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:18 step:86975[D loss: 0.999999] [G loss: 1.000077]\n",
      "epoch:18 step:86980[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:18 step:86985[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:18 step:86990[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:18 step:86995[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:18 step:87000[D loss: 0.999998] [G loss: 1.000059]\n",
      "##############\n",
      "[2.52675613 2.19637826 2.16851065 4.0448523  1.51192545 7.70364316\n",
      " 2.36033716 3.78824065 4.00987864 5.35555947]\n",
      "##########\n",
      "epoch:18 step:87005[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:18 step:87010[D loss: 1.000036] [G loss: 1.000053]\n",
      "epoch:18 step:87015[D loss: 1.000080] [G loss: 0.999903]\n",
      "epoch:18 step:87020[D loss: 0.999981] [G loss: 1.000136]\n",
      "epoch:18 step:87025[D loss: 0.999940] [G loss: 1.000187]\n",
      "epoch:18 step:87030[D loss: 0.999968] [G loss: 1.000030]\n",
      "epoch:18 step:87035[D loss: 0.999949] [G loss: 1.000118]\n",
      "epoch:18 step:87040[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:18 step:87045[D loss: 1.000024] [G loss: 1.000000]\n",
      "epoch:18 step:87050[D loss: 0.999957] [G loss: 1.000100]\n",
      "epoch:18 step:87055[D loss: 1.000019] [G loss: 0.999987]\n",
      "epoch:18 step:87060[D loss: 1.000015] [G loss: 0.999991]\n",
      "epoch:18 step:87065[D loss: 0.999943] [G loss: 1.000044]\n",
      "epoch:18 step:87070[D loss: 1.000008] [G loss: 1.000028]\n",
      "epoch:18 step:87075[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:18 step:87080[D loss: 1.000000] [G loss: 1.000100]\n",
      "epoch:18 step:87085[D loss: 0.999940] [G loss: 1.000089]\n",
      "epoch:18 step:87090[D loss: 0.999949] [G loss: 1.000075]\n",
      "epoch:18 step:87095[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:18 step:87100[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:18 step:87105[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:18 step:87110[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:18 step:87115[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:18 step:87120[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:18 step:87125[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:18 step:87130[D loss: 0.999947] [G loss: 1.000114]\n",
      "epoch:18 step:87135[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:18 step:87140[D loss: 0.999945] [G loss: 1.000134]\n",
      "epoch:18 step:87145[D loss: 0.999969] [G loss: 1.000152]\n",
      "epoch:18 step:87150[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:18 step:87155[D loss: 1.000000] [G loss: 1.000035]\n",
      "epoch:18 step:87160[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:18 step:87165[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:18 step:87170[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:18 step:87175[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:18 step:87180[D loss: 0.999959] [G loss: 1.000055]\n",
      "epoch:18 step:87185[D loss: 0.999947] [G loss: 1.000057]\n",
      "epoch:18 step:87190[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:18 step:87195[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:18 step:87200[D loss: 0.999989] [G loss: 1.000046]\n",
      "##############\n",
      "[2.4509511  2.1366603  2.0306064  3.81486578 1.46543502 7.84108512\n",
      " 2.30793354 3.793915   3.96346066 5.34026553]\n",
      "##########\n",
      "epoch:18 step:87205[D loss: 0.999983] [G loss: 1.000129]\n",
      "epoch:18 step:87210[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:18 step:87215[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:18 step:87220[D loss: 1.000011] [G loss: 1.000064]\n",
      "epoch:18 step:87225[D loss: 1.000012] [G loss: 1.000036]\n",
      "epoch:18 step:87230[D loss: 1.000052] [G loss: 1.000137]\n",
      "epoch:18 step:87235[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:18 step:87240[D loss: 0.999959] [G loss: 1.000168]\n",
      "epoch:18 step:87245[D loss: 0.999970] [G loss: 1.000096]\n",
      "epoch:18 step:87250[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:18 step:87255[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:18 step:87260[D loss: 1.000030] [G loss: 0.999997]\n",
      "epoch:18 step:87265[D loss: 0.999998] [G loss: 0.999992]\n",
      "epoch:18 step:87270[D loss: 0.999968] [G loss: 1.000097]\n",
      "epoch:18 step:87275[D loss: 1.000054] [G loss: 1.000040]\n",
      "epoch:18 step:87280[D loss: 0.999924] [G loss: 1.000129]\n",
      "epoch:18 step:87285[D loss: 0.999949] [G loss: 1.000086]\n",
      "epoch:18 step:87290[D loss: 1.000015] [G loss: 1.000041]\n",
      "epoch:18 step:87295[D loss: 1.000079] [G loss: 0.999909]\n",
      "epoch:18 step:87300[D loss: 0.999994] [G loss: 0.999973]\n",
      "epoch:18 step:87305[D loss: 1.000081] [G loss: 1.000027]\n",
      "epoch:18 step:87310[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:18 step:87315[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:18 step:87320[D loss: 0.999950] [G loss: 1.000113]\n",
      "epoch:18 step:87325[D loss: 0.999999] [G loss: 1.000072]\n",
      "epoch:18 step:87330[D loss: 0.999953] [G loss: 1.000078]\n",
      "epoch:18 step:87335[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:18 step:87340[D loss: 1.000019] [G loss: 1.000018]\n",
      "epoch:18 step:87345[D loss: 0.999984] [G loss: 0.999986]\n",
      "epoch:18 step:87350[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:18 step:87355[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:18 step:87360[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:18 step:87365[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:18 step:87370[D loss: 1.000058] [G loss: 0.999884]\n",
      "epoch:18 step:87375[D loss: 0.999993] [G loss: 1.000129]\n",
      "epoch:18 step:87380[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:18 step:87385[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:18 step:87390[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:18 step:87395[D loss: 0.999988] [G loss: 1.000019]\n",
      "epoch:18 step:87400[D loss: 0.999973] [G loss: 1.000059]\n",
      "##############\n",
      "[2.47798346 2.07503473 2.05206676 3.64292641 1.41766153 7.2334627\n",
      " 2.20232702 3.51156275 3.8890384  5.42740007]\n",
      "##########\n",
      "epoch:18 step:87405[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:18 step:87410[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:18 step:87415[D loss: 1.000040] [G loss: 0.999996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:87420[D loss: 0.999994] [G loss: 1.000056]\n",
      "epoch:18 step:87425[D loss: 0.999948] [G loss: 1.000050]\n",
      "epoch:18 step:87430[D loss: 1.000017] [G loss: 1.000065]\n",
      "epoch:18 step:87435[D loss: 0.999941] [G loss: 1.000120]\n",
      "epoch:18 step:87440[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:18 step:87445[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:18 step:87450[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:18 step:87455[D loss: 1.000021] [G loss: 1.000017]\n",
      "epoch:18 step:87460[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:18 step:87465[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:18 step:87470[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:18 step:87475[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:18 step:87480[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:18 step:87485[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:18 step:87490[D loss: 1.000006] [G loss: 1.000030]\n",
      "epoch:18 step:87495[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:18 step:87500[D loss: 0.999936] [G loss: 1.000079]\n",
      "epoch:18 step:87505[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:18 step:87510[D loss: 0.999956] [G loss: 1.000100]\n",
      "epoch:18 step:87515[D loss: 1.000023] [G loss: 1.000000]\n",
      "epoch:18 step:87520[D loss: 0.999935] [G loss: 1.000069]\n",
      "epoch:18 step:87525[D loss: 0.999979] [G loss: 1.000016]\n",
      "epoch:18 step:87530[D loss: 1.000029] [G loss: 1.000088]\n",
      "epoch:18 step:87535[D loss: 1.000071] [G loss: 0.999961]\n",
      "epoch:18 step:87540[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:18 step:87545[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:18 step:87550[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:18 step:87555[D loss: 0.999945] [G loss: 1.000086]\n",
      "epoch:18 step:87560[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:18 step:87565[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:18 step:87570[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:18 step:87575[D loss: 0.999985] [G loss: 1.000095]\n",
      "epoch:18 step:87580[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:18 step:87585[D loss: 1.000028] [G loss: 1.000067]\n",
      "epoch:18 step:87590[D loss: 0.999943] [G loss: 1.000100]\n",
      "epoch:18 step:87595[D loss: 0.999953] [G loss: 1.000110]\n",
      "epoch:18 step:87600[D loss: 0.999965] [G loss: 1.000070]\n",
      "##############\n",
      "[2.50277421 2.03992928 2.11510749 3.9995182  1.51096484 7.59844504\n",
      " 2.36056766 3.71565824 4.06468938 5.71052803]\n",
      "##########\n",
      "epoch:18 step:87605[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:18 step:87610[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:18 step:87615[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:18 step:87620[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:18 step:87625[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:18 step:87630[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:18 step:87635[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:18 step:87640[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:18 step:87645[D loss: 0.999953] [G loss: 1.000126]\n",
      "epoch:18 step:87650[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:18 step:87655[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:18 step:87660[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:18 step:87665[D loss: 0.999973] [G loss: 1.000111]\n",
      "epoch:18 step:87670[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:18 step:87675[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:18 step:87680[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:18 step:87685[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:18 step:87690[D loss: 1.000007] [G loss: 1.000009]\n",
      "epoch:18 step:87695[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:18 step:87700[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:18 step:87705[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:18 step:87710[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:18 step:87715[D loss: 1.000006] [G loss: 0.999983]\n",
      "epoch:18 step:87720[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:18 step:87725[D loss: 1.000018] [G loss: 0.999995]\n",
      "epoch:18 step:87730[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:18 step:87735[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:18 step:87740[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:18 step:87745[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:18 step:87750[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:18 step:87755[D loss: 1.000053] [G loss: 1.000010]\n",
      "epoch:18 step:87760[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:18 step:87765[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:18 step:87770[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:18 step:87775[D loss: 0.999988] [G loss: 1.000150]\n",
      "epoch:18 step:87780[D loss: 0.999950] [G loss: 1.000115]\n",
      "epoch:18 step:87785[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:18 step:87790[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:18 step:87795[D loss: 1.000071] [G loss: 0.999966]\n",
      "epoch:18 step:87800[D loss: 1.000007] [G loss: 1.000061]\n",
      "##############\n",
      "[2.54766502 2.12644584 2.05354641 3.75282063 1.38226236 7.15139537\n",
      " 2.2808381  3.79297569 3.89405206 5.94129585]\n",
      "##########\n",
      "epoch:18 step:87805[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:18 step:87810[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:18 step:87815[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:18 step:87820[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:18 step:87825[D loss: 1.000019] [G loss: 1.000011]\n",
      "epoch:18 step:87830[D loss: 0.999950] [G loss: 1.000089]\n",
      "epoch:18 step:87835[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:18 step:87840[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:18 step:87845[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:18 step:87850[D loss: 0.999955] [G loss: 1.000093]\n",
      "epoch:18 step:87855[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:18 step:87860[D loss: 1.000008] [G loss: 1.000055]\n",
      "epoch:18 step:87865[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:18 step:87870[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:18 step:87875[D loss: 1.000087] [G loss: 0.999967]\n",
      "epoch:18 step:87880[D loss: 1.000067] [G loss: 0.999986]\n",
      "epoch:18 step:87885[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:18 step:87890[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:18 step:87895[D loss: 0.999956] [G loss: 1.000025]\n",
      "epoch:18 step:87900[D loss: 0.999963] [G loss: 1.000160]\n",
      "epoch:18 step:87905[D loss: 0.999955] [G loss: 1.000098]\n",
      "epoch:18 step:87910[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:18 step:87915[D loss: 0.999986] [G loss: 1.000027]\n",
      "epoch:18 step:87920[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:18 step:87925[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:18 step:87930[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:18 step:87935[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:18 step:87940[D loss: 0.999998] [G loss: 1.000059]\n",
      "epoch:18 step:87945[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:18 step:87950[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:18 step:87955[D loss: 0.999954] [G loss: 1.000072]\n",
      "epoch:18 step:87960[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:18 step:87965[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:18 step:87970[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:18 step:87975[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:18 step:87980[D loss: 0.999995] [G loss: 1.000090]\n",
      "epoch:18 step:87985[D loss: 0.999943] [G loss: 1.000085]\n",
      "epoch:18 step:87990[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:18 step:87995[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:18 step:88000[D loss: 0.999960] [G loss: 1.000086]\n",
      "##############\n",
      "[2.42779545 2.08678997 2.0968175  3.65845333 1.36502006 6.88907525\n",
      " 2.25115199 3.88217942 3.79268224 4.44768823]\n",
      "##########\n",
      "epoch:18 step:88005[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:18 step:88010[D loss: 1.000007] [G loss: 1.000014]\n",
      "epoch:18 step:88015[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:18 step:88020[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:18 step:88025[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:18 step:88030[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:18 step:88035[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:18 step:88040[D loss: 1.000017] [G loss: 1.000086]\n",
      "epoch:18 step:88045[D loss: 0.999959] [G loss: 1.000030]\n",
      "epoch:18 step:88050[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:18 step:88055[D loss: 1.000006] [G loss: 1.000030]\n",
      "epoch:18 step:88060[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:18 step:88065[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:18 step:88070[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:18 step:88075[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:18 step:88080[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:18 step:88085[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:18 step:88090[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:18 step:88095[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:18 step:88100[D loss: 1.000037] [G loss: 1.000041]\n",
      "epoch:18 step:88105[D loss: 1.000014] [G loss: 1.000006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:88110[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:18 step:88115[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:18 step:88120[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:18 step:88125[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:18 step:88130[D loss: 1.000047] [G loss: 1.000004]\n",
      "epoch:18 step:88135[D loss: 1.000005] [G loss: 1.000019]\n",
      "epoch:18 step:88140[D loss: 1.000029] [G loss: 1.000021]\n",
      "epoch:18 step:88145[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:18 step:88150[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:18 step:88155[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:18 step:88160[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:18 step:88165[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:18 step:88170[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:18 step:88175[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:18 step:88180[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:18 step:88185[D loss: 1.000096] [G loss: 0.999899]\n",
      "epoch:18 step:88190[D loss: 0.999928] [G loss: 1.000172]\n",
      "epoch:18 step:88195[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:18 step:88200[D loss: 1.000074] [G loss: 0.999968]\n",
      "##############\n",
      "[2.52496952 2.01479653 2.05952094 3.6768473  1.45036235 7.76072486\n",
      " 2.14644882 3.82333782 3.95257042 6.08107211]\n",
      "##########\n",
      "epoch:18 step:88205[D loss: 0.999918] [G loss: 1.000055]\n",
      "epoch:18 step:88210[D loss: 0.999998] [G loss: 1.000030]\n",
      "epoch:18 step:88215[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:18 step:88220[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:18 step:88225[D loss: 1.000043] [G loss: 0.999982]\n",
      "epoch:18 step:88230[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:18 step:88235[D loss: 0.999937] [G loss: 1.000045]\n",
      "epoch:18 step:88240[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:18 step:88245[D loss: 0.999995] [G loss: 1.000065]\n",
      "epoch:18 step:88250[D loss: 0.999949] [G loss: 1.000113]\n",
      "epoch:18 step:88255[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:18 step:88260[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:18 step:88265[D loss: 0.999938] [G loss: 1.000116]\n",
      "epoch:18 step:88270[D loss: 1.000015] [G loss: 1.000038]\n",
      "epoch:18 step:88275[D loss: 0.999983] [G loss: 1.000143]\n",
      "epoch:18 step:88280[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:18 step:88285[D loss: 0.999985] [G loss: 0.999994]\n",
      "epoch:18 step:88290[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:18 step:88295[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:18 step:88300[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:18 step:88305[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:18 step:88310[D loss: 1.000000] [G loss: 1.000035]\n",
      "epoch:18 step:88315[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:18 step:88320[D loss: 1.000032] [G loss: 1.000005]\n",
      "epoch:18 step:88325[D loss: 0.999932] [G loss: 1.000111]\n",
      "epoch:18 step:88330[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:18 step:88335[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:18 step:88340[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:18 step:88345[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:18 step:88350[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:18 step:88355[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:18 step:88360[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:18 step:88365[D loss: 1.000086] [G loss: 1.000005]\n",
      "epoch:18 step:88370[D loss: 1.000013] [G loss: 1.000117]\n",
      "epoch:18 step:88375[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:18 step:88380[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:18 step:88385[D loss: 0.999988] [G loss: 1.000095]\n",
      "epoch:18 step:88390[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:18 step:88395[D loss: 1.000003] [G loss: 1.000052]\n",
      "epoch:18 step:88400[D loss: 0.999992] [G loss: 1.000018]\n",
      "##############\n",
      "[2.48106251 2.06188434 2.14742742 3.90508644 1.32497807 7.51021696\n",
      " 2.04403135 3.57911181 3.8691323  7.14868929]\n",
      "##########\n",
      "epoch:18 step:88405[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:18 step:88410[D loss: 1.000026] [G loss: 1.000022]\n",
      "epoch:18 step:88415[D loss: 0.999936] [G loss: 1.000076]\n",
      "epoch:18 step:88420[D loss: 0.999977] [G loss: 1.000116]\n",
      "epoch:18 step:88425[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:18 step:88430[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:18 step:88435[D loss: 1.000068] [G loss: 0.999946]\n",
      "epoch:18 step:88440[D loss: 1.000001] [G loss: 1.000032]\n",
      "epoch:18 step:88445[D loss: 0.999997] [G loss: 0.999988]\n",
      "epoch:18 step:88450[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:18 step:88455[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:18 step:88460[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:18 step:88465[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:18 step:88470[D loss: 0.999998] [G loss: 1.000065]\n",
      "epoch:18 step:88475[D loss: 0.999923] [G loss: 1.000089]\n",
      "epoch:18 step:88480[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:18 step:88485[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:18 step:88490[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:18 step:88495[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:18 step:88500[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:18 step:88505[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:18 step:88510[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:18 step:88515[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:18 step:88520[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:18 step:88525[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:18 step:88530[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:18 step:88535[D loss: 0.999975] [G loss: 1.000102]\n",
      "epoch:18 step:88540[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:18 step:88545[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:18 step:88550[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:18 step:88555[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:18 step:88560[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:18 step:88565[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:18 step:88570[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:18 step:88575[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:18 step:88580[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:18 step:88585[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:18 step:88590[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:18 step:88595[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:18 step:88600[D loss: 0.999954] [G loss: 1.000084]\n",
      "##############\n",
      "[2.51010922 2.03590852 2.13578579 3.98409573 1.47976273 7.68931925\n",
      " 2.33451728 3.84530729 3.92663042 7.14771273]\n",
      "##########\n",
      "epoch:18 step:88605[D loss: 0.999998] [G loss: 1.000013]\n",
      "epoch:18 step:88610[D loss: 1.000031] [G loss: 0.999938]\n",
      "epoch:18 step:88615[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:18 step:88620[D loss: 0.999942] [G loss: 1.000101]\n",
      "epoch:18 step:88625[D loss: 1.000011] [G loss: 1.000042]\n",
      "epoch:18 step:88630[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:18 step:88635[D loss: 0.999942] [G loss: 1.000093]\n",
      "epoch:18 step:88640[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:18 step:88645[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:18 step:88650[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:18 step:88655[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:18 step:88660[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:18 step:88665[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:18 step:88670[D loss: 1.000000] [G loss: 1.000016]\n",
      "epoch:18 step:88675[D loss: 1.000013] [G loss: 1.000006]\n",
      "epoch:18 step:88680[D loss: 1.000004] [G loss: 1.000091]\n",
      "epoch:18 step:88685[D loss: 0.999938] [G loss: 1.000070]\n",
      "epoch:18 step:88690[D loss: 1.000007] [G loss: 0.999991]\n",
      "epoch:18 step:88695[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:18 step:88700[D loss: 0.999943] [G loss: 1.000088]\n",
      "epoch:18 step:88705[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:18 step:88710[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:18 step:88715[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:18 step:88720[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:18 step:88725[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:18 step:88730[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:18 step:88735[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:18 step:88740[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:18 step:88745[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:18 step:88750[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:18 step:88755[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:18 step:88760[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:18 step:88765[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:18 step:88770[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:18 step:88775[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:18 step:88780[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:18 step:88785[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:18 step:88790[D loss: 0.999970] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:88795[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:18 step:88800[D loss: 0.999978] [G loss: 1.000062]\n",
      "##############\n",
      "[2.54425304 2.13311279 2.28550758 3.69766843 1.4951145  7.71390304\n",
      " 2.1394142  3.95078916 3.97762645 5.67462796]\n",
      "##########\n",
      "epoch:18 step:88805[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:18 step:88810[D loss: 1.000058] [G loss: 0.999955]\n",
      "epoch:18 step:88815[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:18 step:88820[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:18 step:88825[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:18 step:88830[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:18 step:88835[D loss: 1.000007] [G loss: 1.000044]\n",
      "epoch:18 step:88840[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:18 step:88845[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:18 step:88850[D loss: 0.999980] [G loss: 1.000099]\n",
      "epoch:18 step:88855[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:18 step:88860[D loss: 0.999943] [G loss: 1.000172]\n",
      "epoch:18 step:88865[D loss: 0.999934] [G loss: 1.000074]\n",
      "epoch:18 step:88870[D loss: 0.999998] [G loss: 1.000034]\n",
      "epoch:18 step:88875[D loss: 1.000034] [G loss: 0.999922]\n",
      "epoch:18 step:88880[D loss: 1.000004] [G loss: 0.999931]\n",
      "epoch:18 step:88885[D loss: 0.999945] [G loss: 1.000065]\n",
      "epoch:18 step:88890[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:18 step:88895[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:18 step:88900[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:18 step:88905[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:18 step:88910[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:18 step:88915[D loss: 0.999981] [G loss: 1.000120]\n",
      "epoch:18 step:88920[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:18 step:88925[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:18 step:88930[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:18 step:88935[D loss: 1.000000] [G loss: 1.000028]\n",
      "epoch:18 step:88940[D loss: 0.999999] [G loss: 1.000005]\n",
      "epoch:18 step:88945[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:18 step:88950[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:18 step:88955[D loss: 0.999943] [G loss: 1.000090]\n",
      "epoch:18 step:88960[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:18 step:88965[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:18 step:88970[D loss: 0.999980] [G loss: 1.000023]\n",
      "epoch:18 step:88975[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:18 step:88980[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:18 step:88985[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:18 step:88990[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:18 step:88995[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:18 step:89000[D loss: 0.999972] [G loss: 1.000063]\n",
      "##############\n",
      "[2.59626057 2.08647257 2.13981459 3.95719281 1.50250053 7.59877754\n",
      " 2.32542353 3.79103563 4.00862571 6.00665412]\n",
      "##########\n",
      "epoch:18 step:89005[D loss: 1.000027] [G loss: 1.000026]\n",
      "epoch:18 step:89010[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:18 step:89015[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:19 step:89020[D loss: 1.000029] [G loss: 1.000031]\n",
      "epoch:19 step:89025[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:19 step:89030[D loss: 1.000009] [G loss: 1.000012]\n",
      "epoch:19 step:89035[D loss: 0.999930] [G loss: 1.000112]\n",
      "epoch:19 step:89040[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:19 step:89045[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:19 step:89050[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:19 step:89055[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:19 step:89060[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:19 step:89065[D loss: 1.000037] [G loss: 1.000035]\n",
      "epoch:19 step:89070[D loss: 0.999975] [G loss: 1.000119]\n",
      "epoch:19 step:89075[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:19 step:89080[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:19 step:89085[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:19 step:89090[D loss: 0.999999] [G loss: 1.000088]\n",
      "epoch:19 step:89095[D loss: 0.999943] [G loss: 1.000100]\n",
      "epoch:19 step:89100[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:19 step:89105[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:19 step:89110[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:19 step:89115[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:19 step:89120[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:19 step:89125[D loss: 0.999959] [G loss: 1.000123]\n",
      "epoch:19 step:89130[D loss: 0.999927] [G loss: 1.000118]\n",
      "epoch:19 step:89135[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:19 step:89140[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:19 step:89145[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:19 step:89150[D loss: 1.000045] [G loss: 1.000034]\n",
      "epoch:19 step:89155[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:19 step:89160[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:19 step:89165[D loss: 0.999994] [G loss: 1.000022]\n",
      "epoch:19 step:89170[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:19 step:89175[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:19 step:89180[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:19 step:89185[D loss: 0.999974] [G loss: 1.000115]\n",
      "epoch:19 step:89190[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:19 step:89195[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:19 step:89200[D loss: 0.999958] [G loss: 1.000109]\n",
      "##############\n",
      "[2.58758299 2.12961232 2.12616544 3.76725381 1.53443554 7.59259819\n",
      " 2.26460445 3.60642107 3.99937543 6.33745845]\n",
      "##########\n",
      "epoch:19 step:89205[D loss: 0.999948] [G loss: 1.000079]\n",
      "epoch:19 step:89210[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:19 step:89215[D loss: 1.000040] [G loss: 0.999948]\n",
      "epoch:19 step:89220[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:19 step:89225[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:19 step:89230[D loss: 1.000020] [G loss: 0.999968]\n",
      "epoch:19 step:89235[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:19 step:89240[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:19 step:89245[D loss: 0.999984] [G loss: 1.000014]\n",
      "epoch:19 step:89250[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:19 step:89255[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:19 step:89260[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:19 step:89265[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:19 step:89270[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:19 step:89275[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:19 step:89280[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:19 step:89285[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:19 step:89290[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:19 step:89295[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:19 step:89300[D loss: 1.000006] [G loss: 1.000087]\n",
      "epoch:19 step:89305[D loss: 0.999966] [G loss: 1.000120]\n",
      "epoch:19 step:89310[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:19 step:89315[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:19 step:89320[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:19 step:89325[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:19 step:89330[D loss: 0.999986] [G loss: 1.000111]\n",
      "epoch:19 step:89335[D loss: 1.000003] [G loss: 1.000033]\n",
      "epoch:19 step:89340[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:19 step:89345[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:19 step:89350[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:19 step:89355[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:19 step:89360[D loss: 1.000050] [G loss: 0.999988]\n",
      "epoch:19 step:89365[D loss: 1.000030] [G loss: 0.999995]\n",
      "epoch:19 step:89370[D loss: 1.000059] [G loss: 0.999953]\n",
      "epoch:19 step:89375[D loss: 1.000153] [G loss: 0.999798]\n",
      "epoch:19 step:89380[D loss: 0.999952] [G loss: 1.000019]\n",
      "epoch:19 step:89385[D loss: 0.999904] [G loss: 1.000076]\n",
      "epoch:19 step:89390[D loss: 0.999986] [G loss: 0.999996]\n",
      "epoch:19 step:89395[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:19 step:89400[D loss: 0.999977] [G loss: 1.000016]\n",
      "##############\n",
      "[2.61113157 2.17617352 2.24315289 3.82215276 1.51099114 8.64397269\n",
      " 2.3730113  4.03434339 3.99624249 8.14868929]\n",
      "##########\n",
      "epoch:19 step:89405[D loss: 1.000004] [G loss: 1.000004]\n",
      "epoch:19 step:89410[D loss: 0.999932] [G loss: 1.000100]\n",
      "epoch:19 step:89415[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:19 step:89420[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:19 step:89425[D loss: 0.999954] [G loss: 1.000067]\n",
      "epoch:19 step:89430[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:19 step:89435[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:19 step:89440[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:19 step:89445[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:19 step:89450[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:19 step:89455[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:19 step:89460[D loss: 1.000034] [G loss: 1.000027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:89465[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:19 step:89470[D loss: 0.999957] [G loss: 1.000054]\n",
      "epoch:19 step:89475[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:19 step:89480[D loss: 1.000048] [G loss: 0.999904]\n",
      "epoch:19 step:89485[D loss: 1.000031] [G loss: 0.999960]\n",
      "epoch:19 step:89490[D loss: 1.000014] [G loss: 1.000098]\n",
      "epoch:19 step:89495[D loss: 1.000050] [G loss: 0.999977]\n",
      "epoch:19 step:89500[D loss: 0.999936] [G loss: 1.000233]\n",
      "epoch:19 step:89505[D loss: 1.000022] [G loss: 1.000014]\n",
      "epoch:19 step:89510[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:19 step:89515[D loss: 1.000018] [G loss: 1.000011]\n",
      "epoch:19 step:89520[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:19 step:89525[D loss: 0.999999] [G loss: 1.000068]\n",
      "epoch:19 step:89530[D loss: 1.000002] [G loss: 0.999969]\n",
      "epoch:19 step:89535[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:19 step:89540[D loss: 1.000042] [G loss: 0.999964]\n",
      "epoch:19 step:89545[D loss: 0.999908] [G loss: 1.000099]\n",
      "epoch:19 step:89550[D loss: 1.000005] [G loss: 1.000082]\n",
      "epoch:19 step:89555[D loss: 1.000064] [G loss: 0.999933]\n",
      "epoch:19 step:89560[D loss: 0.999919] [G loss: 1.000127]\n",
      "epoch:19 step:89565[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:19 step:89570[D loss: 0.999919] [G loss: 1.000136]\n",
      "epoch:19 step:89575[D loss: 1.000072] [G loss: 0.999952]\n",
      "epoch:19 step:89580[D loss: 1.000085] [G loss: 0.999946]\n",
      "epoch:19 step:89585[D loss: 0.999961] [G loss: 1.000120]\n",
      "epoch:19 step:89590[D loss: 0.999986] [G loss: 1.000136]\n",
      "epoch:19 step:89595[D loss: 1.000018] [G loss: 0.999956]\n",
      "epoch:19 step:89600[D loss: 0.999979] [G loss: 1.000047]\n",
      "##############\n",
      "[2.64127164 2.23135888 2.22246282 4.00501172 1.57108172 7.40809242\n",
      " 2.48812718 4.17729439 4.03815936 6.01785365]\n",
      "##########\n",
      "epoch:19 step:89605[D loss: 1.000037] [G loss: 0.999960]\n",
      "epoch:19 step:89610[D loss: 1.000016] [G loss: 1.000046]\n",
      "epoch:19 step:89615[D loss: 1.000023] [G loss: 0.999933]\n",
      "epoch:19 step:89620[D loss: 0.999885] [G loss: 1.000154]\n",
      "epoch:19 step:89625[D loss: 0.999927] [G loss: 1.000131]\n",
      "epoch:19 step:89630[D loss: 0.999949] [G loss: 1.000135]\n",
      "epoch:19 step:89635[D loss: 1.000012] [G loss: 0.999929]\n",
      "epoch:19 step:89640[D loss: 0.999946] [G loss: 1.000035]\n",
      "epoch:19 step:89645[D loss: 0.999943] [G loss: 1.000188]\n",
      "epoch:19 step:89650[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:19 step:89655[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:19 step:89660[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:19 step:89665[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:19 step:89670[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:19 step:89675[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:19 step:89680[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:19 step:89685[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:19 step:89690[D loss: 0.999950] [G loss: 1.000053]\n",
      "epoch:19 step:89695[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:19 step:89700[D loss: 0.999944] [G loss: 1.000082]\n",
      "epoch:19 step:89705[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:19 step:89710[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:19 step:89715[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:19 step:89720[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:19 step:89725[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:19 step:89730[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:19 step:89735[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:19 step:89740[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:19 step:89745[D loss: 0.999941] [G loss: 1.000069]\n",
      "epoch:19 step:89750[D loss: 1.000015] [G loss: 1.000034]\n",
      "epoch:19 step:89755[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:19 step:89760[D loss: 0.999996] [G loss: 1.000055]\n",
      "epoch:19 step:89765[D loss: 0.999937] [G loss: 1.000109]\n",
      "epoch:19 step:89770[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:19 step:89775[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:19 step:89780[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:19 step:89785[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:19 step:89790[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:19 step:89795[D loss: 1.000027] [G loss: 1.000009]\n",
      "epoch:19 step:89800[D loss: 0.999947] [G loss: 1.000075]\n",
      "##############\n",
      "[2.60216459 2.1066958  2.15891717 3.8796565  1.54929362 7.64685661\n",
      " 2.1491678  3.76617269 4.02270827 6.18046964]\n",
      "##########\n",
      "epoch:19 step:89805[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:19 step:89810[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:19 step:89815[D loss: 0.999930] [G loss: 1.000098]\n",
      "epoch:19 step:89820[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:19 step:89825[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:19 step:89830[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:19 step:89835[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:19 step:89840[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:19 step:89845[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:19 step:89850[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:19 step:89855[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:19 step:89860[D loss: 0.999999] [G loss: 1.000028]\n",
      "epoch:19 step:89865[D loss: 1.000060] [G loss: 0.999937]\n",
      "epoch:19 step:89870[D loss: 0.999904] [G loss: 1.000211]\n",
      "epoch:19 step:89875[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:19 step:89880[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:19 step:89885[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:19 step:89890[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:19 step:89895[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:19 step:89900[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:19 step:89905[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:19 step:89910[D loss: 1.000011] [G loss: 1.000014]\n",
      "epoch:19 step:89915[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:19 step:89920[D loss: 0.999967] [G loss: 1.000112]\n",
      "epoch:19 step:89925[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:19 step:89930[D loss: 0.999949] [G loss: 1.000135]\n",
      "epoch:19 step:89935[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:19 step:89940[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:19 step:89945[D loss: 0.999990] [G loss: 1.000011]\n",
      "epoch:19 step:89950[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:19 step:89955[D loss: 1.000050] [G loss: 1.000009]\n",
      "epoch:19 step:89960[D loss: 0.999961] [G loss: 1.000046]\n",
      "epoch:19 step:89965[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:19 step:89970[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:19 step:89975[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:19 step:89980[D loss: 1.000044] [G loss: 1.000004]\n",
      "epoch:19 step:89985[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:19 step:89990[D loss: 1.000027] [G loss: 1.000000]\n",
      "epoch:19 step:89995[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:19 step:90000[D loss: 0.999977] [G loss: 1.000127]\n",
      "##############\n",
      "[2.64371499 2.08758118 2.2035529  3.76720924 1.55774175 7.79189731\n",
      " 2.43230807 3.83128408 3.95407594 5.18829051]\n",
      "##########\n",
      "epoch:19 step:90005[D loss: 1.000085] [G loss: 0.999974]\n",
      "epoch:19 step:90010[D loss: 0.999950] [G loss: 1.000066]\n",
      "epoch:19 step:90015[D loss: 0.999976] [G loss: 1.000177]\n",
      "epoch:19 step:90020[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:19 step:90025[D loss: 0.999945] [G loss: 1.000133]\n",
      "epoch:19 step:90030[D loss: 0.999964] [G loss: 1.000111]\n",
      "epoch:19 step:90035[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:19 step:90040[D loss: 0.999985] [G loss: 1.000022]\n",
      "epoch:19 step:90045[D loss: 1.000013] [G loss: 0.999950]\n",
      "epoch:19 step:90050[D loss: 1.000028] [G loss: 0.999996]\n",
      "epoch:19 step:90055[D loss: 0.999943] [G loss: 1.000060]\n",
      "epoch:19 step:90060[D loss: 1.000011] [G loss: 1.000083]\n",
      "epoch:19 step:90065[D loss: 0.999942] [G loss: 1.000123]\n",
      "epoch:19 step:90070[D loss: 0.999922] [G loss: 1.000131]\n",
      "epoch:19 step:90075[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:19 step:90080[D loss: 0.999945] [G loss: 1.000114]\n",
      "epoch:19 step:90085[D loss: 0.999963] [G loss: 1.000131]\n",
      "epoch:19 step:90090[D loss: 0.999985] [G loss: 1.000094]\n",
      "epoch:19 step:90095[D loss: 0.999956] [G loss: 1.000111]\n",
      "epoch:19 step:90100[D loss: 1.000069] [G loss: 1.000071]\n",
      "epoch:19 step:90105[D loss: 0.999969] [G loss: 1.000112]\n",
      "epoch:19 step:90110[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:19 step:90115[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:19 step:90120[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:19 step:90125[D loss: 1.000024] [G loss: 0.999970]\n",
      "epoch:19 step:90130[D loss: 1.000009] [G loss: 1.000030]\n",
      "epoch:19 step:90135[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:19 step:90140[D loss: 1.000025] [G loss: 1.000024]\n",
      "epoch:19 step:90145[D loss: 1.000036] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:90150[D loss: 0.999983] [G loss: 1.000135]\n",
      "epoch:19 step:90155[D loss: 0.999901] [G loss: 1.000179]\n",
      "epoch:19 step:90160[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:19 step:90165[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:19 step:90170[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:19 step:90175[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:19 step:90180[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:19 step:90185[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:19 step:90190[D loss: 1.000014] [G loss: 0.999965]\n",
      "epoch:19 step:90195[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:19 step:90200[D loss: 0.999991] [G loss: 1.000056]\n",
      "##############\n",
      "[2.53206014 2.11780449 2.14301143 3.72236785 1.51671062 6.95815743\n",
      " 2.12458395 3.85726023 3.92616338 5.94408948]\n",
      "##########\n",
      "epoch:19 step:90205[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:19 step:90210[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:19 step:90215[D loss: 0.999998] [G loss: 1.000065]\n",
      "epoch:19 step:90220[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:19 step:90225[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:19 step:90230[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:19 step:90235[D loss: 0.999994] [G loss: 1.000067]\n",
      "epoch:19 step:90240[D loss: 1.000007] [G loss: 0.999998]\n",
      "epoch:19 step:90245[D loss: 0.999932] [G loss: 1.000094]\n",
      "epoch:19 step:90250[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:19 step:90255[D loss: 1.000000] [G loss: 1.000075]\n",
      "epoch:19 step:90260[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:19 step:90265[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:19 step:90270[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:19 step:90275[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:19 step:90280[D loss: 1.000001] [G loss: 1.000065]\n",
      "epoch:19 step:90285[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:19 step:90290[D loss: 1.000011] [G loss: 1.000035]\n",
      "epoch:19 step:90295[D loss: 1.000032] [G loss: 0.999965]\n",
      "epoch:19 step:90300[D loss: 0.999963] [G loss: 1.000097]\n",
      "epoch:19 step:90305[D loss: 1.000075] [G loss: 0.999917]\n",
      "epoch:19 step:90310[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:19 step:90315[D loss: 0.999956] [G loss: 1.000148]\n",
      "epoch:19 step:90320[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:19 step:90325[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:19 step:90330[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:19 step:90335[D loss: 0.999941] [G loss: 1.000050]\n",
      "epoch:19 step:90340[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:19 step:90345[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:19 step:90350[D loss: 0.999978] [G loss: 0.999998]\n",
      "epoch:19 step:90355[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:19 step:90360[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:19 step:90365[D loss: 1.000014] [G loss: 0.999998]\n",
      "epoch:19 step:90370[D loss: 0.999947] [G loss: 1.000105]\n",
      "epoch:19 step:90375[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:19 step:90380[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:19 step:90385[D loss: 0.999977] [G loss: 1.000017]\n",
      "epoch:19 step:90390[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:19 step:90395[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:19 step:90400[D loss: 0.999989] [G loss: 1.000019]\n",
      "##############\n",
      "[2.61572575 2.09268928 2.27157143 3.75512433 1.53668715 7.61527684\n",
      " 2.36299106 3.87614868 4.04429961 5.42282808]\n",
      "##########\n",
      "epoch:19 step:90405[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:19 step:90410[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:19 step:90415[D loss: 0.999971] [G loss: 1.000039]\n",
      "epoch:19 step:90420[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:19 step:90425[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:19 step:90430[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:19 step:90435[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:19 step:90440[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:19 step:90445[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:19 step:90450[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:19 step:90455[D loss: 1.000018] [G loss: 1.000042]\n",
      "epoch:19 step:90460[D loss: 1.000007] [G loss: 1.000020]\n",
      "epoch:19 step:90465[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:19 step:90470[D loss: 0.999997] [G loss: 0.999982]\n",
      "epoch:19 step:90475[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:19 step:90480[D loss: 1.000013] [G loss: 1.000003]\n",
      "epoch:19 step:90485[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:19 step:90490[D loss: 1.000003] [G loss: 1.000074]\n",
      "epoch:19 step:90495[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:19 step:90500[D loss: 0.999983] [G loss: 0.999999]\n",
      "epoch:19 step:90505[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:19 step:90510[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:19 step:90515[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:19 step:90520[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:19 step:90525[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:19 step:90530[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:19 step:90535[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:19 step:90540[D loss: 0.999954] [G loss: 1.000122]\n",
      "epoch:19 step:90545[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:19 step:90550[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:19 step:90555[D loss: 1.000007] [G loss: 1.000005]\n",
      "epoch:19 step:90560[D loss: 1.000047] [G loss: 1.000006]\n",
      "epoch:19 step:90565[D loss: 1.000037] [G loss: 0.999981]\n",
      "epoch:19 step:90570[D loss: 1.000064] [G loss: 0.999961]\n",
      "epoch:19 step:90575[D loss: 0.999943] [G loss: 1.000082]\n",
      "epoch:19 step:90580[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:19 step:90585[D loss: 0.999970] [G loss: 1.000025]\n",
      "epoch:19 step:90590[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:19 step:90595[D loss: 1.000007] [G loss: 1.000045]\n",
      "epoch:19 step:90600[D loss: 0.999991] [G loss: 1.000031]\n",
      "##############\n",
      "[2.5072892  2.06005168 2.03295197 3.71325126 1.46827748 7.31598949\n",
      " 2.20664829 3.80285663 3.9312208  4.51183259]\n",
      "##########\n",
      "epoch:19 step:90605[D loss: 0.999996] [G loss: 1.000002]\n",
      "epoch:19 step:90610[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:19 step:90615[D loss: 1.000006] [G loss: 0.999990]\n",
      "epoch:19 step:90620[D loss: 1.000121] [G loss: 0.999923]\n",
      "epoch:19 step:90625[D loss: 0.999946] [G loss: 1.000184]\n",
      "epoch:19 step:90630[D loss: 1.000005] [G loss: 1.000065]\n",
      "epoch:19 step:90635[D loss: 0.999875] [G loss: 1.000172]\n",
      "epoch:19 step:90640[D loss: 0.999902] [G loss: 1.000137]\n",
      "epoch:19 step:90645[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:19 step:90650[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:19 step:90655[D loss: 0.999945] [G loss: 1.000045]\n",
      "epoch:19 step:90660[D loss: 0.999959] [G loss: 1.000029]\n",
      "epoch:19 step:90665[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:19 step:90670[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:19 step:90675[D loss: 0.999999] [G loss: 0.999961]\n",
      "epoch:19 step:90680[D loss: 1.000014] [G loss: 0.999962]\n",
      "epoch:19 step:90685[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:19 step:90690[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:19 step:90695[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:19 step:90700[D loss: 0.999946] [G loss: 1.000078]\n",
      "epoch:19 step:90705[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:19 step:90710[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:19 step:90715[D loss: 0.999951] [G loss: 1.000068]\n",
      "epoch:19 step:90720[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:19 step:90725[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:19 step:90730[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:19 step:90735[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:19 step:90740[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:19 step:90745[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:19 step:90750[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:19 step:90755[D loss: 1.000024] [G loss: 1.000003]\n",
      "epoch:19 step:90760[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:19 step:90765[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:19 step:90770[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:19 step:90775[D loss: 0.999947] [G loss: 1.000135]\n",
      "epoch:19 step:90780[D loss: 0.999924] [G loss: 1.000124]\n",
      "epoch:19 step:90785[D loss: 1.000023] [G loss: 0.999995]\n",
      "epoch:19 step:90790[D loss: 0.999958] [G loss: 1.000026]\n",
      "epoch:19 step:90795[D loss: 1.000011] [G loss: 1.000023]\n",
      "epoch:19 step:90800[D loss: 0.999960] [G loss: 1.000080]\n",
      "##############\n",
      "[2.53877742 2.09324878 2.14452683 3.82389889 1.38569575 7.00061451\n",
      " 2.20717666 3.96219941 3.92921133 5.06158586]\n",
      "##########\n",
      "epoch:19 step:90805[D loss: 0.999995] [G loss: 1.000110]\n",
      "epoch:19 step:90810[D loss: 0.999995] [G loss: 0.999973]\n",
      "epoch:19 step:90815[D loss: 0.999981] [G loss: 1.000135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:90820[D loss: 0.999926] [G loss: 1.000086]\n",
      "epoch:19 step:90825[D loss: 0.999912] [G loss: 1.000135]\n",
      "epoch:19 step:90830[D loss: 1.000001] [G loss: 0.999995]\n",
      "epoch:19 step:90835[D loss: 1.000038] [G loss: 0.999976]\n",
      "epoch:19 step:90840[D loss: 0.999951] [G loss: 1.000130]\n",
      "epoch:19 step:90845[D loss: 0.999940] [G loss: 1.000119]\n",
      "epoch:19 step:90850[D loss: 1.000084] [G loss: 0.999975]\n",
      "epoch:19 step:90855[D loss: 1.000108] [G loss: 0.999825]\n",
      "epoch:19 step:90860[D loss: 0.999955] [G loss: 1.000118]\n",
      "epoch:19 step:90865[D loss: 0.999885] [G loss: 1.000175]\n",
      "epoch:19 step:90870[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:19 step:90875[D loss: 0.999914] [G loss: 1.000131]\n",
      "epoch:19 step:90880[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:19 step:90885[D loss: 0.999985] [G loss: 1.000106]\n",
      "epoch:19 step:90890[D loss: 1.000001] [G loss: 0.999988]\n",
      "epoch:19 step:90895[D loss: 0.999935] [G loss: 1.000123]\n",
      "epoch:19 step:90900[D loss: 0.999979] [G loss: 1.000104]\n",
      "epoch:19 step:90905[D loss: 1.000142] [G loss: 0.999927]\n",
      "epoch:19 step:90910[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:19 step:90915[D loss: 0.999967] [G loss: 0.999960]\n",
      "epoch:19 step:90920[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:19 step:90925[D loss: 0.999997] [G loss: 0.999985]\n",
      "epoch:19 step:90930[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:19 step:90935[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:19 step:90940[D loss: 1.000002] [G loss: 1.000023]\n",
      "epoch:19 step:90945[D loss: 0.999927] [G loss: 1.000083]\n",
      "epoch:19 step:90950[D loss: 1.000042] [G loss: 1.000023]\n",
      "epoch:19 step:90955[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:19 step:90960[D loss: 0.999960] [G loss: 1.000050]\n",
      "epoch:19 step:90965[D loss: 1.000010] [G loss: 0.999993]\n",
      "epoch:19 step:90970[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:19 step:90975[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:19 step:90980[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:19 step:90985[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:19 step:90990[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:19 step:90995[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:19 step:91000[D loss: 1.000001] [G loss: 0.999980]\n",
      "##############\n",
      "[2.5377957  2.0783685  2.14600601 3.81515794 1.40225171 7.51711649\n",
      " 2.36064759 3.96331353 3.94195217 4.95081316]\n",
      "##########\n",
      "epoch:19 step:91005[D loss: 1.000016] [G loss: 0.999971]\n",
      "epoch:19 step:91010[D loss: 0.999953] [G loss: 1.000102]\n",
      "epoch:19 step:91015[D loss: 1.000029] [G loss: 0.999949]\n",
      "epoch:19 step:91020[D loss: 0.999953] [G loss: 1.000148]\n",
      "epoch:19 step:91025[D loss: 1.000008] [G loss: 1.000057]\n",
      "epoch:19 step:91030[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:19 step:91035[D loss: 1.000002] [G loss: 1.000010]\n",
      "epoch:19 step:91040[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:19 step:91045[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:19 step:91050[D loss: 1.000056] [G loss: 0.999960]\n",
      "epoch:19 step:91055[D loss: 0.999901] [G loss: 1.000111]\n",
      "epoch:19 step:91060[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:19 step:91065[D loss: 1.000031] [G loss: 1.000053]\n",
      "epoch:19 step:91070[D loss: 1.000021] [G loss: 0.999925]\n",
      "epoch:19 step:91075[D loss: 0.999982] [G loss: 1.000024]\n",
      "epoch:19 step:91080[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:19 step:91085[D loss: 1.000000] [G loss: 1.000015]\n",
      "epoch:19 step:91090[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:19 step:91095[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:19 step:91100[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:19 step:91105[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:19 step:91110[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:19 step:91115[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:19 step:91120[D loss: 1.000018] [G loss: 1.000010]\n",
      "epoch:19 step:91125[D loss: 1.000028] [G loss: 1.000029]\n",
      "epoch:19 step:91130[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:19 step:91135[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:19 step:91140[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:19 step:91145[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:19 step:91150[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:19 step:91155[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:19 step:91160[D loss: 0.999953] [G loss: 1.000094]\n",
      "epoch:19 step:91165[D loss: 0.999954] [G loss: 1.000074]\n",
      "epoch:19 step:91170[D loss: 0.999950] [G loss: 1.000090]\n",
      "epoch:19 step:91175[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:19 step:91180[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:19 step:91185[D loss: 1.000015] [G loss: 1.000074]\n",
      "epoch:19 step:91190[D loss: 1.000017] [G loss: 1.000009]\n",
      "epoch:19 step:91195[D loss: 0.999963] [G loss: 1.000045]\n",
      "epoch:19 step:91200[D loss: 0.999980] [G loss: 1.000020]\n",
      "##############\n",
      "[2.58613406 2.10477712 2.28525967 4.10456137 1.55542189 8.13015711\n",
      " 2.54351386 3.92379426 4.08108346 8.14868929]\n",
      "##########\n",
      "epoch:19 step:91205[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:19 step:91210[D loss: 0.999966] [G loss: 1.000025]\n",
      "epoch:19 step:91215[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:19 step:91220[D loss: 0.999967] [G loss: 1.000042]\n",
      "epoch:19 step:91225[D loss: 0.999991] [G loss: 1.000010]\n",
      "epoch:19 step:91230[D loss: 0.999946] [G loss: 1.000116]\n",
      "epoch:19 step:91235[D loss: 0.999921] [G loss: 1.000102]\n",
      "epoch:19 step:91240[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:19 step:91245[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:19 step:91250[D loss: 1.000027] [G loss: 1.000002]\n",
      "epoch:19 step:91255[D loss: 1.000089] [G loss: 0.999879]\n",
      "epoch:19 step:91260[D loss: 0.999928] [G loss: 1.000123]\n",
      "epoch:19 step:91265[D loss: 0.999937] [G loss: 1.000125]\n",
      "epoch:19 step:91270[D loss: 0.999994] [G loss: 1.000001]\n",
      "epoch:19 step:91275[D loss: 0.999937] [G loss: 1.000092]\n",
      "epoch:19 step:91280[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:19 step:91285[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:19 step:91290[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:19 step:91295[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:19 step:91300[D loss: 1.000001] [G loss: 1.000063]\n",
      "epoch:19 step:91305[D loss: 1.000075] [G loss: 0.999961]\n",
      "epoch:19 step:91310[D loss: 1.000063] [G loss: 1.000165]\n",
      "epoch:19 step:91315[D loss: 0.999937] [G loss: 1.000117]\n",
      "epoch:19 step:91320[D loss: 0.999900] [G loss: 1.000155]\n",
      "epoch:19 step:91325[D loss: 0.999985] [G loss: 1.000022]\n",
      "epoch:19 step:91330[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:19 step:91335[D loss: 1.000009] [G loss: 1.000054]\n",
      "epoch:19 step:91340[D loss: 1.000014] [G loss: 1.000013]\n",
      "epoch:19 step:91345[D loss: 0.999989] [G loss: 0.999949]\n",
      "epoch:19 step:91350[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:19 step:91355[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:19 step:91360[D loss: 1.000033] [G loss: 1.000108]\n",
      "epoch:19 step:91365[D loss: 0.999906] [G loss: 1.000182]\n",
      "epoch:19 step:91370[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:19 step:91375[D loss: 0.999917] [G loss: 1.000157]\n",
      "epoch:19 step:91380[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:19 step:91385[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:19 step:91390[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:19 step:91395[D loss: 0.999967] [G loss: 1.000034]\n",
      "epoch:19 step:91400[D loss: 0.999976] [G loss: 1.000033]\n",
      "##############\n",
      "[2.50528725 2.06539101 2.10435527 3.4371244  1.39406189 6.70965814\n",
      " 2.24512659 3.7603382  3.94269437 5.96221926]\n",
      "##########\n",
      "epoch:19 step:91405[D loss: 1.000007] [G loss: 1.000031]\n",
      "epoch:19 step:91410[D loss: 0.999974] [G loss: 1.000019]\n",
      "epoch:19 step:91415[D loss: 0.999940] [G loss: 1.000099]\n",
      "epoch:19 step:91420[D loss: 0.999939] [G loss: 1.000148]\n",
      "epoch:19 step:91425[D loss: 0.999935] [G loss: 1.000095]\n",
      "epoch:19 step:91430[D loss: 1.000004] [G loss: 1.000055]\n",
      "epoch:19 step:91435[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:19 step:91440[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:19 step:91445[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:19 step:91450[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:19 step:91455[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:19 step:91460[D loss: 1.000034] [G loss: 0.999997]\n",
      "epoch:19 step:91465[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:19 step:91470[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:19 step:91475[D loss: 0.999969] [G loss: 1.000147]\n",
      "epoch:19 step:91480[D loss: 0.999937] [G loss: 1.000226]\n",
      "epoch:19 step:91485[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:19 step:91490[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:19 step:91495[D loss: 1.000060] [G loss: 1.000044]\n",
      "epoch:19 step:91500[D loss: 1.000002] [G loss: 1.000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:91505[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:19 step:91510[D loss: 1.000079] [G loss: 0.999891]\n",
      "epoch:19 step:91515[D loss: 1.000039] [G loss: 1.000038]\n",
      "epoch:19 step:91520[D loss: 0.999920] [G loss: 1.000050]\n",
      "epoch:19 step:91525[D loss: 0.999952] [G loss: 1.000064]\n",
      "epoch:19 step:91530[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:19 step:91535[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:19 step:91540[D loss: 0.999949] [G loss: 1.000096]\n",
      "epoch:19 step:91545[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:19 step:91550[D loss: 1.000018] [G loss: 1.000028]\n",
      "epoch:19 step:91555[D loss: 0.999973] [G loss: 1.000156]\n",
      "epoch:19 step:91560[D loss: 0.999945] [G loss: 1.000138]\n",
      "epoch:19 step:91565[D loss: 1.000024] [G loss: 1.000152]\n",
      "epoch:19 step:91570[D loss: 0.999912] [G loss: 1.000139]\n",
      "epoch:19 step:91575[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:19 step:91580[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:19 step:91585[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:19 step:91590[D loss: 0.999984] [G loss: 1.000086]\n",
      "epoch:19 step:91595[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:19 step:91600[D loss: 1.000045] [G loss: 1.000001]\n",
      "##############\n",
      "[2.46044285 2.07841814 2.23602707 3.65570599 1.47973838 7.44656138\n",
      " 2.21948759 3.89243877 3.97359986 4.70696027]\n",
      "##########\n",
      "epoch:19 step:91605[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:19 step:91610[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:19 step:91615[D loss: 0.999942] [G loss: 1.000146]\n",
      "epoch:19 step:91620[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:19 step:91625[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:19 step:91630[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:19 step:91635[D loss: 0.999960] [G loss: 1.000136]\n",
      "epoch:19 step:91640[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:19 step:91645[D loss: 1.000022] [G loss: 0.999971]\n",
      "epoch:19 step:91650[D loss: 0.999967] [G loss: 1.000019]\n",
      "epoch:19 step:91655[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:19 step:91660[D loss: 0.999992] [G loss: 1.000013]\n",
      "epoch:19 step:91665[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:19 step:91670[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:19 step:91675[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:19 step:91680[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:19 step:91685[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:19 step:91690[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:19 step:91695[D loss: 0.999974] [G loss: 1.000132]\n",
      "epoch:19 step:91700[D loss: 0.999980] [G loss: 1.000096]\n",
      "epoch:19 step:91705[D loss: 1.000020] [G loss: 1.000023]\n",
      "epoch:19 step:91710[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:19 step:91715[D loss: 0.999946] [G loss: 1.000070]\n",
      "epoch:19 step:91720[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:19 step:91725[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:19 step:91730[D loss: 1.000050] [G loss: 1.000030]\n",
      "epoch:19 step:91735[D loss: 0.999953] [G loss: 1.000153]\n",
      "epoch:19 step:91740[D loss: 1.000001] [G loss: 1.000082]\n",
      "epoch:19 step:91745[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:19 step:91750[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:19 step:91755[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:19 step:91760[D loss: 1.000011] [G loss: 1.000030]\n",
      "epoch:19 step:91765[D loss: 0.999970] [G loss: 1.000109]\n",
      "epoch:19 step:91770[D loss: 1.000044] [G loss: 1.000004]\n",
      "epoch:19 step:91775[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:19 step:91780[D loss: 1.000021] [G loss: 1.000031]\n",
      "epoch:19 step:91785[D loss: 0.999949] [G loss: 1.000073]\n",
      "epoch:19 step:91790[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:19 step:91795[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:19 step:91800[D loss: 0.999958] [G loss: 1.000072]\n",
      "##############\n",
      "[2.46035886 2.07167825 2.05589304 3.79316656 1.46352594 7.40649534\n",
      " 2.44120457 3.90773291 3.95886443 5.21601729]\n",
      "##########\n",
      "epoch:19 step:91805[D loss: 1.000000] [G loss: 1.000049]\n",
      "epoch:19 step:91810[D loss: 1.000006] [G loss: 1.000047]\n",
      "epoch:19 step:91815[D loss: 0.999943] [G loss: 1.000088]\n",
      "epoch:19 step:91820[D loss: 0.999963] [G loss: 1.000116]\n",
      "epoch:19 step:91825[D loss: 0.999948] [G loss: 1.000109]\n",
      "epoch:19 step:91830[D loss: 0.999983] [G loss: 1.000124]\n",
      "epoch:19 step:91835[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:19 step:91840[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:19 step:91845[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:19 step:91850[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:19 step:91855[D loss: 0.999959] [G loss: 1.000047]\n",
      "epoch:19 step:91860[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:19 step:91865[D loss: 1.000005] [G loss: 1.000042]\n",
      "epoch:19 step:91870[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:19 step:91875[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:19 step:91880[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:19 step:91885[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:19 step:91890[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:19 step:91895[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:19 step:91900[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:19 step:91905[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:19 step:91910[D loss: 1.000000] [G loss: 1.000016]\n",
      "epoch:19 step:91915[D loss: 1.000058] [G loss: 1.000056]\n",
      "epoch:19 step:91920[D loss: 0.999913] [G loss: 1.000120]\n",
      "epoch:19 step:91925[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:19 step:91930[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:19 step:91935[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:19 step:91940[D loss: 1.000005] [G loss: 0.999990]\n",
      "epoch:19 step:91945[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:19 step:91950[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:19 step:91955[D loss: 1.000005] [G loss: 1.000085]\n",
      "epoch:19 step:91960[D loss: 1.000012] [G loss: 1.000079]\n",
      "epoch:19 step:91965[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:19 step:91970[D loss: 0.999960] [G loss: 1.000098]\n",
      "epoch:19 step:91975[D loss: 1.000026] [G loss: 0.999993]\n",
      "epoch:19 step:91980[D loss: 1.000096] [G loss: 0.999939]\n",
      "epoch:19 step:91985[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:19 step:91990[D loss: 1.000105] [G loss: 1.000041]\n",
      "epoch:19 step:91995[D loss: 1.000017] [G loss: 1.000050]\n",
      "epoch:19 step:92000[D loss: 0.999941] [G loss: 1.000137]\n",
      "##############\n",
      "[2.62665253 2.08784558 2.19283208 3.88558073 1.48078655 7.10928214\n",
      " 2.30633662 3.94236903 3.99731064 5.4945236 ]\n",
      "##########\n",
      "epoch:19 step:92005[D loss: 0.999923] [G loss: 1.000140]\n",
      "epoch:19 step:92010[D loss: 0.999965] [G loss: 1.000110]\n",
      "epoch:19 step:92015[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:19 step:92020[D loss: 1.000022] [G loss: 1.000004]\n",
      "epoch:19 step:92025[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:19 step:92030[D loss: 0.999945] [G loss: 1.000082]\n",
      "epoch:19 step:92035[D loss: 0.999963] [G loss: 1.000121]\n",
      "epoch:19 step:92040[D loss: 1.000021] [G loss: 1.000030]\n",
      "epoch:19 step:92045[D loss: 0.999936] [G loss: 1.000061]\n",
      "epoch:19 step:92050[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:19 step:92055[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:19 step:92060[D loss: 1.000103] [G loss: 0.999945]\n",
      "epoch:19 step:92065[D loss: 0.999933] [G loss: 1.000091]\n",
      "epoch:19 step:92070[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:19 step:92075[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:19 step:92080[D loss: 0.999948] [G loss: 1.000097]\n",
      "epoch:19 step:92085[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:19 step:92090[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:19 step:92095[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:19 step:92100[D loss: 1.000013] [G loss: 1.000047]\n",
      "epoch:19 step:92105[D loss: 1.000013] [G loss: 1.000042]\n",
      "epoch:19 step:92110[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:19 step:92115[D loss: 1.000039] [G loss: 1.000014]\n",
      "epoch:19 step:92120[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:19 step:92125[D loss: 0.999996] [G loss: 1.000078]\n",
      "epoch:19 step:92130[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:19 step:92135[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:19 step:92140[D loss: 0.999992] [G loss: 1.000129]\n",
      "epoch:19 step:92145[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:19 step:92150[D loss: 1.000019] [G loss: 1.000027]\n",
      "epoch:19 step:92155[D loss: 1.000027] [G loss: 0.999993]\n",
      "epoch:19 step:92160[D loss: 0.999949] [G loss: 1.000112]\n",
      "epoch:19 step:92165[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:19 step:92170[D loss: 0.999950] [G loss: 1.000089]\n",
      "epoch:19 step:92175[D loss: 0.999936] [G loss: 1.000107]\n",
      "epoch:19 step:92180[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:19 step:92185[D loss: 0.999972] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:92190[D loss: 0.999986] [G loss: 1.000091]\n",
      "epoch:19 step:92195[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:19 step:92200[D loss: 0.999996] [G loss: 1.000076]\n",
      "##############\n",
      "[2.42868207 2.03544627 2.07758562 3.94495986 1.42906388 7.38973331\n",
      " 2.22338352 3.84396465 3.89837526 5.05009653]\n",
      "##########\n",
      "epoch:19 step:92205[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:19 step:92210[D loss: 0.999937] [G loss: 1.000129]\n",
      "epoch:19 step:92215[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:19 step:92220[D loss: 1.000015] [G loss: 1.000026]\n",
      "epoch:19 step:92225[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:19 step:92230[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:19 step:92235[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:19 step:92240[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:19 step:92245[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:19 step:92250[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:19 step:92255[D loss: 1.000027] [G loss: 0.999967]\n",
      "epoch:19 step:92260[D loss: 1.000011] [G loss: 1.000019]\n",
      "epoch:19 step:92265[D loss: 0.999956] [G loss: 1.000059]\n",
      "epoch:19 step:92270[D loss: 1.000004] [G loss: 1.000096]\n",
      "epoch:19 step:92275[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:19 step:92280[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:19 step:92285[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:19 step:92290[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:19 step:92295[D loss: 1.000010] [G loss: 1.000008]\n",
      "epoch:19 step:92300[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:19 step:92305[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:19 step:92310[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:19 step:92315[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:19 step:92320[D loss: 1.000050] [G loss: 0.999972]\n",
      "epoch:19 step:92325[D loss: 1.000012] [G loss: 1.000080]\n",
      "epoch:19 step:92330[D loss: 1.000007] [G loss: 1.000067]\n",
      "epoch:19 step:92335[D loss: 0.999960] [G loss: 1.000014]\n",
      "epoch:19 step:92340[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:19 step:92345[D loss: 1.000007] [G loss: 1.000017]\n",
      "epoch:19 step:92350[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:19 step:92355[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:19 step:92360[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:19 step:92365[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:19 step:92370[D loss: 0.999994] [G loss: 1.000009]\n",
      "epoch:19 step:92375[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:19 step:92380[D loss: 0.999987] [G loss: 1.000024]\n",
      "epoch:19 step:92385[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:19 step:92390[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:19 step:92395[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:19 step:92400[D loss: 0.999960] [G loss: 1.000090]\n",
      "##############\n",
      "[2.58608386 2.09903358 2.21258049 3.98919519 1.44456169 7.56017631\n",
      " 2.30371791 3.81212337 3.89321411 5.33389284]\n",
      "##########\n",
      "epoch:19 step:92405[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:19 step:92410[D loss: 1.000003] [G loss: 1.000032]\n",
      "epoch:19 step:92415[D loss: 1.000010] [G loss: 1.000004]\n",
      "epoch:19 step:92420[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:19 step:92425[D loss: 0.999955] [G loss: 1.000109]\n",
      "epoch:19 step:92430[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:19 step:92435[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:19 step:92440[D loss: 1.000010] [G loss: 1.000016]\n",
      "epoch:19 step:92445[D loss: 1.000011] [G loss: 0.999971]\n",
      "epoch:19 step:92450[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:19 step:92455[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:19 step:92460[D loss: 0.999950] [G loss: 1.000187]\n",
      "epoch:19 step:92465[D loss: 0.999930] [G loss: 1.000106]\n",
      "epoch:19 step:92470[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:19 step:92475[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:19 step:92480[D loss: 1.000089] [G loss: 0.999985]\n",
      "epoch:19 step:92485[D loss: 1.000023] [G loss: 1.000023]\n",
      "epoch:19 step:92490[D loss: 0.999994] [G loss: 1.000026]\n",
      "epoch:19 step:92495[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:19 step:92500[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:19 step:92505[D loss: 0.999976] [G loss: 1.000022]\n",
      "epoch:19 step:92510[D loss: 1.000049] [G loss: 0.999970]\n",
      "epoch:19 step:92515[D loss: 0.999920] [G loss: 1.000134]\n",
      "epoch:19 step:92520[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:19 step:92525[D loss: 1.000007] [G loss: 1.000039]\n",
      "epoch:19 step:92530[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:19 step:92535[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:19 step:92540[D loss: 1.000004] [G loss: 1.000085]\n",
      "epoch:19 step:92545[D loss: 0.999917] [G loss: 1.000216]\n",
      "epoch:19 step:92550[D loss: 0.999933] [G loss: 1.000154]\n",
      "epoch:19 step:92555[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:19 step:92560[D loss: 1.000083] [G loss: 0.999939]\n",
      "epoch:19 step:92565[D loss: 1.000059] [G loss: 0.999954]\n",
      "epoch:19 step:92570[D loss: 1.000063] [G loss: 0.999918]\n",
      "epoch:19 step:92575[D loss: 0.999941] [G loss: 1.000060]\n",
      "epoch:19 step:92580[D loss: 0.999998] [G loss: 0.999969]\n",
      "epoch:19 step:92585[D loss: 1.000064] [G loss: 1.000036]\n",
      "epoch:19 step:92590[D loss: 0.999926] [G loss: 1.000165]\n",
      "epoch:19 step:92595[D loss: 0.999900] [G loss: 1.000121]\n",
      "epoch:19 step:92600[D loss: 0.999976] [G loss: 1.000052]\n",
      "##############\n",
      "[2.62439207 2.185006   2.35217789 3.78725287 1.54953657 7.62003837\n",
      " 2.48296757 3.89174727 4.07912893 6.30613276]\n",
      "##########\n",
      "epoch:19 step:92605[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:19 step:92610[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:19 step:92615[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:19 step:92620[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:19 step:92625[D loss: 1.000021] [G loss: 1.000040]\n",
      "epoch:19 step:92630[D loss: 1.000037] [G loss: 1.000017]\n",
      "epoch:19 step:92635[D loss: 1.000010] [G loss: 1.000063]\n",
      "epoch:19 step:92640[D loss: 0.999983] [G loss: 1.000023]\n",
      "epoch:19 step:92645[D loss: 0.999949] [G loss: 1.000121]\n",
      "epoch:19 step:92650[D loss: 1.000004] [G loss: 1.000027]\n",
      "epoch:19 step:92655[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:19 step:92660[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:19 step:92665[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:19 step:92670[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:19 step:92675[D loss: 0.999980] [G loss: 1.000097]\n",
      "epoch:19 step:92680[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:19 step:92685[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:19 step:92690[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:19 step:92695[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:19 step:92700[D loss: 1.000003] [G loss: 1.000096]\n",
      "epoch:19 step:92705[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:19 step:92710[D loss: 1.000031] [G loss: 1.000051]\n",
      "epoch:19 step:92715[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:19 step:92720[D loss: 0.999984] [G loss: 1.000017]\n",
      "epoch:19 step:92725[D loss: 1.000116] [G loss: 0.999948]\n",
      "epoch:19 step:92730[D loss: 0.999895] [G loss: 1.000005]\n",
      "epoch:19 step:92735[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:19 step:92740[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:19 step:92745[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:19 step:92750[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:19 step:92755[D loss: 1.000035] [G loss: 1.000017]\n",
      "epoch:19 step:92760[D loss: 0.999982] [G loss: 0.999994]\n",
      "epoch:19 step:92765[D loss: 0.999942] [G loss: 1.000072]\n",
      "epoch:19 step:92770[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:19 step:92775[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:19 step:92780[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:19 step:92785[D loss: 1.000002] [G loss: 1.000012]\n",
      "epoch:19 step:92790[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:19 step:92795[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:19 step:92800[D loss: 0.999953] [G loss: 1.000089]\n",
      "##############\n",
      "[2.60036891 2.07476055 2.19679524 3.7305922  1.45671645 7.43257582\n",
      " 2.2323894  3.89774752 3.95270118 5.33645322]\n",
      "##########\n",
      "epoch:19 step:92805[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:19 step:92810[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:19 step:92815[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:19 step:92820[D loss: 1.000000] [G loss: 1.000012]\n",
      "epoch:19 step:92825[D loss: 1.000005] [G loss: 1.000053]\n",
      "epoch:19 step:92830[D loss: 0.999921] [G loss: 1.000128]\n",
      "epoch:19 step:92835[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:19 step:92840[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:19 step:92845[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:19 step:92850[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:19 step:92855[D loss: 0.999958] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:92860[D loss: 0.999940] [G loss: 1.000078]\n",
      "epoch:19 step:92865[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:19 step:92870[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:19 step:92875[D loss: 0.999966] [G loss: 1.000146]\n",
      "epoch:19 step:92880[D loss: 1.000012] [G loss: 0.999985]\n",
      "epoch:19 step:92885[D loss: 1.000016] [G loss: 1.000064]\n",
      "epoch:19 step:92890[D loss: 0.999920] [G loss: 1.000059]\n",
      "epoch:19 step:92895[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:19 step:92900[D loss: 1.000026] [G loss: 0.999980]\n",
      "epoch:19 step:92905[D loss: 1.000047] [G loss: 0.999991]\n",
      "epoch:19 step:92910[D loss: 1.000038] [G loss: 1.000019]\n",
      "epoch:19 step:92915[D loss: 1.000020] [G loss: 1.000009]\n",
      "epoch:19 step:92920[D loss: 0.999882] [G loss: 1.000080]\n",
      "epoch:19 step:92925[D loss: 0.999934] [G loss: 1.000105]\n",
      "epoch:19 step:92930[D loss: 0.999953] [G loss: 1.000117]\n",
      "epoch:19 step:92935[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:19 step:92940[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:19 step:92945[D loss: 0.999959] [G loss: 1.000108]\n",
      "epoch:19 step:92950[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:19 step:92955[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:19 step:92960[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:19 step:92965[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:19 step:92970[D loss: 1.000048] [G loss: 0.999942]\n",
      "epoch:19 step:92975[D loss: 0.999974] [G loss: 1.000025]\n",
      "epoch:19 step:92980[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:19 step:92985[D loss: 0.999947] [G loss: 1.000117]\n",
      "epoch:19 step:92990[D loss: 0.999951] [G loss: 1.000117]\n",
      "epoch:19 step:92995[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:19 step:93000[D loss: 0.999988] [G loss: 1.000064]\n",
      "##############\n",
      "[2.53254656 2.18043942 2.27421276 4.17881665 1.48732486 7.46612381\n",
      " 2.37324175 3.83962649 4.00713351 5.26407795]\n",
      "##########\n",
      "epoch:19 step:93005[D loss: 1.000015] [G loss: 1.000100]\n",
      "epoch:19 step:93010[D loss: 0.999901] [G loss: 1.000155]\n",
      "epoch:19 step:93015[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:19 step:93020[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:19 step:93025[D loss: 0.999989] [G loss: 1.000008]\n",
      "epoch:19 step:93030[D loss: 0.999974] [G loss: 1.000030]\n",
      "epoch:19 step:93035[D loss: 0.999995] [G loss: 1.000081]\n",
      "epoch:19 step:93040[D loss: 1.000004] [G loss: 1.000090]\n",
      "epoch:19 step:93045[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:19 step:93050[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:19 step:93055[D loss: 1.000069] [G loss: 1.000032]\n",
      "epoch:19 step:93060[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:19 step:93065[D loss: 0.999941] [G loss: 1.000105]\n",
      "epoch:19 step:93070[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:19 step:93075[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:19 step:93080[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:19 step:93085[D loss: 1.000024] [G loss: 0.999960]\n",
      "epoch:19 step:93090[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:19 step:93095[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:19 step:93100[D loss: 0.999954] [G loss: 1.000071]\n",
      "epoch:19 step:93105[D loss: 0.999989] [G loss: 1.000010]\n",
      "epoch:19 step:93110[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:19 step:93115[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:19 step:93120[D loss: 1.000009] [G loss: 1.000000]\n",
      "epoch:19 step:93125[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:19 step:93130[D loss: 0.999942] [G loss: 1.000109]\n",
      "epoch:19 step:93135[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:19 step:93140[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:19 step:93145[D loss: 0.999956] [G loss: 1.000116]\n",
      "epoch:19 step:93150[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:19 step:93155[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:19 step:93160[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:19 step:93165[D loss: 0.999980] [G loss: 1.000102]\n",
      "epoch:19 step:93170[D loss: 0.999988] [G loss: 1.000100]\n",
      "epoch:19 step:93175[D loss: 1.000029] [G loss: 1.000039]\n",
      "epoch:19 step:93180[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:19 step:93185[D loss: 1.000033] [G loss: 1.000037]\n",
      "epoch:19 step:93190[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:19 step:93195[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:19 step:93200[D loss: 0.999974] [G loss: 1.000105]\n",
      "##############\n",
      "[2.50573228 2.10306541 2.27539386 3.87140808 1.33478383 7.747545\n",
      " 2.29091548 3.85372501 3.9987696  5.18205248]\n",
      "##########\n",
      "epoch:19 step:93205[D loss: 1.000031] [G loss: 1.000002]\n",
      "epoch:19 step:93210[D loss: 1.000013] [G loss: 1.000039]\n",
      "epoch:19 step:93215[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:19 step:93220[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:19 step:93225[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:19 step:93230[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:19 step:93235[D loss: 1.000025] [G loss: 1.000067]\n",
      "epoch:19 step:93240[D loss: 0.999959] [G loss: 1.000129]\n",
      "epoch:19 step:93245[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:19 step:93250[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:19 step:93255[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:19 step:93260[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:19 step:93265[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:19 step:93270[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:19 step:93275[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:19 step:93280[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:19 step:93285[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:19 step:93290[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:19 step:93295[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:19 step:93300[D loss: 1.000005] [G loss: 0.999976]\n",
      "epoch:19 step:93305[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:19 step:93310[D loss: 1.000005] [G loss: 1.000073]\n",
      "epoch:19 step:93315[D loss: 0.999938] [G loss: 1.000131]\n",
      "epoch:19 step:93320[D loss: 0.999948] [G loss: 1.000087]\n",
      "epoch:19 step:93325[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:19 step:93330[D loss: 0.999959] [G loss: 1.000109]\n",
      "epoch:19 step:93335[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:19 step:93340[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:19 step:93345[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:19 step:93350[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:19 step:93355[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:19 step:93360[D loss: 1.000022] [G loss: 0.999926]\n",
      "epoch:19 step:93365[D loss: 1.000062] [G loss: 0.999991]\n",
      "epoch:19 step:93370[D loss: 0.999940] [G loss: 1.000077]\n",
      "epoch:19 step:93375[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:19 step:93380[D loss: 1.000017] [G loss: 1.000064]\n",
      "epoch:19 step:93385[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:19 step:93390[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:19 step:93395[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:19 step:93400[D loss: 0.999978] [G loss: 1.000074]\n",
      "##############\n",
      "[2.52981349 2.07755439 2.0815104  3.86646949 1.38582677 7.71016242\n",
      " 2.3392933  3.71406489 3.91131044 5.41750432]\n",
      "##########\n",
      "epoch:19 step:93405[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:19 step:93410[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:19 step:93415[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:19 step:93420[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:19 step:93425[D loss: 0.999972] [G loss: 1.000020]\n",
      "epoch:19 step:93430[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:19 step:93435[D loss: 0.999954] [G loss: 1.000094]\n",
      "epoch:19 step:93440[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:19 step:93445[D loss: 1.000005] [G loss: 0.999988]\n",
      "epoch:19 step:93450[D loss: 0.999947] [G loss: 1.000081]\n",
      "epoch:19 step:93455[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:19 step:93460[D loss: 1.000001] [G loss: 1.000067]\n",
      "epoch:19 step:93465[D loss: 0.999951] [G loss: 1.000102]\n",
      "epoch:19 step:93470[D loss: 0.999998] [G loss: 1.000067]\n",
      "epoch:19 step:93475[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:19 step:93480[D loss: 1.000005] [G loss: 1.000046]\n",
      "epoch:19 step:93485[D loss: 0.999945] [G loss: 1.000098]\n",
      "epoch:19 step:93490[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:19 step:93495[D loss: 1.000079] [G loss: 0.999981]\n",
      "epoch:19 step:93500[D loss: 1.000001] [G loss: 1.000006]\n",
      "epoch:19 step:93505[D loss: 0.999953] [G loss: 1.000048]\n",
      "epoch:19 step:93510[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:19 step:93515[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:19 step:93520[D loss: 1.000028] [G loss: 1.000021]\n",
      "epoch:19 step:93525[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:19 step:93530[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:19 step:93535[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:19 step:93540[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:19 step:93545[D loss: 0.999992] [G loss: 1.000083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:93550[D loss: 0.999931] [G loss: 1.000076]\n",
      "epoch:19 step:93555[D loss: 1.000018] [G loss: 1.000054]\n",
      "epoch:19 step:93560[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:19 step:93565[D loss: 0.999942] [G loss: 1.000088]\n",
      "epoch:19 step:93570[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:19 step:93575[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:19 step:93580[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:19 step:93585[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:19 step:93590[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:19 step:93595[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:19 step:93600[D loss: 0.999963] [G loss: 1.000196]\n",
      "##############\n",
      "[2.53655635 2.1273411  2.38090848 3.67433946 1.46503578 7.00409812\n",
      " 2.29179207 3.80320507 3.95349846 4.7562824 ]\n",
      "##########\n",
      "epoch:19 step:93605[D loss: 0.999916] [G loss: 1.000109]\n",
      "epoch:19 step:93610[D loss: 0.999943] [G loss: 1.000084]\n",
      "epoch:19 step:93615[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:19 step:93620[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:19 step:93625[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:19 step:93630[D loss: 0.999994] [G loss: 1.000063]\n",
      "epoch:19 step:93635[D loss: 0.999958] [G loss: 1.000104]\n",
      "epoch:19 step:93640[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:19 step:93645[D loss: 1.000002] [G loss: 1.000040]\n",
      "epoch:19 step:93650[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:19 step:93655[D loss: 0.999933] [G loss: 1.000100]\n",
      "epoch:19 step:93660[D loss: 0.999955] [G loss: 1.000139]\n",
      "epoch:19 step:93665[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:19 step:93670[D loss: 0.999973] [G loss: 1.000112]\n",
      "epoch:19 step:93675[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:19 step:93680[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:19 step:93685[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:19 step:93690[D loss: 1.000025] [G loss: 0.999963]\n",
      "epoch:19 step:93695[D loss: 0.999976] [G loss: 1.000015]\n",
      "epoch:19 step:93700[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:20 step:93705[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:20 step:93710[D loss: 0.999951] [G loss: 1.000093]\n",
      "epoch:20 step:93715[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:20 step:93720[D loss: 0.999992] [G loss: 1.000000]\n",
      "epoch:20 step:93725[D loss: 0.999925] [G loss: 1.000130]\n",
      "epoch:20 step:93730[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:20 step:93735[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:20 step:93740[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:20 step:93745[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:20 step:93750[D loss: 1.000019] [G loss: 1.000058]\n",
      "epoch:20 step:93755[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:20 step:93760[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:20 step:93765[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:20 step:93770[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:20 step:93775[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:20 step:93780[D loss: 0.999955] [G loss: 1.000075]\n",
      "epoch:20 step:93785[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:20 step:93790[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:20 step:93795[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:20 step:93800[D loss: 0.999944] [G loss: 1.000090]\n",
      "##############\n",
      "[2.56224946 2.07256107 2.17078366 3.72394854 1.41960896 8.03911795\n",
      " 2.28663098 3.96596872 3.87638916 4.90945961]\n",
      "##########\n",
      "epoch:20 step:93805[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:20 step:93810[D loss: 0.999945] [G loss: 1.000141]\n",
      "epoch:20 step:93815[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:20 step:93820[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:20 step:93825[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:20 step:93830[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:20 step:93835[D loss: 0.999982] [G loss: 1.000102]\n",
      "epoch:20 step:93840[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:20 step:93845[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:20 step:93850[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:20 step:93855[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:20 step:93860[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:20 step:93865[D loss: 0.999951] [G loss: 1.000112]\n",
      "epoch:20 step:93870[D loss: 1.000002] [G loss: 1.000111]\n",
      "epoch:20 step:93875[D loss: 0.999915] [G loss: 1.000160]\n",
      "epoch:20 step:93880[D loss: 1.000077] [G loss: 0.999963]\n",
      "epoch:20 step:93885[D loss: 1.000010] [G loss: 1.000091]\n",
      "epoch:20 step:93890[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:20 step:93895[D loss: 0.999999] [G loss: 1.000009]\n",
      "epoch:20 step:93900[D loss: 1.000093] [G loss: 0.999907]\n",
      "epoch:20 step:93905[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:20 step:93910[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:20 step:93915[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:20 step:93920[D loss: 0.999930] [G loss: 1.000105]\n",
      "epoch:20 step:93925[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:20 step:93930[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:20 step:93935[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:20 step:93940[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:20 step:93945[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:20 step:93950[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:20 step:93955[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:20 step:93960[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:20 step:93965[D loss: 1.000013] [G loss: 1.000007]\n",
      "epoch:20 step:93970[D loss: 1.000019] [G loss: 1.000038]\n",
      "epoch:20 step:93975[D loss: 0.999947] [G loss: 1.000118]\n",
      "epoch:20 step:93980[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:20 step:93985[D loss: 0.999990] [G loss: 1.000083]\n",
      "epoch:20 step:93990[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:20 step:93995[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:20 step:94000[D loss: 0.999943] [G loss: 1.000119]\n",
      "##############\n",
      "[ 2.55087363  2.18040926  2.27103063  3.72539281  1.48032901 10.27426719\n",
      "  2.33281554  3.84482791  3.97098628  5.38126029]\n",
      "##########\n",
      "epoch:20 step:94005[D loss: 0.999938] [G loss: 1.000116]\n",
      "epoch:20 step:94010[D loss: 1.000024] [G loss: 1.000059]\n",
      "epoch:20 step:94015[D loss: 0.999947] [G loss: 1.000195]\n",
      "epoch:20 step:94020[D loss: 0.999957] [G loss: 1.000143]\n",
      "epoch:20 step:94025[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:20 step:94030[D loss: 0.999959] [G loss: 1.000021]\n",
      "epoch:20 step:94035[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:20 step:94040[D loss: 0.999993] [G loss: 1.000005]\n",
      "epoch:20 step:94045[D loss: 1.000066] [G loss: 0.999973]\n",
      "epoch:20 step:94050[D loss: 1.000078] [G loss: 0.999865]\n",
      "epoch:20 step:94055[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:20 step:94060[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:20 step:94065[D loss: 0.999911] [G loss: 1.000118]\n",
      "epoch:20 step:94070[D loss: 0.999957] [G loss: 1.000052]\n",
      "epoch:20 step:94075[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:20 step:94080[D loss: 0.999974] [G loss: 1.000008]\n",
      "epoch:20 step:94085[D loss: 0.999973] [G loss: 1.000020]\n",
      "epoch:20 step:94090[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:20 step:94095[D loss: 1.000007] [G loss: 1.000043]\n",
      "epoch:20 step:94100[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:20 step:94105[D loss: 0.999914] [G loss: 1.000153]\n",
      "epoch:20 step:94110[D loss: 0.999967] [G loss: 1.000032]\n",
      "epoch:20 step:94115[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:20 step:94120[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:20 step:94125[D loss: 0.999991] [G loss: 1.000014]\n",
      "epoch:20 step:94130[D loss: 0.999981] [G loss: 1.000019]\n",
      "epoch:20 step:94135[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:20 step:94140[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:20 step:94145[D loss: 1.000039] [G loss: 1.000013]\n",
      "epoch:20 step:94150[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:20 step:94155[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:20 step:94160[D loss: 0.999955] [G loss: 1.000054]\n",
      "epoch:20 step:94165[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:20 step:94170[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:20 step:94175[D loss: 1.000026] [G loss: 0.999987]\n",
      "epoch:20 step:94180[D loss: 1.000007] [G loss: 1.000046]\n",
      "epoch:20 step:94185[D loss: 1.000014] [G loss: 1.000026]\n",
      "epoch:20 step:94190[D loss: 0.999993] [G loss: 1.000077]\n",
      "epoch:20 step:94195[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:20 step:94200[D loss: 0.999961] [G loss: 1.000053]\n",
      "##############\n",
      "[2.51146998 2.11101777 2.13534328 4.00804494 1.43607737 7.79188262\n",
      " 2.191886   3.85379541 3.92426815 5.03792177]\n",
      "##########\n",
      "epoch:20 step:94205[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:20 step:94210[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:20 step:94215[D loss: 1.000007] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:94220[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:20 step:94225[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:20 step:94230[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:20 step:94235[D loss: 0.999958] [G loss: 1.000111]\n",
      "epoch:20 step:94240[D loss: 1.000005] [G loss: 1.000056]\n",
      "epoch:20 step:94245[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:20 step:94250[D loss: 0.999885] [G loss: 1.000195]\n",
      "epoch:20 step:94255[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:20 step:94260[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:20 step:94265[D loss: 0.999992] [G loss: 1.000110]\n",
      "epoch:20 step:94270[D loss: 0.999942] [G loss: 1.000097]\n",
      "epoch:20 step:94275[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:20 step:94280[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:20 step:94285[D loss: 1.000051] [G loss: 0.999986]\n",
      "epoch:20 step:94290[D loss: 0.999929] [G loss: 1.000175]\n",
      "epoch:20 step:94295[D loss: 1.000067] [G loss: 1.000032]\n",
      "epoch:20 step:94300[D loss: 1.000046] [G loss: 0.999911]\n",
      "epoch:20 step:94305[D loss: 0.999904] [G loss: 1.000164]\n",
      "epoch:20 step:94310[D loss: 0.999998] [G loss: 1.000085]\n",
      "epoch:20 step:94315[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:20 step:94320[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:20 step:94325[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:20 step:94330[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:20 step:94335[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:20 step:94340[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:20 step:94345[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:20 step:94350[D loss: 0.999954] [G loss: 1.000070]\n",
      "epoch:20 step:94355[D loss: 0.999974] [G loss: 1.000035]\n",
      "epoch:20 step:94360[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:20 step:94365[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:20 step:94370[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:20 step:94375[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:20 step:94380[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:20 step:94385[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:20 step:94390[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:20 step:94395[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:20 step:94400[D loss: 0.999978] [G loss: 1.000065]\n",
      "##############\n",
      "[2.52062361 2.08116552 2.19411452 4.12478149 1.47979222 7.45127911\n",
      " 2.26099615 3.61188148 3.99175502 5.53966121]\n",
      "##########\n",
      "epoch:20 step:94405[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:20 step:94410[D loss: 1.000015] [G loss: 1.000023]\n",
      "epoch:20 step:94415[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:20 step:94420[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:20 step:94425[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:20 step:94430[D loss: 0.999959] [G loss: 1.000097]\n",
      "epoch:20 step:94435[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:20 step:94440[D loss: 1.000006] [G loss: 1.000047]\n",
      "epoch:20 step:94445[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:20 step:94450[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:20 step:94455[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:20 step:94460[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:20 step:94465[D loss: 0.999918] [G loss: 1.000136]\n",
      "epoch:20 step:94470[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:20 step:94475[D loss: 0.999969] [G loss: 1.000098]\n",
      "epoch:20 step:94480[D loss: 1.000005] [G loss: 0.999978]\n",
      "epoch:20 step:94485[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:20 step:94490[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:20 step:94495[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:20 step:94500[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:20 step:94505[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:20 step:94510[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:20 step:94515[D loss: 0.999924] [G loss: 1.000111]\n",
      "epoch:20 step:94520[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:20 step:94525[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:20 step:94530[D loss: 1.000018] [G loss: 1.000012]\n",
      "epoch:20 step:94535[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:20 step:94540[D loss: 1.000010] [G loss: 1.000015]\n",
      "epoch:20 step:94545[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:20 step:94550[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:20 step:94555[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:20 step:94560[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:20 step:94565[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:20 step:94570[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:20 step:94575[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:20 step:94580[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:20 step:94585[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:20 step:94590[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:20 step:94595[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:20 step:94600[D loss: 0.999960] [G loss: 1.000040]\n",
      "##############\n",
      "[2.48454661 2.17271971 2.31898107 4.14629459 1.42911313 7.67097877\n",
      " 2.20411303 3.80893556 3.89856452 5.22544754]\n",
      "##########\n",
      "epoch:20 step:94605[D loss: 1.000016] [G loss: 1.000009]\n",
      "epoch:20 step:94610[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:20 step:94615[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:20 step:94620[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:20 step:94625[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:20 step:94630[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:20 step:94635[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:20 step:94640[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:20 step:94645[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:20 step:94650[D loss: 0.999974] [G loss: 1.000035]\n",
      "epoch:20 step:94655[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:20 step:94660[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:20 step:94665[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:20 step:94670[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:20 step:94675[D loss: 1.000009] [G loss: 1.000001]\n",
      "epoch:20 step:94680[D loss: 1.000046] [G loss: 0.999901]\n",
      "epoch:20 step:94685[D loss: 1.000029] [G loss: 1.000035]\n",
      "epoch:20 step:94690[D loss: 0.999956] [G loss: 1.000198]\n",
      "epoch:20 step:94695[D loss: 0.999896] [G loss: 1.000209]\n",
      "epoch:20 step:94700[D loss: 0.999989] [G loss: 1.000166]\n",
      "epoch:20 step:94705[D loss: 0.999956] [G loss: 1.000119]\n",
      "epoch:20 step:94710[D loss: 0.999978] [G loss: 1.000123]\n",
      "epoch:20 step:94715[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:20 step:94720[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:20 step:94725[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:20 step:94730[D loss: 1.000016] [G loss: 0.999984]\n",
      "epoch:20 step:94735[D loss: 1.000055] [G loss: 0.999960]\n",
      "epoch:20 step:94740[D loss: 0.999904] [G loss: 1.000044]\n",
      "epoch:20 step:94745[D loss: 0.999973] [G loss: 1.000120]\n",
      "epoch:20 step:94750[D loss: 1.000009] [G loss: 1.000000]\n",
      "epoch:20 step:94755[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:20 step:94760[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:20 step:94765[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:20 step:94770[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:20 step:94775[D loss: 0.999960] [G loss: 1.000123]\n",
      "epoch:20 step:94780[D loss: 0.999950] [G loss: 1.000123]\n",
      "epoch:20 step:94785[D loss: 1.000162] [G loss: 0.999962]\n",
      "epoch:20 step:94790[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:20 step:94795[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:20 step:94800[D loss: 0.999981] [G loss: 1.000035]\n",
      "##############\n",
      "[2.56661677 2.14070349 2.37289297 3.82527736 1.47227824 7.32977165\n",
      " 2.37846437 3.84339146 4.00057955 5.98208482]\n",
      "##########\n",
      "epoch:20 step:94805[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:20 step:94810[D loss: 1.000080] [G loss: 0.999886]\n",
      "epoch:20 step:94815[D loss: 1.000047] [G loss: 0.999956]\n",
      "epoch:20 step:94820[D loss: 0.999936] [G loss: 1.000075]\n",
      "epoch:20 step:94825[D loss: 0.999966] [G loss: 1.000130]\n",
      "epoch:20 step:94830[D loss: 1.000085] [G loss: 0.999961]\n",
      "epoch:20 step:94835[D loss: 1.000081] [G loss: 1.000021]\n",
      "epoch:20 step:94840[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:20 step:94845[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:20 step:94850[D loss: 1.000054] [G loss: 1.000000]\n",
      "epoch:20 step:94855[D loss: 0.999904] [G loss: 1.000157]\n",
      "epoch:20 step:94860[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:20 step:94865[D loss: 1.000003] [G loss: 1.000044]\n",
      "epoch:20 step:94870[D loss: 0.999914] [G loss: 1.000180]\n",
      "epoch:20 step:94875[D loss: 0.999989] [G loss: 1.000081]\n",
      "epoch:20 step:94880[D loss: 0.999942] [G loss: 1.000111]\n",
      "epoch:20 step:94885[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:20 step:94890[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:20 step:94895[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:20 step:94900[D loss: 1.000022] [G loss: 0.999934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:94905[D loss: 1.000040] [G loss: 0.999968]\n",
      "epoch:20 step:94910[D loss: 1.000020] [G loss: 0.999973]\n",
      "epoch:20 step:94915[D loss: 0.999967] [G loss: 1.000019]\n",
      "epoch:20 step:94920[D loss: 1.000080] [G loss: 0.999950]\n",
      "epoch:20 step:94925[D loss: 0.999920] [G loss: 1.000143]\n",
      "epoch:20 step:94930[D loss: 0.999913] [G loss: 1.000118]\n",
      "epoch:20 step:94935[D loss: 0.999938] [G loss: 1.000090]\n",
      "epoch:20 step:94940[D loss: 0.999965] [G loss: 1.000135]\n",
      "epoch:20 step:94945[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:20 step:94950[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:20 step:94955[D loss: 0.999960] [G loss: 1.000020]\n",
      "epoch:20 step:94960[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:20 step:94965[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:20 step:94970[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:20 step:94975[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:20 step:94980[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:20 step:94985[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:20 step:94990[D loss: 1.000071] [G loss: 1.000004]\n",
      "epoch:20 step:94995[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:20 step:95000[D loss: 0.999978] [G loss: 1.000100]\n",
      "##############\n",
      "[2.55689517 2.20415734 2.28064943 3.74719591 1.45668856 7.66991794\n",
      " 2.23694232 3.7598458  3.97905538 5.56964895]\n",
      "##########\n",
      "epoch:20 step:95005[D loss: 0.999935] [G loss: 1.000105]\n",
      "epoch:20 step:95010[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:20 step:95015[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:20 step:95020[D loss: 0.999979] [G loss: 1.000030]\n",
      "epoch:20 step:95025[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:20 step:95030[D loss: 1.000065] [G loss: 0.999919]\n",
      "epoch:20 step:95035[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:20 step:95040[D loss: 0.999963] [G loss: 1.000052]\n",
      "epoch:20 step:95045[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:20 step:95050[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:20 step:95055[D loss: 0.999968] [G loss: 1.000040]\n",
      "epoch:20 step:95060[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:20 step:95065[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:20 step:95070[D loss: 0.999995] [G loss: 0.999990]\n",
      "epoch:20 step:95075[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:20 step:95080[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:20 step:95085[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:20 step:95090[D loss: 1.000041] [G loss: 0.999962]\n",
      "epoch:20 step:95095[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:20 step:95100[D loss: 0.999944] [G loss: 1.000105]\n",
      "epoch:20 step:95105[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:20 step:95110[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:20 step:95115[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:20 step:95120[D loss: 1.000006] [G loss: 0.999991]\n",
      "epoch:20 step:95125[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:20 step:95130[D loss: 0.999947] [G loss: 1.000061]\n",
      "epoch:20 step:95135[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:20 step:95140[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:20 step:95145[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:20 step:95150[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:20 step:95155[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:20 step:95160[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:20 step:95165[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:20 step:95170[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:20 step:95175[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:20 step:95180[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:20 step:95185[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:20 step:95190[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:20 step:95195[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:20 step:95200[D loss: 0.999939] [G loss: 1.000096]\n",
      "##############\n",
      "[2.48327353 2.22171296 2.28840739 4.0480872  1.51710438 7.09637351\n",
      " 2.35844613 3.78830071 3.91686827 5.67537488]\n",
      "##########\n",
      "epoch:20 step:95205[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:20 step:95210[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:20 step:95215[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:20 step:95220[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:20 step:95225[D loss: 1.000021] [G loss: 1.000003]\n",
      "epoch:20 step:95230[D loss: 0.999953] [G loss: 1.000141]\n",
      "epoch:20 step:95235[D loss: 0.999948] [G loss: 1.000062]\n",
      "epoch:20 step:95240[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:20 step:95245[D loss: 1.000019] [G loss: 1.000025]\n",
      "epoch:20 step:95250[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:20 step:95255[D loss: 0.999996] [G loss: 1.000071]\n",
      "epoch:20 step:95260[D loss: 0.999924] [G loss: 1.000104]\n",
      "epoch:20 step:95265[D loss: 0.999949] [G loss: 1.000065]\n",
      "epoch:20 step:95270[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:20 step:95275[D loss: 1.000008] [G loss: 1.000043]\n",
      "epoch:20 step:95280[D loss: 1.000013] [G loss: 1.000071]\n",
      "epoch:20 step:95285[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:20 step:95290[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:20 step:95295[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:20 step:95300[D loss: 0.999943] [G loss: 1.000075]\n",
      "epoch:20 step:95305[D loss: 1.000055] [G loss: 0.999970]\n",
      "epoch:20 step:95310[D loss: 1.000001] [G loss: 0.999999]\n",
      "epoch:20 step:95315[D loss: 1.000022] [G loss: 1.000015]\n",
      "epoch:20 step:95320[D loss: 0.999996] [G loss: 1.000006]\n",
      "epoch:20 step:95325[D loss: 0.999941] [G loss: 1.000045]\n",
      "epoch:20 step:95330[D loss: 0.999933] [G loss: 1.000062]\n",
      "epoch:20 step:95335[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:20 step:95340[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:20 step:95345[D loss: 0.999956] [G loss: 1.000121]\n",
      "epoch:20 step:95350[D loss: 0.999998] [G loss: 1.000086]\n",
      "epoch:20 step:95355[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:20 step:95360[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:20 step:95365[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:20 step:95370[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:20 step:95375[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:20 step:95380[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:20 step:95385[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:20 step:95390[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:20 step:95395[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:20 step:95400[D loss: 0.999968] [G loss: 1.000063]\n",
      "##############\n",
      "[2.49699302 2.15301736 2.15513444 3.76136931 1.42841987 7.34880694\n",
      " 2.47521131 3.93905589 3.9856003  5.03507452]\n",
      "##########\n",
      "epoch:20 step:95405[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:20 step:95410[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:20 step:95415[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:20 step:95420[D loss: 1.000017] [G loss: 1.000013]\n",
      "epoch:20 step:95425[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:20 step:95430[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:20 step:95435[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:20 step:95440[D loss: 1.000074] [G loss: 0.999894]\n",
      "epoch:20 step:95445[D loss: 0.999948] [G loss: 1.000060]\n",
      "epoch:20 step:95450[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:20 step:95455[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:20 step:95460[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:20 step:95465[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:20 step:95470[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:20 step:95475[D loss: 0.999988] [G loss: 1.000019]\n",
      "epoch:20 step:95480[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:20 step:95485[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:20 step:95490[D loss: 1.000026] [G loss: 0.999995]\n",
      "epoch:20 step:95495[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:20 step:95500[D loss: 0.999964] [G loss: 1.000111]\n",
      "epoch:20 step:95505[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:20 step:95510[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:20 step:95515[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:20 step:95520[D loss: 1.000081] [G loss: 0.999997]\n",
      "epoch:20 step:95525[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:20 step:95530[D loss: 0.999958] [G loss: 1.000140]\n",
      "epoch:20 step:95535[D loss: 1.000017] [G loss: 1.000056]\n",
      "epoch:20 step:95540[D loss: 0.999979] [G loss: 1.000122]\n",
      "epoch:20 step:95545[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:20 step:95550[D loss: 0.999966] [G loss: 1.000041]\n",
      "epoch:20 step:95555[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:20 step:95560[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:20 step:95565[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:20 step:95570[D loss: 1.000007] [G loss: 1.000050]\n",
      "epoch:20 step:95575[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:20 step:95580[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:20 step:95585[D loss: 0.999941] [G loss: 1.000180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:95590[D loss: 1.000067] [G loss: 1.000094]\n",
      "epoch:20 step:95595[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:20 step:95600[D loss: 0.999966] [G loss: 1.000004]\n",
      "##############\n",
      "[2.5778016  2.10866426 2.24642935 3.91178826 1.49997069 7.91088462\n",
      " 2.43667274 3.89057486 3.94558264 5.52307924]\n",
      "##########\n",
      "epoch:20 step:95605[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:20 step:95610[D loss: 0.999946] [G loss: 1.000082]\n",
      "epoch:20 step:95615[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:20 step:95620[D loss: 0.999966] [G loss: 1.000018]\n",
      "epoch:20 step:95625[D loss: 1.000006] [G loss: 1.000092]\n",
      "epoch:20 step:95630[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:20 step:95635[D loss: 1.000054] [G loss: 1.000073]\n",
      "epoch:20 step:95640[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:20 step:95645[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:20 step:95650[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:20 step:95655[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:20 step:95660[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:20 step:95665[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:20 step:95670[D loss: 0.999992] [G loss: 1.000075]\n",
      "epoch:20 step:95675[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:20 step:95680[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:20 step:95685[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:20 step:95690[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:20 step:95695[D loss: 1.000009] [G loss: 1.000020]\n",
      "epoch:20 step:95700[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:20 step:95705[D loss: 1.000025] [G loss: 0.999958]\n",
      "epoch:20 step:95710[D loss: 0.999930] [G loss: 1.000147]\n",
      "epoch:20 step:95715[D loss: 0.999995] [G loss: 1.000084]\n",
      "epoch:20 step:95720[D loss: 0.999925] [G loss: 1.000122]\n",
      "epoch:20 step:95725[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:20 step:95730[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:20 step:95735[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:20 step:95740[D loss: 0.999973] [G loss: 1.000025]\n",
      "epoch:20 step:95745[D loss: 1.000013] [G loss: 0.999988]\n",
      "epoch:20 step:95750[D loss: 1.000070] [G loss: 1.000027]\n",
      "epoch:20 step:95755[D loss: 1.000013] [G loss: 1.000025]\n",
      "epoch:20 step:95760[D loss: 1.000002] [G loss: 1.000089]\n",
      "epoch:20 step:95765[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:20 step:95770[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:20 step:95775[D loss: 0.999973] [G loss: 1.000020]\n",
      "epoch:20 step:95780[D loss: 0.999957] [G loss: 1.000037]\n",
      "epoch:20 step:95785[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:20 step:95790[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:20 step:95795[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:20 step:95800[D loss: 0.999948] [G loss: 1.000099]\n",
      "##############\n",
      "[2.50899404 2.10384546 2.0600399  3.95923372 1.41082799 7.54465034\n",
      " 2.2282572  3.90985476 3.86042389 5.80305162]\n",
      "##########\n",
      "epoch:20 step:95805[D loss: 1.000025] [G loss: 1.000018]\n",
      "epoch:20 step:95810[D loss: 0.999979] [G loss: 1.000102]\n",
      "epoch:20 step:95815[D loss: 0.999949] [G loss: 1.000123]\n",
      "epoch:20 step:95820[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:20 step:95825[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:20 step:95830[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:20 step:95835[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:20 step:95840[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:20 step:95845[D loss: 1.000015] [G loss: 0.999995]\n",
      "epoch:20 step:95850[D loss: 0.999938] [G loss: 1.000110]\n",
      "epoch:20 step:95855[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:20 step:95860[D loss: 1.000011] [G loss: 1.000045]\n",
      "epoch:20 step:95865[D loss: 0.999942] [G loss: 1.000130]\n",
      "epoch:20 step:95870[D loss: 0.999974] [G loss: 1.000125]\n",
      "epoch:20 step:95875[D loss: 0.999963] [G loss: 1.000128]\n",
      "epoch:20 step:95880[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:20 step:95885[D loss: 0.999959] [G loss: 1.000060]\n",
      "epoch:20 step:95890[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:20 step:95895[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:20 step:95900[D loss: 1.000008] [G loss: 1.000011]\n",
      "epoch:20 step:95905[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:20 step:95910[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:20 step:95915[D loss: 0.999990] [G loss: 1.000080]\n",
      "epoch:20 step:95920[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:20 step:95925[D loss: 0.999955] [G loss: 1.000055]\n",
      "epoch:20 step:95930[D loss: 0.999988] [G loss: 1.000110]\n",
      "epoch:20 step:95935[D loss: 1.000068] [G loss: 1.000006]\n",
      "epoch:20 step:95940[D loss: 1.000067] [G loss: 0.999898]\n",
      "epoch:20 step:95945[D loss: 0.999897] [G loss: 1.000224]\n",
      "epoch:20 step:95950[D loss: 0.999885] [G loss: 1.000260]\n",
      "epoch:20 step:95955[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:20 step:95960[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:20 step:95965[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:20 step:95970[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:20 step:95975[D loss: 0.999977] [G loss: 1.000027]\n",
      "epoch:20 step:95980[D loss: 0.999925] [G loss: 1.000115]\n",
      "epoch:20 step:95985[D loss: 1.000121] [G loss: 0.999897]\n",
      "epoch:20 step:95990[D loss: 1.000141] [G loss: 0.999850]\n",
      "epoch:20 step:95995[D loss: 1.000163] [G loss: 1.000075]\n",
      "epoch:20 step:96000[D loss: 0.999885] [G loss: 1.000182]\n",
      "##############\n",
      "[2.55503256 2.1328564  2.16396018 3.85854512 1.45348817 7.67677816\n",
      " 2.41019608 3.67795578 3.97790538 5.41929374]\n",
      "##########\n",
      "epoch:20 step:96005[D loss: 0.999950] [G loss: 1.000132]\n",
      "epoch:20 step:96010[D loss: 0.999946] [G loss: 1.000077]\n",
      "epoch:20 step:96015[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:20 step:96020[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:20 step:96025[D loss: 1.000031] [G loss: 0.999914]\n",
      "epoch:20 step:96030[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:20 step:96035[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:20 step:96040[D loss: 1.000048] [G loss: 1.000004]\n",
      "epoch:20 step:96045[D loss: 1.000010] [G loss: 1.000099]\n",
      "epoch:20 step:96050[D loss: 0.999949] [G loss: 1.000002]\n",
      "epoch:20 step:96055[D loss: 0.999963] [G loss: 1.000160]\n",
      "epoch:20 step:96060[D loss: 0.999942] [G loss: 1.000104]\n",
      "epoch:20 step:96065[D loss: 0.999964] [G loss: 1.000104]\n",
      "epoch:20 step:96070[D loss: 1.000005] [G loss: 1.000072]\n",
      "epoch:20 step:96075[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:20 step:96080[D loss: 1.000020] [G loss: 0.999988]\n",
      "epoch:20 step:96085[D loss: 1.000006] [G loss: 0.999993]\n",
      "epoch:20 step:96090[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:20 step:96095[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:20 step:96100[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:20 step:96105[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:20 step:96110[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:20 step:96115[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:20 step:96120[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:20 step:96125[D loss: 1.000042] [G loss: 0.999973]\n",
      "epoch:20 step:96130[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:20 step:96135[D loss: 0.999946] [G loss: 1.000113]\n",
      "epoch:20 step:96140[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:20 step:96145[D loss: 0.999951] [G loss: 1.000082]\n",
      "epoch:20 step:96150[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:20 step:96155[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:20 step:96160[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:20 step:96165[D loss: 1.000005] [G loss: 1.000122]\n",
      "epoch:20 step:96170[D loss: 0.999999] [G loss: 1.000070]\n",
      "epoch:20 step:96175[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:20 step:96180[D loss: 1.000094] [G loss: 1.000039]\n",
      "epoch:20 step:96185[D loss: 0.999952] [G loss: 1.000147]\n",
      "epoch:20 step:96190[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:20 step:96195[D loss: 1.000011] [G loss: 0.999983]\n",
      "epoch:20 step:96200[D loss: 1.000065] [G loss: 1.000023]\n",
      "##############\n",
      "[2.5912745  2.11085905 2.12687758 4.00126667 1.52268875 7.78119063\n",
      " 2.35642184 3.75353103 3.92892523 5.96497609]\n",
      "##########\n",
      "epoch:20 step:96205[D loss: 0.999978] [G loss: 0.999953]\n",
      "epoch:20 step:96210[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:20 step:96215[D loss: 1.000031] [G loss: 0.999861]\n",
      "epoch:20 step:96220[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:20 step:96225[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:20 step:96230[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:20 step:96235[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:20 step:96240[D loss: 1.000008] [G loss: 1.000077]\n",
      "epoch:20 step:96245[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:20 step:96250[D loss: 1.000017] [G loss: 1.000114]\n",
      "epoch:20 step:96255[D loss: 0.999952] [G loss: 1.000108]\n",
      "epoch:20 step:96260[D loss: 0.999954] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:96265[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:20 step:96270[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:20 step:96275[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:20 step:96280[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:20 step:96285[D loss: 1.000095] [G loss: 0.999964]\n",
      "epoch:20 step:96290[D loss: 0.999964] [G loss: 1.000009]\n",
      "epoch:20 step:96295[D loss: 0.999971] [G loss: 1.000021]\n",
      "epoch:20 step:96300[D loss: 1.000033] [G loss: 1.000024]\n",
      "epoch:20 step:96305[D loss: 0.999944] [G loss: 1.000137]\n",
      "epoch:20 step:96310[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:20 step:96315[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:20 step:96320[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:20 step:96325[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:20 step:96330[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:20 step:96335[D loss: 0.999932] [G loss: 1.000049]\n",
      "epoch:20 step:96340[D loss: 0.999972] [G loss: 1.000034]\n",
      "epoch:20 step:96345[D loss: 0.999997] [G loss: 1.000071]\n",
      "epoch:20 step:96350[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:20 step:96355[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:20 step:96360[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:20 step:96365[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:20 step:96370[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:20 step:96375[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:20 step:96380[D loss: 1.000001] [G loss: 1.000116]\n",
      "epoch:20 step:96385[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:20 step:96390[D loss: 0.999932] [G loss: 1.000226]\n",
      "epoch:20 step:96395[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:20 step:96400[D loss: 0.999904] [G loss: 1.000155]\n",
      "##############\n",
      "[2.53913619 1.99572911 2.03956943 3.98138518 1.47357199 7.18574428\n",
      " 2.38090424 3.80846599 3.86326214 5.69722177]\n",
      "##########\n",
      "epoch:20 step:96405[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:20 step:96410[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:20 step:96415[D loss: 1.000039] [G loss: 0.999991]\n",
      "epoch:20 step:96420[D loss: 0.999983] [G loss: 1.000118]\n",
      "epoch:20 step:96425[D loss: 1.000047] [G loss: 0.999985]\n",
      "epoch:20 step:96430[D loss: 1.000000] [G loss: 1.000032]\n",
      "epoch:20 step:96435[D loss: 0.999936] [G loss: 0.999993]\n",
      "epoch:20 step:96440[D loss: 0.999951] [G loss: 1.000119]\n",
      "epoch:20 step:96445[D loss: 0.999929] [G loss: 1.000098]\n",
      "epoch:20 step:96450[D loss: 1.000002] [G loss: 1.000040]\n",
      "epoch:20 step:96455[D loss: 0.999995] [G loss: 0.999990]\n",
      "epoch:20 step:96460[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:20 step:96465[D loss: 1.000060] [G loss: 0.999920]\n",
      "epoch:20 step:96470[D loss: 0.999957] [G loss: 1.000042]\n",
      "epoch:20 step:96475[D loss: 1.000004] [G loss: 0.999994]\n",
      "epoch:20 step:96480[D loss: 0.999998] [G loss: 0.999953]\n",
      "epoch:20 step:96485[D loss: 1.000003] [G loss: 0.999996]\n",
      "epoch:20 step:96490[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:20 step:96495[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:20 step:96500[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:20 step:96505[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:20 step:96510[D loss: 0.999955] [G loss: 1.000075]\n",
      "epoch:20 step:96515[D loss: 0.999971] [G loss: 1.000130]\n",
      "epoch:20 step:96520[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:20 step:96525[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:20 step:96530[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:20 step:96535[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:20 step:96540[D loss: 0.999952] [G loss: 1.000074]\n",
      "epoch:20 step:96545[D loss: 0.999996] [G loss: 0.999997]\n",
      "epoch:20 step:96550[D loss: 1.000008] [G loss: 0.999947]\n",
      "epoch:20 step:96555[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:20 step:96560[D loss: 1.000011] [G loss: 0.999999]\n",
      "epoch:20 step:96565[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:20 step:96570[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:20 step:96575[D loss: 0.999986] [G loss: 1.000097]\n",
      "epoch:20 step:96580[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:20 step:96585[D loss: 0.999939] [G loss: 1.000087]\n",
      "epoch:20 step:96590[D loss: 0.999987] [G loss: 1.000121]\n",
      "epoch:20 step:96595[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:20 step:96600[D loss: 1.000022] [G loss: 1.000110]\n",
      "##############\n",
      "[2.51083905 2.00975742 2.04242404 3.72307893 1.46028941 7.21686592\n",
      " 2.17818777 3.72104385 3.97010976 4.40190889]\n",
      "##########\n",
      "epoch:20 step:96605[D loss: 0.999951] [G loss: 1.000082]\n",
      "epoch:20 step:96610[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:20 step:96615[D loss: 1.000008] [G loss: 0.999972]\n",
      "epoch:20 step:96620[D loss: 0.999954] [G loss: 1.000072]\n",
      "epoch:20 step:96625[D loss: 1.000006] [G loss: 0.999989]\n",
      "epoch:20 step:96630[D loss: 1.000010] [G loss: 1.000011]\n",
      "epoch:20 step:96635[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:20 step:96640[D loss: 1.000069] [G loss: 1.000068]\n",
      "epoch:20 step:96645[D loss: 1.000009] [G loss: 1.000067]\n",
      "epoch:20 step:96650[D loss: 0.999930] [G loss: 1.000109]\n",
      "epoch:20 step:96655[D loss: 0.999922] [G loss: 1.000102]\n",
      "epoch:20 step:96660[D loss: 1.000000] [G loss: 1.000055]\n",
      "epoch:20 step:96665[D loss: 1.000088] [G loss: 0.999933]\n",
      "epoch:20 step:96670[D loss: 1.000036] [G loss: 0.999968]\n",
      "epoch:20 step:96675[D loss: 1.000089] [G loss: 1.000046]\n",
      "epoch:20 step:96680[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:20 step:96685[D loss: 0.999920] [G loss: 1.000150]\n",
      "epoch:20 step:96690[D loss: 0.999928] [G loss: 1.000149]\n",
      "epoch:20 step:96695[D loss: 0.999959] [G loss: 1.000050]\n",
      "epoch:20 step:96700[D loss: 0.999954] [G loss: 1.000072]\n",
      "epoch:20 step:96705[D loss: 1.000022] [G loss: 1.000003]\n",
      "epoch:20 step:96710[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:20 step:96715[D loss: 0.999966] [G loss: 1.000028]\n",
      "epoch:20 step:96720[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:20 step:96725[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:20 step:96730[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:20 step:96735[D loss: 1.000028] [G loss: 1.000011]\n",
      "epoch:20 step:96740[D loss: 1.000013] [G loss: 1.000030]\n",
      "epoch:20 step:96745[D loss: 1.000106] [G loss: 0.999997]\n",
      "epoch:20 step:96750[D loss: 0.999888] [G loss: 1.000152]\n",
      "epoch:20 step:96755[D loss: 1.000066] [G loss: 0.999924]\n",
      "epoch:20 step:96760[D loss: 0.999917] [G loss: 1.000181]\n",
      "epoch:20 step:96765[D loss: 0.999942] [G loss: 1.000063]\n",
      "epoch:20 step:96770[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:20 step:96775[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:20 step:96780[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:20 step:96785[D loss: 1.000027] [G loss: 1.000090]\n",
      "epoch:20 step:96790[D loss: 1.000030] [G loss: 1.000005]\n",
      "epoch:20 step:96795[D loss: 0.999937] [G loss: 1.000031]\n",
      "epoch:20 step:96800[D loss: 1.000010] [G loss: 1.000120]\n",
      "##############\n",
      "[2.60472868 2.15707956 2.18477028 3.55954552 1.55343888 7.12461973\n",
      " 2.49852844 4.13061893 4.04372288 5.33928611]\n",
      "##########\n",
      "epoch:20 step:96805[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:20 step:96810[D loss: 0.999928] [G loss: 1.000260]\n",
      "epoch:20 step:96815[D loss: 0.999995] [G loss: 1.000083]\n",
      "epoch:20 step:96820[D loss: 0.999985] [G loss: 1.000106]\n",
      "epoch:20 step:96825[D loss: 1.000036] [G loss: 1.000021]\n",
      "epoch:20 step:96830[D loss: 0.999909] [G loss: 1.000110]\n",
      "epoch:20 step:96835[D loss: 1.000002] [G loss: 1.000014]\n",
      "epoch:20 step:96840[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:20 step:96845[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:20 step:96850[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:20 step:96855[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:20 step:96860[D loss: 1.000002] [G loss: 1.000088]\n",
      "epoch:20 step:96865[D loss: 1.000004] [G loss: 1.000015]\n",
      "epoch:20 step:96870[D loss: 0.999958] [G loss: 1.000042]\n",
      "epoch:20 step:96875[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:20 step:96880[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:20 step:96885[D loss: 1.000027] [G loss: 1.000009]\n",
      "epoch:20 step:96890[D loss: 0.999948] [G loss: 1.000064]\n",
      "epoch:20 step:96895[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:20 step:96900[D loss: 1.000011] [G loss: 1.000045]\n",
      "epoch:20 step:96905[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:20 step:96910[D loss: 0.999925] [G loss: 1.000108]\n",
      "epoch:20 step:96915[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:20 step:96920[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:20 step:96925[D loss: 0.999950] [G loss: 1.000113]\n",
      "epoch:20 step:96930[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:20 step:96935[D loss: 0.999879] [G loss: 1.000135]\n",
      "epoch:20 step:96940[D loss: 0.999999] [G loss: 0.999983]\n",
      "epoch:20 step:96945[D loss: 0.999991] [G loss: 1.000101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:96950[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:20 step:96955[D loss: 0.999934] [G loss: 1.000135]\n",
      "epoch:20 step:96960[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:20 step:96965[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:20 step:96970[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:20 step:96975[D loss: 0.999974] [G loss: 1.000109]\n",
      "epoch:20 step:96980[D loss: 1.000009] [G loss: 1.000014]\n",
      "epoch:20 step:96985[D loss: 0.999951] [G loss: 1.000120]\n",
      "epoch:20 step:96990[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:20 step:96995[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:20 step:97000[D loss: 0.999953] [G loss: 1.000097]\n",
      "##############\n",
      "[2.51171441 2.09093437 2.24854836 4.01461895 1.42324623 7.51360847\n",
      " 2.3725888  3.88385523 3.99643369 5.36251046]\n",
      "##########\n",
      "epoch:20 step:97005[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:20 step:97010[D loss: 1.000004] [G loss: 1.000058]\n",
      "epoch:20 step:97015[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:20 step:97020[D loss: 0.999923] [G loss: 1.000095]\n",
      "epoch:20 step:97025[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:20 step:97030[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:20 step:97035[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:20 step:97040[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:20 step:97045[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:20 step:97050[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:20 step:97055[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:20 step:97060[D loss: 1.000003] [G loss: 1.000072]\n",
      "epoch:20 step:97065[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:20 step:97070[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:20 step:97075[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:20 step:97080[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:20 step:97085[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:20 step:97090[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:20 step:97095[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:20 step:97100[D loss: 1.000006] [G loss: 0.999994]\n",
      "epoch:20 step:97105[D loss: 0.999983] [G loss: 1.000009]\n",
      "epoch:20 step:97110[D loss: 1.000013] [G loss: 1.000067]\n",
      "epoch:20 step:97115[D loss: 0.999951] [G loss: 1.000057]\n",
      "epoch:20 step:97120[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:20 step:97125[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:20 step:97130[D loss: 1.000008] [G loss: 1.000004]\n",
      "epoch:20 step:97135[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:20 step:97140[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:20 step:97145[D loss: 1.000010] [G loss: 1.000143]\n",
      "epoch:20 step:97150[D loss: 0.999987] [G loss: 0.999980]\n",
      "epoch:20 step:97155[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:20 step:97160[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:20 step:97165[D loss: 1.000050] [G loss: 1.000087]\n",
      "epoch:20 step:97170[D loss: 0.999939] [G loss: 1.000137]\n",
      "epoch:20 step:97175[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:20 step:97180[D loss: 1.000010] [G loss: 1.000012]\n",
      "epoch:20 step:97185[D loss: 1.000069] [G loss: 0.999874]\n",
      "epoch:20 step:97190[D loss: 0.999940] [G loss: 1.000049]\n",
      "epoch:20 step:97195[D loss: 1.000070] [G loss: 0.999961]\n",
      "epoch:20 step:97200[D loss: 0.999896] [G loss: 1.000161]\n",
      "##############\n",
      "[2.60075202 2.05361985 2.20534611 3.60788194 1.4367599  8.42012244\n",
      " 2.23314984 3.74374663 3.95014005 5.50466951]\n",
      "##########\n",
      "epoch:20 step:97205[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:20 step:97210[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:20 step:97215[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:20 step:97220[D loss: 0.999983] [G loss: 1.000098]\n",
      "epoch:20 step:97225[D loss: 1.000045] [G loss: 1.000028]\n",
      "epoch:20 step:97230[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:20 step:97235[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:20 step:97240[D loss: 0.999961] [G loss: 1.000114]\n",
      "epoch:20 step:97245[D loss: 1.000035] [G loss: 0.999999]\n",
      "epoch:20 step:97250[D loss: 0.999985] [G loss: 1.000096]\n",
      "epoch:20 step:97255[D loss: 1.000042] [G loss: 0.999910]\n",
      "epoch:20 step:97260[D loss: 1.000026] [G loss: 0.999997]\n",
      "epoch:20 step:97265[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:20 step:97270[D loss: 1.000072] [G loss: 1.000026]\n",
      "epoch:20 step:97275[D loss: 1.000013] [G loss: 1.000006]\n",
      "epoch:20 step:97280[D loss: 0.999947] [G loss: 1.000053]\n",
      "epoch:20 step:97285[D loss: 0.999916] [G loss: 1.000128]\n",
      "epoch:20 step:97290[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:20 step:97295[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:20 step:97300[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:20 step:97305[D loss: 1.000007] [G loss: 1.000053]\n",
      "epoch:20 step:97310[D loss: 1.000003] [G loss: 1.000103]\n",
      "epoch:20 step:97315[D loss: 0.999996] [G loss: 1.000084]\n",
      "epoch:20 step:97320[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:20 step:97325[D loss: 0.999950] [G loss: 1.000071]\n",
      "epoch:20 step:97330[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:20 step:97335[D loss: 0.999999] [G loss: 1.000084]\n",
      "epoch:20 step:97340[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:20 step:97345[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:20 step:97350[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:20 step:97355[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:20 step:97360[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:20 step:97365[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:20 step:97370[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:20 step:97375[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:20 step:97380[D loss: 1.000038] [G loss: 0.999952]\n",
      "epoch:20 step:97385[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:20 step:97390[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:20 step:97395[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:20 step:97400[D loss: 0.999964] [G loss: 1.000071]\n",
      "##############\n",
      "[2.5697788  2.1364479  2.2583266  3.9667644  1.48253986 7.50724283\n",
      " 2.44524854 3.87996146 4.04997566 5.463506  ]\n",
      "##########\n",
      "epoch:20 step:97405[D loss: 0.999998] [G loss: 1.000073]\n",
      "epoch:20 step:97410[D loss: 1.000038] [G loss: 1.000052]\n",
      "epoch:20 step:97415[D loss: 0.999953] [G loss: 1.000056]\n",
      "epoch:20 step:97420[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:20 step:97425[D loss: 1.000015] [G loss: 0.999998]\n",
      "epoch:20 step:97430[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:20 step:97435[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:20 step:97440[D loss: 1.000019] [G loss: 1.000046]\n",
      "epoch:20 step:97445[D loss: 0.999944] [G loss: 1.000095]\n",
      "epoch:20 step:97450[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:20 step:97455[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:20 step:97460[D loss: 0.999974] [G loss: 1.000015]\n",
      "epoch:20 step:97465[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:20 step:97470[D loss: 1.000136] [G loss: 0.999883]\n",
      "epoch:20 step:97475[D loss: 1.000009] [G loss: 1.000010]\n",
      "epoch:20 step:97480[D loss: 0.999941] [G loss: 1.000048]\n",
      "epoch:20 step:97485[D loss: 0.999981] [G loss: 0.999997]\n",
      "epoch:20 step:97490[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:20 step:97495[D loss: 0.999920] [G loss: 1.000135]\n",
      "epoch:20 step:97500[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:20 step:97505[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:20 step:97510[D loss: 1.000031] [G loss: 0.999962]\n",
      "epoch:20 step:97515[D loss: 1.000028] [G loss: 0.999898]\n",
      "epoch:20 step:97520[D loss: 0.999936] [G loss: 1.000117]\n",
      "epoch:20 step:97525[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:20 step:97530[D loss: 0.999952] [G loss: 1.000105]\n",
      "epoch:20 step:97535[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:20 step:97540[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:20 step:97545[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:20 step:97550[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:20 step:97555[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:20 step:97560[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:20 step:97565[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:20 step:97570[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:20 step:97575[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:20 step:97580[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:20 step:97585[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:20 step:97590[D loss: 0.999957] [G loss: 1.000117]\n",
      "epoch:20 step:97595[D loss: 1.000048] [G loss: 0.999956]\n",
      "epoch:20 step:97600[D loss: 1.000029] [G loss: 0.999999]\n",
      "##############\n",
      "[2.61042247 2.1000878  2.23376536 3.68655682 1.43369207 8.23212683\n",
      " 2.34718203 3.65105313 3.93663535 5.43653538]\n",
      "##########\n",
      "epoch:20 step:97605[D loss: 0.999960] [G loss: 1.000013]\n",
      "epoch:20 step:97610[D loss: 0.999994] [G loss: 0.999986]\n",
      "epoch:20 step:97615[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:20 step:97620[D loss: 0.999963] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:97625[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:20 step:97630[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:20 step:97635[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:20 step:97640[D loss: 1.000004] [G loss: 0.999994]\n",
      "epoch:20 step:97645[D loss: 1.000069] [G loss: 0.999936]\n",
      "epoch:20 step:97650[D loss: 0.999921] [G loss: 1.000085]\n",
      "epoch:20 step:97655[D loss: 0.999946] [G loss: 1.000078]\n",
      "epoch:20 step:97660[D loss: 0.999999] [G loss: 0.999994]\n",
      "epoch:20 step:97665[D loss: 0.999983] [G loss: 1.000116]\n",
      "epoch:20 step:97670[D loss: 0.999980] [G loss: 1.000012]\n",
      "epoch:20 step:97675[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:20 step:97680[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:20 step:97685[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:20 step:97690[D loss: 1.000090] [G loss: 0.999887]\n",
      "epoch:20 step:97695[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:20 step:97700[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:20 step:97705[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:20 step:97710[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:20 step:97715[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:20 step:97720[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:20 step:97725[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:20 step:97730[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:20 step:97735[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:20 step:97740[D loss: 1.000065] [G loss: 0.999967]\n",
      "epoch:20 step:97745[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:20 step:97750[D loss: 0.999921] [G loss: 1.000121]\n",
      "epoch:20 step:97755[D loss: 0.999959] [G loss: 1.000110]\n",
      "epoch:20 step:97760[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:20 step:97765[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:20 step:97770[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:20 step:97775[D loss: 0.999936] [G loss: 1.000131]\n",
      "epoch:20 step:97780[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:20 step:97785[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:20 step:97790[D loss: 1.000000] [G loss: 1.000088]\n",
      "epoch:20 step:97795[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:20 step:97800[D loss: 0.999979] [G loss: 1.000065]\n",
      "##############\n",
      "[2.61283766 2.13899919 2.18810734 3.76679679 1.50276807 7.35614628\n",
      " 2.11621601 3.80746201 3.96026244 4.75512782]\n",
      "##########\n",
      "epoch:20 step:97805[D loss: 1.000016] [G loss: 0.999975]\n",
      "epoch:20 step:97810[D loss: 0.999941] [G loss: 1.000124]\n",
      "epoch:20 step:97815[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:20 step:97820[D loss: 0.999977] [G loss: 1.000027]\n",
      "epoch:20 step:97825[D loss: 1.000017] [G loss: 0.999962]\n",
      "epoch:20 step:97830[D loss: 0.999916] [G loss: 1.000111]\n",
      "epoch:20 step:97835[D loss: 0.999957] [G loss: 1.000104]\n",
      "epoch:20 step:97840[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:20 step:97845[D loss: 1.000017] [G loss: 0.999999]\n",
      "epoch:20 step:97850[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:20 step:97855[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:20 step:97860[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:20 step:97865[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:20 step:97870[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:20 step:97875[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:20 step:97880[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:20 step:97885[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:20 step:97890[D loss: 1.000008] [G loss: 1.000015]\n",
      "epoch:20 step:97895[D loss: 1.000010] [G loss: 1.000050]\n",
      "epoch:20 step:97900[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:20 step:97905[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:20 step:97910[D loss: 0.999957] [G loss: 1.000054]\n",
      "epoch:20 step:97915[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:20 step:97920[D loss: 0.999972] [G loss: 1.000121]\n",
      "epoch:20 step:97925[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:20 step:97930[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:20 step:97935[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:20 step:97940[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:20 step:97945[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:20 step:97950[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:20 step:97955[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:20 step:97960[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:20 step:97965[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:20 step:97970[D loss: 0.999915] [G loss: 1.000099]\n",
      "epoch:20 step:97975[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:20 step:97980[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:20 step:97985[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:20 step:97990[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:20 step:97995[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:20 step:98000[D loss: 0.999984] [G loss: 1.000059]\n",
      "##############\n",
      "[2.57671011 2.16478088 2.26009974 4.16818584 1.48369987 7.64196975\n",
      " 2.26920906 3.94581612 4.01842169 4.6355355 ]\n",
      "##########\n",
      "epoch:20 step:98005[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:20 step:98010[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:20 step:98015[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:20 step:98020[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:20 step:98025[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:20 step:98030[D loss: 0.999948] [G loss: 1.000097]\n",
      "epoch:20 step:98035[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:20 step:98040[D loss: 1.000016] [G loss: 0.999983]\n",
      "epoch:20 step:98045[D loss: 0.999939] [G loss: 1.000138]\n",
      "epoch:20 step:98050[D loss: 1.000039] [G loss: 1.000063]\n",
      "epoch:20 step:98055[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:20 step:98060[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:20 step:98065[D loss: 0.999946] [G loss: 1.000038]\n",
      "epoch:20 step:98070[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:20 step:98075[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:20 step:98080[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:20 step:98085[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:20 step:98090[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:20 step:98095[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:20 step:98100[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:20 step:98105[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:20 step:98110[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:20 step:98115[D loss: 1.000003] [G loss: 1.000061]\n",
      "epoch:20 step:98120[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:20 step:98125[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:20 step:98130[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:20 step:98135[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:20 step:98140[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:20 step:98145[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:20 step:98150[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:20 step:98155[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:20 step:98160[D loss: 0.999974] [G loss: 1.000022]\n",
      "epoch:20 step:98165[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:20 step:98170[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:20 step:98175[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:20 step:98180[D loss: 1.000031] [G loss: 1.000050]\n",
      "epoch:20 step:98185[D loss: 1.000023] [G loss: 0.999932]\n",
      "epoch:20 step:98190[D loss: 0.999950] [G loss: 1.000083]\n",
      "epoch:20 step:98195[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:20 step:98200[D loss: 0.999960] [G loss: 1.000069]\n",
      "##############\n",
      "[2.66359439 2.18634508 2.35515675 4.12913625 1.52376047 7.94431495\n",
      " 2.48993378 3.93065502 4.09930771 4.97217095]\n",
      "##########\n",
      "epoch:20 step:98205[D loss: 1.000042] [G loss: 1.000004]\n",
      "epoch:20 step:98210[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:20 step:98215[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:20 step:98220[D loss: 1.000047] [G loss: 1.000014]\n",
      "epoch:20 step:98225[D loss: 1.000056] [G loss: 0.999926]\n",
      "epoch:20 step:98230[D loss: 1.000069] [G loss: 1.000019]\n",
      "epoch:20 step:98235[D loss: 0.999903] [G loss: 1.000082]\n",
      "epoch:20 step:98240[D loss: 0.999949] [G loss: 1.000073]\n",
      "epoch:20 step:98245[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:20 step:98250[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:20 step:98255[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:20 step:98260[D loss: 0.999961] [G loss: 1.000026]\n",
      "epoch:20 step:98265[D loss: 0.999999] [G loss: 1.000028]\n",
      "epoch:20 step:98270[D loss: 0.999949] [G loss: 1.000198]\n",
      "epoch:20 step:98275[D loss: 1.000103] [G loss: 0.999946]\n",
      "epoch:20 step:98280[D loss: 0.999916] [G loss: 1.000158]\n",
      "epoch:20 step:98285[D loss: 1.000184] [G loss: 0.999892]\n",
      "epoch:20 step:98290[D loss: 0.999892] [G loss: 1.000148]\n",
      "epoch:20 step:98295[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:20 step:98300[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:20 step:98305[D loss: 1.000009] [G loss: 1.000030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:98310[D loss: 0.999997] [G loss: 0.999989]\n",
      "epoch:20 step:98315[D loss: 0.999919] [G loss: 1.000079]\n",
      "epoch:20 step:98320[D loss: 0.999961] [G loss: 1.000045]\n",
      "epoch:20 step:98325[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:20 step:98330[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:20 step:98335[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:20 step:98340[D loss: 0.999982] [G loss: 1.000020]\n",
      "epoch:20 step:98345[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:20 step:98350[D loss: 0.999962] [G loss: 1.000044]\n",
      "epoch:20 step:98355[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:20 step:98360[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:20 step:98365[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:20 step:98370[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:20 step:98375[D loss: 1.000017] [G loss: 0.999947]\n",
      "epoch:20 step:98380[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:20 step:98385[D loss: 0.999979] [G loss: 1.000022]\n",
      "epoch:21 step:98390[D loss: 1.000007] [G loss: 1.000073]\n",
      "epoch:21 step:98395[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:21 step:98400[D loss: 0.999954] [G loss: 1.000078]\n",
      "##############\n",
      "[2.6109378  2.16184592 2.2045     3.75337294 1.50342272 7.66198326\n",
      " 2.36974358 3.93637683 3.94770228 4.98256156]\n",
      "##########\n",
      "epoch:21 step:98405[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:21 step:98410[D loss: 0.999977] [G loss: 1.000001]\n",
      "epoch:21 step:98415[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:21 step:98420[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:21 step:98425[D loss: 1.000000] [G loss: 0.999977]\n",
      "epoch:21 step:98430[D loss: 1.000077] [G loss: 0.999920]\n",
      "epoch:21 step:98435[D loss: 1.000011] [G loss: 1.000066]\n",
      "epoch:21 step:98440[D loss: 0.999919] [G loss: 1.000176]\n",
      "epoch:21 step:98445[D loss: 0.999905] [G loss: 1.000138]\n",
      "epoch:21 step:98450[D loss: 0.999962] [G loss: 1.000045]\n",
      "epoch:21 step:98455[D loss: 0.999972] [G loss: 1.000010]\n",
      "epoch:21 step:98460[D loss: 0.999955] [G loss: 1.000124]\n",
      "epoch:21 step:98465[D loss: 0.999999] [G loss: 1.000031]\n",
      "epoch:21 step:98470[D loss: 0.999919] [G loss: 1.000131]\n",
      "epoch:21 step:98475[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:21 step:98480[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:21 step:98485[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:21 step:98490[D loss: 1.000018] [G loss: 1.000021]\n",
      "epoch:21 step:98495[D loss: 1.000065] [G loss: 0.999956]\n",
      "epoch:21 step:98500[D loss: 0.999927] [G loss: 1.000071]\n",
      "epoch:21 step:98505[D loss: 0.999974] [G loss: 1.000148]\n",
      "epoch:21 step:98510[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:21 step:98515[D loss: 0.999948] [G loss: 1.000155]\n",
      "epoch:21 step:98520[D loss: 1.000035] [G loss: 1.000049]\n",
      "epoch:21 step:98525[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:21 step:98530[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:21 step:98535[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:21 step:98540[D loss: 1.000002] [G loss: 1.000047]\n",
      "epoch:21 step:98545[D loss: 0.999999] [G loss: 1.000023]\n",
      "epoch:21 step:98550[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:21 step:98555[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:21 step:98560[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:21 step:98565[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:21 step:98570[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:21 step:98575[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:21 step:98580[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:21 step:98585[D loss: 1.000005] [G loss: 1.000084]\n",
      "epoch:21 step:98590[D loss: 1.000032] [G loss: 1.000000]\n",
      "epoch:21 step:98595[D loss: 0.999998] [G loss: 0.999983]\n",
      "epoch:21 step:98600[D loss: 0.999992] [G loss: 0.999981]\n",
      "##############\n",
      "[2.69422592 2.13413224 2.34259191 3.90597621 1.48002863 7.64858033\n",
      " 2.4132459  3.86652597 4.03327871 5.3961635 ]\n",
      "##########\n",
      "epoch:21 step:98605[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:21 step:98610[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:21 step:98615[D loss: 0.999927] [G loss: 1.000131]\n",
      "epoch:21 step:98620[D loss: 0.999945] [G loss: 1.000105]\n",
      "epoch:21 step:98625[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:21 step:98630[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:21 step:98635[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:21 step:98640[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:21 step:98645[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:21 step:98650[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:21 step:98655[D loss: 1.000011] [G loss: 1.000037]\n",
      "epoch:21 step:98660[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:21 step:98665[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:21 step:98670[D loss: 1.000040] [G loss: 1.000054]\n",
      "epoch:21 step:98675[D loss: 0.999981] [G loss: 1.000122]\n",
      "epoch:21 step:98680[D loss: 0.999952] [G loss: 1.000122]\n",
      "epoch:21 step:98685[D loss: 0.999960] [G loss: 1.000118]\n",
      "epoch:21 step:98690[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:21 step:98695[D loss: 1.000021] [G loss: 1.000048]\n",
      "epoch:21 step:98700[D loss: 1.000085] [G loss: 0.999895]\n",
      "epoch:21 step:98705[D loss: 0.999981] [G loss: 1.000122]\n",
      "epoch:21 step:98710[D loss: 0.999927] [G loss: 1.000081]\n",
      "epoch:21 step:98715[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:21 step:98720[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:21 step:98725[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:21 step:98730[D loss: 1.000020] [G loss: 1.000043]\n",
      "epoch:21 step:98735[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:21 step:98740[D loss: 1.000016] [G loss: 0.999977]\n",
      "epoch:21 step:98745[D loss: 1.000005] [G loss: 1.000120]\n",
      "epoch:21 step:98750[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:21 step:98755[D loss: 0.999941] [G loss: 1.000044]\n",
      "epoch:21 step:98760[D loss: 0.999967] [G loss: 1.000006]\n",
      "epoch:21 step:98765[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:21 step:98770[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:21 step:98775[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:21 step:98780[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:21 step:98785[D loss: 0.999972] [G loss: 1.000096]\n",
      "epoch:21 step:98790[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:21 step:98795[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:21 step:98800[D loss: 0.999938] [G loss: 1.000069]\n",
      "##############\n",
      "[2.55726632 2.04286066 2.21870703 3.67742038 1.40606211 7.24472908\n",
      " 2.23308517 3.92443553 3.89633387 5.04440093]\n",
      "##########\n",
      "epoch:21 step:98805[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:21 step:98810[D loss: 1.000019] [G loss: 0.999993]\n",
      "epoch:21 step:98815[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:21 step:98820[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:21 step:98825[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:21 step:98830[D loss: 0.999957] [G loss: 1.000141]\n",
      "epoch:21 step:98835[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:21 step:98840[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:21 step:98845[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:21 step:98850[D loss: 1.000036] [G loss: 1.000002]\n",
      "epoch:21 step:98855[D loss: 1.000029] [G loss: 0.999982]\n",
      "epoch:21 step:98860[D loss: 1.000035] [G loss: 1.000093]\n",
      "epoch:21 step:98865[D loss: 0.999977] [G loss: 1.000141]\n",
      "epoch:21 step:98870[D loss: 1.000013] [G loss: 1.000072]\n",
      "epoch:21 step:98875[D loss: 0.999908] [G loss: 1.000258]\n",
      "epoch:21 step:98880[D loss: 1.000050] [G loss: 0.999975]\n",
      "epoch:21 step:98885[D loss: 0.999909] [G loss: 1.000158]\n",
      "epoch:21 step:98890[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:21 step:98895[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:21 step:98900[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:21 step:98905[D loss: 1.000049] [G loss: 0.999898]\n",
      "epoch:21 step:98910[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:21 step:98915[D loss: 1.000029] [G loss: 0.999865]\n",
      "epoch:21 step:98920[D loss: 1.000068] [G loss: 0.999972]\n",
      "epoch:21 step:98925[D loss: 1.000077] [G loss: 0.999892]\n",
      "epoch:21 step:98930[D loss: 0.999956] [G loss: 1.000055]\n",
      "epoch:21 step:98935[D loss: 0.999960] [G loss: 1.000124]\n",
      "epoch:21 step:98940[D loss: 0.999933] [G loss: 1.000104]\n",
      "epoch:21 step:98945[D loss: 0.999951] [G loss: 1.000113]\n",
      "epoch:21 step:98950[D loss: 1.000067] [G loss: 0.999962]\n",
      "epoch:21 step:98955[D loss: 0.999909] [G loss: 1.000146]\n",
      "epoch:21 step:98960[D loss: 1.000064] [G loss: 1.000002]\n",
      "epoch:21 step:98965[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:21 step:98970[D loss: 1.000028] [G loss: 1.000024]\n",
      "epoch:21 step:98975[D loss: 1.000060] [G loss: 0.999971]\n",
      "epoch:21 step:98980[D loss: 1.000044] [G loss: 1.000064]\n",
      "epoch:21 step:98985[D loss: 0.999971] [G loss: 0.999973]\n",
      "epoch:21 step:98990[D loss: 1.000013] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:98995[D loss: 1.000016] [G loss: 1.000110]\n",
      "epoch:21 step:99000[D loss: 0.999982] [G loss: 1.000026]\n",
      "##############\n",
      "[2.6130648  2.07303345 2.2062245  3.7313082  1.49254381 7.62741947\n",
      " 2.30466201 3.75659727 3.9752695  5.51586275]\n",
      "##########\n",
      "epoch:21 step:99005[D loss: 1.000015] [G loss: 1.000059]\n",
      "epoch:21 step:99010[D loss: 0.999946] [G loss: 1.000075]\n",
      "epoch:21 step:99015[D loss: 0.999995] [G loss: 1.000122]\n",
      "epoch:21 step:99020[D loss: 0.999939] [G loss: 1.000113]\n",
      "epoch:21 step:99025[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:21 step:99030[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:21 step:99035[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:21 step:99040[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:21 step:99045[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:21 step:99050[D loss: 0.999957] [G loss: 1.000045]\n",
      "epoch:21 step:99055[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:21 step:99060[D loss: 0.999985] [G loss: 1.000005]\n",
      "epoch:21 step:99065[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:21 step:99070[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:21 step:99075[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:21 step:99080[D loss: 0.999998] [G loss: 1.000051]\n",
      "epoch:21 step:99085[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:21 step:99090[D loss: 0.999991] [G loss: 1.000089]\n",
      "epoch:21 step:99095[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:21 step:99100[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:21 step:99105[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:21 step:99110[D loss: 1.000006] [G loss: 1.000077]\n",
      "epoch:21 step:99115[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:21 step:99120[D loss: 0.999999] [G loss: 1.000080]\n",
      "epoch:21 step:99125[D loss: 0.999952] [G loss: 1.000093]\n",
      "epoch:21 step:99130[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:21 step:99135[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:21 step:99140[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:21 step:99145[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:21 step:99150[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:21 step:99155[D loss: 0.999955] [G loss: 1.000111]\n",
      "epoch:21 step:99160[D loss: 1.000006] [G loss: 1.000054]\n",
      "epoch:21 step:99165[D loss: 0.999969] [G loss: 1.000111]\n",
      "epoch:21 step:99170[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:21 step:99175[D loss: 0.999932] [G loss: 1.000105]\n",
      "epoch:21 step:99180[D loss: 0.999952] [G loss: 1.000069]\n",
      "epoch:21 step:99185[D loss: 0.999986] [G loss: 1.000091]\n",
      "epoch:21 step:99190[D loss: 1.000045] [G loss: 1.000019]\n",
      "epoch:21 step:99195[D loss: 1.000076] [G loss: 0.999924]\n",
      "epoch:21 step:99200[D loss: 0.999924] [G loss: 1.000104]\n",
      "##############\n",
      "[2.65649851 2.13987442 2.38939831 3.88727117 1.39504723 7.95893446\n",
      " 2.48218756 3.79079643 4.00706051 4.7450017 ]\n",
      "##########\n",
      "epoch:21 step:99205[D loss: 0.999929] [G loss: 1.000090]\n",
      "epoch:21 step:99210[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:21 step:99215[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:21 step:99220[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:21 step:99225[D loss: 0.999943] [G loss: 1.000129]\n",
      "epoch:21 step:99230[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:21 step:99235[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:21 step:99240[D loss: 0.999965] [G loss: 1.000119]\n",
      "epoch:21 step:99245[D loss: 1.000004] [G loss: 0.999969]\n",
      "epoch:21 step:99250[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:21 step:99255[D loss: 1.000007] [G loss: 1.000015]\n",
      "epoch:21 step:99260[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:21 step:99265[D loss: 0.999970] [G loss: 1.000100]\n",
      "epoch:21 step:99270[D loss: 0.999937] [G loss: 1.000121]\n",
      "epoch:21 step:99275[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:21 step:99280[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:21 step:99285[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:21 step:99290[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:21 step:99295[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:21 step:99300[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:21 step:99305[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:21 step:99310[D loss: 1.000014] [G loss: 0.999958]\n",
      "epoch:21 step:99315[D loss: 1.000002] [G loss: 1.000042]\n",
      "epoch:21 step:99320[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:21 step:99325[D loss: 0.999998] [G loss: 1.000090]\n",
      "epoch:21 step:99330[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:21 step:99335[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:21 step:99340[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:21 step:99345[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:21 step:99350[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:21 step:99355[D loss: 1.000016] [G loss: 1.000065]\n",
      "epoch:21 step:99360[D loss: 1.000021] [G loss: 1.000019]\n",
      "epoch:21 step:99365[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:21 step:99370[D loss: 0.999998] [G loss: 1.000109]\n",
      "epoch:21 step:99375[D loss: 0.999997] [G loss: 1.000175]\n",
      "epoch:21 step:99380[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:21 step:99385[D loss: 0.999968] [G loss: 1.000196]\n",
      "epoch:21 step:99390[D loss: 0.999943] [G loss: 1.000156]\n",
      "epoch:21 step:99395[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:21 step:99400[D loss: 0.999963] [G loss: 1.000094]\n",
      "##############\n",
      "[2.66399864 2.17378937 2.12967364 3.89147861 1.47968255 8.50108253\n",
      " 2.4076105  3.94999949 4.04283904 5.14324466]\n",
      "##########\n",
      "epoch:21 step:99405[D loss: 0.999960] [G loss: 1.000053]\n",
      "epoch:21 step:99410[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:21 step:99415[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:21 step:99420[D loss: 1.000047] [G loss: 0.999935]\n",
      "epoch:21 step:99425[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:21 step:99430[D loss: 1.000033] [G loss: 1.000023]\n",
      "epoch:21 step:99435[D loss: 1.000049] [G loss: 0.999980]\n",
      "epoch:21 step:99440[D loss: 1.000017] [G loss: 0.999975]\n",
      "epoch:21 step:99445[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:21 step:99450[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:21 step:99455[D loss: 0.999994] [G loss: 1.000103]\n",
      "epoch:21 step:99460[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:21 step:99465[D loss: 0.999991] [G loss: 1.000089]\n",
      "epoch:21 step:99470[D loss: 1.000046] [G loss: 1.000146]\n",
      "epoch:21 step:99475[D loss: 0.999937] [G loss: 1.000153]\n",
      "epoch:21 step:99480[D loss: 0.999946] [G loss: 1.000106]\n",
      "epoch:21 step:99485[D loss: 0.999980] [G loss: 1.000093]\n",
      "epoch:21 step:99490[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:21 step:99495[D loss: 1.000016] [G loss: 0.999997]\n",
      "epoch:21 step:99500[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:21 step:99505[D loss: 1.000005] [G loss: 0.999954]\n",
      "epoch:21 step:99510[D loss: 0.999950] [G loss: 1.000148]\n",
      "epoch:21 step:99515[D loss: 1.000075] [G loss: 1.000013]\n",
      "epoch:21 step:99520[D loss: 1.000151] [G loss: 0.999865]\n",
      "epoch:21 step:99525[D loss: 0.999985] [G loss: 0.999980]\n",
      "epoch:21 step:99530[D loss: 0.999933] [G loss: 1.000089]\n",
      "epoch:21 step:99535[D loss: 1.000101] [G loss: 0.999962]\n",
      "epoch:21 step:99540[D loss: 0.999900] [G loss: 1.000237]\n",
      "epoch:21 step:99545[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:21 step:99550[D loss: 1.000023] [G loss: 1.000051]\n",
      "epoch:21 step:99555[D loss: 0.999965] [G loss: 1.000187]\n",
      "epoch:21 step:99560[D loss: 0.999983] [G loss: 1.000180]\n",
      "epoch:21 step:99565[D loss: 0.999954] [G loss: 1.000125]\n",
      "epoch:21 step:99570[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:21 step:99575[D loss: 1.000006] [G loss: 0.999991]\n",
      "epoch:21 step:99580[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:21 step:99585[D loss: 0.999995] [G loss: 1.000002]\n",
      "epoch:21 step:99590[D loss: 1.000110] [G loss: 0.999844]\n",
      "epoch:21 step:99595[D loss: 1.000021] [G loss: 0.999897]\n",
      "epoch:21 step:99600[D loss: 1.000005] [G loss: 0.999940]\n",
      "##############\n",
      "[2.60980459 2.05196953 2.31771247 3.91155515 1.4913292  7.8799982\n",
      " 2.27984993 3.76437827 3.99518725 5.4547416 ]\n",
      "##########\n",
      "epoch:21 step:99605[D loss: 1.000056] [G loss: 0.999974]\n",
      "epoch:21 step:99610[D loss: 1.000060] [G loss: 0.999869]\n",
      "epoch:21 step:99615[D loss: 0.999982] [G loss: 1.000104]\n",
      "epoch:21 step:99620[D loss: 0.999900] [G loss: 1.000097]\n",
      "epoch:21 step:99625[D loss: 0.999989] [G loss: 1.000102]\n",
      "epoch:21 step:99630[D loss: 0.999935] [G loss: 1.000148]\n",
      "epoch:21 step:99635[D loss: 0.999998] [G loss: 1.000013]\n",
      "epoch:21 step:99640[D loss: 0.999971] [G loss: 1.000030]\n",
      "epoch:21 step:99645[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:21 step:99650[D loss: 1.000004] [G loss: 0.999996]\n",
      "epoch:21 step:99655[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:21 step:99660[D loss: 0.999959] [G loss: 1.000104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:99665[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:21 step:99670[D loss: 0.999989] [G loss: 1.000081]\n",
      "epoch:21 step:99675[D loss: 1.000089] [G loss: 0.999978]\n",
      "epoch:21 step:99680[D loss: 0.999917] [G loss: 1.000131]\n",
      "epoch:21 step:99685[D loss: 0.999991] [G loss: 1.000116]\n",
      "epoch:21 step:99690[D loss: 0.999945] [G loss: 1.000091]\n",
      "epoch:21 step:99695[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:21 step:99700[D loss: 1.000052] [G loss: 1.000046]\n",
      "epoch:21 step:99705[D loss: 0.999936] [G loss: 1.000116]\n",
      "epoch:21 step:99710[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:21 step:99715[D loss: 0.999935] [G loss: 1.000178]\n",
      "epoch:21 step:99720[D loss: 0.999939] [G loss: 1.000124]\n",
      "epoch:21 step:99725[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:21 step:99730[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:21 step:99735[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:21 step:99740[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:21 step:99745[D loss: 0.999953] [G loss: 1.000054]\n",
      "epoch:21 step:99750[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:21 step:99755[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:21 step:99760[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:21 step:99765[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:21 step:99770[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:21 step:99775[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:21 step:99780[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:21 step:99785[D loss: 0.999939] [G loss: 1.000113]\n",
      "epoch:21 step:99790[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:21 step:99795[D loss: 0.999967] [G loss: 1.000038]\n",
      "epoch:21 step:99800[D loss: 0.999950] [G loss: 1.000077]\n",
      "##############\n",
      "[2.54194236 2.12114047 2.29912737 4.18473862 1.46795151 7.5231818\n",
      " 2.3599963  3.7285635  3.91000932 5.5007903 ]\n",
      "##########\n",
      "epoch:21 step:99805[D loss: 0.999952] [G loss: 1.000137]\n",
      "epoch:21 step:99810[D loss: 0.999981] [G loss: 1.000091]\n",
      "epoch:21 step:99815[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:21 step:99820[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:21 step:99825[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:21 step:99830[D loss: 0.999943] [G loss: 1.000115]\n",
      "epoch:21 step:99835[D loss: 0.999943] [G loss: 1.000099]\n",
      "epoch:21 step:99840[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:21 step:99845[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:21 step:99850[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:21 step:99855[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:21 step:99860[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:21 step:99865[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:21 step:99870[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:21 step:99875[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:21 step:99880[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:21 step:99885[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:21 step:99890[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:21 step:99895[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:21 step:99900[D loss: 1.000049] [G loss: 1.000004]\n",
      "epoch:21 step:99905[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:21 step:99910[D loss: 1.000042] [G loss: 0.999985]\n",
      "epoch:21 step:99915[D loss: 0.999947] [G loss: 1.000157]\n",
      "epoch:21 step:99920[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:21 step:99925[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:21 step:99930[D loss: 1.000011] [G loss: 0.999994]\n",
      "epoch:21 step:99935[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:21 step:99940[D loss: 1.000046] [G loss: 0.999971]\n",
      "epoch:21 step:99945[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:21 step:99950[D loss: 1.000000] [G loss: 0.999988]\n",
      "epoch:21 step:99955[D loss: 0.999964] [G loss: 1.000044]\n",
      "epoch:21 step:99960[D loss: 0.999961] [G loss: 1.000166]\n",
      "epoch:21 step:99965[D loss: 0.999982] [G loss: 1.000186]\n",
      "epoch:21 step:99970[D loss: 0.999943] [G loss: 1.000075]\n",
      "epoch:21 step:99975[D loss: 0.999989] [G loss: 1.000022]\n",
      "epoch:21 step:99980[D loss: 0.999965] [G loss: 1.000033]\n",
      "epoch:21 step:99985[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:21 step:99990[D loss: 1.000138] [G loss: 0.999926]\n",
      "epoch:21 step:99995[D loss: 1.000067] [G loss: 0.999886]\n",
      "epoch:21 step:100000[D loss: 1.000134] [G loss: 0.999854]\n",
      "##############\n",
      "[2.51462214 2.1278087  2.36268079 3.89809961 1.4927714  7.40467431\n",
      " 2.32261465 3.84136903 3.96414912 5.62158876]\n",
      "##########\n",
      "epoch:21 step:100005[D loss: 0.999909] [G loss: 1.000120]\n",
      "epoch:21 step:100010[D loss: 0.999923] [G loss: 1.000075]\n",
      "epoch:21 step:100015[D loss: 0.999939] [G loss: 1.000063]\n",
      "epoch:21 step:100020[D loss: 0.999958] [G loss: 1.000051]\n",
      "epoch:21 step:100025[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:21 step:100030[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:21 step:100035[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:21 step:100040[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:21 step:100045[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:21 step:100050[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:21 step:100055[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:21 step:100060[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:21 step:100065[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:21 step:100070[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:21 step:100075[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:21 step:100080[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:21 step:100085[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:21 step:100090[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:21 step:100095[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:21 step:100100[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:21 step:100105[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:21 step:100110[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:21 step:100115[D loss: 0.999996] [G loss: 1.000076]\n",
      "epoch:21 step:100120[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:21 step:100125[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:21 step:100130[D loss: 0.999966] [G loss: 1.000114]\n",
      "epoch:21 step:100135[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:21 step:100140[D loss: 0.999979] [G loss: 1.000092]\n",
      "epoch:21 step:100145[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:21 step:100150[D loss: 0.999947] [G loss: 1.000098]\n",
      "epoch:21 step:100155[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:21 step:100160[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:21 step:100165[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:21 step:100170[D loss: 0.999948] [G loss: 1.000101]\n",
      "epoch:21 step:100175[D loss: 0.999974] [G loss: 1.000125]\n",
      "epoch:21 step:100180[D loss: 0.999947] [G loss: 1.000081]\n",
      "epoch:21 step:100185[D loss: 1.000007] [G loss: 1.000066]\n",
      "epoch:21 step:100190[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:21 step:100195[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:21 step:100200[D loss: 1.000031] [G loss: 1.000020]\n",
      "##############\n",
      "[2.58351133 2.1300947  2.34693631 3.77447569 1.3772274  7.35665636\n",
      " 2.27687446 3.67704422 4.06422946 4.94939082]\n",
      "##########\n",
      "epoch:21 step:100205[D loss: 0.999939] [G loss: 1.000250]\n",
      "epoch:21 step:100210[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:21 step:100215[D loss: 1.000052] [G loss: 0.999949]\n",
      "epoch:21 step:100220[D loss: 0.999995] [G loss: 1.000159]\n",
      "epoch:21 step:100225[D loss: 0.999918] [G loss: 1.000216]\n",
      "epoch:21 step:100230[D loss: 0.999866] [G loss: 1.000198]\n",
      "epoch:21 step:100235[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:21 step:100240[D loss: 0.999973] [G loss: 1.000039]\n",
      "epoch:21 step:100245[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:21 step:100250[D loss: 0.999981] [G loss: 1.000033]\n",
      "epoch:21 step:100255[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:21 step:100260[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:21 step:100265[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:21 step:100270[D loss: 1.000092] [G loss: 0.999889]\n",
      "epoch:21 step:100275[D loss: 1.000116] [G loss: 0.999999]\n",
      "epoch:21 step:100280[D loss: 0.999991] [G loss: 1.000016]\n",
      "epoch:21 step:100285[D loss: 0.999950] [G loss: 1.000024]\n",
      "epoch:21 step:100290[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:21 step:100295[D loss: 0.999929] [G loss: 1.000140]\n",
      "epoch:21 step:100300[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:21 step:100305[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:21 step:100310[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:21 step:100315[D loss: 0.999951] [G loss: 1.000073]\n",
      "epoch:21 step:100320[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:21 step:100325[D loss: 0.999945] [G loss: 1.000088]\n",
      "epoch:21 step:100330[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:21 step:100335[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:21 step:100340[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:21 step:100345[D loss: 0.999998] [G loss: 1.000088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:100350[D loss: 0.999927] [G loss: 1.000144]\n",
      "epoch:21 step:100355[D loss: 0.999973] [G loss: 1.000128]\n",
      "epoch:21 step:100360[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:21 step:100365[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:21 step:100370[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:21 step:100375[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:21 step:100380[D loss: 0.999951] [G loss: 1.000082]\n",
      "epoch:21 step:100385[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:21 step:100390[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:21 step:100395[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:21 step:100400[D loss: 0.999953] [G loss: 1.000160]\n",
      "##############\n",
      "[2.47634221 2.16074881 2.19046293 3.867408   1.38114494 8.15993404\n",
      " 2.33532307 3.90107595 4.05640114 6.08340922]\n",
      "##########\n",
      "epoch:21 step:100405[D loss: 0.999929] [G loss: 1.000110]\n",
      "epoch:21 step:100410[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:21 step:100415[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:21 step:100420[D loss: 1.000090] [G loss: 0.999950]\n",
      "epoch:21 step:100425[D loss: 0.999961] [G loss: 1.000040]\n",
      "epoch:21 step:100430[D loss: 0.999947] [G loss: 1.000104]\n",
      "epoch:21 step:100435[D loss: 1.000075] [G loss: 1.000004]\n",
      "epoch:21 step:100440[D loss: 0.999959] [G loss: 1.000110]\n",
      "epoch:21 step:100445[D loss: 1.000016] [G loss: 1.000076]\n",
      "epoch:21 step:100450[D loss: 0.999981] [G loss: 1.000101]\n",
      "epoch:21 step:100455[D loss: 1.000045] [G loss: 0.999955]\n",
      "epoch:21 step:100460[D loss: 0.999941] [G loss: 1.000041]\n",
      "epoch:21 step:100465[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:21 step:100470[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:21 step:100475[D loss: 0.999977] [G loss: 1.000021]\n",
      "epoch:21 step:100480[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:21 step:100485[D loss: 0.999959] [G loss: 1.000055]\n",
      "epoch:21 step:100490[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:21 step:100495[D loss: 0.999941] [G loss: 1.000130]\n",
      "epoch:21 step:100500[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:21 step:100505[D loss: 0.999999] [G loss: 1.000080]\n",
      "epoch:21 step:100510[D loss: 0.999960] [G loss: 1.000108]\n",
      "epoch:21 step:100515[D loss: 1.000002] [G loss: 1.000010]\n",
      "epoch:21 step:100520[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:21 step:100525[D loss: 0.999997] [G loss: 1.000002]\n",
      "epoch:21 step:100530[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:21 step:100535[D loss: 0.999959] [G loss: 1.000103]\n",
      "epoch:21 step:100540[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:21 step:100545[D loss: 1.000008] [G loss: 1.000023]\n",
      "epoch:21 step:100550[D loss: 1.000006] [G loss: 1.000053]\n",
      "epoch:21 step:100555[D loss: 0.999975] [G loss: 1.000163]\n",
      "epoch:21 step:100560[D loss: 0.999933] [G loss: 1.000178]\n",
      "epoch:21 step:100565[D loss: 0.999929] [G loss: 1.000128]\n",
      "epoch:21 step:100570[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:21 step:100575[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:21 step:100580[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:21 step:100585[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:21 step:100590[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:21 step:100595[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:21 step:100600[D loss: 0.999943] [G loss: 1.000120]\n",
      "##############\n",
      "[2.62568712 2.15861258 2.21354886 3.95752699 1.47553407 7.53872602\n",
      " 2.5268549  3.88792248 4.04664884 6.04150848]\n",
      "##########\n",
      "epoch:21 step:100605[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:21 step:100610[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:21 step:100615[D loss: 1.000037] [G loss: 1.000074]\n",
      "epoch:21 step:100620[D loss: 1.000034] [G loss: 1.000032]\n",
      "epoch:21 step:100625[D loss: 1.000074] [G loss: 1.000007]\n",
      "epoch:21 step:100630[D loss: 0.999955] [G loss: 1.000136]\n",
      "epoch:21 step:100635[D loss: 0.999897] [G loss: 1.000277]\n",
      "epoch:21 step:100640[D loss: 0.999968] [G loss: 1.000106]\n",
      "epoch:21 step:100645[D loss: 0.999964] [G loss: 1.000117]\n",
      "epoch:21 step:100650[D loss: 0.999945] [G loss: 1.000111]\n",
      "epoch:21 step:100655[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:21 step:100660[D loss: 1.000015] [G loss: 0.999958]\n",
      "epoch:21 step:100665[D loss: 0.999969] [G loss: 1.000029]\n",
      "epoch:21 step:100670[D loss: 0.999998] [G loss: 1.000080]\n",
      "epoch:21 step:100675[D loss: 1.000112] [G loss: 0.999895]\n",
      "epoch:21 step:100680[D loss: 1.000166] [G loss: 1.000005]\n",
      "epoch:21 step:100685[D loss: 1.000053] [G loss: 0.999808]\n",
      "epoch:21 step:100690[D loss: 0.999937] [G loss: 1.000128]\n",
      "epoch:21 step:100695[D loss: 0.999913] [G loss: 1.000156]\n",
      "epoch:21 step:100700[D loss: 0.999939] [G loss: 1.000122]\n",
      "epoch:21 step:100705[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:21 step:100710[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:21 step:100715[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:21 step:100720[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:21 step:100725[D loss: 1.000007] [G loss: 1.000047]\n",
      "epoch:21 step:100730[D loss: 1.000024] [G loss: 1.000086]\n",
      "epoch:21 step:100735[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:21 step:100740[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:21 step:100745[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:21 step:100750[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:21 step:100755[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:21 step:100760[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:21 step:100765[D loss: 1.000003] [G loss: 1.000018]\n",
      "epoch:21 step:100770[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:21 step:100775[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:21 step:100780[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:21 step:100785[D loss: 0.999947] [G loss: 1.000075]\n",
      "epoch:21 step:100790[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:21 step:100795[D loss: 0.999992] [G loss: 1.000008]\n",
      "epoch:21 step:100800[D loss: 0.999978] [G loss: 1.000066]\n",
      "##############\n",
      "[2.59718333 2.20102871 2.27813067 3.48762256 1.3594405  7.38678626\n",
      " 2.25201417 3.61292929 4.06891335 5.71849153]\n",
      "##########\n",
      "epoch:21 step:100805[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:21 step:100810[D loss: 1.000036] [G loss: 0.999961]\n",
      "epoch:21 step:100815[D loss: 0.999940] [G loss: 1.000089]\n",
      "epoch:21 step:100820[D loss: 0.999936] [G loss: 1.000097]\n",
      "epoch:21 step:100825[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:21 step:100830[D loss: 0.999972] [G loss: 1.000108]\n",
      "epoch:21 step:100835[D loss: 0.999948] [G loss: 1.000129]\n",
      "epoch:21 step:100840[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:21 step:100845[D loss: 0.999982] [G loss: 1.000110]\n",
      "epoch:21 step:100850[D loss: 1.000039] [G loss: 1.000118]\n",
      "epoch:21 step:100855[D loss: 0.999939] [G loss: 1.000197]\n",
      "epoch:21 step:100860[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:21 step:100865[D loss: 1.000015] [G loss: 1.000177]\n",
      "epoch:21 step:100870[D loss: 0.999967] [G loss: 1.000140]\n",
      "epoch:21 step:100875[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:21 step:100880[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:21 step:100885[D loss: 1.000021] [G loss: 1.000031]\n",
      "epoch:21 step:100890[D loss: 0.999930] [G loss: 1.000075]\n",
      "epoch:21 step:100895[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:21 step:100900[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:21 step:100905[D loss: 0.999968] [G loss: 1.000101]\n",
      "epoch:21 step:100910[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:21 step:100915[D loss: 0.999941] [G loss: 1.000113]\n",
      "epoch:21 step:100920[D loss: 1.000012] [G loss: 1.000059]\n",
      "epoch:21 step:100925[D loss: 1.000104] [G loss: 0.999898]\n",
      "epoch:21 step:100930[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:21 step:100935[D loss: 1.000137] [G loss: 1.000064]\n",
      "epoch:21 step:100940[D loss: 0.999918] [G loss: 1.000154]\n",
      "epoch:21 step:100945[D loss: 0.999940] [G loss: 1.000072]\n",
      "epoch:21 step:100950[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:21 step:100955[D loss: 0.999936] [G loss: 1.000115]\n",
      "epoch:21 step:100960[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:21 step:100965[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:21 step:100970[D loss: 1.000102] [G loss: 0.999914]\n",
      "epoch:21 step:100975[D loss: 1.000015] [G loss: 0.999997]\n",
      "epoch:21 step:100980[D loss: 0.999940] [G loss: 1.000094]\n",
      "epoch:21 step:100985[D loss: 1.000001] [G loss: 1.000008]\n",
      "epoch:21 step:100990[D loss: 0.999955] [G loss: 1.000098]\n",
      "epoch:21 step:100995[D loss: 0.999941] [G loss: 1.000080]\n",
      "epoch:21 step:101000[D loss: 1.000002] [G loss: 1.000076]\n",
      "##############\n",
      "[2.48544521 2.202069   2.14781139 3.85229007 1.38370155 7.39076232\n",
      " 2.42449133 3.7084616  3.99642682 5.79331924]\n",
      "##########\n",
      "epoch:21 step:101005[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:21 step:101010[D loss: 0.999956] [G loss: 1.000096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:101015[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:21 step:101020[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:21 step:101025[D loss: 0.999938] [G loss: 1.000093]\n",
      "epoch:21 step:101030[D loss: 0.999948] [G loss: 1.000125]\n",
      "epoch:21 step:101035[D loss: 0.999949] [G loss: 1.000163]\n",
      "epoch:21 step:101040[D loss: 0.999981] [G loss: 1.000033]\n",
      "epoch:21 step:101045[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:21 step:101050[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:21 step:101055[D loss: 0.999979] [G loss: 1.000096]\n",
      "epoch:21 step:101060[D loss: 1.000040] [G loss: 0.999968]\n",
      "epoch:21 step:101065[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:21 step:101070[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:21 step:101075[D loss: 1.000017] [G loss: 0.999999]\n",
      "epoch:21 step:101080[D loss: 1.000001] [G loss: 1.000071]\n",
      "epoch:21 step:101085[D loss: 0.999935] [G loss: 1.000074]\n",
      "epoch:21 step:101090[D loss: 0.999956] [G loss: 1.000066]\n",
      "epoch:21 step:101095[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:21 step:101100[D loss: 0.999998] [G loss: 1.000071]\n",
      "epoch:21 step:101105[D loss: 1.000003] [G loss: 1.000056]\n",
      "epoch:21 step:101110[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:21 step:101115[D loss: 0.999964] [G loss: 1.000124]\n",
      "epoch:21 step:101120[D loss: 0.999936] [G loss: 1.000089]\n",
      "epoch:21 step:101125[D loss: 0.999945] [G loss: 1.000082]\n",
      "epoch:21 step:101130[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:21 step:101135[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:21 step:101140[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:21 step:101145[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:21 step:101150[D loss: 1.000059] [G loss: 0.999948]\n",
      "epoch:21 step:101155[D loss: 0.999952] [G loss: 1.000050]\n",
      "epoch:21 step:101160[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:21 step:101165[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:21 step:101170[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:21 step:101175[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:21 step:101180[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:21 step:101185[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:21 step:101190[D loss: 1.000008] [G loss: 1.000069]\n",
      "epoch:21 step:101195[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:21 step:101200[D loss: 1.000014] [G loss: 1.000072]\n",
      "##############\n",
      "[2.58329432 2.129047   2.16106766 3.78508724 1.40179941 9.27426719\n",
      " 2.31003702 3.53700405 3.97308314 5.28658   ]\n",
      "##########\n",
      "epoch:21 step:101205[D loss: 0.999938] [G loss: 1.000095]\n",
      "epoch:21 step:101210[D loss: 0.999950] [G loss: 1.000101]\n",
      "epoch:21 step:101215[D loss: 0.999982] [G loss: 1.000008]\n",
      "epoch:21 step:101220[D loss: 0.999953] [G loss: 1.000031]\n",
      "epoch:21 step:101225[D loss: 0.999987] [G loss: 1.000105]\n",
      "epoch:21 step:101230[D loss: 0.999937] [G loss: 1.000099]\n",
      "epoch:21 step:101235[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:21 step:101240[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:21 step:101245[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:21 step:101250[D loss: 0.999991] [G loss: 1.000069]\n",
      "epoch:21 step:101255[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:21 step:101260[D loss: 1.000038] [G loss: 1.000045]\n",
      "epoch:21 step:101265[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:21 step:101270[D loss: 0.999903] [G loss: 1.000125]\n",
      "epoch:21 step:101275[D loss: 0.999993] [G loss: 1.000125]\n",
      "epoch:21 step:101280[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:21 step:101285[D loss: 1.000074] [G loss: 1.000058]\n",
      "epoch:21 step:101290[D loss: 0.999940] [G loss: 1.000108]\n",
      "epoch:21 step:101295[D loss: 0.999967] [G loss: 1.000113]\n",
      "epoch:21 step:101300[D loss: 1.000008] [G loss: 1.000021]\n",
      "epoch:21 step:101305[D loss: 0.999969] [G loss: 0.999985]\n",
      "epoch:21 step:101310[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:21 step:101315[D loss: 0.999970] [G loss: 1.000011]\n",
      "epoch:21 step:101320[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:21 step:101325[D loss: 1.000141] [G loss: 0.999909]\n",
      "epoch:21 step:101330[D loss: 1.000046] [G loss: 1.000012]\n",
      "epoch:21 step:101335[D loss: 0.999945] [G loss: 1.000063]\n",
      "epoch:21 step:101340[D loss: 0.999943] [G loss: 1.000143]\n",
      "epoch:21 step:101345[D loss: 0.999945] [G loss: 1.000063]\n",
      "epoch:21 step:101350[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:21 step:101355[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:21 step:101360[D loss: 1.000057] [G loss: 0.999959]\n",
      "epoch:21 step:101365[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:21 step:101370[D loss: 0.999978] [G loss: 1.000004]\n",
      "epoch:21 step:101375[D loss: 1.000018] [G loss: 1.000022]\n",
      "epoch:21 step:101380[D loss: 0.999880] [G loss: 1.000222]\n",
      "epoch:21 step:101385[D loss: 0.999976] [G loss: 1.000175]\n",
      "epoch:21 step:101390[D loss: 0.999943] [G loss: 1.000065]\n",
      "epoch:21 step:101395[D loss: 0.999933] [G loss: 1.000144]\n",
      "epoch:21 step:101400[D loss: 0.999988] [G loss: 1.000029]\n",
      "##############\n",
      "[2.59065555 2.07956892 2.1912768  3.66087973 1.40787963 9.27426719\n",
      " 2.37134344 3.76818992 3.96618566 5.50920798]\n",
      "##########\n",
      "epoch:21 step:101405[D loss: 1.000014] [G loss: 1.000009]\n",
      "epoch:21 step:101410[D loss: 1.000009] [G loss: 1.000028]\n",
      "epoch:21 step:101415[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:21 step:101420[D loss: 0.999994] [G loss: 1.000079]\n",
      "epoch:21 step:101425[D loss: 1.000016] [G loss: 1.000047]\n",
      "epoch:21 step:101430[D loss: 0.999943] [G loss: 1.000324]\n",
      "epoch:21 step:101435[D loss: 0.999902] [G loss: 1.000148]\n",
      "epoch:21 step:101440[D loss: 1.000014] [G loss: 1.000019]\n",
      "epoch:21 step:101445[D loss: 1.000004] [G loss: 1.000056]\n",
      "epoch:21 step:101450[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:21 step:101455[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:21 step:101460[D loss: 1.000017] [G loss: 0.999974]\n",
      "epoch:21 step:101465[D loss: 1.000015] [G loss: 0.999960]\n",
      "epoch:21 step:101470[D loss: 1.000123] [G loss: 0.999924]\n",
      "epoch:21 step:101475[D loss: 1.000027] [G loss: 1.000051]\n",
      "epoch:21 step:101480[D loss: 0.999861] [G loss: 1.000111]\n",
      "epoch:21 step:101485[D loss: 1.000025] [G loss: 1.000114]\n",
      "epoch:21 step:101490[D loss: 0.999985] [G loss: 1.000018]\n",
      "epoch:21 step:101495[D loss: 1.000028] [G loss: 1.000051]\n",
      "epoch:21 step:101500[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:21 step:101505[D loss: 0.999943] [G loss: 1.000182]\n",
      "epoch:21 step:101510[D loss: 0.999979] [G loss: 1.000152]\n",
      "epoch:21 step:101515[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:21 step:101520[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:21 step:101525[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:21 step:101530[D loss: 0.999985] [G loss: 0.999992]\n",
      "epoch:21 step:101535[D loss: 1.000017] [G loss: 0.999996]\n",
      "epoch:21 step:101540[D loss: 0.999926] [G loss: 1.000125]\n",
      "epoch:21 step:101545[D loss: 1.000024] [G loss: 1.000057]\n",
      "epoch:21 step:101550[D loss: 0.999929] [G loss: 1.000138]\n",
      "epoch:21 step:101555[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:21 step:101560[D loss: 1.000034] [G loss: 0.999968]\n",
      "epoch:21 step:101565[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:21 step:101570[D loss: 1.000089] [G loss: 0.999911]\n",
      "epoch:21 step:101575[D loss: 0.999937] [G loss: 1.000062]\n",
      "epoch:21 step:101580[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:21 step:101585[D loss: 1.000008] [G loss: 1.000079]\n",
      "epoch:21 step:101590[D loss: 0.999960] [G loss: 1.000099]\n",
      "epoch:21 step:101595[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:21 step:101600[D loss: 0.999973] [G loss: 1.000051]\n",
      "##############\n",
      "[2.53938773 2.1744663  2.20790447 3.92949976 1.39946407 8.25722175\n",
      " 2.42209553 3.68088838 3.97205817 5.91215135]\n",
      "##########\n",
      "epoch:21 step:101605[D loss: 0.999993] [G loss: 1.000069]\n",
      "epoch:21 step:101610[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:21 step:101615[D loss: 1.000056] [G loss: 0.999961]\n",
      "epoch:21 step:101620[D loss: 0.999924] [G loss: 1.000093]\n",
      "epoch:21 step:101625[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:21 step:101630[D loss: 0.999964] [G loss: 1.000130]\n",
      "epoch:21 step:101635[D loss: 0.999954] [G loss: 1.000076]\n",
      "epoch:21 step:101640[D loss: 1.000000] [G loss: 1.000104]\n",
      "epoch:21 step:101645[D loss: 0.999912] [G loss: 1.000116]\n",
      "epoch:21 step:101650[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:21 step:101655[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:21 step:101660[D loss: 0.999974] [G loss: 1.000026]\n",
      "epoch:21 step:101665[D loss: 0.999970] [G loss: 1.000107]\n",
      "epoch:21 step:101670[D loss: 0.999999] [G loss: 1.000076]\n",
      "epoch:21 step:101675[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:21 step:101680[D loss: 0.999961] [G loss: 1.000100]\n",
      "epoch:21 step:101685[D loss: 0.999975] [G loss: 1.000026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:101690[D loss: 0.999947] [G loss: 1.000163]\n",
      "epoch:21 step:101695[D loss: 0.999995] [G loss: 1.000152]\n",
      "epoch:21 step:101700[D loss: 0.999941] [G loss: 1.000234]\n",
      "epoch:21 step:101705[D loss: 0.999945] [G loss: 1.000086]\n",
      "epoch:21 step:101710[D loss: 0.999925] [G loss: 1.000075]\n",
      "epoch:21 step:101715[D loss: 1.000025] [G loss: 0.999975]\n",
      "epoch:21 step:101720[D loss: 0.999959] [G loss: 1.000038]\n",
      "epoch:21 step:101725[D loss: 0.999994] [G loss: 1.000003]\n",
      "epoch:21 step:101730[D loss: 0.999942] [G loss: 1.000051]\n",
      "epoch:21 step:101735[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:21 step:101740[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:21 step:101745[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:21 step:101750[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:21 step:101755[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:21 step:101760[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:21 step:101765[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:21 step:101770[D loss: 1.000028] [G loss: 0.999958]\n",
      "epoch:21 step:101775[D loss: 1.000008] [G loss: 1.000032]\n",
      "epoch:21 step:101780[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:21 step:101785[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:21 step:101790[D loss: 0.999961] [G loss: 1.000034]\n",
      "epoch:21 step:101795[D loss: 0.999960] [G loss: 1.000131]\n",
      "epoch:21 step:101800[D loss: 0.999957] [G loss: 1.000074]\n",
      "##############\n",
      "[2.54971573 2.03752085 2.07145477 3.93342068 1.37331254 7.60427306\n",
      " 2.27142186 3.58509611 3.93578806 5.33929269]\n",
      "##########\n",
      "epoch:21 step:101805[D loss: 0.999976] [G loss: 1.000004]\n",
      "epoch:21 step:101810[D loss: 1.000033] [G loss: 0.999996]\n",
      "epoch:21 step:101815[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:21 step:101820[D loss: 1.000000] [G loss: 0.999991]\n",
      "epoch:21 step:101825[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:21 step:101830[D loss: 1.000022] [G loss: 1.000006]\n",
      "epoch:21 step:101835[D loss: 0.999926] [G loss: 1.000118]\n",
      "epoch:21 step:101840[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:21 step:101845[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:21 step:101850[D loss: 1.000030] [G loss: 1.000095]\n",
      "epoch:21 step:101855[D loss: 0.999954] [G loss: 1.000126]\n",
      "epoch:21 step:101860[D loss: 0.999959] [G loss: 1.000146]\n",
      "epoch:21 step:101865[D loss: 0.999937] [G loss: 1.000108]\n",
      "epoch:21 step:101870[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:21 step:101875[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:21 step:101880[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:21 step:101885[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:21 step:101890[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:21 step:101895[D loss: 1.000002] [G loss: 1.000016]\n",
      "epoch:21 step:101900[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:21 step:101905[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:21 step:101910[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:21 step:101915[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:21 step:101920[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:21 step:101925[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:21 step:101930[D loss: 1.000021] [G loss: 1.000073]\n",
      "epoch:21 step:101935[D loss: 1.000112] [G loss: 0.999929]\n",
      "epoch:21 step:101940[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:21 step:101945[D loss: 0.999996] [G loss: 0.999978]\n",
      "epoch:21 step:101950[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:21 step:101955[D loss: 1.000123] [G loss: 0.999980]\n",
      "epoch:21 step:101960[D loss: 0.999960] [G loss: 1.000121]\n",
      "epoch:21 step:101965[D loss: 0.999961] [G loss: 1.000030]\n",
      "epoch:21 step:101970[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:21 step:101975[D loss: 1.000006] [G loss: 1.000016]\n",
      "epoch:21 step:101980[D loss: 1.000017] [G loss: 0.999992]\n",
      "epoch:21 step:101985[D loss: 0.999915] [G loss: 1.000060]\n",
      "epoch:21 step:101990[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:21 step:101995[D loss: 1.000011] [G loss: 1.000082]\n",
      "epoch:21 step:102000[D loss: 1.000088] [G loss: 1.000012]\n",
      "##############\n",
      "[2.5898381  2.12727542 2.10795946 3.94726821 1.31007253 8.17971265\n",
      " 2.38557473 3.72553508 3.97597205 5.94349815]\n",
      "##########\n",
      "epoch:21 step:102005[D loss: 0.999911] [G loss: 1.000195]\n",
      "epoch:21 step:102010[D loss: 0.999937] [G loss: 1.000122]\n",
      "epoch:21 step:102015[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:21 step:102020[D loss: 0.999981] [G loss: 1.000125]\n",
      "epoch:21 step:102025[D loss: 1.000023] [G loss: 1.000001]\n",
      "epoch:21 step:102030[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:21 step:102035[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:21 step:102040[D loss: 1.000035] [G loss: 1.000001]\n",
      "epoch:21 step:102045[D loss: 1.000004] [G loss: 1.000029]\n",
      "epoch:21 step:102050[D loss: 0.999989] [G loss: 0.999985]\n",
      "epoch:21 step:102055[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:21 step:102060[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:21 step:102065[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:21 step:102070[D loss: 1.000003] [G loss: 1.000082]\n",
      "epoch:21 step:102075[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:21 step:102080[D loss: 1.000064] [G loss: 1.000006]\n",
      "epoch:21 step:102085[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:21 step:102090[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:21 step:102095[D loss: 1.000011] [G loss: 1.000023]\n",
      "epoch:21 step:102100[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:21 step:102105[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:21 step:102110[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:21 step:102115[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:21 step:102120[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:21 step:102125[D loss: 1.000033] [G loss: 0.999981]\n",
      "epoch:21 step:102130[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:21 step:102135[D loss: 0.999935] [G loss: 1.000112]\n",
      "epoch:21 step:102140[D loss: 1.000015] [G loss: 0.999960]\n",
      "epoch:21 step:102145[D loss: 0.999943] [G loss: 1.000084]\n",
      "epoch:21 step:102150[D loss: 0.999993] [G loss: 1.000088]\n",
      "epoch:21 step:102155[D loss: 1.000052] [G loss: 1.000025]\n",
      "epoch:21 step:102160[D loss: 1.000025] [G loss: 0.999978]\n",
      "epoch:21 step:102165[D loss: 0.999959] [G loss: 1.000028]\n",
      "epoch:21 step:102170[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:21 step:102175[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:21 step:102180[D loss: 0.999978] [G loss: 1.000002]\n",
      "epoch:21 step:102185[D loss: 1.000005] [G loss: 1.000081]\n",
      "epoch:21 step:102190[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:21 step:102195[D loss: 1.000054] [G loss: 0.999994]\n",
      "epoch:21 step:102200[D loss: 0.999886] [G loss: 1.000177]\n",
      "##############\n",
      "[2.50672915 2.08293633 2.19696124 3.96710324 1.29598595 7.57626962\n",
      " 2.32347691 3.73663292 3.87523086 5.83227243]\n",
      "##########\n",
      "epoch:21 step:102205[D loss: 1.000016] [G loss: 0.999953]\n",
      "epoch:21 step:102210[D loss: 0.999999] [G loss: 1.000026]\n",
      "epoch:21 step:102215[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:21 step:102220[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:21 step:102225[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:21 step:102230[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:21 step:102235[D loss: 0.999992] [G loss: 1.000079]\n",
      "epoch:21 step:102240[D loss: 1.000026] [G loss: 0.999947]\n",
      "epoch:21 step:102245[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:21 step:102250[D loss: 0.999971] [G loss: 1.000116]\n",
      "epoch:21 step:102255[D loss: 1.000022] [G loss: 1.000075]\n",
      "epoch:21 step:102260[D loss: 0.999943] [G loss: 1.000084]\n",
      "epoch:21 step:102265[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:21 step:102270[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:21 step:102275[D loss: 1.000028] [G loss: 0.999975]\n",
      "epoch:21 step:102280[D loss: 1.000011] [G loss: 1.000035]\n",
      "epoch:21 step:102285[D loss: 0.999948] [G loss: 1.000162]\n",
      "epoch:21 step:102290[D loss: 0.999891] [G loss: 1.000062]\n",
      "epoch:21 step:102295[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:21 step:102300[D loss: 0.999954] [G loss: 1.000110]\n",
      "epoch:21 step:102305[D loss: 0.999956] [G loss: 1.000128]\n",
      "epoch:21 step:102310[D loss: 0.999985] [G loss: 1.000090]\n",
      "epoch:21 step:102315[D loss: 0.999905] [G loss: 1.000168]\n",
      "epoch:21 step:102320[D loss: 0.999952] [G loss: 1.000115]\n",
      "epoch:21 step:102325[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:21 step:102330[D loss: 0.999968] [G loss: 1.000117]\n",
      "epoch:21 step:102335[D loss: 0.999987] [G loss: 1.000009]\n",
      "epoch:21 step:102340[D loss: 1.000111] [G loss: 0.999771]\n",
      "epoch:21 step:102345[D loss: 0.999887] [G loss: 1.000154]\n",
      "epoch:21 step:102350[D loss: 0.999926] [G loss: 1.000117]\n",
      "epoch:21 step:102355[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:21 step:102360[D loss: 0.999991] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:102365[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:21 step:102370[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:21 step:102375[D loss: 1.000007] [G loss: 1.000077]\n",
      "epoch:21 step:102380[D loss: 0.999953] [G loss: 1.000116]\n",
      "epoch:21 step:102385[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:21 step:102390[D loss: 0.999999] [G loss: 1.000056]\n",
      "epoch:21 step:102395[D loss: 0.999995] [G loss: 0.999989]\n",
      "epoch:21 step:102400[D loss: 0.999953] [G loss: 1.000087]\n",
      "##############\n",
      "[2.52047091 2.25393705 2.27717769 3.84179645 1.42588067 7.40985847\n",
      " 2.36027779 3.82597285 3.99707338 5.15354586]\n",
      "##########\n",
      "epoch:21 step:102405[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:21 step:102410[D loss: 0.999959] [G loss: 1.000185]\n",
      "epoch:21 step:102415[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:21 step:102420[D loss: 0.999981] [G loss: 1.000144]\n",
      "epoch:21 step:102425[D loss: 1.000080] [G loss: 1.000012]\n",
      "epoch:21 step:102430[D loss: 0.999910] [G loss: 1.000127]\n",
      "epoch:21 step:102435[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:21 step:102440[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:21 step:102445[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:21 step:102450[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:21 step:102455[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:21 step:102460[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:21 step:102465[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:21 step:102470[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:21 step:102475[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:21 step:102480[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:21 step:102485[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:21 step:102490[D loss: 1.000039] [G loss: 0.999960]\n",
      "epoch:21 step:102495[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:21 step:102500[D loss: 0.999946] [G loss: 1.000087]\n",
      "epoch:21 step:102505[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:21 step:102510[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:21 step:102515[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:21 step:102520[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:21 step:102525[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:21 step:102530[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:21 step:102535[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:21 step:102540[D loss: 0.999957] [G loss: 1.000097]\n",
      "epoch:21 step:102545[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:21 step:102550[D loss: 1.000009] [G loss: 1.000012]\n",
      "epoch:21 step:102555[D loss: 1.000011] [G loss: 1.000092]\n",
      "epoch:21 step:102560[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:21 step:102565[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:21 step:102570[D loss: 0.999969] [G loss: 1.000110]\n",
      "epoch:21 step:102575[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:21 step:102580[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:21 step:102585[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:21 step:102590[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:21 step:102595[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:21 step:102600[D loss: 0.999973] [G loss: 1.000091]\n",
      "##############\n",
      "[2.54147371 2.08397537 2.19448419 3.69571372 1.33767442 7.46019291\n",
      " 2.09596734 3.68744933 3.88734443 6.49880727]\n",
      "##########\n",
      "epoch:21 step:102605[D loss: 0.999991] [G loss: 1.000120]\n",
      "epoch:21 step:102610[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:21 step:102615[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:21 step:102620[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:21 step:102625[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:21 step:102630[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:21 step:102635[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:21 step:102640[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:21 step:102645[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:21 step:102650[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:21 step:102655[D loss: 0.999986] [G loss: 1.000027]\n",
      "epoch:21 step:102660[D loss: 0.999986] [G loss: 1.000005]\n",
      "epoch:21 step:102665[D loss: 1.000008] [G loss: 1.000052]\n",
      "epoch:21 step:102670[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:21 step:102675[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:21 step:102680[D loss: 1.000012] [G loss: 1.000064]\n",
      "epoch:21 step:102685[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:21 step:102690[D loss: 0.999936] [G loss: 1.000096]\n",
      "epoch:21 step:102695[D loss: 0.999976] [G loss: 1.000026]\n",
      "epoch:21 step:102700[D loss: 1.000023] [G loss: 1.000036]\n",
      "epoch:21 step:102705[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:21 step:102710[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:21 step:102715[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:21 step:102720[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:21 step:102725[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:21 step:102730[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:21 step:102735[D loss: 1.000036] [G loss: 1.000025]\n",
      "epoch:21 step:102740[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:21 step:102745[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:21 step:102750[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:21 step:102755[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:21 step:102760[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:21 step:102765[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:21 step:102770[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:21 step:102775[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:21 step:102780[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:21 step:102785[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:21 step:102790[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:21 step:102795[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:21 step:102800[D loss: 0.999982] [G loss: 1.000074]\n",
      "##############\n",
      "[2.51153275 2.21071083 2.20257085 3.941718   1.37977173 7.78261142\n",
      " 2.39494749 3.81639218 4.00764678 5.13708975]\n",
      "##########\n",
      "epoch:21 step:102805[D loss: 0.999995] [G loss: 1.000025]\n",
      "epoch:21 step:102810[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:21 step:102815[D loss: 1.000005] [G loss: 0.999988]\n",
      "epoch:21 step:102820[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:21 step:102825[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:21 step:102830[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:21 step:102835[D loss: 1.000001] [G loss: 1.000030]\n",
      "epoch:21 step:102840[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:21 step:102845[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:21 step:102850[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:21 step:102855[D loss: 1.000012] [G loss: 1.000049]\n",
      "epoch:21 step:102860[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:21 step:102865[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:21 step:102870[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:21 step:102875[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:21 step:102880[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:21 step:102885[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:21 step:102890[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:21 step:102895[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:21 step:102900[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:21 step:102905[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:21 step:102910[D loss: 0.999992] [G loss: 1.000017]\n",
      "epoch:21 step:102915[D loss: 0.999995] [G loss: 1.000087]\n",
      "epoch:21 step:102920[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:21 step:102925[D loss: 1.000012] [G loss: 1.000026]\n",
      "epoch:21 step:102930[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:21 step:102935[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:21 step:102940[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:21 step:102945[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:21 step:102950[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:21 step:102955[D loss: 1.000012] [G loss: 1.000079]\n",
      "epoch:21 step:102960[D loss: 0.999946] [G loss: 1.000156]\n",
      "epoch:21 step:102965[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:21 step:102970[D loss: 1.000084] [G loss: 0.999999]\n",
      "epoch:21 step:102975[D loss: 0.999947] [G loss: 1.000066]\n",
      "epoch:21 step:102980[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:21 step:102985[D loss: 0.999986] [G loss: 0.999982]\n",
      "epoch:21 step:102990[D loss: 1.000050] [G loss: 0.999924]\n",
      "epoch:21 step:102995[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:21 step:103000[D loss: 0.999955] [G loss: 1.000054]\n",
      "##############\n",
      "[2.57431817 2.16806311 2.24970587 4.05753218 1.44254664 8.05344978\n",
      " 2.43688874 3.70563988 4.00242785 5.37643511]\n",
      "##########\n",
      "epoch:21 step:103005[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:21 step:103010[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:21 step:103015[D loss: 1.000029] [G loss: 0.999998]\n",
      "epoch:21 step:103020[D loss: 0.999988] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:103025[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:21 step:103030[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:21 step:103035[D loss: 0.999948] [G loss: 1.000070]\n",
      "epoch:21 step:103040[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:21 step:103045[D loss: 0.999986] [G loss: 1.000006]\n",
      "epoch:21 step:103050[D loss: 0.999976] [G loss: 1.000029]\n",
      "epoch:21 step:103055[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:21 step:103060[D loss: 0.999991] [G loss: 1.000109]\n",
      "epoch:21 step:103065[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:21 step:103070[D loss: 0.999966] [G loss: 1.000111]\n",
      "epoch:22 step:103075[D loss: 0.999989] [G loss: 1.000122]\n",
      "epoch:22 step:103080[D loss: 0.999938] [G loss: 1.000096]\n",
      "epoch:22 step:103085[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:22 step:103090[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:22 step:103095[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:22 step:103100[D loss: 0.999939] [G loss: 1.000095]\n",
      "epoch:22 step:103105[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:22 step:103110[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:22 step:103115[D loss: 1.000023] [G loss: 1.000019]\n",
      "epoch:22 step:103120[D loss: 1.000093] [G loss: 0.999969]\n",
      "epoch:22 step:103125[D loss: 0.999905] [G loss: 1.000204]\n",
      "epoch:22 step:103130[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:22 step:103135[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:22 step:103140[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:22 step:103145[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:22 step:103150[D loss: 1.000003] [G loss: 1.000058]\n",
      "epoch:22 step:103155[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:22 step:103160[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:22 step:103165[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:22 step:103170[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:22 step:103175[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:22 step:103180[D loss: 1.000031] [G loss: 0.999988]\n",
      "epoch:22 step:103185[D loss: 0.999946] [G loss: 1.000076]\n",
      "epoch:22 step:103190[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:22 step:103195[D loss: 0.999933] [G loss: 1.000092]\n",
      "epoch:22 step:103200[D loss: 0.999992] [G loss: 1.000054]\n",
      "##############\n",
      "[2.61339742 2.12890868 2.1706103  3.9823093  1.50207449 7.93185388\n",
      " 2.29272579 3.86123425 4.04653043 5.05569724]\n",
      "##########\n",
      "epoch:22 step:103205[D loss: 0.999998] [G loss: 1.000092]\n",
      "epoch:22 step:103210[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:22 step:103215[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:22 step:103220[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:22 step:103225[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:22 step:103230[D loss: 0.999950] [G loss: 1.000104]\n",
      "epoch:22 step:103235[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:22 step:103240[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:22 step:103245[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:22 step:103250[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:22 step:103255[D loss: 1.000013] [G loss: 1.000027]\n",
      "epoch:22 step:103260[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:22 step:103265[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:22 step:103270[D loss: 1.000106] [G loss: 0.999939]\n",
      "epoch:22 step:103275[D loss: 1.000054] [G loss: 0.999974]\n",
      "epoch:22 step:103280[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:22 step:103285[D loss: 0.999936] [G loss: 1.000120]\n",
      "epoch:22 step:103290[D loss: 0.999931] [G loss: 1.000104]\n",
      "epoch:22 step:103295[D loss: 0.999952] [G loss: 1.000130]\n",
      "epoch:22 step:103300[D loss: 0.999968] [G loss: 1.000104]\n",
      "epoch:22 step:103305[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:22 step:103310[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:22 step:103315[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:22 step:103320[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:22 step:103325[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:22 step:103330[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:22 step:103335[D loss: 1.000038] [G loss: 0.999971]\n",
      "epoch:22 step:103340[D loss: 0.999998] [G loss: 1.000095]\n",
      "epoch:22 step:103345[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:22 step:103350[D loss: 0.999984] [G loss: 1.000092]\n",
      "epoch:22 step:103355[D loss: 0.999965] [G loss: 1.000111]\n",
      "epoch:22 step:103360[D loss: 0.999984] [G loss: 1.000109]\n",
      "epoch:22 step:103365[D loss: 0.999939] [G loss: 1.000119]\n",
      "epoch:22 step:103370[D loss: 0.999948] [G loss: 1.000111]\n",
      "epoch:22 step:103375[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:22 step:103380[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:22 step:103385[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:22 step:103390[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:22 step:103395[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:22 step:103400[D loss: 0.999959] [G loss: 1.000033]\n",
      "##############\n",
      "[2.53953473 2.15235695 2.13852489 3.83296159 1.47585238 7.47416377\n",
      " 2.30862047 3.80274095 3.94781606 4.88809185]\n",
      "##########\n",
      "epoch:22 step:103405[D loss: 0.999958] [G loss: 1.000058]\n",
      "epoch:22 step:103410[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:22 step:103415[D loss: 1.000070] [G loss: 0.999943]\n",
      "epoch:22 step:103420[D loss: 0.999917] [G loss: 1.000132]\n",
      "epoch:22 step:103425[D loss: 0.999944] [G loss: 1.000117]\n",
      "epoch:22 step:103430[D loss: 0.999986] [G loss: 1.000135]\n",
      "epoch:22 step:103435[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:22 step:103440[D loss: 0.999952] [G loss: 1.000058]\n",
      "epoch:22 step:103445[D loss: 1.000010] [G loss: 1.000016]\n",
      "epoch:22 step:103450[D loss: 0.999958] [G loss: 1.000008]\n",
      "epoch:22 step:103455[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:22 step:103460[D loss: 0.999962] [G loss: 1.000049]\n",
      "epoch:22 step:103465[D loss: 0.999952] [G loss: 1.000128]\n",
      "epoch:22 step:103470[D loss: 0.999954] [G loss: 1.000142]\n",
      "epoch:22 step:103475[D loss: 0.999997] [G loss: 1.000082]\n",
      "epoch:22 step:103480[D loss: 0.999964] [G loss: 0.999977]\n",
      "epoch:22 step:103485[D loss: 0.999948] [G loss: 1.000074]\n",
      "epoch:22 step:103490[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:22 step:103495[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:22 step:103500[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:22 step:103505[D loss: 0.999937] [G loss: 1.000091]\n",
      "epoch:22 step:103510[D loss: 0.999950] [G loss: 1.000050]\n",
      "epoch:22 step:103515[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:22 step:103520[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:22 step:103525[D loss: 0.999930] [G loss: 1.000104]\n",
      "epoch:22 step:103530[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:22 step:103535[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:22 step:103540[D loss: 0.999968] [G loss: 1.000012]\n",
      "epoch:22 step:103545[D loss: 1.000026] [G loss: 0.999981]\n",
      "epoch:22 step:103550[D loss: 1.000102] [G loss: 0.999821]\n",
      "epoch:22 step:103555[D loss: 0.999986] [G loss: 1.000110]\n",
      "epoch:22 step:103560[D loss: 1.000082] [G loss: 0.999903]\n",
      "epoch:22 step:103565[D loss: 0.999930] [G loss: 1.000118]\n",
      "epoch:22 step:103570[D loss: 0.999932] [G loss: 1.000084]\n",
      "epoch:22 step:103575[D loss: 0.999948] [G loss: 1.000060]\n",
      "epoch:22 step:103580[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:22 step:103585[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:22 step:103590[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:22 step:103595[D loss: 1.000008] [G loss: 1.000014]\n",
      "epoch:22 step:103600[D loss: 0.999957] [G loss: 1.000065]\n",
      "##############\n",
      "[2.64124333 2.11821189 2.20781441 4.22096948 1.53606733 9.27426719\n",
      " 2.27994421 3.8803147  4.08227795 5.20178892]\n",
      "##########\n",
      "epoch:22 step:103605[D loss: 1.000065] [G loss: 0.999869]\n",
      "epoch:22 step:103610[D loss: 1.000019] [G loss: 0.999965]\n",
      "epoch:22 step:103615[D loss: 1.000033] [G loss: 0.999978]\n",
      "epoch:22 step:103620[D loss: 1.000010] [G loss: 0.999991]\n",
      "epoch:22 step:103625[D loss: 0.999888] [G loss: 1.000132]\n",
      "epoch:22 step:103630[D loss: 0.999942] [G loss: 1.000098]\n",
      "epoch:22 step:103635[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:22 step:103640[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:22 step:103645[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:22 step:103650[D loss: 0.999955] [G loss: 1.000033]\n",
      "epoch:22 step:103655[D loss: 1.000044] [G loss: 1.000024]\n",
      "epoch:22 step:103660[D loss: 1.000060] [G loss: 0.999965]\n",
      "epoch:22 step:103665[D loss: 0.999965] [G loss: 1.000226]\n",
      "epoch:22 step:103670[D loss: 0.999988] [G loss: 0.999992]\n",
      "epoch:22 step:103675[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:22 step:103680[D loss: 0.999951] [G loss: 1.000123]\n",
      "epoch:22 step:103685[D loss: 0.999950] [G loss: 1.000096]\n",
      "epoch:22 step:103690[D loss: 0.999976] [G loss: 1.000025]\n",
      "epoch:22 step:103695[D loss: 1.000071] [G loss: 0.999978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:103700[D loss: 0.999926] [G loss: 1.000054]\n",
      "epoch:22 step:103705[D loss: 1.000011] [G loss: 1.000002]\n",
      "epoch:22 step:103710[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:22 step:103715[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:22 step:103720[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:22 step:103725[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:22 step:103730[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:22 step:103735[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:22 step:103740[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:22 step:103745[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:22 step:103750[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:22 step:103755[D loss: 1.000016] [G loss: 1.000036]\n",
      "epoch:22 step:103760[D loss: 0.999959] [G loss: 1.000039]\n",
      "epoch:22 step:103765[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:22 step:103770[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:22 step:103775[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:22 step:103780[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:22 step:103785[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:22 step:103790[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:22 step:103795[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:22 step:103800[D loss: 0.999990] [G loss: 1.000018]\n",
      "##############\n",
      "[2.5611443  2.08822896 2.11871977 3.89858507 1.42914183 7.56895044\n",
      " 2.1659994  3.64859104 3.96166273 4.97232745]\n",
      "##########\n",
      "epoch:22 step:103805[D loss: 0.999938] [G loss: 1.000108]\n",
      "epoch:22 step:103810[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:22 step:103815[D loss: 1.000022] [G loss: 0.999955]\n",
      "epoch:22 step:103820[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:22 step:103825[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:22 step:103830[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:22 step:103835[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:22 step:103840[D loss: 0.999961] [G loss: 1.000122]\n",
      "epoch:22 step:103845[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:22 step:103850[D loss: 1.000003] [G loss: 1.000147]\n",
      "epoch:22 step:103855[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:22 step:103860[D loss: 0.999946] [G loss: 1.000110]\n",
      "epoch:22 step:103865[D loss: 0.999987] [G loss: 1.000013]\n",
      "epoch:22 step:103870[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:22 step:103875[D loss: 1.000022] [G loss: 1.000014]\n",
      "epoch:22 step:103880[D loss: 1.000003] [G loss: 1.000057]\n",
      "epoch:22 step:103885[D loss: 0.999955] [G loss: 1.000058]\n",
      "epoch:22 step:103890[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:22 step:103895[D loss: 1.000053] [G loss: 0.999948]\n",
      "epoch:22 step:103900[D loss: 0.999938] [G loss: 1.000153]\n",
      "epoch:22 step:103905[D loss: 0.999890] [G loss: 1.000150]\n",
      "epoch:22 step:103910[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:22 step:103915[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:22 step:103920[D loss: 1.000005] [G loss: 1.000012]\n",
      "epoch:22 step:103925[D loss: 1.000014] [G loss: 0.999988]\n",
      "epoch:22 step:103930[D loss: 0.999986] [G loss: 1.000000]\n",
      "epoch:22 step:103935[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:22 step:103940[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:22 step:103945[D loss: 0.999931] [G loss: 1.000126]\n",
      "epoch:22 step:103950[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:22 step:103955[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:22 step:103960[D loss: 1.000072] [G loss: 0.999958]\n",
      "epoch:22 step:103965[D loss: 1.000041] [G loss: 0.999977]\n",
      "epoch:22 step:103970[D loss: 0.999931] [G loss: 1.000091]\n",
      "epoch:22 step:103975[D loss: 1.000017] [G loss: 1.000043]\n",
      "epoch:22 step:103980[D loss: 0.999994] [G loss: 1.000134]\n",
      "epoch:22 step:103985[D loss: 0.999960] [G loss: 1.000105]\n",
      "epoch:22 step:103990[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:22 step:103995[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:22 step:104000[D loss: 0.999970] [G loss: 1.000039]\n",
      "##############\n",
      "[2.52473808 2.05589168 2.27327228 3.87620615 1.41821834 7.95927513\n",
      " 2.13038445 3.54509287 3.92155725 4.80387838]\n",
      "##########\n",
      "epoch:22 step:104005[D loss: 1.000019] [G loss: 0.999958]\n",
      "epoch:22 step:104010[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:22 step:104015[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:22 step:104020[D loss: 0.999976] [G loss: 1.000022]\n",
      "epoch:22 step:104025[D loss: 1.000041] [G loss: 0.999964]\n",
      "epoch:22 step:104030[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:22 step:104035[D loss: 1.000051] [G loss: 1.000088]\n",
      "epoch:22 step:104040[D loss: 0.999942] [G loss: 1.000065]\n",
      "epoch:22 step:104045[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:22 step:104050[D loss: 0.999962] [G loss: 1.000123]\n",
      "epoch:22 step:104055[D loss: 1.000019] [G loss: 1.000055]\n",
      "epoch:22 step:104060[D loss: 1.000091] [G loss: 0.999999]\n",
      "epoch:22 step:104065[D loss: 0.999889] [G loss: 1.000157]\n",
      "epoch:22 step:104070[D loss: 0.999950] [G loss: 1.000253]\n",
      "epoch:22 step:104075[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:22 step:104080[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:22 step:104085[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:22 step:104090[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:22 step:104095[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:22 step:104100[D loss: 0.999972] [G loss: 1.000023]\n",
      "epoch:22 step:104105[D loss: 1.000015] [G loss: 1.000014]\n",
      "epoch:22 step:104110[D loss: 0.999923] [G loss: 1.000042]\n",
      "epoch:22 step:104115[D loss: 1.000014] [G loss: 1.000042]\n",
      "epoch:22 step:104120[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:22 step:104125[D loss: 0.999947] [G loss: 1.000116]\n",
      "epoch:22 step:104130[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:22 step:104135[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:22 step:104140[D loss: 0.999950] [G loss: 1.000167]\n",
      "epoch:22 step:104145[D loss: 0.999991] [G loss: 1.000129]\n",
      "epoch:22 step:104150[D loss: 1.000049] [G loss: 1.000050]\n",
      "epoch:22 step:104155[D loss: 1.000114] [G loss: 1.000150]\n",
      "epoch:22 step:104160[D loss: 0.999924] [G loss: 1.000142]\n",
      "epoch:22 step:104165[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:22 step:104170[D loss: 1.000013] [G loss: 1.000038]\n",
      "epoch:22 step:104175[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:22 step:104180[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:22 step:104185[D loss: 1.000034] [G loss: 0.999957]\n",
      "epoch:22 step:104190[D loss: 0.999968] [G loss: 1.000024]\n",
      "epoch:22 step:104195[D loss: 1.000006] [G loss: 1.000111]\n",
      "epoch:22 step:104200[D loss: 1.000073] [G loss: 1.000121]\n",
      "##############\n",
      "[2.49124562 2.18291885 2.24775442 3.85429394 1.44647601 8.19292604\n",
      " 2.3357907  3.77878477 3.91979445 5.79459118]\n",
      "##########\n",
      "epoch:22 step:104205[D loss: 1.000041] [G loss: 1.000172]\n",
      "epoch:22 step:104210[D loss: 0.999909] [G loss: 1.000100]\n",
      "epoch:22 step:104215[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:22 step:104220[D loss: 1.000042] [G loss: 1.000035]\n",
      "epoch:22 step:104225[D loss: 1.000005] [G loss: 1.000075]\n",
      "epoch:22 step:104230[D loss: 0.999911] [G loss: 1.000187]\n",
      "epoch:22 step:104235[D loss: 1.000040] [G loss: 1.000074]\n",
      "epoch:22 step:104240[D loss: 0.999938] [G loss: 1.000226]\n",
      "epoch:22 step:104245[D loss: 0.999972] [G loss: 1.000189]\n",
      "epoch:22 step:104250[D loss: 0.999902] [G loss: 1.000166]\n",
      "epoch:22 step:104255[D loss: 0.999899] [G loss: 1.000242]\n",
      "epoch:22 step:104260[D loss: 0.999962] [G loss: 1.000010]\n",
      "epoch:22 step:104265[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:22 step:104270[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:22 step:104275[D loss: 1.000066] [G loss: 0.999972]\n",
      "epoch:22 step:104280[D loss: 0.999936] [G loss: 1.000100]\n",
      "epoch:22 step:104285[D loss: 0.999923] [G loss: 1.000128]\n",
      "epoch:22 step:104290[D loss: 1.000071] [G loss: 0.999939]\n",
      "epoch:22 step:104295[D loss: 1.000186] [G loss: 0.999632]\n",
      "epoch:22 step:104300[D loss: 1.000077] [G loss: 0.999848]\n",
      "epoch:22 step:104305[D loss: 0.999848] [G loss: 1.000232]\n",
      "epoch:22 step:104310[D loss: 1.000038] [G loss: 1.000067]\n",
      "epoch:22 step:104315[D loss: 0.999903] [G loss: 1.000218]\n",
      "epoch:22 step:104320[D loss: 0.999927] [G loss: 1.000149]\n",
      "epoch:22 step:104325[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:22 step:104330[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:22 step:104335[D loss: 0.999961] [G loss: 1.000116]\n",
      "epoch:22 step:104340[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:22 step:104345[D loss: 1.000031] [G loss: 1.000000]\n",
      "epoch:22 step:104350[D loss: 0.999939] [G loss: 1.000131]\n",
      "epoch:22 step:104355[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:22 step:104360[D loss: 1.000027] [G loss: 1.000031]\n",
      "epoch:22 step:104365[D loss: 0.999898] [G loss: 1.000148]\n",
      "epoch:22 step:104370[D loss: 1.000021] [G loss: 1.000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:104375[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:22 step:104380[D loss: 1.000000] [G loss: 1.000052]\n",
      "epoch:22 step:104385[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:22 step:104390[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:22 step:104395[D loss: 0.999965] [G loss: 1.000018]\n",
      "epoch:22 step:104400[D loss: 1.000023] [G loss: 1.000061]\n",
      "##############\n",
      "[2.46891394 2.05583422 2.33654418 3.8541423  1.3044286  7.98631328\n",
      " 2.15878223 3.67287395 4.00380504 5.85858156]\n",
      "##########\n",
      "epoch:22 step:104405[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:22 step:104410[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:22 step:104415[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:22 step:104420[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:22 step:104425[D loss: 0.999989] [G loss: 0.999994]\n",
      "epoch:22 step:104430[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:22 step:104435[D loss: 1.000030] [G loss: 1.000038]\n",
      "epoch:22 step:104440[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:22 step:104445[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:22 step:104450[D loss: 1.000020] [G loss: 0.999941]\n",
      "epoch:22 step:104455[D loss: 0.999954] [G loss: 1.000047]\n",
      "epoch:22 step:104460[D loss: 1.000048] [G loss: 0.999980]\n",
      "epoch:22 step:104465[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:22 step:104470[D loss: 0.999931] [G loss: 1.000125]\n",
      "epoch:22 step:104475[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:22 step:104480[D loss: 0.999979] [G loss: 1.000022]\n",
      "epoch:22 step:104485[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:22 step:104490[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:22 step:104495[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:22 step:104500[D loss: 0.999935] [G loss: 1.000093]\n",
      "epoch:22 step:104505[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:22 step:104510[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:22 step:104515[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:22 step:104520[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:22 step:104525[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:22 step:104530[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:22 step:104535[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:22 step:104540[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:22 step:104545[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:22 step:104550[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:22 step:104555[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:22 step:104560[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:22 step:104565[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:22 step:104570[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:22 step:104575[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:22 step:104580[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:22 step:104585[D loss: 1.000010] [G loss: 1.000028]\n",
      "epoch:22 step:104590[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:22 step:104595[D loss: 1.000003] [G loss: 1.000049]\n",
      "epoch:22 step:104600[D loss: 1.000026] [G loss: 0.999974]\n",
      "##############\n",
      "[2.46381951 2.09200517 2.1251763  3.7371656  1.3737697  7.60573722\n",
      " 2.31831268 3.61296702 3.86043542 7.14868929]\n",
      "##########\n",
      "epoch:22 step:104605[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:22 step:104610[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:22 step:104615[D loss: 1.000016] [G loss: 1.000002]\n",
      "epoch:22 step:104620[D loss: 0.999910] [G loss: 1.000153]\n",
      "epoch:22 step:104625[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:22 step:104630[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:22 step:104635[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:22 step:104640[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:22 step:104645[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:22 step:104650[D loss: 0.999995] [G loss: 1.000074]\n",
      "epoch:22 step:104655[D loss: 0.999961] [G loss: 1.000028]\n",
      "epoch:22 step:104660[D loss: 0.999969] [G loss: 1.000029]\n",
      "epoch:22 step:104665[D loss: 1.000014] [G loss: 0.999969]\n",
      "epoch:22 step:104670[D loss: 1.000003] [G loss: 1.000034]\n",
      "epoch:22 step:104675[D loss: 0.999974] [G loss: 1.000168]\n",
      "epoch:22 step:104680[D loss: 1.000093] [G loss: 0.999897]\n",
      "epoch:22 step:104685[D loss: 1.000058] [G loss: 0.999986]\n",
      "epoch:22 step:104690[D loss: 0.999810] [G loss: 1.000238]\n",
      "epoch:22 step:104695[D loss: 0.999944] [G loss: 1.000026]\n",
      "epoch:22 step:104700[D loss: 0.999943] [G loss: 1.000039]\n",
      "epoch:22 step:104705[D loss: 1.000023] [G loss: 0.999935]\n",
      "epoch:22 step:104710[D loss: 0.999905] [G loss: 1.000056]\n",
      "epoch:22 step:104715[D loss: 0.999994] [G loss: 1.000107]\n",
      "epoch:22 step:104720[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:22 step:104725[D loss: 0.999931] [G loss: 1.000100]\n",
      "epoch:22 step:104730[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:22 step:104735[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:22 step:104740[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:22 step:104745[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:22 step:104750[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:22 step:104755[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:22 step:104760[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:22 step:104765[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:22 step:104770[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:22 step:104775[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:22 step:104780[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:22 step:104785[D loss: 0.999984] [G loss: 1.000027]\n",
      "epoch:22 step:104790[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:22 step:104795[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:22 step:104800[D loss: 1.000038] [G loss: 1.000083]\n",
      "##############\n",
      "[2.5556175  2.09829865 2.23895147 3.92598153 1.38742135 6.97549692\n",
      " 2.27379431 3.78859027 3.98362493 5.16337036]\n",
      "##########\n",
      "epoch:22 step:104805[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:22 step:104810[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:22 step:104815[D loss: 1.000033] [G loss: 1.000042]\n",
      "epoch:22 step:104820[D loss: 0.999952] [G loss: 1.000074]\n",
      "epoch:22 step:104825[D loss: 1.000034] [G loss: 1.000041]\n",
      "epoch:22 step:104830[D loss: 1.000015] [G loss: 1.000045]\n",
      "epoch:22 step:104835[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:22 step:104840[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:22 step:104845[D loss: 1.000008] [G loss: 1.000026]\n",
      "epoch:22 step:104850[D loss: 1.000008] [G loss: 0.999935]\n",
      "epoch:22 step:104855[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:22 step:104860[D loss: 1.000081] [G loss: 1.000044]\n",
      "epoch:22 step:104865[D loss: 0.999937] [G loss: 1.000046]\n",
      "epoch:22 step:104870[D loss: 0.999982] [G loss: 1.000161]\n",
      "epoch:22 step:104875[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:22 step:104880[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:22 step:104885[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:22 step:104890[D loss: 1.000173] [G loss: 0.999772]\n",
      "epoch:22 step:104895[D loss: 0.999974] [G loss: 1.000129]\n",
      "epoch:22 step:104900[D loss: 0.999945] [G loss: 1.000101]\n",
      "epoch:22 step:104905[D loss: 0.999975] [G loss: 1.000221]\n",
      "epoch:22 step:104910[D loss: 1.000030] [G loss: 0.999988]\n",
      "epoch:22 step:104915[D loss: 0.999972] [G loss: 1.000100]\n",
      "epoch:22 step:104920[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:22 step:104925[D loss: 1.000005] [G loss: 1.000033]\n",
      "epoch:22 step:104930[D loss: 0.999980] [G loss: 1.000117]\n",
      "epoch:22 step:104935[D loss: 0.999938] [G loss: 1.000148]\n",
      "epoch:22 step:104940[D loss: 1.000124] [G loss: 1.000052]\n",
      "epoch:22 step:104945[D loss: 0.999917] [G loss: 1.000120]\n",
      "epoch:22 step:104950[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:22 step:104955[D loss: 1.000013] [G loss: 1.000018]\n",
      "epoch:22 step:104960[D loss: 1.000175] [G loss: 0.999850]\n",
      "epoch:22 step:104965[D loss: 1.000004] [G loss: 0.999971]\n",
      "epoch:22 step:104970[D loss: 0.999955] [G loss: 0.999983]\n",
      "epoch:22 step:104975[D loss: 1.000072] [G loss: 0.999893]\n",
      "epoch:22 step:104980[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:22 step:104985[D loss: 0.999955] [G loss: 1.000050]\n",
      "epoch:22 step:104990[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:22 step:104995[D loss: 0.999942] [G loss: 1.000057]\n",
      "epoch:22 step:105000[D loss: 0.999965] [G loss: 1.000101]\n",
      "##############\n",
      "[2.60024016 2.14645851 2.32897375 3.94133932 1.43410478 8.02891242\n",
      " 2.28055231 3.85141132 4.00723021 5.9259118 ]\n",
      "##########\n",
      "epoch:22 step:105005[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:22 step:105010[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:22 step:105015[D loss: 1.000025] [G loss: 1.000060]\n",
      "epoch:22 step:105020[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:22 step:105025[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:22 step:105030[D loss: 1.000035] [G loss: 0.999968]\n",
      "epoch:22 step:105035[D loss: 0.999943] [G loss: 1.000116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:105040[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:22 step:105045[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:22 step:105050[D loss: 1.000012] [G loss: 1.000066]\n",
      "epoch:22 step:105055[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:22 step:105060[D loss: 1.000018] [G loss: 0.999956]\n",
      "epoch:22 step:105065[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:22 step:105070[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:22 step:105075[D loss: 0.999961] [G loss: 1.000133]\n",
      "epoch:22 step:105080[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:22 step:105085[D loss: 0.999951] [G loss: 1.000125]\n",
      "epoch:22 step:105090[D loss: 0.999957] [G loss: 1.000115]\n",
      "epoch:22 step:105095[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:22 step:105100[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:22 step:105105[D loss: 0.999973] [G loss: 1.000114]\n",
      "epoch:22 step:105110[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:22 step:105115[D loss: 0.999961] [G loss: 1.000108]\n",
      "epoch:22 step:105120[D loss: 1.000056] [G loss: 1.000056]\n",
      "epoch:22 step:105125[D loss: 0.999984] [G loss: 1.000006]\n",
      "epoch:22 step:105130[D loss: 0.999994] [G loss: 1.000067]\n",
      "epoch:22 step:105135[D loss: 0.999973] [G loss: 1.000119]\n",
      "epoch:22 step:105140[D loss: 1.000015] [G loss: 1.000059]\n",
      "epoch:22 step:105145[D loss: 0.999904] [G loss: 1.000100]\n",
      "epoch:22 step:105150[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:22 step:105155[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:22 step:105160[D loss: 1.000003] [G loss: 1.000010]\n",
      "epoch:22 step:105165[D loss: 0.999950] [G loss: 1.000093]\n",
      "epoch:22 step:105170[D loss: 0.999930] [G loss: 1.000102]\n",
      "epoch:22 step:105175[D loss: 0.999961] [G loss: 1.000112]\n",
      "epoch:22 step:105180[D loss: 1.000045] [G loss: 1.000010]\n",
      "epoch:22 step:105185[D loss: 0.999985] [G loss: 1.000019]\n",
      "epoch:22 step:105190[D loss: 0.999995] [G loss: 1.000086]\n",
      "epoch:22 step:105195[D loss: 0.999957] [G loss: 1.000119]\n",
      "epoch:22 step:105200[D loss: 0.999983] [G loss: 1.000039]\n",
      "##############\n",
      "[2.5293723  2.10487805 2.16593799 3.56806273 1.39951957 7.31740856\n",
      " 2.30083054 3.77203314 3.92365306 4.63808634]\n",
      "##########\n",
      "epoch:22 step:105205[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:22 step:105210[D loss: 1.000006] [G loss: 1.000037]\n",
      "epoch:22 step:105215[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:22 step:105220[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:22 step:105225[D loss: 0.999952] [G loss: 1.000061]\n",
      "epoch:22 step:105230[D loss: 0.999985] [G loss: 1.000102]\n",
      "epoch:22 step:105235[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:22 step:105240[D loss: 0.999984] [G loss: 1.000091]\n",
      "epoch:22 step:105245[D loss: 1.000042] [G loss: 0.999967]\n",
      "epoch:22 step:105250[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:22 step:105255[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:22 step:105260[D loss: 1.000001] [G loss: 1.000043]\n",
      "epoch:22 step:105265[D loss: 0.999989] [G loss: 1.000030]\n",
      "epoch:22 step:105270[D loss: 0.999940] [G loss: 1.000126]\n",
      "epoch:22 step:105275[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:22 step:105280[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:22 step:105285[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:22 step:105290[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:22 step:105295[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:22 step:105300[D loss: 1.000037] [G loss: 1.000023]\n",
      "epoch:22 step:105305[D loss: 1.000078] [G loss: 0.999939]\n",
      "epoch:22 step:105310[D loss: 1.000046] [G loss: 1.000058]\n",
      "epoch:22 step:105315[D loss: 0.999927] [G loss: 1.000187]\n",
      "epoch:22 step:105320[D loss: 0.999989] [G loss: 1.000122]\n",
      "epoch:22 step:105325[D loss: 0.999999] [G loss: 1.000063]\n",
      "epoch:22 step:105330[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:22 step:105335[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:22 step:105340[D loss: 1.000029] [G loss: 0.999970]\n",
      "epoch:22 step:105345[D loss: 0.999951] [G loss: 1.000140]\n",
      "epoch:22 step:105350[D loss: 1.000025] [G loss: 0.999933]\n",
      "epoch:22 step:105355[D loss: 1.000105] [G loss: 0.999903]\n",
      "epoch:22 step:105360[D loss: 0.999918] [G loss: 1.000259]\n",
      "epoch:22 step:105365[D loss: 1.000175] [G loss: 1.000060]\n",
      "epoch:22 step:105370[D loss: 0.999926] [G loss: 1.000076]\n",
      "epoch:22 step:105375[D loss: 0.999801] [G loss: 1.000382]\n",
      "epoch:22 step:105380[D loss: 0.999925] [G loss: 1.000144]\n",
      "epoch:22 step:105385[D loss: 0.999925] [G loss: 1.000145]\n",
      "epoch:22 step:105390[D loss: 0.999989] [G loss: 1.000015]\n",
      "epoch:22 step:105395[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:22 step:105400[D loss: 0.999954] [G loss: 1.000068]\n",
      "##############\n",
      "[2.5967348  2.1615813  2.30890408 3.98703218 1.4468715  7.92883293\n",
      " 2.40565027 3.66120048 4.02049548 5.03492845]\n",
      "##########\n",
      "epoch:22 step:105405[D loss: 0.999944] [G loss: 1.000088]\n",
      "epoch:22 step:105410[D loss: 1.000090] [G loss: 0.999905]\n",
      "epoch:22 step:105415[D loss: 1.000220] [G loss: 0.999818]\n",
      "epoch:22 step:105420[D loss: 0.999937] [G loss: 1.000102]\n",
      "epoch:22 step:105425[D loss: 0.999961] [G loss: 1.000164]\n",
      "epoch:22 step:105430[D loss: 0.999914] [G loss: 1.000140]\n",
      "epoch:22 step:105435[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:22 step:105440[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:22 step:105445[D loss: 0.999938] [G loss: 1.000123]\n",
      "epoch:22 step:105450[D loss: 1.000018] [G loss: 1.000044]\n",
      "epoch:22 step:105455[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:22 step:105460[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:22 step:105465[D loss: 0.999947] [G loss: 1.000089]\n",
      "epoch:22 step:105470[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:22 step:105475[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:22 step:105480[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:22 step:105485[D loss: 1.000036] [G loss: 0.999944]\n",
      "epoch:22 step:105490[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:22 step:105495[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:22 step:105500[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:22 step:105505[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:22 step:105510[D loss: 0.999911] [G loss: 1.000120]\n",
      "epoch:22 step:105515[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:22 step:105520[D loss: 0.999962] [G loss: 1.000106]\n",
      "epoch:22 step:105525[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:22 step:105530[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:22 step:105535[D loss: 1.000081] [G loss: 0.999965]\n",
      "epoch:22 step:105540[D loss: 0.999880] [G loss: 1.000271]\n",
      "epoch:22 step:105545[D loss: 0.999958] [G loss: 1.000083]\n",
      "epoch:22 step:105550[D loss: 1.000074] [G loss: 1.000025]\n",
      "epoch:22 step:105555[D loss: 0.999976] [G loss: 1.000104]\n",
      "epoch:22 step:105560[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:22 step:105565[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:22 step:105570[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:22 step:105575[D loss: 0.999929] [G loss: 1.000066]\n",
      "epoch:22 step:105580[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:22 step:105585[D loss: 0.999927] [G loss: 1.000105]\n",
      "epoch:22 step:105590[D loss: 0.999966] [G loss: 1.000120]\n",
      "epoch:22 step:105595[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:22 step:105600[D loss: 0.999950] [G loss: 1.000076]\n",
      "##############\n",
      "[2.5299649  2.15971439 2.2583455  3.79493546 1.3969841  7.54863044\n",
      " 2.22678184 3.85500454 3.95081201 5.61872492]\n",
      "##########\n",
      "epoch:22 step:105605[D loss: 1.000033] [G loss: 0.999994]\n",
      "epoch:22 step:105610[D loss: 1.000010] [G loss: 1.000056]\n",
      "epoch:22 step:105615[D loss: 0.999873] [G loss: 1.000224]\n",
      "epoch:22 step:105620[D loss: 1.000164] [G loss: 0.999967]\n",
      "epoch:22 step:105625[D loss: 0.999944] [G loss: 1.000109]\n",
      "epoch:22 step:105630[D loss: 0.999903] [G loss: 1.000115]\n",
      "epoch:22 step:105635[D loss: 0.999997] [G loss: 1.000010]\n",
      "epoch:22 step:105640[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:22 step:105645[D loss: 1.000036] [G loss: 0.999908]\n",
      "epoch:22 step:105650[D loss: 0.999937] [G loss: 1.000100]\n",
      "epoch:22 step:105655[D loss: 1.000029] [G loss: 1.000075]\n",
      "epoch:22 step:105660[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:22 step:105665[D loss: 0.999940] [G loss: 1.000161]\n",
      "epoch:22 step:105670[D loss: 0.999969] [G loss: 1.000139]\n",
      "epoch:22 step:105675[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:22 step:105680[D loss: 0.999998] [G loss: 1.000041]\n",
      "epoch:22 step:105685[D loss: 1.000047] [G loss: 0.999923]\n",
      "epoch:22 step:105690[D loss: 0.999922] [G loss: 1.000108]\n",
      "epoch:22 step:105695[D loss: 1.000026] [G loss: 0.999982]\n",
      "epoch:22 step:105700[D loss: 1.000019] [G loss: 1.000002]\n",
      "epoch:22 step:105705[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:22 step:105710[D loss: 0.999952] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:105715[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:22 step:105720[D loss: 1.000025] [G loss: 1.000013]\n",
      "epoch:22 step:105725[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:22 step:105730[D loss: 0.999934] [G loss: 1.000077]\n",
      "epoch:22 step:105735[D loss: 0.999983] [G loss: 1.000005]\n",
      "epoch:22 step:105740[D loss: 1.000006] [G loss: 1.000097]\n",
      "epoch:22 step:105745[D loss: 0.999938] [G loss: 1.000078]\n",
      "epoch:22 step:105750[D loss: 1.000168] [G loss: 0.999911]\n",
      "epoch:22 step:105755[D loss: 0.999983] [G loss: 1.000106]\n",
      "epoch:22 step:105760[D loss: 0.999947] [G loss: 1.000181]\n",
      "epoch:22 step:105765[D loss: 1.000046] [G loss: 0.999975]\n",
      "epoch:22 step:105770[D loss: 0.999909] [G loss: 1.000177]\n",
      "epoch:22 step:105775[D loss: 1.000049] [G loss: 0.999979]\n",
      "epoch:22 step:105780[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:22 step:105785[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:22 step:105790[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:22 step:105795[D loss: 1.000110] [G loss: 0.999814]\n",
      "epoch:22 step:105800[D loss: 0.999968] [G loss: 1.000061]\n",
      "##############\n",
      "[2.57895557 2.08579053 2.17603234 3.89777863 1.42290858 8.20312094\n",
      " 2.28401661 3.78307971 3.96427468 5.86521945]\n",
      "##########\n",
      "epoch:22 step:105805[D loss: 0.999952] [G loss: 0.999982]\n",
      "epoch:22 step:105810[D loss: 1.000045] [G loss: 0.999881]\n",
      "epoch:22 step:105815[D loss: 1.000016] [G loss: 0.999953]\n",
      "epoch:22 step:105820[D loss: 0.999960] [G loss: 1.000119]\n",
      "epoch:22 step:105825[D loss: 0.999929] [G loss: 1.000072]\n",
      "epoch:22 step:105830[D loss: 1.000012] [G loss: 1.000058]\n",
      "epoch:22 step:105835[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:22 step:105840[D loss: 0.999958] [G loss: 1.000148]\n",
      "epoch:22 step:105845[D loss: 0.999946] [G loss: 1.000084]\n",
      "epoch:22 step:105850[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:22 step:105855[D loss: 0.999988] [G loss: 0.999993]\n",
      "epoch:22 step:105860[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:22 step:105865[D loss: 1.000061] [G loss: 0.999984]\n",
      "epoch:22 step:105870[D loss: 0.999975] [G loss: 1.000027]\n",
      "epoch:22 step:105875[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:22 step:105880[D loss: 0.999940] [G loss: 1.000051]\n",
      "epoch:22 step:105885[D loss: 0.999999] [G loss: 1.000103]\n",
      "epoch:22 step:105890[D loss: 0.999919] [G loss: 1.000125]\n",
      "epoch:22 step:105895[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:22 step:105900[D loss: 0.999937] [G loss: 1.000107]\n",
      "epoch:22 step:105905[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:22 step:105910[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:22 step:105915[D loss: 0.999987] [G loss: 1.000013]\n",
      "epoch:22 step:105920[D loss: 0.999956] [G loss: 1.000049]\n",
      "epoch:22 step:105925[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:22 step:105930[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:22 step:105935[D loss: 0.999940] [G loss: 1.000155]\n",
      "epoch:22 step:105940[D loss: 0.999929] [G loss: 1.000114]\n",
      "epoch:22 step:105945[D loss: 1.000043] [G loss: 1.000031]\n",
      "epoch:22 step:105950[D loss: 0.999956] [G loss: 1.000119]\n",
      "epoch:22 step:105955[D loss: 1.000001] [G loss: 1.000025]\n",
      "epoch:22 step:105960[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:22 step:105965[D loss: 1.000013] [G loss: 1.000040]\n",
      "epoch:22 step:105970[D loss: 1.000039] [G loss: 1.000070]\n",
      "epoch:22 step:105975[D loss: 0.999936] [G loss: 1.000056]\n",
      "epoch:22 step:105980[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:22 step:105985[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:22 step:105990[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:22 step:105995[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:22 step:106000[D loss: 0.999993] [G loss: 0.999999]\n",
      "##############\n",
      "[2.49736966 2.08242542 2.21643938 4.06213882 1.40222586 7.95430458\n",
      " 2.28918883 4.0172846  3.96284788 4.69910157]\n",
      "##########\n",
      "epoch:22 step:106005[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:22 step:106010[D loss: 1.000039] [G loss: 1.000015]\n",
      "epoch:22 step:106015[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:22 step:106020[D loss: 0.999945] [G loss: 1.000122]\n",
      "epoch:22 step:106025[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:22 step:106030[D loss: 1.000004] [G loss: 1.000017]\n",
      "epoch:22 step:106035[D loss: 1.000097] [G loss: 0.999948]\n",
      "epoch:22 step:106040[D loss: 1.000061] [G loss: 0.999876]\n",
      "epoch:22 step:106045[D loss: 0.999998] [G loss: 1.000145]\n",
      "epoch:22 step:106050[D loss: 1.000021] [G loss: 0.999938]\n",
      "epoch:22 step:106055[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:22 step:106060[D loss: 0.999983] [G loss: 0.999995]\n",
      "epoch:22 step:106065[D loss: 0.999939] [G loss: 1.000153]\n",
      "epoch:22 step:106070[D loss: 0.999938] [G loss: 1.000116]\n",
      "epoch:22 step:106075[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:22 step:106080[D loss: 1.000020] [G loss: 0.999962]\n",
      "epoch:22 step:106085[D loss: 0.999933] [G loss: 1.000070]\n",
      "epoch:22 step:106090[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:22 step:106095[D loss: 1.000015] [G loss: 0.999939]\n",
      "epoch:22 step:106100[D loss: 0.999943] [G loss: 1.000067]\n",
      "epoch:22 step:106105[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:22 step:106110[D loss: 1.000015] [G loss: 1.000000]\n",
      "epoch:22 step:106115[D loss: 1.000092] [G loss: 1.000058]\n",
      "epoch:22 step:106120[D loss: 0.999914] [G loss: 1.000118]\n",
      "epoch:22 step:106125[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:22 step:106130[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:22 step:106135[D loss: 0.999972] [G loss: 1.000033]\n",
      "epoch:22 step:106140[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:22 step:106145[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:22 step:106150[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:22 step:106155[D loss: 1.000050] [G loss: 1.000022]\n",
      "epoch:22 step:106160[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:22 step:106165[D loss: 0.999972] [G loss: 0.999960]\n",
      "epoch:22 step:106170[D loss: 1.000063] [G loss: 1.000004]\n",
      "epoch:22 step:106175[D loss: 0.999920] [G loss: 1.000111]\n",
      "epoch:22 step:106180[D loss: 1.000011] [G loss: 1.000076]\n",
      "epoch:22 step:106185[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:22 step:106190[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:22 step:106195[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:22 step:106200[D loss: 0.999977] [G loss: 1.000046]\n",
      "##############\n",
      "[2.58763695 2.20117488 2.36330196 4.167346   1.4785215  8.03807067\n",
      " 2.42495962 3.93579678 4.0861959  5.69517348]\n",
      "##########\n",
      "epoch:22 step:106205[D loss: 1.000008] [G loss: 0.999985]\n",
      "epoch:22 step:106210[D loss: 0.999986] [G loss: 1.000027]\n",
      "epoch:22 step:106215[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:22 step:106220[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:22 step:106225[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:22 step:106230[D loss: 1.000032] [G loss: 1.000040]\n",
      "epoch:22 step:106235[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:22 step:106240[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:22 step:106245[D loss: 1.000019] [G loss: 0.999991]\n",
      "epoch:22 step:106250[D loss: 0.999951] [G loss: 1.000029]\n",
      "epoch:22 step:106255[D loss: 0.999996] [G loss: 1.000096]\n",
      "epoch:22 step:106260[D loss: 0.999902] [G loss: 1.000065]\n",
      "epoch:22 step:106265[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:22 step:106270[D loss: 1.000007] [G loss: 1.000110]\n",
      "epoch:22 step:106275[D loss: 1.000010] [G loss: 0.999969]\n",
      "epoch:22 step:106280[D loss: 0.999934] [G loss: 1.000084]\n",
      "epoch:22 step:106285[D loss: 0.999975] [G loss: 1.000034]\n",
      "epoch:22 step:106290[D loss: 1.000004] [G loss: 0.999998]\n",
      "epoch:22 step:106295[D loss: 1.000021] [G loss: 0.999957]\n",
      "epoch:22 step:106300[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:22 step:106305[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:22 step:106310[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:22 step:106315[D loss: 1.000024] [G loss: 0.999982]\n",
      "epoch:22 step:106320[D loss: 0.999946] [G loss: 1.000094]\n",
      "epoch:22 step:106325[D loss: 1.000008] [G loss: 1.000063]\n",
      "epoch:22 step:106330[D loss: 0.999933] [G loss: 1.000099]\n",
      "epoch:22 step:106335[D loss: 1.000017] [G loss: 0.999979]\n",
      "epoch:22 step:106340[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:22 step:106345[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:22 step:106350[D loss: 1.000025] [G loss: 0.999966]\n",
      "epoch:22 step:106355[D loss: 0.999986] [G loss: 1.000118]\n",
      "epoch:22 step:106360[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:22 step:106365[D loss: 1.000018] [G loss: 0.999963]\n",
      "epoch:22 step:106370[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:22 step:106375[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:22 step:106380[D loss: 1.000156] [G loss: 0.999861]\n",
      "epoch:22 step:106385[D loss: 1.000019] [G loss: 1.000043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:106390[D loss: 0.999972] [G loss: 1.000008]\n",
      "epoch:22 step:106395[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:22 step:106400[D loss: 0.999981] [G loss: 1.000075]\n",
      "##############\n",
      "[2.44813166 2.08602682 2.14593689 3.74920695 1.36757134 7.51426911\n",
      " 2.27943867 3.48045181 3.909857   5.35740274]\n",
      "##########\n",
      "epoch:22 step:106405[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:22 step:106410[D loss: 1.000007] [G loss: 0.999989]\n",
      "epoch:22 step:106415[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:22 step:106420[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:22 step:106425[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:22 step:106430[D loss: 1.000012] [G loss: 0.999971]\n",
      "epoch:22 step:106435[D loss: 0.999943] [G loss: 1.000080]\n",
      "epoch:22 step:106440[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:22 step:106445[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:22 step:106450[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:22 step:106455[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:22 step:106460[D loss: 0.999943] [G loss: 1.000148]\n",
      "epoch:22 step:106465[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:22 step:106470[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:22 step:106475[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:22 step:106480[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:22 step:106485[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:22 step:106490[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:22 step:106495[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:22 step:106500[D loss: 1.000031] [G loss: 1.000044]\n",
      "epoch:22 step:106505[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:22 step:106510[D loss: 0.999979] [G loss: 1.000120]\n",
      "epoch:22 step:106515[D loss: 1.000048] [G loss: 1.000000]\n",
      "epoch:22 step:106520[D loss: 0.999901] [G loss: 1.000138]\n",
      "epoch:22 step:106525[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:22 step:106530[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:22 step:106535[D loss: 1.000027] [G loss: 1.000025]\n",
      "epoch:22 step:106540[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:22 step:106545[D loss: 1.000012] [G loss: 0.999956]\n",
      "epoch:22 step:106550[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:22 step:106555[D loss: 0.999984] [G loss: 1.000010]\n",
      "epoch:22 step:106560[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:22 step:106565[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:22 step:106570[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:22 step:106575[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:22 step:106580[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:22 step:106585[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:22 step:106590[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:22 step:106595[D loss: 1.000023] [G loss: 1.000065]\n",
      "epoch:22 step:106600[D loss: 0.999956] [G loss: 1.000111]\n",
      "##############\n",
      "[2.52327519 2.09813789 2.22168224 4.01127636 1.40641058 7.43249151\n",
      " 2.18867905 3.64648667 3.98811166 5.50907075]\n",
      "##########\n",
      "epoch:22 step:106605[D loss: 0.999968] [G loss: 1.000110]\n",
      "epoch:22 step:106610[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:22 step:106615[D loss: 1.000053] [G loss: 0.999961]\n",
      "epoch:22 step:106620[D loss: 1.000030] [G loss: 1.000036]\n",
      "epoch:22 step:106625[D loss: 1.000045] [G loss: 1.000028]\n",
      "epoch:22 step:106630[D loss: 1.000040] [G loss: 0.999874]\n",
      "epoch:22 step:106635[D loss: 0.999993] [G loss: 1.000055]\n",
      "epoch:22 step:106640[D loss: 1.000149] [G loss: 0.999910]\n",
      "epoch:22 step:106645[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:22 step:106650[D loss: 0.999932] [G loss: 1.000076]\n",
      "epoch:22 step:106655[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:22 step:106660[D loss: 1.000017] [G loss: 0.999957]\n",
      "epoch:22 step:106665[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:22 step:106670[D loss: 1.000008] [G loss: 1.000047]\n",
      "epoch:22 step:106675[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:22 step:106680[D loss: 1.000007] [G loss: 1.000072]\n",
      "epoch:22 step:106685[D loss: 1.000032] [G loss: 1.000063]\n",
      "epoch:22 step:106690[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:22 step:106695[D loss: 0.999964] [G loss: 1.000018]\n",
      "epoch:22 step:106700[D loss: 0.999985] [G loss: 0.999974]\n",
      "epoch:22 step:106705[D loss: 1.000005] [G loss: 1.000064]\n",
      "epoch:22 step:106710[D loss: 0.999971] [G loss: 1.000016]\n",
      "epoch:22 step:106715[D loss: 0.999982] [G loss: 1.000013]\n",
      "epoch:22 step:106720[D loss: 0.999951] [G loss: 1.000092]\n",
      "epoch:22 step:106725[D loss: 1.000018] [G loss: 1.000042]\n",
      "epoch:22 step:106730[D loss: 0.999994] [G loss: 1.000069]\n",
      "epoch:22 step:106735[D loss: 0.999932] [G loss: 1.000097]\n",
      "epoch:22 step:106740[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:22 step:106745[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:22 step:106750[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:22 step:106755[D loss: 1.000044] [G loss: 1.000079]\n",
      "epoch:22 step:106760[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:22 step:106765[D loss: 1.000088] [G loss: 1.000021]\n",
      "epoch:22 step:106770[D loss: 1.000010] [G loss: 1.000023]\n",
      "epoch:22 step:106775[D loss: 0.999967] [G loss: 1.000120]\n",
      "epoch:22 step:106780[D loss: 1.000105] [G loss: 1.000019]\n",
      "epoch:22 step:106785[D loss: 0.999873] [G loss: 1.000086]\n",
      "epoch:22 step:106790[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:22 step:106795[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:22 step:106800[D loss: 0.999974] [G loss: 1.000065]\n",
      "##############\n",
      "[2.58289066 2.097064   2.30326404 3.75728    1.37129112 8.48244327\n",
      " 2.28925016 3.86722281 4.04621049 4.88227955]\n",
      "##########\n",
      "epoch:22 step:106805[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:22 step:106810[D loss: 1.000065] [G loss: 0.999919]\n",
      "epoch:22 step:106815[D loss: 0.999960] [G loss: 1.000049]\n",
      "epoch:22 step:106820[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:22 step:106825[D loss: 0.999943] [G loss: 1.000099]\n",
      "epoch:22 step:106830[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:22 step:106835[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:22 step:106840[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:22 step:106845[D loss: 0.999963] [G loss: 1.000109]\n",
      "epoch:22 step:106850[D loss: 0.999943] [G loss: 1.000115]\n",
      "epoch:22 step:106855[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:22 step:106860[D loss: 1.000002] [G loss: 1.000120]\n",
      "epoch:22 step:106865[D loss: 0.999949] [G loss: 1.000082]\n",
      "epoch:22 step:106870[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:22 step:106875[D loss: 1.000032] [G loss: 0.999964]\n",
      "epoch:22 step:106880[D loss: 1.000057] [G loss: 0.999995]\n",
      "epoch:22 step:106885[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:22 step:106890[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:22 step:106895[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:22 step:106900[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:22 step:106905[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:22 step:106910[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:22 step:106915[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:22 step:106920[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:22 step:106925[D loss: 0.999943] [G loss: 1.000142]\n",
      "epoch:22 step:106930[D loss: 0.999990] [G loss: 1.000129]\n",
      "epoch:22 step:106935[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:22 step:106940[D loss: 1.000044] [G loss: 1.000062]\n",
      "epoch:22 step:106945[D loss: 0.999930] [G loss: 1.000089]\n",
      "epoch:22 step:106950[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:22 step:106955[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:22 step:106960[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:22 step:106965[D loss: 1.000116] [G loss: 0.999876]\n",
      "epoch:22 step:106970[D loss: 1.000076] [G loss: 0.999889]\n",
      "epoch:22 step:106975[D loss: 0.999914] [G loss: 1.000022]\n",
      "epoch:22 step:106980[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:22 step:106985[D loss: 0.999948] [G loss: 1.000179]\n",
      "epoch:22 step:106990[D loss: 0.999946] [G loss: 1.000126]\n",
      "epoch:22 step:106995[D loss: 0.999943] [G loss: 1.000122]\n",
      "epoch:22 step:107000[D loss: 0.999950] [G loss: 1.000163]\n",
      "##############\n",
      "[2.52653642 2.01366586 2.19514661 3.71123986 1.34924951 7.53136359\n",
      " 2.23264178 3.4593492  3.89012471 5.19974294]\n",
      "##########\n",
      "epoch:22 step:107005[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:22 step:107010[D loss: 0.999930] [G loss: 1.000146]\n",
      "epoch:22 step:107015[D loss: 0.999995] [G loss: 1.000117]\n",
      "epoch:22 step:107020[D loss: 0.999941] [G loss: 1.000065]\n",
      "epoch:22 step:107025[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:22 step:107030[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:22 step:107035[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:22 step:107040[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:22 step:107045[D loss: 1.000005] [G loss: 1.000033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:107050[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:22 step:107055[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:22 step:107060[D loss: 0.999966] [G loss: 1.000173]\n",
      "epoch:22 step:107065[D loss: 1.000027] [G loss: 0.999932]\n",
      "epoch:22 step:107070[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:22 step:107075[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:22 step:107080[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:22 step:107085[D loss: 1.000015] [G loss: 0.999995]\n",
      "epoch:22 step:107090[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:22 step:107095[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:22 step:107100[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:22 step:107105[D loss: 1.000057] [G loss: 0.999994]\n",
      "epoch:22 step:107110[D loss: 1.000061] [G loss: 1.000042]\n",
      "epoch:22 step:107115[D loss: 0.999896] [G loss: 1.000173]\n",
      "epoch:22 step:107120[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:22 step:107125[D loss: 0.999978] [G loss: 1.000116]\n",
      "epoch:22 step:107130[D loss: 0.999983] [G loss: 1.000095]\n",
      "epoch:22 step:107135[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:22 step:107140[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:22 step:107145[D loss: 0.999991] [G loss: 1.000022]\n",
      "epoch:22 step:107150[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:22 step:107155[D loss: 0.999929] [G loss: 1.000101]\n",
      "epoch:22 step:107160[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:22 step:107165[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:22 step:107170[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:22 step:107175[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:22 step:107180[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:22 step:107185[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:22 step:107190[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:22 step:107195[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:22 step:107200[D loss: 0.999965] [G loss: 1.000051]\n",
      "##############\n",
      "[2.54116132 2.17284606 2.32727754 3.96467746 1.47115243 7.29782554\n",
      " 2.3048732  3.82277558 3.99982358 5.32807131]\n",
      "##########\n",
      "epoch:22 step:107205[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:22 step:107210[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:22 step:107215[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:22 step:107220[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:22 step:107225[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:22 step:107230[D loss: 1.000047] [G loss: 0.999999]\n",
      "epoch:22 step:107235[D loss: 0.999946] [G loss: 1.000033]\n",
      "epoch:22 step:107240[D loss: 1.000199] [G loss: 0.999802]\n",
      "epoch:22 step:107245[D loss: 0.999942] [G loss: 1.000044]\n",
      "epoch:22 step:107250[D loss: 0.999992] [G loss: 1.000015]\n",
      "epoch:22 step:107255[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:22 step:107260[D loss: 0.999957] [G loss: 1.000099]\n",
      "epoch:22 step:107265[D loss: 1.000011] [G loss: 1.000060]\n",
      "epoch:22 step:107270[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:22 step:107275[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:22 step:107280[D loss: 1.000038] [G loss: 0.999945]\n",
      "epoch:22 step:107285[D loss: 1.000013] [G loss: 1.000033]\n",
      "epoch:22 step:107290[D loss: 1.000020] [G loss: 1.000041]\n",
      "epoch:22 step:107295[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:22 step:107300[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:22 step:107305[D loss: 1.000036] [G loss: 1.000038]\n",
      "epoch:22 step:107310[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:22 step:107315[D loss: 1.000047] [G loss: 1.000158]\n",
      "epoch:22 step:107320[D loss: 0.999909] [G loss: 1.000143]\n",
      "epoch:22 step:107325[D loss: 0.999960] [G loss: 1.000104]\n",
      "epoch:22 step:107330[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:22 step:107335[D loss: 1.000015] [G loss: 0.999965]\n",
      "epoch:22 step:107340[D loss: 0.999997] [G loss: 1.000007]\n",
      "epoch:22 step:107345[D loss: 1.000039] [G loss: 0.999899]\n",
      "epoch:22 step:107350[D loss: 1.000071] [G loss: 1.000094]\n",
      "epoch:22 step:107355[D loss: 0.999908] [G loss: 1.000105]\n",
      "epoch:22 step:107360[D loss: 0.999997] [G loss: 1.000012]\n",
      "epoch:22 step:107365[D loss: 1.000100] [G loss: 0.999917]\n",
      "epoch:22 step:107370[D loss: 0.999874] [G loss: 1.000135]\n",
      "epoch:22 step:107375[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:22 step:107380[D loss: 0.999925] [G loss: 1.000114]\n",
      "epoch:22 step:107385[D loss: 0.999954] [G loss: 1.000139]\n",
      "epoch:22 step:107390[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:22 step:107395[D loss: 1.000016] [G loss: 1.000066]\n",
      "epoch:22 step:107400[D loss: 0.999964] [G loss: 1.000074]\n",
      "##############\n",
      "[2.57100663 2.1031492  2.2450974  4.3051265  1.37023439 7.6670422\n",
      " 2.24452851 3.77360834 3.98309247 5.28750708]\n",
      "##########\n",
      "epoch:22 step:107405[D loss: 1.000037] [G loss: 1.000010]\n",
      "epoch:22 step:107410[D loss: 0.999994] [G loss: 1.000009]\n",
      "epoch:22 step:107415[D loss: 1.000050] [G loss: 0.999936]\n",
      "epoch:22 step:107420[D loss: 1.000034] [G loss: 1.000106]\n",
      "epoch:22 step:107425[D loss: 0.999936] [G loss: 1.000083]\n",
      "epoch:22 step:107430[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:22 step:107435[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:22 step:107440[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:22 step:107445[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:22 step:107450[D loss: 1.000022] [G loss: 0.999962]\n",
      "epoch:22 step:107455[D loss: 0.999918] [G loss: 1.000110]\n",
      "epoch:22 step:107460[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:22 step:107465[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:22 step:107470[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:22 step:107475[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:22 step:107480[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:22 step:107485[D loss: 1.000021] [G loss: 0.999990]\n",
      "epoch:22 step:107490[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:22 step:107495[D loss: 1.000024] [G loss: 1.000002]\n",
      "epoch:22 step:107500[D loss: 1.000002] [G loss: 0.999999]\n",
      "epoch:22 step:107505[D loss: 0.999950] [G loss: 1.000113]\n",
      "epoch:22 step:107510[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:22 step:107515[D loss: 0.999997] [G loss: 1.000098]\n",
      "epoch:22 step:107520[D loss: 1.000001] [G loss: 1.000001]\n",
      "epoch:22 step:107525[D loss: 1.000006] [G loss: 1.000006]\n",
      "epoch:22 step:107530[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:22 step:107535[D loss: 0.999989] [G loss: 1.000026]\n",
      "epoch:22 step:107540[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:22 step:107545[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:22 step:107550[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:22 step:107555[D loss: 0.999956] [G loss: 1.000071]\n",
      "epoch:22 step:107560[D loss: 0.999953] [G loss: 1.000092]\n",
      "epoch:22 step:107565[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:22 step:107570[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:22 step:107575[D loss: 1.000082] [G loss: 0.999917]\n",
      "epoch:22 step:107580[D loss: 0.999952] [G loss: 1.000072]\n",
      "epoch:22 step:107585[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:22 step:107590[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:22 step:107595[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:22 step:107600[D loss: 1.000023] [G loss: 1.000070]\n",
      "##############\n",
      "[2.53334596 2.05959239 2.28847092 3.78224702 1.42691608 7.71935665\n",
      " 2.17352646 3.89661677 3.89108063 5.7524161 ]\n",
      "##########\n",
      "epoch:22 step:107605[D loss: 0.999972] [G loss: 0.999995]\n",
      "epoch:22 step:107610[D loss: 1.000012] [G loss: 1.000039]\n",
      "epoch:22 step:107615[D loss: 0.999973] [G loss: 1.000018]\n",
      "epoch:22 step:107620[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:22 step:107625[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:22 step:107630[D loss: 0.999997] [G loss: 0.999998]\n",
      "epoch:22 step:107635[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:22 step:107640[D loss: 0.999946] [G loss: 1.000056]\n",
      "epoch:22 step:107645[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:22 step:107650[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:22 step:107655[D loss: 1.000100] [G loss: 0.999831]\n",
      "epoch:22 step:107660[D loss: 0.999883] [G loss: 1.000119]\n",
      "epoch:22 step:107665[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:22 step:107670[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:22 step:107675[D loss: 1.000045] [G loss: 0.999920]\n",
      "epoch:22 step:107680[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:22 step:107685[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:22 step:107690[D loss: 1.000022] [G loss: 0.999965]\n",
      "epoch:22 step:107695[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:22 step:107700[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:22 step:107705[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:22 step:107710[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:22 step:107715[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:22 step:107720[D loss: 0.999964] [G loss: 1.000070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:107725[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:22 step:107730[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:22 step:107735[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:22 step:107740[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:22 step:107745[D loss: 1.000003] [G loss: 1.000060]\n",
      "epoch:22 step:107750[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:22 step:107755[D loss: 1.000002] [G loss: 1.000024]\n",
      "epoch:23 step:107760[D loss: 1.000021] [G loss: 1.000055]\n",
      "epoch:23 step:107765[D loss: 0.999940] [G loss: 1.000090]\n",
      "epoch:23 step:107770[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:23 step:107775[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:23 step:107780[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:23 step:107785[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:23 step:107790[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:23 step:107795[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:23 step:107800[D loss: 1.000003] [G loss: 1.000074]\n",
      "##############\n",
      "[2.56542053 2.08574484 2.28614877 4.09375745 1.39828756 7.84881292\n",
      " 2.23583478 3.54238934 3.99974681 5.20517504]\n",
      "##########\n",
      "epoch:23 step:107805[D loss: 1.000069] [G loss: 0.999974]\n",
      "epoch:23 step:107810[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:23 step:107815[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:23 step:107820[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:23 step:107825[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:23 step:107830[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:23 step:107835[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:23 step:107840[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:23 step:107845[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:23 step:107850[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:23 step:107855[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:23 step:107860[D loss: 0.999986] [G loss: 1.000097]\n",
      "epoch:23 step:107865[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:23 step:107870[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:23 step:107875[D loss: 0.999949] [G loss: 1.000128]\n",
      "epoch:23 step:107880[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:23 step:107885[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:23 step:107890[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:23 step:107895[D loss: 0.999921] [G loss: 1.000120]\n",
      "epoch:23 step:107900[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:23 step:107905[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:23 step:107910[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:23 step:107915[D loss: 0.999954] [G loss: 1.000122]\n",
      "epoch:23 step:107920[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:23 step:107925[D loss: 1.000020] [G loss: 1.000084]\n",
      "epoch:23 step:107930[D loss: 0.999937] [G loss: 1.000135]\n",
      "epoch:23 step:107935[D loss: 1.000017] [G loss: 1.000056]\n",
      "epoch:23 step:107940[D loss: 0.999965] [G loss: 1.000132]\n",
      "epoch:23 step:107945[D loss: 0.999917] [G loss: 1.000132]\n",
      "epoch:23 step:107950[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:23 step:107955[D loss: 1.000066] [G loss: 0.999992]\n",
      "epoch:23 step:107960[D loss: 1.000026] [G loss: 0.999939]\n",
      "epoch:23 step:107965[D loss: 0.999900] [G loss: 1.000158]\n",
      "epoch:23 step:107970[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:23 step:107975[D loss: 0.999931] [G loss: 1.000106]\n",
      "epoch:23 step:107980[D loss: 0.999998] [G loss: 0.999982]\n",
      "epoch:23 step:107985[D loss: 0.999963] [G loss: 1.000046]\n",
      "epoch:23 step:107990[D loss: 1.000000] [G loss: 1.000008]\n",
      "epoch:23 step:107995[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:23 step:108000[D loss: 0.999977] [G loss: 1.000014]\n",
      "##############\n",
      "[2.55720067 2.13278143 2.24501401 3.75194798 1.41390752 7.52808765\n",
      " 2.4130338  3.68282727 3.98990153 5.37122749]\n",
      "##########\n",
      "epoch:23 step:108005[D loss: 0.999943] [G loss: 1.000087]\n",
      "epoch:23 step:108010[D loss: 1.000019] [G loss: 0.999989]\n",
      "epoch:23 step:108015[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:23 step:108020[D loss: 0.999930] [G loss: 1.000144]\n",
      "epoch:23 step:108025[D loss: 1.000025] [G loss: 1.000032]\n",
      "epoch:23 step:108030[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:23 step:108035[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:23 step:108040[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:23 step:108045[D loss: 1.000023] [G loss: 1.000062]\n",
      "epoch:23 step:108050[D loss: 0.999977] [G loss: 1.000129]\n",
      "epoch:23 step:108055[D loss: 0.999945] [G loss: 1.000121]\n",
      "epoch:23 step:108060[D loss: 0.999983] [G loss: 1.000088]\n",
      "epoch:23 step:108065[D loss: 1.000003] [G loss: 1.000041]\n",
      "epoch:23 step:108070[D loss: 1.000008] [G loss: 1.000044]\n",
      "epoch:23 step:108075[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:23 step:108080[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:23 step:108085[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:23 step:108090[D loss: 0.999983] [G loss: 1.000018]\n",
      "epoch:23 step:108095[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:23 step:108100[D loss: 1.000045] [G loss: 1.000018]\n",
      "epoch:23 step:108105[D loss: 0.999923] [G loss: 1.000121]\n",
      "epoch:23 step:108110[D loss: 0.999909] [G loss: 1.000199]\n",
      "epoch:23 step:108115[D loss: 1.000063] [G loss: 1.000056]\n",
      "epoch:23 step:108120[D loss: 0.999941] [G loss: 1.000109]\n",
      "epoch:23 step:108125[D loss: 0.999935] [G loss: 1.000044]\n",
      "epoch:23 step:108130[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:23 step:108135[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:23 step:108140[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:23 step:108145[D loss: 0.999957] [G loss: 1.000097]\n",
      "epoch:23 step:108150[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:23 step:108155[D loss: 0.999949] [G loss: 1.000122]\n",
      "epoch:23 step:108160[D loss: 0.999948] [G loss: 1.000140]\n",
      "epoch:23 step:108165[D loss: 0.999996] [G loss: 1.000014]\n",
      "epoch:23 step:108170[D loss: 0.999936] [G loss: 1.000096]\n",
      "epoch:23 step:108175[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:23 step:108180[D loss: 0.999993] [G loss: 0.999994]\n",
      "epoch:23 step:108185[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:23 step:108190[D loss: 0.999991] [G loss: 1.000024]\n",
      "epoch:23 step:108195[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:23 step:108200[D loss: 0.999998] [G loss: 1.000024]\n",
      "##############\n",
      "[2.57480095 2.11875586 2.25522845 3.93481366 1.45063839 8.06436411\n",
      " 2.34268747 3.73158742 3.99257813 5.61366298]\n",
      "##########\n",
      "epoch:23 step:108205[D loss: 1.000009] [G loss: 0.999953]\n",
      "epoch:23 step:108210[D loss: 0.999943] [G loss: 1.000050]\n",
      "epoch:23 step:108215[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:23 step:108220[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:23 step:108225[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:23 step:108230[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:23 step:108235[D loss: 1.000056] [G loss: 0.999978]\n",
      "epoch:23 step:108240[D loss: 1.000038] [G loss: 0.999965]\n",
      "epoch:23 step:108245[D loss: 1.000022] [G loss: 0.999995]\n",
      "epoch:23 step:108250[D loss: 0.999943] [G loss: 1.000131]\n",
      "epoch:23 step:108255[D loss: 0.999933] [G loss: 1.000132]\n",
      "epoch:23 step:108260[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:23 step:108265[D loss: 1.000004] [G loss: 1.000020]\n",
      "epoch:23 step:108270[D loss: 0.999976] [G loss: 1.000020]\n",
      "epoch:23 step:108275[D loss: 1.000023] [G loss: 0.999978]\n",
      "epoch:23 step:108280[D loss: 1.000017] [G loss: 0.999957]\n",
      "epoch:23 step:108285[D loss: 0.999968] [G loss: 1.000005]\n",
      "epoch:23 step:108290[D loss: 0.999954] [G loss: 1.000158]\n",
      "epoch:23 step:108295[D loss: 1.000041] [G loss: 0.999951]\n",
      "epoch:23 step:108300[D loss: 0.999945] [G loss: 1.000075]\n",
      "epoch:23 step:108305[D loss: 0.999957] [G loss: 1.000128]\n",
      "epoch:23 step:108310[D loss: 0.999924] [G loss: 1.000120]\n",
      "epoch:23 step:108315[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:23 step:108320[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:23 step:108325[D loss: 0.999927] [G loss: 1.000108]\n",
      "epoch:23 step:108330[D loss: 1.000000] [G loss: 1.000086]\n",
      "epoch:23 step:108335[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:23 step:108340[D loss: 1.000142] [G loss: 0.999833]\n",
      "epoch:23 step:108345[D loss: 1.000072] [G loss: 0.999988]\n",
      "epoch:23 step:108350[D loss: 1.000086] [G loss: 1.000027]\n",
      "epoch:23 step:108355[D loss: 0.999855] [G loss: 1.000298]\n",
      "epoch:23 step:108360[D loss: 1.000022] [G loss: 0.999997]\n",
      "epoch:23 step:108365[D loss: 0.999954] [G loss: 1.000143]\n",
      "epoch:23 step:108370[D loss: 0.999936] [G loss: 1.000140]\n",
      "epoch:23 step:108375[D loss: 0.999951] [G loss: 1.000119]\n",
      "epoch:23 step:108380[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:23 step:108385[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:23 step:108390[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:23 step:108395[D loss: 1.000003] [G loss: 1.000042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:108400[D loss: 0.999993] [G loss: 1.000011]\n",
      "##############\n",
      "[2.45685022 2.07926218 2.16478047 3.697698   1.33233136 8.00435494\n",
      " 2.24377711 3.59211773 3.89044641 5.21341198]\n",
      "##########\n",
      "epoch:23 step:108405[D loss: 0.999974] [G loss: 0.999981]\n",
      "epoch:23 step:108410[D loss: 0.999955] [G loss: 1.000098]\n",
      "epoch:23 step:108415[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:23 step:108420[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:23 step:108425[D loss: 1.000001] [G loss: 1.000045]\n",
      "epoch:23 step:108430[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:23 step:108435[D loss: 1.000011] [G loss: 1.000009]\n",
      "epoch:23 step:108440[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:23 step:108445[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:23 step:108450[D loss: 0.999950] [G loss: 1.000048]\n",
      "epoch:23 step:108455[D loss: 0.999955] [G loss: 1.000094]\n",
      "epoch:23 step:108460[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:23 step:108465[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:23 step:108470[D loss: 1.000001] [G loss: 1.000037]\n",
      "epoch:23 step:108475[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:23 step:108480[D loss: 0.999949] [G loss: 1.000059]\n",
      "epoch:23 step:108485[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:23 step:108490[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:23 step:108495[D loss: 0.999958] [G loss: 1.000058]\n",
      "epoch:23 step:108500[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:23 step:108505[D loss: 0.999956] [G loss: 1.000062]\n",
      "epoch:23 step:108510[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:23 step:108515[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:23 step:108520[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:23 step:108525[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:23 step:108530[D loss: 0.999935] [G loss: 1.000148]\n",
      "epoch:23 step:108535[D loss: 1.000013] [G loss: 1.000089]\n",
      "epoch:23 step:108540[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:23 step:108545[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:23 step:108550[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:23 step:108555[D loss: 0.999975] [G loss: 1.000005]\n",
      "epoch:23 step:108560[D loss: 1.000076] [G loss: 0.999954]\n",
      "epoch:23 step:108565[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:23 step:108570[D loss: 0.999921] [G loss: 1.000166]\n",
      "epoch:23 step:108575[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:23 step:108580[D loss: 0.999940] [G loss: 1.000073]\n",
      "epoch:23 step:108585[D loss: 1.000015] [G loss: 0.999968]\n",
      "epoch:23 step:108590[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:23 step:108595[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:23 step:108600[D loss: 0.999986] [G loss: 1.000053]\n",
      "##############\n",
      "[2.52417889 2.22190461 2.36450088 3.89384468 1.36158482 7.72592639\n",
      " 2.31484454 3.69891101 4.06551902 5.30039149]\n",
      "##########\n",
      "epoch:23 step:108605[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:23 step:108610[D loss: 1.000017] [G loss: 0.999984]\n",
      "epoch:23 step:108615[D loss: 0.999991] [G loss: 1.000011]\n",
      "epoch:23 step:108620[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:23 step:108625[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:23 step:108630[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:23 step:108635[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:23 step:108640[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:23 step:108645[D loss: 1.000001] [G loss: 1.000030]\n",
      "epoch:23 step:108650[D loss: 1.000064] [G loss: 0.999921]\n",
      "epoch:23 step:108655[D loss: 0.999974] [G loss: 0.999979]\n",
      "epoch:23 step:108660[D loss: 1.000013] [G loss: 1.000027]\n",
      "epoch:23 step:108665[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:23 step:108670[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:23 step:108675[D loss: 0.999961] [G loss: 1.000118]\n",
      "epoch:23 step:108680[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:23 step:108685[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:23 step:108690[D loss: 0.999976] [G loss: 1.000034]\n",
      "epoch:23 step:108695[D loss: 1.000025] [G loss: 1.000035]\n",
      "epoch:23 step:108700[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:23 step:108705[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:23 step:108710[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:23 step:108715[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:23 step:108720[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:23 step:108725[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:23 step:108730[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:23 step:108735[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:23 step:108740[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:23 step:108745[D loss: 1.000094] [G loss: 0.999953]\n",
      "epoch:23 step:108750[D loss: 0.999929] [G loss: 1.000094]\n",
      "epoch:23 step:108755[D loss: 1.000030] [G loss: 1.000026]\n",
      "epoch:23 step:108760[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:23 step:108765[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:23 step:108770[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:23 step:108775[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:23 step:108780[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:23 step:108785[D loss: 1.000035] [G loss: 0.999974]\n",
      "epoch:23 step:108790[D loss: 1.000031] [G loss: 0.999993]\n",
      "epoch:23 step:108795[D loss: 0.999922] [G loss: 1.000055]\n",
      "epoch:23 step:108800[D loss: 1.000010] [G loss: 1.000029]\n",
      "##############\n",
      "[2.50741785 2.11032062 2.13820143 3.9367036  1.29787606 9.27426719\n",
      " 2.1995209  3.64995367 3.88038609 5.15793856]\n",
      "##########\n",
      "epoch:23 step:108805[D loss: 1.000032] [G loss: 1.000029]\n",
      "epoch:23 step:108810[D loss: 0.999989] [G loss: 1.000000]\n",
      "epoch:23 step:108815[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:23 step:108820[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:23 step:108825[D loss: 0.999952] [G loss: 1.000127]\n",
      "epoch:23 step:108830[D loss: 0.999955] [G loss: 1.000129]\n",
      "epoch:23 step:108835[D loss: 0.999934] [G loss: 1.000184]\n",
      "epoch:23 step:108840[D loss: 1.000001] [G loss: 1.000258]\n",
      "epoch:23 step:108845[D loss: 1.000012] [G loss: 1.000028]\n",
      "epoch:23 step:108850[D loss: 0.999948] [G loss: 1.000045]\n",
      "epoch:23 step:108855[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:23 step:108860[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:23 step:108865[D loss: 1.000028] [G loss: 0.999960]\n",
      "epoch:23 step:108870[D loss: 1.000023] [G loss: 0.999966]\n",
      "epoch:23 step:108875[D loss: 0.999923] [G loss: 1.000083]\n",
      "epoch:23 step:108880[D loss: 0.999935] [G loss: 1.000213]\n",
      "epoch:23 step:108885[D loss: 1.000093] [G loss: 1.000034]\n",
      "epoch:23 step:108890[D loss: 0.999991] [G loss: 1.000224]\n",
      "epoch:23 step:108895[D loss: 0.999904] [G loss: 1.000146]\n",
      "epoch:23 step:108900[D loss: 0.999949] [G loss: 1.000133]\n",
      "epoch:23 step:108905[D loss: 0.999954] [G loss: 1.000191]\n",
      "epoch:23 step:108910[D loss: 1.000040] [G loss: 0.999981]\n",
      "epoch:23 step:108915[D loss: 0.999964] [G loss: 1.000115]\n",
      "epoch:23 step:108920[D loss: 1.000035] [G loss: 1.000049]\n",
      "epoch:23 step:108925[D loss: 0.999982] [G loss: 1.000135]\n",
      "epoch:23 step:108930[D loss: 0.999982] [G loss: 1.000102]\n",
      "epoch:23 step:108935[D loss: 0.999923] [G loss: 1.000109]\n",
      "epoch:23 step:108940[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:23 step:108945[D loss: 0.999963] [G loss: 1.000047]\n",
      "epoch:23 step:108950[D loss: 0.999993] [G loss: 0.999978]\n",
      "epoch:23 step:108955[D loss: 1.000116] [G loss: 0.999898]\n",
      "epoch:23 step:108960[D loss: 1.000096] [G loss: 0.999974]\n",
      "epoch:23 step:108965[D loss: 0.999913] [G loss: 1.000226]\n",
      "epoch:23 step:108970[D loss: 0.999942] [G loss: 1.000136]\n",
      "epoch:23 step:108975[D loss: 1.000039] [G loss: 1.000027]\n",
      "epoch:23 step:108980[D loss: 0.999965] [G loss: 1.000135]\n",
      "epoch:23 step:108985[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:23 step:108990[D loss: 0.999920] [G loss: 1.000112]\n",
      "epoch:23 step:108995[D loss: 1.000035] [G loss: 1.000048]\n",
      "epoch:23 step:109000[D loss: 0.999897] [G loss: 1.000168]\n",
      "##############\n",
      "[2.55736859 2.15775142 2.38175049 4.23055104 1.43300498 8.24067009\n",
      " 2.41732197 3.84357475 4.0457587  5.72860422]\n",
      "##########\n",
      "epoch:23 step:109005[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:23 step:109010[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:23 step:109015[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:23 step:109020[D loss: 1.000033] [G loss: 1.000005]\n",
      "epoch:23 step:109025[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:23 step:109030[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:23 step:109035[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:23 step:109040[D loss: 1.000013] [G loss: 0.999985]\n",
      "epoch:23 step:109045[D loss: 1.000022] [G loss: 1.000149]\n",
      "epoch:23 step:109050[D loss: 0.999950] [G loss: 1.000142]\n",
      "epoch:23 step:109055[D loss: 0.999987] [G loss: 1.000119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:109060[D loss: 0.999915] [G loss: 1.000126]\n",
      "epoch:23 step:109065[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:23 step:109070[D loss: 1.000078] [G loss: 0.999927]\n",
      "epoch:23 step:109075[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:23 step:109080[D loss: 0.999957] [G loss: 1.000061]\n",
      "epoch:23 step:109085[D loss: 1.000024] [G loss: 1.000076]\n",
      "epoch:23 step:109090[D loss: 0.999941] [G loss: 1.000099]\n",
      "epoch:23 step:109095[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:23 step:109100[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:23 step:109105[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:23 step:109110[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:23 step:109115[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:23 step:109120[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:23 step:109125[D loss: 0.999927] [G loss: 1.000100]\n",
      "epoch:23 step:109130[D loss: 1.000014] [G loss: 1.000020]\n",
      "epoch:23 step:109135[D loss: 0.999948] [G loss: 1.000125]\n",
      "epoch:23 step:109140[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:23 step:109145[D loss: 0.999976] [G loss: 1.000116]\n",
      "epoch:23 step:109150[D loss: 0.999917] [G loss: 1.000153]\n",
      "epoch:23 step:109155[D loss: 0.999923] [G loss: 1.000155]\n",
      "epoch:23 step:109160[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:23 step:109165[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:23 step:109170[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:23 step:109175[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:23 step:109180[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:23 step:109185[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:23 step:109190[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:23 step:109195[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:23 step:109200[D loss: 0.999981] [G loss: 1.000064]\n",
      "##############\n",
      "[2.52518316 2.14096339 2.27711588 3.83157479 1.49048463 8.00028729\n",
      " 2.46691719 3.77672127 4.03178815 4.75995668]\n",
      "##########\n",
      "epoch:23 step:109205[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:23 step:109210[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:23 step:109215[D loss: 1.000001] [G loss: 1.000015]\n",
      "epoch:23 step:109220[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:23 step:109225[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:23 step:109230[D loss: 1.000038] [G loss: 1.000010]\n",
      "epoch:23 step:109235[D loss: 1.000014] [G loss: 1.000018]\n",
      "epoch:23 step:109240[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:23 step:109245[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:23 step:109250[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:23 step:109255[D loss: 1.000019] [G loss: 0.999967]\n",
      "epoch:23 step:109260[D loss: 1.000016] [G loss: 0.999932]\n",
      "epoch:23 step:109265[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:23 step:109270[D loss: 1.000024] [G loss: 1.000046]\n",
      "epoch:23 step:109275[D loss: 0.999950] [G loss: 1.000052]\n",
      "epoch:23 step:109280[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:23 step:109285[D loss: 1.000010] [G loss: 1.000044]\n",
      "epoch:23 step:109290[D loss: 0.999953] [G loss: 1.000076]\n",
      "epoch:23 step:109295[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:23 step:109300[D loss: 1.000035] [G loss: 0.999986]\n",
      "epoch:23 step:109305[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:23 step:109310[D loss: 1.000017] [G loss: 1.000027]\n",
      "epoch:23 step:109315[D loss: 0.999901] [G loss: 1.000147]\n",
      "epoch:23 step:109320[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:23 step:109325[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:23 step:109330[D loss: 0.999984] [G loss: 1.000098]\n",
      "epoch:23 step:109335[D loss: 1.000041] [G loss: 1.000038]\n",
      "epoch:23 step:109340[D loss: 0.999968] [G loss: 1.000036]\n",
      "epoch:23 step:109345[D loss: 0.999976] [G loss: 1.000017]\n",
      "epoch:23 step:109350[D loss: 1.000019] [G loss: 0.999995]\n",
      "epoch:23 step:109355[D loss: 0.999942] [G loss: 1.000080]\n",
      "epoch:23 step:109360[D loss: 1.000125] [G loss: 0.999988]\n",
      "epoch:23 step:109365[D loss: 1.000089] [G loss: 0.999979]\n",
      "epoch:23 step:109370[D loss: 0.999949] [G loss: 1.000259]\n",
      "epoch:23 step:109375[D loss: 0.999992] [G loss: 0.999974]\n",
      "epoch:23 step:109380[D loss: 0.999951] [G loss: 1.000092]\n",
      "epoch:23 step:109385[D loss: 0.999978] [G loss: 1.000010]\n",
      "epoch:23 step:109390[D loss: 1.000023] [G loss: 1.000052]\n",
      "epoch:23 step:109395[D loss: 0.999950] [G loss: 1.000038]\n",
      "epoch:23 step:109400[D loss: 0.999968] [G loss: 1.000058]\n",
      "##############\n",
      "[2.54050009 2.06661428 2.2672116  3.95674517 1.44661717 7.24752211\n",
      " 2.28907726 3.77078657 4.06212517 5.74652822]\n",
      "##########\n",
      "epoch:23 step:109405[D loss: 1.000033] [G loss: 0.999983]\n",
      "epoch:23 step:109410[D loss: 0.999950] [G loss: 1.000073]\n",
      "epoch:23 step:109415[D loss: 0.999942] [G loss: 1.000110]\n",
      "epoch:23 step:109420[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:23 step:109425[D loss: 1.000022] [G loss: 1.000025]\n",
      "epoch:23 step:109430[D loss: 0.999949] [G loss: 1.000115]\n",
      "epoch:23 step:109435[D loss: 1.000037] [G loss: 0.999951]\n",
      "epoch:23 step:109440[D loss: 0.999919] [G loss: 1.000164]\n",
      "epoch:23 step:109445[D loss: 0.999951] [G loss: 1.000093]\n",
      "epoch:23 step:109450[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:23 step:109455[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:23 step:109460[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:23 step:109465[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:23 step:109470[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:23 step:109475[D loss: 1.000010] [G loss: 0.999977]\n",
      "epoch:23 step:109480[D loss: 0.999956] [G loss: 1.000053]\n",
      "epoch:23 step:109485[D loss: 1.000109] [G loss: 1.000052]\n",
      "epoch:23 step:109490[D loss: 0.999911] [G loss: 1.000084]\n",
      "epoch:23 step:109495[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:23 step:109500[D loss: 1.000049] [G loss: 1.000054]\n",
      "epoch:23 step:109505[D loss: 1.000007] [G loss: 0.999981]\n",
      "epoch:23 step:109510[D loss: 0.999968] [G loss: 1.000173]\n",
      "epoch:23 step:109515[D loss: 0.999967] [G loss: 1.000132]\n",
      "epoch:23 step:109520[D loss: 0.999950] [G loss: 1.000146]\n",
      "epoch:23 step:109525[D loss: 0.999973] [G loss: 1.000034]\n",
      "epoch:23 step:109530[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:23 step:109535[D loss: 0.999960] [G loss: 1.000044]\n",
      "epoch:23 step:109540[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:23 step:109545[D loss: 1.000027] [G loss: 1.000060]\n",
      "epoch:23 step:109550[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:23 step:109555[D loss: 1.000105] [G loss: 0.999911]\n",
      "epoch:23 step:109560[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:23 step:109565[D loss: 0.999954] [G loss: 1.000054]\n",
      "epoch:23 step:109570[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:23 step:109575[D loss: 1.000028] [G loss: 1.000050]\n",
      "epoch:23 step:109580[D loss: 1.000011] [G loss: 1.000029]\n",
      "epoch:23 step:109585[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:23 step:109590[D loss: 0.999996] [G loss: 1.000102]\n",
      "epoch:23 step:109595[D loss: 1.000066] [G loss: 1.000003]\n",
      "epoch:23 step:109600[D loss: 1.000106] [G loss: 0.999958]\n",
      "##############\n",
      "[2.55836057 2.14289962 2.27943364 3.87440875 1.40261531 7.48425989\n",
      " 2.32066542 3.45854791 3.96757386 5.13023721]\n",
      "##########\n",
      "epoch:23 step:109605[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:23 step:109610[D loss: 0.999945] [G loss: 1.000070]\n",
      "epoch:23 step:109615[D loss: 0.999959] [G loss: 1.000097]\n",
      "epoch:23 step:109620[D loss: 1.000028] [G loss: 0.999987]\n",
      "epoch:23 step:109625[D loss: 0.999955] [G loss: 1.000098]\n",
      "epoch:23 step:109630[D loss: 1.000018] [G loss: 1.000030]\n",
      "epoch:23 step:109635[D loss: 1.000003] [G loss: 0.999995]\n",
      "epoch:23 step:109640[D loss: 1.000040] [G loss: 0.999989]\n",
      "epoch:23 step:109645[D loss: 1.000135] [G loss: 0.999957]\n",
      "epoch:23 step:109650[D loss: 1.000002] [G loss: 0.999951]\n",
      "epoch:23 step:109655[D loss: 0.999878] [G loss: 1.000106]\n",
      "epoch:23 step:109660[D loss: 0.999962] [G loss: 0.999938]\n",
      "epoch:23 step:109665[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:23 step:109670[D loss: 0.999942] [G loss: 1.000076]\n",
      "epoch:23 step:109675[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:23 step:109680[D loss: 1.000021] [G loss: 1.000026]\n",
      "epoch:23 step:109685[D loss: 0.999946] [G loss: 1.000048]\n",
      "epoch:23 step:109690[D loss: 1.000103] [G loss: 0.999955]\n",
      "epoch:23 step:109695[D loss: 0.999809] [G loss: 1.000285]\n",
      "epoch:23 step:109700[D loss: 0.999921] [G loss: 1.000061]\n",
      "epoch:23 step:109705[D loss: 1.000000] [G loss: 1.000148]\n",
      "epoch:23 step:109710[D loss: 0.999941] [G loss: 1.000073]\n",
      "epoch:23 step:109715[D loss: 0.999983] [G loss: 1.000091]\n",
      "epoch:23 step:109720[D loss: 0.999922] [G loss: 1.000140]\n",
      "epoch:23 step:109725[D loss: 0.999943] [G loss: 1.000117]\n",
      "epoch:23 step:109730[D loss: 0.999977] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:109735[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:23 step:109740[D loss: 1.000035] [G loss: 0.999964]\n",
      "epoch:23 step:109745[D loss: 1.000003] [G loss: 0.999971]\n",
      "epoch:23 step:109750[D loss: 1.000054] [G loss: 0.999918]\n",
      "epoch:23 step:109755[D loss: 1.000040] [G loss: 0.999893]\n",
      "epoch:23 step:109760[D loss: 0.999915] [G loss: 1.000230]\n",
      "epoch:23 step:109765[D loss: 1.000032] [G loss: 1.000000]\n",
      "epoch:23 step:109770[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:23 step:109775[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:23 step:109780[D loss: 0.999946] [G loss: 1.000055]\n",
      "epoch:23 step:109785[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:23 step:109790[D loss: 1.000014] [G loss: 1.000035]\n",
      "epoch:23 step:109795[D loss: 0.999974] [G loss: 1.000034]\n",
      "epoch:23 step:109800[D loss: 0.999983] [G loss: 1.000066]\n",
      "##############\n",
      "[2.46978174 2.06763705 2.19151855 3.68387908 1.35411158 7.44154716\n",
      " 2.40651968 3.74902181 3.97934817 5.82480136]\n",
      "##########\n",
      "epoch:23 step:109805[D loss: 1.000162] [G loss: 0.999895]\n",
      "epoch:23 step:109810[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:23 step:109815[D loss: 1.000010] [G loss: 1.000040]\n",
      "epoch:23 step:109820[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:23 step:109825[D loss: 0.999999] [G loss: 1.000054]\n",
      "epoch:23 step:109830[D loss: 1.000059] [G loss: 0.999989]\n",
      "epoch:23 step:109835[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:23 step:109840[D loss: 0.999948] [G loss: 1.000108]\n",
      "epoch:23 step:109845[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:23 step:109850[D loss: 0.999942] [G loss: 1.000077]\n",
      "epoch:23 step:109855[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:23 step:109860[D loss: 1.000011] [G loss: 1.000073]\n",
      "epoch:23 step:109865[D loss: 0.999975] [G loss: 1.000120]\n",
      "epoch:23 step:109870[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:23 step:109875[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:23 step:109880[D loss: 0.999942] [G loss: 1.000109]\n",
      "epoch:23 step:109885[D loss: 0.999999] [G loss: 0.999983]\n",
      "epoch:23 step:109890[D loss: 1.000038] [G loss: 0.999956]\n",
      "epoch:23 step:109895[D loss: 0.999969] [G loss: 1.000119]\n",
      "epoch:23 step:109900[D loss: 0.999948] [G loss: 1.000107]\n",
      "epoch:23 step:109905[D loss: 0.999940] [G loss: 1.000077]\n",
      "epoch:23 step:109910[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:23 step:109915[D loss: 1.000003] [G loss: 1.000077]\n",
      "epoch:23 step:109920[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:23 step:109925[D loss: 1.000037] [G loss: 1.000016]\n",
      "epoch:23 step:109930[D loss: 0.999933] [G loss: 1.000152]\n",
      "epoch:23 step:109935[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:23 step:109940[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:23 step:109945[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:23 step:109950[D loss: 0.999959] [G loss: 1.000024]\n",
      "epoch:23 step:109955[D loss: 0.999975] [G loss: 1.000108]\n",
      "epoch:23 step:109960[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:23 step:109965[D loss: 0.999962] [G loss: 1.000128]\n",
      "epoch:23 step:109970[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:23 step:109975[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:23 step:109980[D loss: 0.999968] [G loss: 1.000103]\n",
      "epoch:23 step:109985[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:23 step:109990[D loss: 1.000070] [G loss: 1.000002]\n",
      "epoch:23 step:109995[D loss: 0.999961] [G loss: 1.000129]\n",
      "epoch:23 step:110000[D loss: 0.999966] [G loss: 1.000106]\n",
      "##############\n",
      "[2.5342202  1.94007871 2.2142618  3.65506689 1.30539327 7.64774497\n",
      " 2.06442631 3.80548669 3.85599101 5.2440404 ]\n",
      "##########\n",
      "epoch:23 step:110005[D loss: 0.999941] [G loss: 1.000164]\n",
      "epoch:23 step:110010[D loss: 1.000011] [G loss: 1.000024]\n",
      "epoch:23 step:110015[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:23 step:110020[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:23 step:110025[D loss: 1.000048] [G loss: 0.999931]\n",
      "epoch:23 step:110030[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:23 step:110035[D loss: 0.999966] [G loss: 1.000113]\n",
      "epoch:23 step:110040[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:23 step:110045[D loss: 0.999991] [G loss: 1.000117]\n",
      "epoch:23 step:110050[D loss: 1.000206] [G loss: 0.999958]\n",
      "epoch:23 step:110055[D loss: 0.999994] [G loss: 0.999913]\n",
      "epoch:23 step:110060[D loss: 0.999897] [G loss: 1.000165]\n",
      "epoch:23 step:110065[D loss: 0.999894] [G loss: 1.000151]\n",
      "epoch:23 step:110070[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:23 step:110075[D loss: 1.000059] [G loss: 0.999846]\n",
      "epoch:23 step:110080[D loss: 1.000058] [G loss: 0.999872]\n",
      "epoch:23 step:110085[D loss: 0.999977] [G loss: 1.000018]\n",
      "epoch:23 step:110090[D loss: 0.999936] [G loss: 1.000093]\n",
      "epoch:23 step:110095[D loss: 1.000041] [G loss: 1.000079]\n",
      "epoch:23 step:110100[D loss: 1.000131] [G loss: 1.000008]\n",
      "epoch:23 step:110105[D loss: 0.999905] [G loss: 1.000103]\n",
      "epoch:23 step:110110[D loss: 1.000037] [G loss: 1.000030]\n",
      "epoch:23 step:110115[D loss: 0.999921] [G loss: 1.000146]\n",
      "epoch:23 step:110120[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:23 step:110125[D loss: 0.999954] [G loss: 1.000092]\n",
      "epoch:23 step:110130[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:23 step:110135[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:23 step:110140[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:23 step:110145[D loss: 0.999990] [G loss: 1.000076]\n",
      "epoch:23 step:110150[D loss: 0.999993] [G loss: 1.000005]\n",
      "epoch:23 step:110155[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:23 step:110160[D loss: 1.000001] [G loss: 1.000112]\n",
      "epoch:23 step:110165[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:23 step:110170[D loss: 1.000016] [G loss: 0.999994]\n",
      "epoch:23 step:110175[D loss: 0.999949] [G loss: 1.000077]\n",
      "epoch:23 step:110180[D loss: 1.000013] [G loss: 1.000055]\n",
      "epoch:23 step:110185[D loss: 0.999993] [G loss: 1.000004]\n",
      "epoch:23 step:110190[D loss: 1.000026] [G loss: 1.000036]\n",
      "epoch:23 step:110195[D loss: 1.000015] [G loss: 1.000015]\n",
      "epoch:23 step:110200[D loss: 1.000030] [G loss: 1.000030]\n",
      "##############\n",
      "[2.65411792 2.1285018  2.23706266 3.85559634 1.37661634 8.49218839\n",
      " 2.33689919 3.70309836 4.05101506 5.46982407]\n",
      "##########\n",
      "epoch:23 step:110205[D loss: 0.999999] [G loss: 1.000142]\n",
      "epoch:23 step:110210[D loss: 0.999946] [G loss: 1.000148]\n",
      "epoch:23 step:110215[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:23 step:110220[D loss: 1.000134] [G loss: 0.999943]\n",
      "epoch:23 step:110225[D loss: 1.000022] [G loss: 1.000162]\n",
      "epoch:23 step:110230[D loss: 0.999871] [G loss: 1.000175]\n",
      "epoch:23 step:110235[D loss: 1.000218] [G loss: 0.999944]\n",
      "epoch:23 step:110240[D loss: 1.000053] [G loss: 1.000030]\n",
      "epoch:23 step:110245[D loss: 0.999897] [G loss: 1.000124]\n",
      "epoch:23 step:110250[D loss: 1.000011] [G loss: 1.000006]\n",
      "epoch:23 step:110255[D loss: 0.999995] [G loss: 1.000093]\n",
      "epoch:23 step:110260[D loss: 0.999924] [G loss: 1.000071]\n",
      "epoch:23 step:110265[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:23 step:110270[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:23 step:110275[D loss: 1.000014] [G loss: 1.000007]\n",
      "epoch:23 step:110280[D loss: 0.999910] [G loss: 1.000159]\n",
      "epoch:23 step:110285[D loss: 0.999969] [G loss: 1.000040]\n",
      "epoch:23 step:110290[D loss: 1.000134] [G loss: 0.999903]\n",
      "epoch:23 step:110295[D loss: 1.000068] [G loss: 1.000065]\n",
      "epoch:23 step:110300[D loss: 0.999896] [G loss: 1.000209]\n",
      "epoch:23 step:110305[D loss: 1.000177] [G loss: 1.000072]\n",
      "epoch:23 step:110310[D loss: 0.999993] [G loss: 0.999995]\n",
      "epoch:23 step:110315[D loss: 0.999873] [G loss: 1.000245]\n",
      "epoch:23 step:110320[D loss: 0.999890] [G loss: 1.000118]\n",
      "epoch:23 step:110325[D loss: 0.999888] [G loss: 1.000154]\n",
      "epoch:23 step:110330[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:23 step:110335[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:23 step:110340[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:23 step:110345[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:23 step:110350[D loss: 0.999986] [G loss: 1.000006]\n",
      "epoch:23 step:110355[D loss: 1.000012] [G loss: 1.000062]\n",
      "epoch:23 step:110360[D loss: 1.000087] [G loss: 0.999846]\n",
      "epoch:23 step:110365[D loss: 0.999910] [G loss: 1.000127]\n",
      "epoch:23 step:110370[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:23 step:110375[D loss: 0.999993] [G loss: 1.000147]\n",
      "epoch:23 step:110380[D loss: 0.999900] [G loss: 1.000133]\n",
      "epoch:23 step:110385[D loss: 0.999949] [G loss: 1.000121]\n",
      "epoch:23 step:110390[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:23 step:110395[D loss: 0.999951] [G loss: 1.000113]\n",
      "epoch:23 step:110400[D loss: 0.999981] [G loss: 1.000046]\n",
      "##############\n",
      "[2.53670084 2.19531269 2.0959615  3.73249579 1.33011123 7.82497382\n",
      " 2.0709516  3.61039206 3.91269423 7.14868929]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:110405[D loss: 1.000029] [G loss: 1.000058]\n",
      "epoch:23 step:110410[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:23 step:110415[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:23 step:110420[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:23 step:110425[D loss: 0.999997] [G loss: 1.000072]\n",
      "epoch:23 step:110430[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:23 step:110435[D loss: 0.999995] [G loss: 1.000089]\n",
      "epoch:23 step:110440[D loss: 1.000018] [G loss: 1.000046]\n",
      "epoch:23 step:110445[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:23 step:110450[D loss: 1.000004] [G loss: 1.000077]\n",
      "epoch:23 step:110455[D loss: 0.999926] [G loss: 1.000100]\n",
      "epoch:23 step:110460[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:23 step:110465[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:23 step:110470[D loss: 1.000002] [G loss: 1.000054]\n",
      "epoch:23 step:110475[D loss: 1.000048] [G loss: 0.999982]\n",
      "epoch:23 step:110480[D loss: 1.000059] [G loss: 0.999922]\n",
      "epoch:23 step:110485[D loss: 0.999914] [G loss: 1.000183]\n",
      "epoch:23 step:110490[D loss: 0.999912] [G loss: 1.000128]\n",
      "epoch:23 step:110495[D loss: 0.999963] [G loss: 1.000107]\n",
      "epoch:23 step:110500[D loss: 1.000019] [G loss: 1.000010]\n",
      "epoch:23 step:110505[D loss: 1.000000] [G loss: 1.000089]\n",
      "epoch:23 step:110510[D loss: 0.999994] [G loss: 1.000097]\n",
      "epoch:23 step:110515[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:23 step:110520[D loss: 1.000048] [G loss: 1.000005]\n",
      "epoch:23 step:110525[D loss: 0.999933] [G loss: 1.000056]\n",
      "epoch:23 step:110530[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:23 step:110535[D loss: 1.000043] [G loss: 1.000019]\n",
      "epoch:23 step:110540[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:23 step:110545[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:23 step:110550[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:23 step:110555[D loss: 1.000006] [G loss: 1.000002]\n",
      "epoch:23 step:110560[D loss: 0.999963] [G loss: 1.000127]\n",
      "epoch:23 step:110565[D loss: 0.999953] [G loss: 1.000094]\n",
      "epoch:23 step:110570[D loss: 1.000030] [G loss: 1.000096]\n",
      "epoch:23 step:110575[D loss: 0.999935] [G loss: 1.000116]\n",
      "epoch:23 step:110580[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:23 step:110585[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:23 step:110590[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:23 step:110595[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:23 step:110600[D loss: 0.999956] [G loss: 1.000100]\n",
      "##############\n",
      "[2.46294483 2.04866858 2.21882041 3.84601364 1.32905576 7.46791669\n",
      " 2.39058523 3.74689205 3.91935379 5.71251309]\n",
      "##########\n",
      "epoch:23 step:110605[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:23 step:110610[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:23 step:110615[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:23 step:110620[D loss: 1.000047] [G loss: 1.000004]\n",
      "epoch:23 step:110625[D loss: 0.999956] [G loss: 1.000117]\n",
      "epoch:23 step:110630[D loss: 1.000091] [G loss: 0.999925]\n",
      "epoch:23 step:110635[D loss: 0.999976] [G loss: 1.000123]\n",
      "epoch:23 step:110640[D loss: 0.999884] [G loss: 1.000142]\n",
      "epoch:23 step:110645[D loss: 1.000020] [G loss: 1.000126]\n",
      "epoch:23 step:110650[D loss: 0.999973] [G loss: 1.000122]\n",
      "epoch:23 step:110655[D loss: 0.999995] [G loss: 1.000174]\n",
      "epoch:23 step:110660[D loss: 0.999898] [G loss: 1.000153]\n",
      "epoch:23 step:110665[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:23 step:110670[D loss: 0.999955] [G loss: 1.000116]\n",
      "epoch:23 step:110675[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:23 step:110680[D loss: 0.999968] [G loss: 1.000028]\n",
      "epoch:23 step:110685[D loss: 1.000012] [G loss: 0.999943]\n",
      "epoch:23 step:110690[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:23 step:110695[D loss: 1.000057] [G loss: 0.999995]\n",
      "epoch:23 step:110700[D loss: 1.000122] [G loss: 1.000003]\n",
      "epoch:23 step:110705[D loss: 0.999940] [G loss: 1.000128]\n",
      "epoch:23 step:110710[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:23 step:110715[D loss: 1.000004] [G loss: 0.999982]\n",
      "epoch:23 step:110720[D loss: 1.000061] [G loss: 0.999947]\n",
      "epoch:23 step:110725[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:23 step:110730[D loss: 1.000126] [G loss: 1.000000]\n",
      "epoch:23 step:110735[D loss: 0.999985] [G loss: 1.000114]\n",
      "epoch:23 step:110740[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:23 step:110745[D loss: 0.999944] [G loss: 1.000137]\n",
      "epoch:23 step:110750[D loss: 0.999965] [G loss: 1.000109]\n",
      "epoch:23 step:110755[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:23 step:110760[D loss: 1.000008] [G loss: 1.000023]\n",
      "epoch:23 step:110765[D loss: 1.000042] [G loss: 0.999996]\n",
      "epoch:23 step:110770[D loss: 0.999939] [G loss: 1.000049]\n",
      "epoch:23 step:110775[D loss: 1.000022] [G loss: 1.000007]\n",
      "epoch:23 step:110780[D loss: 0.999995] [G loss: 0.999972]\n",
      "epoch:23 step:110785[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:23 step:110790[D loss: 1.000028] [G loss: 0.999956]\n",
      "epoch:23 step:110795[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:23 step:110800[D loss: 1.000076] [G loss: 1.000067]\n",
      "##############\n",
      "[2.4329481  1.94228084 2.11544386 4.04779453 1.28851585 7.91436576\n",
      " 2.08228125 3.76070938 3.85195906 5.46020139]\n",
      "##########\n",
      "epoch:23 step:110805[D loss: 0.999904] [G loss: 1.000088]\n",
      "epoch:23 step:110810[D loss: 1.000000] [G loss: 1.000056]\n",
      "epoch:23 step:110815[D loss: 1.000001] [G loss: 1.000045]\n",
      "epoch:23 step:110820[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:23 step:110825[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:23 step:110830[D loss: 1.000009] [G loss: 0.999986]\n",
      "epoch:23 step:110835[D loss: 0.999935] [G loss: 1.000124]\n",
      "epoch:23 step:110840[D loss: 1.000032] [G loss: 1.000151]\n",
      "epoch:23 step:110845[D loss: 1.000092] [G loss: 0.999938]\n",
      "epoch:23 step:110850[D loss: 0.999877] [G loss: 1.000098]\n",
      "epoch:23 step:110855[D loss: 1.000042] [G loss: 1.000087]\n",
      "epoch:23 step:110860[D loss: 0.999905] [G loss: 1.000162]\n",
      "epoch:23 step:110865[D loss: 0.999988] [G loss: 1.000103]\n",
      "epoch:23 step:110870[D loss: 0.999977] [G loss: 1.000104]\n",
      "epoch:23 step:110875[D loss: 0.999939] [G loss: 1.000112]\n",
      "epoch:23 step:110880[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:23 step:110885[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:23 step:110890[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:23 step:110895[D loss: 0.999981] [G loss: 1.000021]\n",
      "epoch:23 step:110900[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:23 step:110905[D loss: 1.000032] [G loss: 0.999994]\n",
      "epoch:23 step:110910[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:23 step:110915[D loss: 1.000050] [G loss: 1.000076]\n",
      "epoch:23 step:110920[D loss: 0.999965] [G loss: 1.000022]\n",
      "epoch:23 step:110925[D loss: 0.999948] [G loss: 1.000111]\n",
      "epoch:23 step:110930[D loss: 0.999999] [G loss: 1.000046]\n",
      "epoch:23 step:110935[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:23 step:110940[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:23 step:110945[D loss: 0.999902] [G loss: 1.000101]\n",
      "epoch:23 step:110950[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:23 step:110955[D loss: 1.000090] [G loss: 0.999964]\n",
      "epoch:23 step:110960[D loss: 1.000127] [G loss: 0.999866]\n",
      "epoch:23 step:110965[D loss: 0.999984] [G loss: 1.000005]\n",
      "epoch:23 step:110970[D loss: 0.999944] [G loss: 1.000073]\n",
      "epoch:23 step:110975[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:23 step:110980[D loss: 0.999975] [G loss: 1.000030]\n",
      "epoch:23 step:110985[D loss: 0.999988] [G loss: 1.000069]\n",
      "epoch:23 step:110990[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:23 step:110995[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:23 step:111000[D loss: 1.000028] [G loss: 0.999974]\n",
      "##############\n",
      "[2.4669935  2.07521706 2.18734286 3.94040302 1.30299232 8.01150618\n",
      " 2.36629328 3.81508647 4.03809369 5.04505846]\n",
      "##########\n",
      "epoch:23 step:111005[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:23 step:111010[D loss: 1.000056] [G loss: 1.000057]\n",
      "epoch:23 step:111015[D loss: 0.999976] [G loss: 0.999991]\n",
      "epoch:23 step:111020[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:23 step:111025[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:23 step:111030[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:23 step:111035[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:23 step:111040[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:23 step:111045[D loss: 0.999973] [G loss: 1.000100]\n",
      "epoch:23 step:111050[D loss: 1.000023] [G loss: 1.000050]\n",
      "epoch:23 step:111055[D loss: 0.999988] [G loss: 1.000027]\n",
      "epoch:23 step:111060[D loss: 0.999958] [G loss: 1.000166]\n",
      "epoch:23 step:111065[D loss: 0.999956] [G loss: 1.000188]\n",
      "epoch:23 step:111070[D loss: 1.000028] [G loss: 1.000042]\n",
      "epoch:23 step:111075[D loss: 0.999949] [G loss: 1.000104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:111080[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:23 step:111085[D loss: 1.000037] [G loss: 0.999941]\n",
      "epoch:23 step:111090[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:23 step:111095[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:23 step:111100[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:23 step:111105[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:23 step:111110[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:23 step:111115[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:23 step:111120[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:23 step:111125[D loss: 0.999939] [G loss: 1.000095]\n",
      "epoch:23 step:111130[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:23 step:111135[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:23 step:111140[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:23 step:111145[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:23 step:111150[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:23 step:111155[D loss: 0.999950] [G loss: 1.000106]\n",
      "epoch:23 step:111160[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:23 step:111165[D loss: 0.999958] [G loss: 1.000110]\n",
      "epoch:23 step:111170[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:23 step:111175[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:23 step:111180[D loss: 1.000043] [G loss: 0.999985]\n",
      "epoch:23 step:111185[D loss: 0.999948] [G loss: 1.000110]\n",
      "epoch:23 step:111190[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:23 step:111195[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:23 step:111200[D loss: 0.999977] [G loss: 1.000132]\n",
      "##############\n",
      "[2.61489886 2.02190059 2.01997686 3.89324231 1.40457058 8.24402205\n",
      " 2.39676614 3.68525785 3.95428831 5.76417543]\n",
      "##########\n",
      "epoch:23 step:111205[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:23 step:111210[D loss: 0.999963] [G loss: 1.000113]\n",
      "epoch:23 step:111215[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:23 step:111220[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:23 step:111225[D loss: 0.999954] [G loss: 1.000097]\n",
      "epoch:23 step:111230[D loss: 1.000011] [G loss: 1.000014]\n",
      "epoch:23 step:111235[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:23 step:111240[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:23 step:111245[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:23 step:111250[D loss: 0.999965] [G loss: 1.000116]\n",
      "epoch:23 step:111255[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:23 step:111260[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:23 step:111265[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:23 step:111270[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:23 step:111275[D loss: 0.999967] [G loss: 1.000097]\n",
      "epoch:23 step:111280[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:23 step:111285[D loss: 0.999970] [G loss: 1.000103]\n",
      "epoch:23 step:111290[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:23 step:111295[D loss: 1.000004] [G loss: 0.999991]\n",
      "epoch:23 step:111300[D loss: 1.000078] [G loss: 1.000036]\n",
      "epoch:23 step:111305[D loss: 1.000038] [G loss: 1.000071]\n",
      "epoch:23 step:111310[D loss: 1.000075] [G loss: 0.999986]\n",
      "epoch:23 step:111315[D loss: 0.999949] [G loss: 1.000057]\n",
      "epoch:23 step:111320[D loss: 0.999953] [G loss: 1.000123]\n",
      "epoch:23 step:111325[D loss: 1.000076] [G loss: 1.000126]\n",
      "epoch:23 step:111330[D loss: 0.999890] [G loss: 1.000253]\n",
      "epoch:23 step:111335[D loss: 0.999960] [G loss: 1.000050]\n",
      "epoch:23 step:111340[D loss: 0.999959] [G loss: 1.000027]\n",
      "epoch:23 step:111345[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:23 step:111350[D loss: 1.000005] [G loss: 0.999993]\n",
      "epoch:23 step:111355[D loss: 0.999935] [G loss: 1.000065]\n",
      "epoch:23 step:111360[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:23 step:111365[D loss: 0.999944] [G loss: 1.000102]\n",
      "epoch:23 step:111370[D loss: 1.000017] [G loss: 1.000148]\n",
      "epoch:23 step:111375[D loss: 0.999973] [G loss: 1.000143]\n",
      "epoch:23 step:111380[D loss: 0.999958] [G loss: 1.000097]\n",
      "epoch:23 step:111385[D loss: 0.999929] [G loss: 1.000107]\n",
      "epoch:23 step:111390[D loss: 1.000051] [G loss: 1.000042]\n",
      "epoch:23 step:111395[D loss: 0.999896] [G loss: 1.000122]\n",
      "epoch:23 step:111400[D loss: 0.999983] [G loss: 1.000080]\n",
      "##############\n",
      "[2.47352762 2.06573473 2.03209157 3.64780633 1.28756279 6.48273934\n",
      " 2.13684458 3.51903732 3.90058759 4.86140132]\n",
      "##########\n",
      "epoch:23 step:111405[D loss: 0.999969] [G loss: 1.000145]\n",
      "epoch:23 step:111410[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:23 step:111415[D loss: 1.000009] [G loss: 0.999961]\n",
      "epoch:23 step:111420[D loss: 0.999990] [G loss: 1.000002]\n",
      "epoch:23 step:111425[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:23 step:111430[D loss: 0.999954] [G loss: 1.000054]\n",
      "epoch:23 step:111435[D loss: 1.000059] [G loss: 1.000037]\n",
      "epoch:23 step:111440[D loss: 0.999931] [G loss: 1.000072]\n",
      "epoch:23 step:111445[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:23 step:111450[D loss: 1.000020] [G loss: 1.000025]\n",
      "epoch:23 step:111455[D loss: 1.000049] [G loss: 1.000002]\n",
      "epoch:23 step:111460[D loss: 0.999952] [G loss: 1.000074]\n",
      "epoch:23 step:111465[D loss: 1.000024] [G loss: 1.000142]\n",
      "epoch:23 step:111470[D loss: 0.999910] [G loss: 1.000057]\n",
      "epoch:23 step:111475[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:23 step:111480[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:23 step:111485[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:23 step:111490[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:23 step:111495[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:23 step:111500[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:23 step:111505[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:23 step:111510[D loss: 1.000000] [G loss: 1.000015]\n",
      "epoch:23 step:111515[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:23 step:111520[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:23 step:111525[D loss: 1.000035] [G loss: 1.000031]\n",
      "epoch:23 step:111530[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:23 step:111535[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:23 step:111540[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:23 step:111545[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:23 step:111550[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:23 step:111555[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:23 step:111560[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:23 step:111565[D loss: 0.999966] [G loss: 1.000124]\n",
      "epoch:23 step:111570[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:23 step:111575[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:23 step:111580[D loss: 1.000013] [G loss: 1.000001]\n",
      "epoch:23 step:111585[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:23 step:111590[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:23 step:111595[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:23 step:111600[D loss: 0.999984] [G loss: 1.000069]\n",
      "##############\n",
      "[2.47366947 2.0619816  2.10685887 3.82899191 1.25844285 7.41990404\n",
      " 2.09487219 3.68756855 3.92598947 4.46013643]\n",
      "##########\n",
      "epoch:23 step:111605[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:23 step:111610[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:23 step:111615[D loss: 0.999883] [G loss: 1.000221]\n",
      "epoch:23 step:111620[D loss: 1.000037] [G loss: 0.999955]\n",
      "epoch:23 step:111625[D loss: 1.000054] [G loss: 1.000089]\n",
      "epoch:23 step:111630[D loss: 0.999848] [G loss: 1.000127]\n",
      "epoch:23 step:111635[D loss: 1.000025] [G loss: 1.000021]\n",
      "epoch:23 step:111640[D loss: 0.999932] [G loss: 1.000093]\n",
      "epoch:23 step:111645[D loss: 0.999992] [G loss: 0.999990]\n",
      "epoch:23 step:111650[D loss: 0.999993] [G loss: 1.000080]\n",
      "epoch:23 step:111655[D loss: 0.999996] [G loss: 1.000014]\n",
      "epoch:23 step:111660[D loss: 0.999954] [G loss: 1.000049]\n",
      "epoch:23 step:111665[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:23 step:111670[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:23 step:111675[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:23 step:111680[D loss: 0.999989] [G loss: 1.000026]\n",
      "epoch:23 step:111685[D loss: 1.000014] [G loss: 1.000014]\n",
      "epoch:23 step:111690[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:23 step:111695[D loss: 1.000000] [G loss: 1.000160]\n",
      "epoch:23 step:111700[D loss: 1.000063] [G loss: 1.000060]\n",
      "epoch:23 step:111705[D loss: 0.999932] [G loss: 1.000105]\n",
      "epoch:23 step:111710[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:23 step:111715[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:23 step:111720[D loss: 0.999990] [G loss: 1.000006]\n",
      "epoch:23 step:111725[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:23 step:111730[D loss: 1.000018] [G loss: 0.999993]\n",
      "epoch:23 step:111735[D loss: 0.999930] [G loss: 1.000118]\n",
      "epoch:23 step:111740[D loss: 1.000036] [G loss: 0.999919]\n",
      "epoch:23 step:111745[D loss: 1.000113] [G loss: 0.999854]\n",
      "epoch:23 step:111750[D loss: 0.999898] [G loss: 1.000224]\n",
      "epoch:23 step:111755[D loss: 0.999967] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:111760[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:23 step:111765[D loss: 0.999992] [G loss: 0.999991]\n",
      "epoch:23 step:111770[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:23 step:111775[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:23 step:111780[D loss: 1.000049] [G loss: 1.000002]\n",
      "epoch:23 step:111785[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:23 step:111790[D loss: 0.999927] [G loss: 1.000147]\n",
      "epoch:23 step:111795[D loss: 1.000056] [G loss: 1.000089]\n",
      "epoch:23 step:111800[D loss: 0.999869] [G loss: 1.000148]\n",
      "##############\n",
      "[2.5247827  2.08851074 2.13532955 3.81884611 1.29138269 6.89816093\n",
      " 2.31613523 3.6232929  3.86253005 5.47265162]\n",
      "##########\n",
      "epoch:23 step:111805[D loss: 0.999956] [G loss: 1.000129]\n",
      "epoch:23 step:111810[D loss: 0.999975] [G loss: 1.000146]\n",
      "epoch:23 step:111815[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:23 step:111820[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:23 step:111825[D loss: 1.000002] [G loss: 1.000001]\n",
      "epoch:23 step:111830[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:23 step:111835[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:23 step:111840[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:23 step:111845[D loss: 1.000013] [G loss: 1.000034]\n",
      "epoch:23 step:111850[D loss: 0.999945] [G loss: 1.000083]\n",
      "epoch:23 step:111855[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:23 step:111860[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:23 step:111865[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:23 step:111870[D loss: 0.999938] [G loss: 1.000084]\n",
      "epoch:23 step:111875[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:23 step:111880[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:23 step:111885[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:23 step:111890[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:23 step:111895[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:23 step:111900[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:23 step:111905[D loss: 1.000014] [G loss: 1.000058]\n",
      "epoch:23 step:111910[D loss: 0.999959] [G loss: 1.000120]\n",
      "epoch:23 step:111915[D loss: 1.000037] [G loss: 1.000087]\n",
      "epoch:23 step:111920[D loss: 0.999987] [G loss: 1.000108]\n",
      "epoch:23 step:111925[D loss: 1.000041] [G loss: 0.999992]\n",
      "epoch:23 step:111930[D loss: 0.999926] [G loss: 1.000129]\n",
      "epoch:23 step:111935[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:23 step:111940[D loss: 0.999996] [G loss: 1.000051]\n",
      "epoch:23 step:111945[D loss: 1.000012] [G loss: 1.000047]\n",
      "epoch:23 step:111950[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:23 step:111955[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:23 step:111960[D loss: 1.000036] [G loss: 1.000002]\n",
      "epoch:23 step:111965[D loss: 0.999954] [G loss: 1.000112]\n",
      "epoch:23 step:111970[D loss: 1.000005] [G loss: 1.000003]\n",
      "epoch:23 step:111975[D loss: 1.000047] [G loss: 1.000072]\n",
      "epoch:23 step:111980[D loss: 0.999925] [G loss: 1.000151]\n",
      "epoch:23 step:111985[D loss: 0.999920] [G loss: 1.000136]\n",
      "epoch:23 step:111990[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:23 step:111995[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:23 step:112000[D loss: 0.999993] [G loss: 1.000103]\n",
      "##############\n",
      "[2.48248717 2.05994076 2.0661573  3.7321605  1.30557729 7.6252673\n",
      " 2.20591127 3.59954978 3.91249717 5.98985102]\n",
      "##########\n",
      "epoch:23 step:112005[D loss: 0.999981] [G loss: 1.000098]\n",
      "epoch:23 step:112010[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:23 step:112015[D loss: 1.000002] [G loss: 1.000024]\n",
      "epoch:23 step:112020[D loss: 1.000030] [G loss: 0.999984]\n",
      "epoch:23 step:112025[D loss: 0.999972] [G loss: 1.000006]\n",
      "epoch:23 step:112030[D loss: 1.000004] [G loss: 0.999988]\n",
      "epoch:23 step:112035[D loss: 1.000059] [G loss: 1.000084]\n",
      "epoch:23 step:112040[D loss: 0.999854] [G loss: 1.000212]\n",
      "epoch:23 step:112045[D loss: 0.999892] [G loss: 1.000155]\n",
      "epoch:23 step:112050[D loss: 0.999930] [G loss: 1.000183]\n",
      "epoch:23 step:112055[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:23 step:112060[D loss: 0.999941] [G loss: 1.000106]\n",
      "epoch:23 step:112065[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:23 step:112070[D loss: 1.000001] [G loss: 1.000070]\n",
      "epoch:23 step:112075[D loss: 1.000011] [G loss: 1.000028]\n",
      "epoch:23 step:112080[D loss: 0.999999] [G loss: 0.999998]\n",
      "epoch:23 step:112085[D loss: 1.000021] [G loss: 0.999993]\n",
      "epoch:23 step:112090[D loss: 0.999996] [G loss: 1.000101]\n",
      "epoch:23 step:112095[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:23 step:112100[D loss: 1.000014] [G loss: 1.000124]\n",
      "epoch:23 step:112105[D loss: 1.000068] [G loss: 1.000092]\n",
      "epoch:23 step:112110[D loss: 0.999896] [G loss: 1.000115]\n",
      "epoch:23 step:112115[D loss: 0.999931] [G loss: 1.000075]\n",
      "epoch:23 step:112120[D loss: 1.000049] [G loss: 1.000028]\n",
      "epoch:23 step:112125[D loss: 0.999941] [G loss: 1.000117]\n",
      "epoch:23 step:112130[D loss: 0.999899] [G loss: 1.000118]\n",
      "epoch:23 step:112135[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:23 step:112140[D loss: 0.999987] [G loss: 1.000093]\n",
      "epoch:23 step:112145[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:23 step:112150[D loss: 1.000016] [G loss: 1.000004]\n",
      "epoch:23 step:112155[D loss: 1.000080] [G loss: 0.999906]\n",
      "epoch:23 step:112160[D loss: 0.999945] [G loss: 1.000030]\n",
      "epoch:23 step:112165[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:23 step:112170[D loss: 1.000009] [G loss: 0.999991]\n",
      "epoch:23 step:112175[D loss: 0.999937] [G loss: 1.000122]\n",
      "epoch:23 step:112180[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:23 step:112185[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:23 step:112190[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:23 step:112195[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:23 step:112200[D loss: 0.999983] [G loss: 1.000060]\n",
      "##############\n",
      "[2.43051013 2.10717403 2.08314947 4.06916378 1.35010445 7.42903327\n",
      " 2.17982147 3.59363095 3.87931261 5.77924688]\n",
      "##########\n",
      "epoch:23 step:112205[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:23 step:112210[D loss: 1.000026] [G loss: 0.999964]\n",
      "epoch:23 step:112215[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:23 step:112220[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:23 step:112225[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:23 step:112230[D loss: 0.999936] [G loss: 1.000101]\n",
      "epoch:23 step:112235[D loss: 0.999999] [G loss: 1.000062]\n",
      "epoch:23 step:112240[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:23 step:112245[D loss: 0.999945] [G loss: 1.000067]\n",
      "epoch:23 step:112250[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:23 step:112255[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:23 step:112260[D loss: 1.000036] [G loss: 1.000054]\n",
      "epoch:23 step:112265[D loss: 0.999940] [G loss: 1.000093]\n",
      "epoch:23 step:112270[D loss: 0.999952] [G loss: 1.000057]\n",
      "epoch:23 step:112275[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:23 step:112280[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:23 step:112285[D loss: 1.000036] [G loss: 0.999981]\n",
      "epoch:23 step:112290[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:23 step:112295[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:23 step:112300[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:23 step:112305[D loss: 0.999948] [G loss: 1.000063]\n",
      "epoch:23 step:112310[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:23 step:112315[D loss: 1.000004] [G loss: 1.000015]\n",
      "epoch:23 step:112320[D loss: 0.999997] [G loss: 0.999983]\n",
      "epoch:23 step:112325[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:23 step:112330[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:23 step:112335[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:23 step:112340[D loss: 1.000136] [G loss: 0.999921]\n",
      "epoch:23 step:112345[D loss: 0.999902] [G loss: 1.000120]\n",
      "epoch:23 step:112350[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:23 step:112355[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:23 step:112360[D loss: 0.999979] [G loss: 1.000004]\n",
      "epoch:23 step:112365[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:23 step:112370[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:23 step:112375[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:23 step:112380[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:23 step:112385[D loss: 1.000016] [G loss: 1.000017]\n",
      "epoch:23 step:112390[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:23 step:112395[D loss: 0.999915] [G loss: 1.000142]\n",
      "epoch:23 step:112400[D loss: 0.999990] [G loss: 1.000092]\n",
      "##############\n",
      "[2.41336523 2.07189979 2.15191224 3.7909094  1.34059038 8.38096215\n",
      " 2.22728688 3.60905772 3.88545923 5.41941394]\n",
      "##########\n",
      "epoch:23 step:112405[D loss: 0.999939] [G loss: 1.000086]\n",
      "epoch:23 step:112410[D loss: 1.000037] [G loss: 0.999998]\n",
      "epoch:23 step:112415[D loss: 0.999957] [G loss: 1.000097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:112420[D loss: 1.000029] [G loss: 1.000024]\n",
      "epoch:23 step:112425[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:23 step:112430[D loss: 1.000028] [G loss: 0.999989]\n",
      "epoch:23 step:112435[D loss: 1.000011] [G loss: 0.999965]\n",
      "epoch:23 step:112440[D loss: 0.999978] [G loss: 1.000012]\n",
      "epoch:24 step:112445[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:24 step:112450[D loss: 0.999933] [G loss: 1.000068]\n",
      "epoch:24 step:112455[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:24 step:112460[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:24 step:112465[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:24 step:112470[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:24 step:112475[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:24 step:112480[D loss: 0.999956] [G loss: 1.000070]\n",
      "epoch:24 step:112485[D loss: 1.000003] [G loss: 1.000061]\n",
      "epoch:24 step:112490[D loss: 1.000046] [G loss: 1.000047]\n",
      "epoch:24 step:112495[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:24 step:112500[D loss: 1.000012] [G loss: 0.999944]\n",
      "epoch:24 step:112505[D loss: 0.999913] [G loss: 1.000137]\n",
      "epoch:24 step:112510[D loss: 0.999940] [G loss: 1.000149]\n",
      "epoch:24 step:112515[D loss: 0.999973] [G loss: 1.000152]\n",
      "epoch:24 step:112520[D loss: 0.999952] [G loss: 1.000106]\n",
      "epoch:24 step:112525[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:24 step:112530[D loss: 1.000018] [G loss: 1.000003]\n",
      "epoch:24 step:112535[D loss: 0.999940] [G loss: 1.000098]\n",
      "epoch:24 step:112540[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:24 step:112545[D loss: 0.999954] [G loss: 1.000121]\n",
      "epoch:24 step:112550[D loss: 0.999971] [G loss: 1.000138]\n",
      "epoch:24 step:112555[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:24 step:112560[D loss: 0.999978] [G loss: 1.000130]\n",
      "epoch:24 step:112565[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:24 step:112570[D loss: 0.999924] [G loss: 1.000170]\n",
      "epoch:24 step:112575[D loss: 1.000021] [G loss: 1.000027]\n",
      "epoch:24 step:112580[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:24 step:112585[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:24 step:112590[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:24 step:112595[D loss: 0.999955] [G loss: 1.000103]\n",
      "epoch:24 step:112600[D loss: 0.999974] [G loss: 1.000077]\n",
      "##############\n",
      "[2.54074029 2.0860469  2.28756397 3.91798202 1.40647234 7.22938237\n",
      " 2.18165504 3.7274102  3.98909035 5.71755208]\n",
      "##########\n",
      "epoch:24 step:112605[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:24 step:112610[D loss: 1.000057] [G loss: 0.999972]\n",
      "epoch:24 step:112615[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:24 step:112620[D loss: 1.000049] [G loss: 0.999996]\n",
      "epoch:24 step:112625[D loss: 0.999986] [G loss: 1.000150]\n",
      "epoch:24 step:112630[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:24 step:112635[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:24 step:112640[D loss: 1.000114] [G loss: 0.999849]\n",
      "epoch:24 step:112645[D loss: 1.000024] [G loss: 0.999974]\n",
      "epoch:24 step:112650[D loss: 1.000013] [G loss: 0.999951]\n",
      "epoch:24 step:112655[D loss: 1.000097] [G loss: 0.999870]\n",
      "epoch:24 step:112660[D loss: 0.999936] [G loss: 1.000056]\n",
      "epoch:24 step:112665[D loss: 1.000009] [G loss: 1.000030]\n",
      "epoch:24 step:112670[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:24 step:112675[D loss: 1.000015] [G loss: 1.000050]\n",
      "epoch:24 step:112680[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:24 step:112685[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:24 step:112690[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:24 step:112695[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:24 step:112700[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:24 step:112705[D loss: 1.000039] [G loss: 0.999975]\n",
      "epoch:24 step:112710[D loss: 0.999938] [G loss: 1.000090]\n",
      "epoch:24 step:112715[D loss: 1.000060] [G loss: 0.999982]\n",
      "epoch:24 step:112720[D loss: 0.999999] [G loss: 1.000088]\n",
      "epoch:24 step:112725[D loss: 1.000036] [G loss: 1.000035]\n",
      "epoch:24 step:112730[D loss: 1.000005] [G loss: 1.000075]\n",
      "epoch:24 step:112735[D loss: 0.999953] [G loss: 1.000151]\n",
      "epoch:24 step:112740[D loss: 0.999917] [G loss: 1.000181]\n",
      "epoch:24 step:112745[D loss: 0.999936] [G loss: 1.000187]\n",
      "epoch:24 step:112750[D loss: 0.999908] [G loss: 1.000214]\n",
      "epoch:24 step:112755[D loss: 1.000005] [G loss: 1.000097]\n",
      "epoch:24 step:112760[D loss: 1.000074] [G loss: 1.000033]\n",
      "epoch:24 step:112765[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:24 step:112770[D loss: 0.999935] [G loss: 1.000019]\n",
      "epoch:24 step:112775[D loss: 0.999949] [G loss: 0.999986]\n",
      "epoch:24 step:112780[D loss: 1.000100] [G loss: 0.999843]\n",
      "epoch:24 step:112785[D loss: 1.000046] [G loss: 1.000080]\n",
      "epoch:24 step:112790[D loss: 1.000038] [G loss: 0.999975]\n",
      "epoch:24 step:112795[D loss: 1.000019] [G loss: 0.999975]\n",
      "epoch:24 step:112800[D loss: 1.000078] [G loss: 0.999994]\n",
      "##############\n",
      "[2.48281688 2.12258357 2.24605592 3.8884278  1.39176472 8.28588187\n",
      " 2.25916231 3.6479705  3.96337524 5.18238578]\n",
      "##########\n",
      "epoch:24 step:112805[D loss: 0.999969] [G loss: 1.000014]\n",
      "epoch:24 step:112810[D loss: 0.999894] [G loss: 1.000063]\n",
      "epoch:24 step:112815[D loss: 0.999935] [G loss: 1.000089]\n",
      "epoch:24 step:112820[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:24 step:112825[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:24 step:112830[D loss: 0.999952] [G loss: 1.000062]\n",
      "epoch:24 step:112835[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:24 step:112840[D loss: 0.999960] [G loss: 1.000097]\n",
      "epoch:24 step:112845[D loss: 1.000009] [G loss: 1.000067]\n",
      "epoch:24 step:112850[D loss: 0.999984] [G loss: 0.999996]\n",
      "epoch:24 step:112855[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:24 step:112860[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:24 step:112865[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:24 step:112870[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:24 step:112875[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:24 step:112880[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:24 step:112885[D loss: 1.000018] [G loss: 1.000004]\n",
      "epoch:24 step:112890[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:24 step:112895[D loss: 0.999998] [G loss: 1.000087]\n",
      "epoch:24 step:112900[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:24 step:112905[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:24 step:112910[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:24 step:112915[D loss: 1.000060] [G loss: 0.999874]\n",
      "epoch:24 step:112920[D loss: 0.999990] [G loss: 1.000089]\n",
      "epoch:24 step:112925[D loss: 0.999951] [G loss: 1.000178]\n",
      "epoch:24 step:112930[D loss: 0.999949] [G loss: 1.000160]\n",
      "epoch:24 step:112935[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:24 step:112940[D loss: 0.999949] [G loss: 1.000096]\n",
      "epoch:24 step:112945[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:24 step:112950[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:24 step:112955[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:24 step:112960[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:24 step:112965[D loss: 1.000007] [G loss: 1.000033]\n",
      "epoch:24 step:112970[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:24 step:112975[D loss: 1.000090] [G loss: 0.999910]\n",
      "epoch:24 step:112980[D loss: 1.000063] [G loss: 0.999916]\n",
      "epoch:24 step:112985[D loss: 0.999936] [G loss: 1.000064]\n",
      "epoch:24 step:112990[D loss: 0.999973] [G loss: 1.000111]\n",
      "epoch:24 step:112995[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:24 step:113000[D loss: 0.999952] [G loss: 1.000123]\n",
      "##############\n",
      "[2.53777863 2.17607407 2.24739702 3.72250759 1.41707259 7.64187939\n",
      " 2.37383546 3.75642034 3.97632421 5.57066927]\n",
      "##########\n",
      "epoch:24 step:113005[D loss: 0.999974] [G loss: 1.000109]\n",
      "epoch:24 step:113010[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:24 step:113015[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:24 step:113020[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:24 step:113025[D loss: 0.999994] [G loss: 1.000093]\n",
      "epoch:24 step:113030[D loss: 1.000084] [G loss: 0.999920]\n",
      "epoch:24 step:113035[D loss: 0.999949] [G loss: 1.000205]\n",
      "epoch:24 step:113040[D loss: 1.000037] [G loss: 0.999897]\n",
      "epoch:24 step:113045[D loss: 0.999945] [G loss: 1.000110]\n",
      "epoch:24 step:113050[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:24 step:113055[D loss: 0.999996] [G loss: 1.000081]\n",
      "epoch:24 step:113060[D loss: 0.999952] [G loss: 1.000094]\n",
      "epoch:24 step:113065[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:24 step:113070[D loss: 0.999936] [G loss: 1.000036]\n",
      "epoch:24 step:113075[D loss: 1.000035] [G loss: 0.999941]\n",
      "epoch:24 step:113080[D loss: 0.999926] [G loss: 1.000070]\n",
      "epoch:24 step:113085[D loss: 0.999986] [G loss: 1.000108]\n",
      "epoch:24 step:113090[D loss: 0.999891] [G loss: 1.000125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:113095[D loss: 0.999932] [G loss: 1.000110]\n",
      "epoch:24 step:113100[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:24 step:113105[D loss: 0.999962] [G loss: 1.000145]\n",
      "epoch:24 step:113110[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:24 step:113115[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:24 step:113120[D loss: 1.000010] [G loss: 1.000000]\n",
      "epoch:24 step:113125[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:24 step:113130[D loss: 0.999956] [G loss: 1.000108]\n",
      "epoch:24 step:113135[D loss: 0.999911] [G loss: 1.000122]\n",
      "epoch:24 step:113140[D loss: 0.999938] [G loss: 1.000153]\n",
      "epoch:24 step:113145[D loss: 0.999966] [G loss: 1.000121]\n",
      "epoch:24 step:113150[D loss: 0.999950] [G loss: 1.000111]\n",
      "epoch:24 step:113155[D loss: 0.999933] [G loss: 1.000096]\n",
      "epoch:24 step:113160[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:24 step:113165[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:24 step:113170[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:24 step:113175[D loss: 1.000012] [G loss: 1.000055]\n",
      "epoch:24 step:113180[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:24 step:113185[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:24 step:113190[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:24 step:113195[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:24 step:113200[D loss: 0.999971] [G loss: 1.000078]\n",
      "##############\n",
      "[2.49141616 2.10048706 2.28869545 3.93753264 1.38029842 7.61524569\n",
      " 2.3334223  3.83939392 4.03347051 5.74258611]\n",
      "##########\n",
      "epoch:24 step:113205[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:24 step:113210[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:24 step:113215[D loss: 0.999942] [G loss: 1.000139]\n",
      "epoch:24 step:113220[D loss: 1.000042] [G loss: 1.000024]\n",
      "epoch:24 step:113225[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:24 step:113230[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:24 step:113235[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:24 step:113240[D loss: 0.999995] [G loss: 1.000015]\n",
      "epoch:24 step:113245[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:24 step:113250[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:24 step:113255[D loss: 0.999983] [G loss: 1.000001]\n",
      "epoch:24 step:113260[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:24 step:113265[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:24 step:113270[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:24 step:113275[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:24 step:113280[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:24 step:113285[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:24 step:113290[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:24 step:113295[D loss: 1.000029] [G loss: 0.999968]\n",
      "epoch:24 step:113300[D loss: 0.999940] [G loss: 1.000073]\n",
      "epoch:24 step:113305[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:24 step:113310[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:24 step:113315[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:24 step:113320[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:24 step:113325[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:24 step:113330[D loss: 1.000030] [G loss: 1.000021]\n",
      "epoch:24 step:113335[D loss: 1.000028] [G loss: 0.999961]\n",
      "epoch:24 step:113340[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:24 step:113345[D loss: 0.999918] [G loss: 1.000204]\n",
      "epoch:24 step:113350[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:24 step:113355[D loss: 1.000027] [G loss: 0.999998]\n",
      "epoch:24 step:113360[D loss: 0.999959] [G loss: 1.000127]\n",
      "epoch:24 step:113365[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:24 step:113370[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:24 step:113375[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:24 step:113380[D loss: 1.000001] [G loss: 0.999977]\n",
      "epoch:24 step:113385[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:24 step:113390[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:24 step:113395[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:24 step:113400[D loss: 0.999959] [G loss: 1.000061]\n",
      "##############\n",
      "[2.49663302 2.10370578 2.3589794  3.91944811 1.37471134 8.00362046\n",
      " 2.32364532 3.67356871 3.87064763 5.65678212]\n",
      "##########\n",
      "epoch:24 step:113405[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:24 step:113410[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:24 step:113415[D loss: 0.999942] [G loss: 1.000093]\n",
      "epoch:24 step:113420[D loss: 1.000007] [G loss: 1.000042]\n",
      "epoch:24 step:113425[D loss: 0.999990] [G loss: 1.000153]\n",
      "epoch:24 step:113430[D loss: 0.999999] [G loss: 1.000135]\n",
      "epoch:24 step:113435[D loss: 0.999989] [G loss: 1.000083]\n",
      "epoch:24 step:113440[D loss: 1.000024] [G loss: 1.000200]\n",
      "epoch:24 step:113445[D loss: 1.000029] [G loss: 0.999952]\n",
      "epoch:24 step:113450[D loss: 0.999947] [G loss: 1.000155]\n",
      "epoch:24 step:113455[D loss: 0.999907] [G loss: 1.000162]\n",
      "epoch:24 step:113460[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:24 step:113465[D loss: 1.000013] [G loss: 0.999958]\n",
      "epoch:24 step:113470[D loss: 1.000006] [G loss: 1.000000]\n",
      "epoch:24 step:113475[D loss: 0.999997] [G loss: 0.999990]\n",
      "epoch:24 step:113480[D loss: 0.999979] [G loss: 0.999903]\n",
      "epoch:24 step:113485[D loss: 1.000063] [G loss: 0.999914]\n",
      "epoch:24 step:113490[D loss: 1.000041] [G loss: 0.999950]\n",
      "epoch:24 step:113495[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:24 step:113500[D loss: 0.999985] [G loss: 0.999950]\n",
      "epoch:24 step:113505[D loss: 0.999915] [G loss: 1.000186]\n",
      "epoch:24 step:113510[D loss: 0.999989] [G loss: 1.000116]\n",
      "epoch:24 step:113515[D loss: 1.000084] [G loss: 0.999974]\n",
      "epoch:24 step:113520[D loss: 0.999976] [G loss: 1.000191]\n",
      "epoch:24 step:113525[D loss: 1.000138] [G loss: 1.000140]\n",
      "epoch:24 step:113530[D loss: 0.999969] [G loss: 1.000015]\n",
      "epoch:24 step:113535[D loss: 0.999859] [G loss: 1.000217]\n",
      "epoch:24 step:113540[D loss: 0.999896] [G loss: 1.000210]\n",
      "epoch:24 step:113545[D loss: 0.999942] [G loss: 1.000100]\n",
      "epoch:24 step:113550[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:24 step:113555[D loss: 1.000044] [G loss: 0.999971]\n",
      "epoch:24 step:113560[D loss: 0.999931] [G loss: 1.000065]\n",
      "epoch:24 step:113565[D loss: 1.000045] [G loss: 0.999980]\n",
      "epoch:24 step:113570[D loss: 1.000058] [G loss: 1.000031]\n",
      "epoch:24 step:113575[D loss: 1.000053] [G loss: 1.000052]\n",
      "epoch:24 step:113580[D loss: 0.999982] [G loss: 0.999977]\n",
      "epoch:24 step:113585[D loss: 0.999914] [G loss: 1.000087]\n",
      "epoch:24 step:113590[D loss: 1.000136] [G loss: 0.999908]\n",
      "epoch:24 step:113595[D loss: 0.999903] [G loss: 1.000267]\n",
      "epoch:24 step:113600[D loss: 0.999945] [G loss: 1.000085]\n",
      "##############\n",
      "[2.47830825 2.03834613 2.20392146 3.88688516 1.38740835 7.67017417\n",
      " 2.27008422 3.78200668 3.99457034 5.80488527]\n",
      "##########\n",
      "epoch:24 step:113605[D loss: 0.999958] [G loss: 1.000143]\n",
      "epoch:24 step:113610[D loss: 0.999932] [G loss: 1.000283]\n",
      "epoch:24 step:113615[D loss: 1.000020] [G loss: 1.000075]\n",
      "epoch:24 step:113620[D loss: 1.000020] [G loss: 0.999995]\n",
      "epoch:24 step:113625[D loss: 1.000025] [G loss: 1.000034]\n",
      "epoch:24 step:113630[D loss: 0.999928] [G loss: 1.000088]\n",
      "epoch:24 step:113635[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:24 step:113640[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:24 step:113645[D loss: 1.000069] [G loss: 0.999882]\n",
      "epoch:24 step:113650[D loss: 0.999941] [G loss: 1.000066]\n",
      "epoch:24 step:113655[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:24 step:113660[D loss: 1.000096] [G loss: 1.000018]\n",
      "epoch:24 step:113665[D loss: 0.999896] [G loss: 1.000202]\n",
      "epoch:24 step:113670[D loss: 0.999926] [G loss: 1.000092]\n",
      "epoch:24 step:113675[D loss: 0.999935] [G loss: 1.000033]\n",
      "epoch:24 step:113680[D loss: 1.000054] [G loss: 1.000008]\n",
      "epoch:24 step:113685[D loss: 1.000041] [G loss: 0.999937]\n",
      "epoch:24 step:113690[D loss: 0.999925] [G loss: 1.000183]\n",
      "epoch:24 step:113695[D loss: 0.999954] [G loss: 1.000070]\n",
      "epoch:24 step:113700[D loss: 0.999987] [G loss: 1.000094]\n",
      "epoch:24 step:113705[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:24 step:113710[D loss: 0.999964] [G loss: 1.000042]\n",
      "epoch:24 step:113715[D loss: 1.000022] [G loss: 1.000003]\n",
      "epoch:24 step:113720[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:24 step:113725[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:24 step:113730[D loss: 1.000151] [G loss: 0.999910]\n",
      "epoch:24 step:113735[D loss: 0.999943] [G loss: 1.000093]\n",
      "epoch:24 step:113740[D loss: 0.999895] [G loss: 1.000266]\n",
      "epoch:24 step:113745[D loss: 0.999937] [G loss: 1.000098]\n",
      "epoch:24 step:113750[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:24 step:113755[D loss: 0.999985] [G loss: 1.000090]\n",
      "epoch:24 step:113760[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:24 step:113765[D loss: 0.999984] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:113770[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:24 step:113775[D loss: 0.999954] [G loss: 1.000045]\n",
      "epoch:24 step:113780[D loss: 0.999910] [G loss: 1.000067]\n",
      "epoch:24 step:113785[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:24 step:113790[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:24 step:113795[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:24 step:113800[D loss: 1.000015] [G loss: 1.000066]\n",
      "##############\n",
      "[2.45151736 2.13095531 2.25959418 4.3313519  1.33300149 7.60602958\n",
      " 2.26685447 3.77247116 4.07278612 5.90267247]\n",
      "##########\n",
      "epoch:24 step:113805[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:24 step:113810[D loss: 0.999914] [G loss: 1.000157]\n",
      "epoch:24 step:113815[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:24 step:113820[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:24 step:113825[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:24 step:113830[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:24 step:113835[D loss: 1.000020] [G loss: 0.999982]\n",
      "epoch:24 step:113840[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:24 step:113845[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:24 step:113850[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:24 step:113855[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:24 step:113860[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:24 step:113865[D loss: 1.000016] [G loss: 1.000027]\n",
      "epoch:24 step:113870[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:24 step:113875[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:24 step:113880[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:24 step:113885[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:24 step:113890[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:24 step:113895[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:24 step:113900[D loss: 0.999966] [G loss: 1.000039]\n",
      "epoch:24 step:113905[D loss: 1.000005] [G loss: 1.000023]\n",
      "epoch:24 step:113910[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:24 step:113915[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:24 step:113920[D loss: 0.999947] [G loss: 1.000073]\n",
      "epoch:24 step:113925[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:24 step:113930[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:24 step:113935[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:24 step:113940[D loss: 1.000000] [G loss: 0.999978]\n",
      "epoch:24 step:113945[D loss: 0.999987] [G loss: 0.999986]\n",
      "epoch:24 step:113950[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:24 step:113955[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:24 step:113960[D loss: 0.999941] [G loss: 1.000103]\n",
      "epoch:24 step:113965[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:24 step:113970[D loss: 1.000009] [G loss: 1.000024]\n",
      "epoch:24 step:113975[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:24 step:113980[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:24 step:113985[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:24 step:113990[D loss: 1.000032] [G loss: 0.999981]\n",
      "epoch:24 step:113995[D loss: 1.000003] [G loss: 1.000059]\n",
      "epoch:24 step:114000[D loss: 0.999939] [G loss: 1.000076]\n",
      "##############\n",
      "[2.45521587 1.99815208 2.17852794 3.72249469 1.36505134 7.13209319\n",
      " 2.21932441 3.78009141 3.93972529 4.81212071]\n",
      "##########\n",
      "epoch:24 step:114005[D loss: 0.999983] [G loss: 0.999993]\n",
      "epoch:24 step:114010[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:24 step:114015[D loss: 0.999950] [G loss: 1.000120]\n",
      "epoch:24 step:114020[D loss: 1.000071] [G loss: 1.000049]\n",
      "epoch:24 step:114025[D loss: 0.999957] [G loss: 1.000008]\n",
      "epoch:24 step:114030[D loss: 0.999969] [G loss: 1.000008]\n",
      "epoch:24 step:114035[D loss: 1.000026] [G loss: 0.999983]\n",
      "epoch:24 step:114040[D loss: 0.999990] [G loss: 0.999959]\n",
      "epoch:24 step:114045[D loss: 1.000143] [G loss: 0.999860]\n",
      "epoch:24 step:114050[D loss: 1.000141] [G loss: 0.999814]\n",
      "epoch:24 step:114055[D loss: 1.000189] [G loss: 0.999722]\n",
      "epoch:24 step:114060[D loss: 0.999825] [G loss: 1.000211]\n",
      "epoch:24 step:114065[D loss: 0.999908] [G loss: 1.000075]\n",
      "epoch:24 step:114070[D loss: 0.999938] [G loss: 1.000038]\n",
      "epoch:24 step:114075[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:24 step:114080[D loss: 0.999967] [G loss: 1.000034]\n",
      "epoch:24 step:114085[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:24 step:114090[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:24 step:114095[D loss: 0.999949] [G loss: 1.000058]\n",
      "epoch:24 step:114100[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:24 step:114105[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:24 step:114110[D loss: 0.999934] [G loss: 1.000073]\n",
      "epoch:24 step:114115[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:24 step:114120[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:24 step:114125[D loss: 0.999963] [G loss: 1.000040]\n",
      "epoch:24 step:114130[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:24 step:114135[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:24 step:114140[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:24 step:114145[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:24 step:114150[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:24 step:114155[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:24 step:114160[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:24 step:114165[D loss: 0.999944] [G loss: 1.000089]\n",
      "epoch:24 step:114170[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:24 step:114175[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:24 step:114180[D loss: 1.000039] [G loss: 1.000004]\n",
      "epoch:24 step:114185[D loss: 0.999950] [G loss: 1.000057]\n",
      "epoch:24 step:114190[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:24 step:114195[D loss: 0.999942] [G loss: 1.000059]\n",
      "epoch:24 step:114200[D loss: 0.999994] [G loss: 1.000048]\n",
      "##############\n",
      "[2.53818407 2.06007472 2.13597399 4.11529887 1.39842276 7.02815554\n",
      " 2.19821151 3.61111154 3.88267998 5.75061758]\n",
      "##########\n",
      "epoch:24 step:114205[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:24 step:114210[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:24 step:114215[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:24 step:114220[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:24 step:114225[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:24 step:114230[D loss: 1.000012] [G loss: 1.000027]\n",
      "epoch:24 step:114235[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:24 step:114240[D loss: 0.999937] [G loss: 1.000120]\n",
      "epoch:24 step:114245[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:24 step:114250[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:24 step:114255[D loss: 1.000034] [G loss: 0.999997]\n",
      "epoch:24 step:114260[D loss: 0.999965] [G loss: 1.000159]\n",
      "epoch:24 step:114265[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:24 step:114270[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:24 step:114275[D loss: 1.000060] [G loss: 1.000037]\n",
      "epoch:24 step:114280[D loss: 1.000013] [G loss: 1.000035]\n",
      "epoch:24 step:114285[D loss: 0.999978] [G loss: 1.000116]\n",
      "epoch:24 step:114290[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:24 step:114295[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:24 step:114300[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:24 step:114305[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:24 step:114310[D loss: 0.999980] [G loss: 1.000024]\n",
      "epoch:24 step:114315[D loss: 1.000059] [G loss: 0.999908]\n",
      "epoch:24 step:114320[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:24 step:114325[D loss: 0.999964] [G loss: 1.000125]\n",
      "epoch:24 step:114330[D loss: 1.000077] [G loss: 1.000088]\n",
      "epoch:24 step:114335[D loss: 0.999889] [G loss: 1.000167]\n",
      "epoch:24 step:114340[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:24 step:114345[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:24 step:114350[D loss: 0.999975] [G loss: 1.000019]\n",
      "epoch:24 step:114355[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:24 step:114360[D loss: 0.999942] [G loss: 1.000099]\n",
      "epoch:24 step:114365[D loss: 1.000105] [G loss: 0.999934]\n",
      "epoch:24 step:114370[D loss: 0.999943] [G loss: 1.000039]\n",
      "epoch:24 step:114375[D loss: 1.000041] [G loss: 1.000019]\n",
      "epoch:24 step:114380[D loss: 1.000024] [G loss: 1.000028]\n",
      "epoch:24 step:114385[D loss: 0.999892] [G loss: 1.000024]\n",
      "epoch:24 step:114390[D loss: 1.000054] [G loss: 1.000016]\n",
      "epoch:24 step:114395[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:24 step:114400[D loss: 0.999957] [G loss: 1.000148]\n",
      "##############\n",
      "[2.54132148 2.13011037 2.01191179 3.96073202 1.42840373 7.07831525\n",
      " 2.21670311 3.72489246 3.95828885 5.3606527 ]\n",
      "##########\n",
      "epoch:24 step:114405[D loss: 0.999958] [G loss: 1.000083]\n",
      "epoch:24 step:114410[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:24 step:114415[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:24 step:114420[D loss: 0.999999] [G loss: 1.000025]\n",
      "epoch:24 step:114425[D loss: 1.000039] [G loss: 0.999945]\n",
      "epoch:24 step:114430[D loss: 1.000015] [G loss: 0.999948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:114435[D loss: 1.000003] [G loss: 1.000067]\n",
      "epoch:24 step:114440[D loss: 0.999907] [G loss: 1.000211]\n",
      "epoch:24 step:114445[D loss: 1.000082] [G loss: 0.999949]\n",
      "epoch:24 step:114450[D loss: 1.000143] [G loss: 0.999884]\n",
      "epoch:24 step:114455[D loss: 1.000000] [G loss: 1.000148]\n",
      "epoch:24 step:114460[D loss: 0.999882] [G loss: 1.000189]\n",
      "epoch:24 step:114465[D loss: 0.999902] [G loss: 1.000107]\n",
      "epoch:24 step:114470[D loss: 0.999948] [G loss: 1.000073]\n",
      "epoch:24 step:114475[D loss: 1.000029] [G loss: 0.999960]\n",
      "epoch:24 step:114480[D loss: 0.999981] [G loss: 1.000009]\n",
      "epoch:24 step:114485[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:24 step:114490[D loss: 1.000107] [G loss: 0.999947]\n",
      "epoch:24 step:114495[D loss: 1.000093] [G loss: 0.999832]\n",
      "epoch:24 step:114500[D loss: 0.999927] [G loss: 1.000023]\n",
      "epoch:24 step:114505[D loss: 0.999961] [G loss: 1.000133]\n",
      "epoch:24 step:114510[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:24 step:114515[D loss: 0.999972] [G loss: 1.000117]\n",
      "epoch:24 step:114520[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:24 step:114525[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:24 step:114530[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:24 step:114535[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:24 step:114540[D loss: 0.999941] [G loss: 1.000060]\n",
      "epoch:24 step:114545[D loss: 0.999948] [G loss: 1.000133]\n",
      "epoch:24 step:114550[D loss: 1.000035] [G loss: 0.999999]\n",
      "epoch:24 step:114555[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:24 step:114560[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:24 step:114565[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:24 step:114570[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:24 step:114575[D loss: 1.000020] [G loss: 0.999957]\n",
      "epoch:24 step:114580[D loss: 0.999997] [G loss: 1.000000]\n",
      "epoch:24 step:114585[D loss: 1.000052] [G loss: 0.999886]\n",
      "epoch:24 step:114590[D loss: 0.999995] [G loss: 0.999964]\n",
      "epoch:24 step:114595[D loss: 0.999928] [G loss: 1.000091]\n",
      "epoch:24 step:114600[D loss: 1.000030] [G loss: 1.000033]\n",
      "##############\n",
      "[2.54789853 2.17905471 2.14562955 4.01623122 1.45237807 8.48084008\n",
      " 2.19400336 3.89390151 3.96576335 5.39591371]\n",
      "##########\n",
      "epoch:24 step:114605[D loss: 0.999940] [G loss: 1.000116]\n",
      "epoch:24 step:114610[D loss: 0.999959] [G loss: 1.000130]\n",
      "epoch:24 step:114615[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:24 step:114620[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:24 step:114625[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:24 step:114630[D loss: 0.999983] [G loss: 1.000017]\n",
      "epoch:24 step:114635[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:24 step:114640[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:24 step:114645[D loss: 0.999997] [G loss: 0.999984]\n",
      "epoch:24 step:114650[D loss: 0.999996] [G loss: 1.000009]\n",
      "epoch:24 step:114655[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:24 step:114660[D loss: 1.000009] [G loss: 1.000003]\n",
      "epoch:24 step:114665[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:24 step:114670[D loss: 1.000007] [G loss: 1.000164]\n",
      "epoch:24 step:114675[D loss: 0.999947] [G loss: 1.000167]\n",
      "epoch:24 step:114680[D loss: 0.999903] [G loss: 1.000285]\n",
      "epoch:24 step:114685[D loss: 0.999955] [G loss: 1.000137]\n",
      "epoch:24 step:114690[D loss: 0.999978] [G loss: 1.000113]\n",
      "epoch:24 step:114695[D loss: 0.999945] [G loss: 1.000058]\n",
      "epoch:24 step:114700[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:24 step:114705[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:24 step:114710[D loss: 1.000030] [G loss: 0.999920]\n",
      "epoch:24 step:114715[D loss: 0.999936] [G loss: 1.000099]\n",
      "epoch:24 step:114720[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:24 step:114725[D loss: 1.000055] [G loss: 0.999927]\n",
      "epoch:24 step:114730[D loss: 1.000076] [G loss: 1.000002]\n",
      "epoch:24 step:114735[D loss: 1.000121] [G loss: 1.000126]\n",
      "epoch:24 step:114740[D loss: 0.999996] [G loss: 1.000009]\n",
      "epoch:24 step:114745[D loss: 0.999919] [G loss: 1.000166]\n",
      "epoch:24 step:114750[D loss: 0.999922] [G loss: 1.000094]\n",
      "epoch:24 step:114755[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:24 step:114760[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:24 step:114765[D loss: 0.999993] [G loss: 1.000000]\n",
      "epoch:24 step:114770[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:24 step:114775[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:24 step:114780[D loss: 1.000022] [G loss: 1.000007]\n",
      "epoch:24 step:114785[D loss: 1.000188] [G loss: 0.999845]\n",
      "epoch:24 step:114790[D loss: 0.999883] [G loss: 1.000160]\n",
      "epoch:24 step:114795[D loss: 0.999951] [G loss: 1.000126]\n",
      "epoch:24 step:114800[D loss: 0.999959] [G loss: 1.000079]\n",
      "##############\n",
      "[2.60078635 2.1946312  2.18225916 3.84671903 1.4390188  7.37840783\n",
      " 2.20455939 3.80345369 3.9655478  7.14868929]\n",
      "##########\n",
      "epoch:24 step:114805[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:24 step:114810[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:24 step:114815[D loss: 0.999946] [G loss: 1.000088]\n",
      "epoch:24 step:114820[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:24 step:114825[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:24 step:114830[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:24 step:114835[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:24 step:114840[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:24 step:114845[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:24 step:114850[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:24 step:114855[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:24 step:114860[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:24 step:114865[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:24 step:114870[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:24 step:114875[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:24 step:114880[D loss: 1.000028] [G loss: 1.000042]\n",
      "epoch:24 step:114885[D loss: 0.999938] [G loss: 1.000128]\n",
      "epoch:24 step:114890[D loss: 0.999987] [G loss: 1.000107]\n",
      "epoch:24 step:114895[D loss: 0.999937] [G loss: 1.000123]\n",
      "epoch:24 step:114900[D loss: 1.000016] [G loss: 1.000051]\n",
      "epoch:24 step:114905[D loss: 0.999964] [G loss: 1.000194]\n",
      "epoch:24 step:114910[D loss: 1.000036] [G loss: 1.000020]\n",
      "epoch:24 step:114915[D loss: 0.999933] [G loss: 1.000074]\n",
      "epoch:24 step:114920[D loss: 1.000156] [G loss: 1.000002]\n",
      "epoch:24 step:114925[D loss: 0.999956] [G loss: 1.000161]\n",
      "epoch:24 step:114930[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:24 step:114935[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:24 step:114940[D loss: 1.000107] [G loss: 0.999886]\n",
      "epoch:24 step:114945[D loss: 0.999948] [G loss: 0.999943]\n",
      "epoch:24 step:114950[D loss: 1.000022] [G loss: 0.999945]\n",
      "epoch:24 step:114955[D loss: 0.999998] [G loss: 0.999981]\n",
      "epoch:24 step:114960[D loss: 0.999964] [G loss: 1.000104]\n",
      "epoch:24 step:114965[D loss: 0.999929] [G loss: 1.000134]\n",
      "epoch:24 step:114970[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:24 step:114975[D loss: 1.000024] [G loss: 1.000091]\n",
      "epoch:24 step:114980[D loss: 0.999986] [G loss: 1.000147]\n",
      "epoch:24 step:114985[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:24 step:114990[D loss: 1.000089] [G loss: 1.000122]\n",
      "epoch:24 step:114995[D loss: 1.000013] [G loss: 1.000042]\n",
      "epoch:24 step:115000[D loss: 0.999917] [G loss: 1.000093]\n",
      "##############\n",
      "[2.5562424  2.17615692 2.30614689 4.20828438 1.46838077 8.14822599\n",
      " 2.26363763 3.68914959 3.9787357  5.19832676]\n",
      "##########\n",
      "epoch:24 step:115005[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:24 step:115010[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:24 step:115015[D loss: 0.999982] [G loss: 1.000004]\n",
      "epoch:24 step:115020[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:24 step:115025[D loss: 1.000044] [G loss: 1.000058]\n",
      "epoch:24 step:115030[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:24 step:115035[D loss: 1.000009] [G loss: 1.000010]\n",
      "epoch:24 step:115040[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:24 step:115045[D loss: 0.999921] [G loss: 1.000171]\n",
      "epoch:24 step:115050[D loss: 0.999923] [G loss: 1.000127]\n",
      "epoch:24 step:115055[D loss: 0.999963] [G loss: 1.000118]\n",
      "epoch:24 step:115060[D loss: 0.999964] [G loss: 1.000136]\n",
      "epoch:24 step:115065[D loss: 0.999970] [G loss: 1.000015]\n",
      "epoch:24 step:115070[D loss: 0.999971] [G loss: 1.000022]\n",
      "epoch:24 step:115075[D loss: 0.999945] [G loss: 1.000094]\n",
      "epoch:24 step:115080[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:24 step:115085[D loss: 0.999999] [G loss: 1.000044]\n",
      "epoch:24 step:115090[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:24 step:115095[D loss: 0.999992] [G loss: 1.000010]\n",
      "epoch:24 step:115100[D loss: 0.999988] [G loss: 0.999986]\n",
      "epoch:24 step:115105[D loss: 0.999983] [G loss: 1.000013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:115110[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:24 step:115115[D loss: 0.999996] [G loss: 1.000055]\n",
      "epoch:24 step:115120[D loss: 1.000007] [G loss: 1.000055]\n",
      "epoch:24 step:115125[D loss: 1.000068] [G loss: 0.999984]\n",
      "epoch:24 step:115130[D loss: 1.000015] [G loss: 1.000050]\n",
      "epoch:24 step:115135[D loss: 1.000113] [G loss: 0.999907]\n",
      "epoch:24 step:115140[D loss: 0.999902] [G loss: 1.000162]\n",
      "epoch:24 step:115145[D loss: 1.000047] [G loss: 0.999933]\n",
      "epoch:24 step:115150[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:24 step:115155[D loss: 1.000034] [G loss: 0.999977]\n",
      "epoch:24 step:115160[D loss: 0.999961] [G loss: 1.000025]\n",
      "epoch:24 step:115165[D loss: 0.999954] [G loss: 1.000140]\n",
      "epoch:24 step:115170[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:24 step:115175[D loss: 0.999942] [G loss: 1.000043]\n",
      "epoch:24 step:115180[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:24 step:115185[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:24 step:115190[D loss: 1.000041] [G loss: 1.000098]\n",
      "epoch:24 step:115195[D loss: 0.999957] [G loss: 1.000059]\n",
      "epoch:24 step:115200[D loss: 1.000002] [G loss: 1.000038]\n",
      "##############\n",
      "[2.50796529 2.16038988 2.03876071 4.10294206 1.41174053 8.26117123\n",
      " 2.20530246 3.71048384 3.99839862 5.00732439]\n",
      "##########\n",
      "epoch:24 step:115205[D loss: 0.999960] [G loss: 1.000043]\n",
      "epoch:24 step:115210[D loss: 0.999994] [G loss: 1.000081]\n",
      "epoch:24 step:115215[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:24 step:115220[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:24 step:115225[D loss: 1.000017] [G loss: 1.000041]\n",
      "epoch:24 step:115230[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:24 step:115235[D loss: 0.999984] [G loss: 1.000106]\n",
      "epoch:24 step:115240[D loss: 0.999949] [G loss: 1.000116]\n",
      "epoch:24 step:115245[D loss: 0.999989] [G loss: 1.000099]\n",
      "epoch:24 step:115250[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:24 step:115255[D loss: 0.999982] [G loss: 1.000109]\n",
      "epoch:24 step:115260[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:24 step:115265[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:24 step:115270[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:24 step:115275[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:24 step:115280[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:24 step:115285[D loss: 1.000020] [G loss: 0.999984]\n",
      "epoch:24 step:115290[D loss: 0.999958] [G loss: 1.000026]\n",
      "epoch:24 step:115295[D loss: 0.999983] [G loss: 1.000010]\n",
      "epoch:24 step:115300[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:24 step:115305[D loss: 1.000039] [G loss: 1.000011]\n",
      "epoch:24 step:115310[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:24 step:115315[D loss: 0.999982] [G loss: 1.000134]\n",
      "epoch:24 step:115320[D loss: 1.000027] [G loss: 0.999939]\n",
      "epoch:24 step:115325[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:24 step:115330[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:24 step:115335[D loss: 1.000018] [G loss: 0.999963]\n",
      "epoch:24 step:115340[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:24 step:115345[D loss: 1.000028] [G loss: 1.000027]\n",
      "epoch:24 step:115350[D loss: 0.999943] [G loss: 1.000171]\n",
      "epoch:24 step:115355[D loss: 1.000055] [G loss: 0.999956]\n",
      "epoch:24 step:115360[D loss: 0.999918] [G loss: 1.000080]\n",
      "epoch:24 step:115365[D loss: 1.000010] [G loss: 1.000034]\n",
      "epoch:24 step:115370[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:24 step:115375[D loss: 1.000034] [G loss: 1.000015]\n",
      "epoch:24 step:115380[D loss: 1.000069] [G loss: 1.000130]\n",
      "epoch:24 step:115385[D loss: 1.000026] [G loss: 1.000105]\n",
      "epoch:24 step:115390[D loss: 0.999941] [G loss: 1.000095]\n",
      "epoch:24 step:115395[D loss: 1.000031] [G loss: 0.999957]\n",
      "epoch:24 step:115400[D loss: 0.999993] [G loss: 1.000096]\n",
      "##############\n",
      "[2.46238521 2.14414198 2.13200868 3.85620186 1.36966511 7.35423759\n",
      " 2.33709899 3.8239005  3.9788319  5.03377196]\n",
      "##########\n",
      "epoch:24 step:115405[D loss: 1.000101] [G loss: 0.999913]\n",
      "epoch:24 step:115410[D loss: 1.000103] [G loss: 0.999884]\n",
      "epoch:24 step:115415[D loss: 1.000158] [G loss: 0.999997]\n",
      "epoch:24 step:115420[D loss: 0.999955] [G loss: 1.000095]\n",
      "epoch:24 step:115425[D loss: 0.999864] [G loss: 1.000224]\n",
      "epoch:24 step:115430[D loss: 0.999865] [G loss: 1.000282]\n",
      "epoch:24 step:115435[D loss: 0.999929] [G loss: 1.000135]\n",
      "epoch:24 step:115440[D loss: 0.999929] [G loss: 1.000203]\n",
      "epoch:24 step:115445[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:24 step:115450[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:24 step:115455[D loss: 0.999972] [G loss: 1.000106]\n",
      "epoch:24 step:115460[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:24 step:115465[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:24 step:115470[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:24 step:115475[D loss: 1.000002] [G loss: 1.000040]\n",
      "epoch:24 step:115480[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:24 step:115485[D loss: 1.000000] [G loss: 1.000123]\n",
      "epoch:24 step:115490[D loss: 0.999935] [G loss: 1.000089]\n",
      "epoch:24 step:115495[D loss: 1.000007] [G loss: 0.999992]\n",
      "epoch:24 step:115500[D loss: 0.999965] [G loss: 1.000117]\n",
      "epoch:24 step:115505[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:24 step:115510[D loss: 0.999957] [G loss: 1.000044]\n",
      "epoch:24 step:115515[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:24 step:115520[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:24 step:115525[D loss: 1.000042] [G loss: 0.999994]\n",
      "epoch:24 step:115530[D loss: 1.000051] [G loss: 1.000005]\n",
      "epoch:24 step:115535[D loss: 0.999923] [G loss: 1.000065]\n",
      "epoch:24 step:115540[D loss: 0.999993] [G loss: 1.000130]\n",
      "epoch:24 step:115545[D loss: 0.999947] [G loss: 1.000087]\n",
      "epoch:24 step:115550[D loss: 1.000016] [G loss: 1.000100]\n",
      "epoch:24 step:115555[D loss: 0.999962] [G loss: 1.000119]\n",
      "epoch:24 step:115560[D loss: 0.999960] [G loss: 1.000116]\n",
      "epoch:24 step:115565[D loss: 1.000026] [G loss: 1.000032]\n",
      "epoch:24 step:115570[D loss: 0.999953] [G loss: 1.000110]\n",
      "epoch:24 step:115575[D loss: 1.000032] [G loss: 0.999954]\n",
      "epoch:24 step:115580[D loss: 0.999946] [G loss: 1.000108]\n",
      "epoch:24 step:115585[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:24 step:115590[D loss: 1.000052] [G loss: 0.999942]\n",
      "epoch:24 step:115595[D loss: 0.999981] [G loss: 1.000021]\n",
      "epoch:24 step:115600[D loss: 1.000035] [G loss: 1.000096]\n",
      "##############\n",
      "[2.56549108 2.12475751 2.14062762 3.72806007 1.4648251  8.1406376\n",
      " 2.35913361 3.64148102 4.06003738 7.14868929]\n",
      "##########\n",
      "epoch:24 step:115605[D loss: 1.000006] [G loss: 1.000079]\n",
      "epoch:24 step:115610[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:24 step:115615[D loss: 1.000023] [G loss: 0.999980]\n",
      "epoch:24 step:115620[D loss: 1.000024] [G loss: 1.000011]\n",
      "epoch:24 step:115625[D loss: 1.000097] [G loss: 0.999999]\n",
      "epoch:24 step:115630[D loss: 0.999926] [G loss: 1.000039]\n",
      "epoch:24 step:115635[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:24 step:115640[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:24 step:115645[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:24 step:115650[D loss: 1.000008] [G loss: 0.999979]\n",
      "epoch:24 step:115655[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:24 step:115660[D loss: 0.999911] [G loss: 1.000124]\n",
      "epoch:24 step:115665[D loss: 0.999983] [G loss: 1.000094]\n",
      "epoch:24 step:115670[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:24 step:115675[D loss: 0.999940] [G loss: 1.000075]\n",
      "epoch:24 step:115680[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:24 step:115685[D loss: 1.000015] [G loss: 1.000058]\n",
      "epoch:24 step:115690[D loss: 0.999947] [G loss: 1.000092]\n",
      "epoch:24 step:115695[D loss: 0.999900] [G loss: 1.000194]\n",
      "epoch:24 step:115700[D loss: 0.999937] [G loss: 1.000109]\n",
      "epoch:24 step:115705[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:24 step:115710[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:24 step:115715[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:24 step:115720[D loss: 0.999931] [G loss: 1.000138]\n",
      "epoch:24 step:115725[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:24 step:115730[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:24 step:115735[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:24 step:115740[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:24 step:115745[D loss: 0.999991] [G loss: 1.000075]\n",
      "epoch:24 step:115750[D loss: 0.999977] [G loss: 1.000180]\n",
      "epoch:24 step:115755[D loss: 1.000038] [G loss: 0.999977]\n",
      "epoch:24 step:115760[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:24 step:115765[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:24 step:115770[D loss: 1.000016] [G loss: 1.000009]\n",
      "epoch:24 step:115775[D loss: 0.999953] [G loss: 1.000018]\n",
      "epoch:24 step:115780[D loss: 1.000005] [G loss: 1.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:115785[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:24 step:115790[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:24 step:115795[D loss: 1.000016] [G loss: 1.000009]\n",
      "epoch:24 step:115800[D loss: 0.999996] [G loss: 1.000038]\n",
      "##############\n",
      "[2.42606266 2.07729198 2.14336935 3.61907615 1.40768606 7.55621665\n",
      " 2.24266783 3.78865137 3.86036173 4.98408383]\n",
      "##########\n",
      "epoch:24 step:115805[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:24 step:115810[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:24 step:115815[D loss: 1.000019] [G loss: 1.000049]\n",
      "epoch:24 step:115820[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:24 step:115825[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:24 step:115830[D loss: 1.000032] [G loss: 0.999975]\n",
      "epoch:24 step:115835[D loss: 1.000014] [G loss: 1.000007]\n",
      "epoch:24 step:115840[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:24 step:115845[D loss: 0.999943] [G loss: 1.000063]\n",
      "epoch:24 step:115850[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:24 step:115855[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:24 step:115860[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:24 step:115865[D loss: 1.000033] [G loss: 0.999996]\n",
      "epoch:24 step:115870[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:24 step:115875[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:24 step:115880[D loss: 0.999949] [G loss: 1.000113]\n",
      "epoch:24 step:115885[D loss: 0.999936] [G loss: 1.000153]\n",
      "epoch:24 step:115890[D loss: 0.999944] [G loss: 1.000092]\n",
      "epoch:24 step:115895[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:24 step:115900[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:24 step:115905[D loss: 0.999948] [G loss: 1.000233]\n",
      "epoch:24 step:115910[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:24 step:115915[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:24 step:115920[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:24 step:115925[D loss: 1.000009] [G loss: 0.999987]\n",
      "epoch:24 step:115930[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:24 step:115935[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:24 step:115940[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:24 step:115945[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:24 step:115950[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:24 step:115955[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:24 step:115960[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:24 step:115965[D loss: 0.999927] [G loss: 1.000170]\n",
      "epoch:24 step:115970[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:24 step:115975[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:24 step:115980[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:24 step:115985[D loss: 1.000082] [G loss: 0.999969]\n",
      "epoch:24 step:115990[D loss: 1.000027] [G loss: 1.000062]\n",
      "epoch:24 step:115995[D loss: 1.000011] [G loss: 0.999936]\n",
      "epoch:24 step:116000[D loss: 0.999964] [G loss: 1.000044]\n",
      "##############\n",
      "[2.58632016 2.07282983 2.06946242 4.27551498 1.45003779 7.38244951\n",
      " 2.3178017  3.81856931 3.91954402 6.1092272 ]\n",
      "##########\n",
      "epoch:24 step:116005[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:24 step:116010[D loss: 1.000023] [G loss: 1.000116]\n",
      "epoch:24 step:116015[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:24 step:116020[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:24 step:116025[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:24 step:116030[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:24 step:116035[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:24 step:116040[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:24 step:116045[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:24 step:116050[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:24 step:116055[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:24 step:116060[D loss: 1.000003] [G loss: 1.000038]\n",
      "epoch:24 step:116065[D loss: 0.999994] [G loss: 1.000021]\n",
      "epoch:24 step:116070[D loss: 0.999976] [G loss: 0.999983]\n",
      "epoch:24 step:116075[D loss: 1.000053] [G loss: 1.000096]\n",
      "epoch:24 step:116080[D loss: 0.999918] [G loss: 1.000094]\n",
      "epoch:24 step:116085[D loss: 0.999948] [G loss: 1.000110]\n",
      "epoch:24 step:116090[D loss: 1.000079] [G loss: 0.999991]\n",
      "epoch:24 step:116095[D loss: 0.999942] [G loss: 1.000104]\n",
      "epoch:24 step:116100[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:24 step:116105[D loss: 0.999992] [G loss: 0.999965]\n",
      "epoch:24 step:116110[D loss: 1.000019] [G loss: 0.999980]\n",
      "epoch:24 step:116115[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:24 step:116120[D loss: 1.000062] [G loss: 0.999962]\n",
      "epoch:24 step:116125[D loss: 0.999947] [G loss: 1.000035]\n",
      "epoch:24 step:116130[D loss: 0.999966] [G loss: 1.000052]\n",
      "epoch:24 step:116135[D loss: 0.999990] [G loss: 1.000034]\n",
      "epoch:24 step:116140[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:24 step:116145[D loss: 0.999938] [G loss: 1.000086]\n",
      "epoch:24 step:116150[D loss: 1.000071] [G loss: 0.999991]\n",
      "epoch:24 step:116155[D loss: 0.999894] [G loss: 1.000106]\n",
      "epoch:24 step:116160[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:24 step:116165[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:24 step:116170[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:24 step:116175[D loss: 0.999946] [G loss: 1.000127]\n",
      "epoch:24 step:116180[D loss: 1.000027] [G loss: 1.000021]\n",
      "epoch:24 step:116185[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:24 step:116190[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:24 step:116195[D loss: 0.999947] [G loss: 1.000073]\n",
      "epoch:24 step:116200[D loss: 1.000005] [G loss: 0.999997]\n",
      "##############\n",
      "[2.45397421 2.04441282 2.20317992 3.49015401 1.43178088 7.45393138\n",
      " 2.28624739 3.80340572 4.00939043 5.22031862]\n",
      "##########\n",
      "epoch:24 step:116205[D loss: 0.999996] [G loss: 1.000013]\n",
      "epoch:24 step:116210[D loss: 1.000100] [G loss: 0.999943]\n",
      "epoch:24 step:116215[D loss: 1.000005] [G loss: 1.000101]\n",
      "epoch:24 step:116220[D loss: 0.999985] [G loss: 0.999964]\n",
      "epoch:24 step:116225[D loss: 0.999939] [G loss: 1.000111]\n",
      "epoch:24 step:116230[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:24 step:116235[D loss: 0.999920] [G loss: 1.000093]\n",
      "epoch:24 step:116240[D loss: 1.000035] [G loss: 0.999948]\n",
      "epoch:24 step:116245[D loss: 0.999971] [G loss: 1.000104]\n",
      "epoch:24 step:116250[D loss: 1.000088] [G loss: 0.999976]\n",
      "epoch:24 step:116255[D loss: 0.999947] [G loss: 1.000083]\n",
      "epoch:24 step:116260[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:24 step:116265[D loss: 0.999931] [G loss: 1.000094]\n",
      "epoch:24 step:116270[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:24 step:116275[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:24 step:116280[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:24 step:116285[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:24 step:116290[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:24 step:116295[D loss: 1.000042] [G loss: 0.999917]\n",
      "epoch:24 step:116300[D loss: 1.000008] [G loss: 0.999992]\n",
      "epoch:24 step:116305[D loss: 1.000075] [G loss: 0.999851]\n",
      "epoch:24 step:116310[D loss: 0.999964] [G loss: 1.000262]\n",
      "epoch:24 step:116315[D loss: 0.999811] [G loss: 1.000221]\n",
      "epoch:24 step:116320[D loss: 1.000048] [G loss: 0.999957]\n",
      "epoch:24 step:116325[D loss: 0.999950] [G loss: 1.000050]\n",
      "epoch:24 step:116330[D loss: 1.000032] [G loss: 0.999912]\n",
      "epoch:24 step:116335[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:24 step:116340[D loss: 1.000071] [G loss: 0.999865]\n",
      "epoch:24 step:116345[D loss: 0.999937] [G loss: 1.000050]\n",
      "epoch:24 step:116350[D loss: 0.999986] [G loss: 1.000000]\n",
      "epoch:24 step:116355[D loss: 0.999999] [G loss: 1.000045]\n",
      "epoch:24 step:116360[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:24 step:116365[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:24 step:116370[D loss: 0.999970] [G loss: 1.000143]\n",
      "epoch:24 step:116375[D loss: 0.999938] [G loss: 1.000150]\n",
      "epoch:24 step:116380[D loss: 0.999989] [G loss: 1.000101]\n",
      "epoch:24 step:116385[D loss: 1.000014] [G loss: 1.000087]\n",
      "epoch:24 step:116390[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:24 step:116395[D loss: 1.000008] [G loss: 0.999980]\n",
      "epoch:24 step:116400[D loss: 1.000006] [G loss: 0.999963]\n",
      "##############\n",
      "[2.46821264 2.07724323 1.97836343 3.97989608 1.36273727 6.89477114\n",
      " 2.30910711 3.7261993  3.9258189  5.19806002]\n",
      "##########\n",
      "epoch:24 step:116405[D loss: 0.999977] [G loss: 1.000008]\n",
      "epoch:24 step:116410[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:24 step:116415[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:24 step:116420[D loss: 0.999936] [G loss: 1.000116]\n",
      "epoch:24 step:116425[D loss: 0.999955] [G loss: 1.000110]\n",
      "epoch:24 step:116430[D loss: 1.000013] [G loss: 1.000077]\n",
      "epoch:24 step:116435[D loss: 0.999931] [G loss: 1.000128]\n",
      "epoch:24 step:116440[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:24 step:116445[D loss: 0.999982] [G loss: 1.000083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:116450[D loss: 0.999998] [G loss: 1.000023]\n",
      "epoch:24 step:116455[D loss: 0.999946] [G loss: 1.000133]\n",
      "epoch:24 step:116460[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:24 step:116465[D loss: 0.999999] [G loss: 1.000095]\n",
      "epoch:24 step:116470[D loss: 0.999930] [G loss: 1.000127]\n",
      "epoch:24 step:116475[D loss: 0.999998] [G loss: 1.000007]\n",
      "epoch:24 step:116480[D loss: 0.999999] [G loss: 1.000122]\n",
      "epoch:24 step:116485[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:24 step:116490[D loss: 0.999992] [G loss: 1.000013]\n",
      "epoch:24 step:116495[D loss: 0.999963] [G loss: 1.000133]\n",
      "epoch:24 step:116500[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:24 step:116505[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:24 step:116510[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:24 step:116515[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:24 step:116520[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:24 step:116525[D loss: 0.999955] [G loss: 1.000103]\n",
      "epoch:24 step:116530[D loss: 0.999972] [G loss: 1.000118]\n",
      "epoch:24 step:116535[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:24 step:116540[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:24 step:116545[D loss: 1.000029] [G loss: 0.999961]\n",
      "epoch:24 step:116550[D loss: 1.000011] [G loss: 1.000009]\n",
      "epoch:24 step:116555[D loss: 0.999991] [G loss: 0.999981]\n",
      "epoch:24 step:116560[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:24 step:116565[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:24 step:116570[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:24 step:116575[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:24 step:116580[D loss: 0.999939] [G loss: 1.000114]\n",
      "epoch:24 step:116585[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:24 step:116590[D loss: 0.999959] [G loss: 1.000136]\n",
      "epoch:24 step:116595[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:24 step:116600[D loss: 1.000029] [G loss: 1.000032]\n",
      "##############\n",
      "[2.51132027 2.09285016 2.09569056 3.87029362 1.38832026 7.84144126\n",
      " 2.3201655  3.73653971 3.96712905 4.91511609]\n",
      "##########\n",
      "epoch:24 step:116605[D loss: 0.999941] [G loss: 1.000105]\n",
      "epoch:24 step:116610[D loss: 0.999987] [G loss: 1.000133]\n",
      "epoch:24 step:116615[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:24 step:116620[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:24 step:116625[D loss: 1.000031] [G loss: 0.999990]\n",
      "epoch:24 step:116630[D loss: 0.999912] [G loss: 1.000138]\n",
      "epoch:24 step:116635[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:24 step:116640[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:24 step:116645[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:24 step:116650[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:24 step:116655[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:24 step:116660[D loss: 0.999936] [G loss: 1.000290]\n",
      "epoch:24 step:116665[D loss: 0.999867] [G loss: 1.000227]\n",
      "epoch:24 step:116670[D loss: 0.999996] [G loss: 1.000013]\n",
      "epoch:24 step:116675[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:24 step:116680[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:24 step:116685[D loss: 0.999966] [G loss: 1.000129]\n",
      "epoch:24 step:116690[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:24 step:116695[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:24 step:116700[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:24 step:116705[D loss: 1.000018] [G loss: 1.000016]\n",
      "epoch:24 step:116710[D loss: 0.999929] [G loss: 1.000151]\n",
      "epoch:24 step:116715[D loss: 0.999991] [G loss: 0.999939]\n",
      "epoch:24 step:116720[D loss: 1.000050] [G loss: 1.000150]\n",
      "epoch:24 step:116725[D loss: 1.000028] [G loss: 0.999914]\n",
      "epoch:24 step:116730[D loss: 0.999947] [G loss: 1.000140]\n",
      "epoch:24 step:116735[D loss: 0.999952] [G loss: 1.000216]\n",
      "epoch:24 step:116740[D loss: 0.999935] [G loss: 1.000099]\n",
      "epoch:24 step:116745[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:24 step:116750[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:24 step:116755[D loss: 0.999967] [G loss: 1.000109]\n",
      "epoch:24 step:116760[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:24 step:116765[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:24 step:116770[D loss: 0.999996] [G loss: 0.999973]\n",
      "epoch:24 step:116775[D loss: 0.999991] [G loss: 1.000111]\n",
      "epoch:24 step:116780[D loss: 1.000034] [G loss: 0.999975]\n",
      "epoch:24 step:116785[D loss: 1.000067] [G loss: 0.999963]\n",
      "epoch:24 step:116790[D loss: 0.999999] [G loss: 1.000230]\n",
      "epoch:24 step:116795[D loss: 0.999949] [G loss: 1.000019]\n",
      "epoch:24 step:116800[D loss: 0.999940] [G loss: 1.000081]\n",
      "##############\n",
      "[2.46558854 2.0761594  2.08052763 3.86406197 1.35841679 7.47065332\n",
      " 2.15115044 3.70687437 3.90135186 4.90326235]\n",
      "##########\n",
      "epoch:24 step:116805[D loss: 0.999989] [G loss: 1.000125]\n",
      "epoch:24 step:116810[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:24 step:116815[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:24 step:116820[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:24 step:116825[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:24 step:116830[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:24 step:116835[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:24 step:116840[D loss: 1.000032] [G loss: 0.999982]\n",
      "epoch:24 step:116845[D loss: 0.999944] [G loss: 1.000096]\n",
      "epoch:24 step:116850[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:24 step:116855[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:24 step:116860[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:24 step:116865[D loss: 0.999946] [G loss: 1.000077]\n",
      "epoch:24 step:116870[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:24 step:116875[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:24 step:116880[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:24 step:116885[D loss: 1.000027] [G loss: 1.000032]\n",
      "epoch:24 step:116890[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:24 step:116895[D loss: 1.000021] [G loss: 0.999991]\n",
      "epoch:24 step:116900[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:24 step:116905[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:24 step:116910[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:24 step:116915[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:24 step:116920[D loss: 1.000153] [G loss: 0.999850]\n",
      "epoch:24 step:116925[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:24 step:116930[D loss: 0.999927] [G loss: 1.000062]\n",
      "epoch:24 step:116935[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:24 step:116940[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:24 step:116945[D loss: 1.000035] [G loss: 1.000062]\n",
      "epoch:24 step:116950[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:24 step:116955[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:24 step:116960[D loss: 1.000035] [G loss: 1.000022]\n",
      "epoch:24 step:116965[D loss: 0.999949] [G loss: 1.000117]\n",
      "epoch:24 step:116970[D loss: 1.000035] [G loss: 1.000049]\n",
      "epoch:24 step:116975[D loss: 0.999943] [G loss: 1.000054]\n",
      "epoch:24 step:116980[D loss: 1.000088] [G loss: 0.999862]\n",
      "epoch:24 step:116985[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:24 step:116990[D loss: 0.999991] [G loss: 0.999951]\n",
      "epoch:24 step:116995[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:24 step:117000[D loss: 0.999934] [G loss: 1.000113]\n",
      "##############\n",
      "[2.44939394 2.19558648 2.13811099 4.21126186 1.4086267  7.24317222\n",
      " 2.36356341 3.7159708  3.91327999 5.73273894]\n",
      "##########\n",
      "epoch:24 step:117005[D loss: 0.999918] [G loss: 1.000147]\n",
      "epoch:24 step:117010[D loss: 1.000064] [G loss: 0.999970]\n",
      "epoch:24 step:117015[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:24 step:117020[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:24 step:117025[D loss: 1.000026] [G loss: 1.000136]\n",
      "epoch:24 step:117030[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:24 step:117035[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:24 step:117040[D loss: 0.999974] [G loss: 1.000028]\n",
      "epoch:24 step:117045[D loss: 1.000025] [G loss: 0.999952]\n",
      "epoch:24 step:117050[D loss: 1.000017] [G loss: 0.999922]\n",
      "epoch:24 step:117055[D loss: 1.000005] [G loss: 0.999945]\n",
      "epoch:24 step:117060[D loss: 0.999952] [G loss: 1.000056]\n",
      "epoch:24 step:117065[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:24 step:117070[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:24 step:117075[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:24 step:117080[D loss: 0.999998] [G loss: 1.000012]\n",
      "epoch:24 step:117085[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:24 step:117090[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:24 step:117095[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:24 step:117100[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:24 step:117105[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:24 step:117110[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:24 step:117115[D loss: 1.000039] [G loss: 0.999991]\n",
      "epoch:24 step:117120[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:24 step:117125[D loss: 1.000001] [G loss: 1.000036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:117130[D loss: 1.000029] [G loss: 1.000053]\n",
      "epoch:25 step:117135[D loss: 0.999917] [G loss: 1.000148]\n",
      "epoch:25 step:117140[D loss: 0.999993] [G loss: 1.000002]\n",
      "epoch:25 step:117145[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:25 step:117150[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:25 step:117155[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:25 step:117160[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:25 step:117165[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:25 step:117170[D loss: 0.999955] [G loss: 1.000104]\n",
      "epoch:25 step:117175[D loss: 1.000066] [G loss: 1.000004]\n",
      "epoch:25 step:117180[D loss: 1.000053] [G loss: 0.999954]\n",
      "epoch:25 step:117185[D loss: 0.999934] [G loss: 1.000094]\n",
      "epoch:25 step:117190[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:25 step:117195[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:25 step:117200[D loss: 0.999981] [G loss: 1.000047]\n",
      "##############\n",
      "[2.435403   2.11534021 2.15344761 4.06309448 1.42530424 7.70739494\n",
      " 2.35367203 3.8320383  3.92430502 6.05187668]\n",
      "##########\n",
      "epoch:25 step:117205[D loss: 0.999952] [G loss: 1.000065]\n",
      "epoch:25 step:117210[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:25 step:117215[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:25 step:117220[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:25 step:117225[D loss: 0.999948] [G loss: 1.000100]\n",
      "epoch:25 step:117230[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:25 step:117235[D loss: 1.000028] [G loss: 1.000017]\n",
      "epoch:25 step:117240[D loss: 0.999947] [G loss: 1.000069]\n",
      "epoch:25 step:117245[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:25 step:117250[D loss: 0.999961] [G loss: 1.000110]\n",
      "epoch:25 step:117255[D loss: 0.999978] [G loss: 1.000119]\n",
      "epoch:25 step:117260[D loss: 0.999993] [G loss: 1.000114]\n",
      "epoch:25 step:117265[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:25 step:117270[D loss: 1.000006] [G loss: 0.999973]\n",
      "epoch:25 step:117275[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:25 step:117280[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:25 step:117285[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:25 step:117290[D loss: 0.999948] [G loss: 1.000127]\n",
      "epoch:25 step:117295[D loss: 0.999952] [G loss: 1.000195]\n",
      "epoch:25 step:117300[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:25 step:117305[D loss: 1.000031] [G loss: 1.000109]\n",
      "epoch:25 step:117310[D loss: 0.999911] [G loss: 1.000151]\n",
      "epoch:25 step:117315[D loss: 0.999968] [G loss: 1.000099]\n",
      "epoch:25 step:117320[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:25 step:117325[D loss: 1.000086] [G loss: 0.999956]\n",
      "epoch:25 step:117330[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:25 step:117335[D loss: 1.000017] [G loss: 0.999904]\n",
      "epoch:25 step:117340[D loss: 0.999983] [G loss: 1.000003]\n",
      "epoch:25 step:117345[D loss: 0.999957] [G loss: 1.000066]\n",
      "epoch:25 step:117350[D loss: 0.999934] [G loss: 1.000131]\n",
      "epoch:25 step:117355[D loss: 0.999927] [G loss: 1.000149]\n",
      "epoch:25 step:117360[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:25 step:117365[D loss: 0.999954] [G loss: 1.000047]\n",
      "epoch:25 step:117370[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:25 step:117375[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:25 step:117380[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:25 step:117385[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:25 step:117390[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:25 step:117395[D loss: 0.999958] [G loss: 1.000102]\n",
      "epoch:25 step:117400[D loss: 0.999959] [G loss: 1.000080]\n",
      "##############\n",
      "[2.47957581 2.15011322 2.17133846 3.96750642 1.47313694 6.61413001\n",
      " 2.35062657 3.869694   3.97609771 5.09654577]\n",
      "##########\n",
      "epoch:25 step:117405[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:25 step:117410[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:25 step:117415[D loss: 0.999985] [G loss: 1.000125]\n",
      "epoch:25 step:117420[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:25 step:117425[D loss: 0.999947] [G loss: 1.000096]\n",
      "epoch:25 step:117430[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:25 step:117435[D loss: 1.000068] [G loss: 1.000048]\n",
      "epoch:25 step:117440[D loss: 0.999971] [G loss: 1.000169]\n",
      "epoch:25 step:117445[D loss: 1.000169] [G loss: 0.999839]\n",
      "epoch:25 step:117450[D loss: 0.999958] [G loss: 1.000007]\n",
      "epoch:25 step:117455[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:25 step:117460[D loss: 0.999963] [G loss: 1.000028]\n",
      "epoch:25 step:117465[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:25 step:117470[D loss: 1.000041] [G loss: 1.000013]\n",
      "epoch:25 step:117475[D loss: 1.000046] [G loss: 0.999947]\n",
      "epoch:25 step:117480[D loss: 1.000000] [G loss: 1.000006]\n",
      "epoch:25 step:117485[D loss: 0.999933] [G loss: 1.000209]\n",
      "epoch:25 step:117490[D loss: 0.999906] [G loss: 1.000151]\n",
      "epoch:25 step:117495[D loss: 0.999890] [G loss: 1.000113]\n",
      "epoch:25 step:117500[D loss: 1.000000] [G loss: 0.999963]\n",
      "epoch:25 step:117505[D loss: 0.999996] [G loss: 0.999990]\n",
      "epoch:25 step:117510[D loss: 1.000033] [G loss: 0.999984]\n",
      "epoch:25 step:117515[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:25 step:117520[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:25 step:117525[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:25 step:117530[D loss: 0.999964] [G loss: 1.000143]\n",
      "epoch:25 step:117535[D loss: 0.999935] [G loss: 1.000066]\n",
      "epoch:25 step:117540[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:25 step:117545[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:25 step:117550[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:25 step:117555[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:25 step:117560[D loss: 1.000004] [G loss: 1.000015]\n",
      "epoch:25 step:117565[D loss: 0.999995] [G loss: 1.000103]\n",
      "epoch:25 step:117570[D loss: 1.000105] [G loss: 0.999976]\n",
      "epoch:25 step:117575[D loss: 0.999930] [G loss: 1.000118]\n",
      "epoch:25 step:117580[D loss: 0.999939] [G loss: 1.000110]\n",
      "epoch:25 step:117585[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:25 step:117590[D loss: 0.999984] [G loss: 1.000009]\n",
      "epoch:25 step:117595[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:25 step:117600[D loss: 1.000054] [G loss: 1.000021]\n",
      "##############\n",
      "[2.53098621 2.19193112 2.30194144 3.9073994  1.48155638 7.78073097\n",
      " 2.5224975  3.78779287 4.02753472 4.70919939]\n",
      "##########\n",
      "epoch:25 step:117605[D loss: 1.000016] [G loss: 1.000127]\n",
      "epoch:25 step:117610[D loss: 0.999942] [G loss: 1.000199]\n",
      "epoch:25 step:117615[D loss: 0.999935] [G loss: 1.000237]\n",
      "epoch:25 step:117620[D loss: 0.999944] [G loss: 1.000157]\n",
      "epoch:25 step:117625[D loss: 0.999917] [G loss: 1.000157]\n",
      "epoch:25 step:117630[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:25 step:117635[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:25 step:117640[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:25 step:117645[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:25 step:117650[D loss: 1.000033] [G loss: 0.999970]\n",
      "epoch:25 step:117655[D loss: 0.999947] [G loss: 1.000096]\n",
      "epoch:25 step:117660[D loss: 1.000070] [G loss: 0.999986]\n",
      "epoch:25 step:117665[D loss: 1.000110] [G loss: 0.999911]\n",
      "epoch:25 step:117670[D loss: 0.999895] [G loss: 1.000091]\n",
      "epoch:25 step:117675[D loss: 1.000020] [G loss: 1.000042]\n",
      "epoch:25 step:117680[D loss: 0.999932] [G loss: 1.000083]\n",
      "epoch:25 step:117685[D loss: 0.999904] [G loss: 1.000202]\n",
      "epoch:25 step:117690[D loss: 1.000016] [G loss: 1.000105]\n",
      "epoch:25 step:117695[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:25 step:117700[D loss: 0.999994] [G loss: 1.000143]\n",
      "epoch:25 step:117705[D loss: 0.999922] [G loss: 1.000094]\n",
      "epoch:25 step:117710[D loss: 1.000055] [G loss: 0.999974]\n",
      "epoch:25 step:117715[D loss: 1.000095] [G loss: 0.999964]\n",
      "epoch:25 step:117720[D loss: 1.000153] [G loss: 0.999890]\n",
      "epoch:25 step:117725[D loss: 0.999899] [G loss: 1.000198]\n",
      "epoch:25 step:117730[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:25 step:117735[D loss: 1.000006] [G loss: 1.000002]\n",
      "epoch:25 step:117740[D loss: 0.999945] [G loss: 1.000150]\n",
      "epoch:25 step:117745[D loss: 0.999969] [G loss: 1.000152]\n",
      "epoch:25 step:117750[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:25 step:117755[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:25 step:117760[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:25 step:117765[D loss: 1.000011] [G loss: 1.000043]\n",
      "epoch:25 step:117770[D loss: 0.999986] [G loss: 1.000110]\n",
      "epoch:25 step:117775[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:25 step:117780[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:25 step:117785[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:25 step:117790[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:25 step:117795[D loss: 0.999952] [G loss: 1.000072]\n",
      "epoch:25 step:117800[D loss: 0.999988] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.48933142 2.12276731 2.12786825 3.61882262 1.43691459 7.51487052\n",
      " 2.22819329 3.74286342 3.97274917 5.80376818]\n",
      "##########\n",
      "epoch:25 step:117805[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:25 step:117810[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:25 step:117815[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:25 step:117820[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:25 step:117825[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:25 step:117830[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:25 step:117835[D loss: 1.000005] [G loss: 0.999989]\n",
      "epoch:25 step:117840[D loss: 0.999975] [G loss: 1.000006]\n",
      "epoch:25 step:117845[D loss: 1.000020] [G loss: 0.999969]\n",
      "epoch:25 step:117850[D loss: 1.000083] [G loss: 0.999881]\n",
      "epoch:25 step:117855[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:25 step:117860[D loss: 1.000056] [G loss: 0.999997]\n",
      "epoch:25 step:117865[D loss: 0.999934] [G loss: 1.000128]\n",
      "epoch:25 step:117870[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:25 step:117875[D loss: 0.999964] [G loss: 1.000021]\n",
      "epoch:25 step:117880[D loss: 0.999999] [G loss: 0.999957]\n",
      "epoch:25 step:117885[D loss: 0.999943] [G loss: 1.000090]\n",
      "epoch:25 step:117890[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:25 step:117895[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:25 step:117900[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:25 step:117905[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:25 step:117910[D loss: 1.000029] [G loss: 1.000016]\n",
      "epoch:25 step:117915[D loss: 0.999919] [G loss: 1.000110]\n",
      "epoch:25 step:117920[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:25 step:117925[D loss: 1.000008] [G loss: 1.000017]\n",
      "epoch:25 step:117930[D loss: 0.999970] [G loss: 1.000123]\n",
      "epoch:25 step:117935[D loss: 0.999941] [G loss: 1.000089]\n",
      "epoch:25 step:117940[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:25 step:117945[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:25 step:117950[D loss: 1.000011] [G loss: 1.000049]\n",
      "epoch:25 step:117955[D loss: 1.000099] [G loss: 0.999896]\n",
      "epoch:25 step:117960[D loss: 0.999925] [G loss: 1.000103]\n",
      "epoch:25 step:117965[D loss: 0.999947] [G loss: 1.000058]\n",
      "epoch:25 step:117970[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:25 step:117975[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:25 step:117980[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:25 step:117985[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:25 step:117990[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:25 step:117995[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:25 step:118000[D loss: 0.999968] [G loss: 1.000071]\n",
      "##############\n",
      "[2.54278623 2.13243946 2.20284068 4.44176613 1.43425916 7.75459939\n",
      " 2.36152874 3.69977966 3.91611799 4.34335816]\n",
      "##########\n",
      "epoch:25 step:118005[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:25 step:118010[D loss: 0.999947] [G loss: 1.000095]\n",
      "epoch:25 step:118015[D loss: 0.999970] [G loss: 1.000144]\n",
      "epoch:25 step:118020[D loss: 0.999983] [G loss: 1.000094]\n",
      "epoch:25 step:118025[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:25 step:118030[D loss: 0.999937] [G loss: 1.000140]\n",
      "epoch:25 step:118035[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:25 step:118040[D loss: 0.999933] [G loss: 1.000127]\n",
      "epoch:25 step:118045[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:25 step:118050[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:25 step:118055[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:25 step:118060[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:25 step:118065[D loss: 1.000018] [G loss: 1.000023]\n",
      "epoch:25 step:118070[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:25 step:118075[D loss: 0.999956] [G loss: 1.000069]\n",
      "epoch:25 step:118080[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:25 step:118085[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:25 step:118090[D loss: 0.999974] [G loss: 1.000111]\n",
      "epoch:25 step:118095[D loss: 1.000043] [G loss: 1.000009]\n",
      "epoch:25 step:118100[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:25 step:118105[D loss: 0.999933] [G loss: 1.000076]\n",
      "epoch:25 step:118110[D loss: 0.999981] [G loss: 1.000136]\n",
      "epoch:25 step:118115[D loss: 1.000001] [G loss: 1.000164]\n",
      "epoch:25 step:118120[D loss: 0.999965] [G loss: 1.000153]\n",
      "epoch:25 step:118125[D loss: 1.000015] [G loss: 1.000233]\n",
      "epoch:25 step:118130[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:25 step:118135[D loss: 1.000019] [G loss: 1.000103]\n",
      "epoch:25 step:118140[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:25 step:118145[D loss: 0.999939] [G loss: 1.000053]\n",
      "epoch:25 step:118150[D loss: 1.000005] [G loss: 0.999988]\n",
      "epoch:25 step:118155[D loss: 1.000001] [G loss: 0.999964]\n",
      "epoch:25 step:118160[D loss: 1.000012] [G loss: 0.999969]\n",
      "epoch:25 step:118165[D loss: 0.999959] [G loss: 1.000011]\n",
      "epoch:25 step:118170[D loss: 1.000007] [G loss: 0.999939]\n",
      "epoch:25 step:118175[D loss: 1.000118] [G loss: 0.999837]\n",
      "epoch:25 step:118180[D loss: 1.000003] [G loss: 1.000052]\n",
      "epoch:25 step:118185[D loss: 1.000026] [G loss: 0.999992]\n",
      "epoch:25 step:118190[D loss: 0.999896] [G loss: 1.000163]\n",
      "epoch:25 step:118195[D loss: 0.999989] [G loss: 1.000106]\n",
      "epoch:25 step:118200[D loss: 0.999999] [G loss: 1.000132]\n",
      "##############\n",
      "[2.45227153 2.26167316 2.18679527 4.23655118 1.42126082 7.44646941\n",
      " 2.28951473 3.77708492 3.92599383 6.56939502]\n",
      "##########\n",
      "epoch:25 step:118205[D loss: 1.000050] [G loss: 0.999988]\n",
      "epoch:25 step:118210[D loss: 1.000099] [G loss: 1.000263]\n",
      "epoch:25 step:118215[D loss: 0.999917] [G loss: 1.000216]\n",
      "epoch:25 step:118220[D loss: 0.999938] [G loss: 1.000091]\n",
      "epoch:25 step:118225[D loss: 0.999914] [G loss: 1.000216]\n",
      "epoch:25 step:118230[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:25 step:118235[D loss: 0.999938] [G loss: 1.000050]\n",
      "epoch:25 step:118240[D loss: 1.000022] [G loss: 0.999976]\n",
      "epoch:25 step:118245[D loss: 0.999940] [G loss: 1.000054]\n",
      "epoch:25 step:118250[D loss: 1.000022] [G loss: 1.000016]\n",
      "epoch:25 step:118255[D loss: 1.000075] [G loss: 0.999966]\n",
      "epoch:25 step:118260[D loss: 1.000074] [G loss: 1.000080]\n",
      "epoch:25 step:118265[D loss: 1.000027] [G loss: 0.999939]\n",
      "epoch:25 step:118270[D loss: 0.999980] [G loss: 1.000021]\n",
      "epoch:25 step:118275[D loss: 0.999971] [G loss: 1.000136]\n",
      "epoch:25 step:118280[D loss: 1.000019] [G loss: 1.000047]\n",
      "epoch:25 step:118285[D loss: 0.999880] [G loss: 1.000214]\n",
      "epoch:25 step:118290[D loss: 1.000138] [G loss: 0.999957]\n",
      "epoch:25 step:118295[D loss: 0.999950] [G loss: 1.000228]\n",
      "epoch:25 step:118300[D loss: 1.000003] [G loss: 1.000156]\n",
      "epoch:25 step:118305[D loss: 0.999904] [G loss: 1.000150]\n",
      "epoch:25 step:118310[D loss: 0.999973] [G loss: 1.000183]\n",
      "epoch:25 step:118315[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:25 step:118320[D loss: 1.000008] [G loss: 1.000076]\n",
      "epoch:25 step:118325[D loss: 0.999965] [G loss: 1.000031]\n",
      "epoch:25 step:118330[D loss: 1.000037] [G loss: 0.999945]\n",
      "epoch:25 step:118335[D loss: 1.000012] [G loss: 0.999941]\n",
      "epoch:25 step:118340[D loss: 0.999956] [G loss: 1.000053]\n",
      "epoch:25 step:118345[D loss: 1.000043] [G loss: 0.999977]\n",
      "epoch:25 step:118350[D loss: 1.000116] [G loss: 0.999745]\n",
      "epoch:25 step:118355[D loss: 1.000080] [G loss: 0.999847]\n",
      "epoch:25 step:118360[D loss: 0.999846] [G loss: 1.000182]\n",
      "epoch:25 step:118365[D loss: 0.999984] [G loss: 1.000129]\n",
      "epoch:25 step:118370[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:25 step:118375[D loss: 1.000027] [G loss: 1.000036]\n",
      "epoch:25 step:118380[D loss: 0.999949] [G loss: 1.000059]\n",
      "epoch:25 step:118385[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:25 step:118390[D loss: 0.999961] [G loss: 1.000031]\n",
      "epoch:25 step:118395[D loss: 0.999965] [G loss: 1.000121]\n",
      "epoch:25 step:118400[D loss: 0.999969] [G loss: 1.000126]\n",
      "##############\n",
      "[2.52274817 2.29855658 2.20169112 3.95484504 1.46282046 7.57903358\n",
      " 2.33142558 3.81684049 4.14314979 5.73872365]\n",
      "##########\n",
      "epoch:25 step:118405[D loss: 0.999934] [G loss: 1.000156]\n",
      "epoch:25 step:118410[D loss: 0.999990] [G loss: 1.000095]\n",
      "epoch:25 step:118415[D loss: 1.000117] [G loss: 0.999939]\n",
      "epoch:25 step:118420[D loss: 0.999970] [G loss: 1.000016]\n",
      "epoch:25 step:118425[D loss: 1.000005] [G loss: 1.000038]\n",
      "epoch:25 step:118430[D loss: 0.999913] [G loss: 1.000153]\n",
      "epoch:25 step:118435[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:25 step:118440[D loss: 1.000000] [G loss: 1.000066]\n",
      "epoch:25 step:118445[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:25 step:118450[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:25 step:118455[D loss: 1.000035] [G loss: 0.999999]\n",
      "epoch:25 step:118460[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:25 step:118465[D loss: 0.999984] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:118470[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:25 step:118475[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:25 step:118480[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:25 step:118485[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:25 step:118490[D loss: 1.000025] [G loss: 1.000002]\n",
      "epoch:25 step:118495[D loss: 0.999942] [G loss: 1.000084]\n",
      "epoch:25 step:118500[D loss: 1.000009] [G loss: 0.999997]\n",
      "epoch:25 step:118505[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:25 step:118510[D loss: 0.999931] [G loss: 1.000078]\n",
      "epoch:25 step:118515[D loss: 0.999961] [G loss: 1.000145]\n",
      "epoch:25 step:118520[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:25 step:118525[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:25 step:118530[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:25 step:118535[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:25 step:118540[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:25 step:118545[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:25 step:118550[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:25 step:118555[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:25 step:118560[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:25 step:118565[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:25 step:118570[D loss: 0.999920] [G loss: 1.000156]\n",
      "epoch:25 step:118575[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:25 step:118580[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:25 step:118585[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:25 step:118590[D loss: 1.000004] [G loss: 1.000048]\n",
      "epoch:25 step:118595[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:25 step:118600[D loss: 0.999962] [G loss: 1.000113]\n",
      "##############\n",
      "[2.55709212 2.2477936  2.31919388 4.13618488 1.47727556 7.79913785\n",
      " 2.18807356 3.93868613 4.01901936 6.58653876]\n",
      "##########\n",
      "epoch:25 step:118605[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:25 step:118610[D loss: 0.999990] [G loss: 1.000090]\n",
      "epoch:25 step:118615[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:25 step:118620[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:25 step:118625[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:25 step:118630[D loss: 0.999959] [G loss: 1.000062]\n",
      "epoch:25 step:118635[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:25 step:118640[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:25 step:118645[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:25 step:118650[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:25 step:118655[D loss: 1.000024] [G loss: 1.000078]\n",
      "epoch:25 step:118660[D loss: 0.999929] [G loss: 1.000115]\n",
      "epoch:25 step:118665[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:25 step:118670[D loss: 1.000023] [G loss: 1.000001]\n",
      "epoch:25 step:118675[D loss: 0.999947] [G loss: 1.000137]\n",
      "epoch:25 step:118680[D loss: 1.000052] [G loss: 1.000015]\n",
      "epoch:25 step:118685[D loss: 0.999955] [G loss: 1.000056]\n",
      "epoch:25 step:118690[D loss: 0.999949] [G loss: 1.000078]\n",
      "epoch:25 step:118695[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:25 step:118700[D loss: 0.999936] [G loss: 1.000186]\n",
      "epoch:25 step:118705[D loss: 1.000125] [G loss: 0.999953]\n",
      "epoch:25 step:118710[D loss: 0.999935] [G loss: 1.000035]\n",
      "epoch:25 step:118715[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:25 step:118720[D loss: 1.000014] [G loss: 1.000000]\n",
      "epoch:25 step:118725[D loss: 1.000006] [G loss: 0.999992]\n",
      "epoch:25 step:118730[D loss: 1.000067] [G loss: 0.999971]\n",
      "epoch:25 step:118735[D loss: 1.000020] [G loss: 1.000029]\n",
      "epoch:25 step:118740[D loss: 1.000054] [G loss: 0.999937]\n",
      "epoch:25 step:118745[D loss: 1.000039] [G loss: 0.999858]\n",
      "epoch:25 step:118750[D loss: 0.999941] [G loss: 1.000035]\n",
      "epoch:25 step:118755[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:25 step:118760[D loss: 0.999990] [G loss: 1.000017]\n",
      "epoch:25 step:118765[D loss: 0.999945] [G loss: 1.000077]\n",
      "epoch:25 step:118770[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:25 step:118775[D loss: 1.000023] [G loss: 1.000013]\n",
      "epoch:25 step:118780[D loss: 0.999940] [G loss: 1.000082]\n",
      "epoch:25 step:118785[D loss: 0.999945] [G loss: 1.000061]\n",
      "epoch:25 step:118790[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:25 step:118795[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:25 step:118800[D loss: 0.999976] [G loss: 1.000033]\n",
      "##############\n",
      "[2.45453052 2.10248382 2.17827168 4.1853335  1.39613941 9.27426719\n",
      " 2.30873582 3.78241232 3.90613397 5.04887328]\n",
      "##########\n",
      "epoch:25 step:118805[D loss: 0.999997] [G loss: 0.999983]\n",
      "epoch:25 step:118810[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:25 step:118815[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:25 step:118820[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:25 step:118825[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:25 step:118830[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:25 step:118835[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:25 step:118840[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:25 step:118845[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:25 step:118850[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:25 step:118855[D loss: 1.000049] [G loss: 1.000001]\n",
      "epoch:25 step:118860[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:25 step:118865[D loss: 1.000002] [G loss: 1.000025]\n",
      "epoch:25 step:118870[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:25 step:118875[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:25 step:118880[D loss: 1.000020] [G loss: 1.000021]\n",
      "epoch:25 step:118885[D loss: 0.999956] [G loss: 1.000105]\n",
      "epoch:25 step:118890[D loss: 0.999929] [G loss: 1.000107]\n",
      "epoch:25 step:118895[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:25 step:118900[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:25 step:118905[D loss: 1.000017] [G loss: 0.999957]\n",
      "epoch:25 step:118910[D loss: 0.999900] [G loss: 1.000150]\n",
      "epoch:25 step:118915[D loss: 1.000002] [G loss: 1.000121]\n",
      "epoch:25 step:118920[D loss: 0.999980] [G loss: 0.999999]\n",
      "epoch:25 step:118925[D loss: 0.999975] [G loss: 1.000172]\n",
      "epoch:25 step:118930[D loss: 0.999939] [G loss: 1.000073]\n",
      "epoch:25 step:118935[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:25 step:118940[D loss: 1.000014] [G loss: 1.000027]\n",
      "epoch:25 step:118945[D loss: 1.000093] [G loss: 0.999963]\n",
      "epoch:25 step:118950[D loss: 1.000051] [G loss: 0.999890]\n",
      "epoch:25 step:118955[D loss: 1.000047] [G loss: 0.999933]\n",
      "epoch:25 step:118960[D loss: 1.000146] [G loss: 0.999917]\n",
      "epoch:25 step:118965[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:25 step:118970[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:25 step:118975[D loss: 1.000017] [G loss: 0.999981]\n",
      "epoch:25 step:118980[D loss: 0.999974] [G loss: 1.000116]\n",
      "epoch:25 step:118985[D loss: 0.999894] [G loss: 1.000218]\n",
      "epoch:25 step:118990[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:25 step:118995[D loss: 1.000053] [G loss: 0.999988]\n",
      "epoch:25 step:119000[D loss: 0.999996] [G loss: 1.000036]\n",
      "##############\n",
      "[2.41504174 2.07265902 2.02627511 3.65921098 1.2867708  7.48942667\n",
      " 2.11954418 3.92228781 3.98403737 5.23680911]\n",
      "##########\n",
      "epoch:25 step:119005[D loss: 1.000026] [G loss: 0.999938]\n",
      "epoch:25 step:119010[D loss: 1.000008] [G loss: 1.000007]\n",
      "epoch:25 step:119015[D loss: 1.000237] [G loss: 0.999778]\n",
      "epoch:25 step:119020[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:25 step:119025[D loss: 0.999983] [G loss: 0.999953]\n",
      "epoch:25 step:119030[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:25 step:119035[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:25 step:119040[D loss: 0.999944] [G loss: 1.000073]\n",
      "epoch:25 step:119045[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:25 step:119050[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:25 step:119055[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:25 step:119060[D loss: 1.000071] [G loss: 0.999966]\n",
      "epoch:25 step:119065[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:25 step:119070[D loss: 0.999927] [G loss: 1.000011]\n",
      "epoch:25 step:119075[D loss: 1.000038] [G loss: 1.000098]\n",
      "epoch:25 step:119080[D loss: 0.999941] [G loss: 1.000064]\n",
      "epoch:25 step:119085[D loss: 1.000024] [G loss: 1.000090]\n",
      "epoch:25 step:119090[D loss: 0.999920] [G loss: 1.000091]\n",
      "epoch:25 step:119095[D loss: 1.000019] [G loss: 1.000045]\n",
      "epoch:25 step:119100[D loss: 0.999889] [G loss: 1.000137]\n",
      "epoch:25 step:119105[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:25 step:119110[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:25 step:119115[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:25 step:119120[D loss: 1.000001] [G loss: 1.000005]\n",
      "epoch:25 step:119125[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:25 step:119130[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:25 step:119135[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:25 step:119140[D loss: 0.999986] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:119145[D loss: 0.999949] [G loss: 1.000036]\n",
      "epoch:25 step:119150[D loss: 0.999960] [G loss: 1.000039]\n",
      "epoch:25 step:119155[D loss: 1.000010] [G loss: 1.000085]\n",
      "epoch:25 step:119160[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:25 step:119165[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:25 step:119170[D loss: 0.999961] [G loss: 1.000036]\n",
      "epoch:25 step:119175[D loss: 0.999962] [G loss: 1.000115]\n",
      "epoch:25 step:119180[D loss: 0.999984] [G loss: 1.000010]\n",
      "epoch:25 step:119185[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:25 step:119190[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:25 step:119195[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:25 step:119200[D loss: 0.999985] [G loss: 1.000016]\n",
      "##############\n",
      "[2.41315835 2.13680646 2.14843772 3.90293935 1.44164092 7.46907844\n",
      " 2.36860821 3.79918189 4.03236423 5.19928423]\n",
      "##########\n",
      "epoch:25 step:119205[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:25 step:119210[D loss: 0.999996] [G loss: 1.000041]\n",
      "epoch:25 step:119215[D loss: 0.999943] [G loss: 1.000154]\n",
      "epoch:25 step:119220[D loss: 0.999949] [G loss: 1.000115]\n",
      "epoch:25 step:119225[D loss: 0.999929] [G loss: 1.000127]\n",
      "epoch:25 step:119230[D loss: 0.999986] [G loss: 1.000138]\n",
      "epoch:25 step:119235[D loss: 1.000013] [G loss: 1.000075]\n",
      "epoch:25 step:119240[D loss: 1.000006] [G loss: 0.999997]\n",
      "epoch:25 step:119245[D loss: 0.999947] [G loss: 1.000131]\n",
      "epoch:25 step:119250[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:25 step:119255[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:25 step:119260[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:25 step:119265[D loss: 1.000078] [G loss: 0.999894]\n",
      "epoch:25 step:119270[D loss: 1.000002] [G loss: 0.999988]\n",
      "epoch:25 step:119275[D loss: 0.999909] [G loss: 1.000112]\n",
      "epoch:25 step:119280[D loss: 0.999891] [G loss: 1.000232]\n",
      "epoch:25 step:119285[D loss: 0.999987] [G loss: 1.000201]\n",
      "epoch:25 step:119290[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:25 step:119295[D loss: 1.000024] [G loss: 1.000045]\n",
      "epoch:25 step:119300[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:25 step:119305[D loss: 1.000049] [G loss: 0.999973]\n",
      "epoch:25 step:119310[D loss: 0.999947] [G loss: 1.000064]\n",
      "epoch:25 step:119315[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:25 step:119320[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:25 step:119325[D loss: 0.999972] [G loss: 1.000104]\n",
      "epoch:25 step:119330[D loss: 0.999955] [G loss: 1.000106]\n",
      "epoch:25 step:119335[D loss: 1.000033] [G loss: 0.999913]\n",
      "epoch:25 step:119340[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:25 step:119345[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:25 step:119350[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:25 step:119355[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:25 step:119360[D loss: 0.999966] [G loss: 1.000113]\n",
      "epoch:25 step:119365[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:25 step:119370[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:25 step:119375[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:25 step:119380[D loss: 0.999985] [G loss: 1.000082]\n",
      "epoch:25 step:119385[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:25 step:119390[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:25 step:119395[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:25 step:119400[D loss: 0.999992] [G loss: 1.000035]\n",
      "##############\n",
      "[2.51809952 2.14377071 2.1165768  3.81211273 1.46409284 7.13717102\n",
      " 2.3859179  3.8498214  4.02152398 5.51876755]\n",
      "##########\n",
      "epoch:25 step:119405[D loss: 0.999991] [G loss: 1.000092]\n",
      "epoch:25 step:119410[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:25 step:119415[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:25 step:119420[D loss: 1.000268] [G loss: 0.999771]\n",
      "epoch:25 step:119425[D loss: 0.999930] [G loss: 1.000055]\n",
      "epoch:25 step:119430[D loss: 1.000000] [G loss: 1.000007]\n",
      "epoch:25 step:119435[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:25 step:119440[D loss: 0.999930] [G loss: 1.000063]\n",
      "epoch:25 step:119445[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:25 step:119450[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:25 step:119455[D loss: 0.999992] [G loss: 0.999976]\n",
      "epoch:25 step:119460[D loss: 0.999929] [G loss: 1.000086]\n",
      "epoch:25 step:119465[D loss: 1.000138] [G loss: 0.999938]\n",
      "epoch:25 step:119470[D loss: 1.000147] [G loss: 0.999918]\n",
      "epoch:25 step:119475[D loss: 1.000009] [G loss: 0.999890]\n",
      "epoch:25 step:119480[D loss: 0.999934] [G loss: 1.000176]\n",
      "epoch:25 step:119485[D loss: 0.999909] [G loss: 1.000173]\n",
      "epoch:25 step:119490[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:25 step:119495[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:25 step:119500[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:25 step:119505[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:25 step:119510[D loss: 1.000000] [G loss: 0.999925]\n",
      "epoch:25 step:119515[D loss: 1.000022] [G loss: 0.999966]\n",
      "epoch:25 step:119520[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:25 step:119525[D loss: 1.000005] [G loss: 1.000005]\n",
      "epoch:25 step:119530[D loss: 1.000048] [G loss: 0.999887]\n",
      "epoch:25 step:119535[D loss: 0.999893] [G loss: 1.000092]\n",
      "epoch:25 step:119540[D loss: 1.000055] [G loss: 1.000063]\n",
      "epoch:25 step:119545[D loss: 0.999872] [G loss: 1.000140]\n",
      "epoch:25 step:119550[D loss: 0.999964] [G loss: 1.000041]\n",
      "epoch:25 step:119555[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:25 step:119560[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:25 step:119565[D loss: 1.000022] [G loss: 1.000009]\n",
      "epoch:25 step:119570[D loss: 1.000025] [G loss: 1.000052]\n",
      "epoch:25 step:119575[D loss: 1.000060] [G loss: 1.000001]\n",
      "epoch:25 step:119580[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:25 step:119585[D loss: 1.000009] [G loss: 1.000027]\n",
      "epoch:25 step:119590[D loss: 0.999938] [G loss: 1.000345]\n",
      "epoch:25 step:119595[D loss: 1.000094] [G loss: 0.999953]\n",
      "epoch:25 step:119600[D loss: 0.999931] [G loss: 1.000070]\n",
      "##############\n",
      "[2.49066546 2.13020729 2.09438425 3.57682847 1.37978265 7.37190771\n",
      " 2.2962774  3.59390495 3.97183842 5.41337981]\n",
      "##########\n",
      "epoch:25 step:119605[D loss: 1.000246] [G loss: 0.999873]\n",
      "epoch:25 step:119610[D loss: 1.000006] [G loss: 1.000085]\n",
      "epoch:25 step:119615[D loss: 0.999913] [G loss: 1.000115]\n",
      "epoch:25 step:119620[D loss: 1.000016] [G loss: 1.000006]\n",
      "epoch:25 step:119625[D loss: 1.000099] [G loss: 0.999855]\n",
      "epoch:25 step:119630[D loss: 0.999821] [G loss: 1.000161]\n",
      "epoch:25 step:119635[D loss: 0.999941] [G loss: 1.000079]\n",
      "epoch:25 step:119640[D loss: 0.999950] [G loss: 1.000047]\n",
      "epoch:25 step:119645[D loss: 1.000020] [G loss: 0.999994]\n",
      "epoch:25 step:119650[D loss: 1.000019] [G loss: 1.000028]\n",
      "epoch:25 step:119655[D loss: 0.999919] [G loss: 1.000128]\n",
      "epoch:25 step:119660[D loss: 1.000086] [G loss: 1.000055]\n",
      "epoch:25 step:119665[D loss: 1.000082] [G loss: 0.999957]\n",
      "epoch:25 step:119670[D loss: 1.000022] [G loss: 0.999976]\n",
      "epoch:25 step:119675[D loss: 1.000028] [G loss: 1.000407]\n",
      "epoch:25 step:119680[D loss: 0.999925] [G loss: 1.000118]\n",
      "epoch:25 step:119685[D loss: 0.999923] [G loss: 1.000101]\n",
      "epoch:25 step:119690[D loss: 0.999979] [G loss: 1.000106]\n",
      "epoch:25 step:119695[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:25 step:119700[D loss: 1.000010] [G loss: 0.999929]\n",
      "epoch:25 step:119705[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:25 step:119710[D loss: 1.000031] [G loss: 1.000061]\n",
      "epoch:25 step:119715[D loss: 0.999992] [G loss: 1.000015]\n",
      "epoch:25 step:119720[D loss: 0.999914] [G loss: 1.000104]\n",
      "epoch:25 step:119725[D loss: 0.999930] [G loss: 1.000119]\n",
      "epoch:25 step:119730[D loss: 1.000021] [G loss: 1.000034]\n",
      "epoch:25 step:119735[D loss: 0.999987] [G loss: 1.000023]\n",
      "epoch:25 step:119740[D loss: 0.999971] [G loss: 1.000121]\n",
      "epoch:25 step:119745[D loss: 1.000010] [G loss: 1.000098]\n",
      "epoch:25 step:119750[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:25 step:119755[D loss: 0.999994] [G loss: 1.000013]\n",
      "epoch:25 step:119760[D loss: 0.999973] [G loss: 0.999995]\n",
      "epoch:25 step:119765[D loss: 0.999945] [G loss: 1.000123]\n",
      "epoch:25 step:119770[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:25 step:119775[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:25 step:119780[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:25 step:119785[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:25 step:119790[D loss: 0.999915] [G loss: 1.000114]\n",
      "epoch:25 step:119795[D loss: 0.999997] [G loss: 1.000021]\n",
      "epoch:25 step:119800[D loss: 0.999987] [G loss: 1.000037]\n",
      "##############\n",
      "[2.47190563 2.09716674 2.08021109 3.72554195 1.42642737 8.18346881\n",
      " 2.25908401 3.72206456 4.00486824 5.29532017]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:119805[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:25 step:119810[D loss: 1.000084] [G loss: 0.999915]\n",
      "epoch:25 step:119815[D loss: 1.000022] [G loss: 1.000014]\n",
      "epoch:25 step:119820[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:25 step:119825[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:25 step:119830[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:25 step:119835[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:25 step:119840[D loss: 1.000041] [G loss: 1.000079]\n",
      "epoch:25 step:119845[D loss: 0.999958] [G loss: 1.000135]\n",
      "epoch:25 step:119850[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:25 step:119855[D loss: 0.999967] [G loss: 1.000119]\n",
      "epoch:25 step:119860[D loss: 0.999959] [G loss: 1.000054]\n",
      "epoch:25 step:119865[D loss: 0.999969] [G loss: 1.000098]\n",
      "epoch:25 step:119870[D loss: 0.999999] [G loss: 0.999997]\n",
      "epoch:25 step:119875[D loss: 1.000016] [G loss: 1.000043]\n",
      "epoch:25 step:119880[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:25 step:119885[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:25 step:119890[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:25 step:119895[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:25 step:119900[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:25 step:119905[D loss: 0.999994] [G loss: 0.999984]\n",
      "epoch:25 step:119910[D loss: 0.999948] [G loss: 1.000077]\n",
      "epoch:25 step:119915[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:25 step:119920[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:25 step:119925[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:25 step:119930[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:25 step:119935[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:25 step:119940[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:25 step:119945[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:25 step:119950[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:25 step:119955[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:25 step:119960[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:25 step:119965[D loss: 1.000009] [G loss: 0.999988]\n",
      "epoch:25 step:119970[D loss: 0.999978] [G loss: 1.000003]\n",
      "epoch:25 step:119975[D loss: 0.999938] [G loss: 1.000080]\n",
      "epoch:25 step:119980[D loss: 0.999949] [G loss: 1.000093]\n",
      "epoch:25 step:119985[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:25 step:119990[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:25 step:119995[D loss: 0.999987] [G loss: 1.000015]\n",
      "epoch:25 step:120000[D loss: 1.000041] [G loss: 1.000008]\n",
      "##############\n",
      "[2.3665264  2.10846955 2.08491814 3.62065962 1.35621491 8.12587344\n",
      " 2.2303273  3.60566273 3.86508667 5.23139502]\n",
      "##########\n",
      "epoch:25 step:120005[D loss: 0.999983] [G loss: 1.000088]\n",
      "epoch:25 step:120010[D loss: 0.999935] [G loss: 1.000024]\n",
      "epoch:25 step:120015[D loss: 0.999977] [G loss: 1.000201]\n",
      "epoch:25 step:120020[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:25 step:120025[D loss: 1.000172] [G loss: 1.000108]\n",
      "epoch:25 step:120030[D loss: 0.999911] [G loss: 1.000055]\n",
      "epoch:25 step:120035[D loss: 0.999944] [G loss: 1.000101]\n",
      "epoch:25 step:120040[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:25 step:120045[D loss: 0.999973] [G loss: 1.000114]\n",
      "epoch:25 step:120050[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:25 step:120055[D loss: 0.999997] [G loss: 1.000014]\n",
      "epoch:25 step:120060[D loss: 0.999982] [G loss: 1.000012]\n",
      "epoch:25 step:120065[D loss: 1.000081] [G loss: 0.999964]\n",
      "epoch:25 step:120070[D loss: 1.000164] [G loss: 0.999898]\n",
      "epoch:25 step:120075[D loss: 0.999855] [G loss: 1.000058]\n",
      "epoch:25 step:120080[D loss: 0.999993] [G loss: 1.000001]\n",
      "epoch:25 step:120085[D loss: 0.999902] [G loss: 1.000079]\n",
      "epoch:25 step:120090[D loss: 0.999960] [G loss: 1.000032]\n",
      "epoch:25 step:120095[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:25 step:120100[D loss: 1.000057] [G loss: 0.999947]\n",
      "epoch:25 step:120105[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:25 step:120110[D loss: 0.999932] [G loss: 1.000079]\n",
      "epoch:25 step:120115[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:25 step:120120[D loss: 0.999919] [G loss: 1.000083]\n",
      "epoch:25 step:120125[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:25 step:120130[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:25 step:120135[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:25 step:120140[D loss: 0.999971] [G loss: 1.000020]\n",
      "epoch:25 step:120145[D loss: 1.000064] [G loss: 0.999862]\n",
      "epoch:25 step:120150[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:25 step:120155[D loss: 0.999958] [G loss: 1.000049]\n",
      "epoch:25 step:120160[D loss: 1.000008] [G loss: 1.000057]\n",
      "epoch:25 step:120165[D loss: 1.000055] [G loss: 0.999907]\n",
      "epoch:25 step:120170[D loss: 1.000125] [G loss: 0.999916]\n",
      "epoch:25 step:120175[D loss: 0.999955] [G loss: 1.000019]\n",
      "epoch:25 step:120180[D loss: 0.999934] [G loss: 1.000148]\n",
      "epoch:25 step:120185[D loss: 1.000009] [G loss: 1.000063]\n",
      "epoch:25 step:120190[D loss: 0.999922] [G loss: 1.000068]\n",
      "epoch:25 step:120195[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:25 step:120200[D loss: 0.999944] [G loss: 1.000089]\n",
      "##############\n",
      "[2.3615248  2.01147451 2.02863068 3.55167396 1.33233697 7.67575736\n",
      " 2.15240592 3.64915143 3.8955483  5.59849519]\n",
      "##########\n",
      "epoch:25 step:120205[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:25 step:120210[D loss: 0.999988] [G loss: 1.000102]\n",
      "epoch:25 step:120215[D loss: 1.000020] [G loss: 0.999978]\n",
      "epoch:25 step:120220[D loss: 0.999951] [G loss: 1.000052]\n",
      "epoch:25 step:120225[D loss: 1.000011] [G loss: 1.000026]\n",
      "epoch:25 step:120230[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:25 step:120235[D loss: 1.000048] [G loss: 1.000029]\n",
      "epoch:25 step:120240[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:25 step:120245[D loss: 0.999991] [G loss: 1.000107]\n",
      "epoch:25 step:120250[D loss: 0.999963] [G loss: 1.000193]\n",
      "epoch:25 step:120255[D loss: 0.999940] [G loss: 1.000074]\n",
      "epoch:25 step:120260[D loss: 0.999993] [G loss: 1.000000]\n",
      "epoch:25 step:120265[D loss: 0.999994] [G loss: 0.999969]\n",
      "epoch:25 step:120270[D loss: 0.999947] [G loss: 1.000072]\n",
      "epoch:25 step:120275[D loss: 0.999916] [G loss: 1.000123]\n",
      "epoch:25 step:120280[D loss: 1.000004] [G loss: 1.000012]\n",
      "epoch:25 step:120285[D loss: 1.000019] [G loss: 1.000067]\n",
      "epoch:25 step:120290[D loss: 0.999938] [G loss: 1.000135]\n",
      "epoch:25 step:120295[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:25 step:120300[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:25 step:120305[D loss: 0.999995] [G loss: 1.000022]\n",
      "epoch:25 step:120310[D loss: 1.000050] [G loss: 0.999986]\n",
      "epoch:25 step:120315[D loss: 0.999932] [G loss: 1.000032]\n",
      "epoch:25 step:120320[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:25 step:120325[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:25 step:120330[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:25 step:120335[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:25 step:120340[D loss: 1.000001] [G loss: 1.000023]\n",
      "epoch:25 step:120345[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:25 step:120350[D loss: 1.000048] [G loss: 0.999944]\n",
      "epoch:25 step:120355[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:25 step:120360[D loss: 0.999931] [G loss: 1.000074]\n",
      "epoch:25 step:120365[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:25 step:120370[D loss: 1.000003] [G loss: 1.000060]\n",
      "epoch:25 step:120375[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:25 step:120380[D loss: 1.000025] [G loss: 1.000052]\n",
      "epoch:25 step:120385[D loss: 0.999935] [G loss: 1.000097]\n",
      "epoch:25 step:120390[D loss: 0.999973] [G loss: 1.000120]\n",
      "epoch:25 step:120395[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:25 step:120400[D loss: 0.999950] [G loss: 1.000108]\n",
      "##############\n",
      "[2.54083527 2.06552751 2.05700156 3.77797979 1.37852742 7.28562736\n",
      " 2.21382134 3.74047685 3.91018976 5.26639986]\n",
      "##########\n",
      "epoch:25 step:120405[D loss: 1.000014] [G loss: 0.999952]\n",
      "epoch:25 step:120410[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:25 step:120415[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:25 step:120420[D loss: 0.999951] [G loss: 1.000115]\n",
      "epoch:25 step:120425[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:25 step:120430[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:25 step:120435[D loss: 0.999993] [G loss: 1.000112]\n",
      "epoch:25 step:120440[D loss: 0.999923] [G loss: 1.000168]\n",
      "epoch:25 step:120445[D loss: 0.999951] [G loss: 1.000051]\n",
      "epoch:25 step:120450[D loss: 1.000056] [G loss: 0.999902]\n",
      "epoch:25 step:120455[D loss: 1.000052] [G loss: 0.999969]\n",
      "epoch:25 step:120460[D loss: 0.999977] [G loss: 0.999997]\n",
      "epoch:25 step:120465[D loss: 1.000040] [G loss: 0.999946]\n",
      "epoch:25 step:120470[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:25 step:120475[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:25 step:120480[D loss: 0.999999] [G loss: 1.000045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:120485[D loss: 1.000029] [G loss: 1.000015]\n",
      "epoch:25 step:120490[D loss: 0.999973] [G loss: 1.000015]\n",
      "epoch:25 step:120495[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:25 step:120500[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:25 step:120505[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:25 step:120510[D loss: 0.999955] [G loss: 1.000075]\n",
      "epoch:25 step:120515[D loss: 1.000015] [G loss: 1.000023]\n",
      "epoch:25 step:120520[D loss: 0.999945] [G loss: 1.000123]\n",
      "epoch:25 step:120525[D loss: 0.999972] [G loss: 1.000118]\n",
      "epoch:25 step:120530[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:25 step:120535[D loss: 0.999926] [G loss: 1.000141]\n",
      "epoch:25 step:120540[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:25 step:120545[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:25 step:120550[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:25 step:120555[D loss: 0.999962] [G loss: 1.000036]\n",
      "epoch:25 step:120560[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:25 step:120565[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:25 step:120570[D loss: 1.000059] [G loss: 1.000018]\n",
      "epoch:25 step:120575[D loss: 0.999960] [G loss: 1.000042]\n",
      "epoch:25 step:120580[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:25 step:120585[D loss: 1.000022] [G loss: 1.000071]\n",
      "epoch:25 step:120590[D loss: 1.000042] [G loss: 1.000038]\n",
      "epoch:25 step:120595[D loss: 0.999986] [G loss: 1.000083]\n",
      "epoch:25 step:120600[D loss: 0.999968] [G loss: 1.000064]\n",
      "##############\n",
      "[2.54793146 2.20385542 2.16521816 3.98496798 1.42487286 8.35536003\n",
      " 2.20723253 3.63690228 3.91375594 4.75186216]\n",
      "##########\n",
      "epoch:25 step:120605[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:25 step:120610[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:25 step:120615[D loss: 0.999958] [G loss: 1.000047]\n",
      "epoch:25 step:120620[D loss: 1.000051] [G loss: 0.999939]\n",
      "epoch:25 step:120625[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:25 step:120630[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:25 step:120635[D loss: 0.999994] [G loss: 1.000017]\n",
      "epoch:25 step:120640[D loss: 1.000017] [G loss: 0.999969]\n",
      "epoch:25 step:120645[D loss: 1.000010] [G loss: 0.999991]\n",
      "epoch:25 step:120650[D loss: 0.999984] [G loss: 1.000092]\n",
      "epoch:25 step:120655[D loss: 1.000000] [G loss: 1.000069]\n",
      "epoch:25 step:120660[D loss: 0.999905] [G loss: 1.000137]\n",
      "epoch:25 step:120665[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:25 step:120670[D loss: 0.999975] [G loss: 1.000104]\n",
      "epoch:25 step:120675[D loss: 1.000041] [G loss: 1.000007]\n",
      "epoch:25 step:120680[D loss: 1.000008] [G loss: 0.999979]\n",
      "epoch:25 step:120685[D loss: 0.999926] [G loss: 1.000154]\n",
      "epoch:25 step:120690[D loss: 0.999936] [G loss: 1.000149]\n",
      "epoch:25 step:120695[D loss: 1.000092] [G loss: 1.000063]\n",
      "epoch:25 step:120700[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:25 step:120705[D loss: 0.999924] [G loss: 1.000141]\n",
      "epoch:25 step:120710[D loss: 0.999927] [G loss: 1.000109]\n",
      "epoch:25 step:120715[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:25 step:120720[D loss: 1.000010] [G loss: 1.000006]\n",
      "epoch:25 step:120725[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:25 step:120730[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:25 step:120735[D loss: 0.999995] [G loss: 1.000084]\n",
      "epoch:25 step:120740[D loss: 0.999999] [G loss: 1.000062]\n",
      "epoch:25 step:120745[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:25 step:120750[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:25 step:120755[D loss: 0.999961] [G loss: 1.000049]\n",
      "epoch:25 step:120760[D loss: 0.999926] [G loss: 1.000180]\n",
      "epoch:25 step:120765[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:25 step:120770[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:25 step:120775[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:25 step:120780[D loss: 1.000009] [G loss: 1.000003]\n",
      "epoch:25 step:120785[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:25 step:120790[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:25 step:120795[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:25 step:120800[D loss: 0.999963] [G loss: 1.000088]\n",
      "##############\n",
      "[2.36906786 2.07197918 2.10880486 3.79394802 1.33251691 7.33333439\n",
      " 2.3852551  3.70516314 3.93107409 5.63728823]\n",
      "##########\n",
      "epoch:25 step:120805[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:25 step:120810[D loss: 0.999996] [G loss: 1.000087]\n",
      "epoch:25 step:120815[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:25 step:120820[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:25 step:120825[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:25 step:120830[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:25 step:120835[D loss: 1.000097] [G loss: 1.000031]\n",
      "epoch:25 step:120840[D loss: 0.999885] [G loss: 1.000079]\n",
      "epoch:25 step:120845[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:25 step:120850[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:25 step:120855[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:25 step:120860[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:25 step:120865[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:25 step:120870[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:25 step:120875[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:25 step:120880[D loss: 0.999958] [G loss: 1.000058]\n",
      "epoch:25 step:120885[D loss: 0.999979] [G loss: 1.000030]\n",
      "epoch:25 step:120890[D loss: 0.999948] [G loss: 1.000065]\n",
      "epoch:25 step:120895[D loss: 1.000062] [G loss: 0.999953]\n",
      "epoch:25 step:120900[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:25 step:120905[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:25 step:120910[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:25 step:120915[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:25 step:120920[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:25 step:120925[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:25 step:120930[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:25 step:120935[D loss: 1.000072] [G loss: 0.999957]\n",
      "epoch:25 step:120940[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:25 step:120945[D loss: 0.999953] [G loss: 1.000150]\n",
      "epoch:25 step:120950[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:25 step:120955[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:25 step:120960[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:25 step:120965[D loss: 1.000000] [G loss: 0.999986]\n",
      "epoch:25 step:120970[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:25 step:120975[D loss: 1.000021] [G loss: 0.999961]\n",
      "epoch:25 step:120980[D loss: 1.000034] [G loss: 1.000018]\n",
      "epoch:25 step:120985[D loss: 1.000003] [G loss: 1.000039]\n",
      "epoch:25 step:120990[D loss: 0.999943] [G loss: 1.000157]\n",
      "epoch:25 step:120995[D loss: 0.999963] [G loss: 1.000208]\n",
      "epoch:25 step:121000[D loss: 0.999934] [G loss: 1.000062]\n",
      "##############\n",
      "[2.43125408 2.13410465 2.26442886 3.56131509 1.40521707 8.30176406\n",
      " 2.42454241 3.70489056 3.93610431 5.04679567]\n",
      "##########\n",
      "epoch:25 step:121005[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:25 step:121010[D loss: 1.000014] [G loss: 0.999975]\n",
      "epoch:25 step:121015[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:25 step:121020[D loss: 1.000130] [G loss: 0.999843]\n",
      "epoch:25 step:121025[D loss: 1.000072] [G loss: 0.999852]\n",
      "epoch:25 step:121030[D loss: 0.999857] [G loss: 1.000082]\n",
      "epoch:25 step:121035[D loss: 0.999930] [G loss: 1.000101]\n",
      "epoch:25 step:121040[D loss: 0.999974] [G loss: 1.000114]\n",
      "epoch:25 step:121045[D loss: 0.999998] [G loss: 1.000028]\n",
      "epoch:25 step:121050[D loss: 0.999922] [G loss: 1.000090]\n",
      "epoch:25 step:121055[D loss: 0.999902] [G loss: 1.000244]\n",
      "epoch:25 step:121060[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:25 step:121065[D loss: 1.000051] [G loss: 1.000109]\n",
      "epoch:25 step:121070[D loss: 1.000014] [G loss: 1.000146]\n",
      "epoch:25 step:121075[D loss: 0.999946] [G loss: 1.000074]\n",
      "epoch:25 step:121080[D loss: 1.000034] [G loss: 0.999908]\n",
      "epoch:25 step:121085[D loss: 0.999953] [G loss: 1.000004]\n",
      "epoch:25 step:121090[D loss: 0.999980] [G loss: 1.000014]\n",
      "epoch:25 step:121095[D loss: 1.000020] [G loss: 0.999960]\n",
      "epoch:25 step:121100[D loss: 1.000109] [G loss: 0.999875]\n",
      "epoch:25 step:121105[D loss: 0.999964] [G loss: 1.000028]\n",
      "epoch:25 step:121110[D loss: 0.999948] [G loss: 1.000132]\n",
      "epoch:25 step:121115[D loss: 0.999895] [G loss: 1.000294]\n",
      "epoch:25 step:121120[D loss: 1.000064] [G loss: 0.999843]\n",
      "epoch:25 step:121125[D loss: 0.999998] [G loss: 0.999982]\n",
      "epoch:25 step:121130[D loss: 0.999926] [G loss: 1.000110]\n",
      "epoch:25 step:121135[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:25 step:121140[D loss: 0.999980] [G loss: 1.000099]\n",
      "epoch:25 step:121145[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:25 step:121150[D loss: 1.000011] [G loss: 1.000031]\n",
      "epoch:25 step:121155[D loss: 0.999930] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:121160[D loss: 1.000046] [G loss: 1.000001]\n",
      "epoch:25 step:121165[D loss: 1.000107] [G loss: 0.999982]\n",
      "epoch:25 step:121170[D loss: 0.999988] [G loss: 1.000007]\n",
      "epoch:25 step:121175[D loss: 0.999980] [G loss: 1.000119]\n",
      "epoch:25 step:121180[D loss: 1.000006] [G loss: 1.000113]\n",
      "epoch:25 step:121185[D loss: 0.999937] [G loss: 1.000126]\n",
      "epoch:25 step:121190[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:25 step:121195[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:25 step:121200[D loss: 0.999978] [G loss: 1.000062]\n",
      "##############\n",
      "[2.46134841 2.07609021 2.13464157 3.52364359 1.39206943 7.22786257\n",
      " 2.33623892 3.6593582  3.93292399 5.29436134]\n",
      "##########\n",
      "epoch:25 step:121205[D loss: 0.999950] [G loss: 1.000150]\n",
      "epoch:25 step:121210[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:25 step:121215[D loss: 0.999992] [G loss: 1.000122]\n",
      "epoch:25 step:121220[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:25 step:121225[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:25 step:121230[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:25 step:121235[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:25 step:121240[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:25 step:121245[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:25 step:121250[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:25 step:121255[D loss: 1.000037] [G loss: 0.999990]\n",
      "epoch:25 step:121260[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:25 step:121265[D loss: 0.999972] [G loss: 1.000104]\n",
      "epoch:25 step:121270[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:25 step:121275[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:25 step:121280[D loss: 1.000040] [G loss: 0.999983]\n",
      "epoch:25 step:121285[D loss: 1.000127] [G loss: 0.999875]\n",
      "epoch:25 step:121290[D loss: 0.999883] [G loss: 1.000146]\n",
      "epoch:25 step:121295[D loss: 0.999996] [G loss: 1.000129]\n",
      "epoch:25 step:121300[D loss: 0.999891] [G loss: 1.000171]\n",
      "epoch:25 step:121305[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:25 step:121310[D loss: 0.999952] [G loss: 1.000092]\n",
      "epoch:25 step:121315[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:25 step:121320[D loss: 1.000025] [G loss: 1.000014]\n",
      "epoch:25 step:121325[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:25 step:121330[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:25 step:121335[D loss: 0.999953] [G loss: 1.000067]\n",
      "epoch:25 step:121340[D loss: 0.999988] [G loss: 1.000104]\n",
      "epoch:25 step:121345[D loss: 1.000091] [G loss: 1.000023]\n",
      "epoch:25 step:121350[D loss: 0.999974] [G loss: 1.000133]\n",
      "epoch:25 step:121355[D loss: 0.999875] [G loss: 1.000139]\n",
      "epoch:25 step:121360[D loss: 1.000020] [G loss: 1.000129]\n",
      "epoch:25 step:121365[D loss: 0.999901] [G loss: 1.000204]\n",
      "epoch:25 step:121370[D loss: 1.000002] [G loss: 1.000165]\n",
      "epoch:25 step:121375[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:25 step:121380[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:25 step:121385[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:25 step:121390[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:25 step:121395[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:25 step:121400[D loss: 0.999947] [G loss: 1.000062]\n",
      "##############\n",
      "[2.47665164 2.08529728 2.13949973 3.93953017 1.30563609 7.80196083\n",
      " 2.22803435 3.51270597 3.96218651 4.8823302 ]\n",
      "##########\n",
      "epoch:25 step:121405[D loss: 1.000017] [G loss: 0.999967]\n",
      "epoch:25 step:121410[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:25 step:121415[D loss: 1.000025] [G loss: 1.000023]\n",
      "epoch:25 step:121420[D loss: 0.999990] [G loss: 1.000102]\n",
      "epoch:25 step:121425[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:25 step:121430[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:25 step:121435[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:25 step:121440[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:25 step:121445[D loss: 1.000016] [G loss: 1.000022]\n",
      "epoch:25 step:121450[D loss: 0.999939] [G loss: 1.000071]\n",
      "epoch:25 step:121455[D loss: 0.999954] [G loss: 1.000041]\n",
      "epoch:25 step:121460[D loss: 1.000017] [G loss: 1.000136]\n",
      "epoch:25 step:121465[D loss: 0.999996] [G loss: 1.000068]\n",
      "epoch:25 step:121470[D loss: 0.999944] [G loss: 1.000142]\n",
      "epoch:25 step:121475[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:25 step:121480[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:25 step:121485[D loss: 1.000029] [G loss: 0.999998]\n",
      "epoch:25 step:121490[D loss: 0.999937] [G loss: 1.000022]\n",
      "epoch:25 step:121495[D loss: 0.999954] [G loss: 1.000060]\n",
      "epoch:25 step:121500[D loss: 0.999947] [G loss: 1.000108]\n",
      "epoch:25 step:121505[D loss: 1.000008] [G loss: 1.000054]\n",
      "epoch:25 step:121510[D loss: 0.999942] [G loss: 1.000072]\n",
      "epoch:25 step:121515[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:25 step:121520[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:25 step:121525[D loss: 1.000005] [G loss: 1.000097]\n",
      "epoch:25 step:121530[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:25 step:121535[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:25 step:121540[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:25 step:121545[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:25 step:121550[D loss: 1.000075] [G loss: 0.999986]\n",
      "epoch:25 step:121555[D loss: 0.999986] [G loss: 1.000020]\n",
      "epoch:25 step:121560[D loss: 0.999947] [G loss: 1.000162]\n",
      "epoch:25 step:121565[D loss: 0.999932] [G loss: 1.000099]\n",
      "epoch:25 step:121570[D loss: 0.999958] [G loss: 1.000119]\n",
      "epoch:25 step:121575[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:25 step:121580[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:25 step:121585[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:25 step:121590[D loss: 0.999952] [G loss: 1.000035]\n",
      "epoch:25 step:121595[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:25 step:121600[D loss: 0.999970] [G loss: 1.000070]\n",
      "##############\n",
      "[2.43607483 2.00263157 2.1441533  3.82791941 1.3677263  7.52264571\n",
      " 2.38981462 3.55643699 3.943475   5.34298729]\n",
      "##########\n",
      "epoch:25 step:121605[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:25 step:121610[D loss: 0.999957] [G loss: 1.000044]\n",
      "epoch:25 step:121615[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:25 step:121620[D loss: 0.999981] [G loss: 0.999996]\n",
      "epoch:25 step:121625[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:25 step:121630[D loss: 0.999984] [G loss: 1.000112]\n",
      "epoch:25 step:121635[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:25 step:121640[D loss: 0.999958] [G loss: 1.000099]\n",
      "epoch:25 step:121645[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:25 step:121650[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:25 step:121655[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:25 step:121660[D loss: 0.999996] [G loss: 1.000041]\n",
      "epoch:25 step:121665[D loss: 1.000036] [G loss: 1.000025]\n",
      "epoch:25 step:121670[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:25 step:121675[D loss: 0.999955] [G loss: 1.000070]\n",
      "epoch:25 step:121680[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:25 step:121685[D loss: 1.000009] [G loss: 1.000014]\n",
      "epoch:25 step:121690[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:25 step:121695[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:25 step:121700[D loss: 1.000026] [G loss: 0.999995]\n",
      "epoch:25 step:121705[D loss: 0.999930] [G loss: 1.000103]\n",
      "epoch:25 step:121710[D loss: 1.000030] [G loss: 1.000063]\n",
      "epoch:25 step:121715[D loss: 0.999926] [G loss: 1.000063]\n",
      "epoch:25 step:121720[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:25 step:121725[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:25 step:121730[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:25 step:121735[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:25 step:121740[D loss: 0.999954] [G loss: 1.000066]\n",
      "epoch:25 step:121745[D loss: 0.999943] [G loss: 1.000074]\n",
      "epoch:25 step:121750[D loss: 0.999954] [G loss: 1.000059]\n",
      "epoch:25 step:121755[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:25 step:121760[D loss: 0.999991] [G loss: 1.000007]\n",
      "epoch:25 step:121765[D loss: 0.999989] [G loss: 1.000004]\n",
      "epoch:25 step:121770[D loss: 0.999952] [G loss: 1.000111]\n",
      "epoch:25 step:121775[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:25 step:121780[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:25 step:121785[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:25 step:121790[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:25 step:121795[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:25 step:121800[D loss: 1.000045] [G loss: 1.000027]\n",
      "##############\n",
      "[2.53747822 2.11102143 2.16011209 4.10269741 1.34461839 7.83155393\n",
      " 2.31669943 3.60877293 3.92651285 4.98451847]\n",
      "##########\n",
      "epoch:25 step:121805[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:25 step:121810[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:26 step:121815[D loss: 1.000003] [G loss: 0.999999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:121820[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:26 step:121825[D loss: 0.999944] [G loss: 1.000043]\n",
      "epoch:26 step:121830[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:26 step:121835[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:26 step:121840[D loss: 0.999992] [G loss: 1.000032]\n",
      "epoch:26 step:121845[D loss: 0.999950] [G loss: 1.000066]\n",
      "epoch:26 step:121850[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:26 step:121855[D loss: 1.000014] [G loss: 1.000036]\n",
      "epoch:26 step:121860[D loss: 1.000103] [G loss: 0.999899]\n",
      "epoch:26 step:121865[D loss: 1.000079] [G loss: 0.999873]\n",
      "epoch:26 step:121870[D loss: 0.999951] [G loss: 0.999988]\n",
      "epoch:26 step:121875[D loss: 0.999940] [G loss: 1.000082]\n",
      "epoch:26 step:121880[D loss: 0.999975] [G loss: 1.000026]\n",
      "epoch:26 step:121885[D loss: 1.000047] [G loss: 1.000003]\n",
      "epoch:26 step:121890[D loss: 0.999934] [G loss: 1.000116]\n",
      "epoch:26 step:121895[D loss: 0.999873] [G loss: 1.000146]\n",
      "epoch:26 step:121900[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:26 step:121905[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:26 step:121910[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:26 step:121915[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:26 step:121920[D loss: 1.000040] [G loss: 0.999996]\n",
      "epoch:26 step:121925[D loss: 0.999919] [G loss: 1.000088]\n",
      "epoch:26 step:121930[D loss: 0.999974] [G loss: 1.000115]\n",
      "epoch:26 step:121935[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:26 step:121940[D loss: 0.999989] [G loss: 1.000115]\n",
      "epoch:26 step:121945[D loss: 1.000018] [G loss: 1.000074]\n",
      "epoch:26 step:121950[D loss: 0.999898] [G loss: 1.000172]\n",
      "epoch:26 step:121955[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:26 step:121960[D loss: 1.000018] [G loss: 0.999977]\n",
      "epoch:26 step:121965[D loss: 1.000016] [G loss: 1.000015]\n",
      "epoch:26 step:121970[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:26 step:121975[D loss: 1.000046] [G loss: 0.999980]\n",
      "epoch:26 step:121980[D loss: 1.000068] [G loss: 1.000008]\n",
      "epoch:26 step:121985[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:26 step:121990[D loss: 1.000001] [G loss: 1.000092]\n",
      "epoch:26 step:121995[D loss: 1.000009] [G loss: 1.000083]\n",
      "epoch:26 step:122000[D loss: 0.999950] [G loss: 1.000111]\n",
      "##############\n",
      "[2.46399182 2.05638749 2.17320333 3.85722903 1.34820148 7.279446\n",
      " 2.1897078  3.59391121 3.96079269 4.85840583]\n",
      "##########\n",
      "epoch:26 step:122005[D loss: 0.999978] [G loss: 1.000012]\n",
      "epoch:26 step:122010[D loss: 1.000117] [G loss: 0.999929]\n",
      "epoch:26 step:122015[D loss: 1.000069] [G loss: 0.999888]\n",
      "epoch:26 step:122020[D loss: 0.999973] [G loss: 0.999982]\n",
      "epoch:26 step:122025[D loss: 0.999988] [G loss: 0.999971]\n",
      "epoch:26 step:122030[D loss: 1.000082] [G loss: 0.999726]\n",
      "epoch:26 step:122035[D loss: 0.999936] [G loss: 1.000190]\n",
      "epoch:26 step:122040[D loss: 1.000031] [G loss: 1.000025]\n",
      "epoch:26 step:122045[D loss: 0.999998] [G loss: 1.000041]\n",
      "epoch:26 step:122050[D loss: 0.999979] [G loss: 1.000124]\n",
      "epoch:26 step:122055[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:26 step:122060[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:26 step:122065[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:26 step:122070[D loss: 0.999995] [G loss: 1.000038]\n",
      "epoch:26 step:122075[D loss: 1.000019] [G loss: 1.000070]\n",
      "epoch:26 step:122080[D loss: 0.999996] [G loss: 1.000083]\n",
      "epoch:26 step:122085[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:26 step:122090[D loss: 0.999938] [G loss: 1.000143]\n",
      "epoch:26 step:122095[D loss: 0.999972] [G loss: 1.000124]\n",
      "epoch:26 step:122100[D loss: 0.999939] [G loss: 1.000120]\n",
      "epoch:26 step:122105[D loss: 0.999975] [G loss: 1.000123]\n",
      "epoch:26 step:122110[D loss: 0.999967] [G loss: 1.000112]\n",
      "epoch:26 step:122115[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:26 step:122120[D loss: 0.999975] [G loss: 1.000141]\n",
      "epoch:26 step:122125[D loss: 0.999992] [G loss: 1.000121]\n",
      "epoch:26 step:122130[D loss: 1.000027] [G loss: 1.000059]\n",
      "epoch:26 step:122135[D loss: 1.000009] [G loss: 0.999947]\n",
      "epoch:26 step:122140[D loss: 1.000001] [G loss: 1.000037]\n",
      "epoch:26 step:122145[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:26 step:122150[D loss: 0.999974] [G loss: 1.000029]\n",
      "epoch:26 step:122155[D loss: 1.000110] [G loss: 0.999882]\n",
      "epoch:26 step:122160[D loss: 1.000002] [G loss: 1.000044]\n",
      "epoch:26 step:122165[D loss: 1.000053] [G loss: 1.000013]\n",
      "epoch:26 step:122170[D loss: 1.000051] [G loss: 1.000042]\n",
      "epoch:26 step:122175[D loss: 1.000037] [G loss: 0.999896]\n",
      "epoch:26 step:122180[D loss: 0.999884] [G loss: 1.000058]\n",
      "epoch:26 step:122185[D loss: 0.999915] [G loss: 1.000054]\n",
      "epoch:26 step:122190[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:26 step:122195[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:26 step:122200[D loss: 0.999978] [G loss: 1.000031]\n",
      "##############\n",
      "[2.52076416 2.10023525 2.25354743 3.95693817 1.38701513 8.63930106\n",
      " 2.44539694 3.74856101 4.0706431  5.32444235]\n",
      "##########\n",
      "epoch:26 step:122205[D loss: 1.000015] [G loss: 0.999932]\n",
      "epoch:26 step:122210[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:26 step:122215[D loss: 1.000004] [G loss: 1.000074]\n",
      "epoch:26 step:122220[D loss: 0.999945] [G loss: 1.000049]\n",
      "epoch:26 step:122225[D loss: 1.000026] [G loss: 0.999971]\n",
      "epoch:26 step:122230[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:26 step:122235[D loss: 0.999951] [G loss: 1.000048]\n",
      "epoch:26 step:122240[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:26 step:122245[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:26 step:122250[D loss: 0.999920] [G loss: 1.000132]\n",
      "epoch:26 step:122255[D loss: 0.999917] [G loss: 1.000247]\n",
      "epoch:26 step:122260[D loss: 0.999950] [G loss: 1.000096]\n",
      "epoch:26 step:122265[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:26 step:122270[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:26 step:122275[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:26 step:122280[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:26 step:122285[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:26 step:122290[D loss: 1.000112] [G loss: 0.999828]\n",
      "epoch:26 step:122295[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:26 step:122300[D loss: 1.000085] [G loss: 0.999940]\n",
      "epoch:26 step:122305[D loss: 0.999900] [G loss: 1.000153]\n",
      "epoch:26 step:122310[D loss: 0.999924] [G loss: 1.000136]\n",
      "epoch:26 step:122315[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:26 step:122320[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:26 step:122325[D loss: 1.000005] [G loss: 1.000002]\n",
      "epoch:26 step:122330[D loss: 1.000011] [G loss: 0.999996]\n",
      "epoch:26 step:122335[D loss: 0.999940] [G loss: 1.000115]\n",
      "epoch:26 step:122340[D loss: 0.999903] [G loss: 1.000122]\n",
      "epoch:26 step:122345[D loss: 1.000098] [G loss: 0.999934]\n",
      "epoch:26 step:122350[D loss: 0.999939] [G loss: 1.000136]\n",
      "epoch:26 step:122355[D loss: 0.999912] [G loss: 1.000109]\n",
      "epoch:26 step:122360[D loss: 1.000004] [G loss: 1.000092]\n",
      "epoch:26 step:122365[D loss: 0.999885] [G loss: 1.000178]\n",
      "epoch:26 step:122370[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:26 step:122375[D loss: 0.999976] [G loss: 1.000148]\n",
      "epoch:26 step:122380[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:26 step:122385[D loss: 0.999997] [G loss: 1.000106]\n",
      "epoch:26 step:122390[D loss: 0.999958] [G loss: 1.000058]\n",
      "epoch:26 step:122395[D loss: 1.000084] [G loss: 0.999842]\n",
      "epoch:26 step:122400[D loss: 1.000170] [G loss: 0.999867]\n",
      "##############\n",
      "[2.53247245 2.09496034 2.22883511 3.84324414 1.29913676 8.07713042\n",
      " 2.41747432 3.87704228 3.9928947  7.14868929]\n",
      "##########\n",
      "epoch:26 step:122405[D loss: 1.000119] [G loss: 1.000023]\n",
      "epoch:26 step:122410[D loss: 0.999799] [G loss: 1.000287]\n",
      "epoch:26 step:122415[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:26 step:122420[D loss: 0.999964] [G loss: 1.000133]\n",
      "epoch:26 step:122425[D loss: 0.999945] [G loss: 1.000123]\n",
      "epoch:26 step:122430[D loss: 0.999948] [G loss: 1.000158]\n",
      "epoch:26 step:122435[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:26 step:122440[D loss: 0.999949] [G loss: 1.000045]\n",
      "epoch:26 step:122445[D loss: 0.999946] [G loss: 1.000118]\n",
      "epoch:26 step:122450[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:26 step:122455[D loss: 1.000050] [G loss: 0.999966]\n",
      "epoch:26 step:122460[D loss: 0.999941] [G loss: 1.000047]\n",
      "epoch:26 step:122465[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:26 step:122470[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:26 step:122475[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:26 step:122480[D loss: 0.999933] [G loss: 1.000106]\n",
      "epoch:26 step:122485[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:26 step:122490[D loss: 0.999975] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:122495[D loss: 1.000012] [G loss: 1.000033]\n",
      "epoch:26 step:122500[D loss: 1.000008] [G loss: 0.999952]\n",
      "epoch:26 step:122505[D loss: 0.999941] [G loss: 1.000093]\n",
      "epoch:26 step:122510[D loss: 1.000003] [G loss: 0.999976]\n",
      "epoch:26 step:122515[D loss: 1.000006] [G loss: 1.000063]\n",
      "epoch:26 step:122520[D loss: 0.999987] [G loss: 1.000088]\n",
      "epoch:26 step:122525[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:26 step:122530[D loss: 1.000000] [G loss: 1.000007]\n",
      "epoch:26 step:122535[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:26 step:122540[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:26 step:122545[D loss: 1.000024] [G loss: 0.999999]\n",
      "epoch:26 step:122550[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:26 step:122555[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:26 step:122560[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:26 step:122565[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:26 step:122570[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:26 step:122575[D loss: 0.999971] [G loss: 1.000096]\n",
      "epoch:26 step:122580[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:26 step:122585[D loss: 0.999957] [G loss: 1.000128]\n",
      "epoch:26 step:122590[D loss: 1.000027] [G loss: 1.000004]\n",
      "epoch:26 step:122595[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:26 step:122600[D loss: 0.999976] [G loss: 1.000063]\n",
      "##############\n",
      "[2.49268278 2.09516087 2.24522969 3.88397051 1.3447622  7.13811134\n",
      " 2.22857554 3.54582261 3.93767706 5.41956257]\n",
      "##########\n",
      "epoch:26 step:122605[D loss: 0.999993] [G loss: 0.999991]\n",
      "epoch:26 step:122610[D loss: 1.000024] [G loss: 0.999976]\n",
      "epoch:26 step:122615[D loss: 1.000010] [G loss: 1.000030]\n",
      "epoch:26 step:122620[D loss: 0.999997] [G loss: 1.000121]\n",
      "epoch:26 step:122625[D loss: 0.999946] [G loss: 1.000158]\n",
      "epoch:26 step:122630[D loss: 0.999934] [G loss: 1.000096]\n",
      "epoch:26 step:122635[D loss: 1.000006] [G loss: 1.000081]\n",
      "epoch:26 step:122640[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:26 step:122645[D loss: 0.999983] [G loss: 0.999932]\n",
      "epoch:26 step:122650[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:26 step:122655[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:26 step:122660[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:26 step:122665[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:26 step:122670[D loss: 0.999950] [G loss: 1.000079]\n",
      "epoch:26 step:122675[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:26 step:122680[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:26 step:122685[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:26 step:122690[D loss: 0.999948] [G loss: 1.000091]\n",
      "epoch:26 step:122695[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:26 step:122700[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:26 step:122705[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:26 step:122710[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:26 step:122715[D loss: 1.000012] [G loss: 1.000008]\n",
      "epoch:26 step:122720[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:26 step:122725[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:26 step:122730[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:26 step:122735[D loss: 0.999999] [G loss: 1.000000]\n",
      "epoch:26 step:122740[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:26 step:122745[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:26 step:122750[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:26 step:122755[D loss: 0.999980] [G loss: 0.999996]\n",
      "epoch:26 step:122760[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:26 step:122765[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:26 step:122770[D loss: 0.999945] [G loss: 1.000117]\n",
      "epoch:26 step:122775[D loss: 0.999964] [G loss: 1.000191]\n",
      "epoch:26 step:122780[D loss: 1.000014] [G loss: 0.999990]\n",
      "epoch:26 step:122785[D loss: 1.000036] [G loss: 1.000019]\n",
      "epoch:26 step:122790[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:26 step:122795[D loss: 1.000034] [G loss: 1.000047]\n",
      "epoch:26 step:122800[D loss: 0.999956] [G loss: 1.000220]\n",
      "##############\n",
      "[2.54045336 2.03009265 2.13557648 4.16476806 1.39656118 7.71284007\n",
      " 2.3859351  3.65438993 3.94498526 5.09828357]\n",
      "##########\n",
      "epoch:26 step:122805[D loss: 0.999999] [G loss: 0.999991]\n",
      "epoch:26 step:122810[D loss: 1.000117] [G loss: 1.000012]\n",
      "epoch:26 step:122815[D loss: 0.999949] [G loss: 1.000150]\n",
      "epoch:26 step:122820[D loss: 0.999934] [G loss: 1.000256]\n",
      "epoch:26 step:122825[D loss: 0.999936] [G loss: 1.000144]\n",
      "epoch:26 step:122830[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:26 step:122835[D loss: 0.999956] [G loss: 1.000105]\n",
      "epoch:26 step:122840[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:26 step:122845[D loss: 1.000041] [G loss: 0.999935]\n",
      "epoch:26 step:122850[D loss: 0.999978] [G loss: 0.999969]\n",
      "epoch:26 step:122855[D loss: 1.000032] [G loss: 0.999991]\n",
      "epoch:26 step:122860[D loss: 0.999985] [G loss: 1.000013]\n",
      "epoch:26 step:122865[D loss: 1.000090] [G loss: 0.999916]\n",
      "epoch:26 step:122870[D loss: 1.000014] [G loss: 1.000035]\n",
      "epoch:26 step:122875[D loss: 1.000000] [G loss: 1.000093]\n",
      "epoch:26 step:122880[D loss: 1.000013] [G loss: 1.000011]\n",
      "epoch:26 step:122885[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:26 step:122890[D loss: 1.000089] [G loss: 0.999988]\n",
      "epoch:26 step:122895[D loss: 1.000147] [G loss: 1.000101]\n",
      "epoch:26 step:122900[D loss: 0.999864] [G loss: 1.000235]\n",
      "epoch:26 step:122905[D loss: 0.999862] [G loss: 1.000249]\n",
      "epoch:26 step:122910[D loss: 0.999960] [G loss: 1.000183]\n",
      "epoch:26 step:122915[D loss: 0.999944] [G loss: 1.000091]\n",
      "epoch:26 step:122920[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:26 step:122925[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:26 step:122930[D loss: 0.999936] [G loss: 1.000057]\n",
      "epoch:26 step:122935[D loss: 1.000019] [G loss: 1.000046]\n",
      "epoch:26 step:122940[D loss: 1.000120] [G loss: 0.999853]\n",
      "epoch:26 step:122945[D loss: 1.000110] [G loss: 1.000031]\n",
      "epoch:26 step:122950[D loss: 0.999945] [G loss: 1.000103]\n",
      "epoch:26 step:122955[D loss: 1.000023] [G loss: 1.000014]\n",
      "epoch:26 step:122960[D loss: 1.000078] [G loss: 0.999905]\n",
      "epoch:26 step:122965[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:26 step:122970[D loss: 1.000059] [G loss: 0.999946]\n",
      "epoch:26 step:122975[D loss: 1.000086] [G loss: 1.000044]\n",
      "epoch:26 step:122980[D loss: 1.000065] [G loss: 1.000105]\n",
      "epoch:26 step:122985[D loss: 1.000069] [G loss: 1.000118]\n",
      "epoch:26 step:122990[D loss: 0.999859] [G loss: 1.000249]\n",
      "epoch:26 step:122995[D loss: 0.999970] [G loss: 1.000127]\n",
      "epoch:26 step:123000[D loss: 0.999924] [G loss: 1.000082]\n",
      "##############\n",
      "[2.5187461  2.0586165  2.17512714 3.59448953 1.37787388 6.47870492\n",
      " 2.19186469 3.46921304 3.9036225  5.30815386]\n",
      "##########\n",
      "epoch:26 step:123005[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:26 step:123010[D loss: 1.000044] [G loss: 0.999929]\n",
      "epoch:26 step:123015[D loss: 1.000079] [G loss: 0.999814]\n",
      "epoch:26 step:123020[D loss: 1.000042] [G loss: 0.999928]\n",
      "epoch:26 step:123025[D loss: 0.999986] [G loss: 0.999914]\n",
      "epoch:26 step:123030[D loss: 1.000157] [G loss: 0.999734]\n",
      "epoch:26 step:123035[D loss: 1.000038] [G loss: 0.999869]\n",
      "epoch:26 step:123040[D loss: 1.000038] [G loss: 0.999962]\n",
      "epoch:26 step:123045[D loss: 0.999918] [G loss: 1.000049]\n",
      "epoch:26 step:123050[D loss: 0.999984] [G loss: 1.000109]\n",
      "epoch:26 step:123055[D loss: 1.000082] [G loss: 0.999876]\n",
      "epoch:26 step:123060[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:26 step:123065[D loss: 0.999934] [G loss: 1.000095]\n",
      "epoch:26 step:123070[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:26 step:123075[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:26 step:123080[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:26 step:123085[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:26 step:123090[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:26 step:123095[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:26 step:123100[D loss: 1.000108] [G loss: 0.999991]\n",
      "epoch:26 step:123105[D loss: 0.999964] [G loss: 1.000039]\n",
      "epoch:26 step:123110[D loss: 0.999896] [G loss: 1.000229]\n",
      "epoch:26 step:123115[D loss: 0.999935] [G loss: 1.000082]\n",
      "epoch:26 step:123120[D loss: 0.999983] [G loss: 1.000112]\n",
      "epoch:26 step:123125[D loss: 0.999994] [G loss: 1.000095]\n",
      "epoch:26 step:123130[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:26 step:123135[D loss: 0.999987] [G loss: 1.000002]\n",
      "epoch:26 step:123140[D loss: 1.000097] [G loss: 0.999983]\n",
      "epoch:26 step:123145[D loss: 0.999933] [G loss: 1.000127]\n",
      "epoch:26 step:123150[D loss: 0.999934] [G loss: 1.000037]\n",
      "epoch:26 step:123155[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:26 step:123160[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:26 step:123165[D loss: 0.999952] [G loss: 1.000099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:123170[D loss: 1.000027] [G loss: 1.000084]\n",
      "epoch:26 step:123175[D loss: 0.999934] [G loss: 1.000144]\n",
      "epoch:26 step:123180[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:26 step:123185[D loss: 0.999984] [G loss: 1.000162]\n",
      "epoch:26 step:123190[D loss: 1.000041] [G loss: 1.000003]\n",
      "epoch:26 step:123195[D loss: 1.000019] [G loss: 1.000018]\n",
      "epoch:26 step:123200[D loss: 0.999907] [G loss: 1.000268]\n",
      "##############\n",
      "[2.44020294 2.08912716 2.31051145 3.8678578  1.38572126 7.34095682\n",
      " 2.26881206 3.61014454 3.95454618 5.22977864]\n",
      "##########\n",
      "epoch:26 step:123205[D loss: 1.000012] [G loss: 1.000040]\n",
      "epoch:26 step:123210[D loss: 0.999947] [G loss: 1.000121]\n",
      "epoch:26 step:123215[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:26 step:123220[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:26 step:123225[D loss: 0.999947] [G loss: 1.000120]\n",
      "epoch:26 step:123230[D loss: 0.999983] [G loss: 1.000107]\n",
      "epoch:26 step:123235[D loss: 1.000008] [G loss: 0.999958]\n",
      "epoch:26 step:123240[D loss: 0.999956] [G loss: 1.000071]\n",
      "epoch:26 step:123245[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:26 step:123250[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:26 step:123255[D loss: 0.999949] [G loss: 1.000079]\n",
      "epoch:26 step:123260[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:26 step:123265[D loss: 0.999967] [G loss: 1.000126]\n",
      "epoch:26 step:123270[D loss: 0.999970] [G loss: 1.000028]\n",
      "epoch:26 step:123275[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:26 step:123280[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:26 step:123285[D loss: 1.000024] [G loss: 0.999976]\n",
      "epoch:26 step:123290[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:26 step:123295[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:26 step:123300[D loss: 1.000018] [G loss: 0.999999]\n",
      "epoch:26 step:123305[D loss: 0.999951] [G loss: 1.000079]\n",
      "epoch:26 step:123310[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:26 step:123315[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:26 step:123320[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:26 step:123325[D loss: 1.000005] [G loss: 1.000060]\n",
      "epoch:26 step:123330[D loss: 0.999996] [G loss: 0.999951]\n",
      "epoch:26 step:123335[D loss: 1.000058] [G loss: 0.999958]\n",
      "epoch:26 step:123340[D loss: 1.000025] [G loss: 1.000041]\n",
      "epoch:26 step:123345[D loss: 0.999938] [G loss: 1.000047]\n",
      "epoch:26 step:123350[D loss: 0.999979] [G loss: 1.000013]\n",
      "epoch:26 step:123355[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:26 step:123360[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:26 step:123365[D loss: 1.000026] [G loss: 0.999989]\n",
      "epoch:26 step:123370[D loss: 0.999944] [G loss: 1.000098]\n",
      "epoch:26 step:123375[D loss: 0.999949] [G loss: 1.000112]\n",
      "epoch:26 step:123380[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:26 step:123385[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:26 step:123390[D loss: 1.000010] [G loss: 1.000043]\n",
      "epoch:26 step:123395[D loss: 1.000004] [G loss: 0.999947]\n",
      "epoch:26 step:123400[D loss: 1.000014] [G loss: 0.999960]\n",
      "##############\n",
      "[2.47247007 2.04487838 2.17015176 3.86021131 1.35644289 7.48400694\n",
      " 2.16407571 3.76722968 3.88342791 5.70482171]\n",
      "##########\n",
      "epoch:26 step:123405[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:26 step:123410[D loss: 0.999982] [G loss: 1.000004]\n",
      "epoch:26 step:123415[D loss: 1.000127] [G loss: 0.999995]\n",
      "epoch:26 step:123420[D loss: 0.999928] [G loss: 1.000132]\n",
      "epoch:26 step:123425[D loss: 1.000016] [G loss: 1.000089]\n",
      "epoch:26 step:123430[D loss: 0.999883] [G loss: 1.000112]\n",
      "epoch:26 step:123435[D loss: 0.999954] [G loss: 1.000074]\n",
      "epoch:26 step:123440[D loss: 1.000034] [G loss: 0.999978]\n",
      "epoch:26 step:123445[D loss: 1.000100] [G loss: 0.999901]\n",
      "epoch:26 step:123450[D loss: 0.999909] [G loss: 1.000136]\n",
      "epoch:26 step:123455[D loss: 1.000036] [G loss: 1.000000]\n",
      "epoch:26 step:123460[D loss: 0.999914] [G loss: 1.000067]\n",
      "epoch:26 step:123465[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:26 step:123470[D loss: 1.000016] [G loss: 1.000048]\n",
      "epoch:26 step:123475[D loss: 0.999961] [G loss: 1.000133]\n",
      "epoch:26 step:123480[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:26 step:123485[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:26 step:123490[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:26 step:123495[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:26 step:123500[D loss: 0.999984] [G loss: 1.000010]\n",
      "epoch:26 step:123505[D loss: 0.999996] [G loss: 0.999983]\n",
      "epoch:26 step:123510[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:26 step:123515[D loss: 1.000121] [G loss: 0.999907]\n",
      "epoch:26 step:123520[D loss: 0.999899] [G loss: 1.000182]\n",
      "epoch:26 step:123525[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:26 step:123530[D loss: 0.999951] [G loss: 1.000082]\n",
      "epoch:26 step:123535[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:26 step:123540[D loss: 1.000067] [G loss: 0.999985]\n",
      "epoch:26 step:123545[D loss: 0.999934] [G loss: 1.000079]\n",
      "epoch:26 step:123550[D loss: 0.999966] [G loss: 1.000024]\n",
      "epoch:26 step:123555[D loss: 1.000084] [G loss: 1.000013]\n",
      "epoch:26 step:123560[D loss: 0.999941] [G loss: 1.000079]\n",
      "epoch:26 step:123565[D loss: 1.000121] [G loss: 0.999934]\n",
      "epoch:26 step:123570[D loss: 1.000004] [G loss: 1.000117]\n",
      "epoch:26 step:123575[D loss: 0.999925] [G loss: 1.000149]\n",
      "epoch:26 step:123580[D loss: 1.000019] [G loss: 1.000015]\n",
      "epoch:26 step:123585[D loss: 0.999896] [G loss: 1.000172]\n",
      "epoch:26 step:123590[D loss: 0.999971] [G loss: 1.000157]\n",
      "epoch:26 step:123595[D loss: 0.999957] [G loss: 1.000116]\n",
      "epoch:26 step:123600[D loss: 1.000082] [G loss: 0.999983]\n",
      "##############\n",
      "[2.50299346 2.08443656 2.11423666 3.66927603 1.34362411 8.1138308\n",
      " 2.23126874 3.67240566 3.9169395  4.83056633]\n",
      "##########\n",
      "epoch:26 step:123605[D loss: 0.999989] [G loss: 0.999996]\n",
      "epoch:26 step:123610[D loss: 1.000124] [G loss: 0.999886]\n",
      "epoch:26 step:123615[D loss: 1.000052] [G loss: 0.999883]\n",
      "epoch:26 step:123620[D loss: 0.999889] [G loss: 1.000089]\n",
      "epoch:26 step:123625[D loss: 0.999966] [G loss: 1.000002]\n",
      "epoch:26 step:123630[D loss: 1.000056] [G loss: 1.000018]\n",
      "epoch:26 step:123635[D loss: 1.000024] [G loss: 0.999974]\n",
      "epoch:26 step:123640[D loss: 1.000007] [G loss: 0.999964]\n",
      "epoch:26 step:123645[D loss: 0.999995] [G loss: 1.000098]\n",
      "epoch:26 step:123650[D loss: 1.000044] [G loss: 0.999917]\n",
      "epoch:26 step:123655[D loss: 0.999979] [G loss: 1.000101]\n",
      "epoch:26 step:123660[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:26 step:123665[D loss: 0.999909] [G loss: 1.000184]\n",
      "epoch:26 step:123670[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:26 step:123675[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:26 step:123680[D loss: 1.000114] [G loss: 0.999950]\n",
      "epoch:26 step:123685[D loss: 0.999924] [G loss: 1.000070]\n",
      "epoch:26 step:123690[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:26 step:123695[D loss: 1.000050] [G loss: 0.999933]\n",
      "epoch:26 step:123700[D loss: 1.000054] [G loss: 1.000052]\n",
      "epoch:26 step:123705[D loss: 1.000138] [G loss: 0.999727]\n",
      "epoch:26 step:123710[D loss: 0.999905] [G loss: 1.000058]\n",
      "epoch:26 step:123715[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:26 step:123720[D loss: 1.000037] [G loss: 0.999999]\n",
      "epoch:26 step:123725[D loss: 0.999873] [G loss: 1.000153]\n",
      "epoch:26 step:123730[D loss: 0.999950] [G loss: 1.000070]\n",
      "epoch:26 step:123735[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:26 step:123740[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:26 step:123745[D loss: 1.000004] [G loss: 1.000054]\n",
      "epoch:26 step:123750[D loss: 1.000010] [G loss: 1.000000]\n",
      "epoch:26 step:123755[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:26 step:123760[D loss: 1.000021] [G loss: 1.000083]\n",
      "epoch:26 step:123765[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:26 step:123770[D loss: 1.000054] [G loss: 1.000047]\n",
      "epoch:26 step:123775[D loss: 0.999927] [G loss: 1.000130]\n",
      "epoch:26 step:123780[D loss: 1.000039] [G loss: 0.999982]\n",
      "epoch:26 step:123785[D loss: 0.999933] [G loss: 1.000111]\n",
      "epoch:26 step:123790[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:26 step:123795[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:26 step:123800[D loss: 0.999987] [G loss: 1.000040]\n",
      "##############\n",
      "[2.40678138 2.04505223 2.0486121  3.42000585 1.27548151 7.03973617\n",
      " 2.19811957 3.60732067 3.78662208 5.89690711]\n",
      "##########\n",
      "epoch:26 step:123805[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:26 step:123810[D loss: 0.999996] [G loss: 1.000015]\n",
      "epoch:26 step:123815[D loss: 1.000064] [G loss: 0.999976]\n",
      "epoch:26 step:123820[D loss: 0.999996] [G loss: 1.000039]\n",
      "epoch:26 step:123825[D loss: 0.999965] [G loss: 1.000110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:123830[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:26 step:123835[D loss: 0.999940] [G loss: 1.000049]\n",
      "epoch:26 step:123840[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:26 step:123845[D loss: 1.000005] [G loss: 1.000023]\n",
      "epoch:26 step:123850[D loss: 0.999953] [G loss: 1.000071]\n",
      "epoch:26 step:123855[D loss: 1.000005] [G loss: 0.999990]\n",
      "epoch:26 step:123860[D loss: 1.000124] [G loss: 0.999949]\n",
      "epoch:26 step:123865[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:26 step:123870[D loss: 0.999984] [G loss: 1.000025]\n",
      "epoch:26 step:123875[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:26 step:123880[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:26 step:123885[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:26 step:123890[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:26 step:123895[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:26 step:123900[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:26 step:123905[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:26 step:123910[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:26 step:123915[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:26 step:123920[D loss: 1.000026] [G loss: 0.999989]\n",
      "epoch:26 step:123925[D loss: 0.999949] [G loss: 1.000105]\n",
      "epoch:26 step:123930[D loss: 0.999981] [G loss: 1.000108]\n",
      "epoch:26 step:123935[D loss: 1.000035] [G loss: 1.000042]\n",
      "epoch:26 step:123940[D loss: 0.999950] [G loss: 1.000112]\n",
      "epoch:26 step:123945[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:26 step:123950[D loss: 1.000024] [G loss: 1.000016]\n",
      "epoch:26 step:123955[D loss: 0.999960] [G loss: 1.000101]\n",
      "epoch:26 step:123960[D loss: 0.999985] [G loss: 0.999998]\n",
      "epoch:26 step:123965[D loss: 0.999949] [G loss: 1.000048]\n",
      "epoch:26 step:123970[D loss: 1.000021] [G loss: 1.000004]\n",
      "epoch:26 step:123975[D loss: 0.999999] [G loss: 0.999969]\n",
      "epoch:26 step:123980[D loss: 1.000026] [G loss: 1.000032]\n",
      "epoch:26 step:123985[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:26 step:123990[D loss: 0.999941] [G loss: 1.000065]\n",
      "epoch:26 step:123995[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:26 step:124000[D loss: 0.999985] [G loss: 1.000052]\n",
      "##############\n",
      "[2.420585   2.03309853 2.12246894 3.85171105 1.32008223 7.16649467\n",
      " 2.17730622 3.58109849 3.93477457 5.95996286]\n",
      "##########\n",
      "epoch:26 step:124005[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:26 step:124010[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:26 step:124015[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:26 step:124020[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:26 step:124025[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:26 step:124030[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:26 step:124035[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:26 step:124040[D loss: 1.000001] [G loss: 1.000066]\n",
      "epoch:26 step:124045[D loss: 1.000016] [G loss: 1.000052]\n",
      "epoch:26 step:124050[D loss: 1.000072] [G loss: 0.999959]\n",
      "epoch:26 step:124055[D loss: 0.999809] [G loss: 1.000258]\n",
      "epoch:26 step:124060[D loss: 0.999997] [G loss: 1.000102]\n",
      "epoch:26 step:124065[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:26 step:124070[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:26 step:124075[D loss: 0.999944] [G loss: 1.000133]\n",
      "epoch:26 step:124080[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:26 step:124085[D loss: 1.000005] [G loss: 0.999984]\n",
      "epoch:26 step:124090[D loss: 0.999941] [G loss: 1.000086]\n",
      "epoch:26 step:124095[D loss: 1.000039] [G loss: 0.999951]\n",
      "epoch:26 step:124100[D loss: 0.999995] [G loss: 1.000040]\n",
      "epoch:26 step:124105[D loss: 1.000183] [G loss: 1.000009]\n",
      "epoch:26 step:124110[D loss: 1.000041] [G loss: 0.999872]\n",
      "epoch:26 step:124115[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:26 step:124120[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:26 step:124125[D loss: 0.999938] [G loss: 1.000113]\n",
      "epoch:26 step:124130[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:26 step:124135[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:26 step:124140[D loss: 0.999971] [G loss: 1.000033]\n",
      "epoch:26 step:124145[D loss: 0.999941] [G loss: 1.000108]\n",
      "epoch:26 step:124150[D loss: 1.000140] [G loss: 0.999868]\n",
      "epoch:26 step:124155[D loss: 0.999969] [G loss: 1.000263]\n",
      "epoch:26 step:124160[D loss: 0.999907] [G loss: 1.000143]\n",
      "epoch:26 step:124165[D loss: 0.999963] [G loss: 1.000154]\n",
      "epoch:26 step:124170[D loss: 0.999972] [G loss: 1.000149]\n",
      "epoch:26 step:124175[D loss: 0.999929] [G loss: 1.000138]\n",
      "epoch:26 step:124180[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:26 step:124185[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:26 step:124190[D loss: 0.999982] [G loss: 0.999989]\n",
      "epoch:26 step:124195[D loss: 1.000001] [G loss: 1.000012]\n",
      "epoch:26 step:124200[D loss: 1.000086] [G loss: 0.999902]\n",
      "##############\n",
      "[2.44545287 2.10749407 2.14053104 3.93423303 1.39808412 7.07493877\n",
      " 2.2554871  3.79169768 3.91228967 5.43974449]\n",
      "##########\n",
      "epoch:26 step:124205[D loss: 0.999934] [G loss: 1.000067]\n",
      "epoch:26 step:124210[D loss: 0.999936] [G loss: 1.000026]\n",
      "epoch:26 step:124215[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:26 step:124220[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:26 step:124225[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:26 step:124230[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:26 step:124235[D loss: 1.000034] [G loss: 0.999992]\n",
      "epoch:26 step:124240[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:26 step:124245[D loss: 1.000026] [G loss: 0.999978]\n",
      "epoch:26 step:124250[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:26 step:124255[D loss: 0.999942] [G loss: 1.000129]\n",
      "epoch:26 step:124260[D loss: 0.999978] [G loss: 1.000131]\n",
      "epoch:26 step:124265[D loss: 0.999938] [G loss: 1.000131]\n",
      "epoch:26 step:124270[D loss: 0.999978] [G loss: 1.000102]\n",
      "epoch:26 step:124275[D loss: 1.000039] [G loss: 1.000127]\n",
      "epoch:26 step:124280[D loss: 0.999977] [G loss: 1.000148]\n",
      "epoch:26 step:124285[D loss: 0.999925] [G loss: 1.000108]\n",
      "epoch:26 step:124290[D loss: 1.000163] [G loss: 0.999993]\n",
      "epoch:26 step:124295[D loss: 0.999890] [G loss: 1.000238]\n",
      "epoch:26 step:124300[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:26 step:124305[D loss: 1.000030] [G loss: 0.999991]\n",
      "epoch:26 step:124310[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:26 step:124315[D loss: 0.999894] [G loss: 1.000111]\n",
      "epoch:26 step:124320[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:26 step:124325[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:26 step:124330[D loss: 1.000005] [G loss: 1.000012]\n",
      "epoch:26 step:124335[D loss: 1.000006] [G loss: 1.000047]\n",
      "epoch:26 step:124340[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:26 step:124345[D loss: 1.000080] [G loss: 1.000063]\n",
      "epoch:26 step:124350[D loss: 0.999968] [G loss: 1.000157]\n",
      "epoch:26 step:124355[D loss: 0.999995] [G loss: 1.000101]\n",
      "epoch:26 step:124360[D loss: 1.000134] [G loss: 1.000142]\n",
      "epoch:26 step:124365[D loss: 0.999905] [G loss: 1.000224]\n",
      "epoch:26 step:124370[D loss: 0.999911] [G loss: 1.000131]\n",
      "epoch:26 step:124375[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:26 step:124380[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:26 step:124385[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:26 step:124390[D loss: 0.999989] [G loss: 1.000026]\n",
      "epoch:26 step:124395[D loss: 1.000076] [G loss: 1.000005]\n",
      "epoch:26 step:124400[D loss: 1.000009] [G loss: 0.999927]\n",
      "##############\n",
      "[2.4811734  2.17875027 2.26471957 3.74095649 1.48839967 7.63634658\n",
      " 2.57293495 3.93089256 4.03696311 5.08327608]\n",
      "##########\n",
      "epoch:26 step:124405[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:26 step:124410[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:26 step:124415[D loss: 1.000034] [G loss: 1.000006]\n",
      "epoch:26 step:124420[D loss: 0.999949] [G loss: 1.000077]\n",
      "epoch:26 step:124425[D loss: 0.999912] [G loss: 1.000180]\n",
      "epoch:26 step:124430[D loss: 1.000010] [G loss: 1.000138]\n",
      "epoch:26 step:124435[D loss: 0.999950] [G loss: 1.000092]\n",
      "epoch:26 step:124440[D loss: 0.999993] [G loss: 1.000021]\n",
      "epoch:26 step:124445[D loss: 0.999943] [G loss: 1.000054]\n",
      "epoch:26 step:124450[D loss: 0.999982] [G loss: 1.000031]\n",
      "epoch:26 step:124455[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:26 step:124460[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:26 step:124465[D loss: 0.999980] [G loss: 1.000093]\n",
      "epoch:26 step:124470[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:26 step:124475[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:26 step:124480[D loss: 0.999991] [G loss: 1.000040]\n",
      "epoch:26 step:124485[D loss: 1.000006] [G loss: 1.000035]\n",
      "epoch:26 step:124490[D loss: 0.999976] [G loss: 1.000153]\n",
      "epoch:26 step:124495[D loss: 1.000003] [G loss: 1.000108]\n",
      "epoch:26 step:124500[D loss: 0.999976] [G loss: 1.000109]\n",
      "epoch:26 step:124505[D loss: 1.000049] [G loss: 0.999980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:124510[D loss: 0.999940] [G loss: 1.000120]\n",
      "epoch:26 step:124515[D loss: 0.999941] [G loss: 1.000103]\n",
      "epoch:26 step:124520[D loss: 1.000033] [G loss: 1.000036]\n",
      "epoch:26 step:124525[D loss: 1.000041] [G loss: 1.000007]\n",
      "epoch:26 step:124530[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:26 step:124535[D loss: 1.000094] [G loss: 0.999970]\n",
      "epoch:26 step:124540[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:26 step:124545[D loss: 0.999927] [G loss: 1.000092]\n",
      "epoch:26 step:124550[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:26 step:124555[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:26 step:124560[D loss: 1.000015] [G loss: 1.000080]\n",
      "epoch:26 step:124565[D loss: 1.000031] [G loss: 1.000039]\n",
      "epoch:26 step:124570[D loss: 1.000015] [G loss: 0.999929]\n",
      "epoch:26 step:124575[D loss: 1.000187] [G loss: 0.999858]\n",
      "epoch:26 step:124580[D loss: 0.999900] [G loss: 1.000016]\n",
      "epoch:26 step:124585[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:26 step:124590[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:26 step:124595[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:26 step:124600[D loss: 0.999969] [G loss: 1.000111]\n",
      "##############\n",
      "[2.44000768 2.17291697 2.20077852 3.85147784 1.4459775  7.39486869\n",
      " 2.35867728 3.66250556 3.95702102 5.23414571]\n",
      "##########\n",
      "epoch:26 step:124605[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:26 step:124610[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:26 step:124615[D loss: 0.999995] [G loss: 0.999992]\n",
      "epoch:26 step:124620[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:26 step:124625[D loss: 1.000041] [G loss: 1.000077]\n",
      "epoch:26 step:124630[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:26 step:124635[D loss: 0.999938] [G loss: 1.000162]\n",
      "epoch:26 step:124640[D loss: 0.999968] [G loss: 1.000028]\n",
      "epoch:26 step:124645[D loss: 0.999997] [G loss: 1.000026]\n",
      "epoch:26 step:124650[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:26 step:124655[D loss: 1.000002] [G loss: 1.000034]\n",
      "epoch:26 step:124660[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:26 step:124665[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:26 step:124670[D loss: 0.999950] [G loss: 1.000053]\n",
      "epoch:26 step:124675[D loss: 1.000051] [G loss: 1.000026]\n",
      "epoch:26 step:124680[D loss: 0.999979] [G loss: 1.000007]\n",
      "epoch:26 step:124685[D loss: 1.000101] [G loss: 0.999972]\n",
      "epoch:26 step:124690[D loss: 0.999920] [G loss: 1.000253]\n",
      "epoch:26 step:124695[D loss: 0.999841] [G loss: 1.000152]\n",
      "epoch:26 step:124700[D loss: 1.000057] [G loss: 1.000088]\n",
      "epoch:26 step:124705[D loss: 0.999971] [G loss: 1.000098]\n",
      "epoch:26 step:124710[D loss: 1.000019] [G loss: 1.000245]\n",
      "epoch:26 step:124715[D loss: 0.999909] [G loss: 1.000160]\n",
      "epoch:26 step:124720[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:26 step:124725[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:26 step:124730[D loss: 0.999968] [G loss: 1.000024]\n",
      "epoch:26 step:124735[D loss: 0.999997] [G loss: 0.999989]\n",
      "epoch:26 step:124740[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:26 step:124745[D loss: 1.000004] [G loss: 1.000072]\n",
      "epoch:26 step:124750[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:26 step:124755[D loss: 1.000071] [G loss: 1.000021]\n",
      "epoch:26 step:124760[D loss: 0.999874] [G loss: 1.000167]\n",
      "epoch:26 step:124765[D loss: 0.999960] [G loss: 1.000121]\n",
      "epoch:26 step:124770[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:26 step:124775[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:26 step:124780[D loss: 1.000055] [G loss: 1.000024]\n",
      "epoch:26 step:124785[D loss: 1.000149] [G loss: 1.000151]\n",
      "epoch:26 step:124790[D loss: 0.999940] [G loss: 1.000082]\n",
      "epoch:26 step:124795[D loss: 0.999974] [G loss: 1.000004]\n",
      "epoch:26 step:124800[D loss: 0.999918] [G loss: 1.000167]\n",
      "##############\n",
      "[2.51361403 2.19099464 2.18200118 3.78963324 1.51159188 7.29902785\n",
      " 2.26891813 3.75237459 3.9946262  5.25001284]\n",
      "##########\n",
      "epoch:26 step:124805[D loss: 0.999924] [G loss: 1.000118]\n",
      "epoch:26 step:124810[D loss: 1.000019] [G loss: 1.000120]\n",
      "epoch:26 step:124815[D loss: 0.999940] [G loss: 1.000121]\n",
      "epoch:26 step:124820[D loss: 1.000025] [G loss: 0.999958]\n",
      "epoch:26 step:124825[D loss: 0.999974] [G loss: 1.000018]\n",
      "epoch:26 step:124830[D loss: 1.000000] [G loss: 1.000069]\n",
      "epoch:26 step:124835[D loss: 0.999949] [G loss: 1.000058]\n",
      "epoch:26 step:124840[D loss: 0.999938] [G loss: 1.000038]\n",
      "epoch:26 step:124845[D loss: 1.000013] [G loss: 1.000014]\n",
      "epoch:26 step:124850[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:26 step:124855[D loss: 1.000154] [G loss: 0.999857]\n",
      "epoch:26 step:124860[D loss: 0.999934] [G loss: 1.000067]\n",
      "epoch:26 step:124865[D loss: 1.000057] [G loss: 0.999988]\n",
      "epoch:26 step:124870[D loss: 0.999883] [G loss: 1.000226]\n",
      "epoch:26 step:124875[D loss: 0.999988] [G loss: 0.999982]\n",
      "epoch:26 step:124880[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:26 step:124885[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:26 step:124890[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:26 step:124895[D loss: 1.000030] [G loss: 1.000010]\n",
      "epoch:26 step:124900[D loss: 1.000102] [G loss: 0.999922]\n",
      "epoch:26 step:124905[D loss: 0.999955] [G loss: 1.000021]\n",
      "epoch:26 step:124910[D loss: 1.000044] [G loss: 1.000079]\n",
      "epoch:26 step:124915[D loss: 0.999894] [G loss: 1.000145]\n",
      "epoch:26 step:124920[D loss: 1.000113] [G loss: 0.999894]\n",
      "epoch:26 step:124925[D loss: 0.999939] [G loss: 1.000082]\n",
      "epoch:26 step:124930[D loss: 1.000009] [G loss: 1.000057]\n",
      "epoch:26 step:124935[D loss: 1.000024] [G loss: 1.000098]\n",
      "epoch:26 step:124940[D loss: 0.999928] [G loss: 1.000138]\n",
      "epoch:26 step:124945[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:26 step:124950[D loss: 1.000012] [G loss: 0.999965]\n",
      "epoch:26 step:124955[D loss: 0.999971] [G loss: 0.999981]\n",
      "epoch:26 step:124960[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:26 step:124965[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:26 step:124970[D loss: 0.999972] [G loss: 1.000159]\n",
      "epoch:26 step:124975[D loss: 0.999918] [G loss: 1.000162]\n",
      "epoch:26 step:124980[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:26 step:124985[D loss: 1.000020] [G loss: 1.000072]\n",
      "epoch:26 step:124990[D loss: 0.999901] [G loss: 1.000092]\n",
      "epoch:26 step:124995[D loss: 1.000010] [G loss: 0.999994]\n",
      "epoch:26 step:125000[D loss: 0.999928] [G loss: 1.000123]\n",
      "##############\n",
      "[2.45586927 2.09072696 2.0681949  3.28738678 1.41285756 7.75069236\n",
      " 2.30490107 3.75977762 3.90434351 4.81646374]\n",
      "##########\n",
      "epoch:26 step:125005[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:26 step:125010[D loss: 1.000085] [G loss: 0.999886]\n",
      "epoch:26 step:125015[D loss: 1.000033] [G loss: 0.999950]\n",
      "epoch:26 step:125020[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:26 step:125025[D loss: 0.999927] [G loss: 1.000097]\n",
      "epoch:26 step:125030[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:26 step:125035[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:26 step:125040[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:26 step:125045[D loss: 0.999955] [G loss: 1.000058]\n",
      "epoch:26 step:125050[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:26 step:125055[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:26 step:125060[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:26 step:125065[D loss: 0.999995] [G loss: 1.000106]\n",
      "epoch:26 step:125070[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:26 step:125075[D loss: 0.999966] [G loss: 1.000052]\n",
      "epoch:26 step:125080[D loss: 1.000036] [G loss: 0.999918]\n",
      "epoch:26 step:125085[D loss: 0.999979] [G loss: 1.000020]\n",
      "epoch:26 step:125090[D loss: 0.999986] [G loss: 1.000103]\n",
      "epoch:26 step:125095[D loss: 0.999938] [G loss: 1.000159]\n",
      "epoch:26 step:125100[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:26 step:125105[D loss: 1.000054] [G loss: 0.999933]\n",
      "epoch:26 step:125110[D loss: 0.999909] [G loss: 1.000132]\n",
      "epoch:26 step:125115[D loss: 1.000094] [G loss: 0.999900]\n",
      "epoch:26 step:125120[D loss: 0.999981] [G loss: 1.000185]\n",
      "epoch:26 step:125125[D loss: 0.999986] [G loss: 1.000200]\n",
      "epoch:26 step:125130[D loss: 0.999967] [G loss: 1.000011]\n",
      "epoch:26 step:125135[D loss: 0.999976] [G loss: 0.999983]\n",
      "epoch:26 step:125140[D loss: 1.000020] [G loss: 0.999873]\n",
      "epoch:26 step:125145[D loss: 0.999937] [G loss: 1.000055]\n",
      "epoch:26 step:125150[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:26 step:125155[D loss: 0.999979] [G loss: 1.000016]\n",
      "epoch:26 step:125160[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:26 step:125165[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:26 step:125170[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:26 step:125175[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:26 step:125180[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:26 step:125185[D loss: 1.000010] [G loss: 1.000015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:125190[D loss: 0.999910] [G loss: 1.000121]\n",
      "epoch:26 step:125195[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:26 step:125200[D loss: 0.999998] [G loss: 1.000043]\n",
      "##############\n",
      "[2.51930851 2.1166436  2.12792046 3.60105319 1.43106512 7.48277197\n",
      " 2.38376087 3.46950296 3.87821337 4.76482441]\n",
      "##########\n",
      "epoch:26 step:125205[D loss: 0.999937] [G loss: 1.000117]\n",
      "epoch:26 step:125210[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:26 step:125215[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:26 step:125220[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:26 step:125225[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:26 step:125230[D loss: 0.999997] [G loss: 1.000027]\n",
      "epoch:26 step:125235[D loss: 1.000064] [G loss: 0.999958]\n",
      "epoch:26 step:125240[D loss: 1.000007] [G loss: 1.000000]\n",
      "epoch:26 step:125245[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:26 step:125250[D loss: 1.000020] [G loss: 1.000062]\n",
      "epoch:26 step:125255[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:26 step:125260[D loss: 0.999944] [G loss: 1.000117]\n",
      "epoch:26 step:125265[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:26 step:125270[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:26 step:125275[D loss: 0.999977] [G loss: 1.000103]\n",
      "epoch:26 step:125280[D loss: 0.999929] [G loss: 1.000104]\n",
      "epoch:26 step:125285[D loss: 1.000070] [G loss: 0.999911]\n",
      "epoch:26 step:125290[D loss: 1.000012] [G loss: 0.999955]\n",
      "epoch:26 step:125295[D loss: 0.999918] [G loss: 1.000101]\n",
      "epoch:26 step:125300[D loss: 0.999981] [G loss: 1.000113]\n",
      "epoch:26 step:125305[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:26 step:125310[D loss: 0.999960] [G loss: 1.000121]\n",
      "epoch:26 step:125315[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:26 step:125320[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:26 step:125325[D loss: 1.000016] [G loss: 1.000012]\n",
      "epoch:26 step:125330[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:26 step:125335[D loss: 1.000070] [G loss: 1.000003]\n",
      "epoch:26 step:125340[D loss: 1.000003] [G loss: 1.000066]\n",
      "epoch:26 step:125345[D loss: 0.999937] [G loss: 1.000123]\n",
      "epoch:26 step:125350[D loss: 0.999952] [G loss: 1.000117]\n",
      "epoch:26 step:125355[D loss: 1.000018] [G loss: 1.000057]\n",
      "epoch:26 step:125360[D loss: 1.000098] [G loss: 0.999988]\n",
      "epoch:26 step:125365[D loss: 1.000044] [G loss: 0.999963]\n",
      "epoch:26 step:125370[D loss: 0.999961] [G loss: 1.000032]\n",
      "epoch:26 step:125375[D loss: 1.000038] [G loss: 1.000048]\n",
      "epoch:26 step:125380[D loss: 1.000039] [G loss: 1.000118]\n",
      "epoch:26 step:125385[D loss: 0.999928] [G loss: 1.000134]\n",
      "epoch:26 step:125390[D loss: 0.999951] [G loss: 1.000069]\n",
      "epoch:26 step:125395[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:26 step:125400[D loss: 0.999968] [G loss: 1.000053]\n",
      "##############\n",
      "[2.50277235 2.21056809 2.32485892 3.92574854 1.49545942 7.95743441\n",
      " 2.47402146 3.91238836 4.0771361  5.431255  ]\n",
      "##########\n",
      "epoch:26 step:125405[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:26 step:125410[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:26 step:125415[D loss: 0.999958] [G loss: 1.000125]\n",
      "epoch:26 step:125420[D loss: 0.999982] [G loss: 1.000165]\n",
      "epoch:26 step:125425[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:26 step:125430[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:26 step:125435[D loss: 0.999959] [G loss: 1.000106]\n",
      "epoch:26 step:125440[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:26 step:125445[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:26 step:125450[D loss: 1.000035] [G loss: 1.000028]\n",
      "epoch:26 step:125455[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:26 step:125460[D loss: 1.000039] [G loss: 1.000035]\n",
      "epoch:26 step:125465[D loss: 0.999957] [G loss: 1.000053]\n",
      "epoch:26 step:125470[D loss: 1.000010] [G loss: 0.999983]\n",
      "epoch:26 step:125475[D loss: 0.999938] [G loss: 1.000085]\n",
      "epoch:26 step:125480[D loss: 0.999999] [G loss: 1.000051]\n",
      "epoch:26 step:125485[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:26 step:125490[D loss: 1.000028] [G loss: 1.000024]\n",
      "epoch:26 step:125495[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:26 step:125500[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:26 step:125505[D loss: 1.000010] [G loss: 1.000112]\n",
      "epoch:26 step:125510[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:26 step:125515[D loss: 1.000038] [G loss: 0.999992]\n",
      "epoch:26 step:125520[D loss: 1.000173] [G loss: 0.999933]\n",
      "epoch:26 step:125525[D loss: 0.999854] [G loss: 1.000040]\n",
      "epoch:26 step:125530[D loss: 0.999948] [G loss: 1.000121]\n",
      "epoch:26 step:125535[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:26 step:125540[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:26 step:125545[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:26 step:125550[D loss: 1.000065] [G loss: 0.999950]\n",
      "epoch:26 step:125555[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:26 step:125560[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:26 step:125565[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:26 step:125570[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:26 step:125575[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:26 step:125580[D loss: 1.000012] [G loss: 1.000063]\n",
      "epoch:26 step:125585[D loss: 1.000008] [G loss: 1.000079]\n",
      "epoch:26 step:125590[D loss: 0.999884] [G loss: 1.000125]\n",
      "epoch:26 step:125595[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:26 step:125600[D loss: 0.999976] [G loss: 1.000066]\n",
      "##############\n",
      "[2.48612252 2.20930533 2.23039084 3.90464979 1.38033279 7.40842522\n",
      " 2.08970503 3.65757805 4.0446378  7.14868929]\n",
      "##########\n",
      "epoch:26 step:125605[D loss: 0.999939] [G loss: 1.000092]\n",
      "epoch:26 step:125610[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:26 step:125615[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:26 step:125620[D loss: 1.000098] [G loss: 0.999894]\n",
      "epoch:26 step:125625[D loss: 0.999990] [G loss: 1.000006]\n",
      "epoch:26 step:125630[D loss: 1.000057] [G loss: 0.999918]\n",
      "epoch:26 step:125635[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:26 step:125640[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:26 step:125645[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:26 step:125650[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:26 step:125655[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:26 step:125660[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:26 step:125665[D loss: 1.000008] [G loss: 1.000098]\n",
      "epoch:26 step:125670[D loss: 0.999980] [G loss: 1.000112]\n",
      "epoch:26 step:125675[D loss: 1.000058] [G loss: 0.999902]\n",
      "epoch:26 step:125680[D loss: 1.000087] [G loss: 1.000052]\n",
      "epoch:26 step:125685[D loss: 0.999881] [G loss: 1.000129]\n",
      "epoch:26 step:125690[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:26 step:125695[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:26 step:125700[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:26 step:125705[D loss: 1.000001] [G loss: 1.000093]\n",
      "epoch:26 step:125710[D loss: 0.999998] [G loss: 0.999995]\n",
      "epoch:26 step:125715[D loss: 0.999917] [G loss: 1.000066]\n",
      "epoch:26 step:125720[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:26 step:125725[D loss: 1.000037] [G loss: 1.000032]\n",
      "epoch:26 step:125730[D loss: 0.999997] [G loss: 1.000086]\n",
      "epoch:26 step:125735[D loss: 1.000018] [G loss: 1.000033]\n",
      "epoch:26 step:125740[D loss: 0.999964] [G loss: 1.000122]\n",
      "epoch:26 step:125745[D loss: 1.000006] [G loss: 0.999987]\n",
      "epoch:26 step:125750[D loss: 0.999989] [G loss: 1.000020]\n",
      "epoch:26 step:125755[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:26 step:125760[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:26 step:125765[D loss: 0.999939] [G loss: 1.000109]\n",
      "epoch:26 step:125770[D loss: 0.999916] [G loss: 1.000135]\n",
      "epoch:26 step:125775[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:26 step:125780[D loss: 0.999994] [G loss: 1.000013]\n",
      "epoch:26 step:125785[D loss: 0.999984] [G loss: 1.000114]\n",
      "epoch:26 step:125790[D loss: 1.000033] [G loss: 1.000044]\n",
      "epoch:26 step:125795[D loss: 0.999949] [G loss: 1.000158]\n",
      "epoch:26 step:125800[D loss: 0.999943] [G loss: 1.000230]\n",
      "##############\n",
      "[2.49168601 2.2309826  2.34209182 3.77271253 1.40647641 6.95422904\n",
      " 2.30266902 3.70298691 3.9770482  5.29110931]\n",
      "##########\n",
      "epoch:26 step:125805[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:26 step:125810[D loss: 0.999946] [G loss: 1.000089]\n",
      "epoch:26 step:125815[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:26 step:125820[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:26 step:125825[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:26 step:125830[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:26 step:125835[D loss: 1.000041] [G loss: 1.000052]\n",
      "epoch:26 step:125840[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:26 step:125845[D loss: 1.000044] [G loss: 1.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:125850[D loss: 1.000157] [G loss: 0.999959]\n",
      "epoch:26 step:125855[D loss: 0.999900] [G loss: 1.000146]\n",
      "epoch:26 step:125860[D loss: 0.999945] [G loss: 1.000132]\n",
      "epoch:26 step:125865[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:26 step:125870[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:26 step:125875[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:26 step:125880[D loss: 1.000030] [G loss: 1.000004]\n",
      "epoch:26 step:125885[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:26 step:125890[D loss: 0.999963] [G loss: 1.000120]\n",
      "epoch:26 step:125895[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:26 step:125900[D loss: 0.999975] [G loss: 1.000132]\n",
      "epoch:26 step:125905[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:26 step:125910[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:26 step:125915[D loss: 1.000038] [G loss: 1.000019]\n",
      "epoch:26 step:125920[D loss: 0.999959] [G loss: 1.000117]\n",
      "epoch:26 step:125925[D loss: 0.999917] [G loss: 1.000132]\n",
      "epoch:26 step:125930[D loss: 0.999929] [G loss: 1.000083]\n",
      "epoch:26 step:125935[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:26 step:125940[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:26 step:125945[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:26 step:125950[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:26 step:125955[D loss: 1.000063] [G loss: 0.999927]\n",
      "epoch:26 step:125960[D loss: 0.999844] [G loss: 1.000132]\n",
      "epoch:26 step:125965[D loss: 0.999951] [G loss: 1.000068]\n",
      "epoch:26 step:125970[D loss: 1.000029] [G loss: 0.999977]\n",
      "epoch:26 step:125975[D loss: 0.999977] [G loss: 1.000029]\n",
      "epoch:26 step:125980[D loss: 0.999929] [G loss: 1.000273]\n",
      "epoch:26 step:125985[D loss: 1.000014] [G loss: 0.999943]\n",
      "epoch:26 step:125990[D loss: 0.999896] [G loss: 1.000117]\n",
      "epoch:26 step:125995[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:26 step:126000[D loss: 0.999976] [G loss: 1.000072]\n",
      "##############\n",
      "[2.46454485 2.19103658 2.18444124 3.65463685 1.36021087 7.1846073\n",
      " 2.22744438 3.62920061 3.88111971 5.94520022]\n",
      "##########\n",
      "epoch:26 step:126005[D loss: 1.000040] [G loss: 1.000036]\n",
      "epoch:26 step:126010[D loss: 0.999945] [G loss: 1.000108]\n",
      "epoch:26 step:126015[D loss: 0.999998] [G loss: 1.000052]\n",
      "epoch:26 step:126020[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:26 step:126025[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:26 step:126030[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:26 step:126035[D loss: 0.999900] [G loss: 1.000170]\n",
      "epoch:26 step:126040[D loss: 0.999959] [G loss: 1.000108]\n",
      "epoch:26 step:126045[D loss: 0.999988] [G loss: 1.000101]\n",
      "epoch:26 step:126050[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:26 step:126055[D loss: 1.000047] [G loss: 0.999973]\n",
      "epoch:26 step:126060[D loss: 0.999938] [G loss: 1.000133]\n",
      "epoch:26 step:126065[D loss: 1.000064] [G loss: 0.999909]\n",
      "epoch:26 step:126070[D loss: 0.999957] [G loss: 1.000142]\n",
      "epoch:26 step:126075[D loss: 1.000032] [G loss: 0.999955]\n",
      "epoch:26 step:126080[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:26 step:126085[D loss: 1.000032] [G loss: 0.999983]\n",
      "epoch:26 step:126090[D loss: 1.000026] [G loss: 1.000001]\n",
      "epoch:26 step:126095[D loss: 1.000028] [G loss: 0.999931]\n",
      "epoch:26 step:126100[D loss: 0.999863] [G loss: 1.000148]\n",
      "epoch:26 step:126105[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:26 step:126110[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:26 step:126115[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:26 step:126120[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:26 step:126125[D loss: 0.999951] [G loss: 1.000153]\n",
      "epoch:26 step:126130[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:26 step:126135[D loss: 0.999940] [G loss: 1.000043]\n",
      "epoch:26 step:126140[D loss: 0.999913] [G loss: 1.000095]\n",
      "epoch:26 step:126145[D loss: 1.000008] [G loss: 1.000092]\n",
      "epoch:26 step:126150[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:26 step:126155[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:26 step:126160[D loss: 0.999943] [G loss: 1.000205]\n",
      "epoch:26 step:126165[D loss: 1.000058] [G loss: 0.999800]\n",
      "epoch:26 step:126170[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:26 step:126175[D loss: 1.000062] [G loss: 1.000003]\n",
      "epoch:26 step:126180[D loss: 0.999994] [G loss: 1.000003]\n",
      "epoch:26 step:126185[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:26 step:126190[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:26 step:126195[D loss: 0.999938] [G loss: 1.000075]\n",
      "epoch:26 step:126200[D loss: 0.999976] [G loss: 1.000052]\n",
      "##############\n",
      "[2.40568095 2.09906533 2.22735609 3.98712037 1.42726529 7.52909967\n",
      " 2.3023414  3.65245373 3.92654934 5.93620397]\n",
      "##########\n",
      "epoch:26 step:126205[D loss: 1.000000] [G loss: 0.999978]\n",
      "epoch:26 step:126210[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:26 step:126215[D loss: 0.999925] [G loss: 1.000071]\n",
      "epoch:26 step:126220[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:26 step:126225[D loss: 0.999957] [G loss: 1.000102]\n",
      "epoch:26 step:126230[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:26 step:126235[D loss: 1.000035] [G loss: 1.000052]\n",
      "epoch:26 step:126240[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:26 step:126245[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:26 step:126250[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:26 step:126255[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:26 step:126260[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:26 step:126265[D loss: 1.000030] [G loss: 0.999959]\n",
      "epoch:26 step:126270[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:26 step:126275[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:26 step:126280[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:26 step:126285[D loss: 0.999989] [G loss: 1.000031]\n",
      "epoch:26 step:126290[D loss: 1.000095] [G loss: 0.999990]\n",
      "epoch:26 step:126295[D loss: 0.999926] [G loss: 1.000088]\n",
      "epoch:26 step:126300[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:26 step:126305[D loss: 1.000031] [G loss: 0.999981]\n",
      "epoch:26 step:126310[D loss: 0.999997] [G loss: 1.000001]\n",
      "epoch:26 step:126315[D loss: 0.999968] [G loss: 1.000031]\n",
      "epoch:26 step:126320[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:26 step:126325[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:26 step:126330[D loss: 1.000069] [G loss: 0.999987]\n",
      "epoch:26 step:126335[D loss: 0.999955] [G loss: 1.000104]\n",
      "epoch:26 step:126340[D loss: 1.000021] [G loss: 1.000050]\n",
      "epoch:26 step:126345[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:26 step:126350[D loss: 1.000190] [G loss: 0.999821]\n",
      "epoch:26 step:126355[D loss: 1.000071] [G loss: 0.999891]\n",
      "epoch:26 step:126360[D loss: 0.999987] [G loss: 0.999956]\n",
      "epoch:26 step:126365[D loss: 0.999957] [G loss: 0.999978]\n",
      "epoch:26 step:126370[D loss: 0.999942] [G loss: 1.000044]\n",
      "epoch:26 step:126375[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:26 step:126380[D loss: 1.000030] [G loss: 1.000058]\n",
      "epoch:26 step:126385[D loss: 0.999899] [G loss: 1.000228]\n",
      "epoch:26 step:126390[D loss: 0.999949] [G loss: 1.000124]\n",
      "epoch:26 step:126395[D loss: 1.000060] [G loss: 1.000150]\n",
      "epoch:26 step:126400[D loss: 0.999969] [G loss: 1.000002]\n",
      "##############\n",
      "[2.45848771 2.24422157 2.22421387 3.98256089 1.3618065  7.53566184\n",
      " 2.1420145  3.68514134 4.00068643 5.34607841]\n",
      "##########\n",
      "epoch:26 step:126405[D loss: 1.000005] [G loss: 0.999989]\n",
      "epoch:26 step:126410[D loss: 0.999937] [G loss: 1.000050]\n",
      "epoch:26 step:126415[D loss: 1.000048] [G loss: 0.999995]\n",
      "epoch:26 step:126420[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:26 step:126425[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:26 step:126430[D loss: 0.999975] [G loss: 0.999996]\n",
      "epoch:26 step:126435[D loss: 0.999915] [G loss: 1.000182]\n",
      "epoch:26 step:126440[D loss: 0.999870] [G loss: 1.000288]\n",
      "epoch:26 step:126445[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:26 step:126450[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:26 step:126455[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:26 step:126460[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:26 step:126465[D loss: 0.999997] [G loss: 1.000057]\n",
      "epoch:26 step:126470[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:26 step:126475[D loss: 0.999947] [G loss: 1.000137]\n",
      "epoch:26 step:126480[D loss: 0.999959] [G loss: 1.000127]\n",
      "epoch:26 step:126485[D loss: 1.000066] [G loss: 0.999967]\n",
      "epoch:26 step:126490[D loss: 0.999987] [G loss: 0.999949]\n",
      "epoch:26 step:126495[D loss: 0.999920] [G loss: 1.000075]\n",
      "epoch:27 step:126500[D loss: 0.999963] [G loss: 1.000093]\n",
      "epoch:27 step:126505[D loss: 0.999935] [G loss: 1.000109]\n",
      "epoch:27 step:126510[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:27 step:126515[D loss: 1.000012] [G loss: 1.000056]\n",
      "epoch:27 step:126520[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:27 step:126525[D loss: 0.999940] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:126530[D loss: 0.999950] [G loss: 1.000042]\n",
      "epoch:27 step:126535[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:27 step:126540[D loss: 1.000046] [G loss: 0.999933]\n",
      "epoch:27 step:126545[D loss: 1.000122] [G loss: 0.999869]\n",
      "epoch:27 step:126550[D loss: 1.000022] [G loss: 0.999918]\n",
      "epoch:27 step:126555[D loss: 0.999961] [G loss: 0.999999]\n",
      "epoch:27 step:126560[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:27 step:126565[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:27 step:126570[D loss: 1.000008] [G loss: 1.000036]\n",
      "epoch:27 step:126575[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:27 step:126580[D loss: 0.999944] [G loss: 1.000105]\n",
      "epoch:27 step:126585[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:27 step:126590[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:27 step:126595[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:27 step:126600[D loss: 0.999976] [G loss: 1.000051]\n",
      "##############\n",
      "[2.44580089 2.09417672 2.20235172 3.77513825 1.36849531 7.77544295\n",
      " 2.32099977 3.81344015 3.92635437 4.97504458]\n",
      "##########\n",
      "epoch:27 step:126605[D loss: 1.000043] [G loss: 0.999969]\n",
      "epoch:27 step:126610[D loss: 0.999967] [G loss: 1.000019]\n",
      "epoch:27 step:126615[D loss: 0.999998] [G loss: 1.000092]\n",
      "epoch:27 step:126620[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:27 step:126625[D loss: 1.000009] [G loss: 1.000095]\n",
      "epoch:27 step:126630[D loss: 1.000016] [G loss: 1.000100]\n",
      "epoch:27 step:126635[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:27 step:126640[D loss: 0.999999] [G loss: 1.000023]\n",
      "epoch:27 step:126645[D loss: 1.000069] [G loss: 0.999941]\n",
      "epoch:27 step:126650[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:27 step:126655[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:27 step:126660[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:27 step:126665[D loss: 1.000050] [G loss: 1.000007]\n",
      "epoch:27 step:126670[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:27 step:126675[D loss: 1.000070] [G loss: 0.999926]\n",
      "epoch:27 step:126680[D loss: 1.000061] [G loss: 1.000048]\n",
      "epoch:27 step:126685[D loss: 0.999859] [G loss: 1.000211]\n",
      "epoch:27 step:126690[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:27 step:126695[D loss: 0.999990] [G loss: 1.000011]\n",
      "epoch:27 step:126700[D loss: 1.000028] [G loss: 0.999971]\n",
      "epoch:27 step:126705[D loss: 0.999873] [G loss: 1.000161]\n",
      "epoch:27 step:126710[D loss: 1.000054] [G loss: 0.999879]\n",
      "epoch:27 step:126715[D loss: 0.999824] [G loss: 1.000271]\n",
      "epoch:27 step:126720[D loss: 1.000054] [G loss: 0.999880]\n",
      "epoch:27 step:126725[D loss: 1.000028] [G loss: 0.999932]\n",
      "epoch:27 step:126730[D loss: 1.000047] [G loss: 0.999858]\n",
      "epoch:27 step:126735[D loss: 0.999967] [G loss: 1.000104]\n",
      "epoch:27 step:126740[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:27 step:126745[D loss: 0.999948] [G loss: 1.000179]\n",
      "epoch:27 step:126750[D loss: 0.999953] [G loss: 1.000111]\n",
      "epoch:27 step:126755[D loss: 0.999993] [G loss: 1.000096]\n",
      "epoch:27 step:126760[D loss: 1.000022] [G loss: 0.999994]\n",
      "epoch:27 step:126765[D loss: 1.000036] [G loss: 0.999974]\n",
      "epoch:27 step:126770[D loss: 1.000071] [G loss: 0.999889]\n",
      "epoch:27 step:126775[D loss: 0.999986] [G loss: 1.000115]\n",
      "epoch:27 step:126780[D loss: 0.999940] [G loss: 1.000097]\n",
      "epoch:27 step:126785[D loss: 1.000004] [G loss: 1.000009]\n",
      "epoch:27 step:126790[D loss: 0.999977] [G loss: 1.000143]\n",
      "epoch:27 step:126795[D loss: 0.999912] [G loss: 1.000162]\n",
      "epoch:27 step:126800[D loss: 0.999977] [G loss: 1.000118]\n",
      "##############\n",
      "[2.46377951 2.11504282 2.24934314 3.54086891 1.4267791  7.4287846\n",
      " 2.23709421 3.71570999 3.9354012  5.45218779]\n",
      "##########\n",
      "epoch:27 step:126805[D loss: 1.000084] [G loss: 1.000023]\n",
      "epoch:27 step:126810[D loss: 1.000101] [G loss: 1.000021]\n",
      "epoch:27 step:126815[D loss: 1.000008] [G loss: 1.000101]\n",
      "epoch:27 step:126820[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:27 step:126825[D loss: 0.999988] [G loss: 1.000004]\n",
      "epoch:27 step:126830[D loss: 0.999957] [G loss: 0.999991]\n",
      "epoch:27 step:126835[D loss: 1.000010] [G loss: 0.999910]\n",
      "epoch:27 step:126840[D loss: 1.000033] [G loss: 1.000080]\n",
      "epoch:27 step:126845[D loss: 1.000052] [G loss: 0.999957]\n",
      "epoch:27 step:126850[D loss: 1.000020] [G loss: 0.999984]\n",
      "epoch:27 step:126855[D loss: 1.000098] [G loss: 0.999832]\n",
      "epoch:27 step:126860[D loss: 0.999811] [G loss: 1.000260]\n",
      "epoch:27 step:126865[D loss: 0.999980] [G loss: 0.999891]\n",
      "epoch:27 step:126870[D loss: 0.999941] [G loss: 1.000018]\n",
      "epoch:27 step:126875[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:27 step:126880[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:27 step:126885[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:27 step:126890[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:27 step:126895[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:27 step:126900[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:27 step:126905[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:27 step:126910[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:27 step:126915[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:27 step:126920[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:27 step:126925[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:27 step:126930[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:27 step:126935[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:27 step:126940[D loss: 1.000000] [G loss: 1.000069]\n",
      "epoch:27 step:126945[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:27 step:126950[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:27 step:126955[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:27 step:126960[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:27 step:126965[D loss: 1.000034] [G loss: 0.999968]\n",
      "epoch:27 step:126970[D loss: 1.000065] [G loss: 1.000040]\n",
      "epoch:27 step:126975[D loss: 1.000035] [G loss: 0.999993]\n",
      "epoch:27 step:126980[D loss: 0.999993] [G loss: 1.000134]\n",
      "epoch:27 step:126985[D loss: 1.000010] [G loss: 1.000068]\n",
      "epoch:27 step:126990[D loss: 0.999860] [G loss: 1.000285]\n",
      "epoch:27 step:126995[D loss: 0.999957] [G loss: 1.000115]\n",
      "epoch:27 step:127000[D loss: 0.999998] [G loss: 1.000017]\n",
      "##############\n",
      "[2.39998198 2.06107762 2.18646956 3.56861314 1.40766711 7.31138825\n",
      " 2.23204712 3.7663554  3.8376363  4.90252703]\n",
      "##########\n",
      "epoch:27 step:127005[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:27 step:127010[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:27 step:127015[D loss: 1.000072] [G loss: 0.999844]\n",
      "epoch:27 step:127020[D loss: 1.000022] [G loss: 0.999989]\n",
      "epoch:27 step:127025[D loss: 1.000043] [G loss: 0.999901]\n",
      "epoch:27 step:127030[D loss: 1.000010] [G loss: 1.000058]\n",
      "epoch:27 step:127035[D loss: 1.000082] [G loss: 0.999939]\n",
      "epoch:27 step:127040[D loss: 0.999895] [G loss: 1.000042]\n",
      "epoch:27 step:127045[D loss: 1.000006] [G loss: 1.000081]\n",
      "epoch:27 step:127050[D loss: 0.999955] [G loss: 1.000095]\n",
      "epoch:27 step:127055[D loss: 0.999917] [G loss: 1.000176]\n",
      "epoch:27 step:127060[D loss: 0.999955] [G loss: 1.000185]\n",
      "epoch:27 step:127065[D loss: 0.999891] [G loss: 1.000157]\n",
      "epoch:27 step:127070[D loss: 0.999962] [G loss: 1.000130]\n",
      "epoch:27 step:127075[D loss: 0.999946] [G loss: 1.000094]\n",
      "epoch:27 step:127080[D loss: 1.000065] [G loss: 0.999940]\n",
      "epoch:27 step:127085[D loss: 1.000100] [G loss: 0.999945]\n",
      "epoch:27 step:127090[D loss: 1.000070] [G loss: 1.000020]\n",
      "epoch:27 step:127095[D loss: 0.999937] [G loss: 1.000087]\n",
      "epoch:27 step:127100[D loss: 0.999907] [G loss: 1.000182]\n",
      "epoch:27 step:127105[D loss: 1.000034] [G loss: 0.999983]\n",
      "epoch:27 step:127110[D loss: 0.999936] [G loss: 1.000128]\n",
      "epoch:27 step:127115[D loss: 1.000023] [G loss: 1.000012]\n",
      "epoch:27 step:127120[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:27 step:127125[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:27 step:127130[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:27 step:127135[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:27 step:127140[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:27 step:127145[D loss: 0.999925] [G loss: 1.000121]\n",
      "epoch:27 step:127150[D loss: 1.000014] [G loss: 0.999997]\n",
      "epoch:27 step:127155[D loss: 1.000012] [G loss: 1.000055]\n",
      "epoch:27 step:127160[D loss: 0.999965] [G loss: 1.000110]\n",
      "epoch:27 step:127165[D loss: 0.999936] [G loss: 1.000184]\n",
      "epoch:27 step:127170[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:27 step:127175[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:27 step:127180[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:27 step:127185[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:27 step:127190[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:27 step:127195[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:27 step:127200[D loss: 1.000021] [G loss: 0.999985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.48304872 2.1028171  2.21252296 3.77672027 1.41092495 7.55301673\n",
      " 2.36301288 3.51278909 3.91330438 4.15989305]\n",
      "##########\n",
      "epoch:27 step:127205[D loss: 0.999955] [G loss: 1.000120]\n",
      "epoch:27 step:127210[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:27 step:127215[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:27 step:127220[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:27 step:127225[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:27 step:127230[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:27 step:127235[D loss: 0.999972] [G loss: 1.000037]\n",
      "epoch:27 step:127240[D loss: 1.000010] [G loss: 1.000006]\n",
      "epoch:27 step:127245[D loss: 1.000005] [G loss: 0.999989]\n",
      "epoch:27 step:127250[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:27 step:127255[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:27 step:127260[D loss: 0.999953] [G loss: 1.000104]\n",
      "epoch:27 step:127265[D loss: 0.999980] [G loss: 1.000115]\n",
      "epoch:27 step:127270[D loss: 0.999988] [G loss: 1.000091]\n",
      "epoch:27 step:127275[D loss: 1.000029] [G loss: 1.000046]\n",
      "epoch:27 step:127280[D loss: 0.999922] [G loss: 1.000095]\n",
      "epoch:27 step:127285[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:27 step:127290[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:27 step:127295[D loss: 1.000030] [G loss: 1.000000]\n",
      "epoch:27 step:127300[D loss: 0.999961] [G loss: 1.000142]\n",
      "epoch:27 step:127305[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:27 step:127310[D loss: 0.999986] [G loss: 1.000010]\n",
      "epoch:27 step:127315[D loss: 0.999923] [G loss: 1.000092]\n",
      "epoch:27 step:127320[D loss: 0.999943] [G loss: 1.000077]\n",
      "epoch:27 step:127325[D loss: 1.000011] [G loss: 0.999972]\n",
      "epoch:27 step:127330[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:27 step:127335[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:27 step:127340[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:27 step:127345[D loss: 0.999974] [G loss: 1.000104]\n",
      "epoch:27 step:127350[D loss: 0.999952] [G loss: 1.000070]\n",
      "epoch:27 step:127355[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:27 step:127360[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:27 step:127365[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:27 step:127370[D loss: 0.999998] [G loss: 1.000087]\n",
      "epoch:27 step:127375[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:27 step:127380[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:27 step:127385[D loss: 0.999957] [G loss: 0.999998]\n",
      "epoch:27 step:127390[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:27 step:127395[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:27 step:127400[D loss: 0.999922] [G loss: 1.000111]\n",
      "##############\n",
      "[2.45408111 2.19135869 2.26873184 3.97110478 1.36956332 6.91487908\n",
      " 2.26672187 3.74050489 3.93918089 5.75131263]\n",
      "##########\n",
      "epoch:27 step:127405[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:27 step:127410[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:27 step:127415[D loss: 0.999984] [G loss: 1.000097]\n",
      "epoch:27 step:127420[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:27 step:127425[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:27 step:127430[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:27 step:127435[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:27 step:127440[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:27 step:127445[D loss: 0.999966] [G loss: 1.000033]\n",
      "epoch:27 step:127450[D loss: 1.000008] [G loss: 1.000034]\n",
      "epoch:27 step:127455[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:27 step:127460[D loss: 0.999982] [G loss: 1.000134]\n",
      "epoch:27 step:127465[D loss: 0.999994] [G loss: 1.000026]\n",
      "epoch:27 step:127470[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:27 step:127475[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:27 step:127480[D loss: 1.000002] [G loss: 1.000103]\n",
      "epoch:27 step:127485[D loss: 1.000106] [G loss: 1.000014]\n",
      "epoch:27 step:127490[D loss: 0.999956] [G loss: 1.000075]\n",
      "epoch:27 step:127495[D loss: 1.000042] [G loss: 1.000151]\n",
      "epoch:27 step:127500[D loss: 0.999839] [G loss: 1.000270]\n",
      "epoch:27 step:127505[D loss: 0.999918] [G loss: 1.000203]\n",
      "epoch:27 step:127510[D loss: 0.999965] [G loss: 1.000127]\n",
      "epoch:27 step:127515[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:27 step:127520[D loss: 1.000018] [G loss: 0.999952]\n",
      "epoch:27 step:127525[D loss: 1.000020] [G loss: 0.999934]\n",
      "epoch:27 step:127530[D loss: 1.000035] [G loss: 0.999984]\n",
      "epoch:27 step:127535[D loss: 0.999805] [G loss: 1.000143]\n",
      "epoch:27 step:127540[D loss: 1.000069] [G loss: 0.999972]\n",
      "epoch:27 step:127545[D loss: 1.000030] [G loss: 0.999952]\n",
      "epoch:27 step:127550[D loss: 0.999927] [G loss: 1.000161]\n",
      "epoch:27 step:127555[D loss: 1.000022] [G loss: 0.999911]\n",
      "epoch:27 step:127560[D loss: 0.999865] [G loss: 1.000282]\n",
      "epoch:27 step:127565[D loss: 1.000034] [G loss: 1.000038]\n",
      "epoch:27 step:127570[D loss: 0.999967] [G loss: 1.000142]\n",
      "epoch:27 step:127575[D loss: 0.999939] [G loss: 1.000228]\n",
      "epoch:27 step:127580[D loss: 1.000204] [G loss: 1.000045]\n",
      "epoch:27 step:127585[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:27 step:127590[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:27 step:127595[D loss: 0.999981] [G loss: 1.000110]\n",
      "epoch:27 step:127600[D loss: 0.999977] [G loss: 1.000059]\n",
      "##############\n",
      "[2.45999648 2.20259812 2.37868801 4.13401085 1.39698938 8.47221487\n",
      " 2.44363605 3.56180258 4.01883253 6.07423725]\n",
      "##########\n",
      "epoch:27 step:127605[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:27 step:127610[D loss: 1.000075] [G loss: 1.000005]\n",
      "epoch:27 step:127615[D loss: 0.999978] [G loss: 1.000021]\n",
      "epoch:27 step:127620[D loss: 1.000027] [G loss: 1.000015]\n",
      "epoch:27 step:127625[D loss: 1.000094] [G loss: 1.000235]\n",
      "epoch:27 step:127630[D loss: 0.999957] [G loss: 1.000281]\n",
      "epoch:27 step:127635[D loss: 0.999876] [G loss: 1.000177]\n",
      "epoch:27 step:127640[D loss: 0.999915] [G loss: 1.000128]\n",
      "epoch:27 step:127645[D loss: 1.000045] [G loss: 1.000112]\n",
      "epoch:27 step:127650[D loss: 1.000009] [G loss: 1.000123]\n",
      "epoch:27 step:127655[D loss: 0.999950] [G loss: 1.000113]\n",
      "epoch:27 step:127660[D loss: 0.999994] [G loss: 1.000166]\n",
      "epoch:27 step:127665[D loss: 0.999960] [G loss: 1.000197]\n",
      "epoch:27 step:127670[D loss: 0.999990] [G loss: 1.000123]\n",
      "epoch:27 step:127675[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:27 step:127680[D loss: 1.000007] [G loss: 1.000037]\n",
      "epoch:27 step:127685[D loss: 0.999992] [G loss: 0.999962]\n",
      "epoch:27 step:127690[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:27 step:127695[D loss: 0.999939] [G loss: 1.000078]\n",
      "epoch:27 step:127700[D loss: 1.000088] [G loss: 1.000037]\n",
      "epoch:27 step:127705[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:27 step:127710[D loss: 0.999913] [G loss: 1.000146]\n",
      "epoch:27 step:127715[D loss: 1.000056] [G loss: 1.000074]\n",
      "epoch:27 step:127720[D loss: 1.000086] [G loss: 0.999837]\n",
      "epoch:27 step:127725[D loss: 0.999950] [G loss: 1.000109]\n",
      "epoch:27 step:127730[D loss: 0.999954] [G loss: 1.000041]\n",
      "epoch:27 step:127735[D loss: 1.000128] [G loss: 0.999968]\n",
      "epoch:27 step:127740[D loss: 1.000005] [G loss: 0.999973]\n",
      "epoch:27 step:127745[D loss: 0.999962] [G loss: 1.000119]\n",
      "epoch:27 step:127750[D loss: 0.999945] [G loss: 1.000143]\n",
      "epoch:27 step:127755[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:27 step:127760[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:27 step:127765[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:27 step:127770[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:27 step:127775[D loss: 0.999983] [G loss: 1.000111]\n",
      "epoch:27 step:127780[D loss: 1.000079] [G loss: 0.999949]\n",
      "epoch:27 step:127785[D loss: 1.000004] [G loss: 1.000004]\n",
      "epoch:27 step:127790[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:27 step:127795[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:27 step:127800[D loss: 0.999961] [G loss: 1.000095]\n",
      "##############\n",
      "[2.45952849 2.17657541 2.27671393 4.05148099 1.36951759 7.55660843\n",
      " 2.27161932 3.87630466 4.00286063 5.13178804]\n",
      "##########\n",
      "epoch:27 step:127805[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:27 step:127810[D loss: 1.000021] [G loss: 1.000025]\n",
      "epoch:27 step:127815[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:27 step:127820[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:27 step:127825[D loss: 0.999987] [G loss: 1.000130]\n",
      "epoch:27 step:127830[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:27 step:127835[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:27 step:127840[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:27 step:127845[D loss: 0.999983] [G loss: 1.000099]\n",
      "epoch:27 step:127850[D loss: 0.999975] [G loss: 1.000111]\n",
      "epoch:27 step:127855[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:27 step:127860[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:27 step:127865[D loss: 0.999983] [G loss: 1.000054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:127870[D loss: 1.000003] [G loss: 1.000092]\n",
      "epoch:27 step:127875[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:27 step:127880[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:27 step:127885[D loss: 1.000011] [G loss: 1.000088]\n",
      "epoch:27 step:127890[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:27 step:127895[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:27 step:127900[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:27 step:127905[D loss: 0.999931] [G loss: 1.000096]\n",
      "epoch:27 step:127910[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:27 step:127915[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:27 step:127920[D loss: 1.000011] [G loss: 1.000002]\n",
      "epoch:27 step:127925[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:27 step:127930[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:27 step:127935[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:27 step:127940[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:27 step:127945[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:27 step:127950[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:27 step:127955[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:27 step:127960[D loss: 1.000031] [G loss: 0.999979]\n",
      "epoch:27 step:127965[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:27 step:127970[D loss: 0.999969] [G loss: 1.000109]\n",
      "epoch:27 step:127975[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:27 step:127980[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:27 step:127985[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:27 step:127990[D loss: 0.999947] [G loss: 1.000091]\n",
      "epoch:27 step:127995[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:27 step:128000[D loss: 0.999996] [G loss: 0.999992]\n",
      "##############\n",
      "[2.37442465 2.09661225 2.28649947 3.8135899  1.33637096 8.11261856\n",
      " 2.30403539 3.65465524 3.97367765 5.71915183]\n",
      "##########\n",
      "epoch:27 step:128005[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:27 step:128010[D loss: 0.999962] [G loss: 1.000146]\n",
      "epoch:27 step:128015[D loss: 1.000009] [G loss: 1.000019]\n",
      "epoch:27 step:128020[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:27 step:128025[D loss: 1.000027] [G loss: 0.999975]\n",
      "epoch:27 step:128030[D loss: 0.999986] [G loss: 1.000001]\n",
      "epoch:27 step:128035[D loss: 1.000012] [G loss: 0.999980]\n",
      "epoch:27 step:128040[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:27 step:128045[D loss: 1.000025] [G loss: 0.999961]\n",
      "epoch:27 step:128050[D loss: 1.000084] [G loss: 0.999949]\n",
      "epoch:27 step:128055[D loss: 0.999908] [G loss: 1.000107]\n",
      "epoch:27 step:128060[D loss: 0.999945] [G loss: 1.000072]\n",
      "epoch:27 step:128065[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:27 step:128070[D loss: 1.000029] [G loss: 1.000104]\n",
      "epoch:27 step:128075[D loss: 0.999967] [G loss: 1.000215]\n",
      "epoch:27 step:128080[D loss: 0.999904] [G loss: 1.000014]\n",
      "epoch:27 step:128085[D loss: 1.000009] [G loss: 0.999967]\n",
      "epoch:27 step:128090[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:27 step:128095[D loss: 1.000031] [G loss: 0.999988]\n",
      "epoch:27 step:128100[D loss: 1.000082] [G loss: 1.000020]\n",
      "epoch:27 step:128105[D loss: 1.000081] [G loss: 0.999878]\n",
      "epoch:27 step:128110[D loss: 0.999898] [G loss: 1.000178]\n",
      "epoch:27 step:128115[D loss: 0.999975] [G loss: 1.000011]\n",
      "epoch:27 step:128120[D loss: 0.999924] [G loss: 1.000088]\n",
      "epoch:27 step:128125[D loss: 0.999997] [G loss: 1.000086]\n",
      "epoch:27 step:128130[D loss: 1.000006] [G loss: 1.000001]\n",
      "epoch:27 step:128135[D loss: 0.999955] [G loss: 1.000048]\n",
      "epoch:27 step:128140[D loss: 1.000000] [G loss: 1.000071]\n",
      "epoch:27 step:128145[D loss: 1.000093] [G loss: 0.999928]\n",
      "epoch:27 step:128150[D loss: 0.999928] [G loss: 1.000104]\n",
      "epoch:27 step:128155[D loss: 0.999943] [G loss: 1.000070]\n",
      "epoch:27 step:128160[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:27 step:128165[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:27 step:128170[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:27 step:128175[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:27 step:128180[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:27 step:128185[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:27 step:128190[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:27 step:128195[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:27 step:128200[D loss: 0.999982] [G loss: 1.000021]\n",
      "##############\n",
      "[2.48808265 2.19038594 2.24916066 3.99404945 1.38062704 6.98921043\n",
      " 2.17401527 3.68665402 3.93093351 5.48388063]\n",
      "##########\n",
      "epoch:27 step:128205[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:27 step:128210[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:27 step:128215[D loss: 0.999950] [G loss: 1.000109]\n",
      "epoch:27 step:128220[D loss: 1.000011] [G loss: 0.999969]\n",
      "epoch:27 step:128225[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:27 step:128230[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:27 step:128235[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:27 step:128240[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:27 step:128245[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:27 step:128250[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:27 step:128255[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:27 step:128260[D loss: 0.999906] [G loss: 1.000118]\n",
      "epoch:27 step:128265[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:27 step:128270[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:27 step:128275[D loss: 0.999977] [G loss: 1.000025]\n",
      "epoch:27 step:128280[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:27 step:128285[D loss: 1.000116] [G loss: 0.999993]\n",
      "epoch:27 step:128290[D loss: 0.999938] [G loss: 1.000094]\n",
      "epoch:27 step:128295[D loss: 1.000039] [G loss: 1.000002]\n",
      "epoch:27 step:128300[D loss: 0.999914] [G loss: 1.000116]\n",
      "epoch:27 step:128305[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:27 step:128310[D loss: 1.000065] [G loss: 0.999970]\n",
      "epoch:27 step:128315[D loss: 1.000113] [G loss: 0.999920]\n",
      "epoch:27 step:128320[D loss: 1.000020] [G loss: 0.999970]\n",
      "epoch:27 step:128325[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:27 step:128330[D loss: 1.000091] [G loss: 1.000004]\n",
      "epoch:27 step:128335[D loss: 0.999970] [G loss: 1.000154]\n",
      "epoch:27 step:128340[D loss: 0.999883] [G loss: 1.000172]\n",
      "epoch:27 step:128345[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:27 step:128350[D loss: 0.999962] [G loss: 1.000134]\n",
      "epoch:27 step:128355[D loss: 1.000011] [G loss: 1.000018]\n",
      "epoch:27 step:128360[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:27 step:128365[D loss: 0.999961] [G loss: 1.000172]\n",
      "epoch:27 step:128370[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:27 step:128375[D loss: 0.999991] [G loss: 1.000079]\n",
      "epoch:27 step:128380[D loss: 1.000060] [G loss: 0.999971]\n",
      "epoch:27 step:128385[D loss: 1.000141] [G loss: 0.999900]\n",
      "epoch:27 step:128390[D loss: 1.000090] [G loss: 0.999891]\n",
      "epoch:27 step:128395[D loss: 0.999934] [G loss: 0.999974]\n",
      "epoch:27 step:128400[D loss: 1.000041] [G loss: 0.999956]\n",
      "##############\n",
      "[2.47706504 2.12525437 2.34086281 3.84974995 1.35820568 7.19912574\n",
      " 2.33570815 3.58944441 3.89493771 5.13785025]\n",
      "##########\n",
      "epoch:27 step:128405[D loss: 1.000029] [G loss: 0.999979]\n",
      "epoch:27 step:128410[D loss: 0.999936] [G loss: 1.000127]\n",
      "epoch:27 step:128415[D loss: 0.999950] [G loss: 1.000133]\n",
      "epoch:27 step:128420[D loss: 0.999958] [G loss: 1.000069]\n",
      "epoch:27 step:128425[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:27 step:128430[D loss: 1.000018] [G loss: 1.000030]\n",
      "epoch:27 step:128435[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:27 step:128440[D loss: 0.999965] [G loss: 1.000027]\n",
      "epoch:27 step:128445[D loss: 1.000042] [G loss: 1.000019]\n",
      "epoch:27 step:128450[D loss: 0.999929] [G loss: 1.000068]\n",
      "epoch:27 step:128455[D loss: 1.000059] [G loss: 1.000015]\n",
      "epoch:27 step:128460[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:27 step:128465[D loss: 1.000008] [G loss: 1.000086]\n",
      "epoch:27 step:128470[D loss: 0.999961] [G loss: 1.000158]\n",
      "epoch:27 step:128475[D loss: 0.999936] [G loss: 1.000125]\n",
      "epoch:27 step:128480[D loss: 1.000019] [G loss: 1.000043]\n",
      "epoch:27 step:128485[D loss: 1.000018] [G loss: 0.999957]\n",
      "epoch:27 step:128490[D loss: 1.000053] [G loss: 0.999971]\n",
      "epoch:27 step:128495[D loss: 0.999962] [G loss: 1.000049]\n",
      "epoch:27 step:128500[D loss: 1.000039] [G loss: 1.000023]\n",
      "epoch:27 step:128505[D loss: 0.999974] [G loss: 1.000108]\n",
      "epoch:27 step:128510[D loss: 0.999910] [G loss: 1.000199]\n",
      "epoch:27 step:128515[D loss: 0.999905] [G loss: 1.000156]\n",
      "epoch:27 step:128520[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:27 step:128525[D loss: 0.999985] [G loss: 1.000082]\n",
      "epoch:27 step:128530[D loss: 1.000035] [G loss: 1.000002]\n",
      "epoch:27 step:128535[D loss: 0.999967] [G loss: 1.000037]\n",
      "epoch:27 step:128540[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:27 step:128545[D loss: 1.000037] [G loss: 1.000206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:128550[D loss: 1.000029] [G loss: 1.000082]\n",
      "epoch:27 step:128555[D loss: 0.999908] [G loss: 1.000101]\n",
      "epoch:27 step:128560[D loss: 0.999994] [G loss: 1.000086]\n",
      "epoch:27 step:128565[D loss: 1.000002] [G loss: 1.000062]\n",
      "epoch:27 step:128570[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:27 step:128575[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:27 step:128580[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:27 step:128585[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:27 step:128590[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:27 step:128595[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:27 step:128600[D loss: 0.999978] [G loss: 1.000060]\n",
      "##############\n",
      "[2.53002389 2.17228254 2.30077799 3.71962068 1.41567405 7.47499084\n",
      " 2.33068562 3.69948288 3.9854262  5.38458444]\n",
      "##########\n",
      "epoch:27 step:128605[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:27 step:128610[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:27 step:128615[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:27 step:128620[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:27 step:128625[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:27 step:128630[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:27 step:128635[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:27 step:128640[D loss: 0.999991] [G loss: 1.000022]\n",
      "epoch:27 step:128645[D loss: 0.999983] [G loss: 1.000016]\n",
      "epoch:27 step:128650[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:27 step:128655[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:27 step:128660[D loss: 0.999922] [G loss: 1.000136]\n",
      "epoch:27 step:128665[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:27 step:128670[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:27 step:128675[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:27 step:128680[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:27 step:128685[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:27 step:128690[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:27 step:128695[D loss: 0.999956] [G loss: 1.000111]\n",
      "epoch:27 step:128700[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:27 step:128705[D loss: 1.000010] [G loss: 0.999984]\n",
      "epoch:27 step:128710[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:27 step:128715[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:27 step:128720[D loss: 0.999961] [G loss: 1.000041]\n",
      "epoch:27 step:128725[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:27 step:128730[D loss: 0.999996] [G loss: 1.000079]\n",
      "epoch:27 step:128735[D loss: 0.999992] [G loss: 1.000079]\n",
      "epoch:27 step:128740[D loss: 0.999937] [G loss: 1.000093]\n",
      "epoch:27 step:128745[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:27 step:128750[D loss: 1.000011] [G loss: 1.000020]\n",
      "epoch:27 step:128755[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:27 step:128760[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:27 step:128765[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:27 step:128770[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:27 step:128775[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:27 step:128780[D loss: 1.000027] [G loss: 1.000023]\n",
      "epoch:27 step:128785[D loss: 1.000038] [G loss: 1.000039]\n",
      "epoch:27 step:128790[D loss: 1.000101] [G loss: 1.000144]\n",
      "epoch:27 step:128795[D loss: 0.999791] [G loss: 1.000296]\n",
      "epoch:27 step:128800[D loss: 0.999945] [G loss: 1.000100]\n",
      "##############\n",
      "[2.48264956 2.20452405 2.35805964 3.63865368 1.41769537 7.94407524\n",
      " 2.28233475 3.77818381 4.02706373 7.14868929]\n",
      "##########\n",
      "epoch:27 step:128805[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:27 step:128810[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:27 step:128815[D loss: 1.000020] [G loss: 0.999978]\n",
      "epoch:27 step:128820[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:27 step:128825[D loss: 0.999994] [G loss: 0.999980]\n",
      "epoch:27 step:128830[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:27 step:128835[D loss: 1.000039] [G loss: 1.000065]\n",
      "epoch:27 step:128840[D loss: 1.000075] [G loss: 1.000038]\n",
      "epoch:27 step:128845[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:27 step:128850[D loss: 1.000003] [G loss: 1.000102]\n",
      "epoch:27 step:128855[D loss: 0.999900] [G loss: 1.000169]\n",
      "epoch:27 step:128860[D loss: 0.999953] [G loss: 1.000134]\n",
      "epoch:27 step:128865[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:27 step:128870[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:27 step:128875[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:27 step:128880[D loss: 0.999996] [G loss: 0.999999]\n",
      "epoch:27 step:128885[D loss: 1.000001] [G loss: 1.000080]\n",
      "epoch:27 step:128890[D loss: 1.000023] [G loss: 0.999991]\n",
      "epoch:27 step:128895[D loss: 0.999924] [G loss: 1.000062]\n",
      "epoch:27 step:128900[D loss: 1.000005] [G loss: 1.000057]\n",
      "epoch:27 step:128905[D loss: 0.999993] [G loss: 1.000008]\n",
      "epoch:27 step:128910[D loss: 0.999900] [G loss: 1.000171]\n",
      "epoch:27 step:128915[D loss: 0.999936] [G loss: 1.000174]\n",
      "epoch:27 step:128920[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:27 step:128925[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:27 step:128930[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:27 step:128935[D loss: 1.000063] [G loss: 0.999982]\n",
      "epoch:27 step:128940[D loss: 1.000012] [G loss: 1.000028]\n",
      "epoch:27 step:128945[D loss: 0.999982] [G loss: 1.000023]\n",
      "epoch:27 step:128950[D loss: 1.000006] [G loss: 1.000000]\n",
      "epoch:27 step:128955[D loss: 1.000073] [G loss: 1.000038]\n",
      "epoch:27 step:128960[D loss: 1.000109] [G loss: 1.000108]\n",
      "epoch:27 step:128965[D loss: 0.999983] [G loss: 1.000241]\n",
      "epoch:27 step:128970[D loss: 0.999929] [G loss: 1.000130]\n",
      "epoch:27 step:128975[D loss: 1.000030] [G loss: 1.000408]\n",
      "epoch:27 step:128980[D loss: 1.000009] [G loss: 1.000200]\n",
      "epoch:27 step:128985[D loss: 0.999871] [G loss: 1.000209]\n",
      "epoch:27 step:128990[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:27 step:128995[D loss: 1.000022] [G loss: 1.000032]\n",
      "epoch:27 step:129000[D loss: 0.999952] [G loss: 0.999967]\n",
      "##############\n",
      "[2.48767146 2.14218464 2.14600714 3.58471827 1.46780183 7.18711584\n",
      " 2.2579249  3.64210381 3.88515805 5.33091726]\n",
      "##########\n",
      "epoch:27 step:129005[D loss: 0.999999] [G loss: 0.999992]\n",
      "epoch:27 step:129010[D loss: 0.999984] [G loss: 0.999993]\n",
      "epoch:27 step:129015[D loss: 1.000075] [G loss: 0.999950]\n",
      "epoch:27 step:129020[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:27 step:129025[D loss: 1.000022] [G loss: 0.999899]\n",
      "epoch:27 step:129030[D loss: 1.000164] [G loss: 0.999998]\n",
      "epoch:27 step:129035[D loss: 1.000106] [G loss: 0.999923]\n",
      "epoch:27 step:129040[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:27 step:129045[D loss: 1.000201] [G loss: 1.000000]\n",
      "epoch:27 step:129050[D loss: 0.999846] [G loss: 1.000297]\n",
      "epoch:27 step:129055[D loss: 0.999999] [G loss: 0.999973]\n",
      "epoch:27 step:129060[D loss: 0.999948] [G loss: 1.000118]\n",
      "epoch:27 step:129065[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:27 step:129070[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:27 step:129075[D loss: 0.999972] [G loss: 1.000005]\n",
      "epoch:27 step:129080[D loss: 1.000056] [G loss: 1.000072]\n",
      "epoch:27 step:129085[D loss: 0.999943] [G loss: 1.000085]\n",
      "epoch:27 step:129090[D loss: 0.999985] [G loss: 1.000101]\n",
      "epoch:27 step:129095[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:27 step:129100[D loss: 0.999881] [G loss: 1.000272]\n",
      "epoch:27 step:129105[D loss: 0.999929] [G loss: 1.000106]\n",
      "epoch:27 step:129110[D loss: 1.000006] [G loss: 1.000057]\n",
      "epoch:27 step:129115[D loss: 1.000057] [G loss: 1.000032]\n",
      "epoch:27 step:129120[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:27 step:129125[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:27 step:129130[D loss: 0.999933] [G loss: 1.000082]\n",
      "epoch:27 step:129135[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:27 step:129140[D loss: 1.000003] [G loss: 1.000068]\n",
      "epoch:27 step:129145[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:27 step:129150[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:27 step:129155[D loss: 0.999997] [G loss: 1.000054]\n",
      "epoch:27 step:129160[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:27 step:129165[D loss: 0.999995] [G loss: 1.000075]\n",
      "epoch:27 step:129170[D loss: 0.999989] [G loss: 1.000125]\n",
      "epoch:27 step:129175[D loss: 1.000036] [G loss: 1.000160]\n",
      "epoch:27 step:129180[D loss: 0.999980] [G loss: 1.000229]\n",
      "epoch:27 step:129185[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:27 step:129190[D loss: 0.999993] [G loss: 1.000021]\n",
      "epoch:27 step:129195[D loss: 1.000008] [G loss: 0.999949]\n",
      "epoch:27 step:129200[D loss: 0.999997] [G loss: 1.000033]\n",
      "##############\n",
      "[2.49870721 2.1477883  2.16659478 3.70432752 1.42610174 8.21854638\n",
      " 2.37703472 3.65372192 3.93602028 5.15015997]\n",
      "##########\n",
      "epoch:27 step:129205[D loss: 0.999952] [G loss: 1.000052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:129210[D loss: 1.000041] [G loss: 1.000155]\n",
      "epoch:27 step:129215[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:27 step:129220[D loss: 0.999878] [G loss: 1.000241]\n",
      "epoch:27 step:129225[D loss: 1.000003] [G loss: 1.000112]\n",
      "epoch:27 step:129230[D loss: 0.999964] [G loss: 1.000038]\n",
      "epoch:27 step:129235[D loss: 0.999960] [G loss: 1.000036]\n",
      "epoch:27 step:129240[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:27 step:129245[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:27 step:129250[D loss: 1.000001] [G loss: 1.000073]\n",
      "epoch:27 step:129255[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:27 step:129260[D loss: 1.000073] [G loss: 1.000032]\n",
      "epoch:27 step:129265[D loss: 0.999923] [G loss: 1.000053]\n",
      "epoch:27 step:129270[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:27 step:129275[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:27 step:129280[D loss: 0.999952] [G loss: 1.000071]\n",
      "epoch:27 step:129285[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:27 step:129290[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:27 step:129295[D loss: 1.000014] [G loss: 1.000039]\n",
      "epoch:27 step:129300[D loss: 0.999928] [G loss: 1.000132]\n",
      "epoch:27 step:129305[D loss: 0.999928] [G loss: 1.000092]\n",
      "epoch:27 step:129310[D loss: 1.000080] [G loss: 0.999966]\n",
      "epoch:27 step:129315[D loss: 0.999987] [G loss: 0.999993]\n",
      "epoch:27 step:129320[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:27 step:129325[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:27 step:129330[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:27 step:129335[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:27 step:129340[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:27 step:129345[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:27 step:129350[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:27 step:129355[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:27 step:129360[D loss: 0.999999] [G loss: 1.000135]\n",
      "epoch:27 step:129365[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:27 step:129370[D loss: 1.000004] [G loss: 1.000198]\n",
      "epoch:27 step:129375[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:27 step:129380[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:27 step:129385[D loss: 1.000052] [G loss: 1.000099]\n",
      "epoch:27 step:129390[D loss: 0.999952] [G loss: 1.000144]\n",
      "epoch:27 step:129395[D loss: 1.000096] [G loss: 1.000093]\n",
      "epoch:27 step:129400[D loss: 0.999968] [G loss: 1.000062]\n",
      "##############\n",
      "[2.51695886 2.0771854  2.04584491 3.64966821 1.41495686 6.94773292\n",
      " 2.20622506 3.57838944 3.96949525 5.81497109]\n",
      "##########\n",
      "epoch:27 step:129405[D loss: 1.000090] [G loss: 0.999843]\n",
      "epoch:27 step:129410[D loss: 1.000012] [G loss: 0.999972]\n",
      "epoch:27 step:129415[D loss: 0.999938] [G loss: 1.000020]\n",
      "epoch:27 step:129420[D loss: 1.000023] [G loss: 0.999938]\n",
      "epoch:27 step:129425[D loss: 0.999956] [G loss: 1.000015]\n",
      "epoch:27 step:129430[D loss: 1.000036] [G loss: 1.000069]\n",
      "epoch:27 step:129435[D loss: 1.000183] [G loss: 1.000068]\n",
      "epoch:27 step:129440[D loss: 1.000075] [G loss: 1.000000]\n",
      "epoch:27 step:129445[D loss: 0.999946] [G loss: 1.000027]\n",
      "epoch:27 step:129450[D loss: 0.999934] [G loss: 1.000148]\n",
      "epoch:27 step:129455[D loss: 0.999832] [G loss: 1.000176]\n",
      "epoch:27 step:129460[D loss: 1.000018] [G loss: 0.999977]\n",
      "epoch:27 step:129465[D loss: 0.999966] [G loss: 1.000024]\n",
      "epoch:27 step:129470[D loss: 1.000074] [G loss: 0.999950]\n",
      "epoch:27 step:129475[D loss: 1.000094] [G loss: 0.999806]\n",
      "epoch:27 step:129480[D loss: 1.000021] [G loss: 0.999813]\n",
      "epoch:27 step:129485[D loss: 1.000031] [G loss: 0.999998]\n",
      "epoch:27 step:129490[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:27 step:129495[D loss: 0.999967] [G loss: 1.000115]\n",
      "epoch:27 step:129500[D loss: 0.999934] [G loss: 1.000107]\n",
      "epoch:27 step:129505[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:27 step:129510[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:27 step:129515[D loss: 1.000014] [G loss: 1.000012]\n",
      "epoch:27 step:129520[D loss: 1.000013] [G loss: 1.000017]\n",
      "epoch:27 step:129525[D loss: 1.000013] [G loss: 1.000056]\n",
      "epoch:27 step:129530[D loss: 1.000184] [G loss: 0.999853]\n",
      "epoch:27 step:129535[D loss: 0.999929] [G loss: 1.000269]\n",
      "epoch:27 step:129540[D loss: 1.000095] [G loss: 1.000218]\n",
      "epoch:27 step:129545[D loss: 0.999828] [G loss: 1.000228]\n",
      "epoch:27 step:129550[D loss: 0.999962] [G loss: 1.000167]\n",
      "epoch:27 step:129555[D loss: 0.999978] [G loss: 1.000140]\n",
      "epoch:27 step:129560[D loss: 0.999971] [G loss: 0.999979]\n",
      "epoch:27 step:129565[D loss: 0.999998] [G loss: 1.000015]\n",
      "epoch:27 step:129570[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:27 step:129575[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:27 step:129580[D loss: 1.000065] [G loss: 0.999974]\n",
      "epoch:27 step:129585[D loss: 1.000138] [G loss: 0.999833]\n",
      "epoch:27 step:129590[D loss: 0.999943] [G loss: 1.000011]\n",
      "epoch:27 step:129595[D loss: 0.999906] [G loss: 1.000228]\n",
      "epoch:27 step:129600[D loss: 0.999931] [G loss: 1.000116]\n",
      "##############\n",
      "[2.48656969 2.20416574 2.19030508 3.55236314 1.40115661 7.54743568\n",
      " 2.34831537 3.89968484 3.98956301 5.35048677]\n",
      "##########\n",
      "epoch:27 step:129605[D loss: 1.000040] [G loss: 1.000015]\n",
      "epoch:27 step:129610[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:27 step:129615[D loss: 0.999965] [G loss: 1.000109]\n",
      "epoch:27 step:129620[D loss: 0.999944] [G loss: 1.000132]\n",
      "epoch:27 step:129625[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:27 step:129630[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:27 step:129635[D loss: 0.999950] [G loss: 1.000093]\n",
      "epoch:27 step:129640[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:27 step:129645[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:27 step:129650[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:27 step:129655[D loss: 0.999939] [G loss: 1.000074]\n",
      "epoch:27 step:129660[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:27 step:129665[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:27 step:129670[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:27 step:129675[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:27 step:129680[D loss: 1.000085] [G loss: 0.999958]\n",
      "epoch:27 step:129685[D loss: 0.999936] [G loss: 1.000056]\n",
      "epoch:27 step:129690[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:27 step:129695[D loss: 1.000022] [G loss: 1.000044]\n",
      "epoch:27 step:129700[D loss: 1.000091] [G loss: 0.999891]\n",
      "epoch:27 step:129705[D loss: 0.999944] [G loss: 1.000102]\n",
      "epoch:27 step:129710[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:27 step:129715[D loss: 1.000032] [G loss: 1.000004]\n",
      "epoch:27 step:129720[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:27 step:129725[D loss: 1.000066] [G loss: 0.999906]\n",
      "epoch:27 step:129730[D loss: 0.999859] [G loss: 1.000153]\n",
      "epoch:27 step:129735[D loss: 0.999938] [G loss: 1.000157]\n",
      "epoch:27 step:129740[D loss: 0.999977] [G loss: 1.000159]\n",
      "epoch:27 step:129745[D loss: 0.999901] [G loss: 1.000179]\n",
      "epoch:27 step:129750[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:27 step:129755[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:27 step:129760[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:27 step:129765[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:27 step:129770[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:27 step:129775[D loss: 0.999955] [G loss: 1.000095]\n",
      "epoch:27 step:129780[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:27 step:129785[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:27 step:129790[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:27 step:129795[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:27 step:129800[D loss: 0.999985] [G loss: 1.000049]\n",
      "##############\n",
      "[2.48683242 2.09288428 2.15720743 3.75894055 1.37641667 6.69846873\n",
      " 2.333936   3.61764832 3.8409675  5.30399854]\n",
      "##########\n",
      "epoch:27 step:129805[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:27 step:129810[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:27 step:129815[D loss: 0.999959] [G loss: 1.000039]\n",
      "epoch:27 step:129820[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:27 step:129825[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:27 step:129830[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:27 step:129835[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:27 step:129840[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:27 step:129845[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:27 step:129850[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:27 step:129855[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:27 step:129860[D loss: 1.000006] [G loss: 1.000050]\n",
      "epoch:27 step:129865[D loss: 0.999955] [G loss: 1.000093]\n",
      "epoch:27 step:129870[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:27 step:129875[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:27 step:129880[D loss: 0.999988] [G loss: 1.000039]\n",
      "epoch:27 step:129885[D loss: 1.000005] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:129890[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:27 step:129895[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:27 step:129900[D loss: 0.999940] [G loss: 1.000093]\n",
      "epoch:27 step:129905[D loss: 0.999997] [G loss: 1.000092]\n",
      "epoch:27 step:129910[D loss: 0.999946] [G loss: 1.000069]\n",
      "epoch:27 step:129915[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:27 step:129920[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:27 step:129925[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:27 step:129930[D loss: 0.999962] [G loss: 1.000025]\n",
      "epoch:27 step:129935[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:27 step:129940[D loss: 1.000070] [G loss: 1.000057]\n",
      "epoch:27 step:129945[D loss: 0.999925] [G loss: 1.000075]\n",
      "epoch:27 step:129950[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:27 step:129955[D loss: 0.999956] [G loss: 1.000100]\n",
      "epoch:27 step:129960[D loss: 1.000032] [G loss: 1.000141]\n",
      "epoch:27 step:129965[D loss: 0.999963] [G loss: 1.000124]\n",
      "epoch:27 step:129970[D loss: 0.999932] [G loss: 1.000096]\n",
      "epoch:27 step:129975[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:27 step:129980[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:27 step:129985[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:27 step:129990[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:27 step:129995[D loss: 0.999970] [G loss: 1.000030]\n",
      "epoch:27 step:130000[D loss: 1.000010] [G loss: 0.999942]\n",
      "##############\n",
      "[2.47552208 2.23472225 2.07721872 3.80841155 1.4627253  6.86090993\n",
      " 2.22925961 3.72531869 3.97824025 7.14868929]\n",
      "##########\n",
      "epoch:27 step:130005[D loss: 1.000041] [G loss: 0.999953]\n",
      "epoch:27 step:130010[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:27 step:130015[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:27 step:130020[D loss: 1.000030] [G loss: 1.000045]\n",
      "epoch:27 step:130025[D loss: 0.999935] [G loss: 1.000180]\n",
      "epoch:27 step:130030[D loss: 0.999930] [G loss: 1.000171]\n",
      "epoch:27 step:130035[D loss: 0.999953] [G loss: 1.000130]\n",
      "epoch:27 step:130040[D loss: 1.000005] [G loss: 1.000044]\n",
      "epoch:27 step:130045[D loss: 1.000105] [G loss: 0.999878]\n",
      "epoch:27 step:130050[D loss: 1.000044] [G loss: 0.999940]\n",
      "epoch:27 step:130055[D loss: 1.000056] [G loss: 0.999888]\n",
      "epoch:27 step:130060[D loss: 0.999998] [G loss: 1.000076]\n",
      "epoch:27 step:130065[D loss: 1.000221] [G loss: 1.000041]\n",
      "epoch:27 step:130070[D loss: 1.000025] [G loss: 1.000004]\n",
      "epoch:27 step:130075[D loss: 0.999840] [G loss: 1.000168]\n",
      "epoch:27 step:130080[D loss: 0.999945] [G loss: 1.000112]\n",
      "epoch:27 step:130085[D loss: 1.000005] [G loss: 1.000020]\n",
      "epoch:27 step:130090[D loss: 1.000018] [G loss: 0.999984]\n",
      "epoch:27 step:130095[D loss: 0.999993] [G loss: 1.000004]\n",
      "epoch:27 step:130100[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:27 step:130105[D loss: 1.000050] [G loss: 1.000041]\n",
      "epoch:27 step:130110[D loss: 1.000037] [G loss: 1.000123]\n",
      "epoch:27 step:130115[D loss: 0.999911] [G loss: 1.000225]\n",
      "epoch:27 step:130120[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:27 step:130125[D loss: 0.999958] [G loss: 1.000042]\n",
      "epoch:27 step:130130[D loss: 1.000054] [G loss: 1.000018]\n",
      "epoch:27 step:130135[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:27 step:130140[D loss: 0.999970] [G loss: 1.000035]\n",
      "epoch:27 step:130145[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:27 step:130150[D loss: 1.000014] [G loss: 0.999948]\n",
      "epoch:27 step:130155[D loss: 1.000001] [G loss: 1.000108]\n",
      "epoch:27 step:130160[D loss: 0.999996] [G loss: 1.000041]\n",
      "epoch:27 step:130165[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:27 step:130170[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:27 step:130175[D loss: 0.999970] [G loss: 1.000035]\n",
      "epoch:27 step:130180[D loss: 0.999997] [G loss: 1.000114]\n",
      "epoch:27 step:130185[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:27 step:130190[D loss: 1.000059] [G loss: 1.000112]\n",
      "epoch:27 step:130195[D loss: 0.999958] [G loss: 1.000204]\n",
      "epoch:27 step:130200[D loss: 0.999928] [G loss: 1.000073]\n",
      "##############\n",
      "[2.47225188 2.13497743 2.18871437 3.67514235 1.4519844  6.86949043\n",
      " 2.46049223 3.83389721 3.93348284 5.37371828]\n",
      "##########\n",
      "epoch:27 step:130205[D loss: 1.000067] [G loss: 0.999982]\n",
      "epoch:27 step:130210[D loss: 0.999869] [G loss: 1.000115]\n",
      "epoch:27 step:130215[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:27 step:130220[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:27 step:130225[D loss: 0.999935] [G loss: 1.000129]\n",
      "epoch:27 step:130230[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:27 step:130235[D loss: 0.999973] [G loss: 1.000106]\n",
      "epoch:27 step:130240[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:27 step:130245[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:27 step:130250[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:27 step:130255[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:27 step:130260[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:27 step:130265[D loss: 1.000028] [G loss: 0.999992]\n",
      "epoch:27 step:130270[D loss: 1.000018] [G loss: 0.999973]\n",
      "epoch:27 step:130275[D loss: 0.999924] [G loss: 1.000098]\n",
      "epoch:27 step:130280[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:27 step:130285[D loss: 0.999991] [G loss: 1.000073]\n",
      "epoch:27 step:130290[D loss: 0.999932] [G loss: 1.000100]\n",
      "epoch:27 step:130295[D loss: 1.000022] [G loss: 1.000027]\n",
      "epoch:27 step:130300[D loss: 0.999929] [G loss: 1.000163]\n",
      "epoch:27 step:130305[D loss: 0.999953] [G loss: 1.000204]\n",
      "epoch:27 step:130310[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:27 step:130315[D loss: 1.000018] [G loss: 1.000013]\n",
      "epoch:27 step:130320[D loss: 0.999920] [G loss: 1.000097]\n",
      "epoch:27 step:130325[D loss: 0.999922] [G loss: 1.000153]\n",
      "epoch:27 step:130330[D loss: 0.999932] [G loss: 1.000117]\n",
      "epoch:27 step:130335[D loss: 0.999975] [G loss: 0.999994]\n",
      "epoch:27 step:130340[D loss: 0.999941] [G loss: 1.000069]\n",
      "epoch:27 step:130345[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:27 step:130350[D loss: 1.000081] [G loss: 0.999963]\n",
      "epoch:27 step:130355[D loss: 1.000066] [G loss: 0.999910]\n",
      "epoch:27 step:130360[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:27 step:130365[D loss: 1.000034] [G loss: 1.000167]\n",
      "epoch:27 step:130370[D loss: 0.999896] [G loss: 1.000070]\n",
      "epoch:27 step:130375[D loss: 0.999839] [G loss: 1.000327]\n",
      "epoch:27 step:130380[D loss: 0.999884] [G loss: 1.000204]\n",
      "epoch:27 step:130385[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:27 step:130390[D loss: 1.000015] [G loss: 1.000033]\n",
      "epoch:27 step:130395[D loss: 1.000061] [G loss: 0.999898]\n",
      "epoch:27 step:130400[D loss: 0.999933] [G loss: 0.999984]\n",
      "##############\n",
      "[2.46348346 2.13951587 2.25140495 3.92321655 1.43428783 7.19355463\n",
      " 2.32937807 3.58874218 3.8908359  5.27069499]\n",
      "##########\n",
      "epoch:27 step:130405[D loss: 0.999945] [G loss: 1.000103]\n",
      "epoch:27 step:130410[D loss: 1.000002] [G loss: 1.000060]\n",
      "epoch:27 step:130415[D loss: 1.000024] [G loss: 1.000001]\n",
      "epoch:27 step:130420[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:27 step:130425[D loss: 0.999950] [G loss: 1.000155]\n",
      "epoch:27 step:130430[D loss: 0.999953] [G loss: 1.000102]\n",
      "epoch:27 step:130435[D loss: 1.000060] [G loss: 0.999944]\n",
      "epoch:27 step:130440[D loss: 1.000016] [G loss: 1.000196]\n",
      "epoch:27 step:130445[D loss: 0.999843] [G loss: 1.000175]\n",
      "epoch:27 step:130450[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:27 step:130455[D loss: 1.000005] [G loss: 1.000076]\n",
      "epoch:27 step:130460[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:27 step:130465[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:27 step:130470[D loss: 1.000128] [G loss: 0.999792]\n",
      "epoch:27 step:130475[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:27 step:130480[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:27 step:130485[D loss: 1.000128] [G loss: 0.999891]\n",
      "epoch:27 step:130490[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:27 step:130495[D loss: 0.999928] [G loss: 1.000139]\n",
      "epoch:27 step:130500[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:27 step:130505[D loss: 0.999928] [G loss: 1.000154]\n",
      "epoch:27 step:130510[D loss: 1.000022] [G loss: 1.000038]\n",
      "epoch:27 step:130515[D loss: 0.999990] [G loss: 1.000014]\n",
      "epoch:27 step:130520[D loss: 0.999994] [G loss: 1.000091]\n",
      "epoch:27 step:130525[D loss: 1.000043] [G loss: 0.999977]\n",
      "epoch:27 step:130530[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:27 step:130535[D loss: 1.000088] [G loss: 1.000120]\n",
      "epoch:27 step:130540[D loss: 0.999856] [G loss: 1.000267]\n",
      "epoch:27 step:130545[D loss: 0.999915] [G loss: 1.000180]\n",
      "epoch:27 step:130550[D loss: 0.999981] [G loss: 1.000153]\n",
      "epoch:27 step:130555[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:27 step:130560[D loss: 0.999974] [G loss: 1.000138]\n",
      "epoch:27 step:130565[D loss: 1.000031] [G loss: 0.999966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:130570[D loss: 1.000017] [G loss: 1.000034]\n",
      "epoch:27 step:130575[D loss: 0.999982] [G loss: 1.000119]\n",
      "epoch:27 step:130580[D loss: 0.999912] [G loss: 1.000139]\n",
      "epoch:27 step:130585[D loss: 0.999964] [G loss: 1.000175]\n",
      "epoch:27 step:130590[D loss: 0.999955] [G loss: 1.000089]\n",
      "epoch:27 step:130595[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:27 step:130600[D loss: 0.999984] [G loss: 1.000061]\n",
      "##############\n",
      "[2.42510367 2.03697898 2.19152985 3.61909841 1.46404891 7.39853736\n",
      " 2.2889309  3.61960551 3.83529965 5.26937572]\n",
      "##########\n",
      "epoch:27 step:130605[D loss: 1.000030] [G loss: 1.000027]\n",
      "epoch:27 step:130610[D loss: 1.000087] [G loss: 0.999743]\n",
      "epoch:27 step:130615[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:27 step:130620[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:27 step:130625[D loss: 0.999968] [G loss: 1.000044]\n",
      "epoch:27 step:130630[D loss: 0.999957] [G loss: 1.000114]\n",
      "epoch:27 step:130635[D loss: 1.000023] [G loss: 1.000014]\n",
      "epoch:27 step:130640[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:27 step:130645[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:27 step:130650[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:27 step:130655[D loss: 1.000017] [G loss: 1.000059]\n",
      "epoch:27 step:130660[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:27 step:130665[D loss: 1.000079] [G loss: 1.000051]\n",
      "epoch:27 step:130670[D loss: 0.999921] [G loss: 1.000106]\n",
      "epoch:27 step:130675[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:27 step:130680[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:27 step:130685[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:27 step:130690[D loss: 1.000005] [G loss: 1.000043]\n",
      "epoch:27 step:130695[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:27 step:130700[D loss: 1.000060] [G loss: 0.999923]\n",
      "epoch:27 step:130705[D loss: 0.999930] [G loss: 1.000151]\n",
      "epoch:27 step:130710[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:27 step:130715[D loss: 1.000071] [G loss: 1.000019]\n",
      "epoch:27 step:130720[D loss: 0.999948] [G loss: 1.000141]\n",
      "epoch:27 step:130725[D loss: 0.999852] [G loss: 1.000247]\n",
      "epoch:27 step:130730[D loss: 0.999938] [G loss: 1.000136]\n",
      "epoch:27 step:130735[D loss: 0.999936] [G loss: 1.000138]\n",
      "epoch:27 step:130740[D loss: 0.999971] [G loss: 1.000157]\n",
      "epoch:27 step:130745[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:27 step:130750[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:27 step:130755[D loss: 0.999975] [G loss: 1.000025]\n",
      "epoch:27 step:130760[D loss: 0.999978] [G loss: 1.000016]\n",
      "epoch:27 step:130765[D loss: 1.000015] [G loss: 0.999926]\n",
      "epoch:27 step:130770[D loss: 1.000047] [G loss: 0.999928]\n",
      "epoch:27 step:130775[D loss: 1.000018] [G loss: 1.000139]\n",
      "epoch:27 step:130780[D loss: 1.000087] [G loss: 1.000016]\n",
      "epoch:27 step:130785[D loss: 0.999910] [G loss: 1.000217]\n",
      "epoch:27 step:130790[D loss: 0.999877] [G loss: 1.000241]\n",
      "epoch:27 step:130795[D loss: 0.999876] [G loss: 1.000192]\n",
      "epoch:27 step:130800[D loss: 0.999982] [G loss: 1.000073]\n",
      "##############\n",
      "[2.40103057 2.20957343 2.2671417  3.6393493  1.43737904 7.62414228\n",
      " 2.36721594 3.67824653 4.00269074 5.74604298]\n",
      "##########\n",
      "epoch:27 step:130805[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:27 step:130810[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:27 step:130815[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:27 step:130820[D loss: 0.999976] [G loss: 1.000031]\n",
      "epoch:27 step:130825[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:27 step:130830[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:27 step:130835[D loss: 1.000001] [G loss: 1.000116]\n",
      "epoch:27 step:130840[D loss: 1.000088] [G loss: 0.999849]\n",
      "epoch:27 step:130845[D loss: 1.000092] [G loss: 0.999985]\n",
      "epoch:27 step:130850[D loss: 0.999950] [G loss: 1.000047]\n",
      "epoch:27 step:130855[D loss: 0.999942] [G loss: 1.000065]\n",
      "epoch:27 step:130860[D loss: 1.000034] [G loss: 1.000058]\n",
      "epoch:27 step:130865[D loss: 0.999950] [G loss: 1.000060]\n",
      "epoch:27 step:130870[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:27 step:130875[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:27 step:130880[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:27 step:130885[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:27 step:130890[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:27 step:130895[D loss: 1.000013] [G loss: 1.000016]\n",
      "epoch:27 step:130900[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:27 step:130905[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:27 step:130910[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:27 step:130915[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:27 step:130920[D loss: 0.999954] [G loss: 1.000072]\n",
      "epoch:27 step:130925[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:27 step:130930[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:27 step:130935[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:27 step:130940[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:27 step:130945[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:27 step:130950[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:27 step:130955[D loss: 0.999975] [G loss: 1.000028]\n",
      "epoch:27 step:130960[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:27 step:130965[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:27 step:130970[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:27 step:130975[D loss: 1.000038] [G loss: 1.000008]\n",
      "epoch:27 step:130980[D loss: 0.999989] [G loss: 0.999980]\n",
      "epoch:27 step:130985[D loss: 0.999926] [G loss: 1.000075]\n",
      "epoch:27 step:130990[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:27 step:130995[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:27 step:131000[D loss: 1.000074] [G loss: 0.999947]\n",
      "##############\n",
      "[2.46874842 2.16814176 2.12085095 3.71271423 1.4858236  7.44519805\n",
      " 2.36408719 3.80070106 3.99676216 4.55306699]\n",
      "##########\n",
      "epoch:27 step:131005[D loss: 0.999917] [G loss: 1.000150]\n",
      "epoch:27 step:131010[D loss: 0.999963] [G loss: 1.000015]\n",
      "epoch:27 step:131015[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:27 step:131020[D loss: 1.000015] [G loss: 0.999987]\n",
      "epoch:27 step:131025[D loss: 0.999961] [G loss: 1.000123]\n",
      "epoch:27 step:131030[D loss: 0.999925] [G loss: 1.000041]\n",
      "epoch:27 step:131035[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:27 step:131040[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:27 step:131045[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:27 step:131050[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:27 step:131055[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:27 step:131060[D loss: 0.999940] [G loss: 1.000101]\n",
      "epoch:27 step:131065[D loss: 1.000013] [G loss: 1.000000]\n",
      "epoch:27 step:131070[D loss: 0.999891] [G loss: 1.000192]\n",
      "epoch:27 step:131075[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:27 step:131080[D loss: 1.000046] [G loss: 1.000094]\n",
      "epoch:27 step:131085[D loss: 0.999928] [G loss: 1.000127]\n",
      "epoch:27 step:131090[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:27 step:131095[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:27 step:131100[D loss: 1.000003] [G loss: 1.000041]\n",
      "epoch:27 step:131105[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:27 step:131110[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:27 step:131115[D loss: 1.000015] [G loss: 0.999977]\n",
      "epoch:27 step:131120[D loss: 0.999915] [G loss: 1.000130]\n",
      "epoch:27 step:131125[D loss: 0.999942] [G loss: 1.000072]\n",
      "epoch:27 step:131130[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:27 step:131135[D loss: 1.000008] [G loss: 1.000029]\n",
      "epoch:27 step:131140[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:27 step:131145[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:27 step:131150[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:27 step:131155[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:27 step:131160[D loss: 0.999987] [G loss: 1.000081]\n",
      "epoch:27 step:131165[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:27 step:131170[D loss: 0.999998] [G loss: 1.000071]\n",
      "epoch:27 step:131175[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:27 step:131180[D loss: 0.999925] [G loss: 1.000128]\n",
      "epoch:28 step:131185[D loss: 0.999966] [G loss: 1.000156]\n",
      "epoch:28 step:131190[D loss: 0.999942] [G loss: 1.000103]\n",
      "epoch:28 step:131195[D loss: 0.999936] [G loss: 1.000071]\n",
      "epoch:28 step:131200[D loss: 0.999970] [G loss: 1.000090]\n",
      "##############\n",
      "[2.50369555 2.12768001 2.1048028  3.53164416 1.44378829 8.61623984\n",
      " 2.17066864 3.66262852 3.89771127 5.83149852]\n",
      "##########\n",
      "epoch:28 step:131205[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:28 step:131210[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:28 step:131215[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:28 step:131220[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:28 step:131225[D loss: 0.999993] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:131230[D loss: 1.000093] [G loss: 0.999928]\n",
      "epoch:28 step:131235[D loss: 1.000054] [G loss: 0.999962]\n",
      "epoch:28 step:131240[D loss: 0.999896] [G loss: 1.000105]\n",
      "epoch:28 step:131245[D loss: 0.999912] [G loss: 1.000116]\n",
      "epoch:28 step:131250[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:28 step:131255[D loss: 0.999950] [G loss: 1.000152]\n",
      "epoch:28 step:131260[D loss: 0.999884] [G loss: 1.000205]\n",
      "epoch:28 step:131265[D loss: 0.999991] [G loss: 1.000092]\n",
      "epoch:28 step:131270[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:28 step:131275[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:28 step:131280[D loss: 0.999951] [G loss: 1.000060]\n",
      "epoch:28 step:131285[D loss: 1.000080] [G loss: 0.999964]\n",
      "epoch:28 step:131290[D loss: 0.999998] [G loss: 1.000083]\n",
      "epoch:28 step:131295[D loss: 0.999956] [G loss: 0.999995]\n",
      "epoch:28 step:131300[D loss: 1.000110] [G loss: 0.999905]\n",
      "epoch:28 step:131305[D loss: 0.999897] [G loss: 1.000168]\n",
      "epoch:28 step:131310[D loss: 1.000048] [G loss: 1.000067]\n",
      "epoch:28 step:131315[D loss: 1.000064] [G loss: 1.000082]\n",
      "epoch:28 step:131320[D loss: 0.999914] [G loss: 1.000167]\n",
      "epoch:28 step:131325[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:28 step:131330[D loss: 0.999941] [G loss: 1.000049]\n",
      "epoch:28 step:131335[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:28 step:131340[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:28 step:131345[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:28 step:131350[D loss: 0.999974] [G loss: 1.000113]\n",
      "epoch:28 step:131355[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:28 step:131360[D loss: 0.999975] [G loss: 1.000101]\n",
      "epoch:28 step:131365[D loss: 1.000026] [G loss: 1.000056]\n",
      "epoch:28 step:131370[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:28 step:131375[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:28 step:131380[D loss: 1.000070] [G loss: 0.999981]\n",
      "epoch:28 step:131385[D loss: 1.000090] [G loss: 0.999890]\n",
      "epoch:28 step:131390[D loss: 0.999937] [G loss: 1.000130]\n",
      "epoch:28 step:131395[D loss: 0.999927] [G loss: 1.000165]\n",
      "epoch:28 step:131400[D loss: 1.000000] [G loss: 0.999870]\n",
      "##############\n",
      "[2.44106312 2.07260258 2.28914382 3.49620001 1.4501876  7.44945802\n",
      " 2.25924842 3.63548366 3.93903118 5.53566899]\n",
      "##########\n",
      "epoch:28 step:131405[D loss: 1.000025] [G loss: 0.999991]\n",
      "epoch:28 step:131410[D loss: 0.999908] [G loss: 1.000211]\n",
      "epoch:28 step:131415[D loss: 0.999961] [G loss: 1.000118]\n",
      "epoch:28 step:131420[D loss: 0.999889] [G loss: 1.000191]\n",
      "epoch:28 step:131425[D loss: 0.999964] [G loss: 1.000108]\n",
      "epoch:28 step:131430[D loss: 0.999940] [G loss: 1.000114]\n",
      "epoch:28 step:131435[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:28 step:131440[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:28 step:131445[D loss: 0.999979] [G loss: 1.000147]\n",
      "epoch:28 step:131450[D loss: 1.000021] [G loss: 1.000046]\n",
      "epoch:28 step:131455[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:28 step:131460[D loss: 1.000011] [G loss: 1.000066]\n",
      "epoch:28 step:131465[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:28 step:131470[D loss: 0.999939] [G loss: 1.000085]\n",
      "epoch:28 step:131475[D loss: 0.999953] [G loss: 1.000102]\n",
      "epoch:28 step:131480[D loss: 0.999972] [G loss: 1.000106]\n",
      "epoch:28 step:131485[D loss: 1.000001] [G loss: 1.000079]\n",
      "epoch:28 step:131490[D loss: 1.000003] [G loss: 1.000081]\n",
      "epoch:28 step:131495[D loss: 0.999993] [G loss: 1.000159]\n",
      "epoch:28 step:131500[D loss: 1.000025] [G loss: 1.000031]\n",
      "epoch:28 step:131505[D loss: 0.999968] [G loss: 1.000032]\n",
      "epoch:28 step:131510[D loss: 1.000024] [G loss: 0.999883]\n",
      "epoch:28 step:131515[D loss: 0.999996] [G loss: 0.999942]\n",
      "epoch:28 step:131520[D loss: 0.999937] [G loss: 1.000079]\n",
      "epoch:28 step:131525[D loss: 1.000048] [G loss: 1.000127]\n",
      "epoch:28 step:131530[D loss: 1.000118] [G loss: 0.999941]\n",
      "epoch:28 step:131535[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:28 step:131540[D loss: 1.000066] [G loss: 1.000090]\n",
      "epoch:28 step:131545[D loss: 1.000001] [G loss: 1.000000]\n",
      "epoch:28 step:131550[D loss: 1.000025] [G loss: 1.000027]\n",
      "epoch:28 step:131555[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:28 step:131560[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:28 step:131565[D loss: 0.999946] [G loss: 1.000104]\n",
      "epoch:28 step:131570[D loss: 0.999972] [G loss: 1.000109]\n",
      "epoch:28 step:131575[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:28 step:131580[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:28 step:131585[D loss: 0.999969] [G loss: 1.000114]\n",
      "epoch:28 step:131590[D loss: 0.999981] [G loss: 0.999986]\n",
      "epoch:28 step:131595[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:28 step:131600[D loss: 0.999976] [G loss: 1.000048]\n",
      "##############\n",
      "[2.54263221 2.07972885 2.16328935 3.79654278 1.4389581  9.27426719\n",
      " 2.24024373 3.75793709 3.81818754 5.79096287]\n",
      "##########\n",
      "epoch:28 step:131605[D loss: 1.000114] [G loss: 0.999810]\n",
      "epoch:28 step:131610[D loss: 1.000007] [G loss: 0.999932]\n",
      "epoch:28 step:131615[D loss: 0.999992] [G loss: 1.000100]\n",
      "epoch:28 step:131620[D loss: 0.999941] [G loss: 1.000083]\n",
      "epoch:28 step:131625[D loss: 0.999884] [G loss: 1.000360]\n",
      "epoch:28 step:131630[D loss: 0.999885] [G loss: 1.000174]\n",
      "epoch:28 step:131635[D loss: 0.999966] [G loss: 1.000133]\n",
      "epoch:28 step:131640[D loss: 0.999939] [G loss: 1.000080]\n",
      "epoch:28 step:131645[D loss: 0.999969] [G loss: 1.000040]\n",
      "epoch:28 step:131650[D loss: 1.000039] [G loss: 0.999899]\n",
      "epoch:28 step:131655[D loss: 1.000116] [G loss: 0.999935]\n",
      "epoch:28 step:131660[D loss: 1.000123] [G loss: 0.999887]\n",
      "epoch:28 step:131665[D loss: 0.999979] [G loss: 1.000228]\n",
      "epoch:28 step:131670[D loss: 0.999984] [G loss: 1.000166]\n",
      "epoch:28 step:131675[D loss: 0.999926] [G loss: 1.000211]\n",
      "epoch:28 step:131680[D loss: 0.999907] [G loss: 1.000186]\n",
      "epoch:28 step:131685[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:28 step:131690[D loss: 0.999937] [G loss: 1.000185]\n",
      "epoch:28 step:131695[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:28 step:131700[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:28 step:131705[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:28 step:131710[D loss: 0.999972] [G loss: 1.000028]\n",
      "epoch:28 step:131715[D loss: 1.000060] [G loss: 0.999956]\n",
      "epoch:28 step:131720[D loss: 1.000086] [G loss: 0.999822]\n",
      "epoch:28 step:131725[D loss: 0.999907] [G loss: 1.000006]\n",
      "epoch:28 step:131730[D loss: 1.000038] [G loss: 1.000009]\n",
      "epoch:28 step:131735[D loss: 0.999994] [G loss: 1.000004]\n",
      "epoch:28 step:131740[D loss: 1.000014] [G loss: 1.000079]\n",
      "epoch:28 step:131745[D loss: 0.999963] [G loss: 1.000226]\n",
      "epoch:28 step:131750[D loss: 1.000036] [G loss: 0.999964]\n",
      "epoch:28 step:131755[D loss: 1.000070] [G loss: 1.000007]\n",
      "epoch:28 step:131760[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:28 step:131765[D loss: 1.000049] [G loss: 0.999934]\n",
      "epoch:28 step:131770[D loss: 1.000120] [G loss: 0.999878]\n",
      "epoch:28 step:131775[D loss: 1.000120] [G loss: 0.999828]\n",
      "epoch:28 step:131780[D loss: 0.999943] [G loss: 1.000012]\n",
      "epoch:28 step:131785[D loss: 1.000026] [G loss: 0.999954]\n",
      "epoch:28 step:131790[D loss: 1.000044] [G loss: 1.000013]\n",
      "epoch:28 step:131795[D loss: 1.000102] [G loss: 0.999868]\n",
      "epoch:28 step:131800[D loss: 0.999996] [G loss: 1.000146]\n",
      "##############\n",
      "[2.54225922 2.13012815 2.16139341 3.91935002 1.50151839 7.72341463\n",
      " 2.33085883 3.73442345 4.09890303 6.25766899]\n",
      "##########\n",
      "epoch:28 step:131805[D loss: 0.999973] [G loss: 1.000027]\n",
      "epoch:28 step:131810[D loss: 0.999942] [G loss: 1.000280]\n",
      "epoch:28 step:131815[D loss: 0.999934] [G loss: 1.000111]\n",
      "epoch:28 step:131820[D loss: 1.000011] [G loss: 1.000037]\n",
      "epoch:28 step:131825[D loss: 1.000067] [G loss: 0.999906]\n",
      "epoch:28 step:131830[D loss: 0.999911] [G loss: 1.000097]\n",
      "epoch:28 step:131835[D loss: 0.999953] [G loss: 1.000111]\n",
      "epoch:28 step:131840[D loss: 1.000014] [G loss: 1.000036]\n",
      "epoch:28 step:131845[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:28 step:131850[D loss: 1.000040] [G loss: 0.999895]\n",
      "epoch:28 step:131855[D loss: 1.000079] [G loss: 0.999850]\n",
      "epoch:28 step:131860[D loss: 0.999924] [G loss: 1.000016]\n",
      "epoch:28 step:131865[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:28 step:131870[D loss: 0.999922] [G loss: 1.000147]\n",
      "epoch:28 step:131875[D loss: 1.000014] [G loss: 1.000012]\n",
      "epoch:28 step:131880[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:28 step:131885[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:28 step:131890[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:28 step:131895[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:28 step:131900[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:28 step:131905[D loss: 0.999985] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:131910[D loss: 1.000045] [G loss: 0.999839]\n",
      "epoch:28 step:131915[D loss: 0.999972] [G loss: 1.000123]\n",
      "epoch:28 step:131920[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:28 step:131925[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:28 step:131930[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:28 step:131935[D loss: 1.000013] [G loss: 0.999969]\n",
      "epoch:28 step:131940[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:28 step:131945[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:28 step:131950[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:28 step:131955[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:28 step:131960[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:28 step:131965[D loss: 1.000041] [G loss: 0.999958]\n",
      "epoch:28 step:131970[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:28 step:131975[D loss: 0.999938] [G loss: 1.000128]\n",
      "epoch:28 step:131980[D loss: 0.999952] [G loss: 1.000128]\n",
      "epoch:28 step:131985[D loss: 0.999899] [G loss: 1.000195]\n",
      "epoch:28 step:131990[D loss: 0.999960] [G loss: 1.000122]\n",
      "epoch:28 step:131995[D loss: 0.999990] [G loss: 1.000083]\n",
      "epoch:28 step:132000[D loss: 0.999968] [G loss: 1.000112]\n",
      "##############\n",
      "[2.46371935 2.1710124  2.27353648 3.69049576 1.48342131 6.945607\n",
      " 2.32127329 3.63355658 4.0366964  5.68210265]\n",
      "##########\n",
      "epoch:28 step:132005[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:28 step:132010[D loss: 1.000037] [G loss: 0.999963]\n",
      "epoch:28 step:132015[D loss: 0.999940] [G loss: 1.000054]\n",
      "epoch:28 step:132020[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:28 step:132025[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:28 step:132030[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:28 step:132035[D loss: 0.999947] [G loss: 1.000113]\n",
      "epoch:28 step:132040[D loss: 1.000015] [G loss: 1.000022]\n",
      "epoch:28 step:132045[D loss: 0.999963] [G loss: 1.000035]\n",
      "epoch:28 step:132050[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:28 step:132055[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:28 step:132060[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:28 step:132065[D loss: 0.999955] [G loss: 1.000089]\n",
      "epoch:28 step:132070[D loss: 1.000009] [G loss: 1.000047]\n",
      "epoch:28 step:132075[D loss: 1.000068] [G loss: 0.999962]\n",
      "epoch:28 step:132080[D loss: 0.999892] [G loss: 1.000157]\n",
      "epoch:28 step:132085[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:28 step:132090[D loss: 1.000017] [G loss: 1.000064]\n",
      "epoch:28 step:132095[D loss: 0.999949] [G loss: 1.000146]\n",
      "epoch:28 step:132100[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:28 step:132105[D loss: 1.000033] [G loss: 0.999852]\n",
      "epoch:28 step:132110[D loss: 0.999953] [G loss: 1.000019]\n",
      "epoch:28 step:132115[D loss: 1.000013] [G loss: 0.999997]\n",
      "epoch:28 step:132120[D loss: 1.000027] [G loss: 1.000053]\n",
      "epoch:28 step:132125[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:28 step:132130[D loss: 0.999961] [G loss: 1.000046]\n",
      "epoch:28 step:132135[D loss: 1.000015] [G loss: 1.000068]\n",
      "epoch:28 step:132140[D loss: 0.999951] [G loss: 1.000077]\n",
      "epoch:28 step:132145[D loss: 1.000042] [G loss: 1.000013]\n",
      "epoch:28 step:132150[D loss: 0.999946] [G loss: 1.000102]\n",
      "epoch:28 step:132155[D loss: 1.000006] [G loss: 1.000064]\n",
      "epoch:28 step:132160[D loss: 1.000014] [G loss: 1.000023]\n",
      "epoch:28 step:132165[D loss: 0.999973] [G loss: 1.000175]\n",
      "epoch:28 step:132170[D loss: 0.999979] [G loss: 1.000169]\n",
      "epoch:28 step:132175[D loss: 0.999937] [G loss: 1.000115]\n",
      "epoch:28 step:132180[D loss: 1.000052] [G loss: 1.000081]\n",
      "epoch:28 step:132185[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:28 step:132190[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:28 step:132195[D loss: 0.999979] [G loss: 1.000021]\n",
      "epoch:28 step:132200[D loss: 1.000090] [G loss: 0.999889]\n",
      "##############\n",
      "[2.57337063 2.11247886 2.12607547 3.72876215 1.46638902 7.51290824\n",
      " 2.24508953 3.59184351 3.98790887 5.49027597]\n",
      "##########\n",
      "epoch:28 step:132205[D loss: 1.000074] [G loss: 0.999867]\n",
      "epoch:28 step:132210[D loss: 0.999921] [G loss: 1.000154]\n",
      "epoch:28 step:132215[D loss: 0.999988] [G loss: 1.000104]\n",
      "epoch:28 step:132220[D loss: 0.999900] [G loss: 1.000052]\n",
      "epoch:28 step:132225[D loss: 0.999990] [G loss: 1.000131]\n",
      "epoch:28 step:132230[D loss: 1.000002] [G loss: 1.000020]\n",
      "epoch:28 step:132235[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:28 step:132240[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:28 step:132245[D loss: 0.999971] [G loss: 1.000107]\n",
      "epoch:28 step:132250[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:28 step:132255[D loss: 0.999973] [G loss: 1.000106]\n",
      "epoch:28 step:132260[D loss: 1.000020] [G loss: 1.000012]\n",
      "epoch:28 step:132265[D loss: 1.000032] [G loss: 1.000194]\n",
      "epoch:28 step:132270[D loss: 0.999930] [G loss: 1.000060]\n",
      "epoch:28 step:132275[D loss: 0.999904] [G loss: 1.000146]\n",
      "epoch:28 step:132280[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:28 step:132285[D loss: 1.000010] [G loss: 1.000017]\n",
      "epoch:28 step:132290[D loss: 1.000125] [G loss: 0.999799]\n",
      "epoch:28 step:132295[D loss: 1.000008] [G loss: 1.000079]\n",
      "epoch:28 step:132300[D loss: 0.999938] [G loss: 1.000040]\n",
      "epoch:28 step:132305[D loss: 1.000032] [G loss: 1.000114]\n",
      "epoch:28 step:132310[D loss: 1.000121] [G loss: 1.000074]\n",
      "epoch:28 step:132315[D loss: 1.000203] [G loss: 0.999995]\n",
      "epoch:28 step:132320[D loss: 0.999901] [G loss: 1.000062]\n",
      "epoch:28 step:132325[D loss: 0.999917] [G loss: 1.000152]\n",
      "epoch:28 step:132330[D loss: 0.999944] [G loss: 1.000236]\n",
      "epoch:28 step:132335[D loss: 0.999995] [G loss: 1.000119]\n",
      "epoch:28 step:132340[D loss: 0.999951] [G loss: 1.000122]\n",
      "epoch:28 step:132345[D loss: 1.000013] [G loss: 1.000126]\n",
      "epoch:28 step:132350[D loss: 0.999936] [G loss: 1.000216]\n",
      "epoch:28 step:132355[D loss: 1.000041] [G loss: 1.000083]\n",
      "epoch:28 step:132360[D loss: 0.999909] [G loss: 1.000126]\n",
      "epoch:28 step:132365[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:28 step:132370[D loss: 1.000029] [G loss: 0.999891]\n",
      "epoch:28 step:132375[D loss: 1.000060] [G loss: 0.999915]\n",
      "epoch:28 step:132380[D loss: 1.000109] [G loss: 0.999797]\n",
      "epoch:28 step:132385[D loss: 1.000111] [G loss: 0.999847]\n",
      "epoch:28 step:132390[D loss: 0.999812] [G loss: 1.000365]\n",
      "epoch:28 step:132395[D loss: 1.000061] [G loss: 0.999889]\n",
      "epoch:28 step:132400[D loss: 1.000120] [G loss: 1.000094]\n",
      "##############\n",
      "[2.50507048 2.11038719 2.22570785 3.56307451 1.42248477 7.54241784\n",
      " 2.45002305 3.60694231 3.90291704 5.26533164]\n",
      "##########\n",
      "epoch:28 step:132405[D loss: 0.999840] [G loss: 1.000247]\n",
      "epoch:28 step:132410[D loss: 0.999825] [G loss: 1.000230]\n",
      "epoch:28 step:132415[D loss: 0.999923] [G loss: 1.000130]\n",
      "epoch:28 step:132420[D loss: 0.999970] [G loss: 1.000155]\n",
      "epoch:28 step:132425[D loss: 1.000017] [G loss: 1.000063]\n",
      "epoch:28 step:132430[D loss: 0.999939] [G loss: 1.000125]\n",
      "epoch:28 step:132435[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:28 step:132440[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:28 step:132445[D loss: 1.000022] [G loss: 1.000065]\n",
      "epoch:28 step:132450[D loss: 1.000032] [G loss: 0.999880]\n",
      "epoch:28 step:132455[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:28 step:132460[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:28 step:132465[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:28 step:132470[D loss: 1.000079] [G loss: 1.000128]\n",
      "epoch:28 step:132475[D loss: 1.000013] [G loss: 1.000058]\n",
      "epoch:28 step:132480[D loss: 0.999960] [G loss: 1.000185]\n",
      "epoch:28 step:132485[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:28 step:132490[D loss: 0.999932] [G loss: 1.000095]\n",
      "epoch:28 step:132495[D loss: 1.000010] [G loss: 1.000062]\n",
      "epoch:28 step:132500[D loss: 1.000015] [G loss: 0.999905]\n",
      "epoch:28 step:132505[D loss: 1.000025] [G loss: 0.999912]\n",
      "epoch:28 step:132510[D loss: 1.000006] [G loss: 1.000057]\n",
      "epoch:28 step:132515[D loss: 0.999976] [G loss: 1.000026]\n",
      "epoch:28 step:132520[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:28 step:132525[D loss: 0.999950] [G loss: 1.000064]\n",
      "epoch:28 step:132530[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:28 step:132535[D loss: 0.999944] [G loss: 1.000058]\n",
      "epoch:28 step:132540[D loss: 1.000011] [G loss: 1.000086]\n",
      "epoch:28 step:132545[D loss: 1.000036] [G loss: 0.999967]\n",
      "epoch:28 step:132550[D loss: 0.999946] [G loss: 1.000102]\n",
      "epoch:28 step:132555[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:28 step:132560[D loss: 1.000046] [G loss: 0.999932]\n",
      "epoch:28 step:132565[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:28 step:132570[D loss: 0.999922] [G loss: 1.000197]\n",
      "epoch:28 step:132575[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:28 step:132580[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:28 step:132585[D loss: 0.999945] [G loss: 1.000093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:132590[D loss: 0.999998] [G loss: 1.000050]\n",
      "epoch:28 step:132595[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:28 step:132600[D loss: 1.000049] [G loss: 0.999986]\n",
      "##############\n",
      "[2.50335473 2.17834418 2.19867483 3.83555012 1.40929148 7.61436676\n",
      " 2.30663022 3.66936053 3.95192344 4.69506838]\n",
      "##########\n",
      "epoch:28 step:132605[D loss: 1.000019] [G loss: 0.999968]\n",
      "epoch:28 step:132610[D loss: 0.999922] [G loss: 1.000077]\n",
      "epoch:28 step:132615[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:28 step:132620[D loss: 1.000008] [G loss: 1.000037]\n",
      "epoch:28 step:132625[D loss: 1.000028] [G loss: 1.000038]\n",
      "epoch:28 step:132630[D loss: 0.999951] [G loss: 1.000069]\n",
      "epoch:28 step:132635[D loss: 1.000007] [G loss: 1.000004]\n",
      "epoch:28 step:132640[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:28 step:132645[D loss: 0.999967] [G loss: 1.000027]\n",
      "epoch:28 step:132650[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:28 step:132655[D loss: 1.000051] [G loss: 0.999973]\n",
      "epoch:28 step:132660[D loss: 0.999903] [G loss: 1.000102]\n",
      "epoch:28 step:132665[D loss: 1.000000] [G loss: 1.000009]\n",
      "epoch:28 step:132670[D loss: 1.000008] [G loss: 1.000018]\n",
      "epoch:28 step:132675[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:28 step:132680[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:28 step:132685[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:28 step:132690[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:28 step:132695[D loss: 0.999976] [G loss: 1.000020]\n",
      "epoch:28 step:132700[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:28 step:132705[D loss: 1.000023] [G loss: 1.000038]\n",
      "epoch:28 step:132710[D loss: 1.000027] [G loss: 1.000025]\n",
      "epoch:28 step:132715[D loss: 0.999976] [G loss: 1.000008]\n",
      "epoch:28 step:132720[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:28 step:132725[D loss: 1.000139] [G loss: 0.999895]\n",
      "epoch:28 step:132730[D loss: 1.000034] [G loss: 1.000102]\n",
      "epoch:28 step:132735[D loss: 0.999968] [G loss: 1.000230]\n",
      "epoch:28 step:132740[D loss: 1.000026] [G loss: 0.999937]\n",
      "epoch:28 step:132745[D loss: 0.999859] [G loss: 1.000177]\n",
      "epoch:28 step:132750[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:28 step:132755[D loss: 0.999994] [G loss: 1.000076]\n",
      "epoch:28 step:132760[D loss: 0.999964] [G loss: 1.000223]\n",
      "epoch:28 step:132765[D loss: 0.999952] [G loss: 1.000037]\n",
      "epoch:28 step:132770[D loss: 1.000004] [G loss: 0.999991]\n",
      "epoch:28 step:132775[D loss: 1.000009] [G loss: 1.000019]\n",
      "epoch:28 step:132780[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:28 step:132785[D loss: 1.000162] [G loss: 0.999880]\n",
      "epoch:28 step:132790[D loss: 1.000010] [G loss: 1.000046]\n",
      "epoch:28 step:132795[D loss: 1.000065] [G loss: 1.000024]\n",
      "epoch:28 step:132800[D loss: 1.000063] [G loss: 0.999816]\n",
      "##############\n",
      "[2.50230955 2.19605752 2.09488938 3.71979696 1.41372023 7.66674598\n",
      " 2.30830108 3.63482629 3.89978184 4.90066149]\n",
      "##########\n",
      "epoch:28 step:132805[D loss: 0.999935] [G loss: 1.000041]\n",
      "epoch:28 step:132810[D loss: 0.999973] [G loss: 1.000008]\n",
      "epoch:28 step:132815[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:28 step:132820[D loss: 0.999946] [G loss: 0.999990]\n",
      "epoch:28 step:132825[D loss: 1.000008] [G loss: 1.000045]\n",
      "epoch:28 step:132830[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:28 step:132835[D loss: 0.999938] [G loss: 1.000092]\n",
      "epoch:28 step:132840[D loss: 1.000002] [G loss: 1.000060]\n",
      "epoch:28 step:132845[D loss: 0.999930] [G loss: 1.000096]\n",
      "epoch:28 step:132850[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:28 step:132855[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:28 step:132860[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:28 step:132865[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:28 step:132870[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:28 step:132875[D loss: 0.999999] [G loss: 1.000014]\n",
      "epoch:28 step:132880[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:28 step:132885[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:28 step:132890[D loss: 0.999951] [G loss: 1.000134]\n",
      "epoch:28 step:132895[D loss: 0.999999] [G loss: 1.000046]\n",
      "epoch:28 step:132900[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:28 step:132905[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:28 step:132910[D loss: 1.000146] [G loss: 0.999820]\n",
      "epoch:28 step:132915[D loss: 0.999934] [G loss: 1.000068]\n",
      "epoch:28 step:132920[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:28 step:132925[D loss: 1.000035] [G loss: 1.000032]\n",
      "epoch:28 step:132930[D loss: 0.999942] [G loss: 1.000075]\n",
      "epoch:28 step:132935[D loss: 0.999941] [G loss: 1.000123]\n",
      "epoch:28 step:132940[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:28 step:132945[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:28 step:132950[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:28 step:132955[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:28 step:132960[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:28 step:132965[D loss: 0.999919] [G loss: 1.000126]\n",
      "epoch:28 step:132970[D loss: 1.000081] [G loss: 0.999963]\n",
      "epoch:28 step:132975[D loss: 0.999938] [G loss: 1.000044]\n",
      "epoch:28 step:132980[D loss: 1.000077] [G loss: 1.000046]\n",
      "epoch:28 step:132985[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:28 step:132990[D loss: 0.999955] [G loss: 1.000126]\n",
      "epoch:28 step:132995[D loss: 0.999944] [G loss: 1.000065]\n",
      "epoch:28 step:133000[D loss: 1.000017] [G loss: 1.000054]\n",
      "##############\n",
      "[2.52075262 2.16408484 2.18585163 3.51482868 1.40898601 7.26786177\n",
      " 2.27359191 3.70244288 3.88619476 5.21673555]\n",
      "##########\n",
      "epoch:28 step:133005[D loss: 1.000060] [G loss: 0.999881]\n",
      "epoch:28 step:133010[D loss: 0.999954] [G loss: 1.000075]\n",
      "epoch:28 step:133015[D loss: 0.999970] [G loss: 1.000152]\n",
      "epoch:28 step:133020[D loss: 1.000020] [G loss: 0.999995]\n",
      "epoch:28 step:133025[D loss: 0.999974] [G loss: 1.000122]\n",
      "epoch:28 step:133030[D loss: 0.999921] [G loss: 1.000200]\n",
      "epoch:28 step:133035[D loss: 1.000024] [G loss: 1.000027]\n",
      "epoch:28 step:133040[D loss: 0.999982] [G loss: 1.000175]\n",
      "epoch:28 step:133045[D loss: 0.999930] [G loss: 1.000126]\n",
      "epoch:28 step:133050[D loss: 1.000058] [G loss: 1.000181]\n",
      "epoch:28 step:133055[D loss: 0.999947] [G loss: 1.000092]\n",
      "epoch:28 step:133060[D loss: 1.000035] [G loss: 0.999967]\n",
      "epoch:28 step:133065[D loss: 1.000156] [G loss: 0.999690]\n",
      "epoch:28 step:133070[D loss: 1.000195] [G loss: 0.999900]\n",
      "epoch:28 step:133075[D loss: 1.000263] [G loss: 0.999509]\n",
      "epoch:28 step:133080[D loss: 0.999900] [G loss: 0.999892]\n",
      "epoch:28 step:133085[D loss: 1.000072] [G loss: 0.999842]\n",
      "epoch:28 step:133090[D loss: 0.999980] [G loss: 1.000019]\n",
      "epoch:28 step:133095[D loss: 0.999919] [G loss: 1.000044]\n",
      "epoch:28 step:133100[D loss: 0.999970] [G loss: 1.000113]\n",
      "epoch:28 step:133105[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:28 step:133110[D loss: 1.000000] [G loss: 1.000016]\n",
      "epoch:28 step:133115[D loss: 1.000041] [G loss: 1.000033]\n",
      "epoch:28 step:133120[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:28 step:133125[D loss: 0.999945] [G loss: 1.000039]\n",
      "epoch:28 step:133130[D loss: 1.000042] [G loss: 1.000050]\n",
      "epoch:28 step:133135[D loss: 0.999948] [G loss: 1.000065]\n",
      "epoch:28 step:133140[D loss: 1.000048] [G loss: 1.000045]\n",
      "epoch:28 step:133145[D loss: 0.999943] [G loss: 1.000085]\n",
      "epoch:28 step:133150[D loss: 1.000025] [G loss: 1.000057]\n",
      "epoch:28 step:133155[D loss: 0.999908] [G loss: 1.000141]\n",
      "epoch:28 step:133160[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:28 step:133165[D loss: 1.000041] [G loss: 0.999927]\n",
      "epoch:28 step:133170[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:28 step:133175[D loss: 1.000044] [G loss: 0.999880]\n",
      "epoch:28 step:133180[D loss: 1.000097] [G loss: 0.999910]\n",
      "epoch:28 step:133185[D loss: 0.999985] [G loss: 1.000104]\n",
      "epoch:28 step:133190[D loss: 1.000060] [G loss: 0.999874]\n",
      "epoch:28 step:133195[D loss: 0.999946] [G loss: 1.000199]\n",
      "epoch:28 step:133200[D loss: 0.999925] [G loss: 1.000140]\n",
      "##############\n",
      "[2.62776304 2.2204334  2.28031639 3.51143175 1.40745617 7.55354654\n",
      " 2.33627017 3.75392451 4.05591834 5.99318423]\n",
      "##########\n",
      "epoch:28 step:133205[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:28 step:133210[D loss: 0.999929] [G loss: 1.000181]\n",
      "epoch:28 step:133215[D loss: 1.000030] [G loss: 0.999998]\n",
      "epoch:28 step:133220[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:28 step:133225[D loss: 0.999988] [G loss: 1.000007]\n",
      "epoch:28 step:133230[D loss: 1.000161] [G loss: 0.999873]\n",
      "epoch:28 step:133235[D loss: 1.000046] [G loss: 0.999889]\n",
      "epoch:28 step:133240[D loss: 0.999913] [G loss: 1.000077]\n",
      "epoch:28 step:133245[D loss: 0.999980] [G loss: 1.000075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:133250[D loss: 0.999937] [G loss: 1.000134]\n",
      "epoch:28 step:133255[D loss: 1.000021] [G loss: 1.000131]\n",
      "epoch:28 step:133260[D loss: 0.999938] [G loss: 1.000128]\n",
      "epoch:28 step:133265[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:28 step:133270[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:28 step:133275[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:28 step:133280[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:28 step:133285[D loss: 1.000041] [G loss: 1.000123]\n",
      "epoch:28 step:133290[D loss: 0.999982] [G loss: 1.000149]\n",
      "epoch:28 step:133295[D loss: 0.999965] [G loss: 1.000104]\n",
      "epoch:28 step:133300[D loss: 0.999960] [G loss: 1.000120]\n",
      "epoch:28 step:133305[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:28 step:133310[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:28 step:133315[D loss: 1.000050] [G loss: 0.999979]\n",
      "epoch:28 step:133320[D loss: 1.000079] [G loss: 0.999856]\n",
      "epoch:28 step:133325[D loss: 1.000062] [G loss: 0.999915]\n",
      "epoch:28 step:133330[D loss: 0.999918] [G loss: 1.000135]\n",
      "epoch:28 step:133335[D loss: 0.999872] [G loss: 1.000198]\n",
      "epoch:28 step:133340[D loss: 1.000073] [G loss: 1.000118]\n",
      "epoch:28 step:133345[D loss: 0.999978] [G loss: 1.000124]\n",
      "epoch:28 step:133350[D loss: 1.000096] [G loss: 0.999985]\n",
      "epoch:28 step:133355[D loss: 0.999954] [G loss: 1.000137]\n",
      "epoch:28 step:133360[D loss: 0.999959] [G loss: 1.000029]\n",
      "epoch:28 step:133365[D loss: 0.999940] [G loss: 1.000081]\n",
      "epoch:28 step:133370[D loss: 0.999998] [G loss: 0.999998]\n",
      "epoch:28 step:133375[D loss: 0.999888] [G loss: 1.000085]\n",
      "epoch:28 step:133380[D loss: 1.000025] [G loss: 1.000008]\n",
      "epoch:28 step:133385[D loss: 1.000034] [G loss: 0.999977]\n",
      "epoch:28 step:133390[D loss: 1.000124] [G loss: 0.999945]\n",
      "epoch:28 step:133395[D loss: 0.999926] [G loss: 1.000128]\n",
      "epoch:28 step:133400[D loss: 0.999849] [G loss: 1.000277]\n",
      "##############\n",
      "[2.5417216  2.21697713 2.17982716 3.51768968 1.45699977 7.28812324\n",
      " 2.24369501 3.86964526 4.07668549 5.15411909]\n",
      "##########\n",
      "epoch:28 step:133405[D loss: 0.999936] [G loss: 1.000061]\n",
      "epoch:28 step:133410[D loss: 1.000111] [G loss: 1.000016]\n",
      "epoch:28 step:133415[D loss: 1.000037] [G loss: 1.000170]\n",
      "epoch:28 step:133420[D loss: 0.999968] [G loss: 1.000287]\n",
      "epoch:28 step:133425[D loss: 0.999864] [G loss: 1.000342]\n",
      "epoch:28 step:133430[D loss: 0.999968] [G loss: 1.000253]\n",
      "epoch:28 step:133435[D loss: 0.999942] [G loss: 1.000145]\n",
      "epoch:28 step:133440[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:28 step:133445[D loss: 0.999994] [G loss: 0.999992]\n",
      "epoch:28 step:133450[D loss: 1.000064] [G loss: 1.000023]\n",
      "epoch:28 step:133455[D loss: 1.000010] [G loss: 0.999946]\n",
      "epoch:28 step:133460[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:28 step:133465[D loss: 1.000127] [G loss: 0.999835]\n",
      "epoch:28 step:133470[D loss: 1.000020] [G loss: 1.000052]\n",
      "epoch:28 step:133475[D loss: 1.000197] [G loss: 1.000137]\n",
      "epoch:28 step:133480[D loss: 0.999876] [G loss: 1.000111]\n",
      "epoch:28 step:133485[D loss: 0.999774] [G loss: 1.000360]\n",
      "epoch:28 step:133490[D loss: 0.999996] [G loss: 1.000025]\n",
      "epoch:28 step:133495[D loss: 0.999972] [G loss: 1.000120]\n",
      "epoch:28 step:133500[D loss: 0.999974] [G loss: 1.000124]\n",
      "epoch:28 step:133505[D loss: 1.000021] [G loss: 0.999982]\n",
      "epoch:28 step:133510[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:28 step:133515[D loss: 1.000041] [G loss: 0.999969]\n",
      "epoch:28 step:133520[D loss: 1.000092] [G loss: 1.000032]\n",
      "epoch:28 step:133525[D loss: 1.000108] [G loss: 1.000077]\n",
      "epoch:28 step:133530[D loss: 1.000076] [G loss: 1.000015]\n",
      "epoch:28 step:133535[D loss: 0.999948] [G loss: 1.000202]\n",
      "epoch:28 step:133540[D loss: 0.999893] [G loss: 1.000204]\n",
      "epoch:28 step:133545[D loss: 0.999943] [G loss: 1.000133]\n",
      "epoch:28 step:133550[D loss: 0.999977] [G loss: 1.000105]\n",
      "epoch:28 step:133555[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:28 step:133560[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:28 step:133565[D loss: 1.000044] [G loss: 0.999921]\n",
      "epoch:28 step:133570[D loss: 1.000020] [G loss: 0.999880]\n",
      "epoch:28 step:133575[D loss: 1.000067] [G loss: 0.999992]\n",
      "epoch:28 step:133580[D loss: 0.999920] [G loss: 1.000058]\n",
      "epoch:28 step:133585[D loss: 1.000001] [G loss: 1.000034]\n",
      "epoch:28 step:133590[D loss: 0.999912] [G loss: 1.000134]\n",
      "epoch:28 step:133595[D loss: 0.999946] [G loss: 1.000143]\n",
      "epoch:28 step:133600[D loss: 0.999906] [G loss: 1.000213]\n",
      "##############\n",
      "[2.45557474 2.13372016 2.24207246 3.74507043 1.42027562 6.77486488\n",
      " 2.25909879 3.74049693 3.84745991 5.25694437]\n",
      "##########\n",
      "epoch:28 step:133605[D loss: 0.999939] [G loss: 1.000159]\n",
      "epoch:28 step:133610[D loss: 0.999999] [G loss: 1.000078]\n",
      "epoch:28 step:133615[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:28 step:133620[D loss: 1.000045] [G loss: 0.999984]\n",
      "epoch:28 step:133625[D loss: 0.999980] [G loss: 1.000001]\n",
      "epoch:28 step:133630[D loss: 1.000058] [G loss: 1.000024]\n",
      "epoch:28 step:133635[D loss: 0.999936] [G loss: 1.000135]\n",
      "epoch:28 step:133640[D loss: 0.999962] [G loss: 1.000146]\n",
      "epoch:28 step:133645[D loss: 1.000070] [G loss: 1.000063]\n",
      "epoch:28 step:133650[D loss: 0.999971] [G loss: 1.000203]\n",
      "epoch:28 step:133655[D loss: 1.000094] [G loss: 1.000135]\n",
      "epoch:28 step:133660[D loss: 0.999980] [G loss: 1.000479]\n",
      "epoch:28 step:133665[D loss: 0.999912] [G loss: 1.000313]\n",
      "epoch:28 step:133670[D loss: 0.999924] [G loss: 1.000182]\n",
      "epoch:28 step:133675[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:28 step:133680[D loss: 1.000107] [G loss: 0.999971]\n",
      "epoch:28 step:133685[D loss: 0.999996] [G loss: 0.999905]\n",
      "epoch:28 step:133690[D loss: 0.999932] [G loss: 1.000028]\n",
      "epoch:28 step:133695[D loss: 0.999979] [G loss: 0.999947]\n",
      "epoch:28 step:133700[D loss: 1.000024] [G loss: 0.999890]\n",
      "epoch:28 step:133705[D loss: 1.000020] [G loss: 0.999981]\n",
      "epoch:28 step:133710[D loss: 0.999891] [G loss: 1.000049]\n",
      "epoch:28 step:133715[D loss: 1.000133] [G loss: 0.999980]\n",
      "epoch:28 step:133720[D loss: 1.000186] [G loss: 0.999909]\n",
      "epoch:28 step:133725[D loss: 1.000021] [G loss: 1.000053]\n",
      "epoch:28 step:133730[D loss: 1.000216] [G loss: 1.000071]\n",
      "epoch:28 step:133735[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:28 step:133740[D loss: 0.999798] [G loss: 1.000256]\n",
      "epoch:28 step:133745[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:28 step:133750[D loss: 0.999942] [G loss: 1.000122]\n",
      "epoch:28 step:133755[D loss: 0.999950] [G loss: 1.000117]\n",
      "epoch:28 step:133760[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:28 step:133765[D loss: 0.999969] [G loss: 1.000132]\n",
      "epoch:28 step:133770[D loss: 1.000037] [G loss: 1.000014]\n",
      "epoch:28 step:133775[D loss: 1.000040] [G loss: 1.000030]\n",
      "epoch:28 step:133780[D loss: 1.000139] [G loss: 0.999828]\n",
      "epoch:28 step:133785[D loss: 1.000094] [G loss: 0.999948]\n",
      "epoch:28 step:133790[D loss: 0.999939] [G loss: 1.000186]\n",
      "epoch:28 step:133795[D loss: 0.999959] [G loss: 1.000205]\n",
      "epoch:28 step:133800[D loss: 0.999989] [G loss: 1.000334]\n",
      "##############\n",
      "[2.55188033 2.22142468 2.0879539  3.81177272 1.48574781 8.16949951\n",
      " 2.19018838 3.8257544  3.96826974 5.14005587]\n",
      "##########\n",
      "epoch:28 step:133805[D loss: 0.999908] [G loss: 1.000212]\n",
      "epoch:28 step:133810[D loss: 0.999892] [G loss: 1.000198]\n",
      "epoch:28 step:133815[D loss: 0.999974] [G loss: 1.000175]\n",
      "epoch:28 step:133820[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:28 step:133825[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:28 step:133830[D loss: 0.999954] [G loss: 1.000046]\n",
      "epoch:28 step:133835[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:28 step:133840[D loss: 0.999996] [G loss: 0.999957]\n",
      "epoch:28 step:133845[D loss: 1.000006] [G loss: 0.999996]\n",
      "epoch:28 step:133850[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:28 step:133855[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:28 step:133860[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:28 step:133865[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:28 step:133870[D loss: 1.000021] [G loss: 1.000056]\n",
      "epoch:28 step:133875[D loss: 0.999954] [G loss: 1.000099]\n",
      "epoch:28 step:133880[D loss: 1.000013] [G loss: 0.999976]\n",
      "epoch:28 step:133885[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:28 step:133890[D loss: 0.999943] [G loss: 1.000114]\n",
      "epoch:28 step:133895[D loss: 1.000023] [G loss: 1.000035]\n",
      "epoch:28 step:133900[D loss: 1.000057] [G loss: 0.999903]\n",
      "epoch:28 step:133905[D loss: 0.999904] [G loss: 1.000200]\n",
      "epoch:28 step:133910[D loss: 0.999968] [G loss: 1.000128]\n",
      "epoch:28 step:133915[D loss: 0.999862] [G loss: 1.000141]\n",
      "epoch:28 step:133920[D loss: 0.999942] [G loss: 1.000095]\n",
      "epoch:28 step:133925[D loss: 0.999918] [G loss: 1.000167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:133930[D loss: 1.000036] [G loss: 1.000075]\n",
      "epoch:28 step:133935[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:28 step:133940[D loss: 0.999987] [G loss: 1.000122]\n",
      "epoch:28 step:133945[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:28 step:133950[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:28 step:133955[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:28 step:133960[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:28 step:133965[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:28 step:133970[D loss: 1.000002] [G loss: 1.000080]\n",
      "epoch:28 step:133975[D loss: 1.000019] [G loss: 1.000060]\n",
      "epoch:28 step:133980[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:28 step:133985[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:28 step:133990[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:28 step:133995[D loss: 1.000039] [G loss: 1.000037]\n",
      "epoch:28 step:134000[D loss: 0.999966] [G loss: 1.000064]\n",
      "##############\n",
      "[2.52226239 2.15476871 2.05026806 3.80555747 1.51025499 7.59744813\n",
      " 2.41995554 3.73910929 3.92362958 5.49418377]\n",
      "##########\n",
      "epoch:28 step:134005[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:28 step:134010[D loss: 0.999952] [G loss: 1.000116]\n",
      "epoch:28 step:134015[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:28 step:134020[D loss: 0.999994] [G loss: 1.000142]\n",
      "epoch:28 step:134025[D loss: 0.999981] [G loss: 1.000101]\n",
      "epoch:28 step:134030[D loss: 0.999955] [G loss: 1.000147]\n",
      "epoch:28 step:134035[D loss: 0.999946] [G loss: 1.000106]\n",
      "epoch:28 step:134040[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:28 step:134045[D loss: 1.000021] [G loss: 1.000066]\n",
      "epoch:28 step:134050[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:28 step:134055[D loss: 1.000030] [G loss: 1.000061]\n",
      "epoch:28 step:134060[D loss: 0.999986] [G loss: 1.000116]\n",
      "epoch:28 step:134065[D loss: 0.999931] [G loss: 1.000061]\n",
      "epoch:28 step:134070[D loss: 0.999989] [G loss: 1.000128]\n",
      "epoch:28 step:134075[D loss: 0.999953] [G loss: 1.000114]\n",
      "epoch:28 step:134080[D loss: 1.000088] [G loss: 1.000086]\n",
      "epoch:28 step:134085[D loss: 0.999905] [G loss: 1.000114]\n",
      "epoch:28 step:134090[D loss: 1.000017] [G loss: 0.999995]\n",
      "epoch:28 step:134095[D loss: 0.999946] [G loss: 1.000130]\n",
      "epoch:28 step:134100[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:28 step:134105[D loss: 1.000034] [G loss: 0.999962]\n",
      "epoch:28 step:134110[D loss: 1.000009] [G loss: 1.000000]\n",
      "epoch:28 step:134115[D loss: 1.000014] [G loss: 1.000057]\n",
      "epoch:28 step:134120[D loss: 1.000078] [G loss: 1.000145]\n",
      "epoch:28 step:134125[D loss: 1.000067] [G loss: 1.000133]\n",
      "epoch:28 step:134130[D loss: 0.999937] [G loss: 1.000131]\n",
      "epoch:28 step:134135[D loss: 0.999836] [G loss: 1.000241]\n",
      "epoch:28 step:134140[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:28 step:134145[D loss: 1.000048] [G loss: 1.000019]\n",
      "epoch:28 step:134150[D loss: 1.000002] [G loss: 0.999974]\n",
      "epoch:28 step:134155[D loss: 1.000172] [G loss: 0.999983]\n",
      "epoch:28 step:134160[D loss: 1.000119] [G loss: 1.000009]\n",
      "epoch:28 step:134165[D loss: 0.999864] [G loss: 1.000258]\n",
      "epoch:28 step:134170[D loss: 0.999983] [G loss: 1.000099]\n",
      "epoch:28 step:134175[D loss: 0.999950] [G loss: 1.000163]\n",
      "epoch:28 step:134180[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:28 step:134185[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:28 step:134190[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:28 step:134195[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:28 step:134200[D loss: 0.999971] [G loss: 1.000079]\n",
      "##############\n",
      "[2.50451967 2.1210121  2.08950539 3.60319771 1.49521125 7.96022682\n",
      " 2.18894683 3.69332545 3.91644575 5.06985109]\n",
      "##########\n",
      "epoch:28 step:134205[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:28 step:134210[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:28 step:134215[D loss: 1.000004] [G loss: 1.000045]\n",
      "epoch:28 step:134220[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:28 step:134225[D loss: 1.000061] [G loss: 1.000055]\n",
      "epoch:28 step:134230[D loss: 0.999932] [G loss: 1.000122]\n",
      "epoch:28 step:134235[D loss: 0.999904] [G loss: 1.000123]\n",
      "epoch:28 step:134240[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:28 step:134245[D loss: 1.000006] [G loss: 1.000042]\n",
      "epoch:28 step:134250[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:28 step:134255[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:28 step:134260[D loss: 1.000000] [G loss: 1.000083]\n",
      "epoch:28 step:134265[D loss: 0.999979] [G loss: 1.000136]\n",
      "epoch:28 step:134270[D loss: 1.000028] [G loss: 1.000069]\n",
      "epoch:28 step:134275[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:28 step:134280[D loss: 1.000038] [G loss: 1.000090]\n",
      "epoch:28 step:134285[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:28 step:134290[D loss: 0.999878] [G loss: 1.000299]\n",
      "epoch:28 step:134295[D loss: 1.000029] [G loss: 1.000003]\n",
      "epoch:28 step:134300[D loss: 1.000028] [G loss: 1.000023]\n",
      "epoch:28 step:134305[D loss: 0.999943] [G loss: 1.000278]\n",
      "epoch:28 step:134310[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:28 step:134315[D loss: 0.999995] [G loss: 1.000058]\n",
      "epoch:28 step:134320[D loss: 0.999953] [G loss: 1.000060]\n",
      "epoch:28 step:134325[D loss: 0.999985] [G loss: 1.000020]\n",
      "epoch:28 step:134330[D loss: 1.000106] [G loss: 0.999763]\n",
      "epoch:28 step:134335[D loss: 0.999884] [G loss: 1.000197]\n",
      "epoch:28 step:134340[D loss: 1.000083] [G loss: 1.000095]\n",
      "epoch:28 step:134345[D loss: 0.999921] [G loss: 1.000197]\n",
      "epoch:28 step:134350[D loss: 0.999988] [G loss: 1.000084]\n",
      "epoch:28 step:134355[D loss: 1.000014] [G loss: 0.999990]\n",
      "epoch:28 step:134360[D loss: 1.000030] [G loss: 0.999937]\n",
      "epoch:28 step:134365[D loss: 1.000005] [G loss: 1.000122]\n",
      "epoch:28 step:134370[D loss: 0.999891] [G loss: 1.000021]\n",
      "epoch:28 step:134375[D loss: 0.999890] [G loss: 1.000145]\n",
      "epoch:28 step:134380[D loss: 1.000112] [G loss: 1.000035]\n",
      "epoch:28 step:134385[D loss: 1.000066] [G loss: 1.000100]\n",
      "epoch:28 step:134390[D loss: 1.000021] [G loss: 0.999963]\n",
      "epoch:28 step:134395[D loss: 0.999889] [G loss: 1.000088]\n",
      "epoch:28 step:134400[D loss: 0.999967] [G loss: 1.000064]\n",
      "##############\n",
      "[2.49769073 2.24031295 2.3429741  3.81082062 1.45583554 7.31633933\n",
      " 2.40977872 3.96287869 3.9337377  5.55215643]\n",
      "##########\n",
      "epoch:28 step:134405[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:28 step:134410[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:28 step:134415[D loss: 0.999890] [G loss: 1.000103]\n",
      "epoch:28 step:134420[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:28 step:134425[D loss: 1.000052] [G loss: 1.000079]\n",
      "epoch:28 step:134430[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:28 step:134435[D loss: 1.000087] [G loss: 1.000049]\n",
      "epoch:28 step:134440[D loss: 1.000036] [G loss: 1.000014]\n",
      "epoch:28 step:134445[D loss: 0.999990] [G loss: 1.000078]\n",
      "epoch:28 step:134450[D loss: 0.999980] [G loss: 1.000133]\n",
      "epoch:28 step:134455[D loss: 0.999956] [G loss: 1.000149]\n",
      "epoch:28 step:134460[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:28 step:134465[D loss: 1.000046] [G loss: 0.999946]\n",
      "epoch:28 step:134470[D loss: 0.999977] [G loss: 1.000104]\n",
      "epoch:28 step:134475[D loss: 0.999995] [G loss: 1.000094]\n",
      "epoch:28 step:134480[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:28 step:134485[D loss: 0.999968] [G loss: 1.000145]\n",
      "epoch:28 step:134490[D loss: 1.000047] [G loss: 1.000071]\n",
      "epoch:28 step:134495[D loss: 1.000005] [G loss: 1.000115]\n",
      "epoch:28 step:134500[D loss: 0.999943] [G loss: 1.000106]\n",
      "epoch:28 step:134505[D loss: 1.000011] [G loss: 1.000064]\n",
      "epoch:28 step:134510[D loss: 1.000050] [G loss: 0.999943]\n",
      "epoch:28 step:134515[D loss: 0.999957] [G loss: 0.999939]\n",
      "epoch:28 step:134520[D loss: 1.000062] [G loss: 0.999959]\n",
      "epoch:28 step:134525[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:28 step:134530[D loss: 1.000021] [G loss: 1.000038]\n",
      "epoch:28 step:134535[D loss: 0.999926] [G loss: 1.000092]\n",
      "epoch:28 step:134540[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:28 step:134545[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:28 step:134550[D loss: 0.999950] [G loss: 1.000111]\n",
      "epoch:28 step:134555[D loss: 0.999990] [G loss: 1.000082]\n",
      "epoch:28 step:134560[D loss: 0.999974] [G loss: 1.000018]\n",
      "epoch:28 step:134565[D loss: 0.999979] [G loss: 1.000096]\n",
      "epoch:28 step:134570[D loss: 1.000124] [G loss: 0.999880]\n",
      "epoch:28 step:134575[D loss: 1.000083] [G loss: 0.999900]\n",
      "epoch:28 step:134580[D loss: 0.999997] [G loss: 0.999996]\n",
      "epoch:28 step:134585[D loss: 0.999884] [G loss: 1.000193]\n",
      "epoch:28 step:134590[D loss: 1.000004] [G loss: 1.000144]\n",
      "epoch:28 step:134595[D loss: 1.000009] [G loss: 1.000020]\n",
      "epoch:28 step:134600[D loss: 0.999961] [G loss: 1.000096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.45806166 2.11240989 2.09126555 3.60556513 1.45662559 7.00651655\n",
      " 2.32630698 3.56126549 3.87777027 5.38159754]\n",
      "##########\n",
      "epoch:28 step:134605[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:28 step:134610[D loss: 1.000015] [G loss: 1.000009]\n",
      "epoch:28 step:134615[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:28 step:134620[D loss: 1.000008] [G loss: 1.000013]\n",
      "epoch:28 step:134625[D loss: 1.000092] [G loss: 0.999929]\n",
      "epoch:28 step:134630[D loss: 0.999929] [G loss: 1.000092]\n",
      "epoch:28 step:134635[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:28 step:134640[D loss: 0.999942] [G loss: 1.000117]\n",
      "epoch:28 step:134645[D loss: 1.000172] [G loss: 0.999808]\n",
      "epoch:28 step:134650[D loss: 0.999985] [G loss: 1.000109]\n",
      "epoch:28 step:134655[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:28 step:134660[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:28 step:134665[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:28 step:134670[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:28 step:134675[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:28 step:134680[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:28 step:134685[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:28 step:134690[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:28 step:134695[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:28 step:134700[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:28 step:134705[D loss: 1.000084] [G loss: 1.000015]\n",
      "epoch:28 step:134710[D loss: 0.999906] [G loss: 1.000267]\n",
      "epoch:28 step:134715[D loss: 0.999906] [G loss: 1.000180]\n",
      "epoch:28 step:134720[D loss: 0.999912] [G loss: 1.000244]\n",
      "epoch:28 step:134725[D loss: 0.999943] [G loss: 1.000067]\n",
      "epoch:28 step:134730[D loss: 1.000024] [G loss: 0.999977]\n",
      "epoch:28 step:134735[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:28 step:134740[D loss: 0.999957] [G loss: 1.000007]\n",
      "epoch:28 step:134745[D loss: 0.999948] [G loss: 1.000080]\n",
      "epoch:28 step:134750[D loss: 1.000086] [G loss: 1.000020]\n",
      "epoch:28 step:134755[D loss: 0.999963] [G loss: 0.999992]\n",
      "epoch:28 step:134760[D loss: 1.000053] [G loss: 0.999885]\n",
      "epoch:28 step:134765[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:28 step:134770[D loss: 0.999898] [G loss: 1.000142]\n",
      "epoch:28 step:134775[D loss: 0.999926] [G loss: 1.000114]\n",
      "epoch:28 step:134780[D loss: 1.000060] [G loss: 1.000000]\n",
      "epoch:28 step:134785[D loss: 1.000051] [G loss: 0.999966]\n",
      "epoch:28 step:134790[D loss: 1.000014] [G loss: 1.000104]\n",
      "epoch:28 step:134795[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:28 step:134800[D loss: 0.999938] [G loss: 1.000016]\n",
      "##############\n",
      "[2.61720564 2.24690678 2.28566238 3.75661257 1.50944444 8.40915119\n",
      " 2.335271   3.67432451 4.02186325 6.00768949]\n",
      "##########\n",
      "epoch:28 step:134805[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:28 step:134810[D loss: 0.999978] [G loss: 0.999980]\n",
      "epoch:28 step:134815[D loss: 1.000029] [G loss: 0.999981]\n",
      "epoch:28 step:134820[D loss: 0.999897] [G loss: 1.000104]\n",
      "epoch:28 step:134825[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:28 step:134830[D loss: 0.999947] [G loss: 1.000198]\n",
      "epoch:28 step:134835[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:28 step:134840[D loss: 0.999943] [G loss: 1.000114]\n",
      "epoch:28 step:134845[D loss: 1.000017] [G loss: 1.000020]\n",
      "epoch:28 step:134850[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:28 step:134855[D loss: 0.999938] [G loss: 1.000066]\n",
      "epoch:28 step:134860[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:28 step:134865[D loss: 1.000019] [G loss: 1.000058]\n",
      "epoch:28 step:134870[D loss: 0.999972] [G loss: 1.000031]\n",
      "epoch:28 step:134875[D loss: 0.999947] [G loss: 1.000228]\n",
      "epoch:28 step:134880[D loss: 0.999960] [G loss: 1.000099]\n",
      "epoch:28 step:134885[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:28 step:134890[D loss: 1.000209] [G loss: 0.999847]\n",
      "epoch:28 step:134895[D loss: 0.999854] [G loss: 1.000043]\n",
      "epoch:28 step:134900[D loss: 0.999961] [G loss: 1.000037]\n",
      "epoch:28 step:134905[D loss: 0.999943] [G loss: 1.000063]\n",
      "epoch:28 step:134910[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:28 step:134915[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:28 step:134920[D loss: 1.000082] [G loss: 0.999861]\n",
      "epoch:28 step:134925[D loss: 0.999923] [G loss: 1.000104]\n",
      "epoch:28 step:134930[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:28 step:134935[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:28 step:134940[D loss: 0.999977] [G loss: 1.000018]\n",
      "epoch:28 step:134945[D loss: 0.999982] [G loss: 1.000009]\n",
      "epoch:28 step:134950[D loss: 1.000003] [G loss: 1.000095]\n",
      "epoch:28 step:134955[D loss: 1.000026] [G loss: 1.000032]\n",
      "epoch:28 step:134960[D loss: 0.999999] [G loss: 0.999991]\n",
      "epoch:28 step:134965[D loss: 1.000035] [G loss: 1.000003]\n",
      "epoch:28 step:134970[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:28 step:134975[D loss: 0.999928] [G loss: 1.000055]\n",
      "epoch:28 step:134980[D loss: 0.999921] [G loss: 1.000131]\n",
      "epoch:28 step:134985[D loss: 1.000064] [G loss: 1.000035]\n",
      "epoch:28 step:134990[D loss: 1.000027] [G loss: 1.000169]\n",
      "epoch:28 step:134995[D loss: 0.999895] [G loss: 1.000169]\n",
      "epoch:28 step:135000[D loss: 0.999989] [G loss: 1.000113]\n",
      "##############\n",
      "[2.58127728 2.11662639 2.0867611  3.61982399 1.52802037 7.36395433\n",
      " 2.33428812 3.69929807 3.95696563 4.61040536]\n",
      "##########\n",
      "epoch:28 step:135005[D loss: 0.999932] [G loss: 1.000109]\n",
      "epoch:28 step:135010[D loss: 0.999949] [G loss: 1.000067]\n",
      "epoch:28 step:135015[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:28 step:135020[D loss: 0.999991] [G loss: 0.999995]\n",
      "epoch:28 step:135025[D loss: 0.999926] [G loss: 1.000086]\n",
      "epoch:28 step:135030[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:28 step:135035[D loss: 1.000031] [G loss: 0.999961]\n",
      "epoch:28 step:135040[D loss: 1.000083] [G loss: 0.999860]\n",
      "epoch:28 step:135045[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:28 step:135050[D loss: 1.000075] [G loss: 0.999996]\n",
      "epoch:28 step:135055[D loss: 0.999896] [G loss: 1.000079]\n",
      "epoch:28 step:135060[D loss: 1.000010] [G loss: 1.000092]\n",
      "epoch:28 step:135065[D loss: 0.999904] [G loss: 1.000098]\n",
      "epoch:28 step:135070[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:28 step:135075[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:28 step:135080[D loss: 0.999957] [G loss: 0.999953]\n",
      "epoch:28 step:135085[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:28 step:135090[D loss: 0.999998] [G loss: 1.000009]\n",
      "epoch:28 step:135095[D loss: 1.000003] [G loss: 1.000054]\n",
      "epoch:28 step:135100[D loss: 0.999914] [G loss: 1.000171]\n",
      "epoch:28 step:135105[D loss: 0.999964] [G loss: 1.000112]\n",
      "epoch:28 step:135110[D loss: 1.000012] [G loss: 1.000045]\n",
      "epoch:28 step:135115[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:28 step:135120[D loss: 1.000029] [G loss: 1.000035]\n",
      "epoch:28 step:135125[D loss: 0.999923] [G loss: 1.000277]\n",
      "epoch:28 step:135130[D loss: 0.999969] [G loss: 1.000027]\n",
      "epoch:28 step:135135[D loss: 0.999970] [G loss: 0.999990]\n",
      "epoch:28 step:135140[D loss: 1.000001] [G loss: 0.999912]\n",
      "epoch:28 step:135145[D loss: 0.999952] [G loss: 1.000052]\n",
      "epoch:28 step:135150[D loss: 0.999957] [G loss: 1.000066]\n",
      "epoch:28 step:135155[D loss: 1.000012] [G loss: 1.000015]\n",
      "epoch:28 step:135160[D loss: 0.999944] [G loss: 1.000083]\n",
      "epoch:28 step:135165[D loss: 0.999963] [G loss: 1.000030]\n",
      "epoch:28 step:135170[D loss: 1.000003] [G loss: 1.000117]\n",
      "epoch:28 step:135175[D loss: 1.000033] [G loss: 0.999896]\n",
      "epoch:28 step:135180[D loss: 0.999912] [G loss: 1.000148]\n",
      "epoch:28 step:135185[D loss: 0.999923] [G loss: 1.000119]\n",
      "epoch:28 step:135190[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:28 step:135195[D loss: 0.999979] [G loss: 1.000105]\n",
      "epoch:28 step:135200[D loss: 0.999957] [G loss: 1.000004]\n",
      "##############\n",
      "[2.56730907 2.21452868 2.15563796 3.94899877 1.53163737 6.57335679\n",
      " 2.2941554  3.79195688 3.98668945 4.92544009]\n",
      "##########\n",
      "epoch:28 step:135205[D loss: 1.000015] [G loss: 0.999987]\n",
      "epoch:28 step:135210[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:28 step:135215[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:28 step:135220[D loss: 1.000195] [G loss: 0.999858]\n",
      "epoch:28 step:135225[D loss: 0.999947] [G loss: 1.000033]\n",
      "epoch:28 step:135230[D loss: 0.999950] [G loss: 1.000100]\n",
      "epoch:28 step:135235[D loss: 0.999936] [G loss: 1.000138]\n",
      "epoch:28 step:135240[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:28 step:135245[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:28 step:135250[D loss: 0.999987] [G loss: 1.000027]\n",
      "epoch:28 step:135255[D loss: 0.999959] [G loss: 1.000044]\n",
      "epoch:28 step:135260[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:28 step:135265[D loss: 0.999954] [G loss: 1.000094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:135270[D loss: 1.000054] [G loss: 1.000004]\n",
      "epoch:28 step:135275[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:28 step:135280[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:28 step:135285[D loss: 1.000041] [G loss: 0.999939]\n",
      "epoch:28 step:135290[D loss: 1.000007] [G loss: 0.999968]\n",
      "epoch:28 step:135295[D loss: 0.999985] [G loss: 0.999979]\n",
      "epoch:28 step:135300[D loss: 0.999930] [G loss: 1.000100]\n",
      "epoch:28 step:135305[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:28 step:135310[D loss: 0.999973] [G loss: 1.000022]\n",
      "epoch:28 step:135315[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:28 step:135320[D loss: 0.999951] [G loss: 1.000062]\n",
      "epoch:28 step:135325[D loss: 0.999952] [G loss: 1.000048]\n",
      "epoch:28 step:135330[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:28 step:135335[D loss: 0.999982] [G loss: 1.000104]\n",
      "epoch:28 step:135340[D loss: 1.000007] [G loss: 1.000085]\n",
      "epoch:28 step:135345[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:28 step:135350[D loss: 1.000033] [G loss: 1.000056]\n",
      "epoch:28 step:135355[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:28 step:135360[D loss: 1.000010] [G loss: 1.000048]\n",
      "epoch:28 step:135365[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:28 step:135370[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:28 step:135375[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:28 step:135380[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:28 step:135385[D loss: 0.999988] [G loss: 1.000069]\n",
      "epoch:28 step:135390[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:28 step:135395[D loss: 1.000008] [G loss: 1.000011]\n",
      "epoch:28 step:135400[D loss: 0.999978] [G loss: 1.000201]\n",
      "##############\n",
      "[2.51661569 2.21346961 2.03461319 3.85938625 1.48312682 6.83476097\n",
      " 2.3912717  3.66453912 3.97634492 5.17026259]\n",
      "##########\n",
      "epoch:28 step:135405[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:28 step:135410[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:28 step:135415[D loss: 0.999939] [G loss: 1.000099]\n",
      "epoch:28 step:135420[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:28 step:135425[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:28 step:135430[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:28 step:135435[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:28 step:135440[D loss: 1.000001] [G loss: 1.000017]\n",
      "epoch:28 step:135445[D loss: 1.000034] [G loss: 1.000036]\n",
      "epoch:28 step:135450[D loss: 0.999978] [G loss: 0.999989]\n",
      "epoch:28 step:135455[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:28 step:135460[D loss: 1.000033] [G loss: 1.000038]\n",
      "epoch:28 step:135465[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:28 step:135470[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:28 step:135475[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:28 step:135480[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:28 step:135485[D loss: 0.999942] [G loss: 1.000110]\n",
      "epoch:28 step:135490[D loss: 1.000027] [G loss: 0.999924]\n",
      "epoch:28 step:135495[D loss: 0.999955] [G loss: 1.000089]\n",
      "epoch:28 step:135500[D loss: 1.000005] [G loss: 1.000159]\n",
      "epoch:28 step:135505[D loss: 0.999943] [G loss: 1.000131]\n",
      "epoch:28 step:135510[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:28 step:135515[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:28 step:135520[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:28 step:135525[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:28 step:135530[D loss: 0.999994] [G loss: 1.000074]\n",
      "epoch:28 step:135535[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:28 step:135540[D loss: 1.000024] [G loss: 0.999970]\n",
      "epoch:28 step:135545[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:28 step:135550[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:28 step:135555[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:28 step:135560[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:28 step:135565[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:28 step:135570[D loss: 0.999993] [G loss: 0.999982]\n",
      "epoch:28 step:135575[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:28 step:135580[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:28 step:135585[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:28 step:135590[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:28 step:135595[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:28 step:135600[D loss: 0.999997] [G loss: 1.000062]\n",
      "##############\n",
      "[2.53837468 2.23889349 2.14231558 3.31508615 1.59470151 7.01937339\n",
      " 2.21008567 3.61525206 3.98523308 5.01342684]\n",
      "##########\n",
      "epoch:28 step:135605[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:28 step:135610[D loss: 0.999964] [G loss: 1.000107]\n",
      "epoch:28 step:135615[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:28 step:135620[D loss: 0.999998] [G loss: 1.000011]\n",
      "epoch:28 step:135625[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:28 step:135630[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:28 step:135635[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:28 step:135640[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:28 step:135645[D loss: 0.999986] [G loss: 1.000125]\n",
      "epoch:28 step:135650[D loss: 1.000000] [G loss: 1.000084]\n",
      "epoch:28 step:135655[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:28 step:135660[D loss: 1.000054] [G loss: 0.999971]\n",
      "epoch:28 step:135665[D loss: 0.999915] [G loss: 1.000143]\n",
      "epoch:28 step:135670[D loss: 0.999919] [G loss: 1.000114]\n",
      "epoch:28 step:135675[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:28 step:135680[D loss: 1.000002] [G loss: 1.000010]\n",
      "epoch:28 step:135685[D loss: 1.000011] [G loss: 1.000033]\n",
      "epoch:28 step:135690[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:28 step:135695[D loss: 0.999968] [G loss: 1.000034]\n",
      "epoch:28 step:135700[D loss: 1.000087] [G loss: 1.000013]\n",
      "epoch:28 step:135705[D loss: 1.000040] [G loss: 1.000012]\n",
      "epoch:28 step:135710[D loss: 1.000029] [G loss: 1.000060]\n",
      "epoch:28 step:135715[D loss: 0.999873] [G loss: 1.000138]\n",
      "epoch:28 step:135720[D loss: 1.000050] [G loss: 0.999940]\n",
      "epoch:28 step:135725[D loss: 1.000068] [G loss: 0.999939]\n",
      "epoch:28 step:135730[D loss: 0.999944] [G loss: 1.000035]\n",
      "epoch:28 step:135735[D loss: 0.999906] [G loss: 1.000011]\n",
      "epoch:28 step:135740[D loss: 0.999922] [G loss: 1.000031]\n",
      "epoch:28 step:135745[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:28 step:135750[D loss: 1.000000] [G loss: 1.000146]\n",
      "epoch:28 step:135755[D loss: 0.999936] [G loss: 1.000170]\n",
      "epoch:28 step:135760[D loss: 0.999919] [G loss: 1.000120]\n",
      "epoch:28 step:135765[D loss: 1.000107] [G loss: 0.999943]\n",
      "epoch:28 step:135770[D loss: 0.999923] [G loss: 1.000092]\n",
      "epoch:28 step:135775[D loss: 1.000008] [G loss: 0.999988]\n",
      "epoch:28 step:135780[D loss: 1.000009] [G loss: 0.999957]\n",
      "epoch:28 step:135785[D loss: 1.000102] [G loss: 0.999799]\n",
      "epoch:28 step:135790[D loss: 1.000021] [G loss: 0.999896]\n",
      "epoch:28 step:135795[D loss: 0.999917] [G loss: 1.000102]\n",
      "epoch:28 step:135800[D loss: 0.999976] [G loss: 1.000043]\n",
      "##############\n",
      "[2.62306403 2.25100346 2.25974537 3.75239043 1.56392011 8.35363896\n",
      " 2.33725063 3.87377637 4.05737498 6.09544768]\n",
      "##########\n",
      "epoch:28 step:135805[D loss: 0.999946] [G loss: 1.000105]\n",
      "epoch:28 step:135810[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:28 step:135815[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:28 step:135820[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:28 step:135825[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:28 step:135830[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:28 step:135835[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:28 step:135840[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:28 step:135845[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:28 step:135850[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:28 step:135855[D loss: 1.000144] [G loss: 0.999929]\n",
      "epoch:28 step:135860[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:28 step:135865[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:29 step:135870[D loss: 1.000060] [G loss: 1.000034]\n",
      "epoch:29 step:135875[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:29 step:135880[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:29 step:135885[D loss: 0.999946] [G loss: 1.000097]\n",
      "epoch:29 step:135890[D loss: 1.000046] [G loss: 1.000029]\n",
      "epoch:29 step:135895[D loss: 0.999953] [G loss: 1.000150]\n",
      "epoch:29 step:135900[D loss: 0.999936] [G loss: 1.000083]\n",
      "epoch:29 step:135905[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:29 step:135910[D loss: 1.000006] [G loss: 1.000052]\n",
      "epoch:29 step:135915[D loss: 1.000082] [G loss: 0.999985]\n",
      "epoch:29 step:135920[D loss: 1.000083] [G loss: 0.999870]\n",
      "epoch:29 step:135925[D loss: 0.999977] [G loss: 0.999962]\n",
      "epoch:29 step:135930[D loss: 0.999956] [G loss: 1.000044]\n",
      "epoch:29 step:135935[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:29 step:135940[D loss: 1.000021] [G loss: 1.000039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:135945[D loss: 0.999965] [G loss: 1.000114]\n",
      "epoch:29 step:135950[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:29 step:135955[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:29 step:135960[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:29 step:135965[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:29 step:135970[D loss: 0.999998] [G loss: 1.000051]\n",
      "epoch:29 step:135975[D loss: 1.000060] [G loss: 1.000006]\n",
      "epoch:29 step:135980[D loss: 0.999931] [G loss: 1.000104]\n",
      "epoch:29 step:135985[D loss: 1.000031] [G loss: 0.999985]\n",
      "epoch:29 step:135990[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:29 step:135995[D loss: 1.000034] [G loss: 1.000021]\n",
      "epoch:29 step:136000[D loss: 1.000015] [G loss: 1.000108]\n",
      "##############\n",
      "[2.66460088 2.18778211 2.12538821 3.63739322 1.54981299 9.27329063\n",
      " 2.49478659 3.9186453  4.02229973 5.13469338]\n",
      "##########\n",
      "epoch:29 step:136005[D loss: 0.999992] [G loss: 1.000012]\n",
      "epoch:29 step:136010[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:29 step:136015[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:29 step:136020[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:29 step:136025[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:29 step:136030[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:29 step:136035[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:29 step:136040[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:29 step:136045[D loss: 1.000020] [G loss: 1.000030]\n",
      "epoch:29 step:136050[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:29 step:136055[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:29 step:136060[D loss: 0.999998] [G loss: 1.000077]\n",
      "epoch:29 step:136065[D loss: 1.000110] [G loss: 0.999976]\n",
      "epoch:29 step:136070[D loss: 1.000007] [G loss: 1.000039]\n",
      "epoch:29 step:136075[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:29 step:136080[D loss: 0.999994] [G loss: 1.000102]\n",
      "epoch:29 step:136085[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:29 step:136090[D loss: 0.999938] [G loss: 1.000155]\n",
      "epoch:29 step:136095[D loss: 0.999927] [G loss: 1.000149]\n",
      "epoch:29 step:136100[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:29 step:136105[D loss: 0.999974] [G loss: 1.000101]\n",
      "epoch:29 step:136110[D loss: 0.999950] [G loss: 1.000101]\n",
      "epoch:29 step:136115[D loss: 0.999948] [G loss: 1.000158]\n",
      "epoch:29 step:136120[D loss: 0.999970] [G loss: 1.000116]\n",
      "epoch:29 step:136125[D loss: 0.999968] [G loss: 1.000111]\n",
      "epoch:29 step:136130[D loss: 1.000037] [G loss: 0.999993]\n",
      "epoch:29 step:136135[D loss: 0.999998] [G loss: 1.000144]\n",
      "epoch:29 step:136140[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:29 step:136145[D loss: 1.000017] [G loss: 1.000010]\n",
      "epoch:29 step:136150[D loss: 0.999988] [G loss: 1.000122]\n",
      "epoch:29 step:136155[D loss: 0.999999] [G loss: 1.000097]\n",
      "epoch:29 step:136160[D loss: 0.999979] [G loss: 1.000162]\n",
      "epoch:29 step:136165[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:29 step:136170[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:29 step:136175[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:29 step:136180[D loss: 0.999980] [G loss: 1.000109]\n",
      "epoch:29 step:136185[D loss: 1.000016] [G loss: 1.000002]\n",
      "epoch:29 step:136190[D loss: 0.999940] [G loss: 1.000130]\n",
      "epoch:29 step:136195[D loss: 1.000054] [G loss: 0.999892]\n",
      "epoch:29 step:136200[D loss: 0.999934] [G loss: 1.000039]\n",
      "##############\n",
      "[2.47064934 2.14601702 2.12897218 3.68756941 1.46015666 6.91981196\n",
      " 2.27078589 3.66175878 3.88883224 5.75100923]\n",
      "##########\n",
      "epoch:29 step:136205[D loss: 0.999991] [G loss: 1.000017]\n",
      "epoch:29 step:136210[D loss: 0.999983] [G loss: 1.000155]\n",
      "epoch:29 step:136215[D loss: 0.999885] [G loss: 1.000260]\n",
      "epoch:29 step:136220[D loss: 0.999966] [G loss: 1.000114]\n",
      "epoch:29 step:136225[D loss: 1.000009] [G loss: 1.000060]\n",
      "epoch:29 step:136230[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:29 step:136235[D loss: 0.999919] [G loss: 1.000061]\n",
      "epoch:29 step:136240[D loss: 1.000008] [G loss: 0.999979]\n",
      "epoch:29 step:136245[D loss: 0.999985] [G loss: 0.999935]\n",
      "epoch:29 step:136250[D loss: 1.000058] [G loss: 0.999920]\n",
      "epoch:29 step:136255[D loss: 0.999935] [G loss: 1.000150]\n",
      "epoch:29 step:136260[D loss: 0.999936] [G loss: 1.000100]\n",
      "epoch:29 step:136265[D loss: 1.000007] [G loss: 1.000019]\n",
      "epoch:29 step:136270[D loss: 1.000054] [G loss: 0.999968]\n",
      "epoch:29 step:136275[D loss: 1.000023] [G loss: 0.999949]\n",
      "epoch:29 step:136280[D loss: 0.999908] [G loss: 1.000147]\n",
      "epoch:29 step:136285[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:29 step:136290[D loss: 1.000001] [G loss: 1.000010]\n",
      "epoch:29 step:136295[D loss: 0.999984] [G loss: 0.999995]\n",
      "epoch:29 step:136300[D loss: 1.000048] [G loss: 0.999971]\n",
      "epoch:29 step:136305[D loss: 1.000100] [G loss: 0.999787]\n",
      "epoch:29 step:136310[D loss: 0.999935] [G loss: 1.000263]\n",
      "epoch:29 step:136315[D loss: 0.999936] [G loss: 1.000111]\n",
      "epoch:29 step:136320[D loss: 0.999905] [G loss: 1.000108]\n",
      "epoch:29 step:136325[D loss: 0.999927] [G loss: 1.000135]\n",
      "epoch:29 step:136330[D loss: 0.999945] [G loss: 1.000065]\n",
      "epoch:29 step:136335[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:29 step:136340[D loss: 1.000100] [G loss: 0.999859]\n",
      "epoch:29 step:136345[D loss: 0.999891] [G loss: 1.000139]\n",
      "epoch:29 step:136350[D loss: 1.000131] [G loss: 0.999884]\n",
      "epoch:29 step:136355[D loss: 1.000053] [G loss: 0.999990]\n",
      "epoch:29 step:136360[D loss: 0.999937] [G loss: 1.000122]\n",
      "epoch:29 step:136365[D loss: 0.999880] [G loss: 1.000219]\n",
      "epoch:29 step:136370[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:29 step:136375[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:29 step:136380[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:29 step:136385[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:29 step:136390[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:29 step:136395[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:29 step:136400[D loss: 1.000010] [G loss: 0.999986]\n",
      "##############\n",
      "[2.60402524 2.19944725 2.26899685 3.79975564 1.5831192  7.09760284\n",
      " 2.43431425 3.83534972 3.95613703 5.49675788]\n",
      "##########\n",
      "epoch:29 step:136405[D loss: 0.999956] [G loss: 1.000103]\n",
      "epoch:29 step:136410[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:29 step:136415[D loss: 0.999988] [G loss: 1.000105]\n",
      "epoch:29 step:136420[D loss: 0.999907] [G loss: 1.000148]\n",
      "epoch:29 step:136425[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:29 step:136430[D loss: 0.999964] [G loss: 1.000143]\n",
      "epoch:29 step:136435[D loss: 0.999935] [G loss: 1.000143]\n",
      "epoch:29 step:136440[D loss: 1.000162] [G loss: 0.999901]\n",
      "epoch:29 step:136445[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:29 step:136450[D loss: 1.000014] [G loss: 0.999968]\n",
      "epoch:29 step:136455[D loss: 1.000091] [G loss: 0.999948]\n",
      "epoch:29 step:136460[D loss: 1.000041] [G loss: 0.999989]\n",
      "epoch:29 step:136465[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:29 step:136470[D loss: 0.999986] [G loss: 1.000101]\n",
      "epoch:29 step:136475[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:29 step:136480[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:29 step:136485[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:29 step:136490[D loss: 0.999968] [G loss: 1.000008]\n",
      "epoch:29 step:136495[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:29 step:136500[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:29 step:136505[D loss: 1.000001] [G loss: 1.000066]\n",
      "epoch:29 step:136510[D loss: 1.000050] [G loss: 1.000039]\n",
      "epoch:29 step:136515[D loss: 0.999938] [G loss: 1.000066]\n",
      "epoch:29 step:136520[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:29 step:136525[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:29 step:136530[D loss: 1.000025] [G loss: 1.000030]\n",
      "epoch:29 step:136535[D loss: 0.999953] [G loss: 1.000125]\n",
      "epoch:29 step:136540[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:29 step:136545[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:29 step:136550[D loss: 0.999988] [G loss: 1.000002]\n",
      "epoch:29 step:136555[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:29 step:136560[D loss: 0.999933] [G loss: 1.000116]\n",
      "epoch:29 step:136565[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:29 step:136570[D loss: 1.000018] [G loss: 1.000024]\n",
      "epoch:29 step:136575[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:29 step:136580[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:29 step:136585[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:29 step:136590[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:29 step:136595[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:29 step:136600[D loss: 0.999889] [G loss: 1.000223]\n",
      "##############\n",
      "[2.5411516  2.16854411 2.07969054 3.56390837 1.49562205 7.16581058\n",
      " 2.28901725 3.71882328 3.97011365 4.89983094]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:136605[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:29 step:136610[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:29 step:136615[D loss: 0.999957] [G loss: 1.000056]\n",
      "epoch:29 step:136620[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:29 step:136625[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:29 step:136630[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:29 step:136635[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:29 step:136640[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:29 step:136645[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:29 step:136650[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:29 step:136655[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:29 step:136660[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:29 step:136665[D loss: 0.999997] [G loss: 1.000013]\n",
      "epoch:29 step:136670[D loss: 1.000056] [G loss: 0.999980]\n",
      "epoch:29 step:136675[D loss: 1.000072] [G loss: 0.999931]\n",
      "epoch:29 step:136680[D loss: 0.999952] [G loss: 1.000069]\n",
      "epoch:29 step:136685[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:29 step:136690[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:29 step:136695[D loss: 1.000003] [G loss: 0.999999]\n",
      "epoch:29 step:136700[D loss: 0.999935] [G loss: 1.000077]\n",
      "epoch:29 step:136705[D loss: 0.999944] [G loss: 1.000100]\n",
      "epoch:29 step:136710[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:29 step:136715[D loss: 0.999989] [G loss: 1.000031]\n",
      "epoch:29 step:136720[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:29 step:136725[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:29 step:136730[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:29 step:136735[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:29 step:136740[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:29 step:136745[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:29 step:136750[D loss: 1.000009] [G loss: 0.999998]\n",
      "epoch:29 step:136755[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:29 step:136760[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:29 step:136765[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:29 step:136770[D loss: 1.000006] [G loss: 1.000049]\n",
      "epoch:29 step:136775[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:29 step:136780[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:29 step:136785[D loss: 1.000029] [G loss: 0.999965]\n",
      "epoch:29 step:136790[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:29 step:136795[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:29 step:136800[D loss: 0.999991] [G loss: 1.000040]\n",
      "##############\n",
      "[2.59531298 2.17439812 2.13181502 3.68108487 1.57187833 7.13994438\n",
      " 2.61910664 3.73728799 3.97608209 5.01280637]\n",
      "##########\n",
      "epoch:29 step:136805[D loss: 1.000017] [G loss: 1.000022]\n",
      "epoch:29 step:136810[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:29 step:136815[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:29 step:136820[D loss: 0.999992] [G loss: 1.000085]\n",
      "epoch:29 step:136825[D loss: 1.000004] [G loss: 1.000019]\n",
      "epoch:29 step:136830[D loss: 1.000045] [G loss: 1.000109]\n",
      "epoch:29 step:136835[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:29 step:136840[D loss: 1.000006] [G loss: 0.999982]\n",
      "epoch:29 step:136845[D loss: 1.000120] [G loss: 0.999803]\n",
      "epoch:29 step:136850[D loss: 1.000066] [G loss: 0.999864]\n",
      "epoch:29 step:136855[D loss: 1.000195] [G loss: 0.999844]\n",
      "epoch:29 step:136860[D loss: 0.999868] [G loss: 1.000198]\n",
      "epoch:29 step:136865[D loss: 1.000038] [G loss: 1.000245]\n",
      "epoch:29 step:136870[D loss: 0.999956] [G loss: 1.000197]\n",
      "epoch:29 step:136875[D loss: 0.999908] [G loss: 1.000188]\n",
      "epoch:29 step:136880[D loss: 1.000002] [G loss: 1.000118]\n",
      "epoch:29 step:136885[D loss: 0.999962] [G loss: 1.000030]\n",
      "epoch:29 step:136890[D loss: 0.999975] [G loss: 1.000034]\n",
      "epoch:29 step:136895[D loss: 1.000005] [G loss: 0.999977]\n",
      "epoch:29 step:136900[D loss: 0.999965] [G loss: 1.000032]\n",
      "epoch:29 step:136905[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:29 step:136910[D loss: 1.000007] [G loss: 0.999975]\n",
      "epoch:29 step:136915[D loss: 1.000027] [G loss: 0.999920]\n",
      "epoch:29 step:136920[D loss: 1.000062] [G loss: 1.000005]\n",
      "epoch:29 step:136925[D loss: 1.000015] [G loss: 1.000002]\n",
      "epoch:29 step:136930[D loss: 1.000001] [G loss: 0.999965]\n",
      "epoch:29 step:136935[D loss: 0.999885] [G loss: 1.000239]\n",
      "epoch:29 step:136940[D loss: 1.000010] [G loss: 1.000111]\n",
      "epoch:29 step:136945[D loss: 1.000090] [G loss: 0.999939]\n",
      "epoch:29 step:136950[D loss: 1.000022] [G loss: 1.000302]\n",
      "epoch:29 step:136955[D loss: 0.999826] [G loss: 1.000327]\n",
      "epoch:29 step:136960[D loss: 0.999866] [G loss: 1.000219]\n",
      "epoch:29 step:136965[D loss: 0.999953] [G loss: 1.000188]\n",
      "epoch:29 step:136970[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:29 step:136975[D loss: 1.000015] [G loss: 1.000024]\n",
      "epoch:29 step:136980[D loss: 0.999975] [G loss: 1.000136]\n",
      "epoch:29 step:136985[D loss: 0.999961] [G loss: 1.000038]\n",
      "epoch:29 step:136990[D loss: 1.000077] [G loss: 0.999893]\n",
      "epoch:29 step:136995[D loss: 1.000105] [G loss: 1.000046]\n",
      "epoch:29 step:137000[D loss: 1.000252] [G loss: 0.999841]\n",
      "##############\n",
      "[2.50787407 2.25602939 2.14333848 3.78352918 1.57282164 7.72151576\n",
      " 2.38583719 3.78254797 4.02532315 7.14868929]\n",
      "##########\n",
      "epoch:29 step:137005[D loss: 1.000020] [G loss: 0.999850]\n",
      "epoch:29 step:137010[D loss: 0.999905] [G loss: 1.000116]\n",
      "epoch:29 step:137015[D loss: 1.000062] [G loss: 1.000125]\n",
      "epoch:29 step:137020[D loss: 1.000053] [G loss: 1.000107]\n",
      "epoch:29 step:137025[D loss: 0.999857] [G loss: 1.000290]\n",
      "epoch:29 step:137030[D loss: 1.000035] [G loss: 1.000193]\n",
      "epoch:29 step:137035[D loss: 0.999986] [G loss: 1.000322]\n",
      "epoch:29 step:137040[D loss: 0.999993] [G loss: 1.000151]\n",
      "epoch:29 step:137045[D loss: 0.999928] [G loss: 1.000232]\n",
      "epoch:29 step:137050[D loss: 1.000017] [G loss: 1.000097]\n",
      "epoch:29 step:137055[D loss: 0.999951] [G loss: 1.000019]\n",
      "epoch:29 step:137060[D loss: 1.000056] [G loss: 0.999891]\n",
      "epoch:29 step:137065[D loss: 1.000061] [G loss: 0.999905]\n",
      "epoch:29 step:137070[D loss: 1.000137] [G loss: 0.999778]\n",
      "epoch:29 step:137075[D loss: 0.999974] [G loss: 1.000003]\n",
      "epoch:29 step:137080[D loss: 0.999978] [G loss: 0.999789]\n",
      "epoch:29 step:137085[D loss: 1.000151] [G loss: 0.999809]\n",
      "epoch:29 step:137090[D loss: 0.999942] [G loss: 1.000056]\n",
      "epoch:29 step:137095[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:29 step:137100[D loss: 0.999928] [G loss: 1.000043]\n",
      "epoch:29 step:137105[D loss: 1.000010] [G loss: 1.000130]\n",
      "epoch:29 step:137110[D loss: 0.999979] [G loss: 1.000149]\n",
      "epoch:29 step:137115[D loss: 0.999948] [G loss: 1.000106]\n",
      "epoch:29 step:137120[D loss: 0.999941] [G loss: 1.000073]\n",
      "epoch:29 step:137125[D loss: 1.000015] [G loss: 1.000055]\n",
      "epoch:29 step:137130[D loss: 1.000034] [G loss: 1.000095]\n",
      "epoch:29 step:137135[D loss: 0.999995] [G loss: 1.000019]\n",
      "epoch:29 step:137140[D loss: 1.000023] [G loss: 1.000035]\n",
      "epoch:29 step:137145[D loss: 0.999925] [G loss: 1.000096]\n",
      "epoch:29 step:137150[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:29 step:137155[D loss: 1.000039] [G loss: 1.000052]\n",
      "epoch:29 step:137160[D loss: 0.999840] [G loss: 1.000203]\n",
      "epoch:29 step:137165[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:29 step:137170[D loss: 0.999951] [G loss: 1.000107]\n",
      "epoch:29 step:137175[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:29 step:137180[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:29 step:137185[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:29 step:137190[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:29 step:137195[D loss: 0.999998] [G loss: 1.000034]\n",
      "epoch:29 step:137200[D loss: 0.999940] [G loss: 1.000115]\n",
      "##############\n",
      "[2.5444994  2.20566951 2.21599626 3.8114349  1.52291026 7.30410146\n",
      " 2.55353935 3.83421989 4.00433637 5.40189893]\n",
      "##########\n",
      "epoch:29 step:137205[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:29 step:137210[D loss: 0.999955] [G loss: 1.000098]\n",
      "epoch:29 step:137215[D loss: 0.999975] [G loss: 1.000024]\n",
      "epoch:29 step:137220[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:29 step:137225[D loss: 1.000018] [G loss: 0.999975]\n",
      "epoch:29 step:137230[D loss: 1.000021] [G loss: 1.000055]\n",
      "epoch:29 step:137235[D loss: 0.999937] [G loss: 1.000148]\n",
      "epoch:29 step:137240[D loss: 0.999942] [G loss: 1.000082]\n",
      "epoch:29 step:137245[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:29 step:137250[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:29 step:137255[D loss: 1.000009] [G loss: 1.000053]\n",
      "epoch:29 step:137260[D loss: 0.999952] [G loss: 1.000110]\n",
      "epoch:29 step:137265[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:29 step:137270[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:29 step:137275[D loss: 0.999960] [G loss: 1.000140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:137280[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:29 step:137285[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:29 step:137290[D loss: 1.000001] [G loss: 1.000002]\n",
      "epoch:29 step:137295[D loss: 0.999972] [G loss: 1.000105]\n",
      "epoch:29 step:137300[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:29 step:137305[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:29 step:137310[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:29 step:137315[D loss: 0.999949] [G loss: 1.000103]\n",
      "epoch:29 step:137320[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:29 step:137325[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:29 step:137330[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:29 step:137335[D loss: 0.999906] [G loss: 1.000106]\n",
      "epoch:29 step:137340[D loss: 1.000023] [G loss: 1.000011]\n",
      "epoch:29 step:137345[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:29 step:137350[D loss: 1.000015] [G loss: 0.999957]\n",
      "epoch:29 step:137355[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:29 step:137360[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:29 step:137365[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:29 step:137370[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:29 step:137375[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:29 step:137380[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:29 step:137385[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:29 step:137390[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:29 step:137395[D loss: 0.999999] [G loss: 1.000072]\n",
      "epoch:29 step:137400[D loss: 0.999970] [G loss: 1.000037]\n",
      "##############\n",
      "[2.62614798 2.2252187  2.17866104 3.74675062 1.58697221 7.71499199\n",
      " 2.36408667 3.74957206 4.05934544 4.63017614]\n",
      "##########\n",
      "epoch:29 step:137405[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:29 step:137410[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:29 step:137415[D loss: 1.000071] [G loss: 1.000006]\n",
      "epoch:29 step:137420[D loss: 1.000072] [G loss: 0.999993]\n",
      "epoch:29 step:137425[D loss: 0.999919] [G loss: 1.000129]\n",
      "epoch:29 step:137430[D loss: 0.999957] [G loss: 1.000100]\n",
      "epoch:29 step:137435[D loss: 0.999931] [G loss: 1.000112]\n",
      "epoch:29 step:137440[D loss: 0.999993] [G loss: 1.000112]\n",
      "epoch:29 step:137445[D loss: 0.999996] [G loss: 1.000098]\n",
      "epoch:29 step:137450[D loss: 1.000002] [G loss: 0.999986]\n",
      "epoch:29 step:137455[D loss: 1.000037] [G loss: 0.999892]\n",
      "epoch:29 step:137460[D loss: 1.000044] [G loss: 0.999981]\n",
      "epoch:29 step:137465[D loss: 1.000053] [G loss: 0.999909]\n",
      "epoch:29 step:137470[D loss: 1.000099] [G loss: 0.999893]\n",
      "epoch:29 step:137475[D loss: 1.000185] [G loss: 0.999732]\n",
      "epoch:29 step:137480[D loss: 1.000113] [G loss: 0.999940]\n",
      "epoch:29 step:137485[D loss: 0.999941] [G loss: 0.999885]\n",
      "epoch:29 step:137490[D loss: 0.999836] [G loss: 1.000134]\n",
      "epoch:29 step:137495[D loss: 0.999912] [G loss: 1.000075]\n",
      "epoch:29 step:137500[D loss: 1.000030] [G loss: 0.999938]\n",
      "epoch:29 step:137505[D loss: 0.999940] [G loss: 0.999984]\n",
      "epoch:29 step:137510[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:29 step:137515[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:29 step:137520[D loss: 0.999941] [G loss: 1.000062]\n",
      "epoch:29 step:137525[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:29 step:137530[D loss: 1.000013] [G loss: 1.000038]\n",
      "epoch:29 step:137535[D loss: 0.999945] [G loss: 1.000053]\n",
      "epoch:29 step:137540[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:29 step:137545[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:29 step:137550[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:29 step:137555[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:29 step:137560[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:29 step:137565[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:29 step:137570[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:29 step:137575[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:29 step:137580[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:29 step:137585[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:29 step:137590[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:29 step:137595[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:29 step:137600[D loss: 0.999980] [G loss: 1.000050]\n",
      "##############\n",
      "[2.60011129 2.21085378 2.16958756 3.86061347 1.57227996 7.52222099\n",
      " 2.31692708 3.83511298 4.0333377  4.88915588]\n",
      "##########\n",
      "epoch:29 step:137605[D loss: 0.999995] [G loss: 1.000073]\n",
      "epoch:29 step:137610[D loss: 1.000064] [G loss: 0.999980]\n",
      "epoch:29 step:137615[D loss: 0.999977] [G loss: 0.999993]\n",
      "epoch:29 step:137620[D loss: 1.000111] [G loss: 0.999947]\n",
      "epoch:29 step:137625[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:29 step:137630[D loss: 0.999935] [G loss: 1.000122]\n",
      "epoch:29 step:137635[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:29 step:137640[D loss: 0.999935] [G loss: 1.000098]\n",
      "epoch:29 step:137645[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:29 step:137650[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:29 step:137655[D loss: 1.000030] [G loss: 1.000100]\n",
      "epoch:29 step:137660[D loss: 0.999955] [G loss: 0.999970]\n",
      "epoch:29 step:137665[D loss: 0.999981] [G loss: 1.000138]\n",
      "epoch:29 step:137670[D loss: 1.000060] [G loss: 0.999835]\n",
      "epoch:29 step:137675[D loss: 0.999922] [G loss: 1.000042]\n",
      "epoch:29 step:137680[D loss: 0.999953] [G loss: 1.000061]\n",
      "epoch:29 step:137685[D loss: 1.000103] [G loss: 0.999901]\n",
      "epoch:29 step:137690[D loss: 0.999989] [G loss: 1.000005]\n",
      "epoch:29 step:137695[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:29 step:137700[D loss: 1.000133] [G loss: 0.999892]\n",
      "epoch:29 step:137705[D loss: 0.999956] [G loss: 1.000160]\n",
      "epoch:29 step:137710[D loss: 1.000033] [G loss: 0.999988]\n",
      "epoch:29 step:137715[D loss: 1.000043] [G loss: 0.999946]\n",
      "epoch:29 step:137720[D loss: 1.000025] [G loss: 1.000013]\n",
      "epoch:29 step:137725[D loss: 0.999937] [G loss: 1.000112]\n",
      "epoch:29 step:137730[D loss: 0.999996] [G loss: 0.999978]\n",
      "epoch:29 step:137735[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:29 step:137740[D loss: 1.000003] [G loss: 1.000046]\n",
      "epoch:29 step:137745[D loss: 1.000017] [G loss: 0.999958]\n",
      "epoch:29 step:137750[D loss: 0.999955] [G loss: 1.000136]\n",
      "epoch:29 step:137755[D loss: 1.000286] [G loss: 0.999835]\n",
      "epoch:29 step:137760[D loss: 0.999916] [G loss: 1.000204]\n",
      "epoch:29 step:137765[D loss: 0.999915] [G loss: 0.999988]\n",
      "epoch:29 step:137770[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:29 step:137775[D loss: 1.000000] [G loss: 1.000063]\n",
      "epoch:29 step:137780[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:29 step:137785[D loss: 0.999945] [G loss: 1.000043]\n",
      "epoch:29 step:137790[D loss: 1.000064] [G loss: 1.000045]\n",
      "epoch:29 step:137795[D loss: 0.999931] [G loss: 1.000005]\n",
      "epoch:29 step:137800[D loss: 1.000088] [G loss: 1.000059]\n",
      "##############\n",
      "[2.62147848 2.22333794 2.13484348 3.50511011 1.61518017 7.34084021\n",
      " 2.37073878 3.76897017 4.07475582 5.50402791]\n",
      "##########\n",
      "epoch:29 step:137805[D loss: 0.999963] [G loss: 1.000115]\n",
      "epoch:29 step:137810[D loss: 0.999938] [G loss: 1.000030]\n",
      "epoch:29 step:137815[D loss: 0.999948] [G loss: 1.000216]\n",
      "epoch:29 step:137820[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:29 step:137825[D loss: 1.000042] [G loss: 1.000155]\n",
      "epoch:29 step:137830[D loss: 0.999981] [G loss: 1.000101]\n",
      "epoch:29 step:137835[D loss: 1.000007] [G loss: 1.000093]\n",
      "epoch:29 step:137840[D loss: 0.999949] [G loss: 1.000090]\n",
      "epoch:29 step:137845[D loss: 0.999963] [G loss: 1.000103]\n",
      "epoch:29 step:137850[D loss: 1.000002] [G loss: 1.000023]\n",
      "epoch:29 step:137855[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:29 step:137860[D loss: 1.000053] [G loss: 0.999921]\n",
      "epoch:29 step:137865[D loss: 0.999902] [G loss: 1.000096]\n",
      "epoch:29 step:137870[D loss: 1.000038] [G loss: 0.999971]\n",
      "epoch:29 step:137875[D loss: 1.000035] [G loss: 0.999965]\n",
      "epoch:29 step:137880[D loss: 1.000045] [G loss: 1.000056]\n",
      "epoch:29 step:137885[D loss: 0.999996] [G loss: 1.000015]\n",
      "epoch:29 step:137890[D loss: 0.999893] [G loss: 1.000039]\n",
      "epoch:29 step:137895[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:29 step:137900[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:29 step:137905[D loss: 1.000004] [G loss: 1.000082]\n",
      "epoch:29 step:137910[D loss: 0.999972] [G loss: 1.000126]\n",
      "epoch:29 step:137915[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:29 step:137920[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:29 step:137925[D loss: 1.000052] [G loss: 0.999996]\n",
      "epoch:29 step:137930[D loss: 0.999951] [G loss: 1.000090]\n",
      "epoch:29 step:137935[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:29 step:137940[D loss: 1.000017] [G loss: 1.000054]\n",
      "epoch:29 step:137945[D loss: 1.000020] [G loss: 1.000039]\n",
      "epoch:29 step:137950[D loss: 0.999937] [G loss: 1.000110]\n",
      "epoch:29 step:137955[D loss: 0.999970] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:137960[D loss: 0.999998] [G loss: 0.999980]\n",
      "epoch:29 step:137965[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:29 step:137970[D loss: 0.999951] [G loss: 1.000233]\n",
      "epoch:29 step:137975[D loss: 1.000032] [G loss: 1.000111]\n",
      "epoch:29 step:137980[D loss: 0.999919] [G loss: 1.000188]\n",
      "epoch:29 step:137985[D loss: 1.000030] [G loss: 1.000055]\n",
      "epoch:29 step:137990[D loss: 0.999891] [G loss: 1.000248]\n",
      "epoch:29 step:137995[D loss: 0.999898] [G loss: 1.000162]\n",
      "epoch:29 step:138000[D loss: 1.000001] [G loss: 1.000018]\n",
      "##############\n",
      "[2.58621863 2.24203027 2.12988525 3.47774126 1.53864306 7.40513033\n",
      " 2.41832641 3.77611773 3.93579006 5.00268865]\n",
      "##########\n",
      "epoch:29 step:138005[D loss: 1.000086] [G loss: 1.000017]\n",
      "epoch:29 step:138010[D loss: 0.999952] [G loss: 0.999987]\n",
      "epoch:29 step:138015[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:29 step:138020[D loss: 0.999929] [G loss: 1.000111]\n",
      "epoch:29 step:138025[D loss: 0.999948] [G loss: 1.000247]\n",
      "epoch:29 step:138030[D loss: 0.999985] [G loss: 1.000015]\n",
      "epoch:29 step:138035[D loss: 0.999981] [G loss: 1.000189]\n",
      "epoch:29 step:138040[D loss: 0.999809] [G loss: 1.000403]\n",
      "epoch:29 step:138045[D loss: 0.999900] [G loss: 1.000108]\n",
      "epoch:29 step:138050[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:29 step:138055[D loss: 0.999946] [G loss: 1.000086]\n",
      "epoch:29 step:138060[D loss: 0.999978] [G loss: 1.000123]\n",
      "epoch:29 step:138065[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:29 step:138070[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:29 step:138075[D loss: 0.999972] [G loss: 1.000022]\n",
      "epoch:29 step:138080[D loss: 0.999968] [G loss: 1.000012]\n",
      "epoch:29 step:138085[D loss: 0.999919] [G loss: 1.000131]\n",
      "epoch:29 step:138090[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:29 step:138095[D loss: 1.000044] [G loss: 1.000062]\n",
      "epoch:29 step:138100[D loss: 1.000116] [G loss: 0.999958]\n",
      "epoch:29 step:138105[D loss: 1.000005] [G loss: 1.000159]\n",
      "epoch:29 step:138110[D loss: 0.999914] [G loss: 1.000182]\n",
      "epoch:29 step:138115[D loss: 0.999907] [G loss: 1.000248]\n",
      "epoch:29 step:138120[D loss: 0.999930] [G loss: 1.000102]\n",
      "epoch:29 step:138125[D loss: 0.999974] [G loss: 1.000127]\n",
      "epoch:29 step:138130[D loss: 0.999999] [G loss: 1.000112]\n",
      "epoch:29 step:138135[D loss: 0.999943] [G loss: 1.000090]\n",
      "epoch:29 step:138140[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:29 step:138145[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:29 step:138150[D loss: 1.000077] [G loss: 0.999870]\n",
      "epoch:29 step:138155[D loss: 1.000065] [G loss: 1.000078]\n",
      "epoch:29 step:138160[D loss: 1.000277] [G loss: 0.999892]\n",
      "epoch:29 step:138165[D loss: 0.999940] [G loss: 1.000020]\n",
      "epoch:29 step:138170[D loss: 0.999953] [G loss: 1.000028]\n",
      "epoch:29 step:138175[D loss: 0.999965] [G loss: 0.999994]\n",
      "epoch:29 step:138180[D loss: 0.999872] [G loss: 1.000281]\n",
      "epoch:29 step:138185[D loss: 0.999914] [G loss: 1.000147]\n",
      "epoch:29 step:138190[D loss: 0.999977] [G loss: 1.000027]\n",
      "epoch:29 step:138195[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:29 step:138200[D loss: 0.999975] [G loss: 1.000018]\n",
      "##############\n",
      "[2.53133959 2.30301936 2.23723018 3.93310557 1.52387573 6.45769596\n",
      " 2.4167654  3.82201222 4.01820217 5.44089235]\n",
      "##########\n",
      "epoch:29 step:138205[D loss: 1.000030] [G loss: 1.000139]\n",
      "epoch:29 step:138210[D loss: 1.000088] [G loss: 0.999944]\n",
      "epoch:29 step:138215[D loss: 1.000060] [G loss: 1.000022]\n",
      "epoch:29 step:138220[D loss: 0.999989] [G loss: 1.000219]\n",
      "epoch:29 step:138225[D loss: 0.999907] [G loss: 1.000181]\n",
      "epoch:29 step:138230[D loss: 0.999966] [G loss: 1.000109]\n",
      "epoch:29 step:138235[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:29 step:138240[D loss: 0.999975] [G loss: 0.999980]\n",
      "epoch:29 step:138245[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:29 step:138250[D loss: 0.999970] [G loss: 1.000031]\n",
      "epoch:29 step:138255[D loss: 1.000041] [G loss: 0.999951]\n",
      "epoch:29 step:138260[D loss: 1.000000] [G loss: 0.999983]\n",
      "epoch:29 step:138265[D loss: 0.999963] [G loss: 1.000010]\n",
      "epoch:29 step:138270[D loss: 0.999959] [G loss: 1.000041]\n",
      "epoch:29 step:138275[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:29 step:138280[D loss: 1.000025] [G loss: 0.999983]\n",
      "epoch:29 step:138285[D loss: 0.999960] [G loss: 1.000110]\n",
      "epoch:29 step:138290[D loss: 0.999943] [G loss: 1.000091]\n",
      "epoch:29 step:138295[D loss: 0.999990] [G loss: 1.000134]\n",
      "epoch:29 step:138300[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:29 step:138305[D loss: 1.000058] [G loss: 0.999942]\n",
      "epoch:29 step:138310[D loss: 1.000084] [G loss: 0.999788]\n",
      "epoch:29 step:138315[D loss: 1.000077] [G loss: 0.999897]\n",
      "epoch:29 step:138320[D loss: 0.999903] [G loss: 1.000157]\n",
      "epoch:29 step:138325[D loss: 0.999976] [G loss: 1.000206]\n",
      "epoch:29 step:138330[D loss: 1.000148] [G loss: 1.000392]\n",
      "epoch:29 step:138335[D loss: 0.999947] [G loss: 1.000179]\n",
      "epoch:29 step:138340[D loss: 0.999883] [G loss: 1.000253]\n",
      "epoch:29 step:138345[D loss: 1.000130] [G loss: 1.000253]\n",
      "epoch:29 step:138350[D loss: 1.000033] [G loss: 1.000060]\n",
      "epoch:29 step:138355[D loss: 0.999951] [G loss: 1.000098]\n",
      "epoch:29 step:138360[D loss: 1.000008] [G loss: 0.999994]\n",
      "epoch:29 step:138365[D loss: 1.000021] [G loss: 1.000027]\n",
      "epoch:29 step:138370[D loss: 0.999921] [G loss: 0.999994]\n",
      "epoch:29 step:138375[D loss: 1.000066] [G loss: 0.999905]\n",
      "epoch:29 step:138380[D loss: 0.999950] [G loss: 1.000035]\n",
      "epoch:29 step:138385[D loss: 1.000018] [G loss: 0.999990]\n",
      "epoch:29 step:138390[D loss: 1.000068] [G loss: 0.999870]\n",
      "epoch:29 step:138395[D loss: 0.999951] [G loss: 1.000043]\n",
      "epoch:29 step:138400[D loss: 1.000071] [G loss: 1.000081]\n",
      "##############\n",
      "[2.50984649 2.13724359 2.06865969 3.31331371 1.51594944 7.00956783\n",
      " 2.1395695  3.56258141 3.91496485 4.69018012]\n",
      "##########\n",
      "epoch:29 step:138405[D loss: 1.000150] [G loss: 0.999949]\n",
      "epoch:29 step:138410[D loss: 0.999960] [G loss: 1.000202]\n",
      "epoch:29 step:138415[D loss: 1.000247] [G loss: 1.000203]\n",
      "epoch:29 step:138420[D loss: 0.999930] [G loss: 1.000213]\n",
      "epoch:29 step:138425[D loss: 1.000047] [G loss: 0.999774]\n",
      "epoch:29 step:138430[D loss: 0.999874] [G loss: 1.000322]\n",
      "epoch:29 step:138435[D loss: 0.999901] [G loss: 1.000066]\n",
      "epoch:29 step:138440[D loss: 0.999941] [G loss: 1.000138]\n",
      "epoch:29 step:138445[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:29 step:138450[D loss: 1.000067] [G loss: 0.999924]\n",
      "epoch:29 step:138455[D loss: 1.000039] [G loss: 0.999925]\n",
      "epoch:29 step:138460[D loss: 1.000084] [G loss: 0.999771]\n",
      "epoch:29 step:138465[D loss: 1.000097] [G loss: 0.999823]\n",
      "epoch:29 step:138470[D loss: 1.000153] [G loss: 1.000077]\n",
      "epoch:29 step:138475[D loss: 1.000033] [G loss: 0.999939]\n",
      "epoch:29 step:138480[D loss: 1.000048] [G loss: 1.000035]\n",
      "epoch:29 step:138485[D loss: 0.999959] [G loss: 1.000361]\n",
      "epoch:29 step:138490[D loss: 0.999977] [G loss: 0.999989]\n",
      "epoch:29 step:138495[D loss: 0.999930] [G loss: 1.000127]\n",
      "epoch:29 step:138500[D loss: 0.999948] [G loss: 1.000238]\n",
      "epoch:29 step:138505[D loss: 0.999947] [G loss: 1.000081]\n",
      "epoch:29 step:138510[D loss: 0.999924] [G loss: 1.000126]\n",
      "epoch:29 step:138515[D loss: 1.000022] [G loss: 1.000055]\n",
      "epoch:29 step:138520[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:29 step:138525[D loss: 0.999935] [G loss: 1.000099]\n",
      "epoch:29 step:138530[D loss: 0.999942] [G loss: 1.000093]\n",
      "epoch:29 step:138535[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:29 step:138540[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:29 step:138545[D loss: 0.999972] [G loss: 1.000120]\n",
      "epoch:29 step:138550[D loss: 1.000058] [G loss: 0.999989]\n",
      "epoch:29 step:138555[D loss: 1.000011] [G loss: 1.000043]\n",
      "epoch:29 step:138560[D loss: 0.999982] [G loss: 1.000142]\n",
      "epoch:29 step:138565[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:29 step:138570[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:29 step:138575[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:29 step:138580[D loss: 1.000121] [G loss: 0.999907]\n",
      "epoch:29 step:138585[D loss: 1.000021] [G loss: 0.999952]\n",
      "epoch:29 step:138590[D loss: 1.000084] [G loss: 0.999914]\n",
      "epoch:29 step:138595[D loss: 0.999948] [G loss: 1.000063]\n",
      "epoch:29 step:138600[D loss: 0.999927] [G loss: 1.000141]\n",
      "##############\n",
      "[2.45082057 2.14440942 2.12923803 3.61800221 1.44289771 8.3346911\n",
      " 2.41382578 3.71086611 3.88392247 5.22633799]\n",
      "##########\n",
      "epoch:29 step:138605[D loss: 0.999889] [G loss: 1.000276]\n",
      "epoch:29 step:138610[D loss: 0.999866] [G loss: 1.000241]\n",
      "epoch:29 step:138615[D loss: 1.000027] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:138620[D loss: 0.999945] [G loss: 1.000095]\n",
      "epoch:29 step:138625[D loss: 0.999942] [G loss: 1.000155]\n",
      "epoch:29 step:138630[D loss: 1.000019] [G loss: 1.000030]\n",
      "epoch:29 step:138635[D loss: 0.999960] [G loss: 1.000032]\n",
      "epoch:29 step:138640[D loss: 0.999997] [G loss: 1.000014]\n",
      "epoch:29 step:138645[D loss: 1.000035] [G loss: 1.000044]\n",
      "epoch:29 step:138650[D loss: 1.000106] [G loss: 0.999900]\n",
      "epoch:29 step:138655[D loss: 1.000111] [G loss: 0.999956]\n",
      "epoch:29 step:138660[D loss: 0.999946] [G loss: 1.000131]\n",
      "epoch:29 step:138665[D loss: 0.999918] [G loss: 1.000135]\n",
      "epoch:29 step:138670[D loss: 1.000025] [G loss: 1.000044]\n",
      "epoch:29 step:138675[D loss: 0.999948] [G loss: 1.000164]\n",
      "epoch:29 step:138680[D loss: 0.999978] [G loss: 1.000121]\n",
      "epoch:29 step:138685[D loss: 0.999950] [G loss: 1.000122]\n",
      "epoch:29 step:138690[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:29 step:138695[D loss: 0.999966] [G loss: 1.000103]\n",
      "epoch:29 step:138700[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:29 step:138705[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:29 step:138710[D loss: 1.000038] [G loss: 0.999972]\n",
      "epoch:29 step:138715[D loss: 1.000011] [G loss: 0.999991]\n",
      "epoch:29 step:138720[D loss: 0.999952] [G loss: 1.000051]\n",
      "epoch:29 step:138725[D loss: 0.999934] [G loss: 1.000133]\n",
      "epoch:29 step:138730[D loss: 1.000015] [G loss: 1.000006]\n",
      "epoch:29 step:138735[D loss: 0.999984] [G loss: 1.000115]\n",
      "epoch:29 step:138740[D loss: 0.999991] [G loss: 1.000082]\n",
      "epoch:29 step:138745[D loss: 0.999964] [G loss: 1.000104]\n",
      "epoch:29 step:138750[D loss: 0.999923] [G loss: 1.000112]\n",
      "epoch:29 step:138755[D loss: 0.999941] [G loss: 1.000141]\n",
      "epoch:29 step:138760[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:29 step:138765[D loss: 1.000147] [G loss: 1.000052]\n",
      "epoch:29 step:138770[D loss: 0.999934] [G loss: 1.000016]\n",
      "epoch:29 step:138775[D loss: 0.999984] [G loss: 1.000104]\n",
      "epoch:29 step:138780[D loss: 0.999917] [G loss: 1.000151]\n",
      "epoch:29 step:138785[D loss: 0.999958] [G loss: 1.000103]\n",
      "epoch:29 step:138790[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:29 step:138795[D loss: 0.999941] [G loss: 1.000097]\n",
      "epoch:29 step:138800[D loss: 1.000058] [G loss: 0.999962]\n",
      "##############\n",
      "[2.4524708  2.23425567 2.05601742 3.52723678 1.46657416 7.78261756\n",
      " 2.2812056  3.73472998 3.91381927 5.01968433]\n",
      "##########\n",
      "epoch:29 step:138805[D loss: 1.000009] [G loss: 1.000095]\n",
      "epoch:29 step:138810[D loss: 1.000154] [G loss: 1.000022]\n",
      "epoch:29 step:138815[D loss: 0.999935] [G loss: 1.000193]\n",
      "epoch:29 step:138820[D loss: 1.000006] [G loss: 1.000040]\n",
      "epoch:29 step:138825[D loss: 0.999940] [G loss: 1.000080]\n",
      "epoch:29 step:138830[D loss: 1.000062] [G loss: 0.999869]\n",
      "epoch:29 step:138835[D loss: 1.000038] [G loss: 0.999972]\n",
      "epoch:29 step:138840[D loss: 1.000070] [G loss: 1.000018]\n",
      "epoch:29 step:138845[D loss: 1.000034] [G loss: 1.000037]\n",
      "epoch:29 step:138850[D loss: 0.999975] [G loss: 1.000111]\n",
      "epoch:29 step:138855[D loss: 0.999952] [G loss: 1.000097]\n",
      "epoch:29 step:138860[D loss: 0.999920] [G loss: 1.000120]\n",
      "epoch:29 step:138865[D loss: 0.999966] [G loss: 1.000151]\n",
      "epoch:29 step:138870[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:29 step:138875[D loss: 1.000012] [G loss: 1.000008]\n",
      "epoch:29 step:138880[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:29 step:138885[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:29 step:138890[D loss: 0.999998] [G loss: 0.999995]\n",
      "epoch:29 step:138895[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:29 step:138900[D loss: 0.999997] [G loss: 1.000078]\n",
      "epoch:29 step:138905[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:29 step:138910[D loss: 1.000110] [G loss: 1.000088]\n",
      "epoch:29 step:138915[D loss: 0.999857] [G loss: 1.000136]\n",
      "epoch:29 step:138920[D loss: 0.999953] [G loss: 1.000168]\n",
      "epoch:29 step:138925[D loss: 1.000020] [G loss: 1.000040]\n",
      "epoch:29 step:138930[D loss: 0.999955] [G loss: 1.000042]\n",
      "epoch:29 step:138935[D loss: 0.999970] [G loss: 1.000016]\n",
      "epoch:29 step:138940[D loss: 0.999982] [G loss: 0.999963]\n",
      "epoch:29 step:138945[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:29 step:138950[D loss: 1.000079] [G loss: 0.999965]\n",
      "epoch:29 step:138955[D loss: 1.000018] [G loss: 1.000032]\n",
      "epoch:29 step:138960[D loss: 0.999928] [G loss: 1.000065]\n",
      "epoch:29 step:138965[D loss: 0.999963] [G loss: 1.000182]\n",
      "epoch:29 step:138970[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:29 step:138975[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:29 step:138980[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:29 step:138985[D loss: 1.000042] [G loss: 0.999977]\n",
      "epoch:29 step:138990[D loss: 0.999957] [G loss: 1.000121]\n",
      "epoch:29 step:138995[D loss: 0.999984] [G loss: 1.000028]\n",
      "epoch:29 step:139000[D loss: 1.000047] [G loss: 0.999964]\n",
      "##############\n",
      "[2.51667046 2.19636372 2.19840039 3.77486411 1.48921473 7.50153721\n",
      " 2.17705856 3.93532586 4.00163231 4.96341925]\n",
      "##########\n",
      "epoch:29 step:139005[D loss: 1.000017] [G loss: 0.999948]\n",
      "epoch:29 step:139010[D loss: 1.000074] [G loss: 0.999910]\n",
      "epoch:29 step:139015[D loss: 0.999941] [G loss: 1.000121]\n",
      "epoch:29 step:139020[D loss: 0.999915] [G loss: 1.000125]\n",
      "epoch:29 step:139025[D loss: 1.000035] [G loss: 1.000103]\n",
      "epoch:29 step:139030[D loss: 0.999982] [G loss: 1.000150]\n",
      "epoch:29 step:139035[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:29 step:139040[D loss: 1.000015] [G loss: 0.999992]\n",
      "epoch:29 step:139045[D loss: 0.999982] [G loss: 0.999965]\n",
      "epoch:29 step:139050[D loss: 1.000126] [G loss: 0.999856]\n",
      "epoch:29 step:139055[D loss: 0.999974] [G loss: 0.999944]\n",
      "epoch:29 step:139060[D loss: 0.999977] [G loss: 0.999915]\n",
      "epoch:29 step:139065[D loss: 1.000137] [G loss: 0.999975]\n",
      "epoch:29 step:139070[D loss: 1.000010] [G loss: 0.999945]\n",
      "epoch:29 step:139075[D loss: 1.000016] [G loss: 1.000003]\n",
      "epoch:29 step:139080[D loss: 0.999915] [G loss: 1.000072]\n",
      "epoch:29 step:139085[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:29 step:139090[D loss: 1.000004] [G loss: 1.000032]\n",
      "epoch:29 step:139095[D loss: 1.000086] [G loss: 0.999875]\n",
      "epoch:29 step:139100[D loss: 0.999958] [G loss: 1.000052]\n",
      "epoch:29 step:139105[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:29 step:139110[D loss: 1.000050] [G loss: 1.000056]\n",
      "epoch:29 step:139115[D loss: 1.000023] [G loss: 0.999906]\n",
      "epoch:29 step:139120[D loss: 1.000035] [G loss: 1.000100]\n",
      "epoch:29 step:139125[D loss: 0.999960] [G loss: 1.000152]\n",
      "epoch:29 step:139130[D loss: 0.999929] [G loss: 1.000250]\n",
      "epoch:29 step:139135[D loss: 0.999926] [G loss: 1.000139]\n",
      "epoch:29 step:139140[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:29 step:139145[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:29 step:139150[D loss: 1.000021] [G loss: 0.999959]\n",
      "epoch:29 step:139155[D loss: 0.999936] [G loss: 1.000060]\n",
      "epoch:29 step:139160[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:29 step:139165[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:29 step:139170[D loss: 0.999918] [G loss: 1.000096]\n",
      "epoch:29 step:139175[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:29 step:139180[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:29 step:139185[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:29 step:139190[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:29 step:139195[D loss: 1.000032] [G loss: 0.999994]\n",
      "epoch:29 step:139200[D loss: 0.999969] [G loss: 1.000047]\n",
      "##############\n",
      "[2.52862016 2.17502567 2.10888198 3.75624306 1.47197816 7.2189517\n",
      " 2.22535083 3.61087145 3.97883217 4.81135483]\n",
      "##########\n",
      "epoch:29 step:139205[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:29 step:139210[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:29 step:139215[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:29 step:139220[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:29 step:139225[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:29 step:139230[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:29 step:139235[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:29 step:139240[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:29 step:139245[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:29 step:139250[D loss: 1.000013] [G loss: 0.999977]\n",
      "epoch:29 step:139255[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:29 step:139260[D loss: 1.000013] [G loss: 1.000003]\n",
      "epoch:29 step:139265[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:29 step:139270[D loss: 0.999915] [G loss: 1.000111]\n",
      "epoch:29 step:139275[D loss: 1.000020] [G loss: 1.000115]\n",
      "epoch:29 step:139280[D loss: 0.999889] [G loss: 1.000145]\n",
      "epoch:29 step:139285[D loss: 1.000009] [G loss: 1.000009]\n",
      "epoch:29 step:139290[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:29 step:139295[D loss: 1.000014] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:139300[D loss: 1.000018] [G loss: 1.000038]\n",
      "epoch:29 step:139305[D loss: 1.000009] [G loss: 1.000092]\n",
      "epoch:29 step:139310[D loss: 0.999995] [G loss: 1.000058]\n",
      "epoch:29 step:139315[D loss: 0.999990] [G loss: 0.999936]\n",
      "epoch:29 step:139320[D loss: 0.999950] [G loss: 1.000050]\n",
      "epoch:29 step:139325[D loss: 0.999989] [G loss: 0.999979]\n",
      "epoch:29 step:139330[D loss: 1.000081] [G loss: 1.000028]\n",
      "epoch:29 step:139335[D loss: 1.000138] [G loss: 0.999859]\n",
      "epoch:29 step:139340[D loss: 0.999936] [G loss: 1.000096]\n",
      "epoch:29 step:139345[D loss: 0.999970] [G loss: 1.000130]\n",
      "epoch:29 step:139350[D loss: 0.999891] [G loss: 1.000096]\n",
      "epoch:29 step:139355[D loss: 1.000017] [G loss: 1.000073]\n",
      "epoch:29 step:139360[D loss: 0.999950] [G loss: 1.000076]\n",
      "epoch:29 step:139365[D loss: 0.999960] [G loss: 1.000130]\n",
      "epoch:29 step:139370[D loss: 0.999969] [G loss: 1.000142]\n",
      "epoch:29 step:139375[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:29 step:139380[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:29 step:139385[D loss: 1.000009] [G loss: 0.999965]\n",
      "epoch:29 step:139390[D loss: 1.000170] [G loss: 0.999821]\n",
      "epoch:29 step:139395[D loss: 1.000032] [G loss: 0.999916]\n",
      "epoch:29 step:139400[D loss: 0.999838] [G loss: 1.000231]\n",
      "##############\n",
      "[2.5325351  2.15085222 2.01881607 3.78675774 1.48676175 7.33222053\n",
      " 2.36833623 3.78169912 3.96407106 6.23936536]\n",
      "##########\n",
      "epoch:29 step:139405[D loss: 0.999939] [G loss: 1.000151]\n",
      "epoch:29 step:139410[D loss: 0.999939] [G loss: 1.000024]\n",
      "epoch:29 step:139415[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:29 step:139420[D loss: 0.999993] [G loss: 0.999996]\n",
      "epoch:29 step:139425[D loss: 0.999949] [G loss: 1.000036]\n",
      "epoch:29 step:139430[D loss: 0.999929] [G loss: 1.000112]\n",
      "epoch:29 step:139435[D loss: 1.000119] [G loss: 0.999869]\n",
      "epoch:29 step:139440[D loss: 1.000066] [G loss: 0.999919]\n",
      "epoch:29 step:139445[D loss: 0.999870] [G loss: 1.000162]\n",
      "epoch:29 step:139450[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:29 step:139455[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:29 step:139460[D loss: 0.999945] [G loss: 1.000061]\n",
      "epoch:29 step:139465[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:29 step:139470[D loss: 1.000008] [G loss: 1.000031]\n",
      "epoch:29 step:139475[D loss: 1.000038] [G loss: 1.000031]\n",
      "epoch:29 step:139480[D loss: 1.000046] [G loss: 0.999952]\n",
      "epoch:29 step:139485[D loss: 1.000005] [G loss: 0.999973]\n",
      "epoch:29 step:139490[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:29 step:139495[D loss: 0.999958] [G loss: 1.000022]\n",
      "epoch:29 step:139500[D loss: 1.000003] [G loss: 1.000058]\n",
      "epoch:29 step:139505[D loss: 0.999956] [G loss: 1.000028]\n",
      "epoch:29 step:139510[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:29 step:139515[D loss: 0.999996] [G loss: 1.000084]\n",
      "epoch:29 step:139520[D loss: 0.999966] [G loss: 1.000035]\n",
      "epoch:29 step:139525[D loss: 1.000014] [G loss: 1.000012]\n",
      "epoch:29 step:139530[D loss: 0.999989] [G loss: 1.000020]\n",
      "epoch:29 step:139535[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:29 step:139540[D loss: 0.999944] [G loss: 1.000081]\n",
      "epoch:29 step:139545[D loss: 1.000032] [G loss: 1.000006]\n",
      "epoch:29 step:139550[D loss: 1.000023] [G loss: 1.000056]\n",
      "epoch:29 step:139555[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:29 step:139560[D loss: 1.000043] [G loss: 0.999980]\n",
      "epoch:29 step:139565[D loss: 0.999962] [G loss: 1.000160]\n",
      "epoch:29 step:139570[D loss: 1.000001] [G loss: 1.000036]\n",
      "epoch:29 step:139575[D loss: 1.000199] [G loss: 0.999860]\n",
      "epoch:29 step:139580[D loss: 0.999909] [G loss: 1.000073]\n",
      "epoch:29 step:139585[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:29 step:139590[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:29 step:139595[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:29 step:139600[D loss: 0.999992] [G loss: 1.000076]\n",
      "##############\n",
      "[2.53172994 2.14888965 2.00714176 3.46852514 1.50055936 6.88039546\n",
      " 2.37697968 3.66663387 4.03827232 5.69676751]\n",
      "##########\n",
      "epoch:29 step:139605[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:29 step:139610[D loss: 0.999986] [G loss: 0.999986]\n",
      "epoch:29 step:139615[D loss: 1.000035] [G loss: 0.999986]\n",
      "epoch:29 step:139620[D loss: 0.999972] [G loss: 1.000010]\n",
      "epoch:29 step:139625[D loss: 0.999976] [G loss: 1.000021]\n",
      "epoch:29 step:139630[D loss: 1.000026] [G loss: 1.000114]\n",
      "epoch:29 step:139635[D loss: 1.000003] [G loss: 1.000091]\n",
      "epoch:29 step:139640[D loss: 0.999796] [G loss: 1.000368]\n",
      "epoch:29 step:139645[D loss: 0.999926] [G loss: 1.000110]\n",
      "epoch:29 step:139650[D loss: 1.000023] [G loss: 0.999926]\n",
      "epoch:29 step:139655[D loss: 0.999962] [G loss: 0.999940]\n",
      "epoch:29 step:139660[D loss: 1.000011] [G loss: 0.999986]\n",
      "epoch:29 step:139665[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:29 step:139670[D loss: 0.999996] [G loss: 1.000099]\n",
      "epoch:29 step:139675[D loss: 1.000126] [G loss: 1.000146]\n",
      "epoch:29 step:139680[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:29 step:139685[D loss: 0.999978] [G loss: 1.000099]\n",
      "epoch:29 step:139690[D loss: 1.000041] [G loss: 0.999980]\n",
      "epoch:29 step:139695[D loss: 0.999904] [G loss: 1.000231]\n",
      "epoch:29 step:139700[D loss: 1.000004] [G loss: 1.000102]\n",
      "epoch:29 step:139705[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:29 step:139710[D loss: 0.999960] [G loss: 1.000065]\n",
      "epoch:29 step:139715[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:29 step:139720[D loss: 1.000053] [G loss: 1.000082]\n",
      "epoch:29 step:139725[D loss: 1.000047] [G loss: 0.999926]\n",
      "epoch:29 step:139730[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:29 step:139735[D loss: 1.000230] [G loss: 0.999832]\n",
      "epoch:29 step:139740[D loss: 0.999822] [G loss: 1.000156]\n",
      "epoch:29 step:139745[D loss: 0.999975] [G loss: 1.000112]\n",
      "epoch:29 step:139750[D loss: 0.999975] [G loss: 1.000002]\n",
      "epoch:29 step:139755[D loss: 1.000016] [G loss: 0.999977]\n",
      "epoch:29 step:139760[D loss: 1.000071] [G loss: 1.000019]\n",
      "epoch:29 step:139765[D loss: 0.999939] [G loss: 1.000185]\n",
      "epoch:29 step:139770[D loss: 0.999910] [G loss: 1.000061]\n",
      "epoch:29 step:139775[D loss: 0.999970] [G loss: 1.000041]\n",
      "epoch:29 step:139780[D loss: 0.999953] [G loss: 1.000133]\n",
      "epoch:29 step:139785[D loss: 1.000005] [G loss: 1.000048]\n",
      "epoch:29 step:139790[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:29 step:139795[D loss: 0.999970] [G loss: 1.000153]\n",
      "epoch:29 step:139800[D loss: 0.999958] [G loss: 1.000090]\n",
      "##############\n",
      "[2.54077457 2.12723344 2.03763528 3.61319294 1.50562879 7.26445704\n",
      " 2.24376777 3.7187034  3.92547444 4.26977513]\n",
      "##########\n",
      "epoch:29 step:139805[D loss: 0.999970] [G loss: 1.000143]\n",
      "epoch:29 step:139810[D loss: 0.999919] [G loss: 1.000289]\n",
      "epoch:29 step:139815[D loss: 0.999934] [G loss: 1.000071]\n",
      "epoch:29 step:139820[D loss: 0.999984] [G loss: 1.000020]\n",
      "epoch:29 step:139825[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:29 step:139830[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:29 step:139835[D loss: 1.000011] [G loss: 1.000026]\n",
      "epoch:29 step:139840[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:29 step:139845[D loss: 0.999876] [G loss: 1.000222]\n",
      "epoch:29 step:139850[D loss: 1.000015] [G loss: 1.000058]\n",
      "epoch:29 step:139855[D loss: 0.999952] [G loss: 1.000234]\n",
      "epoch:29 step:139860[D loss: 0.999903] [G loss: 1.000139]\n",
      "epoch:29 step:139865[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:29 step:139870[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:29 step:139875[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:29 step:139880[D loss: 0.999954] [G loss: 1.000095]\n",
      "epoch:29 step:139885[D loss: 1.000003] [G loss: 1.000005]\n",
      "epoch:29 step:139890[D loss: 0.999988] [G loss: 1.000117]\n",
      "epoch:29 step:139895[D loss: 0.999939] [G loss: 1.000091]\n",
      "epoch:29 step:139900[D loss: 1.000014] [G loss: 1.000036]\n",
      "epoch:29 step:139905[D loss: 0.999995] [G loss: 1.000160]\n",
      "epoch:29 step:139910[D loss: 0.999944] [G loss: 1.000081]\n",
      "epoch:29 step:139915[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:29 step:139920[D loss: 0.999950] [G loss: 1.000194]\n",
      "epoch:29 step:139925[D loss: 1.000007] [G loss: 1.000090]\n",
      "epoch:29 step:139930[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:29 step:139935[D loss: 1.000003] [G loss: 0.999996]\n",
      "epoch:29 step:139940[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:29 step:139945[D loss: 0.999976] [G loss: 1.000100]\n",
      "epoch:29 step:139950[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:29 step:139955[D loss: 1.000004] [G loss: 1.000044]\n",
      "epoch:29 step:139960[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:29 step:139965[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:29 step:139970[D loss: 1.000147] [G loss: 0.999883]\n",
      "epoch:29 step:139975[D loss: 1.000026] [G loss: 0.999944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:139980[D loss: 0.999946] [G loss: 1.000074]\n",
      "epoch:29 step:139985[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:29 step:139990[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:29 step:139995[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:29 step:140000[D loss: 0.999946] [G loss: 1.000073]\n",
      "##############\n",
      "[2.49696662 2.13207981 2.05155209 3.62213867 1.52900686 6.70264854\n",
      " 2.24591196 3.82070241 4.04480122 6.07103106]\n",
      "##########\n",
      "epoch:29 step:140005[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:29 step:140010[D loss: 1.000023] [G loss: 1.000029]\n",
      "epoch:29 step:140015[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:29 step:140020[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:29 step:140025[D loss: 1.000119] [G loss: 0.999849]\n",
      "epoch:29 step:140030[D loss: 0.999956] [G loss: 1.000057]\n",
      "epoch:29 step:140035[D loss: 1.000024] [G loss: 1.000073]\n",
      "epoch:29 step:140040[D loss: 0.999936] [G loss: 1.000113]\n",
      "epoch:29 step:140045[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:29 step:140050[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:29 step:140055[D loss: 0.999960] [G loss: 1.000106]\n",
      "epoch:29 step:140060[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:29 step:140065[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:29 step:140070[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:29 step:140075[D loss: 0.999944] [G loss: 1.000101]\n",
      "epoch:29 step:140080[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:29 step:140085[D loss: 1.000019] [G loss: 1.000063]\n",
      "epoch:29 step:140090[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:29 step:140095[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:29 step:140100[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:29 step:140105[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:29 step:140110[D loss: 0.999958] [G loss: 1.000118]\n",
      "epoch:29 step:140115[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:29 step:140120[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:29 step:140125[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:29 step:140130[D loss: 1.000068] [G loss: 0.999991]\n",
      "epoch:29 step:140135[D loss: 0.999919] [G loss: 1.000099]\n",
      "epoch:29 step:140140[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:29 step:140145[D loss: 0.999985] [G loss: 1.000173]\n",
      "epoch:29 step:140150[D loss: 0.999923] [G loss: 1.000161]\n",
      "epoch:29 step:140155[D loss: 0.999956] [G loss: 1.000100]\n",
      "epoch:29 step:140160[D loss: 0.999962] [G loss: 1.000120]\n",
      "epoch:29 step:140165[D loss: 0.999990] [G loss: 1.000012]\n",
      "epoch:29 step:140170[D loss: 0.999980] [G loss: 1.000024]\n",
      "epoch:29 step:140175[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:29 step:140180[D loss: 0.999962] [G loss: 1.000009]\n",
      "epoch:29 step:140185[D loss: 1.000092] [G loss: 1.000005]\n",
      "epoch:29 step:140190[D loss: 0.999910] [G loss: 1.000153]\n",
      "epoch:29 step:140195[D loss: 0.999949] [G loss: 1.000127]\n",
      "epoch:29 step:140200[D loss: 0.999963] [G loss: 1.000139]\n",
      "##############\n",
      "[2.56034239 2.18489742 2.128385   3.48552278 1.60038483 8.29186063\n",
      " 2.40249804 3.80579673 4.06280914 4.82540013]\n",
      "##########\n",
      "epoch:29 step:140205[D loss: 0.999954] [G loss: 1.000121]\n",
      "epoch:29 step:140210[D loss: 1.000038] [G loss: 1.000003]\n",
      "epoch:29 step:140215[D loss: 1.000015] [G loss: 1.000184]\n",
      "epoch:29 step:140220[D loss: 0.999890] [G loss: 1.000149]\n",
      "epoch:29 step:140225[D loss: 1.000013] [G loss: 1.000015]\n",
      "epoch:29 step:140230[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:29 step:140235[D loss: 0.999947] [G loss: 1.000102]\n",
      "epoch:29 step:140240[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:29 step:140245[D loss: 1.000046] [G loss: 0.999873]\n",
      "epoch:29 step:140250[D loss: 0.999963] [G loss: 1.000012]\n",
      "epoch:29 step:140255[D loss: 0.999999] [G loss: 1.000021]\n",
      "epoch:29 step:140260[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:29 step:140265[D loss: 1.000093] [G loss: 0.999969]\n",
      "epoch:29 step:140270[D loss: 0.999899] [G loss: 1.000105]\n",
      "epoch:29 step:140275[D loss: 0.999955] [G loss: 1.000022]\n",
      "epoch:29 step:140280[D loss: 1.000062] [G loss: 0.999996]\n",
      "epoch:29 step:140285[D loss: 0.999948] [G loss: 1.000126]\n",
      "epoch:29 step:140290[D loss: 1.000048] [G loss: 0.999968]\n",
      "epoch:29 step:140295[D loss: 1.000059] [G loss: 0.999866]\n",
      "epoch:29 step:140300[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:29 step:140305[D loss: 0.999976] [G loss: 1.000109]\n",
      "epoch:29 step:140310[D loss: 0.999995] [G loss: 1.000192]\n",
      "epoch:29 step:140315[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:29 step:140320[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:29 step:140325[D loss: 0.999970] [G loss: 1.000003]\n",
      "epoch:29 step:140330[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:29 step:140335[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:29 step:140340[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:29 step:140345[D loss: 1.000172] [G loss: 1.000016]\n",
      "epoch:29 step:140350[D loss: 0.999908] [G loss: 1.000128]\n",
      "epoch:29 step:140355[D loss: 0.999950] [G loss: 1.000053]\n",
      "epoch:29 step:140360[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:29 step:140365[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:29 step:140370[D loss: 0.999995] [G loss: 1.000069]\n",
      "epoch:29 step:140375[D loss: 0.999943] [G loss: 1.000079]\n",
      "epoch:29 step:140380[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:29 step:140385[D loss: 0.999945] [G loss: 1.000060]\n",
      "epoch:29 step:140390[D loss: 0.999954] [G loss: 0.999982]\n",
      "epoch:29 step:140395[D loss: 0.999972] [G loss: 1.000114]\n",
      "epoch:29 step:140400[D loss: 0.999918] [G loss: 1.000086]\n",
      "##############\n",
      "[2.46635249 2.17185713 2.08901758 3.50925484 1.47375061 7.18863777\n",
      " 2.36241898 3.70862079 3.98427729 5.11701247]\n",
      "##########\n",
      "epoch:29 step:140405[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:29 step:140410[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:29 step:140415[D loss: 0.999950] [G loss: 1.000088]\n",
      "epoch:29 step:140420[D loss: 0.999935] [G loss: 1.000117]\n",
      "epoch:29 step:140425[D loss: 1.000029] [G loss: 0.999947]\n",
      "epoch:29 step:140430[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:29 step:140435[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:29 step:140440[D loss: 1.000020] [G loss: 0.999950]\n",
      "epoch:29 step:140445[D loss: 1.000070] [G loss: 0.999856]\n",
      "epoch:29 step:140450[D loss: 1.000095] [G loss: 0.999957]\n",
      "epoch:29 step:140455[D loss: 0.999851] [G loss: 1.000160]\n",
      "epoch:29 step:140460[D loss: 0.999950] [G loss: 1.000064]\n",
      "epoch:29 step:140465[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:29 step:140470[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:29 step:140475[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:29 step:140480[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:29 step:140485[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:29 step:140490[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:29 step:140495[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:29 step:140500[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:29 step:140505[D loss: 0.999969] [G loss: 1.000027]\n",
      "epoch:29 step:140510[D loss: 0.999946] [G loss: 1.000178]\n",
      "epoch:29 step:140515[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:29 step:140520[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:29 step:140525[D loss: 0.999958] [G loss: 1.000109]\n",
      "epoch:29 step:140530[D loss: 1.000022] [G loss: 1.000045]\n",
      "epoch:29 step:140535[D loss: 0.999943] [G loss: 1.000108]\n",
      "epoch:29 step:140540[D loss: 1.000034] [G loss: 1.000026]\n",
      "epoch:29 step:140545[D loss: 0.999977] [G loss: 1.000001]\n",
      "epoch:29 step:140550[D loss: 0.999956] [G loss: 1.000038]\n",
      "epoch:30 step:140555[D loss: 0.999982] [G loss: 1.000106]\n",
      "epoch:30 step:140560[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:30 step:140565[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:30 step:140570[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:30 step:140575[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:30 step:140580[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:30 step:140585[D loss: 0.999985] [G loss: 1.000015]\n",
      "epoch:30 step:140590[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:30 step:140595[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:30 step:140600[D loss: 1.000008] [G loss: 1.000093]\n",
      "##############\n",
      "[2.53941242 2.12883157 2.02399994 3.54637795 1.47908393 6.94873619\n",
      " 2.4120305  3.80171527 4.0017887  4.58062682]\n",
      "##########\n",
      "epoch:30 step:140605[D loss: 1.000036] [G loss: 0.999996]\n",
      "epoch:30 step:140610[D loss: 0.999947] [G loss: 1.000009]\n",
      "epoch:30 step:140615[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:30 step:140620[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:30 step:140625[D loss: 1.000033] [G loss: 0.999997]\n",
      "epoch:30 step:140630[D loss: 0.999961] [G loss: 1.000109]\n",
      "epoch:30 step:140635[D loss: 0.999943] [G loss: 1.000168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:140640[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:30 step:140645[D loss: 1.000033] [G loss: 0.999955]\n",
      "epoch:30 step:140650[D loss: 0.999957] [G loss: 1.000046]\n",
      "epoch:30 step:140655[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:30 step:140660[D loss: 1.000039] [G loss: 1.000097]\n",
      "epoch:30 step:140665[D loss: 0.999929] [G loss: 1.000116]\n",
      "epoch:30 step:140670[D loss: 0.999970] [G loss: 1.000118]\n",
      "epoch:30 step:140675[D loss: 0.999941] [G loss: 1.000125]\n",
      "epoch:30 step:140680[D loss: 0.999962] [G loss: 1.000178]\n",
      "epoch:30 step:140685[D loss: 1.000021] [G loss: 1.000118]\n",
      "epoch:30 step:140690[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:30 step:140695[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:30 step:140700[D loss: 1.000016] [G loss: 0.999973]\n",
      "epoch:30 step:140705[D loss: 0.999943] [G loss: 1.000053]\n",
      "epoch:30 step:140710[D loss: 0.999965] [G loss: 1.000028]\n",
      "epoch:30 step:140715[D loss: 0.999950] [G loss: 1.000079]\n",
      "epoch:30 step:140720[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:30 step:140725[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:30 step:140730[D loss: 0.999960] [G loss: 1.000122]\n",
      "epoch:30 step:140735[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:30 step:140740[D loss: 0.999937] [G loss: 1.000124]\n",
      "epoch:30 step:140745[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:30 step:140750[D loss: 1.000024] [G loss: 0.999967]\n",
      "epoch:30 step:140755[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:30 step:140760[D loss: 1.000000] [G loss: 1.000023]\n",
      "epoch:30 step:140765[D loss: 1.000023] [G loss: 0.999989]\n",
      "epoch:30 step:140770[D loss: 0.999912] [G loss: 1.000142]\n",
      "epoch:30 step:140775[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:30 step:140780[D loss: 0.999943] [G loss: 1.000119]\n",
      "epoch:30 step:140785[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:30 step:140790[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:30 step:140795[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:30 step:140800[D loss: 0.999949] [G loss: 1.000125]\n",
      "##############\n",
      "[2.56988469 2.24693981 2.15423033 3.68175372 1.47400488 7.23270424\n",
      " 2.33818368 3.72471425 4.04755599 5.59564974]\n",
      "##########\n",
      "epoch:30 step:140805[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:30 step:140810[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:30 step:140815[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:30 step:140820[D loss: 1.000064] [G loss: 0.999916]\n",
      "epoch:30 step:140825[D loss: 0.999933] [G loss: 1.000122]\n",
      "epoch:30 step:140830[D loss: 0.999999] [G loss: 1.000013]\n",
      "epoch:30 step:140835[D loss: 0.999952] [G loss: 1.000102]\n",
      "epoch:30 step:140840[D loss: 0.999990] [G loss: 1.000100]\n",
      "epoch:30 step:140845[D loss: 0.999960] [G loss: 1.000126]\n",
      "epoch:30 step:140850[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:30 step:140855[D loss: 0.999983] [G loss: 1.000002]\n",
      "epoch:30 step:140860[D loss: 1.000017] [G loss: 1.000027]\n",
      "epoch:30 step:140865[D loss: 1.000011] [G loss: 1.000106]\n",
      "epoch:30 step:140870[D loss: 0.999927] [G loss: 1.000189]\n",
      "epoch:30 step:140875[D loss: 0.999969] [G loss: 1.000019]\n",
      "epoch:30 step:140880[D loss: 0.999977] [G loss: 1.000013]\n",
      "epoch:30 step:140885[D loss: 1.000048] [G loss: 0.999925]\n",
      "epoch:30 step:140890[D loss: 1.000046] [G loss: 1.000022]\n",
      "epoch:30 step:140895[D loss: 0.999997] [G loss: 1.000171]\n",
      "epoch:30 step:140900[D loss: 1.000025] [G loss: 0.999996]\n",
      "epoch:30 step:140905[D loss: 1.000156] [G loss: 0.999757]\n",
      "epoch:30 step:140910[D loss: 1.000041] [G loss: 1.000066]\n",
      "epoch:30 step:140915[D loss: 0.999943] [G loss: 1.000108]\n",
      "epoch:30 step:140920[D loss: 0.999961] [G loss: 0.999989]\n",
      "epoch:30 step:140925[D loss: 1.000037] [G loss: 1.000056]\n",
      "epoch:30 step:140930[D loss: 0.999970] [G loss: 1.000003]\n",
      "epoch:30 step:140935[D loss: 0.999949] [G loss: 1.000130]\n",
      "epoch:30 step:140940[D loss: 0.999910] [G loss: 1.000160]\n",
      "epoch:30 step:140945[D loss: 0.999860] [G loss: 1.000223]\n",
      "epoch:30 step:140950[D loss: 0.999940] [G loss: 1.000112]\n",
      "epoch:30 step:140955[D loss: 1.000126] [G loss: 0.999859]\n",
      "epoch:30 step:140960[D loss: 0.999935] [G loss: 1.000046]\n",
      "epoch:30 step:140965[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:30 step:140970[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:30 step:140975[D loss: 1.000042] [G loss: 0.999979]\n",
      "epoch:30 step:140980[D loss: 1.000016] [G loss: 0.999983]\n",
      "epoch:30 step:140985[D loss: 1.000085] [G loss: 0.999896]\n",
      "epoch:30 step:140990[D loss: 1.000026] [G loss: 0.999984]\n",
      "epoch:30 step:140995[D loss: 1.000013] [G loss: 1.000104]\n",
      "epoch:30 step:141000[D loss: 0.999941] [G loss: 1.000133]\n",
      "##############\n",
      "[2.52513268 2.2305824  2.11743742 3.71640022 1.48900591 7.9231402\n",
      " 2.39273203 3.93667393 4.02679221 5.42000994]\n",
      "##########\n",
      "epoch:30 step:141005[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:30 step:141010[D loss: 1.000010] [G loss: 0.999997]\n",
      "epoch:30 step:141015[D loss: 1.000041] [G loss: 0.999961]\n",
      "epoch:30 step:141020[D loss: 0.999887] [G loss: 1.000202]\n",
      "epoch:30 step:141025[D loss: 1.000130] [G loss: 0.999980]\n",
      "epoch:30 step:141030[D loss: 1.000070] [G loss: 1.000106]\n",
      "epoch:30 step:141035[D loss: 0.999953] [G loss: 1.000246]\n",
      "epoch:30 step:141040[D loss: 0.999954] [G loss: 1.000261]\n",
      "epoch:30 step:141045[D loss: 0.999818] [G loss: 1.000341]\n",
      "epoch:30 step:141050[D loss: 1.000002] [G loss: 0.999976]\n",
      "epoch:30 step:141055[D loss: 0.999942] [G loss: 1.000124]\n",
      "epoch:30 step:141060[D loss: 0.999934] [G loss: 1.000189]\n",
      "epoch:30 step:141065[D loss: 1.000001] [G loss: 0.999982]\n",
      "epoch:30 step:141070[D loss: 0.999978] [G loss: 1.000013]\n",
      "epoch:30 step:141075[D loss: 1.000045] [G loss: 0.999973]\n",
      "epoch:30 step:141080[D loss: 0.999909] [G loss: 1.000105]\n",
      "epoch:30 step:141085[D loss: 1.000029] [G loss: 1.000017]\n",
      "epoch:30 step:141090[D loss: 1.000199] [G loss: 0.999721]\n",
      "epoch:30 step:141095[D loss: 0.999938] [G loss: 0.999930]\n",
      "epoch:30 step:141100[D loss: 1.000200] [G loss: 0.999784]\n",
      "epoch:30 step:141105[D loss: 0.999940] [G loss: 1.000068]\n",
      "epoch:30 step:141110[D loss: 1.000095] [G loss: 0.999917]\n",
      "epoch:30 step:141115[D loss: 0.999935] [G loss: 1.000213]\n",
      "epoch:30 step:141120[D loss: 0.999937] [G loss: 1.000127]\n",
      "epoch:30 step:141125[D loss: 1.000007] [G loss: 1.000110]\n",
      "epoch:30 step:141130[D loss: 0.999934] [G loss: 1.000096]\n",
      "epoch:30 step:141135[D loss: 1.000079] [G loss: 0.999999]\n",
      "epoch:30 step:141140[D loss: 1.000177] [G loss: 0.999801]\n",
      "epoch:30 step:141145[D loss: 1.000022] [G loss: 1.000104]\n",
      "epoch:30 step:141150[D loss: 0.999896] [G loss: 1.000147]\n",
      "epoch:30 step:141155[D loss: 0.999967] [G loss: 1.000134]\n",
      "epoch:30 step:141160[D loss: 0.999959] [G loss: 1.000242]\n",
      "epoch:30 step:141165[D loss: 0.999960] [G loss: 1.000126]\n",
      "epoch:30 step:141170[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:30 step:141175[D loss: 1.000038] [G loss: 0.999962]\n",
      "epoch:30 step:141180[D loss: 0.999955] [G loss: 1.000063]\n",
      "epoch:30 step:141185[D loss: 0.999980] [G loss: 1.000003]\n",
      "epoch:30 step:141190[D loss: 1.000007] [G loss: 1.000021]\n",
      "epoch:30 step:141195[D loss: 1.000020] [G loss: 1.000085]\n",
      "epoch:30 step:141200[D loss: 0.999960] [G loss: 1.000050]\n",
      "##############\n",
      "[2.53538435 2.13744701 2.03974079 3.57616685 1.46944851 7.75045416\n",
      " 2.22837441 3.89556143 3.96592473 4.77051378]\n",
      "##########\n",
      "epoch:30 step:141205[D loss: 0.999960] [G loss: 1.000147]\n",
      "epoch:30 step:141210[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:30 step:141215[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:30 step:141220[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:30 step:141225[D loss: 1.000014] [G loss: 0.999992]\n",
      "epoch:30 step:141230[D loss: 0.999982] [G loss: 0.999995]\n",
      "epoch:30 step:141235[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:30 step:141240[D loss: 0.999938] [G loss: 1.000088]\n",
      "epoch:30 step:141245[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:30 step:141250[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:30 step:141255[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:30 step:141260[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:30 step:141265[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:30 step:141270[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:30 step:141275[D loss: 0.999947] [G loss: 1.000133]\n",
      "epoch:30 step:141280[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:30 step:141285[D loss: 1.000058] [G loss: 0.999942]\n",
      "epoch:30 step:141290[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:30 step:141295[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:30 step:141300[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:30 step:141305[D loss: 1.000015] [G loss: 1.000042]\n",
      "epoch:30 step:141310[D loss: 0.999947] [G loss: 1.000115]\n",
      "epoch:30 step:141315[D loss: 0.999946] [G loss: 1.000132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:141320[D loss: 0.999971] [G loss: 1.000129]\n",
      "epoch:30 step:141325[D loss: 0.999949] [G loss: 1.000187]\n",
      "epoch:30 step:141330[D loss: 1.000041] [G loss: 1.000048]\n",
      "epoch:30 step:141335[D loss: 0.999961] [G loss: 1.000044]\n",
      "epoch:30 step:141340[D loss: 1.000063] [G loss: 0.999800]\n",
      "epoch:30 step:141345[D loss: 0.999911] [G loss: 1.000069]\n",
      "epoch:30 step:141350[D loss: 1.000087] [G loss: 0.999897]\n",
      "epoch:30 step:141355[D loss: 1.000165] [G loss: 0.999780]\n",
      "epoch:30 step:141360[D loss: 1.000028] [G loss: 1.000038]\n",
      "epoch:30 step:141365[D loss: 1.000045] [G loss: 0.999835]\n",
      "epoch:30 step:141370[D loss: 0.999999] [G loss: 0.999965]\n",
      "epoch:30 step:141375[D loss: 0.999831] [G loss: 1.000126]\n",
      "epoch:30 step:141380[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:30 step:141385[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:30 step:141390[D loss: 1.000006] [G loss: 1.000087]\n",
      "epoch:30 step:141395[D loss: 0.999949] [G loss: 1.000099]\n",
      "epoch:30 step:141400[D loss: 0.999976] [G loss: 1.000078]\n",
      "##############\n",
      "[2.53275919 2.20359564 2.21150174 3.2943148  1.50005679 6.64812736\n",
      " 2.35651959 3.92581496 4.05971199 5.7805567 ]\n",
      "##########\n",
      "epoch:30 step:141405[D loss: 0.999945] [G loss: 1.000109]\n",
      "epoch:30 step:141410[D loss: 1.000036] [G loss: 1.000002]\n",
      "epoch:30 step:141415[D loss: 0.999983] [G loss: 1.000020]\n",
      "epoch:30 step:141420[D loss: 1.000013] [G loss: 1.000031]\n",
      "epoch:30 step:141425[D loss: 0.999998] [G loss: 1.000000]\n",
      "epoch:30 step:141430[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:30 step:141435[D loss: 0.999897] [G loss: 1.000153]\n",
      "epoch:30 step:141440[D loss: 1.000010] [G loss: 1.000126]\n",
      "epoch:30 step:141445[D loss: 1.000034] [G loss: 1.000067]\n",
      "epoch:30 step:141450[D loss: 0.999960] [G loss: 1.000053]\n",
      "epoch:30 step:141455[D loss: 0.999970] [G loss: 1.000181]\n",
      "epoch:30 step:141460[D loss: 0.999946] [G loss: 1.000214]\n",
      "epoch:30 step:141465[D loss: 0.999977] [G loss: 1.000119]\n",
      "epoch:30 step:141470[D loss: 0.999969] [G loss: 1.000113]\n",
      "epoch:30 step:141475[D loss: 1.000061] [G loss: 0.999897]\n",
      "epoch:30 step:141480[D loss: 1.000040] [G loss: 0.999914]\n",
      "epoch:30 step:141485[D loss: 1.000065] [G loss: 0.999976]\n",
      "epoch:30 step:141490[D loss: 1.000040] [G loss: 1.000136]\n",
      "epoch:30 step:141495[D loss: 0.999978] [G loss: 0.999959]\n",
      "epoch:30 step:141500[D loss: 0.999962] [G loss: 1.000016]\n",
      "epoch:30 step:141505[D loss: 0.999946] [G loss: 1.000125]\n",
      "epoch:30 step:141510[D loss: 0.999932] [G loss: 1.000156]\n",
      "epoch:30 step:141515[D loss: 0.999899] [G loss: 1.000332]\n",
      "epoch:30 step:141520[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:30 step:141525[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:30 step:141530[D loss: 1.000000] [G loss: 1.000003]\n",
      "epoch:30 step:141535[D loss: 1.000037] [G loss: 1.000110]\n",
      "epoch:30 step:141540[D loss: 1.000108] [G loss: 1.000046]\n",
      "epoch:30 step:141545[D loss: 1.000151] [G loss: 0.999785]\n",
      "epoch:30 step:141550[D loss: 0.999952] [G loss: 1.000246]\n",
      "epoch:30 step:141555[D loss: 0.999896] [G loss: 1.000240]\n",
      "epoch:30 step:141560[D loss: 0.999922] [G loss: 1.000218]\n",
      "epoch:30 step:141565[D loss: 0.999882] [G loss: 1.000280]\n",
      "epoch:30 step:141570[D loss: 0.999930] [G loss: 1.000137]\n",
      "epoch:30 step:141575[D loss: 0.999946] [G loss: 1.000110]\n",
      "epoch:30 step:141580[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:30 step:141585[D loss: 1.000030] [G loss: 0.999914]\n",
      "epoch:30 step:141590[D loss: 0.999894] [G loss: 1.000038]\n",
      "epoch:30 step:141595[D loss: 1.000067] [G loss: 0.999907]\n",
      "epoch:30 step:141600[D loss: 0.999987] [G loss: 1.000051]\n",
      "##############\n",
      "[2.50470745 2.18674393 2.11973092 3.24516373 1.39828015 7.41829323\n",
      " 2.22271814 3.52609299 3.87745049 4.0596279 ]\n",
      "##########\n",
      "epoch:30 step:141605[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:30 step:141610[D loss: 0.999943] [G loss: 1.000102]\n",
      "epoch:30 step:141615[D loss: 0.999923] [G loss: 1.000104]\n",
      "epoch:30 step:141620[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:30 step:141625[D loss: 1.000028] [G loss: 1.000128]\n",
      "epoch:30 step:141630[D loss: 1.000044] [G loss: 1.000198]\n",
      "epoch:30 step:141635[D loss: 1.000340] [G loss: 0.999860]\n",
      "epoch:30 step:141640[D loss: 0.999919] [G loss: 1.000130]\n",
      "epoch:30 step:141645[D loss: 0.999919] [G loss: 1.000132]\n",
      "epoch:30 step:141650[D loss: 1.000045] [G loss: 0.999988]\n",
      "epoch:30 step:141655[D loss: 0.999914] [G loss: 1.000109]\n",
      "epoch:30 step:141660[D loss: 0.999961] [G loss: 0.999962]\n",
      "epoch:30 step:141665[D loss: 1.000082] [G loss: 0.999837]\n",
      "epoch:30 step:141670[D loss: 0.999991] [G loss: 0.999939]\n",
      "epoch:30 step:141675[D loss: 1.000133] [G loss: 0.999873]\n",
      "epoch:30 step:141680[D loss: 1.000223] [G loss: 0.999870]\n",
      "epoch:30 step:141685[D loss: 1.000181] [G loss: 0.999944]\n",
      "epoch:30 step:141690[D loss: 0.999815] [G loss: 1.000273]\n",
      "epoch:30 step:141695[D loss: 0.999955] [G loss: 1.000044]\n",
      "epoch:30 step:141700[D loss: 0.999921] [G loss: 1.000297]\n",
      "epoch:30 step:141705[D loss: 0.999991] [G loss: 1.000078]\n",
      "epoch:30 step:141710[D loss: 1.000045] [G loss: 1.000067]\n",
      "epoch:30 step:141715[D loss: 0.999966] [G loss: 1.000336]\n",
      "epoch:30 step:141720[D loss: 1.000006] [G loss: 1.000158]\n",
      "epoch:30 step:141725[D loss: 0.999950] [G loss: 1.000396]\n",
      "epoch:30 step:141730[D loss: 0.999932] [G loss: 1.000196]\n",
      "epoch:30 step:141735[D loss: 0.999907] [G loss: 1.000237]\n",
      "epoch:30 step:141740[D loss: 0.999953] [G loss: 1.000048]\n",
      "epoch:30 step:141745[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:30 step:141750[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:30 step:141755[D loss: 1.000049] [G loss: 0.999956]\n",
      "epoch:30 step:141760[D loss: 1.000081] [G loss: 0.999853]\n",
      "epoch:30 step:141765[D loss: 0.999950] [G loss: 0.999872]\n",
      "epoch:30 step:141770[D loss: 1.000043] [G loss: 1.000085]\n",
      "epoch:30 step:141775[D loss: 1.000135] [G loss: 0.999784]\n",
      "epoch:30 step:141780[D loss: 0.999990] [G loss: 1.000096]\n",
      "epoch:30 step:141785[D loss: 0.999681] [G loss: 1.000198]\n",
      "epoch:30 step:141790[D loss: 0.999869] [G loss: 1.000360]\n",
      "epoch:30 step:141795[D loss: 1.000050] [G loss: 1.000029]\n",
      "epoch:30 step:141800[D loss: 0.999861] [G loss: 1.000183]\n",
      "##############\n",
      "[2.38230652 2.1580247  2.17632766 3.76466958 1.34113496 7.36446118\n",
      " 2.20781626 3.74232092 3.8605701  5.1051295 ]\n",
      "##########\n",
      "epoch:30 step:141805[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:30 step:141810[D loss: 1.000009] [G loss: 1.000027]\n",
      "epoch:30 step:141815[D loss: 1.000056] [G loss: 1.000042]\n",
      "epoch:30 step:141820[D loss: 1.000048] [G loss: 1.000002]\n",
      "epoch:30 step:141825[D loss: 0.999983] [G loss: 1.000164]\n",
      "epoch:30 step:141830[D loss: 0.999998] [G loss: 1.000009]\n",
      "epoch:30 step:141835[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:30 step:141840[D loss: 1.000010] [G loss: 1.000128]\n",
      "epoch:30 step:141845[D loss: 0.999953] [G loss: 1.000051]\n",
      "epoch:30 step:141850[D loss: 0.999942] [G loss: 1.000138]\n",
      "epoch:30 step:141855[D loss: 1.000015] [G loss: 1.000040]\n",
      "epoch:30 step:141860[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:30 step:141865[D loss: 0.999951] [G loss: 1.000132]\n",
      "epoch:30 step:141870[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:30 step:141875[D loss: 1.000015] [G loss: 1.000027]\n",
      "epoch:30 step:141880[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:30 step:141885[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:30 step:141890[D loss: 1.000030] [G loss: 0.999989]\n",
      "epoch:30 step:141895[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:30 step:141900[D loss: 1.000068] [G loss: 0.999967]\n",
      "epoch:30 step:141905[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:30 step:141910[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:30 step:141915[D loss: 0.999992] [G loss: 0.999991]\n",
      "epoch:30 step:141920[D loss: 1.000003] [G loss: 1.000109]\n",
      "epoch:30 step:141925[D loss: 0.999971] [G loss: 1.000029]\n",
      "epoch:30 step:141930[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:30 step:141935[D loss: 0.999989] [G loss: 1.000040]\n",
      "epoch:30 step:141940[D loss: 0.999969] [G loss: 1.000113]\n",
      "epoch:30 step:141945[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:30 step:141950[D loss: 0.999961] [G loss: 1.000105]\n",
      "epoch:30 step:141955[D loss: 0.999954] [G loss: 1.000099]\n",
      "epoch:30 step:141960[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:30 step:141965[D loss: 0.999950] [G loss: 1.000073]\n",
      "epoch:30 step:141970[D loss: 1.000026] [G loss: 1.000006]\n",
      "epoch:30 step:141975[D loss: 1.000009] [G loss: 1.000058]\n",
      "epoch:30 step:141980[D loss: 0.999968] [G loss: 1.000116]\n",
      "epoch:30 step:141985[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:30 step:141990[D loss: 1.000034] [G loss: 1.000104]\n",
      "epoch:30 step:141995[D loss: 0.999954] [G loss: 1.000137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:142000[D loss: 0.999977] [G loss: 1.000075]\n",
      "##############\n",
      "[2.53578807 2.26027711 2.20487051 3.70475152 1.4581177  7.91927867\n",
      " 2.15957609 3.63861605 4.10013706 5.50287582]\n",
      "##########\n",
      "epoch:30 step:142005[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:30 step:142010[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:30 step:142015[D loss: 1.000031] [G loss: 1.000029]\n",
      "epoch:30 step:142020[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:30 step:142025[D loss: 1.000022] [G loss: 1.000075]\n",
      "epoch:30 step:142030[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:30 step:142035[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:30 step:142040[D loss: 0.999950] [G loss: 1.000076]\n",
      "epoch:30 step:142045[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:30 step:142050[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:30 step:142055[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:30 step:142060[D loss: 1.000032] [G loss: 0.999958]\n",
      "epoch:30 step:142065[D loss: 1.000070] [G loss: 1.000035]\n",
      "epoch:30 step:142070[D loss: 0.999923] [G loss: 1.000088]\n",
      "epoch:30 step:142075[D loss: 1.000015] [G loss: 1.000095]\n",
      "epoch:30 step:142080[D loss: 0.999978] [G loss: 1.000117]\n",
      "epoch:30 step:142085[D loss: 0.999931] [G loss: 1.000176]\n",
      "epoch:30 step:142090[D loss: 0.999949] [G loss: 1.000101]\n",
      "epoch:30 step:142095[D loss: 0.999984] [G loss: 1.000005]\n",
      "epoch:30 step:142100[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:30 step:142105[D loss: 0.999984] [G loss: 1.000125]\n",
      "epoch:30 step:142110[D loss: 0.999971] [G loss: 1.000023]\n",
      "epoch:30 step:142115[D loss: 0.999997] [G loss: 0.999982]\n",
      "epoch:30 step:142120[D loss: 0.999937] [G loss: 1.000039]\n",
      "epoch:30 step:142125[D loss: 1.000008] [G loss: 1.000040]\n",
      "epoch:30 step:142130[D loss: 0.999970] [G loss: 1.000241]\n",
      "epoch:30 step:142135[D loss: 1.000002] [G loss: 1.000063]\n",
      "epoch:30 step:142140[D loss: 0.999998] [G loss: 1.000073]\n",
      "epoch:30 step:142145[D loss: 0.999954] [G loss: 1.000125]\n",
      "epoch:30 step:142150[D loss: 0.999977] [G loss: 1.000103]\n",
      "epoch:30 step:142155[D loss: 1.000046] [G loss: 1.000142]\n",
      "epoch:30 step:142160[D loss: 1.000003] [G loss: 1.000132]\n",
      "epoch:30 step:142165[D loss: 1.000175] [G loss: 0.999840]\n",
      "epoch:30 step:142170[D loss: 0.999943] [G loss: 1.000017]\n",
      "epoch:30 step:142175[D loss: 0.999955] [G loss: 1.000049]\n",
      "epoch:30 step:142180[D loss: 1.000122] [G loss: 0.999737]\n",
      "epoch:30 step:142185[D loss: 1.000097] [G loss: 0.999961]\n",
      "epoch:30 step:142190[D loss: 0.999855] [G loss: 1.000086]\n",
      "epoch:30 step:142195[D loss: 1.000146] [G loss: 1.000068]\n",
      "epoch:30 step:142200[D loss: 0.999846] [G loss: 1.000140]\n",
      "##############\n",
      "[2.56485601 2.26856815 2.18819272 3.41157097 1.53292379 7.74230408\n",
      " 2.39493154 3.6998974  4.17018921 4.36904337]\n",
      "##########\n",
      "epoch:30 step:142205[D loss: 0.999951] [G loss: 1.000098]\n",
      "epoch:30 step:142210[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:30 step:142215[D loss: 0.999975] [G loss: 1.000120]\n",
      "epoch:30 step:142220[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:30 step:142225[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:30 step:142230[D loss: 1.000009] [G loss: 1.000097]\n",
      "epoch:30 step:142235[D loss: 1.000020] [G loss: 1.000041]\n",
      "epoch:30 step:142240[D loss: 0.999948] [G loss: 1.000050]\n",
      "epoch:30 step:142245[D loss: 1.000005] [G loss: 1.000029]\n",
      "epoch:30 step:142250[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:30 step:142255[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:30 step:142260[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:30 step:142265[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:30 step:142270[D loss: 0.999985] [G loss: 1.000017]\n",
      "epoch:30 step:142275[D loss: 0.999929] [G loss: 1.000096]\n",
      "epoch:30 step:142280[D loss: 1.000098] [G loss: 1.000081]\n",
      "epoch:30 step:142285[D loss: 0.999916] [G loss: 1.000097]\n",
      "epoch:30 step:142290[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:30 step:142295[D loss: 1.000021] [G loss: 1.000068]\n",
      "epoch:30 step:142300[D loss: 0.999948] [G loss: 1.000086]\n",
      "epoch:30 step:142305[D loss: 1.000009] [G loss: 1.000108]\n",
      "epoch:30 step:142310[D loss: 0.999948] [G loss: 1.000177]\n",
      "epoch:30 step:142315[D loss: 0.999936] [G loss: 1.000216]\n",
      "epoch:30 step:142320[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:30 step:142325[D loss: 0.999948] [G loss: 1.000072]\n",
      "epoch:30 step:142330[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:30 step:142335[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:30 step:142340[D loss: 1.000113] [G loss: 0.999975]\n",
      "epoch:30 step:142345[D loss: 0.999973] [G loss: 0.999938]\n",
      "epoch:30 step:142350[D loss: 1.000153] [G loss: 0.999830]\n",
      "epoch:30 step:142355[D loss: 0.999941] [G loss: 1.000129]\n",
      "epoch:30 step:142360[D loss: 0.999942] [G loss: 1.000043]\n",
      "epoch:30 step:142365[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:30 step:142370[D loss: 0.999998] [G loss: 1.000078]\n",
      "epoch:30 step:142375[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:30 step:142380[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:30 step:142385[D loss: 0.999937] [G loss: 1.000250]\n",
      "epoch:30 step:142390[D loss: 1.000062] [G loss: 0.999887]\n",
      "epoch:30 step:142395[D loss: 1.000153] [G loss: 0.999875]\n",
      "epoch:30 step:142400[D loss: 0.999893] [G loss: 1.000274]\n",
      "##############\n",
      "[2.52772753 2.1906595  2.07999895 3.41974135 1.46273173 7.69772973\n",
      " 2.36748902 3.76016618 4.07224424 5.46034762]\n",
      "##########\n",
      "epoch:30 step:142405[D loss: 0.999947] [G loss: 1.000119]\n",
      "epoch:30 step:142410[D loss: 0.999907] [G loss: 1.000200]\n",
      "epoch:30 step:142415[D loss: 0.999923] [G loss: 1.000108]\n",
      "epoch:30 step:142420[D loss: 1.000009] [G loss: 1.000145]\n",
      "epoch:30 step:142425[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:30 step:142430[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:30 step:142435[D loss: 0.999997] [G loss: 1.000019]\n",
      "epoch:30 step:142440[D loss: 1.000138] [G loss: 0.999849]\n",
      "epoch:30 step:142445[D loss: 1.000072] [G loss: 0.999800]\n",
      "epoch:30 step:142450[D loss: 0.999859] [G loss: 1.000160]\n",
      "epoch:30 step:142455[D loss: 1.000072] [G loss: 0.999942]\n",
      "epoch:30 step:142460[D loss: 0.999907] [G loss: 1.000164]\n",
      "epoch:30 step:142465[D loss: 0.999930] [G loss: 1.000101]\n",
      "epoch:30 step:142470[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:30 step:142475[D loss: 1.000072] [G loss: 0.999986]\n",
      "epoch:30 step:142480[D loss: 0.999921] [G loss: 1.000102]\n",
      "epoch:30 step:142485[D loss: 1.000026] [G loss: 1.000075]\n",
      "epoch:30 step:142490[D loss: 1.000017] [G loss: 1.000017]\n",
      "epoch:30 step:142495[D loss: 0.999913] [G loss: 1.000073]\n",
      "epoch:30 step:142500[D loss: 1.000086] [G loss: 1.000084]\n",
      "epoch:30 step:142505[D loss: 0.999935] [G loss: 1.000068]\n",
      "epoch:30 step:142510[D loss: 1.000035] [G loss: 1.000092]\n",
      "epoch:30 step:142515[D loss: 1.000012] [G loss: 1.000015]\n",
      "epoch:30 step:142520[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:30 step:142525[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:30 step:142530[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:30 step:142535[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:30 step:142540[D loss: 1.000068] [G loss: 0.999858]\n",
      "epoch:30 step:142545[D loss: 0.999938] [G loss: 1.000056]\n",
      "epoch:30 step:142550[D loss: 1.000016] [G loss: 1.000003]\n",
      "epoch:30 step:142555[D loss: 1.000089] [G loss: 0.999892]\n",
      "epoch:30 step:142560[D loss: 0.999857] [G loss: 1.000269]\n",
      "epoch:30 step:142565[D loss: 0.999958] [G loss: 1.000195]\n",
      "epoch:30 step:142570[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:30 step:142575[D loss: 0.999890] [G loss: 1.000117]\n",
      "epoch:30 step:142580[D loss: 0.999959] [G loss: 1.000110]\n",
      "epoch:30 step:142585[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:30 step:142590[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:30 step:142595[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:30 step:142600[D loss: 1.000035] [G loss: 1.000024]\n",
      "##############\n",
      "[2.54111749 2.23328212 2.15315835 3.36185152 1.39199639 7.20876366\n",
      " 2.28833771 3.80798154 3.98142095 4.84672335]\n",
      "##########\n",
      "epoch:30 step:142605[D loss: 1.000041] [G loss: 0.999895]\n",
      "epoch:30 step:142610[D loss: 0.999948] [G loss: 1.000066]\n",
      "epoch:30 step:142615[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:30 step:142620[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:30 step:142625[D loss: 1.000005] [G loss: 1.000050]\n",
      "epoch:30 step:142630[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:30 step:142635[D loss: 0.999929] [G loss: 1.000150]\n",
      "epoch:30 step:142640[D loss: 0.999948] [G loss: 1.000158]\n",
      "epoch:30 step:142645[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:30 step:142650[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:30 step:142655[D loss: 0.999980] [G loss: 1.000166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:142660[D loss: 0.999970] [G loss: 1.000166]\n",
      "epoch:30 step:142665[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:30 step:142670[D loss: 0.999932] [G loss: 1.000191]\n",
      "epoch:30 step:142675[D loss: 0.999938] [G loss: 1.000175]\n",
      "epoch:30 step:142680[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:30 step:142685[D loss: 0.999989] [G loss: 0.999946]\n",
      "epoch:30 step:142690[D loss: 1.000000] [G loss: 0.999990]\n",
      "epoch:30 step:142695[D loss: 1.000083] [G loss: 0.999915]\n",
      "epoch:30 step:142700[D loss: 1.000072] [G loss: 0.999901]\n",
      "epoch:30 step:142705[D loss: 0.999937] [G loss: 1.000026]\n",
      "epoch:30 step:142710[D loss: 0.999972] [G loss: 1.000127]\n",
      "epoch:30 step:142715[D loss: 0.999949] [G loss: 1.000076]\n",
      "epoch:30 step:142720[D loss: 1.000079] [G loss: 1.000030]\n",
      "epoch:30 step:142725[D loss: 0.999906] [G loss: 1.000221]\n",
      "epoch:30 step:142730[D loss: 0.999915] [G loss: 1.000089]\n",
      "epoch:30 step:142735[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:30 step:142740[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:30 step:142745[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:30 step:142750[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:30 step:142755[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:30 step:142760[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:30 step:142765[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:30 step:142770[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:30 step:142775[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:30 step:142780[D loss: 1.000009] [G loss: 1.000090]\n",
      "epoch:30 step:142785[D loss: 1.000086] [G loss: 0.999987]\n",
      "epoch:30 step:142790[D loss: 1.000044] [G loss: 1.000023]\n",
      "epoch:30 step:142795[D loss: 0.999974] [G loss: 1.000113]\n",
      "epoch:30 step:142800[D loss: 0.999982] [G loss: 1.000133]\n",
      "##############\n",
      "[2.52140178 2.12554178 2.17045208 3.70020819 1.38750197 7.07473976\n",
      " 2.36190022 3.56151536 4.03567448 5.25879754]\n",
      "##########\n",
      "epoch:30 step:142805[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:30 step:142810[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:30 step:142815[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:30 step:142820[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:30 step:142825[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:30 step:142830[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:30 step:142835[D loss: 1.000023] [G loss: 1.000028]\n",
      "epoch:30 step:142840[D loss: 1.000126] [G loss: 0.999940]\n",
      "epoch:30 step:142845[D loss: 1.000073] [G loss: 1.000369]\n",
      "epoch:30 step:142850[D loss: 0.999934] [G loss: 1.000058]\n",
      "epoch:30 step:142855[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:30 step:142860[D loss: 0.999900] [G loss: 1.000115]\n",
      "epoch:30 step:142865[D loss: 0.999933] [G loss: 1.000106]\n",
      "epoch:30 step:142870[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:30 step:142875[D loss: 1.000012] [G loss: 1.000030]\n",
      "epoch:30 step:142880[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:30 step:142885[D loss: 0.999937] [G loss: 1.000115]\n",
      "epoch:30 step:142890[D loss: 1.000053] [G loss: 1.000014]\n",
      "epoch:30 step:142895[D loss: 1.000178] [G loss: 0.999850]\n",
      "epoch:30 step:142900[D loss: 0.999878] [G loss: 1.000145]\n",
      "epoch:30 step:142905[D loss: 0.999994] [G loss: 1.000102]\n",
      "epoch:30 step:142910[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:30 step:142915[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:30 step:142920[D loss: 1.000007] [G loss: 1.000006]\n",
      "epoch:30 step:142925[D loss: 0.999949] [G loss: 1.000085]\n",
      "epoch:30 step:142930[D loss: 1.000020] [G loss: 0.999994]\n",
      "epoch:30 step:142935[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:30 step:142940[D loss: 0.999983] [G loss: 1.000106]\n",
      "epoch:30 step:142945[D loss: 0.999943] [G loss: 1.000103]\n",
      "epoch:30 step:142950[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:30 step:142955[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:30 step:142960[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:30 step:142965[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:30 step:142970[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:30 step:142975[D loss: 1.000123] [G loss: 0.999920]\n",
      "epoch:30 step:142980[D loss: 0.999931] [G loss: 1.000068]\n",
      "epoch:30 step:142985[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:30 step:142990[D loss: 1.000014] [G loss: 1.000119]\n",
      "epoch:30 step:142995[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:30 step:143000[D loss: 0.999962] [G loss: 1.000105]\n",
      "##############\n",
      "[2.50781239 2.19787794 2.14840693 3.80777738 1.50711001 7.46986639\n",
      " 2.25425677 3.71721513 4.03466733 5.02130703]\n",
      "##########\n",
      "epoch:30 step:143005[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:30 step:143010[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:30 step:143015[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:30 step:143020[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:30 step:143025[D loss: 1.000011] [G loss: 0.999982]\n",
      "epoch:30 step:143030[D loss: 1.000034] [G loss: 1.000074]\n",
      "epoch:30 step:143035[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:30 step:143040[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:30 step:143045[D loss: 0.999940] [G loss: 1.000118]\n",
      "epoch:30 step:143050[D loss: 1.000035] [G loss: 1.000043]\n",
      "epoch:30 step:143055[D loss: 0.999908] [G loss: 1.000103]\n",
      "epoch:30 step:143060[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:30 step:143065[D loss: 0.999924] [G loss: 1.000123]\n",
      "epoch:30 step:143070[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:30 step:143075[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:30 step:143080[D loss: 0.999945] [G loss: 1.000125]\n",
      "epoch:30 step:143085[D loss: 1.000030] [G loss: 1.000018]\n",
      "epoch:30 step:143090[D loss: 1.000038] [G loss: 1.000096]\n",
      "epoch:30 step:143095[D loss: 0.999901] [G loss: 1.000193]\n",
      "epoch:30 step:143100[D loss: 1.000162] [G loss: 1.000072]\n",
      "epoch:30 step:143105[D loss: 0.999863] [G loss: 1.000242]\n",
      "epoch:30 step:143110[D loss: 0.999930] [G loss: 1.000084]\n",
      "epoch:30 step:143115[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:30 step:143120[D loss: 0.999979] [G loss: 1.000005]\n",
      "epoch:30 step:143125[D loss: 0.999941] [G loss: 1.000096]\n",
      "epoch:30 step:143130[D loss: 0.999977] [G loss: 1.000032]\n",
      "epoch:30 step:143135[D loss: 1.000110] [G loss: 0.999993]\n",
      "epoch:30 step:143140[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:30 step:143145[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:30 step:143150[D loss: 0.999958] [G loss: 1.000283]\n",
      "epoch:30 step:143155[D loss: 1.000091] [G loss: 0.999993]\n",
      "epoch:30 step:143160[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:30 step:143165[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:30 step:143170[D loss: 0.999941] [G loss: 1.000172]\n",
      "epoch:30 step:143175[D loss: 1.000015] [G loss: 0.999971]\n",
      "epoch:30 step:143180[D loss: 1.000047] [G loss: 0.999955]\n",
      "epoch:30 step:143185[D loss: 0.999973] [G loss: 0.999975]\n",
      "epoch:30 step:143190[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:30 step:143195[D loss: 1.000075] [G loss: 0.999774]\n",
      "epoch:30 step:143200[D loss: 0.999936] [G loss: 1.000074]\n",
      "##############\n",
      "[2.41365152 2.1306697  2.0930313  3.3587325  1.37973532 6.72572178\n",
      " 2.13252027 3.66764377 3.94713442 5.02431261]\n",
      "##########\n",
      "epoch:30 step:143205[D loss: 1.000012] [G loss: 1.000101]\n",
      "epoch:30 step:143210[D loss: 0.999946] [G loss: 1.000092]\n",
      "epoch:30 step:143215[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:30 step:143220[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:30 step:143225[D loss: 0.999963] [G loss: 1.000043]\n",
      "epoch:30 step:143230[D loss: 1.000000] [G loss: 1.000138]\n",
      "epoch:30 step:143235[D loss: 1.000066] [G loss: 0.999978]\n",
      "epoch:30 step:143240[D loss: 0.999938] [G loss: 1.000139]\n",
      "epoch:30 step:143245[D loss: 0.999962] [G loss: 1.000159]\n",
      "epoch:30 step:143250[D loss: 0.999904] [G loss: 1.000190]\n",
      "epoch:30 step:143255[D loss: 0.999946] [G loss: 1.000146]\n",
      "epoch:30 step:143260[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:30 step:143265[D loss: 1.000063] [G loss: 0.999980]\n",
      "epoch:30 step:143270[D loss: 1.000027] [G loss: 0.999920]\n",
      "epoch:30 step:143275[D loss: 1.000005] [G loss: 1.000022]\n",
      "epoch:30 step:143280[D loss: 1.000034] [G loss: 0.999961]\n",
      "epoch:30 step:143285[D loss: 0.999899] [G loss: 1.000107]\n",
      "epoch:30 step:143290[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:30 step:143295[D loss: 1.000009] [G loss: 1.000066]\n",
      "epoch:30 step:143300[D loss: 1.000040] [G loss: 0.999991]\n",
      "epoch:30 step:143305[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:30 step:143310[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:30 step:143315[D loss: 0.999982] [G loss: 1.000106]\n",
      "epoch:30 step:143320[D loss: 0.999935] [G loss: 1.000074]\n",
      "epoch:30 step:143325[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:30 step:143330[D loss: 1.000024] [G loss: 0.999976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:143335[D loss: 1.000018] [G loss: 0.999997]\n",
      "epoch:30 step:143340[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:30 step:143345[D loss: 1.000024] [G loss: 1.000046]\n",
      "epoch:30 step:143350[D loss: 0.999927] [G loss: 1.000101]\n",
      "epoch:30 step:143355[D loss: 0.999976] [G loss: 1.000114]\n",
      "epoch:30 step:143360[D loss: 0.999925] [G loss: 1.000121]\n",
      "epoch:30 step:143365[D loss: 1.000014] [G loss: 1.000070]\n",
      "epoch:30 step:143370[D loss: 0.999930] [G loss: 1.000098]\n",
      "epoch:30 step:143375[D loss: 0.999949] [G loss: 1.000131]\n",
      "epoch:30 step:143380[D loss: 0.999918] [G loss: 1.000131]\n",
      "epoch:30 step:143385[D loss: 1.000024] [G loss: 0.999978]\n",
      "epoch:30 step:143390[D loss: 0.999930] [G loss: 1.000121]\n",
      "epoch:30 step:143395[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:30 step:143400[D loss: 1.000031] [G loss: 0.999977]\n",
      "##############\n",
      "[2.51536017 2.11024612 2.15264627 3.45082428 1.42027688 6.62745414\n",
      " 2.32144334 3.67960919 4.02110074 5.20533289]\n",
      "##########\n",
      "epoch:30 step:143405[D loss: 0.999993] [G loss: 0.999974]\n",
      "epoch:30 step:143410[D loss: 0.999921] [G loss: 1.000155]\n",
      "epoch:30 step:143415[D loss: 1.000012] [G loss: 1.000052]\n",
      "epoch:30 step:143420[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:30 step:143425[D loss: 1.000130] [G loss: 0.999933]\n",
      "epoch:30 step:143430[D loss: 0.999913] [G loss: 1.000168]\n",
      "epoch:30 step:143435[D loss: 0.999962] [G loss: 1.000028]\n",
      "epoch:30 step:143440[D loss: 0.999989] [G loss: 1.000182]\n",
      "epoch:30 step:143445[D loss: 0.999937] [G loss: 1.000081]\n",
      "epoch:30 step:143450[D loss: 1.000055] [G loss: 1.000131]\n",
      "epoch:30 step:143455[D loss: 0.999945] [G loss: 1.000061]\n",
      "epoch:30 step:143460[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:30 step:143465[D loss: 1.000005] [G loss: 0.999962]\n",
      "epoch:30 step:143470[D loss: 0.999941] [G loss: 1.000049]\n",
      "epoch:30 step:143475[D loss: 1.000013] [G loss: 1.000005]\n",
      "epoch:30 step:143480[D loss: 1.000013] [G loss: 0.999892]\n",
      "epoch:30 step:143485[D loss: 1.000023] [G loss: 1.000165]\n",
      "epoch:30 step:143490[D loss: 0.999989] [G loss: 1.000273]\n",
      "epoch:30 step:143495[D loss: 1.000130] [G loss: 0.999997]\n",
      "epoch:30 step:143500[D loss: 0.999936] [G loss: 1.000171]\n",
      "epoch:30 step:143505[D loss: 0.999930] [G loss: 1.000126]\n",
      "epoch:30 step:143510[D loss: 1.000058] [G loss: 0.999948]\n",
      "epoch:30 step:143515[D loss: 1.000113] [G loss: 0.999942]\n",
      "epoch:30 step:143520[D loss: 1.000068] [G loss: 0.999770]\n",
      "epoch:30 step:143525[D loss: 1.000103] [G loss: 1.000144]\n",
      "epoch:30 step:143530[D loss: 0.999858] [G loss: 1.000243]\n",
      "epoch:30 step:143535[D loss: 1.000008] [G loss: 1.000042]\n",
      "epoch:30 step:143540[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:30 step:143545[D loss: 0.999861] [G loss: 1.000169]\n",
      "epoch:30 step:143550[D loss: 1.000045] [G loss: 0.999972]\n",
      "epoch:30 step:143555[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:30 step:143560[D loss: 0.999985] [G loss: 1.000011]\n",
      "epoch:30 step:143565[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:30 step:143570[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:30 step:143575[D loss: 0.999921] [G loss: 1.000055]\n",
      "epoch:30 step:143580[D loss: 1.000008] [G loss: 0.999975]\n",
      "epoch:30 step:143585[D loss: 0.999961] [G loss: 1.000042]\n",
      "epoch:30 step:143590[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:30 step:143595[D loss: 1.000009] [G loss: 1.000135]\n",
      "epoch:30 step:143600[D loss: 0.999895] [G loss: 1.000097]\n",
      "##############\n",
      "[2.51576486 2.1239405  2.02870153 3.6440329  1.45391844 7.09296516\n",
      " 2.17853607 3.73073126 3.93643065 5.00927927]\n",
      "##########\n",
      "epoch:30 step:143605[D loss: 0.999957] [G loss: 1.000104]\n",
      "epoch:30 step:143610[D loss: 1.000021] [G loss: 1.000038]\n",
      "epoch:30 step:143615[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:30 step:143620[D loss: 1.000010] [G loss: 0.999985]\n",
      "epoch:30 step:143625[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:30 step:143630[D loss: 0.999953] [G loss: 1.000055]\n",
      "epoch:30 step:143635[D loss: 1.000131] [G loss: 0.999976]\n",
      "epoch:30 step:143640[D loss: 0.999973] [G loss: 1.000137]\n",
      "epoch:30 step:143645[D loss: 0.999938] [G loss: 1.000059]\n",
      "epoch:30 step:143650[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:30 step:143655[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:30 step:143660[D loss: 0.999940] [G loss: 1.000093]\n",
      "epoch:30 step:143665[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:30 step:143670[D loss: 0.999905] [G loss: 1.000109]\n",
      "epoch:30 step:143675[D loss: 1.000019] [G loss: 1.000038]\n",
      "epoch:30 step:143680[D loss: 0.999916] [G loss: 1.000084]\n",
      "epoch:30 step:143685[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:30 step:143690[D loss: 0.999977] [G loss: 1.000011]\n",
      "epoch:30 step:143695[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:30 step:143700[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:30 step:143705[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:30 step:143710[D loss: 1.000075] [G loss: 0.999926]\n",
      "epoch:30 step:143715[D loss: 0.999918] [G loss: 1.000176]\n",
      "epoch:30 step:143720[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:30 step:143725[D loss: 1.000041] [G loss: 0.999915]\n",
      "epoch:30 step:143730[D loss: 0.999974] [G loss: 1.000023]\n",
      "epoch:30 step:143735[D loss: 1.000136] [G loss: 0.999795]\n",
      "epoch:30 step:143740[D loss: 0.999875] [G loss: 1.000081]\n",
      "epoch:30 step:143745[D loss: 0.999939] [G loss: 0.999994]\n",
      "epoch:30 step:143750[D loss: 1.000051] [G loss: 1.000098]\n",
      "epoch:30 step:143755[D loss: 1.000067] [G loss: 0.999981]\n",
      "epoch:30 step:143760[D loss: 0.999920] [G loss: 1.000221]\n",
      "epoch:30 step:143765[D loss: 0.999917] [G loss: 1.000084]\n",
      "epoch:30 step:143770[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:30 step:143775[D loss: 1.000008] [G loss: 0.999980]\n",
      "epoch:30 step:143780[D loss: 1.000055] [G loss: 0.999957]\n",
      "epoch:30 step:143785[D loss: 0.999955] [G loss: 0.999982]\n",
      "epoch:30 step:143790[D loss: 0.999938] [G loss: 1.000132]\n",
      "epoch:30 step:143795[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:30 step:143800[D loss: 0.999987] [G loss: 1.000048]\n",
      "##############\n",
      "[2.52447251 2.15848279 2.15675976 3.55824564 1.41801735 6.6728416\n",
      " 2.20578903 3.67322597 3.94438685 4.56682716]\n",
      "##########\n",
      "epoch:30 step:143805[D loss: 1.000022] [G loss: 1.000084]\n",
      "epoch:30 step:143810[D loss: 0.999935] [G loss: 1.000083]\n",
      "epoch:30 step:143815[D loss: 0.999997] [G loss: 1.000075]\n",
      "epoch:30 step:143820[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:30 step:143825[D loss: 0.999981] [G loss: 1.000030]\n",
      "epoch:30 step:143830[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:30 step:143835[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:30 step:143840[D loss: 0.999984] [G loss: 1.000117]\n",
      "epoch:30 step:143845[D loss: 0.999987] [G loss: 1.000111]\n",
      "epoch:30 step:143850[D loss: 0.999981] [G loss: 1.000032]\n",
      "epoch:30 step:143855[D loss: 0.999989] [G loss: 1.000091]\n",
      "epoch:30 step:143860[D loss: 1.000040] [G loss: 1.000101]\n",
      "epoch:30 step:143865[D loss: 0.999961] [G loss: 1.000188]\n",
      "epoch:30 step:143870[D loss: 0.999851] [G loss: 1.000199]\n",
      "epoch:30 step:143875[D loss: 0.999970] [G loss: 1.000012]\n",
      "epoch:30 step:143880[D loss: 1.000050] [G loss: 0.999898]\n",
      "epoch:30 step:143885[D loss: 0.999953] [G loss: 0.999952]\n",
      "epoch:30 step:143890[D loss: 0.999918] [G loss: 1.000060]\n",
      "epoch:30 step:143895[D loss: 1.000013] [G loss: 0.999982]\n",
      "epoch:30 step:143900[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:30 step:143905[D loss: 0.999974] [G loss: 1.000021]\n",
      "epoch:30 step:143910[D loss: 1.000029] [G loss: 0.999924]\n",
      "epoch:30 step:143915[D loss: 0.999991] [G loss: 1.000121]\n",
      "epoch:30 step:143920[D loss: 0.999897] [G loss: 1.000105]\n",
      "epoch:30 step:143925[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:30 step:143930[D loss: 0.999974] [G loss: 1.000015]\n",
      "epoch:30 step:143935[D loss: 0.999995] [G loss: 0.999947]\n",
      "epoch:30 step:143940[D loss: 1.000086] [G loss: 0.999879]\n",
      "epoch:30 step:143945[D loss: 1.000001] [G loss: 0.999984]\n",
      "epoch:30 step:143950[D loss: 1.000017] [G loss: 0.999961]\n",
      "epoch:30 step:143955[D loss: 1.000007] [G loss: 0.999960]\n",
      "epoch:30 step:143960[D loss: 0.999940] [G loss: 1.000215]\n",
      "epoch:30 step:143965[D loss: 0.999914] [G loss: 1.000105]\n",
      "epoch:30 step:143970[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:30 step:143975[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:30 step:143980[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:30 step:143985[D loss: 0.999999] [G loss: 1.000086]\n",
      "epoch:30 step:143990[D loss: 1.000062] [G loss: 0.999947]\n",
      "epoch:30 step:143995[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:30 step:144000[D loss: 0.999941] [G loss: 1.000093]\n",
      "##############\n",
      "[2.53067977 2.11418846 2.15238393 3.41695309 1.44484615 7.16339027\n",
      " 2.1986388  3.72941711 3.93523737 6.66032394]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:144005[D loss: 0.999955] [G loss: 1.000131]\n",
      "epoch:30 step:144010[D loss: 0.999947] [G loss: 1.000117]\n",
      "epoch:30 step:144015[D loss: 1.000154] [G loss: 0.999913]\n",
      "epoch:30 step:144020[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:30 step:144025[D loss: 0.999895] [G loss: 1.000130]\n",
      "epoch:30 step:144030[D loss: 0.999989] [G loss: 1.000020]\n",
      "epoch:30 step:144035[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:30 step:144040[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:30 step:144045[D loss: 0.999957] [G loss: 1.000097]\n",
      "epoch:30 step:144050[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:30 step:144055[D loss: 0.999999] [G loss: 1.000021]\n",
      "epoch:30 step:144060[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:30 step:144065[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:30 step:144070[D loss: 0.999935] [G loss: 1.000126]\n",
      "epoch:30 step:144075[D loss: 0.999995] [G loss: 1.000015]\n",
      "epoch:30 step:144080[D loss: 1.000045] [G loss: 0.999986]\n",
      "epoch:30 step:144085[D loss: 1.000034] [G loss: 0.999978]\n",
      "epoch:30 step:144090[D loss: 1.000038] [G loss: 1.000101]\n",
      "epoch:30 step:144095[D loss: 0.999944] [G loss: 0.999989]\n",
      "epoch:30 step:144100[D loss: 0.999935] [G loss: 1.000071]\n",
      "epoch:30 step:144105[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:30 step:144110[D loss: 0.999940] [G loss: 1.000087]\n",
      "epoch:30 step:144115[D loss: 0.999976] [G loss: 1.000000]\n",
      "epoch:30 step:144120[D loss: 1.000280] [G loss: 0.999805]\n",
      "epoch:30 step:144125[D loss: 1.000141] [G loss: 0.999887]\n",
      "epoch:30 step:144130[D loss: 0.999990] [G loss: 0.999918]\n",
      "epoch:30 step:144135[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:30 step:144140[D loss: 0.999920] [G loss: 1.000172]\n",
      "epoch:30 step:144145[D loss: 0.999955] [G loss: 1.000064]\n",
      "epoch:30 step:144150[D loss: 1.000031] [G loss: 1.000036]\n",
      "epoch:30 step:144155[D loss: 0.999936] [G loss: 1.000110]\n",
      "epoch:30 step:144160[D loss: 1.000018] [G loss: 1.000086]\n",
      "epoch:30 step:144165[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:30 step:144170[D loss: 1.000028] [G loss: 1.000004]\n",
      "epoch:30 step:144175[D loss: 0.999984] [G loss: 0.999924]\n",
      "epoch:30 step:144180[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:30 step:144185[D loss: 1.000089] [G loss: 0.999878]\n",
      "epoch:30 step:144190[D loss: 0.999918] [G loss: 1.000056]\n",
      "epoch:30 step:144195[D loss: 0.999915] [G loss: 1.000147]\n",
      "epoch:30 step:144200[D loss: 1.000054] [G loss: 1.000001]\n",
      "##############\n",
      "[2.52298092 2.11512898 2.11126606 3.52522054 1.43179395 6.92409339\n",
      " 2.39012012 3.58407366 3.99557745 5.15849642]\n",
      "##########\n",
      "epoch:30 step:144205[D loss: 0.999964] [G loss: 1.000010]\n",
      "epoch:30 step:144210[D loss: 0.999977] [G loss: 1.000099]\n",
      "epoch:30 step:144215[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:30 step:144220[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:30 step:144225[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:30 step:144230[D loss: 0.999959] [G loss: 1.000135]\n",
      "epoch:30 step:144235[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:30 step:144240[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:30 step:144245[D loss: 0.999997] [G loss: 1.000155]\n",
      "epoch:30 step:144250[D loss: 0.999939] [G loss: 1.000205]\n",
      "epoch:30 step:144255[D loss: 0.999940] [G loss: 1.000145]\n",
      "epoch:30 step:144260[D loss: 1.000137] [G loss: 1.000032]\n",
      "epoch:30 step:144265[D loss: 0.999803] [G loss: 1.000099]\n",
      "epoch:30 step:144270[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:30 step:144275[D loss: 0.999979] [G loss: 0.999974]\n",
      "epoch:30 step:144280[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:30 step:144285[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:30 step:144290[D loss: 0.999995] [G loss: 1.000017]\n",
      "epoch:30 step:144295[D loss: 0.999980] [G loss: 1.000007]\n",
      "epoch:30 step:144300[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:30 step:144305[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:30 step:144310[D loss: 0.999944] [G loss: 1.000094]\n",
      "epoch:30 step:144315[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:30 step:144320[D loss: 1.000093] [G loss: 0.999893]\n",
      "epoch:30 step:144325[D loss: 0.999935] [G loss: 1.000139]\n",
      "epoch:30 step:144330[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:30 step:144335[D loss: 0.999987] [G loss: 0.999954]\n",
      "epoch:30 step:144340[D loss: 1.000055] [G loss: 0.999920]\n",
      "epoch:30 step:144345[D loss: 0.999913] [G loss: 1.000037]\n",
      "epoch:30 step:144350[D loss: 1.000032] [G loss: 1.000023]\n",
      "epoch:30 step:144355[D loss: 1.000008] [G loss: 1.000103]\n",
      "epoch:30 step:144360[D loss: 0.999912] [G loss: 1.000369]\n",
      "epoch:30 step:144365[D loss: 0.999907] [G loss: 1.000194]\n",
      "epoch:30 step:144370[D loss: 0.999893] [G loss: 1.000173]\n",
      "epoch:30 step:144375[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:30 step:144380[D loss: 0.999988] [G loss: 1.000100]\n",
      "epoch:30 step:144385[D loss: 1.000017] [G loss: 1.000056]\n",
      "epoch:30 step:144390[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:30 step:144395[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:30 step:144400[D loss: 1.000011] [G loss: 0.999989]\n",
      "##############\n",
      "[2.52675625 2.10132422 2.24695282 3.81862058 1.40187846 7.09271774\n",
      " 2.34734552 3.64957546 3.91687285 5.75817261]\n",
      "##########\n",
      "epoch:30 step:144405[D loss: 0.999983] [G loss: 1.000101]\n",
      "epoch:30 step:144410[D loss: 1.000102] [G loss: 0.999794]\n",
      "epoch:30 step:144415[D loss: 1.000096] [G loss: 0.999769]\n",
      "epoch:30 step:144420[D loss: 1.000178] [G loss: 0.999857]\n",
      "epoch:30 step:144425[D loss: 0.999781] [G loss: 1.000256]\n",
      "epoch:30 step:144430[D loss: 1.000027] [G loss: 1.000040]\n",
      "epoch:30 step:144435[D loss: 0.999972] [G loss: 0.999977]\n",
      "epoch:30 step:144440[D loss: 0.999956] [G loss: 1.000050]\n",
      "epoch:30 step:144445[D loss: 1.000007] [G loss: 0.999987]\n",
      "epoch:30 step:144450[D loss: 0.999991] [G loss: 0.999929]\n",
      "epoch:30 step:144455[D loss: 0.999947] [G loss: 1.000066]\n",
      "epoch:30 step:144460[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:30 step:144465[D loss: 0.999996] [G loss: 0.999981]\n",
      "epoch:30 step:144470[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:30 step:144475[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:30 step:144480[D loss: 0.999949] [G loss: 1.000164]\n",
      "epoch:30 step:144485[D loss: 1.000084] [G loss: 0.999872]\n",
      "epoch:30 step:144490[D loss: 1.000123] [G loss: 0.999987]\n",
      "epoch:30 step:144495[D loss: 1.000162] [G loss: 0.999901]\n",
      "epoch:30 step:144500[D loss: 0.999803] [G loss: 1.000212]\n",
      "epoch:30 step:144505[D loss: 0.999975] [G loss: 1.000024]\n",
      "epoch:30 step:144510[D loss: 0.999972] [G loss: 0.999973]\n",
      "epoch:30 step:144515[D loss: 0.999951] [G loss: 1.000001]\n",
      "epoch:30 step:144520[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:30 step:144525[D loss: 1.000016] [G loss: 1.000016]\n",
      "epoch:30 step:144530[D loss: 0.999952] [G loss: 1.000082]\n",
      "epoch:30 step:144535[D loss: 0.999923] [G loss: 1.000111]\n",
      "epoch:30 step:144540[D loss: 1.000073] [G loss: 0.999945]\n",
      "epoch:30 step:144545[D loss: 0.999893] [G loss: 1.000218]\n",
      "epoch:30 step:144550[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:30 step:144555[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:30 step:144560[D loss: 0.999946] [G loss: 1.000096]\n",
      "epoch:30 step:144565[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:30 step:144570[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:30 step:144575[D loss: 0.999984] [G loss: 1.000107]\n",
      "epoch:30 step:144580[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:30 step:144585[D loss: 0.999971] [G loss: 1.000126]\n",
      "epoch:30 step:144590[D loss: 1.000062] [G loss: 0.999971]\n",
      "epoch:30 step:144595[D loss: 0.999980] [G loss: 0.999994]\n",
      "epoch:30 step:144600[D loss: 0.999936] [G loss: 1.000118]\n",
      "##############\n",
      "[2.5388906  2.11836709 2.19775282 3.47964409 1.47417396 7.23219917\n",
      " 2.2410639  3.55709858 3.96933176 4.69389793]\n",
      "##########\n",
      "epoch:30 step:144605[D loss: 0.999955] [G loss: 1.000115]\n",
      "epoch:30 step:144610[D loss: 0.999962] [G loss: 1.000160]\n",
      "epoch:30 step:144615[D loss: 0.999980] [G loss: 1.000117]\n",
      "epoch:30 step:144620[D loss: 1.000060] [G loss: 0.999931]\n",
      "epoch:30 step:144625[D loss: 0.999944] [G loss: 1.000070]\n",
      "epoch:30 step:144630[D loss: 0.999979] [G loss: 1.000109]\n",
      "epoch:30 step:144635[D loss: 0.999936] [G loss: 1.000080]\n",
      "epoch:30 step:144640[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:30 step:144645[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:30 step:144650[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:30 step:144655[D loss: 1.000039] [G loss: 0.999963]\n",
      "epoch:30 step:144660[D loss: 1.000027] [G loss: 0.999996]\n",
      "epoch:30 step:144665[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:30 step:144670[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:30 step:144675[D loss: 0.999965] [G loss: 1.000094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:144680[D loss: 1.000041] [G loss: 0.999941]\n",
      "epoch:30 step:144685[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:30 step:144690[D loss: 0.999948] [G loss: 1.000106]\n",
      "epoch:30 step:144695[D loss: 0.999966] [G loss: 1.000109]\n",
      "epoch:30 step:144700[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:30 step:144705[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:30 step:144710[D loss: 1.000076] [G loss: 1.000007]\n",
      "epoch:30 step:144715[D loss: 0.999923] [G loss: 1.000109]\n",
      "epoch:30 step:144720[D loss: 1.000017] [G loss: 1.000200]\n",
      "epoch:30 step:144725[D loss: 0.999919] [G loss: 1.000125]\n",
      "epoch:30 step:144730[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:30 step:144735[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:30 step:144740[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:30 step:144745[D loss: 1.000011] [G loss: 1.000048]\n",
      "epoch:30 step:144750[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:30 step:144755[D loss: 1.000054] [G loss: 0.999890]\n",
      "epoch:30 step:144760[D loss: 0.999985] [G loss: 0.999993]\n",
      "epoch:30 step:144765[D loss: 1.000021] [G loss: 1.000059]\n",
      "epoch:30 step:144770[D loss: 1.000003] [G loss: 1.000143]\n",
      "epoch:30 step:144775[D loss: 1.000048] [G loss: 0.999982]\n",
      "epoch:30 step:144780[D loss: 0.999891] [G loss: 1.000180]\n",
      "epoch:30 step:144785[D loss: 0.999963] [G loss: 1.000137]\n",
      "epoch:30 step:144790[D loss: 0.999958] [G loss: 1.000176]\n",
      "epoch:30 step:144795[D loss: 0.999971] [G loss: 1.000266]\n",
      "epoch:30 step:144800[D loss: 0.999929] [G loss: 1.000127]\n",
      "##############\n",
      "[2.56388774 2.0881695  2.10322285 3.62615319 1.43679517 8.53215527\n",
      " 2.16535196 3.82735258 3.9537662  5.31603455]\n",
      "##########\n",
      "epoch:30 step:144805[D loss: 0.999996] [G loss: 1.000071]\n",
      "epoch:30 step:144810[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:30 step:144815[D loss: 1.000004] [G loss: 0.999986]\n",
      "epoch:30 step:144820[D loss: 0.999954] [G loss: 1.000058]\n",
      "epoch:30 step:144825[D loss: 1.000048] [G loss: 0.999904]\n",
      "epoch:30 step:144830[D loss: 1.000129] [G loss: 0.999885]\n",
      "epoch:30 step:144835[D loss: 0.999976] [G loss: 0.999875]\n",
      "epoch:30 step:144840[D loss: 1.000044] [G loss: 1.000104]\n",
      "epoch:30 step:144845[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:30 step:144850[D loss: 0.999964] [G loss: 1.000005]\n",
      "epoch:30 step:144855[D loss: 0.999929] [G loss: 1.000133]\n",
      "epoch:30 step:144860[D loss: 1.000005] [G loss: 1.000045]\n",
      "epoch:30 step:144865[D loss: 0.999948] [G loss: 1.000106]\n",
      "epoch:30 step:144870[D loss: 1.000026] [G loss: 0.999974]\n",
      "epoch:30 step:144875[D loss: 0.999993] [G loss: 0.999972]\n",
      "epoch:30 step:144880[D loss: 0.999986] [G loss: 1.000008]\n",
      "epoch:30 step:144885[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:30 step:144890[D loss: 1.000027] [G loss: 0.999936]\n",
      "epoch:30 step:144895[D loss: 1.000015] [G loss: 1.000061]\n",
      "epoch:30 step:144900[D loss: 1.000169] [G loss: 0.999973]\n",
      "epoch:30 step:144905[D loss: 0.999850] [G loss: 1.000123]\n",
      "epoch:30 step:144910[D loss: 0.999955] [G loss: 1.000021]\n",
      "epoch:30 step:144915[D loss: 1.000045] [G loss: 1.000060]\n",
      "epoch:30 step:144920[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:30 step:144925[D loss: 0.999952] [G loss: 1.000061]\n",
      "epoch:30 step:144930[D loss: 0.999943] [G loss: 1.000060]\n",
      "epoch:30 step:144935[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:30 step:144940[D loss: 0.999995] [G loss: 1.000077]\n",
      "epoch:30 step:144945[D loss: 0.999936] [G loss: 1.000038]\n",
      "epoch:30 step:144950[D loss: 0.999999] [G loss: 0.999995]\n",
      "epoch:30 step:144955[D loss: 0.999945] [G loss: 1.000077]\n",
      "epoch:30 step:144960[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:30 step:144965[D loss: 1.000021] [G loss: 0.999984]\n",
      "epoch:30 step:144970[D loss: 1.000069] [G loss: 0.999857]\n",
      "epoch:30 step:144975[D loss: 0.999963] [G loss: 1.000037]\n",
      "epoch:30 step:144980[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:30 step:144985[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:30 step:144990[D loss: 0.999948] [G loss: 1.000086]\n",
      "epoch:30 step:144995[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:30 step:145000[D loss: 0.999975] [G loss: 1.000054]\n",
      "##############\n",
      "[2.47993644 2.08004657 2.13746586 3.61816684 1.49262374 7.28078926\n",
      " 2.2877181  3.78293095 3.89748163 6.08645226]\n",
      "##########\n",
      "epoch:30 step:145005[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:30 step:145010[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:30 step:145015[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:30 step:145020[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:30 step:145025[D loss: 0.999976] [G loss: 1.000028]\n",
      "epoch:30 step:145030[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:30 step:145035[D loss: 1.000009] [G loss: 0.999966]\n",
      "epoch:30 step:145040[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:30 step:145045[D loss: 1.000005] [G loss: 0.999983]\n",
      "epoch:30 step:145050[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:30 step:145055[D loss: 1.000057] [G loss: 0.999968]\n",
      "epoch:30 step:145060[D loss: 1.000000] [G loss: 0.999972]\n",
      "epoch:30 step:145065[D loss: 0.999952] [G loss: 1.000064]\n",
      "epoch:30 step:145070[D loss: 1.000002] [G loss: 1.000051]\n",
      "epoch:30 step:145075[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:30 step:145080[D loss: 0.999981] [G loss: 1.000124]\n",
      "epoch:30 step:145085[D loss: 0.999943] [G loss: 1.000041]\n",
      "epoch:30 step:145090[D loss: 1.000036] [G loss: 1.000025]\n",
      "epoch:30 step:145095[D loss: 1.000024] [G loss: 1.000007]\n",
      "epoch:30 step:145100[D loss: 0.999918] [G loss: 1.000109]\n",
      "epoch:30 step:145105[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:30 step:145110[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:30 step:145115[D loss: 1.000012] [G loss: 0.999994]\n",
      "epoch:30 step:145120[D loss: 0.999991] [G loss: 1.000077]\n",
      "epoch:30 step:145125[D loss: 0.999991] [G loss: 1.000122]\n",
      "epoch:30 step:145130[D loss: 0.999948] [G loss: 1.000148]\n",
      "epoch:30 step:145135[D loss: 1.000052] [G loss: 1.000055]\n",
      "epoch:30 step:145140[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:30 step:145145[D loss: 1.000014] [G loss: 1.000018]\n",
      "epoch:30 step:145150[D loss: 1.000052] [G loss: 0.999895]\n",
      "epoch:30 step:145155[D loss: 1.000029] [G loss: 1.000004]\n",
      "epoch:30 step:145160[D loss: 0.999954] [G loss: 1.000141]\n",
      "epoch:30 step:145165[D loss: 0.999960] [G loss: 1.000050]\n",
      "epoch:30 step:145170[D loss: 0.999957] [G loss: 1.000057]\n",
      "epoch:30 step:145175[D loss: 0.999945] [G loss: 1.000043]\n",
      "epoch:30 step:145180[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:30 step:145185[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:30 step:145190[D loss: 1.000070] [G loss: 1.000008]\n",
      "epoch:30 step:145195[D loss: 0.999948] [G loss: 0.999970]\n",
      "epoch:30 step:145200[D loss: 0.999968] [G loss: 1.000090]\n",
      "##############\n",
      "[2.44807023 2.08275772 2.24818134 3.69258625 1.4573588  6.82762672\n",
      " 2.31783718 3.61381347 3.87498363 5.59016467]\n",
      "##########\n",
      "epoch:30 step:145205[D loss: 0.999997] [G loss: 0.999984]\n",
      "epoch:30 step:145210[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:30 step:145215[D loss: 1.000047] [G loss: 0.999958]\n",
      "epoch:30 step:145220[D loss: 0.999930] [G loss: 1.000096]\n",
      "epoch:30 step:145225[D loss: 0.999942] [G loss: 1.000077]\n",
      "epoch:30 step:145230[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:30 step:145235[D loss: 1.000006] [G loss: 1.000079]\n",
      "epoch:31 step:145240[D loss: 1.000017] [G loss: 1.000083]\n",
      "epoch:31 step:145245[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:31 step:145250[D loss: 0.999898] [G loss: 1.000112]\n",
      "epoch:31 step:145255[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:31 step:145260[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:31 step:145265[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:31 step:145270[D loss: 1.000015] [G loss: 1.000028]\n",
      "epoch:31 step:145275[D loss: 1.000003] [G loss: 0.999990]\n",
      "epoch:31 step:145280[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:31 step:145285[D loss: 0.999968] [G loss: 1.000186]\n",
      "epoch:31 step:145290[D loss: 1.000024] [G loss: 0.999954]\n",
      "epoch:31 step:145295[D loss: 0.999826] [G loss: 1.000212]\n",
      "epoch:31 step:145300[D loss: 0.999942] [G loss: 1.000059]\n",
      "epoch:31 step:145305[D loss: 0.999920] [G loss: 1.000219]\n",
      "epoch:31 step:145310[D loss: 1.000163] [G loss: 0.999950]\n",
      "epoch:31 step:145315[D loss: 0.999958] [G loss: 1.000145]\n",
      "epoch:31 step:145320[D loss: 0.999906] [G loss: 1.000174]\n",
      "epoch:31 step:145325[D loss: 0.999998] [G loss: 1.000060]\n",
      "epoch:31 step:145330[D loss: 1.000007] [G loss: 0.999976]\n",
      "epoch:31 step:145335[D loss: 0.999946] [G loss: 1.000053]\n",
      "epoch:31 step:145340[D loss: 1.000112] [G loss: 0.999919]\n",
      "epoch:31 step:145345[D loss: 1.000135] [G loss: 0.999866]\n",
      "epoch:31 step:145350[D loss: 0.999910] [G loss: 1.000179]\n",
      "epoch:31 step:145355[D loss: 0.999994] [G loss: 1.000150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:145360[D loss: 0.999997] [G loss: 0.999976]\n",
      "epoch:31 step:145365[D loss: 0.999956] [G loss: 1.000226]\n",
      "epoch:31 step:145370[D loss: 1.000049] [G loss: 1.000061]\n",
      "epoch:31 step:145375[D loss: 0.999945] [G loss: 1.000136]\n",
      "epoch:31 step:145380[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:31 step:145385[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:31 step:145390[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:31 step:145395[D loss: 0.999999] [G loss: 1.000026]\n",
      "epoch:31 step:145400[D loss: 0.999938] [G loss: 1.000132]\n",
      "##############\n",
      "[2.52596099 2.10198499 2.27838228 3.63006287 1.44204905 6.91025503\n",
      " 2.40116688 3.65927675 4.03199617 4.9029161 ]\n",
      "##########\n",
      "epoch:31 step:145405[D loss: 0.999994] [G loss: 1.000098]\n",
      "epoch:31 step:145410[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:31 step:145415[D loss: 1.000038] [G loss: 1.000022]\n",
      "epoch:31 step:145420[D loss: 1.000000] [G loss: 1.000110]\n",
      "epoch:31 step:145425[D loss: 0.999918] [G loss: 1.000156]\n",
      "epoch:31 step:145430[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:31 step:145435[D loss: 1.000098] [G loss: 0.999897]\n",
      "epoch:31 step:145440[D loss: 1.000013] [G loss: 0.999974]\n",
      "epoch:31 step:145445[D loss: 0.999930] [G loss: 1.000103]\n",
      "epoch:31 step:145450[D loss: 1.000018] [G loss: 0.999941]\n",
      "epoch:31 step:145455[D loss: 0.999958] [G loss: 1.000045]\n",
      "epoch:31 step:145460[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:31 step:145465[D loss: 0.999945] [G loss: 1.000107]\n",
      "epoch:31 step:145470[D loss: 0.999948] [G loss: 1.000182]\n",
      "epoch:31 step:145475[D loss: 0.999933] [G loss: 1.000160]\n",
      "epoch:31 step:145480[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:31 step:145485[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:31 step:145490[D loss: 0.999994] [G loss: 1.000013]\n",
      "epoch:31 step:145495[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:31 step:145500[D loss: 1.000039] [G loss: 0.999990]\n",
      "epoch:31 step:145505[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:31 step:145510[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:31 step:145515[D loss: 0.999919] [G loss: 1.000232]\n",
      "epoch:31 step:145520[D loss: 1.000008] [G loss: 1.000124]\n",
      "epoch:31 step:145525[D loss: 0.999999] [G loss: 1.000109]\n",
      "epoch:31 step:145530[D loss: 0.999946] [G loss: 1.000145]\n",
      "epoch:31 step:145535[D loss: 0.999986] [G loss: 1.000096]\n",
      "epoch:31 step:145540[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:31 step:145545[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:31 step:145550[D loss: 1.000017] [G loss: 1.000044]\n",
      "epoch:31 step:145555[D loss: 1.000021] [G loss: 1.000015]\n",
      "epoch:31 step:145560[D loss: 1.000014] [G loss: 0.999959]\n",
      "epoch:31 step:145565[D loss: 1.000071] [G loss: 0.999863]\n",
      "epoch:31 step:145570[D loss: 1.000020] [G loss: 1.000026]\n",
      "epoch:31 step:145575[D loss: 1.000026] [G loss: 0.999966]\n",
      "epoch:31 step:145580[D loss: 1.000152] [G loss: 1.000001]\n",
      "epoch:31 step:145585[D loss: 1.000042] [G loss: 0.999938]\n",
      "epoch:31 step:145590[D loss: 1.000167] [G loss: 0.999794]\n",
      "epoch:31 step:145595[D loss: 1.000030] [G loss: 1.000086]\n",
      "epoch:31 step:145600[D loss: 0.999924] [G loss: 1.000143]\n",
      "##############\n",
      "[2.58218779 2.20971873 2.29212831 3.86224448 1.49306092 6.65936363\n",
      " 2.56806661 3.80620819 4.01048118 5.02830934]\n",
      "##########\n",
      "epoch:31 step:145605[D loss: 0.999996] [G loss: 0.999986]\n",
      "epoch:31 step:145610[D loss: 1.000008] [G loss: 0.999972]\n",
      "epoch:31 step:145615[D loss: 1.000023] [G loss: 0.999960]\n",
      "epoch:31 step:145620[D loss: 0.999933] [G loss: 1.000040]\n",
      "epoch:31 step:145625[D loss: 0.999899] [G loss: 1.000171]\n",
      "epoch:31 step:145630[D loss: 1.000025] [G loss: 0.999988]\n",
      "epoch:31 step:145635[D loss: 1.000022] [G loss: 0.999943]\n",
      "epoch:31 step:145640[D loss: 1.000115] [G loss: 0.999984]\n",
      "epoch:31 step:145645[D loss: 0.999926] [G loss: 1.000032]\n",
      "epoch:31 step:145650[D loss: 0.999996] [G loss: 1.000070]\n",
      "epoch:31 step:145655[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:31 step:145660[D loss: 0.999950] [G loss: 1.000008]\n",
      "epoch:31 step:145665[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:31 step:145670[D loss: 0.999997] [G loss: 0.999970]\n",
      "epoch:31 step:145675[D loss: 1.000005] [G loss: 1.000038]\n",
      "epoch:31 step:145680[D loss: 1.000163] [G loss: 0.999889]\n",
      "epoch:31 step:145685[D loss: 1.000040] [G loss: 1.000060]\n",
      "epoch:31 step:145690[D loss: 0.999994] [G loss: 1.000008]\n",
      "epoch:31 step:145695[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:31 step:145700[D loss: 0.999952] [G loss: 1.000063]\n",
      "epoch:31 step:145705[D loss: 1.000020] [G loss: 0.999928]\n",
      "epoch:31 step:145710[D loss: 1.000095] [G loss: 1.000146]\n",
      "epoch:31 step:145715[D loss: 1.000040] [G loss: 1.000015]\n",
      "epoch:31 step:145720[D loss: 1.000091] [G loss: 0.999942]\n",
      "epoch:31 step:145725[D loss: 1.000038] [G loss: 1.000001]\n",
      "epoch:31 step:145730[D loss: 0.999971] [G loss: 1.000111]\n",
      "epoch:31 step:145735[D loss: 0.999913] [G loss: 1.000176]\n",
      "epoch:31 step:145740[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:31 step:145745[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:31 step:145750[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:31 step:145755[D loss: 1.000035] [G loss: 1.000013]\n",
      "epoch:31 step:145760[D loss: 0.999925] [G loss: 1.000165]\n",
      "epoch:31 step:145765[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:31 step:145770[D loss: 0.999957] [G loss: 1.000116]\n",
      "epoch:31 step:145775[D loss: 0.999993] [G loss: 1.000108]\n",
      "epoch:31 step:145780[D loss: 0.999931] [G loss: 1.000124]\n",
      "epoch:31 step:145785[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:31 step:145790[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:31 step:145795[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:31 step:145800[D loss: 0.999983] [G loss: 1.000084]\n",
      "##############\n",
      "[2.55270138 2.12693311 2.27072378 3.92965778 1.52118207 7.04688757\n",
      " 2.54470641 3.68048998 4.02866177 5.35098879]\n",
      "##########\n",
      "epoch:31 step:145805[D loss: 1.000076] [G loss: 1.000009]\n",
      "epoch:31 step:145810[D loss: 0.999935] [G loss: 1.000093]\n",
      "epoch:31 step:145815[D loss: 1.000005] [G loss: 1.000056]\n",
      "epoch:31 step:145820[D loss: 1.000047] [G loss: 1.000099]\n",
      "epoch:31 step:145825[D loss: 1.000196] [G loss: 0.999857]\n",
      "epoch:31 step:145830[D loss: 0.999970] [G loss: 1.000242]\n",
      "epoch:31 step:145835[D loss: 0.999830] [G loss: 1.000229]\n",
      "epoch:31 step:145840[D loss: 0.999942] [G loss: 1.000093]\n",
      "epoch:31 step:145845[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:31 step:145850[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:31 step:145855[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:31 step:145860[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:31 step:145865[D loss: 0.999972] [G loss: 1.000018]\n",
      "epoch:31 step:145870[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:31 step:145875[D loss: 1.000084] [G loss: 0.999918]\n",
      "epoch:31 step:145880[D loss: 1.000052] [G loss: 0.999996]\n",
      "epoch:31 step:145885[D loss: 0.999869] [G loss: 1.000129]\n",
      "epoch:31 step:145890[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:31 step:145895[D loss: 0.999998] [G loss: 1.000076]\n",
      "epoch:31 step:145900[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:31 step:145905[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:31 step:145910[D loss: 0.999994] [G loss: 1.000086]\n",
      "epoch:31 step:145915[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:31 step:145920[D loss: 1.000023] [G loss: 0.999986]\n",
      "epoch:31 step:145925[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:31 step:145930[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:31 step:145935[D loss: 1.000017] [G loss: 1.000023]\n",
      "epoch:31 step:145940[D loss: 0.999946] [G loss: 1.000109]\n",
      "epoch:31 step:145945[D loss: 1.000015] [G loss: 1.000076]\n",
      "epoch:31 step:145950[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:31 step:145955[D loss: 1.000019] [G loss: 0.999958]\n",
      "epoch:31 step:145960[D loss: 1.000017] [G loss: 1.000080]\n",
      "epoch:31 step:145965[D loss: 0.999917] [G loss: 1.000151]\n",
      "epoch:31 step:145970[D loss: 1.000020] [G loss: 1.000163]\n",
      "epoch:31 step:145975[D loss: 0.999961] [G loss: 1.000121]\n",
      "epoch:31 step:145980[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:31 step:145985[D loss: 0.999960] [G loss: 1.000034]\n",
      "epoch:31 step:145990[D loss: 0.999989] [G loss: 1.000006]\n",
      "epoch:31 step:145995[D loss: 1.000050] [G loss: 0.999875]\n",
      "epoch:31 step:146000[D loss: 0.999916] [G loss: 1.000071]\n",
      "##############\n",
      "[2.54032566 2.13768892 2.16711234 3.52692679 1.477759   7.14028617\n",
      " 2.09610544 3.55317567 3.91337367 5.04011476]\n",
      "##########\n",
      "epoch:31 step:146005[D loss: 0.999963] [G loss: 1.000030]\n",
      "epoch:31 step:146010[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:31 step:146015[D loss: 0.999981] [G loss: 1.000086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:146020[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:31 step:146025[D loss: 0.999941] [G loss: 1.000105]\n",
      "epoch:31 step:146030[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:31 step:146035[D loss: 0.999962] [G loss: 1.000113]\n",
      "epoch:31 step:146040[D loss: 1.000041] [G loss: 0.999985]\n",
      "epoch:31 step:146045[D loss: 0.999886] [G loss: 1.000218]\n",
      "epoch:31 step:146050[D loss: 0.999904] [G loss: 1.000132]\n",
      "epoch:31 step:146055[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:31 step:146060[D loss: 1.000034] [G loss: 1.000044]\n",
      "epoch:31 step:146065[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:31 step:146070[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:31 step:146075[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:31 step:146080[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:31 step:146085[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:31 step:146090[D loss: 0.999933] [G loss: 1.000105]\n",
      "epoch:31 step:146095[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:31 step:146100[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:31 step:146105[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:31 step:146110[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:31 step:146115[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:31 step:146120[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:31 step:146125[D loss: 0.999991] [G loss: 1.000118]\n",
      "epoch:31 step:146130[D loss: 1.000003] [G loss: 1.000098]\n",
      "epoch:31 step:146135[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:31 step:146140[D loss: 1.000046] [G loss: 1.000033]\n",
      "epoch:31 step:146145[D loss: 0.999903] [G loss: 1.000191]\n",
      "epoch:31 step:146150[D loss: 1.000065] [G loss: 1.000095]\n",
      "epoch:31 step:146155[D loss: 0.999985] [G loss: 1.000139]\n",
      "epoch:31 step:146160[D loss: 0.999998] [G loss: 0.999995]\n",
      "epoch:31 step:146165[D loss: 1.000096] [G loss: 0.999869]\n",
      "epoch:31 step:146170[D loss: 1.000039] [G loss: 0.999971]\n",
      "epoch:31 step:146175[D loss: 1.000211] [G loss: 0.999823]\n",
      "epoch:31 step:146180[D loss: 0.999925] [G loss: 1.000096]\n",
      "epoch:31 step:146185[D loss: 0.999945] [G loss: 1.000151]\n",
      "epoch:31 step:146190[D loss: 0.999972] [G loss: 1.000029]\n",
      "epoch:31 step:146195[D loss: 1.000031] [G loss: 0.999998]\n",
      "epoch:31 step:146200[D loss: 1.000031] [G loss: 1.000038]\n",
      "##############\n",
      "[2.42160908 2.1168417  2.3352117  3.23123078 1.45303959 7.44100634\n",
      " 2.31131394 3.83750026 3.94165616 4.95843431]\n",
      "##########\n",
      "epoch:31 step:146205[D loss: 1.000013] [G loss: 0.999985]\n",
      "epoch:31 step:146210[D loss: 0.999998] [G loss: 1.000001]\n",
      "epoch:31 step:146215[D loss: 0.999979] [G loss: 1.000011]\n",
      "epoch:31 step:146220[D loss: 1.000136] [G loss: 1.000040]\n",
      "epoch:31 step:146225[D loss: 1.000058] [G loss: 1.000175]\n",
      "epoch:31 step:146230[D loss: 1.000036] [G loss: 1.000072]\n",
      "epoch:31 step:146235[D loss: 1.000256] [G loss: 1.000045]\n",
      "epoch:31 step:146240[D loss: 0.999892] [G loss: 1.000229]\n",
      "epoch:31 step:146245[D loss: 1.000028] [G loss: 1.000087]\n",
      "epoch:31 step:146250[D loss: 0.999916] [G loss: 1.000256]\n",
      "epoch:31 step:146255[D loss: 0.999921] [G loss: 1.000178]\n",
      "epoch:31 step:146260[D loss: 0.999970] [G loss: 1.000137]\n",
      "epoch:31 step:146265[D loss: 1.000042] [G loss: 0.999980]\n",
      "epoch:31 step:146270[D loss: 1.000016] [G loss: 0.999920]\n",
      "epoch:31 step:146275[D loss: 0.999905] [G loss: 1.000002]\n",
      "epoch:31 step:146280[D loss: 1.000084] [G loss: 0.999861]\n",
      "epoch:31 step:146285[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:31 step:146290[D loss: 1.000085] [G loss: 0.999951]\n",
      "epoch:31 step:146295[D loss: 0.999991] [G loss: 1.000157]\n",
      "epoch:31 step:146300[D loss: 1.000082] [G loss: 1.000025]\n",
      "epoch:31 step:146305[D loss: 0.999964] [G loss: 1.000138]\n",
      "epoch:31 step:146310[D loss: 0.999978] [G loss: 1.000201]\n",
      "epoch:31 step:146315[D loss: 1.000019] [G loss: 1.000142]\n",
      "epoch:31 step:146320[D loss: 1.000131] [G loss: 1.000227]\n",
      "epoch:31 step:146325[D loss: 0.999765] [G loss: 1.000354]\n",
      "epoch:31 step:146330[D loss: 0.999868] [G loss: 1.000250]\n",
      "epoch:31 step:146335[D loss: 0.999923] [G loss: 1.000169]\n",
      "epoch:31 step:146340[D loss: 0.999918] [G loss: 1.000105]\n",
      "epoch:31 step:146345[D loss: 1.000010] [G loss: 0.999984]\n",
      "epoch:31 step:146350[D loss: 1.000078] [G loss: 0.999975]\n",
      "epoch:31 step:146355[D loss: 0.999892] [G loss: 1.000136]\n",
      "epoch:31 step:146360[D loss: 0.999993] [G loss: 1.000088]\n",
      "epoch:31 step:146365[D loss: 1.000031] [G loss: 1.000075]\n",
      "epoch:31 step:146370[D loss: 1.000218] [G loss: 0.999919]\n",
      "epoch:31 step:146375[D loss: 0.999894] [G loss: 1.000176]\n",
      "epoch:31 step:146380[D loss: 0.999890] [G loss: 1.000139]\n",
      "epoch:31 step:146385[D loss: 1.000030] [G loss: 1.000102]\n",
      "epoch:31 step:146390[D loss: 1.000038] [G loss: 1.000055]\n",
      "epoch:31 step:146395[D loss: 0.999979] [G loss: 1.000194]\n",
      "epoch:31 step:146400[D loss: 0.999976] [G loss: 1.000200]\n",
      "##############\n",
      "[2.48541441 2.10428684 2.13499047 3.32080823 1.54582108 6.80706809\n",
      " 2.32597038 3.60619179 3.87030013 5.32609136]\n",
      "##########\n",
      "epoch:31 step:146405[D loss: 1.000031] [G loss: 1.000193]\n",
      "epoch:31 step:146410[D loss: 1.000132] [G loss: 1.000061]\n",
      "epoch:31 step:146415[D loss: 1.000018] [G loss: 1.000022]\n",
      "epoch:31 step:146420[D loss: 0.999993] [G loss: 1.000104]\n",
      "epoch:31 step:146425[D loss: 0.999909] [G loss: 1.000107]\n",
      "epoch:31 step:146430[D loss: 1.000032] [G loss: 0.999921]\n",
      "epoch:31 step:146435[D loss: 1.000092] [G loss: 0.999898]\n",
      "epoch:31 step:146440[D loss: 1.000120] [G loss: 0.999873]\n",
      "epoch:31 step:146445[D loss: 1.000134] [G loss: 0.999974]\n",
      "epoch:31 step:146450[D loss: 0.999949] [G loss: 0.999991]\n",
      "epoch:31 step:146455[D loss: 0.999882] [G loss: 1.000310]\n",
      "epoch:31 step:146460[D loss: 1.000051] [G loss: 0.999959]\n",
      "epoch:31 step:146465[D loss: 1.000057] [G loss: 0.999879]\n",
      "epoch:31 step:146470[D loss: 0.999755] [G loss: 1.000258]\n",
      "epoch:31 step:146475[D loss: 1.000072] [G loss: 1.000068]\n",
      "epoch:31 step:146480[D loss: 0.999898] [G loss: 1.000222]\n",
      "epoch:31 step:146485[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:31 step:146490[D loss: 0.999980] [G loss: 1.000019]\n",
      "epoch:31 step:146495[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:31 step:146500[D loss: 1.000010] [G loss: 1.000022]\n",
      "epoch:31 step:146505[D loss: 1.000047] [G loss: 1.000009]\n",
      "epoch:31 step:146510[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:31 step:146515[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:31 step:146520[D loss: 0.999977] [G loss: 1.000115]\n",
      "epoch:31 step:146525[D loss: 0.999961] [G loss: 1.000130]\n",
      "epoch:31 step:146530[D loss: 0.999924] [G loss: 1.000198]\n",
      "epoch:31 step:146535[D loss: 1.000054] [G loss: 1.000019]\n",
      "epoch:31 step:146540[D loss: 0.999936] [G loss: 1.000104]\n",
      "epoch:31 step:146545[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:31 step:146550[D loss: 0.999998] [G loss: 1.000066]\n",
      "epoch:31 step:146555[D loss: 1.000030] [G loss: 1.000034]\n",
      "epoch:31 step:146560[D loss: 0.999938] [G loss: 1.000104]\n",
      "epoch:31 step:146565[D loss: 1.000049] [G loss: 0.999989]\n",
      "epoch:31 step:146570[D loss: 0.999925] [G loss: 1.000101]\n",
      "epoch:31 step:146575[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:31 step:146580[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:31 step:146585[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:31 step:146590[D loss: 0.999944] [G loss: 1.000125]\n",
      "epoch:31 step:146595[D loss: 1.000010] [G loss: 1.000059]\n",
      "epoch:31 step:146600[D loss: 0.999984] [G loss: 1.000095]\n",
      "##############\n",
      "[2.44224832 2.15999626 2.30916486 3.80560294 1.44240514 7.61421838\n",
      " 2.27766843 3.71919985 3.83747476 5.34977426]\n",
      "##########\n",
      "epoch:31 step:146605[D loss: 0.999948] [G loss: 1.000107]\n",
      "epoch:31 step:146610[D loss: 1.000081] [G loss: 0.999900]\n",
      "epoch:31 step:146615[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:31 step:146620[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:31 step:146625[D loss: 1.000049] [G loss: 1.000085]\n",
      "epoch:31 step:146630[D loss: 0.999908] [G loss: 1.000127]\n",
      "epoch:31 step:146635[D loss: 1.000005] [G loss: 1.000107]\n",
      "epoch:31 step:146640[D loss: 0.999906] [G loss: 1.000158]\n",
      "epoch:31 step:146645[D loss: 0.999989] [G loss: 1.000132]\n",
      "epoch:31 step:146650[D loss: 0.999967] [G loss: 1.000176]\n",
      "epoch:31 step:146655[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:31 step:146660[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:31 step:146665[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:31 step:146670[D loss: 0.999963] [G loss: 1.000099]\n",
      "epoch:31 step:146675[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:31 step:146680[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:31 step:146685[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:31 step:146690[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:31 step:146695[D loss: 0.999996] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:146700[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:31 step:146705[D loss: 0.999947] [G loss: 1.000045]\n",
      "epoch:31 step:146710[D loss: 1.000049] [G loss: 1.000073]\n",
      "epoch:31 step:146715[D loss: 0.999959] [G loss: 1.000116]\n",
      "epoch:31 step:146720[D loss: 0.999934] [G loss: 1.000108]\n",
      "epoch:31 step:146725[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:31 step:146730[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:31 step:146735[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:31 step:146740[D loss: 1.000048] [G loss: 0.999913]\n",
      "epoch:31 step:146745[D loss: 0.999938] [G loss: 1.000112]\n",
      "epoch:31 step:146750[D loss: 1.000093] [G loss: 1.000001]\n",
      "epoch:31 step:146755[D loss: 0.999864] [G loss: 1.000180]\n",
      "epoch:31 step:146760[D loss: 0.999948] [G loss: 1.000146]\n",
      "epoch:31 step:146765[D loss: 1.000000] [G loss: 1.000093]\n",
      "epoch:31 step:146770[D loss: 0.999894] [G loss: 1.000214]\n",
      "epoch:31 step:146775[D loss: 0.999947] [G loss: 1.000121]\n",
      "epoch:31 step:146780[D loss: 0.999981] [G loss: 1.000137]\n",
      "epoch:31 step:146785[D loss: 0.999937] [G loss: 1.000187]\n",
      "epoch:31 step:146790[D loss: 0.999964] [G loss: 1.000141]\n",
      "epoch:31 step:146795[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:31 step:146800[D loss: 0.999970] [G loss: 1.000017]\n",
      "##############\n",
      "[2.53525259 2.10869295 2.24966541 3.68625398 1.46797791 7.40093103\n",
      " 2.24311424 3.70581592 4.01938106 5.4741938 ]\n",
      "##########\n",
      "epoch:31 step:146805[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:31 step:146810[D loss: 0.999997] [G loss: 1.000096]\n",
      "epoch:31 step:146815[D loss: 1.000019] [G loss: 1.000079]\n",
      "epoch:31 step:146820[D loss: 0.999948] [G loss: 0.999985]\n",
      "epoch:31 step:146825[D loss: 0.999965] [G loss: 1.000010]\n",
      "epoch:31 step:146830[D loss: 1.000011] [G loss: 1.000010]\n",
      "epoch:31 step:146835[D loss: 1.000042] [G loss: 0.999984]\n",
      "epoch:31 step:146840[D loss: 0.999972] [G loss: 1.000131]\n",
      "epoch:31 step:146845[D loss: 1.000117] [G loss: 0.999954]\n",
      "epoch:31 step:146850[D loss: 1.000048] [G loss: 1.000082]\n",
      "epoch:31 step:146855[D loss: 0.999704] [G loss: 1.000350]\n",
      "epoch:31 step:146860[D loss: 0.999884] [G loss: 1.000197]\n",
      "epoch:31 step:146865[D loss: 0.999988] [G loss: 0.999970]\n",
      "epoch:31 step:146870[D loss: 1.000068] [G loss: 0.999932]\n",
      "epoch:31 step:146875[D loss: 0.999925] [G loss: 0.999968]\n",
      "epoch:31 step:146880[D loss: 1.000032] [G loss: 0.999985]\n",
      "epoch:31 step:146885[D loss: 0.999920] [G loss: 1.000073]\n",
      "epoch:31 step:146890[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:31 step:146895[D loss: 0.999954] [G loss: 1.000070]\n",
      "epoch:31 step:146900[D loss: 0.999973] [G loss: 1.000121]\n",
      "epoch:31 step:146905[D loss: 0.999916] [G loss: 1.000163]\n",
      "epoch:31 step:146910[D loss: 0.999956] [G loss: 1.000125]\n",
      "epoch:31 step:146915[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:31 step:146920[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:31 step:146925[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:31 step:146930[D loss: 1.000046] [G loss: 0.999942]\n",
      "epoch:31 step:146935[D loss: 0.999930] [G loss: 1.000065]\n",
      "epoch:31 step:146940[D loss: 0.999995] [G loss: 1.000038]\n",
      "epoch:31 step:146945[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:31 step:146950[D loss: 0.999925] [G loss: 1.000125]\n",
      "epoch:31 step:146955[D loss: 0.999971] [G loss: 1.000111]\n",
      "epoch:31 step:146960[D loss: 1.000009] [G loss: 1.000100]\n",
      "epoch:31 step:146965[D loss: 1.000065] [G loss: 1.000006]\n",
      "epoch:31 step:146970[D loss: 0.999958] [G loss: 1.000015]\n",
      "epoch:31 step:146975[D loss: 0.999974] [G loss: 0.999991]\n",
      "epoch:31 step:146980[D loss: 1.000258] [G loss: 0.999785]\n",
      "epoch:31 step:146985[D loss: 0.999961] [G loss: 1.000123]\n",
      "epoch:31 step:146990[D loss: 1.000126] [G loss: 0.999921]\n",
      "epoch:31 step:146995[D loss: 0.999981] [G loss: 1.000120]\n",
      "epoch:31 step:147000[D loss: 0.999877] [G loss: 1.000276]\n",
      "##############\n",
      "[2.54963104 2.19156825 2.30099328 3.78254947 1.5461925  7.84110221\n",
      " 2.35222897 3.74467778 3.97618925 4.99936869]\n",
      "##########\n",
      "epoch:31 step:147005[D loss: 0.999862] [G loss: 1.000236]\n",
      "epoch:31 step:147010[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:31 step:147015[D loss: 0.999954] [G loss: 1.000105]\n",
      "epoch:31 step:147020[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:31 step:147025[D loss: 1.000036] [G loss: 0.999968]\n",
      "epoch:31 step:147030[D loss: 0.999907] [G loss: 1.000055]\n",
      "epoch:31 step:147035[D loss: 0.999918] [G loss: 1.000278]\n",
      "epoch:31 step:147040[D loss: 0.999907] [G loss: 1.000085]\n",
      "epoch:31 step:147045[D loss: 0.999968] [G loss: 0.999974]\n",
      "epoch:31 step:147050[D loss: 0.999923] [G loss: 1.000080]\n",
      "epoch:31 step:147055[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:31 step:147060[D loss: 0.999963] [G loss: 1.000044]\n",
      "epoch:31 step:147065[D loss: 0.999925] [G loss: 1.000144]\n",
      "epoch:31 step:147070[D loss: 1.000050] [G loss: 0.999999]\n",
      "epoch:31 step:147075[D loss: 1.000018] [G loss: 0.999982]\n",
      "epoch:31 step:147080[D loss: 1.000036] [G loss: 0.999981]\n",
      "epoch:31 step:147085[D loss: 0.999909] [G loss: 1.000148]\n",
      "epoch:31 step:147090[D loss: 0.999975] [G loss: 1.000101]\n",
      "epoch:31 step:147095[D loss: 0.999889] [G loss: 1.000142]\n",
      "epoch:31 step:147100[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:31 step:147105[D loss: 1.000005] [G loss: 1.000159]\n",
      "epoch:31 step:147110[D loss: 0.999982] [G loss: 0.999988]\n",
      "epoch:31 step:147115[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:31 step:147120[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:31 step:147125[D loss: 1.000109] [G loss: 0.999909]\n",
      "epoch:31 step:147130[D loss: 0.999969] [G loss: 1.000013]\n",
      "epoch:31 step:147135[D loss: 0.999937] [G loss: 1.000000]\n",
      "epoch:31 step:147140[D loss: 0.999917] [G loss: 1.000111]\n",
      "epoch:31 step:147145[D loss: 1.000025] [G loss: 0.999967]\n",
      "epoch:31 step:147150[D loss: 0.999934] [G loss: 1.000008]\n",
      "epoch:31 step:147155[D loss: 1.000000] [G loss: 1.000092]\n",
      "epoch:31 step:147160[D loss: 0.999956] [G loss: 1.000043]\n",
      "epoch:31 step:147165[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:31 step:147170[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:31 step:147175[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:31 step:147180[D loss: 0.999952] [G loss: 1.000056]\n",
      "epoch:31 step:147185[D loss: 1.000077] [G loss: 1.000039]\n",
      "epoch:31 step:147190[D loss: 0.999946] [G loss: 1.000052]\n",
      "epoch:31 step:147195[D loss: 0.999969] [G loss: 1.000251]\n",
      "epoch:31 step:147200[D loss: 0.999981] [G loss: 1.000083]\n",
      "##############\n",
      "[2.5148441  2.09914983 2.30796856 3.80299984 1.5041367  7.52669349\n",
      " 2.39811444 3.47082702 3.99342697 4.81934144]\n",
      "##########\n",
      "epoch:31 step:147205[D loss: 1.000010] [G loss: 1.000105]\n",
      "epoch:31 step:147210[D loss: 0.999851] [G loss: 1.000231]\n",
      "epoch:31 step:147215[D loss: 0.999974] [G loss: 1.000109]\n",
      "epoch:31 step:147220[D loss: 1.000015] [G loss: 0.999994]\n",
      "epoch:31 step:147225[D loss: 0.999931] [G loss: 1.000144]\n",
      "epoch:31 step:147230[D loss: 1.000066] [G loss: 0.999943]\n",
      "epoch:31 step:147235[D loss: 1.000019] [G loss: 1.000015]\n",
      "epoch:31 step:147240[D loss: 1.000017] [G loss: 1.000021]\n",
      "epoch:31 step:147245[D loss: 0.999959] [G loss: 1.000108]\n",
      "epoch:31 step:147250[D loss: 1.000069] [G loss: 1.000008]\n",
      "epoch:31 step:147255[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:31 step:147260[D loss: 0.999908] [G loss: 1.000053]\n",
      "epoch:31 step:147265[D loss: 0.999905] [G loss: 1.000122]\n",
      "epoch:31 step:147270[D loss: 1.000065] [G loss: 0.999964]\n",
      "epoch:31 step:147275[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:31 step:147280[D loss: 1.000024] [G loss: 0.999959]\n",
      "epoch:31 step:147285[D loss: 0.999994] [G loss: 1.000215]\n",
      "epoch:31 step:147290[D loss: 0.999923] [G loss: 1.000118]\n",
      "epoch:31 step:147295[D loss: 0.999985] [G loss: 1.000014]\n",
      "epoch:31 step:147300[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:31 step:147305[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:31 step:147310[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:31 step:147315[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:31 step:147320[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:31 step:147325[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:31 step:147330[D loss: 0.999919] [G loss: 1.000145]\n",
      "epoch:31 step:147335[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:31 step:147340[D loss: 1.000004] [G loss: 1.000187]\n",
      "epoch:31 step:147345[D loss: 1.000020] [G loss: 1.000100]\n",
      "epoch:31 step:147350[D loss: 0.999889] [G loss: 1.000202]\n",
      "epoch:31 step:147355[D loss: 0.999982] [G loss: 1.000108]\n",
      "epoch:31 step:147360[D loss: 0.999798] [G loss: 1.000324]\n",
      "epoch:31 step:147365[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:31 step:147370[D loss: 1.000009] [G loss: 0.999899]\n",
      "epoch:31 step:147375[D loss: 1.000040] [G loss: 0.999949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:147380[D loss: 0.999920] [G loss: 1.000096]\n",
      "epoch:31 step:147385[D loss: 0.999953] [G loss: 1.000047]\n",
      "epoch:31 step:147390[D loss: 0.999989] [G loss: 1.000000]\n",
      "epoch:31 step:147395[D loss: 1.000037] [G loss: 1.000061]\n",
      "epoch:31 step:147400[D loss: 0.999979] [G loss: 1.000066]\n",
      "##############\n",
      "[2.48660601 2.09760652 2.26856389 3.64186511 1.45951024 6.66867256\n",
      " 2.36377691 3.73525905 3.91094268 5.18427363]\n",
      "##########\n",
      "epoch:31 step:147405[D loss: 1.000012] [G loss: 1.000105]\n",
      "epoch:31 step:147410[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:31 step:147415[D loss: 0.999934] [G loss: 1.000068]\n",
      "epoch:31 step:147420[D loss: 0.999910] [G loss: 1.000144]\n",
      "epoch:31 step:147425[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:31 step:147430[D loss: 0.999984] [G loss: 1.000103]\n",
      "epoch:31 step:147435[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:31 step:147440[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:31 step:147445[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:31 step:147450[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:31 step:147455[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:31 step:147460[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:31 step:147465[D loss: 0.999992] [G loss: 1.000107]\n",
      "epoch:31 step:147470[D loss: 1.000079] [G loss: 1.000014]\n",
      "epoch:31 step:147475[D loss: 1.000064] [G loss: 1.000030]\n",
      "epoch:31 step:147480[D loss: 0.999891] [G loss: 1.000196]\n",
      "epoch:31 step:147485[D loss: 0.999976] [G loss: 1.000179]\n",
      "epoch:31 step:147490[D loss: 0.999926] [G loss: 1.000118]\n",
      "epoch:31 step:147495[D loss: 1.000026] [G loss: 1.000087]\n",
      "epoch:31 step:147500[D loss: 0.999941] [G loss: 1.000206]\n",
      "epoch:31 step:147505[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:31 step:147510[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:31 step:147515[D loss: 0.999943] [G loss: 1.000096]\n",
      "epoch:31 step:147520[D loss: 1.000002] [G loss: 1.000054]\n",
      "epoch:31 step:147525[D loss: 0.999975] [G loss: 1.000147]\n",
      "epoch:31 step:147530[D loss: 1.000360] [G loss: 0.999819]\n",
      "epoch:31 step:147535[D loss: 1.000068] [G loss: 0.999854]\n",
      "epoch:31 step:147540[D loss: 1.000038] [G loss: 0.999972]\n",
      "epoch:31 step:147545[D loss: 1.000016] [G loss: 0.999841]\n",
      "epoch:31 step:147550[D loss: 1.000047] [G loss: 0.999922]\n",
      "epoch:31 step:147555[D loss: 0.999874] [G loss: 1.000181]\n",
      "epoch:31 step:147560[D loss: 0.999929] [G loss: 1.000079]\n",
      "epoch:31 step:147565[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:31 step:147570[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:31 step:147575[D loss: 1.000030] [G loss: 0.999964]\n",
      "epoch:31 step:147580[D loss: 1.000156] [G loss: 1.000005]\n",
      "epoch:31 step:147585[D loss: 0.999905] [G loss: 1.000108]\n",
      "epoch:31 step:147590[D loss: 1.000005] [G loss: 1.000243]\n",
      "epoch:31 step:147595[D loss: 1.000052] [G loss: 1.000130]\n",
      "epoch:31 step:147600[D loss: 0.999883] [G loss: 1.000178]\n",
      "##############\n",
      "[2.64547366 2.13502728 2.38695546 3.84841612 1.56291706 6.97530221\n",
      " 2.48854703 3.88201883 4.12090135 5.29460019]\n",
      "##########\n",
      "epoch:31 step:147605[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:31 step:147610[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:31 step:147615[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:31 step:147620[D loss: 1.000003] [G loss: 0.999988]\n",
      "epoch:31 step:147625[D loss: 1.000094] [G loss: 0.999887]\n",
      "epoch:31 step:147630[D loss: 1.000033] [G loss: 0.999973]\n",
      "epoch:31 step:147635[D loss: 1.000017] [G loss: 1.000012]\n",
      "epoch:31 step:147640[D loss: 0.999977] [G loss: 1.000142]\n",
      "epoch:31 step:147645[D loss: 0.999903] [G loss: 1.000125]\n",
      "epoch:31 step:147650[D loss: 0.999922] [G loss: 1.000125]\n",
      "epoch:31 step:147655[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:31 step:147660[D loss: 0.999974] [G loss: 1.000188]\n",
      "epoch:31 step:147665[D loss: 0.999906] [G loss: 1.000124]\n",
      "epoch:31 step:147670[D loss: 0.999993] [G loss: 1.000125]\n",
      "epoch:31 step:147675[D loss: 0.999975] [G loss: 1.000123]\n",
      "epoch:31 step:147680[D loss: 1.000048] [G loss: 0.999995]\n",
      "epoch:31 step:147685[D loss: 0.999961] [G loss: 1.000146]\n",
      "epoch:31 step:147690[D loss: 0.999952] [G loss: 1.000294]\n",
      "epoch:31 step:147695[D loss: 1.000000] [G loss: 1.000112]\n",
      "epoch:31 step:147700[D loss: 0.999941] [G loss: 1.000318]\n",
      "epoch:31 step:147705[D loss: 1.000056] [G loss: 1.000197]\n",
      "epoch:31 step:147710[D loss: 0.999885] [G loss: 1.000213]\n",
      "epoch:31 step:147715[D loss: 0.999933] [G loss: 1.000335]\n",
      "epoch:31 step:147720[D loss: 0.999906] [G loss: 1.000186]\n",
      "epoch:31 step:147725[D loss: 0.999991] [G loss: 1.000120]\n",
      "epoch:31 step:147730[D loss: 1.000071] [G loss: 0.999948]\n",
      "epoch:31 step:147735[D loss: 1.000113] [G loss: 0.999978]\n",
      "epoch:31 step:147740[D loss: 0.999894] [G loss: 0.999996]\n",
      "epoch:31 step:147745[D loss: 0.999914] [G loss: 1.000130]\n",
      "epoch:31 step:147750[D loss: 0.999854] [G loss: 1.000182]\n",
      "epoch:31 step:147755[D loss: 0.999918] [G loss: 1.000181]\n",
      "epoch:31 step:147760[D loss: 1.000033] [G loss: 1.000011]\n",
      "epoch:31 step:147765[D loss: 0.999786] [G loss: 1.000241]\n",
      "epoch:31 step:147770[D loss: 1.000022] [G loss: 1.000148]\n",
      "epoch:31 step:147775[D loss: 1.000036] [G loss: 1.000059]\n",
      "epoch:31 step:147780[D loss: 1.000052] [G loss: 1.000174]\n",
      "epoch:31 step:147785[D loss: 1.000157] [G loss: 1.000194]\n",
      "epoch:31 step:147790[D loss: 0.999705] [G loss: 1.000473]\n",
      "epoch:31 step:147795[D loss: 0.999850] [G loss: 1.000203]\n",
      "epoch:31 step:147800[D loss: 0.999966] [G loss: 1.000134]\n",
      "##############\n",
      "[2.53586902 2.25963063 2.49895823 3.48015776 1.51944299 7.71645058\n",
      " 2.49002957 3.8130622  4.0782213  5.92109777]\n",
      "##########\n",
      "epoch:31 step:147805[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:31 step:147810[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:31 step:147815[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:31 step:147820[D loss: 1.000228] [G loss: 0.999667]\n",
      "epoch:31 step:147825[D loss: 1.000062] [G loss: 0.999901]\n",
      "epoch:31 step:147830[D loss: 0.999917] [G loss: 1.000146]\n",
      "epoch:31 step:147835[D loss: 1.000041] [G loss: 0.999982]\n",
      "epoch:31 step:147840[D loss: 0.999883] [G loss: 1.000255]\n",
      "epoch:31 step:147845[D loss: 0.999914] [G loss: 1.000135]\n",
      "epoch:31 step:147850[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:31 step:147855[D loss: 1.000048] [G loss: 1.000170]\n",
      "epoch:31 step:147860[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:31 step:147865[D loss: 0.999937] [G loss: 1.000190]\n",
      "epoch:31 step:147870[D loss: 0.999925] [G loss: 1.000109]\n",
      "epoch:31 step:147875[D loss: 0.999952] [G loss: 1.000117]\n",
      "epoch:31 step:147880[D loss: 0.999948] [G loss: 1.000125]\n",
      "epoch:31 step:147885[D loss: 0.999968] [G loss: 1.000112]\n",
      "epoch:31 step:147890[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:31 step:147895[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:31 step:147900[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:31 step:147905[D loss: 1.000098] [G loss: 0.999990]\n",
      "epoch:31 step:147910[D loss: 0.999922] [G loss: 1.000144]\n",
      "epoch:31 step:147915[D loss: 1.000000] [G loss: 1.000141]\n",
      "epoch:31 step:147920[D loss: 0.999893] [G loss: 1.000336]\n",
      "epoch:31 step:147925[D loss: 0.999963] [G loss: 1.000118]\n",
      "epoch:31 step:147930[D loss: 0.999932] [G loss: 1.000234]\n",
      "epoch:31 step:147935[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:31 step:147940[D loss: 0.999942] [G loss: 1.000116]\n",
      "epoch:31 step:147945[D loss: 1.000012] [G loss: 0.999994]\n",
      "epoch:31 step:147950[D loss: 1.000182] [G loss: 0.999760]\n",
      "epoch:31 step:147955[D loss: 0.999966] [G loss: 0.999971]\n",
      "epoch:31 step:147960[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:31 step:147965[D loss: 0.999850] [G loss: 1.000188]\n",
      "epoch:31 step:147970[D loss: 1.000005] [G loss: 0.999883]\n",
      "epoch:31 step:147975[D loss: 1.000007] [G loss: 1.000010]\n",
      "epoch:31 step:147980[D loss: 0.999935] [G loss: 1.000128]\n",
      "epoch:31 step:147985[D loss: 0.999968] [G loss: 1.000323]\n",
      "epoch:31 step:147990[D loss: 0.999920] [G loss: 1.000047]\n",
      "epoch:31 step:147995[D loss: 1.000019] [G loss: 1.000073]\n",
      "epoch:31 step:148000[D loss: 1.000029] [G loss: 0.999995]\n",
      "##############\n",
      "[2.46923145 2.21289651 2.35830703 3.99681701 1.49751216 7.77659511\n",
      " 2.41525242 3.82987395 4.15027723 5.43325511]\n",
      "##########\n",
      "epoch:31 step:148005[D loss: 0.999955] [G loss: 1.000055]\n",
      "epoch:31 step:148010[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:31 step:148015[D loss: 1.000032] [G loss: 0.999943]\n",
      "epoch:31 step:148020[D loss: 0.999988] [G loss: 0.999976]\n",
      "epoch:31 step:148025[D loss: 1.000021] [G loss: 0.999908]\n",
      "epoch:31 step:148030[D loss: 1.000057] [G loss: 1.000019]\n",
      "epoch:31 step:148035[D loss: 0.999918] [G loss: 1.000130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:148040[D loss: 1.000012] [G loss: 1.000089]\n",
      "epoch:31 step:148045[D loss: 0.999971] [G loss: 1.000194]\n",
      "epoch:31 step:148050[D loss: 0.999999] [G loss: 1.000110]\n",
      "epoch:31 step:148055[D loss: 0.999913] [G loss: 1.000168]\n",
      "epoch:31 step:148060[D loss: 0.999954] [G loss: 1.000119]\n",
      "epoch:31 step:148065[D loss: 1.000012] [G loss: 0.999997]\n",
      "epoch:31 step:148070[D loss: 1.000015] [G loss: 0.999924]\n",
      "epoch:31 step:148075[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:31 step:148080[D loss: 1.000000] [G loss: 1.000072]\n",
      "epoch:31 step:148085[D loss: 1.000032] [G loss: 0.999994]\n",
      "epoch:31 step:148090[D loss: 0.999927] [G loss: 1.000092]\n",
      "epoch:31 step:148095[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:31 step:148100[D loss: 1.000067] [G loss: 0.999988]\n",
      "epoch:31 step:148105[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:31 step:148110[D loss: 1.000062] [G loss: 1.000098]\n",
      "epoch:31 step:148115[D loss: 0.999892] [G loss: 1.000266]\n",
      "epoch:31 step:148120[D loss: 0.999946] [G loss: 1.000030]\n",
      "epoch:31 step:148125[D loss: 1.000031] [G loss: 1.000079]\n",
      "epoch:31 step:148130[D loss: 0.999916] [G loss: 1.000135]\n",
      "epoch:31 step:148135[D loss: 0.999981] [G loss: 1.000214]\n",
      "epoch:31 step:148140[D loss: 0.999915] [G loss: 1.000149]\n",
      "epoch:31 step:148145[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:31 step:148150[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:31 step:148155[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:31 step:148160[D loss: 1.000000] [G loss: 0.999978]\n",
      "epoch:31 step:148165[D loss: 1.000070] [G loss: 0.999809]\n",
      "epoch:31 step:148170[D loss: 0.999973] [G loss: 0.999984]\n",
      "epoch:31 step:148175[D loss: 1.000157] [G loss: 0.999974]\n",
      "epoch:31 step:148180[D loss: 1.000222] [G loss: 0.999993]\n",
      "epoch:31 step:148185[D loss: 1.000088] [G loss: 0.999928]\n",
      "epoch:31 step:148190[D loss: 0.999960] [G loss: 1.000025]\n",
      "epoch:31 step:148195[D loss: 0.999788] [G loss: 1.000176]\n",
      "epoch:31 step:148200[D loss: 0.999958] [G loss: 1.000045]\n",
      "##############\n",
      "[2.49145922 2.2562612  2.25174885 3.53013454 1.50169135 6.96809902\n",
      " 2.44340044 3.71866729 4.0756998  5.36106027]\n",
      "##########\n",
      "epoch:31 step:148205[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:31 step:148210[D loss: 1.000097] [G loss: 0.999870]\n",
      "epoch:31 step:148215[D loss: 1.000072] [G loss: 0.999966]\n",
      "epoch:31 step:148220[D loss: 0.999914] [G loss: 1.000064]\n",
      "epoch:31 step:148225[D loss: 0.999938] [G loss: 1.000172]\n",
      "epoch:31 step:148230[D loss: 0.999883] [G loss: 1.000117]\n",
      "epoch:31 step:148235[D loss: 1.000019] [G loss: 1.000055]\n",
      "epoch:31 step:148240[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:31 step:148245[D loss: 0.999929] [G loss: 1.000103]\n",
      "epoch:31 step:148250[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:31 step:148255[D loss: 0.999960] [G loss: 1.000034]\n",
      "epoch:31 step:148260[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:31 step:148265[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:31 step:148270[D loss: 0.999917] [G loss: 1.000238]\n",
      "epoch:31 step:148275[D loss: 1.000014] [G loss: 1.000083]\n",
      "epoch:31 step:148280[D loss: 1.000180] [G loss: 1.000005]\n",
      "epoch:31 step:148285[D loss: 0.999871] [G loss: 1.000141]\n",
      "epoch:31 step:148290[D loss: 1.000011] [G loss: 1.000121]\n",
      "epoch:31 step:148295[D loss: 0.999967] [G loss: 1.000149]\n",
      "epoch:31 step:148300[D loss: 1.000001] [G loss: 0.999971]\n",
      "epoch:31 step:148305[D loss: 0.999976] [G loss: 0.999992]\n",
      "epoch:31 step:148310[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:31 step:148315[D loss: 0.999940] [G loss: 1.000043]\n",
      "epoch:31 step:148320[D loss: 1.000105] [G loss: 0.999869]\n",
      "epoch:31 step:148325[D loss: 1.000108] [G loss: 0.999849]\n",
      "epoch:31 step:148330[D loss: 0.999842] [G loss: 1.000120]\n",
      "epoch:31 step:148335[D loss: 1.000130] [G loss: 0.999955]\n",
      "epoch:31 step:148340[D loss: 1.000001] [G loss: 0.999957]\n",
      "epoch:31 step:148345[D loss: 0.999988] [G loss: 1.000250]\n",
      "epoch:31 step:148350[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:31 step:148355[D loss: 0.999946] [G loss: 1.000117]\n",
      "epoch:31 step:148360[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:31 step:148365[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:31 step:148370[D loss: 0.999884] [G loss: 1.000123]\n",
      "epoch:31 step:148375[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:31 step:148380[D loss: 1.000006] [G loss: 0.999988]\n",
      "epoch:31 step:148385[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:31 step:148390[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:31 step:148395[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:31 step:148400[D loss: 0.999940] [G loss: 1.000101]\n",
      "##############\n",
      "[2.58104118 2.21787738 2.23203439 3.98557167 1.49549522 8.16485202\n",
      " 2.46502906 4.03058083 4.00226636 6.10002795]\n",
      "##########\n",
      "epoch:31 step:148405[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:31 step:148410[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:31 step:148415[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:31 step:148420[D loss: 1.000042] [G loss: 1.000044]\n",
      "epoch:31 step:148425[D loss: 0.999930] [G loss: 1.000031]\n",
      "epoch:31 step:148430[D loss: 0.999897] [G loss: 1.000075]\n",
      "epoch:31 step:148435[D loss: 1.000039] [G loss: 0.999993]\n",
      "epoch:31 step:148440[D loss: 0.999959] [G loss: 1.000236]\n",
      "epoch:31 step:148445[D loss: 0.999960] [G loss: 1.000132]\n",
      "epoch:31 step:148450[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:31 step:148455[D loss: 1.000132] [G loss: 0.999806]\n",
      "epoch:31 step:148460[D loss: 1.000041] [G loss: 0.999936]\n",
      "epoch:31 step:148465[D loss: 1.000093] [G loss: 0.999912]\n",
      "epoch:31 step:148470[D loss: 0.999950] [G loss: 0.999990]\n",
      "epoch:31 step:148475[D loss: 0.999880] [G loss: 1.000162]\n",
      "epoch:31 step:148480[D loss: 1.000034] [G loss: 1.000000]\n",
      "epoch:31 step:148485[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:31 step:148490[D loss: 1.000025] [G loss: 1.000079]\n",
      "epoch:31 step:148495[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:31 step:148500[D loss: 0.999829] [G loss: 1.000186]\n",
      "epoch:31 step:148505[D loss: 0.999943] [G loss: 1.000077]\n",
      "epoch:31 step:148510[D loss: 0.999958] [G loss: 1.000109]\n",
      "epoch:31 step:148515[D loss: 1.000016] [G loss: 1.000026]\n",
      "epoch:31 step:148520[D loss: 1.000052] [G loss: 0.999939]\n",
      "epoch:31 step:148525[D loss: 0.999922] [G loss: 1.000062]\n",
      "epoch:31 step:148530[D loss: 0.999986] [G loss: 0.999965]\n",
      "epoch:31 step:148535[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:31 step:148540[D loss: 0.999962] [G loss: 1.000031]\n",
      "epoch:31 step:148545[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:31 step:148550[D loss: 0.999990] [G loss: 1.000119]\n",
      "epoch:31 step:148555[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:31 step:148560[D loss: 1.000010] [G loss: 1.000062]\n",
      "epoch:31 step:148565[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:31 step:148570[D loss: 0.999950] [G loss: 1.000038]\n",
      "epoch:31 step:148575[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:31 step:148580[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:31 step:148585[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:31 step:148590[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:31 step:148595[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:31 step:148600[D loss: 0.999966] [G loss: 1.000044]\n",
      "##############\n",
      "[2.47788206 2.14839863 2.22722005 3.38040726 1.51343561 7.09906822\n",
      " 2.4681453  3.77161669 3.97046518 5.15659482]\n",
      "##########\n",
      "epoch:31 step:148605[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:31 step:148610[D loss: 1.000004] [G loss: 1.000076]\n",
      "epoch:31 step:148615[D loss: 0.999923] [G loss: 1.000121]\n",
      "epoch:31 step:148620[D loss: 0.999948] [G loss: 1.000122]\n",
      "epoch:31 step:148625[D loss: 0.999946] [G loss: 1.000205]\n",
      "epoch:31 step:148630[D loss: 0.999959] [G loss: 1.000118]\n",
      "epoch:31 step:148635[D loss: 1.000012] [G loss: 0.999995]\n",
      "epoch:31 step:148640[D loss: 0.999943] [G loss: 1.000066]\n",
      "epoch:31 step:148645[D loss: 1.000015] [G loss: 1.000058]\n",
      "epoch:31 step:148650[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:31 step:148655[D loss: 0.999991] [G loss: 0.999995]\n",
      "epoch:31 step:148660[D loss: 1.000012] [G loss: 1.000050]\n",
      "epoch:31 step:148665[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:31 step:148670[D loss: 0.999910] [G loss: 1.000112]\n",
      "epoch:31 step:148675[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:31 step:148680[D loss: 1.000025] [G loss: 0.999938]\n",
      "epoch:31 step:148685[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:31 step:148690[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:31 step:148695[D loss: 0.999928] [G loss: 1.000079]\n",
      "epoch:31 step:148700[D loss: 1.000045] [G loss: 1.000085]\n",
      "epoch:31 step:148705[D loss: 0.999958] [G loss: 1.000119]\n",
      "epoch:31 step:148710[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:31 step:148715[D loss: 0.999941] [G loss: 1.000095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:148720[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:31 step:148725[D loss: 1.000008] [G loss: 1.000012]\n",
      "epoch:31 step:148730[D loss: 0.999974] [G loss: 1.000036]\n",
      "epoch:31 step:148735[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:31 step:148740[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:31 step:148745[D loss: 0.999957] [G loss: 1.000102]\n",
      "epoch:31 step:148750[D loss: 0.999935] [G loss: 1.000119]\n",
      "epoch:31 step:148755[D loss: 1.000021] [G loss: 1.000002]\n",
      "epoch:31 step:148760[D loss: 0.999928] [G loss: 1.000183]\n",
      "epoch:31 step:148765[D loss: 0.999921] [G loss: 1.000131]\n",
      "epoch:31 step:148770[D loss: 0.999990] [G loss: 1.000007]\n",
      "epoch:31 step:148775[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:31 step:148780[D loss: 0.999955] [G loss: 1.000046]\n",
      "epoch:31 step:148785[D loss: 1.000059] [G loss: 0.999908]\n",
      "epoch:31 step:148790[D loss: 1.000022] [G loss: 0.999940]\n",
      "epoch:31 step:148795[D loss: 0.999985] [G loss: 0.999937]\n",
      "epoch:31 step:148800[D loss: 0.999912] [G loss: 1.000042]\n",
      "##############\n",
      "[2.5219226  2.13582181 2.18842214 3.6301059  1.50549401 7.46378942\n",
      " 2.47926104 3.63702358 3.93590452 5.22514027]\n",
      "##########\n",
      "epoch:31 step:148805[D loss: 1.000293] [G loss: 0.999865]\n",
      "epoch:31 step:148810[D loss: 0.999900] [G loss: 1.000098]\n",
      "epoch:31 step:148815[D loss: 0.999847] [G loss: 1.000166]\n",
      "epoch:31 step:148820[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:31 step:148825[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:31 step:148830[D loss: 1.000032] [G loss: 0.999959]\n",
      "epoch:31 step:148835[D loss: 0.999976] [G loss: 1.000012]\n",
      "epoch:31 step:148840[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:31 step:148845[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:31 step:148850[D loss: 0.999999] [G loss: 0.999999]\n",
      "epoch:31 step:148855[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:31 step:148860[D loss: 0.999966] [G loss: 1.000019]\n",
      "epoch:31 step:148865[D loss: 1.000030] [G loss: 0.999921]\n",
      "epoch:31 step:148870[D loss: 0.999970] [G loss: 1.000039]\n",
      "epoch:31 step:148875[D loss: 1.000042] [G loss: 0.999974]\n",
      "epoch:31 step:148880[D loss: 0.999939] [G loss: 1.000040]\n",
      "epoch:31 step:148885[D loss: 1.000040] [G loss: 0.999986]\n",
      "epoch:31 step:148890[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:31 step:148895[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:31 step:148900[D loss: 0.999971] [G loss: 1.000021]\n",
      "epoch:31 step:148905[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:31 step:148910[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:31 step:148915[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:31 step:148920[D loss: 1.000002] [G loss: 1.000096]\n",
      "epoch:31 step:148925[D loss: 0.999920] [G loss: 1.000105]\n",
      "epoch:31 step:148930[D loss: 1.000023] [G loss: 1.000047]\n",
      "epoch:31 step:148935[D loss: 0.999974] [G loss: 1.000160]\n",
      "epoch:31 step:148940[D loss: 0.999991] [G loss: 0.999968]\n",
      "epoch:31 step:148945[D loss: 1.000030] [G loss: 1.000095]\n",
      "epoch:31 step:148950[D loss: 0.999931] [G loss: 1.000033]\n",
      "epoch:31 step:148955[D loss: 0.999993] [G loss: 0.999983]\n",
      "epoch:31 step:148960[D loss: 0.999962] [G loss: 1.000044]\n",
      "epoch:31 step:148965[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:31 step:148970[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:31 step:148975[D loss: 1.000048] [G loss: 0.999906]\n",
      "epoch:31 step:148980[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:31 step:148985[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:31 step:148990[D loss: 0.999947] [G loss: 1.000072]\n",
      "epoch:31 step:148995[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:31 step:149000[D loss: 0.999992] [G loss: 1.000046]\n",
      "##############\n",
      "[2.47957079 2.19208465 2.24502275 3.50381473 1.46491247 7.19625902\n",
      " 2.3262849  3.7404245  4.01630565 5.09745361]\n",
      "##########\n",
      "epoch:31 step:149005[D loss: 1.000122] [G loss: 0.999971]\n",
      "epoch:31 step:149010[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:31 step:149015[D loss: 0.999920] [G loss: 1.000065]\n",
      "epoch:31 step:149020[D loss: 0.999959] [G loss: 1.000026]\n",
      "epoch:31 step:149025[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:31 step:149030[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:31 step:149035[D loss: 1.000003] [G loss: 0.999988]\n",
      "epoch:31 step:149040[D loss: 1.000067] [G loss: 0.999911]\n",
      "epoch:31 step:149045[D loss: 1.000114] [G loss: 0.999943]\n",
      "epoch:31 step:149050[D loss: 0.999980] [G loss: 1.000005]\n",
      "epoch:31 step:149055[D loss: 1.000094] [G loss: 0.999878]\n",
      "epoch:31 step:149060[D loss: 1.000006] [G loss: 0.999995]\n",
      "epoch:31 step:149065[D loss: 0.999924] [G loss: 1.000141]\n",
      "epoch:31 step:149070[D loss: 0.999999] [G loss: 1.000055]\n",
      "epoch:31 step:149075[D loss: 0.999968] [G loss: 1.000104]\n",
      "epoch:31 step:149080[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:31 step:149085[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:31 step:149090[D loss: 1.000075] [G loss: 0.999838]\n",
      "epoch:31 step:149095[D loss: 1.000007] [G loss: 1.000066]\n",
      "epoch:31 step:149100[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:31 step:149105[D loss: 1.000354] [G loss: 0.999657]\n",
      "epoch:31 step:149110[D loss: 0.999797] [G loss: 1.000134]\n",
      "epoch:31 step:149115[D loss: 0.999964] [G loss: 1.000123]\n",
      "epoch:31 step:149120[D loss: 0.999988] [G loss: 0.999978]\n",
      "epoch:31 step:149125[D loss: 0.999942] [G loss: 1.000008]\n",
      "epoch:31 step:149130[D loss: 1.000001] [G loss: 1.000010]\n",
      "epoch:31 step:149135[D loss: 0.999976] [G loss: 0.999978]\n",
      "epoch:31 step:149140[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:31 step:149145[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:31 step:149150[D loss: 1.000032] [G loss: 0.999954]\n",
      "epoch:31 step:149155[D loss: 1.000009] [G loss: 1.000035]\n",
      "epoch:31 step:149160[D loss: 0.999958] [G loss: 1.000056]\n",
      "epoch:31 step:149165[D loss: 1.000021] [G loss: 1.000048]\n",
      "epoch:31 step:149170[D loss: 0.999956] [G loss: 1.000115]\n",
      "epoch:31 step:149175[D loss: 0.999888] [G loss: 1.000349]\n",
      "epoch:31 step:149180[D loss: 1.000126] [G loss: 0.999945]\n",
      "epoch:31 step:149185[D loss: 0.999858] [G loss: 1.000126]\n",
      "epoch:31 step:149190[D loss: 0.999965] [G loss: 1.000039]\n",
      "epoch:31 step:149195[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:31 step:149200[D loss: 0.999986] [G loss: 1.000066]\n",
      "##############\n",
      "[2.56385668 2.17728467 2.22317713 3.92545629 1.53210759 6.88424086\n",
      " 2.23461821 3.5933107  3.93572603 4.74114844]\n",
      "##########\n",
      "epoch:31 step:149205[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:31 step:149210[D loss: 0.999942] [G loss: 1.000063]\n",
      "epoch:31 step:149215[D loss: 1.000103] [G loss: 0.999843]\n",
      "epoch:31 step:149220[D loss: 0.999976] [G loss: 0.999990]\n",
      "epoch:31 step:149225[D loss: 1.000012] [G loss: 1.000194]\n",
      "epoch:31 step:149230[D loss: 0.999971] [G loss: 0.999976]\n",
      "epoch:31 step:149235[D loss: 0.999874] [G loss: 1.000126]\n",
      "epoch:31 step:149240[D loss: 0.999936] [G loss: 1.000094]\n",
      "epoch:31 step:149245[D loss: 0.999930] [G loss: 1.000139]\n",
      "epoch:31 step:149250[D loss: 1.000029] [G loss: 1.000031]\n",
      "epoch:31 step:149255[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:31 step:149260[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:31 step:149265[D loss: 0.999944] [G loss: 1.000093]\n",
      "epoch:31 step:149270[D loss: 1.000030] [G loss: 1.000001]\n",
      "epoch:31 step:149275[D loss: 1.000066] [G loss: 1.000063]\n",
      "epoch:31 step:149280[D loss: 0.999910] [G loss: 1.000128]\n",
      "epoch:31 step:149285[D loss: 0.999953] [G loss: 1.000129]\n",
      "epoch:31 step:149290[D loss: 0.999940] [G loss: 1.000200]\n",
      "epoch:31 step:149295[D loss: 0.999982] [G loss: 1.000143]\n",
      "epoch:31 step:149300[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:31 step:149305[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:31 step:149310[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:31 step:149315[D loss: 0.999991] [G loss: 1.000090]\n",
      "epoch:31 step:149320[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:31 step:149325[D loss: 1.000003] [G loss: 1.000108]\n",
      "epoch:31 step:149330[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:31 step:149335[D loss: 0.999937] [G loss: 1.000105]\n",
      "epoch:31 step:149340[D loss: 0.999975] [G loss: 1.000131]\n",
      "epoch:31 step:149345[D loss: 0.999918] [G loss: 1.000167]\n",
      "epoch:31 step:149350[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:31 step:149355[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:31 step:149360[D loss: 1.000013] [G loss: 1.000028]\n",
      "epoch:31 step:149365[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:31 step:149370[D loss: 1.000000] [G loss: 1.000069]\n",
      "epoch:31 step:149375[D loss: 0.999935] [G loss: 1.000132]\n",
      "epoch:31 step:149380[D loss: 1.000081] [G loss: 1.000038]\n",
      "epoch:31 step:149385[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:31 step:149390[D loss: 0.999982] [G loss: 1.000115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:149395[D loss: 1.000099] [G loss: 1.000008]\n",
      "epoch:31 step:149400[D loss: 0.999922] [G loss: 1.000100]\n",
      "##############\n",
      "[2.61332374 2.22720769 2.25309964 3.43227072 1.46571678 7.93697547\n",
      " 2.38174025 3.60231842 4.01681084 5.16253929]\n",
      "##########\n",
      "epoch:31 step:149405[D loss: 1.000120] [G loss: 1.000157]\n",
      "epoch:31 step:149410[D loss: 0.999856] [G loss: 1.000336]\n",
      "epoch:31 step:149415[D loss: 0.999881] [G loss: 1.000156]\n",
      "epoch:31 step:149420[D loss: 0.999931] [G loss: 1.000163]\n",
      "epoch:31 step:149425[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:31 step:149430[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:31 step:149435[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:31 step:149440[D loss: 0.999999] [G loss: 1.000002]\n",
      "epoch:31 step:149445[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:31 step:149450[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:31 step:149455[D loss: 1.000085] [G loss: 0.999950]\n",
      "epoch:31 step:149460[D loss: 0.999876] [G loss: 1.000185]\n",
      "epoch:31 step:149465[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:31 step:149470[D loss: 0.999939] [G loss: 1.000091]\n",
      "epoch:31 step:149475[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:31 step:149480[D loss: 0.999996] [G loss: 1.000303]\n",
      "epoch:31 step:149485[D loss: 0.999939] [G loss: 1.000115]\n",
      "epoch:31 step:149490[D loss: 0.999891] [G loss: 1.000235]\n",
      "epoch:31 step:149495[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:31 step:149500[D loss: 1.000046] [G loss: 0.999935]\n",
      "epoch:31 step:149505[D loss: 0.999993] [G loss: 0.999831]\n",
      "epoch:31 step:149510[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:31 step:149515[D loss: 1.000094] [G loss: 0.999871]\n",
      "epoch:31 step:149520[D loss: 1.000032] [G loss: 1.000000]\n",
      "epoch:31 step:149525[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:31 step:149530[D loss: 0.999946] [G loss: 1.000102]\n",
      "epoch:31 step:149535[D loss: 0.999953] [G loss: 1.000010]\n",
      "epoch:31 step:149540[D loss: 0.999890] [G loss: 1.000243]\n",
      "epoch:31 step:149545[D loss: 0.999929] [G loss: 1.000134]\n",
      "epoch:31 step:149550[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:31 step:149555[D loss: 1.000031] [G loss: 1.000078]\n",
      "epoch:31 step:149560[D loss: 0.999941] [G loss: 1.000041]\n",
      "epoch:31 step:149565[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:31 step:149570[D loss: 0.999931] [G loss: 1.000201]\n",
      "epoch:31 step:149575[D loss: 0.999945] [G loss: 1.000103]\n",
      "epoch:31 step:149580[D loss: 1.000080] [G loss: 1.000004]\n",
      "epoch:31 step:149585[D loss: 1.000099] [G loss: 1.000122]\n",
      "epoch:31 step:149590[D loss: 0.999889] [G loss: 1.000129]\n",
      "epoch:31 step:149595[D loss: 1.000003] [G loss: 1.000016]\n",
      "epoch:31 step:149600[D loss: 0.999983] [G loss: 1.000025]\n",
      "##############\n",
      "[2.56535872 2.1087616  2.27889135 3.64344964 1.50801453 7.62215476\n",
      " 2.24381355 3.73006045 3.92177252 5.190648  ]\n",
      "##########\n",
      "epoch:31 step:149605[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:31 step:149610[D loss: 0.999977] [G loss: 1.000018]\n",
      "epoch:31 step:149615[D loss: 1.000058] [G loss: 0.999920]\n",
      "epoch:31 step:149620[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:31 step:149625[D loss: 0.999990] [G loss: 1.000098]\n",
      "epoch:31 step:149630[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:31 step:149635[D loss: 0.999987] [G loss: 1.000004]\n",
      "epoch:31 step:149640[D loss: 0.999980] [G loss: 1.000009]\n",
      "epoch:31 step:149645[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:31 step:149650[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:31 step:149655[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:31 step:149660[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:31 step:149665[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:31 step:149670[D loss: 0.999966] [G loss: 1.000106]\n",
      "epoch:31 step:149675[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:31 step:149680[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:31 step:149685[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:31 step:149690[D loss: 1.000009] [G loss: 1.000010]\n",
      "epoch:31 step:149695[D loss: 0.999944] [G loss: 1.000067]\n",
      "epoch:31 step:149700[D loss: 1.000025] [G loss: 0.999962]\n",
      "epoch:31 step:149705[D loss: 1.000014] [G loss: 0.999991]\n",
      "epoch:31 step:149710[D loss: 1.000026] [G loss: 0.999896]\n",
      "epoch:31 step:149715[D loss: 0.999951] [G loss: 1.000040]\n",
      "epoch:31 step:149720[D loss: 0.999967] [G loss: 1.000038]\n",
      "epoch:31 step:149725[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:31 step:149730[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:31 step:149735[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:31 step:149740[D loss: 1.000071] [G loss: 1.000002]\n",
      "epoch:31 step:149745[D loss: 0.999994] [G loss: 1.000010]\n",
      "epoch:31 step:149750[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:31 step:149755[D loss: 1.000023] [G loss: 0.999951]\n",
      "epoch:31 step:149760[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:31 step:149765[D loss: 1.000029] [G loss: 1.000054]\n",
      "epoch:31 step:149770[D loss: 0.999945] [G loss: 0.999993]\n",
      "epoch:31 step:149775[D loss: 1.000030] [G loss: 1.000122]\n",
      "epoch:31 step:149780[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:31 step:149785[D loss: 0.999974] [G loss: 1.000136]\n",
      "epoch:31 step:149790[D loss: 0.999934] [G loss: 1.000046]\n",
      "epoch:31 step:149795[D loss: 0.999978] [G loss: 0.999964]\n",
      "epoch:31 step:149800[D loss: 0.999971] [G loss: 1.000030]\n",
      "##############\n",
      "[2.54444504 2.18833905 2.42029842 3.66910579 1.52005264 7.58958944\n",
      " 2.414877   3.83488356 4.07146775 5.08436006]\n",
      "##########\n",
      "epoch:31 step:149805[D loss: 0.999950] [G loss: 1.000121]\n",
      "epoch:31 step:149810[D loss: 1.000019] [G loss: 1.000043]\n",
      "epoch:31 step:149815[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:31 step:149820[D loss: 1.000046] [G loss: 1.000079]\n",
      "epoch:31 step:149825[D loss: 0.999922] [G loss: 1.000053]\n",
      "epoch:31 step:149830[D loss: 0.999992] [G loss: 0.999993]\n",
      "epoch:31 step:149835[D loss: 1.000007] [G loss: 0.999931]\n",
      "epoch:31 step:149840[D loss: 1.000048] [G loss: 0.999966]\n",
      "epoch:31 step:149845[D loss: 0.999950] [G loss: 1.000162]\n",
      "epoch:31 step:149850[D loss: 0.999932] [G loss: 1.000092]\n",
      "epoch:31 step:149855[D loss: 0.999945] [G loss: 1.000087]\n",
      "epoch:31 step:149860[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:31 step:149865[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:31 step:149870[D loss: 0.999990] [G loss: 1.000013]\n",
      "epoch:31 step:149875[D loss: 1.000023] [G loss: 1.000015]\n",
      "epoch:31 step:149880[D loss: 0.999956] [G loss: 1.000023]\n",
      "epoch:31 step:149885[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:31 step:149890[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:31 step:149895[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:31 step:149900[D loss: 1.000006] [G loss: 1.000088]\n",
      "epoch:31 step:149905[D loss: 0.999949] [G loss: 1.000080]\n",
      "epoch:31 step:149910[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:31 step:149915[D loss: 1.000010] [G loss: 1.000008]\n",
      "epoch:31 step:149920[D loss: 0.999954] [G loss: 1.000129]\n",
      "epoch:32 step:149925[D loss: 1.000037] [G loss: 1.000055]\n",
      "epoch:32 step:149930[D loss: 0.999956] [G loss: 1.000137]\n",
      "epoch:32 step:149935[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:32 step:149940[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:32 step:149945[D loss: 0.999976] [G loss: 0.999994]\n",
      "epoch:32 step:149950[D loss: 0.999983] [G loss: 1.000011]\n",
      "epoch:32 step:149955[D loss: 1.000025] [G loss: 0.999998]\n",
      "epoch:32 step:149960[D loss: 0.999961] [G loss: 1.000032]\n",
      "epoch:32 step:149965[D loss: 1.000136] [G loss: 0.999895]\n",
      "epoch:32 step:149970[D loss: 0.999934] [G loss: 1.000258]\n",
      "epoch:32 step:149975[D loss: 1.000061] [G loss: 0.999925]\n",
      "epoch:32 step:149980[D loss: 0.999854] [G loss: 1.000181]\n",
      "epoch:32 step:149985[D loss: 0.999908] [G loss: 1.000130]\n",
      "epoch:32 step:149990[D loss: 0.999952] [G loss: 1.000050]\n",
      "epoch:32 step:149995[D loss: 0.999959] [G loss: 1.000122]\n",
      "epoch:32 step:150000[D loss: 0.999976] [G loss: 1.000071]\n",
      "##############\n",
      "[2.56816376 2.18671699 2.19931725 3.61826435 1.50040304 7.55888218\n",
      " 2.42031536 3.73912014 4.0902301  6.10729899]\n",
      "##########\n",
      "epoch:32 step:150005[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:32 step:150010[D loss: 1.000021] [G loss: 1.000006]\n",
      "epoch:32 step:150015[D loss: 1.000025] [G loss: 0.999996]\n",
      "epoch:32 step:150020[D loss: 0.999924] [G loss: 1.000055]\n",
      "epoch:32 step:150025[D loss: 0.999995] [G loss: 1.000093]\n",
      "epoch:32 step:150030[D loss: 0.999990] [G loss: 1.000116]\n",
      "epoch:32 step:150035[D loss: 0.999857] [G loss: 1.000150]\n",
      "epoch:32 step:150040[D loss: 0.999977] [G loss: 1.000122]\n",
      "epoch:32 step:150045[D loss: 0.999892] [G loss: 1.000163]\n",
      "epoch:32 step:150050[D loss: 1.000094] [G loss: 1.000037]\n",
      "epoch:32 step:150055[D loss: 1.000076] [G loss: 1.000151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:150060[D loss: 0.999871] [G loss: 1.000215]\n",
      "epoch:32 step:150065[D loss: 0.999933] [G loss: 1.000058]\n",
      "epoch:32 step:150070[D loss: 1.000020] [G loss: 0.999963]\n",
      "epoch:32 step:150075[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:32 step:150080[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:32 step:150085[D loss: 0.999991] [G loss: 0.999988]\n",
      "epoch:32 step:150090[D loss: 0.999953] [G loss: 1.000055]\n",
      "epoch:32 step:150095[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:32 step:150100[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:32 step:150105[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:32 step:150110[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:32 step:150115[D loss: 0.999992] [G loss: 1.000001]\n",
      "epoch:32 step:150120[D loss: 1.000033] [G loss: 1.000027]\n",
      "epoch:32 step:150125[D loss: 1.000027] [G loss: 0.999954]\n",
      "epoch:32 step:150130[D loss: 0.999918] [G loss: 1.000125]\n",
      "epoch:32 step:150135[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:32 step:150140[D loss: 0.999972] [G loss: 1.000028]\n",
      "epoch:32 step:150145[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:32 step:150150[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:32 step:150155[D loss: 0.999950] [G loss: 1.000036]\n",
      "epoch:32 step:150160[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:32 step:150165[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:32 step:150170[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:32 step:150175[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:32 step:150180[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:32 step:150185[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:32 step:150190[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:32 step:150195[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:32 step:150200[D loss: 0.999970] [G loss: 1.000052]\n",
      "##############\n",
      "[2.57948083 2.29208279 2.30466358 3.57551865 1.56629018 7.48977708\n",
      " 2.39540081 3.86869776 4.13399163 5.34393282]\n",
      "##########\n",
      "epoch:32 step:150205[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:32 step:150210[D loss: 1.000016] [G loss: 0.999999]\n",
      "epoch:32 step:150215[D loss: 0.999999] [G loss: 1.000007]\n",
      "epoch:32 step:150220[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:32 step:150225[D loss: 0.999973] [G loss: 1.000013]\n",
      "epoch:32 step:150230[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:32 step:150235[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:32 step:150240[D loss: 0.999955] [G loss: 1.000128]\n",
      "epoch:32 step:150245[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:32 step:150250[D loss: 0.999955] [G loss: 1.000070]\n",
      "epoch:32 step:150255[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:32 step:150260[D loss: 0.999982] [G loss: 1.000017]\n",
      "epoch:32 step:150265[D loss: 1.000022] [G loss: 1.000100]\n",
      "epoch:32 step:150270[D loss: 1.000010] [G loss: 0.999998]\n",
      "epoch:32 step:150275[D loss: 0.999936] [G loss: 1.000130]\n",
      "epoch:32 step:150280[D loss: 0.999978] [G loss: 1.000121]\n",
      "epoch:32 step:150285[D loss: 1.000045] [G loss: 0.999992]\n",
      "epoch:32 step:150290[D loss: 0.999999] [G loss: 1.000012]\n",
      "epoch:32 step:150295[D loss: 1.000132] [G loss: 0.999938]\n",
      "epoch:32 step:150300[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:32 step:150305[D loss: 0.999881] [G loss: 1.000229]\n",
      "epoch:32 step:150310[D loss: 1.000043] [G loss: 0.999929]\n",
      "epoch:32 step:150315[D loss: 0.999963] [G loss: 1.000137]\n",
      "epoch:32 step:150320[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:32 step:150325[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:32 step:150330[D loss: 1.000047] [G loss: 0.999937]\n",
      "epoch:32 step:150335[D loss: 0.999979] [G loss: 0.999961]\n",
      "epoch:32 step:150340[D loss: 0.999990] [G loss: 0.999997]\n",
      "epoch:32 step:150345[D loss: 1.000052] [G loss: 1.000031]\n",
      "epoch:32 step:150350[D loss: 0.999945] [G loss: 1.000067]\n",
      "epoch:32 step:150355[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:32 step:150360[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:32 step:150365[D loss: 0.999945] [G loss: 1.000292]\n",
      "epoch:32 step:150370[D loss: 0.999932] [G loss: 1.000144]\n",
      "epoch:32 step:150375[D loss: 0.999946] [G loss: 1.000099]\n",
      "epoch:32 step:150380[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:32 step:150385[D loss: 0.999999] [G loss: 1.000084]\n",
      "epoch:32 step:150390[D loss: 0.999993] [G loss: 0.999992]\n",
      "epoch:32 step:150395[D loss: 1.000057] [G loss: 1.000061]\n",
      "epoch:32 step:150400[D loss: 1.000023] [G loss: 1.000032]\n",
      "##############\n",
      "[2.62477117 2.19289306 2.41475707 3.79579306 1.66267448 7.93019175\n",
      " 2.45677216 3.82728068 4.13137849 5.19312061]\n",
      "##########\n",
      "epoch:32 step:150405[D loss: 0.999852] [G loss: 1.000364]\n",
      "epoch:32 step:150410[D loss: 0.999982] [G loss: 1.000168]\n",
      "epoch:32 step:150415[D loss: 0.999987] [G loss: 1.000125]\n",
      "epoch:32 step:150420[D loss: 0.999948] [G loss: 1.000111]\n",
      "epoch:32 step:150425[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:32 step:150430[D loss: 0.999942] [G loss: 1.000125]\n",
      "epoch:32 step:150435[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:32 step:150440[D loss: 0.999997] [G loss: 1.000016]\n",
      "epoch:32 step:150445[D loss: 1.000104] [G loss: 0.999852]\n",
      "epoch:32 step:150450[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:32 step:150455[D loss: 0.999928] [G loss: 1.000171]\n",
      "epoch:32 step:150460[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:32 step:150465[D loss: 0.999912] [G loss: 1.000094]\n",
      "epoch:32 step:150470[D loss: 0.999993] [G loss: 1.000093]\n",
      "epoch:32 step:150475[D loss: 0.999979] [G loss: 0.999987]\n",
      "epoch:32 step:150480[D loss: 0.999943] [G loss: 1.000135]\n",
      "epoch:32 step:150485[D loss: 1.000029] [G loss: 1.000029]\n",
      "epoch:32 step:150490[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:32 step:150495[D loss: 0.999998] [G loss: 1.000086]\n",
      "epoch:32 step:150500[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:32 step:150505[D loss: 1.000048] [G loss: 0.999953]\n",
      "epoch:32 step:150510[D loss: 1.000019] [G loss: 1.000026]\n",
      "epoch:32 step:150515[D loss: 1.000033] [G loss: 1.000165]\n",
      "epoch:32 step:150520[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:32 step:150525[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:32 step:150530[D loss: 0.999926] [G loss: 1.000196]\n",
      "epoch:32 step:150535[D loss: 0.999923] [G loss: 1.000128]\n",
      "epoch:32 step:150540[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:32 step:150545[D loss: 1.000004] [G loss: 1.000013]\n",
      "epoch:32 step:150550[D loss: 1.000005] [G loss: 1.000076]\n",
      "epoch:32 step:150555[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:32 step:150560[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:32 step:150565[D loss: 1.000083] [G loss: 0.999901]\n",
      "epoch:32 step:150570[D loss: 0.999926] [G loss: 1.000064]\n",
      "epoch:32 step:150575[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:32 step:150580[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:32 step:150585[D loss: 0.999949] [G loss: 1.000055]\n",
      "epoch:32 step:150590[D loss: 0.999995] [G loss: 1.000083]\n",
      "epoch:32 step:150595[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:32 step:150600[D loss: 0.999951] [G loss: 1.000089]\n",
      "##############\n",
      "[2.56264675 2.17040707 2.22700017 3.87698769 1.53122574 7.08199307\n",
      " 2.45872642 3.71091515 4.06547929 5.72161496]\n",
      "##########\n",
      "epoch:32 step:150605[D loss: 1.000018] [G loss: 1.000034]\n",
      "epoch:32 step:150610[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:32 step:150615[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:32 step:150620[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:32 step:150625[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:32 step:150630[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:32 step:150635[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:32 step:150640[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:32 step:150645[D loss: 0.999987] [G loss: 1.000096]\n",
      "epoch:32 step:150650[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:32 step:150655[D loss: 1.000032] [G loss: 1.000046]\n",
      "epoch:32 step:150660[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:32 step:150665[D loss: 1.000041] [G loss: 0.999981]\n",
      "epoch:32 step:150670[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:32 step:150675[D loss: 0.999950] [G loss: 1.000072]\n",
      "epoch:32 step:150680[D loss: 0.999992] [G loss: 1.000008]\n",
      "epoch:32 step:150685[D loss: 0.999978] [G loss: 1.000024]\n",
      "epoch:32 step:150690[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:32 step:150695[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:32 step:150700[D loss: 0.999954] [G loss: 1.000145]\n",
      "epoch:32 step:150705[D loss: 0.999909] [G loss: 1.000074]\n",
      "epoch:32 step:150710[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:32 step:150715[D loss: 1.000004] [G loss: 0.999995]\n",
      "epoch:32 step:150720[D loss: 0.999994] [G loss: 1.000003]\n",
      "epoch:32 step:150725[D loss: 1.000028] [G loss: 0.999968]\n",
      "epoch:32 step:150730[D loss: 1.000016] [G loss: 0.999999]\n",
      "epoch:32 step:150735[D loss: 0.999886] [G loss: 1.000135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:150740[D loss: 0.999926] [G loss: 1.000067]\n",
      "epoch:32 step:150745[D loss: 1.000013] [G loss: 0.999995]\n",
      "epoch:32 step:150750[D loss: 1.000072] [G loss: 0.999887]\n",
      "epoch:32 step:150755[D loss: 0.999904] [G loss: 1.000130]\n",
      "epoch:32 step:150760[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:32 step:150765[D loss: 0.999953] [G loss: 1.000047]\n",
      "epoch:32 step:150770[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:32 step:150775[D loss: 0.999951] [G loss: 1.000104]\n",
      "epoch:32 step:150780[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:32 step:150785[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:32 step:150790[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:32 step:150795[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:32 step:150800[D loss: 0.999963] [G loss: 1.000075]\n",
      "##############\n",
      "[2.6280917  2.19073071 2.21839146 3.93321938 1.5163126  6.94923178\n",
      " 2.42787959 3.96793626 4.07080664 4.86604788]\n",
      "##########\n",
      "epoch:32 step:150805[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:32 step:150810[D loss: 0.999991] [G loss: 1.000103]\n",
      "epoch:32 step:150815[D loss: 1.000019] [G loss: 1.000039]\n",
      "epoch:32 step:150820[D loss: 0.999946] [G loss: 1.000085]\n",
      "epoch:32 step:150825[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:32 step:150830[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:32 step:150835[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:32 step:150840[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:32 step:150845[D loss: 1.000046] [G loss: 0.999957]\n",
      "epoch:32 step:150850[D loss: 0.999996] [G loss: 1.000019]\n",
      "epoch:32 step:150855[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:32 step:150860[D loss: 1.000020] [G loss: 1.000044]\n",
      "epoch:32 step:150865[D loss: 0.999951] [G loss: 1.000094]\n",
      "epoch:32 step:150870[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:32 step:150875[D loss: 1.000016] [G loss: 1.000021]\n",
      "epoch:32 step:150880[D loss: 0.999962] [G loss: 1.000036]\n",
      "epoch:32 step:150885[D loss: 1.000008] [G loss: 1.000028]\n",
      "epoch:32 step:150890[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:32 step:150895[D loss: 1.000038] [G loss: 0.999959]\n",
      "epoch:32 step:150900[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:32 step:150905[D loss: 0.999944] [G loss: 1.000193]\n",
      "epoch:32 step:150910[D loss: 1.000048] [G loss: 1.000146]\n",
      "epoch:32 step:150915[D loss: 0.999934] [G loss: 1.000158]\n",
      "epoch:32 step:150920[D loss: 1.000026] [G loss: 1.000241]\n",
      "epoch:32 step:150925[D loss: 0.999915] [G loss: 1.000195]\n",
      "epoch:32 step:150930[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:32 step:150935[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:32 step:150940[D loss: 1.000057] [G loss: 0.999979]\n",
      "epoch:32 step:150945[D loss: 0.999931] [G loss: 1.000068]\n",
      "epoch:32 step:150950[D loss: 1.000076] [G loss: 0.999936]\n",
      "epoch:32 step:150955[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:32 step:150960[D loss: 0.999932] [G loss: 1.000010]\n",
      "epoch:32 step:150965[D loss: 0.999981] [G loss: 1.000128]\n",
      "epoch:32 step:150970[D loss: 1.000011] [G loss: 1.000055]\n",
      "epoch:32 step:150975[D loss: 0.999935] [G loss: 1.000126]\n",
      "epoch:32 step:150980[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:32 step:150985[D loss: 0.999914] [G loss: 1.000146]\n",
      "epoch:32 step:150990[D loss: 1.000013] [G loss: 1.000082]\n",
      "epoch:32 step:150995[D loss: 0.999899] [G loss: 1.000228]\n",
      "epoch:32 step:151000[D loss: 0.999934] [G loss: 1.000233]\n",
      "##############\n",
      "[2.6552969  2.28681507 2.42024398 3.62064818 1.5363457  6.72433831\n",
      " 2.39689627 3.7832587  4.16588543 5.42731513]\n",
      "##########\n",
      "epoch:32 step:151005[D loss: 1.000090] [G loss: 1.000244]\n",
      "epoch:32 step:151010[D loss: 1.000014] [G loss: 1.000023]\n",
      "epoch:32 step:151015[D loss: 0.999914] [G loss: 1.000125]\n",
      "epoch:32 step:151020[D loss: 0.999972] [G loss: 1.000120]\n",
      "epoch:32 step:151025[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:32 step:151030[D loss: 1.000027] [G loss: 0.999981]\n",
      "epoch:32 step:151035[D loss: 1.000022] [G loss: 0.999970]\n",
      "epoch:32 step:151040[D loss: 1.000122] [G loss: 0.999839]\n",
      "epoch:32 step:151045[D loss: 0.999887] [G loss: 1.000189]\n",
      "epoch:32 step:151050[D loss: 1.000107] [G loss: 1.000043]\n",
      "epoch:32 step:151055[D loss: 1.000181] [G loss: 1.000085]\n",
      "epoch:32 step:151060[D loss: 0.999994] [G loss: 1.000137]\n",
      "epoch:32 step:151065[D loss: 0.999899] [G loss: 1.000145]\n",
      "epoch:32 step:151070[D loss: 1.000114] [G loss: 1.000051]\n",
      "epoch:32 step:151075[D loss: 0.999963] [G loss: 1.000179]\n",
      "epoch:32 step:151080[D loss: 0.999952] [G loss: 1.000168]\n",
      "epoch:32 step:151085[D loss: 1.000136] [G loss: 0.999971]\n",
      "epoch:32 step:151090[D loss: 0.999960] [G loss: 1.000356]\n",
      "epoch:32 step:151095[D loss: 0.999976] [G loss: 1.000309]\n",
      "epoch:32 step:151100[D loss: 0.999848] [G loss: 1.000263]\n",
      "epoch:32 step:151105[D loss: 1.000017] [G loss: 1.000073]\n",
      "epoch:32 step:151110[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:32 step:151115[D loss: 1.000019] [G loss: 1.000022]\n",
      "epoch:32 step:151120[D loss: 1.000178] [G loss: 0.999919]\n",
      "epoch:32 step:151125[D loss: 1.000205] [G loss: 0.999789]\n",
      "epoch:32 step:151130[D loss: 0.999925] [G loss: 1.000084]\n",
      "epoch:32 step:151135[D loss: 1.000003] [G loss: 0.999914]\n",
      "epoch:32 step:151140[D loss: 1.000137] [G loss: 0.999927]\n",
      "epoch:32 step:151145[D loss: 1.000111] [G loss: 0.999834]\n",
      "epoch:32 step:151150[D loss: 1.000057] [G loss: 1.000015]\n",
      "epoch:32 step:151155[D loss: 0.999862] [G loss: 1.000144]\n",
      "epoch:32 step:151160[D loss: 1.000007] [G loss: 1.000114]\n",
      "epoch:32 step:151165[D loss: 0.999875] [G loss: 1.000188]\n",
      "epoch:32 step:151170[D loss: 0.999942] [G loss: 1.000086]\n",
      "epoch:32 step:151175[D loss: 1.000042] [G loss: 0.999967]\n",
      "epoch:32 step:151180[D loss: 0.999935] [G loss: 1.000065]\n",
      "epoch:32 step:151185[D loss: 1.000096] [G loss: 0.999910]\n",
      "epoch:32 step:151190[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:32 step:151195[D loss: 0.999879] [G loss: 1.000190]\n",
      "epoch:32 step:151200[D loss: 0.999970] [G loss: 1.000055]\n",
      "##############\n",
      "[2.64718225 2.30408653 2.39106082 4.02534573 1.59143483 7.79361543\n",
      " 2.38583802 3.81747696 4.13191751 6.5798498 ]\n",
      "##########\n",
      "epoch:32 step:151205[D loss: 0.999995] [G loss: 1.000085]\n",
      "epoch:32 step:151210[D loss: 1.000057] [G loss: 1.000188]\n",
      "epoch:32 step:151215[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:32 step:151220[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:32 step:151225[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:32 step:151230[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:32 step:151235[D loss: 1.000019] [G loss: 1.000109]\n",
      "epoch:32 step:151240[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:32 step:151245[D loss: 0.999941] [G loss: 1.000066]\n",
      "epoch:32 step:151250[D loss: 1.000054] [G loss: 1.000031]\n",
      "epoch:32 step:151255[D loss: 0.999951] [G loss: 1.000123]\n",
      "epoch:32 step:151260[D loss: 0.999973] [G loss: 1.000117]\n",
      "epoch:32 step:151265[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:32 step:151270[D loss: 1.000010] [G loss: 1.000074]\n",
      "epoch:32 step:151275[D loss: 0.999950] [G loss: 1.000108]\n",
      "epoch:32 step:151280[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:32 step:151285[D loss: 0.999945] [G loss: 1.000114]\n",
      "epoch:32 step:151290[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:32 step:151295[D loss: 1.000000] [G loss: 1.000076]\n",
      "epoch:32 step:151300[D loss: 1.000025] [G loss: 1.000025]\n",
      "epoch:32 step:151305[D loss: 0.999926] [G loss: 1.000116]\n",
      "epoch:32 step:151310[D loss: 0.999966] [G loss: 1.000196]\n",
      "epoch:32 step:151315[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:32 step:151320[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:32 step:151325[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:32 step:151330[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:32 step:151335[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:32 step:151340[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:32 step:151345[D loss: 1.000031] [G loss: 1.000004]\n",
      "epoch:32 step:151350[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:32 step:151355[D loss: 0.999946] [G loss: 1.000109]\n",
      "epoch:32 step:151360[D loss: 1.000000] [G loss: 1.000029]\n",
      "epoch:32 step:151365[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:32 step:151370[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:32 step:151375[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:32 step:151380[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:32 step:151385[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:32 step:151390[D loss: 0.999979] [G loss: 1.000092]\n",
      "epoch:32 step:151395[D loss: 1.000041] [G loss: 1.000016]\n",
      "epoch:32 step:151400[D loss: 0.999972] [G loss: 1.000018]\n",
      "##############\n",
      "[2.60291139 2.30459706 2.49226663 3.87529784 1.50682583 7.76041952\n",
      " 2.29354905 3.85962907 4.0797234  5.12529852]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:151405[D loss: 0.999900] [G loss: 1.000133]\n",
      "epoch:32 step:151410[D loss: 1.000002] [G loss: 1.000024]\n",
      "epoch:32 step:151415[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:32 step:151420[D loss: 1.000021] [G loss: 1.000026]\n",
      "epoch:32 step:151425[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:32 step:151430[D loss: 1.000002] [G loss: 1.000011]\n",
      "epoch:32 step:151435[D loss: 1.000020] [G loss: 1.000048]\n",
      "epoch:32 step:151440[D loss: 0.999945] [G loss: 1.000033]\n",
      "epoch:32 step:151445[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:32 step:151450[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:32 step:151455[D loss: 0.999947] [G loss: 1.000073]\n",
      "epoch:32 step:151460[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:32 step:151465[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:32 step:151470[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:32 step:151475[D loss: 1.000071] [G loss: 0.999955]\n",
      "epoch:32 step:151480[D loss: 0.999941] [G loss: 1.000026]\n",
      "epoch:32 step:151485[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:32 step:151490[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:32 step:151495[D loss: 0.999961] [G loss: 1.000178]\n",
      "epoch:32 step:151500[D loss: 0.999991] [G loss: 1.000192]\n",
      "epoch:32 step:151505[D loss: 0.999928] [G loss: 0.999993]\n",
      "epoch:32 step:151510[D loss: 1.000027] [G loss: 0.999869]\n",
      "epoch:32 step:151515[D loss: 1.000014] [G loss: 0.999990]\n",
      "epoch:32 step:151520[D loss: 1.000001] [G loss: 0.999944]\n",
      "epoch:32 step:151525[D loss: 1.000048] [G loss: 0.999930]\n",
      "epoch:32 step:151530[D loss: 1.000139] [G loss: 0.999840]\n",
      "epoch:32 step:151535[D loss: 1.000027] [G loss: 1.000110]\n",
      "epoch:32 step:151540[D loss: 0.999841] [G loss: 1.000116]\n",
      "epoch:32 step:151545[D loss: 0.999994] [G loss: 0.999943]\n",
      "epoch:32 step:151550[D loss: 0.999926] [G loss: 1.000071]\n",
      "epoch:32 step:151555[D loss: 1.000072] [G loss: 0.999978]\n",
      "epoch:32 step:151560[D loss: 0.999951] [G loss: 1.000008]\n",
      "epoch:32 step:151565[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:32 step:151570[D loss: 1.000029] [G loss: 0.999993]\n",
      "epoch:32 step:151575[D loss: 0.999945] [G loss: 1.000113]\n",
      "epoch:32 step:151580[D loss: 0.999941] [G loss: 1.000058]\n",
      "epoch:32 step:151585[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:32 step:151590[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:32 step:151595[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:32 step:151600[D loss: 1.000016] [G loss: 1.000020]\n",
      "##############\n",
      "[2.65097597 2.31283078 2.373633   3.87799076 1.59697612 9.27357666\n",
      " 2.4387053  3.80969706 4.0052401  5.05861971]\n",
      "##########\n",
      "epoch:32 step:151605[D loss: 0.999951] [G loss: 1.000153]\n",
      "epoch:32 step:151610[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:32 step:151615[D loss: 0.999966] [G loss: 0.999998]\n",
      "epoch:32 step:151620[D loss: 0.999954] [G loss: 1.000070]\n",
      "epoch:32 step:151625[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:32 step:151630[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:32 step:151635[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:32 step:151640[D loss: 1.000013] [G loss: 1.000017]\n",
      "epoch:32 step:151645[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:32 step:151650[D loss: 1.000091] [G loss: 1.000042]\n",
      "epoch:32 step:151655[D loss: 0.999924] [G loss: 1.000092]\n",
      "epoch:32 step:151660[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:32 step:151665[D loss: 1.000016] [G loss: 1.000069]\n",
      "epoch:32 step:151670[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:32 step:151675[D loss: 1.000051] [G loss: 0.999945]\n",
      "epoch:32 step:151680[D loss: 0.999917] [G loss: 1.000148]\n",
      "epoch:32 step:151685[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:32 step:151690[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:32 step:151695[D loss: 1.000009] [G loss: 1.000004]\n",
      "epoch:32 step:151700[D loss: 1.000019] [G loss: 0.999896]\n",
      "epoch:32 step:151705[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:32 step:151710[D loss: 0.999968] [G loss: 1.000204]\n",
      "epoch:32 step:151715[D loss: 0.999918] [G loss: 1.000096]\n",
      "epoch:32 step:151720[D loss: 1.000079] [G loss: 0.999982]\n",
      "epoch:32 step:151725[D loss: 1.000009] [G loss: 1.000021]\n",
      "epoch:32 step:151730[D loss: 0.999951] [G loss: 1.000046]\n",
      "epoch:32 step:151735[D loss: 0.999994] [G loss: 1.000070]\n",
      "epoch:32 step:151740[D loss: 1.000103] [G loss: 0.999979]\n",
      "epoch:32 step:151745[D loss: 0.999752] [G loss: 1.000390]\n",
      "epoch:32 step:151750[D loss: 1.000115] [G loss: 0.999863]\n",
      "epoch:32 step:151755[D loss: 1.000139] [G loss: 0.999955]\n",
      "epoch:32 step:151760[D loss: 1.000013] [G loss: 1.000058]\n",
      "epoch:32 step:151765[D loss: 0.999999] [G loss: 1.000083]\n",
      "epoch:32 step:151770[D loss: 1.000008] [G loss: 1.000099]\n",
      "epoch:32 step:151775[D loss: 1.000001] [G loss: 1.000045]\n",
      "epoch:32 step:151780[D loss: 0.999974] [G loss: 1.000109]\n",
      "epoch:32 step:151785[D loss: 0.999927] [G loss: 1.000076]\n",
      "epoch:32 step:151790[D loss: 1.000007] [G loss: 1.000107]\n",
      "epoch:32 step:151795[D loss: 1.000031] [G loss: 1.000011]\n",
      "epoch:32 step:151800[D loss: 1.000004] [G loss: 0.999955]\n",
      "##############\n",
      "[2.59621664 2.21308323 2.35162913 4.1027689  1.596839   7.60952709\n",
      " 2.44937693 3.83093716 3.98919113 5.13599567]\n",
      "##########\n",
      "epoch:32 step:151805[D loss: 1.000065] [G loss: 0.999925]\n",
      "epoch:32 step:151810[D loss: 1.000159] [G loss: 0.999963]\n",
      "epoch:32 step:151815[D loss: 0.999889] [G loss: 1.000125]\n",
      "epoch:32 step:151820[D loss: 0.999861] [G loss: 1.000153]\n",
      "epoch:32 step:151825[D loss: 0.999942] [G loss: 1.000147]\n",
      "epoch:32 step:151830[D loss: 1.000009] [G loss: 1.000078]\n",
      "epoch:32 step:151835[D loss: 0.999878] [G loss: 1.000117]\n",
      "epoch:32 step:151840[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:32 step:151845[D loss: 1.000001] [G loss: 1.000001]\n",
      "epoch:32 step:151850[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:32 step:151855[D loss: 1.000004] [G loss: 1.000007]\n",
      "epoch:32 step:151860[D loss: 1.000013] [G loss: 1.000019]\n",
      "epoch:32 step:151865[D loss: 0.999952] [G loss: 1.000051]\n",
      "epoch:32 step:151870[D loss: 0.999952] [G loss: 1.000110]\n",
      "epoch:32 step:151875[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:32 step:151880[D loss: 0.999988] [G loss: 1.000093]\n",
      "epoch:32 step:151885[D loss: 1.000027] [G loss: 0.999965]\n",
      "epoch:32 step:151890[D loss: 1.000025] [G loss: 1.000033]\n",
      "epoch:32 step:151895[D loss: 0.999975] [G loss: 1.000007]\n",
      "epoch:32 step:151900[D loss: 1.000004] [G loss: 1.000071]\n",
      "epoch:32 step:151905[D loss: 0.999958] [G loss: 1.000026]\n",
      "epoch:32 step:151910[D loss: 1.000044] [G loss: 0.999917]\n",
      "epoch:32 step:151915[D loss: 1.000024] [G loss: 0.999999]\n",
      "epoch:32 step:151920[D loss: 0.999927] [G loss: 1.000119]\n",
      "epoch:32 step:151925[D loss: 0.999981] [G loss: 1.000129]\n",
      "epoch:32 step:151930[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:32 step:151935[D loss: 1.000054] [G loss: 1.000000]\n",
      "epoch:32 step:151940[D loss: 0.999980] [G loss: 1.000114]\n",
      "epoch:32 step:151945[D loss: 0.999898] [G loss: 1.000093]\n",
      "epoch:32 step:151950[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:32 step:151955[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:32 step:151960[D loss: 0.999959] [G loss: 1.000035]\n",
      "epoch:32 step:151965[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:32 step:151970[D loss: 1.000079] [G loss: 1.000061]\n",
      "epoch:32 step:151975[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:32 step:151980[D loss: 0.999955] [G loss: 0.999985]\n",
      "epoch:32 step:151985[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:32 step:151990[D loss: 0.999990] [G loss: 0.999995]\n",
      "epoch:32 step:151995[D loss: 1.000002] [G loss: 1.000070]\n",
      "epoch:32 step:152000[D loss: 0.999953] [G loss: 1.000078]\n",
      "##############\n",
      "[2.59129522 2.30340058 2.25527735 3.69217424 1.57626915 7.52236747\n",
      " 2.36297148 3.87677103 4.01298098 5.79945375]\n",
      "##########\n",
      "epoch:32 step:152005[D loss: 0.999941] [G loss: 1.000144]\n",
      "epoch:32 step:152010[D loss: 0.999870] [G loss: 1.000219]\n",
      "epoch:32 step:152015[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:32 step:152020[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:32 step:152025[D loss: 1.000048] [G loss: 1.000085]\n",
      "epoch:32 step:152030[D loss: 0.999930] [G loss: 1.000181]\n",
      "epoch:32 step:152035[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:32 step:152040[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:32 step:152045[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:32 step:152050[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:32 step:152055[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:32 step:152060[D loss: 1.000031] [G loss: 1.000006]\n",
      "epoch:32 step:152065[D loss: 1.000021] [G loss: 0.999967]\n",
      "epoch:32 step:152070[D loss: 0.999933] [G loss: 1.000101]\n",
      "epoch:32 step:152075[D loss: 0.999914] [G loss: 1.000111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:152080[D loss: 0.999983] [G loss: 1.000088]\n",
      "epoch:32 step:152085[D loss: 0.999899] [G loss: 1.000133]\n",
      "epoch:32 step:152090[D loss: 1.000037] [G loss: 1.000027]\n",
      "epoch:32 step:152095[D loss: 1.000069] [G loss: 0.999967]\n",
      "epoch:32 step:152100[D loss: 0.999941] [G loss: 1.000064]\n",
      "epoch:32 step:152105[D loss: 1.000017] [G loss: 1.000041]\n",
      "epoch:32 step:152110[D loss: 0.999984] [G loss: 1.000021]\n",
      "epoch:32 step:152115[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:32 step:152120[D loss: 1.000015] [G loss: 0.999977]\n",
      "epoch:32 step:152125[D loss: 1.000027] [G loss: 0.999850]\n",
      "epoch:32 step:152130[D loss: 0.999912] [G loss: 1.000153]\n",
      "epoch:32 step:152135[D loss: 0.999901] [G loss: 1.000169]\n",
      "epoch:32 step:152140[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:32 step:152145[D loss: 0.999944] [G loss: 1.000066]\n",
      "epoch:32 step:152150[D loss: 1.000278] [G loss: 0.999894]\n",
      "epoch:32 step:152155[D loss: 0.999899] [G loss: 1.000319]\n",
      "epoch:32 step:152160[D loss: 1.000058] [G loss: 1.000217]\n",
      "epoch:32 step:152165[D loss: 0.999942] [G loss: 1.000162]\n",
      "epoch:32 step:152170[D loss: 0.999907] [G loss: 1.000320]\n",
      "epoch:32 step:152175[D loss: 0.999885] [G loss: 1.000136]\n",
      "epoch:32 step:152180[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:32 step:152185[D loss: 0.999941] [G loss: 1.000092]\n",
      "epoch:32 step:152190[D loss: 1.000005] [G loss: 0.999979]\n",
      "epoch:32 step:152195[D loss: 1.000083] [G loss: 0.999898]\n",
      "epoch:32 step:152200[D loss: 0.999990] [G loss: 0.999931]\n",
      "##############\n",
      "[2.55446318 2.21853186 2.27964018 3.70118054 1.64479101 7.18709502\n",
      " 2.40726483 3.77168101 3.99804866 5.9850481 ]\n",
      "##########\n",
      "epoch:32 step:152205[D loss: 1.000037] [G loss: 0.999975]\n",
      "epoch:32 step:152210[D loss: 1.000339] [G loss: 0.999540]\n",
      "epoch:32 step:152215[D loss: 1.000330] [G loss: 0.999879]\n",
      "epoch:32 step:152220[D loss: 1.000047] [G loss: 0.999838]\n",
      "epoch:32 step:152225[D loss: 0.999996] [G loss: 0.999940]\n",
      "epoch:32 step:152230[D loss: 0.999945] [G loss: 1.000069]\n",
      "epoch:32 step:152235[D loss: 0.999930] [G loss: 1.000219]\n",
      "epoch:32 step:152240[D loss: 0.999933] [G loss: 1.000116]\n",
      "epoch:32 step:152245[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:32 step:152250[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:32 step:152255[D loss: 0.999994] [G loss: 1.000003]\n",
      "epoch:32 step:152260[D loss: 1.000086] [G loss: 0.999944]\n",
      "epoch:32 step:152265[D loss: 1.000274] [G loss: 1.000004]\n",
      "epoch:32 step:152270[D loss: 1.000116] [G loss: 0.999716]\n",
      "epoch:32 step:152275[D loss: 0.999999] [G loss: 1.000114]\n",
      "epoch:32 step:152280[D loss: 0.999797] [G loss: 1.000314]\n",
      "epoch:32 step:152285[D loss: 0.999942] [G loss: 1.000135]\n",
      "epoch:32 step:152290[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:32 step:152295[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:32 step:152300[D loss: 1.000003] [G loss: 1.000020]\n",
      "epoch:32 step:152305[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:32 step:152310[D loss: 1.000040] [G loss: 0.999910]\n",
      "epoch:32 step:152315[D loss: 1.000022] [G loss: 0.999957]\n",
      "epoch:32 step:152320[D loss: 1.000031] [G loss: 0.999941]\n",
      "epoch:32 step:152325[D loss: 1.000039] [G loss: 0.999966]\n",
      "epoch:32 step:152330[D loss: 0.999988] [G loss: 0.999931]\n",
      "epoch:32 step:152335[D loss: 0.999971] [G loss: 1.000018]\n",
      "epoch:32 step:152340[D loss: 1.000021] [G loss: 1.000062]\n",
      "epoch:32 step:152345[D loss: 0.999919] [G loss: 1.000053]\n",
      "epoch:32 step:152350[D loss: 1.000002] [G loss: 1.000129]\n",
      "epoch:32 step:152355[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:32 step:152360[D loss: 1.000035] [G loss: 0.999967]\n",
      "epoch:32 step:152365[D loss: 1.000009] [G loss: 1.000040]\n",
      "epoch:32 step:152370[D loss: 1.000014] [G loss: 0.999998]\n",
      "epoch:32 step:152375[D loss: 1.000042] [G loss: 0.999981]\n",
      "epoch:32 step:152380[D loss: 1.000072] [G loss: 1.000128]\n",
      "epoch:32 step:152385[D loss: 1.000042] [G loss: 1.000321]\n",
      "epoch:32 step:152390[D loss: 1.000054] [G loss: 1.000151]\n",
      "epoch:32 step:152395[D loss: 0.999853] [G loss: 1.000209]\n",
      "epoch:32 step:152400[D loss: 1.000144] [G loss: 1.000175]\n",
      "##############\n",
      "[2.62500514 2.28640086 2.33055899 3.78955489 1.69830283 6.68697746\n",
      " 2.39281275 3.88516652 4.08451295 5.34939219]\n",
      "##########\n",
      "epoch:32 step:152405[D loss: 0.999882] [G loss: 1.000338]\n",
      "epoch:32 step:152410[D loss: 0.999923] [G loss: 1.000111]\n",
      "epoch:32 step:152415[D loss: 1.000032] [G loss: 0.999939]\n",
      "epoch:32 step:152420[D loss: 1.000057] [G loss: 0.999931]\n",
      "epoch:32 step:152425[D loss: 1.000053] [G loss: 0.999713]\n",
      "epoch:32 step:152430[D loss: 1.000006] [G loss: 0.999921]\n",
      "epoch:32 step:152435[D loss: 1.000006] [G loss: 0.999926]\n",
      "epoch:32 step:152440[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:32 step:152445[D loss: 0.999907] [G loss: 1.000147]\n",
      "epoch:32 step:152450[D loss: 0.999942] [G loss: 1.000067]\n",
      "epoch:32 step:152455[D loss: 1.000066] [G loss: 0.999965]\n",
      "epoch:32 step:152460[D loss: 0.999966] [G loss: 1.000152]\n",
      "epoch:32 step:152465[D loss: 1.000047] [G loss: 0.999854]\n",
      "epoch:32 step:152470[D loss: 1.000131] [G loss: 1.000293]\n",
      "epoch:32 step:152475[D loss: 0.999839] [G loss: 1.000265]\n",
      "epoch:32 step:152480[D loss: 0.999906] [G loss: 1.000153]\n",
      "epoch:32 step:152485[D loss: 0.999877] [G loss: 1.000195]\n",
      "epoch:32 step:152490[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:32 step:152495[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:32 step:152500[D loss: 0.999983] [G loss: 1.000011]\n",
      "epoch:32 step:152505[D loss: 1.000143] [G loss: 0.999772]\n",
      "epoch:32 step:152510[D loss: 0.999975] [G loss: 0.999942]\n",
      "epoch:32 step:152515[D loss: 1.000120] [G loss: 0.999818]\n",
      "epoch:32 step:152520[D loss: 0.999972] [G loss: 1.000010]\n",
      "epoch:32 step:152525[D loss: 0.999911] [G loss: 1.000260]\n",
      "epoch:32 step:152530[D loss: 0.999803] [G loss: 1.000203]\n",
      "epoch:32 step:152535[D loss: 1.000092] [G loss: 1.000175]\n",
      "epoch:32 step:152540[D loss: 0.999917] [G loss: 1.000365]\n",
      "epoch:32 step:152545[D loss: 0.999936] [G loss: 1.000111]\n",
      "epoch:32 step:152550[D loss: 1.000013] [G loss: 0.999998]\n",
      "epoch:32 step:152555[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:32 step:152560[D loss: 1.000011] [G loss: 0.999957]\n",
      "epoch:32 step:152565[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:32 step:152570[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:32 step:152575[D loss: 0.999958] [G loss: 1.000039]\n",
      "epoch:32 step:152580[D loss: 0.999930] [G loss: 1.000076]\n",
      "epoch:32 step:152585[D loss: 1.000004] [G loss: 1.000013]\n",
      "epoch:32 step:152590[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:32 step:152595[D loss: 0.999950] [G loss: 1.000059]\n",
      "epoch:32 step:152600[D loss: 1.000030] [G loss: 1.000064]\n",
      "##############\n",
      "[2.50278789 2.28918281 2.29967985 3.70609058 1.55756342 7.35283393\n",
      " 2.63623261 3.78168718 4.06267415 7.14868929]\n",
      "##########\n",
      "epoch:32 step:152605[D loss: 1.000050] [G loss: 0.999998]\n",
      "epoch:32 step:152610[D loss: 0.999963] [G loss: 1.000131]\n",
      "epoch:32 step:152615[D loss: 1.000073] [G loss: 0.999995]\n",
      "epoch:32 step:152620[D loss: 0.999941] [G loss: 1.000099]\n",
      "epoch:32 step:152625[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:32 step:152630[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:32 step:152635[D loss: 1.000144] [G loss: 0.999881]\n",
      "epoch:32 step:152640[D loss: 0.999950] [G loss: 1.000065]\n",
      "epoch:32 step:152645[D loss: 1.000088] [G loss: 0.999851]\n",
      "epoch:32 step:152650[D loss: 1.000053] [G loss: 0.999917]\n",
      "epoch:32 step:152655[D loss: 0.999899] [G loss: 1.000093]\n",
      "epoch:32 step:152660[D loss: 0.999934] [G loss: 1.000137]\n",
      "epoch:32 step:152665[D loss: 0.999985] [G loss: 1.000110]\n",
      "epoch:32 step:152670[D loss: 1.000072] [G loss: 1.000016]\n",
      "epoch:32 step:152675[D loss: 0.999966] [G loss: 1.000042]\n",
      "epoch:32 step:152680[D loss: 0.999933] [G loss: 1.000133]\n",
      "epoch:32 step:152685[D loss: 1.000021] [G loss: 1.000021]\n",
      "epoch:32 step:152690[D loss: 0.999979] [G loss: 1.000018]\n",
      "epoch:32 step:152695[D loss: 1.000023] [G loss: 1.000041]\n",
      "epoch:32 step:152700[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:32 step:152705[D loss: 1.000015] [G loss: 1.000114]\n",
      "epoch:32 step:152710[D loss: 0.999985] [G loss: 1.000155]\n",
      "epoch:32 step:152715[D loss: 0.999961] [G loss: 1.000107]\n",
      "epoch:32 step:152720[D loss: 0.999914] [G loss: 1.000136]\n",
      "epoch:32 step:152725[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:32 step:152730[D loss: 0.999892] [G loss: 1.000124]\n",
      "epoch:32 step:152735[D loss: 0.999937] [G loss: 1.000191]\n",
      "epoch:32 step:152740[D loss: 0.999967] [G loss: 1.000171]\n",
      "epoch:32 step:152745[D loss: 0.999946] [G loss: 1.000099]\n",
      "epoch:32 step:152750[D loss: 0.999991] [G loss: 0.999987]\n",
      "epoch:32 step:152755[D loss: 0.999967] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:152760[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:32 step:152765[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:32 step:152770[D loss: 1.000047] [G loss: 0.999947]\n",
      "epoch:32 step:152775[D loss: 1.000072] [G loss: 0.999841]\n",
      "epoch:32 step:152780[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:32 step:152785[D loss: 0.999888] [G loss: 1.000100]\n",
      "epoch:32 step:152790[D loss: 1.000046] [G loss: 1.000076]\n",
      "epoch:32 step:152795[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:32 step:152800[D loss: 0.999938] [G loss: 1.000079]\n",
      "##############\n",
      "[2.50180234 2.31231196 2.33272746 3.53927734 1.57751675 7.61921729\n",
      " 2.30279524 3.86589806 4.17412238 5.33800651]\n",
      "##########\n",
      "epoch:32 step:152805[D loss: 0.999950] [G loss: 1.000007]\n",
      "epoch:32 step:152810[D loss: 1.000022] [G loss: 1.000076]\n",
      "epoch:32 step:152815[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:32 step:152820[D loss: 1.000157] [G loss: 0.999836]\n",
      "epoch:32 step:152825[D loss: 0.999988] [G loss: 0.999908]\n",
      "epoch:32 step:152830[D loss: 0.999943] [G loss: 1.000135]\n",
      "epoch:32 step:152835[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:32 step:152840[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:32 step:152845[D loss: 0.999970] [G loss: 1.000010]\n",
      "epoch:32 step:152850[D loss: 0.999987] [G loss: 1.000010]\n",
      "epoch:32 step:152855[D loss: 1.000006] [G loss: 0.999991]\n",
      "epoch:32 step:152860[D loss: 1.000136] [G loss: 0.999935]\n",
      "epoch:32 step:152865[D loss: 1.000063] [G loss: 1.000002]\n",
      "epoch:32 step:152870[D loss: 1.000027] [G loss: 0.999872]\n",
      "epoch:32 step:152875[D loss: 0.999949] [G loss: 1.000129]\n",
      "epoch:32 step:152880[D loss: 1.000003] [G loss: 0.999960]\n",
      "epoch:32 step:152885[D loss: 1.000045] [G loss: 1.000016]\n",
      "epoch:32 step:152890[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:32 step:152895[D loss: 1.000093] [G loss: 1.000102]\n",
      "epoch:32 step:152900[D loss: 0.999874] [G loss: 1.000068]\n",
      "epoch:32 step:152905[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:32 step:152910[D loss: 0.999966] [G loss: 1.000120]\n",
      "epoch:32 step:152915[D loss: 0.999934] [G loss: 1.000092]\n",
      "epoch:32 step:152920[D loss: 0.999979] [G loss: 1.000120]\n",
      "epoch:32 step:152925[D loss: 1.000039] [G loss: 0.999956]\n",
      "epoch:32 step:152930[D loss: 1.000011] [G loss: 1.000009]\n",
      "epoch:32 step:152935[D loss: 0.999992] [G loss: 0.999934]\n",
      "epoch:32 step:152940[D loss: 1.000094] [G loss: 0.999900]\n",
      "epoch:32 step:152945[D loss: 0.999946] [G loss: 0.999996]\n",
      "epoch:32 step:152950[D loss: 0.999947] [G loss: 1.000065]\n",
      "epoch:32 step:152955[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:32 step:152960[D loss: 1.000028] [G loss: 1.000001]\n",
      "epoch:32 step:152965[D loss: 1.000132] [G loss: 0.999968]\n",
      "epoch:32 step:152970[D loss: 0.999939] [G loss: 1.000103]\n",
      "epoch:32 step:152975[D loss: 1.000048] [G loss: 1.000049]\n",
      "epoch:32 step:152980[D loss: 0.999860] [G loss: 1.000236]\n",
      "epoch:32 step:152985[D loss: 0.999944] [G loss: 1.000067]\n",
      "epoch:32 step:152990[D loss: 0.999911] [G loss: 1.000110]\n",
      "epoch:32 step:152995[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:32 step:153000[D loss: 1.000020] [G loss: 1.000061]\n",
      "##############\n",
      "[2.550909   2.23234114 2.26863031 3.80567286 1.61092548 7.12129831\n",
      " 2.42765064 4.05095656 4.0023904  4.42571138]\n",
      "##########\n",
      "epoch:32 step:153005[D loss: 1.000080] [G loss: 0.999894]\n",
      "epoch:32 step:153010[D loss: 1.000063] [G loss: 0.999973]\n",
      "epoch:32 step:153015[D loss: 0.999871] [G loss: 1.000096]\n",
      "epoch:32 step:153020[D loss: 1.000010] [G loss: 1.000136]\n",
      "epoch:32 step:153025[D loss: 1.000035] [G loss: 0.999866]\n",
      "epoch:32 step:153030[D loss: 1.000047] [G loss: 0.999993]\n",
      "epoch:32 step:153035[D loss: 0.999858] [G loss: 1.000254]\n",
      "epoch:32 step:153040[D loss: 1.000015] [G loss: 0.999958]\n",
      "epoch:32 step:153045[D loss: 0.999893] [G loss: 1.000322]\n",
      "epoch:32 step:153050[D loss: 0.999870] [G loss: 1.000186]\n",
      "epoch:32 step:153055[D loss: 0.999931] [G loss: 1.000091]\n",
      "epoch:32 step:153060[D loss: 0.999992] [G loss: 1.000018]\n",
      "epoch:32 step:153065[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:32 step:153070[D loss: 0.999955] [G loss: 1.000050]\n",
      "epoch:32 step:153075[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:32 step:153080[D loss: 1.000033] [G loss: 1.000172]\n",
      "epoch:32 step:153085[D loss: 0.999953] [G loss: 1.000233]\n",
      "epoch:32 step:153090[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:32 step:153095[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:32 step:153100[D loss: 1.000017] [G loss: 0.999941]\n",
      "epoch:32 step:153105[D loss: 0.999977] [G loss: 1.000135]\n",
      "epoch:32 step:153110[D loss: 0.999948] [G loss: 1.000033]\n",
      "epoch:32 step:153115[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:32 step:153120[D loss: 1.000053] [G loss: 0.999998]\n",
      "epoch:32 step:153125[D loss: 1.000045] [G loss: 0.999988]\n",
      "epoch:32 step:153130[D loss: 0.999895] [G loss: 1.000092]\n",
      "epoch:32 step:153135[D loss: 0.999926] [G loss: 1.000075]\n",
      "epoch:32 step:153140[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:32 step:153145[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:32 step:153150[D loss: 1.000035] [G loss: 0.999971]\n",
      "epoch:32 step:153155[D loss: 0.999895] [G loss: 1.000126]\n",
      "epoch:32 step:153160[D loss: 1.000005] [G loss: 1.000035]\n",
      "epoch:32 step:153165[D loss: 1.000081] [G loss: 0.999925]\n",
      "epoch:32 step:153170[D loss: 0.999879] [G loss: 1.000187]\n",
      "epoch:32 step:153175[D loss: 1.000032] [G loss: 1.000153]\n",
      "epoch:32 step:153180[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:32 step:153185[D loss: 0.999955] [G loss: 1.000142]\n",
      "epoch:32 step:153190[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:32 step:153195[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:32 step:153200[D loss: 0.999972] [G loss: 1.000112]\n",
      "##############\n",
      "[2.55518676 2.27416446 2.32921559 3.68801613 1.58897154 7.07207155\n",
      " 2.22353428 3.82302182 4.03875399 4.90655805]\n",
      "##########\n",
      "epoch:32 step:153205[D loss: 0.999923] [G loss: 1.000203]\n",
      "epoch:32 step:153210[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:32 step:153215[D loss: 0.999995] [G loss: 1.000085]\n",
      "epoch:32 step:153220[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:32 step:153225[D loss: 1.000017] [G loss: 1.000036]\n",
      "epoch:32 step:153230[D loss: 1.000054] [G loss: 1.000020]\n",
      "epoch:32 step:153235[D loss: 1.000088] [G loss: 0.999944]\n",
      "epoch:32 step:153240[D loss: 0.999954] [G loss: 1.000023]\n",
      "epoch:32 step:153245[D loss: 1.000050] [G loss: 0.999968]\n",
      "epoch:32 step:153250[D loss: 0.999991] [G loss: 0.999981]\n",
      "epoch:32 step:153255[D loss: 0.999880] [G loss: 1.000048]\n",
      "epoch:32 step:153260[D loss: 0.999941] [G loss: 1.000144]\n",
      "epoch:32 step:153265[D loss: 0.999926] [G loss: 1.000084]\n",
      "epoch:32 step:153270[D loss: 0.999975] [G loss: 0.999991]\n",
      "epoch:32 step:153275[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:32 step:153280[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:32 step:153285[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:32 step:153290[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:32 step:153295[D loss: 1.000101] [G loss: 0.999970]\n",
      "epoch:32 step:153300[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:32 step:153305[D loss: 0.999967] [G loss: 1.000116]\n",
      "epoch:32 step:153310[D loss: 0.999996] [G loss: 1.000089]\n",
      "epoch:32 step:153315[D loss: 1.000015] [G loss: 1.000019]\n",
      "epoch:32 step:153320[D loss: 0.999958] [G loss: 1.000104]\n",
      "epoch:32 step:153325[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:32 step:153330[D loss: 0.999948] [G loss: 1.000127]\n",
      "epoch:32 step:153335[D loss: 0.999997] [G loss: 0.999955]\n",
      "epoch:32 step:153340[D loss: 1.000052] [G loss: 0.999929]\n",
      "epoch:32 step:153345[D loss: 1.000212] [G loss: 0.999667]\n",
      "epoch:32 step:153350[D loss: 0.999923] [G loss: 1.000090]\n",
      "epoch:32 step:153355[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:32 step:153360[D loss: 1.000007] [G loss: 1.000013]\n",
      "epoch:32 step:153365[D loss: 1.000008] [G loss: 1.000128]\n",
      "epoch:32 step:153370[D loss: 0.999947] [G loss: 1.000046]\n",
      "epoch:32 step:153375[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:32 step:153380[D loss: 1.000020] [G loss: 0.999955]\n",
      "epoch:32 step:153385[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:32 step:153390[D loss: 0.999973] [G loss: 1.000129]\n",
      "epoch:32 step:153395[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:32 step:153400[D loss: 0.999992] [G loss: 1.000048]\n",
      "##############\n",
      "[2.6959124  2.31462413 2.27144291 3.70470632 1.5822672  7.66935846\n",
      " 2.49397002 3.77548826 4.08183027 5.04122715]\n",
      "##########\n",
      "epoch:32 step:153405[D loss: 0.999942] [G loss: 1.000083]\n",
      "epoch:32 step:153410[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:32 step:153415[D loss: 1.000057] [G loss: 0.999927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:153420[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:32 step:153425[D loss: 1.000041] [G loss: 1.000011]\n",
      "epoch:32 step:153430[D loss: 0.999948] [G loss: 1.000094]\n",
      "epoch:32 step:153435[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:32 step:153440[D loss: 1.000040] [G loss: 0.999998]\n",
      "epoch:32 step:153445[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:32 step:153450[D loss: 0.999937] [G loss: 1.000108]\n",
      "epoch:32 step:153455[D loss: 0.999929] [G loss: 1.000108]\n",
      "epoch:32 step:153460[D loss: 0.999940] [G loss: 1.000094]\n",
      "epoch:32 step:153465[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:32 step:153470[D loss: 1.000015] [G loss: 0.999982]\n",
      "epoch:32 step:153475[D loss: 0.999954] [G loss: 1.000122]\n",
      "epoch:32 step:153480[D loss: 0.999943] [G loss: 1.000071]\n",
      "epoch:32 step:153485[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:32 step:153490[D loss: 1.000124] [G loss: 0.999978]\n",
      "epoch:32 step:153495[D loss: 0.999941] [G loss: 1.000126]\n",
      "epoch:32 step:153500[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:32 step:153505[D loss: 0.999960] [G loss: 1.000100]\n",
      "epoch:32 step:153510[D loss: 0.999955] [G loss: 1.000094]\n",
      "epoch:32 step:153515[D loss: 1.000024] [G loss: 1.000028]\n",
      "epoch:32 step:153520[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:32 step:153525[D loss: 0.999937] [G loss: 1.000100]\n",
      "epoch:32 step:153530[D loss: 1.000000] [G loss: 1.000156]\n",
      "epoch:32 step:153535[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:32 step:153540[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:32 step:153545[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:32 step:153550[D loss: 1.000046] [G loss: 0.999966]\n",
      "epoch:32 step:153555[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:32 step:153560[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:32 step:153565[D loss: 0.999930] [G loss: 1.000088]\n",
      "epoch:32 step:153570[D loss: 1.000010] [G loss: 0.999982]\n",
      "epoch:32 step:153575[D loss: 0.999995] [G loss: 1.000087]\n",
      "epoch:32 step:153580[D loss: 0.999951] [G loss: 1.000053]\n",
      "epoch:32 step:153585[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:32 step:153590[D loss: 1.000038] [G loss: 0.999927]\n",
      "epoch:32 step:153595[D loss: 0.999992] [G loss: 1.000084]\n",
      "epoch:32 step:153600[D loss: 0.999967] [G loss: 1.000057]\n",
      "##############\n",
      "[2.59492987 2.22347109 2.40126948 3.59032854 1.59850803 7.3468168\n",
      " 2.53261718 4.09842917 4.17243668 5.26255443]\n",
      "##########\n",
      "epoch:32 step:153605[D loss: 1.000093] [G loss: 1.000048]\n",
      "epoch:32 step:153610[D loss: 0.999999] [G loss: 0.999982]\n",
      "epoch:32 step:153615[D loss: 1.000039] [G loss: 1.000104]\n",
      "epoch:32 step:153620[D loss: 0.999930] [G loss: 1.000171]\n",
      "epoch:32 step:153625[D loss: 0.999914] [G loss: 1.000094]\n",
      "epoch:32 step:153630[D loss: 1.000081] [G loss: 0.999920]\n",
      "epoch:32 step:153635[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:32 step:153640[D loss: 0.999973] [G loss: 1.000011]\n",
      "epoch:32 step:153645[D loss: 0.999958] [G loss: 1.000041]\n",
      "epoch:32 step:153650[D loss: 0.999952] [G loss: 1.000062]\n",
      "epoch:32 step:153655[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:32 step:153660[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:32 step:153665[D loss: 0.999989] [G loss: 1.000020]\n",
      "epoch:32 step:153670[D loss: 1.000056] [G loss: 0.999930]\n",
      "epoch:32 step:153675[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:32 step:153680[D loss: 0.999934] [G loss: 1.000092]\n",
      "epoch:32 step:153685[D loss: 1.000022] [G loss: 0.999952]\n",
      "epoch:32 step:153690[D loss: 1.000073] [G loss: 1.000132]\n",
      "epoch:32 step:153695[D loss: 0.999947] [G loss: 1.000139]\n",
      "epoch:32 step:153700[D loss: 0.999910] [G loss: 1.000089]\n",
      "epoch:32 step:153705[D loss: 1.000002] [G loss: 0.999952]\n",
      "epoch:32 step:153710[D loss: 1.000000] [G loss: 1.000043]\n",
      "epoch:32 step:153715[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:32 step:153720[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:32 step:153725[D loss: 1.000039] [G loss: 1.000000]\n",
      "epoch:32 step:153730[D loss: 1.000006] [G loss: 1.000126]\n",
      "epoch:32 step:153735[D loss: 0.999864] [G loss: 1.000218]\n",
      "epoch:32 step:153740[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:32 step:153745[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:32 step:153750[D loss: 0.999839] [G loss: 1.000252]\n",
      "epoch:32 step:153755[D loss: 0.999923] [G loss: 1.000175]\n",
      "epoch:32 step:153760[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:32 step:153765[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:32 step:153770[D loss: 0.999986] [G loss: 1.000004]\n",
      "epoch:32 step:153775[D loss: 1.000144] [G loss: 0.999787]\n",
      "epoch:32 step:153780[D loss: 0.999942] [G loss: 1.000088]\n",
      "epoch:32 step:153785[D loss: 0.999980] [G loss: 0.999996]\n",
      "epoch:32 step:153790[D loss: 1.000192] [G loss: 0.999930]\n",
      "epoch:32 step:153795[D loss: 0.999792] [G loss: 1.000170]\n",
      "epoch:32 step:153800[D loss: 0.999994] [G loss: 1.000059]\n",
      "##############\n",
      "[2.61907308 2.31307242 2.36375627 3.81239786 1.62973217 7.39526462\n",
      " 2.42988919 4.05364407 4.11523218 5.50950815]\n",
      "##########\n",
      "epoch:32 step:153805[D loss: 0.999939] [G loss: 1.000025]\n",
      "epoch:32 step:153810[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:32 step:153815[D loss: 1.000020] [G loss: 1.000079]\n",
      "epoch:32 step:153820[D loss: 0.999970] [G loss: 1.000025]\n",
      "epoch:32 step:153825[D loss: 0.999934] [G loss: 1.000053]\n",
      "epoch:32 step:153830[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:32 step:153835[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:32 step:153840[D loss: 0.999958] [G loss: 1.000069]\n",
      "epoch:32 step:153845[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:32 step:153850[D loss: 1.000036] [G loss: 0.999990]\n",
      "epoch:32 step:153855[D loss: 0.999919] [G loss: 1.000129]\n",
      "epoch:32 step:153860[D loss: 0.999991] [G loss: 1.000093]\n",
      "epoch:32 step:153865[D loss: 1.000041] [G loss: 1.000064]\n",
      "epoch:32 step:153870[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:32 step:153875[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:32 step:153880[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:32 step:153885[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:32 step:153890[D loss: 1.000002] [G loss: 0.999985]\n",
      "epoch:32 step:153895[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:32 step:153900[D loss: 1.000004] [G loss: 1.000022]\n",
      "epoch:32 step:153905[D loss: 0.999931] [G loss: 1.000131]\n",
      "epoch:32 step:153910[D loss: 0.999965] [G loss: 1.000162]\n",
      "epoch:32 step:153915[D loss: 0.999954] [G loss: 1.000099]\n",
      "epoch:32 step:153920[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:32 step:153925[D loss: 1.000037] [G loss: 0.999970]\n",
      "epoch:32 step:153930[D loss: 0.999941] [G loss: 1.000058]\n",
      "epoch:32 step:153935[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:32 step:153940[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:32 step:153945[D loss: 1.000000] [G loss: 1.000127]\n",
      "epoch:32 step:153950[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:32 step:153955[D loss: 1.000001] [G loss: 1.000094]\n",
      "epoch:32 step:153960[D loss: 1.000065] [G loss: 1.000032]\n",
      "epoch:32 step:153965[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:32 step:153970[D loss: 1.000001] [G loss: 1.000033]\n",
      "epoch:32 step:153975[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:32 step:153980[D loss: 1.000004] [G loss: 0.999998]\n",
      "epoch:32 step:153985[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:32 step:153990[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:32 step:153995[D loss: 1.000005] [G loss: 1.000055]\n",
      "epoch:32 step:154000[D loss: 0.999993] [G loss: 1.000096]\n",
      "##############\n",
      "[2.59900802 2.27925231 2.30223567 3.91227421 1.63277653 7.4230709\n",
      " 2.58888372 3.87904476 4.07748737 4.98427798]\n",
      "##########\n",
      "epoch:32 step:154005[D loss: 0.999936] [G loss: 1.000130]\n",
      "epoch:32 step:154010[D loss: 1.000078] [G loss: 1.000007]\n",
      "epoch:32 step:154015[D loss: 0.999931] [G loss: 1.000091]\n",
      "epoch:32 step:154020[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:32 step:154025[D loss: 1.000017] [G loss: 1.000102]\n",
      "epoch:32 step:154030[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:32 step:154035[D loss: 0.999915] [G loss: 1.000087]\n",
      "epoch:32 step:154040[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:32 step:154045[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:32 step:154050[D loss: 1.000008] [G loss: 1.000056]\n",
      "epoch:32 step:154055[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:32 step:154060[D loss: 0.999956] [G loss: 1.000029]\n",
      "epoch:32 step:154065[D loss: 1.000073] [G loss: 1.000010]\n",
      "epoch:32 step:154070[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:32 step:154075[D loss: 1.000026] [G loss: 1.000013]\n",
      "epoch:32 step:154080[D loss: 1.000079] [G loss: 1.000031]\n",
      "epoch:32 step:154085[D loss: 0.999946] [G loss: 1.000028]\n",
      "epoch:32 step:154090[D loss: 1.000122] [G loss: 0.999904]\n",
      "epoch:32 step:154095[D loss: 0.999889] [G loss: 1.000229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:154100[D loss: 0.999950] [G loss: 1.000077]\n",
      "epoch:32 step:154105[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:32 step:154110[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:32 step:154115[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:32 step:154120[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:32 step:154125[D loss: 1.000013] [G loss: 1.000005]\n",
      "epoch:32 step:154130[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:32 step:154135[D loss: 1.000045] [G loss: 0.999991]\n",
      "epoch:32 step:154140[D loss: 1.000045] [G loss: 1.000026]\n",
      "epoch:32 step:154145[D loss: 0.999923] [G loss: 1.000134]\n",
      "epoch:32 step:154150[D loss: 0.999919] [G loss: 1.000236]\n",
      "epoch:32 step:154155[D loss: 0.999979] [G loss: 1.000159]\n",
      "epoch:32 step:154160[D loss: 0.999988] [G loss: 1.000113]\n",
      "epoch:32 step:154165[D loss: 1.000049] [G loss: 1.000119]\n",
      "epoch:32 step:154170[D loss: 0.999935] [G loss: 1.000147]\n",
      "epoch:32 step:154175[D loss: 1.000003] [G loss: 1.000049]\n",
      "epoch:32 step:154180[D loss: 1.000014] [G loss: 0.999982]\n",
      "epoch:32 step:154185[D loss: 1.000091] [G loss: 0.999882]\n",
      "epoch:32 step:154190[D loss: 0.999979] [G loss: 0.999987]\n",
      "epoch:32 step:154195[D loss: 0.999976] [G loss: 0.999910]\n",
      "epoch:32 step:154200[D loss: 1.000195] [G loss: 0.999925]\n",
      "##############\n",
      "[2.52532509 2.25640833 2.21513493 3.49364793 1.53383702 7.30462964\n",
      " 2.32560801 3.72207505 4.05352299 5.23211397]\n",
      "##########\n",
      "epoch:32 step:154205[D loss: 1.000158] [G loss: 0.999814]\n",
      "epoch:32 step:154210[D loss: 1.000026] [G loss: 0.999863]\n",
      "epoch:32 step:154215[D loss: 0.999829] [G loss: 1.000374]\n",
      "epoch:32 step:154220[D loss: 0.999935] [G loss: 1.000037]\n",
      "epoch:32 step:154225[D loss: 0.999930] [G loss: 1.000157]\n",
      "epoch:32 step:154230[D loss: 0.999857] [G loss: 1.000228]\n",
      "epoch:32 step:154235[D loss: 0.999952] [G loss: 1.000139]\n",
      "epoch:32 step:154240[D loss: 1.000058] [G loss: 0.999948]\n",
      "epoch:32 step:154245[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:32 step:154250[D loss: 1.000036] [G loss: 0.999960]\n",
      "epoch:32 step:154255[D loss: 1.000104] [G loss: 0.999988]\n",
      "epoch:32 step:154260[D loss: 1.000035] [G loss: 0.999967]\n",
      "epoch:32 step:154265[D loss: 0.999879] [G loss: 1.000242]\n",
      "epoch:32 step:154270[D loss: 1.000128] [G loss: 0.999949]\n",
      "epoch:32 step:154275[D loss: 0.999803] [G loss: 1.000181]\n",
      "epoch:32 step:154280[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:32 step:154285[D loss: 1.000015] [G loss: 1.000081]\n",
      "epoch:32 step:154290[D loss: 0.999963] [G loss: 1.000048]\n",
      "epoch:32 step:154295[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:32 step:154300[D loss: 1.000027] [G loss: 1.000057]\n",
      "epoch:32 step:154305[D loss: 0.999934] [G loss: 1.000081]\n",
      "epoch:32 step:154310[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:32 step:154315[D loss: 1.000016] [G loss: 0.999971]\n",
      "epoch:32 step:154320[D loss: 1.000015] [G loss: 1.000049]\n",
      "epoch:32 step:154325[D loss: 0.999931] [G loss: 1.000094]\n",
      "epoch:32 step:154330[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:32 step:154335[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:32 step:154340[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:32 step:154345[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:32 step:154350[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:32 step:154355[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:32 step:154360[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:32 step:154365[D loss: 0.999999] [G loss: 1.000083]\n",
      "epoch:32 step:154370[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:32 step:154375[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:32 step:154380[D loss: 0.999972] [G loss: 1.000023]\n",
      "epoch:32 step:154385[D loss: 1.000080] [G loss: 0.999988]\n",
      "epoch:32 step:154390[D loss: 0.999961] [G loss: 1.000151]\n",
      "epoch:32 step:154395[D loss: 0.999944] [G loss: 1.000072]\n",
      "epoch:32 step:154400[D loss: 1.000135] [G loss: 0.999852]\n",
      "##############\n",
      "[2.51952913 2.33193554 2.23757376 3.59679618 1.59145752 7.62934825\n",
      " 2.3731594  3.92012405 4.0757906  5.39240329]\n",
      "##########\n",
      "epoch:32 step:154405[D loss: 0.999922] [G loss: 1.000049]\n",
      "epoch:32 step:154410[D loss: 0.999896] [G loss: 1.000123]\n",
      "epoch:32 step:154415[D loss: 0.999943] [G loss: 1.000054]\n",
      "epoch:32 step:154420[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:32 step:154425[D loss: 1.000126] [G loss: 0.999967]\n",
      "epoch:32 step:154430[D loss: 0.999962] [G loss: 1.000104]\n",
      "epoch:32 step:154435[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:32 step:154440[D loss: 1.000049] [G loss: 1.000005]\n",
      "epoch:32 step:154445[D loss: 1.000040] [G loss: 0.999899]\n",
      "epoch:32 step:154450[D loss: 1.000134] [G loss: 0.999989]\n",
      "epoch:32 step:154455[D loss: 0.999921] [G loss: 1.000079]\n",
      "epoch:32 step:154460[D loss: 1.000048] [G loss: 0.999969]\n",
      "epoch:32 step:154465[D loss: 0.999991] [G loss: 0.999983]\n",
      "epoch:32 step:154470[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:32 step:154475[D loss: 0.999959] [G loss: 1.000022]\n",
      "epoch:32 step:154480[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:32 step:154485[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:32 step:154490[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:32 step:154495[D loss: 1.000064] [G loss: 0.999948]\n",
      "epoch:32 step:154500[D loss: 0.999994] [G loss: 0.999971]\n",
      "epoch:32 step:154505[D loss: 1.000153] [G loss: 0.999931]\n",
      "epoch:32 step:154510[D loss: 0.999956] [G loss: 1.000036]\n",
      "epoch:32 step:154515[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:32 step:154520[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:32 step:154525[D loss: 1.000102] [G loss: 0.999943]\n",
      "epoch:32 step:154530[D loss: 0.999976] [G loss: 1.000030]\n",
      "epoch:32 step:154535[D loss: 0.999918] [G loss: 1.000107]\n",
      "epoch:32 step:154540[D loss: 0.999962] [G loss: 1.000040]\n",
      "epoch:32 step:154545[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:32 step:154550[D loss: 1.000031] [G loss: 1.000050]\n",
      "epoch:32 step:154555[D loss: 0.999911] [G loss: 1.000112]\n",
      "epoch:32 step:154560[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:32 step:154565[D loss: 0.999948] [G loss: 1.000076]\n",
      "epoch:32 step:154570[D loss: 0.999969] [G loss: 1.000028]\n",
      "epoch:32 step:154575[D loss: 0.999965] [G loss: 1.000037]\n",
      "epoch:32 step:154580[D loss: 0.999970] [G loss: 1.000031]\n",
      "epoch:32 step:154585[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:32 step:154590[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:32 step:154595[D loss: 1.000012] [G loss: 1.000097]\n",
      "epoch:32 step:154600[D loss: 0.999978] [G loss: 1.000028]\n",
      "##############\n",
      "[2.50505039 2.29421326 2.22384061 3.4998078  1.54520425 7.17041611\n",
      " 2.3771008  3.83329305 4.00420726 5.31667122]\n",
      "##########\n",
      "epoch:32 step:154605[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:33 step:154610[D loss: 0.999981] [G loss: 1.000114]\n",
      "epoch:33 step:154615[D loss: 0.999927] [G loss: 1.000131]\n",
      "epoch:33 step:154620[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:33 step:154625[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:33 step:154630[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:33 step:154635[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:33 step:154640[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:33 step:154645[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:33 step:154650[D loss: 1.000104] [G loss: 0.999903]\n",
      "epoch:33 step:154655[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:33 step:154660[D loss: 1.000059] [G loss: 0.999968]\n",
      "epoch:33 step:154665[D loss: 0.999927] [G loss: 1.000072]\n",
      "epoch:33 step:154670[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:33 step:154675[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:33 step:154680[D loss: 1.000025] [G loss: 1.000068]\n",
      "epoch:33 step:154685[D loss: 0.999929] [G loss: 1.000141]\n",
      "epoch:33 step:154690[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:33 step:154695[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:33 step:154700[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:33 step:154705[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:33 step:154710[D loss: 1.000032] [G loss: 0.999985]\n",
      "epoch:33 step:154715[D loss: 1.000033] [G loss: 1.000020]\n",
      "epoch:33 step:154720[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:33 step:154725[D loss: 0.999890] [G loss: 1.000197]\n",
      "epoch:33 step:154730[D loss: 0.999937] [G loss: 1.000146]\n",
      "epoch:33 step:154735[D loss: 1.000067] [G loss: 1.000045]\n",
      "epoch:33 step:154740[D loss: 1.000036] [G loss: 1.000025]\n",
      "epoch:33 step:154745[D loss: 0.999914] [G loss: 1.000168]\n",
      "epoch:33 step:154750[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:33 step:154755[D loss: 1.000025] [G loss: 0.999988]\n",
      "epoch:33 step:154760[D loss: 0.999932] [G loss: 1.000030]\n",
      "epoch:33 step:154765[D loss: 1.000000] [G loss: 0.999940]\n",
      "epoch:33 step:154770[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:33 step:154775[D loss: 0.999966] [G loss: 1.000079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:154780[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:33 step:154785[D loss: 1.000068] [G loss: 1.000004]\n",
      "epoch:33 step:154790[D loss: 0.999981] [G loss: 1.000169]\n",
      "epoch:33 step:154795[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:33 step:154800[D loss: 0.999996] [G loss: 1.000048]\n",
      "##############\n",
      "[2.54253216 2.13178835 2.31459238 3.66152293 1.54851872 7.17776781\n",
      " 2.36278236 3.9898322  4.05840252 4.91346913]\n",
      "##########\n",
      "epoch:33 step:154805[D loss: 1.000108] [G loss: 0.999923]\n",
      "epoch:33 step:154810[D loss: 1.000011] [G loss: 0.999979]\n",
      "epoch:33 step:154815[D loss: 0.999963] [G loss: 0.999999]\n",
      "epoch:33 step:154820[D loss: 0.999931] [G loss: 1.000133]\n",
      "epoch:33 step:154825[D loss: 0.999978] [G loss: 0.999977]\n",
      "epoch:33 step:154830[D loss: 0.999911] [G loss: 1.000124]\n",
      "epoch:33 step:154835[D loss: 0.999961] [G loss: 1.000122]\n",
      "epoch:33 step:154840[D loss: 0.999929] [G loss: 1.000119]\n",
      "epoch:33 step:154845[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:33 step:154850[D loss: 0.999967] [G loss: 1.000097]\n",
      "epoch:33 step:154855[D loss: 0.999959] [G loss: 1.000050]\n",
      "epoch:33 step:154860[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:33 step:154865[D loss: 0.999998] [G loss: 1.000069]\n",
      "epoch:33 step:154870[D loss: 1.000055] [G loss: 1.000025]\n",
      "epoch:33 step:154875[D loss: 0.999982] [G loss: 1.000121]\n",
      "epoch:33 step:154880[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:33 step:154885[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:33 step:154890[D loss: 0.999988] [G loss: 1.000130]\n",
      "epoch:33 step:154895[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:33 step:154900[D loss: 0.999961] [G loss: 1.000133]\n",
      "epoch:33 step:154905[D loss: 0.999952] [G loss: 1.000103]\n",
      "epoch:33 step:154910[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:33 step:154915[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:33 step:154920[D loss: 0.999985] [G loss: 1.000109]\n",
      "epoch:33 step:154925[D loss: 1.000069] [G loss: 0.999963]\n",
      "epoch:33 step:154930[D loss: 0.999943] [G loss: 1.000093]\n",
      "epoch:33 step:154935[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:33 step:154940[D loss: 1.000004] [G loss: 1.000063]\n",
      "epoch:33 step:154945[D loss: 1.000004] [G loss: 0.999998]\n",
      "epoch:33 step:154950[D loss: 1.000171] [G loss: 0.999879]\n",
      "epoch:33 step:154955[D loss: 1.000061] [G loss: 0.999946]\n",
      "epoch:33 step:154960[D loss: 1.000028] [G loss: 1.000060]\n",
      "epoch:33 step:154965[D loss: 1.000002] [G loss: 1.000243]\n",
      "epoch:33 step:154970[D loss: 1.000011] [G loss: 0.999929]\n",
      "epoch:33 step:154975[D loss: 0.999937] [G loss: 1.000043]\n",
      "epoch:33 step:154980[D loss: 1.000107] [G loss: 0.999969]\n",
      "epoch:33 step:154985[D loss: 1.000007] [G loss: 0.999984]\n",
      "epoch:33 step:154990[D loss: 1.000036] [G loss: 0.999977]\n",
      "epoch:33 step:154995[D loss: 1.000030] [G loss: 0.999932]\n",
      "epoch:33 step:155000[D loss: 0.999949] [G loss: 1.000026]\n",
      "##############\n",
      "[2.61355448 2.24558384 2.33690493 3.68694336 1.62323548 6.978931\n",
      " 2.43451934 3.84341442 4.23131466 5.35694039]\n",
      "##########\n",
      "epoch:33 step:155005[D loss: 0.999978] [G loss: 1.000116]\n",
      "epoch:33 step:155010[D loss: 0.999975] [G loss: 1.000180]\n",
      "epoch:33 step:155015[D loss: 0.999935] [G loss: 1.000057]\n",
      "epoch:33 step:155020[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:33 step:155025[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:33 step:155030[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:33 step:155035[D loss: 0.999939] [G loss: 1.000052]\n",
      "epoch:33 step:155040[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:33 step:155045[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:33 step:155050[D loss: 1.000103] [G loss: 0.999973]\n",
      "epoch:33 step:155055[D loss: 1.000032] [G loss: 0.999883]\n",
      "epoch:33 step:155060[D loss: 0.999942] [G loss: 1.000107]\n",
      "epoch:33 step:155065[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:33 step:155070[D loss: 0.999951] [G loss: 1.000131]\n",
      "epoch:33 step:155075[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:33 step:155080[D loss: 1.000128] [G loss: 0.999858]\n",
      "epoch:33 step:155085[D loss: 0.999983] [G loss: 1.000107]\n",
      "epoch:33 step:155090[D loss: 0.999951] [G loss: 1.000229]\n",
      "epoch:33 step:155095[D loss: 0.999892] [G loss: 1.000331]\n",
      "epoch:33 step:155100[D loss: 1.000066] [G loss: 0.999877]\n",
      "epoch:33 step:155105[D loss: 1.000018] [G loss: 1.000062]\n",
      "epoch:33 step:155110[D loss: 0.999925] [G loss: 1.000088]\n",
      "epoch:33 step:155115[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:33 step:155120[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:33 step:155125[D loss: 1.000082] [G loss: 0.999824]\n",
      "epoch:33 step:155130[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:33 step:155135[D loss: 1.000010] [G loss: 1.000007]\n",
      "epoch:33 step:155140[D loss: 1.000294] [G loss: 0.999647]\n",
      "epoch:33 step:155145[D loss: 1.000250] [G loss: 0.999605]\n",
      "epoch:33 step:155150[D loss: 1.000054] [G loss: 0.999841]\n",
      "epoch:33 step:155155[D loss: 1.000061] [G loss: 0.999927]\n",
      "epoch:33 step:155160[D loss: 0.999847] [G loss: 1.000226]\n",
      "epoch:33 step:155165[D loss: 0.999969] [G loss: 1.000124]\n",
      "epoch:33 step:155170[D loss: 1.000090] [G loss: 1.000006]\n",
      "epoch:33 step:155175[D loss: 0.999924] [G loss: 1.000089]\n",
      "epoch:33 step:155180[D loss: 1.000025] [G loss: 1.000130]\n",
      "epoch:33 step:155185[D loss: 0.999966] [G loss: 1.000041]\n",
      "epoch:33 step:155190[D loss: 0.999988] [G loss: 1.000127]\n",
      "epoch:33 step:155195[D loss: 1.000101] [G loss: 0.999923]\n",
      "epoch:33 step:155200[D loss: 1.000159] [G loss: 0.999972]\n",
      "##############\n",
      "[2.62960673 2.29422509 2.2883151  3.92146859 1.60281257 7.21858692\n",
      " 2.36778321 3.83030598 4.15301383 5.09504087]\n",
      "##########\n",
      "epoch:33 step:155205[D loss: 1.000045] [G loss: 0.999880]\n",
      "epoch:33 step:155210[D loss: 0.999958] [G loss: 1.000120]\n",
      "epoch:33 step:155215[D loss: 0.999982] [G loss: 1.000160]\n",
      "epoch:33 step:155220[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:33 step:155225[D loss: 1.000073] [G loss: 0.999900]\n",
      "epoch:33 step:155230[D loss: 0.999939] [G loss: 1.000060]\n",
      "epoch:33 step:155235[D loss: 0.999981] [G loss: 1.000212]\n",
      "epoch:33 step:155240[D loss: 0.999904] [G loss: 1.000117]\n",
      "epoch:33 step:155245[D loss: 1.000018] [G loss: 1.000054]\n",
      "epoch:33 step:155250[D loss: 1.000029] [G loss: 1.000047]\n",
      "epoch:33 step:155255[D loss: 0.999891] [G loss: 1.000112]\n",
      "epoch:33 step:155260[D loss: 0.999951] [G loss: 1.000108]\n",
      "epoch:33 step:155265[D loss: 1.000049] [G loss: 0.999978]\n",
      "epoch:33 step:155270[D loss: 1.000135] [G loss: 0.999898]\n",
      "epoch:33 step:155275[D loss: 1.000058] [G loss: 0.999996]\n",
      "epoch:33 step:155280[D loss: 0.999814] [G loss: 1.000153]\n",
      "epoch:33 step:155285[D loss: 0.999934] [G loss: 1.000031]\n",
      "epoch:33 step:155290[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:33 step:155295[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:33 step:155300[D loss: 1.000003] [G loss: 1.000081]\n",
      "epoch:33 step:155305[D loss: 0.999951] [G loss: 1.000121]\n",
      "epoch:33 step:155310[D loss: 1.000028] [G loss: 1.000034]\n",
      "epoch:33 step:155315[D loss: 1.000003] [G loss: 0.999982]\n",
      "epoch:33 step:155320[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:33 step:155325[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:33 step:155330[D loss: 0.999966] [G loss: 1.000039]\n",
      "epoch:33 step:155335[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:33 step:155340[D loss: 1.000000] [G loss: 1.000103]\n",
      "epoch:33 step:155345[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:33 step:155350[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:33 step:155355[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:33 step:155360[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:33 step:155365[D loss: 1.000000] [G loss: 1.000066]\n",
      "epoch:33 step:155370[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:33 step:155375[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:33 step:155380[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:33 step:155385[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:33 step:155390[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:33 step:155395[D loss: 1.000033] [G loss: 0.999938]\n",
      "epoch:33 step:155400[D loss: 1.000030] [G loss: 0.999973]\n",
      "##############\n",
      "[2.56772281 2.23939478 2.19702557 3.80271949 1.54195156 7.22164695\n",
      " 2.33785522 3.92799155 4.05729599 5.17899074]\n",
      "##########\n",
      "epoch:33 step:155405[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:33 step:155410[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:33 step:155415[D loss: 1.000045] [G loss: 0.999951]\n",
      "epoch:33 step:155420[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:33 step:155425[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:33 step:155430[D loss: 1.000009] [G loss: 0.999993]\n",
      "epoch:33 step:155435[D loss: 1.000039] [G loss: 1.000014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:155440[D loss: 0.999990] [G loss: 0.999948]\n",
      "epoch:33 step:155445[D loss: 0.999916] [G loss: 0.999993]\n",
      "epoch:33 step:155450[D loss: 0.999992] [G loss: 1.000087]\n",
      "epoch:33 step:155455[D loss: 0.999954] [G loss: 1.000052]\n",
      "epoch:33 step:155460[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:33 step:155465[D loss: 0.999980] [G loss: 1.000121]\n",
      "epoch:33 step:155470[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:33 step:155475[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:33 step:155480[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:33 step:155485[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:33 step:155490[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:33 step:155495[D loss: 0.999946] [G loss: 1.000079]\n",
      "epoch:33 step:155500[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:33 step:155505[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:33 step:155510[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:33 step:155515[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:33 step:155520[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:33 step:155525[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:33 step:155530[D loss: 1.000022] [G loss: 1.000023]\n",
      "epoch:33 step:155535[D loss: 0.999963] [G loss: 0.999997]\n",
      "epoch:33 step:155540[D loss: 0.999938] [G loss: 1.000037]\n",
      "epoch:33 step:155545[D loss: 0.999928] [G loss: 1.000196]\n",
      "epoch:33 step:155550[D loss: 1.000011] [G loss: 0.999983]\n",
      "epoch:33 step:155555[D loss: 0.999998] [G loss: 1.000002]\n",
      "epoch:33 step:155560[D loss: 1.000033] [G loss: 0.999950]\n",
      "epoch:33 step:155565[D loss: 0.999930] [G loss: 1.000087]\n",
      "epoch:33 step:155570[D loss: 1.000025] [G loss: 1.000032]\n",
      "epoch:33 step:155575[D loss: 1.000011] [G loss: 1.000067]\n",
      "epoch:33 step:155580[D loss: 1.000012] [G loss: 1.000078]\n",
      "epoch:33 step:155585[D loss: 0.999978] [G loss: 1.000120]\n",
      "epoch:33 step:155590[D loss: 0.999886] [G loss: 1.000233]\n",
      "epoch:33 step:155595[D loss: 1.000086] [G loss: 0.999996]\n",
      "epoch:33 step:155600[D loss: 0.999953] [G loss: 1.000164]\n",
      "##############\n",
      "[2.61217398 2.21606297 2.24642764 3.90795301 1.58313431 8.46273857\n",
      " 2.46173226 3.87615911 3.998223   5.48805815]\n",
      "##########\n",
      "epoch:33 step:155605[D loss: 1.000090] [G loss: 1.000103]\n",
      "epoch:33 step:155610[D loss: 0.999900] [G loss: 1.000153]\n",
      "epoch:33 step:155615[D loss: 0.999940] [G loss: 1.000151]\n",
      "epoch:33 step:155620[D loss: 0.999958] [G loss: 1.000072]\n",
      "epoch:33 step:155625[D loss: 1.000082] [G loss: 0.999866]\n",
      "epoch:33 step:155630[D loss: 1.000017] [G loss: 0.999950]\n",
      "epoch:33 step:155635[D loss: 1.000051] [G loss: 0.999869]\n",
      "epoch:33 step:155640[D loss: 1.000006] [G loss: 1.000038]\n",
      "epoch:33 step:155645[D loss: 0.999922] [G loss: 1.000032]\n",
      "epoch:33 step:155650[D loss: 0.999948] [G loss: 1.000202]\n",
      "epoch:33 step:155655[D loss: 0.999950] [G loss: 1.000109]\n",
      "epoch:33 step:155660[D loss: 1.000011] [G loss: 1.000024]\n",
      "epoch:33 step:155665[D loss: 0.999940] [G loss: 1.000117]\n",
      "epoch:33 step:155670[D loss: 0.999959] [G loss: 1.000190]\n",
      "epoch:33 step:155675[D loss: 1.000016] [G loss: 1.000051]\n",
      "epoch:33 step:155680[D loss: 1.000053] [G loss: 1.000030]\n",
      "epoch:33 step:155685[D loss: 0.999958] [G loss: 1.000258]\n",
      "epoch:33 step:155690[D loss: 1.000167] [G loss: 1.000192]\n",
      "epoch:33 step:155695[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:33 step:155700[D loss: 0.999883] [G loss: 1.000194]\n",
      "epoch:33 step:155705[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:33 step:155710[D loss: 0.999991] [G loss: 1.000010]\n",
      "epoch:33 step:155715[D loss: 1.000108] [G loss: 0.999772]\n",
      "epoch:33 step:155720[D loss: 1.000102] [G loss: 0.999900]\n",
      "epoch:33 step:155725[D loss: 1.000045] [G loss: 0.999791]\n",
      "epoch:33 step:155730[D loss: 1.000282] [G loss: 0.999731]\n",
      "epoch:33 step:155735[D loss: 1.000249] [G loss: 0.999992]\n",
      "epoch:33 step:155740[D loss: 0.999983] [G loss: 1.000403]\n",
      "epoch:33 step:155745[D loss: 0.999946] [G loss: 1.000014]\n",
      "epoch:33 step:155750[D loss: 0.999808] [G loss: 1.000258]\n",
      "epoch:33 step:155755[D loss: 1.000039] [G loss: 1.000177]\n",
      "epoch:33 step:155760[D loss: 1.000006] [G loss: 1.000016]\n",
      "epoch:33 step:155765[D loss: 0.999973] [G loss: 1.000027]\n",
      "epoch:33 step:155770[D loss: 1.000018] [G loss: 1.000141]\n",
      "epoch:33 step:155775[D loss: 1.000021] [G loss: 1.000157]\n",
      "epoch:33 step:155780[D loss: 1.000003] [G loss: 1.000215]\n",
      "epoch:33 step:155785[D loss: 0.999873] [G loss: 1.000198]\n",
      "epoch:33 step:155790[D loss: 1.000002] [G loss: 1.000079]\n",
      "epoch:33 step:155795[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:33 step:155800[D loss: 0.999985] [G loss: 1.000078]\n",
      "##############\n",
      "[2.53093067 2.18680349 2.33997073 3.87508307 1.60852016 7.19787484\n",
      " 2.31037189 3.63107345 4.00195282 5.26943549]\n",
      "##########\n",
      "epoch:33 step:155805[D loss: 1.000040] [G loss: 0.999936]\n",
      "epoch:33 step:155810[D loss: 1.000126] [G loss: 1.000026]\n",
      "epoch:33 step:155815[D loss: 0.999972] [G loss: 0.999968]\n",
      "epoch:33 step:155820[D loss: 0.999850] [G loss: 1.000223]\n",
      "epoch:33 step:155825[D loss: 1.000047] [G loss: 1.000017]\n",
      "epoch:33 step:155830[D loss: 0.999903] [G loss: 1.000165]\n",
      "epoch:33 step:155835[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:33 step:155840[D loss: 0.999942] [G loss: 1.000031]\n",
      "epoch:33 step:155845[D loss: 1.000035] [G loss: 1.000042]\n",
      "epoch:33 step:155850[D loss: 0.999913] [G loss: 1.000121]\n",
      "epoch:33 step:155855[D loss: 1.000008] [G loss: 1.000018]\n",
      "epoch:33 step:155860[D loss: 1.000014] [G loss: 1.000048]\n",
      "epoch:33 step:155865[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:33 step:155870[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:33 step:155875[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:33 step:155880[D loss: 1.000072] [G loss: 1.000000]\n",
      "epoch:33 step:155885[D loss: 0.999937] [G loss: 1.000187]\n",
      "epoch:33 step:155890[D loss: 0.999997] [G loss: 1.000074]\n",
      "epoch:33 step:155895[D loss: 1.000007] [G loss: 1.000139]\n",
      "epoch:33 step:155900[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:33 step:155905[D loss: 1.000005] [G loss: 1.000047]\n",
      "epoch:33 step:155910[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:33 step:155915[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:33 step:155920[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:33 step:155925[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:33 step:155930[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:33 step:155935[D loss: 1.000042] [G loss: 0.999997]\n",
      "epoch:33 step:155940[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:33 step:155945[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:33 step:155950[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:33 step:155955[D loss: 1.000003] [G loss: 1.000009]\n",
      "epoch:33 step:155960[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:33 step:155965[D loss: 1.000011] [G loss: 1.000085]\n",
      "epoch:33 step:155970[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:33 step:155975[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:33 step:155980[D loss: 0.999998] [G loss: 1.000091]\n",
      "epoch:33 step:155985[D loss: 1.000006] [G loss: 1.000071]\n",
      "epoch:33 step:155990[D loss: 0.999864] [G loss: 1.000160]\n",
      "epoch:33 step:155995[D loss: 0.999935] [G loss: 1.000204]\n",
      "epoch:33 step:156000[D loss: 0.999941] [G loss: 1.000110]\n",
      "##############\n",
      "[2.59515312 2.30013222 2.3887318  3.65535859 1.6472865  7.86213648\n",
      " 2.35081893 3.61809994 4.05798112 5.06001538]\n",
      "##########\n",
      "epoch:33 step:156005[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:33 step:156010[D loss: 1.000029] [G loss: 0.999947]\n",
      "epoch:33 step:156015[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:33 step:156020[D loss: 0.999948] [G loss: 1.000096]\n",
      "epoch:33 step:156025[D loss: 1.000096] [G loss: 0.999897]\n",
      "epoch:33 step:156030[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:33 step:156035[D loss: 0.999887] [G loss: 1.000142]\n",
      "epoch:33 step:156040[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:33 step:156045[D loss: 0.999999] [G loss: 1.000074]\n",
      "epoch:33 step:156050[D loss: 0.999946] [G loss: 1.000040]\n",
      "epoch:33 step:156055[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:33 step:156060[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:33 step:156065[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:33 step:156070[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:33 step:156075[D loss: 1.000010] [G loss: 1.000036]\n",
      "epoch:33 step:156080[D loss: 0.999970] [G loss: 1.000115]\n",
      "epoch:33 step:156085[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:33 step:156090[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:33 step:156095[D loss: 0.999991] [G loss: 1.000079]\n",
      "epoch:33 step:156100[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:33 step:156105[D loss: 0.999974] [G loss: 1.000118]\n",
      "epoch:33 step:156110[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:33 step:156115[D loss: 0.999957] [G loss: 1.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:156120[D loss: 1.000041] [G loss: 0.999980]\n",
      "epoch:33 step:156125[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:33 step:156130[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:33 step:156135[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:33 step:156140[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:33 step:156145[D loss: 0.999943] [G loss: 1.000094]\n",
      "epoch:33 step:156150[D loss: 1.000003] [G loss: 1.000060]\n",
      "epoch:33 step:156155[D loss: 0.999951] [G loss: 1.000090]\n",
      "epoch:33 step:156160[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:33 step:156165[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:33 step:156170[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:33 step:156175[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:33 step:156180[D loss: 1.000035] [G loss: 1.000033]\n",
      "epoch:33 step:156185[D loss: 0.999973] [G loss: 1.000256]\n",
      "epoch:33 step:156190[D loss: 0.999934] [G loss: 1.000036]\n",
      "epoch:33 step:156195[D loss: 1.000006] [G loss: 1.000024]\n",
      "epoch:33 step:156200[D loss: 1.000018] [G loss: 1.000021]\n",
      "##############\n",
      "[2.55094269 2.26169144 2.25526601 3.58633192 1.57517736 7.58919286\n",
      " 2.34881893 3.89449814 4.05780726 4.89006956]\n",
      "##########\n",
      "epoch:33 step:156205[D loss: 0.999969] [G loss: 1.000000]\n",
      "epoch:33 step:156210[D loss: 1.000028] [G loss: 0.999919]\n",
      "epoch:33 step:156215[D loss: 1.000214] [G loss: 0.999698]\n",
      "epoch:33 step:156220[D loss: 1.000112] [G loss: 0.999803]\n",
      "epoch:33 step:156225[D loss: 1.000002] [G loss: 0.999806]\n",
      "epoch:33 step:156230[D loss: 0.999994] [G loss: 1.000033]\n",
      "epoch:33 step:156235[D loss: 0.999920] [G loss: 1.000045]\n",
      "epoch:33 step:156240[D loss: 1.000028] [G loss: 0.999987]\n",
      "epoch:33 step:156245[D loss: 0.999995] [G loss: 0.999965]\n",
      "epoch:33 step:156250[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:33 step:156255[D loss: 1.000001] [G loss: 0.999999]\n",
      "epoch:33 step:156260[D loss: 0.999970] [G loss: 1.000031]\n",
      "epoch:33 step:156265[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:33 step:156270[D loss: 0.999970] [G loss: 1.000147]\n",
      "epoch:33 step:156275[D loss: 0.999903] [G loss: 1.000115]\n",
      "epoch:33 step:156280[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:33 step:156285[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:33 step:156290[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:33 step:156295[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:33 step:156300[D loss: 0.999980] [G loss: 0.999982]\n",
      "epoch:33 step:156305[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:33 step:156310[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:33 step:156315[D loss: 0.999962] [G loss: 1.000104]\n",
      "epoch:33 step:156320[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:33 step:156325[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:33 step:156330[D loss: 1.000019] [G loss: 1.000048]\n",
      "epoch:33 step:156335[D loss: 1.000030] [G loss: 1.000031]\n",
      "epoch:33 step:156340[D loss: 0.999949] [G loss: 1.000077]\n",
      "epoch:33 step:156345[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:33 step:156350[D loss: 1.000090] [G loss: 1.000004]\n",
      "epoch:33 step:156355[D loss: 0.999925] [G loss: 1.000109]\n",
      "epoch:33 step:156360[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:33 step:156365[D loss: 1.000010] [G loss: 1.000078]\n",
      "epoch:33 step:156370[D loss: 0.999961] [G loss: 1.000153]\n",
      "epoch:33 step:156375[D loss: 0.999960] [G loss: 1.000048]\n",
      "epoch:33 step:156380[D loss: 1.000117] [G loss: 0.999809]\n",
      "epoch:33 step:156385[D loss: 0.999961] [G loss: 1.000043]\n",
      "epoch:33 step:156390[D loss: 1.000056] [G loss: 0.999813]\n",
      "epoch:33 step:156395[D loss: 1.000067] [G loss: 1.000099]\n",
      "epoch:33 step:156400[D loss: 0.999920] [G loss: 1.000057]\n",
      "##############\n",
      "[2.57107223 2.28146917 2.31402543 3.77830193 1.5500882  8.27728949\n",
      " 2.44426055 3.89265481 4.11497289 5.18509188]\n",
      "##########\n",
      "epoch:33 step:156405[D loss: 1.000160] [G loss: 0.999849]\n",
      "epoch:33 step:156410[D loss: 0.999867] [G loss: 1.000158]\n",
      "epoch:33 step:156415[D loss: 0.999958] [G loss: 1.000119]\n",
      "epoch:33 step:156420[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:33 step:156425[D loss: 1.000132] [G loss: 0.999866]\n",
      "epoch:33 step:156430[D loss: 1.000049] [G loss: 0.999974]\n",
      "epoch:33 step:156435[D loss: 0.999920] [G loss: 1.000210]\n",
      "epoch:33 step:156440[D loss: 1.000168] [G loss: 1.000003]\n",
      "epoch:33 step:156445[D loss: 0.999923] [G loss: 1.000195]\n",
      "epoch:33 step:156450[D loss: 1.000102] [G loss: 0.999918]\n",
      "epoch:33 step:156455[D loss: 0.999920] [G loss: 1.000312]\n",
      "epoch:33 step:156460[D loss: 0.999744] [G loss: 1.000391]\n",
      "epoch:33 step:156465[D loss: 1.000036] [G loss: 1.000111]\n",
      "epoch:33 step:156470[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:33 step:156475[D loss: 0.999880] [G loss: 1.000364]\n",
      "epoch:33 step:156480[D loss: 0.999928] [G loss: 1.000093]\n",
      "epoch:33 step:156485[D loss: 0.999895] [G loss: 1.000153]\n",
      "epoch:33 step:156490[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:33 step:156495[D loss: 1.000135] [G loss: 0.999851]\n",
      "epoch:33 step:156500[D loss: 0.999945] [G loss: 0.999993]\n",
      "epoch:33 step:156505[D loss: 1.000038] [G loss: 0.999868]\n",
      "epoch:33 step:156510[D loss: 1.000144] [G loss: 0.999890]\n",
      "epoch:33 step:156515[D loss: 1.000069] [G loss: 0.999856]\n",
      "epoch:33 step:156520[D loss: 0.999951] [G loss: 0.999917]\n",
      "epoch:33 step:156525[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:33 step:156530[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:33 step:156535[D loss: 1.000034] [G loss: 0.999919]\n",
      "epoch:33 step:156540[D loss: 1.000031] [G loss: 1.000061]\n",
      "epoch:33 step:156545[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:33 step:156550[D loss: 1.000012] [G loss: 1.000085]\n",
      "epoch:33 step:156555[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:33 step:156560[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:33 step:156565[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:33 step:156570[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:33 step:156575[D loss: 0.999999] [G loss: 1.000016]\n",
      "epoch:33 step:156580[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:33 step:156585[D loss: 1.000028] [G loss: 0.999951]\n",
      "epoch:33 step:156590[D loss: 0.999957] [G loss: 1.000054]\n",
      "epoch:33 step:156595[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:33 step:156600[D loss: 0.999967] [G loss: 1.000117]\n",
      "##############\n",
      "[2.56052869 2.29716983 2.27257036 3.4867322  1.54732467 7.77556652\n",
      " 2.41587344 4.09925184 4.07289617 6.24724002]\n",
      "##########\n",
      "epoch:33 step:156605[D loss: 0.999957] [G loss: 1.000014]\n",
      "epoch:33 step:156610[D loss: 1.000052] [G loss: 0.999944]\n",
      "epoch:33 step:156615[D loss: 1.000152] [G loss: 0.999821]\n",
      "epoch:33 step:156620[D loss: 1.000016] [G loss: 1.000083]\n",
      "epoch:33 step:156625[D loss: 1.000028] [G loss: 1.000000]\n",
      "epoch:33 step:156630[D loss: 0.999931] [G loss: 1.000053]\n",
      "epoch:33 step:156635[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:33 step:156640[D loss: 1.000108] [G loss: 0.999891]\n",
      "epoch:33 step:156645[D loss: 0.999950] [G loss: 0.999961]\n",
      "epoch:33 step:156650[D loss: 1.000066] [G loss: 0.999941]\n",
      "epoch:33 step:156655[D loss: 1.000213] [G loss: 1.000020]\n",
      "epoch:33 step:156660[D loss: 1.000039] [G loss: 0.999921]\n",
      "epoch:33 step:156665[D loss: 0.999860] [G loss: 1.000156]\n",
      "epoch:33 step:156670[D loss: 0.999937] [G loss: 1.000114]\n",
      "epoch:33 step:156675[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:33 step:156680[D loss: 1.000024] [G loss: 1.000014]\n",
      "epoch:33 step:156685[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:33 step:156690[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:33 step:156695[D loss: 0.999946] [G loss: 1.000105]\n",
      "epoch:33 step:156700[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:33 step:156705[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:33 step:156710[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:33 step:156715[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:33 step:156720[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:33 step:156725[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:33 step:156730[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:33 step:156735[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:33 step:156740[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:33 step:156745[D loss: 0.999987] [G loss: 0.999997]\n",
      "epoch:33 step:156750[D loss: 0.999970] [G loss: 1.000026]\n",
      "epoch:33 step:156755[D loss: 1.000001] [G loss: 0.999997]\n",
      "epoch:33 step:156760[D loss: 0.999931] [G loss: 1.000101]\n",
      "epoch:33 step:156765[D loss: 0.999967] [G loss: 1.000117]\n",
      "epoch:33 step:156770[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:33 step:156775[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:33 step:156780[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:33 step:156785[D loss: 1.000039] [G loss: 1.000045]\n",
      "epoch:33 step:156790[D loss: 0.999944] [G loss: 1.000095]\n",
      "epoch:33 step:156795[D loss: 1.000045] [G loss: 1.000033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:156800[D loss: 1.000003] [G loss: 1.000007]\n",
      "##############\n",
      "[2.55465675 2.22079895 2.28053196 3.6189667  1.58712195 7.57064676\n",
      " 2.41844472 3.93439051 4.11882706 5.49357278]\n",
      "##########\n",
      "epoch:33 step:156805[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:33 step:156810[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:33 step:156815[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:33 step:156820[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:33 step:156825[D loss: 0.999956] [G loss: 1.000058]\n",
      "epoch:33 step:156830[D loss: 1.000020] [G loss: 1.000106]\n",
      "epoch:33 step:156835[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:33 step:156840[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:33 step:156845[D loss: 1.000008] [G loss: 1.000054]\n",
      "epoch:33 step:156850[D loss: 0.999939] [G loss: 1.000141]\n",
      "epoch:33 step:156855[D loss: 0.999854] [G loss: 1.000229]\n",
      "epoch:33 step:156860[D loss: 0.999916] [G loss: 1.000205]\n",
      "epoch:33 step:156865[D loss: 0.999918] [G loss: 1.000246]\n",
      "epoch:33 step:156870[D loss: 0.999968] [G loss: 1.000106]\n",
      "epoch:33 step:156875[D loss: 0.999951] [G loss: 1.000092]\n",
      "epoch:33 step:156880[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:33 step:156885[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:33 step:156890[D loss: 1.000034] [G loss: 0.999893]\n",
      "epoch:33 step:156895[D loss: 1.000038] [G loss: 1.000152]\n",
      "epoch:33 step:156900[D loss: 1.000329] [G loss: 0.999866]\n",
      "epoch:33 step:156905[D loss: 0.999883] [G loss: 1.000015]\n",
      "epoch:33 step:156910[D loss: 0.999962] [G loss: 1.000137]\n",
      "epoch:33 step:156915[D loss: 1.000032] [G loss: 0.999925]\n",
      "epoch:33 step:156920[D loss: 0.999881] [G loss: 1.000237]\n",
      "epoch:33 step:156925[D loss: 0.999948] [G loss: 1.000086]\n",
      "epoch:33 step:156930[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:33 step:156935[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:33 step:156940[D loss: 0.999987] [G loss: 0.999975]\n",
      "epoch:33 step:156945[D loss: 1.000038] [G loss: 0.999975]\n",
      "epoch:33 step:156950[D loss: 1.000108] [G loss: 0.999953]\n",
      "epoch:33 step:156955[D loss: 0.999944] [G loss: 1.000059]\n",
      "epoch:33 step:156960[D loss: 0.999963] [G loss: 1.000238]\n",
      "epoch:33 step:156965[D loss: 0.999977] [G loss: 1.000120]\n",
      "epoch:33 step:156970[D loss: 0.999926] [G loss: 1.000091]\n",
      "epoch:33 step:156975[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:33 step:156980[D loss: 0.999978] [G loss: 0.999999]\n",
      "epoch:33 step:156985[D loss: 1.000038] [G loss: 1.000027]\n",
      "epoch:33 step:156990[D loss: 0.999955] [G loss: 1.000027]\n",
      "epoch:33 step:156995[D loss: 1.000071] [G loss: 0.999975]\n",
      "epoch:33 step:157000[D loss: 0.999942] [G loss: 1.000040]\n",
      "##############\n",
      "[2.51519624 2.20140333 2.29400352 3.57541956 1.51907666 6.82730054\n",
      " 2.32466452 3.74048582 4.12003889 5.29379529]\n",
      "##########\n",
      "epoch:33 step:157005[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:33 step:157010[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:33 step:157015[D loss: 0.999940] [G loss: 1.000088]\n",
      "epoch:33 step:157020[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:33 step:157025[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:33 step:157030[D loss: 1.000163] [G loss: 0.999854]\n",
      "epoch:33 step:157035[D loss: 0.999970] [G loss: 1.000036]\n",
      "epoch:33 step:157040[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:33 step:157045[D loss: 1.000017] [G loss: 1.000204]\n",
      "epoch:33 step:157050[D loss: 0.999920] [G loss: 1.000215]\n",
      "epoch:33 step:157055[D loss: 1.000098] [G loss: 0.999968]\n",
      "epoch:33 step:157060[D loss: 1.000026] [G loss: 1.000033]\n",
      "epoch:33 step:157065[D loss: 0.999891] [G loss: 1.000315]\n",
      "epoch:33 step:157070[D loss: 1.000015] [G loss: 1.000196]\n",
      "epoch:33 step:157075[D loss: 0.999944] [G loss: 1.000249]\n",
      "epoch:33 step:157080[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:33 step:157085[D loss: 1.000108] [G loss: 1.000098]\n",
      "epoch:33 step:157090[D loss: 0.999951] [G loss: 1.000171]\n",
      "epoch:33 step:157095[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:33 step:157100[D loss: 0.999997] [G loss: 0.999992]\n",
      "epoch:33 step:157105[D loss: 1.000198] [G loss: 0.999720]\n",
      "epoch:33 step:157110[D loss: 1.000046] [G loss: 0.999799]\n",
      "epoch:33 step:157115[D loss: 1.000160] [G loss: 0.999751]\n",
      "epoch:33 step:157120[D loss: 0.999865] [G loss: 1.000109]\n",
      "epoch:33 step:157125[D loss: 1.000029] [G loss: 0.999991]\n",
      "epoch:33 step:157130[D loss: 0.999906] [G loss: 1.000147]\n",
      "epoch:33 step:157135[D loss: 0.999932] [G loss: 1.000079]\n",
      "epoch:33 step:157140[D loss: 0.999969] [G loss: 1.000251]\n",
      "epoch:33 step:157145[D loss: 0.999967] [G loss: 1.000334]\n",
      "epoch:33 step:157150[D loss: 1.000047] [G loss: 0.999980]\n",
      "epoch:33 step:157155[D loss: 1.000200] [G loss: 1.000204]\n",
      "epoch:33 step:157160[D loss: 0.999870] [G loss: 1.000275]\n",
      "epoch:33 step:157165[D loss: 0.999874] [G loss: 1.000113]\n",
      "epoch:33 step:157170[D loss: 1.000031] [G loss: 0.999998]\n",
      "epoch:33 step:157175[D loss: 1.000088] [G loss: 0.999895]\n",
      "epoch:33 step:157180[D loss: 0.999912] [G loss: 1.000107]\n",
      "epoch:33 step:157185[D loss: 0.999944] [G loss: 1.000092]\n",
      "epoch:33 step:157190[D loss: 1.000100] [G loss: 0.999982]\n",
      "epoch:33 step:157195[D loss: 0.999972] [G loss: 1.000014]\n",
      "epoch:33 step:157200[D loss: 1.000000] [G loss: 1.000087]\n",
      "##############\n",
      "[2.61195502 2.32212526 2.43417222 3.83089898 1.6005994  8.28561454\n",
      " 2.55296117 3.86134276 4.21400649 5.51671984]\n",
      "##########\n",
      "epoch:33 step:157205[D loss: 1.000031] [G loss: 1.000046]\n",
      "epoch:33 step:157210[D loss: 0.999935] [G loss: 1.000186]\n",
      "epoch:33 step:157215[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:33 step:157220[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:33 step:157225[D loss: 1.000016] [G loss: 1.000079]\n",
      "epoch:33 step:157230[D loss: 0.999954] [G loss: 1.000101]\n",
      "epoch:33 step:157235[D loss: 1.000011] [G loss: 1.000032]\n",
      "epoch:33 step:157240[D loss: 0.999917] [G loss: 1.000127]\n",
      "epoch:33 step:157245[D loss: 0.999939] [G loss: 1.000114]\n",
      "epoch:33 step:157250[D loss: 0.999939] [G loss: 1.000087]\n",
      "epoch:33 step:157255[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:33 step:157260[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:33 step:157265[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:33 step:157270[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:33 step:157275[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:33 step:157280[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:33 step:157285[D loss: 1.000039] [G loss: 1.000004]\n",
      "epoch:33 step:157290[D loss: 1.000023] [G loss: 1.000039]\n",
      "epoch:33 step:157295[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:33 step:157300[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:33 step:157305[D loss: 0.999975] [G loss: 1.000120]\n",
      "epoch:33 step:157310[D loss: 0.999955] [G loss: 1.000063]\n",
      "epoch:33 step:157315[D loss: 0.999987] [G loss: 0.999970]\n",
      "epoch:33 step:157320[D loss: 0.999963] [G loss: 1.000128]\n",
      "epoch:33 step:157325[D loss: 1.000017] [G loss: 0.999998]\n",
      "epoch:33 step:157330[D loss: 0.999880] [G loss: 1.000211]\n",
      "epoch:33 step:157335[D loss: 0.999958] [G loss: 1.000157]\n",
      "epoch:33 step:157340[D loss: 0.999942] [G loss: 1.000079]\n",
      "epoch:33 step:157345[D loss: 0.999940] [G loss: 1.000151]\n",
      "epoch:33 step:157350[D loss: 0.999976] [G loss: 1.000111]\n",
      "epoch:33 step:157355[D loss: 0.999970] [G loss: 1.000152]\n",
      "epoch:33 step:157360[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:33 step:157365[D loss: 0.999995] [G loss: 1.000087]\n",
      "epoch:33 step:157370[D loss: 1.000008] [G loss: 1.000029]\n",
      "epoch:33 step:157375[D loss: 0.999957] [G loss: 1.000025]\n",
      "epoch:33 step:157380[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:33 step:157385[D loss: 0.999988] [G loss: 0.999970]\n",
      "epoch:33 step:157390[D loss: 1.000054] [G loss: 0.999903]\n",
      "epoch:33 step:157395[D loss: 0.999972] [G loss: 1.000010]\n",
      "epoch:33 step:157400[D loss: 1.000012] [G loss: 1.000018]\n",
      "##############\n",
      "[2.58562805 2.24831124 2.22517045 3.73852264 1.6281763  7.16135795\n",
      " 2.50421638 4.01117439 4.11346402 5.72263445]\n",
      "##########\n",
      "epoch:33 step:157405[D loss: 0.999934] [G loss: 1.000213]\n",
      "epoch:33 step:157410[D loss: 1.000036] [G loss: 1.000000]\n",
      "epoch:33 step:157415[D loss: 0.999945] [G loss: 1.000203]\n",
      "epoch:33 step:157420[D loss: 0.999884] [G loss: 1.000173]\n",
      "epoch:33 step:157425[D loss: 0.999947] [G loss: 1.000126]\n",
      "epoch:33 step:157430[D loss: 0.999986] [G loss: 1.000115]\n",
      "epoch:33 step:157435[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:33 step:157440[D loss: 1.000023] [G loss: 0.999955]\n",
      "epoch:33 step:157445[D loss: 1.000070] [G loss: 0.999938]\n",
      "epoch:33 step:157450[D loss: 1.000139] [G loss: 0.999768]\n",
      "epoch:33 step:157455[D loss: 1.000068] [G loss: 1.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:157460[D loss: 0.999893] [G loss: 1.000111]\n",
      "epoch:33 step:157465[D loss: 1.000009] [G loss: 0.999984]\n",
      "epoch:33 step:157470[D loss: 0.999899] [G loss: 1.000087]\n",
      "epoch:33 step:157475[D loss: 1.000017] [G loss: 1.000075]\n",
      "epoch:33 step:157480[D loss: 0.999935] [G loss: 1.000060]\n",
      "epoch:33 step:157485[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:33 step:157490[D loss: 0.999960] [G loss: 1.000100]\n",
      "epoch:33 step:157495[D loss: 1.000019] [G loss: 1.000016]\n",
      "epoch:33 step:157500[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:33 step:157505[D loss: 1.000167] [G loss: 0.999976]\n",
      "epoch:33 step:157510[D loss: 0.999869] [G loss: 1.000089]\n",
      "epoch:33 step:157515[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:33 step:157520[D loss: 0.999944] [G loss: 1.000078]\n",
      "epoch:33 step:157525[D loss: 1.000005] [G loss: 1.000103]\n",
      "epoch:33 step:157530[D loss: 0.999944] [G loss: 1.000065]\n",
      "epoch:33 step:157535[D loss: 1.000014] [G loss: 0.999927]\n",
      "epoch:33 step:157540[D loss: 0.999998] [G loss: 0.999984]\n",
      "epoch:33 step:157545[D loss: 1.000058] [G loss: 0.999925]\n",
      "epoch:33 step:157550[D loss: 1.000080] [G loss: 1.000028]\n",
      "epoch:33 step:157555[D loss: 1.000024] [G loss: 0.999956]\n",
      "epoch:33 step:157560[D loss: 0.999954] [G loss: 1.000140]\n",
      "epoch:33 step:157565[D loss: 0.999981] [G loss: 0.999989]\n",
      "epoch:33 step:157570[D loss: 1.000065] [G loss: 1.000014]\n",
      "epoch:33 step:157575[D loss: 1.000015] [G loss: 1.000017]\n",
      "epoch:33 step:157580[D loss: 1.000077] [G loss: 1.000174]\n",
      "epoch:33 step:157585[D loss: 0.999900] [G loss: 1.000163]\n",
      "epoch:33 step:157590[D loss: 1.000020] [G loss: 0.999943]\n",
      "epoch:33 step:157595[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:33 step:157600[D loss: 0.999979] [G loss: 1.000036]\n",
      "##############\n",
      "[2.61432215 2.25012717 2.18598426 3.67753199 1.60035686 7.01289818\n",
      " 2.47501775 3.86336177 4.04494855 5.27395087]\n",
      "##########\n",
      "epoch:33 step:157605[D loss: 0.999941] [G loss: 1.000103]\n",
      "epoch:33 step:157610[D loss: 1.000060] [G loss: 0.999941]\n",
      "epoch:33 step:157615[D loss: 0.999929] [G loss: 1.000087]\n",
      "epoch:33 step:157620[D loss: 0.999912] [G loss: 1.000122]\n",
      "epoch:33 step:157625[D loss: 0.999992] [G loss: 1.000014]\n",
      "epoch:33 step:157630[D loss: 0.999975] [G loss: 1.000034]\n",
      "epoch:33 step:157635[D loss: 0.999952] [G loss: 1.000044]\n",
      "epoch:33 step:157640[D loss: 1.000040] [G loss: 1.000009]\n",
      "epoch:33 step:157645[D loss: 0.999972] [G loss: 1.000033]\n",
      "epoch:33 step:157650[D loss: 1.000050] [G loss: 1.000164]\n",
      "epoch:33 step:157655[D loss: 0.999881] [G loss: 1.000134]\n",
      "epoch:33 step:157660[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:33 step:157665[D loss: 1.000017] [G loss: 0.999980]\n",
      "epoch:33 step:157670[D loss: 1.000015] [G loss: 0.999946]\n",
      "epoch:33 step:157675[D loss: 1.000051] [G loss: 0.999924]\n",
      "epoch:33 step:157680[D loss: 0.999942] [G loss: 1.000206]\n",
      "epoch:33 step:157685[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:33 step:157690[D loss: 1.000010] [G loss: 1.000035]\n",
      "epoch:33 step:157695[D loss: 1.000036] [G loss: 1.000030]\n",
      "epoch:33 step:157700[D loss: 0.999993] [G loss: 1.000109]\n",
      "epoch:33 step:157705[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:33 step:157710[D loss: 0.999951] [G loss: 1.000116]\n",
      "epoch:33 step:157715[D loss: 0.999976] [G loss: 1.000117]\n",
      "epoch:33 step:157720[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:33 step:157725[D loss: 1.000046] [G loss: 0.999905]\n",
      "epoch:33 step:157730[D loss: 0.999927] [G loss: 1.000176]\n",
      "epoch:33 step:157735[D loss: 0.999946] [G loss: 1.000091]\n",
      "epoch:33 step:157740[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:33 step:157745[D loss: 1.000014] [G loss: 0.999959]\n",
      "epoch:33 step:157750[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:33 step:157755[D loss: 1.000031] [G loss: 0.999956]\n",
      "epoch:33 step:157760[D loss: 1.000032] [G loss: 1.000007]\n",
      "epoch:33 step:157765[D loss: 0.999962] [G loss: 1.000173]\n",
      "epoch:33 step:157770[D loss: 1.000050] [G loss: 0.999907]\n",
      "epoch:33 step:157775[D loss: 0.999913] [G loss: 1.000116]\n",
      "epoch:33 step:157780[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:33 step:157785[D loss: 0.999941] [G loss: 1.000100]\n",
      "epoch:33 step:157790[D loss: 1.000132] [G loss: 0.999875]\n",
      "epoch:33 step:157795[D loss: 0.999815] [G loss: 1.000110]\n",
      "epoch:33 step:157800[D loss: 0.999896] [G loss: 1.000045]\n",
      "##############\n",
      "[2.5594689  2.27972171 2.30268154 3.60073285 1.6291766  7.73700233\n",
      " 2.45929903 3.93090717 4.11675532 4.48376161]\n",
      "##########\n",
      "epoch:33 step:157805[D loss: 1.000176] [G loss: 0.999951]\n",
      "epoch:33 step:157810[D loss: 1.000040] [G loss: 1.000113]\n",
      "epoch:33 step:157815[D loss: 0.999855] [G loss: 1.000262]\n",
      "epoch:33 step:157820[D loss: 0.999823] [G loss: 1.000139]\n",
      "epoch:33 step:157825[D loss: 0.999936] [G loss: 1.000137]\n",
      "epoch:33 step:157830[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:33 step:157835[D loss: 0.999987] [G loss: 1.000024]\n",
      "epoch:33 step:157840[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:33 step:157845[D loss: 0.999955] [G loss: 1.000059]\n",
      "epoch:33 step:157850[D loss: 1.000014] [G loss: 1.000047]\n",
      "epoch:33 step:157855[D loss: 0.999993] [G loss: 0.999912]\n",
      "epoch:33 step:157860[D loss: 1.000089] [G loss: 0.999903]\n",
      "epoch:33 step:157865[D loss: 0.999891] [G loss: 1.000134]\n",
      "epoch:33 step:157870[D loss: 1.000080] [G loss: 1.000057]\n",
      "epoch:33 step:157875[D loss: 0.999874] [G loss: 1.000175]\n",
      "epoch:33 step:157880[D loss: 0.999981] [G loss: 1.000092]\n",
      "epoch:33 step:157885[D loss: 0.999968] [G loss: 1.000124]\n",
      "epoch:33 step:157890[D loss: 0.999962] [G loss: 1.000150]\n",
      "epoch:33 step:157895[D loss: 0.999930] [G loss: 1.000193]\n",
      "epoch:33 step:157900[D loss: 0.999967] [G loss: 1.000168]\n",
      "epoch:33 step:157905[D loss: 0.999924] [G loss: 1.000120]\n",
      "epoch:33 step:157910[D loss: 1.000010] [G loss: 1.000039]\n",
      "epoch:33 step:157915[D loss: 1.000020] [G loss: 1.000122]\n",
      "epoch:33 step:157920[D loss: 0.999945] [G loss: 1.000159]\n",
      "epoch:33 step:157925[D loss: 0.999973] [G loss: 1.000030]\n",
      "epoch:33 step:157930[D loss: 1.000109] [G loss: 0.999805]\n",
      "epoch:33 step:157935[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:33 step:157940[D loss: 0.999922] [G loss: 1.000057]\n",
      "epoch:33 step:157945[D loss: 0.999989] [G loss: 1.000086]\n",
      "epoch:33 step:157950[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:33 step:157955[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:33 step:157960[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:33 step:157965[D loss: 0.999949] [G loss: 1.000079]\n",
      "epoch:33 step:157970[D loss: 0.999958] [G loss: 1.000126]\n",
      "epoch:33 step:157975[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:33 step:157980[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:33 step:157985[D loss: 0.999940] [G loss: 1.000080]\n",
      "epoch:33 step:157990[D loss: 0.999961] [G loss: 1.000039]\n",
      "epoch:33 step:157995[D loss: 0.999935] [G loss: 1.000109]\n",
      "epoch:33 step:158000[D loss: 1.000026] [G loss: 0.999963]\n",
      "##############\n",
      "[2.56909298 2.20134335 2.23319511 3.56826595 1.51126088 7.20991231\n",
      " 2.25492889 3.83837978 3.9870422  4.95115118]\n",
      "##########\n",
      "epoch:33 step:158005[D loss: 1.000095] [G loss: 0.999851]\n",
      "epoch:33 step:158010[D loss: 0.999894] [G loss: 1.000114]\n",
      "epoch:33 step:158015[D loss: 1.000053] [G loss: 1.000004]\n",
      "epoch:33 step:158020[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:33 step:158025[D loss: 0.999964] [G loss: 1.000051]\n",
      "epoch:33 step:158030[D loss: 1.000007] [G loss: 1.000028]\n",
      "epoch:33 step:158035[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:33 step:158040[D loss: 1.000010] [G loss: 1.000033]\n",
      "epoch:33 step:158045[D loss: 1.000017] [G loss: 0.999994]\n",
      "epoch:33 step:158050[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:33 step:158055[D loss: 0.999945] [G loss: 1.000076]\n",
      "epoch:33 step:158060[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:33 step:158065[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:33 step:158070[D loss: 1.000014] [G loss: 1.000190]\n",
      "epoch:33 step:158075[D loss: 0.999923] [G loss: 1.000104]\n",
      "epoch:33 step:158080[D loss: 0.999980] [G loss: 0.999993]\n",
      "epoch:33 step:158085[D loss: 0.999957] [G loss: 1.000043]\n",
      "epoch:33 step:158090[D loss: 0.999930] [G loss: 1.000108]\n",
      "epoch:33 step:158095[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:33 step:158100[D loss: 0.999983] [G loss: 1.000106]\n",
      "epoch:33 step:158105[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:33 step:158110[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:33 step:158115[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:33 step:158120[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:33 step:158125[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:33 step:158130[D loss: 1.000009] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:158135[D loss: 0.999965] [G loss: 1.000103]\n",
      "epoch:33 step:158140[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:33 step:158145[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:33 step:158150[D loss: 1.000042] [G loss: 1.000063]\n",
      "epoch:33 step:158155[D loss: 1.000154] [G loss: 0.999968]\n",
      "epoch:33 step:158160[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:33 step:158165[D loss: 0.999909] [G loss: 1.000085]\n",
      "epoch:33 step:158170[D loss: 0.999884] [G loss: 1.000161]\n",
      "epoch:33 step:158175[D loss: 1.000018] [G loss: 1.000146]\n",
      "epoch:33 step:158180[D loss: 0.999950] [G loss: 1.000107]\n",
      "epoch:33 step:158185[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:33 step:158190[D loss: 0.999932] [G loss: 1.000090]\n",
      "epoch:33 step:158195[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:33 step:158200[D loss: 0.999974] [G loss: 1.000081]\n",
      "##############\n",
      "[2.60740551 2.3083272  2.22602052 3.71095145 1.54087315 7.41729762\n",
      " 2.42696387 3.88694115 4.05209486 8.14868929]\n",
      "##########\n",
      "epoch:33 step:158205[D loss: 0.999954] [G loss: 1.000044]\n",
      "epoch:33 step:158210[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:33 step:158215[D loss: 1.000000] [G loss: 1.000083]\n",
      "epoch:33 step:158220[D loss: 1.000043] [G loss: 1.000064]\n",
      "epoch:33 step:158225[D loss: 1.000016] [G loss: 0.999987]\n",
      "epoch:33 step:158230[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:33 step:158235[D loss: 0.999975] [G loss: 0.999958]\n",
      "epoch:33 step:158240[D loss: 0.999956] [G loss: 1.000045]\n",
      "epoch:33 step:158245[D loss: 1.000089] [G loss: 1.000108]\n",
      "epoch:33 step:158250[D loss: 0.999958] [G loss: 1.000002]\n",
      "epoch:33 step:158255[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:33 step:158260[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:33 step:158265[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:33 step:158270[D loss: 0.999989] [G loss: 0.999983]\n",
      "epoch:33 step:158275[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:33 step:158280[D loss: 0.999999] [G loss: 1.000049]\n",
      "epoch:33 step:158285[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:33 step:158290[D loss: 1.000042] [G loss: 1.000128]\n",
      "epoch:33 step:158295[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:33 step:158300[D loss: 0.999993] [G loss: 1.000169]\n",
      "epoch:33 step:158305[D loss: 0.999957] [G loss: 1.000274]\n",
      "epoch:33 step:158310[D loss: 0.999972] [G loss: 1.000125]\n",
      "epoch:33 step:158315[D loss: 1.000367] [G loss: 0.999371]\n",
      "epoch:33 step:158320[D loss: 0.999884] [G loss: 0.999957]\n",
      "epoch:33 step:158325[D loss: 1.000039] [G loss: 0.999930]\n",
      "epoch:33 step:158330[D loss: 0.999982] [G loss: 0.999885]\n",
      "epoch:33 step:158335[D loss: 0.999943] [G loss: 1.000019]\n",
      "epoch:33 step:158340[D loss: 0.999909] [G loss: 1.000054]\n",
      "epoch:33 step:158345[D loss: 0.999956] [G loss: 1.000050]\n",
      "epoch:33 step:158350[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:33 step:158355[D loss: 1.000077] [G loss: 0.999988]\n",
      "epoch:33 step:158360[D loss: 0.999945] [G loss: 1.000073]\n",
      "epoch:33 step:158365[D loss: 0.999949] [G loss: 1.000049]\n",
      "epoch:33 step:158370[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:33 step:158375[D loss: 0.999856] [G loss: 1.000353]\n",
      "epoch:33 step:158380[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:33 step:158385[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:33 step:158390[D loss: 0.999989] [G loss: 1.000002]\n",
      "epoch:33 step:158395[D loss: 1.000084] [G loss: 1.000104]\n",
      "epoch:33 step:158400[D loss: 0.999924] [G loss: 1.000072]\n",
      "##############\n",
      "[2.62030654 2.31138172 2.22148934 3.84692915 1.56062493 7.62520957\n",
      " 2.50948512 3.89172854 4.00811736 5.46520648]\n",
      "##########\n",
      "epoch:33 step:158405[D loss: 1.000017] [G loss: 1.000004]\n",
      "epoch:33 step:158410[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:33 step:158415[D loss: 1.000092] [G loss: 1.000088]\n",
      "epoch:33 step:158420[D loss: 1.000033] [G loss: 0.999967]\n",
      "epoch:33 step:158425[D loss: 0.999923] [G loss: 1.000148]\n",
      "epoch:33 step:158430[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:33 step:158435[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:33 step:158440[D loss: 0.999884] [G loss: 1.000160]\n",
      "epoch:33 step:158445[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:33 step:158450[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:33 step:158455[D loss: 0.999981] [G loss: 0.999942]\n",
      "epoch:33 step:158460[D loss: 1.000135] [G loss: 0.999856]\n",
      "epoch:33 step:158465[D loss: 1.000066] [G loss: 0.999872]\n",
      "epoch:33 step:158470[D loss: 1.000039] [G loss: 0.999920]\n",
      "epoch:33 step:158475[D loss: 1.000147] [G loss: 1.000058]\n",
      "epoch:33 step:158480[D loss: 0.999823] [G loss: 1.000159]\n",
      "epoch:33 step:158485[D loss: 0.999856] [G loss: 1.000264]\n",
      "epoch:33 step:158490[D loss: 0.999939] [G loss: 1.000047]\n",
      "epoch:33 step:158495[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:33 step:158500[D loss: 1.000093] [G loss: 0.999928]\n",
      "epoch:33 step:158505[D loss: 0.999916] [G loss: 1.000056]\n",
      "epoch:33 step:158510[D loss: 0.999933] [G loss: 1.000036]\n",
      "epoch:33 step:158515[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:33 step:158520[D loss: 0.999954] [G loss: 1.000071]\n",
      "epoch:33 step:158525[D loss: 1.000056] [G loss: 0.999970]\n",
      "epoch:33 step:158530[D loss: 0.999952] [G loss: 1.000058]\n",
      "epoch:33 step:158535[D loss: 0.999950] [G loss: 1.000133]\n",
      "epoch:33 step:158540[D loss: 0.999869] [G loss: 1.000167]\n",
      "epoch:33 step:158545[D loss: 0.999971] [G loss: 1.000150]\n",
      "epoch:33 step:158550[D loss: 1.000108] [G loss: 0.999961]\n",
      "epoch:33 step:158555[D loss: 0.999939] [G loss: 1.000062]\n",
      "epoch:33 step:158560[D loss: 0.999992] [G loss: 1.000013]\n",
      "epoch:33 step:158565[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:33 step:158570[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:33 step:158575[D loss: 0.999955] [G loss: 1.000089]\n",
      "epoch:33 step:158580[D loss: 0.999993] [G loss: 1.000012]\n",
      "epoch:33 step:158585[D loss: 0.999981] [G loss: 1.000008]\n",
      "epoch:33 step:158590[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:33 step:158595[D loss: 1.000036] [G loss: 1.000022]\n",
      "epoch:33 step:158600[D loss: 0.999966] [G loss: 1.000047]\n",
      "##############\n",
      "[2.62862206 2.30095914 2.27375434 3.88139262 1.61592427 7.84558105\n",
      " 2.39241991 3.94793028 4.15621699 4.78643083]\n",
      "##########\n",
      "epoch:33 step:158605[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:33 step:158610[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:33 step:158615[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:33 step:158620[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:33 step:158625[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:33 step:158630[D loss: 1.000034] [G loss: 0.999948]\n",
      "epoch:33 step:158635[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:33 step:158640[D loss: 1.000007] [G loss: 1.000066]\n",
      "epoch:33 step:158645[D loss: 1.000074] [G loss: 1.000019]\n",
      "epoch:33 step:158650[D loss: 0.999958] [G loss: 1.000043]\n",
      "epoch:33 step:158655[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:33 step:158660[D loss: 0.999999] [G loss: 1.000000]\n",
      "epoch:33 step:158665[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:33 step:158670[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:33 step:158675[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:33 step:158680[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:33 step:158685[D loss: 1.000049] [G loss: 0.999919]\n",
      "epoch:33 step:158690[D loss: 0.999944] [G loss: 1.000117]\n",
      "epoch:33 step:158695[D loss: 1.000063] [G loss: 0.999972]\n",
      "epoch:33 step:158700[D loss: 0.999959] [G loss: 1.000045]\n",
      "epoch:33 step:158705[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:33 step:158710[D loss: 1.000009] [G loss: 1.000026]\n",
      "epoch:33 step:158715[D loss: 1.000003] [G loss: 1.000052]\n",
      "epoch:33 step:158720[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:33 step:158725[D loss: 0.999956] [G loss: 1.000070]\n",
      "epoch:33 step:158730[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:33 step:158735[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:33 step:158740[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:33 step:158745[D loss: 1.000044] [G loss: 0.999900]\n",
      "epoch:33 step:158750[D loss: 0.999928] [G loss: 1.000192]\n",
      "epoch:33 step:158755[D loss: 0.999946] [G loss: 1.000081]\n",
      "epoch:33 step:158760[D loss: 0.999986] [G loss: 0.999984]\n",
      "epoch:33 step:158765[D loss: 1.000048] [G loss: 1.000026]\n",
      "epoch:33 step:158770[D loss: 0.999987] [G loss: 0.999964]\n",
      "epoch:33 step:158775[D loss: 1.000132] [G loss: 0.999966]\n",
      "epoch:33 step:158780[D loss: 0.999861] [G loss: 1.000157]\n",
      "epoch:33 step:158785[D loss: 0.999900] [G loss: 1.000090]\n",
      "epoch:33 step:158790[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:33 step:158795[D loss: 0.999957] [G loss: 1.000043]\n",
      "epoch:33 step:158800[D loss: 0.999974] [G loss: 1.000087]\n",
      "##############\n",
      "[2.54971139 2.19932333 2.23970857 3.4560512  1.56538896 7.13872882\n",
      " 2.38564826 3.89751938 3.9770928  4.6118054 ]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:158805[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:33 step:158810[D loss: 1.000004] [G loss: 1.000071]\n",
      "epoch:33 step:158815[D loss: 1.000006] [G loss: 1.000033]\n",
      "epoch:33 step:158820[D loss: 0.999829] [G loss: 1.000281]\n",
      "epoch:33 step:158825[D loss: 1.000078] [G loss: 1.000107]\n",
      "epoch:33 step:158830[D loss: 0.999906] [G loss: 1.000114]\n",
      "epoch:33 step:158835[D loss: 0.999961] [G loss: 1.000100]\n",
      "epoch:33 step:158840[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:33 step:158845[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:33 step:158850[D loss: 0.999999] [G loss: 1.000113]\n",
      "epoch:33 step:158855[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:33 step:158860[D loss: 0.999993] [G loss: 0.999973]\n",
      "epoch:33 step:158865[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:33 step:158870[D loss: 1.000019] [G loss: 1.000001]\n",
      "epoch:33 step:158875[D loss: 0.999922] [G loss: 1.000174]\n",
      "epoch:33 step:158880[D loss: 1.000001] [G loss: 1.000024]\n",
      "epoch:33 step:158885[D loss: 1.000016] [G loss: 1.000192]\n",
      "epoch:33 step:158890[D loss: 0.999989] [G loss: 1.000175]\n",
      "epoch:33 step:158895[D loss: 0.999974] [G loss: 0.999969]\n",
      "epoch:33 step:158900[D loss: 0.999968] [G loss: 1.000152]\n",
      "epoch:33 step:158905[D loss: 0.999917] [G loss: 1.000114]\n",
      "epoch:33 step:158910[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:33 step:158915[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:33 step:158920[D loss: 1.000017] [G loss: 1.000001]\n",
      "epoch:33 step:158925[D loss: 1.000122] [G loss: 0.999776]\n",
      "epoch:33 step:158930[D loss: 0.999874] [G loss: 1.000129]\n",
      "epoch:33 step:158935[D loss: 0.999977] [G loss: 1.000007]\n",
      "epoch:33 step:158940[D loss: 1.000060] [G loss: 0.999983]\n",
      "epoch:33 step:158945[D loss: 1.000041] [G loss: 0.999946]\n",
      "epoch:33 step:158950[D loss: 0.999955] [G loss: 1.000197]\n",
      "epoch:33 step:158955[D loss: 1.000181] [G loss: 0.999988]\n",
      "epoch:33 step:158960[D loss: 0.999921] [G loss: 1.000070]\n",
      "epoch:33 step:158965[D loss: 0.999937] [G loss: 1.000073]\n",
      "epoch:33 step:158970[D loss: 1.000022] [G loss: 1.000043]\n",
      "epoch:33 step:158975[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:33 step:158980[D loss: 0.999983] [G loss: 1.000026]\n",
      "epoch:33 step:158985[D loss: 0.999974] [G loss: 0.999980]\n",
      "epoch:33 step:158990[D loss: 0.999910] [G loss: 0.999979]\n",
      "epoch:33 step:158995[D loss: 0.999954] [G loss: 1.000114]\n",
      "epoch:33 step:159000[D loss: 0.999994] [G loss: 1.000013]\n",
      "##############\n",
      "[2.50574835 2.13376799 2.23215183 3.40640392 1.5458233  6.93819194\n",
      " 2.52112187 3.80604456 4.02694349 5.44464134]\n",
      "##########\n",
      "epoch:33 step:159005[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:33 step:159010[D loss: 0.999945] [G loss: 1.000135]\n",
      "epoch:33 step:159015[D loss: 0.999978] [G loss: 0.999998]\n",
      "epoch:33 step:159020[D loss: 0.999944] [G loss: 1.000097]\n",
      "epoch:33 step:159025[D loss: 1.000004] [G loss: 1.000017]\n",
      "epoch:33 step:159030[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:33 step:159035[D loss: 1.000107] [G loss: 0.999772]\n",
      "epoch:33 step:159040[D loss: 0.999915] [G loss: 1.000164]\n",
      "epoch:33 step:159045[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:33 step:159050[D loss: 1.000113] [G loss: 0.999879]\n",
      "epoch:33 step:159055[D loss: 0.999873] [G loss: 1.000131]\n",
      "epoch:33 step:159060[D loss: 0.999896] [G loss: 1.000165]\n",
      "epoch:33 step:159065[D loss: 0.999996] [G loss: 1.000109]\n",
      "epoch:33 step:159070[D loss: 1.000013] [G loss: 1.000135]\n",
      "epoch:33 step:159075[D loss: 1.000033] [G loss: 1.000239]\n",
      "epoch:33 step:159080[D loss: 1.000009] [G loss: 1.000077]\n",
      "epoch:33 step:159085[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:33 step:159090[D loss: 0.999931] [G loss: 1.000089]\n",
      "epoch:33 step:159095[D loss: 0.999986] [G loss: 1.000009]\n",
      "epoch:33 step:159100[D loss: 0.999974] [G loss: 0.999969]\n",
      "epoch:33 step:159105[D loss: 0.999987] [G loss: 1.000011]\n",
      "epoch:33 step:159110[D loss: 1.000117] [G loss: 0.999980]\n",
      "epoch:33 step:159115[D loss: 1.000017] [G loss: 0.999882]\n",
      "epoch:33 step:159120[D loss: 0.999960] [G loss: 1.000011]\n",
      "epoch:33 step:159125[D loss: 0.999944] [G loss: 1.000049]\n",
      "epoch:33 step:159130[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:33 step:159135[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:33 step:159140[D loss: 0.999944] [G loss: 1.000078]\n",
      "epoch:33 step:159145[D loss: 1.000101] [G loss: 0.999869]\n",
      "epoch:33 step:159150[D loss: 1.000061] [G loss: 0.999948]\n",
      "epoch:33 step:159155[D loss: 0.999943] [G loss: 1.000074]\n",
      "epoch:33 step:159160[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:33 step:159165[D loss: 0.999943] [G loss: 1.000076]\n",
      "epoch:33 step:159170[D loss: 0.999933] [G loss: 1.000072]\n",
      "epoch:33 step:159175[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:33 step:159180[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:33 step:159185[D loss: 0.999996] [G loss: 1.000011]\n",
      "epoch:33 step:159190[D loss: 1.000041] [G loss: 1.000045]\n",
      "epoch:33 step:159195[D loss: 0.999953] [G loss: 1.000031]\n",
      "epoch:33 step:159200[D loss: 0.999991] [G loss: 1.000057]\n",
      "##############\n",
      "[2.57045719 2.24233642 2.31954363 4.00302584 1.53171513 8.63063985\n",
      " 2.43134233 3.89441797 4.02931764 5.10163047]\n",
      "##########\n",
      "epoch:33 step:159205[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:33 step:159210[D loss: 1.000113] [G loss: 0.999888]\n",
      "epoch:33 step:159215[D loss: 0.999940] [G loss: 1.000096]\n",
      "epoch:33 step:159220[D loss: 0.999936] [G loss: 1.000118]\n",
      "epoch:33 step:159225[D loss: 1.000029] [G loss: 0.999954]\n",
      "epoch:33 step:159230[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:33 step:159235[D loss: 0.999931] [G loss: 1.000060]\n",
      "epoch:33 step:159240[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:33 step:159245[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:33 step:159250[D loss: 0.999932] [G loss: 1.000065]\n",
      "epoch:33 step:159255[D loss: 0.999962] [G loss: 1.000144]\n",
      "epoch:33 step:159260[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:33 step:159265[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:33 step:159270[D loss: 1.000033] [G loss: 1.000048]\n",
      "epoch:33 step:159275[D loss: 1.000108] [G loss: 0.999932]\n",
      "epoch:33 step:159280[D loss: 0.999943] [G loss: 1.000078]\n",
      "epoch:33 step:159285[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:33 step:159290[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:34 step:159295[D loss: 1.000029] [G loss: 1.000080]\n",
      "epoch:34 step:159300[D loss: 0.999987] [G loss: 1.000011]\n",
      "epoch:34 step:159305[D loss: 0.999982] [G loss: 1.000018]\n",
      "epoch:34 step:159310[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:34 step:159315[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:34 step:159320[D loss: 0.999945] [G loss: 1.000074]\n",
      "epoch:34 step:159325[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:34 step:159330[D loss: 0.999930] [G loss: 1.000114]\n",
      "epoch:34 step:159335[D loss: 0.999951] [G loss: 1.000154]\n",
      "epoch:34 step:159340[D loss: 1.000045] [G loss: 1.000047]\n",
      "epoch:34 step:159345[D loss: 1.000027] [G loss: 0.999985]\n",
      "epoch:34 step:159350[D loss: 0.999972] [G loss: 1.000001]\n",
      "epoch:34 step:159355[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:34 step:159360[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:34 step:159365[D loss: 1.000011] [G loss: 1.000056]\n",
      "epoch:34 step:159370[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:34 step:159375[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:34 step:159380[D loss: 0.999998] [G loss: 1.000004]\n",
      "epoch:34 step:159385[D loss: 1.000014] [G loss: 1.000007]\n",
      "epoch:34 step:159390[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:34 step:159395[D loss: 1.000021] [G loss: 1.000016]\n",
      "epoch:34 step:159400[D loss: 0.999928] [G loss: 1.000214]\n",
      "##############\n",
      "[2.56098419 2.30123233 2.33874554 3.61216773 1.56056759 7.80983722\n",
      " 2.36626418 3.99907003 4.00327151 4.9771343 ]\n",
      "##########\n",
      "epoch:34 step:159405[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:34 step:159410[D loss: 0.999951] [G loss: 1.000155]\n",
      "epoch:34 step:159415[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:34 step:159420[D loss: 1.000007] [G loss: 1.000080]\n",
      "epoch:34 step:159425[D loss: 0.999984] [G loss: 1.000160]\n",
      "epoch:34 step:159430[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:34 step:159435[D loss: 1.000102] [G loss: 0.999934]\n",
      "epoch:34 step:159440[D loss: 1.000158] [G loss: 0.999706]\n",
      "epoch:34 step:159445[D loss: 0.999863] [G loss: 1.000022]\n",
      "epoch:34 step:159450[D loss: 0.999907] [G loss: 1.000096]\n",
      "epoch:34 step:159455[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:34 step:159460[D loss: 1.000032] [G loss: 0.999967]\n",
      "epoch:34 step:159465[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:34 step:159470[D loss: 1.000062] [G loss: 0.999907]\n",
      "epoch:34 step:159475[D loss: 1.000077] [G loss: 0.999971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:159480[D loss: 0.999886] [G loss: 1.000155]\n",
      "epoch:34 step:159485[D loss: 0.999942] [G loss: 1.000088]\n",
      "epoch:34 step:159490[D loss: 1.000038] [G loss: 0.999947]\n",
      "epoch:34 step:159495[D loss: 1.000121] [G loss: 0.999739]\n",
      "epoch:34 step:159500[D loss: 0.999851] [G loss: 1.000192]\n",
      "epoch:34 step:159505[D loss: 0.999929] [G loss: 1.000134]\n",
      "epoch:34 step:159510[D loss: 0.999920] [G loss: 1.000134]\n",
      "epoch:34 step:159515[D loss: 1.000037] [G loss: 0.999956]\n",
      "epoch:34 step:159520[D loss: 1.000081] [G loss: 0.999877]\n",
      "epoch:34 step:159525[D loss: 0.999917] [G loss: 1.000137]\n",
      "epoch:34 step:159530[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:34 step:159535[D loss: 1.000018] [G loss: 0.999958]\n",
      "epoch:34 step:159540[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:34 step:159545[D loss: 1.000007] [G loss: 1.000049]\n",
      "epoch:34 step:159550[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:34 step:159555[D loss: 1.000009] [G loss: 0.999986]\n",
      "epoch:34 step:159560[D loss: 0.999981] [G loss: 1.000120]\n",
      "epoch:34 step:159565[D loss: 0.999999] [G loss: 0.999987]\n",
      "epoch:34 step:159570[D loss: 1.000048] [G loss: 1.000022]\n",
      "epoch:34 step:159575[D loss: 0.999914] [G loss: 1.000072]\n",
      "epoch:34 step:159580[D loss: 0.999999] [G loss: 1.000101]\n",
      "epoch:34 step:159585[D loss: 0.999941] [G loss: 1.000212]\n",
      "epoch:34 step:159590[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:34 step:159595[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:34 step:159600[D loss: 1.000015] [G loss: 1.000046]\n",
      "##############\n",
      "[2.55102697 2.2275877  2.2502037  3.52645891 1.54377071 7.12985483\n",
      " 2.42788051 3.67656766 4.0212399  5.02540773]\n",
      "##########\n",
      "epoch:34 step:159605[D loss: 1.000069] [G loss: 0.999935]\n",
      "epoch:34 step:159610[D loss: 0.999991] [G loss: 1.000115]\n",
      "epoch:34 step:159615[D loss: 1.000051] [G loss: 0.999989]\n",
      "epoch:34 step:159620[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:34 step:159625[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:34 step:159630[D loss: 1.000029] [G loss: 1.000036]\n",
      "epoch:34 step:159635[D loss: 1.000076] [G loss: 1.000105]\n",
      "epoch:34 step:159640[D loss: 1.000079] [G loss: 0.999885]\n",
      "epoch:34 step:159645[D loss: 0.999884] [G loss: 1.000311]\n",
      "epoch:34 step:159650[D loss: 1.000097] [G loss: 1.000008]\n",
      "epoch:34 step:159655[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:34 step:159660[D loss: 1.000000] [G loss: 0.999958]\n",
      "epoch:34 step:159665[D loss: 1.000021] [G loss: 0.999964]\n",
      "epoch:34 step:159670[D loss: 1.000067] [G loss: 0.999965]\n",
      "epoch:34 step:159675[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:34 step:159680[D loss: 1.000089] [G loss: 0.999978]\n",
      "epoch:34 step:159685[D loss: 0.999931] [G loss: 1.000189]\n",
      "epoch:34 step:159690[D loss: 0.999867] [G loss: 1.000227]\n",
      "epoch:34 step:159695[D loss: 0.999957] [G loss: 1.000216]\n",
      "epoch:34 step:159700[D loss: 0.999914] [G loss: 1.000120]\n",
      "epoch:34 step:159705[D loss: 0.999943] [G loss: 1.000152]\n",
      "epoch:34 step:159710[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:34 step:159715[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:34 step:159720[D loss: 1.000020] [G loss: 0.999858]\n",
      "epoch:34 step:159725[D loss: 1.000037] [G loss: 0.999876]\n",
      "epoch:34 step:159730[D loss: 1.000152] [G loss: 0.999938]\n",
      "epoch:34 step:159735[D loss: 1.000106] [G loss: 0.999936]\n",
      "epoch:34 step:159740[D loss: 0.999836] [G loss: 1.000150]\n",
      "epoch:34 step:159745[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:34 step:159750[D loss: 0.999927] [G loss: 1.000148]\n",
      "epoch:34 step:159755[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:34 step:159760[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:34 step:159765[D loss: 1.000120] [G loss: 0.999881]\n",
      "epoch:34 step:159770[D loss: 1.000251] [G loss: 0.999781]\n",
      "epoch:34 step:159775[D loss: 1.000194] [G loss: 0.999850]\n",
      "epoch:34 step:159780[D loss: 1.000117] [G loss: 0.999984]\n",
      "epoch:34 step:159785[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:34 step:159790[D loss: 1.000022] [G loss: 1.000043]\n",
      "epoch:34 step:159795[D loss: 0.999932] [G loss: 1.000147]\n",
      "epoch:34 step:159800[D loss: 1.000015] [G loss: 1.000060]\n",
      "##############\n",
      "[2.50343691 2.2325683  2.22565352 3.34119906 1.5820112  7.55240037\n",
      " 2.33378092 3.76670571 4.0009381  5.25628632]\n",
      "##########\n",
      "epoch:34 step:159805[D loss: 0.999929] [G loss: 1.000102]\n",
      "epoch:34 step:159810[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:34 step:159815[D loss: 1.000002] [G loss: 0.999970]\n",
      "epoch:34 step:159820[D loss: 0.999951] [G loss: 1.000049]\n",
      "epoch:34 step:159825[D loss: 1.000057] [G loss: 1.000043]\n",
      "epoch:34 step:159830[D loss: 1.000162] [G loss: 0.999793]\n",
      "epoch:34 step:159835[D loss: 0.999986] [G loss: 0.999885]\n",
      "epoch:34 step:159840[D loss: 0.999975] [G loss: 1.000217]\n",
      "epoch:34 step:159845[D loss: 1.000012] [G loss: 0.999971]\n",
      "epoch:34 step:159850[D loss: 0.999959] [G loss: 1.000133]\n",
      "epoch:34 step:159855[D loss: 1.000105] [G loss: 1.000015]\n",
      "epoch:34 step:159860[D loss: 1.000075] [G loss: 0.999930]\n",
      "epoch:34 step:159865[D loss: 1.000017] [G loss: 1.000109]\n",
      "epoch:34 step:159870[D loss: 0.999973] [G loss: 1.000031]\n",
      "epoch:34 step:159875[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:34 step:159880[D loss: 1.000097] [G loss: 0.999881]\n",
      "epoch:34 step:159885[D loss: 1.000065] [G loss: 1.000132]\n",
      "epoch:34 step:159890[D loss: 0.999981] [G loss: 0.999935]\n",
      "epoch:34 step:159895[D loss: 0.999822] [G loss: 1.000223]\n",
      "epoch:34 step:159900[D loss: 0.999953] [G loss: 1.000203]\n",
      "epoch:34 step:159905[D loss: 0.999833] [G loss: 1.000383]\n",
      "epoch:34 step:159910[D loss: 0.999979] [G loss: 1.000192]\n",
      "epoch:34 step:159915[D loss: 0.999957] [G loss: 1.000126]\n",
      "epoch:34 step:159920[D loss: 1.000033] [G loss: 1.000112]\n",
      "epoch:34 step:159925[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:34 step:159930[D loss: 1.000074] [G loss: 1.000019]\n",
      "epoch:34 step:159935[D loss: 1.000078] [G loss: 0.999944]\n",
      "epoch:34 step:159940[D loss: 0.999936] [G loss: 0.999977]\n",
      "epoch:34 step:159945[D loss: 0.999955] [G loss: 1.000112]\n",
      "epoch:34 step:159950[D loss: 1.000049] [G loss: 1.000002]\n",
      "epoch:34 step:159955[D loss: 1.000048] [G loss: 0.999983]\n",
      "epoch:34 step:159960[D loss: 0.999985] [G loss: 1.000000]\n",
      "epoch:34 step:159965[D loss: 0.999900] [G loss: 1.000161]\n",
      "epoch:34 step:159970[D loss: 0.999953] [G loss: 1.000028]\n",
      "epoch:34 step:159975[D loss: 1.000025] [G loss: 1.000034]\n",
      "epoch:34 step:159980[D loss: 0.999992] [G loss: 1.000060]\n",
      "epoch:34 step:159985[D loss: 0.999934] [G loss: 1.000106]\n",
      "epoch:34 step:159990[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:34 step:159995[D loss: 1.000012] [G loss: 1.000076]\n",
      "epoch:34 step:160000[D loss: 0.999906] [G loss: 1.000159]\n",
      "##############\n",
      "[2.51973009 2.22194897 2.2301294  3.55348283 1.52697391 7.19726527\n",
      " 2.41542062 3.77770048 4.01201046 5.86546648]\n",
      "##########\n",
      "epoch:34 step:160005[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:34 step:160010[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:34 step:160015[D loss: 0.999975] [G loss: 1.000195]\n",
      "epoch:34 step:160020[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:34 step:160025[D loss: 0.999991] [G loss: 1.000118]\n",
      "epoch:34 step:160030[D loss: 0.999928] [G loss: 1.000061]\n",
      "epoch:34 step:160035[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:34 step:160040[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:34 step:160045[D loss: 0.999982] [G loss: 1.000098]\n",
      "epoch:34 step:160050[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:34 step:160055[D loss: 0.999959] [G loss: 1.000123]\n",
      "epoch:34 step:160060[D loss: 0.999974] [G loss: 1.000110]\n",
      "epoch:34 step:160065[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:34 step:160070[D loss: 1.000055] [G loss: 0.999960]\n",
      "epoch:34 step:160075[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:34 step:160080[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:34 step:160085[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:34 step:160090[D loss: 1.000063] [G loss: 0.999930]\n",
      "epoch:34 step:160095[D loss: 1.000066] [G loss: 0.999961]\n",
      "epoch:34 step:160100[D loss: 1.000100] [G loss: 0.999954]\n",
      "epoch:34 step:160105[D loss: 1.000025] [G loss: 0.999920]\n",
      "epoch:34 step:160110[D loss: 0.999901] [G loss: 1.000180]\n",
      "epoch:34 step:160115[D loss: 0.999952] [G loss: 1.000073]\n",
      "epoch:34 step:160120[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:34 step:160125[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:34 step:160130[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:34 step:160135[D loss: 1.000016] [G loss: 1.000015]\n",
      "epoch:34 step:160140[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:34 step:160145[D loss: 0.999978] [G loss: 1.000095]\n",
      "epoch:34 step:160150[D loss: 0.999965] [G loss: 1.000114]\n",
      "epoch:34 step:160155[D loss: 0.999944] [G loss: 1.000102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:160160[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:34 step:160165[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:34 step:160170[D loss: 1.000012] [G loss: 0.999974]\n",
      "epoch:34 step:160175[D loss: 0.999945] [G loss: 1.000082]\n",
      "epoch:34 step:160180[D loss: 1.000026] [G loss: 1.000073]\n",
      "epoch:34 step:160185[D loss: 0.999814] [G loss: 1.000354]\n",
      "epoch:34 step:160190[D loss: 0.999956] [G loss: 1.000035]\n",
      "epoch:34 step:160195[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:34 step:160200[D loss: 0.999970] [G loss: 1.000077]\n",
      "##############\n",
      "[2.53479542 2.17292305 2.2632685  3.72438561 1.55309961 7.75380759\n",
      " 2.37089893 3.87981861 4.03593273 5.0132993 ]\n",
      "##########\n",
      "epoch:34 step:160205[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:34 step:160210[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:34 step:160215[D loss: 1.000018] [G loss: 1.000032]\n",
      "epoch:34 step:160220[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:34 step:160225[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:34 step:160230[D loss: 0.999970] [G loss: 1.000188]\n",
      "epoch:34 step:160235[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:34 step:160240[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:34 step:160245[D loss: 0.999994] [G loss: 1.000076]\n",
      "epoch:34 step:160250[D loss: 0.999957] [G loss: 1.000039]\n",
      "epoch:34 step:160255[D loss: 1.000047] [G loss: 1.000007]\n",
      "epoch:34 step:160260[D loss: 1.000028] [G loss: 1.000025]\n",
      "epoch:34 step:160265[D loss: 1.000043] [G loss: 1.000040]\n",
      "epoch:34 step:160270[D loss: 0.999919] [G loss: 1.000127]\n",
      "epoch:34 step:160275[D loss: 1.000030] [G loss: 1.000037]\n",
      "epoch:34 step:160280[D loss: 1.000092] [G loss: 1.000089]\n",
      "epoch:34 step:160285[D loss: 0.999907] [G loss: 1.000296]\n",
      "epoch:34 step:160290[D loss: 0.999960] [G loss: 1.000259]\n",
      "epoch:34 step:160295[D loss: 0.999951] [G loss: 1.000161]\n",
      "epoch:34 step:160300[D loss: 0.999895] [G loss: 1.000128]\n",
      "epoch:34 step:160305[D loss: 0.999961] [G loss: 1.000006]\n",
      "epoch:34 step:160310[D loss: 1.000099] [G loss: 0.999757]\n",
      "epoch:34 step:160315[D loss: 1.000072] [G loss: 0.999814]\n",
      "epoch:34 step:160320[D loss: 1.000055] [G loss: 0.999912]\n",
      "epoch:34 step:160325[D loss: 1.000176] [G loss: 0.999868]\n",
      "epoch:34 step:160330[D loss: 0.999850] [G loss: 1.000083]\n",
      "epoch:34 step:160335[D loss: 1.000075] [G loss: 1.000001]\n",
      "epoch:34 step:160340[D loss: 0.999887] [G loss: 1.000205]\n",
      "epoch:34 step:160345[D loss: 1.000015] [G loss: 1.000145]\n",
      "epoch:34 step:160350[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:34 step:160355[D loss: 0.999948] [G loss: 1.000093]\n",
      "epoch:34 step:160360[D loss: 0.999985] [G loss: 1.000105]\n",
      "epoch:34 step:160365[D loss: 0.999960] [G loss: 1.000113]\n",
      "epoch:34 step:160370[D loss: 1.000011] [G loss: 1.000100]\n",
      "epoch:34 step:160375[D loss: 1.000048] [G loss: 1.000199]\n",
      "epoch:34 step:160380[D loss: 0.999995] [G loss: 0.999998]\n",
      "epoch:34 step:160385[D loss: 0.999858] [G loss: 1.000191]\n",
      "epoch:34 step:160390[D loss: 0.999976] [G loss: 1.000116]\n",
      "epoch:34 step:160395[D loss: 0.999982] [G loss: 1.000093]\n",
      "epoch:34 step:160400[D loss: 0.999978] [G loss: 1.000049]\n",
      "##############\n",
      "[2.59789848 2.25729094 2.37290248 3.76278652 1.51213976 7.11075472\n",
      " 2.73833027 3.94983415 4.18637381 5.30625452]\n",
      "##########\n",
      "epoch:34 step:160405[D loss: 1.000009] [G loss: 1.000049]\n",
      "epoch:34 step:160410[D loss: 0.999934] [G loss: 1.000071]\n",
      "epoch:34 step:160415[D loss: 1.000122] [G loss: 0.999945]\n",
      "epoch:34 step:160420[D loss: 0.999990] [G loss: 1.000184]\n",
      "epoch:34 step:160425[D loss: 1.000214] [G loss: 0.999964]\n",
      "epoch:34 step:160430[D loss: 0.999692] [G loss: 1.000382]\n",
      "epoch:34 step:160435[D loss: 0.999907] [G loss: 1.000178]\n",
      "epoch:34 step:160440[D loss: 1.000063] [G loss: 1.000109]\n",
      "epoch:34 step:160445[D loss: 0.999906] [G loss: 1.000225]\n",
      "epoch:34 step:160450[D loss: 0.999884] [G loss: 1.000254]\n",
      "epoch:34 step:160455[D loss: 1.000057] [G loss: 1.000197]\n",
      "epoch:34 step:160460[D loss: 0.999981] [G loss: 1.000220]\n",
      "epoch:34 step:160465[D loss: 0.999956] [G loss: 1.000170]\n",
      "epoch:34 step:160470[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:34 step:160475[D loss: 1.000090] [G loss: 0.999816]\n",
      "epoch:34 step:160480[D loss: 0.999957] [G loss: 1.000021]\n",
      "epoch:34 step:160485[D loss: 1.000036] [G loss: 0.999855]\n",
      "epoch:34 step:160490[D loss: 1.000117] [G loss: 0.999823]\n",
      "epoch:34 step:160495[D loss: 1.000075] [G loss: 1.000056]\n",
      "epoch:34 step:160500[D loss: 1.000183] [G loss: 0.999798]\n",
      "epoch:34 step:160505[D loss: 0.999928] [G loss: 1.000131]\n",
      "epoch:34 step:160510[D loss: 1.000097] [G loss: 1.000130]\n",
      "epoch:34 step:160515[D loss: 0.999950] [G loss: 1.000034]\n",
      "epoch:34 step:160520[D loss: 0.999806] [G loss: 1.000338]\n",
      "epoch:34 step:160525[D loss: 0.999931] [G loss: 1.000095]\n",
      "epoch:34 step:160530[D loss: 1.000000] [G loss: 1.000146]\n",
      "epoch:34 step:160535[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:34 step:160540[D loss: 1.000060] [G loss: 0.999931]\n",
      "epoch:34 step:160545[D loss: 1.000033] [G loss: 1.000020]\n",
      "epoch:34 step:160550[D loss: 1.000034] [G loss: 0.999980]\n",
      "epoch:34 step:160555[D loss: 1.000073] [G loss: 1.000002]\n",
      "epoch:34 step:160560[D loss: 0.999996] [G loss: 1.000095]\n",
      "epoch:34 step:160565[D loss: 0.999953] [G loss: 1.000101]\n",
      "epoch:34 step:160570[D loss: 0.999928] [G loss: 1.000161]\n",
      "epoch:34 step:160575[D loss: 0.999984] [G loss: 1.000130]\n",
      "epoch:34 step:160580[D loss: 1.000062] [G loss: 1.000085]\n",
      "epoch:34 step:160585[D loss: 0.999934] [G loss: 1.000136]\n",
      "epoch:34 step:160590[D loss: 0.999885] [G loss: 1.000237]\n",
      "epoch:34 step:160595[D loss: 0.999950] [G loss: 1.000123]\n",
      "epoch:34 step:160600[D loss: 0.999971] [G loss: 1.000092]\n",
      "##############\n",
      "[2.61132224 2.15566473 2.36422417 3.4759571  1.58133048 7.66312932\n",
      " 2.41640046 3.97286752 4.06806051 4.91030229]\n",
      "##########\n",
      "epoch:34 step:160605[D loss: 0.999966] [G loss: 1.000151]\n",
      "epoch:34 step:160610[D loss: 1.000057] [G loss: 1.000006]\n",
      "epoch:34 step:160615[D loss: 0.999949] [G loss: 1.000111]\n",
      "epoch:34 step:160620[D loss: 1.000051] [G loss: 1.000047]\n",
      "epoch:34 step:160625[D loss: 0.999996] [G loss: 1.000083]\n",
      "epoch:34 step:160630[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:34 step:160635[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:34 step:160640[D loss: 0.999967] [G loss: 1.000131]\n",
      "epoch:34 step:160645[D loss: 0.999988] [G loss: 1.000096]\n",
      "epoch:34 step:160650[D loss: 1.000043] [G loss: 0.999998]\n",
      "epoch:34 step:160655[D loss: 1.000088] [G loss: 0.999979]\n",
      "epoch:34 step:160660[D loss: 0.999886] [G loss: 1.000187]\n",
      "epoch:34 step:160665[D loss: 1.000016] [G loss: 1.000065]\n",
      "epoch:34 step:160670[D loss: 0.999955] [G loss: 1.000149]\n",
      "epoch:34 step:160675[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:34 step:160680[D loss: 1.000062] [G loss: 0.999998]\n",
      "epoch:34 step:160685[D loss: 0.999957] [G loss: 1.000189]\n",
      "epoch:34 step:160690[D loss: 0.999865] [G loss: 1.000248]\n",
      "epoch:34 step:160695[D loss: 0.999956] [G loss: 1.000059]\n",
      "epoch:34 step:160700[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:34 step:160705[D loss: 0.999878] [G loss: 1.000159]\n",
      "epoch:34 step:160710[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:34 step:160715[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:34 step:160720[D loss: 0.999960] [G loss: 1.000100]\n",
      "epoch:34 step:160725[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:34 step:160730[D loss: 0.999977] [G loss: 1.000102]\n",
      "epoch:34 step:160735[D loss: 0.999979] [G loss: 1.000131]\n",
      "epoch:34 step:160740[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:34 step:160745[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:34 step:160750[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:34 step:160755[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:34 step:160760[D loss: 0.999955] [G loss: 1.000048]\n",
      "epoch:34 step:160765[D loss: 1.000036] [G loss: 1.000114]\n",
      "epoch:34 step:160770[D loss: 0.999862] [G loss: 1.000171]\n",
      "epoch:34 step:160775[D loss: 1.000012] [G loss: 1.000067]\n",
      "epoch:34 step:160780[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:34 step:160785[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:34 step:160790[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:34 step:160795[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:34 step:160800[D loss: 0.999970] [G loss: 1.000070]\n",
      "##############\n",
      "[2.53478801 2.20936793 2.32289295 3.73998252 1.57589334 7.68324363\n",
      " 2.54076285 3.91206115 4.091773   8.14868929]\n",
      "##########\n",
      "epoch:34 step:160805[D loss: 1.000039] [G loss: 0.999964]\n",
      "epoch:34 step:160810[D loss: 0.999911] [G loss: 1.000053]\n",
      "epoch:34 step:160815[D loss: 0.999971] [G loss: 1.000053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:160820[D loss: 0.999985] [G loss: 1.000105]\n",
      "epoch:34 step:160825[D loss: 1.000089] [G loss: 1.000096]\n",
      "epoch:34 step:160830[D loss: 0.999925] [G loss: 1.000131]\n",
      "epoch:34 step:160835[D loss: 1.000053] [G loss: 1.000008]\n",
      "epoch:34 step:160840[D loss: 1.000004] [G loss: 1.000099]\n",
      "epoch:34 step:160845[D loss: 1.000154] [G loss: 0.999911]\n",
      "epoch:34 step:160850[D loss: 0.999865] [G loss: 1.000214]\n",
      "epoch:34 step:160855[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:34 step:160860[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:34 step:160865[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:34 step:160870[D loss: 1.000044] [G loss: 1.000156]\n",
      "epoch:34 step:160875[D loss: 1.000031] [G loss: 0.999960]\n",
      "epoch:34 step:160880[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:34 step:160885[D loss: 1.000039] [G loss: 0.999972]\n",
      "epoch:34 step:160890[D loss: 1.000028] [G loss: 0.999884]\n",
      "epoch:34 step:160895[D loss: 1.000114] [G loss: 1.000066]\n",
      "epoch:34 step:160900[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:34 step:160905[D loss: 1.000042] [G loss: 1.000001]\n",
      "epoch:34 step:160910[D loss: 0.999878] [G loss: 1.000074]\n",
      "epoch:34 step:160915[D loss: 0.999954] [G loss: 1.000060]\n",
      "epoch:34 step:160920[D loss: 0.999994] [G loss: 1.000010]\n",
      "epoch:34 step:160925[D loss: 1.000050] [G loss: 0.999959]\n",
      "epoch:34 step:160930[D loss: 0.999906] [G loss: 1.000031]\n",
      "epoch:34 step:160935[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:34 step:160940[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:34 step:160945[D loss: 0.999978] [G loss: 1.000010]\n",
      "epoch:34 step:160950[D loss: 0.999936] [G loss: 1.000089]\n",
      "epoch:34 step:160955[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:34 step:160960[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:34 step:160965[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:34 step:160970[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:34 step:160975[D loss: 0.999996] [G loss: 0.999968]\n",
      "epoch:34 step:160980[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:34 step:160985[D loss: 0.999942] [G loss: 1.000117]\n",
      "epoch:34 step:160990[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:34 step:160995[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:34 step:161000[D loss: 0.999965] [G loss: 1.000068]\n",
      "##############\n",
      "[2.56208484 2.26402945 2.24962139 3.53097466 1.55042833 7.52942222\n",
      " 2.50398021 3.94224978 4.09479148 5.82639553]\n",
      "##########\n",
      "epoch:34 step:161005[D loss: 0.999946] [G loss: 1.000086]\n",
      "epoch:34 step:161010[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:34 step:161015[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:34 step:161020[D loss: 1.000107] [G loss: 0.999931]\n",
      "epoch:34 step:161025[D loss: 0.999919] [G loss: 1.000101]\n",
      "epoch:34 step:161030[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:34 step:161035[D loss: 1.000000] [G loss: 1.000095]\n",
      "epoch:34 step:161040[D loss: 0.999925] [G loss: 1.000146]\n",
      "epoch:34 step:161045[D loss: 1.000091] [G loss: 0.999922]\n",
      "epoch:34 step:161050[D loss: 0.999954] [G loss: 1.000111]\n",
      "epoch:34 step:161055[D loss: 0.999981] [G loss: 1.000105]\n",
      "epoch:34 step:161060[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:34 step:161065[D loss: 1.000031] [G loss: 1.000026]\n",
      "epoch:34 step:161070[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:34 step:161075[D loss: 0.999920] [G loss: 1.000094]\n",
      "epoch:34 step:161080[D loss: 1.000107] [G loss: 1.000010]\n",
      "epoch:34 step:161085[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:34 step:161090[D loss: 1.000096] [G loss: 1.000076]\n",
      "epoch:34 step:161095[D loss: 0.999759] [G loss: 1.000281]\n",
      "epoch:34 step:161100[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:34 step:161105[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:34 step:161110[D loss: 1.000087] [G loss: 0.999943]\n",
      "epoch:34 step:161115[D loss: 1.000017] [G loss: 1.000036]\n",
      "epoch:34 step:161120[D loss: 1.000084] [G loss: 0.999915]\n",
      "epoch:34 step:161125[D loss: 1.000051] [G loss: 1.000082]\n",
      "epoch:34 step:161130[D loss: 0.999982] [G loss: 1.000010]\n",
      "epoch:34 step:161135[D loss: 0.999927] [G loss: 1.000342]\n",
      "epoch:34 step:161140[D loss: 0.999909] [G loss: 1.000251]\n",
      "epoch:34 step:161145[D loss: 0.999953] [G loss: 1.000142]\n",
      "epoch:34 step:161150[D loss: 0.999918] [G loss: 1.000170]\n",
      "epoch:34 step:161155[D loss: 0.999881] [G loss: 1.000179]\n",
      "epoch:34 step:161160[D loss: 0.999966] [G loss: 1.000322]\n",
      "epoch:34 step:161165[D loss: 0.999899] [G loss: 1.000168]\n",
      "epoch:34 step:161170[D loss: 0.999990] [G loss: 0.999958]\n",
      "epoch:34 step:161175[D loss: 0.999973] [G loss: 1.000002]\n",
      "epoch:34 step:161180[D loss: 1.000306] [G loss: 0.999798]\n",
      "epoch:34 step:161185[D loss: 0.999926] [G loss: 1.000174]\n",
      "epoch:34 step:161190[D loss: 0.999990] [G loss: 0.999852]\n",
      "epoch:34 step:161195[D loss: 0.999948] [G loss: 1.000020]\n",
      "epoch:34 step:161200[D loss: 0.999831] [G loss: 1.000255]\n",
      "##############\n",
      "[2.53020548 2.29036729 2.33851595 3.56100188 1.57208431 7.32328195\n",
      " 2.56421259 3.78135341 4.07156766 5.02665755]\n",
      "##########\n",
      "epoch:34 step:161205[D loss: 0.999898] [G loss: 1.000112]\n",
      "epoch:34 step:161210[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:34 step:161215[D loss: 1.000020] [G loss: 1.000058]\n",
      "epoch:34 step:161220[D loss: 0.999958] [G loss: 1.000013]\n",
      "epoch:34 step:161225[D loss: 1.000028] [G loss: 1.000019]\n",
      "epoch:34 step:161230[D loss: 1.000001] [G loss: 0.999980]\n",
      "epoch:34 step:161235[D loss: 0.999936] [G loss: 1.000061]\n",
      "epoch:34 step:161240[D loss: 1.000014] [G loss: 1.000121]\n",
      "epoch:34 step:161245[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:34 step:161250[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:34 step:161255[D loss: 0.999980] [G loss: 1.000023]\n",
      "epoch:34 step:161260[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:34 step:161265[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:34 step:161270[D loss: 1.000004] [G loss: 1.000059]\n",
      "epoch:34 step:161275[D loss: 0.999973] [G loss: 1.000022]\n",
      "epoch:34 step:161280[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:34 step:161285[D loss: 1.000027] [G loss: 0.999887]\n",
      "epoch:34 step:161290[D loss: 1.000002] [G loss: 0.999955]\n",
      "epoch:34 step:161295[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:34 step:161300[D loss: 1.000008] [G loss: 0.999994]\n",
      "epoch:34 step:161305[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:34 step:161310[D loss: 0.999935] [G loss: 1.000118]\n",
      "epoch:34 step:161315[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:34 step:161320[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:34 step:161325[D loss: 1.000133] [G loss: 0.999882]\n",
      "epoch:34 step:161330[D loss: 0.999905] [G loss: 1.000089]\n",
      "epoch:34 step:161335[D loss: 1.000027] [G loss: 0.999981]\n",
      "epoch:34 step:161340[D loss: 1.000089] [G loss: 1.000178]\n",
      "epoch:34 step:161345[D loss: 0.999956] [G loss: 1.000046]\n",
      "epoch:34 step:161350[D loss: 0.999938] [G loss: 1.000094]\n",
      "epoch:34 step:161355[D loss: 1.000027] [G loss: 0.999925]\n",
      "epoch:34 step:161360[D loss: 1.000053] [G loss: 0.999923]\n",
      "epoch:34 step:161365[D loss: 0.999933] [G loss: 1.000055]\n",
      "epoch:34 step:161370[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:34 step:161375[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:34 step:161380[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:34 step:161385[D loss: 0.999957] [G loss: 1.000052]\n",
      "epoch:34 step:161390[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:34 step:161395[D loss: 1.000121] [G loss: 0.999934]\n",
      "epoch:34 step:161400[D loss: 0.999966] [G loss: 1.000145]\n",
      "##############\n",
      "[2.48203862 2.32603612 2.20465032 3.923187   1.55212669 7.71018803\n",
      " 2.32968664 3.85941304 4.00713236 5.96523477]\n",
      "##########\n",
      "epoch:34 step:161405[D loss: 0.999929] [G loss: 1.000135]\n",
      "epoch:34 step:161410[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:34 step:161415[D loss: 1.000025] [G loss: 1.000006]\n",
      "epoch:34 step:161420[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:34 step:161425[D loss: 0.999992] [G loss: 1.000004]\n",
      "epoch:34 step:161430[D loss: 1.000090] [G loss: 0.999921]\n",
      "epoch:34 step:161435[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:34 step:161440[D loss: 1.000094] [G loss: 0.999861]\n",
      "epoch:34 step:161445[D loss: 1.000010] [G loss: 0.999941]\n",
      "epoch:34 step:161450[D loss: 0.999939] [G loss: 1.000299]\n",
      "epoch:34 step:161455[D loss: 0.999748] [G loss: 1.000371]\n",
      "epoch:34 step:161460[D loss: 0.999944] [G loss: 1.000259]\n",
      "epoch:34 step:161465[D loss: 1.000057] [G loss: 1.000080]\n",
      "epoch:34 step:161470[D loss: 0.999940] [G loss: 1.000039]\n",
      "epoch:34 step:161475[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:34 step:161480[D loss: 1.000001] [G loss: 1.000035]\n",
      "epoch:34 step:161485[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:34 step:161490[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:34 step:161495[D loss: 0.999991] [G loss: 0.999995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:161500[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:34 step:161505[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:34 step:161510[D loss: 0.999962] [G loss: 1.000134]\n",
      "epoch:34 step:161515[D loss: 0.999905] [G loss: 1.000105]\n",
      "epoch:34 step:161520[D loss: 1.000154] [G loss: 0.999973]\n",
      "epoch:34 step:161525[D loss: 1.000004] [G loss: 1.000205]\n",
      "epoch:34 step:161530[D loss: 1.000065] [G loss: 1.000132]\n",
      "epoch:34 step:161535[D loss: 0.999900] [G loss: 1.000203]\n",
      "epoch:34 step:161540[D loss: 0.999992] [G loss: 1.000221]\n",
      "epoch:34 step:161545[D loss: 0.999894] [G loss: 1.000117]\n",
      "epoch:34 step:161550[D loss: 0.999999] [G loss: 1.000147]\n",
      "epoch:34 step:161555[D loss: 0.999984] [G loss: 1.000117]\n",
      "epoch:34 step:161560[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:34 step:161565[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:34 step:161570[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:34 step:161575[D loss: 1.000070] [G loss: 0.999859]\n",
      "epoch:34 step:161580[D loss: 1.000116] [G loss: 0.999954]\n",
      "epoch:34 step:161585[D loss: 1.000651] [G loss: 0.999350]\n",
      "epoch:34 step:161590[D loss: 0.999822] [G loss: 1.000101]\n",
      "epoch:34 step:161595[D loss: 0.999872] [G loss: 1.000135]\n",
      "epoch:34 step:161600[D loss: 0.999779] [G loss: 1.000181]\n",
      "##############\n",
      "[2.51193607 2.26440775 2.43441909 3.86486101 1.54646725 7.28673602\n",
      " 2.38856309 3.89722346 4.02172331 4.65010073]\n",
      "##########\n",
      "epoch:34 step:161605[D loss: 0.999901] [G loss: 1.000196]\n",
      "epoch:34 step:161610[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:34 step:161615[D loss: 0.999942] [G loss: 1.000024]\n",
      "epoch:34 step:161620[D loss: 0.999989] [G loss: 1.000109]\n",
      "epoch:34 step:161625[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:34 step:161630[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:34 step:161635[D loss: 1.000141] [G loss: 0.999989]\n",
      "epoch:34 step:161640[D loss: 0.999908] [G loss: 1.000205]\n",
      "epoch:34 step:161645[D loss: 0.999943] [G loss: 1.000182]\n",
      "epoch:34 step:161650[D loss: 0.999923] [G loss: 1.000275]\n",
      "epoch:34 step:161655[D loss: 0.999910] [G loss: 1.000313]\n",
      "epoch:34 step:161660[D loss: 0.999940] [G loss: 1.000107]\n",
      "epoch:34 step:161665[D loss: 0.999957] [G loss: 1.000108]\n",
      "epoch:34 step:161670[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:34 step:161675[D loss: 0.999992] [G loss: 0.999989]\n",
      "epoch:34 step:161680[D loss: 0.999984] [G loss: 0.999943]\n",
      "epoch:34 step:161685[D loss: 1.000029] [G loss: 1.000008]\n",
      "epoch:34 step:161690[D loss: 0.999995] [G loss: 0.999938]\n",
      "epoch:34 step:161695[D loss: 1.000020] [G loss: 0.999890]\n",
      "epoch:34 step:161700[D loss: 0.999916] [G loss: 1.000048]\n",
      "epoch:34 step:161705[D loss: 1.000042] [G loss: 1.000044]\n",
      "epoch:34 step:161710[D loss: 0.999983] [G loss: 0.999961]\n",
      "epoch:34 step:161715[D loss: 0.999918] [G loss: 1.000067]\n",
      "epoch:34 step:161720[D loss: 1.000004] [G loss: 1.000104]\n",
      "epoch:34 step:161725[D loss: 0.999949] [G loss: 1.000103]\n",
      "epoch:34 step:161730[D loss: 1.000033] [G loss: 1.000092]\n",
      "epoch:34 step:161735[D loss: 1.000083] [G loss: 0.999912]\n",
      "epoch:34 step:161740[D loss: 1.000110] [G loss: 0.999855]\n",
      "epoch:34 step:161745[D loss: 1.000058] [G loss: 0.999982]\n",
      "epoch:34 step:161750[D loss: 1.000065] [G loss: 0.999970]\n",
      "epoch:34 step:161755[D loss: 1.000122] [G loss: 1.000218]\n",
      "epoch:34 step:161760[D loss: 0.999943] [G loss: 1.000295]\n",
      "epoch:34 step:161765[D loss: 0.999977] [G loss: 1.000146]\n",
      "epoch:34 step:161770[D loss: 1.000172] [G loss: 1.000064]\n",
      "epoch:34 step:161775[D loss: 0.999881] [G loss: 1.000262]\n",
      "epoch:34 step:161780[D loss: 0.999937] [G loss: 1.000085]\n",
      "epoch:34 step:161785[D loss: 1.000095] [G loss: 0.999809]\n",
      "epoch:34 step:161790[D loss: 1.000239] [G loss: 0.999708]\n",
      "epoch:34 step:161795[D loss: 1.000041] [G loss: 0.999735]\n",
      "epoch:34 step:161800[D loss: 1.000015] [G loss: 0.999819]\n",
      "##############\n",
      "[2.5313261  2.19575064 2.13233074 3.77848396 1.55577146 7.90179347\n",
      " 2.53026323 3.91953731 4.01080014 4.78763714]\n",
      "##########\n",
      "epoch:34 step:161805[D loss: 0.999866] [G loss: 1.000038]\n",
      "epoch:34 step:161810[D loss: 1.000038] [G loss: 0.999923]\n",
      "epoch:34 step:161815[D loss: 1.000084] [G loss: 0.999811]\n",
      "epoch:34 step:161820[D loss: 0.999897] [G loss: 1.000067]\n",
      "epoch:34 step:161825[D loss: 0.999999] [G loss: 1.000074]\n",
      "epoch:34 step:161830[D loss: 1.000029] [G loss: 1.000238]\n",
      "epoch:34 step:161835[D loss: 0.999823] [G loss: 1.000388]\n",
      "epoch:34 step:161840[D loss: 1.000126] [G loss: 1.000379]\n",
      "epoch:34 step:161845[D loss: 0.999880] [G loss: 1.000216]\n",
      "epoch:34 step:161850[D loss: 0.999900] [G loss: 1.000156]\n",
      "epoch:34 step:161855[D loss: 0.999977] [G loss: 1.000110]\n",
      "epoch:34 step:161860[D loss: 0.999923] [G loss: 1.000065]\n",
      "epoch:34 step:161865[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:34 step:161870[D loss: 0.999952] [G loss: 1.000064]\n",
      "epoch:34 step:161875[D loss: 1.000091] [G loss: 0.999975]\n",
      "epoch:34 step:161880[D loss: 1.000091] [G loss: 0.999795]\n",
      "epoch:34 step:161885[D loss: 1.000104] [G loss: 0.999820]\n",
      "epoch:34 step:161890[D loss: 0.999931] [G loss: 1.000173]\n",
      "epoch:34 step:161895[D loss: 0.999924] [G loss: 1.000097]\n",
      "epoch:34 step:161900[D loss: 0.999892] [G loss: 1.000151]\n",
      "epoch:34 step:161905[D loss: 0.999859] [G loss: 1.000274]\n",
      "epoch:34 step:161910[D loss: 1.000092] [G loss: 1.000088]\n",
      "epoch:34 step:161915[D loss: 0.999908] [G loss: 1.000154]\n",
      "epoch:34 step:161920[D loss: 0.999908] [G loss: 1.000083]\n",
      "epoch:34 step:161925[D loss: 0.999962] [G loss: 1.000044]\n",
      "epoch:34 step:161930[D loss: 0.999974] [G loss: 1.000024]\n",
      "epoch:34 step:161935[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:34 step:161940[D loss: 0.999999] [G loss: 1.000078]\n",
      "epoch:34 step:161945[D loss: 1.000031] [G loss: 0.999920]\n",
      "epoch:34 step:161950[D loss: 0.999938] [G loss: 1.000077]\n",
      "epoch:34 step:161955[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:34 step:161960[D loss: 1.000076] [G loss: 0.999924]\n",
      "epoch:34 step:161965[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:34 step:161970[D loss: 0.999998] [G loss: 1.000109]\n",
      "epoch:34 step:161975[D loss: 1.000012] [G loss: 1.000033]\n",
      "epoch:34 step:161980[D loss: 0.999964] [G loss: 1.000111]\n",
      "epoch:34 step:161985[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:34 step:161990[D loss: 0.999988] [G loss: 0.999996]\n",
      "epoch:34 step:161995[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:34 step:162000[D loss: 1.000054] [G loss: 0.999962]\n",
      "##############\n",
      "[2.59554534 2.27333899 2.11038884 3.58097118 1.62375159 6.93328714\n",
      " 2.45463788 3.97495037 4.0022152  5.14953366]\n",
      "##########\n",
      "epoch:34 step:162005[D loss: 0.999969] [G loss: 1.000229]\n",
      "epoch:34 step:162010[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:34 step:162015[D loss: 1.000083] [G loss: 0.999934]\n",
      "epoch:34 step:162020[D loss: 1.000061] [G loss: 0.999936]\n",
      "epoch:34 step:162025[D loss: 0.999927] [G loss: 1.000016]\n",
      "epoch:34 step:162030[D loss: 0.999870] [G loss: 1.000161]\n",
      "epoch:34 step:162035[D loss: 1.000008] [G loss: 0.999989]\n",
      "epoch:34 step:162040[D loss: 1.000014] [G loss: 1.000027]\n",
      "epoch:34 step:162045[D loss: 0.999957] [G loss: 1.000051]\n",
      "epoch:34 step:162050[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:34 step:162055[D loss: 1.000138] [G loss: 0.999860]\n",
      "epoch:34 step:162060[D loss: 0.999923] [G loss: 1.000023]\n",
      "epoch:34 step:162065[D loss: 1.000044] [G loss: 0.999937]\n",
      "epoch:34 step:162070[D loss: 0.999977] [G loss: 1.000012]\n",
      "epoch:34 step:162075[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:34 step:162080[D loss: 0.999933] [G loss: 1.000099]\n",
      "epoch:34 step:162085[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:34 step:162090[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:34 step:162095[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:34 step:162100[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:34 step:162105[D loss: 0.999945] [G loss: 1.000117]\n",
      "epoch:34 step:162110[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:34 step:162115[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:34 step:162120[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:34 step:162125[D loss: 0.999953] [G loss: 1.000064]\n",
      "epoch:34 step:162130[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:34 step:162135[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:34 step:162140[D loss: 0.999992] [G loss: 1.000010]\n",
      "epoch:34 step:162145[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:34 step:162150[D loss: 1.000033] [G loss: 1.000020]\n",
      "epoch:34 step:162155[D loss: 1.000031] [G loss: 1.000034]\n",
      "epoch:34 step:162160[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:34 step:162165[D loss: 1.000049] [G loss: 1.000039]\n",
      "epoch:34 step:162170[D loss: 0.999949] [G loss: 1.000097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:162175[D loss: 0.999961] [G loss: 1.000038]\n",
      "epoch:34 step:162180[D loss: 0.999975] [G loss: 1.000120]\n",
      "epoch:34 step:162185[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:34 step:162190[D loss: 1.000034] [G loss: 1.000120]\n",
      "epoch:34 step:162195[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:34 step:162200[D loss: 0.999994] [G loss: 0.999999]\n",
      "##############\n",
      "[2.51863823 2.22043124 2.17315262 3.752516   1.53717922 7.78828877\n",
      " 2.32166393 3.72380778 4.03881998 5.12501697]\n",
      "##########\n",
      "epoch:34 step:162205[D loss: 1.000054] [G loss: 0.999879]\n",
      "epoch:34 step:162210[D loss: 0.999947] [G loss: 1.000018]\n",
      "epoch:34 step:162215[D loss: 0.999985] [G loss: 1.000020]\n",
      "epoch:34 step:162220[D loss: 1.000047] [G loss: 0.999961]\n",
      "epoch:34 step:162225[D loss: 0.999875] [G loss: 1.000121]\n",
      "epoch:34 step:162230[D loss: 1.000034] [G loss: 1.000063]\n",
      "epoch:34 step:162235[D loss: 1.000066] [G loss: 1.000052]\n",
      "epoch:34 step:162240[D loss: 0.999983] [G loss: 1.000008]\n",
      "epoch:34 step:162245[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:34 step:162250[D loss: 1.000096] [G loss: 0.999890]\n",
      "epoch:34 step:162255[D loss: 1.000031] [G loss: 1.000016]\n",
      "epoch:34 step:162260[D loss: 1.000056] [G loss: 0.999928]\n",
      "epoch:34 step:162265[D loss: 1.000207] [G loss: 0.999967]\n",
      "epoch:34 step:162270[D loss: 0.999903] [G loss: 1.000063]\n",
      "epoch:34 step:162275[D loss: 1.000054] [G loss: 0.999951]\n",
      "epoch:34 step:162280[D loss: 0.999981] [G loss: 1.000173]\n",
      "epoch:34 step:162285[D loss: 0.999950] [G loss: 1.000099]\n",
      "epoch:34 step:162290[D loss: 0.999944] [G loss: 1.000121]\n",
      "epoch:34 step:162295[D loss: 1.000108] [G loss: 0.999868]\n",
      "epoch:34 step:162300[D loss: 0.999982] [G loss: 1.000095]\n",
      "epoch:34 step:162305[D loss: 0.999883] [G loss: 1.000141]\n",
      "epoch:34 step:162310[D loss: 1.000046] [G loss: 1.000033]\n",
      "epoch:34 step:162315[D loss: 0.999985] [G loss: 0.999901]\n",
      "epoch:34 step:162320[D loss: 0.999898] [G loss: 1.000088]\n",
      "epoch:34 step:162325[D loss: 0.999979] [G loss: 1.000027]\n",
      "epoch:34 step:162330[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:34 step:162335[D loss: 1.000126] [G loss: 0.999858]\n",
      "epoch:34 step:162340[D loss: 0.999930] [G loss: 1.000006]\n",
      "epoch:34 step:162345[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:34 step:162350[D loss: 0.999962] [G loss: 1.000133]\n",
      "epoch:34 step:162355[D loss: 0.999935] [G loss: 1.000048]\n",
      "epoch:34 step:162360[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:34 step:162365[D loss: 1.000029] [G loss: 0.999978]\n",
      "epoch:34 step:162370[D loss: 0.999933] [G loss: 1.000040]\n",
      "epoch:34 step:162375[D loss: 1.000096] [G loss: 0.999988]\n",
      "epoch:34 step:162380[D loss: 0.999878] [G loss: 1.000134]\n",
      "epoch:34 step:162385[D loss: 0.999957] [G loss: 1.000005]\n",
      "epoch:34 step:162390[D loss: 1.000047] [G loss: 1.000072]\n",
      "epoch:34 step:162395[D loss: 0.999967] [G loss: 1.000038]\n",
      "epoch:34 step:162400[D loss: 0.999994] [G loss: 1.000090]\n",
      "##############\n",
      "[2.54997613 2.25735059 2.2267262  3.57080773 1.58448172 6.57159016\n",
      " 2.41706988 3.68583145 4.024451   5.81455733]\n",
      "##########\n",
      "epoch:34 step:162405[D loss: 0.999952] [G loss: 1.000103]\n",
      "epoch:34 step:162410[D loss: 0.999977] [G loss: 1.000104]\n",
      "epoch:34 step:162415[D loss: 1.000000] [G loss: 1.000115]\n",
      "epoch:34 step:162420[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:34 step:162425[D loss: 1.000017] [G loss: 1.000010]\n",
      "epoch:34 step:162430[D loss: 1.000003] [G loss: 0.999986]\n",
      "epoch:34 step:162435[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:34 step:162440[D loss: 1.000039] [G loss: 0.999983]\n",
      "epoch:34 step:162445[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:34 step:162450[D loss: 1.000070] [G loss: 1.000038]\n",
      "epoch:34 step:162455[D loss: 0.999896] [G loss: 1.000167]\n",
      "epoch:34 step:162460[D loss: 0.999998] [G loss: 1.000041]\n",
      "epoch:34 step:162465[D loss: 1.000025] [G loss: 0.999965]\n",
      "epoch:34 step:162470[D loss: 0.999954] [G loss: 1.000049]\n",
      "epoch:34 step:162475[D loss: 1.000247] [G loss: 0.999673]\n",
      "epoch:34 step:162480[D loss: 0.999959] [G loss: 0.999934]\n",
      "epoch:34 step:162485[D loss: 0.999865] [G loss: 1.000141]\n",
      "epoch:34 step:162490[D loss: 1.000120] [G loss: 1.000080]\n",
      "epoch:34 step:162495[D loss: 1.000003] [G loss: 1.000121]\n",
      "epoch:34 step:162500[D loss: 0.999891] [G loss: 1.000233]\n",
      "epoch:34 step:162505[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:34 step:162510[D loss: 1.000098] [G loss: 0.999877]\n",
      "epoch:34 step:162515[D loss: 1.000154] [G loss: 0.999699]\n",
      "epoch:34 step:162520[D loss: 1.000028] [G loss: 1.000113]\n",
      "epoch:34 step:162525[D loss: 1.000039] [G loss: 0.999856]\n",
      "epoch:34 step:162530[D loss: 1.000007] [G loss: 0.999961]\n",
      "epoch:34 step:162535[D loss: 0.999917] [G loss: 1.000246]\n",
      "epoch:34 step:162540[D loss: 0.999925] [G loss: 1.000183]\n",
      "epoch:34 step:162545[D loss: 1.000017] [G loss: 1.000312]\n",
      "epoch:34 step:162550[D loss: 0.999861] [G loss: 1.000347]\n",
      "epoch:34 step:162555[D loss: 1.000052] [G loss: 1.000137]\n",
      "epoch:34 step:162560[D loss: 0.999929] [G loss: 1.000180]\n",
      "epoch:34 step:162565[D loss: 0.999892] [G loss: 1.000248]\n",
      "epoch:34 step:162570[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:34 step:162575[D loss: 1.000026] [G loss: 0.999943]\n",
      "epoch:34 step:162580[D loss: 0.999926] [G loss: 1.000040]\n",
      "epoch:34 step:162585[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:34 step:162590[D loss: 0.999982] [G loss: 1.000021]\n",
      "epoch:34 step:162595[D loss: 0.999969] [G loss: 1.000015]\n",
      "epoch:34 step:162600[D loss: 0.999989] [G loss: 1.000058]\n",
      "##############\n",
      "[2.60561472 2.26938102 2.28694355 3.55154569 1.63583709 7.33971031\n",
      " 2.54808715 3.78857508 4.0355359  4.95667141]\n",
      "##########\n",
      "epoch:34 step:162605[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:34 step:162610[D loss: 1.000009] [G loss: 0.999982]\n",
      "epoch:34 step:162615[D loss: 1.000046] [G loss: 1.000003]\n",
      "epoch:34 step:162620[D loss: 1.000057] [G loss: 1.000007]\n",
      "epoch:34 step:162625[D loss: 0.999911] [G loss: 1.000103]\n",
      "epoch:34 step:162630[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:34 step:162635[D loss: 0.999937] [G loss: 1.000095]\n",
      "epoch:34 step:162640[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:34 step:162645[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:34 step:162650[D loss: 0.999996] [G loss: 1.000009]\n",
      "epoch:34 step:162655[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:34 step:162660[D loss: 0.999956] [G loss: 1.000121]\n",
      "epoch:34 step:162665[D loss: 1.000000] [G loss: 1.000090]\n",
      "epoch:34 step:162670[D loss: 0.999943] [G loss: 1.000046]\n",
      "epoch:34 step:162675[D loss: 0.999946] [G loss: 1.000122]\n",
      "epoch:34 step:162680[D loss: 1.000010] [G loss: 1.000065]\n",
      "epoch:34 step:162685[D loss: 1.000048] [G loss: 0.999995]\n",
      "epoch:34 step:162690[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:34 step:162695[D loss: 0.999965] [G loss: 1.000039]\n",
      "epoch:34 step:162700[D loss: 1.000021] [G loss: 1.000079]\n",
      "epoch:34 step:162705[D loss: 0.999927] [G loss: 1.000112]\n",
      "epoch:34 step:162710[D loss: 1.000005] [G loss: 0.999959]\n",
      "epoch:34 step:162715[D loss: 1.000028] [G loss: 1.000019]\n",
      "epoch:34 step:162720[D loss: 0.999976] [G loss: 1.000029]\n",
      "epoch:34 step:162725[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:34 step:162730[D loss: 1.000034] [G loss: 1.000038]\n",
      "epoch:34 step:162735[D loss: 1.000038] [G loss: 0.999930]\n",
      "epoch:34 step:162740[D loss: 0.999936] [G loss: 1.000078]\n",
      "epoch:34 step:162745[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:34 step:162750[D loss: 0.999991] [G loss: 1.000108]\n",
      "epoch:34 step:162755[D loss: 0.999975] [G loss: 1.000170]\n",
      "epoch:34 step:162760[D loss: 0.999965] [G loss: 1.000124]\n",
      "epoch:34 step:162765[D loss: 1.000009] [G loss: 1.000041]\n",
      "epoch:34 step:162770[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:34 step:162775[D loss: 0.999938] [G loss: 1.000054]\n",
      "epoch:34 step:162780[D loss: 0.999963] [G loss: 1.000045]\n",
      "epoch:34 step:162785[D loss: 1.000018] [G loss: 1.000032]\n",
      "epoch:34 step:162790[D loss: 0.999984] [G loss: 1.000028]\n",
      "epoch:34 step:162795[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:34 step:162800[D loss: 0.999976] [G loss: 1.000056]\n",
      "##############\n",
      "[2.6144241  2.23616035 2.22102606 3.76333774 1.53298239 7.38805229\n",
      " 2.37225939 3.87995258 4.00800322 5.48768618]\n",
      "##########\n",
      "epoch:34 step:162805[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:34 step:162810[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:34 step:162815[D loss: 0.999939] [G loss: 1.000138]\n",
      "epoch:34 step:162820[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:34 step:162825[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:34 step:162830[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:34 step:162835[D loss: 1.000066] [G loss: 1.000020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:162840[D loss: 0.999956] [G loss: 1.000202]\n",
      "epoch:34 step:162845[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:34 step:162850[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:34 step:162855[D loss: 0.999963] [G loss: 1.000104]\n",
      "epoch:34 step:162860[D loss: 1.000074] [G loss: 1.000081]\n",
      "epoch:34 step:162865[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:34 step:162870[D loss: 1.000016] [G loss: 0.999959]\n",
      "epoch:34 step:162875[D loss: 0.999933] [G loss: 1.000075]\n",
      "epoch:34 step:162880[D loss: 0.999992] [G loss: 1.000087]\n",
      "epoch:34 step:162885[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:34 step:162890[D loss: 0.999939] [G loss: 1.000089]\n",
      "epoch:34 step:162895[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:34 step:162900[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:34 step:162905[D loss: 1.000010] [G loss: 1.000064]\n",
      "epoch:34 step:162910[D loss: 0.999970] [G loss: 1.000151]\n",
      "epoch:34 step:162915[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:34 step:162920[D loss: 1.000084] [G loss: 0.999944]\n",
      "epoch:34 step:162925[D loss: 0.999931] [G loss: 1.000059]\n",
      "epoch:34 step:162930[D loss: 1.000016] [G loss: 1.000003]\n",
      "epoch:34 step:162935[D loss: 0.999920] [G loss: 1.000091]\n",
      "epoch:34 step:162940[D loss: 1.000017] [G loss: 1.000039]\n",
      "epoch:34 step:162945[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:34 step:162950[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:34 step:162955[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:34 step:162960[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:34 step:162965[D loss: 0.999998] [G loss: 1.000024]\n",
      "epoch:34 step:162970[D loss: 1.000029] [G loss: 1.000030]\n",
      "epoch:34 step:162975[D loss: 1.000063] [G loss: 1.000029]\n",
      "epoch:34 step:162980[D loss: 0.999972] [G loss: 0.999942]\n",
      "epoch:34 step:162985[D loss: 1.000043] [G loss: 1.000169]\n",
      "epoch:34 step:162990[D loss: 1.000068] [G loss: 1.000018]\n",
      "epoch:34 step:162995[D loss: 0.999921] [G loss: 1.000097]\n",
      "epoch:34 step:163000[D loss: 1.000159] [G loss: 0.999770]\n",
      "##############\n",
      "[2.56649742 2.23943313 2.18990903 3.56539511 1.58360228 6.95747566\n",
      " 2.46507151 3.89164573 4.01343019 5.2425244 ]\n",
      "##########\n",
      "epoch:34 step:163005[D loss: 0.999901] [G loss: 1.000088]\n",
      "epoch:34 step:163010[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:34 step:163015[D loss: 0.999974] [G loss: 1.000017]\n",
      "epoch:34 step:163020[D loss: 0.999975] [G loss: 1.000022]\n",
      "epoch:34 step:163025[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:34 step:163030[D loss: 1.000021] [G loss: 1.000037]\n",
      "epoch:34 step:163035[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:34 step:163040[D loss: 1.000032] [G loss: 0.999900]\n",
      "epoch:34 step:163045[D loss: 1.000041] [G loss: 0.999888]\n",
      "epoch:34 step:163050[D loss: 1.000000] [G loss: 0.999948]\n",
      "epoch:34 step:163055[D loss: 1.000015] [G loss: 1.000010]\n",
      "epoch:34 step:163060[D loss: 1.000119] [G loss: 0.999992]\n",
      "epoch:34 step:163065[D loss: 0.999888] [G loss: 1.000218]\n",
      "epoch:34 step:163070[D loss: 0.999935] [G loss: 1.000028]\n",
      "epoch:34 step:163075[D loss: 1.000078] [G loss: 0.999784]\n",
      "epoch:34 step:163080[D loss: 1.000061] [G loss: 0.999884]\n",
      "epoch:34 step:163085[D loss: 0.999980] [G loss: 0.999995]\n",
      "epoch:34 step:163090[D loss: 0.999908] [G loss: 1.000081]\n",
      "epoch:34 step:163095[D loss: 1.000032] [G loss: 1.000186]\n",
      "epoch:34 step:163100[D loss: 1.000222] [G loss: 1.000046]\n",
      "epoch:34 step:163105[D loss: 0.999954] [G loss: 1.000096]\n",
      "epoch:34 step:163110[D loss: 1.000114] [G loss: 0.999881]\n",
      "epoch:34 step:163115[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:34 step:163120[D loss: 0.999925] [G loss: 1.000086]\n",
      "epoch:34 step:163125[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:34 step:163130[D loss: 1.000025] [G loss: 1.000010]\n",
      "epoch:34 step:163135[D loss: 0.999947] [G loss: 1.000002]\n",
      "epoch:34 step:163140[D loss: 1.000013] [G loss: 0.999960]\n",
      "epoch:34 step:163145[D loss: 1.000006] [G loss: 0.999985]\n",
      "epoch:34 step:163150[D loss: 0.999895] [G loss: 1.000147]\n",
      "epoch:34 step:163155[D loss: 0.999913] [G loss: 1.000145]\n",
      "epoch:34 step:163160[D loss: 1.000210] [G loss: 0.999817]\n",
      "epoch:34 step:163165[D loss: 0.999908] [G loss: 1.000059]\n",
      "epoch:34 step:163170[D loss: 0.999893] [G loss: 1.000226]\n",
      "epoch:34 step:163175[D loss: 0.999934] [G loss: 1.000071]\n",
      "epoch:34 step:163180[D loss: 0.999991] [G loss: 1.000086]\n",
      "epoch:34 step:163185[D loss: 0.999992] [G loss: 1.000175]\n",
      "epoch:34 step:163190[D loss: 0.999836] [G loss: 1.000209]\n",
      "epoch:34 step:163195[D loss: 0.999942] [G loss: 1.000069]\n",
      "epoch:34 step:163200[D loss: 0.999981] [G loss: 1.000056]\n",
      "##############\n",
      "[2.59861429 2.21907852 2.30383239 4.34185797 1.57542598 7.55042198\n",
      " 2.49735955 3.74937797 4.01840427 7.14868929]\n",
      "##########\n",
      "epoch:34 step:163205[D loss: 0.999985] [G loss: 1.000123]\n",
      "epoch:34 step:163210[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:34 step:163215[D loss: 0.999954] [G loss: 1.000045]\n",
      "epoch:34 step:163220[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:34 step:163225[D loss: 0.999981] [G loss: 1.000021]\n",
      "epoch:34 step:163230[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:34 step:163235[D loss: 0.999933] [G loss: 1.000182]\n",
      "epoch:34 step:163240[D loss: 0.999888] [G loss: 1.000117]\n",
      "epoch:34 step:163245[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:34 step:163250[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:34 step:163255[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:34 step:163260[D loss: 0.999955] [G loss: 1.000032]\n",
      "epoch:34 step:163265[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:34 step:163270[D loss: 0.999924] [G loss: 1.000066]\n",
      "epoch:34 step:163275[D loss: 1.000006] [G loss: 0.999998]\n",
      "epoch:34 step:163280[D loss: 0.999987] [G loss: 1.000190]\n",
      "epoch:34 step:163285[D loss: 0.999932] [G loss: 1.000129]\n",
      "epoch:34 step:163290[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:34 step:163295[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:34 step:163300[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:34 step:163305[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:34 step:163310[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:34 step:163315[D loss: 1.000089] [G loss: 0.999903]\n",
      "epoch:34 step:163320[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:34 step:163325[D loss: 1.000026] [G loss: 1.000167]\n",
      "epoch:34 step:163330[D loss: 1.000122] [G loss: 0.999939]\n",
      "epoch:34 step:163335[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:34 step:163340[D loss: 0.999975] [G loss: 1.000012]\n",
      "epoch:34 step:163345[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:34 step:163350[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:34 step:163355[D loss: 0.999951] [G loss: 1.000057]\n",
      "epoch:34 step:163360[D loss: 0.999987] [G loss: 1.000099]\n",
      "epoch:34 step:163365[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:34 step:163370[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:34 step:163375[D loss: 1.000008] [G loss: 1.000016]\n",
      "epoch:34 step:163380[D loss: 1.000121] [G loss: 0.999979]\n",
      "epoch:34 step:163385[D loss: 0.999894] [G loss: 0.999957]\n",
      "epoch:34 step:163390[D loss: 0.999913] [G loss: 1.000240]\n",
      "epoch:34 step:163395[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:34 step:163400[D loss: 1.000036] [G loss: 0.999922]\n",
      "##############\n",
      "[2.61737636 2.25222548 2.20259568 3.43845403 1.62041128 7.83042502\n",
      " 2.45922088 3.81003586 3.9595643  5.16377175]\n",
      "##########\n",
      "epoch:34 step:163405[D loss: 0.999936] [G loss: 1.000101]\n",
      "epoch:34 step:163410[D loss: 0.999889] [G loss: 1.000141]\n",
      "epoch:34 step:163415[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:34 step:163420[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:34 step:163425[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:34 step:163430[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:34 step:163435[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:34 step:163440[D loss: 1.000011] [G loss: 1.000065]\n",
      "epoch:34 step:163445[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:34 step:163450[D loss: 1.000102] [G loss: 0.999962]\n",
      "epoch:34 step:163455[D loss: 0.999929] [G loss: 1.000098]\n",
      "epoch:34 step:163460[D loss: 1.000066] [G loss: 1.000067]\n",
      "epoch:34 step:163465[D loss: 0.999941] [G loss: 1.000119]\n",
      "epoch:34 step:163470[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:34 step:163475[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:34 step:163480[D loss: 0.999985] [G loss: 0.999980]\n",
      "epoch:34 step:163485[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:34 step:163490[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:34 step:163495[D loss: 0.999910] [G loss: 1.000137]\n",
      "epoch:34 step:163500[D loss: 0.999932] [G loss: 1.000111]\n",
      "epoch:34 step:163505[D loss: 0.999986] [G loss: 1.000134]\n",
      "epoch:34 step:163510[D loss: 1.000061] [G loss: 1.000022]\n",
      "epoch:34 step:163515[D loss: 0.999961] [G loss: 1.000134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:163520[D loss: 0.999932] [G loss: 1.000103]\n",
      "epoch:34 step:163525[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:34 step:163530[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:34 step:163535[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:34 step:163540[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:34 step:163545[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:34 step:163550[D loss: 0.999979] [G loss: 0.999998]\n",
      "epoch:34 step:163555[D loss: 1.000075] [G loss: 0.999993]\n",
      "epoch:34 step:163560[D loss: 0.999916] [G loss: 1.000103]\n",
      "epoch:34 step:163565[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:34 step:163570[D loss: 1.000055] [G loss: 1.000083]\n",
      "epoch:34 step:163575[D loss: 0.999943] [G loss: 1.000108]\n",
      "epoch:34 step:163580[D loss: 0.999941] [G loss: 1.000092]\n",
      "epoch:34 step:163585[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:34 step:163590[D loss: 1.000025] [G loss: 0.999990]\n",
      "epoch:34 step:163595[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:34 step:163600[D loss: 0.999990] [G loss: 1.000067]\n",
      "##############\n",
      "[2.62030043 2.27311266 2.23042074 3.74144786 1.57861218 7.44746843\n",
      " 2.32030045 3.87568153 4.06010431 5.54522635]\n",
      "##########\n",
      "epoch:34 step:163605[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:34 step:163610[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:34 step:163615[D loss: 0.999945] [G loss: 1.000099]\n",
      "epoch:34 step:163620[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:34 step:163625[D loss: 0.999941] [G loss: 1.000124]\n",
      "epoch:34 step:163630[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:34 step:163635[D loss: 1.000012] [G loss: 1.000007]\n",
      "epoch:34 step:163640[D loss: 1.000084] [G loss: 1.000029]\n",
      "epoch:34 step:163645[D loss: 0.999975] [G loss: 1.000016]\n",
      "epoch:34 step:163650[D loss: 1.000060] [G loss: 0.999834]\n",
      "epoch:34 step:163655[D loss: 0.999939] [G loss: 1.000039]\n",
      "epoch:34 step:163660[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:34 step:163665[D loss: 1.000019] [G loss: 1.000063]\n",
      "epoch:34 step:163670[D loss: 0.999919] [G loss: 1.000200]\n",
      "epoch:34 step:163675[D loss: 0.999908] [G loss: 1.000114]\n",
      "epoch:34 step:163680[D loss: 0.999945] [G loss: 1.000126]\n",
      "epoch:34 step:163685[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:34 step:163690[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:34 step:163695[D loss: 1.000049] [G loss: 0.999959]\n",
      "epoch:34 step:163700[D loss: 0.999924] [G loss: 1.000137]\n",
      "epoch:34 step:163705[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:34 step:163710[D loss: 0.999952] [G loss: 1.000105]\n",
      "epoch:34 step:163715[D loss: 1.000023] [G loss: 1.000084]\n",
      "epoch:34 step:163720[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:34 step:163725[D loss: 0.999966] [G loss: 1.000134]\n",
      "epoch:34 step:163730[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:34 step:163735[D loss: 0.999933] [G loss: 1.000121]\n",
      "epoch:34 step:163740[D loss: 0.999979] [G loss: 1.000015]\n",
      "epoch:34 step:163745[D loss: 1.000003] [G loss: 1.000015]\n",
      "epoch:34 step:163750[D loss: 1.000010] [G loss: 0.999983]\n",
      "epoch:34 step:163755[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:34 step:163760[D loss: 0.999978] [G loss: 1.000104]\n",
      "epoch:34 step:163765[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:34 step:163770[D loss: 1.000078] [G loss: 1.000163]\n",
      "epoch:34 step:163775[D loss: 1.000058] [G loss: 0.999932]\n",
      "epoch:34 step:163780[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:34 step:163785[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:34 step:163790[D loss: 0.999985] [G loss: 1.000090]\n",
      "epoch:34 step:163795[D loss: 0.999954] [G loss: 1.000072]\n",
      "epoch:34 step:163800[D loss: 0.999987] [G loss: 1.000097]\n",
      "##############\n",
      "[2.66431064 2.28727594 2.27355207 3.67049258 1.57714049 7.89339744\n",
      " 2.58391135 4.04037004 4.0891973  5.40432105]\n",
      "##########\n",
      "epoch:34 step:163805[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:34 step:163810[D loss: 0.999958] [G loss: 1.000164]\n",
      "epoch:34 step:163815[D loss: 0.999950] [G loss: 1.000127]\n",
      "epoch:34 step:163820[D loss: 1.000030] [G loss: 1.000126]\n",
      "epoch:34 step:163825[D loss: 0.999921] [G loss: 1.000062]\n",
      "epoch:34 step:163830[D loss: 1.000100] [G loss: 0.999994]\n",
      "epoch:34 step:163835[D loss: 0.999993] [G loss: 1.000012]\n",
      "epoch:34 step:163840[D loss: 0.999983] [G loss: 0.999944]\n",
      "epoch:34 step:163845[D loss: 0.999881] [G loss: 1.000096]\n",
      "epoch:34 step:163850[D loss: 0.999958] [G loss: 1.000049]\n",
      "epoch:34 step:163855[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:34 step:163860[D loss: 1.000026] [G loss: 1.000126]\n",
      "epoch:34 step:163865[D loss: 0.999922] [G loss: 1.000201]\n",
      "epoch:34 step:163870[D loss: 0.999915] [G loss: 1.000185]\n",
      "epoch:34 step:163875[D loss: 0.999952] [G loss: 1.000257]\n",
      "epoch:34 step:163880[D loss: 0.999985] [G loss: 1.000004]\n",
      "epoch:34 step:163885[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:34 step:163890[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:34 step:163895[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:34 step:163900[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:34 step:163905[D loss: 0.999954] [G loss: 1.000031]\n",
      "epoch:34 step:163910[D loss: 0.999949] [G loss: 1.000093]\n",
      "epoch:34 step:163915[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:34 step:163920[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:34 step:163925[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:34 step:163930[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:34 step:163935[D loss: 0.999938] [G loss: 1.000084]\n",
      "epoch:34 step:163940[D loss: 0.999952] [G loss: 1.000061]\n",
      "epoch:34 step:163945[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:34 step:163950[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:34 step:163955[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:34 step:163960[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:34 step:163965[D loss: 0.999979] [G loss: 1.000176]\n",
      "epoch:34 step:163970[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:34 step:163975[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:35 step:163980[D loss: 1.000209] [G loss: 0.999791]\n",
      "epoch:35 step:163985[D loss: 1.000114] [G loss: 0.999892]\n",
      "epoch:35 step:163990[D loss: 0.999983] [G loss: 0.999981]\n",
      "epoch:35 step:163995[D loss: 0.999987] [G loss: 1.000236]\n",
      "epoch:35 step:164000[D loss: 0.999976] [G loss: 1.000126]\n",
      "##############\n",
      "[2.56660235 2.24644404 2.20355411 3.33983684 1.525076   7.02134255\n",
      " 2.39335807 3.96909997 3.96892023 5.30219694]\n",
      "##########\n",
      "epoch:35 step:164005[D loss: 0.999868] [G loss: 1.000290]\n",
      "epoch:35 step:164010[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:35 step:164015[D loss: 0.999987] [G loss: 0.999995]\n",
      "epoch:35 step:164020[D loss: 1.000095] [G loss: 0.999880]\n",
      "epoch:35 step:164025[D loss: 1.000163] [G loss: 0.999865]\n",
      "epoch:35 step:164030[D loss: 1.000095] [G loss: 0.999961]\n",
      "epoch:35 step:164035[D loss: 0.999870] [G loss: 1.000067]\n",
      "epoch:35 step:164040[D loss: 0.999954] [G loss: 0.999901]\n",
      "epoch:35 step:164045[D loss: 0.999988] [G loss: 1.000007]\n",
      "epoch:35 step:164050[D loss: 0.999989] [G loss: 1.000189]\n",
      "epoch:35 step:164055[D loss: 1.000014] [G loss: 1.000105]\n",
      "epoch:35 step:164060[D loss: 0.999892] [G loss: 1.000230]\n",
      "epoch:35 step:164065[D loss: 0.999827] [G loss: 1.000198]\n",
      "epoch:35 step:164070[D loss: 0.999971] [G loss: 1.000153]\n",
      "epoch:35 step:164075[D loss: 1.000039] [G loss: 1.000055]\n",
      "epoch:35 step:164080[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:35 step:164085[D loss: 1.000004] [G loss: 1.000041]\n",
      "epoch:35 step:164090[D loss: 1.000029] [G loss: 0.999925]\n",
      "epoch:35 step:164095[D loss: 1.000098] [G loss: 0.999944]\n",
      "epoch:35 step:164100[D loss: 1.000064] [G loss: 0.999889]\n",
      "epoch:35 step:164105[D loss: 1.000074] [G loss: 1.000096]\n",
      "epoch:35 step:164110[D loss: 1.000076] [G loss: 1.000023]\n",
      "epoch:35 step:164115[D loss: 0.999878] [G loss: 1.000138]\n",
      "epoch:35 step:164120[D loss: 0.999888] [G loss: 1.000100]\n",
      "epoch:35 step:164125[D loss: 0.999926] [G loss: 1.000124]\n",
      "epoch:35 step:164130[D loss: 1.000024] [G loss: 1.000166]\n",
      "epoch:35 step:164135[D loss: 1.000107] [G loss: 1.000104]\n",
      "epoch:35 step:164140[D loss: 1.000056] [G loss: 1.000036]\n",
      "epoch:35 step:164145[D loss: 1.000018] [G loss: 1.000187]\n",
      "epoch:35 step:164150[D loss: 1.000002] [G loss: 1.000059]\n",
      "epoch:35 step:164155[D loss: 0.999941] [G loss: 1.000273]\n",
      "epoch:35 step:164160[D loss: 0.999970] [G loss: 1.000281]\n",
      "epoch:35 step:164165[D loss: 0.999866] [G loss: 1.000259]\n",
      "epoch:35 step:164170[D loss: 0.999979] [G loss: 1.000012]\n",
      "epoch:35 step:164175[D loss: 1.000089] [G loss: 0.999957]\n",
      "epoch:35 step:164180[D loss: 0.999950] [G loss: 0.999965]\n",
      "epoch:35 step:164185[D loss: 0.999985] [G loss: 0.999927]\n",
      "epoch:35 step:164190[D loss: 1.000122] [G loss: 0.999682]\n",
      "epoch:35 step:164195[D loss: 0.999994] [G loss: 0.999949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:164200[D loss: 1.000001] [G loss: 1.000011]\n",
      "##############\n",
      "[2.55109497 2.28620527 2.23897806 3.54997885 1.60232781 7.49165201\n",
      " 2.49144387 3.86544524 3.94263887 5.21714956]\n",
      "##########\n",
      "epoch:35 step:164205[D loss: 1.000015] [G loss: 0.999978]\n",
      "epoch:35 step:164210[D loss: 0.999921] [G loss: 1.000070]\n",
      "epoch:35 step:164215[D loss: 0.999946] [G loss: 1.000103]\n",
      "epoch:35 step:164220[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:35 step:164225[D loss: 0.999999] [G loss: 1.000065]\n",
      "epoch:35 step:164230[D loss: 0.999911] [G loss: 1.000126]\n",
      "epoch:35 step:164235[D loss: 1.000067] [G loss: 0.999922]\n",
      "epoch:35 step:164240[D loss: 0.999932] [G loss: 1.000070]\n",
      "epoch:35 step:164245[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:35 step:164250[D loss: 0.999956] [G loss: 1.000100]\n",
      "epoch:35 step:164255[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:35 step:164260[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:35 step:164265[D loss: 1.000021] [G loss: 1.000023]\n",
      "epoch:35 step:164270[D loss: 0.999930] [G loss: 1.000146]\n",
      "epoch:35 step:164275[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:35 step:164280[D loss: 0.999953] [G loss: 1.000063]\n",
      "epoch:35 step:164285[D loss: 1.000047] [G loss: 0.999971]\n",
      "epoch:35 step:164290[D loss: 1.000198] [G loss: 0.999782]\n",
      "epoch:35 step:164295[D loss: 1.000065] [G loss: 1.000097]\n",
      "epoch:35 step:164300[D loss: 0.999905] [G loss: 1.000086]\n",
      "epoch:35 step:164305[D loss: 0.999922] [G loss: 1.000061]\n",
      "epoch:35 step:164310[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:35 step:164315[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:35 step:164320[D loss: 1.000028] [G loss: 1.000042]\n",
      "epoch:35 step:164325[D loss: 1.000047] [G loss: 0.999882]\n",
      "epoch:35 step:164330[D loss: 1.000024] [G loss: 1.000021]\n",
      "epoch:35 step:164335[D loss: 1.000026] [G loss: 1.000092]\n",
      "epoch:35 step:164340[D loss: 0.999950] [G loss: 1.000075]\n",
      "epoch:35 step:164345[D loss: 0.999997] [G loss: 1.000021]\n",
      "epoch:35 step:164350[D loss: 1.000019] [G loss: 1.000019]\n",
      "epoch:35 step:164355[D loss: 0.999923] [G loss: 1.000167]\n",
      "epoch:35 step:164360[D loss: 0.999968] [G loss: 1.000122]\n",
      "epoch:35 step:164365[D loss: 0.999956] [G loss: 1.000166]\n",
      "epoch:35 step:164370[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:35 step:164375[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:35 step:164380[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:35 step:164385[D loss: 1.000044] [G loss: 0.999983]\n",
      "epoch:35 step:164390[D loss: 0.999954] [G loss: 1.000014]\n",
      "epoch:35 step:164395[D loss: 0.999998] [G loss: 0.999991]\n",
      "epoch:35 step:164400[D loss: 1.000081] [G loss: 0.999975]\n",
      "##############\n",
      "[2.51705301 2.23248258 2.19958163 3.58805676 1.58103205 7.58176994\n",
      " 2.34969908 3.86305322 4.0769297  4.94743769]\n",
      "##########\n",
      "epoch:35 step:164405[D loss: 1.000050] [G loss: 0.999937]\n",
      "epoch:35 step:164410[D loss: 1.000011] [G loss: 1.000063]\n",
      "epoch:35 step:164415[D loss: 0.999994] [G loss: 1.000071]\n",
      "epoch:35 step:164420[D loss: 0.999912] [G loss: 1.000290]\n",
      "epoch:35 step:164425[D loss: 0.999932] [G loss: 1.000090]\n",
      "epoch:35 step:164430[D loss: 0.999989] [G loss: 1.000010]\n",
      "epoch:35 step:164435[D loss: 1.000007] [G loss: 0.999947]\n",
      "epoch:35 step:164440[D loss: 0.999954] [G loss: 0.999983]\n",
      "epoch:35 step:164445[D loss: 1.000113] [G loss: 0.999833]\n",
      "epoch:35 step:164450[D loss: 1.000193] [G loss: 0.999855]\n",
      "epoch:35 step:164455[D loss: 1.000110] [G loss: 0.999989]\n",
      "epoch:35 step:164460[D loss: 0.999938] [G loss: 1.000182]\n",
      "epoch:35 step:164465[D loss: 1.000125] [G loss: 0.999909]\n",
      "epoch:35 step:164470[D loss: 1.000031] [G loss: 1.000032]\n",
      "epoch:35 step:164475[D loss: 1.000062] [G loss: 1.000049]\n",
      "epoch:35 step:164480[D loss: 0.999904] [G loss: 1.000135]\n",
      "epoch:35 step:164485[D loss: 0.999944] [G loss: 1.000152]\n",
      "epoch:35 step:164490[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:35 step:164495[D loss: 1.000044] [G loss: 0.999936]\n",
      "epoch:35 step:164500[D loss: 1.000097] [G loss: 0.999765]\n",
      "epoch:35 step:164505[D loss: 0.999977] [G loss: 1.000016]\n",
      "epoch:35 step:164510[D loss: 1.000110] [G loss: 0.999865]\n",
      "epoch:35 step:164515[D loss: 1.000018] [G loss: 0.999988]\n",
      "epoch:35 step:164520[D loss: 0.999715] [G loss: 1.000285]\n",
      "epoch:35 step:164525[D loss: 0.999989] [G loss: 1.000211]\n",
      "epoch:35 step:164530[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:35 step:164535[D loss: 0.999919] [G loss: 1.000174]\n",
      "epoch:35 step:164540[D loss: 0.999894] [G loss: 1.000360]\n",
      "epoch:35 step:164545[D loss: 0.999956] [G loss: 1.000117]\n",
      "epoch:35 step:164550[D loss: 0.999971] [G loss: 1.000156]\n",
      "epoch:35 step:164555[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:35 step:164560[D loss: 1.000120] [G loss: 0.999873]\n",
      "epoch:35 step:164565[D loss: 1.000137] [G loss: 0.999857]\n",
      "epoch:35 step:164570[D loss: 1.000051] [G loss: 1.000065]\n",
      "epoch:35 step:164575[D loss: 0.999939] [G loss: 1.000050]\n",
      "epoch:35 step:164580[D loss: 1.000097] [G loss: 1.000067]\n",
      "epoch:35 step:164585[D loss: 1.000125] [G loss: 0.999921]\n",
      "epoch:35 step:164590[D loss: 0.999999] [G loss: 1.000074]\n",
      "epoch:35 step:164595[D loss: 1.000033] [G loss: 0.999987]\n",
      "epoch:35 step:164600[D loss: 0.999864] [G loss: 1.000153]\n",
      "##############\n",
      "[2.60787914 2.22860837 2.25440063 3.66999019 1.68275441 7.7102704\n",
      " 2.38369116 3.8479931  4.03527923 4.86368965]\n",
      "##########\n",
      "epoch:35 step:164605[D loss: 0.999947] [G loss: 1.000162]\n",
      "epoch:35 step:164610[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:35 step:164615[D loss: 0.999945] [G loss: 1.000184]\n",
      "epoch:35 step:164620[D loss: 1.000010] [G loss: 0.999997]\n",
      "epoch:35 step:164625[D loss: 0.999937] [G loss: 1.000101]\n",
      "epoch:35 step:164630[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:35 step:164635[D loss: 0.999998] [G loss: 1.000073]\n",
      "epoch:35 step:164640[D loss: 1.000034] [G loss: 0.999974]\n",
      "epoch:35 step:164645[D loss: 1.000031] [G loss: 0.999979]\n",
      "epoch:35 step:164650[D loss: 0.999994] [G loss: 0.999909]\n",
      "epoch:35 step:164655[D loss: 0.999903] [G loss: 1.000083]\n",
      "epoch:35 step:164660[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:35 step:164665[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:35 step:164670[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:35 step:164675[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:35 step:164680[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:35 step:164685[D loss: 0.999996] [G loss: 1.000063]\n",
      "epoch:35 step:164690[D loss: 0.999994] [G loss: 1.000021]\n",
      "epoch:35 step:164695[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:35 step:164700[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:35 step:164705[D loss: 0.999957] [G loss: 1.000135]\n",
      "epoch:35 step:164710[D loss: 0.999993] [G loss: 1.000104]\n",
      "epoch:35 step:164715[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:35 step:164720[D loss: 0.999963] [G loss: 1.000093]\n",
      "epoch:35 step:164725[D loss: 0.999934] [G loss: 1.000088]\n",
      "epoch:35 step:164730[D loss: 0.999927] [G loss: 1.000087]\n",
      "epoch:35 step:164735[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:35 step:164740[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:35 step:164745[D loss: 0.999984] [G loss: 1.000089]\n",
      "epoch:35 step:164750[D loss: 1.000084] [G loss: 0.999816]\n",
      "epoch:35 step:164755[D loss: 1.000011] [G loss: 1.000046]\n",
      "epoch:35 step:164760[D loss: 0.999945] [G loss: 1.000060]\n",
      "epoch:35 step:164765[D loss: 1.000012] [G loss: 0.999960]\n",
      "epoch:35 step:164770[D loss: 1.000002] [G loss: 0.999976]\n",
      "epoch:35 step:164775[D loss: 1.000014] [G loss: 1.000044]\n",
      "epoch:35 step:164780[D loss: 1.000059] [G loss: 1.000083]\n",
      "epoch:35 step:164785[D loss: 1.000037] [G loss: 0.999877]\n",
      "epoch:35 step:164790[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:35 step:164795[D loss: 0.999897] [G loss: 1.000147]\n",
      "epoch:35 step:164800[D loss: 1.000050] [G loss: 0.999935]\n",
      "##############\n",
      "[2.6119336  2.30391729 2.39645851 3.88792464 1.60297818 7.9600193\n",
      " 2.65730615 3.85851293 4.14444514 6.10103651]\n",
      "##########\n",
      "epoch:35 step:164805[D loss: 1.000119] [G loss: 0.999843]\n",
      "epoch:35 step:164810[D loss: 0.999968] [G loss: 0.999984]\n",
      "epoch:35 step:164815[D loss: 0.999907] [G loss: 1.000059]\n",
      "epoch:35 step:164820[D loss: 1.000023] [G loss: 0.999988]\n",
      "epoch:35 step:164825[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:35 step:164830[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:35 step:164835[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:35 step:164840[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:35 step:164845[D loss: 0.999969] [G loss: 1.000043]\n",
      "epoch:35 step:164850[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:35 step:164855[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:35 step:164860[D loss: 0.999976] [G loss: 1.000114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:164865[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:35 step:164870[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:35 step:164875[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:35 step:164880[D loss: 0.999973] [G loss: 1.000141]\n",
      "epoch:35 step:164885[D loss: 0.999991] [G loss: 1.000129]\n",
      "epoch:35 step:164890[D loss: 0.999940] [G loss: 1.000147]\n",
      "epoch:35 step:164895[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:35 step:164900[D loss: 1.000044] [G loss: 0.999908]\n",
      "epoch:35 step:164905[D loss: 0.999947] [G loss: 1.000031]\n",
      "epoch:35 step:164910[D loss: 0.999945] [G loss: 1.000145]\n",
      "epoch:35 step:164915[D loss: 1.000123] [G loss: 0.999987]\n",
      "epoch:35 step:164920[D loss: 0.999913] [G loss: 1.000089]\n",
      "epoch:35 step:164925[D loss: 0.999939] [G loss: 1.000105]\n",
      "epoch:35 step:164930[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:35 step:164935[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:35 step:164940[D loss: 1.000008] [G loss: 1.000055]\n",
      "epoch:35 step:164945[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:35 step:164950[D loss: 0.999983] [G loss: 1.000001]\n",
      "epoch:35 step:164955[D loss: 1.000034] [G loss: 0.999954]\n",
      "epoch:35 step:164960[D loss: 1.000029] [G loss: 1.000110]\n",
      "epoch:35 step:164965[D loss: 1.000134] [G loss: 1.000032]\n",
      "epoch:35 step:164970[D loss: 1.000180] [G loss: 0.999739]\n",
      "epoch:35 step:164975[D loss: 1.000051] [G loss: 1.000244]\n",
      "epoch:35 step:164980[D loss: 0.999977] [G loss: 1.000255]\n",
      "epoch:35 step:164985[D loss: 0.999859] [G loss: 1.000186]\n",
      "epoch:35 step:164990[D loss: 0.999901] [G loss: 1.000220]\n",
      "epoch:35 step:164995[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:35 step:165000[D loss: 1.000005] [G loss: 1.000001]\n",
      "##############\n",
      "[2.68261727 2.26254689 2.24292977 3.76689921 1.62981957 7.89790291\n",
      " 2.39989355 3.97853    4.08250624 5.21990313]\n",
      "##########\n",
      "epoch:35 step:165005[D loss: 1.000073] [G loss: 0.999890]\n",
      "epoch:35 step:165010[D loss: 0.999985] [G loss: 1.000015]\n",
      "epoch:35 step:165015[D loss: 0.999935] [G loss: 0.999963]\n",
      "epoch:35 step:165020[D loss: 1.000083] [G loss: 0.999892]\n",
      "epoch:35 step:165025[D loss: 1.000035] [G loss: 0.999897]\n",
      "epoch:35 step:165030[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:35 step:165035[D loss: 1.000117] [G loss: 0.999827]\n",
      "epoch:35 step:165040[D loss: 0.999783] [G loss: 1.000348]\n",
      "epoch:35 step:165045[D loss: 1.000067] [G loss: 1.000121]\n",
      "epoch:35 step:165050[D loss: 0.999966] [G loss: 1.000239]\n",
      "epoch:35 step:165055[D loss: 1.000047] [G loss: 1.000193]\n",
      "epoch:35 step:165060[D loss: 1.000127] [G loss: 1.000372]\n",
      "epoch:35 step:165065[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:35 step:165070[D loss: 0.999877] [G loss: 1.000245]\n",
      "epoch:35 step:165075[D loss: 0.999923] [G loss: 1.000198]\n",
      "epoch:35 step:165080[D loss: 0.999906] [G loss: 1.000135]\n",
      "epoch:35 step:165085[D loss: 0.999999] [G loss: 0.999965]\n",
      "epoch:35 step:165090[D loss: 1.000102] [G loss: 0.999825]\n",
      "epoch:35 step:165095[D loss: 0.999918] [G loss: 0.999930]\n",
      "epoch:35 step:165100[D loss: 1.000221] [G loss: 0.999891]\n",
      "epoch:35 step:165105[D loss: 1.000220] [G loss: 1.000022]\n",
      "epoch:35 step:165110[D loss: 1.000176] [G loss: 0.999998]\n",
      "epoch:35 step:165115[D loss: 0.999790] [G loss: 1.000475]\n",
      "epoch:35 step:165120[D loss: 0.999890] [G loss: 1.000011]\n",
      "epoch:35 step:165125[D loss: 1.000013] [G loss: 1.000298]\n",
      "epoch:35 step:165130[D loss: 0.999933] [G loss: 1.000313]\n",
      "epoch:35 step:165135[D loss: 0.999932] [G loss: 1.000225]\n",
      "epoch:35 step:165140[D loss: 1.000022] [G loss: 1.000469]\n",
      "epoch:35 step:165145[D loss: 1.000116] [G loss: 1.000243]\n",
      "epoch:35 step:165150[D loss: 0.999887] [G loss: 1.000564]\n",
      "epoch:35 step:165155[D loss: 0.999835] [G loss: 1.000352]\n",
      "epoch:35 step:165160[D loss: 1.000017] [G loss: 1.000049]\n",
      "epoch:35 step:165165[D loss: 1.000003] [G loss: 0.999918]\n",
      "epoch:35 step:165170[D loss: 1.000031] [G loss: 0.999984]\n",
      "epoch:35 step:165175[D loss: 1.000135] [G loss: 0.999936]\n",
      "epoch:35 step:165180[D loss: 1.000105] [G loss: 0.999812]\n",
      "epoch:35 step:165185[D loss: 0.999927] [G loss: 0.999894]\n",
      "epoch:35 step:165190[D loss: 0.999937] [G loss: 0.999833]\n",
      "epoch:35 step:165195[D loss: 1.000215] [G loss: 0.999802]\n",
      "epoch:35 step:165200[D loss: 0.999643] [G loss: 1.000291]\n",
      "##############\n",
      "[2.5519979  2.29318738 2.3682668  3.88727771 1.60960022 7.03550708\n",
      " 2.52309687 3.75699725 4.07000434 5.14126075]\n",
      "##########\n",
      "epoch:35 step:165205[D loss: 1.000119] [G loss: 0.999958]\n",
      "epoch:35 step:165210[D loss: 0.999828] [G loss: 1.000131]\n",
      "epoch:35 step:165215[D loss: 1.000089] [G loss: 0.999966]\n",
      "epoch:35 step:165220[D loss: 1.000093] [G loss: 0.999995]\n",
      "epoch:35 step:165225[D loss: 0.999825] [G loss: 1.000277]\n",
      "epoch:35 step:165230[D loss: 0.999961] [G loss: 1.000023]\n",
      "epoch:35 step:165235[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:35 step:165240[D loss: 1.000023] [G loss: 1.000009]\n",
      "epoch:35 step:165245[D loss: 1.000004] [G loss: 1.000053]\n",
      "epoch:35 step:165250[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:35 step:165255[D loss: 0.999912] [G loss: 1.000039]\n",
      "epoch:35 step:165260[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:35 step:165265[D loss: 1.000101] [G loss: 1.000050]\n",
      "epoch:35 step:165270[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:35 step:165275[D loss: 0.999908] [G loss: 1.000203]\n",
      "epoch:35 step:165280[D loss: 0.999928] [G loss: 1.000204]\n",
      "epoch:35 step:165285[D loss: 0.999955] [G loss: 1.000114]\n",
      "epoch:35 step:165290[D loss: 1.000016] [G loss: 1.000072]\n",
      "epoch:35 step:165295[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:35 step:165300[D loss: 0.999964] [G loss: 1.000029]\n",
      "epoch:35 step:165305[D loss: 1.000008] [G loss: 1.000064]\n",
      "epoch:35 step:165310[D loss: 0.999949] [G loss: 1.000150]\n",
      "epoch:35 step:165315[D loss: 0.999916] [G loss: 1.000178]\n",
      "epoch:35 step:165320[D loss: 0.999954] [G loss: 1.000159]\n",
      "epoch:35 step:165325[D loss: 0.999940] [G loss: 1.000099]\n",
      "epoch:35 step:165330[D loss: 1.000015] [G loss: 0.999943]\n",
      "epoch:35 step:165335[D loss: 0.999975] [G loss: 1.000116]\n",
      "epoch:35 step:165340[D loss: 0.999957] [G loss: 1.000105]\n",
      "epoch:35 step:165345[D loss: 0.999988] [G loss: 1.000099]\n",
      "epoch:35 step:165350[D loss: 1.000100] [G loss: 0.999953]\n",
      "epoch:35 step:165355[D loss: 0.999952] [G loss: 1.000143]\n",
      "epoch:35 step:165360[D loss: 1.000203] [G loss: 0.999731]\n",
      "epoch:35 step:165365[D loss: 0.999973] [G loss: 1.000153]\n",
      "epoch:35 step:165370[D loss: 0.999835] [G loss: 1.000323]\n",
      "epoch:35 step:165375[D loss: 0.999919] [G loss: 1.000227]\n",
      "epoch:35 step:165380[D loss: 0.999946] [G loss: 1.000115]\n",
      "epoch:35 step:165385[D loss: 1.000002] [G loss: 0.999966]\n",
      "epoch:35 step:165390[D loss: 0.999985] [G loss: 0.999960]\n",
      "epoch:35 step:165395[D loss: 1.000111] [G loss: 0.999887]\n",
      "epoch:35 step:165400[D loss: 1.000017] [G loss: 0.999941]\n",
      "##############\n",
      "[2.60870935 2.26170752 2.30423326 4.01076783 1.65158029 7.21486762\n",
      " 2.57493838 4.06693958 4.17738115 5.28194514]\n",
      "##########\n",
      "epoch:35 step:165405[D loss: 0.999934] [G loss: 1.000066]\n",
      "epoch:35 step:165410[D loss: 0.999982] [G loss: 1.000093]\n",
      "epoch:35 step:165415[D loss: 0.999996] [G loss: 0.999985]\n",
      "epoch:35 step:165420[D loss: 0.999933] [G loss: 1.000098]\n",
      "epoch:35 step:165425[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:35 step:165430[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:35 step:165435[D loss: 1.000006] [G loss: 0.999963]\n",
      "epoch:35 step:165440[D loss: 1.000021] [G loss: 1.000009]\n",
      "epoch:35 step:165445[D loss: 0.999943] [G loss: 1.000094]\n",
      "epoch:35 step:165450[D loss: 0.999943] [G loss: 1.000142]\n",
      "epoch:35 step:165455[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:35 step:165460[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:35 step:165465[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:35 step:165470[D loss: 0.999956] [G loss: 1.000096]\n",
      "epoch:35 step:165475[D loss: 1.000063] [G loss: 1.000009]\n",
      "epoch:35 step:165480[D loss: 0.999884] [G loss: 1.000188]\n",
      "epoch:35 step:165485[D loss: 0.999956] [G loss: 1.000114]\n",
      "epoch:35 step:165490[D loss: 1.000022] [G loss: 1.000166]\n",
      "epoch:35 step:165495[D loss: 0.999890] [G loss: 1.000111]\n",
      "epoch:35 step:165500[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:35 step:165505[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:35 step:165510[D loss: 0.999936] [G loss: 1.000092]\n",
      "epoch:35 step:165515[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:35 step:165520[D loss: 0.999981] [G loss: 1.000024]\n",
      "epoch:35 step:165525[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:35 step:165530[D loss: 1.000074] [G loss: 0.999917]\n",
      "epoch:35 step:165535[D loss: 0.999943] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:165540[D loss: 0.999956] [G loss: 1.000057]\n",
      "epoch:35 step:165545[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:35 step:165550[D loss: 0.999983] [G loss: 1.000092]\n",
      "epoch:35 step:165555[D loss: 0.999991] [G loss: 1.000134]\n",
      "epoch:35 step:165560[D loss: 0.999972] [G loss: 0.999986]\n",
      "epoch:35 step:165565[D loss: 1.000063] [G loss: 0.999875]\n",
      "epoch:35 step:165570[D loss: 1.000032] [G loss: 0.999931]\n",
      "epoch:35 step:165575[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:35 step:165580[D loss: 1.000113] [G loss: 0.999947]\n",
      "epoch:35 step:165585[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:35 step:165590[D loss: 0.999989] [G loss: 1.000008]\n",
      "epoch:35 step:165595[D loss: 0.999890] [G loss: 1.000122]\n",
      "epoch:35 step:165600[D loss: 0.999973] [G loss: 1.000022]\n",
      "##############\n",
      "[2.62149463 2.31598207 2.29915296 3.6156696  1.59628312 7.35086845\n",
      " 2.67161392 3.97585615 4.0593789  4.65297079]\n",
      "##########\n",
      "epoch:35 step:165605[D loss: 1.000006] [G loss: 1.000037]\n",
      "epoch:35 step:165610[D loss: 1.000091] [G loss: 0.999892]\n",
      "epoch:35 step:165615[D loss: 0.999886] [G loss: 1.000092]\n",
      "epoch:35 step:165620[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:35 step:165625[D loss: 1.000003] [G loss: 1.000065]\n",
      "epoch:35 step:165630[D loss: 0.999935] [G loss: 1.000107]\n",
      "epoch:35 step:165635[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:35 step:165640[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:35 step:165645[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:35 step:165650[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:35 step:165655[D loss: 1.000023] [G loss: 0.999998]\n",
      "epoch:35 step:165660[D loss: 0.999941] [G loss: 1.000061]\n",
      "epoch:35 step:165665[D loss: 0.999959] [G loss: 1.000135]\n",
      "epoch:35 step:165670[D loss: 0.999948] [G loss: 1.000146]\n",
      "epoch:35 step:165675[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:35 step:165680[D loss: 0.999951] [G loss: 1.000062]\n",
      "epoch:35 step:165685[D loss: 0.999949] [G loss: 1.000095]\n",
      "epoch:35 step:165690[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:35 step:165695[D loss: 1.000025] [G loss: 1.000041]\n",
      "epoch:35 step:165700[D loss: 0.999940] [G loss: 1.000068]\n",
      "epoch:35 step:165705[D loss: 1.000042] [G loss: 1.000279]\n",
      "epoch:35 step:165710[D loss: 0.999859] [G loss: 1.000161]\n",
      "epoch:35 step:165715[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:35 step:165720[D loss: 1.000005] [G loss: 1.000126]\n",
      "epoch:35 step:165725[D loss: 0.999957] [G loss: 1.000119]\n",
      "epoch:35 step:165730[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:35 step:165735[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:35 step:165740[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:35 step:165745[D loss: 0.999927] [G loss: 1.000079]\n",
      "epoch:35 step:165750[D loss: 1.000089] [G loss: 0.999924]\n",
      "epoch:35 step:165755[D loss: 0.999921] [G loss: 1.000109]\n",
      "epoch:35 step:165760[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:35 step:165765[D loss: 1.000083] [G loss: 1.000092]\n",
      "epoch:35 step:165770[D loss: 0.999951] [G loss: 1.000050]\n",
      "epoch:35 step:165775[D loss: 1.000059] [G loss: 1.000096]\n",
      "epoch:35 step:165780[D loss: 0.999899] [G loss: 1.000153]\n",
      "epoch:35 step:165785[D loss: 0.999952] [G loss: 1.000097]\n",
      "epoch:35 step:165790[D loss: 1.000014] [G loss: 1.000023]\n",
      "epoch:35 step:165795[D loss: 0.999939] [G loss: 1.000319]\n",
      "epoch:35 step:165800[D loss: 0.999961] [G loss: 1.000173]\n",
      "##############\n",
      "[2.59974696 2.32044749 2.33123882 3.78078    1.54894179 7.05280685\n",
      " 2.49006792 3.91749707 3.99579302 5.59701087]\n",
      "##########\n",
      "epoch:35 step:165805[D loss: 1.000106] [G loss: 0.999871]\n",
      "epoch:35 step:165810[D loss: 1.000179] [G loss: 1.000039]\n",
      "epoch:35 step:165815[D loss: 0.999986] [G loss: 1.000167]\n",
      "epoch:35 step:165820[D loss: 0.999957] [G loss: 1.000138]\n",
      "epoch:35 step:165825[D loss: 0.999983] [G loss: 1.000147]\n",
      "epoch:35 step:165830[D loss: 0.999971] [G loss: 1.000122]\n",
      "epoch:35 step:165835[D loss: 0.999997] [G loss: 1.000057]\n",
      "epoch:35 step:165840[D loss: 0.999984] [G loss: 1.000003]\n",
      "epoch:35 step:165845[D loss: 1.000013] [G loss: 1.000120]\n",
      "epoch:35 step:165850[D loss: 1.000006] [G loss: 1.000093]\n",
      "epoch:35 step:165855[D loss: 1.000011] [G loss: 1.000055]\n",
      "epoch:35 step:165860[D loss: 0.999917] [G loss: 1.000012]\n",
      "epoch:35 step:165865[D loss: 1.000364] [G loss: 0.999596]\n",
      "epoch:35 step:165870[D loss: 0.999942] [G loss: 1.000097]\n",
      "epoch:35 step:165875[D loss: 0.999934] [G loss: 1.000061]\n",
      "epoch:35 step:165880[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:35 step:165885[D loss: 1.000023] [G loss: 1.000007]\n",
      "epoch:35 step:165890[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:35 step:165895[D loss: 0.999938] [G loss: 1.000103]\n",
      "epoch:35 step:165900[D loss: 1.000048] [G loss: 1.000005]\n",
      "epoch:35 step:165905[D loss: 0.999956] [G loss: 1.000005]\n",
      "epoch:35 step:165910[D loss: 1.000026] [G loss: 1.000145]\n",
      "epoch:35 step:165915[D loss: 0.999995] [G loss: 1.000135]\n",
      "epoch:35 step:165920[D loss: 1.000036] [G loss: 0.999973]\n",
      "epoch:35 step:165925[D loss: 0.999963] [G loss: 1.000097]\n",
      "epoch:35 step:165930[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:35 step:165935[D loss: 0.999955] [G loss: 1.000070]\n",
      "epoch:35 step:165940[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:35 step:165945[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:35 step:165950[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:35 step:165955[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:35 step:165960[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:35 step:165965[D loss: 1.000009] [G loss: 1.000081]\n",
      "epoch:35 step:165970[D loss: 1.000019] [G loss: 0.999985]\n",
      "epoch:35 step:165975[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:35 step:165980[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:35 step:165985[D loss: 0.999958] [G loss: 1.000106]\n",
      "epoch:35 step:165990[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:35 step:165995[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:35 step:166000[D loss: 0.999959] [G loss: 0.999986]\n",
      "##############\n",
      "[2.55560849 2.25446707 2.30271168 3.72362045 1.57208216 8.34059029\n",
      " 2.56104766 3.86476875 4.06952833 4.04168279]\n",
      "##########\n",
      "epoch:35 step:166005[D loss: 0.999963] [G loss: 1.000037]\n",
      "epoch:35 step:166010[D loss: 1.000125] [G loss: 0.999958]\n",
      "epoch:35 step:166015[D loss: 0.999921] [G loss: 1.000100]\n",
      "epoch:35 step:166020[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:35 step:166025[D loss: 1.000140] [G loss: 1.000000]\n",
      "epoch:35 step:166030[D loss: 0.999888] [G loss: 1.000184]\n",
      "epoch:35 step:166035[D loss: 1.000041] [G loss: 1.000037]\n",
      "epoch:35 step:166040[D loss: 1.000004] [G loss: 1.000044]\n",
      "epoch:35 step:166045[D loss: 1.000033] [G loss: 0.999957]\n",
      "epoch:35 step:166050[D loss: 0.999920] [G loss: 1.000081]\n",
      "epoch:35 step:166055[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:35 step:166060[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:35 step:166065[D loss: 0.999927] [G loss: 1.000096]\n",
      "epoch:35 step:166070[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:35 step:166075[D loss: 1.000021] [G loss: 0.999986]\n",
      "epoch:35 step:166080[D loss: 1.000059] [G loss: 1.000021]\n",
      "epoch:35 step:166085[D loss: 1.000039] [G loss: 0.999965]\n",
      "epoch:35 step:166090[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:35 step:166095[D loss: 1.000016] [G loss: 0.999988]\n",
      "epoch:35 step:166100[D loss: 1.000045] [G loss: 0.999976]\n",
      "epoch:35 step:166105[D loss: 1.000008] [G loss: 0.999988]\n",
      "epoch:35 step:166110[D loss: 0.999974] [G loss: 1.000036]\n",
      "epoch:35 step:166115[D loss: 0.999973] [G loss: 1.000018]\n",
      "epoch:35 step:166120[D loss: 0.999962] [G loss: 1.000021]\n",
      "epoch:35 step:166125[D loss: 1.000011] [G loss: 1.000009]\n",
      "epoch:35 step:166130[D loss: 0.999947] [G loss: 1.000113]\n",
      "epoch:35 step:166135[D loss: 1.000040] [G loss: 1.000079]\n",
      "epoch:35 step:166140[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:35 step:166145[D loss: 1.000054] [G loss: 0.999980]\n",
      "epoch:35 step:166150[D loss: 0.999990] [G loss: 1.000008]\n",
      "epoch:35 step:166155[D loss: 0.999940] [G loss: 1.000049]\n",
      "epoch:35 step:166160[D loss: 0.999947] [G loss: 1.000035]\n",
      "epoch:35 step:166165[D loss: 1.000024] [G loss: 1.000012]\n",
      "epoch:35 step:166170[D loss: 0.999943] [G loss: 1.000114]\n",
      "epoch:35 step:166175[D loss: 0.999954] [G loss: 1.000120]\n",
      "epoch:35 step:166180[D loss: 0.999948] [G loss: 1.000124]\n",
      "epoch:35 step:166185[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:35 step:166190[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:35 step:166195[D loss: 0.999992] [G loss: 1.000085]\n",
      "epoch:35 step:166200[D loss: 0.999950] [G loss: 1.000062]\n",
      "##############\n",
      "[2.59247236 2.32742898 2.3420407  3.92807733 1.64048828 6.75141906\n",
      " 2.44346813 3.95848677 3.89567951 5.45100428]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:166205[D loss: 0.999985] [G loss: 1.000149]\n",
      "epoch:35 step:166210[D loss: 0.999958] [G loss: 1.000127]\n",
      "epoch:35 step:166215[D loss: 1.000133] [G loss: 0.999900]\n",
      "epoch:35 step:166220[D loss: 0.999954] [G loss: 1.000131]\n",
      "epoch:35 step:166225[D loss: 0.999898] [G loss: 1.000187]\n",
      "epoch:35 step:166230[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:35 step:166235[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:35 step:166240[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:35 step:166245[D loss: 1.000043] [G loss: 0.999963]\n",
      "epoch:35 step:166250[D loss: 1.000035] [G loss: 0.999906]\n",
      "epoch:35 step:166255[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:35 step:166260[D loss: 1.000098] [G loss: 0.999918]\n",
      "epoch:35 step:166265[D loss: 1.000047] [G loss: 1.000120]\n",
      "epoch:35 step:166270[D loss: 1.000187] [G loss: 1.000149]\n",
      "epoch:35 step:166275[D loss: 0.999904] [G loss: 1.000153]\n",
      "epoch:35 step:166280[D loss: 0.999833] [G loss: 1.000279]\n",
      "epoch:35 step:166285[D loss: 0.999927] [G loss: 1.000105]\n",
      "epoch:35 step:166290[D loss: 0.999956] [G loss: 1.000066]\n",
      "epoch:35 step:166295[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:35 step:166300[D loss: 1.000131] [G loss: 0.999768]\n",
      "epoch:35 step:166305[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:35 step:166310[D loss: 0.999944] [G loss: 1.000007]\n",
      "epoch:35 step:166315[D loss: 1.000126] [G loss: 0.999999]\n",
      "epoch:35 step:166320[D loss: 1.000020] [G loss: 1.000197]\n",
      "epoch:35 step:166325[D loss: 0.999837] [G loss: 1.000221]\n",
      "epoch:35 step:166330[D loss: 0.999996] [G loss: 1.000125]\n",
      "epoch:35 step:166335[D loss: 0.999906] [G loss: 1.000170]\n",
      "epoch:35 step:166340[D loss: 0.999933] [G loss: 1.000124]\n",
      "epoch:35 step:166345[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:35 step:166350[D loss: 1.000000] [G loss: 0.999962]\n",
      "epoch:35 step:166355[D loss: 1.000032] [G loss: 0.999945]\n",
      "epoch:35 step:166360[D loss: 0.999880] [G loss: 1.000089]\n",
      "epoch:35 step:166365[D loss: 1.000111] [G loss: 0.999995]\n",
      "epoch:35 step:166370[D loss: 0.999934] [G loss: 1.000049]\n",
      "epoch:35 step:166375[D loss: 1.000004] [G loss: 0.999993]\n",
      "epoch:35 step:166380[D loss: 0.999940] [G loss: 1.000168]\n",
      "epoch:35 step:166385[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:35 step:166390[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:35 step:166395[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:35 step:166400[D loss: 1.000041] [G loss: 1.000065]\n",
      "##############\n",
      "[2.532228   2.37844977 2.28621662 3.66974079 1.59950634 7.69638705\n",
      " 2.40279361 3.82648459 4.08407466 5.2318051 ]\n",
      "##########\n",
      "epoch:35 step:166405[D loss: 0.999940] [G loss: 1.000062]\n",
      "epoch:35 step:166410[D loss: 1.000060] [G loss: 0.999928]\n",
      "epoch:35 step:166415[D loss: 1.000180] [G loss: 0.999872]\n",
      "epoch:35 step:166420[D loss: 1.000076] [G loss: 1.000151]\n",
      "epoch:35 step:166425[D loss: 0.999794] [G loss: 1.000429]\n",
      "epoch:35 step:166430[D loss: 0.999888] [G loss: 1.000242]\n",
      "epoch:35 step:166435[D loss: 0.999984] [G loss: 1.000233]\n",
      "epoch:35 step:166440[D loss: 1.000096] [G loss: 1.000186]\n",
      "epoch:35 step:166445[D loss: 0.999951] [G loss: 1.000378]\n",
      "epoch:35 step:166450[D loss: 0.999885] [G loss: 1.000221]\n",
      "epoch:35 step:166455[D loss: 1.000240] [G loss: 1.000106]\n",
      "epoch:35 step:166460[D loss: 0.999872] [G loss: 1.000398]\n",
      "epoch:35 step:166465[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:35 step:166470[D loss: 1.000064] [G loss: 0.999887]\n",
      "epoch:35 step:166475[D loss: 1.000269] [G loss: 0.999524]\n",
      "epoch:35 step:166480[D loss: 1.000088] [G loss: 0.999585]\n",
      "epoch:35 step:166485[D loss: 0.999850] [G loss: 1.000072]\n",
      "epoch:35 step:166490[D loss: 0.999997] [G loss: 0.999889]\n",
      "epoch:35 step:166495[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:35 step:166500[D loss: 0.999926] [G loss: 1.000101]\n",
      "epoch:35 step:166505[D loss: 0.999960] [G loss: 0.999955]\n",
      "epoch:35 step:166510[D loss: 1.000142] [G loss: 1.000178]\n",
      "epoch:35 step:166515[D loss: 1.000273] [G loss: 0.999799]\n",
      "epoch:35 step:166520[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:35 step:166525[D loss: 1.000058] [G loss: 1.000301]\n",
      "epoch:35 step:166530[D loss: 0.999997] [G loss: 1.000151]\n",
      "epoch:35 step:166535[D loss: 0.999822] [G loss: 1.000184]\n",
      "epoch:35 step:166540[D loss: 0.999978] [G loss: 1.000154]\n",
      "epoch:35 step:166545[D loss: 0.999927] [G loss: 1.000102]\n",
      "epoch:35 step:166550[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:35 step:166555[D loss: 0.999998] [G loss: 1.000001]\n",
      "epoch:35 step:166560[D loss: 1.000091] [G loss: 1.000055]\n",
      "epoch:35 step:166565[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:35 step:166570[D loss: 0.999997] [G loss: 1.000085]\n",
      "epoch:35 step:166575[D loss: 0.999994] [G loss: 1.000087]\n",
      "epoch:35 step:166580[D loss: 0.999901] [G loss: 1.000187]\n",
      "epoch:35 step:166585[D loss: 0.999880] [G loss: 1.000179]\n",
      "epoch:35 step:166590[D loss: 0.999963] [G loss: 1.000159]\n",
      "epoch:35 step:166595[D loss: 0.999985] [G loss: 1.000270]\n",
      "epoch:35 step:166600[D loss: 0.999890] [G loss: 1.000191]\n",
      "##############\n",
      "[2.61709905 2.29302967 2.29321968 3.68475823 1.64525388 7.47400154\n",
      " 2.50099893 3.98330854 4.1348716  5.68129422]\n",
      "##########\n",
      "epoch:35 step:166605[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:35 step:166610[D loss: 0.999963] [G loss: 1.000125]\n",
      "epoch:35 step:166615[D loss: 0.999921] [G loss: 1.000132]\n",
      "epoch:35 step:166620[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:35 step:166625[D loss: 1.000039] [G loss: 1.000054]\n",
      "epoch:35 step:166630[D loss: 1.000044] [G loss: 0.999963]\n",
      "epoch:35 step:166635[D loss: 0.999950] [G loss: 1.000108]\n",
      "epoch:35 step:166640[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:35 step:166645[D loss: 1.000005] [G loss: 1.000085]\n",
      "epoch:35 step:166650[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:35 step:166655[D loss: 0.999959] [G loss: 1.000181]\n",
      "epoch:35 step:166660[D loss: 1.000062] [G loss: 1.000013]\n",
      "epoch:35 step:166665[D loss: 0.999928] [G loss: 1.000167]\n",
      "epoch:35 step:166670[D loss: 0.999977] [G loss: 1.000121]\n",
      "epoch:35 step:166675[D loss: 1.000006] [G loss: 0.999963]\n",
      "epoch:35 step:166680[D loss: 0.999948] [G loss: 1.000092]\n",
      "epoch:35 step:166685[D loss: 1.000034] [G loss: 0.999913]\n",
      "epoch:35 step:166690[D loss: 1.000119] [G loss: 1.000046]\n",
      "epoch:35 step:166695[D loss: 0.999913] [G loss: 1.000134]\n",
      "epoch:35 step:166700[D loss: 0.999987] [G loss: 1.000149]\n",
      "epoch:35 step:166705[D loss: 1.000099] [G loss: 0.999835]\n",
      "epoch:35 step:166710[D loss: 0.999862] [G loss: 1.000145]\n",
      "epoch:35 step:166715[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:35 step:166720[D loss: 0.999950] [G loss: 1.000149]\n",
      "epoch:35 step:166725[D loss: 0.999981] [G loss: 1.000136]\n",
      "epoch:35 step:166730[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:35 step:166735[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:35 step:166740[D loss: 1.000128] [G loss: 0.999860]\n",
      "epoch:35 step:166745[D loss: 0.999920] [G loss: 1.000089]\n",
      "epoch:35 step:166750[D loss: 1.000006] [G loss: 0.999982]\n",
      "epoch:35 step:166755[D loss: 1.000021] [G loss: 1.000018]\n",
      "epoch:35 step:166760[D loss: 1.000019] [G loss: 0.999920]\n",
      "epoch:35 step:166765[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:35 step:166770[D loss: 0.999906] [G loss: 1.000213]\n",
      "epoch:35 step:166775[D loss: 0.999838] [G loss: 1.000242]\n",
      "epoch:35 step:166780[D loss: 1.000031] [G loss: 1.000113]\n",
      "epoch:35 step:166785[D loss: 0.999945] [G loss: 1.000232]\n",
      "epoch:35 step:166790[D loss: 0.999910] [G loss: 1.000188]\n",
      "epoch:35 step:166795[D loss: 0.999975] [G loss: 1.000127]\n",
      "epoch:35 step:166800[D loss: 0.999919] [G loss: 1.000157]\n",
      "##############\n",
      "[2.5922367  2.31741497 2.26215045 3.52896012 1.67351619 7.30662369\n",
      " 2.37520963 3.76149106 4.05795652 5.35685223]\n",
      "##########\n",
      "epoch:35 step:166805[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:35 step:166810[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:35 step:166815[D loss: 0.999976] [G loss: 1.000017]\n",
      "epoch:35 step:166820[D loss: 1.000031] [G loss: 0.999934]\n",
      "epoch:35 step:166825[D loss: 1.000020] [G loss: 0.999970]\n",
      "epoch:35 step:166830[D loss: 1.000016] [G loss: 0.999941]\n",
      "epoch:35 step:166835[D loss: 1.000129] [G loss: 0.999775]\n",
      "epoch:35 step:166840[D loss: 0.999847] [G loss: 1.000184]\n",
      "epoch:35 step:166845[D loss: 1.000017] [G loss: 1.000081]\n",
      "epoch:35 step:166850[D loss: 0.999888] [G loss: 1.000067]\n",
      "epoch:35 step:166855[D loss: 0.999996] [G loss: 1.000075]\n",
      "epoch:35 step:166860[D loss: 0.999941] [G loss: 1.000140]\n",
      "epoch:35 step:166865[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:35 step:166870[D loss: 0.999958] [G loss: 1.000059]\n",
      "epoch:35 step:166875[D loss: 1.000228] [G loss: 0.999901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:166880[D loss: 0.999809] [G loss: 0.999976]\n",
      "epoch:35 step:166885[D loss: 1.000008] [G loss: 1.000004]\n",
      "epoch:35 step:166890[D loss: 1.000001] [G loss: 1.000101]\n",
      "epoch:35 step:166895[D loss: 1.000017] [G loss: 1.000124]\n",
      "epoch:35 step:166900[D loss: 0.999924] [G loss: 1.000119]\n",
      "epoch:35 step:166905[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:35 step:166910[D loss: 1.000025] [G loss: 0.999976]\n",
      "epoch:35 step:166915[D loss: 1.000036] [G loss: 0.999930]\n",
      "epoch:35 step:166920[D loss: 1.000075] [G loss: 1.000082]\n",
      "epoch:35 step:166925[D loss: 0.999987] [G loss: 0.999858]\n",
      "epoch:35 step:166930[D loss: 0.999955] [G loss: 1.000157]\n",
      "epoch:35 step:166935[D loss: 0.999849] [G loss: 1.000114]\n",
      "epoch:35 step:166940[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:35 step:166945[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:35 step:166950[D loss: 1.000143] [G loss: 0.999934]\n",
      "epoch:35 step:166955[D loss: 0.999869] [G loss: 1.000122]\n",
      "epoch:35 step:166960[D loss: 0.999969] [G loss: 1.000032]\n",
      "epoch:35 step:166965[D loss: 1.000014] [G loss: 0.999984]\n",
      "epoch:35 step:166970[D loss: 0.999930] [G loss: 1.000180]\n",
      "epoch:35 step:166975[D loss: 0.999852] [G loss: 1.000411]\n",
      "epoch:35 step:166980[D loss: 0.999890] [G loss: 1.000155]\n",
      "epoch:35 step:166985[D loss: 0.999954] [G loss: 1.000110]\n",
      "epoch:35 step:166990[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:35 step:166995[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:35 step:167000[D loss: 0.999958] [G loss: 1.000057]\n",
      "##############\n",
      "[2.59257478 2.25832371 2.22588942 3.88079153 1.71814925 7.7639873\n",
      " 2.46638741 3.91578521 3.97235867 5.77597882]\n",
      "##########\n",
      "epoch:35 step:167005[D loss: 0.999949] [G loss: 1.000114]\n",
      "epoch:35 step:167010[D loss: 0.999944] [G loss: 1.000101]\n",
      "epoch:35 step:167015[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:35 step:167020[D loss: 1.000029] [G loss: 1.000138]\n",
      "epoch:35 step:167025[D loss: 0.999955] [G loss: 1.000043]\n",
      "epoch:35 step:167030[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:35 step:167035[D loss: 1.000032] [G loss: 1.000018]\n",
      "epoch:35 step:167040[D loss: 0.999957] [G loss: 1.000036]\n",
      "epoch:35 step:167045[D loss: 1.000004] [G loss: 1.000000]\n",
      "epoch:35 step:167050[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:35 step:167055[D loss: 1.000016] [G loss: 0.999972]\n",
      "epoch:35 step:167060[D loss: 1.000036] [G loss: 1.000044]\n",
      "epoch:35 step:167065[D loss: 1.000026] [G loss: 1.000027]\n",
      "epoch:35 step:167070[D loss: 0.999936] [G loss: 1.000051]\n",
      "epoch:35 step:167075[D loss: 1.000075] [G loss: 1.000050]\n",
      "epoch:35 step:167080[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:35 step:167085[D loss: 1.000006] [G loss: 1.000134]\n",
      "epoch:35 step:167090[D loss: 0.999951] [G loss: 1.000103]\n",
      "epoch:35 step:167095[D loss: 0.999962] [G loss: 1.000125]\n",
      "epoch:35 step:167100[D loss: 0.999984] [G loss: 1.000149]\n",
      "epoch:35 step:167105[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:35 step:167110[D loss: 1.000074] [G loss: 0.999962]\n",
      "epoch:35 step:167115[D loss: 1.000022] [G loss: 0.999923]\n",
      "epoch:35 step:167120[D loss: 0.999922] [G loss: 1.000125]\n",
      "epoch:35 step:167125[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:35 step:167130[D loss: 0.999907] [G loss: 1.000249]\n",
      "epoch:35 step:167135[D loss: 0.999990] [G loss: 1.000128]\n",
      "epoch:35 step:167140[D loss: 0.999958] [G loss: 1.000156]\n",
      "epoch:35 step:167145[D loss: 1.000009] [G loss: 0.999955]\n",
      "epoch:35 step:167150[D loss: 1.000002] [G loss: 1.000040]\n",
      "epoch:35 step:167155[D loss: 1.000150] [G loss: 0.999792]\n",
      "epoch:35 step:167160[D loss: 1.000060] [G loss: 1.000041]\n",
      "epoch:35 step:167165[D loss: 0.999822] [G loss: 1.000120]\n",
      "epoch:35 step:167170[D loss: 0.999889] [G loss: 1.000126]\n",
      "epoch:35 step:167175[D loss: 0.999994] [G loss: 1.000140]\n",
      "epoch:35 step:167180[D loss: 0.999973] [G loss: 1.000137]\n",
      "epoch:35 step:167185[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:35 step:167190[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:35 step:167195[D loss: 0.999963] [G loss: 1.000116]\n",
      "epoch:35 step:167200[D loss: 1.000029] [G loss: 0.999980]\n",
      "##############\n",
      "[2.64622347 2.27260322 2.36368128 4.00792616 1.64144028 7.61292052\n",
      " 2.48561537 3.94618447 4.17658674 5.33528497]\n",
      "##########\n",
      "epoch:35 step:167205[D loss: 1.000022] [G loss: 1.000078]\n",
      "epoch:35 step:167210[D loss: 0.999963] [G loss: 1.000005]\n",
      "epoch:35 step:167215[D loss: 1.000104] [G loss: 0.999788]\n",
      "epoch:35 step:167220[D loss: 1.000067] [G loss: 1.000030]\n",
      "epoch:35 step:167225[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:35 step:167230[D loss: 1.000073] [G loss: 1.000023]\n",
      "epoch:35 step:167235[D loss: 0.999768] [G loss: 1.000349]\n",
      "epoch:35 step:167240[D loss: 0.999918] [G loss: 1.000327]\n",
      "epoch:35 step:167245[D loss: 0.999957] [G loss: 1.000167]\n",
      "epoch:35 step:167250[D loss: 0.999967] [G loss: 1.000137]\n",
      "epoch:35 step:167255[D loss: 1.000044] [G loss: 0.999926]\n",
      "epoch:35 step:167260[D loss: 0.999945] [G loss: 1.000142]\n",
      "epoch:35 step:167265[D loss: 0.999920] [G loss: 1.000035]\n",
      "epoch:35 step:167270[D loss: 0.999920] [G loss: 1.000118]\n",
      "epoch:35 step:167275[D loss: 1.000027] [G loss: 1.000039]\n",
      "epoch:35 step:167280[D loss: 0.999928] [G loss: 1.000053]\n",
      "epoch:35 step:167285[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:35 step:167290[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:35 step:167295[D loss: 1.000000] [G loss: 1.000043]\n",
      "epoch:35 step:167300[D loss: 0.999924] [G loss: 1.000168]\n",
      "epoch:35 step:167305[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:35 step:167310[D loss: 0.999952] [G loss: 1.000045]\n",
      "epoch:35 step:167315[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:35 step:167320[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:35 step:167325[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:35 step:167330[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:35 step:167335[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:35 step:167340[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:35 step:167345[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:35 step:167350[D loss: 0.999990] [G loss: 1.000089]\n",
      "epoch:35 step:167355[D loss: 0.999896] [G loss: 1.000146]\n",
      "epoch:35 step:167360[D loss: 0.999997] [G loss: 1.000093]\n",
      "epoch:35 step:167365[D loss: 0.999962] [G loss: 1.000138]\n",
      "epoch:35 step:167370[D loss: 1.000003] [G loss: 1.000069]\n",
      "epoch:35 step:167375[D loss: 0.999975] [G loss: 1.000104]\n",
      "epoch:35 step:167380[D loss: 0.999948] [G loss: 1.000086]\n",
      "epoch:35 step:167385[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:35 step:167390[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:35 step:167395[D loss: 1.000005] [G loss: 0.999976]\n",
      "epoch:35 step:167400[D loss: 1.000012] [G loss: 1.000040]\n",
      "##############\n",
      "[2.5487737  2.24046647 2.23933048 3.60408789 1.61610033 7.41919252\n",
      " 2.49910166 3.81930068 3.94308296 4.99879162]\n",
      "##########\n",
      "epoch:35 step:167405[D loss: 1.000015] [G loss: 0.999947]\n",
      "epoch:35 step:167410[D loss: 1.000006] [G loss: 1.000008]\n",
      "epoch:35 step:167415[D loss: 0.999989] [G loss: 1.000019]\n",
      "epoch:35 step:167420[D loss: 0.999983] [G loss: 1.000152]\n",
      "epoch:35 step:167425[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:35 step:167430[D loss: 1.000038] [G loss: 1.000050]\n",
      "epoch:35 step:167435[D loss: 0.999909] [G loss: 1.000163]\n",
      "epoch:35 step:167440[D loss: 1.000100] [G loss: 0.999967]\n",
      "epoch:35 step:167445[D loss: 0.999950] [G loss: 1.000131]\n",
      "epoch:35 step:167450[D loss: 0.999937] [G loss: 1.000097]\n",
      "epoch:35 step:167455[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:35 step:167460[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:35 step:167465[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:35 step:167470[D loss: 1.000027] [G loss: 1.000030]\n",
      "epoch:35 step:167475[D loss: 0.999941] [G loss: 1.000095]\n",
      "epoch:35 step:167480[D loss: 1.000018] [G loss: 1.000052]\n",
      "epoch:35 step:167485[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:35 step:167490[D loss: 1.000001] [G loss: 1.000012]\n",
      "epoch:35 step:167495[D loss: 1.000014] [G loss: 1.000024]\n",
      "epoch:35 step:167500[D loss: 1.000059] [G loss: 1.000009]\n",
      "epoch:35 step:167505[D loss: 0.999960] [G loss: 1.000228]\n",
      "epoch:35 step:167510[D loss: 0.999962] [G loss: 1.000110]\n",
      "epoch:35 step:167515[D loss: 1.000024] [G loss: 0.999956]\n",
      "epoch:35 step:167520[D loss: 1.000027] [G loss: 0.999947]\n",
      "epoch:35 step:167525[D loss: 1.000165] [G loss: 0.999842]\n",
      "epoch:35 step:167530[D loss: 1.000093] [G loss: 0.999858]\n",
      "epoch:35 step:167535[D loss: 0.999954] [G loss: 0.999955]\n",
      "epoch:35 step:167540[D loss: 1.000034] [G loss: 1.000007]\n",
      "epoch:35 step:167545[D loss: 1.000177] [G loss: 0.999920]\n",
      "epoch:35 step:167550[D loss: 0.999939] [G loss: 1.000122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:167555[D loss: 0.999903] [G loss: 1.000099]\n",
      "epoch:35 step:167560[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:35 step:167565[D loss: 0.999919] [G loss: 1.000207]\n",
      "epoch:35 step:167570[D loss: 1.000019] [G loss: 0.999997]\n",
      "epoch:35 step:167575[D loss: 0.999965] [G loss: 1.000045]\n",
      "epoch:35 step:167580[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:35 step:167585[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:35 step:167590[D loss: 1.000072] [G loss: 0.999910]\n",
      "epoch:35 step:167595[D loss: 0.999992] [G loss: 0.999985]\n",
      "epoch:35 step:167600[D loss: 0.999944] [G loss: 1.000137]\n",
      "##############\n",
      "[2.5672485  2.28799035 2.2107675  3.76769287 1.65360571 7.3925724\n",
      " 2.49712614 3.82440309 4.1619413  5.18636175]\n",
      "##########\n",
      "epoch:35 step:167605[D loss: 0.999934] [G loss: 1.000086]\n",
      "epoch:35 step:167610[D loss: 1.000022] [G loss: 1.000054]\n",
      "epoch:35 step:167615[D loss: 0.999948] [G loss: 1.000079]\n",
      "epoch:35 step:167620[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:35 step:167625[D loss: 0.999969] [G loss: 1.000128]\n",
      "epoch:35 step:167630[D loss: 0.999997] [G loss: 1.000001]\n",
      "epoch:35 step:167635[D loss: 0.999984] [G loss: 1.000004]\n",
      "epoch:35 step:167640[D loss: 1.000034] [G loss: 0.999952]\n",
      "epoch:35 step:167645[D loss: 1.000017] [G loss: 0.999931]\n",
      "epoch:35 step:167650[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:35 step:167655[D loss: 1.000061] [G loss: 1.000051]\n",
      "epoch:35 step:167660[D loss: 1.000065] [G loss: 0.999982]\n",
      "epoch:35 step:167665[D loss: 1.000025] [G loss: 0.999940]\n",
      "epoch:35 step:167670[D loss: 1.000046] [G loss: 1.000063]\n",
      "epoch:35 step:167675[D loss: 0.999951] [G loss: 1.000098]\n",
      "epoch:35 step:167680[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:35 step:167685[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:35 step:167690[D loss: 0.999982] [G loss: 1.000108]\n",
      "epoch:35 step:167695[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:35 step:167700[D loss: 0.999980] [G loss: 1.000109]\n",
      "epoch:35 step:167705[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:35 step:167710[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:35 step:167715[D loss: 0.999962] [G loss: 1.000111]\n",
      "epoch:35 step:167720[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:35 step:167725[D loss: 1.000048] [G loss: 0.999989]\n",
      "epoch:35 step:167730[D loss: 0.999897] [G loss: 1.000135]\n",
      "epoch:35 step:167735[D loss: 0.999985] [G loss: 1.000011]\n",
      "epoch:35 step:167740[D loss: 1.000004] [G loss: 0.999967]\n",
      "epoch:35 step:167745[D loss: 1.000170] [G loss: 0.999917]\n",
      "epoch:35 step:167750[D loss: 0.999932] [G loss: 1.000201]\n",
      "epoch:35 step:167755[D loss: 0.999934] [G loss: 0.999977]\n",
      "epoch:35 step:167760[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:35 step:167765[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:35 step:167770[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:35 step:167775[D loss: 0.999933] [G loss: 1.000139]\n",
      "epoch:35 step:167780[D loss: 0.999976] [G loss: 1.000124]\n",
      "epoch:35 step:167785[D loss: 1.000162] [G loss: 0.999912]\n",
      "epoch:35 step:167790[D loss: 1.000048] [G loss: 0.999907]\n",
      "epoch:35 step:167795[D loss: 1.000063] [G loss: 1.000022]\n",
      "epoch:35 step:167800[D loss: 1.000013] [G loss: 1.000001]\n",
      "##############\n",
      "[2.62798439 2.29823918 2.20215644 3.66660345 1.69173573 7.79161679\n",
      " 2.4093004  3.74455729 4.10018018 7.14868929]\n",
      "##########\n",
      "epoch:35 step:167805[D loss: 1.000014] [G loss: 0.999997]\n",
      "epoch:35 step:167810[D loss: 0.999919] [G loss: 1.000175]\n",
      "epoch:35 step:167815[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:35 step:167820[D loss: 0.999976] [G loss: 1.000125]\n",
      "epoch:35 step:167825[D loss: 1.000006] [G loss: 0.999948]\n",
      "epoch:35 step:167830[D loss: 1.000109] [G loss: 0.999771]\n",
      "epoch:35 step:167835[D loss: 1.000180] [G loss: 0.999727]\n",
      "epoch:35 step:167840[D loss: 0.999967] [G loss: 0.999971]\n",
      "epoch:35 step:167845[D loss: 1.000103] [G loss: 1.000163]\n",
      "epoch:35 step:167850[D loss: 0.999976] [G loss: 0.999940]\n",
      "epoch:35 step:167855[D loss: 1.000093] [G loss: 0.999989]\n",
      "epoch:35 step:167860[D loss: 0.999926] [G loss: 1.000091]\n",
      "epoch:35 step:167865[D loss: 1.000025] [G loss: 0.999991]\n",
      "epoch:35 step:167870[D loss: 1.000043] [G loss: 0.999849]\n",
      "epoch:35 step:167875[D loss: 1.000042] [G loss: 0.999879]\n",
      "epoch:35 step:167880[D loss: 0.999962] [G loss: 0.999877]\n",
      "epoch:35 step:167885[D loss: 1.000038] [G loss: 0.999960]\n",
      "epoch:35 step:167890[D loss: 0.999965] [G loss: 1.000183]\n",
      "epoch:35 step:167895[D loss: 0.999909] [G loss: 1.000088]\n",
      "epoch:35 step:167900[D loss: 1.000021] [G loss: 1.000052]\n",
      "epoch:35 step:167905[D loss: 0.999923] [G loss: 1.000249]\n",
      "epoch:35 step:167910[D loss: 0.999883] [G loss: 1.000199]\n",
      "epoch:35 step:167915[D loss: 0.999971] [G loss: 1.000168]\n",
      "epoch:35 step:167920[D loss: 0.999999] [G loss: 1.000251]\n",
      "epoch:35 step:167925[D loss: 0.999905] [G loss: 1.000037]\n",
      "epoch:35 step:167930[D loss: 1.000003] [G loss: 0.999998]\n",
      "epoch:35 step:167935[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:35 step:167940[D loss: 0.999955] [G loss: 1.000141]\n",
      "epoch:35 step:167945[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:35 step:167950[D loss: 1.000084] [G loss: 0.999918]\n",
      "epoch:35 step:167955[D loss: 0.999918] [G loss: 1.000176]\n",
      "epoch:35 step:167960[D loss: 1.000074] [G loss: 0.999976]\n",
      "epoch:35 step:167965[D loss: 0.999990] [G loss: 1.000274]\n",
      "epoch:35 step:167970[D loss: 0.999968] [G loss: 0.999984]\n",
      "epoch:35 step:167975[D loss: 0.999926] [G loss: 1.000097]\n",
      "epoch:35 step:167980[D loss: 0.999935] [G loss: 1.000122]\n",
      "epoch:35 step:167985[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:35 step:167990[D loss: 0.999976] [G loss: 1.000104]\n",
      "epoch:35 step:167995[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:35 step:168000[D loss: 1.000005] [G loss: 1.000073]\n",
      "##############\n",
      "[2.62503904 2.37695266 2.32011513 3.71403435 1.71231877 7.07260496\n",
      " 2.38152203 3.81285836 4.08619656 5.3781779 ]\n",
      "##########\n",
      "epoch:35 step:168005[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:35 step:168010[D loss: 1.000014] [G loss: 1.000107]\n",
      "epoch:35 step:168015[D loss: 1.000083] [G loss: 1.000024]\n",
      "epoch:35 step:168020[D loss: 0.999882] [G loss: 1.000145]\n",
      "epoch:35 step:168025[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:35 step:168030[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:35 step:168035[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:35 step:168040[D loss: 0.999911] [G loss: 1.000144]\n",
      "epoch:35 step:168045[D loss: 0.999990] [G loss: 1.000076]\n",
      "epoch:35 step:168050[D loss: 0.999941] [G loss: 1.000132]\n",
      "epoch:35 step:168055[D loss: 0.999962] [G loss: 1.000136]\n",
      "epoch:35 step:168060[D loss: 0.999936] [G loss: 1.000119]\n",
      "epoch:35 step:168065[D loss: 1.000229] [G loss: 0.999779]\n",
      "epoch:35 step:168070[D loss: 0.999936] [G loss: 1.000085]\n",
      "epoch:35 step:168075[D loss: 0.999883] [G loss: 1.000175]\n",
      "epoch:35 step:168080[D loss: 1.000061] [G loss: 0.999904]\n",
      "epoch:35 step:168085[D loss: 0.999951] [G loss: 1.000041]\n",
      "epoch:35 step:168090[D loss: 0.999819] [G loss: 1.000222]\n",
      "epoch:35 step:168095[D loss: 0.999974] [G loss: 0.999955]\n",
      "epoch:35 step:168100[D loss: 1.000023] [G loss: 0.999977]\n",
      "epoch:35 step:168105[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:35 step:168110[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:35 step:168115[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:35 step:168120[D loss: 1.000022] [G loss: 1.000024]\n",
      "epoch:35 step:168125[D loss: 0.999964] [G loss: 1.000123]\n",
      "epoch:35 step:168130[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:35 step:168135[D loss: 1.000111] [G loss: 0.999999]\n",
      "epoch:35 step:168140[D loss: 0.999928] [G loss: 1.000114]\n",
      "epoch:35 step:168145[D loss: 1.000280] [G loss: 0.999841]\n",
      "epoch:35 step:168150[D loss: 0.999883] [G loss: 1.000191]\n",
      "epoch:35 step:168155[D loss: 0.999953] [G loss: 1.000042]\n",
      "epoch:35 step:168160[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:35 step:168165[D loss: 0.999994] [G loss: 0.999996]\n",
      "epoch:35 step:168170[D loss: 0.999975] [G loss: 0.999998]\n",
      "epoch:35 step:168175[D loss: 0.999984] [G loss: 0.999986]\n",
      "epoch:35 step:168180[D loss: 1.000025] [G loss: 1.000037]\n",
      "epoch:35 step:168185[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:35 step:168190[D loss: 0.999972] [G loss: 1.000000]\n",
      "epoch:35 step:168195[D loss: 1.000172] [G loss: 1.000005]\n",
      "epoch:35 step:168200[D loss: 0.999711] [G loss: 1.000456]\n",
      "##############\n",
      "[2.6782377  2.43539665 2.25142201 3.66227093 1.70951905 7.88431326\n",
      " 2.3672104  3.89008804 4.18348719 5.86423311]\n",
      "##########\n",
      "epoch:35 step:168205[D loss: 0.999878] [G loss: 1.000164]\n",
      "epoch:35 step:168210[D loss: 0.999850] [G loss: 1.000302]\n",
      "epoch:35 step:168215[D loss: 0.999963] [G loss: 1.000223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:168220[D loss: 1.000112] [G loss: 1.000183]\n",
      "epoch:35 step:168225[D loss: 0.999909] [G loss: 1.000183]\n",
      "epoch:35 step:168230[D loss: 0.999912] [G loss: 1.000246]\n",
      "epoch:35 step:168235[D loss: 0.999968] [G loss: 1.000027]\n",
      "epoch:35 step:168240[D loss: 1.000049] [G loss: 0.999890]\n",
      "epoch:35 step:168245[D loss: 0.999949] [G loss: 1.000004]\n",
      "epoch:35 step:168250[D loss: 1.000026] [G loss: 0.999810]\n",
      "epoch:35 step:168255[D loss: 1.000236] [G loss: 0.999852]\n",
      "epoch:35 step:168260[D loss: 1.000068] [G loss: 0.999865]\n",
      "epoch:35 step:168265[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:35 step:168270[D loss: 1.000195] [G loss: 0.999734]\n",
      "epoch:35 step:168275[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:35 step:168280[D loss: 0.999882] [G loss: 1.000387]\n",
      "epoch:35 step:168285[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:35 step:168290[D loss: 0.999773] [G loss: 1.000357]\n",
      "epoch:35 step:168295[D loss: 0.999913] [G loss: 1.000102]\n",
      "epoch:35 step:168300[D loss: 0.999933] [G loss: 1.000090]\n",
      "epoch:35 step:168305[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:35 step:168310[D loss: 0.999985] [G loss: 1.000104]\n",
      "epoch:35 step:168315[D loss: 0.999984] [G loss: 0.999960]\n",
      "epoch:35 step:168320[D loss: 1.000001] [G loss: 1.000193]\n",
      "epoch:35 step:168325[D loss: 1.000067] [G loss: 0.999987]\n",
      "epoch:35 step:168330[D loss: 0.999895] [G loss: 1.000078]\n",
      "epoch:35 step:168335[D loss: 0.999933] [G loss: 1.000081]\n",
      "epoch:35 step:168340[D loss: 0.999989] [G loss: 1.000107]\n",
      "epoch:35 step:168345[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:35 step:168350[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:35 step:168355[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:35 step:168360[D loss: 0.999952] [G loss: 1.000035]\n",
      "epoch:35 step:168365[D loss: 1.000007] [G loss: 1.000007]\n",
      "epoch:35 step:168370[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:35 step:168375[D loss: 0.999885] [G loss: 1.000130]\n",
      "epoch:35 step:168380[D loss: 0.999945] [G loss: 1.000035]\n",
      "epoch:35 step:168385[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:35 step:168390[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:35 step:168395[D loss: 0.999921] [G loss: 1.000086]\n",
      "epoch:35 step:168400[D loss: 1.000014] [G loss: 1.000121]\n",
      "##############\n",
      "[2.60223703 2.38211183 2.28555935 3.56933937 1.70573252 6.91475456\n",
      " 2.58292321 3.85014521 4.06499847 5.04858734]\n",
      "##########\n",
      "epoch:35 step:168405[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:35 step:168410[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:35 step:168415[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:35 step:168420[D loss: 1.000000] [G loss: 1.000100]\n",
      "epoch:35 step:168425[D loss: 0.999990] [G loss: 0.999998]\n",
      "epoch:35 step:168430[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:35 step:168435[D loss: 0.999997] [G loss: 0.999995]\n",
      "epoch:35 step:168440[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:35 step:168445[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:35 step:168450[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:35 step:168455[D loss: 1.000132] [G loss: 0.999900]\n",
      "epoch:35 step:168460[D loss: 1.000058] [G loss: 0.999872]\n",
      "epoch:35 step:168465[D loss: 0.999949] [G loss: 1.000051]\n",
      "epoch:35 step:168470[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:35 step:168475[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:35 step:168480[D loss: 0.999978] [G loss: 1.000106]\n",
      "epoch:35 step:168485[D loss: 0.999936] [G loss: 1.000052]\n",
      "epoch:35 step:168490[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:35 step:168495[D loss: 1.000070] [G loss: 0.999970]\n",
      "epoch:35 step:168500[D loss: 1.000053] [G loss: 1.000020]\n",
      "epoch:35 step:168505[D loss: 1.000112] [G loss: 0.999984]\n",
      "epoch:35 step:168510[D loss: 1.000068] [G loss: 0.999972]\n",
      "epoch:35 step:168515[D loss: 1.000122] [G loss: 0.999925]\n",
      "epoch:35 step:168520[D loss: 0.999954] [G loss: 0.999989]\n",
      "epoch:35 step:168525[D loss: 0.999906] [G loss: 0.999995]\n",
      "epoch:35 step:168530[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:35 step:168535[D loss: 0.999913] [G loss: 1.000069]\n",
      "epoch:35 step:168540[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:35 step:168545[D loss: 1.000004] [G loss: 1.000114]\n",
      "epoch:35 step:168550[D loss: 1.000053] [G loss: 1.000019]\n",
      "epoch:35 step:168555[D loss: 1.000007] [G loss: 0.999980]\n",
      "epoch:35 step:168560[D loss: 1.000041] [G loss: 1.000127]\n",
      "epoch:35 step:168565[D loss: 0.999940] [G loss: 1.000062]\n",
      "epoch:35 step:168570[D loss: 1.000008] [G loss: 1.000001]\n",
      "epoch:35 step:168575[D loss: 0.999998] [G loss: 0.999953]\n",
      "epoch:35 step:168580[D loss: 1.000055] [G loss: 0.999879]\n",
      "epoch:35 step:168585[D loss: 0.999951] [G loss: 0.999982]\n",
      "epoch:35 step:168590[D loss: 0.999957] [G loss: 0.999972]\n",
      "epoch:35 step:168595[D loss: 0.999903] [G loss: 1.000166]\n",
      "epoch:35 step:168600[D loss: 0.999945] [G loss: 1.000120]\n",
      "##############\n",
      "[2.59268343 2.37564506 2.36044649 3.74571534 1.65184431 7.03218437\n",
      " 2.56525083 3.90826307 4.11902332 5.13006734]\n",
      "##########\n",
      "epoch:35 step:168605[D loss: 0.999975] [G loss: 1.000108]\n",
      "epoch:35 step:168610[D loss: 0.999991] [G loss: 1.000002]\n",
      "epoch:35 step:168615[D loss: 0.999985] [G loss: 0.999991]\n",
      "epoch:35 step:168620[D loss: 0.999970] [G loss: 1.000037]\n",
      "epoch:35 step:168625[D loss: 0.999992] [G loss: 0.999992]\n",
      "epoch:35 step:168630[D loss: 0.999961] [G loss: 1.000036]\n",
      "epoch:35 step:168635[D loss: 1.000002] [G loss: 0.999987]\n",
      "epoch:35 step:168640[D loss: 0.999955] [G loss: 1.000055]\n",
      "epoch:35 step:168645[D loss: 0.999931] [G loss: 1.000095]\n",
      "epoch:35 step:168650[D loss: 1.000161] [G loss: 0.999847]\n",
      "epoch:35 step:168655[D loss: 0.999991] [G loss: 0.999998]\n",
      "epoch:35 step:168660[D loss: 0.999950] [G loss: 1.000084]\n",
      "epoch:36 step:168665[D loss: 1.000022] [G loss: 0.999963]\n",
      "epoch:36 step:168670[D loss: 0.999997] [G loss: 0.999999]\n",
      "epoch:36 step:168675[D loss: 0.999943] [G loss: 1.000014]\n",
      "epoch:36 step:168680[D loss: 1.000012] [G loss: 0.999981]\n",
      "epoch:36 step:168685[D loss: 1.000026] [G loss: 0.999985]\n",
      "epoch:36 step:168690[D loss: 0.999968] [G loss: 1.000028]\n",
      "epoch:36 step:168695[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:36 step:168700[D loss: 0.999984] [G loss: 0.999948]\n",
      "epoch:36 step:168705[D loss: 1.000109] [G loss: 0.999876]\n",
      "epoch:36 step:168710[D loss: 1.000058] [G loss: 1.000037]\n",
      "epoch:36 step:168715[D loss: 1.000030] [G loss: 0.999938]\n",
      "epoch:36 step:168720[D loss: 0.999961] [G loss: 1.000044]\n",
      "epoch:36 step:168725[D loss: 0.999950] [G loss: 1.000055]\n",
      "epoch:36 step:168730[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:36 step:168735[D loss: 0.999996] [G loss: 1.000060]\n",
      "epoch:36 step:168740[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:36 step:168745[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:36 step:168750[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:36 step:168755[D loss: 0.999988] [G loss: 1.000012]\n",
      "epoch:36 step:168760[D loss: 0.999937] [G loss: 1.000084]\n",
      "epoch:36 step:168765[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:36 step:168770[D loss: 0.999994] [G loss: 1.000071]\n",
      "epoch:36 step:168775[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:36 step:168780[D loss: 1.000002] [G loss: 1.000059]\n",
      "epoch:36 step:168785[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:36 step:168790[D loss: 1.000023] [G loss: 1.000048]\n",
      "epoch:36 step:168795[D loss: 1.000032] [G loss: 1.000004]\n",
      "epoch:36 step:168800[D loss: 1.000004] [G loss: 0.999987]\n",
      "##############\n",
      "[2.63810098 2.30758195 2.29088774 3.66926082 1.62244138 7.17075019\n",
      " 2.33565235 3.92030098 4.05668156 5.35206819]\n",
      "##########\n",
      "epoch:36 step:168805[D loss: 1.000037] [G loss: 0.999920]\n",
      "epoch:36 step:168810[D loss: 1.000091] [G loss: 0.999805]\n",
      "epoch:36 step:168815[D loss: 0.999941] [G loss: 1.000025]\n",
      "epoch:36 step:168820[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:36 step:168825[D loss: 1.000041] [G loss: 0.999961]\n",
      "epoch:36 step:168830[D loss: 1.000083] [G loss: 0.999991]\n",
      "epoch:36 step:168835[D loss: 0.999942] [G loss: 1.000197]\n",
      "epoch:36 step:168840[D loss: 0.999901] [G loss: 1.000291]\n",
      "epoch:36 step:168845[D loss: 0.999985] [G loss: 1.000174]\n",
      "epoch:36 step:168850[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:36 step:168855[D loss: 1.000070] [G loss: 0.999836]\n",
      "epoch:36 step:168860[D loss: 1.000106] [G loss: 0.999885]\n",
      "epoch:36 step:168865[D loss: 1.000116] [G loss: 0.999822]\n",
      "epoch:36 step:168870[D loss: 1.000031] [G loss: 0.999851]\n",
      "epoch:36 step:168875[D loss: 0.999982] [G loss: 1.000027]\n",
      "epoch:36 step:168880[D loss: 0.999980] [G loss: 0.999988]\n",
      "epoch:36 step:168885[D loss: 1.000039] [G loss: 0.999948]\n",
      "epoch:36 step:168890[D loss: 0.999947] [G loss: 1.000134]\n",
      "epoch:36 step:168895[D loss: 0.999869] [G loss: 1.000158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:168900[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:36 step:168905[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:36 step:168910[D loss: 0.999985] [G loss: 1.000131]\n",
      "epoch:36 step:168915[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:36 step:168920[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:36 step:168925[D loss: 0.999950] [G loss: 1.000108]\n",
      "epoch:36 step:168930[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:36 step:168935[D loss: 0.999966] [G loss: 1.000102]\n",
      "epoch:36 step:168940[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:36 step:168945[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:36 step:168950[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:36 step:168955[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:36 step:168960[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:36 step:168965[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:36 step:168970[D loss: 1.000023] [G loss: 1.000047]\n",
      "epoch:36 step:168975[D loss: 1.000059] [G loss: 0.999999]\n",
      "epoch:36 step:168980[D loss: 0.999997] [G loss: 1.000140]\n",
      "epoch:36 step:168985[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:36 step:168990[D loss: 0.999904] [G loss: 1.000128]\n",
      "epoch:36 step:168995[D loss: 1.000014] [G loss: 0.999948]\n",
      "epoch:36 step:169000[D loss: 0.999986] [G loss: 1.000038]\n",
      "##############\n",
      "[2.61124651 2.3200361  2.23193729 3.3495409  1.67038202 6.66220919\n",
      " 2.42541177 3.92357324 4.11319726 5.48124112]\n",
      "##########\n",
      "epoch:36 step:169005[D loss: 1.000029] [G loss: 1.000141]\n",
      "epoch:36 step:169010[D loss: 0.999947] [G loss: 1.000213]\n",
      "epoch:36 step:169015[D loss: 1.000011] [G loss: 1.000012]\n",
      "epoch:36 step:169020[D loss: 0.999989] [G loss: 1.000146]\n",
      "epoch:36 step:169025[D loss: 1.000009] [G loss: 1.000057]\n",
      "epoch:36 step:169030[D loss: 1.000099] [G loss: 0.999881]\n",
      "epoch:36 step:169035[D loss: 1.000100] [G loss: 0.999899]\n",
      "epoch:36 step:169040[D loss: 1.000003] [G loss: 1.000034]\n",
      "epoch:36 step:169045[D loss: 0.999930] [G loss: 1.000185]\n",
      "epoch:36 step:169050[D loss: 0.999927] [G loss: 1.000181]\n",
      "epoch:36 step:169055[D loss: 0.999914] [G loss: 1.000251]\n",
      "epoch:36 step:169060[D loss: 0.999883] [G loss: 1.000155]\n",
      "epoch:36 step:169065[D loss: 1.000035] [G loss: 1.000123]\n",
      "epoch:36 step:169070[D loss: 0.999984] [G loss: 1.000003]\n",
      "epoch:36 step:169075[D loss: 0.999944] [G loss: 1.000067]\n",
      "epoch:36 step:169080[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:36 step:169085[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:36 step:169090[D loss: 0.999972] [G loss: 1.000012]\n",
      "epoch:36 step:169095[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:36 step:169100[D loss: 1.000060] [G loss: 0.999964]\n",
      "epoch:36 step:169105[D loss: 1.000045] [G loss: 0.999990]\n",
      "epoch:36 step:169110[D loss: 1.000035] [G loss: 0.999981]\n",
      "epoch:36 step:169115[D loss: 0.999858] [G loss: 1.000148]\n",
      "epoch:36 step:169120[D loss: 0.999947] [G loss: 1.000130]\n",
      "epoch:36 step:169125[D loss: 0.999936] [G loss: 1.000067]\n",
      "epoch:36 step:169130[D loss: 0.999987] [G loss: 1.000008]\n",
      "epoch:36 step:169135[D loss: 1.000197] [G loss: 0.999874]\n",
      "epoch:36 step:169140[D loss: 1.000090] [G loss: 0.999978]\n",
      "epoch:36 step:169145[D loss: 1.000055] [G loss: 1.000013]\n",
      "epoch:36 step:169150[D loss: 1.000002] [G loss: 1.000205]\n",
      "epoch:36 step:169155[D loss: 0.999956] [G loss: 1.000178]\n",
      "epoch:36 step:169160[D loss: 0.999864] [G loss: 1.000295]\n",
      "epoch:36 step:169165[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:36 step:169170[D loss: 0.999941] [G loss: 1.000095]\n",
      "epoch:36 step:169175[D loss: 0.999950] [G loss: 1.000102]\n",
      "epoch:36 step:169180[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:36 step:169185[D loss: 1.000013] [G loss: 1.000017]\n",
      "epoch:36 step:169190[D loss: 0.999990] [G loss: 0.999983]\n",
      "epoch:36 step:169195[D loss: 0.999997] [G loss: 1.000089]\n",
      "epoch:36 step:169200[D loss: 1.000058] [G loss: 0.999982]\n",
      "##############\n",
      "[2.58425556 2.37616515 2.44557623 3.6779051  1.69706514 7.48768403\n",
      " 2.36986531 3.85086423 4.13059948 5.17556979]\n",
      "##########\n",
      "epoch:36 step:169205[D loss: 0.999760] [G loss: 1.000274]\n",
      "epoch:36 step:169210[D loss: 1.000019] [G loss: 1.000139]\n",
      "epoch:36 step:169215[D loss: 0.999938] [G loss: 1.000149]\n",
      "epoch:36 step:169220[D loss: 0.999961] [G loss: 1.000129]\n",
      "epoch:36 step:169225[D loss: 1.000019] [G loss: 1.000080]\n",
      "epoch:36 step:169230[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:36 step:169235[D loss: 0.999872] [G loss: 1.000241]\n",
      "epoch:36 step:169240[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:36 step:169245[D loss: 1.000017] [G loss: 0.999945]\n",
      "epoch:36 step:169250[D loss: 1.000100] [G loss: 0.999989]\n",
      "epoch:36 step:169255[D loss: 1.000130] [G loss: 0.999886]\n",
      "epoch:36 step:169260[D loss: 0.999998] [G loss: 1.000124]\n",
      "epoch:36 step:169265[D loss: 0.999983] [G loss: 1.000136]\n",
      "epoch:36 step:169270[D loss: 0.999940] [G loss: 1.000181]\n",
      "epoch:36 step:169275[D loss: 0.999928] [G loss: 1.000226]\n",
      "epoch:36 step:169280[D loss: 0.999897] [G loss: 1.000187]\n",
      "epoch:36 step:169285[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:36 step:169290[D loss: 0.999948] [G loss: 1.000082]\n",
      "epoch:36 step:169295[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:36 step:169300[D loss: 1.000001] [G loss: 1.000026]\n",
      "epoch:36 step:169305[D loss: 1.000055] [G loss: 0.999876]\n",
      "epoch:36 step:169310[D loss: 0.999915] [G loss: 1.000078]\n",
      "epoch:36 step:169315[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:36 step:169320[D loss: 1.000045] [G loss: 0.999982]\n",
      "epoch:36 step:169325[D loss: 0.999979] [G loss: 1.000110]\n",
      "epoch:36 step:169330[D loss: 0.999992] [G loss: 1.000107]\n",
      "epoch:36 step:169335[D loss: 0.999952] [G loss: 1.000131]\n",
      "epoch:36 step:169340[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:36 step:169345[D loss: 1.000123] [G loss: 0.999879]\n",
      "epoch:36 step:169350[D loss: 0.999933] [G loss: 1.000065]\n",
      "epoch:36 step:169355[D loss: 0.999956] [G loss: 1.000036]\n",
      "epoch:36 step:169360[D loss: 0.999932] [G loss: 1.000133]\n",
      "epoch:36 step:169365[D loss: 0.999952] [G loss: 1.000116]\n",
      "epoch:36 step:169370[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:36 step:169375[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:36 step:169380[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:36 step:169385[D loss: 0.999930] [G loss: 1.000162]\n",
      "epoch:36 step:169390[D loss: 1.000009] [G loss: 1.000025]\n",
      "epoch:36 step:169395[D loss: 1.000018] [G loss: 1.000030]\n",
      "epoch:36 step:169400[D loss: 0.999969] [G loss: 1.000071]\n",
      "##############\n",
      "[2.68134884 2.35003095 2.33115962 3.58430695 1.71928105 7.5168148\n",
      " 2.34989794 3.801165   4.02711049 4.8513477 ]\n",
      "##########\n",
      "epoch:36 step:169405[D loss: 1.000076] [G loss: 0.999809]\n",
      "epoch:36 step:169410[D loss: 1.000003] [G loss: 0.999943]\n",
      "epoch:36 step:169415[D loss: 0.999904] [G loss: 1.000116]\n",
      "epoch:36 step:169420[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:36 step:169425[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:36 step:169430[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:36 step:169435[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:36 step:169440[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:36 step:169445[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:36 step:169450[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:36 step:169455[D loss: 0.999998] [G loss: 0.999985]\n",
      "epoch:36 step:169460[D loss: 0.999952] [G loss: 1.000102]\n",
      "epoch:36 step:169465[D loss: 1.000018] [G loss: 1.000028]\n",
      "epoch:36 step:169470[D loss: 0.999901] [G loss: 1.000186]\n",
      "epoch:36 step:169475[D loss: 0.999942] [G loss: 1.000087]\n",
      "epoch:36 step:169480[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:36 step:169485[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:36 step:169490[D loss: 0.999955] [G loss: 1.000123]\n",
      "epoch:36 step:169495[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:36 step:169500[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:36 step:169505[D loss: 0.999992] [G loss: 1.000014]\n",
      "epoch:36 step:169510[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:36 step:169515[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:36 step:169520[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:36 step:169525[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:36 step:169530[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:36 step:169535[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:36 step:169540[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:36 step:169545[D loss: 0.999912] [G loss: 1.000100]\n",
      "epoch:36 step:169550[D loss: 1.000083] [G loss: 0.999931]\n",
      "epoch:36 step:169555[D loss: 0.999905] [G loss: 1.000255]\n",
      "epoch:36 step:169560[D loss: 0.999904] [G loss: 1.000160]\n",
      "epoch:36 step:169565[D loss: 0.999915] [G loss: 1.000201]\n",
      "epoch:36 step:169570[D loss: 1.000043] [G loss: 1.000033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:169575[D loss: 1.000026] [G loss: 1.000156]\n",
      "epoch:36 step:169580[D loss: 0.999974] [G loss: 1.000132]\n",
      "epoch:36 step:169585[D loss: 1.000076] [G loss: 0.999851]\n",
      "epoch:36 step:169590[D loss: 1.000060] [G loss: 0.999944]\n",
      "epoch:36 step:169595[D loss: 0.999984] [G loss: 0.999954]\n",
      "epoch:36 step:169600[D loss: 1.000048] [G loss: 1.000110]\n",
      "##############\n",
      "[2.55653976 2.29645759 2.32429535 3.61526358 1.67069195 7.52236591\n",
      " 2.35405215 3.77064831 4.04282713 5.09438087]\n",
      "##########\n",
      "epoch:36 step:169605[D loss: 0.999902] [G loss: 1.000051]\n",
      "epoch:36 step:169610[D loss: 0.999905] [G loss: 1.000069]\n",
      "epoch:36 step:169615[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:36 step:169620[D loss: 1.000095] [G loss: 0.999940]\n",
      "epoch:36 step:169625[D loss: 1.000043] [G loss: 1.000060]\n",
      "epoch:36 step:169630[D loss: 0.999988] [G loss: 0.999964]\n",
      "epoch:36 step:169635[D loss: 0.999993] [G loss: 0.999987]\n",
      "epoch:36 step:169640[D loss: 1.000063] [G loss: 0.999954]\n",
      "epoch:36 step:169645[D loss: 1.000154] [G loss: 0.999949]\n",
      "epoch:36 step:169650[D loss: 1.000112] [G loss: 1.000023]\n",
      "epoch:36 step:169655[D loss: 0.999959] [G loss: 1.000009]\n",
      "epoch:36 step:169660[D loss: 1.000183] [G loss: 1.000020]\n",
      "epoch:36 step:169665[D loss: 0.999805] [G loss: 1.000422]\n",
      "epoch:36 step:169670[D loss: 1.000125] [G loss: 1.000113]\n",
      "epoch:36 step:169675[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:36 step:169680[D loss: 0.999894] [G loss: 1.000175]\n",
      "epoch:36 step:169685[D loss: 0.999943] [G loss: 1.000220]\n",
      "epoch:36 step:169690[D loss: 0.999995] [G loss: 1.000010]\n",
      "epoch:36 step:169695[D loss: 0.999992] [G loss: 0.999985]\n",
      "epoch:36 step:169700[D loss: 0.999936] [G loss: 0.999965]\n",
      "epoch:36 step:169705[D loss: 1.000093] [G loss: 0.999943]\n",
      "epoch:36 step:169710[D loss: 1.000044] [G loss: 0.999859]\n",
      "epoch:36 step:169715[D loss: 1.000010] [G loss: 0.999880]\n",
      "epoch:36 step:169720[D loss: 0.999979] [G loss: 1.000014]\n",
      "epoch:36 step:169725[D loss: 1.000043] [G loss: 0.999977]\n",
      "epoch:36 step:169730[D loss: 0.999957] [G loss: 0.999995]\n",
      "epoch:36 step:169735[D loss: 0.999876] [G loss: 1.000301]\n",
      "epoch:36 step:169740[D loss: 1.000187] [G loss: 0.999825]\n",
      "epoch:36 step:169745[D loss: 1.000268] [G loss: 0.999943]\n",
      "epoch:36 step:169750[D loss: 0.999787] [G loss: 1.000287]\n",
      "epoch:36 step:169755[D loss: 0.999785] [G loss: 1.000308]\n",
      "epoch:36 step:169760[D loss: 0.999932] [G loss: 1.000178]\n",
      "epoch:36 step:169765[D loss: 0.999951] [G loss: 1.000124]\n",
      "epoch:36 step:169770[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:36 step:169775[D loss: 1.000059] [G loss: 0.999954]\n",
      "epoch:36 step:169780[D loss: 0.999970] [G loss: 0.999980]\n",
      "epoch:36 step:169785[D loss: 1.000180] [G loss: 0.999907]\n",
      "epoch:36 step:169790[D loss: 1.000186] [G loss: 0.999901]\n",
      "epoch:36 step:169795[D loss: 0.999941] [G loss: 1.000324]\n",
      "epoch:36 step:169800[D loss: 1.000006] [G loss: 0.999911]\n",
      "##############\n",
      "[2.59587431 2.32399978 2.36065181 3.84816966 1.63379313 7.50281791\n",
      " 2.26736606 3.76680358 4.08510245 5.56565215]\n",
      "##########\n",
      "epoch:36 step:169805[D loss: 0.999935] [G loss: 1.000224]\n",
      "epoch:36 step:169810[D loss: 1.000047] [G loss: 1.000108]\n",
      "epoch:36 step:169815[D loss: 0.999856] [G loss: 1.000397]\n",
      "epoch:36 step:169820[D loss: 0.999984] [G loss: 1.000223]\n",
      "epoch:36 step:169825[D loss: 0.999971] [G loss: 1.000238]\n",
      "epoch:36 step:169830[D loss: 1.000045] [G loss: 1.000213]\n",
      "epoch:36 step:169835[D loss: 0.999928] [G loss: 1.000288]\n",
      "epoch:36 step:169840[D loss: 0.999942] [G loss: 1.000211]\n",
      "epoch:36 step:169845[D loss: 1.000014] [G loss: 1.000055]\n",
      "epoch:36 step:169850[D loss: 0.999976] [G loss: 1.000011]\n",
      "epoch:36 step:169855[D loss: 1.000035] [G loss: 0.999884]\n",
      "epoch:36 step:169860[D loss: 1.000082] [G loss: 0.999754]\n",
      "epoch:36 step:169865[D loss: 1.000110] [G loss: 0.999856]\n",
      "epoch:36 step:169870[D loss: 1.000216] [G loss: 0.999711]\n",
      "epoch:36 step:169875[D loss: 1.000124] [G loss: 0.999724]\n",
      "epoch:36 step:169880[D loss: 1.000275] [G loss: 0.999844]\n",
      "epoch:36 step:169885[D loss: 0.999742] [G loss: 1.000156]\n",
      "epoch:36 step:169890[D loss: 1.000090] [G loss: 1.000248]\n",
      "epoch:36 step:169895[D loss: 0.999855] [G loss: 1.000021]\n",
      "epoch:36 step:169900[D loss: 0.999962] [G loss: 1.000024]\n",
      "epoch:36 step:169905[D loss: 0.999904] [G loss: 1.000269]\n",
      "epoch:36 step:169910[D loss: 0.999741] [G loss: 1.000364]\n",
      "epoch:36 step:169915[D loss: 0.999947] [G loss: 1.000081]\n",
      "epoch:36 step:169920[D loss: 0.999988] [G loss: 0.999941]\n",
      "epoch:36 step:169925[D loss: 1.000186] [G loss: 0.999739]\n",
      "epoch:36 step:169930[D loss: 0.999863] [G loss: 1.000168]\n",
      "epoch:36 step:169935[D loss: 1.000019] [G loss: 1.000005]\n",
      "epoch:36 step:169940[D loss: 0.999923] [G loss: 1.000162]\n",
      "epoch:36 step:169945[D loss: 0.999908] [G loss: 1.000159]\n",
      "epoch:36 step:169950[D loss: 0.999964] [G loss: 1.000173]\n",
      "epoch:36 step:169955[D loss: 0.999938] [G loss: 1.000127]\n",
      "epoch:36 step:169960[D loss: 0.999991] [G loss: 1.000129]\n",
      "epoch:36 step:169965[D loss: 0.999905] [G loss: 1.000153]\n",
      "epoch:36 step:169970[D loss: 0.999913] [G loss: 1.000168]\n",
      "epoch:36 step:169975[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:36 step:169980[D loss: 0.999980] [G loss: 1.000009]\n",
      "epoch:36 step:169985[D loss: 0.999986] [G loss: 0.999993]\n",
      "epoch:36 step:169990[D loss: 1.000067] [G loss: 0.999905]\n",
      "epoch:36 step:169995[D loss: 1.000019] [G loss: 0.999963]\n",
      "epoch:36 step:170000[D loss: 0.999973] [G loss: 1.000064]\n",
      "##############\n",
      "[2.66584607 2.36060202 2.34699579 3.71156753 1.71012635 7.71491035\n",
      " 2.50575479 3.96272688 4.19188354 7.14868929]\n",
      "##########\n",
      "epoch:36 step:170005[D loss: 0.999969] [G loss: 1.000107]\n",
      "epoch:36 step:170010[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:36 step:170015[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:36 step:170020[D loss: 1.000011] [G loss: 1.000177]\n",
      "epoch:36 step:170025[D loss: 0.999953] [G loss: 1.000208]\n",
      "epoch:36 step:170030[D loss: 1.000029] [G loss: 1.000096]\n",
      "epoch:36 step:170035[D loss: 1.000027] [G loss: 1.000031]\n",
      "epoch:36 step:170040[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:36 step:170045[D loss: 1.000065] [G loss: 0.999927]\n",
      "epoch:36 step:170050[D loss: 1.000118] [G loss: 1.000106]\n",
      "epoch:36 step:170055[D loss: 0.999881] [G loss: 1.000160]\n",
      "epoch:36 step:170060[D loss: 0.999826] [G loss: 1.000298]\n",
      "epoch:36 step:170065[D loss: 0.999933] [G loss: 1.000105]\n",
      "epoch:36 step:170070[D loss: 0.999948] [G loss: 1.000065]\n",
      "epoch:36 step:170075[D loss: 0.999964] [G loss: 1.000151]\n",
      "epoch:36 step:170080[D loss: 0.999973] [G loss: 1.000124]\n",
      "epoch:36 step:170085[D loss: 1.000046] [G loss: 0.999930]\n",
      "epoch:36 step:170090[D loss: 0.999939] [G loss: 1.000084]\n",
      "epoch:36 step:170095[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:36 step:170100[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:36 step:170105[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:36 step:170110[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:36 step:170115[D loss: 1.000026] [G loss: 0.999934]\n",
      "epoch:36 step:170120[D loss: 0.999939] [G loss: 1.000057]\n",
      "epoch:36 step:170125[D loss: 1.000040] [G loss: 0.999929]\n",
      "epoch:36 step:170130[D loss: 0.999859] [G loss: 1.000220]\n",
      "epoch:36 step:170135[D loss: 1.000189] [G loss: 0.999798]\n",
      "epoch:36 step:170140[D loss: 0.999838] [G loss: 1.000262]\n",
      "epoch:36 step:170145[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:36 step:170150[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:36 step:170155[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:36 step:170160[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:36 step:170165[D loss: 0.999917] [G loss: 1.000083]\n",
      "epoch:36 step:170170[D loss: 1.000041] [G loss: 0.999964]\n",
      "epoch:36 step:170175[D loss: 1.000052] [G loss: 1.000106]\n",
      "epoch:36 step:170180[D loss: 0.999898] [G loss: 1.000108]\n",
      "epoch:36 step:170185[D loss: 0.999936] [G loss: 1.000156]\n",
      "epoch:36 step:170190[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:36 step:170195[D loss: 0.999925] [G loss: 1.000129]\n",
      "epoch:36 step:170200[D loss: 0.999964] [G loss: 1.000058]\n",
      "##############\n",
      "[2.60094391 2.31608968 2.29622054 3.78611835 1.71503021 6.49983045\n",
      " 2.33224483 3.72951611 4.05284087 4.66275621]\n",
      "##########\n",
      "epoch:36 step:170205[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:36 step:170210[D loss: 1.000013] [G loss: 0.999999]\n",
      "epoch:36 step:170215[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:36 step:170220[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:36 step:170225[D loss: 0.999979] [G loss: 0.999937]\n",
      "epoch:36 step:170230[D loss: 0.999950] [G loss: 1.000058]\n",
      "epoch:36 step:170235[D loss: 1.000010] [G loss: 0.999973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:170240[D loss: 0.999991] [G loss: 1.000117]\n",
      "epoch:36 step:170245[D loss: 0.999958] [G loss: 1.000041]\n",
      "epoch:36 step:170250[D loss: 1.000066] [G loss: 0.999903]\n",
      "epoch:36 step:170255[D loss: 0.999944] [G loss: 1.000014]\n",
      "epoch:36 step:170260[D loss: 1.000018] [G loss: 1.000002]\n",
      "epoch:36 step:170265[D loss: 1.000163] [G loss: 0.999776]\n",
      "epoch:36 step:170270[D loss: 0.999906] [G loss: 1.000161]\n",
      "epoch:36 step:170275[D loss: 0.999994] [G loss: 1.000130]\n",
      "epoch:36 step:170280[D loss: 0.999937] [G loss: 1.000021]\n",
      "epoch:36 step:170285[D loss: 0.999972] [G loss: 0.999990]\n",
      "epoch:36 step:170290[D loss: 1.000070] [G loss: 0.999930]\n",
      "epoch:36 step:170295[D loss: 1.000108] [G loss: 0.999813]\n",
      "epoch:36 step:170300[D loss: 0.999865] [G loss: 1.000129]\n",
      "epoch:36 step:170305[D loss: 0.999950] [G loss: 0.999998]\n",
      "epoch:36 step:170310[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:36 step:170315[D loss: 0.999934] [G loss: 1.000103]\n",
      "epoch:36 step:170320[D loss: 1.000003] [G loss: 1.000094]\n",
      "epoch:36 step:170325[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:36 step:170330[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:36 step:170335[D loss: 0.999942] [G loss: 1.000059]\n",
      "epoch:36 step:170340[D loss: 1.000015] [G loss: 0.999985]\n",
      "epoch:36 step:170345[D loss: 0.999970] [G loss: 1.000020]\n",
      "epoch:36 step:170350[D loss: 0.999920] [G loss: 1.000104]\n",
      "epoch:36 step:170355[D loss: 0.999962] [G loss: 1.000144]\n",
      "epoch:36 step:170360[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:36 step:170365[D loss: 0.999949] [G loss: 1.000096]\n",
      "epoch:36 step:170370[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:36 step:170375[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:36 step:170380[D loss: 0.999998] [G loss: 1.000096]\n",
      "epoch:36 step:170385[D loss: 0.999938] [G loss: 1.000087]\n",
      "epoch:36 step:170390[D loss: 1.000192] [G loss: 0.999850]\n",
      "epoch:36 step:170395[D loss: 0.999967] [G loss: 0.999969]\n",
      "epoch:36 step:170400[D loss: 0.999940] [G loss: 1.000071]\n",
      "##############\n",
      "[2.6285575  2.41321704 2.38578601 3.69290972 1.72532942 7.11374431\n",
      " 2.41435779 3.84788986 4.05701114 6.119879  ]\n",
      "##########\n",
      "epoch:36 step:170405[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:36 step:170410[D loss: 0.999942] [G loss: 1.000087]\n",
      "epoch:36 step:170415[D loss: 0.999962] [G loss: 1.000128]\n",
      "epoch:36 step:170420[D loss: 0.999940] [G loss: 1.000104]\n",
      "epoch:36 step:170425[D loss: 1.000000] [G loss: 1.000081]\n",
      "epoch:36 step:170430[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:36 step:170435[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:36 step:170440[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:36 step:170445[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:36 step:170450[D loss: 1.000064] [G loss: 0.999943]\n",
      "epoch:36 step:170455[D loss: 0.999915] [G loss: 1.000052]\n",
      "epoch:36 step:170460[D loss: 1.000097] [G loss: 1.000003]\n",
      "epoch:36 step:170465[D loss: 0.999939] [G loss: 1.000071]\n",
      "epoch:36 step:170470[D loss: 0.999907] [G loss: 1.000105]\n",
      "epoch:36 step:170475[D loss: 1.000020] [G loss: 1.000003]\n",
      "epoch:36 step:170480[D loss: 1.000125] [G loss: 0.999915]\n",
      "epoch:36 step:170485[D loss: 0.999990] [G loss: 1.000106]\n",
      "epoch:36 step:170490[D loss: 1.000012] [G loss: 1.000106]\n",
      "epoch:36 step:170495[D loss: 1.000128] [G loss: 1.000015]\n",
      "epoch:36 step:170500[D loss: 0.999944] [G loss: 1.000195]\n",
      "epoch:36 step:170505[D loss: 0.999880] [G loss: 1.000162]\n",
      "epoch:36 step:170510[D loss: 0.999939] [G loss: 1.000175]\n",
      "epoch:36 step:170515[D loss: 0.999953] [G loss: 1.000135]\n",
      "epoch:36 step:170520[D loss: 1.000010] [G loss: 0.999983]\n",
      "epoch:36 step:170525[D loss: 1.000027] [G loss: 0.999854]\n",
      "epoch:36 step:170530[D loss: 0.999927] [G loss: 1.000063]\n",
      "epoch:36 step:170535[D loss: 1.000011] [G loss: 0.999992]\n",
      "epoch:36 step:170540[D loss: 0.999928] [G loss: 1.000078]\n",
      "epoch:36 step:170545[D loss: 1.000076] [G loss: 0.999850]\n",
      "epoch:36 step:170550[D loss: 1.000206] [G loss: 0.999861]\n",
      "epoch:36 step:170555[D loss: 1.000023] [G loss: 0.999959]\n",
      "epoch:36 step:170560[D loss: 0.999945] [G loss: 1.000021]\n",
      "epoch:36 step:170565[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:36 step:170570[D loss: 0.999960] [G loss: 1.000098]\n",
      "epoch:36 step:170575[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:36 step:170580[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:36 step:170585[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:36 step:170590[D loss: 0.999916] [G loss: 1.000003]\n",
      "epoch:36 step:170595[D loss: 0.999928] [G loss: 1.000279]\n",
      "epoch:36 step:170600[D loss: 1.000054] [G loss: 1.000054]\n",
      "##############\n",
      "[2.61555108 2.36608276 2.22116724 3.7386533  1.63180012 7.47077003\n",
      " 2.35660392 3.76169961 4.03936355 5.56016733]\n",
      "##########\n",
      "epoch:36 step:170605[D loss: 0.999914] [G loss: 1.000076]\n",
      "epoch:36 step:170610[D loss: 0.999981] [G loss: 1.000219]\n",
      "epoch:36 step:170615[D loss: 0.999950] [G loss: 1.000074]\n",
      "epoch:36 step:170620[D loss: 0.999992] [G loss: 1.000095]\n",
      "epoch:36 step:170625[D loss: 1.000006] [G loss: 1.000010]\n",
      "epoch:36 step:170630[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:36 step:170635[D loss: 0.999949] [G loss: 1.000066]\n",
      "epoch:36 step:170640[D loss: 0.999903] [G loss: 1.000116]\n",
      "epoch:36 step:170645[D loss: 0.999928] [G loss: 1.000172]\n",
      "epoch:36 step:170650[D loss: 1.000142] [G loss: 0.999969]\n",
      "epoch:36 step:170655[D loss: 0.999946] [G loss: 1.000123]\n",
      "epoch:36 step:170660[D loss: 0.999879] [G loss: 1.000224]\n",
      "epoch:36 step:170665[D loss: 1.000038] [G loss: 1.000038]\n",
      "epoch:36 step:170670[D loss: 0.999892] [G loss: 1.000179]\n",
      "epoch:36 step:170675[D loss: 1.000009] [G loss: 1.000103]\n",
      "epoch:36 step:170680[D loss: 0.999950] [G loss: 1.000132]\n",
      "epoch:36 step:170685[D loss: 0.999930] [G loss: 1.000091]\n",
      "epoch:36 step:170690[D loss: 0.999953] [G loss: 1.000059]\n",
      "epoch:36 step:170695[D loss: 1.000091] [G loss: 0.999966]\n",
      "epoch:36 step:170700[D loss: 0.999969] [G loss: 1.000009]\n",
      "epoch:36 step:170705[D loss: 1.000017] [G loss: 0.999973]\n",
      "epoch:36 step:170710[D loss: 1.000145] [G loss: 1.000000]\n",
      "epoch:36 step:170715[D loss: 0.999968] [G loss: 1.000006]\n",
      "epoch:36 step:170720[D loss: 0.999936] [G loss: 1.000059]\n",
      "epoch:36 step:170725[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:36 step:170730[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:36 step:170735[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:36 step:170740[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:36 step:170745[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:36 step:170750[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:36 step:170755[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:36 step:170760[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:36 step:170765[D loss: 1.000057] [G loss: 1.000094]\n",
      "epoch:36 step:170770[D loss: 1.000030] [G loss: 1.000056]\n",
      "epoch:36 step:170775[D loss: 0.999936] [G loss: 1.000123]\n",
      "epoch:36 step:170780[D loss: 1.000043] [G loss: 0.999974]\n",
      "epoch:36 step:170785[D loss: 0.999973] [G loss: 1.000122]\n",
      "epoch:36 step:170790[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:36 step:170795[D loss: 1.000005] [G loss: 0.999926]\n",
      "epoch:36 step:170800[D loss: 0.999983] [G loss: 1.000088]\n",
      "##############\n",
      "[2.51116833 2.25110705 2.21266101 3.30574542 1.5934998  6.99160072\n",
      " 2.2620721  3.79846516 3.99725362 4.70093777]\n",
      "##########\n",
      "epoch:36 step:170805[D loss: 1.000112] [G loss: 0.999868]\n",
      "epoch:36 step:170810[D loss: 1.000009] [G loss: 1.000006]\n",
      "epoch:36 step:170815[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:36 step:170820[D loss: 0.999976] [G loss: 1.000177]\n",
      "epoch:36 step:170825[D loss: 0.999879] [G loss: 1.000216]\n",
      "epoch:36 step:170830[D loss: 1.000105] [G loss: 0.999966]\n",
      "epoch:36 step:170835[D loss: 0.999996] [G loss: 1.000110]\n",
      "epoch:36 step:170840[D loss: 0.999943] [G loss: 1.000036]\n",
      "epoch:36 step:170845[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:36 step:170850[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:36 step:170855[D loss: 0.999929] [G loss: 1.000152]\n",
      "epoch:36 step:170860[D loss: 0.999963] [G loss: 1.000105]\n",
      "epoch:36 step:170865[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:36 step:170870[D loss: 1.000022] [G loss: 0.999957]\n",
      "epoch:36 step:170875[D loss: 0.999930] [G loss: 1.000072]\n",
      "epoch:36 step:170880[D loss: 1.000000] [G loss: 1.000082]\n",
      "epoch:36 step:170885[D loss: 0.999896] [G loss: 1.000116]\n",
      "epoch:36 step:170890[D loss: 1.000048] [G loss: 1.000108]\n",
      "epoch:36 step:170895[D loss: 1.000146] [G loss: 0.999956]\n",
      "epoch:36 step:170900[D loss: 0.999973] [G loss: 1.000219]\n",
      "epoch:36 step:170905[D loss: 0.999854] [G loss: 1.000292]\n",
      "epoch:36 step:170910[D loss: 0.999940] [G loss: 1.000267]\n",
      "epoch:36 step:170915[D loss: 0.999885] [G loss: 1.000193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:170920[D loss: 1.000001] [G loss: 1.000121]\n",
      "epoch:36 step:170925[D loss: 0.999950] [G loss: 1.000163]\n",
      "epoch:36 step:170930[D loss: 0.999964] [G loss: 1.000051]\n",
      "epoch:36 step:170935[D loss: 0.999991] [G loss: 0.999961]\n",
      "epoch:36 step:170940[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:36 step:170945[D loss: 1.000047] [G loss: 1.000050]\n",
      "epoch:36 step:170950[D loss: 1.000262] [G loss: 0.999836]\n",
      "epoch:36 step:170955[D loss: 1.000506] [G loss: 0.999617]\n",
      "epoch:36 step:170960[D loss: 0.999864] [G loss: 1.000037]\n",
      "epoch:36 step:170965[D loss: 0.999914] [G loss: 1.000136]\n",
      "epoch:36 step:170970[D loss: 0.999923] [G loss: 1.000047]\n",
      "epoch:36 step:170975[D loss: 1.000071] [G loss: 0.999901]\n",
      "epoch:36 step:170980[D loss: 0.999934] [G loss: 1.000073]\n",
      "epoch:36 step:170985[D loss: 1.000023] [G loss: 0.999951]\n",
      "epoch:36 step:170990[D loss: 0.999999] [G loss: 1.000004]\n",
      "epoch:36 step:170995[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:36 step:171000[D loss: 1.000030] [G loss: 1.000029]\n",
      "##############\n",
      "[2.61702843 2.35457898 2.38396561 3.96040525 1.61811049 7.80983882\n",
      " 2.32249992 3.79975738 3.9935716  5.77872171]\n",
      "##########\n",
      "epoch:36 step:171005[D loss: 1.000205] [G loss: 1.000086]\n",
      "epoch:36 step:171010[D loss: 0.999973] [G loss: 1.000119]\n",
      "epoch:36 step:171015[D loss: 0.999889] [G loss: 1.000316]\n",
      "epoch:36 step:171020[D loss: 0.999926] [G loss: 1.000204]\n",
      "epoch:36 step:171025[D loss: 0.999913] [G loss: 1.000161]\n",
      "epoch:36 step:171030[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:36 step:171035[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:36 step:171040[D loss: 0.999914] [G loss: 1.000074]\n",
      "epoch:36 step:171045[D loss: 0.999970] [G loss: 1.000001]\n",
      "epoch:36 step:171050[D loss: 1.000062] [G loss: 1.000022]\n",
      "epoch:36 step:171055[D loss: 1.000014] [G loss: 1.000003]\n",
      "epoch:36 step:171060[D loss: 0.999763] [G loss: 1.000214]\n",
      "epoch:36 step:171065[D loss: 1.000039] [G loss: 0.999979]\n",
      "epoch:36 step:171070[D loss: 0.999922] [G loss: 1.000096]\n",
      "epoch:36 step:171075[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:36 step:171080[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:36 step:171085[D loss: 1.000116] [G loss: 0.999910]\n",
      "epoch:36 step:171090[D loss: 0.999947] [G loss: 1.000052]\n",
      "epoch:36 step:171095[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:36 step:171100[D loss: 0.999956] [G loss: 1.000036]\n",
      "epoch:36 step:171105[D loss: 1.000042] [G loss: 1.000058]\n",
      "epoch:36 step:171110[D loss: 1.000041] [G loss: 1.000176]\n",
      "epoch:36 step:171115[D loss: 0.999888] [G loss: 1.000297]\n",
      "epoch:36 step:171120[D loss: 1.000053] [G loss: 1.000146]\n",
      "epoch:36 step:171125[D loss: 0.999881] [G loss: 1.000460]\n",
      "epoch:36 step:171130[D loss: 1.000176] [G loss: 1.000124]\n",
      "epoch:36 step:171135[D loss: 0.999906] [G loss: 1.000238]\n",
      "epoch:36 step:171140[D loss: 1.000044] [G loss: 1.000460]\n",
      "epoch:36 step:171145[D loss: 0.999878] [G loss: 1.000474]\n",
      "epoch:36 step:171150[D loss: 0.999884] [G loss: 1.000158]\n",
      "epoch:36 step:171155[D loss: 0.999999] [G loss: 0.999986]\n",
      "epoch:36 step:171160[D loss: 1.000191] [G loss: 0.999693]\n",
      "epoch:36 step:171165[D loss: 0.999949] [G loss: 0.999914]\n",
      "epoch:36 step:171170[D loss: 1.000247] [G loss: 0.999440]\n",
      "epoch:36 step:171175[D loss: 0.999968] [G loss: 0.999928]\n",
      "epoch:36 step:171180[D loss: 1.000247] [G loss: 0.999634]\n",
      "epoch:36 step:171185[D loss: 1.000049] [G loss: 0.999776]\n",
      "epoch:36 step:171190[D loss: 0.999879] [G loss: 1.000107]\n",
      "epoch:36 step:171195[D loss: 1.000147] [G loss: 0.999993]\n",
      "epoch:36 step:171200[D loss: 0.999882] [G loss: 1.000347]\n",
      "##############\n",
      "[2.49030875 2.35136791 2.33928679 3.50905192 1.55288943 7.3103981\n",
      " 2.25459284 3.67219595 3.99607826 4.2203882 ]\n",
      "##########\n",
      "epoch:36 step:171205[D loss: 0.999843] [G loss: 1.000398]\n",
      "epoch:36 step:171210[D loss: 1.000017] [G loss: 1.000470]\n",
      "epoch:36 step:171215[D loss: 0.999826] [G loss: 1.000375]\n",
      "epoch:36 step:171220[D loss: 0.999850] [G loss: 1.000095]\n",
      "epoch:36 step:171225[D loss: 1.000134] [G loss: 0.999928]\n",
      "epoch:36 step:171230[D loss: 0.999936] [G loss: 1.000100]\n",
      "epoch:36 step:171235[D loss: 0.999981] [G loss: 1.000104]\n",
      "epoch:36 step:171240[D loss: 0.999970] [G loss: 1.000123]\n",
      "epoch:36 step:171245[D loss: 1.000019] [G loss: 1.000088]\n",
      "epoch:36 step:171250[D loss: 1.000016] [G loss: 1.000043]\n",
      "epoch:36 step:171255[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:36 step:171260[D loss: 1.000010] [G loss: 1.000135]\n",
      "epoch:36 step:171265[D loss: 1.000112] [G loss: 0.999839]\n",
      "epoch:36 step:171270[D loss: 1.000015] [G loss: 0.999999]\n",
      "epoch:36 step:171275[D loss: 0.999899] [G loss: 1.000242]\n",
      "epoch:36 step:171280[D loss: 1.000112] [G loss: 1.000035]\n",
      "epoch:36 step:171285[D loss: 0.999917] [G loss: 1.000108]\n",
      "epoch:36 step:171290[D loss: 1.000018] [G loss: 1.000011]\n",
      "epoch:36 step:171295[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:36 step:171300[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:36 step:171305[D loss: 1.000004] [G loss: 1.000111]\n",
      "epoch:36 step:171310[D loss: 1.000069] [G loss: 0.999963]\n",
      "epoch:36 step:171315[D loss: 0.999971] [G loss: 1.000026]\n",
      "epoch:36 step:171320[D loss: 0.999937] [G loss: 1.000082]\n",
      "epoch:36 step:171325[D loss: 0.999881] [G loss: 1.000230]\n",
      "epoch:36 step:171330[D loss: 0.999971] [G loss: 1.000210]\n",
      "epoch:36 step:171335[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:36 step:171340[D loss: 0.999992] [G loss: 1.000209]\n",
      "epoch:36 step:171345[D loss: 1.000020] [G loss: 1.000049]\n",
      "epoch:36 step:171350[D loss: 1.000014] [G loss: 1.000072]\n",
      "epoch:36 step:171355[D loss: 0.999994] [G loss: 1.000151]\n",
      "epoch:36 step:171360[D loss: 0.999988] [G loss: 1.000093]\n",
      "epoch:36 step:171365[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:36 step:171370[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:36 step:171375[D loss: 1.000236] [G loss: 0.999696]\n",
      "epoch:36 step:171380[D loss: 1.000064] [G loss: 0.999927]\n",
      "epoch:36 step:171385[D loss: 1.000016] [G loss: 0.999986]\n",
      "epoch:36 step:171390[D loss: 0.999984] [G loss: 0.999951]\n",
      "epoch:36 step:171395[D loss: 0.999892] [G loss: 1.000147]\n",
      "epoch:36 step:171400[D loss: 0.999997] [G loss: 1.000069]\n",
      "##############\n",
      "[2.5674461  2.30726206 2.354634   3.81556533 1.63003174 7.06723236\n",
      " 2.27180765 3.88643041 4.07753363 4.87165626]\n",
      "##########\n",
      "epoch:36 step:171405[D loss: 0.999903] [G loss: 1.000206]\n",
      "epoch:36 step:171410[D loss: 0.999869] [G loss: 1.000370]\n",
      "epoch:36 step:171415[D loss: 0.999910] [G loss: 1.000102]\n",
      "epoch:36 step:171420[D loss: 0.999999] [G loss: 1.000088]\n",
      "epoch:36 step:171425[D loss: 0.999977] [G loss: 1.000024]\n",
      "epoch:36 step:171430[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:36 step:171435[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:36 step:171440[D loss: 0.999992] [G loss: 1.000017]\n",
      "epoch:36 step:171445[D loss: 0.999987] [G loss: 1.000114]\n",
      "epoch:36 step:171450[D loss: 1.000007] [G loss: 0.999975]\n",
      "epoch:36 step:171455[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:36 step:171460[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:36 step:171465[D loss: 0.999895] [G loss: 1.000170]\n",
      "epoch:36 step:171470[D loss: 0.999900] [G loss: 1.000238]\n",
      "epoch:36 step:171475[D loss: 0.999980] [G loss: 1.000137]\n",
      "epoch:36 step:171480[D loss: 0.999945] [G loss: 1.000108]\n",
      "epoch:36 step:171485[D loss: 0.999968] [G loss: 1.000112]\n",
      "epoch:36 step:171490[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:36 step:171495[D loss: 1.000005] [G loss: 0.999997]\n",
      "epoch:36 step:171500[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:36 step:171505[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:36 step:171510[D loss: 1.000046] [G loss: 0.999951]\n",
      "epoch:36 step:171515[D loss: 1.000006] [G loss: 0.999961]\n",
      "epoch:36 step:171520[D loss: 0.999937] [G loss: 1.000156]\n",
      "epoch:36 step:171525[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:36 step:171530[D loss: 1.000005] [G loss: 1.000072]\n",
      "epoch:36 step:171535[D loss: 1.000115] [G loss: 0.999856]\n",
      "epoch:36 step:171540[D loss: 0.999993] [G loss: 1.000008]\n",
      "epoch:36 step:171545[D loss: 0.999930] [G loss: 1.000059]\n",
      "epoch:36 step:171550[D loss: 1.000030] [G loss: 1.000074]\n",
      "epoch:36 step:171555[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:36 step:171560[D loss: 1.000119] [G loss: 0.999971]\n",
      "epoch:36 step:171565[D loss: 0.999894] [G loss: 1.000124]\n",
      "epoch:36 step:171570[D loss: 1.000004] [G loss: 0.999988]\n",
      "epoch:36 step:171575[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:36 step:171580[D loss: 0.999959] [G loss: 1.000042]\n",
      "epoch:36 step:171585[D loss: 0.999952] [G loss: 1.000111]\n",
      "epoch:36 step:171590[D loss: 1.000032] [G loss: 1.000002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:171595[D loss: 1.000033] [G loss: 1.000072]\n",
      "epoch:36 step:171600[D loss: 1.000002] [G loss: 1.000156]\n",
      "##############\n",
      "[2.52913863 2.29954181 2.36860038 3.8903559  1.6794671  7.39393216\n",
      " 2.43978058 3.83114516 4.19098906 4.99964175]\n",
      "##########\n",
      "epoch:36 step:171605[D loss: 1.000143] [G loss: 1.000281]\n",
      "epoch:36 step:171610[D loss: 0.999788] [G loss: 1.000229]\n",
      "epoch:36 step:171615[D loss: 0.999854] [G loss: 1.000221]\n",
      "epoch:36 step:171620[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:36 step:171625[D loss: 1.000227] [G loss: 0.999776]\n",
      "epoch:36 step:171630[D loss: 0.999974] [G loss: 0.999990]\n",
      "epoch:36 step:171635[D loss: 1.000072] [G loss: 1.000093]\n",
      "epoch:36 step:171640[D loss: 0.999849] [G loss: 1.000166]\n",
      "epoch:36 step:171645[D loss: 0.999996] [G loss: 0.999948]\n",
      "epoch:36 step:171650[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:36 step:171655[D loss: 0.999925] [G loss: 1.000173]\n",
      "epoch:36 step:171660[D loss: 0.999970] [G loss: 1.000149]\n",
      "epoch:36 step:171665[D loss: 1.000022] [G loss: 1.000005]\n",
      "epoch:36 step:171670[D loss: 1.000019] [G loss: 0.999982]\n",
      "epoch:36 step:171675[D loss: 0.999963] [G loss: 1.000003]\n",
      "epoch:36 step:171680[D loss: 0.999941] [G loss: 1.000111]\n",
      "epoch:36 step:171685[D loss: 0.999963] [G loss: 1.000019]\n",
      "epoch:36 step:171690[D loss: 0.999970] [G loss: 1.000015]\n",
      "epoch:36 step:171695[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:36 step:171700[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:36 step:171705[D loss: 1.000158] [G loss: 1.000012]\n",
      "epoch:36 step:171710[D loss: 0.999741] [G loss: 1.000263]\n",
      "epoch:36 step:171715[D loss: 0.999964] [G loss: 1.000194]\n",
      "epoch:36 step:171720[D loss: 0.999905] [G loss: 1.000166]\n",
      "epoch:36 step:171725[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:36 step:171730[D loss: 0.999922] [G loss: 1.000086]\n",
      "epoch:36 step:171735[D loss: 0.999964] [G loss: 1.000029]\n",
      "epoch:36 step:171740[D loss: 0.999992] [G loss: 1.000121]\n",
      "epoch:36 step:171745[D loss: 1.000003] [G loss: 1.000068]\n",
      "epoch:36 step:171750[D loss: 1.000008] [G loss: 1.000025]\n",
      "epoch:36 step:171755[D loss: 0.999930] [G loss: 1.000077]\n",
      "epoch:36 step:171760[D loss: 1.000129] [G loss: 0.999941]\n",
      "epoch:36 step:171765[D loss: 0.999953] [G loss: 0.999962]\n",
      "epoch:36 step:171770[D loss: 1.000077] [G loss: 0.999960]\n",
      "epoch:36 step:171775[D loss: 0.999975] [G loss: 1.000009]\n",
      "epoch:36 step:171780[D loss: 0.999959] [G loss: 1.000042]\n",
      "epoch:36 step:171785[D loss: 0.999943] [G loss: 1.000237]\n",
      "epoch:36 step:171790[D loss: 0.999952] [G loss: 1.000059]\n",
      "epoch:36 step:171795[D loss: 0.999971] [G loss: 1.000037]\n",
      "epoch:36 step:171800[D loss: 1.000014] [G loss: 1.000004]\n",
      "##############\n",
      "[2.59709511 2.34376054 2.38425103 3.44544256 1.70246225 6.93046355\n",
      " 2.39638613 3.76959351 4.23282243 5.77200915]\n",
      "##########\n",
      "epoch:36 step:171805[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:36 step:171810[D loss: 1.000015] [G loss: 0.999995]\n",
      "epoch:36 step:171815[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:36 step:171820[D loss: 1.000104] [G loss: 0.999964]\n",
      "epoch:36 step:171825[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:36 step:171830[D loss: 0.999929] [G loss: 1.000038]\n",
      "epoch:36 step:171835[D loss: 1.000006] [G loss: 1.000012]\n",
      "epoch:36 step:171840[D loss: 1.000014] [G loss: 0.999957]\n",
      "epoch:36 step:171845[D loss: 1.000177] [G loss: 0.999869]\n",
      "epoch:36 step:171850[D loss: 0.999916] [G loss: 1.000083]\n",
      "epoch:36 step:171855[D loss: 1.000015] [G loss: 1.000015]\n",
      "epoch:36 step:171860[D loss: 1.000056] [G loss: 0.999950]\n",
      "epoch:36 step:171865[D loss: 1.000004] [G loss: 0.999977]\n",
      "epoch:36 step:171870[D loss: 0.999925] [G loss: 1.000111]\n",
      "epoch:36 step:171875[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:36 step:171880[D loss: 1.000016] [G loss: 0.999997]\n",
      "epoch:36 step:171885[D loss: 1.000032] [G loss: 1.000021]\n",
      "epoch:36 step:171890[D loss: 1.000068] [G loss: 1.000042]\n",
      "epoch:36 step:171895[D loss: 0.999887] [G loss: 1.000090]\n",
      "epoch:36 step:171900[D loss: 0.999955] [G loss: 1.000118]\n",
      "epoch:36 step:171905[D loss: 1.000091] [G loss: 0.999986]\n",
      "epoch:36 step:171910[D loss: 0.999910] [G loss: 1.000163]\n",
      "epoch:36 step:171915[D loss: 1.000049] [G loss: 1.000162]\n",
      "epoch:36 step:171920[D loss: 0.999942] [G loss: 1.000110]\n",
      "epoch:36 step:171925[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:36 step:171930[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:36 step:171935[D loss: 0.999969] [G loss: 0.999987]\n",
      "epoch:36 step:171940[D loss: 0.999971] [G loss: 1.000103]\n",
      "epoch:36 step:171945[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:36 step:171950[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:36 step:171955[D loss: 0.999950] [G loss: 1.000139]\n",
      "epoch:36 step:171960[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:36 step:171965[D loss: 0.999982] [G loss: 1.000111]\n",
      "epoch:36 step:171970[D loss: 1.000038] [G loss: 1.000061]\n",
      "epoch:36 step:171975[D loss: 0.999988] [G loss: 1.000118]\n",
      "epoch:36 step:171980[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:36 step:171985[D loss: 1.000036] [G loss: 0.999976]\n",
      "epoch:36 step:171990[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:36 step:171995[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:36 step:172000[D loss: 0.999986] [G loss: 1.000042]\n",
      "##############\n",
      "[2.5525043  2.24749136 2.27757812 3.56150902 1.58023383 7.53017563\n",
      " 2.1629628  3.74476497 4.14775536 4.93466453]\n",
      "##########\n",
      "epoch:36 step:172005[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:36 step:172010[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:36 step:172015[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:36 step:172020[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:36 step:172025[D loss: 1.000122] [G loss: 0.999854]\n",
      "epoch:36 step:172030[D loss: 1.000014] [G loss: 0.999939]\n",
      "epoch:36 step:172035[D loss: 1.000024] [G loss: 0.999932]\n",
      "epoch:36 step:172040[D loss: 0.999940] [G loss: 1.000092]\n",
      "epoch:36 step:172045[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:36 step:172050[D loss: 0.999926] [G loss: 1.000089]\n",
      "epoch:36 step:172055[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:36 step:172060[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:36 step:172065[D loss: 0.999989] [G loss: 0.999996]\n",
      "epoch:36 step:172070[D loss: 1.000034] [G loss: 1.000094]\n",
      "epoch:36 step:172075[D loss: 0.999975] [G loss: 1.000111]\n",
      "epoch:36 step:172080[D loss: 0.999955] [G loss: 1.000115]\n",
      "epoch:36 step:172085[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:36 step:172090[D loss: 0.999961] [G loss: 1.000097]\n",
      "epoch:36 step:172095[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:36 step:172100[D loss: 1.000040] [G loss: 0.999865]\n",
      "epoch:36 step:172105[D loss: 0.999997] [G loss: 0.999989]\n",
      "epoch:36 step:172110[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:36 step:172115[D loss: 1.000009] [G loss: 1.000041]\n",
      "epoch:36 step:172120[D loss: 0.999900] [G loss: 1.000153]\n",
      "epoch:36 step:172125[D loss: 0.999967] [G loss: 1.000135]\n",
      "epoch:36 step:172130[D loss: 1.000047] [G loss: 1.000015]\n",
      "epoch:36 step:172135[D loss: 0.999897] [G loss: 1.000126]\n",
      "epoch:36 step:172140[D loss: 1.000033] [G loss: 0.999942]\n",
      "epoch:36 step:172145[D loss: 0.999969] [G loss: 1.000025]\n",
      "epoch:36 step:172150[D loss: 0.999923] [G loss: 1.000123]\n",
      "epoch:36 step:172155[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:36 step:172160[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:36 step:172165[D loss: 0.999985] [G loss: 1.000096]\n",
      "epoch:36 step:172170[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:36 step:172175[D loss: 1.000035] [G loss: 0.999990]\n",
      "epoch:36 step:172180[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:36 step:172185[D loss: 1.000139] [G loss: 0.999836]\n",
      "epoch:36 step:172190[D loss: 0.999988] [G loss: 1.000159]\n",
      "epoch:36 step:172195[D loss: 0.999827] [G loss: 1.000323]\n",
      "epoch:36 step:172200[D loss: 0.999962] [G loss: 1.000122]\n",
      "##############\n",
      "[2.62049742 2.33656616 2.19785361 3.65466535 1.58396581 7.23620763\n",
      " 2.33177055 3.81374652 4.06551112 5.35117676]\n",
      "##########\n",
      "epoch:36 step:172205[D loss: 1.000015] [G loss: 0.999977]\n",
      "epoch:36 step:172210[D loss: 1.000129] [G loss: 0.999875]\n",
      "epoch:36 step:172215[D loss: 0.999969] [G loss: 1.000033]\n",
      "epoch:36 step:172220[D loss: 0.999953] [G loss: 0.999988]\n",
      "epoch:36 step:172225[D loss: 0.999978] [G loss: 1.000103]\n",
      "epoch:36 step:172230[D loss: 1.000354] [G loss: 0.999588]\n",
      "epoch:36 step:172235[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:36 step:172240[D loss: 0.999949] [G loss: 0.999970]\n",
      "epoch:36 step:172245[D loss: 0.999965] [G loss: 1.000021]\n",
      "epoch:36 step:172250[D loss: 1.000007] [G loss: 1.000031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:172255[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:36 step:172260[D loss: 0.999884] [G loss: 1.000052]\n",
      "epoch:36 step:172265[D loss: 0.999974] [G loss: 1.000034]\n",
      "epoch:36 step:172270[D loss: 0.999965] [G loss: 1.000137]\n",
      "epoch:36 step:172275[D loss: 1.000053] [G loss: 1.000120]\n",
      "epoch:36 step:172280[D loss: 0.999864] [G loss: 1.000218]\n",
      "epoch:36 step:172285[D loss: 0.999954] [G loss: 1.000134]\n",
      "epoch:36 step:172290[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:36 step:172295[D loss: 0.999999] [G loss: 0.999985]\n",
      "epoch:36 step:172300[D loss: 1.000040] [G loss: 1.000007]\n",
      "epoch:36 step:172305[D loss: 0.999961] [G loss: 0.999978]\n",
      "epoch:36 step:172310[D loss: 0.999961] [G loss: 1.000031]\n",
      "epoch:36 step:172315[D loss: 1.000023] [G loss: 0.999969]\n",
      "epoch:36 step:172320[D loss: 0.999961] [G loss: 1.000021]\n",
      "epoch:36 step:172325[D loss: 0.999949] [G loss: 1.000019]\n",
      "epoch:36 step:172330[D loss: 0.999990] [G loss: 1.000017]\n",
      "epoch:36 step:172335[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:36 step:172340[D loss: 1.000025] [G loss: 1.000057]\n",
      "epoch:36 step:172345[D loss: 1.000014] [G loss: 1.000114]\n",
      "epoch:36 step:172350[D loss: 0.999957] [G loss: 1.000037]\n",
      "epoch:36 step:172355[D loss: 1.000000] [G loss: 1.000141]\n",
      "epoch:36 step:172360[D loss: 0.999949] [G loss: 1.000125]\n",
      "epoch:36 step:172365[D loss: 0.999915] [G loss: 1.000107]\n",
      "epoch:36 step:172370[D loss: 1.000093] [G loss: 0.999944]\n",
      "epoch:36 step:172375[D loss: 0.999941] [G loss: 1.000034]\n",
      "epoch:36 step:172380[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:36 step:172385[D loss: 0.999954] [G loss: 1.000035]\n",
      "epoch:36 step:172390[D loss: 1.000007] [G loss: 1.000043]\n",
      "epoch:36 step:172395[D loss: 0.999945] [G loss: 1.000027]\n",
      "epoch:36 step:172400[D loss: 0.999980] [G loss: 1.000081]\n",
      "##############\n",
      "[2.62749049 2.2978026  2.21612251 3.63403455 1.63072    7.51512623\n",
      " 2.42195762 3.75922125 4.06993574 5.17901017]\n",
      "##########\n",
      "epoch:36 step:172405[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:36 step:172410[D loss: 1.000064] [G loss: 0.999986]\n",
      "epoch:36 step:172415[D loss: 1.000078] [G loss: 0.999812]\n",
      "epoch:36 step:172420[D loss: 0.999871] [G loss: 1.000170]\n",
      "epoch:36 step:172425[D loss: 1.000170] [G loss: 0.999731]\n",
      "epoch:36 step:172430[D loss: 1.000155] [G loss: 0.999970]\n",
      "epoch:36 step:172435[D loss: 0.999958] [G loss: 1.000129]\n",
      "epoch:36 step:172440[D loss: 0.999940] [G loss: 1.000051]\n",
      "epoch:36 step:172445[D loss: 0.999996] [G loss: 0.999971]\n",
      "epoch:36 step:172450[D loss: 1.000065] [G loss: 0.999990]\n",
      "epoch:36 step:172455[D loss: 0.999889] [G loss: 1.000073]\n",
      "epoch:36 step:172460[D loss: 0.999983] [G loss: 1.000021]\n",
      "epoch:36 step:172465[D loss: 1.000073] [G loss: 0.999872]\n",
      "epoch:36 step:172470[D loss: 1.000338] [G loss: 0.999736]\n",
      "epoch:36 step:172475[D loss: 0.999913] [G loss: 1.000134]\n",
      "epoch:36 step:172480[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:36 step:172485[D loss: 0.999879] [G loss: 1.000213]\n",
      "epoch:36 step:172490[D loss: 0.999899] [G loss: 1.000199]\n",
      "epoch:36 step:172495[D loss: 0.999890] [G loss: 1.000209]\n",
      "epoch:36 step:172500[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:36 step:172505[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:36 step:172510[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:36 step:172515[D loss: 0.999925] [G loss: 1.000095]\n",
      "epoch:36 step:172520[D loss: 1.000070] [G loss: 0.999747]\n",
      "epoch:36 step:172525[D loss: 0.999816] [G loss: 1.000258]\n",
      "epoch:36 step:172530[D loss: 1.000228] [G loss: 0.999860]\n",
      "epoch:36 step:172535[D loss: 0.999963] [G loss: 0.999959]\n",
      "epoch:36 step:172540[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:36 step:172545[D loss: 0.999942] [G loss: 1.000032]\n",
      "epoch:36 step:172550[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:36 step:172555[D loss: 1.000062] [G loss: 1.000005]\n",
      "epoch:36 step:172560[D loss: 1.000053] [G loss: 0.999865]\n",
      "epoch:36 step:172565[D loss: 0.999923] [G loss: 1.000032]\n",
      "epoch:36 step:172570[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:36 step:172575[D loss: 1.000032] [G loss: 0.999944]\n",
      "epoch:36 step:172580[D loss: 0.999979] [G loss: 1.000104]\n",
      "epoch:36 step:172585[D loss: 0.999958] [G loss: 1.000116]\n",
      "epoch:36 step:172590[D loss: 1.000025] [G loss: 1.000027]\n",
      "epoch:36 step:172595[D loss: 1.000063] [G loss: 1.000004]\n",
      "epoch:36 step:172600[D loss: 0.999930] [G loss: 1.000211]\n",
      "##############\n",
      "[2.67660565 2.39620117 2.37970874 3.14365039 1.65640513 7.06047415\n",
      " 2.24968375 3.91716593 4.06758763 5.42000083]\n",
      "##########\n",
      "epoch:36 step:172605[D loss: 1.000141] [G loss: 0.999931]\n",
      "epoch:36 step:172610[D loss: 0.999872] [G loss: 1.000172]\n",
      "epoch:36 step:172615[D loss: 1.000059] [G loss: 0.999916]\n",
      "epoch:36 step:172620[D loss: 1.000004] [G loss: 0.999954]\n",
      "epoch:36 step:172625[D loss: 0.999973] [G loss: 0.999979]\n",
      "epoch:36 step:172630[D loss: 1.000072] [G loss: 0.999883]\n",
      "epoch:36 step:172635[D loss: 0.999992] [G loss: 0.999995]\n",
      "epoch:36 step:172640[D loss: 0.999880] [G loss: 1.000148]\n",
      "epoch:36 step:172645[D loss: 0.999904] [G loss: 1.000155]\n",
      "epoch:36 step:172650[D loss: 0.999970] [G loss: 1.000214]\n",
      "epoch:36 step:172655[D loss: 0.999897] [G loss: 1.000142]\n",
      "epoch:36 step:172660[D loss: 0.999932] [G loss: 1.000037]\n",
      "epoch:36 step:172665[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:36 step:172670[D loss: 0.999966] [G loss: 1.000038]\n",
      "epoch:36 step:172675[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:36 step:172680[D loss: 0.999960] [G loss: 1.000149]\n",
      "epoch:36 step:172685[D loss: 1.000050] [G loss: 0.999992]\n",
      "epoch:36 step:172690[D loss: 0.999935] [G loss: 1.000114]\n",
      "epoch:36 step:172695[D loss: 1.000061] [G loss: 0.999989]\n",
      "epoch:36 step:172700[D loss: 1.000230] [G loss: 0.999949]\n",
      "epoch:36 step:172705[D loss: 0.999903] [G loss: 1.000129]\n",
      "epoch:36 step:172710[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:36 step:172715[D loss: 0.999988] [G loss: 1.000085]\n",
      "epoch:36 step:172720[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:36 step:172725[D loss: 0.999912] [G loss: 1.000075]\n",
      "epoch:36 step:172730[D loss: 1.000020] [G loss: 1.000015]\n",
      "epoch:36 step:172735[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:36 step:172740[D loss: 1.000003] [G loss: 1.000065]\n",
      "epoch:36 step:172745[D loss: 0.999910] [G loss: 1.000151]\n",
      "epoch:36 step:172750[D loss: 1.000043] [G loss: 1.000177]\n",
      "epoch:36 step:172755[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:36 step:172760[D loss: 0.999958] [G loss: 1.000047]\n",
      "epoch:36 step:172765[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:36 step:172770[D loss: 1.000062] [G loss: 0.999912]\n",
      "epoch:36 step:172775[D loss: 0.999945] [G loss: 1.000047]\n",
      "epoch:36 step:172780[D loss: 0.999913] [G loss: 1.000028]\n",
      "epoch:36 step:172785[D loss: 1.000030] [G loss: 0.999992]\n",
      "epoch:36 step:172790[D loss: 0.999845] [G loss: 1.000179]\n",
      "epoch:36 step:172795[D loss: 0.999874] [G loss: 1.000221]\n",
      "epoch:36 step:172800[D loss: 0.999950] [G loss: 1.000141]\n",
      "##############\n",
      "[2.64770574 2.31580004 2.30276276 3.46422172 1.57976755 6.87902895\n",
      " 2.23676749 3.7524913  4.04914207 4.5714247 ]\n",
      "##########\n",
      "epoch:36 step:172805[D loss: 1.000033] [G loss: 1.000007]\n",
      "epoch:36 step:172810[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:36 step:172815[D loss: 1.000015] [G loss: 1.000033]\n",
      "epoch:36 step:172820[D loss: 1.000026] [G loss: 1.000163]\n",
      "epoch:36 step:172825[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:36 step:172830[D loss: 1.000079] [G loss: 1.000032]\n",
      "epoch:36 step:172835[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:36 step:172840[D loss: 1.000029] [G loss: 0.999946]\n",
      "epoch:36 step:172845[D loss: 1.000011] [G loss: 0.999993]\n",
      "epoch:36 step:172850[D loss: 1.000131] [G loss: 0.999762]\n",
      "epoch:36 step:172855[D loss: 0.999937] [G loss: 1.000051]\n",
      "epoch:36 step:172860[D loss: 1.000035] [G loss: 0.999942]\n",
      "epoch:36 step:172865[D loss: 0.999945] [G loss: 1.000133]\n",
      "epoch:36 step:172870[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:36 step:172875[D loss: 0.999984] [G loss: 1.000090]\n",
      "epoch:36 step:172880[D loss: 1.000130] [G loss: 1.000051]\n",
      "epoch:36 step:172885[D loss: 0.999911] [G loss: 1.000158]\n",
      "epoch:36 step:172890[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:36 step:172895[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:36 step:172900[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:36 step:172905[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:36 step:172910[D loss: 0.999964] [G loss: 1.000111]\n",
      "epoch:36 step:172915[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:36 step:172920[D loss: 0.999926] [G loss: 1.000076]\n",
      "epoch:36 step:172925[D loss: 1.000059] [G loss: 0.999980]\n",
      "epoch:36 step:172930[D loss: 0.999994] [G loss: 0.999956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:172935[D loss: 0.999912] [G loss: 1.000154]\n",
      "epoch:36 step:172940[D loss: 1.000062] [G loss: 1.000141]\n",
      "epoch:36 step:172945[D loss: 1.000030] [G loss: 1.000011]\n",
      "epoch:36 step:172950[D loss: 0.999899] [G loss: 1.000153]\n",
      "epoch:36 step:172955[D loss: 1.000006] [G loss: 1.000075]\n",
      "epoch:36 step:172960[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:36 step:172965[D loss: 0.999968] [G loss: 1.000000]\n",
      "epoch:36 step:172970[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:36 step:172975[D loss: 0.999934] [G loss: 1.000151]\n",
      "epoch:36 step:172980[D loss: 0.999989] [G loss: 1.000155]\n",
      "epoch:36 step:172985[D loss: 0.999891] [G loss: 1.000188]\n",
      "epoch:36 step:172990[D loss: 0.999923] [G loss: 1.000117]\n",
      "epoch:36 step:172995[D loss: 1.000003] [G loss: 1.000115]\n",
      "epoch:36 step:173000[D loss: 0.999989] [G loss: 1.000026]\n",
      "##############\n",
      "[2.63264187 2.27009337 2.25664891 3.5923169  1.60675289 7.06242896\n",
      " 2.30510061 3.84398029 4.12910883 5.47737272]\n",
      "##########\n",
      "epoch:36 step:173005[D loss: 0.999923] [G loss: 1.000184]\n",
      "epoch:36 step:173010[D loss: 1.000019] [G loss: 1.000200]\n",
      "epoch:36 step:173015[D loss: 0.999889] [G loss: 1.000139]\n",
      "epoch:36 step:173020[D loss: 0.999957] [G loss: 1.000027]\n",
      "epoch:36 step:173025[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:36 step:173030[D loss: 0.999980] [G loss: 1.000011]\n",
      "epoch:36 step:173035[D loss: 0.999982] [G loss: 1.000089]\n",
      "epoch:36 step:173040[D loss: 0.999881] [G loss: 1.000140]\n",
      "epoch:36 step:173045[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:36 step:173050[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:36 step:173055[D loss: 1.000063] [G loss: 0.999925]\n",
      "epoch:36 step:173060[D loss: 1.000070] [G loss: 0.999962]\n",
      "epoch:36 step:173065[D loss: 0.999886] [G loss: 1.000086]\n",
      "epoch:36 step:173070[D loss: 0.999917] [G loss: 1.000169]\n",
      "epoch:36 step:173075[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:36 step:173080[D loss: 1.000012] [G loss: 1.000068]\n",
      "epoch:36 step:173085[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:36 step:173090[D loss: 1.000068] [G loss: 0.999852]\n",
      "epoch:36 step:173095[D loss: 1.000025] [G loss: 0.999951]\n",
      "epoch:36 step:173100[D loss: 0.999937] [G loss: 1.000132]\n",
      "epoch:36 step:173105[D loss: 1.000080] [G loss: 1.000091]\n",
      "epoch:36 step:173110[D loss: 0.999963] [G loss: 1.000104]\n",
      "epoch:36 step:173115[D loss: 1.000026] [G loss: 1.000029]\n",
      "epoch:36 step:173120[D loss: 0.999960] [G loss: 1.000098]\n",
      "epoch:36 step:173125[D loss: 0.999891] [G loss: 1.000234]\n",
      "epoch:36 step:173130[D loss: 0.999970] [G loss: 1.000133]\n",
      "epoch:36 step:173135[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:36 step:173140[D loss: 1.000124] [G loss: 0.999896]\n",
      "epoch:36 step:173145[D loss: 0.999936] [G loss: 1.000097]\n",
      "epoch:36 step:173150[D loss: 0.999875] [G loss: 1.000105]\n",
      "epoch:36 step:173155[D loss: 0.999985] [G loss: 0.999998]\n",
      "epoch:36 step:173160[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:36 step:173165[D loss: 1.000061] [G loss: 1.000044]\n",
      "epoch:36 step:173170[D loss: 0.999884] [G loss: 1.000131]\n",
      "epoch:36 step:173175[D loss: 0.999955] [G loss: 1.000052]\n",
      "epoch:36 step:173180[D loss: 0.999944] [G loss: 1.000121]\n",
      "epoch:36 step:173185[D loss: 1.000054] [G loss: 1.000014]\n",
      "epoch:36 step:173190[D loss: 1.000022] [G loss: 1.000165]\n",
      "epoch:36 step:173195[D loss: 0.999920] [G loss: 1.000087]\n",
      "epoch:36 step:173200[D loss: 1.000049] [G loss: 0.999977]\n",
      "##############\n",
      "[2.60952731 2.31775258 2.22055364 3.39658583 1.59977306 7.09238115\n",
      " 2.26553041 3.64370902 4.01421308 5.79685428]\n",
      "##########\n",
      "epoch:36 step:173205[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:36 step:173210[D loss: 0.999959] [G loss: 1.000035]\n",
      "epoch:36 step:173215[D loss: 0.999966] [G loss: 1.000040]\n",
      "epoch:36 step:173220[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:36 step:173225[D loss: 0.999950] [G loss: 1.000177]\n",
      "epoch:36 step:173230[D loss: 0.999965] [G loss: 1.000118]\n",
      "epoch:36 step:173235[D loss: 1.000033] [G loss: 0.999951]\n",
      "epoch:36 step:173240[D loss: 1.000051] [G loss: 0.999965]\n",
      "epoch:36 step:173245[D loss: 1.000099] [G loss: 1.000032]\n",
      "epoch:36 step:173250[D loss: 0.999929] [G loss: 1.000052]\n",
      "epoch:36 step:173255[D loss: 0.999967] [G loss: 1.000024]\n",
      "epoch:36 step:173260[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:36 step:173265[D loss: 1.000065] [G loss: 0.999865]\n",
      "epoch:36 step:173270[D loss: 0.999892] [G loss: 1.000185]\n",
      "epoch:36 step:173275[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:36 step:173280[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:36 step:173285[D loss: 1.000058] [G loss: 0.999875]\n",
      "epoch:36 step:173290[D loss: 0.999958] [G loss: 1.000217]\n",
      "epoch:36 step:173295[D loss: 0.999942] [G loss: 1.000149]\n",
      "epoch:36 step:173300[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:36 step:173305[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:36 step:173310[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:36 step:173315[D loss: 0.999957] [G loss: 1.000019]\n",
      "epoch:36 step:173320[D loss: 0.999977] [G loss: 1.000014]\n",
      "epoch:36 step:173325[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:36 step:173330[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:36 step:173335[D loss: 1.000105] [G loss: 0.999992]\n",
      "epoch:36 step:173340[D loss: 0.999975] [G loss: 0.999949]\n",
      "epoch:36 step:173345[D loss: 0.999946] [G loss: 1.000016]\n",
      "epoch:37 step:173350[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:37 step:173355[D loss: 1.000005] [G loss: 0.999999]\n",
      "epoch:37 step:173360[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:37 step:173365[D loss: 0.999996] [G loss: 1.000015]\n",
      "epoch:37 step:173370[D loss: 0.999954] [G loss: 1.000042]\n",
      "epoch:37 step:173375[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:37 step:173380[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:37 step:173385[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:37 step:173390[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:37 step:173395[D loss: 1.000114] [G loss: 0.999939]\n",
      "epoch:37 step:173400[D loss: 0.999923] [G loss: 1.000162]\n",
      "##############\n",
      "[2.65884001 2.38205254 2.35714967 3.71782108 1.60778644 6.2768686\n",
      " 2.49995397 3.79442485 4.05739922 5.86835821]\n",
      "##########\n",
      "epoch:37 step:173405[D loss: 0.999855] [G loss: 1.000140]\n",
      "epoch:37 step:173410[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:37 step:173415[D loss: 0.999978] [G loss: 0.999992]\n",
      "epoch:37 step:173420[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:37 step:173425[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:37 step:173430[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:37 step:173435[D loss: 1.000040] [G loss: 0.999968]\n",
      "epoch:37 step:173440[D loss: 1.000017] [G loss: 0.999903]\n",
      "epoch:37 step:173445[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:37 step:173450[D loss: 1.000061] [G loss: 0.999982]\n",
      "epoch:37 step:173455[D loss: 1.000069] [G loss: 0.999969]\n",
      "epoch:37 step:173460[D loss: 0.999929] [G loss: 1.000091]\n",
      "epoch:37 step:173465[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:37 step:173470[D loss: 0.999998] [G loss: 0.999957]\n",
      "epoch:37 step:173475[D loss: 0.999931] [G loss: 1.000088]\n",
      "epoch:37 step:173480[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:37 step:173485[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:37 step:173490[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:37 step:173495[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:37 step:173500[D loss: 1.000071] [G loss: 0.999952]\n",
      "epoch:37 step:173505[D loss: 0.999972] [G loss: 1.000140]\n",
      "epoch:37 step:173510[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:37 step:173515[D loss: 0.999921] [G loss: 1.000219]\n",
      "epoch:37 step:173520[D loss: 0.999992] [G loss: 0.999989]\n",
      "epoch:37 step:173525[D loss: 1.000240] [G loss: 0.999848]\n",
      "epoch:37 step:173530[D loss: 0.999959] [G loss: 1.000154]\n",
      "epoch:37 step:173535[D loss: 0.999952] [G loss: 1.000113]\n",
      "epoch:37 step:173540[D loss: 1.000041] [G loss: 0.999879]\n",
      "epoch:37 step:173545[D loss: 1.000215] [G loss: 0.999814]\n",
      "epoch:37 step:173550[D loss: 1.000156] [G loss: 0.999674]\n",
      "epoch:37 step:173555[D loss: 0.999919] [G loss: 1.000030]\n",
      "epoch:37 step:173560[D loss: 1.000165] [G loss: 0.999673]\n",
      "epoch:37 step:173565[D loss: 0.999959] [G loss: 1.000091]\n",
      "epoch:37 step:173570[D loss: 1.000065] [G loss: 0.999902]\n",
      "epoch:37 step:173575[D loss: 1.000065] [G loss: 0.999843]\n",
      "epoch:37 step:173580[D loss: 0.999887] [G loss: 1.000169]\n",
      "epoch:37 step:173585[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:37 step:173590[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:37 step:173595[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:37 step:173600[D loss: 0.999929] [G loss: 1.000104]\n",
      "##############\n",
      "[2.58698324 2.27303927 2.25906472 3.56177749 1.5787886  7.11365699\n",
      " 2.30263843 3.83718386 4.08753465 5.39284708]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:173605[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:37 step:173610[D loss: 1.000021] [G loss: 1.000024]\n",
      "epoch:37 step:173615[D loss: 0.999975] [G loss: 1.000135]\n",
      "epoch:37 step:173620[D loss: 0.999990] [G loss: 1.000013]\n",
      "epoch:37 step:173625[D loss: 0.999930] [G loss: 1.000145]\n",
      "epoch:37 step:173630[D loss: 0.999898] [G loss: 1.000220]\n",
      "epoch:37 step:173635[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:37 step:173640[D loss: 0.999820] [G loss: 1.000290]\n",
      "epoch:37 step:173645[D loss: 0.999987] [G loss: 1.000144]\n",
      "epoch:37 step:173650[D loss: 0.999995] [G loss: 1.000084]\n",
      "epoch:37 step:173655[D loss: 1.000051] [G loss: 1.000022]\n",
      "epoch:37 step:173660[D loss: 0.999941] [G loss: 1.000224]\n",
      "epoch:37 step:173665[D loss: 0.999958] [G loss: 1.000123]\n",
      "epoch:37 step:173670[D loss: 1.000045] [G loss: 0.999933]\n",
      "epoch:37 step:173675[D loss: 1.000004] [G loss: 0.999962]\n",
      "epoch:37 step:173680[D loss: 1.000010] [G loss: 1.000019]\n",
      "epoch:37 step:173685[D loss: 1.000035] [G loss: 0.999961]\n",
      "epoch:37 step:173690[D loss: 1.000131] [G loss: 1.000024]\n",
      "epoch:37 step:173695[D loss: 0.999948] [G loss: 1.000081]\n",
      "epoch:37 step:173700[D loss: 1.000148] [G loss: 0.999798]\n",
      "epoch:37 step:173705[D loss: 0.999979] [G loss: 1.000176]\n",
      "epoch:37 step:173710[D loss: 0.999859] [G loss: 1.000179]\n",
      "epoch:37 step:173715[D loss: 0.999934] [G loss: 1.000056]\n",
      "epoch:37 step:173720[D loss: 1.000020] [G loss: 0.999952]\n",
      "epoch:37 step:173725[D loss: 1.000052] [G loss: 0.999949]\n",
      "epoch:37 step:173730[D loss: 0.999921] [G loss: 1.000098]\n",
      "epoch:37 step:173735[D loss: 1.000015] [G loss: 0.999984]\n",
      "epoch:37 step:173740[D loss: 1.000000] [G loss: 1.000081]\n",
      "epoch:37 step:173745[D loss: 0.999995] [G loss: 0.999975]\n",
      "epoch:37 step:173750[D loss: 1.000071] [G loss: 1.000026]\n",
      "epoch:37 step:173755[D loss: 0.999893] [G loss: 1.000181]\n",
      "epoch:37 step:173760[D loss: 1.000035] [G loss: 1.000090]\n",
      "epoch:37 step:173765[D loss: 0.999894] [G loss: 1.000181]\n",
      "epoch:37 step:173770[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:37 step:173775[D loss: 1.000004] [G loss: 1.000017]\n",
      "epoch:37 step:173780[D loss: 0.999955] [G loss: 1.000046]\n",
      "epoch:37 step:173785[D loss: 1.000016] [G loss: 1.000070]\n",
      "epoch:37 step:173790[D loss: 1.000092] [G loss: 1.000084]\n",
      "epoch:37 step:173795[D loss: 0.999915] [G loss: 1.000174]\n",
      "epoch:37 step:173800[D loss: 0.999994] [G loss: 1.000127]\n",
      "##############\n",
      "[2.57694078 2.28507579 2.25889666 3.24932164 1.63275431 7.29757414\n",
      " 2.43100165 3.75510216 3.97331998 4.34920711]\n",
      "##########\n",
      "epoch:37 step:173805[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:37 step:173810[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:37 step:173815[D loss: 0.999964] [G loss: 1.000102]\n",
      "epoch:37 step:173820[D loss: 1.000066] [G loss: 0.999998]\n",
      "epoch:37 step:173825[D loss: 1.000109] [G loss: 0.999875]\n",
      "epoch:37 step:173830[D loss: 1.000039] [G loss: 1.000077]\n",
      "epoch:37 step:173835[D loss: 0.999870] [G loss: 1.000286]\n",
      "epoch:37 step:173840[D loss: 0.999927] [G loss: 1.000115]\n",
      "epoch:37 step:173845[D loss: 1.000047] [G loss: 1.000125]\n",
      "epoch:37 step:173850[D loss: 0.999919] [G loss: 1.000098]\n",
      "epoch:37 step:173855[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:37 step:173860[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:37 step:173865[D loss: 1.000002] [G loss: 0.999984]\n",
      "epoch:37 step:173870[D loss: 1.000098] [G loss: 0.999869]\n",
      "epoch:37 step:173875[D loss: 0.999839] [G loss: 1.000134]\n",
      "epoch:37 step:173880[D loss: 1.000018] [G loss: 1.000133]\n",
      "epoch:37 step:173885[D loss: 1.000024] [G loss: 1.000052]\n",
      "epoch:37 step:173890[D loss: 0.999793] [G loss: 1.000235]\n",
      "epoch:37 step:173895[D loss: 1.000012] [G loss: 1.000080]\n",
      "epoch:37 step:173900[D loss: 0.999891] [G loss: 1.000180]\n",
      "epoch:37 step:173905[D loss: 0.999895] [G loss: 1.000220]\n",
      "epoch:37 step:173910[D loss: 0.999969] [G loss: 1.000116]\n",
      "epoch:37 step:173915[D loss: 0.999801] [G loss: 1.000337]\n",
      "epoch:37 step:173920[D loss: 0.999903] [G loss: 1.000274]\n",
      "epoch:37 step:173925[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:37 step:173930[D loss: 1.000015] [G loss: 1.000036]\n",
      "epoch:37 step:173935[D loss: 1.000198] [G loss: 0.999950]\n",
      "epoch:37 step:173940[D loss: 1.000335] [G loss: 0.999706]\n",
      "epoch:37 step:173945[D loss: 0.999940] [G loss: 0.999960]\n",
      "epoch:37 step:173950[D loss: 0.999981] [G loss: 1.000102]\n",
      "epoch:37 step:173955[D loss: 0.999932] [G loss: 1.000140]\n",
      "epoch:37 step:173960[D loss: 0.999949] [G loss: 1.000136]\n",
      "epoch:37 step:173965[D loss: 0.999981] [G loss: 1.000149]\n",
      "epoch:37 step:173970[D loss: 0.999891] [G loss: 1.000101]\n",
      "epoch:37 step:173975[D loss: 1.000039] [G loss: 1.000012]\n",
      "epoch:37 step:173980[D loss: 0.999891] [G loss: 1.000135]\n",
      "epoch:37 step:173985[D loss: 1.000026] [G loss: 1.000046]\n",
      "epoch:37 step:173990[D loss: 1.000053] [G loss: 0.999866]\n",
      "epoch:37 step:173995[D loss: 0.999921] [G loss: 1.000054]\n",
      "epoch:37 step:174000[D loss: 0.999962] [G loss: 1.000105]\n",
      "##############\n",
      "[2.59655963 2.22679442 2.1813918  3.72993627 1.59544227 7.09767131\n",
      " 2.27984752 3.76620948 4.06275649 4.8670912 ]\n",
      "##########\n",
      "epoch:37 step:174005[D loss: 0.999942] [G loss: 1.000217]\n",
      "epoch:37 step:174010[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:37 step:174015[D loss: 0.999888] [G loss: 1.000212]\n",
      "epoch:37 step:174020[D loss: 0.999887] [G loss: 1.000138]\n",
      "epoch:37 step:174025[D loss: 0.999929] [G loss: 1.000110]\n",
      "epoch:37 step:174030[D loss: 1.000021] [G loss: 1.000040]\n",
      "epoch:37 step:174035[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:37 step:174040[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:37 step:174045[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:37 step:174050[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:37 step:174055[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:37 step:174060[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:37 step:174065[D loss: 0.999933] [G loss: 1.000101]\n",
      "epoch:37 step:174070[D loss: 1.000052] [G loss: 0.999948]\n",
      "epoch:37 step:174075[D loss: 0.999799] [G loss: 1.000225]\n",
      "epoch:37 step:174080[D loss: 1.000082] [G loss: 1.000085]\n",
      "epoch:37 step:174085[D loss: 0.999947] [G loss: 1.000085]\n",
      "epoch:37 step:174090[D loss: 0.999993] [G loss: 0.999998]\n",
      "epoch:37 step:174095[D loss: 0.999999] [G loss: 0.999966]\n",
      "epoch:37 step:174100[D loss: 0.999975] [G loss: 0.999996]\n",
      "epoch:37 step:174105[D loss: 0.999947] [G loss: 1.000061]\n",
      "epoch:37 step:174110[D loss: 0.999926] [G loss: 1.000102]\n",
      "epoch:37 step:174115[D loss: 1.000006] [G loss: 1.000043]\n",
      "epoch:37 step:174120[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:37 step:174125[D loss: 0.999936] [G loss: 1.000175]\n",
      "epoch:37 step:174130[D loss: 1.000002] [G loss: 1.000005]\n",
      "epoch:37 step:174135[D loss: 1.000034] [G loss: 0.999911]\n",
      "epoch:37 step:174140[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:37 step:174145[D loss: 0.999944] [G loss: 1.000094]\n",
      "epoch:37 step:174150[D loss: 1.000074] [G loss: 1.000008]\n",
      "epoch:37 step:174155[D loss: 0.999876] [G loss: 1.000244]\n",
      "epoch:37 step:174160[D loss: 0.999905] [G loss: 1.000187]\n",
      "epoch:37 step:174165[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:37 step:174170[D loss: 1.000084] [G loss: 0.999924]\n",
      "epoch:37 step:174175[D loss: 1.000043] [G loss: 0.999871]\n",
      "epoch:37 step:174180[D loss: 0.999945] [G loss: 1.000022]\n",
      "epoch:37 step:174185[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:37 step:174190[D loss: 1.000017] [G loss: 1.000023]\n",
      "epoch:37 step:174195[D loss: 0.999942] [G loss: 1.000109]\n",
      "epoch:37 step:174200[D loss: 0.999992] [G loss: 1.000041]\n",
      "##############\n",
      "[2.63850466 2.31925099 2.24634474 3.93596631 1.63842601 7.49638807\n",
      " 2.29734607 3.93655054 4.06220396 4.56797243]\n",
      "##########\n",
      "epoch:37 step:174205[D loss: 1.000014] [G loss: 1.000040]\n",
      "epoch:37 step:174210[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:37 step:174215[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:37 step:174220[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:37 step:174225[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:37 step:174230[D loss: 1.000005] [G loss: 0.999991]\n",
      "epoch:37 step:174235[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:37 step:174240[D loss: 1.000027] [G loss: 0.999961]\n",
      "epoch:37 step:174245[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:37 step:174250[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:37 step:174255[D loss: 1.000035] [G loss: 0.999957]\n",
      "epoch:37 step:174260[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:37 step:174265[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:37 step:174270[D loss: 1.000048] [G loss: 0.999961]\n",
      "epoch:37 step:174275[D loss: 1.000011] [G loss: 0.999976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:174280[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:37 step:174285[D loss: 1.000081] [G loss: 0.999995]\n",
      "epoch:37 step:174290[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:37 step:174295[D loss: 0.999960] [G loss: 1.000063]\n",
      "epoch:37 step:174300[D loss: 1.000009] [G loss: 1.000060]\n",
      "epoch:37 step:174305[D loss: 0.999973] [G loss: 1.000030]\n",
      "epoch:37 step:174310[D loss: 1.000010] [G loss: 0.999996]\n",
      "epoch:37 step:174315[D loss: 1.000097] [G loss: 0.999970]\n",
      "epoch:37 step:174320[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:37 step:174325[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:37 step:174330[D loss: 1.000071] [G loss: 1.000081]\n",
      "epoch:37 step:174335[D loss: 1.000145] [G loss: 1.000123]\n",
      "epoch:37 step:174340[D loss: 0.999930] [G loss: 1.000266]\n",
      "epoch:37 step:174345[D loss: 0.999920] [G loss: 1.000390]\n",
      "epoch:37 step:174350[D loss: 0.999864] [G loss: 1.000297]\n",
      "epoch:37 step:174355[D loss: 0.999994] [G loss: 1.000148]\n",
      "epoch:37 step:174360[D loss: 0.999977] [G loss: 1.000182]\n",
      "epoch:37 step:174365[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:37 step:174370[D loss: 0.999990] [G loss: 0.999972]\n",
      "epoch:37 step:174375[D loss: 1.000103] [G loss: 0.999733]\n",
      "epoch:37 step:174380[D loss: 1.000086] [G loss: 0.999764]\n",
      "epoch:37 step:174385[D loss: 0.999999] [G loss: 0.999745]\n",
      "epoch:37 step:174390[D loss: 1.000043] [G loss: 0.999742]\n",
      "epoch:37 step:174395[D loss: 0.999992] [G loss: 0.999970]\n",
      "epoch:37 step:174400[D loss: 1.000145] [G loss: 1.000008]\n",
      "##############\n",
      "[2.59114745 2.22497696 2.15306861 3.40547357 1.53176572 7.17026328\n",
      " 2.4126895  3.5209589  3.98686055 4.71342613]\n",
      "##########\n",
      "epoch:37 step:174405[D loss: 1.000106] [G loss: 0.999860]\n",
      "epoch:37 step:174410[D loss: 0.999994] [G loss: 1.000080]\n",
      "epoch:37 step:174415[D loss: 0.999917] [G loss: 1.000164]\n",
      "epoch:37 step:174420[D loss: 1.000031] [G loss: 1.000058]\n",
      "epoch:37 step:174425[D loss: 1.000089] [G loss: 0.999999]\n",
      "epoch:37 step:174430[D loss: 1.000063] [G loss: 1.000482]\n",
      "epoch:37 step:174435[D loss: 0.999672] [G loss: 1.000488]\n",
      "epoch:37 step:174440[D loss: 0.999929] [G loss: 1.000245]\n",
      "epoch:37 step:174445[D loss: 0.999995] [G loss: 1.000089]\n",
      "epoch:37 step:174450[D loss: 0.999896] [G loss: 1.000145]\n",
      "epoch:37 step:174455[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:37 step:174460[D loss: 1.000085] [G loss: 1.000019]\n",
      "epoch:37 step:174465[D loss: 0.999976] [G loss: 0.999989]\n",
      "epoch:37 step:174470[D loss: 1.000043] [G loss: 1.000042]\n",
      "epoch:37 step:174475[D loss: 1.000172] [G loss: 0.999773]\n",
      "epoch:37 step:174480[D loss: 1.000172] [G loss: 1.000170]\n",
      "epoch:37 step:174485[D loss: 0.999813] [G loss: 1.000240]\n",
      "epoch:37 step:174490[D loss: 0.999819] [G loss: 1.000116]\n",
      "epoch:37 step:174495[D loss: 1.000133] [G loss: 0.999956]\n",
      "epoch:37 step:174500[D loss: 0.999929] [G loss: 1.000188]\n",
      "epoch:37 step:174505[D loss: 0.999984] [G loss: 1.000135]\n",
      "epoch:37 step:174510[D loss: 0.999917] [G loss: 1.000426]\n",
      "epoch:37 step:174515[D loss: 1.000077] [G loss: 1.000036]\n",
      "epoch:37 step:174520[D loss: 0.999873] [G loss: 1.000529]\n",
      "epoch:37 step:174525[D loss: 0.999901] [G loss: 1.000184]\n",
      "epoch:37 step:174530[D loss: 1.000015] [G loss: 1.000132]\n",
      "epoch:37 step:174535[D loss: 0.999939] [G loss: 1.000083]\n",
      "epoch:37 step:174540[D loss: 1.000022] [G loss: 1.000000]\n",
      "epoch:37 step:174545[D loss: 1.000073] [G loss: 0.999940]\n",
      "epoch:37 step:174550[D loss: 1.000040] [G loss: 0.999994]\n",
      "epoch:37 step:174555[D loss: 0.999918] [G loss: 1.000104]\n",
      "epoch:37 step:174560[D loss: 0.999949] [G loss: 0.999996]\n",
      "epoch:37 step:174565[D loss: 1.000183] [G loss: 0.999894]\n",
      "epoch:37 step:174570[D loss: 0.999934] [G loss: 1.000070]\n",
      "epoch:37 step:174575[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:37 step:174580[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:37 step:174585[D loss: 0.999941] [G loss: 1.000158]\n",
      "epoch:37 step:174590[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:37 step:174595[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:37 step:174600[D loss: 0.999981] [G loss: 1.000063]\n",
      "##############\n",
      "[2.62435183 2.34696592 2.25397196 3.78031032 1.63947126 7.02761673\n",
      " 2.3867695  3.84451113 4.03288889 5.97890072]\n",
      "##########\n",
      "epoch:37 step:174605[D loss: 1.000026] [G loss: 0.999975]\n",
      "epoch:37 step:174610[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:37 step:174615[D loss: 1.000045] [G loss: 1.000049]\n",
      "epoch:37 step:174620[D loss: 0.999907] [G loss: 1.000176]\n",
      "epoch:37 step:174625[D loss: 0.999924] [G loss: 1.000099]\n",
      "epoch:37 step:174630[D loss: 0.999952] [G loss: 1.000112]\n",
      "epoch:37 step:174635[D loss: 1.000059] [G loss: 1.000072]\n",
      "epoch:37 step:174640[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:37 step:174645[D loss: 0.999994] [G loss: 1.000101]\n",
      "epoch:37 step:174650[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:37 step:174655[D loss: 0.999929] [G loss: 1.000039]\n",
      "epoch:37 step:174660[D loss: 1.000080] [G loss: 0.999975]\n",
      "epoch:37 step:174665[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:37 step:174670[D loss: 0.999924] [G loss: 1.000106]\n",
      "epoch:37 step:174675[D loss: 0.999974] [G loss: 1.000176]\n",
      "epoch:37 step:174680[D loss: 0.999882] [G loss: 1.000220]\n",
      "epoch:37 step:174685[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:37 step:174690[D loss: 0.999956] [G loss: 1.000142]\n",
      "epoch:37 step:174695[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:37 step:174700[D loss: 1.000014] [G loss: 0.999990]\n",
      "epoch:37 step:174705[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:37 step:174710[D loss: 0.999979] [G loss: 1.000128]\n",
      "epoch:37 step:174715[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:37 step:174720[D loss: 1.000011] [G loss: 1.000056]\n",
      "epoch:37 step:174725[D loss: 0.999976] [G loss: 1.000134]\n",
      "epoch:37 step:174730[D loss: 1.000103] [G loss: 0.999905]\n",
      "epoch:37 step:174735[D loss: 0.999955] [G loss: 1.000216]\n",
      "epoch:37 step:174740[D loss: 0.999908] [G loss: 1.000247]\n",
      "epoch:37 step:174745[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:37 step:174750[D loss: 1.000012] [G loss: 1.000027]\n",
      "epoch:37 step:174755[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:37 step:174760[D loss: 0.999950] [G loss: 1.000031]\n",
      "epoch:37 step:174765[D loss: 0.999978] [G loss: 1.000162]\n",
      "epoch:37 step:174770[D loss: 0.999893] [G loss: 1.000216]\n",
      "epoch:37 step:174775[D loss: 0.999904] [G loss: 1.000134]\n",
      "epoch:37 step:174780[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:37 step:174785[D loss: 1.000097] [G loss: 0.999857]\n",
      "epoch:37 step:174790[D loss: 0.999924] [G loss: 1.000155]\n",
      "epoch:37 step:174795[D loss: 1.000004] [G loss: 1.000088]\n",
      "epoch:37 step:174800[D loss: 0.999982] [G loss: 1.000083]\n",
      "##############\n",
      "[2.63696625 2.29351461 2.36118878 4.08741183 1.56348788 7.68885156\n",
      " 2.3469793  3.70346824 4.10500623 5.43296363]\n",
      "##########\n",
      "epoch:37 step:174805[D loss: 0.999974] [G loss: 1.000116]\n",
      "epoch:37 step:174810[D loss: 0.999981] [G loss: 1.000098]\n",
      "epoch:37 step:174815[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:37 step:174820[D loss: 1.000053] [G loss: 1.000012]\n",
      "epoch:37 step:174825[D loss: 0.999928] [G loss: 1.000115]\n",
      "epoch:37 step:174830[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:37 step:174835[D loss: 0.999934] [G loss: 1.000122]\n",
      "epoch:37 step:174840[D loss: 0.999936] [G loss: 1.000059]\n",
      "epoch:37 step:174845[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:37 step:174850[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:37 step:174855[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:37 step:174860[D loss: 1.000063] [G loss: 0.999959]\n",
      "epoch:37 step:174865[D loss: 0.999944] [G loss: 1.000031]\n",
      "epoch:37 step:174870[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:37 step:174875[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:37 step:174880[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:37 step:174885[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:37 step:174890[D loss: 1.000048] [G loss: 0.999991]\n",
      "epoch:37 step:174895[D loss: 1.000026] [G loss: 1.000094]\n",
      "epoch:37 step:174900[D loss: 1.000039] [G loss: 1.000014]\n",
      "epoch:37 step:174905[D loss: 0.999903] [G loss: 1.000123]\n",
      "epoch:37 step:174910[D loss: 0.999962] [G loss: 1.000099]\n",
      "epoch:37 step:174915[D loss: 0.999970] [G loss: 1.000142]\n",
      "epoch:37 step:174920[D loss: 0.999916] [G loss: 1.000217]\n",
      "epoch:37 step:174925[D loss: 1.000008] [G loss: 1.000094]\n",
      "epoch:37 step:174930[D loss: 1.000018] [G loss: 0.999960]\n",
      "epoch:37 step:174935[D loss: 1.000028] [G loss: 0.999879]\n",
      "epoch:37 step:174940[D loss: 0.999922] [G loss: 0.999932]\n",
      "epoch:37 step:174945[D loss: 1.000140] [G loss: 0.999700]\n",
      "epoch:37 step:174950[D loss: 1.000269] [G loss: 0.999800]\n",
      "epoch:37 step:174955[D loss: 1.000112] [G loss: 0.999820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:174960[D loss: 1.000107] [G loss: 0.999939]\n",
      "epoch:37 step:174965[D loss: 0.999920] [G loss: 0.999906]\n",
      "epoch:37 step:174970[D loss: 0.999932] [G loss: 1.000019]\n",
      "epoch:37 step:174975[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:37 step:174980[D loss: 1.000123] [G loss: 0.999970]\n",
      "epoch:37 step:174985[D loss: 0.999935] [G loss: 1.000022]\n",
      "epoch:37 step:174990[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:37 step:174995[D loss: 0.999996] [G loss: 1.000110]\n",
      "epoch:37 step:175000[D loss: 0.999946] [G loss: 1.000073]\n",
      "##############\n",
      "[2.62765576 2.315782   2.26758598 3.38873863 1.55770698 7.12904643\n",
      " 2.22283149 3.71281833 3.96310898 4.95019014]\n",
      "##########\n",
      "epoch:37 step:175005[D loss: 0.999940] [G loss: 1.000071]\n",
      "epoch:37 step:175010[D loss: 1.000001] [G loss: 0.999986]\n",
      "epoch:37 step:175015[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:37 step:175020[D loss: 0.999966] [G loss: 1.000036]\n",
      "epoch:37 step:175025[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:37 step:175030[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:37 step:175035[D loss: 1.000002] [G loss: 1.000029]\n",
      "epoch:37 step:175040[D loss: 1.000003] [G loss: 0.999997]\n",
      "epoch:37 step:175045[D loss: 0.999956] [G loss: 1.000128]\n",
      "epoch:37 step:175050[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:37 step:175055[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:37 step:175060[D loss: 0.999955] [G loss: 1.000108]\n",
      "epoch:37 step:175065[D loss: 1.000056] [G loss: 0.999928]\n",
      "epoch:37 step:175070[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:37 step:175075[D loss: 1.000060] [G loss: 1.000065]\n",
      "epoch:37 step:175080[D loss: 0.999922] [G loss: 1.000103]\n",
      "epoch:37 step:175085[D loss: 1.000014] [G loss: 1.000059]\n",
      "epoch:37 step:175090[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:37 step:175095[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:37 step:175100[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:37 step:175105[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:37 step:175110[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:37 step:175115[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:37 step:175120[D loss: 1.000009] [G loss: 0.999979]\n",
      "epoch:37 step:175125[D loss: 0.999992] [G loss: 0.999951]\n",
      "epoch:37 step:175130[D loss: 0.999917] [G loss: 1.000100]\n",
      "epoch:37 step:175135[D loss: 1.000073] [G loss: 1.000022]\n",
      "epoch:37 step:175140[D loss: 0.999940] [G loss: 1.000072]\n",
      "epoch:37 step:175145[D loss: 0.999968] [G loss: 1.000185]\n",
      "epoch:37 step:175150[D loss: 0.999982] [G loss: 1.000134]\n",
      "epoch:37 step:175155[D loss: 0.999924] [G loss: 1.000106]\n",
      "epoch:37 step:175160[D loss: 1.000023] [G loss: 1.000008]\n",
      "epoch:37 step:175165[D loss: 1.000136] [G loss: 0.999911]\n",
      "epoch:37 step:175170[D loss: 1.000092] [G loss: 0.999894]\n",
      "epoch:37 step:175175[D loss: 1.000065] [G loss: 0.999899]\n",
      "epoch:37 step:175180[D loss: 1.000057] [G loss: 1.000179]\n",
      "epoch:37 step:175185[D loss: 0.999951] [G loss: 1.000221]\n",
      "epoch:37 step:175190[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:37 step:175195[D loss: 1.000080] [G loss: 0.999924]\n",
      "epoch:37 step:175200[D loss: 0.999942] [G loss: 1.000150]\n",
      "##############\n",
      "[2.65983468 2.3230805  2.31039062 3.57097805 1.68307166 7.40311783\n",
      " 2.20781152 3.74992972 4.05394247 4.89989028]\n",
      "##########\n",
      "epoch:37 step:175205[D loss: 0.999984] [G loss: 1.000101]\n",
      "epoch:37 step:175210[D loss: 0.999957] [G loss: 1.000102]\n",
      "epoch:37 step:175215[D loss: 0.999922] [G loss: 1.000311]\n",
      "epoch:37 step:175220[D loss: 1.000004] [G loss: 1.000014]\n",
      "epoch:37 step:175225[D loss: 1.000010] [G loss: 1.000005]\n",
      "epoch:37 step:175230[D loss: 1.000060] [G loss: 0.999871]\n",
      "epoch:37 step:175235[D loss: 1.000106] [G loss: 0.999996]\n",
      "epoch:37 step:175240[D loss: 1.000195] [G loss: 0.999610]\n",
      "epoch:37 step:175245[D loss: 0.999743] [G loss: 1.000200]\n",
      "epoch:37 step:175250[D loss: 0.999895] [G loss: 1.000094]\n",
      "epoch:37 step:175255[D loss: 0.999878] [G loss: 1.000174]\n",
      "epoch:37 step:175260[D loss: 0.999898] [G loss: 1.000052]\n",
      "epoch:37 step:175265[D loss: 0.999959] [G loss: 1.000108]\n",
      "epoch:37 step:175270[D loss: 1.000010] [G loss: 1.000158]\n",
      "epoch:37 step:175275[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:37 step:175280[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:37 step:175285[D loss: 0.999911] [G loss: 1.000158]\n",
      "epoch:37 step:175290[D loss: 1.000010] [G loss: 1.000039]\n",
      "epoch:37 step:175295[D loss: 0.999951] [G loss: 1.000043]\n",
      "epoch:37 step:175300[D loss: 1.000082] [G loss: 0.999870]\n",
      "epoch:37 step:175305[D loss: 0.999917] [G loss: 1.000061]\n",
      "epoch:37 step:175310[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:37 step:175315[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:37 step:175320[D loss: 0.999979] [G loss: 1.000028]\n",
      "epoch:37 step:175325[D loss: 1.000019] [G loss: 0.999976]\n",
      "epoch:37 step:175330[D loss: 0.999961] [G loss: 1.000045]\n",
      "epoch:37 step:175335[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:37 step:175340[D loss: 0.999931] [G loss: 1.000069]\n",
      "epoch:37 step:175345[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:37 step:175350[D loss: 0.999960] [G loss: 1.000137]\n",
      "epoch:37 step:175355[D loss: 0.999925] [G loss: 1.000160]\n",
      "epoch:37 step:175360[D loss: 1.000017] [G loss: 1.000047]\n",
      "epoch:37 step:175365[D loss: 0.999930] [G loss: 1.000117]\n",
      "epoch:37 step:175370[D loss: 0.999981] [G loss: 0.999988]\n",
      "epoch:37 step:175375[D loss: 0.999973] [G loss: 1.000020]\n",
      "epoch:37 step:175380[D loss: 1.000012] [G loss: 1.000014]\n",
      "epoch:37 step:175385[D loss: 0.999916] [G loss: 1.000097]\n",
      "epoch:37 step:175390[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:37 step:175395[D loss: 1.000077] [G loss: 1.000000]\n",
      "epoch:37 step:175400[D loss: 0.999950] [G loss: 0.999998]\n",
      "##############\n",
      "[2.61545177 2.24205353 2.23820422 3.46117597 1.66092112 6.4906472\n",
      " 2.52796956 3.77428492 4.07045836 5.49367334]\n",
      "##########\n",
      "epoch:37 step:175405[D loss: 1.000001] [G loss: 1.000033]\n",
      "epoch:37 step:175410[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:37 step:175415[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:37 step:175420[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:37 step:175425[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:37 step:175430[D loss: 0.999965] [G loss: 0.999965]\n",
      "epoch:37 step:175435[D loss: 0.999972] [G loss: 1.000007]\n",
      "epoch:37 step:175440[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:37 step:175445[D loss: 0.999993] [G loss: 0.999987]\n",
      "epoch:37 step:175450[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:37 step:175455[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:37 step:175460[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:37 step:175465[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:37 step:175470[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:37 step:175475[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:37 step:175480[D loss: 0.999981] [G loss: 0.999978]\n",
      "epoch:37 step:175485[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:37 step:175490[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:37 step:175495[D loss: 0.999964] [G loss: 1.000026]\n",
      "epoch:37 step:175500[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:37 step:175505[D loss: 1.000014] [G loss: 1.000040]\n",
      "epoch:37 step:175510[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:37 step:175515[D loss: 1.000024] [G loss: 0.999984]\n",
      "epoch:37 step:175520[D loss: 1.000009] [G loss: 1.000053]\n",
      "epoch:37 step:175525[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:37 step:175530[D loss: 0.999941] [G loss: 1.000076]\n",
      "epoch:37 step:175535[D loss: 1.000028] [G loss: 0.999992]\n",
      "epoch:37 step:175540[D loss: 1.000039] [G loss: 0.999979]\n",
      "epoch:37 step:175545[D loss: 0.999974] [G loss: 0.999972]\n",
      "epoch:37 step:175550[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:37 step:175555[D loss: 0.999992] [G loss: 0.999947]\n",
      "epoch:37 step:175560[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:37 step:175565[D loss: 0.999966] [G loss: 1.000032]\n",
      "epoch:37 step:175570[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:37 step:175575[D loss: 1.000030] [G loss: 1.000025]\n",
      "epoch:37 step:175580[D loss: 1.000078] [G loss: 0.999915]\n",
      "epoch:37 step:175585[D loss: 0.999926] [G loss: 1.000215]\n",
      "epoch:37 step:175590[D loss: 1.000004] [G loss: 1.000007]\n",
      "epoch:37 step:175595[D loss: 0.999962] [G loss: 1.000126]\n",
      "epoch:37 step:175600[D loss: 0.999974] [G loss: 1.000056]\n",
      "##############\n",
      "[2.66000032 2.261577   2.2119308  3.58717165 1.58904414 6.70121753\n",
      " 2.25321806 3.8191291  4.08472816 4.89550473]\n",
      "##########\n",
      "epoch:37 step:175605[D loss: 0.999981] [G loss: 1.000003]\n",
      "epoch:37 step:175610[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:37 step:175615[D loss: 0.999980] [G loss: 1.000116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:175620[D loss: 0.999984] [G loss: 0.999991]\n",
      "epoch:37 step:175625[D loss: 0.999893] [G loss: 1.000141]\n",
      "epoch:37 step:175630[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:37 step:175635[D loss: 1.000055] [G loss: 1.000043]\n",
      "epoch:37 step:175640[D loss: 1.000330] [G loss: 0.999884]\n",
      "epoch:37 step:175645[D loss: 0.999914] [G loss: 1.000147]\n",
      "epoch:37 step:175650[D loss: 0.999989] [G loss: 0.999990]\n",
      "epoch:37 step:175655[D loss: 0.999959] [G loss: 0.999997]\n",
      "epoch:37 step:175660[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:37 step:175665[D loss: 1.000043] [G loss: 0.999948]\n",
      "epoch:37 step:175670[D loss: 0.999888] [G loss: 1.000190]\n",
      "epoch:37 step:175675[D loss: 0.999951] [G loss: 1.000129]\n",
      "epoch:37 step:175680[D loss: 0.999869] [G loss: 1.000161]\n",
      "epoch:37 step:175685[D loss: 1.000024] [G loss: 1.000136]\n",
      "epoch:37 step:175690[D loss: 1.000153] [G loss: 1.000016]\n",
      "epoch:37 step:175695[D loss: 0.999875] [G loss: 1.000165]\n",
      "epoch:37 step:175700[D loss: 0.999960] [G loss: 1.000200]\n",
      "epoch:37 step:175705[D loss: 0.999907] [G loss: 1.000151]\n",
      "epoch:37 step:175710[D loss: 0.999961] [G loss: 1.000039]\n",
      "epoch:37 step:175715[D loss: 1.000111] [G loss: 0.999812]\n",
      "epoch:37 step:175720[D loss: 0.999960] [G loss: 0.999993]\n",
      "epoch:37 step:175725[D loss: 0.999993] [G loss: 0.999907]\n",
      "epoch:37 step:175730[D loss: 1.000005] [G loss: 0.999953]\n",
      "epoch:37 step:175735[D loss: 0.999909] [G loss: 1.000134]\n",
      "epoch:37 step:175740[D loss: 0.999917] [G loss: 1.000056]\n",
      "epoch:37 step:175745[D loss: 0.999937] [G loss: 1.000134]\n",
      "epoch:37 step:175750[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:37 step:175755[D loss: 0.999942] [G loss: 1.000085]\n",
      "epoch:37 step:175760[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:37 step:175765[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:37 step:175770[D loss: 1.000026] [G loss: 1.000061]\n",
      "epoch:37 step:175775[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:37 step:175780[D loss: 0.999899] [G loss: 1.000120]\n",
      "epoch:37 step:175785[D loss: 1.000004] [G loss: 1.000074]\n",
      "epoch:37 step:175790[D loss: 0.999866] [G loss: 1.000314]\n",
      "epoch:37 step:175795[D loss: 0.999970] [G loss: 1.000272]\n",
      "epoch:37 step:175800[D loss: 0.999935] [G loss: 1.000191]\n",
      "##############\n",
      "[2.60577833 2.36701907 2.1911709  3.4229879  1.57342408 6.6371187\n",
      " 2.13517517 3.7571344  3.99807387 4.99548702]\n",
      "##########\n",
      "epoch:37 step:175805[D loss: 1.000045] [G loss: 1.000093]\n",
      "epoch:37 step:175810[D loss: 1.000069] [G loss: 1.000140]\n",
      "epoch:37 step:175815[D loss: 0.999960] [G loss: 1.000238]\n",
      "epoch:37 step:175820[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:37 step:175825[D loss: 1.000106] [G loss: 1.000414]\n",
      "epoch:37 step:175830[D loss: 0.999956] [G loss: 1.000233]\n",
      "epoch:37 step:175835[D loss: 0.999932] [G loss: 1.000109]\n",
      "epoch:37 step:175840[D loss: 1.000175] [G loss: 0.999850]\n",
      "epoch:37 step:175845[D loss: 1.000197] [G loss: 0.999641]\n",
      "epoch:37 step:175850[D loss: 0.999848] [G loss: 0.999984]\n",
      "epoch:37 step:175855[D loss: 1.000059] [G loss: 0.999929]\n",
      "epoch:37 step:175860[D loss: 0.999999] [G loss: 0.999901]\n",
      "epoch:37 step:175865[D loss: 1.000039] [G loss: 0.999871]\n",
      "epoch:37 step:175870[D loss: 0.999874] [G loss: 1.000172]\n",
      "epoch:37 step:175875[D loss: 0.999947] [G loss: 1.000039]\n",
      "epoch:37 step:175880[D loss: 1.000035] [G loss: 1.000060]\n",
      "epoch:37 step:175885[D loss: 1.000168] [G loss: 0.999822]\n",
      "epoch:37 step:175890[D loss: 1.000052] [G loss: 1.000130]\n",
      "epoch:37 step:175895[D loss: 1.000098] [G loss: 1.000369]\n",
      "epoch:37 step:175900[D loss: 0.999887] [G loss: 1.000255]\n",
      "epoch:37 step:175905[D loss: 0.999834] [G loss: 1.000162]\n",
      "epoch:37 step:175910[D loss: 0.999936] [G loss: 1.000145]\n",
      "epoch:37 step:175915[D loss: 1.000018] [G loss: 0.999969]\n",
      "epoch:37 step:175920[D loss: 0.999912] [G loss: 1.000082]\n",
      "epoch:37 step:175925[D loss: 1.000033] [G loss: 1.000040]\n",
      "epoch:37 step:175930[D loss: 1.000113] [G loss: 1.000052]\n",
      "epoch:37 step:175935[D loss: 0.999861] [G loss: 1.000221]\n",
      "epoch:37 step:175940[D loss: 0.999827] [G loss: 1.000262]\n",
      "epoch:37 step:175945[D loss: 1.000071] [G loss: 1.000028]\n",
      "epoch:37 step:175950[D loss: 1.000166] [G loss: 0.999859]\n",
      "epoch:37 step:175955[D loss: 0.999884] [G loss: 1.000164]\n",
      "epoch:37 step:175960[D loss: 0.999930] [G loss: 1.000150]\n",
      "epoch:37 step:175965[D loss: 1.000008] [G loss: 1.000090]\n",
      "epoch:37 step:175970[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:37 step:175975[D loss: 1.000080] [G loss: 0.999856]\n",
      "epoch:37 step:175980[D loss: 0.999865] [G loss: 1.000050]\n",
      "epoch:37 step:175985[D loss: 1.000016] [G loss: 0.999974]\n",
      "epoch:37 step:175990[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:37 step:175995[D loss: 0.999970] [G loss: 1.000190]\n",
      "epoch:37 step:176000[D loss: 0.999874] [G loss: 1.000216]\n",
      "##############\n",
      "[2.61564994 2.3162177  2.23184074 3.51992979 1.61653523 6.90157246\n",
      " 2.26012245 3.72578838 4.08042705 4.80510928]\n",
      "##########\n",
      "epoch:37 step:176005[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:37 step:176010[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:37 step:176015[D loss: 1.000000] [G loss: 1.000032]\n",
      "epoch:37 step:176020[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:37 step:176025[D loss: 1.000037] [G loss: 1.000064]\n",
      "epoch:37 step:176030[D loss: 1.000087] [G loss: 0.999964]\n",
      "epoch:37 step:176035[D loss: 0.999983] [G loss: 1.000181]\n",
      "epoch:37 step:176040[D loss: 0.999950] [G loss: 1.000149]\n",
      "epoch:37 step:176045[D loss: 0.999925] [G loss: 1.000118]\n",
      "epoch:37 step:176050[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:37 step:176055[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:37 step:176060[D loss: 1.000140] [G loss: 1.000024]\n",
      "epoch:37 step:176065[D loss: 0.999994] [G loss: 0.999914]\n",
      "epoch:37 step:176070[D loss: 1.000153] [G loss: 0.999750]\n",
      "epoch:37 step:176075[D loss: 1.000214] [G loss: 0.999714]\n",
      "epoch:37 step:176080[D loss: 0.999828] [G loss: 1.000170]\n",
      "epoch:37 step:176085[D loss: 1.000090] [G loss: 0.999789]\n",
      "epoch:37 step:176090[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:37 step:176095[D loss: 0.999865] [G loss: 1.000371]\n",
      "epoch:37 step:176100[D loss: 0.999920] [G loss: 1.000128]\n",
      "epoch:37 step:176105[D loss: 1.000007] [G loss: 1.000048]\n",
      "epoch:37 step:176110[D loss: 1.000171] [G loss: 0.999804]\n",
      "epoch:37 step:176115[D loss: 0.999851] [G loss: 1.000081]\n",
      "epoch:37 step:176120[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:37 step:176125[D loss: 0.999941] [G loss: 1.000067]\n",
      "epoch:37 step:176130[D loss: 1.000096] [G loss: 1.000020]\n",
      "epoch:37 step:176135[D loss: 1.000047] [G loss: 1.000088]\n",
      "epoch:37 step:176140[D loss: 1.000048] [G loss: 1.000156]\n",
      "epoch:37 step:176145[D loss: 0.999904] [G loss: 1.000030]\n",
      "epoch:37 step:176150[D loss: 1.000005] [G loss: 1.000078]\n",
      "epoch:37 step:176155[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:37 step:176160[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:37 step:176165[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:37 step:176170[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:37 step:176175[D loss: 1.000010] [G loss: 0.999997]\n",
      "epoch:37 step:176180[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:37 step:176185[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:37 step:176190[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:37 step:176195[D loss: 0.999978] [G loss: 0.999949]\n",
      "epoch:37 step:176200[D loss: 0.999997] [G loss: 0.999986]\n",
      "##############\n",
      "[2.58544224 2.22340665 2.23107509 3.41174286 1.55324817 6.98667293\n",
      " 2.19184485 3.89378363 4.07359756 4.74131391]\n",
      "##########\n",
      "epoch:37 step:176205[D loss: 1.000035] [G loss: 0.999985]\n",
      "epoch:37 step:176210[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:37 step:176215[D loss: 1.000031] [G loss: 1.000064]\n",
      "epoch:37 step:176220[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:37 step:176225[D loss: 1.000006] [G loss: 0.999971]\n",
      "epoch:37 step:176230[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:37 step:176235[D loss: 1.000033] [G loss: 1.000037]\n",
      "epoch:37 step:176240[D loss: 0.999944] [G loss: 1.000054]\n",
      "epoch:37 step:176245[D loss: 1.000120] [G loss: 1.000048]\n",
      "epoch:37 step:176250[D loss: 0.999926] [G loss: 1.000059]\n",
      "epoch:37 step:176255[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:37 step:176260[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:37 step:176265[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:37 step:176270[D loss: 0.999995] [G loss: 1.000022]\n",
      "epoch:37 step:176275[D loss: 0.999999] [G loss: 1.000000]\n",
      "epoch:37 step:176280[D loss: 1.000031] [G loss: 0.999987]\n",
      "epoch:37 step:176285[D loss: 1.000110] [G loss: 0.999954]\n",
      "epoch:37 step:176290[D loss: 0.999933] [G loss: 1.000317]\n",
      "epoch:37 step:176295[D loss: 0.999804] [G loss: 1.000262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:176300[D loss: 0.999907] [G loss: 1.000098]\n",
      "epoch:37 step:176305[D loss: 1.000006] [G loss: 0.999985]\n",
      "epoch:37 step:176310[D loss: 1.000187] [G loss: 0.999793]\n",
      "epoch:37 step:176315[D loss: 0.999953] [G loss: 1.000036]\n",
      "epoch:37 step:176320[D loss: 1.000128] [G loss: 1.000079]\n",
      "epoch:37 step:176325[D loss: 0.999949] [G loss: 1.000108]\n",
      "epoch:37 step:176330[D loss: 1.000003] [G loss: 1.000037]\n",
      "epoch:37 step:176335[D loss: 0.999898] [G loss: 1.000226]\n",
      "epoch:37 step:176340[D loss: 0.999969] [G loss: 1.000028]\n",
      "epoch:37 step:176345[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:37 step:176350[D loss: 0.999999] [G loss: 1.000012]\n",
      "epoch:37 step:176355[D loss: 0.999988] [G loss: 1.000003]\n",
      "epoch:37 step:176360[D loss: 0.999984] [G loss: 0.999974]\n",
      "epoch:37 step:176365[D loss: 0.999995] [G loss: 0.999990]\n",
      "epoch:37 step:176370[D loss: 0.999990] [G loss: 0.999964]\n",
      "epoch:37 step:176375[D loss: 0.999959] [G loss: 1.000010]\n",
      "epoch:37 step:176380[D loss: 0.999939] [G loss: 1.000044]\n",
      "epoch:37 step:176385[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:37 step:176390[D loss: 1.000057] [G loss: 1.000024]\n",
      "epoch:37 step:176395[D loss: 0.999947] [G loss: 1.000025]\n",
      "epoch:37 step:176400[D loss: 1.000044] [G loss: 1.000002]\n",
      "##############\n",
      "[2.58682836 2.31810969 2.20880593 3.25072391 1.58255269 7.24719132\n",
      " 2.29165472 3.71624707 4.04703212 6.23986687]\n",
      "##########\n",
      "epoch:37 step:176405[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:37 step:176410[D loss: 1.000018] [G loss: 0.999906]\n",
      "epoch:37 step:176415[D loss: 1.000031] [G loss: 0.999928]\n",
      "epoch:37 step:176420[D loss: 1.000008] [G loss: 0.999929]\n",
      "epoch:37 step:176425[D loss: 0.999967] [G loss: 1.000024]\n",
      "epoch:37 step:176430[D loss: 1.000107] [G loss: 0.999978]\n",
      "epoch:37 step:176435[D loss: 1.000041] [G loss: 0.999979]\n",
      "epoch:37 step:176440[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:37 step:176445[D loss: 1.000028] [G loss: 1.000061]\n",
      "epoch:37 step:176450[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:37 step:176455[D loss: 1.000020] [G loss: 1.000057]\n",
      "epoch:37 step:176460[D loss: 0.999931] [G loss: 1.000077]\n",
      "epoch:37 step:176465[D loss: 1.000096] [G loss: 0.999852]\n",
      "epoch:37 step:176470[D loss: 1.000034] [G loss: 1.000066]\n",
      "epoch:37 step:176475[D loss: 0.999977] [G loss: 1.000021]\n",
      "epoch:37 step:176480[D loss: 1.000018] [G loss: 0.999983]\n",
      "epoch:37 step:176485[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:37 step:176490[D loss: 1.000027] [G loss: 0.999906]\n",
      "epoch:37 step:176495[D loss: 1.000023] [G loss: 1.000003]\n",
      "epoch:37 step:176500[D loss: 0.999930] [G loss: 1.000113]\n",
      "epoch:37 step:176505[D loss: 1.000017] [G loss: 1.000101]\n",
      "epoch:37 step:176510[D loss: 0.999947] [G loss: 1.000142]\n",
      "epoch:37 step:176515[D loss: 0.999923] [G loss: 1.000111]\n",
      "epoch:37 step:176520[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:37 step:176525[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:37 step:176530[D loss: 1.000079] [G loss: 0.999960]\n",
      "epoch:37 step:176535[D loss: 0.999844] [G loss: 0.999992]\n",
      "epoch:37 step:176540[D loss: 0.999941] [G loss: 1.000025]\n",
      "epoch:37 step:176545[D loss: 1.000073] [G loss: 1.000168]\n",
      "epoch:37 step:176550[D loss: 1.000055] [G loss: 0.999987]\n",
      "epoch:37 step:176555[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:37 step:176560[D loss: 0.999951] [G loss: 1.000050]\n",
      "epoch:37 step:176565[D loss: 1.000007] [G loss: 1.000060]\n",
      "epoch:37 step:176570[D loss: 0.999999] [G loss: 0.999960]\n",
      "epoch:37 step:176575[D loss: 1.000102] [G loss: 0.999773]\n",
      "epoch:37 step:176580[D loss: 0.999947] [G loss: 1.000017]\n",
      "epoch:37 step:176585[D loss: 0.999921] [G loss: 1.000105]\n",
      "epoch:37 step:176590[D loss: 1.000053] [G loss: 1.000021]\n",
      "epoch:37 step:176595[D loss: 0.999998] [G loss: 1.000044]\n",
      "epoch:37 step:176600[D loss: 1.000026] [G loss: 1.000182]\n",
      "##############\n",
      "[2.59689096 2.35387386 2.22309698 3.46271011 1.61730109 7.00360361\n",
      " 2.30571459 3.77019178 3.94212953 5.79258189]\n",
      "##########\n",
      "epoch:37 step:176605[D loss: 0.999875] [G loss: 1.000138]\n",
      "epoch:37 step:176610[D loss: 0.999944] [G loss: 1.000116]\n",
      "epoch:37 step:176615[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:37 step:176620[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:37 step:176625[D loss: 0.999992] [G loss: 0.999995]\n",
      "epoch:37 step:176630[D loss: 1.000017] [G loss: 1.000005]\n",
      "epoch:37 step:176635[D loss: 0.999952] [G loss: 1.000085]\n",
      "epoch:37 step:176640[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:37 step:176645[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:37 step:176650[D loss: 1.000034] [G loss: 0.999963]\n",
      "epoch:37 step:176655[D loss: 1.000060] [G loss: 1.000040]\n",
      "epoch:37 step:176660[D loss: 0.999845] [G loss: 1.000305]\n",
      "epoch:37 step:176665[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:37 step:176670[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:37 step:176675[D loss: 0.999993] [G loss: 0.999984]\n",
      "epoch:37 step:176680[D loss: 0.999910] [G loss: 1.000048]\n",
      "epoch:37 step:176685[D loss: 1.000018] [G loss: 0.999921]\n",
      "epoch:37 step:176690[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:37 step:176695[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:37 step:176700[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:37 step:176705[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:37 step:176710[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:37 step:176715[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:37 step:176720[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:37 step:176725[D loss: 0.999915] [G loss: 1.000068]\n",
      "epoch:37 step:176730[D loss: 0.999979] [G loss: 1.000094]\n",
      "epoch:37 step:176735[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:37 step:176740[D loss: 0.999929] [G loss: 1.000132]\n",
      "epoch:37 step:176745[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:37 step:176750[D loss: 0.999967] [G loss: 1.000013]\n",
      "epoch:37 step:176755[D loss: 1.000040] [G loss: 0.999993]\n",
      "epoch:37 step:176760[D loss: 0.999946] [G loss: 1.000075]\n",
      "epoch:37 step:176765[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:37 step:176770[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:37 step:176775[D loss: 1.000002] [G loss: 0.999973]\n",
      "epoch:37 step:176780[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:37 step:176785[D loss: 0.999991] [G loss: 1.000084]\n",
      "epoch:37 step:176790[D loss: 1.000111] [G loss: 0.999968]\n",
      "epoch:37 step:176795[D loss: 0.999977] [G loss: 1.000016]\n",
      "epoch:37 step:176800[D loss: 0.999976] [G loss: 1.000045]\n",
      "##############\n",
      "[2.58614764 2.27857482 2.27984931 3.5393698  1.54653485 6.98484251\n",
      " 2.35696671 3.866129   4.04516054 5.71632546]\n",
      "##########\n",
      "epoch:37 step:176805[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:37 step:176810[D loss: 1.000068] [G loss: 1.000091]\n",
      "epoch:37 step:176815[D loss: 1.000002] [G loss: 1.000056]\n",
      "epoch:37 step:176820[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:37 step:176825[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:37 step:176830[D loss: 1.000033] [G loss: 0.999960]\n",
      "epoch:37 step:176835[D loss: 0.999931] [G loss: 1.000057]\n",
      "epoch:37 step:176840[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:37 step:176845[D loss: 0.999939] [G loss: 1.000103]\n",
      "epoch:37 step:176850[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:37 step:176855[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:37 step:176860[D loss: 0.999948] [G loss: 1.000115]\n",
      "epoch:37 step:176865[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:37 step:176870[D loss: 0.999958] [G loss: 1.000116]\n",
      "epoch:37 step:176875[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:37 step:176880[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:37 step:176885[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:37 step:176890[D loss: 1.000133] [G loss: 0.999939]\n",
      "epoch:37 step:176895[D loss: 1.000181] [G loss: 0.999942]\n",
      "epoch:37 step:176900[D loss: 1.000094] [G loss: 0.999815]\n",
      "epoch:37 step:176905[D loss: 0.999843] [G loss: 1.000228]\n",
      "epoch:37 step:176910[D loss: 1.000001] [G loss: 0.999978]\n",
      "epoch:37 step:176915[D loss: 1.000206] [G loss: 1.000091]\n",
      "epoch:37 step:176920[D loss: 1.000181] [G loss: 0.999772]\n",
      "epoch:37 step:176925[D loss: 0.999853] [G loss: 1.000161]\n",
      "epoch:37 step:176930[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:37 step:176935[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:37 step:176940[D loss: 1.000155] [G loss: 0.999856]\n",
      "epoch:37 step:176945[D loss: 0.999903] [G loss: 1.000078]\n",
      "epoch:37 step:176950[D loss: 0.999932] [G loss: 1.000020]\n",
      "epoch:37 step:176955[D loss: 1.000003] [G loss: 1.000069]\n",
      "epoch:37 step:176960[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:37 step:176965[D loss: 0.999969] [G loss: 1.000005]\n",
      "epoch:37 step:176970[D loss: 0.999935] [G loss: 1.000015]\n",
      "epoch:37 step:176975[D loss: 0.999954] [G loss: 1.000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:176980[D loss: 1.000026] [G loss: 1.000050]\n",
      "epoch:37 step:176985[D loss: 0.999943] [G loss: 1.000047]\n",
      "epoch:37 step:176990[D loss: 0.999980] [G loss: 1.000014]\n",
      "epoch:37 step:176995[D loss: 1.000054] [G loss: 1.000046]\n",
      "epoch:37 step:177000[D loss: 0.999943] [G loss: 1.000049]\n",
      "##############\n",
      "[2.62174796 2.24610325 2.12963861 3.54133358 1.58852463 7.29157782\n",
      " 2.26423504 3.79902287 3.99152862 4.94362322]\n",
      "##########\n",
      "epoch:37 step:177005[D loss: 1.000025] [G loss: 0.999947]\n",
      "epoch:37 step:177010[D loss: 1.000006] [G loss: 0.999917]\n",
      "epoch:37 step:177015[D loss: 1.000033] [G loss: 0.999903]\n",
      "epoch:37 step:177020[D loss: 1.000024] [G loss: 0.999911]\n",
      "epoch:37 step:177025[D loss: 0.999975] [G loss: 1.000129]\n",
      "epoch:37 step:177030[D loss: 0.999862] [G loss: 1.000101]\n",
      "epoch:37 step:177035[D loss: 0.999970] [G loss: 0.999974]\n",
      "epoch:37 step:177040[D loss: 0.999948] [G loss: 1.000094]\n",
      "epoch:37 step:177045[D loss: 1.000013] [G loss: 0.999939]\n",
      "epoch:37 step:177050[D loss: 1.000015] [G loss: 0.999935]\n",
      "epoch:37 step:177055[D loss: 1.000068] [G loss: 1.000008]\n",
      "epoch:37 step:177060[D loss: 0.999955] [G loss: 1.000009]\n",
      "epoch:37 step:177065[D loss: 0.999994] [G loss: 0.999993]\n",
      "epoch:37 step:177070[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:37 step:177075[D loss: 0.999932] [G loss: 1.000015]\n",
      "epoch:37 step:177080[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:37 step:177085[D loss: 1.000068] [G loss: 0.999949]\n",
      "epoch:37 step:177090[D loss: 0.999942] [G loss: 1.000077]\n",
      "epoch:37 step:177095[D loss: 1.000052] [G loss: 0.999946]\n",
      "epoch:37 step:177100[D loss: 0.999961] [G loss: 0.999959]\n",
      "epoch:37 step:177105[D loss: 1.000023] [G loss: 0.999938]\n",
      "epoch:37 step:177110[D loss: 0.999916] [G loss: 1.000155]\n",
      "epoch:37 step:177115[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:37 step:177120[D loss: 0.999970] [G loss: 1.000124]\n",
      "epoch:37 step:177125[D loss: 1.000030] [G loss: 0.999862]\n",
      "epoch:37 step:177130[D loss: 0.999973] [G loss: 1.000012]\n",
      "epoch:37 step:177135[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:37 step:177140[D loss: 1.000013] [G loss: 0.999956]\n",
      "epoch:37 step:177145[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:37 step:177150[D loss: 1.000130] [G loss: 0.999907]\n",
      "epoch:37 step:177155[D loss: 1.000093] [G loss: 1.000170]\n",
      "epoch:37 step:177160[D loss: 0.999854] [G loss: 1.000287]\n",
      "epoch:37 step:177165[D loss: 0.999982] [G loss: 1.000132]\n",
      "epoch:37 step:177170[D loss: 1.000050] [G loss: 0.999962]\n",
      "epoch:37 step:177175[D loss: 0.999977] [G loss: 1.000172]\n",
      "epoch:37 step:177180[D loss: 0.999932] [G loss: 1.000190]\n",
      "epoch:37 step:177185[D loss: 0.999937] [G loss: 0.999998]\n",
      "epoch:37 step:177190[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:37 step:177195[D loss: 1.000019] [G loss: 0.999920]\n",
      "epoch:37 step:177200[D loss: 0.999965] [G loss: 1.000078]\n",
      "##############\n",
      "[2.55902734 2.17152265 2.15793528 3.42039186 1.56163934 7.42938578\n",
      " 2.0741788  3.79029498 3.98689632 4.51684969]\n",
      "##########\n",
      "epoch:37 step:177205[D loss: 1.000117] [G loss: 0.999745]\n",
      "epoch:37 step:177210[D loss: 1.000084] [G loss: 0.999854]\n",
      "epoch:37 step:177215[D loss: 1.000577] [G loss: 0.999244]\n",
      "epoch:37 step:177220[D loss: 0.999870] [G loss: 0.999962]\n",
      "epoch:37 step:177225[D loss: 1.000166] [G loss: 0.999817]\n",
      "epoch:37 step:177230[D loss: 0.999939] [G loss: 1.000007]\n",
      "epoch:37 step:177235[D loss: 0.999948] [G loss: 1.000019]\n",
      "epoch:37 step:177240[D loss: 1.000103] [G loss: 0.999985]\n",
      "epoch:37 step:177245[D loss: 1.000008] [G loss: 0.999977]\n",
      "epoch:37 step:177250[D loss: 0.999935] [G loss: 1.000018]\n",
      "epoch:37 step:177255[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:37 step:177260[D loss: 1.000020] [G loss: 0.999971]\n",
      "epoch:37 step:177265[D loss: 1.000003] [G loss: 1.000055]\n",
      "epoch:37 step:177270[D loss: 1.000056] [G loss: 0.999995]\n",
      "epoch:37 step:177275[D loss: 0.999950] [G loss: 1.000172]\n",
      "epoch:37 step:177280[D loss: 1.000046] [G loss: 0.999952]\n",
      "epoch:37 step:177285[D loss: 1.000107] [G loss: 0.999980]\n",
      "epoch:37 step:177290[D loss: 1.000073] [G loss: 1.000126]\n",
      "epoch:37 step:177295[D loss: 0.999905] [G loss: 1.000121]\n",
      "epoch:37 step:177300[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:37 step:177305[D loss: 0.999984] [G loss: 0.999912]\n",
      "epoch:37 step:177310[D loss: 0.999950] [G loss: 1.000068]\n",
      "epoch:37 step:177315[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:37 step:177320[D loss: 0.999955] [G loss: 1.000123]\n",
      "epoch:37 step:177325[D loss: 0.999928] [G loss: 1.000127]\n",
      "epoch:37 step:177330[D loss: 0.999997] [G loss: 1.000098]\n",
      "epoch:37 step:177335[D loss: 0.999966] [G loss: 1.000258]\n",
      "epoch:37 step:177340[D loss: 0.999798] [G loss: 1.000287]\n",
      "epoch:37 step:177345[D loss: 0.999888] [G loss: 1.000122]\n",
      "epoch:37 step:177350[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:37 step:177355[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:37 step:177360[D loss: 0.999932] [G loss: 1.000170]\n",
      "epoch:37 step:177365[D loss: 0.999933] [G loss: 1.000098]\n",
      "epoch:37 step:177370[D loss: 0.999942] [G loss: 1.000179]\n",
      "epoch:37 step:177375[D loss: 0.999960] [G loss: 1.000037]\n",
      "epoch:37 step:177380[D loss: 1.000035] [G loss: 1.000081]\n",
      "epoch:37 step:177385[D loss: 1.000002] [G loss: 1.000246]\n",
      "epoch:37 step:177390[D loss: 0.999898] [G loss: 1.000157]\n",
      "epoch:37 step:177395[D loss: 0.999954] [G loss: 1.000062]\n",
      "epoch:37 step:177400[D loss: 0.999919] [G loss: 1.000129]\n",
      "##############\n",
      "[2.59497731 2.32459703 2.14752198 3.50559272 1.60111443 7.31923529\n",
      " 2.19678544 3.71625286 4.01327953 5.04132936]\n",
      "##########\n",
      "epoch:37 step:177405[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:37 step:177410[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:37 step:177415[D loss: 0.999938] [G loss: 1.000075]\n",
      "epoch:37 step:177420[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:37 step:177425[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:37 step:177430[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:37 step:177435[D loss: 0.999979] [G loss: 1.000122]\n",
      "epoch:37 step:177440[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:37 step:177445[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:37 step:177450[D loss: 0.999956] [G loss: 1.000119]\n",
      "epoch:37 step:177455[D loss: 1.000005] [G loss: 1.000067]\n",
      "epoch:37 step:177460[D loss: 0.999958] [G loss: 1.000009]\n",
      "epoch:37 step:177465[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:37 step:177470[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:37 step:177475[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:37 step:177480[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:37 step:177485[D loss: 0.999946] [G loss: 1.000082]\n",
      "epoch:37 step:177490[D loss: 1.000002] [G loss: 1.000100]\n",
      "epoch:37 step:177495[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:37 step:177500[D loss: 1.000020] [G loss: 0.999978]\n",
      "epoch:37 step:177505[D loss: 1.000088] [G loss: 1.000071]\n",
      "epoch:37 step:177510[D loss: 0.999869] [G loss: 1.000016]\n",
      "epoch:37 step:177515[D loss: 1.000160] [G loss: 0.999916]\n",
      "epoch:37 step:177520[D loss: 0.999915] [G loss: 1.000146]\n",
      "epoch:37 step:177525[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:37 step:177530[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:37 step:177535[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:37 step:177540[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:37 step:177545[D loss: 0.999978] [G loss: 1.000017]\n",
      "epoch:37 step:177550[D loss: 1.000047] [G loss: 0.999929]\n",
      "epoch:37 step:177555[D loss: 0.999963] [G loss: 1.000038]\n",
      "epoch:37 step:177560[D loss: 0.999963] [G loss: 1.000249]\n",
      "epoch:37 step:177565[D loss: 1.000101] [G loss: 1.000216]\n",
      "epoch:37 step:177570[D loss: 0.999905] [G loss: 1.000162]\n",
      "epoch:37 step:177575[D loss: 0.999813] [G loss: 1.000288]\n",
      "epoch:37 step:177580[D loss: 0.999865] [G loss: 1.000324]\n",
      "epoch:37 step:177585[D loss: 0.999961] [G loss: 1.000126]\n",
      "epoch:37 step:177590[D loss: 0.999919] [G loss: 1.000219]\n",
      "epoch:37 step:177595[D loss: 0.999938] [G loss: 1.000089]\n",
      "epoch:37 step:177600[D loss: 0.999952] [G loss: 1.000096]\n",
      "##############\n",
      "[2.64797812 2.32283693 2.25343897 3.51380278 1.56206143 6.78046753\n",
      " 2.38170144 3.71818326 4.06999998 5.49712493]\n",
      "##########\n",
      "epoch:37 step:177605[D loss: 1.000047] [G loss: 0.999906]\n",
      "epoch:37 step:177610[D loss: 1.000111] [G loss: 0.999800]\n",
      "epoch:37 step:177615[D loss: 0.999983] [G loss: 0.999901]\n",
      "epoch:37 step:177620[D loss: 1.000130] [G loss: 0.999754]\n",
      "epoch:37 step:177625[D loss: 1.000113] [G loss: 0.999986]\n",
      "epoch:37 step:177630[D loss: 0.999913] [G loss: 1.000054]\n",
      "epoch:37 step:177635[D loss: 0.999868] [G loss: 1.000123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:177640[D loss: 1.000019] [G loss: 1.000116]\n",
      "epoch:37 step:177645[D loss: 0.999944] [G loss: 1.000066]\n",
      "epoch:37 step:177650[D loss: 0.999921] [G loss: 1.000141]\n",
      "epoch:37 step:177655[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:37 step:177660[D loss: 1.000023] [G loss: 1.000006]\n",
      "epoch:37 step:177665[D loss: 1.000065] [G loss: 0.999951]\n",
      "epoch:37 step:177670[D loss: 1.000017] [G loss: 0.999945]\n",
      "epoch:37 step:177675[D loss: 0.999926] [G loss: 1.000084]\n",
      "epoch:37 step:177680[D loss: 0.999989] [G loss: 1.000221]\n",
      "epoch:37 step:177685[D loss: 0.999973] [G loss: 1.000123]\n",
      "epoch:37 step:177690[D loss: 1.000109] [G loss: 0.999942]\n",
      "epoch:37 step:177695[D loss: 1.000016] [G loss: 1.000146]\n",
      "epoch:37 step:177700[D loss: 0.999937] [G loss: 1.000057]\n",
      "epoch:37 step:177705[D loss: 0.999938] [G loss: 1.000085]\n",
      "epoch:37 step:177710[D loss: 0.999996] [G loss: 0.999986]\n",
      "epoch:37 step:177715[D loss: 1.000042] [G loss: 0.999931]\n",
      "epoch:37 step:177720[D loss: 1.000003] [G loss: 0.999960]\n",
      "epoch:37 step:177725[D loss: 1.000084] [G loss: 0.999870]\n",
      "epoch:37 step:177730[D loss: 0.999884] [G loss: 1.000043]\n",
      "epoch:37 step:177735[D loss: 0.999938] [G loss: 1.000033]\n",
      "epoch:37 step:177740[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:37 step:177745[D loss: 1.000067] [G loss: 0.999957]\n",
      "epoch:37 step:177750[D loss: 0.999889] [G loss: 1.000143]\n",
      "epoch:37 step:177755[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:37 step:177760[D loss: 1.000015] [G loss: 1.000082]\n",
      "epoch:37 step:177765[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:37 step:177770[D loss: 0.999971] [G loss: 1.000139]\n",
      "epoch:37 step:177775[D loss: 0.999968] [G loss: 1.000156]\n",
      "epoch:37 step:177780[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:37 step:177785[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:37 step:177790[D loss: 0.999958] [G loss: 1.000228]\n",
      "epoch:37 step:177795[D loss: 1.000005] [G loss: 0.999999]\n",
      "epoch:37 step:177800[D loss: 1.000015] [G loss: 0.999980]\n",
      "##############\n",
      "[2.5609613  2.34188906 2.23640557 3.79072313 1.61261158 7.49233139\n",
      " 2.21309356 3.68230685 3.97926761 4.78596212]\n",
      "##########\n",
      "epoch:37 step:177805[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:37 step:177810[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:37 step:177815[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:37 step:177820[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:37 step:177825[D loss: 1.000125] [G loss: 0.999904]\n",
      "epoch:37 step:177830[D loss: 0.999967] [G loss: 1.000024]\n",
      "epoch:37 step:177835[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:37 step:177840[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:37 step:177845[D loss: 0.999942] [G loss: 1.000119]\n",
      "epoch:37 step:177850[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:37 step:177855[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:37 step:177860[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:37 step:177865[D loss: 0.999989] [G loss: 1.000120]\n",
      "epoch:37 step:177870[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:37 step:177875[D loss: 0.999996] [G loss: 1.000160]\n",
      "epoch:37 step:177880[D loss: 0.999946] [G loss: 1.000039]\n",
      "epoch:37 step:177885[D loss: 1.000065] [G loss: 0.999986]\n",
      "epoch:37 step:177890[D loss: 0.999826] [G loss: 1.000162]\n",
      "epoch:37 step:177895[D loss: 0.999906] [G loss: 1.000092]\n",
      "epoch:37 step:177900[D loss: 0.999985] [G loss: 0.999945]\n",
      "epoch:37 step:177905[D loss: 0.999930] [G loss: 1.000091]\n",
      "epoch:37 step:177910[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:37 step:177915[D loss: 1.000143] [G loss: 0.999892]\n",
      "epoch:37 step:177920[D loss: 0.999947] [G loss: 1.000229]\n",
      "epoch:37 step:177925[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:37 step:177930[D loss: 1.000021] [G loss: 1.000106]\n",
      "epoch:37 step:177935[D loss: 0.999926] [G loss: 1.000090]\n",
      "epoch:37 step:177940[D loss: 1.000036] [G loss: 0.999972]\n",
      "epoch:37 step:177945[D loss: 1.000031] [G loss: 1.000004]\n",
      "epoch:37 step:177950[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:37 step:177955[D loss: 0.999909] [G loss: 1.000067]\n",
      "epoch:37 step:177960[D loss: 0.999848] [G loss: 1.000148]\n",
      "epoch:37 step:177965[D loss: 0.999917] [G loss: 1.000081]\n",
      "epoch:37 step:177970[D loss: 1.000014] [G loss: 1.000008]\n",
      "epoch:37 step:177975[D loss: 0.999965] [G loss: 1.000142]\n",
      "epoch:37 step:177980[D loss: 0.999953] [G loss: 1.000098]\n",
      "epoch:37 step:177985[D loss: 1.000046] [G loss: 0.999938]\n",
      "epoch:37 step:177990[D loss: 0.999977] [G loss: 0.999995]\n",
      "epoch:37 step:177995[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:37 step:178000[D loss: 0.999961] [G loss: 1.000055]\n",
      "##############\n",
      "[2.52666916 2.37081556 2.33825937 3.84389002 1.55919113 6.97149933\n",
      " 2.24831155 3.58322459 4.02031818 5.44083279]\n",
      "##########\n",
      "epoch:37 step:178005[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:37 step:178010[D loss: 1.000013] [G loss: 1.000006]\n",
      "epoch:37 step:178015[D loss: 1.000005] [G loss: 1.000000]\n",
      "epoch:37 step:178020[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:37 step:178025[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:37 step:178030[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:38 step:178035[D loss: 1.000031] [G loss: 1.000039]\n",
      "epoch:38 step:178040[D loss: 0.999997] [G loss: 1.000078]\n",
      "epoch:38 step:178045[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:38 step:178050[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:38 step:178055[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:38 step:178060[D loss: 1.000002] [G loss: 0.999955]\n",
      "epoch:38 step:178065[D loss: 1.000004] [G loss: 1.000024]\n",
      "epoch:38 step:178070[D loss: 1.000022] [G loss: 0.999952]\n",
      "epoch:38 step:178075[D loss: 0.999989] [G loss: 1.000141]\n",
      "epoch:38 step:178080[D loss: 1.000133] [G loss: 1.000019]\n",
      "epoch:38 step:178085[D loss: 0.999985] [G loss: 1.000143]\n",
      "epoch:38 step:178090[D loss: 0.999790] [G loss: 1.000260]\n",
      "epoch:38 step:178095[D loss: 0.999909] [G loss: 1.000096]\n",
      "epoch:38 step:178100[D loss: 0.999920] [G loss: 1.000112]\n",
      "epoch:38 step:178105[D loss: 1.000024] [G loss: 1.000049]\n",
      "epoch:38 step:178110[D loss: 0.999953] [G loss: 1.000141]\n",
      "epoch:38 step:178115[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:38 step:178120[D loss: 0.999913] [G loss: 1.000217]\n",
      "epoch:38 step:178125[D loss: 0.999939] [G loss: 1.000142]\n",
      "epoch:38 step:178130[D loss: 0.999925] [G loss: 1.000095]\n",
      "epoch:38 step:178135[D loss: 1.000119] [G loss: 0.999895]\n",
      "epoch:38 step:178140[D loss: 1.000065] [G loss: 1.000045]\n",
      "epoch:38 step:178145[D loss: 0.999864] [G loss: 1.000167]\n",
      "epoch:38 step:178150[D loss: 0.999914] [G loss: 1.000161]\n",
      "epoch:38 step:178155[D loss: 0.999928] [G loss: 1.000092]\n",
      "epoch:38 step:178160[D loss: 1.000029] [G loss: 1.000051]\n",
      "epoch:38 step:178165[D loss: 1.000022] [G loss: 1.000168]\n",
      "epoch:38 step:178170[D loss: 0.999952] [G loss: 1.000070]\n",
      "epoch:38 step:178175[D loss: 0.999909] [G loss: 1.000091]\n",
      "epoch:38 step:178180[D loss: 1.000028] [G loss: 1.000059]\n",
      "epoch:38 step:178185[D loss: 0.999957] [G loss: 1.000121]\n",
      "epoch:38 step:178190[D loss: 0.999951] [G loss: 1.000116]\n",
      "epoch:38 step:178195[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:38 step:178200[D loss: 0.999951] [G loss: 1.000204]\n",
      "##############\n",
      "[2.50676898 2.18004092 2.26790517 3.73142867 1.51425614 6.86052268\n",
      " 2.1853274  3.66037656 3.90683725 5.12424447]\n",
      "##########\n",
      "epoch:38 step:178205[D loss: 1.000021] [G loss: 0.999983]\n",
      "epoch:38 step:178210[D loss: 1.000160] [G loss: 0.999917]\n",
      "epoch:38 step:178215[D loss: 1.000032] [G loss: 0.999960]\n",
      "epoch:38 step:178220[D loss: 0.999794] [G loss: 1.000253]\n",
      "epoch:38 step:178225[D loss: 0.999924] [G loss: 1.000119]\n",
      "epoch:38 step:178230[D loss: 1.000015] [G loss: 0.999983]\n",
      "epoch:38 step:178235[D loss: 1.000090] [G loss: 0.999782]\n",
      "epoch:38 step:178240[D loss: 0.999999] [G loss: 0.999930]\n",
      "epoch:38 step:178245[D loss: 0.999968] [G loss: 1.000009]\n",
      "epoch:38 step:178250[D loss: 1.000032] [G loss: 0.999850]\n",
      "epoch:38 step:178255[D loss: 1.000036] [G loss: 0.999996]\n",
      "epoch:38 step:178260[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:38 step:178265[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:38 step:178270[D loss: 0.999919] [G loss: 1.000115]\n",
      "epoch:38 step:178275[D loss: 1.000023] [G loss: 0.999921]\n",
      "epoch:38 step:178280[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:38 step:178285[D loss: 0.999970] [G loss: 1.000014]\n",
      "epoch:38 step:178290[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:38 step:178295[D loss: 0.999959] [G loss: 1.000138]\n",
      "epoch:38 step:178300[D loss: 1.000032] [G loss: 1.000009]\n",
      "epoch:38 step:178305[D loss: 0.999933] [G loss: 1.000112]\n",
      "epoch:38 step:178310[D loss: 0.999953] [G loss: 1.000112]\n",
      "epoch:38 step:178315[D loss: 0.999976] [G loss: 1.000053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:178320[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:38 step:178325[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:38 step:178330[D loss: 0.999941] [G loss: 1.000143]\n",
      "epoch:38 step:178335[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:38 step:178340[D loss: 1.000031] [G loss: 1.000011]\n",
      "epoch:38 step:178345[D loss: 0.999898] [G loss: 1.000271]\n",
      "epoch:38 step:178350[D loss: 1.000054] [G loss: 1.000029]\n",
      "epoch:38 step:178355[D loss: 1.000067] [G loss: 0.999886]\n",
      "epoch:38 step:178360[D loss: 0.999943] [G loss: 0.999967]\n",
      "epoch:38 step:178365[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:38 step:178370[D loss: 0.999926] [G loss: 1.000034]\n",
      "epoch:38 step:178375[D loss: 1.000041] [G loss: 1.000067]\n",
      "epoch:38 step:178380[D loss: 0.999999] [G loss: 1.000051]\n",
      "epoch:38 step:178385[D loss: 1.000030] [G loss: 0.999995]\n",
      "epoch:38 step:178390[D loss: 1.000126] [G loss: 0.999946]\n",
      "epoch:38 step:178395[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:38 step:178400[D loss: 1.000026] [G loss: 0.999985]\n",
      "##############\n",
      "[2.5188895  2.28344198 2.3202965  3.70365489 1.53434184 7.09979629\n",
      " 2.29052824 3.81130966 3.97536039 4.71397735]\n",
      "##########\n",
      "epoch:38 step:178405[D loss: 1.000153] [G loss: 0.999915]\n",
      "epoch:38 step:178410[D loss: 0.999931] [G loss: 1.000122]\n",
      "epoch:38 step:178415[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:38 step:178420[D loss: 1.000030] [G loss: 0.999929]\n",
      "epoch:38 step:178425[D loss: 0.999981] [G loss: 1.000117]\n",
      "epoch:38 step:178430[D loss: 1.000012] [G loss: 1.000057]\n",
      "epoch:38 step:178435[D loss: 0.999925] [G loss: 1.000136]\n",
      "epoch:38 step:178440[D loss: 0.999953] [G loss: 1.000078]\n",
      "epoch:38 step:178445[D loss: 0.999912] [G loss: 1.000150]\n",
      "epoch:38 step:178450[D loss: 0.999958] [G loss: 1.000106]\n",
      "epoch:38 step:178455[D loss: 1.000038] [G loss: 1.000003]\n",
      "epoch:38 step:178460[D loss: 1.000002] [G loss: 0.999992]\n",
      "epoch:38 step:178465[D loss: 0.999974] [G loss: 1.000039]\n",
      "epoch:38 step:178470[D loss: 0.999952] [G loss: 1.000046]\n",
      "epoch:38 step:178475[D loss: 1.000205] [G loss: 0.999882]\n",
      "epoch:38 step:178480[D loss: 0.999976] [G loss: 1.000143]\n",
      "epoch:38 step:178485[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:38 step:178490[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:38 step:178495[D loss: 0.999990] [G loss: 1.000008]\n",
      "epoch:38 step:178500[D loss: 0.999985] [G loss: 1.000017]\n",
      "epoch:38 step:178505[D loss: 1.000042] [G loss: 0.999997]\n",
      "epoch:38 step:178510[D loss: 1.000110] [G loss: 0.999928]\n",
      "epoch:38 step:178515[D loss: 1.000119] [G loss: 0.999972]\n",
      "epoch:38 step:178520[D loss: 0.999921] [G loss: 1.000307]\n",
      "epoch:38 step:178525[D loss: 0.999973] [G loss: 1.000100]\n",
      "epoch:38 step:178530[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:38 step:178535[D loss: 1.000077] [G loss: 0.999889]\n",
      "epoch:38 step:178540[D loss: 0.999929] [G loss: 1.000062]\n",
      "epoch:38 step:178545[D loss: 1.000005] [G loss: 1.000026]\n",
      "epoch:38 step:178550[D loss: 1.000022] [G loss: 0.999864]\n",
      "epoch:38 step:178555[D loss: 0.999920] [G loss: 1.000214]\n",
      "epoch:38 step:178560[D loss: 1.000032] [G loss: 0.999935]\n",
      "epoch:38 step:178565[D loss: 0.999995] [G loss: 1.000167]\n",
      "epoch:38 step:178570[D loss: 0.999935] [G loss: 1.000148]\n",
      "epoch:38 step:178575[D loss: 0.999933] [G loss: 1.000079]\n",
      "epoch:38 step:178580[D loss: 0.999920] [G loss: 1.000125]\n",
      "epoch:38 step:178585[D loss: 0.999995] [G loss: 1.000021]\n",
      "epoch:38 step:178590[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:38 step:178595[D loss: 1.000013] [G loss: 1.000040]\n",
      "epoch:38 step:178600[D loss: 0.999958] [G loss: 1.000063]\n",
      "##############\n",
      "[2.52824249 2.32621398 2.34861536 3.70985026 1.5529723  7.4417032\n",
      " 2.3376417  3.93879461 4.17880426 5.61823486]\n",
      "##########\n",
      "epoch:38 step:178605[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:38 step:178610[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:38 step:178615[D loss: 1.000117] [G loss: 0.999843]\n",
      "epoch:38 step:178620[D loss: 1.000255] [G loss: 0.999948]\n",
      "epoch:38 step:178625[D loss: 1.000031] [G loss: 0.999954]\n",
      "epoch:38 step:178630[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:38 step:178635[D loss: 0.999723] [G loss: 1.000423]\n",
      "epoch:38 step:178640[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:38 step:178645[D loss: 0.999947] [G loss: 1.000135]\n",
      "epoch:38 step:178650[D loss: 0.999963] [G loss: 1.000123]\n",
      "epoch:38 step:178655[D loss: 1.000106] [G loss: 0.999827]\n",
      "epoch:38 step:178660[D loss: 0.999934] [G loss: 1.000076]\n",
      "epoch:38 step:178665[D loss: 1.000007] [G loss: 0.999975]\n",
      "epoch:38 step:178670[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:38 step:178675[D loss: 1.000144] [G loss: 0.999856]\n",
      "epoch:38 step:178680[D loss: 0.999819] [G loss: 1.000166]\n",
      "epoch:38 step:178685[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:38 step:178690[D loss: 1.000036] [G loss: 1.000033]\n",
      "epoch:38 step:178695[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:38 step:178700[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:38 step:178705[D loss: 0.999948] [G loss: 1.000089]\n",
      "epoch:38 step:178710[D loss: 1.000007] [G loss: 1.000114]\n",
      "epoch:38 step:178715[D loss: 1.000031] [G loss: 0.999983]\n",
      "epoch:38 step:178720[D loss: 0.999913] [G loss: 1.000077]\n",
      "epoch:38 step:178725[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:38 step:178730[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:38 step:178735[D loss: 0.999970] [G loss: 1.000114]\n",
      "epoch:38 step:178740[D loss: 1.000034] [G loss: 0.999919]\n",
      "epoch:38 step:178745[D loss: 0.999962] [G loss: 1.000106]\n",
      "epoch:38 step:178750[D loss: 0.999948] [G loss: 1.000160]\n",
      "epoch:38 step:178755[D loss: 0.999968] [G loss: 1.000130]\n",
      "epoch:38 step:178760[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:38 step:178765[D loss: 0.999971] [G loss: 1.000119]\n",
      "epoch:38 step:178770[D loss: 1.000068] [G loss: 0.999879]\n",
      "epoch:38 step:178775[D loss: 1.000004] [G loss: 0.999936]\n",
      "epoch:38 step:178780[D loss: 0.999905] [G loss: 1.000127]\n",
      "epoch:38 step:178785[D loss: 0.999952] [G loss: 0.999995]\n",
      "epoch:38 step:178790[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:38 step:178795[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:38 step:178800[D loss: 0.999968] [G loss: 1.000042]\n",
      "##############\n",
      "[2.56395496 2.24917298 2.24431389 3.91405538 1.48096719 7.19857618\n",
      " 2.30895924 3.77424301 4.02255692 5.07212129]\n",
      "##########\n",
      "epoch:38 step:178805[D loss: 0.999979] [G loss: 1.000096]\n",
      "epoch:38 step:178810[D loss: 0.999976] [G loss: 1.000172]\n",
      "epoch:38 step:178815[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:38 step:178820[D loss: 1.000000] [G loss: 0.999986]\n",
      "epoch:38 step:178825[D loss: 0.999983] [G loss: 0.999983]\n",
      "epoch:38 step:178830[D loss: 0.999945] [G loss: 1.000082]\n",
      "epoch:38 step:178835[D loss: 1.000031] [G loss: 0.999951]\n",
      "epoch:38 step:178840[D loss: 1.000038] [G loss: 0.999945]\n",
      "epoch:38 step:178845[D loss: 0.999925] [G loss: 1.000116]\n",
      "epoch:38 step:178850[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:38 step:178855[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:38 step:178860[D loss: 1.000025] [G loss: 0.999945]\n",
      "epoch:38 step:178865[D loss: 0.999865] [G loss: 1.000116]\n",
      "epoch:38 step:178870[D loss: 0.999920] [G loss: 1.000052]\n",
      "epoch:38 step:178875[D loss: 0.999984] [G loss: 1.000109]\n",
      "epoch:38 step:178880[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:38 step:178885[D loss: 0.999944] [G loss: 1.000147]\n",
      "epoch:38 step:178890[D loss: 0.999948] [G loss: 1.000054]\n",
      "epoch:38 step:178895[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:38 step:178900[D loss: 0.999986] [G loss: 1.000005]\n",
      "epoch:38 step:178905[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:38 step:178910[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:38 step:178915[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:38 step:178920[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:38 step:178925[D loss: 1.000060] [G loss: 1.000001]\n",
      "epoch:38 step:178930[D loss: 0.999918] [G loss: 1.000081]\n",
      "epoch:38 step:178935[D loss: 0.999976] [G loss: 1.000151]\n",
      "epoch:38 step:178940[D loss: 0.999950] [G loss: 1.000112]\n",
      "epoch:38 step:178945[D loss: 0.999983] [G loss: 1.000091]\n",
      "epoch:38 step:178950[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:38 step:178955[D loss: 1.000034] [G loss: 0.999998]\n",
      "epoch:38 step:178960[D loss: 1.000044] [G loss: 0.999958]\n",
      "epoch:38 step:178965[D loss: 0.999986] [G loss: 1.000145]\n",
      "epoch:38 step:178970[D loss: 1.000049] [G loss: 0.999989]\n",
      "epoch:38 step:178975[D loss: 0.999949] [G loss: 1.000138]\n",
      "epoch:38 step:178980[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:38 step:178985[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:38 step:178990[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:38 step:178995[D loss: 0.999976] [G loss: 1.000125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:179000[D loss: 1.000027] [G loss: 1.000094]\n",
      "##############\n",
      "[2.58870215 2.30614302 2.34477388 3.61628034 1.58764107 7.68362562\n",
      " 2.40770889 3.69440222 4.01710484 5.45904283]\n",
      "##########\n",
      "epoch:38 step:179005[D loss: 0.999904] [G loss: 1.000072]\n",
      "epoch:38 step:179010[D loss: 0.999974] [G loss: 1.000143]\n",
      "epoch:38 step:179015[D loss: 0.999972] [G loss: 1.000187]\n",
      "epoch:38 step:179020[D loss: 1.000073] [G loss: 1.000043]\n",
      "epoch:38 step:179025[D loss: 1.000061] [G loss: 0.999954]\n",
      "epoch:38 step:179030[D loss: 1.000249] [G loss: 0.999940]\n",
      "epoch:38 step:179035[D loss: 0.999758] [G loss: 1.000379]\n",
      "epoch:38 step:179040[D loss: 0.999888] [G loss: 1.000169]\n",
      "epoch:38 step:179045[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:38 step:179050[D loss: 0.999968] [G loss: 1.000008]\n",
      "epoch:38 step:179055[D loss: 1.000066] [G loss: 0.999874]\n",
      "epoch:38 step:179060[D loss: 1.000111] [G loss: 0.999930]\n",
      "epoch:38 step:179065[D loss: 0.999976] [G loss: 0.999946]\n",
      "epoch:38 step:179070[D loss: 0.999865] [G loss: 1.000053]\n",
      "epoch:38 step:179075[D loss: 1.000007] [G loss: 1.000069]\n",
      "epoch:38 step:179080[D loss: 0.999963] [G loss: 1.000107]\n",
      "epoch:38 step:179085[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:38 step:179090[D loss: 0.999972] [G loss: 1.000037]\n",
      "epoch:38 step:179095[D loss: 0.999998] [G loss: 1.000035]\n",
      "epoch:38 step:179100[D loss: 0.999968] [G loss: 1.000145]\n",
      "epoch:38 step:179105[D loss: 0.999960] [G loss: 1.000154]\n",
      "epoch:38 step:179110[D loss: 1.000029] [G loss: 1.000017]\n",
      "epoch:38 step:179115[D loss: 1.000309] [G loss: 1.000045]\n",
      "epoch:38 step:179120[D loss: 1.000100] [G loss: 0.999803]\n",
      "epoch:38 step:179125[D loss: 0.999833] [G loss: 1.000279]\n",
      "epoch:38 step:179130[D loss: 0.999942] [G loss: 1.000268]\n",
      "epoch:38 step:179135[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:38 step:179140[D loss: 1.000121] [G loss: 0.999820]\n",
      "epoch:38 step:179145[D loss: 1.000275] [G loss: 0.999489]\n",
      "epoch:38 step:179150[D loss: 1.000027] [G loss: 0.999890]\n",
      "epoch:38 step:179155[D loss: 1.000025] [G loss: 1.000017]\n",
      "epoch:38 step:179160[D loss: 0.999960] [G loss: 1.000297]\n",
      "epoch:38 step:179165[D loss: 1.000281] [G loss: 0.999770]\n",
      "epoch:38 step:179170[D loss: 0.999720] [G loss: 1.000376]\n",
      "epoch:38 step:179175[D loss: 0.999638] [G loss: 1.000463]\n",
      "epoch:38 step:179180[D loss: 1.000199] [G loss: 0.999944]\n",
      "epoch:38 step:179185[D loss: 0.999854] [G loss: 1.000349]\n",
      "epoch:38 step:179190[D loss: 0.999918] [G loss: 1.000173]\n",
      "epoch:38 step:179195[D loss: 0.999984] [G loss: 1.000275]\n",
      "epoch:38 step:179200[D loss: 0.999890] [G loss: 1.000391]\n",
      "##############\n",
      "[2.6130328  2.27957276 2.23468138 3.45561496 1.54632297 7.01720069\n",
      " 2.25791301 3.87779786 3.97363755 4.9662619 ]\n",
      "##########\n",
      "epoch:38 step:179205[D loss: 0.999919] [G loss: 1.000394]\n",
      "epoch:38 step:179210[D loss: 0.999766] [G loss: 1.000458]\n",
      "epoch:38 step:179215[D loss: 0.999958] [G loss: 1.000148]\n",
      "epoch:38 step:179220[D loss: 0.999984] [G loss: 0.999959]\n",
      "epoch:38 step:179225[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:38 step:179230[D loss: 1.000108] [G loss: 0.999946]\n",
      "epoch:38 step:179235[D loss: 1.000159] [G loss: 0.999735]\n",
      "epoch:38 step:179240[D loss: 1.000265] [G loss: 0.999489]\n",
      "epoch:38 step:179245[D loss: 1.000005] [G loss: 0.999937]\n",
      "epoch:38 step:179250[D loss: 1.000109] [G loss: 1.000085]\n",
      "epoch:38 step:179255[D loss: 0.999814] [G loss: 1.000254]\n",
      "epoch:38 step:179260[D loss: 0.999953] [G loss: 1.000076]\n",
      "epoch:38 step:179265[D loss: 0.999806] [G loss: 1.000072]\n",
      "epoch:38 step:179270[D loss: 0.999961] [G loss: 1.000231]\n",
      "epoch:38 step:179275[D loss: 0.999941] [G loss: 1.000226]\n",
      "epoch:38 step:179280[D loss: 1.000066] [G loss: 0.999883]\n",
      "epoch:38 step:179285[D loss: 0.999968] [G loss: 1.000019]\n",
      "epoch:38 step:179290[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:38 step:179295[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:38 step:179300[D loss: 0.999942] [G loss: 1.000167]\n",
      "epoch:38 step:179305[D loss: 0.999945] [G loss: 1.000166]\n",
      "epoch:38 step:179310[D loss: 0.999942] [G loss: 1.000154]\n",
      "epoch:38 step:179315[D loss: 0.999952] [G loss: 1.000114]\n",
      "epoch:38 step:179320[D loss: 1.000008] [G loss: 1.000083]\n",
      "epoch:38 step:179325[D loss: 1.000038] [G loss: 0.999932]\n",
      "epoch:38 step:179330[D loss: 1.000007] [G loss: 1.000017]\n",
      "epoch:38 step:179335[D loss: 0.999954] [G loss: 1.000094]\n",
      "epoch:38 step:179340[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:38 step:179345[D loss: 1.000027] [G loss: 1.000024]\n",
      "epoch:38 step:179350[D loss: 0.999918] [G loss: 1.000120]\n",
      "epoch:38 step:179355[D loss: 0.999943] [G loss: 1.000079]\n",
      "epoch:38 step:179360[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:38 step:179365[D loss: 0.999925] [G loss: 1.000118]\n",
      "epoch:38 step:179370[D loss: 1.000013] [G loss: 1.000020]\n",
      "epoch:38 step:179375[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:38 step:179380[D loss: 1.000007] [G loss: 1.000042]\n",
      "epoch:38 step:179385[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:38 step:179390[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:38 step:179395[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:38 step:179400[D loss: 1.000005] [G loss: 1.000005]\n",
      "##############\n",
      "[2.57636562 2.33026397 2.38895692 3.50724745 1.57842989 6.81563133\n",
      " 2.27827629 3.68706251 4.05862356 5.14385408]\n",
      "##########\n",
      "epoch:38 step:179405[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:38 step:179410[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:38 step:179415[D loss: 0.999963] [G loss: 1.000035]\n",
      "epoch:38 step:179420[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:38 step:179425[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:38 step:179430[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:38 step:179435[D loss: 0.999970] [G loss: 1.000043]\n",
      "epoch:38 step:179440[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:38 step:179445[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:38 step:179450[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:38 step:179455[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:38 step:179460[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:38 step:179465[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:38 step:179470[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:38 step:179475[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:38 step:179480[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:38 step:179485[D loss: 0.999930] [G loss: 1.000096]\n",
      "epoch:38 step:179490[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:38 step:179495[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:38 step:179500[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:38 step:179505[D loss: 1.000012] [G loss: 1.000068]\n",
      "epoch:38 step:179510[D loss: 0.999946] [G loss: 1.000115]\n",
      "epoch:38 step:179515[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:38 step:179520[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:38 step:179525[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:38 step:179530[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:38 step:179535[D loss: 0.999996] [G loss: 1.000004]\n",
      "epoch:38 step:179540[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:38 step:179545[D loss: 1.000070] [G loss: 0.999951]\n",
      "epoch:38 step:179550[D loss: 0.999965] [G loss: 1.000016]\n",
      "epoch:38 step:179555[D loss: 1.000040] [G loss: 0.999970]\n",
      "epoch:38 step:179560[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:38 step:179565[D loss: 0.999941] [G loss: 1.000064]\n",
      "epoch:38 step:179570[D loss: 0.999932] [G loss: 1.000097]\n",
      "epoch:38 step:179575[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:38 step:179580[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:38 step:179585[D loss: 1.000047] [G loss: 0.999976]\n",
      "epoch:38 step:179590[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:38 step:179595[D loss: 0.999982] [G loss: 1.000036]\n",
      "epoch:38 step:179600[D loss: 0.999960] [G loss: 1.000070]\n",
      "##############\n",
      "[2.51972218 2.26858541 2.31744354 3.48784398 1.50632879 6.65667867\n",
      " 2.25937111 3.72871074 3.9586682  5.92552886]\n",
      "##########\n",
      "epoch:38 step:179605[D loss: 0.999935] [G loss: 1.000160]\n",
      "epoch:38 step:179610[D loss: 1.000006] [G loss: 1.000159]\n",
      "epoch:38 step:179615[D loss: 0.999948] [G loss: 1.000032]\n",
      "epoch:38 step:179620[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:38 step:179625[D loss: 0.999968] [G loss: 1.000106]\n",
      "epoch:38 step:179630[D loss: 1.000013] [G loss: 0.999987]\n",
      "epoch:38 step:179635[D loss: 1.000056] [G loss: 1.000026]\n",
      "epoch:38 step:179640[D loss: 1.000077] [G loss: 0.999940]\n",
      "epoch:38 step:179645[D loss: 1.000040] [G loss: 1.000052]\n",
      "epoch:38 step:179650[D loss: 0.999996] [G loss: 1.000019]\n",
      "epoch:38 step:179655[D loss: 0.999972] [G loss: 0.999992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:179660[D loss: 1.000055] [G loss: 0.999980]\n",
      "epoch:38 step:179665[D loss: 1.000207] [G loss: 0.999864]\n",
      "epoch:38 step:179670[D loss: 0.999951] [G loss: 0.999983]\n",
      "epoch:38 step:179675[D loss: 1.000032] [G loss: 1.000113]\n",
      "epoch:38 step:179680[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:38 step:179685[D loss: 0.999938] [G loss: 1.000097]\n",
      "epoch:38 step:179690[D loss: 0.999939] [G loss: 1.000088]\n",
      "epoch:38 step:179695[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:38 step:179700[D loss: 0.999976] [G loss: 1.000134]\n",
      "epoch:38 step:179705[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:38 step:179710[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:38 step:179715[D loss: 1.000015] [G loss: 1.000054]\n",
      "epoch:38 step:179720[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:38 step:179725[D loss: 1.000012] [G loss: 0.999969]\n",
      "epoch:38 step:179730[D loss: 0.999914] [G loss: 1.000112]\n",
      "epoch:38 step:179735[D loss: 0.999930] [G loss: 1.000126]\n",
      "epoch:38 step:179740[D loss: 0.999961] [G loss: 1.000100]\n",
      "epoch:38 step:179745[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:38 step:179750[D loss: 1.000009] [G loss: 0.999971]\n",
      "epoch:38 step:179755[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:38 step:179760[D loss: 1.000141] [G loss: 0.999927]\n",
      "epoch:38 step:179765[D loss: 1.000013] [G loss: 0.999911]\n",
      "epoch:38 step:179770[D loss: 0.999943] [G loss: 1.000034]\n",
      "epoch:38 step:179775[D loss: 1.000052] [G loss: 1.000151]\n",
      "epoch:38 step:179780[D loss: 0.999952] [G loss: 1.000035]\n",
      "epoch:38 step:179785[D loss: 0.999989] [G loss: 1.000135]\n",
      "epoch:38 step:179790[D loss: 1.000009] [G loss: 1.000161]\n",
      "epoch:38 step:179795[D loss: 0.999905] [G loss: 1.000189]\n",
      "epoch:38 step:179800[D loss: 0.999993] [G loss: 1.000071]\n",
      "##############\n",
      "[2.63625697 2.26648866 2.2354474  3.31836851 1.62896623 7.40503143\n",
      " 2.29422409 3.68027606 4.02785791 5.03545212]\n",
      "##########\n",
      "epoch:38 step:179805[D loss: 1.000016] [G loss: 0.999939]\n",
      "epoch:38 step:179810[D loss: 0.999984] [G loss: 0.999975]\n",
      "epoch:38 step:179815[D loss: 0.999940] [G loss: 1.000007]\n",
      "epoch:38 step:179820[D loss: 1.000215] [G loss: 0.999786]\n",
      "epoch:38 step:179825[D loss: 0.999920] [G loss: 0.999999]\n",
      "epoch:38 step:179830[D loss: 1.000211] [G loss: 0.999845]\n",
      "epoch:38 step:179835[D loss: 0.999914] [G loss: 1.000139]\n",
      "epoch:38 step:179840[D loss: 0.999930] [G loss: 1.000004]\n",
      "epoch:38 step:179845[D loss: 0.999888] [G loss: 1.000090]\n",
      "epoch:38 step:179850[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:38 step:179855[D loss: 0.999967] [G loss: 1.000017]\n",
      "epoch:38 step:179860[D loss: 0.999905] [G loss: 1.000187]\n",
      "epoch:38 step:179865[D loss: 0.999959] [G loss: 1.000346]\n",
      "epoch:38 step:179870[D loss: 0.999966] [G loss: 1.000120]\n",
      "epoch:38 step:179875[D loss: 1.000054] [G loss: 0.999936]\n",
      "epoch:38 step:179880[D loss: 1.000086] [G loss: 0.999929]\n",
      "epoch:38 step:179885[D loss: 1.000066] [G loss: 0.999938]\n",
      "epoch:38 step:179890[D loss: 0.999877] [G loss: 1.000224]\n",
      "epoch:38 step:179895[D loss: 0.999932] [G loss: 1.000080]\n",
      "epoch:38 step:179900[D loss: 1.000102] [G loss: 1.000141]\n",
      "epoch:38 step:179905[D loss: 1.000006] [G loss: 1.000054]\n",
      "epoch:38 step:179910[D loss: 0.999955] [G loss: 1.000029]\n",
      "epoch:38 step:179915[D loss: 1.000046] [G loss: 0.999848]\n",
      "epoch:38 step:179920[D loss: 1.000171] [G loss: 0.999935]\n",
      "epoch:38 step:179925[D loss: 0.999968] [G loss: 1.000103]\n",
      "epoch:38 step:179930[D loss: 0.999837] [G loss: 0.999990]\n",
      "epoch:38 step:179935[D loss: 1.000038] [G loss: 0.999807]\n",
      "epoch:38 step:179940[D loss: 0.999780] [G loss: 1.000265]\n",
      "epoch:38 step:179945[D loss: 0.999821] [G loss: 1.000152]\n",
      "epoch:38 step:179950[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:38 step:179955[D loss: 1.000075] [G loss: 0.999932]\n",
      "epoch:38 step:179960[D loss: 0.999943] [G loss: 1.000021]\n",
      "epoch:38 step:179965[D loss: 1.000056] [G loss: 1.000093]\n",
      "epoch:38 step:179970[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:38 step:179975[D loss: 0.999877] [G loss: 0.999989]\n",
      "epoch:38 step:179980[D loss: 0.999998] [G loss: 1.000093]\n",
      "epoch:38 step:179985[D loss: 0.999898] [G loss: 1.000064]\n",
      "epoch:38 step:179990[D loss: 1.000079] [G loss: 1.000028]\n",
      "epoch:38 step:179995[D loss: 0.999939] [G loss: 1.000075]\n",
      "epoch:38 step:180000[D loss: 0.999934] [G loss: 1.000219]\n",
      "##############\n",
      "[2.62346928 2.27000041 2.19826417 3.26838522 1.60399323 7.12179252\n",
      " 2.30561643 3.58686421 4.00757793 5.81383272]\n",
      "##########\n",
      "epoch:38 step:180005[D loss: 0.999935] [G loss: 1.000114]\n",
      "epoch:38 step:180010[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:38 step:180015[D loss: 1.000003] [G loss: 0.999949]\n",
      "epoch:38 step:180020[D loss: 1.000115] [G loss: 0.999852]\n",
      "epoch:38 step:180025[D loss: 1.000025] [G loss: 0.999966]\n",
      "epoch:38 step:180030[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:38 step:180035[D loss: 1.000023] [G loss: 1.000022]\n",
      "epoch:38 step:180040[D loss: 0.999932] [G loss: 1.000194]\n",
      "epoch:38 step:180045[D loss: 1.000090] [G loss: 0.999910]\n",
      "epoch:38 step:180050[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:38 step:180055[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:38 step:180060[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:38 step:180065[D loss: 0.999988] [G loss: 1.000123]\n",
      "epoch:38 step:180070[D loss: 0.999940] [G loss: 1.000075]\n",
      "epoch:38 step:180075[D loss: 1.000048] [G loss: 0.999938]\n",
      "epoch:38 step:180080[D loss: 1.000195] [G loss: 0.999998]\n",
      "epoch:38 step:180085[D loss: 0.999904] [G loss: 1.000139]\n",
      "epoch:38 step:180090[D loss: 1.000020] [G loss: 1.000037]\n",
      "epoch:38 step:180095[D loss: 1.000010] [G loss: 0.999964]\n",
      "epoch:38 step:180100[D loss: 1.000039] [G loss: 0.999955]\n",
      "epoch:38 step:180105[D loss: 0.999951] [G loss: 1.000105]\n",
      "epoch:38 step:180110[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:38 step:180115[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:38 step:180120[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:38 step:180125[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:38 step:180130[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:38 step:180135[D loss: 1.000013] [G loss: 1.000070]\n",
      "epoch:38 step:180140[D loss: 1.000029] [G loss: 1.000125]\n",
      "epoch:38 step:180145[D loss: 0.999897] [G loss: 1.000168]\n",
      "epoch:38 step:180150[D loss: 1.000002] [G loss: 1.000051]\n",
      "epoch:38 step:180155[D loss: 0.999927] [G loss: 1.000131]\n",
      "epoch:38 step:180160[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:38 step:180165[D loss: 1.000013] [G loss: 0.999919]\n",
      "epoch:38 step:180170[D loss: 0.999983] [G loss: 1.000091]\n",
      "epoch:38 step:180175[D loss: 0.999922] [G loss: 1.000141]\n",
      "epoch:38 step:180180[D loss: 0.999945] [G loss: 1.000179]\n",
      "epoch:38 step:180185[D loss: 0.999974] [G loss: 0.999965]\n",
      "epoch:38 step:180190[D loss: 1.000004] [G loss: 1.000133]\n",
      "epoch:38 step:180195[D loss: 1.000009] [G loss: 1.000049]\n",
      "epoch:38 step:180200[D loss: 1.000024] [G loss: 1.000025]\n",
      "##############\n",
      "[2.58902473 2.17617084 2.32443851 3.25514394 1.50386766 6.85815456\n",
      " 2.38277797 3.85469376 4.05249303 5.10567709]\n",
      "##########\n",
      "epoch:38 step:180205[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:38 step:180210[D loss: 1.000107] [G loss: 1.000080]\n",
      "epoch:38 step:180215[D loss: 0.999866] [G loss: 1.000236]\n",
      "epoch:38 step:180220[D loss: 1.000003] [G loss: 1.000064]\n",
      "epoch:38 step:180225[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:38 step:180230[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:38 step:180235[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:38 step:180240[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:38 step:180245[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:38 step:180250[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:38 step:180255[D loss: 1.000050] [G loss: 0.999941]\n",
      "epoch:38 step:180260[D loss: 0.999966] [G loss: 1.000030]\n",
      "epoch:38 step:180265[D loss: 1.000037] [G loss: 0.999985]\n",
      "epoch:38 step:180270[D loss: 0.999950] [G loss: 1.000174]\n",
      "epoch:38 step:180275[D loss: 0.999984] [G loss: 1.000102]\n",
      "epoch:38 step:180280[D loss: 0.999970] [G loss: 1.000130]\n",
      "epoch:38 step:180285[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:38 step:180290[D loss: 0.999980] [G loss: 1.000099]\n",
      "epoch:38 step:180295[D loss: 0.999995] [G loss: 1.000080]\n",
      "epoch:38 step:180300[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:38 step:180305[D loss: 1.000004] [G loss: 0.999978]\n",
      "epoch:38 step:180310[D loss: 1.000026] [G loss: 0.999935]\n",
      "epoch:38 step:180315[D loss: 1.000124] [G loss: 0.999819]\n",
      "epoch:38 step:180320[D loss: 0.999994] [G loss: 1.000131]\n",
      "epoch:38 step:180325[D loss: 1.000292] [G loss: 0.999943]\n",
      "epoch:38 step:180330[D loss: 0.999849] [G loss: 1.000286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:180335[D loss: 0.999886] [G loss: 1.000200]\n",
      "epoch:38 step:180340[D loss: 0.999938] [G loss: 1.000053]\n",
      "epoch:38 step:180345[D loss: 0.999991] [G loss: 1.000016]\n",
      "epoch:38 step:180350[D loss: 1.000066] [G loss: 0.999895]\n",
      "epoch:38 step:180355[D loss: 1.000076] [G loss: 0.999931]\n",
      "epoch:38 step:180360[D loss: 0.999976] [G loss: 0.999991]\n",
      "epoch:38 step:180365[D loss: 0.999896] [G loss: 1.000168]\n",
      "epoch:38 step:180370[D loss: 0.999983] [G loss: 1.000104]\n",
      "epoch:38 step:180375[D loss: 0.999937] [G loss: 1.000223]\n",
      "epoch:38 step:180380[D loss: 0.999922] [G loss: 1.000157]\n",
      "epoch:38 step:180385[D loss: 0.999943] [G loss: 1.000184]\n",
      "epoch:38 step:180390[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:38 step:180395[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:38 step:180400[D loss: 0.999981] [G loss: 0.999971]\n",
      "##############\n",
      "[2.57969134 2.14385163 2.29770538 3.71067527 1.50312157 6.5079739\n",
      " 2.38094866 3.6153434  4.04680987 5.16295125]\n",
      "##########\n",
      "epoch:38 step:180405[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:38 step:180410[D loss: 0.999948] [G loss: 1.000049]\n",
      "epoch:38 step:180415[D loss: 0.999974] [G loss: 1.000027]\n",
      "epoch:38 step:180420[D loss: 0.999954] [G loss: 1.000071]\n",
      "epoch:38 step:180425[D loss: 1.000002] [G loss: 0.999980]\n",
      "epoch:38 step:180430[D loss: 0.999955] [G loss: 1.000031]\n",
      "epoch:38 step:180435[D loss: 1.000009] [G loss: 1.000087]\n",
      "epoch:38 step:180440[D loss: 0.999962] [G loss: 1.000022]\n",
      "epoch:38 step:180445[D loss: 0.999970] [G loss: 1.000117]\n",
      "epoch:38 step:180450[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:38 step:180455[D loss: 1.000125] [G loss: 0.999899]\n",
      "epoch:38 step:180460[D loss: 0.999935] [G loss: 1.000062]\n",
      "epoch:38 step:180465[D loss: 1.000002] [G loss: 1.000115]\n",
      "epoch:38 step:180470[D loss: 1.000033] [G loss: 1.000044]\n",
      "epoch:38 step:180475[D loss: 1.000204] [G loss: 0.999857]\n",
      "epoch:38 step:180480[D loss: 0.999777] [G loss: 1.000422]\n",
      "epoch:38 step:180485[D loss: 0.999915] [G loss: 1.000252]\n",
      "epoch:38 step:180490[D loss: 0.999955] [G loss: 1.000322]\n",
      "epoch:38 step:180495[D loss: 0.999887] [G loss: 1.000486]\n",
      "epoch:38 step:180500[D loss: 1.000047] [G loss: 1.000255]\n",
      "epoch:38 step:180505[D loss: 0.999886] [G loss: 1.000200]\n",
      "epoch:38 step:180510[D loss: 1.000099] [G loss: 1.000210]\n",
      "epoch:38 step:180515[D loss: 1.000091] [G loss: 1.000057]\n",
      "epoch:38 step:180520[D loss: 0.999916] [G loss: 1.000121]\n",
      "epoch:38 step:180525[D loss: 1.000150] [G loss: 0.999776]\n",
      "epoch:38 step:180530[D loss: 1.000143] [G loss: 0.999794]\n",
      "epoch:38 step:180535[D loss: 0.999897] [G loss: 0.999929]\n",
      "epoch:38 step:180540[D loss: 0.999970] [G loss: 0.999903]\n",
      "epoch:38 step:180545[D loss: 0.999891] [G loss: 1.000125]\n",
      "epoch:38 step:180550[D loss: 1.000106] [G loss: 0.999762]\n",
      "epoch:38 step:180555[D loss: 1.000060] [G loss: 0.999838]\n",
      "epoch:38 step:180560[D loss: 0.999926] [G loss: 1.000116]\n",
      "epoch:38 step:180565[D loss: 0.999933] [G loss: 1.000321]\n",
      "epoch:38 step:180570[D loss: 0.999998] [G loss: 1.000130]\n",
      "epoch:38 step:180575[D loss: 1.000033] [G loss: 1.000164]\n",
      "epoch:38 step:180580[D loss: 1.000230] [G loss: 1.000200]\n",
      "epoch:38 step:180585[D loss: 0.999806] [G loss: 1.000333]\n",
      "epoch:38 step:180590[D loss: 0.999750] [G loss: 1.000249]\n",
      "epoch:38 step:180595[D loss: 0.999958] [G loss: 1.000124]\n",
      "epoch:38 step:180600[D loss: 0.999978] [G loss: 1.000037]\n",
      "##############\n",
      "[2.56333445 2.26493365 2.40335491 3.30680249 1.4811003  6.87684035\n",
      " 2.50985647 3.82686807 4.09130853 5.92778077]\n",
      "##########\n",
      "epoch:38 step:180605[D loss: 0.999932] [G loss: 1.000055]\n",
      "epoch:38 step:180610[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:38 step:180615[D loss: 1.000347] [G loss: 0.999603]\n",
      "epoch:38 step:180620[D loss: 0.999950] [G loss: 0.999933]\n",
      "epoch:38 step:180625[D loss: 0.999941] [G loss: 1.000043]\n",
      "epoch:38 step:180630[D loss: 1.000145] [G loss: 0.999847]\n",
      "epoch:38 step:180635[D loss: 0.999884] [G loss: 1.000308]\n",
      "epoch:38 step:180640[D loss: 0.999920] [G loss: 1.000216]\n",
      "epoch:38 step:180645[D loss: 1.000018] [G loss: 1.000058]\n",
      "epoch:38 step:180650[D loss: 1.000041] [G loss: 1.000120]\n",
      "epoch:38 step:180655[D loss: 0.999946] [G loss: 1.000126]\n",
      "epoch:38 step:180660[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:38 step:180665[D loss: 0.999968] [G loss: 1.000107]\n",
      "epoch:38 step:180670[D loss: 1.000010] [G loss: 0.999965]\n",
      "epoch:38 step:180675[D loss: 1.000008] [G loss: 1.000066]\n",
      "epoch:38 step:180680[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:38 step:180685[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:38 step:180690[D loss: 0.999938] [G loss: 1.000097]\n",
      "epoch:38 step:180695[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:38 step:180700[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:38 step:180705[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:38 step:180710[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:38 step:180715[D loss: 1.000077] [G loss: 0.999872]\n",
      "epoch:38 step:180720[D loss: 0.999942] [G loss: 1.000138]\n",
      "epoch:38 step:180725[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:38 step:180730[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:38 step:180735[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:38 step:180740[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:38 step:180745[D loss: 0.999997] [G loss: 1.000082]\n",
      "epoch:38 step:180750[D loss: 1.000000] [G loss: 1.000083]\n",
      "epoch:38 step:180755[D loss: 1.000036] [G loss: 1.000035]\n",
      "epoch:38 step:180760[D loss: 1.000046] [G loss: 1.000000]\n",
      "epoch:38 step:180765[D loss: 0.999939] [G loss: 1.000049]\n",
      "epoch:38 step:180770[D loss: 0.999898] [G loss: 1.000176]\n",
      "epoch:38 step:180775[D loss: 0.999925] [G loss: 1.000141]\n",
      "epoch:38 step:180780[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:38 step:180785[D loss: 0.999990] [G loss: 1.000091]\n",
      "epoch:38 step:180790[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:38 step:180795[D loss: 1.000072] [G loss: 0.999995]\n",
      "epoch:38 step:180800[D loss: 0.999937] [G loss: 1.000056]\n",
      "##############\n",
      "[2.52861462 2.22806712 2.28970033 3.55174166 1.55638606 6.83567881\n",
      " 2.30048697 3.81835647 4.02116086 5.6223221 ]\n",
      "##########\n",
      "epoch:38 step:180805[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:38 step:180810[D loss: 0.999950] [G loss: 1.000111]\n",
      "epoch:38 step:180815[D loss: 0.999954] [G loss: 1.000110]\n",
      "epoch:38 step:180820[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:38 step:180825[D loss: 0.999952] [G loss: 1.000102]\n",
      "epoch:38 step:180830[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:38 step:180835[D loss: 1.000024] [G loss: 0.999964]\n",
      "epoch:38 step:180840[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:38 step:180845[D loss: 1.000036] [G loss: 0.999991]\n",
      "epoch:38 step:180850[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:38 step:180855[D loss: 1.000016] [G loss: 1.000044]\n",
      "epoch:38 step:180860[D loss: 0.999947] [G loss: 1.000075]\n",
      "epoch:38 step:180865[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:38 step:180870[D loss: 0.999949] [G loss: 1.000110]\n",
      "epoch:38 step:180875[D loss: 0.999989] [G loss: 1.000079]\n",
      "epoch:38 step:180880[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:38 step:180885[D loss: 0.999953] [G loss: 1.000098]\n",
      "epoch:38 step:180890[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:38 step:180895[D loss: 1.000065] [G loss: 1.000044]\n",
      "epoch:38 step:180900[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:38 step:180905[D loss: 0.999989] [G loss: 1.000174]\n",
      "epoch:38 step:180910[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:38 step:180915[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:38 step:180920[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:38 step:180925[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:38 step:180930[D loss: 1.000017] [G loss: 0.999993]\n",
      "epoch:38 step:180935[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:38 step:180940[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:38 step:180945[D loss: 1.000069] [G loss: 0.999886]\n",
      "epoch:38 step:180950[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:38 step:180955[D loss: 0.999998] [G loss: 1.000012]\n",
      "epoch:38 step:180960[D loss: 1.000059] [G loss: 0.999968]\n",
      "epoch:38 step:180965[D loss: 0.999923] [G loss: 1.000154]\n",
      "epoch:38 step:180970[D loss: 0.999949] [G loss: 1.000217]\n",
      "epoch:38 step:180975[D loss: 1.000049] [G loss: 1.000120]\n",
      "epoch:38 step:180980[D loss: 1.000071] [G loss: 0.999896]\n",
      "epoch:38 step:180985[D loss: 0.999894] [G loss: 1.000158]\n",
      "epoch:38 step:180990[D loss: 0.999995] [G loss: 1.000069]\n",
      "epoch:38 step:180995[D loss: 1.000160] [G loss: 0.999797]\n",
      "epoch:38 step:181000[D loss: 1.000066] [G loss: 0.999881]\n",
      "##############\n",
      "[2.55792754 2.23919755 2.27381563 3.58518853 1.55612209 7.18561959\n",
      " 2.22864064 3.76374387 3.98108282 4.68309008]\n",
      "##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:181005[D loss: 1.000310] [G loss: 0.999701]\n",
      "epoch:38 step:181010[D loss: 1.000041] [G loss: 0.999817]\n",
      "epoch:38 step:181015[D loss: 0.999814] [G loss: 1.000175]\n",
      "epoch:38 step:181020[D loss: 0.999921] [G loss: 1.000100]\n",
      "epoch:38 step:181025[D loss: 0.999972] [G loss: 1.000109]\n",
      "epoch:38 step:181030[D loss: 0.999873] [G loss: 1.000233]\n",
      "epoch:38 step:181035[D loss: 0.999965] [G loss: 1.000045]\n",
      "epoch:38 step:181040[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:38 step:181045[D loss: 0.999949] [G loss: 1.000064]\n",
      "epoch:38 step:181050[D loss: 1.000017] [G loss: 0.999967]\n",
      "epoch:38 step:181055[D loss: 0.999899] [G loss: 1.000061]\n",
      "epoch:38 step:181060[D loss: 0.999961] [G loss: 1.000037]\n",
      "epoch:38 step:181065[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:38 step:181070[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:38 step:181075[D loss: 1.000045] [G loss: 1.000020]\n",
      "epoch:38 step:181080[D loss: 0.999957] [G loss: 1.000046]\n",
      "epoch:38 step:181085[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:38 step:181090[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:38 step:181095[D loss: 0.999952] [G loss: 1.000064]\n",
      "epoch:38 step:181100[D loss: 1.000003] [G loss: 0.999992]\n",
      "epoch:38 step:181105[D loss: 0.999955] [G loss: 1.000010]\n",
      "epoch:38 step:181110[D loss: 0.999992] [G loss: 1.000015]\n",
      "epoch:38 step:181115[D loss: 1.000041] [G loss: 1.000086]\n",
      "epoch:38 step:181120[D loss: 0.999955] [G loss: 1.000127]\n",
      "epoch:38 step:181125[D loss: 0.999906] [G loss: 1.000068]\n",
      "epoch:38 step:181130[D loss: 1.000034] [G loss: 1.000081]\n",
      "epoch:38 step:181135[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:38 step:181140[D loss: 1.000035] [G loss: 1.000046]\n",
      "epoch:38 step:181145[D loss: 0.999913] [G loss: 1.000102]\n",
      "epoch:38 step:181150[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:38 step:181155[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:38 step:181160[D loss: 0.999928] [G loss: 1.000134]\n",
      "epoch:38 step:181165[D loss: 1.000069] [G loss: 1.000034]\n",
      "epoch:38 step:181170[D loss: 1.000035] [G loss: 0.999955]\n",
      "epoch:38 step:181175[D loss: 0.999928] [G loss: 1.000243]\n",
      "epoch:38 step:181180[D loss: 0.999990] [G loss: 1.000177]\n",
      "epoch:38 step:181185[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:38 step:181190[D loss: 0.999993] [G loss: 1.000091]\n",
      "epoch:38 step:181195[D loss: 1.000000] [G loss: 1.000087]\n",
      "epoch:38 step:181200[D loss: 1.000013] [G loss: 1.000028]\n",
      "##############\n",
      "[2.65564595 2.18640109 2.20179152 3.42741666 1.54066519 6.92751853\n",
      " 2.35716644 3.8881556  4.10971551 5.87167205]\n",
      "##########\n",
      "epoch:38 step:181205[D loss: 1.000013] [G loss: 0.999937]\n",
      "epoch:38 step:181210[D loss: 1.000109] [G loss: 0.999775]\n",
      "epoch:38 step:181215[D loss: 1.000255] [G loss: 0.999723]\n",
      "epoch:38 step:181220[D loss: 0.999699] [G loss: 1.000290]\n",
      "epoch:38 step:181225[D loss: 0.999952] [G loss: 0.999985]\n",
      "epoch:38 step:181230[D loss: 1.000146] [G loss: 0.999907]\n",
      "epoch:38 step:181235[D loss: 1.000056] [G loss: 1.000215]\n",
      "epoch:38 step:181240[D loss: 0.999867] [G loss: 1.000216]\n",
      "epoch:38 step:181245[D loss: 0.999900] [G loss: 1.000095]\n",
      "epoch:38 step:181250[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:38 step:181255[D loss: 1.000031] [G loss: 0.999944]\n",
      "epoch:38 step:181260[D loss: 1.000052] [G loss: 0.999904]\n",
      "epoch:38 step:181265[D loss: 1.000008] [G loss: 0.999863]\n",
      "epoch:38 step:181270[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:38 step:181275[D loss: 1.000111] [G loss: 0.999892]\n",
      "epoch:38 step:181280[D loss: 0.999799] [G loss: 1.000297]\n",
      "epoch:38 step:181285[D loss: 0.999989] [G loss: 1.000353]\n",
      "epoch:38 step:181290[D loss: 0.999869] [G loss: 1.000282]\n",
      "epoch:38 step:181295[D loss: 0.999942] [G loss: 1.000222]\n",
      "epoch:38 step:181300[D loss: 0.999961] [G loss: 1.000117]\n",
      "epoch:38 step:181305[D loss: 0.999982] [G loss: 0.999969]\n",
      "epoch:38 step:181310[D loss: 1.000008] [G loss: 1.000071]\n",
      "epoch:38 step:181315[D loss: 1.000031] [G loss: 0.999975]\n",
      "epoch:38 step:181320[D loss: 0.999916] [G loss: 1.000069]\n",
      "epoch:38 step:181325[D loss: 0.999985] [G loss: 1.000113]\n",
      "epoch:38 step:181330[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:38 step:181335[D loss: 0.999956] [G loss: 1.000111]\n",
      "epoch:38 step:181340[D loss: 1.000054] [G loss: 1.000004]\n",
      "epoch:38 step:181345[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:38 step:181350[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:38 step:181355[D loss: 1.000044] [G loss: 0.999965]\n",
      "epoch:38 step:181360[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:38 step:181365[D loss: 0.999924] [G loss: 1.000075]\n",
      "epoch:38 step:181370[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:38 step:181375[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:38 step:181380[D loss: 1.000009] [G loss: 1.000054]\n",
      "epoch:38 step:181385[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:38 step:181390[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:38 step:181395[D loss: 1.000035] [G loss: 0.999978]\n",
      "epoch:38 step:181400[D loss: 0.999949] [G loss: 1.000105]\n",
      "##############\n",
      "[2.56735614 2.22909287 2.22517908 3.20726801 1.51913063 6.33805992\n",
      " 2.33135222 3.82928215 3.98704815 6.09559395]\n",
      "##########\n",
      "epoch:38 step:181405[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:38 step:181410[D loss: 0.999990] [G loss: 1.000014]\n",
      "epoch:38 step:181415[D loss: 0.999939] [G loss: 1.000107]\n",
      "epoch:38 step:181420[D loss: 0.999985] [G loss: 1.000121]\n",
      "epoch:38 step:181425[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:38 step:181430[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:38 step:181435[D loss: 1.000000] [G loss: 0.999997]\n",
      "epoch:38 step:181440[D loss: 1.000073] [G loss: 0.999954]\n",
      "epoch:38 step:181445[D loss: 0.999953] [G loss: 1.000093]\n",
      "epoch:38 step:181450[D loss: 0.999933] [G loss: 1.000081]\n",
      "epoch:38 step:181455[D loss: 1.000001] [G loss: 0.999980]\n",
      "epoch:38 step:181460[D loss: 0.999930] [G loss: 1.000129]\n",
      "epoch:38 step:181465[D loss: 0.999957] [G loss: 1.000041]\n",
      "epoch:38 step:181470[D loss: 0.999987] [G loss: 1.000019]\n",
      "epoch:38 step:181475[D loss: 1.000016] [G loss: 1.000160]\n",
      "epoch:38 step:181480[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:38 step:181485[D loss: 0.999947] [G loss: 1.000203]\n",
      "epoch:38 step:181490[D loss: 1.000002] [G loss: 1.000108]\n",
      "epoch:38 step:181495[D loss: 1.000031] [G loss: 1.000064]\n",
      "epoch:38 step:181500[D loss: 0.999921] [G loss: 1.000162]\n",
      "epoch:38 step:181505[D loss: 0.999965] [G loss: 1.000028]\n",
      "epoch:38 step:181510[D loss: 1.000007] [G loss: 1.000000]\n",
      "epoch:38 step:181515[D loss: 0.999948] [G loss: 1.000078]\n",
      "epoch:38 step:181520[D loss: 0.999971] [G loss: 1.000101]\n",
      "epoch:38 step:181525[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:38 step:181530[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:38 step:181535[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:38 step:181540[D loss: 1.000018] [G loss: 0.999973]\n",
      "epoch:38 step:181545[D loss: 0.999980] [G loss: 1.000099]\n",
      "epoch:38 step:181550[D loss: 1.000015] [G loss: 1.000050]\n",
      "epoch:38 step:181555[D loss: 0.999986] [G loss: 1.000140]\n",
      "epoch:38 step:181560[D loss: 0.999960] [G loss: 1.000131]\n",
      "epoch:38 step:181565[D loss: 0.999922] [G loss: 1.000127]\n",
      "epoch:38 step:181570[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:38 step:181575[D loss: 1.000185] [G loss: 0.999737]\n",
      "epoch:38 step:181580[D loss: 1.000084] [G loss: 0.999976]\n",
      "epoch:38 step:181585[D loss: 1.000040] [G loss: 1.000045]\n",
      "epoch:38 step:181590[D loss: 1.000005] [G loss: 0.999851]\n",
      "epoch:38 step:181595[D loss: 1.000073] [G loss: 0.999958]\n",
      "epoch:38 step:181600[D loss: 1.000165] [G loss: 1.000147]\n",
      "##############\n",
      "[2.52920948 2.32322283 2.32499301 3.48413105 1.48767047 6.89620458\n",
      " 2.40841382 3.70727794 3.9394649  5.45259478]\n",
      "##########\n",
      "epoch:38 step:181605[D loss: 1.000133] [G loss: 0.999915]\n",
      "epoch:38 step:181610[D loss: 0.999841] [G loss: 1.000175]\n",
      "epoch:38 step:181615[D loss: 0.999983] [G loss: 1.000017]\n",
      "epoch:38 step:181620[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:38 step:181625[D loss: 1.000040] [G loss: 0.999952]\n",
      "epoch:38 step:181630[D loss: 1.000012] [G loss: 1.000097]\n",
      "epoch:38 step:181635[D loss: 1.000002] [G loss: 1.000050]\n",
      "epoch:38 step:181640[D loss: 0.999979] [G loss: 1.000125]\n",
      "epoch:38 step:181645[D loss: 1.000052] [G loss: 1.000087]\n",
      "epoch:38 step:181650[D loss: 0.999931] [G loss: 1.000103]\n",
      "epoch:38 step:181655[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:38 step:181660[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:38 step:181665[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:38 step:181670[D loss: 1.000060] [G loss: 1.000000]\n",
      "epoch:38 step:181675[D loss: 0.999984] [G loss: 1.000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:181680[D loss: 1.000028] [G loss: 1.000032]\n",
      "epoch:38 step:181685[D loss: 0.999974] [G loss: 0.999996]\n",
      "epoch:38 step:181690[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:38 step:181695[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:38 step:181700[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:38 step:181705[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:38 step:181710[D loss: 1.000015] [G loss: 0.999998]\n",
      "epoch:38 step:181715[D loss: 1.000147] [G loss: 0.999801]\n",
      "epoch:38 step:181720[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:38 step:181725[D loss: 1.000254] [G loss: 0.999843]\n",
      "epoch:38 step:181730[D loss: 0.999968] [G loss: 1.000140]\n",
      "epoch:38 step:181735[D loss: 0.999928] [G loss: 1.000111]\n",
      "epoch:38 step:181740[D loss: 1.000136] [G loss: 0.999843]\n",
      "epoch:38 step:181745[D loss: 0.999870] [G loss: 1.000059]\n",
      "epoch:38 step:181750[D loss: 0.999995] [G loss: 1.000002]\n",
      "epoch:38 step:181755[D loss: 0.999954] [G loss: 1.000059]\n",
      "epoch:38 step:181760[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:38 step:181765[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:38 step:181770[D loss: 1.000006] [G loss: 0.999983]\n",
      "epoch:38 step:181775[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:38 step:181780[D loss: 1.000084] [G loss: 0.999966]\n",
      "epoch:38 step:181785[D loss: 0.999929] [G loss: 1.000092]\n",
      "epoch:38 step:181790[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:38 step:181795[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:38 step:181800[D loss: 1.000075] [G loss: 1.000019]\n",
      "##############\n",
      "[2.54648183 2.27267394 2.30567165 3.57822777 1.46216831 7.07733344\n",
      " 2.22143238 3.45995408 4.06054128 5.35477712]\n",
      "##########\n",
      "epoch:38 step:181805[D loss: 0.999937] [G loss: 1.000155]\n",
      "epoch:38 step:181810[D loss: 0.999937] [G loss: 1.000013]\n",
      "epoch:38 step:181815[D loss: 0.999999] [G loss: 0.999997]\n",
      "epoch:38 step:181820[D loss: 0.999906] [G loss: 1.000095]\n",
      "epoch:38 step:181825[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:38 step:181830[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:38 step:181835[D loss: 0.999930] [G loss: 1.000180]\n",
      "epoch:38 step:181840[D loss: 1.000146] [G loss: 0.999960]\n",
      "epoch:38 step:181845[D loss: 1.000031] [G loss: 0.999937]\n",
      "epoch:38 step:181850[D loss: 1.000006] [G loss: 0.999997]\n",
      "epoch:38 step:181855[D loss: 0.999947] [G loss: 1.000087]\n",
      "epoch:38 step:181860[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:38 step:181865[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:38 step:181870[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:38 step:181875[D loss: 0.999944] [G loss: 1.000081]\n",
      "epoch:38 step:181880[D loss: 0.999958] [G loss: 1.000056]\n",
      "epoch:38 step:181885[D loss: 1.000026] [G loss: 1.000119]\n",
      "epoch:38 step:181890[D loss: 0.999958] [G loss: 1.000114]\n",
      "epoch:38 step:181895[D loss: 0.999891] [G loss: 1.000209]\n",
      "epoch:38 step:181900[D loss: 1.000169] [G loss: 0.999838]\n",
      "epoch:38 step:181905[D loss: 0.999867] [G loss: 1.000097]\n",
      "epoch:38 step:181910[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:38 step:181915[D loss: 0.999923] [G loss: 1.000021]\n",
      "epoch:38 step:181920[D loss: 0.999967] [G loss: 1.000035]\n",
      "epoch:38 step:181925[D loss: 0.999990] [G loss: 0.999981]\n",
      "epoch:38 step:181930[D loss: 0.999818] [G loss: 1.000208]\n",
      "epoch:38 step:181935[D loss: 0.999957] [G loss: 1.000033]\n",
      "epoch:38 step:181940[D loss: 0.999932] [G loss: 1.000083]\n",
      "epoch:38 step:181945[D loss: 1.000019] [G loss: 0.999977]\n",
      "epoch:38 step:181950[D loss: 0.999978] [G loss: 1.000113]\n",
      "epoch:38 step:181955[D loss: 0.999981] [G loss: 1.000099]\n",
      "epoch:38 step:181960[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:38 step:181965[D loss: 1.000004] [G loss: 0.999987]\n",
      "epoch:38 step:181970[D loss: 1.000025] [G loss: 1.000017]\n",
      "epoch:38 step:181975[D loss: 1.000007] [G loss: 1.000192]\n",
      "epoch:38 step:181980[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:38 step:181985[D loss: 0.999995] [G loss: 1.000009]\n",
      "epoch:38 step:181990[D loss: 0.999890] [G loss: 1.000042]\n",
      "epoch:38 step:181995[D loss: 0.999974] [G loss: 0.999968]\n",
      "epoch:38 step:182000[D loss: 1.000072] [G loss: 0.999861]\n",
      "##############\n",
      "[2.53133384 2.33786971 2.29251767 3.47693132 1.49217556 6.70575896\n",
      " 2.24722921 3.69953027 3.90792573 5.48564516]\n",
      "##########\n",
      "epoch:38 step:182005[D loss: 1.000062] [G loss: 0.999998]\n",
      "epoch:38 step:182010[D loss: 0.999874] [G loss: 1.000342]\n",
      "epoch:38 step:182015[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:38 step:182020[D loss: 1.000033] [G loss: 1.000058]\n",
      "epoch:38 step:182025[D loss: 1.000041] [G loss: 0.999939]\n",
      "epoch:38 step:182030[D loss: 0.999906] [G loss: 1.000097]\n",
      "epoch:38 step:182035[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:38 step:182040[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:38 step:182045[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:38 step:182050[D loss: 0.999976] [G loss: 1.000030]\n",
      "epoch:38 step:182055[D loss: 1.000094] [G loss: 0.999926]\n",
      "epoch:38 step:182060[D loss: 1.000020] [G loss: 0.999863]\n",
      "epoch:38 step:182065[D loss: 1.000075] [G loss: 1.000075]\n",
      "epoch:38 step:182070[D loss: 1.000103] [G loss: 1.000111]\n",
      "epoch:38 step:182075[D loss: 0.999823] [G loss: 1.000219]\n",
      "epoch:38 step:182080[D loss: 0.999921] [G loss: 1.000157]\n",
      "epoch:38 step:182085[D loss: 1.000088] [G loss: 0.999848]\n",
      "epoch:38 step:182090[D loss: 1.000019] [G loss: 1.000060]\n",
      "epoch:38 step:182095[D loss: 0.999942] [G loss: 1.000193]\n",
      "epoch:38 step:182100[D loss: 1.000006] [G loss: 1.000014]\n",
      "epoch:38 step:182105[D loss: 1.000041] [G loss: 0.999918]\n",
      "epoch:38 step:182110[D loss: 1.000028] [G loss: 1.000074]\n",
      "epoch:38 step:182115[D loss: 0.999920] [G loss: 1.000114]\n",
      "epoch:38 step:182120[D loss: 1.000013] [G loss: 1.000051]\n",
      "epoch:38 step:182125[D loss: 0.999960] [G loss: 1.000097]\n",
      "epoch:38 step:182130[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:38 step:182135[D loss: 1.000096] [G loss: 0.999871]\n",
      "epoch:38 step:182140[D loss: 1.000105] [G loss: 0.999802]\n",
      "epoch:38 step:182145[D loss: 1.000108] [G loss: 0.999756]\n",
      "epoch:38 step:182150[D loss: 0.999988] [G loss: 0.999963]\n",
      "epoch:38 step:182155[D loss: 1.000035] [G loss: 0.999966]\n",
      "epoch:38 step:182160[D loss: 0.999975] [G loss: 0.999999]\n",
      "epoch:38 step:182165[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:38 step:182170[D loss: 0.999899] [G loss: 1.000188]\n",
      "epoch:38 step:182175[D loss: 0.999953] [G loss: 1.000154]\n",
      "epoch:38 step:182180[D loss: 0.999944] [G loss: 1.000122]\n",
      "epoch:38 step:182185[D loss: 1.000060] [G loss: 0.999953]\n",
      "epoch:38 step:182190[D loss: 1.000004] [G loss: 1.000161]\n",
      "epoch:38 step:182195[D loss: 0.999892] [G loss: 1.000056]\n",
      "epoch:38 step:182200[D loss: 1.000080] [G loss: 1.000226]\n",
      "##############\n",
      "[2.56713052 2.35523281 2.31131678 3.79561687 1.44589267 6.90612792\n",
      " 2.36779876 3.65162011 4.09263596 5.07866628]\n",
      "##########\n",
      "epoch:38 step:182205[D loss: 0.999901] [G loss: 1.000224]\n",
      "epoch:38 step:182210[D loss: 0.999953] [G loss: 1.000092]\n",
      "epoch:38 step:182215[D loss: 0.999985] [G loss: 1.000087]\n",
      "epoch:38 step:182220[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:38 step:182225[D loss: 0.999980] [G loss: 1.000101]\n",
      "epoch:38 step:182230[D loss: 0.999943] [G loss: 1.000088]\n",
      "epoch:38 step:182235[D loss: 1.000070] [G loss: 0.999921]\n",
      "epoch:38 step:182240[D loss: 1.000088] [G loss: 0.999832]\n",
      "epoch:38 step:182245[D loss: 0.999958] [G loss: 1.000189]\n",
      "epoch:38 step:182250[D loss: 1.000145] [G loss: 1.000013]\n",
      "epoch:38 step:182255[D loss: 0.999899] [G loss: 1.000205]\n",
      "epoch:38 step:182260[D loss: 0.999932] [G loss: 1.000158]\n",
      "epoch:38 step:182265[D loss: 0.999872] [G loss: 1.000268]\n",
      "epoch:38 step:182270[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:38 step:182275[D loss: 0.999931] [G loss: 1.000249]\n",
      "epoch:38 step:182280[D loss: 0.999924] [G loss: 1.000123]\n",
      "epoch:38 step:182285[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:38 step:182290[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:38 step:182295[D loss: 0.999966] [G loss: 1.000026]\n",
      "epoch:38 step:182300[D loss: 0.999892] [G loss: 1.000086]\n",
      "epoch:38 step:182305[D loss: 0.999980] [G loss: 1.000001]\n",
      "epoch:38 step:182310[D loss: 1.000171] [G loss: 1.000100]\n",
      "epoch:38 step:182315[D loss: 0.999933] [G loss: 1.000137]\n",
      "epoch:38 step:182320[D loss: 1.000053] [G loss: 1.000049]\n",
      "epoch:38 step:182325[D loss: 1.000099] [G loss: 0.999920]\n",
      "epoch:38 step:182330[D loss: 0.999929] [G loss: 1.000051]\n",
      "epoch:38 step:182335[D loss: 0.999898] [G loss: 1.000134]\n",
      "epoch:38 step:182340[D loss: 1.000009] [G loss: 1.000031]\n",
      "epoch:38 step:182345[D loss: 1.000013] [G loss: 1.000024]\n",
      "epoch:38 step:182350[D loss: 1.000008] [G loss: 1.000030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:182355[D loss: 1.000053] [G loss: 1.000029]\n",
      "epoch:38 step:182360[D loss: 0.999935] [G loss: 1.000124]\n",
      "epoch:38 step:182365[D loss: 1.000067] [G loss: 1.000046]\n",
      "epoch:38 step:182370[D loss: 0.999906] [G loss: 1.000262]\n",
      "epoch:38 step:182375[D loss: 0.999922] [G loss: 1.000214]\n",
      "epoch:38 step:182380[D loss: 1.000029] [G loss: 1.000212]\n",
      "epoch:38 step:182385[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:38 step:182390[D loss: 1.000001] [G loss: 1.000083]\n",
      "epoch:38 step:182395[D loss: 1.000020] [G loss: 1.000096]\n",
      "epoch:38 step:182400[D loss: 0.999973] [G loss: 1.000081]\n",
      "##############\n",
      "[2.65140751 2.32009436 2.2469022  3.75173279 1.63734518 6.50686597\n",
      " 2.37355037 3.80781235 4.05611537 5.79330756]\n",
      "##########\n",
      "epoch:38 step:182405[D loss: 0.999943] [G loss: 1.000121]\n",
      "epoch:38 step:182410[D loss: 1.000009] [G loss: 0.999992]\n",
      "epoch:38 step:182415[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:38 step:182420[D loss: 1.000036] [G loss: 1.000015]\n",
      "epoch:38 step:182425[D loss: 0.999914] [G loss: 1.000115]\n",
      "epoch:38 step:182430[D loss: 1.000041] [G loss: 1.000112]\n",
      "epoch:38 step:182435[D loss: 0.999949] [G loss: 1.000044]\n",
      "epoch:38 step:182440[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:38 step:182445[D loss: 0.999922] [G loss: 1.000172]\n",
      "epoch:38 step:182450[D loss: 0.999915] [G loss: 1.000109]\n",
      "epoch:38 step:182455[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:38 step:182460[D loss: 0.999972] [G loss: 0.999985]\n",
      "epoch:38 step:182465[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:38 step:182470[D loss: 0.999953] [G loss: 1.000123]\n",
      "epoch:38 step:182475[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:38 step:182480[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:38 step:182485[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:38 step:182490[D loss: 0.999973] [G loss: 1.000100]\n",
      "epoch:38 step:182495[D loss: 1.000039] [G loss: 1.000035]\n",
      "epoch:38 step:182500[D loss: 1.000002] [G loss: 1.000094]\n",
      "epoch:38 step:182505[D loss: 0.999928] [G loss: 1.000098]\n",
      "epoch:38 step:182510[D loss: 1.000105] [G loss: 0.999925]\n",
      "epoch:38 step:182515[D loss: 1.000076] [G loss: 0.999717]\n",
      "epoch:38 step:182520[D loss: 0.999959] [G loss: 1.000015]\n",
      "epoch:38 step:182525[D loss: 0.999889] [G loss: 1.000123]\n",
      "epoch:38 step:182530[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:38 step:182535[D loss: 1.000026] [G loss: 0.999985]\n",
      "epoch:38 step:182540[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:38 step:182545[D loss: 0.999987] [G loss: 0.999985]\n",
      "epoch:38 step:182550[D loss: 1.000167] [G loss: 0.999826]\n",
      "epoch:38 step:182555[D loss: 1.000001] [G loss: 1.000073]\n",
      "epoch:38 step:182560[D loss: 1.000043] [G loss: 1.000162]\n",
      "epoch:38 step:182565[D loss: 0.999935] [G loss: 1.000076]\n",
      "epoch:38 step:182570[D loss: 1.000002] [G loss: 1.000146]\n",
      "epoch:38 step:182575[D loss: 1.000097] [G loss: 0.999877]\n",
      "epoch:38 step:182580[D loss: 0.999965] [G loss: 1.000039]\n",
      "epoch:38 step:182585[D loss: 0.999943] [G loss: 1.000074]\n",
      "epoch:38 step:182590[D loss: 1.000020] [G loss: 0.999915]\n",
      "epoch:38 step:182595[D loss: 0.999988] [G loss: 1.000018]\n",
      "epoch:38 step:182600[D loss: 1.000011] [G loss: 1.000113]\n",
      "##############\n",
      "[2.55509216 2.29719992 2.24496329 3.87199321 1.52545565 6.31879327\n",
      " 2.23172816 3.6916934  4.08135951 7.14868929]\n",
      "##########\n",
      "epoch:38 step:182605[D loss: 1.000050] [G loss: 1.000027]\n",
      "epoch:38 step:182610[D loss: 0.999881] [G loss: 1.000168]\n",
      "epoch:38 step:182615[D loss: 1.000167] [G loss: 1.000007]\n",
      "epoch:38 step:182620[D loss: 0.999933] [G loss: 1.000105]\n",
      "epoch:38 step:182625[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:38 step:182630[D loss: 1.000035] [G loss: 0.999896]\n",
      "epoch:38 step:182635[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:38 step:182640[D loss: 1.000042] [G loss: 0.999945]\n",
      "epoch:38 step:182645[D loss: 0.999946] [G loss: 1.000035]\n",
      "epoch:38 step:182650[D loss: 0.999941] [G loss: 1.000011]\n",
      "epoch:38 step:182655[D loss: 0.999978] [G loss: 1.000118]\n",
      "epoch:38 step:182660[D loss: 1.000013] [G loss: 1.000078]\n",
      "epoch:38 step:182665[D loss: 1.000001] [G loss: 1.000015]\n",
      "epoch:38 step:182670[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:38 step:182675[D loss: 0.999932] [G loss: 1.000055]\n",
      "epoch:38 step:182680[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:38 step:182685[D loss: 1.000031] [G loss: 0.999977]\n",
      "epoch:38 step:182690[D loss: 0.999942] [G loss: 1.000123]\n",
      "epoch:38 step:182695[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:38 step:182700[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:38 step:182705[D loss: 1.000047] [G loss: 1.000117]\n",
      "epoch:38 step:182710[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:38 step:182715[D loss: 0.999951] [G loss: 1.000070]\n",
      "epoch:39 step:182720[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:39 step:182725[D loss: 1.000027] [G loss: 0.999963]\n",
      "epoch:39 step:182730[D loss: 1.000006] [G loss: 0.999984]\n",
      "epoch:39 step:182735[D loss: 1.000008] [G loss: 1.000051]\n",
      "epoch:39 step:182740[D loss: 0.999923] [G loss: 1.000114]\n",
      "epoch:39 step:182745[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:39 step:182750[D loss: 0.999948] [G loss: 1.000077]\n",
      "epoch:39 step:182755[D loss: 0.999944] [G loss: 1.000075]\n",
      "epoch:39 step:182760[D loss: 1.000051] [G loss: 0.999922]\n",
      "epoch:39 step:182765[D loss: 1.000108] [G loss: 0.999953]\n",
      "epoch:39 step:182770[D loss: 1.000023] [G loss: 1.000045]\n",
      "epoch:39 step:182775[D loss: 0.999898] [G loss: 1.000078]\n",
      "epoch:39 step:182780[D loss: 1.000003] [G loss: 1.000025]\n",
      "epoch:39 step:182785[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:39 step:182790[D loss: 0.999974] [G loss: 1.000129]\n",
      "epoch:39 step:182795[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:39 step:182800[D loss: 0.999954] [G loss: 1.000086]\n",
      "##############\n",
      "[2.55865707 2.35283381 2.36759942 3.80784076 1.52403964 8.043123\n",
      " 2.26922679 3.8365     4.10253846 5.35568515]\n",
      "##########\n",
      "epoch:39 step:182805[D loss: 1.000007] [G loss: 1.000010]\n",
      "epoch:39 step:182810[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:39 step:182815[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:39 step:182820[D loss: 0.999964] [G loss: 1.000112]\n",
      "epoch:39 step:182825[D loss: 1.000067] [G loss: 1.000048]\n",
      "epoch:39 step:182830[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:39 step:182835[D loss: 0.999961] [G loss: 1.000133]\n",
      "epoch:39 step:182840[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:39 step:182845[D loss: 0.999962] [G loss: 1.000106]\n",
      "epoch:39 step:182850[D loss: 0.999987] [G loss: 1.000184]\n",
      "epoch:39 step:182855[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:39 step:182860[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:39 step:182865[D loss: 1.000045] [G loss: 1.000001]\n",
      "epoch:39 step:182870[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:39 step:182875[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:39 step:182880[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:39 step:182885[D loss: 1.000002] [G loss: 1.000073]\n",
      "epoch:39 step:182890[D loss: 0.999964] [G loss: 1.000147]\n",
      "epoch:39 step:182895[D loss: 0.999998] [G loss: 1.000144]\n",
      "epoch:39 step:182900[D loss: 0.999960] [G loss: 1.000144]\n",
      "epoch:39 step:182905[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:39 step:182910[D loss: 1.000033] [G loss: 0.999948]\n",
      "epoch:39 step:182915[D loss: 1.000120] [G loss: 0.999898]\n",
      "epoch:39 step:182920[D loss: 1.000019] [G loss: 0.999924]\n",
      "epoch:39 step:182925[D loss: 0.999951] [G loss: 1.000120]\n",
      "epoch:39 step:182930[D loss: 0.999914] [G loss: 1.000115]\n",
      "epoch:39 step:182935[D loss: 0.999946] [G loss: 1.000026]\n",
      "epoch:39 step:182940[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:39 step:182945[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:39 step:182950[D loss: 0.999936] [G loss: 1.000117]\n",
      "epoch:39 step:182955[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:39 step:182960[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:39 step:182965[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:39 step:182970[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:39 step:182975[D loss: 0.999999] [G loss: 1.000116]\n",
      "epoch:39 step:182980[D loss: 1.000050] [G loss: 1.000044]\n",
      "epoch:39 step:182985[D loss: 1.000041] [G loss: 1.000008]\n",
      "epoch:39 step:182990[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:39 step:182995[D loss: 1.000041] [G loss: 0.999927]\n",
      "epoch:39 step:183000[D loss: 0.999912] [G loss: 1.000091]\n",
      "##############\n",
      "[2.65140053 2.28434656 2.25330908 3.73659405 1.61123179 6.81419626\n",
      " 2.30884514 3.57419886 4.09625122 5.98408839]\n",
      "##########\n",
      "epoch:39 step:183005[D loss: 0.999946] [G loss: 1.000106]\n",
      "epoch:39 step:183010[D loss: 0.999942] [G loss: 1.000092]\n",
      "epoch:39 step:183015[D loss: 0.999992] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:183020[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:39 step:183025[D loss: 0.999985] [G loss: 1.000111]\n",
      "epoch:39 step:183030[D loss: 1.000028] [G loss: 1.000039]\n",
      "epoch:39 step:183035[D loss: 1.000042] [G loss: 1.000030]\n",
      "epoch:39 step:183040[D loss: 1.000032] [G loss: 0.999941]\n",
      "epoch:39 step:183045[D loss: 1.000248] [G loss: 0.999626]\n",
      "epoch:39 step:183050[D loss: 1.000008] [G loss: 0.999956]\n",
      "epoch:39 step:183055[D loss: 1.000050] [G loss: 0.999957]\n",
      "epoch:39 step:183060[D loss: 1.000162] [G loss: 1.000161]\n",
      "epoch:39 step:183065[D loss: 0.999957] [G loss: 1.000148]\n",
      "epoch:39 step:183070[D loss: 0.999953] [G loss: 1.000206]\n",
      "epoch:39 step:183075[D loss: 0.999899] [G loss: 1.000396]\n",
      "epoch:39 step:183080[D loss: 0.999807] [G loss: 1.000263]\n",
      "epoch:39 step:183085[D loss: 0.999930] [G loss: 1.000057]\n",
      "epoch:39 step:183090[D loss: 1.000046] [G loss: 0.999971]\n",
      "epoch:39 step:183095[D loss: 1.000003] [G loss: 0.999933]\n",
      "epoch:39 step:183100[D loss: 0.999994] [G loss: 0.999987]\n",
      "epoch:39 step:183105[D loss: 0.999913] [G loss: 1.000116]\n",
      "epoch:39 step:183110[D loss: 1.000097] [G loss: 0.999929]\n",
      "epoch:39 step:183115[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:39 step:183120[D loss: 1.000134] [G loss: 0.999963]\n",
      "epoch:39 step:183125[D loss: 0.999883] [G loss: 1.000172]\n",
      "epoch:39 step:183130[D loss: 0.999908] [G loss: 1.000166]\n",
      "epoch:39 step:183135[D loss: 0.999937] [G loss: 1.000079]\n",
      "epoch:39 step:183140[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:39 step:183145[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:39 step:183150[D loss: 1.000021] [G loss: 1.000043]\n",
      "epoch:39 step:183155[D loss: 0.999937] [G loss: 1.000152]\n",
      "epoch:39 step:183160[D loss: 1.000045] [G loss: 1.000109]\n",
      "epoch:39 step:183165[D loss: 1.000073] [G loss: 0.999891]\n",
      "epoch:39 step:183170[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:39 step:183175[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:39 step:183180[D loss: 0.999951] [G loss: 1.000102]\n",
      "epoch:39 step:183185[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:39 step:183190[D loss: 1.000165] [G loss: 1.000052]\n",
      "epoch:39 step:183195[D loss: 1.000121] [G loss: 1.000007]\n",
      "epoch:39 step:183200[D loss: 1.000162] [G loss: 0.999942]\n",
      "##############\n",
      "[2.62753527 2.36153824 2.31605273 3.2602572  1.657825   6.71525825\n",
      " 2.20459897 3.80360323 4.07684526 4.21381563]\n",
      "##########\n",
      "epoch:39 step:183205[D loss: 0.999814] [G loss: 1.000481]\n",
      "epoch:39 step:183210[D loss: 0.999919] [G loss: 1.000212]\n",
      "epoch:39 step:183215[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:39 step:183220[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:39 step:183225[D loss: 0.999965] [G loss: 1.000032]\n",
      "epoch:39 step:183230[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:39 step:183235[D loss: 1.000046] [G loss: 0.999912]\n",
      "epoch:39 step:183240[D loss: 1.000034] [G loss: 0.999964]\n",
      "epoch:39 step:183245[D loss: 1.000080] [G loss: 0.999747]\n",
      "epoch:39 step:183250[D loss: 1.000034] [G loss: 1.000154]\n",
      "epoch:39 step:183255[D loss: 1.000008] [G loss: 1.000099]\n",
      "epoch:39 step:183260[D loss: 0.999846] [G loss: 1.000137]\n",
      "epoch:39 step:183265[D loss: 1.000072] [G loss: 1.000006]\n",
      "epoch:39 step:183270[D loss: 0.999947] [G loss: 1.000152]\n",
      "epoch:39 step:183275[D loss: 0.999885] [G loss: 1.000218]\n",
      "epoch:39 step:183280[D loss: 1.000011] [G loss: 1.000089]\n",
      "epoch:39 step:183285[D loss: 0.999970] [G loss: 1.000106]\n",
      "epoch:39 step:183290[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:39 step:183295[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:39 step:183300[D loss: 1.000273] [G loss: 0.999721]\n",
      "epoch:39 step:183305[D loss: 1.000091] [G loss: 1.000050]\n",
      "epoch:39 step:183310[D loss: 1.000037] [G loss: 1.000087]\n",
      "epoch:39 step:183315[D loss: 1.000003] [G loss: 0.999927]\n",
      "epoch:39 step:183320[D loss: 1.000033] [G loss: 1.000222]\n",
      "epoch:39 step:183325[D loss: 0.999936] [G loss: 1.000300]\n",
      "epoch:39 step:183330[D loss: 1.000007] [G loss: 1.000100]\n",
      "epoch:39 step:183335[D loss: 0.999981] [G loss: 1.000145]\n",
      "epoch:39 step:183340[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:39 step:183345[D loss: 0.999993] [G loss: 1.000109]\n",
      "epoch:39 step:183350[D loss: 1.000002] [G loss: 0.999989]\n",
      "epoch:39 step:183355[D loss: 1.000051] [G loss: 0.999925]\n",
      "epoch:39 step:183360[D loss: 1.000038] [G loss: 1.000031]\n",
      "epoch:39 step:183365[D loss: 0.999798] [G loss: 1.000265]\n",
      "epoch:39 step:183370[D loss: 0.999898] [G loss: 1.000139]\n",
      "epoch:39 step:183375[D loss: 1.000076] [G loss: 1.000043]\n",
      "epoch:39 step:183380[D loss: 1.000087] [G loss: 0.999910]\n",
      "epoch:39 step:183385[D loss: 0.999915] [G loss: 1.000196]\n",
      "epoch:39 step:183390[D loss: 1.000011] [G loss: 0.999990]\n",
      "epoch:39 step:183395[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:39 step:183400[D loss: 1.000024] [G loss: 1.000018]\n",
      "##############\n",
      "[2.58327094 2.33158011 2.33967718 4.36656027 1.60003941 7.05738682\n",
      " 2.38505582 3.64332413 4.13798317 5.09749254]\n",
      "##########\n",
      "epoch:39 step:183405[D loss: 0.999932] [G loss: 1.000098]\n",
      "epoch:39 step:183410[D loss: 0.999967] [G loss: 1.000116]\n",
      "epoch:39 step:183415[D loss: 0.999973] [G loss: 1.000122]\n",
      "epoch:39 step:183420[D loss: 1.000042] [G loss: 1.000048]\n",
      "epoch:39 step:183425[D loss: 0.999948] [G loss: 1.000145]\n",
      "epoch:39 step:183430[D loss: 1.000006] [G loss: 1.000080]\n",
      "epoch:39 step:183435[D loss: 0.999926] [G loss: 1.000162]\n",
      "epoch:39 step:183440[D loss: 1.000083] [G loss: 0.999990]\n",
      "epoch:39 step:183445[D loss: 0.999938] [G loss: 1.000124]\n",
      "epoch:39 step:183450[D loss: 1.000060] [G loss: 1.000037]\n",
      "epoch:39 step:183455[D loss: 0.999869] [G loss: 1.000188]\n",
      "epoch:39 step:183460[D loss: 1.000004] [G loss: 0.999970]\n",
      "epoch:39 step:183465[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:39 step:183470[D loss: 1.000000] [G loss: 0.999984]\n",
      "epoch:39 step:183475[D loss: 1.000011] [G loss: 0.999945]\n",
      "epoch:39 step:183480[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:39 step:183485[D loss: 0.999987] [G loss: 0.999940]\n",
      "epoch:39 step:183490[D loss: 0.999934] [G loss: 1.000049]\n",
      "epoch:39 step:183495[D loss: 1.000067] [G loss: 0.999945]\n",
      "epoch:39 step:183500[D loss: 0.999934] [G loss: 1.000068]\n",
      "epoch:39 step:183505[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:39 step:183510[D loss: 0.999992] [G loss: 0.999996]\n",
      "epoch:39 step:183515[D loss: 1.000009] [G loss: 1.000050]\n",
      "epoch:39 step:183520[D loss: 1.000071] [G loss: 0.999987]\n",
      "epoch:39 step:183525[D loss: 1.000003] [G loss: 1.000033]\n",
      "epoch:39 step:183530[D loss: 0.999918] [G loss: 1.000079]\n",
      "epoch:39 step:183535[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:39 step:183540[D loss: 1.000070] [G loss: 0.999951]\n",
      "epoch:39 step:183545[D loss: 1.000065] [G loss: 0.999924]\n",
      "epoch:39 step:183550[D loss: 0.999952] [G loss: 1.000029]\n",
      "epoch:39 step:183555[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:39 step:183560[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:39 step:183565[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:39 step:183570[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:39 step:183575[D loss: 0.999957] [G loss: 1.000043]\n",
      "epoch:39 step:183580[D loss: 1.000043] [G loss: 0.999946]\n",
      "epoch:39 step:183585[D loss: 0.999916] [G loss: 1.000112]\n",
      "epoch:39 step:183590[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:39 step:183595[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:39 step:183600[D loss: 0.999974] [G loss: 1.000077]\n",
      "##############\n",
      "[2.60209348 2.29223061 2.4047969  3.27654622 1.58098536 6.70053042\n",
      " 2.18106069 3.56445266 4.02971212 5.05044588]\n",
      "##########\n",
      "epoch:39 step:183605[D loss: 1.000018] [G loss: 1.000036]\n",
      "epoch:39 step:183610[D loss: 1.000001] [G loss: 1.000064]\n",
      "epoch:39 step:183615[D loss: 0.999873] [G loss: 1.000125]\n",
      "epoch:39 step:183620[D loss: 1.000031] [G loss: 1.000066]\n",
      "epoch:39 step:183625[D loss: 0.999925] [G loss: 1.000181]\n",
      "epoch:39 step:183630[D loss: 0.999955] [G loss: 1.000154]\n",
      "epoch:39 step:183635[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:39 step:183640[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:39 step:183645[D loss: 1.000010] [G loss: 1.000010]\n",
      "epoch:39 step:183650[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:39 step:183655[D loss: 1.000081] [G loss: 0.999942]\n",
      "epoch:39 step:183660[D loss: 0.999891] [G loss: 1.000058]\n",
      "epoch:39 step:183665[D loss: 0.999909] [G loss: 1.000114]\n",
      "epoch:39 step:183670[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:39 step:183675[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:39 step:183680[D loss: 1.000013] [G loss: 1.000063]\n",
      "epoch:39 step:183685[D loss: 1.000014] [G loss: 1.000030]\n",
      "epoch:39 step:183690[D loss: 1.000026] [G loss: 0.999984]\n",
      "epoch:39 step:183695[D loss: 1.000007] [G loss: 1.000013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:183700[D loss: 1.000084] [G loss: 1.000020]\n",
      "epoch:39 step:183705[D loss: 1.000251] [G loss: 0.999897]\n",
      "epoch:39 step:183710[D loss: 0.999998] [G loss: 1.000188]\n",
      "epoch:39 step:183715[D loss: 1.000059] [G loss: 1.000230]\n",
      "epoch:39 step:183720[D loss: 0.999853] [G loss: 1.000305]\n",
      "epoch:39 step:183725[D loss: 0.999941] [G loss: 1.000140]\n",
      "epoch:39 step:183730[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:39 step:183735[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:39 step:183740[D loss: 1.000018] [G loss: 1.000014]\n",
      "epoch:39 step:183745[D loss: 1.000026] [G loss: 0.999962]\n",
      "epoch:39 step:183750[D loss: 1.000183] [G loss: 0.999678]\n",
      "epoch:39 step:183755[D loss: 0.999916] [G loss: 0.999899]\n",
      "epoch:39 step:183760[D loss: 1.000186] [G loss: 0.999820]\n",
      "epoch:39 step:183765[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:39 step:183770[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:39 step:183775[D loss: 0.999929] [G loss: 1.000059]\n",
      "epoch:39 step:183780[D loss: 1.000044] [G loss: 0.999995]\n",
      "epoch:39 step:183785[D loss: 1.000087] [G loss: 0.999971]\n",
      "epoch:39 step:183790[D loss: 1.000051] [G loss: 1.000070]\n",
      "epoch:39 step:183795[D loss: 0.999966] [G loss: 1.000265]\n",
      "epoch:39 step:183800[D loss: 1.000225] [G loss: 1.000233]\n",
      "##############\n",
      "[2.60549774 2.39853198 2.40991638 3.88013848 1.51368727 7.56106687\n",
      " 2.24654616 3.92362418 4.11152935 5.56373937]\n",
      "##########\n",
      "epoch:39 step:183805[D loss: 0.999814] [G loss: 1.000354]\n",
      "epoch:39 step:183810[D loss: 0.999938] [G loss: 1.000128]\n",
      "epoch:39 step:183815[D loss: 0.999941] [G loss: 1.000163]\n",
      "epoch:39 step:183820[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:39 step:183825[D loss: 1.000043] [G loss: 1.000007]\n",
      "epoch:39 step:183830[D loss: 1.000189] [G loss: 0.999817]\n",
      "epoch:39 step:183835[D loss: 0.999819] [G loss: 1.000164]\n",
      "epoch:39 step:183840[D loss: 1.000111] [G loss: 0.999965]\n",
      "epoch:39 step:183845[D loss: 1.000120] [G loss: 1.000121]\n",
      "epoch:39 step:183850[D loss: 1.000413] [G loss: 0.999753]\n",
      "epoch:39 step:183855[D loss: 0.999706] [G loss: 1.000392]\n",
      "epoch:39 step:183860[D loss: 0.999878] [G loss: 1.000195]\n",
      "epoch:39 step:183865[D loss: 0.999911] [G loss: 1.000418]\n",
      "epoch:39 step:183870[D loss: 0.999926] [G loss: 1.000244]\n",
      "epoch:39 step:183875[D loss: 0.999901] [G loss: 1.000267]\n",
      "epoch:39 step:183880[D loss: 1.000063] [G loss: 1.000139]\n",
      "epoch:39 step:183885[D loss: 0.999964] [G loss: 1.000290]\n",
      "epoch:39 step:183890[D loss: 0.999947] [G loss: 1.000306]\n",
      "epoch:39 step:183895[D loss: 0.999892] [G loss: 1.000212]\n",
      "epoch:39 step:183900[D loss: 1.000057] [G loss: 1.000037]\n",
      "epoch:39 step:183905[D loss: 1.000015] [G loss: 0.999805]\n",
      "epoch:39 step:183910[D loss: 1.000051] [G loss: 0.999861]\n",
      "epoch:39 step:183915[D loss: 1.000093] [G loss: 0.999838]\n",
      "epoch:39 step:183920[D loss: 1.000339] [G loss: 0.999612]\n",
      "epoch:39 step:183925[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:39 step:183930[D loss: 0.999834] [G loss: 1.000233]\n",
      "epoch:39 step:183935[D loss: 0.999891] [G loss: 1.000423]\n",
      "epoch:39 step:183940[D loss: 1.000022] [G loss: 0.999986]\n",
      "epoch:39 step:183945[D loss: 1.000093] [G loss: 0.999958]\n",
      "epoch:39 step:183950[D loss: 0.999729] [G loss: 1.000264]\n",
      "epoch:39 step:183955[D loss: 1.000019] [G loss: 1.000103]\n",
      "epoch:39 step:183960[D loss: 1.000010] [G loss: 1.000040]\n",
      "epoch:39 step:183965[D loss: 0.999983] [G loss: 1.000102]\n",
      "epoch:39 step:183970[D loss: 1.000004] [G loss: 0.999968]\n",
      "epoch:39 step:183975[D loss: 1.000007] [G loss: 1.000033]\n",
      "epoch:39 step:183980[D loss: 1.000045] [G loss: 0.999873]\n",
      "epoch:39 step:183985[D loss: 0.999980] [G loss: 1.000112]\n",
      "epoch:39 step:183990[D loss: 0.999902] [G loss: 1.000214]\n",
      "epoch:39 step:183995[D loss: 0.999906] [G loss: 1.000143]\n",
      "epoch:39 step:184000[D loss: 0.999933] [G loss: 1.000157]\n",
      "##############\n",
      "[2.62952623 2.31644071 2.41171968 3.63715616 1.5838971  7.34007501\n",
      " 2.29931747 3.54834351 4.08843536 5.904871  ]\n",
      "##########\n",
      "epoch:39 step:184005[D loss: 1.000258] [G loss: 0.999947]\n",
      "epoch:39 step:184010[D loss: 0.999944] [G loss: 1.000118]\n",
      "epoch:39 step:184015[D loss: 0.999900] [G loss: 1.000240]\n",
      "epoch:39 step:184020[D loss: 0.999920] [G loss: 1.000215]\n",
      "epoch:39 step:184025[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:39 step:184030[D loss: 1.000216] [G loss: 0.999733]\n",
      "epoch:39 step:184035[D loss: 1.000011] [G loss: 0.999962]\n",
      "epoch:39 step:184040[D loss: 0.999897] [G loss: 1.000096]\n",
      "epoch:39 step:184045[D loss: 1.000083] [G loss: 1.000069]\n",
      "epoch:39 step:184050[D loss: 0.999921] [G loss: 1.000054]\n",
      "epoch:39 step:184055[D loss: 1.000011] [G loss: 0.999919]\n",
      "epoch:39 step:184060[D loss: 0.999989] [G loss: 1.000088]\n",
      "epoch:39 step:184065[D loss: 1.000003] [G loss: 1.000118]\n",
      "epoch:39 step:184070[D loss: 0.999950] [G loss: 1.000090]\n",
      "epoch:39 step:184075[D loss: 1.000042] [G loss: 1.000122]\n",
      "epoch:39 step:184080[D loss: 0.999937] [G loss: 1.000135]\n",
      "epoch:39 step:184085[D loss: 0.999940] [G loss: 1.000181]\n",
      "epoch:39 step:184090[D loss: 1.000053] [G loss: 0.999962]\n",
      "epoch:39 step:184095[D loss: 1.000056] [G loss: 1.000006]\n",
      "epoch:39 step:184100[D loss: 0.999983] [G loss: 0.999990]\n",
      "epoch:39 step:184105[D loss: 1.000111] [G loss: 0.999961]\n",
      "epoch:39 step:184110[D loss: 0.999911] [G loss: 1.000171]\n",
      "epoch:39 step:184115[D loss: 0.999842] [G loss: 1.000290]\n",
      "epoch:39 step:184120[D loss: 0.999959] [G loss: 1.000124]\n",
      "epoch:39 step:184125[D loss: 0.999970] [G loss: 1.000109]\n",
      "epoch:39 step:184130[D loss: 0.999948] [G loss: 1.000120]\n",
      "epoch:39 step:184135[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:39 step:184140[D loss: 1.000015] [G loss: 1.000036]\n",
      "epoch:39 step:184145[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:39 step:184150[D loss: 1.000016] [G loss: 1.000056]\n",
      "epoch:39 step:184155[D loss: 1.000041] [G loss: 1.000104]\n",
      "epoch:39 step:184160[D loss: 0.999947] [G loss: 1.000075]\n",
      "epoch:39 step:184165[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:39 step:184170[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:39 step:184175[D loss: 0.999998] [G loss: 1.000000]\n",
      "epoch:39 step:184180[D loss: 1.000037] [G loss: 0.999975]\n",
      "epoch:39 step:184185[D loss: 0.999943] [G loss: 1.000118]\n",
      "epoch:39 step:184190[D loss: 0.999983] [G loss: 1.000111]\n",
      "epoch:39 step:184195[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:39 step:184200[D loss: 0.999958] [G loss: 1.000128]\n",
      "##############\n",
      "[2.52425546 2.27525784 2.29327711 3.32244083 1.46297658 6.56480552\n",
      " 2.05946697 3.66433705 3.88151323 5.34873519]\n",
      "##########\n",
      "epoch:39 step:184205[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:39 step:184210[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:39 step:184215[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:39 step:184220[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:39 step:184225[D loss: 1.000005] [G loss: 1.000027]\n",
      "epoch:39 step:184230[D loss: 1.000022] [G loss: 1.000075]\n",
      "epoch:39 step:184235[D loss: 0.999921] [G loss: 1.000075]\n",
      "epoch:39 step:184240[D loss: 1.000008] [G loss: 1.000016]\n",
      "epoch:39 step:184245[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:39 step:184250[D loss: 0.999994] [G loss: 1.000085]\n",
      "epoch:39 step:184255[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:39 step:184260[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:39 step:184265[D loss: 1.000058] [G loss: 1.000036]\n",
      "epoch:39 step:184270[D loss: 1.000061] [G loss: 1.000063]\n",
      "epoch:39 step:184275[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:39 step:184280[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:39 step:184285[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:39 step:184290[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:39 step:184295[D loss: 0.999979] [G loss: 1.000105]\n",
      "epoch:39 step:184300[D loss: 1.000070] [G loss: 0.999980]\n",
      "epoch:39 step:184305[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:39 step:184310[D loss: 1.000026] [G loss: 0.999993]\n",
      "epoch:39 step:184315[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:39 step:184320[D loss: 1.000247] [G loss: 0.999796]\n",
      "epoch:39 step:184325[D loss: 0.999981] [G loss: 1.000115]\n",
      "epoch:39 step:184330[D loss: 1.000004] [G loss: 1.000075]\n",
      "epoch:39 step:184335[D loss: 0.999940] [G loss: 1.000098]\n",
      "epoch:39 step:184340[D loss: 0.999929] [G loss: 1.000052]\n",
      "epoch:39 step:184345[D loss: 1.000060] [G loss: 0.999983]\n",
      "epoch:39 step:184350[D loss: 1.000061] [G loss: 0.999928]\n",
      "epoch:39 step:184355[D loss: 0.999934] [G loss: 1.000001]\n",
      "epoch:39 step:184360[D loss: 1.000077] [G loss: 1.000052]\n",
      "epoch:39 step:184365[D loss: 0.999913] [G loss: 1.000261]\n",
      "epoch:39 step:184370[D loss: 0.999856] [G loss: 1.000143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:184375[D loss: 0.999900] [G loss: 1.000308]\n",
      "epoch:39 step:184380[D loss: 0.999913] [G loss: 1.000261]\n",
      "epoch:39 step:184385[D loss: 0.999989] [G loss: 1.000012]\n",
      "epoch:39 step:184390[D loss: 0.999940] [G loss: 1.000087]\n",
      "epoch:39 step:184395[D loss: 1.000097] [G loss: 0.999930]\n",
      "epoch:39 step:184400[D loss: 1.000052] [G loss: 0.999885]\n",
      "##############\n",
      "[2.56900616 2.33057439 2.27479883 3.5988541  1.56660881 6.95091946\n",
      " 2.13442934 3.72222162 3.95243739 4.79967577]\n",
      "##########\n",
      "epoch:39 step:184405[D loss: 1.000022] [G loss: 0.999789]\n",
      "epoch:39 step:184410[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:39 step:184415[D loss: 0.999935] [G loss: 1.000068]\n",
      "epoch:39 step:184420[D loss: 0.999946] [G loss: 1.000123]\n",
      "epoch:39 step:184425[D loss: 0.999997] [G loss: 0.999992]\n",
      "epoch:39 step:184430[D loss: 0.999949] [G loss: 1.000115]\n",
      "epoch:39 step:184435[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:39 step:184440[D loss: 0.999975] [G loss: 1.000126]\n",
      "epoch:39 step:184445[D loss: 1.000050] [G loss: 1.000013]\n",
      "epoch:39 step:184450[D loss: 0.999936] [G loss: 1.000091]\n",
      "epoch:39 step:184455[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:39 step:184460[D loss: 1.000011] [G loss: 1.000137]\n",
      "epoch:39 step:184465[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:39 step:184470[D loss: 1.000007] [G loss: 1.000127]\n",
      "epoch:39 step:184475[D loss: 1.000080] [G loss: 0.999963]\n",
      "epoch:39 step:184480[D loss: 0.999936] [G loss: 1.000158]\n",
      "epoch:39 step:184485[D loss: 0.999919] [G loss: 1.000171]\n",
      "epoch:39 step:184490[D loss: 0.999996] [G loss: 0.999971]\n",
      "epoch:39 step:184495[D loss: 1.000000] [G loss: 0.999933]\n",
      "epoch:39 step:184500[D loss: 0.999960] [G loss: 1.000038]\n",
      "epoch:39 step:184505[D loss: 1.000211] [G loss: 0.999800]\n",
      "epoch:39 step:184510[D loss: 0.999960] [G loss: 0.999944]\n",
      "epoch:39 step:184515[D loss: 1.000103] [G loss: 0.999910]\n",
      "epoch:39 step:184520[D loss: 0.999942] [G loss: 1.000119]\n",
      "epoch:39 step:184525[D loss: 0.999905] [G loss: 1.000119]\n",
      "epoch:39 step:184530[D loss: 0.999947] [G loss: 1.000090]\n",
      "epoch:39 step:184535[D loss: 0.999988] [G loss: 1.000118]\n",
      "epoch:39 step:184540[D loss: 1.000082] [G loss: 0.999909]\n",
      "epoch:39 step:184545[D loss: 1.000069] [G loss: 0.999974]\n",
      "epoch:39 step:184550[D loss: 1.000184] [G loss: 0.999925]\n",
      "epoch:39 step:184555[D loss: 1.000173] [G loss: 0.999870]\n",
      "epoch:39 step:184560[D loss: 1.000151] [G loss: 0.999805]\n",
      "epoch:39 step:184565[D loss: 0.999920] [G loss: 1.000214]\n",
      "epoch:39 step:184570[D loss: 0.999854] [G loss: 1.000297]\n",
      "epoch:39 step:184575[D loss: 1.000016] [G loss: 1.000051]\n",
      "epoch:39 step:184580[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:39 step:184585[D loss: 0.999986] [G loss: 1.000179]\n",
      "epoch:39 step:184590[D loss: 1.000074] [G loss: 0.999898]\n",
      "epoch:39 step:184595[D loss: 1.000019] [G loss: 0.999896]\n",
      "epoch:39 step:184600[D loss: 1.000039] [G loss: 0.999957]\n",
      "##############\n",
      "[2.59654058 2.3661043  2.29720792 3.82642492 1.5854558  6.71907829\n",
      " 2.24153987 3.86217163 3.8656609  4.06261494]\n",
      "##########\n",
      "epoch:39 step:184605[D loss: 1.000183] [G loss: 0.999805]\n",
      "epoch:39 step:184610[D loss: 0.999905] [G loss: 1.000020]\n",
      "epoch:39 step:184615[D loss: 0.999899] [G loss: 1.000020]\n",
      "epoch:39 step:184620[D loss: 0.999867] [G loss: 1.000209]\n",
      "epoch:39 step:184625[D loss: 0.999926] [G loss: 1.000141]\n",
      "epoch:39 step:184630[D loss: 0.999955] [G loss: 1.000032]\n",
      "epoch:39 step:184635[D loss: 0.999958] [G loss: 1.000010]\n",
      "epoch:39 step:184640[D loss: 1.000123] [G loss: 0.999847]\n",
      "epoch:39 step:184645[D loss: 0.999891] [G loss: 1.000070]\n",
      "epoch:39 step:184650[D loss: 0.999947] [G loss: 1.000179]\n",
      "epoch:39 step:184655[D loss: 0.999953] [G loss: 1.000153]\n",
      "epoch:39 step:184660[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:39 step:184665[D loss: 1.000005] [G loss: 1.000111]\n",
      "epoch:39 step:184670[D loss: 0.999958] [G loss: 1.000041]\n",
      "epoch:39 step:184675[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:39 step:184680[D loss: 0.999990] [G loss: 0.999992]\n",
      "epoch:39 step:184685[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:39 step:184690[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:39 step:184695[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:39 step:184700[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:39 step:184705[D loss: 1.000007] [G loss: 0.999960]\n",
      "epoch:39 step:184710[D loss: 1.000126] [G loss: 0.999769]\n",
      "epoch:39 step:184715[D loss: 0.999919] [G loss: 1.000175]\n",
      "epoch:39 step:184720[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:39 step:184725[D loss: 0.999916] [G loss: 1.000183]\n",
      "epoch:39 step:184730[D loss: 1.000060] [G loss: 0.999974]\n",
      "epoch:39 step:184735[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:39 step:184740[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:39 step:184745[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:39 step:184750[D loss: 1.000029] [G loss: 1.000074]\n",
      "epoch:39 step:184755[D loss: 0.999983] [G loss: 0.999995]\n",
      "epoch:39 step:184760[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:39 step:184765[D loss: 1.000210] [G loss: 0.999898]\n",
      "epoch:39 step:184770[D loss: 0.999926] [G loss: 1.000022]\n",
      "epoch:39 step:184775[D loss: 0.999927] [G loss: 1.000067]\n",
      "epoch:39 step:184780[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:39 step:184785[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:39 step:184790[D loss: 1.000046] [G loss: 1.000072]\n",
      "epoch:39 step:184795[D loss: 1.000027] [G loss: 0.999980]\n",
      "epoch:39 step:184800[D loss: 0.999960] [G loss: 1.000096]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('wgan')):\n",
    "    os.mkdir('saved_models_{}'.format('wgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('wgan'), mode='w')\n",
    "import cv2\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "        # y_trai/n = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # ---------------------\n",
    "                    #  Train Discriminator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Select a random batch of images\n",
    "                    # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                    # imgs = X_train[idx]\n",
    "\n",
    "                    # Sample noise as generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                    # Generate a batch of new images\n",
    "                    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                    # Train the critic\n",
    "                    d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                    d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                    # Clip critic weights\n",
    "                    for l in self.critic.layers:\n",
    "                        weights = l.get_weights()\n",
    "                        weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                        l.set_weights(weights)\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d[D loss: %f] [G loss: %f]\" % (epoch, global_step, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=40, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
