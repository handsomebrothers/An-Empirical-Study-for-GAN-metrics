{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f52880db278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# #指定使用那块GUP训练\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "# 设置最大占有GPU不超过显存的70%\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 \n",
    "# # 重点：设置动态分配GPU\n",
    "config.gpu_options.allow_growth = True\n",
    "# 创建session时\n",
    "tf.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 394,305\n",
      "Trainable params: 393,409\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,051,267\n",
      "Trainable params: 1,050,883\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "epoch:0 step:1 [D loss: 1.010275, acc.: 35.16%] [G loss: 0.829435]\n",
      "epoch:0 step:2 [D loss: 0.902872, acc.: 40.62%] [G loss: 0.879745]\n",
      "epoch:0 step:3 [D loss: 0.872813, acc.: 50.00%] [G loss: 1.247018]\n",
      "epoch:0 step:4 [D loss: 0.706090, acc.: 59.38%] [G loss: 1.181223]\n",
      "epoch:0 step:5 [D loss: 0.777010, acc.: 61.72%] [G loss: 1.299854]\n",
      "epoch:0 step:6 [D loss: 0.805521, acc.: 46.09%] [G loss: 1.160176]\n",
      "epoch:0 step:7 [D loss: 0.908557, acc.: 45.31%] [G loss: 1.114883]\n",
      "epoch:0 step:8 [D loss: 0.925312, acc.: 41.41%] [G loss: 1.144742]\n",
      "epoch:0 step:9 [D loss: 0.860158, acc.: 49.22%] [G loss: 1.132403]\n",
      "epoch:0 step:10 [D loss: 0.760819, acc.: 57.81%] [G loss: 1.323533]\n",
      "epoch:0 step:11 [D loss: 0.762819, acc.: 55.47%] [G loss: 1.159047]\n",
      "epoch:0 step:12 [D loss: 0.826469, acc.: 53.91%] [G loss: 1.301805]\n",
      "epoch:0 step:13 [D loss: 0.792867, acc.: 50.78%] [G loss: 1.143082]\n",
      "epoch:0 step:14 [D loss: 0.841541, acc.: 50.00%] [G loss: 1.156353]\n",
      "epoch:0 step:15 [D loss: 0.771148, acc.: 56.25%] [G loss: 0.970907]\n",
      "epoch:0 step:16 [D loss: 0.849318, acc.: 51.56%] [G loss: 0.885490]\n",
      "epoch:0 step:17 [D loss: 0.730222, acc.: 56.25%] [G loss: 0.897920]\n",
      "epoch:0 step:18 [D loss: 0.646524, acc.: 63.28%] [G loss: 1.100800]\n",
      "epoch:0 step:19 [D loss: 0.808281, acc.: 56.25%] [G loss: 1.060183]\n",
      "epoch:0 step:20 [D loss: 0.700918, acc.: 57.03%] [G loss: 1.286924]\n",
      "epoch:0 step:21 [D loss: 0.759576, acc.: 57.03%] [G loss: 1.400595]\n",
      "epoch:0 step:22 [D loss: 0.737045, acc.: 56.25%] [G loss: 1.353201]\n",
      "epoch:0 step:23 [D loss: 0.658701, acc.: 59.38%] [G loss: 1.294219]\n",
      "epoch:0 step:24 [D loss: 0.746602, acc.: 51.56%] [G loss: 1.385572]\n",
      "epoch:0 step:25 [D loss: 0.686068, acc.: 60.16%] [G loss: 1.396867]\n",
      "epoch:0 step:26 [D loss: 0.723482, acc.: 63.28%] [G loss: 1.424566]\n",
      "epoch:0 step:27 [D loss: 0.755977, acc.: 54.69%] [G loss: 1.432894]\n",
      "epoch:0 step:28 [D loss: 0.734751, acc.: 58.59%] [G loss: 1.848016]\n",
      "epoch:0 step:29 [D loss: 0.736180, acc.: 60.16%] [G loss: 1.856815]\n",
      "epoch:0 step:30 [D loss: 0.588310, acc.: 74.22%] [G loss: 1.288254]\n",
      "epoch:0 step:31 [D loss: 0.434682, acc.: 79.69%] [G loss: 1.003405]\n",
      "epoch:0 step:32 [D loss: 0.358791, acc.: 88.28%] [G loss: 0.791571]\n",
      "epoch:0 step:33 [D loss: 0.321247, acc.: 89.84%] [G loss: 0.560407]\n",
      "epoch:0 step:34 [D loss: 0.177634, acc.: 96.88%] [G loss: 0.438706]\n",
      "epoch:0 step:35 [D loss: 0.166211, acc.: 96.88%] [G loss: 0.535474]\n",
      "epoch:0 step:36 [D loss: 0.302217, acc.: 87.50%] [G loss: 0.574620]\n",
      "epoch:0 step:37 [D loss: 0.280149, acc.: 90.62%] [G loss: 0.716550]\n",
      "epoch:0 step:38 [D loss: 0.525527, acc.: 77.34%] [G loss: 1.342773]\n",
      "epoch:0 step:39 [D loss: 0.504562, acc.: 73.44%] [G loss: 1.965527]\n",
      "epoch:0 step:40 [D loss: 0.860962, acc.: 50.00%] [G loss: 1.949580]\n",
      "epoch:0 step:41 [D loss: 0.744437, acc.: 63.28%] [G loss: 1.669598]\n",
      "epoch:0 step:42 [D loss: 0.591351, acc.: 71.88%] [G loss: 1.223938]\n",
      "epoch:0 step:43 [D loss: 0.546533, acc.: 75.00%] [G loss: 0.819786]\n",
      "epoch:0 step:44 [D loss: 0.319203, acc.: 91.41%] [G loss: 0.748129]\n",
      "epoch:0 step:45 [D loss: 0.327706, acc.: 88.28%] [G loss: 0.429042]\n",
      "epoch:0 step:46 [D loss: 0.237317, acc.: 94.53%] [G loss: 0.451535]\n",
      "epoch:0 step:47 [D loss: 0.215763, acc.: 91.41%] [G loss: 0.380836]\n",
      "epoch:0 step:48 [D loss: 0.171934, acc.: 96.09%] [G loss: 0.428989]\n",
      "epoch:0 step:49 [D loss: 0.138091, acc.: 99.22%] [G loss: 0.422085]\n",
      "epoch:0 step:50 [D loss: 0.129667, acc.: 97.66%] [G loss: 0.494025]\n",
      "epoch:0 step:51 [D loss: 0.119907, acc.: 98.44%] [G loss: 0.517354]\n",
      "epoch:0 step:52 [D loss: 0.121473, acc.: 100.00%] [G loss: 0.543377]\n",
      "epoch:0 step:53 [D loss: 0.098263, acc.: 100.00%] [G loss: 0.516491]\n",
      "epoch:0 step:54 [D loss: 0.108243, acc.: 97.66%] [G loss: 0.420952]\n",
      "epoch:0 step:55 [D loss: 0.112205, acc.: 98.44%] [G loss: 0.493729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:56 [D loss: 0.186728, acc.: 94.53%] [G loss: 0.459123]\n",
      "epoch:0 step:57 [D loss: 0.213630, acc.: 92.19%] [G loss: 0.678822]\n",
      "epoch:0 step:58 [D loss: 0.176153, acc.: 96.09%] [G loss: 0.574987]\n",
      "epoch:0 step:59 [D loss: 0.239362, acc.: 93.75%] [G loss: 0.608872]\n",
      "epoch:0 step:60 [D loss: 0.397591, acc.: 81.25%] [G loss: 0.938434]\n",
      "epoch:0 step:61 [D loss: 0.619071, acc.: 69.53%] [G loss: 1.242561]\n",
      "epoch:0 step:62 [D loss: 0.811314, acc.: 57.81%] [G loss: 1.712152]\n",
      "epoch:0 step:63 [D loss: 1.110198, acc.: 46.88%] [G loss: 1.895045]\n",
      "epoch:0 step:64 [D loss: 1.048169, acc.: 52.34%] [G loss: 1.549279]\n",
      "epoch:0 step:65 [D loss: 0.934177, acc.: 54.69%] [G loss: 1.022854]\n",
      "epoch:0 step:66 [D loss: 0.667106, acc.: 69.53%] [G loss: 0.726846]\n",
      "epoch:0 step:67 [D loss: 0.446826, acc.: 82.03%] [G loss: 0.611340]\n",
      "epoch:0 step:68 [D loss: 0.332240, acc.: 86.72%] [G loss: 0.699833]\n",
      "epoch:0 step:69 [D loss: 0.463681, acc.: 80.47%] [G loss: 0.770100]\n",
      "epoch:0 step:70 [D loss: 0.504405, acc.: 77.34%] [G loss: 0.716207]\n",
      "epoch:0 step:71 [D loss: 0.429157, acc.: 82.03%] [G loss: 0.727224]\n",
      "epoch:0 step:72 [D loss: 0.673304, acc.: 57.03%] [G loss: 1.156378]\n",
      "epoch:0 step:73 [D loss: 0.759467, acc.: 56.25%] [G loss: 1.719924]\n",
      "epoch:0 step:74 [D loss: 0.817669, acc.: 56.25%] [G loss: 2.060549]\n",
      "epoch:0 step:75 [D loss: 0.876064, acc.: 50.78%] [G loss: 1.707696]\n",
      "epoch:0 step:76 [D loss: 0.635025, acc.: 73.44%] [G loss: 1.393877]\n",
      "epoch:0 step:77 [D loss: 0.562272, acc.: 75.78%] [G loss: 1.077702]\n",
      "epoch:0 step:78 [D loss: 0.406190, acc.: 82.03%] [G loss: 0.916065]\n",
      "epoch:0 step:79 [D loss: 0.432172, acc.: 83.59%] [G loss: 0.799999]\n",
      "epoch:0 step:80 [D loss: 0.535578, acc.: 78.12%] [G loss: 0.790004]\n",
      "epoch:0 step:81 [D loss: 0.330401, acc.: 86.72%] [G loss: 0.823910]\n",
      "epoch:0 step:82 [D loss: 0.715122, acc.: 64.84%] [G loss: 0.965208]\n",
      "epoch:0 step:83 [D loss: 0.755829, acc.: 66.41%] [G loss: 1.300982]\n",
      "epoch:0 step:84 [D loss: 0.617618, acc.: 73.44%] [G loss: 1.024912]\n",
      "epoch:0 step:85 [D loss: 0.583486, acc.: 70.31%] [G loss: 0.924458]\n",
      "epoch:0 step:86 [D loss: 0.675451, acc.: 60.94%] [G loss: 1.269812]\n",
      "epoch:0 step:87 [D loss: 0.651464, acc.: 70.31%] [G loss: 1.330363]\n",
      "epoch:0 step:88 [D loss: 0.682962, acc.: 67.19%] [G loss: 1.529924]\n",
      "epoch:0 step:89 [D loss: 0.665562, acc.: 67.19%] [G loss: 1.583335]\n",
      "epoch:0 step:90 [D loss: 0.718630, acc.: 68.75%] [G loss: 1.397230]\n",
      "epoch:0 step:91 [D loss: 0.607810, acc.: 67.97%] [G loss: 1.327395]\n",
      "epoch:0 step:92 [D loss: 0.503385, acc.: 82.81%] [G loss: 0.922201]\n",
      "epoch:0 step:93 [D loss: 0.514563, acc.: 74.22%] [G loss: 0.792049]\n",
      "epoch:0 step:94 [D loss: 0.252881, acc.: 92.19%] [G loss: 0.750202]\n",
      "epoch:0 step:95 [D loss: 0.210303, acc.: 97.66%] [G loss: 0.426018]\n",
      "epoch:0 step:96 [D loss: 0.629843, acc.: 67.19%] [G loss: 0.441514]\n",
      "epoch:0 step:97 [D loss: 0.351344, acc.: 85.94%] [G loss: 0.499952]\n",
      "epoch:0 step:98 [D loss: 0.336307, acc.: 85.16%] [G loss: 0.353000]\n",
      "epoch:0 step:99 [D loss: 0.325153, acc.: 90.62%] [G loss: 0.635159]\n",
      "epoch:0 step:100 [D loss: 0.499895, acc.: 76.56%] [G loss: 0.512050]\n",
      "epoch:0 step:101 [D loss: 0.417952, acc.: 81.25%] [G loss: 0.818373]\n",
      "epoch:0 step:102 [D loss: 0.527091, acc.: 78.12%] [G loss: 0.551288]\n",
      "epoch:0 step:103 [D loss: 0.533067, acc.: 74.22%] [G loss: 0.863924]\n",
      "epoch:0 step:104 [D loss: 0.795259, acc.: 50.00%] [G loss: 0.688341]\n",
      "epoch:0 step:105 [D loss: 0.880291, acc.: 56.25%] [G loss: 0.939314]\n",
      "epoch:0 step:106 [D loss: 0.789179, acc.: 58.59%] [G loss: 1.060071]\n",
      "epoch:0 step:107 [D loss: 1.183636, acc.: 42.19%] [G loss: 1.005162]\n",
      "epoch:0 step:108 [D loss: 1.037119, acc.: 41.41%] [G loss: 0.965757]\n",
      "epoch:0 step:109 [D loss: 0.992109, acc.: 42.97%] [G loss: 1.087566]\n",
      "epoch:0 step:110 [D loss: 1.191110, acc.: 39.06%] [G loss: 1.144123]\n",
      "epoch:0 step:111 [D loss: 0.793481, acc.: 53.91%] [G loss: 1.550228]\n",
      "epoch:0 step:112 [D loss: 1.118607, acc.: 43.75%] [G loss: 1.269094]\n",
      "epoch:0 step:113 [D loss: 0.888478, acc.: 53.12%] [G loss: 1.319086]\n",
      "epoch:0 step:114 [D loss: 1.038879, acc.: 48.44%] [G loss: 1.217515]\n",
      "epoch:0 step:115 [D loss: 0.719200, acc.: 63.28%] [G loss: 1.325245]\n",
      "epoch:0 step:116 [D loss: 0.677004, acc.: 62.50%] [G loss: 1.135901]\n",
      "epoch:0 step:117 [D loss: 0.568822, acc.: 69.53%] [G loss: 0.802207]\n",
      "epoch:0 step:118 [D loss: 0.396476, acc.: 83.59%] [G loss: 0.907311]\n",
      "epoch:0 step:119 [D loss: 0.456898, acc.: 77.34%] [G loss: 0.696590]\n",
      "epoch:0 step:120 [D loss: 0.579309, acc.: 75.00%] [G loss: 0.823123]\n",
      "epoch:0 step:121 [D loss: 0.590518, acc.: 78.91%] [G loss: 1.129557]\n",
      "epoch:0 step:122 [D loss: 0.719134, acc.: 62.50%] [G loss: 1.236806]\n",
      "epoch:0 step:123 [D loss: 0.905607, acc.: 46.09%] [G loss: 1.495995]\n",
      "epoch:0 step:124 [D loss: 0.771120, acc.: 55.47%] [G loss: 1.638748]\n",
      "epoch:0 step:125 [D loss: 0.767349, acc.: 57.03%] [G loss: 1.094419]\n",
      "epoch:0 step:126 [D loss: 0.748958, acc.: 59.38%] [G loss: 1.336082]\n",
      "epoch:0 step:127 [D loss: 0.815692, acc.: 51.56%] [G loss: 1.365138]\n",
      "epoch:0 step:128 [D loss: 0.977615, acc.: 42.97%] [G loss: 1.347558]\n",
      "epoch:0 step:129 [D loss: 0.902760, acc.: 46.88%] [G loss: 1.391396]\n",
      "epoch:0 step:130 [D loss: 0.625251, acc.: 67.19%] [G loss: 1.457318]\n",
      "epoch:0 step:131 [D loss: 0.810834, acc.: 53.12%] [G loss: 1.396338]\n",
      "epoch:0 step:132 [D loss: 0.779513, acc.: 55.47%] [G loss: 1.272726]\n",
      "epoch:0 step:133 [D loss: 0.728139, acc.: 57.81%] [G loss: 1.399718]\n",
      "epoch:0 step:134 [D loss: 0.748666, acc.: 54.69%] [G loss: 1.404863]\n",
      "epoch:0 step:135 [D loss: 0.654150, acc.: 62.50%] [G loss: 1.264417]\n",
      "epoch:0 step:136 [D loss: 0.497787, acc.: 77.34%] [G loss: 1.203643]\n",
      "epoch:0 step:137 [D loss: 0.552707, acc.: 76.56%] [G loss: 1.152173]\n",
      "epoch:0 step:138 [D loss: 0.576994, acc.: 71.09%] [G loss: 1.208819]\n",
      "epoch:0 step:139 [D loss: 0.800106, acc.: 49.22%] [G loss: 1.121002]\n",
      "epoch:0 step:140 [D loss: 0.617138, acc.: 70.31%] [G loss: 0.981861]\n",
      "epoch:0 step:141 [D loss: 0.806772, acc.: 53.91%] [G loss: 1.000743]\n",
      "epoch:0 step:142 [D loss: 0.754812, acc.: 58.59%] [G loss: 1.326010]\n",
      "epoch:0 step:143 [D loss: 0.787537, acc.: 51.56%] [G loss: 1.267258]\n",
      "epoch:0 step:144 [D loss: 0.702459, acc.: 60.94%] [G loss: 1.400977]\n",
      "epoch:0 step:145 [D loss: 0.552374, acc.: 66.41%] [G loss: 1.193658]\n",
      "epoch:0 step:146 [D loss: 0.825915, acc.: 50.00%] [G loss: 1.079554]\n",
      "epoch:0 step:147 [D loss: 0.723481, acc.: 61.72%] [G loss: 1.244926]\n",
      "epoch:0 step:148 [D loss: 0.481517, acc.: 78.91%] [G loss: 1.099378]\n",
      "epoch:0 step:149 [D loss: 0.876937, acc.: 48.44%] [G loss: 1.168305]\n",
      "epoch:0 step:150 [D loss: 0.814153, acc.: 52.34%] [G loss: 1.368688]\n",
      "epoch:0 step:151 [D loss: 0.558422, acc.: 69.53%] [G loss: 1.465479]\n",
      "epoch:0 step:152 [D loss: 0.752177, acc.: 52.34%] [G loss: 1.201671]\n",
      "epoch:0 step:153 [D loss: 0.680382, acc.: 57.81%] [G loss: 1.138973]\n",
      "epoch:0 step:154 [D loss: 0.761740, acc.: 59.38%] [G loss: 1.533878]\n",
      "epoch:0 step:155 [D loss: 0.623257, acc.: 64.84%] [G loss: 1.307121]\n",
      "epoch:0 step:156 [D loss: 0.610746, acc.: 67.97%] [G loss: 1.328408]\n",
      "epoch:0 step:157 [D loss: 0.572041, acc.: 69.53%] [G loss: 1.464981]\n",
      "epoch:0 step:158 [D loss: 0.558143, acc.: 67.19%] [G loss: 1.642531]\n",
      "epoch:0 step:159 [D loss: 0.496051, acc.: 80.47%] [G loss: 1.773543]\n",
      "epoch:0 step:160 [D loss: 0.489899, acc.: 76.56%] [G loss: 1.518237]\n",
      "epoch:0 step:161 [D loss: 0.632931, acc.: 66.41%] [G loss: 1.382483]\n",
      "epoch:0 step:162 [D loss: 0.521384, acc.: 74.22%] [G loss: 0.958416]\n",
      "epoch:0 step:163 [D loss: 0.525895, acc.: 79.69%] [G loss: 0.916210]\n",
      "epoch:0 step:164 [D loss: 0.618512, acc.: 66.41%] [G loss: 0.907988]\n",
      "epoch:0 step:165 [D loss: 0.538896, acc.: 72.66%] [G loss: 0.869426]\n",
      "epoch:0 step:166 [D loss: 0.563904, acc.: 71.88%] [G loss: 0.785875]\n",
      "epoch:0 step:167 [D loss: 0.623119, acc.: 65.62%] [G loss: 0.996514]\n",
      "epoch:0 step:168 [D loss: 0.568281, acc.: 71.09%] [G loss: 1.062990]\n",
      "epoch:0 step:169 [D loss: 0.700242, acc.: 59.38%] [G loss: 0.887204]\n",
      "epoch:0 step:170 [D loss: 0.699772, acc.: 57.03%] [G loss: 0.900014]\n",
      "epoch:0 step:171 [D loss: 0.662133, acc.: 61.72%] [G loss: 0.969081]\n",
      "epoch:0 step:172 [D loss: 0.719408, acc.: 57.81%] [G loss: 1.222278]\n",
      "epoch:0 step:173 [D loss: 0.771464, acc.: 52.34%] [G loss: 1.368461]\n",
      "epoch:0 step:174 [D loss: 0.883664, acc.: 48.44%] [G loss: 1.205220]\n",
      "epoch:0 step:175 [D loss: 0.805208, acc.: 57.81%] [G loss: 1.405227]\n",
      "epoch:0 step:176 [D loss: 0.663228, acc.: 65.62%] [G loss: 1.832072]\n",
      "epoch:0 step:177 [D loss: 0.744910, acc.: 56.25%] [G loss: 1.657024]\n",
      "epoch:0 step:178 [D loss: 0.656020, acc.: 63.28%] [G loss: 1.708267]\n",
      "epoch:0 step:179 [D loss: 0.654452, acc.: 62.50%] [G loss: 1.894085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:180 [D loss: 0.459373, acc.: 75.00%] [G loss: 1.555543]\n",
      "epoch:0 step:181 [D loss: 0.562998, acc.: 71.09%] [G loss: 1.189204]\n",
      "epoch:0 step:182 [D loss: 0.519722, acc.: 75.00%] [G loss: 1.173047]\n",
      "epoch:0 step:183 [D loss: 0.554624, acc.: 72.66%] [G loss: 0.867581]\n",
      "epoch:0 step:184 [D loss: 0.498431, acc.: 74.22%] [G loss: 0.895129]\n",
      "epoch:0 step:185 [D loss: 0.575146, acc.: 66.41%] [G loss: 0.945896]\n",
      "epoch:0 step:186 [D loss: 0.652261, acc.: 60.16%] [G loss: 1.195312]\n",
      "epoch:0 step:187 [D loss: 0.655370, acc.: 64.06%] [G loss: 1.019290]\n",
      "epoch:0 step:188 [D loss: 0.761274, acc.: 53.12%] [G loss: 1.018791]\n",
      "epoch:0 step:189 [D loss: 0.751081, acc.: 50.00%] [G loss: 1.410949]\n",
      "epoch:0 step:190 [D loss: 0.602940, acc.: 64.06%] [G loss: 1.442718]\n",
      "epoch:0 step:191 [D loss: 0.688492, acc.: 63.28%] [G loss: 1.699823]\n",
      "epoch:0 step:192 [D loss: 0.561646, acc.: 70.31%] [G loss: 1.372007]\n",
      "epoch:0 step:193 [D loss: 0.485091, acc.: 76.56%] [G loss: 1.128498]\n",
      "epoch:0 step:194 [D loss: 0.608385, acc.: 70.31%] [G loss: 1.390562]\n",
      "epoch:0 step:195 [D loss: 0.493783, acc.: 75.00%] [G loss: 1.616170]\n",
      "epoch:0 step:196 [D loss: 0.418208, acc.: 80.47%] [G loss: 1.304698]\n",
      "epoch:0 step:197 [D loss: 0.607724, acc.: 64.84%] [G loss: 0.881115]\n",
      "epoch:0 step:198 [D loss: 0.505589, acc.: 78.12%] [G loss: 1.103786]\n",
      "epoch:0 step:199 [D loss: 0.485218, acc.: 78.91%] [G loss: 1.156110]\n",
      "epoch:0 step:200 [D loss: 0.670036, acc.: 60.94%] [G loss: 1.102039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:41: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:201 [D loss: 0.727636, acc.: 56.25%] [G loss: 1.016541]\n",
      "epoch:0 step:202 [D loss: 0.588281, acc.: 68.75%] [G loss: 1.127703]\n",
      "epoch:0 step:203 [D loss: 0.760119, acc.: 54.69%] [G loss: 1.069809]\n",
      "epoch:0 step:204 [D loss: 0.701839, acc.: 59.38%] [G loss: 1.073573]\n",
      "epoch:0 step:205 [D loss: 0.736521, acc.: 60.16%] [G loss: 1.091356]\n",
      "epoch:0 step:206 [D loss: 0.741254, acc.: 54.69%] [G loss: 1.222856]\n",
      "epoch:0 step:207 [D loss: 0.667383, acc.: 64.84%] [G loss: 1.252706]\n",
      "epoch:0 step:208 [D loss: 0.794981, acc.: 51.56%] [G loss: 0.728459]\n",
      "epoch:0 step:209 [D loss: 0.670285, acc.: 63.28%] [G loss: 1.196496]\n",
      "epoch:0 step:210 [D loss: 0.556763, acc.: 67.97%] [G loss: 1.323104]\n",
      "epoch:0 step:211 [D loss: 0.786440, acc.: 57.81%] [G loss: 1.040331]\n",
      "epoch:0 step:212 [D loss: 0.777508, acc.: 56.25%] [G loss: 0.913735]\n",
      "epoch:0 step:213 [D loss: 0.880655, acc.: 46.88%] [G loss: 1.015615]\n",
      "epoch:0 step:214 [D loss: 0.945036, acc.: 45.31%] [G loss: 0.925602]\n",
      "epoch:0 step:215 [D loss: 0.851578, acc.: 44.53%] [G loss: 0.997305]\n",
      "epoch:0 step:216 [D loss: 0.877403, acc.: 48.44%] [G loss: 0.804840]\n",
      "epoch:0 step:217 [D loss: 0.654846, acc.: 63.28%] [G loss: 1.054213]\n",
      "epoch:0 step:218 [D loss: 0.962817, acc.: 41.41%] [G loss: 1.103464]\n",
      "epoch:0 step:219 [D loss: 0.539653, acc.: 72.66%] [G loss: 1.600448]\n",
      "epoch:0 step:220 [D loss: 0.636909, acc.: 64.84%] [G loss: 1.284249]\n",
      "epoch:0 step:221 [D loss: 0.796777, acc.: 53.12%] [G loss: 0.879458]\n",
      "epoch:0 step:222 [D loss: 0.575931, acc.: 70.31%] [G loss: 1.260299]\n",
      "epoch:0 step:223 [D loss: 0.805275, acc.: 53.91%] [G loss: 1.132018]\n",
      "epoch:0 step:224 [D loss: 0.711821, acc.: 57.81%] [G loss: 0.879187]\n",
      "epoch:0 step:225 [D loss: 0.589381, acc.: 67.97%] [G loss: 1.247180]\n",
      "epoch:0 step:226 [D loss: 0.654776, acc.: 64.84%] [G loss: 0.923550]\n",
      "epoch:0 step:227 [D loss: 0.673929, acc.: 63.28%] [G loss: 0.902259]\n",
      "epoch:0 step:228 [D loss: 0.781976, acc.: 54.69%] [G loss: 0.719980]\n",
      "epoch:0 step:229 [D loss: 0.829568, acc.: 48.44%] [G loss: 0.928678]\n",
      "epoch:0 step:230 [D loss: 0.789771, acc.: 53.12%] [G loss: 1.166881]\n",
      "epoch:0 step:231 [D loss: 0.894570, acc.: 50.00%] [G loss: 1.005698]\n",
      "epoch:0 step:232 [D loss: 0.771919, acc.: 53.91%] [G loss: 1.007530]\n",
      "epoch:0 step:233 [D loss: 0.897383, acc.: 45.31%] [G loss: 0.972492]\n",
      "epoch:0 step:234 [D loss: 0.754136, acc.: 55.47%] [G loss: 0.954490]\n",
      "epoch:0 step:235 [D loss: 0.674289, acc.: 55.47%] [G loss: 0.982845]\n",
      "epoch:0 step:236 [D loss: 0.865324, acc.: 49.22%] [G loss: 0.799313]\n",
      "epoch:0 step:237 [D loss: 0.802467, acc.: 53.91%] [G loss: 0.934210]\n",
      "epoch:0 step:238 [D loss: 0.564030, acc.: 75.78%] [G loss: 0.987004]\n",
      "epoch:0 step:239 [D loss: 0.649102, acc.: 57.81%] [G loss: 1.218506]\n",
      "epoch:0 step:240 [D loss: 0.620353, acc.: 68.75%] [G loss: 1.019929]\n",
      "epoch:0 step:241 [D loss: 0.794412, acc.: 51.56%] [G loss: 0.831473]\n",
      "epoch:0 step:242 [D loss: 0.742608, acc.: 57.03%] [G loss: 0.865563]\n",
      "epoch:0 step:243 [D loss: 0.618918, acc.: 67.97%] [G loss: 0.904806]\n",
      "epoch:0 step:244 [D loss: 0.702690, acc.: 57.03%] [G loss: 0.738107]\n",
      "epoch:0 step:245 [D loss: 0.727361, acc.: 59.38%] [G loss: 0.856790]\n",
      "epoch:0 step:246 [D loss: 0.724164, acc.: 59.38%] [G loss: 0.977473]\n",
      "epoch:0 step:247 [D loss: 0.600068, acc.: 69.53%] [G loss: 0.956334]\n",
      "epoch:0 step:248 [D loss: 0.957011, acc.: 36.72%] [G loss: 1.106781]\n",
      "epoch:0 step:249 [D loss: 0.737642, acc.: 58.59%] [G loss: 0.946899]\n",
      "epoch:0 step:250 [D loss: 0.711975, acc.: 58.59%] [G loss: 1.105214]\n",
      "epoch:0 step:251 [D loss: 0.816038, acc.: 52.34%] [G loss: 0.897035]\n",
      "epoch:0 step:252 [D loss: 1.042526, acc.: 44.53%] [G loss: 1.125111]\n",
      "epoch:0 step:253 [D loss: 0.694727, acc.: 64.06%] [G loss: 0.955300]\n",
      "epoch:0 step:254 [D loss: 0.800521, acc.: 52.34%] [G loss: 0.955635]\n",
      "epoch:0 step:255 [D loss: 0.987806, acc.: 37.50%] [G loss: 0.862790]\n",
      "epoch:0 step:256 [D loss: 0.727056, acc.: 54.69%] [G loss: 0.923400]\n",
      "epoch:0 step:257 [D loss: 0.730845, acc.: 64.06%] [G loss: 0.881432]\n",
      "epoch:0 step:258 [D loss: 0.626541, acc.: 66.41%] [G loss: 1.047415]\n",
      "epoch:0 step:259 [D loss: 0.780324, acc.: 57.03%] [G loss: 0.959812]\n",
      "epoch:0 step:260 [D loss: 0.608303, acc.: 64.84%] [G loss: 1.074806]\n",
      "epoch:0 step:261 [D loss: 0.606959, acc.: 63.28%] [G loss: 1.067521]\n",
      "epoch:0 step:262 [D loss: 0.654419, acc.: 60.94%] [G loss: 0.979989]\n",
      "epoch:0 step:263 [D loss: 0.762118, acc.: 58.59%] [G loss: 0.946996]\n",
      "epoch:0 step:264 [D loss: 0.659629, acc.: 63.28%] [G loss: 1.126348]\n",
      "epoch:0 step:265 [D loss: 0.776550, acc.: 57.03%] [G loss: 0.794645]\n",
      "epoch:0 step:266 [D loss: 0.645468, acc.: 62.50%] [G loss: 0.861888]\n",
      "epoch:0 step:267 [D loss: 0.749463, acc.: 53.91%] [G loss: 0.810613]\n",
      "epoch:0 step:268 [D loss: 0.705165, acc.: 56.25%] [G loss: 0.936439]\n",
      "epoch:0 step:269 [D loss: 0.850011, acc.: 50.78%] [G loss: 0.978504]\n",
      "epoch:0 step:270 [D loss: 0.930015, acc.: 41.41%] [G loss: 1.021344]\n",
      "epoch:0 step:271 [D loss: 0.722779, acc.: 57.81%] [G loss: 1.168817]\n",
      "epoch:0 step:272 [D loss: 0.762643, acc.: 50.78%] [G loss: 1.153722]\n",
      "epoch:0 step:273 [D loss: 0.692536, acc.: 60.16%] [G loss: 0.984332]\n",
      "epoch:0 step:274 [D loss: 0.746432, acc.: 53.12%] [G loss: 1.024626]\n",
      "epoch:0 step:275 [D loss: 0.706754, acc.: 59.38%] [G loss: 1.141638]\n",
      "epoch:0 step:276 [D loss: 0.699965, acc.: 55.47%] [G loss: 0.905262]\n",
      "epoch:0 step:277 [D loss: 0.790345, acc.: 50.78%] [G loss: 1.031381]\n",
      "epoch:0 step:278 [D loss: 0.681244, acc.: 59.38%] [G loss: 1.018929]\n",
      "epoch:0 step:279 [D loss: 0.799854, acc.: 53.91%] [G loss: 1.029859]\n",
      "epoch:0 step:280 [D loss: 0.852331, acc.: 47.66%] [G loss: 0.945705]\n",
      "epoch:0 step:281 [D loss: 0.715585, acc.: 58.59%] [G loss: 1.153224]\n",
      "epoch:0 step:282 [D loss: 0.553026, acc.: 67.19%] [G loss: 1.412200]\n",
      "epoch:0 step:283 [D loss: 0.537777, acc.: 71.09%] [G loss: 1.261336]\n",
      "epoch:0 step:284 [D loss: 0.517465, acc.: 74.22%] [G loss: 1.200509]\n",
      "epoch:0 step:285 [D loss: 0.457102, acc.: 76.56%] [G loss: 1.213280]\n",
      "epoch:0 step:286 [D loss: 0.511082, acc.: 80.47%] [G loss: 1.074957]\n",
      "epoch:0 step:287 [D loss: 0.447225, acc.: 77.34%] [G loss: 0.916339]\n",
      "epoch:0 step:288 [D loss: 0.405331, acc.: 87.50%] [G loss: 0.886315]\n",
      "epoch:0 step:289 [D loss: 0.426371, acc.: 81.25%] [G loss: 0.739754]\n",
      "epoch:0 step:290 [D loss: 0.594505, acc.: 71.09%] [G loss: 0.743865]\n",
      "epoch:0 step:291 [D loss: 0.608603, acc.: 69.53%] [G loss: 0.606437]\n",
      "epoch:0 step:292 [D loss: 0.515387, acc.: 75.78%] [G loss: 0.638905]\n",
      "epoch:0 step:293 [D loss: 0.730299, acc.: 60.94%] [G loss: 0.663557]\n",
      "epoch:0 step:294 [D loss: 0.538666, acc.: 79.69%] [G loss: 0.842613]\n",
      "epoch:0 step:295 [D loss: 0.564931, acc.: 70.31%] [G loss: 0.648944]\n",
      "epoch:0 step:296 [D loss: 0.799888, acc.: 49.22%] [G loss: 0.776615]\n",
      "epoch:0 step:297 [D loss: 0.937285, acc.: 48.44%] [G loss: 0.731078]\n",
      "epoch:0 step:298 [D loss: 0.937038, acc.: 42.19%] [G loss: 0.963548]\n",
      "epoch:0 step:299 [D loss: 0.921039, acc.: 44.53%] [G loss: 0.956712]\n",
      "epoch:0 step:300 [D loss: 0.752300, acc.: 54.69%] [G loss: 1.065065]\n",
      "epoch:0 step:301 [D loss: 0.882682, acc.: 46.88%] [G loss: 1.003619]\n",
      "epoch:0 step:302 [D loss: 0.899505, acc.: 42.19%] [G loss: 1.193260]\n",
      "epoch:0 step:303 [D loss: 0.822608, acc.: 49.22%] [G loss: 0.889852]\n",
      "epoch:0 step:304 [D loss: 0.758320, acc.: 57.81%] [G loss: 1.040489]\n",
      "epoch:0 step:305 [D loss: 0.832352, acc.: 51.56%] [G loss: 1.200189]\n",
      "epoch:0 step:306 [D loss: 0.867064, acc.: 50.00%] [G loss: 1.168064]\n",
      "epoch:0 step:307 [D loss: 0.760310, acc.: 56.25%] [G loss: 1.014084]\n",
      "epoch:0 step:308 [D loss: 0.673603, acc.: 62.50%] [G loss: 1.126439]\n",
      "epoch:0 step:309 [D loss: 0.825557, acc.: 52.34%] [G loss: 0.904880]\n",
      "epoch:0 step:310 [D loss: 0.782953, acc.: 51.56%] [G loss: 1.084596]\n",
      "epoch:0 step:311 [D loss: 0.732158, acc.: 57.81%] [G loss: 1.212982]\n",
      "epoch:0 step:312 [D loss: 0.811485, acc.: 49.22%] [G loss: 1.123935]\n",
      "epoch:0 step:313 [D loss: 0.798462, acc.: 49.22%] [G loss: 1.085850]\n",
      "epoch:0 step:314 [D loss: 0.674253, acc.: 57.81%] [G loss: 1.106157]\n",
      "epoch:0 step:315 [D loss: 0.901289, acc.: 47.66%] [G loss: 1.102780]\n",
      "epoch:0 step:316 [D loss: 0.710599, acc.: 59.38%] [G loss: 1.181336]\n",
      "epoch:0 step:317 [D loss: 0.737782, acc.: 57.03%] [G loss: 1.163842]\n",
      "epoch:0 step:318 [D loss: 0.726383, acc.: 57.03%] [G loss: 1.027181]\n",
      "epoch:0 step:319 [D loss: 0.722828, acc.: 64.84%] [G loss: 0.967934]\n",
      "epoch:0 step:320 [D loss: 0.690913, acc.: 57.81%] [G loss: 0.996383]\n",
      "epoch:0 step:321 [D loss: 0.579452, acc.: 67.19%] [G loss: 1.217347]\n",
      "epoch:0 step:322 [D loss: 0.795429, acc.: 53.12%] [G loss: 0.991003]\n",
      "epoch:0 step:323 [D loss: 0.690444, acc.: 59.38%] [G loss: 1.211642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:324 [D loss: 0.682827, acc.: 60.94%] [G loss: 0.982694]\n",
      "epoch:0 step:325 [D loss: 0.725710, acc.: 56.25%] [G loss: 1.145139]\n",
      "epoch:0 step:326 [D loss: 0.728850, acc.: 59.38%] [G loss: 1.090545]\n",
      "epoch:0 step:327 [D loss: 0.613937, acc.: 64.06%] [G loss: 0.931122]\n",
      "epoch:0 step:328 [D loss: 0.641645, acc.: 66.41%] [G loss: 0.889441]\n",
      "epoch:0 step:329 [D loss: 0.714782, acc.: 57.03%] [G loss: 0.860087]\n",
      "epoch:0 step:330 [D loss: 0.743958, acc.: 56.25%] [G loss: 0.691066]\n",
      "epoch:0 step:331 [D loss: 0.701349, acc.: 57.81%] [G loss: 0.739746]\n",
      "epoch:0 step:332 [D loss: 0.704883, acc.: 64.06%] [G loss: 0.707682]\n",
      "epoch:0 step:333 [D loss: 0.669425, acc.: 59.38%] [G loss: 0.844051]\n",
      "epoch:0 step:334 [D loss: 0.695785, acc.: 58.59%] [G loss: 0.530466]\n",
      "epoch:0 step:335 [D loss: 0.759648, acc.: 54.69%] [G loss: 0.709363]\n",
      "epoch:0 step:336 [D loss: 0.687431, acc.: 60.16%] [G loss: 0.881075]\n",
      "epoch:0 step:337 [D loss: 0.760456, acc.: 51.56%] [G loss: 0.620274]\n",
      "epoch:0 step:338 [D loss: 0.981701, acc.: 35.16%] [G loss: 0.563488]\n",
      "epoch:0 step:339 [D loss: 0.761013, acc.: 56.25%] [G loss: 0.855670]\n",
      "epoch:0 step:340 [D loss: 0.976469, acc.: 39.06%] [G loss: 0.700073]\n",
      "epoch:0 step:341 [D loss: 0.872038, acc.: 45.31%] [G loss: 0.715762]\n",
      "epoch:0 step:342 [D loss: 0.812026, acc.: 51.56%] [G loss: 1.011708]\n",
      "epoch:0 step:343 [D loss: 0.849654, acc.: 47.66%] [G loss: 0.802901]\n",
      "epoch:0 step:344 [D loss: 0.833865, acc.: 49.22%] [G loss: 0.976860]\n",
      "epoch:0 step:345 [D loss: 0.875417, acc.: 44.53%] [G loss: 1.067876]\n",
      "epoch:0 step:346 [D loss: 0.826879, acc.: 47.66%] [G loss: 1.049744]\n",
      "epoch:0 step:347 [D loss: 0.844460, acc.: 49.22%] [G loss: 0.999167]\n",
      "epoch:0 step:348 [D loss: 0.841082, acc.: 50.78%] [G loss: 1.027743]\n",
      "epoch:0 step:349 [D loss: 0.707955, acc.: 57.03%] [G loss: 1.233493]\n",
      "epoch:0 step:350 [D loss: 0.695882, acc.: 58.59%] [G loss: 1.160600]\n",
      "epoch:0 step:351 [D loss: 0.576151, acc.: 68.75%] [G loss: 1.119279]\n",
      "epoch:0 step:352 [D loss: 0.609388, acc.: 71.88%] [G loss: 0.951722]\n",
      "epoch:0 step:353 [D loss: 0.559490, acc.: 69.53%] [G loss: 1.171261]\n",
      "epoch:0 step:354 [D loss: 0.638979, acc.: 68.75%] [G loss: 0.961916]\n",
      "epoch:0 step:355 [D loss: 0.525641, acc.: 72.66%] [G loss: 1.129659]\n",
      "epoch:0 step:356 [D loss: 0.541546, acc.: 73.44%] [G loss: 0.949252]\n",
      "epoch:0 step:357 [D loss: 0.591645, acc.: 65.62%] [G loss: 1.089560]\n",
      "epoch:0 step:358 [D loss: 0.500681, acc.: 73.44%] [G loss: 1.147032]\n",
      "epoch:0 step:359 [D loss: 0.571476, acc.: 71.09%] [G loss: 0.979700]\n",
      "epoch:0 step:360 [D loss: 0.536713, acc.: 72.66%] [G loss: 0.641554]\n",
      "epoch:0 step:361 [D loss: 0.395134, acc.: 86.72%] [G loss: 0.904447]\n",
      "epoch:0 step:362 [D loss: 0.562773, acc.: 71.09%] [G loss: 0.747731]\n",
      "epoch:0 step:363 [D loss: 0.473287, acc.: 78.12%] [G loss: 0.632814]\n",
      "epoch:0 step:364 [D loss: 0.513540, acc.: 76.56%] [G loss: 0.693144]\n",
      "epoch:0 step:365 [D loss: 0.605042, acc.: 69.53%] [G loss: 1.013485]\n",
      "epoch:0 step:366 [D loss: 0.676568, acc.: 67.19%] [G loss: 0.952760]\n",
      "epoch:0 step:367 [D loss: 0.575463, acc.: 71.09%] [G loss: 0.608514]\n",
      "epoch:0 step:368 [D loss: 0.624869, acc.: 64.06%] [G loss: 0.574710]\n",
      "epoch:0 step:369 [D loss: 0.585549, acc.: 66.41%] [G loss: 0.790049]\n",
      "epoch:0 step:370 [D loss: 0.766341, acc.: 53.91%] [G loss: 0.731354]\n",
      "epoch:0 step:371 [D loss: 0.998417, acc.: 42.19%] [G loss: 0.668386]\n",
      "epoch:0 step:372 [D loss: 0.904913, acc.: 46.09%] [G loss: 0.875675]\n",
      "epoch:0 step:373 [D loss: 0.965364, acc.: 37.50%] [G loss: 0.921550]\n",
      "epoch:0 step:374 [D loss: 0.763166, acc.: 57.03%] [G loss: 0.960285]\n",
      "epoch:0 step:375 [D loss: 0.758200, acc.: 53.12%] [G loss: 1.065310]\n",
      "epoch:0 step:376 [D loss: 0.789618, acc.: 50.78%] [G loss: 0.956890]\n",
      "epoch:0 step:377 [D loss: 0.981360, acc.: 39.06%] [G loss: 1.005606]\n",
      "epoch:0 step:378 [D loss: 0.883618, acc.: 47.66%] [G loss: 0.971565]\n",
      "epoch:0 step:379 [D loss: 0.792404, acc.: 49.22%] [G loss: 1.073924]\n",
      "epoch:0 step:380 [D loss: 0.842290, acc.: 50.78%] [G loss: 1.011283]\n",
      "epoch:0 step:381 [D loss: 0.788179, acc.: 56.25%] [G loss: 0.879575]\n",
      "epoch:0 step:382 [D loss: 0.845621, acc.: 46.09%] [G loss: 0.899488]\n",
      "epoch:0 step:383 [D loss: 0.750182, acc.: 58.59%] [G loss: 0.858978]\n",
      "epoch:0 step:384 [D loss: 0.843344, acc.: 49.22%] [G loss: 0.833480]\n",
      "epoch:0 step:385 [D loss: 0.662248, acc.: 57.03%] [G loss: 0.900866]\n",
      "epoch:0 step:386 [D loss: 0.763306, acc.: 52.34%] [G loss: 1.028995]\n",
      "epoch:0 step:387 [D loss: 0.711924, acc.: 56.25%] [G loss: 1.053843]\n",
      "epoch:0 step:388 [D loss: 0.796117, acc.: 45.31%] [G loss: 0.934804]\n",
      "epoch:0 step:389 [D loss: 0.775076, acc.: 53.91%] [G loss: 0.963582]\n",
      "epoch:0 step:390 [D loss: 0.715653, acc.: 57.03%] [G loss: 1.060184]\n",
      "epoch:0 step:391 [D loss: 0.800566, acc.: 53.12%] [G loss: 0.954758]\n",
      "epoch:0 step:392 [D loss: 0.678008, acc.: 58.59%] [G loss: 1.138268]\n",
      "epoch:0 step:393 [D loss: 0.650983, acc.: 62.50%] [G loss: 1.150595]\n",
      "epoch:0 step:394 [D loss: 0.612380, acc.: 66.41%] [G loss: 1.112142]\n",
      "epoch:0 step:395 [D loss: 0.652095, acc.: 65.62%] [G loss: 1.068546]\n",
      "epoch:0 step:396 [D loss: 0.732711, acc.: 61.72%] [G loss: 1.039233]\n",
      "epoch:0 step:397 [D loss: 0.664219, acc.: 60.94%] [G loss: 1.097544]\n",
      "epoch:0 step:398 [D loss: 0.754250, acc.: 56.25%] [G loss: 1.094459]\n",
      "epoch:0 step:399 [D loss: 0.554767, acc.: 70.31%] [G loss: 0.996972]\n",
      "epoch:0 step:400 [D loss: 0.744196, acc.: 51.56%] [G loss: 1.018305]\n",
      "epoch:0 step:401 [D loss: 0.718652, acc.: 52.34%] [G loss: 1.154461]\n",
      "epoch:0 step:402 [D loss: 0.730026, acc.: 53.91%] [G loss: 1.087555]\n",
      "epoch:0 step:403 [D loss: 0.741615, acc.: 50.00%] [G loss: 1.079210]\n",
      "epoch:0 step:404 [D loss: 0.630679, acc.: 62.50%] [G loss: 1.195955]\n",
      "epoch:0 step:405 [D loss: 0.739544, acc.: 50.00%] [G loss: 1.039112]\n",
      "epoch:0 step:406 [D loss: 0.627235, acc.: 69.53%] [G loss: 1.166849]\n",
      "epoch:0 step:407 [D loss: 0.594944, acc.: 67.19%] [G loss: 1.202431]\n",
      "epoch:0 step:408 [D loss: 0.582506, acc.: 67.19%] [G loss: 1.166796]\n",
      "epoch:0 step:409 [D loss: 0.605678, acc.: 70.31%] [G loss: 1.018782]\n",
      "epoch:0 step:410 [D loss: 0.579054, acc.: 70.31%] [G loss: 1.026908]\n",
      "epoch:0 step:411 [D loss: 0.777897, acc.: 57.81%] [G loss: 1.052890]\n",
      "epoch:0 step:412 [D loss: 0.643326, acc.: 61.72%] [G loss: 0.992334]\n",
      "epoch:0 step:413 [D loss: 0.642843, acc.: 59.38%] [G loss: 0.912836]\n",
      "epoch:0 step:414 [D loss: 0.635710, acc.: 63.28%] [G loss: 1.074461]\n",
      "epoch:0 step:415 [D loss: 0.653775, acc.: 60.94%] [G loss: 0.868564]\n",
      "epoch:0 step:416 [D loss: 0.699799, acc.: 59.38%] [G loss: 0.969877]\n",
      "epoch:0 step:417 [D loss: 0.704113, acc.: 63.28%] [G loss: 0.895922]\n",
      "epoch:0 step:418 [D loss: 0.720854, acc.: 56.25%] [G loss: 0.960738]\n",
      "epoch:0 step:419 [D loss: 0.755282, acc.: 54.69%] [G loss: 0.976618]\n",
      "epoch:0 step:420 [D loss: 0.748637, acc.: 50.78%] [G loss: 0.859169]\n",
      "epoch:0 step:421 [D loss: 0.725568, acc.: 56.25%] [G loss: 0.909581]\n",
      "epoch:0 step:422 [D loss: 0.626607, acc.: 67.19%] [G loss: 1.191039]\n",
      "epoch:0 step:423 [D loss: 0.680134, acc.: 60.16%] [G loss: 1.101070]\n",
      "epoch:0 step:424 [D loss: 0.841181, acc.: 43.75%] [G loss: 1.082014]\n",
      "epoch:0 step:425 [D loss: 0.664700, acc.: 62.50%] [G loss: 1.085904]\n",
      "epoch:0 step:426 [D loss: 0.781929, acc.: 45.31%] [G loss: 1.068292]\n",
      "epoch:0 step:427 [D loss: 0.700574, acc.: 58.59%] [G loss: 0.936728]\n",
      "epoch:0 step:428 [D loss: 0.683078, acc.: 58.59%] [G loss: 1.035296]\n",
      "epoch:0 step:429 [D loss: 0.972612, acc.: 35.94%] [G loss: 0.714870]\n",
      "epoch:0 step:430 [D loss: 0.744340, acc.: 54.69%] [G loss: 0.832257]\n",
      "epoch:0 step:431 [D loss: 0.779871, acc.: 54.69%] [G loss: 0.985156]\n",
      "epoch:0 step:432 [D loss: 0.944491, acc.: 39.84%] [G loss: 1.224447]\n",
      "epoch:0 step:433 [D loss: 0.856483, acc.: 45.31%] [G loss: 1.047495]\n",
      "epoch:0 step:434 [D loss: 0.839182, acc.: 46.09%] [G loss: 0.801425]\n",
      "epoch:0 step:435 [D loss: 0.753390, acc.: 52.34%] [G loss: 0.810059]\n",
      "epoch:0 step:436 [D loss: 0.848154, acc.: 41.41%] [G loss: 0.858450]\n",
      "epoch:0 step:437 [D loss: 0.776003, acc.: 53.91%] [G loss: 0.970273]\n",
      "epoch:0 step:438 [D loss: 0.792259, acc.: 50.00%] [G loss: 0.939299]\n",
      "epoch:0 step:439 [D loss: 0.721171, acc.: 53.91%] [G loss: 0.966464]\n",
      "epoch:0 step:440 [D loss: 0.739674, acc.: 54.69%] [G loss: 0.776717]\n",
      "epoch:0 step:441 [D loss: 0.762161, acc.: 53.91%] [G loss: 0.735098]\n",
      "epoch:0 step:442 [D loss: 0.729235, acc.: 55.47%] [G loss: 0.836592]\n",
      "epoch:0 step:443 [D loss: 0.726820, acc.: 55.47%] [G loss: 0.855409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:444 [D loss: 0.821088, acc.: 53.12%] [G loss: 0.621204]\n",
      "epoch:0 step:445 [D loss: 0.718759, acc.: 56.25%] [G loss: 0.801761]\n",
      "epoch:0 step:446 [D loss: 0.898220, acc.: 45.31%] [G loss: 0.718948]\n",
      "epoch:0 step:447 [D loss: 0.850041, acc.: 43.75%] [G loss: 0.864797]\n",
      "epoch:0 step:448 [D loss: 0.662485, acc.: 64.06%] [G loss: 0.708841]\n",
      "epoch:0 step:449 [D loss: 0.896159, acc.: 41.41%] [G loss: 0.869062]\n",
      "epoch:0 step:450 [D loss: 0.777049, acc.: 49.22%] [G loss: 0.816665]\n",
      "epoch:0 step:451 [D loss: 0.903438, acc.: 42.97%] [G loss: 0.863945]\n",
      "epoch:0 step:452 [D loss: 0.800169, acc.: 49.22%] [G loss: 1.017660]\n",
      "epoch:0 step:453 [D loss: 0.901928, acc.: 41.41%] [G loss: 1.021122]\n",
      "epoch:0 step:454 [D loss: 0.675484, acc.: 60.16%] [G loss: 0.980894]\n",
      "epoch:0 step:455 [D loss: 0.819976, acc.: 50.00%] [G loss: 1.124477]\n",
      "epoch:0 step:456 [D loss: 0.797762, acc.: 45.31%] [G loss: 0.951136]\n",
      "epoch:0 step:457 [D loss: 0.797481, acc.: 46.88%] [G loss: 0.949239]\n",
      "epoch:0 step:458 [D loss: 0.734666, acc.: 50.78%] [G loss: 0.948009]\n",
      "epoch:0 step:459 [D loss: 0.779063, acc.: 45.31%] [G loss: 0.934516]\n",
      "epoch:0 step:460 [D loss: 0.771757, acc.: 46.88%] [G loss: 0.796004]\n",
      "epoch:0 step:461 [D loss: 0.811947, acc.: 46.09%] [G loss: 0.858401]\n",
      "epoch:0 step:462 [D loss: 0.775468, acc.: 50.78%] [G loss: 0.868191]\n",
      "epoch:0 step:463 [D loss: 0.695379, acc.: 59.38%] [G loss: 0.922943]\n",
      "epoch:0 step:464 [D loss: 0.851165, acc.: 42.19%] [G loss: 0.855380]\n",
      "epoch:0 step:465 [D loss: 0.789651, acc.: 49.22%] [G loss: 0.831413]\n",
      "epoch:0 step:466 [D loss: 0.712748, acc.: 53.12%] [G loss: 0.870129]\n",
      "epoch:0 step:467 [D loss: 0.766774, acc.: 51.56%] [G loss: 0.974859]\n",
      "epoch:0 step:468 [D loss: 0.831373, acc.: 43.75%] [G loss: 0.872196]\n",
      "epoch:0 step:469 [D loss: 0.761696, acc.: 52.34%] [G loss: 0.835291]\n",
      "epoch:0 step:470 [D loss: 0.676201, acc.: 61.72%] [G loss: 0.898856]\n",
      "epoch:0 step:471 [D loss: 0.799671, acc.: 48.44%] [G loss: 0.789893]\n",
      "epoch:0 step:472 [D loss: 0.791896, acc.: 46.88%] [G loss: 0.942082]\n",
      "epoch:0 step:473 [D loss: 0.700599, acc.: 55.47%] [G loss: 1.032872]\n",
      "epoch:0 step:474 [D loss: 0.707627, acc.: 57.03%] [G loss: 0.940173]\n",
      "epoch:0 step:475 [D loss: 0.658069, acc.: 58.59%] [G loss: 0.846110]\n",
      "epoch:0 step:476 [D loss: 0.625949, acc.: 69.53%] [G loss: 0.843005]\n",
      "epoch:0 step:477 [D loss: 0.661720, acc.: 62.50%] [G loss: 0.837807]\n",
      "epoch:0 step:478 [D loss: 0.785199, acc.: 53.12%] [G loss: 0.958365]\n",
      "epoch:0 step:479 [D loss: 0.648895, acc.: 69.53%] [G loss: 1.003898]\n",
      "epoch:0 step:480 [D loss: 0.670239, acc.: 63.28%] [G loss: 0.925370]\n",
      "epoch:0 step:481 [D loss: 0.670309, acc.: 63.28%] [G loss: 0.798942]\n",
      "epoch:0 step:482 [D loss: 0.635023, acc.: 60.94%] [G loss: 0.703667]\n",
      "epoch:0 step:483 [D loss: 0.720850, acc.: 60.94%] [G loss: 0.788607]\n",
      "epoch:0 step:484 [D loss: 0.794333, acc.: 51.56%] [G loss: 0.914441]\n",
      "epoch:0 step:485 [D loss: 0.714389, acc.: 62.50%] [G loss: 0.979693]\n",
      "epoch:0 step:486 [D loss: 0.669964, acc.: 60.16%] [G loss: 0.940170]\n",
      "epoch:0 step:487 [D loss: 0.661972, acc.: 65.62%] [G loss: 0.900357]\n",
      "epoch:0 step:488 [D loss: 0.646671, acc.: 60.94%] [G loss: 0.893110]\n",
      "epoch:0 step:489 [D loss: 0.724544, acc.: 52.34%] [G loss: 1.012626]\n",
      "epoch:0 step:490 [D loss: 0.732047, acc.: 53.12%] [G loss: 1.055491]\n",
      "epoch:0 step:491 [D loss: 0.710336, acc.: 56.25%] [G loss: 1.116373]\n",
      "epoch:0 step:492 [D loss: 0.641762, acc.: 61.72%] [G loss: 1.193930]\n",
      "epoch:0 step:493 [D loss: 0.714814, acc.: 54.69%] [G loss: 0.953413]\n",
      "epoch:0 step:494 [D loss: 0.718343, acc.: 55.47%] [G loss: 0.916920]\n",
      "epoch:0 step:495 [D loss: 0.623369, acc.: 67.97%] [G loss: 1.162985]\n",
      "epoch:0 step:496 [D loss: 0.694129, acc.: 57.03%] [G loss: 1.063711]\n",
      "epoch:0 step:497 [D loss: 0.631858, acc.: 64.06%] [G loss: 1.009392]\n",
      "epoch:0 step:498 [D loss: 0.655318, acc.: 65.62%] [G loss: 0.906841]\n",
      "epoch:0 step:499 [D loss: 0.686193, acc.: 56.25%] [G loss: 0.985416]\n",
      "epoch:0 step:500 [D loss: 0.748450, acc.: 55.47%] [G loss: 1.057673]\n",
      "epoch:0 step:501 [D loss: 0.642046, acc.: 64.06%] [G loss: 1.043516]\n",
      "epoch:0 step:502 [D loss: 0.689519, acc.: 51.56%] [G loss: 0.970951]\n",
      "epoch:0 step:503 [D loss: 0.659697, acc.: 60.94%] [G loss: 1.084250]\n",
      "epoch:0 step:504 [D loss: 0.772897, acc.: 54.69%] [G loss: 1.061890]\n",
      "epoch:0 step:505 [D loss: 0.645205, acc.: 64.06%] [G loss: 1.022125]\n",
      "epoch:0 step:506 [D loss: 0.766244, acc.: 53.91%] [G loss: 1.015924]\n",
      "epoch:0 step:507 [D loss: 0.664397, acc.: 61.72%] [G loss: 0.961774]\n",
      "epoch:0 step:508 [D loss: 0.644357, acc.: 62.50%] [G loss: 1.007138]\n",
      "epoch:0 step:509 [D loss: 0.686448, acc.: 64.06%] [G loss: 0.956274]\n",
      "epoch:0 step:510 [D loss: 0.644600, acc.: 67.97%] [G loss: 0.893353]\n",
      "epoch:0 step:511 [D loss: 0.756033, acc.: 54.69%] [G loss: 0.951544]\n",
      "epoch:0 step:512 [D loss: 0.633191, acc.: 66.41%] [G loss: 1.086583]\n",
      "epoch:0 step:513 [D loss: 0.699425, acc.: 57.81%] [G loss: 0.977271]\n",
      "epoch:0 step:514 [D loss: 0.708450, acc.: 56.25%] [G loss: 1.007891]\n",
      "epoch:0 step:515 [D loss: 0.825716, acc.: 45.31%] [G loss: 0.961973]\n",
      "epoch:0 step:516 [D loss: 0.746446, acc.: 59.38%] [G loss: 1.016682]\n",
      "epoch:0 step:517 [D loss: 0.773947, acc.: 54.69%] [G loss: 1.009481]\n",
      "epoch:0 step:518 [D loss: 0.757194, acc.: 57.81%] [G loss: 0.930188]\n",
      "epoch:0 step:519 [D loss: 0.813370, acc.: 50.00%] [G loss: 1.032337]\n",
      "epoch:0 step:520 [D loss: 0.692134, acc.: 50.78%] [G loss: 0.982268]\n",
      "epoch:0 step:521 [D loss: 0.859338, acc.: 46.09%] [G loss: 0.868643]\n",
      "epoch:0 step:522 [D loss: 0.747467, acc.: 52.34%] [G loss: 0.934380]\n",
      "epoch:0 step:523 [D loss: 0.775024, acc.: 55.47%] [G loss: 0.810392]\n",
      "epoch:0 step:524 [D loss: 0.819548, acc.: 50.00%] [G loss: 0.982321]\n",
      "epoch:0 step:525 [D loss: 0.713243, acc.: 56.25%] [G loss: 1.134005]\n",
      "epoch:0 step:526 [D loss: 0.799799, acc.: 46.09%] [G loss: 1.065937]\n",
      "epoch:0 step:527 [D loss: 0.639407, acc.: 60.94%] [G loss: 1.001631]\n",
      "epoch:0 step:528 [D loss: 0.755905, acc.: 53.91%] [G loss: 1.007591]\n",
      "epoch:0 step:529 [D loss: 0.642409, acc.: 62.50%] [G loss: 0.773551]\n",
      "epoch:0 step:530 [D loss: 0.747526, acc.: 55.47%] [G loss: 0.722713]\n",
      "epoch:0 step:531 [D loss: 0.775383, acc.: 49.22%] [G loss: 0.714833]\n",
      "epoch:0 step:532 [D loss: 0.617095, acc.: 67.19%] [G loss: 0.777387]\n",
      "epoch:0 step:533 [D loss: 0.625025, acc.: 66.41%] [G loss: 0.942399]\n",
      "epoch:0 step:534 [D loss: 0.784692, acc.: 45.31%] [G loss: 0.862855]\n",
      "epoch:0 step:535 [D loss: 0.708647, acc.: 59.38%] [G loss: 0.981414]\n",
      "epoch:0 step:536 [D loss: 0.701416, acc.: 58.59%] [G loss: 0.896555]\n",
      "epoch:0 step:537 [D loss: 0.669065, acc.: 64.84%] [G loss: 0.867905]\n",
      "epoch:0 step:538 [D loss: 0.725813, acc.: 53.91%] [G loss: 0.953202]\n",
      "epoch:0 step:539 [D loss: 0.809328, acc.: 46.09%] [G loss: 0.963553]\n",
      "epoch:0 step:540 [D loss: 0.711558, acc.: 54.69%] [G loss: 1.037183]\n",
      "epoch:0 step:541 [D loss: 0.618351, acc.: 68.75%] [G loss: 1.179547]\n",
      "epoch:0 step:542 [D loss: 0.834491, acc.: 47.66%] [G loss: 0.869953]\n",
      "epoch:0 step:543 [D loss: 0.685131, acc.: 59.38%] [G loss: 0.837013]\n",
      "epoch:0 step:544 [D loss: 0.685030, acc.: 57.81%] [G loss: 0.956596]\n",
      "epoch:0 step:545 [D loss: 0.830822, acc.: 50.00%] [G loss: 0.984723]\n",
      "epoch:0 step:546 [D loss: 0.660105, acc.: 60.16%] [G loss: 1.089768]\n",
      "epoch:0 step:547 [D loss: 0.750803, acc.: 51.56%] [G loss: 0.970423]\n",
      "epoch:0 step:548 [D loss: 0.646355, acc.: 60.94%] [G loss: 0.949228]\n",
      "epoch:0 step:549 [D loss: 0.567821, acc.: 71.88%] [G loss: 0.963077]\n",
      "epoch:0 step:550 [D loss: 0.746534, acc.: 52.34%] [G loss: 0.906073]\n",
      "epoch:0 step:551 [D loss: 0.618304, acc.: 71.09%] [G loss: 0.858629]\n",
      "epoch:0 step:552 [D loss: 0.713476, acc.: 60.16%] [G loss: 0.857144]\n",
      "epoch:0 step:553 [D loss: 0.637203, acc.: 63.28%] [G loss: 0.929276]\n",
      "epoch:0 step:554 [D loss: 0.713125, acc.: 57.03%] [G loss: 0.784301]\n",
      "epoch:0 step:555 [D loss: 0.740780, acc.: 54.69%] [G loss: 0.883942]\n",
      "epoch:0 step:556 [D loss: 0.712544, acc.: 53.91%] [G loss: 0.989229]\n",
      "epoch:0 step:557 [D loss: 0.805019, acc.: 53.91%] [G loss: 1.011002]\n",
      "epoch:0 step:558 [D loss: 0.701464, acc.: 60.16%] [G loss: 1.070461]\n",
      "epoch:0 step:559 [D loss: 0.767395, acc.: 50.00%] [G loss: 1.016484]\n",
      "epoch:0 step:560 [D loss: 0.656220, acc.: 67.19%] [G loss: 0.867750]\n",
      "epoch:0 step:561 [D loss: 0.640980, acc.: 62.50%] [G loss: 0.722728]\n",
      "epoch:0 step:562 [D loss: 0.673002, acc.: 59.38%] [G loss: 0.957981]\n",
      "epoch:0 step:563 [D loss: 0.630738, acc.: 67.19%] [G loss: 0.923672]\n",
      "epoch:0 step:564 [D loss: 0.703897, acc.: 54.69%] [G loss: 0.793677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:565 [D loss: 0.807522, acc.: 47.66%] [G loss: 1.098747]\n",
      "epoch:0 step:566 [D loss: 0.652874, acc.: 59.38%] [G loss: 1.046451]\n",
      "epoch:0 step:567 [D loss: 0.829951, acc.: 39.06%] [G loss: 0.869849]\n",
      "epoch:0 step:568 [D loss: 0.644542, acc.: 67.19%] [G loss: 1.123909]\n",
      "epoch:0 step:569 [D loss: 0.673868, acc.: 59.38%] [G loss: 1.001199]\n",
      "epoch:0 step:570 [D loss: 0.648597, acc.: 59.38%] [G loss: 1.005943]\n",
      "epoch:0 step:571 [D loss: 0.781798, acc.: 48.44%] [G loss: 0.997034]\n",
      "epoch:0 step:572 [D loss: 0.617566, acc.: 69.53%] [G loss: 0.929023]\n",
      "epoch:0 step:573 [D loss: 0.665497, acc.: 62.50%] [G loss: 0.722420]\n",
      "epoch:0 step:574 [D loss: 0.665697, acc.: 60.94%] [G loss: 0.786766]\n",
      "epoch:0 step:575 [D loss: 0.643779, acc.: 66.41%] [G loss: 0.873168]\n",
      "epoch:0 step:576 [D loss: 0.727820, acc.: 53.91%] [G loss: 0.882454]\n",
      "epoch:0 step:577 [D loss: 0.702877, acc.: 58.59%] [G loss: 0.903294]\n",
      "epoch:0 step:578 [D loss: 0.755672, acc.: 56.25%] [G loss: 0.801032]\n",
      "epoch:0 step:579 [D loss: 0.724254, acc.: 53.12%] [G loss: 0.905379]\n",
      "epoch:0 step:580 [D loss: 0.722734, acc.: 61.72%] [G loss: 1.066489]\n",
      "epoch:0 step:581 [D loss: 0.846348, acc.: 46.88%] [G loss: 0.860165]\n",
      "epoch:0 step:582 [D loss: 0.658353, acc.: 60.94%] [G loss: 0.965293]\n",
      "epoch:0 step:583 [D loss: 0.652563, acc.: 66.41%] [G loss: 0.876198]\n",
      "epoch:0 step:584 [D loss: 0.747275, acc.: 53.91%] [G loss: 0.898648]\n",
      "epoch:0 step:585 [D loss: 0.657629, acc.: 60.16%] [G loss: 0.816664]\n",
      "epoch:0 step:586 [D loss: 0.635733, acc.: 64.84%] [G loss: 0.887797]\n",
      "epoch:0 step:587 [D loss: 0.740638, acc.: 49.22%] [G loss: 0.894180]\n",
      "epoch:0 step:588 [D loss: 0.780923, acc.: 48.44%] [G loss: 0.900275]\n",
      "epoch:0 step:589 [D loss: 0.765513, acc.: 54.69%] [G loss: 1.092072]\n",
      "epoch:0 step:590 [D loss: 0.719931, acc.: 53.91%] [G loss: 1.040575]\n",
      "epoch:0 step:591 [D loss: 0.726911, acc.: 58.59%] [G loss: 0.968123]\n",
      "epoch:0 step:592 [D loss: 0.727045, acc.: 53.12%] [G loss: 1.070931]\n",
      "epoch:0 step:593 [D loss: 0.784896, acc.: 54.69%] [G loss: 0.928161]\n",
      "epoch:0 step:594 [D loss: 0.648931, acc.: 62.50%] [G loss: 0.931706]\n",
      "epoch:0 step:595 [D loss: 0.716687, acc.: 53.91%] [G loss: 0.854182]\n",
      "epoch:0 step:596 [D loss: 0.818518, acc.: 45.31%] [G loss: 0.832527]\n",
      "epoch:0 step:597 [D loss: 0.836067, acc.: 45.31%] [G loss: 0.800908]\n",
      "epoch:0 step:598 [D loss: 0.757207, acc.: 52.34%] [G loss: 0.837053]\n",
      "epoch:0 step:599 [D loss: 0.670250, acc.: 57.81%] [G loss: 1.089002]\n",
      "epoch:0 step:600 [D loss: 0.715034, acc.: 54.69%] [G loss: 0.837140]\n",
      "epoch:0 step:601 [D loss: 0.629338, acc.: 61.72%] [G loss: 0.866630]\n",
      "epoch:0 step:602 [D loss: 0.640873, acc.: 58.59%] [G loss: 1.099869]\n",
      "epoch:0 step:603 [D loss: 0.746886, acc.: 51.56%] [G loss: 0.915533]\n",
      "epoch:0 step:604 [D loss: 0.675079, acc.: 63.28%] [G loss: 0.923078]\n",
      "epoch:0 step:605 [D loss: 0.622111, acc.: 68.75%] [G loss: 0.844336]\n",
      "epoch:0 step:606 [D loss: 0.729566, acc.: 51.56%] [G loss: 0.867685]\n",
      "epoch:0 step:607 [D loss: 0.648059, acc.: 60.16%] [G loss: 0.794514]\n",
      "epoch:0 step:608 [D loss: 0.654004, acc.: 57.81%] [G loss: 0.910524]\n",
      "epoch:0 step:609 [D loss: 0.671798, acc.: 60.16%] [G loss: 0.885197]\n",
      "epoch:0 step:610 [D loss: 0.708911, acc.: 59.38%] [G loss: 0.872105]\n",
      "epoch:0 step:611 [D loss: 0.771191, acc.: 48.44%] [G loss: 0.832646]\n",
      "epoch:0 step:612 [D loss: 0.735041, acc.: 52.34%] [G loss: 0.992230]\n",
      "epoch:0 step:613 [D loss: 0.771832, acc.: 50.78%] [G loss: 1.037780]\n",
      "epoch:0 step:614 [D loss: 0.777455, acc.: 51.56%] [G loss: 0.966664]\n",
      "epoch:0 step:615 [D loss: 0.921462, acc.: 43.75%] [G loss: 0.942016]\n",
      "epoch:0 step:616 [D loss: 0.774837, acc.: 50.00%] [G loss: 1.096011]\n",
      "epoch:0 step:617 [D loss: 0.799382, acc.: 46.09%] [G loss: 1.076282]\n",
      "epoch:0 step:618 [D loss: 0.774292, acc.: 50.00%] [G loss: 1.145416]\n",
      "epoch:0 step:619 [D loss: 0.751264, acc.: 50.78%] [G loss: 1.058455]\n",
      "epoch:0 step:620 [D loss: 0.729139, acc.: 57.81%] [G loss: 1.054163]\n",
      "epoch:0 step:621 [D loss: 0.763450, acc.: 48.44%] [G loss: 1.027120]\n",
      "epoch:0 step:622 [D loss: 0.680301, acc.: 54.69%] [G loss: 0.998017]\n",
      "epoch:0 step:623 [D loss: 0.731342, acc.: 57.03%] [G loss: 1.094498]\n",
      "epoch:0 step:624 [D loss: 0.642088, acc.: 63.28%] [G loss: 0.934734]\n",
      "epoch:0 step:625 [D loss: 0.731229, acc.: 58.59%] [G loss: 0.932079]\n",
      "epoch:0 step:626 [D loss: 0.836945, acc.: 45.31%] [G loss: 1.002758]\n",
      "epoch:0 step:627 [D loss: 0.779686, acc.: 48.44%] [G loss: 0.890290]\n",
      "epoch:0 step:628 [D loss: 0.751503, acc.: 55.47%] [G loss: 1.007332]\n",
      "epoch:0 step:629 [D loss: 0.672754, acc.: 66.41%] [G loss: 1.219316]\n",
      "epoch:0 step:630 [D loss: 0.803524, acc.: 50.78%] [G loss: 1.082776]\n",
      "epoch:0 step:631 [D loss: 0.834123, acc.: 48.44%] [G loss: 0.910332]\n",
      "epoch:0 step:632 [D loss: 0.787824, acc.: 48.44%] [G loss: 0.938124]\n",
      "epoch:0 step:633 [D loss: 0.798755, acc.: 53.12%] [G loss: 1.189388]\n",
      "epoch:0 step:634 [D loss: 0.767765, acc.: 53.12%] [G loss: 0.858043]\n",
      "epoch:0 step:635 [D loss: 0.697989, acc.: 57.81%] [G loss: 0.948212]\n",
      "epoch:0 step:636 [D loss: 0.756031, acc.: 51.56%] [G loss: 1.117523]\n",
      "epoch:0 step:637 [D loss: 0.709498, acc.: 55.47%] [G loss: 1.030533]\n",
      "epoch:0 step:638 [D loss: 0.718196, acc.: 60.94%] [G loss: 1.049180]\n",
      "epoch:0 step:639 [D loss: 0.694129, acc.: 56.25%] [G loss: 0.933141]\n",
      "epoch:0 step:640 [D loss: 0.611909, acc.: 65.62%] [G loss: 1.090477]\n",
      "epoch:0 step:641 [D loss: 0.760927, acc.: 50.78%] [G loss: 0.954939]\n",
      "epoch:0 step:642 [D loss: 0.707921, acc.: 61.72%] [G loss: 0.934134]\n",
      "epoch:0 step:643 [D loss: 0.721480, acc.: 50.00%] [G loss: 0.896898]\n",
      "epoch:0 step:644 [D loss: 0.644432, acc.: 66.41%] [G loss: 0.966734]\n",
      "epoch:0 step:645 [D loss: 0.767634, acc.: 51.56%] [G loss: 0.835253]\n",
      "epoch:0 step:646 [D loss: 0.645316, acc.: 65.62%] [G loss: 0.933058]\n",
      "epoch:0 step:647 [D loss: 0.660733, acc.: 59.38%] [G loss: 0.971137]\n",
      "epoch:0 step:648 [D loss: 0.743473, acc.: 50.78%] [G loss: 0.789886]\n",
      "epoch:0 step:649 [D loss: 0.634553, acc.: 68.75%] [G loss: 0.991593]\n",
      "epoch:0 step:650 [D loss: 0.794964, acc.: 53.12%] [G loss: 0.953486]\n",
      "epoch:0 step:651 [D loss: 0.773078, acc.: 49.22%] [G loss: 0.866154]\n",
      "epoch:0 step:652 [D loss: 0.761251, acc.: 53.12%] [G loss: 0.949459]\n",
      "epoch:0 step:653 [D loss: 0.627433, acc.: 64.06%] [G loss: 0.996824]\n",
      "epoch:0 step:654 [D loss: 0.760905, acc.: 47.66%] [G loss: 0.920394]\n",
      "epoch:0 step:655 [D loss: 0.827275, acc.: 43.75%] [G loss: 1.035089]\n",
      "epoch:0 step:656 [D loss: 0.704854, acc.: 56.25%] [G loss: 1.028157]\n",
      "epoch:0 step:657 [D loss: 0.669398, acc.: 57.03%] [G loss: 0.980896]\n",
      "epoch:0 step:658 [D loss: 0.689536, acc.: 50.78%] [G loss: 0.825152]\n",
      "epoch:0 step:659 [D loss: 0.725823, acc.: 57.81%] [G loss: 0.770083]\n",
      "epoch:0 step:660 [D loss: 0.779311, acc.: 50.00%] [G loss: 0.861479]\n",
      "epoch:0 step:661 [D loss: 0.792348, acc.: 47.66%] [G loss: 0.821608]\n",
      "epoch:0 step:662 [D loss: 0.655710, acc.: 55.47%] [G loss: 0.806838]\n",
      "epoch:0 step:663 [D loss: 0.699960, acc.: 52.34%] [G loss: 0.743861]\n",
      "epoch:0 step:664 [D loss: 0.697656, acc.: 57.81%] [G loss: 0.848844]\n",
      "epoch:0 step:665 [D loss: 0.799541, acc.: 47.66%] [G loss: 0.716934]\n",
      "epoch:0 step:666 [D loss: 0.798175, acc.: 48.44%] [G loss: 0.768804]\n",
      "epoch:0 step:667 [D loss: 0.815527, acc.: 44.53%] [G loss: 0.957696]\n",
      "epoch:0 step:668 [D loss: 0.708977, acc.: 61.72%] [G loss: 0.846022]\n",
      "epoch:0 step:669 [D loss: 0.629792, acc.: 62.50%] [G loss: 0.774590]\n",
      "epoch:0 step:670 [D loss: 0.867754, acc.: 34.38%] [G loss: 0.629932]\n",
      "epoch:0 step:671 [D loss: 0.749084, acc.: 50.78%] [G loss: 0.910577]\n",
      "epoch:0 step:672 [D loss: 0.765678, acc.: 56.25%] [G loss: 1.082252]\n",
      "epoch:0 step:673 [D loss: 0.704257, acc.: 54.69%] [G loss: 1.117345]\n",
      "epoch:0 step:674 [D loss: 0.815197, acc.: 41.41%] [G loss: 0.930914]\n",
      "epoch:0 step:675 [D loss: 0.676605, acc.: 60.16%] [G loss: 0.960474]\n",
      "epoch:0 step:676 [D loss: 0.693517, acc.: 53.12%] [G loss: 0.992503]\n",
      "epoch:0 step:677 [D loss: 0.758375, acc.: 51.56%] [G loss: 0.899040]\n",
      "epoch:0 step:678 [D loss: 0.684381, acc.: 60.94%] [G loss: 1.175482]\n",
      "epoch:0 step:679 [D loss: 0.716190, acc.: 53.91%] [G loss: 1.110905]\n",
      "epoch:0 step:680 [D loss: 0.631224, acc.: 64.84%] [G loss: 1.061434]\n",
      "epoch:0 step:681 [D loss: 0.690050, acc.: 55.47%] [G loss: 1.038013]\n",
      "epoch:0 step:682 [D loss: 0.685831, acc.: 59.38%] [G loss: 0.978777]\n",
      "epoch:0 step:683 [D loss: 0.682633, acc.: 60.94%] [G loss: 0.925338]\n",
      "epoch:0 step:684 [D loss: 0.707910, acc.: 50.78%] [G loss: 0.846887]\n",
      "epoch:0 step:685 [D loss: 0.709692, acc.: 52.34%] [G loss: 0.968604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:686 [D loss: 0.693885, acc.: 57.81%] [G loss: 0.968691]\n",
      "epoch:0 step:687 [D loss: 0.755241, acc.: 48.44%] [G loss: 1.090862]\n",
      "epoch:0 step:688 [D loss: 0.603884, acc.: 70.31%] [G loss: 1.007507]\n",
      "epoch:0 step:689 [D loss: 0.589724, acc.: 70.31%] [G loss: 1.021573]\n",
      "epoch:0 step:690 [D loss: 0.569030, acc.: 71.88%] [G loss: 0.813625]\n",
      "epoch:0 step:691 [D loss: 0.538098, acc.: 74.22%] [G loss: 0.895222]\n",
      "epoch:0 step:692 [D loss: 0.596743, acc.: 72.66%] [G loss: 0.804304]\n",
      "epoch:0 step:693 [D loss: 0.489612, acc.: 80.47%] [G loss: 0.884285]\n",
      "epoch:0 step:694 [D loss: 0.636559, acc.: 66.41%] [G loss: 0.753602]\n",
      "epoch:0 step:695 [D loss: 0.632411, acc.: 62.50%] [G loss: 0.845936]\n",
      "epoch:0 step:696 [D loss: 0.616926, acc.: 63.28%] [G loss: 0.864708]\n",
      "epoch:0 step:697 [D loss: 0.741704, acc.: 55.47%] [G loss: 1.001481]\n",
      "epoch:0 step:698 [D loss: 0.592222, acc.: 68.75%] [G loss: 0.769201]\n",
      "epoch:0 step:699 [D loss: 0.777308, acc.: 43.75%] [G loss: 0.898512]\n",
      "epoch:0 step:700 [D loss: 0.574535, acc.: 70.31%] [G loss: 0.922033]\n",
      "epoch:0 step:701 [D loss: 0.663618, acc.: 55.47%] [G loss: 0.769835]\n",
      "epoch:0 step:702 [D loss: 0.702971, acc.: 53.91%] [G loss: 0.931766]\n",
      "epoch:0 step:703 [D loss: 0.699543, acc.: 57.81%] [G loss: 0.784619]\n",
      "epoch:0 step:704 [D loss: 0.609582, acc.: 65.62%] [G loss: 1.110502]\n",
      "epoch:0 step:705 [D loss: 0.664469, acc.: 59.38%] [G loss: 1.050739]\n",
      "epoch:0 step:706 [D loss: 0.640421, acc.: 68.75%] [G loss: 0.927834]\n",
      "epoch:0 step:707 [D loss: 0.653887, acc.: 65.62%] [G loss: 0.897274]\n",
      "epoch:0 step:708 [D loss: 0.555058, acc.: 70.31%] [G loss: 0.918036]\n",
      "epoch:0 step:709 [D loss: 0.622372, acc.: 61.72%] [G loss: 0.962505]\n",
      "epoch:0 step:710 [D loss: 0.720275, acc.: 50.78%] [G loss: 0.875476]\n",
      "epoch:0 step:711 [D loss: 0.579536, acc.: 68.75%] [G loss: 0.901152]\n",
      "epoch:0 step:712 [D loss: 0.700038, acc.: 60.16%] [G loss: 0.984078]\n",
      "epoch:0 step:713 [D loss: 0.718207, acc.: 53.12%] [G loss: 0.859923]\n",
      "epoch:0 step:714 [D loss: 0.666969, acc.: 62.50%] [G loss: 1.046823]\n",
      "epoch:0 step:715 [D loss: 0.850453, acc.: 42.97%] [G loss: 1.054105]\n",
      "epoch:0 step:716 [D loss: 0.689519, acc.: 58.59%] [G loss: 1.062209]\n",
      "epoch:0 step:717 [D loss: 0.637938, acc.: 58.59%] [G loss: 0.982782]\n",
      "epoch:0 step:718 [D loss: 0.735584, acc.: 57.03%] [G loss: 0.984061]\n",
      "epoch:0 step:719 [D loss: 0.734054, acc.: 50.78%] [G loss: 0.967780]\n",
      "epoch:0 step:720 [D loss: 0.736124, acc.: 50.00%] [G loss: 1.099930]\n",
      "epoch:0 step:721 [D loss: 0.642575, acc.: 60.94%] [G loss: 0.981666]\n",
      "epoch:0 step:722 [D loss: 0.674940, acc.: 63.28%] [G loss: 1.142314]\n",
      "epoch:0 step:723 [D loss: 0.772368, acc.: 46.88%] [G loss: 0.897089]\n",
      "epoch:0 step:724 [D loss: 0.766640, acc.: 45.31%] [G loss: 0.912390]\n",
      "epoch:0 step:725 [D loss: 0.690891, acc.: 57.81%] [G loss: 0.902464]\n",
      "epoch:0 step:726 [D loss: 0.697492, acc.: 59.38%] [G loss: 0.989619]\n",
      "epoch:0 step:727 [D loss: 0.744910, acc.: 52.34%] [G loss: 0.919847]\n",
      "epoch:0 step:728 [D loss: 0.720615, acc.: 54.69%] [G loss: 0.869569]\n",
      "epoch:0 step:729 [D loss: 0.738450, acc.: 50.78%] [G loss: 0.790195]\n",
      "epoch:0 step:730 [D loss: 0.747340, acc.: 55.47%] [G loss: 0.966156]\n",
      "epoch:0 step:731 [D loss: 0.691365, acc.: 56.25%] [G loss: 1.015121]\n",
      "epoch:0 step:732 [D loss: 0.528703, acc.: 75.78%] [G loss: 0.931314]\n",
      "epoch:0 step:733 [D loss: 0.585900, acc.: 68.75%] [G loss: 0.741415]\n",
      "epoch:0 step:734 [D loss: 0.666916, acc.: 54.69%] [G loss: 0.660915]\n",
      "epoch:0 step:735 [D loss: 0.678634, acc.: 58.59%] [G loss: 0.827010]\n",
      "epoch:0 step:736 [D loss: 0.727912, acc.: 50.78%] [G loss: 0.704877]\n",
      "epoch:0 step:737 [D loss: 0.738875, acc.: 54.69%] [G loss: 0.795066]\n",
      "epoch:0 step:738 [D loss: 0.739767, acc.: 48.44%] [G loss: 0.909960]\n",
      "epoch:0 step:739 [D loss: 0.653735, acc.: 59.38%] [G loss: 1.088523]\n",
      "epoch:0 step:740 [D loss: 0.788487, acc.: 46.09%] [G loss: 0.734992]\n",
      "epoch:0 step:741 [D loss: 0.789119, acc.: 47.66%] [G loss: 0.772310]\n",
      "epoch:0 step:742 [D loss: 0.807269, acc.: 50.78%] [G loss: 0.926378]\n",
      "epoch:0 step:743 [D loss: 0.684134, acc.: 63.28%] [G loss: 1.054558]\n",
      "epoch:0 step:744 [D loss: 0.527057, acc.: 72.66%] [G loss: 1.215140]\n",
      "epoch:0 step:745 [D loss: 0.564837, acc.: 72.66%] [G loss: 0.819052]\n",
      "epoch:0 step:746 [D loss: 0.761909, acc.: 53.91%] [G loss: 0.946024]\n",
      "epoch:0 step:747 [D loss: 0.702540, acc.: 56.25%] [G loss: 0.888557]\n",
      "epoch:0 step:748 [D loss: 0.690923, acc.: 57.81%] [G loss: 0.961304]\n",
      "epoch:0 step:749 [D loss: 0.673381, acc.: 57.03%] [G loss: 0.900917]\n",
      "epoch:0 step:750 [D loss: 0.790924, acc.: 47.66%] [G loss: 0.863286]\n",
      "epoch:0 step:751 [D loss: 0.769655, acc.: 53.12%] [G loss: 1.026436]\n",
      "epoch:0 step:752 [D loss: 0.643517, acc.: 61.72%] [G loss: 1.087512]\n",
      "epoch:0 step:753 [D loss: 0.901348, acc.: 39.06%] [G loss: 0.847531]\n",
      "epoch:0 step:754 [D loss: 0.718608, acc.: 57.81%] [G loss: 1.040933]\n",
      "epoch:0 step:755 [D loss: 0.756589, acc.: 50.78%] [G loss: 1.038241]\n",
      "epoch:0 step:756 [D loss: 0.838116, acc.: 39.06%] [G loss: 0.845419]\n",
      "epoch:0 step:757 [D loss: 0.695468, acc.: 54.69%] [G loss: 0.996937]\n",
      "epoch:0 step:758 [D loss: 0.626036, acc.: 64.84%] [G loss: 1.068645]\n",
      "epoch:0 step:759 [D loss: 0.822914, acc.: 43.75%] [G loss: 0.956269]\n",
      "epoch:0 step:760 [D loss: 0.726895, acc.: 57.03%] [G loss: 0.902392]\n",
      "epoch:0 step:761 [D loss: 0.679692, acc.: 59.38%] [G loss: 1.052949]\n",
      "epoch:0 step:762 [D loss: 0.707251, acc.: 57.81%] [G loss: 0.933648]\n",
      "epoch:0 step:763 [D loss: 0.712170, acc.: 57.03%] [G loss: 0.947450]\n",
      "epoch:0 step:764 [D loss: 0.640380, acc.: 57.81%] [G loss: 0.904338]\n",
      "epoch:0 step:765 [D loss: 0.823701, acc.: 42.19%] [G loss: 0.905077]\n",
      "epoch:0 step:766 [D loss: 0.731722, acc.: 53.12%] [G loss: 0.984119]\n",
      "epoch:0 step:767 [D loss: 0.717404, acc.: 50.78%] [G loss: 0.918859]\n",
      "epoch:0 step:768 [D loss: 0.771924, acc.: 46.88%] [G loss: 0.976873]\n",
      "epoch:0 step:769 [D loss: 0.692231, acc.: 57.03%] [G loss: 0.929908]\n",
      "epoch:0 step:770 [D loss: 0.727287, acc.: 52.34%] [G loss: 0.914450]\n",
      "epoch:0 step:771 [D loss: 0.722660, acc.: 56.25%] [G loss: 0.911115]\n",
      "epoch:0 step:772 [D loss: 0.695268, acc.: 53.12%] [G loss: 1.002805]\n",
      "epoch:0 step:773 [D loss: 0.661316, acc.: 63.28%] [G loss: 0.880527]\n",
      "epoch:0 step:774 [D loss: 0.552451, acc.: 73.44%] [G loss: 0.863422]\n",
      "epoch:0 step:775 [D loss: 0.607876, acc.: 67.19%] [G loss: 0.697513]\n",
      "epoch:0 step:776 [D loss: 0.611156, acc.: 67.19%] [G loss: 0.931316]\n",
      "epoch:0 step:777 [D loss: 0.675969, acc.: 58.59%] [G loss: 0.942237]\n",
      "epoch:0 step:778 [D loss: 0.754429, acc.: 49.22%] [G loss: 0.912240]\n",
      "epoch:0 step:779 [D loss: 0.686776, acc.: 57.81%] [G loss: 1.009400]\n",
      "epoch:0 step:780 [D loss: 0.695633, acc.: 53.91%] [G loss: 1.065955]\n",
      "epoch:0 step:781 [D loss: 0.713770, acc.: 59.38%] [G loss: 0.912056]\n",
      "epoch:1 step:782 [D loss: 0.763313, acc.: 49.22%] [G loss: 1.040273]\n",
      "epoch:1 step:783 [D loss: 0.578140, acc.: 65.62%] [G loss: 0.912909]\n",
      "epoch:1 step:784 [D loss: 0.740519, acc.: 53.12%] [G loss: 0.873142]\n",
      "epoch:1 step:785 [D loss: 0.624587, acc.: 62.50%] [G loss: 0.831658]\n",
      "epoch:1 step:786 [D loss: 0.705217, acc.: 57.81%] [G loss: 0.802398]\n",
      "epoch:1 step:787 [D loss: 0.806890, acc.: 42.97%] [G loss: 0.937496]\n",
      "epoch:1 step:788 [D loss: 0.753561, acc.: 52.34%] [G loss: 0.999060]\n",
      "epoch:1 step:789 [D loss: 0.771064, acc.: 42.19%] [G loss: 1.127227]\n",
      "epoch:1 step:790 [D loss: 0.761267, acc.: 53.91%] [G loss: 0.926785]\n",
      "epoch:1 step:791 [D loss: 0.814938, acc.: 45.31%] [G loss: 0.895528]\n",
      "epoch:1 step:792 [D loss: 0.674038, acc.: 57.03%] [G loss: 0.905027]\n",
      "epoch:1 step:793 [D loss: 0.736022, acc.: 56.25%] [G loss: 0.998451]\n",
      "epoch:1 step:794 [D loss: 0.798060, acc.: 48.44%] [G loss: 0.974450]\n",
      "epoch:1 step:795 [D loss: 0.694580, acc.: 56.25%] [G loss: 1.036919]\n",
      "epoch:1 step:796 [D loss: 0.713225, acc.: 60.16%] [G loss: 0.922552]\n",
      "epoch:1 step:797 [D loss: 0.645267, acc.: 62.50%] [G loss: 0.928287]\n",
      "epoch:1 step:798 [D loss: 0.660778, acc.: 61.72%] [G loss: 1.029013]\n",
      "epoch:1 step:799 [D loss: 0.672768, acc.: 56.25%] [G loss: 0.837734]\n",
      "epoch:1 step:800 [D loss: 0.691013, acc.: 56.25%] [G loss: 0.927435]\n",
      "epoch:1 step:801 [D loss: 0.641163, acc.: 63.28%] [G loss: 0.999005]\n",
      "epoch:1 step:802 [D loss: 0.621401, acc.: 71.09%] [G loss: 0.869197]\n",
      "epoch:1 step:803 [D loss: 0.657621, acc.: 64.06%] [G loss: 0.971728]\n",
      "epoch:1 step:804 [D loss: 0.678834, acc.: 56.25%] [G loss: 0.894072]\n",
      "epoch:1 step:805 [D loss: 0.622519, acc.: 67.19%] [G loss: 0.805566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:806 [D loss: 0.627069, acc.: 66.41%] [G loss: 0.805513]\n",
      "epoch:1 step:807 [D loss: 0.701546, acc.: 53.12%] [G loss: 0.659174]\n",
      "epoch:1 step:808 [D loss: 0.685224, acc.: 56.25%] [G loss: 0.735382]\n",
      "epoch:1 step:809 [D loss: 0.633870, acc.: 64.84%] [G loss: 0.798596]\n",
      "epoch:1 step:810 [D loss: 0.680965, acc.: 57.81%] [G loss: 0.809389]\n",
      "epoch:1 step:811 [D loss: 0.727451, acc.: 54.69%] [G loss: 0.735759]\n",
      "epoch:1 step:812 [D loss: 0.704929, acc.: 52.34%] [G loss: 0.788621]\n",
      "epoch:1 step:813 [D loss: 0.687896, acc.: 60.94%] [G loss: 0.779358]\n",
      "epoch:1 step:814 [D loss: 0.668953, acc.: 55.47%] [G loss: 0.797380]\n",
      "epoch:1 step:815 [D loss: 0.661697, acc.: 58.59%] [G loss: 0.807659]\n",
      "epoch:1 step:816 [D loss: 0.661696, acc.: 61.72%] [G loss: 0.920008]\n",
      "epoch:1 step:817 [D loss: 0.741284, acc.: 53.12%] [G loss: 0.965320]\n",
      "epoch:1 step:818 [D loss: 0.619437, acc.: 65.62%] [G loss: 0.958395]\n",
      "epoch:1 step:819 [D loss: 0.664332, acc.: 64.84%] [G loss: 0.800292]\n",
      "epoch:1 step:820 [D loss: 0.670124, acc.: 60.94%] [G loss: 0.918872]\n",
      "epoch:1 step:821 [D loss: 0.661816, acc.: 64.06%] [G loss: 0.896293]\n",
      "epoch:1 step:822 [D loss: 0.643605, acc.: 62.50%] [G loss: 1.054520]\n",
      "epoch:1 step:823 [D loss: 0.639520, acc.: 63.28%] [G loss: 0.955990]\n",
      "epoch:1 step:824 [D loss: 0.668864, acc.: 60.94%] [G loss: 0.880465]\n",
      "epoch:1 step:825 [D loss: 0.674173, acc.: 54.69%] [G loss: 0.854955]\n",
      "epoch:1 step:826 [D loss: 0.560061, acc.: 72.66%] [G loss: 0.905582]\n",
      "epoch:1 step:827 [D loss: 0.501543, acc.: 75.78%] [G loss: 1.030137]\n",
      "epoch:1 step:828 [D loss: 0.660740, acc.: 61.72%] [G loss: 0.875415]\n",
      "epoch:1 step:829 [D loss: 0.582788, acc.: 71.09%] [G loss: 0.957741]\n",
      "epoch:1 step:830 [D loss: 0.681484, acc.: 59.38%] [G loss: 0.803689]\n",
      "epoch:1 step:831 [D loss: 0.653485, acc.: 58.59%] [G loss: 0.829414]\n",
      "epoch:1 step:832 [D loss: 0.646932, acc.: 63.28%] [G loss: 0.990859]\n",
      "epoch:1 step:833 [D loss: 0.536427, acc.: 76.56%] [G loss: 0.985819]\n",
      "epoch:1 step:834 [D loss: 0.595970, acc.: 67.97%] [G loss: 0.798635]\n",
      "epoch:1 step:835 [D loss: 0.683416, acc.: 60.16%] [G loss: 0.918033]\n",
      "epoch:1 step:836 [D loss: 0.671918, acc.: 60.94%] [G loss: 0.924903]\n",
      "epoch:1 step:837 [D loss: 0.756655, acc.: 50.00%] [G loss: 0.943544]\n",
      "epoch:1 step:838 [D loss: 0.621738, acc.: 61.72%] [G loss: 0.791944]\n",
      "epoch:1 step:839 [D loss: 0.798859, acc.: 50.00%] [G loss: 0.861885]\n",
      "epoch:1 step:840 [D loss: 0.707235, acc.: 53.91%] [G loss: 0.878592]\n",
      "epoch:1 step:841 [D loss: 0.737112, acc.: 53.12%] [G loss: 0.957632]\n",
      "epoch:1 step:842 [D loss: 0.888577, acc.: 37.50%] [G loss: 1.025787]\n",
      "epoch:1 step:843 [D loss: 0.784411, acc.: 51.56%] [G loss: 0.932184]\n",
      "epoch:1 step:844 [D loss: 0.744755, acc.: 53.12%] [G loss: 1.083605]\n",
      "epoch:1 step:845 [D loss: 0.707144, acc.: 53.91%] [G loss: 1.022388]\n",
      "epoch:1 step:846 [D loss: 0.753235, acc.: 52.34%] [G loss: 0.948027]\n",
      "epoch:1 step:847 [D loss: 0.737643, acc.: 53.12%] [G loss: 0.877941]\n",
      "epoch:1 step:848 [D loss: 0.845374, acc.: 44.53%] [G loss: 0.803824]\n",
      "epoch:1 step:849 [D loss: 0.685284, acc.: 54.69%] [G loss: 0.873342]\n",
      "epoch:1 step:850 [D loss: 0.799794, acc.: 48.44%] [G loss: 0.846745]\n",
      "epoch:1 step:851 [D loss: 0.671970, acc.: 57.81%] [G loss: 0.852850]\n",
      "epoch:1 step:852 [D loss: 0.770942, acc.: 53.12%] [G loss: 0.902003]\n",
      "epoch:1 step:853 [D loss: 0.698149, acc.: 60.94%] [G loss: 0.898080]\n",
      "epoch:1 step:854 [D loss: 0.669803, acc.: 60.94%] [G loss: 1.008543]\n",
      "epoch:1 step:855 [D loss: 0.724325, acc.: 52.34%] [G loss: 0.857988]\n",
      "epoch:1 step:856 [D loss: 0.691697, acc.: 56.25%] [G loss: 0.922726]\n",
      "epoch:1 step:857 [D loss: 0.726135, acc.: 54.69%] [G loss: 1.080428]\n",
      "epoch:1 step:858 [D loss: 0.774999, acc.: 47.66%] [G loss: 0.920557]\n",
      "epoch:1 step:859 [D loss: 0.643865, acc.: 66.41%] [G loss: 0.849013]\n",
      "epoch:1 step:860 [D loss: 0.787279, acc.: 45.31%] [G loss: 0.844786]\n",
      "epoch:1 step:861 [D loss: 0.768430, acc.: 52.34%] [G loss: 1.029528]\n",
      "epoch:1 step:862 [D loss: 0.678586, acc.: 58.59%] [G loss: 1.031353]\n",
      "epoch:1 step:863 [D loss: 0.700482, acc.: 60.94%] [G loss: 0.887272]\n",
      "epoch:1 step:864 [D loss: 0.711108, acc.: 58.59%] [G loss: 0.810993]\n",
      "epoch:1 step:865 [D loss: 0.747688, acc.: 47.66%] [G loss: 0.826423]\n",
      "epoch:1 step:866 [D loss: 0.714082, acc.: 54.69%] [G loss: 0.825778]\n",
      "epoch:1 step:867 [D loss: 0.675485, acc.: 58.59%] [G loss: 0.834389]\n",
      "epoch:1 step:868 [D loss: 0.757937, acc.: 53.91%] [G loss: 0.905518]\n",
      "epoch:1 step:869 [D loss: 0.707366, acc.: 56.25%] [G loss: 0.911571]\n",
      "epoch:1 step:870 [D loss: 0.742272, acc.: 51.56%] [G loss: 0.881598]\n",
      "epoch:1 step:871 [D loss: 0.756405, acc.: 53.12%] [G loss: 1.037402]\n",
      "epoch:1 step:872 [D loss: 0.724849, acc.: 54.69%] [G loss: 0.869403]\n",
      "epoch:1 step:873 [D loss: 0.716444, acc.: 53.12%] [G loss: 0.821787]\n",
      "epoch:1 step:874 [D loss: 0.717166, acc.: 53.12%] [G loss: 1.015798]\n",
      "epoch:1 step:875 [D loss: 0.723614, acc.: 51.56%] [G loss: 0.834420]\n",
      "epoch:1 step:876 [D loss: 0.839800, acc.: 44.53%] [G loss: 0.878536]\n",
      "epoch:1 step:877 [D loss: 0.728043, acc.: 57.03%] [G loss: 0.859024]\n",
      "epoch:1 step:878 [D loss: 0.750409, acc.: 55.47%] [G loss: 0.973582]\n",
      "epoch:1 step:879 [D loss: 0.770495, acc.: 51.56%] [G loss: 0.987758]\n",
      "epoch:1 step:880 [D loss: 0.716429, acc.: 57.81%] [G loss: 0.956940]\n",
      "epoch:1 step:881 [D loss: 0.820951, acc.: 44.53%] [G loss: 0.902193]\n",
      "epoch:1 step:882 [D loss: 0.714789, acc.: 54.69%] [G loss: 0.787925]\n",
      "epoch:1 step:883 [D loss: 0.722969, acc.: 53.91%] [G loss: 0.787097]\n",
      "epoch:1 step:884 [D loss: 0.751934, acc.: 50.00%] [G loss: 0.858157]\n",
      "epoch:1 step:885 [D loss: 0.834521, acc.: 36.72%] [G loss: 0.797752]\n",
      "epoch:1 step:886 [D loss: 0.753107, acc.: 52.34%] [G loss: 0.755366]\n",
      "epoch:1 step:887 [D loss: 0.745337, acc.: 51.56%] [G loss: 0.862398]\n",
      "epoch:1 step:888 [D loss: 0.854751, acc.: 33.59%] [G loss: 0.791126]\n",
      "epoch:1 step:889 [D loss: 0.851721, acc.: 42.19%] [G loss: 0.815600]\n",
      "epoch:1 step:890 [D loss: 0.832706, acc.: 35.16%] [G loss: 0.898532]\n",
      "epoch:1 step:891 [D loss: 0.802176, acc.: 44.53%] [G loss: 0.862939]\n",
      "epoch:1 step:892 [D loss: 0.895769, acc.: 40.62%] [G loss: 0.835965]\n",
      "epoch:1 step:893 [D loss: 0.757785, acc.: 49.22%] [G loss: 0.919548]\n",
      "epoch:1 step:894 [D loss: 0.893056, acc.: 35.16%] [G loss: 0.891017]\n",
      "epoch:1 step:895 [D loss: 0.712995, acc.: 54.69%] [G loss: 0.978256]\n",
      "epoch:1 step:896 [D loss: 0.798132, acc.: 45.31%] [G loss: 0.881136]\n",
      "epoch:1 step:897 [D loss: 0.813003, acc.: 45.31%] [G loss: 0.730381]\n",
      "epoch:1 step:898 [D loss: 0.730673, acc.: 50.00%] [G loss: 0.980435]\n",
      "epoch:1 step:899 [D loss: 0.707978, acc.: 56.25%] [G loss: 0.995405]\n",
      "epoch:1 step:900 [D loss: 0.774241, acc.: 56.25%] [G loss: 0.827016]\n",
      "epoch:1 step:901 [D loss: 0.771406, acc.: 46.88%] [G loss: 0.864668]\n",
      "epoch:1 step:902 [D loss: 0.639433, acc.: 64.06%] [G loss: 0.945311]\n",
      "epoch:1 step:903 [D loss: 0.796478, acc.: 44.53%] [G loss: 0.778950]\n",
      "epoch:1 step:904 [D loss: 0.757068, acc.: 48.44%] [G loss: 0.745361]\n",
      "epoch:1 step:905 [D loss: 0.737680, acc.: 43.75%] [G loss: 0.781118]\n",
      "epoch:1 step:906 [D loss: 0.906633, acc.: 32.81%] [G loss: 0.675726]\n",
      "epoch:1 step:907 [D loss: 0.735293, acc.: 53.12%] [G loss: 0.972705]\n",
      "epoch:1 step:908 [D loss: 0.755283, acc.: 48.44%] [G loss: 0.804162]\n",
      "epoch:1 step:909 [D loss: 0.720629, acc.: 53.12%] [G loss: 0.805773]\n",
      "epoch:1 step:910 [D loss: 0.799846, acc.: 42.19%] [G loss: 0.812935]\n",
      "epoch:1 step:911 [D loss: 0.772250, acc.: 50.00%] [G loss: 0.822344]\n",
      "epoch:1 step:912 [D loss: 0.765881, acc.: 46.88%] [G loss: 0.803931]\n",
      "epoch:1 step:913 [D loss: 0.757067, acc.: 47.66%] [G loss: 0.816136]\n",
      "epoch:1 step:914 [D loss: 0.697641, acc.: 53.12%] [G loss: 1.032039]\n",
      "epoch:1 step:915 [D loss: 0.664017, acc.: 56.25%] [G loss: 0.966832]\n",
      "epoch:1 step:916 [D loss: 0.673243, acc.: 64.06%] [G loss: 0.829862]\n",
      "epoch:1 step:917 [D loss: 0.763456, acc.: 50.00%] [G loss: 0.819811]\n",
      "epoch:1 step:918 [D loss: 0.691644, acc.: 55.47%] [G loss: 0.949444]\n",
      "epoch:1 step:919 [D loss: 0.681273, acc.: 59.38%] [G loss: 0.836322]\n",
      "epoch:1 step:920 [D loss: 0.727619, acc.: 57.03%] [G loss: 0.704485]\n",
      "epoch:1 step:921 [D loss: 0.750229, acc.: 49.22%] [G loss: 0.709739]\n",
      "epoch:1 step:922 [D loss: 0.706121, acc.: 57.81%] [G loss: 0.871536]\n",
      "epoch:1 step:923 [D loss: 0.671899, acc.: 61.72%] [G loss: 0.877311]\n",
      "epoch:1 step:924 [D loss: 0.721532, acc.: 57.03%] [G loss: 0.843061]\n",
      "epoch:1 step:925 [D loss: 0.763498, acc.: 53.12%] [G loss: 0.844809]\n",
      "epoch:1 step:926 [D loss: 0.776151, acc.: 50.00%] [G loss: 0.936109]\n",
      "epoch:1 step:927 [D loss: 0.764549, acc.: 52.34%] [G loss: 0.838194]\n",
      "epoch:1 step:928 [D loss: 0.658233, acc.: 62.50%] [G loss: 1.053523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:929 [D loss: 0.706772, acc.: 61.72%] [G loss: 0.921253]\n",
      "epoch:1 step:930 [D loss: 0.757387, acc.: 46.09%] [G loss: 0.786207]\n",
      "epoch:1 step:931 [D loss: 0.714984, acc.: 49.22%] [G loss: 0.798762]\n",
      "epoch:1 step:932 [D loss: 0.673661, acc.: 59.38%] [G loss: 0.763741]\n",
      "epoch:1 step:933 [D loss: 0.616343, acc.: 69.53%] [G loss: 0.851403]\n",
      "epoch:1 step:934 [D loss: 0.663169, acc.: 57.81%] [G loss: 0.688101]\n",
      "epoch:1 step:935 [D loss: 0.701392, acc.: 57.03%] [G loss: 0.755966]\n",
      "epoch:1 step:936 [D loss: 0.721009, acc.: 47.66%] [G loss: 0.778696]\n",
      "epoch:1 step:937 [D loss: 0.691765, acc.: 58.59%] [G loss: 0.710477]\n",
      "epoch:1 step:938 [D loss: 0.629218, acc.: 66.41%] [G loss: 0.917831]\n",
      "epoch:1 step:939 [D loss: 0.741739, acc.: 46.09%] [G loss: 0.730890]\n",
      "epoch:1 step:940 [D loss: 0.653791, acc.: 63.28%] [G loss: 0.706507]\n",
      "epoch:1 step:941 [D loss: 0.829431, acc.: 43.75%] [G loss: 0.694326]\n",
      "epoch:1 step:942 [D loss: 0.779043, acc.: 45.31%] [G loss: 0.640464]\n",
      "epoch:1 step:943 [D loss: 0.781109, acc.: 45.31%] [G loss: 0.719867]\n",
      "epoch:1 step:944 [D loss: 0.661586, acc.: 56.25%] [G loss: 0.767114]\n",
      "epoch:1 step:945 [D loss: 0.731717, acc.: 50.78%] [G loss: 0.799701]\n",
      "epoch:1 step:946 [D loss: 0.793467, acc.: 40.62%] [G loss: 0.776709]\n",
      "epoch:1 step:947 [D loss: 0.741340, acc.: 46.88%] [G loss: 0.807387]\n",
      "epoch:1 step:948 [D loss: 0.761294, acc.: 46.88%] [G loss: 0.778157]\n",
      "epoch:1 step:949 [D loss: 0.734627, acc.: 52.34%] [G loss: 0.740038]\n",
      "epoch:1 step:950 [D loss: 0.764969, acc.: 46.09%] [G loss: 0.782366]\n",
      "epoch:1 step:951 [D loss: 0.808805, acc.: 50.00%] [G loss: 0.781805]\n",
      "epoch:1 step:952 [D loss: 0.786030, acc.: 39.84%] [G loss: 0.775099]\n",
      "epoch:1 step:953 [D loss: 0.750903, acc.: 50.78%] [G loss: 0.850883]\n",
      "epoch:1 step:954 [D loss: 0.762538, acc.: 48.44%] [G loss: 0.919612]\n",
      "epoch:1 step:955 [D loss: 0.774174, acc.: 46.88%] [G loss: 0.887306]\n",
      "epoch:1 step:956 [D loss: 0.784996, acc.: 43.75%] [G loss: 0.871337]\n",
      "epoch:1 step:957 [D loss: 0.795529, acc.: 43.75%] [G loss: 0.782530]\n",
      "epoch:1 step:958 [D loss: 0.600896, acc.: 66.41%] [G loss: 0.894104]\n",
      "epoch:1 step:959 [D loss: 0.702732, acc.: 56.25%] [G loss: 0.847676]\n",
      "epoch:1 step:960 [D loss: 0.737496, acc.: 51.56%] [G loss: 0.885257]\n",
      "epoch:1 step:961 [D loss: 0.658173, acc.: 58.59%] [G loss: 0.823322]\n",
      "epoch:1 step:962 [D loss: 0.607484, acc.: 71.09%] [G loss: 0.820704]\n",
      "epoch:1 step:963 [D loss: 0.589671, acc.: 68.75%] [G loss: 0.907632]\n",
      "epoch:1 step:964 [D loss: 0.673256, acc.: 58.59%] [G loss: 0.897940]\n",
      "epoch:1 step:965 [D loss: 0.721847, acc.: 58.59%] [G loss: 0.757798]\n",
      "epoch:1 step:966 [D loss: 0.732841, acc.: 53.12%] [G loss: 0.641947]\n",
      "epoch:1 step:967 [D loss: 0.839984, acc.: 39.84%] [G loss: 0.705049]\n",
      "epoch:1 step:968 [D loss: 0.590870, acc.: 72.66%] [G loss: 0.738173]\n",
      "epoch:1 step:969 [D loss: 0.714030, acc.: 58.59%] [G loss: 0.831404]\n",
      "epoch:1 step:970 [D loss: 0.552644, acc.: 76.56%] [G loss: 0.725554]\n",
      "epoch:1 step:971 [D loss: 0.802662, acc.: 46.88%] [G loss: 0.721782]\n",
      "epoch:1 step:972 [D loss: 0.659133, acc.: 63.28%] [G loss: 0.727494]\n",
      "epoch:1 step:973 [D loss: 0.675955, acc.: 60.16%] [G loss: 0.713808]\n",
      "epoch:1 step:974 [D loss: 0.716574, acc.: 56.25%] [G loss: 0.769100]\n",
      "epoch:1 step:975 [D loss: 0.796109, acc.: 44.53%] [G loss: 0.823269]\n",
      "epoch:1 step:976 [D loss: 0.983194, acc.: 24.22%] [G loss: 0.831347]\n",
      "epoch:1 step:977 [D loss: 0.803446, acc.: 43.75%] [G loss: 0.791080]\n",
      "epoch:1 step:978 [D loss: 0.751219, acc.: 52.34%] [G loss: 0.843354]\n",
      "epoch:1 step:979 [D loss: 0.732464, acc.: 47.66%] [G loss: 0.774480]\n",
      "epoch:1 step:980 [D loss: 0.828736, acc.: 42.19%] [G loss: 0.800292]\n",
      "epoch:1 step:981 [D loss: 0.773418, acc.: 50.00%] [G loss: 0.789257]\n",
      "epoch:1 step:982 [D loss: 0.775556, acc.: 47.66%] [G loss: 0.891858]\n",
      "epoch:1 step:983 [D loss: 0.745941, acc.: 54.69%] [G loss: 0.875249]\n",
      "epoch:1 step:984 [D loss: 0.726555, acc.: 57.81%] [G loss: 0.994945]\n",
      "epoch:1 step:985 [D loss: 0.811812, acc.: 44.53%] [G loss: 0.875348]\n",
      "epoch:1 step:986 [D loss: 0.773779, acc.: 46.09%] [G loss: 0.927245]\n",
      "epoch:1 step:987 [D loss: 0.749373, acc.: 54.69%] [G loss: 0.828979]\n",
      "epoch:1 step:988 [D loss: 0.575515, acc.: 70.31%] [G loss: 0.952452]\n",
      "epoch:1 step:989 [D loss: 0.802409, acc.: 42.19%] [G loss: 0.862138]\n",
      "epoch:1 step:990 [D loss: 0.717149, acc.: 50.00%] [G loss: 0.961041]\n",
      "epoch:1 step:991 [D loss: 0.684641, acc.: 61.72%] [G loss: 0.870879]\n",
      "epoch:1 step:992 [D loss: 0.747135, acc.: 59.38%] [G loss: 0.789311]\n",
      "epoch:1 step:993 [D loss: 0.659013, acc.: 61.72%] [G loss: 0.901287]\n",
      "epoch:1 step:994 [D loss: 0.750073, acc.: 53.91%] [G loss: 0.878638]\n",
      "epoch:1 step:995 [D loss: 0.773609, acc.: 43.75%] [G loss: 0.820282]\n",
      "epoch:1 step:996 [D loss: 0.759546, acc.: 51.56%] [G loss: 0.919055]\n",
      "epoch:1 step:997 [D loss: 0.859891, acc.: 45.31%] [G loss: 0.879280]\n",
      "epoch:1 step:998 [D loss: 0.749921, acc.: 51.56%] [G loss: 0.821505]\n",
      "epoch:1 step:999 [D loss: 0.730835, acc.: 48.44%] [G loss: 0.814956]\n",
      "epoch:1 step:1000 [D loss: 0.702492, acc.: 53.12%] [G loss: 0.808837]\n",
      "epoch:1 step:1001 [D loss: 0.723400, acc.: 54.69%] [G loss: 0.642717]\n",
      "epoch:1 step:1002 [D loss: 0.827162, acc.: 45.31%] [G loss: 0.771039]\n",
      "epoch:1 step:1003 [D loss: 0.730757, acc.: 46.88%] [G loss: 0.698268]\n",
      "epoch:1 step:1004 [D loss: 0.831409, acc.: 43.75%] [G loss: 0.736692]\n",
      "epoch:1 step:1005 [D loss: 0.734986, acc.: 43.75%] [G loss: 0.806221]\n",
      "epoch:1 step:1006 [D loss: 0.722265, acc.: 52.34%] [G loss: 0.696594]\n",
      "epoch:1 step:1007 [D loss: 0.691888, acc.: 61.72%] [G loss: 0.840158]\n",
      "epoch:1 step:1008 [D loss: 0.684392, acc.: 57.03%] [G loss: 0.809847]\n",
      "epoch:1 step:1009 [D loss: 0.715799, acc.: 52.34%] [G loss: 0.740362]\n",
      "epoch:1 step:1010 [D loss: 0.650833, acc.: 58.59%] [G loss: 0.904316]\n",
      "epoch:1 step:1011 [D loss: 0.781748, acc.: 50.78%] [G loss: 0.827323]\n",
      "epoch:1 step:1012 [D loss: 0.715127, acc.: 57.03%] [G loss: 0.909802]\n",
      "epoch:1 step:1013 [D loss: 0.722934, acc.: 53.91%] [G loss: 0.877826]\n",
      "epoch:1 step:1014 [D loss: 0.762519, acc.: 49.22%] [G loss: 0.933070]\n",
      "epoch:1 step:1015 [D loss: 0.794751, acc.: 53.91%] [G loss: 0.874133]\n",
      "epoch:1 step:1016 [D loss: 0.741239, acc.: 50.78%] [G loss: 0.851258]\n",
      "epoch:1 step:1017 [D loss: 0.759890, acc.: 43.75%] [G loss: 0.633501]\n",
      "epoch:1 step:1018 [D loss: 0.735319, acc.: 58.59%] [G loss: 0.810710]\n",
      "epoch:1 step:1019 [D loss: 0.780809, acc.: 51.56%] [G loss: 0.801639]\n",
      "epoch:1 step:1020 [D loss: 0.728658, acc.: 50.78%] [G loss: 0.817342]\n",
      "epoch:1 step:1021 [D loss: 0.785081, acc.: 42.19%] [G loss: 0.896294]\n",
      "epoch:1 step:1022 [D loss: 0.742225, acc.: 52.34%] [G loss: 0.938222]\n",
      "epoch:1 step:1023 [D loss: 0.709998, acc.: 53.91%] [G loss: 0.792596]\n",
      "epoch:1 step:1024 [D loss: 0.722105, acc.: 53.12%] [G loss: 0.773187]\n",
      "epoch:1 step:1025 [D loss: 0.695885, acc.: 58.59%] [G loss: 0.949443]\n",
      "epoch:1 step:1026 [D loss: 0.722650, acc.: 50.00%] [G loss: 0.883415]\n",
      "epoch:1 step:1027 [D loss: 0.780783, acc.: 42.19%] [G loss: 0.750200]\n",
      "epoch:1 step:1028 [D loss: 0.754980, acc.: 48.44%] [G loss: 0.853478]\n",
      "epoch:1 step:1029 [D loss: 0.801355, acc.: 39.06%] [G loss: 0.808641]\n",
      "epoch:1 step:1030 [D loss: 0.744196, acc.: 50.00%] [G loss: 0.778891]\n",
      "epoch:1 step:1031 [D loss: 0.786745, acc.: 46.88%] [G loss: 0.763561]\n",
      "epoch:1 step:1032 [D loss: 0.649114, acc.: 61.72%] [G loss: 0.890563]\n",
      "epoch:1 step:1033 [D loss: 0.747479, acc.: 48.44%] [G loss: 0.931758]\n",
      "epoch:1 step:1034 [D loss: 0.728288, acc.: 50.00%] [G loss: 0.954704]\n",
      "epoch:1 step:1035 [D loss: 0.741025, acc.: 50.00%] [G loss: 0.901845]\n",
      "epoch:1 step:1036 [D loss: 0.715102, acc.: 51.56%] [G loss: 0.869383]\n",
      "epoch:1 step:1037 [D loss: 0.662534, acc.: 63.28%] [G loss: 0.897234]\n",
      "epoch:1 step:1038 [D loss: 0.676992, acc.: 60.94%] [G loss: 0.877149]\n",
      "epoch:1 step:1039 [D loss: 0.665489, acc.: 57.81%] [G loss: 0.880418]\n",
      "epoch:1 step:1040 [D loss: 0.682819, acc.: 57.03%] [G loss: 0.860591]\n",
      "epoch:1 step:1041 [D loss: 0.753428, acc.: 51.56%] [G loss: 0.783633]\n",
      "epoch:1 step:1042 [D loss: 0.767923, acc.: 42.97%] [G loss: 0.942215]\n",
      "epoch:1 step:1043 [D loss: 0.672128, acc.: 55.47%] [G loss: 0.859999]\n",
      "epoch:1 step:1044 [D loss: 0.641846, acc.: 64.06%] [G loss: 0.974198]\n",
      "epoch:1 step:1045 [D loss: 0.634301, acc.: 62.50%] [G loss: 0.747014]\n",
      "epoch:1 step:1046 [D loss: 0.706351, acc.: 57.81%] [G loss: 0.703384]\n",
      "epoch:1 step:1047 [D loss: 0.649390, acc.: 60.16%] [G loss: 0.736374]\n",
      "epoch:1 step:1048 [D loss: 0.677834, acc.: 64.06%] [G loss: 0.745831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1049 [D loss: 0.670049, acc.: 59.38%] [G loss: 0.733542]\n",
      "epoch:1 step:1050 [D loss: 0.681396, acc.: 60.94%] [G loss: 0.704632]\n",
      "epoch:1 step:1051 [D loss: 0.687998, acc.: 60.94%] [G loss: 0.804414]\n",
      "epoch:1 step:1052 [D loss: 0.697320, acc.: 58.59%] [G loss: 0.629905]\n",
      "epoch:1 step:1053 [D loss: 0.658340, acc.: 64.84%] [G loss: 0.580207]\n",
      "epoch:1 step:1054 [D loss: 0.665434, acc.: 65.62%] [G loss: 0.521974]\n",
      "epoch:1 step:1055 [D loss: 0.700435, acc.: 54.69%] [G loss: 0.704974]\n",
      "epoch:1 step:1056 [D loss: 0.781589, acc.: 47.66%] [G loss: 0.721756]\n",
      "epoch:1 step:1057 [D loss: 0.725513, acc.: 51.56%] [G loss: 0.749895]\n",
      "epoch:1 step:1058 [D loss: 0.973877, acc.: 34.38%] [G loss: 0.736004]\n",
      "epoch:1 step:1059 [D loss: 0.774828, acc.: 50.00%] [G loss: 0.651708]\n",
      "epoch:1 step:1060 [D loss: 0.880629, acc.: 42.19%] [G loss: 0.698348]\n",
      "epoch:1 step:1061 [D loss: 0.783950, acc.: 47.66%] [G loss: 0.710561]\n",
      "epoch:1 step:1062 [D loss: 0.808685, acc.: 37.50%] [G loss: 0.796634]\n",
      "epoch:1 step:1063 [D loss: 0.787378, acc.: 49.22%] [G loss: 0.819409]\n",
      "epoch:1 step:1064 [D loss: 0.615119, acc.: 70.31%] [G loss: 0.839832]\n",
      "epoch:1 step:1065 [D loss: 0.658709, acc.: 60.94%] [G loss: 0.851909]\n",
      "epoch:1 step:1066 [D loss: 0.620142, acc.: 66.41%] [G loss: 0.883096]\n",
      "epoch:1 step:1067 [D loss: 0.640582, acc.: 61.72%] [G loss: 0.807826]\n",
      "epoch:1 step:1068 [D loss: 0.576970, acc.: 74.22%] [G loss: 0.982664]\n",
      "epoch:1 step:1069 [D loss: 0.670084, acc.: 66.41%] [G loss: 0.908550]\n",
      "epoch:1 step:1070 [D loss: 0.606491, acc.: 67.19%] [G loss: 0.853011]\n",
      "epoch:1 step:1071 [D loss: 0.651691, acc.: 62.50%] [G loss: 0.837809]\n",
      "epoch:1 step:1072 [D loss: 0.732749, acc.: 52.34%] [G loss: 0.885522]\n",
      "epoch:1 step:1073 [D loss: 0.684980, acc.: 57.81%] [G loss: 0.801584]\n",
      "epoch:1 step:1074 [D loss: 0.639180, acc.: 64.06%] [G loss: 0.851048]\n",
      "epoch:1 step:1075 [D loss: 0.772671, acc.: 53.12%] [G loss: 0.730489]\n",
      "epoch:1 step:1076 [D loss: 0.676758, acc.: 57.03%] [G loss: 0.786991]\n",
      "epoch:1 step:1077 [D loss: 0.742461, acc.: 47.66%] [G loss: 0.776929]\n",
      "epoch:1 step:1078 [D loss: 0.803266, acc.: 42.19%] [G loss: 0.759501]\n",
      "epoch:1 step:1079 [D loss: 0.851541, acc.: 38.28%] [G loss: 0.707970]\n",
      "epoch:1 step:1080 [D loss: 0.751099, acc.: 50.00%] [G loss: 0.872489]\n",
      "epoch:1 step:1081 [D loss: 0.773007, acc.: 44.53%] [G loss: 0.850952]\n",
      "epoch:1 step:1082 [D loss: 0.762008, acc.: 46.09%] [G loss: 0.882478]\n",
      "epoch:1 step:1083 [D loss: 0.803784, acc.: 39.84%] [G loss: 0.754105]\n",
      "epoch:1 step:1084 [D loss: 0.712189, acc.: 53.91%] [G loss: 0.797176]\n",
      "epoch:1 step:1085 [D loss: 0.792191, acc.: 43.75%] [G loss: 0.755380]\n",
      "epoch:1 step:1086 [D loss: 0.747266, acc.: 53.91%] [G loss: 0.813531]\n",
      "epoch:1 step:1087 [D loss: 0.844378, acc.: 37.50%] [G loss: 0.705037]\n",
      "epoch:1 step:1088 [D loss: 0.784350, acc.: 44.53%] [G loss: 0.756216]\n",
      "epoch:1 step:1089 [D loss: 0.710391, acc.: 54.69%] [G loss: 0.754084]\n",
      "epoch:1 step:1090 [D loss: 0.695477, acc.: 50.78%] [G loss: 0.815375]\n",
      "epoch:1 step:1091 [D loss: 0.717135, acc.: 48.44%] [G loss: 0.879761]\n",
      "epoch:1 step:1092 [D loss: 0.689783, acc.: 59.38%] [G loss: 0.790202]\n",
      "epoch:1 step:1093 [D loss: 0.718050, acc.: 53.91%] [G loss: 0.780574]\n",
      "epoch:1 step:1094 [D loss: 0.741911, acc.: 51.56%] [G loss: 0.816192]\n",
      "epoch:1 step:1095 [D loss: 0.769671, acc.: 49.22%] [G loss: 0.830475]\n",
      "epoch:1 step:1096 [D loss: 0.826981, acc.: 38.28%] [G loss: 0.915804]\n",
      "epoch:1 step:1097 [D loss: 0.745812, acc.: 46.88%] [G loss: 0.791816]\n",
      "epoch:1 step:1098 [D loss: 0.745098, acc.: 45.31%] [G loss: 0.792757]\n",
      "epoch:1 step:1099 [D loss: 0.748785, acc.: 46.88%] [G loss: 0.756009]\n",
      "epoch:1 step:1100 [D loss: 0.777504, acc.: 48.44%] [G loss: 0.831523]\n",
      "epoch:1 step:1101 [D loss: 0.727001, acc.: 52.34%] [G loss: 0.760302]\n",
      "epoch:1 step:1102 [D loss: 0.721922, acc.: 50.78%] [G loss: 0.963932]\n",
      "epoch:1 step:1103 [D loss: 0.742437, acc.: 56.25%] [G loss: 0.859518]\n",
      "epoch:1 step:1104 [D loss: 0.785845, acc.: 42.97%] [G loss: 0.823988]\n",
      "epoch:1 step:1105 [D loss: 0.733476, acc.: 46.88%] [G loss: 0.806602]\n",
      "epoch:1 step:1106 [D loss: 0.763544, acc.: 50.00%] [G loss: 0.782756]\n",
      "epoch:1 step:1107 [D loss: 0.740247, acc.: 44.53%] [G loss: 0.796009]\n",
      "epoch:1 step:1108 [D loss: 0.743537, acc.: 45.31%] [G loss: 0.823115]\n",
      "epoch:1 step:1109 [D loss: 0.796097, acc.: 46.09%] [G loss: 0.818414]\n",
      "epoch:1 step:1110 [D loss: 0.772702, acc.: 50.00%] [G loss: 0.805470]\n",
      "epoch:1 step:1111 [D loss: 0.768663, acc.: 47.66%] [G loss: 0.892105]\n",
      "epoch:1 step:1112 [D loss: 0.686820, acc.: 60.16%] [G loss: 0.849268]\n",
      "epoch:1 step:1113 [D loss: 0.714431, acc.: 49.22%] [G loss: 0.881741]\n",
      "epoch:1 step:1114 [D loss: 0.717605, acc.: 52.34%] [G loss: 0.857299]\n",
      "epoch:1 step:1115 [D loss: 0.703853, acc.: 58.59%] [G loss: 0.934715]\n",
      "epoch:1 step:1116 [D loss: 0.651712, acc.: 58.59%] [G loss: 1.076151]\n",
      "epoch:1 step:1117 [D loss: 0.617565, acc.: 65.62%] [G loss: 0.911074]\n",
      "epoch:1 step:1118 [D loss: 0.732537, acc.: 58.59%] [G loss: 0.825416]\n",
      "epoch:1 step:1119 [D loss: 0.756195, acc.: 53.12%] [G loss: 0.812108]\n",
      "epoch:1 step:1120 [D loss: 0.725624, acc.: 49.22%] [G loss: 0.664242]\n",
      "epoch:1 step:1121 [D loss: 0.718795, acc.: 53.91%] [G loss: 0.824392]\n",
      "epoch:1 step:1122 [D loss: 0.783762, acc.: 44.53%] [G loss: 0.826718]\n",
      "epoch:1 step:1123 [D loss: 0.747859, acc.: 48.44%] [G loss: 0.968274]\n",
      "epoch:1 step:1124 [D loss: 0.848892, acc.: 44.53%] [G loss: 0.762073]\n",
      "epoch:1 step:1125 [D loss: 0.868897, acc.: 35.94%] [G loss: 0.813565]\n",
      "epoch:1 step:1126 [D loss: 0.735147, acc.: 53.91%] [G loss: 0.812574]\n",
      "epoch:1 step:1127 [D loss: 0.748928, acc.: 47.66%] [G loss: 0.823543]\n",
      "epoch:1 step:1128 [D loss: 0.777776, acc.: 46.09%] [G loss: 0.771114]\n",
      "epoch:1 step:1129 [D loss: 0.731120, acc.: 53.12%] [G loss: 0.996117]\n",
      "epoch:1 step:1130 [D loss: 0.721764, acc.: 49.22%] [G loss: 0.915831]\n",
      "epoch:1 step:1131 [D loss: 0.754470, acc.: 47.66%] [G loss: 0.995219]\n",
      "epoch:1 step:1132 [D loss: 0.712629, acc.: 57.81%] [G loss: 0.794857]\n",
      "epoch:1 step:1133 [D loss: 0.702085, acc.: 53.12%] [G loss: 0.838098]\n",
      "epoch:1 step:1134 [D loss: 0.716382, acc.: 50.00%] [G loss: 0.816417]\n",
      "epoch:1 step:1135 [D loss: 0.720863, acc.: 53.91%] [G loss: 0.811503]\n",
      "epoch:1 step:1136 [D loss: 0.715082, acc.: 50.00%] [G loss: 0.744340]\n",
      "epoch:1 step:1137 [D loss: 0.723634, acc.: 55.47%] [G loss: 0.815289]\n",
      "epoch:1 step:1138 [D loss: 0.830986, acc.: 39.84%] [G loss: 0.697928]\n",
      "epoch:1 step:1139 [D loss: 0.719459, acc.: 52.34%] [G loss: 0.920198]\n",
      "epoch:1 step:1140 [D loss: 0.737654, acc.: 51.56%] [G loss: 0.864073]\n",
      "epoch:1 step:1141 [D loss: 0.750610, acc.: 53.91%] [G loss: 0.896918]\n",
      "epoch:1 step:1142 [D loss: 0.794043, acc.: 46.88%] [G loss: 0.830382]\n",
      "epoch:1 step:1143 [D loss: 0.706411, acc.: 49.22%] [G loss: 0.876757]\n",
      "epoch:1 step:1144 [D loss: 0.802130, acc.: 42.97%] [G loss: 0.760389]\n",
      "epoch:1 step:1145 [D loss: 0.725748, acc.: 55.47%] [G loss: 0.770658]\n",
      "epoch:1 step:1146 [D loss: 0.742019, acc.: 50.00%] [G loss: 0.746695]\n",
      "epoch:1 step:1147 [D loss: 0.724007, acc.: 46.88%] [G loss: 0.752902]\n",
      "epoch:1 step:1148 [D loss: 0.718858, acc.: 53.12%] [G loss: 0.765880]\n",
      "epoch:1 step:1149 [D loss: 0.770660, acc.: 46.88%] [G loss: 0.753709]\n",
      "epoch:1 step:1150 [D loss: 0.709876, acc.: 52.34%] [G loss: 0.930746]\n",
      "epoch:1 step:1151 [D loss: 0.681422, acc.: 58.59%] [G loss: 0.844968]\n",
      "epoch:1 step:1152 [D loss: 0.755498, acc.: 46.09%] [G loss: 0.806727]\n",
      "epoch:1 step:1153 [D loss: 0.686512, acc.: 57.03%] [G loss: 0.843713]\n",
      "epoch:1 step:1154 [D loss: 0.757954, acc.: 43.75%] [G loss: 0.830957]\n",
      "epoch:1 step:1155 [D loss: 0.743096, acc.: 47.66%] [G loss: 0.791601]\n",
      "epoch:1 step:1156 [D loss: 0.783018, acc.: 42.97%] [G loss: 0.765976]\n",
      "epoch:1 step:1157 [D loss: 0.709656, acc.: 53.12%] [G loss: 0.776320]\n",
      "epoch:1 step:1158 [D loss: 0.648165, acc.: 58.59%] [G loss: 0.882624]\n",
      "epoch:1 step:1159 [D loss: 0.737718, acc.: 53.91%] [G loss: 0.732076]\n",
      "epoch:1 step:1160 [D loss: 0.709803, acc.: 50.78%] [G loss: 0.836927]\n",
      "epoch:1 step:1161 [D loss: 0.719804, acc.: 52.34%] [G loss: 0.869278]\n",
      "epoch:1 step:1162 [D loss: 0.708447, acc.: 58.59%] [G loss: 0.789443]\n",
      "epoch:1 step:1163 [D loss: 0.756685, acc.: 52.34%] [G loss: 0.827508]\n",
      "epoch:1 step:1164 [D loss: 0.703766, acc.: 50.78%] [G loss: 0.746732]\n",
      "epoch:1 step:1165 [D loss: 0.700942, acc.: 53.91%] [G loss: 0.797844]\n",
      "epoch:1 step:1166 [D loss: 0.744937, acc.: 44.53%] [G loss: 0.836557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1167 [D loss: 0.719938, acc.: 53.12%] [G loss: 0.821902]\n",
      "epoch:1 step:1168 [D loss: 0.741082, acc.: 50.78%] [G loss: 0.833314]\n",
      "epoch:1 step:1169 [D loss: 0.746467, acc.: 45.31%] [G loss: 0.860582]\n",
      "epoch:1 step:1170 [D loss: 0.776002, acc.: 52.34%] [G loss: 0.956126]\n",
      "epoch:1 step:1171 [D loss: 0.767230, acc.: 48.44%] [G loss: 0.924470]\n",
      "epoch:1 step:1172 [D loss: 0.654989, acc.: 64.06%] [G loss: 0.800696]\n",
      "epoch:1 step:1173 [D loss: 0.753381, acc.: 47.66%] [G loss: 0.696272]\n",
      "epoch:1 step:1174 [D loss: 0.700425, acc.: 60.16%] [G loss: 0.760642]\n",
      "epoch:1 step:1175 [D loss: 0.771972, acc.: 42.19%] [G loss: 0.711129]\n",
      "epoch:1 step:1176 [D loss: 0.744479, acc.: 47.66%] [G loss: 0.782591]\n",
      "epoch:1 step:1177 [D loss: 0.765530, acc.: 50.00%] [G loss: 0.833392]\n",
      "epoch:1 step:1178 [D loss: 0.787565, acc.: 37.50%] [G loss: 0.763579]\n",
      "epoch:1 step:1179 [D loss: 0.762511, acc.: 41.41%] [G loss: 0.903440]\n",
      "epoch:1 step:1180 [D loss: 0.749264, acc.: 42.97%] [G loss: 0.874826]\n",
      "epoch:1 step:1181 [D loss: 0.738850, acc.: 47.66%] [G loss: 0.814656]\n",
      "epoch:1 step:1182 [D loss: 0.715716, acc.: 46.09%] [G loss: 0.852080]\n",
      "epoch:1 step:1183 [D loss: 0.742241, acc.: 54.69%] [G loss: 0.810835]\n",
      "epoch:1 step:1184 [D loss: 0.744581, acc.: 43.75%] [G loss: 0.856124]\n",
      "epoch:1 step:1185 [D loss: 0.724227, acc.: 46.88%] [G loss: 0.877847]\n",
      "epoch:1 step:1186 [D loss: 0.719197, acc.: 48.44%] [G loss: 0.855370]\n",
      "epoch:1 step:1187 [D loss: 0.772708, acc.: 42.97%] [G loss: 0.761979]\n",
      "epoch:1 step:1188 [D loss: 0.679267, acc.: 55.47%] [G loss: 0.720716]\n",
      "epoch:1 step:1189 [D loss: 0.785921, acc.: 42.19%] [G loss: 0.834009]\n",
      "epoch:1 step:1190 [D loss: 0.759830, acc.: 48.44%] [G loss: 0.754893]\n",
      "epoch:1 step:1191 [D loss: 0.795404, acc.: 41.41%] [G loss: 0.846507]\n",
      "epoch:1 step:1192 [D loss: 0.754621, acc.: 50.78%] [G loss: 0.780361]\n",
      "epoch:1 step:1193 [D loss: 0.726114, acc.: 50.78%] [G loss: 0.861973]\n",
      "epoch:1 step:1194 [D loss: 0.797838, acc.: 42.19%] [G loss: 0.837996]\n",
      "epoch:1 step:1195 [D loss: 0.760316, acc.: 47.66%] [G loss: 0.789086]\n",
      "epoch:1 step:1196 [D loss: 0.714285, acc.: 55.47%] [G loss: 0.826023]\n",
      "epoch:1 step:1197 [D loss: 0.710920, acc.: 50.78%] [G loss: 0.849157]\n",
      "epoch:1 step:1198 [D loss: 0.687702, acc.: 58.59%] [G loss: 0.771489]\n",
      "epoch:1 step:1199 [D loss: 0.749499, acc.: 50.78%] [G loss: 0.828709]\n",
      "epoch:1 step:1200 [D loss: 0.780572, acc.: 42.19%] [G loss: 0.887548]\n",
      "epoch:1 step:1201 [D loss: 0.731043, acc.: 50.78%] [G loss: 0.889806]\n",
      "epoch:1 step:1202 [D loss: 0.669889, acc.: 56.25%] [G loss: 0.907940]\n",
      "epoch:1 step:1203 [D loss: 0.686358, acc.: 54.69%] [G loss: 0.885843]\n",
      "epoch:1 step:1204 [D loss: 0.673147, acc.: 57.81%] [G loss: 0.924213]\n",
      "epoch:1 step:1205 [D loss: 0.672077, acc.: 61.72%] [G loss: 0.919096]\n",
      "epoch:1 step:1206 [D loss: 0.692036, acc.: 58.59%] [G loss: 0.870801]\n",
      "epoch:1 step:1207 [D loss: 0.741039, acc.: 47.66%] [G loss: 0.844022]\n",
      "epoch:1 step:1208 [D loss: 0.704435, acc.: 57.81%] [G loss: 0.889939]\n",
      "epoch:1 step:1209 [D loss: 0.759642, acc.: 53.91%] [G loss: 0.753619]\n",
      "epoch:1 step:1210 [D loss: 0.740161, acc.: 47.66%] [G loss: 0.791443]\n",
      "epoch:1 step:1211 [D loss: 0.683714, acc.: 56.25%] [G loss: 0.787045]\n",
      "epoch:1 step:1212 [D loss: 0.802346, acc.: 39.84%] [G loss: 0.804965]\n",
      "epoch:1 step:1213 [D loss: 0.682543, acc.: 57.03%] [G loss: 0.868363]\n",
      "epoch:1 step:1214 [D loss: 0.722349, acc.: 51.56%] [G loss: 0.886600]\n",
      "epoch:1 step:1215 [D loss: 0.783607, acc.: 42.19%] [G loss: 0.908435]\n",
      "epoch:1 step:1216 [D loss: 0.711968, acc.: 54.69%] [G loss: 0.931999]\n",
      "epoch:1 step:1217 [D loss: 0.688248, acc.: 57.03%] [G loss: 0.989795]\n",
      "epoch:1 step:1218 [D loss: 0.707604, acc.: 56.25%] [G loss: 0.955641]\n",
      "epoch:1 step:1219 [D loss: 0.668615, acc.: 58.59%] [G loss: 0.999743]\n",
      "epoch:1 step:1220 [D loss: 0.724312, acc.: 55.47%] [G loss: 0.830667]\n",
      "epoch:1 step:1221 [D loss: 0.698365, acc.: 57.03%] [G loss: 0.841485]\n",
      "epoch:1 step:1222 [D loss: 0.706323, acc.: 52.34%] [G loss: 0.842654]\n",
      "epoch:1 step:1223 [D loss: 0.719473, acc.: 46.09%] [G loss: 0.875766]\n",
      "epoch:1 step:1224 [D loss: 0.772001, acc.: 39.84%] [G loss: 0.837877]\n",
      "epoch:1 step:1225 [D loss: 0.730690, acc.: 53.12%] [G loss: 0.948209]\n",
      "epoch:1 step:1226 [D loss: 0.716273, acc.: 56.25%] [G loss: 0.919977]\n",
      "epoch:1 step:1227 [D loss: 0.713021, acc.: 49.22%] [G loss: 0.913565]\n",
      "epoch:1 step:1228 [D loss: 0.703013, acc.: 56.25%] [G loss: 0.865397]\n",
      "epoch:1 step:1229 [D loss: 0.751401, acc.: 40.62%] [G loss: 0.955947]\n",
      "epoch:1 step:1230 [D loss: 0.739708, acc.: 52.34%] [G loss: 0.843800]\n",
      "epoch:1 step:1231 [D loss: 0.698907, acc.: 56.25%] [G loss: 0.976639]\n",
      "epoch:1 step:1232 [D loss: 0.706215, acc.: 53.12%] [G loss: 0.942287]\n",
      "epoch:1 step:1233 [D loss: 0.760248, acc.: 44.53%] [G loss: 0.882107]\n",
      "epoch:1 step:1234 [D loss: 0.720411, acc.: 53.91%] [G loss: 0.832979]\n",
      "epoch:1 step:1235 [D loss: 0.688476, acc.: 56.25%] [G loss: 0.759853]\n",
      "epoch:1 step:1236 [D loss: 0.723105, acc.: 51.56%] [G loss: 0.798898]\n",
      "epoch:1 step:1237 [D loss: 0.691311, acc.: 60.16%] [G loss: 0.864118]\n",
      "epoch:1 step:1238 [D loss: 0.689653, acc.: 55.47%] [G loss: 0.887507]\n",
      "epoch:1 step:1239 [D loss: 0.700283, acc.: 55.47%] [G loss: 0.841747]\n",
      "epoch:1 step:1240 [D loss: 0.749690, acc.: 59.38%] [G loss: 0.941238]\n",
      "epoch:1 step:1241 [D loss: 0.706285, acc.: 55.47%] [G loss: 0.830458]\n",
      "epoch:1 step:1242 [D loss: 0.674646, acc.: 53.91%] [G loss: 0.992121]\n",
      "epoch:1 step:1243 [D loss: 0.707174, acc.: 53.91%] [G loss: 0.933575]\n",
      "epoch:1 step:1244 [D loss: 0.669267, acc.: 60.94%] [G loss: 0.879974]\n",
      "epoch:1 step:1245 [D loss: 0.707831, acc.: 51.56%] [G loss: 0.927075]\n",
      "epoch:1 step:1246 [D loss: 0.684148, acc.: 55.47%] [G loss: 0.884806]\n",
      "epoch:1 step:1247 [D loss: 0.676030, acc.: 60.16%] [G loss: 0.857287]\n",
      "epoch:1 step:1248 [D loss: 0.733197, acc.: 50.00%] [G loss: 0.846102]\n",
      "epoch:1 step:1249 [D loss: 0.713923, acc.: 52.34%] [G loss: 0.750210]\n",
      "epoch:1 step:1250 [D loss: 0.665581, acc.: 55.47%] [G loss: 0.938121]\n",
      "epoch:1 step:1251 [D loss: 0.674986, acc.: 53.91%] [G loss: 0.904169]\n",
      "epoch:1 step:1252 [D loss: 0.699701, acc.: 52.34%] [G loss: 0.863205]\n",
      "epoch:1 step:1253 [D loss: 0.741753, acc.: 50.78%] [G loss: 0.829423]\n",
      "epoch:1 step:1254 [D loss: 0.780461, acc.: 48.44%] [G loss: 0.725116]\n",
      "epoch:1 step:1255 [D loss: 0.726969, acc.: 49.22%] [G loss: 0.790442]\n",
      "epoch:1 step:1256 [D loss: 0.689344, acc.: 58.59%] [G loss: 0.839111]\n",
      "epoch:1 step:1257 [D loss: 0.718121, acc.: 50.00%] [G loss: 0.837891]\n",
      "epoch:1 step:1258 [D loss: 0.686999, acc.: 56.25%] [G loss: 0.845391]\n",
      "epoch:1 step:1259 [D loss: 0.668718, acc.: 65.62%] [G loss: 0.867034]\n",
      "epoch:1 step:1260 [D loss: 0.706301, acc.: 53.91%] [G loss: 0.816878]\n",
      "epoch:1 step:1261 [D loss: 0.654793, acc.: 61.72%] [G loss: 0.857071]\n",
      "epoch:1 step:1262 [D loss: 0.613948, acc.: 71.09%] [G loss: 1.016352]\n",
      "epoch:1 step:1263 [D loss: 0.720163, acc.: 53.12%] [G loss: 0.804271]\n",
      "epoch:1 step:1264 [D loss: 0.756958, acc.: 47.66%] [G loss: 0.821329]\n",
      "epoch:1 step:1265 [D loss: 0.637716, acc.: 60.16%] [G loss: 0.765925]\n",
      "epoch:1 step:1266 [D loss: 0.725753, acc.: 53.91%] [G loss: 0.736123]\n",
      "epoch:1 step:1267 [D loss: 0.664999, acc.: 60.94%] [G loss: 0.871478]\n",
      "epoch:1 step:1268 [D loss: 0.679811, acc.: 61.72%] [G loss: 0.837494]\n",
      "epoch:1 step:1269 [D loss: 0.661241, acc.: 59.38%] [G loss: 0.721861]\n",
      "epoch:1 step:1270 [D loss: 0.712461, acc.: 50.78%] [G loss: 0.781114]\n",
      "epoch:1 step:1271 [D loss: 0.627652, acc.: 64.06%] [G loss: 0.784636]\n",
      "epoch:1 step:1272 [D loss: 0.675411, acc.: 60.16%] [G loss: 0.805073]\n",
      "epoch:1 step:1273 [D loss: 0.766801, acc.: 45.31%] [G loss: 0.899440]\n",
      "epoch:1 step:1274 [D loss: 0.602210, acc.: 71.09%] [G loss: 0.856485]\n",
      "epoch:1 step:1275 [D loss: 0.671300, acc.: 59.38%] [G loss: 0.914562]\n",
      "epoch:1 step:1276 [D loss: 0.683707, acc.: 57.81%] [G loss: 0.826922]\n",
      "epoch:1 step:1277 [D loss: 0.680045, acc.: 56.25%] [G loss: 0.791368]\n",
      "epoch:1 step:1278 [D loss: 0.664456, acc.: 63.28%] [G loss: 0.856531]\n",
      "epoch:1 step:1279 [D loss: 0.609352, acc.: 64.84%] [G loss: 0.860691]\n",
      "epoch:1 step:1280 [D loss: 0.631361, acc.: 64.84%] [G loss: 0.973418]\n",
      "epoch:1 step:1281 [D loss: 0.710078, acc.: 49.22%] [G loss: 0.911449]\n",
      "epoch:1 step:1282 [D loss: 0.694152, acc.: 53.12%] [G loss: 0.900469]\n",
      "epoch:1 step:1283 [D loss: 0.676219, acc.: 59.38%] [G loss: 0.848330]\n",
      "epoch:1 step:1284 [D loss: 0.682487, acc.: 58.59%] [G loss: 0.886925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1285 [D loss: 0.655737, acc.: 63.28%] [G loss: 0.902507]\n",
      "epoch:1 step:1286 [D loss: 0.580347, acc.: 75.78%] [G loss: 0.931211]\n",
      "epoch:1 step:1287 [D loss: 0.601043, acc.: 69.53%] [G loss: 0.850079]\n",
      "epoch:1 step:1288 [D loss: 0.639149, acc.: 63.28%] [G loss: 0.851163]\n",
      "epoch:1 step:1289 [D loss: 0.630739, acc.: 69.53%] [G loss: 0.881935]\n",
      "epoch:1 step:1290 [D loss: 0.671983, acc.: 58.59%] [G loss: 0.869051]\n",
      "epoch:1 step:1291 [D loss: 0.669363, acc.: 54.69%] [G loss: 0.860302]\n",
      "epoch:1 step:1292 [D loss: 0.729769, acc.: 48.44%] [G loss: 0.833589]\n",
      "epoch:1 step:1293 [D loss: 0.763786, acc.: 46.88%] [G loss: 0.916038]\n",
      "epoch:1 step:1294 [D loss: 0.704250, acc.: 49.22%] [G loss: 0.834281]\n",
      "epoch:1 step:1295 [D loss: 0.758931, acc.: 49.22%] [G loss: 0.769546]\n",
      "epoch:1 step:1296 [D loss: 0.735157, acc.: 52.34%] [G loss: 0.825271]\n",
      "epoch:1 step:1297 [D loss: 0.680367, acc.: 58.59%] [G loss: 0.733642]\n",
      "epoch:1 step:1298 [D loss: 0.787661, acc.: 42.97%] [G loss: 0.840104]\n",
      "epoch:1 step:1299 [D loss: 0.730286, acc.: 51.56%] [G loss: 0.826995]\n",
      "epoch:1 step:1300 [D loss: 0.755708, acc.: 49.22%] [G loss: 0.869300]\n",
      "epoch:1 step:1301 [D loss: 0.771518, acc.: 44.53%] [G loss: 0.783005]\n",
      "epoch:1 step:1302 [D loss: 0.696649, acc.: 55.47%] [G loss: 0.823396]\n",
      "epoch:1 step:1303 [D loss: 0.742387, acc.: 46.88%] [G loss: 0.835568]\n",
      "epoch:1 step:1304 [D loss: 0.702425, acc.: 53.12%] [G loss: 0.720194]\n",
      "epoch:1 step:1305 [D loss: 0.822348, acc.: 32.81%] [G loss: 0.746571]\n",
      "epoch:1 step:1306 [D loss: 0.723327, acc.: 52.34%] [G loss: 0.809214]\n",
      "epoch:1 step:1307 [D loss: 0.755817, acc.: 49.22%] [G loss: 0.764282]\n",
      "epoch:1 step:1308 [D loss: 0.725897, acc.: 48.44%] [G loss: 0.852872]\n",
      "epoch:1 step:1309 [D loss: 0.696779, acc.: 56.25%] [G loss: 0.786239]\n",
      "epoch:1 step:1310 [D loss: 0.637266, acc.: 62.50%] [G loss: 0.773992]\n",
      "epoch:1 step:1311 [D loss: 0.711340, acc.: 52.34%] [G loss: 0.806375]\n",
      "epoch:1 step:1312 [D loss: 0.774192, acc.: 49.22%] [G loss: 0.841280]\n",
      "epoch:1 step:1313 [D loss: 0.729647, acc.: 50.00%] [G loss: 0.842530]\n",
      "epoch:1 step:1314 [D loss: 0.763866, acc.: 53.12%] [G loss: 0.812544]\n",
      "epoch:1 step:1315 [D loss: 0.652827, acc.: 60.16%] [G loss: 0.904805]\n",
      "epoch:1 step:1316 [D loss: 0.672218, acc.: 61.72%] [G loss: 0.912057]\n",
      "epoch:1 step:1317 [D loss: 0.713006, acc.: 54.69%] [G loss: 0.840864]\n",
      "epoch:1 step:1318 [D loss: 0.804152, acc.: 48.44%] [G loss: 0.760544]\n",
      "epoch:1 step:1319 [D loss: 0.724335, acc.: 52.34%] [G loss: 0.838522]\n",
      "epoch:1 step:1320 [D loss: 0.701144, acc.: 57.81%] [G loss: 0.867869]\n",
      "epoch:1 step:1321 [D loss: 0.678630, acc.: 57.03%] [G loss: 0.689774]\n",
      "epoch:1 step:1322 [D loss: 0.697026, acc.: 57.03%] [G loss: 0.861264]\n",
      "epoch:1 step:1323 [D loss: 0.826793, acc.: 40.62%] [G loss: 0.715379]\n",
      "epoch:1 step:1324 [D loss: 0.671874, acc.: 58.59%] [G loss: 0.703042]\n",
      "epoch:1 step:1325 [D loss: 0.595595, acc.: 71.09%] [G loss: 0.760502]\n",
      "epoch:1 step:1326 [D loss: 0.789238, acc.: 48.44%] [G loss: 0.763986]\n",
      "epoch:1 step:1327 [D loss: 0.809259, acc.: 45.31%] [G loss: 0.717496]\n",
      "epoch:1 step:1328 [D loss: 0.737000, acc.: 46.09%] [G loss: 0.707643]\n",
      "epoch:1 step:1329 [D loss: 0.718952, acc.: 52.34%] [G loss: 0.737738]\n",
      "epoch:1 step:1330 [D loss: 0.713126, acc.: 51.56%] [G loss: 0.681196]\n",
      "epoch:1 step:1331 [D loss: 0.738638, acc.: 48.44%] [G loss: 0.753041]\n",
      "epoch:1 step:1332 [D loss: 0.772438, acc.: 47.66%] [G loss: 0.773421]\n",
      "epoch:1 step:1333 [D loss: 0.771414, acc.: 45.31%] [G loss: 0.801068]\n",
      "epoch:1 step:1334 [D loss: 0.763373, acc.: 48.44%] [G loss: 0.808202]\n",
      "epoch:1 step:1335 [D loss: 0.794411, acc.: 36.72%] [G loss: 0.863308]\n",
      "epoch:1 step:1336 [D loss: 0.774024, acc.: 39.84%] [G loss: 0.872495]\n",
      "epoch:1 step:1337 [D loss: 0.766394, acc.: 47.66%] [G loss: 0.796588]\n",
      "epoch:1 step:1338 [D loss: 0.753952, acc.: 48.44%] [G loss: 0.842647]\n",
      "epoch:1 step:1339 [D loss: 0.769705, acc.: 46.88%] [G loss: 0.837713]\n",
      "epoch:1 step:1340 [D loss: 0.727914, acc.: 52.34%] [G loss: 0.855661]\n",
      "epoch:1 step:1341 [D loss: 0.716252, acc.: 51.56%] [G loss: 0.859034]\n",
      "epoch:1 step:1342 [D loss: 0.741860, acc.: 49.22%] [G loss: 0.873837]\n",
      "epoch:1 step:1343 [D loss: 0.694045, acc.: 61.72%] [G loss: 0.840156]\n",
      "epoch:1 step:1344 [D loss: 0.693400, acc.: 55.47%] [G loss: 1.005246]\n",
      "epoch:1 step:1345 [D loss: 0.682565, acc.: 57.03%] [G loss: 0.866079]\n",
      "epoch:1 step:1346 [D loss: 0.709252, acc.: 50.00%] [G loss: 0.886366]\n",
      "epoch:1 step:1347 [D loss: 0.695832, acc.: 57.81%] [G loss: 0.960092]\n",
      "epoch:1 step:1348 [D loss: 0.707485, acc.: 51.56%] [G loss: 0.808100]\n",
      "epoch:1 step:1349 [D loss: 0.667968, acc.: 60.16%] [G loss: 0.845186]\n",
      "epoch:1 step:1350 [D loss: 0.630598, acc.: 65.62%] [G loss: 0.821379]\n",
      "epoch:1 step:1351 [D loss: 0.619209, acc.: 63.28%] [G loss: 0.838990]\n",
      "epoch:1 step:1352 [D loss: 0.783847, acc.: 43.75%] [G loss: 0.801888]\n",
      "epoch:1 step:1353 [D loss: 0.699963, acc.: 54.69%] [G loss: 0.712712]\n",
      "epoch:1 step:1354 [D loss: 0.679396, acc.: 56.25%] [G loss: 0.747327]\n",
      "epoch:1 step:1355 [D loss: 0.672752, acc.: 61.72%] [G loss: 0.757859]\n",
      "epoch:1 step:1356 [D loss: 0.659279, acc.: 56.25%] [G loss: 0.747740]\n",
      "epoch:1 step:1357 [D loss: 0.678319, acc.: 55.47%] [G loss: 0.738491]\n",
      "epoch:1 step:1358 [D loss: 0.703149, acc.: 57.03%] [G loss: 0.720590]\n",
      "epoch:1 step:1359 [D loss: 0.709774, acc.: 53.12%] [G loss: 0.729013]\n",
      "epoch:1 step:1360 [D loss: 0.693500, acc.: 53.12%] [G loss: 0.694308]\n",
      "epoch:1 step:1361 [D loss: 0.761649, acc.: 45.31%] [G loss: 0.689581]\n",
      "epoch:1 step:1362 [D loss: 0.755613, acc.: 45.31%] [G loss: 0.732280]\n",
      "epoch:1 step:1363 [D loss: 0.751204, acc.: 51.56%] [G loss: 0.725047]\n",
      "epoch:1 step:1364 [D loss: 0.716723, acc.: 50.00%] [G loss: 0.810994]\n",
      "epoch:1 step:1365 [D loss: 0.739310, acc.: 50.00%] [G loss: 0.755573]\n",
      "epoch:1 step:1366 [D loss: 0.709432, acc.: 47.66%] [G loss: 0.832528]\n",
      "epoch:1 step:1367 [D loss: 0.719968, acc.: 53.91%] [G loss: 0.829683]\n",
      "epoch:1 step:1368 [D loss: 0.658509, acc.: 59.38%] [G loss: 0.909154]\n",
      "epoch:1 step:1369 [D loss: 0.646688, acc.: 66.41%] [G loss: 0.808360]\n",
      "epoch:1 step:1370 [D loss: 0.688308, acc.: 59.38%] [G loss: 0.875206]\n",
      "epoch:1 step:1371 [D loss: 0.676150, acc.: 57.81%] [G loss: 0.741614]\n",
      "epoch:1 step:1372 [D loss: 0.727775, acc.: 47.66%] [G loss: 0.746870]\n",
      "epoch:1 step:1373 [D loss: 0.730195, acc.: 54.69%] [G loss: 0.824692]\n",
      "epoch:1 step:1374 [D loss: 0.695813, acc.: 58.59%] [G loss: 0.734244]\n",
      "epoch:1 step:1375 [D loss: 0.702301, acc.: 54.69%] [G loss: 0.836716]\n",
      "epoch:1 step:1376 [D loss: 0.664492, acc.: 64.06%] [G loss: 0.911077]\n",
      "epoch:1 step:1377 [D loss: 0.753388, acc.: 46.09%] [G loss: 0.780272]\n",
      "epoch:1 step:1378 [D loss: 0.689763, acc.: 51.56%] [G loss: 0.840244]\n",
      "epoch:1 step:1379 [D loss: 0.674053, acc.: 60.16%] [G loss: 0.796619]\n",
      "epoch:1 step:1380 [D loss: 0.802282, acc.: 42.19%] [G loss: 0.831172]\n",
      "epoch:1 step:1381 [D loss: 0.722286, acc.: 63.28%] [G loss: 0.766121]\n",
      "epoch:1 step:1382 [D loss: 0.787949, acc.: 49.22%] [G loss: 0.708590]\n",
      "epoch:1 step:1383 [D loss: 0.649604, acc.: 61.72%] [G loss: 0.705827]\n",
      "epoch:1 step:1384 [D loss: 0.772478, acc.: 47.66%] [G loss: 0.862755]\n",
      "epoch:1 step:1385 [D loss: 0.734270, acc.: 48.44%] [G loss: 0.824504]\n",
      "epoch:1 step:1386 [D loss: 0.735434, acc.: 55.47%] [G loss: 0.790003]\n",
      "epoch:1 step:1387 [D loss: 0.737493, acc.: 48.44%] [G loss: 0.833374]\n",
      "epoch:1 step:1388 [D loss: 0.665834, acc.: 58.59%] [G loss: 0.845498]\n",
      "epoch:1 step:1389 [D loss: 0.676238, acc.: 59.38%] [G loss: 1.018951]\n",
      "epoch:1 step:1390 [D loss: 0.683192, acc.: 64.84%] [G loss: 0.958266]\n",
      "epoch:1 step:1391 [D loss: 0.637168, acc.: 63.28%] [G loss: 0.867137]\n",
      "epoch:1 step:1392 [D loss: 0.656752, acc.: 63.28%] [G loss: 0.823712]\n",
      "epoch:1 step:1393 [D loss: 0.628102, acc.: 68.75%] [G loss: 0.718247]\n",
      "epoch:1 step:1394 [D loss: 0.603071, acc.: 68.75%] [G loss: 0.732651]\n",
      "epoch:1 step:1395 [D loss: 0.766086, acc.: 50.78%] [G loss: 0.735425]\n",
      "epoch:1 step:1396 [D loss: 0.609342, acc.: 69.53%] [G loss: 0.703654]\n",
      "epoch:1 step:1397 [D loss: 0.730155, acc.: 51.56%] [G loss: 0.626544]\n",
      "epoch:1 step:1398 [D loss: 0.687141, acc.: 56.25%] [G loss: 0.564384]\n",
      "epoch:1 step:1399 [D loss: 0.692415, acc.: 56.25%] [G loss: 0.629230]\n",
      "epoch:1 step:1400 [D loss: 0.727999, acc.: 50.00%] [G loss: 0.722393]\n",
      "epoch:1 step:1401 [D loss: 0.782338, acc.: 46.88%] [G loss: 0.600303]\n",
      "epoch:1 step:1402 [D loss: 0.692404, acc.: 58.59%] [G loss: 0.771580]\n",
      "epoch:1 step:1403 [D loss: 0.741396, acc.: 53.91%] [G loss: 0.758057]\n",
      "epoch:1 step:1404 [D loss: 0.729449, acc.: 46.88%] [G loss: 0.800916]\n",
      "epoch:1 step:1405 [D loss: 0.678458, acc.: 54.69%] [G loss: 0.786067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1406 [D loss: 0.768956, acc.: 50.00%] [G loss: 0.779189]\n",
      "epoch:1 step:1407 [D loss: 0.755259, acc.: 46.09%] [G loss: 0.809468]\n",
      "epoch:1 step:1408 [D loss: 0.739992, acc.: 50.78%] [G loss: 0.839150]\n",
      "epoch:1 step:1409 [D loss: 0.676875, acc.: 64.84%] [G loss: 0.963738]\n",
      "epoch:1 step:1410 [D loss: 0.726891, acc.: 50.78%] [G loss: 0.898300]\n",
      "epoch:1 step:1411 [D loss: 0.638441, acc.: 57.81%] [G loss: 0.938733]\n",
      "epoch:1 step:1412 [D loss: 0.679997, acc.: 60.94%] [G loss: 0.886667]\n",
      "epoch:1 step:1413 [D loss: 0.670646, acc.: 60.16%] [G loss: 0.917205]\n",
      "epoch:1 step:1414 [D loss: 0.696786, acc.: 58.59%] [G loss: 0.850187]\n",
      "epoch:1 step:1415 [D loss: 0.714917, acc.: 60.16%] [G loss: 0.814434]\n",
      "epoch:1 step:1416 [D loss: 0.653963, acc.: 64.84%] [G loss: 0.626275]\n",
      "epoch:1 step:1417 [D loss: 0.640012, acc.: 62.50%] [G loss: 0.628636]\n",
      "epoch:1 step:1418 [D loss: 0.638718, acc.: 64.84%] [G loss: 0.799591]\n",
      "epoch:1 step:1419 [D loss: 0.614450, acc.: 66.41%] [G loss: 0.887668]\n",
      "epoch:1 step:1420 [D loss: 0.707600, acc.: 57.81%] [G loss: 0.837652]\n",
      "epoch:1 step:1421 [D loss: 0.751646, acc.: 46.88%] [G loss: 0.771671]\n",
      "epoch:1 step:1422 [D loss: 0.820322, acc.: 37.50%] [G loss: 0.746457]\n",
      "epoch:1 step:1423 [D loss: 0.746181, acc.: 50.78%] [G loss: 0.845404]\n",
      "epoch:1 step:1424 [D loss: 0.708360, acc.: 52.34%] [G loss: 0.866510]\n",
      "epoch:1 step:1425 [D loss: 0.704830, acc.: 51.56%] [G loss: 0.766014]\n",
      "epoch:1 step:1426 [D loss: 0.712622, acc.: 55.47%] [G loss: 0.818034]\n",
      "epoch:1 step:1427 [D loss: 0.780864, acc.: 39.06%] [G loss: 0.819612]\n",
      "epoch:1 step:1428 [D loss: 0.748235, acc.: 42.19%] [G loss: 0.707293]\n",
      "epoch:1 step:1429 [D loss: 0.707718, acc.: 54.69%] [G loss: 0.710274]\n",
      "epoch:1 step:1430 [D loss: 0.749652, acc.: 42.97%] [G loss: 0.809530]\n",
      "epoch:1 step:1431 [D loss: 0.745759, acc.: 50.00%] [G loss: 0.799265]\n",
      "epoch:1 step:1432 [D loss: 0.686652, acc.: 53.12%] [G loss: 0.756057]\n",
      "epoch:1 step:1433 [D loss: 0.711291, acc.: 51.56%] [G loss: 0.844517]\n",
      "epoch:1 step:1434 [D loss: 0.705232, acc.: 50.78%] [G loss: 0.883915]\n",
      "epoch:1 step:1435 [D loss: 0.717860, acc.: 49.22%] [G loss: 0.878809]\n",
      "epoch:1 step:1436 [D loss: 0.712441, acc.: 53.12%] [G loss: 0.853696]\n",
      "epoch:1 step:1437 [D loss: 0.741488, acc.: 44.53%] [G loss: 0.876051]\n",
      "epoch:1 step:1438 [D loss: 0.772279, acc.: 50.00%] [G loss: 0.846050]\n",
      "epoch:1 step:1439 [D loss: 0.771883, acc.: 38.28%] [G loss: 0.764398]\n",
      "epoch:1 step:1440 [D loss: 0.718550, acc.: 46.88%] [G loss: 0.815324]\n",
      "epoch:1 step:1441 [D loss: 0.751432, acc.: 37.50%] [G loss: 0.830915]\n",
      "epoch:1 step:1442 [D loss: 0.796924, acc.: 40.62%] [G loss: 0.793479]\n",
      "epoch:1 step:1443 [D loss: 0.705700, acc.: 53.12%] [G loss: 0.834865]\n",
      "epoch:1 step:1444 [D loss: 0.684965, acc.: 59.38%] [G loss: 0.820179]\n",
      "epoch:1 step:1445 [D loss: 0.739201, acc.: 46.88%] [G loss: 0.789157]\n",
      "epoch:1 step:1446 [D loss: 0.735720, acc.: 53.91%] [G loss: 0.821549]\n",
      "epoch:1 step:1447 [D loss: 0.709234, acc.: 54.69%] [G loss: 0.819205]\n",
      "epoch:1 step:1448 [D loss: 0.729853, acc.: 49.22%] [G loss: 0.767890]\n",
      "epoch:1 step:1449 [D loss: 0.732485, acc.: 49.22%] [G loss: 0.845979]\n",
      "epoch:1 step:1450 [D loss: 0.743129, acc.: 49.22%] [G loss: 0.751969]\n",
      "epoch:1 step:1451 [D loss: 0.759462, acc.: 42.19%] [G loss: 0.768951]\n",
      "epoch:1 step:1452 [D loss: 0.666673, acc.: 62.50%] [G loss: 0.824561]\n",
      "epoch:1 step:1453 [D loss: 0.752819, acc.: 47.66%] [G loss: 0.813673]\n",
      "epoch:1 step:1454 [D loss: 0.712333, acc.: 53.12%] [G loss: 0.880659]\n",
      "epoch:1 step:1455 [D loss: 0.732186, acc.: 49.22%] [G loss: 0.734989]\n",
      "epoch:1 step:1456 [D loss: 0.716752, acc.: 50.78%] [G loss: 0.820623]\n",
      "epoch:1 step:1457 [D loss: 0.678099, acc.: 63.28%] [G loss: 0.783240]\n",
      "epoch:1 step:1458 [D loss: 0.739076, acc.: 52.34%] [G loss: 0.817004]\n",
      "epoch:1 step:1459 [D loss: 0.658726, acc.: 53.91%] [G loss: 0.847768]\n",
      "epoch:1 step:1460 [D loss: 0.685913, acc.: 52.34%] [G loss: 0.829849]\n",
      "epoch:1 step:1461 [D loss: 0.675274, acc.: 52.34%] [G loss: 0.844839]\n",
      "epoch:1 step:1462 [D loss: 0.739871, acc.: 57.81%] [G loss: 0.873183]\n",
      "epoch:1 step:1463 [D loss: 0.726012, acc.: 46.09%] [G loss: 0.787658]\n",
      "epoch:1 step:1464 [D loss: 0.670309, acc.: 61.72%] [G loss: 0.851672]\n",
      "epoch:1 step:1465 [D loss: 0.707118, acc.: 54.69%] [G loss: 0.796902]\n",
      "epoch:1 step:1466 [D loss: 0.676033, acc.: 60.94%] [G loss: 0.896206]\n",
      "epoch:1 step:1467 [D loss: 0.708686, acc.: 54.69%] [G loss: 0.800047]\n",
      "epoch:1 step:1468 [D loss: 0.715589, acc.: 53.91%] [G loss: 0.798788]\n",
      "epoch:1 step:1469 [D loss: 0.687418, acc.: 56.25%] [G loss: 0.900308]\n",
      "epoch:1 step:1470 [D loss: 0.732695, acc.: 50.00%] [G loss: 0.890863]\n",
      "epoch:1 step:1471 [D loss: 0.625713, acc.: 64.06%] [G loss: 0.901009]\n",
      "epoch:1 step:1472 [D loss: 0.690504, acc.: 59.38%] [G loss: 0.817416]\n",
      "epoch:1 step:1473 [D loss: 0.802704, acc.: 46.09%] [G loss: 0.704878]\n",
      "epoch:1 step:1474 [D loss: 0.685527, acc.: 61.72%] [G loss: 0.892663]\n",
      "epoch:1 step:1475 [D loss: 0.722377, acc.: 52.34%] [G loss: 0.884453]\n",
      "epoch:1 step:1476 [D loss: 0.663143, acc.: 61.72%] [G loss: 0.935304]\n",
      "epoch:1 step:1477 [D loss: 0.707676, acc.: 50.00%] [G loss: 0.870750]\n",
      "epoch:1 step:1478 [D loss: 0.745146, acc.: 44.53%] [G loss: 0.814991]\n",
      "epoch:1 step:1479 [D loss: 0.703920, acc.: 55.47%] [G loss: 0.807069]\n",
      "epoch:1 step:1480 [D loss: 0.616526, acc.: 64.06%] [G loss: 0.851852]\n",
      "epoch:1 step:1481 [D loss: 0.663379, acc.: 65.62%] [G loss: 0.898280]\n",
      "epoch:1 step:1482 [D loss: 0.673343, acc.: 57.81%] [G loss: 0.789879]\n",
      "epoch:1 step:1483 [D loss: 0.672630, acc.: 53.91%] [G loss: 0.823498]\n",
      "epoch:1 step:1484 [D loss: 0.645453, acc.: 63.28%] [G loss: 0.845384]\n",
      "epoch:1 step:1485 [D loss: 0.642399, acc.: 65.62%] [G loss: 0.801657]\n",
      "epoch:1 step:1486 [D loss: 0.646242, acc.: 59.38%] [G loss: 0.885389]\n",
      "epoch:1 step:1487 [D loss: 0.641427, acc.: 62.50%] [G loss: 0.910054]\n",
      "epoch:1 step:1488 [D loss: 0.695168, acc.: 53.91%] [G loss: 0.834875]\n",
      "epoch:1 step:1489 [D loss: 0.702536, acc.: 52.34%] [G loss: 0.875416]\n",
      "epoch:1 step:1490 [D loss: 0.674860, acc.: 64.84%] [G loss: 0.879624]\n",
      "epoch:1 step:1491 [D loss: 0.741950, acc.: 42.97%] [G loss: 0.927032]\n",
      "epoch:1 step:1492 [D loss: 0.719842, acc.: 57.03%] [G loss: 0.889333]\n",
      "epoch:1 step:1493 [D loss: 0.718177, acc.: 53.91%] [G loss: 0.916865]\n",
      "epoch:1 step:1494 [D loss: 0.812453, acc.: 36.72%] [G loss: 0.848899]\n",
      "epoch:1 step:1495 [D loss: 0.643369, acc.: 63.28%] [G loss: 0.928935]\n",
      "epoch:1 step:1496 [D loss: 0.744065, acc.: 50.00%] [G loss: 0.797338]\n",
      "epoch:1 step:1497 [D loss: 0.653958, acc.: 61.72%] [G loss: 0.824348]\n",
      "epoch:1 step:1498 [D loss: 0.760657, acc.: 46.88%] [G loss: 0.785282]\n",
      "epoch:1 step:1499 [D loss: 0.807445, acc.: 42.97%] [G loss: 0.818912]\n",
      "epoch:1 step:1500 [D loss: 0.714156, acc.: 50.00%] [G loss: 0.987853]\n",
      "epoch:1 step:1501 [D loss: 0.734534, acc.: 53.12%] [G loss: 0.977087]\n",
      "epoch:1 step:1502 [D loss: 0.749327, acc.: 46.88%] [G loss: 0.849663]\n",
      "epoch:1 step:1503 [D loss: 0.783708, acc.: 46.88%] [G loss: 0.841032]\n",
      "epoch:1 step:1504 [D loss: 0.863731, acc.: 36.72%] [G loss: 0.764980]\n",
      "epoch:1 step:1505 [D loss: 0.737398, acc.: 50.78%] [G loss: 0.773019]\n",
      "epoch:1 step:1506 [D loss: 0.707112, acc.: 53.91%] [G loss: 0.906796]\n",
      "epoch:1 step:1507 [D loss: 0.746853, acc.: 52.34%] [G loss: 0.837314]\n",
      "epoch:1 step:1508 [D loss: 0.734920, acc.: 48.44%] [G loss: 0.848897]\n",
      "epoch:1 step:1509 [D loss: 0.692830, acc.: 50.00%] [G loss: 0.892496]\n",
      "epoch:1 step:1510 [D loss: 0.738738, acc.: 53.12%] [G loss: 0.949175]\n",
      "epoch:1 step:1511 [D loss: 0.700609, acc.: 53.12%] [G loss: 0.870095]\n",
      "epoch:1 step:1512 [D loss: 0.673811, acc.: 57.03%] [G loss: 0.825564]\n",
      "epoch:1 step:1513 [D loss: 0.687967, acc.: 54.69%] [G loss: 0.876859]\n",
      "epoch:1 step:1514 [D loss: 0.764312, acc.: 39.06%] [G loss: 0.810766]\n",
      "epoch:1 step:1515 [D loss: 0.690481, acc.: 53.12%] [G loss: 0.862458]\n",
      "epoch:1 step:1516 [D loss: 0.677313, acc.: 56.25%] [G loss: 0.854997]\n",
      "epoch:1 step:1517 [D loss: 0.752794, acc.: 48.44%] [G loss: 0.962945]\n",
      "epoch:1 step:1518 [D loss: 0.668255, acc.: 59.38%] [G loss: 0.974001]\n",
      "epoch:1 step:1519 [D loss: 0.671818, acc.: 63.28%] [G loss: 0.868228]\n",
      "epoch:1 step:1520 [D loss: 0.733593, acc.: 52.34%] [G loss: 0.779772]\n",
      "epoch:1 step:1521 [D loss: 0.699843, acc.: 58.59%] [G loss: 0.831365]\n",
      "epoch:1 step:1522 [D loss: 0.683618, acc.: 60.16%] [G loss: 0.806816]\n",
      "epoch:1 step:1523 [D loss: 0.720533, acc.: 53.91%] [G loss: 0.824241]\n",
      "epoch:1 step:1524 [D loss: 0.685533, acc.: 54.69%] [G loss: 0.838601]\n",
      "epoch:1 step:1525 [D loss: 0.758902, acc.: 46.88%] [G loss: 0.883229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1526 [D loss: 0.748956, acc.: 50.00%] [G loss: 0.790750]\n",
      "epoch:1 step:1527 [D loss: 0.726747, acc.: 49.22%] [G loss: 0.836743]\n",
      "epoch:1 step:1528 [D loss: 0.729061, acc.: 49.22%] [G loss: 0.834611]\n",
      "epoch:1 step:1529 [D loss: 0.690434, acc.: 53.91%] [G loss: 0.812576]\n",
      "epoch:1 step:1530 [D loss: 0.728027, acc.: 53.12%] [G loss: 0.769497]\n",
      "epoch:1 step:1531 [D loss: 0.766677, acc.: 43.75%] [G loss: 0.727275]\n",
      "epoch:1 step:1532 [D loss: 0.738269, acc.: 46.88%] [G loss: 0.750832]\n",
      "epoch:1 step:1533 [D loss: 0.716562, acc.: 53.12%] [G loss: 0.864956]\n",
      "epoch:1 step:1534 [D loss: 0.719715, acc.: 50.78%] [G loss: 0.791939]\n",
      "epoch:1 step:1535 [D loss: 0.717850, acc.: 51.56%] [G loss: 0.790641]\n",
      "epoch:1 step:1536 [D loss: 0.717233, acc.: 47.66%] [G loss: 0.858981]\n",
      "epoch:1 step:1537 [D loss: 0.728390, acc.: 46.88%] [G loss: 0.825370]\n",
      "epoch:1 step:1538 [D loss: 0.744234, acc.: 47.66%] [G loss: 0.727270]\n",
      "epoch:1 step:1539 [D loss: 0.744920, acc.: 46.88%] [G loss: 0.811619]\n",
      "epoch:1 step:1540 [D loss: 0.675510, acc.: 60.16%] [G loss: 0.855322]\n",
      "epoch:1 step:1541 [D loss: 0.739100, acc.: 51.56%] [G loss: 0.823513]\n",
      "epoch:1 step:1542 [D loss: 0.678452, acc.: 60.94%] [G loss: 0.838780]\n",
      "epoch:1 step:1543 [D loss: 0.696391, acc.: 54.69%] [G loss: 0.770385]\n",
      "epoch:1 step:1544 [D loss: 0.700156, acc.: 52.34%] [G loss: 0.785152]\n",
      "epoch:1 step:1545 [D loss: 0.694091, acc.: 54.69%] [G loss: 0.779897]\n",
      "epoch:1 step:1546 [D loss: 0.655979, acc.: 60.16%] [G loss: 0.878006]\n",
      "epoch:1 step:1547 [D loss: 0.603230, acc.: 66.41%] [G loss: 0.800167]\n",
      "epoch:1 step:1548 [D loss: 0.726071, acc.: 51.56%] [G loss: 0.816496]\n",
      "epoch:1 step:1549 [D loss: 0.662581, acc.: 60.94%] [G loss: 0.808328]\n",
      "epoch:1 step:1550 [D loss: 0.691194, acc.: 47.66%] [G loss: 0.888498]\n",
      "epoch:1 step:1551 [D loss: 0.661281, acc.: 68.75%] [G loss: 0.921660]\n",
      "epoch:1 step:1552 [D loss: 0.651682, acc.: 58.59%] [G loss: 0.892566]\n",
      "epoch:1 step:1553 [D loss: 0.649934, acc.: 63.28%] [G loss: 0.885882]\n",
      "epoch:1 step:1554 [D loss: 0.647048, acc.: 58.59%] [G loss: 0.901411]\n",
      "epoch:1 step:1555 [D loss: 0.699442, acc.: 56.25%] [G loss: 0.738238]\n",
      "epoch:1 step:1556 [D loss: 0.718383, acc.: 49.22%] [G loss: 0.776639]\n",
      "epoch:1 step:1557 [D loss: 0.669899, acc.: 57.03%] [G loss: 0.740367]\n",
      "epoch:1 step:1558 [D loss: 0.737723, acc.: 49.22%] [G loss: 0.754663]\n",
      "epoch:1 step:1559 [D loss: 0.706884, acc.: 53.91%] [G loss: 0.835873]\n",
      "epoch:1 step:1560 [D loss: 0.755019, acc.: 47.66%] [G loss: 0.917116]\n",
      "epoch:1 step:1561 [D loss: 0.814741, acc.: 41.41%] [G loss: 0.797638]\n",
      "epoch:1 step:1562 [D loss: 0.712856, acc.: 55.47%] [G loss: 0.835763]\n",
      "epoch:2 step:1563 [D loss: 0.697951, acc.: 53.91%] [G loss: 0.908982]\n",
      "epoch:2 step:1564 [D loss: 0.741856, acc.: 50.00%] [G loss: 0.845533]\n",
      "epoch:2 step:1565 [D loss: 0.719643, acc.: 57.03%] [G loss: 0.829834]\n",
      "epoch:2 step:1566 [D loss: 0.718308, acc.: 52.34%] [G loss: 0.841271]\n",
      "epoch:2 step:1567 [D loss: 0.767340, acc.: 49.22%] [G loss: 0.874802]\n",
      "epoch:2 step:1568 [D loss: 0.684807, acc.: 57.03%] [G loss: 0.952610]\n",
      "epoch:2 step:1569 [D loss: 0.628036, acc.: 68.75%] [G loss: 1.010746]\n",
      "epoch:2 step:1570 [D loss: 0.659924, acc.: 62.50%] [G loss: 0.958805]\n",
      "epoch:2 step:1571 [D loss: 0.654266, acc.: 60.16%] [G loss: 0.893855]\n",
      "epoch:2 step:1572 [D loss: 0.657350, acc.: 62.50%] [G loss: 0.835152]\n",
      "epoch:2 step:1573 [D loss: 0.671018, acc.: 58.59%] [G loss: 0.820016]\n",
      "epoch:2 step:1574 [D loss: 0.668686, acc.: 60.94%] [G loss: 0.806201]\n",
      "epoch:2 step:1575 [D loss: 0.689276, acc.: 54.69%] [G loss: 0.726509]\n",
      "epoch:2 step:1576 [D loss: 0.730767, acc.: 52.34%] [G loss: 0.857691]\n",
      "epoch:2 step:1577 [D loss: 0.816942, acc.: 37.50%] [G loss: 0.833655]\n",
      "epoch:2 step:1578 [D loss: 0.689020, acc.: 60.94%] [G loss: 0.827468]\n",
      "epoch:2 step:1579 [D loss: 0.768185, acc.: 47.66%] [G loss: 0.963976]\n",
      "epoch:2 step:1580 [D loss: 0.723443, acc.: 57.81%] [G loss: 0.963733]\n",
      "epoch:2 step:1581 [D loss: 0.696272, acc.: 53.91%] [G loss: 1.022806]\n",
      "epoch:2 step:1582 [D loss: 0.711212, acc.: 52.34%] [G loss: 0.887940]\n",
      "epoch:2 step:1583 [D loss: 0.694478, acc.: 55.47%] [G loss: 0.866103]\n",
      "epoch:2 step:1584 [D loss: 0.674723, acc.: 60.16%] [G loss: 0.883206]\n",
      "epoch:2 step:1585 [D loss: 0.596890, acc.: 71.09%] [G loss: 1.043838]\n",
      "epoch:2 step:1586 [D loss: 0.704554, acc.: 57.81%] [G loss: 0.829629]\n",
      "epoch:2 step:1587 [D loss: 0.679812, acc.: 60.16%] [G loss: 0.848865]\n",
      "epoch:2 step:1588 [D loss: 0.660244, acc.: 58.59%] [G loss: 0.859534]\n",
      "epoch:2 step:1589 [D loss: 0.587133, acc.: 72.66%] [G loss: 0.863655]\n",
      "epoch:2 step:1590 [D loss: 0.599727, acc.: 71.09%] [G loss: 0.757057]\n",
      "epoch:2 step:1591 [D loss: 0.609670, acc.: 71.88%] [G loss: 0.819233]\n",
      "epoch:2 step:1592 [D loss: 0.657518, acc.: 55.47%] [G loss: 0.837566]\n",
      "epoch:2 step:1593 [D loss: 0.639066, acc.: 63.28%] [G loss: 0.749126]\n",
      "epoch:2 step:1594 [D loss: 0.654379, acc.: 60.94%] [G loss: 0.743900]\n",
      "epoch:2 step:1595 [D loss: 0.666560, acc.: 58.59%] [G loss: 0.855533]\n",
      "epoch:2 step:1596 [D loss: 0.633745, acc.: 64.84%] [G loss: 0.796701]\n",
      "epoch:2 step:1597 [D loss: 0.771156, acc.: 46.09%] [G loss: 0.622826]\n",
      "epoch:2 step:1598 [D loss: 0.703920, acc.: 52.34%] [G loss: 0.799916]\n",
      "epoch:2 step:1599 [D loss: 0.706517, acc.: 57.81%] [G loss: 0.741663]\n",
      "epoch:2 step:1600 [D loss: 0.697431, acc.: 54.69%] [G loss: 0.724643]\n",
      "epoch:2 step:1601 [D loss: 0.656684, acc.: 62.50%] [G loss: 0.752349]\n",
      "epoch:2 step:1602 [D loss: 0.725528, acc.: 45.31%] [G loss: 0.811073]\n",
      "epoch:2 step:1603 [D loss: 0.775049, acc.: 50.00%] [G loss: 0.810797]\n",
      "epoch:2 step:1604 [D loss: 0.806808, acc.: 39.06%] [G loss: 0.768695]\n",
      "epoch:2 step:1605 [D loss: 0.780436, acc.: 47.66%] [G loss: 0.907850]\n",
      "epoch:2 step:1606 [D loss: 0.682383, acc.: 58.59%] [G loss: 0.791651]\n",
      "epoch:2 step:1607 [D loss: 0.662071, acc.: 56.25%] [G loss: 0.947414]\n",
      "epoch:2 step:1608 [D loss: 0.689684, acc.: 55.47%] [G loss: 0.879517]\n",
      "epoch:2 step:1609 [D loss: 0.737613, acc.: 47.66%] [G loss: 0.908569]\n",
      "epoch:2 step:1610 [D loss: 0.628985, acc.: 66.41%] [G loss: 0.899864]\n",
      "epoch:2 step:1611 [D loss: 0.712601, acc.: 50.00%] [G loss: 0.889993]\n",
      "epoch:2 step:1612 [D loss: 0.651703, acc.: 66.41%] [G loss: 1.025825]\n",
      "epoch:2 step:1613 [D loss: 0.684986, acc.: 50.78%] [G loss: 0.820050]\n",
      "epoch:2 step:1614 [D loss: 0.682263, acc.: 56.25%] [G loss: 0.974720]\n",
      "epoch:2 step:1615 [D loss: 0.669227, acc.: 55.47%] [G loss: 0.800180]\n",
      "epoch:2 step:1616 [D loss: 0.646456, acc.: 63.28%] [G loss: 0.688029]\n",
      "epoch:2 step:1617 [D loss: 0.680043, acc.: 62.50%] [G loss: 1.033546]\n",
      "epoch:2 step:1618 [D loss: 0.673385, acc.: 60.16%] [G loss: 0.861625]\n",
      "epoch:2 step:1619 [D loss: 0.687722, acc.: 53.91%] [G loss: 0.793161]\n",
      "epoch:2 step:1620 [D loss: 0.687419, acc.: 59.38%] [G loss: 0.822274]\n",
      "epoch:2 step:1621 [D loss: 0.608377, acc.: 68.75%] [G loss: 0.781309]\n",
      "epoch:2 step:1622 [D loss: 0.751823, acc.: 50.00%] [G loss: 0.758959]\n",
      "epoch:2 step:1623 [D loss: 0.649979, acc.: 60.16%] [G loss: 0.885262]\n",
      "epoch:2 step:1624 [D loss: 0.620122, acc.: 64.06%] [G loss: 0.795758]\n",
      "epoch:2 step:1625 [D loss: 0.689323, acc.: 54.69%] [G loss: 0.683432]\n",
      "epoch:2 step:1626 [D loss: 0.794438, acc.: 46.88%] [G loss: 0.718984]\n",
      "epoch:2 step:1627 [D loss: 0.750602, acc.: 50.00%] [G loss: 0.637994]\n",
      "epoch:2 step:1628 [D loss: 0.769512, acc.: 45.31%] [G loss: 0.719851]\n",
      "epoch:2 step:1629 [D loss: 0.765841, acc.: 48.44%] [G loss: 0.725353]\n",
      "epoch:2 step:1630 [D loss: 0.776315, acc.: 43.75%] [G loss: 0.816103]\n",
      "epoch:2 step:1631 [D loss: 0.730172, acc.: 50.78%] [G loss: 0.852162]\n",
      "epoch:2 step:1632 [D loss: 0.753112, acc.: 45.31%] [G loss: 0.762155]\n",
      "epoch:2 step:1633 [D loss: 0.813258, acc.: 41.41%] [G loss: 0.794263]\n",
      "epoch:2 step:1634 [D loss: 0.670304, acc.: 57.81%] [G loss: 0.819701]\n",
      "epoch:2 step:1635 [D loss: 0.699793, acc.: 53.91%] [G loss: 0.921471]\n",
      "epoch:2 step:1636 [D loss: 0.712697, acc.: 49.22%] [G loss: 0.955835]\n",
      "epoch:2 step:1637 [D loss: 0.600266, acc.: 67.19%] [G loss: 0.925167]\n",
      "epoch:2 step:1638 [D loss: 0.733584, acc.: 45.31%] [G loss: 0.904168]\n",
      "epoch:2 step:1639 [D loss: 0.673986, acc.: 58.59%] [G loss: 0.876772]\n",
      "epoch:2 step:1640 [D loss: 0.632209, acc.: 67.19%] [G loss: 0.827527]\n",
      "epoch:2 step:1641 [D loss: 0.647376, acc.: 63.28%] [G loss: 0.987490]\n",
      "epoch:2 step:1642 [D loss: 0.594629, acc.: 68.75%] [G loss: 0.979044]\n",
      "epoch:2 step:1643 [D loss: 0.703879, acc.: 55.47%] [G loss: 0.809433]\n",
      "epoch:2 step:1644 [D loss: 0.664131, acc.: 61.72%] [G loss: 0.849509]\n",
      "epoch:2 step:1645 [D loss: 0.701501, acc.: 57.81%] [G loss: 0.803593]\n",
      "epoch:2 step:1646 [D loss: 0.633917, acc.: 66.41%] [G loss: 0.774404]\n",
      "epoch:2 step:1647 [D loss: 0.655202, acc.: 61.72%] [G loss: 0.923939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1648 [D loss: 0.636683, acc.: 60.94%] [G loss: 0.838144]\n",
      "epoch:2 step:1649 [D loss: 0.670868, acc.: 55.47%] [G loss: 0.851313]\n",
      "epoch:2 step:1650 [D loss: 0.641140, acc.: 71.09%] [G loss: 0.822147]\n",
      "epoch:2 step:1651 [D loss: 0.628497, acc.: 67.97%] [G loss: 0.831937]\n",
      "epoch:2 step:1652 [D loss: 0.777414, acc.: 48.44%] [G loss: 0.778752]\n",
      "epoch:2 step:1653 [D loss: 0.720565, acc.: 52.34%] [G loss: 0.770611]\n",
      "epoch:2 step:1654 [D loss: 0.634878, acc.: 60.94%] [G loss: 0.797409]\n",
      "epoch:2 step:1655 [D loss: 0.719715, acc.: 47.66%] [G loss: 0.821117]\n",
      "epoch:2 step:1656 [D loss: 0.709602, acc.: 55.47%] [G loss: 0.815495]\n",
      "epoch:2 step:1657 [D loss: 0.723411, acc.: 50.78%] [G loss: 0.718350]\n",
      "epoch:2 step:1658 [D loss: 0.681750, acc.: 58.59%] [G loss: 0.806408]\n",
      "epoch:2 step:1659 [D loss: 0.660128, acc.: 60.94%] [G loss: 0.780116]\n",
      "epoch:2 step:1660 [D loss: 0.694910, acc.: 53.12%] [G loss: 0.796369]\n",
      "epoch:2 step:1661 [D loss: 0.724589, acc.: 52.34%] [G loss: 0.801302]\n",
      "epoch:2 step:1662 [D loss: 0.709340, acc.: 54.69%] [G loss: 0.840660]\n",
      "epoch:2 step:1663 [D loss: 0.671870, acc.: 53.91%] [G loss: 0.749836]\n",
      "epoch:2 step:1664 [D loss: 0.859742, acc.: 37.50%] [G loss: 0.668615]\n",
      "epoch:2 step:1665 [D loss: 0.766204, acc.: 50.00%] [G loss: 0.718815]\n",
      "epoch:2 step:1666 [D loss: 0.747338, acc.: 49.22%] [G loss: 0.843971]\n",
      "epoch:2 step:1667 [D loss: 0.777324, acc.: 44.53%] [G loss: 0.814906]\n",
      "epoch:2 step:1668 [D loss: 0.723657, acc.: 46.09%] [G loss: 0.830991]\n",
      "epoch:2 step:1669 [D loss: 0.797487, acc.: 39.06%] [G loss: 0.853219]\n",
      "epoch:2 step:1670 [D loss: 0.807454, acc.: 42.97%] [G loss: 0.783348]\n",
      "epoch:2 step:1671 [D loss: 0.737817, acc.: 50.78%] [G loss: 0.796831]\n",
      "epoch:2 step:1672 [D loss: 0.676829, acc.: 57.81%] [G loss: 0.830739]\n",
      "epoch:2 step:1673 [D loss: 0.712569, acc.: 53.91%] [G loss: 0.844729]\n",
      "epoch:2 step:1674 [D loss: 0.620221, acc.: 65.62%] [G loss: 0.964866]\n",
      "epoch:2 step:1675 [D loss: 0.628223, acc.: 60.16%] [G loss: 0.832072]\n",
      "epoch:2 step:1676 [D loss: 0.583944, acc.: 73.44%] [G loss: 0.834272]\n",
      "epoch:2 step:1677 [D loss: 0.670409, acc.: 60.16%] [G loss: 0.834269]\n",
      "epoch:2 step:1678 [D loss: 0.645875, acc.: 62.50%] [G loss: 0.788250]\n",
      "epoch:2 step:1679 [D loss: 0.671736, acc.: 54.69%] [G loss: 0.864062]\n",
      "epoch:2 step:1680 [D loss: 0.578349, acc.: 69.53%] [G loss: 0.900304]\n",
      "epoch:2 step:1681 [D loss: 0.666076, acc.: 57.03%] [G loss: 0.897792]\n",
      "epoch:2 step:1682 [D loss: 0.694953, acc.: 52.34%] [G loss: 0.891587]\n",
      "epoch:2 step:1683 [D loss: 0.670973, acc.: 62.50%] [G loss: 0.891142]\n",
      "epoch:2 step:1684 [D loss: 0.691748, acc.: 63.28%] [G loss: 0.768423]\n",
      "epoch:2 step:1685 [D loss: 0.647391, acc.: 60.16%] [G loss: 0.847314]\n",
      "epoch:2 step:1686 [D loss: 0.671783, acc.: 61.72%] [G loss: 0.782164]\n",
      "epoch:2 step:1687 [D loss: 0.771539, acc.: 37.50%] [G loss: 0.727391]\n",
      "epoch:2 step:1688 [D loss: 0.692732, acc.: 50.78%] [G loss: 0.867955]\n",
      "epoch:2 step:1689 [D loss: 0.662413, acc.: 64.06%] [G loss: 0.679773]\n",
      "epoch:2 step:1690 [D loss: 0.710776, acc.: 53.91%] [G loss: 0.737364]\n",
      "epoch:2 step:1691 [D loss: 0.689574, acc.: 57.81%] [G loss: 0.825747]\n",
      "epoch:2 step:1692 [D loss: 0.666855, acc.: 60.16%] [G loss: 0.810821]\n",
      "epoch:2 step:1693 [D loss: 0.699389, acc.: 56.25%] [G loss: 0.725781]\n",
      "epoch:2 step:1694 [D loss: 0.731180, acc.: 52.34%] [G loss: 0.750262]\n",
      "epoch:2 step:1695 [D loss: 0.761530, acc.: 47.66%] [G loss: 0.741440]\n",
      "epoch:2 step:1696 [D loss: 0.713305, acc.: 52.34%] [G loss: 0.822258]\n",
      "epoch:2 step:1697 [D loss: 0.816642, acc.: 42.97%] [G loss: 0.859582]\n",
      "epoch:2 step:1698 [D loss: 0.675421, acc.: 59.38%] [G loss: 0.876084]\n",
      "epoch:2 step:1699 [D loss: 0.707675, acc.: 48.44%] [G loss: 0.927401]\n",
      "epoch:2 step:1700 [D loss: 0.750146, acc.: 48.44%] [G loss: 0.734929]\n",
      "epoch:2 step:1701 [D loss: 0.739416, acc.: 50.78%] [G loss: 0.767462]\n",
      "epoch:2 step:1702 [D loss: 0.658779, acc.: 54.69%] [G loss: 0.748649]\n",
      "epoch:2 step:1703 [D loss: 0.714674, acc.: 53.12%] [G loss: 0.872111]\n",
      "epoch:2 step:1704 [D loss: 0.670316, acc.: 61.72%] [G loss: 0.886487]\n",
      "epoch:2 step:1705 [D loss: 0.675805, acc.: 63.28%] [G loss: 0.906037]\n",
      "epoch:2 step:1706 [D loss: 0.650104, acc.: 65.62%] [G loss: 0.871743]\n",
      "epoch:2 step:1707 [D loss: 0.644087, acc.: 67.19%] [G loss: 0.923740]\n",
      "epoch:2 step:1708 [D loss: 0.619457, acc.: 67.97%] [G loss: 0.900392]\n",
      "epoch:2 step:1709 [D loss: 0.687644, acc.: 56.25%] [G loss: 0.919161]\n",
      "epoch:2 step:1710 [D loss: 0.665179, acc.: 60.94%] [G loss: 0.844724]\n",
      "epoch:2 step:1711 [D loss: 0.633996, acc.: 64.84%] [G loss: 0.909645]\n",
      "epoch:2 step:1712 [D loss: 0.684268, acc.: 59.38%] [G loss: 0.866591]\n",
      "epoch:2 step:1713 [D loss: 0.677742, acc.: 58.59%] [G loss: 0.852528]\n",
      "epoch:2 step:1714 [D loss: 0.707521, acc.: 52.34%] [G loss: 0.919753]\n",
      "epoch:2 step:1715 [D loss: 0.631558, acc.: 65.62%] [G loss: 0.880381]\n",
      "epoch:2 step:1716 [D loss: 0.713723, acc.: 50.78%] [G loss: 0.764962]\n",
      "epoch:2 step:1717 [D loss: 0.701178, acc.: 53.91%] [G loss: 0.854060]\n",
      "epoch:2 step:1718 [D loss: 0.650479, acc.: 63.28%] [G loss: 0.749048]\n",
      "epoch:2 step:1719 [D loss: 0.696405, acc.: 60.94%] [G loss: 0.836080]\n",
      "epoch:2 step:1720 [D loss: 0.645696, acc.: 64.84%] [G loss: 0.775404]\n",
      "epoch:2 step:1721 [D loss: 0.684860, acc.: 55.47%] [G loss: 0.776873]\n",
      "epoch:2 step:1722 [D loss: 0.606597, acc.: 66.41%] [G loss: 0.710577]\n",
      "epoch:2 step:1723 [D loss: 0.656433, acc.: 58.59%] [G loss: 0.742757]\n",
      "epoch:2 step:1724 [D loss: 0.762847, acc.: 46.09%] [G loss: 0.702127]\n",
      "epoch:2 step:1725 [D loss: 0.756292, acc.: 46.88%] [G loss: 0.691104]\n",
      "epoch:2 step:1726 [D loss: 0.721493, acc.: 53.91%] [G loss: 0.752038]\n",
      "epoch:2 step:1727 [D loss: 0.721362, acc.: 50.78%] [G loss: 0.906163]\n",
      "epoch:2 step:1728 [D loss: 0.735111, acc.: 50.00%] [G loss: 0.926279]\n",
      "epoch:2 step:1729 [D loss: 0.798274, acc.: 40.62%] [G loss: 0.734232]\n",
      "epoch:2 step:1730 [D loss: 0.739600, acc.: 44.53%] [G loss: 0.788787]\n",
      "epoch:2 step:1731 [D loss: 0.683431, acc.: 55.47%] [G loss: 0.771595]\n",
      "epoch:2 step:1732 [D loss: 0.725477, acc.: 50.00%] [G loss: 0.784851]\n",
      "epoch:2 step:1733 [D loss: 0.645890, acc.: 61.72%] [G loss: 0.801222]\n",
      "epoch:2 step:1734 [D loss: 0.736334, acc.: 46.09%] [G loss: 0.813459]\n",
      "epoch:2 step:1735 [D loss: 0.706785, acc.: 52.34%] [G loss: 0.908027]\n",
      "epoch:2 step:1736 [D loss: 0.701835, acc.: 48.44%] [G loss: 0.854600]\n",
      "epoch:2 step:1737 [D loss: 0.737758, acc.: 46.88%] [G loss: 0.886555]\n",
      "epoch:2 step:1738 [D loss: 0.718795, acc.: 47.66%] [G loss: 0.863834]\n",
      "epoch:2 step:1739 [D loss: 0.699693, acc.: 55.47%] [G loss: 0.847626]\n",
      "epoch:2 step:1740 [D loss: 0.693394, acc.: 56.25%] [G loss: 0.845153]\n",
      "epoch:2 step:1741 [D loss: 0.676513, acc.: 53.91%] [G loss: 0.848490]\n",
      "epoch:2 step:1742 [D loss: 0.723283, acc.: 47.66%] [G loss: 0.815902]\n",
      "epoch:2 step:1743 [D loss: 0.652691, acc.: 61.72%] [G loss: 0.827626]\n",
      "epoch:2 step:1744 [D loss: 0.675259, acc.: 60.16%] [G loss: 0.887942]\n",
      "epoch:2 step:1745 [D loss: 0.711320, acc.: 51.56%] [G loss: 0.847267]\n",
      "epoch:2 step:1746 [D loss: 0.668282, acc.: 57.81%] [G loss: 0.964365]\n",
      "epoch:2 step:1747 [D loss: 0.704612, acc.: 62.50%] [G loss: 0.981442]\n",
      "epoch:2 step:1748 [D loss: 0.665749, acc.: 56.25%] [G loss: 0.952967]\n",
      "epoch:2 step:1749 [D loss: 0.667683, acc.: 60.16%] [G loss: 0.898992]\n",
      "epoch:2 step:1750 [D loss: 0.729520, acc.: 50.00%] [G loss: 0.833266]\n",
      "epoch:2 step:1751 [D loss: 0.627058, acc.: 64.06%] [G loss: 0.900084]\n",
      "epoch:2 step:1752 [D loss: 0.564256, acc.: 76.56%] [G loss: 0.973292]\n",
      "epoch:2 step:1753 [D loss: 0.707392, acc.: 57.81%] [G loss: 0.907616]\n",
      "epoch:2 step:1754 [D loss: 0.653586, acc.: 57.81%] [G loss: 0.858366]\n",
      "epoch:2 step:1755 [D loss: 0.628925, acc.: 68.75%] [G loss: 0.780772]\n",
      "epoch:2 step:1756 [D loss: 0.624508, acc.: 60.16%] [G loss: 0.924740]\n",
      "epoch:2 step:1757 [D loss: 0.671370, acc.: 60.94%] [G loss: 0.792162]\n",
      "epoch:2 step:1758 [D loss: 0.697688, acc.: 55.47%] [G loss: 0.662277]\n",
      "epoch:2 step:1759 [D loss: 0.659915, acc.: 60.16%] [G loss: 0.803134]\n",
      "epoch:2 step:1760 [D loss: 0.697558, acc.: 55.47%] [G loss: 0.784493]\n",
      "epoch:2 step:1761 [D loss: 0.691030, acc.: 56.25%] [G loss: 0.706077]\n",
      "epoch:2 step:1762 [D loss: 0.700240, acc.: 57.03%] [G loss: 0.698729]\n",
      "epoch:2 step:1763 [D loss: 0.741878, acc.: 56.25%] [G loss: 0.717503]\n",
      "epoch:2 step:1764 [D loss: 0.770414, acc.: 46.09%] [G loss: 0.687093]\n",
      "epoch:2 step:1765 [D loss: 0.771202, acc.: 46.88%] [G loss: 0.703386]\n",
      "epoch:2 step:1766 [D loss: 0.739546, acc.: 46.09%] [G loss: 0.768478]\n",
      "epoch:2 step:1767 [D loss: 0.674208, acc.: 61.72%] [G loss: 0.743017]\n",
      "epoch:2 step:1768 [D loss: 0.735911, acc.: 53.12%] [G loss: 0.738356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1769 [D loss: 0.721315, acc.: 50.00%] [G loss: 0.729124]\n",
      "epoch:2 step:1770 [D loss: 0.747505, acc.: 43.75%] [G loss: 0.838055]\n",
      "epoch:2 step:1771 [D loss: 0.845055, acc.: 36.72%] [G loss: 0.721073]\n",
      "epoch:2 step:1772 [D loss: 0.756830, acc.: 41.41%] [G loss: 0.851006]\n",
      "epoch:2 step:1773 [D loss: 0.709913, acc.: 48.44%] [G loss: 0.919960]\n",
      "epoch:2 step:1774 [D loss: 0.706788, acc.: 54.69%] [G loss: 0.965807]\n",
      "epoch:2 step:1775 [D loss: 0.691567, acc.: 59.38%] [G loss: 0.948156]\n",
      "epoch:2 step:1776 [D loss: 0.732718, acc.: 46.88%] [G loss: 0.917831]\n",
      "epoch:2 step:1777 [D loss: 0.711371, acc.: 51.56%] [G loss: 0.995913]\n",
      "epoch:2 step:1778 [D loss: 0.720351, acc.: 54.69%] [G loss: 0.968843]\n",
      "epoch:2 step:1779 [D loss: 0.652984, acc.: 60.94%] [G loss: 0.948906]\n",
      "epoch:2 step:1780 [D loss: 0.696317, acc.: 60.94%] [G loss: 0.945922]\n",
      "epoch:2 step:1781 [D loss: 0.702053, acc.: 53.91%] [G loss: 0.835576]\n",
      "epoch:2 step:1782 [D loss: 0.580355, acc.: 74.22%] [G loss: 0.823067]\n",
      "epoch:2 step:1783 [D loss: 0.598708, acc.: 70.31%] [G loss: 0.788958]\n",
      "epoch:2 step:1784 [D loss: 0.563155, acc.: 74.22%] [G loss: 0.764912]\n",
      "epoch:2 step:1785 [D loss: 0.669815, acc.: 57.03%] [G loss: 0.803907]\n",
      "epoch:2 step:1786 [D loss: 0.639575, acc.: 69.53%] [G loss: 0.733967]\n",
      "epoch:2 step:1787 [D loss: 0.592534, acc.: 67.97%] [G loss: 0.797119]\n",
      "epoch:2 step:1788 [D loss: 0.628532, acc.: 67.19%] [G loss: 0.625603]\n",
      "epoch:2 step:1789 [D loss: 0.711663, acc.: 55.47%] [G loss: 0.776841]\n",
      "epoch:2 step:1790 [D loss: 0.657133, acc.: 58.59%] [G loss: 0.677865]\n",
      "epoch:2 step:1791 [D loss: 0.617013, acc.: 66.41%] [G loss: 0.640927]\n",
      "epoch:2 step:1792 [D loss: 0.643788, acc.: 60.94%] [G loss: 0.679095]\n",
      "epoch:2 step:1793 [D loss: 0.735245, acc.: 52.34%] [G loss: 0.782439]\n",
      "epoch:2 step:1794 [D loss: 0.805152, acc.: 42.97%] [G loss: 0.839305]\n",
      "epoch:2 step:1795 [D loss: 0.697585, acc.: 55.47%] [G loss: 0.904384]\n",
      "epoch:2 step:1796 [D loss: 0.668891, acc.: 60.16%] [G loss: 1.051579]\n",
      "epoch:2 step:1797 [D loss: 0.835120, acc.: 44.53%] [G loss: 0.834876]\n",
      "epoch:2 step:1798 [D loss: 0.696298, acc.: 57.03%] [G loss: 0.851157]\n",
      "epoch:2 step:1799 [D loss: 0.760973, acc.: 46.09%] [G loss: 0.769569]\n",
      "epoch:2 step:1800 [D loss: 0.779883, acc.: 41.41%] [G loss: 0.851482]\n",
      "epoch:2 step:1801 [D loss: 0.764650, acc.: 49.22%] [G loss: 0.805607]\n",
      "epoch:2 step:1802 [D loss: 0.718686, acc.: 50.78%] [G loss: 0.841701]\n",
      "epoch:2 step:1803 [D loss: 0.741136, acc.: 50.00%] [G loss: 0.831510]\n",
      "epoch:2 step:1804 [D loss: 0.642117, acc.: 63.28%] [G loss: 0.866594]\n",
      "epoch:2 step:1805 [D loss: 0.759810, acc.: 46.88%] [G loss: 0.865374]\n",
      "epoch:2 step:1806 [D loss: 0.760281, acc.: 50.00%] [G loss: 0.896055]\n",
      "epoch:2 step:1807 [D loss: 0.702278, acc.: 57.03%] [G loss: 0.990036]\n",
      "epoch:2 step:1808 [D loss: 0.670204, acc.: 60.94%] [G loss: 0.993325]\n",
      "epoch:2 step:1809 [D loss: 0.664126, acc.: 60.16%] [G loss: 0.840712]\n",
      "epoch:2 step:1810 [D loss: 0.637445, acc.: 60.94%] [G loss: 0.861244]\n",
      "epoch:2 step:1811 [D loss: 0.672684, acc.: 58.59%] [G loss: 0.951294]\n",
      "epoch:2 step:1812 [D loss: 0.678050, acc.: 64.84%] [G loss: 0.840033]\n",
      "epoch:2 step:1813 [D loss: 0.651602, acc.: 63.28%] [G loss: 0.774427]\n",
      "epoch:2 step:1814 [D loss: 0.646257, acc.: 61.72%] [G loss: 0.844828]\n",
      "epoch:2 step:1815 [D loss: 0.586582, acc.: 74.22%] [G loss: 0.905854]\n",
      "epoch:2 step:1816 [D loss: 0.680647, acc.: 63.28%] [G loss: 0.790849]\n",
      "epoch:2 step:1817 [D loss: 0.700361, acc.: 58.59%] [G loss: 0.815472]\n",
      "epoch:2 step:1818 [D loss: 0.704045, acc.: 54.69%] [G loss: 0.800873]\n",
      "epoch:2 step:1819 [D loss: 0.684442, acc.: 62.50%] [G loss: 0.851008]\n",
      "epoch:2 step:1820 [D loss: 0.676259, acc.: 57.81%] [G loss: 0.907727]\n",
      "epoch:2 step:1821 [D loss: 0.780688, acc.: 53.12%] [G loss: 0.926072]\n",
      "epoch:2 step:1822 [D loss: 0.672404, acc.: 58.59%] [G loss: 0.892802]\n",
      "epoch:2 step:1823 [D loss: 0.824903, acc.: 39.06%] [G loss: 0.782795]\n",
      "epoch:2 step:1824 [D loss: 0.742081, acc.: 48.44%] [G loss: 0.864424]\n",
      "epoch:2 step:1825 [D loss: 0.660542, acc.: 66.41%] [G loss: 0.971905]\n",
      "epoch:2 step:1826 [D loss: 0.682739, acc.: 57.03%] [G loss: 0.873281]\n",
      "epoch:2 step:1827 [D loss: 0.738837, acc.: 46.09%] [G loss: 0.897747]\n",
      "epoch:2 step:1828 [D loss: 0.653633, acc.: 57.03%] [G loss: 0.899901]\n",
      "epoch:2 step:1829 [D loss: 0.662312, acc.: 60.16%] [G loss: 0.947384]\n",
      "epoch:2 step:1830 [D loss: 0.657026, acc.: 66.41%] [G loss: 0.765809]\n",
      "epoch:2 step:1831 [D loss: 0.713891, acc.: 54.69%] [G loss: 0.722585]\n",
      "epoch:2 step:1832 [D loss: 0.587027, acc.: 71.09%] [G loss: 0.686764]\n",
      "epoch:2 step:1833 [D loss: 0.713389, acc.: 51.56%] [G loss: 0.725196]\n",
      "epoch:2 step:1834 [D loss: 0.734608, acc.: 50.78%] [G loss: 0.729688]\n",
      "epoch:2 step:1835 [D loss: 0.761177, acc.: 46.09%] [G loss: 0.852872]\n",
      "epoch:2 step:1836 [D loss: 0.785586, acc.: 46.09%] [G loss: 0.806277]\n",
      "epoch:2 step:1837 [D loss: 0.792741, acc.: 39.06%] [G loss: 0.777969]\n",
      "epoch:2 step:1838 [D loss: 0.705557, acc.: 53.91%] [G loss: 0.814552]\n",
      "epoch:2 step:1839 [D loss: 0.770816, acc.: 49.22%] [G loss: 0.861851]\n",
      "epoch:2 step:1840 [D loss: 0.708171, acc.: 57.03%] [G loss: 0.795919]\n",
      "epoch:2 step:1841 [D loss: 0.695731, acc.: 55.47%] [G loss: 0.968832]\n",
      "epoch:2 step:1842 [D loss: 0.638715, acc.: 62.50%] [G loss: 0.871192]\n",
      "epoch:2 step:1843 [D loss: 0.667263, acc.: 54.69%] [G loss: 0.843766]\n",
      "epoch:2 step:1844 [D loss: 0.756309, acc.: 49.22%] [G loss: 0.795256]\n",
      "epoch:2 step:1845 [D loss: 0.615176, acc.: 71.88%] [G loss: 0.786658]\n",
      "epoch:2 step:1846 [D loss: 0.680702, acc.: 60.16%] [G loss: 0.837411]\n",
      "epoch:2 step:1847 [D loss: 0.684747, acc.: 57.03%] [G loss: 0.931643]\n",
      "epoch:2 step:1848 [D loss: 0.657279, acc.: 61.72%] [G loss: 0.883730]\n",
      "epoch:2 step:1849 [D loss: 0.660072, acc.: 60.94%] [G loss: 0.824275]\n",
      "epoch:2 step:1850 [D loss: 0.667786, acc.: 62.50%] [G loss: 0.800378]\n",
      "epoch:2 step:1851 [D loss: 0.613236, acc.: 68.75%] [G loss: 0.909130]\n",
      "epoch:2 step:1852 [D loss: 0.700625, acc.: 57.81%] [G loss: 0.985529]\n",
      "epoch:2 step:1853 [D loss: 0.627422, acc.: 65.62%] [G loss: 0.863223]\n",
      "epoch:2 step:1854 [D loss: 0.666949, acc.: 63.28%] [G loss: 0.801545]\n",
      "epoch:2 step:1855 [D loss: 0.697098, acc.: 55.47%] [G loss: 0.723856]\n",
      "epoch:2 step:1856 [D loss: 0.769749, acc.: 46.09%] [G loss: 0.787904]\n",
      "epoch:2 step:1857 [D loss: 0.710643, acc.: 53.91%] [G loss: 0.867884]\n",
      "epoch:2 step:1858 [D loss: 0.730687, acc.: 49.22%] [G loss: 0.897198]\n",
      "epoch:2 step:1859 [D loss: 0.724149, acc.: 55.47%] [G loss: 0.852394]\n",
      "epoch:2 step:1860 [D loss: 0.780084, acc.: 50.00%] [G loss: 0.787072]\n",
      "epoch:2 step:1861 [D loss: 0.722842, acc.: 54.69%] [G loss: 0.786898]\n",
      "epoch:2 step:1862 [D loss: 0.690206, acc.: 53.12%] [G loss: 0.777592]\n",
      "epoch:2 step:1863 [D loss: 0.766785, acc.: 51.56%] [G loss: 0.865581]\n",
      "epoch:2 step:1864 [D loss: 0.759812, acc.: 46.09%] [G loss: 0.880658]\n",
      "epoch:2 step:1865 [D loss: 0.651278, acc.: 58.59%] [G loss: 0.884064]\n",
      "epoch:2 step:1866 [D loss: 0.687530, acc.: 55.47%] [G loss: 0.821960]\n",
      "epoch:2 step:1867 [D loss: 0.747088, acc.: 50.00%] [G loss: 0.843741]\n",
      "epoch:2 step:1868 [D loss: 0.722698, acc.: 45.31%] [G loss: 0.835778]\n",
      "epoch:2 step:1869 [D loss: 0.697435, acc.: 53.91%] [G loss: 0.883952]\n",
      "epoch:2 step:1870 [D loss: 0.669172, acc.: 58.59%] [G loss: 0.942772]\n",
      "epoch:2 step:1871 [D loss: 0.714335, acc.: 53.91%] [G loss: 0.883571]\n",
      "epoch:2 step:1872 [D loss: 0.674054, acc.: 63.28%] [G loss: 0.923608]\n",
      "epoch:2 step:1873 [D loss: 0.604043, acc.: 72.66%] [G loss: 0.913097]\n",
      "epoch:2 step:1874 [D loss: 0.647856, acc.: 64.06%] [G loss: 0.910295]\n",
      "epoch:2 step:1875 [D loss: 0.678735, acc.: 57.81%] [G loss: 0.953321]\n",
      "epoch:2 step:1876 [D loss: 0.654984, acc.: 66.41%] [G loss: 0.856740]\n",
      "epoch:2 step:1877 [D loss: 0.626939, acc.: 67.97%] [G loss: 0.827080]\n",
      "epoch:2 step:1878 [D loss: 0.727593, acc.: 52.34%] [G loss: 0.849445]\n",
      "epoch:2 step:1879 [D loss: 0.559714, acc.: 77.34%] [G loss: 0.781089]\n",
      "epoch:2 step:1880 [D loss: 0.737245, acc.: 50.00%] [G loss: 0.840416]\n",
      "epoch:2 step:1881 [D loss: 0.662173, acc.: 64.06%] [G loss: 0.870365]\n",
      "epoch:2 step:1882 [D loss: 0.672625, acc.: 61.72%] [G loss: 0.775757]\n",
      "epoch:2 step:1883 [D loss: 0.741982, acc.: 51.56%] [G loss: 0.871692]\n",
      "epoch:2 step:1884 [D loss: 0.630934, acc.: 61.72%] [G loss: 0.850676]\n",
      "epoch:2 step:1885 [D loss: 0.681512, acc.: 58.59%] [G loss: 0.815863]\n",
      "epoch:2 step:1886 [D loss: 0.717963, acc.: 54.69%] [G loss: 0.800645]\n",
      "epoch:2 step:1887 [D loss: 0.759875, acc.: 49.22%] [G loss: 0.788155]\n",
      "epoch:2 step:1888 [D loss: 0.749544, acc.: 51.56%] [G loss: 0.802306]\n",
      "epoch:2 step:1889 [D loss: 0.737272, acc.: 49.22%] [G loss: 0.773840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1890 [D loss: 0.771725, acc.: 45.31%] [G loss: 0.699214]\n",
      "epoch:2 step:1891 [D loss: 0.755582, acc.: 46.88%] [G loss: 0.671633]\n",
      "epoch:2 step:1892 [D loss: 0.878969, acc.: 35.16%] [G loss: 0.719481]\n",
      "epoch:2 step:1893 [D loss: 0.743689, acc.: 47.66%] [G loss: 0.789094]\n",
      "epoch:2 step:1894 [D loss: 0.675558, acc.: 55.47%] [G loss: 0.932674]\n",
      "epoch:2 step:1895 [D loss: 0.715546, acc.: 50.78%] [G loss: 0.992825]\n",
      "epoch:2 step:1896 [D loss: 0.679391, acc.: 60.94%] [G loss: 0.863610]\n",
      "epoch:2 step:1897 [D loss: 0.672040, acc.: 64.06%] [G loss: 0.851071]\n",
      "epoch:2 step:1898 [D loss: 0.708000, acc.: 57.81%] [G loss: 0.712878]\n",
      "epoch:2 step:1899 [D loss: 0.719604, acc.: 55.47%] [G loss: 0.835956]\n",
      "epoch:2 step:1900 [D loss: 0.767365, acc.: 46.88%] [G loss: 0.743713]\n",
      "epoch:2 step:1901 [D loss: 0.692959, acc.: 59.38%] [G loss: 0.824129]\n",
      "epoch:2 step:1902 [D loss: 0.775558, acc.: 49.22%] [G loss: 0.888909]\n",
      "epoch:2 step:1903 [D loss: 0.666653, acc.: 58.59%] [G loss: 0.958165]\n",
      "epoch:2 step:1904 [D loss: 0.659059, acc.: 62.50%] [G loss: 0.943754]\n",
      "epoch:2 step:1905 [D loss: 0.715901, acc.: 52.34%] [G loss: 0.789916]\n",
      "epoch:2 step:1906 [D loss: 0.739470, acc.: 52.34%] [G loss: 0.801118]\n",
      "epoch:2 step:1907 [D loss: 0.742440, acc.: 49.22%] [G loss: 0.900287]\n",
      "epoch:2 step:1908 [D loss: 0.767930, acc.: 46.09%] [G loss: 0.838847]\n",
      "epoch:2 step:1909 [D loss: 0.700089, acc.: 47.66%] [G loss: 0.837146]\n",
      "epoch:2 step:1910 [D loss: 0.768513, acc.: 50.00%] [G loss: 0.896210]\n",
      "epoch:2 step:1911 [D loss: 0.718882, acc.: 46.09%] [G loss: 0.897196]\n",
      "epoch:2 step:1912 [D loss: 0.705903, acc.: 54.69%] [G loss: 0.912482]\n",
      "epoch:2 step:1913 [D loss: 0.703058, acc.: 53.91%] [G loss: 0.926110]\n",
      "epoch:2 step:1914 [D loss: 0.739852, acc.: 45.31%] [G loss: 0.852957]\n",
      "epoch:2 step:1915 [D loss: 0.730408, acc.: 46.88%] [G loss: 0.793760]\n",
      "epoch:2 step:1916 [D loss: 0.686024, acc.: 57.03%] [G loss: 0.802683]\n",
      "epoch:2 step:1917 [D loss: 0.715013, acc.: 52.34%] [G loss: 0.746688]\n",
      "epoch:2 step:1918 [D loss: 0.759008, acc.: 44.53%] [G loss: 0.823763]\n",
      "epoch:2 step:1919 [D loss: 0.703704, acc.: 57.81%] [G loss: 0.779160]\n",
      "epoch:2 step:1920 [D loss: 0.729362, acc.: 47.66%] [G loss: 0.771992]\n",
      "epoch:2 step:1921 [D loss: 0.744588, acc.: 45.31%] [G loss: 0.890750]\n",
      "epoch:2 step:1922 [D loss: 0.738130, acc.: 50.78%] [G loss: 0.792040]\n",
      "epoch:2 step:1923 [D loss: 0.694701, acc.: 54.69%] [G loss: 0.778951]\n",
      "epoch:2 step:1924 [D loss: 0.746496, acc.: 43.75%] [G loss: 0.740565]\n",
      "epoch:2 step:1925 [D loss: 0.770715, acc.: 50.00%] [G loss: 0.794245]\n",
      "epoch:2 step:1926 [D loss: 0.738345, acc.: 52.34%] [G loss: 0.806857]\n",
      "epoch:2 step:1927 [D loss: 0.747029, acc.: 41.41%] [G loss: 0.827187]\n",
      "epoch:2 step:1928 [D loss: 0.706765, acc.: 53.12%] [G loss: 0.795170]\n",
      "epoch:2 step:1929 [D loss: 0.741882, acc.: 48.44%] [G loss: 0.852003]\n",
      "epoch:2 step:1930 [D loss: 0.672609, acc.: 56.25%] [G loss: 0.877215]\n",
      "epoch:2 step:1931 [D loss: 0.690157, acc.: 58.59%] [G loss: 0.856703]\n",
      "epoch:2 step:1932 [D loss: 0.722188, acc.: 55.47%] [G loss: 0.734410]\n",
      "epoch:2 step:1933 [D loss: 0.650693, acc.: 63.28%] [G loss: 0.780588]\n",
      "epoch:2 step:1934 [D loss: 0.685830, acc.: 53.12%] [G loss: 0.795057]\n",
      "epoch:2 step:1935 [D loss: 0.630789, acc.: 67.97%] [G loss: 0.764675]\n",
      "epoch:2 step:1936 [D loss: 0.670033, acc.: 53.12%] [G loss: 0.796915]\n",
      "epoch:2 step:1937 [D loss: 0.661232, acc.: 58.59%] [G loss: 0.853418]\n",
      "epoch:2 step:1938 [D loss: 0.683115, acc.: 64.84%] [G loss: 0.827556]\n",
      "epoch:2 step:1939 [D loss: 0.619238, acc.: 66.41%] [G loss: 0.830046]\n",
      "epoch:2 step:1940 [D loss: 0.660277, acc.: 59.38%] [G loss: 0.954035]\n",
      "epoch:2 step:1941 [D loss: 0.623631, acc.: 68.75%] [G loss: 0.872261]\n",
      "epoch:2 step:1942 [D loss: 0.650931, acc.: 59.38%] [G loss: 0.825394]\n",
      "epoch:2 step:1943 [D loss: 0.606700, acc.: 67.97%] [G loss: 0.879800]\n",
      "epoch:2 step:1944 [D loss: 0.627504, acc.: 71.88%] [G loss: 0.873670]\n",
      "epoch:2 step:1945 [D loss: 0.672788, acc.: 55.47%] [G loss: 0.874822]\n",
      "epoch:2 step:1946 [D loss: 0.587007, acc.: 71.88%] [G loss: 0.861398]\n",
      "epoch:2 step:1947 [D loss: 0.683821, acc.: 61.72%] [G loss: 0.783409]\n",
      "epoch:2 step:1948 [D loss: 0.638800, acc.: 60.94%] [G loss: 0.780498]\n",
      "epoch:2 step:1949 [D loss: 0.685545, acc.: 57.81%] [G loss: 0.784339]\n",
      "epoch:2 step:1950 [D loss: 0.774914, acc.: 37.50%] [G loss: 0.770861]\n",
      "epoch:2 step:1951 [D loss: 0.652229, acc.: 67.97%] [G loss: 0.888605]\n",
      "epoch:2 step:1952 [D loss: 0.709289, acc.: 51.56%] [G loss: 0.732034]\n",
      "epoch:2 step:1953 [D loss: 0.741720, acc.: 46.88%] [G loss: 0.644566]\n",
      "epoch:2 step:1954 [D loss: 0.700916, acc.: 55.47%] [G loss: 0.696579]\n",
      "epoch:2 step:1955 [D loss: 0.695387, acc.: 57.81%] [G loss: 0.641015]\n",
      "epoch:2 step:1956 [D loss: 0.746854, acc.: 48.44%] [G loss: 0.895244]\n",
      "epoch:2 step:1957 [D loss: 0.738761, acc.: 44.53%] [G loss: 0.821951]\n",
      "epoch:2 step:1958 [D loss: 0.867366, acc.: 30.47%] [G loss: 0.801277]\n",
      "epoch:2 step:1959 [D loss: 0.814679, acc.: 42.97%] [G loss: 0.852955]\n",
      "epoch:2 step:1960 [D loss: 0.782979, acc.: 41.41%] [G loss: 0.730149]\n",
      "epoch:2 step:1961 [D loss: 0.694090, acc.: 54.69%] [G loss: 0.885684]\n",
      "epoch:2 step:1962 [D loss: 0.743434, acc.: 46.88%] [G loss: 0.857075]\n",
      "epoch:2 step:1963 [D loss: 0.670136, acc.: 55.47%] [G loss: 1.002906]\n",
      "epoch:2 step:1964 [D loss: 0.707415, acc.: 53.91%] [G loss: 0.936627]\n",
      "epoch:2 step:1965 [D loss: 0.678964, acc.: 57.03%] [G loss: 0.928582]\n",
      "epoch:2 step:1966 [D loss: 0.685019, acc.: 57.03%] [G loss: 0.853038]\n",
      "epoch:2 step:1967 [D loss: 0.682083, acc.: 60.94%] [G loss: 0.963793]\n",
      "epoch:2 step:1968 [D loss: 0.652869, acc.: 64.84%] [G loss: 1.005485]\n",
      "epoch:2 step:1969 [D loss: 0.733547, acc.: 48.44%] [G loss: 0.865298]\n",
      "epoch:2 step:1970 [D loss: 0.758496, acc.: 48.44%] [G loss: 0.901551]\n",
      "epoch:2 step:1971 [D loss: 0.673094, acc.: 56.25%] [G loss: 0.954535]\n",
      "epoch:2 step:1972 [D loss: 0.642532, acc.: 60.16%] [G loss: 1.013334]\n",
      "epoch:2 step:1973 [D loss: 0.690739, acc.: 60.94%] [G loss: 0.852199]\n",
      "epoch:2 step:1974 [D loss: 0.665217, acc.: 62.50%] [G loss: 0.849237]\n",
      "epoch:2 step:1975 [D loss: 0.671811, acc.: 55.47%] [G loss: 0.889357]\n",
      "epoch:2 step:1976 [D loss: 0.646919, acc.: 64.84%] [G loss: 0.859786]\n",
      "epoch:2 step:1977 [D loss: 0.660008, acc.: 59.38%] [G loss: 0.766350]\n",
      "epoch:2 step:1978 [D loss: 0.673046, acc.: 59.38%] [G loss: 0.826757]\n",
      "epoch:2 step:1979 [D loss: 0.755857, acc.: 46.88%] [G loss: 0.734451]\n",
      "epoch:2 step:1980 [D loss: 0.687279, acc.: 56.25%] [G loss: 0.751732]\n",
      "epoch:2 step:1981 [D loss: 0.694101, acc.: 54.69%] [G loss: 0.790477]\n",
      "epoch:2 step:1982 [D loss: 0.633872, acc.: 64.84%] [G loss: 0.927896]\n",
      "epoch:2 step:1983 [D loss: 0.760674, acc.: 46.09%] [G loss: 0.766282]\n",
      "epoch:2 step:1984 [D loss: 0.671883, acc.: 54.69%] [G loss: 0.828696]\n",
      "epoch:2 step:1985 [D loss: 0.718409, acc.: 50.78%] [G loss: 0.735274]\n",
      "epoch:2 step:1986 [D loss: 0.694145, acc.: 57.03%] [G loss: 0.685635]\n",
      "epoch:2 step:1987 [D loss: 0.661776, acc.: 60.94%] [G loss: 0.814381]\n",
      "epoch:2 step:1988 [D loss: 0.752497, acc.: 49.22%] [G loss: 0.794899]\n",
      "epoch:2 step:1989 [D loss: 0.714985, acc.: 50.78%] [G loss: 0.737720]\n",
      "epoch:2 step:1990 [D loss: 0.676302, acc.: 60.16%] [G loss: 0.797433]\n",
      "epoch:2 step:1991 [D loss: 0.700950, acc.: 54.69%] [G loss: 0.695664]\n",
      "epoch:2 step:1992 [D loss: 0.636399, acc.: 64.06%] [G loss: 0.794876]\n",
      "epoch:2 step:1993 [D loss: 0.783088, acc.: 37.50%] [G loss: 0.793517]\n",
      "epoch:2 step:1994 [D loss: 0.661003, acc.: 63.28%] [G loss: 0.741431]\n",
      "epoch:2 step:1995 [D loss: 0.705329, acc.: 53.12%] [G loss: 0.777368]\n",
      "epoch:2 step:1996 [D loss: 0.772592, acc.: 46.88%] [G loss: 0.801038]\n",
      "epoch:2 step:1997 [D loss: 0.635291, acc.: 62.50%] [G loss: 0.823415]\n",
      "epoch:2 step:1998 [D loss: 0.698140, acc.: 58.59%] [G loss: 0.853708]\n",
      "epoch:2 step:1999 [D loss: 0.693143, acc.: 50.78%] [G loss: 0.883029]\n",
      "epoch:2 step:2000 [D loss: 0.694523, acc.: 51.56%] [G loss: 0.980271]\n",
      "epoch:2 step:2001 [D loss: 0.745494, acc.: 47.66%] [G loss: 0.906506]\n",
      "epoch:2 step:2002 [D loss: 0.673585, acc.: 60.94%] [G loss: 0.837658]\n",
      "epoch:2 step:2003 [D loss: 0.691203, acc.: 53.91%] [G loss: 0.857550]\n",
      "epoch:2 step:2004 [D loss: 0.646350, acc.: 62.50%] [G loss: 0.850382]\n",
      "epoch:2 step:2005 [D loss: 0.681112, acc.: 56.25%] [G loss: 0.936249]\n",
      "epoch:2 step:2006 [D loss: 0.604607, acc.: 69.53%] [G loss: 0.978347]\n",
      "epoch:2 step:2007 [D loss: 0.672667, acc.: 57.81%] [G loss: 0.927050]\n",
      "epoch:2 step:2008 [D loss: 0.730361, acc.: 46.88%] [G loss: 0.888155]\n",
      "epoch:2 step:2009 [D loss: 0.620668, acc.: 64.84%] [G loss: 0.826556]\n",
      "epoch:2 step:2010 [D loss: 0.676917, acc.: 59.38%] [G loss: 0.779388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2011 [D loss: 0.627561, acc.: 64.06%] [G loss: 0.793991]\n",
      "epoch:2 step:2012 [D loss: 0.634456, acc.: 62.50%] [G loss: 0.803310]\n",
      "epoch:2 step:2013 [D loss: 0.653557, acc.: 60.16%] [G loss: 0.867743]\n",
      "epoch:2 step:2014 [D loss: 0.696390, acc.: 49.22%] [G loss: 0.910883]\n",
      "epoch:2 step:2015 [D loss: 0.675592, acc.: 60.16%] [G loss: 0.810512]\n",
      "epoch:2 step:2016 [D loss: 0.666753, acc.: 53.91%] [G loss: 0.794034]\n",
      "epoch:2 step:2017 [D loss: 0.809220, acc.: 43.75%] [G loss: 0.764705]\n",
      "epoch:2 step:2018 [D loss: 0.661865, acc.: 61.72%] [G loss: 0.708688]\n",
      "epoch:2 step:2019 [D loss: 0.677851, acc.: 61.72%] [G loss: 0.770685]\n",
      "epoch:2 step:2020 [D loss: 0.679956, acc.: 51.56%] [G loss: 0.787109]\n",
      "epoch:2 step:2021 [D loss: 0.664530, acc.: 58.59%] [G loss: 0.614348]\n",
      "epoch:2 step:2022 [D loss: 0.777273, acc.: 42.97%] [G loss: 0.732061]\n",
      "epoch:2 step:2023 [D loss: 0.734046, acc.: 50.00%] [G loss: 0.779348]\n",
      "epoch:2 step:2024 [D loss: 0.730460, acc.: 52.34%] [G loss: 0.705900]\n",
      "epoch:2 step:2025 [D loss: 0.713331, acc.: 53.91%] [G loss: 0.724155]\n",
      "epoch:2 step:2026 [D loss: 0.757954, acc.: 40.62%] [G loss: 0.701781]\n",
      "epoch:2 step:2027 [D loss: 0.691682, acc.: 54.69%] [G loss: 0.628996]\n",
      "epoch:2 step:2028 [D loss: 0.607591, acc.: 66.41%] [G loss: 0.684944]\n",
      "epoch:2 step:2029 [D loss: 0.726689, acc.: 49.22%] [G loss: 0.633595]\n",
      "epoch:2 step:2030 [D loss: 0.663038, acc.: 58.59%] [G loss: 0.719770]\n",
      "epoch:2 step:2031 [D loss: 0.701796, acc.: 52.34%] [G loss: 0.669839]\n",
      "epoch:2 step:2032 [D loss: 0.674927, acc.: 53.12%] [G loss: 0.677699]\n",
      "epoch:2 step:2033 [D loss: 0.691921, acc.: 56.25%] [G loss: 0.623594]\n",
      "epoch:2 step:2034 [D loss: 0.828789, acc.: 45.31%] [G loss: 0.724243]\n",
      "epoch:2 step:2035 [D loss: 0.833413, acc.: 41.41%] [G loss: 0.620702]\n",
      "epoch:2 step:2036 [D loss: 0.734986, acc.: 48.44%] [G loss: 0.723697]\n",
      "epoch:2 step:2037 [D loss: 0.796858, acc.: 43.75%] [G loss: 0.764781]\n",
      "epoch:2 step:2038 [D loss: 0.727443, acc.: 47.66%] [G loss: 0.806226]\n",
      "epoch:2 step:2039 [D loss: 0.685116, acc.: 62.50%] [G loss: 0.833370]\n",
      "epoch:2 step:2040 [D loss: 0.743794, acc.: 46.09%] [G loss: 0.969013]\n",
      "epoch:2 step:2041 [D loss: 0.694567, acc.: 53.12%] [G loss: 0.731919]\n",
      "epoch:2 step:2042 [D loss: 0.729565, acc.: 49.22%] [G loss: 0.803786]\n",
      "epoch:2 step:2043 [D loss: 0.700781, acc.: 53.91%] [G loss: 0.844460]\n",
      "epoch:2 step:2044 [D loss: 0.739084, acc.: 47.66%] [G loss: 0.857019]\n",
      "epoch:2 step:2045 [D loss: 0.745449, acc.: 47.66%] [G loss: 0.869573]\n",
      "epoch:2 step:2046 [D loss: 0.664376, acc.: 57.81%] [G loss: 0.794953]\n",
      "epoch:2 step:2047 [D loss: 0.673109, acc.: 71.09%] [G loss: 0.859302]\n",
      "epoch:2 step:2048 [D loss: 0.644865, acc.: 61.72%] [G loss: 0.886903]\n",
      "epoch:2 step:2049 [D loss: 0.643013, acc.: 60.94%] [G loss: 0.891181]\n",
      "epoch:2 step:2050 [D loss: 0.659148, acc.: 57.81%] [G loss: 0.828729]\n",
      "epoch:2 step:2051 [D loss: 0.732890, acc.: 48.44%] [G loss: 0.854341]\n",
      "epoch:2 step:2052 [D loss: 0.609242, acc.: 63.28%] [G loss: 0.777237]\n",
      "epoch:2 step:2053 [D loss: 0.555908, acc.: 80.47%] [G loss: 0.839605]\n",
      "epoch:2 step:2054 [D loss: 0.626359, acc.: 68.75%] [G loss: 0.795632]\n",
      "epoch:2 step:2055 [D loss: 0.583429, acc.: 77.34%] [G loss: 0.862230]\n",
      "epoch:2 step:2056 [D loss: 0.705208, acc.: 55.47%] [G loss: 0.824616]\n",
      "epoch:2 step:2057 [D loss: 0.639556, acc.: 70.31%] [G loss: 0.907216]\n",
      "epoch:2 step:2058 [D loss: 0.696742, acc.: 53.91%] [G loss: 0.728321]\n",
      "epoch:2 step:2059 [D loss: 0.632496, acc.: 64.06%] [G loss: 0.828610]\n",
      "epoch:2 step:2060 [D loss: 0.610656, acc.: 69.53%] [G loss: 0.739172]\n",
      "epoch:2 step:2061 [D loss: 0.633717, acc.: 58.59%] [G loss: 0.616212]\n",
      "epoch:2 step:2062 [D loss: 0.712977, acc.: 55.47%] [G loss: 0.668827]\n",
      "epoch:2 step:2063 [D loss: 0.731913, acc.: 53.12%] [G loss: 0.703026]\n",
      "epoch:2 step:2064 [D loss: 0.628311, acc.: 64.06%] [G loss: 0.683563]\n",
      "epoch:2 step:2065 [D loss: 0.623688, acc.: 63.28%] [G loss: 0.810403]\n",
      "epoch:2 step:2066 [D loss: 0.687204, acc.: 60.94%] [G loss: 0.658613]\n",
      "epoch:2 step:2067 [D loss: 0.607937, acc.: 64.84%] [G loss: 0.679137]\n",
      "epoch:2 step:2068 [D loss: 0.732568, acc.: 57.03%] [G loss: 0.718090]\n",
      "epoch:2 step:2069 [D loss: 0.705405, acc.: 58.59%] [G loss: 0.680242]\n",
      "epoch:2 step:2070 [D loss: 0.738678, acc.: 50.78%] [G loss: 0.685615]\n",
      "epoch:2 step:2071 [D loss: 0.724129, acc.: 50.00%] [G loss: 0.662530]\n",
      "epoch:2 step:2072 [D loss: 0.768955, acc.: 42.97%] [G loss: 0.700671]\n",
      "epoch:2 step:2073 [D loss: 0.780642, acc.: 42.97%] [G loss: 0.876355]\n",
      "epoch:2 step:2074 [D loss: 0.724849, acc.: 52.34%] [G loss: 1.017736]\n",
      "epoch:2 step:2075 [D loss: 0.783567, acc.: 50.78%] [G loss: 1.060377]\n",
      "epoch:2 step:2076 [D loss: 0.772313, acc.: 51.56%] [G loss: 0.835906]\n",
      "epoch:2 step:2077 [D loss: 0.675148, acc.: 59.38%] [G loss: 0.909923]\n",
      "epoch:2 step:2078 [D loss: 0.644467, acc.: 66.41%] [G loss: 0.927854]\n",
      "epoch:2 step:2079 [D loss: 0.648851, acc.: 57.81%] [G loss: 0.968015]\n",
      "epoch:2 step:2080 [D loss: 0.676725, acc.: 59.38%] [G loss: 0.900837]\n",
      "epoch:2 step:2081 [D loss: 0.653170, acc.: 62.50%] [G loss: 0.894698]\n",
      "epoch:2 step:2082 [D loss: 0.680641, acc.: 57.03%] [G loss: 0.940843]\n",
      "epoch:2 step:2083 [D loss: 0.611354, acc.: 64.84%] [G loss: 0.923158]\n",
      "epoch:2 step:2084 [D loss: 0.696775, acc.: 57.03%] [G loss: 0.926899]\n",
      "epoch:2 step:2085 [D loss: 0.702130, acc.: 56.25%] [G loss: 0.796701]\n",
      "epoch:2 step:2086 [D loss: 0.761935, acc.: 45.31%] [G loss: 0.826515]\n",
      "epoch:2 step:2087 [D loss: 0.660625, acc.: 59.38%] [G loss: 0.807205]\n",
      "epoch:2 step:2088 [D loss: 0.831512, acc.: 38.28%] [G loss: 0.752843]\n",
      "epoch:2 step:2089 [D loss: 0.679495, acc.: 57.03%] [G loss: 0.809948]\n",
      "epoch:2 step:2090 [D loss: 0.710333, acc.: 50.00%] [G loss: 0.820055]\n",
      "epoch:2 step:2091 [D loss: 0.700441, acc.: 55.47%] [G loss: 0.798691]\n",
      "epoch:2 step:2092 [D loss: 0.698010, acc.: 52.34%] [G loss: 0.864527]\n",
      "epoch:2 step:2093 [D loss: 0.747435, acc.: 50.00%] [G loss: 0.948276]\n",
      "epoch:2 step:2094 [D loss: 0.693246, acc.: 56.25%] [G loss: 0.879285]\n",
      "epoch:2 step:2095 [D loss: 0.686632, acc.: 58.59%] [G loss: 1.001470]\n",
      "epoch:2 step:2096 [D loss: 0.674893, acc.: 61.72%] [G loss: 1.032362]\n",
      "epoch:2 step:2097 [D loss: 0.667376, acc.: 61.72%] [G loss: 0.988917]\n",
      "epoch:2 step:2098 [D loss: 0.649459, acc.: 63.28%] [G loss: 1.096095]\n",
      "epoch:2 step:2099 [D loss: 0.685469, acc.: 57.81%] [G loss: 1.025095]\n",
      "epoch:2 step:2100 [D loss: 0.644494, acc.: 65.62%] [G loss: 0.940068]\n",
      "epoch:2 step:2101 [D loss: 0.618432, acc.: 65.62%] [G loss: 0.895897]\n",
      "epoch:2 step:2102 [D loss: 0.653636, acc.: 60.16%] [G loss: 0.821767]\n",
      "epoch:2 step:2103 [D loss: 0.635314, acc.: 64.06%] [G loss: 0.928798]\n",
      "epoch:2 step:2104 [D loss: 0.652131, acc.: 61.72%] [G loss: 0.801028]\n",
      "epoch:2 step:2105 [D loss: 0.640894, acc.: 59.38%] [G loss: 0.851275]\n",
      "epoch:2 step:2106 [D loss: 0.696647, acc.: 52.34%] [G loss: 0.949335]\n",
      "epoch:2 step:2107 [D loss: 0.708254, acc.: 53.91%] [G loss: 0.785508]\n",
      "epoch:2 step:2108 [D loss: 0.732366, acc.: 53.91%] [G loss: 0.658389]\n",
      "epoch:2 step:2109 [D loss: 0.704964, acc.: 57.03%] [G loss: 0.755791]\n",
      "epoch:2 step:2110 [D loss: 0.716629, acc.: 50.78%] [G loss: 0.741649]\n",
      "epoch:2 step:2111 [D loss: 0.682996, acc.: 56.25%] [G loss: 0.757606]\n",
      "epoch:2 step:2112 [D loss: 0.807228, acc.: 39.84%] [G loss: 0.783864]\n",
      "epoch:2 step:2113 [D loss: 0.729887, acc.: 52.34%] [G loss: 0.928098]\n",
      "epoch:2 step:2114 [D loss: 0.731203, acc.: 49.22%] [G loss: 0.980414]\n",
      "epoch:2 step:2115 [D loss: 0.703401, acc.: 54.69%] [G loss: 0.992436]\n",
      "epoch:2 step:2116 [D loss: 0.655288, acc.: 58.59%] [G loss: 0.953509]\n",
      "epoch:2 step:2117 [D loss: 0.684609, acc.: 59.38%] [G loss: 0.952217]\n",
      "epoch:2 step:2118 [D loss: 0.728132, acc.: 50.00%] [G loss: 0.783575]\n",
      "epoch:2 step:2119 [D loss: 0.680529, acc.: 57.81%] [G loss: 0.798172]\n",
      "epoch:2 step:2120 [D loss: 0.707311, acc.: 49.22%] [G loss: 0.979612]\n",
      "epoch:2 step:2121 [D loss: 0.739061, acc.: 45.31%] [G loss: 0.780068]\n",
      "epoch:2 step:2122 [D loss: 0.691894, acc.: 56.25%] [G loss: 0.884432]\n",
      "epoch:2 step:2123 [D loss: 0.658441, acc.: 63.28%] [G loss: 0.950529]\n",
      "epoch:2 step:2124 [D loss: 0.667990, acc.: 60.94%] [G loss: 0.839369]\n",
      "epoch:2 step:2125 [D loss: 0.673220, acc.: 58.59%] [G loss: 0.802556]\n",
      "epoch:2 step:2126 [D loss: 0.656581, acc.: 57.03%] [G loss: 0.824592]\n",
      "epoch:2 step:2127 [D loss: 0.722890, acc.: 55.47%] [G loss: 0.829681]\n",
      "epoch:2 step:2128 [D loss: 0.788663, acc.: 46.88%] [G loss: 0.798862]\n",
      "epoch:2 step:2129 [D loss: 0.713084, acc.: 53.12%] [G loss: 0.929672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2130 [D loss: 0.763667, acc.: 47.66%] [G loss: 0.830975]\n",
      "epoch:2 step:2131 [D loss: 0.767352, acc.: 45.31%] [G loss: 0.815087]\n",
      "epoch:2 step:2132 [D loss: 0.791081, acc.: 36.72%] [G loss: 0.778003]\n",
      "epoch:2 step:2133 [D loss: 0.752762, acc.: 50.00%] [G loss: 0.723779]\n",
      "epoch:2 step:2134 [D loss: 0.663204, acc.: 60.94%] [G loss: 0.734218]\n",
      "epoch:2 step:2135 [D loss: 0.737543, acc.: 47.66%] [G loss: 0.733059]\n",
      "epoch:2 step:2136 [D loss: 0.768376, acc.: 43.75%] [G loss: 0.811259]\n",
      "epoch:2 step:2137 [D loss: 0.707142, acc.: 51.56%] [G loss: 0.867420]\n",
      "epoch:2 step:2138 [D loss: 0.633692, acc.: 65.62%] [G loss: 0.888502]\n",
      "epoch:2 step:2139 [D loss: 0.644646, acc.: 64.84%] [G loss: 0.930960]\n",
      "epoch:2 step:2140 [D loss: 0.648104, acc.: 61.72%] [G loss: 0.969209]\n",
      "epoch:2 step:2141 [D loss: 0.619296, acc.: 65.62%] [G loss: 0.883783]\n",
      "epoch:2 step:2142 [D loss: 0.681813, acc.: 60.16%] [G loss: 0.882969]\n",
      "epoch:2 step:2143 [D loss: 0.676261, acc.: 60.16%] [G loss: 0.828352]\n",
      "epoch:2 step:2144 [D loss: 0.628157, acc.: 66.41%] [G loss: 0.937596]\n",
      "epoch:2 step:2145 [D loss: 0.635615, acc.: 61.72%] [G loss: 0.893254]\n",
      "epoch:2 step:2146 [D loss: 0.603101, acc.: 71.09%] [G loss: 0.877276]\n",
      "epoch:2 step:2147 [D loss: 0.705171, acc.: 54.69%] [G loss: 0.862822]\n",
      "epoch:2 step:2148 [D loss: 0.571104, acc.: 75.00%] [G loss: 0.897932]\n",
      "epoch:2 step:2149 [D loss: 0.582599, acc.: 68.75%] [G loss: 0.743373]\n",
      "epoch:2 step:2150 [D loss: 0.711244, acc.: 59.38%] [G loss: 0.780459]\n",
      "epoch:2 step:2151 [D loss: 0.683661, acc.: 53.91%] [G loss: 0.733835]\n",
      "epoch:2 step:2152 [D loss: 0.709060, acc.: 53.12%] [G loss: 0.747278]\n",
      "epoch:2 step:2153 [D loss: 0.699172, acc.: 52.34%] [G loss: 0.781260]\n",
      "epoch:2 step:2154 [D loss: 0.764780, acc.: 49.22%] [G loss: 0.786957]\n",
      "epoch:2 step:2155 [D loss: 0.740112, acc.: 45.31%] [G loss: 0.763714]\n",
      "epoch:2 step:2156 [D loss: 0.873935, acc.: 33.59%] [G loss: 0.841018]\n",
      "epoch:2 step:2157 [D loss: 0.749718, acc.: 48.44%] [G loss: 0.891992]\n",
      "epoch:2 step:2158 [D loss: 0.792835, acc.: 37.50%] [G loss: 0.902302]\n",
      "epoch:2 step:2159 [D loss: 0.689055, acc.: 57.81%] [G loss: 0.939918]\n",
      "epoch:2 step:2160 [D loss: 0.641062, acc.: 64.84%] [G loss: 0.983847]\n",
      "epoch:2 step:2161 [D loss: 0.593121, acc.: 68.75%] [G loss: 1.084047]\n",
      "epoch:2 step:2162 [D loss: 0.630493, acc.: 65.62%] [G loss: 0.919458]\n",
      "epoch:2 step:2163 [D loss: 0.602106, acc.: 67.19%] [G loss: 0.966432]\n",
      "epoch:2 step:2164 [D loss: 0.631743, acc.: 59.38%] [G loss: 0.878538]\n",
      "epoch:2 step:2165 [D loss: 0.712495, acc.: 54.69%] [G loss: 0.874422]\n",
      "epoch:2 step:2166 [D loss: 0.651585, acc.: 64.06%] [G loss: 0.839953]\n",
      "epoch:2 step:2167 [D loss: 0.717690, acc.: 51.56%] [G loss: 0.882693]\n",
      "epoch:2 step:2168 [D loss: 0.664030, acc.: 59.38%] [G loss: 0.817536]\n",
      "epoch:2 step:2169 [D loss: 0.713348, acc.: 50.78%] [G loss: 0.728710]\n",
      "epoch:2 step:2170 [D loss: 0.759371, acc.: 46.88%] [G loss: 0.895791]\n",
      "epoch:2 step:2171 [D loss: 0.675165, acc.: 57.03%] [G loss: 1.002944]\n",
      "epoch:2 step:2172 [D loss: 0.658681, acc.: 64.06%] [G loss: 0.893896]\n",
      "epoch:2 step:2173 [D loss: 0.756605, acc.: 43.75%] [G loss: 0.764482]\n",
      "epoch:2 step:2174 [D loss: 0.702432, acc.: 54.69%] [G loss: 0.849805]\n",
      "epoch:2 step:2175 [D loss: 0.797075, acc.: 42.19%] [G loss: 0.781714]\n",
      "epoch:2 step:2176 [D loss: 0.724651, acc.: 50.78%] [G loss: 0.826802]\n",
      "epoch:2 step:2177 [D loss: 0.775624, acc.: 40.62%] [G loss: 0.873701]\n",
      "epoch:2 step:2178 [D loss: 0.622387, acc.: 65.62%] [G loss: 0.877327]\n",
      "epoch:2 step:2179 [D loss: 0.785079, acc.: 45.31%] [G loss: 0.857661]\n",
      "epoch:2 step:2180 [D loss: 0.691319, acc.: 53.12%] [G loss: 0.918790]\n",
      "epoch:2 step:2181 [D loss: 0.752240, acc.: 53.91%] [G loss: 0.907459]\n",
      "epoch:2 step:2182 [D loss: 0.750556, acc.: 46.09%] [G loss: 0.791420]\n",
      "epoch:2 step:2183 [D loss: 0.658479, acc.: 61.72%] [G loss: 0.866064]\n",
      "epoch:2 step:2184 [D loss: 0.731886, acc.: 55.47%] [G loss: 0.921642]\n",
      "epoch:2 step:2185 [D loss: 0.651243, acc.: 61.72%] [G loss: 0.850442]\n",
      "epoch:2 step:2186 [D loss: 0.614447, acc.: 69.53%] [G loss: 0.835986]\n",
      "epoch:2 step:2187 [D loss: 0.637277, acc.: 69.53%] [G loss: 0.694686]\n",
      "epoch:2 step:2188 [D loss: 0.621523, acc.: 64.06%] [G loss: 0.731961]\n",
      "epoch:2 step:2189 [D loss: 0.751376, acc.: 48.44%] [G loss: 0.829387]\n",
      "epoch:2 step:2190 [D loss: 0.658917, acc.: 60.94%] [G loss: 0.774524]\n",
      "epoch:2 step:2191 [D loss: 0.699682, acc.: 54.69%] [G loss: 0.757646]\n",
      "epoch:2 step:2192 [D loss: 0.814686, acc.: 41.41%] [G loss: 0.769710]\n",
      "epoch:2 step:2193 [D loss: 0.756999, acc.: 46.88%] [G loss: 0.855276]\n",
      "epoch:2 step:2194 [D loss: 0.859828, acc.: 30.47%] [G loss: 0.786956]\n",
      "epoch:2 step:2195 [D loss: 0.805613, acc.: 42.97%] [G loss: 0.899879]\n",
      "epoch:2 step:2196 [D loss: 0.779344, acc.: 42.97%] [G loss: 0.807954]\n",
      "epoch:2 step:2197 [D loss: 0.808994, acc.: 40.62%] [G loss: 0.777411]\n",
      "epoch:2 step:2198 [D loss: 0.785668, acc.: 41.41%] [G loss: 0.918785]\n",
      "epoch:2 step:2199 [D loss: 0.742629, acc.: 44.53%] [G loss: 0.833312]\n",
      "epoch:2 step:2200 [D loss: 0.748597, acc.: 53.12%] [G loss: 0.840699]\n",
      "epoch:2 step:2201 [D loss: 0.748245, acc.: 44.53%] [G loss: 0.801165]\n",
      "epoch:2 step:2202 [D loss: 0.672591, acc.: 56.25%] [G loss: 0.845327]\n",
      "epoch:2 step:2203 [D loss: 0.749225, acc.: 39.06%] [G loss: 0.815223]\n",
      "epoch:2 step:2204 [D loss: 0.707426, acc.: 49.22%] [G loss: 0.866934]\n",
      "epoch:2 step:2205 [D loss: 0.708114, acc.: 57.81%] [G loss: 0.932338]\n",
      "epoch:2 step:2206 [D loss: 0.709661, acc.: 50.00%] [G loss: 0.876299]\n",
      "epoch:2 step:2207 [D loss: 0.703717, acc.: 54.69%] [G loss: 0.922702]\n",
      "epoch:2 step:2208 [D loss: 0.672740, acc.: 60.94%] [G loss: 0.847144]\n",
      "epoch:2 step:2209 [D loss: 0.647681, acc.: 60.94%] [G loss: 0.798709]\n",
      "epoch:2 step:2210 [D loss: 0.627415, acc.: 64.06%] [G loss: 0.829219]\n",
      "epoch:2 step:2211 [D loss: 0.618470, acc.: 67.19%] [G loss: 0.750057]\n",
      "epoch:2 step:2212 [D loss: 0.600262, acc.: 68.75%] [G loss: 0.839352]\n",
      "epoch:2 step:2213 [D loss: 0.604936, acc.: 71.09%] [G loss: 0.946075]\n",
      "epoch:2 step:2214 [D loss: 0.598258, acc.: 68.75%] [G loss: 0.806973]\n",
      "epoch:2 step:2215 [D loss: 0.674243, acc.: 63.28%] [G loss: 0.801885]\n",
      "epoch:2 step:2216 [D loss: 0.642436, acc.: 60.16%] [G loss: 0.893700]\n",
      "epoch:2 step:2217 [D loss: 0.669179, acc.: 57.03%] [G loss: 0.931409]\n",
      "epoch:2 step:2218 [D loss: 0.617733, acc.: 64.84%] [G loss: 0.840794]\n",
      "epoch:2 step:2219 [D loss: 0.679587, acc.: 56.25%] [G loss: 0.799496]\n",
      "epoch:2 step:2220 [D loss: 0.563895, acc.: 77.34%] [G loss: 0.856994]\n",
      "epoch:2 step:2221 [D loss: 0.618887, acc.: 72.66%] [G loss: 0.741893]\n",
      "epoch:2 step:2222 [D loss: 0.709012, acc.: 53.91%] [G loss: 0.763061]\n",
      "epoch:2 step:2223 [D loss: 0.700238, acc.: 54.69%] [G loss: 0.865667]\n",
      "epoch:2 step:2224 [D loss: 0.684788, acc.: 60.16%] [G loss: 0.651147]\n",
      "epoch:2 step:2225 [D loss: 0.665542, acc.: 57.03%] [G loss: 0.597466]\n",
      "epoch:2 step:2226 [D loss: 0.703177, acc.: 55.47%] [G loss: 0.575435]\n",
      "epoch:2 step:2227 [D loss: 0.715199, acc.: 51.56%] [G loss: 0.729694]\n",
      "epoch:2 step:2228 [D loss: 0.716981, acc.: 50.78%] [G loss: 0.811383]\n",
      "epoch:2 step:2229 [D loss: 0.739607, acc.: 54.69%] [G loss: 0.736732]\n",
      "epoch:2 step:2230 [D loss: 0.716714, acc.: 55.47%] [G loss: 0.786450]\n",
      "epoch:2 step:2231 [D loss: 0.770353, acc.: 40.62%] [G loss: 0.827527]\n",
      "epoch:2 step:2232 [D loss: 0.730508, acc.: 50.78%] [G loss: 0.993761]\n",
      "epoch:2 step:2233 [D loss: 0.696492, acc.: 54.69%] [G loss: 0.937494]\n",
      "epoch:2 step:2234 [D loss: 0.671506, acc.: 58.59%] [G loss: 0.876872]\n",
      "epoch:2 step:2235 [D loss: 0.676306, acc.: 57.81%] [G loss: 0.979228]\n",
      "epoch:2 step:2236 [D loss: 0.691611, acc.: 50.78%] [G loss: 0.944850]\n",
      "epoch:2 step:2237 [D loss: 0.671601, acc.: 56.25%] [G loss: 0.951921]\n",
      "epoch:2 step:2238 [D loss: 0.704083, acc.: 53.12%] [G loss: 0.999986]\n",
      "epoch:2 step:2239 [D loss: 0.634865, acc.: 64.84%] [G loss: 0.955448]\n",
      "epoch:2 step:2240 [D loss: 0.668624, acc.: 57.81%] [G loss: 0.941969]\n",
      "epoch:2 step:2241 [D loss: 0.655450, acc.: 60.94%] [G loss: 0.928050]\n",
      "epoch:2 step:2242 [D loss: 0.681469, acc.: 59.38%] [G loss: 0.885053]\n",
      "epoch:2 step:2243 [D loss: 0.689959, acc.: 52.34%] [G loss: 0.899368]\n",
      "epoch:2 step:2244 [D loss: 0.690192, acc.: 54.69%] [G loss: 0.850690]\n",
      "epoch:2 step:2245 [D loss: 0.788196, acc.: 43.75%] [G loss: 0.772055]\n",
      "epoch:2 step:2246 [D loss: 0.702248, acc.: 54.69%] [G loss: 0.741862]\n",
      "epoch:2 step:2247 [D loss: 0.750163, acc.: 47.66%] [G loss: 0.763714]\n",
      "epoch:2 step:2248 [D loss: 0.723910, acc.: 57.03%] [G loss: 0.823738]\n",
      "epoch:2 step:2249 [D loss: 0.754083, acc.: 46.88%] [G loss: 0.875999]\n",
      "epoch:2 step:2250 [D loss: 0.739772, acc.: 48.44%] [G loss: 0.925153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2251 [D loss: 0.675409, acc.: 58.59%] [G loss: 0.988852]\n",
      "epoch:2 step:2252 [D loss: 0.723081, acc.: 49.22%] [G loss: 0.861041]\n",
      "epoch:2 step:2253 [D loss: 0.719808, acc.: 57.03%] [G loss: 0.802117]\n",
      "epoch:2 step:2254 [D loss: 0.808965, acc.: 42.19%] [G loss: 0.878506]\n",
      "epoch:2 step:2255 [D loss: 0.703348, acc.: 53.12%] [G loss: 0.843563]\n",
      "epoch:2 step:2256 [D loss: 0.691129, acc.: 53.91%] [G loss: 0.871457]\n",
      "epoch:2 step:2257 [D loss: 0.682771, acc.: 56.25%] [G loss: 0.839961]\n",
      "epoch:2 step:2258 [D loss: 0.698193, acc.: 53.12%] [G loss: 0.826596]\n",
      "epoch:2 step:2259 [D loss: 0.727598, acc.: 51.56%] [G loss: 0.875795]\n",
      "epoch:2 step:2260 [D loss: 0.646865, acc.: 62.50%] [G loss: 0.888845]\n",
      "epoch:2 step:2261 [D loss: 0.710400, acc.: 52.34%] [G loss: 0.903708]\n",
      "epoch:2 step:2262 [D loss: 0.645634, acc.: 66.41%] [G loss: 0.904438]\n",
      "epoch:2 step:2263 [D loss: 0.701350, acc.: 54.69%] [G loss: 0.836246]\n",
      "epoch:2 step:2264 [D loss: 0.698332, acc.: 57.03%] [G loss: 0.895134]\n",
      "epoch:2 step:2265 [D loss: 0.692332, acc.: 55.47%] [G loss: 0.736985]\n",
      "epoch:2 step:2266 [D loss: 0.702239, acc.: 55.47%] [G loss: 0.736352]\n",
      "epoch:2 step:2267 [D loss: 0.679653, acc.: 57.81%] [G loss: 0.831734]\n",
      "epoch:2 step:2268 [D loss: 0.719428, acc.: 50.00%] [G loss: 0.814752]\n",
      "epoch:2 step:2269 [D loss: 0.813878, acc.: 33.59%] [G loss: 0.735131]\n",
      "epoch:2 step:2270 [D loss: 0.764888, acc.: 48.44%] [G loss: 0.723210]\n",
      "epoch:2 step:2271 [D loss: 0.735819, acc.: 51.56%] [G loss: 0.777659]\n",
      "epoch:2 step:2272 [D loss: 0.753859, acc.: 44.53%] [G loss: 0.827500]\n",
      "epoch:2 step:2273 [D loss: 0.678623, acc.: 58.59%] [G loss: 0.855177]\n",
      "epoch:2 step:2274 [D loss: 0.748553, acc.: 49.22%] [G loss: 0.798462]\n",
      "epoch:2 step:2275 [D loss: 0.737162, acc.: 47.66%] [G loss: 0.936512]\n",
      "epoch:2 step:2276 [D loss: 0.636150, acc.: 64.06%] [G loss: 0.820530]\n",
      "epoch:2 step:2277 [D loss: 0.703805, acc.: 54.69%] [G loss: 0.822271]\n",
      "epoch:2 step:2278 [D loss: 0.681852, acc.: 60.94%] [G loss: 0.827187]\n",
      "epoch:2 step:2279 [D loss: 0.724648, acc.: 55.47%] [G loss: 0.765214]\n",
      "epoch:2 step:2280 [D loss: 0.758858, acc.: 45.31%] [G loss: 0.831879]\n",
      "epoch:2 step:2281 [D loss: 0.794077, acc.: 37.50%] [G loss: 0.827111]\n",
      "epoch:2 step:2282 [D loss: 0.724329, acc.: 50.78%] [G loss: 0.895432]\n",
      "epoch:2 step:2283 [D loss: 0.714181, acc.: 55.47%] [G loss: 0.794689]\n",
      "epoch:2 step:2284 [D loss: 0.654398, acc.: 67.19%] [G loss: 0.880232]\n",
      "epoch:2 step:2285 [D loss: 0.711300, acc.: 50.00%] [G loss: 0.771814]\n",
      "epoch:2 step:2286 [D loss: 0.649752, acc.: 61.72%] [G loss: 0.797825]\n",
      "epoch:2 step:2287 [D loss: 0.725341, acc.: 50.78%] [G loss: 0.768788]\n",
      "epoch:2 step:2288 [D loss: 0.598978, acc.: 69.53%] [G loss: 0.867093]\n",
      "epoch:2 step:2289 [D loss: 0.776954, acc.: 45.31%] [G loss: 0.792824]\n",
      "epoch:2 step:2290 [D loss: 0.663409, acc.: 57.81%] [G loss: 0.855480]\n",
      "epoch:2 step:2291 [D loss: 0.668707, acc.: 64.06%] [G loss: 0.731585]\n",
      "epoch:2 step:2292 [D loss: 0.756601, acc.: 47.66%] [G loss: 0.680951]\n",
      "epoch:2 step:2293 [D loss: 0.746572, acc.: 52.34%] [G loss: 0.668281]\n",
      "epoch:2 step:2294 [D loss: 0.698892, acc.: 55.47%] [G loss: 0.877595]\n",
      "epoch:2 step:2295 [D loss: 0.656159, acc.: 64.84%] [G loss: 0.762879]\n",
      "epoch:2 step:2296 [D loss: 0.648454, acc.: 60.94%] [G loss: 0.792418]\n",
      "epoch:2 step:2297 [D loss: 0.721488, acc.: 53.12%] [G loss: 0.758452]\n",
      "epoch:2 step:2298 [D loss: 0.622560, acc.: 64.84%] [G loss: 0.785920]\n",
      "epoch:2 step:2299 [D loss: 0.730766, acc.: 48.44%] [G loss: 0.772310]\n",
      "epoch:2 step:2300 [D loss: 0.588146, acc.: 70.31%] [G loss: 0.946026]\n",
      "epoch:2 step:2301 [D loss: 0.693640, acc.: 56.25%] [G loss: 0.829259]\n",
      "epoch:2 step:2302 [D loss: 0.735634, acc.: 51.56%] [G loss: 0.904004]\n",
      "epoch:2 step:2303 [D loss: 0.573871, acc.: 72.66%] [G loss: 0.957537]\n",
      "epoch:2 step:2304 [D loss: 0.636140, acc.: 60.94%] [G loss: 0.924526]\n",
      "epoch:2 step:2305 [D loss: 0.625585, acc.: 66.41%] [G loss: 0.874490]\n",
      "epoch:2 step:2306 [D loss: 0.571768, acc.: 75.00%] [G loss: 0.874801]\n",
      "epoch:2 step:2307 [D loss: 0.632014, acc.: 57.03%] [G loss: 0.842547]\n",
      "epoch:2 step:2308 [D loss: 0.655303, acc.: 57.81%] [G loss: 0.952240]\n",
      "epoch:2 step:2309 [D loss: 0.568045, acc.: 72.66%] [G loss: 0.905406]\n",
      "epoch:2 step:2310 [D loss: 0.584069, acc.: 67.19%] [G loss: 0.886120]\n",
      "epoch:2 step:2311 [D loss: 0.599629, acc.: 71.09%] [G loss: 0.933134]\n",
      "epoch:2 step:2312 [D loss: 0.627246, acc.: 66.41%] [G loss: 0.964963]\n",
      "epoch:2 step:2313 [D loss: 0.600523, acc.: 71.88%] [G loss: 0.830957]\n",
      "epoch:2 step:2314 [D loss: 0.575220, acc.: 71.88%] [G loss: 0.696372]\n",
      "epoch:2 step:2315 [D loss: 0.685015, acc.: 55.47%] [G loss: 0.807836]\n",
      "epoch:2 step:2316 [D loss: 0.530267, acc.: 75.78%] [G loss: 0.668103]\n",
      "epoch:2 step:2317 [D loss: 0.615386, acc.: 67.19%] [G loss: 0.769137]\n",
      "epoch:2 step:2318 [D loss: 0.578851, acc.: 72.66%] [G loss: 0.623488]\n",
      "epoch:2 step:2319 [D loss: 0.662542, acc.: 61.72%] [G loss: 0.685580]\n",
      "epoch:2 step:2320 [D loss: 0.699228, acc.: 54.69%] [G loss: 0.665248]\n",
      "epoch:2 step:2321 [D loss: 0.649824, acc.: 58.59%] [G loss: 0.698813]\n",
      "epoch:2 step:2322 [D loss: 0.746124, acc.: 50.00%] [G loss: 0.719657]\n",
      "epoch:2 step:2323 [D loss: 0.771625, acc.: 46.88%] [G loss: 0.652437]\n",
      "epoch:2 step:2324 [D loss: 0.826303, acc.: 39.06%] [G loss: 0.656125]\n",
      "epoch:2 step:2325 [D loss: 0.799642, acc.: 39.06%] [G loss: 0.723385]\n",
      "epoch:2 step:2326 [D loss: 0.753554, acc.: 45.31%] [G loss: 0.873959]\n",
      "epoch:2 step:2327 [D loss: 0.782671, acc.: 42.97%] [G loss: 0.975690]\n",
      "epoch:2 step:2328 [D loss: 0.696585, acc.: 54.69%] [G loss: 0.864275]\n",
      "epoch:2 step:2329 [D loss: 0.604083, acc.: 64.84%] [G loss: 0.992831]\n",
      "epoch:2 step:2330 [D loss: 0.661990, acc.: 59.38%] [G loss: 0.892119]\n",
      "epoch:2 step:2331 [D loss: 0.589123, acc.: 71.88%] [G loss: 1.113273]\n",
      "epoch:2 step:2332 [D loss: 0.651487, acc.: 66.41%] [G loss: 0.862819]\n",
      "epoch:2 step:2333 [D loss: 0.754890, acc.: 50.00%] [G loss: 0.839377]\n",
      "epoch:2 step:2334 [D loss: 0.750744, acc.: 49.22%] [G loss: 0.767387]\n",
      "epoch:2 step:2335 [D loss: 0.753859, acc.: 51.56%] [G loss: 0.736251]\n",
      "epoch:2 step:2336 [D loss: 0.731049, acc.: 52.34%] [G loss: 0.801379]\n",
      "epoch:2 step:2337 [D loss: 0.694270, acc.: 53.91%] [G loss: 0.741575]\n",
      "epoch:2 step:2338 [D loss: 0.752284, acc.: 46.88%] [G loss: 0.839655]\n",
      "epoch:2 step:2339 [D loss: 0.790927, acc.: 41.41%] [G loss: 0.908498]\n",
      "epoch:2 step:2340 [D loss: 0.701899, acc.: 58.59%] [G loss: 0.892354]\n",
      "epoch:2 step:2341 [D loss: 0.764673, acc.: 49.22%] [G loss: 0.880223]\n",
      "epoch:2 step:2342 [D loss: 0.831656, acc.: 35.16%] [G loss: 0.766501]\n",
      "epoch:2 step:2343 [D loss: 0.710308, acc.: 50.78%] [G loss: 0.810647]\n",
      "epoch:3 step:2344 [D loss: 0.708497, acc.: 56.25%] [G loss: 0.784071]\n",
      "epoch:3 step:2345 [D loss: 0.742859, acc.: 47.66%] [G loss: 0.880268]\n",
      "epoch:3 step:2346 [D loss: 0.680677, acc.: 56.25%] [G loss: 0.803285]\n",
      "epoch:3 step:2347 [D loss: 0.750481, acc.: 45.31%] [G loss: 0.815295]\n",
      "epoch:3 step:2348 [D loss: 0.679117, acc.: 61.72%] [G loss: 0.705834]\n",
      "epoch:3 step:2349 [D loss: 0.631308, acc.: 64.06%] [G loss: 0.718255]\n",
      "epoch:3 step:2350 [D loss: 0.685698, acc.: 63.28%] [G loss: 0.722887]\n",
      "epoch:3 step:2351 [D loss: 0.655898, acc.: 59.38%] [G loss: 0.795313]\n",
      "epoch:3 step:2352 [D loss: 0.687869, acc.: 56.25%] [G loss: 0.760327]\n",
      "epoch:3 step:2353 [D loss: 0.706727, acc.: 53.91%] [G loss: 0.757932]\n",
      "epoch:3 step:2354 [D loss: 0.745303, acc.: 47.66%] [G loss: 0.769771]\n",
      "epoch:3 step:2355 [D loss: 0.757323, acc.: 46.88%] [G loss: 0.884837]\n",
      "epoch:3 step:2356 [D loss: 0.720995, acc.: 50.78%] [G loss: 0.789522]\n",
      "epoch:3 step:2357 [D loss: 0.782224, acc.: 42.19%] [G loss: 0.778184]\n",
      "epoch:3 step:2358 [D loss: 0.707256, acc.: 58.59%] [G loss: 0.858303]\n",
      "epoch:3 step:2359 [D loss: 0.793212, acc.: 44.53%] [G loss: 0.753149]\n",
      "epoch:3 step:2360 [D loss: 0.766848, acc.: 48.44%] [G loss: 0.847642]\n",
      "epoch:3 step:2361 [D loss: 0.722671, acc.: 46.09%] [G loss: 0.937179]\n",
      "epoch:3 step:2362 [D loss: 0.663619, acc.: 61.72%] [G loss: 1.006670]\n",
      "epoch:3 step:2363 [D loss: 0.703906, acc.: 47.66%] [G loss: 0.923630]\n",
      "epoch:3 step:2364 [D loss: 0.677694, acc.: 55.47%] [G loss: 1.027366]\n",
      "epoch:3 step:2365 [D loss: 0.678952, acc.: 61.72%] [G loss: 0.910093]\n",
      "epoch:3 step:2366 [D loss: 0.684665, acc.: 54.69%] [G loss: 0.941479]\n",
      "epoch:3 step:2367 [D loss: 0.626840, acc.: 69.53%] [G loss: 0.787983]\n",
      "epoch:3 step:2368 [D loss: 0.617562, acc.: 64.84%] [G loss: 0.845722]\n",
      "epoch:3 step:2369 [D loss: 0.625248, acc.: 63.28%] [G loss: 0.820674]\n",
      "epoch:3 step:2370 [D loss: 0.660655, acc.: 63.28%] [G loss: 0.808683]\n",
      "epoch:3 step:2371 [D loss: 0.699198, acc.: 54.69%] [G loss: 0.821030]\n",
      "epoch:3 step:2372 [D loss: 0.855554, acc.: 33.59%] [G loss: 0.645032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2373 [D loss: 0.594692, acc.: 71.88%] [G loss: 0.652610]\n",
      "epoch:3 step:2374 [D loss: 0.751352, acc.: 44.53%] [G loss: 0.714373]\n",
      "epoch:3 step:2375 [D loss: 0.679270, acc.: 57.03%] [G loss: 0.852726]\n",
      "epoch:3 step:2376 [D loss: 0.745438, acc.: 53.12%] [G loss: 0.718927]\n",
      "epoch:3 step:2377 [D loss: 0.700480, acc.: 52.34%] [G loss: 0.724624]\n",
      "epoch:3 step:2378 [D loss: 0.837050, acc.: 38.28%] [G loss: 0.781746]\n",
      "epoch:3 step:2379 [D loss: 0.700145, acc.: 49.22%] [G loss: 0.801638]\n",
      "epoch:3 step:2380 [D loss: 0.743359, acc.: 46.88%] [G loss: 0.804122]\n",
      "epoch:3 step:2381 [D loss: 0.715964, acc.: 53.91%] [G loss: 0.813480]\n",
      "epoch:3 step:2382 [D loss: 0.698671, acc.: 46.88%] [G loss: 0.812105]\n",
      "epoch:3 step:2383 [D loss: 0.678748, acc.: 58.59%] [G loss: 0.776956]\n",
      "epoch:3 step:2384 [D loss: 0.699268, acc.: 57.03%] [G loss: 0.730673]\n",
      "epoch:3 step:2385 [D loss: 0.738428, acc.: 45.31%] [G loss: 0.869263]\n",
      "epoch:3 step:2386 [D loss: 0.632672, acc.: 67.19%] [G loss: 0.867479]\n",
      "epoch:3 step:2387 [D loss: 0.703720, acc.: 49.22%] [G loss: 0.726150]\n",
      "epoch:3 step:2388 [D loss: 0.620530, acc.: 65.62%] [G loss: 0.852206]\n",
      "epoch:3 step:2389 [D loss: 0.703625, acc.: 59.38%] [G loss: 0.835680]\n",
      "epoch:3 step:2390 [D loss: 0.616588, acc.: 64.06%] [G loss: 0.822491]\n",
      "epoch:3 step:2391 [D loss: 0.744257, acc.: 50.00%] [G loss: 0.769412]\n",
      "epoch:3 step:2392 [D loss: 0.717131, acc.: 57.03%] [G loss: 0.788251]\n",
      "epoch:3 step:2393 [D loss: 0.747481, acc.: 46.88%] [G loss: 0.893208]\n",
      "epoch:3 step:2394 [D loss: 0.648140, acc.: 64.84%] [G loss: 0.843805]\n",
      "epoch:3 step:2395 [D loss: 0.724903, acc.: 53.91%] [G loss: 0.826059]\n",
      "epoch:3 step:2396 [D loss: 0.651403, acc.: 57.81%] [G loss: 0.817543]\n",
      "epoch:3 step:2397 [D loss: 0.680358, acc.: 62.50%] [G loss: 0.801652]\n",
      "epoch:3 step:2398 [D loss: 0.763538, acc.: 46.09%] [G loss: 0.804044]\n",
      "epoch:3 step:2399 [D loss: 0.839927, acc.: 36.72%] [G loss: 0.755591]\n",
      "epoch:3 step:2400 [D loss: 0.693014, acc.: 53.91%] [G loss: 0.847948]\n",
      "epoch:3 step:2401 [D loss: 0.692568, acc.: 51.56%] [G loss: 0.795804]\n",
      "epoch:3 step:2402 [D loss: 0.685488, acc.: 60.16%] [G loss: 0.886046]\n",
      "epoch:3 step:2403 [D loss: 0.740484, acc.: 50.78%] [G loss: 0.848858]\n",
      "epoch:3 step:2404 [D loss: 0.728796, acc.: 46.09%] [G loss: 0.867166]\n",
      "epoch:3 step:2405 [D loss: 0.700423, acc.: 55.47%] [G loss: 1.079887]\n",
      "epoch:3 step:2406 [D loss: 0.621050, acc.: 64.84%] [G loss: 1.031452]\n",
      "epoch:3 step:2407 [D loss: 0.706949, acc.: 53.91%] [G loss: 0.859370]\n",
      "epoch:3 step:2408 [D loss: 0.707490, acc.: 47.66%] [G loss: 0.956208]\n",
      "epoch:3 step:2409 [D loss: 0.687067, acc.: 57.81%] [G loss: 0.824088]\n",
      "epoch:3 step:2410 [D loss: 0.692054, acc.: 50.78%] [G loss: 0.883633]\n",
      "epoch:3 step:2411 [D loss: 0.700557, acc.: 54.69%] [G loss: 0.834643]\n",
      "epoch:3 step:2412 [D loss: 0.701767, acc.: 46.88%] [G loss: 0.887092]\n",
      "epoch:3 step:2413 [D loss: 0.732212, acc.: 45.31%] [G loss: 0.914681]\n",
      "epoch:3 step:2414 [D loss: 0.714859, acc.: 56.25%] [G loss: 0.762024]\n",
      "epoch:3 step:2415 [D loss: 0.746298, acc.: 50.00%] [G loss: 0.726306]\n",
      "epoch:3 step:2416 [D loss: 0.662659, acc.: 61.72%] [G loss: 0.741083]\n",
      "epoch:3 step:2417 [D loss: 0.716506, acc.: 56.25%] [G loss: 0.858477]\n",
      "epoch:3 step:2418 [D loss: 0.706836, acc.: 51.56%] [G loss: 0.823839]\n",
      "epoch:3 step:2419 [D loss: 0.643499, acc.: 63.28%] [G loss: 0.888824]\n",
      "epoch:3 step:2420 [D loss: 0.601784, acc.: 70.31%] [G loss: 0.845743]\n",
      "epoch:3 step:2421 [D loss: 0.647098, acc.: 65.62%] [G loss: 0.783928]\n",
      "epoch:3 step:2422 [D loss: 0.686842, acc.: 53.12%] [G loss: 0.834027]\n",
      "epoch:3 step:2423 [D loss: 0.666862, acc.: 58.59%] [G loss: 0.785908]\n",
      "epoch:3 step:2424 [D loss: 0.670484, acc.: 60.16%] [G loss: 0.799330]\n",
      "epoch:3 step:2425 [D loss: 0.699849, acc.: 50.78%] [G loss: 0.834449]\n",
      "epoch:3 step:2426 [D loss: 0.719567, acc.: 52.34%] [G loss: 0.747065]\n",
      "epoch:3 step:2427 [D loss: 0.744010, acc.: 44.53%] [G loss: 0.842593]\n",
      "epoch:3 step:2428 [D loss: 0.689366, acc.: 53.12%] [G loss: 0.819254]\n",
      "epoch:3 step:2429 [D loss: 0.722275, acc.: 52.34%] [G loss: 0.860612]\n",
      "epoch:3 step:2430 [D loss: 0.687670, acc.: 52.34%] [G loss: 0.910706]\n",
      "epoch:3 step:2431 [D loss: 0.683580, acc.: 56.25%] [G loss: 0.869567]\n",
      "epoch:3 step:2432 [D loss: 0.638927, acc.: 65.62%] [G loss: 0.814587]\n",
      "epoch:3 step:2433 [D loss: 0.754460, acc.: 44.53%] [G loss: 0.771424]\n",
      "epoch:3 step:2434 [D loss: 0.756302, acc.: 49.22%] [G loss: 0.793553]\n",
      "epoch:3 step:2435 [D loss: 0.703677, acc.: 55.47%] [G loss: 0.771404]\n",
      "epoch:3 step:2436 [D loss: 0.712967, acc.: 53.12%] [G loss: 0.779311]\n",
      "epoch:3 step:2437 [D loss: 0.677091, acc.: 55.47%] [G loss: 0.812088]\n",
      "epoch:3 step:2438 [D loss: 0.739076, acc.: 46.88%] [G loss: 0.840778]\n",
      "epoch:3 step:2439 [D loss: 0.698618, acc.: 53.12%] [G loss: 0.920245]\n",
      "epoch:3 step:2440 [D loss: 0.719151, acc.: 48.44%] [G loss: 0.844083]\n",
      "epoch:3 step:2441 [D loss: 0.764108, acc.: 42.97%] [G loss: 0.821421]\n",
      "epoch:3 step:2442 [D loss: 0.732567, acc.: 46.09%] [G loss: 0.762168]\n",
      "epoch:3 step:2443 [D loss: 0.710261, acc.: 55.47%] [G loss: 0.862826]\n",
      "epoch:3 step:2444 [D loss: 0.827080, acc.: 32.81%] [G loss: 0.758642]\n",
      "epoch:3 step:2445 [D loss: 0.710416, acc.: 57.03%] [G loss: 0.771280]\n",
      "epoch:3 step:2446 [D loss: 0.740963, acc.: 48.44%] [G loss: 0.751024]\n",
      "epoch:3 step:2447 [D loss: 0.698929, acc.: 56.25%] [G loss: 0.760981]\n",
      "epoch:3 step:2448 [D loss: 0.685660, acc.: 57.03%] [G loss: 0.882075]\n",
      "epoch:3 step:2449 [D loss: 0.715805, acc.: 48.44%] [G loss: 0.801657]\n",
      "epoch:3 step:2450 [D loss: 0.734287, acc.: 48.44%] [G loss: 0.841690]\n",
      "epoch:3 step:2451 [D loss: 0.741028, acc.: 53.12%] [G loss: 0.832942]\n",
      "epoch:3 step:2452 [D loss: 0.735373, acc.: 48.44%] [G loss: 0.795223]\n",
      "epoch:3 step:2453 [D loss: 0.712646, acc.: 52.34%] [G loss: 0.701758]\n",
      "epoch:3 step:2454 [D loss: 0.762448, acc.: 45.31%] [G loss: 0.822776]\n",
      "epoch:3 step:2455 [D loss: 0.702541, acc.: 50.78%] [G loss: 0.826366]\n",
      "epoch:3 step:2456 [D loss: 0.678512, acc.: 60.16%] [G loss: 0.854774]\n",
      "epoch:3 step:2457 [D loss: 0.676839, acc.: 57.81%] [G loss: 0.832336]\n",
      "epoch:3 step:2458 [D loss: 0.734979, acc.: 47.66%] [G loss: 0.796416]\n",
      "epoch:3 step:2459 [D loss: 0.733221, acc.: 46.09%] [G loss: 0.729869]\n",
      "epoch:3 step:2460 [D loss: 0.733985, acc.: 50.00%] [G loss: 0.772872]\n",
      "epoch:3 step:2461 [D loss: 0.690044, acc.: 49.22%] [G loss: 0.738904]\n",
      "epoch:3 step:2462 [D loss: 0.733852, acc.: 51.56%] [G loss: 0.835392]\n",
      "epoch:3 step:2463 [D loss: 0.724862, acc.: 45.31%] [G loss: 0.839208]\n",
      "epoch:3 step:2464 [D loss: 0.679732, acc.: 56.25%] [G loss: 0.831212]\n",
      "epoch:3 step:2465 [D loss: 0.730769, acc.: 46.88%] [G loss: 0.804241]\n",
      "epoch:3 step:2466 [D loss: 0.665973, acc.: 54.69%] [G loss: 0.842085]\n",
      "epoch:3 step:2467 [D loss: 0.736872, acc.: 52.34%] [G loss: 0.723438]\n",
      "epoch:3 step:2468 [D loss: 0.715887, acc.: 50.78%] [G loss: 0.782233]\n",
      "epoch:3 step:2469 [D loss: 0.753864, acc.: 46.88%] [G loss: 0.830087]\n",
      "epoch:3 step:2470 [D loss: 0.744988, acc.: 42.19%] [G loss: 0.760734]\n",
      "epoch:3 step:2471 [D loss: 0.684650, acc.: 57.81%] [G loss: 0.696914]\n",
      "epoch:3 step:2472 [D loss: 0.679096, acc.: 61.72%] [G loss: 0.771149]\n",
      "epoch:3 step:2473 [D loss: 0.730862, acc.: 48.44%] [G loss: 0.772581]\n",
      "epoch:3 step:2474 [D loss: 0.800099, acc.: 45.31%] [G loss: 0.802560]\n",
      "epoch:3 step:2475 [D loss: 0.671248, acc.: 63.28%] [G loss: 0.835289]\n",
      "epoch:3 step:2476 [D loss: 0.717325, acc.: 50.78%] [G loss: 0.847468]\n",
      "epoch:3 step:2477 [D loss: 0.719200, acc.: 50.00%] [G loss: 0.908043]\n",
      "epoch:3 step:2478 [D loss: 0.730938, acc.: 53.12%] [G loss: 0.837258]\n",
      "epoch:3 step:2479 [D loss: 0.670302, acc.: 57.81%] [G loss: 0.875565]\n",
      "epoch:3 step:2480 [D loss: 0.684220, acc.: 55.47%] [G loss: 0.884444]\n",
      "epoch:3 step:2481 [D loss: 0.676672, acc.: 58.59%] [G loss: 0.839934]\n",
      "epoch:3 step:2482 [D loss: 0.715782, acc.: 53.91%] [G loss: 0.843336]\n",
      "epoch:3 step:2483 [D loss: 0.715097, acc.: 53.91%] [G loss: 0.855061]\n",
      "epoch:3 step:2484 [D loss: 0.682642, acc.: 59.38%] [G loss: 0.875530]\n",
      "epoch:3 step:2485 [D loss: 0.664378, acc.: 66.41%] [G loss: 0.844031]\n",
      "epoch:3 step:2486 [D loss: 0.600535, acc.: 72.66%] [G loss: 0.819684]\n",
      "epoch:3 step:2487 [D loss: 0.672326, acc.: 52.34%] [G loss: 0.783006]\n",
      "epoch:3 step:2488 [D loss: 0.638335, acc.: 58.59%] [G loss: 0.789322]\n",
      "epoch:3 step:2489 [D loss: 0.675589, acc.: 57.03%] [G loss: 0.687643]\n",
      "epoch:3 step:2490 [D loss: 0.721543, acc.: 49.22%] [G loss: 0.817779]\n",
      "epoch:3 step:2491 [D loss: 0.669502, acc.: 57.81%] [G loss: 0.805557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2492 [D loss: 0.654280, acc.: 61.72%] [G loss: 0.725490]\n",
      "epoch:3 step:2493 [D loss: 0.588369, acc.: 75.78%] [G loss: 0.687498]\n",
      "epoch:3 step:2494 [D loss: 0.655229, acc.: 64.84%] [G loss: 0.730078]\n",
      "epoch:3 step:2495 [D loss: 0.653075, acc.: 61.72%] [G loss: 0.690623]\n",
      "epoch:3 step:2496 [D loss: 0.660174, acc.: 59.38%] [G loss: 0.669739]\n",
      "epoch:3 step:2497 [D loss: 0.658103, acc.: 67.19%] [G loss: 0.629559]\n",
      "epoch:3 step:2498 [D loss: 0.688501, acc.: 60.94%] [G loss: 0.602156]\n",
      "epoch:3 step:2499 [D loss: 0.662028, acc.: 58.59%] [G loss: 0.576001]\n",
      "epoch:3 step:2500 [D loss: 0.748726, acc.: 45.31%] [G loss: 0.632697]\n",
      "epoch:3 step:2501 [D loss: 0.725525, acc.: 46.09%] [G loss: 0.666399]\n",
      "epoch:3 step:2502 [D loss: 0.764648, acc.: 42.19%] [G loss: 0.704925]\n",
      "epoch:3 step:2503 [D loss: 0.837995, acc.: 34.38%] [G loss: 0.707155]\n",
      "epoch:3 step:2504 [D loss: 0.745966, acc.: 46.09%] [G loss: 0.795197]\n",
      "epoch:3 step:2505 [D loss: 0.668640, acc.: 62.50%] [G loss: 0.928260]\n",
      "epoch:3 step:2506 [D loss: 0.650930, acc.: 60.94%] [G loss: 0.992055]\n",
      "epoch:3 step:2507 [D loss: 0.689475, acc.: 50.78%] [G loss: 0.919108]\n",
      "epoch:3 step:2508 [D loss: 0.710838, acc.: 56.25%] [G loss: 0.929485]\n",
      "epoch:3 step:2509 [D loss: 0.637489, acc.: 65.62%] [G loss: 0.909941]\n",
      "epoch:3 step:2510 [D loss: 0.671433, acc.: 63.28%] [G loss: 0.778811]\n",
      "epoch:3 step:2511 [D loss: 0.649285, acc.: 67.19%] [G loss: 0.784849]\n",
      "epoch:3 step:2512 [D loss: 0.608934, acc.: 71.88%] [G loss: 0.910835]\n",
      "epoch:3 step:2513 [D loss: 0.626614, acc.: 66.41%] [G loss: 0.838376]\n",
      "epoch:3 step:2514 [D loss: 0.678358, acc.: 63.28%] [G loss: 0.732680]\n",
      "epoch:3 step:2515 [D loss: 0.645457, acc.: 65.62%] [G loss: 0.770131]\n",
      "epoch:3 step:2516 [D loss: 0.697562, acc.: 55.47%] [G loss: 0.776909]\n",
      "epoch:3 step:2517 [D loss: 0.611997, acc.: 67.97%] [G loss: 0.707845]\n",
      "epoch:3 step:2518 [D loss: 0.564917, acc.: 75.00%] [G loss: 0.712724]\n",
      "epoch:3 step:2519 [D loss: 0.706685, acc.: 52.34%] [G loss: 0.688684]\n",
      "epoch:3 step:2520 [D loss: 0.639119, acc.: 64.06%] [G loss: 0.643242]\n",
      "epoch:3 step:2521 [D loss: 0.652786, acc.: 63.28%] [G loss: 0.674761]\n",
      "epoch:3 step:2522 [D loss: 0.647555, acc.: 61.72%] [G loss: 0.670383]\n",
      "epoch:3 step:2523 [D loss: 0.657570, acc.: 57.03%] [G loss: 0.878385]\n",
      "epoch:3 step:2524 [D loss: 0.686988, acc.: 52.34%] [G loss: 0.891374]\n",
      "epoch:3 step:2525 [D loss: 0.812962, acc.: 43.75%] [G loss: 0.871444]\n",
      "epoch:3 step:2526 [D loss: 0.769099, acc.: 46.88%] [G loss: 1.006942]\n",
      "epoch:3 step:2527 [D loss: 0.766009, acc.: 45.31%] [G loss: 0.940049]\n",
      "epoch:3 step:2528 [D loss: 0.695973, acc.: 58.59%] [G loss: 0.909011]\n",
      "epoch:3 step:2529 [D loss: 0.692620, acc.: 60.16%] [G loss: 1.018621]\n",
      "epoch:3 step:2530 [D loss: 0.695471, acc.: 53.12%] [G loss: 0.945272]\n",
      "epoch:3 step:2531 [D loss: 0.700553, acc.: 53.91%] [G loss: 1.004174]\n",
      "epoch:3 step:2532 [D loss: 0.582865, acc.: 71.88%] [G loss: 0.960229]\n",
      "epoch:3 step:2533 [D loss: 0.636430, acc.: 62.50%] [G loss: 0.963607]\n",
      "epoch:3 step:2534 [D loss: 0.578480, acc.: 71.09%] [G loss: 0.998971]\n",
      "epoch:3 step:2535 [D loss: 0.582054, acc.: 74.22%] [G loss: 0.924000]\n",
      "epoch:3 step:2536 [D loss: 0.669712, acc.: 62.50%] [G loss: 0.688689]\n",
      "epoch:3 step:2537 [D loss: 0.642793, acc.: 62.50%] [G loss: 0.738118]\n",
      "epoch:3 step:2538 [D loss: 0.592623, acc.: 70.31%] [G loss: 0.708942]\n",
      "epoch:3 step:2539 [D loss: 0.706269, acc.: 53.91%] [G loss: 0.683268]\n",
      "epoch:3 step:2540 [D loss: 0.755904, acc.: 42.97%] [G loss: 0.688592]\n",
      "epoch:3 step:2541 [D loss: 0.685582, acc.: 61.72%] [G loss: 0.689722]\n",
      "epoch:3 step:2542 [D loss: 0.775487, acc.: 42.19%] [G loss: 0.816451]\n",
      "epoch:3 step:2543 [D loss: 0.733267, acc.: 49.22%] [G loss: 0.785285]\n",
      "epoch:3 step:2544 [D loss: 0.642262, acc.: 65.62%] [G loss: 0.863450]\n",
      "epoch:3 step:2545 [D loss: 0.776110, acc.: 42.97%] [G loss: 0.890328]\n",
      "epoch:3 step:2546 [D loss: 0.677557, acc.: 56.25%] [G loss: 0.777008]\n",
      "epoch:3 step:2547 [D loss: 0.686459, acc.: 53.91%] [G loss: 0.783201]\n",
      "epoch:3 step:2548 [D loss: 0.636069, acc.: 66.41%] [G loss: 0.853400]\n",
      "epoch:3 step:2549 [D loss: 0.682142, acc.: 53.91%] [G loss: 0.896493]\n",
      "epoch:3 step:2550 [D loss: 0.766700, acc.: 49.22%] [G loss: 0.887797]\n",
      "epoch:3 step:2551 [D loss: 0.678680, acc.: 57.03%] [G loss: 0.843232]\n",
      "epoch:3 step:2552 [D loss: 0.663010, acc.: 62.50%] [G loss: 0.862409]\n",
      "epoch:3 step:2553 [D loss: 0.636454, acc.: 61.72%] [G loss: 0.845499]\n",
      "epoch:3 step:2554 [D loss: 0.690421, acc.: 57.81%] [G loss: 0.774463]\n",
      "epoch:3 step:2555 [D loss: 0.689820, acc.: 53.12%] [G loss: 0.904555]\n",
      "epoch:3 step:2556 [D loss: 0.788446, acc.: 42.97%] [G loss: 0.809825]\n",
      "epoch:3 step:2557 [D loss: 0.681737, acc.: 65.62%] [G loss: 0.792586]\n",
      "epoch:3 step:2558 [D loss: 0.765849, acc.: 47.66%] [G loss: 0.796504]\n",
      "epoch:3 step:2559 [D loss: 0.683569, acc.: 58.59%] [G loss: 0.808767]\n",
      "epoch:3 step:2560 [D loss: 0.786616, acc.: 42.97%] [G loss: 0.839127]\n",
      "epoch:3 step:2561 [D loss: 0.768750, acc.: 42.19%] [G loss: 0.825170]\n",
      "epoch:3 step:2562 [D loss: 0.769992, acc.: 48.44%] [G loss: 0.835950]\n",
      "epoch:3 step:2563 [D loss: 0.714206, acc.: 52.34%] [G loss: 0.933885]\n",
      "epoch:3 step:2564 [D loss: 0.778241, acc.: 48.44%] [G loss: 0.941262]\n",
      "epoch:3 step:2565 [D loss: 0.653992, acc.: 61.72%] [G loss: 0.892760]\n",
      "epoch:3 step:2566 [D loss: 0.819943, acc.: 35.16%] [G loss: 0.709379]\n",
      "epoch:3 step:2567 [D loss: 0.702588, acc.: 55.47%] [G loss: 0.909925]\n",
      "epoch:3 step:2568 [D loss: 0.621783, acc.: 67.19%] [G loss: 0.856883]\n",
      "epoch:3 step:2569 [D loss: 0.674346, acc.: 62.50%] [G loss: 0.697976]\n",
      "epoch:3 step:2570 [D loss: 0.659929, acc.: 66.41%] [G loss: 0.741633]\n",
      "epoch:3 step:2571 [D loss: 0.707622, acc.: 53.12%] [G loss: 0.781787]\n",
      "epoch:3 step:2572 [D loss: 0.781244, acc.: 42.19%] [G loss: 0.763513]\n",
      "epoch:3 step:2573 [D loss: 0.791244, acc.: 41.41%] [G loss: 0.771409]\n",
      "epoch:3 step:2574 [D loss: 0.668996, acc.: 62.50%] [G loss: 0.842625]\n",
      "epoch:3 step:2575 [D loss: 0.736939, acc.: 50.78%] [G loss: 0.818995]\n",
      "epoch:3 step:2576 [D loss: 0.644635, acc.: 64.06%] [G loss: 0.932259]\n",
      "epoch:3 step:2577 [D loss: 0.759834, acc.: 44.53%] [G loss: 0.984859]\n",
      "epoch:3 step:2578 [D loss: 0.762455, acc.: 46.09%] [G loss: 0.781115]\n",
      "epoch:3 step:2579 [D loss: 0.692254, acc.: 53.91%] [G loss: 0.824000]\n",
      "epoch:3 step:2580 [D loss: 0.664517, acc.: 58.59%] [G loss: 0.760339]\n",
      "epoch:3 step:2581 [D loss: 0.607072, acc.: 68.75%] [G loss: 0.824616]\n",
      "epoch:3 step:2582 [D loss: 0.679281, acc.: 56.25%] [G loss: 0.905352]\n",
      "epoch:3 step:2583 [D loss: 0.692820, acc.: 55.47%] [G loss: 0.864634]\n",
      "epoch:3 step:2584 [D loss: 0.668012, acc.: 60.16%] [G loss: 0.820960]\n",
      "epoch:3 step:2585 [D loss: 0.698614, acc.: 55.47%] [G loss: 0.810199]\n",
      "epoch:3 step:2586 [D loss: 0.735158, acc.: 48.44%] [G loss: 0.791790]\n",
      "epoch:3 step:2587 [D loss: 0.740727, acc.: 49.22%] [G loss: 0.750497]\n",
      "epoch:3 step:2588 [D loss: 0.753865, acc.: 49.22%] [G loss: 0.805527]\n",
      "epoch:3 step:2589 [D loss: 0.659122, acc.: 64.06%] [G loss: 0.765474]\n",
      "epoch:3 step:2590 [D loss: 0.710071, acc.: 55.47%] [G loss: 0.748232]\n",
      "epoch:3 step:2591 [D loss: 0.735867, acc.: 47.66%] [G loss: 0.706756]\n",
      "epoch:3 step:2592 [D loss: 0.767923, acc.: 42.19%] [G loss: 0.953935]\n",
      "epoch:3 step:2593 [D loss: 0.735756, acc.: 48.44%] [G loss: 0.806456]\n",
      "epoch:3 step:2594 [D loss: 0.728478, acc.: 52.34%] [G loss: 0.800984]\n",
      "epoch:3 step:2595 [D loss: 0.668830, acc.: 58.59%] [G loss: 0.761415]\n",
      "epoch:3 step:2596 [D loss: 0.710580, acc.: 50.00%] [G loss: 0.912071]\n",
      "epoch:3 step:2597 [D loss: 0.694903, acc.: 50.78%] [G loss: 0.953393]\n",
      "epoch:3 step:2598 [D loss: 0.664879, acc.: 60.16%] [G loss: 0.957723]\n",
      "epoch:3 step:2599 [D loss: 0.628725, acc.: 63.28%] [G loss: 0.797388]\n",
      "epoch:3 step:2600 [D loss: 0.624055, acc.: 69.53%] [G loss: 0.879571]\n",
      "epoch:3 step:2601 [D loss: 0.586285, acc.: 71.88%] [G loss: 0.875193]\n",
      "epoch:3 step:2602 [D loss: 0.617097, acc.: 68.75%] [G loss: 0.891905]\n",
      "epoch:3 step:2603 [D loss: 0.609067, acc.: 71.88%] [G loss: 0.929414]\n",
      "epoch:3 step:2604 [D loss: 0.704080, acc.: 47.66%] [G loss: 0.832105]\n",
      "epoch:3 step:2605 [D loss: 0.676796, acc.: 51.56%] [G loss: 0.839376]\n",
      "epoch:3 step:2606 [D loss: 0.648046, acc.: 64.06%] [G loss: 0.776399]\n",
      "epoch:3 step:2607 [D loss: 0.635759, acc.: 64.06%] [G loss: 0.884085]\n",
      "epoch:3 step:2608 [D loss: 0.693980, acc.: 57.03%] [G loss: 0.766272]\n",
      "epoch:3 step:2609 [D loss: 0.743050, acc.: 51.56%] [G loss: 0.649053]\n",
      "epoch:3 step:2610 [D loss: 0.599708, acc.: 71.88%] [G loss: 0.784047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2611 [D loss: 0.631534, acc.: 66.41%] [G loss: 0.733451]\n",
      "epoch:3 step:2612 [D loss: 0.669425, acc.: 57.03%] [G loss: 0.710941]\n",
      "epoch:3 step:2613 [D loss: 0.706852, acc.: 51.56%] [G loss: 0.748459]\n",
      "epoch:3 step:2614 [D loss: 0.668863, acc.: 57.81%] [G loss: 0.735368]\n",
      "epoch:3 step:2615 [D loss: 0.690374, acc.: 51.56%] [G loss: 0.650678]\n",
      "epoch:3 step:2616 [D loss: 0.739426, acc.: 47.66%] [G loss: 0.670404]\n",
      "epoch:3 step:2617 [D loss: 0.734588, acc.: 50.00%] [G loss: 0.665697]\n",
      "epoch:3 step:2618 [D loss: 0.692313, acc.: 49.22%] [G loss: 0.614813]\n",
      "epoch:3 step:2619 [D loss: 0.668349, acc.: 55.47%] [G loss: 0.732131]\n",
      "epoch:3 step:2620 [D loss: 0.853227, acc.: 40.62%] [G loss: 0.630813]\n",
      "epoch:3 step:2621 [D loss: 0.787697, acc.: 42.19%] [G loss: 0.577812]\n",
      "epoch:3 step:2622 [D loss: 0.750098, acc.: 48.44%] [G loss: 0.701667]\n",
      "epoch:3 step:2623 [D loss: 0.694850, acc.: 53.91%] [G loss: 0.955895]\n",
      "epoch:3 step:2624 [D loss: 0.814266, acc.: 35.16%] [G loss: 0.804091]\n",
      "epoch:3 step:2625 [D loss: 0.785991, acc.: 42.19%] [G loss: 0.831326]\n",
      "epoch:3 step:2626 [D loss: 0.683398, acc.: 56.25%] [G loss: 0.861810]\n",
      "epoch:3 step:2627 [D loss: 0.588138, acc.: 76.56%] [G loss: 0.915913]\n",
      "epoch:3 step:2628 [D loss: 0.625861, acc.: 67.97%] [G loss: 0.921911]\n",
      "epoch:3 step:2629 [D loss: 0.631665, acc.: 62.50%] [G loss: 0.827961]\n",
      "epoch:3 step:2630 [D loss: 0.707021, acc.: 53.12%] [G loss: 0.795387]\n",
      "epoch:3 step:2631 [D loss: 0.644636, acc.: 64.06%] [G loss: 0.794292]\n",
      "epoch:3 step:2632 [D loss: 0.560578, acc.: 77.34%] [G loss: 0.734365]\n",
      "epoch:3 step:2633 [D loss: 0.612733, acc.: 67.97%] [G loss: 0.735983]\n",
      "epoch:3 step:2634 [D loss: 0.689925, acc.: 60.16%] [G loss: 0.693691]\n",
      "epoch:3 step:2635 [D loss: 0.594808, acc.: 68.75%] [G loss: 0.708019]\n",
      "epoch:3 step:2636 [D loss: 0.613834, acc.: 65.62%] [G loss: 0.696573]\n",
      "epoch:3 step:2637 [D loss: 0.554779, acc.: 76.56%] [G loss: 0.758454]\n",
      "epoch:3 step:2638 [D loss: 0.565411, acc.: 76.56%] [G loss: 0.584538]\n",
      "epoch:3 step:2639 [D loss: 0.776155, acc.: 44.53%] [G loss: 0.585160]\n",
      "epoch:3 step:2640 [D loss: 0.648223, acc.: 66.41%] [G loss: 0.620980]\n",
      "epoch:3 step:2641 [D loss: 0.701175, acc.: 54.69%] [G loss: 0.657480]\n",
      "epoch:3 step:2642 [D loss: 0.722536, acc.: 48.44%] [G loss: 0.693800]\n",
      "epoch:3 step:2643 [D loss: 0.706270, acc.: 55.47%] [G loss: 0.793875]\n",
      "epoch:3 step:2644 [D loss: 0.751433, acc.: 42.97%] [G loss: 0.826316]\n",
      "epoch:3 step:2645 [D loss: 0.718140, acc.: 46.09%] [G loss: 0.817990]\n",
      "epoch:3 step:2646 [D loss: 0.686068, acc.: 53.12%] [G loss: 0.959546]\n",
      "epoch:3 step:2647 [D loss: 0.684706, acc.: 58.59%] [G loss: 0.910681]\n",
      "epoch:3 step:2648 [D loss: 0.686641, acc.: 53.91%] [G loss: 0.828109]\n",
      "epoch:3 step:2649 [D loss: 0.680398, acc.: 56.25%] [G loss: 0.967171]\n",
      "epoch:3 step:2650 [D loss: 0.681150, acc.: 57.03%] [G loss: 1.026186]\n",
      "epoch:3 step:2651 [D loss: 0.588688, acc.: 67.97%] [G loss: 0.824275]\n",
      "epoch:3 step:2652 [D loss: 0.687483, acc.: 53.12%] [G loss: 0.900054]\n",
      "epoch:3 step:2653 [D loss: 0.616050, acc.: 66.41%] [G loss: 0.831936]\n",
      "epoch:3 step:2654 [D loss: 0.712831, acc.: 50.78%] [G loss: 0.849109]\n",
      "epoch:3 step:2655 [D loss: 0.691702, acc.: 54.69%] [G loss: 0.870980]\n",
      "epoch:3 step:2656 [D loss: 0.772555, acc.: 39.84%] [G loss: 0.820598]\n",
      "epoch:3 step:2657 [D loss: 0.689448, acc.: 58.59%] [G loss: 0.801265]\n",
      "epoch:3 step:2658 [D loss: 0.746950, acc.: 50.78%] [G loss: 0.762511]\n",
      "epoch:3 step:2659 [D loss: 0.597697, acc.: 71.88%] [G loss: 0.845783]\n",
      "epoch:3 step:2660 [D loss: 0.586356, acc.: 72.66%] [G loss: 0.883046]\n",
      "epoch:3 step:2661 [D loss: 0.642501, acc.: 64.84%] [G loss: 0.856869]\n",
      "epoch:3 step:2662 [D loss: 0.660351, acc.: 60.16%] [G loss: 0.827065]\n",
      "epoch:3 step:2663 [D loss: 0.711086, acc.: 48.44%] [G loss: 0.883833]\n",
      "epoch:3 step:2664 [D loss: 0.709004, acc.: 55.47%] [G loss: 0.846074]\n",
      "epoch:3 step:2665 [D loss: 0.588426, acc.: 71.09%] [G loss: 0.947853]\n",
      "epoch:3 step:2666 [D loss: 0.661433, acc.: 59.38%] [G loss: 0.882802]\n",
      "epoch:3 step:2667 [D loss: 0.622226, acc.: 67.97%] [G loss: 0.831305]\n",
      "epoch:3 step:2668 [D loss: 0.660879, acc.: 57.03%] [G loss: 0.673397]\n",
      "epoch:3 step:2669 [D loss: 0.622624, acc.: 62.50%] [G loss: 0.904079]\n",
      "epoch:3 step:2670 [D loss: 0.600297, acc.: 68.75%] [G loss: 0.734342]\n",
      "epoch:3 step:2671 [D loss: 0.629695, acc.: 62.50%] [G loss: 0.818628]\n",
      "epoch:3 step:2672 [D loss: 0.650753, acc.: 60.94%] [G loss: 0.638277]\n",
      "epoch:3 step:2673 [D loss: 0.781818, acc.: 41.41%] [G loss: 0.577803]\n",
      "epoch:3 step:2674 [D loss: 0.732522, acc.: 48.44%] [G loss: 0.675826]\n",
      "epoch:3 step:2675 [D loss: 0.704957, acc.: 51.56%] [G loss: 0.669146]\n",
      "epoch:3 step:2676 [D loss: 0.737642, acc.: 44.53%] [G loss: 0.831929]\n",
      "epoch:3 step:2677 [D loss: 0.714559, acc.: 52.34%] [G loss: 0.743076]\n",
      "epoch:3 step:2678 [D loss: 0.702579, acc.: 57.03%] [G loss: 0.599008]\n",
      "epoch:3 step:2679 [D loss: 0.758962, acc.: 42.19%] [G loss: 0.616763]\n",
      "epoch:3 step:2680 [D loss: 0.744798, acc.: 46.09%] [G loss: 0.585845]\n",
      "epoch:3 step:2681 [D loss: 0.767442, acc.: 46.88%] [G loss: 0.766292]\n",
      "epoch:3 step:2682 [D loss: 0.593247, acc.: 65.62%] [G loss: 0.813001]\n",
      "epoch:3 step:2683 [D loss: 0.692143, acc.: 56.25%] [G loss: 0.821218]\n",
      "epoch:3 step:2684 [D loss: 0.680576, acc.: 59.38%] [G loss: 0.849862]\n",
      "epoch:3 step:2685 [D loss: 0.765097, acc.: 46.88%] [G loss: 0.811503]\n",
      "epoch:3 step:2686 [D loss: 0.737287, acc.: 51.56%] [G loss: 0.894988]\n",
      "epoch:3 step:2687 [D loss: 0.637237, acc.: 64.06%] [G loss: 0.789151]\n",
      "epoch:3 step:2688 [D loss: 0.582537, acc.: 71.88%] [G loss: 0.797192]\n",
      "epoch:3 step:2689 [D loss: 0.527580, acc.: 79.69%] [G loss: 0.835708]\n",
      "epoch:3 step:2690 [D loss: 0.561906, acc.: 81.25%] [G loss: 0.706398]\n",
      "epoch:3 step:2691 [D loss: 0.472719, acc.: 89.06%] [G loss: 0.623365]\n",
      "epoch:3 step:2692 [D loss: 0.625968, acc.: 66.41%] [G loss: 0.798865]\n",
      "epoch:3 step:2693 [D loss: 0.412297, acc.: 90.62%] [G loss: 0.609355]\n",
      "epoch:3 step:2694 [D loss: 0.499923, acc.: 78.12%] [G loss: 0.614930]\n",
      "epoch:3 step:2695 [D loss: 0.477746, acc.: 82.81%] [G loss: 0.455970]\n",
      "epoch:3 step:2696 [D loss: 0.509527, acc.: 79.69%] [G loss: 0.519487]\n",
      "epoch:3 step:2697 [D loss: 0.578433, acc.: 69.53%] [G loss: 0.509583]\n",
      "epoch:3 step:2698 [D loss: 0.655424, acc.: 57.81%] [G loss: 0.521007]\n",
      "epoch:3 step:2699 [D loss: 0.647386, acc.: 58.59%] [G loss: 0.555431]\n",
      "epoch:3 step:2700 [D loss: 0.595378, acc.: 72.66%] [G loss: 0.485592]\n",
      "epoch:3 step:2701 [D loss: 0.665226, acc.: 59.38%] [G loss: 0.586751]\n",
      "epoch:3 step:2702 [D loss: 0.939462, acc.: 25.00%] [G loss: 0.558287]\n",
      "epoch:3 step:2703 [D loss: 0.889080, acc.: 32.81%] [G loss: 0.733257]\n",
      "epoch:3 step:2704 [D loss: 0.674799, acc.: 59.38%] [G loss: 0.817651]\n",
      "epoch:3 step:2705 [D loss: 0.801081, acc.: 46.09%] [G loss: 0.951719]\n",
      "epoch:3 step:2706 [D loss: 0.739020, acc.: 46.09%] [G loss: 0.714568]\n",
      "epoch:3 step:2707 [D loss: 0.691169, acc.: 50.78%] [G loss: 0.819151]\n",
      "epoch:3 step:2708 [D loss: 0.790135, acc.: 44.53%] [G loss: 0.806407]\n",
      "epoch:3 step:2709 [D loss: 0.728524, acc.: 49.22%] [G loss: 0.901152]\n",
      "epoch:3 step:2710 [D loss: 0.764852, acc.: 52.34%] [G loss: 0.790929]\n",
      "epoch:3 step:2711 [D loss: 0.728908, acc.: 51.56%] [G loss: 0.814757]\n",
      "epoch:3 step:2712 [D loss: 0.651397, acc.: 63.28%] [G loss: 0.754482]\n",
      "epoch:3 step:2713 [D loss: 0.733710, acc.: 51.56%] [G loss: 0.684967]\n",
      "epoch:3 step:2714 [D loss: 0.749872, acc.: 50.00%] [G loss: 0.769324]\n",
      "epoch:3 step:2715 [D loss: 0.698429, acc.: 53.91%] [G loss: 0.976425]\n",
      "epoch:3 step:2716 [D loss: 0.711319, acc.: 53.91%] [G loss: 1.116699]\n",
      "epoch:3 step:2717 [D loss: 0.603410, acc.: 70.31%] [G loss: 1.123507]\n",
      "epoch:3 step:2718 [D loss: 0.613787, acc.: 71.09%] [G loss: 1.064766]\n",
      "epoch:3 step:2719 [D loss: 0.592920, acc.: 71.09%] [G loss: 1.015436]\n",
      "epoch:3 step:2720 [D loss: 0.524561, acc.: 78.91%] [G loss: 1.024436]\n",
      "epoch:3 step:2721 [D loss: 0.512982, acc.: 78.12%] [G loss: 1.037905]\n",
      "epoch:3 step:2722 [D loss: 0.458109, acc.: 92.97%] [G loss: 0.995717]\n",
      "epoch:3 step:2723 [D loss: 0.501742, acc.: 82.81%] [G loss: 0.953579]\n",
      "epoch:3 step:2724 [D loss: 0.625797, acc.: 61.72%] [G loss: 0.839906]\n",
      "epoch:3 step:2725 [D loss: 0.603225, acc.: 67.97%] [G loss: 0.919199]\n",
      "epoch:3 step:2726 [D loss: 0.550694, acc.: 77.34%] [G loss: 0.836388]\n",
      "epoch:3 step:2727 [D loss: 0.607314, acc.: 64.84%] [G loss: 0.773319]\n",
      "epoch:3 step:2728 [D loss: 0.735772, acc.: 48.44%] [G loss: 0.699578]\n",
      "epoch:3 step:2729 [D loss: 0.758776, acc.: 50.00%] [G loss: 0.849988]\n",
      "epoch:3 step:2730 [D loss: 0.710717, acc.: 57.03%] [G loss: 0.976090]\n",
      "epoch:3 step:2731 [D loss: 0.757607, acc.: 43.75%] [G loss: 0.742348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2732 [D loss: 0.769262, acc.: 49.22%] [G loss: 0.748025]\n",
      "epoch:3 step:2733 [D loss: 0.740313, acc.: 51.56%] [G loss: 0.715463]\n",
      "epoch:3 step:2734 [D loss: 0.872187, acc.: 38.28%] [G loss: 0.702746]\n",
      "epoch:3 step:2735 [D loss: 0.707322, acc.: 55.47%] [G loss: 0.719219]\n",
      "epoch:3 step:2736 [D loss: 0.641423, acc.: 61.72%] [G loss: 0.868731]\n",
      "epoch:3 step:2737 [D loss: 0.677313, acc.: 53.91%] [G loss: 1.015890]\n",
      "epoch:3 step:2738 [D loss: 0.681266, acc.: 60.16%] [G loss: 1.010614]\n",
      "epoch:3 step:2739 [D loss: 0.601701, acc.: 67.19%] [G loss: 0.866383]\n",
      "epoch:3 step:2740 [D loss: 0.677054, acc.: 58.59%] [G loss: 0.856590]\n",
      "epoch:3 step:2741 [D loss: 0.616313, acc.: 64.84%] [G loss: 0.956439]\n",
      "epoch:3 step:2742 [D loss: 0.558217, acc.: 78.12%] [G loss: 1.012520]\n",
      "epoch:3 step:2743 [D loss: 0.617888, acc.: 64.06%] [G loss: 0.800599]\n",
      "epoch:3 step:2744 [D loss: 0.663170, acc.: 59.38%] [G loss: 0.827124]\n",
      "epoch:3 step:2745 [D loss: 0.657495, acc.: 55.47%] [G loss: 0.841036]\n",
      "epoch:3 step:2746 [D loss: 0.623661, acc.: 67.97%] [G loss: 0.808578]\n",
      "epoch:3 step:2747 [D loss: 0.643582, acc.: 63.28%] [G loss: 0.890705]\n",
      "epoch:3 step:2748 [D loss: 0.745500, acc.: 47.66%] [G loss: 0.994194]\n",
      "epoch:3 step:2749 [D loss: 0.665276, acc.: 59.38%] [G loss: 0.827684]\n",
      "epoch:3 step:2750 [D loss: 0.610593, acc.: 65.62%] [G loss: 0.895087]\n",
      "epoch:3 step:2751 [D loss: 0.654677, acc.: 64.84%] [G loss: 0.761325]\n",
      "epoch:3 step:2752 [D loss: 0.742885, acc.: 53.12%] [G loss: 0.750523]\n",
      "epoch:3 step:2753 [D loss: 0.684510, acc.: 56.25%] [G loss: 0.856977]\n",
      "epoch:3 step:2754 [D loss: 0.780184, acc.: 47.66%] [G loss: 0.697227]\n",
      "epoch:3 step:2755 [D loss: 0.742734, acc.: 48.44%] [G loss: 0.711036]\n",
      "epoch:3 step:2756 [D loss: 0.743748, acc.: 51.56%] [G loss: 0.842148]\n",
      "epoch:3 step:2757 [D loss: 0.808729, acc.: 39.84%] [G loss: 0.790561]\n",
      "epoch:3 step:2758 [D loss: 0.689764, acc.: 55.47%] [G loss: 0.903881]\n",
      "epoch:3 step:2759 [D loss: 0.719059, acc.: 53.91%] [G loss: 0.898882]\n",
      "epoch:3 step:2760 [D loss: 0.677961, acc.: 54.69%] [G loss: 0.937624]\n",
      "epoch:3 step:2761 [D loss: 0.701046, acc.: 49.22%] [G loss: 0.851795]\n",
      "epoch:3 step:2762 [D loss: 0.656945, acc.: 64.84%] [G loss: 0.930295]\n",
      "epoch:3 step:2763 [D loss: 0.727480, acc.: 53.91%] [G loss: 0.760632]\n",
      "epoch:3 step:2764 [D loss: 0.706352, acc.: 58.59%] [G loss: 0.772075]\n",
      "epoch:3 step:2765 [D loss: 0.713849, acc.: 57.03%] [G loss: 0.787428]\n",
      "epoch:3 step:2766 [D loss: 0.697618, acc.: 53.91%] [G loss: 0.735627]\n",
      "epoch:3 step:2767 [D loss: 0.756343, acc.: 46.09%] [G loss: 0.713397]\n",
      "epoch:3 step:2768 [D loss: 0.711116, acc.: 53.12%] [G loss: 0.891126]\n",
      "epoch:3 step:2769 [D loss: 0.791358, acc.: 40.62%] [G loss: 0.826795]\n",
      "epoch:3 step:2770 [D loss: 0.824627, acc.: 41.41%] [G loss: 0.884759]\n",
      "epoch:3 step:2771 [D loss: 0.771873, acc.: 42.97%] [G loss: 1.018243]\n",
      "epoch:3 step:2772 [D loss: 0.686404, acc.: 59.38%] [G loss: 0.867247]\n",
      "epoch:3 step:2773 [D loss: 0.797766, acc.: 42.97%] [G loss: 1.014750]\n",
      "epoch:3 step:2774 [D loss: 0.759840, acc.: 46.09%] [G loss: 0.835293]\n",
      "epoch:3 step:2775 [D loss: 0.628793, acc.: 67.97%] [G loss: 0.939352]\n",
      "epoch:3 step:2776 [D loss: 0.690809, acc.: 51.56%] [G loss: 0.934598]\n",
      "epoch:3 step:2777 [D loss: 0.701132, acc.: 57.81%] [G loss: 0.904335]\n",
      "epoch:3 step:2778 [D loss: 0.660371, acc.: 59.38%] [G loss: 0.897315]\n",
      "epoch:3 step:2779 [D loss: 0.659046, acc.: 63.28%] [G loss: 0.907073]\n",
      "epoch:3 step:2780 [D loss: 0.687951, acc.: 57.03%] [G loss: 0.794673]\n",
      "epoch:3 step:2781 [D loss: 0.731455, acc.: 50.00%] [G loss: 0.848018]\n",
      "epoch:3 step:2782 [D loss: 0.669421, acc.: 58.59%] [G loss: 0.909637]\n",
      "epoch:3 step:2783 [D loss: 0.683429, acc.: 58.59%] [G loss: 0.889001]\n",
      "epoch:3 step:2784 [D loss: 0.719308, acc.: 50.78%] [G loss: 0.885279]\n",
      "epoch:3 step:2785 [D loss: 0.671128, acc.: 57.03%] [G loss: 0.869771]\n",
      "epoch:3 step:2786 [D loss: 0.762472, acc.: 46.88%] [G loss: 0.881263]\n",
      "epoch:3 step:2787 [D loss: 0.728893, acc.: 50.78%] [G loss: 0.832879]\n",
      "epoch:3 step:2788 [D loss: 0.786395, acc.: 43.75%] [G loss: 0.743210]\n",
      "epoch:3 step:2789 [D loss: 0.703679, acc.: 50.78%] [G loss: 0.772277]\n",
      "epoch:3 step:2790 [D loss: 0.694792, acc.: 53.91%] [G loss: 0.815017]\n",
      "epoch:3 step:2791 [D loss: 0.737348, acc.: 49.22%] [G loss: 0.833430]\n",
      "epoch:3 step:2792 [D loss: 0.732346, acc.: 53.12%] [G loss: 0.821546]\n",
      "epoch:3 step:2793 [D loss: 0.669793, acc.: 55.47%] [G loss: 0.831710]\n",
      "epoch:3 step:2794 [D loss: 0.720590, acc.: 54.69%] [G loss: 0.789147]\n",
      "epoch:3 step:2795 [D loss: 0.663577, acc.: 60.94%] [G loss: 0.785327]\n",
      "epoch:3 step:2796 [D loss: 0.747605, acc.: 46.09%] [G loss: 0.887803]\n",
      "epoch:3 step:2797 [D loss: 0.715696, acc.: 46.88%] [G loss: 0.818672]\n",
      "epoch:3 step:2798 [D loss: 0.782632, acc.: 47.66%] [G loss: 0.826055]\n",
      "epoch:3 step:2799 [D loss: 0.690198, acc.: 57.03%] [G loss: 0.841132]\n",
      "epoch:3 step:2800 [D loss: 0.741399, acc.: 50.00%] [G loss: 0.804771]\n",
      "epoch:3 step:2801 [D loss: 0.687509, acc.: 53.12%] [G loss: 0.734577]\n",
      "epoch:3 step:2802 [D loss: 0.742285, acc.: 48.44%] [G loss: 0.738358]\n",
      "epoch:3 step:2803 [D loss: 0.694206, acc.: 53.91%] [G loss: 0.898335]\n",
      "epoch:3 step:2804 [D loss: 0.706831, acc.: 53.12%] [G loss: 0.852151]\n",
      "epoch:3 step:2805 [D loss: 0.703546, acc.: 53.91%] [G loss: 0.811557]\n",
      "epoch:3 step:2806 [D loss: 0.759634, acc.: 46.09%] [G loss: 0.757501]\n",
      "epoch:3 step:2807 [D loss: 0.800682, acc.: 42.19%] [G loss: 0.872575]\n",
      "epoch:3 step:2808 [D loss: 0.665785, acc.: 61.72%] [G loss: 0.816147]\n",
      "epoch:3 step:2809 [D loss: 0.609378, acc.: 70.31%] [G loss: 0.940003]\n",
      "epoch:3 step:2810 [D loss: 0.661761, acc.: 58.59%] [G loss: 0.761403]\n",
      "epoch:3 step:2811 [D loss: 0.726454, acc.: 49.22%] [G loss: 0.712594]\n",
      "epoch:3 step:2812 [D loss: 0.741743, acc.: 48.44%] [G loss: 0.720655]\n",
      "epoch:3 step:2813 [D loss: 0.726759, acc.: 50.78%] [G loss: 0.847960]\n",
      "epoch:3 step:2814 [D loss: 0.680042, acc.: 49.22%] [G loss: 0.818391]\n",
      "epoch:3 step:2815 [D loss: 0.717704, acc.: 49.22%] [G loss: 0.764055]\n",
      "epoch:3 step:2816 [D loss: 0.668189, acc.: 64.06%] [G loss: 0.751982]\n",
      "epoch:3 step:2817 [D loss: 0.677148, acc.: 60.94%] [G loss: 0.723808]\n",
      "epoch:3 step:2818 [D loss: 0.718458, acc.: 50.78%] [G loss: 0.648600]\n",
      "epoch:3 step:2819 [D loss: 0.701681, acc.: 59.38%] [G loss: 0.662972]\n",
      "epoch:3 step:2820 [D loss: 0.773817, acc.: 46.88%] [G loss: 0.828088]\n",
      "epoch:3 step:2821 [D loss: 0.699029, acc.: 52.34%] [G loss: 0.886457]\n",
      "epoch:3 step:2822 [D loss: 0.707745, acc.: 55.47%] [G loss: 0.786373]\n",
      "epoch:3 step:2823 [D loss: 0.698887, acc.: 53.91%] [G loss: 0.834690]\n",
      "epoch:3 step:2824 [D loss: 0.650571, acc.: 62.50%] [G loss: 0.785505]\n",
      "epoch:3 step:2825 [D loss: 0.661892, acc.: 60.16%] [G loss: 0.779245]\n",
      "epoch:3 step:2826 [D loss: 0.778425, acc.: 42.97%] [G loss: 0.814515]\n",
      "epoch:3 step:2827 [D loss: 0.675911, acc.: 60.16%] [G loss: 0.830378]\n",
      "epoch:3 step:2828 [D loss: 0.712494, acc.: 53.91%] [G loss: 0.768067]\n",
      "epoch:3 step:2829 [D loss: 0.654498, acc.: 57.81%] [G loss: 0.833375]\n",
      "epoch:3 step:2830 [D loss: 0.653435, acc.: 63.28%] [G loss: 0.902839]\n",
      "epoch:3 step:2831 [D loss: 0.640342, acc.: 63.28%] [G loss: 0.952560]\n",
      "epoch:3 step:2832 [D loss: 0.693146, acc.: 53.91%] [G loss: 0.828565]\n",
      "epoch:3 step:2833 [D loss: 0.671934, acc.: 57.81%] [G loss: 0.872816]\n",
      "epoch:3 step:2834 [D loss: 0.720563, acc.: 50.00%] [G loss: 0.794277]\n",
      "epoch:3 step:2835 [D loss: 0.661885, acc.: 56.25%] [G loss: 0.864459]\n",
      "epoch:3 step:2836 [D loss: 0.702064, acc.: 53.12%] [G loss: 0.799056]\n",
      "epoch:3 step:2837 [D loss: 0.660677, acc.: 61.72%] [G loss: 0.807425]\n",
      "epoch:3 step:2838 [D loss: 0.680472, acc.: 60.16%] [G loss: 0.827644]\n",
      "epoch:3 step:2839 [D loss: 0.766149, acc.: 43.75%] [G loss: 0.815904]\n",
      "epoch:3 step:2840 [D loss: 0.674313, acc.: 60.16%] [G loss: 0.821265]\n",
      "epoch:3 step:2841 [D loss: 0.640077, acc.: 60.94%] [G loss: 0.761268]\n",
      "epoch:3 step:2842 [D loss: 0.726008, acc.: 51.56%] [G loss: 0.790037]\n",
      "epoch:3 step:2843 [D loss: 0.582291, acc.: 72.66%] [G loss: 0.928796]\n",
      "epoch:3 step:2844 [D loss: 0.738179, acc.: 42.97%] [G loss: 0.854924]\n",
      "epoch:3 step:2845 [D loss: 0.723071, acc.: 49.22%] [G loss: 0.749644]\n",
      "epoch:3 step:2846 [D loss: 0.658184, acc.: 63.28%] [G loss: 0.836823]\n",
      "epoch:3 step:2847 [D loss: 0.644787, acc.: 61.72%] [G loss: 0.885412]\n",
      "epoch:3 step:2848 [D loss: 0.681590, acc.: 50.00%] [G loss: 0.844956]\n",
      "epoch:3 step:2849 [D loss: 0.756050, acc.: 46.09%] [G loss: 0.904085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2850 [D loss: 0.611777, acc.: 67.19%] [G loss: 0.836266]\n",
      "epoch:3 step:2851 [D loss: 0.621042, acc.: 71.88%] [G loss: 0.808134]\n",
      "epoch:3 step:2852 [D loss: 0.688645, acc.: 54.69%] [G loss: 0.910337]\n",
      "epoch:3 step:2853 [D loss: 0.676964, acc.: 52.34%] [G loss: 0.929198]\n",
      "epoch:3 step:2854 [D loss: 0.710566, acc.: 54.69%] [G loss: 0.860660]\n",
      "epoch:3 step:2855 [D loss: 0.681187, acc.: 53.12%] [G loss: 0.944203]\n",
      "epoch:3 step:2856 [D loss: 0.663978, acc.: 56.25%] [G loss: 0.858191]\n",
      "epoch:3 step:2857 [D loss: 0.687447, acc.: 55.47%] [G loss: 0.901346]\n",
      "epoch:3 step:2858 [D loss: 0.638556, acc.: 60.16%] [G loss: 0.877468]\n",
      "epoch:3 step:2859 [D loss: 0.619814, acc.: 72.66%] [G loss: 0.886796]\n",
      "epoch:3 step:2860 [D loss: 0.691164, acc.: 53.91%] [G loss: 0.892126]\n",
      "epoch:3 step:2861 [D loss: 0.676611, acc.: 51.56%] [G loss: 0.731555]\n",
      "epoch:3 step:2862 [D loss: 0.720803, acc.: 51.56%] [G loss: 0.797464]\n",
      "epoch:3 step:2863 [D loss: 0.681987, acc.: 54.69%] [G loss: 0.751135]\n",
      "epoch:3 step:2864 [D loss: 0.720828, acc.: 49.22%] [G loss: 0.794973]\n",
      "epoch:3 step:2865 [D loss: 0.718361, acc.: 50.78%] [G loss: 0.823991]\n",
      "epoch:3 step:2866 [D loss: 0.731906, acc.: 54.69%] [G loss: 0.901728]\n",
      "epoch:3 step:2867 [D loss: 0.741340, acc.: 46.88%] [G loss: 0.851625]\n",
      "epoch:3 step:2868 [D loss: 0.676032, acc.: 57.03%] [G loss: 0.760197]\n",
      "epoch:3 step:2869 [D loss: 0.743567, acc.: 51.56%] [G loss: 0.813532]\n",
      "epoch:3 step:2870 [D loss: 0.745704, acc.: 54.69%] [G loss: 0.762304]\n",
      "epoch:3 step:2871 [D loss: 0.763036, acc.: 53.12%] [G loss: 0.821985]\n",
      "epoch:3 step:2872 [D loss: 0.716454, acc.: 50.78%] [G loss: 0.873147]\n",
      "epoch:3 step:2873 [D loss: 0.734311, acc.: 49.22%] [G loss: 0.978486]\n",
      "epoch:3 step:2874 [D loss: 0.709426, acc.: 55.47%] [G loss: 0.934374]\n",
      "epoch:3 step:2875 [D loss: 0.705759, acc.: 57.03%] [G loss: 0.842367]\n",
      "epoch:3 step:2876 [D loss: 0.667445, acc.: 57.03%] [G loss: 0.788636]\n",
      "epoch:3 step:2877 [D loss: 0.629227, acc.: 65.62%] [G loss: 0.783645]\n",
      "epoch:3 step:2878 [D loss: 0.745140, acc.: 45.31%] [G loss: 0.822875]\n",
      "epoch:3 step:2879 [D loss: 0.650356, acc.: 62.50%] [G loss: 0.799615]\n",
      "epoch:3 step:2880 [D loss: 0.656040, acc.: 60.94%] [G loss: 0.734892]\n",
      "epoch:3 step:2881 [D loss: 0.708715, acc.: 46.88%] [G loss: 0.751485]\n",
      "epoch:3 step:2882 [D loss: 0.702502, acc.: 53.91%] [G loss: 0.921230]\n",
      "epoch:3 step:2883 [D loss: 0.657835, acc.: 57.81%] [G loss: 0.965232]\n",
      "epoch:3 step:2884 [D loss: 0.725771, acc.: 50.00%] [G loss: 0.866565]\n",
      "epoch:3 step:2885 [D loss: 0.733899, acc.: 46.88%] [G loss: 0.774614]\n",
      "epoch:3 step:2886 [D loss: 0.685965, acc.: 53.91%] [G loss: 0.792960]\n",
      "epoch:3 step:2887 [D loss: 0.713470, acc.: 50.00%] [G loss: 0.853262]\n",
      "epoch:3 step:2888 [D loss: 0.712967, acc.: 53.91%] [G loss: 0.881561]\n",
      "epoch:3 step:2889 [D loss: 0.750468, acc.: 43.75%] [G loss: 0.781970]\n",
      "epoch:3 step:2890 [D loss: 0.698199, acc.: 52.34%] [G loss: 0.752473]\n",
      "epoch:3 step:2891 [D loss: 0.720882, acc.: 47.66%] [G loss: 0.845429]\n",
      "epoch:3 step:2892 [D loss: 0.675559, acc.: 60.94%] [G loss: 0.788090]\n",
      "epoch:3 step:2893 [D loss: 0.777843, acc.: 45.31%] [G loss: 0.869165]\n",
      "epoch:3 step:2894 [D loss: 0.640572, acc.: 61.72%] [G loss: 0.929198]\n",
      "epoch:3 step:2895 [D loss: 0.727841, acc.: 45.31%] [G loss: 0.851735]\n",
      "epoch:3 step:2896 [D loss: 0.657891, acc.: 64.84%] [G loss: 0.897782]\n",
      "epoch:3 step:2897 [D loss: 0.670831, acc.: 54.69%] [G loss: 0.992236]\n",
      "epoch:3 step:2898 [D loss: 0.760104, acc.: 51.56%] [G loss: 0.859632]\n",
      "epoch:3 step:2899 [D loss: 0.659254, acc.: 55.47%] [G loss: 0.801430]\n",
      "epoch:3 step:2900 [D loss: 0.661937, acc.: 61.72%] [G loss: 0.829739]\n",
      "epoch:3 step:2901 [D loss: 0.655685, acc.: 61.72%] [G loss: 0.888692]\n",
      "epoch:3 step:2902 [D loss: 0.686930, acc.: 56.25%] [G loss: 0.877719]\n",
      "epoch:3 step:2903 [D loss: 0.663044, acc.: 64.06%] [G loss: 0.908398]\n",
      "epoch:3 step:2904 [D loss: 0.711045, acc.: 51.56%] [G loss: 0.883492]\n",
      "epoch:3 step:2905 [D loss: 0.631018, acc.: 63.28%] [G loss: 0.922422]\n",
      "epoch:3 step:2906 [D loss: 0.763101, acc.: 41.41%] [G loss: 0.844217]\n",
      "epoch:3 step:2907 [D loss: 0.716389, acc.: 51.56%] [G loss: 0.950987]\n",
      "epoch:3 step:2908 [D loss: 0.735669, acc.: 48.44%] [G loss: 0.885972]\n",
      "epoch:3 step:2909 [D loss: 0.717955, acc.: 55.47%] [G loss: 0.829942]\n",
      "epoch:3 step:2910 [D loss: 0.674074, acc.: 60.94%] [G loss: 0.938565]\n",
      "epoch:3 step:2911 [D loss: 0.701536, acc.: 44.53%] [G loss: 0.820068]\n",
      "epoch:3 step:2912 [D loss: 0.801928, acc.: 35.16%] [G loss: 0.761762]\n",
      "epoch:3 step:2913 [D loss: 0.792317, acc.: 40.62%] [G loss: 0.840028]\n",
      "epoch:3 step:2914 [D loss: 0.775952, acc.: 41.41%] [G loss: 0.797256]\n",
      "epoch:3 step:2915 [D loss: 0.723438, acc.: 49.22%] [G loss: 0.849498]\n",
      "epoch:3 step:2916 [D loss: 0.622019, acc.: 65.62%] [G loss: 0.785577]\n",
      "epoch:3 step:2917 [D loss: 0.727769, acc.: 53.91%] [G loss: 0.725723]\n",
      "epoch:3 step:2918 [D loss: 0.731205, acc.: 49.22%] [G loss: 0.679701]\n",
      "epoch:3 step:2919 [D loss: 0.694095, acc.: 55.47%] [G loss: 0.773372]\n",
      "epoch:3 step:2920 [D loss: 0.690658, acc.: 53.12%] [G loss: 0.787027]\n",
      "epoch:3 step:2921 [D loss: 0.646363, acc.: 65.62%] [G loss: 0.788333]\n",
      "epoch:3 step:2922 [D loss: 0.746571, acc.: 41.41%] [G loss: 0.770708]\n",
      "epoch:3 step:2923 [D loss: 0.715222, acc.: 54.69%] [G loss: 0.768855]\n",
      "epoch:3 step:2924 [D loss: 0.740611, acc.: 46.88%] [G loss: 0.777366]\n",
      "epoch:3 step:2925 [D loss: 0.729679, acc.: 42.19%] [G loss: 0.814538]\n",
      "epoch:3 step:2926 [D loss: 0.710565, acc.: 50.78%] [G loss: 0.897559]\n",
      "epoch:3 step:2927 [D loss: 0.786479, acc.: 38.28%] [G loss: 0.795697]\n",
      "epoch:3 step:2928 [D loss: 0.701581, acc.: 48.44%] [G loss: 0.907790]\n",
      "epoch:3 step:2929 [D loss: 0.756201, acc.: 42.19%] [G loss: 0.855158]\n",
      "epoch:3 step:2930 [D loss: 0.656505, acc.: 61.72%] [G loss: 0.892501]\n",
      "epoch:3 step:2931 [D loss: 0.676629, acc.: 61.72%] [G loss: 0.876135]\n",
      "epoch:3 step:2932 [D loss: 0.624302, acc.: 69.53%] [G loss: 0.835424]\n",
      "epoch:3 step:2933 [D loss: 0.669072, acc.: 55.47%] [G loss: 0.860237]\n",
      "epoch:3 step:2934 [D loss: 0.639623, acc.: 65.62%] [G loss: 0.877728]\n",
      "epoch:3 step:2935 [D loss: 0.660271, acc.: 58.59%] [G loss: 0.781668]\n",
      "epoch:3 step:2936 [D loss: 0.599637, acc.: 67.19%] [G loss: 0.787892]\n",
      "epoch:3 step:2937 [D loss: 0.612312, acc.: 67.19%] [G loss: 0.741665]\n",
      "epoch:3 step:2938 [D loss: 0.632289, acc.: 65.62%] [G loss: 0.724331]\n",
      "epoch:3 step:2939 [D loss: 0.712268, acc.: 48.44%] [G loss: 0.725007]\n",
      "epoch:3 step:2940 [D loss: 0.666078, acc.: 59.38%] [G loss: 0.809281]\n",
      "epoch:3 step:2941 [D loss: 0.670497, acc.: 60.94%] [G loss: 0.849691]\n",
      "epoch:3 step:2942 [D loss: 0.742034, acc.: 48.44%] [G loss: 0.766444]\n",
      "epoch:3 step:2943 [D loss: 0.776251, acc.: 47.66%] [G loss: 0.782309]\n",
      "epoch:3 step:2944 [D loss: 0.708463, acc.: 55.47%] [G loss: 0.860292]\n",
      "epoch:3 step:2945 [D loss: 0.701965, acc.: 52.34%] [G loss: 0.840032]\n",
      "epoch:3 step:2946 [D loss: 0.719514, acc.: 51.56%] [G loss: 0.850852]\n",
      "epoch:3 step:2947 [D loss: 0.689723, acc.: 52.34%] [G loss: 0.767719]\n",
      "epoch:3 step:2948 [D loss: 0.677402, acc.: 60.16%] [G loss: 0.799765]\n",
      "epoch:3 step:2949 [D loss: 0.639263, acc.: 60.16%] [G loss: 0.871484]\n",
      "epoch:3 step:2950 [D loss: 0.680780, acc.: 57.03%] [G loss: 0.807920]\n",
      "epoch:3 step:2951 [D loss: 0.711946, acc.: 53.12%] [G loss: 0.924302]\n",
      "epoch:3 step:2952 [D loss: 0.683291, acc.: 62.50%] [G loss: 0.841105]\n",
      "epoch:3 step:2953 [D loss: 0.691170, acc.: 56.25%] [G loss: 0.914951]\n",
      "epoch:3 step:2954 [D loss: 0.687049, acc.: 57.81%] [G loss: 0.953303]\n",
      "epoch:3 step:2955 [D loss: 0.664980, acc.: 59.38%] [G loss: 0.970315]\n",
      "epoch:3 step:2956 [D loss: 0.709705, acc.: 50.00%] [G loss: 0.818711]\n",
      "epoch:3 step:2957 [D loss: 0.671483, acc.: 64.84%] [G loss: 0.881028]\n",
      "epoch:3 step:2958 [D loss: 0.613893, acc.: 67.19%] [G loss: 0.925895]\n",
      "epoch:3 step:2959 [D loss: 0.589817, acc.: 73.44%] [G loss: 0.939094]\n",
      "epoch:3 step:2960 [D loss: 0.676886, acc.: 60.16%] [G loss: 0.857920]\n",
      "epoch:3 step:2961 [D loss: 0.709389, acc.: 57.81%] [G loss: 0.854917]\n",
      "epoch:3 step:2962 [D loss: 0.648262, acc.: 63.28%] [G loss: 1.084856]\n",
      "epoch:3 step:2963 [D loss: 0.643886, acc.: 64.84%] [G loss: 1.022133]\n",
      "epoch:3 step:2964 [D loss: 0.723329, acc.: 53.12%] [G loss: 1.095451]\n",
      "epoch:3 step:2965 [D loss: 0.693901, acc.: 60.94%] [G loss: 0.846576]\n",
      "epoch:3 step:2966 [D loss: 0.658688, acc.: 60.16%] [G loss: 0.957029]\n",
      "epoch:3 step:2967 [D loss: 0.620104, acc.: 64.06%] [G loss: 1.024423]\n",
      "epoch:3 step:2968 [D loss: 0.743320, acc.: 46.88%] [G loss: 0.894692]\n",
      "epoch:3 step:2969 [D loss: 0.654344, acc.: 62.50%] [G loss: 0.844018]\n",
      "epoch:3 step:2970 [D loss: 0.668376, acc.: 57.81%] [G loss: 0.846529]\n",
      "epoch:3 step:2971 [D loss: 0.630078, acc.: 64.06%] [G loss: 0.825533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2972 [D loss: 0.595558, acc.: 70.31%] [G loss: 0.752606]\n",
      "epoch:3 step:2973 [D loss: 0.600889, acc.: 71.88%] [G loss: 0.758015]\n",
      "epoch:3 step:2974 [D loss: 0.677349, acc.: 56.25%] [G loss: 0.695868]\n",
      "epoch:3 step:2975 [D loss: 0.544475, acc.: 76.56%] [G loss: 0.720826]\n",
      "epoch:3 step:2976 [D loss: 0.636027, acc.: 64.84%] [G loss: 0.709837]\n",
      "epoch:3 step:2977 [D loss: 0.737618, acc.: 51.56%] [G loss: 0.689738]\n",
      "epoch:3 step:2978 [D loss: 0.631048, acc.: 66.41%] [G loss: 0.648777]\n",
      "epoch:3 step:2979 [D loss: 0.529444, acc.: 76.56%] [G loss: 0.741668]\n",
      "epoch:3 step:2980 [D loss: 0.714082, acc.: 53.91%] [G loss: 0.744124]\n",
      "epoch:3 step:2981 [D loss: 0.681358, acc.: 57.03%] [G loss: 0.716036]\n",
      "epoch:3 step:2982 [D loss: 0.749424, acc.: 46.88%] [G loss: 0.745756]\n",
      "epoch:3 step:2983 [D loss: 0.705034, acc.: 50.78%] [G loss: 0.830789]\n",
      "epoch:3 step:2984 [D loss: 0.652510, acc.: 57.03%] [G loss: 1.006857]\n",
      "epoch:3 step:2985 [D loss: 0.638461, acc.: 65.62%] [G loss: 0.835827]\n",
      "epoch:3 step:2986 [D loss: 0.710348, acc.: 53.12%] [G loss: 0.935464]\n",
      "epoch:3 step:2987 [D loss: 0.682024, acc.: 57.81%] [G loss: 0.865276]\n",
      "epoch:3 step:2988 [D loss: 0.630795, acc.: 64.06%] [G loss: 0.906573]\n",
      "epoch:3 step:2989 [D loss: 0.622116, acc.: 61.72%] [G loss: 0.870915]\n",
      "epoch:3 step:2990 [D loss: 0.567937, acc.: 70.31%] [G loss: 0.838961]\n",
      "epoch:3 step:2991 [D loss: 0.576036, acc.: 67.19%] [G loss: 0.824102]\n",
      "epoch:3 step:2992 [D loss: 0.550580, acc.: 74.22%] [G loss: 0.938971]\n",
      "epoch:3 step:2993 [D loss: 0.539525, acc.: 75.78%] [G loss: 0.716487]\n",
      "epoch:3 step:2994 [D loss: 0.610972, acc.: 64.84%] [G loss: 0.624097]\n",
      "epoch:3 step:2995 [D loss: 0.649003, acc.: 57.81%] [G loss: 0.540573]\n",
      "epoch:3 step:2996 [D loss: 0.636504, acc.: 62.50%] [G loss: 0.523932]\n",
      "epoch:3 step:2997 [D loss: 0.740605, acc.: 51.56%] [G loss: 0.506644]\n",
      "epoch:3 step:2998 [D loss: 0.720010, acc.: 52.34%] [G loss: 0.680172]\n",
      "epoch:3 step:2999 [D loss: 0.926579, acc.: 35.94%] [G loss: 0.614739]\n",
      "epoch:3 step:3000 [D loss: 0.822700, acc.: 34.38%] [G loss: 0.605628]\n",
      "epoch:3 step:3001 [D loss: 0.800426, acc.: 46.09%] [G loss: 0.649386]\n",
      "epoch:3 step:3002 [D loss: 0.781115, acc.: 46.09%] [G loss: 0.728387]\n",
      "epoch:3 step:3003 [D loss: 0.714609, acc.: 57.03%] [G loss: 1.136821]\n",
      "epoch:3 step:3004 [D loss: 0.740149, acc.: 52.34%] [G loss: 1.056194]\n",
      "epoch:3 step:3005 [D loss: 0.665738, acc.: 63.28%] [G loss: 1.026504]\n",
      "epoch:3 step:3006 [D loss: 0.653428, acc.: 59.38%] [G loss: 1.046975]\n",
      "epoch:3 step:3007 [D loss: 0.611088, acc.: 68.75%] [G loss: 0.899098]\n",
      "epoch:3 step:3008 [D loss: 0.661622, acc.: 60.16%] [G loss: 0.887857]\n",
      "epoch:3 step:3009 [D loss: 0.626818, acc.: 71.88%] [G loss: 0.826945]\n",
      "epoch:3 step:3010 [D loss: 0.712025, acc.: 54.69%] [G loss: 0.836559]\n",
      "epoch:3 step:3011 [D loss: 0.623832, acc.: 71.88%] [G loss: 0.822930]\n",
      "epoch:3 step:3012 [D loss: 0.678054, acc.: 56.25%] [G loss: 0.773313]\n",
      "epoch:3 step:3013 [D loss: 0.732508, acc.: 53.12%] [G loss: 0.851601]\n",
      "epoch:3 step:3014 [D loss: 0.710962, acc.: 53.91%] [G loss: 0.681148]\n",
      "epoch:3 step:3015 [D loss: 0.646202, acc.: 59.38%] [G loss: 0.901961]\n",
      "epoch:3 step:3016 [D loss: 0.745962, acc.: 42.97%] [G loss: 0.923609]\n",
      "epoch:3 step:3017 [D loss: 0.696510, acc.: 53.12%] [G loss: 0.916552]\n",
      "epoch:3 step:3018 [D loss: 0.636041, acc.: 62.50%] [G loss: 0.977236]\n",
      "epoch:3 step:3019 [D loss: 0.727688, acc.: 51.56%] [G loss: 0.807959]\n",
      "epoch:3 step:3020 [D loss: 0.672903, acc.: 57.81%] [G loss: 0.837264]\n",
      "epoch:3 step:3021 [D loss: 0.637042, acc.: 64.84%] [G loss: 0.878079]\n",
      "epoch:3 step:3022 [D loss: 0.694544, acc.: 60.94%] [G loss: 0.804091]\n",
      "epoch:3 step:3023 [D loss: 0.682477, acc.: 59.38%] [G loss: 0.852125]\n",
      "epoch:3 step:3024 [D loss: 0.747529, acc.: 46.88%] [G loss: 0.814569]\n",
      "epoch:3 step:3025 [D loss: 0.668380, acc.: 59.38%] [G loss: 0.835589]\n",
      "epoch:3 step:3026 [D loss: 0.739763, acc.: 53.12%] [G loss: 0.868493]\n",
      "epoch:3 step:3027 [D loss: 0.719131, acc.: 50.78%] [G loss: 0.872695]\n",
      "epoch:3 step:3028 [D loss: 0.720756, acc.: 50.00%] [G loss: 0.892347]\n",
      "epoch:3 step:3029 [D loss: 0.710067, acc.: 53.12%] [G loss: 0.861661]\n",
      "epoch:3 step:3030 [D loss: 0.688821, acc.: 55.47%] [G loss: 0.874507]\n",
      "epoch:3 step:3031 [D loss: 0.672080, acc.: 62.50%] [G loss: 0.972600]\n",
      "epoch:3 step:3032 [D loss: 0.685940, acc.: 57.03%] [G loss: 0.878347]\n",
      "epoch:3 step:3033 [D loss: 0.670434, acc.: 60.16%] [G loss: 0.863274]\n",
      "epoch:3 step:3034 [D loss: 0.691208, acc.: 57.81%] [G loss: 0.907669]\n",
      "epoch:3 step:3035 [D loss: 0.821514, acc.: 39.84%] [G loss: 0.825675]\n",
      "epoch:3 step:3036 [D loss: 0.649511, acc.: 63.28%] [G loss: 0.837882]\n",
      "epoch:3 step:3037 [D loss: 0.682160, acc.: 60.94%] [G loss: 0.817037]\n",
      "epoch:3 step:3038 [D loss: 0.734716, acc.: 53.91%] [G loss: 0.920921]\n",
      "epoch:3 step:3039 [D loss: 0.630982, acc.: 60.94%] [G loss: 0.989061]\n",
      "epoch:3 step:3040 [D loss: 0.722820, acc.: 53.12%] [G loss: 0.988584]\n",
      "epoch:3 step:3041 [D loss: 0.663366, acc.: 63.28%] [G loss: 0.759581]\n",
      "epoch:3 step:3042 [D loss: 0.692137, acc.: 51.56%] [G loss: 0.843394]\n",
      "epoch:3 step:3043 [D loss: 0.621353, acc.: 71.88%] [G loss: 0.876757]\n",
      "epoch:3 step:3044 [D loss: 0.689489, acc.: 57.03%] [G loss: 0.906234]\n",
      "epoch:3 step:3045 [D loss: 0.636430, acc.: 63.28%] [G loss: 0.898656]\n",
      "epoch:3 step:3046 [D loss: 0.774555, acc.: 46.09%] [G loss: 0.818444]\n",
      "epoch:3 step:3047 [D loss: 0.636798, acc.: 65.62%] [G loss: 0.916433]\n",
      "epoch:3 step:3048 [D loss: 0.620854, acc.: 67.19%] [G loss: 0.985751]\n",
      "epoch:3 step:3049 [D loss: 0.738007, acc.: 49.22%] [G loss: 0.898319]\n",
      "epoch:3 step:3050 [D loss: 0.766574, acc.: 44.53%] [G loss: 0.896080]\n",
      "epoch:3 step:3051 [D loss: 0.736417, acc.: 53.12%] [G loss: 0.895067]\n",
      "epoch:3 step:3052 [D loss: 0.760187, acc.: 41.41%] [G loss: 0.736317]\n",
      "epoch:3 step:3053 [D loss: 0.734394, acc.: 51.56%] [G loss: 0.813021]\n",
      "epoch:3 step:3054 [D loss: 0.642656, acc.: 61.72%] [G loss: 0.781233]\n",
      "epoch:3 step:3055 [D loss: 0.746422, acc.: 45.31%] [G loss: 0.906275]\n",
      "epoch:3 step:3056 [D loss: 0.709019, acc.: 51.56%] [G loss: 0.853175]\n",
      "epoch:3 step:3057 [D loss: 0.716803, acc.: 53.91%] [G loss: 0.864783]\n",
      "epoch:3 step:3058 [D loss: 0.802798, acc.: 43.75%] [G loss: 0.816573]\n",
      "epoch:3 step:3059 [D loss: 0.704664, acc.: 53.12%] [G loss: 0.837660]\n",
      "epoch:3 step:3060 [D loss: 0.717945, acc.: 51.56%] [G loss: 0.804513]\n",
      "epoch:3 step:3061 [D loss: 0.705048, acc.: 53.91%] [G loss: 0.825061]\n",
      "epoch:3 step:3062 [D loss: 0.752296, acc.: 47.66%] [G loss: 0.881270]\n",
      "epoch:3 step:3063 [D loss: 0.657679, acc.: 59.38%] [G loss: 0.904395]\n",
      "epoch:3 step:3064 [D loss: 0.692811, acc.: 51.56%] [G loss: 0.946000]\n",
      "epoch:3 step:3065 [D loss: 0.619486, acc.: 69.53%] [G loss: 0.985177]\n",
      "epoch:3 step:3066 [D loss: 0.704758, acc.: 50.78%] [G loss: 0.842151]\n",
      "epoch:3 step:3067 [D loss: 0.698575, acc.: 57.03%] [G loss: 0.862144]\n",
      "epoch:3 step:3068 [D loss: 0.618773, acc.: 64.06%] [G loss: 0.969279]\n",
      "epoch:3 step:3069 [D loss: 0.619079, acc.: 68.75%] [G loss: 0.933075]\n",
      "epoch:3 step:3070 [D loss: 0.690807, acc.: 59.38%] [G loss: 1.015214]\n",
      "epoch:3 step:3071 [D loss: 0.642584, acc.: 67.19%] [G loss: 0.902887]\n",
      "epoch:3 step:3072 [D loss: 0.687203, acc.: 56.25%] [G loss: 0.895290]\n",
      "epoch:3 step:3073 [D loss: 0.630471, acc.: 64.06%] [G loss: 0.997900]\n",
      "epoch:3 step:3074 [D loss: 0.687968, acc.: 57.81%] [G loss: 1.003947]\n",
      "epoch:3 step:3075 [D loss: 0.671131, acc.: 60.94%] [G loss: 0.928362]\n",
      "epoch:3 step:3076 [D loss: 0.670289, acc.: 60.94%] [G loss: 0.821953]\n",
      "epoch:3 step:3077 [D loss: 0.697731, acc.: 57.81%] [G loss: 0.778012]\n",
      "epoch:3 step:3078 [D loss: 0.712606, acc.: 53.12%] [G loss: 0.844828]\n",
      "epoch:3 step:3079 [D loss: 0.624777, acc.: 66.41%] [G loss: 0.932801]\n",
      "epoch:3 step:3080 [D loss: 0.705743, acc.: 50.78%] [G loss: 0.852488]\n",
      "epoch:3 step:3081 [D loss: 0.709682, acc.: 54.69%] [G loss: 0.840801]\n",
      "epoch:3 step:3082 [D loss: 0.687689, acc.: 59.38%] [G loss: 0.773834]\n",
      "epoch:3 step:3083 [D loss: 0.632856, acc.: 64.06%] [G loss: 0.885009]\n",
      "epoch:3 step:3084 [D loss: 0.624208, acc.: 64.84%] [G loss: 0.778830]\n",
      "epoch:3 step:3085 [D loss: 0.816547, acc.: 35.16%] [G loss: 0.757917]\n",
      "epoch:3 step:3086 [D loss: 0.644024, acc.: 65.62%] [G loss: 0.777524]\n",
      "epoch:3 step:3087 [D loss: 0.665940, acc.: 59.38%] [G loss: 0.717351]\n",
      "epoch:3 step:3088 [D loss: 0.724162, acc.: 50.00%] [G loss: 0.775283]\n",
      "epoch:3 step:3089 [D loss: 0.710212, acc.: 56.25%] [G loss: 0.692414]\n",
      "epoch:3 step:3090 [D loss: 0.747814, acc.: 50.78%] [G loss: 0.856307]\n",
      "epoch:3 step:3091 [D loss: 0.734191, acc.: 45.31%] [G loss: 0.792868]\n",
      "epoch:3 step:3092 [D loss: 0.662211, acc.: 56.25%] [G loss: 0.840398]\n",
      "epoch:3 step:3093 [D loss: 0.653673, acc.: 61.72%] [G loss: 0.936145]\n",
      "epoch:3 step:3094 [D loss: 0.666153, acc.: 57.03%] [G loss: 0.922960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3095 [D loss: 0.642097, acc.: 65.62%] [G loss: 0.869252]\n",
      "epoch:3 step:3096 [D loss: 0.634841, acc.: 62.50%] [G loss: 0.794683]\n",
      "epoch:3 step:3097 [D loss: 0.616686, acc.: 66.41%] [G loss: 0.833324]\n",
      "epoch:3 step:3098 [D loss: 0.640678, acc.: 64.06%] [G loss: 0.818178]\n",
      "epoch:3 step:3099 [D loss: 0.645662, acc.: 63.28%] [G loss: 0.830044]\n",
      "epoch:3 step:3100 [D loss: 0.606250, acc.: 67.19%] [G loss: 0.737989]\n",
      "epoch:3 step:3101 [D loss: 0.617412, acc.: 66.41%] [G loss: 0.733196]\n",
      "epoch:3 step:3102 [D loss: 0.596962, acc.: 73.44%] [G loss: 0.809132]\n",
      "epoch:3 step:3103 [D loss: 0.631055, acc.: 71.09%] [G loss: 0.786178]\n",
      "epoch:3 step:3104 [D loss: 0.677675, acc.: 57.81%] [G loss: 0.736679]\n",
      "epoch:3 step:3105 [D loss: 0.593881, acc.: 69.53%] [G loss: 0.690552]\n",
      "epoch:3 step:3106 [D loss: 0.676398, acc.: 53.12%] [G loss: 0.708089]\n",
      "epoch:3 step:3107 [D loss: 0.673074, acc.: 55.47%] [G loss: 0.663853]\n",
      "epoch:3 step:3108 [D loss: 0.559506, acc.: 76.56%] [G loss: 0.610424]\n",
      "epoch:3 step:3109 [D loss: 0.777991, acc.: 42.19%] [G loss: 0.674322]\n",
      "epoch:3 step:3110 [D loss: 0.779196, acc.: 46.09%] [G loss: 0.694403]\n",
      "epoch:3 step:3111 [D loss: 0.735052, acc.: 46.09%] [G loss: 0.769621]\n",
      "epoch:3 step:3112 [D loss: 0.792989, acc.: 40.62%] [G loss: 0.797633]\n",
      "epoch:3 step:3113 [D loss: 0.737990, acc.: 47.66%] [G loss: 0.907884]\n",
      "epoch:3 step:3114 [D loss: 0.708226, acc.: 52.34%] [G loss: 0.770280]\n",
      "epoch:3 step:3115 [D loss: 0.741331, acc.: 46.09%] [G loss: 0.795800]\n",
      "epoch:3 step:3116 [D loss: 0.736512, acc.: 49.22%] [G loss: 0.907296]\n",
      "epoch:3 step:3117 [D loss: 0.666636, acc.: 61.72%] [G loss: 0.949438]\n",
      "epoch:3 step:3118 [D loss: 0.767971, acc.: 42.97%] [G loss: 0.898260]\n",
      "epoch:3 step:3119 [D loss: 0.716589, acc.: 48.44%] [G loss: 0.837044]\n",
      "epoch:3 step:3120 [D loss: 0.702704, acc.: 46.09%] [G loss: 0.941460]\n",
      "epoch:3 step:3121 [D loss: 0.642152, acc.: 70.31%] [G loss: 0.983492]\n",
      "epoch:3 step:3122 [D loss: 0.674664, acc.: 57.03%] [G loss: 0.889359]\n",
      "epoch:3 step:3123 [D loss: 0.696787, acc.: 53.91%] [G loss: 0.910403]\n",
      "epoch:3 step:3124 [D loss: 0.610722, acc.: 68.75%] [G loss: 0.971898]\n",
      "epoch:4 step:3125 [D loss: 0.641589, acc.: 62.50%] [G loss: 0.963939]\n",
      "epoch:4 step:3126 [D loss: 0.759492, acc.: 43.75%] [G loss: 0.948971]\n",
      "epoch:4 step:3127 [D loss: 0.639196, acc.: 57.03%] [G loss: 0.918816]\n",
      "epoch:4 step:3128 [D loss: 0.655342, acc.: 58.59%] [G loss: 0.900983]\n",
      "epoch:4 step:3129 [D loss: 0.710733, acc.: 47.66%] [G loss: 0.973717]\n",
      "epoch:4 step:3130 [D loss: 0.665127, acc.: 56.25%] [G loss: 0.947091]\n",
      "epoch:4 step:3131 [D loss: 0.734672, acc.: 45.31%] [G loss: 0.858239]\n",
      "epoch:4 step:3132 [D loss: 0.697189, acc.: 50.00%] [G loss: 0.806649]\n",
      "epoch:4 step:3133 [D loss: 0.746092, acc.: 43.75%] [G loss: 0.755789]\n",
      "epoch:4 step:3134 [D loss: 0.750769, acc.: 47.66%] [G loss: 0.842315]\n",
      "epoch:4 step:3135 [D loss: 0.703180, acc.: 55.47%] [G loss: 0.825732]\n",
      "epoch:4 step:3136 [D loss: 0.726640, acc.: 45.31%] [G loss: 0.692821]\n",
      "epoch:4 step:3137 [D loss: 0.670194, acc.: 55.47%] [G loss: 0.921669]\n",
      "epoch:4 step:3138 [D loss: 0.573920, acc.: 71.09%] [G loss: 0.903191]\n",
      "epoch:4 step:3139 [D loss: 0.747477, acc.: 48.44%] [G loss: 0.715629]\n",
      "epoch:4 step:3140 [D loss: 0.679597, acc.: 56.25%] [G loss: 0.729856]\n",
      "epoch:4 step:3141 [D loss: 0.701515, acc.: 51.56%] [G loss: 0.791435]\n",
      "epoch:4 step:3142 [D loss: 0.681409, acc.: 56.25%] [G loss: 0.925699]\n",
      "epoch:4 step:3143 [D loss: 0.664462, acc.: 60.16%] [G loss: 0.865361]\n",
      "epoch:4 step:3144 [D loss: 0.717965, acc.: 52.34%] [G loss: 0.799586]\n",
      "epoch:4 step:3145 [D loss: 0.732013, acc.: 50.78%] [G loss: 0.852949]\n",
      "epoch:4 step:3146 [D loss: 0.636558, acc.: 64.84%] [G loss: 0.894095]\n",
      "epoch:4 step:3147 [D loss: 0.666392, acc.: 63.28%] [G loss: 0.857678]\n",
      "epoch:4 step:3148 [D loss: 0.718567, acc.: 55.47%] [G loss: 0.881987]\n",
      "epoch:4 step:3149 [D loss: 0.735580, acc.: 48.44%] [G loss: 0.852754]\n",
      "epoch:4 step:3150 [D loss: 0.649146, acc.: 63.28%] [G loss: 0.705957]\n",
      "epoch:4 step:3151 [D loss: 0.602440, acc.: 71.09%] [G loss: 0.826225]\n",
      "epoch:4 step:3152 [D loss: 0.637516, acc.: 59.38%] [G loss: 0.988583]\n",
      "epoch:4 step:3153 [D loss: 0.729603, acc.: 50.00%] [G loss: 0.964002]\n",
      "epoch:4 step:3154 [D loss: 0.690326, acc.: 53.91%] [G loss: 0.874069]\n",
      "epoch:4 step:3155 [D loss: 0.716463, acc.: 50.00%] [G loss: 0.802835]\n",
      "epoch:4 step:3156 [D loss: 0.722712, acc.: 51.56%] [G loss: 0.899220]\n",
      "epoch:4 step:3157 [D loss: 0.717239, acc.: 53.91%] [G loss: 0.888076]\n",
      "epoch:4 step:3158 [D loss: 0.692842, acc.: 60.16%] [G loss: 0.944026]\n",
      "epoch:4 step:3159 [D loss: 0.740629, acc.: 53.12%] [G loss: 0.912227]\n",
      "epoch:4 step:3160 [D loss: 0.663787, acc.: 61.72%] [G loss: 0.806652]\n",
      "epoch:4 step:3161 [D loss: 0.731272, acc.: 50.78%] [G loss: 0.886215]\n",
      "epoch:4 step:3162 [D loss: 0.730336, acc.: 50.78%] [G loss: 0.867468]\n",
      "epoch:4 step:3163 [D loss: 0.648999, acc.: 62.50%] [G loss: 0.903373]\n",
      "epoch:4 step:3164 [D loss: 0.727393, acc.: 50.78%] [G loss: 0.891826]\n",
      "epoch:4 step:3165 [D loss: 0.686297, acc.: 62.50%] [G loss: 0.915912]\n",
      "epoch:4 step:3166 [D loss: 0.697279, acc.: 59.38%] [G loss: 0.850612]\n",
      "epoch:4 step:3167 [D loss: 0.687490, acc.: 56.25%] [G loss: 0.903760]\n",
      "epoch:4 step:3168 [D loss: 0.757853, acc.: 48.44%] [G loss: 0.932548]\n",
      "epoch:4 step:3169 [D loss: 0.697960, acc.: 57.81%] [G loss: 0.858639]\n",
      "epoch:4 step:3170 [D loss: 0.697792, acc.: 53.12%] [G loss: 0.851066]\n",
      "epoch:4 step:3171 [D loss: 0.701824, acc.: 53.12%] [G loss: 0.887149]\n",
      "epoch:4 step:3172 [D loss: 0.737746, acc.: 48.44%] [G loss: 0.951774]\n",
      "epoch:4 step:3173 [D loss: 0.723716, acc.: 50.78%] [G loss: 0.817525]\n",
      "epoch:4 step:3174 [D loss: 0.740258, acc.: 53.91%] [G loss: 0.956098]\n",
      "epoch:4 step:3175 [D loss: 0.691362, acc.: 57.81%] [G loss: 0.839400]\n",
      "epoch:4 step:3176 [D loss: 0.655946, acc.: 59.38%] [G loss: 0.836226]\n",
      "epoch:4 step:3177 [D loss: 0.690782, acc.: 58.59%] [G loss: 0.869005]\n",
      "epoch:4 step:3178 [D loss: 0.730063, acc.: 50.00%] [G loss: 0.731343]\n",
      "epoch:4 step:3179 [D loss: 0.660052, acc.: 59.38%] [G loss: 0.830834]\n",
      "epoch:4 step:3180 [D loss: 0.696689, acc.: 54.69%] [G loss: 1.013086]\n",
      "epoch:4 step:3181 [D loss: 0.699531, acc.: 50.78%] [G loss: 0.787095]\n",
      "epoch:4 step:3182 [D loss: 0.625893, acc.: 67.19%] [G loss: 0.840078]\n",
      "epoch:4 step:3183 [D loss: 0.646587, acc.: 60.16%] [G loss: 0.879412]\n",
      "epoch:4 step:3184 [D loss: 0.604476, acc.: 71.88%] [G loss: 0.956035]\n",
      "epoch:4 step:3185 [D loss: 0.724532, acc.: 50.78%] [G loss: 0.841743]\n",
      "epoch:4 step:3186 [D loss: 0.630076, acc.: 60.16%] [G loss: 0.861960]\n",
      "epoch:4 step:3187 [D loss: 0.587288, acc.: 71.09%] [G loss: 0.960342]\n",
      "epoch:4 step:3188 [D loss: 0.655892, acc.: 63.28%] [G loss: 0.862518]\n",
      "epoch:4 step:3189 [D loss: 0.729160, acc.: 46.09%] [G loss: 0.704221]\n",
      "epoch:4 step:3190 [D loss: 0.685433, acc.: 56.25%] [G loss: 0.841763]\n",
      "epoch:4 step:3191 [D loss: 0.732539, acc.: 43.75%] [G loss: 0.836956]\n",
      "epoch:4 step:3192 [D loss: 0.666041, acc.: 57.81%] [G loss: 0.734830]\n",
      "epoch:4 step:3193 [D loss: 0.628093, acc.: 69.53%] [G loss: 0.746111]\n",
      "epoch:4 step:3194 [D loss: 0.820556, acc.: 35.16%] [G loss: 0.711692]\n",
      "epoch:4 step:3195 [D loss: 0.661227, acc.: 57.81%] [G loss: 0.817807]\n",
      "epoch:4 step:3196 [D loss: 0.775914, acc.: 42.97%] [G loss: 0.809991]\n",
      "epoch:4 step:3197 [D loss: 0.659102, acc.: 55.47%] [G loss: 0.731642]\n",
      "epoch:4 step:3198 [D loss: 0.663307, acc.: 63.28%] [G loss: 0.829270]\n",
      "epoch:4 step:3199 [D loss: 0.628264, acc.: 67.19%] [G loss: 1.010500]\n",
      "epoch:4 step:3200 [D loss: 0.653347, acc.: 62.50%] [G loss: 0.994449]\n",
      "epoch:4 step:3201 [D loss: 0.661994, acc.: 62.50%] [G loss: 0.986714]\n",
      "epoch:4 step:3202 [D loss: 0.594822, acc.: 70.31%] [G loss: 0.930510]\n",
      "epoch:4 step:3203 [D loss: 0.640135, acc.: 64.06%] [G loss: 0.886618]\n",
      "epoch:4 step:3204 [D loss: 0.620607, acc.: 66.41%] [G loss: 0.879563]\n",
      "epoch:4 step:3205 [D loss: 0.561331, acc.: 73.44%] [G loss: 0.865919]\n",
      "epoch:4 step:3206 [D loss: 0.585356, acc.: 70.31%] [G loss: 0.818696]\n",
      "epoch:4 step:3207 [D loss: 0.625173, acc.: 63.28%] [G loss: 0.979865]\n",
      "epoch:4 step:3208 [D loss: 0.617487, acc.: 67.97%] [G loss: 0.824307]\n",
      "epoch:4 step:3209 [D loss: 0.642866, acc.: 58.59%] [G loss: 0.745789]\n",
      "epoch:4 step:3210 [D loss: 0.684228, acc.: 57.81%] [G loss: 0.758532]\n",
      "epoch:4 step:3211 [D loss: 0.590544, acc.: 68.75%] [G loss: 0.742611]\n",
      "epoch:4 step:3212 [D loss: 0.659020, acc.: 60.16%] [G loss: 0.799634]\n",
      "epoch:4 step:3213 [D loss: 0.721300, acc.: 53.91%] [G loss: 0.837118]\n",
      "epoch:4 step:3214 [D loss: 0.722327, acc.: 54.69%] [G loss: 0.792743]\n",
      "epoch:4 step:3215 [D loss: 0.678165, acc.: 57.81%] [G loss: 0.854285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3216 [D loss: 0.759529, acc.: 46.09%] [G loss: 0.748987]\n",
      "epoch:4 step:3217 [D loss: 0.682252, acc.: 56.25%] [G loss: 0.740001]\n",
      "epoch:4 step:3218 [D loss: 0.716053, acc.: 53.12%] [G loss: 0.773976]\n",
      "epoch:4 step:3219 [D loss: 0.758439, acc.: 44.53%] [G loss: 0.948312]\n",
      "epoch:4 step:3220 [D loss: 0.694710, acc.: 55.47%] [G loss: 0.774441]\n",
      "epoch:4 step:3221 [D loss: 0.671217, acc.: 57.81%] [G loss: 0.749720]\n",
      "epoch:4 step:3222 [D loss: 0.675183, acc.: 66.41%] [G loss: 0.790913]\n",
      "epoch:4 step:3223 [D loss: 0.660943, acc.: 63.28%] [G loss: 0.725003]\n",
      "epoch:4 step:3224 [D loss: 0.652505, acc.: 67.19%] [G loss: 0.752450]\n",
      "epoch:4 step:3225 [D loss: 0.709525, acc.: 53.91%] [G loss: 0.674283]\n",
      "epoch:4 step:3226 [D loss: 0.781564, acc.: 50.00%] [G loss: 0.652457]\n",
      "epoch:4 step:3227 [D loss: 0.710003, acc.: 51.56%] [G loss: 0.633518]\n",
      "epoch:4 step:3228 [D loss: 0.843544, acc.: 34.38%] [G loss: 0.610610]\n",
      "epoch:4 step:3229 [D loss: 0.685833, acc.: 58.59%] [G loss: 0.640151]\n",
      "epoch:4 step:3230 [D loss: 0.761988, acc.: 46.09%] [G loss: 0.751302]\n",
      "epoch:4 step:3231 [D loss: 0.746501, acc.: 46.09%] [G loss: 0.843662]\n",
      "epoch:4 step:3232 [D loss: 0.774806, acc.: 46.09%] [G loss: 0.738565]\n",
      "epoch:4 step:3233 [D loss: 0.667940, acc.: 58.59%] [G loss: 0.849827]\n",
      "epoch:4 step:3234 [D loss: 0.712427, acc.: 47.66%] [G loss: 0.878564]\n",
      "epoch:4 step:3235 [D loss: 0.660757, acc.: 56.25%] [G loss: 0.990519]\n",
      "epoch:4 step:3236 [D loss: 0.629254, acc.: 66.41%] [G loss: 1.046290]\n",
      "epoch:4 step:3237 [D loss: 0.661380, acc.: 60.16%] [G loss: 0.913054]\n",
      "epoch:4 step:3238 [D loss: 0.647856, acc.: 60.94%] [G loss: 0.894863]\n",
      "epoch:4 step:3239 [D loss: 0.648077, acc.: 64.84%] [G loss: 0.927967]\n",
      "epoch:4 step:3240 [D loss: 0.663149, acc.: 63.28%] [G loss: 0.972404]\n",
      "epoch:4 step:3241 [D loss: 0.647791, acc.: 67.97%] [G loss: 0.833525]\n",
      "epoch:4 step:3242 [D loss: 0.681290, acc.: 54.69%] [G loss: 0.829963]\n",
      "epoch:4 step:3243 [D loss: 0.680810, acc.: 54.69%] [G loss: 0.998539]\n",
      "epoch:4 step:3244 [D loss: 0.670855, acc.: 52.34%] [G loss: 0.896254]\n",
      "epoch:4 step:3245 [D loss: 0.736020, acc.: 50.00%] [G loss: 0.837830]\n",
      "epoch:4 step:3246 [D loss: 0.661318, acc.: 60.94%] [G loss: 0.838618]\n",
      "epoch:4 step:3247 [D loss: 0.657465, acc.: 60.94%] [G loss: 0.759839]\n",
      "epoch:4 step:3248 [D loss: 0.646355, acc.: 58.59%] [G loss: 0.790361]\n",
      "epoch:4 step:3249 [D loss: 0.714407, acc.: 48.44%] [G loss: 0.767945]\n",
      "epoch:4 step:3250 [D loss: 0.624068, acc.: 65.62%] [G loss: 0.903843]\n",
      "epoch:4 step:3251 [D loss: 0.615736, acc.: 65.62%] [G loss: 0.923066]\n",
      "epoch:4 step:3252 [D loss: 0.708461, acc.: 52.34%] [G loss: 0.803958]\n",
      "epoch:4 step:3253 [D loss: 0.578416, acc.: 71.88%] [G loss: 0.777936]\n",
      "epoch:4 step:3254 [D loss: 0.763520, acc.: 49.22%] [G loss: 0.829416]\n",
      "epoch:4 step:3255 [D loss: 0.688596, acc.: 55.47%] [G loss: 0.742301]\n",
      "epoch:4 step:3256 [D loss: 0.726032, acc.: 49.22%] [G loss: 0.675472]\n",
      "epoch:4 step:3257 [D loss: 0.684338, acc.: 56.25%] [G loss: 0.710595]\n",
      "epoch:4 step:3258 [D loss: 0.705060, acc.: 53.12%] [G loss: 0.717682]\n",
      "epoch:4 step:3259 [D loss: 0.752567, acc.: 50.00%] [G loss: 0.664612]\n",
      "epoch:4 step:3260 [D loss: 0.736284, acc.: 52.34%] [G loss: 0.651639]\n",
      "epoch:4 step:3261 [D loss: 0.667960, acc.: 63.28%] [G loss: 0.801263]\n",
      "epoch:4 step:3262 [D loss: 0.764764, acc.: 46.09%] [G loss: 0.655313]\n",
      "epoch:4 step:3263 [D loss: 0.708031, acc.: 57.03%] [G loss: 0.849881]\n",
      "epoch:4 step:3264 [D loss: 0.772735, acc.: 42.19%] [G loss: 0.803401]\n",
      "epoch:4 step:3265 [D loss: 0.655241, acc.: 61.72%] [G loss: 0.875006]\n",
      "epoch:4 step:3266 [D loss: 0.723679, acc.: 45.31%] [G loss: 0.840824]\n",
      "epoch:4 step:3267 [D loss: 0.686708, acc.: 57.81%] [G loss: 0.916744]\n",
      "epoch:4 step:3268 [D loss: 0.733660, acc.: 46.09%] [G loss: 0.768288]\n",
      "epoch:4 step:3269 [D loss: 0.680061, acc.: 56.25%] [G loss: 0.837638]\n",
      "epoch:4 step:3270 [D loss: 0.670442, acc.: 58.59%] [G loss: 0.864524]\n",
      "epoch:4 step:3271 [D loss: 0.638525, acc.: 63.28%] [G loss: 0.989460]\n",
      "epoch:4 step:3272 [D loss: 0.667664, acc.: 59.38%] [G loss: 0.971235]\n",
      "epoch:4 step:3273 [D loss: 0.658074, acc.: 64.06%] [G loss: 0.922167]\n",
      "epoch:4 step:3274 [D loss: 0.683661, acc.: 56.25%] [G loss: 0.974958]\n",
      "epoch:4 step:3275 [D loss: 0.684365, acc.: 55.47%] [G loss: 0.872517]\n",
      "epoch:4 step:3276 [D loss: 0.656709, acc.: 61.72%] [G loss: 0.874166]\n",
      "epoch:4 step:3277 [D loss: 0.704570, acc.: 53.91%] [G loss: 0.831641]\n",
      "epoch:4 step:3278 [D loss: 0.662611, acc.: 64.84%] [G loss: 0.774532]\n",
      "epoch:4 step:3279 [D loss: 0.751211, acc.: 46.09%] [G loss: 0.883426]\n",
      "epoch:4 step:3280 [D loss: 0.546579, acc.: 75.00%] [G loss: 0.876004]\n",
      "epoch:4 step:3281 [D loss: 0.667291, acc.: 57.03%] [G loss: 0.745001]\n",
      "epoch:4 step:3282 [D loss: 0.572528, acc.: 73.44%] [G loss: 0.842669]\n",
      "epoch:4 step:3283 [D loss: 0.629611, acc.: 66.41%] [G loss: 0.922195]\n",
      "epoch:4 step:3284 [D loss: 0.680818, acc.: 54.69%] [G loss: 0.797508]\n",
      "epoch:4 step:3285 [D loss: 0.707337, acc.: 53.91%] [G loss: 0.796328]\n",
      "epoch:4 step:3286 [D loss: 0.713100, acc.: 53.91%] [G loss: 0.907086]\n",
      "epoch:4 step:3287 [D loss: 0.661079, acc.: 60.16%] [G loss: 0.881251]\n",
      "epoch:4 step:3288 [D loss: 0.682580, acc.: 53.91%] [G loss: 1.043483]\n",
      "epoch:4 step:3289 [D loss: 0.649688, acc.: 57.03%] [G loss: 0.927517]\n",
      "epoch:4 step:3290 [D loss: 0.726995, acc.: 49.22%] [G loss: 0.827753]\n",
      "epoch:4 step:3291 [D loss: 0.787877, acc.: 46.88%] [G loss: 0.944694]\n",
      "epoch:4 step:3292 [D loss: 0.566822, acc.: 77.34%] [G loss: 0.884434]\n",
      "epoch:4 step:3293 [D loss: 0.659021, acc.: 62.50%] [G loss: 0.801788]\n",
      "epoch:4 step:3294 [D loss: 0.684367, acc.: 56.25%] [G loss: 0.765750]\n",
      "epoch:4 step:3295 [D loss: 0.745497, acc.: 49.22%] [G loss: 0.861133]\n",
      "epoch:4 step:3296 [D loss: 0.728936, acc.: 50.00%] [G loss: 0.926646]\n",
      "epoch:4 step:3297 [D loss: 0.724967, acc.: 56.25%] [G loss: 0.940761]\n",
      "epoch:4 step:3298 [D loss: 0.667441, acc.: 57.03%] [G loss: 0.853683]\n",
      "epoch:4 step:3299 [D loss: 0.736040, acc.: 47.66%] [G loss: 0.757948]\n",
      "epoch:4 step:3300 [D loss: 0.704925, acc.: 50.00%] [G loss: 0.733263]\n",
      "epoch:4 step:3301 [D loss: 0.604531, acc.: 67.19%] [G loss: 0.881042]\n",
      "epoch:4 step:3302 [D loss: 0.765172, acc.: 42.19%] [G loss: 0.698936]\n",
      "epoch:4 step:3303 [D loss: 0.811996, acc.: 45.31%] [G loss: 0.751917]\n",
      "epoch:4 step:3304 [D loss: 0.634129, acc.: 67.19%] [G loss: 0.921305]\n",
      "epoch:4 step:3305 [D loss: 0.687517, acc.: 60.16%] [G loss: 0.947383]\n",
      "epoch:4 step:3306 [D loss: 0.738902, acc.: 53.12%] [G loss: 0.925109]\n",
      "epoch:4 step:3307 [D loss: 0.683141, acc.: 60.94%] [G loss: 0.761634]\n",
      "epoch:4 step:3308 [D loss: 0.721777, acc.: 52.34%] [G loss: 0.803831]\n",
      "epoch:4 step:3309 [D loss: 0.653694, acc.: 58.59%] [G loss: 0.825687]\n",
      "epoch:4 step:3310 [D loss: 0.685832, acc.: 54.69%] [G loss: 0.785831]\n",
      "epoch:4 step:3311 [D loss: 0.754607, acc.: 45.31%] [G loss: 0.859922]\n",
      "epoch:4 step:3312 [D loss: 0.681623, acc.: 58.59%] [G loss: 0.719717]\n",
      "epoch:4 step:3313 [D loss: 0.646908, acc.: 64.84%] [G loss: 0.867999]\n",
      "epoch:4 step:3314 [D loss: 0.625818, acc.: 64.06%] [G loss: 0.832473]\n",
      "epoch:4 step:3315 [D loss: 0.708992, acc.: 51.56%] [G loss: 0.913666]\n",
      "epoch:4 step:3316 [D loss: 0.600204, acc.: 63.28%] [G loss: 0.941914]\n",
      "epoch:4 step:3317 [D loss: 0.720980, acc.: 54.69%] [G loss: 0.878040]\n",
      "epoch:4 step:3318 [D loss: 0.731804, acc.: 48.44%] [G loss: 0.905754]\n",
      "epoch:4 step:3319 [D loss: 0.705216, acc.: 51.56%] [G loss: 0.819806]\n",
      "epoch:4 step:3320 [D loss: 0.681891, acc.: 53.91%] [G loss: 0.785365]\n",
      "epoch:4 step:3321 [D loss: 0.707908, acc.: 50.00%] [G loss: 0.789549]\n",
      "epoch:4 step:3322 [D loss: 0.617355, acc.: 64.06%] [G loss: 0.778541]\n",
      "epoch:4 step:3323 [D loss: 0.672226, acc.: 54.69%] [G loss: 0.836480]\n",
      "epoch:4 step:3324 [D loss: 0.637900, acc.: 62.50%] [G loss: 0.840425]\n",
      "epoch:4 step:3325 [D loss: 0.632322, acc.: 58.59%] [G loss: 0.837776]\n",
      "epoch:4 step:3326 [D loss: 0.767599, acc.: 43.75%] [G loss: 0.666610]\n",
      "epoch:4 step:3327 [D loss: 0.722177, acc.: 52.34%] [G loss: 0.754160]\n",
      "epoch:4 step:3328 [D loss: 0.655407, acc.: 59.38%] [G loss: 0.924931]\n",
      "epoch:4 step:3329 [D loss: 0.565463, acc.: 75.78%] [G loss: 0.756373]\n",
      "epoch:4 step:3330 [D loss: 0.632117, acc.: 62.50%] [G loss: 0.891693]\n",
      "epoch:4 step:3331 [D loss: 0.569443, acc.: 76.56%] [G loss: 0.879796]\n",
      "epoch:4 step:3332 [D loss: 0.617117, acc.: 64.84%] [G loss: 0.714285]\n",
      "epoch:4 step:3333 [D loss: 0.614096, acc.: 64.06%] [G loss: 0.875470]\n",
      "epoch:4 step:3334 [D loss: 0.536367, acc.: 81.25%] [G loss: 0.846132]\n",
      "epoch:4 step:3335 [D loss: 0.635907, acc.: 61.72%] [G loss: 0.726023]\n",
      "epoch:4 step:3336 [D loss: 0.591743, acc.: 71.09%] [G loss: 0.659387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3337 [D loss: 0.678895, acc.: 56.25%] [G loss: 0.543187]\n",
      "epoch:4 step:3338 [D loss: 0.680868, acc.: 58.59%] [G loss: 0.704057]\n",
      "epoch:4 step:3339 [D loss: 0.586509, acc.: 67.97%] [G loss: 0.669454]\n",
      "epoch:4 step:3340 [D loss: 0.702118, acc.: 55.47%] [G loss: 0.675975]\n",
      "epoch:4 step:3341 [D loss: 0.764938, acc.: 50.00%] [G loss: 0.779971]\n",
      "epoch:4 step:3342 [D loss: 0.716002, acc.: 50.78%] [G loss: 0.743710]\n",
      "epoch:4 step:3343 [D loss: 0.731742, acc.: 51.56%] [G loss: 0.786605]\n",
      "epoch:4 step:3344 [D loss: 0.612800, acc.: 69.53%] [G loss: 0.916092]\n",
      "epoch:4 step:3345 [D loss: 0.714673, acc.: 52.34%] [G loss: 0.929472]\n",
      "epoch:4 step:3346 [D loss: 0.620762, acc.: 62.50%] [G loss: 0.893162]\n",
      "epoch:4 step:3347 [D loss: 0.662669, acc.: 63.28%] [G loss: 0.925446]\n",
      "epoch:4 step:3348 [D loss: 0.578582, acc.: 72.66%] [G loss: 0.951961]\n",
      "epoch:4 step:3349 [D loss: 0.686665, acc.: 56.25%] [G loss: 0.979064]\n",
      "epoch:4 step:3350 [D loss: 0.600889, acc.: 69.53%] [G loss: 1.051831]\n",
      "epoch:4 step:3351 [D loss: 0.689010, acc.: 55.47%] [G loss: 1.158008]\n",
      "epoch:4 step:3352 [D loss: 0.712151, acc.: 52.34%] [G loss: 0.832215]\n",
      "epoch:4 step:3353 [D loss: 0.725418, acc.: 46.88%] [G loss: 0.865286]\n",
      "epoch:4 step:3354 [D loss: 0.742653, acc.: 42.97%] [G loss: 0.899253]\n",
      "epoch:4 step:3355 [D loss: 0.699966, acc.: 53.12%] [G loss: 0.798289]\n",
      "epoch:4 step:3356 [D loss: 0.624537, acc.: 66.41%] [G loss: 0.848777]\n",
      "epoch:4 step:3357 [D loss: 0.630155, acc.: 67.19%] [G loss: 0.890326]\n",
      "epoch:4 step:3358 [D loss: 0.640981, acc.: 60.16%] [G loss: 0.849388]\n",
      "epoch:4 step:3359 [D loss: 0.679957, acc.: 64.06%] [G loss: 0.807642]\n",
      "epoch:4 step:3360 [D loss: 0.837568, acc.: 40.62%] [G loss: 0.615702]\n",
      "epoch:4 step:3361 [D loss: 0.702751, acc.: 55.47%] [G loss: 0.790137]\n",
      "epoch:4 step:3362 [D loss: 0.546473, acc.: 75.00%] [G loss: 0.746056]\n",
      "epoch:4 step:3363 [D loss: 0.701997, acc.: 56.25%] [G loss: 0.823600]\n",
      "epoch:4 step:3364 [D loss: 0.714163, acc.: 52.34%] [G loss: 0.706820]\n",
      "epoch:4 step:3365 [D loss: 0.633635, acc.: 64.06%] [G loss: 0.653464]\n",
      "epoch:4 step:3366 [D loss: 0.646849, acc.: 63.28%] [G loss: 0.635459]\n",
      "epoch:4 step:3367 [D loss: 0.689434, acc.: 60.16%] [G loss: 0.696338]\n",
      "epoch:4 step:3368 [D loss: 0.766878, acc.: 48.44%] [G loss: 0.696647]\n",
      "epoch:4 step:3369 [D loss: 0.783483, acc.: 44.53%] [G loss: 0.681411]\n",
      "epoch:4 step:3370 [D loss: 0.625878, acc.: 66.41%] [G loss: 0.792078]\n",
      "epoch:4 step:3371 [D loss: 0.718945, acc.: 50.78%] [G loss: 0.789662]\n",
      "epoch:4 step:3372 [D loss: 0.685940, acc.: 57.81%] [G loss: 0.864257]\n",
      "epoch:4 step:3373 [D loss: 0.793467, acc.: 46.09%] [G loss: 0.834551]\n",
      "epoch:4 step:3374 [D loss: 0.676214, acc.: 55.47%] [G loss: 0.860946]\n",
      "epoch:4 step:3375 [D loss: 0.690385, acc.: 55.47%] [G loss: 0.890681]\n",
      "epoch:4 step:3376 [D loss: 0.678294, acc.: 56.25%] [G loss: 0.881778]\n",
      "epoch:4 step:3377 [D loss: 0.560203, acc.: 72.66%] [G loss: 1.038064]\n",
      "epoch:4 step:3378 [D loss: 0.657288, acc.: 57.03%] [G loss: 0.926613]\n",
      "epoch:4 step:3379 [D loss: 0.742548, acc.: 46.09%] [G loss: 0.969491]\n",
      "epoch:4 step:3380 [D loss: 0.635230, acc.: 67.97%] [G loss: 0.872912]\n",
      "epoch:4 step:3381 [D loss: 0.639612, acc.: 63.28%] [G loss: 0.907371]\n",
      "epoch:4 step:3382 [D loss: 0.593132, acc.: 71.88%] [G loss: 0.984290]\n",
      "epoch:4 step:3383 [D loss: 0.653499, acc.: 60.94%] [G loss: 0.807570]\n",
      "epoch:4 step:3384 [D loss: 0.692362, acc.: 60.16%] [G loss: 0.670403]\n",
      "epoch:4 step:3385 [D loss: 0.644397, acc.: 60.16%] [G loss: 0.823644]\n",
      "epoch:4 step:3386 [D loss: 0.555295, acc.: 75.78%] [G loss: 0.854085]\n",
      "epoch:4 step:3387 [D loss: 0.726574, acc.: 49.22%] [G loss: 0.627116]\n",
      "epoch:4 step:3388 [D loss: 0.602523, acc.: 72.66%] [G loss: 0.671472]\n",
      "epoch:4 step:3389 [D loss: 0.588298, acc.: 65.62%] [G loss: 0.717976]\n",
      "epoch:4 step:3390 [D loss: 0.736013, acc.: 46.09%] [G loss: 0.620514]\n",
      "epoch:4 step:3391 [D loss: 0.947287, acc.: 27.34%] [G loss: 0.582607]\n",
      "epoch:4 step:3392 [D loss: 0.765089, acc.: 47.66%] [G loss: 0.695563]\n",
      "epoch:4 step:3393 [D loss: 0.651116, acc.: 60.94%] [G loss: 0.764108]\n",
      "epoch:4 step:3394 [D loss: 0.708275, acc.: 57.03%] [G loss: 0.703158]\n",
      "epoch:4 step:3395 [D loss: 0.775006, acc.: 42.97%] [G loss: 0.710534]\n",
      "epoch:4 step:3396 [D loss: 0.747343, acc.: 46.88%] [G loss: 0.728286]\n",
      "epoch:4 step:3397 [D loss: 0.680434, acc.: 59.38%] [G loss: 0.877644]\n",
      "epoch:4 step:3398 [D loss: 0.758550, acc.: 42.97%] [G loss: 0.813892]\n",
      "epoch:4 step:3399 [D loss: 0.685473, acc.: 54.69%] [G loss: 0.852862]\n",
      "epoch:4 step:3400 [D loss: 0.695312, acc.: 57.81%] [G loss: 0.939887]\n",
      "epoch:4 step:3401 [D loss: 0.648620, acc.: 63.28%] [G loss: 0.969930]\n",
      "epoch:4 step:3402 [D loss: 0.653305, acc.: 61.72%] [G loss: 1.015120]\n",
      "epoch:4 step:3403 [D loss: 0.583798, acc.: 75.00%] [G loss: 1.063920]\n",
      "epoch:4 step:3404 [D loss: 0.640085, acc.: 67.19%] [G loss: 0.968573]\n",
      "epoch:4 step:3405 [D loss: 0.616226, acc.: 71.09%] [G loss: 1.087659]\n",
      "epoch:4 step:3406 [D loss: 0.578313, acc.: 72.66%] [G loss: 1.238119]\n",
      "epoch:4 step:3407 [D loss: 0.492894, acc.: 82.03%] [G loss: 0.879647]\n",
      "epoch:4 step:3408 [D loss: 0.561482, acc.: 71.88%] [G loss: 0.900172]\n",
      "epoch:4 step:3409 [D loss: 0.613093, acc.: 67.19%] [G loss: 0.824049]\n",
      "epoch:4 step:3410 [D loss: 0.628279, acc.: 61.72%] [G loss: 0.913095]\n",
      "epoch:4 step:3411 [D loss: 0.601893, acc.: 67.97%] [G loss: 0.800474]\n",
      "epoch:4 step:3412 [D loss: 0.633645, acc.: 62.50%] [G loss: 0.723735]\n",
      "epoch:4 step:3413 [D loss: 0.722369, acc.: 50.78%] [G loss: 0.678246]\n",
      "epoch:4 step:3414 [D loss: 0.692609, acc.: 53.12%] [G loss: 0.686696]\n",
      "epoch:4 step:3415 [D loss: 0.700036, acc.: 53.12%] [G loss: 0.749355]\n",
      "epoch:4 step:3416 [D loss: 0.683031, acc.: 57.03%] [G loss: 0.697162]\n",
      "epoch:4 step:3417 [D loss: 0.691075, acc.: 56.25%] [G loss: 0.792538]\n",
      "epoch:4 step:3418 [D loss: 0.705861, acc.: 50.78%] [G loss: 0.733387]\n",
      "epoch:4 step:3419 [D loss: 0.703246, acc.: 56.25%] [G loss: 0.749203]\n",
      "epoch:4 step:3420 [D loss: 0.628629, acc.: 65.62%] [G loss: 0.643319]\n",
      "epoch:4 step:3421 [D loss: 0.699170, acc.: 51.56%] [G loss: 0.669339]\n",
      "epoch:4 step:3422 [D loss: 0.656538, acc.: 59.38%] [G loss: 0.705868]\n",
      "epoch:4 step:3423 [D loss: 0.759160, acc.: 43.75%] [G loss: 0.625195]\n",
      "epoch:4 step:3424 [D loss: 0.786755, acc.: 43.75%] [G loss: 0.861852]\n",
      "epoch:4 step:3425 [D loss: 0.681982, acc.: 54.69%] [G loss: 0.743552]\n",
      "epoch:4 step:3426 [D loss: 0.692809, acc.: 58.59%] [G loss: 0.662895]\n",
      "epoch:4 step:3427 [D loss: 0.751007, acc.: 42.97%] [G loss: 0.588687]\n",
      "epoch:4 step:3428 [D loss: 0.727562, acc.: 50.00%] [G loss: 0.754695]\n",
      "epoch:4 step:3429 [D loss: 0.741429, acc.: 46.88%] [G loss: 0.768686]\n",
      "epoch:4 step:3430 [D loss: 0.780109, acc.: 41.41%] [G loss: 0.897675]\n",
      "epoch:4 step:3431 [D loss: 0.635736, acc.: 66.41%] [G loss: 1.056147]\n",
      "epoch:4 step:3432 [D loss: 0.709956, acc.: 51.56%] [G loss: 0.984705]\n",
      "epoch:4 step:3433 [D loss: 0.650704, acc.: 60.16%] [G loss: 0.830874]\n",
      "epoch:4 step:3434 [D loss: 0.631503, acc.: 69.53%] [G loss: 0.931599]\n",
      "epoch:4 step:3435 [D loss: 0.628987, acc.: 63.28%] [G loss: 0.881858]\n",
      "epoch:4 step:3436 [D loss: 0.616921, acc.: 66.41%] [G loss: 0.934426]\n",
      "epoch:4 step:3437 [D loss: 0.575421, acc.: 73.44%] [G loss: 0.817116]\n",
      "epoch:4 step:3438 [D loss: 0.670579, acc.: 58.59%] [G loss: 0.790813]\n",
      "epoch:4 step:3439 [D loss: 0.483455, acc.: 89.84%] [G loss: 0.744429]\n",
      "epoch:4 step:3440 [D loss: 0.514511, acc.: 82.03%] [G loss: 0.551741]\n",
      "epoch:4 step:3441 [D loss: 0.554936, acc.: 72.66%] [G loss: 0.468955]\n",
      "epoch:4 step:3442 [D loss: 0.383668, acc.: 92.19%] [G loss: 0.607074]\n",
      "epoch:4 step:3443 [D loss: 0.605162, acc.: 65.62%] [G loss: 0.624797]\n",
      "epoch:4 step:3444 [D loss: 0.386750, acc.: 92.19%] [G loss: 0.793685]\n",
      "epoch:4 step:3445 [D loss: 0.424349, acc.: 89.06%] [G loss: 0.453890]\n",
      "epoch:4 step:3446 [D loss: 0.638665, acc.: 64.06%] [G loss: 0.562829]\n",
      "epoch:4 step:3447 [D loss: 0.573630, acc.: 67.97%] [G loss: 0.457096]\n",
      "epoch:4 step:3448 [D loss: 0.489019, acc.: 82.03%] [G loss: 0.623727]\n",
      "epoch:4 step:3449 [D loss: 0.649964, acc.: 58.59%] [G loss: 0.606293]\n",
      "epoch:4 step:3450 [D loss: 0.708844, acc.: 50.78%] [G loss: 0.685427]\n",
      "epoch:4 step:3451 [D loss: 0.674287, acc.: 57.03%] [G loss: 0.860449]\n",
      "epoch:4 step:3452 [D loss: 0.766455, acc.: 49.22%] [G loss: 0.845950]\n",
      "epoch:4 step:3453 [D loss: 0.794943, acc.: 47.66%] [G loss: 0.907173]\n",
      "epoch:4 step:3454 [D loss: 0.658948, acc.: 62.50%] [G loss: 0.988863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3455 [D loss: 0.658235, acc.: 58.59%] [G loss: 0.899685]\n",
      "epoch:4 step:3456 [D loss: 0.610692, acc.: 61.72%] [G loss: 0.950249]\n",
      "epoch:4 step:3457 [D loss: 0.564241, acc.: 78.91%] [G loss: 1.063797]\n",
      "epoch:4 step:3458 [D loss: 0.600898, acc.: 66.41%] [G loss: 1.066702]\n",
      "epoch:4 step:3459 [D loss: 0.553874, acc.: 75.00%] [G loss: 1.022055]\n",
      "epoch:4 step:3460 [D loss: 0.715778, acc.: 53.91%] [G loss: 0.810819]\n",
      "epoch:4 step:3461 [D loss: 0.800586, acc.: 39.06%] [G loss: 0.812145]\n",
      "epoch:4 step:3462 [D loss: 0.667666, acc.: 60.16%] [G loss: 0.795712]\n",
      "epoch:4 step:3463 [D loss: 0.720378, acc.: 53.91%] [G loss: 0.687711]\n",
      "epoch:4 step:3464 [D loss: 0.575728, acc.: 72.66%] [G loss: 0.838179]\n",
      "epoch:4 step:3465 [D loss: 0.606402, acc.: 67.97%] [G loss: 0.830372]\n",
      "epoch:4 step:3466 [D loss: 0.623609, acc.: 65.62%] [G loss: 0.599289]\n",
      "epoch:4 step:3467 [D loss: 0.759758, acc.: 45.31%] [G loss: 0.607358]\n",
      "epoch:4 step:3468 [D loss: 0.586944, acc.: 69.53%] [G loss: 0.555823]\n",
      "epoch:4 step:3469 [D loss: 0.538615, acc.: 71.09%] [G loss: 0.507284]\n",
      "epoch:4 step:3470 [D loss: 0.590358, acc.: 70.31%] [G loss: 0.520217]\n",
      "epoch:4 step:3471 [D loss: 0.802408, acc.: 42.19%] [G loss: 0.561689]\n",
      "epoch:4 step:3472 [D loss: 0.747445, acc.: 47.66%] [G loss: 0.551393]\n",
      "epoch:4 step:3473 [D loss: 0.755446, acc.: 49.22%] [G loss: 0.662241]\n",
      "epoch:4 step:3474 [D loss: 0.977633, acc.: 25.78%] [G loss: 0.610659]\n",
      "epoch:4 step:3475 [D loss: 0.887806, acc.: 28.91%] [G loss: 0.784674]\n",
      "epoch:4 step:3476 [D loss: 0.763379, acc.: 44.53%] [G loss: 0.864454]\n",
      "epoch:4 step:3477 [D loss: 0.742659, acc.: 51.56%] [G loss: 0.911915]\n",
      "epoch:4 step:3478 [D loss: 0.689285, acc.: 56.25%] [G loss: 0.880155]\n",
      "epoch:4 step:3479 [D loss: 0.743828, acc.: 49.22%] [G loss: 0.870180]\n",
      "epoch:4 step:3480 [D loss: 0.688375, acc.: 57.81%] [G loss: 0.914812]\n",
      "epoch:4 step:3481 [D loss: 0.739222, acc.: 48.44%] [G loss: 0.853656]\n",
      "epoch:4 step:3482 [D loss: 0.668388, acc.: 59.38%] [G loss: 0.765256]\n",
      "epoch:4 step:3483 [D loss: 0.659321, acc.: 60.16%] [G loss: 0.784414]\n",
      "epoch:4 step:3484 [D loss: 0.677619, acc.: 55.47%] [G loss: 0.849957]\n",
      "epoch:4 step:3485 [D loss: 0.613270, acc.: 69.53%] [G loss: 0.853673]\n",
      "epoch:4 step:3486 [D loss: 0.736120, acc.: 52.34%] [G loss: 0.802585]\n",
      "epoch:4 step:3487 [D loss: 0.636944, acc.: 63.28%] [G loss: 0.794495]\n",
      "epoch:4 step:3488 [D loss: 0.606858, acc.: 66.41%] [G loss: 0.882964]\n",
      "epoch:4 step:3489 [D loss: 0.553643, acc.: 76.56%] [G loss: 0.921264]\n",
      "epoch:4 step:3490 [D loss: 0.725924, acc.: 53.91%] [G loss: 0.830212]\n",
      "epoch:4 step:3491 [D loss: 0.602141, acc.: 67.19%] [G loss: 0.839081]\n",
      "epoch:4 step:3492 [D loss: 0.616711, acc.: 67.19%] [G loss: 0.777236]\n",
      "epoch:4 step:3493 [D loss: 0.598586, acc.: 70.31%] [G loss: 0.855327]\n",
      "epoch:4 step:3494 [D loss: 0.520829, acc.: 79.69%] [G loss: 0.757044]\n",
      "epoch:4 step:3495 [D loss: 0.647723, acc.: 65.62%] [G loss: 0.676617]\n",
      "epoch:4 step:3496 [D loss: 0.663888, acc.: 63.28%] [G loss: 0.831565]\n",
      "epoch:4 step:3497 [D loss: 0.810062, acc.: 37.50%] [G loss: 0.783464]\n",
      "epoch:4 step:3498 [D loss: 0.829548, acc.: 41.41%] [G loss: 0.823105]\n",
      "epoch:4 step:3499 [D loss: 0.752697, acc.: 41.41%] [G loss: 0.842828]\n",
      "epoch:4 step:3500 [D loss: 0.688037, acc.: 57.03%] [G loss: 0.739277]\n",
      "epoch:4 step:3501 [D loss: 0.743260, acc.: 48.44%] [G loss: 0.757909]\n",
      "epoch:4 step:3502 [D loss: 0.760144, acc.: 49.22%] [G loss: 0.690184]\n",
      "epoch:4 step:3503 [D loss: 0.724588, acc.: 54.69%] [G loss: 0.926454]\n",
      "epoch:4 step:3504 [D loss: 0.827902, acc.: 43.75%] [G loss: 0.822231]\n",
      "epoch:4 step:3505 [D loss: 0.786599, acc.: 48.44%] [G loss: 0.912441]\n",
      "epoch:4 step:3506 [D loss: 0.757972, acc.: 47.66%] [G loss: 0.756416]\n",
      "epoch:4 step:3507 [D loss: 0.856339, acc.: 29.69%] [G loss: 0.717882]\n",
      "epoch:4 step:3508 [D loss: 0.767027, acc.: 44.53%] [G loss: 0.771714]\n",
      "epoch:4 step:3509 [D loss: 0.665837, acc.: 60.16%] [G loss: 0.900069]\n",
      "epoch:4 step:3510 [D loss: 0.649513, acc.: 62.50%] [G loss: 0.971373]\n",
      "epoch:4 step:3511 [D loss: 0.785158, acc.: 39.84%] [G loss: 0.815408]\n",
      "epoch:4 step:3512 [D loss: 0.664968, acc.: 60.94%] [G loss: 1.069789]\n",
      "epoch:4 step:3513 [D loss: 0.687388, acc.: 57.03%] [G loss: 0.821221]\n",
      "epoch:4 step:3514 [D loss: 0.739980, acc.: 46.09%] [G loss: 0.794712]\n",
      "epoch:4 step:3515 [D loss: 0.837829, acc.: 31.25%] [G loss: 0.798532]\n",
      "epoch:4 step:3516 [D loss: 0.597287, acc.: 67.97%] [G loss: 0.915021]\n",
      "epoch:4 step:3517 [D loss: 0.667552, acc.: 62.50%] [G loss: 0.858910]\n",
      "epoch:4 step:3518 [D loss: 0.668694, acc.: 57.81%] [G loss: 0.859771]\n",
      "epoch:4 step:3519 [D loss: 0.698836, acc.: 51.56%] [G loss: 0.841877]\n",
      "epoch:4 step:3520 [D loss: 0.678885, acc.: 56.25%] [G loss: 0.950068]\n",
      "epoch:4 step:3521 [D loss: 0.678508, acc.: 59.38%] [G loss: 0.877807]\n",
      "epoch:4 step:3522 [D loss: 0.637204, acc.: 63.28%] [G loss: 0.777231]\n",
      "epoch:4 step:3523 [D loss: 0.676811, acc.: 57.81%] [G loss: 0.844814]\n",
      "epoch:4 step:3524 [D loss: 0.622755, acc.: 63.28%] [G loss: 0.967867]\n",
      "epoch:4 step:3525 [D loss: 0.703337, acc.: 54.69%] [G loss: 0.828629]\n",
      "epoch:4 step:3526 [D loss: 0.650140, acc.: 60.16%] [G loss: 0.878714]\n",
      "epoch:4 step:3527 [D loss: 0.655433, acc.: 57.81%] [G loss: 0.916808]\n",
      "epoch:4 step:3528 [D loss: 0.699162, acc.: 56.25%] [G loss: 0.800853]\n",
      "epoch:4 step:3529 [D loss: 0.725886, acc.: 46.88%] [G loss: 0.797817]\n",
      "epoch:4 step:3530 [D loss: 0.653678, acc.: 59.38%] [G loss: 0.945397]\n",
      "epoch:4 step:3531 [D loss: 0.720708, acc.: 49.22%] [G loss: 0.847938]\n",
      "epoch:4 step:3532 [D loss: 0.712981, acc.: 48.44%] [G loss: 0.896799]\n",
      "epoch:4 step:3533 [D loss: 0.637463, acc.: 64.06%] [G loss: 0.995363]\n",
      "epoch:4 step:3534 [D loss: 0.628471, acc.: 67.19%] [G loss: 0.946243]\n",
      "epoch:4 step:3535 [D loss: 0.816614, acc.: 40.62%] [G loss: 0.864101]\n",
      "epoch:4 step:3536 [D loss: 0.642499, acc.: 60.94%] [G loss: 0.845559]\n",
      "epoch:4 step:3537 [D loss: 0.754100, acc.: 46.09%] [G loss: 0.816393]\n",
      "epoch:4 step:3538 [D loss: 0.616897, acc.: 67.19%] [G loss: 0.898802]\n",
      "epoch:4 step:3539 [D loss: 0.658676, acc.: 64.84%] [G loss: 0.956171]\n",
      "epoch:4 step:3540 [D loss: 0.658453, acc.: 61.72%] [G loss: 0.837994]\n",
      "epoch:4 step:3541 [D loss: 0.626399, acc.: 71.09%] [G loss: 0.976849]\n",
      "epoch:4 step:3542 [D loss: 0.664310, acc.: 63.28%] [G loss: 0.893566]\n",
      "epoch:4 step:3543 [D loss: 0.670792, acc.: 63.28%] [G loss: 0.740697]\n",
      "epoch:4 step:3544 [D loss: 0.648923, acc.: 67.97%] [G loss: 0.708238]\n",
      "epoch:4 step:3545 [D loss: 0.623773, acc.: 63.28%] [G loss: 0.691592]\n",
      "epoch:4 step:3546 [D loss: 0.718749, acc.: 59.38%] [G loss: 0.647668]\n",
      "epoch:4 step:3547 [D loss: 0.786267, acc.: 46.09%] [G loss: 0.734049]\n",
      "epoch:4 step:3548 [D loss: 0.674474, acc.: 60.16%] [G loss: 0.741865]\n",
      "epoch:4 step:3549 [D loss: 0.695767, acc.: 53.91%] [G loss: 0.729243]\n",
      "epoch:4 step:3550 [D loss: 0.794158, acc.: 39.84%] [G loss: 0.824082]\n",
      "epoch:4 step:3551 [D loss: 0.701787, acc.: 52.34%] [G loss: 0.822069]\n",
      "epoch:4 step:3552 [D loss: 0.671135, acc.: 64.84%] [G loss: 0.937604]\n",
      "epoch:4 step:3553 [D loss: 0.574993, acc.: 71.88%] [G loss: 0.918177]\n",
      "epoch:4 step:3554 [D loss: 0.742944, acc.: 51.56%] [G loss: 0.786964]\n",
      "epoch:4 step:3555 [D loss: 0.674709, acc.: 57.03%] [G loss: 0.911877]\n",
      "epoch:4 step:3556 [D loss: 0.616088, acc.: 63.28%] [G loss: 0.931185]\n",
      "epoch:4 step:3557 [D loss: 0.691539, acc.: 58.59%] [G loss: 1.051059]\n",
      "epoch:4 step:3558 [D loss: 0.681030, acc.: 57.03%] [G loss: 0.877124]\n",
      "epoch:4 step:3559 [D loss: 0.678546, acc.: 57.03%] [G loss: 0.751178]\n",
      "epoch:4 step:3560 [D loss: 0.681397, acc.: 57.81%] [G loss: 0.861495]\n",
      "epoch:4 step:3561 [D loss: 0.740181, acc.: 44.53%] [G loss: 0.728053]\n",
      "epoch:4 step:3562 [D loss: 0.671299, acc.: 57.03%] [G loss: 0.675524]\n",
      "epoch:4 step:3563 [D loss: 0.583058, acc.: 73.44%] [G loss: 0.621266]\n",
      "epoch:4 step:3564 [D loss: 0.794638, acc.: 42.97%] [G loss: 0.694172]\n",
      "epoch:4 step:3565 [D loss: 0.524911, acc.: 82.03%] [G loss: 0.724020]\n",
      "epoch:4 step:3566 [D loss: 0.649386, acc.: 60.16%] [G loss: 0.662603]\n",
      "epoch:4 step:3567 [D loss: 0.653689, acc.: 65.62%] [G loss: 0.590059]\n",
      "epoch:4 step:3568 [D loss: 0.483569, acc.: 82.81%] [G loss: 0.602589]\n",
      "epoch:4 step:3569 [D loss: 0.622062, acc.: 67.97%] [G loss: 0.657537]\n",
      "epoch:4 step:3570 [D loss: 0.740533, acc.: 46.09%] [G loss: 0.621606]\n",
      "epoch:4 step:3571 [D loss: 0.774210, acc.: 37.50%] [G loss: 0.569780]\n",
      "epoch:4 step:3572 [D loss: 0.699043, acc.: 50.00%] [G loss: 0.665405]\n",
      "epoch:4 step:3573 [D loss: 0.863784, acc.: 32.03%] [G loss: 0.657833]\n",
      "epoch:4 step:3574 [D loss: 0.829905, acc.: 41.41%] [G loss: 0.700211]\n",
      "epoch:4 step:3575 [D loss: 0.771152, acc.: 48.44%] [G loss: 0.786903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3576 [D loss: 0.784548, acc.: 45.31%] [G loss: 1.017335]\n",
      "epoch:4 step:3577 [D loss: 0.696064, acc.: 53.91%] [G loss: 0.988363]\n",
      "epoch:4 step:3578 [D loss: 0.669429, acc.: 60.94%] [G loss: 0.945786]\n",
      "epoch:4 step:3579 [D loss: 0.720789, acc.: 51.56%] [G loss: 0.998518]\n",
      "epoch:4 step:3580 [D loss: 0.617764, acc.: 71.09%] [G loss: 0.876849]\n",
      "epoch:4 step:3581 [D loss: 0.672858, acc.: 60.16%] [G loss: 0.787660]\n",
      "epoch:4 step:3582 [D loss: 0.588351, acc.: 72.66%] [G loss: 0.900996]\n",
      "epoch:4 step:3583 [D loss: 0.627411, acc.: 62.50%] [G loss: 0.852660]\n",
      "epoch:4 step:3584 [D loss: 0.646948, acc.: 64.84%] [G loss: 0.861912]\n",
      "epoch:4 step:3585 [D loss: 0.635859, acc.: 68.75%] [G loss: 0.830936]\n",
      "epoch:4 step:3586 [D loss: 0.529453, acc.: 82.81%] [G loss: 0.854406]\n",
      "epoch:4 step:3587 [D loss: 0.599114, acc.: 74.22%] [G loss: 0.797435]\n",
      "epoch:4 step:3588 [D loss: 0.618579, acc.: 67.19%] [G loss: 0.760378]\n",
      "epoch:4 step:3589 [D loss: 0.682170, acc.: 53.12%] [G loss: 0.762982]\n",
      "epoch:4 step:3590 [D loss: 0.660537, acc.: 61.72%] [G loss: 0.861944]\n",
      "epoch:4 step:3591 [D loss: 0.703010, acc.: 58.59%] [G loss: 0.828010]\n",
      "epoch:4 step:3592 [D loss: 0.696031, acc.: 54.69%] [G loss: 0.768902]\n",
      "epoch:4 step:3593 [D loss: 0.696844, acc.: 53.12%] [G loss: 0.882565]\n",
      "epoch:4 step:3594 [D loss: 0.735091, acc.: 50.00%] [G loss: 1.005419]\n",
      "epoch:4 step:3595 [D loss: 0.694590, acc.: 55.47%] [G loss: 0.995115]\n",
      "epoch:4 step:3596 [D loss: 0.774139, acc.: 45.31%] [G loss: 0.926329]\n",
      "epoch:4 step:3597 [D loss: 0.812473, acc.: 42.97%] [G loss: 0.899430]\n",
      "epoch:4 step:3598 [D loss: 0.661643, acc.: 62.50%] [G loss: 0.769952]\n",
      "epoch:4 step:3599 [D loss: 0.722175, acc.: 50.00%] [G loss: 0.808542]\n",
      "epoch:4 step:3600 [D loss: 0.719058, acc.: 46.88%] [G loss: 0.789416]\n",
      "epoch:4 step:3601 [D loss: 0.685806, acc.: 54.69%] [G loss: 0.805131]\n",
      "epoch:4 step:3602 [D loss: 0.701822, acc.: 51.56%] [G loss: 0.787709]\n",
      "epoch:4 step:3603 [D loss: 0.775780, acc.: 42.97%] [G loss: 0.854629]\n",
      "epoch:4 step:3604 [D loss: 0.747303, acc.: 50.78%] [G loss: 0.834490]\n",
      "epoch:4 step:3605 [D loss: 0.673300, acc.: 58.59%] [G loss: 0.970452]\n",
      "epoch:4 step:3606 [D loss: 0.702639, acc.: 55.47%] [G loss: 0.936859]\n",
      "epoch:4 step:3607 [D loss: 0.678860, acc.: 57.03%] [G loss: 0.831442]\n",
      "epoch:4 step:3608 [D loss: 0.633847, acc.: 65.62%] [G loss: 0.852556]\n",
      "epoch:4 step:3609 [D loss: 0.638876, acc.: 60.94%] [G loss: 0.910207]\n",
      "epoch:4 step:3610 [D loss: 0.641673, acc.: 64.84%] [G loss: 0.782825]\n",
      "epoch:4 step:3611 [D loss: 0.694097, acc.: 59.38%] [G loss: 0.796004]\n",
      "epoch:4 step:3612 [D loss: 0.649064, acc.: 60.94%] [G loss: 0.739918]\n",
      "epoch:4 step:3613 [D loss: 0.681504, acc.: 57.81%] [G loss: 0.686964]\n",
      "epoch:4 step:3614 [D loss: 0.667307, acc.: 60.16%] [G loss: 0.686402]\n",
      "epoch:4 step:3615 [D loss: 0.707574, acc.: 52.34%] [G loss: 0.776313]\n",
      "epoch:4 step:3616 [D loss: 0.692977, acc.: 54.69%] [G loss: 0.778567]\n",
      "epoch:4 step:3617 [D loss: 0.647320, acc.: 62.50%] [G loss: 0.854856]\n",
      "epoch:4 step:3618 [D loss: 0.781308, acc.: 38.28%] [G loss: 0.766570]\n",
      "epoch:4 step:3619 [D loss: 0.737618, acc.: 43.75%] [G loss: 0.759242]\n",
      "epoch:4 step:3620 [D loss: 0.677376, acc.: 57.03%] [G loss: 0.836757]\n",
      "epoch:4 step:3621 [D loss: 0.685591, acc.: 60.94%] [G loss: 0.825823]\n",
      "epoch:4 step:3622 [D loss: 0.666335, acc.: 60.16%] [G loss: 0.724254]\n",
      "epoch:4 step:3623 [D loss: 0.735336, acc.: 50.78%] [G loss: 0.892238]\n",
      "epoch:4 step:3624 [D loss: 0.639434, acc.: 64.84%] [G loss: 0.720746]\n",
      "epoch:4 step:3625 [D loss: 0.705858, acc.: 50.00%] [G loss: 0.812787]\n",
      "epoch:4 step:3626 [D loss: 0.694683, acc.: 48.44%] [G loss: 0.817213]\n",
      "epoch:4 step:3627 [D loss: 0.754541, acc.: 52.34%] [G loss: 0.807100]\n",
      "epoch:4 step:3628 [D loss: 0.710061, acc.: 53.12%] [G loss: 0.829396]\n",
      "epoch:4 step:3629 [D loss: 0.715425, acc.: 48.44%] [G loss: 0.753245]\n",
      "epoch:4 step:3630 [D loss: 0.737032, acc.: 54.69%] [G loss: 0.820455]\n",
      "epoch:4 step:3631 [D loss: 0.751194, acc.: 42.97%] [G loss: 0.775831]\n",
      "epoch:4 step:3632 [D loss: 0.592276, acc.: 71.09%] [G loss: 0.873236]\n",
      "epoch:4 step:3633 [D loss: 0.723958, acc.: 50.00%] [G loss: 0.766398]\n",
      "epoch:4 step:3634 [D loss: 0.700882, acc.: 57.03%] [G loss: 0.860487]\n",
      "epoch:4 step:3635 [D loss: 0.736784, acc.: 43.75%] [G loss: 0.752120]\n",
      "epoch:4 step:3636 [D loss: 0.668226, acc.: 57.81%] [G loss: 0.916061]\n",
      "epoch:4 step:3637 [D loss: 0.735558, acc.: 50.78%] [G loss: 0.742150]\n",
      "epoch:4 step:3638 [D loss: 0.741999, acc.: 46.88%] [G loss: 0.807591]\n",
      "epoch:4 step:3639 [D loss: 0.697762, acc.: 55.47%] [G loss: 0.891951]\n",
      "epoch:4 step:3640 [D loss: 0.734970, acc.: 53.12%] [G loss: 0.884780]\n",
      "epoch:4 step:3641 [D loss: 0.636359, acc.: 60.94%] [G loss: 1.009567]\n",
      "epoch:4 step:3642 [D loss: 0.651506, acc.: 64.06%] [G loss: 0.916452]\n",
      "epoch:4 step:3643 [D loss: 0.764225, acc.: 42.19%] [G loss: 0.844829]\n",
      "epoch:4 step:3644 [D loss: 0.684537, acc.: 53.91%] [G loss: 0.917827]\n",
      "epoch:4 step:3645 [D loss: 0.698613, acc.: 57.81%] [G loss: 0.817631]\n",
      "epoch:4 step:3646 [D loss: 0.721094, acc.: 41.41%] [G loss: 0.879862]\n",
      "epoch:4 step:3647 [D loss: 0.744577, acc.: 43.75%] [G loss: 0.756982]\n",
      "epoch:4 step:3648 [D loss: 0.681448, acc.: 55.47%] [G loss: 0.880257]\n",
      "epoch:4 step:3649 [D loss: 0.681211, acc.: 57.03%] [G loss: 0.758085]\n",
      "epoch:4 step:3650 [D loss: 0.814532, acc.: 43.75%] [G loss: 0.680017]\n",
      "epoch:4 step:3651 [D loss: 0.886019, acc.: 32.81%] [G loss: 0.664085]\n",
      "epoch:4 step:3652 [D loss: 0.736314, acc.: 55.47%] [G loss: 0.744649]\n",
      "epoch:4 step:3653 [D loss: 0.811323, acc.: 35.94%] [G loss: 0.666674]\n",
      "epoch:4 step:3654 [D loss: 0.697121, acc.: 54.69%] [G loss: 0.874114]\n",
      "epoch:4 step:3655 [D loss: 0.665409, acc.: 62.50%] [G loss: 0.935979]\n",
      "epoch:4 step:3656 [D loss: 0.714735, acc.: 53.91%] [G loss: 0.788992]\n",
      "epoch:4 step:3657 [D loss: 0.772439, acc.: 46.09%] [G loss: 0.803289]\n",
      "epoch:4 step:3658 [D loss: 0.696304, acc.: 57.03%] [G loss: 0.827022]\n",
      "epoch:4 step:3659 [D loss: 0.693729, acc.: 57.03%] [G loss: 0.774830]\n",
      "epoch:4 step:3660 [D loss: 0.783094, acc.: 39.06%] [G loss: 0.784776]\n",
      "epoch:4 step:3661 [D loss: 0.677540, acc.: 53.91%] [G loss: 0.902540]\n",
      "epoch:4 step:3662 [D loss: 0.683084, acc.: 57.81%] [G loss: 0.898475]\n",
      "epoch:4 step:3663 [D loss: 0.695929, acc.: 52.34%] [G loss: 0.954072]\n",
      "epoch:4 step:3664 [D loss: 0.756068, acc.: 43.75%] [G loss: 0.774480]\n",
      "epoch:4 step:3665 [D loss: 0.611444, acc.: 74.22%] [G loss: 0.954830]\n",
      "epoch:4 step:3666 [D loss: 0.676558, acc.: 57.03%] [G loss: 0.821498]\n",
      "epoch:4 step:3667 [D loss: 0.631155, acc.: 67.97%] [G loss: 0.842565]\n",
      "epoch:4 step:3668 [D loss: 0.634682, acc.: 68.75%] [G loss: 0.889612]\n",
      "epoch:4 step:3669 [D loss: 0.618428, acc.: 67.97%] [G loss: 0.952326]\n",
      "epoch:4 step:3670 [D loss: 0.683923, acc.: 53.91%] [G loss: 0.803909]\n",
      "epoch:4 step:3671 [D loss: 0.640337, acc.: 62.50%] [G loss: 0.677116]\n",
      "epoch:4 step:3672 [D loss: 0.613400, acc.: 68.75%] [G loss: 0.736411]\n",
      "epoch:4 step:3673 [D loss: 0.629173, acc.: 67.97%] [G loss: 0.691838]\n",
      "epoch:4 step:3674 [D loss: 0.582681, acc.: 75.78%] [G loss: 0.638320]\n",
      "epoch:4 step:3675 [D loss: 0.734157, acc.: 51.56%] [G loss: 0.630183]\n",
      "epoch:4 step:3676 [D loss: 0.545934, acc.: 75.00%] [G loss: 0.717245]\n",
      "epoch:4 step:3677 [D loss: 0.697932, acc.: 53.91%] [G loss: 0.661742]\n",
      "epoch:4 step:3678 [D loss: 0.607653, acc.: 64.06%] [G loss: 0.753235]\n",
      "epoch:4 step:3679 [D loss: 0.727562, acc.: 48.44%] [G loss: 0.608654]\n",
      "epoch:4 step:3680 [D loss: 0.722472, acc.: 52.34%] [G loss: 0.602701]\n",
      "epoch:4 step:3681 [D loss: 0.764337, acc.: 43.75%] [G loss: 0.577104]\n",
      "epoch:4 step:3682 [D loss: 0.712643, acc.: 55.47%] [G loss: 0.609505]\n",
      "epoch:4 step:3683 [D loss: 0.619901, acc.: 59.38%] [G loss: 0.661426]\n",
      "epoch:4 step:3684 [D loss: 0.720420, acc.: 45.31%] [G loss: 0.697429]\n",
      "epoch:4 step:3685 [D loss: 0.737502, acc.: 44.53%] [G loss: 0.715710]\n",
      "epoch:4 step:3686 [D loss: 0.738128, acc.: 51.56%] [G loss: 0.686376]\n",
      "epoch:4 step:3687 [D loss: 0.618847, acc.: 67.19%] [G loss: 0.835426]\n",
      "epoch:4 step:3688 [D loss: 0.691814, acc.: 52.34%] [G loss: 0.781122]\n",
      "epoch:4 step:3689 [D loss: 0.723321, acc.: 46.09%] [G loss: 0.840669]\n",
      "epoch:4 step:3690 [D loss: 0.713111, acc.: 57.03%] [G loss: 0.878652]\n",
      "epoch:4 step:3691 [D loss: 0.716015, acc.: 50.78%] [G loss: 0.891983]\n",
      "epoch:4 step:3692 [D loss: 0.623303, acc.: 65.62%] [G loss: 0.972117]\n",
      "epoch:4 step:3693 [D loss: 0.625116, acc.: 67.19%] [G loss: 0.980059]\n",
      "epoch:4 step:3694 [D loss: 0.695259, acc.: 57.03%] [G loss: 0.872490]\n",
      "epoch:4 step:3695 [D loss: 0.609834, acc.: 71.09%] [G loss: 0.847278]\n",
      "epoch:4 step:3696 [D loss: 0.537786, acc.: 78.91%] [G loss: 0.970629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3697 [D loss: 0.606612, acc.: 72.66%] [G loss: 0.821913]\n",
      "epoch:4 step:3698 [D loss: 0.642638, acc.: 62.50%] [G loss: 0.686364]\n",
      "epoch:4 step:3699 [D loss: 0.700250, acc.: 62.50%] [G loss: 0.593902]\n",
      "epoch:4 step:3700 [D loss: 0.576433, acc.: 69.53%] [G loss: 0.681963]\n",
      "epoch:4 step:3701 [D loss: 0.570289, acc.: 75.00%] [G loss: 0.757647]\n",
      "epoch:4 step:3702 [D loss: 0.600184, acc.: 69.53%] [G loss: 0.687184]\n",
      "epoch:4 step:3703 [D loss: 0.597401, acc.: 75.00%] [G loss: 0.632494]\n",
      "epoch:4 step:3704 [D loss: 0.711016, acc.: 53.91%] [G loss: 0.541414]\n",
      "epoch:4 step:3705 [D loss: 0.654955, acc.: 60.94%] [G loss: 0.461458]\n",
      "epoch:4 step:3706 [D loss: 0.742615, acc.: 52.34%] [G loss: 0.548948]\n",
      "epoch:4 step:3707 [D loss: 0.562761, acc.: 74.22%] [G loss: 0.630376]\n",
      "epoch:4 step:3708 [D loss: 0.687925, acc.: 56.25%] [G loss: 0.604169]\n",
      "epoch:4 step:3709 [D loss: 0.665488, acc.: 57.81%] [G loss: 0.535204]\n",
      "epoch:4 step:3710 [D loss: 0.825276, acc.: 39.06%] [G loss: 0.640289]\n",
      "epoch:4 step:3711 [D loss: 0.647086, acc.: 63.28%] [G loss: 0.624395]\n",
      "epoch:4 step:3712 [D loss: 0.849239, acc.: 34.38%] [G loss: 0.721646]\n",
      "epoch:4 step:3713 [D loss: 0.723312, acc.: 52.34%] [G loss: 0.696416]\n",
      "epoch:4 step:3714 [D loss: 0.738527, acc.: 51.56%] [G loss: 0.878759]\n",
      "epoch:4 step:3715 [D loss: 0.694388, acc.: 53.12%] [G loss: 0.914246]\n",
      "epoch:4 step:3716 [D loss: 0.763729, acc.: 46.09%] [G loss: 0.895239]\n",
      "epoch:4 step:3717 [D loss: 0.690906, acc.: 55.47%] [G loss: 0.900963]\n",
      "epoch:4 step:3718 [D loss: 0.671105, acc.: 56.25%] [G loss: 0.883511]\n",
      "epoch:4 step:3719 [D loss: 0.703314, acc.: 58.59%] [G loss: 0.991092]\n",
      "epoch:4 step:3720 [D loss: 0.605874, acc.: 68.75%] [G loss: 1.072884]\n",
      "epoch:4 step:3721 [D loss: 0.645114, acc.: 63.28%] [G loss: 0.924447]\n",
      "epoch:4 step:3722 [D loss: 0.623350, acc.: 66.41%] [G loss: 0.917737]\n",
      "epoch:4 step:3723 [D loss: 0.635661, acc.: 67.97%] [G loss: 0.842282]\n",
      "epoch:4 step:3724 [D loss: 0.531368, acc.: 81.25%] [G loss: 0.882472]\n",
      "epoch:4 step:3725 [D loss: 0.733955, acc.: 47.66%] [G loss: 0.770383]\n",
      "epoch:4 step:3726 [D loss: 0.637667, acc.: 63.28%] [G loss: 0.790002]\n",
      "epoch:4 step:3727 [D loss: 0.747847, acc.: 46.09%] [G loss: 0.835377]\n",
      "epoch:4 step:3728 [D loss: 0.668566, acc.: 61.72%] [G loss: 0.806878]\n",
      "epoch:4 step:3729 [D loss: 0.676760, acc.: 56.25%] [G loss: 0.783176]\n",
      "epoch:4 step:3730 [D loss: 0.679806, acc.: 56.25%] [G loss: 0.765169]\n",
      "epoch:4 step:3731 [D loss: 0.715564, acc.: 47.66%] [G loss: 0.718086]\n",
      "epoch:4 step:3732 [D loss: 0.719030, acc.: 51.56%] [G loss: 0.719596]\n",
      "epoch:4 step:3733 [D loss: 0.713823, acc.: 52.34%] [G loss: 0.776482]\n",
      "epoch:4 step:3734 [D loss: 0.685200, acc.: 55.47%] [G loss: 0.726745]\n",
      "epoch:4 step:3735 [D loss: 0.838938, acc.: 31.25%] [G loss: 0.807647]\n",
      "epoch:4 step:3736 [D loss: 0.726080, acc.: 47.66%] [G loss: 0.877656]\n",
      "epoch:4 step:3737 [D loss: 0.741776, acc.: 50.00%] [G loss: 0.834344]\n",
      "epoch:4 step:3738 [D loss: 0.710297, acc.: 59.38%] [G loss: 0.798037]\n",
      "epoch:4 step:3739 [D loss: 0.681835, acc.: 55.47%] [G loss: 0.814240]\n",
      "epoch:4 step:3740 [D loss: 0.696400, acc.: 57.03%] [G loss: 0.855555]\n",
      "epoch:4 step:3741 [D loss: 0.772460, acc.: 47.66%] [G loss: 0.772730]\n",
      "epoch:4 step:3742 [D loss: 0.707131, acc.: 50.00%] [G loss: 0.851224]\n",
      "epoch:4 step:3743 [D loss: 0.721141, acc.: 48.44%] [G loss: 0.879982]\n",
      "epoch:4 step:3744 [D loss: 0.731856, acc.: 49.22%] [G loss: 0.784163]\n",
      "epoch:4 step:3745 [D loss: 0.802495, acc.: 41.41%] [G loss: 0.815222]\n",
      "epoch:4 step:3746 [D loss: 0.767248, acc.: 53.91%] [G loss: 0.980775]\n",
      "epoch:4 step:3747 [D loss: 0.783075, acc.: 40.62%] [G loss: 0.795992]\n",
      "epoch:4 step:3748 [D loss: 0.770769, acc.: 46.09%] [G loss: 0.753050]\n",
      "epoch:4 step:3749 [D loss: 0.778171, acc.: 43.75%] [G loss: 0.723369]\n",
      "epoch:4 step:3750 [D loss: 0.749837, acc.: 41.41%] [G loss: 0.851409]\n",
      "epoch:4 step:3751 [D loss: 0.689955, acc.: 60.94%] [G loss: 0.754395]\n",
      "epoch:4 step:3752 [D loss: 0.698914, acc.: 54.69%] [G loss: 0.855456]\n",
      "epoch:4 step:3753 [D loss: 0.732447, acc.: 50.78%] [G loss: 0.892577]\n",
      "epoch:4 step:3754 [D loss: 0.708799, acc.: 57.81%] [G loss: 1.052111]\n",
      "epoch:4 step:3755 [D loss: 0.822613, acc.: 38.28%] [G loss: 0.951775]\n",
      "epoch:4 step:3756 [D loss: 0.723551, acc.: 48.44%] [G loss: 0.832739]\n",
      "epoch:4 step:3757 [D loss: 0.733976, acc.: 51.56%] [G loss: 0.862891]\n",
      "epoch:4 step:3758 [D loss: 0.668020, acc.: 57.81%] [G loss: 0.771969]\n",
      "epoch:4 step:3759 [D loss: 0.719283, acc.: 51.56%] [G loss: 0.749623]\n",
      "epoch:4 step:3760 [D loss: 0.636086, acc.: 67.19%] [G loss: 0.783607]\n",
      "epoch:4 step:3761 [D loss: 0.674699, acc.: 58.59%] [G loss: 0.848296]\n",
      "epoch:4 step:3762 [D loss: 0.696193, acc.: 53.12%] [G loss: 0.873335]\n",
      "epoch:4 step:3763 [D loss: 0.588076, acc.: 75.00%] [G loss: 0.807727]\n",
      "epoch:4 step:3764 [D loss: 0.661962, acc.: 60.16%] [G loss: 0.757401]\n",
      "epoch:4 step:3765 [D loss: 0.701319, acc.: 54.69%] [G loss: 0.734382]\n",
      "epoch:4 step:3766 [D loss: 0.713926, acc.: 55.47%] [G loss: 0.782918]\n",
      "epoch:4 step:3767 [D loss: 0.669073, acc.: 60.16%] [G loss: 0.735546]\n",
      "epoch:4 step:3768 [D loss: 0.722649, acc.: 48.44%] [G loss: 0.829883]\n",
      "epoch:4 step:3769 [D loss: 0.747573, acc.: 43.75%] [G loss: 0.711777]\n",
      "epoch:4 step:3770 [D loss: 0.647346, acc.: 64.84%] [G loss: 0.974092]\n",
      "epoch:4 step:3771 [D loss: 0.738436, acc.: 46.88%] [G loss: 0.733554]\n",
      "epoch:4 step:3772 [D loss: 0.654746, acc.: 60.94%] [G loss: 0.836153]\n",
      "epoch:4 step:3773 [D loss: 0.624062, acc.: 61.72%] [G loss: 0.892903]\n",
      "epoch:4 step:3774 [D loss: 0.656937, acc.: 57.81%] [G loss: 0.908375]\n",
      "epoch:4 step:3775 [D loss: 0.632270, acc.: 61.72%] [G loss: 0.788386]\n",
      "epoch:4 step:3776 [D loss: 0.609923, acc.: 68.75%] [G loss: 0.817830]\n",
      "epoch:4 step:3777 [D loss: 0.672117, acc.: 64.06%] [G loss: 0.761127]\n",
      "epoch:4 step:3778 [D loss: 0.755015, acc.: 46.88%] [G loss: 0.842154]\n",
      "epoch:4 step:3779 [D loss: 0.723720, acc.: 53.12%] [G loss: 0.818299]\n",
      "epoch:4 step:3780 [D loss: 0.756048, acc.: 42.97%] [G loss: 0.779963]\n",
      "epoch:4 step:3781 [D loss: 0.711759, acc.: 56.25%] [G loss: 0.808454]\n",
      "epoch:4 step:3782 [D loss: 0.717885, acc.: 50.78%] [G loss: 0.811890]\n",
      "epoch:4 step:3783 [D loss: 0.609337, acc.: 69.53%] [G loss: 0.855998]\n",
      "epoch:4 step:3784 [D loss: 0.739348, acc.: 50.78%] [G loss: 0.822000]\n",
      "epoch:4 step:3785 [D loss: 0.741561, acc.: 50.78%] [G loss: 0.717984]\n",
      "epoch:4 step:3786 [D loss: 0.737063, acc.: 51.56%] [G loss: 0.854280]\n",
      "epoch:4 step:3787 [D loss: 0.683600, acc.: 51.56%] [G loss: 0.889971]\n",
      "epoch:4 step:3788 [D loss: 0.672206, acc.: 57.03%] [G loss: 0.908382]\n",
      "epoch:4 step:3789 [D loss: 0.659981, acc.: 60.16%] [G loss: 0.915251]\n",
      "epoch:4 step:3790 [D loss: 0.615495, acc.: 64.84%] [G loss: 0.848409]\n",
      "epoch:4 step:3791 [D loss: 0.721530, acc.: 57.03%] [G loss: 0.804192]\n",
      "epoch:4 step:3792 [D loss: 0.697763, acc.: 53.12%] [G loss: 0.850870]\n",
      "epoch:4 step:3793 [D loss: 0.708299, acc.: 53.12%] [G loss: 0.821918]\n",
      "epoch:4 step:3794 [D loss: 0.714566, acc.: 50.00%] [G loss: 0.927059]\n",
      "epoch:4 step:3795 [D loss: 0.706522, acc.: 50.00%] [G loss: 0.794705]\n",
      "epoch:4 step:3796 [D loss: 0.683503, acc.: 56.25%] [G loss: 0.888401]\n",
      "epoch:4 step:3797 [D loss: 0.667860, acc.: 56.25%] [G loss: 0.909809]\n",
      "epoch:4 step:3798 [D loss: 0.729604, acc.: 55.47%] [G loss: 0.859165]\n",
      "epoch:4 step:3799 [D loss: 0.704736, acc.: 53.91%] [G loss: 0.846396]\n",
      "epoch:4 step:3800 [D loss: 0.728774, acc.: 48.44%] [G loss: 0.863256]\n",
      "epoch:4 step:3801 [D loss: 0.612502, acc.: 67.97%] [G loss: 0.955811]\n",
      "epoch:4 step:3802 [D loss: 0.724152, acc.: 47.66%] [G loss: 0.792264]\n",
      "epoch:4 step:3803 [D loss: 0.632246, acc.: 64.84%] [G loss: 0.869781]\n",
      "epoch:4 step:3804 [D loss: 0.752299, acc.: 47.66%] [G loss: 0.902296]\n",
      "epoch:4 step:3805 [D loss: 0.659982, acc.: 57.03%] [G loss: 0.777756]\n",
      "epoch:4 step:3806 [D loss: 0.642964, acc.: 64.06%] [G loss: 0.827137]\n",
      "epoch:4 step:3807 [D loss: 0.665965, acc.: 60.16%] [G loss: 0.863602]\n",
      "epoch:4 step:3808 [D loss: 0.691490, acc.: 55.47%] [G loss: 0.818123]\n",
      "epoch:4 step:3809 [D loss: 0.636372, acc.: 67.19%] [G loss: 0.920678]\n",
      "epoch:4 step:3810 [D loss: 0.671411, acc.: 58.59%] [G loss: 0.851317]\n",
      "epoch:4 step:3811 [D loss: 0.631084, acc.: 60.94%] [G loss: 0.858410]\n",
      "epoch:4 step:3812 [D loss: 0.623263, acc.: 67.19%] [G loss: 0.886634]\n",
      "epoch:4 step:3813 [D loss: 0.653427, acc.: 61.72%] [G loss: 0.887157]\n",
      "epoch:4 step:3814 [D loss: 0.688202, acc.: 56.25%] [G loss: 0.823554]\n",
      "epoch:4 step:3815 [D loss: 0.611846, acc.: 69.53%] [G loss: 0.815628]\n",
      "epoch:4 step:3816 [D loss: 0.759665, acc.: 48.44%] [G loss: 0.856658]\n",
      "epoch:4 step:3817 [D loss: 0.694957, acc.: 55.47%] [G loss: 0.793511]\n",
      "epoch:4 step:3818 [D loss: 0.722719, acc.: 46.09%] [G loss: 0.821476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3819 [D loss: 0.622367, acc.: 67.97%] [G loss: 0.888114]\n",
      "epoch:4 step:3820 [D loss: 0.736348, acc.: 52.34%] [G loss: 0.739201]\n",
      "epoch:4 step:3821 [D loss: 0.744336, acc.: 50.00%] [G loss: 0.720899]\n",
      "epoch:4 step:3822 [D loss: 0.643952, acc.: 64.06%] [G loss: 0.758696]\n",
      "epoch:4 step:3823 [D loss: 0.732408, acc.: 48.44%] [G loss: 0.926310]\n",
      "epoch:4 step:3824 [D loss: 0.696729, acc.: 59.38%] [G loss: 0.829913]\n",
      "epoch:4 step:3825 [D loss: 0.658604, acc.: 56.25%] [G loss: 0.820647]\n",
      "epoch:4 step:3826 [D loss: 0.675767, acc.: 56.25%] [G loss: 0.850776]\n",
      "epoch:4 step:3827 [D loss: 0.759839, acc.: 45.31%] [G loss: 0.678761]\n",
      "epoch:4 step:3828 [D loss: 0.630618, acc.: 66.41%] [G loss: 0.861597]\n",
      "epoch:4 step:3829 [D loss: 0.710117, acc.: 52.34%] [G loss: 0.841500]\n",
      "epoch:4 step:3830 [D loss: 0.792034, acc.: 42.19%] [G loss: 0.745695]\n",
      "epoch:4 step:3831 [D loss: 0.761808, acc.: 45.31%] [G loss: 0.703511]\n",
      "epoch:4 step:3832 [D loss: 0.773024, acc.: 44.53%] [G loss: 0.757644]\n",
      "epoch:4 step:3833 [D loss: 0.737105, acc.: 50.00%] [G loss: 0.761421]\n",
      "epoch:4 step:3834 [D loss: 0.706103, acc.: 54.69%] [G loss: 0.888404]\n",
      "epoch:4 step:3835 [D loss: 0.630508, acc.: 64.84%] [G loss: 0.922708]\n",
      "epoch:4 step:3836 [D loss: 0.730969, acc.: 48.44%] [G loss: 0.903961]\n",
      "epoch:4 step:3837 [D loss: 0.627719, acc.: 64.84%] [G loss: 0.867003]\n",
      "epoch:4 step:3838 [D loss: 0.710752, acc.: 48.44%] [G loss: 0.862811]\n",
      "epoch:4 step:3839 [D loss: 0.707591, acc.: 50.00%] [G loss: 0.913542]\n",
      "epoch:4 step:3840 [D loss: 0.671888, acc.: 57.81%] [G loss: 0.888167]\n",
      "epoch:4 step:3841 [D loss: 0.650917, acc.: 62.50%] [G loss: 0.832893]\n",
      "epoch:4 step:3842 [D loss: 0.747552, acc.: 50.00%] [G loss: 0.774711]\n",
      "epoch:4 step:3843 [D loss: 0.694594, acc.: 53.91%] [G loss: 0.830210]\n",
      "epoch:4 step:3844 [D loss: 0.669016, acc.: 60.16%] [G loss: 0.873329]\n",
      "epoch:4 step:3845 [D loss: 0.691307, acc.: 54.69%] [G loss: 0.838757]\n",
      "epoch:4 step:3846 [D loss: 0.684806, acc.: 55.47%] [G loss: 0.867725]\n",
      "epoch:4 step:3847 [D loss: 0.673846, acc.: 54.69%] [G loss: 0.905200]\n",
      "epoch:4 step:3848 [D loss: 0.720278, acc.: 53.12%] [G loss: 0.881173]\n",
      "epoch:4 step:3849 [D loss: 0.671828, acc.: 59.38%] [G loss: 0.823155]\n",
      "epoch:4 step:3850 [D loss: 0.715570, acc.: 53.12%] [G loss: 0.822440]\n",
      "epoch:4 step:3851 [D loss: 0.664660, acc.: 61.72%] [G loss: 0.789805]\n",
      "epoch:4 step:3852 [D loss: 0.617248, acc.: 64.84%] [G loss: 0.915953]\n",
      "epoch:4 step:3853 [D loss: 0.647001, acc.: 62.50%] [G loss: 0.859330]\n",
      "epoch:4 step:3854 [D loss: 0.629294, acc.: 66.41%] [G loss: 0.837310]\n",
      "epoch:4 step:3855 [D loss: 0.670366, acc.: 60.94%] [G loss: 0.855568]\n",
      "epoch:4 step:3856 [D loss: 0.647888, acc.: 67.97%] [G loss: 0.790870]\n",
      "epoch:4 step:3857 [D loss: 0.615774, acc.: 68.75%] [G loss: 0.848857]\n",
      "epoch:4 step:3858 [D loss: 0.687519, acc.: 53.12%] [G loss: 0.864628]\n",
      "epoch:4 step:3859 [D loss: 0.754479, acc.: 45.31%] [G loss: 0.920131]\n",
      "epoch:4 step:3860 [D loss: 0.675207, acc.: 55.47%] [G loss: 0.963700]\n",
      "epoch:4 step:3861 [D loss: 0.643548, acc.: 61.72%] [G loss: 1.000467]\n",
      "epoch:4 step:3862 [D loss: 0.650233, acc.: 64.06%] [G loss: 0.911024]\n",
      "epoch:4 step:3863 [D loss: 0.658135, acc.: 62.50%] [G loss: 0.830719]\n",
      "epoch:4 step:3864 [D loss: 0.634181, acc.: 60.94%] [G loss: 1.000020]\n",
      "epoch:4 step:3865 [D loss: 0.614691, acc.: 71.09%] [G loss: 0.870431]\n",
      "epoch:4 step:3866 [D loss: 0.636987, acc.: 64.06%] [G loss: 0.806951]\n",
      "epoch:4 step:3867 [D loss: 0.686669, acc.: 56.25%] [G loss: 0.872933]\n",
      "epoch:4 step:3868 [D loss: 0.704737, acc.: 51.56%] [G loss: 0.775506]\n",
      "epoch:4 step:3869 [D loss: 0.685792, acc.: 54.69%] [G loss: 0.776230]\n",
      "epoch:4 step:3870 [D loss: 0.671705, acc.: 63.28%] [G loss: 0.882205]\n",
      "epoch:4 step:3871 [D loss: 0.628241, acc.: 74.22%] [G loss: 0.847099]\n",
      "epoch:4 step:3872 [D loss: 0.711594, acc.: 50.00%] [G loss: 0.741312]\n",
      "epoch:4 step:3873 [D loss: 0.634105, acc.: 63.28%] [G loss: 0.713554]\n",
      "epoch:4 step:3874 [D loss: 0.699593, acc.: 46.88%] [G loss: 0.668622]\n",
      "epoch:4 step:3875 [D loss: 0.599180, acc.: 71.88%] [G loss: 0.676386]\n",
      "epoch:4 step:3876 [D loss: 0.645481, acc.: 65.62%] [G loss: 0.681694]\n",
      "epoch:4 step:3877 [D loss: 0.839217, acc.: 41.41%] [G loss: 0.648960]\n",
      "epoch:4 step:3878 [D loss: 0.696812, acc.: 51.56%] [G loss: 0.931782]\n",
      "epoch:4 step:3879 [D loss: 0.715286, acc.: 52.34%] [G loss: 0.783923]\n",
      "epoch:4 step:3880 [D loss: 0.736534, acc.: 53.91%] [G loss: 0.842017]\n",
      "epoch:4 step:3881 [D loss: 0.760811, acc.: 41.41%] [G loss: 0.841298]\n",
      "epoch:4 step:3882 [D loss: 0.797619, acc.: 39.06%] [G loss: 0.729631]\n",
      "epoch:4 step:3883 [D loss: 0.722873, acc.: 46.88%] [G loss: 0.809728]\n",
      "epoch:4 step:3884 [D loss: 0.682630, acc.: 55.47%] [G loss: 0.776477]\n",
      "epoch:4 step:3885 [D loss: 0.686126, acc.: 55.47%] [G loss: 0.813608]\n",
      "epoch:4 step:3886 [D loss: 0.786813, acc.: 34.38%] [G loss: 0.822285]\n",
      "epoch:4 step:3887 [D loss: 0.700994, acc.: 50.78%] [G loss: 0.915065]\n",
      "epoch:4 step:3888 [D loss: 0.798241, acc.: 36.72%] [G loss: 0.790524]\n",
      "epoch:4 step:3889 [D loss: 0.719128, acc.: 50.00%] [G loss: 0.922371]\n",
      "epoch:4 step:3890 [D loss: 0.684263, acc.: 57.81%] [G loss: 0.844962]\n",
      "epoch:4 step:3891 [D loss: 0.701557, acc.: 53.91%] [G loss: 0.746809]\n",
      "epoch:4 step:3892 [D loss: 0.763388, acc.: 42.19%] [G loss: 0.836355]\n",
      "epoch:4 step:3893 [D loss: 0.748299, acc.: 42.97%] [G loss: 0.703088]\n",
      "epoch:4 step:3894 [D loss: 0.757733, acc.: 39.84%] [G loss: 0.702238]\n",
      "epoch:4 step:3895 [D loss: 0.709740, acc.: 50.00%] [G loss: 0.729505]\n",
      "epoch:4 step:3896 [D loss: 0.690776, acc.: 57.81%] [G loss: 0.818886]\n",
      "epoch:4 step:3897 [D loss: 0.742360, acc.: 48.44%] [G loss: 0.742925]\n",
      "epoch:4 step:3898 [D loss: 0.704039, acc.: 56.25%] [G loss: 0.774193]\n",
      "epoch:4 step:3899 [D loss: 0.679942, acc.: 56.25%] [G loss: 0.883273]\n",
      "epoch:4 step:3900 [D loss: 0.627716, acc.: 64.84%] [G loss: 0.944518]\n",
      "epoch:4 step:3901 [D loss: 0.720555, acc.: 51.56%] [G loss: 0.770781]\n",
      "epoch:4 step:3902 [D loss: 0.672180, acc.: 56.25%] [G loss: 0.804004]\n",
      "epoch:4 step:3903 [D loss: 0.722424, acc.: 49.22%] [G loss: 0.767690]\n",
      "epoch:4 step:3904 [D loss: 0.697254, acc.: 56.25%] [G loss: 0.906970]\n",
      "epoch:4 step:3905 [D loss: 0.660094, acc.: 61.72%] [G loss: 0.771808]\n",
      "epoch:5 step:3906 [D loss: 0.726596, acc.: 52.34%] [G loss: 0.889595]\n",
      "epoch:5 step:3907 [D loss: 0.767426, acc.: 47.66%] [G loss: 0.911737]\n",
      "epoch:5 step:3908 [D loss: 0.667627, acc.: 59.38%] [G loss: 0.790810]\n",
      "epoch:5 step:3909 [D loss: 0.697971, acc.: 55.47%] [G loss: 0.837091]\n",
      "epoch:5 step:3910 [D loss: 0.677119, acc.: 59.38%] [G loss: 0.897529]\n",
      "epoch:5 step:3911 [D loss: 0.668331, acc.: 57.81%] [G loss: 0.816218]\n",
      "epoch:5 step:3912 [D loss: 0.662436, acc.: 64.84%] [G loss: 0.859643]\n",
      "epoch:5 step:3913 [D loss: 0.714423, acc.: 51.56%] [G loss: 0.811851]\n",
      "epoch:5 step:3914 [D loss: 0.693977, acc.: 53.12%] [G loss: 0.810112]\n",
      "epoch:5 step:3915 [D loss: 0.730655, acc.: 47.66%] [G loss: 0.760742]\n",
      "epoch:5 step:3916 [D loss: 0.673361, acc.: 62.50%] [G loss: 0.841827]\n",
      "epoch:5 step:3917 [D loss: 0.727713, acc.: 46.09%] [G loss: 0.784045]\n",
      "epoch:5 step:3918 [D loss: 0.719097, acc.: 46.09%] [G loss: 0.790411]\n",
      "epoch:5 step:3919 [D loss: 0.683588, acc.: 56.25%] [G loss: 0.777405]\n",
      "epoch:5 step:3920 [D loss: 0.732971, acc.: 46.88%] [G loss: 0.870836]\n",
      "epoch:5 step:3921 [D loss: 0.723208, acc.: 49.22%] [G loss: 0.784664]\n",
      "epoch:5 step:3922 [D loss: 0.761498, acc.: 41.41%] [G loss: 0.797206]\n",
      "epoch:5 step:3923 [D loss: 0.704544, acc.: 51.56%] [G loss: 0.779534]\n",
      "epoch:5 step:3924 [D loss: 0.762594, acc.: 45.31%] [G loss: 0.906218]\n",
      "epoch:5 step:3925 [D loss: 0.686546, acc.: 54.69%] [G loss: 0.833773]\n",
      "epoch:5 step:3926 [D loss: 0.736696, acc.: 49.22%] [G loss: 0.770417]\n",
      "epoch:5 step:3927 [D loss: 0.766795, acc.: 40.62%] [G loss: 0.725249]\n",
      "epoch:5 step:3928 [D loss: 0.752177, acc.: 45.31%] [G loss: 0.863228]\n",
      "epoch:5 step:3929 [D loss: 0.684549, acc.: 50.00%] [G loss: 0.870183]\n",
      "epoch:5 step:3930 [D loss: 0.789129, acc.: 40.62%] [G loss: 0.778369]\n",
      "epoch:5 step:3931 [D loss: 0.717712, acc.: 47.66%] [G loss: 0.894554]\n",
      "epoch:5 step:3932 [D loss: 0.687529, acc.: 50.78%] [G loss: 0.913933]\n",
      "epoch:5 step:3933 [D loss: 0.702840, acc.: 54.69%] [G loss: 0.895264]\n",
      "epoch:5 step:3934 [D loss: 0.696711, acc.: 57.03%] [G loss: 0.853687]\n",
      "epoch:5 step:3935 [D loss: 0.698230, acc.: 56.25%] [G loss: 0.848355]\n",
      "epoch:5 step:3936 [D loss: 0.713082, acc.: 52.34%] [G loss: 0.761068]\n",
      "epoch:5 step:3937 [D loss: 0.702763, acc.: 53.12%] [G loss: 0.875403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:3938 [D loss: 0.675705, acc.: 60.94%] [G loss: 0.981662]\n",
      "epoch:5 step:3939 [D loss: 0.664771, acc.: 61.72%] [G loss: 0.927889]\n",
      "epoch:5 step:3940 [D loss: 0.637643, acc.: 60.94%] [G loss: 0.855565]\n",
      "epoch:5 step:3941 [D loss: 0.688778, acc.: 62.50%] [G loss: 0.810622]\n",
      "epoch:5 step:3942 [D loss: 0.716323, acc.: 47.66%] [G loss: 0.830618]\n",
      "epoch:5 step:3943 [D loss: 0.729892, acc.: 48.44%] [G loss: 0.843757]\n",
      "epoch:5 step:3944 [D loss: 0.680899, acc.: 62.50%] [G loss: 0.777631]\n",
      "epoch:5 step:3945 [D loss: 0.747846, acc.: 46.09%] [G loss: 0.767766]\n",
      "epoch:5 step:3946 [D loss: 0.695382, acc.: 57.03%] [G loss: 0.961440]\n",
      "epoch:5 step:3947 [D loss: 0.779715, acc.: 39.84%] [G loss: 0.814720]\n",
      "epoch:5 step:3948 [D loss: 0.725317, acc.: 47.66%] [G loss: 0.746963]\n",
      "epoch:5 step:3949 [D loss: 0.768350, acc.: 46.09%] [G loss: 0.743594]\n",
      "epoch:5 step:3950 [D loss: 0.733603, acc.: 41.41%] [G loss: 0.729724]\n",
      "epoch:5 step:3951 [D loss: 0.757512, acc.: 48.44%] [G loss: 0.811319]\n",
      "epoch:5 step:3952 [D loss: 0.705754, acc.: 50.78%] [G loss: 0.884779]\n",
      "epoch:5 step:3953 [D loss: 0.760356, acc.: 41.41%] [G loss: 0.807378]\n",
      "epoch:5 step:3954 [D loss: 0.787211, acc.: 46.09%] [G loss: 0.904163]\n",
      "epoch:5 step:3955 [D loss: 0.739183, acc.: 46.09%] [G loss: 0.807122]\n",
      "epoch:5 step:3956 [D loss: 0.725557, acc.: 49.22%] [G loss: 0.812792]\n",
      "epoch:5 step:3957 [D loss: 0.696270, acc.: 53.91%] [G loss: 0.874563]\n",
      "epoch:5 step:3958 [D loss: 0.702718, acc.: 56.25%] [G loss: 0.817465]\n",
      "epoch:5 step:3959 [D loss: 0.708742, acc.: 56.25%] [G loss: 0.893089]\n",
      "epoch:5 step:3960 [D loss: 0.733925, acc.: 46.88%] [G loss: 0.886074]\n",
      "epoch:5 step:3961 [D loss: 0.726303, acc.: 53.91%] [G loss: 0.901739]\n",
      "epoch:5 step:3962 [D loss: 0.682216, acc.: 56.25%] [G loss: 0.881628]\n",
      "epoch:5 step:3963 [D loss: 0.679564, acc.: 59.38%] [G loss: 0.761225]\n",
      "epoch:5 step:3964 [D loss: 0.681576, acc.: 60.16%] [G loss: 0.773189]\n",
      "epoch:5 step:3965 [D loss: 0.691962, acc.: 57.81%] [G loss: 0.819601]\n",
      "epoch:5 step:3966 [D loss: 0.745288, acc.: 45.31%] [G loss: 0.847623]\n",
      "epoch:5 step:3967 [D loss: 0.698636, acc.: 54.69%] [G loss: 0.910634]\n",
      "epoch:5 step:3968 [D loss: 0.658411, acc.: 60.94%] [G loss: 0.909332]\n",
      "epoch:5 step:3969 [D loss: 0.722747, acc.: 44.53%] [G loss: 0.859150]\n",
      "epoch:5 step:3970 [D loss: 0.714776, acc.: 53.12%] [G loss: 0.884005]\n",
      "epoch:5 step:3971 [D loss: 0.719559, acc.: 48.44%] [G loss: 0.784744]\n",
      "epoch:5 step:3972 [D loss: 0.746889, acc.: 44.53%] [G loss: 0.784174]\n",
      "epoch:5 step:3973 [D loss: 0.655771, acc.: 57.81%] [G loss: 0.726383]\n",
      "epoch:5 step:3974 [D loss: 0.803578, acc.: 39.06%] [G loss: 0.733407]\n",
      "epoch:5 step:3975 [D loss: 0.693846, acc.: 50.78%] [G loss: 0.831353]\n",
      "epoch:5 step:3976 [D loss: 0.765412, acc.: 47.66%] [G loss: 0.790972]\n",
      "epoch:5 step:3977 [D loss: 0.644809, acc.: 64.84%] [G loss: 0.854987]\n",
      "epoch:5 step:3978 [D loss: 0.702890, acc.: 57.81%] [G loss: 0.790658]\n",
      "epoch:5 step:3979 [D loss: 0.665907, acc.: 58.59%] [G loss: 0.766238]\n",
      "epoch:5 step:3980 [D loss: 0.722716, acc.: 48.44%] [G loss: 0.664539]\n",
      "epoch:5 step:3981 [D loss: 0.719905, acc.: 50.78%] [G loss: 0.789345]\n",
      "epoch:5 step:3982 [D loss: 0.617680, acc.: 69.53%] [G loss: 0.795746]\n",
      "epoch:5 step:3983 [D loss: 0.647713, acc.: 61.72%] [G loss: 0.774207]\n",
      "epoch:5 step:3984 [D loss: 0.677414, acc.: 58.59%] [G loss: 0.760924]\n",
      "epoch:5 step:3985 [D loss: 0.664182, acc.: 60.16%] [G loss: 0.865546]\n",
      "epoch:5 step:3986 [D loss: 0.746760, acc.: 45.31%] [G loss: 0.729718]\n",
      "epoch:5 step:3987 [D loss: 0.667863, acc.: 61.72%] [G loss: 0.840023]\n",
      "epoch:5 step:3988 [D loss: 0.662062, acc.: 57.81%] [G loss: 0.852099]\n",
      "epoch:5 step:3989 [D loss: 0.701801, acc.: 56.25%] [G loss: 0.807285]\n",
      "epoch:5 step:3990 [D loss: 0.712403, acc.: 54.69%] [G loss: 0.840737]\n",
      "epoch:5 step:3991 [D loss: 0.693806, acc.: 55.47%] [G loss: 0.775207]\n",
      "epoch:5 step:3992 [D loss: 0.626125, acc.: 64.84%] [G loss: 0.788776]\n",
      "epoch:5 step:3993 [D loss: 0.655777, acc.: 61.72%] [G loss: 0.810232]\n",
      "epoch:5 step:3994 [D loss: 0.583920, acc.: 75.78%] [G loss: 0.850147]\n",
      "epoch:5 step:3995 [D loss: 0.681845, acc.: 57.81%] [G loss: 0.841239]\n",
      "epoch:5 step:3996 [D loss: 0.751953, acc.: 46.09%] [G loss: 0.852776]\n",
      "epoch:5 step:3997 [D loss: 0.748882, acc.: 47.66%] [G loss: 0.760705]\n",
      "epoch:5 step:3998 [D loss: 0.700248, acc.: 57.81%] [G loss: 0.830259]\n",
      "epoch:5 step:3999 [D loss: 0.619838, acc.: 71.09%] [G loss: 0.906759]\n",
      "epoch:5 step:4000 [D loss: 0.654243, acc.: 57.81%] [G loss: 0.859720]\n",
      "epoch:5 step:4001 [D loss: 0.645005, acc.: 67.19%] [G loss: 0.937025]\n",
      "epoch:5 step:4002 [D loss: 0.639941, acc.: 61.72%] [G loss: 0.910120]\n",
      "epoch:5 step:4003 [D loss: 0.634678, acc.: 64.06%] [G loss: 0.967025]\n",
      "epoch:5 step:4004 [D loss: 0.599515, acc.: 69.53%] [G loss: 0.990507]\n",
      "epoch:5 step:4005 [D loss: 0.679985, acc.: 60.94%] [G loss: 0.860204]\n",
      "epoch:5 step:4006 [D loss: 0.679700, acc.: 59.38%] [G loss: 0.791778]\n",
      "epoch:5 step:4007 [D loss: 0.638931, acc.: 66.41%] [G loss: 0.816241]\n",
      "epoch:5 step:4008 [D loss: 0.647635, acc.: 61.72%] [G loss: 0.823900]\n",
      "epoch:5 step:4009 [D loss: 0.742715, acc.: 50.00%] [G loss: 0.792565]\n",
      "epoch:5 step:4010 [D loss: 0.566450, acc.: 78.12%] [G loss: 0.824634]\n",
      "epoch:5 step:4011 [D loss: 0.615931, acc.: 71.88%] [G loss: 0.849417]\n",
      "epoch:5 step:4012 [D loss: 0.689634, acc.: 57.81%] [G loss: 0.738298]\n",
      "epoch:5 step:4013 [D loss: 0.646432, acc.: 65.62%] [G loss: 0.766723]\n",
      "epoch:5 step:4014 [D loss: 0.705258, acc.: 50.78%] [G loss: 0.786325]\n",
      "epoch:5 step:4015 [D loss: 0.596392, acc.: 71.09%] [G loss: 0.744992]\n",
      "epoch:5 step:4016 [D loss: 0.697456, acc.: 53.12%] [G loss: 0.669899]\n",
      "epoch:5 step:4017 [D loss: 0.644493, acc.: 61.72%] [G loss: 0.656058]\n",
      "epoch:5 step:4018 [D loss: 0.695930, acc.: 52.34%] [G loss: 0.732043]\n",
      "epoch:5 step:4019 [D loss: 0.585384, acc.: 72.66%] [G loss: 0.683091]\n",
      "epoch:5 step:4020 [D loss: 0.725849, acc.: 51.56%] [G loss: 0.761772]\n",
      "epoch:5 step:4021 [D loss: 0.808623, acc.: 35.16%] [G loss: 0.715281]\n",
      "epoch:5 step:4022 [D loss: 0.648510, acc.: 64.06%] [G loss: 0.683317]\n",
      "epoch:5 step:4023 [D loss: 0.667605, acc.: 62.50%] [G loss: 0.731218]\n",
      "epoch:5 step:4024 [D loss: 0.644635, acc.: 66.41%] [G loss: 0.730808]\n",
      "epoch:5 step:4025 [D loss: 0.700050, acc.: 48.44%] [G loss: 0.714687]\n",
      "epoch:5 step:4026 [D loss: 0.731243, acc.: 50.00%] [G loss: 0.751413]\n",
      "epoch:5 step:4027 [D loss: 0.633754, acc.: 66.41%] [G loss: 0.683927]\n",
      "epoch:5 step:4028 [D loss: 0.776455, acc.: 44.53%] [G loss: 0.641082]\n",
      "epoch:5 step:4029 [D loss: 0.782132, acc.: 38.28%] [G loss: 0.716536]\n",
      "epoch:5 step:4030 [D loss: 0.744083, acc.: 46.88%] [G loss: 0.797643]\n",
      "epoch:5 step:4031 [D loss: 0.742277, acc.: 47.66%] [G loss: 0.740613]\n",
      "epoch:5 step:4032 [D loss: 0.655612, acc.: 62.50%] [G loss: 0.829445]\n",
      "epoch:5 step:4033 [D loss: 0.690028, acc.: 53.12%] [G loss: 0.816190]\n",
      "epoch:5 step:4034 [D loss: 0.655813, acc.: 63.28%] [G loss: 0.912319]\n",
      "epoch:5 step:4035 [D loss: 0.744850, acc.: 42.19%] [G loss: 0.824514]\n",
      "epoch:5 step:4036 [D loss: 0.735498, acc.: 44.53%] [G loss: 0.857387]\n",
      "epoch:5 step:4037 [D loss: 0.619339, acc.: 66.41%] [G loss: 0.870000]\n",
      "epoch:5 step:4038 [D loss: 0.682177, acc.: 53.91%] [G loss: 0.765484]\n",
      "epoch:5 step:4039 [D loss: 0.657706, acc.: 62.50%] [G loss: 0.935436]\n",
      "epoch:5 step:4040 [D loss: 0.638602, acc.: 63.28%] [G loss: 0.865489]\n",
      "epoch:5 step:4041 [D loss: 0.625880, acc.: 64.84%] [G loss: 0.949026]\n",
      "epoch:5 step:4042 [D loss: 0.717293, acc.: 48.44%] [G loss: 0.875598]\n",
      "epoch:5 step:4043 [D loss: 0.641238, acc.: 64.84%] [G loss: 0.662811]\n",
      "epoch:5 step:4044 [D loss: 0.714131, acc.: 53.12%] [G loss: 0.686435]\n",
      "epoch:5 step:4045 [D loss: 0.600316, acc.: 71.09%] [G loss: 0.794155]\n",
      "epoch:5 step:4046 [D loss: 0.692662, acc.: 56.25%] [G loss: 0.710374]\n",
      "epoch:5 step:4047 [D loss: 0.624229, acc.: 67.97%] [G loss: 0.816973]\n",
      "epoch:5 step:4048 [D loss: 0.615112, acc.: 71.09%] [G loss: 0.809733]\n",
      "epoch:5 step:4049 [D loss: 0.747007, acc.: 49.22%] [G loss: 0.688918]\n",
      "epoch:5 step:4050 [D loss: 0.714912, acc.: 50.00%] [G loss: 0.768464]\n",
      "epoch:5 step:4051 [D loss: 0.703433, acc.: 56.25%] [G loss: 0.729296]\n",
      "epoch:5 step:4052 [D loss: 0.707762, acc.: 45.31%] [G loss: 0.709770]\n",
      "epoch:5 step:4053 [D loss: 0.772890, acc.: 39.06%] [G loss: 0.664565]\n",
      "epoch:5 step:4054 [D loss: 0.726279, acc.: 47.66%] [G loss: 0.706802]\n",
      "epoch:5 step:4055 [D loss: 0.711401, acc.: 51.56%] [G loss: 0.732576]\n",
      "epoch:5 step:4056 [D loss: 0.854481, acc.: 30.47%] [G loss: 0.803651]\n",
      "epoch:5 step:4057 [D loss: 0.824405, acc.: 39.84%] [G loss: 0.754668]\n",
      "epoch:5 step:4058 [D loss: 0.711441, acc.: 52.34%] [G loss: 0.861929]\n",
      "epoch:5 step:4059 [D loss: 0.721097, acc.: 51.56%] [G loss: 0.879964]\n",
      "epoch:5 step:4060 [D loss: 0.703341, acc.: 54.69%] [G loss: 0.957923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4061 [D loss: 0.779769, acc.: 46.88%] [G loss: 0.877379]\n",
      "epoch:5 step:4062 [D loss: 0.633977, acc.: 65.62%] [G loss: 0.912884]\n",
      "epoch:5 step:4063 [D loss: 0.752535, acc.: 54.69%] [G loss: 0.898425]\n",
      "epoch:5 step:4064 [D loss: 0.662734, acc.: 60.94%] [G loss: 0.880702]\n",
      "epoch:5 step:4065 [D loss: 0.628562, acc.: 62.50%] [G loss: 0.786792]\n",
      "epoch:5 step:4066 [D loss: 0.763021, acc.: 49.22%] [G loss: 0.750585]\n",
      "epoch:5 step:4067 [D loss: 0.651134, acc.: 63.28%] [G loss: 0.832806]\n",
      "epoch:5 step:4068 [D loss: 0.606922, acc.: 71.09%] [G loss: 0.894936]\n",
      "epoch:5 step:4069 [D loss: 0.637988, acc.: 64.84%] [G loss: 0.870108]\n",
      "epoch:5 step:4070 [D loss: 0.667813, acc.: 57.03%] [G loss: 0.791130]\n",
      "epoch:5 step:4071 [D loss: 0.660880, acc.: 59.38%] [G loss: 0.841584]\n",
      "epoch:5 step:4072 [D loss: 0.673146, acc.: 60.94%] [G loss: 0.832120]\n",
      "epoch:5 step:4073 [D loss: 0.629031, acc.: 65.62%] [G loss: 0.912078]\n",
      "epoch:5 step:4074 [D loss: 0.683204, acc.: 59.38%] [G loss: 0.744369]\n",
      "epoch:5 step:4075 [D loss: 0.640005, acc.: 67.97%] [G loss: 0.955214]\n",
      "epoch:5 step:4076 [D loss: 0.667847, acc.: 60.94%] [G loss: 0.727121]\n",
      "epoch:5 step:4077 [D loss: 0.650670, acc.: 66.41%] [G loss: 0.649266]\n",
      "epoch:5 step:4078 [D loss: 0.682663, acc.: 57.81%] [G loss: 0.711190]\n",
      "epoch:5 step:4079 [D loss: 0.721896, acc.: 57.81%] [G loss: 0.843161]\n",
      "epoch:5 step:4080 [D loss: 0.670880, acc.: 58.59%] [G loss: 0.829017]\n",
      "epoch:5 step:4081 [D loss: 0.704822, acc.: 50.78%] [G loss: 0.680008]\n",
      "epoch:5 step:4082 [D loss: 0.643929, acc.: 58.59%] [G loss: 0.849440]\n",
      "epoch:5 step:4083 [D loss: 0.793028, acc.: 42.97%] [G loss: 0.806463]\n",
      "epoch:5 step:4084 [D loss: 0.719990, acc.: 54.69%] [G loss: 0.847224]\n",
      "epoch:5 step:4085 [D loss: 0.664005, acc.: 64.84%] [G loss: 0.876839]\n",
      "epoch:5 step:4086 [D loss: 0.614918, acc.: 69.53%] [G loss: 0.834365]\n",
      "epoch:5 step:4087 [D loss: 0.750871, acc.: 46.88%] [G loss: 0.802106]\n",
      "epoch:5 step:4088 [D loss: 0.709649, acc.: 57.81%] [G loss: 0.906474]\n",
      "epoch:5 step:4089 [D loss: 0.683394, acc.: 50.00%] [G loss: 0.904781]\n",
      "epoch:5 step:4090 [D loss: 0.700132, acc.: 56.25%] [G loss: 0.853752]\n",
      "epoch:5 step:4091 [D loss: 0.747536, acc.: 48.44%] [G loss: 0.800261]\n",
      "epoch:5 step:4092 [D loss: 0.628392, acc.: 66.41%] [G loss: 0.887993]\n",
      "epoch:5 step:4093 [D loss: 0.677352, acc.: 59.38%] [G loss: 0.802433]\n",
      "epoch:5 step:4094 [D loss: 0.702284, acc.: 52.34%] [G loss: 0.961484]\n",
      "epoch:5 step:4095 [D loss: 0.718431, acc.: 53.12%] [G loss: 0.902125]\n",
      "epoch:5 step:4096 [D loss: 0.546791, acc.: 71.88%] [G loss: 0.986971]\n",
      "epoch:5 step:4097 [D loss: 0.659307, acc.: 62.50%] [G loss: 0.927423]\n",
      "epoch:5 step:4098 [D loss: 0.644609, acc.: 67.19%] [G loss: 0.796568]\n",
      "epoch:5 step:4099 [D loss: 0.593013, acc.: 72.66%] [G loss: 0.801738]\n",
      "epoch:5 step:4100 [D loss: 0.662318, acc.: 57.81%] [G loss: 0.813459]\n",
      "epoch:5 step:4101 [D loss: 0.694290, acc.: 62.50%] [G loss: 0.708239]\n",
      "epoch:5 step:4102 [D loss: 0.582819, acc.: 73.44%] [G loss: 0.712247]\n",
      "epoch:5 step:4103 [D loss: 0.672062, acc.: 60.16%] [G loss: 0.642860]\n",
      "epoch:5 step:4104 [D loss: 0.633251, acc.: 64.84%] [G loss: 0.615670]\n",
      "epoch:5 step:4105 [D loss: 0.683008, acc.: 57.03%] [G loss: 0.588349]\n",
      "epoch:5 step:4106 [D loss: 0.626682, acc.: 64.84%] [G loss: 0.614220]\n",
      "epoch:5 step:4107 [D loss: 0.850138, acc.: 31.25%] [G loss: 0.585010]\n",
      "epoch:5 step:4108 [D loss: 0.679534, acc.: 57.03%] [G loss: 0.659906]\n",
      "epoch:5 step:4109 [D loss: 0.678334, acc.: 64.84%] [G loss: 0.719397]\n",
      "epoch:5 step:4110 [D loss: 0.854176, acc.: 28.12%] [G loss: 0.686240]\n",
      "epoch:5 step:4111 [D loss: 0.707396, acc.: 50.78%] [G loss: 0.817769]\n",
      "epoch:5 step:4112 [D loss: 0.694319, acc.: 57.03%] [G loss: 0.751654]\n",
      "epoch:5 step:4113 [D loss: 0.692441, acc.: 54.69%] [G loss: 0.801504]\n",
      "epoch:5 step:4114 [D loss: 0.693969, acc.: 53.12%] [G loss: 1.029154]\n",
      "epoch:5 step:4115 [D loss: 0.663837, acc.: 60.16%] [G loss: 0.901713]\n",
      "epoch:5 step:4116 [D loss: 0.708047, acc.: 52.34%] [G loss: 0.897071]\n",
      "epoch:5 step:4117 [D loss: 0.738647, acc.: 44.53%] [G loss: 0.771574]\n",
      "epoch:5 step:4118 [D loss: 0.760774, acc.: 39.06%] [G loss: 0.796319]\n",
      "epoch:5 step:4119 [D loss: 0.733037, acc.: 47.66%] [G loss: 0.751381]\n",
      "epoch:5 step:4120 [D loss: 0.735464, acc.: 43.75%] [G loss: 0.853934]\n",
      "epoch:5 step:4121 [D loss: 0.715354, acc.: 53.12%] [G loss: 0.801183]\n",
      "epoch:5 step:4122 [D loss: 0.707759, acc.: 55.47%] [G loss: 0.764024]\n",
      "epoch:5 step:4123 [D loss: 0.723043, acc.: 51.56%] [G loss: 0.876400]\n",
      "epoch:5 step:4124 [D loss: 0.704384, acc.: 53.12%] [G loss: 0.754740]\n",
      "epoch:5 step:4125 [D loss: 0.694374, acc.: 49.22%] [G loss: 0.954508]\n",
      "epoch:5 step:4126 [D loss: 0.698331, acc.: 54.69%] [G loss: 0.839122]\n",
      "epoch:5 step:4127 [D loss: 0.727662, acc.: 50.00%] [G loss: 0.960593]\n",
      "epoch:5 step:4128 [D loss: 0.738377, acc.: 45.31%] [G loss: 0.714680]\n",
      "epoch:5 step:4129 [D loss: 0.724113, acc.: 51.56%] [G loss: 0.737290]\n",
      "epoch:5 step:4130 [D loss: 0.745999, acc.: 49.22%] [G loss: 0.819809]\n",
      "epoch:5 step:4131 [D loss: 0.754514, acc.: 53.91%] [G loss: 0.869273]\n",
      "epoch:5 step:4132 [D loss: 0.672413, acc.: 60.94%] [G loss: 0.976243]\n",
      "epoch:5 step:4133 [D loss: 0.732003, acc.: 51.56%] [G loss: 0.844948]\n",
      "epoch:5 step:4134 [D loss: 0.686158, acc.: 54.69%] [G loss: 0.855524]\n",
      "epoch:5 step:4135 [D loss: 0.739812, acc.: 49.22%] [G loss: 0.827076]\n",
      "epoch:5 step:4136 [D loss: 0.641633, acc.: 67.19%] [G loss: 0.786844]\n",
      "epoch:5 step:4137 [D loss: 0.673252, acc.: 55.47%] [G loss: 0.838222]\n",
      "epoch:5 step:4138 [D loss: 0.728257, acc.: 53.12%] [G loss: 0.878353]\n",
      "epoch:5 step:4139 [D loss: 0.706827, acc.: 55.47%] [G loss: 0.852663]\n",
      "epoch:5 step:4140 [D loss: 0.741607, acc.: 52.34%] [G loss: 0.823919]\n",
      "epoch:5 step:4141 [D loss: 0.692550, acc.: 59.38%] [G loss: 0.773822]\n",
      "epoch:5 step:4142 [D loss: 0.639913, acc.: 63.28%] [G loss: 0.879085]\n",
      "epoch:5 step:4143 [D loss: 0.679963, acc.: 61.72%] [G loss: 0.850464]\n",
      "epoch:5 step:4144 [D loss: 0.742118, acc.: 39.84%] [G loss: 0.831779]\n",
      "epoch:5 step:4145 [D loss: 0.654743, acc.: 61.72%] [G loss: 0.847324]\n",
      "epoch:5 step:4146 [D loss: 0.682247, acc.: 62.50%] [G loss: 0.896355]\n",
      "epoch:5 step:4147 [D loss: 0.669292, acc.: 57.81%] [G loss: 0.841222]\n",
      "epoch:5 step:4148 [D loss: 0.677714, acc.: 55.47%] [G loss: 0.916665]\n",
      "epoch:5 step:4149 [D loss: 0.658428, acc.: 60.94%] [G loss: 0.808887]\n",
      "epoch:5 step:4150 [D loss: 0.766276, acc.: 39.84%] [G loss: 0.727533]\n",
      "epoch:5 step:4151 [D loss: 0.717684, acc.: 46.09%] [G loss: 0.704068]\n",
      "epoch:5 step:4152 [D loss: 0.672184, acc.: 57.81%] [G loss: 0.668220]\n",
      "epoch:5 step:4153 [D loss: 0.660238, acc.: 64.84%] [G loss: 0.811161]\n",
      "epoch:5 step:4154 [D loss: 0.657831, acc.: 57.81%] [G loss: 0.840486]\n",
      "epoch:5 step:4155 [D loss: 0.689905, acc.: 53.12%] [G loss: 0.727512]\n",
      "epoch:5 step:4156 [D loss: 0.719918, acc.: 54.69%] [G loss: 0.798830]\n",
      "epoch:5 step:4157 [D loss: 0.724627, acc.: 50.78%] [G loss: 0.850887]\n",
      "epoch:5 step:4158 [D loss: 0.720150, acc.: 46.88%] [G loss: 0.770099]\n",
      "epoch:5 step:4159 [D loss: 0.769967, acc.: 40.62%] [G loss: 0.774417]\n",
      "epoch:5 step:4160 [D loss: 0.724745, acc.: 50.78%] [G loss: 0.815530]\n",
      "epoch:5 step:4161 [D loss: 0.785707, acc.: 40.62%] [G loss: 0.713666]\n",
      "epoch:5 step:4162 [D loss: 0.749369, acc.: 48.44%] [G loss: 0.706823]\n",
      "epoch:5 step:4163 [D loss: 0.728421, acc.: 46.88%] [G loss: 0.741756]\n",
      "epoch:5 step:4164 [D loss: 0.742207, acc.: 49.22%] [G loss: 0.950938]\n",
      "epoch:5 step:4165 [D loss: 0.665444, acc.: 59.38%] [G loss: 0.920700]\n",
      "epoch:5 step:4166 [D loss: 0.687271, acc.: 50.00%] [G loss: 0.935229]\n",
      "epoch:5 step:4167 [D loss: 0.719047, acc.: 57.81%] [G loss: 0.851381]\n",
      "epoch:5 step:4168 [D loss: 0.693274, acc.: 56.25%] [G loss: 0.796165]\n",
      "epoch:5 step:4169 [D loss: 0.692135, acc.: 55.47%] [G loss: 0.812517]\n",
      "epoch:5 step:4170 [D loss: 0.655853, acc.: 58.59%] [G loss: 0.841594]\n",
      "epoch:5 step:4171 [D loss: 0.688183, acc.: 54.69%] [G loss: 0.810554]\n",
      "epoch:5 step:4172 [D loss: 0.723043, acc.: 45.31%] [G loss: 0.692479]\n",
      "epoch:5 step:4173 [D loss: 0.643647, acc.: 66.41%] [G loss: 0.743728]\n",
      "epoch:5 step:4174 [D loss: 0.709845, acc.: 57.03%] [G loss: 0.771123]\n",
      "epoch:5 step:4175 [D loss: 0.644235, acc.: 60.16%] [G loss: 0.819381]\n",
      "epoch:5 step:4176 [D loss: 0.628242, acc.: 64.06%] [G loss: 0.751498]\n",
      "epoch:5 step:4177 [D loss: 0.708965, acc.: 50.78%] [G loss: 0.723592]\n",
      "epoch:5 step:4178 [D loss: 0.725406, acc.: 50.78%] [G loss: 0.761866]\n",
      "epoch:5 step:4179 [D loss: 0.713238, acc.: 53.12%] [G loss: 0.750502]\n",
      "epoch:5 step:4180 [D loss: 0.739219, acc.: 47.66%] [G loss: 0.763504]\n",
      "epoch:5 step:4181 [D loss: 0.791541, acc.: 29.69%] [G loss: 0.792154]\n",
      "epoch:5 step:4182 [D loss: 0.781590, acc.: 43.75%] [G loss: 0.852262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4183 [D loss: 0.754234, acc.: 43.75%] [G loss: 0.795671]\n",
      "epoch:5 step:4184 [D loss: 0.684316, acc.: 53.91%] [G loss: 0.822731]\n",
      "epoch:5 step:4185 [D loss: 0.756063, acc.: 38.28%] [G loss: 0.716495]\n",
      "epoch:5 step:4186 [D loss: 0.737554, acc.: 43.75%] [G loss: 0.815024]\n",
      "epoch:5 step:4187 [D loss: 0.707935, acc.: 48.44%] [G loss: 0.762942]\n",
      "epoch:5 step:4188 [D loss: 0.758185, acc.: 45.31%] [G loss: 0.672718]\n",
      "epoch:5 step:4189 [D loss: 0.666692, acc.: 62.50%] [G loss: 0.950043]\n",
      "epoch:5 step:4190 [D loss: 0.671433, acc.: 61.72%] [G loss: 0.852819]\n",
      "epoch:5 step:4191 [D loss: 0.643881, acc.: 64.06%] [G loss: 0.824998]\n",
      "epoch:5 step:4192 [D loss: 0.710588, acc.: 50.00%] [G loss: 0.880588]\n",
      "epoch:5 step:4193 [D loss: 0.711058, acc.: 50.78%] [G loss: 0.803844]\n",
      "epoch:5 step:4194 [D loss: 0.649211, acc.: 62.50%] [G loss: 0.776217]\n",
      "epoch:5 step:4195 [D loss: 0.696182, acc.: 51.56%] [G loss: 0.759002]\n",
      "epoch:5 step:4196 [D loss: 0.727487, acc.: 42.97%] [G loss: 0.811459]\n",
      "epoch:5 step:4197 [D loss: 0.712802, acc.: 46.09%] [G loss: 0.854020]\n",
      "epoch:5 step:4198 [D loss: 0.694365, acc.: 54.69%] [G loss: 0.878711]\n",
      "epoch:5 step:4199 [D loss: 0.707802, acc.: 49.22%] [G loss: 0.920886]\n",
      "epoch:5 step:4200 [D loss: 0.699665, acc.: 59.38%] [G loss: 0.908042]\n",
      "epoch:5 step:4201 [D loss: 0.733634, acc.: 43.75%] [G loss: 0.757493]\n",
      "epoch:5 step:4202 [D loss: 0.762155, acc.: 46.88%] [G loss: 0.812062]\n",
      "epoch:5 step:4203 [D loss: 0.660803, acc.: 61.72%] [G loss: 0.850219]\n",
      "epoch:5 step:4204 [D loss: 0.753279, acc.: 41.41%] [G loss: 0.762561]\n",
      "epoch:5 step:4205 [D loss: 0.706794, acc.: 53.91%] [G loss: 0.843370]\n",
      "epoch:5 step:4206 [D loss: 0.703261, acc.: 50.78%] [G loss: 0.685771]\n",
      "epoch:5 step:4207 [D loss: 0.641033, acc.: 64.06%] [G loss: 0.808174]\n",
      "epoch:5 step:4208 [D loss: 0.671944, acc.: 59.38%] [G loss: 0.870379]\n",
      "epoch:5 step:4209 [D loss: 0.680938, acc.: 57.03%] [G loss: 0.839955]\n",
      "epoch:5 step:4210 [D loss: 0.688823, acc.: 53.91%] [G loss: 0.745088]\n",
      "epoch:5 step:4211 [D loss: 0.710669, acc.: 52.34%] [G loss: 0.819413]\n",
      "epoch:5 step:4212 [D loss: 0.680160, acc.: 59.38%] [G loss: 0.743221]\n",
      "epoch:5 step:4213 [D loss: 0.631914, acc.: 66.41%] [G loss: 0.872328]\n",
      "epoch:5 step:4214 [D loss: 0.660763, acc.: 61.72%] [G loss: 0.819174]\n",
      "epoch:5 step:4215 [D loss: 0.650091, acc.: 61.72%] [G loss: 0.859942]\n",
      "epoch:5 step:4216 [D loss: 0.691089, acc.: 58.59%] [G loss: 0.844298]\n",
      "epoch:5 step:4217 [D loss: 0.705398, acc.: 57.03%] [G loss: 0.756847]\n",
      "epoch:5 step:4218 [D loss: 0.746841, acc.: 46.09%] [G loss: 0.786310]\n",
      "epoch:5 step:4219 [D loss: 0.655357, acc.: 59.38%] [G loss: 0.845178]\n",
      "epoch:5 step:4220 [D loss: 0.689437, acc.: 63.28%] [G loss: 0.849175]\n",
      "epoch:5 step:4221 [D loss: 0.625612, acc.: 67.97%] [G loss: 0.851220]\n",
      "epoch:5 step:4222 [D loss: 0.682663, acc.: 57.81%] [G loss: 0.700305]\n",
      "epoch:5 step:4223 [D loss: 0.712300, acc.: 50.78%] [G loss: 0.777186]\n",
      "epoch:5 step:4224 [D loss: 0.645351, acc.: 64.84%] [G loss: 0.854639]\n",
      "epoch:5 step:4225 [D loss: 0.779084, acc.: 40.62%] [G loss: 0.771318]\n",
      "epoch:5 step:4226 [D loss: 0.690744, acc.: 50.00%] [G loss: 0.818427]\n",
      "epoch:5 step:4227 [D loss: 0.649337, acc.: 61.72%] [G loss: 0.768367]\n",
      "epoch:5 step:4228 [D loss: 0.736612, acc.: 50.78%] [G loss: 0.724263]\n",
      "epoch:5 step:4229 [D loss: 0.734054, acc.: 46.09%] [G loss: 0.824594]\n",
      "epoch:5 step:4230 [D loss: 0.749487, acc.: 45.31%] [G loss: 0.819935]\n",
      "epoch:5 step:4231 [D loss: 0.705602, acc.: 47.66%] [G loss: 0.759382]\n",
      "epoch:5 step:4232 [D loss: 0.697224, acc.: 54.69%] [G loss: 0.834968]\n",
      "epoch:5 step:4233 [D loss: 0.729755, acc.: 48.44%] [G loss: 0.813682]\n",
      "epoch:5 step:4234 [D loss: 0.692348, acc.: 60.16%] [G loss: 0.825104]\n",
      "epoch:5 step:4235 [D loss: 0.786853, acc.: 39.84%] [G loss: 0.740277]\n",
      "epoch:5 step:4236 [D loss: 0.755975, acc.: 42.19%] [G loss: 0.702789]\n",
      "epoch:5 step:4237 [D loss: 0.678777, acc.: 57.03%] [G loss: 0.769016]\n",
      "epoch:5 step:4238 [D loss: 0.750029, acc.: 50.78%] [G loss: 0.734886]\n",
      "epoch:5 step:4239 [D loss: 0.691120, acc.: 56.25%] [G loss: 0.803715]\n",
      "epoch:5 step:4240 [D loss: 0.685290, acc.: 48.44%] [G loss: 0.843420]\n",
      "epoch:5 step:4241 [D loss: 0.753168, acc.: 47.66%] [G loss: 0.894588]\n",
      "epoch:5 step:4242 [D loss: 0.671350, acc.: 57.81%] [G loss: 0.870758]\n",
      "epoch:5 step:4243 [D loss: 0.593939, acc.: 73.44%] [G loss: 0.815049]\n",
      "epoch:5 step:4244 [D loss: 0.619353, acc.: 68.75%] [G loss: 0.806114]\n",
      "epoch:5 step:4245 [D loss: 0.640498, acc.: 63.28%] [G loss: 0.849219]\n",
      "epoch:5 step:4246 [D loss: 0.616962, acc.: 70.31%] [G loss: 0.873608]\n",
      "epoch:5 step:4247 [D loss: 0.623213, acc.: 67.19%] [G loss: 0.734672]\n",
      "epoch:5 step:4248 [D loss: 0.604670, acc.: 65.62%] [G loss: 0.841545]\n",
      "epoch:5 step:4249 [D loss: 0.618915, acc.: 65.62%] [G loss: 0.713864]\n",
      "epoch:5 step:4250 [D loss: 0.606696, acc.: 65.62%] [G loss: 0.702569]\n",
      "epoch:5 step:4251 [D loss: 0.547622, acc.: 77.34%] [G loss: 0.678488]\n",
      "epoch:5 step:4252 [D loss: 0.787958, acc.: 35.16%] [G loss: 0.503011]\n",
      "epoch:5 step:4253 [D loss: 0.619161, acc.: 66.41%] [G loss: 0.734058]\n",
      "epoch:5 step:4254 [D loss: 0.704483, acc.: 59.38%] [G loss: 0.643291]\n",
      "epoch:5 step:4255 [D loss: 0.628161, acc.: 64.84%] [G loss: 0.644111]\n",
      "epoch:5 step:4256 [D loss: 0.759956, acc.: 42.97%] [G loss: 0.602765]\n",
      "epoch:5 step:4257 [D loss: 0.766485, acc.: 41.41%] [G loss: 0.614015]\n",
      "epoch:5 step:4258 [D loss: 0.745603, acc.: 50.78%] [G loss: 0.668949]\n",
      "epoch:5 step:4259 [D loss: 0.794357, acc.: 40.62%] [G loss: 0.630903]\n",
      "epoch:5 step:4260 [D loss: 0.713692, acc.: 50.00%] [G loss: 0.503144]\n",
      "epoch:5 step:4261 [D loss: 0.910526, acc.: 28.91%] [G loss: 0.535673]\n",
      "epoch:5 step:4262 [D loss: 0.830038, acc.: 28.91%] [G loss: 0.750589]\n",
      "epoch:5 step:4263 [D loss: 0.772887, acc.: 36.72%] [G loss: 0.803131]\n",
      "epoch:5 step:4264 [D loss: 0.795432, acc.: 42.97%] [G loss: 0.732009]\n",
      "epoch:5 step:4265 [D loss: 0.822447, acc.: 33.59%] [G loss: 0.792454]\n",
      "epoch:5 step:4266 [D loss: 0.700627, acc.: 50.78%] [G loss: 0.820351]\n",
      "epoch:5 step:4267 [D loss: 0.704503, acc.: 57.03%] [G loss: 0.814391]\n",
      "epoch:5 step:4268 [D loss: 0.701210, acc.: 52.34%] [G loss: 0.836806]\n",
      "epoch:5 step:4269 [D loss: 0.714433, acc.: 56.25%] [G loss: 0.941590]\n",
      "epoch:5 step:4270 [D loss: 0.696791, acc.: 60.16%] [G loss: 0.866019]\n",
      "epoch:5 step:4271 [D loss: 0.695992, acc.: 57.81%] [G loss: 0.870117]\n",
      "epoch:5 step:4272 [D loss: 0.650896, acc.: 65.62%] [G loss: 0.893988]\n",
      "epoch:5 step:4273 [D loss: 0.624000, acc.: 68.75%] [G loss: 0.960094]\n",
      "epoch:5 step:4274 [D loss: 0.715968, acc.: 51.56%] [G loss: 0.922345]\n",
      "epoch:5 step:4275 [D loss: 0.687419, acc.: 56.25%] [G loss: 0.886297]\n",
      "epoch:5 step:4276 [D loss: 0.681528, acc.: 58.59%] [G loss: 0.908843]\n",
      "epoch:5 step:4277 [D loss: 0.641284, acc.: 62.50%] [G loss: 0.908318]\n",
      "epoch:5 step:4278 [D loss: 0.610484, acc.: 75.00%] [G loss: 0.913811]\n",
      "epoch:5 step:4279 [D loss: 0.713979, acc.: 53.12%] [G loss: 0.833716]\n",
      "epoch:5 step:4280 [D loss: 0.660275, acc.: 60.94%] [G loss: 0.863003]\n",
      "epoch:5 step:4281 [D loss: 0.592433, acc.: 76.56%] [G loss: 0.931342]\n",
      "epoch:5 step:4282 [D loss: 0.670435, acc.: 58.59%] [G loss: 0.785267]\n",
      "epoch:5 step:4283 [D loss: 0.686007, acc.: 60.16%] [G loss: 0.660514]\n",
      "epoch:5 step:4284 [D loss: 0.633730, acc.: 68.75%] [G loss: 0.752140]\n",
      "epoch:5 step:4285 [D loss: 0.637529, acc.: 64.06%] [G loss: 0.788102]\n",
      "epoch:5 step:4286 [D loss: 0.686190, acc.: 54.69%] [G loss: 0.710354]\n",
      "epoch:5 step:4287 [D loss: 0.623787, acc.: 68.75%] [G loss: 0.743625]\n",
      "epoch:5 step:4288 [D loss: 0.630685, acc.: 67.19%] [G loss: 0.622311]\n",
      "epoch:5 step:4289 [D loss: 0.606337, acc.: 70.31%] [G loss: 0.680787]\n",
      "epoch:5 step:4290 [D loss: 0.689262, acc.: 62.50%] [G loss: 0.720321]\n",
      "epoch:5 step:4291 [D loss: 0.700020, acc.: 52.34%] [G loss: 0.666138]\n",
      "epoch:5 step:4292 [D loss: 0.723445, acc.: 53.12%] [G loss: 0.798931]\n",
      "epoch:5 step:4293 [D loss: 0.730881, acc.: 47.66%] [G loss: 0.859008]\n",
      "epoch:5 step:4294 [D loss: 0.736970, acc.: 46.88%] [G loss: 0.688875]\n",
      "epoch:5 step:4295 [D loss: 0.630935, acc.: 67.19%] [G loss: 0.746622]\n",
      "epoch:5 step:4296 [D loss: 0.851968, acc.: 31.25%] [G loss: 0.670445]\n",
      "epoch:5 step:4297 [D loss: 0.702385, acc.: 50.78%] [G loss: 0.655335]\n",
      "epoch:5 step:4298 [D loss: 0.612744, acc.: 65.62%] [G loss: 0.771513]\n",
      "epoch:5 step:4299 [D loss: 0.726710, acc.: 49.22%] [G loss: 0.718430]\n",
      "epoch:5 step:4300 [D loss: 0.701169, acc.: 51.56%] [G loss: 0.849308]\n",
      "epoch:5 step:4301 [D loss: 0.815590, acc.: 35.94%] [G loss: 0.784936]\n",
      "epoch:5 step:4302 [D loss: 0.797824, acc.: 31.25%] [G loss: 0.761044]\n",
      "epoch:5 step:4303 [D loss: 0.726847, acc.: 48.44%] [G loss: 0.795463]\n",
      "epoch:5 step:4304 [D loss: 0.695000, acc.: 56.25%] [G loss: 0.831690]\n",
      "epoch:5 step:4305 [D loss: 0.699013, acc.: 51.56%] [G loss: 0.882486]\n",
      "epoch:5 step:4306 [D loss: 0.653838, acc.: 60.94%] [G loss: 0.932101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4307 [D loss: 0.708194, acc.: 49.22%] [G loss: 0.871234]\n",
      "epoch:5 step:4308 [D loss: 0.642538, acc.: 64.06%] [G loss: 0.881392]\n",
      "epoch:5 step:4309 [D loss: 0.637495, acc.: 64.84%] [G loss: 0.811922]\n",
      "epoch:5 step:4310 [D loss: 0.679827, acc.: 58.59%] [G loss: 0.852493]\n",
      "epoch:5 step:4311 [D loss: 0.685415, acc.: 53.12%] [G loss: 0.818656]\n",
      "epoch:5 step:4312 [D loss: 0.706928, acc.: 50.78%] [G loss: 0.911895]\n",
      "epoch:5 step:4313 [D loss: 0.704087, acc.: 48.44%] [G loss: 0.873940]\n",
      "epoch:5 step:4314 [D loss: 0.763136, acc.: 46.09%] [G loss: 0.808885]\n",
      "epoch:5 step:4315 [D loss: 0.646003, acc.: 62.50%] [G loss: 0.819496]\n",
      "epoch:5 step:4316 [D loss: 0.669720, acc.: 64.84%] [G loss: 0.768338]\n",
      "epoch:5 step:4317 [D loss: 0.697240, acc.: 54.69%] [G loss: 0.733614]\n",
      "epoch:5 step:4318 [D loss: 0.700603, acc.: 54.69%] [G loss: 0.673005]\n",
      "epoch:5 step:4319 [D loss: 0.617489, acc.: 71.09%] [G loss: 0.729098]\n",
      "epoch:5 step:4320 [D loss: 0.726810, acc.: 44.53%] [G loss: 0.736416]\n",
      "epoch:5 step:4321 [D loss: 0.688967, acc.: 54.69%] [G loss: 0.676896]\n",
      "epoch:5 step:4322 [D loss: 0.781130, acc.: 42.19%] [G loss: 0.729811]\n",
      "epoch:5 step:4323 [D loss: 0.795723, acc.: 36.72%] [G loss: 0.761043]\n",
      "epoch:5 step:4324 [D loss: 0.702289, acc.: 50.00%] [G loss: 0.847020]\n",
      "epoch:5 step:4325 [D loss: 0.739539, acc.: 42.97%] [G loss: 0.800292]\n",
      "epoch:5 step:4326 [D loss: 0.743593, acc.: 47.66%] [G loss: 0.901512]\n",
      "epoch:5 step:4327 [D loss: 0.736913, acc.: 43.75%] [G loss: 0.955741]\n",
      "epoch:5 step:4328 [D loss: 0.696957, acc.: 55.47%] [G loss: 0.946140]\n",
      "epoch:5 step:4329 [D loss: 0.733673, acc.: 48.44%] [G loss: 0.781006]\n",
      "epoch:5 step:4330 [D loss: 0.687881, acc.: 56.25%] [G loss: 0.914997]\n",
      "epoch:5 step:4331 [D loss: 0.746462, acc.: 49.22%] [G loss: 0.799771]\n",
      "epoch:5 step:4332 [D loss: 0.664533, acc.: 64.06%] [G loss: 0.864805]\n",
      "epoch:5 step:4333 [D loss: 0.731667, acc.: 49.22%] [G loss: 0.777968]\n",
      "epoch:5 step:4334 [D loss: 0.696042, acc.: 51.56%] [G loss: 0.709560]\n",
      "epoch:5 step:4335 [D loss: 0.643487, acc.: 64.06%] [G loss: 0.747067]\n",
      "epoch:5 step:4336 [D loss: 0.752983, acc.: 39.84%] [G loss: 0.900850]\n",
      "epoch:5 step:4337 [D loss: 0.671961, acc.: 51.56%] [G loss: 0.855007]\n",
      "epoch:5 step:4338 [D loss: 0.643937, acc.: 62.50%] [G loss: 0.960344]\n",
      "epoch:5 step:4339 [D loss: 0.659085, acc.: 63.28%] [G loss: 0.936508]\n",
      "epoch:5 step:4340 [D loss: 0.676190, acc.: 60.16%] [G loss: 0.796457]\n",
      "epoch:5 step:4341 [D loss: 0.729033, acc.: 48.44%] [G loss: 0.879927]\n",
      "epoch:5 step:4342 [D loss: 0.644400, acc.: 64.84%] [G loss: 0.808567]\n",
      "epoch:5 step:4343 [D loss: 0.655975, acc.: 62.50%] [G loss: 0.866681]\n",
      "epoch:5 step:4344 [D loss: 0.707391, acc.: 56.25%] [G loss: 0.847410]\n",
      "epoch:5 step:4345 [D loss: 0.641199, acc.: 66.41%] [G loss: 0.818712]\n",
      "epoch:5 step:4346 [D loss: 0.678364, acc.: 54.69%] [G loss: 0.799104]\n",
      "epoch:5 step:4347 [D loss: 0.665497, acc.: 57.81%] [G loss: 0.800815]\n",
      "epoch:5 step:4348 [D loss: 0.656849, acc.: 63.28%] [G loss: 0.876757]\n",
      "epoch:5 step:4349 [D loss: 0.700872, acc.: 53.12%] [G loss: 0.819723]\n",
      "epoch:5 step:4350 [D loss: 0.682142, acc.: 57.81%] [G loss: 0.827090]\n",
      "epoch:5 step:4351 [D loss: 0.738812, acc.: 42.97%] [G loss: 0.890698]\n",
      "epoch:5 step:4352 [D loss: 0.660643, acc.: 56.25%] [G loss: 0.873486]\n",
      "epoch:5 step:4353 [D loss: 0.647532, acc.: 66.41%] [G loss: 0.807627]\n",
      "epoch:5 step:4354 [D loss: 0.726959, acc.: 48.44%] [G loss: 0.851367]\n",
      "epoch:5 step:4355 [D loss: 0.647214, acc.: 64.06%] [G loss: 0.873429]\n",
      "epoch:5 step:4356 [D loss: 0.739060, acc.: 48.44%] [G loss: 0.804380]\n",
      "epoch:5 step:4357 [D loss: 0.707385, acc.: 53.12%] [G loss: 0.793165]\n",
      "epoch:5 step:4358 [D loss: 0.731254, acc.: 47.66%] [G loss: 0.781730]\n",
      "epoch:5 step:4359 [D loss: 0.735007, acc.: 48.44%] [G loss: 0.760359]\n",
      "epoch:5 step:4360 [D loss: 0.767524, acc.: 45.31%] [G loss: 0.737447]\n",
      "epoch:5 step:4361 [D loss: 0.701386, acc.: 50.00%] [G loss: 0.811870]\n",
      "epoch:5 step:4362 [D loss: 0.748147, acc.: 49.22%] [G loss: 0.633853]\n",
      "epoch:5 step:4363 [D loss: 0.733366, acc.: 47.66%] [G loss: 0.681845]\n",
      "epoch:5 step:4364 [D loss: 0.735829, acc.: 47.66%] [G loss: 0.744546]\n",
      "epoch:5 step:4365 [D loss: 0.711464, acc.: 51.56%] [G loss: 0.767321]\n",
      "epoch:5 step:4366 [D loss: 0.748466, acc.: 46.09%] [G loss: 0.727318]\n",
      "epoch:5 step:4367 [D loss: 0.709194, acc.: 49.22%] [G loss: 0.763251]\n",
      "epoch:5 step:4368 [D loss: 0.685745, acc.: 56.25%] [G loss: 0.737399]\n",
      "epoch:5 step:4369 [D loss: 0.683448, acc.: 59.38%] [G loss: 0.699202]\n",
      "epoch:5 step:4370 [D loss: 0.684001, acc.: 57.81%] [G loss: 0.708135]\n",
      "epoch:5 step:4371 [D loss: 0.677497, acc.: 53.91%] [G loss: 0.735352]\n",
      "epoch:5 step:4372 [D loss: 0.666496, acc.: 57.03%] [G loss: 0.733968]\n",
      "epoch:5 step:4373 [D loss: 0.693990, acc.: 56.25%] [G loss: 0.730220]\n",
      "epoch:5 step:4374 [D loss: 0.662142, acc.: 56.25%] [G loss: 0.807808]\n",
      "epoch:5 step:4375 [D loss: 0.625497, acc.: 67.97%] [G loss: 0.915600]\n",
      "epoch:5 step:4376 [D loss: 0.694948, acc.: 55.47%] [G loss: 0.783944]\n",
      "epoch:5 step:4377 [D loss: 0.749045, acc.: 48.44%] [G loss: 0.842140]\n",
      "epoch:5 step:4378 [D loss: 0.708129, acc.: 52.34%] [G loss: 0.776108]\n",
      "epoch:5 step:4379 [D loss: 0.591917, acc.: 73.44%] [G loss: 0.782724]\n",
      "epoch:5 step:4380 [D loss: 0.634215, acc.: 64.84%] [G loss: 0.894996]\n",
      "epoch:5 step:4381 [D loss: 0.639307, acc.: 65.62%] [G loss: 0.797064]\n",
      "epoch:5 step:4382 [D loss: 0.622629, acc.: 66.41%] [G loss: 1.015625]\n",
      "epoch:5 step:4383 [D loss: 0.591874, acc.: 72.66%] [G loss: 0.892827]\n",
      "epoch:5 step:4384 [D loss: 0.630954, acc.: 63.28%] [G loss: 0.866602]\n",
      "epoch:5 step:4385 [D loss: 0.745518, acc.: 50.00%] [G loss: 0.766956]\n",
      "epoch:5 step:4386 [D loss: 0.606914, acc.: 70.31%] [G loss: 0.870262]\n",
      "epoch:5 step:4387 [D loss: 0.664344, acc.: 60.94%] [G loss: 0.822255]\n",
      "epoch:5 step:4388 [D loss: 0.661963, acc.: 62.50%] [G loss: 0.776540]\n",
      "epoch:5 step:4389 [D loss: 0.636441, acc.: 63.28%] [G loss: 0.743063]\n",
      "epoch:5 step:4390 [D loss: 0.635189, acc.: 66.41%] [G loss: 0.718521]\n",
      "epoch:5 step:4391 [D loss: 0.658531, acc.: 57.81%] [G loss: 0.669248]\n",
      "epoch:5 step:4392 [D loss: 0.694040, acc.: 55.47%] [G loss: 0.660758]\n",
      "epoch:5 step:4393 [D loss: 0.707127, acc.: 50.78%] [G loss: 0.746479]\n",
      "epoch:5 step:4394 [D loss: 0.646977, acc.: 65.62%] [G loss: 0.690820]\n",
      "epoch:5 step:4395 [D loss: 0.591429, acc.: 68.75%] [G loss: 0.667923]\n",
      "epoch:5 step:4396 [D loss: 0.571833, acc.: 77.34%] [G loss: 0.719278]\n",
      "epoch:5 step:4397 [D loss: 0.807588, acc.: 37.50%] [G loss: 0.561552]\n",
      "epoch:5 step:4398 [D loss: 0.706716, acc.: 45.31%] [G loss: 0.755419]\n",
      "epoch:5 step:4399 [D loss: 0.833859, acc.: 29.69%] [G loss: 0.669452]\n",
      "epoch:5 step:4400 [D loss: 0.736198, acc.: 48.44%] [G loss: 0.740975]\n",
      "epoch:5 step:4401 [D loss: 0.705168, acc.: 49.22%] [G loss: 0.758941]\n",
      "epoch:5 step:4402 [D loss: 0.811565, acc.: 33.59%] [G loss: 0.778775]\n",
      "epoch:5 step:4403 [D loss: 0.757222, acc.: 45.31%] [G loss: 0.776925]\n",
      "epoch:5 step:4404 [D loss: 0.759377, acc.: 48.44%] [G loss: 0.836295]\n",
      "epoch:5 step:4405 [D loss: 0.769633, acc.: 44.53%] [G loss: 0.704437]\n",
      "epoch:5 step:4406 [D loss: 0.743001, acc.: 43.75%] [G loss: 0.760507]\n",
      "epoch:5 step:4407 [D loss: 0.752496, acc.: 40.62%] [G loss: 0.759285]\n",
      "epoch:5 step:4408 [D loss: 0.734754, acc.: 42.97%] [G loss: 0.901654]\n",
      "epoch:5 step:4409 [D loss: 0.705747, acc.: 50.00%] [G loss: 0.858908]\n",
      "epoch:5 step:4410 [D loss: 0.658701, acc.: 57.03%] [G loss: 0.836184]\n",
      "epoch:5 step:4411 [D loss: 0.699719, acc.: 51.56%] [G loss: 0.813384]\n",
      "epoch:5 step:4412 [D loss: 0.678862, acc.: 53.12%] [G loss: 0.813480]\n",
      "epoch:5 step:4413 [D loss: 0.660335, acc.: 61.72%] [G loss: 0.784588]\n",
      "epoch:5 step:4414 [D loss: 0.734085, acc.: 46.09%] [G loss: 0.927144]\n",
      "epoch:5 step:4415 [D loss: 0.733090, acc.: 46.88%] [G loss: 0.879870]\n",
      "epoch:5 step:4416 [D loss: 0.725876, acc.: 48.44%] [G loss: 0.881765]\n",
      "epoch:5 step:4417 [D loss: 0.681216, acc.: 61.72%] [G loss: 0.963051]\n",
      "epoch:5 step:4418 [D loss: 0.666452, acc.: 60.16%] [G loss: 0.964891]\n",
      "epoch:5 step:4419 [D loss: 0.624974, acc.: 66.41%] [G loss: 0.850107]\n",
      "epoch:5 step:4420 [D loss: 0.701498, acc.: 53.12%] [G loss: 0.842759]\n",
      "epoch:5 step:4421 [D loss: 0.669042, acc.: 60.94%] [G loss: 0.835911]\n",
      "epoch:5 step:4422 [D loss: 0.772335, acc.: 43.75%] [G loss: 0.734381]\n",
      "epoch:5 step:4423 [D loss: 0.676873, acc.: 53.91%] [G loss: 0.897971]\n",
      "epoch:5 step:4424 [D loss: 0.652901, acc.: 65.62%] [G loss: 0.763149]\n",
      "epoch:5 step:4425 [D loss: 0.710117, acc.: 53.91%] [G loss: 0.859111]\n",
      "epoch:5 step:4426 [D loss: 0.614120, acc.: 68.75%] [G loss: 0.903579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4427 [D loss: 0.686240, acc.: 56.25%] [G loss: 0.910415]\n",
      "epoch:5 step:4428 [D loss: 0.764999, acc.: 44.53%] [G loss: 0.824552]\n",
      "epoch:5 step:4429 [D loss: 0.735458, acc.: 50.00%] [G loss: 0.757654]\n",
      "epoch:5 step:4430 [D loss: 0.656497, acc.: 62.50%] [G loss: 0.822193]\n",
      "epoch:5 step:4431 [D loss: 0.844603, acc.: 35.94%] [G loss: 0.769846]\n",
      "epoch:5 step:4432 [D loss: 0.686099, acc.: 57.81%] [G loss: 0.740742]\n",
      "epoch:5 step:4433 [D loss: 0.785139, acc.: 36.72%] [G loss: 0.692954]\n",
      "epoch:5 step:4434 [D loss: 0.752856, acc.: 46.09%] [G loss: 0.779157]\n",
      "epoch:5 step:4435 [D loss: 0.696978, acc.: 49.22%] [G loss: 0.750645]\n",
      "epoch:5 step:4436 [D loss: 0.753197, acc.: 43.75%] [G loss: 0.797624]\n",
      "epoch:5 step:4437 [D loss: 0.738351, acc.: 46.09%] [G loss: 0.783549]\n",
      "epoch:5 step:4438 [D loss: 0.737112, acc.: 42.19%] [G loss: 0.722182]\n",
      "epoch:5 step:4439 [D loss: 0.755550, acc.: 42.19%] [G loss: 0.733400]\n",
      "epoch:5 step:4440 [D loss: 0.708267, acc.: 53.12%] [G loss: 0.822021]\n",
      "epoch:5 step:4441 [D loss: 0.770645, acc.: 41.41%] [G loss: 0.727535]\n",
      "epoch:5 step:4442 [D loss: 0.771286, acc.: 46.09%] [G loss: 0.795486]\n",
      "epoch:5 step:4443 [D loss: 0.689509, acc.: 57.81%] [G loss: 0.874554]\n",
      "epoch:5 step:4444 [D loss: 0.679853, acc.: 56.25%] [G loss: 0.878596]\n",
      "epoch:5 step:4445 [D loss: 0.771991, acc.: 43.75%] [G loss: 0.783800]\n",
      "epoch:5 step:4446 [D loss: 0.720003, acc.: 54.69%] [G loss: 0.742431]\n",
      "epoch:5 step:4447 [D loss: 0.719910, acc.: 44.53%] [G loss: 0.882142]\n",
      "epoch:5 step:4448 [D loss: 0.642253, acc.: 63.28%] [G loss: 0.972496]\n",
      "epoch:5 step:4449 [D loss: 0.691059, acc.: 56.25%] [G loss: 0.911467]\n",
      "epoch:5 step:4450 [D loss: 0.651419, acc.: 59.38%] [G loss: 0.981156]\n",
      "epoch:5 step:4451 [D loss: 0.701689, acc.: 56.25%] [G loss: 0.890594]\n",
      "epoch:5 step:4452 [D loss: 0.712389, acc.: 50.00%] [G loss: 0.881242]\n",
      "epoch:5 step:4453 [D loss: 0.676242, acc.: 61.72%] [G loss: 0.776868]\n",
      "epoch:5 step:4454 [D loss: 0.669854, acc.: 58.59%] [G loss: 0.866139]\n",
      "epoch:5 step:4455 [D loss: 0.645495, acc.: 67.19%] [G loss: 0.804330]\n",
      "epoch:5 step:4456 [D loss: 0.649958, acc.: 66.41%] [G loss: 0.952754]\n",
      "epoch:5 step:4457 [D loss: 0.715525, acc.: 53.12%] [G loss: 0.830131]\n",
      "epoch:5 step:4458 [D loss: 0.700686, acc.: 53.12%] [G loss: 0.849408]\n",
      "epoch:5 step:4459 [D loss: 0.612053, acc.: 71.09%] [G loss: 0.879068]\n",
      "epoch:5 step:4460 [D loss: 0.631368, acc.: 60.94%] [G loss: 0.888436]\n",
      "epoch:5 step:4461 [D loss: 0.703350, acc.: 54.69%] [G loss: 0.831005]\n",
      "epoch:5 step:4462 [D loss: 0.636611, acc.: 63.28%] [G loss: 0.809936]\n",
      "epoch:5 step:4463 [D loss: 0.637113, acc.: 65.62%] [G loss: 0.755778]\n",
      "epoch:5 step:4464 [D loss: 0.683919, acc.: 53.12%] [G loss: 0.700183]\n",
      "epoch:5 step:4465 [D loss: 0.664728, acc.: 59.38%] [G loss: 0.847100]\n",
      "epoch:5 step:4466 [D loss: 0.710830, acc.: 53.12%] [G loss: 0.710303]\n",
      "epoch:5 step:4467 [D loss: 0.760420, acc.: 43.75%] [G loss: 0.793782]\n",
      "epoch:5 step:4468 [D loss: 0.755363, acc.: 46.88%] [G loss: 0.780131]\n",
      "epoch:5 step:4469 [D loss: 0.731001, acc.: 50.00%] [G loss: 0.765705]\n",
      "epoch:5 step:4470 [D loss: 0.775636, acc.: 38.28%] [G loss: 0.787608]\n",
      "epoch:5 step:4471 [D loss: 0.682318, acc.: 55.47%] [G loss: 0.831188]\n",
      "epoch:5 step:4472 [D loss: 0.707575, acc.: 53.12%] [G loss: 0.767214]\n",
      "epoch:5 step:4473 [D loss: 0.680615, acc.: 57.03%] [G loss: 0.811242]\n",
      "epoch:5 step:4474 [D loss: 0.741019, acc.: 45.31%] [G loss: 0.852844]\n",
      "epoch:5 step:4475 [D loss: 0.771670, acc.: 45.31%] [G loss: 0.770891]\n",
      "epoch:5 step:4476 [D loss: 0.723772, acc.: 51.56%] [G loss: 0.792407]\n",
      "epoch:5 step:4477 [D loss: 0.659101, acc.: 60.94%] [G loss: 0.831252]\n",
      "epoch:5 step:4478 [D loss: 0.741901, acc.: 51.56%] [G loss: 0.781387]\n",
      "epoch:5 step:4479 [D loss: 0.805280, acc.: 30.47%] [G loss: 0.762109]\n",
      "epoch:5 step:4480 [D loss: 0.754472, acc.: 41.41%] [G loss: 0.822427]\n",
      "epoch:5 step:4481 [D loss: 0.705183, acc.: 55.47%] [G loss: 0.892995]\n",
      "epoch:5 step:4482 [D loss: 0.735807, acc.: 46.09%] [G loss: 0.797371]\n",
      "epoch:5 step:4483 [D loss: 0.696522, acc.: 55.47%] [G loss: 0.818934]\n",
      "epoch:5 step:4484 [D loss: 0.714408, acc.: 53.91%] [G loss: 0.858261]\n",
      "epoch:5 step:4485 [D loss: 0.758172, acc.: 46.88%] [G loss: 0.762588]\n",
      "epoch:5 step:4486 [D loss: 0.726516, acc.: 48.44%] [G loss: 0.822916]\n",
      "epoch:5 step:4487 [D loss: 0.688814, acc.: 60.16%] [G loss: 0.780655]\n",
      "epoch:5 step:4488 [D loss: 0.693387, acc.: 58.59%] [G loss: 0.819317]\n",
      "epoch:5 step:4489 [D loss: 0.693132, acc.: 55.47%] [G loss: 0.930825]\n",
      "epoch:5 step:4490 [D loss: 0.643470, acc.: 62.50%] [G loss: 0.876164]\n",
      "epoch:5 step:4491 [D loss: 0.654299, acc.: 62.50%] [G loss: 0.849936]\n",
      "epoch:5 step:4492 [D loss: 0.656216, acc.: 63.28%] [G loss: 0.780404]\n",
      "epoch:5 step:4493 [D loss: 0.635075, acc.: 66.41%] [G loss: 0.928736]\n",
      "epoch:5 step:4494 [D loss: 0.593771, acc.: 74.22%] [G loss: 0.874669]\n",
      "epoch:5 step:4495 [D loss: 0.614558, acc.: 70.31%] [G loss: 0.908908]\n",
      "epoch:5 step:4496 [D loss: 0.706930, acc.: 53.12%] [G loss: 0.850739]\n",
      "epoch:5 step:4497 [D loss: 0.700717, acc.: 53.91%] [G loss: 0.841887]\n",
      "epoch:5 step:4498 [D loss: 0.641163, acc.: 65.62%] [G loss: 0.802994]\n",
      "epoch:5 step:4499 [D loss: 0.678347, acc.: 55.47%] [G loss: 0.870623]\n",
      "epoch:5 step:4500 [D loss: 0.647635, acc.: 61.72%] [G loss: 0.857262]\n",
      "epoch:5 step:4501 [D loss: 0.730070, acc.: 50.00%] [G loss: 0.865674]\n",
      "epoch:5 step:4502 [D loss: 0.623675, acc.: 67.19%] [G loss: 0.779826]\n",
      "epoch:5 step:4503 [D loss: 0.685904, acc.: 55.47%] [G loss: 0.776773]\n",
      "epoch:5 step:4504 [D loss: 0.643730, acc.: 66.41%] [G loss: 0.834557]\n",
      "epoch:5 step:4505 [D loss: 0.668131, acc.: 63.28%] [G loss: 0.776113]\n",
      "epoch:5 step:4506 [D loss: 0.720307, acc.: 47.66%] [G loss: 0.812426]\n",
      "epoch:5 step:4507 [D loss: 0.693605, acc.: 50.00%] [G loss: 0.750951]\n",
      "epoch:5 step:4508 [D loss: 0.660458, acc.: 60.94%] [G loss: 0.841516]\n",
      "epoch:5 step:4509 [D loss: 0.681343, acc.: 53.91%] [G loss: 0.726593]\n",
      "epoch:5 step:4510 [D loss: 0.634667, acc.: 64.06%] [G loss: 0.820369]\n",
      "epoch:5 step:4511 [D loss: 0.663924, acc.: 63.28%] [G loss: 0.831732]\n",
      "epoch:5 step:4512 [D loss: 0.739413, acc.: 44.53%] [G loss: 0.773286]\n",
      "epoch:5 step:4513 [D loss: 0.629642, acc.: 63.28%] [G loss: 0.876116]\n",
      "epoch:5 step:4514 [D loss: 0.679218, acc.: 55.47%] [G loss: 0.818808]\n",
      "epoch:5 step:4515 [D loss: 0.657694, acc.: 60.94%] [G loss: 0.843952]\n",
      "epoch:5 step:4516 [D loss: 0.725429, acc.: 49.22%] [G loss: 0.901790]\n",
      "epoch:5 step:4517 [D loss: 0.740865, acc.: 46.88%] [G loss: 0.770508]\n",
      "epoch:5 step:4518 [D loss: 0.799392, acc.: 38.28%] [G loss: 0.721280]\n",
      "epoch:5 step:4519 [D loss: 0.722141, acc.: 52.34%] [G loss: 0.811548]\n",
      "epoch:5 step:4520 [D loss: 0.696830, acc.: 53.91%] [G loss: 0.771044]\n",
      "epoch:5 step:4521 [D loss: 0.700789, acc.: 53.12%] [G loss: 0.835438]\n",
      "epoch:5 step:4522 [D loss: 0.709289, acc.: 53.12%] [G loss: 0.783684]\n",
      "epoch:5 step:4523 [D loss: 0.750692, acc.: 45.31%] [G loss: 0.755105]\n",
      "epoch:5 step:4524 [D loss: 0.699298, acc.: 52.34%] [G loss: 0.830708]\n",
      "epoch:5 step:4525 [D loss: 0.618898, acc.: 69.53%] [G loss: 0.816067]\n",
      "epoch:5 step:4526 [D loss: 0.697026, acc.: 56.25%] [G loss: 0.845805]\n",
      "epoch:5 step:4527 [D loss: 0.681328, acc.: 61.72%] [G loss: 0.741011]\n",
      "epoch:5 step:4528 [D loss: 0.626729, acc.: 71.09%] [G loss: 0.924273]\n",
      "epoch:5 step:4529 [D loss: 0.721164, acc.: 52.34%] [G loss: 0.787788]\n",
      "epoch:5 step:4530 [D loss: 0.672289, acc.: 58.59%] [G loss: 0.830234]\n",
      "epoch:5 step:4531 [D loss: 0.716737, acc.: 47.66%] [G loss: 0.775282]\n",
      "epoch:5 step:4532 [D loss: 0.697955, acc.: 51.56%] [G loss: 0.823595]\n",
      "epoch:5 step:4533 [D loss: 0.667217, acc.: 57.03%] [G loss: 0.849459]\n",
      "epoch:5 step:4534 [D loss: 0.735323, acc.: 49.22%] [G loss: 0.820374]\n",
      "epoch:5 step:4535 [D loss: 0.667020, acc.: 60.16%] [G loss: 0.945524]\n",
      "epoch:5 step:4536 [D loss: 0.671806, acc.: 60.94%] [G loss: 0.762290]\n",
      "epoch:5 step:4537 [D loss: 0.731639, acc.: 50.78%] [G loss: 0.801331]\n",
      "epoch:5 step:4538 [D loss: 0.698961, acc.: 52.34%] [G loss: 0.832512]\n",
      "epoch:5 step:4539 [D loss: 0.663804, acc.: 57.03%] [G loss: 0.829742]\n",
      "epoch:5 step:4540 [D loss: 0.679364, acc.: 55.47%] [G loss: 0.761704]\n",
      "epoch:5 step:4541 [D loss: 0.665969, acc.: 62.50%] [G loss: 0.862983]\n",
      "epoch:5 step:4542 [D loss: 0.672596, acc.: 54.69%] [G loss: 0.898313]\n",
      "epoch:5 step:4543 [D loss: 0.747025, acc.: 49.22%] [G loss: 0.798109]\n",
      "epoch:5 step:4544 [D loss: 0.702318, acc.: 54.69%] [G loss: 0.739073]\n",
      "epoch:5 step:4545 [D loss: 0.682250, acc.: 56.25%] [G loss: 0.804839]\n",
      "epoch:5 step:4546 [D loss: 0.700085, acc.: 51.56%] [G loss: 0.737904]\n",
      "epoch:5 step:4547 [D loss: 0.694596, acc.: 46.09%] [G loss: 0.691138]\n",
      "epoch:5 step:4548 [D loss: 0.692611, acc.: 55.47%] [G loss: 0.739619]\n",
      "epoch:5 step:4549 [D loss: 0.710915, acc.: 46.09%] [G loss: 0.741262]\n",
      "epoch:5 step:4550 [D loss: 0.799019, acc.: 40.62%] [G loss: 0.765823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4551 [D loss: 0.730186, acc.: 46.88%] [G loss: 0.754885]\n",
      "epoch:5 step:4552 [D loss: 0.775531, acc.: 44.53%] [G loss: 0.763039]\n",
      "epoch:5 step:4553 [D loss: 0.763145, acc.: 42.19%] [G loss: 0.673972]\n",
      "epoch:5 step:4554 [D loss: 0.744924, acc.: 46.09%] [G loss: 0.793074]\n",
      "epoch:5 step:4555 [D loss: 0.665882, acc.: 54.69%] [G loss: 0.804749]\n",
      "epoch:5 step:4556 [D loss: 0.754491, acc.: 47.66%] [G loss: 0.797086]\n",
      "epoch:5 step:4557 [D loss: 0.677574, acc.: 60.16%] [G loss: 0.856609]\n",
      "epoch:5 step:4558 [D loss: 0.729587, acc.: 45.31%] [G loss: 0.812866]\n",
      "epoch:5 step:4559 [D loss: 0.699192, acc.: 57.03%] [G loss: 0.850553]\n",
      "epoch:5 step:4560 [D loss: 0.666091, acc.: 53.12%] [G loss: 0.851645]\n",
      "epoch:5 step:4561 [D loss: 0.682252, acc.: 52.34%] [G loss: 0.814301]\n",
      "epoch:5 step:4562 [D loss: 0.782333, acc.: 39.84%] [G loss: 0.801895]\n",
      "epoch:5 step:4563 [D loss: 0.672237, acc.: 60.94%] [G loss: 0.813031]\n",
      "epoch:5 step:4564 [D loss: 0.699028, acc.: 53.91%] [G loss: 0.818505]\n",
      "epoch:5 step:4565 [D loss: 0.731220, acc.: 49.22%] [G loss: 0.848960]\n",
      "epoch:5 step:4566 [D loss: 0.653454, acc.: 60.16%] [G loss: 0.956040]\n",
      "epoch:5 step:4567 [D loss: 0.658838, acc.: 63.28%] [G loss: 0.937240]\n",
      "epoch:5 step:4568 [D loss: 0.671810, acc.: 54.69%] [G loss: 0.906832]\n",
      "epoch:5 step:4569 [D loss: 0.627271, acc.: 62.50%] [G loss: 0.896172]\n",
      "epoch:5 step:4570 [D loss: 0.680397, acc.: 60.94%] [G loss: 0.810158]\n",
      "epoch:5 step:4571 [D loss: 0.661765, acc.: 58.59%] [G loss: 0.900841]\n",
      "epoch:5 step:4572 [D loss: 0.630775, acc.: 67.19%] [G loss: 0.863501]\n",
      "epoch:5 step:4573 [D loss: 0.643989, acc.: 64.84%] [G loss: 0.870855]\n",
      "epoch:5 step:4574 [D loss: 0.637101, acc.: 65.62%] [G loss: 0.864234]\n",
      "epoch:5 step:4575 [D loss: 0.626999, acc.: 66.41%] [G loss: 0.935865]\n",
      "epoch:5 step:4576 [D loss: 0.634541, acc.: 66.41%] [G loss: 0.874992]\n",
      "epoch:5 step:4577 [D loss: 0.654031, acc.: 60.94%] [G loss: 0.834903]\n",
      "epoch:5 step:4578 [D loss: 0.657952, acc.: 62.50%] [G loss: 0.915670]\n",
      "epoch:5 step:4579 [D loss: 0.646410, acc.: 59.38%] [G loss: 0.846294]\n",
      "epoch:5 step:4580 [D loss: 0.728925, acc.: 54.69%] [G loss: 0.902323]\n",
      "epoch:5 step:4581 [D loss: 0.734307, acc.: 47.66%] [G loss: 0.879931]\n",
      "epoch:5 step:4582 [D loss: 0.669728, acc.: 58.59%] [G loss: 0.872246]\n",
      "epoch:5 step:4583 [D loss: 0.703774, acc.: 44.53%] [G loss: 0.973692]\n",
      "epoch:5 step:4584 [D loss: 0.679226, acc.: 62.50%] [G loss: 0.907431]\n",
      "epoch:5 step:4585 [D loss: 0.668302, acc.: 63.28%] [G loss: 0.975032]\n",
      "epoch:5 step:4586 [D loss: 0.717568, acc.: 52.34%] [G loss: 0.791374]\n",
      "epoch:5 step:4587 [D loss: 0.755601, acc.: 46.09%] [G loss: 0.724568]\n",
      "epoch:5 step:4588 [D loss: 0.685371, acc.: 55.47%] [G loss: 0.762782]\n",
      "epoch:5 step:4589 [D loss: 0.644324, acc.: 64.06%] [G loss: 0.796092]\n",
      "epoch:5 step:4590 [D loss: 0.681032, acc.: 60.94%] [G loss: 0.798069]\n",
      "epoch:5 step:4591 [D loss: 0.705199, acc.: 55.47%] [G loss: 0.801724]\n",
      "epoch:5 step:4592 [D loss: 0.716626, acc.: 53.91%] [G loss: 0.703242]\n",
      "epoch:5 step:4593 [D loss: 0.773781, acc.: 39.06%] [G loss: 0.755451]\n",
      "epoch:5 step:4594 [D loss: 0.732969, acc.: 49.22%] [G loss: 0.818610]\n",
      "epoch:5 step:4595 [D loss: 0.724982, acc.: 47.66%] [G loss: 0.766040]\n",
      "epoch:5 step:4596 [D loss: 0.689483, acc.: 54.69%] [G loss: 0.832014]\n",
      "epoch:5 step:4597 [D loss: 0.774397, acc.: 46.09%] [G loss: 0.659061]\n",
      "epoch:5 step:4598 [D loss: 0.662102, acc.: 63.28%] [G loss: 0.820049]\n",
      "epoch:5 step:4599 [D loss: 0.703933, acc.: 53.12%] [G loss: 0.822327]\n",
      "epoch:5 step:4600 [D loss: 0.638305, acc.: 65.62%] [G loss: 0.846115]\n",
      "epoch:5 step:4601 [D loss: 0.676103, acc.: 57.03%] [G loss: 0.805491]\n",
      "epoch:5 step:4602 [D loss: 0.794871, acc.: 37.50%] [G loss: 0.763123]\n",
      "epoch:5 step:4603 [D loss: 0.634562, acc.: 66.41%] [G loss: 0.794763]\n",
      "epoch:5 step:4604 [D loss: 0.686241, acc.: 57.81%] [G loss: 0.767784]\n",
      "epoch:5 step:4605 [D loss: 0.648818, acc.: 61.72%] [G loss: 0.856522]\n",
      "epoch:5 step:4606 [D loss: 0.699082, acc.: 53.91%] [G loss: 0.862496]\n",
      "epoch:5 step:4607 [D loss: 0.660212, acc.: 61.72%] [G loss: 0.783166]\n",
      "epoch:5 step:4608 [D loss: 0.589428, acc.: 75.78%] [G loss: 0.816150]\n",
      "epoch:5 step:4609 [D loss: 0.638749, acc.: 64.84%] [G loss: 0.772035]\n",
      "epoch:5 step:4610 [D loss: 0.609277, acc.: 71.09%] [G loss: 0.839930]\n",
      "epoch:5 step:4611 [D loss: 0.666747, acc.: 60.16%] [G loss: 0.694886]\n",
      "epoch:5 step:4612 [D loss: 0.662679, acc.: 58.59%] [G loss: 0.774652]\n",
      "epoch:5 step:4613 [D loss: 0.774350, acc.: 42.19%] [G loss: 0.717069]\n",
      "epoch:5 step:4614 [D loss: 0.793559, acc.: 46.88%] [G loss: 0.768474]\n",
      "epoch:5 step:4615 [D loss: 0.696980, acc.: 52.34%] [G loss: 0.761682]\n",
      "epoch:5 step:4616 [D loss: 0.667429, acc.: 59.38%] [G loss: 0.766474]\n",
      "epoch:5 step:4617 [D loss: 0.724324, acc.: 47.66%] [G loss: 0.762954]\n",
      "epoch:5 step:4618 [D loss: 0.756535, acc.: 42.97%] [G loss: 0.867630]\n",
      "epoch:5 step:4619 [D loss: 0.759196, acc.: 42.97%] [G loss: 0.877149]\n",
      "epoch:5 step:4620 [D loss: 0.756934, acc.: 43.75%] [G loss: 0.787813]\n",
      "epoch:5 step:4621 [D loss: 0.707358, acc.: 57.03%] [G loss: 0.855154]\n",
      "epoch:5 step:4622 [D loss: 0.719028, acc.: 52.34%] [G loss: 0.824826]\n",
      "epoch:5 step:4623 [D loss: 0.734128, acc.: 47.66%] [G loss: 0.810990]\n",
      "epoch:5 step:4624 [D loss: 0.681553, acc.: 54.69%] [G loss: 0.785814]\n",
      "epoch:5 step:4625 [D loss: 0.825196, acc.: 41.41%] [G loss: 0.687859]\n",
      "epoch:5 step:4626 [D loss: 0.722440, acc.: 50.78%] [G loss: 0.708042]\n",
      "epoch:5 step:4627 [D loss: 0.711957, acc.: 53.91%] [G loss: 0.808773]\n",
      "epoch:5 step:4628 [D loss: 0.789890, acc.: 36.72%] [G loss: 0.823658]\n",
      "epoch:5 step:4629 [D loss: 0.690627, acc.: 56.25%] [G loss: 0.808972]\n",
      "epoch:5 step:4630 [D loss: 0.716334, acc.: 52.34%] [G loss: 0.783432]\n",
      "epoch:5 step:4631 [D loss: 0.640540, acc.: 60.94%] [G loss: 0.854469]\n",
      "epoch:5 step:4632 [D loss: 0.679139, acc.: 52.34%] [G loss: 0.946973]\n",
      "epoch:5 step:4633 [D loss: 0.709219, acc.: 52.34%] [G loss: 0.820967]\n",
      "epoch:5 step:4634 [D loss: 0.674146, acc.: 53.12%] [G loss: 0.965264]\n",
      "epoch:5 step:4635 [D loss: 0.662823, acc.: 63.28%] [G loss: 0.937796]\n",
      "epoch:5 step:4636 [D loss: 0.615405, acc.: 68.75%] [G loss: 0.934559]\n",
      "epoch:5 step:4637 [D loss: 0.635849, acc.: 67.19%] [G loss: 0.933357]\n",
      "epoch:5 step:4638 [D loss: 0.633208, acc.: 71.88%] [G loss: 0.892349]\n",
      "epoch:5 step:4639 [D loss: 0.693692, acc.: 56.25%] [G loss: 0.828107]\n",
      "epoch:5 step:4640 [D loss: 0.658577, acc.: 66.41%] [G loss: 0.899357]\n",
      "epoch:5 step:4641 [D loss: 0.661383, acc.: 57.81%] [G loss: 0.787268]\n",
      "epoch:5 step:4642 [D loss: 0.637400, acc.: 60.94%] [G loss: 0.815260]\n",
      "epoch:5 step:4643 [D loss: 0.620570, acc.: 68.75%] [G loss: 0.886693]\n",
      "epoch:5 step:4644 [D loss: 0.636156, acc.: 66.41%] [G loss: 0.880093]\n",
      "epoch:5 step:4645 [D loss: 0.663365, acc.: 61.72%] [G loss: 0.796675]\n",
      "epoch:5 step:4646 [D loss: 0.670293, acc.: 53.91%] [G loss: 0.823535]\n",
      "epoch:5 step:4647 [D loss: 0.701433, acc.: 54.69%] [G loss: 0.739829]\n",
      "epoch:5 step:4648 [D loss: 0.666437, acc.: 61.72%] [G loss: 0.763197]\n",
      "epoch:5 step:4649 [D loss: 0.734655, acc.: 50.78%] [G loss: 0.768873]\n",
      "epoch:5 step:4650 [D loss: 0.748494, acc.: 42.97%] [G loss: 0.730079]\n",
      "epoch:5 step:4651 [D loss: 0.678451, acc.: 56.25%] [G loss: 0.763635]\n",
      "epoch:5 step:4652 [D loss: 0.676389, acc.: 60.16%] [G loss: 0.844428]\n",
      "epoch:5 step:4653 [D loss: 0.721420, acc.: 50.78%] [G loss: 0.811805]\n",
      "epoch:5 step:4654 [D loss: 0.688517, acc.: 55.47%] [G loss: 0.785033]\n",
      "epoch:5 step:4655 [D loss: 0.745939, acc.: 48.44%] [G loss: 0.800845]\n",
      "epoch:5 step:4656 [D loss: 0.730976, acc.: 45.31%] [G loss: 0.764521]\n",
      "epoch:5 step:4657 [D loss: 0.769130, acc.: 42.19%] [G loss: 0.746777]\n",
      "epoch:5 step:4658 [D loss: 0.758686, acc.: 45.31%] [G loss: 0.759171]\n",
      "epoch:5 step:4659 [D loss: 0.736500, acc.: 45.31%] [G loss: 0.856426]\n",
      "epoch:5 step:4660 [D loss: 0.699987, acc.: 53.91%] [G loss: 0.927652]\n",
      "epoch:5 step:4661 [D loss: 0.796144, acc.: 36.72%] [G loss: 0.712928]\n",
      "epoch:5 step:4662 [D loss: 0.668454, acc.: 57.81%] [G loss: 0.811986]\n",
      "epoch:5 step:4663 [D loss: 0.734805, acc.: 46.09%] [G loss: 0.897204]\n",
      "epoch:5 step:4664 [D loss: 0.720263, acc.: 50.78%] [G loss: 0.895708]\n",
      "epoch:5 step:4665 [D loss: 0.650737, acc.: 62.50%] [G loss: 0.857282]\n",
      "epoch:5 step:4666 [D loss: 0.692729, acc.: 51.56%] [G loss: 0.834300]\n",
      "epoch:5 step:4667 [D loss: 0.690875, acc.: 53.12%] [G loss: 1.008045]\n",
      "epoch:5 step:4668 [D loss: 0.688983, acc.: 51.56%] [G loss: 0.860320]\n",
      "epoch:5 step:4669 [D loss: 0.702141, acc.: 50.00%] [G loss: 0.919438]\n",
      "epoch:5 step:4670 [D loss: 0.651948, acc.: 59.38%] [G loss: 0.980933]\n",
      "epoch:5 step:4671 [D loss: 0.629874, acc.: 67.97%] [G loss: 1.079351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4672 [D loss: 0.654738, acc.: 55.47%] [G loss: 1.099740]\n",
      "epoch:5 step:4673 [D loss: 0.649176, acc.: 65.62%] [G loss: 0.849546]\n",
      "epoch:5 step:4674 [D loss: 0.607232, acc.: 69.53%] [G loss: 0.919162]\n",
      "epoch:5 step:4675 [D loss: 0.626952, acc.: 67.97%] [G loss: 0.855621]\n",
      "epoch:5 step:4676 [D loss: 0.628721, acc.: 65.62%] [G loss: 0.923699]\n",
      "epoch:5 step:4677 [D loss: 0.614047, acc.: 65.62%] [G loss: 0.769391]\n",
      "epoch:5 step:4678 [D loss: 0.693627, acc.: 52.34%] [G loss: 0.708292]\n",
      "epoch:5 step:4679 [D loss: 0.623256, acc.: 66.41%] [G loss: 0.705403]\n",
      "epoch:5 step:4680 [D loss: 0.699136, acc.: 53.91%] [G loss: 0.782310]\n",
      "epoch:5 step:4681 [D loss: 0.592656, acc.: 73.44%] [G loss: 0.726907]\n",
      "epoch:5 step:4682 [D loss: 0.716788, acc.: 53.12%] [G loss: 0.759148]\n",
      "epoch:5 step:4683 [D loss: 0.688476, acc.: 55.47%] [G loss: 0.697605]\n",
      "epoch:5 step:4684 [D loss: 0.772268, acc.: 47.66%] [G loss: 0.802030]\n",
      "epoch:5 step:4685 [D loss: 0.789829, acc.: 42.97%] [G loss: 0.706194]\n",
      "epoch:5 step:4686 [D loss: 0.668324, acc.: 57.81%] [G loss: 0.795665]\n",
      "epoch:6 step:4687 [D loss: 0.729778, acc.: 51.56%] [G loss: 0.771269]\n",
      "epoch:6 step:4688 [D loss: 0.715926, acc.: 48.44%] [G loss: 0.785568]\n",
      "epoch:6 step:4689 [D loss: 0.746900, acc.: 46.09%] [G loss: 0.726470]\n",
      "epoch:6 step:4690 [D loss: 0.755652, acc.: 46.09%] [G loss: 0.715337]\n",
      "epoch:6 step:4691 [D loss: 0.734107, acc.: 48.44%] [G loss: 0.772338]\n",
      "epoch:6 step:4692 [D loss: 0.685382, acc.: 57.81%] [G loss: 0.779347]\n",
      "epoch:6 step:4693 [D loss: 0.735074, acc.: 48.44%] [G loss: 0.863463]\n",
      "epoch:6 step:4694 [D loss: 0.694144, acc.: 53.91%] [G loss: 0.987375]\n",
      "epoch:6 step:4695 [D loss: 0.681430, acc.: 57.03%] [G loss: 0.880599]\n",
      "epoch:6 step:4696 [D loss: 0.676241, acc.: 59.38%] [G loss: 0.921102]\n",
      "epoch:6 step:4697 [D loss: 0.696494, acc.: 56.25%] [G loss: 0.942752]\n",
      "epoch:6 step:4698 [D loss: 0.720317, acc.: 47.66%] [G loss: 0.875682]\n",
      "epoch:6 step:4699 [D loss: 0.663509, acc.: 59.38%] [G loss: 0.896236]\n",
      "epoch:6 step:4700 [D loss: 0.676548, acc.: 60.16%] [G loss: 0.896239]\n",
      "epoch:6 step:4701 [D loss: 0.740852, acc.: 46.09%] [G loss: 0.897648]\n",
      "epoch:6 step:4702 [D loss: 0.721213, acc.: 49.22%] [G loss: 0.878380]\n",
      "epoch:6 step:4703 [D loss: 0.687516, acc.: 60.16%] [G loss: 0.862211]\n",
      "epoch:6 step:4704 [D loss: 0.702045, acc.: 56.25%] [G loss: 0.863069]\n",
      "epoch:6 step:4705 [D loss: 0.661773, acc.: 61.72%] [G loss: 0.797757]\n",
      "epoch:6 step:4706 [D loss: 0.692009, acc.: 57.03%] [G loss: 0.834767]\n",
      "epoch:6 step:4707 [D loss: 0.669835, acc.: 58.59%] [G loss: 0.673379]\n",
      "epoch:6 step:4708 [D loss: 0.663261, acc.: 63.28%] [G loss: 0.854748]\n",
      "epoch:6 step:4709 [D loss: 0.749721, acc.: 45.31%] [G loss: 0.809271]\n",
      "epoch:6 step:4710 [D loss: 0.673444, acc.: 58.59%] [G loss: 0.869908]\n",
      "epoch:6 step:4711 [D loss: 0.639102, acc.: 59.38%] [G loss: 0.745814]\n",
      "epoch:6 step:4712 [D loss: 0.738431, acc.: 46.09%] [G loss: 0.750122]\n",
      "epoch:6 step:4713 [D loss: 0.672967, acc.: 60.16%] [G loss: 0.735060]\n",
      "epoch:6 step:4714 [D loss: 0.752717, acc.: 44.53%] [G loss: 0.819496]\n",
      "epoch:6 step:4715 [D loss: 0.685128, acc.: 59.38%] [G loss: 0.857368]\n",
      "epoch:6 step:4716 [D loss: 0.651775, acc.: 60.16%] [G loss: 0.907883]\n",
      "epoch:6 step:4717 [D loss: 0.720934, acc.: 48.44%] [G loss: 0.783524]\n",
      "epoch:6 step:4718 [D loss: 0.705322, acc.: 52.34%] [G loss: 0.821948]\n",
      "epoch:6 step:4719 [D loss: 0.740271, acc.: 50.78%] [G loss: 0.905066]\n",
      "epoch:6 step:4720 [D loss: 0.806404, acc.: 36.72%] [G loss: 0.762738]\n",
      "epoch:6 step:4721 [D loss: 0.741010, acc.: 44.53%] [G loss: 0.805786]\n",
      "epoch:6 step:4722 [D loss: 0.720596, acc.: 38.28%] [G loss: 0.758986]\n",
      "epoch:6 step:4723 [D loss: 0.758314, acc.: 42.19%] [G loss: 0.760749]\n",
      "epoch:6 step:4724 [D loss: 0.719700, acc.: 50.78%] [G loss: 0.744350]\n",
      "epoch:6 step:4725 [D loss: 0.705141, acc.: 46.88%] [G loss: 0.853987]\n",
      "epoch:6 step:4726 [D loss: 0.789151, acc.: 42.97%] [G loss: 0.765641]\n",
      "epoch:6 step:4727 [D loss: 0.707425, acc.: 56.25%] [G loss: 0.857469]\n",
      "epoch:6 step:4728 [D loss: 0.731475, acc.: 42.19%] [G loss: 0.816811]\n",
      "epoch:6 step:4729 [D loss: 0.652939, acc.: 62.50%] [G loss: 0.897974]\n",
      "epoch:6 step:4730 [D loss: 0.653486, acc.: 61.72%] [G loss: 0.860248]\n",
      "epoch:6 step:4731 [D loss: 0.657454, acc.: 59.38%] [G loss: 0.848739]\n",
      "epoch:6 step:4732 [D loss: 0.619117, acc.: 65.62%] [G loss: 0.770538]\n",
      "epoch:6 step:4733 [D loss: 0.657164, acc.: 60.94%] [G loss: 0.968506]\n",
      "epoch:6 step:4734 [D loss: 0.649440, acc.: 63.28%] [G loss: 0.962467]\n",
      "epoch:6 step:4735 [D loss: 0.716607, acc.: 50.78%] [G loss: 0.800717]\n",
      "epoch:6 step:4736 [D loss: 0.699229, acc.: 53.91%] [G loss: 0.806971]\n",
      "epoch:6 step:4737 [D loss: 0.674871, acc.: 54.69%] [G loss: 0.747960]\n",
      "epoch:6 step:4738 [D loss: 0.614918, acc.: 66.41%] [G loss: 0.752556]\n",
      "epoch:6 step:4739 [D loss: 0.731279, acc.: 44.53%] [G loss: 0.826162]\n",
      "epoch:6 step:4740 [D loss: 0.662018, acc.: 59.38%] [G loss: 0.813729]\n",
      "epoch:6 step:4741 [D loss: 0.752254, acc.: 46.09%] [G loss: 0.742837]\n",
      "epoch:6 step:4742 [D loss: 0.572179, acc.: 75.00%] [G loss: 0.809861]\n",
      "epoch:6 step:4743 [D loss: 0.705359, acc.: 53.91%] [G loss: 0.739256]\n",
      "epoch:6 step:4744 [D loss: 0.658727, acc.: 57.81%] [G loss: 0.885857]\n",
      "epoch:6 step:4745 [D loss: 0.663938, acc.: 62.50%] [G loss: 0.762996]\n",
      "epoch:6 step:4746 [D loss: 0.640869, acc.: 67.97%] [G loss: 0.775101]\n",
      "epoch:6 step:4747 [D loss: 0.724909, acc.: 49.22%] [G loss: 0.751682]\n",
      "epoch:6 step:4748 [D loss: 0.755175, acc.: 43.75%] [G loss: 0.805792]\n",
      "epoch:6 step:4749 [D loss: 0.762971, acc.: 43.75%] [G loss: 0.853568]\n",
      "epoch:6 step:4750 [D loss: 0.700181, acc.: 52.34%] [G loss: 0.820191]\n",
      "epoch:6 step:4751 [D loss: 0.683698, acc.: 53.12%] [G loss: 0.815871]\n",
      "epoch:6 step:4752 [D loss: 0.706652, acc.: 54.69%] [G loss: 0.836533]\n",
      "epoch:6 step:4753 [D loss: 0.753593, acc.: 47.66%] [G loss: 0.844620]\n",
      "epoch:6 step:4754 [D loss: 0.742652, acc.: 46.09%] [G loss: 0.818115]\n",
      "epoch:6 step:4755 [D loss: 0.712559, acc.: 54.69%] [G loss: 0.837278]\n",
      "epoch:6 step:4756 [D loss: 0.750598, acc.: 40.62%] [G loss: 0.823989]\n",
      "epoch:6 step:4757 [D loss: 0.682448, acc.: 60.94%] [G loss: 0.784694]\n",
      "epoch:6 step:4758 [D loss: 0.662088, acc.: 59.38%] [G loss: 0.766512]\n",
      "epoch:6 step:4759 [D loss: 0.621718, acc.: 69.53%] [G loss: 0.886027]\n",
      "epoch:6 step:4760 [D loss: 0.638440, acc.: 69.53%] [G loss: 0.805805]\n",
      "epoch:6 step:4761 [D loss: 0.607430, acc.: 71.09%] [G loss: 0.957860]\n",
      "epoch:6 step:4762 [D loss: 0.706635, acc.: 57.03%] [G loss: 0.772865]\n",
      "epoch:6 step:4763 [D loss: 0.650748, acc.: 62.50%] [G loss: 0.765679]\n",
      "epoch:6 step:4764 [D loss: 0.660972, acc.: 58.59%] [G loss: 0.707269]\n",
      "epoch:6 step:4765 [D loss: 0.700361, acc.: 53.12%] [G loss: 0.786098]\n",
      "epoch:6 step:4766 [D loss: 0.704445, acc.: 50.00%] [G loss: 0.714650]\n",
      "epoch:6 step:4767 [D loss: 0.674684, acc.: 60.16%] [G loss: 0.833905]\n",
      "epoch:6 step:4768 [D loss: 0.677344, acc.: 57.03%] [G loss: 0.776548]\n",
      "epoch:6 step:4769 [D loss: 0.703661, acc.: 55.47%] [G loss: 0.876485]\n",
      "epoch:6 step:4770 [D loss: 0.630998, acc.: 63.28%] [G loss: 0.736367]\n",
      "epoch:6 step:4771 [D loss: 0.740984, acc.: 45.31%] [G loss: 0.731093]\n",
      "epoch:6 step:4772 [D loss: 0.693320, acc.: 51.56%] [G loss: 0.772440]\n",
      "epoch:6 step:4773 [D loss: 0.704478, acc.: 50.00%] [G loss: 0.837551]\n",
      "epoch:6 step:4774 [D loss: 0.636955, acc.: 63.28%] [G loss: 0.947843]\n",
      "epoch:6 step:4775 [D loss: 0.664145, acc.: 61.72%] [G loss: 0.861376]\n",
      "epoch:6 step:4776 [D loss: 0.769674, acc.: 41.41%] [G loss: 0.918775]\n",
      "epoch:6 step:4777 [D loss: 0.674459, acc.: 61.72%] [G loss: 0.827657]\n",
      "epoch:6 step:4778 [D loss: 0.683930, acc.: 52.34%] [G loss: 0.964663]\n",
      "epoch:6 step:4779 [D loss: 0.677681, acc.: 58.59%] [G loss: 0.899120]\n",
      "epoch:6 step:4780 [D loss: 0.704944, acc.: 53.91%] [G loss: 0.835695]\n",
      "epoch:6 step:4781 [D loss: 0.657390, acc.: 60.94%] [G loss: 0.848130]\n",
      "epoch:6 step:4782 [D loss: 0.694945, acc.: 50.78%] [G loss: 0.801291]\n",
      "epoch:6 step:4783 [D loss: 0.733244, acc.: 54.69%] [G loss: 0.803710]\n",
      "epoch:6 step:4784 [D loss: 0.701355, acc.: 53.91%] [G loss: 0.955139]\n",
      "epoch:6 step:4785 [D loss: 0.722849, acc.: 47.66%] [G loss: 0.865090]\n",
      "epoch:6 step:4786 [D loss: 0.703546, acc.: 48.44%] [G loss: 0.913664]\n",
      "epoch:6 step:4787 [D loss: 0.715836, acc.: 52.34%] [G loss: 0.817940]\n",
      "epoch:6 step:4788 [D loss: 0.714746, acc.: 51.56%] [G loss: 0.810508]\n",
      "epoch:6 step:4789 [D loss: 0.712697, acc.: 54.69%] [G loss: 0.707284]\n",
      "epoch:6 step:4790 [D loss: 0.770510, acc.: 39.06%] [G loss: 0.825560]\n",
      "epoch:6 step:4791 [D loss: 0.703901, acc.: 50.78%] [G loss: 0.903792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4792 [D loss: 0.645778, acc.: 57.03%] [G loss: 0.896744]\n",
      "epoch:6 step:4793 [D loss: 0.663027, acc.: 62.50%] [G loss: 0.898160]\n",
      "epoch:6 step:4794 [D loss: 0.789582, acc.: 45.31%] [G loss: 0.802535]\n",
      "epoch:6 step:4795 [D loss: 0.783575, acc.: 39.06%] [G loss: 0.769049]\n",
      "epoch:6 step:4796 [D loss: 0.659604, acc.: 59.38%] [G loss: 0.753820]\n",
      "epoch:6 step:4797 [D loss: 0.650005, acc.: 61.72%] [G loss: 0.758046]\n",
      "epoch:6 step:4798 [D loss: 0.736494, acc.: 48.44%] [G loss: 0.771475]\n",
      "epoch:6 step:4799 [D loss: 0.671180, acc.: 61.72%] [G loss: 0.762827]\n",
      "epoch:6 step:4800 [D loss: 0.704325, acc.: 53.91%] [G loss: 0.814419]\n",
      "epoch:6 step:4801 [D loss: 0.678491, acc.: 57.81%] [G loss: 0.883085]\n",
      "epoch:6 step:4802 [D loss: 0.689486, acc.: 57.81%] [G loss: 0.827982]\n",
      "epoch:6 step:4803 [D loss: 0.636255, acc.: 61.72%] [G loss: 0.839079]\n",
      "epoch:6 step:4804 [D loss: 0.673341, acc.: 60.16%] [G loss: 0.876908]\n",
      "epoch:6 step:4805 [D loss: 0.660916, acc.: 60.16%] [G loss: 0.859982]\n",
      "epoch:6 step:4806 [D loss: 0.701506, acc.: 56.25%] [G loss: 0.683667]\n",
      "epoch:6 step:4807 [D loss: 0.654474, acc.: 64.06%] [G loss: 0.896447]\n",
      "epoch:6 step:4808 [D loss: 0.719181, acc.: 44.53%] [G loss: 0.765936]\n",
      "epoch:6 step:4809 [D loss: 0.668951, acc.: 59.38%] [G loss: 0.926745]\n",
      "epoch:6 step:4810 [D loss: 0.769173, acc.: 43.75%] [G loss: 0.799186]\n",
      "epoch:6 step:4811 [D loss: 0.688883, acc.: 52.34%] [G loss: 0.921094]\n",
      "epoch:6 step:4812 [D loss: 0.720132, acc.: 52.34%] [G loss: 0.911196]\n",
      "epoch:6 step:4813 [D loss: 0.737045, acc.: 50.00%] [G loss: 0.797765]\n",
      "epoch:6 step:4814 [D loss: 0.675258, acc.: 59.38%] [G loss: 0.897651]\n",
      "epoch:6 step:4815 [D loss: 0.655823, acc.: 63.28%] [G loss: 0.762586]\n",
      "epoch:6 step:4816 [D loss: 0.729057, acc.: 45.31%] [G loss: 0.835998]\n",
      "epoch:6 step:4817 [D loss: 0.682640, acc.: 55.47%] [G loss: 0.874869]\n",
      "epoch:6 step:4818 [D loss: 0.583065, acc.: 74.22%] [G loss: 0.834885]\n",
      "epoch:6 step:4819 [D loss: 0.666690, acc.: 60.16%] [G loss: 0.826107]\n",
      "epoch:6 step:4820 [D loss: 0.705857, acc.: 51.56%] [G loss: 0.946001]\n",
      "epoch:6 step:4821 [D loss: 0.714339, acc.: 52.34%] [G loss: 0.778316]\n",
      "epoch:6 step:4822 [D loss: 0.697445, acc.: 56.25%] [G loss: 0.779761]\n",
      "epoch:6 step:4823 [D loss: 0.709694, acc.: 46.88%] [G loss: 0.767620]\n",
      "epoch:6 step:4824 [D loss: 0.734471, acc.: 50.00%] [G loss: 0.752623]\n",
      "epoch:6 step:4825 [D loss: 0.656106, acc.: 63.28%] [G loss: 0.956937]\n",
      "epoch:6 step:4826 [D loss: 0.707738, acc.: 46.88%] [G loss: 0.862229]\n",
      "epoch:6 step:4827 [D loss: 0.734459, acc.: 44.53%] [G loss: 0.880359]\n",
      "epoch:6 step:4828 [D loss: 0.651968, acc.: 70.31%] [G loss: 0.856760]\n",
      "epoch:6 step:4829 [D loss: 0.725082, acc.: 50.78%] [G loss: 0.829754]\n",
      "epoch:6 step:4830 [D loss: 0.679742, acc.: 56.25%] [G loss: 0.856506]\n",
      "epoch:6 step:4831 [D loss: 0.721200, acc.: 49.22%] [G loss: 0.840562]\n",
      "epoch:6 step:4832 [D loss: 0.677609, acc.: 57.03%] [G loss: 0.836300]\n",
      "epoch:6 step:4833 [D loss: 0.736019, acc.: 43.75%] [G loss: 0.756132]\n",
      "epoch:6 step:4834 [D loss: 0.684327, acc.: 57.81%] [G loss: 0.761337]\n",
      "epoch:6 step:4835 [D loss: 0.596919, acc.: 70.31%] [G loss: 0.808748]\n",
      "epoch:6 step:4836 [D loss: 0.720077, acc.: 48.44%] [G loss: 0.865260]\n",
      "epoch:6 step:4837 [D loss: 0.695831, acc.: 50.78%] [G loss: 0.901374]\n",
      "epoch:6 step:4838 [D loss: 0.723843, acc.: 46.09%] [G loss: 0.852081]\n",
      "epoch:6 step:4839 [D loss: 0.695244, acc.: 58.59%] [G loss: 0.733973]\n",
      "epoch:6 step:4840 [D loss: 0.707991, acc.: 50.00%] [G loss: 0.752087]\n",
      "epoch:6 step:4841 [D loss: 0.763329, acc.: 42.19%] [G loss: 0.831322]\n",
      "epoch:6 step:4842 [D loss: 0.756014, acc.: 47.66%] [G loss: 0.822874]\n",
      "epoch:6 step:4843 [D loss: 0.715346, acc.: 51.56%] [G loss: 0.875907]\n",
      "epoch:6 step:4844 [D loss: 0.701891, acc.: 53.12%] [G loss: 0.852409]\n",
      "epoch:6 step:4845 [D loss: 0.676318, acc.: 56.25%] [G loss: 0.887633]\n",
      "epoch:6 step:4846 [D loss: 0.650776, acc.: 62.50%] [G loss: 0.869256]\n",
      "epoch:6 step:4847 [D loss: 0.723057, acc.: 51.56%] [G loss: 0.905464]\n",
      "epoch:6 step:4848 [D loss: 0.621513, acc.: 66.41%] [G loss: 0.964087]\n",
      "epoch:6 step:4849 [D loss: 0.696398, acc.: 53.12%] [G loss: 0.855594]\n",
      "epoch:6 step:4850 [D loss: 0.632415, acc.: 66.41%] [G loss: 0.928177]\n",
      "epoch:6 step:4851 [D loss: 0.705499, acc.: 53.12%] [G loss: 0.892883]\n",
      "epoch:6 step:4852 [D loss: 0.661848, acc.: 63.28%] [G loss: 0.900384]\n",
      "epoch:6 step:4853 [D loss: 0.700763, acc.: 50.00%] [G loss: 0.852338]\n",
      "epoch:6 step:4854 [D loss: 0.644412, acc.: 59.38%] [G loss: 0.844985]\n",
      "epoch:6 step:4855 [D loss: 0.660230, acc.: 64.84%] [G loss: 0.811417]\n",
      "epoch:6 step:4856 [D loss: 0.695045, acc.: 54.69%] [G loss: 0.855059]\n",
      "epoch:6 step:4857 [D loss: 0.663258, acc.: 55.47%] [G loss: 0.790170]\n",
      "epoch:6 step:4858 [D loss: 0.685946, acc.: 54.69%] [G loss: 0.805313]\n",
      "epoch:6 step:4859 [D loss: 0.678361, acc.: 58.59%] [G loss: 0.793275]\n",
      "epoch:6 step:4860 [D loss: 0.724877, acc.: 50.78%] [G loss: 0.779696]\n",
      "epoch:6 step:4861 [D loss: 0.702459, acc.: 48.44%] [G loss: 0.760409]\n",
      "epoch:6 step:4862 [D loss: 0.632284, acc.: 68.75%] [G loss: 0.926635]\n",
      "epoch:6 step:4863 [D loss: 0.689048, acc.: 56.25%] [G loss: 0.804543]\n",
      "epoch:6 step:4864 [D loss: 0.696769, acc.: 56.25%] [G loss: 0.821478]\n",
      "epoch:6 step:4865 [D loss: 0.694806, acc.: 50.78%] [G loss: 0.737123]\n",
      "epoch:6 step:4866 [D loss: 0.670559, acc.: 60.16%] [G loss: 0.778921]\n",
      "epoch:6 step:4867 [D loss: 0.681581, acc.: 53.12%] [G loss: 0.802263]\n",
      "epoch:6 step:4868 [D loss: 0.706747, acc.: 53.91%] [G loss: 0.828705]\n",
      "epoch:6 step:4869 [D loss: 0.790429, acc.: 33.59%] [G loss: 0.785616]\n",
      "epoch:6 step:4870 [D loss: 0.646063, acc.: 66.41%] [G loss: 0.866978]\n",
      "epoch:6 step:4871 [D loss: 0.685311, acc.: 54.69%] [G loss: 0.802268]\n",
      "epoch:6 step:4872 [D loss: 0.751644, acc.: 45.31%] [G loss: 0.803946]\n",
      "epoch:6 step:4873 [D loss: 0.699922, acc.: 49.22%] [G loss: 0.888347]\n",
      "epoch:6 step:4874 [D loss: 0.715929, acc.: 56.25%] [G loss: 0.908191]\n",
      "epoch:6 step:4875 [D loss: 0.658583, acc.: 57.03%] [G loss: 0.873605]\n",
      "epoch:6 step:4876 [D loss: 0.721166, acc.: 47.66%] [G loss: 0.960727]\n",
      "epoch:6 step:4877 [D loss: 0.711787, acc.: 51.56%] [G loss: 0.911040]\n",
      "epoch:6 step:4878 [D loss: 0.722447, acc.: 44.53%] [G loss: 0.890719]\n",
      "epoch:6 step:4879 [D loss: 0.742789, acc.: 42.19%] [G loss: 0.944305]\n",
      "epoch:6 step:4880 [D loss: 0.666390, acc.: 60.94%] [G loss: 0.855227]\n",
      "epoch:6 step:4881 [D loss: 0.673275, acc.: 53.12%] [G loss: 1.001084]\n",
      "epoch:6 step:4882 [D loss: 0.695400, acc.: 53.91%] [G loss: 0.803073]\n",
      "epoch:6 step:4883 [D loss: 0.706432, acc.: 53.12%] [G loss: 0.894213]\n",
      "epoch:6 step:4884 [D loss: 0.619233, acc.: 65.62%] [G loss: 0.839819]\n",
      "epoch:6 step:4885 [D loss: 0.721557, acc.: 53.91%] [G loss: 0.831043]\n",
      "epoch:6 step:4886 [D loss: 0.674499, acc.: 59.38%] [G loss: 0.879560]\n",
      "epoch:6 step:4887 [D loss: 0.682534, acc.: 62.50%] [G loss: 0.788873]\n",
      "epoch:6 step:4888 [D loss: 0.775627, acc.: 41.41%] [G loss: 0.748696]\n",
      "epoch:6 step:4889 [D loss: 0.683935, acc.: 52.34%] [G loss: 0.802213]\n",
      "epoch:6 step:4890 [D loss: 0.702736, acc.: 56.25%] [G loss: 0.806013]\n",
      "epoch:6 step:4891 [D loss: 0.694961, acc.: 53.91%] [G loss: 0.829368]\n",
      "epoch:6 step:4892 [D loss: 0.693540, acc.: 53.91%] [G loss: 0.803710]\n",
      "epoch:6 step:4893 [D loss: 0.620863, acc.: 65.62%] [G loss: 0.808433]\n",
      "epoch:6 step:4894 [D loss: 0.595245, acc.: 69.53%] [G loss: 0.912514]\n",
      "epoch:6 step:4895 [D loss: 0.656679, acc.: 62.50%] [G loss: 0.853700]\n",
      "epoch:6 step:4896 [D loss: 0.714845, acc.: 51.56%] [G loss: 0.845299]\n",
      "epoch:6 step:4897 [D loss: 0.641388, acc.: 65.62%] [G loss: 0.920276]\n",
      "epoch:6 step:4898 [D loss: 0.688019, acc.: 57.03%] [G loss: 0.833809]\n",
      "epoch:6 step:4899 [D loss: 0.751399, acc.: 42.97%] [G loss: 0.817864]\n",
      "epoch:6 step:4900 [D loss: 0.633977, acc.: 59.38%] [G loss: 0.871276]\n",
      "epoch:6 step:4901 [D loss: 0.645001, acc.: 60.94%] [G loss: 1.017124]\n",
      "epoch:6 step:4902 [D loss: 0.696851, acc.: 57.03%] [G loss: 0.959751]\n",
      "epoch:6 step:4903 [D loss: 0.674368, acc.: 56.25%] [G loss: 0.847029]\n",
      "epoch:6 step:4904 [D loss: 0.634390, acc.: 67.97%] [G loss: 0.858092]\n",
      "epoch:6 step:4905 [D loss: 0.621188, acc.: 70.31%] [G loss: 0.878860]\n",
      "epoch:6 step:4906 [D loss: 0.627974, acc.: 63.28%] [G loss: 0.934750]\n",
      "epoch:6 step:4907 [D loss: 0.768053, acc.: 36.72%] [G loss: 0.891881]\n",
      "epoch:6 step:4908 [D loss: 0.630579, acc.: 65.62%] [G loss: 0.914389]\n",
      "epoch:6 step:4909 [D loss: 0.689248, acc.: 54.69%] [G loss: 0.856338]\n",
      "epoch:6 step:4910 [D loss: 0.595481, acc.: 69.53%] [G loss: 0.833218]\n",
      "epoch:6 step:4911 [D loss: 0.669241, acc.: 56.25%] [G loss: 0.783918]\n",
      "epoch:6 step:4912 [D loss: 0.645732, acc.: 59.38%] [G loss: 0.800182]\n",
      "epoch:6 step:4913 [D loss: 0.706637, acc.: 53.91%] [G loss: 0.874139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4914 [D loss: 0.658163, acc.: 59.38%] [G loss: 0.782934]\n",
      "epoch:6 step:4915 [D loss: 0.730330, acc.: 51.56%] [G loss: 0.779807]\n",
      "epoch:6 step:4916 [D loss: 0.668849, acc.: 57.03%] [G loss: 0.895332]\n",
      "epoch:6 step:4917 [D loss: 0.693097, acc.: 55.47%] [G loss: 0.798211]\n",
      "epoch:6 step:4918 [D loss: 0.611179, acc.: 69.53%] [G loss: 0.803403]\n",
      "epoch:6 step:4919 [D loss: 0.665952, acc.: 58.59%] [G loss: 0.796326]\n",
      "epoch:6 step:4920 [D loss: 0.779961, acc.: 42.19%] [G loss: 0.691941]\n",
      "epoch:6 step:4921 [D loss: 0.791791, acc.: 39.84%] [G loss: 0.617336]\n",
      "epoch:6 step:4922 [D loss: 0.753200, acc.: 42.19%] [G loss: 0.741990]\n",
      "epoch:6 step:4923 [D loss: 0.651567, acc.: 64.84%] [G loss: 0.724363]\n",
      "epoch:6 step:4924 [D loss: 0.728741, acc.: 46.88%] [G loss: 0.787743]\n",
      "epoch:6 step:4925 [D loss: 0.722833, acc.: 52.34%] [G loss: 0.763971]\n",
      "epoch:6 step:4926 [D loss: 0.764405, acc.: 43.75%] [G loss: 0.727590]\n",
      "epoch:6 step:4927 [D loss: 0.800758, acc.: 34.38%] [G loss: 0.714555]\n",
      "epoch:6 step:4928 [D loss: 0.684593, acc.: 51.56%] [G loss: 0.811367]\n",
      "epoch:6 step:4929 [D loss: 0.747759, acc.: 43.75%] [G loss: 0.908007]\n",
      "epoch:6 step:4930 [D loss: 0.655549, acc.: 63.28%] [G loss: 0.864778]\n",
      "epoch:6 step:4931 [D loss: 0.680636, acc.: 57.03%] [G loss: 0.912903]\n",
      "epoch:6 step:4932 [D loss: 0.615905, acc.: 75.00%] [G loss: 0.884278]\n",
      "epoch:6 step:4933 [D loss: 0.593300, acc.: 72.66%] [G loss: 1.008469]\n",
      "epoch:6 step:4934 [D loss: 0.610746, acc.: 71.88%] [G loss: 1.025458]\n",
      "epoch:6 step:4935 [D loss: 0.551484, acc.: 77.34%] [G loss: 0.864465]\n",
      "epoch:6 step:4936 [D loss: 0.548848, acc.: 74.22%] [G loss: 0.950579]\n",
      "epoch:6 step:4937 [D loss: 0.530758, acc.: 78.12%] [G loss: 0.843618]\n",
      "epoch:6 step:4938 [D loss: 0.559667, acc.: 78.12%] [G loss: 0.778980]\n",
      "epoch:6 step:4939 [D loss: 0.509920, acc.: 79.69%] [G loss: 0.904660]\n",
      "epoch:6 step:4940 [D loss: 0.538843, acc.: 84.38%] [G loss: 0.625520]\n",
      "epoch:6 step:4941 [D loss: 0.633089, acc.: 66.41%] [G loss: 0.666716]\n",
      "epoch:6 step:4942 [D loss: 0.555377, acc.: 75.00%] [G loss: 0.500031]\n",
      "epoch:6 step:4943 [D loss: 0.634300, acc.: 63.28%] [G loss: 0.455236]\n",
      "epoch:6 step:4944 [D loss: 0.593444, acc.: 75.00%] [G loss: 0.507561]\n",
      "epoch:6 step:4945 [D loss: 0.747633, acc.: 53.12%] [G loss: 0.644797]\n",
      "epoch:6 step:4946 [D loss: 0.642562, acc.: 64.84%] [G loss: 0.822498]\n",
      "epoch:6 step:4947 [D loss: 0.691852, acc.: 53.91%] [G loss: 0.681103]\n",
      "epoch:6 step:4948 [D loss: 0.708193, acc.: 51.56%] [G loss: 0.603496]\n",
      "epoch:6 step:4949 [D loss: 0.894545, acc.: 25.00%] [G loss: 0.674730]\n",
      "epoch:6 step:4950 [D loss: 0.726016, acc.: 50.78%] [G loss: 0.619391]\n",
      "epoch:6 step:4951 [D loss: 0.800741, acc.: 42.19%] [G loss: 0.652669]\n",
      "epoch:6 step:4952 [D loss: 0.817636, acc.: 32.81%] [G loss: 0.693326]\n",
      "epoch:6 step:4953 [D loss: 0.898086, acc.: 27.34%] [G loss: 0.728421]\n",
      "epoch:6 step:4954 [D loss: 0.774748, acc.: 42.19%] [G loss: 0.757055]\n",
      "epoch:6 step:4955 [D loss: 0.772874, acc.: 34.38%] [G loss: 0.786071]\n",
      "epoch:6 step:4956 [D loss: 0.739370, acc.: 48.44%] [G loss: 0.816653]\n",
      "epoch:6 step:4957 [D loss: 0.722552, acc.: 45.31%] [G loss: 0.894071]\n",
      "epoch:6 step:4958 [D loss: 0.735178, acc.: 46.88%] [G loss: 0.846866]\n",
      "epoch:6 step:4959 [D loss: 0.696680, acc.: 54.69%] [G loss: 0.777673]\n",
      "epoch:6 step:4960 [D loss: 0.704396, acc.: 50.00%] [G loss: 0.835774]\n",
      "epoch:6 step:4961 [D loss: 0.640780, acc.: 60.16%] [G loss: 0.887700]\n",
      "epoch:6 step:4962 [D loss: 0.656036, acc.: 67.19%] [G loss: 0.809212]\n",
      "epoch:6 step:4963 [D loss: 0.703406, acc.: 53.12%] [G loss: 0.886407]\n",
      "epoch:6 step:4964 [D loss: 0.570821, acc.: 76.56%] [G loss: 0.850585]\n",
      "epoch:6 step:4965 [D loss: 0.642122, acc.: 62.50%] [G loss: 0.935596]\n",
      "epoch:6 step:4966 [D loss: 0.679587, acc.: 57.03%] [G loss: 0.907323]\n",
      "epoch:6 step:4967 [D loss: 0.654207, acc.: 59.38%] [G loss: 0.907706]\n",
      "epoch:6 step:4968 [D loss: 0.651550, acc.: 64.06%] [G loss: 0.998341]\n",
      "epoch:6 step:4969 [D loss: 0.625649, acc.: 65.62%] [G loss: 0.888719]\n",
      "epoch:6 step:4970 [D loss: 0.691225, acc.: 60.94%] [G loss: 0.833395]\n",
      "epoch:6 step:4971 [D loss: 0.679663, acc.: 57.81%] [G loss: 0.802064]\n",
      "epoch:6 step:4972 [D loss: 0.688132, acc.: 58.59%] [G loss: 0.808522]\n",
      "epoch:6 step:4973 [D loss: 0.684155, acc.: 57.81%] [G loss: 0.833574]\n",
      "epoch:6 step:4974 [D loss: 0.724944, acc.: 55.47%] [G loss: 0.682393]\n",
      "epoch:6 step:4975 [D loss: 0.728879, acc.: 46.09%] [G loss: 0.681026]\n",
      "epoch:6 step:4976 [D loss: 0.687871, acc.: 52.34%] [G loss: 0.766918]\n",
      "epoch:6 step:4977 [D loss: 0.755674, acc.: 41.41%] [G loss: 0.787197]\n",
      "epoch:6 step:4978 [D loss: 0.730220, acc.: 46.88%] [G loss: 0.617745]\n",
      "epoch:6 step:4979 [D loss: 0.709984, acc.: 50.78%] [G loss: 0.726289]\n",
      "epoch:6 step:4980 [D loss: 0.760069, acc.: 41.41%] [G loss: 0.732565]\n",
      "epoch:6 step:4981 [D loss: 0.777177, acc.: 41.41%] [G loss: 0.810280]\n",
      "epoch:6 step:4982 [D loss: 0.727820, acc.: 45.31%] [G loss: 0.816671]\n",
      "epoch:6 step:4983 [D loss: 0.792776, acc.: 33.59%] [G loss: 0.787511]\n",
      "epoch:6 step:4984 [D loss: 0.723412, acc.: 53.91%] [G loss: 0.808455]\n",
      "epoch:6 step:4985 [D loss: 0.742865, acc.: 47.66%] [G loss: 0.798487]\n",
      "epoch:6 step:4986 [D loss: 0.799574, acc.: 35.16%] [G loss: 0.786469]\n",
      "epoch:6 step:4987 [D loss: 0.700688, acc.: 58.59%] [G loss: 0.900306]\n",
      "epoch:6 step:4988 [D loss: 0.634892, acc.: 64.84%] [G loss: 0.957165]\n",
      "epoch:6 step:4989 [D loss: 0.664643, acc.: 58.59%] [G loss: 0.868743]\n",
      "epoch:6 step:4990 [D loss: 0.640508, acc.: 64.06%] [G loss: 0.922414]\n",
      "epoch:6 step:4991 [D loss: 0.661893, acc.: 57.81%] [G loss: 0.882288]\n",
      "epoch:6 step:4992 [D loss: 0.596017, acc.: 74.22%] [G loss: 0.827679]\n",
      "epoch:6 step:4993 [D loss: 0.613152, acc.: 66.41%] [G loss: 0.930482]\n",
      "epoch:6 step:4994 [D loss: 0.557907, acc.: 78.12%] [G loss: 1.018714]\n",
      "epoch:6 step:4995 [D loss: 0.618137, acc.: 65.62%] [G loss: 0.894514]\n",
      "epoch:6 step:4996 [D loss: 0.571947, acc.: 72.66%] [G loss: 0.846350]\n",
      "epoch:6 step:4997 [D loss: 0.679479, acc.: 63.28%] [G loss: 0.832187]\n",
      "epoch:6 step:4998 [D loss: 0.655262, acc.: 59.38%] [G loss: 0.733177]\n",
      "epoch:6 step:4999 [D loss: 0.596906, acc.: 75.78%] [G loss: 0.815465]\n",
      "epoch:6 step:5000 [D loss: 0.679014, acc.: 59.38%] [G loss: 0.680433]\n",
      "epoch:6 step:5001 [D loss: 0.623244, acc.: 67.97%] [G loss: 0.647390]\n",
      "epoch:6 step:5002 [D loss: 0.756791, acc.: 45.31%] [G loss: 0.696466]\n",
      "epoch:6 step:5003 [D loss: 0.751477, acc.: 44.53%] [G loss: 0.688245]\n",
      "epoch:6 step:5004 [D loss: 0.637622, acc.: 63.28%] [G loss: 0.762522]\n",
      "epoch:6 step:5005 [D loss: 0.726169, acc.: 49.22%] [G loss: 0.872781]\n",
      "epoch:6 step:5006 [D loss: 0.682787, acc.: 56.25%] [G loss: 0.735458]\n",
      "epoch:6 step:5007 [D loss: 0.680921, acc.: 53.12%] [G loss: 0.787746]\n",
      "epoch:6 step:5008 [D loss: 0.796359, acc.: 39.06%] [G loss: 0.825841]\n",
      "epoch:6 step:5009 [D loss: 0.741872, acc.: 43.75%] [G loss: 0.858573]\n",
      "epoch:6 step:5010 [D loss: 0.690327, acc.: 56.25%] [G loss: 0.949876]\n",
      "epoch:6 step:5011 [D loss: 0.669562, acc.: 60.94%] [G loss: 0.945334]\n",
      "epoch:6 step:5012 [D loss: 0.592300, acc.: 72.66%] [G loss: 1.106575]\n",
      "epoch:6 step:5013 [D loss: 0.681766, acc.: 58.59%] [G loss: 0.921638]\n",
      "epoch:6 step:5014 [D loss: 0.656559, acc.: 57.81%] [G loss: 0.937269]\n",
      "epoch:6 step:5015 [D loss: 0.665433, acc.: 61.72%] [G loss: 0.847635]\n",
      "epoch:6 step:5016 [D loss: 0.699817, acc.: 57.03%] [G loss: 0.896158]\n",
      "epoch:6 step:5017 [D loss: 0.675853, acc.: 59.38%] [G loss: 0.914088]\n",
      "epoch:6 step:5018 [D loss: 0.585756, acc.: 78.12%] [G loss: 1.077197]\n",
      "epoch:6 step:5019 [D loss: 0.649275, acc.: 63.28%] [G loss: 0.882778]\n",
      "epoch:6 step:5020 [D loss: 0.701490, acc.: 54.69%] [G loss: 0.719258]\n",
      "epoch:6 step:5021 [D loss: 0.683539, acc.: 57.03%] [G loss: 0.734505]\n",
      "epoch:6 step:5022 [D loss: 0.688207, acc.: 53.91%] [G loss: 0.769637]\n",
      "epoch:6 step:5023 [D loss: 0.581623, acc.: 69.53%] [G loss: 0.765219]\n",
      "epoch:6 step:5024 [D loss: 0.709739, acc.: 51.56%] [G loss: 0.667438]\n",
      "epoch:6 step:5025 [D loss: 0.708697, acc.: 50.00%] [G loss: 0.639145]\n",
      "epoch:6 step:5026 [D loss: 0.793005, acc.: 40.62%] [G loss: 0.769767]\n",
      "epoch:6 step:5027 [D loss: 0.640236, acc.: 65.62%] [G loss: 0.834893]\n",
      "epoch:6 step:5028 [D loss: 0.846855, acc.: 39.06%] [G loss: 0.756788]\n",
      "epoch:6 step:5029 [D loss: 0.751594, acc.: 42.97%] [G loss: 0.665674]\n",
      "epoch:6 step:5030 [D loss: 0.749344, acc.: 42.19%] [G loss: 0.728996]\n",
      "epoch:6 step:5031 [D loss: 0.715259, acc.: 50.00%] [G loss: 0.758082]\n",
      "epoch:6 step:5032 [D loss: 0.743758, acc.: 52.34%] [G loss: 0.783797]\n",
      "epoch:6 step:5033 [D loss: 0.747189, acc.: 48.44%] [G loss: 0.933775]\n",
      "epoch:6 step:5034 [D loss: 0.637831, acc.: 62.50%] [G loss: 0.876419]\n",
      "epoch:6 step:5035 [D loss: 0.660465, acc.: 60.16%] [G loss: 0.946906]\n",
      "epoch:6 step:5036 [D loss: 0.702807, acc.: 50.78%] [G loss: 0.854051]\n",
      "epoch:6 step:5037 [D loss: 0.753598, acc.: 48.44%] [G loss: 0.740973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5038 [D loss: 0.727995, acc.: 50.78%] [G loss: 0.724943]\n",
      "epoch:6 step:5039 [D loss: 0.686576, acc.: 54.69%] [G loss: 0.908723]\n",
      "epoch:6 step:5040 [D loss: 0.680098, acc.: 56.25%] [G loss: 0.747604]\n",
      "epoch:6 step:5041 [D loss: 0.695471, acc.: 53.91%] [G loss: 0.781359]\n",
      "epoch:6 step:5042 [D loss: 0.747913, acc.: 47.66%] [G loss: 0.760510]\n",
      "epoch:6 step:5043 [D loss: 0.697816, acc.: 50.78%] [G loss: 0.794885]\n",
      "epoch:6 step:5044 [D loss: 0.629365, acc.: 63.28%] [G loss: 0.859550]\n",
      "epoch:6 step:5045 [D loss: 0.713158, acc.: 46.09%] [G loss: 0.887227]\n",
      "epoch:6 step:5046 [D loss: 0.679664, acc.: 55.47%] [G loss: 0.811002]\n",
      "epoch:6 step:5047 [D loss: 0.605591, acc.: 70.31%] [G loss: 0.892489]\n",
      "epoch:6 step:5048 [D loss: 0.691448, acc.: 52.34%] [G loss: 0.874881]\n",
      "epoch:6 step:5049 [D loss: 0.596511, acc.: 70.31%] [G loss: 0.840947]\n",
      "epoch:6 step:5050 [D loss: 0.634149, acc.: 67.19%] [G loss: 0.818105]\n",
      "epoch:6 step:5051 [D loss: 0.588259, acc.: 76.56%] [G loss: 0.855096]\n",
      "epoch:6 step:5052 [D loss: 0.610345, acc.: 65.62%] [G loss: 0.889305]\n",
      "epoch:6 step:5053 [D loss: 0.658705, acc.: 65.62%] [G loss: 0.732201]\n",
      "epoch:6 step:5054 [D loss: 0.622628, acc.: 68.75%] [G loss: 0.881174]\n",
      "epoch:6 step:5055 [D loss: 0.687055, acc.: 58.59%] [G loss: 0.783749]\n",
      "epoch:6 step:5056 [D loss: 0.666486, acc.: 57.03%] [G loss: 0.766423]\n",
      "epoch:6 step:5057 [D loss: 0.618728, acc.: 63.28%] [G loss: 0.685865]\n",
      "epoch:6 step:5058 [D loss: 0.585305, acc.: 73.44%] [G loss: 0.674087]\n",
      "epoch:6 step:5059 [D loss: 0.780149, acc.: 39.06%] [G loss: 0.724430]\n",
      "epoch:6 step:5060 [D loss: 0.692952, acc.: 54.69%] [G loss: 0.778515]\n",
      "epoch:6 step:5061 [D loss: 0.739192, acc.: 44.53%] [G loss: 0.619271]\n",
      "epoch:6 step:5062 [D loss: 0.664634, acc.: 60.94%] [G loss: 0.749426]\n",
      "epoch:6 step:5063 [D loss: 0.719745, acc.: 50.00%] [G loss: 0.728719]\n",
      "epoch:6 step:5064 [D loss: 0.736092, acc.: 42.19%] [G loss: 0.825636]\n",
      "epoch:6 step:5065 [D loss: 0.728565, acc.: 47.66%] [G loss: 0.858122]\n",
      "epoch:6 step:5066 [D loss: 0.777015, acc.: 42.19%] [G loss: 0.791845]\n",
      "epoch:6 step:5067 [D loss: 0.710629, acc.: 48.44%] [G loss: 0.785923]\n",
      "epoch:6 step:5068 [D loss: 0.683366, acc.: 52.34%] [G loss: 0.805292]\n",
      "epoch:6 step:5069 [D loss: 0.706551, acc.: 45.31%] [G loss: 0.815619]\n",
      "epoch:6 step:5070 [D loss: 0.680815, acc.: 53.12%] [G loss: 0.861562]\n",
      "epoch:6 step:5071 [D loss: 0.684531, acc.: 53.12%] [G loss: 0.945452]\n",
      "epoch:6 step:5072 [D loss: 0.639267, acc.: 64.84%] [G loss: 0.910632]\n",
      "epoch:6 step:5073 [D loss: 0.660805, acc.: 57.03%] [G loss: 0.906738]\n",
      "epoch:6 step:5074 [D loss: 0.733675, acc.: 43.75%] [G loss: 0.894334]\n",
      "epoch:6 step:5075 [D loss: 0.731858, acc.: 46.09%] [G loss: 0.843381]\n",
      "epoch:6 step:5076 [D loss: 0.627795, acc.: 65.62%] [G loss: 0.814576]\n",
      "epoch:6 step:5077 [D loss: 0.719891, acc.: 54.69%] [G loss: 0.746312]\n",
      "epoch:6 step:5078 [D loss: 0.615922, acc.: 65.62%] [G loss: 0.841845]\n",
      "epoch:6 step:5079 [D loss: 0.659819, acc.: 64.84%] [G loss: 0.774455]\n",
      "epoch:6 step:5080 [D loss: 0.714666, acc.: 50.00%] [G loss: 0.774599]\n",
      "epoch:6 step:5081 [D loss: 0.644327, acc.: 57.03%] [G loss: 0.968609]\n",
      "epoch:6 step:5082 [D loss: 0.639400, acc.: 67.97%] [G loss: 0.896236]\n",
      "epoch:6 step:5083 [D loss: 0.622659, acc.: 64.84%] [G loss: 0.926369]\n",
      "epoch:6 step:5084 [D loss: 0.693262, acc.: 56.25%] [G loss: 0.808638]\n",
      "epoch:6 step:5085 [D loss: 0.658901, acc.: 61.72%] [G loss: 0.705435]\n",
      "epoch:6 step:5086 [D loss: 0.685626, acc.: 56.25%] [G loss: 0.786294]\n",
      "epoch:6 step:5087 [D loss: 0.624198, acc.: 70.31%] [G loss: 0.795861]\n",
      "epoch:6 step:5088 [D loss: 0.631995, acc.: 64.06%] [G loss: 0.717143]\n",
      "epoch:6 step:5089 [D loss: 0.643021, acc.: 64.06%] [G loss: 0.712688]\n",
      "epoch:6 step:5090 [D loss: 0.672516, acc.: 53.12%] [G loss: 0.803712]\n",
      "epoch:6 step:5091 [D loss: 0.698539, acc.: 53.12%] [G loss: 0.783184]\n",
      "epoch:6 step:5092 [D loss: 0.778648, acc.: 40.62%] [G loss: 0.766379]\n",
      "epoch:6 step:5093 [D loss: 0.716458, acc.: 46.88%] [G loss: 0.763324]\n",
      "epoch:6 step:5094 [D loss: 0.722976, acc.: 50.00%] [G loss: 0.703883]\n",
      "epoch:6 step:5095 [D loss: 0.758532, acc.: 45.31%] [G loss: 0.768078]\n",
      "epoch:6 step:5096 [D loss: 0.688007, acc.: 59.38%] [G loss: 0.840000]\n",
      "epoch:6 step:5097 [D loss: 0.764334, acc.: 43.75%] [G loss: 0.781587]\n",
      "epoch:6 step:5098 [D loss: 0.759347, acc.: 40.62%] [G loss: 0.792503]\n",
      "epoch:6 step:5099 [D loss: 0.731229, acc.: 43.75%] [G loss: 0.784680]\n",
      "epoch:6 step:5100 [D loss: 0.722720, acc.: 52.34%] [G loss: 0.864017]\n",
      "epoch:6 step:5101 [D loss: 0.653224, acc.: 64.84%] [G loss: 0.914222]\n",
      "epoch:6 step:5102 [D loss: 0.711130, acc.: 55.47%] [G loss: 0.923703]\n",
      "epoch:6 step:5103 [D loss: 0.612081, acc.: 69.53%] [G loss: 0.911196]\n",
      "epoch:6 step:5104 [D loss: 0.623363, acc.: 67.19%] [G loss: 0.844906]\n",
      "epoch:6 step:5105 [D loss: 0.681356, acc.: 59.38%] [G loss: 0.735473]\n",
      "epoch:6 step:5106 [D loss: 0.564621, acc.: 76.56%] [G loss: 0.972384]\n",
      "epoch:6 step:5107 [D loss: 0.586283, acc.: 74.22%] [G loss: 0.778444]\n",
      "epoch:6 step:5108 [D loss: 0.565146, acc.: 75.00%] [G loss: 0.797964]\n",
      "epoch:6 step:5109 [D loss: 0.662604, acc.: 60.94%] [G loss: 0.751996]\n",
      "epoch:6 step:5110 [D loss: 0.646187, acc.: 64.84%] [G loss: 0.695895]\n",
      "epoch:6 step:5111 [D loss: 0.639133, acc.: 62.50%] [G loss: 0.770459]\n",
      "epoch:6 step:5112 [D loss: 0.658860, acc.: 60.94%] [G loss: 0.757415]\n",
      "epoch:6 step:5113 [D loss: 0.626979, acc.: 65.62%] [G loss: 0.722078]\n",
      "epoch:6 step:5114 [D loss: 0.729074, acc.: 49.22%] [G loss: 0.736085]\n",
      "epoch:6 step:5115 [D loss: 0.648406, acc.: 66.41%] [G loss: 0.729654]\n",
      "epoch:6 step:5116 [D loss: 0.639639, acc.: 66.41%] [G loss: 0.816447]\n",
      "epoch:6 step:5117 [D loss: 0.732933, acc.: 41.41%] [G loss: 0.861057]\n",
      "epoch:6 step:5118 [D loss: 0.728550, acc.: 52.34%] [G loss: 0.790344]\n",
      "epoch:6 step:5119 [D loss: 0.762636, acc.: 44.53%] [G loss: 0.857520]\n",
      "epoch:6 step:5120 [D loss: 0.817534, acc.: 36.72%] [G loss: 0.818915]\n",
      "epoch:6 step:5121 [D loss: 0.734144, acc.: 44.53%] [G loss: 0.797144]\n",
      "epoch:6 step:5122 [D loss: 0.742793, acc.: 46.88%] [G loss: 0.853328]\n",
      "epoch:6 step:5123 [D loss: 0.771519, acc.: 45.31%] [G loss: 0.829918]\n",
      "epoch:6 step:5124 [D loss: 0.686394, acc.: 57.03%] [G loss: 0.866162]\n",
      "epoch:6 step:5125 [D loss: 0.603737, acc.: 66.41%] [G loss: 1.019599]\n",
      "epoch:6 step:5126 [D loss: 0.718159, acc.: 50.78%] [G loss: 0.874059]\n",
      "epoch:6 step:5127 [D loss: 0.678443, acc.: 63.28%] [G loss: 0.856252]\n",
      "epoch:6 step:5128 [D loss: 0.615153, acc.: 67.97%] [G loss: 0.834670]\n",
      "epoch:6 step:5129 [D loss: 0.665408, acc.: 64.84%] [G loss: 0.799624]\n",
      "epoch:6 step:5130 [D loss: 0.637079, acc.: 67.19%] [G loss: 0.836205]\n",
      "epoch:6 step:5131 [D loss: 0.693234, acc.: 53.12%] [G loss: 0.899185]\n",
      "epoch:6 step:5132 [D loss: 0.685273, acc.: 55.47%] [G loss: 0.853534]\n",
      "epoch:6 step:5133 [D loss: 0.643421, acc.: 61.72%] [G loss: 0.757529]\n",
      "epoch:6 step:5134 [D loss: 0.689666, acc.: 55.47%] [G loss: 0.885269]\n",
      "epoch:6 step:5135 [D loss: 0.643453, acc.: 61.72%] [G loss: 0.908692]\n",
      "epoch:6 step:5136 [D loss: 0.631542, acc.: 70.31%] [G loss: 0.794229]\n",
      "epoch:6 step:5137 [D loss: 0.720781, acc.: 52.34%] [G loss: 0.865039]\n",
      "epoch:6 step:5138 [D loss: 0.644003, acc.: 60.16%] [G loss: 0.877240]\n",
      "epoch:6 step:5139 [D loss: 0.798432, acc.: 42.19%] [G loss: 0.735549]\n",
      "epoch:6 step:5140 [D loss: 0.705465, acc.: 50.78%] [G loss: 0.784269]\n",
      "epoch:6 step:5141 [D loss: 0.711605, acc.: 52.34%] [G loss: 0.710499]\n",
      "epoch:6 step:5142 [D loss: 0.761910, acc.: 38.28%] [G loss: 0.865490]\n",
      "epoch:6 step:5143 [D loss: 0.642498, acc.: 62.50%] [G loss: 0.821465]\n",
      "epoch:6 step:5144 [D loss: 0.661823, acc.: 62.50%] [G loss: 0.885534]\n",
      "epoch:6 step:5145 [D loss: 0.754515, acc.: 47.66%] [G loss: 0.804561]\n",
      "epoch:6 step:5146 [D loss: 0.699405, acc.: 56.25%] [G loss: 0.776093]\n",
      "epoch:6 step:5147 [D loss: 0.697651, acc.: 53.12%] [G loss: 0.794108]\n",
      "epoch:6 step:5148 [D loss: 0.666797, acc.: 64.84%] [G loss: 0.841477]\n",
      "epoch:6 step:5149 [D loss: 0.798414, acc.: 37.50%] [G loss: 0.786229]\n",
      "epoch:6 step:5150 [D loss: 0.658461, acc.: 64.84%] [G loss: 0.911166]\n",
      "epoch:6 step:5151 [D loss: 0.649381, acc.: 70.31%] [G loss: 0.869991]\n",
      "epoch:6 step:5152 [D loss: 0.678326, acc.: 57.03%] [G loss: 0.891107]\n",
      "epoch:6 step:5153 [D loss: 0.728160, acc.: 49.22%] [G loss: 0.828325]\n",
      "epoch:6 step:5154 [D loss: 0.618430, acc.: 69.53%] [G loss: 0.914403]\n",
      "epoch:6 step:5155 [D loss: 0.726081, acc.: 42.19%] [G loss: 0.849247]\n",
      "epoch:6 step:5156 [D loss: 0.647118, acc.: 66.41%] [G loss: 0.938517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5157 [D loss: 0.660642, acc.: 58.59%] [G loss: 0.964131]\n",
      "epoch:6 step:5158 [D loss: 0.667671, acc.: 57.03%] [G loss: 0.888666]\n",
      "epoch:6 step:5159 [D loss: 0.741631, acc.: 48.44%] [G loss: 0.729570]\n",
      "epoch:6 step:5160 [D loss: 0.624473, acc.: 67.97%] [G loss: 0.754729]\n",
      "epoch:6 step:5161 [D loss: 0.696153, acc.: 50.78%] [G loss: 0.663983]\n",
      "epoch:6 step:5162 [D loss: 0.697573, acc.: 57.03%] [G loss: 0.807276]\n",
      "epoch:6 step:5163 [D loss: 0.643465, acc.: 65.62%] [G loss: 0.912497]\n",
      "epoch:6 step:5164 [D loss: 0.667851, acc.: 57.03%] [G loss: 0.779364]\n",
      "epoch:6 step:5165 [D loss: 0.692155, acc.: 53.91%] [G loss: 0.837868]\n",
      "epoch:6 step:5166 [D loss: 0.681561, acc.: 56.25%] [G loss: 0.849836]\n",
      "epoch:6 step:5167 [D loss: 0.584581, acc.: 71.09%] [G loss: 0.967167]\n",
      "epoch:6 step:5168 [D loss: 0.736397, acc.: 47.66%] [G loss: 0.730004]\n",
      "epoch:6 step:5169 [D loss: 0.701681, acc.: 50.78%] [G loss: 0.813342]\n",
      "epoch:6 step:5170 [D loss: 0.630548, acc.: 66.41%] [G loss: 0.915895]\n",
      "epoch:6 step:5171 [D loss: 0.712212, acc.: 47.66%] [G loss: 0.777827]\n",
      "epoch:6 step:5172 [D loss: 0.698670, acc.: 51.56%] [G loss: 0.681251]\n",
      "epoch:6 step:5173 [D loss: 0.733015, acc.: 47.66%] [G loss: 0.768171]\n",
      "epoch:6 step:5174 [D loss: 0.740063, acc.: 44.53%] [G loss: 0.758557]\n",
      "epoch:6 step:5175 [D loss: 0.689297, acc.: 54.69%] [G loss: 0.774345]\n",
      "epoch:6 step:5176 [D loss: 0.674108, acc.: 58.59%] [G loss: 0.864262]\n",
      "epoch:6 step:5177 [D loss: 0.643324, acc.: 64.84%] [G loss: 0.890259]\n",
      "epoch:6 step:5178 [D loss: 0.669293, acc.: 57.81%] [G loss: 0.902506]\n",
      "epoch:6 step:5179 [D loss: 0.686256, acc.: 51.56%] [G loss: 0.804004]\n",
      "epoch:6 step:5180 [D loss: 0.641304, acc.: 62.50%] [G loss: 0.858523]\n",
      "epoch:6 step:5181 [D loss: 0.663022, acc.: 60.16%] [G loss: 0.841762]\n",
      "epoch:6 step:5182 [D loss: 0.668701, acc.: 58.59%] [G loss: 0.927100]\n",
      "epoch:6 step:5183 [D loss: 0.676982, acc.: 56.25%] [G loss: 0.858564]\n",
      "epoch:6 step:5184 [D loss: 0.631520, acc.: 62.50%] [G loss: 0.837978]\n",
      "epoch:6 step:5185 [D loss: 0.750511, acc.: 50.78%] [G loss: 0.848748]\n",
      "epoch:6 step:5186 [D loss: 0.671041, acc.: 59.38%] [G loss: 0.898912]\n",
      "epoch:6 step:5187 [D loss: 0.740612, acc.: 44.53%] [G loss: 0.802098]\n",
      "epoch:6 step:5188 [D loss: 0.667755, acc.: 57.81%] [G loss: 0.880847]\n",
      "epoch:6 step:5189 [D loss: 0.642314, acc.: 64.06%] [G loss: 0.841977]\n",
      "epoch:6 step:5190 [D loss: 0.741233, acc.: 45.31%] [G loss: 0.777673]\n",
      "epoch:6 step:5191 [D loss: 0.727757, acc.: 42.97%] [G loss: 0.767249]\n",
      "epoch:6 step:5192 [D loss: 0.693608, acc.: 57.03%] [G loss: 0.806880]\n",
      "epoch:6 step:5193 [D loss: 0.759229, acc.: 45.31%] [G loss: 0.809595]\n",
      "epoch:6 step:5194 [D loss: 0.749554, acc.: 43.75%] [G loss: 0.784610]\n",
      "epoch:6 step:5195 [D loss: 0.703675, acc.: 50.78%] [G loss: 0.856163]\n",
      "epoch:6 step:5196 [D loss: 0.715028, acc.: 49.22%] [G loss: 0.689344]\n",
      "epoch:6 step:5197 [D loss: 0.744639, acc.: 46.88%] [G loss: 0.684748]\n",
      "epoch:6 step:5198 [D loss: 0.670283, acc.: 55.47%] [G loss: 0.803853]\n",
      "epoch:6 step:5199 [D loss: 0.751595, acc.: 42.97%] [G loss: 0.773066]\n",
      "epoch:6 step:5200 [D loss: 0.737250, acc.: 47.66%] [G loss: 0.737165]\n",
      "epoch:6 step:5201 [D loss: 0.746576, acc.: 50.78%] [G loss: 0.749025]\n",
      "epoch:6 step:5202 [D loss: 0.752263, acc.: 46.09%] [G loss: 0.815440]\n",
      "epoch:6 step:5203 [D loss: 0.811417, acc.: 36.72%] [G loss: 0.781682]\n",
      "epoch:6 step:5204 [D loss: 0.715076, acc.: 50.00%] [G loss: 0.818873]\n",
      "epoch:6 step:5205 [D loss: 0.697668, acc.: 51.56%] [G loss: 0.858771]\n",
      "epoch:6 step:5206 [D loss: 0.730246, acc.: 50.00%] [G loss: 0.743702]\n",
      "epoch:6 step:5207 [D loss: 0.694635, acc.: 60.16%] [G loss: 0.941090]\n",
      "epoch:6 step:5208 [D loss: 0.698103, acc.: 50.00%] [G loss: 0.846528]\n",
      "epoch:6 step:5209 [D loss: 0.661686, acc.: 60.94%] [G loss: 0.882971]\n",
      "epoch:6 step:5210 [D loss: 0.717145, acc.: 49.22%] [G loss: 0.842665]\n",
      "epoch:6 step:5211 [D loss: 0.741662, acc.: 42.97%] [G loss: 0.885211]\n",
      "epoch:6 step:5212 [D loss: 0.752160, acc.: 53.91%] [G loss: 0.821478]\n",
      "epoch:6 step:5213 [D loss: 0.708420, acc.: 50.78%] [G loss: 0.806139]\n",
      "epoch:6 step:5214 [D loss: 0.704331, acc.: 55.47%] [G loss: 0.799622]\n",
      "epoch:6 step:5215 [D loss: 0.699423, acc.: 57.81%] [G loss: 0.700931]\n",
      "epoch:6 step:5216 [D loss: 0.699129, acc.: 57.81%] [G loss: 0.746340]\n",
      "epoch:6 step:5217 [D loss: 0.733039, acc.: 49.22%] [G loss: 0.798585]\n",
      "epoch:6 step:5218 [D loss: 0.691976, acc.: 56.25%] [G loss: 0.951413]\n",
      "epoch:6 step:5219 [D loss: 0.724537, acc.: 50.00%] [G loss: 0.996807]\n",
      "epoch:6 step:5220 [D loss: 0.693069, acc.: 56.25%] [G loss: 0.917227]\n",
      "epoch:6 step:5221 [D loss: 0.721512, acc.: 50.00%] [G loss: 0.934757]\n",
      "epoch:6 step:5222 [D loss: 0.627762, acc.: 67.19%] [G loss: 1.004874]\n",
      "epoch:6 step:5223 [D loss: 0.686528, acc.: 58.59%] [G loss: 0.823182]\n",
      "epoch:6 step:5224 [D loss: 0.662032, acc.: 61.72%] [G loss: 0.915769]\n",
      "epoch:6 step:5225 [D loss: 0.637832, acc.: 66.41%] [G loss: 0.962485]\n",
      "epoch:6 step:5226 [D loss: 0.626912, acc.: 67.97%] [G loss: 0.912381]\n",
      "epoch:6 step:5227 [D loss: 0.645949, acc.: 62.50%] [G loss: 0.924926]\n",
      "epoch:6 step:5228 [D loss: 0.658532, acc.: 60.16%] [G loss: 0.909679]\n",
      "epoch:6 step:5229 [D loss: 0.674700, acc.: 60.94%] [G loss: 0.882946]\n",
      "epoch:6 step:5230 [D loss: 0.633359, acc.: 62.50%] [G loss: 0.921473]\n",
      "epoch:6 step:5231 [D loss: 0.654565, acc.: 63.28%] [G loss: 0.939776]\n",
      "epoch:6 step:5232 [D loss: 0.766300, acc.: 46.09%] [G loss: 0.780759]\n",
      "epoch:6 step:5233 [D loss: 0.706691, acc.: 52.34%] [G loss: 0.857153]\n",
      "epoch:6 step:5234 [D loss: 0.645800, acc.: 68.75%] [G loss: 0.788029]\n",
      "epoch:6 step:5235 [D loss: 0.645521, acc.: 60.94%] [G loss: 0.788974]\n",
      "epoch:6 step:5236 [D loss: 0.670465, acc.: 57.81%] [G loss: 0.719365]\n",
      "epoch:6 step:5237 [D loss: 0.606607, acc.: 73.44%] [G loss: 0.840693]\n",
      "epoch:6 step:5238 [D loss: 0.702049, acc.: 54.69%] [G loss: 0.830327]\n",
      "epoch:6 step:5239 [D loss: 0.695404, acc.: 59.38%] [G loss: 0.874291]\n",
      "epoch:6 step:5240 [D loss: 0.664146, acc.: 58.59%] [G loss: 0.915794]\n",
      "epoch:6 step:5241 [D loss: 0.627458, acc.: 67.19%] [G loss: 0.865764]\n",
      "epoch:6 step:5242 [D loss: 0.626146, acc.: 69.53%] [G loss: 0.805222]\n",
      "epoch:6 step:5243 [D loss: 0.753208, acc.: 43.75%] [G loss: 0.734232]\n",
      "epoch:6 step:5244 [D loss: 0.631037, acc.: 68.75%] [G loss: 0.825485]\n",
      "epoch:6 step:5245 [D loss: 0.710142, acc.: 52.34%] [G loss: 0.816414]\n",
      "epoch:6 step:5246 [D loss: 0.769627, acc.: 39.06%] [G loss: 0.822485]\n",
      "epoch:6 step:5247 [D loss: 0.684472, acc.: 52.34%] [G loss: 0.879237]\n",
      "epoch:6 step:5248 [D loss: 0.703041, acc.: 56.25%] [G loss: 0.827912]\n",
      "epoch:6 step:5249 [D loss: 0.739899, acc.: 46.88%] [G loss: 0.710863]\n",
      "epoch:6 step:5250 [D loss: 0.758950, acc.: 46.09%] [G loss: 0.784051]\n",
      "epoch:6 step:5251 [D loss: 0.685971, acc.: 57.03%] [G loss: 0.910852]\n",
      "epoch:6 step:5252 [D loss: 0.655177, acc.: 60.16%] [G loss: 0.924941]\n",
      "epoch:6 step:5253 [D loss: 0.675117, acc.: 64.84%] [G loss: 0.850666]\n",
      "epoch:6 step:5254 [D loss: 0.704371, acc.: 56.25%] [G loss: 0.779552]\n",
      "epoch:6 step:5255 [D loss: 0.705061, acc.: 52.34%] [G loss: 0.798466]\n",
      "epoch:6 step:5256 [D loss: 0.711477, acc.: 55.47%] [G loss: 0.858150]\n",
      "epoch:6 step:5257 [D loss: 0.748479, acc.: 44.53%] [G loss: 0.832462]\n",
      "epoch:6 step:5258 [D loss: 0.695462, acc.: 56.25%] [G loss: 0.749263]\n",
      "epoch:6 step:5259 [D loss: 0.665430, acc.: 67.97%] [G loss: 0.848229]\n",
      "epoch:6 step:5260 [D loss: 0.778159, acc.: 41.41%] [G loss: 0.713884]\n",
      "epoch:6 step:5261 [D loss: 0.742045, acc.: 45.31%] [G loss: 0.790795]\n",
      "epoch:6 step:5262 [D loss: 0.727252, acc.: 49.22%] [G loss: 0.817048]\n",
      "epoch:6 step:5263 [D loss: 0.738373, acc.: 46.09%] [G loss: 0.788459]\n",
      "epoch:6 step:5264 [D loss: 0.708223, acc.: 50.00%] [G loss: 0.764915]\n",
      "epoch:6 step:5265 [D loss: 0.701711, acc.: 54.69%] [G loss: 0.808861]\n",
      "epoch:6 step:5266 [D loss: 0.736141, acc.: 53.12%] [G loss: 0.825695]\n",
      "epoch:6 step:5267 [D loss: 0.675629, acc.: 56.25%] [G loss: 0.745147]\n",
      "epoch:6 step:5268 [D loss: 0.704143, acc.: 54.69%] [G loss: 0.832307]\n",
      "epoch:6 step:5269 [D loss: 0.709548, acc.: 51.56%] [G loss: 0.796346]\n",
      "epoch:6 step:5270 [D loss: 0.763627, acc.: 44.53%] [G loss: 0.822230]\n",
      "epoch:6 step:5271 [D loss: 0.679099, acc.: 60.16%] [G loss: 0.818269]\n",
      "epoch:6 step:5272 [D loss: 0.677320, acc.: 55.47%] [G loss: 0.832833]\n",
      "epoch:6 step:5273 [D loss: 0.649000, acc.: 60.16%] [G loss: 0.831095]\n",
      "epoch:6 step:5274 [D loss: 0.602029, acc.: 73.44%] [G loss: 0.761061]\n",
      "epoch:6 step:5275 [D loss: 0.656229, acc.: 64.06%] [G loss: 0.833578]\n",
      "epoch:6 step:5276 [D loss: 0.650133, acc.: 60.16%] [G loss: 0.732389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5277 [D loss: 0.703629, acc.: 51.56%] [G loss: 0.751147]\n",
      "epoch:6 step:5278 [D loss: 0.669453, acc.: 57.03%] [G loss: 0.813356]\n",
      "epoch:6 step:5279 [D loss: 0.768376, acc.: 42.19%] [G loss: 0.766427]\n",
      "epoch:6 step:5280 [D loss: 0.654037, acc.: 62.50%] [G loss: 0.818304]\n",
      "epoch:6 step:5281 [D loss: 0.709734, acc.: 51.56%] [G loss: 0.798177]\n",
      "epoch:6 step:5282 [D loss: 0.704563, acc.: 58.59%] [G loss: 0.850301]\n",
      "epoch:6 step:5283 [D loss: 0.705774, acc.: 57.81%] [G loss: 0.809948]\n",
      "epoch:6 step:5284 [D loss: 0.639762, acc.: 63.28%] [G loss: 0.919184]\n",
      "epoch:6 step:5285 [D loss: 0.684657, acc.: 58.59%] [G loss: 0.995229]\n",
      "epoch:6 step:5286 [D loss: 0.747233, acc.: 40.62%] [G loss: 0.886326]\n",
      "epoch:6 step:5287 [D loss: 0.652339, acc.: 63.28%] [G loss: 0.776443]\n",
      "epoch:6 step:5288 [D loss: 0.726677, acc.: 50.78%] [G loss: 0.795771]\n",
      "epoch:6 step:5289 [D loss: 0.688630, acc.: 57.81%] [G loss: 0.730039]\n",
      "epoch:6 step:5290 [D loss: 0.700623, acc.: 57.81%] [G loss: 0.808098]\n",
      "epoch:6 step:5291 [D loss: 0.659672, acc.: 57.03%] [G loss: 0.822320]\n",
      "epoch:6 step:5292 [D loss: 0.674460, acc.: 58.59%] [G loss: 0.885921]\n",
      "epoch:6 step:5293 [D loss: 0.696528, acc.: 48.44%] [G loss: 0.893669]\n",
      "epoch:6 step:5294 [D loss: 0.635440, acc.: 62.50%] [G loss: 0.828008]\n",
      "epoch:6 step:5295 [D loss: 0.720586, acc.: 52.34%] [G loss: 0.874131]\n",
      "epoch:6 step:5296 [D loss: 0.674544, acc.: 63.28%] [G loss: 0.861568]\n",
      "epoch:6 step:5297 [D loss: 0.680914, acc.: 57.81%] [G loss: 0.823688]\n",
      "epoch:6 step:5298 [D loss: 0.643405, acc.: 67.19%] [G loss: 0.947783]\n",
      "epoch:6 step:5299 [D loss: 0.708017, acc.: 55.47%] [G loss: 0.819113]\n",
      "epoch:6 step:5300 [D loss: 0.656305, acc.: 58.59%] [G loss: 0.816644]\n",
      "epoch:6 step:5301 [D loss: 0.764445, acc.: 41.41%] [G loss: 0.786110]\n",
      "epoch:6 step:5302 [D loss: 0.674530, acc.: 54.69%] [G loss: 0.825099]\n",
      "epoch:6 step:5303 [D loss: 0.682007, acc.: 57.81%] [G loss: 0.772118]\n",
      "epoch:6 step:5304 [D loss: 0.700128, acc.: 50.78%] [G loss: 0.749776]\n",
      "epoch:6 step:5305 [D loss: 0.709110, acc.: 50.00%] [G loss: 0.767112]\n",
      "epoch:6 step:5306 [D loss: 0.649587, acc.: 57.81%] [G loss: 0.746830]\n",
      "epoch:6 step:5307 [D loss: 0.729527, acc.: 50.00%] [G loss: 0.824901]\n",
      "epoch:6 step:5308 [D loss: 0.765792, acc.: 43.75%] [G loss: 0.705560]\n",
      "epoch:6 step:5309 [D loss: 0.681704, acc.: 58.59%] [G loss: 0.944611]\n",
      "epoch:6 step:5310 [D loss: 0.722458, acc.: 51.56%] [G loss: 0.746508]\n",
      "epoch:6 step:5311 [D loss: 0.741539, acc.: 47.66%] [G loss: 0.791901]\n",
      "epoch:6 step:5312 [D loss: 0.720693, acc.: 54.69%] [G loss: 0.861877]\n",
      "epoch:6 step:5313 [D loss: 0.702334, acc.: 53.12%] [G loss: 0.835650]\n",
      "epoch:6 step:5314 [D loss: 0.652435, acc.: 62.50%] [G loss: 0.827401]\n",
      "epoch:6 step:5315 [D loss: 0.738200, acc.: 51.56%] [G loss: 0.861754]\n",
      "epoch:6 step:5316 [D loss: 0.709769, acc.: 52.34%] [G loss: 0.776443]\n",
      "epoch:6 step:5317 [D loss: 0.729962, acc.: 46.09%] [G loss: 0.821766]\n",
      "epoch:6 step:5318 [D loss: 0.736180, acc.: 52.34%] [G loss: 0.780926]\n",
      "epoch:6 step:5319 [D loss: 0.686390, acc.: 54.69%] [G loss: 0.795932]\n",
      "epoch:6 step:5320 [D loss: 0.705566, acc.: 53.91%] [G loss: 0.762068]\n",
      "epoch:6 step:5321 [D loss: 0.600796, acc.: 73.44%] [G loss: 0.690051]\n",
      "epoch:6 step:5322 [D loss: 0.592927, acc.: 68.75%] [G loss: 0.841936]\n",
      "epoch:6 step:5323 [D loss: 0.771589, acc.: 47.66%] [G loss: 0.898602]\n",
      "epoch:6 step:5324 [D loss: 0.611177, acc.: 71.09%] [G loss: 0.837216]\n",
      "epoch:6 step:5325 [D loss: 0.648426, acc.: 64.84%] [G loss: 0.806026]\n",
      "epoch:6 step:5326 [D loss: 0.738727, acc.: 41.41%] [G loss: 0.737174]\n",
      "epoch:6 step:5327 [D loss: 0.695602, acc.: 59.38%] [G loss: 0.824707]\n",
      "epoch:6 step:5328 [D loss: 0.690228, acc.: 49.22%] [G loss: 0.823229]\n",
      "epoch:6 step:5329 [D loss: 0.805193, acc.: 34.38%] [G loss: 0.746084]\n",
      "epoch:6 step:5330 [D loss: 0.682467, acc.: 58.59%] [G loss: 0.782535]\n",
      "epoch:6 step:5331 [D loss: 0.723467, acc.: 52.34%] [G loss: 0.923959]\n",
      "epoch:6 step:5332 [D loss: 0.753555, acc.: 46.88%] [G loss: 0.859392]\n",
      "epoch:6 step:5333 [D loss: 0.664924, acc.: 62.50%] [G loss: 0.741459]\n",
      "epoch:6 step:5334 [D loss: 0.704594, acc.: 54.69%] [G loss: 0.727094]\n",
      "epoch:6 step:5335 [D loss: 0.739912, acc.: 43.75%] [G loss: 0.852583]\n",
      "epoch:6 step:5336 [D loss: 0.705239, acc.: 54.69%] [G loss: 0.853209]\n",
      "epoch:6 step:5337 [D loss: 0.734452, acc.: 46.88%] [G loss: 0.797230]\n",
      "epoch:6 step:5338 [D loss: 0.691181, acc.: 56.25%] [G loss: 0.732719]\n",
      "epoch:6 step:5339 [D loss: 0.742825, acc.: 48.44%] [G loss: 0.796204]\n",
      "epoch:6 step:5340 [D loss: 0.705987, acc.: 52.34%] [G loss: 0.789697]\n",
      "epoch:6 step:5341 [D loss: 0.712357, acc.: 55.47%] [G loss: 0.835979]\n",
      "epoch:6 step:5342 [D loss: 0.702170, acc.: 55.47%] [G loss: 0.770927]\n",
      "epoch:6 step:5343 [D loss: 0.742895, acc.: 47.66%] [G loss: 0.803237]\n",
      "epoch:6 step:5344 [D loss: 0.666515, acc.: 54.69%] [G loss: 0.855805]\n",
      "epoch:6 step:5345 [D loss: 0.697620, acc.: 61.72%] [G loss: 0.933225]\n",
      "epoch:6 step:5346 [D loss: 0.694943, acc.: 53.91%] [G loss: 0.898453]\n",
      "epoch:6 step:5347 [D loss: 0.688399, acc.: 54.69%] [G loss: 0.814044]\n",
      "epoch:6 step:5348 [D loss: 0.735744, acc.: 46.09%] [G loss: 0.828369]\n",
      "epoch:6 step:5349 [D loss: 0.689931, acc.: 54.69%] [G loss: 0.895278]\n",
      "epoch:6 step:5350 [D loss: 0.657242, acc.: 59.38%] [G loss: 0.904224]\n",
      "epoch:6 step:5351 [D loss: 0.640727, acc.: 61.72%] [G loss: 0.935999]\n",
      "epoch:6 step:5352 [D loss: 0.649662, acc.: 64.06%] [G loss: 1.031948]\n",
      "epoch:6 step:5353 [D loss: 0.669032, acc.: 57.81%] [G loss: 0.875059]\n",
      "epoch:6 step:5354 [D loss: 0.633803, acc.: 60.94%] [G loss: 0.795327]\n",
      "epoch:6 step:5355 [D loss: 0.647054, acc.: 65.62%] [G loss: 0.830352]\n",
      "epoch:6 step:5356 [D loss: 0.654877, acc.: 58.59%] [G loss: 0.921959]\n",
      "epoch:6 step:5357 [D loss: 0.680515, acc.: 58.59%] [G loss: 0.741017]\n",
      "epoch:6 step:5358 [D loss: 0.664885, acc.: 62.50%] [G loss: 0.804047]\n",
      "epoch:6 step:5359 [D loss: 0.710434, acc.: 53.12%] [G loss: 0.754156]\n",
      "epoch:6 step:5360 [D loss: 0.696397, acc.: 59.38%] [G loss: 0.741538]\n",
      "epoch:6 step:5361 [D loss: 0.758983, acc.: 39.84%] [G loss: 0.764672]\n",
      "epoch:6 step:5362 [D loss: 0.663315, acc.: 64.06%] [G loss: 0.724276]\n",
      "epoch:6 step:5363 [D loss: 0.755721, acc.: 40.62%] [G loss: 0.817481]\n",
      "epoch:6 step:5364 [D loss: 0.709977, acc.: 50.00%] [G loss: 0.810913]\n",
      "epoch:6 step:5365 [D loss: 0.702192, acc.: 50.00%] [G loss: 0.848377]\n",
      "epoch:6 step:5366 [D loss: 0.684622, acc.: 54.69%] [G loss: 0.803940]\n",
      "epoch:6 step:5367 [D loss: 0.709691, acc.: 50.00%] [G loss: 0.842589]\n",
      "epoch:6 step:5368 [D loss: 0.720169, acc.: 50.00%] [G loss: 0.862248]\n",
      "epoch:6 step:5369 [D loss: 0.677827, acc.: 56.25%] [G loss: 0.819554]\n",
      "epoch:6 step:5370 [D loss: 0.678804, acc.: 60.94%] [G loss: 0.789499]\n",
      "epoch:6 step:5371 [D loss: 0.750010, acc.: 49.22%] [G loss: 0.799957]\n",
      "epoch:6 step:5372 [D loss: 0.687446, acc.: 56.25%] [G loss: 0.811055]\n",
      "epoch:6 step:5373 [D loss: 0.691538, acc.: 55.47%] [G loss: 0.845330]\n",
      "epoch:6 step:5374 [D loss: 0.753007, acc.: 46.88%] [G loss: 0.838405]\n",
      "epoch:6 step:5375 [D loss: 0.728174, acc.: 48.44%] [G loss: 0.846163]\n",
      "epoch:6 step:5376 [D loss: 0.603861, acc.: 72.66%] [G loss: 0.904166]\n",
      "epoch:6 step:5377 [D loss: 0.682374, acc.: 58.59%] [G loss: 0.876869]\n",
      "epoch:6 step:5378 [D loss: 0.695514, acc.: 57.81%] [G loss: 0.861984]\n",
      "epoch:6 step:5379 [D loss: 0.636281, acc.: 66.41%] [G loss: 0.870458]\n",
      "epoch:6 step:5380 [D loss: 0.630555, acc.: 67.19%] [G loss: 0.797527]\n",
      "epoch:6 step:5381 [D loss: 0.606506, acc.: 75.00%] [G loss: 0.856384]\n",
      "epoch:6 step:5382 [D loss: 0.712126, acc.: 46.88%] [G loss: 0.790878]\n",
      "epoch:6 step:5383 [D loss: 0.680613, acc.: 61.72%] [G loss: 0.864334]\n",
      "epoch:6 step:5384 [D loss: 0.684276, acc.: 59.38%] [G loss: 0.807441]\n",
      "epoch:6 step:5385 [D loss: 0.668765, acc.: 51.56%] [G loss: 0.823814]\n",
      "epoch:6 step:5386 [D loss: 0.675322, acc.: 54.69%] [G loss: 0.732744]\n",
      "epoch:6 step:5387 [D loss: 0.719841, acc.: 50.78%] [G loss: 0.905452]\n",
      "epoch:6 step:5388 [D loss: 0.708997, acc.: 55.47%] [G loss: 0.805276]\n",
      "epoch:6 step:5389 [D loss: 0.760901, acc.: 42.19%] [G loss: 0.696638]\n",
      "epoch:6 step:5390 [D loss: 0.732505, acc.: 50.78%] [G loss: 0.792162]\n",
      "epoch:6 step:5391 [D loss: 0.698080, acc.: 53.12%] [G loss: 0.776022]\n",
      "epoch:6 step:5392 [D loss: 0.581038, acc.: 71.09%] [G loss: 0.772947]\n",
      "epoch:6 step:5393 [D loss: 0.702033, acc.: 53.12%] [G loss: 0.754986]\n",
      "epoch:6 step:5394 [D loss: 0.772031, acc.: 42.19%] [G loss: 0.764438]\n",
      "epoch:6 step:5395 [D loss: 0.759298, acc.: 47.66%] [G loss: 0.759547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5396 [D loss: 0.754305, acc.: 42.97%] [G loss: 0.800714]\n",
      "epoch:6 step:5397 [D loss: 0.694623, acc.: 53.12%] [G loss: 0.943316]\n",
      "epoch:6 step:5398 [D loss: 0.757857, acc.: 44.53%] [G loss: 0.942467]\n",
      "epoch:6 step:5399 [D loss: 0.746238, acc.: 46.88%] [G loss: 0.856265]\n",
      "epoch:6 step:5400 [D loss: 0.705426, acc.: 52.34%] [G loss: 0.911887]\n",
      "epoch:6 step:5401 [D loss: 0.729886, acc.: 47.66%] [G loss: 0.800653]\n",
      "epoch:6 step:5402 [D loss: 0.635919, acc.: 71.88%] [G loss: 0.837376]\n",
      "epoch:6 step:5403 [D loss: 0.619785, acc.: 71.88%] [G loss: 0.844955]\n",
      "epoch:6 step:5404 [D loss: 0.683189, acc.: 51.56%] [G loss: 0.779354]\n",
      "epoch:6 step:5405 [D loss: 0.700913, acc.: 50.78%] [G loss: 0.839465]\n",
      "epoch:6 step:5406 [D loss: 0.625365, acc.: 68.75%] [G loss: 0.928939]\n",
      "epoch:6 step:5407 [D loss: 0.683879, acc.: 50.78%] [G loss: 0.823418]\n",
      "epoch:6 step:5408 [D loss: 0.641382, acc.: 64.84%] [G loss: 0.712612]\n",
      "epoch:6 step:5409 [D loss: 0.610531, acc.: 68.75%] [G loss: 0.664082]\n",
      "epoch:6 step:5410 [D loss: 0.670023, acc.: 60.16%] [G loss: 0.695072]\n",
      "epoch:6 step:5411 [D loss: 0.647498, acc.: 62.50%] [G loss: 0.784580]\n",
      "epoch:6 step:5412 [D loss: 0.696748, acc.: 49.22%] [G loss: 0.874290]\n",
      "epoch:6 step:5413 [D loss: 0.662614, acc.: 57.03%] [G loss: 0.756263]\n",
      "epoch:6 step:5414 [D loss: 0.693714, acc.: 58.59%] [G loss: 0.789896]\n",
      "epoch:6 step:5415 [D loss: 0.697524, acc.: 53.12%] [G loss: 0.753560]\n",
      "epoch:6 step:5416 [D loss: 0.663110, acc.: 60.94%] [G loss: 0.681993]\n",
      "epoch:6 step:5417 [D loss: 0.727783, acc.: 48.44%] [G loss: 0.726195]\n",
      "epoch:6 step:5418 [D loss: 0.791210, acc.: 39.06%] [G loss: 0.775609]\n",
      "epoch:6 step:5419 [D loss: 0.703811, acc.: 46.09%] [G loss: 0.767198]\n",
      "epoch:6 step:5420 [D loss: 0.687483, acc.: 56.25%] [G loss: 0.803410]\n",
      "epoch:6 step:5421 [D loss: 0.773926, acc.: 40.62%] [G loss: 0.827397]\n",
      "epoch:6 step:5422 [D loss: 0.625237, acc.: 62.50%] [G loss: 0.838024]\n",
      "epoch:6 step:5423 [D loss: 0.716630, acc.: 52.34%] [G loss: 0.757897]\n",
      "epoch:6 step:5424 [D loss: 0.692336, acc.: 53.91%] [G loss: 0.887682]\n",
      "epoch:6 step:5425 [D loss: 0.701722, acc.: 52.34%] [G loss: 0.880808]\n",
      "epoch:6 step:5426 [D loss: 0.631081, acc.: 64.84%] [G loss: 0.907470]\n",
      "epoch:6 step:5427 [D loss: 0.677978, acc.: 55.47%] [G loss: 0.838060]\n",
      "epoch:6 step:5428 [D loss: 0.714516, acc.: 52.34%] [G loss: 0.807996]\n",
      "epoch:6 step:5429 [D loss: 0.679127, acc.: 59.38%] [G loss: 0.801596]\n",
      "epoch:6 step:5430 [D loss: 0.670888, acc.: 58.59%] [G loss: 0.863179]\n",
      "epoch:6 step:5431 [D loss: 0.621907, acc.: 75.00%] [G loss: 0.790659]\n",
      "epoch:6 step:5432 [D loss: 0.730915, acc.: 46.88%] [G loss: 0.775733]\n",
      "epoch:6 step:5433 [D loss: 0.682264, acc.: 60.16%] [G loss: 0.822294]\n",
      "epoch:6 step:5434 [D loss: 0.690650, acc.: 59.38%] [G loss: 0.798525]\n",
      "epoch:6 step:5435 [D loss: 0.651989, acc.: 55.47%] [G loss: 0.803993]\n",
      "epoch:6 step:5436 [D loss: 0.665253, acc.: 57.81%] [G loss: 0.903144]\n",
      "epoch:6 step:5437 [D loss: 0.655080, acc.: 64.84%] [G loss: 0.877791]\n",
      "epoch:6 step:5438 [D loss: 0.658794, acc.: 62.50%] [G loss: 0.798693]\n",
      "epoch:6 step:5439 [D loss: 0.724321, acc.: 50.00%] [G loss: 0.837736]\n",
      "epoch:6 step:5440 [D loss: 0.676362, acc.: 58.59%] [G loss: 0.790209]\n",
      "epoch:6 step:5441 [D loss: 0.725222, acc.: 50.00%] [G loss: 0.818515]\n",
      "epoch:6 step:5442 [D loss: 0.722962, acc.: 50.78%] [G loss: 0.859505]\n",
      "epoch:6 step:5443 [D loss: 0.726882, acc.: 47.66%] [G loss: 0.867065]\n",
      "epoch:6 step:5444 [D loss: 0.698660, acc.: 56.25%] [G loss: 0.806302]\n",
      "epoch:6 step:5445 [D loss: 0.723200, acc.: 42.97%] [G loss: 0.805544]\n",
      "epoch:6 step:5446 [D loss: 0.739224, acc.: 45.31%] [G loss: 0.761058]\n",
      "epoch:6 step:5447 [D loss: 0.699009, acc.: 58.59%] [G loss: 0.810029]\n",
      "epoch:6 step:5448 [D loss: 0.776820, acc.: 44.53%] [G loss: 0.802430]\n",
      "epoch:6 step:5449 [D loss: 0.720538, acc.: 53.12%] [G loss: 0.826844]\n",
      "epoch:6 step:5450 [D loss: 0.693274, acc.: 51.56%] [G loss: 0.736517]\n",
      "epoch:6 step:5451 [D loss: 0.686190, acc.: 60.16%] [G loss: 0.726165]\n",
      "epoch:6 step:5452 [D loss: 0.721493, acc.: 50.00%] [G loss: 0.869223]\n",
      "epoch:6 step:5453 [D loss: 0.703972, acc.: 57.81%] [G loss: 0.788389]\n",
      "epoch:6 step:5454 [D loss: 0.672285, acc.: 60.16%] [G loss: 0.787311]\n",
      "epoch:6 step:5455 [D loss: 0.709968, acc.: 46.09%] [G loss: 0.759804]\n",
      "epoch:6 step:5456 [D loss: 0.669093, acc.: 63.28%] [G loss: 0.857235]\n",
      "epoch:6 step:5457 [D loss: 0.701272, acc.: 53.12%] [G loss: 0.765003]\n",
      "epoch:6 step:5458 [D loss: 0.652896, acc.: 61.72%] [G loss: 0.861884]\n",
      "epoch:6 step:5459 [D loss: 0.689649, acc.: 57.03%] [G loss: 0.811886]\n",
      "epoch:6 step:5460 [D loss: 0.690009, acc.: 57.03%] [G loss: 0.784031]\n",
      "epoch:6 step:5461 [D loss: 0.714293, acc.: 49.22%] [G loss: 0.757278]\n",
      "epoch:6 step:5462 [D loss: 0.736504, acc.: 50.00%] [G loss: 0.795455]\n",
      "epoch:6 step:5463 [D loss: 0.660441, acc.: 59.38%] [G loss: 0.761788]\n",
      "epoch:6 step:5464 [D loss: 0.729307, acc.: 46.09%] [G loss: 0.710448]\n",
      "epoch:6 step:5465 [D loss: 0.750774, acc.: 45.31%] [G loss: 0.774620]\n",
      "epoch:6 step:5466 [D loss: 0.751069, acc.: 43.75%] [G loss: 0.757673]\n",
      "epoch:6 step:5467 [D loss: 0.624593, acc.: 70.31%] [G loss: 0.836935]\n",
      "epoch:7 step:5468 [D loss: 0.670859, acc.: 61.72%] [G loss: 0.873393]\n",
      "epoch:7 step:5469 [D loss: 0.697399, acc.: 51.56%] [G loss: 0.811826]\n",
      "epoch:7 step:5470 [D loss: 0.676161, acc.: 62.50%] [G loss: 0.881620]\n",
      "epoch:7 step:5471 [D loss: 0.705904, acc.: 52.34%] [G loss: 0.852898]\n",
      "epoch:7 step:5472 [D loss: 0.757544, acc.: 42.97%] [G loss: 0.714256]\n",
      "epoch:7 step:5473 [D loss: 0.684140, acc.: 57.03%] [G loss: 0.762985]\n",
      "epoch:7 step:5474 [D loss: 0.677713, acc.: 57.03%] [G loss: 0.762406]\n",
      "epoch:7 step:5475 [D loss: 0.715634, acc.: 57.03%] [G loss: 0.841767]\n",
      "epoch:7 step:5476 [D loss: 0.673864, acc.: 57.81%] [G loss: 0.826758]\n",
      "epoch:7 step:5477 [D loss: 0.677119, acc.: 53.12%] [G loss: 0.835416]\n",
      "epoch:7 step:5478 [D loss: 0.725015, acc.: 48.44%] [G loss: 0.821903]\n",
      "epoch:7 step:5479 [D loss: 0.646882, acc.: 64.84%] [G loss: 0.918832]\n",
      "epoch:7 step:5480 [D loss: 0.666274, acc.: 62.50%] [G loss: 0.832544]\n",
      "epoch:7 step:5481 [D loss: 0.713831, acc.: 47.66%] [G loss: 0.835001]\n",
      "epoch:7 step:5482 [D loss: 0.736100, acc.: 52.34%] [G loss: 0.792315]\n",
      "epoch:7 step:5483 [D loss: 0.693413, acc.: 56.25%] [G loss: 0.755206]\n",
      "epoch:7 step:5484 [D loss: 0.729864, acc.: 40.62%] [G loss: 0.820729]\n",
      "epoch:7 step:5485 [D loss: 0.703826, acc.: 54.69%] [G loss: 0.812996]\n",
      "epoch:7 step:5486 [D loss: 0.713774, acc.: 48.44%] [G loss: 0.817746]\n",
      "epoch:7 step:5487 [D loss: 0.714216, acc.: 47.66%] [G loss: 0.868847]\n",
      "epoch:7 step:5488 [D loss: 0.673420, acc.: 57.03%] [G loss: 0.876687]\n",
      "epoch:7 step:5489 [D loss: 0.695358, acc.: 53.12%] [G loss: 0.880205]\n",
      "epoch:7 step:5490 [D loss: 0.723704, acc.: 47.66%] [G loss: 0.910949]\n",
      "epoch:7 step:5491 [D loss: 0.673580, acc.: 59.38%] [G loss: 0.813759]\n",
      "epoch:7 step:5492 [D loss: 0.733919, acc.: 52.34%] [G loss: 0.851617]\n",
      "epoch:7 step:5493 [D loss: 0.643422, acc.: 62.50%] [G loss: 0.761312]\n",
      "epoch:7 step:5494 [D loss: 0.666277, acc.: 64.84%] [G loss: 0.758165]\n",
      "epoch:7 step:5495 [D loss: 0.663618, acc.: 64.84%] [G loss: 0.792328]\n",
      "epoch:7 step:5496 [D loss: 0.663374, acc.: 55.47%] [G loss: 0.803325]\n",
      "epoch:7 step:5497 [D loss: 0.654502, acc.: 63.28%] [G loss: 0.824928]\n",
      "epoch:7 step:5498 [D loss: 0.732532, acc.: 47.66%] [G loss: 0.769881]\n",
      "epoch:7 step:5499 [D loss: 0.725334, acc.: 47.66%] [G loss: 0.817178]\n",
      "epoch:7 step:5500 [D loss: 0.679335, acc.: 52.34%] [G loss: 0.855174]\n",
      "epoch:7 step:5501 [D loss: 0.692095, acc.: 54.69%] [G loss: 0.813374]\n",
      "epoch:7 step:5502 [D loss: 0.664531, acc.: 62.50%] [G loss: 0.808818]\n",
      "epoch:7 step:5503 [D loss: 0.693424, acc.: 53.91%] [G loss: 0.876236]\n",
      "epoch:7 step:5504 [D loss: 0.724451, acc.: 50.00%] [G loss: 0.791276]\n",
      "epoch:7 step:5505 [D loss: 0.747636, acc.: 45.31%] [G loss: 0.731595]\n",
      "epoch:7 step:5506 [D loss: 0.685868, acc.: 57.03%] [G loss: 0.812630]\n",
      "epoch:7 step:5507 [D loss: 0.705427, acc.: 51.56%] [G loss: 0.889397]\n",
      "epoch:7 step:5508 [D loss: 0.704177, acc.: 55.47%] [G loss: 0.780045]\n",
      "epoch:7 step:5509 [D loss: 0.711586, acc.: 48.44%] [G loss: 0.802042]\n",
      "epoch:7 step:5510 [D loss: 0.693470, acc.: 55.47%] [G loss: 0.743904]\n",
      "epoch:7 step:5511 [D loss: 0.705892, acc.: 51.56%] [G loss: 0.796186]\n",
      "epoch:7 step:5512 [D loss: 0.677985, acc.: 54.69%] [G loss: 0.835508]\n",
      "epoch:7 step:5513 [D loss: 0.647826, acc.: 63.28%] [G loss: 0.828191]\n",
      "epoch:7 step:5514 [D loss: 0.691131, acc.: 58.59%] [G loss: 0.861009]\n",
      "epoch:7 step:5515 [D loss: 0.681233, acc.: 57.81%] [G loss: 0.928433]\n",
      "epoch:7 step:5516 [D loss: 0.678225, acc.: 54.69%] [G loss: 0.910380]\n",
      "epoch:7 step:5517 [D loss: 0.736306, acc.: 52.34%] [G loss: 0.827426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5518 [D loss: 0.712570, acc.: 53.12%] [G loss: 0.815039]\n",
      "epoch:7 step:5519 [D loss: 0.710022, acc.: 50.78%] [G loss: 0.870955]\n",
      "epoch:7 step:5520 [D loss: 0.657658, acc.: 60.16%] [G loss: 0.895995]\n",
      "epoch:7 step:5521 [D loss: 0.720833, acc.: 46.09%] [G loss: 0.752387]\n",
      "epoch:7 step:5522 [D loss: 0.697368, acc.: 56.25%] [G loss: 0.788078]\n",
      "epoch:7 step:5523 [D loss: 0.700621, acc.: 59.38%] [G loss: 0.794600]\n",
      "epoch:7 step:5524 [D loss: 0.598077, acc.: 69.53%] [G loss: 0.882409]\n",
      "epoch:7 step:5525 [D loss: 0.699691, acc.: 53.12%] [G loss: 0.777990]\n",
      "epoch:7 step:5526 [D loss: 0.645694, acc.: 64.06%] [G loss: 0.787852]\n",
      "epoch:7 step:5527 [D loss: 0.706191, acc.: 46.09%] [G loss: 0.848537]\n",
      "epoch:7 step:5528 [D loss: 0.730913, acc.: 46.09%] [G loss: 0.825532]\n",
      "epoch:7 step:5529 [D loss: 0.656621, acc.: 57.81%] [G loss: 0.951102]\n",
      "epoch:7 step:5530 [D loss: 0.660544, acc.: 65.62%] [G loss: 0.825138]\n",
      "epoch:7 step:5531 [D loss: 0.663768, acc.: 62.50%] [G loss: 0.826834]\n",
      "epoch:7 step:5532 [D loss: 0.647117, acc.: 60.16%] [G loss: 0.881711]\n",
      "epoch:7 step:5533 [D loss: 0.756730, acc.: 41.41%] [G loss: 0.751310]\n",
      "epoch:7 step:5534 [D loss: 0.695871, acc.: 56.25%] [G loss: 0.838244]\n",
      "epoch:7 step:5535 [D loss: 0.663342, acc.: 60.94%] [G loss: 0.842232]\n",
      "epoch:7 step:5536 [D loss: 0.677816, acc.: 58.59%] [G loss: 0.778738]\n",
      "epoch:7 step:5537 [D loss: 0.743874, acc.: 47.66%] [G loss: 0.839744]\n",
      "epoch:7 step:5538 [D loss: 0.719239, acc.: 45.31%] [G loss: 0.771864]\n",
      "epoch:7 step:5539 [D loss: 0.655370, acc.: 63.28%] [G loss: 0.765568]\n",
      "epoch:7 step:5540 [D loss: 0.736666, acc.: 47.66%] [G loss: 0.712229]\n",
      "epoch:7 step:5541 [D loss: 0.704024, acc.: 53.91%] [G loss: 0.719938]\n",
      "epoch:7 step:5542 [D loss: 0.713427, acc.: 46.88%] [G loss: 0.850420]\n",
      "epoch:7 step:5543 [D loss: 0.804868, acc.: 38.28%] [G loss: 0.825676]\n",
      "epoch:7 step:5544 [D loss: 0.725876, acc.: 46.88%] [G loss: 0.779282]\n",
      "epoch:7 step:5545 [D loss: 0.728486, acc.: 50.00%] [G loss: 0.936937]\n",
      "epoch:7 step:5546 [D loss: 0.667078, acc.: 59.38%] [G loss: 0.877671]\n",
      "epoch:7 step:5547 [D loss: 0.654626, acc.: 56.25%] [G loss: 0.888302]\n",
      "epoch:7 step:5548 [D loss: 0.618974, acc.: 71.09%] [G loss: 0.794542]\n",
      "epoch:7 step:5549 [D loss: 0.769040, acc.: 43.75%] [G loss: 0.795797]\n",
      "epoch:7 step:5550 [D loss: 0.703609, acc.: 49.22%] [G loss: 0.769786]\n",
      "epoch:7 step:5551 [D loss: 0.721619, acc.: 50.00%] [G loss: 0.841752]\n",
      "epoch:7 step:5552 [D loss: 0.697714, acc.: 53.91%] [G loss: 0.863318]\n",
      "epoch:7 step:5553 [D loss: 0.647295, acc.: 60.16%] [G loss: 0.916147]\n",
      "epoch:7 step:5554 [D loss: 0.706019, acc.: 52.34%] [G loss: 0.913096]\n",
      "epoch:7 step:5555 [D loss: 0.705746, acc.: 50.00%] [G loss: 0.803976]\n",
      "epoch:7 step:5556 [D loss: 0.674867, acc.: 56.25%] [G loss: 0.961522]\n",
      "epoch:7 step:5557 [D loss: 0.647395, acc.: 56.25%] [G loss: 0.914794]\n",
      "epoch:7 step:5558 [D loss: 0.666444, acc.: 63.28%] [G loss: 0.803346]\n",
      "epoch:7 step:5559 [D loss: 0.703402, acc.: 52.34%] [G loss: 0.745262]\n",
      "epoch:7 step:5560 [D loss: 0.713962, acc.: 50.78%] [G loss: 0.731318]\n",
      "epoch:7 step:5561 [D loss: 0.695816, acc.: 54.69%] [G loss: 0.814116]\n",
      "epoch:7 step:5562 [D loss: 0.688497, acc.: 57.03%] [G loss: 0.813238]\n",
      "epoch:7 step:5563 [D loss: 0.723804, acc.: 44.53%] [G loss: 0.978143]\n",
      "epoch:7 step:5564 [D loss: 0.688098, acc.: 57.03%] [G loss: 0.898436]\n",
      "epoch:7 step:5565 [D loss: 0.626609, acc.: 63.28%] [G loss: 0.876927]\n",
      "epoch:7 step:5566 [D loss: 0.656352, acc.: 64.06%] [G loss: 0.741751]\n",
      "epoch:7 step:5567 [D loss: 0.722240, acc.: 48.44%] [G loss: 0.736014]\n",
      "epoch:7 step:5568 [D loss: 0.637704, acc.: 64.06%] [G loss: 0.824516]\n",
      "epoch:7 step:5569 [D loss: 0.727300, acc.: 45.31%] [G loss: 0.821904]\n",
      "epoch:7 step:5570 [D loss: 0.757787, acc.: 42.19%] [G loss: 0.754352]\n",
      "epoch:7 step:5571 [D loss: 0.744946, acc.: 49.22%] [G loss: 0.724872]\n",
      "epoch:7 step:5572 [D loss: 0.695984, acc.: 56.25%] [G loss: 0.731508]\n",
      "epoch:7 step:5573 [D loss: 0.682847, acc.: 53.91%] [G loss: 0.797568]\n",
      "epoch:7 step:5574 [D loss: 0.670901, acc.: 57.03%] [G loss: 0.815391]\n",
      "epoch:7 step:5575 [D loss: 0.819243, acc.: 37.50%] [G loss: 0.811588]\n",
      "epoch:7 step:5576 [D loss: 0.743909, acc.: 50.78%] [G loss: 0.802876]\n",
      "epoch:7 step:5577 [D loss: 0.705121, acc.: 48.44%] [G loss: 0.757864]\n",
      "epoch:7 step:5578 [D loss: 0.700046, acc.: 48.44%] [G loss: 0.740433]\n",
      "epoch:7 step:5579 [D loss: 0.682477, acc.: 53.12%] [G loss: 0.801914]\n",
      "epoch:7 step:5580 [D loss: 0.658954, acc.: 64.06%] [G loss: 0.817812]\n",
      "epoch:7 step:5581 [D loss: 0.677893, acc.: 57.81%] [G loss: 0.778870]\n",
      "epoch:7 step:5582 [D loss: 0.641741, acc.: 65.62%] [G loss: 0.822084]\n",
      "epoch:7 step:5583 [D loss: 0.695935, acc.: 52.34%] [G loss: 0.799737]\n",
      "epoch:7 step:5584 [D loss: 0.635293, acc.: 63.28%] [G loss: 0.764365]\n",
      "epoch:7 step:5585 [D loss: 0.681616, acc.: 57.81%] [G loss: 0.804988]\n",
      "epoch:7 step:5586 [D loss: 0.668427, acc.: 58.59%] [G loss: 0.825160]\n",
      "epoch:7 step:5587 [D loss: 0.668189, acc.: 59.38%] [G loss: 0.834323]\n",
      "epoch:7 step:5588 [D loss: 0.651820, acc.: 65.62%] [G loss: 0.937733]\n",
      "epoch:7 step:5589 [D loss: 0.695542, acc.: 51.56%] [G loss: 0.808436]\n",
      "epoch:7 step:5590 [D loss: 0.702890, acc.: 56.25%] [G loss: 0.847795]\n",
      "epoch:7 step:5591 [D loss: 0.690674, acc.: 54.69%] [G loss: 0.718759]\n",
      "epoch:7 step:5592 [D loss: 0.718116, acc.: 53.12%] [G loss: 0.725212]\n",
      "epoch:7 step:5593 [D loss: 0.662387, acc.: 60.94%] [G loss: 0.779670]\n",
      "epoch:7 step:5594 [D loss: 0.618278, acc.: 67.19%] [G loss: 0.809510]\n",
      "epoch:7 step:5595 [D loss: 0.698792, acc.: 55.47%] [G loss: 0.860438]\n",
      "epoch:7 step:5596 [D loss: 0.715587, acc.: 48.44%] [G loss: 0.781976]\n",
      "epoch:7 step:5597 [D loss: 0.653412, acc.: 60.16%] [G loss: 0.836431]\n",
      "epoch:7 step:5598 [D loss: 0.627651, acc.: 71.88%] [G loss: 0.718685]\n",
      "epoch:7 step:5599 [D loss: 0.673064, acc.: 57.81%] [G loss: 0.738824]\n",
      "epoch:7 step:5600 [D loss: 0.639763, acc.: 69.53%] [G loss: 0.772693]\n",
      "epoch:7 step:5601 [D loss: 0.764620, acc.: 39.84%] [G loss: 0.752686]\n",
      "epoch:7 step:5602 [D loss: 0.733046, acc.: 47.66%] [G loss: 0.631235]\n",
      "epoch:7 step:5603 [D loss: 0.678700, acc.: 58.59%] [G loss: 0.688186]\n",
      "epoch:7 step:5604 [D loss: 0.731633, acc.: 48.44%] [G loss: 0.754382]\n",
      "epoch:7 step:5605 [D loss: 0.691355, acc.: 58.59%] [G loss: 0.695557]\n",
      "epoch:7 step:5606 [D loss: 0.784247, acc.: 44.53%] [G loss: 0.792839]\n",
      "epoch:7 step:5607 [D loss: 0.736674, acc.: 40.62%] [G loss: 0.859077]\n",
      "epoch:7 step:5608 [D loss: 0.722241, acc.: 50.00%] [G loss: 0.784096]\n",
      "epoch:7 step:5609 [D loss: 0.710957, acc.: 51.56%] [G loss: 0.785197]\n",
      "epoch:7 step:5610 [D loss: 0.757819, acc.: 47.66%] [G loss: 0.730592]\n",
      "epoch:7 step:5611 [D loss: 0.667827, acc.: 58.59%] [G loss: 0.867958]\n",
      "epoch:7 step:5612 [D loss: 0.656630, acc.: 63.28%] [G loss: 0.877958]\n",
      "epoch:7 step:5613 [D loss: 0.693176, acc.: 57.03%] [G loss: 0.845013]\n",
      "epoch:7 step:5614 [D loss: 0.683775, acc.: 51.56%] [G loss: 0.761073]\n",
      "epoch:7 step:5615 [D loss: 0.645249, acc.: 64.84%] [G loss: 0.957295]\n",
      "epoch:7 step:5616 [D loss: 0.696652, acc.: 57.81%] [G loss: 0.820852]\n",
      "epoch:7 step:5617 [D loss: 0.670710, acc.: 56.25%] [G loss: 0.830005]\n",
      "epoch:7 step:5618 [D loss: 0.733599, acc.: 47.66%] [G loss: 0.725672]\n",
      "epoch:7 step:5619 [D loss: 0.696375, acc.: 55.47%] [G loss: 0.744864]\n",
      "epoch:7 step:5620 [D loss: 0.629580, acc.: 63.28%] [G loss: 0.789473]\n",
      "epoch:7 step:5621 [D loss: 0.703463, acc.: 50.78%] [G loss: 0.757122]\n",
      "epoch:7 step:5622 [D loss: 0.725748, acc.: 53.12%] [G loss: 0.677427]\n",
      "epoch:7 step:5623 [D loss: 0.652599, acc.: 58.59%] [G loss: 0.842221]\n",
      "epoch:7 step:5624 [D loss: 0.635013, acc.: 66.41%] [G loss: 0.675891]\n",
      "epoch:7 step:5625 [D loss: 0.662466, acc.: 53.12%] [G loss: 0.738084]\n",
      "epoch:7 step:5626 [D loss: 0.733405, acc.: 50.00%] [G loss: 0.670402]\n",
      "epoch:7 step:5627 [D loss: 0.656411, acc.: 60.94%] [G loss: 0.825277]\n",
      "epoch:7 step:5628 [D loss: 0.828419, acc.: 34.38%] [G loss: 0.822050]\n",
      "epoch:7 step:5629 [D loss: 0.760082, acc.: 44.53%] [G loss: 0.779650]\n",
      "epoch:7 step:5630 [D loss: 0.745401, acc.: 41.41%] [G loss: 0.763363]\n",
      "epoch:7 step:5631 [D loss: 0.674999, acc.: 59.38%] [G loss: 0.899378]\n",
      "epoch:7 step:5632 [D loss: 0.713748, acc.: 54.69%] [G loss: 0.818752]\n",
      "epoch:7 step:5633 [D loss: 0.619729, acc.: 63.28%] [G loss: 0.831113]\n",
      "epoch:7 step:5634 [D loss: 0.757886, acc.: 40.62%] [G loss: 0.839284]\n",
      "epoch:7 step:5635 [D loss: 0.643771, acc.: 61.72%] [G loss: 0.835840]\n",
      "epoch:7 step:5636 [D loss: 0.659079, acc.: 62.50%] [G loss: 0.842307]\n",
      "epoch:7 step:5637 [D loss: 0.594353, acc.: 74.22%] [G loss: 1.021901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5638 [D loss: 0.664953, acc.: 58.59%] [G loss: 0.905511]\n",
      "epoch:7 step:5639 [D loss: 0.653549, acc.: 64.84%] [G loss: 0.870849]\n",
      "epoch:7 step:5640 [D loss: 0.633530, acc.: 63.28%] [G loss: 0.943318]\n",
      "epoch:7 step:5641 [D loss: 0.632409, acc.: 65.62%] [G loss: 0.941880]\n",
      "epoch:7 step:5642 [D loss: 0.601710, acc.: 70.31%] [G loss: 0.828789]\n",
      "epoch:7 step:5643 [D loss: 0.696412, acc.: 53.91%] [G loss: 0.856795]\n",
      "epoch:7 step:5644 [D loss: 0.588270, acc.: 68.75%] [G loss: 0.826050]\n",
      "epoch:7 step:5645 [D loss: 0.693694, acc.: 60.16%] [G loss: 0.832070]\n",
      "epoch:7 step:5646 [D loss: 0.603060, acc.: 70.31%] [G loss: 0.742575]\n",
      "epoch:7 step:5647 [D loss: 0.636546, acc.: 71.88%] [G loss: 0.780435]\n",
      "epoch:7 step:5648 [D loss: 0.653770, acc.: 56.25%] [G loss: 0.786505]\n",
      "epoch:7 step:5649 [D loss: 0.706163, acc.: 53.12%] [G loss: 0.684043]\n",
      "epoch:7 step:5650 [D loss: 0.719251, acc.: 52.34%] [G loss: 0.771216]\n",
      "epoch:7 step:5651 [D loss: 0.779188, acc.: 39.06%] [G loss: 0.782457]\n",
      "epoch:7 step:5652 [D loss: 0.696626, acc.: 53.91%] [G loss: 0.736890]\n",
      "epoch:7 step:5653 [D loss: 0.721218, acc.: 46.09%] [G loss: 0.826766]\n",
      "epoch:7 step:5654 [D loss: 0.725763, acc.: 46.88%] [G loss: 0.758225]\n",
      "epoch:7 step:5655 [D loss: 0.787199, acc.: 39.06%] [G loss: 0.700729]\n",
      "epoch:7 step:5656 [D loss: 0.738778, acc.: 41.41%] [G loss: 0.709893]\n",
      "epoch:7 step:5657 [D loss: 0.653344, acc.: 60.94%] [G loss: 0.671306]\n",
      "epoch:7 step:5658 [D loss: 0.737688, acc.: 53.12%] [G loss: 0.708864]\n",
      "epoch:7 step:5659 [D loss: 0.650504, acc.: 59.38%] [G loss: 0.743872]\n",
      "epoch:7 step:5660 [D loss: 0.711196, acc.: 55.47%] [G loss: 0.810349]\n",
      "epoch:7 step:5661 [D loss: 0.714985, acc.: 51.56%] [G loss: 0.806151]\n",
      "epoch:7 step:5662 [D loss: 0.740233, acc.: 42.97%] [G loss: 0.845650]\n",
      "epoch:7 step:5663 [D loss: 0.675341, acc.: 62.50%] [G loss: 0.848804]\n",
      "epoch:7 step:5664 [D loss: 0.704648, acc.: 53.12%] [G loss: 0.927527]\n",
      "epoch:7 step:5665 [D loss: 0.640279, acc.: 64.06%] [G loss: 0.938486]\n",
      "epoch:7 step:5666 [D loss: 0.652073, acc.: 64.06%] [G loss: 0.810338]\n",
      "epoch:7 step:5667 [D loss: 0.659953, acc.: 62.50%] [G loss: 0.798935]\n",
      "epoch:7 step:5668 [D loss: 0.602866, acc.: 71.09%] [G loss: 0.878782]\n",
      "epoch:7 step:5669 [D loss: 0.732644, acc.: 43.75%] [G loss: 0.751708]\n",
      "epoch:7 step:5670 [D loss: 0.624983, acc.: 70.31%] [G loss: 0.780689]\n",
      "epoch:7 step:5671 [D loss: 0.741164, acc.: 47.66%] [G loss: 0.715888]\n",
      "epoch:7 step:5672 [D loss: 0.713527, acc.: 54.69%] [G loss: 0.723101]\n",
      "epoch:7 step:5673 [D loss: 0.671852, acc.: 61.72%] [G loss: 0.729990]\n",
      "epoch:7 step:5674 [D loss: 0.634426, acc.: 64.06%] [G loss: 0.787123]\n",
      "epoch:7 step:5675 [D loss: 0.709869, acc.: 50.00%] [G loss: 0.819260]\n",
      "epoch:7 step:5676 [D loss: 0.661625, acc.: 67.19%] [G loss: 0.671568]\n",
      "epoch:7 step:5677 [D loss: 0.596090, acc.: 68.75%] [G loss: 0.724535]\n",
      "epoch:7 step:5678 [D loss: 0.707397, acc.: 49.22%] [G loss: 0.685677]\n",
      "epoch:7 step:5679 [D loss: 0.700661, acc.: 53.12%] [G loss: 0.803748]\n",
      "epoch:7 step:5680 [D loss: 0.784349, acc.: 44.53%] [G loss: 0.727620]\n",
      "epoch:7 step:5681 [D loss: 0.649081, acc.: 66.41%] [G loss: 0.754955]\n",
      "epoch:7 step:5682 [D loss: 0.743156, acc.: 46.09%] [G loss: 0.686412]\n",
      "epoch:7 step:5683 [D loss: 0.708145, acc.: 47.66%] [G loss: 0.765570]\n",
      "epoch:7 step:5684 [D loss: 0.740940, acc.: 53.12%] [G loss: 0.732698]\n",
      "epoch:7 step:5685 [D loss: 0.693697, acc.: 53.12%] [G loss: 0.889384]\n",
      "epoch:7 step:5686 [D loss: 0.719102, acc.: 49.22%] [G loss: 0.753902]\n",
      "epoch:7 step:5687 [D loss: 0.692282, acc.: 50.78%] [G loss: 0.841430]\n",
      "epoch:7 step:5688 [D loss: 0.697663, acc.: 51.56%] [G loss: 0.742778]\n",
      "epoch:7 step:5689 [D loss: 0.651791, acc.: 60.16%] [G loss: 0.755608]\n",
      "epoch:7 step:5690 [D loss: 0.695173, acc.: 58.59%] [G loss: 0.770135]\n",
      "epoch:7 step:5691 [D loss: 0.719677, acc.: 56.25%] [G loss: 0.819843]\n",
      "epoch:7 step:5692 [D loss: 0.681509, acc.: 60.16%] [G loss: 0.889829]\n",
      "epoch:7 step:5693 [D loss: 0.712613, acc.: 52.34%] [G loss: 0.741688]\n",
      "epoch:7 step:5694 [D loss: 0.683450, acc.: 57.81%] [G loss: 0.843086]\n",
      "epoch:7 step:5695 [D loss: 0.676310, acc.: 55.47%] [G loss: 0.848478]\n",
      "epoch:7 step:5696 [D loss: 0.715534, acc.: 50.78%] [G loss: 0.930668]\n",
      "epoch:7 step:5697 [D loss: 0.655520, acc.: 60.94%] [G loss: 0.976460]\n",
      "epoch:7 step:5698 [D loss: 0.706135, acc.: 54.69%] [G loss: 0.898636]\n",
      "epoch:7 step:5699 [D loss: 0.728534, acc.: 44.53%] [G loss: 0.901497]\n",
      "epoch:7 step:5700 [D loss: 0.649741, acc.: 61.72%] [G loss: 0.855586]\n",
      "epoch:7 step:5701 [D loss: 0.655361, acc.: 60.94%] [G loss: 0.934699]\n",
      "epoch:7 step:5702 [D loss: 0.625609, acc.: 70.31%] [G loss: 0.919778]\n",
      "epoch:7 step:5703 [D loss: 0.633704, acc.: 65.62%] [G loss: 0.874459]\n",
      "epoch:7 step:5704 [D loss: 0.573253, acc.: 79.69%] [G loss: 0.871565]\n",
      "epoch:7 step:5705 [D loss: 0.641604, acc.: 68.75%] [G loss: 0.793676]\n",
      "epoch:7 step:5706 [D loss: 0.642222, acc.: 67.19%] [G loss: 0.823770]\n",
      "epoch:7 step:5707 [D loss: 0.736023, acc.: 46.09%] [G loss: 0.828580]\n",
      "epoch:7 step:5708 [D loss: 0.641479, acc.: 62.50%] [G loss: 0.775200]\n",
      "epoch:7 step:5709 [D loss: 0.592318, acc.: 71.88%] [G loss: 0.890518]\n",
      "epoch:7 step:5710 [D loss: 0.541965, acc.: 78.91%] [G loss: 0.862449]\n",
      "epoch:7 step:5711 [D loss: 0.568448, acc.: 74.22%] [G loss: 0.837721]\n",
      "epoch:7 step:5712 [D loss: 0.603423, acc.: 67.97%] [G loss: 0.805810]\n",
      "epoch:7 step:5713 [D loss: 0.591295, acc.: 73.44%] [G loss: 0.790768]\n",
      "epoch:7 step:5714 [D loss: 0.660635, acc.: 55.47%] [G loss: 0.742101]\n",
      "epoch:7 step:5715 [D loss: 0.597838, acc.: 74.22%] [G loss: 0.629268]\n",
      "epoch:7 step:5716 [D loss: 0.628032, acc.: 65.62%] [G loss: 0.719914]\n",
      "epoch:7 step:5717 [D loss: 0.651106, acc.: 63.28%] [G loss: 0.705019]\n",
      "epoch:7 step:5718 [D loss: 0.595280, acc.: 71.88%] [G loss: 0.669378]\n",
      "epoch:7 step:5719 [D loss: 0.697407, acc.: 51.56%] [G loss: 0.670554]\n",
      "epoch:7 step:5720 [D loss: 0.675138, acc.: 53.91%] [G loss: 0.782975]\n",
      "epoch:7 step:5721 [D loss: 0.770973, acc.: 37.50%] [G loss: 0.752275]\n",
      "epoch:7 step:5722 [D loss: 0.719689, acc.: 49.22%] [G loss: 0.710447]\n",
      "epoch:7 step:5723 [D loss: 0.705934, acc.: 46.09%] [G loss: 0.617936]\n",
      "epoch:7 step:5724 [D loss: 0.703846, acc.: 53.12%] [G loss: 0.630666]\n",
      "epoch:7 step:5725 [D loss: 0.751932, acc.: 42.19%] [G loss: 0.638696]\n",
      "epoch:7 step:5726 [D loss: 0.721707, acc.: 49.22%] [G loss: 0.751027]\n",
      "epoch:7 step:5727 [D loss: 0.745244, acc.: 44.53%] [G loss: 0.749487]\n",
      "epoch:7 step:5728 [D loss: 0.738928, acc.: 50.00%] [G loss: 0.838831]\n",
      "epoch:7 step:5729 [D loss: 0.662184, acc.: 60.16%] [G loss: 0.823969]\n",
      "epoch:7 step:5730 [D loss: 0.762010, acc.: 44.53%] [G loss: 0.825783]\n",
      "epoch:7 step:5731 [D loss: 0.723166, acc.: 50.00%] [G loss: 0.802380]\n",
      "epoch:7 step:5732 [D loss: 0.717963, acc.: 53.12%] [G loss: 0.782238]\n",
      "epoch:7 step:5733 [D loss: 0.724792, acc.: 50.00%] [G loss: 0.811969]\n",
      "epoch:7 step:5734 [D loss: 0.625204, acc.: 70.31%] [G loss: 0.808928]\n",
      "epoch:7 step:5735 [D loss: 0.605306, acc.: 71.09%] [G loss: 0.801239]\n",
      "epoch:7 step:5736 [D loss: 0.647359, acc.: 62.50%] [G loss: 0.748598]\n",
      "epoch:7 step:5737 [D loss: 0.524839, acc.: 80.47%] [G loss: 0.940670]\n",
      "epoch:7 step:5738 [D loss: 0.577734, acc.: 73.44%] [G loss: 0.759107]\n",
      "epoch:7 step:5739 [D loss: 0.604387, acc.: 64.06%] [G loss: 0.667562]\n",
      "epoch:7 step:5740 [D loss: 0.595728, acc.: 74.22%] [G loss: 0.739879]\n",
      "epoch:7 step:5741 [D loss: 0.712061, acc.: 56.25%] [G loss: 0.635111]\n",
      "epoch:7 step:5742 [D loss: 0.628361, acc.: 66.41%] [G loss: 0.606726]\n",
      "epoch:7 step:5743 [D loss: 0.663740, acc.: 64.84%] [G loss: 0.739815]\n",
      "epoch:7 step:5744 [D loss: 0.649617, acc.: 67.97%] [G loss: 0.595696]\n",
      "epoch:7 step:5745 [D loss: 0.663978, acc.: 60.94%] [G loss: 0.689395]\n",
      "epoch:7 step:5746 [D loss: 0.737872, acc.: 50.00%] [G loss: 0.678477]\n",
      "epoch:7 step:5747 [D loss: 0.695866, acc.: 53.91%] [G loss: 0.646684]\n",
      "epoch:7 step:5748 [D loss: 0.718104, acc.: 50.00%] [G loss: 0.544938]\n",
      "epoch:7 step:5749 [D loss: 0.743709, acc.: 49.22%] [G loss: 0.619515]\n",
      "epoch:7 step:5750 [D loss: 0.837716, acc.: 30.47%] [G loss: 0.684603]\n",
      "epoch:7 step:5751 [D loss: 0.824729, acc.: 34.38%] [G loss: 0.759947]\n",
      "epoch:7 step:5752 [D loss: 0.782309, acc.: 32.03%] [G loss: 0.850887]\n",
      "epoch:7 step:5753 [D loss: 0.735088, acc.: 46.88%] [G loss: 0.891785]\n",
      "epoch:7 step:5754 [D loss: 0.777025, acc.: 46.88%] [G loss: 0.943954]\n",
      "epoch:7 step:5755 [D loss: 0.692793, acc.: 54.69%] [G loss: 0.913947]\n",
      "epoch:7 step:5756 [D loss: 0.715936, acc.: 46.88%] [G loss: 0.863973]\n",
      "epoch:7 step:5757 [D loss: 0.738991, acc.: 44.53%] [G loss: 0.821268]\n",
      "epoch:7 step:5758 [D loss: 0.779020, acc.: 39.06%] [G loss: 0.781049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5759 [D loss: 0.671227, acc.: 58.59%] [G loss: 0.882058]\n",
      "epoch:7 step:5760 [D loss: 0.659272, acc.: 64.84%] [G loss: 0.883035]\n",
      "epoch:7 step:5761 [D loss: 0.738104, acc.: 45.31%] [G loss: 0.912405]\n",
      "epoch:7 step:5762 [D loss: 0.747895, acc.: 47.66%] [G loss: 0.880083]\n",
      "epoch:7 step:5763 [D loss: 0.719168, acc.: 54.69%] [G loss: 0.873015]\n",
      "epoch:7 step:5764 [D loss: 0.708345, acc.: 56.25%] [G loss: 0.820121]\n",
      "epoch:7 step:5765 [D loss: 0.611304, acc.: 70.31%] [G loss: 0.897003]\n",
      "epoch:7 step:5766 [D loss: 0.748809, acc.: 42.97%] [G loss: 0.865679]\n",
      "epoch:7 step:5767 [D loss: 0.635060, acc.: 68.75%] [G loss: 0.796878]\n",
      "epoch:7 step:5768 [D loss: 0.743540, acc.: 50.78%] [G loss: 0.892813]\n",
      "epoch:7 step:5769 [D loss: 0.645843, acc.: 57.81%] [G loss: 0.879956]\n",
      "epoch:7 step:5770 [D loss: 0.672892, acc.: 60.16%] [G loss: 0.925530]\n",
      "epoch:7 step:5771 [D loss: 0.672847, acc.: 62.50%] [G loss: 0.866684]\n",
      "epoch:7 step:5772 [D loss: 0.726924, acc.: 50.78%] [G loss: 0.792724]\n",
      "epoch:7 step:5773 [D loss: 0.694706, acc.: 53.91%] [G loss: 0.779335]\n",
      "epoch:7 step:5774 [D loss: 0.675286, acc.: 62.50%] [G loss: 0.777914]\n",
      "epoch:7 step:5775 [D loss: 0.616851, acc.: 69.53%] [G loss: 0.882686]\n",
      "epoch:7 step:5776 [D loss: 0.696453, acc.: 54.69%] [G loss: 0.704971]\n",
      "epoch:7 step:5777 [D loss: 0.648194, acc.: 61.72%] [G loss: 0.771369]\n",
      "epoch:7 step:5778 [D loss: 0.708036, acc.: 48.44%] [G loss: 0.718878]\n",
      "epoch:7 step:5779 [D loss: 0.649880, acc.: 58.59%] [G loss: 0.730075]\n",
      "epoch:7 step:5780 [D loss: 0.845130, acc.: 31.25%] [G loss: 0.658242]\n",
      "epoch:7 step:5781 [D loss: 0.695884, acc.: 53.12%] [G loss: 0.708472]\n",
      "epoch:7 step:5782 [D loss: 0.759326, acc.: 42.19%] [G loss: 0.646372]\n",
      "epoch:7 step:5783 [D loss: 0.701335, acc.: 54.69%] [G loss: 0.647249]\n",
      "epoch:7 step:5784 [D loss: 0.717608, acc.: 57.81%] [G loss: 0.784497]\n",
      "epoch:7 step:5785 [D loss: 0.652885, acc.: 62.50%] [G loss: 0.779835]\n",
      "epoch:7 step:5786 [D loss: 0.685160, acc.: 58.59%] [G loss: 0.731024]\n",
      "epoch:7 step:5787 [D loss: 0.698086, acc.: 54.69%] [G loss: 0.743264]\n",
      "epoch:7 step:5788 [D loss: 0.706434, acc.: 51.56%] [G loss: 0.710121]\n",
      "epoch:7 step:5789 [D loss: 0.678071, acc.: 55.47%] [G loss: 0.722234]\n",
      "epoch:7 step:5790 [D loss: 0.702337, acc.: 56.25%] [G loss: 0.910648]\n",
      "epoch:7 step:5791 [D loss: 0.743707, acc.: 45.31%] [G loss: 0.760998]\n",
      "epoch:7 step:5792 [D loss: 0.674195, acc.: 53.12%] [G loss: 1.006804]\n",
      "epoch:7 step:5793 [D loss: 0.707228, acc.: 51.56%] [G loss: 0.943588]\n",
      "epoch:7 step:5794 [D loss: 0.682013, acc.: 58.59%] [G loss: 0.920633]\n",
      "epoch:7 step:5795 [D loss: 0.692762, acc.: 50.00%] [G loss: 0.802529]\n",
      "epoch:7 step:5796 [D loss: 0.687410, acc.: 50.78%] [G loss: 0.832321]\n",
      "epoch:7 step:5797 [D loss: 0.657989, acc.: 60.94%] [G loss: 0.875949]\n",
      "epoch:7 step:5798 [D loss: 0.620402, acc.: 67.19%] [G loss: 0.843851]\n",
      "epoch:7 step:5799 [D loss: 0.616585, acc.: 67.97%] [G loss: 0.838499]\n",
      "epoch:7 step:5800 [D loss: 0.605680, acc.: 68.75%] [G loss: 0.750035]\n",
      "epoch:7 step:5801 [D loss: 0.564741, acc.: 78.12%] [G loss: 0.821154]\n",
      "epoch:7 step:5802 [D loss: 0.551971, acc.: 75.78%] [G loss: 0.727030]\n",
      "epoch:7 step:5803 [D loss: 0.559601, acc.: 75.00%] [G loss: 0.642407]\n",
      "epoch:7 step:5804 [D loss: 0.575978, acc.: 72.66%] [G loss: 0.631440]\n",
      "epoch:7 step:5805 [D loss: 0.542638, acc.: 77.34%] [G loss: 0.555815]\n",
      "epoch:7 step:5806 [D loss: 0.689262, acc.: 55.47%] [G loss: 0.541461]\n",
      "epoch:7 step:5807 [D loss: 0.644682, acc.: 62.50%] [G loss: 0.658114]\n",
      "epoch:7 step:5808 [D loss: 0.676328, acc.: 56.25%] [G loss: 0.681122]\n",
      "epoch:7 step:5809 [D loss: 0.683275, acc.: 56.25%] [G loss: 0.594999]\n",
      "epoch:7 step:5810 [D loss: 0.819951, acc.: 37.50%] [G loss: 0.685152]\n",
      "epoch:7 step:5811 [D loss: 0.734731, acc.: 47.66%] [G loss: 0.648984]\n",
      "epoch:7 step:5812 [D loss: 0.825517, acc.: 37.50%] [G loss: 0.571316]\n",
      "epoch:7 step:5813 [D loss: 0.728457, acc.: 45.31%] [G loss: 0.635288]\n",
      "epoch:7 step:5814 [D loss: 0.742393, acc.: 46.09%] [G loss: 0.662429]\n",
      "epoch:7 step:5815 [D loss: 0.805887, acc.: 38.28%] [G loss: 0.672928]\n",
      "epoch:7 step:5816 [D loss: 0.788396, acc.: 32.81%] [G loss: 0.780036]\n",
      "epoch:7 step:5817 [D loss: 0.750316, acc.: 47.66%] [G loss: 0.761375]\n",
      "epoch:7 step:5818 [D loss: 0.854734, acc.: 28.12%] [G loss: 0.753347]\n",
      "epoch:7 step:5819 [D loss: 0.743690, acc.: 39.84%] [G loss: 0.756008]\n",
      "epoch:7 step:5820 [D loss: 0.732722, acc.: 50.78%] [G loss: 0.845609]\n",
      "epoch:7 step:5821 [D loss: 0.707271, acc.: 51.56%] [G loss: 0.914040]\n",
      "epoch:7 step:5822 [D loss: 0.686579, acc.: 55.47%] [G loss: 0.966874]\n",
      "epoch:7 step:5823 [D loss: 0.654421, acc.: 63.28%] [G loss: 0.881523]\n",
      "epoch:7 step:5824 [D loss: 0.645480, acc.: 64.84%] [G loss: 0.943579]\n",
      "epoch:7 step:5825 [D loss: 0.612046, acc.: 69.53%] [G loss: 0.995276]\n",
      "epoch:7 step:5826 [D loss: 0.648607, acc.: 58.59%] [G loss: 0.987383]\n",
      "epoch:7 step:5827 [D loss: 0.637366, acc.: 66.41%] [G loss: 1.043115]\n",
      "epoch:7 step:5828 [D loss: 0.662734, acc.: 57.81%] [G loss: 0.975239]\n",
      "epoch:7 step:5829 [D loss: 0.599868, acc.: 71.09%] [G loss: 0.946924]\n",
      "epoch:7 step:5830 [D loss: 0.751924, acc.: 48.44%] [G loss: 0.831904]\n",
      "epoch:7 step:5831 [D loss: 0.670175, acc.: 57.03%] [G loss: 0.776425]\n",
      "epoch:7 step:5832 [D loss: 0.633826, acc.: 67.97%] [G loss: 0.672566]\n",
      "epoch:7 step:5833 [D loss: 0.614834, acc.: 64.84%] [G loss: 0.699043]\n",
      "epoch:7 step:5834 [D loss: 0.632599, acc.: 67.97%] [G loss: 0.817762]\n",
      "epoch:7 step:5835 [D loss: 0.612787, acc.: 67.97%] [G loss: 0.801660]\n",
      "epoch:7 step:5836 [D loss: 0.789156, acc.: 39.84%] [G loss: 0.810237]\n",
      "epoch:7 step:5837 [D loss: 0.685856, acc.: 60.94%] [G loss: 0.828885]\n",
      "epoch:7 step:5838 [D loss: 0.682450, acc.: 56.25%] [G loss: 0.839594]\n",
      "epoch:7 step:5839 [D loss: 0.683360, acc.: 55.47%] [G loss: 0.845721]\n",
      "epoch:7 step:5840 [D loss: 0.667886, acc.: 59.38%] [G loss: 0.774903]\n",
      "epoch:7 step:5841 [D loss: 0.709759, acc.: 46.88%] [G loss: 0.771637]\n",
      "epoch:7 step:5842 [D loss: 0.741720, acc.: 46.09%] [G loss: 0.738332]\n",
      "epoch:7 step:5843 [D loss: 0.681187, acc.: 59.38%] [G loss: 0.786629]\n",
      "epoch:7 step:5844 [D loss: 0.677547, acc.: 63.28%] [G loss: 0.808319]\n",
      "epoch:7 step:5845 [D loss: 0.677570, acc.: 58.59%] [G loss: 0.819860]\n",
      "epoch:7 step:5846 [D loss: 0.686731, acc.: 53.12%] [G loss: 0.786572]\n",
      "epoch:7 step:5847 [D loss: 0.722258, acc.: 50.00%] [G loss: 0.836046]\n",
      "epoch:7 step:5848 [D loss: 0.641493, acc.: 66.41%] [G loss: 0.942567]\n",
      "epoch:7 step:5849 [D loss: 0.664189, acc.: 57.81%] [G loss: 0.891578]\n",
      "epoch:7 step:5850 [D loss: 0.693659, acc.: 53.91%] [G loss: 0.826880]\n",
      "epoch:7 step:5851 [D loss: 0.635739, acc.: 61.72%] [G loss: 0.793761]\n",
      "epoch:7 step:5852 [D loss: 0.700121, acc.: 54.69%] [G loss: 0.937012]\n",
      "epoch:7 step:5853 [D loss: 0.638130, acc.: 63.28%] [G loss: 0.816235]\n",
      "epoch:7 step:5854 [D loss: 0.717538, acc.: 50.00%] [G loss: 0.801170]\n",
      "epoch:7 step:5855 [D loss: 0.720383, acc.: 52.34%] [G loss: 0.863724]\n",
      "epoch:7 step:5856 [D loss: 0.709413, acc.: 51.56%] [G loss: 0.932921]\n",
      "epoch:7 step:5857 [D loss: 0.657087, acc.: 54.69%] [G loss: 0.856086]\n",
      "epoch:7 step:5858 [D loss: 0.777722, acc.: 41.41%] [G loss: 0.785548]\n",
      "epoch:7 step:5859 [D loss: 0.706499, acc.: 57.03%] [G loss: 0.765237]\n",
      "epoch:7 step:5860 [D loss: 0.675518, acc.: 57.81%] [G loss: 0.740424]\n",
      "epoch:7 step:5861 [D loss: 0.700683, acc.: 46.88%] [G loss: 0.702772]\n",
      "epoch:7 step:5862 [D loss: 0.711332, acc.: 48.44%] [G loss: 0.624837]\n",
      "epoch:7 step:5863 [D loss: 0.673019, acc.: 59.38%] [G loss: 0.731311]\n",
      "epoch:7 step:5864 [D loss: 0.729272, acc.: 53.12%] [G loss: 0.733528]\n",
      "epoch:7 step:5865 [D loss: 0.697137, acc.: 54.69%] [G loss: 0.728075]\n",
      "epoch:7 step:5866 [D loss: 0.692225, acc.: 57.81%] [G loss: 0.773866]\n",
      "epoch:7 step:5867 [D loss: 0.687557, acc.: 52.34%] [G loss: 0.760022]\n",
      "epoch:7 step:5868 [D loss: 0.737061, acc.: 47.66%] [G loss: 0.729223]\n",
      "epoch:7 step:5869 [D loss: 0.677844, acc.: 64.06%] [G loss: 0.748347]\n",
      "epoch:7 step:5870 [D loss: 0.688032, acc.: 52.34%] [G loss: 0.759912]\n",
      "epoch:7 step:5871 [D loss: 0.661647, acc.: 60.94%] [G loss: 0.802151]\n",
      "epoch:7 step:5872 [D loss: 0.710740, acc.: 53.91%] [G loss: 0.835009]\n",
      "epoch:7 step:5873 [D loss: 0.691429, acc.: 53.91%] [G loss: 0.727460]\n",
      "epoch:7 step:5874 [D loss: 0.700949, acc.: 52.34%] [G loss: 0.798204]\n",
      "epoch:7 step:5875 [D loss: 0.762940, acc.: 38.28%] [G loss: 0.800593]\n",
      "epoch:7 step:5876 [D loss: 0.655489, acc.: 57.81%] [G loss: 0.811087]\n",
      "epoch:7 step:5877 [D loss: 0.683793, acc.: 59.38%] [G loss: 0.659264]\n",
      "epoch:7 step:5878 [D loss: 0.770497, acc.: 47.66%] [G loss: 0.860507]\n",
      "epoch:7 step:5879 [D loss: 0.683332, acc.: 54.69%] [G loss: 0.699484]\n",
      "epoch:7 step:5880 [D loss: 0.709439, acc.: 53.12%] [G loss: 0.740569]\n",
      "epoch:7 step:5881 [D loss: 0.692085, acc.: 50.78%] [G loss: 0.783674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5882 [D loss: 0.699525, acc.: 53.91%] [G loss: 0.815432]\n",
      "epoch:7 step:5883 [D loss: 0.706247, acc.: 53.12%] [G loss: 0.843647]\n",
      "epoch:7 step:5884 [D loss: 0.696404, acc.: 55.47%] [G loss: 0.810111]\n",
      "epoch:7 step:5885 [D loss: 0.669525, acc.: 57.81%] [G loss: 0.801701]\n",
      "epoch:7 step:5886 [D loss: 0.712968, acc.: 50.78%] [G loss: 0.742236]\n",
      "epoch:7 step:5887 [D loss: 0.714440, acc.: 51.56%] [G loss: 0.874746]\n",
      "epoch:7 step:5888 [D loss: 0.678617, acc.: 61.72%] [G loss: 0.821555]\n",
      "epoch:7 step:5889 [D loss: 0.688889, acc.: 49.22%] [G loss: 0.804495]\n",
      "epoch:7 step:5890 [D loss: 0.672944, acc.: 61.72%] [G loss: 0.776578]\n",
      "epoch:7 step:5891 [D loss: 0.733184, acc.: 47.66%] [G loss: 0.775484]\n",
      "epoch:7 step:5892 [D loss: 0.635439, acc.: 63.28%] [G loss: 0.783122]\n",
      "epoch:7 step:5893 [D loss: 0.721935, acc.: 48.44%] [G loss: 0.760129]\n",
      "epoch:7 step:5894 [D loss: 0.688916, acc.: 57.03%] [G loss: 0.763703]\n",
      "epoch:7 step:5895 [D loss: 0.763770, acc.: 40.62%] [G loss: 0.772235]\n",
      "epoch:7 step:5896 [D loss: 0.748799, acc.: 45.31%] [G loss: 0.806625]\n",
      "epoch:7 step:5897 [D loss: 0.728780, acc.: 46.88%] [G loss: 0.795041]\n",
      "epoch:7 step:5898 [D loss: 0.782743, acc.: 38.28%] [G loss: 0.713796]\n",
      "epoch:7 step:5899 [D loss: 0.720173, acc.: 52.34%] [G loss: 0.793215]\n",
      "epoch:7 step:5900 [D loss: 0.674208, acc.: 57.81%] [G loss: 0.712301]\n",
      "epoch:7 step:5901 [D loss: 0.722845, acc.: 46.09%] [G loss: 0.795931]\n",
      "epoch:7 step:5902 [D loss: 0.629222, acc.: 67.19%] [G loss: 0.870053]\n",
      "epoch:7 step:5903 [D loss: 0.732198, acc.: 46.09%] [G loss: 0.822461]\n",
      "epoch:7 step:5904 [D loss: 0.716611, acc.: 52.34%] [G loss: 0.825201]\n",
      "epoch:7 step:5905 [D loss: 0.705309, acc.: 48.44%] [G loss: 0.743587]\n",
      "epoch:7 step:5906 [D loss: 0.674912, acc.: 57.03%] [G loss: 0.814597]\n",
      "epoch:7 step:5907 [D loss: 0.734939, acc.: 46.88%] [G loss: 0.809346]\n",
      "epoch:7 step:5908 [D loss: 0.718350, acc.: 45.31%] [G loss: 0.827938]\n",
      "epoch:7 step:5909 [D loss: 0.709266, acc.: 50.00%] [G loss: 0.795808]\n",
      "epoch:7 step:5910 [D loss: 0.612645, acc.: 70.31%] [G loss: 0.854321]\n",
      "epoch:7 step:5911 [D loss: 0.698714, acc.: 52.34%] [G loss: 0.817355]\n",
      "epoch:7 step:5912 [D loss: 0.749565, acc.: 43.75%] [G loss: 0.703713]\n",
      "epoch:7 step:5913 [D loss: 0.775550, acc.: 36.72%] [G loss: 0.759967]\n",
      "epoch:7 step:5914 [D loss: 0.699577, acc.: 52.34%] [G loss: 0.729983]\n",
      "epoch:7 step:5915 [D loss: 0.778568, acc.: 39.06%] [G loss: 0.795316]\n",
      "epoch:7 step:5916 [D loss: 0.630877, acc.: 69.53%] [G loss: 0.831451]\n",
      "epoch:7 step:5917 [D loss: 0.660577, acc.: 60.16%] [G loss: 0.803661]\n",
      "epoch:7 step:5918 [D loss: 0.683097, acc.: 57.81%] [G loss: 0.850064]\n",
      "epoch:7 step:5919 [D loss: 0.652514, acc.: 64.06%] [G loss: 0.870371]\n",
      "epoch:7 step:5920 [D loss: 0.741765, acc.: 47.66%] [G loss: 0.834780]\n",
      "epoch:7 step:5921 [D loss: 0.715814, acc.: 46.09%] [G loss: 0.805805]\n",
      "epoch:7 step:5922 [D loss: 0.666683, acc.: 61.72%] [G loss: 0.832837]\n",
      "epoch:7 step:5923 [D loss: 0.633246, acc.: 61.72%] [G loss: 0.851616]\n",
      "epoch:7 step:5924 [D loss: 0.663819, acc.: 60.16%] [G loss: 0.788156]\n",
      "epoch:7 step:5925 [D loss: 0.719615, acc.: 50.00%] [G loss: 0.807666]\n",
      "epoch:7 step:5926 [D loss: 0.769648, acc.: 41.41%] [G loss: 0.770272]\n",
      "epoch:7 step:5927 [D loss: 0.701096, acc.: 54.69%] [G loss: 0.770674]\n",
      "epoch:7 step:5928 [D loss: 0.633478, acc.: 63.28%] [G loss: 0.842193]\n",
      "epoch:7 step:5929 [D loss: 0.668967, acc.: 62.50%] [G loss: 0.780718]\n",
      "epoch:7 step:5930 [D loss: 0.636047, acc.: 65.62%] [G loss: 0.815693]\n",
      "epoch:7 step:5931 [D loss: 0.711354, acc.: 56.25%] [G loss: 0.781138]\n",
      "epoch:7 step:5932 [D loss: 0.707193, acc.: 60.16%] [G loss: 0.747645]\n",
      "epoch:7 step:5933 [D loss: 0.672106, acc.: 62.50%] [G loss: 0.729439]\n",
      "epoch:7 step:5934 [D loss: 0.685488, acc.: 53.91%] [G loss: 0.734863]\n",
      "epoch:7 step:5935 [D loss: 0.648730, acc.: 64.84%] [G loss: 0.855838]\n",
      "epoch:7 step:5936 [D loss: 0.723652, acc.: 44.53%] [G loss: 0.834253]\n",
      "epoch:7 step:5937 [D loss: 0.696069, acc.: 51.56%] [G loss: 0.799240]\n",
      "epoch:7 step:5938 [D loss: 0.673031, acc.: 56.25%] [G loss: 0.799459]\n",
      "epoch:7 step:5939 [D loss: 0.735852, acc.: 46.88%] [G loss: 0.796483]\n",
      "epoch:7 step:5940 [D loss: 0.790945, acc.: 42.97%] [G loss: 0.738145]\n",
      "epoch:7 step:5941 [D loss: 0.673505, acc.: 57.81%] [G loss: 0.819075]\n",
      "epoch:7 step:5942 [D loss: 0.705958, acc.: 50.00%] [G loss: 0.718663]\n",
      "epoch:7 step:5943 [D loss: 0.708291, acc.: 52.34%] [G loss: 0.775410]\n",
      "epoch:7 step:5944 [D loss: 0.717386, acc.: 55.47%] [G loss: 0.801519]\n",
      "epoch:7 step:5945 [D loss: 0.713703, acc.: 53.91%] [G loss: 0.798393]\n",
      "epoch:7 step:5946 [D loss: 0.717460, acc.: 47.66%] [G loss: 0.813318]\n",
      "epoch:7 step:5947 [D loss: 0.699161, acc.: 52.34%] [G loss: 0.941570]\n",
      "epoch:7 step:5948 [D loss: 0.656683, acc.: 60.16%] [G loss: 0.876132]\n",
      "epoch:7 step:5949 [D loss: 0.726019, acc.: 46.88%] [G loss: 0.811290]\n",
      "epoch:7 step:5950 [D loss: 0.663723, acc.: 60.94%] [G loss: 0.784397]\n",
      "epoch:7 step:5951 [D loss: 0.658498, acc.: 59.38%] [G loss: 0.815905]\n",
      "epoch:7 step:5952 [D loss: 0.666313, acc.: 58.59%] [G loss: 0.820137]\n",
      "epoch:7 step:5953 [D loss: 0.623156, acc.: 69.53%] [G loss: 0.898706]\n",
      "epoch:7 step:5954 [D loss: 0.651108, acc.: 64.84%] [G loss: 0.841592]\n",
      "epoch:7 step:5955 [D loss: 0.667470, acc.: 59.38%] [G loss: 0.790800]\n",
      "epoch:7 step:5956 [D loss: 0.707595, acc.: 51.56%] [G loss: 0.750947]\n",
      "epoch:7 step:5957 [D loss: 0.630042, acc.: 69.53%] [G loss: 0.915237]\n",
      "epoch:7 step:5958 [D loss: 0.730994, acc.: 42.97%] [G loss: 0.738011]\n",
      "epoch:7 step:5959 [D loss: 0.657399, acc.: 60.16%] [G loss: 0.769389]\n",
      "epoch:7 step:5960 [D loss: 0.662321, acc.: 60.16%] [G loss: 0.778690]\n",
      "epoch:7 step:5961 [D loss: 0.677480, acc.: 56.25%] [G loss: 0.763959]\n",
      "epoch:7 step:5962 [D loss: 0.700374, acc.: 50.78%] [G loss: 0.776719]\n",
      "epoch:7 step:5963 [D loss: 0.695496, acc.: 57.81%] [G loss: 0.785266]\n",
      "epoch:7 step:5964 [D loss: 0.745449, acc.: 46.09%] [G loss: 0.809200]\n",
      "epoch:7 step:5965 [D loss: 0.777474, acc.: 42.97%] [G loss: 0.745485]\n",
      "epoch:7 step:5966 [D loss: 0.742667, acc.: 45.31%] [G loss: 0.708501]\n",
      "epoch:7 step:5967 [D loss: 0.658103, acc.: 59.38%] [G loss: 0.805011]\n",
      "epoch:7 step:5968 [D loss: 0.749218, acc.: 45.31%] [G loss: 0.828364]\n",
      "epoch:7 step:5969 [D loss: 0.677822, acc.: 58.59%] [G loss: 0.854506]\n",
      "epoch:7 step:5970 [D loss: 0.709909, acc.: 50.00%] [G loss: 0.838148]\n",
      "epoch:7 step:5971 [D loss: 0.704570, acc.: 58.59%] [G loss: 0.855119]\n",
      "epoch:7 step:5972 [D loss: 0.704972, acc.: 52.34%] [G loss: 0.742220]\n",
      "epoch:7 step:5973 [D loss: 0.705572, acc.: 53.12%] [G loss: 0.849314]\n",
      "epoch:7 step:5974 [D loss: 0.733239, acc.: 52.34%] [G loss: 0.841294]\n",
      "epoch:7 step:5975 [D loss: 0.738757, acc.: 46.09%] [G loss: 0.813493]\n",
      "epoch:7 step:5976 [D loss: 0.737105, acc.: 41.41%] [G loss: 0.727101]\n",
      "epoch:7 step:5977 [D loss: 0.646324, acc.: 64.06%] [G loss: 0.836237]\n",
      "epoch:7 step:5978 [D loss: 0.709097, acc.: 48.44%] [G loss: 0.767546]\n",
      "epoch:7 step:5979 [D loss: 0.671653, acc.: 59.38%] [G loss: 0.906643]\n",
      "epoch:7 step:5980 [D loss: 0.705442, acc.: 55.47%] [G loss: 0.809948]\n",
      "epoch:7 step:5981 [D loss: 0.773419, acc.: 47.66%] [G loss: 0.829138]\n",
      "epoch:7 step:5982 [D loss: 0.601693, acc.: 73.44%] [G loss: 0.893429]\n",
      "epoch:7 step:5983 [D loss: 0.703440, acc.: 50.78%] [G loss: 0.761597]\n",
      "epoch:7 step:5984 [D loss: 0.720159, acc.: 49.22%] [G loss: 0.785272]\n",
      "epoch:7 step:5985 [D loss: 0.658623, acc.: 62.50%] [G loss: 0.720335]\n",
      "epoch:7 step:5986 [D loss: 0.750621, acc.: 45.31%] [G loss: 0.732320]\n",
      "epoch:7 step:5987 [D loss: 0.687805, acc.: 59.38%] [G loss: 0.751351]\n",
      "epoch:7 step:5988 [D loss: 0.690329, acc.: 57.81%] [G loss: 0.817899]\n",
      "epoch:7 step:5989 [D loss: 0.724478, acc.: 43.75%] [G loss: 0.842116]\n",
      "epoch:7 step:5990 [D loss: 0.682520, acc.: 50.00%] [G loss: 0.803048]\n",
      "epoch:7 step:5991 [D loss: 0.709623, acc.: 54.69%] [G loss: 0.838342]\n",
      "epoch:7 step:5992 [D loss: 0.671226, acc.: 59.38%] [G loss: 0.793262]\n",
      "epoch:7 step:5993 [D loss: 0.771986, acc.: 45.31%] [G loss: 0.733625]\n",
      "epoch:7 step:5994 [D loss: 0.726117, acc.: 51.56%] [G loss: 0.711360]\n",
      "epoch:7 step:5995 [D loss: 0.713404, acc.: 55.47%] [G loss: 0.763554]\n",
      "epoch:7 step:5996 [D loss: 0.673424, acc.: 53.12%] [G loss: 0.832353]\n",
      "epoch:7 step:5997 [D loss: 0.726073, acc.: 48.44%] [G loss: 0.749554]\n",
      "epoch:7 step:5998 [D loss: 0.660262, acc.: 65.62%] [G loss: 0.840304]\n",
      "epoch:7 step:5999 [D loss: 0.707919, acc.: 50.78%] [G loss: 0.801709]\n",
      "epoch:7 step:6000 [D loss: 0.755009, acc.: 39.84%] [G loss: 0.795447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6001 [D loss: 0.689642, acc.: 51.56%] [G loss: 0.865076]\n",
      "epoch:7 step:6002 [D loss: 0.772303, acc.: 42.97%] [G loss: 0.772862]\n",
      "epoch:7 step:6003 [D loss: 0.752105, acc.: 43.75%] [G loss: 0.833440]\n",
      "epoch:7 step:6004 [D loss: 0.664019, acc.: 55.47%] [G loss: 0.742483]\n",
      "epoch:7 step:6005 [D loss: 0.671221, acc.: 57.03%] [G loss: 0.844660]\n",
      "epoch:7 step:6006 [D loss: 0.713655, acc.: 45.31%] [G loss: 0.782160]\n",
      "epoch:7 step:6007 [D loss: 0.722345, acc.: 48.44%] [G loss: 0.787931]\n",
      "epoch:7 step:6008 [D loss: 0.687348, acc.: 52.34%] [G loss: 0.802477]\n",
      "epoch:7 step:6009 [D loss: 0.648464, acc.: 60.94%] [G loss: 0.764978]\n",
      "epoch:7 step:6010 [D loss: 0.641156, acc.: 64.06%] [G loss: 0.842596]\n",
      "epoch:7 step:6011 [D loss: 0.687784, acc.: 53.91%] [G loss: 0.794218]\n",
      "epoch:7 step:6012 [D loss: 0.690263, acc.: 54.69%] [G loss: 0.810104]\n",
      "epoch:7 step:6013 [D loss: 0.709732, acc.: 49.22%] [G loss: 0.847205]\n",
      "epoch:7 step:6014 [D loss: 0.695347, acc.: 61.72%] [G loss: 0.871625]\n",
      "epoch:7 step:6015 [D loss: 0.668943, acc.: 58.59%] [G loss: 0.768474]\n",
      "epoch:7 step:6016 [D loss: 0.745857, acc.: 39.84%] [G loss: 0.781006]\n",
      "epoch:7 step:6017 [D loss: 0.628546, acc.: 64.06%] [G loss: 0.835580]\n",
      "epoch:7 step:6018 [D loss: 0.643705, acc.: 68.75%] [G loss: 0.797837]\n",
      "epoch:7 step:6019 [D loss: 0.686450, acc.: 54.69%] [G loss: 0.777543]\n",
      "epoch:7 step:6020 [D loss: 0.653262, acc.: 60.16%] [G loss: 0.837086]\n",
      "epoch:7 step:6021 [D loss: 0.650254, acc.: 62.50%] [G loss: 0.937742]\n",
      "epoch:7 step:6022 [D loss: 0.748328, acc.: 51.56%] [G loss: 0.827047]\n",
      "epoch:7 step:6023 [D loss: 0.686912, acc.: 56.25%] [G loss: 0.782156]\n",
      "epoch:7 step:6024 [D loss: 0.706147, acc.: 46.88%] [G loss: 0.723682]\n",
      "epoch:7 step:6025 [D loss: 0.718313, acc.: 52.34%] [G loss: 0.711162]\n",
      "epoch:7 step:6026 [D loss: 0.647101, acc.: 65.62%] [G loss: 0.790678]\n",
      "epoch:7 step:6027 [D loss: 0.679141, acc.: 57.03%] [G loss: 0.808280]\n",
      "epoch:7 step:6028 [D loss: 0.685894, acc.: 57.03%] [G loss: 0.788182]\n",
      "epoch:7 step:6029 [D loss: 0.693324, acc.: 56.25%] [G loss: 0.853539]\n",
      "epoch:7 step:6030 [D loss: 0.691285, acc.: 54.69%] [G loss: 0.830173]\n",
      "epoch:7 step:6031 [D loss: 0.722672, acc.: 47.66%] [G loss: 0.742401]\n",
      "epoch:7 step:6032 [D loss: 0.708920, acc.: 46.88%] [G loss: 0.825569]\n",
      "epoch:7 step:6033 [D loss: 0.638328, acc.: 63.28%] [G loss: 0.900507]\n",
      "epoch:7 step:6034 [D loss: 0.717712, acc.: 53.12%] [G loss: 0.879773]\n",
      "epoch:7 step:6035 [D loss: 0.707284, acc.: 55.47%] [G loss: 0.861160]\n",
      "epoch:7 step:6036 [D loss: 0.661563, acc.: 62.50%] [G loss: 1.009820]\n",
      "epoch:7 step:6037 [D loss: 0.681367, acc.: 57.03%] [G loss: 0.846125]\n",
      "epoch:7 step:6038 [D loss: 0.707629, acc.: 46.09%] [G loss: 0.727486]\n",
      "epoch:7 step:6039 [D loss: 0.656538, acc.: 65.62%] [G loss: 0.769470]\n",
      "epoch:7 step:6040 [D loss: 0.650027, acc.: 60.94%] [G loss: 0.829782]\n",
      "epoch:7 step:6041 [D loss: 0.717310, acc.: 52.34%] [G loss: 0.788133]\n",
      "epoch:7 step:6042 [D loss: 0.679320, acc.: 51.56%] [G loss: 0.722660]\n",
      "epoch:7 step:6043 [D loss: 0.647662, acc.: 67.19%] [G loss: 0.767862]\n",
      "epoch:7 step:6044 [D loss: 0.718725, acc.: 53.91%] [G loss: 0.775959]\n",
      "epoch:7 step:6045 [D loss: 0.684333, acc.: 55.47%] [G loss: 0.673789]\n",
      "epoch:7 step:6046 [D loss: 0.671567, acc.: 61.72%] [G loss: 0.885444]\n",
      "epoch:7 step:6047 [D loss: 0.740549, acc.: 46.88%] [G loss: 0.708815]\n",
      "epoch:7 step:6048 [D loss: 0.666080, acc.: 53.12%] [G loss: 0.751441]\n",
      "epoch:7 step:6049 [D loss: 0.753027, acc.: 39.84%] [G loss: 0.734192]\n",
      "epoch:7 step:6050 [D loss: 0.686638, acc.: 51.56%] [G loss: 0.731745]\n",
      "epoch:7 step:6051 [D loss: 0.684950, acc.: 59.38%] [G loss: 0.814624]\n",
      "epoch:7 step:6052 [D loss: 0.735069, acc.: 48.44%] [G loss: 0.871727]\n",
      "epoch:7 step:6053 [D loss: 0.688337, acc.: 50.00%] [G loss: 0.800677]\n",
      "epoch:7 step:6054 [D loss: 0.668200, acc.: 60.16%] [G loss: 0.842978]\n",
      "epoch:7 step:6055 [D loss: 0.697095, acc.: 50.78%] [G loss: 0.798876]\n",
      "epoch:7 step:6056 [D loss: 0.710683, acc.: 53.12%] [G loss: 0.773312]\n",
      "epoch:7 step:6057 [D loss: 0.678411, acc.: 58.59%] [G loss: 0.884794]\n",
      "epoch:7 step:6058 [D loss: 0.638387, acc.: 64.06%] [G loss: 0.813139]\n",
      "epoch:7 step:6059 [D loss: 0.792012, acc.: 39.84%] [G loss: 0.768759]\n",
      "epoch:7 step:6060 [D loss: 0.702013, acc.: 54.69%] [G loss: 0.811473]\n",
      "epoch:7 step:6061 [D loss: 0.677999, acc.: 64.06%] [G loss: 0.827328]\n",
      "epoch:7 step:6062 [D loss: 0.662711, acc.: 64.06%] [G loss: 0.766624]\n",
      "epoch:7 step:6063 [D loss: 0.661012, acc.: 61.72%] [G loss: 0.841867]\n",
      "epoch:7 step:6064 [D loss: 0.651156, acc.: 67.19%] [G loss: 0.795699]\n",
      "epoch:7 step:6065 [D loss: 0.655430, acc.: 67.19%] [G loss: 0.811331]\n",
      "epoch:7 step:6066 [D loss: 0.715906, acc.: 49.22%] [G loss: 0.753038]\n",
      "epoch:7 step:6067 [D loss: 0.622118, acc.: 67.19%] [G loss: 0.808772]\n",
      "epoch:7 step:6068 [D loss: 0.710452, acc.: 53.12%] [G loss: 0.746713]\n",
      "epoch:7 step:6069 [D loss: 0.666538, acc.: 65.62%] [G loss: 0.808413]\n",
      "epoch:7 step:6070 [D loss: 0.724365, acc.: 50.00%] [G loss: 0.822078]\n",
      "epoch:7 step:6071 [D loss: 0.736961, acc.: 50.78%] [G loss: 0.796041]\n",
      "epoch:7 step:6072 [D loss: 0.676709, acc.: 55.47%] [G loss: 0.836586]\n",
      "epoch:7 step:6073 [D loss: 0.699525, acc.: 53.91%] [G loss: 0.804682]\n",
      "epoch:7 step:6074 [D loss: 0.679659, acc.: 55.47%] [G loss: 0.823007]\n",
      "epoch:7 step:6075 [D loss: 0.674850, acc.: 55.47%] [G loss: 0.721700]\n",
      "epoch:7 step:6076 [D loss: 0.682248, acc.: 55.47%] [G loss: 0.737836]\n",
      "epoch:7 step:6077 [D loss: 0.674873, acc.: 59.38%] [G loss: 0.736603]\n",
      "epoch:7 step:6078 [D loss: 0.757743, acc.: 40.62%] [G loss: 0.721992]\n",
      "epoch:7 step:6079 [D loss: 0.730337, acc.: 50.78%] [G loss: 0.718911]\n",
      "epoch:7 step:6080 [D loss: 0.804765, acc.: 33.59%] [G loss: 0.665982]\n",
      "epoch:7 step:6081 [D loss: 0.692053, acc.: 57.03%] [G loss: 0.783802]\n",
      "epoch:7 step:6082 [D loss: 0.716079, acc.: 49.22%] [G loss: 0.806252]\n",
      "epoch:7 step:6083 [D loss: 0.668454, acc.: 66.41%] [G loss: 0.780028]\n",
      "epoch:7 step:6084 [D loss: 0.716990, acc.: 52.34%] [G loss: 0.711615]\n",
      "epoch:7 step:6085 [D loss: 0.722519, acc.: 45.31%] [G loss: 0.814317]\n",
      "epoch:7 step:6086 [D loss: 0.668268, acc.: 57.81%] [G loss: 0.865421]\n",
      "epoch:7 step:6087 [D loss: 0.722445, acc.: 48.44%] [G loss: 0.844552]\n",
      "epoch:7 step:6088 [D loss: 0.673591, acc.: 53.91%] [G loss: 0.899633]\n",
      "epoch:7 step:6089 [D loss: 0.674202, acc.: 58.59%] [G loss: 0.983747]\n",
      "epoch:7 step:6090 [D loss: 0.662206, acc.: 58.59%] [G loss: 0.949752]\n",
      "epoch:7 step:6091 [D loss: 0.655040, acc.: 64.06%] [G loss: 0.842875]\n",
      "epoch:7 step:6092 [D loss: 0.629421, acc.: 62.50%] [G loss: 0.773978]\n",
      "epoch:7 step:6093 [D loss: 0.657877, acc.: 60.94%] [G loss: 0.810540]\n",
      "epoch:7 step:6094 [D loss: 0.659340, acc.: 62.50%] [G loss: 0.790739]\n",
      "epoch:7 step:6095 [D loss: 0.658031, acc.: 57.03%] [G loss: 0.834322]\n",
      "epoch:7 step:6096 [D loss: 0.672268, acc.: 58.59%] [G loss: 0.803475]\n",
      "epoch:7 step:6097 [D loss: 0.705292, acc.: 53.12%] [G loss: 0.808377]\n",
      "epoch:7 step:6098 [D loss: 0.730302, acc.: 50.78%] [G loss: 0.742937]\n",
      "epoch:7 step:6099 [D loss: 0.664366, acc.: 64.84%] [G loss: 0.782839]\n",
      "epoch:7 step:6100 [D loss: 0.697444, acc.: 56.25%] [G loss: 0.792106]\n",
      "epoch:7 step:6101 [D loss: 0.732351, acc.: 46.88%] [G loss: 0.721575]\n",
      "epoch:7 step:6102 [D loss: 0.727891, acc.: 48.44%] [G loss: 0.734326]\n",
      "epoch:7 step:6103 [D loss: 0.737621, acc.: 45.31%] [G loss: 0.755673]\n",
      "epoch:7 step:6104 [D loss: 0.659751, acc.: 60.94%] [G loss: 0.810214]\n",
      "epoch:7 step:6105 [D loss: 0.797202, acc.: 39.06%] [G loss: 0.714178]\n",
      "epoch:7 step:6106 [D loss: 0.693247, acc.: 55.47%] [G loss: 0.734430]\n",
      "epoch:7 step:6107 [D loss: 0.726914, acc.: 46.88%] [G loss: 0.724718]\n",
      "epoch:7 step:6108 [D loss: 0.705631, acc.: 58.59%] [G loss: 0.731156]\n",
      "epoch:7 step:6109 [D loss: 0.700697, acc.: 50.78%] [G loss: 0.833310]\n",
      "epoch:7 step:6110 [D loss: 0.700768, acc.: 50.78%] [G loss: 0.798133]\n",
      "epoch:7 step:6111 [D loss: 0.739978, acc.: 49.22%] [G loss: 0.837742]\n",
      "epoch:7 step:6112 [D loss: 0.736809, acc.: 43.75%] [G loss: 0.808299]\n",
      "epoch:7 step:6113 [D loss: 0.681711, acc.: 56.25%] [G loss: 0.852271]\n",
      "epoch:7 step:6114 [D loss: 0.798199, acc.: 42.97%] [G loss: 0.858133]\n",
      "epoch:7 step:6115 [D loss: 0.653875, acc.: 58.59%] [G loss: 0.911538]\n",
      "epoch:7 step:6116 [D loss: 0.684868, acc.: 57.81%] [G loss: 0.762855]\n",
      "epoch:7 step:6117 [D loss: 0.697501, acc.: 50.00%] [G loss: 0.839586]\n",
      "epoch:7 step:6118 [D loss: 0.717453, acc.: 46.88%] [G loss: 0.776322]\n",
      "epoch:7 step:6119 [D loss: 0.649961, acc.: 64.84%] [G loss: 0.768097]\n",
      "epoch:7 step:6120 [D loss: 0.669073, acc.: 60.16%] [G loss: 0.769313]\n",
      "epoch:7 step:6121 [D loss: 0.739040, acc.: 45.31%] [G loss: 0.786375]\n",
      "epoch:7 step:6122 [D loss: 0.680471, acc.: 54.69%] [G loss: 0.893063]\n",
      "epoch:7 step:6123 [D loss: 0.683100, acc.: 58.59%] [G loss: 0.847262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6124 [D loss: 0.701496, acc.: 50.78%] [G loss: 0.806656]\n",
      "epoch:7 step:6125 [D loss: 0.640383, acc.: 68.75%] [G loss: 0.929508]\n",
      "epoch:7 step:6126 [D loss: 0.762136, acc.: 42.97%] [G loss: 0.827574]\n",
      "epoch:7 step:6127 [D loss: 0.664859, acc.: 62.50%] [G loss: 0.881574]\n",
      "epoch:7 step:6128 [D loss: 0.698842, acc.: 53.12%] [G loss: 0.888034]\n",
      "epoch:7 step:6129 [D loss: 0.721515, acc.: 49.22%] [G loss: 0.786488]\n",
      "epoch:7 step:6130 [D loss: 0.753082, acc.: 40.62%] [G loss: 0.764422]\n",
      "epoch:7 step:6131 [D loss: 0.687835, acc.: 53.91%] [G loss: 0.729870]\n",
      "epoch:7 step:6132 [D loss: 0.725784, acc.: 43.75%] [G loss: 0.700779]\n",
      "epoch:7 step:6133 [D loss: 0.728060, acc.: 51.56%] [G loss: 0.781444]\n",
      "epoch:7 step:6134 [D loss: 0.659061, acc.: 65.62%] [G loss: 0.799176]\n",
      "epoch:7 step:6135 [D loss: 0.707467, acc.: 57.03%] [G loss: 0.867661]\n",
      "epoch:7 step:6136 [D loss: 0.712163, acc.: 50.78%] [G loss: 0.803460]\n",
      "epoch:7 step:6137 [D loss: 0.715647, acc.: 46.88%] [G loss: 0.867062]\n",
      "epoch:7 step:6138 [D loss: 0.710046, acc.: 49.22%] [G loss: 0.808244]\n",
      "epoch:7 step:6139 [D loss: 0.665332, acc.: 60.16%] [G loss: 0.720121]\n",
      "epoch:7 step:6140 [D loss: 0.636035, acc.: 65.62%] [G loss: 0.858016]\n",
      "epoch:7 step:6141 [D loss: 0.686843, acc.: 53.91%] [G loss: 0.802447]\n",
      "epoch:7 step:6142 [D loss: 0.681739, acc.: 57.03%] [G loss: 0.902948]\n",
      "epoch:7 step:6143 [D loss: 0.717444, acc.: 56.25%] [G loss: 0.769911]\n",
      "epoch:7 step:6144 [D loss: 0.675174, acc.: 53.91%] [G loss: 0.840252]\n",
      "epoch:7 step:6145 [D loss: 0.706922, acc.: 46.88%] [G loss: 0.770494]\n",
      "epoch:7 step:6146 [D loss: 0.688806, acc.: 51.56%] [G loss: 0.832656]\n",
      "epoch:7 step:6147 [D loss: 0.619773, acc.: 63.28%] [G loss: 0.889429]\n",
      "epoch:7 step:6148 [D loss: 0.689799, acc.: 57.03%] [G loss: 0.754552]\n",
      "epoch:7 step:6149 [D loss: 0.761177, acc.: 46.09%] [G loss: 0.774333]\n",
      "epoch:7 step:6150 [D loss: 0.731623, acc.: 48.44%] [G loss: 0.835608]\n",
      "epoch:7 step:6151 [D loss: 0.658802, acc.: 57.03%] [G loss: 0.801561]\n",
      "epoch:7 step:6152 [D loss: 0.745995, acc.: 39.84%] [G loss: 0.773725]\n",
      "epoch:7 step:6153 [D loss: 0.697738, acc.: 53.12%] [G loss: 0.787152]\n",
      "epoch:7 step:6154 [D loss: 0.760796, acc.: 39.06%] [G loss: 0.716779]\n",
      "epoch:7 step:6155 [D loss: 0.691330, acc.: 53.91%] [G loss: 0.867346]\n",
      "epoch:7 step:6156 [D loss: 0.731429, acc.: 48.44%] [G loss: 0.899871]\n",
      "epoch:7 step:6157 [D loss: 0.666876, acc.: 54.69%] [G loss: 0.768294]\n",
      "epoch:7 step:6158 [D loss: 0.740473, acc.: 44.53%] [G loss: 0.757862]\n",
      "epoch:7 step:6159 [D loss: 0.796937, acc.: 33.59%] [G loss: 0.730791]\n",
      "epoch:7 step:6160 [D loss: 0.693308, acc.: 57.03%] [G loss: 0.754072]\n",
      "epoch:7 step:6161 [D loss: 0.675036, acc.: 57.03%] [G loss: 0.707185]\n",
      "epoch:7 step:6162 [D loss: 0.655435, acc.: 57.03%] [G loss: 0.795496]\n",
      "epoch:7 step:6163 [D loss: 0.685672, acc.: 57.03%] [G loss: 0.738767]\n",
      "epoch:7 step:6164 [D loss: 0.692026, acc.: 54.69%] [G loss: 0.836973]\n",
      "epoch:7 step:6165 [D loss: 0.646473, acc.: 64.06%] [G loss: 0.766545]\n",
      "epoch:7 step:6166 [D loss: 0.709686, acc.: 50.78%] [G loss: 0.723737]\n",
      "epoch:7 step:6167 [D loss: 0.754838, acc.: 41.41%] [G loss: 0.899540]\n",
      "epoch:7 step:6168 [D loss: 0.672132, acc.: 62.50%] [G loss: 0.862320]\n",
      "epoch:7 step:6169 [D loss: 0.655245, acc.: 60.16%] [G loss: 0.853970]\n",
      "epoch:7 step:6170 [D loss: 0.630604, acc.: 67.19%] [G loss: 0.794441]\n",
      "epoch:7 step:6171 [D loss: 0.636401, acc.: 64.06%] [G loss: 0.893414]\n",
      "epoch:7 step:6172 [D loss: 0.722891, acc.: 49.22%] [G loss: 0.838515]\n",
      "epoch:7 step:6173 [D loss: 0.674290, acc.: 57.81%] [G loss: 0.751536]\n",
      "epoch:7 step:6174 [D loss: 0.740815, acc.: 44.53%] [G loss: 0.708784]\n",
      "epoch:7 step:6175 [D loss: 0.673460, acc.: 59.38%] [G loss: 0.755964]\n",
      "epoch:7 step:6176 [D loss: 0.705191, acc.: 50.00%] [G loss: 0.748316]\n",
      "epoch:7 step:6177 [D loss: 0.620732, acc.: 67.97%] [G loss: 0.796264]\n",
      "epoch:7 step:6178 [D loss: 0.631425, acc.: 60.16%] [G loss: 0.804615]\n",
      "epoch:7 step:6179 [D loss: 0.726065, acc.: 47.66%] [G loss: 0.847982]\n",
      "epoch:7 step:6180 [D loss: 0.665251, acc.: 60.94%] [G loss: 0.891705]\n",
      "epoch:7 step:6181 [D loss: 0.670725, acc.: 59.38%] [G loss: 0.767602]\n",
      "epoch:7 step:6182 [D loss: 0.711473, acc.: 49.22%] [G loss: 0.809113]\n",
      "epoch:7 step:6183 [D loss: 0.643024, acc.: 64.84%] [G loss: 0.756856]\n",
      "epoch:7 step:6184 [D loss: 0.659823, acc.: 64.06%] [G loss: 0.800883]\n",
      "epoch:7 step:6185 [D loss: 0.701869, acc.: 54.69%] [G loss: 0.767593]\n",
      "epoch:7 step:6186 [D loss: 0.674846, acc.: 54.69%] [G loss: 0.818157]\n",
      "epoch:7 step:6187 [D loss: 0.688351, acc.: 55.47%] [G loss: 0.745365]\n",
      "epoch:7 step:6188 [D loss: 0.774291, acc.: 39.84%] [G loss: 0.826451]\n",
      "epoch:7 step:6189 [D loss: 0.677595, acc.: 56.25%] [G loss: 0.835681]\n",
      "epoch:7 step:6190 [D loss: 0.758150, acc.: 45.31%] [G loss: 0.810101]\n",
      "epoch:7 step:6191 [D loss: 0.672917, acc.: 61.72%] [G loss: 0.900685]\n",
      "epoch:7 step:6192 [D loss: 0.688893, acc.: 56.25%] [G loss: 0.809850]\n",
      "epoch:7 step:6193 [D loss: 0.673065, acc.: 53.91%] [G loss: 0.865241]\n",
      "epoch:7 step:6194 [D loss: 0.695108, acc.: 57.03%] [G loss: 0.797151]\n",
      "epoch:7 step:6195 [D loss: 0.672121, acc.: 60.94%] [G loss: 0.820538]\n",
      "epoch:7 step:6196 [D loss: 0.732228, acc.: 46.88%] [G loss: 0.770727]\n",
      "epoch:7 step:6197 [D loss: 0.754156, acc.: 43.75%] [G loss: 0.788997]\n",
      "epoch:7 step:6198 [D loss: 0.689353, acc.: 60.94%] [G loss: 0.804151]\n",
      "epoch:7 step:6199 [D loss: 0.594872, acc.: 67.19%] [G loss: 0.795927]\n",
      "epoch:7 step:6200 [D loss: 0.637339, acc.: 68.75%] [G loss: 0.763707]\n",
      "epoch:7 step:6201 [D loss: 0.735125, acc.: 46.09%] [G loss: 0.778882]\n",
      "epoch:7 step:6202 [D loss: 0.663830, acc.: 62.50%] [G loss: 0.824569]\n",
      "epoch:7 step:6203 [D loss: 0.653742, acc.: 66.41%] [G loss: 0.898255]\n",
      "epoch:7 step:6204 [D loss: 0.761000, acc.: 45.31%] [G loss: 0.808401]\n",
      "epoch:7 step:6205 [D loss: 0.638624, acc.: 62.50%] [G loss: 0.821400]\n",
      "epoch:7 step:6206 [D loss: 0.710567, acc.: 51.56%] [G loss: 0.868326]\n",
      "epoch:7 step:6207 [D loss: 0.680514, acc.: 58.59%] [G loss: 0.735774]\n",
      "epoch:7 step:6208 [D loss: 0.762825, acc.: 42.97%] [G loss: 0.779964]\n",
      "epoch:7 step:6209 [D loss: 0.727722, acc.: 50.78%] [G loss: 0.774298]\n",
      "epoch:7 step:6210 [D loss: 0.635969, acc.: 67.19%] [G loss: 0.798401]\n",
      "epoch:7 step:6211 [D loss: 0.727224, acc.: 44.53%] [G loss: 0.726798]\n",
      "epoch:7 step:6212 [D loss: 0.709826, acc.: 53.12%] [G loss: 0.841506]\n",
      "epoch:7 step:6213 [D loss: 0.724604, acc.: 48.44%] [G loss: 0.732286]\n",
      "epoch:7 step:6214 [D loss: 0.660682, acc.: 63.28%] [G loss: 0.751250]\n",
      "epoch:7 step:6215 [D loss: 0.729530, acc.: 47.66%] [G loss: 0.902236]\n",
      "epoch:7 step:6216 [D loss: 0.625814, acc.: 67.97%] [G loss: 0.926876]\n",
      "epoch:7 step:6217 [D loss: 0.680006, acc.: 60.94%] [G loss: 0.833949]\n",
      "epoch:7 step:6218 [D loss: 0.698810, acc.: 59.38%] [G loss: 0.838440]\n",
      "epoch:7 step:6219 [D loss: 0.698312, acc.: 49.22%] [G loss: 0.801398]\n",
      "epoch:7 step:6220 [D loss: 0.675315, acc.: 59.38%] [G loss: 0.896959]\n",
      "epoch:7 step:6221 [D loss: 0.693394, acc.: 60.16%] [G loss: 0.754118]\n",
      "epoch:7 step:6222 [D loss: 0.745802, acc.: 50.00%] [G loss: 0.794076]\n",
      "epoch:7 step:6223 [D loss: 0.740554, acc.: 47.66%] [G loss: 0.785712]\n",
      "epoch:7 step:6224 [D loss: 0.770704, acc.: 39.06%] [G loss: 0.776721]\n",
      "epoch:7 step:6225 [D loss: 0.663902, acc.: 57.81%] [G loss: 0.816214]\n",
      "epoch:7 step:6226 [D loss: 0.759569, acc.: 35.16%] [G loss: 0.790594]\n",
      "epoch:7 step:6227 [D loss: 0.736705, acc.: 43.75%] [G loss: 0.768530]\n",
      "epoch:7 step:6228 [D loss: 0.780181, acc.: 39.06%] [G loss: 0.783453]\n",
      "epoch:7 step:6229 [D loss: 0.746250, acc.: 44.53%] [G loss: 0.830952]\n",
      "epoch:7 step:6230 [D loss: 0.739415, acc.: 47.66%] [G loss: 0.810589]\n",
      "epoch:7 step:6231 [D loss: 0.665250, acc.: 62.50%] [G loss: 0.825193]\n",
      "epoch:7 step:6232 [D loss: 0.680456, acc.: 59.38%] [G loss: 0.871026]\n",
      "epoch:7 step:6233 [D loss: 0.692498, acc.: 54.69%] [G loss: 0.835030]\n",
      "epoch:7 step:6234 [D loss: 0.683210, acc.: 57.81%] [G loss: 0.829471]\n",
      "epoch:7 step:6235 [D loss: 0.626214, acc.: 67.19%] [G loss: 0.896216]\n",
      "epoch:7 step:6236 [D loss: 0.638852, acc.: 67.19%] [G loss: 0.888642]\n",
      "epoch:7 step:6237 [D loss: 0.707557, acc.: 51.56%] [G loss: 0.838900]\n",
      "epoch:7 step:6238 [D loss: 0.695100, acc.: 52.34%] [G loss: 0.847886]\n",
      "epoch:7 step:6239 [D loss: 0.706780, acc.: 53.12%] [G loss: 0.823712]\n",
      "epoch:7 step:6240 [D loss: 0.662003, acc.: 54.69%] [G loss: 0.823474]\n",
      "epoch:7 step:6241 [D loss: 0.678573, acc.: 56.25%] [G loss: 0.832471]\n",
      "epoch:7 step:6242 [D loss: 0.755867, acc.: 42.19%] [G loss: 0.778457]\n",
      "epoch:7 step:6243 [D loss: 0.725670, acc.: 46.09%] [G loss: 0.677914]\n",
      "epoch:7 step:6244 [D loss: 0.719291, acc.: 47.66%] [G loss: 0.834343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6245 [D loss: 0.666084, acc.: 55.47%] [G loss: 0.821004]\n",
      "epoch:7 step:6246 [D loss: 0.640431, acc.: 64.06%] [G loss: 0.818076]\n",
      "epoch:7 step:6247 [D loss: 0.736380, acc.: 47.66%] [G loss: 0.737375]\n",
      "epoch:7 step:6248 [D loss: 0.698205, acc.: 52.34%] [G loss: 0.769012]\n",
      "epoch:8 step:6249 [D loss: 0.722188, acc.: 52.34%] [G loss: 0.803597]\n",
      "epoch:8 step:6250 [D loss: 0.685506, acc.: 59.38%] [G loss: 0.865963]\n",
      "epoch:8 step:6251 [D loss: 0.716578, acc.: 46.09%] [G loss: 0.714067]\n",
      "epoch:8 step:6252 [D loss: 0.666868, acc.: 58.59%] [G loss: 0.772447]\n",
      "epoch:8 step:6253 [D loss: 0.710210, acc.: 47.66%] [G loss: 0.771643]\n",
      "epoch:8 step:6254 [D loss: 0.683270, acc.: 53.91%] [G loss: 0.775265]\n",
      "epoch:8 step:6255 [D loss: 0.746627, acc.: 43.75%] [G loss: 0.877733]\n",
      "epoch:8 step:6256 [D loss: 0.683626, acc.: 58.59%] [G loss: 0.832340]\n",
      "epoch:8 step:6257 [D loss: 0.672089, acc.: 55.47%] [G loss: 0.807729]\n",
      "epoch:8 step:6258 [D loss: 0.686260, acc.: 52.34%] [G loss: 0.816397]\n",
      "epoch:8 step:6259 [D loss: 0.709703, acc.: 48.44%] [G loss: 0.863513]\n",
      "epoch:8 step:6260 [D loss: 0.673787, acc.: 53.91%] [G loss: 0.795518]\n",
      "epoch:8 step:6261 [D loss: 0.726442, acc.: 46.88%] [G loss: 0.812614]\n",
      "epoch:8 step:6262 [D loss: 0.692281, acc.: 57.81%] [G loss: 0.880818]\n",
      "epoch:8 step:6263 [D loss: 0.729980, acc.: 48.44%] [G loss: 0.867208]\n",
      "epoch:8 step:6264 [D loss: 0.716578, acc.: 50.78%] [G loss: 0.764882]\n",
      "epoch:8 step:6265 [D loss: 0.669812, acc.: 58.59%] [G loss: 0.851847]\n",
      "epoch:8 step:6266 [D loss: 0.717958, acc.: 50.00%] [G loss: 0.790665]\n",
      "epoch:8 step:6267 [D loss: 0.694421, acc.: 49.22%] [G loss: 0.806034]\n",
      "epoch:8 step:6268 [D loss: 0.722249, acc.: 45.31%] [G loss: 0.853382]\n",
      "epoch:8 step:6269 [D loss: 0.696456, acc.: 55.47%] [G loss: 0.849306]\n",
      "epoch:8 step:6270 [D loss: 0.691514, acc.: 55.47%] [G loss: 0.858365]\n",
      "epoch:8 step:6271 [D loss: 0.664869, acc.: 56.25%] [G loss: 0.845903]\n",
      "epoch:8 step:6272 [D loss: 0.752221, acc.: 43.75%] [G loss: 0.869314]\n",
      "epoch:8 step:6273 [D loss: 0.787745, acc.: 40.62%] [G loss: 0.812744]\n",
      "epoch:8 step:6274 [D loss: 0.758887, acc.: 42.19%] [G loss: 0.745856]\n",
      "epoch:8 step:6275 [D loss: 0.706926, acc.: 47.66%] [G loss: 0.766971]\n",
      "epoch:8 step:6276 [D loss: 0.682381, acc.: 55.47%] [G loss: 0.835654]\n",
      "epoch:8 step:6277 [D loss: 0.666641, acc.: 60.16%] [G loss: 0.798855]\n",
      "epoch:8 step:6278 [D loss: 0.682217, acc.: 54.69%] [G loss: 0.771191]\n",
      "epoch:8 step:6279 [D loss: 0.676531, acc.: 54.69%] [G loss: 0.811401]\n",
      "epoch:8 step:6280 [D loss: 0.724533, acc.: 43.75%] [G loss: 0.760675]\n",
      "epoch:8 step:6281 [D loss: 0.732891, acc.: 45.31%] [G loss: 0.809635]\n",
      "epoch:8 step:6282 [D loss: 0.706186, acc.: 53.91%] [G loss: 0.768527]\n",
      "epoch:8 step:6283 [D loss: 0.696852, acc.: 54.69%] [G loss: 0.743473]\n",
      "epoch:8 step:6284 [D loss: 0.692137, acc.: 54.69%] [G loss: 0.898556]\n",
      "epoch:8 step:6285 [D loss: 0.754856, acc.: 42.19%] [G loss: 0.841658]\n",
      "epoch:8 step:6286 [D loss: 0.734695, acc.: 45.31%] [G loss: 0.814845]\n",
      "epoch:8 step:6287 [D loss: 0.724523, acc.: 43.75%] [G loss: 0.792708]\n",
      "epoch:8 step:6288 [D loss: 0.639103, acc.: 63.28%] [G loss: 0.895251]\n",
      "epoch:8 step:6289 [D loss: 0.670375, acc.: 54.69%] [G loss: 0.819964]\n",
      "epoch:8 step:6290 [D loss: 0.709271, acc.: 53.12%] [G loss: 0.816922]\n",
      "epoch:8 step:6291 [D loss: 0.686319, acc.: 56.25%] [G loss: 0.728049]\n",
      "epoch:8 step:6292 [D loss: 0.745984, acc.: 37.50%] [G loss: 0.760417]\n",
      "epoch:8 step:6293 [D loss: 0.730776, acc.: 50.00%] [G loss: 0.812191]\n",
      "epoch:8 step:6294 [D loss: 0.748085, acc.: 40.62%] [G loss: 0.758703]\n",
      "epoch:8 step:6295 [D loss: 0.749715, acc.: 46.09%] [G loss: 0.778121]\n",
      "epoch:8 step:6296 [D loss: 0.748513, acc.: 43.75%] [G loss: 0.783421]\n",
      "epoch:8 step:6297 [D loss: 0.682923, acc.: 57.81%] [G loss: 0.849928]\n",
      "epoch:8 step:6298 [D loss: 0.755247, acc.: 41.41%] [G loss: 0.769355]\n",
      "epoch:8 step:6299 [D loss: 0.715718, acc.: 52.34%] [G loss: 0.773623]\n",
      "epoch:8 step:6300 [D loss: 0.759749, acc.: 46.88%] [G loss: 0.843110]\n",
      "epoch:8 step:6301 [D loss: 0.713171, acc.: 55.47%] [G loss: 0.758552]\n",
      "epoch:8 step:6302 [D loss: 0.726580, acc.: 51.56%] [G loss: 0.772696]\n",
      "epoch:8 step:6303 [D loss: 0.706036, acc.: 53.12%] [G loss: 0.792163]\n",
      "epoch:8 step:6304 [D loss: 0.686147, acc.: 52.34%] [G loss: 0.787738]\n",
      "epoch:8 step:6305 [D loss: 0.704292, acc.: 56.25%] [G loss: 0.800119]\n",
      "epoch:8 step:6306 [D loss: 0.639998, acc.: 67.97%] [G loss: 0.862385]\n",
      "epoch:8 step:6307 [D loss: 0.644568, acc.: 66.41%] [G loss: 0.867202]\n",
      "epoch:8 step:6308 [D loss: 0.662503, acc.: 65.62%] [G loss: 0.871164]\n",
      "epoch:8 step:6309 [D loss: 0.677542, acc.: 57.03%] [G loss: 0.852508]\n",
      "epoch:8 step:6310 [D loss: 0.710947, acc.: 48.44%] [G loss: 0.927725]\n",
      "epoch:8 step:6311 [D loss: 0.633220, acc.: 69.53%] [G loss: 0.764198]\n",
      "epoch:8 step:6312 [D loss: 0.711945, acc.: 53.91%] [G loss: 0.781796]\n",
      "epoch:8 step:6313 [D loss: 0.681167, acc.: 50.78%] [G loss: 0.847246]\n",
      "epoch:8 step:6314 [D loss: 0.718421, acc.: 51.56%] [G loss: 0.915967]\n",
      "epoch:8 step:6315 [D loss: 0.690142, acc.: 50.78%] [G loss: 0.819253]\n",
      "epoch:8 step:6316 [D loss: 0.692755, acc.: 54.69%] [G loss: 0.829039]\n",
      "epoch:8 step:6317 [D loss: 0.675524, acc.: 60.94%] [G loss: 0.836392]\n",
      "epoch:8 step:6318 [D loss: 0.720204, acc.: 42.19%] [G loss: 0.848041]\n",
      "epoch:8 step:6319 [D loss: 0.743655, acc.: 46.09%] [G loss: 0.766560]\n",
      "epoch:8 step:6320 [D loss: 0.753371, acc.: 42.97%] [G loss: 0.801964]\n",
      "epoch:8 step:6321 [D loss: 0.668415, acc.: 61.72%] [G loss: 0.801549]\n",
      "epoch:8 step:6322 [D loss: 0.679926, acc.: 54.69%] [G loss: 0.745228]\n",
      "epoch:8 step:6323 [D loss: 0.678231, acc.: 59.38%] [G loss: 0.773480]\n",
      "epoch:8 step:6324 [D loss: 0.706043, acc.: 46.88%] [G loss: 0.740317]\n",
      "epoch:8 step:6325 [D loss: 0.740879, acc.: 39.84%] [G loss: 0.845571]\n",
      "epoch:8 step:6326 [D loss: 0.745197, acc.: 47.66%] [G loss: 0.732882]\n",
      "epoch:8 step:6327 [D loss: 0.632368, acc.: 69.53%] [G loss: 0.862268]\n",
      "epoch:8 step:6328 [D loss: 0.714937, acc.: 49.22%] [G loss: 0.851246]\n",
      "epoch:8 step:6329 [D loss: 0.726535, acc.: 50.78%] [G loss: 0.837600]\n",
      "epoch:8 step:6330 [D loss: 0.733205, acc.: 45.31%] [G loss: 0.789082]\n",
      "epoch:8 step:6331 [D loss: 0.765732, acc.: 38.28%] [G loss: 0.792119]\n",
      "epoch:8 step:6332 [D loss: 0.714425, acc.: 51.56%] [G loss: 0.793032]\n",
      "epoch:8 step:6333 [D loss: 0.719921, acc.: 50.78%] [G loss: 0.820638]\n",
      "epoch:8 step:6334 [D loss: 0.665529, acc.: 62.50%] [G loss: 0.843912]\n",
      "epoch:8 step:6335 [D loss: 0.710770, acc.: 56.25%] [G loss: 0.822355]\n",
      "epoch:8 step:6336 [D loss: 0.710049, acc.: 56.25%] [G loss: 0.846020]\n",
      "epoch:8 step:6337 [D loss: 0.676196, acc.: 53.91%] [G loss: 0.816438]\n",
      "epoch:8 step:6338 [D loss: 0.710144, acc.: 52.34%] [G loss: 0.810041]\n",
      "epoch:8 step:6339 [D loss: 0.786868, acc.: 38.28%] [G loss: 0.746692]\n",
      "epoch:8 step:6340 [D loss: 0.723096, acc.: 50.00%] [G loss: 0.833342]\n",
      "epoch:8 step:6341 [D loss: 0.702557, acc.: 53.12%] [G loss: 0.751990]\n",
      "epoch:8 step:6342 [D loss: 0.641828, acc.: 64.84%] [G loss: 0.776479]\n",
      "epoch:8 step:6343 [D loss: 0.737214, acc.: 47.66%] [G loss: 0.823120]\n",
      "epoch:8 step:6344 [D loss: 0.708211, acc.: 49.22%] [G loss: 0.694319]\n",
      "epoch:8 step:6345 [D loss: 0.653710, acc.: 58.59%] [G loss: 0.849186]\n",
      "epoch:8 step:6346 [D loss: 0.670964, acc.: 60.16%] [G loss: 0.791603]\n",
      "epoch:8 step:6347 [D loss: 0.672491, acc.: 67.97%] [G loss: 0.794985]\n",
      "epoch:8 step:6348 [D loss: 0.693508, acc.: 53.12%] [G loss: 0.812926]\n",
      "epoch:8 step:6349 [D loss: 0.691954, acc.: 54.69%] [G loss: 0.845084]\n",
      "epoch:8 step:6350 [D loss: 0.686706, acc.: 52.34%] [G loss: 0.832010]\n",
      "epoch:8 step:6351 [D loss: 0.710067, acc.: 53.91%] [G loss: 0.869187]\n",
      "epoch:8 step:6352 [D loss: 0.698474, acc.: 51.56%] [G loss: 0.870437]\n",
      "epoch:8 step:6353 [D loss: 0.685829, acc.: 56.25%] [G loss: 0.798062]\n",
      "epoch:8 step:6354 [D loss: 0.658078, acc.: 64.84%] [G loss: 0.794839]\n",
      "epoch:8 step:6355 [D loss: 0.693017, acc.: 54.69%] [G loss: 0.823927]\n",
      "epoch:8 step:6356 [D loss: 0.713483, acc.: 53.12%] [G loss: 0.789854]\n",
      "epoch:8 step:6357 [D loss: 0.711606, acc.: 46.88%] [G loss: 0.711107]\n",
      "epoch:8 step:6358 [D loss: 0.651377, acc.: 66.41%] [G loss: 0.775653]\n",
      "epoch:8 step:6359 [D loss: 0.705211, acc.: 54.69%] [G loss: 0.793919]\n",
      "epoch:8 step:6360 [D loss: 0.715846, acc.: 46.88%] [G loss: 0.789657]\n",
      "epoch:8 step:6361 [D loss: 0.732129, acc.: 50.78%] [G loss: 0.808347]\n",
      "epoch:8 step:6362 [D loss: 0.715280, acc.: 48.44%] [G loss: 0.802497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6363 [D loss: 0.709525, acc.: 53.12%] [G loss: 0.757433]\n",
      "epoch:8 step:6364 [D loss: 0.694067, acc.: 49.22%] [G loss: 0.783110]\n",
      "epoch:8 step:6365 [D loss: 0.669303, acc.: 63.28%] [G loss: 0.786983]\n",
      "epoch:8 step:6366 [D loss: 0.729336, acc.: 49.22%] [G loss: 0.725077]\n",
      "epoch:8 step:6367 [D loss: 0.736672, acc.: 44.53%] [G loss: 0.772356]\n",
      "epoch:8 step:6368 [D loss: 0.691967, acc.: 51.56%] [G loss: 0.764417]\n",
      "epoch:8 step:6369 [D loss: 0.743461, acc.: 40.62%] [G loss: 0.710963]\n",
      "epoch:8 step:6370 [D loss: 0.731885, acc.: 47.66%] [G loss: 0.813208]\n",
      "epoch:8 step:6371 [D loss: 0.711717, acc.: 50.00%] [G loss: 0.716852]\n",
      "epoch:8 step:6372 [D loss: 0.683065, acc.: 60.16%] [G loss: 0.748715]\n",
      "epoch:8 step:6373 [D loss: 0.796287, acc.: 30.47%] [G loss: 0.752579]\n",
      "epoch:8 step:6374 [D loss: 0.738851, acc.: 45.31%] [G loss: 0.810658]\n",
      "epoch:8 step:6375 [D loss: 0.686893, acc.: 58.59%] [G loss: 0.740531]\n",
      "epoch:8 step:6376 [D loss: 0.653708, acc.: 61.72%] [G loss: 0.836344]\n",
      "epoch:8 step:6377 [D loss: 0.699720, acc.: 42.97%] [G loss: 0.716946]\n",
      "epoch:8 step:6378 [D loss: 0.670828, acc.: 61.72%] [G loss: 0.702379]\n",
      "epoch:8 step:6379 [D loss: 0.688944, acc.: 52.34%] [G loss: 0.728028]\n",
      "epoch:8 step:6380 [D loss: 0.672931, acc.: 64.06%] [G loss: 0.801598]\n",
      "epoch:8 step:6381 [D loss: 0.678174, acc.: 60.16%] [G loss: 0.833166]\n",
      "epoch:8 step:6382 [D loss: 0.702267, acc.: 53.12%] [G loss: 0.844771]\n",
      "epoch:8 step:6383 [D loss: 0.746373, acc.: 44.53%] [G loss: 0.735455]\n",
      "epoch:8 step:6384 [D loss: 0.642971, acc.: 65.62%] [G loss: 0.787909]\n",
      "epoch:8 step:6385 [D loss: 0.736673, acc.: 48.44%] [G loss: 0.784314]\n",
      "epoch:8 step:6386 [D loss: 0.710661, acc.: 51.56%] [G loss: 0.770091]\n",
      "epoch:8 step:6387 [D loss: 0.677379, acc.: 57.81%] [G loss: 0.789207]\n",
      "epoch:8 step:6388 [D loss: 0.733977, acc.: 44.53%] [G loss: 0.764672]\n",
      "epoch:8 step:6389 [D loss: 0.729585, acc.: 40.62%] [G loss: 0.767074]\n",
      "epoch:8 step:6390 [D loss: 0.723141, acc.: 50.00%] [G loss: 0.816102]\n",
      "epoch:8 step:6391 [D loss: 0.684631, acc.: 57.81%] [G loss: 0.768107]\n",
      "epoch:8 step:6392 [D loss: 0.663079, acc.: 65.62%] [G loss: 0.752983]\n",
      "epoch:8 step:6393 [D loss: 0.702845, acc.: 56.25%] [G loss: 0.807399]\n",
      "epoch:8 step:6394 [D loss: 0.688178, acc.: 52.34%] [G loss: 0.789120]\n",
      "epoch:8 step:6395 [D loss: 0.715458, acc.: 49.22%] [G loss: 0.845805]\n",
      "epoch:8 step:6396 [D loss: 0.692718, acc.: 54.69%] [G loss: 0.794285]\n",
      "epoch:8 step:6397 [D loss: 0.645641, acc.: 62.50%] [G loss: 0.720089]\n",
      "epoch:8 step:6398 [D loss: 0.723059, acc.: 51.56%] [G loss: 0.636982]\n",
      "epoch:8 step:6399 [D loss: 0.722891, acc.: 46.09%] [G loss: 0.749478]\n",
      "epoch:8 step:6400 [D loss: 0.673613, acc.: 60.94%] [G loss: 0.868001]\n",
      "epoch:8 step:6401 [D loss: 0.673214, acc.: 56.25%] [G loss: 0.754092]\n",
      "epoch:8 step:6402 [D loss: 0.694240, acc.: 49.22%] [G loss: 0.772352]\n",
      "epoch:8 step:6403 [D loss: 0.762234, acc.: 50.00%] [G loss: 0.710284]\n",
      "epoch:8 step:6404 [D loss: 0.776849, acc.: 36.72%] [G loss: 0.696592]\n",
      "epoch:8 step:6405 [D loss: 0.700293, acc.: 50.78%] [G loss: 0.727428]\n",
      "epoch:8 step:6406 [D loss: 0.698331, acc.: 51.56%] [G loss: 0.716878]\n",
      "epoch:8 step:6407 [D loss: 0.693227, acc.: 53.91%] [G loss: 0.763662]\n",
      "epoch:8 step:6408 [D loss: 0.665108, acc.: 57.03%] [G loss: 0.794721]\n",
      "epoch:8 step:6409 [D loss: 0.695953, acc.: 58.59%] [G loss: 0.760831]\n",
      "epoch:8 step:6410 [D loss: 0.697803, acc.: 48.44%] [G loss: 0.804768]\n",
      "epoch:8 step:6411 [D loss: 0.724382, acc.: 46.88%] [G loss: 0.805091]\n",
      "epoch:8 step:6412 [D loss: 0.682760, acc.: 58.59%] [G loss: 0.819516]\n",
      "epoch:8 step:6413 [D loss: 0.703793, acc.: 49.22%] [G loss: 0.860771]\n",
      "epoch:8 step:6414 [D loss: 0.672092, acc.: 60.94%] [G loss: 0.803696]\n",
      "epoch:8 step:6415 [D loss: 0.718938, acc.: 51.56%] [G loss: 0.797449]\n",
      "epoch:8 step:6416 [D loss: 0.730065, acc.: 46.09%] [G loss: 0.803405]\n",
      "epoch:8 step:6417 [D loss: 0.739541, acc.: 40.62%] [G loss: 0.895553]\n",
      "epoch:8 step:6418 [D loss: 0.713129, acc.: 53.12%] [G loss: 0.843039]\n",
      "epoch:8 step:6419 [D loss: 0.711717, acc.: 55.47%] [G loss: 0.904964]\n",
      "epoch:8 step:6420 [D loss: 0.744389, acc.: 46.88%] [G loss: 0.818440]\n",
      "epoch:8 step:6421 [D loss: 0.739161, acc.: 45.31%] [G loss: 0.770121]\n",
      "epoch:8 step:6422 [D loss: 0.777156, acc.: 35.94%] [G loss: 0.745673]\n",
      "epoch:8 step:6423 [D loss: 0.739051, acc.: 46.09%] [G loss: 0.863233]\n",
      "epoch:8 step:6424 [D loss: 0.704598, acc.: 52.34%] [G loss: 0.839753]\n",
      "epoch:8 step:6425 [D loss: 0.658410, acc.: 58.59%] [G loss: 0.833814]\n",
      "epoch:8 step:6426 [D loss: 0.761922, acc.: 39.84%] [G loss: 0.789181]\n",
      "epoch:8 step:6427 [D loss: 0.711241, acc.: 53.12%] [G loss: 0.799121]\n",
      "epoch:8 step:6428 [D loss: 0.617485, acc.: 69.53%] [G loss: 0.894020]\n",
      "epoch:8 step:6429 [D loss: 0.668346, acc.: 53.91%] [G loss: 0.814582]\n",
      "epoch:8 step:6430 [D loss: 0.750921, acc.: 45.31%] [G loss: 0.764696]\n",
      "epoch:8 step:6431 [D loss: 0.655896, acc.: 61.72%] [G loss: 0.780674]\n",
      "epoch:8 step:6432 [D loss: 0.765110, acc.: 38.28%] [G loss: 0.712165]\n",
      "epoch:8 step:6433 [D loss: 0.681989, acc.: 56.25%] [G loss: 0.766522]\n",
      "epoch:8 step:6434 [D loss: 0.709805, acc.: 49.22%] [G loss: 0.822716]\n",
      "epoch:8 step:6435 [D loss: 0.671885, acc.: 57.81%] [G loss: 0.884974]\n",
      "epoch:8 step:6436 [D loss: 0.730634, acc.: 46.88%] [G loss: 0.805250]\n",
      "epoch:8 step:6437 [D loss: 0.670578, acc.: 54.69%] [G loss: 0.827615]\n",
      "epoch:8 step:6438 [D loss: 0.677629, acc.: 57.03%] [G loss: 0.768364]\n",
      "epoch:8 step:6439 [D loss: 0.686603, acc.: 57.81%] [G loss: 0.829037]\n",
      "epoch:8 step:6440 [D loss: 0.642994, acc.: 65.62%] [G loss: 0.788311]\n",
      "epoch:8 step:6441 [D loss: 0.672133, acc.: 57.03%] [G loss: 0.791682]\n",
      "epoch:8 step:6442 [D loss: 0.710905, acc.: 49.22%] [G loss: 0.788440]\n",
      "epoch:8 step:6443 [D loss: 0.697966, acc.: 57.81%] [G loss: 0.770070]\n",
      "epoch:8 step:6444 [D loss: 0.655019, acc.: 61.72%] [G loss: 0.817922]\n",
      "epoch:8 step:6445 [D loss: 0.716622, acc.: 48.44%] [G loss: 0.829226]\n",
      "epoch:8 step:6446 [D loss: 0.717221, acc.: 46.09%] [G loss: 0.765831]\n",
      "epoch:8 step:6447 [D loss: 0.704198, acc.: 54.69%] [G loss: 0.754167]\n",
      "epoch:8 step:6448 [D loss: 0.715104, acc.: 46.88%] [G loss: 0.723624]\n",
      "epoch:8 step:6449 [D loss: 0.725793, acc.: 43.75%] [G loss: 0.765988]\n",
      "epoch:8 step:6450 [D loss: 0.673734, acc.: 59.38%] [G loss: 0.755322]\n",
      "epoch:8 step:6451 [D loss: 0.679636, acc.: 62.50%] [G loss: 0.823307]\n",
      "epoch:8 step:6452 [D loss: 0.708488, acc.: 57.81%] [G loss: 0.731508]\n",
      "epoch:8 step:6453 [D loss: 0.665229, acc.: 58.59%] [G loss: 0.783200]\n",
      "epoch:8 step:6454 [D loss: 0.708419, acc.: 56.25%] [G loss: 0.807600]\n",
      "epoch:8 step:6455 [D loss: 0.681464, acc.: 55.47%] [G loss: 0.811675]\n",
      "epoch:8 step:6456 [D loss: 0.695430, acc.: 53.12%] [G loss: 0.887626]\n",
      "epoch:8 step:6457 [D loss: 0.689743, acc.: 50.00%] [G loss: 0.740691]\n",
      "epoch:8 step:6458 [D loss: 0.641060, acc.: 61.72%] [G loss: 0.769809]\n",
      "epoch:8 step:6459 [D loss: 0.702767, acc.: 59.38%] [G loss: 0.783178]\n",
      "epoch:8 step:6460 [D loss: 0.698868, acc.: 53.12%] [G loss: 0.716938]\n",
      "epoch:8 step:6461 [D loss: 0.830633, acc.: 28.12%] [G loss: 0.674175]\n",
      "epoch:8 step:6462 [D loss: 0.680771, acc.: 55.47%] [G loss: 0.816238]\n",
      "epoch:8 step:6463 [D loss: 0.691412, acc.: 57.03%] [G loss: 0.795472]\n",
      "epoch:8 step:6464 [D loss: 0.767570, acc.: 37.50%] [G loss: 0.822104]\n",
      "epoch:8 step:6465 [D loss: 0.719052, acc.: 50.78%] [G loss: 0.742633]\n",
      "epoch:8 step:6466 [D loss: 0.719472, acc.: 53.12%] [G loss: 0.813986]\n",
      "epoch:8 step:6467 [D loss: 0.707105, acc.: 55.47%] [G loss: 0.790819]\n",
      "epoch:8 step:6468 [D loss: 0.708729, acc.: 50.00%] [G loss: 0.819534]\n",
      "epoch:8 step:6469 [D loss: 0.724482, acc.: 47.66%] [G loss: 0.833015]\n",
      "epoch:8 step:6470 [D loss: 0.647693, acc.: 64.84%] [G loss: 0.870064]\n",
      "epoch:8 step:6471 [D loss: 0.666104, acc.: 62.50%] [G loss: 0.796897]\n",
      "epoch:8 step:6472 [D loss: 0.680718, acc.: 67.19%] [G loss: 0.847902]\n",
      "epoch:8 step:6473 [D loss: 0.694562, acc.: 51.56%] [G loss: 0.749840]\n",
      "epoch:8 step:6474 [D loss: 0.737663, acc.: 45.31%] [G loss: 0.781200]\n",
      "epoch:8 step:6475 [D loss: 0.651153, acc.: 64.06%] [G loss: 0.876872]\n",
      "epoch:8 step:6476 [D loss: 0.669261, acc.: 53.91%] [G loss: 0.799172]\n",
      "epoch:8 step:6477 [D loss: 0.667711, acc.: 61.72%] [G loss: 0.785621]\n",
      "epoch:8 step:6478 [D loss: 0.736069, acc.: 46.88%] [G loss: 0.811948]\n",
      "epoch:8 step:6479 [D loss: 0.702343, acc.: 53.12%] [G loss: 0.789806]\n",
      "epoch:8 step:6480 [D loss: 0.722862, acc.: 48.44%] [G loss: 0.740943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6481 [D loss: 0.701767, acc.: 55.47%] [G loss: 0.702165]\n",
      "epoch:8 step:6482 [D loss: 0.687697, acc.: 58.59%] [G loss: 0.818219]\n",
      "epoch:8 step:6483 [D loss: 0.686122, acc.: 57.03%] [G loss: 0.769205]\n",
      "epoch:8 step:6484 [D loss: 0.687829, acc.: 57.03%] [G loss: 0.735734]\n",
      "epoch:8 step:6485 [D loss: 0.790870, acc.: 35.94%] [G loss: 0.732562]\n",
      "epoch:8 step:6486 [D loss: 0.697553, acc.: 54.69%] [G loss: 0.806600]\n",
      "epoch:8 step:6487 [D loss: 0.694152, acc.: 57.03%] [G loss: 0.768194]\n",
      "epoch:8 step:6488 [D loss: 0.774773, acc.: 35.94%] [G loss: 0.831907]\n",
      "epoch:8 step:6489 [D loss: 0.744327, acc.: 43.75%] [G loss: 0.891020]\n",
      "epoch:8 step:6490 [D loss: 0.669443, acc.: 55.47%] [G loss: 0.806678]\n",
      "epoch:8 step:6491 [D loss: 0.683395, acc.: 55.47%] [G loss: 0.829975]\n",
      "epoch:8 step:6492 [D loss: 0.773250, acc.: 36.72%] [G loss: 0.728362]\n",
      "epoch:8 step:6493 [D loss: 0.744940, acc.: 42.97%] [G loss: 0.744893]\n",
      "epoch:8 step:6494 [D loss: 0.688915, acc.: 55.47%] [G loss: 0.757788]\n",
      "epoch:8 step:6495 [D loss: 0.734352, acc.: 50.78%] [G loss: 0.742261]\n",
      "epoch:8 step:6496 [D loss: 0.724594, acc.: 47.66%] [G loss: 0.782170]\n",
      "epoch:8 step:6497 [D loss: 0.763398, acc.: 39.84%] [G loss: 0.807181]\n",
      "epoch:8 step:6498 [D loss: 0.694543, acc.: 55.47%] [G loss: 0.927972]\n",
      "epoch:8 step:6499 [D loss: 0.682371, acc.: 52.34%] [G loss: 0.824012]\n",
      "epoch:8 step:6500 [D loss: 0.694379, acc.: 51.56%] [G loss: 0.807352]\n",
      "epoch:8 step:6501 [D loss: 0.709448, acc.: 53.91%] [G loss: 0.840478]\n",
      "epoch:8 step:6502 [D loss: 0.665357, acc.: 62.50%] [G loss: 0.812407]\n",
      "epoch:8 step:6503 [D loss: 0.716403, acc.: 50.78%] [G loss: 0.695785]\n",
      "epoch:8 step:6504 [D loss: 0.674632, acc.: 57.81%] [G loss: 0.809814]\n",
      "epoch:8 step:6505 [D loss: 0.698854, acc.: 51.56%] [G loss: 0.788754]\n",
      "epoch:8 step:6506 [D loss: 0.679436, acc.: 57.03%] [G loss: 0.818720]\n",
      "epoch:8 step:6507 [D loss: 0.664440, acc.: 57.03%] [G loss: 0.806893]\n",
      "epoch:8 step:6508 [D loss: 0.670634, acc.: 59.38%] [G loss: 0.857624]\n",
      "epoch:8 step:6509 [D loss: 0.656109, acc.: 62.50%] [G loss: 0.880935]\n",
      "epoch:8 step:6510 [D loss: 0.683319, acc.: 53.12%] [G loss: 0.824746]\n",
      "epoch:8 step:6511 [D loss: 0.705311, acc.: 55.47%] [G loss: 0.815274]\n",
      "epoch:8 step:6512 [D loss: 0.725407, acc.: 43.75%] [G loss: 0.783472]\n",
      "epoch:8 step:6513 [D loss: 0.710456, acc.: 50.78%] [G loss: 0.752174]\n",
      "epoch:8 step:6514 [D loss: 0.748446, acc.: 40.62%] [G loss: 0.745198]\n",
      "epoch:8 step:6515 [D loss: 0.763438, acc.: 42.97%] [G loss: 0.775316]\n",
      "epoch:8 step:6516 [D loss: 0.678339, acc.: 57.03%] [G loss: 0.791132]\n",
      "epoch:8 step:6517 [D loss: 0.728521, acc.: 46.88%] [G loss: 0.760182]\n",
      "epoch:8 step:6518 [D loss: 0.729430, acc.: 42.97%] [G loss: 0.781275]\n",
      "epoch:8 step:6519 [D loss: 0.748721, acc.: 42.97%] [G loss: 0.810526]\n",
      "epoch:8 step:6520 [D loss: 0.709681, acc.: 49.22%] [G loss: 0.779523]\n",
      "epoch:8 step:6521 [D loss: 0.697388, acc.: 49.22%] [G loss: 0.831232]\n",
      "epoch:8 step:6522 [D loss: 0.736431, acc.: 46.09%] [G loss: 0.813692]\n",
      "epoch:8 step:6523 [D loss: 0.735488, acc.: 38.28%] [G loss: 0.826141]\n",
      "epoch:8 step:6524 [D loss: 0.691527, acc.: 55.47%] [G loss: 0.882257]\n",
      "epoch:8 step:6525 [D loss: 0.779928, acc.: 36.72%] [G loss: 0.799720]\n",
      "epoch:8 step:6526 [D loss: 0.701208, acc.: 55.47%] [G loss: 0.751620]\n",
      "epoch:8 step:6527 [D loss: 0.720135, acc.: 44.53%] [G loss: 0.723661]\n",
      "epoch:8 step:6528 [D loss: 0.726626, acc.: 52.34%] [G loss: 0.788512]\n",
      "epoch:8 step:6529 [D loss: 0.683680, acc.: 56.25%] [G loss: 0.795902]\n",
      "epoch:8 step:6530 [D loss: 0.675203, acc.: 55.47%] [G loss: 0.851534]\n",
      "epoch:8 step:6531 [D loss: 0.645337, acc.: 61.72%] [G loss: 0.837525]\n",
      "epoch:8 step:6532 [D loss: 0.742332, acc.: 43.75%] [G loss: 0.775518]\n",
      "epoch:8 step:6533 [D loss: 0.687520, acc.: 51.56%] [G loss: 0.817698]\n",
      "epoch:8 step:6534 [D loss: 0.663973, acc.: 64.06%] [G loss: 0.842054]\n",
      "epoch:8 step:6535 [D loss: 0.699844, acc.: 57.81%] [G loss: 0.768336]\n",
      "epoch:8 step:6536 [D loss: 0.683374, acc.: 53.91%] [G loss: 0.816847]\n",
      "epoch:8 step:6537 [D loss: 0.726146, acc.: 46.88%] [G loss: 0.755146]\n",
      "epoch:8 step:6538 [D loss: 0.657513, acc.: 61.72%] [G loss: 0.875141]\n",
      "epoch:8 step:6539 [D loss: 0.691983, acc.: 57.03%] [G loss: 0.828340]\n",
      "epoch:8 step:6540 [D loss: 0.753529, acc.: 42.19%] [G loss: 0.802304]\n",
      "epoch:8 step:6541 [D loss: 0.701959, acc.: 50.78%] [G loss: 0.742231]\n",
      "epoch:8 step:6542 [D loss: 0.736951, acc.: 43.75%] [G loss: 0.720846]\n",
      "epoch:8 step:6543 [D loss: 0.733944, acc.: 43.75%] [G loss: 0.738442]\n",
      "epoch:8 step:6544 [D loss: 0.703335, acc.: 53.12%] [G loss: 0.787038]\n",
      "epoch:8 step:6545 [D loss: 0.713713, acc.: 52.34%] [G loss: 0.790241]\n",
      "epoch:8 step:6546 [D loss: 0.680199, acc.: 57.03%] [G loss: 0.779420]\n",
      "epoch:8 step:6547 [D loss: 0.731261, acc.: 42.19%] [G loss: 0.727960]\n",
      "epoch:8 step:6548 [D loss: 0.684649, acc.: 52.34%] [G loss: 0.792651]\n",
      "epoch:8 step:6549 [D loss: 0.732455, acc.: 46.09%] [G loss: 0.698708]\n",
      "epoch:8 step:6550 [D loss: 0.655408, acc.: 65.62%] [G loss: 0.777615]\n",
      "epoch:8 step:6551 [D loss: 0.659396, acc.: 62.50%] [G loss: 0.828658]\n",
      "epoch:8 step:6552 [D loss: 0.711372, acc.: 50.00%] [G loss: 0.796895]\n",
      "epoch:8 step:6553 [D loss: 0.706873, acc.: 56.25%] [G loss: 0.837616]\n",
      "epoch:8 step:6554 [D loss: 0.667170, acc.: 60.94%] [G loss: 0.903532]\n",
      "epoch:8 step:6555 [D loss: 0.645049, acc.: 63.28%] [G loss: 0.797854]\n",
      "epoch:8 step:6556 [D loss: 0.700295, acc.: 51.56%] [G loss: 0.772692]\n",
      "epoch:8 step:6557 [D loss: 0.704724, acc.: 50.00%] [G loss: 0.800513]\n",
      "epoch:8 step:6558 [D loss: 0.722144, acc.: 46.88%] [G loss: 0.842515]\n",
      "epoch:8 step:6559 [D loss: 0.731562, acc.: 47.66%] [G loss: 0.895899]\n",
      "epoch:8 step:6560 [D loss: 0.695569, acc.: 53.12%] [G loss: 0.847837]\n",
      "epoch:8 step:6561 [D loss: 0.718225, acc.: 46.88%] [G loss: 0.752423]\n",
      "epoch:8 step:6562 [D loss: 0.691542, acc.: 63.28%] [G loss: 0.900619]\n",
      "epoch:8 step:6563 [D loss: 0.669807, acc.: 57.03%] [G loss: 0.753244]\n",
      "epoch:8 step:6564 [D loss: 0.681966, acc.: 49.22%] [G loss: 0.716220]\n",
      "epoch:8 step:6565 [D loss: 0.677029, acc.: 56.25%] [G loss: 0.765772]\n",
      "epoch:8 step:6566 [D loss: 0.641490, acc.: 67.19%] [G loss: 0.752622]\n",
      "epoch:8 step:6567 [D loss: 0.758259, acc.: 39.84%] [G loss: 0.856194]\n",
      "epoch:8 step:6568 [D loss: 0.723892, acc.: 46.88%] [G loss: 0.830800]\n",
      "epoch:8 step:6569 [D loss: 0.657094, acc.: 57.81%] [G loss: 0.755263]\n",
      "epoch:8 step:6570 [D loss: 0.700709, acc.: 51.56%] [G loss: 0.748180]\n",
      "epoch:8 step:6571 [D loss: 0.670257, acc.: 60.94%] [G loss: 0.800897]\n",
      "epoch:8 step:6572 [D loss: 0.730944, acc.: 48.44%] [G loss: 0.776831]\n",
      "epoch:8 step:6573 [D loss: 0.660060, acc.: 55.47%] [G loss: 0.794185]\n",
      "epoch:8 step:6574 [D loss: 0.653616, acc.: 61.72%] [G loss: 0.866577]\n",
      "epoch:8 step:6575 [D loss: 0.711784, acc.: 49.22%] [G loss: 0.768374]\n",
      "epoch:8 step:6576 [D loss: 0.703415, acc.: 51.56%] [G loss: 0.837886]\n",
      "epoch:8 step:6577 [D loss: 0.738920, acc.: 39.06%] [G loss: 0.786554]\n",
      "epoch:8 step:6578 [D loss: 0.760353, acc.: 43.75%] [G loss: 0.766793]\n",
      "epoch:8 step:6579 [D loss: 0.692438, acc.: 52.34%] [G loss: 0.923630]\n",
      "epoch:8 step:6580 [D loss: 0.692472, acc.: 49.22%] [G loss: 0.811883]\n",
      "epoch:8 step:6581 [D loss: 0.639925, acc.: 64.06%] [G loss: 0.793940]\n",
      "epoch:8 step:6582 [D loss: 0.667587, acc.: 61.72%] [G loss: 0.847356]\n",
      "epoch:8 step:6583 [D loss: 0.670153, acc.: 60.94%] [G loss: 0.775756]\n",
      "epoch:8 step:6584 [D loss: 0.651204, acc.: 61.72%] [G loss: 0.890616]\n",
      "epoch:8 step:6585 [D loss: 0.676157, acc.: 60.94%] [G loss: 0.776077]\n",
      "epoch:8 step:6586 [D loss: 0.664182, acc.: 57.03%] [G loss: 0.780087]\n",
      "epoch:8 step:6587 [D loss: 0.594103, acc.: 78.91%] [G loss: 0.804672]\n",
      "epoch:8 step:6588 [D loss: 0.652120, acc.: 62.50%] [G loss: 0.778350]\n",
      "epoch:8 step:6589 [D loss: 0.672413, acc.: 57.81%] [G loss: 0.733446]\n",
      "epoch:8 step:6590 [D loss: 0.648273, acc.: 63.28%] [G loss: 0.741512]\n",
      "epoch:8 step:6591 [D loss: 0.693762, acc.: 51.56%] [G loss: 0.683244]\n",
      "epoch:8 step:6592 [D loss: 0.702977, acc.: 52.34%] [G loss: 0.693452]\n",
      "epoch:8 step:6593 [D loss: 0.705159, acc.: 52.34%] [G loss: 0.718222]\n",
      "epoch:8 step:6594 [D loss: 0.699132, acc.: 57.03%] [G loss: 0.687206]\n",
      "epoch:8 step:6595 [D loss: 0.703275, acc.: 52.34%] [G loss: 0.675882]\n",
      "epoch:8 step:6596 [D loss: 0.709021, acc.: 49.22%] [G loss: 0.689222]\n",
      "epoch:8 step:6597 [D loss: 0.752465, acc.: 32.81%] [G loss: 0.636701]\n",
      "epoch:8 step:6598 [D loss: 0.723813, acc.: 51.56%] [G loss: 0.744628]\n",
      "epoch:8 step:6599 [D loss: 0.683352, acc.: 53.91%] [G loss: 0.650611]\n",
      "epoch:8 step:6600 [D loss: 0.768413, acc.: 37.50%] [G loss: 0.674700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6601 [D loss: 0.696389, acc.: 51.56%] [G loss: 0.661705]\n",
      "epoch:8 step:6602 [D loss: 0.702153, acc.: 46.88%] [G loss: 0.755631]\n",
      "epoch:8 step:6603 [D loss: 0.750319, acc.: 43.75%] [G loss: 0.791977]\n",
      "epoch:8 step:6604 [D loss: 0.731138, acc.: 49.22%] [G loss: 0.753720]\n",
      "epoch:8 step:6605 [D loss: 0.712927, acc.: 50.00%] [G loss: 0.846970]\n",
      "epoch:8 step:6606 [D loss: 0.755938, acc.: 39.06%] [G loss: 0.831984]\n",
      "epoch:8 step:6607 [D loss: 0.713208, acc.: 54.69%] [G loss: 0.895959]\n",
      "epoch:8 step:6608 [D loss: 0.685455, acc.: 57.03%] [G loss: 0.805155]\n",
      "epoch:8 step:6609 [D loss: 0.691877, acc.: 52.34%] [G loss: 0.794850]\n",
      "epoch:8 step:6610 [D loss: 0.704269, acc.: 50.00%] [G loss: 0.807516]\n",
      "epoch:8 step:6611 [D loss: 0.661317, acc.: 62.50%] [G loss: 0.852601]\n",
      "epoch:8 step:6612 [D loss: 0.660361, acc.: 64.84%] [G loss: 0.783266]\n",
      "epoch:8 step:6613 [D loss: 0.595751, acc.: 74.22%] [G loss: 0.872907]\n",
      "epoch:8 step:6614 [D loss: 0.617202, acc.: 65.62%] [G loss: 0.673401]\n",
      "epoch:8 step:6615 [D loss: 0.697350, acc.: 53.91%] [G loss: 0.731637]\n",
      "epoch:8 step:6616 [D loss: 0.619201, acc.: 70.31%] [G loss: 0.721787]\n",
      "epoch:8 step:6617 [D loss: 0.649664, acc.: 61.72%] [G loss: 0.766276]\n",
      "epoch:8 step:6618 [D loss: 0.630634, acc.: 66.41%] [G loss: 0.745484]\n",
      "epoch:8 step:6619 [D loss: 0.688589, acc.: 53.12%] [G loss: 0.677326]\n",
      "epoch:8 step:6620 [D loss: 0.666577, acc.: 56.25%] [G loss: 0.653801]\n",
      "epoch:8 step:6621 [D loss: 0.795898, acc.: 37.50%] [G loss: 0.787429]\n",
      "epoch:8 step:6622 [D loss: 0.727664, acc.: 40.62%] [G loss: 0.770265]\n",
      "epoch:8 step:6623 [D loss: 0.736921, acc.: 43.75%] [G loss: 0.677419]\n",
      "epoch:8 step:6624 [D loss: 0.737329, acc.: 51.56%] [G loss: 0.751433]\n",
      "epoch:8 step:6625 [D loss: 0.707744, acc.: 51.56%] [G loss: 0.836497]\n",
      "epoch:8 step:6626 [D loss: 0.684073, acc.: 53.91%] [G loss: 0.820288]\n",
      "epoch:8 step:6627 [D loss: 0.697396, acc.: 54.69%] [G loss: 0.855813]\n",
      "epoch:8 step:6628 [D loss: 0.758394, acc.: 42.97%] [G loss: 0.937559]\n",
      "epoch:8 step:6629 [D loss: 0.609211, acc.: 72.66%] [G loss: 0.865253]\n",
      "epoch:8 step:6630 [D loss: 0.697981, acc.: 54.69%] [G loss: 0.866900]\n",
      "epoch:8 step:6631 [D loss: 0.724521, acc.: 46.88%] [G loss: 0.906563]\n",
      "epoch:8 step:6632 [D loss: 0.599482, acc.: 70.31%] [G loss: 0.923461]\n",
      "epoch:8 step:6633 [D loss: 0.654258, acc.: 63.28%] [G loss: 0.844028]\n",
      "epoch:8 step:6634 [D loss: 0.673449, acc.: 59.38%] [G loss: 0.814264]\n",
      "epoch:8 step:6635 [D loss: 0.699535, acc.: 54.69%] [G loss: 0.813891]\n",
      "epoch:8 step:6636 [D loss: 0.713691, acc.: 47.66%] [G loss: 0.849786]\n",
      "epoch:8 step:6637 [D loss: 0.772614, acc.: 32.03%] [G loss: 0.804304]\n",
      "epoch:8 step:6638 [D loss: 0.668446, acc.: 60.16%] [G loss: 0.809774]\n",
      "epoch:8 step:6639 [D loss: 0.712486, acc.: 54.69%] [G loss: 0.808940]\n",
      "epoch:8 step:6640 [D loss: 0.655085, acc.: 64.84%] [G loss: 0.802835]\n",
      "epoch:8 step:6641 [D loss: 0.625432, acc.: 66.41%] [G loss: 0.817735]\n",
      "epoch:8 step:6642 [D loss: 0.624521, acc.: 71.09%] [G loss: 0.888558]\n",
      "epoch:8 step:6643 [D loss: 0.665870, acc.: 59.38%] [G loss: 0.833690]\n",
      "epoch:8 step:6644 [D loss: 0.689055, acc.: 59.38%] [G loss: 0.809354]\n",
      "epoch:8 step:6645 [D loss: 0.640022, acc.: 66.41%] [G loss: 0.758988]\n",
      "epoch:8 step:6646 [D loss: 0.641344, acc.: 64.84%] [G loss: 0.827285]\n",
      "epoch:8 step:6647 [D loss: 0.660221, acc.: 63.28%] [G loss: 0.774536]\n",
      "epoch:8 step:6648 [D loss: 0.710910, acc.: 52.34%] [G loss: 0.696459]\n",
      "epoch:8 step:6649 [D loss: 0.689132, acc.: 53.91%] [G loss: 0.711173]\n",
      "epoch:8 step:6650 [D loss: 0.697281, acc.: 52.34%] [G loss: 0.809370]\n",
      "epoch:8 step:6651 [D loss: 0.669816, acc.: 58.59%] [G loss: 0.794516]\n",
      "epoch:8 step:6652 [D loss: 0.688510, acc.: 56.25%] [G loss: 0.824567]\n",
      "epoch:8 step:6653 [D loss: 0.701947, acc.: 49.22%] [G loss: 0.832380]\n",
      "epoch:8 step:6654 [D loss: 0.747081, acc.: 42.97%] [G loss: 0.739161]\n",
      "epoch:8 step:6655 [D loss: 0.701499, acc.: 51.56%] [G loss: 0.753623]\n",
      "epoch:8 step:6656 [D loss: 0.666856, acc.: 56.25%] [G loss: 0.766558]\n",
      "epoch:8 step:6657 [D loss: 0.754899, acc.: 39.84%] [G loss: 0.791570]\n",
      "epoch:8 step:6658 [D loss: 0.660766, acc.: 55.47%] [G loss: 0.758765]\n",
      "epoch:8 step:6659 [D loss: 0.839785, acc.: 28.91%] [G loss: 0.692612]\n",
      "epoch:8 step:6660 [D loss: 0.674265, acc.: 57.03%] [G loss: 0.692301]\n",
      "epoch:8 step:6661 [D loss: 0.721327, acc.: 46.88%] [G loss: 0.685771]\n",
      "epoch:8 step:6662 [D loss: 0.744793, acc.: 47.66%] [G loss: 0.689255]\n",
      "epoch:8 step:6663 [D loss: 0.713580, acc.: 50.78%] [G loss: 0.860465]\n",
      "epoch:8 step:6664 [D loss: 0.666450, acc.: 56.25%] [G loss: 0.874720]\n",
      "epoch:8 step:6665 [D loss: 0.642374, acc.: 61.72%] [G loss: 0.896198]\n",
      "epoch:8 step:6666 [D loss: 0.657601, acc.: 60.94%] [G loss: 0.901540]\n",
      "epoch:8 step:6667 [D loss: 0.662999, acc.: 57.03%] [G loss: 0.891337]\n",
      "epoch:8 step:6668 [D loss: 0.608279, acc.: 69.53%] [G loss: 0.929498]\n",
      "epoch:8 step:6669 [D loss: 0.626932, acc.: 68.75%] [G loss: 0.819973]\n",
      "epoch:8 step:6670 [D loss: 0.603659, acc.: 75.00%] [G loss: 0.914360]\n",
      "epoch:8 step:6671 [D loss: 0.606579, acc.: 74.22%] [G loss: 0.790055]\n",
      "epoch:8 step:6672 [D loss: 0.627731, acc.: 68.75%] [G loss: 0.786520]\n",
      "epoch:8 step:6673 [D loss: 0.604254, acc.: 70.31%] [G loss: 0.716650]\n",
      "epoch:8 step:6674 [D loss: 0.640095, acc.: 63.28%] [G loss: 0.796153]\n",
      "epoch:8 step:6675 [D loss: 0.676954, acc.: 58.59%] [G loss: 0.679707]\n",
      "epoch:8 step:6676 [D loss: 0.558833, acc.: 78.91%] [G loss: 0.691380]\n",
      "epoch:8 step:6677 [D loss: 0.638949, acc.: 64.06%] [G loss: 0.517039]\n",
      "epoch:8 step:6678 [D loss: 0.689243, acc.: 52.34%] [G loss: 0.629143]\n",
      "epoch:8 step:6679 [D loss: 0.626745, acc.: 69.53%] [G loss: 0.696542]\n",
      "epoch:8 step:6680 [D loss: 0.537117, acc.: 84.38%] [G loss: 0.646452]\n",
      "epoch:8 step:6681 [D loss: 0.753336, acc.: 40.62%] [G loss: 0.637141]\n",
      "epoch:8 step:6682 [D loss: 0.839163, acc.: 33.59%] [G loss: 0.638350]\n",
      "epoch:8 step:6683 [D loss: 0.781124, acc.: 35.94%] [G loss: 0.634888]\n",
      "epoch:8 step:6684 [D loss: 0.798878, acc.: 28.12%] [G loss: 0.655052]\n",
      "epoch:8 step:6685 [D loss: 0.848557, acc.: 21.09%] [G loss: 0.682147]\n",
      "epoch:8 step:6686 [D loss: 0.696144, acc.: 53.91%] [G loss: 0.708394]\n",
      "epoch:8 step:6687 [D loss: 0.787471, acc.: 32.03%] [G loss: 0.756404]\n",
      "epoch:8 step:6688 [D loss: 0.740695, acc.: 42.19%] [G loss: 0.711217]\n",
      "epoch:8 step:6689 [D loss: 0.717250, acc.: 51.56%] [G loss: 0.745617]\n",
      "epoch:8 step:6690 [D loss: 0.754833, acc.: 41.41%] [G loss: 0.825103]\n",
      "epoch:8 step:6691 [D loss: 0.680820, acc.: 53.12%] [G loss: 0.960916]\n",
      "epoch:8 step:6692 [D loss: 0.705712, acc.: 52.34%] [G loss: 0.883610]\n",
      "epoch:8 step:6693 [D loss: 0.662374, acc.: 59.38%] [G loss: 0.880976]\n",
      "epoch:8 step:6694 [D loss: 0.652136, acc.: 60.94%] [G loss: 0.850326]\n",
      "epoch:8 step:6695 [D loss: 0.598483, acc.: 70.31%] [G loss: 0.955706]\n",
      "epoch:8 step:6696 [D loss: 0.609619, acc.: 70.31%] [G loss: 1.006225]\n",
      "epoch:8 step:6697 [D loss: 0.578522, acc.: 75.00%] [G loss: 0.858434]\n",
      "epoch:8 step:6698 [D loss: 0.631462, acc.: 68.75%] [G loss: 0.830106]\n",
      "epoch:8 step:6699 [D loss: 0.606422, acc.: 72.66%] [G loss: 0.837088]\n",
      "epoch:8 step:6700 [D loss: 0.593837, acc.: 70.31%] [G loss: 0.911826]\n",
      "epoch:8 step:6701 [D loss: 0.696653, acc.: 53.91%] [G loss: 0.908472]\n",
      "epoch:8 step:6702 [D loss: 0.629732, acc.: 67.97%] [G loss: 0.797382]\n",
      "epoch:8 step:6703 [D loss: 0.677906, acc.: 60.16%] [G loss: 0.731176]\n",
      "epoch:8 step:6704 [D loss: 0.657693, acc.: 60.16%] [G loss: 0.790621]\n",
      "epoch:8 step:6705 [D loss: 0.638937, acc.: 64.84%] [G loss: 0.808164]\n",
      "epoch:8 step:6706 [D loss: 0.619070, acc.: 73.44%] [G loss: 0.744967]\n",
      "epoch:8 step:6707 [D loss: 0.673046, acc.: 63.28%] [G loss: 0.791034]\n",
      "epoch:8 step:6708 [D loss: 0.663074, acc.: 61.72%] [G loss: 0.689172]\n",
      "epoch:8 step:6709 [D loss: 0.676997, acc.: 51.56%] [G loss: 0.729471]\n",
      "epoch:8 step:6710 [D loss: 0.658796, acc.: 60.16%] [G loss: 0.632978]\n",
      "epoch:8 step:6711 [D loss: 0.703440, acc.: 52.34%] [G loss: 0.780680]\n",
      "epoch:8 step:6712 [D loss: 0.703383, acc.: 57.03%] [G loss: 0.618157]\n",
      "epoch:8 step:6713 [D loss: 0.749019, acc.: 46.88%] [G loss: 0.666953]\n",
      "epoch:8 step:6714 [D loss: 0.734191, acc.: 42.97%] [G loss: 0.628523]\n",
      "epoch:8 step:6715 [D loss: 0.750730, acc.: 47.66%] [G loss: 0.674946]\n",
      "epoch:8 step:6716 [D loss: 0.613109, acc.: 71.88%] [G loss: 0.678174]\n",
      "epoch:8 step:6717 [D loss: 0.704264, acc.: 57.81%] [G loss: 0.703743]\n",
      "epoch:8 step:6718 [D loss: 0.724333, acc.: 52.34%] [G loss: 0.692587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6719 [D loss: 0.759884, acc.: 38.28%] [G loss: 0.680548]\n",
      "epoch:8 step:6720 [D loss: 0.765575, acc.: 39.84%] [G loss: 0.711426]\n",
      "epoch:8 step:6721 [D loss: 0.879067, acc.: 23.44%] [G loss: 0.661714]\n",
      "epoch:8 step:6722 [D loss: 0.790028, acc.: 39.84%] [G loss: 0.745849]\n",
      "epoch:8 step:6723 [D loss: 0.765054, acc.: 42.19%] [G loss: 0.799213]\n",
      "epoch:8 step:6724 [D loss: 0.702169, acc.: 49.22%] [G loss: 0.836214]\n",
      "epoch:8 step:6725 [D loss: 0.723328, acc.: 53.12%] [G loss: 0.863028]\n",
      "epoch:8 step:6726 [D loss: 0.691569, acc.: 62.50%] [G loss: 0.864820]\n",
      "epoch:8 step:6727 [D loss: 0.702097, acc.: 51.56%] [G loss: 0.900103]\n",
      "epoch:8 step:6728 [D loss: 0.752913, acc.: 42.97%] [G loss: 0.804462]\n",
      "epoch:8 step:6729 [D loss: 0.675840, acc.: 54.69%] [G loss: 0.874014]\n",
      "epoch:8 step:6730 [D loss: 0.697533, acc.: 54.69%] [G loss: 0.743737]\n",
      "epoch:8 step:6731 [D loss: 0.706331, acc.: 50.78%] [G loss: 0.854091]\n",
      "epoch:8 step:6732 [D loss: 0.636401, acc.: 67.97%] [G loss: 0.807653]\n",
      "epoch:8 step:6733 [D loss: 0.643902, acc.: 64.84%] [G loss: 0.741062]\n",
      "epoch:8 step:6734 [D loss: 0.586251, acc.: 74.22%] [G loss: 0.830605]\n",
      "epoch:8 step:6735 [D loss: 0.742779, acc.: 46.09%] [G loss: 0.686657]\n",
      "epoch:8 step:6736 [D loss: 0.681824, acc.: 58.59%] [G loss: 0.756091]\n",
      "epoch:8 step:6737 [D loss: 0.707971, acc.: 50.00%] [G loss: 0.716439]\n",
      "epoch:8 step:6738 [D loss: 0.628245, acc.: 69.53%] [G loss: 0.769428]\n",
      "epoch:8 step:6739 [D loss: 0.657756, acc.: 59.38%] [G loss: 0.787983]\n",
      "epoch:8 step:6740 [D loss: 0.696131, acc.: 54.69%] [G loss: 0.763182]\n",
      "epoch:8 step:6741 [D loss: 0.602839, acc.: 71.88%] [G loss: 0.840078]\n",
      "epoch:8 step:6742 [D loss: 0.692496, acc.: 57.81%] [G loss: 0.790037]\n",
      "epoch:8 step:6743 [D loss: 0.689963, acc.: 55.47%] [G loss: 0.809620]\n",
      "epoch:8 step:6744 [D loss: 0.706518, acc.: 55.47%] [G loss: 0.688798]\n",
      "epoch:8 step:6745 [D loss: 0.680653, acc.: 59.38%] [G loss: 0.785057]\n",
      "epoch:8 step:6746 [D loss: 0.650543, acc.: 67.19%] [G loss: 0.788692]\n",
      "epoch:8 step:6747 [D loss: 0.670019, acc.: 55.47%] [G loss: 0.776904]\n",
      "epoch:8 step:6748 [D loss: 0.664483, acc.: 59.38%] [G loss: 0.709213]\n",
      "epoch:8 step:6749 [D loss: 0.706187, acc.: 58.59%] [G loss: 0.653801]\n",
      "epoch:8 step:6750 [D loss: 0.730785, acc.: 46.88%] [G loss: 0.701589]\n",
      "epoch:8 step:6751 [D loss: 0.723830, acc.: 47.66%] [G loss: 0.825726]\n",
      "epoch:8 step:6752 [D loss: 0.774596, acc.: 36.72%] [G loss: 0.746649]\n",
      "epoch:8 step:6753 [D loss: 0.710575, acc.: 49.22%] [G loss: 0.790960]\n",
      "epoch:8 step:6754 [D loss: 0.723081, acc.: 51.56%] [G loss: 0.910686]\n",
      "epoch:8 step:6755 [D loss: 0.716196, acc.: 51.56%] [G loss: 0.887582]\n",
      "epoch:8 step:6756 [D loss: 0.690392, acc.: 61.72%] [G loss: 0.864777]\n",
      "epoch:8 step:6757 [D loss: 0.748910, acc.: 40.62%] [G loss: 0.854613]\n",
      "epoch:8 step:6758 [D loss: 0.669717, acc.: 63.28%] [G loss: 0.928382]\n",
      "epoch:8 step:6759 [D loss: 0.654856, acc.: 60.94%] [G loss: 0.886178]\n",
      "epoch:8 step:6760 [D loss: 0.628489, acc.: 71.88%] [G loss: 0.827525]\n",
      "epoch:8 step:6761 [D loss: 0.661322, acc.: 61.72%] [G loss: 0.886510]\n",
      "epoch:8 step:6762 [D loss: 0.686625, acc.: 56.25%] [G loss: 0.745024]\n",
      "epoch:8 step:6763 [D loss: 0.714854, acc.: 51.56%] [G loss: 0.733490]\n",
      "epoch:8 step:6764 [D loss: 0.665008, acc.: 60.94%] [G loss: 0.945672]\n",
      "epoch:8 step:6765 [D loss: 0.720562, acc.: 56.25%] [G loss: 0.882404]\n",
      "epoch:8 step:6766 [D loss: 0.584093, acc.: 73.44%] [G loss: 0.998515]\n",
      "epoch:8 step:6767 [D loss: 0.609978, acc.: 75.78%] [G loss: 0.902939]\n",
      "epoch:8 step:6768 [D loss: 0.639481, acc.: 61.72%] [G loss: 0.945696]\n",
      "epoch:8 step:6769 [D loss: 0.655252, acc.: 62.50%] [G loss: 0.836347]\n",
      "epoch:8 step:6770 [D loss: 0.624873, acc.: 66.41%] [G loss: 0.849309]\n",
      "epoch:8 step:6771 [D loss: 0.609131, acc.: 71.09%] [G loss: 0.884998]\n",
      "epoch:8 step:6772 [D loss: 0.685706, acc.: 56.25%] [G loss: 0.736558]\n",
      "epoch:8 step:6773 [D loss: 0.682055, acc.: 63.28%] [G loss: 0.935364]\n",
      "epoch:8 step:6774 [D loss: 0.789703, acc.: 36.72%] [G loss: 0.759657]\n",
      "epoch:8 step:6775 [D loss: 0.650669, acc.: 64.84%] [G loss: 0.741033]\n",
      "epoch:8 step:6776 [D loss: 0.662461, acc.: 57.81%] [G loss: 0.745619]\n",
      "epoch:8 step:6777 [D loss: 0.673454, acc.: 53.12%] [G loss: 0.736674]\n",
      "epoch:8 step:6778 [D loss: 0.690829, acc.: 52.34%] [G loss: 0.676573]\n",
      "epoch:8 step:6779 [D loss: 0.693788, acc.: 56.25%] [G loss: 0.840983]\n",
      "epoch:8 step:6780 [D loss: 0.724230, acc.: 46.09%] [G loss: 0.775772]\n",
      "epoch:8 step:6781 [D loss: 0.649085, acc.: 67.19%] [G loss: 0.830004]\n",
      "epoch:8 step:6782 [D loss: 0.649218, acc.: 63.28%] [G loss: 0.770414]\n",
      "epoch:8 step:6783 [D loss: 0.767019, acc.: 38.28%] [G loss: 0.753108]\n",
      "epoch:8 step:6784 [D loss: 0.627962, acc.: 64.84%] [G loss: 0.764527]\n",
      "epoch:8 step:6785 [D loss: 0.669804, acc.: 59.38%] [G loss: 0.794702]\n",
      "epoch:8 step:6786 [D loss: 0.680079, acc.: 54.69%] [G loss: 0.709916]\n",
      "epoch:8 step:6787 [D loss: 0.752428, acc.: 46.09%] [G loss: 0.692259]\n",
      "epoch:8 step:6788 [D loss: 0.620555, acc.: 67.97%] [G loss: 0.795522]\n",
      "epoch:8 step:6789 [D loss: 0.665216, acc.: 66.41%] [G loss: 0.780990]\n",
      "epoch:8 step:6790 [D loss: 0.680771, acc.: 54.69%] [G loss: 0.807426]\n",
      "epoch:8 step:6791 [D loss: 0.694200, acc.: 54.69%] [G loss: 0.792855]\n",
      "epoch:8 step:6792 [D loss: 0.842379, acc.: 25.78%] [G loss: 0.773406]\n",
      "epoch:8 step:6793 [D loss: 0.693874, acc.: 50.78%] [G loss: 0.877657]\n",
      "epoch:8 step:6794 [D loss: 0.862748, acc.: 26.56%] [G loss: 0.714402]\n",
      "epoch:8 step:6795 [D loss: 0.759118, acc.: 39.06%] [G loss: 0.702688]\n",
      "epoch:8 step:6796 [D loss: 0.756036, acc.: 46.88%] [G loss: 0.757405]\n",
      "epoch:8 step:6797 [D loss: 0.714880, acc.: 52.34%] [G loss: 0.870125]\n",
      "epoch:8 step:6798 [D loss: 0.716052, acc.: 49.22%] [G loss: 0.759276]\n",
      "epoch:8 step:6799 [D loss: 0.738779, acc.: 44.53%] [G loss: 0.835658]\n",
      "epoch:8 step:6800 [D loss: 0.715274, acc.: 48.44%] [G loss: 0.790846]\n",
      "epoch:8 step:6801 [D loss: 0.710659, acc.: 51.56%] [G loss: 0.751866]\n",
      "epoch:8 step:6802 [D loss: 0.695280, acc.: 54.69%] [G loss: 0.929486]\n",
      "epoch:8 step:6803 [D loss: 0.651291, acc.: 64.06%] [G loss: 0.777401]\n",
      "epoch:8 step:6804 [D loss: 0.771763, acc.: 36.72%] [G loss: 0.752629]\n",
      "epoch:8 step:6805 [D loss: 0.753939, acc.: 42.19%] [G loss: 0.864977]\n",
      "epoch:8 step:6806 [D loss: 0.644716, acc.: 69.53%] [G loss: 0.840507]\n",
      "epoch:8 step:6807 [D loss: 0.683923, acc.: 58.59%] [G loss: 0.867738]\n",
      "epoch:8 step:6808 [D loss: 0.692207, acc.: 54.69%] [G loss: 0.788557]\n",
      "epoch:8 step:6809 [D loss: 0.702838, acc.: 47.66%] [G loss: 0.848754]\n",
      "epoch:8 step:6810 [D loss: 0.679848, acc.: 64.06%] [G loss: 0.823699]\n",
      "epoch:8 step:6811 [D loss: 0.713587, acc.: 50.00%] [G loss: 0.769002]\n",
      "epoch:8 step:6812 [D loss: 0.672697, acc.: 54.69%] [G loss: 0.825184]\n",
      "epoch:8 step:6813 [D loss: 0.693735, acc.: 57.03%] [G loss: 0.721039]\n",
      "epoch:8 step:6814 [D loss: 0.717146, acc.: 48.44%] [G loss: 0.845172]\n",
      "epoch:8 step:6815 [D loss: 0.613205, acc.: 71.09%] [G loss: 0.957498]\n",
      "epoch:8 step:6816 [D loss: 0.625662, acc.: 64.84%] [G loss: 0.799039]\n",
      "epoch:8 step:6817 [D loss: 0.607009, acc.: 73.44%] [G loss: 0.900268]\n",
      "epoch:8 step:6818 [D loss: 0.589394, acc.: 75.78%] [G loss: 0.811451]\n",
      "epoch:8 step:6819 [D loss: 0.676177, acc.: 54.69%] [G loss: 0.732774]\n",
      "epoch:8 step:6820 [D loss: 0.643175, acc.: 59.38%] [G loss: 0.729822]\n",
      "epoch:8 step:6821 [D loss: 0.699507, acc.: 53.12%] [G loss: 0.768758]\n",
      "epoch:8 step:6822 [D loss: 0.604610, acc.: 68.75%] [G loss: 0.762970]\n",
      "epoch:8 step:6823 [D loss: 0.665362, acc.: 60.16%] [G loss: 0.667301]\n",
      "epoch:8 step:6824 [D loss: 0.716677, acc.: 51.56%] [G loss: 0.728886]\n",
      "epoch:8 step:6825 [D loss: 0.658654, acc.: 64.06%] [G loss: 0.741093]\n",
      "epoch:8 step:6826 [D loss: 0.636441, acc.: 64.06%] [G loss: 0.754119]\n",
      "epoch:8 step:6827 [D loss: 0.690969, acc.: 53.91%] [G loss: 0.695927]\n",
      "epoch:8 step:6828 [D loss: 0.686012, acc.: 57.03%] [G loss: 0.710613]\n",
      "epoch:8 step:6829 [D loss: 0.794318, acc.: 37.50%] [G loss: 0.644350]\n",
      "epoch:8 step:6830 [D loss: 0.696613, acc.: 50.78%] [G loss: 0.697595]\n",
      "epoch:8 step:6831 [D loss: 0.760457, acc.: 43.75%] [G loss: 0.702406]\n",
      "epoch:8 step:6832 [D loss: 0.695559, acc.: 48.44%] [G loss: 0.747511]\n",
      "epoch:8 step:6833 [D loss: 0.694835, acc.: 53.12%] [G loss: 0.813485]\n",
      "epoch:8 step:6834 [D loss: 0.706962, acc.: 51.56%] [G loss: 0.828393]\n",
      "epoch:8 step:6835 [D loss: 0.653189, acc.: 63.28%] [G loss: 0.775340]\n",
      "epoch:8 step:6836 [D loss: 0.639841, acc.: 63.28%] [G loss: 0.887533]\n",
      "epoch:8 step:6837 [D loss: 0.719843, acc.: 48.44%] [G loss: 0.759418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6838 [D loss: 0.730434, acc.: 42.97%] [G loss: 0.734712]\n",
      "epoch:8 step:6839 [D loss: 0.654090, acc.: 64.84%] [G loss: 0.879350]\n",
      "epoch:8 step:6840 [D loss: 0.727007, acc.: 42.97%] [G loss: 0.780858]\n",
      "epoch:8 step:6841 [D loss: 0.725051, acc.: 53.12%] [G loss: 0.843302]\n",
      "epoch:8 step:6842 [D loss: 0.617436, acc.: 67.19%] [G loss: 0.905577]\n",
      "epoch:8 step:6843 [D loss: 0.652715, acc.: 60.94%] [G loss: 0.833558]\n",
      "epoch:8 step:6844 [D loss: 0.627063, acc.: 67.19%] [G loss: 0.853647]\n",
      "epoch:8 step:6845 [D loss: 0.591543, acc.: 74.22%] [G loss: 0.927678]\n",
      "epoch:8 step:6846 [D loss: 0.608674, acc.: 67.97%] [G loss: 0.863095]\n",
      "epoch:8 step:6847 [D loss: 0.628598, acc.: 65.62%] [G loss: 0.842621]\n",
      "epoch:8 step:6848 [D loss: 0.604335, acc.: 71.09%] [G loss: 0.775092]\n",
      "epoch:8 step:6849 [D loss: 0.579083, acc.: 75.00%] [G loss: 0.761984]\n",
      "epoch:8 step:6850 [D loss: 0.670906, acc.: 62.50%] [G loss: 0.656507]\n",
      "epoch:8 step:6851 [D loss: 0.621031, acc.: 71.09%] [G loss: 0.773668]\n",
      "epoch:8 step:6852 [D loss: 0.556475, acc.: 76.56%] [G loss: 0.727625]\n",
      "epoch:8 step:6853 [D loss: 0.621903, acc.: 67.97%] [G loss: 0.672642]\n",
      "epoch:8 step:6854 [D loss: 0.649000, acc.: 61.72%] [G loss: 0.597912]\n",
      "epoch:8 step:6855 [D loss: 0.695573, acc.: 58.59%] [G loss: 0.580795]\n",
      "epoch:8 step:6856 [D loss: 0.710041, acc.: 51.56%] [G loss: 0.565979]\n",
      "epoch:8 step:6857 [D loss: 0.694156, acc.: 59.38%] [G loss: 0.602142]\n",
      "epoch:8 step:6858 [D loss: 0.631182, acc.: 69.53%] [G loss: 0.553603]\n",
      "epoch:8 step:6859 [D loss: 0.712691, acc.: 53.12%] [G loss: 0.650462]\n",
      "epoch:8 step:6860 [D loss: 0.713982, acc.: 50.78%] [G loss: 0.649428]\n",
      "epoch:8 step:6861 [D loss: 0.721159, acc.: 47.66%] [G loss: 0.695279]\n",
      "epoch:8 step:6862 [D loss: 0.723857, acc.: 46.09%] [G loss: 0.716400]\n",
      "epoch:8 step:6863 [D loss: 0.784745, acc.: 25.78%] [G loss: 0.659539]\n",
      "epoch:8 step:6864 [D loss: 0.782970, acc.: 39.84%] [G loss: 0.723640]\n",
      "epoch:8 step:6865 [D loss: 0.790921, acc.: 41.41%] [G loss: 0.809788]\n",
      "epoch:8 step:6866 [D loss: 0.746775, acc.: 44.53%] [G loss: 0.796571]\n",
      "epoch:8 step:6867 [D loss: 0.727449, acc.: 45.31%] [G loss: 0.810471]\n",
      "epoch:8 step:6868 [D loss: 0.700949, acc.: 55.47%] [G loss: 0.763194]\n",
      "epoch:8 step:6869 [D loss: 0.759315, acc.: 40.62%] [G loss: 0.845463]\n",
      "epoch:8 step:6870 [D loss: 0.693089, acc.: 56.25%] [G loss: 0.862573]\n",
      "epoch:8 step:6871 [D loss: 0.695337, acc.: 57.03%] [G loss: 0.811316]\n",
      "epoch:8 step:6872 [D loss: 0.715498, acc.: 46.09%] [G loss: 0.728338]\n",
      "epoch:8 step:6873 [D loss: 0.673011, acc.: 62.50%] [G loss: 0.814179]\n",
      "epoch:8 step:6874 [D loss: 0.692352, acc.: 53.91%] [G loss: 0.820678]\n",
      "epoch:8 step:6875 [D loss: 0.628132, acc.: 70.31%] [G loss: 0.810110]\n",
      "epoch:8 step:6876 [D loss: 0.634587, acc.: 67.97%] [G loss: 0.781915]\n",
      "epoch:8 step:6877 [D loss: 0.667717, acc.: 60.16%] [G loss: 0.741358]\n",
      "epoch:8 step:6878 [D loss: 0.661124, acc.: 62.50%] [G loss: 0.729473]\n",
      "epoch:8 step:6879 [D loss: 0.675742, acc.: 61.72%] [G loss: 0.770062]\n",
      "epoch:8 step:6880 [D loss: 0.497284, acc.: 86.72%] [G loss: 0.866585]\n",
      "epoch:8 step:6881 [D loss: 0.660082, acc.: 58.59%] [G loss: 0.719909]\n",
      "epoch:8 step:6882 [D loss: 0.720599, acc.: 50.00%] [G loss: 0.695848]\n",
      "epoch:8 step:6883 [D loss: 0.686690, acc.: 59.38%] [G loss: 0.751576]\n",
      "epoch:8 step:6884 [D loss: 0.627233, acc.: 67.97%] [G loss: 0.917763]\n",
      "epoch:8 step:6885 [D loss: 0.701939, acc.: 53.12%] [G loss: 0.851766]\n",
      "epoch:8 step:6886 [D loss: 0.717107, acc.: 46.88%] [G loss: 0.775916]\n",
      "epoch:8 step:6887 [D loss: 0.724198, acc.: 50.78%] [G loss: 0.739303]\n",
      "epoch:8 step:6888 [D loss: 0.599450, acc.: 74.22%] [G loss: 0.886323]\n",
      "epoch:8 step:6889 [D loss: 0.735826, acc.: 44.53%] [G loss: 0.776873]\n",
      "epoch:8 step:6890 [D loss: 0.729791, acc.: 43.75%] [G loss: 0.781553]\n",
      "epoch:8 step:6891 [D loss: 0.728696, acc.: 46.09%] [G loss: 0.726215]\n",
      "epoch:8 step:6892 [D loss: 0.724985, acc.: 52.34%] [G loss: 0.739615]\n",
      "epoch:8 step:6893 [D loss: 0.668639, acc.: 57.81%] [G loss: 0.894761]\n",
      "epoch:8 step:6894 [D loss: 0.705706, acc.: 51.56%] [G loss: 0.835745]\n",
      "epoch:8 step:6895 [D loss: 0.706624, acc.: 55.47%] [G loss: 0.808710]\n",
      "epoch:8 step:6896 [D loss: 0.719514, acc.: 50.00%] [G loss: 0.785173]\n",
      "epoch:8 step:6897 [D loss: 0.731486, acc.: 50.00%] [G loss: 0.710504]\n",
      "epoch:8 step:6898 [D loss: 0.691769, acc.: 55.47%] [G loss: 0.788412]\n",
      "epoch:8 step:6899 [D loss: 0.763687, acc.: 43.75%] [G loss: 0.718302]\n",
      "epoch:8 step:6900 [D loss: 0.701762, acc.: 51.56%] [G loss: 0.698858]\n",
      "epoch:8 step:6901 [D loss: 0.753457, acc.: 44.53%] [G loss: 0.858268]\n",
      "epoch:8 step:6902 [D loss: 0.722500, acc.: 46.09%] [G loss: 0.833326]\n",
      "epoch:8 step:6903 [D loss: 0.703286, acc.: 53.12%] [G loss: 0.861072]\n",
      "epoch:8 step:6904 [D loss: 0.671831, acc.: 60.94%] [G loss: 0.857312]\n",
      "epoch:8 step:6905 [D loss: 0.817273, acc.: 31.25%] [G loss: 0.741359]\n",
      "epoch:8 step:6906 [D loss: 0.707811, acc.: 52.34%] [G loss: 0.824061]\n",
      "epoch:8 step:6907 [D loss: 0.702185, acc.: 52.34%] [G loss: 0.778679]\n",
      "epoch:8 step:6908 [D loss: 0.702477, acc.: 54.69%] [G loss: 0.802972]\n",
      "epoch:8 step:6909 [D loss: 0.697736, acc.: 53.12%] [G loss: 0.866757]\n",
      "epoch:8 step:6910 [D loss: 0.654822, acc.: 65.62%] [G loss: 0.854332]\n",
      "epoch:8 step:6911 [D loss: 0.701013, acc.: 50.78%] [G loss: 0.800266]\n",
      "epoch:8 step:6912 [D loss: 0.648592, acc.: 61.72%] [G loss: 0.911577]\n",
      "epoch:8 step:6913 [D loss: 0.657983, acc.: 56.25%] [G loss: 0.818515]\n",
      "epoch:8 step:6914 [D loss: 0.603567, acc.: 72.66%] [G loss: 0.807359]\n",
      "epoch:8 step:6915 [D loss: 0.768324, acc.: 39.06%] [G loss: 0.822444]\n",
      "epoch:8 step:6916 [D loss: 0.678504, acc.: 62.50%] [G loss: 0.839446]\n",
      "epoch:8 step:6917 [D loss: 0.729306, acc.: 47.66%] [G loss: 0.725809]\n",
      "epoch:8 step:6918 [D loss: 0.714631, acc.: 50.00%] [G loss: 0.841492]\n",
      "epoch:8 step:6919 [D loss: 0.739122, acc.: 46.09%] [G loss: 0.714044]\n",
      "epoch:8 step:6920 [D loss: 0.699746, acc.: 53.91%] [G loss: 0.783128]\n",
      "epoch:8 step:6921 [D loss: 0.708802, acc.: 47.66%] [G loss: 0.780050]\n",
      "epoch:8 step:6922 [D loss: 0.765474, acc.: 38.28%] [G loss: 0.709723]\n",
      "epoch:8 step:6923 [D loss: 0.748550, acc.: 40.62%] [G loss: 0.796912]\n",
      "epoch:8 step:6924 [D loss: 0.698588, acc.: 55.47%] [G loss: 0.782048]\n",
      "epoch:8 step:6925 [D loss: 0.701161, acc.: 50.00%] [G loss: 0.765715]\n",
      "epoch:8 step:6926 [D loss: 0.696547, acc.: 57.03%] [G loss: 0.751474]\n",
      "epoch:8 step:6927 [D loss: 0.699872, acc.: 50.00%] [G loss: 0.784829]\n",
      "epoch:8 step:6928 [D loss: 0.712040, acc.: 48.44%] [G loss: 0.720563]\n",
      "epoch:8 step:6929 [D loss: 0.724414, acc.: 48.44%] [G loss: 0.762308]\n",
      "epoch:8 step:6930 [D loss: 0.709882, acc.: 47.66%] [G loss: 0.741060]\n",
      "epoch:8 step:6931 [D loss: 0.678071, acc.: 50.78%] [G loss: 0.781788]\n",
      "epoch:8 step:6932 [D loss: 0.730431, acc.: 45.31%] [G loss: 0.767513]\n",
      "epoch:8 step:6933 [D loss: 0.674871, acc.: 57.03%] [G loss: 0.780232]\n",
      "epoch:8 step:6934 [D loss: 0.703983, acc.: 47.66%] [G loss: 0.699080]\n",
      "epoch:8 step:6935 [D loss: 0.707987, acc.: 46.09%] [G loss: 0.702782]\n",
      "epoch:8 step:6936 [D loss: 0.673602, acc.: 55.47%] [G loss: 0.851282]\n",
      "epoch:8 step:6937 [D loss: 0.723153, acc.: 47.66%] [G loss: 0.767617]\n",
      "epoch:8 step:6938 [D loss: 0.684743, acc.: 55.47%] [G loss: 0.728147]\n",
      "epoch:8 step:6939 [D loss: 0.690539, acc.: 53.91%] [G loss: 0.785622]\n",
      "epoch:8 step:6940 [D loss: 0.767505, acc.: 43.75%] [G loss: 0.706685]\n",
      "epoch:8 step:6941 [D loss: 0.676173, acc.: 59.38%] [G loss: 0.789867]\n",
      "epoch:8 step:6942 [D loss: 0.733732, acc.: 46.88%] [G loss: 0.776707]\n",
      "epoch:8 step:6943 [D loss: 0.683282, acc.: 54.69%] [G loss: 0.671666]\n",
      "epoch:8 step:6944 [D loss: 0.694932, acc.: 53.91%] [G loss: 0.741535]\n",
      "epoch:8 step:6945 [D loss: 0.749656, acc.: 48.44%] [G loss: 0.771448]\n",
      "epoch:8 step:6946 [D loss: 0.661545, acc.: 62.50%] [G loss: 0.766773]\n",
      "epoch:8 step:6947 [D loss: 0.648149, acc.: 67.97%] [G loss: 0.795015]\n",
      "epoch:8 step:6948 [D loss: 0.686109, acc.: 59.38%] [G loss: 0.817611]\n",
      "epoch:8 step:6949 [D loss: 0.720061, acc.: 51.56%] [G loss: 0.857974]\n",
      "epoch:8 step:6950 [D loss: 0.698943, acc.: 48.44%] [G loss: 0.808170]\n",
      "epoch:8 step:6951 [D loss: 0.702006, acc.: 53.12%] [G loss: 0.750676]\n",
      "epoch:8 step:6952 [D loss: 0.731192, acc.: 46.88%] [G loss: 0.743544]\n",
      "epoch:8 step:6953 [D loss: 0.651710, acc.: 60.16%] [G loss: 0.828218]\n",
      "epoch:8 step:6954 [D loss: 0.715081, acc.: 46.09%] [G loss: 0.800699]\n",
      "epoch:8 step:6955 [D loss: 0.700836, acc.: 52.34%] [G loss: 0.798085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6956 [D loss: 0.698464, acc.: 50.78%] [G loss: 0.810149]\n",
      "epoch:8 step:6957 [D loss: 0.718040, acc.: 48.44%] [G loss: 0.815107]\n",
      "epoch:8 step:6958 [D loss: 0.717530, acc.: 42.97%] [G loss: 0.818096]\n",
      "epoch:8 step:6959 [D loss: 0.655242, acc.: 66.41%] [G loss: 0.841976]\n",
      "epoch:8 step:6960 [D loss: 0.717333, acc.: 51.56%] [G loss: 0.807539]\n",
      "epoch:8 step:6961 [D loss: 0.702099, acc.: 53.91%] [G loss: 0.805189]\n",
      "epoch:8 step:6962 [D loss: 0.716305, acc.: 47.66%] [G loss: 0.766328]\n",
      "epoch:8 step:6963 [D loss: 0.694008, acc.: 53.91%] [G loss: 0.804152]\n",
      "epoch:8 step:6964 [D loss: 0.687549, acc.: 61.72%] [G loss: 0.737726]\n",
      "epoch:8 step:6965 [D loss: 0.641343, acc.: 64.84%] [G loss: 0.748900]\n",
      "epoch:8 step:6966 [D loss: 0.685121, acc.: 56.25%] [G loss: 0.683753]\n",
      "epoch:8 step:6967 [D loss: 0.689800, acc.: 60.16%] [G loss: 0.800936]\n",
      "epoch:8 step:6968 [D loss: 0.682474, acc.: 58.59%] [G loss: 0.824319]\n",
      "epoch:8 step:6969 [D loss: 0.728738, acc.: 46.88%] [G loss: 0.783219]\n",
      "epoch:8 step:6970 [D loss: 0.700551, acc.: 48.44%] [G loss: 0.697398]\n",
      "epoch:8 step:6971 [D loss: 0.730894, acc.: 50.00%] [G loss: 0.744841]\n",
      "epoch:8 step:6972 [D loss: 0.684687, acc.: 52.34%] [G loss: 0.780402]\n",
      "epoch:8 step:6973 [D loss: 0.683825, acc.: 50.78%] [G loss: 0.727785]\n",
      "epoch:8 step:6974 [D loss: 0.663221, acc.: 59.38%] [G loss: 0.735301]\n",
      "epoch:8 step:6975 [D loss: 0.738069, acc.: 44.53%] [G loss: 0.713869]\n",
      "epoch:8 step:6976 [D loss: 0.724439, acc.: 44.53%] [G loss: 0.782818]\n",
      "epoch:8 step:6977 [D loss: 0.685619, acc.: 51.56%] [G loss: 0.756768]\n",
      "epoch:8 step:6978 [D loss: 0.672734, acc.: 53.91%] [G loss: 0.780555]\n",
      "epoch:8 step:6979 [D loss: 0.745921, acc.: 44.53%] [G loss: 0.788114]\n",
      "epoch:8 step:6980 [D loss: 0.687437, acc.: 55.47%] [G loss: 0.834633]\n",
      "epoch:8 step:6981 [D loss: 0.681296, acc.: 57.03%] [G loss: 0.774803]\n",
      "epoch:8 step:6982 [D loss: 0.775340, acc.: 42.19%] [G loss: 0.827504]\n",
      "epoch:8 step:6983 [D loss: 0.728318, acc.: 46.88%] [G loss: 0.749139]\n",
      "epoch:8 step:6984 [D loss: 0.678754, acc.: 52.34%] [G loss: 0.786474]\n",
      "epoch:8 step:6985 [D loss: 0.739098, acc.: 43.75%] [G loss: 0.748073]\n",
      "epoch:8 step:6986 [D loss: 0.677490, acc.: 55.47%] [G loss: 0.774353]\n",
      "epoch:8 step:6987 [D loss: 0.708735, acc.: 51.56%] [G loss: 0.840389]\n",
      "epoch:8 step:6988 [D loss: 0.727995, acc.: 47.66%] [G loss: 0.798797]\n",
      "epoch:8 step:6989 [D loss: 0.696630, acc.: 62.50%] [G loss: 0.770573]\n",
      "epoch:8 step:6990 [D loss: 0.773263, acc.: 40.62%] [G loss: 0.735535]\n",
      "epoch:8 step:6991 [D loss: 0.753262, acc.: 46.09%] [G loss: 0.792698]\n",
      "epoch:8 step:6992 [D loss: 0.692137, acc.: 54.69%] [G loss: 0.814330]\n",
      "epoch:8 step:6993 [D loss: 0.681496, acc.: 58.59%] [G loss: 0.838364]\n",
      "epoch:8 step:6994 [D loss: 0.692452, acc.: 50.00%] [G loss: 0.880187]\n",
      "epoch:8 step:6995 [D loss: 0.705375, acc.: 51.56%] [G loss: 0.762435]\n",
      "epoch:8 step:6996 [D loss: 0.696475, acc.: 57.03%] [G loss: 0.756632]\n",
      "epoch:8 step:6997 [D loss: 0.707038, acc.: 49.22%] [G loss: 0.822522]\n",
      "epoch:8 step:6998 [D loss: 0.804156, acc.: 38.28%] [G loss: 0.682415]\n",
      "epoch:8 step:6999 [D loss: 0.710200, acc.: 51.56%] [G loss: 0.758390]\n",
      "epoch:8 step:7000 [D loss: 0.694154, acc.: 57.03%] [G loss: 0.798236]\n",
      "epoch:8 step:7001 [D loss: 0.781357, acc.: 37.50%] [G loss: 0.733366]\n",
      "epoch:8 step:7002 [D loss: 0.706374, acc.: 54.69%] [G loss: 0.848713]\n",
      "epoch:8 step:7003 [D loss: 0.743523, acc.: 43.75%] [G loss: 0.852081]\n",
      "epoch:8 step:7004 [D loss: 0.686052, acc.: 56.25%] [G loss: 0.905062]\n",
      "epoch:8 step:7005 [D loss: 0.767156, acc.: 37.50%] [G loss: 0.784008]\n",
      "epoch:8 step:7006 [D loss: 0.647466, acc.: 64.84%] [G loss: 0.748118]\n",
      "epoch:8 step:7007 [D loss: 0.731429, acc.: 47.66%] [G loss: 0.765624]\n",
      "epoch:8 step:7008 [D loss: 0.687210, acc.: 54.69%] [G loss: 0.803790]\n",
      "epoch:8 step:7009 [D loss: 0.705157, acc.: 53.12%] [G loss: 0.763931]\n",
      "epoch:8 step:7010 [D loss: 0.682012, acc.: 53.12%] [G loss: 0.845232]\n",
      "epoch:8 step:7011 [D loss: 0.695323, acc.: 50.78%] [G loss: 0.850122]\n",
      "epoch:8 step:7012 [D loss: 0.738622, acc.: 37.50%] [G loss: 0.765705]\n",
      "epoch:8 step:7013 [D loss: 0.688697, acc.: 53.12%] [G loss: 0.882926]\n",
      "epoch:8 step:7014 [D loss: 0.673135, acc.: 57.03%] [G loss: 0.813271]\n",
      "epoch:8 step:7015 [D loss: 0.651231, acc.: 61.72%] [G loss: 0.846176]\n",
      "epoch:8 step:7016 [D loss: 0.689696, acc.: 58.59%] [G loss: 0.768473]\n",
      "epoch:8 step:7017 [D loss: 0.727689, acc.: 42.97%] [G loss: 0.790815]\n",
      "epoch:8 step:7018 [D loss: 0.687556, acc.: 53.91%] [G loss: 0.775248]\n",
      "epoch:8 step:7019 [D loss: 0.718606, acc.: 48.44%] [G loss: 0.863160]\n",
      "epoch:8 step:7020 [D loss: 0.705815, acc.: 51.56%] [G loss: 0.824293]\n",
      "epoch:8 step:7021 [D loss: 0.696614, acc.: 56.25%] [G loss: 0.787976]\n",
      "epoch:8 step:7022 [D loss: 0.683261, acc.: 56.25%] [G loss: 0.814132]\n",
      "epoch:8 step:7023 [D loss: 0.730112, acc.: 45.31%] [G loss: 0.805963]\n",
      "epoch:8 step:7024 [D loss: 0.757373, acc.: 36.72%] [G loss: 0.697930]\n",
      "epoch:8 step:7025 [D loss: 0.700250, acc.: 53.12%] [G loss: 0.764169]\n",
      "epoch:8 step:7026 [D loss: 0.733884, acc.: 48.44%] [G loss: 0.744664]\n",
      "epoch:8 step:7027 [D loss: 0.657281, acc.: 58.59%] [G loss: 0.829511]\n",
      "epoch:8 step:7028 [D loss: 0.789535, acc.: 33.59%] [G loss: 0.799171]\n",
      "epoch:8 step:7029 [D loss: 0.708044, acc.: 46.09%] [G loss: 0.830794]\n",
      "epoch:9 step:7030 [D loss: 0.698473, acc.: 53.91%] [G loss: 0.937848]\n",
      "epoch:9 step:7031 [D loss: 0.682020, acc.: 58.59%] [G loss: 0.842467]\n",
      "epoch:9 step:7032 [D loss: 0.678695, acc.: 56.25%] [G loss: 0.810666]\n",
      "epoch:9 step:7033 [D loss: 0.697941, acc.: 54.69%] [G loss: 0.788288]\n",
      "epoch:9 step:7034 [D loss: 0.690068, acc.: 53.12%] [G loss: 0.813092]\n",
      "epoch:9 step:7035 [D loss: 0.624242, acc.: 67.97%] [G loss: 0.846239]\n",
      "epoch:9 step:7036 [D loss: 0.708210, acc.: 48.44%] [G loss: 0.893915]\n",
      "epoch:9 step:7037 [D loss: 0.710247, acc.: 47.66%] [G loss: 0.806666]\n",
      "epoch:9 step:7038 [D loss: 0.646430, acc.: 64.84%] [G loss: 0.831157]\n",
      "epoch:9 step:7039 [D loss: 0.704283, acc.: 55.47%] [G loss: 0.828602]\n",
      "epoch:9 step:7040 [D loss: 0.759203, acc.: 37.50%] [G loss: 0.779581]\n",
      "epoch:9 step:7041 [D loss: 0.707243, acc.: 46.88%] [G loss: 0.842513]\n",
      "epoch:9 step:7042 [D loss: 0.672529, acc.: 56.25%] [G loss: 0.825005]\n",
      "epoch:9 step:7043 [D loss: 0.720464, acc.: 49.22%] [G loss: 0.795490]\n",
      "epoch:9 step:7044 [D loss: 0.726921, acc.: 49.22%] [G loss: 0.751702]\n",
      "epoch:9 step:7045 [D loss: 0.680139, acc.: 56.25%] [G loss: 0.831829]\n",
      "epoch:9 step:7046 [D loss: 0.653579, acc.: 61.72%] [G loss: 0.805780]\n",
      "epoch:9 step:7047 [D loss: 0.706743, acc.: 53.12%] [G loss: 0.752153]\n",
      "epoch:9 step:7048 [D loss: 0.712994, acc.: 55.47%] [G loss: 0.773508]\n",
      "epoch:9 step:7049 [D loss: 0.706835, acc.: 52.34%] [G loss: 0.751056]\n",
      "epoch:9 step:7050 [D loss: 0.687365, acc.: 52.34%] [G loss: 0.816694]\n",
      "epoch:9 step:7051 [D loss: 0.663298, acc.: 57.03%] [G loss: 0.807828]\n",
      "epoch:9 step:7052 [D loss: 0.702848, acc.: 57.03%] [G loss: 0.773296]\n",
      "epoch:9 step:7053 [D loss: 0.747473, acc.: 44.53%] [G loss: 0.829809]\n",
      "epoch:9 step:7054 [D loss: 0.695368, acc.: 50.78%] [G loss: 0.792529]\n",
      "epoch:9 step:7055 [D loss: 0.690870, acc.: 53.91%] [G loss: 0.814780]\n",
      "epoch:9 step:7056 [D loss: 0.658050, acc.: 64.06%] [G loss: 0.797286]\n",
      "epoch:9 step:7057 [D loss: 0.732859, acc.: 42.97%] [G loss: 0.756716]\n",
      "epoch:9 step:7058 [D loss: 0.688472, acc.: 57.03%] [G loss: 0.732256]\n",
      "epoch:9 step:7059 [D loss: 0.725721, acc.: 42.97%] [G loss: 0.723302]\n",
      "epoch:9 step:7060 [D loss: 0.695431, acc.: 51.56%] [G loss: 0.811694]\n",
      "epoch:9 step:7061 [D loss: 0.720301, acc.: 53.91%] [G loss: 0.795487]\n",
      "epoch:9 step:7062 [D loss: 0.714729, acc.: 49.22%] [G loss: 0.751746]\n",
      "epoch:9 step:7063 [D loss: 0.678164, acc.: 54.69%] [G loss: 0.821583]\n",
      "epoch:9 step:7064 [D loss: 0.726550, acc.: 41.41%] [G loss: 0.755665]\n",
      "epoch:9 step:7065 [D loss: 0.737416, acc.: 46.09%] [G loss: 0.756510]\n",
      "epoch:9 step:7066 [D loss: 0.642666, acc.: 67.19%] [G loss: 0.705354]\n",
      "epoch:9 step:7067 [D loss: 0.695834, acc.: 54.69%] [G loss: 0.824384]\n",
      "epoch:9 step:7068 [D loss: 0.673949, acc.: 57.03%] [G loss: 0.778929]\n",
      "epoch:9 step:7069 [D loss: 0.748054, acc.: 40.62%] [G loss: 0.743509]\n",
      "epoch:9 step:7070 [D loss: 0.697885, acc.: 54.69%] [G loss: 0.729424]\n",
      "epoch:9 step:7071 [D loss: 0.694278, acc.: 48.44%] [G loss: 0.788696]\n",
      "epoch:9 step:7072 [D loss: 0.704254, acc.: 49.22%] [G loss: 0.799750]\n",
      "epoch:9 step:7073 [D loss: 0.709366, acc.: 52.34%] [G loss: 0.714841]\n",
      "epoch:9 step:7074 [D loss: 0.689540, acc.: 53.12%] [G loss: 0.772737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7075 [D loss: 0.675316, acc.: 62.50%] [G loss: 0.751389]\n",
      "epoch:9 step:7076 [D loss: 0.678931, acc.: 53.12%] [G loss: 0.791832]\n",
      "epoch:9 step:7077 [D loss: 0.712059, acc.: 50.78%] [G loss: 0.757793]\n",
      "epoch:9 step:7078 [D loss: 0.703039, acc.: 53.12%] [G loss: 0.751950]\n",
      "epoch:9 step:7079 [D loss: 0.739160, acc.: 47.66%] [G loss: 0.701535]\n",
      "epoch:9 step:7080 [D loss: 0.724481, acc.: 46.88%] [G loss: 0.759428]\n",
      "epoch:9 step:7081 [D loss: 0.683585, acc.: 57.03%] [G loss: 0.760715]\n",
      "epoch:9 step:7082 [D loss: 0.695417, acc.: 49.22%] [G loss: 0.703811]\n",
      "epoch:9 step:7083 [D loss: 0.774112, acc.: 38.28%] [G loss: 0.713104]\n",
      "epoch:9 step:7084 [D loss: 0.713180, acc.: 44.53%] [G loss: 0.792512]\n",
      "epoch:9 step:7085 [D loss: 0.672326, acc.: 56.25%] [G loss: 0.789112]\n",
      "epoch:9 step:7086 [D loss: 0.663693, acc.: 57.81%] [G loss: 0.797423]\n",
      "epoch:9 step:7087 [D loss: 0.692912, acc.: 57.03%] [G loss: 0.757091]\n",
      "epoch:9 step:7088 [D loss: 0.683878, acc.: 57.03%] [G loss: 0.748089]\n",
      "epoch:9 step:7089 [D loss: 0.719980, acc.: 51.56%] [G loss: 0.772493]\n",
      "epoch:9 step:7090 [D loss: 0.709163, acc.: 47.66%] [G loss: 0.857514]\n",
      "epoch:9 step:7091 [D loss: 0.670228, acc.: 60.94%] [G loss: 0.890161]\n",
      "epoch:9 step:7092 [D loss: 0.711061, acc.: 52.34%] [G loss: 0.804764]\n",
      "epoch:9 step:7093 [D loss: 0.757457, acc.: 42.19%] [G loss: 0.752647]\n",
      "epoch:9 step:7094 [D loss: 0.691683, acc.: 56.25%] [G loss: 0.799892]\n",
      "epoch:9 step:7095 [D loss: 0.738401, acc.: 47.66%] [G loss: 0.856573]\n",
      "epoch:9 step:7096 [D loss: 0.741103, acc.: 41.41%] [G loss: 0.776895]\n",
      "epoch:9 step:7097 [D loss: 0.755188, acc.: 44.53%] [G loss: 0.754624]\n",
      "epoch:9 step:7098 [D loss: 0.698058, acc.: 49.22%] [G loss: 0.764464]\n",
      "epoch:9 step:7099 [D loss: 0.750852, acc.: 44.53%] [G loss: 0.827099]\n",
      "epoch:9 step:7100 [D loss: 0.766578, acc.: 39.06%] [G loss: 0.710647]\n",
      "epoch:9 step:7101 [D loss: 0.746544, acc.: 40.62%] [G loss: 0.747538]\n",
      "epoch:9 step:7102 [D loss: 0.709153, acc.: 50.00%] [G loss: 0.754644]\n",
      "epoch:9 step:7103 [D loss: 0.684227, acc.: 57.81%] [G loss: 0.790489]\n",
      "epoch:9 step:7104 [D loss: 0.694858, acc.: 50.00%] [G loss: 0.733498]\n",
      "epoch:9 step:7105 [D loss: 0.675661, acc.: 61.72%] [G loss: 0.785340]\n",
      "epoch:9 step:7106 [D loss: 0.708423, acc.: 52.34%] [G loss: 0.794915]\n",
      "epoch:9 step:7107 [D loss: 0.738832, acc.: 45.31%] [G loss: 0.760246]\n",
      "epoch:9 step:7108 [D loss: 0.704567, acc.: 53.91%] [G loss: 0.750312]\n",
      "epoch:9 step:7109 [D loss: 0.666462, acc.: 51.56%] [G loss: 0.775643]\n",
      "epoch:9 step:7110 [D loss: 0.734107, acc.: 46.09%] [G loss: 0.812821]\n",
      "epoch:9 step:7111 [D loss: 0.696926, acc.: 55.47%] [G loss: 0.840549]\n",
      "epoch:9 step:7112 [D loss: 0.713482, acc.: 44.53%] [G loss: 0.827562]\n",
      "epoch:9 step:7113 [D loss: 0.731002, acc.: 46.09%] [G loss: 0.780868]\n",
      "epoch:9 step:7114 [D loss: 0.725735, acc.: 50.00%] [G loss: 0.811002]\n",
      "epoch:9 step:7115 [D loss: 0.676185, acc.: 55.47%] [G loss: 0.776863]\n",
      "epoch:9 step:7116 [D loss: 0.738507, acc.: 42.97%] [G loss: 0.786531]\n",
      "epoch:9 step:7117 [D loss: 0.688254, acc.: 57.03%] [G loss: 0.842385]\n",
      "epoch:9 step:7118 [D loss: 0.669708, acc.: 64.06%] [G loss: 0.771424]\n",
      "epoch:9 step:7119 [D loss: 0.745667, acc.: 47.66%] [G loss: 0.863302]\n",
      "epoch:9 step:7120 [D loss: 0.698705, acc.: 53.12%] [G loss: 0.848904]\n",
      "epoch:9 step:7121 [D loss: 0.697693, acc.: 53.12%] [G loss: 0.846047]\n",
      "epoch:9 step:7122 [D loss: 0.725174, acc.: 46.09%] [G loss: 0.808371]\n",
      "epoch:9 step:7123 [D loss: 0.661366, acc.: 64.06%] [G loss: 0.895443]\n",
      "epoch:9 step:7124 [D loss: 0.702537, acc.: 48.44%] [G loss: 0.905221]\n",
      "epoch:9 step:7125 [D loss: 0.686393, acc.: 53.12%] [G loss: 0.992880]\n",
      "epoch:9 step:7126 [D loss: 0.690523, acc.: 55.47%] [G loss: 0.820803]\n",
      "epoch:9 step:7127 [D loss: 0.685948, acc.: 59.38%] [G loss: 0.817778]\n",
      "epoch:9 step:7128 [D loss: 0.666001, acc.: 57.03%] [G loss: 0.845917]\n",
      "epoch:9 step:7129 [D loss: 0.686510, acc.: 50.78%] [G loss: 0.876063]\n",
      "epoch:9 step:7130 [D loss: 0.666523, acc.: 60.94%] [G loss: 0.856698]\n",
      "epoch:9 step:7131 [D loss: 0.704299, acc.: 51.56%] [G loss: 0.772472]\n",
      "epoch:9 step:7132 [D loss: 0.717211, acc.: 49.22%] [G loss: 0.868637]\n",
      "epoch:9 step:7133 [D loss: 0.645715, acc.: 60.16%] [G loss: 0.836236]\n",
      "epoch:9 step:7134 [D loss: 0.681704, acc.: 57.81%] [G loss: 0.818274]\n",
      "epoch:9 step:7135 [D loss: 0.691459, acc.: 55.47%] [G loss: 0.860441]\n",
      "epoch:9 step:7136 [D loss: 0.671979, acc.: 53.91%] [G loss: 0.804169]\n",
      "epoch:9 step:7137 [D loss: 0.723464, acc.: 44.53%] [G loss: 0.790841]\n",
      "epoch:9 step:7138 [D loss: 0.679536, acc.: 59.38%] [G loss: 0.779066]\n",
      "epoch:9 step:7139 [D loss: 0.653753, acc.: 67.97%] [G loss: 0.765633]\n",
      "epoch:9 step:7140 [D loss: 0.664537, acc.: 55.47%] [G loss: 0.789418]\n",
      "epoch:9 step:7141 [D loss: 0.674213, acc.: 60.94%] [G loss: 0.861731]\n",
      "epoch:9 step:7142 [D loss: 0.715359, acc.: 46.09%] [G loss: 0.790139]\n",
      "epoch:9 step:7143 [D loss: 0.692713, acc.: 55.47%] [G loss: 0.858701]\n",
      "epoch:9 step:7144 [D loss: 0.692798, acc.: 58.59%] [G loss: 0.850646]\n",
      "epoch:9 step:7145 [D loss: 0.684405, acc.: 56.25%] [G loss: 0.866665]\n",
      "epoch:9 step:7146 [D loss: 0.736739, acc.: 44.53%] [G loss: 0.845764]\n",
      "epoch:9 step:7147 [D loss: 0.680163, acc.: 59.38%] [G loss: 0.785650]\n",
      "epoch:9 step:7148 [D loss: 0.690114, acc.: 52.34%] [G loss: 0.860312]\n",
      "epoch:9 step:7149 [D loss: 0.734597, acc.: 48.44%] [G loss: 0.768435]\n",
      "epoch:9 step:7150 [D loss: 0.672135, acc.: 53.12%] [G loss: 0.792286]\n",
      "epoch:9 step:7151 [D loss: 0.688211, acc.: 50.78%] [G loss: 0.790491]\n",
      "epoch:9 step:7152 [D loss: 0.662386, acc.: 59.38%] [G loss: 0.761922]\n",
      "epoch:9 step:7153 [D loss: 0.726626, acc.: 44.53%] [G loss: 0.752545]\n",
      "epoch:9 step:7154 [D loss: 0.720118, acc.: 44.53%] [G loss: 0.732222]\n",
      "epoch:9 step:7155 [D loss: 0.774208, acc.: 35.16%] [G loss: 0.723936]\n",
      "epoch:9 step:7156 [D loss: 0.659421, acc.: 58.59%] [G loss: 0.808612]\n",
      "epoch:9 step:7157 [D loss: 0.684901, acc.: 58.59%] [G loss: 0.750882]\n",
      "epoch:9 step:7158 [D loss: 0.710361, acc.: 51.56%] [G loss: 0.790891]\n",
      "epoch:9 step:7159 [D loss: 0.733989, acc.: 44.53%] [G loss: 0.766775]\n",
      "epoch:9 step:7160 [D loss: 0.668662, acc.: 56.25%] [G loss: 0.784133]\n",
      "epoch:9 step:7161 [D loss: 0.671175, acc.: 60.16%] [G loss: 0.761107]\n",
      "epoch:9 step:7162 [D loss: 0.713058, acc.: 52.34%] [G loss: 0.802938]\n",
      "epoch:9 step:7163 [D loss: 0.703403, acc.: 55.47%] [G loss: 0.826520]\n",
      "epoch:9 step:7164 [D loss: 0.741316, acc.: 41.41%] [G loss: 0.740545]\n",
      "epoch:9 step:7165 [D loss: 0.714018, acc.: 54.69%] [G loss: 0.785083]\n",
      "epoch:9 step:7166 [D loss: 0.685006, acc.: 55.47%] [G loss: 0.849299]\n",
      "epoch:9 step:7167 [D loss: 0.697142, acc.: 52.34%] [G loss: 0.748254]\n",
      "epoch:9 step:7168 [D loss: 0.690567, acc.: 56.25%] [G loss: 0.754205]\n",
      "epoch:9 step:7169 [D loss: 0.664882, acc.: 57.81%] [G loss: 0.812118]\n",
      "epoch:9 step:7170 [D loss: 0.662052, acc.: 65.62%] [G loss: 0.791695]\n",
      "epoch:9 step:7171 [D loss: 0.685001, acc.: 53.91%] [G loss: 0.758009]\n",
      "epoch:9 step:7172 [D loss: 0.691449, acc.: 52.34%] [G loss: 0.824351]\n",
      "epoch:9 step:7173 [D loss: 0.681254, acc.: 60.94%] [G loss: 0.748968]\n",
      "epoch:9 step:7174 [D loss: 0.728853, acc.: 44.53%] [G loss: 0.719287]\n",
      "epoch:9 step:7175 [D loss: 0.711135, acc.: 52.34%] [G loss: 0.789046]\n",
      "epoch:9 step:7176 [D loss: 0.698321, acc.: 53.12%] [G loss: 0.773545]\n",
      "epoch:9 step:7177 [D loss: 0.691703, acc.: 53.12%] [G loss: 0.957519]\n",
      "epoch:9 step:7178 [D loss: 0.743036, acc.: 40.62%] [G loss: 0.812763]\n",
      "epoch:9 step:7179 [D loss: 0.733505, acc.: 42.97%] [G loss: 0.831820]\n",
      "epoch:9 step:7180 [D loss: 0.689364, acc.: 52.34%] [G loss: 0.762695]\n",
      "epoch:9 step:7181 [D loss: 0.694787, acc.: 53.12%] [G loss: 0.803922]\n",
      "epoch:9 step:7182 [D loss: 0.716172, acc.: 50.00%] [G loss: 0.748219]\n",
      "epoch:9 step:7183 [D loss: 0.688644, acc.: 50.78%] [G loss: 0.700857]\n",
      "epoch:9 step:7184 [D loss: 0.715551, acc.: 50.00%] [G loss: 0.712682]\n",
      "epoch:9 step:7185 [D loss: 0.711497, acc.: 48.44%] [G loss: 0.768385]\n",
      "epoch:9 step:7186 [D loss: 0.711126, acc.: 48.44%] [G loss: 0.772645]\n",
      "epoch:9 step:7187 [D loss: 0.696060, acc.: 50.78%] [G loss: 0.768795]\n",
      "epoch:9 step:7188 [D loss: 0.727302, acc.: 46.09%] [G loss: 0.773318]\n",
      "epoch:9 step:7189 [D loss: 0.676979, acc.: 61.72%] [G loss: 0.770359]\n",
      "epoch:9 step:7190 [D loss: 0.677341, acc.: 57.81%] [G loss: 0.865482]\n",
      "epoch:9 step:7191 [D loss: 0.697820, acc.: 53.12%] [G loss: 0.757842]\n",
      "epoch:9 step:7192 [D loss: 0.679111, acc.: 60.16%] [G loss: 0.828889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7193 [D loss: 0.696317, acc.: 50.78%] [G loss: 0.817345]\n",
      "epoch:9 step:7194 [D loss: 0.701395, acc.: 50.00%] [G loss: 0.847534]\n",
      "epoch:9 step:7195 [D loss: 0.695088, acc.: 56.25%] [G loss: 0.867482]\n",
      "epoch:9 step:7196 [D loss: 0.718013, acc.: 47.66%] [G loss: 0.828498]\n",
      "epoch:9 step:7197 [D loss: 0.718489, acc.: 50.00%] [G loss: 0.771031]\n",
      "epoch:9 step:7198 [D loss: 0.730772, acc.: 46.09%] [G loss: 0.769068]\n",
      "epoch:9 step:7199 [D loss: 0.699295, acc.: 53.12%] [G loss: 0.819400]\n",
      "epoch:9 step:7200 [D loss: 0.758224, acc.: 44.53%] [G loss: 0.730007]\n",
      "epoch:9 step:7201 [D loss: 0.704171, acc.: 50.00%] [G loss: 0.753252]\n",
      "epoch:9 step:7202 [D loss: 0.731146, acc.: 45.31%] [G loss: 0.848492]\n",
      "epoch:9 step:7203 [D loss: 0.699239, acc.: 52.34%] [G loss: 0.829340]\n",
      "epoch:9 step:7204 [D loss: 0.708953, acc.: 46.88%] [G loss: 0.712442]\n",
      "epoch:9 step:7205 [D loss: 0.764572, acc.: 42.19%] [G loss: 0.844844]\n",
      "epoch:9 step:7206 [D loss: 0.700379, acc.: 49.22%] [G loss: 0.762411]\n",
      "epoch:9 step:7207 [D loss: 0.756692, acc.: 42.97%] [G loss: 0.863317]\n",
      "epoch:9 step:7208 [D loss: 0.687404, acc.: 57.81%] [G loss: 0.820671]\n",
      "epoch:9 step:7209 [D loss: 0.691825, acc.: 56.25%] [G loss: 0.793049]\n",
      "epoch:9 step:7210 [D loss: 0.662041, acc.: 59.38%] [G loss: 0.802633]\n",
      "epoch:9 step:7211 [D loss: 0.738441, acc.: 42.19%] [G loss: 0.759902]\n",
      "epoch:9 step:7212 [D loss: 0.693331, acc.: 56.25%] [G loss: 0.814387]\n",
      "epoch:9 step:7213 [D loss: 0.729003, acc.: 45.31%] [G loss: 0.809249]\n",
      "epoch:9 step:7214 [D loss: 0.639068, acc.: 63.28%] [G loss: 0.798479]\n",
      "epoch:9 step:7215 [D loss: 0.720053, acc.: 46.88%] [G loss: 0.832058]\n",
      "epoch:9 step:7216 [D loss: 0.688033, acc.: 50.78%] [G loss: 0.811379]\n",
      "epoch:9 step:7217 [D loss: 0.677890, acc.: 58.59%] [G loss: 0.770396]\n",
      "epoch:9 step:7218 [D loss: 0.681145, acc.: 53.91%] [G loss: 0.774316]\n",
      "epoch:9 step:7219 [D loss: 0.709623, acc.: 55.47%] [G loss: 0.853974]\n",
      "epoch:9 step:7220 [D loss: 0.700275, acc.: 51.56%] [G loss: 0.773142]\n",
      "epoch:9 step:7221 [D loss: 0.667455, acc.: 60.16%] [G loss: 0.856332]\n",
      "epoch:9 step:7222 [D loss: 0.712389, acc.: 50.00%] [G loss: 0.817212]\n",
      "epoch:9 step:7223 [D loss: 0.720133, acc.: 46.09%] [G loss: 0.810272]\n",
      "epoch:9 step:7224 [D loss: 0.744377, acc.: 39.84%] [G loss: 0.733221]\n",
      "epoch:9 step:7225 [D loss: 0.703538, acc.: 53.91%] [G loss: 0.741052]\n",
      "epoch:9 step:7226 [D loss: 0.704184, acc.: 49.22%] [G loss: 0.853785]\n",
      "epoch:9 step:7227 [D loss: 0.704605, acc.: 53.91%] [G loss: 0.829197]\n",
      "epoch:9 step:7228 [D loss: 0.700336, acc.: 53.91%] [G loss: 0.854269]\n",
      "epoch:9 step:7229 [D loss: 0.709818, acc.: 50.78%] [G loss: 0.743073]\n",
      "epoch:9 step:7230 [D loss: 0.729198, acc.: 47.66%] [G loss: 0.697100]\n",
      "epoch:9 step:7231 [D loss: 0.739161, acc.: 42.19%] [G loss: 0.811242]\n",
      "epoch:9 step:7232 [D loss: 0.660996, acc.: 60.16%] [G loss: 0.744182]\n",
      "epoch:9 step:7233 [D loss: 0.741345, acc.: 40.62%] [G loss: 0.722155]\n",
      "epoch:9 step:7234 [D loss: 0.706940, acc.: 49.22%] [G loss: 0.779472]\n",
      "epoch:9 step:7235 [D loss: 0.726002, acc.: 48.44%] [G loss: 0.929063]\n",
      "epoch:9 step:7236 [D loss: 0.632265, acc.: 71.09%] [G loss: 0.846722]\n",
      "epoch:9 step:7237 [D loss: 0.710167, acc.: 48.44%] [G loss: 0.780465]\n",
      "epoch:9 step:7238 [D loss: 0.713106, acc.: 50.00%] [G loss: 0.704984]\n",
      "epoch:9 step:7239 [D loss: 0.623183, acc.: 75.78%] [G loss: 0.725201]\n",
      "epoch:9 step:7240 [D loss: 0.729918, acc.: 46.88%] [G loss: 0.701253]\n",
      "epoch:9 step:7241 [D loss: 0.743106, acc.: 42.19%] [G loss: 0.802098]\n",
      "epoch:9 step:7242 [D loss: 0.769964, acc.: 36.72%] [G loss: 0.773070]\n",
      "epoch:9 step:7243 [D loss: 0.633713, acc.: 64.06%] [G loss: 0.778116]\n",
      "epoch:9 step:7244 [D loss: 0.701211, acc.: 53.12%] [G loss: 0.820710]\n",
      "epoch:9 step:7245 [D loss: 0.677586, acc.: 56.25%] [G loss: 0.763376]\n",
      "epoch:9 step:7246 [D loss: 0.686680, acc.: 53.12%] [G loss: 0.825425]\n",
      "epoch:9 step:7247 [D loss: 0.716253, acc.: 47.66%] [G loss: 0.763888]\n",
      "epoch:9 step:7248 [D loss: 0.668831, acc.: 61.72%] [G loss: 0.779084]\n",
      "epoch:9 step:7249 [D loss: 0.687172, acc.: 55.47%] [G loss: 0.741339]\n",
      "epoch:9 step:7250 [D loss: 0.709303, acc.: 46.88%] [G loss: 0.747952]\n",
      "epoch:9 step:7251 [D loss: 0.690594, acc.: 53.12%] [G loss: 0.769809]\n",
      "epoch:9 step:7252 [D loss: 0.747014, acc.: 40.62%] [G loss: 0.751463]\n",
      "epoch:9 step:7253 [D loss: 0.703736, acc.: 50.78%] [G loss: 0.798259]\n",
      "epoch:9 step:7254 [D loss: 0.713816, acc.: 53.91%] [G loss: 0.788520]\n",
      "epoch:9 step:7255 [D loss: 0.670305, acc.: 57.03%] [G loss: 0.762869]\n",
      "epoch:9 step:7256 [D loss: 0.730571, acc.: 46.88%] [G loss: 0.785418]\n",
      "epoch:9 step:7257 [D loss: 0.725160, acc.: 46.88%] [G loss: 0.727726]\n",
      "epoch:9 step:7258 [D loss: 0.671809, acc.: 63.28%] [G loss: 0.782382]\n",
      "epoch:9 step:7259 [D loss: 0.692840, acc.: 54.69%] [G loss: 0.759384]\n",
      "epoch:9 step:7260 [D loss: 0.707465, acc.: 50.78%] [G loss: 0.743891]\n",
      "epoch:9 step:7261 [D loss: 0.737780, acc.: 41.41%] [G loss: 0.730507]\n",
      "epoch:9 step:7262 [D loss: 0.733382, acc.: 51.56%] [G loss: 0.743800]\n",
      "epoch:9 step:7263 [D loss: 0.704308, acc.: 50.78%] [G loss: 0.772434]\n",
      "epoch:9 step:7264 [D loss: 0.756979, acc.: 39.06%] [G loss: 0.727702]\n",
      "epoch:9 step:7265 [D loss: 0.636245, acc.: 69.53%] [G loss: 0.745706]\n",
      "epoch:9 step:7266 [D loss: 0.730249, acc.: 43.75%] [G loss: 0.693297]\n",
      "epoch:9 step:7267 [D loss: 0.659384, acc.: 62.50%] [G loss: 0.826888]\n",
      "epoch:9 step:7268 [D loss: 0.716420, acc.: 49.22%] [G loss: 0.790862]\n",
      "epoch:9 step:7269 [D loss: 0.721278, acc.: 43.75%] [G loss: 0.813848]\n",
      "epoch:9 step:7270 [D loss: 0.660293, acc.: 59.38%] [G loss: 0.818808]\n",
      "epoch:9 step:7271 [D loss: 0.699841, acc.: 52.34%] [G loss: 0.731336]\n",
      "epoch:9 step:7272 [D loss: 0.666404, acc.: 58.59%] [G loss: 0.763302]\n",
      "epoch:9 step:7273 [D loss: 0.716589, acc.: 46.88%] [G loss: 0.723033]\n",
      "epoch:9 step:7274 [D loss: 0.736883, acc.: 42.19%] [G loss: 0.694198]\n",
      "epoch:9 step:7275 [D loss: 0.786568, acc.: 37.50%] [G loss: 0.740596]\n",
      "epoch:9 step:7276 [D loss: 0.684920, acc.: 56.25%] [G loss: 0.893106]\n",
      "epoch:9 step:7277 [D loss: 0.682213, acc.: 50.78%] [G loss: 0.944497]\n",
      "epoch:9 step:7278 [D loss: 0.707841, acc.: 50.78%] [G loss: 0.802992]\n",
      "epoch:9 step:7279 [D loss: 0.722556, acc.: 47.66%] [G loss: 0.827424]\n",
      "epoch:9 step:7280 [D loss: 0.657242, acc.: 63.28%] [G loss: 0.790178]\n",
      "epoch:9 step:7281 [D loss: 0.656683, acc.: 67.19%] [G loss: 0.854729]\n",
      "epoch:9 step:7282 [D loss: 0.689030, acc.: 55.47%] [G loss: 0.870223]\n",
      "epoch:9 step:7283 [D loss: 0.713624, acc.: 48.44%] [G loss: 0.753593]\n",
      "epoch:9 step:7284 [D loss: 0.656663, acc.: 63.28%] [G loss: 0.746749]\n",
      "epoch:9 step:7285 [D loss: 0.663269, acc.: 57.81%] [G loss: 0.735553]\n",
      "epoch:9 step:7286 [D loss: 0.679145, acc.: 58.59%] [G loss: 0.856814]\n",
      "epoch:9 step:7287 [D loss: 0.707875, acc.: 48.44%] [G loss: 0.929439]\n",
      "epoch:9 step:7288 [D loss: 0.728502, acc.: 48.44%] [G loss: 0.847830]\n",
      "epoch:9 step:7289 [D loss: 0.634180, acc.: 64.84%] [G loss: 0.806225]\n",
      "epoch:9 step:7290 [D loss: 0.630309, acc.: 63.28%] [G loss: 0.820946]\n",
      "epoch:9 step:7291 [D loss: 0.688050, acc.: 53.91%] [G loss: 0.864150]\n",
      "epoch:9 step:7292 [D loss: 0.676730, acc.: 49.22%] [G loss: 0.780602]\n",
      "epoch:9 step:7293 [D loss: 0.641008, acc.: 66.41%] [G loss: 0.757798]\n",
      "epoch:9 step:7294 [D loss: 0.633952, acc.: 66.41%] [G loss: 0.771543]\n",
      "epoch:9 step:7295 [D loss: 0.747762, acc.: 42.19%] [G loss: 0.723358]\n",
      "epoch:9 step:7296 [D loss: 0.739512, acc.: 50.00%] [G loss: 0.696599]\n",
      "epoch:9 step:7297 [D loss: 0.697441, acc.: 52.34%] [G loss: 0.666285]\n",
      "epoch:9 step:7298 [D loss: 0.698765, acc.: 55.47%] [G loss: 0.716043]\n",
      "epoch:9 step:7299 [D loss: 0.702276, acc.: 52.34%] [G loss: 0.726126]\n",
      "epoch:9 step:7300 [D loss: 0.684518, acc.: 57.03%] [G loss: 0.828943]\n",
      "epoch:9 step:7301 [D loss: 0.721851, acc.: 50.00%] [G loss: 0.786906]\n",
      "epoch:9 step:7302 [D loss: 0.729009, acc.: 46.88%] [G loss: 0.767185]\n",
      "epoch:9 step:7303 [D loss: 0.733242, acc.: 47.66%] [G loss: 0.827459]\n",
      "epoch:9 step:7304 [D loss: 0.730854, acc.: 46.88%] [G loss: 0.830976]\n",
      "epoch:9 step:7305 [D loss: 0.686220, acc.: 57.03%] [G loss: 0.801446]\n",
      "epoch:9 step:7306 [D loss: 0.704883, acc.: 55.47%] [G loss: 0.783883]\n",
      "epoch:9 step:7307 [D loss: 0.665800, acc.: 61.72%] [G loss: 0.912051]\n",
      "epoch:9 step:7308 [D loss: 0.723761, acc.: 47.66%] [G loss: 0.732917]\n",
      "epoch:9 step:7309 [D loss: 0.723074, acc.: 42.97%] [G loss: 0.893282]\n",
      "epoch:9 step:7310 [D loss: 0.727079, acc.: 46.88%] [G loss: 0.873699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7311 [D loss: 0.694530, acc.: 53.12%] [G loss: 0.784974]\n",
      "epoch:9 step:7312 [D loss: 0.754920, acc.: 41.41%] [G loss: 0.741864]\n",
      "epoch:9 step:7313 [D loss: 0.736734, acc.: 44.53%] [G loss: 0.836977]\n",
      "epoch:9 step:7314 [D loss: 0.717995, acc.: 48.44%] [G loss: 0.803409]\n",
      "epoch:9 step:7315 [D loss: 0.682490, acc.: 50.00%] [G loss: 0.870052]\n",
      "epoch:9 step:7316 [D loss: 0.729839, acc.: 45.31%] [G loss: 0.804686]\n",
      "epoch:9 step:7317 [D loss: 0.676398, acc.: 57.81%] [G loss: 0.799940]\n",
      "epoch:9 step:7318 [D loss: 0.642529, acc.: 63.28%] [G loss: 0.801532]\n",
      "epoch:9 step:7319 [D loss: 0.637477, acc.: 66.41%] [G loss: 0.791902]\n",
      "epoch:9 step:7320 [D loss: 0.709985, acc.: 46.88%] [G loss: 0.772891]\n",
      "epoch:9 step:7321 [D loss: 0.671834, acc.: 60.16%] [G loss: 0.769089]\n",
      "epoch:9 step:7322 [D loss: 0.711178, acc.: 51.56%] [G loss: 0.744133]\n",
      "epoch:9 step:7323 [D loss: 0.700261, acc.: 53.12%] [G loss: 0.729847]\n",
      "epoch:9 step:7324 [D loss: 0.708752, acc.: 47.66%] [G loss: 0.737265]\n",
      "epoch:9 step:7325 [D loss: 0.635170, acc.: 64.06%] [G loss: 0.755349]\n",
      "epoch:9 step:7326 [D loss: 0.773678, acc.: 39.06%] [G loss: 0.735428]\n",
      "epoch:9 step:7327 [D loss: 0.722549, acc.: 45.31%] [G loss: 0.730721]\n",
      "epoch:9 step:7328 [D loss: 0.744316, acc.: 45.31%] [G loss: 0.723857]\n",
      "epoch:9 step:7329 [D loss: 0.730359, acc.: 48.44%] [G loss: 0.662191]\n",
      "epoch:9 step:7330 [D loss: 0.712642, acc.: 51.56%] [G loss: 0.678747]\n",
      "epoch:9 step:7331 [D loss: 0.636107, acc.: 64.84%] [G loss: 0.781375]\n",
      "epoch:9 step:7332 [D loss: 0.707286, acc.: 53.12%] [G loss: 0.721969]\n",
      "epoch:9 step:7333 [D loss: 0.712584, acc.: 49.22%] [G loss: 0.795406]\n",
      "epoch:9 step:7334 [D loss: 0.773795, acc.: 39.84%] [G loss: 0.700062]\n",
      "epoch:9 step:7335 [D loss: 0.732207, acc.: 50.00%] [G loss: 0.745187]\n",
      "epoch:9 step:7336 [D loss: 0.723399, acc.: 50.00%] [G loss: 0.757573]\n",
      "epoch:9 step:7337 [D loss: 0.664186, acc.: 57.03%] [G loss: 0.782467]\n",
      "epoch:9 step:7338 [D loss: 0.712886, acc.: 43.75%] [G loss: 0.763911]\n",
      "epoch:9 step:7339 [D loss: 0.741741, acc.: 46.09%] [G loss: 0.761827]\n",
      "epoch:9 step:7340 [D loss: 0.743013, acc.: 46.88%] [G loss: 0.814924]\n",
      "epoch:9 step:7341 [D loss: 0.721044, acc.: 46.88%] [G loss: 0.826353]\n",
      "epoch:9 step:7342 [D loss: 0.714847, acc.: 49.22%] [G loss: 0.821374]\n",
      "epoch:9 step:7343 [D loss: 0.682120, acc.: 56.25%] [G loss: 0.830597]\n",
      "epoch:9 step:7344 [D loss: 0.700882, acc.: 54.69%] [G loss: 0.815764]\n",
      "epoch:9 step:7345 [D loss: 0.631953, acc.: 67.19%] [G loss: 0.692906]\n",
      "epoch:9 step:7346 [D loss: 0.721616, acc.: 45.31%] [G loss: 0.756122]\n",
      "epoch:9 step:7347 [D loss: 0.651398, acc.: 64.06%] [G loss: 0.696488]\n",
      "epoch:9 step:7348 [D loss: 0.733296, acc.: 47.66%] [G loss: 0.711018]\n",
      "epoch:9 step:7349 [D loss: 0.622621, acc.: 71.09%] [G loss: 0.664096]\n",
      "epoch:9 step:7350 [D loss: 0.642796, acc.: 66.41%] [G loss: 0.693901]\n",
      "epoch:9 step:7351 [D loss: 0.707989, acc.: 51.56%] [G loss: 0.771647]\n",
      "epoch:9 step:7352 [D loss: 0.623712, acc.: 68.75%] [G loss: 0.649556]\n",
      "epoch:9 step:7353 [D loss: 0.669713, acc.: 58.59%] [G loss: 0.668765]\n",
      "epoch:9 step:7354 [D loss: 0.653881, acc.: 62.50%] [G loss: 0.773638]\n",
      "epoch:9 step:7355 [D loss: 0.738515, acc.: 43.75%] [G loss: 0.669394]\n",
      "epoch:9 step:7356 [D loss: 0.713019, acc.: 48.44%] [G loss: 0.670634]\n",
      "epoch:9 step:7357 [D loss: 0.716500, acc.: 53.91%] [G loss: 0.663074]\n",
      "epoch:9 step:7358 [D loss: 0.752428, acc.: 45.31%] [G loss: 0.639558]\n",
      "epoch:9 step:7359 [D loss: 0.737299, acc.: 42.97%] [G loss: 0.699853]\n",
      "epoch:9 step:7360 [D loss: 0.720062, acc.: 46.88%] [G loss: 0.715582]\n",
      "epoch:9 step:7361 [D loss: 0.701952, acc.: 51.56%] [G loss: 0.644163]\n",
      "epoch:9 step:7362 [D loss: 0.721328, acc.: 44.53%] [G loss: 0.783557]\n",
      "epoch:9 step:7363 [D loss: 0.715254, acc.: 46.88%] [G loss: 0.819249]\n",
      "epoch:9 step:7364 [D loss: 0.707274, acc.: 50.78%] [G loss: 0.713820]\n",
      "epoch:9 step:7365 [D loss: 0.725334, acc.: 42.19%] [G loss: 0.733093]\n",
      "epoch:9 step:7366 [D loss: 0.731405, acc.: 46.88%] [G loss: 0.781349]\n",
      "epoch:9 step:7367 [D loss: 0.703081, acc.: 50.78%] [G loss: 0.718485]\n",
      "epoch:9 step:7368 [D loss: 0.707621, acc.: 52.34%] [G loss: 0.781771]\n",
      "epoch:9 step:7369 [D loss: 0.712356, acc.: 48.44%] [G loss: 0.753291]\n",
      "epoch:9 step:7370 [D loss: 0.719311, acc.: 46.88%] [G loss: 0.840097]\n",
      "epoch:9 step:7371 [D loss: 0.742055, acc.: 39.06%] [G loss: 0.772110]\n",
      "epoch:9 step:7372 [D loss: 0.706191, acc.: 53.12%] [G loss: 0.826713]\n",
      "epoch:9 step:7373 [D loss: 0.728156, acc.: 43.75%] [G loss: 0.820119]\n",
      "epoch:9 step:7374 [D loss: 0.642911, acc.: 64.84%] [G loss: 0.763222]\n",
      "epoch:9 step:7375 [D loss: 0.714911, acc.: 44.53%] [G loss: 0.797797]\n",
      "epoch:9 step:7376 [D loss: 0.724648, acc.: 47.66%] [G loss: 0.855281]\n",
      "epoch:9 step:7377 [D loss: 0.707822, acc.: 51.56%] [G loss: 0.853007]\n",
      "epoch:9 step:7378 [D loss: 0.718111, acc.: 45.31%] [G loss: 0.788527]\n",
      "epoch:9 step:7379 [D loss: 0.715050, acc.: 53.12%] [G loss: 0.861076]\n",
      "epoch:9 step:7380 [D loss: 0.736919, acc.: 46.88%] [G loss: 0.779454]\n",
      "epoch:9 step:7381 [D loss: 0.697793, acc.: 53.12%] [G loss: 0.758561]\n",
      "epoch:9 step:7382 [D loss: 0.675020, acc.: 56.25%] [G loss: 0.828515]\n",
      "epoch:9 step:7383 [D loss: 0.716820, acc.: 47.66%] [G loss: 0.777107]\n",
      "epoch:9 step:7384 [D loss: 0.700353, acc.: 53.12%] [G loss: 0.794110]\n",
      "epoch:9 step:7385 [D loss: 0.672138, acc.: 53.91%] [G loss: 0.749022]\n",
      "epoch:9 step:7386 [D loss: 0.698135, acc.: 50.00%] [G loss: 0.746318]\n",
      "epoch:9 step:7387 [D loss: 0.699381, acc.: 52.34%] [G loss: 0.799443]\n",
      "epoch:9 step:7388 [D loss: 0.688093, acc.: 52.34%] [G loss: 0.778265]\n",
      "epoch:9 step:7389 [D loss: 0.690006, acc.: 55.47%] [G loss: 0.847963]\n",
      "epoch:9 step:7390 [D loss: 0.736486, acc.: 41.41%] [G loss: 0.760851]\n",
      "epoch:9 step:7391 [D loss: 0.710304, acc.: 44.53%] [G loss: 0.750803]\n",
      "epoch:9 step:7392 [D loss: 0.686085, acc.: 54.69%] [G loss: 0.790764]\n",
      "epoch:9 step:7393 [D loss: 0.725365, acc.: 45.31%] [G loss: 0.812440]\n",
      "epoch:9 step:7394 [D loss: 0.733262, acc.: 42.97%] [G loss: 0.725034]\n",
      "epoch:9 step:7395 [D loss: 0.711022, acc.: 47.66%] [G loss: 0.785399]\n",
      "epoch:9 step:7396 [D loss: 0.719982, acc.: 50.78%] [G loss: 0.782726]\n",
      "epoch:9 step:7397 [D loss: 0.676197, acc.: 56.25%] [G loss: 0.818024]\n",
      "epoch:9 step:7398 [D loss: 0.716364, acc.: 45.31%] [G loss: 0.797918]\n",
      "epoch:9 step:7399 [D loss: 0.668682, acc.: 60.94%] [G loss: 0.805503]\n",
      "epoch:9 step:7400 [D loss: 0.679122, acc.: 53.91%] [G loss: 0.852496]\n",
      "epoch:9 step:7401 [D loss: 0.721437, acc.: 44.53%] [G loss: 0.752254]\n",
      "epoch:9 step:7402 [D loss: 0.719458, acc.: 48.44%] [G loss: 0.796703]\n",
      "epoch:9 step:7403 [D loss: 0.676767, acc.: 54.69%] [G loss: 0.738836]\n",
      "epoch:9 step:7404 [D loss: 0.693883, acc.: 54.69%] [G loss: 0.778242]\n",
      "epoch:9 step:7405 [D loss: 0.673776, acc.: 56.25%] [G loss: 0.758161]\n",
      "epoch:9 step:7406 [D loss: 0.661061, acc.: 64.06%] [G loss: 0.873520]\n",
      "epoch:9 step:7407 [D loss: 0.704150, acc.: 52.34%] [G loss: 0.750555]\n",
      "epoch:9 step:7408 [D loss: 0.687188, acc.: 57.81%] [G loss: 0.810492]\n",
      "epoch:9 step:7409 [D loss: 0.722432, acc.: 46.09%] [G loss: 0.794233]\n",
      "epoch:9 step:7410 [D loss: 0.645681, acc.: 60.94%] [G loss: 0.821707]\n",
      "epoch:9 step:7411 [D loss: 0.645326, acc.: 60.16%] [G loss: 0.790132]\n",
      "epoch:9 step:7412 [D loss: 0.674992, acc.: 57.03%] [G loss: 0.783505]\n",
      "epoch:9 step:7413 [D loss: 0.686484, acc.: 55.47%] [G loss: 0.784571]\n",
      "epoch:9 step:7414 [D loss: 0.749436, acc.: 44.53%] [G loss: 0.788289]\n",
      "epoch:9 step:7415 [D loss: 0.680986, acc.: 57.81%] [G loss: 0.776528]\n",
      "epoch:9 step:7416 [D loss: 0.697722, acc.: 53.91%] [G loss: 0.769487]\n",
      "epoch:9 step:7417 [D loss: 0.753192, acc.: 31.25%] [G loss: 0.807084]\n",
      "epoch:9 step:7418 [D loss: 0.717981, acc.: 49.22%] [G loss: 0.731392]\n",
      "epoch:9 step:7419 [D loss: 0.702236, acc.: 50.78%] [G loss: 0.844528]\n",
      "epoch:9 step:7420 [D loss: 0.746439, acc.: 40.62%] [G loss: 0.755943]\n",
      "epoch:9 step:7421 [D loss: 0.740537, acc.: 42.19%] [G loss: 0.790133]\n",
      "epoch:9 step:7422 [D loss: 0.710118, acc.: 46.09%] [G loss: 0.754096]\n",
      "epoch:9 step:7423 [D loss: 0.678805, acc.: 60.94%] [G loss: 0.819565]\n",
      "epoch:9 step:7424 [D loss: 0.684794, acc.: 54.69%] [G loss: 0.764510]\n",
      "epoch:9 step:7425 [D loss: 0.680022, acc.: 53.91%] [G loss: 0.749090]\n",
      "epoch:9 step:7426 [D loss: 0.706531, acc.: 53.91%] [G loss: 0.775759]\n",
      "epoch:9 step:7427 [D loss: 0.674792, acc.: 62.50%] [G loss: 0.805825]\n",
      "epoch:9 step:7428 [D loss: 0.714647, acc.: 52.34%] [G loss: 0.755976]\n",
      "epoch:9 step:7429 [D loss: 0.720041, acc.: 43.75%] [G loss: 0.744245]\n",
      "epoch:9 step:7430 [D loss: 0.663887, acc.: 60.16%] [G loss: 0.825471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7431 [D loss: 0.727424, acc.: 41.41%] [G loss: 0.744259]\n",
      "epoch:9 step:7432 [D loss: 0.675451, acc.: 57.81%] [G loss: 0.780836]\n",
      "epoch:9 step:7433 [D loss: 0.663078, acc.: 59.38%] [G loss: 0.788435]\n",
      "epoch:9 step:7434 [D loss: 0.719645, acc.: 47.66%] [G loss: 0.813029]\n",
      "epoch:9 step:7435 [D loss: 0.671488, acc.: 60.94%] [G loss: 0.850243]\n",
      "epoch:9 step:7436 [D loss: 0.669030, acc.: 55.47%] [G loss: 0.792552]\n",
      "epoch:9 step:7437 [D loss: 0.699343, acc.: 57.81%] [G loss: 0.732676]\n",
      "epoch:9 step:7438 [D loss: 0.688458, acc.: 57.03%] [G loss: 0.832134]\n",
      "epoch:9 step:7439 [D loss: 0.679518, acc.: 57.03%] [G loss: 0.776524]\n",
      "epoch:9 step:7440 [D loss: 0.756946, acc.: 42.97%] [G loss: 0.792594]\n",
      "epoch:9 step:7441 [D loss: 0.711225, acc.: 45.31%] [G loss: 0.770859]\n",
      "epoch:9 step:7442 [D loss: 0.707193, acc.: 50.00%] [G loss: 0.721173]\n",
      "epoch:9 step:7443 [D loss: 0.722592, acc.: 47.66%] [G loss: 0.764767]\n",
      "epoch:9 step:7444 [D loss: 0.690722, acc.: 57.03%] [G loss: 0.771977]\n",
      "epoch:9 step:7445 [D loss: 0.644270, acc.: 67.97%] [G loss: 0.796273]\n",
      "epoch:9 step:7446 [D loss: 0.678392, acc.: 54.69%] [G loss: 0.872986]\n",
      "epoch:9 step:7447 [D loss: 0.665325, acc.: 57.81%] [G loss: 0.830853]\n",
      "epoch:9 step:7448 [D loss: 0.728670, acc.: 50.78%] [G loss: 0.786961]\n",
      "epoch:9 step:7449 [D loss: 0.653596, acc.: 57.03%] [G loss: 0.819400]\n",
      "epoch:9 step:7450 [D loss: 0.645386, acc.: 63.28%] [G loss: 0.920712]\n",
      "epoch:9 step:7451 [D loss: 0.729302, acc.: 47.66%] [G loss: 0.814616]\n",
      "epoch:9 step:7452 [D loss: 0.668816, acc.: 62.50%] [G loss: 0.799211]\n",
      "epoch:9 step:7453 [D loss: 0.738857, acc.: 44.53%] [G loss: 0.769363]\n",
      "epoch:9 step:7454 [D loss: 0.667256, acc.: 60.16%] [G loss: 0.759961]\n",
      "epoch:9 step:7455 [D loss: 0.730583, acc.: 40.62%] [G loss: 0.817052]\n",
      "epoch:9 step:7456 [D loss: 0.679796, acc.: 62.50%] [G loss: 0.755029]\n",
      "epoch:9 step:7457 [D loss: 0.750244, acc.: 43.75%] [G loss: 0.653606]\n",
      "epoch:9 step:7458 [D loss: 0.721496, acc.: 43.75%] [G loss: 0.692948]\n",
      "epoch:9 step:7459 [D loss: 0.764442, acc.: 38.28%] [G loss: 0.703380]\n",
      "epoch:9 step:7460 [D loss: 0.780517, acc.: 32.81%] [G loss: 0.699275]\n",
      "epoch:9 step:7461 [D loss: 0.728141, acc.: 42.19%] [G loss: 0.830685]\n",
      "epoch:9 step:7462 [D loss: 0.659379, acc.: 61.72%] [G loss: 0.823404]\n",
      "epoch:9 step:7463 [D loss: 0.683796, acc.: 58.59%] [G loss: 0.899612]\n",
      "epoch:9 step:7464 [D loss: 0.688992, acc.: 50.00%] [G loss: 0.803009]\n",
      "epoch:9 step:7465 [D loss: 0.762129, acc.: 39.84%] [G loss: 0.724253]\n",
      "epoch:9 step:7466 [D loss: 0.721124, acc.: 47.66%] [G loss: 0.801879]\n",
      "epoch:9 step:7467 [D loss: 0.720578, acc.: 48.44%] [G loss: 0.726895]\n",
      "epoch:9 step:7468 [D loss: 0.691168, acc.: 50.78%] [G loss: 0.742050]\n",
      "epoch:9 step:7469 [D loss: 0.706061, acc.: 48.44%] [G loss: 0.785724]\n",
      "epoch:9 step:7470 [D loss: 0.723309, acc.: 43.75%] [G loss: 0.799145]\n",
      "epoch:9 step:7471 [D loss: 0.693028, acc.: 54.69%] [G loss: 0.779682]\n",
      "epoch:9 step:7472 [D loss: 0.703987, acc.: 57.81%] [G loss: 0.782401]\n",
      "epoch:9 step:7473 [D loss: 0.696446, acc.: 57.81%] [G loss: 0.773076]\n",
      "epoch:9 step:7474 [D loss: 0.653514, acc.: 58.59%] [G loss: 0.788412]\n",
      "epoch:9 step:7475 [D loss: 0.701068, acc.: 50.78%] [G loss: 0.721739]\n",
      "epoch:9 step:7476 [D loss: 0.693857, acc.: 53.91%] [G loss: 0.695390]\n",
      "epoch:9 step:7477 [D loss: 0.684600, acc.: 57.81%] [G loss: 0.716915]\n",
      "epoch:9 step:7478 [D loss: 0.686640, acc.: 56.25%] [G loss: 0.796731]\n",
      "epoch:9 step:7479 [D loss: 0.667966, acc.: 54.69%] [G loss: 0.784142]\n",
      "epoch:9 step:7480 [D loss: 0.706913, acc.: 49.22%] [G loss: 0.686956]\n",
      "epoch:9 step:7481 [D loss: 0.687680, acc.: 53.91%] [G loss: 0.731921]\n",
      "epoch:9 step:7482 [D loss: 0.671012, acc.: 57.03%] [G loss: 0.690405]\n",
      "epoch:9 step:7483 [D loss: 0.690367, acc.: 52.34%] [G loss: 0.734902]\n",
      "epoch:9 step:7484 [D loss: 0.720808, acc.: 46.09%] [G loss: 0.831831]\n",
      "epoch:9 step:7485 [D loss: 0.685759, acc.: 57.81%] [G loss: 0.764256]\n",
      "epoch:9 step:7486 [D loss: 0.685112, acc.: 55.47%] [G loss: 0.777276]\n",
      "epoch:9 step:7487 [D loss: 0.681384, acc.: 53.12%] [G loss: 0.889893]\n",
      "epoch:9 step:7488 [D loss: 0.727409, acc.: 45.31%] [G loss: 0.898697]\n",
      "epoch:9 step:7489 [D loss: 0.718376, acc.: 53.12%] [G loss: 0.743779]\n",
      "epoch:9 step:7490 [D loss: 0.681946, acc.: 55.47%] [G loss: 0.803404]\n",
      "epoch:9 step:7491 [D loss: 0.698109, acc.: 52.34%] [G loss: 0.823621]\n",
      "epoch:9 step:7492 [D loss: 0.656135, acc.: 62.50%] [G loss: 0.877909]\n",
      "epoch:9 step:7493 [D loss: 0.694314, acc.: 51.56%] [G loss: 0.831200]\n",
      "epoch:9 step:7494 [D loss: 0.675010, acc.: 57.03%] [G loss: 0.773083]\n",
      "epoch:9 step:7495 [D loss: 0.651454, acc.: 65.62%] [G loss: 0.796562]\n",
      "epoch:9 step:7496 [D loss: 0.697064, acc.: 52.34%] [G loss: 0.809856]\n",
      "epoch:9 step:7497 [D loss: 0.730916, acc.: 46.09%] [G loss: 0.834117]\n",
      "epoch:9 step:7498 [D loss: 0.711036, acc.: 53.12%] [G loss: 0.773118]\n",
      "epoch:9 step:7499 [D loss: 0.712915, acc.: 54.69%] [G loss: 0.843619]\n",
      "epoch:9 step:7500 [D loss: 0.698257, acc.: 56.25%] [G loss: 0.743036]\n",
      "epoch:9 step:7501 [D loss: 0.710107, acc.: 48.44%] [G loss: 0.770452]\n",
      "epoch:9 step:7502 [D loss: 0.768855, acc.: 46.09%] [G loss: 0.747875]\n",
      "epoch:9 step:7503 [D loss: 0.764700, acc.: 41.41%] [G loss: 0.744852]\n",
      "epoch:9 step:7504 [D loss: 0.695723, acc.: 52.34%] [G loss: 0.787999]\n",
      "epoch:9 step:7505 [D loss: 0.673320, acc.: 53.12%] [G loss: 0.826107]\n",
      "epoch:9 step:7506 [D loss: 0.656455, acc.: 65.62%] [G loss: 0.746046]\n",
      "epoch:9 step:7507 [D loss: 0.722088, acc.: 46.09%] [G loss: 0.818010]\n",
      "epoch:9 step:7508 [D loss: 0.752092, acc.: 37.50%] [G loss: 0.785444]\n",
      "epoch:9 step:7509 [D loss: 0.698652, acc.: 53.91%] [G loss: 0.798706]\n",
      "epoch:9 step:7510 [D loss: 0.681365, acc.: 55.47%] [G loss: 0.778230]\n",
      "epoch:9 step:7511 [D loss: 0.768839, acc.: 44.53%] [G loss: 0.747405]\n",
      "epoch:9 step:7512 [D loss: 0.669965, acc.: 58.59%] [G loss: 0.751246]\n",
      "epoch:9 step:7513 [D loss: 0.687364, acc.: 55.47%] [G loss: 0.756975]\n",
      "epoch:9 step:7514 [D loss: 0.676082, acc.: 60.16%] [G loss: 0.745458]\n",
      "epoch:9 step:7515 [D loss: 0.688884, acc.: 61.72%] [G loss: 0.793442]\n",
      "epoch:9 step:7516 [D loss: 0.695364, acc.: 56.25%] [G loss: 0.763578]\n",
      "epoch:9 step:7517 [D loss: 0.684712, acc.: 53.12%] [G loss: 0.799237]\n",
      "epoch:9 step:7518 [D loss: 0.734851, acc.: 41.41%] [G loss: 0.792542]\n",
      "epoch:9 step:7519 [D loss: 0.706957, acc.: 54.69%] [G loss: 0.785346]\n",
      "epoch:9 step:7520 [D loss: 0.713691, acc.: 53.91%] [G loss: 0.811947]\n",
      "epoch:9 step:7521 [D loss: 0.687599, acc.: 53.12%] [G loss: 0.867020]\n",
      "epoch:9 step:7522 [D loss: 0.658493, acc.: 62.50%] [G loss: 0.787477]\n",
      "epoch:9 step:7523 [D loss: 0.684290, acc.: 55.47%] [G loss: 0.863980]\n",
      "epoch:9 step:7524 [D loss: 0.662298, acc.: 65.62%] [G loss: 0.758745]\n",
      "epoch:9 step:7525 [D loss: 0.711244, acc.: 45.31%] [G loss: 0.788656]\n",
      "epoch:9 step:7526 [D loss: 0.677310, acc.: 54.69%] [G loss: 0.751655]\n",
      "epoch:9 step:7527 [D loss: 0.679202, acc.: 53.91%] [G loss: 0.767735]\n",
      "epoch:9 step:7528 [D loss: 0.717860, acc.: 44.53%] [G loss: 0.694487]\n",
      "epoch:9 step:7529 [D loss: 0.684970, acc.: 55.47%] [G loss: 0.731001]\n",
      "epoch:9 step:7530 [D loss: 0.731157, acc.: 50.78%] [G loss: 0.770983]\n",
      "epoch:9 step:7531 [D loss: 0.690331, acc.: 60.16%] [G loss: 0.862795]\n",
      "epoch:9 step:7532 [D loss: 0.703642, acc.: 49.22%] [G loss: 0.737502]\n",
      "epoch:9 step:7533 [D loss: 0.753066, acc.: 41.41%] [G loss: 0.709454]\n",
      "epoch:9 step:7534 [D loss: 0.713757, acc.: 47.66%] [G loss: 0.744229]\n",
      "epoch:9 step:7535 [D loss: 0.713729, acc.: 50.00%] [G loss: 0.720874]\n",
      "epoch:9 step:7536 [D loss: 0.685068, acc.: 53.12%] [G loss: 0.739653]\n",
      "epoch:9 step:7537 [D loss: 0.677236, acc.: 62.50%] [G loss: 0.803300]\n",
      "epoch:9 step:7538 [D loss: 0.713600, acc.: 46.88%] [G loss: 0.796581]\n",
      "epoch:9 step:7539 [D loss: 0.622439, acc.: 67.97%] [G loss: 0.751546]\n",
      "epoch:9 step:7540 [D loss: 0.705658, acc.: 50.00%] [G loss: 0.700740]\n",
      "epoch:9 step:7541 [D loss: 0.707809, acc.: 54.69%] [G loss: 0.731452]\n",
      "epoch:9 step:7542 [D loss: 0.727530, acc.: 42.97%] [G loss: 0.765568]\n",
      "epoch:9 step:7543 [D loss: 0.681850, acc.: 57.81%] [G loss: 0.752081]\n",
      "epoch:9 step:7544 [D loss: 0.713190, acc.: 49.22%] [G loss: 0.735935]\n",
      "epoch:9 step:7545 [D loss: 0.773918, acc.: 35.94%] [G loss: 0.795998]\n",
      "epoch:9 step:7546 [D loss: 0.749301, acc.: 40.62%] [G loss: 0.752601]\n",
      "epoch:9 step:7547 [D loss: 0.694420, acc.: 53.12%] [G loss: 0.761058]\n",
      "epoch:9 step:7548 [D loss: 0.708698, acc.: 52.34%] [G loss: 0.805589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7549 [D loss: 0.721602, acc.: 46.09%] [G loss: 0.764323]\n",
      "epoch:9 step:7550 [D loss: 0.691247, acc.: 53.12%] [G loss: 0.847446]\n",
      "epoch:9 step:7551 [D loss: 0.754129, acc.: 44.53%] [G loss: 0.831971]\n",
      "epoch:9 step:7552 [D loss: 0.677287, acc.: 61.72%] [G loss: 0.823606]\n",
      "epoch:9 step:7553 [D loss: 0.755293, acc.: 37.50%] [G loss: 0.747098]\n",
      "epoch:9 step:7554 [D loss: 0.702180, acc.: 47.66%] [G loss: 0.801318]\n",
      "epoch:9 step:7555 [D loss: 0.779426, acc.: 41.41%] [G loss: 0.810973]\n",
      "epoch:9 step:7556 [D loss: 0.687994, acc.: 56.25%] [G loss: 0.759710]\n",
      "epoch:9 step:7557 [D loss: 0.678062, acc.: 57.03%] [G loss: 0.726428]\n",
      "epoch:9 step:7558 [D loss: 0.687868, acc.: 53.12%] [G loss: 0.754682]\n",
      "epoch:9 step:7559 [D loss: 0.734137, acc.: 43.75%] [G loss: 0.747803]\n",
      "epoch:9 step:7560 [D loss: 0.722668, acc.: 46.09%] [G loss: 0.791738]\n",
      "epoch:9 step:7561 [D loss: 0.741494, acc.: 44.53%] [G loss: 0.821359]\n",
      "epoch:9 step:7562 [D loss: 0.710641, acc.: 46.88%] [G loss: 0.774613]\n",
      "epoch:9 step:7563 [D loss: 0.732877, acc.: 44.53%] [G loss: 0.738738]\n",
      "epoch:9 step:7564 [D loss: 0.708385, acc.: 51.56%] [G loss: 0.754946]\n",
      "epoch:9 step:7565 [D loss: 0.714663, acc.: 45.31%] [G loss: 0.814340]\n",
      "epoch:9 step:7566 [D loss: 0.696414, acc.: 46.09%] [G loss: 0.864816]\n",
      "epoch:9 step:7567 [D loss: 0.704435, acc.: 53.12%] [G loss: 0.835050]\n",
      "epoch:9 step:7568 [D loss: 0.683325, acc.: 56.25%] [G loss: 0.918573]\n",
      "epoch:9 step:7569 [D loss: 0.700441, acc.: 54.69%] [G loss: 0.834450]\n",
      "epoch:9 step:7570 [D loss: 0.655725, acc.: 61.72%] [G loss: 0.852373]\n",
      "epoch:9 step:7571 [D loss: 0.679638, acc.: 57.03%] [G loss: 0.833008]\n",
      "epoch:9 step:7572 [D loss: 0.710889, acc.: 49.22%] [G loss: 0.791108]\n",
      "epoch:9 step:7573 [D loss: 0.611094, acc.: 69.53%] [G loss: 0.828032]\n",
      "epoch:9 step:7574 [D loss: 0.691866, acc.: 58.59%] [G loss: 0.806460]\n",
      "epoch:9 step:7575 [D loss: 0.760536, acc.: 40.62%] [G loss: 0.781587]\n",
      "epoch:9 step:7576 [D loss: 0.691327, acc.: 54.69%] [G loss: 0.789577]\n",
      "epoch:9 step:7577 [D loss: 0.668195, acc.: 56.25%] [G loss: 0.839696]\n",
      "epoch:9 step:7578 [D loss: 0.706138, acc.: 48.44%] [G loss: 0.867027]\n",
      "epoch:9 step:7579 [D loss: 0.693460, acc.: 55.47%] [G loss: 0.829980]\n",
      "epoch:9 step:7580 [D loss: 0.665077, acc.: 57.03%] [G loss: 0.778139]\n",
      "epoch:9 step:7581 [D loss: 0.705544, acc.: 56.25%] [G loss: 0.769025]\n",
      "epoch:9 step:7582 [D loss: 0.722787, acc.: 50.78%] [G loss: 0.664915]\n",
      "epoch:9 step:7583 [D loss: 0.687225, acc.: 55.47%] [G loss: 0.748569]\n",
      "epoch:9 step:7584 [D loss: 0.693418, acc.: 54.69%] [G loss: 0.744699]\n",
      "epoch:9 step:7585 [D loss: 0.675811, acc.: 54.69%] [G loss: 0.809567]\n",
      "epoch:9 step:7586 [D loss: 0.723732, acc.: 46.09%] [G loss: 0.797254]\n",
      "epoch:9 step:7587 [D loss: 0.713959, acc.: 51.56%] [G loss: 0.752755]\n",
      "epoch:9 step:7588 [D loss: 0.665235, acc.: 59.38%] [G loss: 0.765697]\n",
      "epoch:9 step:7589 [D loss: 0.719512, acc.: 49.22%] [G loss: 0.787480]\n",
      "epoch:9 step:7590 [D loss: 0.675537, acc.: 60.16%] [G loss: 0.772865]\n",
      "epoch:9 step:7591 [D loss: 0.677150, acc.: 57.81%] [G loss: 0.776020]\n",
      "epoch:9 step:7592 [D loss: 0.720898, acc.: 46.88%] [G loss: 0.725383]\n",
      "epoch:9 step:7593 [D loss: 0.721904, acc.: 46.09%] [G loss: 0.778615]\n",
      "epoch:9 step:7594 [D loss: 0.739900, acc.: 41.41%] [G loss: 0.824038]\n",
      "epoch:9 step:7595 [D loss: 0.741827, acc.: 46.88%] [G loss: 0.760856]\n",
      "epoch:9 step:7596 [D loss: 0.693776, acc.: 51.56%] [G loss: 0.769005]\n",
      "epoch:9 step:7597 [D loss: 0.723646, acc.: 43.75%] [G loss: 0.741586]\n",
      "epoch:9 step:7598 [D loss: 0.727959, acc.: 46.88%] [G loss: 0.728544]\n",
      "epoch:9 step:7599 [D loss: 0.693916, acc.: 49.22%] [G loss: 0.877490]\n",
      "epoch:9 step:7600 [D loss: 0.660497, acc.: 60.94%] [G loss: 0.831616]\n",
      "epoch:9 step:7601 [D loss: 0.678761, acc.: 61.72%] [G loss: 0.890761]\n",
      "epoch:9 step:7602 [D loss: 0.652956, acc.: 62.50%] [G loss: 0.794893]\n",
      "epoch:9 step:7603 [D loss: 0.745791, acc.: 45.31%] [G loss: 0.715068]\n",
      "epoch:9 step:7604 [D loss: 0.685344, acc.: 61.72%] [G loss: 0.707428]\n",
      "epoch:9 step:7605 [D loss: 0.640040, acc.: 61.72%] [G loss: 0.746349]\n",
      "epoch:9 step:7606 [D loss: 0.742076, acc.: 44.53%] [G loss: 0.757229]\n",
      "epoch:9 step:7607 [D loss: 0.718887, acc.: 54.69%] [G loss: 0.758218]\n",
      "epoch:9 step:7608 [D loss: 0.621308, acc.: 71.09%] [G loss: 0.798615]\n",
      "epoch:9 step:7609 [D loss: 0.668446, acc.: 57.03%] [G loss: 0.800606]\n",
      "epoch:9 step:7610 [D loss: 0.694463, acc.: 52.34%] [G loss: 0.710288]\n",
      "epoch:9 step:7611 [D loss: 0.735833, acc.: 41.41%] [G loss: 0.692297]\n",
      "epoch:9 step:7612 [D loss: 0.620597, acc.: 67.97%] [G loss: 0.718591]\n",
      "epoch:9 step:7613 [D loss: 0.726752, acc.: 42.97%] [G loss: 0.707001]\n",
      "epoch:9 step:7614 [D loss: 0.740308, acc.: 42.97%] [G loss: 0.710221]\n",
      "epoch:9 step:7615 [D loss: 0.702574, acc.: 53.12%] [G loss: 0.735436]\n",
      "epoch:9 step:7616 [D loss: 0.734454, acc.: 43.75%] [G loss: 0.699603]\n",
      "epoch:9 step:7617 [D loss: 0.746838, acc.: 46.88%] [G loss: 0.729030]\n",
      "epoch:9 step:7618 [D loss: 0.703642, acc.: 50.78%] [G loss: 0.824785]\n",
      "epoch:9 step:7619 [D loss: 0.673665, acc.: 59.38%] [G loss: 0.797592]\n",
      "epoch:9 step:7620 [D loss: 0.710233, acc.: 53.91%] [G loss: 0.840928]\n",
      "epoch:9 step:7621 [D loss: 0.707416, acc.: 53.12%] [G loss: 0.836336]\n",
      "epoch:9 step:7622 [D loss: 0.693054, acc.: 57.03%] [G loss: 0.838913]\n",
      "epoch:9 step:7623 [D loss: 0.697803, acc.: 59.38%] [G loss: 0.834547]\n",
      "epoch:9 step:7624 [D loss: 0.621895, acc.: 68.75%] [G loss: 0.850055]\n",
      "epoch:9 step:7625 [D loss: 0.648467, acc.: 64.06%] [G loss: 0.802255]\n",
      "epoch:9 step:7626 [D loss: 0.627980, acc.: 68.75%] [G loss: 0.879803]\n",
      "epoch:9 step:7627 [D loss: 0.631939, acc.: 62.50%] [G loss: 0.876365]\n",
      "epoch:9 step:7628 [D loss: 0.661076, acc.: 60.16%] [G loss: 0.832292]\n",
      "epoch:9 step:7629 [D loss: 0.657672, acc.: 59.38%] [G loss: 0.867400]\n",
      "epoch:9 step:7630 [D loss: 0.669497, acc.: 56.25%] [G loss: 0.840303]\n",
      "epoch:9 step:7631 [D loss: 0.614356, acc.: 66.41%] [G loss: 0.852184]\n",
      "epoch:9 step:7632 [D loss: 0.684815, acc.: 53.91%] [G loss: 0.784440]\n",
      "epoch:9 step:7633 [D loss: 0.603355, acc.: 71.88%] [G loss: 0.833641]\n",
      "epoch:9 step:7634 [D loss: 0.678556, acc.: 58.59%] [G loss: 0.776181]\n",
      "epoch:9 step:7635 [D loss: 0.707662, acc.: 45.31%] [G loss: 0.790369]\n",
      "epoch:9 step:7636 [D loss: 0.661448, acc.: 57.03%] [G loss: 0.793401]\n",
      "epoch:9 step:7637 [D loss: 0.699712, acc.: 50.00%] [G loss: 0.808071]\n",
      "epoch:9 step:7638 [D loss: 0.680513, acc.: 54.69%] [G loss: 0.766996]\n",
      "epoch:9 step:7639 [D loss: 0.653631, acc.: 63.28%] [G loss: 0.800532]\n",
      "epoch:9 step:7640 [D loss: 0.704984, acc.: 46.09%] [G loss: 0.907179]\n",
      "epoch:9 step:7641 [D loss: 0.755696, acc.: 41.41%] [G loss: 0.744578]\n",
      "epoch:9 step:7642 [D loss: 0.725714, acc.: 50.78%] [G loss: 0.789541]\n",
      "epoch:9 step:7643 [D loss: 0.733829, acc.: 45.31%] [G loss: 0.785671]\n",
      "epoch:9 step:7644 [D loss: 0.703857, acc.: 52.34%] [G loss: 0.717824]\n",
      "epoch:9 step:7645 [D loss: 0.734191, acc.: 45.31%] [G loss: 0.743651]\n",
      "epoch:9 step:7646 [D loss: 0.760480, acc.: 39.84%] [G loss: 0.700447]\n",
      "epoch:9 step:7647 [D loss: 0.698235, acc.: 53.12%] [G loss: 0.710556]\n",
      "epoch:9 step:7648 [D loss: 0.723222, acc.: 45.31%] [G loss: 0.725428]\n",
      "epoch:9 step:7649 [D loss: 0.694927, acc.: 54.69%] [G loss: 0.713371]\n",
      "epoch:9 step:7650 [D loss: 0.715602, acc.: 52.34%] [G loss: 0.728956]\n",
      "epoch:9 step:7651 [D loss: 0.649907, acc.: 60.94%] [G loss: 0.828406]\n",
      "epoch:9 step:7652 [D loss: 0.754321, acc.: 41.41%] [G loss: 0.713019]\n",
      "epoch:9 step:7653 [D loss: 0.707334, acc.: 50.78%] [G loss: 0.712693]\n",
      "epoch:9 step:7654 [D loss: 0.688136, acc.: 53.91%] [G loss: 0.693824]\n",
      "epoch:9 step:7655 [D loss: 0.623648, acc.: 71.88%] [G loss: 0.760060]\n",
      "epoch:9 step:7656 [D loss: 0.637660, acc.: 69.53%] [G loss: 0.755035]\n",
      "epoch:9 step:7657 [D loss: 0.650187, acc.: 59.38%] [G loss: 0.723339]\n",
      "epoch:9 step:7658 [D loss: 0.667279, acc.: 60.94%] [G loss: 0.860632]\n",
      "epoch:9 step:7659 [D loss: 0.692185, acc.: 49.22%] [G loss: 0.723548]\n",
      "epoch:9 step:7660 [D loss: 0.670562, acc.: 60.94%] [G loss: 0.819098]\n",
      "epoch:9 step:7661 [D loss: 0.700056, acc.: 54.69%] [G loss: 0.706231]\n",
      "epoch:9 step:7662 [D loss: 0.705344, acc.: 49.22%] [G loss: 0.726485]\n",
      "epoch:9 step:7663 [D loss: 0.698445, acc.: 58.59%] [G loss: 0.717905]\n",
      "epoch:9 step:7664 [D loss: 0.659615, acc.: 61.72%] [G loss: 0.728645]\n",
      "epoch:9 step:7665 [D loss: 0.704024, acc.: 50.00%] [G loss: 0.732523]\n",
      "epoch:9 step:7666 [D loss: 0.737405, acc.: 45.31%] [G loss: 0.752089]\n",
      "epoch:9 step:7667 [D loss: 0.682713, acc.: 59.38%] [G loss: 0.823641]\n",
      "epoch:9 step:7668 [D loss: 0.717603, acc.: 53.12%] [G loss: 0.730574]\n",
      "epoch:9 step:7669 [D loss: 0.704842, acc.: 51.56%] [G loss: 0.750284]\n",
      "epoch:9 step:7670 [D loss: 0.715170, acc.: 50.00%] [G loss: 0.774367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7671 [D loss: 0.665917, acc.: 52.34%] [G loss: 0.833957]\n",
      "epoch:9 step:7672 [D loss: 0.751770, acc.: 46.88%] [G loss: 0.866078]\n",
      "epoch:9 step:7673 [D loss: 0.681137, acc.: 53.91%] [G loss: 0.774423]\n",
      "epoch:9 step:7674 [D loss: 0.697334, acc.: 48.44%] [G loss: 0.724659]\n",
      "epoch:9 step:7675 [D loss: 0.685237, acc.: 54.69%] [G loss: 0.784768]\n",
      "epoch:9 step:7676 [D loss: 0.689367, acc.: 53.91%] [G loss: 0.719178]\n",
      "epoch:9 step:7677 [D loss: 0.652312, acc.: 62.50%] [G loss: 0.766064]\n",
      "epoch:9 step:7678 [D loss: 0.692736, acc.: 56.25%] [G loss: 0.765454]\n",
      "epoch:9 step:7679 [D loss: 0.755233, acc.: 39.06%] [G loss: 0.721636]\n",
      "epoch:9 step:7680 [D loss: 0.698186, acc.: 47.66%] [G loss: 0.803106]\n",
      "epoch:9 step:7681 [D loss: 0.663665, acc.: 61.72%] [G loss: 0.763366]\n",
      "epoch:9 step:7682 [D loss: 0.692182, acc.: 54.69%] [G loss: 0.747275]\n",
      "epoch:9 step:7683 [D loss: 0.709527, acc.: 50.00%] [G loss: 0.803905]\n",
      "epoch:9 step:7684 [D loss: 0.718523, acc.: 46.88%] [G loss: 0.747238]\n",
      "epoch:9 step:7685 [D loss: 0.620832, acc.: 68.75%] [G loss: 0.773471]\n",
      "epoch:9 step:7686 [D loss: 0.702052, acc.: 48.44%] [G loss: 0.748948]\n",
      "epoch:9 step:7687 [D loss: 0.663635, acc.: 64.84%] [G loss: 0.804113]\n",
      "epoch:9 step:7688 [D loss: 0.682244, acc.: 57.81%] [G loss: 0.763409]\n",
      "epoch:9 step:7689 [D loss: 0.657385, acc.: 58.59%] [G loss: 0.892107]\n",
      "epoch:9 step:7690 [D loss: 0.640559, acc.: 57.81%] [G loss: 0.842263]\n",
      "epoch:9 step:7691 [D loss: 0.679388, acc.: 60.16%] [G loss: 0.781571]\n",
      "epoch:9 step:7692 [D loss: 0.632931, acc.: 66.41%] [G loss: 0.776351]\n",
      "epoch:9 step:7693 [D loss: 0.659773, acc.: 60.16%] [G loss: 0.746460]\n",
      "epoch:9 step:7694 [D loss: 0.711218, acc.: 46.88%] [G loss: 0.766966]\n",
      "epoch:9 step:7695 [D loss: 0.676514, acc.: 59.38%] [G loss: 0.802509]\n",
      "epoch:9 step:7696 [D loss: 0.669368, acc.: 59.38%] [G loss: 0.777427]\n",
      "epoch:9 step:7697 [D loss: 0.656125, acc.: 63.28%] [G loss: 0.764446]\n",
      "epoch:9 step:7698 [D loss: 0.636135, acc.: 64.06%] [G loss: 0.724756]\n",
      "epoch:9 step:7699 [D loss: 0.715646, acc.: 47.66%] [G loss: 0.767332]\n",
      "epoch:9 step:7700 [D loss: 0.666193, acc.: 56.25%] [G loss: 0.817713]\n",
      "epoch:9 step:7701 [D loss: 0.686919, acc.: 57.81%] [G loss: 0.644614]\n",
      "epoch:9 step:7702 [D loss: 0.650203, acc.: 64.06%] [G loss: 0.820342]\n",
      "epoch:9 step:7703 [D loss: 0.701718, acc.: 47.66%] [G loss: 0.727805]\n",
      "epoch:9 step:7704 [D loss: 0.716427, acc.: 50.00%] [G loss: 0.709355]\n",
      "epoch:9 step:7705 [D loss: 0.737168, acc.: 45.31%] [G loss: 0.659070]\n",
      "epoch:9 step:7706 [D loss: 0.755518, acc.: 43.75%] [G loss: 0.683212]\n",
      "epoch:9 step:7707 [D loss: 0.752740, acc.: 42.19%] [G loss: 0.753081]\n",
      "epoch:9 step:7708 [D loss: 0.675073, acc.: 62.50%] [G loss: 0.797765]\n",
      "epoch:9 step:7709 [D loss: 0.694691, acc.: 53.12%] [G loss: 0.780465]\n",
      "epoch:9 step:7710 [D loss: 0.698919, acc.: 51.56%] [G loss: 0.792284]\n",
      "epoch:9 step:7711 [D loss: 0.682011, acc.: 58.59%] [G loss: 0.808124]\n",
      "epoch:9 step:7712 [D loss: 0.720711, acc.: 54.69%] [G loss: 0.796858]\n",
      "epoch:9 step:7713 [D loss: 0.710745, acc.: 51.56%] [G loss: 0.794995]\n",
      "epoch:9 step:7714 [D loss: 0.683706, acc.: 61.72%] [G loss: 0.804329]\n",
      "epoch:9 step:7715 [D loss: 0.696421, acc.: 57.03%] [G loss: 0.828365]\n",
      "epoch:9 step:7716 [D loss: 0.734966, acc.: 45.31%] [G loss: 0.716083]\n",
      "epoch:9 step:7717 [D loss: 0.668578, acc.: 61.72%] [G loss: 0.763179]\n",
      "epoch:9 step:7718 [D loss: 0.732311, acc.: 49.22%] [G loss: 0.708819]\n",
      "epoch:9 step:7719 [D loss: 0.651896, acc.: 62.50%] [G loss: 0.761193]\n",
      "epoch:9 step:7720 [D loss: 0.683443, acc.: 59.38%] [G loss: 0.749313]\n",
      "epoch:9 step:7721 [D loss: 0.775883, acc.: 39.84%] [G loss: 0.691099]\n",
      "epoch:9 step:7722 [D loss: 0.683649, acc.: 54.69%] [G loss: 0.694522]\n",
      "epoch:9 step:7723 [D loss: 0.669907, acc.: 62.50%] [G loss: 0.816274]\n",
      "epoch:9 step:7724 [D loss: 0.718097, acc.: 46.09%] [G loss: 0.708873]\n",
      "epoch:9 step:7725 [D loss: 0.743186, acc.: 43.75%] [G loss: 0.648368]\n",
      "epoch:9 step:7726 [D loss: 0.793906, acc.: 32.81%] [G loss: 0.685304]\n",
      "epoch:9 step:7727 [D loss: 0.684229, acc.: 58.59%] [G loss: 0.735259]\n",
      "epoch:9 step:7728 [D loss: 0.726076, acc.: 39.06%] [G loss: 0.751665]\n",
      "epoch:9 step:7729 [D loss: 0.742449, acc.: 38.28%] [G loss: 0.789617]\n",
      "epoch:9 step:7730 [D loss: 0.741342, acc.: 42.97%] [G loss: 0.842735]\n",
      "epoch:9 step:7731 [D loss: 0.723879, acc.: 48.44%] [G loss: 0.718168]\n",
      "epoch:9 step:7732 [D loss: 0.694578, acc.: 53.91%] [G loss: 0.780517]\n",
      "epoch:9 step:7733 [D loss: 0.711102, acc.: 53.12%] [G loss: 0.708743]\n",
      "epoch:9 step:7734 [D loss: 0.715849, acc.: 50.00%] [G loss: 0.702617]\n",
      "epoch:9 step:7735 [D loss: 0.730784, acc.: 44.53%] [G loss: 0.782580]\n",
      "epoch:9 step:7736 [D loss: 0.692449, acc.: 53.12%] [G loss: 0.807093]\n",
      "epoch:9 step:7737 [D loss: 0.772254, acc.: 28.91%] [G loss: 0.676284]\n",
      "epoch:9 step:7738 [D loss: 0.705866, acc.: 52.34%] [G loss: 0.792292]\n",
      "epoch:9 step:7739 [D loss: 0.715683, acc.: 42.19%] [G loss: 0.787027]\n",
      "epoch:9 step:7740 [D loss: 0.661550, acc.: 58.59%] [G loss: 0.781999]\n",
      "epoch:9 step:7741 [D loss: 0.673296, acc.: 54.69%] [G loss: 0.855012]\n",
      "epoch:9 step:7742 [D loss: 0.722188, acc.: 47.66%] [G loss: 0.865671]\n",
      "epoch:9 step:7743 [D loss: 0.695612, acc.: 52.34%] [G loss: 0.900916]\n",
      "epoch:9 step:7744 [D loss: 0.691094, acc.: 51.56%] [G loss: 0.837677]\n",
      "epoch:9 step:7745 [D loss: 0.698868, acc.: 49.22%] [G loss: 0.763034]\n",
      "epoch:9 step:7746 [D loss: 0.640661, acc.: 66.41%] [G loss: 0.883637]\n",
      "epoch:9 step:7747 [D loss: 0.647344, acc.: 58.59%] [G loss: 0.818614]\n",
      "epoch:9 step:7748 [D loss: 0.688543, acc.: 53.12%] [G loss: 0.768147]\n",
      "epoch:9 step:7749 [D loss: 0.741362, acc.: 43.75%] [G loss: 0.784053]\n",
      "epoch:9 step:7750 [D loss: 0.672725, acc.: 60.94%] [G loss: 0.749215]\n",
      "epoch:9 step:7751 [D loss: 0.650831, acc.: 66.41%] [G loss: 0.855339]\n",
      "epoch:9 step:7752 [D loss: 0.715065, acc.: 46.88%] [G loss: 0.775927]\n",
      "epoch:9 step:7753 [D loss: 0.692366, acc.: 53.12%] [G loss: 0.822292]\n",
      "epoch:9 step:7754 [D loss: 0.695202, acc.: 51.56%] [G loss: 0.802622]\n",
      "epoch:9 step:7755 [D loss: 0.694624, acc.: 50.78%] [G loss: 0.828542]\n",
      "epoch:9 step:7756 [D loss: 0.694466, acc.: 54.69%] [G loss: 0.815249]\n",
      "epoch:9 step:7757 [D loss: 0.733001, acc.: 45.31%] [G loss: 0.708263]\n",
      "epoch:9 step:7758 [D loss: 0.675860, acc.: 53.91%] [G loss: 0.745815]\n",
      "epoch:9 step:7759 [D loss: 0.666712, acc.: 61.72%] [G loss: 0.725479]\n",
      "epoch:9 step:7760 [D loss: 0.651032, acc.: 65.62%] [G loss: 0.838490]\n",
      "epoch:9 step:7761 [D loss: 0.664514, acc.: 56.25%] [G loss: 0.842391]\n",
      "epoch:9 step:7762 [D loss: 0.667066, acc.: 64.06%] [G loss: 0.816040]\n",
      "epoch:9 step:7763 [D loss: 0.707005, acc.: 53.12%] [G loss: 0.789499]\n",
      "epoch:9 step:7764 [D loss: 0.725655, acc.: 48.44%] [G loss: 0.819770]\n",
      "epoch:9 step:7765 [D loss: 0.654088, acc.: 65.62%] [G loss: 0.765635]\n",
      "epoch:9 step:7766 [D loss: 0.763800, acc.: 43.75%] [G loss: 0.769026]\n",
      "epoch:9 step:7767 [D loss: 0.691244, acc.: 60.94%] [G loss: 0.730707]\n",
      "epoch:9 step:7768 [D loss: 0.760020, acc.: 33.59%] [G loss: 0.747725]\n",
      "epoch:9 step:7769 [D loss: 0.664105, acc.: 62.50%] [G loss: 0.746037]\n",
      "epoch:9 step:7770 [D loss: 0.706795, acc.: 51.56%] [G loss: 0.734324]\n",
      "epoch:9 step:7771 [D loss: 0.730546, acc.: 46.88%] [G loss: 0.713293]\n",
      "epoch:9 step:7772 [D loss: 0.699840, acc.: 50.00%] [G loss: 0.767386]\n",
      "epoch:9 step:7773 [D loss: 0.723961, acc.: 44.53%] [G loss: 0.777767]\n",
      "epoch:9 step:7774 [D loss: 0.740607, acc.: 45.31%] [G loss: 0.851588]\n",
      "epoch:9 step:7775 [D loss: 0.652208, acc.: 61.72%] [G loss: 0.778561]\n",
      "epoch:9 step:7776 [D loss: 0.712492, acc.: 55.47%] [G loss: 0.813429]\n",
      "epoch:9 step:7777 [D loss: 0.752099, acc.: 46.09%] [G loss: 0.756247]\n",
      "epoch:9 step:7778 [D loss: 0.625147, acc.: 72.66%] [G loss: 0.828944]\n",
      "epoch:9 step:7779 [D loss: 0.647592, acc.: 62.50%] [G loss: 0.805887]\n",
      "epoch:9 step:7780 [D loss: 0.716962, acc.: 48.44%] [G loss: 0.758890]\n",
      "epoch:9 step:7781 [D loss: 0.713600, acc.: 46.88%] [G loss: 0.760325]\n",
      "epoch:9 step:7782 [D loss: 0.759271, acc.: 36.72%] [G loss: 0.749433]\n",
      "epoch:9 step:7783 [D loss: 0.652296, acc.: 67.97%] [G loss: 0.773623]\n",
      "epoch:9 step:7784 [D loss: 0.711396, acc.: 50.00%] [G loss: 0.786958]\n",
      "epoch:9 step:7785 [D loss: 0.635921, acc.: 67.19%] [G loss: 0.808576]\n",
      "epoch:9 step:7786 [D loss: 0.690767, acc.: 52.34%] [G loss: 0.788664]\n",
      "epoch:9 step:7787 [D loss: 0.685150, acc.: 54.69%] [G loss: 0.753726]\n",
      "epoch:9 step:7788 [D loss: 0.726895, acc.: 47.66%] [G loss: 0.804663]\n",
      "epoch:9 step:7789 [D loss: 0.703025, acc.: 50.78%] [G loss: 0.778697]\n",
      "epoch:9 step:7790 [D loss: 0.740016, acc.: 44.53%] [G loss: 0.699496]\n",
      "epoch:9 step:7791 [D loss: 0.699845, acc.: 52.34%] [G loss: 0.805627]\n",
      "epoch:9 step:7792 [D loss: 0.663870, acc.: 59.38%] [G loss: 0.802523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7793 [D loss: 0.702585, acc.: 49.22%] [G loss: 0.840467]\n",
      "epoch:9 step:7794 [D loss: 0.635331, acc.: 68.75%] [G loss: 0.798750]\n",
      "epoch:9 step:7795 [D loss: 0.673875, acc.: 59.38%] [G loss: 0.816311]\n",
      "epoch:9 step:7796 [D loss: 0.727671, acc.: 50.78%] [G loss: 0.781471]\n",
      "epoch:9 step:7797 [D loss: 0.649868, acc.: 64.06%] [G loss: 0.844888]\n",
      "epoch:9 step:7798 [D loss: 0.698908, acc.: 53.91%] [G loss: 0.817352]\n",
      "epoch:9 step:7799 [D loss: 0.706205, acc.: 46.09%] [G loss: 0.815670]\n",
      "epoch:9 step:7800 [D loss: 0.697853, acc.: 48.44%] [G loss: 0.809991]\n",
      "epoch:9 step:7801 [D loss: 0.687318, acc.: 52.34%] [G loss: 0.772144]\n",
      "epoch:9 step:7802 [D loss: 0.680166, acc.: 57.03%] [G loss: 0.768948]\n",
      "epoch:9 step:7803 [D loss: 0.732001, acc.: 46.09%] [G loss: 0.774958]\n",
      "epoch:9 step:7804 [D loss: 0.666375, acc.: 60.16%] [G loss: 0.773416]\n",
      "epoch:9 step:7805 [D loss: 0.713128, acc.: 42.97%] [G loss: 0.757435]\n",
      "epoch:9 step:7806 [D loss: 0.706076, acc.: 50.00%] [G loss: 0.712602]\n",
      "epoch:9 step:7807 [D loss: 0.708433, acc.: 52.34%] [G loss: 0.852005]\n",
      "epoch:9 step:7808 [D loss: 0.705858, acc.: 47.66%] [G loss: 0.742203]\n",
      "epoch:9 step:7809 [D loss: 0.690080, acc.: 53.12%] [G loss: 0.760352]\n",
      "epoch:9 step:7810 [D loss: 0.656928, acc.: 61.72%] [G loss: 0.841066]\n",
      "epoch:10 step:7811 [D loss: 0.671023, acc.: 57.81%] [G loss: 0.855570]\n",
      "epoch:10 step:7812 [D loss: 0.659157, acc.: 61.72%] [G loss: 0.807950]\n",
      "epoch:10 step:7813 [D loss: 0.654115, acc.: 64.84%] [G loss: 0.862802]\n",
      "epoch:10 step:7814 [D loss: 0.710058, acc.: 46.88%] [G loss: 0.794315]\n",
      "epoch:10 step:7815 [D loss: 0.725923, acc.: 43.75%] [G loss: 0.806853]\n",
      "epoch:10 step:7816 [D loss: 0.715803, acc.: 53.91%] [G loss: 0.761681]\n",
      "epoch:10 step:7817 [D loss: 0.751381, acc.: 35.94%] [G loss: 0.813031]\n",
      "epoch:10 step:7818 [D loss: 0.689391, acc.: 54.69%] [G loss: 0.827263]\n",
      "epoch:10 step:7819 [D loss: 0.696552, acc.: 53.12%] [G loss: 0.816786]\n",
      "epoch:10 step:7820 [D loss: 0.718369, acc.: 42.19%] [G loss: 0.982890]\n",
      "epoch:10 step:7821 [D loss: 0.646148, acc.: 62.50%] [G loss: 0.866365]\n",
      "epoch:10 step:7822 [D loss: 0.680652, acc.: 56.25%] [G loss: 0.789884]\n",
      "epoch:10 step:7823 [D loss: 0.634760, acc.: 62.50%] [G loss: 0.885186]\n",
      "epoch:10 step:7824 [D loss: 0.698715, acc.: 63.28%] [G loss: 0.840963]\n",
      "epoch:10 step:7825 [D loss: 0.727870, acc.: 44.53%] [G loss: 0.712517]\n",
      "epoch:10 step:7826 [D loss: 0.663476, acc.: 58.59%] [G loss: 0.738713]\n",
      "epoch:10 step:7827 [D loss: 0.710713, acc.: 53.91%] [G loss: 0.736452]\n",
      "epoch:10 step:7828 [D loss: 0.674095, acc.: 57.03%] [G loss: 0.710242]\n",
      "epoch:10 step:7829 [D loss: 0.722780, acc.: 42.97%] [G loss: 0.767520]\n",
      "epoch:10 step:7830 [D loss: 0.709017, acc.: 46.88%] [G loss: 0.751046]\n",
      "epoch:10 step:7831 [D loss: 0.698371, acc.: 51.56%] [G loss: 0.783832]\n",
      "epoch:10 step:7832 [D loss: 0.689234, acc.: 53.91%] [G loss: 0.757682]\n",
      "epoch:10 step:7833 [D loss: 0.709218, acc.: 53.91%] [G loss: 0.832060]\n",
      "epoch:10 step:7834 [D loss: 0.734739, acc.: 49.22%] [G loss: 0.881767]\n",
      "epoch:10 step:7835 [D loss: 0.726879, acc.: 51.56%] [G loss: 0.810441]\n",
      "epoch:10 step:7836 [D loss: 0.692581, acc.: 50.00%] [G loss: 0.808843]\n",
      "epoch:10 step:7837 [D loss: 0.652432, acc.: 62.50%] [G loss: 0.777407]\n",
      "epoch:10 step:7838 [D loss: 0.739739, acc.: 46.09%] [G loss: 0.777694]\n",
      "epoch:10 step:7839 [D loss: 0.680507, acc.: 53.12%] [G loss: 0.771970]\n",
      "epoch:10 step:7840 [D loss: 0.700843, acc.: 50.00%] [G loss: 0.750425]\n",
      "epoch:10 step:7841 [D loss: 0.743581, acc.: 39.06%] [G loss: 0.711973]\n",
      "epoch:10 step:7842 [D loss: 0.646554, acc.: 65.62%] [G loss: 0.728374]\n",
      "epoch:10 step:7843 [D loss: 0.677041, acc.: 58.59%] [G loss: 0.724151]\n",
      "epoch:10 step:7844 [D loss: 0.662420, acc.: 63.28%] [G loss: 0.727209]\n",
      "epoch:10 step:7845 [D loss: 0.732872, acc.: 46.09%] [G loss: 0.769475]\n",
      "epoch:10 step:7846 [D loss: 0.712553, acc.: 51.56%] [G loss: 0.767034]\n",
      "epoch:10 step:7847 [D loss: 0.691609, acc.: 53.12%] [G loss: 0.788015]\n",
      "epoch:10 step:7848 [D loss: 0.652263, acc.: 60.94%] [G loss: 0.789207]\n",
      "epoch:10 step:7849 [D loss: 0.709222, acc.: 48.44%] [G loss: 0.800271]\n",
      "epoch:10 step:7850 [D loss: 0.733369, acc.: 44.53%] [G loss: 0.716472]\n",
      "epoch:10 step:7851 [D loss: 0.660266, acc.: 60.16%] [G loss: 0.768337]\n",
      "epoch:10 step:7852 [D loss: 0.710981, acc.: 44.53%] [G loss: 0.739164]\n",
      "epoch:10 step:7853 [D loss: 0.691225, acc.: 55.47%] [G loss: 0.714476]\n",
      "epoch:10 step:7854 [D loss: 0.692189, acc.: 54.69%] [G loss: 0.698307]\n",
      "epoch:10 step:7855 [D loss: 0.657958, acc.: 62.50%] [G loss: 0.723359]\n",
      "epoch:10 step:7856 [D loss: 0.778715, acc.: 35.16%] [G loss: 0.695927]\n",
      "epoch:10 step:7857 [D loss: 0.728858, acc.: 42.97%] [G loss: 0.770157]\n",
      "epoch:10 step:7858 [D loss: 0.744085, acc.: 39.84%] [G loss: 0.766698]\n",
      "epoch:10 step:7859 [D loss: 0.742015, acc.: 43.75%] [G loss: 0.726247]\n",
      "epoch:10 step:7860 [D loss: 0.782886, acc.: 42.19%] [G loss: 0.746579]\n",
      "epoch:10 step:7861 [D loss: 0.683587, acc.: 57.81%] [G loss: 0.749649]\n",
      "epoch:10 step:7862 [D loss: 0.740706, acc.: 51.56%] [G loss: 0.769603]\n",
      "epoch:10 step:7863 [D loss: 0.693591, acc.: 52.34%] [G loss: 0.757426]\n",
      "epoch:10 step:7864 [D loss: 0.732216, acc.: 43.75%] [G loss: 0.740246]\n",
      "epoch:10 step:7865 [D loss: 0.675993, acc.: 57.03%] [G loss: 0.810581]\n",
      "epoch:10 step:7866 [D loss: 0.694715, acc.: 58.59%] [G loss: 0.778766]\n",
      "epoch:10 step:7867 [D loss: 0.693766, acc.: 58.59%] [G loss: 0.749807]\n",
      "epoch:10 step:7868 [D loss: 0.681605, acc.: 52.34%] [G loss: 0.705008]\n",
      "epoch:10 step:7869 [D loss: 0.718853, acc.: 53.91%] [G loss: 0.746971]\n",
      "epoch:10 step:7870 [D loss: 0.719802, acc.: 45.31%] [G loss: 0.885420]\n",
      "epoch:10 step:7871 [D loss: 0.634106, acc.: 66.41%] [G loss: 0.826345]\n",
      "epoch:10 step:7872 [D loss: 0.691520, acc.: 57.81%] [G loss: 0.867630]\n",
      "epoch:10 step:7873 [D loss: 0.725937, acc.: 46.09%] [G loss: 0.770023]\n",
      "epoch:10 step:7874 [D loss: 0.649690, acc.: 65.62%] [G loss: 0.816641]\n",
      "epoch:10 step:7875 [D loss: 0.669430, acc.: 58.59%] [G loss: 0.753333]\n",
      "epoch:10 step:7876 [D loss: 0.691456, acc.: 50.00%] [G loss: 0.779881]\n",
      "epoch:10 step:7877 [D loss: 0.690866, acc.: 53.91%] [G loss: 0.775706]\n",
      "epoch:10 step:7878 [D loss: 0.666375, acc.: 58.59%] [G loss: 0.779476]\n",
      "epoch:10 step:7879 [D loss: 0.701727, acc.: 46.09%] [G loss: 0.739357]\n",
      "epoch:10 step:7880 [D loss: 0.733416, acc.: 48.44%] [G loss: 0.749628]\n",
      "epoch:10 step:7881 [D loss: 0.774565, acc.: 40.62%] [G loss: 0.671659]\n",
      "epoch:10 step:7882 [D loss: 0.735189, acc.: 46.88%] [G loss: 0.745233]\n",
      "epoch:10 step:7883 [D loss: 0.703244, acc.: 52.34%] [G loss: 0.677894]\n",
      "epoch:10 step:7884 [D loss: 0.715638, acc.: 41.41%] [G loss: 0.680016]\n",
      "epoch:10 step:7885 [D loss: 0.704349, acc.: 57.03%] [G loss: 0.756687]\n",
      "epoch:10 step:7886 [D loss: 0.752092, acc.: 50.00%] [G loss: 0.777851]\n",
      "epoch:10 step:7887 [D loss: 0.734697, acc.: 46.09%] [G loss: 0.766312]\n",
      "epoch:10 step:7888 [D loss: 0.756683, acc.: 42.97%] [G loss: 0.746020]\n",
      "epoch:10 step:7889 [D loss: 0.709489, acc.: 50.00%] [G loss: 0.899325]\n",
      "epoch:10 step:7890 [D loss: 0.722539, acc.: 45.31%] [G loss: 0.805378]\n",
      "epoch:10 step:7891 [D loss: 0.654011, acc.: 62.50%] [G loss: 0.832494]\n",
      "epoch:10 step:7892 [D loss: 0.721432, acc.: 48.44%] [G loss: 0.786122]\n",
      "epoch:10 step:7893 [D loss: 0.640162, acc.: 64.06%] [G loss: 0.890877]\n",
      "epoch:10 step:7894 [D loss: 0.718045, acc.: 46.88%] [G loss: 0.732693]\n",
      "epoch:10 step:7895 [D loss: 0.701609, acc.: 56.25%] [G loss: 0.784539]\n",
      "epoch:10 step:7896 [D loss: 0.659435, acc.: 64.06%] [G loss: 0.809097]\n",
      "epoch:10 step:7897 [D loss: 0.696799, acc.: 55.47%] [G loss: 0.810482]\n",
      "epoch:10 step:7898 [D loss: 0.735162, acc.: 41.41%] [G loss: 0.723936]\n",
      "epoch:10 step:7899 [D loss: 0.681097, acc.: 54.69%] [G loss: 0.737715]\n",
      "epoch:10 step:7900 [D loss: 0.661722, acc.: 58.59%] [G loss: 0.736357]\n",
      "epoch:10 step:7901 [D loss: 0.674010, acc.: 63.28%] [G loss: 0.722874]\n",
      "epoch:10 step:7902 [D loss: 0.639161, acc.: 69.53%] [G loss: 0.699389]\n",
      "epoch:10 step:7903 [D loss: 0.652579, acc.: 59.38%] [G loss: 0.712366]\n",
      "epoch:10 step:7904 [D loss: 0.665213, acc.: 62.50%] [G loss: 0.698135]\n",
      "epoch:10 step:7905 [D loss: 0.650860, acc.: 58.59%] [G loss: 0.724405]\n",
      "epoch:10 step:7906 [D loss: 0.730742, acc.: 40.62%] [G loss: 0.690482]\n",
      "epoch:10 step:7907 [D loss: 0.721837, acc.: 50.78%] [G loss: 0.731798]\n",
      "epoch:10 step:7908 [D loss: 0.785433, acc.: 32.81%] [G loss: 0.733646]\n",
      "epoch:10 step:7909 [D loss: 0.677192, acc.: 60.16%] [G loss: 0.730208]\n",
      "epoch:10 step:7910 [D loss: 0.729715, acc.: 44.53%] [G loss: 0.805233]\n",
      "epoch:10 step:7911 [D loss: 0.665910, acc.: 60.94%] [G loss: 0.838234]\n",
      "epoch:10 step:7912 [D loss: 0.713120, acc.: 50.00%] [G loss: 0.774143]\n",
      "epoch:10 step:7913 [D loss: 0.724511, acc.: 44.53%] [G loss: 0.797425]\n",
      "epoch:10 step:7914 [D loss: 0.721941, acc.: 50.00%] [G loss: 0.784282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7915 [D loss: 0.713528, acc.: 50.78%] [G loss: 0.790435]\n",
      "epoch:10 step:7916 [D loss: 0.622406, acc.: 71.88%] [G loss: 0.744734]\n",
      "epoch:10 step:7917 [D loss: 0.741957, acc.: 38.28%] [G loss: 0.722628]\n",
      "epoch:10 step:7918 [D loss: 0.787131, acc.: 35.94%] [G loss: 0.697433]\n",
      "epoch:10 step:7919 [D loss: 0.691779, acc.: 56.25%] [G loss: 0.651005]\n",
      "epoch:10 step:7920 [D loss: 0.702326, acc.: 55.47%] [G loss: 0.762865]\n",
      "epoch:10 step:7921 [D loss: 0.733107, acc.: 40.62%] [G loss: 0.712964]\n",
      "epoch:10 step:7922 [D loss: 0.691375, acc.: 52.34%] [G loss: 0.737954]\n",
      "epoch:10 step:7923 [D loss: 0.693925, acc.: 49.22%] [G loss: 0.761977]\n",
      "epoch:10 step:7924 [D loss: 0.676925, acc.: 58.59%] [G loss: 0.818455]\n",
      "epoch:10 step:7925 [D loss: 0.686088, acc.: 53.12%] [G loss: 0.779577]\n",
      "epoch:10 step:7926 [D loss: 0.742663, acc.: 42.19%] [G loss: 0.755006]\n",
      "epoch:10 step:7927 [D loss: 0.709717, acc.: 46.88%] [G loss: 0.698929]\n",
      "epoch:10 step:7928 [D loss: 0.690303, acc.: 50.78%] [G loss: 0.746801]\n",
      "epoch:10 step:7929 [D loss: 0.687713, acc.: 54.69%] [G loss: 0.758894]\n",
      "epoch:10 step:7930 [D loss: 0.696225, acc.: 51.56%] [G loss: 0.791221]\n",
      "epoch:10 step:7931 [D loss: 0.731270, acc.: 45.31%] [G loss: 0.793430]\n",
      "epoch:10 step:7932 [D loss: 0.698540, acc.: 52.34%] [G loss: 0.777798]\n",
      "epoch:10 step:7933 [D loss: 0.721229, acc.: 44.53%] [G loss: 0.799290]\n",
      "epoch:10 step:7934 [D loss: 0.775928, acc.: 37.50%] [G loss: 0.741340]\n",
      "epoch:10 step:7935 [D loss: 0.710161, acc.: 46.09%] [G loss: 0.653303]\n",
      "epoch:10 step:7936 [D loss: 0.711462, acc.: 51.56%] [G loss: 0.690057]\n",
      "epoch:10 step:7937 [D loss: 0.663083, acc.: 60.16%] [G loss: 0.724764]\n",
      "epoch:10 step:7938 [D loss: 0.650370, acc.: 63.28%] [G loss: 0.721053]\n",
      "epoch:10 step:7939 [D loss: 0.698111, acc.: 57.03%] [G loss: 0.697842]\n",
      "epoch:10 step:7940 [D loss: 0.691125, acc.: 47.66%] [G loss: 0.693097]\n",
      "epoch:10 step:7941 [D loss: 0.716367, acc.: 52.34%] [G loss: 0.745850]\n",
      "epoch:10 step:7942 [D loss: 0.667379, acc.: 64.06%] [G loss: 0.801298]\n",
      "epoch:10 step:7943 [D loss: 0.714841, acc.: 48.44%] [G loss: 0.746069]\n",
      "epoch:10 step:7944 [D loss: 0.649786, acc.: 60.94%] [G loss: 0.914677]\n",
      "epoch:10 step:7945 [D loss: 0.810138, acc.: 36.72%] [G loss: 0.790846]\n",
      "epoch:10 step:7946 [D loss: 0.711035, acc.: 43.75%] [G loss: 0.751235]\n",
      "epoch:10 step:7947 [D loss: 0.733217, acc.: 46.88%] [G loss: 0.793319]\n",
      "epoch:10 step:7948 [D loss: 0.721915, acc.: 51.56%] [G loss: 0.747199]\n",
      "epoch:10 step:7949 [D loss: 0.692715, acc.: 56.25%] [G loss: 0.800172]\n",
      "epoch:10 step:7950 [D loss: 0.675183, acc.: 60.16%] [G loss: 0.784445]\n",
      "epoch:10 step:7951 [D loss: 0.696966, acc.: 55.47%] [G loss: 0.850068]\n",
      "epoch:10 step:7952 [D loss: 0.730070, acc.: 48.44%] [G loss: 0.819455]\n",
      "epoch:10 step:7953 [D loss: 0.736707, acc.: 41.41%] [G loss: 0.784722]\n",
      "epoch:10 step:7954 [D loss: 0.670148, acc.: 60.94%] [G loss: 0.755049]\n",
      "epoch:10 step:7955 [D loss: 0.707787, acc.: 51.56%] [G loss: 0.739465]\n",
      "epoch:10 step:7956 [D loss: 0.638508, acc.: 64.84%] [G loss: 0.801127]\n",
      "epoch:10 step:7957 [D loss: 0.720785, acc.: 48.44%] [G loss: 0.747916]\n",
      "epoch:10 step:7958 [D loss: 0.715490, acc.: 49.22%] [G loss: 0.809326]\n",
      "epoch:10 step:7959 [D loss: 0.634174, acc.: 69.53%] [G loss: 0.793193]\n",
      "epoch:10 step:7960 [D loss: 0.731095, acc.: 46.88%] [G loss: 0.761440]\n",
      "epoch:10 step:7961 [D loss: 0.719647, acc.: 45.31%] [G loss: 0.802807]\n",
      "epoch:10 step:7962 [D loss: 0.711395, acc.: 45.31%] [G loss: 0.798053]\n",
      "epoch:10 step:7963 [D loss: 0.726816, acc.: 48.44%] [G loss: 0.719240]\n",
      "epoch:10 step:7964 [D loss: 0.686257, acc.: 54.69%] [G loss: 0.802097]\n",
      "epoch:10 step:7965 [D loss: 0.732077, acc.: 46.09%] [G loss: 0.780395]\n",
      "epoch:10 step:7966 [D loss: 0.749514, acc.: 41.41%] [G loss: 0.762020]\n",
      "epoch:10 step:7967 [D loss: 0.661448, acc.: 53.12%] [G loss: 0.730765]\n",
      "epoch:10 step:7968 [D loss: 0.677693, acc.: 53.91%] [G loss: 0.778229]\n",
      "epoch:10 step:7969 [D loss: 0.740743, acc.: 43.75%] [G loss: 0.763883]\n",
      "epoch:10 step:7970 [D loss: 0.679255, acc.: 54.69%] [G loss: 0.754552]\n",
      "epoch:10 step:7971 [D loss: 0.742250, acc.: 42.19%] [G loss: 0.727988]\n",
      "epoch:10 step:7972 [D loss: 0.673365, acc.: 55.47%] [G loss: 0.820147]\n",
      "epoch:10 step:7973 [D loss: 0.722624, acc.: 52.34%] [G loss: 0.813396]\n",
      "epoch:10 step:7974 [D loss: 0.737147, acc.: 43.75%] [G loss: 0.763692]\n",
      "epoch:10 step:7975 [D loss: 0.696492, acc.: 56.25%] [G loss: 0.786285]\n",
      "epoch:10 step:7976 [D loss: 0.739695, acc.: 43.75%] [G loss: 0.817620]\n",
      "epoch:10 step:7977 [D loss: 0.718065, acc.: 48.44%] [G loss: 0.815317]\n",
      "epoch:10 step:7978 [D loss: 0.697668, acc.: 54.69%] [G loss: 0.797866]\n",
      "epoch:10 step:7979 [D loss: 0.706844, acc.: 48.44%] [G loss: 0.826703]\n",
      "epoch:10 step:7980 [D loss: 0.688844, acc.: 53.91%] [G loss: 0.798781]\n",
      "epoch:10 step:7981 [D loss: 0.730077, acc.: 41.41%] [G loss: 0.790635]\n",
      "epoch:10 step:7982 [D loss: 0.681177, acc.: 55.47%] [G loss: 0.806461]\n",
      "epoch:10 step:7983 [D loss: 0.674027, acc.: 60.16%] [G loss: 0.822535]\n",
      "epoch:10 step:7984 [D loss: 0.731471, acc.: 41.41%] [G loss: 0.811323]\n",
      "epoch:10 step:7985 [D loss: 0.733838, acc.: 42.19%] [G loss: 0.797674]\n",
      "epoch:10 step:7986 [D loss: 0.710323, acc.: 47.66%] [G loss: 0.836987]\n",
      "epoch:10 step:7987 [D loss: 0.664146, acc.: 60.94%] [G loss: 0.779003]\n",
      "epoch:10 step:7988 [D loss: 0.705771, acc.: 50.00%] [G loss: 0.817519]\n",
      "epoch:10 step:7989 [D loss: 0.702222, acc.: 50.78%] [G loss: 0.788732]\n",
      "epoch:10 step:7990 [D loss: 0.687667, acc.: 57.81%] [G loss: 0.789500]\n",
      "epoch:10 step:7991 [D loss: 0.695337, acc.: 55.47%] [G loss: 0.803393]\n",
      "epoch:10 step:7992 [D loss: 0.735352, acc.: 42.97%] [G loss: 0.779551]\n",
      "epoch:10 step:7993 [D loss: 0.734316, acc.: 50.00%] [G loss: 0.747692]\n",
      "epoch:10 step:7994 [D loss: 0.724146, acc.: 46.09%] [G loss: 0.751302]\n",
      "epoch:10 step:7995 [D loss: 0.703684, acc.: 51.56%] [G loss: 0.758565]\n",
      "epoch:10 step:7996 [D loss: 0.682993, acc.: 56.25%] [G loss: 0.739305]\n",
      "epoch:10 step:7997 [D loss: 0.682290, acc.: 57.03%] [G loss: 0.783663]\n",
      "epoch:10 step:7998 [D loss: 0.707376, acc.: 51.56%] [G loss: 0.747397]\n",
      "epoch:10 step:7999 [D loss: 0.678547, acc.: 55.47%] [G loss: 0.755008]\n",
      "epoch:10 step:8000 [D loss: 0.667984, acc.: 60.16%] [G loss: 0.799074]\n",
      "epoch:10 step:8001 [D loss: 0.694997, acc.: 49.22%] [G loss: 0.807403]\n",
      "epoch:10 step:8002 [D loss: 0.709025, acc.: 48.44%] [G loss: 0.819545]\n",
      "epoch:10 step:8003 [D loss: 0.718128, acc.: 41.41%] [G loss: 0.778911]\n",
      "epoch:10 step:8004 [D loss: 0.707035, acc.: 53.12%] [G loss: 0.772290]\n",
      "epoch:10 step:8005 [D loss: 0.764353, acc.: 38.28%] [G loss: 0.767070]\n",
      "epoch:10 step:8006 [D loss: 0.750713, acc.: 42.19%] [G loss: 0.794447]\n",
      "epoch:10 step:8007 [D loss: 0.701032, acc.: 54.69%] [G loss: 0.738392]\n",
      "epoch:10 step:8008 [D loss: 0.643706, acc.: 70.31%] [G loss: 0.894180]\n",
      "epoch:10 step:8009 [D loss: 0.777591, acc.: 40.62%] [G loss: 0.740548]\n",
      "epoch:10 step:8010 [D loss: 0.680836, acc.: 52.34%] [G loss: 0.815063]\n",
      "epoch:10 step:8011 [D loss: 0.697697, acc.: 50.00%] [G loss: 0.812751]\n",
      "epoch:10 step:8012 [D loss: 0.694401, acc.: 52.34%] [G loss: 0.790842]\n",
      "epoch:10 step:8013 [D loss: 0.702472, acc.: 46.88%] [G loss: 0.812967]\n",
      "epoch:10 step:8014 [D loss: 0.703789, acc.: 44.53%] [G loss: 0.776774]\n",
      "epoch:10 step:8015 [D loss: 0.690810, acc.: 59.38%] [G loss: 0.811124]\n",
      "epoch:10 step:8016 [D loss: 0.689638, acc.: 56.25%] [G loss: 0.752721]\n",
      "epoch:10 step:8017 [D loss: 0.680513, acc.: 57.81%] [G loss: 0.759789]\n",
      "epoch:10 step:8018 [D loss: 0.737712, acc.: 45.31%] [G loss: 0.796324]\n",
      "epoch:10 step:8019 [D loss: 0.705414, acc.: 55.47%] [G loss: 0.876177]\n",
      "epoch:10 step:8020 [D loss: 0.665600, acc.: 57.03%] [G loss: 0.714813]\n",
      "epoch:10 step:8021 [D loss: 0.736082, acc.: 39.84%] [G loss: 0.762764]\n",
      "epoch:10 step:8022 [D loss: 0.704309, acc.: 48.44%] [G loss: 0.756083]\n",
      "epoch:10 step:8023 [D loss: 0.653207, acc.: 60.94%] [G loss: 0.843127]\n",
      "epoch:10 step:8024 [D loss: 0.738232, acc.: 42.19%] [G loss: 0.721483]\n",
      "epoch:10 step:8025 [D loss: 0.680893, acc.: 52.34%] [G loss: 0.811259]\n",
      "epoch:10 step:8026 [D loss: 0.704879, acc.: 53.12%] [G loss: 0.804476]\n",
      "epoch:10 step:8027 [D loss: 0.670230, acc.: 55.47%] [G loss: 0.772587]\n",
      "epoch:10 step:8028 [D loss: 0.658913, acc.: 62.50%] [G loss: 0.785456]\n",
      "epoch:10 step:8029 [D loss: 0.694883, acc.: 53.12%] [G loss: 0.771551]\n",
      "epoch:10 step:8030 [D loss: 0.685863, acc.: 53.12%] [G loss: 0.765938]\n",
      "epoch:10 step:8031 [D loss: 0.679128, acc.: 56.25%] [G loss: 0.806176]\n",
      "epoch:10 step:8032 [D loss: 0.681463, acc.: 57.81%] [G loss: 0.786621]\n",
      "epoch:10 step:8033 [D loss: 0.723177, acc.: 47.66%] [G loss: 0.809790]\n",
      "epoch:10 step:8034 [D loss: 0.718901, acc.: 45.31%] [G loss: 0.711074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8035 [D loss: 0.723458, acc.: 47.66%] [G loss: 0.723894]\n",
      "epoch:10 step:8036 [D loss: 0.656756, acc.: 66.41%] [G loss: 0.773748]\n",
      "epoch:10 step:8037 [D loss: 0.733783, acc.: 45.31%] [G loss: 0.770552]\n",
      "epoch:10 step:8038 [D loss: 0.742936, acc.: 48.44%] [G loss: 0.815978]\n",
      "epoch:10 step:8039 [D loss: 0.751350, acc.: 46.88%] [G loss: 0.756559]\n",
      "epoch:10 step:8040 [D loss: 0.719624, acc.: 50.78%] [G loss: 0.795735]\n",
      "epoch:10 step:8041 [D loss: 0.671252, acc.: 61.72%] [G loss: 0.919889]\n",
      "epoch:10 step:8042 [D loss: 0.702581, acc.: 52.34%] [G loss: 0.808261]\n",
      "epoch:10 step:8043 [D loss: 0.696942, acc.: 57.03%] [G loss: 0.765231]\n",
      "epoch:10 step:8044 [D loss: 0.765022, acc.: 41.41%] [G loss: 0.744646]\n",
      "epoch:10 step:8045 [D loss: 0.714907, acc.: 50.00%] [G loss: 0.809952]\n",
      "epoch:10 step:8046 [D loss: 0.650475, acc.: 60.94%] [G loss: 0.847021]\n",
      "epoch:10 step:8047 [D loss: 0.690854, acc.: 57.03%] [G loss: 0.819961]\n",
      "epoch:10 step:8048 [D loss: 0.730649, acc.: 42.19%] [G loss: 0.792856]\n",
      "epoch:10 step:8049 [D loss: 0.718358, acc.: 52.34%] [G loss: 0.763900]\n",
      "epoch:10 step:8050 [D loss: 0.724369, acc.: 45.31%] [G loss: 0.835681]\n",
      "epoch:10 step:8051 [D loss: 0.691620, acc.: 53.91%] [G loss: 0.770662]\n",
      "epoch:10 step:8052 [D loss: 0.626664, acc.: 67.19%] [G loss: 0.905270]\n",
      "epoch:10 step:8053 [D loss: 0.677128, acc.: 53.12%] [G loss: 0.800251]\n",
      "epoch:10 step:8054 [D loss: 0.680698, acc.: 56.25%] [G loss: 0.740586]\n",
      "epoch:10 step:8055 [D loss: 0.722374, acc.: 42.19%] [G loss: 0.733472]\n",
      "epoch:10 step:8056 [D loss: 0.670369, acc.: 55.47%] [G loss: 0.831475]\n",
      "epoch:10 step:8057 [D loss: 0.622727, acc.: 67.97%] [G loss: 0.934751]\n",
      "epoch:10 step:8058 [D loss: 0.694521, acc.: 57.03%] [G loss: 0.801639]\n",
      "epoch:10 step:8059 [D loss: 0.713874, acc.: 50.78%] [G loss: 0.753259]\n",
      "epoch:10 step:8060 [D loss: 0.694434, acc.: 59.38%] [G loss: 0.705476]\n",
      "epoch:10 step:8061 [D loss: 0.701999, acc.: 56.25%] [G loss: 0.715809]\n",
      "epoch:10 step:8062 [D loss: 0.678329, acc.: 55.47%] [G loss: 0.773453]\n",
      "epoch:10 step:8063 [D loss: 0.663785, acc.: 62.50%] [G loss: 0.740469]\n",
      "epoch:10 step:8064 [D loss: 0.705117, acc.: 49.22%] [G loss: 0.792832]\n",
      "epoch:10 step:8065 [D loss: 0.697939, acc.: 51.56%] [G loss: 0.776963]\n",
      "epoch:10 step:8066 [D loss: 0.739770, acc.: 42.19%] [G loss: 0.687854]\n",
      "epoch:10 step:8067 [D loss: 0.714351, acc.: 46.09%] [G loss: 0.733186]\n",
      "epoch:10 step:8068 [D loss: 0.682259, acc.: 54.69%] [G loss: 0.792341]\n",
      "epoch:10 step:8069 [D loss: 0.712029, acc.: 43.75%] [G loss: 0.737684]\n",
      "epoch:10 step:8070 [D loss: 0.706309, acc.: 52.34%] [G loss: 0.780018]\n",
      "epoch:10 step:8071 [D loss: 0.671102, acc.: 57.03%] [G loss: 0.774437]\n",
      "epoch:10 step:8072 [D loss: 0.725983, acc.: 45.31%] [G loss: 0.756736]\n",
      "epoch:10 step:8073 [D loss: 0.686470, acc.: 57.81%] [G loss: 0.802743]\n",
      "epoch:10 step:8074 [D loss: 0.675941, acc.: 55.47%] [G loss: 0.850191]\n",
      "epoch:10 step:8075 [D loss: 0.711065, acc.: 46.88%] [G loss: 0.773856]\n",
      "epoch:10 step:8076 [D loss: 0.721101, acc.: 46.09%] [G loss: 0.790429]\n",
      "epoch:10 step:8077 [D loss: 0.741816, acc.: 42.97%] [G loss: 0.761049]\n",
      "epoch:10 step:8078 [D loss: 0.652309, acc.: 61.72%] [G loss: 0.816718]\n",
      "epoch:10 step:8079 [D loss: 0.680676, acc.: 52.34%] [G loss: 0.832074]\n",
      "epoch:10 step:8080 [D loss: 0.640628, acc.: 71.09%] [G loss: 0.832911]\n",
      "epoch:10 step:8081 [D loss: 0.717171, acc.: 46.88%] [G loss: 0.819986]\n",
      "epoch:10 step:8082 [D loss: 0.740175, acc.: 45.31%] [G loss: 0.788445]\n",
      "epoch:10 step:8083 [D loss: 0.671739, acc.: 63.28%] [G loss: 0.795054]\n",
      "epoch:10 step:8084 [D loss: 0.768309, acc.: 39.06%] [G loss: 0.733548]\n",
      "epoch:10 step:8085 [D loss: 0.755996, acc.: 43.75%] [G loss: 0.810419]\n",
      "epoch:10 step:8086 [D loss: 0.701381, acc.: 50.00%] [G loss: 0.767088]\n",
      "epoch:10 step:8087 [D loss: 0.863472, acc.: 25.78%] [G loss: 0.744732]\n",
      "epoch:10 step:8088 [D loss: 0.777561, acc.: 37.50%] [G loss: 0.732725]\n",
      "epoch:10 step:8089 [D loss: 0.684131, acc.: 53.12%] [G loss: 0.804855]\n",
      "epoch:10 step:8090 [D loss: 0.686626, acc.: 50.00%] [G loss: 0.848294]\n",
      "epoch:10 step:8091 [D loss: 0.718888, acc.: 46.88%] [G loss: 0.751575]\n",
      "epoch:10 step:8092 [D loss: 0.729948, acc.: 43.75%] [G loss: 0.758057]\n",
      "epoch:10 step:8093 [D loss: 0.709014, acc.: 51.56%] [G loss: 0.689674]\n",
      "epoch:10 step:8094 [D loss: 0.742037, acc.: 42.19%] [G loss: 0.751468]\n",
      "epoch:10 step:8095 [D loss: 0.664840, acc.: 56.25%] [G loss: 0.848532]\n",
      "epoch:10 step:8096 [D loss: 0.708729, acc.: 51.56%] [G loss: 0.828944]\n",
      "epoch:10 step:8097 [D loss: 0.722651, acc.: 46.09%] [G loss: 0.795421]\n",
      "epoch:10 step:8098 [D loss: 0.713293, acc.: 47.66%] [G loss: 0.719451]\n",
      "epoch:10 step:8099 [D loss: 0.676683, acc.: 62.50%] [G loss: 0.843890]\n",
      "epoch:10 step:8100 [D loss: 0.668762, acc.: 57.03%] [G loss: 0.811417]\n",
      "epoch:10 step:8101 [D loss: 0.738726, acc.: 40.62%] [G loss: 0.813685]\n",
      "epoch:10 step:8102 [D loss: 0.687125, acc.: 55.47%] [G loss: 0.764094]\n",
      "epoch:10 step:8103 [D loss: 0.736244, acc.: 45.31%] [G loss: 0.805145]\n",
      "epoch:10 step:8104 [D loss: 0.718222, acc.: 50.78%] [G loss: 0.775365]\n",
      "epoch:10 step:8105 [D loss: 0.682814, acc.: 56.25%] [G loss: 0.777346]\n",
      "epoch:10 step:8106 [D loss: 0.699119, acc.: 50.00%] [G loss: 0.769862]\n",
      "epoch:10 step:8107 [D loss: 0.718944, acc.: 50.00%] [G loss: 0.694440]\n",
      "epoch:10 step:8108 [D loss: 0.680577, acc.: 59.38%] [G loss: 0.744313]\n",
      "epoch:10 step:8109 [D loss: 0.699152, acc.: 52.34%] [G loss: 0.671833]\n",
      "epoch:10 step:8110 [D loss: 0.717414, acc.: 46.09%] [G loss: 0.729331]\n",
      "epoch:10 step:8111 [D loss: 0.730453, acc.: 44.53%] [G loss: 0.773785]\n",
      "epoch:10 step:8112 [D loss: 0.688885, acc.: 53.12%] [G loss: 0.741921]\n",
      "epoch:10 step:8113 [D loss: 0.705098, acc.: 47.66%] [G loss: 0.774450]\n",
      "epoch:10 step:8114 [D loss: 0.721909, acc.: 46.88%] [G loss: 0.777253]\n",
      "epoch:10 step:8115 [D loss: 0.721964, acc.: 50.00%] [G loss: 0.757307]\n",
      "epoch:10 step:8116 [D loss: 0.731628, acc.: 46.88%] [G loss: 0.735625]\n",
      "epoch:10 step:8117 [D loss: 0.716781, acc.: 50.00%] [G loss: 0.764101]\n",
      "epoch:10 step:8118 [D loss: 0.720594, acc.: 47.66%] [G loss: 0.775593]\n",
      "epoch:10 step:8119 [D loss: 0.669859, acc.: 59.38%] [G loss: 0.812780]\n",
      "epoch:10 step:8120 [D loss: 0.681480, acc.: 51.56%] [G loss: 0.799310]\n",
      "epoch:10 step:8121 [D loss: 0.714084, acc.: 48.44%] [G loss: 0.755863]\n",
      "epoch:10 step:8122 [D loss: 0.711277, acc.: 47.66%] [G loss: 0.803164]\n",
      "epoch:10 step:8123 [D loss: 0.703197, acc.: 52.34%] [G loss: 0.747941]\n",
      "epoch:10 step:8124 [D loss: 0.770088, acc.: 32.03%] [G loss: 0.786689]\n",
      "epoch:10 step:8125 [D loss: 0.704890, acc.: 53.12%] [G loss: 0.749924]\n",
      "epoch:10 step:8126 [D loss: 0.713537, acc.: 47.66%] [G loss: 0.692462]\n",
      "epoch:10 step:8127 [D loss: 0.765122, acc.: 36.72%] [G loss: 0.704452]\n",
      "epoch:10 step:8128 [D loss: 0.698348, acc.: 48.44%] [G loss: 0.767922]\n",
      "epoch:10 step:8129 [D loss: 0.690715, acc.: 53.91%] [G loss: 0.703316]\n",
      "epoch:10 step:8130 [D loss: 0.705940, acc.: 56.25%] [G loss: 0.694079]\n",
      "epoch:10 step:8131 [D loss: 0.680985, acc.: 51.56%] [G loss: 0.761799]\n",
      "epoch:10 step:8132 [D loss: 0.730715, acc.: 47.66%] [G loss: 0.795923]\n",
      "epoch:10 step:8133 [D loss: 0.675045, acc.: 56.25%] [G loss: 0.802682]\n",
      "epoch:10 step:8134 [D loss: 0.671106, acc.: 64.06%] [G loss: 0.806976]\n",
      "epoch:10 step:8135 [D loss: 0.736109, acc.: 40.62%] [G loss: 0.797526]\n",
      "epoch:10 step:8136 [D loss: 0.699878, acc.: 48.44%] [G loss: 0.830247]\n",
      "epoch:10 step:8137 [D loss: 0.651923, acc.: 60.16%] [G loss: 0.826832]\n",
      "epoch:10 step:8138 [D loss: 0.694538, acc.: 57.81%] [G loss: 0.777001]\n",
      "epoch:10 step:8139 [D loss: 0.679727, acc.: 57.03%] [G loss: 0.785318]\n",
      "epoch:10 step:8140 [D loss: 0.704158, acc.: 49.22%] [G loss: 0.755999]\n",
      "epoch:10 step:8141 [D loss: 0.696436, acc.: 53.12%] [G loss: 0.752464]\n",
      "epoch:10 step:8142 [D loss: 0.648244, acc.: 66.41%] [G loss: 0.854465]\n",
      "epoch:10 step:8143 [D loss: 0.664074, acc.: 62.50%] [G loss: 0.848548]\n",
      "epoch:10 step:8144 [D loss: 0.648115, acc.: 67.19%] [G loss: 0.837633]\n",
      "epoch:10 step:8145 [D loss: 0.673587, acc.: 64.06%] [G loss: 0.807246]\n",
      "epoch:10 step:8146 [D loss: 0.710369, acc.: 46.88%] [G loss: 0.754917]\n",
      "epoch:10 step:8147 [D loss: 0.666109, acc.: 57.81%] [G loss: 0.738633]\n",
      "epoch:10 step:8148 [D loss: 0.752063, acc.: 39.06%] [G loss: 0.757204]\n",
      "epoch:10 step:8149 [D loss: 0.689308, acc.: 52.34%] [G loss: 0.765461]\n",
      "epoch:10 step:8150 [D loss: 0.683811, acc.: 50.78%] [G loss: 0.753187]\n",
      "epoch:10 step:8151 [D loss: 0.709658, acc.: 46.09%] [G loss: 0.797394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8152 [D loss: 0.768434, acc.: 36.72%] [G loss: 0.738754]\n",
      "epoch:10 step:8153 [D loss: 0.752087, acc.: 39.06%] [G loss: 0.677955]\n",
      "epoch:10 step:8154 [D loss: 0.711294, acc.: 45.31%] [G loss: 0.727749]\n",
      "epoch:10 step:8155 [D loss: 0.711126, acc.: 45.31%] [G loss: 0.789890]\n",
      "epoch:10 step:8156 [D loss: 0.698389, acc.: 55.47%] [G loss: 0.742582]\n",
      "epoch:10 step:8157 [D loss: 0.720155, acc.: 45.31%] [G loss: 0.777285]\n",
      "epoch:10 step:8158 [D loss: 0.720708, acc.: 45.31%] [G loss: 0.727554]\n",
      "epoch:10 step:8159 [D loss: 0.694262, acc.: 50.78%] [G loss: 0.784254]\n",
      "epoch:10 step:8160 [D loss: 0.709058, acc.: 52.34%] [G loss: 0.784341]\n",
      "epoch:10 step:8161 [D loss: 0.667381, acc.: 58.59%] [G loss: 0.803426]\n",
      "epoch:10 step:8162 [D loss: 0.639868, acc.: 70.31%] [G loss: 0.751437]\n",
      "epoch:10 step:8163 [D loss: 0.719614, acc.: 45.31%] [G loss: 0.723835]\n",
      "epoch:10 step:8164 [D loss: 0.706138, acc.: 46.88%] [G loss: 0.742497]\n",
      "epoch:10 step:8165 [D loss: 0.779382, acc.: 35.16%] [G loss: 0.681024]\n",
      "epoch:10 step:8166 [D loss: 0.659250, acc.: 59.38%] [G loss: 0.796520]\n",
      "epoch:10 step:8167 [D loss: 0.691558, acc.: 55.47%] [G loss: 0.759471]\n",
      "epoch:10 step:8168 [D loss: 0.684416, acc.: 55.47%] [G loss: 0.783921]\n",
      "epoch:10 step:8169 [D loss: 0.644350, acc.: 69.53%] [G loss: 0.897697]\n",
      "epoch:10 step:8170 [D loss: 0.648829, acc.: 71.88%] [G loss: 0.833035]\n",
      "epoch:10 step:8171 [D loss: 0.640483, acc.: 65.62%] [G loss: 0.832934]\n",
      "epoch:10 step:8172 [D loss: 0.646496, acc.: 64.84%] [G loss: 0.761959]\n",
      "epoch:10 step:8173 [D loss: 0.655289, acc.: 65.62%] [G loss: 0.847582]\n",
      "epoch:10 step:8174 [D loss: 0.691837, acc.: 50.78%] [G loss: 0.751169]\n",
      "epoch:10 step:8175 [D loss: 0.638788, acc.: 62.50%] [G loss: 0.725207]\n",
      "epoch:10 step:8176 [D loss: 0.664855, acc.: 62.50%] [G loss: 0.745393]\n",
      "epoch:10 step:8177 [D loss: 0.693335, acc.: 57.03%] [G loss: 0.665893]\n",
      "epoch:10 step:8178 [D loss: 0.697453, acc.: 49.22%] [G loss: 0.704207]\n",
      "epoch:10 step:8179 [D loss: 0.647805, acc.: 61.72%] [G loss: 0.668853]\n",
      "epoch:10 step:8180 [D loss: 0.736344, acc.: 57.81%] [G loss: 0.716717]\n",
      "epoch:10 step:8181 [D loss: 0.681004, acc.: 57.81%] [G loss: 0.766951]\n",
      "epoch:10 step:8182 [D loss: 0.681392, acc.: 53.91%] [G loss: 0.794492]\n",
      "epoch:10 step:8183 [D loss: 0.788922, acc.: 32.81%] [G loss: 0.792412]\n",
      "epoch:10 step:8184 [D loss: 0.701686, acc.: 53.12%] [G loss: 0.793929]\n",
      "epoch:10 step:8185 [D loss: 0.715421, acc.: 42.19%] [G loss: 0.754773]\n",
      "epoch:10 step:8186 [D loss: 0.667708, acc.: 57.81%] [G loss: 0.757281]\n",
      "epoch:10 step:8187 [D loss: 0.770383, acc.: 39.84%] [G loss: 0.815346]\n",
      "epoch:10 step:8188 [D loss: 0.658790, acc.: 59.38%] [G loss: 0.773493]\n",
      "epoch:10 step:8189 [D loss: 0.714902, acc.: 50.78%] [G loss: 0.753639]\n",
      "epoch:10 step:8190 [D loss: 0.685068, acc.: 55.47%] [G loss: 0.872432]\n",
      "epoch:10 step:8191 [D loss: 0.660040, acc.: 61.72%] [G loss: 0.802925]\n",
      "epoch:10 step:8192 [D loss: 0.731882, acc.: 53.12%] [G loss: 0.777431]\n",
      "epoch:10 step:8193 [D loss: 0.627068, acc.: 67.97%] [G loss: 0.848786]\n",
      "epoch:10 step:8194 [D loss: 0.691616, acc.: 53.12%] [G loss: 0.784784]\n",
      "epoch:10 step:8195 [D loss: 0.688490, acc.: 53.12%] [G loss: 0.844572]\n",
      "epoch:10 step:8196 [D loss: 0.631653, acc.: 67.19%] [G loss: 0.819659]\n",
      "epoch:10 step:8197 [D loss: 0.650795, acc.: 68.75%] [G loss: 0.819040]\n",
      "epoch:10 step:8198 [D loss: 0.780332, acc.: 32.03%] [G loss: 0.750764]\n",
      "epoch:10 step:8199 [D loss: 0.713561, acc.: 42.19%] [G loss: 0.875226]\n",
      "epoch:10 step:8200 [D loss: 0.679903, acc.: 58.59%] [G loss: 0.772717]\n",
      "epoch:10 step:8201 [D loss: 0.768449, acc.: 40.62%] [G loss: 0.715678]\n",
      "epoch:10 step:8202 [D loss: 0.742139, acc.: 45.31%] [G loss: 0.733103]\n",
      "epoch:10 step:8203 [D loss: 0.658745, acc.: 60.16%] [G loss: 0.741548]\n",
      "epoch:10 step:8204 [D loss: 0.751158, acc.: 42.19%] [G loss: 0.741746]\n",
      "epoch:10 step:8205 [D loss: 0.690667, acc.: 51.56%] [G loss: 0.841819]\n",
      "epoch:10 step:8206 [D loss: 0.734573, acc.: 41.41%] [G loss: 0.761637]\n",
      "epoch:10 step:8207 [D loss: 0.672114, acc.: 60.94%] [G loss: 0.811359]\n",
      "epoch:10 step:8208 [D loss: 0.707890, acc.: 51.56%] [G loss: 0.828565]\n",
      "epoch:10 step:8209 [D loss: 0.670596, acc.: 57.81%] [G loss: 0.802274]\n",
      "epoch:10 step:8210 [D loss: 0.714048, acc.: 51.56%] [G loss: 0.810476]\n",
      "epoch:10 step:8211 [D loss: 0.693087, acc.: 53.12%] [G loss: 0.774310]\n",
      "epoch:10 step:8212 [D loss: 0.691871, acc.: 53.12%] [G loss: 0.750470]\n",
      "epoch:10 step:8213 [D loss: 0.686479, acc.: 53.12%] [G loss: 0.748649]\n",
      "epoch:10 step:8214 [D loss: 0.692552, acc.: 51.56%] [G loss: 0.734148]\n",
      "epoch:10 step:8215 [D loss: 0.680644, acc.: 59.38%] [G loss: 0.790091]\n",
      "epoch:10 step:8216 [D loss: 0.660393, acc.: 64.84%] [G loss: 0.755246]\n",
      "epoch:10 step:8217 [D loss: 0.740504, acc.: 40.62%] [G loss: 0.732345]\n",
      "epoch:10 step:8218 [D loss: 0.705235, acc.: 51.56%] [G loss: 0.811089]\n",
      "epoch:10 step:8219 [D loss: 0.727856, acc.: 47.66%] [G loss: 0.763886]\n",
      "epoch:10 step:8220 [D loss: 0.675230, acc.: 57.03%] [G loss: 0.742001]\n",
      "epoch:10 step:8221 [D loss: 0.763421, acc.: 45.31%] [G loss: 0.766419]\n",
      "epoch:10 step:8222 [D loss: 0.689952, acc.: 52.34%] [G loss: 0.789808]\n",
      "epoch:10 step:8223 [D loss: 0.682320, acc.: 59.38%] [G loss: 0.767828]\n",
      "epoch:10 step:8224 [D loss: 0.719296, acc.: 51.56%] [G loss: 0.711006]\n",
      "epoch:10 step:8225 [D loss: 0.728699, acc.: 44.53%] [G loss: 0.753214]\n",
      "epoch:10 step:8226 [D loss: 0.676613, acc.: 60.16%] [G loss: 0.849447]\n",
      "epoch:10 step:8227 [D loss: 0.698676, acc.: 53.12%] [G loss: 0.840943]\n",
      "epoch:10 step:8228 [D loss: 0.646988, acc.: 64.84%] [G loss: 0.881892]\n",
      "epoch:10 step:8229 [D loss: 0.687638, acc.: 46.88%] [G loss: 0.858439]\n",
      "epoch:10 step:8230 [D loss: 0.667562, acc.: 61.72%] [G loss: 0.827580]\n",
      "epoch:10 step:8231 [D loss: 0.672156, acc.: 58.59%] [G loss: 0.771726]\n",
      "epoch:10 step:8232 [D loss: 0.689670, acc.: 57.03%] [G loss: 0.835570]\n",
      "epoch:10 step:8233 [D loss: 0.665931, acc.: 65.62%] [G loss: 0.797392]\n",
      "epoch:10 step:8234 [D loss: 0.691957, acc.: 51.56%] [G loss: 0.827427]\n",
      "epoch:10 step:8235 [D loss: 0.652514, acc.: 60.94%] [G loss: 0.854793]\n",
      "epoch:10 step:8236 [D loss: 0.693418, acc.: 54.69%] [G loss: 0.732698]\n",
      "epoch:10 step:8237 [D loss: 0.660166, acc.: 63.28%] [G loss: 0.730782]\n",
      "epoch:10 step:8238 [D loss: 0.700657, acc.: 53.12%] [G loss: 0.756666]\n",
      "epoch:10 step:8239 [D loss: 0.620203, acc.: 68.75%] [G loss: 0.695757]\n",
      "epoch:10 step:8240 [D loss: 0.697637, acc.: 53.12%] [G loss: 0.769317]\n",
      "epoch:10 step:8241 [D loss: 0.692867, acc.: 51.56%] [G loss: 0.790213]\n",
      "epoch:10 step:8242 [D loss: 0.691312, acc.: 54.69%] [G loss: 0.768291]\n",
      "epoch:10 step:8243 [D loss: 0.711082, acc.: 50.78%] [G loss: 0.778382]\n",
      "epoch:10 step:8244 [D loss: 0.733967, acc.: 38.28%] [G loss: 0.744499]\n",
      "epoch:10 step:8245 [D loss: 0.714515, acc.: 49.22%] [G loss: 0.801759]\n",
      "epoch:10 step:8246 [D loss: 0.738417, acc.: 42.97%] [G loss: 0.777906]\n",
      "epoch:10 step:8247 [D loss: 0.749367, acc.: 45.31%] [G loss: 0.807959]\n",
      "epoch:10 step:8248 [D loss: 0.712321, acc.: 45.31%] [G loss: 0.746183]\n",
      "epoch:10 step:8249 [D loss: 0.701676, acc.: 47.66%] [G loss: 0.763886]\n",
      "epoch:10 step:8250 [D loss: 0.731296, acc.: 42.97%] [G loss: 0.752949]\n",
      "epoch:10 step:8251 [D loss: 0.776600, acc.: 32.81%] [G loss: 0.730065]\n",
      "epoch:10 step:8252 [D loss: 0.686737, acc.: 53.12%] [G loss: 0.745395]\n",
      "epoch:10 step:8253 [D loss: 0.738108, acc.: 40.62%] [G loss: 0.728165]\n",
      "epoch:10 step:8254 [D loss: 0.693620, acc.: 53.12%] [G loss: 0.844045]\n",
      "epoch:10 step:8255 [D loss: 0.707909, acc.: 50.00%] [G loss: 0.781915]\n",
      "epoch:10 step:8256 [D loss: 0.712282, acc.: 50.78%] [G loss: 0.740805]\n",
      "epoch:10 step:8257 [D loss: 0.689373, acc.: 59.38%] [G loss: 0.771657]\n",
      "epoch:10 step:8258 [D loss: 0.704470, acc.: 50.78%] [G loss: 0.757476]\n",
      "epoch:10 step:8259 [D loss: 0.703878, acc.: 52.34%] [G loss: 0.746928]\n",
      "epoch:10 step:8260 [D loss: 0.655405, acc.: 60.16%] [G loss: 0.797062]\n",
      "epoch:10 step:8261 [D loss: 0.686611, acc.: 51.56%] [G loss: 0.786818]\n",
      "epoch:10 step:8262 [D loss: 0.675653, acc.: 57.03%] [G loss: 0.822014]\n",
      "epoch:10 step:8263 [D loss: 0.698864, acc.: 49.22%] [G loss: 0.844084]\n",
      "epoch:10 step:8264 [D loss: 0.682275, acc.: 57.81%] [G loss: 0.800317]\n",
      "epoch:10 step:8265 [D loss: 0.652097, acc.: 57.81%] [G loss: 0.816617]\n",
      "epoch:10 step:8266 [D loss: 0.690210, acc.: 57.03%] [G loss: 0.790910]\n",
      "epoch:10 step:8267 [D loss: 0.664617, acc.: 57.03%] [G loss: 0.777712]\n",
      "epoch:10 step:8268 [D loss: 0.700520, acc.: 53.12%] [G loss: 0.749459]\n",
      "epoch:10 step:8269 [D loss: 0.697908, acc.: 54.69%] [G loss: 0.743478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8270 [D loss: 0.674766, acc.: 61.72%] [G loss: 0.752410]\n",
      "epoch:10 step:8271 [D loss: 0.642594, acc.: 66.41%] [G loss: 0.769608]\n",
      "epoch:10 step:8272 [D loss: 0.717972, acc.: 46.09%] [G loss: 0.733409]\n",
      "epoch:10 step:8273 [D loss: 0.744933, acc.: 49.22%] [G loss: 0.707240]\n",
      "epoch:10 step:8274 [D loss: 0.670881, acc.: 59.38%] [G loss: 0.755008]\n",
      "epoch:10 step:8275 [D loss: 0.641633, acc.: 65.62%] [G loss: 0.764588]\n",
      "epoch:10 step:8276 [D loss: 0.660927, acc.: 59.38%] [G loss: 0.768419]\n",
      "epoch:10 step:8277 [D loss: 0.714440, acc.: 53.91%] [G loss: 0.762987]\n",
      "epoch:10 step:8278 [D loss: 0.674472, acc.: 58.59%] [G loss: 0.770123]\n",
      "epoch:10 step:8279 [D loss: 0.741240, acc.: 46.09%] [G loss: 0.817747]\n",
      "epoch:10 step:8280 [D loss: 0.692263, acc.: 54.69%] [G loss: 0.746058]\n",
      "epoch:10 step:8281 [D loss: 0.700012, acc.: 53.91%] [G loss: 0.731778]\n",
      "epoch:10 step:8282 [D loss: 0.759442, acc.: 39.06%] [G loss: 0.789422]\n",
      "epoch:10 step:8283 [D loss: 0.810992, acc.: 36.72%] [G loss: 0.725298]\n",
      "epoch:10 step:8284 [D loss: 0.730113, acc.: 42.97%] [G loss: 0.842993]\n",
      "epoch:10 step:8285 [D loss: 0.666891, acc.: 54.69%] [G loss: 0.808940]\n",
      "epoch:10 step:8286 [D loss: 0.687593, acc.: 53.12%] [G loss: 0.824226]\n",
      "epoch:10 step:8287 [D loss: 0.620596, acc.: 67.97%] [G loss: 0.831578]\n",
      "epoch:10 step:8288 [D loss: 0.701879, acc.: 53.91%] [G loss: 0.750259]\n",
      "epoch:10 step:8289 [D loss: 0.656124, acc.: 60.94%] [G loss: 0.780177]\n",
      "epoch:10 step:8290 [D loss: 0.730410, acc.: 45.31%] [G loss: 0.791924]\n",
      "epoch:10 step:8291 [D loss: 0.736748, acc.: 46.09%] [G loss: 0.717184]\n",
      "epoch:10 step:8292 [D loss: 0.701265, acc.: 56.25%] [G loss: 0.720517]\n",
      "epoch:10 step:8293 [D loss: 0.792188, acc.: 35.94%] [G loss: 0.749815]\n",
      "epoch:10 step:8294 [D loss: 0.699778, acc.: 53.91%] [G loss: 0.759590]\n",
      "epoch:10 step:8295 [D loss: 0.663574, acc.: 65.62%] [G loss: 0.716236]\n",
      "epoch:10 step:8296 [D loss: 0.670049, acc.: 57.81%] [G loss: 0.781349]\n",
      "epoch:10 step:8297 [D loss: 0.702404, acc.: 53.91%] [G loss: 0.785137]\n",
      "epoch:10 step:8298 [D loss: 0.696842, acc.: 50.78%] [G loss: 0.726705]\n",
      "epoch:10 step:8299 [D loss: 0.693049, acc.: 52.34%] [G loss: 0.760772]\n",
      "epoch:10 step:8300 [D loss: 0.715232, acc.: 50.78%] [G loss: 0.717135]\n",
      "epoch:10 step:8301 [D loss: 0.708106, acc.: 52.34%] [G loss: 0.708195]\n",
      "epoch:10 step:8302 [D loss: 0.742584, acc.: 40.62%] [G loss: 0.732975]\n",
      "epoch:10 step:8303 [D loss: 0.673480, acc.: 58.59%] [G loss: 0.746053]\n",
      "epoch:10 step:8304 [D loss: 0.719137, acc.: 45.31%] [G loss: 0.795146]\n",
      "epoch:10 step:8305 [D loss: 0.704086, acc.: 56.25%] [G loss: 0.787048]\n",
      "epoch:10 step:8306 [D loss: 0.674734, acc.: 58.59%] [G loss: 0.822228]\n",
      "epoch:10 step:8307 [D loss: 0.661601, acc.: 60.94%] [G loss: 0.838045]\n",
      "epoch:10 step:8308 [D loss: 0.705900, acc.: 53.91%] [G loss: 0.760576]\n",
      "epoch:10 step:8309 [D loss: 0.659729, acc.: 63.28%] [G loss: 0.766642]\n",
      "epoch:10 step:8310 [D loss: 0.701121, acc.: 48.44%] [G loss: 0.753089]\n",
      "epoch:10 step:8311 [D loss: 0.681490, acc.: 57.81%] [G loss: 0.795128]\n",
      "epoch:10 step:8312 [D loss: 0.680976, acc.: 53.91%] [G loss: 0.815853]\n",
      "epoch:10 step:8313 [D loss: 0.674868, acc.: 55.47%] [G loss: 0.839381]\n",
      "epoch:10 step:8314 [D loss: 0.677881, acc.: 53.12%] [G loss: 0.803113]\n",
      "epoch:10 step:8315 [D loss: 0.680867, acc.: 60.16%] [G loss: 0.831186]\n",
      "epoch:10 step:8316 [D loss: 0.705983, acc.: 49.22%] [G loss: 0.826324]\n",
      "epoch:10 step:8317 [D loss: 0.651006, acc.: 62.50%] [G loss: 0.787552]\n",
      "epoch:10 step:8318 [D loss: 0.671747, acc.: 60.16%] [G loss: 0.737699]\n",
      "epoch:10 step:8319 [D loss: 0.729273, acc.: 42.97%] [G loss: 0.712508]\n",
      "epoch:10 step:8320 [D loss: 0.689810, acc.: 52.34%] [G loss: 0.706564]\n",
      "epoch:10 step:8321 [D loss: 0.688685, acc.: 55.47%] [G loss: 0.724383]\n",
      "epoch:10 step:8322 [D loss: 0.741302, acc.: 42.19%] [G loss: 0.821019]\n",
      "epoch:10 step:8323 [D loss: 0.722323, acc.: 48.44%] [G loss: 0.782152]\n",
      "epoch:10 step:8324 [D loss: 0.722770, acc.: 46.88%] [G loss: 0.705569]\n",
      "epoch:10 step:8325 [D loss: 0.687610, acc.: 47.66%] [G loss: 0.732435]\n",
      "epoch:10 step:8326 [D loss: 0.654854, acc.: 64.84%] [G loss: 0.763928]\n",
      "epoch:10 step:8327 [D loss: 0.712847, acc.: 55.47%] [G loss: 0.731972]\n",
      "epoch:10 step:8328 [D loss: 0.633072, acc.: 64.84%] [G loss: 0.807916]\n",
      "epoch:10 step:8329 [D loss: 0.719005, acc.: 44.53%] [G loss: 0.782851]\n",
      "epoch:10 step:8330 [D loss: 0.711632, acc.: 46.88%] [G loss: 0.819490]\n",
      "epoch:10 step:8331 [D loss: 0.676118, acc.: 59.38%] [G loss: 0.768373]\n",
      "epoch:10 step:8332 [D loss: 0.705492, acc.: 51.56%] [G loss: 0.856029]\n",
      "epoch:10 step:8333 [D loss: 0.700589, acc.: 49.22%] [G loss: 0.765399]\n",
      "epoch:10 step:8334 [D loss: 0.687959, acc.: 58.59%] [G loss: 0.733438]\n",
      "epoch:10 step:8335 [D loss: 0.712652, acc.: 48.44%] [G loss: 0.706332]\n",
      "epoch:10 step:8336 [D loss: 0.813196, acc.: 37.50%] [G loss: 0.718294]\n",
      "epoch:10 step:8337 [D loss: 0.703923, acc.: 52.34%] [G loss: 0.654260]\n",
      "epoch:10 step:8338 [D loss: 0.702740, acc.: 53.91%] [G loss: 0.688607]\n",
      "epoch:10 step:8339 [D loss: 0.677855, acc.: 60.94%] [G loss: 0.674455]\n",
      "epoch:10 step:8340 [D loss: 0.674934, acc.: 54.69%] [G loss: 0.679389]\n",
      "epoch:10 step:8341 [D loss: 0.758236, acc.: 40.62%] [G loss: 0.708951]\n",
      "epoch:10 step:8342 [D loss: 0.713414, acc.: 48.44%] [G loss: 0.844108]\n",
      "epoch:10 step:8343 [D loss: 0.684690, acc.: 50.78%] [G loss: 0.745542]\n",
      "epoch:10 step:8344 [D loss: 0.674586, acc.: 55.47%] [G loss: 0.802278]\n",
      "epoch:10 step:8345 [D loss: 0.751646, acc.: 41.41%] [G loss: 0.843295]\n",
      "epoch:10 step:8346 [D loss: 0.657297, acc.: 56.25%] [G loss: 0.824698]\n",
      "epoch:10 step:8347 [D loss: 0.755093, acc.: 39.06%] [G loss: 0.811816]\n",
      "epoch:10 step:8348 [D loss: 0.650336, acc.: 67.19%] [G loss: 0.783423]\n",
      "epoch:10 step:8349 [D loss: 0.694290, acc.: 50.78%] [G loss: 0.771280]\n",
      "epoch:10 step:8350 [D loss: 0.700914, acc.: 50.00%] [G loss: 0.767785]\n",
      "epoch:10 step:8351 [D loss: 0.698099, acc.: 57.81%] [G loss: 0.869638]\n",
      "epoch:10 step:8352 [D loss: 0.669893, acc.: 60.16%] [G loss: 0.840715]\n",
      "epoch:10 step:8353 [D loss: 0.653581, acc.: 64.06%] [G loss: 0.788787]\n",
      "epoch:10 step:8354 [D loss: 0.689507, acc.: 50.00%] [G loss: 0.831312]\n",
      "epoch:10 step:8355 [D loss: 0.650848, acc.: 66.41%] [G loss: 0.813639]\n",
      "epoch:10 step:8356 [D loss: 0.728576, acc.: 49.22%] [G loss: 0.746431]\n",
      "epoch:10 step:8357 [D loss: 0.645895, acc.: 63.28%] [G loss: 0.763320]\n",
      "epoch:10 step:8358 [D loss: 0.693426, acc.: 46.88%] [G loss: 0.756441]\n",
      "epoch:10 step:8359 [D loss: 0.677550, acc.: 57.03%] [G loss: 0.739162]\n",
      "epoch:10 step:8360 [D loss: 0.657642, acc.: 57.81%] [G loss: 0.695700]\n",
      "epoch:10 step:8361 [D loss: 0.639307, acc.: 65.62%] [G loss: 0.708534]\n",
      "epoch:10 step:8362 [D loss: 0.666425, acc.: 58.59%] [G loss: 0.758503]\n",
      "epoch:10 step:8363 [D loss: 0.762041, acc.: 38.28%] [G loss: 0.701354]\n",
      "epoch:10 step:8364 [D loss: 0.670358, acc.: 64.06%] [G loss: 0.741595]\n",
      "epoch:10 step:8365 [D loss: 0.672256, acc.: 52.34%] [G loss: 0.820032]\n",
      "epoch:10 step:8366 [D loss: 0.747750, acc.: 32.81%] [G loss: 0.796203]\n",
      "epoch:10 step:8367 [D loss: 0.732557, acc.: 44.53%] [G loss: 0.719578]\n",
      "epoch:10 step:8368 [D loss: 0.682597, acc.: 50.00%] [G loss: 0.692624]\n",
      "epoch:10 step:8369 [D loss: 0.667114, acc.: 54.69%] [G loss: 0.698287]\n",
      "epoch:10 step:8370 [D loss: 0.729596, acc.: 41.41%] [G loss: 0.702628]\n",
      "epoch:10 step:8371 [D loss: 0.738787, acc.: 44.53%] [G loss: 0.655310]\n",
      "epoch:10 step:8372 [D loss: 0.738275, acc.: 45.31%] [G loss: 0.733434]\n",
      "epoch:10 step:8373 [D loss: 0.743949, acc.: 42.97%] [G loss: 0.748658]\n",
      "epoch:10 step:8374 [D loss: 0.760866, acc.: 34.38%] [G loss: 0.784330]\n",
      "epoch:10 step:8375 [D loss: 0.697843, acc.: 51.56%] [G loss: 0.833634]\n",
      "epoch:10 step:8376 [D loss: 0.737271, acc.: 42.19%] [G loss: 0.785046]\n",
      "epoch:10 step:8377 [D loss: 0.685679, acc.: 55.47%] [G loss: 0.793942]\n",
      "epoch:10 step:8378 [D loss: 0.657245, acc.: 59.38%] [G loss: 0.815966]\n",
      "epoch:10 step:8379 [D loss: 0.644199, acc.: 67.19%] [G loss: 0.917096]\n",
      "epoch:10 step:8380 [D loss: 0.621663, acc.: 68.75%] [G loss: 0.867438]\n",
      "epoch:10 step:8381 [D loss: 0.702317, acc.: 50.78%] [G loss: 0.743036]\n",
      "epoch:10 step:8382 [D loss: 0.651058, acc.: 62.50%] [G loss: 0.865046]\n",
      "epoch:10 step:8383 [D loss: 0.640703, acc.: 65.62%] [G loss: 0.846574]\n",
      "epoch:10 step:8384 [D loss: 0.635688, acc.: 71.09%] [G loss: 0.760030]\n",
      "epoch:10 step:8385 [D loss: 0.662366, acc.: 63.28%] [G loss: 0.812707]\n",
      "epoch:10 step:8386 [D loss: 0.629015, acc.: 67.19%] [G loss: 0.749687]\n",
      "epoch:10 step:8387 [D loss: 0.643206, acc.: 67.19%] [G loss: 0.754959]\n",
      "epoch:10 step:8388 [D loss: 0.646640, acc.: 64.06%] [G loss: 0.762156]\n",
      "epoch:10 step:8389 [D loss: 0.633735, acc.: 70.31%] [G loss: 0.787077]\n",
      "epoch:10 step:8390 [D loss: 0.637482, acc.: 64.06%] [G loss: 0.705299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8391 [D loss: 0.683473, acc.: 55.47%] [G loss: 0.673303]\n",
      "epoch:10 step:8392 [D loss: 0.672298, acc.: 59.38%] [G loss: 0.691037]\n",
      "epoch:10 step:8393 [D loss: 0.730772, acc.: 46.09%] [G loss: 0.669527]\n",
      "epoch:10 step:8394 [D loss: 0.631599, acc.: 64.06%] [G loss: 0.715518]\n",
      "epoch:10 step:8395 [D loss: 0.700232, acc.: 49.22%] [G loss: 0.729450]\n",
      "epoch:10 step:8396 [D loss: 0.667899, acc.: 60.16%] [G loss: 0.762834]\n",
      "epoch:10 step:8397 [D loss: 0.655614, acc.: 60.16%] [G loss: 0.750227]\n",
      "epoch:10 step:8398 [D loss: 0.648330, acc.: 66.41%] [G loss: 0.762153]\n",
      "epoch:10 step:8399 [D loss: 0.713146, acc.: 51.56%] [G loss: 0.682928]\n",
      "epoch:10 step:8400 [D loss: 0.689494, acc.: 51.56%] [G loss: 0.710168]\n",
      "epoch:10 step:8401 [D loss: 0.749249, acc.: 39.84%] [G loss: 0.735219]\n",
      "epoch:10 step:8402 [D loss: 0.761779, acc.: 38.28%] [G loss: 0.843085]\n",
      "epoch:10 step:8403 [D loss: 0.760328, acc.: 35.94%] [G loss: 0.764223]\n",
      "epoch:10 step:8404 [D loss: 0.728619, acc.: 39.84%] [G loss: 0.753099]\n",
      "epoch:10 step:8405 [D loss: 0.692543, acc.: 50.00%] [G loss: 0.749848]\n",
      "epoch:10 step:8406 [D loss: 0.704706, acc.: 50.78%] [G loss: 0.800746]\n",
      "epoch:10 step:8407 [D loss: 0.715445, acc.: 46.09%] [G loss: 0.793993]\n",
      "epoch:10 step:8408 [D loss: 0.680871, acc.: 61.72%] [G loss: 0.821525]\n",
      "epoch:10 step:8409 [D loss: 0.657332, acc.: 64.06%] [G loss: 0.841115]\n",
      "epoch:10 step:8410 [D loss: 0.690172, acc.: 54.69%] [G loss: 0.822986]\n",
      "epoch:10 step:8411 [D loss: 0.666110, acc.: 57.81%] [G loss: 0.787242]\n",
      "epoch:10 step:8412 [D loss: 0.703623, acc.: 53.12%] [G loss: 0.784897]\n",
      "epoch:10 step:8413 [D loss: 0.634994, acc.: 64.06%] [G loss: 0.875261]\n",
      "epoch:10 step:8414 [D loss: 0.625277, acc.: 69.53%] [G loss: 0.849087]\n",
      "epoch:10 step:8415 [D loss: 0.672984, acc.: 63.28%] [G loss: 0.799992]\n",
      "epoch:10 step:8416 [D loss: 0.648522, acc.: 63.28%] [G loss: 0.799478]\n",
      "epoch:10 step:8417 [D loss: 0.689448, acc.: 57.81%] [G loss: 0.772979]\n",
      "epoch:10 step:8418 [D loss: 0.676383, acc.: 53.91%] [G loss: 0.673328]\n",
      "epoch:10 step:8419 [D loss: 0.680177, acc.: 58.59%] [G loss: 0.707251]\n",
      "epoch:10 step:8420 [D loss: 0.700857, acc.: 54.69%] [G loss: 0.732258]\n",
      "epoch:10 step:8421 [D loss: 0.690565, acc.: 49.22%] [G loss: 0.786999]\n",
      "epoch:10 step:8422 [D loss: 0.697024, acc.: 50.78%] [G loss: 0.779058]\n",
      "epoch:10 step:8423 [D loss: 0.706018, acc.: 44.53%] [G loss: 0.761495]\n",
      "epoch:10 step:8424 [D loss: 0.731941, acc.: 48.44%] [G loss: 0.727333]\n",
      "epoch:10 step:8425 [D loss: 0.664143, acc.: 57.81%] [G loss: 0.746518]\n",
      "epoch:10 step:8426 [D loss: 0.682378, acc.: 50.78%] [G loss: 0.827587]\n",
      "epoch:10 step:8427 [D loss: 0.718570, acc.: 50.00%] [G loss: 0.781539]\n",
      "epoch:10 step:8428 [D loss: 0.703476, acc.: 52.34%] [G loss: 0.718801]\n",
      "epoch:10 step:8429 [D loss: 0.663822, acc.: 56.25%] [G loss: 0.803052]\n",
      "epoch:10 step:8430 [D loss: 0.677011, acc.: 57.81%] [G loss: 0.832378]\n",
      "epoch:10 step:8431 [D loss: 0.706492, acc.: 52.34%] [G loss: 0.764097]\n",
      "epoch:10 step:8432 [D loss: 0.683100, acc.: 51.56%] [G loss: 0.815462]\n",
      "epoch:10 step:8433 [D loss: 0.698688, acc.: 49.22%] [G loss: 0.703741]\n",
      "epoch:10 step:8434 [D loss: 0.705719, acc.: 56.25%] [G loss: 0.814134]\n",
      "epoch:10 step:8435 [D loss: 0.699768, acc.: 52.34%] [G loss: 0.774163]\n",
      "epoch:10 step:8436 [D loss: 0.787836, acc.: 35.94%] [G loss: 0.681395]\n",
      "epoch:10 step:8437 [D loss: 0.697008, acc.: 57.03%] [G loss: 0.790458]\n",
      "epoch:10 step:8438 [D loss: 0.702158, acc.: 50.00%] [G loss: 0.887934]\n",
      "epoch:10 step:8439 [D loss: 0.693335, acc.: 58.59%] [G loss: 0.800925]\n",
      "epoch:10 step:8440 [D loss: 0.726212, acc.: 47.66%] [G loss: 0.817030]\n",
      "epoch:10 step:8441 [D loss: 0.721361, acc.: 46.09%] [G loss: 0.821850]\n",
      "epoch:10 step:8442 [D loss: 0.660706, acc.: 62.50%] [G loss: 0.854692]\n",
      "epoch:10 step:8443 [D loss: 0.708364, acc.: 53.91%] [G loss: 0.750982]\n",
      "epoch:10 step:8444 [D loss: 0.778693, acc.: 39.06%] [G loss: 0.713540]\n",
      "epoch:10 step:8445 [D loss: 0.709793, acc.: 46.88%] [G loss: 0.745107]\n",
      "epoch:10 step:8446 [D loss: 0.781268, acc.: 38.28%] [G loss: 0.724511]\n",
      "epoch:10 step:8447 [D loss: 0.705655, acc.: 47.66%] [G loss: 0.821712]\n",
      "epoch:10 step:8448 [D loss: 0.697034, acc.: 54.69%] [G loss: 0.780106]\n",
      "epoch:10 step:8449 [D loss: 0.710984, acc.: 52.34%] [G loss: 0.754095]\n",
      "epoch:10 step:8450 [D loss: 0.709334, acc.: 53.91%] [G loss: 0.773847]\n",
      "epoch:10 step:8451 [D loss: 0.706503, acc.: 51.56%] [G loss: 0.736893]\n",
      "epoch:10 step:8452 [D loss: 0.716737, acc.: 41.41%] [G loss: 0.796215]\n",
      "epoch:10 step:8453 [D loss: 0.673166, acc.: 59.38%] [G loss: 0.850901]\n",
      "epoch:10 step:8454 [D loss: 0.699053, acc.: 50.78%] [G loss: 0.808182]\n",
      "epoch:10 step:8455 [D loss: 0.644881, acc.: 67.19%] [G loss: 0.833968]\n",
      "epoch:10 step:8456 [D loss: 0.727824, acc.: 47.66%] [G loss: 0.816864]\n",
      "epoch:10 step:8457 [D loss: 0.736914, acc.: 45.31%] [G loss: 0.787530]\n",
      "epoch:10 step:8458 [D loss: 0.646754, acc.: 66.41%] [G loss: 0.792383]\n",
      "epoch:10 step:8459 [D loss: 0.674078, acc.: 57.81%] [G loss: 0.809370]\n",
      "epoch:10 step:8460 [D loss: 0.661926, acc.: 64.06%] [G loss: 0.762977]\n",
      "epoch:10 step:8461 [D loss: 0.678880, acc.: 59.38%] [G loss: 0.735413]\n",
      "epoch:10 step:8462 [D loss: 0.676870, acc.: 53.91%] [G loss: 0.796973]\n",
      "epoch:10 step:8463 [D loss: 0.670060, acc.: 57.03%] [G loss: 0.732005]\n",
      "epoch:10 step:8464 [D loss: 0.663346, acc.: 58.59%] [G loss: 0.771183]\n",
      "epoch:10 step:8465 [D loss: 0.650757, acc.: 61.72%] [G loss: 0.766236]\n",
      "epoch:10 step:8466 [D loss: 0.756041, acc.: 33.59%] [G loss: 0.775335]\n",
      "epoch:10 step:8467 [D loss: 0.750019, acc.: 40.62%] [G loss: 0.770275]\n",
      "epoch:10 step:8468 [D loss: 0.687265, acc.: 54.69%] [G loss: 0.817046]\n",
      "epoch:10 step:8469 [D loss: 0.684090, acc.: 53.12%] [G loss: 0.848743]\n",
      "epoch:10 step:8470 [D loss: 0.720854, acc.: 47.66%] [G loss: 0.765589]\n",
      "epoch:10 step:8471 [D loss: 0.673716, acc.: 60.16%] [G loss: 0.783546]\n",
      "epoch:10 step:8472 [D loss: 0.691415, acc.: 51.56%] [G loss: 0.809200]\n",
      "epoch:10 step:8473 [D loss: 0.641305, acc.: 64.84%] [G loss: 0.868301]\n",
      "epoch:10 step:8474 [D loss: 0.733277, acc.: 42.97%] [G loss: 0.791640]\n",
      "epoch:10 step:8475 [D loss: 0.708524, acc.: 52.34%] [G loss: 0.799511]\n",
      "epoch:10 step:8476 [D loss: 0.706658, acc.: 53.91%] [G loss: 0.850261]\n",
      "epoch:10 step:8477 [D loss: 0.617981, acc.: 71.09%] [G loss: 0.769814]\n",
      "epoch:10 step:8478 [D loss: 0.706469, acc.: 53.12%] [G loss: 0.790876]\n",
      "epoch:10 step:8479 [D loss: 0.672492, acc.: 57.81%] [G loss: 0.745540]\n",
      "epoch:10 step:8480 [D loss: 0.726496, acc.: 42.97%] [G loss: 0.726786]\n",
      "epoch:10 step:8481 [D loss: 0.705095, acc.: 47.66%] [G loss: 0.724259]\n",
      "epoch:10 step:8482 [D loss: 0.653649, acc.: 62.50%] [G loss: 0.799100]\n",
      "epoch:10 step:8483 [D loss: 0.636086, acc.: 67.19%] [G loss: 0.799908]\n",
      "epoch:10 step:8484 [D loss: 0.699190, acc.: 59.38%] [G loss: 0.885643]\n",
      "epoch:10 step:8485 [D loss: 0.706933, acc.: 49.22%] [G loss: 0.842461]\n",
      "epoch:10 step:8486 [D loss: 0.663793, acc.: 56.25%] [G loss: 0.763129]\n",
      "epoch:10 step:8487 [D loss: 0.728014, acc.: 46.88%] [G loss: 0.798535]\n",
      "epoch:10 step:8488 [D loss: 0.748650, acc.: 38.28%] [G loss: 0.739219]\n",
      "epoch:10 step:8489 [D loss: 0.687631, acc.: 57.03%] [G loss: 0.710064]\n",
      "epoch:10 step:8490 [D loss: 0.623443, acc.: 70.31%] [G loss: 0.830684]\n",
      "epoch:10 step:8491 [D loss: 0.647284, acc.: 64.84%] [G loss: 0.804804]\n",
      "epoch:10 step:8492 [D loss: 0.736544, acc.: 43.75%] [G loss: 0.755830]\n",
      "epoch:10 step:8493 [D loss: 0.685519, acc.: 53.91%] [G loss: 0.758501]\n",
      "epoch:10 step:8494 [D loss: 0.682419, acc.: 54.69%] [G loss: 0.843124]\n",
      "epoch:10 step:8495 [D loss: 0.687846, acc.: 53.12%] [G loss: 0.752246]\n",
      "epoch:10 step:8496 [D loss: 0.730143, acc.: 40.62%] [G loss: 0.679742]\n",
      "epoch:10 step:8497 [D loss: 0.692647, acc.: 51.56%] [G loss: 0.753797]\n",
      "epoch:10 step:8498 [D loss: 0.701140, acc.: 51.56%] [G loss: 0.824502]\n",
      "epoch:10 step:8499 [D loss: 0.673542, acc.: 53.91%] [G loss: 0.781991]\n",
      "epoch:10 step:8500 [D loss: 0.680675, acc.: 58.59%] [G loss: 0.759030]\n",
      "epoch:10 step:8501 [D loss: 0.671693, acc.: 60.94%] [G loss: 0.741493]\n",
      "epoch:10 step:8502 [D loss: 0.771414, acc.: 35.16%] [G loss: 0.699614]\n",
      "epoch:10 step:8503 [D loss: 0.637440, acc.: 66.41%] [G loss: 0.742568]\n",
      "epoch:10 step:8504 [D loss: 0.761706, acc.: 35.94%] [G loss: 0.705408]\n",
      "epoch:10 step:8505 [D loss: 0.739262, acc.: 46.88%] [G loss: 0.685589]\n",
      "epoch:10 step:8506 [D loss: 0.707221, acc.: 52.34%] [G loss: 0.671193]\n",
      "epoch:10 step:8507 [D loss: 0.736186, acc.: 42.97%] [G loss: 0.728849]\n",
      "epoch:10 step:8508 [D loss: 0.685979, acc.: 59.38%] [G loss: 0.702549]\n",
      "epoch:10 step:8509 [D loss: 0.705249, acc.: 50.78%] [G loss: 0.685817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8510 [D loss: 0.688035, acc.: 53.91%] [G loss: 0.776266]\n",
      "epoch:10 step:8511 [D loss: 0.717512, acc.: 50.78%] [G loss: 0.825351]\n",
      "epoch:10 step:8512 [D loss: 0.667195, acc.: 60.94%] [G loss: 0.780673]\n",
      "epoch:10 step:8513 [D loss: 0.718974, acc.: 47.66%] [G loss: 0.765745]\n",
      "epoch:10 step:8514 [D loss: 0.676264, acc.: 57.81%] [G loss: 0.777616]\n",
      "epoch:10 step:8515 [D loss: 0.706050, acc.: 55.47%] [G loss: 0.763687]\n",
      "epoch:10 step:8516 [D loss: 0.643205, acc.: 66.41%] [G loss: 0.837607]\n",
      "epoch:10 step:8517 [D loss: 0.715011, acc.: 49.22%] [G loss: 0.790794]\n",
      "epoch:10 step:8518 [D loss: 0.727154, acc.: 42.19%] [G loss: 0.718128]\n",
      "epoch:10 step:8519 [D loss: 0.670766, acc.: 56.25%] [G loss: 0.738027]\n",
      "epoch:10 step:8520 [D loss: 0.678210, acc.: 61.72%] [G loss: 0.836472]\n",
      "epoch:10 step:8521 [D loss: 0.651922, acc.: 62.50%] [G loss: 0.838989]\n",
      "epoch:10 step:8522 [D loss: 0.646346, acc.: 67.19%] [G loss: 0.822545]\n",
      "epoch:10 step:8523 [D loss: 0.658644, acc.: 64.84%] [G loss: 0.861980]\n",
      "epoch:10 step:8524 [D loss: 0.630941, acc.: 64.06%] [G loss: 0.802140]\n",
      "epoch:10 step:8525 [D loss: 0.704007, acc.: 52.34%] [G loss: 0.707692]\n",
      "epoch:10 step:8526 [D loss: 0.630754, acc.: 65.62%] [G loss: 0.678620]\n",
      "epoch:10 step:8527 [D loss: 0.683250, acc.: 59.38%] [G loss: 0.789285]\n",
      "epoch:10 step:8528 [D loss: 0.698697, acc.: 48.44%] [G loss: 0.706507]\n",
      "epoch:10 step:8529 [D loss: 0.734396, acc.: 45.31%] [G loss: 0.756650]\n",
      "epoch:10 step:8530 [D loss: 0.737899, acc.: 50.00%] [G loss: 0.829008]\n",
      "epoch:10 step:8531 [D loss: 0.687364, acc.: 54.69%] [G loss: 0.729565]\n",
      "epoch:10 step:8532 [D loss: 0.702057, acc.: 46.88%] [G loss: 0.753307]\n",
      "epoch:10 step:8533 [D loss: 0.794130, acc.: 35.94%] [G loss: 0.704855]\n",
      "epoch:10 step:8534 [D loss: 0.758131, acc.: 37.50%] [G loss: 0.668379]\n",
      "epoch:10 step:8535 [D loss: 0.659469, acc.: 63.28%] [G loss: 0.729221]\n",
      "epoch:10 step:8536 [D loss: 0.688945, acc.: 56.25%] [G loss: 0.810840]\n",
      "epoch:10 step:8537 [D loss: 0.686785, acc.: 49.22%] [G loss: 0.802977]\n",
      "epoch:10 step:8538 [D loss: 0.734170, acc.: 47.66%] [G loss: 0.769615]\n",
      "epoch:10 step:8539 [D loss: 0.702045, acc.: 57.03%] [G loss: 0.874807]\n",
      "epoch:10 step:8540 [D loss: 0.727386, acc.: 46.09%] [G loss: 0.672910]\n",
      "epoch:10 step:8541 [D loss: 0.660630, acc.: 62.50%] [G loss: 0.785251]\n",
      "epoch:10 step:8542 [D loss: 0.734888, acc.: 43.75%] [G loss: 0.705849]\n",
      "epoch:10 step:8543 [D loss: 0.723782, acc.: 46.09%] [G loss: 0.724085]\n",
      "epoch:10 step:8544 [D loss: 0.717991, acc.: 44.53%] [G loss: 0.741919]\n",
      "epoch:10 step:8545 [D loss: 0.711720, acc.: 46.88%] [G loss: 0.764946]\n",
      "epoch:10 step:8546 [D loss: 0.687607, acc.: 53.91%] [G loss: 0.830156]\n",
      "epoch:10 step:8547 [D loss: 0.756746, acc.: 39.06%] [G loss: 0.797090]\n",
      "epoch:10 step:8548 [D loss: 0.735007, acc.: 45.31%] [G loss: 0.842330]\n",
      "epoch:10 step:8549 [D loss: 0.692376, acc.: 55.47%] [G loss: 0.815510]\n",
      "epoch:10 step:8550 [D loss: 0.652958, acc.: 62.50%] [G loss: 0.874821]\n",
      "epoch:10 step:8551 [D loss: 0.674088, acc.: 57.03%] [G loss: 0.855881]\n",
      "epoch:10 step:8552 [D loss: 0.690371, acc.: 55.47%] [G loss: 0.818170]\n",
      "epoch:10 step:8553 [D loss: 0.650941, acc.: 64.84%] [G loss: 0.806890]\n",
      "epoch:10 step:8554 [D loss: 0.639061, acc.: 67.19%] [G loss: 0.768494]\n",
      "epoch:10 step:8555 [D loss: 0.643202, acc.: 60.94%] [G loss: 0.767656]\n",
      "epoch:10 step:8556 [D loss: 0.671540, acc.: 53.91%] [G loss: 0.722275]\n",
      "epoch:10 step:8557 [D loss: 0.635832, acc.: 69.53%] [G loss: 0.707077]\n",
      "epoch:10 step:8558 [D loss: 0.693211, acc.: 55.47%] [G loss: 0.689130]\n",
      "epoch:10 step:8559 [D loss: 0.624569, acc.: 73.44%] [G loss: 0.787185]\n",
      "epoch:10 step:8560 [D loss: 0.715744, acc.: 49.22%] [G loss: 0.750790]\n",
      "epoch:10 step:8561 [D loss: 0.696595, acc.: 57.03%] [G loss: 0.794700]\n",
      "epoch:10 step:8562 [D loss: 0.773379, acc.: 32.81%] [G loss: 0.767808]\n",
      "epoch:10 step:8563 [D loss: 0.697402, acc.: 50.78%] [G loss: 0.707534]\n",
      "epoch:10 step:8564 [D loss: 0.688487, acc.: 46.88%] [G loss: 0.790710]\n",
      "epoch:10 step:8565 [D loss: 0.726616, acc.: 44.53%] [G loss: 0.783315]\n",
      "epoch:10 step:8566 [D loss: 0.763839, acc.: 34.38%] [G loss: 0.726382]\n",
      "epoch:10 step:8567 [D loss: 0.766017, acc.: 38.28%] [G loss: 0.716712]\n",
      "epoch:10 step:8568 [D loss: 0.698255, acc.: 52.34%] [G loss: 0.762399]\n",
      "epoch:10 step:8569 [D loss: 0.738968, acc.: 38.28%] [G loss: 0.727971]\n",
      "epoch:10 step:8570 [D loss: 0.688792, acc.: 57.03%] [G loss: 0.770714]\n",
      "epoch:10 step:8571 [D loss: 0.716663, acc.: 46.88%] [G loss: 0.786525]\n",
      "epoch:10 step:8572 [D loss: 0.749962, acc.: 40.62%] [G loss: 0.894247]\n",
      "epoch:10 step:8573 [D loss: 0.711665, acc.: 46.88%] [G loss: 0.798573]\n",
      "epoch:10 step:8574 [D loss: 0.705878, acc.: 50.00%] [G loss: 0.882296]\n",
      "epoch:10 step:8575 [D loss: 0.694077, acc.: 50.00%] [G loss: 0.908780]\n",
      "epoch:10 step:8576 [D loss: 0.743947, acc.: 45.31%] [G loss: 0.788575]\n",
      "epoch:10 step:8577 [D loss: 0.671658, acc.: 55.47%] [G loss: 0.843133]\n",
      "epoch:10 step:8578 [D loss: 0.696653, acc.: 52.34%] [G loss: 0.909109]\n",
      "epoch:10 step:8579 [D loss: 0.702344, acc.: 50.78%] [G loss: 0.837861]\n",
      "epoch:10 step:8580 [D loss: 0.666157, acc.: 62.50%] [G loss: 0.849107]\n",
      "epoch:10 step:8581 [D loss: 0.698052, acc.: 53.12%] [G loss: 0.873111]\n",
      "epoch:10 step:8582 [D loss: 0.726817, acc.: 46.09%] [G loss: 0.836209]\n",
      "epoch:10 step:8583 [D loss: 0.693207, acc.: 49.22%] [G loss: 0.799135]\n",
      "epoch:10 step:8584 [D loss: 0.677852, acc.: 64.84%] [G loss: 0.866828]\n",
      "epoch:10 step:8585 [D loss: 0.730495, acc.: 50.00%] [G loss: 0.836117]\n",
      "epoch:10 step:8586 [D loss: 0.656231, acc.: 61.72%] [G loss: 0.908560]\n",
      "epoch:10 step:8587 [D loss: 0.661913, acc.: 57.03%] [G loss: 0.691673]\n",
      "epoch:10 step:8588 [D loss: 0.677535, acc.: 59.38%] [G loss: 0.783817]\n",
      "epoch:10 step:8589 [D loss: 0.650725, acc.: 61.72%] [G loss: 0.736283]\n",
      "epoch:10 step:8590 [D loss: 0.664804, acc.: 60.16%] [G loss: 0.803886]\n",
      "epoch:10 step:8591 [D loss: 0.648539, acc.: 64.84%] [G loss: 0.751296]\n",
      "epoch:11 step:8592 [D loss: 0.698201, acc.: 55.47%] [G loss: 0.785355]\n",
      "epoch:11 step:8593 [D loss: 0.673499, acc.: 57.03%] [G loss: 0.840423]\n",
      "epoch:11 step:8594 [D loss: 0.649897, acc.: 62.50%] [G loss: 0.857552]\n",
      "epoch:11 step:8595 [D loss: 0.708722, acc.: 50.78%] [G loss: 0.716781]\n",
      "epoch:11 step:8596 [D loss: 0.637253, acc.: 64.06%] [G loss: 0.787467]\n",
      "epoch:11 step:8597 [D loss: 0.687018, acc.: 51.56%] [G loss: 0.781021]\n",
      "epoch:11 step:8598 [D loss: 0.740870, acc.: 46.09%] [G loss: 0.656916]\n",
      "epoch:11 step:8599 [D loss: 0.680157, acc.: 52.34%] [G loss: 0.730145]\n",
      "epoch:11 step:8600 [D loss: 0.708801, acc.: 53.91%] [G loss: 0.769922]\n",
      "epoch:11 step:8601 [D loss: 0.741647, acc.: 40.62%] [G loss: 0.765710]\n",
      "epoch:11 step:8602 [D loss: 0.713673, acc.: 50.78%] [G loss: 0.806496]\n",
      "epoch:11 step:8603 [D loss: 0.709097, acc.: 53.12%] [G loss: 0.845153]\n",
      "epoch:11 step:8604 [D loss: 0.682105, acc.: 58.59%] [G loss: 0.758370]\n",
      "epoch:11 step:8605 [D loss: 0.723891, acc.: 46.09%] [G loss: 0.764717]\n",
      "epoch:11 step:8606 [D loss: 0.740538, acc.: 40.62%] [G loss: 0.783942]\n",
      "epoch:11 step:8607 [D loss: 0.710069, acc.: 50.78%] [G loss: 0.790753]\n",
      "epoch:11 step:8608 [D loss: 0.722423, acc.: 46.88%] [G loss: 0.755169]\n",
      "epoch:11 step:8609 [D loss: 0.723448, acc.: 51.56%] [G loss: 0.766844]\n",
      "epoch:11 step:8610 [D loss: 0.715735, acc.: 49.22%] [G loss: 0.788660]\n",
      "epoch:11 step:8611 [D loss: 0.730964, acc.: 43.75%] [G loss: 0.705958]\n",
      "epoch:11 step:8612 [D loss: 0.703747, acc.: 55.47%] [G loss: 0.812165]\n",
      "epoch:11 step:8613 [D loss: 0.629683, acc.: 68.75%] [G loss: 0.860827]\n",
      "epoch:11 step:8614 [D loss: 0.680471, acc.: 50.78%] [G loss: 0.767431]\n",
      "epoch:11 step:8615 [D loss: 0.744505, acc.: 36.72%] [G loss: 0.735906]\n",
      "epoch:11 step:8616 [D loss: 0.748128, acc.: 39.06%] [G loss: 0.762747]\n",
      "epoch:11 step:8617 [D loss: 0.720137, acc.: 45.31%] [G loss: 0.715424]\n",
      "epoch:11 step:8618 [D loss: 0.662277, acc.: 57.03%] [G loss: 0.766915]\n",
      "epoch:11 step:8619 [D loss: 0.698133, acc.: 56.25%] [G loss: 0.694669]\n",
      "epoch:11 step:8620 [D loss: 0.699718, acc.: 53.91%] [G loss: 0.748730]\n",
      "epoch:11 step:8621 [D loss: 0.681734, acc.: 58.59%] [G loss: 0.747880]\n",
      "epoch:11 step:8622 [D loss: 0.675953, acc.: 56.25%] [G loss: 0.756978]\n",
      "epoch:11 step:8623 [D loss: 0.670373, acc.: 60.94%] [G loss: 0.687206]\n",
      "epoch:11 step:8624 [D loss: 0.694669, acc.: 50.78%] [G loss: 0.723523]\n",
      "epoch:11 step:8625 [D loss: 0.708335, acc.: 54.69%] [G loss: 0.810609]\n",
      "epoch:11 step:8626 [D loss: 0.652716, acc.: 59.38%] [G loss: 0.827501]\n",
      "epoch:11 step:8627 [D loss: 0.674637, acc.: 56.25%] [G loss: 0.844911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8628 [D loss: 0.756521, acc.: 33.59%] [G loss: 0.755271]\n",
      "epoch:11 step:8629 [D loss: 0.720534, acc.: 42.19%] [G loss: 0.691357]\n",
      "epoch:11 step:8630 [D loss: 0.726392, acc.: 47.66%] [G loss: 0.797873]\n",
      "epoch:11 step:8631 [D loss: 0.743062, acc.: 38.28%] [G loss: 0.766179]\n",
      "epoch:11 step:8632 [D loss: 0.695949, acc.: 56.25%] [G loss: 0.776469]\n",
      "epoch:11 step:8633 [D loss: 0.667906, acc.: 57.03%] [G loss: 0.771544]\n",
      "epoch:11 step:8634 [D loss: 0.706170, acc.: 48.44%] [G loss: 0.774340]\n",
      "epoch:11 step:8635 [D loss: 0.732096, acc.: 40.62%] [G loss: 0.737381]\n",
      "epoch:11 step:8636 [D loss: 0.757326, acc.: 42.19%] [G loss: 0.719954]\n",
      "epoch:11 step:8637 [D loss: 0.676079, acc.: 57.03%] [G loss: 0.745283]\n",
      "epoch:11 step:8638 [D loss: 0.725858, acc.: 44.53%] [G loss: 0.711391]\n",
      "epoch:11 step:8639 [D loss: 0.718141, acc.: 46.09%] [G loss: 0.701117]\n",
      "epoch:11 step:8640 [D loss: 0.653408, acc.: 58.59%] [G loss: 0.660453]\n",
      "epoch:11 step:8641 [D loss: 0.762082, acc.: 41.41%] [G loss: 0.727607]\n",
      "epoch:11 step:8642 [D loss: 0.706170, acc.: 53.12%] [G loss: 0.752666]\n",
      "epoch:11 step:8643 [D loss: 0.681064, acc.: 57.81%] [G loss: 0.731912]\n",
      "epoch:11 step:8644 [D loss: 0.708605, acc.: 50.00%] [G loss: 0.702374]\n",
      "epoch:11 step:8645 [D loss: 0.721095, acc.: 50.00%] [G loss: 0.775024]\n",
      "epoch:11 step:8646 [D loss: 0.749035, acc.: 36.72%] [G loss: 0.768288]\n",
      "epoch:11 step:8647 [D loss: 0.680755, acc.: 57.03%] [G loss: 0.751317]\n",
      "epoch:11 step:8648 [D loss: 0.703427, acc.: 49.22%] [G loss: 0.753732]\n",
      "epoch:11 step:8649 [D loss: 0.722178, acc.: 46.09%] [G loss: 0.774823]\n",
      "epoch:11 step:8650 [D loss: 0.695044, acc.: 51.56%] [G loss: 0.772991]\n",
      "epoch:11 step:8651 [D loss: 0.692244, acc.: 50.78%] [G loss: 0.797895]\n",
      "epoch:11 step:8652 [D loss: 0.720554, acc.: 46.88%] [G loss: 0.778158]\n",
      "epoch:11 step:8653 [D loss: 0.689975, acc.: 50.78%] [G loss: 0.890470]\n",
      "epoch:11 step:8654 [D loss: 0.707333, acc.: 47.66%] [G loss: 0.749518]\n",
      "epoch:11 step:8655 [D loss: 0.685671, acc.: 52.34%] [G loss: 0.823263]\n",
      "epoch:11 step:8656 [D loss: 0.711162, acc.: 44.53%] [G loss: 0.752978]\n",
      "epoch:11 step:8657 [D loss: 0.726254, acc.: 53.12%] [G loss: 0.753084]\n",
      "epoch:11 step:8658 [D loss: 0.744155, acc.: 42.19%] [G loss: 0.775986]\n",
      "epoch:11 step:8659 [D loss: 0.715285, acc.: 47.66%] [G loss: 0.768587]\n",
      "epoch:11 step:8660 [D loss: 0.709112, acc.: 45.31%] [G loss: 0.806207]\n",
      "epoch:11 step:8661 [D loss: 0.711207, acc.: 51.56%] [G loss: 0.793055]\n",
      "epoch:11 step:8662 [D loss: 0.737763, acc.: 42.97%] [G loss: 0.706855]\n",
      "epoch:11 step:8663 [D loss: 0.707206, acc.: 49.22%] [G loss: 0.734910]\n",
      "epoch:11 step:8664 [D loss: 0.740420, acc.: 40.62%] [G loss: 0.734325]\n",
      "epoch:11 step:8665 [D loss: 0.682616, acc.: 56.25%] [G loss: 0.744729]\n",
      "epoch:11 step:8666 [D loss: 0.677004, acc.: 53.12%] [G loss: 0.843047]\n",
      "epoch:11 step:8667 [D loss: 0.665822, acc.: 58.59%] [G loss: 0.793327]\n",
      "epoch:11 step:8668 [D loss: 0.677841, acc.: 53.12%] [G loss: 0.784003]\n",
      "epoch:11 step:8669 [D loss: 0.683992, acc.: 54.69%] [G loss: 0.753642]\n",
      "epoch:11 step:8670 [D loss: 0.712489, acc.: 51.56%] [G loss: 0.689574]\n",
      "epoch:11 step:8671 [D loss: 0.679302, acc.: 53.12%] [G loss: 0.808834]\n",
      "epoch:11 step:8672 [D loss: 0.756492, acc.: 35.94%] [G loss: 0.776797]\n",
      "epoch:11 step:8673 [D loss: 0.682711, acc.: 53.12%] [G loss: 0.785527]\n",
      "epoch:11 step:8674 [D loss: 0.694104, acc.: 46.88%] [G loss: 0.774161]\n",
      "epoch:11 step:8675 [D loss: 0.711104, acc.: 45.31%] [G loss: 0.725313]\n",
      "epoch:11 step:8676 [D loss: 0.687804, acc.: 53.91%] [G loss: 0.775820]\n",
      "epoch:11 step:8677 [D loss: 0.720142, acc.: 42.97%] [G loss: 0.782747]\n",
      "epoch:11 step:8678 [D loss: 0.692078, acc.: 47.66%] [G loss: 0.777216]\n",
      "epoch:11 step:8679 [D loss: 0.700811, acc.: 53.91%] [G loss: 0.766267]\n",
      "epoch:11 step:8680 [D loss: 0.657278, acc.: 64.06%] [G loss: 0.808503]\n",
      "epoch:11 step:8681 [D loss: 0.708045, acc.: 50.78%] [G loss: 0.805605]\n",
      "epoch:11 step:8682 [D loss: 0.727511, acc.: 46.09%] [G loss: 0.816108]\n",
      "epoch:11 step:8683 [D loss: 0.718888, acc.: 47.66%] [G loss: 0.821273]\n",
      "epoch:11 step:8684 [D loss: 0.693135, acc.: 60.16%] [G loss: 0.805184]\n",
      "epoch:11 step:8685 [D loss: 0.679814, acc.: 57.03%] [G loss: 0.768547]\n",
      "epoch:11 step:8686 [D loss: 0.728386, acc.: 50.78%] [G loss: 0.813085]\n",
      "epoch:11 step:8687 [D loss: 0.627875, acc.: 64.84%] [G loss: 0.852969]\n",
      "epoch:11 step:8688 [D loss: 0.688288, acc.: 58.59%] [G loss: 0.850633]\n",
      "epoch:11 step:8689 [D loss: 0.655012, acc.: 60.16%] [G loss: 0.817795]\n",
      "epoch:11 step:8690 [D loss: 0.693847, acc.: 53.12%] [G loss: 0.779722]\n",
      "epoch:11 step:8691 [D loss: 0.746208, acc.: 40.62%] [G loss: 0.841276]\n",
      "epoch:11 step:8692 [D loss: 0.646610, acc.: 66.41%] [G loss: 0.793717]\n",
      "epoch:11 step:8693 [D loss: 0.641373, acc.: 67.19%] [G loss: 0.774132]\n",
      "epoch:11 step:8694 [D loss: 0.703270, acc.: 46.88%] [G loss: 0.793690]\n",
      "epoch:11 step:8695 [D loss: 0.742515, acc.: 46.88%] [G loss: 0.679020]\n",
      "epoch:11 step:8696 [D loss: 0.726273, acc.: 41.41%] [G loss: 0.724358]\n",
      "epoch:11 step:8697 [D loss: 0.655599, acc.: 59.38%] [G loss: 0.754518]\n",
      "epoch:11 step:8698 [D loss: 0.719340, acc.: 50.00%] [G loss: 0.742568]\n",
      "epoch:11 step:8699 [D loss: 0.753822, acc.: 44.53%] [G loss: 0.712142]\n",
      "epoch:11 step:8700 [D loss: 0.715564, acc.: 49.22%] [G loss: 0.715416]\n",
      "epoch:11 step:8701 [D loss: 0.670131, acc.: 58.59%] [G loss: 0.745915]\n",
      "epoch:11 step:8702 [D loss: 0.651472, acc.: 59.38%] [G loss: 0.861882]\n",
      "epoch:11 step:8703 [D loss: 0.703429, acc.: 49.22%] [G loss: 0.818078]\n",
      "epoch:11 step:8704 [D loss: 0.705078, acc.: 53.12%] [G loss: 0.801769]\n",
      "epoch:11 step:8705 [D loss: 0.678563, acc.: 57.81%] [G loss: 0.763977]\n",
      "epoch:11 step:8706 [D loss: 0.726931, acc.: 46.88%] [G loss: 0.721456]\n",
      "epoch:11 step:8707 [D loss: 0.664980, acc.: 60.16%] [G loss: 0.807206]\n",
      "epoch:11 step:8708 [D loss: 0.679195, acc.: 54.69%] [G loss: 0.715937]\n",
      "epoch:11 step:8709 [D loss: 0.707556, acc.: 52.34%] [G loss: 0.797260]\n",
      "epoch:11 step:8710 [D loss: 0.658560, acc.: 58.59%] [G loss: 0.815347]\n",
      "epoch:11 step:8711 [D loss: 0.681479, acc.: 59.38%] [G loss: 0.730773]\n",
      "epoch:11 step:8712 [D loss: 0.730575, acc.: 45.31%] [G loss: 0.732353]\n",
      "epoch:11 step:8713 [D loss: 0.676439, acc.: 51.56%] [G loss: 0.721494]\n",
      "epoch:11 step:8714 [D loss: 0.718538, acc.: 49.22%] [G loss: 0.743231]\n",
      "epoch:11 step:8715 [D loss: 0.726699, acc.: 39.84%] [G loss: 0.754856]\n",
      "epoch:11 step:8716 [D loss: 0.730613, acc.: 39.84%] [G loss: 0.699680]\n",
      "epoch:11 step:8717 [D loss: 0.792406, acc.: 35.94%] [G loss: 0.741738]\n",
      "epoch:11 step:8718 [D loss: 0.744609, acc.: 41.41%] [G loss: 0.677257]\n",
      "epoch:11 step:8719 [D loss: 0.671515, acc.: 56.25%] [G loss: 0.753398]\n",
      "epoch:11 step:8720 [D loss: 0.691487, acc.: 51.56%] [G loss: 0.765236]\n",
      "epoch:11 step:8721 [D loss: 0.737227, acc.: 40.62%] [G loss: 0.700152]\n",
      "epoch:11 step:8722 [D loss: 0.703015, acc.: 51.56%] [G loss: 0.773254]\n",
      "epoch:11 step:8723 [D loss: 0.690526, acc.: 46.09%] [G loss: 0.704844]\n",
      "epoch:11 step:8724 [D loss: 0.674148, acc.: 53.12%] [G loss: 0.816732]\n",
      "epoch:11 step:8725 [D loss: 0.692921, acc.: 55.47%] [G loss: 0.782467]\n",
      "epoch:11 step:8726 [D loss: 0.785440, acc.: 37.50%] [G loss: 0.806937]\n",
      "epoch:11 step:8727 [D loss: 0.681862, acc.: 53.12%] [G loss: 0.880330]\n",
      "epoch:11 step:8728 [D loss: 0.714739, acc.: 49.22%] [G loss: 0.909284]\n",
      "epoch:11 step:8729 [D loss: 0.751239, acc.: 41.41%] [G loss: 0.779873]\n",
      "epoch:11 step:8730 [D loss: 0.681653, acc.: 57.03%] [G loss: 0.842338]\n",
      "epoch:11 step:8731 [D loss: 0.731064, acc.: 55.47%] [G loss: 0.779991]\n",
      "epoch:11 step:8732 [D loss: 0.657472, acc.: 67.97%] [G loss: 0.831315]\n",
      "epoch:11 step:8733 [D loss: 0.702634, acc.: 53.91%] [G loss: 0.822131]\n",
      "epoch:11 step:8734 [D loss: 0.678446, acc.: 57.81%] [G loss: 0.815212]\n",
      "epoch:11 step:8735 [D loss: 0.682720, acc.: 56.25%] [G loss: 0.782782]\n",
      "epoch:11 step:8736 [D loss: 0.676052, acc.: 61.72%] [G loss: 0.779461]\n",
      "epoch:11 step:8737 [D loss: 0.632864, acc.: 64.06%] [G loss: 0.856012]\n",
      "epoch:11 step:8738 [D loss: 0.626831, acc.: 68.75%] [G loss: 0.937238]\n",
      "epoch:11 step:8739 [D loss: 0.637339, acc.: 70.31%] [G loss: 0.799333]\n",
      "epoch:11 step:8740 [D loss: 0.654481, acc.: 62.50%] [G loss: 0.770560]\n",
      "epoch:11 step:8741 [D loss: 0.665280, acc.: 62.50%] [G loss: 0.719017]\n",
      "epoch:11 step:8742 [D loss: 0.691679, acc.: 57.81%] [G loss: 0.730293]\n",
      "epoch:11 step:8743 [D loss: 0.697848, acc.: 51.56%] [G loss: 0.720699]\n",
      "epoch:11 step:8744 [D loss: 0.696010, acc.: 53.91%] [G loss: 0.702957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8745 [D loss: 0.652407, acc.: 65.62%] [G loss: 0.775056]\n",
      "epoch:11 step:8746 [D loss: 0.709286, acc.: 52.34%] [G loss: 0.652502]\n",
      "epoch:11 step:8747 [D loss: 0.732005, acc.: 44.53%] [G loss: 0.719808]\n",
      "epoch:11 step:8748 [D loss: 0.664487, acc.: 63.28%] [G loss: 0.687829]\n",
      "epoch:11 step:8749 [D loss: 0.757096, acc.: 42.97%] [G loss: 0.749514]\n",
      "epoch:11 step:8750 [D loss: 0.692526, acc.: 60.16%] [G loss: 0.752423]\n",
      "epoch:11 step:8751 [D loss: 0.697494, acc.: 53.12%] [G loss: 0.742408]\n",
      "epoch:11 step:8752 [D loss: 0.733457, acc.: 42.97%] [G loss: 0.706579]\n",
      "epoch:11 step:8753 [D loss: 0.652406, acc.: 60.94%] [G loss: 0.794749]\n",
      "epoch:11 step:8754 [D loss: 0.685929, acc.: 52.34%] [G loss: 0.675579]\n",
      "epoch:11 step:8755 [D loss: 0.708243, acc.: 53.12%] [G loss: 0.793181]\n",
      "epoch:11 step:8756 [D loss: 0.652212, acc.: 61.72%] [G loss: 0.865605]\n",
      "epoch:11 step:8757 [D loss: 0.656702, acc.: 54.69%] [G loss: 0.799502]\n",
      "epoch:11 step:8758 [D loss: 0.702066, acc.: 54.69%] [G loss: 0.887060]\n",
      "epoch:11 step:8759 [D loss: 0.650709, acc.: 64.06%] [G loss: 0.851793]\n",
      "epoch:11 step:8760 [D loss: 0.659310, acc.: 64.06%] [G loss: 0.839710]\n",
      "epoch:11 step:8761 [D loss: 0.640578, acc.: 68.75%] [G loss: 0.784045]\n",
      "epoch:11 step:8762 [D loss: 0.694905, acc.: 57.03%] [G loss: 0.787225]\n",
      "epoch:11 step:8763 [D loss: 0.638671, acc.: 66.41%] [G loss: 0.739859]\n",
      "epoch:11 step:8764 [D loss: 0.613767, acc.: 73.44%] [G loss: 0.701842]\n",
      "epoch:11 step:8765 [D loss: 0.676892, acc.: 55.47%] [G loss: 0.650420]\n",
      "epoch:11 step:8766 [D loss: 0.687337, acc.: 56.25%] [G loss: 0.715266]\n",
      "epoch:11 step:8767 [D loss: 0.745852, acc.: 42.19%] [G loss: 0.711514]\n",
      "epoch:11 step:8768 [D loss: 0.671827, acc.: 56.25%] [G loss: 0.742682]\n",
      "epoch:11 step:8769 [D loss: 0.724103, acc.: 42.19%] [G loss: 0.665072]\n",
      "epoch:11 step:8770 [D loss: 0.641807, acc.: 69.53%] [G loss: 0.655223]\n",
      "epoch:11 step:8771 [D loss: 0.707213, acc.: 53.91%] [G loss: 0.709201]\n",
      "epoch:11 step:8772 [D loss: 0.717761, acc.: 48.44%] [G loss: 0.712458]\n",
      "epoch:11 step:8773 [D loss: 0.672524, acc.: 57.81%] [G loss: 0.737218]\n",
      "epoch:11 step:8774 [D loss: 0.737408, acc.: 46.88%] [G loss: 0.689584]\n",
      "epoch:11 step:8775 [D loss: 0.692597, acc.: 61.72%] [G loss: 0.706051]\n",
      "epoch:11 step:8776 [D loss: 0.682083, acc.: 55.47%] [G loss: 0.691429]\n",
      "epoch:11 step:8777 [D loss: 0.747651, acc.: 43.75%] [G loss: 0.728088]\n",
      "epoch:11 step:8778 [D loss: 0.744840, acc.: 38.28%] [G loss: 0.790861]\n",
      "epoch:11 step:8779 [D loss: 0.705797, acc.: 55.47%] [G loss: 0.835070]\n",
      "epoch:11 step:8780 [D loss: 0.654830, acc.: 60.94%] [G loss: 0.811987]\n",
      "epoch:11 step:8781 [D loss: 0.694644, acc.: 51.56%] [G loss: 0.805435]\n",
      "epoch:11 step:8782 [D loss: 0.703402, acc.: 50.78%] [G loss: 0.827405]\n",
      "epoch:11 step:8783 [D loss: 0.677216, acc.: 57.81%] [G loss: 0.838839]\n",
      "epoch:11 step:8784 [D loss: 0.739678, acc.: 36.72%] [G loss: 0.803699]\n",
      "epoch:11 step:8785 [D loss: 0.584407, acc.: 78.12%] [G loss: 0.899575]\n",
      "epoch:11 step:8786 [D loss: 0.714373, acc.: 51.56%] [G loss: 0.815964]\n",
      "epoch:11 step:8787 [D loss: 0.658781, acc.: 67.19%] [G loss: 0.789793]\n",
      "epoch:11 step:8788 [D loss: 0.694677, acc.: 49.22%] [G loss: 0.771976]\n",
      "epoch:11 step:8789 [D loss: 0.628361, acc.: 65.62%] [G loss: 0.727956]\n",
      "epoch:11 step:8790 [D loss: 0.716293, acc.: 50.78%] [G loss: 0.664490]\n",
      "epoch:11 step:8791 [D loss: 0.688259, acc.: 55.47%] [G loss: 0.710565]\n",
      "epoch:11 step:8792 [D loss: 0.644251, acc.: 64.06%] [G loss: 0.701779]\n",
      "epoch:11 step:8793 [D loss: 0.651872, acc.: 61.72%] [G loss: 0.704232]\n",
      "epoch:11 step:8794 [D loss: 0.618427, acc.: 71.88%] [G loss: 0.804648]\n",
      "epoch:11 step:8795 [D loss: 0.638261, acc.: 66.41%] [G loss: 0.792082]\n",
      "epoch:11 step:8796 [D loss: 0.709512, acc.: 55.47%] [G loss: 0.757084]\n",
      "epoch:11 step:8797 [D loss: 0.661881, acc.: 62.50%] [G loss: 0.748087]\n",
      "epoch:11 step:8798 [D loss: 0.657862, acc.: 64.84%] [G loss: 0.723520]\n",
      "epoch:11 step:8799 [D loss: 0.783125, acc.: 32.81%] [G loss: 0.707059]\n",
      "epoch:11 step:8800 [D loss: 0.682851, acc.: 58.59%] [G loss: 0.735742]\n",
      "epoch:11 step:8801 [D loss: 0.719128, acc.: 44.53%] [G loss: 0.685112]\n",
      "epoch:11 step:8802 [D loss: 0.670279, acc.: 57.81%] [G loss: 0.764529]\n",
      "epoch:11 step:8803 [D loss: 0.709006, acc.: 50.00%] [G loss: 0.716417]\n",
      "epoch:11 step:8804 [D loss: 0.747679, acc.: 46.09%] [G loss: 0.757003]\n",
      "epoch:11 step:8805 [D loss: 0.716298, acc.: 49.22%] [G loss: 0.781522]\n",
      "epoch:11 step:8806 [D loss: 0.732083, acc.: 43.75%] [G loss: 0.750802]\n",
      "epoch:11 step:8807 [D loss: 0.722098, acc.: 50.00%] [G loss: 0.708359]\n",
      "epoch:11 step:8808 [D loss: 0.699392, acc.: 56.25%] [G loss: 0.780991]\n",
      "epoch:11 step:8809 [D loss: 0.700613, acc.: 46.88%] [G loss: 0.772208]\n",
      "epoch:11 step:8810 [D loss: 0.691944, acc.: 53.91%] [G loss: 0.826105]\n",
      "epoch:11 step:8811 [D loss: 0.718363, acc.: 43.75%] [G loss: 0.710781]\n",
      "epoch:11 step:8812 [D loss: 0.686479, acc.: 58.59%] [G loss: 0.855198]\n",
      "epoch:11 step:8813 [D loss: 0.667312, acc.: 57.03%] [G loss: 0.799325]\n",
      "epoch:11 step:8814 [D loss: 0.658413, acc.: 56.25%] [G loss: 0.775720]\n",
      "epoch:11 step:8815 [D loss: 0.733331, acc.: 38.28%] [G loss: 0.754499]\n",
      "epoch:11 step:8816 [D loss: 0.675982, acc.: 58.59%] [G loss: 0.788335]\n",
      "epoch:11 step:8817 [D loss: 0.693962, acc.: 59.38%] [G loss: 0.785645]\n",
      "epoch:11 step:8818 [D loss: 0.684972, acc.: 53.91%] [G loss: 0.751265]\n",
      "epoch:11 step:8819 [D loss: 0.695886, acc.: 58.59%] [G loss: 0.733725]\n",
      "epoch:11 step:8820 [D loss: 0.696093, acc.: 50.78%] [G loss: 0.717960]\n",
      "epoch:11 step:8821 [D loss: 0.690611, acc.: 58.59%] [G loss: 0.743823]\n",
      "epoch:11 step:8822 [D loss: 0.624976, acc.: 71.09%] [G loss: 0.781246]\n",
      "epoch:11 step:8823 [D loss: 0.773313, acc.: 39.84%] [G loss: 0.737677]\n",
      "epoch:11 step:8824 [D loss: 0.657078, acc.: 55.47%] [G loss: 0.705197]\n",
      "epoch:11 step:8825 [D loss: 0.761274, acc.: 35.16%] [G loss: 0.770079]\n",
      "epoch:11 step:8826 [D loss: 0.763338, acc.: 43.75%] [G loss: 0.654954]\n",
      "epoch:11 step:8827 [D loss: 0.663810, acc.: 58.59%] [G loss: 0.664881]\n",
      "epoch:11 step:8828 [D loss: 0.724037, acc.: 42.19%] [G loss: 0.684519]\n",
      "epoch:11 step:8829 [D loss: 0.654210, acc.: 60.16%] [G loss: 0.707725]\n",
      "epoch:11 step:8830 [D loss: 0.717017, acc.: 52.34%] [G loss: 0.806393]\n",
      "epoch:11 step:8831 [D loss: 0.696694, acc.: 51.56%] [G loss: 0.715513]\n",
      "epoch:11 step:8832 [D loss: 0.704620, acc.: 47.66%] [G loss: 0.775045]\n",
      "epoch:11 step:8833 [D loss: 0.776107, acc.: 38.28%] [G loss: 0.740225]\n",
      "epoch:11 step:8834 [D loss: 0.713959, acc.: 50.00%] [G loss: 0.773697]\n",
      "epoch:11 step:8835 [D loss: 0.719580, acc.: 48.44%] [G loss: 0.750763]\n",
      "epoch:11 step:8836 [D loss: 0.717204, acc.: 47.66%] [G loss: 0.726654]\n",
      "epoch:11 step:8837 [D loss: 0.734015, acc.: 44.53%] [G loss: 0.743510]\n",
      "epoch:11 step:8838 [D loss: 0.690346, acc.: 56.25%] [G loss: 0.764964]\n",
      "epoch:11 step:8839 [D loss: 0.700810, acc.: 48.44%] [G loss: 0.803942]\n",
      "epoch:11 step:8840 [D loss: 0.679305, acc.: 57.81%] [G loss: 0.810589]\n",
      "epoch:11 step:8841 [D loss: 0.650244, acc.: 60.16%] [G loss: 0.857468]\n",
      "epoch:11 step:8842 [D loss: 0.683147, acc.: 56.25%] [G loss: 0.819607]\n",
      "epoch:11 step:8843 [D loss: 0.689187, acc.: 51.56%] [G loss: 0.826697]\n",
      "epoch:11 step:8844 [D loss: 0.706108, acc.: 49.22%] [G loss: 0.784537]\n",
      "epoch:11 step:8845 [D loss: 0.692029, acc.: 45.31%] [G loss: 0.783011]\n",
      "epoch:11 step:8846 [D loss: 0.607911, acc.: 73.44%] [G loss: 0.763057]\n",
      "epoch:11 step:8847 [D loss: 0.730591, acc.: 42.97%] [G loss: 0.737412]\n",
      "epoch:11 step:8848 [D loss: 0.594969, acc.: 77.34%] [G loss: 0.797580]\n",
      "epoch:11 step:8849 [D loss: 0.672001, acc.: 60.94%] [G loss: 0.734456]\n",
      "epoch:11 step:8850 [D loss: 0.709041, acc.: 45.31%] [G loss: 0.746256]\n",
      "epoch:11 step:8851 [D loss: 0.715634, acc.: 54.69%] [G loss: 0.726831]\n",
      "epoch:11 step:8852 [D loss: 0.686956, acc.: 51.56%] [G loss: 0.829311]\n",
      "epoch:11 step:8853 [D loss: 0.706213, acc.: 46.88%] [G loss: 0.887788]\n",
      "epoch:11 step:8854 [D loss: 0.707894, acc.: 49.22%] [G loss: 0.820693]\n",
      "epoch:11 step:8855 [D loss: 0.681818, acc.: 60.16%] [G loss: 0.794976]\n",
      "epoch:11 step:8856 [D loss: 0.660068, acc.: 61.72%] [G loss: 0.820276]\n",
      "epoch:11 step:8857 [D loss: 0.742700, acc.: 43.75%] [G loss: 0.765316]\n",
      "epoch:11 step:8858 [D loss: 0.759827, acc.: 39.06%] [G loss: 0.767702]\n",
      "epoch:11 step:8859 [D loss: 0.670121, acc.: 61.72%] [G loss: 0.691915]\n",
      "epoch:11 step:8860 [D loss: 0.738212, acc.: 42.19%] [G loss: 0.816630]\n",
      "epoch:11 step:8861 [D loss: 0.711624, acc.: 49.22%] [G loss: 0.779105]\n",
      "epoch:11 step:8862 [D loss: 0.736432, acc.: 42.97%] [G loss: 0.770402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8863 [D loss: 0.705681, acc.: 51.56%] [G loss: 0.759817]\n",
      "epoch:11 step:8864 [D loss: 0.678309, acc.: 58.59%] [G loss: 0.801349]\n",
      "epoch:11 step:8865 [D loss: 0.650213, acc.: 69.53%] [G loss: 0.789417]\n",
      "epoch:11 step:8866 [D loss: 0.684474, acc.: 57.03%] [G loss: 0.695675]\n",
      "epoch:11 step:8867 [D loss: 0.647897, acc.: 61.72%] [G loss: 0.713277]\n",
      "epoch:11 step:8868 [D loss: 0.698436, acc.: 53.12%] [G loss: 0.685164]\n",
      "epoch:11 step:8869 [D loss: 0.633099, acc.: 67.97%] [G loss: 0.735146]\n",
      "epoch:11 step:8870 [D loss: 0.743189, acc.: 46.09%] [G loss: 0.772063]\n",
      "epoch:11 step:8871 [D loss: 0.692372, acc.: 53.91%] [G loss: 0.713401]\n",
      "epoch:11 step:8872 [D loss: 0.713837, acc.: 44.53%] [G loss: 0.723645]\n",
      "epoch:11 step:8873 [D loss: 0.683696, acc.: 58.59%] [G loss: 0.723279]\n",
      "epoch:11 step:8874 [D loss: 0.711293, acc.: 47.66%] [G loss: 0.750053]\n",
      "epoch:11 step:8875 [D loss: 0.708409, acc.: 50.00%] [G loss: 0.686427]\n",
      "epoch:11 step:8876 [D loss: 0.708447, acc.: 52.34%] [G loss: 0.742038]\n",
      "epoch:11 step:8877 [D loss: 0.651307, acc.: 61.72%] [G loss: 0.816336]\n",
      "epoch:11 step:8878 [D loss: 0.778476, acc.: 31.25%] [G loss: 0.781948]\n",
      "epoch:11 step:8879 [D loss: 0.695479, acc.: 52.34%] [G loss: 0.802754]\n",
      "epoch:11 step:8880 [D loss: 0.686220, acc.: 55.47%] [G loss: 0.753054]\n",
      "epoch:11 step:8881 [D loss: 0.726575, acc.: 45.31%] [G loss: 0.780496]\n",
      "epoch:11 step:8882 [D loss: 0.724636, acc.: 48.44%] [G loss: 0.743836]\n",
      "epoch:11 step:8883 [D loss: 0.707829, acc.: 50.78%] [G loss: 0.795229]\n",
      "epoch:11 step:8884 [D loss: 0.675978, acc.: 64.06%] [G loss: 0.809118]\n",
      "epoch:11 step:8885 [D loss: 0.660966, acc.: 61.72%] [G loss: 0.899128]\n",
      "epoch:11 step:8886 [D loss: 0.700481, acc.: 51.56%] [G loss: 0.829628]\n",
      "epoch:11 step:8887 [D loss: 0.704230, acc.: 53.12%] [G loss: 0.826796]\n",
      "epoch:11 step:8888 [D loss: 0.662460, acc.: 60.94%] [G loss: 0.800409]\n",
      "epoch:11 step:8889 [D loss: 0.716586, acc.: 46.88%] [G loss: 0.839613]\n",
      "epoch:11 step:8890 [D loss: 0.645653, acc.: 65.62%] [G loss: 0.873070]\n",
      "epoch:11 step:8891 [D loss: 0.625069, acc.: 67.19%] [G loss: 0.842039]\n",
      "epoch:11 step:8892 [D loss: 0.670370, acc.: 59.38%] [G loss: 0.748332]\n",
      "epoch:11 step:8893 [D loss: 0.615113, acc.: 73.44%] [G loss: 0.772978]\n",
      "epoch:11 step:8894 [D loss: 0.677694, acc.: 55.47%] [G loss: 0.739379]\n",
      "epoch:11 step:8895 [D loss: 0.649815, acc.: 64.06%] [G loss: 0.779689]\n",
      "epoch:11 step:8896 [D loss: 0.638835, acc.: 66.41%] [G loss: 0.746425]\n",
      "epoch:11 step:8897 [D loss: 0.650133, acc.: 67.97%] [G loss: 0.781973]\n",
      "epoch:11 step:8898 [D loss: 0.653628, acc.: 60.94%] [G loss: 0.735450]\n",
      "epoch:11 step:8899 [D loss: 0.705443, acc.: 51.56%] [G loss: 0.637203]\n",
      "epoch:11 step:8900 [D loss: 0.580474, acc.: 69.53%] [G loss: 0.806680]\n",
      "epoch:11 step:8901 [D loss: 0.712336, acc.: 51.56%] [G loss: 0.637557]\n",
      "epoch:11 step:8902 [D loss: 0.695300, acc.: 53.12%] [G loss: 0.630430]\n",
      "epoch:11 step:8903 [D loss: 0.823291, acc.: 35.16%] [G loss: 0.594801]\n",
      "epoch:11 step:8904 [D loss: 0.766956, acc.: 40.62%] [G loss: 0.597076]\n",
      "epoch:11 step:8905 [D loss: 0.705782, acc.: 52.34%] [G loss: 0.756024]\n",
      "epoch:11 step:8906 [D loss: 0.803174, acc.: 39.06%] [G loss: 0.724755]\n",
      "epoch:11 step:8907 [D loss: 0.737382, acc.: 45.31%] [G loss: 0.752643]\n",
      "epoch:11 step:8908 [D loss: 0.689562, acc.: 57.03%] [G loss: 0.723035]\n",
      "epoch:11 step:8909 [D loss: 0.669602, acc.: 57.03%] [G loss: 0.818266]\n",
      "epoch:11 step:8910 [D loss: 0.723382, acc.: 42.19%] [G loss: 0.845592]\n",
      "epoch:11 step:8911 [D loss: 0.734497, acc.: 43.75%] [G loss: 0.830998]\n",
      "epoch:11 step:8912 [D loss: 0.665225, acc.: 57.81%] [G loss: 0.868823]\n",
      "epoch:11 step:8913 [D loss: 0.683595, acc.: 53.91%] [G loss: 0.784179]\n",
      "epoch:11 step:8914 [D loss: 0.681995, acc.: 51.56%] [G loss: 0.853444]\n",
      "epoch:11 step:8915 [D loss: 0.683108, acc.: 54.69%] [G loss: 0.759492]\n",
      "epoch:11 step:8916 [D loss: 0.626455, acc.: 70.31%] [G loss: 0.831441]\n",
      "epoch:11 step:8917 [D loss: 0.660651, acc.: 60.94%] [G loss: 0.818424]\n",
      "epoch:11 step:8918 [D loss: 0.624008, acc.: 69.53%] [G loss: 0.747977]\n",
      "epoch:11 step:8919 [D loss: 0.624346, acc.: 65.62%] [G loss: 0.843844]\n",
      "epoch:11 step:8920 [D loss: 0.652181, acc.: 60.94%] [G loss: 0.663383]\n",
      "epoch:11 step:8921 [D loss: 0.706932, acc.: 47.66%] [G loss: 0.716109]\n",
      "epoch:11 step:8922 [D loss: 0.670071, acc.: 56.25%] [G loss: 0.707663]\n",
      "epoch:11 step:8923 [D loss: 0.704082, acc.: 52.34%] [G loss: 0.746003]\n",
      "epoch:11 step:8924 [D loss: 0.725271, acc.: 42.97%] [G loss: 0.736139]\n",
      "epoch:11 step:8925 [D loss: 0.774119, acc.: 40.62%] [G loss: 0.743161]\n",
      "epoch:11 step:8926 [D loss: 0.669133, acc.: 56.25%] [G loss: 0.818992]\n",
      "epoch:11 step:8927 [D loss: 0.730814, acc.: 46.09%] [G loss: 0.846875]\n",
      "epoch:11 step:8928 [D loss: 0.687673, acc.: 57.03%] [G loss: 0.701846]\n",
      "epoch:11 step:8929 [D loss: 0.630312, acc.: 67.19%] [G loss: 0.748547]\n",
      "epoch:11 step:8930 [D loss: 0.750485, acc.: 35.16%] [G loss: 0.734618]\n",
      "epoch:11 step:8931 [D loss: 0.724634, acc.: 46.88%] [G loss: 0.665531]\n",
      "epoch:11 step:8932 [D loss: 0.706475, acc.: 50.78%] [G loss: 0.817000]\n",
      "epoch:11 step:8933 [D loss: 0.741646, acc.: 38.28%] [G loss: 0.731740]\n",
      "epoch:11 step:8934 [D loss: 0.706481, acc.: 47.66%] [G loss: 0.762813]\n",
      "epoch:11 step:8935 [D loss: 0.735142, acc.: 42.19%] [G loss: 0.773900]\n",
      "epoch:11 step:8936 [D loss: 0.761636, acc.: 39.84%] [G loss: 0.742063]\n",
      "epoch:11 step:8937 [D loss: 0.726631, acc.: 46.88%] [G loss: 0.726097]\n",
      "epoch:11 step:8938 [D loss: 0.690001, acc.: 60.16%] [G loss: 0.813323]\n",
      "epoch:11 step:8939 [D loss: 0.677884, acc.: 53.12%] [G loss: 0.846721]\n",
      "epoch:11 step:8940 [D loss: 0.695136, acc.: 53.12%] [G loss: 0.843441]\n",
      "epoch:11 step:8941 [D loss: 0.744123, acc.: 44.53%] [G loss: 0.778350]\n",
      "epoch:11 step:8942 [D loss: 0.706447, acc.: 51.56%] [G loss: 0.786960]\n",
      "epoch:11 step:8943 [D loss: 0.668696, acc.: 60.94%] [G loss: 0.895932]\n",
      "epoch:11 step:8944 [D loss: 0.695374, acc.: 55.47%] [G loss: 0.774178]\n",
      "epoch:11 step:8945 [D loss: 0.676844, acc.: 54.69%] [G loss: 0.835686]\n",
      "epoch:11 step:8946 [D loss: 0.697278, acc.: 50.78%] [G loss: 0.800024]\n",
      "epoch:11 step:8947 [D loss: 0.698564, acc.: 52.34%] [G loss: 0.730444]\n",
      "epoch:11 step:8948 [D loss: 0.653184, acc.: 60.16%] [G loss: 0.770011]\n",
      "epoch:11 step:8949 [D loss: 0.609748, acc.: 67.97%] [G loss: 0.791486]\n",
      "epoch:11 step:8950 [D loss: 0.618631, acc.: 74.22%] [G loss: 0.755715]\n",
      "epoch:11 step:8951 [D loss: 0.666532, acc.: 57.81%] [G loss: 0.730923]\n",
      "epoch:11 step:8952 [D loss: 0.656011, acc.: 56.25%] [G loss: 0.700964]\n",
      "epoch:11 step:8953 [D loss: 0.595537, acc.: 76.56%] [G loss: 0.768566]\n",
      "epoch:11 step:8954 [D loss: 0.684130, acc.: 59.38%] [G loss: 0.710247]\n",
      "epoch:11 step:8955 [D loss: 0.647543, acc.: 63.28%] [G loss: 0.687985]\n",
      "epoch:11 step:8956 [D loss: 0.693912, acc.: 56.25%] [G loss: 0.673665]\n",
      "epoch:11 step:8957 [D loss: 0.698347, acc.: 50.00%] [G loss: 0.620014]\n",
      "epoch:11 step:8958 [D loss: 0.656716, acc.: 61.72%] [G loss: 0.694986]\n",
      "epoch:11 step:8959 [D loss: 0.667239, acc.: 57.03%] [G loss: 0.827052]\n",
      "epoch:11 step:8960 [D loss: 0.745748, acc.: 40.62%] [G loss: 0.606197]\n",
      "epoch:11 step:8961 [D loss: 0.713417, acc.: 50.00%] [G loss: 0.674205]\n",
      "epoch:11 step:8962 [D loss: 0.726548, acc.: 47.66%] [G loss: 0.662579]\n",
      "epoch:11 step:8963 [D loss: 0.741280, acc.: 46.88%] [G loss: 0.715514]\n",
      "epoch:11 step:8964 [D loss: 0.692388, acc.: 53.12%] [G loss: 0.780700]\n",
      "epoch:11 step:8965 [D loss: 0.760743, acc.: 38.28%] [G loss: 0.799701]\n",
      "epoch:11 step:8966 [D loss: 0.748832, acc.: 42.19%] [G loss: 0.730419]\n",
      "epoch:11 step:8967 [D loss: 0.747742, acc.: 37.50%] [G loss: 0.779059]\n",
      "epoch:11 step:8968 [D loss: 0.687848, acc.: 57.81%] [G loss: 0.788655]\n",
      "epoch:11 step:8969 [D loss: 0.702440, acc.: 55.47%] [G loss: 0.762346]\n",
      "epoch:11 step:8970 [D loss: 0.690216, acc.: 53.12%] [G loss: 0.747861]\n",
      "epoch:11 step:8971 [D loss: 0.720281, acc.: 50.78%] [G loss: 0.820045]\n",
      "epoch:11 step:8972 [D loss: 0.655115, acc.: 61.72%] [G loss: 0.737833]\n",
      "epoch:11 step:8973 [D loss: 0.713187, acc.: 50.00%] [G loss: 0.770617]\n",
      "epoch:11 step:8974 [D loss: 0.646710, acc.: 63.28%] [G loss: 0.753114]\n",
      "epoch:11 step:8975 [D loss: 0.628573, acc.: 65.62%] [G loss: 0.852885]\n",
      "epoch:11 step:8976 [D loss: 0.703562, acc.: 53.91%] [G loss: 0.714376]\n",
      "epoch:11 step:8977 [D loss: 0.636247, acc.: 67.19%] [G loss: 0.749640]\n",
      "epoch:11 step:8978 [D loss: 0.694734, acc.: 51.56%] [G loss: 0.745368]\n",
      "epoch:11 step:8979 [D loss: 0.697118, acc.: 53.12%] [G loss: 0.744190]\n",
      "epoch:11 step:8980 [D loss: 0.680131, acc.: 53.91%] [G loss: 0.691481]\n",
      "epoch:11 step:8981 [D loss: 0.707123, acc.: 50.78%] [G loss: 0.723447]\n",
      "epoch:11 step:8982 [D loss: 0.641305, acc.: 65.62%] [G loss: 0.657106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8983 [D loss: 0.757343, acc.: 42.19%] [G loss: 0.606598]\n",
      "epoch:11 step:8984 [D loss: 0.663802, acc.: 65.62%] [G loss: 0.618409]\n",
      "epoch:11 step:8985 [D loss: 0.656100, acc.: 60.94%] [G loss: 0.591695]\n",
      "epoch:11 step:8986 [D loss: 0.772878, acc.: 36.72%] [G loss: 0.661552]\n",
      "epoch:11 step:8987 [D loss: 0.673184, acc.: 58.59%] [G loss: 0.749481]\n",
      "epoch:11 step:8988 [D loss: 0.654906, acc.: 60.16%] [G loss: 0.724209]\n",
      "epoch:11 step:8989 [D loss: 0.715977, acc.: 46.09%] [G loss: 0.770278]\n",
      "epoch:11 step:8990 [D loss: 0.701062, acc.: 51.56%] [G loss: 0.730781]\n",
      "epoch:11 step:8991 [D loss: 0.772943, acc.: 42.19%] [G loss: 0.699062]\n",
      "epoch:11 step:8992 [D loss: 0.705277, acc.: 55.47%] [G loss: 0.721121]\n",
      "epoch:11 step:8993 [D loss: 0.737995, acc.: 46.09%] [G loss: 0.782310]\n",
      "epoch:11 step:8994 [D loss: 0.680202, acc.: 57.81%] [G loss: 0.765791]\n",
      "epoch:11 step:8995 [D loss: 0.719148, acc.: 46.88%] [G loss: 0.822921]\n",
      "epoch:11 step:8996 [D loss: 0.709008, acc.: 49.22%] [G loss: 0.830717]\n",
      "epoch:11 step:8997 [D loss: 0.625196, acc.: 64.84%] [G loss: 0.869629]\n",
      "epoch:11 step:8998 [D loss: 0.748633, acc.: 44.53%] [G loss: 0.825155]\n",
      "epoch:11 step:8999 [D loss: 0.714716, acc.: 50.00%] [G loss: 0.778546]\n",
      "epoch:11 step:9000 [D loss: 0.709661, acc.: 52.34%] [G loss: 0.760135]\n",
      "epoch:11 step:9001 [D loss: 0.649301, acc.: 65.62%] [G loss: 0.909952]\n",
      "epoch:11 step:9002 [D loss: 0.715368, acc.: 55.47%] [G loss: 0.773485]\n",
      "epoch:11 step:9003 [D loss: 0.664483, acc.: 57.03%] [G loss: 0.777369]\n",
      "epoch:11 step:9004 [D loss: 0.609350, acc.: 74.22%] [G loss: 0.814096]\n",
      "epoch:11 step:9005 [D loss: 0.705318, acc.: 50.78%] [G loss: 0.727123]\n",
      "epoch:11 step:9006 [D loss: 0.726998, acc.: 46.09%] [G loss: 0.722542]\n",
      "epoch:11 step:9007 [D loss: 0.620533, acc.: 70.31%] [G loss: 0.742763]\n",
      "epoch:11 step:9008 [D loss: 0.678810, acc.: 60.94%] [G loss: 0.746916]\n",
      "epoch:11 step:9009 [D loss: 0.628077, acc.: 72.66%] [G loss: 0.724779]\n",
      "epoch:11 step:9010 [D loss: 0.715243, acc.: 45.31%] [G loss: 0.738342]\n",
      "epoch:11 step:9011 [D loss: 0.797831, acc.: 31.25%] [G loss: 0.720028]\n",
      "epoch:11 step:9012 [D loss: 0.633449, acc.: 68.75%] [G loss: 0.745489]\n",
      "epoch:11 step:9013 [D loss: 0.727332, acc.: 43.75%] [G loss: 0.768510]\n",
      "epoch:11 step:9014 [D loss: 0.710221, acc.: 47.66%] [G loss: 0.750664]\n",
      "epoch:11 step:9015 [D loss: 0.788149, acc.: 32.81%] [G loss: 0.665597]\n",
      "epoch:11 step:9016 [D loss: 0.712881, acc.: 50.00%] [G loss: 0.724828]\n",
      "epoch:11 step:9017 [D loss: 0.746561, acc.: 42.97%] [G loss: 0.692206]\n",
      "epoch:11 step:9018 [D loss: 0.686655, acc.: 54.69%] [G loss: 0.704417]\n",
      "epoch:11 step:9019 [D loss: 0.801552, acc.: 37.50%] [G loss: 0.695832]\n",
      "epoch:11 step:9020 [D loss: 0.685163, acc.: 56.25%] [G loss: 0.850046]\n",
      "epoch:11 step:9021 [D loss: 0.624384, acc.: 67.19%] [G loss: 0.883905]\n",
      "epoch:11 step:9022 [D loss: 0.688830, acc.: 50.78%] [G loss: 0.949746]\n",
      "epoch:11 step:9023 [D loss: 0.678942, acc.: 62.50%] [G loss: 0.861596]\n",
      "epoch:11 step:9024 [D loss: 0.680466, acc.: 59.38%] [G loss: 0.960927]\n",
      "epoch:11 step:9025 [D loss: 0.636037, acc.: 72.66%] [G loss: 0.859774]\n",
      "epoch:11 step:9026 [D loss: 0.670635, acc.: 61.72%] [G loss: 0.782511]\n",
      "epoch:11 step:9027 [D loss: 0.701728, acc.: 45.31%] [G loss: 0.858964]\n",
      "epoch:11 step:9028 [D loss: 0.720134, acc.: 42.97%] [G loss: 0.679066]\n",
      "epoch:11 step:9029 [D loss: 0.684568, acc.: 53.12%] [G loss: 0.750125]\n",
      "epoch:11 step:9030 [D loss: 0.737980, acc.: 39.84%] [G loss: 0.726246]\n",
      "epoch:11 step:9031 [D loss: 0.671845, acc.: 58.59%] [G loss: 0.746434]\n",
      "epoch:11 step:9032 [D loss: 0.717751, acc.: 49.22%] [G loss: 0.686516]\n",
      "epoch:11 step:9033 [D loss: 0.747914, acc.: 38.28%] [G loss: 0.708588]\n",
      "epoch:11 step:9034 [D loss: 0.684068, acc.: 50.78%] [G loss: 0.730440]\n",
      "epoch:11 step:9035 [D loss: 0.726143, acc.: 45.31%] [G loss: 0.682091]\n",
      "epoch:11 step:9036 [D loss: 0.724435, acc.: 48.44%] [G loss: 0.760276]\n",
      "epoch:11 step:9037 [D loss: 0.748561, acc.: 34.38%] [G loss: 0.724870]\n",
      "epoch:11 step:9038 [D loss: 0.722567, acc.: 47.66%] [G loss: 0.792458]\n",
      "epoch:11 step:9039 [D loss: 0.728758, acc.: 37.50%] [G loss: 0.754762]\n",
      "epoch:11 step:9040 [D loss: 0.697964, acc.: 53.12%] [G loss: 0.747315]\n",
      "epoch:11 step:9041 [D loss: 0.722915, acc.: 39.84%] [G loss: 0.805297]\n",
      "epoch:11 step:9042 [D loss: 0.740963, acc.: 41.41%] [G loss: 0.790805]\n",
      "epoch:11 step:9043 [D loss: 0.658960, acc.: 65.62%] [G loss: 0.830851]\n",
      "epoch:11 step:9044 [D loss: 0.687934, acc.: 53.12%] [G loss: 0.850686]\n",
      "epoch:11 step:9045 [D loss: 0.704128, acc.: 53.12%] [G loss: 0.764632]\n",
      "epoch:11 step:9046 [D loss: 0.704510, acc.: 46.88%] [G loss: 0.811349]\n",
      "epoch:11 step:9047 [D loss: 0.735075, acc.: 42.97%] [G loss: 0.716993]\n",
      "epoch:11 step:9048 [D loss: 0.636618, acc.: 64.84%] [G loss: 0.853547]\n",
      "epoch:11 step:9049 [D loss: 0.681650, acc.: 55.47%] [G loss: 0.786519]\n",
      "epoch:11 step:9050 [D loss: 0.685179, acc.: 53.12%] [G loss: 0.790889]\n",
      "epoch:11 step:9051 [D loss: 0.751910, acc.: 41.41%] [G loss: 0.729926]\n",
      "epoch:11 step:9052 [D loss: 0.625959, acc.: 66.41%] [G loss: 0.874884]\n",
      "epoch:11 step:9053 [D loss: 0.654041, acc.: 64.06%] [G loss: 0.782291]\n",
      "epoch:11 step:9054 [D loss: 0.698018, acc.: 45.31%] [G loss: 0.791344]\n",
      "epoch:11 step:9055 [D loss: 0.710604, acc.: 49.22%] [G loss: 0.822124]\n",
      "epoch:11 step:9056 [D loss: 0.615940, acc.: 72.66%] [G loss: 0.781029]\n",
      "epoch:11 step:9057 [D loss: 0.658531, acc.: 55.47%] [G loss: 0.779387]\n",
      "epoch:11 step:9058 [D loss: 0.689044, acc.: 46.09%] [G loss: 0.708593]\n",
      "epoch:11 step:9059 [D loss: 0.702242, acc.: 52.34%] [G loss: 0.773632]\n",
      "epoch:11 step:9060 [D loss: 0.694019, acc.: 56.25%] [G loss: 0.771897]\n",
      "epoch:11 step:9061 [D loss: 0.680355, acc.: 55.47%] [G loss: 0.728361]\n",
      "epoch:11 step:9062 [D loss: 0.683150, acc.: 60.16%] [G loss: 0.707846]\n",
      "epoch:11 step:9063 [D loss: 0.758728, acc.: 42.97%] [G loss: 0.774620]\n",
      "epoch:11 step:9064 [D loss: 0.824427, acc.: 33.59%] [G loss: 0.709306]\n",
      "epoch:11 step:9065 [D loss: 0.709689, acc.: 49.22%] [G loss: 0.730310]\n",
      "epoch:11 step:9066 [D loss: 0.725020, acc.: 41.41%] [G loss: 0.761756]\n",
      "epoch:11 step:9067 [D loss: 0.707970, acc.: 52.34%] [G loss: 0.701508]\n",
      "epoch:11 step:9068 [D loss: 0.720179, acc.: 49.22%] [G loss: 0.775230]\n",
      "epoch:11 step:9069 [D loss: 0.689808, acc.: 62.50%] [G loss: 0.831671]\n",
      "epoch:11 step:9070 [D loss: 0.695893, acc.: 52.34%] [G loss: 0.801169]\n",
      "epoch:11 step:9071 [D loss: 0.647259, acc.: 65.62%] [G loss: 0.817963]\n",
      "epoch:11 step:9072 [D loss: 0.682261, acc.: 57.03%] [G loss: 0.788061]\n",
      "epoch:11 step:9073 [D loss: 0.754448, acc.: 41.41%] [G loss: 0.782741]\n",
      "epoch:11 step:9074 [D loss: 0.699818, acc.: 46.09%] [G loss: 0.765607]\n",
      "epoch:11 step:9075 [D loss: 0.745378, acc.: 39.06%] [G loss: 0.627427]\n",
      "epoch:11 step:9076 [D loss: 0.683603, acc.: 54.69%] [G loss: 0.774475]\n",
      "epoch:11 step:9077 [D loss: 0.661231, acc.: 63.28%] [G loss: 0.786774]\n",
      "epoch:11 step:9078 [D loss: 0.690249, acc.: 57.03%] [G loss: 0.722549]\n",
      "epoch:11 step:9079 [D loss: 0.705099, acc.: 53.12%] [G loss: 0.800122]\n",
      "epoch:11 step:9080 [D loss: 0.640732, acc.: 64.84%] [G loss: 0.733390]\n",
      "epoch:11 step:9081 [D loss: 0.674714, acc.: 56.25%] [G loss: 0.724204]\n",
      "epoch:11 step:9082 [D loss: 0.661642, acc.: 58.59%] [G loss: 0.771061]\n",
      "epoch:11 step:9083 [D loss: 0.679972, acc.: 53.91%] [G loss: 0.792199]\n",
      "epoch:11 step:9084 [D loss: 0.674051, acc.: 57.81%] [G loss: 0.730659]\n",
      "epoch:11 step:9085 [D loss: 0.689268, acc.: 56.25%] [G loss: 0.788931]\n",
      "epoch:11 step:9086 [D loss: 0.689683, acc.: 52.34%] [G loss: 0.814242]\n",
      "epoch:11 step:9087 [D loss: 0.738162, acc.: 41.41%] [G loss: 0.762947]\n",
      "epoch:11 step:9088 [D loss: 0.681981, acc.: 58.59%] [G loss: 0.708222]\n",
      "epoch:11 step:9089 [D loss: 0.666891, acc.: 61.72%] [G loss: 0.774629]\n",
      "epoch:11 step:9090 [D loss: 0.696493, acc.: 52.34%] [G loss: 0.763944]\n",
      "epoch:11 step:9091 [D loss: 0.679894, acc.: 57.03%] [G loss: 0.838573]\n",
      "epoch:11 step:9092 [D loss: 0.703442, acc.: 55.47%] [G loss: 0.808010]\n",
      "epoch:11 step:9093 [D loss: 0.694638, acc.: 53.12%] [G loss: 0.810866]\n",
      "epoch:11 step:9094 [D loss: 0.735244, acc.: 43.75%] [G loss: 0.777533]\n",
      "epoch:11 step:9095 [D loss: 0.668235, acc.: 57.03%] [G loss: 0.780352]\n",
      "epoch:11 step:9096 [D loss: 0.665671, acc.: 65.62%] [G loss: 0.808802]\n",
      "epoch:11 step:9097 [D loss: 0.725513, acc.: 46.09%] [G loss: 0.797693]\n",
      "epoch:11 step:9098 [D loss: 0.687191, acc.: 53.12%] [G loss: 0.754639]\n",
      "epoch:11 step:9099 [D loss: 0.703086, acc.: 56.25%] [G loss: 0.741234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9100 [D loss: 0.689893, acc.: 53.12%] [G loss: 0.824347]\n",
      "epoch:11 step:9101 [D loss: 0.678447, acc.: 51.56%] [G loss: 0.748173]\n",
      "epoch:11 step:9102 [D loss: 0.716100, acc.: 46.09%] [G loss: 0.781793]\n",
      "epoch:11 step:9103 [D loss: 0.722830, acc.: 46.88%] [G loss: 0.811211]\n",
      "epoch:11 step:9104 [D loss: 0.647602, acc.: 66.41%] [G loss: 0.817191]\n",
      "epoch:11 step:9105 [D loss: 0.700308, acc.: 53.91%] [G loss: 0.687490]\n",
      "epoch:11 step:9106 [D loss: 0.703664, acc.: 48.44%] [G loss: 0.740844]\n",
      "epoch:11 step:9107 [D loss: 0.650743, acc.: 64.84%] [G loss: 0.688504]\n",
      "epoch:11 step:9108 [D loss: 0.707975, acc.: 52.34%] [G loss: 0.693012]\n",
      "epoch:11 step:9109 [D loss: 0.701592, acc.: 47.66%] [G loss: 0.710482]\n",
      "epoch:11 step:9110 [D loss: 0.670854, acc.: 57.03%] [G loss: 0.748407]\n",
      "epoch:11 step:9111 [D loss: 0.715234, acc.: 50.00%] [G loss: 0.712177]\n",
      "epoch:11 step:9112 [D loss: 0.671956, acc.: 57.81%] [G loss: 0.720691]\n",
      "epoch:11 step:9113 [D loss: 0.729942, acc.: 44.53%] [G loss: 0.742435]\n",
      "epoch:11 step:9114 [D loss: 0.727157, acc.: 47.66%] [G loss: 0.796103]\n",
      "epoch:11 step:9115 [D loss: 0.683055, acc.: 53.91%] [G loss: 0.878542]\n",
      "epoch:11 step:9116 [D loss: 0.730717, acc.: 42.97%] [G loss: 0.746411]\n",
      "epoch:11 step:9117 [D loss: 0.824515, acc.: 28.12%] [G loss: 0.735948]\n",
      "epoch:11 step:9118 [D loss: 0.703668, acc.: 45.31%] [G loss: 0.783626]\n",
      "epoch:11 step:9119 [D loss: 0.717216, acc.: 48.44%] [G loss: 0.770268]\n",
      "epoch:11 step:9120 [D loss: 0.685175, acc.: 53.91%] [G loss: 0.814544]\n",
      "epoch:11 step:9121 [D loss: 0.674442, acc.: 57.03%] [G loss: 0.831816]\n",
      "epoch:11 step:9122 [D loss: 0.672294, acc.: 60.94%] [G loss: 0.779397]\n",
      "epoch:11 step:9123 [D loss: 0.744789, acc.: 44.53%] [G loss: 0.760781]\n",
      "epoch:11 step:9124 [D loss: 0.692013, acc.: 52.34%] [G loss: 0.771976]\n",
      "epoch:11 step:9125 [D loss: 0.705019, acc.: 50.78%] [G loss: 0.826545]\n",
      "epoch:11 step:9126 [D loss: 0.698592, acc.: 57.03%] [G loss: 0.738392]\n",
      "epoch:11 step:9127 [D loss: 0.690706, acc.: 58.59%] [G loss: 0.737746]\n",
      "epoch:11 step:9128 [D loss: 0.693443, acc.: 53.91%] [G loss: 0.728137]\n",
      "epoch:11 step:9129 [D loss: 0.677242, acc.: 55.47%] [G loss: 0.748634]\n",
      "epoch:11 step:9130 [D loss: 0.678134, acc.: 59.38%] [G loss: 0.755595]\n",
      "epoch:11 step:9131 [D loss: 0.686050, acc.: 50.00%] [G loss: 0.712104]\n",
      "epoch:11 step:9132 [D loss: 0.685704, acc.: 54.69%] [G loss: 0.675985]\n",
      "epoch:11 step:9133 [D loss: 0.707348, acc.: 49.22%] [G loss: 0.780150]\n",
      "epoch:11 step:9134 [D loss: 0.653572, acc.: 62.50%] [G loss: 0.770720]\n",
      "epoch:11 step:9135 [D loss: 0.694930, acc.: 50.00%] [G loss: 0.704932]\n",
      "epoch:11 step:9136 [D loss: 0.643917, acc.: 65.62%] [G loss: 0.881754]\n",
      "epoch:11 step:9137 [D loss: 0.791765, acc.: 39.06%] [G loss: 0.756461]\n",
      "epoch:11 step:9138 [D loss: 0.662194, acc.: 57.03%] [G loss: 0.656555]\n",
      "epoch:11 step:9139 [D loss: 0.715579, acc.: 49.22%] [G loss: 0.763603]\n",
      "epoch:11 step:9140 [D loss: 0.748239, acc.: 42.97%] [G loss: 0.762899]\n",
      "epoch:11 step:9141 [D loss: 0.721061, acc.: 50.78%] [G loss: 0.847239]\n",
      "epoch:11 step:9142 [D loss: 0.707358, acc.: 56.25%] [G loss: 0.769070]\n",
      "epoch:11 step:9143 [D loss: 0.775345, acc.: 33.59%] [G loss: 0.770853]\n",
      "epoch:11 step:9144 [D loss: 0.725121, acc.: 43.75%] [G loss: 0.789104]\n",
      "epoch:11 step:9145 [D loss: 0.664353, acc.: 58.59%] [G loss: 0.849860]\n",
      "epoch:11 step:9146 [D loss: 0.740093, acc.: 38.28%] [G loss: 0.800703]\n",
      "epoch:11 step:9147 [D loss: 0.765624, acc.: 37.50%] [G loss: 0.799681]\n",
      "epoch:11 step:9148 [D loss: 0.710111, acc.: 51.56%] [G loss: 0.760673]\n",
      "epoch:11 step:9149 [D loss: 0.733374, acc.: 37.50%] [G loss: 0.800156]\n",
      "epoch:11 step:9150 [D loss: 0.666770, acc.: 57.81%] [G loss: 0.832566]\n",
      "epoch:11 step:9151 [D loss: 0.642184, acc.: 68.75%] [G loss: 0.807112]\n",
      "epoch:11 step:9152 [D loss: 0.721785, acc.: 50.00%] [G loss: 0.767196]\n",
      "epoch:11 step:9153 [D loss: 0.649197, acc.: 64.06%] [G loss: 0.793138]\n",
      "epoch:11 step:9154 [D loss: 0.671136, acc.: 58.59%] [G loss: 0.806515]\n",
      "epoch:11 step:9155 [D loss: 0.724478, acc.: 41.41%] [G loss: 0.805090]\n",
      "epoch:11 step:9156 [D loss: 0.691601, acc.: 54.69%] [G loss: 0.817996]\n",
      "epoch:11 step:9157 [D loss: 0.670582, acc.: 62.50%] [G loss: 0.801726]\n",
      "epoch:11 step:9158 [D loss: 0.707938, acc.: 46.09%] [G loss: 0.667524]\n",
      "epoch:11 step:9159 [D loss: 0.686173, acc.: 57.03%] [G loss: 0.731880]\n",
      "epoch:11 step:9160 [D loss: 0.675750, acc.: 57.81%] [G loss: 0.758988]\n",
      "epoch:11 step:9161 [D loss: 0.717066, acc.: 49.22%] [G loss: 0.769346]\n",
      "epoch:11 step:9162 [D loss: 0.673531, acc.: 61.72%] [G loss: 0.757169]\n",
      "epoch:11 step:9163 [D loss: 0.715250, acc.: 46.09%] [G loss: 0.751435]\n",
      "epoch:11 step:9164 [D loss: 0.663224, acc.: 58.59%] [G loss: 0.724867]\n",
      "epoch:11 step:9165 [D loss: 0.712232, acc.: 47.66%] [G loss: 0.721169]\n",
      "epoch:11 step:9166 [D loss: 0.735852, acc.: 42.97%] [G loss: 0.724456]\n",
      "epoch:11 step:9167 [D loss: 0.689014, acc.: 55.47%] [G loss: 0.722967]\n",
      "epoch:11 step:9168 [D loss: 0.695772, acc.: 51.56%] [G loss: 0.763696]\n",
      "epoch:11 step:9169 [D loss: 0.693958, acc.: 54.69%] [G loss: 0.725795]\n",
      "epoch:11 step:9170 [D loss: 0.705156, acc.: 49.22%] [G loss: 0.793255]\n",
      "epoch:11 step:9171 [D loss: 0.722712, acc.: 49.22%] [G loss: 0.764450]\n",
      "epoch:11 step:9172 [D loss: 0.724054, acc.: 43.75%] [G loss: 0.749104]\n",
      "epoch:11 step:9173 [D loss: 0.726722, acc.: 42.97%] [G loss: 0.760098]\n",
      "epoch:11 step:9174 [D loss: 0.705348, acc.: 48.44%] [G loss: 0.754379]\n",
      "epoch:11 step:9175 [D loss: 0.688352, acc.: 50.78%] [G loss: 0.764898]\n",
      "epoch:11 step:9176 [D loss: 0.693682, acc.: 55.47%] [G loss: 0.753551]\n",
      "epoch:11 step:9177 [D loss: 0.697365, acc.: 49.22%] [G loss: 0.793996]\n",
      "epoch:11 step:9178 [D loss: 0.656943, acc.: 65.62%] [G loss: 0.744964]\n",
      "epoch:11 step:9179 [D loss: 0.681298, acc.: 57.81%] [G loss: 0.731370]\n",
      "epoch:11 step:9180 [D loss: 0.667412, acc.: 60.94%] [G loss: 0.780946]\n",
      "epoch:11 step:9181 [D loss: 0.669495, acc.: 57.81%] [G loss: 0.773227]\n",
      "epoch:11 step:9182 [D loss: 0.663149, acc.: 56.25%] [G loss: 0.776243]\n",
      "epoch:11 step:9183 [D loss: 0.733752, acc.: 45.31%] [G loss: 0.800878]\n",
      "epoch:11 step:9184 [D loss: 0.694503, acc.: 49.22%] [G loss: 0.741369]\n",
      "epoch:11 step:9185 [D loss: 0.670029, acc.: 52.34%] [G loss: 0.780946]\n",
      "epoch:11 step:9186 [D loss: 0.675121, acc.: 61.72%] [G loss: 0.734219]\n",
      "epoch:11 step:9187 [D loss: 0.657204, acc.: 67.97%] [G loss: 0.685274]\n",
      "epoch:11 step:9188 [D loss: 0.648538, acc.: 64.06%] [G loss: 0.753617]\n",
      "epoch:11 step:9189 [D loss: 0.616135, acc.: 72.66%] [G loss: 0.742766]\n",
      "epoch:11 step:9190 [D loss: 0.688337, acc.: 54.69%] [G loss: 0.678185]\n",
      "epoch:11 step:9191 [D loss: 0.688781, acc.: 52.34%] [G loss: 0.744245]\n",
      "epoch:11 step:9192 [D loss: 0.659690, acc.: 60.16%] [G loss: 0.694129]\n",
      "epoch:11 step:9193 [D loss: 0.702765, acc.: 50.78%] [G loss: 0.682366]\n",
      "epoch:11 step:9194 [D loss: 0.717547, acc.: 46.88%] [G loss: 0.756758]\n",
      "epoch:11 step:9195 [D loss: 0.744153, acc.: 41.41%] [G loss: 0.739728]\n",
      "epoch:11 step:9196 [D loss: 0.690921, acc.: 52.34%] [G loss: 0.744674]\n",
      "epoch:11 step:9197 [D loss: 0.710043, acc.: 49.22%] [G loss: 0.793765]\n",
      "epoch:11 step:9198 [D loss: 0.654870, acc.: 67.19%] [G loss: 0.709530]\n",
      "epoch:11 step:9199 [D loss: 0.744788, acc.: 43.75%] [G loss: 0.771079]\n",
      "epoch:11 step:9200 [D loss: 0.776031, acc.: 35.16%] [G loss: 0.736365]\n",
      "epoch:11 step:9201 [D loss: 0.725395, acc.: 43.75%] [G loss: 0.865227]\n",
      "epoch:11 step:9202 [D loss: 0.691540, acc.: 51.56%] [G loss: 0.811842]\n",
      "epoch:11 step:9203 [D loss: 0.716114, acc.: 44.53%] [G loss: 0.823647]\n",
      "epoch:11 step:9204 [D loss: 0.738684, acc.: 47.66%] [G loss: 0.779734]\n",
      "epoch:11 step:9205 [D loss: 0.728990, acc.: 48.44%] [G loss: 0.787477]\n",
      "epoch:11 step:9206 [D loss: 0.711821, acc.: 51.56%] [G loss: 0.822633]\n",
      "epoch:11 step:9207 [D loss: 0.667633, acc.: 56.25%] [G loss: 0.922568]\n",
      "epoch:11 step:9208 [D loss: 0.705126, acc.: 52.34%] [G loss: 0.885298]\n",
      "epoch:11 step:9209 [D loss: 0.637277, acc.: 66.41%] [G loss: 0.887862]\n",
      "epoch:11 step:9210 [D loss: 0.647013, acc.: 65.62%] [G loss: 0.867836]\n",
      "epoch:11 step:9211 [D loss: 0.675695, acc.: 60.94%] [G loss: 0.812487]\n",
      "epoch:11 step:9212 [D loss: 0.643365, acc.: 66.41%] [G loss: 0.817526]\n",
      "epoch:11 step:9213 [D loss: 0.686407, acc.: 59.38%] [G loss: 0.804128]\n",
      "epoch:11 step:9214 [D loss: 0.713527, acc.: 50.78%] [G loss: 0.776513]\n",
      "epoch:11 step:9215 [D loss: 0.641226, acc.: 60.94%] [G loss: 0.744954]\n",
      "epoch:11 step:9216 [D loss: 0.721749, acc.: 51.56%] [G loss: 0.748755]\n",
      "epoch:11 step:9217 [D loss: 0.673053, acc.: 58.59%] [G loss: 0.812306]\n",
      "epoch:11 step:9218 [D loss: 0.664833, acc.: 63.28%] [G loss: 0.740957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9219 [D loss: 0.679318, acc.: 54.69%] [G loss: 0.703793]\n",
      "epoch:11 step:9220 [D loss: 0.721303, acc.: 43.75%] [G loss: 0.691727]\n",
      "epoch:11 step:9221 [D loss: 0.745644, acc.: 37.50%] [G loss: 0.735785]\n",
      "epoch:11 step:9222 [D loss: 0.703186, acc.: 54.69%] [G loss: 0.778997]\n",
      "epoch:11 step:9223 [D loss: 0.701032, acc.: 50.78%] [G loss: 0.690182]\n",
      "epoch:11 step:9224 [D loss: 0.720627, acc.: 47.66%] [G loss: 0.681100]\n",
      "epoch:11 step:9225 [D loss: 0.767727, acc.: 35.16%] [G loss: 0.698700]\n",
      "epoch:11 step:9226 [D loss: 0.700828, acc.: 53.12%] [G loss: 0.767040]\n",
      "epoch:11 step:9227 [D loss: 0.678955, acc.: 60.94%] [G loss: 0.845931]\n",
      "epoch:11 step:9228 [D loss: 0.674122, acc.: 53.91%] [G loss: 0.889422]\n",
      "epoch:11 step:9229 [D loss: 0.715285, acc.: 47.66%] [G loss: 0.815225]\n",
      "epoch:11 step:9230 [D loss: 0.750078, acc.: 37.50%] [G loss: 0.777460]\n",
      "epoch:11 step:9231 [D loss: 0.712321, acc.: 50.78%] [G loss: 0.790309]\n",
      "epoch:11 step:9232 [D loss: 0.671468, acc.: 59.38%] [G loss: 0.811009]\n",
      "epoch:11 step:9233 [D loss: 0.702173, acc.: 45.31%] [G loss: 0.786948]\n",
      "epoch:11 step:9234 [D loss: 0.651293, acc.: 62.50%] [G loss: 0.823234]\n",
      "epoch:11 step:9235 [D loss: 0.670450, acc.: 55.47%] [G loss: 0.793110]\n",
      "epoch:11 step:9236 [D loss: 0.631823, acc.: 66.41%] [G loss: 0.818361]\n",
      "epoch:11 step:9237 [D loss: 0.659776, acc.: 62.50%] [G loss: 0.833319]\n",
      "epoch:11 step:9238 [D loss: 0.687148, acc.: 52.34%] [G loss: 0.760013]\n",
      "epoch:11 step:9239 [D loss: 0.621484, acc.: 67.19%] [G loss: 0.742612]\n",
      "epoch:11 step:9240 [D loss: 0.666560, acc.: 57.03%] [G loss: 0.740135]\n",
      "epoch:11 step:9241 [D loss: 0.612455, acc.: 71.88%] [G loss: 0.677511]\n",
      "epoch:11 step:9242 [D loss: 0.569680, acc.: 78.12%] [G loss: 0.693422]\n",
      "epoch:11 step:9243 [D loss: 0.726982, acc.: 46.88%] [G loss: 0.695813]\n",
      "epoch:11 step:9244 [D loss: 0.675225, acc.: 53.12%] [G loss: 0.636725]\n",
      "epoch:11 step:9245 [D loss: 0.671482, acc.: 55.47%] [G loss: 0.731587]\n",
      "epoch:11 step:9246 [D loss: 0.652867, acc.: 66.41%] [G loss: 0.765671]\n",
      "epoch:11 step:9247 [D loss: 0.745902, acc.: 38.28%] [G loss: 0.814081]\n",
      "epoch:11 step:9248 [D loss: 0.777991, acc.: 38.28%] [G loss: 0.687687]\n",
      "epoch:11 step:9249 [D loss: 0.690695, acc.: 51.56%] [G loss: 0.723973]\n",
      "epoch:11 step:9250 [D loss: 0.695235, acc.: 49.22%] [G loss: 0.812365]\n",
      "epoch:11 step:9251 [D loss: 0.704976, acc.: 48.44%] [G loss: 0.815182]\n",
      "epoch:11 step:9252 [D loss: 0.695267, acc.: 58.59%] [G loss: 0.830471]\n",
      "epoch:11 step:9253 [D loss: 0.669196, acc.: 57.03%] [G loss: 0.875076]\n",
      "epoch:11 step:9254 [D loss: 0.687491, acc.: 57.81%] [G loss: 0.792103]\n",
      "epoch:11 step:9255 [D loss: 0.716772, acc.: 51.56%] [G loss: 0.742137]\n",
      "epoch:11 step:9256 [D loss: 0.653239, acc.: 60.94%] [G loss: 0.823498]\n",
      "epoch:11 step:9257 [D loss: 0.718730, acc.: 46.09%] [G loss: 0.804638]\n",
      "epoch:11 step:9258 [D loss: 0.660896, acc.: 60.94%] [G loss: 0.805034]\n",
      "epoch:11 step:9259 [D loss: 0.690620, acc.: 60.94%] [G loss: 0.821296]\n",
      "epoch:11 step:9260 [D loss: 0.697272, acc.: 51.56%] [G loss: 0.708049]\n",
      "epoch:11 step:9261 [D loss: 0.735402, acc.: 43.75%] [G loss: 0.813242]\n",
      "epoch:11 step:9262 [D loss: 0.726201, acc.: 44.53%] [G loss: 0.824694]\n",
      "epoch:11 step:9263 [D loss: 0.673253, acc.: 59.38%] [G loss: 0.769038]\n",
      "epoch:11 step:9264 [D loss: 0.682831, acc.: 54.69%] [G loss: 0.803831]\n",
      "epoch:11 step:9265 [D loss: 0.714793, acc.: 46.09%] [G loss: 0.827324]\n",
      "epoch:11 step:9266 [D loss: 0.683301, acc.: 57.03%] [G loss: 0.859964]\n",
      "epoch:11 step:9267 [D loss: 0.745665, acc.: 37.50%] [G loss: 0.732952]\n",
      "epoch:11 step:9268 [D loss: 0.671445, acc.: 60.94%] [G loss: 0.827189]\n",
      "epoch:11 step:9269 [D loss: 0.686301, acc.: 52.34%] [G loss: 0.806073]\n",
      "epoch:11 step:9270 [D loss: 0.682828, acc.: 57.03%] [G loss: 0.800003]\n",
      "epoch:11 step:9271 [D loss: 0.703265, acc.: 52.34%] [G loss: 0.802186]\n",
      "epoch:11 step:9272 [D loss: 0.672506, acc.: 60.94%] [G loss: 0.824417]\n",
      "epoch:11 step:9273 [D loss: 0.701786, acc.: 44.53%] [G loss: 0.766742]\n",
      "epoch:11 step:9274 [D loss: 0.706724, acc.: 45.31%] [G loss: 0.761081]\n",
      "epoch:11 step:9275 [D loss: 0.663590, acc.: 64.06%] [G loss: 0.818098]\n",
      "epoch:11 step:9276 [D loss: 0.714151, acc.: 57.81%] [G loss: 0.741875]\n",
      "epoch:11 step:9277 [D loss: 0.728819, acc.: 44.53%] [G loss: 0.733135]\n",
      "epoch:11 step:9278 [D loss: 0.733147, acc.: 41.41%] [G loss: 0.754286]\n",
      "epoch:11 step:9279 [D loss: 0.674078, acc.: 60.16%] [G loss: 0.767934]\n",
      "epoch:11 step:9280 [D loss: 0.697640, acc.: 51.56%] [G loss: 0.751533]\n",
      "epoch:11 step:9281 [D loss: 0.686848, acc.: 57.03%] [G loss: 0.759434]\n",
      "epoch:11 step:9282 [D loss: 0.625513, acc.: 64.84%] [G loss: 0.811749]\n",
      "epoch:11 step:9283 [D loss: 0.789455, acc.: 32.03%] [G loss: 0.747083]\n",
      "epoch:11 step:9284 [D loss: 0.714918, acc.: 52.34%] [G loss: 0.806132]\n",
      "epoch:11 step:9285 [D loss: 0.672753, acc.: 54.69%] [G loss: 0.775218]\n",
      "epoch:11 step:9286 [D loss: 0.673514, acc.: 62.50%] [G loss: 0.772782]\n",
      "epoch:11 step:9287 [D loss: 0.748323, acc.: 32.03%] [G loss: 0.786011]\n",
      "epoch:11 step:9288 [D loss: 0.672674, acc.: 60.94%] [G loss: 0.757366]\n",
      "epoch:11 step:9289 [D loss: 0.720221, acc.: 47.66%] [G loss: 0.773534]\n",
      "epoch:11 step:9290 [D loss: 0.688297, acc.: 51.56%] [G loss: 0.790451]\n",
      "epoch:11 step:9291 [D loss: 0.688117, acc.: 57.03%] [G loss: 0.812145]\n",
      "epoch:11 step:9292 [D loss: 0.685577, acc.: 52.34%] [G loss: 0.806412]\n",
      "epoch:11 step:9293 [D loss: 0.643148, acc.: 66.41%] [G loss: 0.822073]\n",
      "epoch:11 step:9294 [D loss: 0.689180, acc.: 53.91%] [G loss: 0.805409]\n",
      "epoch:11 step:9295 [D loss: 0.667600, acc.: 64.84%] [G loss: 0.739833]\n",
      "epoch:11 step:9296 [D loss: 0.694556, acc.: 49.22%] [G loss: 0.658075]\n",
      "epoch:11 step:9297 [D loss: 0.753231, acc.: 44.53%] [G loss: 0.695980]\n",
      "epoch:11 step:9298 [D loss: 0.718935, acc.: 52.34%] [G loss: 0.706354]\n",
      "epoch:11 step:9299 [D loss: 0.729175, acc.: 46.09%] [G loss: 0.725431]\n",
      "epoch:11 step:9300 [D loss: 0.678555, acc.: 58.59%] [G loss: 0.690437]\n",
      "epoch:11 step:9301 [D loss: 0.718189, acc.: 50.00%] [G loss: 0.768299]\n",
      "epoch:11 step:9302 [D loss: 0.720303, acc.: 49.22%] [G loss: 0.824559]\n",
      "epoch:11 step:9303 [D loss: 0.704312, acc.: 46.88%] [G loss: 0.793815]\n",
      "epoch:11 step:9304 [D loss: 0.667899, acc.: 58.59%] [G loss: 0.778887]\n",
      "epoch:11 step:9305 [D loss: 0.688611, acc.: 54.69%] [G loss: 0.857412]\n",
      "epoch:11 step:9306 [D loss: 0.660938, acc.: 63.28%] [G loss: 0.750921]\n",
      "epoch:11 step:9307 [D loss: 0.654860, acc.: 64.84%] [G loss: 0.865333]\n",
      "epoch:11 step:9308 [D loss: 0.678669, acc.: 59.38%] [G loss: 0.787166]\n",
      "epoch:11 step:9309 [D loss: 0.670249, acc.: 55.47%] [G loss: 0.784832]\n",
      "epoch:11 step:9310 [D loss: 0.718408, acc.: 47.66%] [G loss: 0.753896]\n",
      "epoch:11 step:9311 [D loss: 0.697449, acc.: 56.25%] [G loss: 0.765306]\n",
      "epoch:11 step:9312 [D loss: 0.677568, acc.: 55.47%] [G loss: 0.762752]\n",
      "epoch:11 step:9313 [D loss: 0.626553, acc.: 67.97%] [G loss: 0.785367]\n",
      "epoch:11 step:9314 [D loss: 0.764857, acc.: 39.84%] [G loss: 0.757652]\n",
      "epoch:11 step:9315 [D loss: 0.706603, acc.: 51.56%] [G loss: 0.756007]\n",
      "epoch:11 step:9316 [D loss: 0.710047, acc.: 47.66%] [G loss: 0.768605]\n",
      "epoch:11 step:9317 [D loss: 0.707552, acc.: 51.56%] [G loss: 0.755737]\n",
      "epoch:11 step:9318 [D loss: 0.676811, acc.: 54.69%] [G loss: 0.804115]\n",
      "epoch:11 step:9319 [D loss: 0.690812, acc.: 52.34%] [G loss: 0.763798]\n",
      "epoch:11 step:9320 [D loss: 0.697847, acc.: 52.34%] [G loss: 0.768795]\n",
      "epoch:11 step:9321 [D loss: 0.655050, acc.: 62.50%] [G loss: 0.793490]\n",
      "epoch:11 step:9322 [D loss: 0.707072, acc.: 53.91%] [G loss: 0.708560]\n",
      "epoch:11 step:9323 [D loss: 0.702112, acc.: 52.34%] [G loss: 0.747501]\n",
      "epoch:11 step:9324 [D loss: 0.699787, acc.: 48.44%] [G loss: 0.764018]\n",
      "epoch:11 step:9325 [D loss: 0.729582, acc.: 42.97%] [G loss: 0.704586]\n",
      "epoch:11 step:9326 [D loss: 0.772527, acc.: 34.38%] [G loss: 0.680238]\n",
      "epoch:11 step:9327 [D loss: 0.700035, acc.: 56.25%] [G loss: 0.781947]\n",
      "epoch:11 step:9328 [D loss: 0.710289, acc.: 42.97%] [G loss: 0.834525]\n",
      "epoch:11 step:9329 [D loss: 0.689620, acc.: 57.81%] [G loss: 0.785789]\n",
      "epoch:11 step:9330 [D loss: 0.737582, acc.: 34.38%] [G loss: 0.773082]\n",
      "epoch:11 step:9331 [D loss: 0.708734, acc.: 48.44%] [G loss: 0.760231]\n",
      "epoch:11 step:9332 [D loss: 0.664617, acc.: 61.72%] [G loss: 0.821272]\n",
      "epoch:11 step:9333 [D loss: 0.719527, acc.: 46.09%] [G loss: 0.820356]\n",
      "epoch:11 step:9334 [D loss: 0.783028, acc.: 37.50%] [G loss: 0.672554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9335 [D loss: 0.729427, acc.: 45.31%] [G loss: 0.729563]\n",
      "epoch:11 step:9336 [D loss: 0.683104, acc.: 58.59%] [G loss: 0.805332]\n",
      "epoch:11 step:9337 [D loss: 0.668129, acc.: 54.69%] [G loss: 0.705689]\n",
      "epoch:11 step:9338 [D loss: 0.723166, acc.: 50.00%] [G loss: 0.755587]\n",
      "epoch:11 step:9339 [D loss: 0.683956, acc.: 55.47%] [G loss: 0.735198]\n",
      "epoch:11 step:9340 [D loss: 0.681090, acc.: 54.69%] [G loss: 0.751119]\n",
      "epoch:11 step:9341 [D loss: 0.671976, acc.: 60.94%] [G loss: 0.808034]\n",
      "epoch:11 step:9342 [D loss: 0.685927, acc.: 53.12%] [G loss: 0.826419]\n",
      "epoch:11 step:9343 [D loss: 0.742131, acc.: 39.84%] [G loss: 0.787122]\n",
      "epoch:11 step:9344 [D loss: 0.677824, acc.: 60.16%] [G loss: 0.859857]\n",
      "epoch:11 step:9345 [D loss: 0.684238, acc.: 53.12%] [G loss: 0.847636]\n",
      "epoch:11 step:9346 [D loss: 0.689716, acc.: 56.25%] [G loss: 0.841915]\n",
      "epoch:11 step:9347 [D loss: 0.701150, acc.: 46.09%] [G loss: 0.800245]\n",
      "epoch:11 step:9348 [D loss: 0.683693, acc.: 60.16%] [G loss: 0.797153]\n",
      "epoch:11 step:9349 [D loss: 0.719116, acc.: 45.31%] [G loss: 0.715642]\n",
      "epoch:11 step:9350 [D loss: 0.682416, acc.: 53.91%] [G loss: 0.741675]\n",
      "epoch:11 step:9351 [D loss: 0.662866, acc.: 63.28%] [G loss: 0.704788]\n",
      "epoch:11 step:9352 [D loss: 0.634268, acc.: 67.97%] [G loss: 0.702070]\n",
      "epoch:11 step:9353 [D loss: 0.739421, acc.: 45.31%] [G loss: 0.644918]\n",
      "epoch:11 step:9354 [D loss: 0.760939, acc.: 37.50%] [G loss: 0.660976]\n",
      "epoch:11 step:9355 [D loss: 0.691187, acc.: 56.25%] [G loss: 0.778810]\n",
      "epoch:11 step:9356 [D loss: 0.692155, acc.: 54.69%] [G loss: 0.761719]\n",
      "epoch:11 step:9357 [D loss: 0.724385, acc.: 43.75%] [G loss: 0.780634]\n",
      "epoch:11 step:9358 [D loss: 0.677874, acc.: 53.12%] [G loss: 0.766408]\n",
      "epoch:11 step:9359 [D loss: 0.678003, acc.: 55.47%] [G loss: 0.729301]\n",
      "epoch:11 step:9360 [D loss: 0.716893, acc.: 50.00%] [G loss: 0.706035]\n",
      "epoch:11 step:9361 [D loss: 0.680390, acc.: 57.03%] [G loss: 0.786373]\n",
      "epoch:11 step:9362 [D loss: 0.683916, acc.: 52.34%] [G loss: 0.680745]\n",
      "epoch:11 step:9363 [D loss: 0.719730, acc.: 43.75%] [G loss: 0.744347]\n",
      "epoch:11 step:9364 [D loss: 0.606843, acc.: 68.75%] [G loss: 0.759975]\n",
      "epoch:11 step:9365 [D loss: 0.712401, acc.: 46.88%] [G loss: 0.790940]\n",
      "epoch:11 step:9366 [D loss: 0.681867, acc.: 50.78%] [G loss: 0.783353]\n",
      "epoch:11 step:9367 [D loss: 0.718245, acc.: 50.78%] [G loss: 0.738285]\n",
      "epoch:11 step:9368 [D loss: 0.715455, acc.: 48.44%] [G loss: 0.705275]\n",
      "epoch:11 step:9369 [D loss: 0.714375, acc.: 44.53%] [G loss: 0.744018]\n",
      "epoch:11 step:9370 [D loss: 0.716388, acc.: 49.22%] [G loss: 0.761887]\n",
      "epoch:11 step:9371 [D loss: 0.738695, acc.: 42.97%] [G loss: 0.725120]\n",
      "epoch:11 step:9372 [D loss: 0.706394, acc.: 47.66%] [G loss: 0.717067]\n",
      "epoch:12 step:9373 [D loss: 0.678445, acc.: 55.47%] [G loss: 0.802926]\n",
      "epoch:12 step:9374 [D loss: 0.699074, acc.: 47.66%] [G loss: 0.803329]\n",
      "epoch:12 step:9375 [D loss: 0.704339, acc.: 46.88%] [G loss: 0.752227]\n",
      "epoch:12 step:9376 [D loss: 0.693264, acc.: 56.25%] [G loss: 0.704464]\n",
      "epoch:12 step:9377 [D loss: 0.697622, acc.: 50.78%] [G loss: 0.839740]\n",
      "epoch:12 step:9378 [D loss: 0.670039, acc.: 60.94%] [G loss: 0.818052]\n",
      "epoch:12 step:9379 [D loss: 0.635830, acc.: 63.28%] [G loss: 0.863966]\n",
      "epoch:12 step:9380 [D loss: 0.675146, acc.: 57.03%] [G loss: 0.859449]\n",
      "epoch:12 step:9381 [D loss: 0.674293, acc.: 61.72%] [G loss: 0.830033]\n",
      "epoch:12 step:9382 [D loss: 0.671438, acc.: 57.81%] [G loss: 0.766652]\n",
      "epoch:12 step:9383 [D loss: 0.697797, acc.: 53.91%] [G loss: 0.864349]\n",
      "epoch:12 step:9384 [D loss: 0.627618, acc.: 67.97%] [G loss: 0.812927]\n",
      "epoch:12 step:9385 [D loss: 0.682409, acc.: 60.16%] [G loss: 0.719087]\n",
      "epoch:12 step:9386 [D loss: 0.631699, acc.: 65.62%] [G loss: 0.833492]\n",
      "epoch:12 step:9387 [D loss: 0.720540, acc.: 49.22%] [G loss: 0.790376]\n",
      "epoch:12 step:9388 [D loss: 0.738509, acc.: 40.62%] [G loss: 0.720829]\n",
      "epoch:12 step:9389 [D loss: 0.728623, acc.: 48.44%] [G loss: 0.705288]\n",
      "epoch:12 step:9390 [D loss: 0.640101, acc.: 70.31%] [G loss: 0.740204]\n",
      "epoch:12 step:9391 [D loss: 0.680968, acc.: 58.59%] [G loss: 0.649076]\n",
      "epoch:12 step:9392 [D loss: 0.669747, acc.: 62.50%] [G loss: 0.766590]\n",
      "epoch:12 step:9393 [D loss: 0.678075, acc.: 60.94%] [G loss: 0.685242]\n",
      "epoch:12 step:9394 [D loss: 0.660282, acc.: 60.16%] [G loss: 0.819051]\n",
      "epoch:12 step:9395 [D loss: 0.753037, acc.: 37.50%] [G loss: 0.743232]\n",
      "epoch:12 step:9396 [D loss: 0.754214, acc.: 35.16%] [G loss: 0.730470]\n",
      "epoch:12 step:9397 [D loss: 0.750152, acc.: 43.75%] [G loss: 0.773646]\n",
      "epoch:12 step:9398 [D loss: 0.723990, acc.: 53.12%] [G loss: 0.698082]\n",
      "epoch:12 step:9399 [D loss: 0.641250, acc.: 69.53%] [G loss: 0.735111]\n",
      "epoch:12 step:9400 [D loss: 0.746022, acc.: 39.06%] [G loss: 0.806288]\n",
      "epoch:12 step:9401 [D loss: 0.733309, acc.: 47.66%] [G loss: 0.767298]\n",
      "epoch:12 step:9402 [D loss: 0.724030, acc.: 44.53%] [G loss: 0.735110]\n",
      "epoch:12 step:9403 [D loss: 0.695651, acc.: 53.12%] [G loss: 0.800634]\n",
      "epoch:12 step:9404 [D loss: 0.691628, acc.: 53.12%] [G loss: 0.721722]\n",
      "epoch:12 step:9405 [D loss: 0.679626, acc.: 53.91%] [G loss: 0.765452]\n",
      "epoch:12 step:9406 [D loss: 0.710039, acc.: 50.78%] [G loss: 0.770648]\n",
      "epoch:12 step:9407 [D loss: 0.701137, acc.: 50.78%] [G loss: 0.738632]\n",
      "epoch:12 step:9408 [D loss: 0.670552, acc.: 63.28%] [G loss: 0.774792]\n",
      "epoch:12 step:9409 [D loss: 0.678768, acc.: 61.72%] [G loss: 0.786037]\n",
      "epoch:12 step:9410 [D loss: 0.655959, acc.: 64.06%] [G loss: 0.894284]\n",
      "epoch:12 step:9411 [D loss: 0.671840, acc.: 53.91%] [G loss: 0.772796]\n",
      "epoch:12 step:9412 [D loss: 0.680413, acc.: 61.72%] [G loss: 0.738147]\n",
      "epoch:12 step:9413 [D loss: 0.653250, acc.: 65.62%] [G loss: 0.806518]\n",
      "epoch:12 step:9414 [D loss: 0.632226, acc.: 64.84%] [G loss: 0.730574]\n",
      "epoch:12 step:9415 [D loss: 0.659401, acc.: 65.62%] [G loss: 0.739617]\n",
      "epoch:12 step:9416 [D loss: 0.670066, acc.: 59.38%] [G loss: 0.765386]\n",
      "epoch:12 step:9417 [D loss: 0.681357, acc.: 57.81%] [G loss: 0.757576]\n",
      "epoch:12 step:9418 [D loss: 0.642228, acc.: 61.72%] [G loss: 0.843108]\n",
      "epoch:12 step:9419 [D loss: 0.674908, acc.: 54.69%] [G loss: 0.754640]\n",
      "epoch:12 step:9420 [D loss: 0.682249, acc.: 56.25%] [G loss: 0.774808]\n",
      "epoch:12 step:9421 [D loss: 0.751112, acc.: 39.06%] [G loss: 0.637157]\n",
      "epoch:12 step:9422 [D loss: 0.749151, acc.: 46.09%] [G loss: 0.724984]\n",
      "epoch:12 step:9423 [D loss: 0.717523, acc.: 51.56%] [G loss: 0.726466]\n",
      "epoch:12 step:9424 [D loss: 0.724568, acc.: 39.84%] [G loss: 0.793743]\n",
      "epoch:12 step:9425 [D loss: 0.695161, acc.: 50.00%] [G loss: 0.805576]\n",
      "epoch:12 step:9426 [D loss: 0.735514, acc.: 42.19%] [G loss: 0.724238]\n",
      "epoch:12 step:9427 [D loss: 0.704381, acc.: 48.44%] [G loss: 0.747968]\n",
      "epoch:12 step:9428 [D loss: 0.691550, acc.: 56.25%] [G loss: 0.754218]\n",
      "epoch:12 step:9429 [D loss: 0.721408, acc.: 42.97%] [G loss: 0.748026]\n",
      "epoch:12 step:9430 [D loss: 0.765900, acc.: 36.72%] [G loss: 0.760347]\n",
      "epoch:12 step:9431 [D loss: 0.705794, acc.: 49.22%] [G loss: 0.698069]\n",
      "epoch:12 step:9432 [D loss: 0.762182, acc.: 31.25%] [G loss: 0.791207]\n",
      "epoch:12 step:9433 [D loss: 0.679072, acc.: 56.25%] [G loss: 0.791247]\n",
      "epoch:12 step:9434 [D loss: 0.704182, acc.: 53.12%] [G loss: 0.813640]\n",
      "epoch:12 step:9435 [D loss: 0.703185, acc.: 47.66%] [G loss: 0.804994]\n",
      "epoch:12 step:9436 [D loss: 0.724528, acc.: 44.53%] [G loss: 0.773633]\n",
      "epoch:12 step:9437 [D loss: 0.708007, acc.: 50.00%] [G loss: 0.818137]\n",
      "epoch:12 step:9438 [D loss: 0.714270, acc.: 47.66%] [G loss: 0.741300]\n",
      "epoch:12 step:9439 [D loss: 0.725955, acc.: 43.75%] [G loss: 0.809735]\n",
      "epoch:12 step:9440 [D loss: 0.679458, acc.: 50.78%] [G loss: 0.827400]\n",
      "epoch:12 step:9441 [D loss: 0.714142, acc.: 51.56%] [G loss: 0.741995]\n",
      "epoch:12 step:9442 [D loss: 0.701321, acc.: 53.12%] [G loss: 0.784609]\n",
      "epoch:12 step:9443 [D loss: 0.724704, acc.: 41.41%] [G loss: 0.706764]\n",
      "epoch:12 step:9444 [D loss: 0.694877, acc.: 50.78%] [G loss: 0.687350]\n",
      "epoch:12 step:9445 [D loss: 0.660321, acc.: 57.03%] [G loss: 0.706174]\n",
      "epoch:12 step:9446 [D loss: 0.700869, acc.: 50.78%] [G loss: 0.747535]\n",
      "epoch:12 step:9447 [D loss: 0.674189, acc.: 57.81%] [G loss: 0.747921]\n",
      "epoch:12 step:9448 [D loss: 0.689375, acc.: 58.59%] [G loss: 0.817848]\n",
      "epoch:12 step:9449 [D loss: 0.699517, acc.: 47.66%] [G loss: 0.794280]\n",
      "epoch:12 step:9450 [D loss: 0.704924, acc.: 47.66%] [G loss: 0.820393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9451 [D loss: 0.669159, acc.: 61.72%] [G loss: 0.732741]\n",
      "epoch:12 step:9452 [D loss: 0.691214, acc.: 53.12%] [G loss: 0.811672]\n",
      "epoch:12 step:9453 [D loss: 0.656503, acc.: 64.84%] [G loss: 0.802761]\n",
      "epoch:12 step:9454 [D loss: 0.692366, acc.: 58.59%] [G loss: 0.798251]\n",
      "epoch:12 step:9455 [D loss: 0.677778, acc.: 57.03%] [G loss: 0.830317]\n",
      "epoch:12 step:9456 [D loss: 0.660807, acc.: 63.28%] [G loss: 0.832811]\n",
      "epoch:12 step:9457 [D loss: 0.680569, acc.: 58.59%] [G loss: 0.826551]\n",
      "epoch:12 step:9458 [D loss: 0.683620, acc.: 54.69%] [G loss: 0.715451]\n",
      "epoch:12 step:9459 [D loss: 0.675341, acc.: 59.38%] [G loss: 0.840285]\n",
      "epoch:12 step:9460 [D loss: 0.694393, acc.: 53.91%] [G loss: 0.773145]\n",
      "epoch:12 step:9461 [D loss: 0.617966, acc.: 75.00%] [G loss: 0.779324]\n",
      "epoch:12 step:9462 [D loss: 0.719194, acc.: 46.09%] [G loss: 0.742217]\n",
      "epoch:12 step:9463 [D loss: 0.701985, acc.: 53.91%] [G loss: 0.720705]\n",
      "epoch:12 step:9464 [D loss: 0.709595, acc.: 46.88%] [G loss: 0.753292]\n",
      "epoch:12 step:9465 [D loss: 0.735909, acc.: 51.56%] [G loss: 0.720929]\n",
      "epoch:12 step:9466 [D loss: 0.723208, acc.: 50.78%] [G loss: 0.699973]\n",
      "epoch:12 step:9467 [D loss: 0.716611, acc.: 46.88%] [G loss: 0.775888]\n",
      "epoch:12 step:9468 [D loss: 0.721807, acc.: 50.00%] [G loss: 0.902510]\n",
      "epoch:12 step:9469 [D loss: 0.673665, acc.: 57.81%] [G loss: 0.834337]\n",
      "epoch:12 step:9470 [D loss: 0.722205, acc.: 49.22%] [G loss: 0.815329]\n",
      "epoch:12 step:9471 [D loss: 0.682222, acc.: 49.22%] [G loss: 0.770022]\n",
      "epoch:12 step:9472 [D loss: 0.742206, acc.: 46.09%] [G loss: 0.797117]\n",
      "epoch:12 step:9473 [D loss: 0.693419, acc.: 53.91%] [G loss: 0.798281]\n",
      "epoch:12 step:9474 [D loss: 0.641403, acc.: 63.28%] [G loss: 0.792372]\n",
      "epoch:12 step:9475 [D loss: 0.711244, acc.: 52.34%] [G loss: 0.724431]\n",
      "epoch:12 step:9476 [D loss: 0.693398, acc.: 49.22%] [G loss: 0.835495]\n",
      "epoch:12 step:9477 [D loss: 0.633706, acc.: 70.31%] [G loss: 0.772616]\n",
      "epoch:12 step:9478 [D loss: 0.710895, acc.: 57.81%] [G loss: 0.792320]\n",
      "epoch:12 step:9479 [D loss: 0.686083, acc.: 54.69%] [G loss: 0.672746]\n",
      "epoch:12 step:9480 [D loss: 0.761883, acc.: 39.84%] [G loss: 0.706686]\n",
      "epoch:12 step:9481 [D loss: 0.691123, acc.: 51.56%] [G loss: 0.682757]\n",
      "epoch:12 step:9482 [D loss: 0.725645, acc.: 47.66%] [G loss: 0.723780]\n",
      "epoch:12 step:9483 [D loss: 0.668978, acc.: 51.56%] [G loss: 0.696115]\n",
      "epoch:12 step:9484 [D loss: 0.688059, acc.: 54.69%] [G loss: 0.699373]\n",
      "epoch:12 step:9485 [D loss: 0.721389, acc.: 46.09%] [G loss: 0.744181]\n",
      "epoch:12 step:9486 [D loss: 0.731935, acc.: 40.62%] [G loss: 0.704488]\n",
      "epoch:12 step:9487 [D loss: 0.720621, acc.: 46.88%] [G loss: 0.789196]\n",
      "epoch:12 step:9488 [D loss: 0.723202, acc.: 48.44%] [G loss: 0.739411]\n",
      "epoch:12 step:9489 [D loss: 0.705287, acc.: 48.44%] [G loss: 0.715537]\n",
      "epoch:12 step:9490 [D loss: 0.677771, acc.: 60.16%] [G loss: 0.793567]\n",
      "epoch:12 step:9491 [D loss: 0.746524, acc.: 39.84%] [G loss: 0.770392]\n",
      "epoch:12 step:9492 [D loss: 0.730086, acc.: 48.44%] [G loss: 0.783612]\n",
      "epoch:12 step:9493 [D loss: 0.722633, acc.: 42.97%] [G loss: 0.741202]\n",
      "epoch:12 step:9494 [D loss: 0.709399, acc.: 51.56%] [G loss: 0.740242]\n",
      "epoch:12 step:9495 [D loss: 0.715397, acc.: 42.97%] [G loss: 0.683114]\n",
      "epoch:12 step:9496 [D loss: 0.697861, acc.: 57.81%] [G loss: 0.729703]\n",
      "epoch:12 step:9497 [D loss: 0.741086, acc.: 46.09%] [G loss: 0.746586]\n",
      "epoch:12 step:9498 [D loss: 0.712632, acc.: 49.22%] [G loss: 0.770714]\n",
      "epoch:12 step:9499 [D loss: 0.717355, acc.: 49.22%] [G loss: 0.738771]\n",
      "epoch:12 step:9500 [D loss: 0.687021, acc.: 54.69%] [G loss: 0.731073]\n",
      "epoch:12 step:9501 [D loss: 0.712945, acc.: 39.84%] [G loss: 0.781634]\n",
      "epoch:12 step:9502 [D loss: 0.703696, acc.: 53.91%] [G loss: 0.747273]\n",
      "epoch:12 step:9503 [D loss: 0.662339, acc.: 60.94%] [G loss: 0.786716]\n",
      "epoch:12 step:9504 [D loss: 0.657638, acc.: 60.16%] [G loss: 0.874389]\n",
      "epoch:12 step:9505 [D loss: 0.702361, acc.: 42.97%] [G loss: 0.806277]\n",
      "epoch:12 step:9506 [D loss: 0.676965, acc.: 55.47%] [G loss: 0.827253]\n",
      "epoch:12 step:9507 [D loss: 0.731561, acc.: 42.97%] [G loss: 0.766322]\n",
      "epoch:12 step:9508 [D loss: 0.650574, acc.: 73.44%] [G loss: 0.781235]\n",
      "epoch:12 step:9509 [D loss: 0.709091, acc.: 50.78%] [G loss: 0.774332]\n",
      "epoch:12 step:9510 [D loss: 0.672309, acc.: 57.81%] [G loss: 0.714709]\n",
      "epoch:12 step:9511 [D loss: 0.660517, acc.: 57.81%] [G loss: 0.743647]\n",
      "epoch:12 step:9512 [D loss: 0.699328, acc.: 46.88%] [G loss: 0.706010]\n",
      "epoch:12 step:9513 [D loss: 0.711944, acc.: 50.00%] [G loss: 0.726277]\n",
      "epoch:12 step:9514 [D loss: 0.697712, acc.: 53.12%] [G loss: 0.749205]\n",
      "epoch:12 step:9515 [D loss: 0.711571, acc.: 47.66%] [G loss: 0.733899]\n",
      "epoch:12 step:9516 [D loss: 0.697421, acc.: 49.22%] [G loss: 0.730382]\n",
      "epoch:12 step:9517 [D loss: 0.671903, acc.: 56.25%] [G loss: 0.796231]\n",
      "epoch:12 step:9518 [D loss: 0.642668, acc.: 64.84%] [G loss: 0.771163]\n",
      "epoch:12 step:9519 [D loss: 0.708871, acc.: 51.56%] [G loss: 0.710427]\n",
      "epoch:12 step:9520 [D loss: 0.698770, acc.: 46.88%] [G loss: 0.650720]\n",
      "epoch:12 step:9521 [D loss: 0.738900, acc.: 42.97%] [G loss: 0.648287]\n",
      "epoch:12 step:9522 [D loss: 0.700859, acc.: 48.44%] [G loss: 0.709064]\n",
      "epoch:12 step:9523 [D loss: 0.742149, acc.: 46.09%] [G loss: 0.707286]\n",
      "epoch:12 step:9524 [D loss: 0.697091, acc.: 50.00%] [G loss: 0.749887]\n",
      "epoch:12 step:9525 [D loss: 0.686979, acc.: 59.38%] [G loss: 0.777428]\n",
      "epoch:12 step:9526 [D loss: 0.680607, acc.: 56.25%] [G loss: 0.771553]\n",
      "epoch:12 step:9527 [D loss: 0.685786, acc.: 58.59%] [G loss: 0.716139]\n",
      "epoch:12 step:9528 [D loss: 0.711913, acc.: 52.34%] [G loss: 0.728235]\n",
      "epoch:12 step:9529 [D loss: 0.714276, acc.: 49.22%] [G loss: 0.681192]\n",
      "epoch:12 step:9530 [D loss: 0.756533, acc.: 37.50%] [G loss: 0.786516]\n",
      "epoch:12 step:9531 [D loss: 0.697782, acc.: 45.31%] [G loss: 0.768567]\n",
      "epoch:12 step:9532 [D loss: 0.704474, acc.: 54.69%] [G loss: 0.750465]\n",
      "epoch:12 step:9533 [D loss: 0.746291, acc.: 39.06%] [G loss: 0.772369]\n",
      "epoch:12 step:9534 [D loss: 0.683384, acc.: 53.12%] [G loss: 0.774031]\n",
      "epoch:12 step:9535 [D loss: 0.705026, acc.: 58.59%] [G loss: 0.776126]\n",
      "epoch:12 step:9536 [D loss: 0.723800, acc.: 41.41%] [G loss: 0.827480]\n",
      "epoch:12 step:9537 [D loss: 0.614789, acc.: 67.19%] [G loss: 0.839305]\n",
      "epoch:12 step:9538 [D loss: 0.704376, acc.: 53.12%] [G loss: 0.783934]\n",
      "epoch:12 step:9539 [D loss: 0.693321, acc.: 58.59%] [G loss: 0.771694]\n",
      "epoch:12 step:9540 [D loss: 0.667305, acc.: 58.59%] [G loss: 0.824433]\n",
      "epoch:12 step:9541 [D loss: 0.699140, acc.: 46.88%] [G loss: 0.741689]\n",
      "epoch:12 step:9542 [D loss: 0.695708, acc.: 57.03%] [G loss: 0.764494]\n",
      "epoch:12 step:9543 [D loss: 0.658282, acc.: 64.84%] [G loss: 0.705478]\n",
      "epoch:12 step:9544 [D loss: 0.665241, acc.: 62.50%] [G loss: 0.811275]\n",
      "epoch:12 step:9545 [D loss: 0.770018, acc.: 38.28%] [G loss: 0.750708]\n",
      "epoch:12 step:9546 [D loss: 0.698784, acc.: 49.22%] [G loss: 0.730438]\n",
      "epoch:12 step:9547 [D loss: 0.681263, acc.: 54.69%] [G loss: 0.763541]\n",
      "epoch:12 step:9548 [D loss: 0.639078, acc.: 64.84%] [G loss: 0.749350]\n",
      "epoch:12 step:9549 [D loss: 0.711736, acc.: 48.44%] [G loss: 0.721025]\n",
      "epoch:12 step:9550 [D loss: 0.665320, acc.: 59.38%] [G loss: 0.697948]\n",
      "epoch:12 step:9551 [D loss: 0.710721, acc.: 49.22%] [G loss: 0.690951]\n",
      "epoch:12 step:9552 [D loss: 0.693967, acc.: 50.00%] [G loss: 0.756405]\n",
      "epoch:12 step:9553 [D loss: 0.713184, acc.: 46.88%] [G loss: 0.675551]\n",
      "epoch:12 step:9554 [D loss: 0.807053, acc.: 34.38%] [G loss: 0.715160]\n",
      "epoch:12 step:9555 [D loss: 0.714450, acc.: 53.91%] [G loss: 0.714767]\n",
      "epoch:12 step:9556 [D loss: 0.726197, acc.: 40.62%] [G loss: 0.790301]\n",
      "epoch:12 step:9557 [D loss: 0.749286, acc.: 39.84%] [G loss: 0.706117]\n",
      "epoch:12 step:9558 [D loss: 0.711673, acc.: 53.91%] [G loss: 0.763909]\n",
      "epoch:12 step:9559 [D loss: 0.701910, acc.: 50.78%] [G loss: 0.761697]\n",
      "epoch:12 step:9560 [D loss: 0.756730, acc.: 43.75%] [G loss: 0.731097]\n",
      "epoch:12 step:9561 [D loss: 0.710591, acc.: 50.78%] [G loss: 0.798212]\n",
      "epoch:12 step:9562 [D loss: 0.743154, acc.: 41.41%] [G loss: 0.742283]\n",
      "epoch:12 step:9563 [D loss: 0.702557, acc.: 52.34%] [G loss: 0.797800]\n",
      "epoch:12 step:9564 [D loss: 0.706909, acc.: 54.69%] [G loss: 0.847677]\n",
      "epoch:12 step:9565 [D loss: 0.746991, acc.: 42.19%] [G loss: 0.768339]\n",
      "epoch:12 step:9566 [D loss: 0.673187, acc.: 57.03%] [G loss: 0.763889]\n",
      "epoch:12 step:9567 [D loss: 0.738087, acc.: 43.75%] [G loss: 0.730885]\n",
      "epoch:12 step:9568 [D loss: 0.668503, acc.: 60.94%] [G loss: 0.822067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9569 [D loss: 0.729489, acc.: 39.06%] [G loss: 0.765196]\n",
      "epoch:12 step:9570 [D loss: 0.708946, acc.: 49.22%] [G loss: 0.716429]\n",
      "epoch:12 step:9571 [D loss: 0.683344, acc.: 58.59%] [G loss: 0.719949]\n",
      "epoch:12 step:9572 [D loss: 0.707823, acc.: 55.47%] [G loss: 0.791815]\n",
      "epoch:12 step:9573 [D loss: 0.664297, acc.: 60.94%] [G loss: 0.768334]\n",
      "epoch:12 step:9574 [D loss: 0.685730, acc.: 52.34%] [G loss: 0.790213]\n",
      "epoch:12 step:9575 [D loss: 0.641259, acc.: 64.84%] [G loss: 0.803418]\n",
      "epoch:12 step:9576 [D loss: 0.729598, acc.: 50.00%] [G loss: 0.798108]\n",
      "epoch:12 step:9577 [D loss: 0.721334, acc.: 41.41%] [G loss: 0.817627]\n",
      "epoch:12 step:9578 [D loss: 0.719588, acc.: 42.19%] [G loss: 0.839962]\n",
      "epoch:12 step:9579 [D loss: 0.633673, acc.: 74.22%] [G loss: 0.844944]\n",
      "epoch:12 step:9580 [D loss: 0.664038, acc.: 58.59%] [G loss: 0.799287]\n",
      "epoch:12 step:9581 [D loss: 0.676682, acc.: 57.03%] [G loss: 0.935024]\n",
      "epoch:12 step:9582 [D loss: 0.690420, acc.: 53.91%] [G loss: 0.849750]\n",
      "epoch:12 step:9583 [D loss: 0.653467, acc.: 66.41%] [G loss: 0.801692]\n",
      "epoch:12 step:9584 [D loss: 0.669574, acc.: 58.59%] [G loss: 0.752589]\n",
      "epoch:12 step:9585 [D loss: 0.652477, acc.: 63.28%] [G loss: 0.885813]\n",
      "epoch:12 step:9586 [D loss: 0.664962, acc.: 56.25%] [G loss: 0.931913]\n",
      "epoch:12 step:9587 [D loss: 0.657967, acc.: 60.16%] [G loss: 0.766855]\n",
      "epoch:12 step:9588 [D loss: 0.734798, acc.: 43.75%] [G loss: 0.767299]\n",
      "epoch:12 step:9589 [D loss: 0.683160, acc.: 50.00%] [G loss: 0.858490]\n",
      "epoch:12 step:9590 [D loss: 0.654631, acc.: 57.81%] [G loss: 0.758129]\n",
      "epoch:12 step:9591 [D loss: 0.677733, acc.: 56.25%] [G loss: 0.832047]\n",
      "epoch:12 step:9592 [D loss: 0.689424, acc.: 63.28%] [G loss: 0.767648]\n",
      "epoch:12 step:9593 [D loss: 0.714840, acc.: 46.09%] [G loss: 0.724067]\n",
      "epoch:12 step:9594 [D loss: 0.693403, acc.: 49.22%] [G loss: 0.733120]\n",
      "epoch:12 step:9595 [D loss: 0.650995, acc.: 67.97%] [G loss: 0.774396]\n",
      "epoch:12 step:9596 [D loss: 0.682644, acc.: 54.69%] [G loss: 0.774516]\n",
      "epoch:12 step:9597 [D loss: 0.662461, acc.: 62.50%] [G loss: 0.764599]\n",
      "epoch:12 step:9598 [D loss: 0.720367, acc.: 44.53%] [G loss: 0.766133]\n",
      "epoch:12 step:9599 [D loss: 0.704808, acc.: 54.69%] [G loss: 0.749965]\n",
      "epoch:12 step:9600 [D loss: 0.739399, acc.: 45.31%] [G loss: 0.765574]\n",
      "epoch:12 step:9601 [D loss: 0.691221, acc.: 51.56%] [G loss: 0.797993]\n",
      "epoch:12 step:9602 [D loss: 0.687096, acc.: 57.03%] [G loss: 0.799499]\n",
      "epoch:12 step:9603 [D loss: 0.705353, acc.: 42.97%] [G loss: 0.740046]\n",
      "epoch:12 step:9604 [D loss: 0.720677, acc.: 51.56%] [G loss: 0.741511]\n",
      "epoch:12 step:9605 [D loss: 0.680825, acc.: 56.25%] [G loss: 0.771244]\n",
      "epoch:12 step:9606 [D loss: 0.700238, acc.: 54.69%] [G loss: 0.709328]\n",
      "epoch:12 step:9607 [D loss: 0.745161, acc.: 40.62%] [G loss: 0.637197]\n",
      "epoch:12 step:9608 [D loss: 0.719860, acc.: 48.44%] [G loss: 0.685898]\n",
      "epoch:12 step:9609 [D loss: 0.774170, acc.: 37.50%] [G loss: 0.694964]\n",
      "epoch:12 step:9610 [D loss: 0.666726, acc.: 57.03%] [G loss: 0.703686]\n",
      "epoch:12 step:9611 [D loss: 0.716574, acc.: 49.22%] [G loss: 0.662650]\n",
      "epoch:12 step:9612 [D loss: 0.640760, acc.: 61.72%] [G loss: 0.815479]\n",
      "epoch:12 step:9613 [D loss: 0.697028, acc.: 55.47%] [G loss: 0.771003]\n",
      "epoch:12 step:9614 [D loss: 0.720804, acc.: 46.88%] [G loss: 0.700974]\n",
      "epoch:12 step:9615 [D loss: 0.733173, acc.: 46.88%] [G loss: 0.736628]\n",
      "epoch:12 step:9616 [D loss: 0.662556, acc.: 61.72%] [G loss: 0.702972]\n",
      "epoch:12 step:9617 [D loss: 0.743376, acc.: 38.28%] [G loss: 0.705798]\n",
      "epoch:12 step:9618 [D loss: 0.685501, acc.: 57.03%] [G loss: 0.763496]\n",
      "epoch:12 step:9619 [D loss: 0.669009, acc.: 63.28%] [G loss: 0.701841]\n",
      "epoch:12 step:9620 [D loss: 0.698098, acc.: 55.47%] [G loss: 0.707555]\n",
      "epoch:12 step:9621 [D loss: 0.662563, acc.: 60.16%] [G loss: 0.728672]\n",
      "epoch:12 step:9622 [D loss: 0.713773, acc.: 47.66%] [G loss: 0.707949]\n",
      "epoch:12 step:9623 [D loss: 0.702717, acc.: 50.78%] [G loss: 0.761319]\n",
      "epoch:12 step:9624 [D loss: 0.731210, acc.: 50.78%] [G loss: 0.771214]\n",
      "epoch:12 step:9625 [D loss: 0.721505, acc.: 45.31%] [G loss: 0.754829]\n",
      "epoch:12 step:9626 [D loss: 0.647710, acc.: 61.72%] [G loss: 0.906952]\n",
      "epoch:12 step:9627 [D loss: 0.723482, acc.: 53.12%] [G loss: 0.787648]\n",
      "epoch:12 step:9628 [D loss: 0.736370, acc.: 41.41%] [G loss: 0.776665]\n",
      "epoch:12 step:9629 [D loss: 0.676033, acc.: 59.38%] [G loss: 0.768070]\n",
      "epoch:12 step:9630 [D loss: 0.732044, acc.: 48.44%] [G loss: 0.793451]\n",
      "epoch:12 step:9631 [D loss: 0.687589, acc.: 54.69%] [G loss: 0.801982]\n",
      "epoch:12 step:9632 [D loss: 0.717563, acc.: 49.22%] [G loss: 0.784859]\n",
      "epoch:12 step:9633 [D loss: 0.738897, acc.: 42.97%] [G loss: 0.823001]\n",
      "epoch:12 step:9634 [D loss: 0.681035, acc.: 55.47%] [G loss: 0.911418]\n",
      "epoch:12 step:9635 [D loss: 0.641278, acc.: 64.06%] [G loss: 0.877535]\n",
      "epoch:12 step:9636 [D loss: 0.712534, acc.: 45.31%] [G loss: 0.752615]\n",
      "epoch:12 step:9637 [D loss: 0.644218, acc.: 64.06%] [G loss: 0.777309]\n",
      "epoch:12 step:9638 [D loss: 0.683662, acc.: 56.25%] [G loss: 0.794728]\n",
      "epoch:12 step:9639 [D loss: 0.677366, acc.: 57.81%] [G loss: 0.806543]\n",
      "epoch:12 step:9640 [D loss: 0.684449, acc.: 58.59%] [G loss: 0.739571]\n",
      "epoch:12 step:9641 [D loss: 0.678984, acc.: 58.59%] [G loss: 0.749408]\n",
      "epoch:12 step:9642 [D loss: 0.683847, acc.: 56.25%] [G loss: 0.748028]\n",
      "epoch:12 step:9643 [D loss: 0.667775, acc.: 55.47%] [G loss: 0.777981]\n",
      "epoch:12 step:9644 [D loss: 0.669675, acc.: 56.25%] [G loss: 0.729834]\n",
      "epoch:12 step:9645 [D loss: 0.780278, acc.: 33.59%] [G loss: 0.744764]\n",
      "epoch:12 step:9646 [D loss: 0.680693, acc.: 47.66%] [G loss: 0.821716]\n",
      "epoch:12 step:9647 [D loss: 0.691557, acc.: 53.91%] [G loss: 0.745911]\n",
      "epoch:12 step:9648 [D loss: 0.723455, acc.: 43.75%] [G loss: 0.703223]\n",
      "epoch:12 step:9649 [D loss: 0.805723, acc.: 32.03%] [G loss: 0.718252]\n",
      "epoch:12 step:9650 [D loss: 0.720500, acc.: 45.31%] [G loss: 0.695815]\n",
      "epoch:12 step:9651 [D loss: 0.713435, acc.: 47.66%] [G loss: 0.788350]\n",
      "epoch:12 step:9652 [D loss: 0.679666, acc.: 55.47%] [G loss: 0.759432]\n",
      "epoch:12 step:9653 [D loss: 0.714451, acc.: 44.53%] [G loss: 0.731568]\n",
      "epoch:12 step:9654 [D loss: 0.719109, acc.: 46.88%] [G loss: 0.749277]\n",
      "epoch:12 step:9655 [D loss: 0.723162, acc.: 47.66%] [G loss: 0.743756]\n",
      "epoch:12 step:9656 [D loss: 0.670710, acc.: 58.59%] [G loss: 0.734663]\n",
      "epoch:12 step:9657 [D loss: 0.685838, acc.: 50.78%] [G loss: 0.822177]\n",
      "epoch:12 step:9658 [D loss: 0.704141, acc.: 44.53%] [G loss: 0.767784]\n",
      "epoch:12 step:9659 [D loss: 0.754207, acc.: 38.28%] [G loss: 0.740040]\n",
      "epoch:12 step:9660 [D loss: 0.765877, acc.: 40.62%] [G loss: 0.752375]\n",
      "epoch:12 step:9661 [D loss: 0.712889, acc.: 45.31%] [G loss: 0.894258]\n",
      "epoch:12 step:9662 [D loss: 0.718607, acc.: 45.31%] [G loss: 0.807989]\n",
      "epoch:12 step:9663 [D loss: 0.755348, acc.: 38.28%] [G loss: 0.759246]\n",
      "epoch:12 step:9664 [D loss: 0.756774, acc.: 39.06%] [G loss: 0.746740]\n",
      "epoch:12 step:9665 [D loss: 0.704004, acc.: 53.91%] [G loss: 0.768973]\n",
      "epoch:12 step:9666 [D loss: 0.678570, acc.: 57.03%] [G loss: 0.736187]\n",
      "epoch:12 step:9667 [D loss: 0.671589, acc.: 59.38%] [G loss: 0.815339]\n",
      "epoch:12 step:9668 [D loss: 0.721991, acc.: 44.53%] [G loss: 0.761258]\n",
      "epoch:12 step:9669 [D loss: 0.725261, acc.: 42.19%] [G loss: 0.700572]\n",
      "epoch:12 step:9670 [D loss: 0.700084, acc.: 52.34%] [G loss: 0.779000]\n",
      "epoch:12 step:9671 [D loss: 0.735912, acc.: 44.53%] [G loss: 0.701451]\n",
      "epoch:12 step:9672 [D loss: 0.699374, acc.: 48.44%] [G loss: 0.754524]\n",
      "epoch:12 step:9673 [D loss: 0.727944, acc.: 45.31%] [G loss: 0.750191]\n",
      "epoch:12 step:9674 [D loss: 0.712235, acc.: 42.97%] [G loss: 0.771157]\n",
      "epoch:12 step:9675 [D loss: 0.709741, acc.: 45.31%] [G loss: 0.827981]\n",
      "epoch:12 step:9676 [D loss: 0.698133, acc.: 51.56%] [G loss: 0.765725]\n",
      "epoch:12 step:9677 [D loss: 0.723389, acc.: 44.53%] [G loss: 0.775071]\n",
      "epoch:12 step:9678 [D loss: 0.718607, acc.: 49.22%] [G loss: 0.820283]\n",
      "epoch:12 step:9679 [D loss: 0.711191, acc.: 49.22%] [G loss: 0.790564]\n",
      "epoch:12 step:9680 [D loss: 0.715746, acc.: 51.56%] [G loss: 0.760836]\n",
      "epoch:12 step:9681 [D loss: 0.679383, acc.: 53.12%] [G loss: 0.778251]\n",
      "epoch:12 step:9682 [D loss: 0.759946, acc.: 39.06%] [G loss: 0.753166]\n",
      "epoch:12 step:9683 [D loss: 0.671824, acc.: 57.03%] [G loss: 0.745932]\n",
      "epoch:12 step:9684 [D loss: 0.682571, acc.: 57.81%] [G loss: 0.728777]\n",
      "epoch:12 step:9685 [D loss: 0.697551, acc.: 55.47%] [G loss: 0.802853]\n",
      "epoch:12 step:9686 [D loss: 0.705233, acc.: 52.34%] [G loss: 0.760322]\n",
      "epoch:12 step:9687 [D loss: 0.699939, acc.: 48.44%] [G loss: 0.795293]\n",
      "epoch:12 step:9688 [D loss: 0.666430, acc.: 60.16%] [G loss: 0.759140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9689 [D loss: 0.715166, acc.: 49.22%] [G loss: 0.777691]\n",
      "epoch:12 step:9690 [D loss: 0.670333, acc.: 54.69%] [G loss: 0.738371]\n",
      "epoch:12 step:9691 [D loss: 0.724008, acc.: 49.22%] [G loss: 0.741765]\n",
      "epoch:12 step:9692 [D loss: 0.749162, acc.: 40.62%] [G loss: 0.739231]\n",
      "epoch:12 step:9693 [D loss: 0.758009, acc.: 37.50%] [G loss: 0.758289]\n",
      "epoch:12 step:9694 [D loss: 0.621641, acc.: 68.75%] [G loss: 0.817870]\n",
      "epoch:12 step:9695 [D loss: 0.659775, acc.: 60.16%] [G loss: 0.755626]\n",
      "epoch:12 step:9696 [D loss: 0.706677, acc.: 53.91%] [G loss: 0.853908]\n",
      "epoch:12 step:9697 [D loss: 0.701789, acc.: 50.00%] [G loss: 0.866163]\n",
      "epoch:12 step:9698 [D loss: 0.675014, acc.: 56.25%] [G loss: 0.824279]\n",
      "epoch:12 step:9699 [D loss: 0.640785, acc.: 67.19%] [G loss: 0.766485]\n",
      "epoch:12 step:9700 [D loss: 0.692643, acc.: 50.78%] [G loss: 0.823952]\n",
      "epoch:12 step:9701 [D loss: 0.664454, acc.: 59.38%] [G loss: 0.811093]\n",
      "epoch:12 step:9702 [D loss: 0.635154, acc.: 71.09%] [G loss: 0.724863]\n",
      "epoch:12 step:9703 [D loss: 0.738105, acc.: 42.19%] [G loss: 0.711651]\n",
      "epoch:12 step:9704 [D loss: 0.661013, acc.: 63.28%] [G loss: 0.767010]\n",
      "epoch:12 step:9705 [D loss: 0.670395, acc.: 60.16%] [G loss: 0.810991]\n",
      "epoch:12 step:9706 [D loss: 0.746057, acc.: 40.62%] [G loss: 0.720947]\n",
      "epoch:12 step:9707 [D loss: 0.683715, acc.: 56.25%] [G loss: 0.761985]\n",
      "epoch:12 step:9708 [D loss: 0.733236, acc.: 43.75%] [G loss: 0.706457]\n",
      "epoch:12 step:9709 [D loss: 0.686845, acc.: 56.25%] [G loss: 0.766217]\n",
      "epoch:12 step:9710 [D loss: 0.793922, acc.: 29.69%] [G loss: 0.733919]\n",
      "epoch:12 step:9711 [D loss: 0.715055, acc.: 49.22%] [G loss: 0.660708]\n",
      "epoch:12 step:9712 [D loss: 0.725395, acc.: 48.44%] [G loss: 0.790663]\n",
      "epoch:12 step:9713 [D loss: 0.690720, acc.: 57.81%] [G loss: 0.726854]\n",
      "epoch:12 step:9714 [D loss: 0.737659, acc.: 35.94%] [G loss: 0.794922]\n",
      "epoch:12 step:9715 [D loss: 0.720177, acc.: 50.00%] [G loss: 0.720036]\n",
      "epoch:12 step:9716 [D loss: 0.689473, acc.: 50.78%] [G loss: 0.743305]\n",
      "epoch:12 step:9717 [D loss: 0.638586, acc.: 66.41%] [G loss: 0.816767]\n",
      "epoch:12 step:9718 [D loss: 0.651384, acc.: 61.72%] [G loss: 0.775797]\n",
      "epoch:12 step:9719 [D loss: 0.690227, acc.: 57.03%] [G loss: 0.786978]\n",
      "epoch:12 step:9720 [D loss: 0.679017, acc.: 56.25%] [G loss: 0.703350]\n",
      "epoch:12 step:9721 [D loss: 0.656486, acc.: 63.28%] [G loss: 0.769141]\n",
      "epoch:12 step:9722 [D loss: 0.705288, acc.: 49.22%] [G loss: 0.738422]\n",
      "epoch:12 step:9723 [D loss: 0.718515, acc.: 46.09%] [G loss: 0.672537]\n",
      "epoch:12 step:9724 [D loss: 0.693247, acc.: 50.78%] [G loss: 0.808199]\n",
      "epoch:12 step:9725 [D loss: 0.648829, acc.: 61.72%] [G loss: 0.729505]\n",
      "epoch:12 step:9726 [D loss: 0.710779, acc.: 57.03%] [G loss: 0.742866]\n",
      "epoch:12 step:9727 [D loss: 0.721573, acc.: 46.09%] [G loss: 0.732796]\n",
      "epoch:12 step:9728 [D loss: 0.709251, acc.: 49.22%] [G loss: 0.646258]\n",
      "epoch:12 step:9729 [D loss: 0.692403, acc.: 55.47%] [G loss: 0.723737]\n",
      "epoch:12 step:9730 [D loss: 0.701171, acc.: 52.34%] [G loss: 0.684805]\n",
      "epoch:12 step:9731 [D loss: 0.723570, acc.: 43.75%] [G loss: 0.760643]\n",
      "epoch:12 step:9732 [D loss: 0.760940, acc.: 38.28%] [G loss: 0.688007]\n",
      "epoch:12 step:9733 [D loss: 0.701703, acc.: 49.22%] [G loss: 0.704286]\n",
      "epoch:12 step:9734 [D loss: 0.693056, acc.: 47.66%] [G loss: 0.776304]\n",
      "epoch:12 step:9735 [D loss: 0.727628, acc.: 43.75%] [G loss: 0.661614]\n",
      "epoch:12 step:9736 [D loss: 0.731810, acc.: 40.62%] [G loss: 0.743603]\n",
      "epoch:12 step:9737 [D loss: 0.688890, acc.: 54.69%] [G loss: 0.770265]\n",
      "epoch:12 step:9738 [D loss: 0.690195, acc.: 50.00%] [G loss: 0.767590]\n",
      "epoch:12 step:9739 [D loss: 0.702043, acc.: 51.56%] [G loss: 0.776812]\n",
      "epoch:12 step:9740 [D loss: 0.656855, acc.: 64.06%] [G loss: 0.865172]\n",
      "epoch:12 step:9741 [D loss: 0.685282, acc.: 53.12%] [G loss: 0.769606]\n",
      "epoch:12 step:9742 [D loss: 0.692512, acc.: 53.91%] [G loss: 0.842593]\n",
      "epoch:12 step:9743 [D loss: 0.640477, acc.: 66.41%] [G loss: 0.824347]\n",
      "epoch:12 step:9744 [D loss: 0.655451, acc.: 61.72%] [G loss: 0.824778]\n",
      "epoch:12 step:9745 [D loss: 0.689322, acc.: 53.12%] [G loss: 0.835324]\n",
      "epoch:12 step:9746 [D loss: 0.679348, acc.: 53.12%] [G loss: 0.816238]\n",
      "epoch:12 step:9747 [D loss: 0.714401, acc.: 45.31%] [G loss: 0.813933]\n",
      "epoch:12 step:9748 [D loss: 0.679551, acc.: 55.47%] [G loss: 0.791005]\n",
      "epoch:12 step:9749 [D loss: 0.673207, acc.: 57.81%] [G loss: 0.744108]\n",
      "epoch:12 step:9750 [D loss: 0.723834, acc.: 40.62%] [G loss: 0.741705]\n",
      "epoch:12 step:9751 [D loss: 0.644022, acc.: 71.88%] [G loss: 0.735054]\n",
      "epoch:12 step:9752 [D loss: 0.703524, acc.: 53.91%] [G loss: 0.803720]\n",
      "epoch:12 step:9753 [D loss: 0.672894, acc.: 61.72%] [G loss: 0.707942]\n",
      "epoch:12 step:9754 [D loss: 0.697876, acc.: 53.12%] [G loss: 0.716956]\n",
      "epoch:12 step:9755 [D loss: 0.708163, acc.: 48.44%] [G loss: 0.737055]\n",
      "epoch:12 step:9756 [D loss: 0.686212, acc.: 60.16%] [G loss: 0.731524]\n",
      "epoch:12 step:9757 [D loss: 0.762109, acc.: 34.38%] [G loss: 0.686796]\n",
      "epoch:12 step:9758 [D loss: 0.655601, acc.: 57.81%] [G loss: 0.712795]\n",
      "epoch:12 step:9759 [D loss: 0.745152, acc.: 44.53%] [G loss: 0.734458]\n",
      "epoch:12 step:9760 [D loss: 0.727847, acc.: 41.41%] [G loss: 0.815110]\n",
      "epoch:12 step:9761 [D loss: 0.701138, acc.: 46.09%] [G loss: 0.782132]\n",
      "epoch:12 step:9762 [D loss: 0.737048, acc.: 46.88%] [G loss: 0.803541]\n",
      "epoch:12 step:9763 [D loss: 0.768881, acc.: 38.28%] [G loss: 0.745816]\n",
      "epoch:12 step:9764 [D loss: 0.701317, acc.: 51.56%] [G loss: 0.740540]\n",
      "epoch:12 step:9765 [D loss: 0.734802, acc.: 44.53%] [G loss: 0.674122]\n",
      "epoch:12 step:9766 [D loss: 0.675643, acc.: 59.38%] [G loss: 0.713676]\n",
      "epoch:12 step:9767 [D loss: 0.722378, acc.: 48.44%] [G loss: 0.719034]\n",
      "epoch:12 step:9768 [D loss: 0.684027, acc.: 61.72%] [G loss: 0.763257]\n",
      "epoch:12 step:9769 [D loss: 0.683013, acc.: 54.69%] [G loss: 0.766983]\n",
      "epoch:12 step:9770 [D loss: 0.717109, acc.: 48.44%] [G loss: 0.719560]\n",
      "epoch:12 step:9771 [D loss: 0.726298, acc.: 41.41%] [G loss: 0.812366]\n",
      "epoch:12 step:9772 [D loss: 0.690498, acc.: 53.12%] [G loss: 0.811304]\n",
      "epoch:12 step:9773 [D loss: 0.656443, acc.: 59.38%] [G loss: 0.740420]\n",
      "epoch:12 step:9774 [D loss: 0.706959, acc.: 49.22%] [G loss: 0.798033]\n",
      "epoch:12 step:9775 [D loss: 0.615710, acc.: 68.75%] [G loss: 0.753115]\n",
      "epoch:12 step:9776 [D loss: 0.695991, acc.: 53.91%] [G loss: 0.773519]\n",
      "epoch:12 step:9777 [D loss: 0.666341, acc.: 62.50%] [G loss: 0.768427]\n",
      "epoch:12 step:9778 [D loss: 0.699562, acc.: 53.12%] [G loss: 0.717823]\n",
      "epoch:12 step:9779 [D loss: 0.675633, acc.: 55.47%] [G loss: 0.715391]\n",
      "epoch:12 step:9780 [D loss: 0.749236, acc.: 32.03%] [G loss: 0.728565]\n",
      "epoch:12 step:9781 [D loss: 0.744373, acc.: 32.81%] [G loss: 0.744317]\n",
      "epoch:12 step:9782 [D loss: 0.701294, acc.: 49.22%] [G loss: 0.656958]\n",
      "epoch:12 step:9783 [D loss: 0.738113, acc.: 45.31%] [G loss: 0.735766]\n",
      "epoch:12 step:9784 [D loss: 0.690566, acc.: 54.69%] [G loss: 0.633961]\n",
      "epoch:12 step:9785 [D loss: 0.699150, acc.: 54.69%] [G loss: 0.685400]\n",
      "epoch:12 step:9786 [D loss: 0.719527, acc.: 53.12%] [G loss: 0.728031]\n",
      "epoch:12 step:9787 [D loss: 0.670670, acc.: 61.72%] [G loss: 0.803728]\n",
      "epoch:12 step:9788 [D loss: 0.674374, acc.: 59.38%] [G loss: 0.836692]\n",
      "epoch:12 step:9789 [D loss: 0.658188, acc.: 64.84%] [G loss: 0.763407]\n",
      "epoch:12 step:9790 [D loss: 0.700633, acc.: 50.78%] [G loss: 0.788631]\n",
      "epoch:12 step:9791 [D loss: 0.708653, acc.: 50.78%] [G loss: 0.819535]\n",
      "epoch:12 step:9792 [D loss: 0.662957, acc.: 59.38%] [G loss: 0.813053]\n",
      "epoch:12 step:9793 [D loss: 0.669280, acc.: 52.34%] [G loss: 0.872250]\n",
      "epoch:12 step:9794 [D loss: 0.706076, acc.: 50.78%] [G loss: 0.765454]\n",
      "epoch:12 step:9795 [D loss: 0.683010, acc.: 53.91%] [G loss: 0.829495]\n",
      "epoch:12 step:9796 [D loss: 0.702624, acc.: 49.22%] [G loss: 0.759968]\n",
      "epoch:12 step:9797 [D loss: 0.645156, acc.: 66.41%] [G loss: 0.870416]\n",
      "epoch:12 step:9798 [D loss: 0.748050, acc.: 41.41%] [G loss: 0.735519]\n",
      "epoch:12 step:9799 [D loss: 0.654750, acc.: 67.19%] [G loss: 0.808770]\n",
      "epoch:12 step:9800 [D loss: 0.679203, acc.: 56.25%] [G loss: 0.783950]\n",
      "epoch:12 step:9801 [D loss: 0.723514, acc.: 46.88%] [G loss: 0.650751]\n",
      "epoch:12 step:9802 [D loss: 0.677011, acc.: 57.81%] [G loss: 0.724833]\n",
      "epoch:12 step:9803 [D loss: 0.696275, acc.: 50.78%] [G loss: 0.825422]\n",
      "epoch:12 step:9804 [D loss: 0.674042, acc.: 57.03%] [G loss: 0.786220]\n",
      "epoch:12 step:9805 [D loss: 0.666707, acc.: 63.28%] [G loss: 0.764129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9806 [D loss: 0.631584, acc.: 72.66%] [G loss: 0.736192]\n",
      "epoch:12 step:9807 [D loss: 0.667842, acc.: 57.81%] [G loss: 0.711263]\n",
      "epoch:12 step:9808 [D loss: 0.696697, acc.: 50.00%] [G loss: 0.728241]\n",
      "epoch:12 step:9809 [D loss: 0.664090, acc.: 58.59%] [G loss: 0.717319]\n",
      "epoch:12 step:9810 [D loss: 0.779957, acc.: 31.25%] [G loss: 0.631926]\n",
      "epoch:12 step:9811 [D loss: 0.633592, acc.: 62.50%] [G loss: 0.734453]\n",
      "epoch:12 step:9812 [D loss: 0.639502, acc.: 66.41%] [G loss: 0.685750]\n",
      "epoch:12 step:9813 [D loss: 0.716810, acc.: 46.88%] [G loss: 0.664547]\n",
      "epoch:12 step:9814 [D loss: 0.670016, acc.: 60.94%] [G loss: 0.772661]\n",
      "epoch:12 step:9815 [D loss: 0.686357, acc.: 58.59%] [G loss: 0.717835]\n",
      "epoch:12 step:9816 [D loss: 0.720321, acc.: 47.66%] [G loss: 0.716780]\n",
      "epoch:12 step:9817 [D loss: 0.720730, acc.: 44.53%] [G loss: 0.771791]\n",
      "epoch:12 step:9818 [D loss: 0.774262, acc.: 35.94%] [G loss: 0.824299]\n",
      "epoch:12 step:9819 [D loss: 0.715220, acc.: 47.66%] [G loss: 0.784824]\n",
      "epoch:12 step:9820 [D loss: 0.689772, acc.: 57.03%] [G loss: 0.904138]\n",
      "epoch:12 step:9821 [D loss: 0.685651, acc.: 56.25%] [G loss: 0.932384]\n",
      "epoch:12 step:9822 [D loss: 0.733420, acc.: 43.75%] [G loss: 0.863172]\n",
      "epoch:12 step:9823 [D loss: 0.690307, acc.: 50.00%] [G loss: 0.893960]\n",
      "epoch:12 step:9824 [D loss: 0.684767, acc.: 54.69%] [G loss: 0.845672]\n",
      "epoch:12 step:9825 [D loss: 0.737637, acc.: 46.09%] [G loss: 0.891765]\n",
      "epoch:12 step:9826 [D loss: 0.686365, acc.: 53.91%] [G loss: 0.792805]\n",
      "epoch:12 step:9827 [D loss: 0.694799, acc.: 51.56%] [G loss: 0.694863]\n",
      "epoch:12 step:9828 [D loss: 0.633786, acc.: 67.19%] [G loss: 0.718798]\n",
      "epoch:12 step:9829 [D loss: 0.663402, acc.: 60.94%] [G loss: 0.793100]\n",
      "epoch:12 step:9830 [D loss: 0.665620, acc.: 57.81%] [G loss: 0.744855]\n",
      "epoch:12 step:9831 [D loss: 0.692252, acc.: 58.59%] [G loss: 0.763173]\n",
      "epoch:12 step:9832 [D loss: 0.600722, acc.: 72.66%] [G loss: 0.765278]\n",
      "epoch:12 step:9833 [D loss: 0.655374, acc.: 65.62%] [G loss: 0.790338]\n",
      "epoch:12 step:9834 [D loss: 0.637027, acc.: 62.50%] [G loss: 0.788713]\n",
      "epoch:12 step:9835 [D loss: 0.641720, acc.: 70.31%] [G loss: 0.703991]\n",
      "epoch:12 step:9836 [D loss: 0.681862, acc.: 53.91%] [G loss: 0.675509]\n",
      "epoch:12 step:9837 [D loss: 0.728058, acc.: 46.09%] [G loss: 0.747239]\n",
      "epoch:12 step:9838 [D loss: 0.619663, acc.: 69.53%] [G loss: 0.750134]\n",
      "epoch:12 step:9839 [D loss: 0.693138, acc.: 47.66%] [G loss: 0.806685]\n",
      "epoch:12 step:9840 [D loss: 0.677646, acc.: 53.12%] [G loss: 0.803784]\n",
      "epoch:12 step:9841 [D loss: 0.731211, acc.: 46.09%] [G loss: 0.748082]\n",
      "epoch:12 step:9842 [D loss: 0.752837, acc.: 40.62%] [G loss: 0.802326]\n",
      "epoch:12 step:9843 [D loss: 0.739559, acc.: 42.97%] [G loss: 0.802627]\n",
      "epoch:12 step:9844 [D loss: 0.676995, acc.: 59.38%] [G loss: 0.757234]\n",
      "epoch:12 step:9845 [D loss: 0.785244, acc.: 35.16%] [G loss: 0.699799]\n",
      "epoch:12 step:9846 [D loss: 0.735057, acc.: 39.84%] [G loss: 0.722741]\n",
      "epoch:12 step:9847 [D loss: 0.723723, acc.: 47.66%] [G loss: 0.775063]\n",
      "epoch:12 step:9848 [D loss: 0.609337, acc.: 78.91%] [G loss: 0.775422]\n",
      "epoch:12 step:9849 [D loss: 0.686526, acc.: 57.03%] [G loss: 0.798605]\n",
      "epoch:12 step:9850 [D loss: 0.652765, acc.: 60.94%] [G loss: 0.750586]\n",
      "epoch:12 step:9851 [D loss: 0.690015, acc.: 55.47%] [G loss: 0.910758]\n",
      "epoch:12 step:9852 [D loss: 0.664671, acc.: 57.81%] [G loss: 0.791900]\n",
      "epoch:12 step:9853 [D loss: 0.702968, acc.: 52.34%] [G loss: 0.843580]\n",
      "epoch:12 step:9854 [D loss: 0.793400, acc.: 33.59%] [G loss: 0.682039]\n",
      "epoch:12 step:9855 [D loss: 0.666355, acc.: 57.81%] [G loss: 0.766345]\n",
      "epoch:12 step:9856 [D loss: 0.661019, acc.: 57.81%] [G loss: 0.692447]\n",
      "epoch:12 step:9857 [D loss: 0.650015, acc.: 65.62%] [G loss: 0.745706]\n",
      "epoch:12 step:9858 [D loss: 0.674546, acc.: 57.03%] [G loss: 0.718386]\n",
      "epoch:12 step:9859 [D loss: 0.674408, acc.: 56.25%] [G loss: 0.702747]\n",
      "epoch:12 step:9860 [D loss: 0.710093, acc.: 53.12%] [G loss: 0.749172]\n",
      "epoch:12 step:9861 [D loss: 0.747988, acc.: 32.81%] [G loss: 0.776402]\n",
      "epoch:12 step:9862 [D loss: 0.722726, acc.: 49.22%] [G loss: 0.769896]\n",
      "epoch:12 step:9863 [D loss: 0.794538, acc.: 28.12%] [G loss: 0.685358]\n",
      "epoch:12 step:9864 [D loss: 0.748930, acc.: 34.38%] [G loss: 0.738805]\n",
      "epoch:12 step:9865 [D loss: 0.700448, acc.: 50.78%] [G loss: 0.743746]\n",
      "epoch:12 step:9866 [D loss: 0.677146, acc.: 57.81%] [G loss: 0.853797]\n",
      "epoch:12 step:9867 [D loss: 0.676516, acc.: 56.25%] [G loss: 0.786865]\n",
      "epoch:12 step:9868 [D loss: 0.731214, acc.: 43.75%] [G loss: 0.765241]\n",
      "epoch:12 step:9869 [D loss: 0.718782, acc.: 50.00%] [G loss: 0.803999]\n",
      "epoch:12 step:9870 [D loss: 0.739427, acc.: 39.84%] [G loss: 0.739636]\n",
      "epoch:12 step:9871 [D loss: 0.734408, acc.: 44.53%] [G loss: 0.818459]\n",
      "epoch:12 step:9872 [D loss: 0.668077, acc.: 58.59%] [G loss: 0.801739]\n",
      "epoch:12 step:9873 [D loss: 0.692415, acc.: 53.91%] [G loss: 0.814035]\n",
      "epoch:12 step:9874 [D loss: 0.657809, acc.: 61.72%] [G loss: 0.866891]\n",
      "epoch:12 step:9875 [D loss: 0.714736, acc.: 50.78%] [G loss: 0.801288]\n",
      "epoch:12 step:9876 [D loss: 0.702244, acc.: 50.00%] [G loss: 0.815095]\n",
      "epoch:12 step:9877 [D loss: 0.700945, acc.: 50.00%] [G loss: 0.823240]\n",
      "epoch:12 step:9878 [D loss: 0.710929, acc.: 52.34%] [G loss: 0.802761]\n",
      "epoch:12 step:9879 [D loss: 0.658335, acc.: 60.94%] [G loss: 0.831105]\n",
      "epoch:12 step:9880 [D loss: 0.667949, acc.: 56.25%] [G loss: 0.777274]\n",
      "epoch:12 step:9881 [D loss: 0.663704, acc.: 64.84%] [G loss: 0.811643]\n",
      "epoch:12 step:9882 [D loss: 0.653997, acc.: 66.41%] [G loss: 0.764795]\n",
      "epoch:12 step:9883 [D loss: 0.654989, acc.: 58.59%] [G loss: 0.721727]\n",
      "epoch:12 step:9884 [D loss: 0.728107, acc.: 42.19%] [G loss: 0.703533]\n",
      "epoch:12 step:9885 [D loss: 0.692813, acc.: 50.00%] [G loss: 0.852439]\n",
      "epoch:12 step:9886 [D loss: 0.734204, acc.: 49.22%] [G loss: 0.653102]\n",
      "epoch:12 step:9887 [D loss: 0.654936, acc.: 62.50%] [G loss: 0.701571]\n",
      "epoch:12 step:9888 [D loss: 0.688820, acc.: 57.03%] [G loss: 0.746706]\n",
      "epoch:12 step:9889 [D loss: 0.766171, acc.: 39.06%] [G loss: 0.710436]\n",
      "epoch:12 step:9890 [D loss: 0.705911, acc.: 46.88%] [G loss: 0.747916]\n",
      "epoch:12 step:9891 [D loss: 0.761025, acc.: 42.97%] [G loss: 0.740826]\n",
      "epoch:12 step:9892 [D loss: 0.674095, acc.: 58.59%] [G loss: 0.723714]\n",
      "epoch:12 step:9893 [D loss: 0.677545, acc.: 57.03%] [G loss: 0.712830]\n",
      "epoch:12 step:9894 [D loss: 0.679937, acc.: 53.91%] [G loss: 0.770328]\n",
      "epoch:12 step:9895 [D loss: 0.677862, acc.: 53.12%] [G loss: 0.754981]\n",
      "epoch:12 step:9896 [D loss: 0.697446, acc.: 53.12%] [G loss: 0.772317]\n",
      "epoch:12 step:9897 [D loss: 0.677529, acc.: 55.47%] [G loss: 0.730666]\n",
      "epoch:12 step:9898 [D loss: 0.776342, acc.: 34.38%] [G loss: 0.692450]\n",
      "epoch:12 step:9899 [D loss: 0.708598, acc.: 49.22%] [G loss: 0.671171]\n",
      "epoch:12 step:9900 [D loss: 0.684087, acc.: 54.69%] [G loss: 0.785404]\n",
      "epoch:12 step:9901 [D loss: 0.708602, acc.: 47.66%] [G loss: 0.747188]\n",
      "epoch:12 step:9902 [D loss: 0.665088, acc.: 57.03%] [G loss: 0.736480]\n",
      "epoch:12 step:9903 [D loss: 0.649458, acc.: 65.62%] [G loss: 0.811810]\n",
      "epoch:12 step:9904 [D loss: 0.666616, acc.: 60.16%] [G loss: 0.821022]\n",
      "epoch:12 step:9905 [D loss: 0.732099, acc.: 42.97%] [G loss: 0.734377]\n",
      "epoch:12 step:9906 [D loss: 0.721992, acc.: 42.19%] [G loss: 0.716585]\n",
      "epoch:12 step:9907 [D loss: 0.667033, acc.: 65.62%] [G loss: 0.854245]\n",
      "epoch:12 step:9908 [D loss: 0.655725, acc.: 67.97%] [G loss: 0.854309]\n",
      "epoch:12 step:9909 [D loss: 0.716518, acc.: 42.97%] [G loss: 0.743680]\n",
      "epoch:12 step:9910 [D loss: 0.656201, acc.: 64.84%] [G loss: 0.824326]\n",
      "epoch:12 step:9911 [D loss: 0.708743, acc.: 55.47%] [G loss: 0.802441]\n",
      "epoch:12 step:9912 [D loss: 0.734240, acc.: 45.31%] [G loss: 0.755990]\n",
      "epoch:12 step:9913 [D loss: 0.734794, acc.: 39.84%] [G loss: 0.755204]\n",
      "epoch:12 step:9914 [D loss: 0.737141, acc.: 39.84%] [G loss: 0.727447]\n",
      "epoch:12 step:9915 [D loss: 0.668312, acc.: 63.28%] [G loss: 0.746147]\n",
      "epoch:12 step:9916 [D loss: 0.674341, acc.: 58.59%] [G loss: 0.820322]\n",
      "epoch:12 step:9917 [D loss: 0.651269, acc.: 60.16%] [G loss: 0.773329]\n",
      "epoch:12 step:9918 [D loss: 0.781140, acc.: 36.72%] [G loss: 0.724007]\n",
      "epoch:12 step:9919 [D loss: 0.674822, acc.: 56.25%] [G loss: 0.764119]\n",
      "epoch:12 step:9920 [D loss: 0.695952, acc.: 54.69%] [G loss: 0.722520]\n",
      "epoch:12 step:9921 [D loss: 0.661700, acc.: 64.06%] [G loss: 0.816856]\n",
      "epoch:12 step:9922 [D loss: 0.707422, acc.: 48.44%] [G loss: 0.766471]\n",
      "epoch:12 step:9923 [D loss: 0.703833, acc.: 46.88%] [G loss: 0.760079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9924 [D loss: 0.704847, acc.: 46.88%] [G loss: 0.743764]\n",
      "epoch:12 step:9925 [D loss: 0.671731, acc.: 60.94%] [G loss: 0.848826]\n",
      "epoch:12 step:9926 [D loss: 0.681323, acc.: 56.25%] [G loss: 0.770825]\n",
      "epoch:12 step:9927 [D loss: 0.677787, acc.: 54.69%] [G loss: 0.918131]\n",
      "epoch:12 step:9928 [D loss: 0.664003, acc.: 57.81%] [G loss: 0.822593]\n",
      "epoch:12 step:9929 [D loss: 0.726620, acc.: 49.22%] [G loss: 0.748532]\n",
      "epoch:12 step:9930 [D loss: 0.678830, acc.: 55.47%] [G loss: 0.703492]\n",
      "epoch:12 step:9931 [D loss: 0.681021, acc.: 57.81%] [G loss: 0.800753]\n",
      "epoch:12 step:9932 [D loss: 0.662268, acc.: 63.28%] [G loss: 0.721208]\n",
      "epoch:12 step:9933 [D loss: 0.722747, acc.: 48.44%] [G loss: 0.786104]\n",
      "epoch:12 step:9934 [D loss: 0.716301, acc.: 46.88%] [G loss: 0.734156]\n",
      "epoch:12 step:9935 [D loss: 0.642364, acc.: 71.09%] [G loss: 0.811255]\n",
      "epoch:12 step:9936 [D loss: 0.695717, acc.: 51.56%] [G loss: 0.784247]\n",
      "epoch:12 step:9937 [D loss: 0.708823, acc.: 48.44%] [G loss: 0.772150]\n",
      "epoch:12 step:9938 [D loss: 0.695754, acc.: 51.56%] [G loss: 0.807826]\n",
      "epoch:12 step:9939 [D loss: 0.745834, acc.: 38.28%] [G loss: 0.782489]\n",
      "epoch:12 step:9940 [D loss: 0.720598, acc.: 44.53%] [G loss: 0.798719]\n",
      "epoch:12 step:9941 [D loss: 0.711519, acc.: 42.97%] [G loss: 0.826001]\n",
      "epoch:12 step:9942 [D loss: 0.683597, acc.: 54.69%] [G loss: 0.709431]\n",
      "epoch:12 step:9943 [D loss: 0.687191, acc.: 56.25%] [G loss: 0.850723]\n",
      "epoch:12 step:9944 [D loss: 0.712188, acc.: 46.09%] [G loss: 0.725834]\n",
      "epoch:12 step:9945 [D loss: 0.725046, acc.: 43.75%] [G loss: 0.714629]\n",
      "epoch:12 step:9946 [D loss: 0.749370, acc.: 42.97%] [G loss: 0.751360]\n",
      "epoch:12 step:9947 [D loss: 0.693898, acc.: 50.00%] [G loss: 0.773440]\n",
      "epoch:12 step:9948 [D loss: 0.647502, acc.: 64.84%] [G loss: 0.789440]\n",
      "epoch:12 step:9949 [D loss: 0.707342, acc.: 50.78%] [G loss: 0.739308]\n",
      "epoch:12 step:9950 [D loss: 0.663099, acc.: 61.72%] [G loss: 0.794427]\n",
      "epoch:12 step:9951 [D loss: 0.646510, acc.: 71.09%] [G loss: 0.759897]\n",
      "epoch:12 step:9952 [D loss: 0.694733, acc.: 50.78%] [G loss: 0.806391]\n",
      "epoch:12 step:9953 [D loss: 0.712847, acc.: 50.78%] [G loss: 0.734561]\n",
      "epoch:12 step:9954 [D loss: 0.720266, acc.: 46.88%] [G loss: 0.776421]\n",
      "epoch:12 step:9955 [D loss: 0.667354, acc.: 61.72%] [G loss: 0.807464]\n",
      "epoch:12 step:9956 [D loss: 0.716194, acc.: 50.00%] [G loss: 0.772932]\n",
      "epoch:12 step:9957 [D loss: 0.729729, acc.: 48.44%] [G loss: 0.721043]\n",
      "epoch:12 step:9958 [D loss: 0.679002, acc.: 57.03%] [G loss: 0.773691]\n",
      "epoch:12 step:9959 [D loss: 0.652757, acc.: 60.16%] [G loss: 0.823692]\n",
      "epoch:12 step:9960 [D loss: 0.712857, acc.: 43.75%] [G loss: 0.790239]\n",
      "epoch:12 step:9961 [D loss: 0.710781, acc.: 50.00%] [G loss: 0.718180]\n",
      "epoch:12 step:9962 [D loss: 0.674786, acc.: 57.03%] [G loss: 0.820065]\n",
      "epoch:12 step:9963 [D loss: 0.667547, acc.: 57.81%] [G loss: 0.872751]\n",
      "epoch:12 step:9964 [D loss: 0.732552, acc.: 41.41%] [G loss: 0.743988]\n",
      "epoch:12 step:9965 [D loss: 0.727868, acc.: 45.31%] [G loss: 0.774583]\n",
      "epoch:12 step:9966 [D loss: 0.753080, acc.: 39.84%] [G loss: 0.727482]\n",
      "epoch:12 step:9967 [D loss: 0.695179, acc.: 42.97%] [G loss: 0.693052]\n",
      "epoch:12 step:9968 [D loss: 0.736126, acc.: 46.88%] [G loss: 0.777220]\n",
      "epoch:12 step:9969 [D loss: 0.736889, acc.: 43.75%] [G loss: 0.713036]\n",
      "epoch:12 step:9970 [D loss: 0.748098, acc.: 38.28%] [G loss: 0.744357]\n",
      "epoch:12 step:9971 [D loss: 0.764332, acc.: 31.25%] [G loss: 0.712132]\n",
      "epoch:12 step:9972 [D loss: 0.735815, acc.: 42.19%] [G loss: 0.707087]\n",
      "epoch:12 step:9973 [D loss: 0.704092, acc.: 50.00%] [G loss: 0.733281]\n",
      "epoch:12 step:9974 [D loss: 0.715851, acc.: 52.34%] [G loss: 0.781722]\n",
      "epoch:12 step:9975 [D loss: 0.761297, acc.: 32.81%] [G loss: 0.790496]\n",
      "epoch:12 step:9976 [D loss: 0.720800, acc.: 49.22%] [G loss: 0.743375]\n",
      "epoch:12 step:9977 [D loss: 0.705514, acc.: 52.34%] [G loss: 0.755481]\n",
      "epoch:12 step:9978 [D loss: 0.732015, acc.: 45.31%] [G loss: 0.783403]\n",
      "epoch:12 step:9979 [D loss: 0.705134, acc.: 46.88%] [G loss: 0.820148]\n",
      "epoch:12 step:9980 [D loss: 0.694136, acc.: 48.44%] [G loss: 0.840727]\n",
      "epoch:12 step:9981 [D loss: 0.768098, acc.: 39.06%] [G loss: 0.790003]\n",
      "epoch:12 step:9982 [D loss: 0.694686, acc.: 48.44%] [G loss: 0.756629]\n",
      "epoch:12 step:9983 [D loss: 0.777794, acc.: 28.12%] [G loss: 0.778002]\n",
      "epoch:12 step:9984 [D loss: 0.683289, acc.: 60.16%] [G loss: 0.827091]\n",
      "epoch:12 step:9985 [D loss: 0.721877, acc.: 46.88%] [G loss: 0.783859]\n",
      "epoch:12 step:9986 [D loss: 0.710775, acc.: 46.09%] [G loss: 0.877927]\n",
      "epoch:12 step:9987 [D loss: 0.688723, acc.: 55.47%] [G loss: 0.757558]\n",
      "epoch:12 step:9988 [D loss: 0.696859, acc.: 55.47%] [G loss: 0.782832]\n",
      "epoch:12 step:9989 [D loss: 0.691470, acc.: 53.12%] [G loss: 0.783733]\n",
      "epoch:12 step:9990 [D loss: 0.624388, acc.: 71.09%] [G loss: 0.814157]\n",
      "epoch:12 step:9991 [D loss: 0.682037, acc.: 57.81%] [G loss: 0.731916]\n",
      "epoch:12 step:9992 [D loss: 0.683891, acc.: 55.47%] [G loss: 0.748027]\n",
      "epoch:12 step:9993 [D loss: 0.663586, acc.: 61.72%] [G loss: 0.800836]\n",
      "epoch:12 step:9994 [D loss: 0.683697, acc.: 56.25%] [G loss: 0.758170]\n",
      "epoch:12 step:9995 [D loss: 0.704983, acc.: 51.56%] [G loss: 0.821105]\n",
      "epoch:12 step:9996 [D loss: 0.714705, acc.: 51.56%] [G loss: 0.750771]\n",
      "epoch:12 step:9997 [D loss: 0.717958, acc.: 52.34%] [G loss: 0.770853]\n",
      "epoch:12 step:9998 [D loss: 0.724478, acc.: 48.44%] [G loss: 0.778207]\n",
      "epoch:12 step:9999 [D loss: 0.657383, acc.: 64.06%] [G loss: 0.764299]\n",
      "epoch:12 step:10000 [D loss: 0.624692, acc.: 75.78%] [G loss: 0.847714]\n",
      "epoch:12 step:10001 [D loss: 0.741649, acc.: 39.06%] [G loss: 0.833253]\n",
      "epoch:12 step:10002 [D loss: 0.690099, acc.: 53.12%] [G loss: 0.894277]\n",
      "epoch:12 step:10003 [D loss: 0.727713, acc.: 46.88%] [G loss: 0.804666]\n",
      "epoch:12 step:10004 [D loss: 0.697543, acc.: 53.12%] [G loss: 0.775139]\n",
      "epoch:12 step:10005 [D loss: 0.680744, acc.: 55.47%] [G loss: 0.830817]\n",
      "epoch:12 step:10006 [D loss: 0.652026, acc.: 65.62%] [G loss: 0.770509]\n",
      "epoch:12 step:10007 [D loss: 0.720018, acc.: 47.66%] [G loss: 0.677371]\n",
      "epoch:12 step:10008 [D loss: 0.671491, acc.: 62.50%] [G loss: 0.796959]\n",
      "epoch:12 step:10009 [D loss: 0.700946, acc.: 53.91%] [G loss: 0.768094]\n",
      "epoch:12 step:10010 [D loss: 0.726010, acc.: 42.97%] [G loss: 0.703611]\n",
      "epoch:12 step:10011 [D loss: 0.737377, acc.: 42.19%] [G loss: 0.629610]\n",
      "epoch:12 step:10012 [D loss: 0.725771, acc.: 42.97%] [G loss: 0.739075]\n",
      "epoch:12 step:10013 [D loss: 0.702827, acc.: 50.78%] [G loss: 0.771932]\n",
      "epoch:12 step:10014 [D loss: 0.667558, acc.: 60.16%] [G loss: 0.684948]\n",
      "epoch:12 step:10015 [D loss: 0.692196, acc.: 54.69%] [G loss: 0.751216]\n",
      "epoch:12 step:10016 [D loss: 0.713959, acc.: 50.78%] [G loss: 0.796309]\n",
      "epoch:12 step:10017 [D loss: 0.674456, acc.: 60.16%] [G loss: 0.760963]\n",
      "epoch:12 step:10018 [D loss: 0.641266, acc.: 67.19%] [G loss: 0.831113]\n",
      "epoch:12 step:10019 [D loss: 0.728992, acc.: 46.09%] [G loss: 0.756766]\n",
      "epoch:12 step:10020 [D loss: 0.714795, acc.: 46.88%] [G loss: 0.836461]\n",
      "epoch:12 step:10021 [D loss: 0.679943, acc.: 58.59%] [G loss: 0.751180]\n",
      "epoch:12 step:10022 [D loss: 0.630096, acc.: 70.31%] [G loss: 0.746392]\n",
      "epoch:12 step:10023 [D loss: 0.630559, acc.: 63.28%] [G loss: 0.765535]\n",
      "epoch:12 step:10024 [D loss: 0.682972, acc.: 55.47%] [G loss: 0.704123]\n",
      "epoch:12 step:10025 [D loss: 0.708509, acc.: 52.34%] [G loss: 0.702909]\n",
      "epoch:12 step:10026 [D loss: 0.714604, acc.: 46.09%] [G loss: 0.734818]\n",
      "epoch:12 step:10027 [D loss: 0.687823, acc.: 52.34%] [G loss: 0.695811]\n",
      "epoch:12 step:10028 [D loss: 0.721212, acc.: 50.00%] [G loss: 0.677498]\n",
      "epoch:12 step:10029 [D loss: 0.677953, acc.: 54.69%] [G loss: 0.719943]\n",
      "epoch:12 step:10030 [D loss: 0.688083, acc.: 54.69%] [G loss: 0.801195]\n",
      "epoch:12 step:10031 [D loss: 0.683786, acc.: 57.81%] [G loss: 0.810346]\n",
      "epoch:12 step:10032 [D loss: 0.695014, acc.: 58.59%] [G loss: 0.775855]\n",
      "epoch:12 step:10033 [D loss: 0.741437, acc.: 45.31%] [G loss: 0.841260]\n",
      "epoch:12 step:10034 [D loss: 0.674776, acc.: 57.03%] [G loss: 0.862845]\n",
      "epoch:12 step:10035 [D loss: 0.662517, acc.: 60.94%] [G loss: 0.825151]\n",
      "epoch:12 step:10036 [D loss: 0.709547, acc.: 54.69%] [G loss: 0.847053]\n",
      "epoch:12 step:10037 [D loss: 0.712524, acc.: 49.22%] [G loss: 0.822530]\n",
      "epoch:12 step:10038 [D loss: 0.646882, acc.: 63.28%] [G loss: 0.858843]\n",
      "epoch:12 step:10039 [D loss: 0.695723, acc.: 56.25%] [G loss: 0.826724]\n",
      "epoch:12 step:10040 [D loss: 0.738781, acc.: 45.31%] [G loss: 0.775887]\n",
      "epoch:12 step:10041 [D loss: 0.672347, acc.: 65.62%] [G loss: 0.790213]\n",
      "epoch:12 step:10042 [D loss: 0.665352, acc.: 64.06%] [G loss: 0.897936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10043 [D loss: 0.707563, acc.: 51.56%] [G loss: 0.796168]\n",
      "epoch:12 step:10044 [D loss: 0.706317, acc.: 50.78%] [G loss: 0.780555]\n",
      "epoch:12 step:10045 [D loss: 0.671224, acc.: 63.28%] [G loss: 0.820864]\n",
      "epoch:12 step:10046 [D loss: 0.732193, acc.: 51.56%] [G loss: 0.776750]\n",
      "epoch:12 step:10047 [D loss: 0.682633, acc.: 54.69%] [G loss: 0.742999]\n",
      "epoch:12 step:10048 [D loss: 0.688068, acc.: 51.56%] [G loss: 0.779355]\n",
      "epoch:12 step:10049 [D loss: 0.683818, acc.: 57.03%] [G loss: 0.770736]\n",
      "epoch:12 step:10050 [D loss: 0.671665, acc.: 60.94%] [G loss: 0.794867]\n",
      "epoch:12 step:10051 [D loss: 0.699268, acc.: 53.12%] [G loss: 0.752288]\n",
      "epoch:12 step:10052 [D loss: 0.643804, acc.: 65.62%] [G loss: 0.762168]\n",
      "epoch:12 step:10053 [D loss: 0.654720, acc.: 64.06%] [G loss: 0.799564]\n",
      "epoch:12 step:10054 [D loss: 0.694359, acc.: 49.22%] [G loss: 0.764691]\n",
      "epoch:12 step:10055 [D loss: 0.731686, acc.: 41.41%] [G loss: 0.770147]\n",
      "epoch:12 step:10056 [D loss: 0.707933, acc.: 46.09%] [G loss: 0.701895]\n",
      "epoch:12 step:10057 [D loss: 0.740272, acc.: 35.16%] [G loss: 0.702173]\n",
      "epoch:12 step:10058 [D loss: 0.722282, acc.: 47.66%] [G loss: 0.686985]\n",
      "epoch:12 step:10059 [D loss: 0.668420, acc.: 60.16%] [G loss: 0.771619]\n",
      "epoch:12 step:10060 [D loss: 0.721955, acc.: 42.97%] [G loss: 0.773463]\n",
      "epoch:12 step:10061 [D loss: 0.698687, acc.: 53.91%] [G loss: 0.731473]\n",
      "epoch:12 step:10062 [D loss: 0.690153, acc.: 55.47%] [G loss: 0.769005]\n",
      "epoch:12 step:10063 [D loss: 0.671561, acc.: 60.16%] [G loss: 0.689186]\n",
      "epoch:12 step:10064 [D loss: 0.801011, acc.: 32.81%] [G loss: 0.683934]\n",
      "epoch:12 step:10065 [D loss: 0.647669, acc.: 64.84%] [G loss: 0.710815]\n",
      "epoch:12 step:10066 [D loss: 0.694968, acc.: 53.91%] [G loss: 0.691468]\n",
      "epoch:12 step:10067 [D loss: 0.717615, acc.: 49.22%] [G loss: 0.683564]\n",
      "epoch:12 step:10068 [D loss: 0.743479, acc.: 42.97%] [G loss: 0.664569]\n",
      "epoch:12 step:10069 [D loss: 0.806763, acc.: 31.25%] [G loss: 0.634515]\n",
      "epoch:12 step:10070 [D loss: 0.683721, acc.: 53.12%] [G loss: 0.771734]\n",
      "epoch:12 step:10071 [D loss: 0.737366, acc.: 39.06%] [G loss: 0.782928]\n",
      "epoch:12 step:10072 [D loss: 0.702148, acc.: 51.56%] [G loss: 0.762292]\n",
      "epoch:12 step:10073 [D loss: 0.689826, acc.: 50.00%] [G loss: 0.881754]\n",
      "epoch:12 step:10074 [D loss: 0.688485, acc.: 57.81%] [G loss: 0.931404]\n",
      "epoch:12 step:10075 [D loss: 0.682320, acc.: 56.25%] [G loss: 0.778705]\n",
      "epoch:12 step:10076 [D loss: 0.680648, acc.: 50.78%] [G loss: 0.783112]\n",
      "epoch:12 step:10077 [D loss: 0.656215, acc.: 64.06%] [G loss: 0.743491]\n",
      "epoch:12 step:10078 [D loss: 0.673825, acc.: 58.59%] [G loss: 0.786009]\n",
      "epoch:12 step:10079 [D loss: 0.710520, acc.: 47.66%] [G loss: 0.728241]\n",
      "epoch:12 step:10080 [D loss: 0.788447, acc.: 37.50%] [G loss: 0.765193]\n",
      "epoch:12 step:10081 [D loss: 0.706835, acc.: 53.91%] [G loss: 0.764588]\n",
      "epoch:12 step:10082 [D loss: 0.666639, acc.: 56.25%] [G loss: 0.757950]\n",
      "epoch:12 step:10083 [D loss: 0.694523, acc.: 53.91%] [G loss: 0.779017]\n",
      "epoch:12 step:10084 [D loss: 0.678879, acc.: 60.16%] [G loss: 0.799779]\n",
      "epoch:12 step:10085 [D loss: 0.706557, acc.: 46.09%] [G loss: 0.727391]\n",
      "epoch:12 step:10086 [D loss: 0.697700, acc.: 53.12%] [G loss: 0.793586]\n",
      "epoch:12 step:10087 [D loss: 0.681656, acc.: 59.38%] [G loss: 0.776381]\n",
      "epoch:12 step:10088 [D loss: 0.671219, acc.: 60.94%] [G loss: 0.660963]\n",
      "epoch:12 step:10089 [D loss: 0.636753, acc.: 69.53%] [G loss: 0.769139]\n",
      "epoch:12 step:10090 [D loss: 0.685137, acc.: 58.59%] [G loss: 0.773746]\n",
      "epoch:12 step:10091 [D loss: 0.690911, acc.: 53.91%] [G loss: 0.790461]\n",
      "epoch:12 step:10092 [D loss: 0.780802, acc.: 34.38%] [G loss: 0.707446]\n",
      "epoch:12 step:10093 [D loss: 0.695873, acc.: 50.00%] [G loss: 0.766282]\n",
      "epoch:12 step:10094 [D loss: 0.648051, acc.: 57.81%] [G loss: 0.717273]\n",
      "epoch:12 step:10095 [D loss: 0.753914, acc.: 41.41%] [G loss: 0.704465]\n",
      "epoch:12 step:10096 [D loss: 0.723332, acc.: 49.22%] [G loss: 0.708540]\n",
      "epoch:12 step:10097 [D loss: 0.688299, acc.: 53.12%] [G loss: 0.735190]\n",
      "epoch:12 step:10098 [D loss: 0.690593, acc.: 51.56%] [G loss: 0.764998]\n",
      "epoch:12 step:10099 [D loss: 0.678646, acc.: 56.25%] [G loss: 0.768865]\n",
      "epoch:12 step:10100 [D loss: 0.702972, acc.: 52.34%] [G loss: 0.772437]\n",
      "epoch:12 step:10101 [D loss: 0.703979, acc.: 50.00%] [G loss: 0.813920]\n",
      "epoch:12 step:10102 [D loss: 0.667493, acc.: 57.81%] [G loss: 0.820741]\n",
      "epoch:12 step:10103 [D loss: 0.642023, acc.: 65.62%] [G loss: 0.774655]\n",
      "epoch:12 step:10104 [D loss: 0.688489, acc.: 49.22%] [G loss: 0.797570]\n",
      "epoch:12 step:10105 [D loss: 0.634740, acc.: 70.31%] [G loss: 0.726038]\n",
      "epoch:12 step:10106 [D loss: 0.716236, acc.: 50.00%] [G loss: 0.746401]\n",
      "epoch:12 step:10107 [D loss: 0.714229, acc.: 47.66%] [G loss: 0.790732]\n",
      "epoch:12 step:10108 [D loss: 0.649541, acc.: 67.19%] [G loss: 0.796468]\n",
      "epoch:12 step:10109 [D loss: 0.670298, acc.: 57.81%] [G loss: 0.751392]\n",
      "epoch:12 step:10110 [D loss: 0.680610, acc.: 61.72%] [G loss: 0.718064]\n",
      "epoch:12 step:10111 [D loss: 0.750258, acc.: 36.72%] [G loss: 0.758352]\n",
      "epoch:12 step:10112 [D loss: 0.690266, acc.: 55.47%] [G loss: 0.689216]\n",
      "epoch:12 step:10113 [D loss: 0.636422, acc.: 63.28%] [G loss: 0.679299]\n",
      "epoch:12 step:10114 [D loss: 0.758693, acc.: 37.50%] [G loss: 0.619408]\n",
      "epoch:12 step:10115 [D loss: 0.715572, acc.: 50.78%] [G loss: 0.693466]\n",
      "epoch:12 step:10116 [D loss: 0.728439, acc.: 48.44%] [G loss: 0.654583]\n",
      "epoch:12 step:10117 [D loss: 0.740575, acc.: 35.94%] [G loss: 0.648118]\n",
      "epoch:12 step:10118 [D loss: 0.698193, acc.: 53.91%] [G loss: 0.723831]\n",
      "epoch:12 step:10119 [D loss: 0.719460, acc.: 47.66%] [G loss: 0.747656]\n",
      "epoch:12 step:10120 [D loss: 0.787156, acc.: 28.12%] [G loss: 0.776579]\n",
      "epoch:12 step:10121 [D loss: 0.722298, acc.: 47.66%] [G loss: 0.776588]\n",
      "epoch:12 step:10122 [D loss: 0.713693, acc.: 47.66%] [G loss: 0.757868]\n",
      "epoch:12 step:10123 [D loss: 0.710697, acc.: 45.31%] [G loss: 0.782726]\n",
      "epoch:12 step:10124 [D loss: 0.758874, acc.: 37.50%] [G loss: 0.738317]\n",
      "epoch:12 step:10125 [D loss: 0.746455, acc.: 42.97%] [G loss: 0.826509]\n",
      "epoch:12 step:10126 [D loss: 0.702679, acc.: 49.22%] [G loss: 0.755162]\n",
      "epoch:12 step:10127 [D loss: 0.664465, acc.: 60.94%] [G loss: 0.868365]\n",
      "epoch:12 step:10128 [D loss: 0.693297, acc.: 53.91%] [G loss: 0.806118]\n",
      "epoch:12 step:10129 [D loss: 0.695982, acc.: 54.69%] [G loss: 0.768139]\n",
      "epoch:12 step:10130 [D loss: 0.704719, acc.: 52.34%] [G loss: 0.827802]\n",
      "epoch:12 step:10131 [D loss: 0.705928, acc.: 45.31%] [G loss: 0.749035]\n",
      "epoch:12 step:10132 [D loss: 0.672897, acc.: 58.59%] [G loss: 0.733880]\n",
      "epoch:12 step:10133 [D loss: 0.652241, acc.: 60.94%] [G loss: 0.712410]\n",
      "epoch:12 step:10134 [D loss: 0.676718, acc.: 60.16%] [G loss: 0.724101]\n",
      "epoch:12 step:10135 [D loss: 0.715217, acc.: 49.22%] [G loss: 0.739941]\n",
      "epoch:12 step:10136 [D loss: 0.738317, acc.: 42.19%] [G loss: 0.683085]\n",
      "epoch:12 step:10137 [D loss: 0.699870, acc.: 46.88%] [G loss: 0.736000]\n",
      "epoch:12 step:10138 [D loss: 0.656233, acc.: 61.72%] [G loss: 0.795669]\n",
      "epoch:12 step:10139 [D loss: 0.709076, acc.: 52.34%] [G loss: 0.813759]\n",
      "epoch:12 step:10140 [D loss: 0.694149, acc.: 55.47%] [G loss: 0.873987]\n",
      "epoch:12 step:10141 [D loss: 0.747054, acc.: 41.41%] [G loss: 0.862908]\n",
      "epoch:12 step:10142 [D loss: 0.664220, acc.: 53.91%] [G loss: 0.838550]\n",
      "epoch:12 step:10143 [D loss: 0.677335, acc.: 58.59%] [G loss: 0.884693]\n",
      "epoch:12 step:10144 [D loss: 0.738318, acc.: 38.28%] [G loss: 0.739613]\n",
      "epoch:12 step:10145 [D loss: 0.688554, acc.: 51.56%] [G loss: 0.750255]\n",
      "epoch:12 step:10146 [D loss: 0.674617, acc.: 59.38%] [G loss: 0.777994]\n",
      "epoch:12 step:10147 [D loss: 0.710252, acc.: 48.44%] [G loss: 0.775430]\n",
      "epoch:12 step:10148 [D loss: 0.694766, acc.: 54.69%] [G loss: 0.822670]\n",
      "epoch:12 step:10149 [D loss: 0.653225, acc.: 63.28%] [G loss: 0.789313]\n",
      "epoch:12 step:10150 [D loss: 0.669588, acc.: 60.94%] [G loss: 0.794582]\n",
      "epoch:12 step:10151 [D loss: 0.692195, acc.: 59.38%] [G loss: 0.812999]\n",
      "epoch:12 step:10152 [D loss: 0.727148, acc.: 48.44%] [G loss: 0.744940]\n",
      "epoch:12 step:10153 [D loss: 0.623734, acc.: 73.44%] [G loss: 0.766477]\n",
      "epoch:13 step:10154 [D loss: 0.698722, acc.: 53.12%] [G loss: 0.780404]\n",
      "epoch:13 step:10155 [D loss: 0.675526, acc.: 55.47%] [G loss: 0.729946]\n",
      "epoch:13 step:10156 [D loss: 0.676602, acc.: 50.78%] [G loss: 0.728934]\n",
      "epoch:13 step:10157 [D loss: 0.721604, acc.: 41.41%] [G loss: 0.783881]\n",
      "epoch:13 step:10158 [D loss: 0.648893, acc.: 60.94%] [G loss: 0.675018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10159 [D loss: 0.649955, acc.: 65.62%] [G loss: 0.715867]\n",
      "epoch:13 step:10160 [D loss: 0.686121, acc.: 56.25%] [G loss: 0.723116]\n",
      "epoch:13 step:10161 [D loss: 0.677329, acc.: 60.16%] [G loss: 0.839374]\n",
      "epoch:13 step:10162 [D loss: 0.768793, acc.: 37.50%] [G loss: 0.747084]\n",
      "epoch:13 step:10163 [D loss: 0.694045, acc.: 57.03%] [G loss: 0.689490]\n",
      "epoch:13 step:10164 [D loss: 0.689868, acc.: 50.78%] [G loss: 0.730215]\n",
      "epoch:13 step:10165 [D loss: 0.669015, acc.: 62.50%] [G loss: 0.697717]\n",
      "epoch:13 step:10166 [D loss: 0.730025, acc.: 46.09%] [G loss: 0.651472]\n",
      "epoch:13 step:10167 [D loss: 0.725047, acc.: 43.75%] [G loss: 0.692353]\n",
      "epoch:13 step:10168 [D loss: 0.752207, acc.: 39.84%] [G loss: 0.743888]\n",
      "epoch:13 step:10169 [D loss: 0.760845, acc.: 42.19%] [G loss: 0.647754]\n",
      "epoch:13 step:10170 [D loss: 0.720663, acc.: 49.22%] [G loss: 0.752576]\n",
      "epoch:13 step:10171 [D loss: 0.700267, acc.: 46.88%] [G loss: 0.803606]\n",
      "epoch:13 step:10172 [D loss: 0.716284, acc.: 42.19%] [G loss: 0.787445]\n",
      "epoch:13 step:10173 [D loss: 0.685322, acc.: 54.69%] [G loss: 0.816731]\n",
      "epoch:13 step:10174 [D loss: 0.657219, acc.: 57.81%] [G loss: 0.823674]\n",
      "epoch:13 step:10175 [D loss: 0.693153, acc.: 49.22%] [G loss: 0.824283]\n",
      "epoch:13 step:10176 [D loss: 0.696061, acc.: 48.44%] [G loss: 0.841388]\n",
      "epoch:13 step:10177 [D loss: 0.712876, acc.: 50.00%] [G loss: 0.740052]\n",
      "epoch:13 step:10178 [D loss: 0.681094, acc.: 54.69%] [G loss: 0.701890]\n",
      "epoch:13 step:10179 [D loss: 0.706885, acc.: 46.88%] [G loss: 0.710585]\n",
      "epoch:13 step:10180 [D loss: 0.609540, acc.: 78.12%] [G loss: 0.760507]\n",
      "epoch:13 step:10181 [D loss: 0.710516, acc.: 50.78%] [G loss: 0.728568]\n",
      "epoch:13 step:10182 [D loss: 0.691710, acc.: 54.69%] [G loss: 0.769358]\n",
      "epoch:13 step:10183 [D loss: 0.640016, acc.: 69.53%] [G loss: 0.739513]\n",
      "epoch:13 step:10184 [D loss: 0.676990, acc.: 61.72%] [G loss: 0.720083]\n",
      "epoch:13 step:10185 [D loss: 0.675875, acc.: 53.12%] [G loss: 0.714191]\n",
      "epoch:13 step:10186 [D loss: 0.676744, acc.: 56.25%] [G loss: 0.691944]\n",
      "epoch:13 step:10187 [D loss: 0.693511, acc.: 55.47%] [G loss: 0.752014]\n",
      "epoch:13 step:10188 [D loss: 0.684224, acc.: 59.38%] [G loss: 0.688455]\n",
      "epoch:13 step:10189 [D loss: 0.621756, acc.: 78.12%] [G loss: 0.721245]\n",
      "epoch:13 step:10190 [D loss: 0.695186, acc.: 50.78%] [G loss: 0.685310]\n",
      "epoch:13 step:10191 [D loss: 0.682145, acc.: 56.25%] [G loss: 0.659316]\n",
      "epoch:13 step:10192 [D loss: 0.765104, acc.: 36.72%] [G loss: 0.661344]\n",
      "epoch:13 step:10193 [D loss: 0.682677, acc.: 50.78%] [G loss: 0.677329]\n",
      "epoch:13 step:10194 [D loss: 0.673148, acc.: 55.47%] [G loss: 0.698540]\n",
      "epoch:13 step:10195 [D loss: 0.785397, acc.: 32.03%] [G loss: 0.694076]\n",
      "epoch:13 step:10196 [D loss: 0.776003, acc.: 34.38%] [G loss: 0.680600]\n",
      "epoch:13 step:10197 [D loss: 0.704490, acc.: 54.69%] [G loss: 0.692599]\n",
      "epoch:13 step:10198 [D loss: 0.691138, acc.: 50.78%] [G loss: 0.757495]\n",
      "epoch:13 step:10199 [D loss: 0.699521, acc.: 50.00%] [G loss: 0.799437]\n",
      "epoch:13 step:10200 [D loss: 0.672862, acc.: 57.03%] [G loss: 0.776540]\n",
      "epoch:13 step:10201 [D loss: 0.679403, acc.: 55.47%] [G loss: 0.757896]\n",
      "epoch:13 step:10202 [D loss: 0.697591, acc.: 54.69%] [G loss: 0.758950]\n",
      "epoch:13 step:10203 [D loss: 0.691817, acc.: 51.56%] [G loss: 0.747733]\n",
      "epoch:13 step:10204 [D loss: 0.673877, acc.: 54.69%] [G loss: 0.775353]\n",
      "epoch:13 step:10205 [D loss: 0.668088, acc.: 60.94%] [G loss: 0.799016]\n",
      "epoch:13 step:10206 [D loss: 0.648405, acc.: 64.84%] [G loss: 0.775552]\n",
      "epoch:13 step:10207 [D loss: 0.680309, acc.: 57.81%] [G loss: 0.772143]\n",
      "epoch:13 step:10208 [D loss: 0.665110, acc.: 60.94%] [G loss: 0.787301]\n",
      "epoch:13 step:10209 [D loss: 0.641216, acc.: 67.19%] [G loss: 0.780525]\n",
      "epoch:13 step:10210 [D loss: 0.678613, acc.: 54.69%] [G loss: 0.728092]\n",
      "epoch:13 step:10211 [D loss: 0.678327, acc.: 57.03%] [G loss: 0.763344]\n",
      "epoch:13 step:10212 [D loss: 0.635409, acc.: 69.53%] [G loss: 0.707347]\n",
      "epoch:13 step:10213 [D loss: 0.705883, acc.: 54.69%] [G loss: 0.769480]\n",
      "epoch:13 step:10214 [D loss: 0.687704, acc.: 55.47%] [G loss: 0.821755]\n",
      "epoch:13 step:10215 [D loss: 0.737412, acc.: 48.44%] [G loss: 0.756026]\n",
      "epoch:13 step:10216 [D loss: 0.652858, acc.: 60.16%] [G loss: 0.759958]\n",
      "epoch:13 step:10217 [D loss: 0.752722, acc.: 39.84%] [G loss: 0.770850]\n",
      "epoch:13 step:10218 [D loss: 0.782354, acc.: 37.50%] [G loss: 0.738566]\n",
      "epoch:13 step:10219 [D loss: 0.721170, acc.: 45.31%] [G loss: 0.795047]\n",
      "epoch:13 step:10220 [D loss: 0.669600, acc.: 55.47%] [G loss: 0.829260]\n",
      "epoch:13 step:10221 [D loss: 0.690126, acc.: 57.81%] [G loss: 0.746971]\n",
      "epoch:13 step:10222 [D loss: 0.687708, acc.: 56.25%] [G loss: 0.780846]\n",
      "epoch:13 step:10223 [D loss: 0.693643, acc.: 50.78%] [G loss: 0.785580]\n",
      "epoch:13 step:10224 [D loss: 0.717241, acc.: 42.19%] [G loss: 0.743863]\n",
      "epoch:13 step:10225 [D loss: 0.705423, acc.: 53.91%] [G loss: 0.727249]\n",
      "epoch:13 step:10226 [D loss: 0.674182, acc.: 60.16%] [G loss: 0.727437]\n",
      "epoch:13 step:10227 [D loss: 0.679670, acc.: 55.47%] [G loss: 0.778377]\n",
      "epoch:13 step:10228 [D loss: 0.673898, acc.: 55.47%] [G loss: 0.768302]\n",
      "epoch:13 step:10229 [D loss: 0.671075, acc.: 57.03%] [G loss: 0.794896]\n",
      "epoch:13 step:10230 [D loss: 0.699528, acc.: 50.00%] [G loss: 0.810473]\n",
      "epoch:13 step:10231 [D loss: 0.719364, acc.: 44.53%] [G loss: 0.750651]\n",
      "epoch:13 step:10232 [D loss: 0.688401, acc.: 52.34%] [G loss: 0.814331]\n",
      "epoch:13 step:10233 [D loss: 0.626961, acc.: 68.75%] [G loss: 0.908641]\n",
      "epoch:13 step:10234 [D loss: 0.662516, acc.: 63.28%] [G loss: 0.779197]\n",
      "epoch:13 step:10235 [D loss: 0.619338, acc.: 79.69%] [G loss: 0.796823]\n",
      "epoch:13 step:10236 [D loss: 0.679332, acc.: 60.16%] [G loss: 0.801738]\n",
      "epoch:13 step:10237 [D loss: 0.695458, acc.: 51.56%] [G loss: 0.815943]\n",
      "epoch:13 step:10238 [D loss: 0.697053, acc.: 51.56%] [G loss: 0.742085]\n",
      "epoch:13 step:10239 [D loss: 0.690613, acc.: 53.91%] [G loss: 0.711173]\n",
      "epoch:13 step:10240 [D loss: 0.688488, acc.: 59.38%] [G loss: 0.811368]\n",
      "epoch:13 step:10241 [D loss: 0.700176, acc.: 50.78%] [G loss: 0.839718]\n",
      "epoch:13 step:10242 [D loss: 0.720368, acc.: 46.88%] [G loss: 0.772806]\n",
      "epoch:13 step:10243 [D loss: 0.669048, acc.: 56.25%] [G loss: 0.804647]\n",
      "epoch:13 step:10244 [D loss: 0.708241, acc.: 52.34%] [G loss: 0.749412]\n",
      "epoch:13 step:10245 [D loss: 0.662541, acc.: 62.50%] [G loss: 0.793673]\n",
      "epoch:13 step:10246 [D loss: 0.686670, acc.: 57.03%] [G loss: 0.708011]\n",
      "epoch:13 step:10247 [D loss: 0.720130, acc.: 47.66%] [G loss: 0.757891]\n",
      "epoch:13 step:10248 [D loss: 0.674760, acc.: 57.03%] [G loss: 0.821223]\n",
      "epoch:13 step:10249 [D loss: 0.701090, acc.: 50.78%] [G loss: 0.775353]\n",
      "epoch:13 step:10250 [D loss: 0.741311, acc.: 40.62%] [G loss: 0.800752]\n",
      "epoch:13 step:10251 [D loss: 0.698185, acc.: 53.12%] [G loss: 0.883368]\n",
      "epoch:13 step:10252 [D loss: 0.707816, acc.: 42.97%] [G loss: 0.837941]\n",
      "epoch:13 step:10253 [D loss: 0.654607, acc.: 59.38%] [G loss: 0.882733]\n",
      "epoch:13 step:10254 [D loss: 0.651083, acc.: 66.41%] [G loss: 0.837485]\n",
      "epoch:13 step:10255 [D loss: 0.691526, acc.: 55.47%] [G loss: 0.808563]\n",
      "epoch:13 step:10256 [D loss: 0.708496, acc.: 46.88%] [G loss: 0.807010]\n",
      "epoch:13 step:10257 [D loss: 0.722257, acc.: 45.31%] [G loss: 0.678786]\n",
      "epoch:13 step:10258 [D loss: 0.688137, acc.: 57.03%] [G loss: 0.756957]\n",
      "epoch:13 step:10259 [D loss: 0.695416, acc.: 47.66%] [G loss: 0.713797]\n",
      "epoch:13 step:10260 [D loss: 0.700384, acc.: 45.31%] [G loss: 0.757438]\n",
      "epoch:13 step:10261 [D loss: 0.780356, acc.: 32.81%] [G loss: 0.728860]\n",
      "epoch:13 step:10262 [D loss: 0.708285, acc.: 50.00%] [G loss: 0.644169]\n",
      "epoch:13 step:10263 [D loss: 0.707212, acc.: 53.12%] [G loss: 0.759100]\n",
      "epoch:13 step:10264 [D loss: 0.717496, acc.: 43.75%] [G loss: 0.763998]\n",
      "epoch:13 step:10265 [D loss: 0.670116, acc.: 63.28%] [G loss: 0.815347]\n",
      "epoch:13 step:10266 [D loss: 0.681307, acc.: 50.00%] [G loss: 0.788738]\n",
      "epoch:13 step:10267 [D loss: 0.668791, acc.: 57.81%] [G loss: 0.775401]\n",
      "epoch:13 step:10268 [D loss: 0.682328, acc.: 56.25%] [G loss: 0.743675]\n",
      "epoch:13 step:10269 [D loss: 0.704483, acc.: 53.12%] [G loss: 0.772253]\n",
      "epoch:13 step:10270 [D loss: 0.680816, acc.: 48.44%] [G loss: 0.756904]\n",
      "epoch:13 step:10271 [D loss: 0.695640, acc.: 49.22%] [G loss: 0.741657]\n",
      "epoch:13 step:10272 [D loss: 0.656329, acc.: 57.81%] [G loss: 0.764568]\n",
      "epoch:13 step:10273 [D loss: 0.700373, acc.: 53.12%] [G loss: 0.772350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10274 [D loss: 0.650358, acc.: 58.59%] [G loss: 0.770942]\n",
      "epoch:13 step:10275 [D loss: 0.734002, acc.: 49.22%] [G loss: 0.777407]\n",
      "epoch:13 step:10276 [D loss: 0.756311, acc.: 40.62%] [G loss: 0.745395]\n",
      "epoch:13 step:10277 [D loss: 0.727291, acc.: 39.84%] [G loss: 0.781977]\n",
      "epoch:13 step:10278 [D loss: 0.755214, acc.: 37.50%] [G loss: 0.806275]\n",
      "epoch:13 step:10279 [D loss: 0.686760, acc.: 53.12%] [G loss: 0.708702]\n",
      "epoch:13 step:10280 [D loss: 0.699697, acc.: 48.44%] [G loss: 0.766634]\n",
      "epoch:13 step:10281 [D loss: 0.684527, acc.: 50.00%] [G loss: 0.783584]\n",
      "epoch:13 step:10282 [D loss: 0.718158, acc.: 46.09%] [G loss: 0.809339]\n",
      "epoch:13 step:10283 [D loss: 0.689641, acc.: 54.69%] [G loss: 0.757582]\n",
      "epoch:13 step:10284 [D loss: 0.713222, acc.: 52.34%] [G loss: 0.721309]\n",
      "epoch:13 step:10285 [D loss: 0.637473, acc.: 64.06%] [G loss: 0.866582]\n",
      "epoch:13 step:10286 [D loss: 0.693060, acc.: 51.56%] [G loss: 0.876855]\n",
      "epoch:13 step:10287 [D loss: 0.655173, acc.: 60.94%] [G loss: 0.806332]\n",
      "epoch:13 step:10288 [D loss: 0.756507, acc.: 41.41%] [G loss: 0.754194]\n",
      "epoch:13 step:10289 [D loss: 0.715640, acc.: 46.88%] [G loss: 0.718239]\n",
      "epoch:13 step:10290 [D loss: 0.734101, acc.: 43.75%] [G loss: 0.741135]\n",
      "epoch:13 step:10291 [D loss: 0.721592, acc.: 46.88%] [G loss: 0.734263]\n",
      "epoch:13 step:10292 [D loss: 0.691123, acc.: 59.38%] [G loss: 0.755662]\n",
      "epoch:13 step:10293 [D loss: 0.663889, acc.: 65.62%] [G loss: 0.770005]\n",
      "epoch:13 step:10294 [D loss: 0.752471, acc.: 35.94%] [G loss: 0.747567]\n",
      "epoch:13 step:10295 [D loss: 0.739262, acc.: 39.84%] [G loss: 0.781067]\n",
      "epoch:13 step:10296 [D loss: 0.733217, acc.: 45.31%] [G loss: 0.756474]\n",
      "epoch:13 step:10297 [D loss: 0.698549, acc.: 47.66%] [G loss: 0.748229]\n",
      "epoch:13 step:10298 [D loss: 0.658724, acc.: 64.06%] [G loss: 0.765044]\n",
      "epoch:13 step:10299 [D loss: 0.641283, acc.: 68.75%] [G loss: 0.740133]\n",
      "epoch:13 step:10300 [D loss: 0.667856, acc.: 61.72%] [G loss: 0.763957]\n",
      "epoch:13 step:10301 [D loss: 0.722271, acc.: 48.44%] [G loss: 0.800690]\n",
      "epoch:13 step:10302 [D loss: 0.736957, acc.: 46.88%] [G loss: 0.714087]\n",
      "epoch:13 step:10303 [D loss: 0.743169, acc.: 42.97%] [G loss: 0.697911]\n",
      "epoch:13 step:10304 [D loss: 0.750312, acc.: 41.41%] [G loss: 0.759802]\n",
      "epoch:13 step:10305 [D loss: 0.719966, acc.: 44.53%] [G loss: 0.736467]\n",
      "epoch:13 step:10306 [D loss: 0.703072, acc.: 48.44%] [G loss: 0.688580]\n",
      "epoch:13 step:10307 [D loss: 0.684817, acc.: 55.47%] [G loss: 0.739963]\n",
      "epoch:13 step:10308 [D loss: 0.692714, acc.: 56.25%] [G loss: 0.672616]\n",
      "epoch:13 step:10309 [D loss: 0.722996, acc.: 43.75%] [G loss: 0.766798]\n",
      "epoch:13 step:10310 [D loss: 0.685736, acc.: 53.12%] [G loss: 0.815530]\n",
      "epoch:13 step:10311 [D loss: 0.728437, acc.: 43.75%] [G loss: 0.701232]\n",
      "epoch:13 step:10312 [D loss: 0.721439, acc.: 49.22%] [G loss: 0.791827]\n",
      "epoch:13 step:10313 [D loss: 0.640815, acc.: 67.19%] [G loss: 0.758552]\n",
      "epoch:13 step:10314 [D loss: 0.717105, acc.: 39.84%] [G loss: 0.670990]\n",
      "epoch:13 step:10315 [D loss: 0.713353, acc.: 47.66%] [G loss: 0.707999]\n",
      "epoch:13 step:10316 [D loss: 0.705890, acc.: 50.78%] [G loss: 0.786837]\n",
      "epoch:13 step:10317 [D loss: 0.688663, acc.: 57.03%] [G loss: 0.763555]\n",
      "epoch:13 step:10318 [D loss: 0.701248, acc.: 52.34%] [G loss: 0.768224]\n",
      "epoch:13 step:10319 [D loss: 0.719802, acc.: 47.66%] [G loss: 0.785075]\n",
      "epoch:13 step:10320 [D loss: 0.738434, acc.: 44.53%] [G loss: 0.765852]\n",
      "epoch:13 step:10321 [D loss: 0.733097, acc.: 37.50%] [G loss: 0.724364]\n",
      "epoch:13 step:10322 [D loss: 0.688235, acc.: 54.69%] [G loss: 0.757129]\n",
      "epoch:13 step:10323 [D loss: 0.685336, acc.: 57.03%] [G loss: 0.776954]\n",
      "epoch:13 step:10324 [D loss: 0.690739, acc.: 53.91%] [G loss: 0.785684]\n",
      "epoch:13 step:10325 [D loss: 0.711147, acc.: 52.34%] [G loss: 0.769330]\n",
      "epoch:13 step:10326 [D loss: 0.766390, acc.: 28.91%] [G loss: 0.759801]\n",
      "epoch:13 step:10327 [D loss: 0.697402, acc.: 52.34%] [G loss: 0.778429]\n",
      "epoch:13 step:10328 [D loss: 0.748392, acc.: 39.84%] [G loss: 0.748130]\n",
      "epoch:13 step:10329 [D loss: 0.751130, acc.: 35.16%] [G loss: 0.800966]\n",
      "epoch:13 step:10330 [D loss: 0.670712, acc.: 59.38%] [G loss: 0.821502]\n",
      "epoch:13 step:10331 [D loss: 0.659872, acc.: 59.38%] [G loss: 0.836839]\n",
      "epoch:13 step:10332 [D loss: 0.676816, acc.: 57.03%] [G loss: 0.739569]\n",
      "epoch:13 step:10333 [D loss: 0.652665, acc.: 62.50%] [G loss: 0.726808]\n",
      "epoch:13 step:10334 [D loss: 0.676568, acc.: 60.94%] [G loss: 0.836713]\n",
      "epoch:13 step:10335 [D loss: 0.733347, acc.: 48.44%] [G loss: 0.788727]\n",
      "epoch:13 step:10336 [D loss: 0.684509, acc.: 54.69%] [G loss: 0.747082]\n",
      "epoch:13 step:10337 [D loss: 0.662129, acc.: 59.38%] [G loss: 0.830446]\n",
      "epoch:13 step:10338 [D loss: 0.621091, acc.: 76.56%] [G loss: 0.810766]\n",
      "epoch:13 step:10339 [D loss: 0.684346, acc.: 54.69%] [G loss: 0.799612]\n",
      "epoch:13 step:10340 [D loss: 0.682635, acc.: 53.12%] [G loss: 0.701324]\n",
      "epoch:13 step:10341 [D loss: 0.719278, acc.: 42.97%] [G loss: 0.703707]\n",
      "epoch:13 step:10342 [D loss: 0.676210, acc.: 57.03%] [G loss: 0.708804]\n",
      "epoch:13 step:10343 [D loss: 0.676152, acc.: 59.38%] [G loss: 0.737605]\n",
      "epoch:13 step:10344 [D loss: 0.701697, acc.: 47.66%] [G loss: 0.787883]\n",
      "epoch:13 step:10345 [D loss: 0.646447, acc.: 64.06%] [G loss: 0.757076]\n",
      "epoch:13 step:10346 [D loss: 0.710903, acc.: 50.00%] [G loss: 0.721770]\n",
      "epoch:13 step:10347 [D loss: 0.724419, acc.: 42.19%] [G loss: 0.743235]\n",
      "epoch:13 step:10348 [D loss: 0.685511, acc.: 56.25%] [G loss: 0.731640]\n",
      "epoch:13 step:10349 [D loss: 0.721007, acc.: 52.34%] [G loss: 0.693015]\n",
      "epoch:13 step:10350 [D loss: 0.730156, acc.: 47.66%] [G loss: 0.669189]\n",
      "epoch:13 step:10351 [D loss: 0.718038, acc.: 46.09%] [G loss: 0.768446]\n",
      "epoch:13 step:10352 [D loss: 0.684526, acc.: 50.78%] [G loss: 0.722576]\n",
      "epoch:13 step:10353 [D loss: 0.717383, acc.: 45.31%] [G loss: 0.722858]\n",
      "epoch:13 step:10354 [D loss: 0.680001, acc.: 58.59%] [G loss: 0.679098]\n",
      "epoch:13 step:10355 [D loss: 0.680132, acc.: 50.78%] [G loss: 0.795328]\n",
      "epoch:13 step:10356 [D loss: 0.698482, acc.: 53.12%] [G loss: 0.766555]\n",
      "epoch:13 step:10357 [D loss: 0.683148, acc.: 61.72%] [G loss: 0.799196]\n",
      "epoch:13 step:10358 [D loss: 0.692660, acc.: 55.47%] [G loss: 0.752511]\n",
      "epoch:13 step:10359 [D loss: 0.711233, acc.: 46.09%] [G loss: 0.814791]\n",
      "epoch:13 step:10360 [D loss: 0.651591, acc.: 66.41%] [G loss: 0.820139]\n",
      "epoch:13 step:10361 [D loss: 0.721380, acc.: 47.66%] [G loss: 0.770937]\n",
      "epoch:13 step:10362 [D loss: 0.687086, acc.: 50.78%] [G loss: 0.808325]\n",
      "epoch:13 step:10363 [D loss: 0.668766, acc.: 60.94%] [G loss: 0.846283]\n",
      "epoch:13 step:10364 [D loss: 0.699574, acc.: 55.47%] [G loss: 0.778099]\n",
      "epoch:13 step:10365 [D loss: 0.670108, acc.: 62.50%] [G loss: 0.809749]\n",
      "epoch:13 step:10366 [D loss: 0.674068, acc.: 66.41%] [G loss: 0.791309]\n",
      "epoch:13 step:10367 [D loss: 0.667449, acc.: 55.47%] [G loss: 0.788464]\n",
      "epoch:13 step:10368 [D loss: 0.684569, acc.: 60.94%] [G loss: 0.784744]\n",
      "epoch:13 step:10369 [D loss: 0.737231, acc.: 46.09%] [G loss: 0.725247]\n",
      "epoch:13 step:10370 [D loss: 0.711487, acc.: 45.31%] [G loss: 0.715574]\n",
      "epoch:13 step:10371 [D loss: 0.706448, acc.: 48.44%] [G loss: 0.680389]\n",
      "epoch:13 step:10372 [D loss: 0.679847, acc.: 54.69%] [G loss: 0.767181]\n",
      "epoch:13 step:10373 [D loss: 0.726929, acc.: 48.44%] [G loss: 0.694217]\n",
      "epoch:13 step:10374 [D loss: 0.704712, acc.: 53.91%] [G loss: 0.682673]\n",
      "epoch:13 step:10375 [D loss: 0.712043, acc.: 50.78%] [G loss: 0.672642]\n",
      "epoch:13 step:10376 [D loss: 0.738990, acc.: 41.41%] [G loss: 0.754683]\n",
      "epoch:13 step:10377 [D loss: 0.710671, acc.: 50.78%] [G loss: 0.743452]\n",
      "epoch:13 step:10378 [D loss: 0.692949, acc.: 56.25%] [G loss: 0.738981]\n",
      "epoch:13 step:10379 [D loss: 0.769850, acc.: 32.81%] [G loss: 0.767666]\n",
      "epoch:13 step:10380 [D loss: 0.699326, acc.: 53.91%] [G loss: 0.822128]\n",
      "epoch:13 step:10381 [D loss: 0.732867, acc.: 43.75%] [G loss: 0.736389]\n",
      "epoch:13 step:10382 [D loss: 0.673597, acc.: 57.03%] [G loss: 0.731333]\n",
      "epoch:13 step:10383 [D loss: 0.702636, acc.: 54.69%] [G loss: 0.727363]\n",
      "epoch:13 step:10384 [D loss: 0.708307, acc.: 47.66%] [G loss: 0.724496]\n",
      "epoch:13 step:10385 [D loss: 0.741011, acc.: 43.75%] [G loss: 0.720340]\n",
      "epoch:13 step:10386 [D loss: 0.647219, acc.: 72.66%] [G loss: 0.836260]\n",
      "epoch:13 step:10387 [D loss: 0.737774, acc.: 46.88%] [G loss: 0.757821]\n",
      "epoch:13 step:10388 [D loss: 0.777135, acc.: 35.16%] [G loss: 0.684114]\n",
      "epoch:13 step:10389 [D loss: 0.723304, acc.: 47.66%] [G loss: 0.667861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10390 [D loss: 0.733041, acc.: 43.75%] [G loss: 0.713024]\n",
      "epoch:13 step:10391 [D loss: 0.701612, acc.: 56.25%] [G loss: 0.701139]\n",
      "epoch:13 step:10392 [D loss: 0.714448, acc.: 51.56%] [G loss: 0.675564]\n",
      "epoch:13 step:10393 [D loss: 0.759951, acc.: 36.72%] [G loss: 0.705034]\n",
      "epoch:13 step:10394 [D loss: 0.702565, acc.: 47.66%] [G loss: 0.810936]\n",
      "epoch:13 step:10395 [D loss: 0.690334, acc.: 60.94%] [G loss: 0.741461]\n",
      "epoch:13 step:10396 [D loss: 0.700466, acc.: 55.47%] [G loss: 0.785255]\n",
      "epoch:13 step:10397 [D loss: 0.685912, acc.: 57.81%] [G loss: 0.802054]\n",
      "epoch:13 step:10398 [D loss: 0.709888, acc.: 48.44%] [G loss: 0.706600]\n",
      "epoch:13 step:10399 [D loss: 0.696053, acc.: 54.69%] [G loss: 0.766821]\n",
      "epoch:13 step:10400 [D loss: 0.688717, acc.: 52.34%] [G loss: 0.762586]\n",
      "epoch:13 step:10401 [D loss: 0.675404, acc.: 59.38%] [G loss: 0.724732]\n",
      "epoch:13 step:10402 [D loss: 0.742488, acc.: 37.50%] [G loss: 0.734559]\n",
      "epoch:13 step:10403 [D loss: 0.735840, acc.: 42.97%] [G loss: 0.730191]\n",
      "epoch:13 step:10404 [D loss: 0.706774, acc.: 52.34%] [G loss: 0.750485]\n",
      "epoch:13 step:10405 [D loss: 0.743969, acc.: 37.50%] [G loss: 0.731513]\n",
      "epoch:13 step:10406 [D loss: 0.746095, acc.: 39.06%] [G loss: 0.764171]\n",
      "epoch:13 step:10407 [D loss: 0.706763, acc.: 48.44%] [G loss: 0.745187]\n",
      "epoch:13 step:10408 [D loss: 0.722833, acc.: 46.09%] [G loss: 0.746572]\n",
      "epoch:13 step:10409 [D loss: 0.725901, acc.: 43.75%] [G loss: 0.767517]\n",
      "epoch:13 step:10410 [D loss: 0.663617, acc.: 60.94%] [G loss: 0.771031]\n",
      "epoch:13 step:10411 [D loss: 0.675452, acc.: 54.69%] [G loss: 0.757747]\n",
      "epoch:13 step:10412 [D loss: 0.671582, acc.: 58.59%] [G loss: 0.795335]\n",
      "epoch:13 step:10413 [D loss: 0.698328, acc.: 53.12%] [G loss: 0.813229]\n",
      "epoch:13 step:10414 [D loss: 0.692452, acc.: 53.91%] [G loss: 0.836653]\n",
      "epoch:13 step:10415 [D loss: 0.737572, acc.: 44.53%] [G loss: 0.840431]\n",
      "epoch:13 step:10416 [D loss: 0.685886, acc.: 55.47%] [G loss: 0.795740]\n",
      "epoch:13 step:10417 [D loss: 0.714168, acc.: 50.00%] [G loss: 0.794613]\n",
      "epoch:13 step:10418 [D loss: 0.674893, acc.: 56.25%] [G loss: 0.775836]\n",
      "epoch:13 step:10419 [D loss: 0.729983, acc.: 43.75%] [G loss: 0.758682]\n",
      "epoch:13 step:10420 [D loss: 0.762768, acc.: 33.59%] [G loss: 0.733749]\n",
      "epoch:13 step:10421 [D loss: 0.688606, acc.: 52.34%] [G loss: 0.758599]\n",
      "epoch:13 step:10422 [D loss: 0.656161, acc.: 64.84%] [G loss: 0.742044]\n",
      "epoch:13 step:10423 [D loss: 0.707914, acc.: 53.91%] [G loss: 0.724953]\n",
      "epoch:13 step:10424 [D loss: 0.688190, acc.: 50.78%] [G loss: 0.692081]\n",
      "epoch:13 step:10425 [D loss: 0.718162, acc.: 39.84%] [G loss: 0.730994]\n",
      "epoch:13 step:10426 [D loss: 0.668188, acc.: 60.94%] [G loss: 0.730990]\n",
      "epoch:13 step:10427 [D loss: 0.731648, acc.: 46.09%] [G loss: 0.759077]\n",
      "epoch:13 step:10428 [D loss: 0.707501, acc.: 51.56%] [G loss: 0.759232]\n",
      "epoch:13 step:10429 [D loss: 0.686776, acc.: 57.03%] [G loss: 0.678370]\n",
      "epoch:13 step:10430 [D loss: 0.750669, acc.: 38.28%] [G loss: 0.785709]\n",
      "epoch:13 step:10431 [D loss: 0.723395, acc.: 39.84%] [G loss: 0.682423]\n",
      "epoch:13 step:10432 [D loss: 0.734554, acc.: 44.53%] [G loss: 0.738513]\n",
      "epoch:13 step:10433 [D loss: 0.725684, acc.: 37.50%] [G loss: 0.739261]\n",
      "epoch:13 step:10434 [D loss: 0.701042, acc.: 53.12%] [G loss: 0.793383]\n",
      "epoch:13 step:10435 [D loss: 0.692297, acc.: 53.12%] [G loss: 0.863601]\n",
      "epoch:13 step:10436 [D loss: 0.702639, acc.: 48.44%] [G loss: 0.848237]\n",
      "epoch:13 step:10437 [D loss: 0.662075, acc.: 62.50%] [G loss: 0.865378]\n",
      "epoch:13 step:10438 [D loss: 0.719597, acc.: 48.44%] [G loss: 0.820868]\n",
      "epoch:13 step:10439 [D loss: 0.715476, acc.: 49.22%] [G loss: 0.819214]\n",
      "epoch:13 step:10440 [D loss: 0.753895, acc.: 38.28%] [G loss: 0.792814]\n",
      "epoch:13 step:10441 [D loss: 0.712896, acc.: 46.88%] [G loss: 0.716037]\n",
      "epoch:13 step:10442 [D loss: 0.732620, acc.: 46.09%] [G loss: 0.713561]\n",
      "epoch:13 step:10443 [D loss: 0.659286, acc.: 60.16%] [G loss: 0.767273]\n",
      "epoch:13 step:10444 [D loss: 0.708026, acc.: 46.88%] [G loss: 0.778664]\n",
      "epoch:13 step:10445 [D loss: 0.691267, acc.: 56.25%] [G loss: 0.742164]\n",
      "epoch:13 step:10446 [D loss: 0.691403, acc.: 53.91%] [G loss: 0.756167]\n",
      "epoch:13 step:10447 [D loss: 0.720156, acc.: 40.62%] [G loss: 0.743583]\n",
      "epoch:13 step:10448 [D loss: 0.669088, acc.: 53.91%] [G loss: 0.816556]\n",
      "epoch:13 step:10449 [D loss: 0.725726, acc.: 42.97%] [G loss: 0.747218]\n",
      "epoch:13 step:10450 [D loss: 0.645930, acc.: 60.16%] [G loss: 0.813937]\n",
      "epoch:13 step:10451 [D loss: 0.676674, acc.: 60.16%] [G loss: 0.870270]\n",
      "epoch:13 step:10452 [D loss: 0.731177, acc.: 42.97%] [G loss: 0.727837]\n",
      "epoch:13 step:10453 [D loss: 0.751393, acc.: 34.38%] [G loss: 0.701748]\n",
      "epoch:13 step:10454 [D loss: 0.676938, acc.: 57.81%] [G loss: 0.736033]\n",
      "epoch:13 step:10455 [D loss: 0.680076, acc.: 57.03%] [G loss: 0.735495]\n",
      "epoch:13 step:10456 [D loss: 0.665083, acc.: 57.03%] [G loss: 0.690471]\n",
      "epoch:13 step:10457 [D loss: 0.673866, acc.: 60.94%] [G loss: 0.720430]\n",
      "epoch:13 step:10458 [D loss: 0.707145, acc.: 48.44%] [G loss: 0.732234]\n",
      "epoch:13 step:10459 [D loss: 0.688813, acc.: 53.91%] [G loss: 0.712270]\n",
      "epoch:13 step:10460 [D loss: 0.702530, acc.: 52.34%] [G loss: 0.714356]\n",
      "epoch:13 step:10461 [D loss: 0.666073, acc.: 57.81%] [G loss: 0.735336]\n",
      "epoch:13 step:10462 [D loss: 0.697005, acc.: 50.00%] [G loss: 0.728134]\n",
      "epoch:13 step:10463 [D loss: 0.652239, acc.: 63.28%] [G loss: 0.701900]\n",
      "epoch:13 step:10464 [D loss: 0.699081, acc.: 56.25%] [G loss: 0.733346]\n",
      "epoch:13 step:10465 [D loss: 0.741037, acc.: 41.41%] [G loss: 0.630769]\n",
      "epoch:13 step:10466 [D loss: 0.736381, acc.: 41.41%] [G loss: 0.740690]\n",
      "epoch:13 step:10467 [D loss: 0.732181, acc.: 41.41%] [G loss: 0.717206]\n",
      "epoch:13 step:10468 [D loss: 0.778079, acc.: 35.16%] [G loss: 0.723193]\n",
      "epoch:13 step:10469 [D loss: 0.694208, acc.: 54.69%] [G loss: 0.689355]\n",
      "epoch:13 step:10470 [D loss: 0.689574, acc.: 50.00%] [G loss: 0.704639]\n",
      "epoch:13 step:10471 [D loss: 0.700411, acc.: 54.69%] [G loss: 0.749434]\n",
      "epoch:13 step:10472 [D loss: 0.696624, acc.: 57.81%] [G loss: 0.766991]\n",
      "epoch:13 step:10473 [D loss: 0.738907, acc.: 42.97%] [G loss: 0.780195]\n",
      "epoch:13 step:10474 [D loss: 0.734989, acc.: 39.84%] [G loss: 0.794881]\n",
      "epoch:13 step:10475 [D loss: 0.687517, acc.: 58.59%] [G loss: 0.730500]\n",
      "epoch:13 step:10476 [D loss: 0.662611, acc.: 61.72%] [G loss: 0.708740]\n",
      "epoch:13 step:10477 [D loss: 0.702276, acc.: 52.34%] [G loss: 0.740054]\n",
      "epoch:13 step:10478 [D loss: 0.656422, acc.: 63.28%] [G loss: 0.865442]\n",
      "epoch:13 step:10479 [D loss: 0.749415, acc.: 39.06%] [G loss: 0.838348]\n",
      "epoch:13 step:10480 [D loss: 0.730206, acc.: 42.97%] [G loss: 0.784176]\n",
      "epoch:13 step:10481 [D loss: 0.716390, acc.: 46.09%] [G loss: 0.836593]\n",
      "epoch:13 step:10482 [D loss: 0.696374, acc.: 52.34%] [G loss: 0.815700]\n",
      "epoch:13 step:10483 [D loss: 0.699541, acc.: 50.78%] [G loss: 0.754425]\n",
      "epoch:13 step:10484 [D loss: 0.655686, acc.: 64.06%] [G loss: 0.789624]\n",
      "epoch:13 step:10485 [D loss: 0.689826, acc.: 53.91%] [G loss: 0.731734]\n",
      "epoch:13 step:10486 [D loss: 0.722047, acc.: 42.97%] [G loss: 0.768115]\n",
      "epoch:13 step:10487 [D loss: 0.657986, acc.: 59.38%] [G loss: 0.835344]\n",
      "epoch:13 step:10488 [D loss: 0.678773, acc.: 50.00%] [G loss: 0.725491]\n",
      "epoch:13 step:10489 [D loss: 0.664806, acc.: 60.16%] [G loss: 0.738247]\n",
      "epoch:13 step:10490 [D loss: 0.717979, acc.: 45.31%] [G loss: 0.725198]\n",
      "epoch:13 step:10491 [D loss: 0.761682, acc.: 37.50%] [G loss: 0.668870]\n",
      "epoch:13 step:10492 [D loss: 0.685623, acc.: 49.22%] [G loss: 0.705837]\n",
      "epoch:13 step:10493 [D loss: 0.679181, acc.: 53.12%] [G loss: 0.713339]\n",
      "epoch:13 step:10494 [D loss: 0.691244, acc.: 50.00%] [G loss: 0.784608]\n",
      "epoch:13 step:10495 [D loss: 0.698360, acc.: 53.12%] [G loss: 0.794081]\n",
      "epoch:13 step:10496 [D loss: 0.663293, acc.: 60.16%] [G loss: 0.764570]\n",
      "epoch:13 step:10497 [D loss: 0.739324, acc.: 39.06%] [G loss: 0.751227]\n",
      "epoch:13 step:10498 [D loss: 0.744241, acc.: 41.41%] [G loss: 0.810087]\n",
      "epoch:13 step:10499 [D loss: 0.699491, acc.: 49.22%] [G loss: 0.776813]\n",
      "epoch:13 step:10500 [D loss: 0.711352, acc.: 53.91%] [G loss: 0.762377]\n",
      "epoch:13 step:10501 [D loss: 0.734043, acc.: 40.62%] [G loss: 0.736972]\n",
      "epoch:13 step:10502 [D loss: 0.707801, acc.: 50.78%] [G loss: 0.738267]\n",
      "epoch:13 step:10503 [D loss: 0.714604, acc.: 44.53%] [G loss: 0.745150]\n",
      "epoch:13 step:10504 [D loss: 0.724191, acc.: 45.31%] [G loss: 0.816526]\n",
      "epoch:13 step:10505 [D loss: 0.737023, acc.: 42.97%] [G loss: 0.787009]\n",
      "epoch:13 step:10506 [D loss: 0.674307, acc.: 58.59%] [G loss: 0.815981]\n",
      "epoch:13 step:10507 [D loss: 0.690658, acc.: 52.34%] [G loss: 0.834444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10508 [D loss: 0.728891, acc.: 42.19%] [G loss: 0.770322]\n",
      "epoch:13 step:10509 [D loss: 0.688526, acc.: 53.12%] [G loss: 0.763513]\n",
      "epoch:13 step:10510 [D loss: 0.687379, acc.: 48.44%] [G loss: 0.763514]\n",
      "epoch:13 step:10511 [D loss: 0.696052, acc.: 57.81%] [G loss: 0.878437]\n",
      "epoch:13 step:10512 [D loss: 0.675028, acc.: 54.69%] [G loss: 0.734139]\n",
      "epoch:13 step:10513 [D loss: 0.672625, acc.: 61.72%] [G loss: 0.740683]\n",
      "epoch:13 step:10514 [D loss: 0.668890, acc.: 60.16%] [G loss: 0.770566]\n",
      "epoch:13 step:10515 [D loss: 0.635457, acc.: 64.84%] [G loss: 0.687143]\n",
      "epoch:13 step:10516 [D loss: 0.672037, acc.: 56.25%] [G loss: 0.744139]\n",
      "epoch:13 step:10517 [D loss: 0.689697, acc.: 50.78%] [G loss: 0.683046]\n",
      "epoch:13 step:10518 [D loss: 0.647302, acc.: 70.31%] [G loss: 0.694253]\n",
      "epoch:13 step:10519 [D loss: 0.691184, acc.: 53.91%] [G loss: 0.709719]\n",
      "epoch:13 step:10520 [D loss: 0.701626, acc.: 51.56%] [G loss: 0.722968]\n",
      "epoch:13 step:10521 [D loss: 0.640237, acc.: 67.97%] [G loss: 0.730713]\n",
      "epoch:13 step:10522 [D loss: 0.718482, acc.: 44.53%] [G loss: 0.722292]\n",
      "epoch:13 step:10523 [D loss: 0.723383, acc.: 50.00%] [G loss: 0.696989]\n",
      "epoch:13 step:10524 [D loss: 0.695863, acc.: 48.44%] [G loss: 0.710168]\n",
      "epoch:13 step:10525 [D loss: 0.681668, acc.: 53.12%] [G loss: 0.721557]\n",
      "epoch:13 step:10526 [D loss: 0.703819, acc.: 47.66%] [G loss: 0.736580]\n",
      "epoch:13 step:10527 [D loss: 0.711083, acc.: 49.22%] [G loss: 0.705451]\n",
      "epoch:13 step:10528 [D loss: 0.766579, acc.: 36.72%] [G loss: 0.677186]\n",
      "epoch:13 step:10529 [D loss: 0.719848, acc.: 45.31%] [G loss: 0.752584]\n",
      "epoch:13 step:10530 [D loss: 0.690991, acc.: 59.38%] [G loss: 0.796965]\n",
      "epoch:13 step:10531 [D loss: 0.672947, acc.: 60.16%] [G loss: 0.793468]\n",
      "epoch:13 step:10532 [D loss: 0.677710, acc.: 66.41%] [G loss: 0.815985]\n",
      "epoch:13 step:10533 [D loss: 0.700292, acc.: 50.78%] [G loss: 0.795164]\n",
      "epoch:13 step:10534 [D loss: 0.647403, acc.: 65.62%] [G loss: 0.804002]\n",
      "epoch:13 step:10535 [D loss: 0.660670, acc.: 64.84%] [G loss: 0.779079]\n",
      "epoch:13 step:10536 [D loss: 0.723194, acc.: 43.75%] [G loss: 0.750758]\n",
      "epoch:13 step:10537 [D loss: 0.629217, acc.: 69.53%] [G loss: 0.788174]\n",
      "epoch:13 step:10538 [D loss: 0.661708, acc.: 60.16%] [G loss: 0.809044]\n",
      "epoch:13 step:10539 [D loss: 0.614948, acc.: 74.22%] [G loss: 0.758571]\n",
      "epoch:13 step:10540 [D loss: 0.621976, acc.: 73.44%] [G loss: 0.810355]\n",
      "epoch:13 step:10541 [D loss: 0.663817, acc.: 62.50%] [G loss: 0.863760]\n",
      "epoch:13 step:10542 [D loss: 0.653548, acc.: 57.03%] [G loss: 0.816559]\n",
      "epoch:13 step:10543 [D loss: 0.641512, acc.: 61.72%] [G loss: 0.779164]\n",
      "epoch:13 step:10544 [D loss: 0.707133, acc.: 46.88%] [G loss: 0.639834]\n",
      "epoch:13 step:10545 [D loss: 0.684392, acc.: 53.91%] [G loss: 0.641307]\n",
      "epoch:13 step:10546 [D loss: 0.691710, acc.: 55.47%] [G loss: 0.628370]\n",
      "epoch:13 step:10547 [D loss: 0.688082, acc.: 53.91%] [G loss: 0.604313]\n",
      "epoch:13 step:10548 [D loss: 0.666524, acc.: 58.59%] [G loss: 0.649940]\n",
      "epoch:13 step:10549 [D loss: 0.645750, acc.: 61.72%] [G loss: 0.691929]\n",
      "epoch:13 step:10550 [D loss: 0.744464, acc.: 44.53%] [G loss: 0.609540]\n",
      "epoch:13 step:10551 [D loss: 0.719811, acc.: 48.44%] [G loss: 0.713376]\n",
      "epoch:13 step:10552 [D loss: 0.709821, acc.: 50.78%] [G loss: 0.704868]\n",
      "epoch:13 step:10553 [D loss: 0.750315, acc.: 37.50%] [G loss: 0.752610]\n",
      "epoch:13 step:10554 [D loss: 0.700523, acc.: 53.12%] [G loss: 0.740197]\n",
      "epoch:13 step:10555 [D loss: 0.717653, acc.: 49.22%] [G loss: 0.719365]\n",
      "epoch:13 step:10556 [D loss: 0.666199, acc.: 60.16%] [G loss: 0.812711]\n",
      "epoch:13 step:10557 [D loss: 0.714468, acc.: 52.34%] [G loss: 0.728684]\n",
      "epoch:13 step:10558 [D loss: 0.732588, acc.: 44.53%] [G loss: 0.770079]\n",
      "epoch:13 step:10559 [D loss: 0.681767, acc.: 60.94%] [G loss: 0.779686]\n",
      "epoch:13 step:10560 [D loss: 0.765565, acc.: 32.81%] [G loss: 0.752026]\n",
      "epoch:13 step:10561 [D loss: 0.666581, acc.: 60.94%] [G loss: 0.807538]\n",
      "epoch:13 step:10562 [D loss: 0.691133, acc.: 54.69%] [G loss: 0.768371]\n",
      "epoch:13 step:10563 [D loss: 0.649735, acc.: 66.41%] [G loss: 0.826754]\n",
      "epoch:13 step:10564 [D loss: 0.695983, acc.: 52.34%] [G loss: 0.816768]\n",
      "epoch:13 step:10565 [D loss: 0.688946, acc.: 52.34%] [G loss: 0.787986]\n",
      "epoch:13 step:10566 [D loss: 0.674407, acc.: 57.81%] [G loss: 0.741850]\n",
      "epoch:13 step:10567 [D loss: 0.609245, acc.: 75.00%] [G loss: 0.770606]\n",
      "epoch:13 step:10568 [D loss: 0.706947, acc.: 52.34%] [G loss: 0.697188]\n",
      "epoch:13 step:10569 [D loss: 0.610249, acc.: 75.78%] [G loss: 0.720298]\n",
      "epoch:13 step:10570 [D loss: 0.654340, acc.: 65.62%] [G loss: 0.778041]\n",
      "epoch:13 step:10571 [D loss: 0.718874, acc.: 46.88%] [G loss: 0.694606]\n",
      "epoch:13 step:10572 [D loss: 0.647953, acc.: 66.41%] [G loss: 0.763149]\n",
      "epoch:13 step:10573 [D loss: 0.605420, acc.: 71.09%] [G loss: 0.757092]\n",
      "epoch:13 step:10574 [D loss: 0.623688, acc.: 69.53%] [G loss: 0.762320]\n",
      "epoch:13 step:10575 [D loss: 0.726320, acc.: 46.09%] [G loss: 0.682203]\n",
      "epoch:13 step:10576 [D loss: 0.652289, acc.: 60.94%] [G loss: 0.749548]\n",
      "epoch:13 step:10577 [D loss: 0.761302, acc.: 33.59%] [G loss: 0.707370]\n",
      "epoch:13 step:10578 [D loss: 0.598883, acc.: 77.34%] [G loss: 0.650958]\n",
      "epoch:13 step:10579 [D loss: 0.728118, acc.: 45.31%] [G loss: 0.689644]\n",
      "epoch:13 step:10580 [D loss: 0.601612, acc.: 74.22%] [G loss: 0.758180]\n",
      "epoch:13 step:10581 [D loss: 0.684265, acc.: 58.59%] [G loss: 0.681307]\n",
      "epoch:13 step:10582 [D loss: 0.692653, acc.: 59.38%] [G loss: 0.653122]\n",
      "epoch:13 step:10583 [D loss: 0.787150, acc.: 42.19%] [G loss: 0.646841]\n",
      "epoch:13 step:10584 [D loss: 0.759563, acc.: 37.50%] [G loss: 0.758521]\n",
      "epoch:13 step:10585 [D loss: 0.720071, acc.: 42.97%] [G loss: 0.751558]\n",
      "epoch:13 step:10586 [D loss: 0.687829, acc.: 53.12%] [G loss: 0.794713]\n",
      "epoch:13 step:10587 [D loss: 0.684613, acc.: 58.59%] [G loss: 0.833630]\n",
      "epoch:13 step:10588 [D loss: 0.708187, acc.: 46.09%] [G loss: 0.756083]\n",
      "epoch:13 step:10589 [D loss: 0.727115, acc.: 45.31%] [G loss: 0.758122]\n",
      "epoch:13 step:10590 [D loss: 0.669285, acc.: 56.25%] [G loss: 0.775092]\n",
      "epoch:13 step:10591 [D loss: 0.700114, acc.: 52.34%] [G loss: 0.845859]\n",
      "epoch:13 step:10592 [D loss: 0.746744, acc.: 36.72%] [G loss: 0.820040]\n",
      "epoch:13 step:10593 [D loss: 0.691202, acc.: 53.12%] [G loss: 0.806467]\n",
      "epoch:13 step:10594 [D loss: 0.681057, acc.: 54.69%] [G loss: 0.796076]\n",
      "epoch:13 step:10595 [D loss: 0.660196, acc.: 58.59%] [G loss: 0.802917]\n",
      "epoch:13 step:10596 [D loss: 0.639629, acc.: 71.09%] [G loss: 0.817265]\n",
      "epoch:13 step:10597 [D loss: 0.658915, acc.: 64.84%] [G loss: 0.793862]\n",
      "epoch:13 step:10598 [D loss: 0.687137, acc.: 57.03%] [G loss: 0.766418]\n",
      "epoch:13 step:10599 [D loss: 0.689751, acc.: 54.69%] [G loss: 0.724855]\n",
      "epoch:13 step:10600 [D loss: 0.585327, acc.: 77.34%] [G loss: 0.681590]\n",
      "epoch:13 step:10601 [D loss: 0.629429, acc.: 68.75%] [G loss: 0.669478]\n",
      "epoch:13 step:10602 [D loss: 0.736161, acc.: 41.41%] [G loss: 0.624814]\n",
      "epoch:13 step:10603 [D loss: 0.630378, acc.: 67.19%] [G loss: 0.688736]\n",
      "epoch:13 step:10604 [D loss: 0.685302, acc.: 58.59%] [G loss: 0.686641]\n",
      "epoch:13 step:10605 [D loss: 0.663911, acc.: 67.19%] [G loss: 0.667158]\n",
      "epoch:13 step:10606 [D loss: 0.741267, acc.: 34.38%] [G loss: 0.687668]\n",
      "epoch:13 step:10607 [D loss: 0.667095, acc.: 59.38%] [G loss: 0.728827]\n",
      "epoch:13 step:10608 [D loss: 0.690127, acc.: 52.34%] [G loss: 0.739491]\n",
      "epoch:13 step:10609 [D loss: 0.680960, acc.: 53.12%] [G loss: 0.650595]\n",
      "epoch:13 step:10610 [D loss: 0.762002, acc.: 32.81%] [G loss: 0.703557]\n",
      "epoch:13 step:10611 [D loss: 0.720425, acc.: 50.78%] [G loss: 0.740271]\n",
      "epoch:13 step:10612 [D loss: 0.762249, acc.: 34.38%] [G loss: 0.693450]\n",
      "epoch:13 step:10613 [D loss: 0.749188, acc.: 36.72%] [G loss: 0.758613]\n",
      "epoch:13 step:10614 [D loss: 0.658342, acc.: 60.94%] [G loss: 0.802737]\n",
      "epoch:13 step:10615 [D loss: 0.689350, acc.: 54.69%] [G loss: 0.838187]\n",
      "epoch:13 step:10616 [D loss: 0.711548, acc.: 53.12%] [G loss: 0.757893]\n",
      "epoch:13 step:10617 [D loss: 0.697955, acc.: 47.66%] [G loss: 0.743337]\n",
      "epoch:13 step:10618 [D loss: 0.707586, acc.: 46.88%] [G loss: 0.733462]\n",
      "epoch:13 step:10619 [D loss: 0.684701, acc.: 54.69%] [G loss: 0.733338]\n",
      "epoch:13 step:10620 [D loss: 0.687911, acc.: 53.91%] [G loss: 0.780253]\n",
      "epoch:13 step:10621 [D loss: 0.659713, acc.: 64.06%] [G loss: 0.803373]\n",
      "epoch:13 step:10622 [D loss: 0.732958, acc.: 42.19%] [G loss: 0.874964]\n",
      "epoch:13 step:10623 [D loss: 0.692814, acc.: 51.56%] [G loss: 0.750354]\n",
      "epoch:13 step:10624 [D loss: 0.675355, acc.: 63.28%] [G loss: 0.771782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10625 [D loss: 0.642174, acc.: 69.53%] [G loss: 0.727287]\n",
      "epoch:13 step:10626 [D loss: 0.742646, acc.: 41.41%] [G loss: 0.676790]\n",
      "epoch:13 step:10627 [D loss: 0.771765, acc.: 34.38%] [G loss: 0.696276]\n",
      "epoch:13 step:10628 [D loss: 0.760482, acc.: 39.84%] [G loss: 0.674259]\n",
      "epoch:13 step:10629 [D loss: 0.699380, acc.: 53.91%] [G loss: 0.736700]\n",
      "epoch:13 step:10630 [D loss: 0.679832, acc.: 58.59%] [G loss: 0.702984]\n",
      "epoch:13 step:10631 [D loss: 0.656282, acc.: 66.41%] [G loss: 0.743557]\n",
      "epoch:13 step:10632 [D loss: 0.644033, acc.: 68.75%] [G loss: 0.776514]\n",
      "epoch:13 step:10633 [D loss: 0.653721, acc.: 66.41%] [G loss: 0.770383]\n",
      "epoch:13 step:10634 [D loss: 0.714202, acc.: 51.56%] [G loss: 0.796020]\n",
      "epoch:13 step:10635 [D loss: 0.734061, acc.: 43.75%] [G loss: 0.802590]\n",
      "epoch:13 step:10636 [D loss: 0.726838, acc.: 39.84%] [G loss: 0.745447]\n",
      "epoch:13 step:10637 [D loss: 0.693211, acc.: 57.03%] [G loss: 0.712838]\n",
      "epoch:13 step:10638 [D loss: 0.680756, acc.: 57.03%] [G loss: 0.704175]\n",
      "epoch:13 step:10639 [D loss: 0.742217, acc.: 42.19%] [G loss: 0.752265]\n",
      "epoch:13 step:10640 [D loss: 0.679405, acc.: 57.03%] [G loss: 0.763127]\n",
      "epoch:13 step:10641 [D loss: 0.677149, acc.: 57.03%] [G loss: 0.704991]\n",
      "epoch:13 step:10642 [D loss: 0.703853, acc.: 49.22%] [G loss: 0.728256]\n",
      "epoch:13 step:10643 [D loss: 0.697866, acc.: 57.81%] [G loss: 0.761588]\n",
      "epoch:13 step:10644 [D loss: 0.714546, acc.: 50.78%] [G loss: 0.738422]\n",
      "epoch:13 step:10645 [D loss: 0.719912, acc.: 49.22%] [G loss: 0.805199]\n",
      "epoch:13 step:10646 [D loss: 0.680530, acc.: 52.34%] [G loss: 0.808589]\n",
      "epoch:13 step:10647 [D loss: 0.648900, acc.: 67.97%] [G loss: 0.799249]\n",
      "epoch:13 step:10648 [D loss: 0.645635, acc.: 64.84%] [G loss: 0.884786]\n",
      "epoch:13 step:10649 [D loss: 0.667137, acc.: 57.81%] [G loss: 0.886837]\n",
      "epoch:13 step:10650 [D loss: 0.683984, acc.: 54.69%] [G loss: 0.842767]\n",
      "epoch:13 step:10651 [D loss: 0.702571, acc.: 52.34%] [G loss: 0.771140]\n",
      "epoch:13 step:10652 [D loss: 0.672911, acc.: 53.91%] [G loss: 0.738868]\n",
      "epoch:13 step:10653 [D loss: 0.705528, acc.: 50.00%] [G loss: 0.782114]\n",
      "epoch:13 step:10654 [D loss: 0.717846, acc.: 46.09%] [G loss: 0.763334]\n",
      "epoch:13 step:10655 [D loss: 0.735560, acc.: 41.41%] [G loss: 0.779979]\n",
      "epoch:13 step:10656 [D loss: 0.691870, acc.: 50.78%] [G loss: 0.742856]\n",
      "epoch:13 step:10657 [D loss: 0.714987, acc.: 43.75%] [G loss: 0.710689]\n",
      "epoch:13 step:10658 [D loss: 0.682986, acc.: 55.47%] [G loss: 0.733649]\n",
      "epoch:13 step:10659 [D loss: 0.670402, acc.: 58.59%] [G loss: 0.723080]\n",
      "epoch:13 step:10660 [D loss: 0.694482, acc.: 48.44%] [G loss: 0.706772]\n",
      "epoch:13 step:10661 [D loss: 0.696317, acc.: 52.34%] [G loss: 0.699732]\n",
      "epoch:13 step:10662 [D loss: 0.636781, acc.: 65.62%] [G loss: 0.733981]\n",
      "epoch:13 step:10663 [D loss: 0.691333, acc.: 53.12%] [G loss: 0.750584]\n",
      "epoch:13 step:10664 [D loss: 0.659728, acc.: 57.81%] [G loss: 0.717929]\n",
      "epoch:13 step:10665 [D loss: 0.707070, acc.: 52.34%] [G loss: 0.702208]\n",
      "epoch:13 step:10666 [D loss: 0.741551, acc.: 40.62%] [G loss: 0.651967]\n",
      "epoch:13 step:10667 [D loss: 0.762498, acc.: 36.72%] [G loss: 0.629336]\n",
      "epoch:13 step:10668 [D loss: 0.689594, acc.: 49.22%] [G loss: 0.666727]\n",
      "epoch:13 step:10669 [D loss: 0.686901, acc.: 60.16%] [G loss: 0.749471]\n",
      "epoch:13 step:10670 [D loss: 0.634673, acc.: 62.50%] [G loss: 0.757037]\n",
      "epoch:13 step:10671 [D loss: 0.667352, acc.: 57.81%] [G loss: 0.779727]\n",
      "epoch:13 step:10672 [D loss: 0.772282, acc.: 32.03%] [G loss: 0.693510]\n",
      "epoch:13 step:10673 [D loss: 0.708869, acc.: 51.56%] [G loss: 0.709275]\n",
      "epoch:13 step:10674 [D loss: 0.661686, acc.: 60.94%] [G loss: 0.740589]\n",
      "epoch:13 step:10675 [D loss: 0.723759, acc.: 49.22%] [G loss: 0.797626]\n",
      "epoch:13 step:10676 [D loss: 0.729236, acc.: 40.62%] [G loss: 0.709987]\n",
      "epoch:13 step:10677 [D loss: 0.701573, acc.: 50.00%] [G loss: 0.866824]\n",
      "epoch:13 step:10678 [D loss: 0.611507, acc.: 78.12%] [G loss: 0.792032]\n",
      "epoch:13 step:10679 [D loss: 0.771349, acc.: 39.84%] [G loss: 0.731038]\n",
      "epoch:13 step:10680 [D loss: 0.681353, acc.: 56.25%] [G loss: 0.799610]\n",
      "epoch:13 step:10681 [D loss: 0.732745, acc.: 53.12%] [G loss: 0.792014]\n",
      "epoch:13 step:10682 [D loss: 0.660805, acc.: 61.72%] [G loss: 0.803903]\n",
      "epoch:13 step:10683 [D loss: 0.726435, acc.: 42.19%] [G loss: 0.650690]\n",
      "epoch:13 step:10684 [D loss: 0.684424, acc.: 58.59%] [G loss: 0.794235]\n",
      "epoch:13 step:10685 [D loss: 0.725325, acc.: 45.31%] [G loss: 0.700900]\n",
      "epoch:13 step:10686 [D loss: 0.700054, acc.: 52.34%] [G loss: 0.775391]\n",
      "epoch:13 step:10687 [D loss: 0.719193, acc.: 46.88%] [G loss: 0.774613]\n",
      "epoch:13 step:10688 [D loss: 0.671526, acc.: 56.25%] [G loss: 0.701894]\n",
      "epoch:13 step:10689 [D loss: 0.709592, acc.: 43.75%] [G loss: 0.744895]\n",
      "epoch:13 step:10690 [D loss: 0.726721, acc.: 46.09%] [G loss: 0.725640]\n",
      "epoch:13 step:10691 [D loss: 0.686674, acc.: 55.47%] [G loss: 0.761328]\n",
      "epoch:13 step:10692 [D loss: 0.687313, acc.: 57.03%] [G loss: 0.677806]\n",
      "epoch:13 step:10693 [D loss: 0.735795, acc.: 46.09%] [G loss: 0.711745]\n",
      "epoch:13 step:10694 [D loss: 0.722925, acc.: 42.19%] [G loss: 0.704600]\n",
      "epoch:13 step:10695 [D loss: 0.706702, acc.: 50.00%] [G loss: 0.779210]\n",
      "epoch:13 step:10696 [D loss: 0.676736, acc.: 53.91%] [G loss: 0.831698]\n",
      "epoch:13 step:10697 [D loss: 0.670273, acc.: 59.38%] [G loss: 0.778270]\n",
      "epoch:13 step:10698 [D loss: 0.648043, acc.: 58.59%] [G loss: 0.797258]\n",
      "epoch:13 step:10699 [D loss: 0.719879, acc.: 49.22%] [G loss: 0.778734]\n",
      "epoch:13 step:10700 [D loss: 0.632072, acc.: 69.53%] [G loss: 0.770064]\n",
      "epoch:13 step:10701 [D loss: 0.710902, acc.: 51.56%] [G loss: 0.734949]\n",
      "epoch:13 step:10702 [D loss: 0.680821, acc.: 58.59%] [G loss: 0.788496]\n",
      "epoch:13 step:10703 [D loss: 0.757700, acc.: 39.84%] [G loss: 0.765695]\n",
      "epoch:13 step:10704 [D loss: 0.711944, acc.: 47.66%] [G loss: 0.712168]\n",
      "epoch:13 step:10705 [D loss: 0.723534, acc.: 46.09%] [G loss: 0.800365]\n",
      "epoch:13 step:10706 [D loss: 0.633782, acc.: 73.44%] [G loss: 0.733364]\n",
      "epoch:13 step:10707 [D loss: 0.652954, acc.: 64.84%] [G loss: 0.763873]\n",
      "epoch:13 step:10708 [D loss: 0.622781, acc.: 68.75%] [G loss: 0.816159]\n",
      "epoch:13 step:10709 [D loss: 0.687641, acc.: 63.28%] [G loss: 0.768910]\n",
      "epoch:13 step:10710 [D loss: 0.678176, acc.: 55.47%] [G loss: 0.767397]\n",
      "epoch:13 step:10711 [D loss: 0.648396, acc.: 66.41%] [G loss: 0.740206]\n",
      "epoch:13 step:10712 [D loss: 0.616116, acc.: 70.31%] [G loss: 0.809008]\n",
      "epoch:13 step:10713 [D loss: 0.692105, acc.: 53.12%] [G loss: 0.753653]\n",
      "epoch:13 step:10714 [D loss: 0.713610, acc.: 46.88%] [G loss: 0.719290]\n",
      "epoch:13 step:10715 [D loss: 0.767142, acc.: 35.94%] [G loss: 0.682061]\n",
      "epoch:13 step:10716 [D loss: 0.690637, acc.: 49.22%] [G loss: 0.687328]\n",
      "epoch:13 step:10717 [D loss: 0.716522, acc.: 47.66%] [G loss: 0.672371]\n",
      "epoch:13 step:10718 [D loss: 0.769282, acc.: 32.03%] [G loss: 0.692150]\n",
      "epoch:13 step:10719 [D loss: 0.746594, acc.: 42.97%] [G loss: 0.752515]\n",
      "epoch:13 step:10720 [D loss: 0.733758, acc.: 45.31%] [G loss: 0.828109]\n",
      "epoch:13 step:10721 [D loss: 0.713814, acc.: 48.44%] [G loss: 0.753517]\n",
      "epoch:13 step:10722 [D loss: 0.724670, acc.: 42.97%] [G loss: 0.755764]\n",
      "epoch:13 step:10723 [D loss: 0.691463, acc.: 52.34%] [G loss: 0.779740]\n",
      "epoch:13 step:10724 [D loss: 0.714581, acc.: 49.22%] [G loss: 0.758502]\n",
      "epoch:13 step:10725 [D loss: 0.648322, acc.: 67.19%] [G loss: 0.827842]\n",
      "epoch:13 step:10726 [D loss: 0.717178, acc.: 47.66%] [G loss: 0.773958]\n",
      "epoch:13 step:10727 [D loss: 0.686810, acc.: 57.81%] [G loss: 0.740456]\n",
      "epoch:13 step:10728 [D loss: 0.712931, acc.: 45.31%] [G loss: 0.728812]\n",
      "epoch:13 step:10729 [D loss: 0.629489, acc.: 69.53%] [G loss: 0.795823]\n",
      "epoch:13 step:10730 [D loss: 0.662231, acc.: 60.16%] [G loss: 0.709389]\n",
      "epoch:13 step:10731 [D loss: 0.650776, acc.: 66.41%] [G loss: 0.771513]\n",
      "epoch:13 step:10732 [D loss: 0.655411, acc.: 63.28%] [G loss: 0.831171]\n",
      "epoch:13 step:10733 [D loss: 0.648972, acc.: 60.94%] [G loss: 0.822701]\n",
      "epoch:13 step:10734 [D loss: 0.685774, acc.: 52.34%] [G loss: 0.771090]\n",
      "epoch:13 step:10735 [D loss: 0.646504, acc.: 67.19%] [G loss: 0.734824]\n",
      "epoch:13 step:10736 [D loss: 0.659902, acc.: 59.38%] [G loss: 0.727578]\n",
      "epoch:13 step:10737 [D loss: 0.690646, acc.: 50.78%] [G loss: 0.750272]\n",
      "epoch:13 step:10738 [D loss: 0.688757, acc.: 53.91%] [G loss: 0.711443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10739 [D loss: 0.678249, acc.: 55.47%] [G loss: 0.737282]\n",
      "epoch:13 step:10740 [D loss: 0.674545, acc.: 60.16%] [G loss: 0.709147]\n",
      "epoch:13 step:10741 [D loss: 0.658287, acc.: 58.59%] [G loss: 0.821779]\n",
      "epoch:13 step:10742 [D loss: 0.689556, acc.: 57.81%] [G loss: 0.829910]\n",
      "epoch:13 step:10743 [D loss: 0.665077, acc.: 60.16%] [G loss: 0.797647]\n",
      "epoch:13 step:10744 [D loss: 0.687293, acc.: 52.34%] [G loss: 0.815858]\n",
      "epoch:13 step:10745 [D loss: 0.715114, acc.: 48.44%] [G loss: 0.773543]\n",
      "epoch:13 step:10746 [D loss: 0.697527, acc.: 54.69%] [G loss: 0.795669]\n",
      "epoch:13 step:10747 [D loss: 0.752906, acc.: 38.28%] [G loss: 0.705608]\n",
      "epoch:13 step:10748 [D loss: 0.671100, acc.: 55.47%] [G loss: 0.769680]\n",
      "epoch:13 step:10749 [D loss: 0.700261, acc.: 46.88%] [G loss: 0.757368]\n",
      "epoch:13 step:10750 [D loss: 0.697851, acc.: 56.25%] [G loss: 0.862786]\n",
      "epoch:13 step:10751 [D loss: 0.686050, acc.: 56.25%] [G loss: 0.827669]\n",
      "epoch:13 step:10752 [D loss: 0.731900, acc.: 39.84%] [G loss: 0.712917]\n",
      "epoch:13 step:10753 [D loss: 0.660377, acc.: 61.72%] [G loss: 0.729298]\n",
      "epoch:13 step:10754 [D loss: 0.729133, acc.: 47.66%] [G loss: 0.720633]\n",
      "epoch:13 step:10755 [D loss: 0.655024, acc.: 60.16%] [G loss: 0.743368]\n",
      "epoch:13 step:10756 [D loss: 0.744264, acc.: 36.72%] [G loss: 0.692241]\n",
      "epoch:13 step:10757 [D loss: 0.721047, acc.: 45.31%] [G loss: 0.743701]\n",
      "epoch:13 step:10758 [D loss: 0.699202, acc.: 50.78%] [G loss: 0.741890]\n",
      "epoch:13 step:10759 [D loss: 0.713147, acc.: 48.44%] [G loss: 0.743491]\n",
      "epoch:13 step:10760 [D loss: 0.697867, acc.: 50.78%] [G loss: 0.750471]\n",
      "epoch:13 step:10761 [D loss: 0.665310, acc.: 60.16%] [G loss: 0.721032]\n",
      "epoch:13 step:10762 [D loss: 0.694042, acc.: 50.78%] [G loss: 0.747978]\n",
      "epoch:13 step:10763 [D loss: 0.669408, acc.: 57.81%] [G loss: 0.806321]\n",
      "epoch:13 step:10764 [D loss: 0.716891, acc.: 49.22%] [G loss: 0.773704]\n",
      "epoch:13 step:10765 [D loss: 0.683404, acc.: 52.34%] [G loss: 0.757711]\n",
      "epoch:13 step:10766 [D loss: 0.715186, acc.: 57.03%] [G loss: 0.792807]\n",
      "epoch:13 step:10767 [D loss: 0.720219, acc.: 44.53%] [G loss: 0.813437]\n",
      "epoch:13 step:10768 [D loss: 0.657575, acc.: 61.72%] [G loss: 0.838724]\n",
      "epoch:13 step:10769 [D loss: 0.669205, acc.: 60.16%] [G loss: 0.813984]\n",
      "epoch:13 step:10770 [D loss: 0.717484, acc.: 49.22%] [G loss: 0.784170]\n",
      "epoch:13 step:10771 [D loss: 0.686342, acc.: 56.25%] [G loss: 0.823018]\n",
      "epoch:13 step:10772 [D loss: 0.704075, acc.: 46.88%] [G loss: 0.774390]\n",
      "epoch:13 step:10773 [D loss: 0.643265, acc.: 65.62%] [G loss: 0.867739]\n",
      "epoch:13 step:10774 [D loss: 0.673967, acc.: 57.03%] [G loss: 0.815067]\n",
      "epoch:13 step:10775 [D loss: 0.674526, acc.: 60.94%] [G loss: 0.843217]\n",
      "epoch:13 step:10776 [D loss: 0.678799, acc.: 57.81%] [G loss: 0.809636]\n",
      "epoch:13 step:10777 [D loss: 0.670671, acc.: 56.25%] [G loss: 0.790535]\n",
      "epoch:13 step:10778 [D loss: 0.690714, acc.: 53.91%] [G loss: 0.777150]\n",
      "epoch:13 step:10779 [D loss: 0.702883, acc.: 53.91%] [G loss: 0.750360]\n",
      "epoch:13 step:10780 [D loss: 0.688749, acc.: 56.25%] [G loss: 0.677856]\n",
      "epoch:13 step:10781 [D loss: 0.720545, acc.: 47.66%] [G loss: 0.696354]\n",
      "epoch:13 step:10782 [D loss: 0.689263, acc.: 56.25%] [G loss: 0.754406]\n",
      "epoch:13 step:10783 [D loss: 0.754597, acc.: 41.41%] [G loss: 0.637150]\n",
      "epoch:13 step:10784 [D loss: 0.727629, acc.: 42.97%] [G loss: 0.803813]\n",
      "epoch:13 step:10785 [D loss: 0.732423, acc.: 44.53%] [G loss: 0.721046]\n",
      "epoch:13 step:10786 [D loss: 0.750096, acc.: 39.84%] [G loss: 0.780745]\n",
      "epoch:13 step:10787 [D loss: 0.752848, acc.: 35.94%] [G loss: 0.735533]\n",
      "epoch:13 step:10788 [D loss: 0.736335, acc.: 39.06%] [G loss: 0.755255]\n",
      "epoch:13 step:10789 [D loss: 0.698659, acc.: 56.25%] [G loss: 0.767361]\n",
      "epoch:13 step:10790 [D loss: 0.721937, acc.: 42.97%] [G loss: 0.730146]\n",
      "epoch:13 step:10791 [D loss: 0.747184, acc.: 46.09%] [G loss: 0.744950]\n",
      "epoch:13 step:10792 [D loss: 0.740055, acc.: 39.84%] [G loss: 0.712589]\n",
      "epoch:13 step:10793 [D loss: 0.683064, acc.: 52.34%] [G loss: 0.749045]\n",
      "epoch:13 step:10794 [D loss: 0.695077, acc.: 57.03%] [G loss: 0.705386]\n",
      "epoch:13 step:10795 [D loss: 0.711463, acc.: 49.22%] [G loss: 0.779195]\n",
      "epoch:13 step:10796 [D loss: 0.738734, acc.: 41.41%] [G loss: 0.728832]\n",
      "epoch:13 step:10797 [D loss: 0.693765, acc.: 52.34%] [G loss: 0.781349]\n",
      "epoch:13 step:10798 [D loss: 0.701258, acc.: 46.88%] [G loss: 0.791199]\n",
      "epoch:13 step:10799 [D loss: 0.700295, acc.: 45.31%] [G loss: 0.818361]\n",
      "epoch:13 step:10800 [D loss: 0.718470, acc.: 50.78%] [G loss: 0.783243]\n",
      "epoch:13 step:10801 [D loss: 0.668427, acc.: 56.25%] [G loss: 0.758351]\n",
      "epoch:13 step:10802 [D loss: 0.701684, acc.: 52.34%] [G loss: 0.719524]\n",
      "epoch:13 step:10803 [D loss: 0.701073, acc.: 50.78%] [G loss: 0.733975]\n",
      "epoch:13 step:10804 [D loss: 0.699926, acc.: 55.47%] [G loss: 0.711563]\n",
      "epoch:13 step:10805 [D loss: 0.691034, acc.: 55.47%] [G loss: 0.703095]\n",
      "epoch:13 step:10806 [D loss: 0.672157, acc.: 64.84%] [G loss: 0.739901]\n",
      "epoch:13 step:10807 [D loss: 0.721433, acc.: 45.31%] [G loss: 0.765628]\n",
      "epoch:13 step:10808 [D loss: 0.677751, acc.: 57.03%] [G loss: 0.694081]\n",
      "epoch:13 step:10809 [D loss: 0.721667, acc.: 43.75%] [G loss: 0.791862]\n",
      "epoch:13 step:10810 [D loss: 0.713148, acc.: 41.41%] [G loss: 0.797010]\n",
      "epoch:13 step:10811 [D loss: 0.677693, acc.: 63.28%] [G loss: 0.796386]\n",
      "epoch:13 step:10812 [D loss: 0.722913, acc.: 40.62%] [G loss: 0.752564]\n",
      "epoch:13 step:10813 [D loss: 0.713091, acc.: 50.00%] [G loss: 0.782822]\n",
      "epoch:13 step:10814 [D loss: 0.679406, acc.: 57.81%] [G loss: 0.777427]\n",
      "epoch:13 step:10815 [D loss: 0.700760, acc.: 47.66%] [G loss: 0.805435]\n",
      "epoch:13 step:10816 [D loss: 0.653190, acc.: 58.59%] [G loss: 0.763057]\n",
      "epoch:13 step:10817 [D loss: 0.706229, acc.: 45.31%] [G loss: 0.777890]\n",
      "epoch:13 step:10818 [D loss: 0.672425, acc.: 57.03%] [G loss: 0.730373]\n",
      "epoch:13 step:10819 [D loss: 0.691279, acc.: 51.56%] [G loss: 0.784507]\n",
      "epoch:13 step:10820 [D loss: 0.691709, acc.: 52.34%] [G loss: 0.754179]\n",
      "epoch:13 step:10821 [D loss: 0.687082, acc.: 57.03%] [G loss: 0.751150]\n",
      "epoch:13 step:10822 [D loss: 0.684942, acc.: 53.91%] [G loss: 0.785325]\n",
      "epoch:13 step:10823 [D loss: 0.734194, acc.: 40.62%] [G loss: 0.858035]\n",
      "epoch:13 step:10824 [D loss: 0.697673, acc.: 57.81%] [G loss: 0.785342]\n",
      "epoch:13 step:10825 [D loss: 0.663406, acc.: 64.84%] [G loss: 0.899592]\n",
      "epoch:13 step:10826 [D loss: 0.643591, acc.: 66.41%] [G loss: 0.898064]\n",
      "epoch:13 step:10827 [D loss: 0.693861, acc.: 56.25%] [G loss: 0.803572]\n",
      "epoch:13 step:10828 [D loss: 0.657757, acc.: 70.31%] [G loss: 0.863386]\n",
      "epoch:13 step:10829 [D loss: 0.685807, acc.: 55.47%] [G loss: 0.878962]\n",
      "epoch:13 step:10830 [D loss: 0.703228, acc.: 50.00%] [G loss: 0.708331]\n",
      "epoch:13 step:10831 [D loss: 0.725977, acc.: 45.31%] [G loss: 0.779663]\n",
      "epoch:13 step:10832 [D loss: 0.675084, acc.: 58.59%] [G loss: 0.763754]\n",
      "epoch:13 step:10833 [D loss: 0.643114, acc.: 67.97%] [G loss: 0.838202]\n",
      "epoch:13 step:10834 [D loss: 0.668937, acc.: 60.94%] [G loss: 0.832052]\n",
      "epoch:13 step:10835 [D loss: 0.708910, acc.: 51.56%] [G loss: 0.756828]\n",
      "epoch:13 step:10836 [D loss: 0.664642, acc.: 58.59%] [G loss: 0.779544]\n",
      "epoch:13 step:10837 [D loss: 0.699447, acc.: 48.44%] [G loss: 0.700180]\n",
      "epoch:13 step:10838 [D loss: 0.760198, acc.: 35.16%] [G loss: 0.709973]\n",
      "epoch:13 step:10839 [D loss: 0.717465, acc.: 50.78%] [G loss: 0.780201]\n",
      "epoch:13 step:10840 [D loss: 0.672101, acc.: 59.38%] [G loss: 0.788962]\n",
      "epoch:13 step:10841 [D loss: 0.735601, acc.: 41.41%] [G loss: 0.707253]\n",
      "epoch:13 step:10842 [D loss: 0.748860, acc.: 42.97%] [G loss: 0.747227]\n",
      "epoch:13 step:10843 [D loss: 0.678992, acc.: 52.34%] [G loss: 0.761346]\n",
      "epoch:13 step:10844 [D loss: 0.674310, acc.: 55.47%] [G loss: 0.766382]\n",
      "epoch:13 step:10845 [D loss: 0.768684, acc.: 37.50%] [G loss: 0.682438]\n",
      "epoch:13 step:10846 [D loss: 0.684508, acc.: 56.25%] [G loss: 0.748793]\n",
      "epoch:13 step:10847 [D loss: 0.697966, acc.: 53.12%] [G loss: 0.740869]\n",
      "epoch:13 step:10848 [D loss: 0.720550, acc.: 42.19%] [G loss: 0.679090]\n",
      "epoch:13 step:10849 [D loss: 0.777629, acc.: 29.69%] [G loss: 0.717586]\n",
      "epoch:13 step:10850 [D loss: 0.707588, acc.: 50.00%] [G loss: 0.730698]\n",
      "epoch:13 step:10851 [D loss: 0.654199, acc.: 64.06%] [G loss: 0.782841]\n",
      "epoch:13 step:10852 [D loss: 0.707991, acc.: 46.09%] [G loss: 0.723892]\n",
      "epoch:13 step:10853 [D loss: 0.709173, acc.: 45.31%] [G loss: 0.725728]\n",
      "epoch:13 step:10854 [D loss: 0.677314, acc.: 57.81%] [G loss: 0.756637]\n",
      "epoch:13 step:10855 [D loss: 0.681022, acc.: 59.38%] [G loss: 0.705139]\n",
      "epoch:13 step:10856 [D loss: 0.689880, acc.: 53.91%] [G loss: 0.723462]\n",
      "epoch:13 step:10857 [D loss: 0.716500, acc.: 44.53%] [G loss: 0.685943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10858 [D loss: 0.665181, acc.: 58.59%] [G loss: 0.797904]\n",
      "epoch:13 step:10859 [D loss: 0.744746, acc.: 40.62%] [G loss: 0.663750]\n",
      "epoch:13 step:10860 [D loss: 0.730621, acc.: 42.97%] [G loss: 0.688037]\n",
      "epoch:13 step:10861 [D loss: 0.753840, acc.: 38.28%] [G loss: 0.693608]\n",
      "epoch:13 step:10862 [D loss: 0.705210, acc.: 49.22%] [G loss: 0.684753]\n",
      "epoch:13 step:10863 [D loss: 0.674856, acc.: 63.28%] [G loss: 0.677658]\n",
      "epoch:13 step:10864 [D loss: 0.661586, acc.: 60.94%] [G loss: 0.776831]\n",
      "epoch:13 step:10865 [D loss: 0.696108, acc.: 51.56%] [G loss: 0.708912]\n",
      "epoch:13 step:10866 [D loss: 0.667226, acc.: 57.03%] [G loss: 0.758298]\n",
      "epoch:13 step:10867 [D loss: 0.684789, acc.: 55.47%] [G loss: 0.719452]\n",
      "epoch:13 step:10868 [D loss: 0.648001, acc.: 62.50%] [G loss: 0.777468]\n",
      "epoch:13 step:10869 [D loss: 0.673012, acc.: 61.72%] [G loss: 0.701858]\n",
      "epoch:13 step:10870 [D loss: 0.649911, acc.: 64.06%] [G loss: 0.742735]\n",
      "epoch:13 step:10871 [D loss: 0.705199, acc.: 52.34%] [G loss: 0.758833]\n",
      "epoch:13 step:10872 [D loss: 0.698803, acc.: 53.12%] [G loss: 0.786368]\n",
      "epoch:13 step:10873 [D loss: 0.719336, acc.: 46.88%] [G loss: 0.772213]\n",
      "epoch:13 step:10874 [D loss: 0.746315, acc.: 32.81%] [G loss: 0.746504]\n",
      "epoch:13 step:10875 [D loss: 0.697773, acc.: 52.34%] [G loss: 0.728231]\n",
      "epoch:13 step:10876 [D loss: 0.736413, acc.: 41.41%] [G loss: 0.694424]\n",
      "epoch:13 step:10877 [D loss: 0.707677, acc.: 53.12%] [G loss: 0.687180]\n",
      "epoch:13 step:10878 [D loss: 0.680642, acc.: 56.25%] [G loss: 0.781863]\n",
      "epoch:13 step:10879 [D loss: 0.727887, acc.: 43.75%] [G loss: 0.819958]\n",
      "epoch:13 step:10880 [D loss: 0.683178, acc.: 50.00%] [G loss: 0.807014]\n",
      "epoch:13 step:10881 [D loss: 0.705872, acc.: 48.44%] [G loss: 0.820278]\n",
      "epoch:13 step:10882 [D loss: 0.724159, acc.: 46.09%] [G loss: 0.772765]\n",
      "epoch:13 step:10883 [D loss: 0.663876, acc.: 60.94%] [G loss: 0.748208]\n",
      "epoch:13 step:10884 [D loss: 0.732682, acc.: 44.53%] [G loss: 0.739190]\n",
      "epoch:13 step:10885 [D loss: 0.676528, acc.: 56.25%] [G loss: 0.759963]\n",
      "epoch:13 step:10886 [D loss: 0.663585, acc.: 57.81%] [G loss: 0.803536]\n",
      "epoch:13 step:10887 [D loss: 0.650805, acc.: 63.28%] [G loss: 0.754750]\n",
      "epoch:13 step:10888 [D loss: 0.744963, acc.: 42.97%] [G loss: 0.839748]\n",
      "epoch:13 step:10889 [D loss: 0.707990, acc.: 54.69%] [G loss: 0.753296]\n",
      "epoch:13 step:10890 [D loss: 0.709055, acc.: 46.88%] [G loss: 0.763664]\n",
      "epoch:13 step:10891 [D loss: 0.703614, acc.: 53.12%] [G loss: 0.784730]\n",
      "epoch:13 step:10892 [D loss: 0.723400, acc.: 46.88%] [G loss: 0.791236]\n",
      "epoch:13 step:10893 [D loss: 0.656429, acc.: 61.72%] [G loss: 0.701697]\n",
      "epoch:13 step:10894 [D loss: 0.710800, acc.: 46.09%] [G loss: 0.665302]\n",
      "epoch:13 step:10895 [D loss: 0.775964, acc.: 29.69%] [G loss: 0.717134]\n",
      "epoch:13 step:10896 [D loss: 0.718304, acc.: 42.97%] [G loss: 0.700786]\n",
      "epoch:13 step:10897 [D loss: 0.705592, acc.: 50.00%] [G loss: 0.732061]\n",
      "epoch:13 step:10898 [D loss: 0.685472, acc.: 53.91%] [G loss: 0.750341]\n",
      "epoch:13 step:10899 [D loss: 0.709258, acc.: 50.78%] [G loss: 0.835252]\n",
      "epoch:13 step:10900 [D loss: 0.659099, acc.: 61.72%] [G loss: 0.793960]\n",
      "epoch:13 step:10901 [D loss: 0.687205, acc.: 46.09%] [G loss: 0.773730]\n",
      "epoch:13 step:10902 [D loss: 0.630601, acc.: 69.53%] [G loss: 0.816033]\n",
      "epoch:13 step:10903 [D loss: 0.631433, acc.: 69.53%] [G loss: 0.792805]\n",
      "epoch:13 step:10904 [D loss: 0.707880, acc.: 49.22%] [G loss: 0.781610]\n",
      "epoch:13 step:10905 [D loss: 0.678408, acc.: 58.59%] [G loss: 0.771487]\n",
      "epoch:13 step:10906 [D loss: 0.632484, acc.: 68.75%] [G loss: 0.727619]\n",
      "epoch:13 step:10907 [D loss: 0.666998, acc.: 59.38%] [G loss: 0.729402]\n",
      "epoch:13 step:10908 [D loss: 0.631590, acc.: 71.09%] [G loss: 0.777720]\n",
      "epoch:13 step:10909 [D loss: 0.701761, acc.: 50.00%] [G loss: 0.751325]\n",
      "epoch:13 step:10910 [D loss: 0.700278, acc.: 48.44%] [G loss: 0.744521]\n",
      "epoch:13 step:10911 [D loss: 0.691235, acc.: 49.22%] [G loss: 0.634807]\n",
      "epoch:13 step:10912 [D loss: 0.673008, acc.: 56.25%] [G loss: 0.717360]\n",
      "epoch:13 step:10913 [D loss: 0.689334, acc.: 49.22%] [G loss: 0.760332]\n",
      "epoch:13 step:10914 [D loss: 0.677142, acc.: 57.03%] [G loss: 0.738952]\n",
      "epoch:13 step:10915 [D loss: 0.696646, acc.: 54.69%] [G loss: 0.714656]\n",
      "epoch:13 step:10916 [D loss: 0.702288, acc.: 53.12%] [G loss: 0.745813]\n",
      "epoch:13 step:10917 [D loss: 0.733922, acc.: 35.94%] [G loss: 0.739112]\n",
      "epoch:13 step:10918 [D loss: 0.660255, acc.: 57.81%] [G loss: 0.742467]\n",
      "epoch:13 step:10919 [D loss: 0.686767, acc.: 57.81%] [G loss: 0.719745]\n",
      "epoch:13 step:10920 [D loss: 0.703457, acc.: 46.09%] [G loss: 0.751752]\n",
      "epoch:13 step:10921 [D loss: 0.712424, acc.: 46.09%] [G loss: 0.780808]\n",
      "epoch:13 step:10922 [D loss: 0.702488, acc.: 50.78%] [G loss: 0.747246]\n",
      "epoch:13 step:10923 [D loss: 0.624068, acc.: 75.00%] [G loss: 0.807066]\n",
      "epoch:13 step:10924 [D loss: 0.684061, acc.: 53.91%] [G loss: 0.828566]\n",
      "epoch:13 step:10925 [D loss: 0.737947, acc.: 42.19%] [G loss: 0.757602]\n",
      "epoch:13 step:10926 [D loss: 0.726610, acc.: 41.41%] [G loss: 0.744622]\n",
      "epoch:13 step:10927 [D loss: 0.682601, acc.: 54.69%] [G loss: 0.715372]\n",
      "epoch:13 step:10928 [D loss: 0.730595, acc.: 44.53%] [G loss: 0.711429]\n",
      "epoch:13 step:10929 [D loss: 0.699346, acc.: 55.47%] [G loss: 0.760628]\n",
      "epoch:13 step:10930 [D loss: 0.672991, acc.: 57.81%] [G loss: 0.736081]\n",
      "epoch:13 step:10931 [D loss: 0.669548, acc.: 64.06%] [G loss: 0.767038]\n",
      "epoch:13 step:10932 [D loss: 0.685319, acc.: 52.34%] [G loss: 0.754259]\n",
      "epoch:13 step:10933 [D loss: 0.694299, acc.: 54.69%] [G loss: 0.743307]\n",
      "epoch:13 step:10934 [D loss: 0.585491, acc.: 82.81%] [G loss: 0.742470]\n",
      "epoch:14 step:10935 [D loss: 0.673795, acc.: 60.16%] [G loss: 0.788739]\n",
      "epoch:14 step:10936 [D loss: 0.646095, acc.: 67.19%] [G loss: 0.754261]\n",
      "epoch:14 step:10937 [D loss: 0.708176, acc.: 49.22%] [G loss: 0.682257]\n",
      "epoch:14 step:10938 [D loss: 0.673179, acc.: 55.47%] [G loss: 0.718315]\n",
      "epoch:14 step:10939 [D loss: 0.610922, acc.: 67.19%] [G loss: 0.695366]\n",
      "epoch:14 step:10940 [D loss: 0.677598, acc.: 57.81%] [G loss: 0.727146]\n",
      "epoch:14 step:10941 [D loss: 0.733045, acc.: 42.97%] [G loss: 0.707047]\n",
      "epoch:14 step:10942 [D loss: 0.656300, acc.: 60.94%] [G loss: 0.749135]\n",
      "epoch:14 step:10943 [D loss: 0.703383, acc.: 50.78%] [G loss: 0.778766]\n",
      "epoch:14 step:10944 [D loss: 0.772367, acc.: 38.28%] [G loss: 0.683003]\n",
      "epoch:14 step:10945 [D loss: 0.729172, acc.: 38.28%] [G loss: 0.724083]\n",
      "epoch:14 step:10946 [D loss: 0.725366, acc.: 45.31%] [G loss: 0.799754]\n",
      "epoch:14 step:10947 [D loss: 0.705436, acc.: 48.44%] [G loss: 0.835322]\n",
      "epoch:14 step:10948 [D loss: 0.669637, acc.: 64.06%] [G loss: 0.835420]\n",
      "epoch:14 step:10949 [D loss: 0.714720, acc.: 45.31%] [G loss: 0.807955]\n",
      "epoch:14 step:10950 [D loss: 0.719300, acc.: 50.78%] [G loss: 0.757164]\n",
      "epoch:14 step:10951 [D loss: 0.730282, acc.: 39.06%] [G loss: 0.731430]\n",
      "epoch:14 step:10952 [D loss: 0.713367, acc.: 46.88%] [G loss: 0.777475]\n",
      "epoch:14 step:10953 [D loss: 0.694327, acc.: 51.56%] [G loss: 0.758129]\n",
      "epoch:14 step:10954 [D loss: 0.715131, acc.: 42.97%] [G loss: 0.741364]\n",
      "epoch:14 step:10955 [D loss: 0.670582, acc.: 57.03%] [G loss: 0.841293]\n",
      "epoch:14 step:10956 [D loss: 0.657058, acc.: 65.62%] [G loss: 0.827505]\n",
      "epoch:14 step:10957 [D loss: 0.693534, acc.: 53.12%] [G loss: 0.796476]\n",
      "epoch:14 step:10958 [D loss: 0.672338, acc.: 60.16%] [G loss: 0.773766]\n",
      "epoch:14 step:10959 [D loss: 0.685542, acc.: 57.81%] [G loss: 0.789698]\n",
      "epoch:14 step:10960 [D loss: 0.690701, acc.: 53.91%] [G loss: 0.720843]\n",
      "epoch:14 step:10961 [D loss: 0.703751, acc.: 50.00%] [G loss: 0.713497]\n",
      "epoch:14 step:10962 [D loss: 0.663216, acc.: 59.38%] [G loss: 0.810261]\n",
      "epoch:14 step:10963 [D loss: 0.658207, acc.: 63.28%] [G loss: 0.822949]\n",
      "epoch:14 step:10964 [D loss: 0.704088, acc.: 49.22%] [G loss: 0.741578]\n",
      "epoch:14 step:10965 [D loss: 0.643759, acc.: 63.28%] [G loss: 0.789338]\n",
      "epoch:14 step:10966 [D loss: 0.724159, acc.: 46.09%] [G loss: 0.735441]\n",
      "epoch:14 step:10967 [D loss: 0.657046, acc.: 64.84%] [G loss: 0.754856]\n",
      "epoch:14 step:10968 [D loss: 0.685084, acc.: 59.38%] [G loss: 0.731291]\n",
      "epoch:14 step:10969 [D loss: 0.653233, acc.: 63.28%] [G loss: 0.747481]\n",
      "epoch:14 step:10970 [D loss: 0.670449, acc.: 62.50%] [G loss: 0.724905]\n",
      "epoch:14 step:10971 [D loss: 0.704838, acc.: 48.44%] [G loss: 0.711800]\n",
      "epoch:14 step:10972 [D loss: 0.675591, acc.: 50.00%] [G loss: 0.694952]\n",
      "epoch:14 step:10973 [D loss: 0.681221, acc.: 56.25%] [G loss: 0.757021]\n",
      "epoch:14 step:10974 [D loss: 0.742508, acc.: 42.19%] [G loss: 0.742635]\n",
      "epoch:14 step:10975 [D loss: 0.705639, acc.: 46.88%] [G loss: 0.695101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:10976 [D loss: 0.677200, acc.: 57.03%] [G loss: 0.727419]\n",
      "epoch:14 step:10977 [D loss: 0.737004, acc.: 36.72%] [G loss: 0.695373]\n",
      "epoch:14 step:10978 [D loss: 0.717718, acc.: 46.09%] [G loss: 0.689834]\n",
      "epoch:14 step:10979 [D loss: 0.724774, acc.: 46.88%] [G loss: 0.702809]\n",
      "epoch:14 step:10980 [D loss: 0.648667, acc.: 67.19%] [G loss: 0.719549]\n",
      "epoch:14 step:10981 [D loss: 0.713714, acc.: 47.66%] [G loss: 0.705954]\n",
      "epoch:14 step:10982 [D loss: 0.702405, acc.: 54.69%] [G loss: 0.791873]\n",
      "epoch:14 step:10983 [D loss: 0.773056, acc.: 34.38%] [G loss: 0.709463]\n",
      "epoch:14 step:10984 [D loss: 0.763425, acc.: 35.94%] [G loss: 0.768692]\n",
      "epoch:14 step:10985 [D loss: 0.680282, acc.: 53.12%] [G loss: 0.798939]\n",
      "epoch:14 step:10986 [D loss: 0.713502, acc.: 47.66%] [G loss: 0.757826]\n",
      "epoch:14 step:10987 [D loss: 0.677048, acc.: 53.91%] [G loss: 0.771464]\n",
      "epoch:14 step:10988 [D loss: 0.737299, acc.: 39.06%] [G loss: 0.777115]\n",
      "epoch:14 step:10989 [D loss: 0.667990, acc.: 60.94%] [G loss: 0.775126]\n",
      "epoch:14 step:10990 [D loss: 0.668606, acc.: 56.25%] [G loss: 0.828321]\n",
      "epoch:14 step:10991 [D loss: 0.717964, acc.: 50.78%] [G loss: 0.734518]\n",
      "epoch:14 step:10992 [D loss: 0.701042, acc.: 53.12%] [G loss: 0.765449]\n",
      "epoch:14 step:10993 [D loss: 0.675212, acc.: 57.81%] [G loss: 0.802095]\n",
      "epoch:14 step:10994 [D loss: 0.666057, acc.: 61.72%] [G loss: 0.784477]\n",
      "epoch:14 step:10995 [D loss: 0.687914, acc.: 50.00%] [G loss: 0.771090]\n",
      "epoch:14 step:10996 [D loss: 0.703894, acc.: 53.12%] [G loss: 0.743535]\n",
      "epoch:14 step:10997 [D loss: 0.688126, acc.: 55.47%] [G loss: 0.784768]\n",
      "epoch:14 step:10998 [D loss: 0.677081, acc.: 60.94%] [G loss: 0.753922]\n",
      "epoch:14 step:10999 [D loss: 0.705165, acc.: 47.66%] [G loss: 0.766038]\n",
      "epoch:14 step:11000 [D loss: 0.724599, acc.: 46.09%] [G loss: 0.778720]\n",
      "epoch:14 step:11001 [D loss: 0.665248, acc.: 64.06%] [G loss: 0.798386]\n",
      "epoch:14 step:11002 [D loss: 0.725993, acc.: 42.19%] [G loss: 0.790962]\n",
      "epoch:14 step:11003 [D loss: 0.704982, acc.: 51.56%] [G loss: 0.790062]\n",
      "epoch:14 step:11004 [D loss: 0.713084, acc.: 51.56%] [G loss: 0.784188]\n",
      "epoch:14 step:11005 [D loss: 0.770573, acc.: 31.25%] [G loss: 0.721226]\n",
      "epoch:14 step:11006 [D loss: 0.727850, acc.: 42.97%] [G loss: 0.737390]\n",
      "epoch:14 step:11007 [D loss: 0.678342, acc.: 60.94%] [G loss: 0.746025]\n",
      "epoch:14 step:11008 [D loss: 0.721757, acc.: 50.78%] [G loss: 0.785954]\n",
      "epoch:14 step:11009 [D loss: 0.657180, acc.: 60.16%] [G loss: 0.749141]\n",
      "epoch:14 step:11010 [D loss: 0.718629, acc.: 50.00%] [G loss: 0.748778]\n",
      "epoch:14 step:11011 [D loss: 0.669451, acc.: 57.81%] [G loss: 0.761444]\n",
      "epoch:14 step:11012 [D loss: 0.706033, acc.: 52.34%] [G loss: 0.800809]\n",
      "epoch:14 step:11013 [D loss: 0.642899, acc.: 66.41%] [G loss: 0.889088]\n",
      "epoch:14 step:11014 [D loss: 0.715728, acc.: 49.22%] [G loss: 0.834490]\n",
      "epoch:14 step:11015 [D loss: 0.713198, acc.: 48.44%] [G loss: 0.804461]\n",
      "epoch:14 step:11016 [D loss: 0.673399, acc.: 58.59%] [G loss: 0.735350]\n",
      "epoch:14 step:11017 [D loss: 0.651140, acc.: 64.84%] [G loss: 0.849409]\n",
      "epoch:14 step:11018 [D loss: 0.709155, acc.: 44.53%] [G loss: 0.834298]\n",
      "epoch:14 step:11019 [D loss: 0.694655, acc.: 54.69%] [G loss: 0.783019]\n",
      "epoch:14 step:11020 [D loss: 0.664554, acc.: 57.03%] [G loss: 0.737687]\n",
      "epoch:14 step:11021 [D loss: 0.714808, acc.: 46.09%] [G loss: 0.718244]\n",
      "epoch:14 step:11022 [D loss: 0.688788, acc.: 53.12%] [G loss: 0.759334]\n",
      "epoch:14 step:11023 [D loss: 0.689441, acc.: 49.22%] [G loss: 0.756362]\n",
      "epoch:14 step:11024 [D loss: 0.618729, acc.: 68.75%] [G loss: 0.822827]\n",
      "epoch:14 step:11025 [D loss: 0.759772, acc.: 35.16%] [G loss: 0.697638]\n",
      "epoch:14 step:11026 [D loss: 0.727392, acc.: 48.44%] [G loss: 0.757904]\n",
      "epoch:14 step:11027 [D loss: 0.715461, acc.: 50.00%] [G loss: 0.725905]\n",
      "epoch:14 step:11028 [D loss: 0.733371, acc.: 45.31%] [G loss: 0.719024]\n",
      "epoch:14 step:11029 [D loss: 0.776419, acc.: 39.06%] [G loss: 0.702832]\n",
      "epoch:14 step:11030 [D loss: 0.700559, acc.: 50.78%] [G loss: 0.782884]\n",
      "epoch:14 step:11031 [D loss: 0.755551, acc.: 30.47%] [G loss: 0.719636]\n",
      "epoch:14 step:11032 [D loss: 0.714083, acc.: 50.00%] [G loss: 0.857307]\n",
      "epoch:14 step:11033 [D loss: 0.698070, acc.: 50.78%] [G loss: 0.753070]\n",
      "epoch:14 step:11034 [D loss: 0.652532, acc.: 59.38%] [G loss: 0.847369]\n",
      "epoch:14 step:11035 [D loss: 0.699625, acc.: 51.56%] [G loss: 0.798404]\n",
      "epoch:14 step:11036 [D loss: 0.657765, acc.: 64.06%] [G loss: 0.895990]\n",
      "epoch:14 step:11037 [D loss: 0.733816, acc.: 47.66%] [G loss: 0.764614]\n",
      "epoch:14 step:11038 [D loss: 0.663726, acc.: 57.81%] [G loss: 0.830927]\n",
      "epoch:14 step:11039 [D loss: 0.667069, acc.: 59.38%] [G loss: 0.713451]\n",
      "epoch:14 step:11040 [D loss: 0.694398, acc.: 53.91%] [G loss: 0.783558]\n",
      "epoch:14 step:11041 [D loss: 0.687058, acc.: 55.47%] [G loss: 0.724111]\n",
      "epoch:14 step:11042 [D loss: 0.735784, acc.: 38.28%] [G loss: 0.756792]\n",
      "epoch:14 step:11043 [D loss: 0.654100, acc.: 67.97%] [G loss: 0.735945]\n",
      "epoch:14 step:11044 [D loss: 0.654407, acc.: 63.28%] [G loss: 0.738540]\n",
      "epoch:14 step:11045 [D loss: 0.700219, acc.: 50.00%] [G loss: 0.754710]\n",
      "epoch:14 step:11046 [D loss: 0.681288, acc.: 56.25%] [G loss: 0.744076]\n",
      "epoch:14 step:11047 [D loss: 0.640516, acc.: 70.31%] [G loss: 0.732340]\n",
      "epoch:14 step:11048 [D loss: 0.628898, acc.: 72.66%] [G loss: 0.727747]\n",
      "epoch:14 step:11049 [D loss: 0.706343, acc.: 52.34%] [G loss: 0.755170]\n",
      "epoch:14 step:11050 [D loss: 0.754518, acc.: 42.19%] [G loss: 0.713777]\n",
      "epoch:14 step:11051 [D loss: 0.684395, acc.: 53.12%] [G loss: 0.743799]\n",
      "epoch:14 step:11052 [D loss: 0.677159, acc.: 62.50%] [G loss: 0.792268]\n",
      "epoch:14 step:11053 [D loss: 0.587963, acc.: 81.25%] [G loss: 0.771118]\n",
      "epoch:14 step:11054 [D loss: 0.713935, acc.: 46.09%] [G loss: 0.753635]\n",
      "epoch:14 step:11055 [D loss: 0.735921, acc.: 39.06%] [G loss: 0.721863]\n",
      "epoch:14 step:11056 [D loss: 0.720550, acc.: 46.88%] [G loss: 0.700475]\n",
      "epoch:14 step:11057 [D loss: 0.717869, acc.: 44.53%] [G loss: 0.724326]\n",
      "epoch:14 step:11058 [D loss: 0.815712, acc.: 27.34%] [G loss: 0.687791]\n",
      "epoch:14 step:11059 [D loss: 0.683223, acc.: 53.91%] [G loss: 0.665088]\n",
      "epoch:14 step:11060 [D loss: 0.714185, acc.: 45.31%] [G loss: 0.718330]\n",
      "epoch:14 step:11061 [D loss: 0.649396, acc.: 65.62%] [G loss: 0.744007]\n",
      "epoch:14 step:11062 [D loss: 0.758298, acc.: 41.41%] [G loss: 0.692780]\n",
      "epoch:14 step:11063 [D loss: 0.685158, acc.: 57.03%] [G loss: 0.776945]\n",
      "epoch:14 step:11064 [D loss: 0.692263, acc.: 53.12%] [G loss: 0.718314]\n",
      "epoch:14 step:11065 [D loss: 0.699707, acc.: 51.56%] [G loss: 0.761272]\n",
      "epoch:14 step:11066 [D loss: 0.676956, acc.: 64.06%] [G loss: 0.794226]\n",
      "epoch:14 step:11067 [D loss: 0.690931, acc.: 52.34%] [G loss: 0.760856]\n",
      "epoch:14 step:11068 [D loss: 0.669886, acc.: 57.03%] [G loss: 0.796640]\n",
      "epoch:14 step:11069 [D loss: 0.719714, acc.: 47.66%] [G loss: 0.773103]\n",
      "epoch:14 step:11070 [D loss: 0.709312, acc.: 46.88%] [G loss: 0.741966]\n",
      "epoch:14 step:11071 [D loss: 0.724410, acc.: 49.22%] [G loss: 0.787114]\n",
      "epoch:14 step:11072 [D loss: 0.700246, acc.: 46.88%] [G loss: 0.797207]\n",
      "epoch:14 step:11073 [D loss: 0.688517, acc.: 54.69%] [G loss: 0.756498]\n",
      "epoch:14 step:11074 [D loss: 0.667489, acc.: 64.84%] [G loss: 0.726075]\n",
      "epoch:14 step:11075 [D loss: 0.636385, acc.: 62.50%] [G loss: 0.672056]\n",
      "epoch:14 step:11076 [D loss: 0.699781, acc.: 52.34%] [G loss: 0.701917]\n",
      "epoch:14 step:11077 [D loss: 0.615421, acc.: 67.97%] [G loss: 0.857805]\n",
      "epoch:14 step:11078 [D loss: 0.694950, acc.: 57.81%] [G loss: 0.753563]\n",
      "epoch:14 step:11079 [D loss: 0.646270, acc.: 60.94%] [G loss: 0.724989]\n",
      "epoch:14 step:11080 [D loss: 0.696422, acc.: 52.34%] [G loss: 0.682257]\n",
      "epoch:14 step:11081 [D loss: 0.684790, acc.: 60.16%] [G loss: 0.723970]\n",
      "epoch:14 step:11082 [D loss: 0.721359, acc.: 45.31%] [G loss: 0.677299]\n",
      "epoch:14 step:11083 [D loss: 0.758471, acc.: 39.84%] [G loss: 0.720036]\n",
      "epoch:14 step:11084 [D loss: 0.729487, acc.: 47.66%] [G loss: 0.816885]\n",
      "epoch:14 step:11085 [D loss: 0.737986, acc.: 36.72%] [G loss: 0.736149]\n",
      "epoch:14 step:11086 [D loss: 0.774941, acc.: 34.38%] [G loss: 0.741300]\n",
      "epoch:14 step:11087 [D loss: 0.715351, acc.: 48.44%] [G loss: 0.753747]\n",
      "epoch:14 step:11088 [D loss: 0.690499, acc.: 46.09%] [G loss: 0.808441]\n",
      "epoch:14 step:11089 [D loss: 0.709700, acc.: 52.34%] [G loss: 0.805022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11090 [D loss: 0.754875, acc.: 37.50%] [G loss: 0.724487]\n",
      "epoch:14 step:11091 [D loss: 0.644503, acc.: 67.97%] [G loss: 0.743942]\n",
      "epoch:14 step:11092 [D loss: 0.682557, acc.: 56.25%] [G loss: 0.757267]\n",
      "epoch:14 step:11093 [D loss: 0.625989, acc.: 73.44%] [G loss: 0.732444]\n",
      "epoch:14 step:11094 [D loss: 0.667031, acc.: 58.59%] [G loss: 0.720925]\n",
      "epoch:14 step:11095 [D loss: 0.652443, acc.: 60.16%] [G loss: 0.769522]\n",
      "epoch:14 step:11096 [D loss: 0.688263, acc.: 58.59%] [G loss: 0.684941]\n",
      "epoch:14 step:11097 [D loss: 0.723362, acc.: 42.97%] [G loss: 0.729416]\n",
      "epoch:14 step:11098 [D loss: 0.674375, acc.: 57.03%] [G loss: 0.795674]\n",
      "epoch:14 step:11099 [D loss: 0.676984, acc.: 53.12%] [G loss: 0.869633]\n",
      "epoch:14 step:11100 [D loss: 0.672789, acc.: 57.81%] [G loss: 0.763102]\n",
      "epoch:14 step:11101 [D loss: 0.687843, acc.: 60.16%] [G loss: 0.710024]\n",
      "epoch:14 step:11102 [D loss: 0.633982, acc.: 67.97%] [G loss: 0.667858]\n",
      "epoch:14 step:11103 [D loss: 0.683363, acc.: 50.78%] [G loss: 0.683891]\n",
      "epoch:14 step:11104 [D loss: 0.694878, acc.: 53.91%] [G loss: 0.659538]\n",
      "epoch:14 step:11105 [D loss: 0.714830, acc.: 51.56%] [G loss: 0.683946]\n",
      "epoch:14 step:11106 [D loss: 0.753305, acc.: 35.94%] [G loss: 0.734903]\n",
      "epoch:14 step:11107 [D loss: 0.748194, acc.: 37.50%] [G loss: 0.680684]\n",
      "epoch:14 step:11108 [D loss: 0.708358, acc.: 49.22%] [G loss: 0.718054]\n",
      "epoch:14 step:11109 [D loss: 0.720335, acc.: 46.09%] [G loss: 0.756347]\n",
      "epoch:14 step:11110 [D loss: 0.747466, acc.: 36.72%] [G loss: 0.795362]\n",
      "epoch:14 step:11111 [D loss: 0.731167, acc.: 41.41%] [G loss: 0.797952]\n",
      "epoch:14 step:11112 [D loss: 0.724673, acc.: 54.69%] [G loss: 0.853456]\n",
      "epoch:14 step:11113 [D loss: 0.662948, acc.: 64.06%] [G loss: 0.803803]\n",
      "epoch:14 step:11114 [D loss: 0.676306, acc.: 57.81%] [G loss: 0.848283]\n",
      "epoch:14 step:11115 [D loss: 0.679668, acc.: 52.34%] [G loss: 0.822585]\n",
      "epoch:14 step:11116 [D loss: 0.706782, acc.: 50.00%] [G loss: 0.831714]\n",
      "epoch:14 step:11117 [D loss: 0.668892, acc.: 61.72%] [G loss: 0.843914]\n",
      "epoch:14 step:11118 [D loss: 0.647707, acc.: 64.06%] [G loss: 0.789569]\n",
      "epoch:14 step:11119 [D loss: 0.585244, acc.: 80.47%] [G loss: 0.808232]\n",
      "epoch:14 step:11120 [D loss: 0.621094, acc.: 67.19%] [G loss: 0.792118]\n",
      "epoch:14 step:11121 [D loss: 0.627461, acc.: 67.19%] [G loss: 0.761232]\n",
      "epoch:14 step:11122 [D loss: 0.654561, acc.: 63.28%] [G loss: 0.727224]\n",
      "epoch:14 step:11123 [D loss: 0.595316, acc.: 75.78%] [G loss: 0.771779]\n",
      "epoch:14 step:11124 [D loss: 0.629036, acc.: 67.19%] [G loss: 0.760472]\n",
      "epoch:14 step:11125 [D loss: 0.601765, acc.: 78.91%] [G loss: 0.705144]\n",
      "epoch:14 step:11126 [D loss: 0.653966, acc.: 67.19%] [G loss: 0.719860]\n",
      "epoch:14 step:11127 [D loss: 0.631715, acc.: 68.75%] [G loss: 0.644664]\n",
      "epoch:14 step:11128 [D loss: 0.636323, acc.: 67.19%] [G loss: 0.608546]\n",
      "epoch:14 step:11129 [D loss: 0.684025, acc.: 53.91%] [G loss: 0.584630]\n",
      "epoch:14 step:11130 [D loss: 0.694325, acc.: 47.66%] [G loss: 0.642747]\n",
      "epoch:14 step:11131 [D loss: 0.695895, acc.: 57.81%] [G loss: 0.630489]\n",
      "epoch:14 step:11132 [D loss: 0.717601, acc.: 49.22%] [G loss: 0.585024]\n",
      "epoch:14 step:11133 [D loss: 0.734588, acc.: 42.97%] [G loss: 0.661238]\n",
      "epoch:14 step:11134 [D loss: 0.606337, acc.: 71.88%] [G loss: 0.563868]\n",
      "epoch:14 step:11135 [D loss: 0.764222, acc.: 45.31%] [G loss: 0.541177]\n",
      "epoch:14 step:11136 [D loss: 0.833980, acc.: 25.78%] [G loss: 0.618196]\n",
      "epoch:14 step:11137 [D loss: 0.740890, acc.: 46.09%] [G loss: 0.650377]\n",
      "epoch:14 step:11138 [D loss: 0.675454, acc.: 51.56%] [G loss: 0.841165]\n",
      "epoch:14 step:11139 [D loss: 0.840043, acc.: 19.53%] [G loss: 0.720079]\n",
      "epoch:14 step:11140 [D loss: 0.770765, acc.: 37.50%] [G loss: 0.709856]\n",
      "epoch:14 step:11141 [D loss: 0.685356, acc.: 50.00%] [G loss: 0.727581]\n",
      "epoch:14 step:11142 [D loss: 0.708999, acc.: 50.00%] [G loss: 0.721695]\n",
      "epoch:14 step:11143 [D loss: 0.715649, acc.: 46.88%] [G loss: 0.805091]\n",
      "epoch:14 step:11144 [D loss: 0.637461, acc.: 69.53%] [G loss: 0.854257]\n",
      "epoch:14 step:11145 [D loss: 0.650434, acc.: 65.62%] [G loss: 0.827851]\n",
      "epoch:14 step:11146 [D loss: 0.631095, acc.: 71.09%] [G loss: 0.844596]\n",
      "epoch:14 step:11147 [D loss: 0.684106, acc.: 58.59%] [G loss: 0.842293]\n",
      "epoch:14 step:11148 [D loss: 0.683147, acc.: 53.91%] [G loss: 0.783062]\n",
      "epoch:14 step:11149 [D loss: 0.602906, acc.: 75.78%] [G loss: 0.854770]\n",
      "epoch:14 step:11150 [D loss: 0.624435, acc.: 68.75%] [G loss: 0.826133]\n",
      "epoch:14 step:11151 [D loss: 0.576055, acc.: 79.69%] [G loss: 0.728450]\n",
      "epoch:14 step:11152 [D loss: 0.629332, acc.: 69.53%] [G loss: 0.746302]\n",
      "epoch:14 step:11153 [D loss: 0.621432, acc.: 73.44%] [G loss: 0.699369]\n",
      "epoch:14 step:11154 [D loss: 0.624029, acc.: 63.28%] [G loss: 0.733595]\n",
      "epoch:14 step:11155 [D loss: 0.635714, acc.: 65.62%] [G loss: 0.651873]\n",
      "epoch:14 step:11156 [D loss: 0.793461, acc.: 35.94%] [G loss: 0.637569]\n",
      "epoch:14 step:11157 [D loss: 0.614139, acc.: 69.53%] [G loss: 0.698189]\n",
      "epoch:14 step:11158 [D loss: 0.691379, acc.: 53.91%] [G loss: 0.643964]\n",
      "epoch:14 step:11159 [D loss: 0.637099, acc.: 67.19%] [G loss: 0.661731]\n",
      "epoch:14 step:11160 [D loss: 0.643827, acc.: 64.84%] [G loss: 0.629049]\n",
      "epoch:14 step:11161 [D loss: 0.617177, acc.: 76.56%] [G loss: 0.617425]\n",
      "epoch:14 step:11162 [D loss: 0.732671, acc.: 42.19%] [G loss: 0.586191]\n",
      "epoch:14 step:11163 [D loss: 0.695462, acc.: 53.12%] [G loss: 0.638218]\n",
      "epoch:14 step:11164 [D loss: 0.681426, acc.: 54.69%] [G loss: 0.574332]\n",
      "epoch:14 step:11165 [D loss: 0.749318, acc.: 41.41%] [G loss: 0.596364]\n",
      "epoch:14 step:11166 [D loss: 0.705591, acc.: 45.31%] [G loss: 0.610870]\n",
      "epoch:14 step:11167 [D loss: 0.730692, acc.: 45.31%] [G loss: 0.646226]\n",
      "epoch:14 step:11168 [D loss: 0.752162, acc.: 43.75%] [G loss: 0.669607]\n",
      "epoch:14 step:11169 [D loss: 0.779590, acc.: 37.50%] [G loss: 0.656857]\n",
      "epoch:14 step:11170 [D loss: 0.774021, acc.: 37.50%] [G loss: 0.743750]\n",
      "epoch:14 step:11171 [D loss: 0.696971, acc.: 51.56%] [G loss: 0.760772]\n",
      "epoch:14 step:11172 [D loss: 0.665203, acc.: 66.41%] [G loss: 0.898756]\n",
      "epoch:14 step:11173 [D loss: 0.692609, acc.: 54.69%] [G loss: 0.800885]\n",
      "epoch:14 step:11174 [D loss: 0.699986, acc.: 51.56%] [G loss: 0.886208]\n",
      "epoch:14 step:11175 [D loss: 0.698756, acc.: 50.00%] [G loss: 0.778328]\n",
      "epoch:14 step:11176 [D loss: 0.690316, acc.: 56.25%] [G loss: 0.821162]\n",
      "epoch:14 step:11177 [D loss: 0.675390, acc.: 54.69%] [G loss: 0.769047]\n",
      "epoch:14 step:11178 [D loss: 0.631057, acc.: 70.31%] [G loss: 0.873571]\n",
      "epoch:14 step:11179 [D loss: 0.685415, acc.: 53.91%] [G loss: 0.715536]\n",
      "epoch:14 step:11180 [D loss: 0.697067, acc.: 53.91%] [G loss: 0.751305]\n",
      "epoch:14 step:11181 [D loss: 0.614776, acc.: 74.22%] [G loss: 0.767545]\n",
      "epoch:14 step:11182 [D loss: 0.618620, acc.: 71.88%] [G loss: 0.761464]\n",
      "epoch:14 step:11183 [D loss: 0.568410, acc.: 75.78%] [G loss: 0.823728]\n",
      "epoch:14 step:11184 [D loss: 0.567770, acc.: 80.47%] [G loss: 0.697552]\n",
      "epoch:14 step:11185 [D loss: 0.672088, acc.: 61.72%] [G loss: 0.681437]\n",
      "epoch:14 step:11186 [D loss: 0.610277, acc.: 72.66%] [G loss: 0.747628]\n",
      "epoch:14 step:11187 [D loss: 0.646210, acc.: 62.50%] [G loss: 0.707592]\n",
      "epoch:14 step:11188 [D loss: 0.642035, acc.: 65.62%] [G loss: 0.638080]\n",
      "epoch:14 step:11189 [D loss: 0.681471, acc.: 53.91%] [G loss: 0.647696]\n",
      "epoch:14 step:11190 [D loss: 0.747105, acc.: 39.06%] [G loss: 0.645549]\n",
      "epoch:14 step:11191 [D loss: 0.707227, acc.: 54.69%] [G loss: 0.642678]\n",
      "epoch:14 step:11192 [D loss: 0.729161, acc.: 46.88%] [G loss: 0.654458]\n",
      "epoch:14 step:11193 [D loss: 0.690399, acc.: 52.34%] [G loss: 0.693965]\n",
      "epoch:14 step:11194 [D loss: 0.680138, acc.: 55.47%] [G loss: 0.666675]\n",
      "epoch:14 step:11195 [D loss: 0.631958, acc.: 62.50%] [G loss: 0.741791]\n",
      "epoch:14 step:11196 [D loss: 0.625811, acc.: 65.62%] [G loss: 0.739215]\n",
      "epoch:14 step:11197 [D loss: 0.672399, acc.: 57.03%] [G loss: 0.789031]\n",
      "epoch:14 step:11198 [D loss: 0.790360, acc.: 30.47%] [G loss: 0.775215]\n",
      "epoch:14 step:11199 [D loss: 0.770480, acc.: 37.50%] [G loss: 0.686382]\n",
      "epoch:14 step:11200 [D loss: 0.702059, acc.: 50.00%] [G loss: 0.755965]\n",
      "epoch:14 step:11201 [D loss: 0.830901, acc.: 26.56%] [G loss: 0.714647]\n",
      "epoch:14 step:11202 [D loss: 0.700690, acc.: 53.91%] [G loss: 0.696275]\n",
      "epoch:14 step:11203 [D loss: 0.700926, acc.: 50.00%] [G loss: 0.761028]\n",
      "epoch:14 step:11204 [D loss: 0.681155, acc.: 57.03%] [G loss: 0.721851]\n",
      "epoch:14 step:11205 [D loss: 0.717547, acc.: 47.66%] [G loss: 0.722232]\n",
      "epoch:14 step:11206 [D loss: 0.730727, acc.: 50.00%] [G loss: 0.808099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11207 [D loss: 0.734894, acc.: 42.19%] [G loss: 0.776652]\n",
      "epoch:14 step:11208 [D loss: 0.747290, acc.: 39.06%] [G loss: 0.766562]\n",
      "epoch:14 step:11209 [D loss: 0.639956, acc.: 67.97%] [G loss: 0.861269]\n",
      "epoch:14 step:11210 [D loss: 0.709188, acc.: 44.53%] [G loss: 0.739698]\n",
      "epoch:14 step:11211 [D loss: 0.720462, acc.: 50.00%] [G loss: 0.841544]\n",
      "epoch:14 step:11212 [D loss: 0.641487, acc.: 69.53%] [G loss: 0.867788]\n",
      "epoch:14 step:11213 [D loss: 0.625622, acc.: 70.31%] [G loss: 0.818476]\n",
      "epoch:14 step:11214 [D loss: 0.612684, acc.: 71.88%] [G loss: 0.841965]\n",
      "epoch:14 step:11215 [D loss: 0.672233, acc.: 68.75%] [G loss: 0.802948]\n",
      "epoch:14 step:11216 [D loss: 0.668703, acc.: 59.38%] [G loss: 0.751743]\n",
      "epoch:14 step:11217 [D loss: 0.668554, acc.: 60.16%] [G loss: 0.714268]\n",
      "epoch:14 step:11218 [D loss: 0.654581, acc.: 60.94%] [G loss: 0.704284]\n",
      "epoch:14 step:11219 [D loss: 0.640126, acc.: 64.84%] [G loss: 0.648930]\n",
      "epoch:14 step:11220 [D loss: 0.723159, acc.: 45.31%] [G loss: 0.676579]\n",
      "epoch:14 step:11221 [D loss: 0.741331, acc.: 42.97%] [G loss: 0.618391]\n",
      "epoch:14 step:11222 [D loss: 0.677198, acc.: 57.03%] [G loss: 0.668610]\n",
      "epoch:14 step:11223 [D loss: 0.720538, acc.: 46.88%] [G loss: 0.684021]\n",
      "epoch:14 step:11224 [D loss: 0.684039, acc.: 50.78%] [G loss: 0.697217]\n",
      "epoch:14 step:11225 [D loss: 0.722280, acc.: 46.09%] [G loss: 0.817368]\n",
      "epoch:14 step:11226 [D loss: 0.702378, acc.: 54.69%] [G loss: 0.708745]\n",
      "epoch:14 step:11227 [D loss: 0.738402, acc.: 44.53%] [G loss: 0.724232]\n",
      "epoch:14 step:11228 [D loss: 0.679802, acc.: 61.72%] [G loss: 0.718905]\n",
      "epoch:14 step:11229 [D loss: 0.702647, acc.: 58.59%] [G loss: 0.740342]\n",
      "epoch:14 step:11230 [D loss: 0.741150, acc.: 46.09%] [G loss: 0.739626]\n",
      "epoch:14 step:11231 [D loss: 0.685592, acc.: 58.59%] [G loss: 0.813244]\n",
      "epoch:14 step:11232 [D loss: 0.704562, acc.: 50.78%] [G loss: 0.859999]\n",
      "epoch:14 step:11233 [D loss: 0.687263, acc.: 56.25%] [G loss: 0.826544]\n",
      "epoch:14 step:11234 [D loss: 0.743170, acc.: 37.50%] [G loss: 0.776012]\n",
      "epoch:14 step:11235 [D loss: 0.712231, acc.: 45.31%] [G loss: 0.824599]\n",
      "epoch:14 step:11236 [D loss: 0.601166, acc.: 76.56%] [G loss: 0.921329]\n",
      "epoch:14 step:11237 [D loss: 0.615559, acc.: 69.53%] [G loss: 0.849985]\n",
      "epoch:14 step:11238 [D loss: 0.703861, acc.: 47.66%] [G loss: 0.720526]\n",
      "epoch:14 step:11239 [D loss: 0.695005, acc.: 57.81%] [G loss: 0.760821]\n",
      "epoch:14 step:11240 [D loss: 0.616340, acc.: 70.31%] [G loss: 0.763001]\n",
      "epoch:14 step:11241 [D loss: 0.709551, acc.: 50.78%] [G loss: 0.680149]\n",
      "epoch:14 step:11242 [D loss: 0.584889, acc.: 79.69%] [G loss: 0.667806]\n",
      "epoch:14 step:11243 [D loss: 0.669383, acc.: 55.47%] [G loss: 0.689933]\n",
      "epoch:14 step:11244 [D loss: 0.693696, acc.: 57.81%] [G loss: 0.662358]\n",
      "epoch:14 step:11245 [D loss: 0.707204, acc.: 52.34%] [G loss: 0.669184]\n",
      "epoch:14 step:11246 [D loss: 0.597029, acc.: 73.44%] [G loss: 0.705506]\n",
      "epoch:14 step:11247 [D loss: 0.730303, acc.: 46.88%] [G loss: 0.672508]\n",
      "epoch:14 step:11248 [D loss: 0.752948, acc.: 39.06%] [G loss: 0.693050]\n",
      "epoch:14 step:11249 [D loss: 0.765266, acc.: 39.84%] [G loss: 0.730922]\n",
      "epoch:14 step:11250 [D loss: 0.734220, acc.: 36.72%] [G loss: 0.685236]\n",
      "epoch:14 step:11251 [D loss: 0.760902, acc.: 35.16%] [G loss: 0.772218]\n",
      "epoch:14 step:11252 [D loss: 0.658232, acc.: 61.72%] [G loss: 0.764560]\n",
      "epoch:14 step:11253 [D loss: 0.755668, acc.: 38.28%] [G loss: 0.768416]\n",
      "epoch:14 step:11254 [D loss: 0.705810, acc.: 53.12%] [G loss: 0.791888]\n",
      "epoch:14 step:11255 [D loss: 0.694679, acc.: 51.56%] [G loss: 0.777954]\n",
      "epoch:14 step:11256 [D loss: 0.679750, acc.: 53.12%] [G loss: 0.791147]\n",
      "epoch:14 step:11257 [D loss: 0.606152, acc.: 74.22%] [G loss: 0.825509]\n",
      "epoch:14 step:11258 [D loss: 0.644394, acc.: 65.62%] [G loss: 0.804009]\n",
      "epoch:14 step:11259 [D loss: 0.686949, acc.: 55.47%] [G loss: 0.815424]\n",
      "epoch:14 step:11260 [D loss: 0.654180, acc.: 65.62%] [G loss: 0.769510]\n",
      "epoch:14 step:11261 [D loss: 0.648556, acc.: 63.28%] [G loss: 0.888640]\n",
      "epoch:14 step:11262 [D loss: 0.612557, acc.: 75.00%] [G loss: 0.871112]\n",
      "epoch:14 step:11263 [D loss: 0.696966, acc.: 47.66%] [G loss: 0.684949]\n",
      "epoch:14 step:11264 [D loss: 0.639505, acc.: 64.84%] [G loss: 0.790980]\n",
      "epoch:14 step:11265 [D loss: 0.658279, acc.: 59.38%] [G loss: 0.803326]\n",
      "epoch:14 step:11266 [D loss: 0.675157, acc.: 58.59%] [G loss: 0.759974]\n",
      "epoch:14 step:11267 [D loss: 0.598747, acc.: 76.56%] [G loss: 0.785576]\n",
      "epoch:14 step:11268 [D loss: 0.684261, acc.: 52.34%] [G loss: 0.693947]\n",
      "epoch:14 step:11269 [D loss: 0.783048, acc.: 33.59%] [G loss: 0.630086]\n",
      "epoch:14 step:11270 [D loss: 0.671265, acc.: 60.94%] [G loss: 0.747996]\n",
      "epoch:14 step:11271 [D loss: 0.698100, acc.: 52.34%] [G loss: 0.692864]\n",
      "epoch:14 step:11272 [D loss: 0.681050, acc.: 59.38%] [G loss: 0.658125]\n",
      "epoch:14 step:11273 [D loss: 0.693556, acc.: 57.81%] [G loss: 0.642522]\n",
      "epoch:14 step:11274 [D loss: 0.715643, acc.: 50.00%] [G loss: 0.665614]\n",
      "epoch:14 step:11275 [D loss: 0.758686, acc.: 42.19%] [G loss: 0.642425]\n",
      "epoch:14 step:11276 [D loss: 0.738418, acc.: 44.53%] [G loss: 0.725787]\n",
      "epoch:14 step:11277 [D loss: 0.768602, acc.: 37.50%] [G loss: 0.687877]\n",
      "epoch:14 step:11278 [D loss: 0.734979, acc.: 45.31%] [G loss: 0.727753]\n",
      "epoch:14 step:11279 [D loss: 0.672711, acc.: 56.25%] [G loss: 0.790488]\n",
      "epoch:14 step:11280 [D loss: 0.779353, acc.: 35.16%] [G loss: 0.775053]\n",
      "epoch:14 step:11281 [D loss: 0.721653, acc.: 48.44%] [G loss: 0.805206]\n",
      "epoch:14 step:11282 [D loss: 0.684177, acc.: 53.12%] [G loss: 0.854967]\n",
      "epoch:14 step:11283 [D loss: 0.678215, acc.: 58.59%] [G loss: 0.938235]\n",
      "epoch:14 step:11284 [D loss: 0.718311, acc.: 46.09%] [G loss: 0.892130]\n",
      "epoch:14 step:11285 [D loss: 0.681451, acc.: 57.03%] [G loss: 0.856839]\n",
      "epoch:14 step:11286 [D loss: 0.630555, acc.: 71.88%] [G loss: 0.869631]\n",
      "epoch:14 step:11287 [D loss: 0.642299, acc.: 65.62%] [G loss: 0.802984]\n",
      "epoch:14 step:11288 [D loss: 0.713105, acc.: 50.00%] [G loss: 0.823365]\n",
      "epoch:14 step:11289 [D loss: 0.670547, acc.: 57.03%] [G loss: 0.765182]\n",
      "epoch:14 step:11290 [D loss: 0.632788, acc.: 69.53%] [G loss: 0.825083]\n",
      "epoch:14 step:11291 [D loss: 0.692521, acc.: 57.81%] [G loss: 0.768731]\n",
      "epoch:14 step:11292 [D loss: 0.598718, acc.: 75.00%] [G loss: 0.823026]\n",
      "epoch:14 step:11293 [D loss: 0.692804, acc.: 54.69%] [G loss: 0.664341]\n",
      "epoch:14 step:11294 [D loss: 0.621485, acc.: 71.09%] [G loss: 0.659665]\n",
      "epoch:14 step:11295 [D loss: 0.700385, acc.: 50.00%] [G loss: 0.662866]\n",
      "epoch:14 step:11296 [D loss: 0.707599, acc.: 43.75%] [G loss: 0.616725]\n",
      "epoch:14 step:11297 [D loss: 0.692686, acc.: 51.56%] [G loss: 0.626877]\n",
      "epoch:14 step:11298 [D loss: 0.667167, acc.: 62.50%] [G loss: 0.536007]\n",
      "epoch:14 step:11299 [D loss: 0.703304, acc.: 53.91%] [G loss: 0.619027]\n",
      "epoch:14 step:11300 [D loss: 0.700460, acc.: 46.88%] [G loss: 0.608881]\n",
      "epoch:14 step:11301 [D loss: 0.719235, acc.: 45.31%] [G loss: 0.669988]\n",
      "epoch:14 step:11302 [D loss: 0.685620, acc.: 51.56%] [G loss: 0.741295]\n",
      "epoch:14 step:11303 [D loss: 0.635095, acc.: 68.75%] [G loss: 0.773433]\n",
      "epoch:14 step:11304 [D loss: 0.749118, acc.: 43.75%] [G loss: 0.699871]\n",
      "epoch:14 step:11305 [D loss: 0.704889, acc.: 46.88%] [G loss: 0.732929]\n",
      "epoch:14 step:11306 [D loss: 0.730625, acc.: 47.66%] [G loss: 0.762297]\n",
      "epoch:14 step:11307 [D loss: 0.832550, acc.: 25.00%] [G loss: 0.777063]\n",
      "epoch:14 step:11308 [D loss: 0.682726, acc.: 53.12%] [G loss: 0.799668]\n",
      "epoch:14 step:11309 [D loss: 0.671405, acc.: 60.94%] [G loss: 0.860739]\n",
      "epoch:14 step:11310 [D loss: 0.676098, acc.: 55.47%] [G loss: 0.771847]\n",
      "epoch:14 step:11311 [D loss: 0.719103, acc.: 50.78%] [G loss: 0.772567]\n",
      "epoch:14 step:11312 [D loss: 0.744163, acc.: 42.19%] [G loss: 0.732503]\n",
      "epoch:14 step:11313 [D loss: 0.688623, acc.: 53.91%] [G loss: 0.740278]\n",
      "epoch:14 step:11314 [D loss: 0.719691, acc.: 40.62%] [G loss: 0.790384]\n",
      "epoch:14 step:11315 [D loss: 0.664803, acc.: 64.06%] [G loss: 0.716518]\n",
      "epoch:14 step:11316 [D loss: 0.711088, acc.: 46.09%] [G loss: 0.759147]\n",
      "epoch:14 step:11317 [D loss: 0.679964, acc.: 53.12%] [G loss: 0.775789]\n",
      "epoch:14 step:11318 [D loss: 0.640844, acc.: 65.62%] [G loss: 0.783173]\n",
      "epoch:14 step:11319 [D loss: 0.679202, acc.: 54.69%] [G loss: 0.758706]\n",
      "epoch:14 step:11320 [D loss: 0.675013, acc.: 56.25%] [G loss: 0.720996]\n",
      "epoch:14 step:11321 [D loss: 0.670455, acc.: 60.16%] [G loss: 0.731772]\n",
      "epoch:14 step:11322 [D loss: 0.763139, acc.: 38.28%] [G loss: 0.702298]\n",
      "epoch:14 step:11323 [D loss: 0.727448, acc.: 45.31%] [G loss: 0.783283]\n",
      "epoch:14 step:11324 [D loss: 0.621990, acc.: 67.19%] [G loss: 0.826832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11325 [D loss: 0.780351, acc.: 35.94%] [G loss: 0.712078]\n",
      "epoch:14 step:11326 [D loss: 0.689896, acc.: 53.91%] [G loss: 0.758891]\n",
      "epoch:14 step:11327 [D loss: 0.634428, acc.: 70.31%] [G loss: 0.750615]\n",
      "epoch:14 step:11328 [D loss: 0.711938, acc.: 47.66%] [G loss: 0.698034]\n",
      "epoch:14 step:11329 [D loss: 0.665500, acc.: 60.16%] [G loss: 0.787975]\n",
      "epoch:14 step:11330 [D loss: 0.672094, acc.: 62.50%] [G loss: 0.729100]\n",
      "epoch:14 step:11331 [D loss: 0.648363, acc.: 64.84%] [G loss: 0.817972]\n",
      "epoch:14 step:11332 [D loss: 0.739477, acc.: 39.06%] [G loss: 0.739615]\n",
      "epoch:14 step:11333 [D loss: 0.666636, acc.: 59.38%] [G loss: 0.832871]\n",
      "epoch:14 step:11334 [D loss: 0.691507, acc.: 51.56%] [G loss: 0.683370]\n",
      "epoch:14 step:11335 [D loss: 0.651551, acc.: 61.72%] [G loss: 0.776763]\n",
      "epoch:14 step:11336 [D loss: 0.738879, acc.: 46.09%] [G loss: 0.678586]\n",
      "epoch:14 step:11337 [D loss: 0.644874, acc.: 62.50%] [G loss: 0.737481]\n",
      "epoch:14 step:11338 [D loss: 0.668343, acc.: 53.91%] [G loss: 0.759196]\n",
      "epoch:14 step:11339 [D loss: 0.657650, acc.: 60.94%] [G loss: 0.796258]\n",
      "epoch:14 step:11340 [D loss: 0.668778, acc.: 56.25%] [G loss: 0.782463]\n",
      "epoch:14 step:11341 [D loss: 0.714997, acc.: 52.34%] [G loss: 0.746435]\n",
      "epoch:14 step:11342 [D loss: 0.656019, acc.: 61.72%] [G loss: 0.757772]\n",
      "epoch:14 step:11343 [D loss: 0.701000, acc.: 52.34%] [G loss: 0.821355]\n",
      "epoch:14 step:11344 [D loss: 0.664200, acc.: 61.72%] [G loss: 0.881171]\n",
      "epoch:14 step:11345 [D loss: 0.699142, acc.: 60.94%] [G loss: 0.861306]\n",
      "epoch:14 step:11346 [D loss: 0.702919, acc.: 50.00%] [G loss: 0.798580]\n",
      "epoch:14 step:11347 [D loss: 0.670515, acc.: 61.72%] [G loss: 0.773226]\n",
      "epoch:14 step:11348 [D loss: 0.672223, acc.: 57.81%] [G loss: 0.860482]\n",
      "epoch:14 step:11349 [D loss: 0.604485, acc.: 77.34%] [G loss: 0.821372]\n",
      "epoch:14 step:11350 [D loss: 0.653097, acc.: 64.06%] [G loss: 0.804833]\n",
      "epoch:14 step:11351 [D loss: 0.697906, acc.: 50.00%] [G loss: 0.673108]\n",
      "epoch:14 step:11352 [D loss: 0.632557, acc.: 71.09%] [G loss: 0.755020]\n",
      "epoch:14 step:11353 [D loss: 0.692336, acc.: 53.91%] [G loss: 0.718068]\n",
      "epoch:14 step:11354 [D loss: 0.693998, acc.: 53.91%] [G loss: 0.689221]\n",
      "epoch:14 step:11355 [D loss: 0.725659, acc.: 44.53%] [G loss: 0.616227]\n",
      "epoch:14 step:11356 [D loss: 0.623633, acc.: 71.09%] [G loss: 0.694705]\n",
      "epoch:14 step:11357 [D loss: 0.680085, acc.: 56.25%] [G loss: 0.675792]\n",
      "epoch:14 step:11358 [D loss: 0.696765, acc.: 50.78%] [G loss: 0.666200]\n",
      "epoch:14 step:11359 [D loss: 0.760232, acc.: 45.31%] [G loss: 0.666016]\n",
      "epoch:14 step:11360 [D loss: 0.762837, acc.: 37.50%] [G loss: 0.617309]\n",
      "epoch:14 step:11361 [D loss: 0.756858, acc.: 39.06%] [G loss: 0.677087]\n",
      "epoch:14 step:11362 [D loss: 0.799416, acc.: 23.44%] [G loss: 0.661245]\n",
      "epoch:14 step:11363 [D loss: 0.715655, acc.: 48.44%] [G loss: 0.739492]\n",
      "epoch:14 step:11364 [D loss: 0.691998, acc.: 53.12%] [G loss: 0.686692]\n",
      "epoch:14 step:11365 [D loss: 0.717008, acc.: 50.00%] [G loss: 0.731719]\n",
      "epoch:14 step:11366 [D loss: 0.671599, acc.: 55.47%] [G loss: 0.756128]\n",
      "epoch:14 step:11367 [D loss: 0.744785, acc.: 38.28%] [G loss: 0.791526]\n",
      "epoch:14 step:11368 [D loss: 0.747390, acc.: 41.41%] [G loss: 0.705144]\n",
      "epoch:14 step:11369 [D loss: 0.714887, acc.: 50.78%] [G loss: 0.776340]\n",
      "epoch:14 step:11370 [D loss: 0.758229, acc.: 38.28%] [G loss: 0.859470]\n",
      "epoch:14 step:11371 [D loss: 0.729392, acc.: 49.22%] [G loss: 0.772786]\n",
      "epoch:14 step:11372 [D loss: 0.697737, acc.: 57.81%] [G loss: 0.809411]\n",
      "epoch:14 step:11373 [D loss: 0.719970, acc.: 50.78%] [G loss: 0.826591]\n",
      "epoch:14 step:11374 [D loss: 0.688175, acc.: 57.03%] [G loss: 0.813007]\n",
      "epoch:14 step:11375 [D loss: 0.706692, acc.: 48.44%] [G loss: 0.821616]\n",
      "epoch:14 step:11376 [D loss: 0.637777, acc.: 67.19%] [G loss: 0.826091]\n",
      "epoch:14 step:11377 [D loss: 0.620590, acc.: 68.75%] [G loss: 0.825590]\n",
      "epoch:14 step:11378 [D loss: 0.733651, acc.: 46.09%] [G loss: 0.743425]\n",
      "epoch:14 step:11379 [D loss: 0.657823, acc.: 59.38%] [G loss: 0.806249]\n",
      "epoch:14 step:11380 [D loss: 0.720913, acc.: 52.34%] [G loss: 0.674217]\n",
      "epoch:14 step:11381 [D loss: 0.643069, acc.: 67.19%] [G loss: 0.757962]\n",
      "epoch:14 step:11382 [D loss: 0.682343, acc.: 53.12%] [G loss: 0.765489]\n",
      "epoch:14 step:11383 [D loss: 0.702329, acc.: 47.66%] [G loss: 0.678416]\n",
      "epoch:14 step:11384 [D loss: 0.704265, acc.: 44.53%] [G loss: 0.727040]\n",
      "epoch:14 step:11385 [D loss: 0.711162, acc.: 51.56%] [G loss: 0.707297]\n",
      "epoch:14 step:11386 [D loss: 0.733590, acc.: 40.62%] [G loss: 0.764930]\n",
      "epoch:14 step:11387 [D loss: 0.818303, acc.: 25.00%] [G loss: 0.664802]\n",
      "epoch:14 step:11388 [D loss: 0.716264, acc.: 44.53%] [G loss: 0.773664]\n",
      "epoch:14 step:11389 [D loss: 0.696331, acc.: 48.44%] [G loss: 0.738395]\n",
      "epoch:14 step:11390 [D loss: 0.788638, acc.: 34.38%] [G loss: 0.673682]\n",
      "epoch:14 step:11391 [D loss: 0.720002, acc.: 41.41%] [G loss: 0.698696]\n",
      "epoch:14 step:11392 [D loss: 0.749140, acc.: 40.62%] [G loss: 0.868068]\n",
      "epoch:14 step:11393 [D loss: 0.769769, acc.: 35.94%] [G loss: 0.745558]\n",
      "epoch:14 step:11394 [D loss: 0.777890, acc.: 32.03%] [G loss: 0.770604]\n",
      "epoch:14 step:11395 [D loss: 0.682021, acc.: 52.34%] [G loss: 0.944775]\n",
      "epoch:14 step:11396 [D loss: 0.724089, acc.: 46.09%] [G loss: 0.860195]\n",
      "epoch:14 step:11397 [D loss: 0.748365, acc.: 46.88%] [G loss: 0.787787]\n",
      "epoch:14 step:11398 [D loss: 0.709998, acc.: 51.56%] [G loss: 0.807025]\n",
      "epoch:14 step:11399 [D loss: 0.666828, acc.: 60.16%] [G loss: 0.890520]\n",
      "epoch:14 step:11400 [D loss: 0.643885, acc.: 60.16%] [G loss: 0.839154]\n",
      "epoch:14 step:11401 [D loss: 0.701621, acc.: 50.00%] [G loss: 0.900780]\n",
      "epoch:14 step:11402 [D loss: 0.686673, acc.: 55.47%] [G loss: 0.871338]\n",
      "epoch:14 step:11403 [D loss: 0.684000, acc.: 55.47%] [G loss: 0.783178]\n",
      "epoch:14 step:11404 [D loss: 0.706178, acc.: 50.00%] [G loss: 0.811765]\n",
      "epoch:14 step:11405 [D loss: 0.669603, acc.: 57.81%] [G loss: 0.751351]\n",
      "epoch:14 step:11406 [D loss: 0.679097, acc.: 59.38%] [G loss: 0.694005]\n",
      "epoch:14 step:11407 [D loss: 0.729841, acc.: 54.69%] [G loss: 0.725039]\n",
      "epoch:14 step:11408 [D loss: 0.680291, acc.: 57.81%] [G loss: 0.754063]\n",
      "epoch:14 step:11409 [D loss: 0.693249, acc.: 56.25%] [G loss: 0.746884]\n",
      "epoch:14 step:11410 [D loss: 0.646582, acc.: 65.62%] [G loss: 0.723885]\n",
      "epoch:14 step:11411 [D loss: 0.680078, acc.: 54.69%] [G loss: 0.812076]\n",
      "epoch:14 step:11412 [D loss: 0.686601, acc.: 55.47%] [G loss: 0.776645]\n",
      "epoch:14 step:11413 [D loss: 0.663972, acc.: 66.41%] [G loss: 0.815492]\n",
      "epoch:14 step:11414 [D loss: 0.709497, acc.: 51.56%] [G loss: 0.786994]\n",
      "epoch:14 step:11415 [D loss: 0.679822, acc.: 58.59%] [G loss: 0.751599]\n",
      "epoch:14 step:11416 [D loss: 0.689438, acc.: 54.69%] [G loss: 0.774344]\n",
      "epoch:14 step:11417 [D loss: 0.700721, acc.: 57.81%] [G loss: 0.739793]\n",
      "epoch:14 step:11418 [D loss: 0.677161, acc.: 58.59%] [G loss: 0.712678]\n",
      "epoch:14 step:11419 [D loss: 0.676966, acc.: 64.06%] [G loss: 0.758202]\n",
      "epoch:14 step:11420 [D loss: 0.710886, acc.: 46.88%] [G loss: 0.725084]\n",
      "epoch:14 step:11421 [D loss: 0.741723, acc.: 42.97%] [G loss: 0.718264]\n",
      "epoch:14 step:11422 [D loss: 0.688574, acc.: 52.34%] [G loss: 0.763556]\n",
      "epoch:14 step:11423 [D loss: 0.691232, acc.: 53.12%] [G loss: 0.780548]\n",
      "epoch:14 step:11424 [D loss: 0.727887, acc.: 42.19%] [G loss: 0.724386]\n",
      "epoch:14 step:11425 [D loss: 0.732028, acc.: 43.75%] [G loss: 0.699442]\n",
      "epoch:14 step:11426 [D loss: 0.780538, acc.: 28.91%] [G loss: 0.730216]\n",
      "epoch:14 step:11427 [D loss: 0.669842, acc.: 58.59%] [G loss: 0.843068]\n",
      "epoch:14 step:11428 [D loss: 0.662097, acc.: 64.06%] [G loss: 0.724778]\n",
      "epoch:14 step:11429 [D loss: 0.725295, acc.: 47.66%] [G loss: 0.771852]\n",
      "epoch:14 step:11430 [D loss: 0.673096, acc.: 60.16%] [G loss: 0.759356]\n",
      "epoch:14 step:11431 [D loss: 0.703281, acc.: 54.69%] [G loss: 0.754508]\n",
      "epoch:14 step:11432 [D loss: 0.739116, acc.: 42.19%] [G loss: 0.749699]\n",
      "epoch:14 step:11433 [D loss: 0.722644, acc.: 46.88%] [G loss: 0.648889]\n",
      "epoch:14 step:11434 [D loss: 0.683957, acc.: 50.00%] [G loss: 0.685677]\n",
      "epoch:14 step:11435 [D loss: 0.714731, acc.: 51.56%] [G loss: 0.821496]\n",
      "epoch:14 step:11436 [D loss: 0.729470, acc.: 46.09%] [G loss: 0.782913]\n",
      "epoch:14 step:11437 [D loss: 0.672277, acc.: 58.59%] [G loss: 0.787856]\n",
      "epoch:14 step:11438 [D loss: 0.664964, acc.: 58.59%] [G loss: 0.793361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11439 [D loss: 0.682987, acc.: 58.59%] [G loss: 0.734244]\n",
      "epoch:14 step:11440 [D loss: 0.701533, acc.: 52.34%] [G loss: 0.786186]\n",
      "epoch:14 step:11441 [D loss: 0.670472, acc.: 54.69%] [G loss: 0.763038]\n",
      "epoch:14 step:11442 [D loss: 0.678455, acc.: 59.38%] [G loss: 0.717648]\n",
      "epoch:14 step:11443 [D loss: 0.697888, acc.: 46.09%] [G loss: 0.728409]\n",
      "epoch:14 step:11444 [D loss: 0.641277, acc.: 69.53%] [G loss: 0.760248]\n",
      "epoch:14 step:11445 [D loss: 0.681482, acc.: 53.91%] [G loss: 0.784748]\n",
      "epoch:14 step:11446 [D loss: 0.722127, acc.: 52.34%] [G loss: 0.708069]\n",
      "epoch:14 step:11447 [D loss: 0.695612, acc.: 46.88%] [G loss: 0.812114]\n",
      "epoch:14 step:11448 [D loss: 0.697926, acc.: 50.00%] [G loss: 0.751305]\n",
      "epoch:14 step:11449 [D loss: 0.696881, acc.: 52.34%] [G loss: 0.820865]\n",
      "epoch:14 step:11450 [D loss: 0.665077, acc.: 60.94%] [G loss: 0.708341]\n",
      "epoch:14 step:11451 [D loss: 0.724174, acc.: 48.44%] [G loss: 0.719419]\n",
      "epoch:14 step:11452 [D loss: 0.708033, acc.: 46.09%] [G loss: 0.709522]\n",
      "epoch:14 step:11453 [D loss: 0.699103, acc.: 52.34%] [G loss: 0.804288]\n",
      "epoch:14 step:11454 [D loss: 0.717571, acc.: 49.22%] [G loss: 0.789066]\n",
      "epoch:14 step:11455 [D loss: 0.670210, acc.: 60.16%] [G loss: 0.729917]\n",
      "epoch:14 step:11456 [D loss: 0.670977, acc.: 57.81%] [G loss: 0.789157]\n",
      "epoch:14 step:11457 [D loss: 0.709698, acc.: 50.78%] [G loss: 0.832033]\n",
      "epoch:14 step:11458 [D loss: 0.678606, acc.: 53.91%] [G loss: 0.955721]\n",
      "epoch:14 step:11459 [D loss: 0.703434, acc.: 51.56%] [G loss: 0.736871]\n",
      "epoch:14 step:11460 [D loss: 0.798511, acc.: 33.59%] [G loss: 0.769547]\n",
      "epoch:14 step:11461 [D loss: 0.692550, acc.: 51.56%] [G loss: 0.742280]\n",
      "epoch:14 step:11462 [D loss: 0.702411, acc.: 52.34%] [G loss: 0.699872]\n",
      "epoch:14 step:11463 [D loss: 0.693219, acc.: 53.91%] [G loss: 0.714058]\n",
      "epoch:14 step:11464 [D loss: 0.689625, acc.: 50.00%] [G loss: 0.724970]\n",
      "epoch:14 step:11465 [D loss: 0.704974, acc.: 51.56%] [G loss: 0.756123]\n",
      "epoch:14 step:11466 [D loss: 0.713919, acc.: 51.56%] [G loss: 0.790539]\n",
      "epoch:14 step:11467 [D loss: 0.701126, acc.: 53.12%] [G loss: 0.787844]\n",
      "epoch:14 step:11468 [D loss: 0.671242, acc.: 60.94%] [G loss: 0.770658]\n",
      "epoch:14 step:11469 [D loss: 0.711768, acc.: 49.22%] [G loss: 0.752867]\n",
      "epoch:14 step:11470 [D loss: 0.702556, acc.: 52.34%] [G loss: 0.796343]\n",
      "epoch:14 step:11471 [D loss: 0.720837, acc.: 42.97%] [G loss: 0.799794]\n",
      "epoch:14 step:11472 [D loss: 0.673991, acc.: 60.94%] [G loss: 0.792313]\n",
      "epoch:14 step:11473 [D loss: 0.718537, acc.: 43.75%] [G loss: 0.708799]\n",
      "epoch:14 step:11474 [D loss: 0.736081, acc.: 39.06%] [G loss: 0.641060]\n",
      "epoch:14 step:11475 [D loss: 0.703245, acc.: 49.22%] [G loss: 0.722743]\n",
      "epoch:14 step:11476 [D loss: 0.674501, acc.: 64.84%] [G loss: 0.751901]\n",
      "epoch:14 step:11477 [D loss: 0.700148, acc.: 48.44%] [G loss: 0.752673]\n",
      "epoch:14 step:11478 [D loss: 0.714761, acc.: 49.22%] [G loss: 0.742563]\n",
      "epoch:14 step:11479 [D loss: 0.675069, acc.: 53.91%] [G loss: 0.737322]\n",
      "epoch:14 step:11480 [D loss: 0.770021, acc.: 36.72%] [G loss: 0.703437]\n",
      "epoch:14 step:11481 [D loss: 0.720161, acc.: 42.97%] [G loss: 0.737360]\n",
      "epoch:14 step:11482 [D loss: 0.707250, acc.: 46.88%] [G loss: 0.782043]\n",
      "epoch:14 step:11483 [D loss: 0.762330, acc.: 35.94%] [G loss: 0.729063]\n",
      "epoch:14 step:11484 [D loss: 0.719098, acc.: 47.66%] [G loss: 0.797135]\n",
      "epoch:14 step:11485 [D loss: 0.710577, acc.: 51.56%] [G loss: 0.787266]\n",
      "epoch:14 step:11486 [D loss: 0.737828, acc.: 40.62%] [G loss: 0.757609]\n",
      "epoch:14 step:11487 [D loss: 0.682249, acc.: 61.72%] [G loss: 0.768464]\n",
      "epoch:14 step:11488 [D loss: 0.685197, acc.: 50.78%] [G loss: 0.915563]\n",
      "epoch:14 step:11489 [D loss: 0.705745, acc.: 52.34%] [G loss: 0.775564]\n",
      "epoch:14 step:11490 [D loss: 0.686018, acc.: 50.78%] [G loss: 0.768926]\n",
      "epoch:14 step:11491 [D loss: 0.706276, acc.: 48.44%] [G loss: 0.739209]\n",
      "epoch:14 step:11492 [D loss: 0.691777, acc.: 55.47%] [G loss: 0.742538]\n",
      "epoch:14 step:11493 [D loss: 0.681496, acc.: 59.38%] [G loss: 0.742705]\n",
      "epoch:14 step:11494 [D loss: 0.687653, acc.: 60.16%] [G loss: 0.789307]\n",
      "epoch:14 step:11495 [D loss: 0.712334, acc.: 46.09%] [G loss: 0.740722]\n",
      "epoch:14 step:11496 [D loss: 0.703758, acc.: 55.47%] [G loss: 0.818779]\n",
      "epoch:14 step:11497 [D loss: 0.690407, acc.: 54.69%] [G loss: 0.816023]\n",
      "epoch:14 step:11498 [D loss: 0.679915, acc.: 46.09%] [G loss: 0.809870]\n",
      "epoch:14 step:11499 [D loss: 0.668726, acc.: 61.72%] [G loss: 0.820193]\n",
      "epoch:14 step:11500 [D loss: 0.658519, acc.: 57.03%] [G loss: 0.841357]\n",
      "epoch:14 step:11501 [D loss: 0.685248, acc.: 54.69%] [G loss: 0.747029]\n",
      "epoch:14 step:11502 [D loss: 0.673266, acc.: 62.50%] [G loss: 0.839751]\n",
      "epoch:14 step:11503 [D loss: 0.689992, acc.: 56.25%] [G loss: 0.745228]\n",
      "epoch:14 step:11504 [D loss: 0.677707, acc.: 54.69%] [G loss: 0.830399]\n",
      "epoch:14 step:11505 [D loss: 0.718905, acc.: 46.88%] [G loss: 0.729346]\n",
      "epoch:14 step:11506 [D loss: 0.690768, acc.: 56.25%] [G loss: 0.782863]\n",
      "epoch:14 step:11507 [D loss: 0.697599, acc.: 52.34%] [G loss: 0.808648]\n",
      "epoch:14 step:11508 [D loss: 0.708453, acc.: 50.00%] [G loss: 0.734474]\n",
      "epoch:14 step:11509 [D loss: 0.704396, acc.: 50.78%] [G loss: 0.741924]\n",
      "epoch:14 step:11510 [D loss: 0.673280, acc.: 54.69%] [G loss: 0.765643]\n",
      "epoch:14 step:11511 [D loss: 0.692935, acc.: 46.09%] [G loss: 0.790763]\n",
      "epoch:14 step:11512 [D loss: 0.696165, acc.: 58.59%] [G loss: 0.763006]\n",
      "epoch:14 step:11513 [D loss: 0.667390, acc.: 59.38%] [G loss: 0.814824]\n",
      "epoch:14 step:11514 [D loss: 0.701149, acc.: 51.56%] [G loss: 0.743423]\n",
      "epoch:14 step:11515 [D loss: 0.754076, acc.: 34.38%] [G loss: 0.719530]\n",
      "epoch:14 step:11516 [D loss: 0.684017, acc.: 54.69%] [G loss: 0.740583]\n",
      "epoch:14 step:11517 [D loss: 0.712534, acc.: 46.88%] [G loss: 0.758792]\n",
      "epoch:14 step:11518 [D loss: 0.718238, acc.: 49.22%] [G loss: 0.768305]\n",
      "epoch:14 step:11519 [D loss: 0.726012, acc.: 38.28%] [G loss: 0.745166]\n",
      "epoch:14 step:11520 [D loss: 0.659843, acc.: 57.03%] [G loss: 0.752791]\n",
      "epoch:14 step:11521 [D loss: 0.680908, acc.: 53.91%] [G loss: 0.784085]\n",
      "epoch:14 step:11522 [D loss: 0.706107, acc.: 50.78%] [G loss: 0.804059]\n",
      "epoch:14 step:11523 [D loss: 0.729473, acc.: 50.78%] [G loss: 0.734556]\n",
      "epoch:14 step:11524 [D loss: 0.684795, acc.: 60.16%] [G loss: 0.792031]\n",
      "epoch:14 step:11525 [D loss: 0.708172, acc.: 51.56%] [G loss: 0.760793]\n",
      "epoch:14 step:11526 [D loss: 0.741671, acc.: 46.09%] [G loss: 0.831652]\n",
      "epoch:14 step:11527 [D loss: 0.706003, acc.: 48.44%] [G loss: 0.822107]\n",
      "epoch:14 step:11528 [D loss: 0.676893, acc.: 57.81%] [G loss: 0.795381]\n",
      "epoch:14 step:11529 [D loss: 0.647700, acc.: 66.41%] [G loss: 0.729311]\n",
      "epoch:14 step:11530 [D loss: 0.630608, acc.: 67.97%] [G loss: 0.852382]\n",
      "epoch:14 step:11531 [D loss: 0.676737, acc.: 55.47%] [G loss: 0.740368]\n",
      "epoch:14 step:11532 [D loss: 0.679649, acc.: 60.94%] [G loss: 0.775979]\n",
      "epoch:14 step:11533 [D loss: 0.700902, acc.: 46.09%] [G loss: 0.811012]\n",
      "epoch:14 step:11534 [D loss: 0.693307, acc.: 53.91%] [G loss: 0.752291]\n",
      "epoch:14 step:11535 [D loss: 0.685979, acc.: 50.00%] [G loss: 0.757228]\n",
      "epoch:14 step:11536 [D loss: 0.719206, acc.: 43.75%] [G loss: 0.758056]\n",
      "epoch:14 step:11537 [D loss: 0.753262, acc.: 41.41%] [G loss: 0.740495]\n",
      "epoch:14 step:11538 [D loss: 0.739120, acc.: 42.19%] [G loss: 0.794225]\n",
      "epoch:14 step:11539 [D loss: 0.684372, acc.: 57.03%] [G loss: 0.745602]\n",
      "epoch:14 step:11540 [D loss: 0.730833, acc.: 46.09%] [G loss: 0.748240]\n",
      "epoch:14 step:11541 [D loss: 0.692064, acc.: 53.12%] [G loss: 0.791534]\n",
      "epoch:14 step:11542 [D loss: 0.679627, acc.: 57.03%] [G loss: 0.853242]\n",
      "epoch:14 step:11543 [D loss: 0.763273, acc.: 38.28%] [G loss: 0.764804]\n",
      "epoch:14 step:11544 [D loss: 0.673156, acc.: 54.69%] [G loss: 0.752325]\n",
      "epoch:14 step:11545 [D loss: 0.692162, acc.: 54.69%] [G loss: 0.717354]\n",
      "epoch:14 step:11546 [D loss: 0.685494, acc.: 50.78%] [G loss: 0.744666]\n",
      "epoch:14 step:11547 [D loss: 0.732526, acc.: 46.09%] [G loss: 0.692338]\n",
      "epoch:14 step:11548 [D loss: 0.712829, acc.: 55.47%] [G loss: 0.755394]\n",
      "epoch:14 step:11549 [D loss: 0.705479, acc.: 42.97%] [G loss: 0.753128]\n",
      "epoch:14 step:11550 [D loss: 0.682380, acc.: 60.16%] [G loss: 0.807952]\n",
      "epoch:14 step:11551 [D loss: 0.715417, acc.: 42.19%] [G loss: 0.748068]\n",
      "epoch:14 step:11552 [D loss: 0.676036, acc.: 53.91%] [G loss: 0.754136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11553 [D loss: 0.690899, acc.: 52.34%] [G loss: 0.820889]\n",
      "epoch:14 step:11554 [D loss: 0.704066, acc.: 54.69%] [G loss: 0.732586]\n",
      "epoch:14 step:11555 [D loss: 0.715347, acc.: 46.88%] [G loss: 0.804167]\n",
      "epoch:14 step:11556 [D loss: 0.684803, acc.: 55.47%] [G loss: 0.786053]\n",
      "epoch:14 step:11557 [D loss: 0.698068, acc.: 52.34%] [G loss: 0.802074]\n",
      "epoch:14 step:11558 [D loss: 0.643928, acc.: 67.19%] [G loss: 0.873218]\n",
      "epoch:14 step:11559 [D loss: 0.685498, acc.: 53.12%] [G loss: 0.756501]\n",
      "epoch:14 step:11560 [D loss: 0.713404, acc.: 48.44%] [G loss: 0.792614]\n",
      "epoch:14 step:11561 [D loss: 0.676065, acc.: 57.03%] [G loss: 0.771225]\n",
      "epoch:14 step:11562 [D loss: 0.669684, acc.: 61.72%] [G loss: 0.826467]\n",
      "epoch:14 step:11563 [D loss: 0.722785, acc.: 46.09%] [G loss: 0.745745]\n",
      "epoch:14 step:11564 [D loss: 0.652582, acc.: 59.38%] [G loss: 0.798309]\n",
      "epoch:14 step:11565 [D loss: 0.724660, acc.: 45.31%] [G loss: 0.748001]\n",
      "epoch:14 step:11566 [D loss: 0.666557, acc.: 61.72%] [G loss: 0.788106]\n",
      "epoch:14 step:11567 [D loss: 0.671515, acc.: 60.16%] [G loss: 0.687043]\n",
      "epoch:14 step:11568 [D loss: 0.757769, acc.: 33.59%] [G loss: 0.608195]\n",
      "epoch:14 step:11569 [D loss: 0.646068, acc.: 64.06%] [G loss: 0.674363]\n",
      "epoch:14 step:11570 [D loss: 0.722475, acc.: 45.31%] [G loss: 0.690673]\n",
      "epoch:14 step:11571 [D loss: 0.693527, acc.: 54.69%] [G loss: 0.702661]\n",
      "epoch:14 step:11572 [D loss: 0.685491, acc.: 56.25%] [G loss: 0.749860]\n",
      "epoch:14 step:11573 [D loss: 0.685980, acc.: 54.69%] [G loss: 0.722909]\n",
      "epoch:14 step:11574 [D loss: 0.660701, acc.: 67.97%] [G loss: 0.756035]\n",
      "epoch:14 step:11575 [D loss: 0.754197, acc.: 42.19%] [G loss: 0.680076]\n",
      "epoch:14 step:11576 [D loss: 0.716536, acc.: 45.31%] [G loss: 0.683397]\n",
      "epoch:14 step:11577 [D loss: 0.714745, acc.: 42.19%] [G loss: 0.792503]\n",
      "epoch:14 step:11578 [D loss: 0.730415, acc.: 42.19%] [G loss: 0.725643]\n",
      "epoch:14 step:11579 [D loss: 0.631804, acc.: 70.31%] [G loss: 0.724442]\n",
      "epoch:14 step:11580 [D loss: 0.773386, acc.: 31.25%] [G loss: 0.752331]\n",
      "epoch:14 step:11581 [D loss: 0.762078, acc.: 43.75%] [G loss: 0.695013]\n",
      "epoch:14 step:11582 [D loss: 0.702102, acc.: 50.00%] [G loss: 0.758008]\n",
      "epoch:14 step:11583 [D loss: 0.720597, acc.: 48.44%] [G loss: 0.722908]\n",
      "epoch:14 step:11584 [D loss: 0.707005, acc.: 52.34%] [G loss: 0.767006]\n",
      "epoch:14 step:11585 [D loss: 0.685372, acc.: 55.47%] [G loss: 0.748356]\n",
      "epoch:14 step:11586 [D loss: 0.662537, acc.: 62.50%] [G loss: 0.685336]\n",
      "epoch:14 step:11587 [D loss: 0.669012, acc.: 57.03%] [G loss: 0.760388]\n",
      "epoch:14 step:11588 [D loss: 0.685615, acc.: 51.56%] [G loss: 0.681504]\n",
      "epoch:14 step:11589 [D loss: 0.661827, acc.: 65.62%] [G loss: 0.756219]\n",
      "epoch:14 step:11590 [D loss: 0.726544, acc.: 45.31%] [G loss: 0.669616]\n",
      "epoch:14 step:11591 [D loss: 0.659975, acc.: 60.94%] [G loss: 0.670938]\n",
      "epoch:14 step:11592 [D loss: 0.689772, acc.: 53.91%] [G loss: 0.665796]\n",
      "epoch:14 step:11593 [D loss: 0.704592, acc.: 51.56%] [G loss: 0.710738]\n",
      "epoch:14 step:11594 [D loss: 0.687883, acc.: 53.12%] [G loss: 0.727216]\n",
      "epoch:14 step:11595 [D loss: 0.671070, acc.: 61.72%] [G loss: 0.745973]\n",
      "epoch:14 step:11596 [D loss: 0.652086, acc.: 63.28%] [G loss: 0.727686]\n",
      "epoch:14 step:11597 [D loss: 0.647494, acc.: 62.50%] [G loss: 0.701456]\n",
      "epoch:14 step:11598 [D loss: 0.727768, acc.: 50.00%] [G loss: 0.742934]\n",
      "epoch:14 step:11599 [D loss: 0.714018, acc.: 50.78%] [G loss: 0.803803]\n",
      "epoch:14 step:11600 [D loss: 0.737404, acc.: 42.97%] [G loss: 0.800648]\n",
      "epoch:14 step:11601 [D loss: 0.738617, acc.: 42.19%] [G loss: 0.831299]\n",
      "epoch:14 step:11602 [D loss: 0.704568, acc.: 49.22%] [G loss: 0.859843]\n",
      "epoch:14 step:11603 [D loss: 0.771283, acc.: 43.75%] [G loss: 0.822457]\n",
      "epoch:14 step:11604 [D loss: 0.700956, acc.: 50.78%] [G loss: 0.878713]\n",
      "epoch:14 step:11605 [D loss: 0.765336, acc.: 45.31%] [G loss: 0.787877]\n",
      "epoch:14 step:11606 [D loss: 0.740415, acc.: 42.19%] [G loss: 0.831414]\n",
      "epoch:14 step:11607 [D loss: 0.625511, acc.: 73.44%] [G loss: 0.765774]\n",
      "epoch:14 step:11608 [D loss: 0.688975, acc.: 53.12%] [G loss: 0.739316]\n",
      "epoch:14 step:11609 [D loss: 0.667405, acc.: 63.28%] [G loss: 0.813837]\n",
      "epoch:14 step:11610 [D loss: 0.710161, acc.: 48.44%] [G loss: 0.794229]\n",
      "epoch:14 step:11611 [D loss: 0.671355, acc.: 60.94%] [G loss: 0.747764]\n",
      "epoch:14 step:11612 [D loss: 0.695848, acc.: 53.12%] [G loss: 0.773962]\n",
      "epoch:14 step:11613 [D loss: 0.663089, acc.: 59.38%] [G loss: 0.793838]\n",
      "epoch:14 step:11614 [D loss: 0.696996, acc.: 51.56%] [G loss: 0.707090]\n",
      "epoch:14 step:11615 [D loss: 0.636758, acc.: 68.75%] [G loss: 0.845981]\n",
      "epoch:14 step:11616 [D loss: 0.731846, acc.: 47.66%] [G loss: 0.768091]\n",
      "epoch:14 step:11617 [D loss: 0.701928, acc.: 48.44%] [G loss: 0.740612]\n",
      "epoch:14 step:11618 [D loss: 0.719285, acc.: 42.97%] [G loss: 0.727730]\n",
      "epoch:14 step:11619 [D loss: 0.700126, acc.: 51.56%] [G loss: 0.761232]\n",
      "epoch:14 step:11620 [D loss: 0.686468, acc.: 56.25%] [G loss: 0.737434]\n",
      "epoch:14 step:11621 [D loss: 0.646508, acc.: 64.06%] [G loss: 0.744479]\n",
      "epoch:14 step:11622 [D loss: 0.718828, acc.: 51.56%] [G loss: 0.785062]\n",
      "epoch:14 step:11623 [D loss: 0.680428, acc.: 57.81%] [G loss: 0.712941]\n",
      "epoch:14 step:11624 [D loss: 0.689709, acc.: 53.91%] [G loss: 0.748510]\n",
      "epoch:14 step:11625 [D loss: 0.699971, acc.: 52.34%] [G loss: 0.731796]\n",
      "epoch:14 step:11626 [D loss: 0.773453, acc.: 35.94%] [G loss: 0.758521]\n",
      "epoch:14 step:11627 [D loss: 0.682268, acc.: 56.25%] [G loss: 0.763371]\n",
      "epoch:14 step:11628 [D loss: 0.697275, acc.: 51.56%] [G loss: 0.753989]\n",
      "epoch:14 step:11629 [D loss: 0.632593, acc.: 75.78%] [G loss: 0.751462]\n",
      "epoch:14 step:11630 [D loss: 0.699919, acc.: 51.56%] [G loss: 0.781441]\n",
      "epoch:14 step:11631 [D loss: 0.724007, acc.: 43.75%] [G loss: 0.673776]\n",
      "epoch:14 step:11632 [D loss: 0.719870, acc.: 47.66%] [G loss: 0.732215]\n",
      "epoch:14 step:11633 [D loss: 0.735434, acc.: 36.72%] [G loss: 0.738825]\n",
      "epoch:14 step:11634 [D loss: 0.683461, acc.: 53.12%] [G loss: 0.699216]\n",
      "epoch:14 step:11635 [D loss: 0.674571, acc.: 62.50%] [G loss: 0.803577]\n",
      "epoch:14 step:11636 [D loss: 0.748185, acc.: 39.06%] [G loss: 0.774851]\n",
      "epoch:14 step:11637 [D loss: 0.684529, acc.: 51.56%] [G loss: 0.693447]\n",
      "epoch:14 step:11638 [D loss: 0.696109, acc.: 55.47%] [G loss: 0.750349]\n",
      "epoch:14 step:11639 [D loss: 0.736500, acc.: 41.41%] [G loss: 0.689233]\n",
      "epoch:14 step:11640 [D loss: 0.717940, acc.: 48.44%] [G loss: 0.771815]\n",
      "epoch:14 step:11641 [D loss: 0.685589, acc.: 54.69%] [G loss: 0.777757]\n",
      "epoch:14 step:11642 [D loss: 0.704520, acc.: 53.12%] [G loss: 0.823298]\n",
      "epoch:14 step:11643 [D loss: 0.727499, acc.: 50.00%] [G loss: 0.688597]\n",
      "epoch:14 step:11644 [D loss: 0.673878, acc.: 57.81%] [G loss: 0.701220]\n",
      "epoch:14 step:11645 [D loss: 0.716241, acc.: 47.66%] [G loss: 0.732669]\n",
      "epoch:14 step:11646 [D loss: 0.695478, acc.: 52.34%] [G loss: 0.751286]\n",
      "epoch:14 step:11647 [D loss: 0.646607, acc.: 58.59%] [G loss: 0.698729]\n",
      "epoch:14 step:11648 [D loss: 0.698427, acc.: 50.00%] [G loss: 0.722860]\n",
      "epoch:14 step:11649 [D loss: 0.678181, acc.: 57.81%] [G loss: 0.763355]\n",
      "epoch:14 step:11650 [D loss: 0.666221, acc.: 62.50%] [G loss: 0.781376]\n",
      "epoch:14 step:11651 [D loss: 0.616150, acc.: 75.78%] [G loss: 0.721136]\n",
      "epoch:14 step:11652 [D loss: 0.766616, acc.: 34.38%] [G loss: 0.670532]\n",
      "epoch:14 step:11653 [D loss: 0.786663, acc.: 38.28%] [G loss: 0.699922]\n",
      "epoch:14 step:11654 [D loss: 0.749304, acc.: 40.62%] [G loss: 0.772599]\n",
      "epoch:14 step:11655 [D loss: 0.736538, acc.: 44.53%] [G loss: 0.761938]\n",
      "epoch:14 step:11656 [D loss: 0.728290, acc.: 42.97%] [G loss: 0.719594]\n",
      "epoch:14 step:11657 [D loss: 0.813106, acc.: 26.56%] [G loss: 0.687755]\n",
      "epoch:14 step:11658 [D loss: 0.707702, acc.: 53.12%] [G loss: 0.790226]\n",
      "epoch:14 step:11659 [D loss: 0.722164, acc.: 42.19%] [G loss: 0.770735]\n",
      "epoch:14 step:11660 [D loss: 0.730292, acc.: 42.97%] [G loss: 0.731838]\n",
      "epoch:14 step:11661 [D loss: 0.660257, acc.: 61.72%] [G loss: 0.767945]\n",
      "epoch:14 step:11662 [D loss: 0.731237, acc.: 52.34%] [G loss: 0.759533]\n",
      "epoch:14 step:11663 [D loss: 0.695805, acc.: 53.91%] [G loss: 0.709749]\n",
      "epoch:14 step:11664 [D loss: 0.702712, acc.: 50.78%] [G loss: 0.779636]\n",
      "epoch:14 step:11665 [D loss: 0.664187, acc.: 56.25%] [G loss: 0.788819]\n",
      "epoch:14 step:11666 [D loss: 0.675556, acc.: 58.59%] [G loss: 0.756907]\n",
      "epoch:14 step:11667 [D loss: 0.643668, acc.: 67.19%] [G loss: 0.898253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11668 [D loss: 0.674971, acc.: 55.47%] [G loss: 0.765582]\n",
      "epoch:14 step:11669 [D loss: 0.719566, acc.: 39.84%] [G loss: 0.724430]\n",
      "epoch:14 step:11670 [D loss: 0.678130, acc.: 57.03%] [G loss: 0.828843]\n",
      "epoch:14 step:11671 [D loss: 0.688546, acc.: 51.56%] [G loss: 0.740168]\n",
      "epoch:14 step:11672 [D loss: 0.646737, acc.: 62.50%] [G loss: 0.722981]\n",
      "epoch:14 step:11673 [D loss: 0.699728, acc.: 50.78%] [G loss: 0.686510]\n",
      "epoch:14 step:11674 [D loss: 0.691053, acc.: 59.38%] [G loss: 0.715718]\n",
      "epoch:14 step:11675 [D loss: 0.674640, acc.: 59.38%] [G loss: 0.730061]\n",
      "epoch:14 step:11676 [D loss: 0.707427, acc.: 52.34%] [G loss: 0.740205]\n",
      "epoch:14 step:11677 [D loss: 0.739371, acc.: 46.09%] [G loss: 0.638391]\n",
      "epoch:14 step:11678 [D loss: 0.685283, acc.: 53.91%] [G loss: 0.712194]\n",
      "epoch:14 step:11679 [D loss: 0.696425, acc.: 50.00%] [G loss: 0.746220]\n",
      "epoch:14 step:11680 [D loss: 0.696239, acc.: 52.34%] [G loss: 0.775358]\n",
      "epoch:14 step:11681 [D loss: 0.711777, acc.: 52.34%] [G loss: 0.731841]\n",
      "epoch:14 step:11682 [D loss: 0.703748, acc.: 48.44%] [G loss: 0.787467]\n",
      "epoch:14 step:11683 [D loss: 0.672377, acc.: 59.38%] [G loss: 0.780378]\n",
      "epoch:14 step:11684 [D loss: 0.690359, acc.: 56.25%] [G loss: 0.743809]\n",
      "epoch:14 step:11685 [D loss: 0.681575, acc.: 61.72%] [G loss: 0.726193]\n",
      "epoch:14 step:11686 [D loss: 0.651936, acc.: 64.06%] [G loss: 0.811832]\n",
      "epoch:14 step:11687 [D loss: 0.656235, acc.: 63.28%] [G loss: 0.801391]\n",
      "epoch:14 step:11688 [D loss: 0.698597, acc.: 51.56%] [G loss: 0.833246]\n",
      "epoch:14 step:11689 [D loss: 0.661137, acc.: 64.06%] [G loss: 0.846426]\n",
      "epoch:14 step:11690 [D loss: 0.659213, acc.: 60.16%] [G loss: 0.794094]\n",
      "epoch:14 step:11691 [D loss: 0.711874, acc.: 45.31%] [G loss: 0.745110]\n",
      "epoch:14 step:11692 [D loss: 0.708884, acc.: 51.56%] [G loss: 0.727796]\n",
      "epoch:14 step:11693 [D loss: 0.671664, acc.: 57.03%] [G loss: 0.778879]\n",
      "epoch:14 step:11694 [D loss: 0.686684, acc.: 59.38%] [G loss: 0.748091]\n",
      "epoch:14 step:11695 [D loss: 0.688522, acc.: 53.12%] [G loss: 0.745383]\n",
      "epoch:14 step:11696 [D loss: 0.686931, acc.: 57.03%] [G loss: 0.748384]\n",
      "epoch:14 step:11697 [D loss: 0.696720, acc.: 53.91%] [G loss: 0.743631]\n",
      "epoch:14 step:11698 [D loss: 0.741815, acc.: 38.28%] [G loss: 0.719808]\n",
      "epoch:14 step:11699 [D loss: 0.680242, acc.: 55.47%] [G loss: 0.794803]\n",
      "epoch:14 step:11700 [D loss: 0.738788, acc.: 38.28%] [G loss: 0.739248]\n",
      "epoch:14 step:11701 [D loss: 0.708093, acc.: 53.91%] [G loss: 0.751633]\n",
      "epoch:14 step:11702 [D loss: 0.739049, acc.: 39.84%] [G loss: 0.741866]\n",
      "epoch:14 step:11703 [D loss: 0.720449, acc.: 49.22%] [G loss: 0.754382]\n",
      "epoch:14 step:11704 [D loss: 0.681578, acc.: 52.34%] [G loss: 0.818998]\n",
      "epoch:14 step:11705 [D loss: 0.708722, acc.: 50.78%] [G loss: 0.747532]\n",
      "epoch:14 step:11706 [D loss: 0.722207, acc.: 47.66%] [G loss: 0.723419]\n",
      "epoch:14 step:11707 [D loss: 0.670940, acc.: 57.81%] [G loss: 0.817349]\n",
      "epoch:14 step:11708 [D loss: 0.672180, acc.: 61.72%] [G loss: 0.739661]\n",
      "epoch:14 step:11709 [D loss: 0.739824, acc.: 38.28%] [G loss: 0.668994]\n",
      "epoch:14 step:11710 [D loss: 0.713470, acc.: 50.78%] [G loss: 0.778661]\n",
      "epoch:14 step:11711 [D loss: 0.706425, acc.: 42.97%] [G loss: 0.728158]\n",
      "epoch:14 step:11712 [D loss: 0.712291, acc.: 51.56%] [G loss: 0.744294]\n",
      "epoch:14 step:11713 [D loss: 0.710878, acc.: 53.12%] [G loss: 0.796094]\n",
      "epoch:14 step:11714 [D loss: 0.656286, acc.: 62.50%] [G loss: 0.791329]\n",
      "epoch:14 step:11715 [D loss: 0.660330, acc.: 59.38%] [G loss: 0.764609]\n",
      "epoch:15 step:11716 [D loss: 0.675061, acc.: 60.16%] [G loss: 0.739144]\n",
      "epoch:15 step:11717 [D loss: 0.722776, acc.: 47.66%] [G loss: 0.785423]\n",
      "epoch:15 step:11718 [D loss: 0.707801, acc.: 48.44%] [G loss: 0.764386]\n",
      "epoch:15 step:11719 [D loss: 0.668288, acc.: 57.81%] [G loss: 0.742414]\n",
      "epoch:15 step:11720 [D loss: 0.673261, acc.: 55.47%] [G loss: 0.767300]\n",
      "epoch:15 step:11721 [D loss: 0.698585, acc.: 53.91%] [G loss: 0.775986]\n",
      "epoch:15 step:11722 [D loss: 0.715084, acc.: 45.31%] [G loss: 0.912979]\n",
      "epoch:15 step:11723 [D loss: 0.687292, acc.: 57.03%] [G loss: 0.795892]\n",
      "epoch:15 step:11724 [D loss: 0.688385, acc.: 57.81%] [G loss: 0.841662]\n",
      "epoch:15 step:11725 [D loss: 0.668523, acc.: 62.50%] [G loss: 0.783354]\n",
      "epoch:15 step:11726 [D loss: 0.726253, acc.: 46.09%] [G loss: 0.746281]\n",
      "epoch:15 step:11727 [D loss: 0.721443, acc.: 46.09%] [G loss: 0.699168]\n",
      "epoch:15 step:11728 [D loss: 0.702816, acc.: 42.97%] [G loss: 0.732069]\n",
      "epoch:15 step:11729 [D loss: 0.750648, acc.: 41.41%] [G loss: 0.767968]\n",
      "epoch:15 step:11730 [D loss: 0.724914, acc.: 50.00%] [G loss: 0.818219]\n",
      "epoch:15 step:11731 [D loss: 0.714679, acc.: 46.88%] [G loss: 0.748401]\n",
      "epoch:15 step:11732 [D loss: 0.735607, acc.: 40.62%] [G loss: 0.743922]\n",
      "epoch:15 step:11733 [D loss: 0.718881, acc.: 50.78%] [G loss: 0.661908]\n",
      "epoch:15 step:11734 [D loss: 0.688976, acc.: 58.59%] [G loss: 0.752706]\n",
      "epoch:15 step:11735 [D loss: 0.668266, acc.: 57.03%] [G loss: 0.764674]\n",
      "epoch:15 step:11736 [D loss: 0.728289, acc.: 45.31%] [G loss: 0.705595]\n",
      "epoch:15 step:11737 [D loss: 0.727594, acc.: 45.31%] [G loss: 0.711623]\n",
      "epoch:15 step:11738 [D loss: 0.751669, acc.: 36.72%] [G loss: 0.734138]\n",
      "epoch:15 step:11739 [D loss: 0.701417, acc.: 50.78%] [G loss: 0.750049]\n",
      "epoch:15 step:11740 [D loss: 0.745893, acc.: 37.50%] [G loss: 0.755731]\n",
      "epoch:15 step:11741 [D loss: 0.710909, acc.: 43.75%] [G loss: 0.694686]\n",
      "epoch:15 step:11742 [D loss: 0.693193, acc.: 53.12%] [G loss: 0.755043]\n",
      "epoch:15 step:11743 [D loss: 0.728194, acc.: 43.75%] [G loss: 0.715277]\n",
      "epoch:15 step:11744 [D loss: 0.707292, acc.: 47.66%] [G loss: 0.693627]\n",
      "epoch:15 step:11745 [D loss: 0.706097, acc.: 49.22%] [G loss: 0.744900]\n",
      "epoch:15 step:11746 [D loss: 0.708068, acc.: 48.44%] [G loss: 0.735096]\n",
      "epoch:15 step:11747 [D loss: 0.701679, acc.: 50.00%] [G loss: 0.716771]\n",
      "epoch:15 step:11748 [D loss: 0.631621, acc.: 69.53%] [G loss: 0.784958]\n",
      "epoch:15 step:11749 [D loss: 0.674265, acc.: 61.72%] [G loss: 0.812937]\n",
      "epoch:15 step:11750 [D loss: 0.705048, acc.: 48.44%] [G loss: 0.791001]\n",
      "epoch:15 step:11751 [D loss: 0.695859, acc.: 53.91%] [G loss: 0.777186]\n",
      "epoch:15 step:11752 [D loss: 0.670337, acc.: 59.38%] [G loss: 0.817647]\n",
      "epoch:15 step:11753 [D loss: 0.732522, acc.: 45.31%] [G loss: 0.784595]\n",
      "epoch:15 step:11754 [D loss: 0.645019, acc.: 67.97%] [G loss: 0.746149]\n",
      "epoch:15 step:11755 [D loss: 0.685331, acc.: 55.47%] [G loss: 0.803216]\n",
      "epoch:15 step:11756 [D loss: 0.664487, acc.: 60.16%] [G loss: 0.770639]\n",
      "epoch:15 step:11757 [D loss: 0.677270, acc.: 60.94%] [G loss: 0.714844]\n",
      "epoch:15 step:11758 [D loss: 0.659484, acc.: 60.94%] [G loss: 0.797118]\n",
      "epoch:15 step:11759 [D loss: 0.693645, acc.: 53.91%] [G loss: 0.706994]\n",
      "epoch:15 step:11760 [D loss: 0.638980, acc.: 67.97%] [G loss: 0.713313]\n",
      "epoch:15 step:11761 [D loss: 0.663734, acc.: 60.16%] [G loss: 0.724315]\n",
      "epoch:15 step:11762 [D loss: 0.696031, acc.: 50.78%] [G loss: 0.759069]\n",
      "epoch:15 step:11763 [D loss: 0.639077, acc.: 63.28%] [G loss: 0.721207]\n",
      "epoch:15 step:11764 [D loss: 0.691634, acc.: 57.81%] [G loss: 0.770764]\n",
      "epoch:15 step:11765 [D loss: 0.680826, acc.: 53.91%] [G loss: 0.803149]\n",
      "epoch:15 step:11766 [D loss: 0.688100, acc.: 58.59%] [G loss: 0.748696]\n",
      "epoch:15 step:11767 [D loss: 0.638004, acc.: 68.75%] [G loss: 0.774307]\n",
      "epoch:15 step:11768 [D loss: 0.697736, acc.: 53.12%] [G loss: 0.756212]\n",
      "epoch:15 step:11769 [D loss: 0.724241, acc.: 48.44%] [G loss: 0.745554]\n",
      "epoch:15 step:11770 [D loss: 0.722380, acc.: 49.22%] [G loss: 0.738178]\n",
      "epoch:15 step:11771 [D loss: 0.648354, acc.: 63.28%] [G loss: 0.712497]\n",
      "epoch:15 step:11772 [D loss: 0.680392, acc.: 57.81%] [G loss: 0.777512]\n",
      "epoch:15 step:11773 [D loss: 0.733312, acc.: 45.31%] [G loss: 0.767841]\n",
      "epoch:15 step:11774 [D loss: 0.660350, acc.: 60.16%] [G loss: 0.789473]\n",
      "epoch:15 step:11775 [D loss: 0.669121, acc.: 58.59%] [G loss: 0.760656]\n",
      "epoch:15 step:11776 [D loss: 0.682074, acc.: 56.25%] [G loss: 0.814210]\n",
      "epoch:15 step:11777 [D loss: 0.671276, acc.: 60.16%] [G loss: 0.823821]\n",
      "epoch:15 step:11778 [D loss: 0.678289, acc.: 58.59%] [G loss: 0.831298]\n",
      "epoch:15 step:11779 [D loss: 0.678367, acc.: 60.94%] [G loss: 0.836617]\n",
      "epoch:15 step:11780 [D loss: 0.693150, acc.: 48.44%] [G loss: 0.884959]\n",
      "epoch:15 step:11781 [D loss: 0.691947, acc.: 50.78%] [G loss: 0.802004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11782 [D loss: 0.732733, acc.: 42.97%] [G loss: 0.774182]\n",
      "epoch:15 step:11783 [D loss: 0.691708, acc.: 55.47%] [G loss: 0.784043]\n",
      "epoch:15 step:11784 [D loss: 0.691523, acc.: 55.47%] [G loss: 0.806459]\n",
      "epoch:15 step:11785 [D loss: 0.673226, acc.: 60.94%] [G loss: 0.768172]\n",
      "epoch:15 step:11786 [D loss: 0.711621, acc.: 48.44%] [G loss: 0.683131]\n",
      "epoch:15 step:11787 [D loss: 0.757420, acc.: 43.75%] [G loss: 0.711880]\n",
      "epoch:15 step:11788 [D loss: 0.718054, acc.: 49.22%] [G loss: 0.761445]\n",
      "epoch:15 step:11789 [D loss: 0.671759, acc.: 56.25%] [G loss: 0.824067]\n",
      "epoch:15 step:11790 [D loss: 0.611560, acc.: 68.75%] [G loss: 0.902897]\n",
      "epoch:15 step:11791 [D loss: 0.734127, acc.: 47.66%] [G loss: 0.785500]\n",
      "epoch:15 step:11792 [D loss: 0.692535, acc.: 55.47%] [G loss: 0.796644]\n",
      "epoch:15 step:11793 [D loss: 0.677570, acc.: 59.38%] [G loss: 0.791611]\n",
      "epoch:15 step:11794 [D loss: 0.649501, acc.: 62.50%] [G loss: 0.848795]\n",
      "epoch:15 step:11795 [D loss: 0.704958, acc.: 46.09%] [G loss: 0.809702]\n",
      "epoch:15 step:11796 [D loss: 0.626886, acc.: 68.75%] [G loss: 0.839911]\n",
      "epoch:15 step:11797 [D loss: 0.694882, acc.: 53.12%] [G loss: 0.762827]\n",
      "epoch:15 step:11798 [D loss: 0.717758, acc.: 51.56%] [G loss: 0.821270]\n",
      "epoch:15 step:11799 [D loss: 0.676812, acc.: 48.44%] [G loss: 0.771303]\n",
      "epoch:15 step:11800 [D loss: 0.713923, acc.: 48.44%] [G loss: 0.769943]\n",
      "epoch:15 step:11801 [D loss: 0.665903, acc.: 60.16%] [G loss: 0.764596]\n",
      "epoch:15 step:11802 [D loss: 0.695150, acc.: 56.25%] [G loss: 0.771974]\n",
      "epoch:15 step:11803 [D loss: 0.705495, acc.: 50.78%] [G loss: 0.779606]\n",
      "epoch:15 step:11804 [D loss: 0.675380, acc.: 65.62%] [G loss: 0.763221]\n",
      "epoch:15 step:11805 [D loss: 0.703165, acc.: 46.09%] [G loss: 0.845515]\n",
      "epoch:15 step:11806 [D loss: 0.676900, acc.: 56.25%] [G loss: 0.733777]\n",
      "epoch:15 step:11807 [D loss: 0.729095, acc.: 42.19%] [G loss: 0.731822]\n",
      "epoch:15 step:11808 [D loss: 0.709844, acc.: 47.66%] [G loss: 0.667306]\n",
      "epoch:15 step:11809 [D loss: 0.705796, acc.: 51.56%] [G loss: 0.747939]\n",
      "epoch:15 step:11810 [D loss: 0.690020, acc.: 57.03%] [G loss: 0.836470]\n",
      "epoch:15 step:11811 [D loss: 0.693984, acc.: 54.69%] [G loss: 0.799650]\n",
      "epoch:15 step:11812 [D loss: 0.747189, acc.: 32.03%] [G loss: 0.712565]\n",
      "epoch:15 step:11813 [D loss: 0.709303, acc.: 45.31%] [G loss: 0.758387]\n",
      "epoch:15 step:11814 [D loss: 0.698672, acc.: 45.31%] [G loss: 0.819955]\n",
      "epoch:15 step:11815 [D loss: 0.712268, acc.: 49.22%] [G loss: 0.739556]\n",
      "epoch:15 step:11816 [D loss: 0.688869, acc.: 50.00%] [G loss: 0.777837]\n",
      "epoch:15 step:11817 [D loss: 0.699914, acc.: 52.34%] [G loss: 0.723586]\n",
      "epoch:15 step:11818 [D loss: 0.732318, acc.: 47.66%] [G loss: 0.780594]\n",
      "epoch:15 step:11819 [D loss: 0.701784, acc.: 50.78%] [G loss: 0.777431]\n",
      "epoch:15 step:11820 [D loss: 0.680560, acc.: 54.69%] [G loss: 0.781025]\n",
      "epoch:15 step:11821 [D loss: 0.653879, acc.: 61.72%] [G loss: 0.758202]\n",
      "epoch:15 step:11822 [D loss: 0.733773, acc.: 48.44%] [G loss: 0.734000]\n",
      "epoch:15 step:11823 [D loss: 0.764933, acc.: 39.84%] [G loss: 0.758545]\n",
      "epoch:15 step:11824 [D loss: 0.706912, acc.: 47.66%] [G loss: 0.645223]\n",
      "epoch:15 step:11825 [D loss: 0.710222, acc.: 47.66%] [G loss: 0.627779]\n",
      "epoch:15 step:11826 [D loss: 0.696070, acc.: 54.69%] [G loss: 0.738029]\n",
      "epoch:15 step:11827 [D loss: 0.693693, acc.: 56.25%] [G loss: 0.740382]\n",
      "epoch:15 step:11828 [D loss: 0.718891, acc.: 50.00%] [G loss: 0.740950]\n",
      "epoch:15 step:11829 [D loss: 0.695513, acc.: 57.03%] [G loss: 0.794928]\n",
      "epoch:15 step:11830 [D loss: 0.677246, acc.: 56.25%] [G loss: 0.751576]\n",
      "epoch:15 step:11831 [D loss: 0.690688, acc.: 55.47%] [G loss: 0.802284]\n",
      "epoch:15 step:11832 [D loss: 0.760671, acc.: 42.19%] [G loss: 0.796556]\n",
      "epoch:15 step:11833 [D loss: 0.742619, acc.: 40.62%] [G loss: 0.813230]\n",
      "epoch:15 step:11834 [D loss: 0.699326, acc.: 57.81%] [G loss: 0.723039]\n",
      "epoch:15 step:11835 [D loss: 0.714625, acc.: 50.78%] [G loss: 0.742196]\n",
      "epoch:15 step:11836 [D loss: 0.700218, acc.: 51.56%] [G loss: 0.782202]\n",
      "epoch:15 step:11837 [D loss: 0.687057, acc.: 57.81%] [G loss: 0.675308]\n",
      "epoch:15 step:11838 [D loss: 0.717933, acc.: 50.78%] [G loss: 0.748356]\n",
      "epoch:15 step:11839 [D loss: 0.669846, acc.: 59.38%] [G loss: 0.892516]\n",
      "epoch:15 step:11840 [D loss: 0.754342, acc.: 35.16%] [G loss: 0.823686]\n",
      "epoch:15 step:11841 [D loss: 0.705290, acc.: 52.34%] [G loss: 0.825788]\n",
      "epoch:15 step:11842 [D loss: 0.717032, acc.: 53.91%] [G loss: 0.791887]\n",
      "epoch:15 step:11843 [D loss: 0.679243, acc.: 54.69%] [G loss: 0.757788]\n",
      "epoch:15 step:11844 [D loss: 0.710970, acc.: 47.66%] [G loss: 0.725356]\n",
      "epoch:15 step:11845 [D loss: 0.734539, acc.: 36.72%] [G loss: 0.733986]\n",
      "epoch:15 step:11846 [D loss: 0.670589, acc.: 58.59%] [G loss: 0.788236]\n",
      "epoch:15 step:11847 [D loss: 0.741690, acc.: 43.75%] [G loss: 0.708296]\n",
      "epoch:15 step:11848 [D loss: 0.661422, acc.: 61.72%] [G loss: 0.697704]\n",
      "epoch:15 step:11849 [D loss: 0.680051, acc.: 58.59%] [G loss: 0.747288]\n",
      "epoch:15 step:11850 [D loss: 0.704199, acc.: 49.22%] [G loss: 0.691478]\n",
      "epoch:15 step:11851 [D loss: 0.714719, acc.: 46.88%] [G loss: 0.725810]\n",
      "epoch:15 step:11852 [D loss: 0.702943, acc.: 46.88%] [G loss: 0.747448]\n",
      "epoch:15 step:11853 [D loss: 0.681014, acc.: 55.47%] [G loss: 0.733014]\n",
      "epoch:15 step:11854 [D loss: 0.730334, acc.: 45.31%] [G loss: 0.645976]\n",
      "epoch:15 step:11855 [D loss: 0.713907, acc.: 43.75%] [G loss: 0.825602]\n",
      "epoch:15 step:11856 [D loss: 0.629196, acc.: 72.66%] [G loss: 0.756538]\n",
      "epoch:15 step:11857 [D loss: 0.714514, acc.: 43.75%] [G loss: 0.699454]\n",
      "epoch:15 step:11858 [D loss: 0.717320, acc.: 43.75%] [G loss: 0.672562]\n",
      "epoch:15 step:11859 [D loss: 0.707212, acc.: 52.34%] [G loss: 0.639728]\n",
      "epoch:15 step:11860 [D loss: 0.730441, acc.: 45.31%] [G loss: 0.768413]\n",
      "epoch:15 step:11861 [D loss: 0.731495, acc.: 42.97%] [G loss: 0.765140]\n",
      "epoch:15 step:11862 [D loss: 0.710016, acc.: 50.00%] [G loss: 0.773724]\n",
      "epoch:15 step:11863 [D loss: 0.746339, acc.: 40.62%] [G loss: 0.767136]\n",
      "epoch:15 step:11864 [D loss: 0.726624, acc.: 42.19%] [G loss: 0.739134]\n",
      "epoch:15 step:11865 [D loss: 0.736008, acc.: 48.44%] [G loss: 0.734035]\n",
      "epoch:15 step:11866 [D loss: 0.676975, acc.: 55.47%] [G loss: 0.778319]\n",
      "epoch:15 step:11867 [D loss: 0.715222, acc.: 42.19%] [G loss: 0.728490]\n",
      "epoch:15 step:11868 [D loss: 0.700964, acc.: 54.69%] [G loss: 0.738635]\n",
      "epoch:15 step:11869 [D loss: 0.688062, acc.: 47.66%] [G loss: 0.738811]\n",
      "epoch:15 step:11870 [D loss: 0.651343, acc.: 61.72%] [G loss: 0.749179]\n",
      "epoch:15 step:11871 [D loss: 0.698400, acc.: 49.22%] [G loss: 0.713408]\n",
      "epoch:15 step:11872 [D loss: 0.627640, acc.: 71.09%] [G loss: 0.731365]\n",
      "epoch:15 step:11873 [D loss: 0.643799, acc.: 64.84%] [G loss: 0.769605]\n",
      "epoch:15 step:11874 [D loss: 0.695393, acc.: 50.00%] [G loss: 0.696476]\n",
      "epoch:15 step:11875 [D loss: 0.639310, acc.: 67.19%] [G loss: 0.733649]\n",
      "epoch:15 step:11876 [D loss: 0.667405, acc.: 57.81%] [G loss: 0.760823]\n",
      "epoch:15 step:11877 [D loss: 0.656979, acc.: 60.16%] [G loss: 0.771926]\n",
      "epoch:15 step:11878 [D loss: 0.666106, acc.: 57.81%] [G loss: 0.688967]\n",
      "epoch:15 step:11879 [D loss: 0.650115, acc.: 57.81%] [G loss: 0.804984]\n",
      "epoch:15 step:11880 [D loss: 0.691478, acc.: 50.78%] [G loss: 0.764067]\n",
      "epoch:15 step:11881 [D loss: 0.711742, acc.: 44.53%] [G loss: 0.678267]\n",
      "epoch:15 step:11882 [D loss: 0.725938, acc.: 43.75%] [G loss: 0.725653]\n",
      "epoch:15 step:11883 [D loss: 0.686829, acc.: 50.00%] [G loss: 0.741732]\n",
      "epoch:15 step:11884 [D loss: 0.731603, acc.: 41.41%] [G loss: 0.698716]\n",
      "epoch:15 step:11885 [D loss: 0.624857, acc.: 72.66%] [G loss: 0.757011]\n",
      "epoch:15 step:11886 [D loss: 0.706886, acc.: 48.44%] [G loss: 0.702001]\n",
      "epoch:15 step:11887 [D loss: 0.761037, acc.: 35.16%] [G loss: 0.706952]\n",
      "epoch:15 step:11888 [D loss: 0.745495, acc.: 42.97%] [G loss: 0.712800]\n",
      "epoch:15 step:11889 [D loss: 0.692162, acc.: 51.56%] [G loss: 0.756062]\n",
      "epoch:15 step:11890 [D loss: 0.735529, acc.: 39.84%] [G loss: 0.748310]\n",
      "epoch:15 step:11891 [D loss: 0.713041, acc.: 48.44%] [G loss: 0.760283]\n",
      "epoch:15 step:11892 [D loss: 0.743316, acc.: 39.84%] [G loss: 0.744542]\n",
      "epoch:15 step:11893 [D loss: 0.716579, acc.: 46.09%] [G loss: 0.803232]\n",
      "epoch:15 step:11894 [D loss: 0.712482, acc.: 42.19%] [G loss: 0.773981]\n",
      "epoch:15 step:11895 [D loss: 0.699197, acc.: 50.00%] [G loss: 0.811561]\n",
      "epoch:15 step:11896 [D loss: 0.726157, acc.: 43.75%] [G loss: 0.755163]\n",
      "epoch:15 step:11897 [D loss: 0.737799, acc.: 42.19%] [G loss: 0.827035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11898 [D loss: 0.679378, acc.: 59.38%] [G loss: 0.825547]\n",
      "epoch:15 step:11899 [D loss: 0.683282, acc.: 49.22%] [G loss: 0.814858]\n",
      "epoch:15 step:11900 [D loss: 0.662469, acc.: 57.81%] [G loss: 0.843744]\n",
      "epoch:15 step:11901 [D loss: 0.695150, acc.: 55.47%] [G loss: 0.788922]\n",
      "epoch:15 step:11902 [D loss: 0.716005, acc.: 42.19%] [G loss: 0.797554]\n",
      "epoch:15 step:11903 [D loss: 0.701198, acc.: 50.78%] [G loss: 0.760557]\n",
      "epoch:15 step:11904 [D loss: 0.655813, acc.: 59.38%] [G loss: 0.771444]\n",
      "epoch:15 step:11905 [D loss: 0.658646, acc.: 65.62%] [G loss: 0.734591]\n",
      "epoch:15 step:11906 [D loss: 0.667875, acc.: 60.16%] [G loss: 0.707901]\n",
      "epoch:15 step:11907 [D loss: 0.679572, acc.: 60.94%] [G loss: 0.738571]\n",
      "epoch:15 step:11908 [D loss: 0.703635, acc.: 52.34%] [G loss: 0.756387]\n",
      "epoch:15 step:11909 [D loss: 0.690265, acc.: 55.47%] [G loss: 0.752336]\n",
      "epoch:15 step:11910 [D loss: 0.718727, acc.: 46.09%] [G loss: 0.740810]\n",
      "epoch:15 step:11911 [D loss: 0.648422, acc.: 62.50%] [G loss: 0.760549]\n",
      "epoch:15 step:11912 [D loss: 0.736534, acc.: 34.38%] [G loss: 0.738032]\n",
      "epoch:15 step:11913 [D loss: 0.735131, acc.: 44.53%] [G loss: 0.727809]\n",
      "epoch:15 step:11914 [D loss: 0.731577, acc.: 41.41%] [G loss: 0.714349]\n",
      "epoch:15 step:11915 [D loss: 0.667860, acc.: 61.72%] [G loss: 0.735348]\n",
      "epoch:15 step:11916 [D loss: 0.766276, acc.: 35.94%] [G loss: 0.650568]\n",
      "epoch:15 step:11917 [D loss: 0.725158, acc.: 42.97%] [G loss: 0.679890]\n",
      "epoch:15 step:11918 [D loss: 0.685347, acc.: 64.06%] [G loss: 0.728965]\n",
      "epoch:15 step:11919 [D loss: 0.689484, acc.: 57.03%] [G loss: 0.704758]\n",
      "epoch:15 step:11920 [D loss: 0.716727, acc.: 52.34%] [G loss: 0.740677]\n",
      "epoch:15 step:11921 [D loss: 0.766731, acc.: 31.25%] [G loss: 0.710029]\n",
      "epoch:15 step:11922 [D loss: 0.673915, acc.: 62.50%] [G loss: 0.731695]\n",
      "epoch:15 step:11923 [D loss: 0.720394, acc.: 50.00%] [G loss: 0.711460]\n",
      "epoch:15 step:11924 [D loss: 0.701775, acc.: 55.47%] [G loss: 0.801097]\n",
      "epoch:15 step:11925 [D loss: 0.701591, acc.: 53.91%] [G loss: 0.810267]\n",
      "epoch:15 step:11926 [D loss: 0.665796, acc.: 58.59%] [G loss: 0.728861]\n",
      "epoch:15 step:11927 [D loss: 0.684103, acc.: 53.91%] [G loss: 0.810207]\n",
      "epoch:15 step:11928 [D loss: 0.698932, acc.: 51.56%] [G loss: 0.776960]\n",
      "epoch:15 step:11929 [D loss: 0.670483, acc.: 57.81%] [G loss: 0.812980]\n",
      "epoch:15 step:11930 [D loss: 0.692457, acc.: 52.34%] [G loss: 0.752462]\n",
      "epoch:15 step:11931 [D loss: 0.679432, acc.: 56.25%] [G loss: 0.765843]\n",
      "epoch:15 step:11932 [D loss: 0.684348, acc.: 55.47%] [G loss: 0.760063]\n",
      "epoch:15 step:11933 [D loss: 0.689649, acc.: 50.78%] [G loss: 0.774381]\n",
      "epoch:15 step:11934 [D loss: 0.654881, acc.: 64.84%] [G loss: 0.769155]\n",
      "epoch:15 step:11935 [D loss: 0.635326, acc.: 64.06%] [G loss: 0.796197]\n",
      "epoch:15 step:11936 [D loss: 0.642489, acc.: 66.41%] [G loss: 0.777150]\n",
      "epoch:15 step:11937 [D loss: 0.732941, acc.: 42.19%] [G loss: 0.712972]\n",
      "epoch:15 step:11938 [D loss: 0.719407, acc.: 36.72%] [G loss: 0.741929]\n",
      "epoch:15 step:11939 [D loss: 0.722818, acc.: 38.28%] [G loss: 0.793020]\n",
      "epoch:15 step:11940 [D loss: 0.644667, acc.: 72.66%] [G loss: 0.752870]\n",
      "epoch:15 step:11941 [D loss: 0.648877, acc.: 64.84%] [G loss: 0.847703]\n",
      "epoch:15 step:11942 [D loss: 0.687321, acc.: 55.47%] [G loss: 0.766177]\n",
      "epoch:15 step:11943 [D loss: 0.668921, acc.: 64.06%] [G loss: 0.803355]\n",
      "epoch:15 step:11944 [D loss: 0.660666, acc.: 58.59%] [G loss: 0.706289]\n",
      "epoch:15 step:11945 [D loss: 0.625137, acc.: 73.44%] [G loss: 0.780191]\n",
      "epoch:15 step:11946 [D loss: 0.659891, acc.: 65.62%] [G loss: 0.731838]\n",
      "epoch:15 step:11947 [D loss: 0.720628, acc.: 51.56%] [G loss: 0.718045]\n",
      "epoch:15 step:11948 [D loss: 0.686250, acc.: 57.03%] [G loss: 0.651350]\n",
      "epoch:15 step:11949 [D loss: 0.787755, acc.: 35.16%] [G loss: 0.618756]\n",
      "epoch:15 step:11950 [D loss: 0.779272, acc.: 34.38%] [G loss: 0.623523]\n",
      "epoch:15 step:11951 [D loss: 0.702908, acc.: 50.78%] [G loss: 0.658222]\n",
      "epoch:15 step:11952 [D loss: 0.746309, acc.: 38.28%] [G loss: 0.703629]\n",
      "epoch:15 step:11953 [D loss: 0.718611, acc.: 46.88%] [G loss: 0.693006]\n",
      "epoch:15 step:11954 [D loss: 0.690866, acc.: 54.69%] [G loss: 0.792537]\n",
      "epoch:15 step:11955 [D loss: 0.705074, acc.: 50.78%] [G loss: 0.808964]\n",
      "epoch:15 step:11956 [D loss: 0.698865, acc.: 60.94%] [G loss: 0.714240]\n",
      "epoch:15 step:11957 [D loss: 0.758291, acc.: 39.06%] [G loss: 0.734286]\n",
      "epoch:15 step:11958 [D loss: 0.722845, acc.: 43.75%] [G loss: 0.684582]\n",
      "epoch:15 step:11959 [D loss: 0.645536, acc.: 63.28%] [G loss: 0.743915]\n",
      "epoch:15 step:11960 [D loss: 0.689183, acc.: 53.12%] [G loss: 0.774908]\n",
      "epoch:15 step:11961 [D loss: 0.724214, acc.: 46.88%] [G loss: 0.718001]\n",
      "epoch:15 step:11962 [D loss: 0.721145, acc.: 48.44%] [G loss: 0.693221]\n",
      "epoch:15 step:11963 [D loss: 0.744363, acc.: 40.62%] [G loss: 0.684255]\n",
      "epoch:15 step:11964 [D loss: 0.695005, acc.: 56.25%] [G loss: 0.709143]\n",
      "epoch:15 step:11965 [D loss: 0.729633, acc.: 44.53%] [G loss: 0.732076]\n",
      "epoch:15 step:11966 [D loss: 0.701287, acc.: 54.69%] [G loss: 0.750671]\n",
      "epoch:15 step:11967 [D loss: 0.722634, acc.: 47.66%] [G loss: 0.784481]\n",
      "epoch:15 step:11968 [D loss: 0.666105, acc.: 56.25%] [G loss: 0.830085]\n",
      "epoch:15 step:11969 [D loss: 0.711037, acc.: 47.66%] [G loss: 0.822455]\n",
      "epoch:15 step:11970 [D loss: 0.784565, acc.: 32.03%] [G loss: 0.792143]\n",
      "epoch:15 step:11971 [D loss: 0.742655, acc.: 43.75%] [G loss: 0.758181]\n",
      "epoch:15 step:11972 [D loss: 0.676340, acc.: 57.81%] [G loss: 0.783728]\n",
      "epoch:15 step:11973 [D loss: 0.698067, acc.: 57.03%] [G loss: 0.739935]\n",
      "epoch:15 step:11974 [D loss: 0.647904, acc.: 61.72%] [G loss: 0.758264]\n",
      "epoch:15 step:11975 [D loss: 0.681972, acc.: 57.81%] [G loss: 0.713292]\n",
      "epoch:15 step:11976 [D loss: 0.694907, acc.: 51.56%] [G loss: 0.769086]\n",
      "epoch:15 step:11977 [D loss: 0.737387, acc.: 44.53%] [G loss: 0.749810]\n",
      "epoch:15 step:11978 [D loss: 0.685366, acc.: 51.56%] [G loss: 0.742849]\n",
      "epoch:15 step:11979 [D loss: 0.650504, acc.: 66.41%] [G loss: 0.798341]\n",
      "epoch:15 step:11980 [D loss: 0.674564, acc.: 59.38%] [G loss: 0.741318]\n",
      "epoch:15 step:11981 [D loss: 0.697235, acc.: 55.47%] [G loss: 0.799365]\n",
      "epoch:15 step:11982 [D loss: 0.716713, acc.: 42.97%] [G loss: 0.776677]\n",
      "epoch:15 step:11983 [D loss: 0.641038, acc.: 64.84%] [G loss: 0.744469]\n",
      "epoch:15 step:11984 [D loss: 0.687592, acc.: 56.25%] [G loss: 0.743403]\n",
      "epoch:15 step:11985 [D loss: 0.729892, acc.: 40.62%] [G loss: 0.750646]\n",
      "epoch:15 step:11986 [D loss: 0.704032, acc.: 46.88%] [G loss: 0.699835]\n",
      "epoch:15 step:11987 [D loss: 0.686940, acc.: 52.34%] [G loss: 0.697710]\n",
      "epoch:15 step:11988 [D loss: 0.707750, acc.: 46.88%] [G loss: 0.740024]\n",
      "epoch:15 step:11989 [D loss: 0.714010, acc.: 48.44%] [G loss: 0.705965]\n",
      "epoch:15 step:11990 [D loss: 0.674342, acc.: 53.91%] [G loss: 0.727597]\n",
      "epoch:15 step:11991 [D loss: 0.687772, acc.: 53.12%] [G loss: 0.725403]\n",
      "epoch:15 step:11992 [D loss: 0.776096, acc.: 37.50%] [G loss: 0.757642]\n",
      "epoch:15 step:11993 [D loss: 0.677365, acc.: 54.69%] [G loss: 0.711581]\n",
      "epoch:15 step:11994 [D loss: 0.809259, acc.: 28.91%] [G loss: 0.665655]\n",
      "epoch:15 step:11995 [D loss: 0.729659, acc.: 43.75%] [G loss: 0.733814]\n",
      "epoch:15 step:11996 [D loss: 0.725792, acc.: 41.41%] [G loss: 0.778982]\n",
      "epoch:15 step:11997 [D loss: 0.694915, acc.: 52.34%] [G loss: 0.767937]\n",
      "epoch:15 step:11998 [D loss: 0.674458, acc.: 55.47%] [G loss: 0.794651]\n",
      "epoch:15 step:11999 [D loss: 0.670039, acc.: 62.50%] [G loss: 0.805632]\n",
      "epoch:15 step:12000 [D loss: 0.663561, acc.: 64.06%] [G loss: 0.816682]\n",
      "epoch:15 step:12001 [D loss: 0.700865, acc.: 47.66%] [G loss: 0.784086]\n",
      "epoch:15 step:12002 [D loss: 0.674370, acc.: 60.16%] [G loss: 0.810447]\n",
      "epoch:15 step:12003 [D loss: 0.677761, acc.: 51.56%] [G loss: 0.820838]\n",
      "epoch:15 step:12004 [D loss: 0.697712, acc.: 49.22%] [G loss: 0.763409]\n",
      "epoch:15 step:12005 [D loss: 0.624050, acc.: 72.66%] [G loss: 0.738708]\n",
      "epoch:15 step:12006 [D loss: 0.738654, acc.: 40.62%] [G loss: 0.747308]\n",
      "epoch:15 step:12007 [D loss: 0.722234, acc.: 48.44%] [G loss: 0.720594]\n",
      "epoch:15 step:12008 [D loss: 0.676513, acc.: 57.03%] [G loss: 0.686399]\n",
      "epoch:15 step:12009 [D loss: 0.676697, acc.: 57.81%] [G loss: 0.754862]\n",
      "epoch:15 step:12010 [D loss: 0.661963, acc.: 54.69%] [G loss: 0.772856]\n",
      "epoch:15 step:12011 [D loss: 0.684310, acc.: 55.47%] [G loss: 0.763697]\n",
      "epoch:15 step:12012 [D loss: 0.703907, acc.: 51.56%] [G loss: 0.783247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12013 [D loss: 0.670881, acc.: 56.25%] [G loss: 0.769908]\n",
      "epoch:15 step:12014 [D loss: 0.717226, acc.: 49.22%] [G loss: 0.788391]\n",
      "epoch:15 step:12015 [D loss: 0.652735, acc.: 61.72%] [G loss: 0.730721]\n",
      "epoch:15 step:12016 [D loss: 0.692409, acc.: 51.56%] [G loss: 0.739248]\n",
      "epoch:15 step:12017 [D loss: 0.721423, acc.: 43.75%] [G loss: 0.754153]\n",
      "epoch:15 step:12018 [D loss: 0.676843, acc.: 56.25%] [G loss: 0.751960]\n",
      "epoch:15 step:12019 [D loss: 0.703577, acc.: 53.12%] [G loss: 0.704547]\n",
      "epoch:15 step:12020 [D loss: 0.728564, acc.: 44.53%] [G loss: 0.727502]\n",
      "epoch:15 step:12021 [D loss: 0.641139, acc.: 68.75%] [G loss: 0.692869]\n",
      "epoch:15 step:12022 [D loss: 0.693988, acc.: 45.31%] [G loss: 0.709486]\n",
      "epoch:15 step:12023 [D loss: 0.721235, acc.: 45.31%] [G loss: 0.690721]\n",
      "epoch:15 step:12024 [D loss: 0.728591, acc.: 46.09%] [G loss: 0.716479]\n",
      "epoch:15 step:12025 [D loss: 0.749278, acc.: 35.16%] [G loss: 0.726604]\n",
      "epoch:15 step:12026 [D loss: 0.679036, acc.: 55.47%] [G loss: 0.733885]\n",
      "epoch:15 step:12027 [D loss: 0.726927, acc.: 42.19%] [G loss: 0.699727]\n",
      "epoch:15 step:12028 [D loss: 0.696386, acc.: 49.22%] [G loss: 0.802862]\n",
      "epoch:15 step:12029 [D loss: 0.727593, acc.: 46.88%] [G loss: 0.758204]\n",
      "epoch:15 step:12030 [D loss: 0.745240, acc.: 42.19%] [G loss: 0.659567]\n",
      "epoch:15 step:12031 [D loss: 0.714997, acc.: 46.09%] [G loss: 0.761245]\n",
      "epoch:15 step:12032 [D loss: 0.734191, acc.: 38.28%] [G loss: 0.728084]\n",
      "epoch:15 step:12033 [D loss: 0.675544, acc.: 54.69%] [G loss: 0.722843]\n",
      "epoch:15 step:12034 [D loss: 0.788177, acc.: 29.69%] [G loss: 0.768755]\n",
      "epoch:15 step:12035 [D loss: 0.711810, acc.: 43.75%] [G loss: 0.777610]\n",
      "epoch:15 step:12036 [D loss: 0.745061, acc.: 38.28%] [G loss: 0.769183]\n",
      "epoch:15 step:12037 [D loss: 0.685490, acc.: 49.22%] [G loss: 0.682701]\n",
      "epoch:15 step:12038 [D loss: 0.704025, acc.: 49.22%] [G loss: 0.771408]\n",
      "epoch:15 step:12039 [D loss: 0.678878, acc.: 60.94%] [G loss: 0.689224]\n",
      "epoch:15 step:12040 [D loss: 0.718712, acc.: 45.31%] [G loss: 0.815129]\n",
      "epoch:15 step:12041 [D loss: 0.687842, acc.: 53.12%] [G loss: 0.827473]\n",
      "epoch:15 step:12042 [D loss: 0.709973, acc.: 47.66%] [G loss: 0.741113]\n",
      "epoch:15 step:12043 [D loss: 0.687049, acc.: 55.47%] [G loss: 0.816270]\n",
      "epoch:15 step:12044 [D loss: 0.720838, acc.: 40.62%] [G loss: 0.762060]\n",
      "epoch:15 step:12045 [D loss: 0.697474, acc.: 56.25%] [G loss: 0.732748]\n",
      "epoch:15 step:12046 [D loss: 0.722360, acc.: 46.88%] [G loss: 0.795677]\n",
      "epoch:15 step:12047 [D loss: 0.656249, acc.: 60.16%] [G loss: 0.789351]\n",
      "epoch:15 step:12048 [D loss: 0.650263, acc.: 62.50%] [G loss: 0.746666]\n",
      "epoch:15 step:12049 [D loss: 0.660695, acc.: 63.28%] [G loss: 0.805272]\n",
      "epoch:15 step:12050 [D loss: 0.671402, acc.: 59.38%] [G loss: 0.799724]\n",
      "epoch:15 step:12051 [D loss: 0.662247, acc.: 60.16%] [G loss: 0.714013]\n",
      "epoch:15 step:12052 [D loss: 0.760072, acc.: 35.16%] [G loss: 0.683066]\n",
      "epoch:15 step:12053 [D loss: 0.742145, acc.: 40.62%] [G loss: 0.748980]\n",
      "epoch:15 step:12054 [D loss: 0.699079, acc.: 46.09%] [G loss: 0.743520]\n",
      "epoch:15 step:12055 [D loss: 0.736749, acc.: 41.41%] [G loss: 0.668542]\n",
      "epoch:15 step:12056 [D loss: 0.695088, acc.: 51.56%] [G loss: 0.764735]\n",
      "epoch:15 step:12057 [D loss: 0.717460, acc.: 46.09%] [G loss: 0.784757]\n",
      "epoch:15 step:12058 [D loss: 0.668590, acc.: 60.94%] [G loss: 0.737851]\n",
      "epoch:15 step:12059 [D loss: 0.750327, acc.: 39.84%] [G loss: 0.743289]\n",
      "epoch:15 step:12060 [D loss: 0.698703, acc.: 49.22%] [G loss: 0.722926]\n",
      "epoch:15 step:12061 [D loss: 0.707541, acc.: 46.09%] [G loss: 0.786568]\n",
      "epoch:15 step:12062 [D loss: 0.726608, acc.: 42.19%] [G loss: 0.873958]\n",
      "epoch:15 step:12063 [D loss: 0.705135, acc.: 51.56%] [G loss: 0.740222]\n",
      "epoch:15 step:12064 [D loss: 0.756813, acc.: 34.38%] [G loss: 0.743962]\n",
      "epoch:15 step:12065 [D loss: 0.748250, acc.: 38.28%] [G loss: 0.811724]\n",
      "epoch:15 step:12066 [D loss: 0.714753, acc.: 47.66%] [G loss: 0.753309]\n",
      "epoch:15 step:12067 [D loss: 0.677093, acc.: 59.38%] [G loss: 0.791079]\n",
      "epoch:15 step:12068 [D loss: 0.694912, acc.: 55.47%] [G loss: 0.779570]\n",
      "epoch:15 step:12069 [D loss: 0.646437, acc.: 69.53%] [G loss: 0.795151]\n",
      "epoch:15 step:12070 [D loss: 0.680359, acc.: 58.59%] [G loss: 0.756619]\n",
      "epoch:15 step:12071 [D loss: 0.716392, acc.: 47.66%] [G loss: 0.714047]\n",
      "epoch:15 step:12072 [D loss: 0.731972, acc.: 40.62%] [G loss: 0.763339]\n",
      "epoch:15 step:12073 [D loss: 0.696883, acc.: 50.00%] [G loss: 0.774310]\n",
      "epoch:15 step:12074 [D loss: 0.715709, acc.: 47.66%] [G loss: 0.798982]\n",
      "epoch:15 step:12075 [D loss: 0.699391, acc.: 50.00%] [G loss: 0.735982]\n",
      "epoch:15 step:12076 [D loss: 0.668943, acc.: 62.50%] [G loss: 0.715114]\n",
      "epoch:15 step:12077 [D loss: 0.664559, acc.: 59.38%] [G loss: 0.678507]\n",
      "epoch:15 step:12078 [D loss: 0.664780, acc.: 58.59%] [G loss: 0.753169]\n",
      "epoch:15 step:12079 [D loss: 0.677468, acc.: 55.47%] [G loss: 0.726042]\n",
      "epoch:15 step:12080 [D loss: 0.663851, acc.: 67.19%] [G loss: 0.713914]\n",
      "epoch:15 step:12081 [D loss: 0.657491, acc.: 57.03%] [G loss: 0.730477]\n",
      "epoch:15 step:12082 [D loss: 0.695763, acc.: 50.78%] [G loss: 0.750591]\n",
      "epoch:15 step:12083 [D loss: 0.680862, acc.: 53.12%] [G loss: 0.753208]\n",
      "epoch:15 step:12084 [D loss: 0.658106, acc.: 60.16%] [G loss: 0.815274]\n",
      "epoch:15 step:12085 [D loss: 0.676657, acc.: 57.81%] [G loss: 0.841019]\n",
      "epoch:15 step:12086 [D loss: 0.709858, acc.: 50.00%] [G loss: 0.806259]\n",
      "epoch:15 step:12087 [D loss: 0.707668, acc.: 49.22%] [G loss: 0.782257]\n",
      "epoch:15 step:12088 [D loss: 0.706609, acc.: 53.91%] [G loss: 0.773004]\n",
      "epoch:15 step:12089 [D loss: 0.714045, acc.: 46.09%] [G loss: 0.795658]\n",
      "epoch:15 step:12090 [D loss: 0.693866, acc.: 49.22%] [G loss: 0.751431]\n",
      "epoch:15 step:12091 [D loss: 0.683470, acc.: 54.69%] [G loss: 0.805521]\n",
      "epoch:15 step:12092 [D loss: 0.695348, acc.: 50.00%] [G loss: 0.778694]\n",
      "epoch:15 step:12093 [D loss: 0.673782, acc.: 60.16%] [G loss: 0.790918]\n",
      "epoch:15 step:12094 [D loss: 0.647885, acc.: 69.53%] [G loss: 0.792816]\n",
      "epoch:15 step:12095 [D loss: 0.715797, acc.: 46.09%] [G loss: 0.750393]\n",
      "epoch:15 step:12096 [D loss: 0.671095, acc.: 57.03%] [G loss: 0.729094]\n",
      "epoch:15 step:12097 [D loss: 0.673235, acc.: 53.12%] [G loss: 0.796363]\n",
      "epoch:15 step:12098 [D loss: 0.672810, acc.: 57.81%] [G loss: 0.750113]\n",
      "epoch:15 step:12099 [D loss: 0.684434, acc.: 55.47%] [G loss: 0.815388]\n",
      "epoch:15 step:12100 [D loss: 0.676371, acc.: 55.47%] [G loss: 0.735015]\n",
      "epoch:15 step:12101 [D loss: 0.731447, acc.: 43.75%] [G loss: 0.760021]\n",
      "epoch:15 step:12102 [D loss: 0.687154, acc.: 51.56%] [G loss: 0.737327]\n",
      "epoch:15 step:12103 [D loss: 0.726576, acc.: 45.31%] [G loss: 0.747288]\n",
      "epoch:15 step:12104 [D loss: 0.636595, acc.: 71.88%] [G loss: 0.732458]\n",
      "epoch:15 step:12105 [D loss: 0.696079, acc.: 50.78%] [G loss: 0.751337]\n",
      "epoch:15 step:12106 [D loss: 0.746189, acc.: 42.97%] [G loss: 0.765885]\n",
      "epoch:15 step:12107 [D loss: 0.728567, acc.: 42.97%] [G loss: 0.764159]\n",
      "epoch:15 step:12108 [D loss: 0.675188, acc.: 64.06%] [G loss: 0.731318]\n",
      "epoch:15 step:12109 [D loss: 0.717253, acc.: 45.31%] [G loss: 0.727584]\n",
      "epoch:15 step:12110 [D loss: 0.733769, acc.: 46.09%] [G loss: 0.735251]\n",
      "epoch:15 step:12111 [D loss: 0.685910, acc.: 56.25%] [G loss: 0.787807]\n",
      "epoch:15 step:12112 [D loss: 0.690181, acc.: 54.69%] [G loss: 0.718167]\n",
      "epoch:15 step:12113 [D loss: 0.705027, acc.: 49.22%] [G loss: 0.740035]\n",
      "epoch:15 step:12114 [D loss: 0.695608, acc.: 57.81%] [G loss: 0.799717]\n",
      "epoch:15 step:12115 [D loss: 0.733190, acc.: 46.88%] [G loss: 0.771612]\n",
      "epoch:15 step:12116 [D loss: 0.675008, acc.: 54.69%] [G loss: 0.708245]\n",
      "epoch:15 step:12117 [D loss: 0.674325, acc.: 57.03%] [G loss: 0.740889]\n",
      "epoch:15 step:12118 [D loss: 0.714174, acc.: 47.66%] [G loss: 0.736728]\n",
      "epoch:15 step:12119 [D loss: 0.661533, acc.: 64.06%] [G loss: 0.777260]\n",
      "epoch:15 step:12120 [D loss: 0.706654, acc.: 46.88%] [G loss: 0.804862]\n",
      "epoch:15 step:12121 [D loss: 0.693207, acc.: 52.34%] [G loss: 0.729156]\n",
      "epoch:15 step:12122 [D loss: 0.736362, acc.: 39.84%] [G loss: 0.718423]\n",
      "epoch:15 step:12123 [D loss: 0.709665, acc.: 51.56%] [G loss: 0.742445]\n",
      "epoch:15 step:12124 [D loss: 0.726843, acc.: 42.97%] [G loss: 0.808722]\n",
      "epoch:15 step:12125 [D loss: 0.693438, acc.: 55.47%] [G loss: 0.802971]\n",
      "epoch:15 step:12126 [D loss: 0.726444, acc.: 44.53%] [G loss: 0.803951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12127 [D loss: 0.657416, acc.: 57.81%] [G loss: 0.788201]\n",
      "epoch:15 step:12128 [D loss: 0.652388, acc.: 61.72%] [G loss: 0.772317]\n",
      "epoch:15 step:12129 [D loss: 0.691285, acc.: 53.12%] [G loss: 0.754964]\n",
      "epoch:15 step:12130 [D loss: 0.674041, acc.: 57.03%] [G loss: 0.838412]\n",
      "epoch:15 step:12131 [D loss: 0.672798, acc.: 59.38%] [G loss: 0.719620]\n",
      "epoch:15 step:12132 [D loss: 0.733969, acc.: 40.62%] [G loss: 0.697365]\n",
      "epoch:15 step:12133 [D loss: 0.639572, acc.: 61.72%] [G loss: 0.704617]\n",
      "epoch:15 step:12134 [D loss: 0.679942, acc.: 56.25%] [G loss: 0.724416]\n",
      "epoch:15 step:12135 [D loss: 0.645019, acc.: 60.16%] [G loss: 0.768354]\n",
      "epoch:15 step:12136 [D loss: 0.688596, acc.: 56.25%] [G loss: 0.756701]\n",
      "epoch:15 step:12137 [D loss: 0.675619, acc.: 58.59%] [G loss: 0.771106]\n",
      "epoch:15 step:12138 [D loss: 0.649126, acc.: 70.31%] [G loss: 0.756340]\n",
      "epoch:15 step:12139 [D loss: 0.728991, acc.: 42.97%] [G loss: 0.722388]\n",
      "epoch:15 step:12140 [D loss: 0.683373, acc.: 59.38%] [G loss: 0.682190]\n",
      "epoch:15 step:12141 [D loss: 0.726776, acc.: 45.31%] [G loss: 0.709070]\n",
      "epoch:15 step:12142 [D loss: 0.679197, acc.: 58.59%] [G loss: 0.772918]\n",
      "epoch:15 step:12143 [D loss: 0.690678, acc.: 57.03%] [G loss: 0.724971]\n",
      "epoch:15 step:12144 [D loss: 0.667667, acc.: 62.50%] [G loss: 0.721592]\n",
      "epoch:15 step:12145 [D loss: 0.716868, acc.: 50.00%] [G loss: 0.681571]\n",
      "epoch:15 step:12146 [D loss: 0.778431, acc.: 38.28%] [G loss: 0.688571]\n",
      "epoch:15 step:12147 [D loss: 0.711569, acc.: 50.00%] [G loss: 0.764663]\n",
      "epoch:15 step:12148 [D loss: 0.727375, acc.: 48.44%] [G loss: 0.711501]\n",
      "epoch:15 step:12149 [D loss: 0.690832, acc.: 53.12%] [G loss: 0.780836]\n",
      "epoch:15 step:12150 [D loss: 0.691218, acc.: 50.00%] [G loss: 0.859727]\n",
      "epoch:15 step:12151 [D loss: 0.757126, acc.: 36.72%] [G loss: 0.717149]\n",
      "epoch:15 step:12152 [D loss: 0.708518, acc.: 49.22%] [G loss: 0.764654]\n",
      "epoch:15 step:12153 [D loss: 0.673880, acc.: 60.16%] [G loss: 0.774443]\n",
      "epoch:15 step:12154 [D loss: 0.674990, acc.: 58.59%] [G loss: 0.786516]\n",
      "epoch:15 step:12155 [D loss: 0.673492, acc.: 57.81%] [G loss: 0.733088]\n",
      "epoch:15 step:12156 [D loss: 0.708155, acc.: 52.34%] [G loss: 0.745139]\n",
      "epoch:15 step:12157 [D loss: 0.709863, acc.: 52.34%] [G loss: 0.833248]\n",
      "epoch:15 step:12158 [D loss: 0.704760, acc.: 50.78%] [G loss: 0.713768]\n",
      "epoch:15 step:12159 [D loss: 0.716621, acc.: 44.53%] [G loss: 0.822116]\n",
      "epoch:15 step:12160 [D loss: 0.713517, acc.: 51.56%] [G loss: 0.728300]\n",
      "epoch:15 step:12161 [D loss: 0.644088, acc.: 64.06%] [G loss: 0.794894]\n",
      "epoch:15 step:12162 [D loss: 0.696005, acc.: 53.12%] [G loss: 0.736929]\n",
      "epoch:15 step:12163 [D loss: 0.694799, acc.: 50.00%] [G loss: 0.774256]\n",
      "epoch:15 step:12164 [D loss: 0.641065, acc.: 64.06%] [G loss: 0.750787]\n",
      "epoch:15 step:12165 [D loss: 0.667639, acc.: 57.03%] [G loss: 0.880510]\n",
      "epoch:15 step:12166 [D loss: 0.721295, acc.: 45.31%] [G loss: 0.841988]\n",
      "epoch:15 step:12167 [D loss: 0.669716, acc.: 55.47%] [G loss: 0.729943]\n",
      "epoch:15 step:12168 [D loss: 0.729679, acc.: 49.22%] [G loss: 0.768676]\n",
      "epoch:15 step:12169 [D loss: 0.734237, acc.: 48.44%] [G loss: 0.748359]\n",
      "epoch:15 step:12170 [D loss: 0.697574, acc.: 48.44%] [G loss: 0.767191]\n",
      "epoch:15 step:12171 [D loss: 0.596166, acc.: 80.47%] [G loss: 0.759291]\n",
      "epoch:15 step:12172 [D loss: 0.762668, acc.: 34.38%] [G loss: 0.731426]\n",
      "epoch:15 step:12173 [D loss: 0.672105, acc.: 57.03%] [G loss: 0.774107]\n",
      "epoch:15 step:12174 [D loss: 0.721188, acc.: 40.62%] [G loss: 0.790143]\n",
      "epoch:15 step:12175 [D loss: 0.721768, acc.: 44.53%] [G loss: 0.741026]\n",
      "epoch:15 step:12176 [D loss: 0.705725, acc.: 50.00%] [G loss: 0.724897]\n",
      "epoch:15 step:12177 [D loss: 0.706413, acc.: 50.78%] [G loss: 0.801350]\n",
      "epoch:15 step:12178 [D loss: 0.692469, acc.: 53.91%] [G loss: 0.845465]\n",
      "epoch:15 step:12179 [D loss: 0.658358, acc.: 61.72%] [G loss: 0.740692]\n",
      "epoch:15 step:12180 [D loss: 0.713345, acc.: 43.75%] [G loss: 0.753735]\n",
      "epoch:15 step:12181 [D loss: 0.675719, acc.: 55.47%] [G loss: 0.798444]\n",
      "epoch:15 step:12182 [D loss: 0.727945, acc.: 45.31%] [G loss: 0.753385]\n",
      "epoch:15 step:12183 [D loss: 0.674510, acc.: 60.94%] [G loss: 0.741666]\n",
      "epoch:15 step:12184 [D loss: 0.696432, acc.: 46.09%] [G loss: 0.732358]\n",
      "epoch:15 step:12185 [D loss: 0.710302, acc.: 47.66%] [G loss: 0.775955]\n",
      "epoch:15 step:12186 [D loss: 0.692158, acc.: 53.91%] [G loss: 0.814177]\n",
      "epoch:15 step:12187 [D loss: 0.667439, acc.: 60.94%] [G loss: 0.844582]\n",
      "epoch:15 step:12188 [D loss: 0.762287, acc.: 46.88%] [G loss: 0.823233]\n",
      "epoch:15 step:12189 [D loss: 0.730165, acc.: 39.06%] [G loss: 0.724251]\n",
      "epoch:15 step:12190 [D loss: 0.759658, acc.: 33.59%] [G loss: 0.739334]\n",
      "epoch:15 step:12191 [D loss: 0.682593, acc.: 59.38%] [G loss: 0.777510]\n",
      "epoch:15 step:12192 [D loss: 0.644389, acc.: 65.62%] [G loss: 0.778636]\n",
      "epoch:15 step:12193 [D loss: 0.644419, acc.: 68.75%] [G loss: 0.773626]\n",
      "epoch:15 step:12194 [D loss: 0.700114, acc.: 48.44%] [G loss: 0.756837]\n",
      "epoch:15 step:12195 [D loss: 0.705103, acc.: 48.44%] [G loss: 0.730192]\n",
      "epoch:15 step:12196 [D loss: 0.702992, acc.: 49.22%] [G loss: 0.701382]\n",
      "epoch:15 step:12197 [D loss: 0.698457, acc.: 52.34%] [G loss: 0.707352]\n",
      "epoch:15 step:12198 [D loss: 0.722755, acc.: 46.09%] [G loss: 0.668990]\n",
      "epoch:15 step:12199 [D loss: 0.716880, acc.: 47.66%] [G loss: 0.661824]\n",
      "epoch:15 step:12200 [D loss: 0.653574, acc.: 66.41%] [G loss: 0.738039]\n",
      "epoch:15 step:12201 [D loss: 0.724653, acc.: 50.00%] [G loss: 0.735182]\n",
      "epoch:15 step:12202 [D loss: 0.710320, acc.: 50.78%] [G loss: 0.722167]\n",
      "epoch:15 step:12203 [D loss: 0.708725, acc.: 49.22%] [G loss: 0.745808]\n",
      "epoch:15 step:12204 [D loss: 0.684690, acc.: 56.25%] [G loss: 0.734140]\n",
      "epoch:15 step:12205 [D loss: 0.716445, acc.: 49.22%] [G loss: 0.708343]\n",
      "epoch:15 step:12206 [D loss: 0.716777, acc.: 50.00%] [G loss: 0.785647]\n",
      "epoch:15 step:12207 [D loss: 0.725660, acc.: 42.97%] [G loss: 0.759906]\n",
      "epoch:15 step:12208 [D loss: 0.709789, acc.: 51.56%] [G loss: 0.814087]\n",
      "epoch:15 step:12209 [D loss: 0.657816, acc.: 62.50%] [G loss: 0.814240]\n",
      "epoch:15 step:12210 [D loss: 0.738846, acc.: 42.19%] [G loss: 0.810700]\n",
      "epoch:15 step:12211 [D loss: 0.665022, acc.: 57.03%] [G loss: 0.774540]\n",
      "epoch:15 step:12212 [D loss: 0.712452, acc.: 43.75%] [G loss: 0.747832]\n",
      "epoch:15 step:12213 [D loss: 0.688568, acc.: 50.00%] [G loss: 0.790603]\n",
      "epoch:15 step:12214 [D loss: 0.637666, acc.: 71.88%] [G loss: 0.728720]\n",
      "epoch:15 step:12215 [D loss: 0.718555, acc.: 48.44%] [G loss: 0.782090]\n",
      "epoch:15 step:12216 [D loss: 0.719534, acc.: 42.19%] [G loss: 0.787000]\n",
      "epoch:15 step:12217 [D loss: 0.680364, acc.: 57.81%] [G loss: 0.765821]\n",
      "epoch:15 step:12218 [D loss: 0.652767, acc.: 64.84%] [G loss: 0.796788]\n",
      "epoch:15 step:12219 [D loss: 0.680176, acc.: 54.69%] [G loss: 0.813664]\n",
      "epoch:15 step:12220 [D loss: 0.688924, acc.: 57.81%] [G loss: 0.796107]\n",
      "epoch:15 step:12221 [D loss: 0.713282, acc.: 47.66%] [G loss: 0.782600]\n",
      "epoch:15 step:12222 [D loss: 0.700058, acc.: 49.22%] [G loss: 0.722594]\n",
      "epoch:15 step:12223 [D loss: 0.716159, acc.: 45.31%] [G loss: 0.728061]\n",
      "epoch:15 step:12224 [D loss: 0.712467, acc.: 44.53%] [G loss: 0.796162]\n",
      "epoch:15 step:12225 [D loss: 0.646595, acc.: 70.31%] [G loss: 0.766325]\n",
      "epoch:15 step:12226 [D loss: 0.723896, acc.: 39.84%] [G loss: 0.754348]\n",
      "epoch:15 step:12227 [D loss: 0.715996, acc.: 50.78%] [G loss: 0.837190]\n",
      "epoch:15 step:12228 [D loss: 0.755580, acc.: 39.06%] [G loss: 0.748719]\n",
      "epoch:15 step:12229 [D loss: 0.773127, acc.: 37.50%] [G loss: 0.735179]\n",
      "epoch:15 step:12230 [D loss: 0.690392, acc.: 53.91%] [G loss: 0.759735]\n",
      "epoch:15 step:12231 [D loss: 0.666589, acc.: 62.50%] [G loss: 0.692616]\n",
      "epoch:15 step:12232 [D loss: 0.683610, acc.: 53.12%] [G loss: 0.738441]\n",
      "epoch:15 step:12233 [D loss: 0.668455, acc.: 58.59%] [G loss: 0.744401]\n",
      "epoch:15 step:12234 [D loss: 0.687807, acc.: 50.78%] [G loss: 0.753908]\n",
      "epoch:15 step:12235 [D loss: 0.692242, acc.: 52.34%] [G loss: 0.768955]\n",
      "epoch:15 step:12236 [D loss: 0.679814, acc.: 57.03%] [G loss: 0.765090]\n",
      "epoch:15 step:12237 [D loss: 0.691389, acc.: 53.91%] [G loss: 0.795103]\n",
      "epoch:15 step:12238 [D loss: 0.648733, acc.: 58.59%] [G loss: 0.779354]\n",
      "epoch:15 step:12239 [D loss: 0.690949, acc.: 52.34%] [G loss: 0.742965]\n",
      "epoch:15 step:12240 [D loss: 0.687577, acc.: 54.69%] [G loss: 0.671893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12241 [D loss: 0.884182, acc.: 11.72%] [G loss: 0.656474]\n",
      "epoch:15 step:12242 [D loss: 0.722284, acc.: 46.88%] [G loss: 0.749201]\n",
      "epoch:15 step:12243 [D loss: 0.699037, acc.: 53.12%] [G loss: 0.676834]\n",
      "epoch:15 step:12244 [D loss: 0.712503, acc.: 49.22%] [G loss: 0.708618]\n",
      "epoch:15 step:12245 [D loss: 0.655832, acc.: 64.84%] [G loss: 0.724797]\n",
      "epoch:15 step:12246 [D loss: 0.683738, acc.: 48.44%] [G loss: 0.751757]\n",
      "epoch:15 step:12247 [D loss: 0.748080, acc.: 39.06%] [G loss: 0.741118]\n",
      "epoch:15 step:12248 [D loss: 0.696465, acc.: 48.44%] [G loss: 0.853035]\n",
      "epoch:15 step:12249 [D loss: 0.681097, acc.: 57.03%] [G loss: 0.815126]\n",
      "epoch:15 step:12250 [D loss: 0.710837, acc.: 46.88%] [G loss: 0.787542]\n",
      "epoch:15 step:12251 [D loss: 0.646816, acc.: 61.72%] [G loss: 0.831602]\n",
      "epoch:15 step:12252 [D loss: 0.737785, acc.: 44.53%] [G loss: 0.724506]\n",
      "epoch:15 step:12253 [D loss: 0.663344, acc.: 64.06%] [G loss: 0.760702]\n",
      "epoch:15 step:12254 [D loss: 0.697260, acc.: 53.12%] [G loss: 0.759418]\n",
      "epoch:15 step:12255 [D loss: 0.717341, acc.: 49.22%] [G loss: 0.733262]\n",
      "epoch:15 step:12256 [D loss: 0.667090, acc.: 61.72%] [G loss: 0.782724]\n",
      "epoch:15 step:12257 [D loss: 0.706429, acc.: 50.00%] [G loss: 0.743581]\n",
      "epoch:15 step:12258 [D loss: 0.713593, acc.: 45.31%] [G loss: 0.753183]\n",
      "epoch:15 step:12259 [D loss: 0.689662, acc.: 54.69%] [G loss: 0.731473]\n",
      "epoch:15 step:12260 [D loss: 0.679673, acc.: 57.03%] [G loss: 0.800772]\n",
      "epoch:15 step:12261 [D loss: 0.778706, acc.: 39.06%] [G loss: 0.771043]\n",
      "epoch:15 step:12262 [D loss: 0.655995, acc.: 67.97%] [G loss: 0.787907]\n",
      "epoch:15 step:12263 [D loss: 0.741175, acc.: 37.50%] [G loss: 0.787063]\n",
      "epoch:15 step:12264 [D loss: 0.671055, acc.: 57.81%] [G loss: 0.727020]\n",
      "epoch:15 step:12265 [D loss: 0.689079, acc.: 53.91%] [G loss: 0.723790]\n",
      "epoch:15 step:12266 [D loss: 0.705602, acc.: 48.44%] [G loss: 0.789915]\n",
      "epoch:15 step:12267 [D loss: 0.751590, acc.: 32.81%] [G loss: 0.693624]\n",
      "epoch:15 step:12268 [D loss: 0.721239, acc.: 44.53%] [G loss: 0.772896]\n",
      "epoch:15 step:12269 [D loss: 0.682552, acc.: 56.25%] [G loss: 0.808907]\n",
      "epoch:15 step:12270 [D loss: 0.694395, acc.: 51.56%] [G loss: 0.764960]\n",
      "epoch:15 step:12271 [D loss: 0.700927, acc.: 46.09%] [G loss: 0.765365]\n",
      "epoch:15 step:12272 [D loss: 0.729445, acc.: 47.66%] [G loss: 0.730431]\n",
      "epoch:15 step:12273 [D loss: 0.681210, acc.: 53.12%] [G loss: 0.784018]\n",
      "epoch:15 step:12274 [D loss: 0.667658, acc.: 55.47%] [G loss: 0.816760]\n",
      "epoch:15 step:12275 [D loss: 0.752536, acc.: 35.94%] [G loss: 0.766531]\n",
      "epoch:15 step:12276 [D loss: 0.702289, acc.: 54.69%] [G loss: 0.754732]\n",
      "epoch:15 step:12277 [D loss: 0.678766, acc.: 57.81%] [G loss: 0.841950]\n",
      "epoch:15 step:12278 [D loss: 0.680713, acc.: 52.34%] [G loss: 0.733190]\n",
      "epoch:15 step:12279 [D loss: 0.680781, acc.: 51.56%] [G loss: 0.720027]\n",
      "epoch:15 step:12280 [D loss: 0.653203, acc.: 60.16%] [G loss: 0.784828]\n",
      "epoch:15 step:12281 [D loss: 0.716999, acc.: 44.53%] [G loss: 0.772364]\n",
      "epoch:15 step:12282 [D loss: 0.679483, acc.: 53.91%] [G loss: 0.846158]\n",
      "epoch:15 step:12283 [D loss: 0.703246, acc.: 43.75%] [G loss: 0.852513]\n",
      "epoch:15 step:12284 [D loss: 0.675063, acc.: 60.16%] [G loss: 0.767209]\n",
      "epoch:15 step:12285 [D loss: 0.703791, acc.: 50.78%] [G loss: 0.710060]\n",
      "epoch:15 step:12286 [D loss: 0.750782, acc.: 35.16%] [G loss: 0.728531]\n",
      "epoch:15 step:12287 [D loss: 0.721509, acc.: 45.31%] [G loss: 0.707793]\n",
      "epoch:15 step:12288 [D loss: 0.691053, acc.: 56.25%] [G loss: 0.740697]\n",
      "epoch:15 step:12289 [D loss: 0.685995, acc.: 57.81%] [G loss: 0.733075]\n",
      "epoch:15 step:12290 [D loss: 0.719771, acc.: 42.97%] [G loss: 0.703774]\n",
      "epoch:15 step:12291 [D loss: 0.687392, acc.: 51.56%] [G loss: 0.673005]\n",
      "epoch:15 step:12292 [D loss: 0.748027, acc.: 37.50%] [G loss: 0.735893]\n",
      "epoch:15 step:12293 [D loss: 0.673686, acc.: 57.03%] [G loss: 0.722045]\n",
      "epoch:15 step:12294 [D loss: 0.666240, acc.: 54.69%] [G loss: 0.731093]\n",
      "epoch:15 step:12295 [D loss: 0.739904, acc.: 47.66%] [G loss: 0.694299]\n",
      "epoch:15 step:12296 [D loss: 0.718174, acc.: 43.75%] [G loss: 0.753392]\n",
      "epoch:15 step:12297 [D loss: 0.680970, acc.: 57.03%] [G loss: 0.833079]\n",
      "epoch:15 step:12298 [D loss: 0.710362, acc.: 49.22%] [G loss: 0.705311]\n",
      "epoch:15 step:12299 [D loss: 0.670311, acc.: 63.28%] [G loss: 0.756589]\n",
      "epoch:15 step:12300 [D loss: 0.717440, acc.: 49.22%] [G loss: 0.680975]\n",
      "epoch:15 step:12301 [D loss: 0.625521, acc.: 70.31%] [G loss: 0.693089]\n",
      "epoch:15 step:12302 [D loss: 0.711100, acc.: 48.44%] [G loss: 0.718285]\n",
      "epoch:15 step:12303 [D loss: 0.689089, acc.: 58.59%] [G loss: 0.734722]\n",
      "epoch:15 step:12304 [D loss: 0.681914, acc.: 53.91%] [G loss: 0.747871]\n",
      "epoch:15 step:12305 [D loss: 0.704353, acc.: 50.00%] [G loss: 0.792058]\n",
      "epoch:15 step:12306 [D loss: 0.702218, acc.: 42.97%] [G loss: 0.738964]\n",
      "epoch:15 step:12307 [D loss: 0.774983, acc.: 37.50%] [G loss: 0.797887]\n",
      "epoch:15 step:12308 [D loss: 0.726052, acc.: 40.62%] [G loss: 0.748636]\n",
      "epoch:15 step:12309 [D loss: 0.689092, acc.: 55.47%] [G loss: 0.704710]\n",
      "epoch:15 step:12310 [D loss: 0.703037, acc.: 49.22%] [G loss: 0.778374]\n",
      "epoch:15 step:12311 [D loss: 0.684042, acc.: 57.03%] [G loss: 0.746304]\n",
      "epoch:15 step:12312 [D loss: 0.738707, acc.: 40.62%] [G loss: 0.679251]\n",
      "epoch:15 step:12313 [D loss: 0.681731, acc.: 53.91%] [G loss: 0.787362]\n",
      "epoch:15 step:12314 [D loss: 0.705176, acc.: 46.09%] [G loss: 0.807789]\n",
      "epoch:15 step:12315 [D loss: 0.686811, acc.: 55.47%] [G loss: 0.808346]\n",
      "epoch:15 step:12316 [D loss: 0.643274, acc.: 65.62%] [G loss: 0.757707]\n",
      "epoch:15 step:12317 [D loss: 0.632187, acc.: 71.88%] [G loss: 0.748409]\n",
      "epoch:15 step:12318 [D loss: 0.629902, acc.: 60.16%] [G loss: 0.885907]\n",
      "epoch:15 step:12319 [D loss: 0.640694, acc.: 71.09%] [G loss: 0.748844]\n",
      "epoch:15 step:12320 [D loss: 0.690924, acc.: 55.47%] [G loss: 0.707757]\n",
      "epoch:15 step:12321 [D loss: 0.642447, acc.: 67.19%] [G loss: 0.736835]\n",
      "epoch:15 step:12322 [D loss: 0.683759, acc.: 57.03%] [G loss: 0.683777]\n",
      "epoch:15 step:12323 [D loss: 0.644003, acc.: 62.50%] [G loss: 0.698076]\n",
      "epoch:15 step:12324 [D loss: 0.693192, acc.: 51.56%] [G loss: 0.634333]\n",
      "epoch:15 step:12325 [D loss: 0.640533, acc.: 67.19%] [G loss: 0.723186]\n",
      "epoch:15 step:12326 [D loss: 0.669879, acc.: 57.03%] [G loss: 0.699178]\n",
      "epoch:15 step:12327 [D loss: 0.678695, acc.: 57.81%] [G loss: 0.730810]\n",
      "epoch:15 step:12328 [D loss: 0.697146, acc.: 51.56%] [G loss: 0.779831]\n",
      "epoch:15 step:12329 [D loss: 0.741328, acc.: 45.31%] [G loss: 0.678978]\n",
      "epoch:15 step:12330 [D loss: 0.661605, acc.: 61.72%] [G loss: 0.746764]\n",
      "epoch:15 step:12331 [D loss: 0.744345, acc.: 39.84%] [G loss: 0.695494]\n",
      "epoch:15 step:12332 [D loss: 0.728254, acc.: 49.22%] [G loss: 0.751564]\n",
      "epoch:15 step:12333 [D loss: 0.698603, acc.: 53.12%] [G loss: 0.744539]\n",
      "epoch:15 step:12334 [D loss: 0.742437, acc.: 38.28%] [G loss: 0.673892]\n",
      "epoch:15 step:12335 [D loss: 0.704330, acc.: 49.22%] [G loss: 0.759485]\n",
      "epoch:15 step:12336 [D loss: 0.679554, acc.: 59.38%] [G loss: 0.762558]\n",
      "epoch:15 step:12337 [D loss: 0.694167, acc.: 48.44%] [G loss: 0.761119]\n",
      "epoch:15 step:12338 [D loss: 0.680226, acc.: 52.34%] [G loss: 0.769469]\n",
      "epoch:15 step:12339 [D loss: 0.685702, acc.: 53.12%] [G loss: 0.749522]\n",
      "epoch:15 step:12340 [D loss: 0.735628, acc.: 45.31%] [G loss: 0.767894]\n",
      "epoch:15 step:12341 [D loss: 0.656053, acc.: 63.28%] [G loss: 0.748439]\n",
      "epoch:15 step:12342 [D loss: 0.690764, acc.: 59.38%] [G loss: 0.712703]\n",
      "epoch:15 step:12343 [D loss: 0.715052, acc.: 52.34%] [G loss: 0.760997]\n",
      "epoch:15 step:12344 [D loss: 0.706411, acc.: 50.78%] [G loss: 0.760188]\n",
      "epoch:15 step:12345 [D loss: 0.743549, acc.: 42.97%] [G loss: 0.718796]\n",
      "epoch:15 step:12346 [D loss: 0.663042, acc.: 59.38%] [G loss: 0.776836]\n",
      "epoch:15 step:12347 [D loss: 0.646852, acc.: 64.84%] [G loss: 0.775935]\n",
      "epoch:15 step:12348 [D loss: 0.668667, acc.: 56.25%] [G loss: 0.860820]\n",
      "epoch:15 step:12349 [D loss: 0.720711, acc.: 44.53%] [G loss: 0.745687]\n",
      "epoch:15 step:12350 [D loss: 0.660331, acc.: 63.28%] [G loss: 0.747631]\n",
      "epoch:15 step:12351 [D loss: 0.639571, acc.: 67.97%] [G loss: 0.736193]\n",
      "epoch:15 step:12352 [D loss: 0.656836, acc.: 60.16%] [G loss: 0.726596]\n",
      "epoch:15 step:12353 [D loss: 0.676454, acc.: 58.59%] [G loss: 0.767815]\n",
      "epoch:15 step:12354 [D loss: 0.716325, acc.: 51.56%] [G loss: 0.738025]\n",
      "epoch:15 step:12355 [D loss: 0.668458, acc.: 57.03%] [G loss: 0.780217]\n",
      "epoch:15 step:12356 [D loss: 0.708895, acc.: 50.78%] [G loss: 0.752844]\n",
      "epoch:15 step:12357 [D loss: 0.724135, acc.: 45.31%] [G loss: 0.665516]\n",
      "epoch:15 step:12358 [D loss: 0.718610, acc.: 46.88%] [G loss: 0.675415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12359 [D loss: 0.692026, acc.: 57.03%] [G loss: 0.672433]\n",
      "epoch:15 step:12360 [D loss: 0.726699, acc.: 44.53%] [G loss: 0.642224]\n",
      "epoch:15 step:12361 [D loss: 0.704745, acc.: 44.53%] [G loss: 0.744566]\n",
      "epoch:15 step:12362 [D loss: 0.770005, acc.: 39.84%] [G loss: 0.683367]\n",
      "epoch:15 step:12363 [D loss: 0.682706, acc.: 55.47%] [G loss: 0.703506]\n",
      "epoch:15 step:12364 [D loss: 0.743970, acc.: 38.28%] [G loss: 0.701530]\n",
      "epoch:15 step:12365 [D loss: 0.748741, acc.: 36.72%] [G loss: 0.698426]\n",
      "epoch:15 step:12366 [D loss: 0.661112, acc.: 57.03%] [G loss: 0.712691]\n",
      "epoch:15 step:12367 [D loss: 0.698598, acc.: 52.34%] [G loss: 0.751226]\n",
      "epoch:15 step:12368 [D loss: 0.665664, acc.: 58.59%] [G loss: 0.783363]\n",
      "epoch:15 step:12369 [D loss: 0.713806, acc.: 49.22%] [G loss: 0.750929]\n",
      "epoch:15 step:12370 [D loss: 0.691051, acc.: 53.12%] [G loss: 0.763114]\n",
      "epoch:15 step:12371 [D loss: 0.691999, acc.: 53.91%] [G loss: 0.758387]\n",
      "epoch:15 step:12372 [D loss: 0.715339, acc.: 44.53%] [G loss: 0.755531]\n",
      "epoch:15 step:12373 [D loss: 0.687833, acc.: 60.94%] [G loss: 0.739936]\n",
      "epoch:15 step:12374 [D loss: 0.703154, acc.: 51.56%] [G loss: 0.775210]\n",
      "epoch:15 step:12375 [D loss: 0.749930, acc.: 35.16%] [G loss: 0.707556]\n",
      "epoch:15 step:12376 [D loss: 0.668945, acc.: 66.41%] [G loss: 0.813162]\n",
      "epoch:15 step:12377 [D loss: 0.686410, acc.: 52.34%] [G loss: 0.829356]\n",
      "epoch:15 step:12378 [D loss: 0.640308, acc.: 67.97%] [G loss: 0.745921]\n",
      "epoch:15 step:12379 [D loss: 0.668182, acc.: 56.25%] [G loss: 0.803151]\n",
      "epoch:15 step:12380 [D loss: 0.656160, acc.: 67.19%] [G loss: 0.783480]\n",
      "epoch:15 step:12381 [D loss: 0.632463, acc.: 71.09%] [G loss: 0.735597]\n",
      "epoch:15 step:12382 [D loss: 0.647254, acc.: 60.94%] [G loss: 0.765038]\n",
      "epoch:15 step:12383 [D loss: 0.650636, acc.: 64.06%] [G loss: 0.783121]\n",
      "epoch:15 step:12384 [D loss: 0.675101, acc.: 55.47%] [G loss: 0.770949]\n",
      "epoch:15 step:12385 [D loss: 0.674861, acc.: 62.50%] [G loss: 0.674202]\n",
      "epoch:15 step:12386 [D loss: 0.721181, acc.: 41.41%] [G loss: 0.725998]\n",
      "epoch:15 step:12387 [D loss: 0.738601, acc.: 40.62%] [G loss: 0.656336]\n",
      "epoch:15 step:12388 [D loss: 0.650900, acc.: 65.62%] [G loss: 0.729665]\n",
      "epoch:15 step:12389 [D loss: 0.695666, acc.: 54.69%] [G loss: 0.691193]\n",
      "epoch:15 step:12390 [D loss: 0.776135, acc.: 32.81%] [G loss: 0.691653]\n",
      "epoch:15 step:12391 [D loss: 0.747332, acc.: 38.28%] [G loss: 0.702647]\n",
      "epoch:15 step:12392 [D loss: 0.687724, acc.: 51.56%] [G loss: 0.696136]\n",
      "epoch:15 step:12393 [D loss: 0.739515, acc.: 39.84%] [G loss: 0.754777]\n",
      "epoch:15 step:12394 [D loss: 0.714154, acc.: 49.22%] [G loss: 0.712747]\n",
      "epoch:15 step:12395 [D loss: 0.678022, acc.: 56.25%] [G loss: 0.763244]\n",
      "epoch:15 step:12396 [D loss: 0.744712, acc.: 40.62%] [G loss: 0.771575]\n",
      "epoch:15 step:12397 [D loss: 0.688451, acc.: 52.34%] [G loss: 0.714945]\n",
      "epoch:15 step:12398 [D loss: 0.703345, acc.: 48.44%] [G loss: 0.732560]\n",
      "epoch:15 step:12399 [D loss: 0.693026, acc.: 51.56%] [G loss: 0.782725]\n",
      "epoch:15 step:12400 [D loss: 0.707239, acc.: 51.56%] [G loss: 0.799372]\n",
      "epoch:15 step:12401 [D loss: 0.694742, acc.: 50.78%] [G loss: 0.797085]\n",
      "epoch:15 step:12402 [D loss: 0.647756, acc.: 58.59%] [G loss: 0.836190]\n",
      "epoch:15 step:12403 [D loss: 0.685531, acc.: 53.12%] [G loss: 0.830877]\n",
      "epoch:15 step:12404 [D loss: 0.709027, acc.: 49.22%] [G loss: 0.726133]\n",
      "epoch:15 step:12405 [D loss: 0.722089, acc.: 46.09%] [G loss: 0.774655]\n",
      "epoch:15 step:12406 [D loss: 0.697872, acc.: 47.66%] [G loss: 0.750087]\n",
      "epoch:15 step:12407 [D loss: 0.766963, acc.: 30.47%] [G loss: 0.733677]\n",
      "epoch:15 step:12408 [D loss: 0.685348, acc.: 58.59%] [G loss: 0.742640]\n",
      "epoch:15 step:12409 [D loss: 0.682789, acc.: 53.91%] [G loss: 0.757805]\n",
      "epoch:15 step:12410 [D loss: 0.637094, acc.: 62.50%] [G loss: 0.749792]\n",
      "epoch:15 step:12411 [D loss: 0.703282, acc.: 50.00%] [G loss: 0.720331]\n",
      "epoch:15 step:12412 [D loss: 0.673148, acc.: 57.81%] [G loss: 0.745654]\n",
      "epoch:15 step:12413 [D loss: 0.646838, acc.: 68.75%] [G loss: 0.777139]\n",
      "epoch:15 step:12414 [D loss: 0.710734, acc.: 50.00%] [G loss: 0.700784]\n",
      "epoch:15 step:12415 [D loss: 0.710985, acc.: 48.44%] [G loss: 0.685889]\n",
      "epoch:15 step:12416 [D loss: 0.648881, acc.: 63.28%] [G loss: 0.675566]\n",
      "epoch:15 step:12417 [D loss: 0.669424, acc.: 59.38%] [G loss: 0.686715]\n",
      "epoch:15 step:12418 [D loss: 0.720224, acc.: 48.44%] [G loss: 0.670785]\n",
      "epoch:15 step:12419 [D loss: 0.638412, acc.: 70.31%] [G loss: 0.706906]\n",
      "epoch:15 step:12420 [D loss: 0.660478, acc.: 61.72%] [G loss: 0.781720]\n",
      "epoch:15 step:12421 [D loss: 0.701959, acc.: 44.53%] [G loss: 0.712454]\n",
      "epoch:15 step:12422 [D loss: 0.682964, acc.: 53.91%] [G loss: 0.751482]\n",
      "epoch:15 step:12423 [D loss: 0.725899, acc.: 47.66%] [G loss: 0.662425]\n",
      "epoch:15 step:12424 [D loss: 0.659792, acc.: 61.72%] [G loss: 0.748771]\n",
      "epoch:15 step:12425 [D loss: 0.663255, acc.: 61.72%] [G loss: 0.811651]\n",
      "epoch:15 step:12426 [D loss: 0.738793, acc.: 50.00%] [G loss: 0.703057]\n",
      "epoch:15 step:12427 [D loss: 0.715823, acc.: 44.53%] [G loss: 0.725950]\n",
      "epoch:15 step:12428 [D loss: 0.698192, acc.: 49.22%] [G loss: 0.804971]\n",
      "epoch:15 step:12429 [D loss: 0.696429, acc.: 54.69%] [G loss: 0.741987]\n",
      "epoch:15 step:12430 [D loss: 0.708751, acc.: 46.09%] [G loss: 0.782372]\n",
      "epoch:15 step:12431 [D loss: 0.693158, acc.: 50.00%] [G loss: 0.756955]\n",
      "epoch:15 step:12432 [D loss: 0.629395, acc.: 67.97%] [G loss: 0.872609]\n",
      "epoch:15 step:12433 [D loss: 0.731113, acc.: 45.31%] [G loss: 0.748758]\n",
      "epoch:15 step:12434 [D loss: 0.696489, acc.: 51.56%] [G loss: 0.753119]\n",
      "epoch:15 step:12435 [D loss: 0.720550, acc.: 47.66%] [G loss: 0.721598]\n",
      "epoch:15 step:12436 [D loss: 0.710079, acc.: 50.78%] [G loss: 0.722943]\n",
      "epoch:15 step:12437 [D loss: 0.650960, acc.: 60.94%] [G loss: 0.773006]\n",
      "epoch:15 step:12438 [D loss: 0.765981, acc.: 40.62%] [G loss: 0.742571]\n",
      "epoch:15 step:12439 [D loss: 0.693346, acc.: 57.03%] [G loss: 0.734965]\n",
      "epoch:15 step:12440 [D loss: 0.659205, acc.: 58.59%] [G loss: 0.733745]\n",
      "epoch:15 step:12441 [D loss: 0.683384, acc.: 57.81%] [G loss: 0.739524]\n",
      "epoch:15 step:12442 [D loss: 0.728519, acc.: 44.53%] [G loss: 0.684462]\n",
      "epoch:15 step:12443 [D loss: 0.670945, acc.: 56.25%] [G loss: 0.763720]\n",
      "epoch:15 step:12444 [D loss: 0.719273, acc.: 43.75%] [G loss: 0.723761]\n",
      "epoch:15 step:12445 [D loss: 0.683501, acc.: 53.12%] [G loss: 0.777755]\n",
      "epoch:15 step:12446 [D loss: 0.636916, acc.: 69.53%] [G loss: 0.720312]\n",
      "epoch:15 step:12447 [D loss: 0.724641, acc.: 47.66%] [G loss: 0.738532]\n",
      "epoch:15 step:12448 [D loss: 0.752870, acc.: 29.69%] [G loss: 0.682985]\n",
      "epoch:15 step:12449 [D loss: 0.681278, acc.: 59.38%] [G loss: 0.736707]\n",
      "epoch:15 step:12450 [D loss: 0.699587, acc.: 46.88%] [G loss: 0.751181]\n",
      "epoch:15 step:12451 [D loss: 0.708926, acc.: 52.34%] [G loss: 0.777040]\n",
      "epoch:15 step:12452 [D loss: 0.710071, acc.: 45.31%] [G loss: 0.761443]\n",
      "epoch:15 step:12453 [D loss: 0.653248, acc.: 66.41%] [G loss: 0.741196]\n",
      "epoch:15 step:12454 [D loss: 0.707797, acc.: 46.09%] [G loss: 0.755771]\n",
      "epoch:15 step:12455 [D loss: 0.722470, acc.: 42.97%] [G loss: 0.681406]\n",
      "epoch:15 step:12456 [D loss: 0.640206, acc.: 67.97%] [G loss: 0.781777]\n",
      "epoch:15 step:12457 [D loss: 0.705142, acc.: 48.44%] [G loss: 0.732916]\n",
      "epoch:15 step:12458 [D loss: 0.712160, acc.: 50.00%] [G loss: 0.755629]\n",
      "epoch:15 step:12459 [D loss: 0.698858, acc.: 50.78%] [G loss: 0.765687]\n",
      "epoch:15 step:12460 [D loss: 0.696372, acc.: 48.44%] [G loss: 0.772555]\n",
      "epoch:15 step:12461 [D loss: 0.712235, acc.: 50.00%] [G loss: 0.757336]\n",
      "epoch:15 step:12462 [D loss: 0.712819, acc.: 51.56%] [G loss: 0.720920]\n",
      "epoch:15 step:12463 [D loss: 0.690606, acc.: 55.47%] [G loss: 0.802210]\n",
      "epoch:15 step:12464 [D loss: 0.658697, acc.: 64.06%] [G loss: 0.719851]\n",
      "epoch:15 step:12465 [D loss: 0.706160, acc.: 50.78%] [G loss: 0.717744]\n",
      "epoch:15 step:12466 [D loss: 0.674141, acc.: 58.59%] [G loss: 0.725296]\n",
      "epoch:15 step:12467 [D loss: 0.698518, acc.: 54.69%] [G loss: 0.792963]\n",
      "epoch:15 step:12468 [D loss: 0.720070, acc.: 43.75%] [G loss: 0.725195]\n",
      "epoch:15 step:12469 [D loss: 0.697525, acc.: 49.22%] [G loss: 0.721814]\n",
      "epoch:15 step:12470 [D loss: 0.692275, acc.: 52.34%] [G loss: 0.782208]\n",
      "epoch:15 step:12471 [D loss: 0.737404, acc.: 47.66%] [G loss: 0.730475]\n",
      "epoch:15 step:12472 [D loss: 0.643189, acc.: 62.50%] [G loss: 0.735422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12473 [D loss: 0.731494, acc.: 42.97%] [G loss: 0.749809]\n",
      "epoch:15 step:12474 [D loss: 0.716151, acc.: 39.84%] [G loss: 0.712323]\n",
      "epoch:15 step:12475 [D loss: 0.678224, acc.: 59.38%] [G loss: 0.775431]\n",
      "epoch:15 step:12476 [D loss: 0.746663, acc.: 41.41%] [G loss: 0.733777]\n",
      "epoch:15 step:12477 [D loss: 0.736098, acc.: 43.75%] [G loss: 0.775101]\n",
      "epoch:15 step:12478 [D loss: 0.764176, acc.: 40.62%] [G loss: 0.705501]\n",
      "epoch:15 step:12479 [D loss: 0.724003, acc.: 47.66%] [G loss: 0.760009]\n",
      "epoch:15 step:12480 [D loss: 0.701389, acc.: 48.44%] [G loss: 0.751795]\n",
      "epoch:15 step:12481 [D loss: 0.685127, acc.: 54.69%] [G loss: 0.845630]\n",
      "epoch:15 step:12482 [D loss: 0.683371, acc.: 53.91%] [G loss: 0.733639]\n",
      "epoch:15 step:12483 [D loss: 0.723781, acc.: 40.62%] [G loss: 0.775001]\n",
      "epoch:15 step:12484 [D loss: 0.676720, acc.: 56.25%] [G loss: 0.816268]\n",
      "epoch:15 step:12485 [D loss: 0.670281, acc.: 59.38%] [G loss: 0.839237]\n",
      "epoch:15 step:12486 [D loss: 0.702967, acc.: 50.00%] [G loss: 0.831073]\n",
      "epoch:15 step:12487 [D loss: 0.683543, acc.: 57.03%] [G loss: 0.814627]\n",
      "epoch:15 step:12488 [D loss: 0.697108, acc.: 53.12%] [G loss: 0.814583]\n",
      "epoch:15 step:12489 [D loss: 0.652537, acc.: 64.84%] [G loss: 0.786901]\n",
      "epoch:15 step:12490 [D loss: 0.690647, acc.: 52.34%] [G loss: 0.821968]\n",
      "epoch:15 step:12491 [D loss: 0.688018, acc.: 51.56%] [G loss: 0.776037]\n",
      "epoch:15 step:12492 [D loss: 0.690594, acc.: 52.34%] [G loss: 0.810659]\n",
      "epoch:15 step:12493 [D loss: 0.689937, acc.: 50.00%] [G loss: 0.721974]\n",
      "epoch:15 step:12494 [D loss: 0.691606, acc.: 53.12%] [G loss: 0.752297]\n",
      "epoch:15 step:12495 [D loss: 0.698659, acc.: 57.03%] [G loss: 0.713932]\n",
      "epoch:15 step:12496 [D loss: 0.608949, acc.: 75.78%] [G loss: 0.799010]\n",
      "epoch:16 step:12497 [D loss: 0.665743, acc.: 56.25%] [G loss: 0.776173]\n",
      "epoch:16 step:12498 [D loss: 0.685726, acc.: 57.81%] [G loss: 0.810462]\n",
      "epoch:16 step:12499 [D loss: 0.701728, acc.: 48.44%] [G loss: 0.776892]\n",
      "epoch:16 step:12500 [D loss: 0.693007, acc.: 60.16%] [G loss: 0.745898]\n",
      "epoch:16 step:12501 [D loss: 0.667525, acc.: 56.25%] [G loss: 0.715014]\n",
      "epoch:16 step:12502 [D loss: 0.724878, acc.: 46.09%] [G loss: 0.749088]\n",
      "epoch:16 step:12503 [D loss: 0.725564, acc.: 39.84%] [G loss: 0.843888]\n",
      "epoch:16 step:12504 [D loss: 0.665753, acc.: 57.81%] [G loss: 0.803122]\n",
      "epoch:16 step:12505 [D loss: 0.660842, acc.: 64.84%] [G loss: 0.858979]\n",
      "epoch:16 step:12506 [D loss: 0.713679, acc.: 50.00%] [G loss: 0.799670]\n",
      "epoch:16 step:12507 [D loss: 0.732976, acc.: 38.28%] [G loss: 0.737064]\n",
      "epoch:16 step:12508 [D loss: 0.737314, acc.: 42.19%] [G loss: 0.721886]\n",
      "epoch:16 step:12509 [D loss: 0.720915, acc.: 48.44%] [G loss: 0.720957]\n",
      "epoch:16 step:12510 [D loss: 0.727034, acc.: 47.66%] [G loss: 0.711872]\n",
      "epoch:16 step:12511 [D loss: 0.705420, acc.: 40.62%] [G loss: 0.747236]\n",
      "epoch:16 step:12512 [D loss: 0.723858, acc.: 44.53%] [G loss: 0.774147]\n",
      "epoch:16 step:12513 [D loss: 0.725266, acc.: 44.53%] [G loss: 0.774412]\n",
      "epoch:16 step:12514 [D loss: 0.750175, acc.: 35.16%] [G loss: 0.760892]\n",
      "epoch:16 step:12515 [D loss: 0.735963, acc.: 43.75%] [G loss: 0.747916]\n",
      "epoch:16 step:12516 [D loss: 0.706725, acc.: 46.09%] [G loss: 0.802798]\n",
      "epoch:16 step:12517 [D loss: 0.662603, acc.: 59.38%] [G loss: 0.852776]\n",
      "epoch:16 step:12518 [D loss: 0.700620, acc.: 46.88%] [G loss: 0.828384]\n",
      "epoch:16 step:12519 [D loss: 0.687457, acc.: 53.91%] [G loss: 0.866896]\n",
      "epoch:16 step:12520 [D loss: 0.691897, acc.: 57.03%] [G loss: 0.805892]\n",
      "epoch:16 step:12521 [D loss: 0.792859, acc.: 33.59%] [G loss: 0.821962]\n",
      "epoch:16 step:12522 [D loss: 0.662165, acc.: 58.59%] [G loss: 0.774123]\n",
      "epoch:16 step:12523 [D loss: 0.670281, acc.: 60.94%] [G loss: 0.742936]\n",
      "epoch:16 step:12524 [D loss: 0.730972, acc.: 42.19%] [G loss: 0.718587]\n",
      "epoch:16 step:12525 [D loss: 0.684211, acc.: 54.69%] [G loss: 0.742862]\n",
      "epoch:16 step:12526 [D loss: 0.688736, acc.: 54.69%] [G loss: 0.733975]\n",
      "epoch:16 step:12527 [D loss: 0.677696, acc.: 56.25%] [G loss: 0.723805]\n",
      "epoch:16 step:12528 [D loss: 0.687499, acc.: 54.69%] [G loss: 0.769965]\n",
      "epoch:16 step:12529 [D loss: 0.702773, acc.: 49.22%] [G loss: 0.842478]\n",
      "epoch:16 step:12530 [D loss: 0.678764, acc.: 60.16%] [G loss: 0.791837]\n",
      "epoch:16 step:12531 [D loss: 0.733701, acc.: 45.31%] [G loss: 0.768372]\n",
      "epoch:16 step:12532 [D loss: 0.685072, acc.: 50.00%] [G loss: 0.810682]\n",
      "epoch:16 step:12533 [D loss: 0.700190, acc.: 51.56%] [G loss: 0.762561]\n",
      "epoch:16 step:12534 [D loss: 0.739038, acc.: 41.41%] [G loss: 0.701597]\n",
      "epoch:16 step:12535 [D loss: 0.694666, acc.: 53.12%] [G loss: 0.815808]\n",
      "epoch:16 step:12536 [D loss: 0.702518, acc.: 51.56%] [G loss: 0.788534]\n",
      "epoch:16 step:12537 [D loss: 0.688991, acc.: 62.50%] [G loss: 0.775571]\n",
      "epoch:16 step:12538 [D loss: 0.688110, acc.: 56.25%] [G loss: 0.704817]\n",
      "epoch:16 step:12539 [D loss: 0.727739, acc.: 46.09%] [G loss: 0.709113]\n",
      "epoch:16 step:12540 [D loss: 0.735450, acc.: 37.50%] [G loss: 0.781131]\n",
      "epoch:16 step:12541 [D loss: 0.679224, acc.: 55.47%] [G loss: 0.748387]\n",
      "epoch:16 step:12542 [D loss: 0.709484, acc.: 41.41%] [G loss: 0.743022]\n",
      "epoch:16 step:12543 [D loss: 0.692558, acc.: 53.91%] [G loss: 0.726785]\n",
      "epoch:16 step:12544 [D loss: 0.700408, acc.: 53.91%] [G loss: 0.735016]\n",
      "epoch:16 step:12545 [D loss: 0.650155, acc.: 60.94%] [G loss: 0.719067]\n",
      "epoch:16 step:12546 [D loss: 0.715693, acc.: 48.44%] [G loss: 0.718328]\n",
      "epoch:16 step:12547 [D loss: 0.711046, acc.: 50.00%] [G loss: 0.740636]\n",
      "epoch:16 step:12548 [D loss: 0.697068, acc.: 48.44%] [G loss: 0.700774]\n",
      "epoch:16 step:12549 [D loss: 0.666834, acc.: 59.38%] [G loss: 0.769839]\n",
      "epoch:16 step:12550 [D loss: 0.713670, acc.: 41.41%] [G loss: 0.722109]\n",
      "epoch:16 step:12551 [D loss: 0.726759, acc.: 44.53%] [G loss: 0.759306]\n",
      "epoch:16 step:12552 [D loss: 0.685439, acc.: 57.81%] [G loss: 0.726457]\n",
      "epoch:16 step:12553 [D loss: 0.715193, acc.: 46.88%] [G loss: 0.727914]\n",
      "epoch:16 step:12554 [D loss: 0.682018, acc.: 55.47%] [G loss: 0.745983]\n",
      "epoch:16 step:12555 [D loss: 0.672813, acc.: 60.16%] [G loss: 0.836446]\n",
      "epoch:16 step:12556 [D loss: 0.667858, acc.: 57.03%] [G loss: 0.828538]\n",
      "epoch:16 step:12557 [D loss: 0.727912, acc.: 41.41%] [G loss: 0.782111]\n",
      "epoch:16 step:12558 [D loss: 0.690734, acc.: 54.69%] [G loss: 0.762575]\n",
      "epoch:16 step:12559 [D loss: 0.709810, acc.: 48.44%] [G loss: 0.773650]\n",
      "epoch:16 step:12560 [D loss: 0.656448, acc.: 60.94%] [G loss: 0.773973]\n",
      "epoch:16 step:12561 [D loss: 0.686992, acc.: 56.25%] [G loss: 0.792539]\n",
      "epoch:16 step:12562 [D loss: 0.724691, acc.: 43.75%] [G loss: 0.830245]\n",
      "epoch:16 step:12563 [D loss: 0.628237, acc.: 65.62%] [G loss: 0.828286]\n",
      "epoch:16 step:12564 [D loss: 0.661671, acc.: 59.38%] [G loss: 0.758784]\n",
      "epoch:16 step:12565 [D loss: 0.734506, acc.: 42.19%] [G loss: 0.715488]\n",
      "epoch:16 step:12566 [D loss: 0.704454, acc.: 53.91%] [G loss: 0.736250]\n",
      "epoch:16 step:12567 [D loss: 0.721412, acc.: 42.97%] [G loss: 0.720846]\n",
      "epoch:16 step:12568 [D loss: 0.741755, acc.: 42.97%] [G loss: 0.689616]\n",
      "epoch:16 step:12569 [D loss: 0.699779, acc.: 53.91%] [G loss: 0.745786]\n",
      "epoch:16 step:12570 [D loss: 0.676732, acc.: 60.94%] [G loss: 0.786357]\n",
      "epoch:16 step:12571 [D loss: 0.647220, acc.: 64.84%] [G loss: 0.793148]\n",
      "epoch:16 step:12572 [D loss: 0.700536, acc.: 53.12%] [G loss: 0.713005]\n",
      "epoch:16 step:12573 [D loss: 0.680622, acc.: 55.47%] [G loss: 0.748887]\n",
      "epoch:16 step:12574 [D loss: 0.768354, acc.: 30.47%] [G loss: 0.721660]\n",
      "epoch:16 step:12575 [D loss: 0.734448, acc.: 39.84%] [G loss: 0.778515]\n",
      "epoch:16 step:12576 [D loss: 0.677405, acc.: 54.69%] [G loss: 0.745658]\n",
      "epoch:16 step:12577 [D loss: 0.701076, acc.: 46.09%] [G loss: 0.772160]\n",
      "epoch:16 step:12578 [D loss: 0.697555, acc.: 51.56%] [G loss: 0.726238]\n",
      "epoch:16 step:12579 [D loss: 0.670091, acc.: 58.59%] [G loss: 0.767779]\n",
      "epoch:16 step:12580 [D loss: 0.760341, acc.: 32.03%] [G loss: 0.743903]\n",
      "epoch:16 step:12581 [D loss: 0.649082, acc.: 58.59%] [G loss: 0.840256]\n",
      "epoch:16 step:12582 [D loss: 0.702554, acc.: 48.44%] [G loss: 0.754302]\n",
      "epoch:16 step:12583 [D loss: 0.728962, acc.: 42.19%] [G loss: 0.735743]\n",
      "epoch:16 step:12584 [D loss: 0.766287, acc.: 35.16%] [G loss: 0.768033]\n",
      "epoch:16 step:12585 [D loss: 0.727405, acc.: 41.41%] [G loss: 0.759960]\n",
      "epoch:16 step:12586 [D loss: 0.711736, acc.: 55.47%] [G loss: 0.727261]\n",
      "epoch:16 step:12587 [D loss: 0.709279, acc.: 50.00%] [G loss: 0.779262]\n",
      "epoch:16 step:12588 [D loss: 0.690948, acc.: 53.91%] [G loss: 0.721492]\n",
      "epoch:16 step:12589 [D loss: 0.692011, acc.: 48.44%] [G loss: 0.779536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12590 [D loss: 0.674586, acc.: 61.72%] [G loss: 0.831218]\n",
      "epoch:16 step:12591 [D loss: 0.736598, acc.: 35.16%] [G loss: 0.698298]\n",
      "epoch:16 step:12592 [D loss: 0.709717, acc.: 49.22%] [G loss: 0.759444]\n",
      "epoch:16 step:12593 [D loss: 0.716797, acc.: 37.50%] [G loss: 0.759591]\n",
      "epoch:16 step:12594 [D loss: 0.743642, acc.: 37.50%] [G loss: 0.722365]\n",
      "epoch:16 step:12595 [D loss: 0.696617, acc.: 47.66%] [G loss: 0.773676]\n",
      "epoch:16 step:12596 [D loss: 0.704477, acc.: 48.44%] [G loss: 0.798337]\n",
      "epoch:16 step:12597 [D loss: 0.710945, acc.: 50.00%] [G loss: 0.794933]\n",
      "epoch:16 step:12598 [D loss: 0.697645, acc.: 53.12%] [G loss: 0.755226]\n",
      "epoch:16 step:12599 [D loss: 0.747997, acc.: 43.75%] [G loss: 0.736858]\n",
      "epoch:16 step:12600 [D loss: 0.696806, acc.: 52.34%] [G loss: 0.779179]\n",
      "epoch:16 step:12601 [D loss: 0.672712, acc.: 60.16%] [G loss: 0.778444]\n",
      "epoch:16 step:12602 [D loss: 0.666537, acc.: 64.84%] [G loss: 0.743047]\n",
      "epoch:16 step:12603 [D loss: 0.719113, acc.: 44.53%] [G loss: 0.740185]\n",
      "epoch:16 step:12604 [D loss: 0.737045, acc.: 36.72%] [G loss: 0.744543]\n",
      "epoch:16 step:12605 [D loss: 0.692829, acc.: 54.69%] [G loss: 0.718962]\n",
      "epoch:16 step:12606 [D loss: 0.729973, acc.: 48.44%] [G loss: 0.670407]\n",
      "epoch:16 step:12607 [D loss: 0.674193, acc.: 62.50%] [G loss: 0.695114]\n",
      "epoch:16 step:12608 [D loss: 0.666852, acc.: 61.72%] [G loss: 0.699121]\n",
      "epoch:16 step:12609 [D loss: 0.706883, acc.: 48.44%] [G loss: 0.801668]\n",
      "epoch:16 step:12610 [D loss: 0.667389, acc.: 59.38%] [G loss: 0.765599]\n",
      "epoch:16 step:12611 [D loss: 0.697557, acc.: 52.34%] [G loss: 0.782546]\n",
      "epoch:16 step:12612 [D loss: 0.680839, acc.: 51.56%] [G loss: 0.773452]\n",
      "epoch:16 step:12613 [D loss: 0.658940, acc.: 59.38%] [G loss: 0.788032]\n",
      "epoch:16 step:12614 [D loss: 0.724731, acc.: 43.75%] [G loss: 0.752658]\n",
      "epoch:16 step:12615 [D loss: 0.648842, acc.: 66.41%] [G loss: 0.737177]\n",
      "epoch:16 step:12616 [D loss: 0.718266, acc.: 44.53%] [G loss: 0.705374]\n",
      "epoch:16 step:12617 [D loss: 0.676598, acc.: 50.00%] [G loss: 0.708522]\n",
      "epoch:16 step:12618 [D loss: 0.742816, acc.: 34.38%] [G loss: 0.670402]\n",
      "epoch:16 step:12619 [D loss: 0.741714, acc.: 46.88%] [G loss: 0.696583]\n",
      "epoch:16 step:12620 [D loss: 0.701024, acc.: 55.47%] [G loss: 0.720999]\n",
      "epoch:16 step:12621 [D loss: 0.729660, acc.: 37.50%] [G loss: 0.725422]\n",
      "epoch:16 step:12622 [D loss: 0.756425, acc.: 34.38%] [G loss: 0.717207]\n",
      "epoch:16 step:12623 [D loss: 0.685669, acc.: 59.38%] [G loss: 0.752553]\n",
      "epoch:16 step:12624 [D loss: 0.682208, acc.: 53.91%] [G loss: 0.765095]\n",
      "epoch:16 step:12625 [D loss: 0.710844, acc.: 50.78%] [G loss: 0.737496]\n",
      "epoch:16 step:12626 [D loss: 0.719483, acc.: 42.19%] [G loss: 0.715689]\n",
      "epoch:16 step:12627 [D loss: 0.714255, acc.: 46.88%] [G loss: 0.674801]\n",
      "epoch:16 step:12628 [D loss: 0.698649, acc.: 51.56%] [G loss: 0.737877]\n",
      "epoch:16 step:12629 [D loss: 0.644367, acc.: 65.62%] [G loss: 0.706416]\n",
      "epoch:16 step:12630 [D loss: 0.710791, acc.: 51.56%] [G loss: 0.805095]\n",
      "epoch:16 step:12631 [D loss: 0.726789, acc.: 41.41%] [G loss: 0.703910]\n",
      "epoch:16 step:12632 [D loss: 0.740243, acc.: 39.06%] [G loss: 0.726711]\n",
      "epoch:16 step:12633 [D loss: 0.668498, acc.: 56.25%] [G loss: 0.780925]\n",
      "epoch:16 step:12634 [D loss: 0.755554, acc.: 42.97%] [G loss: 0.726467]\n",
      "epoch:16 step:12635 [D loss: 0.684943, acc.: 49.22%] [G loss: 0.644158]\n",
      "epoch:16 step:12636 [D loss: 0.694097, acc.: 51.56%] [G loss: 0.734021]\n",
      "epoch:16 step:12637 [D loss: 0.695256, acc.: 51.56%] [G loss: 0.777708]\n",
      "epoch:16 step:12638 [D loss: 0.729628, acc.: 46.88%] [G loss: 0.703090]\n",
      "epoch:16 step:12639 [D loss: 0.698484, acc.: 52.34%] [G loss: 0.769224]\n",
      "epoch:16 step:12640 [D loss: 0.702895, acc.: 51.56%] [G loss: 0.742469]\n",
      "epoch:16 step:12641 [D loss: 0.723394, acc.: 44.53%] [G loss: 0.830805]\n",
      "epoch:16 step:12642 [D loss: 0.623866, acc.: 64.84%] [G loss: 0.850045]\n",
      "epoch:16 step:12643 [D loss: 0.676717, acc.: 59.38%] [G loss: 0.814127]\n",
      "epoch:16 step:12644 [D loss: 0.679882, acc.: 57.03%] [G loss: 0.828716]\n",
      "epoch:16 step:12645 [D loss: 0.708770, acc.: 39.84%] [G loss: 0.742791]\n",
      "epoch:16 step:12646 [D loss: 0.750534, acc.: 46.09%] [G loss: 0.710195]\n",
      "epoch:16 step:12647 [D loss: 0.674946, acc.: 57.03%] [G loss: 0.792387]\n",
      "epoch:16 step:12648 [D loss: 0.675013, acc.: 64.06%] [G loss: 0.770345]\n",
      "epoch:16 step:12649 [D loss: 0.705505, acc.: 48.44%] [G loss: 0.744957]\n",
      "epoch:16 step:12650 [D loss: 0.691863, acc.: 56.25%] [G loss: 0.787586]\n",
      "epoch:16 step:12651 [D loss: 0.730294, acc.: 42.19%] [G loss: 0.752841]\n",
      "epoch:16 step:12652 [D loss: 0.750932, acc.: 41.41%] [G loss: 0.758926]\n",
      "epoch:16 step:12653 [D loss: 0.653737, acc.: 61.72%] [G loss: 0.712901]\n",
      "epoch:16 step:12654 [D loss: 0.678555, acc.: 60.16%] [G loss: 0.745406]\n",
      "epoch:16 step:12655 [D loss: 0.654734, acc.: 65.62%] [G loss: 0.829486]\n",
      "epoch:16 step:12656 [D loss: 0.681288, acc.: 55.47%] [G loss: 0.774801]\n",
      "epoch:16 step:12657 [D loss: 0.704424, acc.: 52.34%] [G loss: 0.803175]\n",
      "epoch:16 step:12658 [D loss: 0.688169, acc.: 54.69%] [G loss: 0.753292]\n",
      "epoch:16 step:12659 [D loss: 0.728417, acc.: 47.66%] [G loss: 0.797644]\n",
      "epoch:16 step:12660 [D loss: 0.688706, acc.: 54.69%] [G loss: 0.773395]\n",
      "epoch:16 step:12661 [D loss: 0.712034, acc.: 49.22%] [G loss: 0.798940]\n",
      "epoch:16 step:12662 [D loss: 0.713284, acc.: 44.53%] [G loss: 0.793715]\n",
      "epoch:16 step:12663 [D loss: 0.683840, acc.: 60.94%] [G loss: 0.838822]\n",
      "epoch:16 step:12664 [D loss: 0.681906, acc.: 56.25%] [G loss: 0.720648]\n",
      "epoch:16 step:12665 [D loss: 0.696488, acc.: 53.12%] [G loss: 0.746447]\n",
      "epoch:16 step:12666 [D loss: 0.685297, acc.: 55.47%] [G loss: 0.774074]\n",
      "epoch:16 step:12667 [D loss: 0.722508, acc.: 51.56%] [G loss: 0.750530]\n",
      "epoch:16 step:12668 [D loss: 0.695019, acc.: 52.34%] [G loss: 0.755977]\n",
      "epoch:16 step:12669 [D loss: 0.705891, acc.: 44.53%] [G loss: 0.797459]\n",
      "epoch:16 step:12670 [D loss: 0.731190, acc.: 42.97%] [G loss: 0.767846]\n",
      "epoch:16 step:12671 [D loss: 0.711067, acc.: 42.97%] [G loss: 0.769758]\n",
      "epoch:16 step:12672 [D loss: 0.735661, acc.: 40.62%] [G loss: 0.722918]\n",
      "epoch:16 step:12673 [D loss: 0.717917, acc.: 41.41%] [G loss: 0.757545]\n",
      "epoch:16 step:12674 [D loss: 0.679086, acc.: 52.34%] [G loss: 0.789773]\n",
      "epoch:16 step:12675 [D loss: 0.727533, acc.: 42.97%] [G loss: 0.741810]\n",
      "epoch:16 step:12676 [D loss: 0.693375, acc.: 49.22%] [G loss: 0.730640]\n",
      "epoch:16 step:12677 [D loss: 0.637825, acc.: 67.19%] [G loss: 0.844801]\n",
      "epoch:16 step:12678 [D loss: 0.743178, acc.: 36.72%] [G loss: 0.722198]\n",
      "epoch:16 step:12679 [D loss: 0.682373, acc.: 57.03%] [G loss: 0.805448]\n",
      "epoch:16 step:12680 [D loss: 0.666145, acc.: 59.38%] [G loss: 0.784550]\n",
      "epoch:16 step:12681 [D loss: 0.686658, acc.: 56.25%] [G loss: 0.793360]\n",
      "epoch:16 step:12682 [D loss: 0.674853, acc.: 56.25%] [G loss: 0.762465]\n",
      "epoch:16 step:12683 [D loss: 0.686749, acc.: 53.91%] [G loss: 0.788847]\n",
      "epoch:16 step:12684 [D loss: 0.752430, acc.: 37.50%] [G loss: 0.794572]\n",
      "epoch:16 step:12685 [D loss: 0.668918, acc.: 54.69%] [G loss: 0.688902]\n",
      "epoch:16 step:12686 [D loss: 0.686003, acc.: 57.81%] [G loss: 0.682895]\n",
      "epoch:16 step:12687 [D loss: 0.665552, acc.: 60.16%] [G loss: 0.745203]\n",
      "epoch:16 step:12688 [D loss: 0.650603, acc.: 65.62%] [G loss: 0.774989]\n",
      "epoch:16 step:12689 [D loss: 0.642342, acc.: 64.84%] [G loss: 0.802978]\n",
      "epoch:16 step:12690 [D loss: 0.670579, acc.: 60.16%] [G loss: 0.679792]\n",
      "epoch:16 step:12691 [D loss: 0.706490, acc.: 49.22%] [G loss: 0.684771]\n",
      "epoch:16 step:12692 [D loss: 0.754457, acc.: 32.03%] [G loss: 0.687954]\n",
      "epoch:16 step:12693 [D loss: 0.709336, acc.: 51.56%] [G loss: 0.679223]\n",
      "epoch:16 step:12694 [D loss: 0.629219, acc.: 67.97%] [G loss: 0.810938]\n",
      "epoch:16 step:12695 [D loss: 0.702873, acc.: 46.09%] [G loss: 0.697692]\n",
      "epoch:16 step:12696 [D loss: 0.733129, acc.: 41.41%] [G loss: 0.738195]\n",
      "epoch:16 step:12697 [D loss: 0.685226, acc.: 56.25%] [G loss: 0.783750]\n",
      "epoch:16 step:12698 [D loss: 0.786603, acc.: 35.16%] [G loss: 0.703378]\n",
      "epoch:16 step:12699 [D loss: 0.669313, acc.: 62.50%] [G loss: 0.726863]\n",
      "epoch:16 step:12700 [D loss: 0.708920, acc.: 50.78%] [G loss: 0.777912]\n",
      "epoch:16 step:12701 [D loss: 0.742722, acc.: 44.53%] [G loss: 0.671853]\n",
      "epoch:16 step:12702 [D loss: 0.742767, acc.: 44.53%] [G loss: 0.723433]\n",
      "epoch:16 step:12703 [D loss: 0.670128, acc.: 60.16%] [G loss: 0.735291]\n",
      "epoch:16 step:12704 [D loss: 0.677423, acc.: 57.03%] [G loss: 0.775639]\n",
      "epoch:16 step:12705 [D loss: 0.669116, acc.: 62.50%] [G loss: 0.765084]\n",
      "epoch:16 step:12706 [D loss: 0.702076, acc.: 54.69%] [G loss: 0.732198]\n",
      "epoch:16 step:12707 [D loss: 0.676163, acc.: 63.28%] [G loss: 0.774788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12708 [D loss: 0.665618, acc.: 56.25%] [G loss: 0.785465]\n",
      "epoch:16 step:12709 [D loss: 0.726947, acc.: 43.75%] [G loss: 0.730631]\n",
      "epoch:16 step:12710 [D loss: 0.699938, acc.: 45.31%] [G loss: 0.763068]\n",
      "epoch:16 step:12711 [D loss: 0.687122, acc.: 51.56%] [G loss: 0.758148]\n",
      "epoch:16 step:12712 [D loss: 0.674067, acc.: 61.72%] [G loss: 0.827676]\n",
      "epoch:16 step:12713 [D loss: 0.685616, acc.: 57.81%] [G loss: 0.775348]\n",
      "epoch:16 step:12714 [D loss: 0.672797, acc.: 55.47%] [G loss: 0.819903]\n",
      "epoch:16 step:12715 [D loss: 0.669409, acc.: 60.94%] [G loss: 0.776554]\n",
      "epoch:16 step:12716 [D loss: 0.626257, acc.: 67.19%] [G loss: 0.857610]\n",
      "epoch:16 step:12717 [D loss: 0.696952, acc.: 51.56%] [G loss: 0.774457]\n",
      "epoch:16 step:12718 [D loss: 0.682949, acc.: 54.69%] [G loss: 0.724534]\n",
      "epoch:16 step:12719 [D loss: 0.735525, acc.: 42.19%] [G loss: 0.761712]\n",
      "epoch:16 step:12720 [D loss: 0.688765, acc.: 57.81%] [G loss: 0.741619]\n",
      "epoch:16 step:12721 [D loss: 0.680462, acc.: 53.12%] [G loss: 0.679032]\n",
      "epoch:16 step:12722 [D loss: 0.721063, acc.: 44.53%] [G loss: 0.735647]\n",
      "epoch:16 step:12723 [D loss: 0.733320, acc.: 44.53%] [G loss: 0.821679]\n",
      "epoch:16 step:12724 [D loss: 0.683086, acc.: 57.81%] [G loss: 0.804199]\n",
      "epoch:16 step:12725 [D loss: 0.666118, acc.: 61.72%] [G loss: 0.752607]\n",
      "epoch:16 step:12726 [D loss: 0.688540, acc.: 51.56%] [G loss: 0.725987]\n",
      "epoch:16 step:12727 [D loss: 0.643533, acc.: 69.53%] [G loss: 0.790616]\n",
      "epoch:16 step:12728 [D loss: 0.678890, acc.: 57.03%] [G loss: 0.770692]\n",
      "epoch:16 step:12729 [D loss: 0.660972, acc.: 65.62%] [G loss: 0.679951]\n",
      "epoch:16 step:12730 [D loss: 0.828739, acc.: 23.44%] [G loss: 0.664066]\n",
      "epoch:16 step:12731 [D loss: 0.784403, acc.: 31.25%] [G loss: 0.639343]\n",
      "epoch:16 step:12732 [D loss: 0.697511, acc.: 53.91%] [G loss: 0.684533]\n",
      "epoch:16 step:12733 [D loss: 0.678278, acc.: 53.12%] [G loss: 0.677891]\n",
      "epoch:16 step:12734 [D loss: 0.734026, acc.: 42.19%] [G loss: 0.748687]\n",
      "epoch:16 step:12735 [D loss: 0.683388, acc.: 56.25%] [G loss: 0.734215]\n",
      "epoch:16 step:12736 [D loss: 0.741367, acc.: 36.72%] [G loss: 0.713815]\n",
      "epoch:16 step:12737 [D loss: 0.731686, acc.: 43.75%] [G loss: 0.740693]\n",
      "epoch:16 step:12738 [D loss: 0.705821, acc.: 46.88%] [G loss: 0.730107]\n",
      "epoch:16 step:12739 [D loss: 0.733391, acc.: 41.41%] [G loss: 0.763588]\n",
      "epoch:16 step:12740 [D loss: 0.698106, acc.: 50.00%] [G loss: 0.730597]\n",
      "epoch:16 step:12741 [D loss: 0.734969, acc.: 46.09%] [G loss: 0.786448]\n",
      "epoch:16 step:12742 [D loss: 0.723710, acc.: 44.53%] [G loss: 0.747534]\n",
      "epoch:16 step:12743 [D loss: 0.633652, acc.: 71.09%] [G loss: 0.733366]\n",
      "epoch:16 step:12744 [D loss: 0.681659, acc.: 57.81%] [G loss: 0.689589]\n",
      "epoch:16 step:12745 [D loss: 0.700495, acc.: 53.12%] [G loss: 0.673278]\n",
      "epoch:16 step:12746 [D loss: 0.682076, acc.: 56.25%] [G loss: 0.739609]\n",
      "epoch:16 step:12747 [D loss: 0.684327, acc.: 57.03%] [G loss: 0.722323]\n",
      "epoch:16 step:12748 [D loss: 0.703309, acc.: 53.12%] [G loss: 0.712870]\n",
      "epoch:16 step:12749 [D loss: 0.715345, acc.: 42.97%] [G loss: 0.787929]\n",
      "epoch:16 step:12750 [D loss: 0.691233, acc.: 49.22%] [G loss: 0.798682]\n",
      "epoch:16 step:12751 [D loss: 0.716602, acc.: 44.53%] [G loss: 0.757150]\n",
      "epoch:16 step:12752 [D loss: 0.691507, acc.: 51.56%] [G loss: 0.733267]\n",
      "epoch:16 step:12753 [D loss: 0.689704, acc.: 54.69%] [G loss: 0.727441]\n",
      "epoch:16 step:12754 [D loss: 0.691067, acc.: 51.56%] [G loss: 0.689268]\n",
      "epoch:16 step:12755 [D loss: 0.729214, acc.: 41.41%] [G loss: 0.753330]\n",
      "epoch:16 step:12756 [D loss: 0.642811, acc.: 68.75%] [G loss: 0.783653]\n",
      "epoch:16 step:12757 [D loss: 0.714442, acc.: 47.66%] [G loss: 0.807731]\n",
      "epoch:16 step:12758 [D loss: 0.681093, acc.: 54.69%] [G loss: 0.780272]\n",
      "epoch:16 step:12759 [D loss: 0.701272, acc.: 53.91%] [G loss: 0.809568]\n",
      "epoch:16 step:12760 [D loss: 0.738041, acc.: 42.97%] [G loss: 0.752036]\n",
      "epoch:16 step:12761 [D loss: 0.645389, acc.: 67.97%] [G loss: 0.757802]\n",
      "epoch:16 step:12762 [D loss: 0.659917, acc.: 57.03%] [G loss: 0.790618]\n",
      "epoch:16 step:12763 [D loss: 0.812296, acc.: 29.69%] [G loss: 0.701238]\n",
      "epoch:16 step:12764 [D loss: 0.690869, acc.: 48.44%] [G loss: 0.722806]\n",
      "epoch:16 step:12765 [D loss: 0.692850, acc.: 55.47%] [G loss: 0.690627]\n",
      "epoch:16 step:12766 [D loss: 0.689655, acc.: 51.56%] [G loss: 0.758881]\n",
      "epoch:16 step:12767 [D loss: 0.709388, acc.: 41.41%] [G loss: 0.761348]\n",
      "epoch:16 step:12768 [D loss: 0.698620, acc.: 53.12%] [G loss: 0.686066]\n",
      "epoch:16 step:12769 [D loss: 0.694047, acc.: 56.25%] [G loss: 0.782215]\n",
      "epoch:16 step:12770 [D loss: 0.732955, acc.: 42.97%] [G loss: 0.767548]\n",
      "epoch:16 step:12771 [D loss: 0.680214, acc.: 53.12%] [G loss: 0.780032]\n",
      "epoch:16 step:12772 [D loss: 0.728967, acc.: 42.97%] [G loss: 0.847978]\n",
      "epoch:16 step:12773 [D loss: 0.786827, acc.: 36.72%] [G loss: 0.767392]\n",
      "epoch:16 step:12774 [D loss: 0.741031, acc.: 42.97%] [G loss: 0.682330]\n",
      "epoch:16 step:12775 [D loss: 0.698787, acc.: 53.12%] [G loss: 0.741738]\n",
      "epoch:16 step:12776 [D loss: 0.678502, acc.: 57.03%] [G loss: 0.822484]\n",
      "epoch:16 step:12777 [D loss: 0.681374, acc.: 65.62%] [G loss: 0.721956]\n",
      "epoch:16 step:12778 [D loss: 0.671111, acc.: 57.81%] [G loss: 0.783695]\n",
      "epoch:16 step:12779 [D loss: 0.626171, acc.: 73.44%] [G loss: 0.760762]\n",
      "epoch:16 step:12780 [D loss: 0.713043, acc.: 46.88%] [G loss: 0.710824]\n",
      "epoch:16 step:12781 [D loss: 0.651403, acc.: 67.19%] [G loss: 0.742721]\n",
      "epoch:16 step:12782 [D loss: 0.657346, acc.: 64.84%] [G loss: 0.730506]\n",
      "epoch:16 step:12783 [D loss: 0.755639, acc.: 37.50%] [G loss: 0.644660]\n",
      "epoch:16 step:12784 [D loss: 0.721782, acc.: 43.75%] [G loss: 0.710882]\n",
      "epoch:16 step:12785 [D loss: 0.712104, acc.: 42.19%] [G loss: 0.730862]\n",
      "epoch:16 step:12786 [D loss: 0.699699, acc.: 53.91%] [G loss: 0.731022]\n",
      "epoch:16 step:12787 [D loss: 0.691456, acc.: 55.47%] [G loss: 0.713507]\n",
      "epoch:16 step:12788 [D loss: 0.673085, acc.: 64.06%] [G loss: 0.696959]\n",
      "epoch:16 step:12789 [D loss: 0.695757, acc.: 51.56%] [G loss: 0.653255]\n",
      "epoch:16 step:12790 [D loss: 0.695235, acc.: 55.47%] [G loss: 0.716781]\n",
      "epoch:16 step:12791 [D loss: 0.724747, acc.: 45.31%] [G loss: 0.771803]\n",
      "epoch:16 step:12792 [D loss: 0.718388, acc.: 48.44%] [G loss: 0.768611]\n",
      "epoch:16 step:12793 [D loss: 0.723599, acc.: 46.88%] [G loss: 0.773782]\n",
      "epoch:16 step:12794 [D loss: 0.635940, acc.: 71.09%] [G loss: 0.754980]\n",
      "epoch:16 step:12795 [D loss: 0.718053, acc.: 50.00%] [G loss: 0.732478]\n",
      "epoch:16 step:12796 [D loss: 0.709711, acc.: 52.34%] [G loss: 0.728514]\n",
      "epoch:16 step:12797 [D loss: 0.722149, acc.: 39.84%] [G loss: 0.706974]\n",
      "epoch:16 step:12798 [D loss: 0.667498, acc.: 57.03%] [G loss: 0.760366]\n",
      "epoch:16 step:12799 [D loss: 0.648583, acc.: 65.62%] [G loss: 0.735306]\n",
      "epoch:16 step:12800 [D loss: 0.664541, acc.: 57.81%] [G loss: 0.780814]\n",
      "epoch:16 step:12801 [D loss: 0.695150, acc.: 51.56%] [G loss: 0.739448]\n",
      "epoch:16 step:12802 [D loss: 0.667561, acc.: 61.72%] [G loss: 0.812422]\n",
      "epoch:16 step:12803 [D loss: 0.700565, acc.: 56.25%] [G loss: 0.764339]\n",
      "epoch:16 step:12804 [D loss: 0.707773, acc.: 46.88%] [G loss: 0.744042]\n",
      "epoch:16 step:12805 [D loss: 0.694785, acc.: 51.56%] [G loss: 0.722882]\n",
      "epoch:16 step:12806 [D loss: 0.703292, acc.: 48.44%] [G loss: 0.770026]\n",
      "epoch:16 step:12807 [D loss: 0.659615, acc.: 61.72%] [G loss: 0.719871]\n",
      "epoch:16 step:12808 [D loss: 0.718217, acc.: 43.75%] [G loss: 0.729986]\n",
      "epoch:16 step:12809 [D loss: 0.658704, acc.: 60.94%] [G loss: 0.712781]\n",
      "epoch:16 step:12810 [D loss: 0.678491, acc.: 60.16%] [G loss: 0.749743]\n",
      "epoch:16 step:12811 [D loss: 0.726015, acc.: 40.62%] [G loss: 0.766507]\n",
      "epoch:16 step:12812 [D loss: 0.697047, acc.: 56.25%] [G loss: 0.694670]\n",
      "epoch:16 step:12813 [D loss: 0.681170, acc.: 57.81%] [G loss: 0.680783]\n",
      "epoch:16 step:12814 [D loss: 0.644189, acc.: 66.41%] [G loss: 0.778797]\n",
      "epoch:16 step:12815 [D loss: 0.688466, acc.: 55.47%] [G loss: 0.774854]\n",
      "epoch:16 step:12816 [D loss: 0.670815, acc.: 57.03%] [G loss: 0.676027]\n",
      "epoch:16 step:12817 [D loss: 0.680278, acc.: 56.25%] [G loss: 0.712605]\n",
      "epoch:16 step:12818 [D loss: 0.725586, acc.: 45.31%] [G loss: 0.711151]\n",
      "epoch:16 step:12819 [D loss: 0.742261, acc.: 44.53%] [G loss: 0.727372]\n",
      "epoch:16 step:12820 [D loss: 0.688314, acc.: 53.12%] [G loss: 0.725563]\n",
      "epoch:16 step:12821 [D loss: 0.737062, acc.: 44.53%] [G loss: 0.752494]\n",
      "epoch:16 step:12822 [D loss: 0.719308, acc.: 45.31%] [G loss: 0.771656]\n",
      "epoch:16 step:12823 [D loss: 0.690267, acc.: 49.22%] [G loss: 0.815028]\n",
      "epoch:16 step:12824 [D loss: 0.688537, acc.: 51.56%] [G loss: 0.888750]\n",
      "epoch:16 step:12825 [D loss: 0.759826, acc.: 40.62%] [G loss: 0.774319]\n",
      "epoch:16 step:12826 [D loss: 0.734421, acc.: 45.31%] [G loss: 0.709119]\n",
      "epoch:16 step:12827 [D loss: 0.721585, acc.: 45.31%] [G loss: 0.759675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12828 [D loss: 0.743599, acc.: 39.84%] [G loss: 0.786892]\n",
      "epoch:16 step:12829 [D loss: 0.682592, acc.: 53.91%] [G loss: 0.787897]\n",
      "epoch:16 step:12830 [D loss: 0.641870, acc.: 63.28%] [G loss: 0.892136]\n",
      "epoch:16 step:12831 [D loss: 0.684093, acc.: 57.81%] [G loss: 0.818748]\n",
      "epoch:16 step:12832 [D loss: 0.621461, acc.: 69.53%] [G loss: 0.841457]\n",
      "epoch:16 step:12833 [D loss: 0.691933, acc.: 53.12%] [G loss: 0.834345]\n",
      "epoch:16 step:12834 [D loss: 0.708373, acc.: 53.12%] [G loss: 0.871788]\n",
      "epoch:16 step:12835 [D loss: 0.639716, acc.: 74.22%] [G loss: 0.830068]\n",
      "epoch:16 step:12836 [D loss: 0.623790, acc.: 71.09%] [G loss: 0.731520]\n",
      "epoch:16 step:12837 [D loss: 0.657897, acc.: 62.50%] [G loss: 0.779557]\n",
      "epoch:16 step:12838 [D loss: 0.750027, acc.: 39.06%] [G loss: 0.724281]\n",
      "epoch:16 step:12839 [D loss: 0.678583, acc.: 55.47%] [G loss: 0.760676]\n",
      "epoch:16 step:12840 [D loss: 0.680084, acc.: 53.12%] [G loss: 0.683252]\n",
      "epoch:16 step:12841 [D loss: 0.720172, acc.: 45.31%] [G loss: 0.613756]\n",
      "epoch:16 step:12842 [D loss: 0.671033, acc.: 54.69%] [G loss: 0.704441]\n",
      "epoch:16 step:12843 [D loss: 0.749270, acc.: 35.94%] [G loss: 0.702632]\n",
      "epoch:16 step:12844 [D loss: 0.692689, acc.: 52.34%] [G loss: 0.694821]\n",
      "epoch:16 step:12845 [D loss: 0.714986, acc.: 45.31%] [G loss: 0.726396]\n",
      "epoch:16 step:12846 [D loss: 0.759771, acc.: 36.72%] [G loss: 0.750788]\n",
      "epoch:16 step:12847 [D loss: 0.716539, acc.: 45.31%] [G loss: 0.724075]\n",
      "epoch:16 step:12848 [D loss: 0.759591, acc.: 35.16%] [G loss: 0.800250]\n",
      "epoch:16 step:12849 [D loss: 0.713652, acc.: 49.22%] [G loss: 0.756383]\n",
      "epoch:16 step:12850 [D loss: 0.697364, acc.: 50.00%] [G loss: 0.733722]\n",
      "epoch:16 step:12851 [D loss: 0.695992, acc.: 48.44%] [G loss: 0.742340]\n",
      "epoch:16 step:12852 [D loss: 0.681562, acc.: 50.78%] [G loss: 0.689207]\n",
      "epoch:16 step:12853 [D loss: 0.688637, acc.: 50.78%] [G loss: 0.727432]\n",
      "epoch:16 step:12854 [D loss: 0.711296, acc.: 46.09%] [G loss: 0.773466]\n",
      "epoch:16 step:12855 [D loss: 0.697571, acc.: 53.91%] [G loss: 0.745539]\n",
      "epoch:16 step:12856 [D loss: 0.718302, acc.: 50.00%] [G loss: 0.737344]\n",
      "epoch:16 step:12857 [D loss: 0.685305, acc.: 53.12%] [G loss: 0.761348]\n",
      "epoch:16 step:12858 [D loss: 0.728850, acc.: 37.50%] [G loss: 0.686251]\n",
      "epoch:16 step:12859 [D loss: 0.794921, acc.: 27.34%] [G loss: 0.696141]\n",
      "epoch:16 step:12860 [D loss: 0.695264, acc.: 50.00%] [G loss: 0.698825]\n",
      "epoch:16 step:12861 [D loss: 0.648143, acc.: 64.84%] [G loss: 0.730725]\n",
      "epoch:16 step:12862 [D loss: 0.682313, acc.: 57.81%] [G loss: 0.741643]\n",
      "epoch:16 step:12863 [D loss: 0.694592, acc.: 52.34%] [G loss: 0.712393]\n",
      "epoch:16 step:12864 [D loss: 0.706583, acc.: 45.31%] [G loss: 0.753187]\n",
      "epoch:16 step:12865 [D loss: 0.695458, acc.: 60.94%] [G loss: 0.810639]\n",
      "epoch:16 step:12866 [D loss: 0.663697, acc.: 65.62%] [G loss: 0.745127]\n",
      "epoch:16 step:12867 [D loss: 0.672423, acc.: 61.72%] [G loss: 0.717386]\n",
      "epoch:16 step:12868 [D loss: 0.630586, acc.: 71.88%] [G loss: 0.859999]\n",
      "epoch:16 step:12869 [D loss: 0.651685, acc.: 57.03%] [G loss: 0.807845]\n",
      "epoch:16 step:12870 [D loss: 0.654929, acc.: 61.72%] [G loss: 0.806179]\n",
      "epoch:16 step:12871 [D loss: 0.670936, acc.: 55.47%] [G loss: 0.758159]\n",
      "epoch:16 step:12872 [D loss: 0.654952, acc.: 64.84%] [G loss: 0.764194]\n",
      "epoch:16 step:12873 [D loss: 0.666320, acc.: 60.16%] [G loss: 0.749562]\n",
      "epoch:16 step:12874 [D loss: 0.670510, acc.: 58.59%] [G loss: 0.765416]\n",
      "epoch:16 step:12875 [D loss: 0.710289, acc.: 55.47%] [G loss: 0.741869]\n",
      "epoch:16 step:12876 [D loss: 0.759897, acc.: 31.25%] [G loss: 0.760074]\n",
      "epoch:16 step:12877 [D loss: 0.699065, acc.: 50.78%] [G loss: 0.661304]\n",
      "epoch:16 step:12878 [D loss: 0.744856, acc.: 36.72%] [G loss: 0.738737]\n",
      "epoch:16 step:12879 [D loss: 0.732135, acc.: 37.50%] [G loss: 0.732522]\n",
      "epoch:16 step:12880 [D loss: 0.713202, acc.: 43.75%] [G loss: 0.728959]\n",
      "epoch:16 step:12881 [D loss: 0.723216, acc.: 42.97%] [G loss: 0.743850]\n",
      "epoch:16 step:12882 [D loss: 0.681395, acc.: 58.59%] [G loss: 0.711115]\n",
      "epoch:16 step:12883 [D loss: 0.685443, acc.: 55.47%] [G loss: 0.757793]\n",
      "epoch:16 step:12884 [D loss: 0.671702, acc.: 55.47%] [G loss: 0.823397]\n",
      "epoch:16 step:12885 [D loss: 0.659873, acc.: 62.50%] [G loss: 0.763890]\n",
      "epoch:16 step:12886 [D loss: 0.709083, acc.: 49.22%] [G loss: 0.780048]\n",
      "epoch:16 step:12887 [D loss: 0.728856, acc.: 45.31%] [G loss: 0.794945]\n",
      "epoch:16 step:12888 [D loss: 0.735241, acc.: 45.31%] [G loss: 0.777927]\n",
      "epoch:16 step:12889 [D loss: 0.755410, acc.: 41.41%] [G loss: 0.747646]\n",
      "epoch:16 step:12890 [D loss: 0.672269, acc.: 62.50%] [G loss: 0.786764]\n",
      "epoch:16 step:12891 [D loss: 0.677785, acc.: 57.03%] [G loss: 0.826890]\n",
      "epoch:16 step:12892 [D loss: 0.685972, acc.: 53.12%] [G loss: 0.742253]\n",
      "epoch:16 step:12893 [D loss: 0.661411, acc.: 61.72%] [G loss: 0.798710]\n",
      "epoch:16 step:12894 [D loss: 0.668529, acc.: 60.16%] [G loss: 0.709620]\n",
      "epoch:16 step:12895 [D loss: 0.684531, acc.: 61.72%] [G loss: 0.780987]\n",
      "epoch:16 step:12896 [D loss: 0.763256, acc.: 33.59%] [G loss: 0.686826]\n",
      "epoch:16 step:12897 [D loss: 0.630768, acc.: 75.00%] [G loss: 0.736538]\n",
      "epoch:16 step:12898 [D loss: 0.655941, acc.: 60.94%] [G loss: 0.725254]\n",
      "epoch:16 step:12899 [D loss: 0.681075, acc.: 58.59%] [G loss: 0.703929]\n",
      "epoch:16 step:12900 [D loss: 0.643951, acc.: 65.62%] [G loss: 0.778962]\n",
      "epoch:16 step:12901 [D loss: 0.743857, acc.: 38.28%] [G loss: 0.725756]\n",
      "epoch:16 step:12902 [D loss: 0.685536, acc.: 53.91%] [G loss: 0.814084]\n",
      "epoch:16 step:12903 [D loss: 0.675257, acc.: 63.28%] [G loss: 0.717971]\n",
      "epoch:16 step:12904 [D loss: 0.678926, acc.: 58.59%] [G loss: 0.743347]\n",
      "epoch:16 step:12905 [D loss: 0.622114, acc.: 69.53%] [G loss: 0.744771]\n",
      "epoch:16 step:12906 [D loss: 0.717030, acc.: 42.19%] [G loss: 0.707972]\n",
      "epoch:16 step:12907 [D loss: 0.770756, acc.: 35.94%] [G loss: 0.764780]\n",
      "epoch:16 step:12908 [D loss: 0.687870, acc.: 52.34%] [G loss: 0.720749]\n",
      "epoch:16 step:12909 [D loss: 0.736465, acc.: 41.41%] [G loss: 0.750406]\n",
      "epoch:16 step:12910 [D loss: 0.773140, acc.: 35.16%] [G loss: 0.688130]\n",
      "epoch:16 step:12911 [D loss: 0.685346, acc.: 55.47%] [G loss: 0.762878]\n",
      "epoch:16 step:12912 [D loss: 0.652832, acc.: 63.28%] [G loss: 0.775442]\n",
      "epoch:16 step:12913 [D loss: 0.719902, acc.: 42.97%] [G loss: 0.783547]\n",
      "epoch:16 step:12914 [D loss: 0.661663, acc.: 62.50%] [G loss: 0.827415]\n",
      "epoch:16 step:12915 [D loss: 0.662230, acc.: 64.06%] [G loss: 0.772105]\n",
      "epoch:16 step:12916 [D loss: 0.657913, acc.: 64.84%] [G loss: 0.766886]\n",
      "epoch:16 step:12917 [D loss: 0.726514, acc.: 49.22%] [G loss: 0.753479]\n",
      "epoch:16 step:12918 [D loss: 0.676011, acc.: 61.72%] [G loss: 0.747635]\n",
      "epoch:16 step:12919 [D loss: 0.710940, acc.: 50.00%] [G loss: 0.736990]\n",
      "epoch:16 step:12920 [D loss: 0.682966, acc.: 62.50%] [G loss: 0.735124]\n",
      "epoch:16 step:12921 [D loss: 0.716544, acc.: 46.88%] [G loss: 0.743009]\n",
      "epoch:16 step:12922 [D loss: 0.720180, acc.: 41.41%] [G loss: 0.767284]\n",
      "epoch:16 step:12923 [D loss: 0.659980, acc.: 62.50%] [G loss: 0.706216]\n",
      "epoch:16 step:12924 [D loss: 0.668044, acc.: 61.72%] [G loss: 0.750119]\n",
      "epoch:16 step:12925 [D loss: 0.673720, acc.: 58.59%] [G loss: 0.665224]\n",
      "epoch:16 step:12926 [D loss: 0.662481, acc.: 57.03%] [G loss: 0.683096]\n",
      "epoch:16 step:12927 [D loss: 0.669648, acc.: 58.59%] [G loss: 0.727368]\n",
      "epoch:16 step:12928 [D loss: 0.626895, acc.: 68.75%] [G loss: 0.717273]\n",
      "epoch:16 step:12929 [D loss: 0.655973, acc.: 63.28%] [G loss: 0.705974]\n",
      "epoch:16 step:12930 [D loss: 0.781428, acc.: 37.50%] [G loss: 0.661075]\n",
      "epoch:16 step:12931 [D loss: 0.728008, acc.: 45.31%] [G loss: 0.665836]\n",
      "epoch:16 step:12932 [D loss: 0.646852, acc.: 61.72%] [G loss: 0.731720]\n",
      "epoch:16 step:12933 [D loss: 0.729112, acc.: 42.19%] [G loss: 0.793726]\n",
      "epoch:16 step:12934 [D loss: 0.734500, acc.: 49.22%] [G loss: 0.728736]\n",
      "epoch:16 step:12935 [D loss: 0.725560, acc.: 46.09%] [G loss: 0.741954]\n",
      "epoch:16 step:12936 [D loss: 0.746787, acc.: 40.62%] [G loss: 0.796329]\n",
      "epoch:16 step:12937 [D loss: 0.740426, acc.: 36.72%] [G loss: 0.727622]\n",
      "epoch:16 step:12938 [D loss: 0.711343, acc.: 45.31%] [G loss: 0.785525]\n",
      "epoch:16 step:12939 [D loss: 0.651744, acc.: 63.28%] [G loss: 0.813449]\n",
      "epoch:16 step:12940 [D loss: 0.719472, acc.: 48.44%] [G loss: 0.814806]\n",
      "epoch:16 step:12941 [D loss: 0.725191, acc.: 42.19%] [G loss: 0.753331]\n",
      "epoch:16 step:12942 [D loss: 0.715067, acc.: 49.22%] [G loss: 0.764871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12943 [D loss: 0.663531, acc.: 59.38%] [G loss: 0.726391]\n",
      "epoch:16 step:12944 [D loss: 0.710413, acc.: 46.88%] [G loss: 0.782261]\n",
      "epoch:16 step:12945 [D loss: 0.668388, acc.: 54.69%] [G loss: 0.766687]\n",
      "epoch:16 step:12946 [D loss: 0.699300, acc.: 50.00%] [G loss: 0.770249]\n",
      "epoch:16 step:12947 [D loss: 0.731895, acc.: 41.41%] [G loss: 0.756241]\n",
      "epoch:16 step:12948 [D loss: 0.687715, acc.: 53.12%] [G loss: 0.789904]\n",
      "epoch:16 step:12949 [D loss: 0.764690, acc.: 34.38%] [G loss: 0.734527]\n",
      "epoch:16 step:12950 [D loss: 0.696825, acc.: 52.34%] [G loss: 0.742522]\n",
      "epoch:16 step:12951 [D loss: 0.687300, acc.: 50.78%] [G loss: 0.782517]\n",
      "epoch:16 step:12952 [D loss: 0.676200, acc.: 54.69%] [G loss: 0.775951]\n",
      "epoch:16 step:12953 [D loss: 0.731442, acc.: 41.41%] [G loss: 0.770456]\n",
      "epoch:16 step:12954 [D loss: 0.676964, acc.: 56.25%] [G loss: 0.747806]\n",
      "epoch:16 step:12955 [D loss: 0.721528, acc.: 42.19%] [G loss: 0.767387]\n",
      "epoch:16 step:12956 [D loss: 0.675043, acc.: 59.38%] [G loss: 0.795333]\n",
      "epoch:16 step:12957 [D loss: 0.667320, acc.: 60.94%] [G loss: 0.796484]\n",
      "epoch:16 step:12958 [D loss: 0.691037, acc.: 56.25%] [G loss: 0.786404]\n",
      "epoch:16 step:12959 [D loss: 0.681355, acc.: 57.03%] [G loss: 0.737336]\n",
      "epoch:16 step:12960 [D loss: 0.714130, acc.: 52.34%] [G loss: 0.697274]\n",
      "epoch:16 step:12961 [D loss: 0.649707, acc.: 62.50%] [G loss: 0.719542]\n",
      "epoch:16 step:12962 [D loss: 0.686227, acc.: 55.47%] [G loss: 0.654437]\n",
      "epoch:16 step:12963 [D loss: 0.655931, acc.: 68.75%] [G loss: 0.690420]\n",
      "epoch:16 step:12964 [D loss: 0.676955, acc.: 52.34%] [G loss: 0.667331]\n",
      "epoch:16 step:12965 [D loss: 0.723473, acc.: 48.44%] [G loss: 0.782371]\n",
      "epoch:16 step:12966 [D loss: 0.709765, acc.: 46.88%] [G loss: 0.726923]\n",
      "epoch:16 step:12967 [D loss: 0.740169, acc.: 35.94%] [G loss: 0.772423]\n",
      "epoch:16 step:12968 [D loss: 0.662416, acc.: 60.16%] [G loss: 0.850320]\n",
      "epoch:16 step:12969 [D loss: 0.799544, acc.: 30.47%] [G loss: 0.705397]\n",
      "epoch:16 step:12970 [D loss: 0.683182, acc.: 57.81%] [G loss: 0.734258]\n",
      "epoch:16 step:12971 [D loss: 0.735318, acc.: 38.28%] [G loss: 0.706962]\n",
      "epoch:16 step:12972 [D loss: 0.724256, acc.: 43.75%] [G loss: 0.770078]\n",
      "epoch:16 step:12973 [D loss: 0.697098, acc.: 53.91%] [G loss: 0.763953]\n",
      "epoch:16 step:12974 [D loss: 0.646225, acc.: 65.62%] [G loss: 0.768748]\n",
      "epoch:16 step:12975 [D loss: 0.664524, acc.: 59.38%] [G loss: 0.793908]\n",
      "epoch:16 step:12976 [D loss: 0.681348, acc.: 56.25%] [G loss: 0.796213]\n",
      "epoch:16 step:12977 [D loss: 0.715137, acc.: 41.41%] [G loss: 0.793873]\n",
      "epoch:16 step:12978 [D loss: 0.756005, acc.: 39.84%] [G loss: 0.700941]\n",
      "epoch:16 step:12979 [D loss: 0.736512, acc.: 43.75%] [G loss: 0.734257]\n",
      "epoch:16 step:12980 [D loss: 0.695832, acc.: 50.00%] [G loss: 0.692037]\n",
      "epoch:16 step:12981 [D loss: 0.718059, acc.: 50.78%] [G loss: 0.697838]\n",
      "epoch:16 step:12982 [D loss: 0.719242, acc.: 44.53%] [G loss: 0.710299]\n",
      "epoch:16 step:12983 [D loss: 0.677636, acc.: 57.81%] [G loss: 0.677440]\n",
      "epoch:16 step:12984 [D loss: 0.735238, acc.: 39.06%] [G loss: 0.721163]\n",
      "epoch:16 step:12985 [D loss: 0.704174, acc.: 47.66%] [G loss: 0.771483]\n",
      "epoch:16 step:12986 [D loss: 0.695028, acc.: 57.81%] [G loss: 0.812457]\n",
      "epoch:16 step:12987 [D loss: 0.695397, acc.: 50.78%] [G loss: 0.727942]\n",
      "epoch:16 step:12988 [D loss: 0.707969, acc.: 46.88%] [G loss: 0.709547]\n",
      "epoch:16 step:12989 [D loss: 0.651717, acc.: 67.19%] [G loss: 0.761238]\n",
      "epoch:16 step:12990 [D loss: 0.679620, acc.: 57.81%] [G loss: 0.701596]\n",
      "epoch:16 step:12991 [D loss: 0.680483, acc.: 53.12%] [G loss: 0.733351]\n",
      "epoch:16 step:12992 [D loss: 0.669924, acc.: 60.94%] [G loss: 0.800273]\n",
      "epoch:16 step:12993 [D loss: 0.725499, acc.: 46.88%] [G loss: 0.723785]\n",
      "epoch:16 step:12994 [D loss: 0.735756, acc.: 39.84%] [G loss: 0.758445]\n",
      "epoch:16 step:12995 [D loss: 0.669175, acc.: 63.28%] [G loss: 0.723048]\n",
      "epoch:16 step:12996 [D loss: 0.756881, acc.: 31.25%] [G loss: 0.708330]\n",
      "epoch:16 step:12997 [D loss: 0.696598, acc.: 58.59%] [G loss: 0.740057]\n",
      "epoch:16 step:12998 [D loss: 0.713220, acc.: 52.34%] [G loss: 0.748204]\n",
      "epoch:16 step:12999 [D loss: 0.735607, acc.: 40.62%] [G loss: 0.811034]\n",
      "epoch:16 step:13000 [D loss: 0.742694, acc.: 37.50%] [G loss: 0.764208]\n",
      "epoch:16 step:13001 [D loss: 0.680982, acc.: 57.03%] [G loss: 0.727442]\n",
      "epoch:16 step:13002 [D loss: 0.669545, acc.: 64.06%] [G loss: 0.773227]\n",
      "epoch:16 step:13003 [D loss: 0.732785, acc.: 42.97%] [G loss: 0.764509]\n",
      "epoch:16 step:13004 [D loss: 0.699057, acc.: 52.34%] [G loss: 0.706023]\n",
      "epoch:16 step:13005 [D loss: 0.689256, acc.: 47.66%] [G loss: 0.760480]\n",
      "epoch:16 step:13006 [D loss: 0.671635, acc.: 55.47%] [G loss: 0.778737]\n",
      "epoch:16 step:13007 [D loss: 0.695389, acc.: 53.12%] [G loss: 0.749623]\n",
      "epoch:16 step:13008 [D loss: 0.708361, acc.: 50.78%] [G loss: 0.780028]\n",
      "epoch:16 step:13009 [D loss: 0.745752, acc.: 38.28%] [G loss: 0.711268]\n",
      "epoch:16 step:13010 [D loss: 0.780509, acc.: 27.34%] [G loss: 0.658921]\n",
      "epoch:16 step:13011 [D loss: 0.653183, acc.: 67.19%] [G loss: 0.774948]\n",
      "epoch:16 step:13012 [D loss: 0.684076, acc.: 50.78%] [G loss: 0.724342]\n",
      "epoch:16 step:13013 [D loss: 0.699604, acc.: 52.34%] [G loss: 0.746320]\n",
      "epoch:16 step:13014 [D loss: 0.662469, acc.: 61.72%] [G loss: 0.692156]\n",
      "epoch:16 step:13015 [D loss: 0.697666, acc.: 53.91%] [G loss: 0.790915]\n",
      "epoch:16 step:13016 [D loss: 0.640654, acc.: 68.75%] [G loss: 0.791592]\n",
      "epoch:16 step:13017 [D loss: 0.633619, acc.: 68.75%] [G loss: 0.741493]\n",
      "epoch:16 step:13018 [D loss: 0.757295, acc.: 36.72%] [G loss: 0.741747]\n",
      "epoch:16 step:13019 [D loss: 0.744870, acc.: 38.28%] [G loss: 0.785959]\n",
      "epoch:16 step:13020 [D loss: 0.668285, acc.: 53.91%] [G loss: 0.759388]\n",
      "epoch:16 step:13021 [D loss: 0.640227, acc.: 57.03%] [G loss: 0.856681]\n",
      "epoch:16 step:13022 [D loss: 0.780844, acc.: 42.19%] [G loss: 0.724968]\n",
      "epoch:16 step:13023 [D loss: 0.680132, acc.: 57.81%] [G loss: 0.682906]\n",
      "epoch:16 step:13024 [D loss: 0.717175, acc.: 42.97%] [G loss: 0.660001]\n",
      "epoch:16 step:13025 [D loss: 0.707322, acc.: 50.00%] [G loss: 0.642043]\n",
      "epoch:16 step:13026 [D loss: 0.696130, acc.: 51.56%] [G loss: 0.678992]\n",
      "epoch:16 step:13027 [D loss: 0.671564, acc.: 60.16%] [G loss: 0.754341]\n",
      "epoch:16 step:13028 [D loss: 0.749763, acc.: 39.84%] [G loss: 0.794486]\n",
      "epoch:16 step:13029 [D loss: 0.700794, acc.: 47.66%] [G loss: 0.752947]\n",
      "epoch:16 step:13030 [D loss: 0.694752, acc.: 50.00%] [G loss: 0.798689]\n",
      "epoch:16 step:13031 [D loss: 0.707516, acc.: 51.56%] [G loss: 0.781860]\n",
      "epoch:16 step:13032 [D loss: 0.700572, acc.: 50.78%] [G loss: 0.752518]\n",
      "epoch:16 step:13033 [D loss: 0.694758, acc.: 50.00%] [G loss: 0.801981]\n",
      "epoch:16 step:13034 [D loss: 0.707878, acc.: 44.53%] [G loss: 0.749005]\n",
      "epoch:16 step:13035 [D loss: 0.701820, acc.: 54.69%] [G loss: 0.693432]\n",
      "epoch:16 step:13036 [D loss: 0.720571, acc.: 46.09%] [G loss: 0.763888]\n",
      "epoch:16 step:13037 [D loss: 0.746994, acc.: 35.16%] [G loss: 0.711164]\n",
      "epoch:16 step:13038 [D loss: 0.726219, acc.: 46.09%] [G loss: 0.770007]\n",
      "epoch:16 step:13039 [D loss: 0.703412, acc.: 52.34%] [G loss: 0.790637]\n",
      "epoch:16 step:13040 [D loss: 0.654510, acc.: 60.16%] [G loss: 0.828903]\n",
      "epoch:16 step:13041 [D loss: 0.661423, acc.: 62.50%] [G loss: 0.752733]\n",
      "epoch:16 step:13042 [D loss: 0.774212, acc.: 35.94%] [G loss: 0.750981]\n",
      "epoch:16 step:13043 [D loss: 0.645273, acc.: 67.97%] [G loss: 0.839401]\n",
      "epoch:16 step:13044 [D loss: 0.716183, acc.: 43.75%] [G loss: 0.765114]\n",
      "epoch:16 step:13045 [D loss: 0.697653, acc.: 51.56%] [G loss: 0.704333]\n",
      "epoch:16 step:13046 [D loss: 0.675344, acc.: 55.47%] [G loss: 0.727898]\n",
      "epoch:16 step:13047 [D loss: 0.727374, acc.: 45.31%] [G loss: 0.687498]\n",
      "epoch:16 step:13048 [D loss: 0.722869, acc.: 41.41%] [G loss: 0.732656]\n",
      "epoch:16 step:13049 [D loss: 0.683658, acc.: 55.47%] [G loss: 0.765222]\n",
      "epoch:16 step:13050 [D loss: 0.637892, acc.: 77.34%] [G loss: 0.808425]\n",
      "epoch:16 step:13051 [D loss: 0.660931, acc.: 64.84%] [G loss: 0.770711]\n",
      "epoch:16 step:13052 [D loss: 0.701895, acc.: 50.78%] [G loss: 0.707367]\n",
      "epoch:16 step:13053 [D loss: 0.716409, acc.: 42.19%] [G loss: 0.745302]\n",
      "epoch:16 step:13054 [D loss: 0.645890, acc.: 71.88%] [G loss: 0.767028]\n",
      "epoch:16 step:13055 [D loss: 0.699126, acc.: 51.56%] [G loss: 0.738185]\n",
      "epoch:16 step:13056 [D loss: 0.749129, acc.: 32.81%] [G loss: 0.725190]\n",
      "epoch:16 step:13057 [D loss: 0.688055, acc.: 52.34%] [G loss: 0.728680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13058 [D loss: 0.672052, acc.: 60.16%] [G loss: 0.711123]\n",
      "epoch:16 step:13059 [D loss: 0.669826, acc.: 60.94%] [G loss: 0.778243]\n",
      "epoch:16 step:13060 [D loss: 0.668007, acc.: 62.50%] [G loss: 0.777651]\n",
      "epoch:16 step:13061 [D loss: 0.671734, acc.: 53.12%] [G loss: 0.757719]\n",
      "epoch:16 step:13062 [D loss: 0.687346, acc.: 53.12%] [G loss: 0.783664]\n",
      "epoch:16 step:13063 [D loss: 0.664374, acc.: 59.38%] [G loss: 0.808902]\n",
      "epoch:16 step:13064 [D loss: 0.670234, acc.: 58.59%] [G loss: 0.856322]\n",
      "epoch:16 step:13065 [D loss: 0.672279, acc.: 53.12%] [G loss: 0.777242]\n",
      "epoch:16 step:13066 [D loss: 0.693348, acc.: 55.47%] [G loss: 0.833652]\n",
      "epoch:16 step:13067 [D loss: 0.678303, acc.: 57.81%] [G loss: 0.829986]\n",
      "epoch:16 step:13068 [D loss: 0.640858, acc.: 61.72%] [G loss: 0.815177]\n",
      "epoch:16 step:13069 [D loss: 0.672234, acc.: 62.50%] [G loss: 0.810713]\n",
      "epoch:16 step:13070 [D loss: 0.754829, acc.: 35.94%] [G loss: 0.710763]\n",
      "epoch:16 step:13071 [D loss: 0.690430, acc.: 49.22%] [G loss: 0.714102]\n",
      "epoch:16 step:13072 [D loss: 0.694324, acc.: 55.47%] [G loss: 0.721218]\n",
      "epoch:16 step:13073 [D loss: 0.734978, acc.: 42.19%] [G loss: 0.659426]\n",
      "epoch:16 step:13074 [D loss: 0.679737, acc.: 53.91%] [G loss: 0.743304]\n",
      "epoch:16 step:13075 [D loss: 0.715318, acc.: 47.66%] [G loss: 0.829013]\n",
      "epoch:16 step:13076 [D loss: 0.712229, acc.: 52.34%] [G loss: 0.770076]\n",
      "epoch:16 step:13077 [D loss: 0.676765, acc.: 53.12%] [G loss: 0.748076]\n",
      "epoch:16 step:13078 [D loss: 0.642642, acc.: 67.19%] [G loss: 0.783026]\n",
      "epoch:16 step:13079 [D loss: 0.740968, acc.: 35.16%] [G loss: 0.695600]\n",
      "epoch:16 step:13080 [D loss: 0.718443, acc.: 46.09%] [G loss: 0.718215]\n",
      "epoch:16 step:13081 [D loss: 0.674648, acc.: 61.72%] [G loss: 0.746498]\n",
      "epoch:16 step:13082 [D loss: 0.687715, acc.: 55.47%] [G loss: 0.767184]\n",
      "epoch:16 step:13083 [D loss: 0.676916, acc.: 55.47%] [G loss: 0.722885]\n",
      "epoch:16 step:13084 [D loss: 0.647274, acc.: 65.62%] [G loss: 0.719866]\n",
      "epoch:16 step:13085 [D loss: 0.674211, acc.: 63.28%] [G loss: 0.690247]\n",
      "epoch:16 step:13086 [D loss: 0.695262, acc.: 49.22%] [G loss: 0.762554]\n",
      "epoch:16 step:13087 [D loss: 0.747286, acc.: 38.28%] [G loss: 0.713659]\n",
      "epoch:16 step:13088 [D loss: 0.697051, acc.: 50.00%] [G loss: 0.722734]\n",
      "epoch:16 step:13089 [D loss: 0.670428, acc.: 61.72%] [G loss: 0.746141]\n",
      "epoch:16 step:13090 [D loss: 0.717581, acc.: 44.53%] [G loss: 0.695286]\n",
      "epoch:16 step:13091 [D loss: 0.660732, acc.: 59.38%] [G loss: 0.748237]\n",
      "epoch:16 step:13092 [D loss: 0.687440, acc.: 53.12%] [G loss: 0.757274]\n",
      "epoch:16 step:13093 [D loss: 0.686943, acc.: 51.56%] [G loss: 0.736453]\n",
      "epoch:16 step:13094 [D loss: 0.698075, acc.: 56.25%] [G loss: 0.723932]\n",
      "epoch:16 step:13095 [D loss: 0.718550, acc.: 45.31%] [G loss: 0.792673]\n",
      "epoch:16 step:13096 [D loss: 0.639650, acc.: 68.75%] [G loss: 0.810313]\n",
      "epoch:16 step:13097 [D loss: 0.669936, acc.: 58.59%] [G loss: 0.764593]\n",
      "epoch:16 step:13098 [D loss: 0.689493, acc.: 53.12%] [G loss: 0.792850]\n",
      "epoch:16 step:13099 [D loss: 0.652318, acc.: 61.72%] [G loss: 0.766777]\n",
      "epoch:16 step:13100 [D loss: 0.716679, acc.: 50.78%] [G loss: 0.776205]\n",
      "epoch:16 step:13101 [D loss: 0.672051, acc.: 61.72%] [G loss: 0.742666]\n",
      "epoch:16 step:13102 [D loss: 0.673415, acc.: 57.81%] [G loss: 0.711397]\n",
      "epoch:16 step:13103 [D loss: 0.685600, acc.: 55.47%] [G loss: 0.674941]\n",
      "epoch:16 step:13104 [D loss: 0.660654, acc.: 64.06%] [G loss: 0.735679]\n",
      "epoch:16 step:13105 [D loss: 0.661327, acc.: 65.62%] [G loss: 0.701167]\n",
      "epoch:16 step:13106 [D loss: 0.673617, acc.: 58.59%] [G loss: 0.747059]\n",
      "epoch:16 step:13107 [D loss: 0.699553, acc.: 53.91%] [G loss: 0.675434]\n",
      "epoch:16 step:13108 [D loss: 0.685493, acc.: 60.94%] [G loss: 0.766402]\n",
      "epoch:16 step:13109 [D loss: 0.727887, acc.: 44.53%] [G loss: 0.665586]\n",
      "epoch:16 step:13110 [D loss: 0.670945, acc.: 64.06%] [G loss: 0.740125]\n",
      "epoch:16 step:13111 [D loss: 0.709480, acc.: 49.22%] [G loss: 0.687815]\n",
      "epoch:16 step:13112 [D loss: 0.703121, acc.: 46.88%] [G loss: 0.703037]\n",
      "epoch:16 step:13113 [D loss: 0.753346, acc.: 35.94%] [G loss: 0.669751]\n",
      "epoch:16 step:13114 [D loss: 0.698609, acc.: 46.88%] [G loss: 0.780815]\n",
      "epoch:16 step:13115 [D loss: 0.690722, acc.: 56.25%] [G loss: 0.754950]\n",
      "epoch:16 step:13116 [D loss: 0.668549, acc.: 59.38%] [G loss: 0.740633]\n",
      "epoch:16 step:13117 [D loss: 0.697811, acc.: 50.78%] [G loss: 0.748648]\n",
      "epoch:16 step:13118 [D loss: 0.705431, acc.: 49.22%] [G loss: 0.710840]\n",
      "epoch:16 step:13119 [D loss: 0.694060, acc.: 49.22%] [G loss: 0.748480]\n",
      "epoch:16 step:13120 [D loss: 0.734674, acc.: 39.06%] [G loss: 0.703505]\n",
      "epoch:16 step:13121 [D loss: 0.728609, acc.: 44.53%] [G loss: 0.763693]\n",
      "epoch:16 step:13122 [D loss: 0.716903, acc.: 45.31%] [G loss: 0.733397]\n",
      "epoch:16 step:13123 [D loss: 0.714828, acc.: 45.31%] [G loss: 0.727523]\n",
      "epoch:16 step:13124 [D loss: 0.669118, acc.: 65.62%] [G loss: 0.768253]\n",
      "epoch:16 step:13125 [D loss: 0.725608, acc.: 46.88%] [G loss: 0.814830]\n",
      "epoch:16 step:13126 [D loss: 0.622093, acc.: 75.00%] [G loss: 0.781988]\n",
      "epoch:16 step:13127 [D loss: 0.714089, acc.: 46.88%] [G loss: 0.740765]\n",
      "epoch:16 step:13128 [D loss: 0.678462, acc.: 58.59%] [G loss: 0.722823]\n",
      "epoch:16 step:13129 [D loss: 0.708530, acc.: 44.53%] [G loss: 0.699804]\n",
      "epoch:16 step:13130 [D loss: 0.704974, acc.: 48.44%] [G loss: 0.722731]\n",
      "epoch:16 step:13131 [D loss: 0.719898, acc.: 49.22%] [G loss: 0.730684]\n",
      "epoch:16 step:13132 [D loss: 0.677223, acc.: 57.03%] [G loss: 0.837563]\n",
      "epoch:16 step:13133 [D loss: 0.657754, acc.: 61.72%] [G loss: 0.810373]\n",
      "epoch:16 step:13134 [D loss: 0.684511, acc.: 57.81%] [G loss: 0.810972]\n",
      "epoch:16 step:13135 [D loss: 0.677595, acc.: 54.69%] [G loss: 0.772873]\n",
      "epoch:16 step:13136 [D loss: 0.683956, acc.: 57.03%] [G loss: 0.789866]\n",
      "epoch:16 step:13137 [D loss: 0.675916, acc.: 57.03%] [G loss: 0.705534]\n",
      "epoch:16 step:13138 [D loss: 0.700923, acc.: 50.78%] [G loss: 0.671459]\n",
      "epoch:16 step:13139 [D loss: 0.729172, acc.: 46.09%] [G loss: 0.668838]\n",
      "epoch:16 step:13140 [D loss: 0.665462, acc.: 61.72%] [G loss: 0.683394]\n",
      "epoch:16 step:13141 [D loss: 0.691500, acc.: 55.47%] [G loss: 0.662461]\n",
      "epoch:16 step:13142 [D loss: 0.709621, acc.: 48.44%] [G loss: 0.673555]\n",
      "epoch:16 step:13143 [D loss: 0.742005, acc.: 39.06%] [G loss: 0.647532]\n",
      "epoch:16 step:13144 [D loss: 0.689375, acc.: 50.78%] [G loss: 0.706453]\n",
      "epoch:16 step:13145 [D loss: 0.756348, acc.: 33.59%] [G loss: 0.661747]\n",
      "epoch:16 step:13146 [D loss: 0.654646, acc.: 64.84%] [G loss: 0.710596]\n",
      "epoch:16 step:13147 [D loss: 0.794804, acc.: 28.91%] [G loss: 0.723918]\n",
      "epoch:16 step:13148 [D loss: 0.747972, acc.: 46.09%] [G loss: 0.699866]\n",
      "epoch:16 step:13149 [D loss: 0.697361, acc.: 53.12%] [G loss: 0.787270]\n",
      "epoch:16 step:13150 [D loss: 0.667637, acc.: 60.94%] [G loss: 0.744194]\n",
      "epoch:16 step:13151 [D loss: 0.725574, acc.: 43.75%] [G loss: 0.771747]\n",
      "epoch:16 step:13152 [D loss: 0.689235, acc.: 60.16%] [G loss: 0.715188]\n",
      "epoch:16 step:13153 [D loss: 0.720902, acc.: 45.31%] [G loss: 0.722191]\n",
      "epoch:16 step:13154 [D loss: 0.680996, acc.: 53.12%] [G loss: 0.782985]\n",
      "epoch:16 step:13155 [D loss: 0.688393, acc.: 57.81%] [G loss: 0.823223]\n",
      "epoch:16 step:13156 [D loss: 0.671985, acc.: 58.59%] [G loss: 0.836594]\n",
      "epoch:16 step:13157 [D loss: 0.684528, acc.: 57.03%] [G loss: 0.804440]\n",
      "epoch:16 step:13158 [D loss: 0.692524, acc.: 52.34%] [G loss: 0.787064]\n",
      "epoch:16 step:13159 [D loss: 0.657413, acc.: 60.16%] [G loss: 0.777836]\n",
      "epoch:16 step:13160 [D loss: 0.608801, acc.: 78.12%] [G loss: 0.749801]\n",
      "epoch:16 step:13161 [D loss: 0.672021, acc.: 62.50%] [G loss: 0.753648]\n",
      "epoch:16 step:13162 [D loss: 0.644467, acc.: 66.41%] [G loss: 0.800288]\n",
      "epoch:16 step:13163 [D loss: 0.640721, acc.: 67.97%] [G loss: 0.804116]\n",
      "epoch:16 step:13164 [D loss: 0.647530, acc.: 65.62%] [G loss: 0.805059]\n",
      "epoch:16 step:13165 [D loss: 0.714325, acc.: 50.00%] [G loss: 0.703886]\n",
      "epoch:16 step:13166 [D loss: 0.620115, acc.: 71.09%] [G loss: 0.773495]\n",
      "epoch:16 step:13167 [D loss: 0.661946, acc.: 60.94%] [G loss: 0.772014]\n",
      "epoch:16 step:13168 [D loss: 0.729944, acc.: 47.66%] [G loss: 0.713415]\n",
      "epoch:16 step:13169 [D loss: 0.652339, acc.: 65.62%] [G loss: 0.675845]\n",
      "epoch:16 step:13170 [D loss: 0.675781, acc.: 56.25%] [G loss: 0.716029]\n",
      "epoch:16 step:13171 [D loss: 0.719032, acc.: 51.56%] [G loss: 0.718764]\n",
      "epoch:16 step:13172 [D loss: 0.702345, acc.: 57.03%] [G loss: 0.693843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13173 [D loss: 0.705733, acc.: 46.09%] [G loss: 0.736437]\n",
      "epoch:16 step:13174 [D loss: 0.752489, acc.: 32.03%] [G loss: 0.758089]\n",
      "epoch:16 step:13175 [D loss: 0.715643, acc.: 45.31%] [G loss: 0.740026]\n",
      "epoch:16 step:13176 [D loss: 0.685406, acc.: 54.69%] [G loss: 0.779999]\n",
      "epoch:16 step:13177 [D loss: 0.731395, acc.: 45.31%] [G loss: 0.837614]\n",
      "epoch:16 step:13178 [D loss: 0.686655, acc.: 55.47%] [G loss: 0.833942]\n",
      "epoch:16 step:13179 [D loss: 0.685058, acc.: 50.00%] [G loss: 0.788226]\n",
      "epoch:16 step:13180 [D loss: 0.695927, acc.: 48.44%] [G loss: 0.796600]\n",
      "epoch:16 step:13181 [D loss: 0.714744, acc.: 49.22%] [G loss: 0.768739]\n",
      "epoch:16 step:13182 [D loss: 0.731092, acc.: 42.97%] [G loss: 0.790989]\n",
      "epoch:16 step:13183 [D loss: 0.647595, acc.: 65.62%] [G loss: 0.784817]\n",
      "epoch:16 step:13184 [D loss: 0.688593, acc.: 49.22%] [G loss: 0.793811]\n",
      "epoch:16 step:13185 [D loss: 0.711345, acc.: 53.91%] [G loss: 0.754931]\n",
      "epoch:16 step:13186 [D loss: 0.677863, acc.: 56.25%] [G loss: 0.768204]\n",
      "epoch:16 step:13187 [D loss: 0.714758, acc.: 46.88%] [G loss: 0.817488]\n",
      "epoch:16 step:13188 [D loss: 0.724588, acc.: 46.09%] [G loss: 0.748601]\n",
      "epoch:16 step:13189 [D loss: 0.662199, acc.: 62.50%] [G loss: 0.759681]\n",
      "epoch:16 step:13190 [D loss: 0.693519, acc.: 58.59%] [G loss: 0.733104]\n",
      "epoch:16 step:13191 [D loss: 0.695085, acc.: 56.25%] [G loss: 0.746023]\n",
      "epoch:16 step:13192 [D loss: 0.683636, acc.: 50.78%] [G loss: 0.732678]\n",
      "epoch:16 step:13193 [D loss: 0.728059, acc.: 50.78%] [G loss: 0.728912]\n",
      "epoch:16 step:13194 [D loss: 0.659482, acc.: 64.06%] [G loss: 0.711733]\n",
      "epoch:16 step:13195 [D loss: 0.691877, acc.: 57.03%] [G loss: 0.779372]\n",
      "epoch:16 step:13196 [D loss: 0.670531, acc.: 67.97%] [G loss: 0.709803]\n",
      "epoch:16 step:13197 [D loss: 0.671217, acc.: 57.03%] [G loss: 0.732019]\n",
      "epoch:16 step:13198 [D loss: 0.770997, acc.: 37.50%] [G loss: 0.736749]\n",
      "epoch:16 step:13199 [D loss: 0.708123, acc.: 50.00%] [G loss: 0.722573]\n",
      "epoch:16 step:13200 [D loss: 0.724717, acc.: 40.62%] [G loss: 0.728250]\n",
      "epoch:16 step:13201 [D loss: 0.701872, acc.: 46.09%] [G loss: 0.761720]\n",
      "epoch:16 step:13202 [D loss: 0.685257, acc.: 53.91%] [G loss: 0.771257]\n",
      "epoch:16 step:13203 [D loss: 0.663777, acc.: 61.72%] [G loss: 0.809179]\n",
      "epoch:16 step:13204 [D loss: 0.722826, acc.: 50.00%] [G loss: 0.711953]\n",
      "epoch:16 step:13205 [D loss: 0.671010, acc.: 55.47%] [G loss: 0.814176]\n",
      "epoch:16 step:13206 [D loss: 0.641790, acc.: 65.62%] [G loss: 0.909585]\n",
      "epoch:16 step:13207 [D loss: 0.673692, acc.: 57.81%] [G loss: 0.805460]\n",
      "epoch:16 step:13208 [D loss: 0.693094, acc.: 63.28%] [G loss: 0.837942]\n",
      "epoch:16 step:13209 [D loss: 0.697692, acc.: 52.34%] [G loss: 0.836387]\n",
      "epoch:16 step:13210 [D loss: 0.701216, acc.: 50.00%] [G loss: 0.811927]\n",
      "epoch:16 step:13211 [D loss: 0.680788, acc.: 57.81%] [G loss: 0.776935]\n",
      "epoch:16 step:13212 [D loss: 0.649759, acc.: 63.28%] [G loss: 0.797281]\n",
      "epoch:16 step:13213 [D loss: 0.647714, acc.: 61.72%] [G loss: 0.766054]\n",
      "epoch:16 step:13214 [D loss: 0.694841, acc.: 49.22%] [G loss: 0.764132]\n",
      "epoch:16 step:13215 [D loss: 0.660771, acc.: 63.28%] [G loss: 0.753005]\n",
      "epoch:16 step:13216 [D loss: 0.660217, acc.: 63.28%] [G loss: 0.866519]\n",
      "epoch:16 step:13217 [D loss: 0.648942, acc.: 58.59%] [G loss: 0.709501]\n",
      "epoch:16 step:13218 [D loss: 0.662620, acc.: 61.72%] [G loss: 0.699203]\n",
      "epoch:16 step:13219 [D loss: 0.702166, acc.: 54.69%] [G loss: 0.698027]\n",
      "epoch:16 step:13220 [D loss: 0.659136, acc.: 62.50%] [G loss: 0.585766]\n",
      "epoch:16 step:13221 [D loss: 0.704216, acc.: 51.56%] [G loss: 0.645338]\n",
      "epoch:16 step:13222 [D loss: 0.721507, acc.: 42.19%] [G loss: 0.593023]\n",
      "epoch:16 step:13223 [D loss: 0.700189, acc.: 53.91%] [G loss: 0.699058]\n",
      "epoch:16 step:13224 [D loss: 0.727029, acc.: 38.28%] [G loss: 0.595727]\n",
      "epoch:16 step:13225 [D loss: 0.721771, acc.: 49.22%] [G loss: 0.707040]\n",
      "epoch:16 step:13226 [D loss: 0.680933, acc.: 57.03%] [G loss: 0.613054]\n",
      "epoch:16 step:13227 [D loss: 0.654528, acc.: 64.84%] [G loss: 0.699496]\n",
      "epoch:16 step:13228 [D loss: 0.704991, acc.: 50.78%] [G loss: 0.661494]\n",
      "epoch:16 step:13229 [D loss: 0.784533, acc.: 30.47%] [G loss: 0.712053]\n",
      "epoch:16 step:13230 [D loss: 0.769281, acc.: 38.28%] [G loss: 0.733022]\n",
      "epoch:16 step:13231 [D loss: 0.737809, acc.: 37.50%] [G loss: 0.771618]\n",
      "epoch:16 step:13232 [D loss: 0.745026, acc.: 41.41%] [G loss: 0.750684]\n",
      "epoch:16 step:13233 [D loss: 0.684683, acc.: 52.34%] [G loss: 0.843742]\n",
      "epoch:16 step:13234 [D loss: 0.639919, acc.: 71.09%] [G loss: 0.820834]\n",
      "epoch:16 step:13235 [D loss: 0.672337, acc.: 60.94%] [G loss: 0.796225]\n",
      "epoch:16 step:13236 [D loss: 0.687374, acc.: 55.47%] [G loss: 0.751060]\n",
      "epoch:16 step:13237 [D loss: 0.654480, acc.: 64.84%] [G loss: 0.847861]\n",
      "epoch:16 step:13238 [D loss: 0.721984, acc.: 46.09%] [G loss: 0.781511]\n",
      "epoch:16 step:13239 [D loss: 0.686869, acc.: 51.56%] [G loss: 0.677361]\n",
      "epoch:16 step:13240 [D loss: 0.735922, acc.: 46.09%] [G loss: 0.724512]\n",
      "epoch:16 step:13241 [D loss: 0.675501, acc.: 55.47%] [G loss: 0.763836]\n",
      "epoch:16 step:13242 [D loss: 0.703525, acc.: 46.88%] [G loss: 0.740955]\n",
      "epoch:16 step:13243 [D loss: 0.738298, acc.: 40.62%] [G loss: 0.773196]\n",
      "epoch:16 step:13244 [D loss: 0.671054, acc.: 57.81%] [G loss: 0.688858]\n",
      "epoch:16 step:13245 [D loss: 0.631923, acc.: 62.50%] [G loss: 0.753928]\n",
      "epoch:16 step:13246 [D loss: 0.688578, acc.: 51.56%] [G loss: 0.791652]\n",
      "epoch:16 step:13247 [D loss: 0.691951, acc.: 56.25%] [G loss: 0.749512]\n",
      "epoch:16 step:13248 [D loss: 0.671264, acc.: 54.69%] [G loss: 0.723994]\n",
      "epoch:16 step:13249 [D loss: 0.767130, acc.: 36.72%] [G loss: 0.754605]\n",
      "epoch:16 step:13250 [D loss: 0.745763, acc.: 35.16%] [G loss: 0.737108]\n",
      "epoch:16 step:13251 [D loss: 0.691322, acc.: 51.56%] [G loss: 0.736875]\n",
      "epoch:16 step:13252 [D loss: 0.715087, acc.: 46.88%] [G loss: 0.772198]\n",
      "epoch:16 step:13253 [D loss: 0.726673, acc.: 44.53%] [G loss: 0.796845]\n",
      "epoch:16 step:13254 [D loss: 0.736094, acc.: 40.62%] [G loss: 0.734714]\n",
      "epoch:16 step:13255 [D loss: 0.725510, acc.: 44.53%] [G loss: 0.754187]\n",
      "epoch:16 step:13256 [D loss: 0.725162, acc.: 51.56%] [G loss: 0.720532]\n",
      "epoch:16 step:13257 [D loss: 0.678691, acc.: 55.47%] [G loss: 0.777367]\n",
      "epoch:16 step:13258 [D loss: 0.746660, acc.: 41.41%] [G loss: 0.699683]\n",
      "epoch:16 step:13259 [D loss: 0.681635, acc.: 60.16%] [G loss: 0.706710]\n",
      "epoch:16 step:13260 [D loss: 0.711950, acc.: 50.00%] [G loss: 0.758132]\n",
      "epoch:16 step:13261 [D loss: 0.683430, acc.: 57.03%] [G loss: 0.786316]\n",
      "epoch:16 step:13262 [D loss: 0.769378, acc.: 34.38%] [G loss: 0.713484]\n",
      "epoch:16 step:13263 [D loss: 0.689461, acc.: 57.81%] [G loss: 0.831593]\n",
      "epoch:16 step:13264 [D loss: 0.739690, acc.: 42.97%] [G loss: 0.804813]\n",
      "epoch:16 step:13265 [D loss: 0.696592, acc.: 49.22%] [G loss: 0.779134]\n",
      "epoch:16 step:13266 [D loss: 0.699394, acc.: 54.69%] [G loss: 0.728648]\n",
      "epoch:16 step:13267 [D loss: 0.736102, acc.: 39.06%] [G loss: 0.807063]\n",
      "epoch:16 step:13268 [D loss: 0.679412, acc.: 50.00%] [G loss: 0.758097]\n",
      "epoch:16 step:13269 [D loss: 0.694468, acc.: 51.56%] [G loss: 0.745761]\n",
      "epoch:16 step:13270 [D loss: 0.666703, acc.: 55.47%] [G loss: 0.779180]\n",
      "epoch:16 step:13271 [D loss: 0.668040, acc.: 55.47%] [G loss: 0.827544]\n",
      "epoch:16 step:13272 [D loss: 0.686584, acc.: 53.91%] [G loss: 0.788950]\n",
      "epoch:16 step:13273 [D loss: 0.672240, acc.: 60.16%] [G loss: 0.739606]\n",
      "epoch:16 step:13274 [D loss: 0.654675, acc.: 67.19%] [G loss: 0.746568]\n",
      "epoch:16 step:13275 [D loss: 0.683142, acc.: 53.91%] [G loss: 0.767384]\n",
      "epoch:16 step:13276 [D loss: 0.676787, acc.: 60.16%] [G loss: 0.691552]\n",
      "epoch:16 step:13277 [D loss: 0.675365, acc.: 59.38%] [G loss: 0.707121]\n",
      "epoch:17 step:13278 [D loss: 0.674031, acc.: 59.38%] [G loss: 0.687343]\n",
      "epoch:17 step:13279 [D loss: 0.668913, acc.: 56.25%] [G loss: 0.720705]\n",
      "epoch:17 step:13280 [D loss: 0.697068, acc.: 52.34%] [G loss: 0.659308]\n",
      "epoch:17 step:13281 [D loss: 0.696656, acc.: 56.25%] [G loss: 0.760808]\n",
      "epoch:17 step:13282 [D loss: 0.684491, acc.: 55.47%] [G loss: 0.776708]\n",
      "epoch:17 step:13283 [D loss: 0.719636, acc.: 41.41%] [G loss: 0.751051]\n",
      "epoch:17 step:13284 [D loss: 0.670374, acc.: 57.81%] [G loss: 0.821724]\n",
      "epoch:17 step:13285 [D loss: 0.686213, acc.: 57.03%] [G loss: 0.736439]\n",
      "epoch:17 step:13286 [D loss: 0.690723, acc.: 54.69%] [G loss: 0.761666]\n",
      "epoch:17 step:13287 [D loss: 0.650302, acc.: 64.84%] [G loss: 0.755084]\n",
      "epoch:17 step:13288 [D loss: 0.741038, acc.: 39.06%] [G loss: 0.685784]\n",
      "epoch:17 step:13289 [D loss: 0.758382, acc.: 42.19%] [G loss: 0.720992]\n",
      "epoch:17 step:13290 [D loss: 0.670682, acc.: 61.72%] [G loss: 0.795651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13291 [D loss: 0.695083, acc.: 50.00%] [G loss: 0.741566]\n",
      "epoch:17 step:13292 [D loss: 0.717331, acc.: 50.00%] [G loss: 0.727786]\n",
      "epoch:17 step:13293 [D loss: 0.705189, acc.: 48.44%] [G loss: 0.717256]\n",
      "epoch:17 step:13294 [D loss: 0.711059, acc.: 44.53%] [G loss: 0.767853]\n",
      "epoch:17 step:13295 [D loss: 0.728369, acc.: 46.09%] [G loss: 0.737150]\n",
      "epoch:17 step:13296 [D loss: 0.721305, acc.: 46.09%] [G loss: 0.674594]\n",
      "epoch:17 step:13297 [D loss: 0.693753, acc.: 55.47%] [G loss: 0.766690]\n",
      "epoch:17 step:13298 [D loss: 0.741333, acc.: 40.62%] [G loss: 0.776002]\n",
      "epoch:17 step:13299 [D loss: 0.678042, acc.: 61.72%] [G loss: 0.798528]\n",
      "epoch:17 step:13300 [D loss: 0.681746, acc.: 58.59%] [G loss: 0.809456]\n",
      "epoch:17 step:13301 [D loss: 0.702048, acc.: 50.78%] [G loss: 0.771237]\n",
      "epoch:17 step:13302 [D loss: 0.716939, acc.: 47.66%] [G loss: 0.757324]\n",
      "epoch:17 step:13303 [D loss: 0.704145, acc.: 50.78%] [G loss: 0.761198]\n",
      "epoch:17 step:13304 [D loss: 0.687631, acc.: 53.12%] [G loss: 0.746051]\n",
      "epoch:17 step:13305 [D loss: 0.672743, acc.: 52.34%] [G loss: 0.766974]\n",
      "epoch:17 step:13306 [D loss: 0.655127, acc.: 58.59%] [G loss: 0.806228]\n",
      "epoch:17 step:13307 [D loss: 0.678213, acc.: 53.12%] [G loss: 0.759933]\n",
      "epoch:17 step:13308 [D loss: 0.690774, acc.: 52.34%] [G loss: 0.770930]\n",
      "epoch:17 step:13309 [D loss: 0.711308, acc.: 49.22%] [G loss: 0.738181]\n",
      "epoch:17 step:13310 [D loss: 0.702062, acc.: 53.91%] [G loss: 0.771420]\n",
      "epoch:17 step:13311 [D loss: 0.704575, acc.: 50.00%] [G loss: 0.724709]\n",
      "epoch:17 step:13312 [D loss: 0.717674, acc.: 46.09%] [G loss: 0.675982]\n",
      "epoch:17 step:13313 [D loss: 0.763832, acc.: 31.25%] [G loss: 0.696111]\n",
      "epoch:17 step:13314 [D loss: 0.704379, acc.: 52.34%] [G loss: 0.770052]\n",
      "epoch:17 step:13315 [D loss: 0.707723, acc.: 46.09%] [G loss: 0.775031]\n",
      "epoch:17 step:13316 [D loss: 0.708063, acc.: 52.34%] [G loss: 0.752043]\n",
      "epoch:17 step:13317 [D loss: 0.700918, acc.: 50.00%] [G loss: 0.743175]\n",
      "epoch:17 step:13318 [D loss: 0.705763, acc.: 46.09%] [G loss: 0.744129]\n",
      "epoch:17 step:13319 [D loss: 0.703522, acc.: 49.22%] [G loss: 0.805199]\n",
      "epoch:17 step:13320 [D loss: 0.693025, acc.: 53.12%] [G loss: 0.812773]\n",
      "epoch:17 step:13321 [D loss: 0.796420, acc.: 23.44%] [G loss: 0.726813]\n",
      "epoch:17 step:13322 [D loss: 0.701303, acc.: 51.56%] [G loss: 0.742736]\n",
      "epoch:17 step:13323 [D loss: 0.711322, acc.: 50.78%] [G loss: 0.826470]\n",
      "epoch:17 step:13324 [D loss: 0.691929, acc.: 47.66%] [G loss: 0.832348]\n",
      "epoch:17 step:13325 [D loss: 0.703593, acc.: 46.88%] [G loss: 0.837408]\n",
      "epoch:17 step:13326 [D loss: 0.654011, acc.: 59.38%] [G loss: 0.753441]\n",
      "epoch:17 step:13327 [D loss: 0.733660, acc.: 42.97%] [G loss: 0.740737]\n",
      "epoch:17 step:13328 [D loss: 0.697033, acc.: 55.47%] [G loss: 0.712338]\n",
      "epoch:17 step:13329 [D loss: 0.656098, acc.: 64.84%] [G loss: 0.737297]\n",
      "epoch:17 step:13330 [D loss: 0.721564, acc.: 44.53%] [G loss: 0.733214]\n",
      "epoch:17 step:13331 [D loss: 0.706910, acc.: 43.75%] [G loss: 0.704085]\n",
      "epoch:17 step:13332 [D loss: 0.676836, acc.: 56.25%] [G loss: 0.770319]\n",
      "epoch:17 step:13333 [D loss: 0.736183, acc.: 46.09%] [G loss: 0.726565]\n",
      "epoch:17 step:13334 [D loss: 0.693678, acc.: 50.78%] [G loss: 0.723048]\n",
      "epoch:17 step:13335 [D loss: 0.680032, acc.: 52.34%] [G loss: 0.674244]\n",
      "epoch:17 step:13336 [D loss: 0.723339, acc.: 47.66%] [G loss: 0.808898]\n",
      "epoch:17 step:13337 [D loss: 0.728469, acc.: 41.41%] [G loss: 0.731731]\n",
      "epoch:17 step:13338 [D loss: 0.664332, acc.: 64.06%] [G loss: 0.704261]\n",
      "epoch:17 step:13339 [D loss: 0.653947, acc.: 60.16%] [G loss: 0.742024]\n",
      "epoch:17 step:13340 [D loss: 0.726242, acc.: 42.19%] [G loss: 0.756071]\n",
      "epoch:17 step:13341 [D loss: 0.721883, acc.: 50.78%] [G loss: 0.812493]\n",
      "epoch:17 step:13342 [D loss: 0.736908, acc.: 38.28%] [G loss: 0.812514]\n",
      "epoch:17 step:13343 [D loss: 0.706455, acc.: 53.12%] [G loss: 0.787324]\n",
      "epoch:17 step:13344 [D loss: 0.665620, acc.: 57.81%] [G loss: 0.864371]\n",
      "epoch:17 step:13345 [D loss: 0.734918, acc.: 44.53%] [G loss: 0.764490]\n",
      "epoch:17 step:13346 [D loss: 0.713184, acc.: 52.34%] [G loss: 0.761437]\n",
      "epoch:17 step:13347 [D loss: 0.701625, acc.: 54.69%] [G loss: 0.753699]\n",
      "epoch:17 step:13348 [D loss: 0.683691, acc.: 57.81%] [G loss: 0.772676]\n",
      "epoch:17 step:13349 [D loss: 0.691478, acc.: 47.66%] [G loss: 0.713153]\n",
      "epoch:17 step:13350 [D loss: 0.677266, acc.: 57.81%] [G loss: 0.747450]\n",
      "epoch:17 step:13351 [D loss: 0.659586, acc.: 62.50%] [G loss: 0.764145]\n",
      "epoch:17 step:13352 [D loss: 0.684215, acc.: 57.03%] [G loss: 0.749022]\n",
      "epoch:17 step:13353 [D loss: 0.700637, acc.: 47.66%] [G loss: 0.816056]\n",
      "epoch:17 step:13354 [D loss: 0.617209, acc.: 73.44%] [G loss: 0.782771]\n",
      "epoch:17 step:13355 [D loss: 0.701881, acc.: 50.00%] [G loss: 0.740017]\n",
      "epoch:17 step:13356 [D loss: 0.684100, acc.: 59.38%] [G loss: 0.762247]\n",
      "epoch:17 step:13357 [D loss: 0.671546, acc.: 59.38%] [G loss: 0.822440]\n",
      "epoch:17 step:13358 [D loss: 0.679047, acc.: 60.94%] [G loss: 0.822392]\n",
      "epoch:17 step:13359 [D loss: 0.682412, acc.: 53.12%] [G loss: 0.775730]\n",
      "epoch:17 step:13360 [D loss: 0.668555, acc.: 60.16%] [G loss: 0.771559]\n",
      "epoch:17 step:13361 [D loss: 0.784400, acc.: 28.12%] [G loss: 0.727731]\n",
      "epoch:17 step:13362 [D loss: 0.628932, acc.: 71.09%] [G loss: 0.834210]\n",
      "epoch:17 step:13363 [D loss: 0.698700, acc.: 46.09%] [G loss: 0.695984]\n",
      "epoch:17 step:13364 [D loss: 0.719276, acc.: 47.66%] [G loss: 0.777436]\n",
      "epoch:17 step:13365 [D loss: 0.675221, acc.: 54.69%] [G loss: 0.805094]\n",
      "epoch:17 step:13366 [D loss: 0.682620, acc.: 50.00%] [G loss: 0.782231]\n",
      "epoch:17 step:13367 [D loss: 0.703260, acc.: 46.88%] [G loss: 0.813393]\n",
      "epoch:17 step:13368 [D loss: 0.795071, acc.: 35.94%] [G loss: 0.741219]\n",
      "epoch:17 step:13369 [D loss: 0.746290, acc.: 35.16%] [G loss: 0.711458]\n",
      "epoch:17 step:13370 [D loss: 0.674161, acc.: 58.59%] [G loss: 0.779633]\n",
      "epoch:17 step:13371 [D loss: 0.707718, acc.: 48.44%] [G loss: 0.786553]\n",
      "epoch:17 step:13372 [D loss: 0.696556, acc.: 52.34%] [G loss: 0.736603]\n",
      "epoch:17 step:13373 [D loss: 0.696405, acc.: 48.44%] [G loss: 0.851237]\n",
      "epoch:17 step:13374 [D loss: 0.665713, acc.: 58.59%] [G loss: 0.869088]\n",
      "epoch:17 step:13375 [D loss: 0.713666, acc.: 50.00%] [G loss: 0.927139]\n",
      "epoch:17 step:13376 [D loss: 0.684768, acc.: 54.69%] [G loss: 0.843639]\n",
      "epoch:17 step:13377 [D loss: 0.742658, acc.: 44.53%] [G loss: 0.731091]\n",
      "epoch:17 step:13378 [D loss: 0.678394, acc.: 53.91%] [G loss: 0.750439]\n",
      "epoch:17 step:13379 [D loss: 0.719314, acc.: 46.88%] [G loss: 0.752156]\n",
      "epoch:17 step:13380 [D loss: 0.764820, acc.: 38.28%] [G loss: 0.677438]\n",
      "epoch:17 step:13381 [D loss: 0.754145, acc.: 35.16%] [G loss: 0.715528]\n",
      "epoch:17 step:13382 [D loss: 0.700279, acc.: 51.56%] [G loss: 0.683886]\n",
      "epoch:17 step:13383 [D loss: 0.719119, acc.: 50.78%] [G loss: 0.701224]\n",
      "epoch:17 step:13384 [D loss: 0.672781, acc.: 57.81%] [G loss: 0.706218]\n",
      "epoch:17 step:13385 [D loss: 0.794648, acc.: 32.03%] [G loss: 0.628089]\n",
      "epoch:17 step:13386 [D loss: 0.728481, acc.: 45.31%] [G loss: 0.654760]\n",
      "epoch:17 step:13387 [D loss: 0.694889, acc.: 53.91%] [G loss: 0.684105]\n",
      "epoch:17 step:13388 [D loss: 0.726959, acc.: 48.44%] [G loss: 0.661081]\n",
      "epoch:17 step:13389 [D loss: 0.688385, acc.: 53.12%] [G loss: 0.757348]\n",
      "epoch:17 step:13390 [D loss: 0.663603, acc.: 61.72%] [G loss: 0.669917]\n",
      "epoch:17 step:13391 [D loss: 0.688572, acc.: 53.12%] [G loss: 0.743017]\n",
      "epoch:17 step:13392 [D loss: 0.756479, acc.: 38.28%] [G loss: 0.719003]\n",
      "epoch:17 step:13393 [D loss: 0.709669, acc.: 45.31%] [G loss: 0.720473]\n",
      "epoch:17 step:13394 [D loss: 0.664575, acc.: 57.03%] [G loss: 0.736364]\n",
      "epoch:17 step:13395 [D loss: 0.678102, acc.: 57.81%] [G loss: 0.742739]\n",
      "epoch:17 step:13396 [D loss: 0.682787, acc.: 54.69%] [G loss: 0.728800]\n",
      "epoch:17 step:13397 [D loss: 0.661813, acc.: 64.84%] [G loss: 0.757755]\n",
      "epoch:17 step:13398 [D loss: 0.646297, acc.: 67.19%] [G loss: 0.782241]\n",
      "epoch:17 step:13399 [D loss: 0.722898, acc.: 46.88%] [G loss: 0.672570]\n",
      "epoch:17 step:13400 [D loss: 0.699022, acc.: 48.44%] [G loss: 0.694331]\n",
      "epoch:17 step:13401 [D loss: 0.734050, acc.: 40.62%] [G loss: 0.717124]\n",
      "epoch:17 step:13402 [D loss: 0.742826, acc.: 34.38%] [G loss: 0.728137]\n",
      "epoch:17 step:13403 [D loss: 0.737367, acc.: 40.62%] [G loss: 0.661342]\n",
      "epoch:17 step:13404 [D loss: 0.693339, acc.: 53.91%] [G loss: 0.694036]\n",
      "epoch:17 step:13405 [D loss: 0.682529, acc.: 55.47%] [G loss: 0.723980]\n",
      "epoch:17 step:13406 [D loss: 0.697356, acc.: 55.47%] [G loss: 0.753679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13407 [D loss: 0.693193, acc.: 50.78%] [G loss: 0.793456]\n",
      "epoch:17 step:13408 [D loss: 0.730931, acc.: 46.09%] [G loss: 0.792453]\n",
      "epoch:17 step:13409 [D loss: 0.684119, acc.: 52.34%] [G loss: 0.771697]\n",
      "epoch:17 step:13410 [D loss: 0.707494, acc.: 44.53%] [G loss: 0.741341]\n",
      "epoch:17 step:13411 [D loss: 0.692389, acc.: 52.34%] [G loss: 0.769423]\n",
      "epoch:17 step:13412 [D loss: 0.741829, acc.: 42.97%] [G loss: 0.749090]\n",
      "epoch:17 step:13413 [D loss: 0.670093, acc.: 59.38%] [G loss: 0.789296]\n",
      "epoch:17 step:13414 [D loss: 0.712351, acc.: 43.75%] [G loss: 0.725083]\n",
      "epoch:17 step:13415 [D loss: 0.720958, acc.: 50.00%] [G loss: 0.703860]\n",
      "epoch:17 step:13416 [D loss: 0.690589, acc.: 56.25%] [G loss: 0.692594]\n",
      "epoch:17 step:13417 [D loss: 0.675304, acc.: 55.47%] [G loss: 0.731532]\n",
      "epoch:17 step:13418 [D loss: 0.716703, acc.: 45.31%] [G loss: 0.704172]\n",
      "epoch:17 step:13419 [D loss: 0.660897, acc.: 62.50%] [G loss: 0.845434]\n",
      "epoch:17 step:13420 [D loss: 0.690182, acc.: 52.34%] [G loss: 0.774057]\n",
      "epoch:17 step:13421 [D loss: 0.703350, acc.: 45.31%] [G loss: 0.712191]\n",
      "epoch:17 step:13422 [D loss: 0.712413, acc.: 46.09%] [G loss: 0.684201]\n",
      "epoch:17 step:13423 [D loss: 0.651423, acc.: 64.06%] [G loss: 0.691417]\n",
      "epoch:17 step:13424 [D loss: 0.651205, acc.: 63.28%] [G loss: 0.778936]\n",
      "epoch:17 step:13425 [D loss: 0.707634, acc.: 52.34%] [G loss: 0.749582]\n",
      "epoch:17 step:13426 [D loss: 0.744684, acc.: 42.19%] [G loss: 0.673443]\n",
      "epoch:17 step:13427 [D loss: 0.763311, acc.: 38.28%] [G loss: 0.703390]\n",
      "epoch:17 step:13428 [D loss: 0.688128, acc.: 56.25%] [G loss: 0.713570]\n",
      "epoch:17 step:13429 [D loss: 0.701081, acc.: 50.78%] [G loss: 0.731537]\n",
      "epoch:17 step:13430 [D loss: 0.722332, acc.: 46.88%] [G loss: 0.758178]\n",
      "epoch:17 step:13431 [D loss: 0.664702, acc.: 60.16%] [G loss: 0.763511]\n",
      "epoch:17 step:13432 [D loss: 0.690559, acc.: 51.56%] [G loss: 0.752290]\n",
      "epoch:17 step:13433 [D loss: 0.715721, acc.: 46.09%] [G loss: 0.737415]\n",
      "epoch:17 step:13434 [D loss: 0.707245, acc.: 47.66%] [G loss: 0.644899]\n",
      "epoch:17 step:13435 [D loss: 0.700769, acc.: 46.88%] [G loss: 0.723055]\n",
      "epoch:17 step:13436 [D loss: 0.667613, acc.: 57.81%] [G loss: 0.774375]\n",
      "epoch:17 step:13437 [D loss: 0.709620, acc.: 48.44%] [G loss: 0.743349]\n",
      "epoch:17 step:13438 [D loss: 0.686594, acc.: 50.78%] [G loss: 0.801591]\n",
      "epoch:17 step:13439 [D loss: 0.711697, acc.: 40.62%] [G loss: 0.792958]\n",
      "epoch:17 step:13440 [D loss: 0.670444, acc.: 57.03%] [G loss: 0.763994]\n",
      "epoch:17 step:13441 [D loss: 0.727801, acc.: 41.41%] [G loss: 0.777793]\n",
      "epoch:17 step:13442 [D loss: 0.718959, acc.: 41.41%] [G loss: 0.837285]\n",
      "epoch:17 step:13443 [D loss: 0.666720, acc.: 60.16%] [G loss: 0.793654]\n",
      "epoch:17 step:13444 [D loss: 0.744965, acc.: 34.38%] [G loss: 0.754350]\n",
      "epoch:17 step:13445 [D loss: 0.699153, acc.: 51.56%] [G loss: 0.735298]\n",
      "epoch:17 step:13446 [D loss: 0.742657, acc.: 36.72%] [G loss: 0.811555]\n",
      "epoch:17 step:13447 [D loss: 0.722998, acc.: 39.06%] [G loss: 0.823471]\n",
      "epoch:17 step:13448 [D loss: 0.702803, acc.: 52.34%] [G loss: 0.820709]\n",
      "epoch:17 step:13449 [D loss: 0.718205, acc.: 44.53%] [G loss: 0.749471]\n",
      "epoch:17 step:13450 [D loss: 0.707873, acc.: 48.44%] [G loss: 0.715938]\n",
      "epoch:17 step:13451 [D loss: 0.695303, acc.: 46.09%] [G loss: 0.776256]\n",
      "epoch:17 step:13452 [D loss: 0.684444, acc.: 56.25%] [G loss: 0.813721]\n",
      "epoch:17 step:13453 [D loss: 0.687857, acc.: 55.47%] [G loss: 0.744784]\n",
      "epoch:17 step:13454 [D loss: 0.723165, acc.: 44.53%] [G loss: 0.719099]\n",
      "epoch:17 step:13455 [D loss: 0.706537, acc.: 51.56%] [G loss: 0.775563]\n",
      "epoch:17 step:13456 [D loss: 0.663893, acc.: 60.94%] [G loss: 0.813056]\n",
      "epoch:17 step:13457 [D loss: 0.667997, acc.: 57.03%] [G loss: 0.843252]\n",
      "epoch:17 step:13458 [D loss: 0.656274, acc.: 68.75%] [G loss: 0.761584]\n",
      "epoch:17 step:13459 [D loss: 0.752390, acc.: 34.38%] [G loss: 0.800454]\n",
      "epoch:17 step:13460 [D loss: 0.701416, acc.: 50.00%] [G loss: 0.720402]\n",
      "epoch:17 step:13461 [D loss: 0.726973, acc.: 35.94%] [G loss: 0.753148]\n",
      "epoch:17 step:13462 [D loss: 0.689879, acc.: 54.69%] [G loss: 0.784783]\n",
      "epoch:17 step:13463 [D loss: 0.699026, acc.: 53.91%] [G loss: 0.814481]\n",
      "epoch:17 step:13464 [D loss: 0.693927, acc.: 48.44%] [G loss: 0.790369]\n",
      "epoch:17 step:13465 [D loss: 0.726391, acc.: 51.56%] [G loss: 0.722636]\n",
      "epoch:17 step:13466 [D loss: 0.674782, acc.: 56.25%] [G loss: 0.758025]\n",
      "epoch:17 step:13467 [D loss: 0.728876, acc.: 39.84%] [G loss: 0.723713]\n",
      "epoch:17 step:13468 [D loss: 0.711445, acc.: 48.44%] [G loss: 0.821001]\n",
      "epoch:17 step:13469 [D loss: 0.756916, acc.: 32.81%] [G loss: 0.736466]\n",
      "epoch:17 step:13470 [D loss: 0.720453, acc.: 46.88%] [G loss: 0.748085]\n",
      "epoch:17 step:13471 [D loss: 0.690622, acc.: 53.12%] [G loss: 0.721407]\n",
      "epoch:17 step:13472 [D loss: 0.708801, acc.: 45.31%] [G loss: 0.753319]\n",
      "epoch:17 step:13473 [D loss: 0.723581, acc.: 41.41%] [G loss: 0.730293]\n",
      "epoch:17 step:13474 [D loss: 0.687973, acc.: 60.16%] [G loss: 0.748374]\n",
      "epoch:17 step:13475 [D loss: 0.689095, acc.: 53.91%] [G loss: 0.769247]\n",
      "epoch:17 step:13476 [D loss: 0.736896, acc.: 45.31%] [G loss: 0.736252]\n",
      "epoch:17 step:13477 [D loss: 0.749093, acc.: 37.50%] [G loss: 0.683903]\n",
      "epoch:17 step:13478 [D loss: 0.677548, acc.: 58.59%] [G loss: 0.777852]\n",
      "epoch:17 step:13479 [D loss: 0.719511, acc.: 49.22%] [G loss: 0.688431]\n",
      "epoch:17 step:13480 [D loss: 0.678969, acc.: 53.91%] [G loss: 0.746686]\n",
      "epoch:17 step:13481 [D loss: 0.708358, acc.: 46.09%] [G loss: 0.781897]\n",
      "epoch:17 step:13482 [D loss: 0.721764, acc.: 43.75%] [G loss: 0.784111]\n",
      "epoch:17 step:13483 [D loss: 0.709840, acc.: 48.44%] [G loss: 0.781343]\n",
      "epoch:17 step:13484 [D loss: 0.629822, acc.: 73.44%] [G loss: 0.781579]\n",
      "epoch:17 step:13485 [D loss: 0.685946, acc.: 52.34%] [G loss: 0.742305]\n",
      "epoch:17 step:13486 [D loss: 0.675677, acc.: 53.12%] [G loss: 0.734810]\n",
      "epoch:17 step:13487 [D loss: 0.676734, acc.: 58.59%] [G loss: 0.764241]\n",
      "epoch:17 step:13488 [D loss: 0.676046, acc.: 51.56%] [G loss: 0.737490]\n",
      "epoch:17 step:13489 [D loss: 0.679935, acc.: 57.03%] [G loss: 0.784689]\n",
      "epoch:17 step:13490 [D loss: 0.720471, acc.: 41.41%] [G loss: 0.742165]\n",
      "epoch:17 step:13491 [D loss: 0.660393, acc.: 61.72%] [G loss: 0.771297]\n",
      "epoch:17 step:13492 [D loss: 0.652791, acc.: 62.50%] [G loss: 0.750109]\n",
      "epoch:17 step:13493 [D loss: 0.749912, acc.: 33.59%] [G loss: 0.699587]\n",
      "epoch:17 step:13494 [D loss: 0.710543, acc.: 50.00%] [G loss: 0.731699]\n",
      "epoch:17 step:13495 [D loss: 0.687497, acc.: 50.78%] [G loss: 0.732871]\n",
      "epoch:17 step:13496 [D loss: 0.670260, acc.: 63.28%] [G loss: 0.715803]\n",
      "epoch:17 step:13497 [D loss: 0.677511, acc.: 54.69%] [G loss: 0.800272]\n",
      "epoch:17 step:13498 [D loss: 0.698669, acc.: 44.53%] [G loss: 0.731165]\n",
      "epoch:17 step:13499 [D loss: 0.734338, acc.: 42.19%] [G loss: 0.719931]\n",
      "epoch:17 step:13500 [D loss: 0.677167, acc.: 57.03%] [G loss: 0.768996]\n",
      "epoch:17 step:13501 [D loss: 0.661235, acc.: 64.06%] [G loss: 0.687772]\n",
      "epoch:17 step:13502 [D loss: 0.668158, acc.: 61.72%] [G loss: 0.660935]\n",
      "epoch:17 step:13503 [D loss: 0.720046, acc.: 47.66%] [G loss: 0.702394]\n",
      "epoch:17 step:13504 [D loss: 0.721973, acc.: 50.78%] [G loss: 0.764671]\n",
      "epoch:17 step:13505 [D loss: 0.699220, acc.: 51.56%] [G loss: 0.786943]\n",
      "epoch:17 step:13506 [D loss: 0.650009, acc.: 64.84%] [G loss: 0.833699]\n",
      "epoch:17 step:13507 [D loss: 0.745687, acc.: 35.16%] [G loss: 0.769020]\n",
      "epoch:17 step:13508 [D loss: 0.678297, acc.: 52.34%] [G loss: 0.805504]\n",
      "epoch:17 step:13509 [D loss: 0.740577, acc.: 45.31%] [G loss: 0.701962]\n",
      "epoch:17 step:13510 [D loss: 0.672439, acc.: 61.72%] [G loss: 0.757317]\n",
      "epoch:17 step:13511 [D loss: 0.691782, acc.: 51.56%] [G loss: 0.709182]\n",
      "epoch:17 step:13512 [D loss: 0.761625, acc.: 38.28%] [G loss: 0.719573]\n",
      "epoch:17 step:13513 [D loss: 0.749066, acc.: 43.75%] [G loss: 0.672178]\n",
      "epoch:17 step:13514 [D loss: 0.749861, acc.: 45.31%] [G loss: 0.662683]\n",
      "epoch:17 step:13515 [D loss: 0.715497, acc.: 42.19%] [G loss: 0.717340]\n",
      "epoch:17 step:13516 [D loss: 0.681514, acc.: 57.03%] [G loss: 0.769890]\n",
      "epoch:17 step:13517 [D loss: 0.723415, acc.: 48.44%] [G loss: 0.771239]\n",
      "epoch:17 step:13518 [D loss: 0.690878, acc.: 53.12%] [G loss: 0.743041]\n",
      "epoch:17 step:13519 [D loss: 0.705201, acc.: 50.78%] [G loss: 0.758288]\n",
      "epoch:17 step:13520 [D loss: 0.708468, acc.: 44.53%] [G loss: 0.743188]\n",
      "epoch:17 step:13521 [D loss: 0.676552, acc.: 58.59%] [G loss: 0.781273]\n",
      "epoch:17 step:13522 [D loss: 0.682901, acc.: 57.03%] [G loss: 0.782704]\n",
      "epoch:17 step:13523 [D loss: 0.684767, acc.: 53.12%] [G loss: 0.758284]\n",
      "epoch:17 step:13524 [D loss: 0.661502, acc.: 63.28%] [G loss: 0.785170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13525 [D loss: 0.654403, acc.: 61.72%] [G loss: 0.815248]\n",
      "epoch:17 step:13526 [D loss: 0.690970, acc.: 55.47%] [G loss: 0.770815]\n",
      "epoch:17 step:13527 [D loss: 0.672428, acc.: 59.38%] [G loss: 0.732251]\n",
      "epoch:17 step:13528 [D loss: 0.699169, acc.: 49.22%] [G loss: 0.712047]\n",
      "epoch:17 step:13529 [D loss: 0.688542, acc.: 50.78%] [G loss: 0.744799]\n",
      "epoch:17 step:13530 [D loss: 0.733466, acc.: 42.97%] [G loss: 0.732555]\n",
      "epoch:17 step:13531 [D loss: 0.750776, acc.: 42.19%] [G loss: 0.684949]\n",
      "epoch:17 step:13532 [D loss: 0.701161, acc.: 50.00%] [G loss: 0.740651]\n",
      "epoch:17 step:13533 [D loss: 0.717222, acc.: 44.53%] [G loss: 0.760059]\n",
      "epoch:17 step:13534 [D loss: 0.710241, acc.: 47.66%] [G loss: 0.737740]\n",
      "epoch:17 step:13535 [D loss: 0.682797, acc.: 54.69%] [G loss: 0.751030]\n",
      "epoch:17 step:13536 [D loss: 0.676301, acc.: 54.69%] [G loss: 0.920259]\n",
      "epoch:17 step:13537 [D loss: 0.685317, acc.: 54.69%] [G loss: 0.787319]\n",
      "epoch:17 step:13538 [D loss: 0.666111, acc.: 60.16%] [G loss: 0.789610]\n",
      "epoch:17 step:13539 [D loss: 0.669417, acc.: 63.28%] [G loss: 0.801853]\n",
      "epoch:17 step:13540 [D loss: 0.715146, acc.: 50.78%] [G loss: 0.754435]\n",
      "epoch:17 step:13541 [D loss: 0.656748, acc.: 70.31%] [G loss: 0.807651]\n",
      "epoch:17 step:13542 [D loss: 0.699201, acc.: 51.56%] [G loss: 0.813376]\n",
      "epoch:17 step:13543 [D loss: 0.673922, acc.: 57.81%] [G loss: 0.796847]\n",
      "epoch:17 step:13544 [D loss: 0.736118, acc.: 39.84%] [G loss: 0.735081]\n",
      "epoch:17 step:13545 [D loss: 0.707645, acc.: 50.00%] [G loss: 0.718201]\n",
      "epoch:17 step:13546 [D loss: 0.665699, acc.: 63.28%] [G loss: 0.758414]\n",
      "epoch:17 step:13547 [D loss: 0.660300, acc.: 63.28%] [G loss: 0.779912]\n",
      "epoch:17 step:13548 [D loss: 0.712987, acc.: 52.34%] [G loss: 0.802215]\n",
      "epoch:17 step:13549 [D loss: 0.696062, acc.: 55.47%] [G loss: 0.747543]\n",
      "epoch:17 step:13550 [D loss: 0.706895, acc.: 50.78%] [G loss: 0.765880]\n",
      "epoch:17 step:13551 [D loss: 0.656392, acc.: 66.41%] [G loss: 0.825827]\n",
      "epoch:17 step:13552 [D loss: 0.699207, acc.: 53.12%] [G loss: 0.768058]\n",
      "epoch:17 step:13553 [D loss: 0.659485, acc.: 62.50%] [G loss: 0.805523]\n",
      "epoch:17 step:13554 [D loss: 0.728946, acc.: 41.41%] [G loss: 0.744558]\n",
      "epoch:17 step:13555 [D loss: 0.746731, acc.: 40.62%] [G loss: 0.740976]\n",
      "epoch:17 step:13556 [D loss: 0.666775, acc.: 63.28%] [G loss: 0.738344]\n",
      "epoch:17 step:13557 [D loss: 0.672300, acc.: 57.81%] [G loss: 0.767709]\n",
      "epoch:17 step:13558 [D loss: 0.671014, acc.: 54.69%] [G loss: 0.759698]\n",
      "epoch:17 step:13559 [D loss: 0.709181, acc.: 50.78%] [G loss: 0.745782]\n",
      "epoch:17 step:13560 [D loss: 0.670981, acc.: 61.72%] [G loss: 0.769914]\n",
      "epoch:17 step:13561 [D loss: 0.644228, acc.: 68.75%] [G loss: 0.747192]\n",
      "epoch:17 step:13562 [D loss: 0.684508, acc.: 50.00%] [G loss: 0.811603]\n",
      "epoch:17 step:13563 [D loss: 0.686723, acc.: 50.00%] [G loss: 0.781418]\n",
      "epoch:17 step:13564 [D loss: 0.682342, acc.: 53.91%] [G loss: 0.764819]\n",
      "epoch:17 step:13565 [D loss: 0.684945, acc.: 58.59%] [G loss: 0.743836]\n",
      "epoch:17 step:13566 [D loss: 0.676260, acc.: 57.81%] [G loss: 0.746432]\n",
      "epoch:17 step:13567 [D loss: 0.656762, acc.: 65.62%] [G loss: 0.726788]\n",
      "epoch:17 step:13568 [D loss: 0.730796, acc.: 42.19%] [G loss: 0.729784]\n",
      "epoch:17 step:13569 [D loss: 0.692137, acc.: 59.38%] [G loss: 0.758228]\n",
      "epoch:17 step:13570 [D loss: 0.704745, acc.: 57.03%] [G loss: 0.692423]\n",
      "epoch:17 step:13571 [D loss: 0.710143, acc.: 50.78%] [G loss: 0.795375]\n",
      "epoch:17 step:13572 [D loss: 0.697458, acc.: 50.00%] [G loss: 0.719039]\n",
      "epoch:17 step:13573 [D loss: 0.700405, acc.: 55.47%] [G loss: 0.725993]\n",
      "epoch:17 step:13574 [D loss: 0.669544, acc.: 58.59%] [G loss: 0.785618]\n",
      "epoch:17 step:13575 [D loss: 0.697105, acc.: 53.12%] [G loss: 0.799469]\n",
      "epoch:17 step:13576 [D loss: 0.698297, acc.: 47.66%] [G loss: 0.754919]\n",
      "epoch:17 step:13577 [D loss: 0.715838, acc.: 49.22%] [G loss: 0.745460]\n",
      "epoch:17 step:13578 [D loss: 0.675659, acc.: 60.16%] [G loss: 0.748417]\n",
      "epoch:17 step:13579 [D loss: 0.659774, acc.: 64.06%] [G loss: 0.747475]\n",
      "epoch:17 step:13580 [D loss: 0.710633, acc.: 51.56%] [G loss: 0.773700]\n",
      "epoch:17 step:13581 [D loss: 0.672012, acc.: 55.47%] [G loss: 0.789450]\n",
      "epoch:17 step:13582 [D loss: 0.766301, acc.: 34.38%] [G loss: 0.713936]\n",
      "epoch:17 step:13583 [D loss: 0.664530, acc.: 54.69%] [G loss: 0.752305]\n",
      "epoch:17 step:13584 [D loss: 0.708181, acc.: 54.69%] [G loss: 0.707116]\n",
      "epoch:17 step:13585 [D loss: 0.648166, acc.: 60.16%] [G loss: 0.750685]\n",
      "epoch:17 step:13586 [D loss: 0.702376, acc.: 49.22%] [G loss: 0.693934]\n",
      "epoch:17 step:13587 [D loss: 0.709417, acc.: 52.34%] [G loss: 0.764598]\n",
      "epoch:17 step:13588 [D loss: 0.720720, acc.: 53.91%] [G loss: 0.738153]\n",
      "epoch:17 step:13589 [D loss: 0.666271, acc.: 62.50%] [G loss: 0.726139]\n",
      "epoch:17 step:13590 [D loss: 0.732085, acc.: 43.75%] [G loss: 0.666600]\n",
      "epoch:17 step:13591 [D loss: 0.714250, acc.: 45.31%] [G loss: 0.705967]\n",
      "epoch:17 step:13592 [D loss: 0.737303, acc.: 37.50%] [G loss: 0.669177]\n",
      "epoch:17 step:13593 [D loss: 0.741178, acc.: 43.75%] [G loss: 0.709985]\n",
      "epoch:17 step:13594 [D loss: 0.650574, acc.: 62.50%] [G loss: 0.792552]\n",
      "epoch:17 step:13595 [D loss: 0.679281, acc.: 60.94%] [G loss: 0.804209]\n",
      "epoch:17 step:13596 [D loss: 0.695833, acc.: 49.22%] [G loss: 0.747670]\n",
      "epoch:17 step:13597 [D loss: 0.674378, acc.: 60.16%] [G loss: 0.771593]\n",
      "epoch:17 step:13598 [D loss: 0.692889, acc.: 57.03%] [G loss: 0.804879]\n",
      "epoch:17 step:13599 [D loss: 0.699011, acc.: 53.12%] [G loss: 0.705218]\n",
      "epoch:17 step:13600 [D loss: 0.701261, acc.: 53.91%] [G loss: 0.772141]\n",
      "epoch:17 step:13601 [D loss: 0.674328, acc.: 62.50%] [G loss: 0.746301]\n",
      "epoch:17 step:13602 [D loss: 0.696350, acc.: 50.78%] [G loss: 0.809727]\n",
      "epoch:17 step:13603 [D loss: 0.683490, acc.: 57.81%] [G loss: 0.886526]\n",
      "epoch:17 step:13604 [D loss: 0.697481, acc.: 49.22%] [G loss: 0.833543]\n",
      "epoch:17 step:13605 [D loss: 0.691873, acc.: 60.16%] [G loss: 0.839100]\n",
      "epoch:17 step:13606 [D loss: 0.717526, acc.: 46.88%] [G loss: 0.765901]\n",
      "epoch:17 step:13607 [D loss: 0.700245, acc.: 50.78%] [G loss: 0.732447]\n",
      "epoch:17 step:13608 [D loss: 0.699476, acc.: 50.78%] [G loss: 0.740076]\n",
      "epoch:17 step:13609 [D loss: 0.679348, acc.: 58.59%] [G loss: 0.730897]\n",
      "epoch:17 step:13610 [D loss: 0.687684, acc.: 50.00%] [G loss: 0.772031]\n",
      "epoch:17 step:13611 [D loss: 0.691923, acc.: 52.34%] [G loss: 0.699216]\n",
      "epoch:17 step:13612 [D loss: 0.725341, acc.: 43.75%] [G loss: 0.670300]\n",
      "epoch:17 step:13613 [D loss: 0.701851, acc.: 57.03%] [G loss: 0.722253]\n",
      "epoch:17 step:13614 [D loss: 0.703805, acc.: 50.00%] [G loss: 0.734851]\n",
      "epoch:17 step:13615 [D loss: 0.797735, acc.: 27.34%] [G loss: 0.671927]\n",
      "epoch:17 step:13616 [D loss: 0.699178, acc.: 49.22%] [G loss: 0.763475]\n",
      "epoch:17 step:13617 [D loss: 0.713051, acc.: 46.88%] [G loss: 0.749927]\n",
      "epoch:17 step:13618 [D loss: 0.734069, acc.: 40.62%] [G loss: 0.712744]\n",
      "epoch:17 step:13619 [D loss: 0.697300, acc.: 48.44%] [G loss: 0.714001]\n",
      "epoch:17 step:13620 [D loss: 0.674796, acc.: 55.47%] [G loss: 0.713984]\n",
      "epoch:17 step:13621 [D loss: 0.676796, acc.: 60.94%] [G loss: 0.739137]\n",
      "epoch:17 step:13622 [D loss: 0.694716, acc.: 48.44%] [G loss: 0.770012]\n",
      "epoch:17 step:13623 [D loss: 0.667744, acc.: 58.59%] [G loss: 0.836436]\n",
      "epoch:17 step:13624 [D loss: 0.716114, acc.: 44.53%] [G loss: 0.829675]\n",
      "epoch:17 step:13625 [D loss: 0.729893, acc.: 44.53%] [G loss: 0.771815]\n",
      "epoch:17 step:13626 [D loss: 0.702018, acc.: 46.88%] [G loss: 0.803041]\n",
      "epoch:17 step:13627 [D loss: 0.725492, acc.: 42.97%] [G loss: 0.758454]\n",
      "epoch:17 step:13628 [D loss: 0.740076, acc.: 38.28%] [G loss: 0.750237]\n",
      "epoch:17 step:13629 [D loss: 0.725445, acc.: 40.62%] [G loss: 0.762509]\n",
      "epoch:17 step:13630 [D loss: 0.691685, acc.: 51.56%] [G loss: 0.742062]\n",
      "epoch:17 step:13631 [D loss: 0.649229, acc.: 61.72%] [G loss: 0.799866]\n",
      "epoch:17 step:13632 [D loss: 0.692760, acc.: 53.12%] [G loss: 0.764869]\n",
      "epoch:17 step:13633 [D loss: 0.705216, acc.: 51.56%] [G loss: 0.748612]\n",
      "epoch:17 step:13634 [D loss: 0.694624, acc.: 46.88%] [G loss: 0.811859]\n",
      "epoch:17 step:13635 [D loss: 0.718842, acc.: 49.22%] [G loss: 0.757927]\n",
      "epoch:17 step:13636 [D loss: 0.705092, acc.: 51.56%] [G loss: 0.779838]\n",
      "epoch:17 step:13637 [D loss: 0.716829, acc.: 50.00%] [G loss: 0.761550]\n",
      "epoch:17 step:13638 [D loss: 0.651239, acc.: 62.50%] [G loss: 0.770368]\n",
      "epoch:17 step:13639 [D loss: 0.661513, acc.: 60.16%] [G loss: 0.819491]\n",
      "epoch:17 step:13640 [D loss: 0.726744, acc.: 38.28%] [G loss: 0.704377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13641 [D loss: 0.683672, acc.: 58.59%] [G loss: 0.733101]\n",
      "epoch:17 step:13642 [D loss: 0.692660, acc.: 50.78%] [G loss: 0.708647]\n",
      "epoch:17 step:13643 [D loss: 0.658573, acc.: 66.41%] [G loss: 0.742857]\n",
      "epoch:17 step:13644 [D loss: 0.678789, acc.: 53.91%] [G loss: 0.762040]\n",
      "epoch:17 step:13645 [D loss: 0.693018, acc.: 54.69%] [G loss: 0.720553]\n",
      "epoch:17 step:13646 [D loss: 0.687927, acc.: 57.81%] [G loss: 0.687504]\n",
      "epoch:17 step:13647 [D loss: 0.760265, acc.: 38.28%] [G loss: 0.716249]\n",
      "epoch:17 step:13648 [D loss: 0.702743, acc.: 41.41%] [G loss: 0.749010]\n",
      "epoch:17 step:13649 [D loss: 0.654846, acc.: 63.28%] [G loss: 0.791331]\n",
      "epoch:17 step:13650 [D loss: 0.699286, acc.: 48.44%] [G loss: 0.759598]\n",
      "epoch:17 step:13651 [D loss: 0.675135, acc.: 58.59%] [G loss: 0.794247]\n",
      "epoch:17 step:13652 [D loss: 0.715026, acc.: 45.31%] [G loss: 0.768959]\n",
      "epoch:17 step:13653 [D loss: 0.648465, acc.: 60.94%] [G loss: 0.807669]\n",
      "epoch:17 step:13654 [D loss: 0.707154, acc.: 53.12%] [G loss: 0.748328]\n",
      "epoch:17 step:13655 [D loss: 0.690462, acc.: 60.16%] [G loss: 0.769312]\n",
      "epoch:17 step:13656 [D loss: 0.679630, acc.: 55.47%] [G loss: 0.757718]\n",
      "epoch:17 step:13657 [D loss: 0.740496, acc.: 46.88%] [G loss: 0.731185]\n",
      "epoch:17 step:13658 [D loss: 0.682692, acc.: 57.81%] [G loss: 0.693685]\n",
      "epoch:17 step:13659 [D loss: 0.711334, acc.: 46.09%] [G loss: 0.761247]\n",
      "epoch:17 step:13660 [D loss: 0.786384, acc.: 33.59%] [G loss: 0.666844]\n",
      "epoch:17 step:13661 [D loss: 0.660372, acc.: 61.72%] [G loss: 0.711775]\n",
      "epoch:17 step:13662 [D loss: 0.694892, acc.: 46.09%] [G loss: 0.714350]\n",
      "epoch:17 step:13663 [D loss: 0.685270, acc.: 53.12%] [G loss: 0.741078]\n",
      "epoch:17 step:13664 [D loss: 0.683083, acc.: 53.12%] [G loss: 0.715526]\n",
      "epoch:17 step:13665 [D loss: 0.697148, acc.: 49.22%] [G loss: 0.792935]\n",
      "epoch:17 step:13666 [D loss: 0.707483, acc.: 43.75%] [G loss: 0.821583]\n",
      "epoch:17 step:13667 [D loss: 0.672362, acc.: 55.47%] [G loss: 0.867869]\n",
      "epoch:17 step:13668 [D loss: 0.753583, acc.: 41.41%] [G loss: 0.780549]\n",
      "epoch:17 step:13669 [D loss: 0.761264, acc.: 36.72%] [G loss: 0.754331]\n",
      "epoch:17 step:13670 [D loss: 0.669218, acc.: 55.47%] [G loss: 0.738527]\n",
      "epoch:17 step:13671 [D loss: 0.684864, acc.: 52.34%] [G loss: 0.699667]\n",
      "epoch:17 step:13672 [D loss: 0.710250, acc.: 43.75%] [G loss: 0.736956]\n",
      "epoch:17 step:13673 [D loss: 0.650096, acc.: 67.97%] [G loss: 0.747954]\n",
      "epoch:17 step:13674 [D loss: 0.700879, acc.: 54.69%] [G loss: 0.704892]\n",
      "epoch:17 step:13675 [D loss: 0.689385, acc.: 58.59%] [G loss: 0.668398]\n",
      "epoch:17 step:13676 [D loss: 0.669521, acc.: 59.38%] [G loss: 0.723506]\n",
      "epoch:17 step:13677 [D loss: 0.713467, acc.: 42.19%] [G loss: 0.702740]\n",
      "epoch:17 step:13678 [D loss: 0.669168, acc.: 60.94%] [G loss: 0.782080]\n",
      "epoch:17 step:13679 [D loss: 0.703886, acc.: 46.88%] [G loss: 0.705856]\n",
      "epoch:17 step:13680 [D loss: 0.691154, acc.: 57.03%] [G loss: 0.760434]\n",
      "epoch:17 step:13681 [D loss: 0.680942, acc.: 52.34%] [G loss: 0.797794]\n",
      "epoch:17 step:13682 [D loss: 0.736987, acc.: 42.19%] [G loss: 0.774408]\n",
      "epoch:17 step:13683 [D loss: 0.643402, acc.: 69.53%] [G loss: 0.826296]\n",
      "epoch:17 step:13684 [D loss: 0.679098, acc.: 57.03%] [G loss: 0.816541]\n",
      "epoch:17 step:13685 [D loss: 0.674435, acc.: 64.06%] [G loss: 0.803397]\n",
      "epoch:17 step:13686 [D loss: 0.714892, acc.: 44.53%] [G loss: 0.737455]\n",
      "epoch:17 step:13687 [D loss: 0.657820, acc.: 65.62%] [G loss: 0.718192]\n",
      "epoch:17 step:13688 [D loss: 0.745865, acc.: 39.84%] [G loss: 0.707186]\n",
      "epoch:17 step:13689 [D loss: 0.731416, acc.: 45.31%] [G loss: 0.747715]\n",
      "epoch:17 step:13690 [D loss: 0.690714, acc.: 52.34%] [G loss: 0.699502]\n",
      "epoch:17 step:13691 [D loss: 0.728663, acc.: 38.28%] [G loss: 0.686122]\n",
      "epoch:17 step:13692 [D loss: 0.690462, acc.: 49.22%] [G loss: 0.715664]\n",
      "epoch:17 step:13693 [D loss: 0.655892, acc.: 61.72%] [G loss: 0.723536]\n",
      "epoch:17 step:13694 [D loss: 0.681609, acc.: 54.69%] [G loss: 0.702504]\n",
      "epoch:17 step:13695 [D loss: 0.710937, acc.: 49.22%] [G loss: 0.752115]\n",
      "epoch:17 step:13696 [D loss: 0.727090, acc.: 39.84%] [G loss: 0.786373]\n",
      "epoch:17 step:13697 [D loss: 0.653251, acc.: 60.16%] [G loss: 0.864637]\n",
      "epoch:17 step:13698 [D loss: 0.745886, acc.: 41.41%] [G loss: 0.786812]\n",
      "epoch:17 step:13699 [D loss: 0.711061, acc.: 46.88%] [G loss: 0.801661]\n",
      "epoch:17 step:13700 [D loss: 0.746408, acc.: 40.62%] [G loss: 0.768767]\n",
      "epoch:17 step:13701 [D loss: 0.720837, acc.: 41.41%] [G loss: 0.783036]\n",
      "epoch:17 step:13702 [D loss: 0.716367, acc.: 49.22%] [G loss: 0.726474]\n",
      "epoch:17 step:13703 [D loss: 0.743937, acc.: 46.09%] [G loss: 0.749224]\n",
      "epoch:17 step:13704 [D loss: 0.703835, acc.: 46.88%] [G loss: 0.778423]\n",
      "epoch:17 step:13705 [D loss: 0.726188, acc.: 42.97%] [G loss: 0.757601]\n",
      "epoch:17 step:13706 [D loss: 0.694466, acc.: 46.09%] [G loss: 0.752291]\n",
      "epoch:17 step:13707 [D loss: 0.699392, acc.: 49.22%] [G loss: 0.778236]\n",
      "epoch:17 step:13708 [D loss: 0.736035, acc.: 41.41%] [G loss: 0.786185]\n",
      "epoch:17 step:13709 [D loss: 0.709076, acc.: 50.00%] [G loss: 0.771497]\n",
      "epoch:17 step:13710 [D loss: 0.696294, acc.: 51.56%] [G loss: 0.872586]\n",
      "epoch:17 step:13711 [D loss: 0.683004, acc.: 53.91%] [G loss: 0.804813]\n",
      "epoch:17 step:13712 [D loss: 0.689650, acc.: 53.12%] [G loss: 0.798749]\n",
      "epoch:17 step:13713 [D loss: 0.718908, acc.: 42.97%] [G loss: 0.834076]\n",
      "epoch:17 step:13714 [D loss: 0.732062, acc.: 39.06%] [G loss: 0.749607]\n",
      "epoch:17 step:13715 [D loss: 0.697618, acc.: 51.56%] [G loss: 0.818919]\n",
      "epoch:17 step:13716 [D loss: 0.681849, acc.: 51.56%] [G loss: 0.817750]\n",
      "epoch:17 step:13717 [D loss: 0.651310, acc.: 64.84%] [G loss: 0.750832]\n",
      "epoch:17 step:13718 [D loss: 0.700940, acc.: 51.56%] [G loss: 0.805608]\n",
      "epoch:17 step:13719 [D loss: 0.703162, acc.: 50.00%] [G loss: 0.770276]\n",
      "epoch:17 step:13720 [D loss: 0.686441, acc.: 58.59%] [G loss: 0.722388]\n",
      "epoch:17 step:13721 [D loss: 0.703849, acc.: 51.56%] [G loss: 0.754310]\n",
      "epoch:17 step:13722 [D loss: 0.738957, acc.: 41.41%] [G loss: 0.752027]\n",
      "epoch:17 step:13723 [D loss: 0.674806, acc.: 63.28%] [G loss: 0.762140]\n",
      "epoch:17 step:13724 [D loss: 0.732737, acc.: 42.97%] [G loss: 0.710015]\n",
      "epoch:17 step:13725 [D loss: 0.723828, acc.: 42.19%] [G loss: 0.748076]\n",
      "epoch:17 step:13726 [D loss: 0.674281, acc.: 63.28%] [G loss: 0.736651]\n",
      "epoch:17 step:13727 [D loss: 0.696754, acc.: 50.00%] [G loss: 0.733362]\n",
      "epoch:17 step:13728 [D loss: 0.693507, acc.: 50.00%] [G loss: 0.739226]\n",
      "epoch:17 step:13729 [D loss: 0.708617, acc.: 43.75%] [G loss: 0.757759]\n",
      "epoch:17 step:13730 [D loss: 0.677823, acc.: 58.59%] [G loss: 0.784514]\n",
      "epoch:17 step:13731 [D loss: 0.733477, acc.: 42.19%] [G loss: 0.778569]\n",
      "epoch:17 step:13732 [D loss: 0.721902, acc.: 43.75%] [G loss: 0.706704]\n",
      "epoch:17 step:13733 [D loss: 0.709297, acc.: 50.78%] [G loss: 0.784274]\n",
      "epoch:17 step:13734 [D loss: 0.685925, acc.: 54.69%] [G loss: 0.815749]\n",
      "epoch:17 step:13735 [D loss: 0.716037, acc.: 46.88%] [G loss: 0.726804]\n",
      "epoch:17 step:13736 [D loss: 0.739609, acc.: 45.31%] [G loss: 0.754505]\n",
      "epoch:17 step:13737 [D loss: 0.704086, acc.: 48.44%] [G loss: 0.786249]\n",
      "epoch:17 step:13738 [D loss: 0.711404, acc.: 49.22%] [G loss: 0.752160]\n",
      "epoch:17 step:13739 [D loss: 0.681448, acc.: 57.81%] [G loss: 0.837634]\n",
      "epoch:17 step:13740 [D loss: 0.716543, acc.: 46.09%] [G loss: 0.777530]\n",
      "epoch:17 step:13741 [D loss: 0.700963, acc.: 50.78%] [G loss: 0.796871]\n",
      "epoch:17 step:13742 [D loss: 0.707688, acc.: 50.78%] [G loss: 0.807551]\n",
      "epoch:17 step:13743 [D loss: 0.671478, acc.: 62.50%] [G loss: 0.801687]\n",
      "epoch:17 step:13744 [D loss: 0.708668, acc.: 48.44%] [G loss: 0.754339]\n",
      "epoch:17 step:13745 [D loss: 0.649246, acc.: 60.16%] [G loss: 0.821872]\n",
      "epoch:17 step:13746 [D loss: 0.652853, acc.: 64.06%] [G loss: 0.840078]\n",
      "epoch:17 step:13747 [D loss: 0.694641, acc.: 50.00%] [G loss: 0.808307]\n",
      "epoch:17 step:13748 [D loss: 0.712579, acc.: 50.00%] [G loss: 0.737402]\n",
      "epoch:17 step:13749 [D loss: 0.688580, acc.: 61.72%] [G loss: 0.742392]\n",
      "epoch:17 step:13750 [D loss: 0.830005, acc.: 28.12%] [G loss: 0.679775]\n",
      "epoch:17 step:13751 [D loss: 0.729393, acc.: 46.09%] [G loss: 0.697326]\n",
      "epoch:17 step:13752 [D loss: 0.707710, acc.: 53.12%] [G loss: 0.673296]\n",
      "epoch:17 step:13753 [D loss: 0.714548, acc.: 50.00%] [G loss: 0.664390]\n",
      "epoch:17 step:13754 [D loss: 0.677731, acc.: 52.34%] [G loss: 0.768698]\n",
      "epoch:17 step:13755 [D loss: 0.681562, acc.: 57.03%] [G loss: 0.805225]\n",
      "epoch:17 step:13756 [D loss: 0.660125, acc.: 60.16%] [G loss: 0.826077]\n",
      "epoch:17 step:13757 [D loss: 0.670844, acc.: 58.59%] [G loss: 0.787169]\n",
      "epoch:17 step:13758 [D loss: 0.708602, acc.: 52.34%] [G loss: 0.741621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13759 [D loss: 0.742667, acc.: 44.53%] [G loss: 0.784437]\n",
      "epoch:17 step:13760 [D loss: 0.759966, acc.: 39.84%] [G loss: 0.716296]\n",
      "epoch:17 step:13761 [D loss: 0.683418, acc.: 57.81%] [G loss: 0.685205]\n",
      "epoch:17 step:13762 [D loss: 0.733530, acc.: 45.31%] [G loss: 0.769275]\n",
      "epoch:17 step:13763 [D loss: 0.701886, acc.: 51.56%] [G loss: 0.751083]\n",
      "epoch:17 step:13764 [D loss: 0.701556, acc.: 50.00%] [G loss: 0.758799]\n",
      "epoch:17 step:13765 [D loss: 0.708726, acc.: 48.44%] [G loss: 0.745955]\n",
      "epoch:17 step:13766 [D loss: 0.683207, acc.: 56.25%] [G loss: 0.755538]\n",
      "epoch:17 step:13767 [D loss: 0.637355, acc.: 70.31%] [G loss: 0.740799]\n",
      "epoch:17 step:13768 [D loss: 0.702715, acc.: 50.00%] [G loss: 0.765943]\n",
      "epoch:17 step:13769 [D loss: 0.697988, acc.: 48.44%] [G loss: 0.810153]\n",
      "epoch:17 step:13770 [D loss: 0.680904, acc.: 55.47%] [G loss: 0.741051]\n",
      "epoch:17 step:13771 [D loss: 0.680358, acc.: 59.38%] [G loss: 0.766952]\n",
      "epoch:17 step:13772 [D loss: 0.640808, acc.: 70.31%] [G loss: 0.712601]\n",
      "epoch:17 step:13773 [D loss: 0.683255, acc.: 53.91%] [G loss: 0.806572]\n",
      "epoch:17 step:13774 [D loss: 0.641763, acc.: 72.66%] [G loss: 0.756981]\n",
      "epoch:17 step:13775 [D loss: 0.717501, acc.: 51.56%] [G loss: 0.706314]\n",
      "epoch:17 step:13776 [D loss: 0.659593, acc.: 60.94%] [G loss: 0.743479]\n",
      "epoch:17 step:13777 [D loss: 0.726500, acc.: 46.09%] [G loss: 0.671922]\n",
      "epoch:17 step:13778 [D loss: 0.721421, acc.: 43.75%] [G loss: 0.786799]\n",
      "epoch:17 step:13779 [D loss: 0.703706, acc.: 53.12%] [G loss: 0.717846]\n",
      "epoch:17 step:13780 [D loss: 0.698597, acc.: 48.44%] [G loss: 0.796767]\n",
      "epoch:17 step:13781 [D loss: 0.706925, acc.: 52.34%] [G loss: 0.739659]\n",
      "epoch:17 step:13782 [D loss: 0.700493, acc.: 55.47%] [G loss: 0.810420]\n",
      "epoch:17 step:13783 [D loss: 0.712839, acc.: 43.75%] [G loss: 0.788341]\n",
      "epoch:17 step:13784 [D loss: 0.695847, acc.: 51.56%] [G loss: 0.780637]\n",
      "epoch:17 step:13785 [D loss: 0.719353, acc.: 49.22%] [G loss: 0.732962]\n",
      "epoch:17 step:13786 [D loss: 0.674795, acc.: 55.47%] [G loss: 0.726499]\n",
      "epoch:17 step:13787 [D loss: 0.693617, acc.: 50.00%] [G loss: 0.696497]\n",
      "epoch:17 step:13788 [D loss: 0.703228, acc.: 46.09%] [G loss: 0.665159]\n",
      "epoch:17 step:13789 [D loss: 0.712169, acc.: 45.31%] [G loss: 0.815314]\n",
      "epoch:17 step:13790 [D loss: 0.759447, acc.: 34.38%] [G loss: 0.745064]\n",
      "epoch:17 step:13791 [D loss: 0.726901, acc.: 51.56%] [G loss: 0.718777]\n",
      "epoch:17 step:13792 [D loss: 0.690517, acc.: 51.56%] [G loss: 0.726857]\n",
      "epoch:17 step:13793 [D loss: 0.657420, acc.: 60.94%] [G loss: 0.784774]\n",
      "epoch:17 step:13794 [D loss: 0.657001, acc.: 60.94%] [G loss: 0.819193]\n",
      "epoch:17 step:13795 [D loss: 0.686022, acc.: 55.47%] [G loss: 0.780271]\n",
      "epoch:17 step:13796 [D loss: 0.641096, acc.: 67.19%] [G loss: 0.759932]\n",
      "epoch:17 step:13797 [D loss: 0.654740, acc.: 67.97%] [G loss: 0.703114]\n",
      "epoch:17 step:13798 [D loss: 0.629159, acc.: 70.31%] [G loss: 0.758182]\n",
      "epoch:17 step:13799 [D loss: 0.733547, acc.: 39.84%] [G loss: 0.739250]\n",
      "epoch:17 step:13800 [D loss: 0.658563, acc.: 61.72%] [G loss: 0.750186]\n",
      "epoch:17 step:13801 [D loss: 0.690521, acc.: 57.03%] [G loss: 0.800914]\n",
      "epoch:17 step:13802 [D loss: 0.632028, acc.: 71.09%] [G loss: 0.850155]\n",
      "epoch:17 step:13803 [D loss: 0.793936, acc.: 38.28%] [G loss: 0.735701]\n",
      "epoch:17 step:13804 [D loss: 0.656865, acc.: 57.81%] [G loss: 0.758156]\n",
      "epoch:17 step:13805 [D loss: 0.717316, acc.: 53.12%] [G loss: 0.733419]\n",
      "epoch:17 step:13806 [D loss: 0.710214, acc.: 50.78%] [G loss: 0.710287]\n",
      "epoch:17 step:13807 [D loss: 0.623177, acc.: 77.34%] [G loss: 0.762158]\n",
      "epoch:17 step:13808 [D loss: 0.670690, acc.: 64.84%] [G loss: 0.752125]\n",
      "epoch:17 step:13809 [D loss: 0.694654, acc.: 52.34%] [G loss: 0.772832]\n",
      "epoch:17 step:13810 [D loss: 0.717297, acc.: 45.31%] [G loss: 0.764992]\n",
      "epoch:17 step:13811 [D loss: 0.656610, acc.: 59.38%] [G loss: 0.746509]\n",
      "epoch:17 step:13812 [D loss: 0.703491, acc.: 50.78%] [G loss: 0.776715]\n",
      "epoch:17 step:13813 [D loss: 0.667760, acc.: 60.94%] [G loss: 0.776679]\n",
      "epoch:17 step:13814 [D loss: 0.744116, acc.: 36.72%] [G loss: 0.740362]\n",
      "epoch:17 step:13815 [D loss: 0.681978, acc.: 52.34%] [G loss: 0.731189]\n",
      "epoch:17 step:13816 [D loss: 0.715565, acc.: 46.09%] [G loss: 0.715826]\n",
      "epoch:17 step:13817 [D loss: 0.749523, acc.: 30.47%] [G loss: 0.671925]\n",
      "epoch:17 step:13818 [D loss: 0.695030, acc.: 54.69%] [G loss: 0.818999]\n",
      "epoch:17 step:13819 [D loss: 0.680037, acc.: 55.47%] [G loss: 0.771566]\n",
      "epoch:17 step:13820 [D loss: 0.719039, acc.: 44.53%] [G loss: 0.754003]\n",
      "epoch:17 step:13821 [D loss: 0.704339, acc.: 47.66%] [G loss: 0.770744]\n",
      "epoch:17 step:13822 [D loss: 0.640645, acc.: 67.19%] [G loss: 0.877561]\n",
      "epoch:17 step:13823 [D loss: 0.678596, acc.: 57.03%] [G loss: 0.760511]\n",
      "epoch:17 step:13824 [D loss: 0.616002, acc.: 75.00%] [G loss: 0.783277]\n",
      "epoch:17 step:13825 [D loss: 0.651027, acc.: 64.06%] [G loss: 0.787196]\n",
      "epoch:17 step:13826 [D loss: 0.633423, acc.: 68.75%] [G loss: 0.747849]\n",
      "epoch:17 step:13827 [D loss: 0.696331, acc.: 53.91%] [G loss: 0.813260]\n",
      "epoch:17 step:13828 [D loss: 0.623285, acc.: 73.44%] [G loss: 0.812176]\n",
      "epoch:17 step:13829 [D loss: 0.689463, acc.: 51.56%] [G loss: 0.709973]\n",
      "epoch:17 step:13830 [D loss: 0.681633, acc.: 60.94%] [G loss: 0.667923]\n",
      "epoch:17 step:13831 [D loss: 0.677810, acc.: 56.25%] [G loss: 0.745252]\n",
      "epoch:17 step:13832 [D loss: 0.665766, acc.: 64.06%] [G loss: 0.720570]\n",
      "epoch:17 step:13833 [D loss: 0.714127, acc.: 44.53%] [G loss: 0.703200]\n",
      "epoch:17 step:13834 [D loss: 0.692522, acc.: 55.47%] [G loss: 0.657323]\n",
      "epoch:17 step:13835 [D loss: 0.724605, acc.: 46.88%] [G loss: 0.698007]\n",
      "epoch:17 step:13836 [D loss: 0.656001, acc.: 63.28%] [G loss: 0.716929]\n",
      "epoch:17 step:13837 [D loss: 0.740228, acc.: 39.06%] [G loss: 0.660585]\n",
      "epoch:17 step:13838 [D loss: 0.720103, acc.: 41.41%] [G loss: 0.732126]\n",
      "epoch:17 step:13839 [D loss: 0.707403, acc.: 54.69%] [G loss: 0.765699]\n",
      "epoch:17 step:13840 [D loss: 0.704923, acc.: 54.69%] [G loss: 0.704009]\n",
      "epoch:17 step:13841 [D loss: 0.726263, acc.: 42.97%] [G loss: 0.745617]\n",
      "epoch:17 step:13842 [D loss: 0.694192, acc.: 52.34%] [G loss: 0.715174]\n",
      "epoch:17 step:13843 [D loss: 0.706844, acc.: 49.22%] [G loss: 0.750423]\n",
      "epoch:17 step:13844 [D loss: 0.701972, acc.: 50.78%] [G loss: 0.734096]\n",
      "epoch:17 step:13845 [D loss: 0.694271, acc.: 52.34%] [G loss: 0.806341]\n",
      "epoch:17 step:13846 [D loss: 0.686535, acc.: 53.12%] [G loss: 0.791367]\n",
      "epoch:17 step:13847 [D loss: 0.687589, acc.: 55.47%] [G loss: 0.814642]\n",
      "epoch:17 step:13848 [D loss: 0.704807, acc.: 46.09%] [G loss: 0.760298]\n",
      "epoch:17 step:13849 [D loss: 0.672691, acc.: 55.47%] [G loss: 0.807245]\n",
      "epoch:17 step:13850 [D loss: 0.726368, acc.: 41.41%] [G loss: 0.754322]\n",
      "epoch:17 step:13851 [D loss: 0.697754, acc.: 54.69%] [G loss: 0.756177]\n",
      "epoch:17 step:13852 [D loss: 0.680765, acc.: 57.03%] [G loss: 0.758038]\n",
      "epoch:17 step:13853 [D loss: 0.698365, acc.: 51.56%] [G loss: 0.690378]\n",
      "epoch:17 step:13854 [D loss: 0.703532, acc.: 45.31%] [G loss: 0.737680]\n",
      "epoch:17 step:13855 [D loss: 0.671638, acc.: 57.03%] [G loss: 0.756271]\n",
      "epoch:17 step:13856 [D loss: 0.696008, acc.: 42.97%] [G loss: 0.731708]\n",
      "epoch:17 step:13857 [D loss: 0.733658, acc.: 41.41%] [G loss: 0.706077]\n",
      "epoch:17 step:13858 [D loss: 0.740124, acc.: 37.50%] [G loss: 0.721937]\n",
      "epoch:17 step:13859 [D loss: 0.728560, acc.: 45.31%] [G loss: 0.782779]\n",
      "epoch:17 step:13860 [D loss: 0.659367, acc.: 66.41%] [G loss: 0.779751]\n",
      "epoch:17 step:13861 [D loss: 0.681260, acc.: 56.25%] [G loss: 0.717978]\n",
      "epoch:17 step:13862 [D loss: 0.682022, acc.: 50.00%] [G loss: 0.739690]\n",
      "epoch:17 step:13863 [D loss: 0.667577, acc.: 58.59%] [G loss: 0.728642]\n",
      "epoch:17 step:13864 [D loss: 0.618945, acc.: 72.66%] [G loss: 0.803482]\n",
      "epoch:17 step:13865 [D loss: 0.711158, acc.: 43.75%] [G loss: 0.709473]\n",
      "epoch:17 step:13866 [D loss: 0.686835, acc.: 60.94%] [G loss: 0.723577]\n",
      "epoch:17 step:13867 [D loss: 0.725016, acc.: 39.06%] [G loss: 0.784626]\n",
      "epoch:17 step:13868 [D loss: 0.694493, acc.: 54.69%] [G loss: 0.746406]\n",
      "epoch:17 step:13869 [D loss: 0.697654, acc.: 52.34%] [G loss: 0.713430]\n",
      "epoch:17 step:13870 [D loss: 0.708686, acc.: 50.78%] [G loss: 0.702040]\n",
      "epoch:17 step:13871 [D loss: 0.694420, acc.: 50.00%] [G loss: 0.716732]\n",
      "epoch:17 step:13872 [D loss: 0.661167, acc.: 63.28%] [G loss: 0.761893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13873 [D loss: 0.721027, acc.: 40.62%] [G loss: 0.727812]\n",
      "epoch:17 step:13874 [D loss: 0.699115, acc.: 53.91%] [G loss: 0.729597]\n",
      "epoch:17 step:13875 [D loss: 0.709231, acc.: 52.34%] [G loss: 0.747705]\n",
      "epoch:17 step:13876 [D loss: 0.714581, acc.: 43.75%] [G loss: 0.729375]\n",
      "epoch:17 step:13877 [D loss: 0.684701, acc.: 56.25%] [G loss: 0.712788]\n",
      "epoch:17 step:13878 [D loss: 0.722589, acc.: 44.53%] [G loss: 0.705856]\n",
      "epoch:17 step:13879 [D loss: 0.738166, acc.: 40.62%] [G loss: 0.700501]\n",
      "epoch:17 step:13880 [D loss: 0.706378, acc.: 49.22%] [G loss: 0.775083]\n",
      "epoch:17 step:13881 [D loss: 0.699422, acc.: 54.69%] [G loss: 0.713032]\n",
      "epoch:17 step:13882 [D loss: 0.673035, acc.: 57.81%] [G loss: 0.775898]\n",
      "epoch:17 step:13883 [D loss: 0.686150, acc.: 54.69%] [G loss: 0.803445]\n",
      "epoch:17 step:13884 [D loss: 0.662451, acc.: 62.50%] [G loss: 0.747877]\n",
      "epoch:17 step:13885 [D loss: 0.639444, acc.: 68.75%] [G loss: 0.840078]\n",
      "epoch:17 step:13886 [D loss: 0.719957, acc.: 46.09%] [G loss: 0.805063]\n",
      "epoch:17 step:13887 [D loss: 0.694078, acc.: 50.78%] [G loss: 0.756673]\n",
      "epoch:17 step:13888 [D loss: 0.685658, acc.: 54.69%] [G loss: 0.772325]\n",
      "epoch:17 step:13889 [D loss: 0.651229, acc.: 63.28%] [G loss: 0.737697]\n",
      "epoch:17 step:13890 [D loss: 0.703325, acc.: 52.34%] [G loss: 0.711674]\n",
      "epoch:17 step:13891 [D loss: 0.721533, acc.: 51.56%] [G loss: 0.733269]\n",
      "epoch:17 step:13892 [D loss: 0.646483, acc.: 64.06%] [G loss: 0.722169]\n",
      "epoch:17 step:13893 [D loss: 0.634787, acc.: 70.31%] [G loss: 0.759117]\n",
      "epoch:17 step:13894 [D loss: 0.658279, acc.: 60.94%] [G loss: 0.651261]\n",
      "epoch:17 step:13895 [D loss: 0.663994, acc.: 64.84%] [G loss: 0.705220]\n",
      "epoch:17 step:13896 [D loss: 0.724973, acc.: 43.75%] [G loss: 0.662558]\n",
      "epoch:17 step:13897 [D loss: 0.741936, acc.: 47.66%] [G loss: 0.621766]\n",
      "epoch:17 step:13898 [D loss: 0.674779, acc.: 60.16%] [G loss: 0.684257]\n",
      "epoch:17 step:13899 [D loss: 0.699542, acc.: 48.44%] [G loss: 0.691814]\n",
      "epoch:17 step:13900 [D loss: 0.772870, acc.: 39.84%] [G loss: 0.694001]\n",
      "epoch:17 step:13901 [D loss: 0.721984, acc.: 39.84%] [G loss: 0.716576]\n",
      "epoch:17 step:13902 [D loss: 0.722368, acc.: 52.34%] [G loss: 0.680093]\n",
      "epoch:17 step:13903 [D loss: 0.761312, acc.: 38.28%] [G loss: 0.719199]\n",
      "epoch:17 step:13904 [D loss: 0.752891, acc.: 30.47%] [G loss: 0.675307]\n",
      "epoch:17 step:13905 [D loss: 0.715743, acc.: 48.44%] [G loss: 0.748428]\n",
      "epoch:17 step:13906 [D loss: 0.665649, acc.: 59.38%] [G loss: 0.910629]\n",
      "epoch:17 step:13907 [D loss: 0.692052, acc.: 49.22%] [G loss: 0.799387]\n",
      "epoch:17 step:13908 [D loss: 0.755630, acc.: 39.84%] [G loss: 0.790111]\n",
      "epoch:17 step:13909 [D loss: 0.670341, acc.: 58.59%] [G loss: 0.780669]\n",
      "epoch:17 step:13910 [D loss: 0.721450, acc.: 50.00%] [G loss: 0.747756]\n",
      "epoch:17 step:13911 [D loss: 0.678068, acc.: 57.81%] [G loss: 0.737831]\n",
      "epoch:17 step:13912 [D loss: 0.657750, acc.: 62.50%] [G loss: 0.783302]\n",
      "epoch:17 step:13913 [D loss: 0.700240, acc.: 53.91%] [G loss: 0.731375]\n",
      "epoch:17 step:13914 [D loss: 0.668243, acc.: 64.84%] [G loss: 0.834868]\n",
      "epoch:17 step:13915 [D loss: 0.729847, acc.: 50.78%] [G loss: 0.767558]\n",
      "epoch:17 step:13916 [D loss: 0.646851, acc.: 67.19%] [G loss: 0.786311]\n",
      "epoch:17 step:13917 [D loss: 0.630146, acc.: 71.09%] [G loss: 0.843944]\n",
      "epoch:17 step:13918 [D loss: 0.665380, acc.: 59.38%] [G loss: 0.818475]\n",
      "epoch:17 step:13919 [D loss: 0.709951, acc.: 49.22%] [G loss: 0.777756]\n",
      "epoch:17 step:13920 [D loss: 0.663008, acc.: 57.03%] [G loss: 0.803676]\n",
      "epoch:17 step:13921 [D loss: 0.633793, acc.: 69.53%] [G loss: 0.774668]\n",
      "epoch:17 step:13922 [D loss: 0.676408, acc.: 56.25%] [G loss: 0.696820]\n",
      "epoch:17 step:13923 [D loss: 0.778070, acc.: 32.81%] [G loss: 0.778839]\n",
      "epoch:17 step:13924 [D loss: 0.716852, acc.: 51.56%] [G loss: 0.720224]\n",
      "epoch:17 step:13925 [D loss: 0.710639, acc.: 45.31%] [G loss: 0.713309]\n",
      "epoch:17 step:13926 [D loss: 0.748936, acc.: 39.06%] [G loss: 0.724211]\n",
      "epoch:17 step:13927 [D loss: 0.732339, acc.: 45.31%] [G loss: 0.695729]\n",
      "epoch:17 step:13928 [D loss: 0.670169, acc.: 60.16%] [G loss: 0.734829]\n",
      "epoch:17 step:13929 [D loss: 0.742091, acc.: 44.53%] [G loss: 0.759589]\n",
      "epoch:17 step:13930 [D loss: 0.676665, acc.: 60.16%] [G loss: 0.785822]\n",
      "epoch:17 step:13931 [D loss: 0.716250, acc.: 46.88%] [G loss: 0.735057]\n",
      "epoch:17 step:13932 [D loss: 0.736952, acc.: 36.72%] [G loss: 0.783695]\n",
      "epoch:17 step:13933 [D loss: 0.727027, acc.: 45.31%] [G loss: 0.748461]\n",
      "epoch:17 step:13934 [D loss: 0.727718, acc.: 39.06%] [G loss: 0.799053]\n",
      "epoch:17 step:13935 [D loss: 0.660637, acc.: 61.72%] [G loss: 0.807552]\n",
      "epoch:17 step:13936 [D loss: 0.755299, acc.: 36.72%] [G loss: 0.837249]\n",
      "epoch:17 step:13937 [D loss: 0.721330, acc.: 44.53%] [G loss: 0.910444]\n",
      "epoch:17 step:13938 [D loss: 0.670062, acc.: 55.47%] [G loss: 0.870587]\n",
      "epoch:17 step:13939 [D loss: 0.690110, acc.: 55.47%] [G loss: 0.735536]\n",
      "epoch:17 step:13940 [D loss: 0.637427, acc.: 66.41%] [G loss: 0.882275]\n",
      "epoch:17 step:13941 [D loss: 0.675367, acc.: 62.50%] [G loss: 0.755735]\n",
      "epoch:17 step:13942 [D loss: 0.665867, acc.: 66.41%] [G loss: 0.812889]\n",
      "epoch:17 step:13943 [D loss: 0.649240, acc.: 69.53%] [G loss: 0.801028]\n",
      "epoch:17 step:13944 [D loss: 0.653720, acc.: 63.28%] [G loss: 0.782371]\n",
      "epoch:17 step:13945 [D loss: 0.734450, acc.: 39.06%] [G loss: 0.733253]\n",
      "epoch:17 step:13946 [D loss: 0.659498, acc.: 64.06%] [G loss: 0.786850]\n",
      "epoch:17 step:13947 [D loss: 0.652571, acc.: 67.97%] [G loss: 0.835041]\n",
      "epoch:17 step:13948 [D loss: 0.694521, acc.: 54.69%] [G loss: 0.716338]\n",
      "epoch:17 step:13949 [D loss: 0.712671, acc.: 50.00%] [G loss: 0.698472]\n",
      "epoch:17 step:13950 [D loss: 0.680498, acc.: 60.94%] [G loss: 0.759599]\n",
      "epoch:17 step:13951 [D loss: 0.688152, acc.: 54.69%] [G loss: 0.841266]\n",
      "epoch:17 step:13952 [D loss: 0.726145, acc.: 42.97%] [G loss: 0.725587]\n",
      "epoch:17 step:13953 [D loss: 0.677257, acc.: 57.03%] [G loss: 0.754685]\n",
      "epoch:17 step:13954 [D loss: 0.639011, acc.: 66.41%] [G loss: 0.743909]\n",
      "epoch:17 step:13955 [D loss: 0.739406, acc.: 39.06%] [G loss: 0.705622]\n",
      "epoch:17 step:13956 [D loss: 0.698865, acc.: 58.59%] [G loss: 0.762149]\n",
      "epoch:17 step:13957 [D loss: 0.687773, acc.: 53.12%] [G loss: 0.737544]\n",
      "epoch:17 step:13958 [D loss: 0.697687, acc.: 47.66%] [G loss: 0.743881]\n",
      "epoch:17 step:13959 [D loss: 0.672219, acc.: 57.81%] [G loss: 0.706495]\n",
      "epoch:17 step:13960 [D loss: 0.712238, acc.: 52.34%] [G loss: 0.769966]\n",
      "epoch:17 step:13961 [D loss: 0.692546, acc.: 50.78%] [G loss: 0.750594]\n",
      "epoch:17 step:13962 [D loss: 0.718582, acc.: 45.31%] [G loss: 0.772713]\n",
      "epoch:17 step:13963 [D loss: 0.702357, acc.: 50.78%] [G loss: 0.778672]\n",
      "epoch:17 step:13964 [D loss: 0.705171, acc.: 53.12%] [G loss: 0.690652]\n",
      "epoch:17 step:13965 [D loss: 0.695427, acc.: 50.00%] [G loss: 0.758814]\n",
      "epoch:17 step:13966 [D loss: 0.674725, acc.: 59.38%] [G loss: 0.787278]\n",
      "epoch:17 step:13967 [D loss: 0.674084, acc.: 57.03%] [G loss: 0.748198]\n",
      "epoch:17 step:13968 [D loss: 0.652722, acc.: 62.50%] [G loss: 0.779314]\n",
      "epoch:17 step:13969 [D loss: 0.806491, acc.: 30.47%] [G loss: 0.748752]\n",
      "epoch:17 step:13970 [D loss: 0.692505, acc.: 59.38%] [G loss: 0.724625]\n",
      "epoch:17 step:13971 [D loss: 0.677549, acc.: 60.16%] [G loss: 0.716216]\n",
      "epoch:17 step:13972 [D loss: 0.646441, acc.: 67.19%] [G loss: 0.754326]\n",
      "epoch:17 step:13973 [D loss: 0.737201, acc.: 43.75%] [G loss: 0.693797]\n",
      "epoch:17 step:13974 [D loss: 0.735759, acc.: 43.75%] [G loss: 0.690265]\n",
      "epoch:17 step:13975 [D loss: 0.666725, acc.: 57.03%] [G loss: 0.672320]\n",
      "epoch:17 step:13976 [D loss: 0.742400, acc.: 40.62%] [G loss: 0.658422]\n",
      "epoch:17 step:13977 [D loss: 0.686260, acc.: 53.12%] [G loss: 0.713987]\n",
      "epoch:17 step:13978 [D loss: 0.673704, acc.: 61.72%] [G loss: 0.710654]\n",
      "epoch:17 step:13979 [D loss: 0.700014, acc.: 53.91%] [G loss: 0.718311]\n",
      "epoch:17 step:13980 [D loss: 0.665101, acc.: 59.38%] [G loss: 0.734612]\n",
      "epoch:17 step:13981 [D loss: 0.753662, acc.: 38.28%] [G loss: 0.672683]\n",
      "epoch:17 step:13982 [D loss: 0.698911, acc.: 51.56%] [G loss: 0.728400]\n",
      "epoch:17 step:13983 [D loss: 0.715866, acc.: 44.53%] [G loss: 0.718358]\n",
      "epoch:17 step:13984 [D loss: 0.726992, acc.: 47.66%] [G loss: 0.722684]\n",
      "epoch:17 step:13985 [D loss: 0.723607, acc.: 45.31%] [G loss: 0.730345]\n",
      "epoch:17 step:13986 [D loss: 0.710504, acc.: 46.09%] [G loss: 0.739868]\n",
      "epoch:17 step:13987 [D loss: 0.667901, acc.: 57.81%] [G loss: 0.773520]\n",
      "epoch:17 step:13988 [D loss: 0.668304, acc.: 60.94%] [G loss: 0.779348]\n",
      "epoch:17 step:13989 [D loss: 0.699202, acc.: 53.91%] [G loss: 0.832210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13990 [D loss: 0.741425, acc.: 41.41%] [G loss: 0.811384]\n",
      "epoch:17 step:13991 [D loss: 0.719861, acc.: 46.88%] [G loss: 0.762353]\n",
      "epoch:17 step:13992 [D loss: 0.662806, acc.: 56.25%] [G loss: 0.761405]\n",
      "epoch:17 step:13993 [D loss: 0.667967, acc.: 65.62%] [G loss: 0.804389]\n",
      "epoch:17 step:13994 [D loss: 0.706532, acc.: 46.09%] [G loss: 0.777617]\n",
      "epoch:17 step:13995 [D loss: 0.687680, acc.: 55.47%] [G loss: 0.831846]\n",
      "epoch:17 step:13996 [D loss: 0.739861, acc.: 36.72%] [G loss: 0.758486]\n",
      "epoch:17 step:13997 [D loss: 0.708582, acc.: 48.44%] [G loss: 0.775808]\n",
      "epoch:17 step:13998 [D loss: 0.729305, acc.: 39.84%] [G loss: 0.764371]\n",
      "epoch:17 step:13999 [D loss: 0.706390, acc.: 49.22%] [G loss: 0.731266]\n",
      "epoch:17 step:14000 [D loss: 0.781560, acc.: 27.34%] [G loss: 0.660770]\n",
      "epoch:17 step:14001 [D loss: 0.672629, acc.: 60.94%] [G loss: 0.713407]\n",
      "epoch:17 step:14002 [D loss: 0.709845, acc.: 48.44%] [G loss: 0.790049]\n",
      "epoch:17 step:14003 [D loss: 0.717737, acc.: 49.22%] [G loss: 0.731886]\n",
      "epoch:17 step:14004 [D loss: 0.688386, acc.: 55.47%] [G loss: 0.763627]\n",
      "epoch:17 step:14005 [D loss: 0.731411, acc.: 42.19%] [G loss: 0.796671]\n",
      "epoch:17 step:14006 [D loss: 0.660819, acc.: 60.94%] [G loss: 0.706943]\n",
      "epoch:17 step:14007 [D loss: 0.691422, acc.: 53.12%] [G loss: 0.762237]\n",
      "epoch:17 step:14008 [D loss: 0.694050, acc.: 52.34%] [G loss: 0.712455]\n",
      "epoch:17 step:14009 [D loss: 0.698643, acc.: 49.22%] [G loss: 0.748449]\n",
      "epoch:17 step:14010 [D loss: 0.675295, acc.: 62.50%] [G loss: 0.728942]\n",
      "epoch:17 step:14011 [D loss: 0.724676, acc.: 46.88%] [G loss: 0.777560]\n",
      "epoch:17 step:14012 [D loss: 0.743723, acc.: 35.94%] [G loss: 0.771553]\n",
      "epoch:17 step:14013 [D loss: 0.647264, acc.: 66.41%] [G loss: 0.749448]\n",
      "epoch:17 step:14014 [D loss: 0.760429, acc.: 42.97%] [G loss: 0.762189]\n",
      "epoch:17 step:14015 [D loss: 0.688565, acc.: 55.47%] [G loss: 0.807494]\n",
      "epoch:17 step:14016 [D loss: 0.727177, acc.: 44.53%] [G loss: 0.795051]\n",
      "epoch:17 step:14017 [D loss: 0.698648, acc.: 48.44%] [G loss: 0.819195]\n",
      "epoch:17 step:14018 [D loss: 0.698723, acc.: 52.34%] [G loss: 0.809686]\n",
      "epoch:17 step:14019 [D loss: 0.740721, acc.: 35.94%] [G loss: 0.824329]\n",
      "epoch:17 step:14020 [D loss: 0.712075, acc.: 44.53%] [G loss: 0.765287]\n",
      "epoch:17 step:14021 [D loss: 0.706433, acc.: 53.91%] [G loss: 0.736581]\n",
      "epoch:17 step:14022 [D loss: 0.702514, acc.: 48.44%] [G loss: 0.787678]\n",
      "epoch:17 step:14023 [D loss: 0.692074, acc.: 49.22%] [G loss: 0.749655]\n",
      "epoch:17 step:14024 [D loss: 0.716434, acc.: 48.44%] [G loss: 0.741414]\n",
      "epoch:17 step:14025 [D loss: 0.677617, acc.: 55.47%] [G loss: 0.763090]\n",
      "epoch:17 step:14026 [D loss: 0.720130, acc.: 39.84%] [G loss: 0.747191]\n",
      "epoch:17 step:14027 [D loss: 0.692032, acc.: 51.56%] [G loss: 0.776048]\n",
      "epoch:17 step:14028 [D loss: 0.680152, acc.: 56.25%] [G loss: 0.746066]\n",
      "epoch:17 step:14029 [D loss: 0.692005, acc.: 54.69%] [G loss: 0.739178]\n",
      "epoch:17 step:14030 [D loss: 0.697209, acc.: 53.91%] [G loss: 0.706759]\n",
      "epoch:17 step:14031 [D loss: 0.715237, acc.: 46.88%] [G loss: 0.735360]\n",
      "epoch:17 step:14032 [D loss: 0.713216, acc.: 46.88%] [G loss: 0.730475]\n",
      "epoch:17 step:14033 [D loss: 0.706287, acc.: 49.22%] [G loss: 0.754107]\n",
      "epoch:17 step:14034 [D loss: 0.679027, acc.: 57.03%] [G loss: 0.839524]\n",
      "epoch:17 step:14035 [D loss: 0.726008, acc.: 43.75%] [G loss: 0.734887]\n",
      "epoch:17 step:14036 [D loss: 0.736616, acc.: 42.19%] [G loss: 0.704019]\n",
      "epoch:17 step:14037 [D loss: 0.732205, acc.: 38.28%] [G loss: 0.756994]\n",
      "epoch:17 step:14038 [D loss: 0.677575, acc.: 53.91%] [G loss: 0.799718]\n",
      "epoch:17 step:14039 [D loss: 0.698827, acc.: 55.47%] [G loss: 0.767203]\n",
      "epoch:17 step:14040 [D loss: 0.703930, acc.: 49.22%] [G loss: 0.746173]\n",
      "epoch:17 step:14041 [D loss: 0.702857, acc.: 50.00%] [G loss: 0.718793]\n",
      "epoch:17 step:14042 [D loss: 0.709201, acc.: 50.00%] [G loss: 0.706501]\n",
      "epoch:17 step:14043 [D loss: 0.710842, acc.: 49.22%] [G loss: 0.809922]\n",
      "epoch:17 step:14044 [D loss: 0.659326, acc.: 68.75%] [G loss: 0.763545]\n",
      "epoch:17 step:14045 [D loss: 0.674068, acc.: 55.47%] [G loss: 0.766587]\n",
      "epoch:17 step:14046 [D loss: 0.706417, acc.: 43.75%] [G loss: 0.711648]\n",
      "epoch:17 step:14047 [D loss: 0.690102, acc.: 53.12%] [G loss: 0.797285]\n",
      "epoch:17 step:14048 [D loss: 0.685293, acc.: 53.12%] [G loss: 0.788820]\n",
      "epoch:17 step:14049 [D loss: 0.677624, acc.: 59.38%] [G loss: 0.749013]\n",
      "epoch:17 step:14050 [D loss: 0.689182, acc.: 56.25%] [G loss: 0.704212]\n",
      "epoch:17 step:14051 [D loss: 0.718447, acc.: 46.88%] [G loss: 0.733822]\n",
      "epoch:17 step:14052 [D loss: 0.742423, acc.: 39.06%] [G loss: 0.715642]\n",
      "epoch:17 step:14053 [D loss: 0.727792, acc.: 46.09%] [G loss: 0.747881]\n",
      "epoch:17 step:14054 [D loss: 0.710953, acc.: 50.00%] [G loss: 0.741570]\n",
      "epoch:17 step:14055 [D loss: 0.699069, acc.: 50.78%] [G loss: 0.725562]\n",
      "epoch:17 step:14056 [D loss: 0.761763, acc.: 36.72%] [G loss: 0.770025]\n",
      "epoch:17 step:14057 [D loss: 0.761127, acc.: 29.69%] [G loss: 0.735566]\n",
      "epoch:17 step:14058 [D loss: 0.671842, acc.: 62.50%] [G loss: 0.763128]\n",
      "epoch:18 step:14059 [D loss: 0.667776, acc.: 56.25%] [G loss: 0.808631]\n",
      "epoch:18 step:14060 [D loss: 0.723440, acc.: 51.56%] [G loss: 0.823161]\n",
      "epoch:18 step:14061 [D loss: 0.698516, acc.: 55.47%] [G loss: 0.754673]\n",
      "epoch:18 step:14062 [D loss: 0.692947, acc.: 54.69%] [G loss: 0.767249]\n",
      "epoch:18 step:14063 [D loss: 0.695919, acc.: 53.12%] [G loss: 0.698592]\n",
      "epoch:18 step:14064 [D loss: 0.672599, acc.: 57.81%] [G loss: 0.787877]\n",
      "epoch:18 step:14065 [D loss: 0.668527, acc.: 60.16%] [G loss: 0.796703]\n",
      "epoch:18 step:14066 [D loss: 0.634370, acc.: 70.31%] [G loss: 0.799433]\n",
      "epoch:18 step:14067 [D loss: 0.666296, acc.: 64.84%] [G loss: 0.814112]\n",
      "epoch:18 step:14068 [D loss: 0.726002, acc.: 44.53%] [G loss: 0.750490]\n",
      "epoch:18 step:14069 [D loss: 0.741355, acc.: 38.28%] [G loss: 0.755885]\n",
      "epoch:18 step:14070 [D loss: 0.682976, acc.: 56.25%] [G loss: 0.762993]\n",
      "epoch:18 step:14071 [D loss: 0.685627, acc.: 52.34%] [G loss: 0.768558]\n",
      "epoch:18 step:14072 [D loss: 0.662647, acc.: 67.19%] [G loss: 0.892627]\n",
      "epoch:18 step:14073 [D loss: 0.693390, acc.: 50.00%] [G loss: 0.772791]\n",
      "epoch:18 step:14074 [D loss: 0.720624, acc.: 47.66%] [G loss: 0.757601]\n",
      "epoch:18 step:14075 [D loss: 0.698309, acc.: 51.56%] [G loss: 0.794695]\n",
      "epoch:18 step:14076 [D loss: 0.693817, acc.: 50.00%] [G loss: 0.806918]\n",
      "epoch:18 step:14077 [D loss: 0.696057, acc.: 54.69%] [G loss: 0.824054]\n",
      "epoch:18 step:14078 [D loss: 0.656323, acc.: 63.28%] [G loss: 0.755607]\n",
      "epoch:18 step:14079 [D loss: 0.686388, acc.: 50.78%] [G loss: 0.779299]\n",
      "epoch:18 step:14080 [D loss: 0.667264, acc.: 54.69%] [G loss: 0.766778]\n",
      "epoch:18 step:14081 [D loss: 0.742854, acc.: 35.94%] [G loss: 0.719324]\n",
      "epoch:18 step:14082 [D loss: 0.662976, acc.: 61.72%] [G loss: 0.728852]\n",
      "epoch:18 step:14083 [D loss: 0.708376, acc.: 47.66%] [G loss: 0.660798]\n",
      "epoch:18 step:14084 [D loss: 0.690521, acc.: 51.56%] [G loss: 0.729711]\n",
      "epoch:18 step:14085 [D loss: 0.660190, acc.: 64.84%] [G loss: 0.745088]\n",
      "epoch:18 step:14086 [D loss: 0.700545, acc.: 54.69%] [G loss: 0.739952]\n",
      "epoch:18 step:14087 [D loss: 0.708106, acc.: 46.88%] [G loss: 0.694862]\n",
      "epoch:18 step:14088 [D loss: 0.684515, acc.: 55.47%] [G loss: 0.742973]\n",
      "epoch:18 step:14089 [D loss: 0.694000, acc.: 51.56%] [G loss: 0.760890]\n",
      "epoch:18 step:14090 [D loss: 0.679343, acc.: 57.81%] [G loss: 0.754737]\n",
      "epoch:18 step:14091 [D loss: 0.700913, acc.: 50.00%] [G loss: 0.728751]\n",
      "epoch:18 step:14092 [D loss: 0.702756, acc.: 53.12%] [G loss: 0.771943]\n",
      "epoch:18 step:14093 [D loss: 0.737588, acc.: 37.50%] [G loss: 0.758039]\n",
      "epoch:18 step:14094 [D loss: 0.693591, acc.: 48.44%] [G loss: 0.767511]\n",
      "epoch:18 step:14095 [D loss: 0.712948, acc.: 46.09%] [G loss: 0.746488]\n",
      "epoch:18 step:14096 [D loss: 0.697589, acc.: 49.22%] [G loss: 0.745055]\n",
      "epoch:18 step:14097 [D loss: 0.648766, acc.: 60.94%] [G loss: 0.775972]\n",
      "epoch:18 step:14098 [D loss: 0.698620, acc.: 58.59%] [G loss: 0.743437]\n",
      "epoch:18 step:14099 [D loss: 0.706797, acc.: 44.53%] [G loss: 0.745933]\n",
      "epoch:18 step:14100 [D loss: 0.673752, acc.: 59.38%] [G loss: 0.742550]\n",
      "epoch:18 step:14101 [D loss: 0.655183, acc.: 65.62%] [G loss: 0.705183]\n",
      "epoch:18 step:14102 [D loss: 0.731162, acc.: 43.75%] [G loss: 0.691042]\n",
      "epoch:18 step:14103 [D loss: 0.619338, acc.: 71.09%] [G loss: 0.769414]\n",
      "epoch:18 step:14104 [D loss: 0.754898, acc.: 43.75%] [G loss: 0.681514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14105 [D loss: 0.642345, acc.: 67.19%] [G loss: 0.805044]\n",
      "epoch:18 step:14106 [D loss: 0.666227, acc.: 61.72%] [G loss: 0.811116]\n",
      "epoch:18 step:14107 [D loss: 0.727282, acc.: 42.19%] [G loss: 0.724469]\n",
      "epoch:18 step:14108 [D loss: 0.720675, acc.: 47.66%] [G loss: 0.662862]\n",
      "epoch:18 step:14109 [D loss: 0.637543, acc.: 74.22%] [G loss: 0.665223]\n",
      "epoch:18 step:14110 [D loss: 0.686643, acc.: 54.69%] [G loss: 0.643817]\n",
      "epoch:18 step:14111 [D loss: 0.690597, acc.: 55.47%] [G loss: 0.716017]\n",
      "epoch:18 step:14112 [D loss: 0.708451, acc.: 46.09%] [G loss: 0.696262]\n",
      "epoch:18 step:14113 [D loss: 0.690225, acc.: 60.16%] [G loss: 0.645652]\n",
      "epoch:18 step:14114 [D loss: 0.700165, acc.: 47.66%] [G loss: 0.675516]\n",
      "epoch:18 step:14115 [D loss: 0.695514, acc.: 53.12%] [G loss: 0.695372]\n",
      "epoch:18 step:14116 [D loss: 0.705559, acc.: 49.22%] [G loss: 0.745455]\n",
      "epoch:18 step:14117 [D loss: 0.699322, acc.: 50.78%] [G loss: 0.745861]\n",
      "epoch:18 step:14118 [D loss: 0.686558, acc.: 53.91%] [G loss: 0.766288]\n",
      "epoch:18 step:14119 [D loss: 0.720917, acc.: 44.53%] [G loss: 0.793027]\n",
      "epoch:18 step:14120 [D loss: 0.689486, acc.: 55.47%] [G loss: 0.841075]\n",
      "epoch:18 step:14121 [D loss: 0.739940, acc.: 42.19%] [G loss: 0.781766]\n",
      "epoch:18 step:14122 [D loss: 0.693654, acc.: 53.12%] [G loss: 0.833720]\n",
      "epoch:18 step:14123 [D loss: 0.692494, acc.: 52.34%] [G loss: 0.780182]\n",
      "epoch:18 step:14124 [D loss: 0.699318, acc.: 50.78%] [G loss: 0.738686]\n",
      "epoch:18 step:14125 [D loss: 0.703051, acc.: 49.22%] [G loss: 0.819113]\n",
      "epoch:18 step:14126 [D loss: 0.697373, acc.: 47.66%] [G loss: 0.784370]\n",
      "epoch:18 step:14127 [D loss: 0.702609, acc.: 49.22%] [G loss: 0.758758]\n",
      "epoch:18 step:14128 [D loss: 0.738185, acc.: 41.41%] [G loss: 0.752515]\n",
      "epoch:18 step:14129 [D loss: 0.673037, acc.: 54.69%] [G loss: 0.686276]\n",
      "epoch:18 step:14130 [D loss: 0.699697, acc.: 50.00%] [G loss: 0.707108]\n",
      "epoch:18 step:14131 [D loss: 0.672392, acc.: 55.47%] [G loss: 0.724797]\n",
      "epoch:18 step:14132 [D loss: 0.671366, acc.: 58.59%] [G loss: 0.688873]\n",
      "epoch:18 step:14133 [D loss: 0.697348, acc.: 55.47%] [G loss: 0.716040]\n",
      "epoch:18 step:14134 [D loss: 0.719947, acc.: 46.09%] [G loss: 0.704609]\n",
      "epoch:18 step:14135 [D loss: 0.694236, acc.: 46.88%] [G loss: 0.687116]\n",
      "epoch:18 step:14136 [D loss: 0.729130, acc.: 41.41%] [G loss: 0.778160]\n",
      "epoch:18 step:14137 [D loss: 0.712399, acc.: 44.53%] [G loss: 0.766778]\n",
      "epoch:18 step:14138 [D loss: 0.665736, acc.: 63.28%] [G loss: 0.760152]\n",
      "epoch:18 step:14139 [D loss: 0.685978, acc.: 50.78%] [G loss: 0.765418]\n",
      "epoch:18 step:14140 [D loss: 0.667066, acc.: 62.50%] [G loss: 0.775235]\n",
      "epoch:18 step:14141 [D loss: 0.681344, acc.: 49.22%] [G loss: 0.770138]\n",
      "epoch:18 step:14142 [D loss: 0.673397, acc.: 60.16%] [G loss: 0.760695]\n",
      "epoch:18 step:14143 [D loss: 0.688915, acc.: 55.47%] [G loss: 0.779138]\n",
      "epoch:18 step:14144 [D loss: 0.656213, acc.: 67.19%] [G loss: 0.823264]\n",
      "epoch:18 step:14145 [D loss: 0.664112, acc.: 60.94%] [G loss: 0.827422]\n",
      "epoch:18 step:14146 [D loss: 0.644473, acc.: 64.06%] [G loss: 0.779256]\n",
      "epoch:18 step:14147 [D loss: 0.685734, acc.: 47.66%] [G loss: 0.743718]\n",
      "epoch:18 step:14148 [D loss: 0.700833, acc.: 50.00%] [G loss: 0.855446]\n",
      "epoch:18 step:14149 [D loss: 0.680495, acc.: 53.91%] [G loss: 0.818158]\n",
      "epoch:18 step:14150 [D loss: 0.745539, acc.: 35.94%] [G loss: 0.797872]\n",
      "epoch:18 step:14151 [D loss: 0.672626, acc.: 56.25%] [G loss: 0.766873]\n",
      "epoch:18 step:14152 [D loss: 0.702698, acc.: 51.56%] [G loss: 0.760904]\n",
      "epoch:18 step:14153 [D loss: 0.693975, acc.: 52.34%] [G loss: 0.670400]\n",
      "epoch:18 step:14154 [D loss: 0.705554, acc.: 43.75%] [G loss: 0.755769]\n",
      "epoch:18 step:14155 [D loss: 0.706942, acc.: 52.34%] [G loss: 0.745391]\n",
      "epoch:18 step:14156 [D loss: 0.716193, acc.: 48.44%] [G loss: 0.741808]\n",
      "epoch:18 step:14157 [D loss: 0.692102, acc.: 51.56%] [G loss: 0.784883]\n",
      "epoch:18 step:14158 [D loss: 0.654309, acc.: 64.84%] [G loss: 0.865456]\n",
      "epoch:18 step:14159 [D loss: 0.667741, acc.: 65.62%] [G loss: 0.730752]\n",
      "epoch:18 step:14160 [D loss: 0.673364, acc.: 60.16%] [G loss: 0.808865]\n",
      "epoch:18 step:14161 [D loss: 0.765233, acc.: 32.81%] [G loss: 0.792655]\n",
      "epoch:18 step:14162 [D loss: 0.702704, acc.: 53.91%] [G loss: 0.779222]\n",
      "epoch:18 step:14163 [D loss: 0.662592, acc.: 63.28%] [G loss: 0.790969]\n",
      "epoch:18 step:14164 [D loss: 0.620396, acc.: 70.31%] [G loss: 0.937959]\n",
      "epoch:18 step:14165 [D loss: 0.691818, acc.: 49.22%] [G loss: 0.783411]\n",
      "epoch:18 step:14166 [D loss: 0.728300, acc.: 42.19%] [G loss: 0.808736]\n",
      "epoch:18 step:14167 [D loss: 0.692727, acc.: 52.34%] [G loss: 0.699428]\n",
      "epoch:18 step:14168 [D loss: 0.691272, acc.: 50.00%] [G loss: 0.674958]\n",
      "epoch:18 step:14169 [D loss: 0.699676, acc.: 51.56%] [G loss: 0.720165]\n",
      "epoch:18 step:14170 [D loss: 0.683667, acc.: 57.03%] [G loss: 0.689620]\n",
      "epoch:18 step:14171 [D loss: 0.684871, acc.: 53.12%] [G loss: 0.734053]\n",
      "epoch:18 step:14172 [D loss: 0.694181, acc.: 56.25%] [G loss: 0.728595]\n",
      "epoch:18 step:14173 [D loss: 0.687348, acc.: 59.38%] [G loss: 0.752759]\n",
      "epoch:18 step:14174 [D loss: 0.762339, acc.: 35.16%] [G loss: 0.740478]\n",
      "epoch:18 step:14175 [D loss: 0.733000, acc.: 39.06%] [G loss: 0.745365]\n",
      "epoch:18 step:14176 [D loss: 0.694726, acc.: 57.03%] [G loss: 0.801283]\n",
      "epoch:18 step:14177 [D loss: 0.704240, acc.: 50.78%] [G loss: 0.729521]\n",
      "epoch:18 step:14178 [D loss: 0.700061, acc.: 50.78%] [G loss: 0.711951]\n",
      "epoch:18 step:14179 [D loss: 0.703548, acc.: 47.66%] [G loss: 0.695951]\n",
      "epoch:18 step:14180 [D loss: 0.702881, acc.: 46.88%] [G loss: 0.757601]\n",
      "epoch:18 step:14181 [D loss: 0.678284, acc.: 55.47%] [G loss: 0.794121]\n",
      "epoch:18 step:14182 [D loss: 0.691515, acc.: 53.12%] [G loss: 0.711926]\n",
      "epoch:18 step:14183 [D loss: 0.794969, acc.: 25.78%] [G loss: 0.717532]\n",
      "epoch:18 step:14184 [D loss: 0.810445, acc.: 35.16%] [G loss: 0.711599]\n",
      "epoch:18 step:14185 [D loss: 0.655969, acc.: 63.28%] [G loss: 0.746252]\n",
      "epoch:18 step:14186 [D loss: 0.716093, acc.: 43.75%] [G loss: 0.791061]\n",
      "epoch:18 step:14187 [D loss: 0.692581, acc.: 53.91%] [G loss: 0.812518]\n",
      "epoch:18 step:14188 [D loss: 0.697299, acc.: 48.44%] [G loss: 0.831228]\n",
      "epoch:18 step:14189 [D loss: 0.687435, acc.: 57.81%] [G loss: 0.752587]\n",
      "epoch:18 step:14190 [D loss: 0.672795, acc.: 58.59%] [G loss: 0.786313]\n",
      "epoch:18 step:14191 [D loss: 0.678272, acc.: 54.69%] [G loss: 0.800055]\n",
      "epoch:18 step:14192 [D loss: 0.718753, acc.: 50.78%] [G loss: 0.743526]\n",
      "epoch:18 step:14193 [D loss: 0.695293, acc.: 53.91%] [G loss: 0.728422]\n",
      "epoch:18 step:14194 [D loss: 0.717064, acc.: 43.75%] [G loss: 0.737193]\n",
      "epoch:18 step:14195 [D loss: 0.700651, acc.: 44.53%] [G loss: 0.789136]\n",
      "epoch:18 step:14196 [D loss: 0.729861, acc.: 42.97%] [G loss: 0.768945]\n",
      "epoch:18 step:14197 [D loss: 0.604945, acc.: 69.53%] [G loss: 0.816123]\n",
      "epoch:18 step:14198 [D loss: 0.685678, acc.: 50.78%] [G loss: 0.779035]\n",
      "epoch:18 step:14199 [D loss: 0.657726, acc.: 60.94%] [G loss: 0.780531]\n",
      "epoch:18 step:14200 [D loss: 0.699965, acc.: 45.31%] [G loss: 0.682270]\n",
      "epoch:18 step:14201 [D loss: 0.733279, acc.: 40.62%] [G loss: 0.699037]\n",
      "epoch:18 step:14202 [D loss: 0.690798, acc.: 56.25%] [G loss: 0.697323]\n",
      "epoch:18 step:14203 [D loss: 0.720381, acc.: 46.09%] [G loss: 0.730431]\n",
      "epoch:18 step:14204 [D loss: 0.653521, acc.: 64.06%] [G loss: 0.695837]\n",
      "epoch:18 step:14205 [D loss: 0.655958, acc.: 60.16%] [G loss: 0.703425]\n",
      "epoch:18 step:14206 [D loss: 0.686738, acc.: 53.12%] [G loss: 0.669661]\n",
      "epoch:18 step:14207 [D loss: 0.668826, acc.: 58.59%] [G loss: 0.661419]\n",
      "epoch:18 step:14208 [D loss: 0.699715, acc.: 53.12%] [G loss: 0.681693]\n",
      "epoch:18 step:14209 [D loss: 0.636584, acc.: 70.31%] [G loss: 0.685680]\n",
      "epoch:18 step:14210 [D loss: 0.659867, acc.: 63.28%] [G loss: 0.740359]\n",
      "epoch:18 step:14211 [D loss: 0.696518, acc.: 50.78%] [G loss: 0.742010]\n",
      "epoch:18 step:14212 [D loss: 0.696730, acc.: 51.56%] [G loss: 0.734772]\n",
      "epoch:18 step:14213 [D loss: 0.664963, acc.: 60.16%] [G loss: 0.746956]\n",
      "epoch:18 step:14214 [D loss: 0.721604, acc.: 42.19%] [G loss: 0.691863]\n",
      "epoch:18 step:14215 [D loss: 0.692637, acc.: 57.03%] [G loss: 0.766591]\n",
      "epoch:18 step:14216 [D loss: 0.680266, acc.: 58.59%] [G loss: 0.839228]\n",
      "epoch:18 step:14217 [D loss: 0.702855, acc.: 51.56%] [G loss: 0.768744]\n",
      "epoch:18 step:14218 [D loss: 0.688506, acc.: 50.00%] [G loss: 0.814323]\n",
      "epoch:18 step:14219 [D loss: 0.702148, acc.: 45.31%] [G loss: 0.818930]\n",
      "epoch:18 step:14220 [D loss: 0.671629, acc.: 58.59%] [G loss: 0.752922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14221 [D loss: 0.662124, acc.: 60.16%] [G loss: 0.795556]\n",
      "epoch:18 step:14222 [D loss: 0.652888, acc.: 67.19%] [G loss: 0.785005]\n",
      "epoch:18 step:14223 [D loss: 0.685862, acc.: 52.34%] [G loss: 0.724703]\n",
      "epoch:18 step:14224 [D loss: 0.667294, acc.: 57.03%] [G loss: 0.786809]\n",
      "epoch:18 step:14225 [D loss: 0.718163, acc.: 42.19%] [G loss: 0.768516]\n",
      "epoch:18 step:14226 [D loss: 0.658371, acc.: 61.72%] [G loss: 0.699283]\n",
      "epoch:18 step:14227 [D loss: 0.673093, acc.: 64.06%] [G loss: 0.771265]\n",
      "epoch:18 step:14228 [D loss: 0.666451, acc.: 67.19%] [G loss: 0.792172]\n",
      "epoch:18 step:14229 [D loss: 0.668781, acc.: 62.50%] [G loss: 0.862706]\n",
      "epoch:18 step:14230 [D loss: 0.688509, acc.: 56.25%] [G loss: 0.848639]\n",
      "epoch:18 step:14231 [D loss: 0.722405, acc.: 42.97%] [G loss: 0.783903]\n",
      "epoch:18 step:14232 [D loss: 0.707305, acc.: 47.66%] [G loss: 0.800775]\n",
      "epoch:18 step:14233 [D loss: 0.769504, acc.: 32.81%] [G loss: 0.724514]\n",
      "epoch:18 step:14234 [D loss: 0.683181, acc.: 54.69%] [G loss: 0.796503]\n",
      "epoch:18 step:14235 [D loss: 0.700821, acc.: 56.25%] [G loss: 0.814250]\n",
      "epoch:18 step:14236 [D loss: 0.728608, acc.: 43.75%] [G loss: 0.772166]\n",
      "epoch:18 step:14237 [D loss: 0.674884, acc.: 62.50%] [G loss: 0.765385]\n",
      "epoch:18 step:14238 [D loss: 0.706702, acc.: 52.34%] [G loss: 0.716127]\n",
      "epoch:18 step:14239 [D loss: 0.684965, acc.: 53.12%] [G loss: 0.742517]\n",
      "epoch:18 step:14240 [D loss: 0.766025, acc.: 30.47%] [G loss: 0.755173]\n",
      "epoch:18 step:14241 [D loss: 0.723638, acc.: 50.78%] [G loss: 0.737410]\n",
      "epoch:18 step:14242 [D loss: 0.710107, acc.: 50.00%] [G loss: 0.707798]\n",
      "epoch:18 step:14243 [D loss: 0.705913, acc.: 53.12%] [G loss: 0.748946]\n",
      "epoch:18 step:14244 [D loss: 0.705829, acc.: 47.66%] [G loss: 0.801528]\n",
      "epoch:18 step:14245 [D loss: 0.714281, acc.: 46.88%] [G loss: 0.771545]\n",
      "epoch:18 step:14246 [D loss: 0.692454, acc.: 52.34%] [G loss: 0.778788]\n",
      "epoch:18 step:14247 [D loss: 0.711041, acc.: 50.00%] [G loss: 0.741015]\n",
      "epoch:18 step:14248 [D loss: 0.717385, acc.: 47.66%] [G loss: 0.748709]\n",
      "epoch:18 step:14249 [D loss: 0.683113, acc.: 54.69%] [G loss: 0.811442]\n",
      "epoch:18 step:14250 [D loss: 0.681452, acc.: 56.25%] [G loss: 0.780075]\n",
      "epoch:18 step:14251 [D loss: 0.666332, acc.: 67.19%] [G loss: 0.749155]\n",
      "epoch:18 step:14252 [D loss: 0.685138, acc.: 53.12%] [G loss: 0.772890]\n",
      "epoch:18 step:14253 [D loss: 0.685778, acc.: 54.69%] [G loss: 0.729149]\n",
      "epoch:18 step:14254 [D loss: 0.657817, acc.: 64.06%] [G loss: 0.826279]\n",
      "epoch:18 step:14255 [D loss: 0.690974, acc.: 50.78%] [G loss: 0.794829]\n",
      "epoch:18 step:14256 [D loss: 0.732122, acc.: 41.41%] [G loss: 0.755185]\n",
      "epoch:18 step:14257 [D loss: 0.705274, acc.: 50.78%] [G loss: 0.707894]\n",
      "epoch:18 step:14258 [D loss: 0.700873, acc.: 46.88%] [G loss: 0.738928]\n",
      "epoch:18 step:14259 [D loss: 0.678599, acc.: 58.59%] [G loss: 0.747561]\n",
      "epoch:18 step:14260 [D loss: 0.665027, acc.: 53.91%] [G loss: 0.692082]\n",
      "epoch:18 step:14261 [D loss: 0.662171, acc.: 57.81%] [G loss: 0.691564]\n",
      "epoch:18 step:14262 [D loss: 0.686980, acc.: 52.34%] [G loss: 0.726046]\n",
      "epoch:18 step:14263 [D loss: 0.652833, acc.: 67.97%] [G loss: 0.761923]\n",
      "epoch:18 step:14264 [D loss: 0.670970, acc.: 61.72%] [G loss: 0.699492]\n",
      "epoch:18 step:14265 [D loss: 0.683724, acc.: 52.34%] [G loss: 0.726253]\n",
      "epoch:18 step:14266 [D loss: 0.678976, acc.: 56.25%] [G loss: 0.774259]\n",
      "epoch:18 step:14267 [D loss: 0.688312, acc.: 56.25%] [G loss: 0.701106]\n",
      "epoch:18 step:14268 [D loss: 0.685074, acc.: 57.03%] [G loss: 0.678839]\n",
      "epoch:18 step:14269 [D loss: 0.704672, acc.: 49.22%] [G loss: 0.696259]\n",
      "epoch:18 step:14270 [D loss: 0.696956, acc.: 54.69%] [G loss: 0.755517]\n",
      "epoch:18 step:14271 [D loss: 0.678700, acc.: 57.81%] [G loss: 0.811419]\n",
      "epoch:18 step:14272 [D loss: 0.717691, acc.: 42.19%] [G loss: 0.750308]\n",
      "epoch:18 step:14273 [D loss: 0.661539, acc.: 66.41%] [G loss: 0.795253]\n",
      "epoch:18 step:14274 [D loss: 0.693570, acc.: 50.78%] [G loss: 0.747501]\n",
      "epoch:18 step:14275 [D loss: 0.700259, acc.: 49.22%] [G loss: 0.719569]\n",
      "epoch:18 step:14276 [D loss: 0.735436, acc.: 39.84%] [G loss: 0.691627]\n",
      "epoch:18 step:14277 [D loss: 0.709858, acc.: 44.53%] [G loss: 0.673930]\n",
      "epoch:18 step:14278 [D loss: 0.744313, acc.: 42.19%] [G loss: 0.758826]\n",
      "epoch:18 step:14279 [D loss: 0.671736, acc.: 57.81%] [G loss: 0.760731]\n",
      "epoch:18 step:14280 [D loss: 0.717792, acc.: 45.31%] [G loss: 0.814662]\n",
      "epoch:18 step:14281 [D loss: 0.702715, acc.: 53.12%] [G loss: 0.787791]\n",
      "epoch:18 step:14282 [D loss: 0.701155, acc.: 50.78%] [G loss: 0.805309]\n",
      "epoch:18 step:14283 [D loss: 0.699310, acc.: 47.66%] [G loss: 0.718004]\n",
      "epoch:18 step:14284 [D loss: 0.674498, acc.: 56.25%] [G loss: 0.775440]\n",
      "epoch:18 step:14285 [D loss: 0.665531, acc.: 60.16%] [G loss: 0.748716]\n",
      "epoch:18 step:14286 [D loss: 0.709812, acc.: 47.66%] [G loss: 0.765902]\n",
      "epoch:18 step:14287 [D loss: 0.700201, acc.: 45.31%] [G loss: 0.748010]\n",
      "epoch:18 step:14288 [D loss: 0.687337, acc.: 55.47%] [G loss: 0.778263]\n",
      "epoch:18 step:14289 [D loss: 0.656219, acc.: 62.50%] [G loss: 0.813123]\n",
      "epoch:18 step:14290 [D loss: 0.758890, acc.: 41.41%] [G loss: 0.765257]\n",
      "epoch:18 step:14291 [D loss: 0.649097, acc.: 64.06%] [G loss: 0.717733]\n",
      "epoch:18 step:14292 [D loss: 0.724630, acc.: 49.22%] [G loss: 0.740702]\n",
      "epoch:18 step:14293 [D loss: 0.722651, acc.: 45.31%] [G loss: 0.770376]\n",
      "epoch:18 step:14294 [D loss: 0.705256, acc.: 46.09%] [G loss: 0.655328]\n",
      "epoch:18 step:14295 [D loss: 0.695269, acc.: 51.56%] [G loss: 0.671344]\n",
      "epoch:18 step:14296 [D loss: 0.746711, acc.: 44.53%] [G loss: 0.684370]\n",
      "epoch:18 step:14297 [D loss: 0.689350, acc.: 50.78%] [G loss: 0.760317]\n",
      "epoch:18 step:14298 [D loss: 0.690604, acc.: 54.69%] [G loss: 0.828873]\n",
      "epoch:18 step:14299 [D loss: 0.716242, acc.: 49.22%] [G loss: 0.761511]\n",
      "epoch:18 step:14300 [D loss: 0.720422, acc.: 46.88%] [G loss: 0.806527]\n",
      "epoch:18 step:14301 [D loss: 0.723678, acc.: 46.88%] [G loss: 0.713825]\n",
      "epoch:18 step:14302 [D loss: 0.669084, acc.: 55.47%] [G loss: 0.793847]\n",
      "epoch:18 step:14303 [D loss: 0.721843, acc.: 44.53%] [G loss: 0.721685]\n",
      "epoch:18 step:14304 [D loss: 0.719269, acc.: 49.22%] [G loss: 0.697986]\n",
      "epoch:18 step:14305 [D loss: 0.644354, acc.: 65.62%] [G loss: 0.717287]\n",
      "epoch:18 step:14306 [D loss: 0.660840, acc.: 58.59%] [G loss: 0.836934]\n",
      "epoch:18 step:14307 [D loss: 0.722298, acc.: 48.44%] [G loss: 0.786531]\n",
      "epoch:18 step:14308 [D loss: 0.668104, acc.: 60.16%] [G loss: 0.820915]\n",
      "epoch:18 step:14309 [D loss: 0.681709, acc.: 57.03%] [G loss: 0.761486]\n",
      "epoch:18 step:14310 [D loss: 0.691653, acc.: 49.22%] [G loss: 0.777898]\n",
      "epoch:18 step:14311 [D loss: 0.707712, acc.: 53.12%] [G loss: 0.800710]\n",
      "epoch:18 step:14312 [D loss: 0.738175, acc.: 37.50%] [G loss: 0.767585]\n",
      "epoch:18 step:14313 [D loss: 0.682198, acc.: 60.94%] [G loss: 0.691788]\n",
      "epoch:18 step:14314 [D loss: 0.709121, acc.: 50.78%] [G loss: 0.754577]\n",
      "epoch:18 step:14315 [D loss: 0.706589, acc.: 53.91%] [G loss: 0.794894]\n",
      "epoch:18 step:14316 [D loss: 0.671225, acc.: 57.81%] [G loss: 0.776642]\n",
      "epoch:18 step:14317 [D loss: 0.738298, acc.: 42.19%] [G loss: 0.730536]\n",
      "epoch:18 step:14318 [D loss: 0.678410, acc.: 54.69%] [G loss: 0.761294]\n",
      "epoch:18 step:14319 [D loss: 0.707105, acc.: 52.34%] [G loss: 0.787543]\n",
      "epoch:18 step:14320 [D loss: 0.679587, acc.: 57.03%] [G loss: 0.773422]\n",
      "epoch:18 step:14321 [D loss: 0.710007, acc.: 46.09%] [G loss: 0.783103]\n",
      "epoch:18 step:14322 [D loss: 0.726608, acc.: 39.06%] [G loss: 0.788835]\n",
      "epoch:18 step:14323 [D loss: 0.691622, acc.: 55.47%] [G loss: 0.804173]\n",
      "epoch:18 step:14324 [D loss: 0.686923, acc.: 53.12%] [G loss: 0.746769]\n",
      "epoch:18 step:14325 [D loss: 0.712284, acc.: 49.22%] [G loss: 0.797515]\n",
      "epoch:18 step:14326 [D loss: 0.674483, acc.: 60.94%] [G loss: 0.703902]\n",
      "epoch:18 step:14327 [D loss: 0.671286, acc.: 57.03%] [G loss: 0.767464]\n",
      "epoch:18 step:14328 [D loss: 0.664348, acc.: 60.94%] [G loss: 0.777379]\n",
      "epoch:18 step:14329 [D loss: 0.700511, acc.: 48.44%] [G loss: 0.705889]\n",
      "epoch:18 step:14330 [D loss: 0.640401, acc.: 67.97%] [G loss: 0.701425]\n",
      "epoch:18 step:14331 [D loss: 0.724901, acc.: 43.75%] [G loss: 0.804756]\n",
      "epoch:18 step:14332 [D loss: 0.686776, acc.: 61.72%] [G loss: 0.738397]\n",
      "epoch:18 step:14333 [D loss: 0.716779, acc.: 47.66%] [G loss: 0.785609]\n",
      "epoch:18 step:14334 [D loss: 0.711111, acc.: 48.44%] [G loss: 0.753890]\n",
      "epoch:18 step:14335 [D loss: 0.678086, acc.: 53.12%] [G loss: 0.761260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14336 [D loss: 0.659827, acc.: 62.50%] [G loss: 0.753388]\n",
      "epoch:18 step:14337 [D loss: 0.705827, acc.: 44.53%] [G loss: 0.758275]\n",
      "epoch:18 step:14338 [D loss: 0.725199, acc.: 39.84%] [G loss: 0.727266]\n",
      "epoch:18 step:14339 [D loss: 0.704431, acc.: 51.56%] [G loss: 0.752620]\n",
      "epoch:18 step:14340 [D loss: 0.712214, acc.: 46.88%] [G loss: 0.795556]\n",
      "epoch:18 step:14341 [D loss: 0.677427, acc.: 57.81%] [G loss: 0.800487]\n",
      "epoch:18 step:14342 [D loss: 0.664847, acc.: 62.50%] [G loss: 0.811668]\n",
      "epoch:18 step:14343 [D loss: 0.693780, acc.: 50.00%] [G loss: 0.794592]\n",
      "epoch:18 step:14344 [D loss: 0.700424, acc.: 49.22%] [G loss: 0.802593]\n",
      "epoch:18 step:14345 [D loss: 0.747459, acc.: 41.41%] [G loss: 0.793239]\n",
      "epoch:18 step:14346 [D loss: 0.749141, acc.: 35.94%] [G loss: 0.811201]\n",
      "epoch:18 step:14347 [D loss: 0.725364, acc.: 41.41%] [G loss: 0.791657]\n",
      "epoch:18 step:14348 [D loss: 0.687153, acc.: 60.94%] [G loss: 0.734856]\n",
      "epoch:18 step:14349 [D loss: 0.708073, acc.: 46.09%] [G loss: 0.761787]\n",
      "epoch:18 step:14350 [D loss: 0.685932, acc.: 58.59%] [G loss: 0.762885]\n",
      "epoch:18 step:14351 [D loss: 0.707152, acc.: 50.78%] [G loss: 0.766555]\n",
      "epoch:18 step:14352 [D loss: 0.709363, acc.: 49.22%] [G loss: 0.736684]\n",
      "epoch:18 step:14353 [D loss: 0.728307, acc.: 43.75%] [G loss: 0.735026]\n",
      "epoch:18 step:14354 [D loss: 0.677815, acc.: 60.16%] [G loss: 0.755672]\n",
      "epoch:18 step:14355 [D loss: 0.728390, acc.: 40.62%] [G loss: 0.703631]\n",
      "epoch:18 step:14356 [D loss: 0.699030, acc.: 54.69%] [G loss: 0.802439]\n",
      "epoch:18 step:14357 [D loss: 0.710473, acc.: 53.91%] [G loss: 0.722768]\n",
      "epoch:18 step:14358 [D loss: 0.731146, acc.: 48.44%] [G loss: 0.752526]\n",
      "epoch:18 step:14359 [D loss: 0.703331, acc.: 50.00%] [G loss: 0.748166]\n",
      "epoch:18 step:14360 [D loss: 0.686646, acc.: 53.91%] [G loss: 0.745856]\n",
      "epoch:18 step:14361 [D loss: 0.655438, acc.: 60.94%] [G loss: 0.782725]\n",
      "epoch:18 step:14362 [D loss: 0.699530, acc.: 49.22%] [G loss: 0.733755]\n",
      "epoch:18 step:14363 [D loss: 0.694668, acc.: 53.91%] [G loss: 0.753960]\n",
      "epoch:18 step:14364 [D loss: 0.713186, acc.: 49.22%] [G loss: 0.734835]\n",
      "epoch:18 step:14365 [D loss: 0.688037, acc.: 53.91%] [G loss: 0.781041]\n",
      "epoch:18 step:14366 [D loss: 0.704568, acc.: 50.00%] [G loss: 0.745446]\n",
      "epoch:18 step:14367 [D loss: 0.682626, acc.: 53.91%] [G loss: 0.779533]\n",
      "epoch:18 step:14368 [D loss: 0.683448, acc.: 57.03%] [G loss: 0.774930]\n",
      "epoch:18 step:14369 [D loss: 0.724895, acc.: 42.97%] [G loss: 0.728890]\n",
      "epoch:18 step:14370 [D loss: 0.727902, acc.: 39.06%] [G loss: 0.717590]\n",
      "epoch:18 step:14371 [D loss: 0.724853, acc.: 43.75%] [G loss: 0.762315]\n",
      "epoch:18 step:14372 [D loss: 0.683134, acc.: 53.12%] [G loss: 0.759883]\n",
      "epoch:18 step:14373 [D loss: 0.694663, acc.: 50.78%] [G loss: 0.758525]\n",
      "epoch:18 step:14374 [D loss: 0.698985, acc.: 50.00%] [G loss: 0.795356]\n",
      "epoch:18 step:14375 [D loss: 0.722701, acc.: 44.53%] [G loss: 0.726456]\n",
      "epoch:18 step:14376 [D loss: 0.691254, acc.: 52.34%] [G loss: 0.707214]\n",
      "epoch:18 step:14377 [D loss: 0.677976, acc.: 55.47%] [G loss: 0.765337]\n",
      "epoch:18 step:14378 [D loss: 0.684952, acc.: 56.25%] [G loss: 0.735575]\n",
      "epoch:18 step:14379 [D loss: 0.717490, acc.: 44.53%] [G loss: 0.692205]\n",
      "epoch:18 step:14380 [D loss: 0.662588, acc.: 60.16%] [G loss: 0.729611]\n",
      "epoch:18 step:14381 [D loss: 0.680800, acc.: 56.25%] [G loss: 0.746426]\n",
      "epoch:18 step:14382 [D loss: 0.694951, acc.: 51.56%] [G loss: 0.720324]\n",
      "epoch:18 step:14383 [D loss: 0.679444, acc.: 56.25%] [G loss: 0.776760]\n",
      "epoch:18 step:14384 [D loss: 0.722918, acc.: 43.75%] [G loss: 0.871655]\n",
      "epoch:18 step:14385 [D loss: 0.706185, acc.: 47.66%] [G loss: 0.817141]\n",
      "epoch:18 step:14386 [D loss: 0.713652, acc.: 47.66%] [G loss: 0.826714]\n",
      "epoch:18 step:14387 [D loss: 0.720393, acc.: 42.97%] [G loss: 0.736875]\n",
      "epoch:18 step:14388 [D loss: 0.708912, acc.: 49.22%] [G loss: 0.797342]\n",
      "epoch:18 step:14389 [D loss: 0.732732, acc.: 42.97%] [G loss: 0.716995]\n",
      "epoch:18 step:14390 [D loss: 0.706914, acc.: 50.78%] [G loss: 0.724544]\n",
      "epoch:18 step:14391 [D loss: 0.621420, acc.: 73.44%] [G loss: 0.777801]\n",
      "epoch:18 step:14392 [D loss: 0.644453, acc.: 65.62%] [G loss: 0.773586]\n",
      "epoch:18 step:14393 [D loss: 0.696654, acc.: 53.12%] [G loss: 0.792141]\n",
      "epoch:18 step:14394 [D loss: 0.677852, acc.: 62.50%] [G loss: 0.740210]\n",
      "epoch:18 step:14395 [D loss: 0.678592, acc.: 58.59%] [G loss: 0.779141]\n",
      "epoch:18 step:14396 [D loss: 0.720373, acc.: 46.88%] [G loss: 0.696233]\n",
      "epoch:18 step:14397 [D loss: 0.704727, acc.: 54.69%] [G loss: 0.708448]\n",
      "epoch:18 step:14398 [D loss: 0.717271, acc.: 43.75%] [G loss: 0.683836]\n",
      "epoch:18 step:14399 [D loss: 0.695410, acc.: 49.22%] [G loss: 0.852820]\n",
      "epoch:18 step:14400 [D loss: 0.666629, acc.: 56.25%] [G loss: 0.778683]\n",
      "epoch:18 step:14401 [D loss: 0.714827, acc.: 51.56%] [G loss: 0.866325]\n",
      "epoch:18 step:14402 [D loss: 0.690299, acc.: 51.56%] [G loss: 0.829664]\n",
      "epoch:18 step:14403 [D loss: 0.698112, acc.: 46.88%] [G loss: 0.766687]\n",
      "epoch:18 step:14404 [D loss: 0.709001, acc.: 47.66%] [G loss: 0.818224]\n",
      "epoch:18 step:14405 [D loss: 0.689950, acc.: 56.25%] [G loss: 0.732124]\n",
      "epoch:18 step:14406 [D loss: 0.689893, acc.: 53.12%] [G loss: 0.836688]\n",
      "epoch:18 step:14407 [D loss: 0.666924, acc.: 60.94%] [G loss: 0.738121]\n",
      "epoch:18 step:14408 [D loss: 0.752683, acc.: 42.97%] [G loss: 0.717803]\n",
      "epoch:18 step:14409 [D loss: 0.717733, acc.: 42.19%] [G loss: 0.739971]\n",
      "epoch:18 step:14410 [D loss: 0.675371, acc.: 55.47%] [G loss: 0.756188]\n",
      "epoch:18 step:14411 [D loss: 0.700787, acc.: 48.44%] [G loss: 0.766827]\n",
      "epoch:18 step:14412 [D loss: 0.675698, acc.: 58.59%] [G loss: 0.743181]\n",
      "epoch:18 step:14413 [D loss: 0.699875, acc.: 51.56%] [G loss: 0.766823]\n",
      "epoch:18 step:14414 [D loss: 0.640002, acc.: 60.16%] [G loss: 0.751076]\n",
      "epoch:18 step:14415 [D loss: 0.675419, acc.: 60.94%] [G loss: 0.778670]\n",
      "epoch:18 step:14416 [D loss: 0.706074, acc.: 48.44%] [G loss: 0.827827]\n",
      "epoch:18 step:14417 [D loss: 0.660057, acc.: 58.59%] [G loss: 0.761271]\n",
      "epoch:18 step:14418 [D loss: 0.677575, acc.: 57.03%] [G loss: 0.733041]\n",
      "epoch:18 step:14419 [D loss: 0.677998, acc.: 53.91%] [G loss: 0.803379]\n",
      "epoch:18 step:14420 [D loss: 0.708744, acc.: 50.78%] [G loss: 0.733679]\n",
      "epoch:18 step:14421 [D loss: 0.719528, acc.: 41.41%] [G loss: 0.729699]\n",
      "epoch:18 step:14422 [D loss: 0.703940, acc.: 46.88%] [G loss: 0.720823]\n",
      "epoch:18 step:14423 [D loss: 0.704059, acc.: 48.44%] [G loss: 0.740712]\n",
      "epoch:18 step:14424 [D loss: 0.673861, acc.: 60.94%] [G loss: 0.649529]\n",
      "epoch:18 step:14425 [D loss: 0.684239, acc.: 55.47%] [G loss: 0.743334]\n",
      "epoch:18 step:14426 [D loss: 0.661285, acc.: 57.81%] [G loss: 0.718824]\n",
      "epoch:18 step:14427 [D loss: 0.720351, acc.: 42.19%] [G loss: 0.762821]\n",
      "epoch:18 step:14428 [D loss: 0.712708, acc.: 50.78%] [G loss: 0.694261]\n",
      "epoch:18 step:14429 [D loss: 0.691445, acc.: 57.81%] [G loss: 0.761617]\n",
      "epoch:18 step:14430 [D loss: 0.673127, acc.: 60.94%] [G loss: 0.788849]\n",
      "epoch:18 step:14431 [D loss: 0.648843, acc.: 63.28%] [G loss: 0.774804]\n",
      "epoch:18 step:14432 [D loss: 0.671872, acc.: 57.81%] [G loss: 0.802668]\n",
      "epoch:18 step:14433 [D loss: 0.710038, acc.: 46.88%] [G loss: 0.772036]\n",
      "epoch:18 step:14434 [D loss: 0.620016, acc.: 73.44%] [G loss: 0.803995]\n",
      "epoch:18 step:14435 [D loss: 0.710708, acc.: 45.31%] [G loss: 0.728298]\n",
      "epoch:18 step:14436 [D loss: 0.657511, acc.: 64.84%] [G loss: 0.802502]\n",
      "epoch:18 step:14437 [D loss: 0.652065, acc.: 60.94%] [G loss: 0.791026]\n",
      "epoch:18 step:14438 [D loss: 0.753101, acc.: 37.50%] [G loss: 0.681180]\n",
      "epoch:18 step:14439 [D loss: 0.649344, acc.: 62.50%] [G loss: 0.708594]\n",
      "epoch:18 step:14440 [D loss: 0.761247, acc.: 38.28%] [G loss: 0.669080]\n",
      "epoch:18 step:14441 [D loss: 0.695197, acc.: 50.78%] [G loss: 0.739301]\n",
      "epoch:18 step:14442 [D loss: 0.725319, acc.: 46.88%] [G loss: 0.749465]\n",
      "epoch:18 step:14443 [D loss: 0.677797, acc.: 59.38%] [G loss: 0.762426]\n",
      "epoch:18 step:14444 [D loss: 0.654151, acc.: 67.97%] [G loss: 0.736655]\n",
      "epoch:18 step:14445 [D loss: 0.656687, acc.: 61.72%] [G loss: 0.820529]\n",
      "epoch:18 step:14446 [D loss: 0.693744, acc.: 46.88%] [G loss: 0.740457]\n",
      "epoch:18 step:14447 [D loss: 0.692411, acc.: 50.00%] [G loss: 0.761043]\n",
      "epoch:18 step:14448 [D loss: 0.659152, acc.: 57.81%] [G loss: 0.850754]\n",
      "epoch:18 step:14449 [D loss: 0.713764, acc.: 52.34%] [G loss: 0.776434]\n",
      "epoch:18 step:14450 [D loss: 0.710379, acc.: 45.31%] [G loss: 0.776371]\n",
      "epoch:18 step:14451 [D loss: 0.670098, acc.: 57.03%] [G loss: 0.740504]\n",
      "epoch:18 step:14452 [D loss: 0.673444, acc.: 61.72%] [G loss: 0.761012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14453 [D loss: 0.725366, acc.: 48.44%] [G loss: 0.743925]\n",
      "epoch:18 step:14454 [D loss: 0.656840, acc.: 67.19%] [G loss: 0.767562]\n",
      "epoch:18 step:14455 [D loss: 0.684253, acc.: 55.47%] [G loss: 0.764589]\n",
      "epoch:18 step:14456 [D loss: 0.745026, acc.: 42.97%] [G loss: 0.776285]\n",
      "epoch:18 step:14457 [D loss: 0.668266, acc.: 59.38%] [G loss: 0.729235]\n",
      "epoch:18 step:14458 [D loss: 0.732765, acc.: 47.66%] [G loss: 0.720656]\n",
      "epoch:18 step:14459 [D loss: 0.611999, acc.: 71.88%] [G loss: 0.721629]\n",
      "epoch:18 step:14460 [D loss: 0.683800, acc.: 57.81%] [G loss: 0.710184]\n",
      "epoch:18 step:14461 [D loss: 0.669858, acc.: 53.91%] [G loss: 0.724124]\n",
      "epoch:18 step:14462 [D loss: 0.668958, acc.: 60.94%] [G loss: 0.788214]\n",
      "epoch:18 step:14463 [D loss: 0.704452, acc.: 54.69%] [G loss: 0.745269]\n",
      "epoch:18 step:14464 [D loss: 0.656354, acc.: 59.38%] [G loss: 0.791895]\n",
      "epoch:18 step:14465 [D loss: 0.687871, acc.: 51.56%] [G loss: 0.792424]\n",
      "epoch:18 step:14466 [D loss: 0.673199, acc.: 57.81%] [G loss: 0.757596]\n",
      "epoch:18 step:14467 [D loss: 0.663807, acc.: 60.16%] [G loss: 0.721227]\n",
      "epoch:18 step:14468 [D loss: 0.662121, acc.: 61.72%] [G loss: 0.767058]\n",
      "epoch:18 step:14469 [D loss: 0.778885, acc.: 37.50%] [G loss: 0.710671]\n",
      "epoch:18 step:14470 [D loss: 0.711545, acc.: 44.53%] [G loss: 0.711626]\n",
      "epoch:18 step:14471 [D loss: 0.693145, acc.: 56.25%] [G loss: 0.678624]\n",
      "epoch:18 step:14472 [D loss: 0.703136, acc.: 48.44%] [G loss: 0.708679]\n",
      "epoch:18 step:14473 [D loss: 0.695257, acc.: 59.38%] [G loss: 0.720270]\n",
      "epoch:18 step:14474 [D loss: 0.639251, acc.: 65.62%] [G loss: 0.839123]\n",
      "epoch:18 step:14475 [D loss: 0.736635, acc.: 46.88%] [G loss: 0.788907]\n",
      "epoch:18 step:14476 [D loss: 0.680223, acc.: 51.56%] [G loss: 0.737746]\n",
      "epoch:18 step:14477 [D loss: 0.676229, acc.: 60.16%] [G loss: 0.824298]\n",
      "epoch:18 step:14478 [D loss: 0.720303, acc.: 42.97%] [G loss: 0.717804]\n",
      "epoch:18 step:14479 [D loss: 0.698563, acc.: 49.22%] [G loss: 0.796160]\n",
      "epoch:18 step:14480 [D loss: 0.687817, acc.: 52.34%] [G loss: 0.775408]\n",
      "epoch:18 step:14481 [D loss: 0.684204, acc.: 53.91%] [G loss: 0.784638]\n",
      "epoch:18 step:14482 [D loss: 0.745312, acc.: 40.62%] [G loss: 0.750929]\n",
      "epoch:18 step:14483 [D loss: 0.715552, acc.: 49.22%] [G loss: 0.753036]\n",
      "epoch:18 step:14484 [D loss: 0.677227, acc.: 57.03%] [G loss: 0.728645]\n",
      "epoch:18 step:14485 [D loss: 0.662058, acc.: 58.59%] [G loss: 0.752726]\n",
      "epoch:18 step:14486 [D loss: 0.689246, acc.: 58.59%] [G loss: 0.670195]\n",
      "epoch:18 step:14487 [D loss: 0.677566, acc.: 53.91%] [G loss: 0.721546]\n",
      "epoch:18 step:14488 [D loss: 0.674635, acc.: 60.94%] [G loss: 0.745919]\n",
      "epoch:18 step:14489 [D loss: 0.694230, acc.: 51.56%] [G loss: 0.742161]\n",
      "epoch:18 step:14490 [D loss: 0.655329, acc.: 67.19%] [G loss: 0.709246]\n",
      "epoch:18 step:14491 [D loss: 0.666711, acc.: 62.50%] [G loss: 0.777153]\n",
      "epoch:18 step:14492 [D loss: 0.685859, acc.: 52.34%] [G loss: 0.852583]\n",
      "epoch:18 step:14493 [D loss: 0.704781, acc.: 48.44%] [G loss: 0.736990]\n",
      "epoch:18 step:14494 [D loss: 0.714499, acc.: 40.62%] [G loss: 0.784804]\n",
      "epoch:18 step:14495 [D loss: 0.762035, acc.: 32.81%] [G loss: 0.716134]\n",
      "epoch:18 step:14496 [D loss: 0.698932, acc.: 51.56%] [G loss: 0.773032]\n",
      "epoch:18 step:14497 [D loss: 0.714969, acc.: 45.31%] [G loss: 0.758590]\n",
      "epoch:18 step:14498 [D loss: 0.721569, acc.: 51.56%] [G loss: 0.732426]\n",
      "epoch:18 step:14499 [D loss: 0.717194, acc.: 45.31%] [G loss: 0.811843]\n",
      "epoch:18 step:14500 [D loss: 0.730693, acc.: 42.97%] [G loss: 0.785932]\n",
      "epoch:18 step:14501 [D loss: 0.677608, acc.: 60.94%] [G loss: 0.773789]\n",
      "epoch:18 step:14502 [D loss: 0.700606, acc.: 50.00%] [G loss: 0.761978]\n",
      "epoch:18 step:14503 [D loss: 0.742393, acc.: 38.28%] [G loss: 0.750861]\n",
      "epoch:18 step:14504 [D loss: 0.682531, acc.: 57.03%] [G loss: 0.771158]\n",
      "epoch:18 step:14505 [D loss: 0.682308, acc.: 53.91%] [G loss: 0.805136]\n",
      "epoch:18 step:14506 [D loss: 0.668897, acc.: 60.16%] [G loss: 0.812051]\n",
      "epoch:18 step:14507 [D loss: 0.675535, acc.: 57.03%] [G loss: 0.801331]\n",
      "epoch:18 step:14508 [D loss: 0.688707, acc.: 52.34%] [G loss: 0.763791]\n",
      "epoch:18 step:14509 [D loss: 0.675015, acc.: 58.59%] [G loss: 0.785780]\n",
      "epoch:18 step:14510 [D loss: 0.668374, acc.: 62.50%] [G loss: 0.818135]\n",
      "epoch:18 step:14511 [D loss: 0.718161, acc.: 53.12%] [G loss: 0.820997]\n",
      "epoch:18 step:14512 [D loss: 0.698697, acc.: 55.47%] [G loss: 0.762745]\n",
      "epoch:18 step:14513 [D loss: 0.690042, acc.: 51.56%] [G loss: 0.722591]\n",
      "epoch:18 step:14514 [D loss: 0.695773, acc.: 53.91%] [G loss: 0.744288]\n",
      "epoch:18 step:14515 [D loss: 0.727606, acc.: 45.31%] [G loss: 0.756156]\n",
      "epoch:18 step:14516 [D loss: 0.670857, acc.: 60.16%] [G loss: 0.809334]\n",
      "epoch:18 step:14517 [D loss: 0.748638, acc.: 42.19%] [G loss: 0.696697]\n",
      "epoch:18 step:14518 [D loss: 0.686414, acc.: 54.69%] [G loss: 0.744303]\n",
      "epoch:18 step:14519 [D loss: 0.678121, acc.: 58.59%] [G loss: 0.786747]\n",
      "epoch:18 step:14520 [D loss: 0.699186, acc.: 51.56%] [G loss: 0.743127]\n",
      "epoch:18 step:14521 [D loss: 0.752893, acc.: 39.06%] [G loss: 0.748415]\n",
      "epoch:18 step:14522 [D loss: 0.701833, acc.: 49.22%] [G loss: 0.778786]\n",
      "epoch:18 step:14523 [D loss: 0.730166, acc.: 46.09%] [G loss: 0.767089]\n",
      "epoch:18 step:14524 [D loss: 0.666520, acc.: 65.62%] [G loss: 0.802756]\n",
      "epoch:18 step:14525 [D loss: 0.675914, acc.: 67.97%] [G loss: 0.802716]\n",
      "epoch:18 step:14526 [D loss: 0.674959, acc.: 59.38%] [G loss: 0.826965]\n",
      "epoch:18 step:14527 [D loss: 0.668176, acc.: 62.50%] [G loss: 0.799813]\n",
      "epoch:18 step:14528 [D loss: 0.689300, acc.: 54.69%] [G loss: 0.803877]\n",
      "epoch:18 step:14529 [D loss: 0.683659, acc.: 49.22%] [G loss: 0.827632]\n",
      "epoch:18 step:14530 [D loss: 0.694589, acc.: 57.03%] [G loss: 0.782597]\n",
      "epoch:18 step:14531 [D loss: 0.717526, acc.: 50.00%] [G loss: 0.793558]\n",
      "epoch:18 step:14532 [D loss: 0.651747, acc.: 63.28%] [G loss: 0.688140]\n",
      "epoch:18 step:14533 [D loss: 0.723867, acc.: 40.62%] [G loss: 0.699904]\n",
      "epoch:18 step:14534 [D loss: 0.696030, acc.: 50.78%] [G loss: 0.715345]\n",
      "epoch:18 step:14535 [D loss: 0.686601, acc.: 57.81%] [G loss: 0.755519]\n",
      "epoch:18 step:14536 [D loss: 0.620086, acc.: 71.09%] [G loss: 0.792184]\n",
      "epoch:18 step:14537 [D loss: 0.704879, acc.: 46.88%] [G loss: 0.763910]\n",
      "epoch:18 step:14538 [D loss: 0.717393, acc.: 47.66%] [G loss: 0.785529]\n",
      "epoch:18 step:14539 [D loss: 0.729989, acc.: 44.53%] [G loss: 0.735881]\n",
      "epoch:18 step:14540 [D loss: 0.759450, acc.: 43.75%] [G loss: 0.684527]\n",
      "epoch:18 step:14541 [D loss: 0.749849, acc.: 40.62%] [G loss: 0.706828]\n",
      "epoch:18 step:14542 [D loss: 0.653852, acc.: 60.16%] [G loss: 0.767804]\n",
      "epoch:18 step:14543 [D loss: 0.701862, acc.: 54.69%] [G loss: 0.729650]\n",
      "epoch:18 step:14544 [D loss: 0.743049, acc.: 36.72%] [G loss: 0.689686]\n",
      "epoch:18 step:14545 [D loss: 0.752393, acc.: 32.03%] [G loss: 0.736253]\n",
      "epoch:18 step:14546 [D loss: 0.713247, acc.: 45.31%] [G loss: 0.758758]\n",
      "epoch:18 step:14547 [D loss: 0.689144, acc.: 53.91%] [G loss: 0.790258]\n",
      "epoch:18 step:14548 [D loss: 0.678395, acc.: 57.81%] [G loss: 0.814777]\n",
      "epoch:18 step:14549 [D loss: 0.640967, acc.: 67.97%] [G loss: 0.834162]\n",
      "epoch:18 step:14550 [D loss: 0.711473, acc.: 47.66%] [G loss: 0.759582]\n",
      "epoch:18 step:14551 [D loss: 0.688969, acc.: 51.56%] [G loss: 0.800330]\n",
      "epoch:18 step:14552 [D loss: 0.721534, acc.: 43.75%] [G loss: 0.785345]\n",
      "epoch:18 step:14553 [D loss: 0.709501, acc.: 46.88%] [G loss: 0.852276]\n",
      "epoch:18 step:14554 [D loss: 0.685150, acc.: 53.91%] [G loss: 0.828780]\n",
      "epoch:18 step:14555 [D loss: 0.695110, acc.: 52.34%] [G loss: 0.789303]\n",
      "epoch:18 step:14556 [D loss: 0.689602, acc.: 53.91%] [G loss: 0.747674]\n",
      "epoch:18 step:14557 [D loss: 0.673303, acc.: 59.38%] [G loss: 0.758675]\n",
      "epoch:18 step:14558 [D loss: 0.670836, acc.: 60.16%] [G loss: 0.725044]\n",
      "epoch:18 step:14559 [D loss: 0.683624, acc.: 56.25%] [G loss: 0.751479]\n",
      "epoch:18 step:14560 [D loss: 0.689894, acc.: 52.34%] [G loss: 0.733385]\n",
      "epoch:18 step:14561 [D loss: 0.678674, acc.: 53.91%] [G loss: 0.761879]\n",
      "epoch:18 step:14562 [D loss: 0.698823, acc.: 46.88%] [G loss: 0.784211]\n",
      "epoch:18 step:14563 [D loss: 0.620629, acc.: 79.69%] [G loss: 0.869073]\n",
      "epoch:18 step:14564 [D loss: 0.717131, acc.: 46.88%] [G loss: 0.779055]\n",
      "epoch:18 step:14565 [D loss: 0.677104, acc.: 60.16%] [G loss: 0.765935]\n",
      "epoch:18 step:14566 [D loss: 0.684922, acc.: 58.59%] [G loss: 0.722298]\n",
      "epoch:18 step:14567 [D loss: 0.708154, acc.: 49.22%] [G loss: 0.794087]\n",
      "epoch:18 step:14568 [D loss: 0.678106, acc.: 57.03%] [G loss: 0.757265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14569 [D loss: 0.707711, acc.: 46.09%] [G loss: 0.769137]\n",
      "epoch:18 step:14570 [D loss: 0.766872, acc.: 30.47%] [G loss: 0.705775]\n",
      "epoch:18 step:14571 [D loss: 0.729872, acc.: 42.19%] [G loss: 0.714187]\n",
      "epoch:18 step:14572 [D loss: 0.686208, acc.: 60.16%] [G loss: 0.682254]\n",
      "epoch:18 step:14573 [D loss: 0.698311, acc.: 51.56%] [G loss: 0.702673]\n",
      "epoch:18 step:14574 [D loss: 0.688655, acc.: 50.00%] [G loss: 0.719145]\n",
      "epoch:18 step:14575 [D loss: 0.704343, acc.: 46.88%] [G loss: 0.737933]\n",
      "epoch:18 step:14576 [D loss: 0.639198, acc.: 66.41%] [G loss: 0.738262]\n",
      "epoch:18 step:14577 [D loss: 0.693857, acc.: 53.91%] [G loss: 0.754960]\n",
      "epoch:18 step:14578 [D loss: 0.702031, acc.: 50.00%] [G loss: 0.689176]\n",
      "epoch:18 step:14579 [D loss: 0.692021, acc.: 51.56%] [G loss: 0.701111]\n",
      "epoch:18 step:14580 [D loss: 0.696000, acc.: 55.47%] [G loss: 0.780148]\n",
      "epoch:18 step:14581 [D loss: 0.691153, acc.: 55.47%] [G loss: 0.713778]\n",
      "epoch:18 step:14582 [D loss: 0.715345, acc.: 47.66%] [G loss: 0.698282]\n",
      "epoch:18 step:14583 [D loss: 0.684300, acc.: 60.16%] [G loss: 0.766924]\n",
      "epoch:18 step:14584 [D loss: 0.865731, acc.: 20.31%] [G loss: 0.697904]\n",
      "epoch:18 step:14585 [D loss: 0.738681, acc.: 46.88%] [G loss: 0.699825]\n",
      "epoch:18 step:14586 [D loss: 0.738477, acc.: 37.50%] [G loss: 0.733230]\n",
      "epoch:18 step:14587 [D loss: 0.681747, acc.: 53.91%] [G loss: 0.760809]\n",
      "epoch:18 step:14588 [D loss: 0.680234, acc.: 57.03%] [G loss: 0.809996]\n",
      "epoch:18 step:14589 [D loss: 0.650827, acc.: 65.62%] [G loss: 0.782739]\n",
      "epoch:18 step:14590 [D loss: 0.719230, acc.: 42.97%] [G loss: 0.770568]\n",
      "epoch:18 step:14591 [D loss: 0.691641, acc.: 52.34%] [G loss: 0.804397]\n",
      "epoch:18 step:14592 [D loss: 0.658034, acc.: 62.50%] [G loss: 0.855038]\n",
      "epoch:18 step:14593 [D loss: 0.713365, acc.: 47.66%] [G loss: 0.805283]\n",
      "epoch:18 step:14594 [D loss: 0.663195, acc.: 55.47%] [G loss: 0.827252]\n",
      "epoch:18 step:14595 [D loss: 0.663944, acc.: 57.81%] [G loss: 0.780204]\n",
      "epoch:18 step:14596 [D loss: 0.638533, acc.: 69.53%] [G loss: 0.788986]\n",
      "epoch:18 step:14597 [D loss: 0.669041, acc.: 58.59%] [G loss: 0.800338]\n",
      "epoch:18 step:14598 [D loss: 0.693548, acc.: 46.88%] [G loss: 0.704313]\n",
      "epoch:18 step:14599 [D loss: 0.644380, acc.: 65.62%] [G loss: 0.732330]\n",
      "epoch:18 step:14600 [D loss: 0.589289, acc.: 75.00%] [G loss: 0.777679]\n",
      "epoch:18 step:14601 [D loss: 0.677894, acc.: 54.69%] [G loss: 0.683395]\n",
      "epoch:18 step:14602 [D loss: 0.661548, acc.: 62.50%] [G loss: 0.707860]\n",
      "epoch:18 step:14603 [D loss: 0.654518, acc.: 59.38%] [G loss: 0.725576]\n",
      "epoch:18 step:14604 [D loss: 0.751168, acc.: 39.06%] [G loss: 0.686623]\n",
      "epoch:18 step:14605 [D loss: 0.647324, acc.: 60.94%] [G loss: 0.707939]\n",
      "epoch:18 step:14606 [D loss: 0.706384, acc.: 46.09%] [G loss: 0.701231]\n",
      "epoch:18 step:14607 [D loss: 0.677141, acc.: 58.59%] [G loss: 0.653787]\n",
      "epoch:18 step:14608 [D loss: 0.735208, acc.: 42.97%] [G loss: 0.664482]\n",
      "epoch:18 step:14609 [D loss: 0.668362, acc.: 59.38%] [G loss: 0.689611]\n",
      "epoch:18 step:14610 [D loss: 0.789744, acc.: 32.81%] [G loss: 0.709670]\n",
      "epoch:18 step:14611 [D loss: 0.756809, acc.: 32.03%] [G loss: 0.719438]\n",
      "epoch:18 step:14612 [D loss: 0.719990, acc.: 45.31%] [G loss: 0.721262]\n",
      "epoch:18 step:14613 [D loss: 0.723463, acc.: 40.62%] [G loss: 0.812843]\n",
      "epoch:18 step:14614 [D loss: 0.745570, acc.: 42.19%] [G loss: 0.750153]\n",
      "epoch:18 step:14615 [D loss: 0.685070, acc.: 58.59%] [G loss: 0.739979]\n",
      "epoch:18 step:14616 [D loss: 0.680545, acc.: 58.59%] [G loss: 0.800038]\n",
      "epoch:18 step:14617 [D loss: 0.642194, acc.: 71.88%] [G loss: 0.804331]\n",
      "epoch:18 step:14618 [D loss: 0.682758, acc.: 57.03%] [G loss: 0.753949]\n",
      "epoch:18 step:14619 [D loss: 0.719392, acc.: 45.31%] [G loss: 0.732700]\n",
      "epoch:18 step:14620 [D loss: 0.717207, acc.: 46.88%] [G loss: 0.753450]\n",
      "epoch:18 step:14621 [D loss: 0.655318, acc.: 64.84%] [G loss: 0.780925]\n",
      "epoch:18 step:14622 [D loss: 0.681967, acc.: 56.25%] [G loss: 0.744511]\n",
      "epoch:18 step:14623 [D loss: 0.698440, acc.: 53.12%] [G loss: 0.774516]\n",
      "epoch:18 step:14624 [D loss: 0.670970, acc.: 61.72%] [G loss: 0.775720]\n",
      "epoch:18 step:14625 [D loss: 0.677333, acc.: 56.25%] [G loss: 0.790377]\n",
      "epoch:18 step:14626 [D loss: 0.708208, acc.: 45.31%] [G loss: 0.772808]\n",
      "epoch:18 step:14627 [D loss: 0.677789, acc.: 53.91%] [G loss: 0.734061]\n",
      "epoch:18 step:14628 [D loss: 0.644867, acc.: 71.09%] [G loss: 0.719268]\n",
      "epoch:18 step:14629 [D loss: 0.661575, acc.: 60.94%] [G loss: 0.764324]\n",
      "epoch:18 step:14630 [D loss: 0.657561, acc.: 63.28%] [G loss: 0.642965]\n",
      "epoch:18 step:14631 [D loss: 0.666913, acc.: 59.38%] [G loss: 0.684798]\n",
      "epoch:18 step:14632 [D loss: 0.734008, acc.: 48.44%] [G loss: 0.706503]\n",
      "epoch:18 step:14633 [D loss: 0.693410, acc.: 50.00%] [G loss: 0.665168]\n",
      "epoch:18 step:14634 [D loss: 0.709471, acc.: 48.44%] [G loss: 0.699174]\n",
      "epoch:18 step:14635 [D loss: 0.746154, acc.: 43.75%] [G loss: 0.650192]\n",
      "epoch:18 step:14636 [D loss: 0.638407, acc.: 67.97%] [G loss: 0.742735]\n",
      "epoch:18 step:14637 [D loss: 0.742917, acc.: 36.72%] [G loss: 0.728572]\n",
      "epoch:18 step:14638 [D loss: 0.753049, acc.: 39.06%] [G loss: 0.774118]\n",
      "epoch:18 step:14639 [D loss: 0.718610, acc.: 39.06%] [G loss: 0.703421]\n",
      "epoch:18 step:14640 [D loss: 0.691043, acc.: 58.59%] [G loss: 0.736770]\n",
      "epoch:18 step:14641 [D loss: 0.724772, acc.: 45.31%] [G loss: 0.747903]\n",
      "epoch:18 step:14642 [D loss: 0.683604, acc.: 50.78%] [G loss: 0.772871]\n",
      "epoch:18 step:14643 [D loss: 0.677936, acc.: 57.81%] [G loss: 0.738606]\n",
      "epoch:18 step:14644 [D loss: 0.714972, acc.: 46.88%] [G loss: 0.736533]\n",
      "epoch:18 step:14645 [D loss: 0.653085, acc.: 60.94%] [G loss: 0.807597]\n",
      "epoch:18 step:14646 [D loss: 0.697556, acc.: 54.69%] [G loss: 0.771546]\n",
      "epoch:18 step:14647 [D loss: 0.678380, acc.: 64.84%] [G loss: 0.771507]\n",
      "epoch:18 step:14648 [D loss: 0.678956, acc.: 55.47%] [G loss: 0.829889]\n",
      "epoch:18 step:14649 [D loss: 0.690595, acc.: 51.56%] [G loss: 0.840015]\n",
      "epoch:18 step:14650 [D loss: 0.680590, acc.: 58.59%] [G loss: 0.782615]\n",
      "epoch:18 step:14651 [D loss: 0.694574, acc.: 52.34%] [G loss: 0.760955]\n",
      "epoch:18 step:14652 [D loss: 0.658166, acc.: 60.94%] [G loss: 0.769703]\n",
      "epoch:18 step:14653 [D loss: 0.636007, acc.: 71.88%] [G loss: 0.764456]\n",
      "epoch:18 step:14654 [D loss: 0.655199, acc.: 58.59%] [G loss: 0.699508]\n",
      "epoch:18 step:14655 [D loss: 0.612977, acc.: 77.34%] [G loss: 0.779194]\n",
      "epoch:18 step:14656 [D loss: 0.678289, acc.: 57.81%] [G loss: 0.707051]\n",
      "epoch:18 step:14657 [D loss: 0.661457, acc.: 64.84%] [G loss: 0.670705]\n",
      "epoch:18 step:14658 [D loss: 0.669613, acc.: 58.59%] [G loss: 0.739427]\n",
      "epoch:18 step:14659 [D loss: 0.579359, acc.: 75.00%] [G loss: 0.703506]\n",
      "epoch:18 step:14660 [D loss: 0.662120, acc.: 57.81%] [G loss: 0.751760]\n",
      "epoch:18 step:14661 [D loss: 0.648191, acc.: 58.59%] [G loss: 0.698200]\n",
      "epoch:18 step:14662 [D loss: 0.670922, acc.: 58.59%] [G loss: 0.704628]\n",
      "epoch:18 step:14663 [D loss: 0.674320, acc.: 60.16%] [G loss: 0.695345]\n",
      "epoch:18 step:14664 [D loss: 0.683172, acc.: 60.16%] [G loss: 0.718558]\n",
      "epoch:18 step:14665 [D loss: 0.657200, acc.: 60.16%] [G loss: 0.664540]\n",
      "epoch:18 step:14666 [D loss: 0.731995, acc.: 42.97%] [G loss: 0.725320]\n",
      "epoch:18 step:14667 [D loss: 0.712286, acc.: 50.00%] [G loss: 0.792763]\n",
      "epoch:18 step:14668 [D loss: 0.689993, acc.: 53.91%] [G loss: 0.680579]\n",
      "epoch:18 step:14669 [D loss: 0.708995, acc.: 51.56%] [G loss: 0.665761]\n",
      "epoch:18 step:14670 [D loss: 0.743717, acc.: 34.38%] [G loss: 0.762415]\n",
      "epoch:18 step:14671 [D loss: 0.723885, acc.: 45.31%] [G loss: 0.740123]\n",
      "epoch:18 step:14672 [D loss: 0.712649, acc.: 42.97%] [G loss: 0.814203]\n",
      "epoch:18 step:14673 [D loss: 0.677547, acc.: 55.47%] [G loss: 0.830845]\n",
      "epoch:18 step:14674 [D loss: 0.712928, acc.: 47.66%] [G loss: 0.820541]\n",
      "epoch:18 step:14675 [D loss: 0.730777, acc.: 44.53%] [G loss: 0.766981]\n",
      "epoch:18 step:14676 [D loss: 0.677540, acc.: 53.12%] [G loss: 0.745661]\n",
      "epoch:18 step:14677 [D loss: 0.642519, acc.: 61.72%] [G loss: 0.723186]\n",
      "epoch:18 step:14678 [D loss: 0.667117, acc.: 54.69%] [G loss: 0.749212]\n",
      "epoch:18 step:14679 [D loss: 0.714957, acc.: 51.56%] [G loss: 0.755993]\n",
      "epoch:18 step:14680 [D loss: 0.645304, acc.: 64.84%] [G loss: 0.783768]\n",
      "epoch:18 step:14681 [D loss: 0.671513, acc.: 57.81%] [G loss: 0.746413]\n",
      "epoch:18 step:14682 [D loss: 0.681254, acc.: 55.47%] [G loss: 0.742040]\n",
      "epoch:18 step:14683 [D loss: 0.666749, acc.: 60.94%] [G loss: 0.759506]\n",
      "epoch:18 step:14684 [D loss: 0.674137, acc.: 56.25%] [G loss: 0.751242]\n",
      "epoch:18 step:14685 [D loss: 0.719250, acc.: 46.09%] [G loss: 0.660701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14686 [D loss: 0.734835, acc.: 44.53%] [G loss: 0.705700]\n",
      "epoch:18 step:14687 [D loss: 0.676021, acc.: 57.81%] [G loss: 0.730325]\n",
      "epoch:18 step:14688 [D loss: 0.607590, acc.: 68.75%] [G loss: 0.755937]\n",
      "epoch:18 step:14689 [D loss: 0.743074, acc.: 37.50%] [G loss: 0.715868]\n",
      "epoch:18 step:14690 [D loss: 0.621383, acc.: 75.78%] [G loss: 0.685934]\n",
      "epoch:18 step:14691 [D loss: 0.792130, acc.: 28.91%] [G loss: 0.701295]\n",
      "epoch:18 step:14692 [D loss: 0.741267, acc.: 42.97%] [G loss: 0.696797]\n",
      "epoch:18 step:14693 [D loss: 0.681448, acc.: 64.84%] [G loss: 0.675646]\n",
      "epoch:18 step:14694 [D loss: 0.697822, acc.: 53.12%] [G loss: 0.743726]\n",
      "epoch:18 step:14695 [D loss: 0.707340, acc.: 49.22%] [G loss: 0.724620]\n",
      "epoch:18 step:14696 [D loss: 0.709714, acc.: 53.91%] [G loss: 0.672304]\n",
      "epoch:18 step:14697 [D loss: 0.710019, acc.: 45.31%] [G loss: 0.774146]\n",
      "epoch:18 step:14698 [D loss: 0.671638, acc.: 60.94%] [G loss: 0.722928]\n",
      "epoch:18 step:14699 [D loss: 0.721699, acc.: 44.53%] [G loss: 0.703220]\n",
      "epoch:18 step:14700 [D loss: 0.760189, acc.: 35.94%] [G loss: 0.773344]\n",
      "epoch:18 step:14701 [D loss: 0.738629, acc.: 37.50%] [G loss: 0.707143]\n",
      "epoch:18 step:14702 [D loss: 0.728677, acc.: 40.62%] [G loss: 0.708214]\n",
      "epoch:18 step:14703 [D loss: 0.724535, acc.: 40.62%] [G loss: 0.747778]\n",
      "epoch:18 step:14704 [D loss: 0.727279, acc.: 42.97%] [G loss: 0.850185]\n",
      "epoch:18 step:14705 [D loss: 0.707305, acc.: 47.66%] [G loss: 0.793060]\n",
      "epoch:18 step:14706 [D loss: 0.699999, acc.: 50.78%] [G loss: 0.786782]\n",
      "epoch:18 step:14707 [D loss: 0.670378, acc.: 59.38%] [G loss: 0.758416]\n",
      "epoch:18 step:14708 [D loss: 0.684183, acc.: 53.12%] [G loss: 0.787136]\n",
      "epoch:18 step:14709 [D loss: 0.712286, acc.: 46.88%] [G loss: 0.782328]\n",
      "epoch:18 step:14710 [D loss: 0.681095, acc.: 56.25%] [G loss: 0.759273]\n",
      "epoch:18 step:14711 [D loss: 0.706851, acc.: 53.12%] [G loss: 0.814142]\n",
      "epoch:18 step:14712 [D loss: 0.714644, acc.: 50.00%] [G loss: 0.731736]\n",
      "epoch:18 step:14713 [D loss: 0.629962, acc.: 72.66%] [G loss: 0.777263]\n",
      "epoch:18 step:14714 [D loss: 0.738038, acc.: 44.53%] [G loss: 0.738453]\n",
      "epoch:18 step:14715 [D loss: 0.655591, acc.: 62.50%] [G loss: 0.690171]\n",
      "epoch:18 step:14716 [D loss: 0.643591, acc.: 69.53%] [G loss: 0.749993]\n",
      "epoch:18 step:14717 [D loss: 0.658733, acc.: 65.62%] [G loss: 0.657205]\n",
      "epoch:18 step:14718 [D loss: 0.717180, acc.: 42.19%] [G loss: 0.740530]\n",
      "epoch:18 step:14719 [D loss: 0.659738, acc.: 60.94%] [G loss: 0.794333]\n",
      "epoch:18 step:14720 [D loss: 0.661625, acc.: 65.62%] [G loss: 0.751397]\n",
      "epoch:18 step:14721 [D loss: 0.694140, acc.: 56.25%] [G loss: 0.741030]\n",
      "epoch:18 step:14722 [D loss: 0.696490, acc.: 47.66%] [G loss: 0.796544]\n",
      "epoch:18 step:14723 [D loss: 0.664859, acc.: 63.28%] [G loss: 0.769259]\n",
      "epoch:18 step:14724 [D loss: 0.694068, acc.: 53.91%] [G loss: 0.828221]\n",
      "epoch:18 step:14725 [D loss: 0.729513, acc.: 46.09%] [G loss: 0.781089]\n",
      "epoch:18 step:14726 [D loss: 0.728492, acc.: 44.53%] [G loss: 0.728176]\n",
      "epoch:18 step:14727 [D loss: 0.675722, acc.: 57.81%] [G loss: 0.754444]\n",
      "epoch:18 step:14728 [D loss: 0.694281, acc.: 50.00%] [G loss: 0.736971]\n",
      "epoch:18 step:14729 [D loss: 0.740323, acc.: 39.06%] [G loss: 0.754806]\n",
      "epoch:18 step:14730 [D loss: 0.750996, acc.: 35.94%] [G loss: 0.765409]\n",
      "epoch:18 step:14731 [D loss: 0.599568, acc.: 80.47%] [G loss: 0.847340]\n",
      "epoch:18 step:14732 [D loss: 0.729449, acc.: 44.53%] [G loss: 0.739837]\n",
      "epoch:18 step:14733 [D loss: 0.717602, acc.: 45.31%] [G loss: 0.763479]\n",
      "epoch:18 step:14734 [D loss: 0.699484, acc.: 44.53%] [G loss: 0.731375]\n",
      "epoch:18 step:14735 [D loss: 0.661815, acc.: 57.81%] [G loss: 0.725311]\n",
      "epoch:18 step:14736 [D loss: 0.655410, acc.: 62.50%] [G loss: 0.815476]\n",
      "epoch:18 step:14737 [D loss: 0.672374, acc.: 59.38%] [G loss: 0.763877]\n",
      "epoch:18 step:14738 [D loss: 0.653230, acc.: 67.97%] [G loss: 0.798556]\n",
      "epoch:18 step:14739 [D loss: 0.645383, acc.: 67.19%] [G loss: 0.791793]\n",
      "epoch:18 step:14740 [D loss: 0.698626, acc.: 54.69%] [G loss: 0.731437]\n",
      "epoch:18 step:14741 [D loss: 0.658697, acc.: 61.72%] [G loss: 0.756513]\n",
      "epoch:18 step:14742 [D loss: 0.670164, acc.: 61.72%] [G loss: 0.798099]\n",
      "epoch:18 step:14743 [D loss: 0.723886, acc.: 42.19%] [G loss: 0.765094]\n",
      "epoch:18 step:14744 [D loss: 0.731825, acc.: 42.97%] [G loss: 0.713542]\n",
      "epoch:18 step:14745 [D loss: 0.637620, acc.: 75.00%] [G loss: 0.764597]\n",
      "epoch:18 step:14746 [D loss: 0.699442, acc.: 56.25%] [G loss: 0.749336]\n",
      "epoch:18 step:14747 [D loss: 0.724306, acc.: 43.75%] [G loss: 0.755044]\n",
      "epoch:18 step:14748 [D loss: 0.690778, acc.: 60.94%] [G loss: 0.747003]\n",
      "epoch:18 step:14749 [D loss: 0.606413, acc.: 79.69%] [G loss: 0.775068]\n",
      "epoch:18 step:14750 [D loss: 0.761741, acc.: 30.47%] [G loss: 0.757234]\n",
      "epoch:18 step:14751 [D loss: 0.722410, acc.: 44.53%] [G loss: 0.725406]\n",
      "epoch:18 step:14752 [D loss: 0.660111, acc.: 64.84%] [G loss: 0.772626]\n",
      "epoch:18 step:14753 [D loss: 0.687060, acc.: 53.12%] [G loss: 0.783248]\n",
      "epoch:18 step:14754 [D loss: 0.711096, acc.: 46.09%] [G loss: 0.738238]\n",
      "epoch:18 step:14755 [D loss: 0.753887, acc.: 42.19%] [G loss: 0.784876]\n",
      "epoch:18 step:14756 [D loss: 0.653120, acc.: 66.41%] [G loss: 0.749872]\n",
      "epoch:18 step:14757 [D loss: 0.685772, acc.: 53.12%] [G loss: 0.757455]\n",
      "epoch:18 step:14758 [D loss: 0.650055, acc.: 64.84%] [G loss: 0.742147]\n",
      "epoch:18 step:14759 [D loss: 0.727912, acc.: 42.19%] [G loss: 0.768457]\n",
      "epoch:18 step:14760 [D loss: 0.704621, acc.: 52.34%] [G loss: 0.761102]\n",
      "epoch:18 step:14761 [D loss: 0.727877, acc.: 40.62%] [G loss: 0.729245]\n",
      "epoch:18 step:14762 [D loss: 0.713890, acc.: 51.56%] [G loss: 0.766214]\n",
      "epoch:18 step:14763 [D loss: 0.708078, acc.: 45.31%] [G loss: 0.792460]\n",
      "epoch:18 step:14764 [D loss: 0.685225, acc.: 62.50%] [G loss: 0.742930]\n",
      "epoch:18 step:14765 [D loss: 0.689818, acc.: 53.12%] [G loss: 0.788947]\n",
      "epoch:18 step:14766 [D loss: 0.711275, acc.: 39.84%] [G loss: 0.749888]\n",
      "epoch:18 step:14767 [D loss: 0.689336, acc.: 54.69%] [G loss: 0.731799]\n",
      "epoch:18 step:14768 [D loss: 0.700162, acc.: 49.22%] [G loss: 0.704782]\n",
      "epoch:18 step:14769 [D loss: 0.677979, acc.: 59.38%] [G loss: 0.720761]\n",
      "epoch:18 step:14770 [D loss: 0.683982, acc.: 53.91%] [G loss: 0.795973]\n",
      "epoch:18 step:14771 [D loss: 0.709318, acc.: 47.66%] [G loss: 0.777440]\n",
      "epoch:18 step:14772 [D loss: 0.687286, acc.: 55.47%] [G loss: 0.759286]\n",
      "epoch:18 step:14773 [D loss: 0.689777, acc.: 55.47%] [G loss: 0.797294]\n",
      "epoch:18 step:14774 [D loss: 0.695420, acc.: 50.00%] [G loss: 0.742791]\n",
      "epoch:18 step:14775 [D loss: 0.704507, acc.: 53.12%] [G loss: 0.800690]\n",
      "epoch:18 step:14776 [D loss: 0.649043, acc.: 63.28%] [G loss: 0.844033]\n",
      "epoch:18 step:14777 [D loss: 0.667557, acc.: 61.72%] [G loss: 0.803487]\n",
      "epoch:18 step:14778 [D loss: 0.706898, acc.: 42.97%] [G loss: 0.792866]\n",
      "epoch:18 step:14779 [D loss: 0.708599, acc.: 50.00%] [G loss: 0.769426]\n",
      "epoch:18 step:14780 [D loss: 0.690714, acc.: 53.12%] [G loss: 0.796260]\n",
      "epoch:18 step:14781 [D loss: 0.750792, acc.: 42.19%] [G loss: 0.749518]\n",
      "epoch:18 step:14782 [D loss: 0.703541, acc.: 49.22%] [G loss: 0.717690]\n",
      "epoch:18 step:14783 [D loss: 0.683277, acc.: 60.16%] [G loss: 0.716293]\n",
      "epoch:18 step:14784 [D loss: 0.694679, acc.: 57.81%] [G loss: 0.714016]\n",
      "epoch:18 step:14785 [D loss: 0.632010, acc.: 65.62%] [G loss: 0.763069]\n",
      "epoch:18 step:14786 [D loss: 0.722245, acc.: 43.75%] [G loss: 0.759623]\n",
      "epoch:18 step:14787 [D loss: 0.692713, acc.: 56.25%] [G loss: 0.738206]\n",
      "epoch:18 step:14788 [D loss: 0.678359, acc.: 60.16%] [G loss: 0.751674]\n",
      "epoch:18 step:14789 [D loss: 0.697984, acc.: 57.03%] [G loss: 0.777965]\n",
      "epoch:18 step:14790 [D loss: 0.729050, acc.: 42.19%] [G loss: 0.726258]\n",
      "epoch:18 step:14791 [D loss: 0.671271, acc.: 65.62%] [G loss: 0.700895]\n",
      "epoch:18 step:14792 [D loss: 0.711784, acc.: 43.75%] [G loss: 0.743948]\n",
      "epoch:18 step:14793 [D loss: 0.671341, acc.: 60.16%] [G loss: 0.747024]\n",
      "epoch:18 step:14794 [D loss: 0.692211, acc.: 55.47%] [G loss: 0.673036]\n",
      "epoch:18 step:14795 [D loss: 0.743605, acc.: 37.50%] [G loss: 0.704004]\n",
      "epoch:18 step:14796 [D loss: 0.713880, acc.: 48.44%] [G loss: 0.702090]\n",
      "epoch:18 step:14797 [D loss: 0.731928, acc.: 42.19%] [G loss: 0.658137]\n",
      "epoch:18 step:14798 [D loss: 0.702974, acc.: 51.56%] [G loss: 0.697654]\n",
      "epoch:18 step:14799 [D loss: 0.691320, acc.: 54.69%] [G loss: 0.699961]\n",
      "epoch:18 step:14800 [D loss: 0.692184, acc.: 53.12%] [G loss: 0.767249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14801 [D loss: 0.687259, acc.: 56.25%] [G loss: 0.787970]\n",
      "epoch:18 step:14802 [D loss: 0.677695, acc.: 60.16%] [G loss: 0.801671]\n",
      "epoch:18 step:14803 [D loss: 0.719396, acc.: 48.44%] [G loss: 0.692768]\n",
      "epoch:18 step:14804 [D loss: 0.696204, acc.: 53.91%] [G loss: 0.805409]\n",
      "epoch:18 step:14805 [D loss: 0.731061, acc.: 46.09%] [G loss: 0.722445]\n",
      "epoch:18 step:14806 [D loss: 0.721356, acc.: 45.31%] [G loss: 0.772835]\n",
      "epoch:18 step:14807 [D loss: 0.666647, acc.: 57.81%] [G loss: 0.760295]\n",
      "epoch:18 step:14808 [D loss: 0.713392, acc.: 46.88%] [G loss: 0.746333]\n",
      "epoch:18 step:14809 [D loss: 0.711660, acc.: 42.19%] [G loss: 0.696863]\n",
      "epoch:18 step:14810 [D loss: 0.692877, acc.: 52.34%] [G loss: 0.735726]\n",
      "epoch:18 step:14811 [D loss: 0.733186, acc.: 44.53%] [G loss: 0.763023]\n",
      "epoch:18 step:14812 [D loss: 0.702411, acc.: 53.12%] [G loss: 0.733820]\n",
      "epoch:18 step:14813 [D loss: 0.716295, acc.: 45.31%] [G loss: 0.783790]\n",
      "epoch:18 step:14814 [D loss: 0.732039, acc.: 45.31%] [G loss: 0.762062]\n",
      "epoch:18 step:14815 [D loss: 0.707749, acc.: 45.31%] [G loss: 0.773798]\n",
      "epoch:18 step:14816 [D loss: 0.693315, acc.: 55.47%] [G loss: 0.750302]\n",
      "epoch:18 step:14817 [D loss: 0.717033, acc.: 48.44%] [G loss: 0.712167]\n",
      "epoch:18 step:14818 [D loss: 0.718099, acc.: 43.75%] [G loss: 0.726861]\n",
      "epoch:18 step:14819 [D loss: 0.710019, acc.: 50.00%] [G loss: 0.749801]\n",
      "epoch:18 step:14820 [D loss: 0.721862, acc.: 47.66%] [G loss: 0.771680]\n",
      "epoch:18 step:14821 [D loss: 0.709241, acc.: 51.56%] [G loss: 0.801151]\n",
      "epoch:18 step:14822 [D loss: 0.707618, acc.: 49.22%] [G loss: 0.781233]\n",
      "epoch:18 step:14823 [D loss: 0.679170, acc.: 60.16%] [G loss: 0.772076]\n",
      "epoch:18 step:14824 [D loss: 0.708335, acc.: 51.56%] [G loss: 0.713626]\n",
      "epoch:18 step:14825 [D loss: 0.640086, acc.: 71.88%] [G loss: 0.824545]\n",
      "epoch:18 step:14826 [D loss: 0.694549, acc.: 55.47%] [G loss: 0.747593]\n",
      "epoch:18 step:14827 [D loss: 0.699165, acc.: 52.34%] [G loss: 0.757945]\n",
      "epoch:18 step:14828 [D loss: 0.680866, acc.: 62.50%] [G loss: 0.750352]\n",
      "epoch:18 step:14829 [D loss: 0.711016, acc.: 46.88%] [G loss: 0.831564]\n",
      "epoch:18 step:14830 [D loss: 0.703380, acc.: 49.22%] [G loss: 0.807987]\n",
      "epoch:18 step:14831 [D loss: 0.697399, acc.: 49.22%] [G loss: 0.751671]\n",
      "epoch:18 step:14832 [D loss: 0.662364, acc.: 65.62%] [G loss: 0.769077]\n",
      "epoch:18 step:14833 [D loss: 0.692987, acc.: 56.25%] [G loss: 0.797233]\n",
      "epoch:18 step:14834 [D loss: 0.682769, acc.: 54.69%] [G loss: 0.761291]\n",
      "epoch:18 step:14835 [D loss: 0.705131, acc.: 50.00%] [G loss: 0.690402]\n",
      "epoch:18 step:14836 [D loss: 0.716838, acc.: 47.66%] [G loss: 0.737524]\n",
      "epoch:18 step:14837 [D loss: 0.737946, acc.: 42.97%] [G loss: 0.676123]\n",
      "epoch:18 step:14838 [D loss: 0.738213, acc.: 35.94%] [G loss: 0.779876]\n",
      "epoch:18 step:14839 [D loss: 0.674802, acc.: 56.25%] [G loss: 0.772731]\n",
      "epoch:19 step:14840 [D loss: 0.664099, acc.: 60.16%] [G loss: 0.782231]\n",
      "epoch:19 step:14841 [D loss: 0.725097, acc.: 42.19%] [G loss: 0.851568]\n",
      "epoch:19 step:14842 [D loss: 0.759226, acc.: 39.06%] [G loss: 0.689788]\n",
      "epoch:19 step:14843 [D loss: 0.710806, acc.: 43.75%] [G loss: 0.727217]\n",
      "epoch:19 step:14844 [D loss: 0.657346, acc.: 56.25%] [G loss: 0.797863]\n",
      "epoch:19 step:14845 [D loss: 0.680852, acc.: 56.25%] [G loss: 0.766815]\n",
      "epoch:19 step:14846 [D loss: 0.699010, acc.: 56.25%] [G loss: 0.848797]\n",
      "epoch:19 step:14847 [D loss: 0.716061, acc.: 46.88%] [G loss: 0.794841]\n",
      "epoch:19 step:14848 [D loss: 0.705598, acc.: 49.22%] [G loss: 0.816974]\n",
      "epoch:19 step:14849 [D loss: 0.672801, acc.: 57.03%] [G loss: 0.837802]\n",
      "epoch:19 step:14850 [D loss: 0.702416, acc.: 53.91%] [G loss: 0.791296]\n",
      "epoch:19 step:14851 [D loss: 0.678890, acc.: 55.47%] [G loss: 0.741753]\n",
      "epoch:19 step:14852 [D loss: 0.705875, acc.: 48.44%] [G loss: 0.827438]\n",
      "epoch:19 step:14853 [D loss: 0.695251, acc.: 53.91%] [G loss: 0.867787]\n",
      "epoch:19 step:14854 [D loss: 0.760507, acc.: 35.16%] [G loss: 0.774344]\n",
      "epoch:19 step:14855 [D loss: 0.662112, acc.: 67.97%] [G loss: 0.756079]\n",
      "epoch:19 step:14856 [D loss: 0.657038, acc.: 60.94%] [G loss: 0.798373]\n",
      "epoch:19 step:14857 [D loss: 0.661618, acc.: 60.16%] [G loss: 0.781698]\n",
      "epoch:19 step:14858 [D loss: 0.679153, acc.: 50.78%] [G loss: 0.779588]\n",
      "epoch:19 step:14859 [D loss: 0.703134, acc.: 50.78%] [G loss: 0.743437]\n",
      "epoch:19 step:14860 [D loss: 0.704480, acc.: 52.34%] [G loss: 0.782407]\n",
      "epoch:19 step:14861 [D loss: 0.702010, acc.: 52.34%] [G loss: 0.764712]\n",
      "epoch:19 step:14862 [D loss: 0.683460, acc.: 52.34%] [G loss: 0.734299]\n",
      "epoch:19 step:14863 [D loss: 0.695770, acc.: 51.56%] [G loss: 0.770756]\n",
      "epoch:19 step:14864 [D loss: 0.711359, acc.: 40.62%] [G loss: 0.739035]\n",
      "epoch:19 step:14865 [D loss: 0.728029, acc.: 42.97%] [G loss: 0.737985]\n",
      "epoch:19 step:14866 [D loss: 0.672801, acc.: 61.72%] [G loss: 0.780269]\n",
      "epoch:19 step:14867 [D loss: 0.701201, acc.: 49.22%] [G loss: 0.726880]\n",
      "epoch:19 step:14868 [D loss: 0.698786, acc.: 51.56%] [G loss: 0.748527]\n",
      "epoch:19 step:14869 [D loss: 0.680251, acc.: 61.72%] [G loss: 0.737948]\n",
      "epoch:19 step:14870 [D loss: 0.704961, acc.: 50.78%] [G loss: 0.743852]\n",
      "epoch:19 step:14871 [D loss: 0.683482, acc.: 58.59%] [G loss: 0.718662]\n",
      "epoch:19 step:14872 [D loss: 0.718639, acc.: 43.75%] [G loss: 0.671279]\n",
      "epoch:19 step:14873 [D loss: 0.700190, acc.: 48.44%] [G loss: 0.701850]\n",
      "epoch:19 step:14874 [D loss: 0.700784, acc.: 50.00%] [G loss: 0.739220]\n",
      "epoch:19 step:14875 [D loss: 0.726456, acc.: 43.75%] [G loss: 0.691560]\n",
      "epoch:19 step:14876 [D loss: 0.682709, acc.: 55.47%] [G loss: 0.731281]\n",
      "epoch:19 step:14877 [D loss: 0.714963, acc.: 48.44%] [G loss: 0.731072]\n",
      "epoch:19 step:14878 [D loss: 0.705557, acc.: 50.00%] [G loss: 0.720211]\n",
      "epoch:19 step:14879 [D loss: 0.710476, acc.: 50.00%] [G loss: 0.795245]\n",
      "epoch:19 step:14880 [D loss: 0.660584, acc.: 62.50%] [G loss: 0.817044]\n",
      "epoch:19 step:14881 [D loss: 0.668271, acc.: 58.59%] [G loss: 0.792632]\n",
      "epoch:19 step:14882 [D loss: 0.692236, acc.: 52.34%] [G loss: 0.761376]\n",
      "epoch:19 step:14883 [D loss: 0.647369, acc.: 66.41%] [G loss: 0.790240]\n",
      "epoch:19 step:14884 [D loss: 0.656527, acc.: 61.72%] [G loss: 0.722308]\n",
      "epoch:19 step:14885 [D loss: 0.634130, acc.: 75.78%] [G loss: 0.785312]\n",
      "epoch:19 step:14886 [D loss: 0.626952, acc.: 72.66%] [G loss: 0.787618]\n",
      "epoch:19 step:14887 [D loss: 0.664776, acc.: 58.59%] [G loss: 0.805272]\n",
      "epoch:19 step:14888 [D loss: 0.670420, acc.: 60.94%] [G loss: 0.766542]\n",
      "epoch:19 step:14889 [D loss: 0.723775, acc.: 50.78%] [G loss: 0.749221]\n",
      "epoch:19 step:14890 [D loss: 0.619783, acc.: 71.88%] [G loss: 0.763447]\n",
      "epoch:19 step:14891 [D loss: 0.701036, acc.: 48.44%] [G loss: 0.741053]\n",
      "epoch:19 step:14892 [D loss: 0.704273, acc.: 48.44%] [G loss: 0.742637]\n",
      "epoch:19 step:14893 [D loss: 0.692339, acc.: 53.12%] [G loss: 0.797230]\n",
      "epoch:19 step:14894 [D loss: 0.683642, acc.: 50.00%] [G loss: 0.694382]\n",
      "epoch:19 step:14895 [D loss: 0.710925, acc.: 50.00%] [G loss: 0.758470]\n",
      "epoch:19 step:14896 [D loss: 0.677523, acc.: 52.34%] [G loss: 0.766238]\n",
      "epoch:19 step:14897 [D loss: 0.708491, acc.: 46.88%] [G loss: 0.705580]\n",
      "epoch:19 step:14898 [D loss: 0.705423, acc.: 51.56%] [G loss: 0.730091]\n",
      "epoch:19 step:14899 [D loss: 0.683658, acc.: 57.03%] [G loss: 0.788269]\n",
      "epoch:19 step:14900 [D loss: 0.699657, acc.: 47.66%] [G loss: 0.834552]\n",
      "epoch:19 step:14901 [D loss: 0.698472, acc.: 46.88%] [G loss: 0.861921]\n",
      "epoch:19 step:14902 [D loss: 0.687692, acc.: 57.03%] [G loss: 0.780053]\n",
      "epoch:19 step:14903 [D loss: 0.696876, acc.: 50.00%] [G loss: 0.785046]\n",
      "epoch:19 step:14904 [D loss: 0.675668, acc.: 56.25%] [G loss: 0.820574]\n",
      "epoch:19 step:14905 [D loss: 0.718146, acc.: 50.78%] [G loss: 0.879097]\n",
      "epoch:19 step:14906 [D loss: 0.664940, acc.: 61.72%] [G loss: 0.754106]\n",
      "epoch:19 step:14907 [D loss: 0.670652, acc.: 57.81%] [G loss: 0.761863]\n",
      "epoch:19 step:14908 [D loss: 0.718940, acc.: 43.75%] [G loss: 0.789608]\n",
      "epoch:19 step:14909 [D loss: 0.747788, acc.: 41.41%] [G loss: 0.674860]\n",
      "epoch:19 step:14910 [D loss: 0.696081, acc.: 56.25%] [G loss: 0.702589]\n",
      "epoch:19 step:14911 [D loss: 0.689213, acc.: 51.56%] [G loss: 0.700046]\n",
      "epoch:19 step:14912 [D loss: 0.709872, acc.: 54.69%] [G loss: 0.715716]\n",
      "epoch:19 step:14913 [D loss: 0.634935, acc.: 78.91%] [G loss: 0.740698]\n",
      "epoch:19 step:14914 [D loss: 0.660148, acc.: 54.69%] [G loss: 0.765927]\n",
      "epoch:19 step:14915 [D loss: 0.701836, acc.: 60.94%] [G loss: 0.744056]\n",
      "epoch:19 step:14916 [D loss: 0.674101, acc.: 57.81%] [G loss: 0.722573]\n",
      "epoch:19 step:14917 [D loss: 0.679496, acc.: 58.59%] [G loss: 0.761169]\n",
      "epoch:19 step:14918 [D loss: 0.712523, acc.: 50.78%] [G loss: 0.680024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:14919 [D loss: 0.626463, acc.: 70.31%] [G loss: 0.798048]\n",
      "epoch:19 step:14920 [D loss: 0.724898, acc.: 42.19%] [G loss: 0.687330]\n",
      "epoch:19 step:14921 [D loss: 0.671288, acc.: 57.03%] [G loss: 0.746872]\n",
      "epoch:19 step:14922 [D loss: 0.746421, acc.: 36.72%] [G loss: 0.758191]\n",
      "epoch:19 step:14923 [D loss: 0.761114, acc.: 32.81%] [G loss: 0.764047]\n",
      "epoch:19 step:14924 [D loss: 0.643347, acc.: 67.19%] [G loss: 0.834252]\n",
      "epoch:19 step:14925 [D loss: 0.650631, acc.: 68.75%] [G loss: 0.813646]\n",
      "epoch:19 step:14926 [D loss: 0.734472, acc.: 43.75%] [G loss: 0.685152]\n",
      "epoch:19 step:14927 [D loss: 0.727775, acc.: 42.19%] [G loss: 0.785182]\n",
      "epoch:19 step:14928 [D loss: 0.726385, acc.: 43.75%] [G loss: 0.698730]\n",
      "epoch:19 step:14929 [D loss: 0.701126, acc.: 52.34%] [G loss: 0.823505]\n",
      "epoch:19 step:14930 [D loss: 0.709048, acc.: 49.22%] [G loss: 0.747559]\n",
      "epoch:19 step:14931 [D loss: 0.708153, acc.: 51.56%] [G loss: 0.686271]\n",
      "epoch:19 step:14932 [D loss: 0.692348, acc.: 53.91%] [G loss: 0.718823]\n",
      "epoch:19 step:14933 [D loss: 0.683498, acc.: 50.00%] [G loss: 0.757047]\n",
      "epoch:19 step:14934 [D loss: 0.706815, acc.: 48.44%] [G loss: 0.818716]\n",
      "epoch:19 step:14935 [D loss: 0.638703, acc.: 67.97%] [G loss: 0.750890]\n",
      "epoch:19 step:14936 [D loss: 0.693461, acc.: 52.34%] [G loss: 0.792597]\n",
      "epoch:19 step:14937 [D loss: 0.693050, acc.: 52.34%] [G loss: 0.802694]\n",
      "epoch:19 step:14938 [D loss: 0.630821, acc.: 72.66%] [G loss: 0.825493]\n",
      "epoch:19 step:14939 [D loss: 0.687217, acc.: 53.91%] [G loss: 0.819985]\n",
      "epoch:19 step:14940 [D loss: 0.710643, acc.: 46.88%] [G loss: 0.737186]\n",
      "epoch:19 step:14941 [D loss: 0.677643, acc.: 53.91%] [G loss: 0.763805]\n",
      "epoch:19 step:14942 [D loss: 0.710293, acc.: 46.88%] [G loss: 0.739490]\n",
      "epoch:19 step:14943 [D loss: 0.723543, acc.: 40.62%] [G loss: 0.727710]\n",
      "epoch:19 step:14944 [D loss: 0.709929, acc.: 49.22%] [G loss: 0.746388]\n",
      "epoch:19 step:14945 [D loss: 0.668305, acc.: 61.72%] [G loss: 0.790723]\n",
      "epoch:19 step:14946 [D loss: 0.719324, acc.: 45.31%] [G loss: 0.731204]\n",
      "epoch:19 step:14947 [D loss: 0.756011, acc.: 38.28%] [G loss: 0.700816]\n",
      "epoch:19 step:14948 [D loss: 0.697107, acc.: 50.78%] [G loss: 0.663270]\n",
      "epoch:19 step:14949 [D loss: 0.716379, acc.: 46.88%] [G loss: 0.700974]\n",
      "epoch:19 step:14950 [D loss: 0.654926, acc.: 63.28%] [G loss: 0.734873]\n",
      "epoch:19 step:14951 [D loss: 0.678104, acc.: 61.72%] [G loss: 0.752596]\n",
      "epoch:19 step:14952 [D loss: 0.689090, acc.: 50.00%] [G loss: 0.804988]\n",
      "epoch:19 step:14953 [D loss: 0.666093, acc.: 63.28%] [G loss: 0.733071]\n",
      "epoch:19 step:14954 [D loss: 0.655683, acc.: 62.50%] [G loss: 0.856739]\n",
      "epoch:19 step:14955 [D loss: 0.753237, acc.: 43.75%] [G loss: 0.748024]\n",
      "epoch:19 step:14956 [D loss: 0.676485, acc.: 56.25%] [G loss: 0.751694]\n",
      "epoch:19 step:14957 [D loss: 0.695923, acc.: 49.22%] [G loss: 0.773626]\n",
      "epoch:19 step:14958 [D loss: 0.683148, acc.: 60.94%] [G loss: 0.670324]\n",
      "epoch:19 step:14959 [D loss: 0.697101, acc.: 50.78%] [G loss: 0.773511]\n",
      "epoch:19 step:14960 [D loss: 0.711506, acc.: 49.22%] [G loss: 0.730555]\n",
      "epoch:19 step:14961 [D loss: 0.707780, acc.: 47.66%] [G loss: 0.804033]\n",
      "epoch:19 step:14962 [D loss: 0.717072, acc.: 48.44%] [G loss: 0.714007]\n",
      "epoch:19 step:14963 [D loss: 0.713816, acc.: 44.53%] [G loss: 0.745093]\n",
      "epoch:19 step:14964 [D loss: 0.754180, acc.: 34.38%] [G loss: 0.723183]\n",
      "epoch:19 step:14965 [D loss: 0.714481, acc.: 46.88%] [G loss: 0.695263]\n",
      "epoch:19 step:14966 [D loss: 0.705937, acc.: 51.56%] [G loss: 0.688697]\n",
      "epoch:19 step:14967 [D loss: 0.651394, acc.: 68.75%] [G loss: 0.739042]\n",
      "epoch:19 step:14968 [D loss: 0.687836, acc.: 57.81%] [G loss: 0.800966]\n",
      "epoch:19 step:14969 [D loss: 0.671350, acc.: 61.72%] [G loss: 0.796708]\n",
      "epoch:19 step:14970 [D loss: 0.702253, acc.: 51.56%] [G loss: 0.750237]\n",
      "epoch:19 step:14971 [D loss: 0.693570, acc.: 55.47%] [G loss: 0.725030]\n",
      "epoch:19 step:14972 [D loss: 0.652127, acc.: 61.72%] [G loss: 0.778024]\n",
      "epoch:19 step:14973 [D loss: 0.715919, acc.: 46.88%] [G loss: 0.794711]\n",
      "epoch:19 step:14974 [D loss: 0.768625, acc.: 39.06%] [G loss: 0.755633]\n",
      "epoch:19 step:14975 [D loss: 0.677374, acc.: 58.59%] [G loss: 0.772449]\n",
      "epoch:19 step:14976 [D loss: 0.737887, acc.: 43.75%] [G loss: 0.739527]\n",
      "epoch:19 step:14977 [D loss: 0.709756, acc.: 45.31%] [G loss: 0.716608]\n",
      "epoch:19 step:14978 [D loss: 0.655212, acc.: 56.25%] [G loss: 0.788523]\n",
      "epoch:19 step:14979 [D loss: 0.673877, acc.: 53.91%] [G loss: 0.832383]\n",
      "epoch:19 step:14980 [D loss: 0.715618, acc.: 43.75%] [G loss: 0.759740]\n",
      "epoch:19 step:14981 [D loss: 0.681493, acc.: 53.12%] [G loss: 0.797996]\n",
      "epoch:19 step:14982 [D loss: 0.727289, acc.: 49.22%] [G loss: 0.734136]\n",
      "epoch:19 step:14983 [D loss: 0.703100, acc.: 54.69%] [G loss: 0.694450]\n",
      "epoch:19 step:14984 [D loss: 0.694528, acc.: 56.25%] [G loss: 0.721579]\n",
      "epoch:19 step:14985 [D loss: 0.671724, acc.: 60.94%] [G loss: 0.751028]\n",
      "epoch:19 step:14986 [D loss: 0.701741, acc.: 49.22%] [G loss: 0.717244]\n",
      "epoch:19 step:14987 [D loss: 0.711668, acc.: 50.00%] [G loss: 0.723530]\n",
      "epoch:19 step:14988 [D loss: 0.730048, acc.: 50.00%] [G loss: 0.698169]\n",
      "epoch:19 step:14989 [D loss: 0.747535, acc.: 39.06%] [G loss: 0.734006]\n",
      "epoch:19 step:14990 [D loss: 0.748047, acc.: 39.06%] [G loss: 0.758970]\n",
      "epoch:19 step:14991 [D loss: 0.649302, acc.: 64.06%] [G loss: 0.827966]\n",
      "epoch:19 step:14992 [D loss: 0.717475, acc.: 44.53%] [G loss: 0.759409]\n",
      "epoch:19 step:14993 [D loss: 0.703005, acc.: 53.91%] [G loss: 0.752782]\n",
      "epoch:19 step:14994 [D loss: 0.691448, acc.: 52.34%] [G loss: 0.772635]\n",
      "epoch:19 step:14995 [D loss: 0.754534, acc.: 35.16%] [G loss: 0.766689]\n",
      "epoch:19 step:14996 [D loss: 0.700183, acc.: 50.00%] [G loss: 0.759598]\n",
      "epoch:19 step:14997 [D loss: 0.681177, acc.: 57.81%] [G loss: 0.783203]\n",
      "epoch:19 step:14998 [D loss: 0.652389, acc.: 65.62%] [G loss: 0.780701]\n",
      "epoch:19 step:14999 [D loss: 0.648029, acc.: 64.84%] [G loss: 0.802221]\n",
      "epoch:19 step:15000 [D loss: 0.673678, acc.: 58.59%] [G loss: 0.813022]\n",
      "epoch:19 step:15001 [D loss: 0.699314, acc.: 50.78%] [G loss: 0.833625]\n",
      "epoch:19 step:15002 [D loss: 0.695142, acc.: 48.44%] [G loss: 0.816505]\n",
      "epoch:19 step:15003 [D loss: 0.713227, acc.: 49.22%] [G loss: 0.856385]\n",
      "epoch:19 step:15004 [D loss: 0.672427, acc.: 60.94%] [G loss: 0.890969]\n",
      "epoch:19 step:15005 [D loss: 0.695994, acc.: 50.00%] [G loss: 0.782132]\n",
      "epoch:19 step:15006 [D loss: 0.701370, acc.: 49.22%] [G loss: 0.782637]\n",
      "epoch:19 step:15007 [D loss: 0.643005, acc.: 65.62%] [G loss: 0.709988]\n",
      "epoch:19 step:15008 [D loss: 0.698689, acc.: 50.78%] [G loss: 0.781656]\n",
      "epoch:19 step:15009 [D loss: 0.682405, acc.: 55.47%] [G loss: 0.837566]\n",
      "epoch:19 step:15010 [D loss: 0.704456, acc.: 50.00%] [G loss: 0.784536]\n",
      "epoch:19 step:15011 [D loss: 0.700255, acc.: 53.12%] [G loss: 0.693500]\n",
      "epoch:19 step:15012 [D loss: 0.737010, acc.: 42.19%] [G loss: 0.768054]\n",
      "epoch:19 step:15013 [D loss: 0.681689, acc.: 49.22%] [G loss: 0.825985]\n",
      "epoch:19 step:15014 [D loss: 0.695193, acc.: 46.09%] [G loss: 0.695725]\n",
      "epoch:19 step:15015 [D loss: 0.708768, acc.: 46.88%] [G loss: 0.773923]\n",
      "epoch:19 step:15016 [D loss: 0.689085, acc.: 52.34%] [G loss: 0.756998]\n",
      "epoch:19 step:15017 [D loss: 0.706513, acc.: 52.34%] [G loss: 0.719415]\n",
      "epoch:19 step:15018 [D loss: 0.663494, acc.: 55.47%] [G loss: 0.769012]\n",
      "epoch:19 step:15019 [D loss: 0.682578, acc.: 57.81%] [G loss: 0.689365]\n",
      "epoch:19 step:15020 [D loss: 0.680243, acc.: 52.34%] [G loss: 0.767579]\n",
      "epoch:19 step:15021 [D loss: 0.770832, acc.: 32.81%] [G loss: 0.764708]\n",
      "epoch:19 step:15022 [D loss: 0.677163, acc.: 53.12%] [G loss: 0.775912]\n",
      "epoch:19 step:15023 [D loss: 0.688198, acc.: 53.12%] [G loss: 0.803074]\n",
      "epoch:19 step:15024 [D loss: 0.660338, acc.: 65.62%] [G loss: 0.795608]\n",
      "epoch:19 step:15025 [D loss: 0.681754, acc.: 59.38%] [G loss: 0.780500]\n",
      "epoch:19 step:15026 [D loss: 0.702114, acc.: 44.53%] [G loss: 0.751287]\n",
      "epoch:19 step:15027 [D loss: 0.729849, acc.: 47.66%] [G loss: 0.771448]\n",
      "epoch:19 step:15028 [D loss: 0.636380, acc.: 66.41%] [G loss: 0.775043]\n",
      "epoch:19 step:15029 [D loss: 0.697928, acc.: 48.44%] [G loss: 0.772614]\n",
      "epoch:19 step:15030 [D loss: 0.694627, acc.: 50.78%] [G loss: 0.786357]\n",
      "epoch:19 step:15031 [D loss: 0.677888, acc.: 55.47%] [G loss: 0.795087]\n",
      "epoch:19 step:15032 [D loss: 0.684658, acc.: 56.25%] [G loss: 0.709181]\n",
      "epoch:19 step:15033 [D loss: 0.698955, acc.: 49.22%] [G loss: 0.725539]\n",
      "epoch:19 step:15034 [D loss: 0.701259, acc.: 51.56%] [G loss: 0.750185]\n",
      "epoch:19 step:15035 [D loss: 0.654134, acc.: 67.19%] [G loss: 0.748461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15036 [D loss: 0.715208, acc.: 45.31%] [G loss: 0.656754]\n",
      "epoch:19 step:15037 [D loss: 0.679357, acc.: 53.12%] [G loss: 0.689210]\n",
      "epoch:19 step:15038 [D loss: 0.694915, acc.: 57.81%] [G loss: 0.739526]\n",
      "epoch:19 step:15039 [D loss: 0.685003, acc.: 52.34%] [G loss: 0.747564]\n",
      "epoch:19 step:15040 [D loss: 0.698177, acc.: 50.78%] [G loss: 0.782914]\n",
      "epoch:19 step:15041 [D loss: 0.736173, acc.: 39.84%] [G loss: 0.767221]\n",
      "epoch:19 step:15042 [D loss: 0.695245, acc.: 54.69%] [G loss: 0.692520]\n",
      "epoch:19 step:15043 [D loss: 0.738883, acc.: 37.50%] [G loss: 0.747505]\n",
      "epoch:19 step:15044 [D loss: 0.732133, acc.: 43.75%] [G loss: 0.790499]\n",
      "epoch:19 step:15045 [D loss: 0.761847, acc.: 39.06%] [G loss: 0.786944]\n",
      "epoch:19 step:15046 [D loss: 0.648581, acc.: 65.62%] [G loss: 0.815427]\n",
      "epoch:19 step:15047 [D loss: 0.647883, acc.: 69.53%] [G loss: 0.775180]\n",
      "epoch:19 step:15048 [D loss: 0.706281, acc.: 45.31%] [G loss: 0.781930]\n",
      "epoch:19 step:15049 [D loss: 0.686812, acc.: 56.25%] [G loss: 0.757957]\n",
      "epoch:19 step:15050 [D loss: 0.674766, acc.: 64.84%] [G loss: 0.782108]\n",
      "epoch:19 step:15051 [D loss: 0.689167, acc.: 52.34%] [G loss: 0.785863]\n",
      "epoch:19 step:15052 [D loss: 0.776906, acc.: 24.22%] [G loss: 0.704781]\n",
      "epoch:19 step:15053 [D loss: 0.678947, acc.: 56.25%] [G loss: 0.770841]\n",
      "epoch:19 step:15054 [D loss: 0.714229, acc.: 46.88%] [G loss: 0.768730]\n",
      "epoch:19 step:15055 [D loss: 0.725234, acc.: 46.09%] [G loss: 0.678380]\n",
      "epoch:19 step:15056 [D loss: 0.723339, acc.: 41.41%] [G loss: 0.723020]\n",
      "epoch:19 step:15057 [D loss: 0.692579, acc.: 53.12%] [G loss: 0.755584]\n",
      "epoch:19 step:15058 [D loss: 0.676595, acc.: 59.38%] [G loss: 0.752237]\n",
      "epoch:19 step:15059 [D loss: 0.703389, acc.: 53.91%] [G loss: 0.800470]\n",
      "epoch:19 step:15060 [D loss: 0.739125, acc.: 48.44%] [G loss: 0.802379]\n",
      "epoch:19 step:15061 [D loss: 0.650148, acc.: 67.19%] [G loss: 0.788783]\n",
      "epoch:19 step:15062 [D loss: 0.694909, acc.: 47.66%] [G loss: 0.754945]\n",
      "epoch:19 step:15063 [D loss: 0.693553, acc.: 53.12%] [G loss: 0.710962]\n",
      "epoch:19 step:15064 [D loss: 0.720897, acc.: 49.22%] [G loss: 0.773503]\n",
      "epoch:19 step:15065 [D loss: 0.689131, acc.: 54.69%] [G loss: 0.776728]\n",
      "epoch:19 step:15066 [D loss: 0.687235, acc.: 53.12%] [G loss: 0.760038]\n",
      "epoch:19 step:15067 [D loss: 0.669564, acc.: 61.72%] [G loss: 0.786516]\n",
      "epoch:19 step:15068 [D loss: 0.685708, acc.: 52.34%] [G loss: 0.676878]\n",
      "epoch:19 step:15069 [D loss: 0.702929, acc.: 56.25%] [G loss: 0.779069]\n",
      "epoch:19 step:15070 [D loss: 0.682308, acc.: 59.38%] [G loss: 0.704597]\n",
      "epoch:19 step:15071 [D loss: 0.739141, acc.: 41.41%] [G loss: 0.750357]\n",
      "epoch:19 step:15072 [D loss: 0.692476, acc.: 53.12%] [G loss: 0.693007]\n",
      "epoch:19 step:15073 [D loss: 0.721239, acc.: 46.88%] [G loss: 0.702916]\n",
      "epoch:19 step:15074 [D loss: 0.738037, acc.: 47.66%] [G loss: 0.683867]\n",
      "epoch:19 step:15075 [D loss: 0.704000, acc.: 51.56%] [G loss: 0.706315]\n",
      "epoch:19 step:15076 [D loss: 0.706111, acc.: 46.88%] [G loss: 0.676428]\n",
      "epoch:19 step:15077 [D loss: 0.713830, acc.: 45.31%] [G loss: 0.766917]\n",
      "epoch:19 step:15078 [D loss: 0.676856, acc.: 56.25%] [G loss: 0.729333]\n",
      "epoch:19 step:15079 [D loss: 0.731872, acc.: 42.19%] [G loss: 0.794865]\n",
      "epoch:19 step:15080 [D loss: 0.716370, acc.: 46.88%] [G loss: 0.864555]\n",
      "epoch:19 step:15081 [D loss: 0.711399, acc.: 47.66%] [G loss: 0.777923]\n",
      "epoch:19 step:15082 [D loss: 0.685387, acc.: 55.47%] [G loss: 0.745017]\n",
      "epoch:19 step:15083 [D loss: 0.662187, acc.: 60.94%] [G loss: 0.741240]\n",
      "epoch:19 step:15084 [D loss: 0.731326, acc.: 46.88%] [G loss: 0.726661]\n",
      "epoch:19 step:15085 [D loss: 0.735413, acc.: 40.62%] [G loss: 0.747411]\n",
      "epoch:19 step:15086 [D loss: 0.709085, acc.: 46.88%] [G loss: 0.773128]\n",
      "epoch:19 step:15087 [D loss: 0.679512, acc.: 57.03%] [G loss: 0.725211]\n",
      "epoch:19 step:15088 [D loss: 0.688856, acc.: 54.69%] [G loss: 0.752930]\n",
      "epoch:19 step:15089 [D loss: 0.693276, acc.: 52.34%] [G loss: 0.763589]\n",
      "epoch:19 step:15090 [D loss: 0.637834, acc.: 71.09%] [G loss: 0.714903]\n",
      "epoch:19 step:15091 [D loss: 0.657986, acc.: 67.19%] [G loss: 0.797344]\n",
      "epoch:19 step:15092 [D loss: 0.744370, acc.: 37.50%] [G loss: 0.724850]\n",
      "epoch:19 step:15093 [D loss: 0.705477, acc.: 50.00%] [G loss: 0.724345]\n",
      "epoch:19 step:15094 [D loss: 0.722330, acc.: 44.53%] [G loss: 0.781263]\n",
      "epoch:19 step:15095 [D loss: 0.726649, acc.: 42.97%] [G loss: 0.727469]\n",
      "epoch:19 step:15096 [D loss: 0.701429, acc.: 47.66%] [G loss: 0.742560]\n",
      "epoch:19 step:15097 [D loss: 0.669785, acc.: 60.94%] [G loss: 0.791263]\n",
      "epoch:19 step:15098 [D loss: 0.647115, acc.: 61.72%] [G loss: 0.761733]\n",
      "epoch:19 step:15099 [D loss: 0.683184, acc.: 58.59%] [G loss: 0.829949]\n",
      "epoch:19 step:15100 [D loss: 0.649729, acc.: 60.94%] [G loss: 0.763876]\n",
      "epoch:19 step:15101 [D loss: 0.681829, acc.: 55.47%] [G loss: 0.733645]\n",
      "epoch:19 step:15102 [D loss: 0.696997, acc.: 51.56%] [G loss: 0.751832]\n",
      "epoch:19 step:15103 [D loss: 0.759727, acc.: 35.94%] [G loss: 0.813804]\n",
      "epoch:19 step:15104 [D loss: 0.673557, acc.: 60.16%] [G loss: 0.741904]\n",
      "epoch:19 step:15105 [D loss: 0.700319, acc.: 52.34%] [G loss: 0.740325]\n",
      "epoch:19 step:15106 [D loss: 0.753441, acc.: 35.16%] [G loss: 0.685973]\n",
      "epoch:19 step:15107 [D loss: 0.716252, acc.: 42.97%] [G loss: 0.696878]\n",
      "epoch:19 step:15108 [D loss: 0.693944, acc.: 55.47%] [G loss: 0.769609]\n",
      "epoch:19 step:15109 [D loss: 0.678707, acc.: 61.72%] [G loss: 0.727642]\n",
      "epoch:19 step:15110 [D loss: 0.700848, acc.: 50.00%] [G loss: 0.759857]\n",
      "epoch:19 step:15111 [D loss: 0.690615, acc.: 53.12%] [G loss: 0.739024]\n",
      "epoch:19 step:15112 [D loss: 0.674864, acc.: 56.25%] [G loss: 0.790739]\n",
      "epoch:19 step:15113 [D loss: 0.700490, acc.: 50.78%] [G loss: 0.775466]\n",
      "epoch:19 step:15114 [D loss: 0.722275, acc.: 42.97%] [G loss: 0.802999]\n",
      "epoch:19 step:15115 [D loss: 0.710230, acc.: 47.66%] [G loss: 0.761296]\n",
      "epoch:19 step:15116 [D loss: 0.736364, acc.: 39.06%] [G loss: 0.797601]\n",
      "epoch:19 step:15117 [D loss: 0.719766, acc.: 44.53%] [G loss: 0.759359]\n",
      "epoch:19 step:15118 [D loss: 0.660263, acc.: 60.94%] [G loss: 0.747643]\n",
      "epoch:19 step:15119 [D loss: 0.714848, acc.: 45.31%] [G loss: 0.764409]\n",
      "epoch:19 step:15120 [D loss: 0.678695, acc.: 53.91%] [G loss: 0.931869]\n",
      "epoch:19 step:15121 [D loss: 0.674255, acc.: 53.91%] [G loss: 0.824373]\n",
      "epoch:19 step:15122 [D loss: 0.672615, acc.: 59.38%] [G loss: 0.770149]\n",
      "epoch:19 step:15123 [D loss: 0.623189, acc.: 68.75%] [G loss: 0.809423]\n",
      "epoch:19 step:15124 [D loss: 0.617401, acc.: 71.09%] [G loss: 0.820123]\n",
      "epoch:19 step:15125 [D loss: 0.725331, acc.: 48.44%] [G loss: 0.727307]\n",
      "epoch:19 step:15126 [D loss: 0.703223, acc.: 51.56%] [G loss: 0.721150]\n",
      "epoch:19 step:15127 [D loss: 0.686929, acc.: 57.03%] [G loss: 0.685939]\n",
      "epoch:19 step:15128 [D loss: 0.691011, acc.: 57.03%] [G loss: 0.744779]\n",
      "epoch:19 step:15129 [D loss: 0.634929, acc.: 71.09%] [G loss: 0.647875]\n",
      "epoch:19 step:15130 [D loss: 0.696198, acc.: 48.44%] [G loss: 0.729797]\n",
      "epoch:19 step:15131 [D loss: 0.717267, acc.: 49.22%] [G loss: 0.695782]\n",
      "epoch:19 step:15132 [D loss: 0.660546, acc.: 61.72%] [G loss: 0.726125]\n",
      "epoch:19 step:15133 [D loss: 0.708847, acc.: 51.56%] [G loss: 0.723011]\n",
      "epoch:19 step:15134 [D loss: 0.749769, acc.: 38.28%] [G loss: 0.710065]\n",
      "epoch:19 step:15135 [D loss: 0.758914, acc.: 35.94%] [G loss: 0.742270]\n",
      "epoch:19 step:15136 [D loss: 0.704034, acc.: 51.56%] [G loss: 0.749951]\n",
      "epoch:19 step:15137 [D loss: 0.751078, acc.: 35.16%] [G loss: 0.720506]\n",
      "epoch:19 step:15138 [D loss: 0.681027, acc.: 54.69%] [G loss: 0.769473]\n",
      "epoch:19 step:15139 [D loss: 0.725499, acc.: 48.44%] [G loss: 0.796921]\n",
      "epoch:19 step:15140 [D loss: 0.704868, acc.: 47.66%] [G loss: 0.707351]\n",
      "epoch:19 step:15141 [D loss: 0.735873, acc.: 45.31%] [G loss: 0.760477]\n",
      "epoch:19 step:15142 [D loss: 0.661170, acc.: 64.84%] [G loss: 0.747172]\n",
      "epoch:19 step:15143 [D loss: 0.707626, acc.: 54.69%] [G loss: 0.775457]\n",
      "epoch:19 step:15144 [D loss: 0.677634, acc.: 59.38%] [G loss: 0.798120]\n",
      "epoch:19 step:15145 [D loss: 0.663990, acc.: 64.84%] [G loss: 0.860218]\n",
      "epoch:19 step:15146 [D loss: 0.703681, acc.: 55.47%] [G loss: 0.758692]\n",
      "epoch:19 step:15147 [D loss: 0.694449, acc.: 50.00%] [G loss: 0.807476]\n",
      "epoch:19 step:15148 [D loss: 0.699622, acc.: 50.78%] [G loss: 0.780488]\n",
      "epoch:19 step:15149 [D loss: 0.726931, acc.: 39.84%] [G loss: 0.753540]\n",
      "epoch:19 step:15150 [D loss: 0.717805, acc.: 46.09%] [G loss: 0.822608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15151 [D loss: 0.715680, acc.: 44.53%] [G loss: 0.722530]\n",
      "epoch:19 step:15152 [D loss: 0.689237, acc.: 58.59%] [G loss: 0.765539]\n",
      "epoch:19 step:15153 [D loss: 0.684429, acc.: 47.66%] [G loss: 0.736227]\n",
      "epoch:19 step:15154 [D loss: 0.712379, acc.: 46.88%] [G loss: 0.724677]\n",
      "epoch:19 step:15155 [D loss: 0.687975, acc.: 55.47%] [G loss: 0.686056]\n",
      "epoch:19 step:15156 [D loss: 0.734901, acc.: 41.41%] [G loss: 0.736114]\n",
      "epoch:19 step:15157 [D loss: 0.652136, acc.: 67.19%] [G loss: 0.670486]\n",
      "epoch:19 step:15158 [D loss: 0.753212, acc.: 35.94%] [G loss: 0.708228]\n",
      "epoch:19 step:15159 [D loss: 0.722579, acc.: 50.78%] [G loss: 0.663653]\n",
      "epoch:19 step:15160 [D loss: 0.730173, acc.: 43.75%] [G loss: 0.707399]\n",
      "epoch:19 step:15161 [D loss: 0.745118, acc.: 38.28%] [G loss: 0.662149]\n",
      "epoch:19 step:15162 [D loss: 0.732528, acc.: 36.72%] [G loss: 0.717096]\n",
      "epoch:19 step:15163 [D loss: 0.709915, acc.: 46.88%] [G loss: 0.717564]\n",
      "epoch:19 step:15164 [D loss: 0.714878, acc.: 45.31%] [G loss: 0.719845]\n",
      "epoch:19 step:15165 [D loss: 0.726233, acc.: 42.19%] [G loss: 0.769422]\n",
      "epoch:19 step:15166 [D loss: 0.698320, acc.: 53.12%] [G loss: 0.745395]\n",
      "epoch:19 step:15167 [D loss: 0.685506, acc.: 53.12%] [G loss: 0.716200]\n",
      "epoch:19 step:15168 [D loss: 0.800984, acc.: 26.56%] [G loss: 0.734422]\n",
      "epoch:19 step:15169 [D loss: 0.700353, acc.: 49.22%] [G loss: 0.782799]\n",
      "epoch:19 step:15170 [D loss: 0.717800, acc.: 47.66%] [G loss: 0.784151]\n",
      "epoch:19 step:15171 [D loss: 0.710988, acc.: 47.66%] [G loss: 0.784705]\n",
      "epoch:19 step:15172 [D loss: 0.679358, acc.: 62.50%] [G loss: 0.751180]\n",
      "epoch:19 step:15173 [D loss: 0.674850, acc.: 56.25%] [G loss: 0.832606]\n",
      "epoch:19 step:15174 [D loss: 0.692877, acc.: 50.00%] [G loss: 0.740987]\n",
      "epoch:19 step:15175 [D loss: 0.673216, acc.: 57.81%] [G loss: 0.847566]\n",
      "epoch:19 step:15176 [D loss: 0.695115, acc.: 54.69%] [G loss: 0.774987]\n",
      "epoch:19 step:15177 [D loss: 0.703401, acc.: 49.22%] [G loss: 0.761143]\n",
      "epoch:19 step:15178 [D loss: 0.649515, acc.: 70.31%] [G loss: 0.788701]\n",
      "epoch:19 step:15179 [D loss: 0.671224, acc.: 55.47%] [G loss: 0.741010]\n",
      "epoch:19 step:15180 [D loss: 0.637858, acc.: 71.88%] [G loss: 0.790887]\n",
      "epoch:19 step:15181 [D loss: 0.698522, acc.: 53.12%] [G loss: 0.804690]\n",
      "epoch:19 step:15182 [D loss: 0.649485, acc.: 65.62%] [G loss: 0.744815]\n",
      "epoch:19 step:15183 [D loss: 0.687311, acc.: 54.69%] [G loss: 0.725790]\n",
      "epoch:19 step:15184 [D loss: 0.640536, acc.: 67.97%] [G loss: 0.775495]\n",
      "epoch:19 step:15185 [D loss: 0.689045, acc.: 55.47%] [G loss: 0.733274]\n",
      "epoch:19 step:15186 [D loss: 0.669790, acc.: 57.03%] [G loss: 0.768426]\n",
      "epoch:19 step:15187 [D loss: 0.706542, acc.: 46.09%] [G loss: 0.767762]\n",
      "epoch:19 step:15188 [D loss: 0.691825, acc.: 58.59%] [G loss: 0.774489]\n",
      "epoch:19 step:15189 [D loss: 0.757503, acc.: 37.50%] [G loss: 0.718119]\n",
      "epoch:19 step:15190 [D loss: 0.734953, acc.: 41.41%] [G loss: 0.806190]\n",
      "epoch:19 step:15191 [D loss: 0.670071, acc.: 60.94%] [G loss: 0.816473]\n",
      "epoch:19 step:15192 [D loss: 0.682814, acc.: 53.91%] [G loss: 0.771675]\n",
      "epoch:19 step:15193 [D loss: 0.736852, acc.: 50.78%] [G loss: 0.728857]\n",
      "epoch:19 step:15194 [D loss: 0.730325, acc.: 42.19%] [G loss: 0.760685]\n",
      "epoch:19 step:15195 [D loss: 0.714445, acc.: 41.41%] [G loss: 0.768444]\n",
      "epoch:19 step:15196 [D loss: 0.695366, acc.: 53.91%] [G loss: 0.777207]\n",
      "epoch:19 step:15197 [D loss: 0.696337, acc.: 53.12%] [G loss: 0.843713]\n",
      "epoch:19 step:15198 [D loss: 0.670337, acc.: 57.03%] [G loss: 0.768288]\n",
      "epoch:19 step:15199 [D loss: 0.736481, acc.: 39.84%] [G loss: 0.752493]\n",
      "epoch:19 step:15200 [D loss: 0.702177, acc.: 50.00%] [G loss: 0.798004]\n",
      "epoch:19 step:15201 [D loss: 0.721496, acc.: 49.22%] [G loss: 0.782943]\n",
      "epoch:19 step:15202 [D loss: 0.673869, acc.: 56.25%] [G loss: 0.771932]\n",
      "epoch:19 step:15203 [D loss: 0.682224, acc.: 57.03%] [G loss: 0.718088]\n",
      "epoch:19 step:15204 [D loss: 0.725350, acc.: 45.31%] [G loss: 0.710457]\n",
      "epoch:19 step:15205 [D loss: 0.731703, acc.: 42.97%] [G loss: 0.717322]\n",
      "epoch:19 step:15206 [D loss: 0.683084, acc.: 55.47%] [G loss: 0.778661]\n",
      "epoch:19 step:15207 [D loss: 0.656377, acc.: 61.72%] [G loss: 0.761749]\n",
      "epoch:19 step:15208 [D loss: 0.680933, acc.: 51.56%] [G loss: 0.795230]\n",
      "epoch:19 step:15209 [D loss: 0.684791, acc.: 57.03%] [G loss: 0.786636]\n",
      "epoch:19 step:15210 [D loss: 0.662620, acc.: 64.84%] [G loss: 0.763795]\n",
      "epoch:19 step:15211 [D loss: 0.644235, acc.: 70.31%] [G loss: 0.798652]\n",
      "epoch:19 step:15212 [D loss: 0.668990, acc.: 53.91%] [G loss: 0.811732]\n",
      "epoch:19 step:15213 [D loss: 0.716369, acc.: 45.31%] [G loss: 0.765221]\n",
      "epoch:19 step:15214 [D loss: 0.701868, acc.: 46.88%] [G loss: 0.741630]\n",
      "epoch:19 step:15215 [D loss: 0.648419, acc.: 68.75%] [G loss: 0.743772]\n",
      "epoch:19 step:15216 [D loss: 0.660209, acc.: 59.38%] [G loss: 0.656630]\n",
      "epoch:19 step:15217 [D loss: 0.735601, acc.: 45.31%] [G loss: 0.712448]\n",
      "epoch:19 step:15218 [D loss: 0.673599, acc.: 64.06%] [G loss: 0.717588]\n",
      "epoch:19 step:15219 [D loss: 0.676453, acc.: 58.59%] [G loss: 0.786482]\n",
      "epoch:19 step:15220 [D loss: 0.595963, acc.: 78.91%] [G loss: 0.833111]\n",
      "epoch:19 step:15221 [D loss: 0.691036, acc.: 58.59%] [G loss: 0.763107]\n",
      "epoch:19 step:15222 [D loss: 0.661167, acc.: 64.84%] [G loss: 0.735899]\n",
      "epoch:19 step:15223 [D loss: 0.692976, acc.: 50.78%] [G loss: 0.656152]\n",
      "epoch:19 step:15224 [D loss: 0.716024, acc.: 48.44%] [G loss: 0.733155]\n",
      "epoch:19 step:15225 [D loss: 0.690056, acc.: 51.56%] [G loss: 0.749359]\n",
      "epoch:19 step:15226 [D loss: 0.701080, acc.: 51.56%] [G loss: 0.739270]\n",
      "epoch:19 step:15227 [D loss: 0.715745, acc.: 48.44%] [G loss: 0.779270]\n",
      "epoch:19 step:15228 [D loss: 0.741277, acc.: 45.31%] [G loss: 0.788284]\n",
      "epoch:19 step:15229 [D loss: 0.731057, acc.: 44.53%] [G loss: 0.749436]\n",
      "epoch:19 step:15230 [D loss: 0.763785, acc.: 37.50%] [G loss: 0.727252]\n",
      "epoch:19 step:15231 [D loss: 0.700600, acc.: 49.22%] [G loss: 0.704927]\n",
      "epoch:19 step:15232 [D loss: 0.712047, acc.: 41.41%] [G loss: 0.701911]\n",
      "epoch:19 step:15233 [D loss: 0.672513, acc.: 55.47%] [G loss: 0.729410]\n",
      "epoch:19 step:15234 [D loss: 0.686910, acc.: 56.25%] [G loss: 0.730078]\n",
      "epoch:19 step:15235 [D loss: 0.672161, acc.: 60.16%] [G loss: 0.688193]\n",
      "epoch:19 step:15236 [D loss: 0.677671, acc.: 52.34%] [G loss: 0.745110]\n",
      "epoch:19 step:15237 [D loss: 0.690569, acc.: 55.47%] [G loss: 0.724992]\n",
      "epoch:19 step:15238 [D loss: 0.705904, acc.: 50.00%] [G loss: 0.697123]\n",
      "epoch:19 step:15239 [D loss: 0.693570, acc.: 54.69%] [G loss: 0.742215]\n",
      "epoch:19 step:15240 [D loss: 0.680427, acc.: 52.34%] [G loss: 0.708412]\n",
      "epoch:19 step:15241 [D loss: 0.705007, acc.: 49.22%] [G loss: 0.751958]\n",
      "epoch:19 step:15242 [D loss: 0.668222, acc.: 60.16%] [G loss: 0.738925]\n",
      "epoch:19 step:15243 [D loss: 0.715040, acc.: 47.66%] [G loss: 0.710875]\n",
      "epoch:19 step:15244 [D loss: 0.656319, acc.: 60.16%] [G loss: 0.794439]\n",
      "epoch:19 step:15245 [D loss: 0.656735, acc.: 58.59%] [G loss: 0.786629]\n",
      "epoch:19 step:15246 [D loss: 0.646035, acc.: 62.50%] [G loss: 0.786329]\n",
      "epoch:19 step:15247 [D loss: 0.703526, acc.: 52.34%] [G loss: 0.747869]\n",
      "epoch:19 step:15248 [D loss: 0.623307, acc.: 75.00%] [G loss: 0.782618]\n",
      "epoch:19 step:15249 [D loss: 0.635380, acc.: 71.88%] [G loss: 0.773640]\n",
      "epoch:19 step:15250 [D loss: 0.742110, acc.: 37.50%] [G loss: 0.693613]\n",
      "epoch:19 step:15251 [D loss: 0.686787, acc.: 54.69%] [G loss: 0.696586]\n",
      "epoch:19 step:15252 [D loss: 0.682280, acc.: 57.81%] [G loss: 0.673704]\n",
      "epoch:19 step:15253 [D loss: 0.702920, acc.: 50.00%] [G loss: 0.648255]\n",
      "epoch:19 step:15254 [D loss: 0.675662, acc.: 57.03%] [G loss: 0.749305]\n",
      "epoch:19 step:15255 [D loss: 0.652730, acc.: 61.72%] [G loss: 0.765737]\n",
      "epoch:19 step:15256 [D loss: 0.712652, acc.: 45.31%] [G loss: 0.796725]\n",
      "epoch:19 step:15257 [D loss: 0.682943, acc.: 53.12%] [G loss: 0.746790]\n",
      "epoch:19 step:15258 [D loss: 0.647523, acc.: 65.62%] [G loss: 0.777914]\n",
      "epoch:19 step:15259 [D loss: 0.698128, acc.: 49.22%] [G loss: 0.723773]\n",
      "epoch:19 step:15260 [D loss: 0.679941, acc.: 60.16%] [G loss: 0.741532]\n",
      "epoch:19 step:15261 [D loss: 0.684146, acc.: 51.56%] [G loss: 0.831178]\n",
      "epoch:19 step:15262 [D loss: 0.682332, acc.: 51.56%] [G loss: 0.840378]\n",
      "epoch:19 step:15263 [D loss: 0.725338, acc.: 45.31%] [G loss: 0.761491]\n",
      "epoch:19 step:15264 [D loss: 0.704498, acc.: 53.12%] [G loss: 0.699848]\n",
      "epoch:19 step:15265 [D loss: 0.672464, acc.: 66.41%] [G loss: 0.747694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15266 [D loss: 0.678239, acc.: 52.34%] [G loss: 0.801516]\n",
      "epoch:19 step:15267 [D loss: 0.718356, acc.: 43.75%] [G loss: 0.679225]\n",
      "epoch:19 step:15268 [D loss: 0.671986, acc.: 56.25%] [G loss: 0.736813]\n",
      "epoch:19 step:15269 [D loss: 0.701438, acc.: 55.47%] [G loss: 0.671790]\n",
      "epoch:19 step:15270 [D loss: 0.668090, acc.: 57.03%] [G loss: 0.744979]\n",
      "epoch:19 step:15271 [D loss: 0.693742, acc.: 54.69%] [G loss: 0.726228]\n",
      "epoch:19 step:15272 [D loss: 0.657504, acc.: 64.06%] [G loss: 0.732522]\n",
      "epoch:19 step:15273 [D loss: 0.756233, acc.: 37.50%] [G loss: 0.716565]\n",
      "epoch:19 step:15274 [D loss: 0.720699, acc.: 42.19%] [G loss: 0.672902]\n",
      "epoch:19 step:15275 [D loss: 0.732447, acc.: 48.44%] [G loss: 0.664328]\n",
      "epoch:19 step:15276 [D loss: 0.772889, acc.: 32.81%] [G loss: 0.754785]\n",
      "epoch:19 step:15277 [D loss: 0.625271, acc.: 71.88%] [G loss: 0.784258]\n",
      "epoch:19 step:15278 [D loss: 0.704421, acc.: 49.22%] [G loss: 0.794065]\n",
      "epoch:19 step:15279 [D loss: 0.704907, acc.: 47.66%] [G loss: 0.766479]\n",
      "epoch:19 step:15280 [D loss: 0.676932, acc.: 54.69%] [G loss: 0.823636]\n",
      "epoch:19 step:15281 [D loss: 0.689985, acc.: 55.47%] [G loss: 0.775511]\n",
      "epoch:19 step:15282 [D loss: 0.671813, acc.: 58.59%] [G loss: 0.784247]\n",
      "epoch:19 step:15283 [D loss: 0.695655, acc.: 53.91%] [G loss: 0.767154]\n",
      "epoch:19 step:15284 [D loss: 0.728412, acc.: 42.97%] [G loss: 0.783171]\n",
      "epoch:19 step:15285 [D loss: 0.701291, acc.: 53.12%] [G loss: 0.819214]\n",
      "epoch:19 step:15286 [D loss: 0.653518, acc.: 57.81%] [G loss: 0.787458]\n",
      "epoch:19 step:15287 [D loss: 0.642407, acc.: 68.75%] [G loss: 0.858107]\n",
      "epoch:19 step:15288 [D loss: 0.663625, acc.: 57.81%] [G loss: 0.739923]\n",
      "epoch:19 step:15289 [D loss: 0.701385, acc.: 46.88%] [G loss: 0.764184]\n",
      "epoch:19 step:15290 [D loss: 0.711180, acc.: 42.19%] [G loss: 0.795604]\n",
      "epoch:19 step:15291 [D loss: 0.663632, acc.: 61.72%] [G loss: 0.782516]\n",
      "epoch:19 step:15292 [D loss: 0.724239, acc.: 53.12%] [G loss: 0.762841]\n",
      "epoch:19 step:15293 [D loss: 0.684400, acc.: 57.03%] [G loss: 0.764202]\n",
      "epoch:19 step:15294 [D loss: 0.725713, acc.: 48.44%] [G loss: 0.738365]\n",
      "epoch:19 step:15295 [D loss: 0.703411, acc.: 56.25%] [G loss: 0.700633]\n",
      "epoch:19 step:15296 [D loss: 0.731071, acc.: 46.09%] [G loss: 0.737580]\n",
      "epoch:19 step:15297 [D loss: 0.674042, acc.: 60.16%] [G loss: 0.770779]\n",
      "epoch:19 step:15298 [D loss: 0.724710, acc.: 49.22%] [G loss: 0.742923]\n",
      "epoch:19 step:15299 [D loss: 0.713777, acc.: 44.53%] [G loss: 0.721495]\n",
      "epoch:19 step:15300 [D loss: 0.693201, acc.: 51.56%] [G loss: 0.777989]\n",
      "epoch:19 step:15301 [D loss: 0.724102, acc.: 46.09%] [G loss: 0.645790]\n",
      "epoch:19 step:15302 [D loss: 0.712568, acc.: 46.09%] [G loss: 0.748508]\n",
      "epoch:19 step:15303 [D loss: 0.677306, acc.: 57.03%] [G loss: 0.787810]\n",
      "epoch:19 step:15304 [D loss: 0.649521, acc.: 61.72%] [G loss: 0.758690]\n",
      "epoch:19 step:15305 [D loss: 0.635818, acc.: 64.06%] [G loss: 0.774667]\n",
      "epoch:19 step:15306 [D loss: 0.738520, acc.: 43.75%] [G loss: 0.786331]\n",
      "epoch:19 step:15307 [D loss: 0.644524, acc.: 67.19%] [G loss: 0.765852]\n",
      "epoch:19 step:15308 [D loss: 0.688742, acc.: 53.91%] [G loss: 0.743056]\n",
      "epoch:19 step:15309 [D loss: 0.673744, acc.: 60.16%] [G loss: 0.720903]\n",
      "epoch:19 step:15310 [D loss: 0.714758, acc.: 47.66%] [G loss: 0.782968]\n",
      "epoch:19 step:15311 [D loss: 0.700118, acc.: 49.22%] [G loss: 0.769985]\n",
      "epoch:19 step:15312 [D loss: 0.753768, acc.: 42.19%] [G loss: 0.742018]\n",
      "epoch:19 step:15313 [D loss: 0.705841, acc.: 50.78%] [G loss: 0.775189]\n",
      "epoch:19 step:15314 [D loss: 0.719929, acc.: 41.41%] [G loss: 0.710829]\n",
      "epoch:19 step:15315 [D loss: 0.715518, acc.: 45.31%] [G loss: 0.751024]\n",
      "epoch:19 step:15316 [D loss: 0.712448, acc.: 48.44%] [G loss: 0.792398]\n",
      "epoch:19 step:15317 [D loss: 0.644549, acc.: 73.44%] [G loss: 0.851993]\n",
      "epoch:19 step:15318 [D loss: 0.664380, acc.: 62.50%] [G loss: 0.777518]\n",
      "epoch:19 step:15319 [D loss: 0.665963, acc.: 69.53%] [G loss: 0.775837]\n",
      "epoch:19 step:15320 [D loss: 0.721741, acc.: 39.84%] [G loss: 0.782392]\n",
      "epoch:19 step:15321 [D loss: 0.730652, acc.: 47.66%] [G loss: 0.726037]\n",
      "epoch:19 step:15322 [D loss: 0.701324, acc.: 51.56%] [G loss: 0.759474]\n",
      "epoch:19 step:15323 [D loss: 0.682042, acc.: 53.12%] [G loss: 0.828358]\n",
      "epoch:19 step:15324 [D loss: 0.647173, acc.: 61.72%] [G loss: 0.782789]\n",
      "epoch:19 step:15325 [D loss: 0.719444, acc.: 38.28%] [G loss: 0.762488]\n",
      "epoch:19 step:15326 [D loss: 0.691563, acc.: 52.34%] [G loss: 0.723420]\n",
      "epoch:19 step:15327 [D loss: 0.705980, acc.: 53.12%] [G loss: 0.710922]\n",
      "epoch:19 step:15328 [D loss: 0.681444, acc.: 58.59%] [G loss: 0.716449]\n",
      "epoch:19 step:15329 [D loss: 0.684413, acc.: 57.03%] [G loss: 0.708046]\n",
      "epoch:19 step:15330 [D loss: 0.674376, acc.: 62.50%] [G loss: 0.732813]\n",
      "epoch:19 step:15331 [D loss: 0.699761, acc.: 53.91%] [G loss: 0.781457]\n",
      "epoch:19 step:15332 [D loss: 0.666481, acc.: 58.59%] [G loss: 0.718261]\n",
      "epoch:19 step:15333 [D loss: 0.634297, acc.: 71.09%] [G loss: 0.756888]\n",
      "epoch:19 step:15334 [D loss: 0.672342, acc.: 64.06%] [G loss: 0.733839]\n",
      "epoch:19 step:15335 [D loss: 0.702062, acc.: 49.22%] [G loss: 0.761009]\n",
      "epoch:19 step:15336 [D loss: 0.671545, acc.: 60.94%] [G loss: 0.741265]\n",
      "epoch:19 step:15337 [D loss: 0.714723, acc.: 48.44%] [G loss: 0.781003]\n",
      "epoch:19 step:15338 [D loss: 0.638607, acc.: 70.31%] [G loss: 0.814859]\n",
      "epoch:19 step:15339 [D loss: 0.709062, acc.: 46.09%] [G loss: 0.714171]\n",
      "epoch:19 step:15340 [D loss: 0.673988, acc.: 58.59%] [G loss: 0.705360]\n",
      "epoch:19 step:15341 [D loss: 0.696941, acc.: 50.78%] [G loss: 0.760728]\n",
      "epoch:19 step:15342 [D loss: 0.707541, acc.: 46.88%] [G loss: 0.812372]\n",
      "epoch:19 step:15343 [D loss: 0.719514, acc.: 45.31%] [G loss: 0.739519]\n",
      "epoch:19 step:15344 [D loss: 0.732892, acc.: 41.41%] [G loss: 0.737603]\n",
      "epoch:19 step:15345 [D loss: 0.671452, acc.: 59.38%] [G loss: 0.764564]\n",
      "epoch:19 step:15346 [D loss: 0.645519, acc.: 67.19%] [G loss: 0.745356]\n",
      "epoch:19 step:15347 [D loss: 0.741027, acc.: 35.94%] [G loss: 0.698959]\n",
      "epoch:19 step:15348 [D loss: 0.652951, acc.: 65.62%] [G loss: 0.730704]\n",
      "epoch:19 step:15349 [D loss: 0.666716, acc.: 54.69%] [G loss: 0.764318]\n",
      "epoch:19 step:15350 [D loss: 0.697986, acc.: 55.47%] [G loss: 0.749271]\n",
      "epoch:19 step:15351 [D loss: 0.677035, acc.: 55.47%] [G loss: 0.851017]\n",
      "epoch:19 step:15352 [D loss: 0.671137, acc.: 57.03%] [G loss: 0.823108]\n",
      "epoch:19 step:15353 [D loss: 0.777490, acc.: 35.16%] [G loss: 0.763633]\n",
      "epoch:19 step:15354 [D loss: 0.652891, acc.: 66.41%] [G loss: 0.723607]\n",
      "epoch:19 step:15355 [D loss: 0.667944, acc.: 60.94%] [G loss: 0.702859]\n",
      "epoch:19 step:15356 [D loss: 0.717436, acc.: 44.53%] [G loss: 0.717752]\n",
      "epoch:19 step:15357 [D loss: 0.689099, acc.: 61.72%] [G loss: 0.758374]\n",
      "epoch:19 step:15358 [D loss: 0.654167, acc.: 65.62%] [G loss: 0.705055]\n",
      "epoch:19 step:15359 [D loss: 0.653193, acc.: 63.28%] [G loss: 0.789417]\n",
      "epoch:19 step:15360 [D loss: 0.641702, acc.: 70.31%] [G loss: 0.778209]\n",
      "epoch:19 step:15361 [D loss: 0.739002, acc.: 36.72%] [G loss: 0.727233]\n",
      "epoch:19 step:15362 [D loss: 0.682387, acc.: 57.81%] [G loss: 0.688166]\n",
      "epoch:19 step:15363 [D loss: 0.688219, acc.: 57.03%] [G loss: 0.842029]\n",
      "epoch:19 step:15364 [D loss: 0.679981, acc.: 52.34%] [G loss: 0.786779]\n",
      "epoch:19 step:15365 [D loss: 0.773500, acc.: 39.06%] [G loss: 0.729027]\n",
      "epoch:19 step:15366 [D loss: 0.694199, acc.: 56.25%] [G loss: 0.727678]\n",
      "epoch:19 step:15367 [D loss: 0.722908, acc.: 44.53%] [G loss: 0.721043]\n",
      "epoch:19 step:15368 [D loss: 0.684492, acc.: 55.47%] [G loss: 0.726910]\n",
      "epoch:19 step:15369 [D loss: 0.665048, acc.: 59.38%] [G loss: 0.787323]\n",
      "epoch:19 step:15370 [D loss: 0.688814, acc.: 56.25%] [G loss: 0.702743]\n",
      "epoch:19 step:15371 [D loss: 0.704737, acc.: 46.09%] [G loss: 0.743690]\n",
      "epoch:19 step:15372 [D loss: 0.692378, acc.: 50.78%] [G loss: 0.763526]\n",
      "epoch:19 step:15373 [D loss: 0.687428, acc.: 58.59%] [G loss: 0.774321]\n",
      "epoch:19 step:15374 [D loss: 0.763310, acc.: 30.47%] [G loss: 0.762622]\n",
      "epoch:19 step:15375 [D loss: 0.675201, acc.: 66.41%] [G loss: 0.781515]\n",
      "epoch:19 step:15376 [D loss: 0.712371, acc.: 50.78%] [G loss: 0.762555]\n",
      "epoch:19 step:15377 [D loss: 0.695041, acc.: 59.38%] [G loss: 0.772130]\n",
      "epoch:19 step:15378 [D loss: 0.712488, acc.: 47.66%] [G loss: 0.735922]\n",
      "epoch:19 step:15379 [D loss: 0.649983, acc.: 68.75%] [G loss: 0.774667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15380 [D loss: 0.661937, acc.: 64.06%] [G loss: 0.785050]\n",
      "epoch:19 step:15381 [D loss: 0.704228, acc.: 53.91%] [G loss: 0.743841]\n",
      "epoch:19 step:15382 [D loss: 0.693220, acc.: 55.47%] [G loss: 0.756841]\n",
      "epoch:19 step:15383 [D loss: 0.670475, acc.: 60.16%] [G loss: 0.826953]\n",
      "epoch:19 step:15384 [D loss: 0.610434, acc.: 75.78%] [G loss: 0.826538]\n",
      "epoch:19 step:15385 [D loss: 0.734298, acc.: 46.88%] [G loss: 0.765984]\n",
      "epoch:19 step:15386 [D loss: 0.676207, acc.: 50.78%] [G loss: 0.774751]\n",
      "epoch:19 step:15387 [D loss: 0.688230, acc.: 57.03%] [G loss: 0.733735]\n",
      "epoch:19 step:15388 [D loss: 0.651561, acc.: 65.62%] [G loss: 0.787411]\n",
      "epoch:19 step:15389 [D loss: 0.597213, acc.: 80.47%] [G loss: 0.726862]\n",
      "epoch:19 step:15390 [D loss: 0.673286, acc.: 57.03%] [G loss: 0.744086]\n",
      "epoch:19 step:15391 [D loss: 0.734493, acc.: 46.09%] [G loss: 0.734306]\n",
      "epoch:19 step:15392 [D loss: 0.737980, acc.: 39.84%] [G loss: 0.712059]\n",
      "epoch:19 step:15393 [D loss: 0.685611, acc.: 57.03%] [G loss: 0.724767]\n",
      "epoch:19 step:15394 [D loss: 0.692847, acc.: 56.25%] [G loss: 0.682668]\n",
      "epoch:19 step:15395 [D loss: 0.694409, acc.: 53.12%] [G loss: 0.733148]\n",
      "epoch:19 step:15396 [D loss: 0.642070, acc.: 71.09%] [G loss: 0.776500]\n",
      "epoch:19 step:15397 [D loss: 0.700438, acc.: 50.78%] [G loss: 0.735008]\n",
      "epoch:19 step:15398 [D loss: 0.671381, acc.: 60.94%] [G loss: 0.730131]\n",
      "epoch:19 step:15399 [D loss: 0.683147, acc.: 56.25%] [G loss: 0.730472]\n",
      "epoch:19 step:15400 [D loss: 0.708371, acc.: 42.97%] [G loss: 0.703743]\n",
      "epoch:19 step:15401 [D loss: 0.705081, acc.: 49.22%] [G loss: 0.731036]\n",
      "epoch:19 step:15402 [D loss: 0.712549, acc.: 42.19%] [G loss: 0.725159]\n",
      "epoch:19 step:15403 [D loss: 0.696198, acc.: 52.34%] [G loss: 0.765872]\n",
      "epoch:19 step:15404 [D loss: 0.714736, acc.: 48.44%] [G loss: 0.741865]\n",
      "epoch:19 step:15405 [D loss: 0.715518, acc.: 54.69%] [G loss: 0.788901]\n",
      "epoch:19 step:15406 [D loss: 0.649983, acc.: 59.38%] [G loss: 0.814150]\n",
      "epoch:19 step:15407 [D loss: 0.680301, acc.: 59.38%] [G loss: 0.748673]\n",
      "epoch:19 step:15408 [D loss: 0.681045, acc.: 50.78%] [G loss: 0.899751]\n",
      "epoch:19 step:15409 [D loss: 0.668686, acc.: 65.62%] [G loss: 0.833950]\n",
      "epoch:19 step:15410 [D loss: 0.741831, acc.: 43.75%] [G loss: 0.786145]\n",
      "epoch:19 step:15411 [D loss: 0.685160, acc.: 57.03%] [G loss: 0.813169]\n",
      "epoch:19 step:15412 [D loss: 0.719144, acc.: 42.97%] [G loss: 0.792828]\n",
      "epoch:19 step:15413 [D loss: 0.758091, acc.: 46.09%] [G loss: 0.784809]\n",
      "epoch:19 step:15414 [D loss: 0.734945, acc.: 46.09%] [G loss: 0.746154]\n",
      "epoch:19 step:15415 [D loss: 0.694145, acc.: 47.66%] [G loss: 0.800014]\n",
      "epoch:19 step:15416 [D loss: 0.737819, acc.: 45.31%] [G loss: 0.806141]\n",
      "epoch:19 step:15417 [D loss: 0.671596, acc.: 58.59%] [G loss: 0.772726]\n",
      "epoch:19 step:15418 [D loss: 0.691105, acc.: 53.12%] [G loss: 0.811112]\n",
      "epoch:19 step:15419 [D loss: 0.722591, acc.: 46.09%] [G loss: 0.759347]\n",
      "epoch:19 step:15420 [D loss: 0.722318, acc.: 46.88%] [G loss: 0.798725]\n",
      "epoch:19 step:15421 [D loss: 0.693163, acc.: 55.47%] [G loss: 0.762675]\n",
      "epoch:19 step:15422 [D loss: 0.689345, acc.: 55.47%] [G loss: 0.706226]\n",
      "epoch:19 step:15423 [D loss: 0.693129, acc.: 52.34%] [G loss: 0.737263]\n",
      "epoch:19 step:15424 [D loss: 0.692983, acc.: 50.78%] [G loss: 0.745848]\n",
      "epoch:19 step:15425 [D loss: 0.650821, acc.: 64.84%] [G loss: 0.811082]\n",
      "epoch:19 step:15426 [D loss: 0.700692, acc.: 53.91%] [G loss: 0.798537]\n",
      "epoch:19 step:15427 [D loss: 0.708705, acc.: 50.00%] [G loss: 0.746981]\n",
      "epoch:19 step:15428 [D loss: 0.712993, acc.: 46.88%] [G loss: 0.764841]\n",
      "epoch:19 step:15429 [D loss: 0.703627, acc.: 46.09%] [G loss: 0.837348]\n",
      "epoch:19 step:15430 [D loss: 0.674402, acc.: 60.16%] [G loss: 0.845080]\n",
      "epoch:19 step:15431 [D loss: 0.730535, acc.: 47.66%] [G loss: 0.745826]\n",
      "epoch:19 step:15432 [D loss: 0.728270, acc.: 46.88%] [G loss: 0.777149]\n",
      "epoch:19 step:15433 [D loss: 0.711092, acc.: 44.53%] [G loss: 0.740993]\n",
      "epoch:19 step:15434 [D loss: 0.654998, acc.: 64.84%] [G loss: 0.776261]\n",
      "epoch:19 step:15435 [D loss: 0.717986, acc.: 42.97%] [G loss: 0.757656]\n",
      "epoch:19 step:15436 [D loss: 0.644420, acc.: 67.19%] [G loss: 0.804564]\n",
      "epoch:19 step:15437 [D loss: 0.676816, acc.: 53.12%] [G loss: 0.712840]\n",
      "epoch:19 step:15438 [D loss: 0.685113, acc.: 55.47%] [G loss: 0.791909]\n",
      "epoch:19 step:15439 [D loss: 0.685288, acc.: 59.38%] [G loss: 0.779443]\n",
      "epoch:19 step:15440 [D loss: 0.713862, acc.: 46.88%] [G loss: 0.687008]\n",
      "epoch:19 step:15441 [D loss: 0.706681, acc.: 45.31%] [G loss: 0.783397]\n",
      "epoch:19 step:15442 [D loss: 0.706564, acc.: 51.56%] [G loss: 0.738302]\n",
      "epoch:19 step:15443 [D loss: 0.725897, acc.: 42.19%] [G loss: 0.770597]\n",
      "epoch:19 step:15444 [D loss: 0.697123, acc.: 50.78%] [G loss: 0.722331]\n",
      "epoch:19 step:15445 [D loss: 0.662926, acc.: 64.06%] [G loss: 0.750537]\n",
      "epoch:19 step:15446 [D loss: 0.722682, acc.: 44.53%] [G loss: 0.768740]\n",
      "epoch:19 step:15447 [D loss: 0.703062, acc.: 50.78%] [G loss: 0.732206]\n",
      "epoch:19 step:15448 [D loss: 0.736071, acc.: 47.66%] [G loss: 0.750048]\n",
      "epoch:19 step:15449 [D loss: 0.699743, acc.: 57.03%] [G loss: 0.734049]\n",
      "epoch:19 step:15450 [D loss: 0.683419, acc.: 57.81%] [G loss: 0.752721]\n",
      "epoch:19 step:15451 [D loss: 0.700851, acc.: 46.09%] [G loss: 0.712212]\n",
      "epoch:19 step:15452 [D loss: 0.736356, acc.: 41.41%] [G loss: 0.725962]\n",
      "epoch:19 step:15453 [D loss: 0.713675, acc.: 45.31%] [G loss: 0.778901]\n",
      "epoch:19 step:15454 [D loss: 0.696511, acc.: 53.91%] [G loss: 0.785400]\n",
      "epoch:19 step:15455 [D loss: 0.670314, acc.: 54.69%] [G loss: 0.790946]\n",
      "epoch:19 step:15456 [D loss: 0.693183, acc.: 53.91%] [G loss: 0.734533]\n",
      "epoch:19 step:15457 [D loss: 0.668728, acc.: 58.59%] [G loss: 0.792249]\n",
      "epoch:19 step:15458 [D loss: 0.700608, acc.: 50.78%] [G loss: 0.742033]\n",
      "epoch:19 step:15459 [D loss: 0.700386, acc.: 48.44%] [G loss: 0.777961]\n",
      "epoch:19 step:15460 [D loss: 0.674538, acc.: 58.59%] [G loss: 0.781618]\n",
      "epoch:19 step:15461 [D loss: 0.657449, acc.: 62.50%] [G loss: 0.767089]\n",
      "epoch:19 step:15462 [D loss: 0.708852, acc.: 46.09%] [G loss: 0.756728]\n",
      "epoch:19 step:15463 [D loss: 0.709360, acc.: 40.62%] [G loss: 0.781372]\n",
      "epoch:19 step:15464 [D loss: 0.722652, acc.: 43.75%] [G loss: 0.717711]\n",
      "epoch:19 step:15465 [D loss: 0.743719, acc.: 40.62%] [G loss: 0.709875]\n",
      "epoch:19 step:15466 [D loss: 0.707396, acc.: 48.44%] [G loss: 0.758863]\n",
      "epoch:19 step:15467 [D loss: 0.691656, acc.: 56.25%] [G loss: 0.759917]\n",
      "epoch:19 step:15468 [D loss: 0.690650, acc.: 54.69%] [G loss: 0.753268]\n",
      "epoch:19 step:15469 [D loss: 0.702213, acc.: 46.88%] [G loss: 0.728702]\n",
      "epoch:19 step:15470 [D loss: 0.724580, acc.: 44.53%] [G loss: 0.728141]\n",
      "epoch:19 step:15471 [D loss: 0.682132, acc.: 56.25%] [G loss: 0.755373]\n",
      "epoch:19 step:15472 [D loss: 0.741779, acc.: 46.88%] [G loss: 0.721001]\n",
      "epoch:19 step:15473 [D loss: 0.664489, acc.: 63.28%] [G loss: 0.742895]\n",
      "epoch:19 step:15474 [D loss: 0.698955, acc.: 50.78%] [G loss: 0.709964]\n",
      "epoch:19 step:15475 [D loss: 0.644099, acc.: 66.41%] [G loss: 0.822879]\n",
      "epoch:19 step:15476 [D loss: 0.694338, acc.: 55.47%] [G loss: 0.691519]\n",
      "epoch:19 step:15477 [D loss: 0.722378, acc.: 49.22%] [G loss: 0.706235]\n",
      "epoch:19 step:15478 [D loss: 0.705541, acc.: 44.53%] [G loss: 0.719615]\n",
      "epoch:19 step:15479 [D loss: 0.696986, acc.: 50.00%] [G loss: 0.755154]\n",
      "epoch:19 step:15480 [D loss: 0.736726, acc.: 42.97%] [G loss: 0.715071]\n",
      "epoch:19 step:15481 [D loss: 0.712884, acc.: 44.53%] [G loss: 0.778454]\n",
      "epoch:19 step:15482 [D loss: 0.715520, acc.: 46.88%] [G loss: 0.736042]\n",
      "epoch:19 step:15483 [D loss: 0.678595, acc.: 60.94%] [G loss: 0.792066]\n",
      "epoch:19 step:15484 [D loss: 0.712875, acc.: 46.88%] [G loss: 0.753696]\n",
      "epoch:19 step:15485 [D loss: 0.731846, acc.: 39.06%] [G loss: 0.786191]\n",
      "epoch:19 step:15486 [D loss: 0.720146, acc.: 42.97%] [G loss: 0.766085]\n",
      "epoch:19 step:15487 [D loss: 0.695528, acc.: 46.09%] [G loss: 0.760259]\n",
      "epoch:19 step:15488 [D loss: 0.689735, acc.: 48.44%] [G loss: 0.821624]\n",
      "epoch:19 step:15489 [D loss: 0.653063, acc.: 67.97%] [G loss: 0.804343]\n",
      "epoch:19 step:15490 [D loss: 0.715496, acc.: 50.00%] [G loss: 0.732209]\n",
      "epoch:19 step:15491 [D loss: 0.673692, acc.: 63.28%] [G loss: 0.725250]\n",
      "epoch:19 step:15492 [D loss: 0.698720, acc.: 53.91%] [G loss: 0.767712]\n",
      "epoch:19 step:15493 [D loss: 0.709517, acc.: 46.88%] [G loss: 0.702074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15494 [D loss: 0.681394, acc.: 57.81%] [G loss: 0.754040]\n",
      "epoch:19 step:15495 [D loss: 0.732597, acc.: 42.19%] [G loss: 0.800313]\n",
      "epoch:19 step:15496 [D loss: 0.699441, acc.: 52.34%] [G loss: 0.712608]\n",
      "epoch:19 step:15497 [D loss: 0.688487, acc.: 60.94%] [G loss: 0.758634]\n",
      "epoch:19 step:15498 [D loss: 0.685471, acc.: 50.78%] [G loss: 0.787457]\n",
      "epoch:19 step:15499 [D loss: 0.663979, acc.: 58.59%] [G loss: 0.822280]\n",
      "epoch:19 step:15500 [D loss: 0.686106, acc.: 53.91%] [G loss: 0.749587]\n",
      "epoch:19 step:15501 [D loss: 0.709972, acc.: 47.66%] [G loss: 0.752696]\n",
      "epoch:19 step:15502 [D loss: 0.661299, acc.: 59.38%] [G loss: 0.759988]\n",
      "epoch:19 step:15503 [D loss: 0.695185, acc.: 45.31%] [G loss: 0.780362]\n",
      "epoch:19 step:15504 [D loss: 0.710803, acc.: 46.09%] [G loss: 0.737895]\n",
      "epoch:19 step:15505 [D loss: 0.691189, acc.: 60.16%] [G loss: 0.743741]\n",
      "epoch:19 step:15506 [D loss: 0.681007, acc.: 53.12%] [G loss: 0.773047]\n",
      "epoch:19 step:15507 [D loss: 0.653548, acc.: 68.75%] [G loss: 0.802936]\n",
      "epoch:19 step:15508 [D loss: 0.689324, acc.: 53.12%] [G loss: 0.774127]\n",
      "epoch:19 step:15509 [D loss: 0.692063, acc.: 58.59%] [G loss: 0.826957]\n",
      "epoch:19 step:15510 [D loss: 0.691099, acc.: 54.69%] [G loss: 0.802971]\n",
      "epoch:19 step:15511 [D loss: 0.740015, acc.: 40.62%] [G loss: 0.760926]\n",
      "epoch:19 step:15512 [D loss: 0.644406, acc.: 67.19%] [G loss: 0.794329]\n",
      "epoch:19 step:15513 [D loss: 0.702675, acc.: 46.09%] [G loss: 0.860569]\n",
      "epoch:19 step:15514 [D loss: 0.719157, acc.: 46.09%] [G loss: 0.776905]\n",
      "epoch:19 step:15515 [D loss: 0.717586, acc.: 48.44%] [G loss: 0.736941]\n",
      "epoch:19 step:15516 [D loss: 0.684592, acc.: 53.91%] [G loss: 0.771254]\n",
      "epoch:19 step:15517 [D loss: 0.683607, acc.: 55.47%] [G loss: 0.687609]\n",
      "epoch:19 step:15518 [D loss: 0.678846, acc.: 54.69%] [G loss: 0.764148]\n",
      "epoch:19 step:15519 [D loss: 0.627835, acc.: 71.09%] [G loss: 0.743998]\n",
      "epoch:19 step:15520 [D loss: 0.684989, acc.: 55.47%] [G loss: 0.766408]\n",
      "epoch:19 step:15521 [D loss: 0.697393, acc.: 57.81%] [G loss: 0.790203]\n",
      "epoch:19 step:15522 [D loss: 0.686635, acc.: 55.47%] [G loss: 0.739545]\n",
      "epoch:19 step:15523 [D loss: 0.705533, acc.: 50.78%] [G loss: 0.769089]\n",
      "epoch:19 step:15524 [D loss: 0.724837, acc.: 47.66%] [G loss: 0.739376]\n",
      "epoch:19 step:15525 [D loss: 0.734824, acc.: 42.97%] [G loss: 0.800340]\n",
      "epoch:19 step:15526 [D loss: 0.674830, acc.: 59.38%] [G loss: 0.709041]\n",
      "epoch:19 step:15527 [D loss: 0.717133, acc.: 39.06%] [G loss: 0.733885]\n",
      "epoch:19 step:15528 [D loss: 0.687424, acc.: 58.59%] [G loss: 0.776145]\n",
      "epoch:19 step:15529 [D loss: 0.690520, acc.: 53.91%] [G loss: 0.821555]\n",
      "epoch:19 step:15530 [D loss: 0.671009, acc.: 57.03%] [G loss: 0.754905]\n",
      "epoch:19 step:15531 [D loss: 0.757736, acc.: 47.66%] [G loss: 0.782783]\n",
      "epoch:19 step:15532 [D loss: 0.673436, acc.: 57.03%] [G loss: 0.745025]\n",
      "epoch:19 step:15533 [D loss: 0.691472, acc.: 57.81%] [G loss: 0.717738]\n",
      "epoch:19 step:15534 [D loss: 0.652415, acc.: 64.06%] [G loss: 0.732795]\n",
      "epoch:19 step:15535 [D loss: 0.713082, acc.: 49.22%] [G loss: 0.684087]\n",
      "epoch:19 step:15536 [D loss: 0.752964, acc.: 35.94%] [G loss: 0.720049]\n",
      "epoch:19 step:15537 [D loss: 0.647368, acc.: 66.41%] [G loss: 0.686337]\n",
      "epoch:19 step:15538 [D loss: 0.725266, acc.: 41.41%] [G loss: 0.698804]\n",
      "epoch:19 step:15539 [D loss: 0.675104, acc.: 57.81%] [G loss: 0.694300]\n",
      "epoch:19 step:15540 [D loss: 0.716980, acc.: 42.19%] [G loss: 0.689148]\n",
      "epoch:19 step:15541 [D loss: 0.753657, acc.: 38.28%] [G loss: 0.716258]\n",
      "epoch:19 step:15542 [D loss: 0.736794, acc.: 46.09%] [G loss: 0.782002]\n",
      "epoch:19 step:15543 [D loss: 0.741040, acc.: 39.84%] [G loss: 0.760054]\n",
      "epoch:19 step:15544 [D loss: 0.719496, acc.: 50.78%] [G loss: 0.798342]\n",
      "epoch:19 step:15545 [D loss: 0.648920, acc.: 64.06%] [G loss: 0.791967]\n",
      "epoch:19 step:15546 [D loss: 0.710985, acc.: 50.00%] [G loss: 0.832434]\n",
      "epoch:19 step:15547 [D loss: 0.710370, acc.: 47.66%] [G loss: 0.732709]\n",
      "epoch:19 step:15548 [D loss: 0.701801, acc.: 46.88%] [G loss: 0.711262]\n",
      "epoch:19 step:15549 [D loss: 0.726532, acc.: 40.62%] [G loss: 0.751687]\n",
      "epoch:19 step:15550 [D loss: 0.714871, acc.: 42.97%] [G loss: 0.848362]\n",
      "epoch:19 step:15551 [D loss: 0.675587, acc.: 57.81%] [G loss: 0.826474]\n",
      "epoch:19 step:15552 [D loss: 0.678638, acc.: 56.25%] [G loss: 0.838138]\n",
      "epoch:19 step:15553 [D loss: 0.687627, acc.: 60.16%] [G loss: 0.813155]\n",
      "epoch:19 step:15554 [D loss: 0.680928, acc.: 56.25%] [G loss: 0.877280]\n",
      "epoch:19 step:15555 [D loss: 0.680763, acc.: 60.16%] [G loss: 0.806419]\n",
      "epoch:19 step:15556 [D loss: 0.644020, acc.: 68.75%] [G loss: 0.835678]\n",
      "epoch:19 step:15557 [D loss: 0.684629, acc.: 57.81%] [G loss: 0.744467]\n",
      "epoch:19 step:15558 [D loss: 0.685861, acc.: 50.78%] [G loss: 0.773720]\n",
      "epoch:19 step:15559 [D loss: 0.707467, acc.: 54.69%] [G loss: 0.728339]\n",
      "epoch:19 step:15560 [D loss: 0.720306, acc.: 45.31%] [G loss: 0.756044]\n",
      "epoch:19 step:15561 [D loss: 0.681224, acc.: 53.91%] [G loss: 0.759431]\n",
      "epoch:19 step:15562 [D loss: 0.766173, acc.: 39.84%] [G loss: 0.738601]\n",
      "epoch:19 step:15563 [D loss: 0.690522, acc.: 57.03%] [G loss: 0.729967]\n",
      "epoch:19 step:15564 [D loss: 0.688386, acc.: 49.22%] [G loss: 0.749536]\n",
      "epoch:19 step:15565 [D loss: 0.676307, acc.: 65.62%] [G loss: 0.715094]\n",
      "epoch:19 step:15566 [D loss: 0.660495, acc.: 62.50%] [G loss: 0.690025]\n",
      "epoch:19 step:15567 [D loss: 0.677583, acc.: 55.47%] [G loss: 0.725939]\n",
      "epoch:19 step:15568 [D loss: 0.712031, acc.: 47.66%] [G loss: 0.759945]\n",
      "epoch:19 step:15569 [D loss: 0.703561, acc.: 56.25%] [G loss: 0.672748]\n",
      "epoch:19 step:15570 [D loss: 0.641743, acc.: 62.50%] [G loss: 0.733541]\n",
      "epoch:19 step:15571 [D loss: 0.684700, acc.: 57.03%] [G loss: 0.786100]\n",
      "epoch:19 step:15572 [D loss: 0.693525, acc.: 53.12%] [G loss: 0.778839]\n",
      "epoch:19 step:15573 [D loss: 0.670799, acc.: 59.38%] [G loss: 0.723075]\n",
      "epoch:19 step:15574 [D loss: 0.717971, acc.: 42.97%] [G loss: 0.802989]\n",
      "epoch:19 step:15575 [D loss: 0.709729, acc.: 46.88%] [G loss: 0.751360]\n",
      "epoch:19 step:15576 [D loss: 0.721181, acc.: 51.56%] [G loss: 0.734799]\n",
      "epoch:19 step:15577 [D loss: 0.670574, acc.: 59.38%] [G loss: 0.801165]\n",
      "epoch:19 step:15578 [D loss: 0.697496, acc.: 51.56%] [G loss: 0.730309]\n",
      "epoch:19 step:15579 [D loss: 0.716771, acc.: 43.75%] [G loss: 0.734732]\n",
      "epoch:19 step:15580 [D loss: 0.648106, acc.: 64.84%] [G loss: 0.774834]\n",
      "epoch:19 step:15581 [D loss: 0.709581, acc.: 45.31%] [G loss: 0.738275]\n",
      "epoch:19 step:15582 [D loss: 0.677964, acc.: 55.47%] [G loss: 0.791623]\n",
      "epoch:19 step:15583 [D loss: 0.691075, acc.: 50.00%] [G loss: 0.681406]\n",
      "epoch:19 step:15584 [D loss: 0.705802, acc.: 50.00%] [G loss: 0.721129]\n",
      "epoch:19 step:15585 [D loss: 0.723951, acc.: 49.22%] [G loss: 0.757169]\n",
      "epoch:19 step:15586 [D loss: 0.710343, acc.: 45.31%] [G loss: 0.705151]\n",
      "epoch:19 step:15587 [D loss: 0.697764, acc.: 52.34%] [G loss: 0.702538]\n",
      "epoch:19 step:15588 [D loss: 0.694861, acc.: 59.38%] [G loss: 0.755864]\n",
      "epoch:19 step:15589 [D loss: 0.715793, acc.: 50.78%] [G loss: 0.709099]\n",
      "epoch:19 step:15590 [D loss: 0.660151, acc.: 60.16%] [G loss: 0.745800]\n",
      "epoch:19 step:15591 [D loss: 0.694209, acc.: 51.56%] [G loss: 0.750152]\n",
      "epoch:19 step:15592 [D loss: 0.668678, acc.: 59.38%] [G loss: 0.745738]\n",
      "epoch:19 step:15593 [D loss: 0.687978, acc.: 58.59%] [G loss: 0.756600]\n",
      "epoch:19 step:15594 [D loss: 0.710790, acc.: 44.53%] [G loss: 0.748078]\n",
      "epoch:19 step:15595 [D loss: 0.635942, acc.: 73.44%] [G loss: 0.802241]\n",
      "epoch:19 step:15596 [D loss: 0.663483, acc.: 63.28%] [G loss: 0.758511]\n",
      "epoch:19 step:15597 [D loss: 0.688361, acc.: 59.38%] [G loss: 0.743590]\n",
      "epoch:19 step:15598 [D loss: 0.689288, acc.: 55.47%] [G loss: 0.745660]\n",
      "epoch:19 step:15599 [D loss: 0.703589, acc.: 51.56%] [G loss: 0.763137]\n",
      "epoch:19 step:15600 [D loss: 0.721095, acc.: 44.53%] [G loss: 0.664410]\n",
      "epoch:19 step:15601 [D loss: 0.702581, acc.: 47.66%] [G loss: 0.815728]\n",
      "epoch:19 step:15602 [D loss: 0.683068, acc.: 58.59%] [G loss: 0.833958]\n",
      "epoch:19 step:15603 [D loss: 0.686363, acc.: 46.88%] [G loss: 0.797643]\n",
      "epoch:19 step:15604 [D loss: 0.691828, acc.: 51.56%] [G loss: 0.770795]\n",
      "epoch:19 step:15605 [D loss: 0.703838, acc.: 48.44%] [G loss: 0.742799]\n",
      "epoch:19 step:15606 [D loss: 0.687244, acc.: 53.12%] [G loss: 0.742954]\n",
      "epoch:19 step:15607 [D loss: 0.702100, acc.: 46.88%] [G loss: 0.695413]\n",
      "epoch:19 step:15608 [D loss: 0.703068, acc.: 46.88%] [G loss: 0.772337]\n",
      "epoch:19 step:15609 [D loss: 0.699006, acc.: 50.00%] [G loss: 0.772951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15610 [D loss: 0.720142, acc.: 48.44%] [G loss: 0.761923]\n",
      "epoch:19 step:15611 [D loss: 0.707240, acc.: 44.53%] [G loss: 0.764032]\n",
      "epoch:19 step:15612 [D loss: 0.719843, acc.: 41.41%] [G loss: 0.727731]\n",
      "epoch:19 step:15613 [D loss: 0.655667, acc.: 66.41%] [G loss: 0.762870]\n",
      "epoch:19 step:15614 [D loss: 0.711447, acc.: 43.75%] [G loss: 0.725176]\n",
      "epoch:19 step:15615 [D loss: 0.698261, acc.: 51.56%] [G loss: 0.730279]\n",
      "epoch:19 step:15616 [D loss: 0.719273, acc.: 49.22%] [G loss: 0.755483]\n",
      "epoch:19 step:15617 [D loss: 0.638278, acc.: 67.97%] [G loss: 0.768346]\n",
      "epoch:19 step:15618 [D loss: 0.708843, acc.: 51.56%] [G loss: 0.778615]\n",
      "epoch:19 step:15619 [D loss: 0.732037, acc.: 39.84%] [G loss: 0.691432]\n",
      "epoch:19 step:15620 [D loss: 0.691776, acc.: 50.00%] [G loss: 0.723645]\n",
      "epoch:20 step:15621 [D loss: 0.630217, acc.: 68.75%] [G loss: 0.758330]\n",
      "epoch:20 step:15622 [D loss: 0.667129, acc.: 60.94%] [G loss: 0.778201]\n",
      "epoch:20 step:15623 [D loss: 0.706364, acc.: 50.78%] [G loss: 0.720060]\n",
      "epoch:20 step:15624 [D loss: 0.730037, acc.: 41.41%] [G loss: 0.662531]\n",
      "epoch:20 step:15625 [D loss: 0.735684, acc.: 39.06%] [G loss: 0.748466]\n",
      "epoch:20 step:15626 [D loss: 0.710185, acc.: 49.22%] [G loss: 0.717221]\n",
      "epoch:20 step:15627 [D loss: 0.667930, acc.: 57.03%] [G loss: 0.862098]\n",
      "epoch:20 step:15628 [D loss: 0.663971, acc.: 66.41%] [G loss: 0.751729]\n",
      "epoch:20 step:15629 [D loss: 0.649905, acc.: 62.50%] [G loss: 0.761582]\n",
      "epoch:20 step:15630 [D loss: 0.745898, acc.: 39.84%] [G loss: 0.714276]\n",
      "epoch:20 step:15631 [D loss: 0.710858, acc.: 45.31%] [G loss: 0.730152]\n",
      "epoch:20 step:15632 [D loss: 0.705709, acc.: 45.31%] [G loss: 0.702991]\n",
      "epoch:20 step:15633 [D loss: 0.669412, acc.: 60.94%] [G loss: 0.785280]\n",
      "epoch:20 step:15634 [D loss: 0.696750, acc.: 50.78%] [G loss: 0.736752]\n",
      "epoch:20 step:15635 [D loss: 0.689473, acc.: 52.34%] [G loss: 0.720519]\n",
      "epoch:20 step:15636 [D loss: 0.706947, acc.: 48.44%] [G loss: 0.693138]\n",
      "epoch:20 step:15637 [D loss: 0.684758, acc.: 55.47%] [G loss: 0.733103]\n",
      "epoch:20 step:15638 [D loss: 0.674644, acc.: 60.16%] [G loss: 0.740400]\n",
      "epoch:20 step:15639 [D loss: 0.673449, acc.: 62.50%] [G loss: 0.706967]\n",
      "epoch:20 step:15640 [D loss: 0.670241, acc.: 63.28%] [G loss: 0.746967]\n",
      "epoch:20 step:15641 [D loss: 0.705657, acc.: 56.25%] [G loss: 0.765763]\n",
      "epoch:20 step:15642 [D loss: 0.679458, acc.: 57.81%] [G loss: 0.731216]\n",
      "epoch:20 step:15643 [D loss: 0.713499, acc.: 46.09%] [G loss: 0.772898]\n",
      "epoch:20 step:15644 [D loss: 0.659247, acc.: 60.94%] [G loss: 0.824226]\n",
      "epoch:20 step:15645 [D loss: 0.748350, acc.: 41.41%] [G loss: 0.751367]\n",
      "epoch:20 step:15646 [D loss: 0.702597, acc.: 46.88%] [G loss: 0.745320]\n",
      "epoch:20 step:15647 [D loss: 0.686902, acc.: 53.12%] [G loss: 0.735230]\n",
      "epoch:20 step:15648 [D loss: 0.717836, acc.: 47.66%] [G loss: 0.666934]\n",
      "epoch:20 step:15649 [D loss: 0.688454, acc.: 49.22%] [G loss: 0.710808]\n",
      "epoch:20 step:15650 [D loss: 0.712098, acc.: 43.75%] [G loss: 0.686734]\n",
      "epoch:20 step:15651 [D loss: 0.742176, acc.: 36.72%] [G loss: 0.703862]\n",
      "epoch:20 step:15652 [D loss: 0.706305, acc.: 47.66%] [G loss: 0.742353]\n",
      "epoch:20 step:15653 [D loss: 0.707485, acc.: 53.91%] [G loss: 0.800513]\n",
      "epoch:20 step:15654 [D loss: 0.670314, acc.: 53.91%] [G loss: 0.797736]\n",
      "epoch:20 step:15655 [D loss: 0.664185, acc.: 61.72%] [G loss: 0.743326]\n",
      "epoch:20 step:15656 [D loss: 0.666241, acc.: 63.28%] [G loss: 0.758276]\n",
      "epoch:20 step:15657 [D loss: 0.687244, acc.: 54.69%] [G loss: 0.763383]\n",
      "epoch:20 step:15658 [D loss: 0.693666, acc.: 55.47%] [G loss: 0.776559]\n",
      "epoch:20 step:15659 [D loss: 0.688941, acc.: 49.22%] [G loss: 0.759654]\n",
      "epoch:20 step:15660 [D loss: 0.737596, acc.: 43.75%] [G loss: 0.765986]\n",
      "epoch:20 step:15661 [D loss: 0.683486, acc.: 53.12%] [G loss: 0.673922]\n",
      "epoch:20 step:15662 [D loss: 0.674298, acc.: 59.38%] [G loss: 0.793027]\n",
      "epoch:20 step:15663 [D loss: 0.718077, acc.: 41.41%] [G loss: 0.766569]\n",
      "epoch:20 step:15664 [D loss: 0.725754, acc.: 46.88%] [G loss: 0.753666]\n",
      "epoch:20 step:15665 [D loss: 0.710894, acc.: 53.91%] [G loss: 0.693758]\n",
      "epoch:20 step:15666 [D loss: 0.715168, acc.: 50.00%] [G loss: 0.720152]\n",
      "epoch:20 step:15667 [D loss: 0.662259, acc.: 64.84%] [G loss: 0.774824]\n",
      "epoch:20 step:15668 [D loss: 0.701784, acc.: 56.25%] [G loss: 0.761306]\n",
      "epoch:20 step:15669 [D loss: 0.698479, acc.: 53.12%] [G loss: 0.716927]\n",
      "epoch:20 step:15670 [D loss: 0.660568, acc.: 63.28%] [G loss: 0.704201]\n",
      "epoch:20 step:15671 [D loss: 0.666986, acc.: 62.50%] [G loss: 0.814526]\n",
      "epoch:20 step:15672 [D loss: 0.677159, acc.: 57.81%] [G loss: 0.753468]\n",
      "epoch:20 step:15673 [D loss: 0.687326, acc.: 53.12%] [G loss: 0.840805]\n",
      "epoch:20 step:15674 [D loss: 0.720067, acc.: 47.66%] [G loss: 0.740490]\n",
      "epoch:20 step:15675 [D loss: 0.698431, acc.: 52.34%] [G loss: 0.817666]\n",
      "epoch:20 step:15676 [D loss: 0.690654, acc.: 55.47%] [G loss: 0.774965]\n",
      "epoch:20 step:15677 [D loss: 0.681320, acc.: 57.03%] [G loss: 0.739779]\n",
      "epoch:20 step:15678 [D loss: 0.663403, acc.: 59.38%] [G loss: 0.790400]\n",
      "epoch:20 step:15679 [D loss: 0.657741, acc.: 62.50%] [G loss: 0.861549]\n",
      "epoch:20 step:15680 [D loss: 0.682651, acc.: 54.69%] [G loss: 0.786901]\n",
      "epoch:20 step:15681 [D loss: 0.692802, acc.: 57.03%] [G loss: 0.834822]\n",
      "epoch:20 step:15682 [D loss: 0.700177, acc.: 57.81%] [G loss: 0.843086]\n",
      "epoch:20 step:15683 [D loss: 0.682000, acc.: 55.47%] [G loss: 0.828648]\n",
      "epoch:20 step:15684 [D loss: 0.713275, acc.: 43.75%] [G loss: 0.774045]\n",
      "epoch:20 step:15685 [D loss: 0.702801, acc.: 54.69%] [G loss: 0.830785]\n",
      "epoch:20 step:15686 [D loss: 0.726617, acc.: 48.44%] [G loss: 0.785150]\n",
      "epoch:20 step:15687 [D loss: 0.698721, acc.: 50.00%] [G loss: 0.785232]\n",
      "epoch:20 step:15688 [D loss: 0.691883, acc.: 58.59%] [G loss: 0.857051]\n",
      "epoch:20 step:15689 [D loss: 0.737147, acc.: 42.97%] [G loss: 0.737010]\n",
      "epoch:20 step:15690 [D loss: 0.739792, acc.: 43.75%] [G loss: 0.742799]\n",
      "epoch:20 step:15691 [D loss: 0.684315, acc.: 56.25%] [G loss: 0.770766]\n",
      "epoch:20 step:15692 [D loss: 0.680292, acc.: 56.25%] [G loss: 0.725194]\n",
      "epoch:20 step:15693 [D loss: 0.655948, acc.: 66.41%] [G loss: 0.745345]\n",
      "epoch:20 step:15694 [D loss: 0.658718, acc.: 58.59%] [G loss: 0.806830]\n",
      "epoch:20 step:15695 [D loss: 0.619463, acc.: 70.31%] [G loss: 0.745931]\n",
      "epoch:20 step:15696 [D loss: 0.635986, acc.: 63.28%] [G loss: 0.786754]\n",
      "epoch:20 step:15697 [D loss: 0.754983, acc.: 46.09%] [G loss: 0.749488]\n",
      "epoch:20 step:15698 [D loss: 0.684504, acc.: 57.03%] [G loss: 0.777175]\n",
      "epoch:20 step:15699 [D loss: 0.650839, acc.: 68.75%] [G loss: 0.860790]\n",
      "epoch:20 step:15700 [D loss: 0.747118, acc.: 42.19%] [G loss: 0.758743]\n",
      "epoch:20 step:15701 [D loss: 0.672044, acc.: 58.59%] [G loss: 0.840485]\n",
      "epoch:20 step:15702 [D loss: 0.676666, acc.: 53.12%] [G loss: 0.787738]\n",
      "epoch:20 step:15703 [D loss: 0.707195, acc.: 51.56%] [G loss: 0.748026]\n",
      "epoch:20 step:15704 [D loss: 0.661643, acc.: 62.50%] [G loss: 0.715120]\n",
      "epoch:20 step:15705 [D loss: 0.700141, acc.: 51.56%] [G loss: 0.702867]\n",
      "epoch:20 step:15706 [D loss: 0.690148, acc.: 56.25%] [G loss: 0.765413]\n",
      "epoch:20 step:15707 [D loss: 0.735597, acc.: 42.97%] [G loss: 0.710148]\n",
      "epoch:20 step:15708 [D loss: 0.721016, acc.: 42.97%] [G loss: 0.675488]\n",
      "epoch:20 step:15709 [D loss: 0.674108, acc.: 60.16%] [G loss: 0.732846]\n",
      "epoch:20 step:15710 [D loss: 0.690298, acc.: 57.03%] [G loss: 0.797841]\n",
      "epoch:20 step:15711 [D loss: 0.714284, acc.: 51.56%] [G loss: 0.798172]\n",
      "epoch:20 step:15712 [D loss: 0.707548, acc.: 51.56%] [G loss: 0.783144]\n",
      "epoch:20 step:15713 [D loss: 0.678157, acc.: 60.94%] [G loss: 0.819286]\n",
      "epoch:20 step:15714 [D loss: 0.665009, acc.: 59.38%] [G loss: 0.775743]\n",
      "epoch:20 step:15715 [D loss: 0.729352, acc.: 39.84%] [G loss: 0.864273]\n",
      "epoch:20 step:15716 [D loss: 0.681517, acc.: 57.81%] [G loss: 0.860404]\n",
      "epoch:20 step:15717 [D loss: 0.722027, acc.: 39.84%] [G loss: 0.822054]\n",
      "epoch:20 step:15718 [D loss: 0.703837, acc.: 53.91%] [G loss: 0.773542]\n",
      "epoch:20 step:15719 [D loss: 0.688596, acc.: 52.34%] [G loss: 0.816670]\n",
      "epoch:20 step:15720 [D loss: 0.664526, acc.: 56.25%] [G loss: 0.876923]\n",
      "epoch:20 step:15721 [D loss: 0.720093, acc.: 43.75%] [G loss: 0.815877]\n",
      "epoch:20 step:15722 [D loss: 0.719572, acc.: 42.19%] [G loss: 0.759909]\n",
      "epoch:20 step:15723 [D loss: 0.704431, acc.: 50.00%] [G loss: 0.788809]\n",
      "epoch:20 step:15724 [D loss: 0.692296, acc.: 53.12%] [G loss: 0.745535]\n",
      "epoch:20 step:15725 [D loss: 0.721448, acc.: 44.53%] [G loss: 0.725711]\n",
      "epoch:20 step:15726 [D loss: 0.696109, acc.: 50.00%] [G loss: 0.770989]\n",
      "epoch:20 step:15727 [D loss: 0.699002, acc.: 46.09%] [G loss: 0.727537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15728 [D loss: 0.789588, acc.: 35.94%] [G loss: 0.663778]\n",
      "epoch:20 step:15729 [D loss: 0.700942, acc.: 55.47%] [G loss: 0.685468]\n",
      "epoch:20 step:15730 [D loss: 0.697595, acc.: 54.69%] [G loss: 0.712124]\n",
      "epoch:20 step:15731 [D loss: 0.701350, acc.: 52.34%] [G loss: 0.744268]\n",
      "epoch:20 step:15732 [D loss: 0.697631, acc.: 46.09%] [G loss: 0.634678]\n",
      "epoch:20 step:15733 [D loss: 0.696608, acc.: 52.34%] [G loss: 0.703121]\n",
      "epoch:20 step:15734 [D loss: 0.645467, acc.: 70.31%] [G loss: 0.702218]\n",
      "epoch:20 step:15735 [D loss: 0.725657, acc.: 44.53%] [G loss: 0.696968]\n",
      "epoch:20 step:15736 [D loss: 0.721604, acc.: 42.97%] [G loss: 0.755587]\n",
      "epoch:20 step:15737 [D loss: 0.694754, acc.: 49.22%] [G loss: 0.705989]\n",
      "epoch:20 step:15738 [D loss: 0.680219, acc.: 54.69%] [G loss: 0.708398]\n",
      "epoch:20 step:15739 [D loss: 0.695594, acc.: 52.34%] [G loss: 0.763114]\n",
      "epoch:20 step:15740 [D loss: 0.709309, acc.: 50.78%] [G loss: 0.710330]\n",
      "epoch:20 step:15741 [D loss: 0.703431, acc.: 43.75%] [G loss: 0.705039]\n",
      "epoch:20 step:15742 [D loss: 0.740648, acc.: 41.41%] [G loss: 0.735351]\n",
      "epoch:20 step:15743 [D loss: 0.725216, acc.: 39.84%] [G loss: 0.738790]\n",
      "epoch:20 step:15744 [D loss: 0.679231, acc.: 53.12%] [G loss: 0.700097]\n",
      "epoch:20 step:15745 [D loss: 0.737893, acc.: 40.62%] [G loss: 0.705103]\n",
      "epoch:20 step:15746 [D loss: 0.722445, acc.: 44.53%] [G loss: 0.703933]\n",
      "epoch:20 step:15747 [D loss: 0.703821, acc.: 52.34%] [G loss: 0.670408]\n",
      "epoch:20 step:15748 [D loss: 0.694472, acc.: 53.12%] [G loss: 0.716983]\n",
      "epoch:20 step:15749 [D loss: 0.709284, acc.: 47.66%] [G loss: 0.726861]\n",
      "epoch:20 step:15750 [D loss: 0.706239, acc.: 48.44%] [G loss: 0.775069]\n",
      "epoch:20 step:15751 [D loss: 0.671886, acc.: 60.94%] [G loss: 0.753975]\n",
      "epoch:20 step:15752 [D loss: 0.737634, acc.: 37.50%] [G loss: 0.794738]\n",
      "epoch:20 step:15753 [D loss: 0.673939, acc.: 55.47%] [G loss: 0.766541]\n",
      "epoch:20 step:15754 [D loss: 0.659465, acc.: 62.50%] [G loss: 0.772496]\n",
      "epoch:20 step:15755 [D loss: 0.731749, acc.: 46.09%] [G loss: 0.785651]\n",
      "epoch:20 step:15756 [D loss: 0.668784, acc.: 55.47%] [G loss: 0.752046]\n",
      "epoch:20 step:15757 [D loss: 0.696725, acc.: 52.34%] [G loss: 0.772830]\n",
      "epoch:20 step:15758 [D loss: 0.678645, acc.: 52.34%] [G loss: 0.759549]\n",
      "epoch:20 step:15759 [D loss: 0.675544, acc.: 58.59%] [G loss: 0.752411]\n",
      "epoch:20 step:15760 [D loss: 0.707892, acc.: 46.09%] [G loss: 0.729471]\n",
      "epoch:20 step:15761 [D loss: 0.663083, acc.: 58.59%] [G loss: 0.744214]\n",
      "epoch:20 step:15762 [D loss: 0.717373, acc.: 46.09%] [G loss: 0.747289]\n",
      "epoch:20 step:15763 [D loss: 0.709764, acc.: 49.22%] [G loss: 0.777056]\n",
      "epoch:20 step:15764 [D loss: 0.668390, acc.: 60.16%] [G loss: 0.730259]\n",
      "epoch:20 step:15765 [D loss: 0.664258, acc.: 68.75%] [G loss: 0.828959]\n",
      "epoch:20 step:15766 [D loss: 0.698687, acc.: 48.44%] [G loss: 0.770951]\n",
      "epoch:20 step:15767 [D loss: 0.710704, acc.: 53.12%] [G loss: 0.808421]\n",
      "epoch:20 step:15768 [D loss: 0.688773, acc.: 56.25%] [G loss: 0.773185]\n",
      "epoch:20 step:15769 [D loss: 0.736536, acc.: 39.06%] [G loss: 0.728654]\n",
      "epoch:20 step:15770 [D loss: 0.699379, acc.: 54.69%] [G loss: 0.731444]\n",
      "epoch:20 step:15771 [D loss: 0.673050, acc.: 57.03%] [G loss: 0.765199]\n",
      "epoch:20 step:15772 [D loss: 0.691787, acc.: 50.78%] [G loss: 0.776591]\n",
      "epoch:20 step:15773 [D loss: 0.717497, acc.: 53.91%] [G loss: 0.686154]\n",
      "epoch:20 step:15774 [D loss: 0.727305, acc.: 43.75%] [G loss: 0.716503]\n",
      "epoch:20 step:15775 [D loss: 0.689337, acc.: 55.47%] [G loss: 0.714693]\n",
      "epoch:20 step:15776 [D loss: 0.738684, acc.: 38.28%] [G loss: 0.719894]\n",
      "epoch:20 step:15777 [D loss: 0.669432, acc.: 59.38%] [G loss: 0.753518]\n",
      "epoch:20 step:15778 [D loss: 0.640749, acc.: 68.75%] [G loss: 0.786287]\n",
      "epoch:20 step:15779 [D loss: 0.718075, acc.: 44.53%] [G loss: 0.724390]\n",
      "epoch:20 step:15780 [D loss: 0.678611, acc.: 56.25%] [G loss: 0.727581]\n",
      "epoch:20 step:15781 [D loss: 0.697636, acc.: 46.09%] [G loss: 0.716988]\n",
      "epoch:20 step:15782 [D loss: 0.694758, acc.: 46.88%] [G loss: 0.800671]\n",
      "epoch:20 step:15783 [D loss: 0.692070, acc.: 57.03%] [G loss: 0.715302]\n",
      "epoch:20 step:15784 [D loss: 0.728215, acc.: 45.31%] [G loss: 0.829839]\n",
      "epoch:20 step:15785 [D loss: 0.727660, acc.: 40.62%] [G loss: 0.870870]\n",
      "epoch:20 step:15786 [D loss: 0.724926, acc.: 45.31%] [G loss: 0.812038]\n",
      "epoch:20 step:15787 [D loss: 0.728731, acc.: 45.31%] [G loss: 0.765729]\n",
      "epoch:20 step:15788 [D loss: 0.686408, acc.: 49.22%] [G loss: 0.792352]\n",
      "epoch:20 step:15789 [D loss: 0.732304, acc.: 46.88%] [G loss: 0.788989]\n",
      "epoch:20 step:15790 [D loss: 0.668600, acc.: 63.28%] [G loss: 0.799745]\n",
      "epoch:20 step:15791 [D loss: 0.695876, acc.: 56.25%] [G loss: 0.837366]\n",
      "epoch:20 step:15792 [D loss: 0.693118, acc.: 56.25%] [G loss: 0.812247]\n",
      "epoch:20 step:15793 [D loss: 0.716736, acc.: 39.84%] [G loss: 0.856648]\n",
      "epoch:20 step:15794 [D loss: 0.686559, acc.: 50.78%] [G loss: 0.830084]\n",
      "epoch:20 step:15795 [D loss: 0.698093, acc.: 46.88%] [G loss: 0.766642]\n",
      "epoch:20 step:15796 [D loss: 0.694166, acc.: 56.25%] [G loss: 0.784837]\n",
      "epoch:20 step:15797 [D loss: 0.713192, acc.: 50.78%] [G loss: 0.805337]\n",
      "epoch:20 step:15798 [D loss: 0.702799, acc.: 48.44%] [G loss: 0.733165]\n",
      "epoch:20 step:15799 [D loss: 0.651037, acc.: 72.66%] [G loss: 0.789842]\n",
      "epoch:20 step:15800 [D loss: 0.657509, acc.: 60.16%] [G loss: 0.823626]\n",
      "epoch:20 step:15801 [D loss: 0.660467, acc.: 63.28%] [G loss: 0.799692]\n",
      "epoch:20 step:15802 [D loss: 0.783274, acc.: 32.81%] [G loss: 0.760573]\n",
      "epoch:20 step:15803 [D loss: 0.645934, acc.: 71.88%] [G loss: 0.775357]\n",
      "epoch:20 step:15804 [D loss: 0.641688, acc.: 63.28%] [G loss: 0.753615]\n",
      "epoch:20 step:15805 [D loss: 0.690718, acc.: 53.12%] [G loss: 0.714622]\n",
      "epoch:20 step:15806 [D loss: 0.693556, acc.: 51.56%] [G loss: 0.761174]\n",
      "epoch:20 step:15807 [D loss: 0.658011, acc.: 64.84%] [G loss: 0.768742]\n",
      "epoch:20 step:15808 [D loss: 0.710899, acc.: 53.12%] [G loss: 0.767618]\n",
      "epoch:20 step:15809 [D loss: 0.662297, acc.: 63.28%] [G loss: 0.751081]\n",
      "epoch:20 step:15810 [D loss: 0.717283, acc.: 49.22%] [G loss: 0.760175]\n",
      "epoch:20 step:15811 [D loss: 0.666090, acc.: 64.84%] [G loss: 0.759945]\n",
      "epoch:20 step:15812 [D loss: 0.702493, acc.: 49.22%] [G loss: 0.712804]\n",
      "epoch:20 step:15813 [D loss: 0.700348, acc.: 47.66%] [G loss: 0.725667]\n",
      "epoch:20 step:15814 [D loss: 0.696517, acc.: 50.78%] [G loss: 0.782423]\n",
      "epoch:20 step:15815 [D loss: 0.706088, acc.: 53.91%] [G loss: 0.721389]\n",
      "epoch:20 step:15816 [D loss: 0.682018, acc.: 57.03%] [G loss: 0.793562]\n",
      "epoch:20 step:15817 [D loss: 0.711625, acc.: 46.88%] [G loss: 0.744492]\n",
      "epoch:20 step:15818 [D loss: 0.682403, acc.: 52.34%] [G loss: 0.788816]\n",
      "epoch:20 step:15819 [D loss: 0.659223, acc.: 60.16%] [G loss: 0.774843]\n",
      "epoch:20 step:15820 [D loss: 0.673694, acc.: 61.72%] [G loss: 0.739628]\n",
      "epoch:20 step:15821 [D loss: 0.725330, acc.: 42.97%] [G loss: 0.684486]\n",
      "epoch:20 step:15822 [D loss: 0.683944, acc.: 53.12%] [G loss: 0.764986]\n",
      "epoch:20 step:15823 [D loss: 0.682770, acc.: 60.16%] [G loss: 0.759760]\n",
      "epoch:20 step:15824 [D loss: 0.696645, acc.: 53.12%] [G loss: 0.782565]\n",
      "epoch:20 step:15825 [D loss: 0.741539, acc.: 38.28%] [G loss: 0.741118]\n",
      "epoch:20 step:15826 [D loss: 0.711866, acc.: 42.97%] [G loss: 0.716443]\n",
      "epoch:20 step:15827 [D loss: 0.654926, acc.: 71.09%] [G loss: 0.738503]\n",
      "epoch:20 step:15828 [D loss: 0.721978, acc.: 50.00%] [G loss: 0.768937]\n",
      "epoch:20 step:15829 [D loss: 0.712832, acc.: 50.78%] [G loss: 0.756099]\n",
      "epoch:20 step:15830 [D loss: 0.703826, acc.: 53.12%] [G loss: 0.810391]\n",
      "epoch:20 step:15831 [D loss: 0.723411, acc.: 41.41%] [G loss: 0.753409]\n",
      "epoch:20 step:15832 [D loss: 0.687036, acc.: 50.78%] [G loss: 0.772219]\n",
      "epoch:20 step:15833 [D loss: 0.715097, acc.: 45.31%] [G loss: 0.736806]\n",
      "epoch:20 step:15834 [D loss: 0.719957, acc.: 47.66%] [G loss: 0.778993]\n",
      "epoch:20 step:15835 [D loss: 0.661545, acc.: 62.50%] [G loss: 0.725988]\n",
      "epoch:20 step:15836 [D loss: 0.686563, acc.: 58.59%] [G loss: 0.730048]\n",
      "epoch:20 step:15837 [D loss: 0.653655, acc.: 61.72%] [G loss: 0.685836]\n",
      "epoch:20 step:15838 [D loss: 0.699922, acc.: 48.44%] [G loss: 0.723786]\n",
      "epoch:20 step:15839 [D loss: 0.666462, acc.: 64.84%] [G loss: 0.735690]\n",
      "epoch:20 step:15840 [D loss: 0.718919, acc.: 42.97%] [G loss: 0.732958]\n",
      "epoch:20 step:15841 [D loss: 0.727279, acc.: 50.78%] [G loss: 0.701732]\n",
      "epoch:20 step:15842 [D loss: 0.681718, acc.: 56.25%] [G loss: 0.773815]\n",
      "epoch:20 step:15843 [D loss: 0.746976, acc.: 41.41%] [G loss: 0.745390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15844 [D loss: 0.724267, acc.: 47.66%] [G loss: 0.755075]\n",
      "epoch:20 step:15845 [D loss: 0.714439, acc.: 46.88%] [G loss: 0.763357]\n",
      "epoch:20 step:15846 [D loss: 0.692783, acc.: 60.94%] [G loss: 0.811343]\n",
      "epoch:20 step:15847 [D loss: 0.716566, acc.: 46.09%] [G loss: 0.699767]\n",
      "epoch:20 step:15848 [D loss: 0.718148, acc.: 47.66%] [G loss: 0.791913]\n",
      "epoch:20 step:15849 [D loss: 0.719559, acc.: 42.19%] [G loss: 0.734956]\n",
      "epoch:20 step:15850 [D loss: 0.692748, acc.: 54.69%] [G loss: 0.734489]\n",
      "epoch:20 step:15851 [D loss: 0.683726, acc.: 51.56%] [G loss: 0.745163]\n",
      "epoch:20 step:15852 [D loss: 0.713196, acc.: 50.00%] [G loss: 0.775879]\n",
      "epoch:20 step:15853 [D loss: 0.664360, acc.: 62.50%] [G loss: 0.742209]\n",
      "epoch:20 step:15854 [D loss: 0.757920, acc.: 38.28%] [G loss: 0.701012]\n",
      "epoch:20 step:15855 [D loss: 0.751895, acc.: 45.31%] [G loss: 0.715454]\n",
      "epoch:20 step:15856 [D loss: 0.707410, acc.: 46.88%] [G loss: 0.690377]\n",
      "epoch:20 step:15857 [D loss: 0.696215, acc.: 53.12%] [G loss: 0.697117]\n",
      "epoch:20 step:15858 [D loss: 0.711462, acc.: 42.19%] [G loss: 0.719265]\n",
      "epoch:20 step:15859 [D loss: 0.656978, acc.: 61.72%] [G loss: 0.775123]\n",
      "epoch:20 step:15860 [D loss: 0.722956, acc.: 41.41%] [G loss: 0.758794]\n",
      "epoch:20 step:15861 [D loss: 0.675973, acc.: 55.47%] [G loss: 0.812502]\n",
      "epoch:20 step:15862 [D loss: 0.731804, acc.: 38.28%] [G loss: 0.704621]\n",
      "epoch:20 step:15863 [D loss: 0.712748, acc.: 44.53%] [G loss: 0.801527]\n",
      "epoch:20 step:15864 [D loss: 0.667730, acc.: 61.72%] [G loss: 0.765527]\n",
      "epoch:20 step:15865 [D loss: 0.720459, acc.: 46.09%] [G loss: 0.781036]\n",
      "epoch:20 step:15866 [D loss: 0.678276, acc.: 56.25%] [G loss: 0.778493]\n",
      "epoch:20 step:15867 [D loss: 0.705779, acc.: 46.09%] [G loss: 0.757692]\n",
      "epoch:20 step:15868 [D loss: 0.689945, acc.: 54.69%] [G loss: 0.752891]\n",
      "epoch:20 step:15869 [D loss: 0.678017, acc.: 60.16%] [G loss: 0.739140]\n",
      "epoch:20 step:15870 [D loss: 0.726354, acc.: 42.97%] [G loss: 0.709329]\n",
      "epoch:20 step:15871 [D loss: 0.656339, acc.: 58.59%] [G loss: 0.777050]\n",
      "epoch:20 step:15872 [D loss: 0.674296, acc.: 59.38%] [G loss: 0.755521]\n",
      "epoch:20 step:15873 [D loss: 0.677551, acc.: 58.59%] [G loss: 0.757358]\n",
      "epoch:20 step:15874 [D loss: 0.732544, acc.: 43.75%] [G loss: 0.777467]\n",
      "epoch:20 step:15875 [D loss: 0.750242, acc.: 46.88%] [G loss: 0.756028]\n",
      "epoch:20 step:15876 [D loss: 0.677024, acc.: 56.25%] [G loss: 0.695666]\n",
      "epoch:20 step:15877 [D loss: 0.682409, acc.: 57.03%] [G loss: 0.732160]\n",
      "epoch:20 step:15878 [D loss: 0.696335, acc.: 51.56%] [G loss: 0.806354]\n",
      "epoch:20 step:15879 [D loss: 0.690952, acc.: 53.12%] [G loss: 0.796784]\n",
      "epoch:20 step:15880 [D loss: 0.682052, acc.: 53.91%] [G loss: 0.807043]\n",
      "epoch:20 step:15881 [D loss: 0.692683, acc.: 53.12%] [G loss: 0.786121]\n",
      "epoch:20 step:15882 [D loss: 0.680446, acc.: 52.34%] [G loss: 0.865708]\n",
      "epoch:20 step:15883 [D loss: 0.651539, acc.: 60.16%] [G loss: 0.845999]\n",
      "epoch:20 step:15884 [D loss: 0.703006, acc.: 50.78%] [G loss: 0.796345]\n",
      "epoch:20 step:15885 [D loss: 0.707424, acc.: 51.56%] [G loss: 0.729004]\n",
      "epoch:20 step:15886 [D loss: 0.699150, acc.: 48.44%] [G loss: 0.811206]\n",
      "epoch:20 step:15887 [D loss: 0.745139, acc.: 40.62%] [G loss: 0.758085]\n",
      "epoch:20 step:15888 [D loss: 0.681234, acc.: 53.91%] [G loss: 0.702165]\n",
      "epoch:20 step:15889 [D loss: 0.644754, acc.: 69.53%] [G loss: 0.740426]\n",
      "epoch:20 step:15890 [D loss: 0.731475, acc.: 42.19%] [G loss: 0.813191]\n",
      "epoch:20 step:15891 [D loss: 0.691031, acc.: 51.56%] [G loss: 0.734541]\n",
      "epoch:20 step:15892 [D loss: 0.652310, acc.: 66.41%] [G loss: 0.745334]\n",
      "epoch:20 step:15893 [D loss: 0.726195, acc.: 42.97%] [G loss: 0.741749]\n",
      "epoch:20 step:15894 [D loss: 0.695079, acc.: 55.47%] [G loss: 0.761520]\n",
      "epoch:20 step:15895 [D loss: 0.701200, acc.: 56.25%] [G loss: 0.714887]\n",
      "epoch:20 step:15896 [D loss: 0.681912, acc.: 59.38%] [G loss: 0.757984]\n",
      "epoch:20 step:15897 [D loss: 0.778145, acc.: 35.16%] [G loss: 0.699638]\n",
      "epoch:20 step:15898 [D loss: 0.704454, acc.: 46.88%] [G loss: 0.710357]\n",
      "epoch:20 step:15899 [D loss: 0.687694, acc.: 57.03%] [G loss: 0.764449]\n",
      "epoch:20 step:15900 [D loss: 0.698617, acc.: 48.44%] [G loss: 0.754002]\n",
      "epoch:20 step:15901 [D loss: 0.758037, acc.: 35.94%] [G loss: 0.679739]\n",
      "epoch:20 step:15902 [D loss: 0.696980, acc.: 53.91%] [G loss: 0.792110]\n",
      "epoch:20 step:15903 [D loss: 0.722818, acc.: 42.97%] [G loss: 0.770457]\n",
      "epoch:20 step:15904 [D loss: 0.691347, acc.: 50.78%] [G loss: 0.848934]\n",
      "epoch:20 step:15905 [D loss: 0.678376, acc.: 57.03%] [G loss: 0.801489]\n",
      "epoch:20 step:15906 [D loss: 0.629803, acc.: 69.53%] [G loss: 0.830216]\n",
      "epoch:20 step:15907 [D loss: 0.710122, acc.: 50.78%] [G loss: 0.851165]\n",
      "epoch:20 step:15908 [D loss: 0.697068, acc.: 52.34%] [G loss: 0.772648]\n",
      "epoch:20 step:15909 [D loss: 0.695666, acc.: 48.44%] [G loss: 0.764377]\n",
      "epoch:20 step:15910 [D loss: 0.656417, acc.: 64.06%] [G loss: 0.818864]\n",
      "epoch:20 step:15911 [D loss: 0.712276, acc.: 44.53%] [G loss: 0.808385]\n",
      "epoch:20 step:15912 [D loss: 0.715427, acc.: 50.78%] [G loss: 0.744492]\n",
      "epoch:20 step:15913 [D loss: 0.693631, acc.: 55.47%] [G loss: 0.735594]\n",
      "epoch:20 step:15914 [D loss: 0.666175, acc.: 64.06%] [G loss: 0.749133]\n",
      "epoch:20 step:15915 [D loss: 0.673807, acc.: 59.38%] [G loss: 0.722857]\n",
      "epoch:20 step:15916 [D loss: 0.705580, acc.: 43.75%] [G loss: 0.732705]\n",
      "epoch:20 step:15917 [D loss: 0.691671, acc.: 55.47%] [G loss: 0.760272]\n",
      "epoch:20 step:15918 [D loss: 0.711464, acc.: 48.44%] [G loss: 0.699650]\n",
      "epoch:20 step:15919 [D loss: 0.677874, acc.: 57.81%] [G loss: 0.750489]\n",
      "epoch:20 step:15920 [D loss: 0.707969, acc.: 51.56%] [G loss: 0.710308]\n",
      "epoch:20 step:15921 [D loss: 0.669908, acc.: 57.03%] [G loss: 0.720342]\n",
      "epoch:20 step:15922 [D loss: 0.702941, acc.: 58.59%] [G loss: 0.741009]\n",
      "epoch:20 step:15923 [D loss: 0.758852, acc.: 31.25%] [G loss: 0.682476]\n",
      "epoch:20 step:15924 [D loss: 0.716089, acc.: 42.97%] [G loss: 0.761540]\n",
      "epoch:20 step:15925 [D loss: 0.723962, acc.: 39.84%] [G loss: 0.776178]\n",
      "epoch:20 step:15926 [D loss: 0.713428, acc.: 52.34%] [G loss: 0.778583]\n",
      "epoch:20 step:15927 [D loss: 0.714721, acc.: 44.53%] [G loss: 0.674890]\n",
      "epoch:20 step:15928 [D loss: 0.644302, acc.: 66.41%] [G loss: 0.739403]\n",
      "epoch:20 step:15929 [D loss: 0.679103, acc.: 55.47%] [G loss: 0.817504]\n",
      "epoch:20 step:15930 [D loss: 0.702511, acc.: 50.00%] [G loss: 0.737079]\n",
      "epoch:20 step:15931 [D loss: 0.724347, acc.: 50.78%] [G loss: 0.774250]\n",
      "epoch:20 step:15932 [D loss: 0.675456, acc.: 58.59%] [G loss: 0.845843]\n",
      "epoch:20 step:15933 [D loss: 0.681187, acc.: 62.50%] [G loss: 0.747386]\n",
      "epoch:20 step:15934 [D loss: 0.691900, acc.: 57.03%] [G loss: 0.787238]\n",
      "epoch:20 step:15935 [D loss: 0.700440, acc.: 51.56%] [G loss: 0.746374]\n",
      "epoch:20 step:15936 [D loss: 0.698640, acc.: 52.34%] [G loss: 0.758961]\n",
      "epoch:20 step:15937 [D loss: 0.756567, acc.: 35.94%] [G loss: 0.715642]\n",
      "epoch:20 step:15938 [D loss: 0.669619, acc.: 64.84%] [G loss: 0.760075]\n",
      "epoch:20 step:15939 [D loss: 0.674482, acc.: 60.16%] [G loss: 0.722208]\n",
      "epoch:20 step:15940 [D loss: 0.755241, acc.: 32.03%] [G loss: 0.754077]\n",
      "epoch:20 step:15941 [D loss: 0.726735, acc.: 46.88%] [G loss: 0.738485]\n",
      "epoch:20 step:15942 [D loss: 0.708616, acc.: 46.88%] [G loss: 0.755836]\n",
      "epoch:20 step:15943 [D loss: 0.687056, acc.: 53.91%] [G loss: 0.729666]\n",
      "epoch:20 step:15944 [D loss: 0.687357, acc.: 56.25%] [G loss: 0.803871]\n",
      "epoch:20 step:15945 [D loss: 0.719004, acc.: 40.62%] [G loss: 0.781118]\n",
      "epoch:20 step:15946 [D loss: 0.662685, acc.: 60.94%] [G loss: 0.766460]\n",
      "epoch:20 step:15947 [D loss: 0.693559, acc.: 50.78%] [G loss: 0.782780]\n",
      "epoch:20 step:15948 [D loss: 0.716790, acc.: 50.00%] [G loss: 0.799467]\n",
      "epoch:20 step:15949 [D loss: 0.722298, acc.: 48.44%] [G loss: 0.788972]\n",
      "epoch:20 step:15950 [D loss: 0.691533, acc.: 57.03%] [G loss: 0.742266]\n",
      "epoch:20 step:15951 [D loss: 0.748273, acc.: 40.62%] [G loss: 0.756628]\n",
      "epoch:20 step:15952 [D loss: 0.660187, acc.: 62.50%] [G loss: 0.730807]\n",
      "epoch:20 step:15953 [D loss: 0.694126, acc.: 52.34%] [G loss: 0.783704]\n",
      "epoch:20 step:15954 [D loss: 0.726917, acc.: 39.84%] [G loss: 0.743283]\n",
      "epoch:20 step:15955 [D loss: 0.705888, acc.: 47.66%] [G loss: 0.750246]\n",
      "epoch:20 step:15956 [D loss: 0.718889, acc.: 48.44%] [G loss: 0.725733]\n",
      "epoch:20 step:15957 [D loss: 0.709685, acc.: 46.88%] [G loss: 0.715966]\n",
      "epoch:20 step:15958 [D loss: 0.712968, acc.: 41.41%] [G loss: 0.713009]\n",
      "epoch:20 step:15959 [D loss: 0.761070, acc.: 33.59%] [G loss: 0.676699]\n",
      "epoch:20 step:15960 [D loss: 0.718538, acc.: 48.44%] [G loss: 0.750551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15961 [D loss: 0.710924, acc.: 50.78%] [G loss: 0.745330]\n",
      "epoch:20 step:15962 [D loss: 0.702616, acc.: 54.69%] [G loss: 0.760446]\n",
      "epoch:20 step:15963 [D loss: 0.718073, acc.: 46.88%] [G loss: 0.731320]\n",
      "epoch:20 step:15964 [D loss: 0.651532, acc.: 58.59%] [G loss: 0.738697]\n",
      "epoch:20 step:15965 [D loss: 0.743243, acc.: 39.06%] [G loss: 0.717047]\n",
      "epoch:20 step:15966 [D loss: 0.677836, acc.: 55.47%] [G loss: 0.736368]\n",
      "epoch:20 step:15967 [D loss: 0.692613, acc.: 51.56%] [G loss: 0.785733]\n",
      "epoch:20 step:15968 [D loss: 0.681099, acc.: 52.34%] [G loss: 0.759945]\n",
      "epoch:20 step:15969 [D loss: 0.662864, acc.: 66.41%] [G loss: 0.831462]\n",
      "epoch:20 step:15970 [D loss: 0.663102, acc.: 59.38%] [G loss: 0.784678]\n",
      "epoch:20 step:15971 [D loss: 0.685168, acc.: 53.12%] [G loss: 0.842170]\n",
      "epoch:20 step:15972 [D loss: 0.650717, acc.: 66.41%] [G loss: 0.782186]\n",
      "epoch:20 step:15973 [D loss: 0.656105, acc.: 64.06%] [G loss: 0.817171]\n",
      "epoch:20 step:15974 [D loss: 0.654737, acc.: 64.84%] [G loss: 0.862859]\n",
      "epoch:20 step:15975 [D loss: 0.723167, acc.: 40.62%] [G loss: 0.718022]\n",
      "epoch:20 step:15976 [D loss: 0.693747, acc.: 50.78%] [G loss: 0.755608]\n",
      "epoch:20 step:15977 [D loss: 0.696394, acc.: 59.38%] [G loss: 0.701855]\n",
      "epoch:20 step:15978 [D loss: 0.715524, acc.: 45.31%] [G loss: 0.685809]\n",
      "epoch:20 step:15979 [D loss: 0.679112, acc.: 57.81%] [G loss: 0.793816]\n",
      "epoch:20 step:15980 [D loss: 0.679179, acc.: 57.03%] [G loss: 0.745688]\n",
      "epoch:20 step:15981 [D loss: 0.644461, acc.: 67.97%] [G loss: 0.756474]\n",
      "epoch:20 step:15982 [D loss: 0.681484, acc.: 53.91%] [G loss: 0.661589]\n",
      "epoch:20 step:15983 [D loss: 0.693474, acc.: 55.47%] [G loss: 0.665497]\n",
      "epoch:20 step:15984 [D loss: 0.699711, acc.: 49.22%] [G loss: 0.671233]\n",
      "epoch:20 step:15985 [D loss: 0.647035, acc.: 67.97%] [G loss: 0.669830]\n",
      "epoch:20 step:15986 [D loss: 0.715971, acc.: 42.97%] [G loss: 0.661953]\n",
      "epoch:20 step:15987 [D loss: 0.701307, acc.: 50.78%] [G loss: 0.695482]\n",
      "epoch:20 step:15988 [D loss: 0.706950, acc.: 48.44%] [G loss: 0.691990]\n",
      "epoch:20 step:15989 [D loss: 0.744795, acc.: 35.94%] [G loss: 0.699443]\n",
      "epoch:20 step:15990 [D loss: 0.691629, acc.: 51.56%] [G loss: 0.729327]\n",
      "epoch:20 step:15991 [D loss: 0.683074, acc.: 57.81%] [G loss: 0.747447]\n",
      "epoch:20 step:15992 [D loss: 0.704516, acc.: 49.22%] [G loss: 0.832057]\n",
      "epoch:20 step:15993 [D loss: 0.720914, acc.: 48.44%] [G loss: 0.893317]\n",
      "epoch:20 step:15994 [D loss: 0.691396, acc.: 52.34%] [G loss: 0.790217]\n",
      "epoch:20 step:15995 [D loss: 0.743307, acc.: 45.31%] [G loss: 0.872471]\n",
      "epoch:20 step:15996 [D loss: 0.668723, acc.: 57.81%] [G loss: 0.801216]\n",
      "epoch:20 step:15997 [D loss: 0.693528, acc.: 54.69%] [G loss: 0.827266]\n",
      "epoch:20 step:15998 [D loss: 0.666972, acc.: 65.62%] [G loss: 0.804443]\n",
      "epoch:20 step:15999 [D loss: 0.664658, acc.: 67.97%] [G loss: 0.799009]\n",
      "epoch:20 step:16000 [D loss: 0.673326, acc.: 59.38%] [G loss: 0.708287]\n",
      "epoch:20 step:16001 [D loss: 0.600046, acc.: 78.12%] [G loss: 0.809692]\n",
      "epoch:20 step:16002 [D loss: 0.706030, acc.: 54.69%] [G loss: 0.793261]\n",
      "epoch:20 step:16003 [D loss: 0.717281, acc.: 41.41%] [G loss: 0.707445]\n",
      "epoch:20 step:16004 [D loss: 0.723979, acc.: 43.75%] [G loss: 0.752569]\n",
      "epoch:20 step:16005 [D loss: 0.694472, acc.: 56.25%] [G loss: 0.767623]\n",
      "epoch:20 step:16006 [D loss: 0.708905, acc.: 46.09%] [G loss: 0.738399]\n",
      "epoch:20 step:16007 [D loss: 0.708964, acc.: 47.66%] [G loss: 0.738946]\n",
      "epoch:20 step:16008 [D loss: 0.747680, acc.: 38.28%] [G loss: 0.799198]\n",
      "epoch:20 step:16009 [D loss: 0.741682, acc.: 39.84%] [G loss: 0.735062]\n",
      "epoch:20 step:16010 [D loss: 0.689877, acc.: 55.47%] [G loss: 0.823780]\n",
      "epoch:20 step:16011 [D loss: 0.720062, acc.: 46.88%] [G loss: 0.762715]\n",
      "epoch:20 step:16012 [D loss: 0.696845, acc.: 51.56%] [G loss: 0.736647]\n",
      "epoch:20 step:16013 [D loss: 0.704458, acc.: 51.56%] [G loss: 0.717429]\n",
      "epoch:20 step:16014 [D loss: 0.689732, acc.: 55.47%] [G loss: 0.736367]\n",
      "epoch:20 step:16015 [D loss: 0.700249, acc.: 50.78%] [G loss: 0.751610]\n",
      "epoch:20 step:16016 [D loss: 0.688910, acc.: 52.34%] [G loss: 0.710421]\n",
      "epoch:20 step:16017 [D loss: 0.688528, acc.: 53.91%] [G loss: 0.751929]\n",
      "epoch:20 step:16018 [D loss: 0.694516, acc.: 53.12%] [G loss: 0.751421]\n",
      "epoch:20 step:16019 [D loss: 0.657393, acc.: 67.97%] [G loss: 0.730037]\n",
      "epoch:20 step:16020 [D loss: 0.719501, acc.: 48.44%] [G loss: 0.688382]\n",
      "epoch:20 step:16021 [D loss: 0.675593, acc.: 57.03%] [G loss: 0.702311]\n",
      "epoch:20 step:16022 [D loss: 0.694335, acc.: 53.91%] [G loss: 0.732375]\n",
      "epoch:20 step:16023 [D loss: 0.666863, acc.: 61.72%] [G loss: 0.706658]\n",
      "epoch:20 step:16024 [D loss: 0.677439, acc.: 56.25%] [G loss: 0.743533]\n",
      "epoch:20 step:16025 [D loss: 0.672106, acc.: 57.03%] [G loss: 0.787745]\n",
      "epoch:20 step:16026 [D loss: 0.717988, acc.: 45.31%] [G loss: 0.732724]\n",
      "epoch:20 step:16027 [D loss: 0.701406, acc.: 50.00%] [G loss: 0.729668]\n",
      "epoch:20 step:16028 [D loss: 0.704779, acc.: 49.22%] [G loss: 0.756532]\n",
      "epoch:20 step:16029 [D loss: 0.683953, acc.: 53.12%] [G loss: 0.748711]\n",
      "epoch:20 step:16030 [D loss: 0.696449, acc.: 50.78%] [G loss: 0.743967]\n",
      "epoch:20 step:16031 [D loss: 0.707040, acc.: 49.22%] [G loss: 0.751288]\n",
      "epoch:20 step:16032 [D loss: 0.722752, acc.: 37.50%] [G loss: 0.743126]\n",
      "epoch:20 step:16033 [D loss: 0.747370, acc.: 36.72%] [G loss: 0.706527]\n",
      "epoch:20 step:16034 [D loss: 0.700792, acc.: 53.91%] [G loss: 0.778275]\n",
      "epoch:20 step:16035 [D loss: 0.661831, acc.: 63.28%] [G loss: 0.795304]\n",
      "epoch:20 step:16036 [D loss: 0.690567, acc.: 46.09%] [G loss: 0.723145]\n",
      "epoch:20 step:16037 [D loss: 0.705403, acc.: 50.78%] [G loss: 0.705320]\n",
      "epoch:20 step:16038 [D loss: 0.701349, acc.: 55.47%] [G loss: 0.698692]\n",
      "epoch:20 step:16039 [D loss: 0.658111, acc.: 63.28%] [G loss: 0.777671]\n",
      "epoch:20 step:16040 [D loss: 0.680777, acc.: 54.69%] [G loss: 0.738001]\n",
      "epoch:20 step:16041 [D loss: 0.686996, acc.: 58.59%] [G loss: 0.731015]\n",
      "epoch:20 step:16042 [D loss: 0.676389, acc.: 56.25%] [G loss: 0.817566]\n",
      "epoch:20 step:16043 [D loss: 0.709655, acc.: 51.56%] [G loss: 0.809799]\n",
      "epoch:20 step:16044 [D loss: 0.721322, acc.: 46.09%] [G loss: 0.786092]\n",
      "epoch:20 step:16045 [D loss: 0.669033, acc.: 56.25%] [G loss: 0.691939]\n",
      "epoch:20 step:16046 [D loss: 0.695673, acc.: 49.22%] [G loss: 0.776515]\n",
      "epoch:20 step:16047 [D loss: 0.699503, acc.: 53.91%] [G loss: 0.790595]\n",
      "epoch:20 step:16048 [D loss: 0.709104, acc.: 45.31%] [G loss: 0.700277]\n",
      "epoch:20 step:16049 [D loss: 0.699540, acc.: 48.44%] [G loss: 0.673450]\n",
      "epoch:20 step:16050 [D loss: 0.702171, acc.: 56.25%] [G loss: 0.685465]\n",
      "epoch:20 step:16051 [D loss: 0.708509, acc.: 50.00%] [G loss: 0.721548]\n",
      "epoch:20 step:16052 [D loss: 0.649109, acc.: 68.75%] [G loss: 0.781730]\n",
      "epoch:20 step:16053 [D loss: 0.674847, acc.: 60.16%] [G loss: 0.727027]\n",
      "epoch:20 step:16054 [D loss: 0.706879, acc.: 46.88%] [G loss: 0.725223]\n",
      "epoch:20 step:16055 [D loss: 0.680654, acc.: 55.47%] [G loss: 0.727699]\n",
      "epoch:20 step:16056 [D loss: 0.741029, acc.: 37.50%] [G loss: 0.715829]\n",
      "epoch:20 step:16057 [D loss: 0.769025, acc.: 35.16%] [G loss: 0.716996]\n",
      "epoch:20 step:16058 [D loss: 0.695652, acc.: 53.12%] [G loss: 0.722553]\n",
      "epoch:20 step:16059 [D loss: 0.715097, acc.: 39.06%] [G loss: 0.768824]\n",
      "epoch:20 step:16060 [D loss: 0.714775, acc.: 42.19%] [G loss: 0.750801]\n",
      "epoch:20 step:16061 [D loss: 0.730244, acc.: 42.19%] [G loss: 0.833056]\n",
      "epoch:20 step:16062 [D loss: 0.683389, acc.: 60.94%] [G loss: 0.748376]\n",
      "epoch:20 step:16063 [D loss: 0.688729, acc.: 59.38%] [G loss: 0.753755]\n",
      "epoch:20 step:16064 [D loss: 0.697500, acc.: 45.31%] [G loss: 0.772881]\n",
      "epoch:20 step:16065 [D loss: 0.689574, acc.: 52.34%] [G loss: 0.790572]\n",
      "epoch:20 step:16066 [D loss: 0.730536, acc.: 48.44%] [G loss: 0.768222]\n",
      "epoch:20 step:16067 [D loss: 0.656070, acc.: 64.84%] [G loss: 0.775625]\n",
      "epoch:20 step:16068 [D loss: 0.723363, acc.: 54.69%] [G loss: 0.786368]\n",
      "epoch:20 step:16069 [D loss: 0.656130, acc.: 65.62%] [G loss: 0.756156]\n",
      "epoch:20 step:16070 [D loss: 0.660318, acc.: 64.84%] [G loss: 0.768573]\n",
      "epoch:20 step:16071 [D loss: 0.678069, acc.: 57.03%] [G loss: 0.763504]\n",
      "epoch:20 step:16072 [D loss: 0.648709, acc.: 63.28%] [G loss: 0.767439]\n",
      "epoch:20 step:16073 [D loss: 0.712323, acc.: 48.44%] [G loss: 0.789222]\n",
      "epoch:20 step:16074 [D loss: 0.681573, acc.: 53.91%] [G loss: 0.733849]\n",
      "epoch:20 step:16075 [D loss: 0.683197, acc.: 55.47%] [G loss: 0.803546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16076 [D loss: 0.655680, acc.: 63.28%] [G loss: 0.750499]\n",
      "epoch:20 step:16077 [D loss: 0.710404, acc.: 48.44%] [G loss: 0.703746]\n",
      "epoch:20 step:16078 [D loss: 0.677834, acc.: 56.25%] [G loss: 0.741410]\n",
      "epoch:20 step:16079 [D loss: 0.746945, acc.: 37.50%] [G loss: 0.734693]\n",
      "epoch:20 step:16080 [D loss: 0.713170, acc.: 53.12%] [G loss: 0.748421]\n",
      "epoch:20 step:16081 [D loss: 0.700913, acc.: 47.66%] [G loss: 0.798865]\n",
      "epoch:20 step:16082 [D loss: 0.674094, acc.: 54.69%] [G loss: 0.857026]\n",
      "epoch:20 step:16083 [D loss: 0.715182, acc.: 52.34%] [G loss: 0.785894]\n",
      "epoch:20 step:16084 [D loss: 0.672798, acc.: 61.72%] [G loss: 0.779403]\n",
      "epoch:20 step:16085 [D loss: 0.688936, acc.: 53.91%] [G loss: 0.792813]\n",
      "epoch:20 step:16086 [D loss: 0.634929, acc.: 71.09%] [G loss: 0.740304]\n",
      "epoch:20 step:16087 [D loss: 0.686007, acc.: 52.34%] [G loss: 0.773944]\n",
      "epoch:20 step:16088 [D loss: 0.685373, acc.: 50.78%] [G loss: 0.751280]\n",
      "epoch:20 step:16089 [D loss: 0.681965, acc.: 54.69%] [G loss: 0.832655]\n",
      "epoch:20 step:16090 [D loss: 0.702597, acc.: 52.34%] [G loss: 0.764247]\n",
      "epoch:20 step:16091 [D loss: 0.682864, acc.: 60.16%] [G loss: 0.787749]\n",
      "epoch:20 step:16092 [D loss: 0.705444, acc.: 56.25%] [G loss: 0.763982]\n",
      "epoch:20 step:16093 [D loss: 0.848467, acc.: 22.66%] [G loss: 0.727346]\n",
      "epoch:20 step:16094 [D loss: 0.678672, acc.: 54.69%] [G loss: 0.742834]\n",
      "epoch:20 step:16095 [D loss: 0.723647, acc.: 48.44%] [G loss: 0.712052]\n",
      "epoch:20 step:16096 [D loss: 0.697598, acc.: 52.34%] [G loss: 0.686020]\n",
      "epoch:20 step:16097 [D loss: 0.681335, acc.: 60.94%] [G loss: 0.734975]\n",
      "epoch:20 step:16098 [D loss: 0.686300, acc.: 53.12%] [G loss: 0.705786]\n",
      "epoch:20 step:16099 [D loss: 0.712260, acc.: 50.00%] [G loss: 0.809720]\n",
      "epoch:20 step:16100 [D loss: 0.681240, acc.: 61.72%] [G loss: 0.772083]\n",
      "epoch:20 step:16101 [D loss: 0.719681, acc.: 48.44%] [G loss: 0.686875]\n",
      "epoch:20 step:16102 [D loss: 0.733407, acc.: 41.41%] [G loss: 0.689120]\n",
      "epoch:20 step:16103 [D loss: 0.729584, acc.: 49.22%] [G loss: 0.725927]\n",
      "epoch:20 step:16104 [D loss: 0.698784, acc.: 55.47%] [G loss: 0.735239]\n",
      "epoch:20 step:16105 [D loss: 0.697381, acc.: 54.69%] [G loss: 0.722749]\n",
      "epoch:20 step:16106 [D loss: 0.705997, acc.: 43.75%] [G loss: 0.735172]\n",
      "epoch:20 step:16107 [D loss: 0.728302, acc.: 45.31%] [G loss: 0.730049]\n",
      "epoch:20 step:16108 [D loss: 0.673660, acc.: 53.12%] [G loss: 0.712984]\n",
      "epoch:20 step:16109 [D loss: 0.685293, acc.: 56.25%] [G loss: 0.723689]\n",
      "epoch:20 step:16110 [D loss: 0.669245, acc.: 60.94%] [G loss: 0.801977]\n",
      "epoch:20 step:16111 [D loss: 0.664425, acc.: 58.59%] [G loss: 0.804563]\n",
      "epoch:20 step:16112 [D loss: 0.673589, acc.: 58.59%] [G loss: 0.827043]\n",
      "epoch:20 step:16113 [D loss: 0.694830, acc.: 61.72%] [G loss: 0.804936]\n",
      "epoch:20 step:16114 [D loss: 0.641745, acc.: 63.28%] [G loss: 0.772566]\n",
      "epoch:20 step:16115 [D loss: 0.684612, acc.: 53.12%] [G loss: 0.776452]\n",
      "epoch:20 step:16116 [D loss: 0.666566, acc.: 64.06%] [G loss: 0.769368]\n",
      "epoch:20 step:16117 [D loss: 0.709044, acc.: 46.88%] [G loss: 0.762307]\n",
      "epoch:20 step:16118 [D loss: 0.678551, acc.: 60.16%] [G loss: 0.762175]\n",
      "epoch:20 step:16119 [D loss: 0.665581, acc.: 56.25%] [G loss: 0.753841]\n",
      "epoch:20 step:16120 [D loss: 0.694073, acc.: 50.78%] [G loss: 0.725674]\n",
      "epoch:20 step:16121 [D loss: 0.707495, acc.: 47.66%] [G loss: 0.695658]\n",
      "epoch:20 step:16122 [D loss: 0.682648, acc.: 54.69%] [G loss: 0.729368]\n",
      "epoch:20 step:16123 [D loss: 0.705458, acc.: 48.44%] [G loss: 0.725511]\n",
      "epoch:20 step:16124 [D loss: 0.690457, acc.: 51.56%] [G loss: 0.822406]\n",
      "epoch:20 step:16125 [D loss: 0.664732, acc.: 60.94%] [G loss: 0.756318]\n",
      "epoch:20 step:16126 [D loss: 0.684361, acc.: 57.81%] [G loss: 0.754868]\n",
      "epoch:20 step:16127 [D loss: 0.680535, acc.: 57.81%] [G loss: 0.830184]\n",
      "epoch:20 step:16128 [D loss: 0.716510, acc.: 46.09%] [G loss: 0.760331]\n",
      "epoch:20 step:16129 [D loss: 0.694654, acc.: 57.03%] [G loss: 0.715251]\n",
      "epoch:20 step:16130 [D loss: 0.676829, acc.: 58.59%] [G loss: 0.732687]\n",
      "epoch:20 step:16131 [D loss: 0.680122, acc.: 52.34%] [G loss: 0.699289]\n",
      "epoch:20 step:16132 [D loss: 0.705219, acc.: 47.66%] [G loss: 0.719476]\n",
      "epoch:20 step:16133 [D loss: 0.750364, acc.: 38.28%] [G loss: 0.694332]\n",
      "epoch:20 step:16134 [D loss: 0.737547, acc.: 42.19%] [G loss: 0.682997]\n",
      "epoch:20 step:16135 [D loss: 0.731736, acc.: 45.31%] [G loss: 0.717348]\n",
      "epoch:20 step:16136 [D loss: 0.718738, acc.: 45.31%] [G loss: 0.678599]\n",
      "epoch:20 step:16137 [D loss: 0.697211, acc.: 53.12%] [G loss: 0.785218]\n",
      "epoch:20 step:16138 [D loss: 0.688981, acc.: 55.47%] [G loss: 0.797637]\n",
      "epoch:20 step:16139 [D loss: 0.714343, acc.: 45.31%] [G loss: 0.777942]\n",
      "epoch:20 step:16140 [D loss: 0.683586, acc.: 50.00%] [G loss: 0.797350]\n",
      "epoch:20 step:16141 [D loss: 0.714944, acc.: 50.78%] [G loss: 0.680063]\n",
      "epoch:20 step:16142 [D loss: 0.756593, acc.: 31.25%] [G loss: 0.786157]\n",
      "epoch:20 step:16143 [D loss: 0.700214, acc.: 56.25%] [G loss: 0.789446]\n",
      "epoch:20 step:16144 [D loss: 0.671714, acc.: 55.47%] [G loss: 0.791168]\n",
      "epoch:20 step:16145 [D loss: 0.683673, acc.: 53.12%] [G loss: 0.846161]\n",
      "epoch:20 step:16146 [D loss: 0.751625, acc.: 39.84%] [G loss: 0.737534]\n",
      "epoch:20 step:16147 [D loss: 0.649836, acc.: 66.41%] [G loss: 0.792310]\n",
      "epoch:20 step:16148 [D loss: 0.713192, acc.: 50.00%] [G loss: 0.746894]\n",
      "epoch:20 step:16149 [D loss: 0.711515, acc.: 49.22%] [G loss: 0.750677]\n",
      "epoch:20 step:16150 [D loss: 0.675952, acc.: 59.38%] [G loss: 0.693761]\n",
      "epoch:20 step:16151 [D loss: 0.685988, acc.: 52.34%] [G loss: 0.711416]\n",
      "epoch:20 step:16152 [D loss: 0.734917, acc.: 45.31%] [G loss: 0.687502]\n",
      "epoch:20 step:16153 [D loss: 0.705245, acc.: 48.44%] [G loss: 0.727812]\n",
      "epoch:20 step:16154 [D loss: 0.685922, acc.: 50.78%] [G loss: 0.709898]\n",
      "epoch:20 step:16155 [D loss: 0.704476, acc.: 45.31%] [G loss: 0.730912]\n",
      "epoch:20 step:16156 [D loss: 0.702319, acc.: 56.25%] [G loss: 0.747314]\n",
      "epoch:20 step:16157 [D loss: 0.722278, acc.: 44.53%] [G loss: 0.718702]\n",
      "epoch:20 step:16158 [D loss: 0.667702, acc.: 57.03%] [G loss: 0.868919]\n",
      "epoch:20 step:16159 [D loss: 0.677455, acc.: 64.84%] [G loss: 0.819597]\n",
      "epoch:20 step:16160 [D loss: 0.722514, acc.: 46.88%] [G loss: 0.749724]\n",
      "epoch:20 step:16161 [D loss: 0.678331, acc.: 57.03%] [G loss: 0.734257]\n",
      "epoch:20 step:16162 [D loss: 0.702294, acc.: 53.12%] [G loss: 0.725001]\n",
      "epoch:20 step:16163 [D loss: 0.734804, acc.: 45.31%] [G loss: 0.695834]\n",
      "epoch:20 step:16164 [D loss: 0.725023, acc.: 42.97%] [G loss: 0.699551]\n",
      "epoch:20 step:16165 [D loss: 0.665483, acc.: 60.94%] [G loss: 0.888421]\n",
      "epoch:20 step:16166 [D loss: 0.757892, acc.: 39.84%] [G loss: 0.704410]\n",
      "epoch:20 step:16167 [D loss: 0.699561, acc.: 50.00%] [G loss: 0.778248]\n",
      "epoch:20 step:16168 [D loss: 0.719004, acc.: 46.88%] [G loss: 0.800082]\n",
      "epoch:20 step:16169 [D loss: 0.699400, acc.: 50.00%] [G loss: 0.749106]\n",
      "epoch:20 step:16170 [D loss: 0.740237, acc.: 40.62%] [G loss: 0.724276]\n",
      "epoch:20 step:16171 [D loss: 0.690714, acc.: 52.34%] [G loss: 0.724878]\n",
      "epoch:20 step:16172 [D loss: 0.728799, acc.: 37.50%] [G loss: 0.742367]\n",
      "epoch:20 step:16173 [D loss: 0.684846, acc.: 51.56%] [G loss: 0.736612]\n",
      "epoch:20 step:16174 [D loss: 0.669374, acc.: 54.69%] [G loss: 0.801867]\n",
      "epoch:20 step:16175 [D loss: 0.700214, acc.: 53.12%] [G loss: 0.800708]\n",
      "epoch:20 step:16176 [D loss: 0.700439, acc.: 51.56%] [G loss: 0.742622]\n",
      "epoch:20 step:16177 [D loss: 0.670985, acc.: 59.38%] [G loss: 0.757519]\n",
      "epoch:20 step:16178 [D loss: 0.671430, acc.: 57.81%] [G loss: 0.808348]\n",
      "epoch:20 step:16179 [D loss: 0.652702, acc.: 66.41%] [G loss: 0.730804]\n",
      "epoch:20 step:16180 [D loss: 0.694976, acc.: 51.56%] [G loss: 0.708152]\n",
      "epoch:20 step:16181 [D loss: 0.694896, acc.: 53.12%] [G loss: 0.714990]\n",
      "epoch:20 step:16182 [D loss: 0.648630, acc.: 67.97%] [G loss: 0.751778]\n",
      "epoch:20 step:16183 [D loss: 0.703579, acc.: 56.25%] [G loss: 0.756543]\n",
      "epoch:20 step:16184 [D loss: 0.664978, acc.: 64.84%] [G loss: 0.780879]\n",
      "epoch:20 step:16185 [D loss: 0.658930, acc.: 67.97%] [G loss: 0.768784]\n",
      "epoch:20 step:16186 [D loss: 0.681228, acc.: 61.72%] [G loss: 0.767625]\n",
      "epoch:20 step:16187 [D loss: 0.644247, acc.: 70.31%] [G loss: 0.804996]\n",
      "epoch:20 step:16188 [D loss: 0.708759, acc.: 46.88%] [G loss: 0.793385]\n",
      "epoch:20 step:16189 [D loss: 0.712878, acc.: 46.09%] [G loss: 0.783682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16190 [D loss: 0.660179, acc.: 60.94%] [G loss: 0.837200]\n",
      "epoch:20 step:16191 [D loss: 0.695931, acc.: 49.22%] [G loss: 0.768736]\n",
      "epoch:20 step:16192 [D loss: 0.665811, acc.: 60.16%] [G loss: 0.754076]\n",
      "epoch:20 step:16193 [D loss: 0.699443, acc.: 54.69%] [G loss: 0.704569]\n",
      "epoch:20 step:16194 [D loss: 0.718213, acc.: 50.00%] [G loss: 0.752017]\n",
      "epoch:20 step:16195 [D loss: 0.681125, acc.: 52.34%] [G loss: 0.804579]\n",
      "epoch:20 step:16196 [D loss: 0.668384, acc.: 61.72%] [G loss: 0.762111]\n",
      "epoch:20 step:16197 [D loss: 0.687821, acc.: 56.25%] [G loss: 0.694878]\n",
      "epoch:20 step:16198 [D loss: 0.730168, acc.: 45.31%] [G loss: 0.689251]\n",
      "epoch:20 step:16199 [D loss: 0.657690, acc.: 59.38%] [G loss: 0.763037]\n",
      "epoch:20 step:16200 [D loss: 0.707061, acc.: 50.78%] [G loss: 0.726606]\n",
      "epoch:20 step:16201 [D loss: 0.755080, acc.: 41.41%] [G loss: 0.767165]\n",
      "epoch:20 step:16202 [D loss: 0.722750, acc.: 50.78%] [G loss: 0.814807]\n",
      "epoch:20 step:16203 [D loss: 0.683424, acc.: 50.78%] [G loss: 0.755752]\n",
      "epoch:20 step:16204 [D loss: 0.724202, acc.: 47.66%] [G loss: 0.705304]\n",
      "epoch:20 step:16205 [D loss: 0.715328, acc.: 46.09%] [G loss: 0.738724]\n",
      "epoch:20 step:16206 [D loss: 0.686829, acc.: 59.38%] [G loss: 0.768220]\n",
      "epoch:20 step:16207 [D loss: 0.686322, acc.: 52.34%] [G loss: 0.794466]\n",
      "epoch:20 step:16208 [D loss: 0.703412, acc.: 50.00%] [G loss: 0.762881]\n",
      "epoch:20 step:16209 [D loss: 0.663209, acc.: 59.38%] [G loss: 0.788052]\n",
      "epoch:20 step:16210 [D loss: 0.696413, acc.: 47.66%] [G loss: 0.735147]\n",
      "epoch:20 step:16211 [D loss: 0.701048, acc.: 51.56%] [G loss: 0.815985]\n",
      "epoch:20 step:16212 [D loss: 0.693955, acc.: 51.56%] [G loss: 0.826132]\n",
      "epoch:20 step:16213 [D loss: 0.677640, acc.: 50.00%] [G loss: 0.767871]\n",
      "epoch:20 step:16214 [D loss: 0.701238, acc.: 53.12%] [G loss: 0.789453]\n",
      "epoch:20 step:16215 [D loss: 0.615348, acc.: 73.44%] [G loss: 0.746500]\n",
      "epoch:20 step:16216 [D loss: 0.705260, acc.: 49.22%] [G loss: 0.767055]\n",
      "epoch:20 step:16217 [D loss: 0.700627, acc.: 48.44%] [G loss: 0.741931]\n",
      "epoch:20 step:16218 [D loss: 0.633112, acc.: 71.88%] [G loss: 0.750422]\n",
      "epoch:20 step:16219 [D loss: 0.685638, acc.: 51.56%] [G loss: 0.816349]\n",
      "epoch:20 step:16220 [D loss: 0.706671, acc.: 53.12%] [G loss: 0.755198]\n",
      "epoch:20 step:16221 [D loss: 0.709444, acc.: 46.09%] [G loss: 0.802210]\n",
      "epoch:20 step:16222 [D loss: 0.637240, acc.: 69.53%] [G loss: 0.766316]\n",
      "epoch:20 step:16223 [D loss: 0.686382, acc.: 54.69%] [G loss: 0.896373]\n",
      "epoch:20 step:16224 [D loss: 0.745802, acc.: 43.75%] [G loss: 0.784470]\n",
      "epoch:20 step:16225 [D loss: 0.714470, acc.: 47.66%] [G loss: 0.791888]\n",
      "epoch:20 step:16226 [D loss: 0.714053, acc.: 49.22%] [G loss: 0.801228]\n",
      "epoch:20 step:16227 [D loss: 0.628716, acc.: 68.75%] [G loss: 0.772530]\n",
      "epoch:20 step:16228 [D loss: 0.685509, acc.: 54.69%] [G loss: 0.788759]\n",
      "epoch:20 step:16229 [D loss: 0.686996, acc.: 52.34%] [G loss: 0.773322]\n",
      "epoch:20 step:16230 [D loss: 0.670519, acc.: 62.50%] [G loss: 0.735387]\n",
      "epoch:20 step:16231 [D loss: 0.665243, acc.: 64.84%] [G loss: 0.802717]\n",
      "epoch:20 step:16232 [D loss: 0.698137, acc.: 54.69%] [G loss: 0.719502]\n",
      "epoch:20 step:16233 [D loss: 0.745571, acc.: 36.72%] [G loss: 0.711194]\n",
      "epoch:20 step:16234 [D loss: 0.704673, acc.: 50.00%] [G loss: 0.714000]\n",
      "epoch:20 step:16235 [D loss: 0.732816, acc.: 41.41%] [G loss: 0.769922]\n",
      "epoch:20 step:16236 [D loss: 0.694270, acc.: 51.56%] [G loss: 0.785096]\n",
      "epoch:20 step:16237 [D loss: 0.730043, acc.: 41.41%] [G loss: 0.702387]\n",
      "epoch:20 step:16238 [D loss: 0.656412, acc.: 68.75%] [G loss: 0.729670]\n",
      "epoch:20 step:16239 [D loss: 0.706522, acc.: 51.56%] [G loss: 0.706651]\n",
      "epoch:20 step:16240 [D loss: 0.663566, acc.: 62.50%] [G loss: 0.720062]\n",
      "epoch:20 step:16241 [D loss: 0.705207, acc.: 50.00%] [G loss: 0.818941]\n",
      "epoch:20 step:16242 [D loss: 0.657525, acc.: 61.72%] [G loss: 0.784599]\n",
      "epoch:20 step:16243 [D loss: 0.728441, acc.: 41.41%] [G loss: 0.726324]\n",
      "epoch:20 step:16244 [D loss: 0.656161, acc.: 66.41%] [G loss: 0.770585]\n",
      "epoch:20 step:16245 [D loss: 0.713857, acc.: 41.41%] [G loss: 0.760398]\n",
      "epoch:20 step:16246 [D loss: 0.691497, acc.: 51.56%] [G loss: 0.758228]\n",
      "epoch:20 step:16247 [D loss: 0.670797, acc.: 57.03%] [G loss: 0.802474]\n",
      "epoch:20 step:16248 [D loss: 0.662082, acc.: 63.28%] [G loss: 0.768200]\n",
      "epoch:20 step:16249 [D loss: 0.689794, acc.: 50.78%] [G loss: 0.788222]\n",
      "epoch:20 step:16250 [D loss: 0.663415, acc.: 61.72%] [G loss: 0.779722]\n",
      "epoch:20 step:16251 [D loss: 0.720462, acc.: 46.09%] [G loss: 0.753036]\n",
      "epoch:20 step:16252 [D loss: 0.655217, acc.: 59.38%] [G loss: 0.692678]\n",
      "epoch:20 step:16253 [D loss: 0.672692, acc.: 57.81%] [G loss: 0.762257]\n",
      "epoch:20 step:16254 [D loss: 0.670461, acc.: 53.91%] [G loss: 0.830423]\n",
      "epoch:20 step:16255 [D loss: 0.672548, acc.: 62.50%] [G loss: 0.799277]\n",
      "epoch:20 step:16256 [D loss: 0.686718, acc.: 58.59%] [G loss: 0.772055]\n",
      "epoch:20 step:16257 [D loss: 0.680218, acc.: 56.25%] [G loss: 0.745841]\n",
      "epoch:20 step:16258 [D loss: 0.703419, acc.: 53.91%] [G loss: 0.781191]\n",
      "epoch:20 step:16259 [D loss: 0.709230, acc.: 49.22%] [G loss: 0.749749]\n",
      "epoch:20 step:16260 [D loss: 0.667418, acc.: 60.94%] [G loss: 0.718538]\n",
      "epoch:20 step:16261 [D loss: 0.736884, acc.: 42.97%] [G loss: 0.733964]\n",
      "epoch:20 step:16262 [D loss: 0.713013, acc.: 43.75%] [G loss: 0.732874]\n",
      "epoch:20 step:16263 [D loss: 0.744336, acc.: 41.41%] [G loss: 0.763332]\n",
      "epoch:20 step:16264 [D loss: 0.677728, acc.: 54.69%] [G loss: 0.775416]\n",
      "epoch:20 step:16265 [D loss: 0.682249, acc.: 58.59%] [G loss: 0.764591]\n",
      "epoch:20 step:16266 [D loss: 0.722133, acc.: 44.53%] [G loss: 0.752536]\n",
      "epoch:20 step:16267 [D loss: 0.699994, acc.: 45.31%] [G loss: 0.768145]\n",
      "epoch:20 step:16268 [D loss: 0.694244, acc.: 53.12%] [G loss: 0.713461]\n",
      "epoch:20 step:16269 [D loss: 0.690814, acc.: 54.69%] [G loss: 0.727321]\n",
      "epoch:20 step:16270 [D loss: 0.661654, acc.: 62.50%] [G loss: 0.718744]\n",
      "epoch:20 step:16271 [D loss: 0.683477, acc.: 57.03%] [G loss: 0.754364]\n",
      "epoch:20 step:16272 [D loss: 0.662481, acc.: 64.84%] [G loss: 0.719966]\n",
      "epoch:20 step:16273 [D loss: 0.715907, acc.: 45.31%] [G loss: 0.743501]\n",
      "epoch:20 step:16274 [D loss: 0.708959, acc.: 49.22%] [G loss: 0.722257]\n",
      "epoch:20 step:16275 [D loss: 0.732221, acc.: 42.19%] [G loss: 0.785541]\n",
      "epoch:20 step:16276 [D loss: 0.706217, acc.: 57.81%] [G loss: 0.759452]\n",
      "epoch:20 step:16277 [D loss: 0.729720, acc.: 39.84%] [G loss: 0.767839]\n",
      "epoch:20 step:16278 [D loss: 0.691087, acc.: 52.34%] [G loss: 0.740183]\n",
      "epoch:20 step:16279 [D loss: 0.675412, acc.: 54.69%] [G loss: 0.783912]\n",
      "epoch:20 step:16280 [D loss: 0.711779, acc.: 49.22%] [G loss: 0.809669]\n",
      "epoch:20 step:16281 [D loss: 0.654881, acc.: 65.62%] [G loss: 0.814969]\n",
      "epoch:20 step:16282 [D loss: 0.717478, acc.: 48.44%] [G loss: 0.755958]\n",
      "epoch:20 step:16283 [D loss: 0.660273, acc.: 62.50%] [G loss: 0.877312]\n",
      "epoch:20 step:16284 [D loss: 0.644142, acc.: 71.09%] [G loss: 0.804186]\n",
      "epoch:20 step:16285 [D loss: 0.701910, acc.: 52.34%] [G loss: 0.824254]\n",
      "epoch:20 step:16286 [D loss: 0.666688, acc.: 61.72%] [G loss: 0.775662]\n",
      "epoch:20 step:16287 [D loss: 0.655722, acc.: 60.94%] [G loss: 0.814788]\n",
      "epoch:20 step:16288 [D loss: 0.677016, acc.: 57.03%] [G loss: 0.782482]\n",
      "epoch:20 step:16289 [D loss: 0.646881, acc.: 68.75%] [G loss: 0.821218]\n",
      "epoch:20 step:16290 [D loss: 0.671095, acc.: 59.38%] [G loss: 0.797277]\n",
      "epoch:20 step:16291 [D loss: 0.697592, acc.: 53.12%] [G loss: 0.696434]\n",
      "epoch:20 step:16292 [D loss: 0.741162, acc.: 42.19%] [G loss: 0.734688]\n",
      "epoch:20 step:16293 [D loss: 0.649786, acc.: 64.84%] [G loss: 0.756191]\n",
      "epoch:20 step:16294 [D loss: 0.651189, acc.: 59.38%] [G loss: 0.796063]\n",
      "epoch:20 step:16295 [D loss: 0.708879, acc.: 50.00%] [G loss: 0.675573]\n",
      "epoch:20 step:16296 [D loss: 0.728117, acc.: 39.84%] [G loss: 0.759493]\n",
      "epoch:20 step:16297 [D loss: 0.701029, acc.: 53.12%] [G loss: 0.683209]\n",
      "epoch:20 step:16298 [D loss: 0.693030, acc.: 51.56%] [G loss: 0.745602]\n",
      "epoch:20 step:16299 [D loss: 0.771626, acc.: 29.69%] [G loss: 0.670661]\n",
      "epoch:20 step:16300 [D loss: 0.693473, acc.: 50.78%] [G loss: 0.749867]\n",
      "epoch:20 step:16301 [D loss: 0.701683, acc.: 51.56%] [G loss: 0.749197]\n",
      "epoch:20 step:16302 [D loss: 0.715897, acc.: 50.00%] [G loss: 0.682805]\n",
      "epoch:20 step:16303 [D loss: 0.722816, acc.: 39.84%] [G loss: 0.770335]\n",
      "epoch:20 step:16304 [D loss: 0.661846, acc.: 60.16%] [G loss: 0.841059]\n",
      "epoch:20 step:16305 [D loss: 0.692791, acc.: 55.47%] [G loss: 0.809234]\n",
      "epoch:20 step:16306 [D loss: 0.669114, acc.: 57.81%] [G loss: 0.768215]\n",
      "epoch:20 step:16307 [D loss: 0.672813, acc.: 59.38%] [G loss: 0.732032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16308 [D loss: 0.709783, acc.: 50.00%] [G loss: 0.815827]\n",
      "epoch:20 step:16309 [D loss: 0.682755, acc.: 53.91%] [G loss: 0.797952]\n",
      "epoch:20 step:16310 [D loss: 0.669601, acc.: 65.62%] [G loss: 0.779408]\n",
      "epoch:20 step:16311 [D loss: 0.669339, acc.: 56.25%] [G loss: 0.803851]\n",
      "epoch:20 step:16312 [D loss: 0.710786, acc.: 48.44%] [G loss: 0.782029]\n",
      "epoch:20 step:16313 [D loss: 0.698601, acc.: 56.25%] [G loss: 0.743099]\n",
      "epoch:20 step:16314 [D loss: 0.656187, acc.: 65.62%] [G loss: 0.812665]\n",
      "epoch:20 step:16315 [D loss: 0.648540, acc.: 67.97%] [G loss: 0.705922]\n",
      "epoch:20 step:16316 [D loss: 0.675236, acc.: 53.91%] [G loss: 0.763284]\n",
      "epoch:20 step:16317 [D loss: 0.689568, acc.: 57.81%] [G loss: 0.791851]\n",
      "epoch:20 step:16318 [D loss: 0.677408, acc.: 63.28%] [G loss: 0.765287]\n",
      "epoch:20 step:16319 [D loss: 0.707477, acc.: 53.12%] [G loss: 0.754194]\n",
      "epoch:20 step:16320 [D loss: 0.696140, acc.: 47.66%] [G loss: 0.684283]\n",
      "epoch:20 step:16321 [D loss: 0.679679, acc.: 57.81%] [G loss: 0.742543]\n",
      "epoch:20 step:16322 [D loss: 0.717685, acc.: 43.75%] [G loss: 0.795332]\n",
      "epoch:20 step:16323 [D loss: 0.721396, acc.: 46.09%] [G loss: 0.673565]\n",
      "epoch:20 step:16324 [D loss: 0.738307, acc.: 39.84%] [G loss: 0.684719]\n",
      "epoch:20 step:16325 [D loss: 0.714019, acc.: 47.66%] [G loss: 0.718279]\n",
      "epoch:20 step:16326 [D loss: 0.701069, acc.: 48.44%] [G loss: 0.755172]\n",
      "epoch:20 step:16327 [D loss: 0.756884, acc.: 33.59%] [G loss: 0.664746]\n",
      "epoch:20 step:16328 [D loss: 0.737307, acc.: 40.62%] [G loss: 0.721463]\n",
      "epoch:20 step:16329 [D loss: 0.749155, acc.: 37.50%] [G loss: 0.622403]\n",
      "epoch:20 step:16330 [D loss: 0.728069, acc.: 51.56%] [G loss: 0.691364]\n",
      "epoch:20 step:16331 [D loss: 0.700841, acc.: 44.53%] [G loss: 0.731100]\n",
      "epoch:20 step:16332 [D loss: 0.675565, acc.: 51.56%] [G loss: 0.765135]\n",
      "epoch:20 step:16333 [D loss: 0.699566, acc.: 53.12%] [G loss: 0.786150]\n",
      "epoch:20 step:16334 [D loss: 0.694140, acc.: 49.22%] [G loss: 0.779258]\n",
      "epoch:20 step:16335 [D loss: 0.712211, acc.: 50.00%] [G loss: 0.773759]\n",
      "epoch:20 step:16336 [D loss: 0.717927, acc.: 42.97%] [G loss: 0.750694]\n",
      "epoch:20 step:16337 [D loss: 0.619818, acc.: 79.69%] [G loss: 0.807036]\n",
      "epoch:20 step:16338 [D loss: 0.668998, acc.: 60.16%] [G loss: 0.763855]\n",
      "epoch:20 step:16339 [D loss: 0.705466, acc.: 53.12%] [G loss: 0.801853]\n",
      "epoch:20 step:16340 [D loss: 0.700823, acc.: 50.00%] [G loss: 0.791322]\n",
      "epoch:20 step:16341 [D loss: 0.703987, acc.: 56.25%] [G loss: 0.807066]\n",
      "epoch:20 step:16342 [D loss: 0.723977, acc.: 42.19%] [G loss: 0.786317]\n",
      "epoch:20 step:16343 [D loss: 0.762209, acc.: 40.62%] [G loss: 0.725921]\n",
      "epoch:20 step:16344 [D loss: 0.734377, acc.: 48.44%] [G loss: 0.780982]\n",
      "epoch:20 step:16345 [D loss: 0.659966, acc.: 60.94%] [G loss: 0.796339]\n",
      "epoch:20 step:16346 [D loss: 0.665174, acc.: 58.59%] [G loss: 0.804792]\n",
      "epoch:20 step:16347 [D loss: 0.684583, acc.: 50.78%] [G loss: 0.819919]\n",
      "epoch:20 step:16348 [D loss: 0.680440, acc.: 55.47%] [G loss: 0.723727]\n",
      "epoch:20 step:16349 [D loss: 0.684927, acc.: 58.59%] [G loss: 0.732911]\n",
      "epoch:20 step:16350 [D loss: 0.694009, acc.: 51.56%] [G loss: 0.749272]\n",
      "epoch:20 step:16351 [D loss: 0.709490, acc.: 50.78%] [G loss: 0.765752]\n",
      "epoch:20 step:16352 [D loss: 0.673422, acc.: 55.47%] [G loss: 0.708615]\n",
      "epoch:20 step:16353 [D loss: 0.679367, acc.: 56.25%] [G loss: 0.708116]\n",
      "epoch:20 step:16354 [D loss: 0.687439, acc.: 62.50%] [G loss: 0.732400]\n",
      "epoch:20 step:16355 [D loss: 0.692591, acc.: 53.12%] [G loss: 0.769031]\n",
      "epoch:20 step:16356 [D loss: 0.649808, acc.: 63.28%] [G loss: 0.759464]\n",
      "epoch:20 step:16357 [D loss: 0.702001, acc.: 50.00%] [G loss: 0.734704]\n",
      "epoch:20 step:16358 [D loss: 0.678882, acc.: 62.50%] [G loss: 0.731566]\n",
      "epoch:20 step:16359 [D loss: 0.675038, acc.: 50.78%] [G loss: 0.764380]\n",
      "epoch:20 step:16360 [D loss: 0.740755, acc.: 43.75%] [G loss: 0.708942]\n",
      "epoch:20 step:16361 [D loss: 0.674407, acc.: 55.47%] [G loss: 0.707393]\n",
      "epoch:20 step:16362 [D loss: 0.688331, acc.: 51.56%] [G loss: 0.809602]\n",
      "epoch:20 step:16363 [D loss: 0.730459, acc.: 38.28%] [G loss: 0.734421]\n",
      "epoch:20 step:16364 [D loss: 0.713634, acc.: 46.09%] [G loss: 0.696824]\n",
      "epoch:20 step:16365 [D loss: 0.678575, acc.: 50.78%] [G loss: 0.760612]\n",
      "epoch:20 step:16366 [D loss: 0.690857, acc.: 52.34%] [G loss: 0.692200]\n",
      "epoch:20 step:16367 [D loss: 0.643770, acc.: 63.28%] [G loss: 0.740142]\n",
      "epoch:20 step:16368 [D loss: 0.640905, acc.: 70.31%] [G loss: 0.712483]\n",
      "epoch:20 step:16369 [D loss: 0.624330, acc.: 71.88%] [G loss: 0.760251]\n",
      "epoch:20 step:16370 [D loss: 0.741168, acc.: 37.50%] [G loss: 0.696219]\n",
      "epoch:20 step:16371 [D loss: 0.680898, acc.: 57.81%] [G loss: 0.713406]\n",
      "epoch:20 step:16372 [D loss: 0.703168, acc.: 50.00%] [G loss: 0.759465]\n",
      "epoch:20 step:16373 [D loss: 0.697372, acc.: 47.66%] [G loss: 0.798648]\n",
      "epoch:20 step:16374 [D loss: 0.648535, acc.: 60.94%] [G loss: 0.843843]\n",
      "epoch:20 step:16375 [D loss: 0.648499, acc.: 59.38%] [G loss: 0.806707]\n",
      "epoch:20 step:16376 [D loss: 0.701154, acc.: 52.34%] [G loss: 0.794730]\n",
      "epoch:20 step:16377 [D loss: 0.695332, acc.: 53.91%] [G loss: 0.795996]\n",
      "epoch:20 step:16378 [D loss: 0.693549, acc.: 56.25%] [G loss: 0.764504]\n",
      "epoch:20 step:16379 [D loss: 0.702263, acc.: 52.34%] [G loss: 0.859802]\n",
      "epoch:20 step:16380 [D loss: 0.665787, acc.: 64.06%] [G loss: 0.793626]\n",
      "epoch:20 step:16381 [D loss: 0.713820, acc.: 50.00%] [G loss: 0.742615]\n",
      "epoch:20 step:16382 [D loss: 0.735744, acc.: 36.72%] [G loss: 0.740458]\n",
      "epoch:20 step:16383 [D loss: 0.710263, acc.: 55.47%] [G loss: 0.741480]\n",
      "epoch:20 step:16384 [D loss: 0.671970, acc.: 60.16%] [G loss: 0.720973]\n",
      "epoch:20 step:16385 [D loss: 0.634122, acc.: 69.53%] [G loss: 0.732872]\n",
      "epoch:20 step:16386 [D loss: 0.680527, acc.: 57.03%] [G loss: 0.747033]\n",
      "epoch:20 step:16387 [D loss: 0.729320, acc.: 46.88%] [G loss: 0.707369]\n",
      "epoch:20 step:16388 [D loss: 0.694517, acc.: 46.88%] [G loss: 0.798941]\n",
      "epoch:20 step:16389 [D loss: 0.712462, acc.: 46.88%] [G loss: 0.745230]\n",
      "epoch:20 step:16390 [D loss: 0.695141, acc.: 53.91%] [G loss: 0.738556]\n",
      "epoch:20 step:16391 [D loss: 0.730452, acc.: 44.53%] [G loss: 0.761365]\n",
      "epoch:20 step:16392 [D loss: 0.660558, acc.: 64.06%] [G loss: 0.737968]\n",
      "epoch:20 step:16393 [D loss: 0.691494, acc.: 51.56%] [G loss: 0.714491]\n",
      "epoch:20 step:16394 [D loss: 0.715535, acc.: 50.78%] [G loss: 0.770684]\n",
      "epoch:20 step:16395 [D loss: 0.684692, acc.: 55.47%] [G loss: 0.776465]\n",
      "epoch:20 step:16396 [D loss: 0.687637, acc.: 54.69%] [G loss: 0.752728]\n",
      "epoch:20 step:16397 [D loss: 0.696743, acc.: 52.34%] [G loss: 0.811718]\n",
      "epoch:20 step:16398 [D loss: 0.685485, acc.: 53.12%] [G loss: 0.779791]\n",
      "epoch:20 step:16399 [D loss: 0.686058, acc.: 58.59%] [G loss: 0.697220]\n",
      "epoch:20 step:16400 [D loss: 0.691509, acc.: 57.03%] [G loss: 0.762644]\n",
      "epoch:20 step:16401 [D loss: 0.715314, acc.: 53.12%] [G loss: 0.728590]\n",
      "epoch:21 step:16402 [D loss: 0.662053, acc.: 61.72%] [G loss: 0.797524]\n",
      "epoch:21 step:16403 [D loss: 0.724642, acc.: 48.44%] [G loss: 0.804851]\n",
      "epoch:21 step:16404 [D loss: 0.723872, acc.: 48.44%] [G loss: 0.863273]\n",
      "epoch:21 step:16405 [D loss: 0.672216, acc.: 61.72%] [G loss: 0.768800]\n",
      "epoch:21 step:16406 [D loss: 0.710808, acc.: 48.44%] [G loss: 0.777717]\n",
      "epoch:21 step:16407 [D loss: 0.694490, acc.: 53.12%] [G loss: 0.740363]\n",
      "epoch:21 step:16408 [D loss: 0.687729, acc.: 53.12%] [G loss: 0.700478]\n",
      "epoch:21 step:16409 [D loss: 0.660436, acc.: 62.50%] [G loss: 0.807993]\n",
      "epoch:21 step:16410 [D loss: 0.675696, acc.: 54.69%] [G loss: 0.775106]\n",
      "epoch:21 step:16411 [D loss: 0.660233, acc.: 59.38%] [G loss: 0.842462]\n",
      "epoch:21 step:16412 [D loss: 0.677785, acc.: 52.34%] [G loss: 0.783679]\n",
      "epoch:21 step:16413 [D loss: 0.674070, acc.: 59.38%] [G loss: 0.773076]\n",
      "epoch:21 step:16414 [D loss: 0.702593, acc.: 47.66%] [G loss: 0.777922]\n",
      "epoch:21 step:16415 [D loss: 0.671092, acc.: 53.12%] [G loss: 0.884902]\n",
      "epoch:21 step:16416 [D loss: 0.698726, acc.: 48.44%] [G loss: 0.831084]\n",
      "epoch:21 step:16417 [D loss: 0.672467, acc.: 58.59%] [G loss: 0.799438]\n",
      "epoch:21 step:16418 [D loss: 0.703349, acc.: 50.00%] [G loss: 0.757680]\n",
      "epoch:21 step:16419 [D loss: 0.678139, acc.: 59.38%] [G loss: 0.762241]\n",
      "epoch:21 step:16420 [D loss: 0.644416, acc.: 69.53%] [G loss: 0.818096]\n",
      "epoch:21 step:16421 [D loss: 0.640175, acc.: 64.06%] [G loss: 0.767135]\n",
      "epoch:21 step:16422 [D loss: 0.650684, acc.: 60.94%] [G loss: 0.835928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16423 [D loss: 0.679547, acc.: 57.03%] [G loss: 0.802346]\n",
      "epoch:21 step:16424 [D loss: 0.683921, acc.: 56.25%] [G loss: 0.755298]\n",
      "epoch:21 step:16425 [D loss: 0.658512, acc.: 62.50%] [G loss: 0.746209]\n",
      "epoch:21 step:16426 [D loss: 0.726599, acc.: 43.75%] [G loss: 0.726482]\n",
      "epoch:21 step:16427 [D loss: 0.757118, acc.: 38.28%] [G loss: 0.628853]\n",
      "epoch:21 step:16428 [D loss: 0.673357, acc.: 54.69%] [G loss: 0.759020]\n",
      "epoch:21 step:16429 [D loss: 0.674630, acc.: 59.38%] [G loss: 0.777243]\n",
      "epoch:21 step:16430 [D loss: 0.692142, acc.: 52.34%] [G loss: 0.750633]\n",
      "epoch:21 step:16431 [D loss: 0.703586, acc.: 45.31%] [G loss: 0.847760]\n",
      "epoch:21 step:16432 [D loss: 0.691056, acc.: 55.47%] [G loss: 0.782209]\n",
      "epoch:21 step:16433 [D loss: 0.705533, acc.: 45.31%] [G loss: 0.744953]\n",
      "epoch:21 step:16434 [D loss: 0.669486, acc.: 60.16%] [G loss: 0.756760]\n",
      "epoch:21 step:16435 [D loss: 0.717114, acc.: 45.31%] [G loss: 0.731702]\n",
      "epoch:21 step:16436 [D loss: 0.714958, acc.: 50.78%] [G loss: 0.745541]\n",
      "epoch:21 step:16437 [D loss: 0.725554, acc.: 39.84%] [G loss: 0.712108]\n",
      "epoch:21 step:16438 [D loss: 0.713152, acc.: 47.66%] [G loss: 0.692933]\n",
      "epoch:21 step:16439 [D loss: 0.673155, acc.: 58.59%] [G loss: 0.781006]\n",
      "epoch:21 step:16440 [D loss: 0.712236, acc.: 40.62%] [G loss: 0.792598]\n",
      "epoch:21 step:16441 [D loss: 0.705100, acc.: 50.00%] [G loss: 0.744236]\n",
      "epoch:21 step:16442 [D loss: 0.718531, acc.: 44.53%] [G loss: 0.746321]\n",
      "epoch:21 step:16443 [D loss: 0.637524, acc.: 67.19%] [G loss: 0.733120]\n",
      "epoch:21 step:16444 [D loss: 0.747001, acc.: 40.62%] [G loss: 0.707016]\n",
      "epoch:21 step:16445 [D loss: 0.727764, acc.: 38.28%] [G loss: 0.761011]\n",
      "epoch:21 step:16446 [D loss: 0.641708, acc.: 67.19%] [G loss: 0.732081]\n",
      "epoch:21 step:16447 [D loss: 0.672956, acc.: 57.03%] [G loss: 0.767600]\n",
      "epoch:21 step:16448 [D loss: 0.668509, acc.: 58.59%] [G loss: 0.801945]\n",
      "epoch:21 step:16449 [D loss: 0.693586, acc.: 55.47%] [G loss: 0.711577]\n",
      "epoch:21 step:16450 [D loss: 0.648191, acc.: 65.62%] [G loss: 0.758871]\n",
      "epoch:21 step:16451 [D loss: 0.684186, acc.: 57.03%] [G loss: 0.750998]\n",
      "epoch:21 step:16452 [D loss: 0.687597, acc.: 51.56%] [G loss: 0.791842]\n",
      "epoch:21 step:16453 [D loss: 0.663706, acc.: 60.94%] [G loss: 0.810141]\n",
      "epoch:21 step:16454 [D loss: 0.757979, acc.: 38.28%] [G loss: 0.701160]\n",
      "epoch:21 step:16455 [D loss: 0.729672, acc.: 45.31%] [G loss: 0.777426]\n",
      "epoch:21 step:16456 [D loss: 0.758253, acc.: 31.25%] [G loss: 0.696090]\n",
      "epoch:21 step:16457 [D loss: 0.706729, acc.: 43.75%] [G loss: 0.739815]\n",
      "epoch:21 step:16458 [D loss: 0.659662, acc.: 64.84%] [G loss: 0.716993]\n",
      "epoch:21 step:16459 [D loss: 0.715387, acc.: 42.97%] [G loss: 0.716263]\n",
      "epoch:21 step:16460 [D loss: 0.677770, acc.: 55.47%] [G loss: 0.747707]\n",
      "epoch:21 step:16461 [D loss: 0.697914, acc.: 55.47%] [G loss: 0.871794]\n",
      "epoch:21 step:16462 [D loss: 0.678633, acc.: 55.47%] [G loss: 0.855470]\n",
      "epoch:21 step:16463 [D loss: 0.678582, acc.: 57.81%] [G loss: 0.783459]\n",
      "epoch:21 step:16464 [D loss: 0.718641, acc.: 45.31%] [G loss: 0.717978]\n",
      "epoch:21 step:16465 [D loss: 0.675892, acc.: 60.16%] [G loss: 0.773321]\n",
      "epoch:21 step:16466 [D loss: 0.764629, acc.: 30.47%] [G loss: 0.745023]\n",
      "epoch:21 step:16467 [D loss: 0.771693, acc.: 34.38%] [G loss: 0.752794]\n",
      "epoch:21 step:16468 [D loss: 0.721495, acc.: 46.09%] [G loss: 0.726956]\n",
      "epoch:21 step:16469 [D loss: 0.699358, acc.: 47.66%] [G loss: 0.757272]\n",
      "epoch:21 step:16470 [D loss: 0.704001, acc.: 51.56%] [G loss: 0.800745]\n",
      "epoch:21 step:16471 [D loss: 0.713941, acc.: 48.44%] [G loss: 0.788530]\n",
      "epoch:21 step:16472 [D loss: 0.722771, acc.: 43.75%] [G loss: 0.697386]\n",
      "epoch:21 step:16473 [D loss: 0.711570, acc.: 50.00%] [G loss: 0.724616]\n",
      "epoch:21 step:16474 [D loss: 0.695943, acc.: 53.91%] [G loss: 0.751230]\n",
      "epoch:21 step:16475 [D loss: 0.650708, acc.: 69.53%] [G loss: 0.755628]\n",
      "epoch:21 step:16476 [D loss: 0.684443, acc.: 50.78%] [G loss: 0.685628]\n",
      "epoch:21 step:16477 [D loss: 0.734230, acc.: 39.06%] [G loss: 0.688455]\n",
      "epoch:21 step:16478 [D loss: 0.719710, acc.: 42.97%] [G loss: 0.726038]\n",
      "epoch:21 step:16479 [D loss: 0.701331, acc.: 53.12%] [G loss: 0.720535]\n",
      "epoch:21 step:16480 [D loss: 0.702580, acc.: 45.31%] [G loss: 0.738671]\n",
      "epoch:21 step:16481 [D loss: 0.676891, acc.: 55.47%] [G loss: 0.804649]\n",
      "epoch:21 step:16482 [D loss: 0.701019, acc.: 47.66%] [G loss: 0.770211]\n",
      "epoch:21 step:16483 [D loss: 0.656844, acc.: 66.41%] [G loss: 0.783963]\n",
      "epoch:21 step:16484 [D loss: 0.688577, acc.: 53.12%] [G loss: 0.791067]\n",
      "epoch:21 step:16485 [D loss: 0.595358, acc.: 82.03%] [G loss: 0.788383]\n",
      "epoch:21 step:16486 [D loss: 0.649598, acc.: 70.31%] [G loss: 0.756292]\n",
      "epoch:21 step:16487 [D loss: 0.652427, acc.: 65.62%] [G loss: 0.732927]\n",
      "epoch:21 step:16488 [D loss: 0.671027, acc.: 57.81%] [G loss: 0.730685]\n",
      "epoch:21 step:16489 [D loss: 0.662874, acc.: 64.06%] [G loss: 0.745750]\n",
      "epoch:21 step:16490 [D loss: 0.675510, acc.: 62.50%] [G loss: 0.788314]\n",
      "epoch:21 step:16491 [D loss: 0.697481, acc.: 54.69%] [G loss: 0.795804]\n",
      "epoch:21 step:16492 [D loss: 0.677968, acc.: 58.59%] [G loss: 0.740823]\n",
      "epoch:21 step:16493 [D loss: 0.698338, acc.: 48.44%] [G loss: 0.703839]\n",
      "epoch:21 step:16494 [D loss: 0.687234, acc.: 53.12%] [G loss: 0.696924]\n",
      "epoch:21 step:16495 [D loss: 0.633527, acc.: 67.19%] [G loss: 0.725913]\n",
      "epoch:21 step:16496 [D loss: 0.682787, acc.: 58.59%] [G loss: 0.785379]\n",
      "epoch:21 step:16497 [D loss: 0.704370, acc.: 53.12%] [G loss: 0.746371]\n",
      "epoch:21 step:16498 [D loss: 0.719761, acc.: 44.53%] [G loss: 0.703412]\n",
      "epoch:21 step:16499 [D loss: 0.699297, acc.: 51.56%] [G loss: 0.850357]\n",
      "epoch:21 step:16500 [D loss: 0.658127, acc.: 59.38%] [G loss: 0.767685]\n",
      "epoch:21 step:16501 [D loss: 0.695770, acc.: 48.44%] [G loss: 0.759566]\n",
      "epoch:21 step:16502 [D loss: 0.684951, acc.: 55.47%] [G loss: 0.781883]\n",
      "epoch:21 step:16503 [D loss: 0.727673, acc.: 40.62%] [G loss: 0.742585]\n",
      "epoch:21 step:16504 [D loss: 0.813822, acc.: 21.09%] [G loss: 0.681002]\n",
      "epoch:21 step:16505 [D loss: 0.725718, acc.: 44.53%] [G loss: 0.772147]\n",
      "epoch:21 step:16506 [D loss: 0.699466, acc.: 54.69%] [G loss: 0.713412]\n",
      "epoch:21 step:16507 [D loss: 0.730370, acc.: 37.50%] [G loss: 0.704763]\n",
      "epoch:21 step:16508 [D loss: 0.643726, acc.: 65.62%] [G loss: 0.782740]\n",
      "epoch:21 step:16509 [D loss: 0.766112, acc.: 35.94%] [G loss: 0.696361]\n",
      "epoch:21 step:16510 [D loss: 0.705173, acc.: 50.00%] [G loss: 0.750156]\n",
      "epoch:21 step:16511 [D loss: 0.675047, acc.: 55.47%] [G loss: 0.727052]\n",
      "epoch:21 step:16512 [D loss: 0.682660, acc.: 54.69%] [G loss: 0.798346]\n",
      "epoch:21 step:16513 [D loss: 0.693112, acc.: 47.66%] [G loss: 0.771036]\n",
      "epoch:21 step:16514 [D loss: 0.720703, acc.: 50.00%] [G loss: 0.753491]\n",
      "epoch:21 step:16515 [D loss: 0.684303, acc.: 56.25%] [G loss: 0.755290]\n",
      "epoch:21 step:16516 [D loss: 0.705700, acc.: 46.88%] [G loss: 0.795823]\n",
      "epoch:21 step:16517 [D loss: 0.727357, acc.: 48.44%] [G loss: 0.751368]\n",
      "epoch:21 step:16518 [D loss: 0.716674, acc.: 42.19%] [G loss: 0.768870]\n",
      "epoch:21 step:16519 [D loss: 0.675973, acc.: 57.03%] [G loss: 0.799472]\n",
      "epoch:21 step:16520 [D loss: 0.669650, acc.: 60.94%] [G loss: 0.759002]\n",
      "epoch:21 step:16521 [D loss: 0.717830, acc.: 42.97%] [G loss: 0.748866]\n",
      "epoch:21 step:16522 [D loss: 0.681446, acc.: 60.94%] [G loss: 0.827087]\n",
      "epoch:21 step:16523 [D loss: 0.690433, acc.: 50.00%] [G loss: 0.759345]\n",
      "epoch:21 step:16524 [D loss: 0.690882, acc.: 49.22%] [G loss: 0.765773]\n",
      "epoch:21 step:16525 [D loss: 0.692739, acc.: 54.69%] [G loss: 0.718762]\n",
      "epoch:21 step:16526 [D loss: 0.718773, acc.: 46.88%] [G loss: 0.727363]\n",
      "epoch:21 step:16527 [D loss: 0.685045, acc.: 56.25%] [G loss: 0.691725]\n",
      "epoch:21 step:16528 [D loss: 0.611416, acc.: 75.78%] [G loss: 0.776909]\n",
      "epoch:21 step:16529 [D loss: 0.668952, acc.: 64.84%] [G loss: 0.723956]\n",
      "epoch:21 step:16530 [D loss: 0.690444, acc.: 60.16%] [G loss: 0.795950]\n",
      "epoch:21 step:16531 [D loss: 0.664546, acc.: 60.94%] [G loss: 0.792757]\n",
      "epoch:21 step:16532 [D loss: 0.636156, acc.: 64.84%] [G loss: 0.799144]\n",
      "epoch:21 step:16533 [D loss: 0.647563, acc.: 66.41%] [G loss: 0.798415]\n",
      "epoch:21 step:16534 [D loss: 0.680819, acc.: 57.81%] [G loss: 0.750987]\n",
      "epoch:21 step:16535 [D loss: 0.687538, acc.: 55.47%] [G loss: 0.782647]\n",
      "epoch:21 step:16536 [D loss: 0.739420, acc.: 46.09%] [G loss: 0.786157]\n",
      "epoch:21 step:16537 [D loss: 0.665047, acc.: 58.59%] [G loss: 0.717603]\n",
      "epoch:21 step:16538 [D loss: 0.694991, acc.: 51.56%] [G loss: 0.728744]\n",
      "epoch:21 step:16539 [D loss: 0.703444, acc.: 47.66%] [G loss: 0.733694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16540 [D loss: 0.673768, acc.: 55.47%] [G loss: 0.749299]\n",
      "epoch:21 step:16541 [D loss: 0.742683, acc.: 39.06%] [G loss: 0.774858]\n",
      "epoch:21 step:16542 [D loss: 0.711400, acc.: 50.00%] [G loss: 0.770853]\n",
      "epoch:21 step:16543 [D loss: 0.701000, acc.: 53.12%] [G loss: 0.775380]\n",
      "epoch:21 step:16544 [D loss: 0.722664, acc.: 47.66%] [G loss: 0.719517]\n",
      "epoch:21 step:16545 [D loss: 0.685089, acc.: 58.59%] [G loss: 0.811678]\n",
      "epoch:21 step:16546 [D loss: 0.687144, acc.: 53.91%] [G loss: 0.809252]\n",
      "epoch:21 step:16547 [D loss: 0.662879, acc.: 59.38%] [G loss: 0.769705]\n",
      "epoch:21 step:16548 [D loss: 0.723150, acc.: 39.84%] [G loss: 0.795819]\n",
      "epoch:21 step:16549 [D loss: 0.704448, acc.: 50.78%] [G loss: 0.764836]\n",
      "epoch:21 step:16550 [D loss: 0.701675, acc.: 56.25%] [G loss: 0.746236]\n",
      "epoch:21 step:16551 [D loss: 0.684868, acc.: 54.69%] [G loss: 0.766292]\n",
      "epoch:21 step:16552 [D loss: 0.704301, acc.: 46.09%] [G loss: 0.733317]\n",
      "epoch:21 step:16553 [D loss: 0.691777, acc.: 54.69%] [G loss: 0.750246]\n",
      "epoch:21 step:16554 [D loss: 0.688748, acc.: 53.12%] [G loss: 0.697710]\n",
      "epoch:21 step:16555 [D loss: 0.670871, acc.: 56.25%] [G loss: 0.818991]\n",
      "epoch:21 step:16556 [D loss: 0.680066, acc.: 55.47%] [G loss: 0.778465]\n",
      "epoch:21 step:16557 [D loss: 0.698391, acc.: 50.00%] [G loss: 0.762909]\n",
      "epoch:21 step:16558 [D loss: 0.695765, acc.: 54.69%] [G loss: 0.749785]\n",
      "epoch:21 step:16559 [D loss: 0.685564, acc.: 53.12%] [G loss: 0.790400]\n",
      "epoch:21 step:16560 [D loss: 0.714965, acc.: 47.66%] [G loss: 0.767039]\n",
      "epoch:21 step:16561 [D loss: 0.635106, acc.: 71.09%] [G loss: 0.809737]\n",
      "epoch:21 step:16562 [D loss: 0.667449, acc.: 58.59%] [G loss: 0.737766]\n",
      "epoch:21 step:16563 [D loss: 0.732101, acc.: 42.19%] [G loss: 0.692810]\n",
      "epoch:21 step:16564 [D loss: 0.662406, acc.: 60.16%] [G loss: 0.705388]\n",
      "epoch:21 step:16565 [D loss: 0.635090, acc.: 69.53%] [G loss: 0.684654]\n",
      "epoch:21 step:16566 [D loss: 0.689085, acc.: 51.56%] [G loss: 0.727773]\n",
      "epoch:21 step:16567 [D loss: 0.748145, acc.: 39.06%] [G loss: 0.758235]\n",
      "epoch:21 step:16568 [D loss: 0.704661, acc.: 45.31%] [G loss: 0.718224]\n",
      "epoch:21 step:16569 [D loss: 0.715860, acc.: 42.19%] [G loss: 0.740475]\n",
      "epoch:21 step:16570 [D loss: 0.696561, acc.: 53.91%] [G loss: 0.829726]\n",
      "epoch:21 step:16571 [D loss: 0.717940, acc.: 50.78%] [G loss: 0.767154]\n",
      "epoch:21 step:16572 [D loss: 0.708194, acc.: 47.66%] [G loss: 0.720527]\n",
      "epoch:21 step:16573 [D loss: 0.708484, acc.: 52.34%] [G loss: 0.744531]\n",
      "epoch:21 step:16574 [D loss: 0.696428, acc.: 52.34%] [G loss: 0.744335]\n",
      "epoch:21 step:16575 [D loss: 0.728001, acc.: 41.41%] [G loss: 0.720658]\n",
      "epoch:21 step:16576 [D loss: 0.722490, acc.: 42.19%] [G loss: 0.739649]\n",
      "epoch:21 step:16577 [D loss: 0.710239, acc.: 52.34%] [G loss: 0.758525]\n",
      "epoch:21 step:16578 [D loss: 0.779892, acc.: 35.94%] [G loss: 0.773378]\n",
      "epoch:21 step:16579 [D loss: 0.682664, acc.: 54.69%] [G loss: 0.767895]\n",
      "epoch:21 step:16580 [D loss: 0.672989, acc.: 57.81%] [G loss: 0.716296]\n",
      "epoch:21 step:16581 [D loss: 0.685441, acc.: 51.56%] [G loss: 0.790037]\n",
      "epoch:21 step:16582 [D loss: 0.659906, acc.: 61.72%] [G loss: 0.809395]\n",
      "epoch:21 step:16583 [D loss: 0.736919, acc.: 43.75%] [G loss: 0.739356]\n",
      "epoch:21 step:16584 [D loss: 0.656437, acc.: 71.88%] [G loss: 0.791156]\n",
      "epoch:21 step:16585 [D loss: 0.686799, acc.: 53.12%] [G loss: 0.776804]\n",
      "epoch:21 step:16586 [D loss: 0.654534, acc.: 71.88%] [G loss: 0.763513]\n",
      "epoch:21 step:16587 [D loss: 0.664258, acc.: 60.94%] [G loss: 0.763380]\n",
      "epoch:21 step:16588 [D loss: 0.644138, acc.: 64.84%] [G loss: 0.771428]\n",
      "epoch:21 step:16589 [D loss: 0.710092, acc.: 46.88%] [G loss: 0.753305]\n",
      "epoch:21 step:16590 [D loss: 0.654780, acc.: 61.72%] [G loss: 0.761623]\n",
      "epoch:21 step:16591 [D loss: 0.690052, acc.: 57.03%] [G loss: 0.767345]\n",
      "epoch:21 step:16592 [D loss: 0.723722, acc.: 46.09%] [G loss: 0.781051]\n",
      "epoch:21 step:16593 [D loss: 0.689388, acc.: 58.59%] [G loss: 0.742701]\n",
      "epoch:21 step:16594 [D loss: 0.772213, acc.: 28.12%] [G loss: 0.748721]\n",
      "epoch:21 step:16595 [D loss: 0.700127, acc.: 52.34%] [G loss: 0.745383]\n",
      "epoch:21 step:16596 [D loss: 0.736677, acc.: 38.28%] [G loss: 0.748607]\n",
      "epoch:21 step:16597 [D loss: 0.655882, acc.: 67.19%] [G loss: 0.803768]\n",
      "epoch:21 step:16598 [D loss: 0.769856, acc.: 39.84%] [G loss: 0.703386]\n",
      "epoch:21 step:16599 [D loss: 0.696408, acc.: 49.22%] [G loss: 0.718735]\n",
      "epoch:21 step:16600 [D loss: 0.673020, acc.: 60.16%] [G loss: 0.787266]\n",
      "epoch:21 step:16601 [D loss: 0.705243, acc.: 43.75%] [G loss: 0.747714]\n",
      "epoch:21 step:16602 [D loss: 0.673169, acc.: 56.25%] [G loss: 0.757916]\n",
      "epoch:21 step:16603 [D loss: 0.759541, acc.: 34.38%] [G loss: 0.691912]\n",
      "epoch:21 step:16604 [D loss: 0.725091, acc.: 38.28%] [G loss: 0.671771]\n",
      "epoch:21 step:16605 [D loss: 0.709719, acc.: 48.44%] [G loss: 0.742022]\n",
      "epoch:21 step:16606 [D loss: 0.721000, acc.: 41.41%] [G loss: 0.809653]\n",
      "epoch:21 step:16607 [D loss: 0.697910, acc.: 46.88%] [G loss: 0.708461]\n",
      "epoch:21 step:16608 [D loss: 0.653568, acc.: 62.50%] [G loss: 0.738319]\n",
      "epoch:21 step:16609 [D loss: 0.714277, acc.: 49.22%] [G loss: 0.715396]\n",
      "epoch:21 step:16610 [D loss: 0.687563, acc.: 60.16%] [G loss: 0.826758]\n",
      "epoch:21 step:16611 [D loss: 0.671405, acc.: 59.38%] [G loss: 0.844834]\n",
      "epoch:21 step:16612 [D loss: 0.663058, acc.: 60.16%] [G loss: 0.827049]\n",
      "epoch:21 step:16613 [D loss: 0.708334, acc.: 50.00%] [G loss: 0.754865]\n",
      "epoch:21 step:16614 [D loss: 0.663352, acc.: 64.84%] [G loss: 0.817140]\n",
      "epoch:21 step:16615 [D loss: 0.714588, acc.: 47.66%] [G loss: 0.761234]\n",
      "epoch:21 step:16616 [D loss: 0.703038, acc.: 55.47%] [G loss: 0.747407]\n",
      "epoch:21 step:16617 [D loss: 0.694293, acc.: 51.56%] [G loss: 0.748576]\n",
      "epoch:21 step:16618 [D loss: 0.659480, acc.: 60.94%] [G loss: 0.763143]\n",
      "epoch:21 step:16619 [D loss: 0.696487, acc.: 53.12%] [G loss: 0.819224]\n",
      "epoch:21 step:16620 [D loss: 0.648453, acc.: 64.84%] [G loss: 0.767613]\n",
      "epoch:21 step:16621 [D loss: 0.697779, acc.: 47.66%] [G loss: 0.732706]\n",
      "epoch:21 step:16622 [D loss: 0.754480, acc.: 35.94%] [G loss: 0.774172]\n",
      "epoch:21 step:16623 [D loss: 0.725820, acc.: 46.09%] [G loss: 0.784066]\n",
      "epoch:21 step:16624 [D loss: 0.708785, acc.: 43.75%] [G loss: 0.739516]\n",
      "epoch:21 step:16625 [D loss: 0.704026, acc.: 44.53%] [G loss: 0.757316]\n",
      "epoch:21 step:16626 [D loss: 0.693156, acc.: 49.22%] [G loss: 0.726127]\n",
      "epoch:21 step:16627 [D loss: 0.720560, acc.: 52.34%] [G loss: 0.746329]\n",
      "epoch:21 step:16628 [D loss: 0.721409, acc.: 39.84%] [G loss: 0.743364]\n",
      "epoch:21 step:16629 [D loss: 0.673109, acc.: 63.28%] [G loss: 0.740920]\n",
      "epoch:21 step:16630 [D loss: 0.685767, acc.: 55.47%] [G loss: 0.735039]\n",
      "epoch:21 step:16631 [D loss: 0.712760, acc.: 46.88%] [G loss: 0.794679]\n",
      "epoch:21 step:16632 [D loss: 0.672884, acc.: 61.72%] [G loss: 0.838965]\n",
      "epoch:21 step:16633 [D loss: 0.741109, acc.: 46.88%] [G loss: 0.724673]\n",
      "epoch:21 step:16634 [D loss: 0.641437, acc.: 64.06%] [G loss: 0.785420]\n",
      "epoch:21 step:16635 [D loss: 0.749472, acc.: 37.50%] [G loss: 0.753025]\n",
      "epoch:21 step:16636 [D loss: 0.740264, acc.: 43.75%] [G loss: 0.743772]\n",
      "epoch:21 step:16637 [D loss: 0.671706, acc.: 57.81%] [G loss: 0.763382]\n",
      "epoch:21 step:16638 [D loss: 0.678225, acc.: 53.91%] [G loss: 0.730356]\n",
      "epoch:21 step:16639 [D loss: 0.693513, acc.: 52.34%] [G loss: 0.696477]\n",
      "epoch:21 step:16640 [D loss: 0.699090, acc.: 48.44%] [G loss: 0.721103]\n",
      "epoch:21 step:16641 [D loss: 0.714932, acc.: 47.66%] [G loss: 0.793635]\n",
      "epoch:21 step:16642 [D loss: 0.684259, acc.: 52.34%] [G loss: 0.782484]\n",
      "epoch:21 step:16643 [D loss: 0.681904, acc.: 60.16%] [G loss: 0.678129]\n",
      "epoch:21 step:16644 [D loss: 0.639815, acc.: 71.09%] [G loss: 0.752931]\n",
      "epoch:21 step:16645 [D loss: 0.690092, acc.: 55.47%] [G loss: 0.769416]\n",
      "epoch:21 step:16646 [D loss: 0.743279, acc.: 39.84%] [G loss: 0.744104]\n",
      "epoch:21 step:16647 [D loss: 0.724820, acc.: 47.66%] [G loss: 0.736774]\n",
      "epoch:21 step:16648 [D loss: 0.685357, acc.: 56.25%] [G loss: 0.746978]\n",
      "epoch:21 step:16649 [D loss: 0.709934, acc.: 49.22%] [G loss: 0.761756]\n",
      "epoch:21 step:16650 [D loss: 0.750731, acc.: 41.41%] [G loss: 0.795796]\n",
      "epoch:21 step:16651 [D loss: 0.694754, acc.: 51.56%] [G loss: 0.750531]\n",
      "epoch:21 step:16652 [D loss: 0.681522, acc.: 57.03%] [G loss: 0.739205]\n",
      "epoch:21 step:16653 [D loss: 0.701545, acc.: 53.12%] [G loss: 0.748814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16654 [D loss: 0.733727, acc.: 40.62%] [G loss: 0.835775]\n",
      "epoch:21 step:16655 [D loss: 0.706270, acc.: 54.69%] [G loss: 0.786032]\n",
      "epoch:21 step:16656 [D loss: 0.723223, acc.: 41.41%] [G loss: 0.730900]\n",
      "epoch:21 step:16657 [D loss: 0.720555, acc.: 46.09%] [G loss: 0.700521]\n",
      "epoch:21 step:16658 [D loss: 0.700466, acc.: 53.12%] [G loss: 0.727126]\n",
      "epoch:21 step:16659 [D loss: 0.693383, acc.: 55.47%] [G loss: 0.738202]\n",
      "epoch:21 step:16660 [D loss: 0.695670, acc.: 55.47%] [G loss: 0.713297]\n",
      "epoch:21 step:16661 [D loss: 0.664924, acc.: 66.41%] [G loss: 0.813025]\n",
      "epoch:21 step:16662 [D loss: 0.670347, acc.: 58.59%] [G loss: 0.830956]\n",
      "epoch:21 step:16663 [D loss: 0.655706, acc.: 61.72%] [G loss: 0.803617]\n",
      "epoch:21 step:16664 [D loss: 0.705292, acc.: 50.00%] [G loss: 0.774023]\n",
      "epoch:21 step:16665 [D loss: 0.692830, acc.: 57.03%] [G loss: 0.826542]\n",
      "epoch:21 step:16666 [D loss: 0.682324, acc.: 57.81%] [G loss: 0.897148]\n",
      "epoch:21 step:16667 [D loss: 0.690280, acc.: 58.59%] [G loss: 0.739398]\n",
      "epoch:21 step:16668 [D loss: 0.779676, acc.: 32.03%] [G loss: 0.703172]\n",
      "epoch:21 step:16669 [D loss: 0.639854, acc.: 68.75%] [G loss: 0.746690]\n",
      "epoch:21 step:16670 [D loss: 0.634477, acc.: 67.97%] [G loss: 0.693236]\n",
      "epoch:21 step:16671 [D loss: 0.669655, acc.: 59.38%] [G loss: 0.696612]\n",
      "epoch:21 step:16672 [D loss: 0.685130, acc.: 56.25%] [G loss: 0.758586]\n",
      "epoch:21 step:16673 [D loss: 0.651186, acc.: 67.97%] [G loss: 0.701841]\n",
      "epoch:21 step:16674 [D loss: 0.620797, acc.: 77.34%] [G loss: 0.833767]\n",
      "epoch:21 step:16675 [D loss: 0.719385, acc.: 48.44%] [G loss: 0.753657]\n",
      "epoch:21 step:16676 [D loss: 0.716862, acc.: 46.09%] [G loss: 0.748805]\n",
      "epoch:21 step:16677 [D loss: 0.664405, acc.: 57.81%] [G loss: 0.806134]\n",
      "epoch:21 step:16678 [D loss: 0.737039, acc.: 42.19%] [G loss: 0.711043]\n",
      "epoch:21 step:16679 [D loss: 0.693084, acc.: 54.69%] [G loss: 0.690279]\n",
      "epoch:21 step:16680 [D loss: 0.711683, acc.: 52.34%] [G loss: 0.733121]\n",
      "epoch:21 step:16681 [D loss: 0.719347, acc.: 51.56%] [G loss: 0.740527]\n",
      "epoch:21 step:16682 [D loss: 0.711961, acc.: 42.19%] [G loss: 0.744905]\n",
      "epoch:21 step:16683 [D loss: 0.703526, acc.: 50.00%] [G loss: 0.665325]\n",
      "epoch:21 step:16684 [D loss: 0.700589, acc.: 53.91%] [G loss: 0.714443]\n",
      "epoch:21 step:16685 [D loss: 0.655132, acc.: 62.50%] [G loss: 0.759681]\n",
      "epoch:21 step:16686 [D loss: 0.673691, acc.: 60.94%] [G loss: 0.765155]\n",
      "epoch:21 step:16687 [D loss: 0.703278, acc.: 48.44%] [G loss: 0.680978]\n",
      "epoch:21 step:16688 [D loss: 0.697622, acc.: 51.56%] [G loss: 0.731815]\n",
      "epoch:21 step:16689 [D loss: 0.697875, acc.: 53.12%] [G loss: 0.741610]\n",
      "epoch:21 step:16690 [D loss: 0.691857, acc.: 54.69%] [G loss: 0.798582]\n",
      "epoch:21 step:16691 [D loss: 0.681677, acc.: 53.12%] [G loss: 0.753299]\n",
      "epoch:21 step:16692 [D loss: 0.726632, acc.: 39.84%] [G loss: 0.824802]\n",
      "epoch:21 step:16693 [D loss: 0.700388, acc.: 47.66%] [G loss: 0.786515]\n",
      "epoch:21 step:16694 [D loss: 0.697976, acc.: 47.66%] [G loss: 0.725686]\n",
      "epoch:21 step:16695 [D loss: 0.675086, acc.: 55.47%] [G loss: 0.722128]\n",
      "epoch:21 step:16696 [D loss: 0.655162, acc.: 64.06%] [G loss: 0.773884]\n",
      "epoch:21 step:16697 [D loss: 0.696038, acc.: 47.66%] [G loss: 0.778317]\n",
      "epoch:21 step:16698 [D loss: 0.675411, acc.: 52.34%] [G loss: 0.744416]\n",
      "epoch:21 step:16699 [D loss: 0.687752, acc.: 53.12%] [G loss: 0.723521]\n",
      "epoch:21 step:16700 [D loss: 0.671598, acc.: 57.03%] [G loss: 0.739658]\n",
      "epoch:21 step:16701 [D loss: 0.633287, acc.: 67.19%] [G loss: 0.828863]\n",
      "epoch:21 step:16702 [D loss: 0.692615, acc.: 53.91%] [G loss: 0.733127]\n",
      "epoch:21 step:16703 [D loss: 0.677742, acc.: 62.50%] [G loss: 0.739729]\n",
      "epoch:21 step:16704 [D loss: 0.657687, acc.: 65.62%] [G loss: 0.764635]\n",
      "epoch:21 step:16705 [D loss: 0.677250, acc.: 57.03%] [G loss: 0.763274]\n",
      "epoch:21 step:16706 [D loss: 0.707749, acc.: 51.56%] [G loss: 0.692141]\n",
      "epoch:21 step:16707 [D loss: 0.656878, acc.: 64.84%] [G loss: 0.703424]\n",
      "epoch:21 step:16708 [D loss: 0.668201, acc.: 60.16%] [G loss: 0.740604]\n",
      "epoch:21 step:16709 [D loss: 0.653642, acc.: 60.94%] [G loss: 0.703363]\n",
      "epoch:21 step:16710 [D loss: 0.682003, acc.: 60.16%] [G loss: 0.714703]\n",
      "epoch:21 step:16711 [D loss: 0.642880, acc.: 68.75%] [G loss: 0.807587]\n",
      "epoch:21 step:16712 [D loss: 0.708474, acc.: 50.78%] [G loss: 0.696121]\n",
      "epoch:21 step:16713 [D loss: 0.690679, acc.: 56.25%] [G loss: 0.619213]\n",
      "epoch:21 step:16714 [D loss: 0.764504, acc.: 37.50%] [G loss: 0.677306]\n",
      "epoch:21 step:16715 [D loss: 0.752981, acc.: 35.16%] [G loss: 0.644887]\n",
      "epoch:21 step:16716 [D loss: 0.759187, acc.: 33.59%] [G loss: 0.718093]\n",
      "epoch:21 step:16717 [D loss: 0.732179, acc.: 42.97%] [G loss: 0.652172]\n",
      "epoch:21 step:16718 [D loss: 0.720100, acc.: 45.31%] [G loss: 0.699653]\n",
      "epoch:21 step:16719 [D loss: 0.712931, acc.: 50.00%] [G loss: 0.692803]\n",
      "epoch:21 step:16720 [D loss: 0.675364, acc.: 54.69%] [G loss: 0.733038]\n",
      "epoch:21 step:16721 [D loss: 0.762159, acc.: 35.94%] [G loss: 0.791802]\n",
      "epoch:21 step:16722 [D loss: 0.766727, acc.: 34.38%] [G loss: 0.726917]\n",
      "epoch:21 step:16723 [D loss: 0.686693, acc.: 53.91%] [G loss: 0.772453]\n",
      "epoch:21 step:16724 [D loss: 0.709658, acc.: 47.66%] [G loss: 0.793780]\n",
      "epoch:21 step:16725 [D loss: 0.724546, acc.: 49.22%] [G loss: 0.753922]\n",
      "epoch:21 step:16726 [D loss: 0.713274, acc.: 41.41%] [G loss: 0.793199]\n",
      "epoch:21 step:16727 [D loss: 0.680171, acc.: 52.34%] [G loss: 0.869222]\n",
      "epoch:21 step:16728 [D loss: 0.719749, acc.: 46.09%] [G loss: 0.798584]\n",
      "epoch:21 step:16729 [D loss: 0.626896, acc.: 72.66%] [G loss: 0.850862]\n",
      "epoch:21 step:16730 [D loss: 0.699702, acc.: 57.03%] [G loss: 0.726223]\n",
      "epoch:21 step:16731 [D loss: 0.667801, acc.: 58.59%] [G loss: 0.759898]\n",
      "epoch:21 step:16732 [D loss: 0.682945, acc.: 58.59%] [G loss: 0.775112]\n",
      "epoch:21 step:16733 [D loss: 0.684389, acc.: 56.25%] [G loss: 0.736579]\n",
      "epoch:21 step:16734 [D loss: 0.638084, acc.: 69.53%] [G loss: 0.785310]\n",
      "epoch:21 step:16735 [D loss: 0.679777, acc.: 57.03%] [G loss: 0.747879]\n",
      "epoch:21 step:16736 [D loss: 0.625632, acc.: 71.88%] [G loss: 0.711139]\n",
      "epoch:21 step:16737 [D loss: 0.624070, acc.: 68.75%] [G loss: 0.752105]\n",
      "epoch:21 step:16738 [D loss: 0.698211, acc.: 53.91%] [G loss: 0.717871]\n",
      "epoch:21 step:16739 [D loss: 0.676409, acc.: 49.22%] [G loss: 0.668325]\n",
      "epoch:21 step:16740 [D loss: 0.660283, acc.: 60.94%] [G loss: 0.670105]\n",
      "epoch:21 step:16741 [D loss: 0.691965, acc.: 57.81%] [G loss: 0.748688]\n",
      "epoch:21 step:16742 [D loss: 0.680424, acc.: 57.03%] [G loss: 0.750974]\n",
      "epoch:21 step:16743 [D loss: 0.684139, acc.: 64.06%] [G loss: 0.770590]\n",
      "epoch:21 step:16744 [D loss: 0.728141, acc.: 45.31%] [G loss: 0.673380]\n",
      "epoch:21 step:16745 [D loss: 0.688142, acc.: 57.03%] [G loss: 0.726098]\n",
      "epoch:21 step:16746 [D loss: 0.721079, acc.: 46.88%] [G loss: 0.721702]\n",
      "epoch:21 step:16747 [D loss: 0.707576, acc.: 48.44%] [G loss: 0.676886]\n",
      "epoch:21 step:16748 [D loss: 0.699488, acc.: 53.12%] [G loss: 0.751468]\n",
      "epoch:21 step:16749 [D loss: 0.724722, acc.: 43.75%] [G loss: 0.744739]\n",
      "epoch:21 step:16750 [D loss: 0.751490, acc.: 35.94%] [G loss: 0.719303]\n",
      "epoch:21 step:16751 [D loss: 0.709825, acc.: 52.34%] [G loss: 0.748677]\n",
      "epoch:21 step:16752 [D loss: 0.727747, acc.: 42.97%] [G loss: 0.810563]\n",
      "epoch:21 step:16753 [D loss: 0.707282, acc.: 50.78%] [G loss: 0.746439]\n",
      "epoch:21 step:16754 [D loss: 0.669991, acc.: 56.25%] [G loss: 0.779381]\n",
      "epoch:21 step:16755 [D loss: 0.699621, acc.: 52.34%] [G loss: 0.819560]\n",
      "epoch:21 step:16756 [D loss: 0.685060, acc.: 50.78%] [G loss: 0.782764]\n",
      "epoch:21 step:16757 [D loss: 0.705576, acc.: 49.22%] [G loss: 0.772589]\n",
      "epoch:21 step:16758 [D loss: 0.682258, acc.: 55.47%] [G loss: 0.754321]\n",
      "epoch:21 step:16759 [D loss: 0.695358, acc.: 55.47%] [G loss: 0.788692]\n",
      "epoch:21 step:16760 [D loss: 0.649938, acc.: 61.72%] [G loss: 0.762822]\n",
      "epoch:21 step:16761 [D loss: 0.653007, acc.: 60.16%] [G loss: 0.721645]\n",
      "epoch:21 step:16762 [D loss: 0.652085, acc.: 62.50%] [G loss: 0.734579]\n",
      "epoch:21 step:16763 [D loss: 0.686740, acc.: 57.03%] [G loss: 0.790267]\n",
      "epoch:21 step:16764 [D loss: 0.684399, acc.: 54.69%] [G loss: 0.685458]\n",
      "epoch:21 step:16765 [D loss: 0.726870, acc.: 49.22%] [G loss: 0.654620]\n",
      "epoch:21 step:16766 [D loss: 0.660191, acc.: 58.59%] [G loss: 0.693898]\n",
      "epoch:21 step:16767 [D loss: 0.725022, acc.: 46.88%] [G loss: 0.744158]\n",
      "epoch:21 step:16768 [D loss: 0.688308, acc.: 53.12%] [G loss: 0.707975]\n",
      "epoch:21 step:16769 [D loss: 0.680811, acc.: 54.69%] [G loss: 0.801077]\n",
      "epoch:21 step:16770 [D loss: 0.715309, acc.: 50.00%] [G loss: 0.766666]\n",
      "epoch:21 step:16771 [D loss: 0.693209, acc.: 47.66%] [G loss: 0.738358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16772 [D loss: 0.710885, acc.: 48.44%] [G loss: 0.767512]\n",
      "epoch:21 step:16773 [D loss: 0.688946, acc.: 57.03%] [G loss: 0.717670]\n",
      "epoch:21 step:16774 [D loss: 0.709412, acc.: 42.97%] [G loss: 0.756822]\n",
      "epoch:21 step:16775 [D loss: 0.676978, acc.: 57.03%] [G loss: 0.758162]\n",
      "epoch:21 step:16776 [D loss: 0.715138, acc.: 46.09%] [G loss: 0.665935]\n",
      "epoch:21 step:16777 [D loss: 0.660295, acc.: 60.94%] [G loss: 0.731228]\n",
      "epoch:21 step:16778 [D loss: 0.690912, acc.: 52.34%] [G loss: 0.800260]\n",
      "epoch:21 step:16779 [D loss: 0.705923, acc.: 52.34%] [G loss: 0.780689]\n",
      "epoch:21 step:16780 [D loss: 0.646301, acc.: 60.94%] [G loss: 0.781729]\n",
      "epoch:21 step:16781 [D loss: 0.714040, acc.: 53.12%] [G loss: 0.733267]\n",
      "epoch:21 step:16782 [D loss: 0.646876, acc.: 57.81%] [G loss: 0.749508]\n",
      "epoch:21 step:16783 [D loss: 0.713399, acc.: 43.75%] [G loss: 0.740330]\n",
      "epoch:21 step:16784 [D loss: 0.678752, acc.: 56.25%] [G loss: 0.754988]\n",
      "epoch:21 step:16785 [D loss: 0.676471, acc.: 53.91%] [G loss: 0.824173]\n",
      "epoch:21 step:16786 [D loss: 0.667559, acc.: 56.25%] [G loss: 0.859592]\n",
      "epoch:21 step:16787 [D loss: 0.702698, acc.: 52.34%] [G loss: 0.747398]\n",
      "epoch:21 step:16788 [D loss: 0.642827, acc.: 67.97%] [G loss: 0.770102]\n",
      "epoch:21 step:16789 [D loss: 0.724601, acc.: 43.75%] [G loss: 0.734071]\n",
      "epoch:21 step:16790 [D loss: 0.709595, acc.: 53.12%] [G loss: 0.814123]\n",
      "epoch:21 step:16791 [D loss: 0.671142, acc.: 60.16%] [G loss: 0.806540]\n",
      "epoch:21 step:16792 [D loss: 0.718145, acc.: 49.22%] [G loss: 0.768799]\n",
      "epoch:21 step:16793 [D loss: 0.701835, acc.: 46.88%] [G loss: 0.705531]\n",
      "epoch:21 step:16794 [D loss: 0.689800, acc.: 53.91%] [G loss: 0.705506]\n",
      "epoch:21 step:16795 [D loss: 0.653771, acc.: 63.28%] [G loss: 0.677853]\n",
      "epoch:21 step:16796 [D loss: 0.683296, acc.: 52.34%] [G loss: 0.698842]\n",
      "epoch:21 step:16797 [D loss: 0.646615, acc.: 63.28%] [G loss: 0.691503]\n",
      "epoch:21 step:16798 [D loss: 0.737555, acc.: 45.31%] [G loss: 0.696579]\n",
      "epoch:21 step:16799 [D loss: 0.684301, acc.: 55.47%] [G loss: 0.751540]\n",
      "epoch:21 step:16800 [D loss: 0.670237, acc.: 54.69%] [G loss: 0.798306]\n",
      "epoch:21 step:16801 [D loss: 0.726676, acc.: 46.88%] [G loss: 0.766294]\n",
      "epoch:21 step:16802 [D loss: 0.683804, acc.: 54.69%] [G loss: 0.640347]\n",
      "epoch:21 step:16803 [D loss: 0.682328, acc.: 55.47%] [G loss: 0.718802]\n",
      "epoch:21 step:16804 [D loss: 0.653150, acc.: 59.38%] [G loss: 0.726138]\n",
      "epoch:21 step:16805 [D loss: 0.675797, acc.: 65.62%] [G loss: 0.751122]\n",
      "epoch:21 step:16806 [D loss: 0.722252, acc.: 50.00%] [G loss: 0.714341]\n",
      "epoch:21 step:16807 [D loss: 0.728578, acc.: 46.09%] [G loss: 0.746091]\n",
      "epoch:21 step:16808 [D loss: 0.671042, acc.: 54.69%] [G loss: 0.789132]\n",
      "epoch:21 step:16809 [D loss: 0.696456, acc.: 53.91%] [G loss: 0.738745]\n",
      "epoch:21 step:16810 [D loss: 0.667940, acc.: 59.38%] [G loss: 0.757380]\n",
      "epoch:21 step:16811 [D loss: 0.643065, acc.: 70.31%] [G loss: 0.844325]\n",
      "epoch:21 step:16812 [D loss: 0.712703, acc.: 53.91%] [G loss: 0.831641]\n",
      "epoch:21 step:16813 [D loss: 0.665185, acc.: 61.72%] [G loss: 0.751150]\n",
      "epoch:21 step:16814 [D loss: 0.710724, acc.: 43.75%] [G loss: 0.759049]\n",
      "epoch:21 step:16815 [D loss: 0.721428, acc.: 48.44%] [G loss: 0.746032]\n",
      "epoch:21 step:16816 [D loss: 0.718156, acc.: 44.53%] [G loss: 0.713827]\n",
      "epoch:21 step:16817 [D loss: 0.713408, acc.: 41.41%] [G loss: 0.672695]\n",
      "epoch:21 step:16818 [D loss: 0.703678, acc.: 48.44%] [G loss: 0.737568]\n",
      "epoch:21 step:16819 [D loss: 0.700667, acc.: 48.44%] [G loss: 0.713095]\n",
      "epoch:21 step:16820 [D loss: 0.710383, acc.: 49.22%] [G loss: 0.789419]\n",
      "epoch:21 step:16821 [D loss: 0.738260, acc.: 42.19%] [G loss: 0.724976]\n",
      "epoch:21 step:16822 [D loss: 0.696341, acc.: 50.00%] [G loss: 0.777418]\n",
      "epoch:21 step:16823 [D loss: 0.713686, acc.: 48.44%] [G loss: 0.797088]\n",
      "epoch:21 step:16824 [D loss: 0.707684, acc.: 47.66%] [G loss: 0.773426]\n",
      "epoch:21 step:16825 [D loss: 0.729348, acc.: 46.09%] [G loss: 0.700155]\n",
      "epoch:21 step:16826 [D loss: 0.712143, acc.: 50.78%] [G loss: 0.743559]\n",
      "epoch:21 step:16827 [D loss: 0.703280, acc.: 54.69%] [G loss: 0.735369]\n",
      "epoch:21 step:16828 [D loss: 0.688053, acc.: 57.81%] [G loss: 0.760716]\n",
      "epoch:21 step:16829 [D loss: 0.713692, acc.: 46.09%] [G loss: 0.683384]\n",
      "epoch:21 step:16830 [D loss: 0.700201, acc.: 52.34%] [G loss: 0.672405]\n",
      "epoch:21 step:16831 [D loss: 0.707419, acc.: 49.22%] [G loss: 0.736886]\n",
      "epoch:21 step:16832 [D loss: 0.714199, acc.: 46.88%] [G loss: 0.777663]\n",
      "epoch:21 step:16833 [D loss: 0.686274, acc.: 54.69%] [G loss: 0.726748]\n",
      "epoch:21 step:16834 [D loss: 0.698199, acc.: 53.91%] [G loss: 0.739397]\n",
      "epoch:21 step:16835 [D loss: 0.672027, acc.: 57.81%] [G loss: 0.742636]\n",
      "epoch:21 step:16836 [D loss: 0.739331, acc.: 40.62%] [G loss: 0.744124]\n",
      "epoch:21 step:16837 [D loss: 0.717069, acc.: 37.50%] [G loss: 0.741995]\n",
      "epoch:21 step:16838 [D loss: 0.697038, acc.: 55.47%] [G loss: 0.715348]\n",
      "epoch:21 step:16839 [D loss: 0.708662, acc.: 50.78%] [G loss: 0.761905]\n",
      "epoch:21 step:16840 [D loss: 0.695804, acc.: 53.12%] [G loss: 0.755694]\n",
      "epoch:21 step:16841 [D loss: 0.688221, acc.: 53.91%] [G loss: 0.744471]\n",
      "epoch:21 step:16842 [D loss: 0.687406, acc.: 50.78%] [G loss: 0.814605]\n",
      "epoch:21 step:16843 [D loss: 0.675182, acc.: 54.69%] [G loss: 0.804860]\n",
      "epoch:21 step:16844 [D loss: 0.701193, acc.: 51.56%] [G loss: 0.790929]\n",
      "epoch:21 step:16845 [D loss: 0.679715, acc.: 55.47%] [G loss: 0.786888]\n",
      "epoch:21 step:16846 [D loss: 0.718093, acc.: 41.41%] [G loss: 0.860892]\n",
      "epoch:21 step:16847 [D loss: 0.687413, acc.: 55.47%] [G loss: 0.801135]\n",
      "epoch:21 step:16848 [D loss: 0.679775, acc.: 57.81%] [G loss: 0.859071]\n",
      "epoch:21 step:16849 [D loss: 0.709346, acc.: 47.66%] [G loss: 0.850536]\n",
      "epoch:21 step:16850 [D loss: 0.704166, acc.: 46.09%] [G loss: 0.785890]\n",
      "epoch:21 step:16851 [D loss: 0.658589, acc.: 64.84%] [G loss: 0.771611]\n",
      "epoch:21 step:16852 [D loss: 0.705287, acc.: 50.78%] [G loss: 0.793079]\n",
      "epoch:21 step:16853 [D loss: 0.662180, acc.: 60.94%] [G loss: 0.772394]\n",
      "epoch:21 step:16854 [D loss: 0.696551, acc.: 53.12%] [G loss: 0.806577]\n",
      "epoch:21 step:16855 [D loss: 0.713479, acc.: 46.09%] [G loss: 0.748141]\n",
      "epoch:21 step:16856 [D loss: 0.697983, acc.: 48.44%] [G loss: 0.796620]\n",
      "epoch:21 step:16857 [D loss: 0.683761, acc.: 57.03%] [G loss: 0.800569]\n",
      "epoch:21 step:16858 [D loss: 0.709316, acc.: 40.62%] [G loss: 0.751641]\n",
      "epoch:21 step:16859 [D loss: 0.729874, acc.: 42.97%] [G loss: 0.780935]\n",
      "epoch:21 step:16860 [D loss: 0.740129, acc.: 49.22%] [G loss: 0.753980]\n",
      "epoch:21 step:16861 [D loss: 0.702595, acc.: 53.12%] [G loss: 0.830048]\n",
      "epoch:21 step:16862 [D loss: 0.633361, acc.: 68.75%] [G loss: 0.822370]\n",
      "epoch:21 step:16863 [D loss: 0.710476, acc.: 39.06%] [G loss: 0.786022]\n",
      "epoch:21 step:16864 [D loss: 0.669163, acc.: 60.94%] [G loss: 0.766967]\n",
      "epoch:21 step:16865 [D loss: 0.687436, acc.: 55.47%] [G loss: 0.700513]\n",
      "epoch:21 step:16866 [D loss: 0.701804, acc.: 42.19%] [G loss: 0.700454]\n",
      "epoch:21 step:16867 [D loss: 0.665144, acc.: 61.72%] [G loss: 0.748851]\n",
      "epoch:21 step:16868 [D loss: 0.719509, acc.: 46.88%] [G loss: 0.745438]\n",
      "epoch:21 step:16869 [D loss: 0.661923, acc.: 62.50%] [G loss: 0.804338]\n",
      "epoch:21 step:16870 [D loss: 0.682747, acc.: 57.81%] [G loss: 0.786529]\n",
      "epoch:21 step:16871 [D loss: 0.709960, acc.: 51.56%] [G loss: 0.745332]\n",
      "epoch:21 step:16872 [D loss: 0.676021, acc.: 57.03%] [G loss: 0.745399]\n",
      "epoch:21 step:16873 [D loss: 0.677823, acc.: 60.16%] [G loss: 0.834507]\n",
      "epoch:21 step:16874 [D loss: 0.762072, acc.: 42.97%] [G loss: 0.702710]\n",
      "epoch:21 step:16875 [D loss: 0.645408, acc.: 65.62%] [G loss: 0.746562]\n",
      "epoch:21 step:16876 [D loss: 0.703193, acc.: 47.66%] [G loss: 0.715075]\n",
      "epoch:21 step:16877 [D loss: 0.708789, acc.: 53.91%] [G loss: 0.718603]\n",
      "epoch:21 step:16878 [D loss: 0.682688, acc.: 57.81%] [G loss: 0.768039]\n",
      "epoch:21 step:16879 [D loss: 0.673441, acc.: 59.38%] [G loss: 0.823207]\n",
      "epoch:21 step:16880 [D loss: 0.710240, acc.: 46.88%] [G loss: 0.778611]\n",
      "epoch:21 step:16881 [D loss: 0.681824, acc.: 55.47%] [G loss: 0.714151]\n",
      "epoch:21 step:16882 [D loss: 0.727842, acc.: 36.72%] [G loss: 0.746322]\n",
      "epoch:21 step:16883 [D loss: 0.737069, acc.: 42.19%] [G loss: 0.740795]\n",
      "epoch:21 step:16884 [D loss: 0.706333, acc.: 45.31%] [G loss: 0.717917]\n",
      "epoch:21 step:16885 [D loss: 0.679323, acc.: 57.03%] [G loss: 0.752691]\n",
      "epoch:21 step:16886 [D loss: 0.702186, acc.: 50.00%] [G loss: 0.722127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16887 [D loss: 0.721784, acc.: 46.88%] [G loss: 0.729435]\n",
      "epoch:21 step:16888 [D loss: 0.717031, acc.: 50.00%] [G loss: 0.721471]\n",
      "epoch:21 step:16889 [D loss: 0.725295, acc.: 44.53%] [G loss: 0.738107]\n",
      "epoch:21 step:16890 [D loss: 0.703666, acc.: 47.66%] [G loss: 0.734274]\n",
      "epoch:21 step:16891 [D loss: 0.687840, acc.: 56.25%] [G loss: 0.741059]\n",
      "epoch:21 step:16892 [D loss: 0.704426, acc.: 50.00%] [G loss: 0.778037]\n",
      "epoch:21 step:16893 [D loss: 0.713440, acc.: 49.22%] [G loss: 0.716493]\n",
      "epoch:21 step:16894 [D loss: 0.747191, acc.: 34.38%] [G loss: 0.689653]\n",
      "epoch:21 step:16895 [D loss: 0.719165, acc.: 46.88%] [G loss: 0.744640]\n",
      "epoch:21 step:16896 [D loss: 0.679401, acc.: 55.47%] [G loss: 0.761823]\n",
      "epoch:21 step:16897 [D loss: 0.668515, acc.: 57.03%] [G loss: 0.791802]\n",
      "epoch:21 step:16898 [D loss: 0.677815, acc.: 55.47%] [G loss: 0.746375]\n",
      "epoch:21 step:16899 [D loss: 0.678951, acc.: 53.12%] [G loss: 0.686994]\n",
      "epoch:21 step:16900 [D loss: 0.658364, acc.: 64.84%] [G loss: 0.784202]\n",
      "epoch:21 step:16901 [D loss: 0.703726, acc.: 57.81%] [G loss: 0.774031]\n",
      "epoch:21 step:16902 [D loss: 0.675588, acc.: 57.03%] [G loss: 0.736116]\n",
      "epoch:21 step:16903 [D loss: 0.713114, acc.: 44.53%] [G loss: 0.736612]\n",
      "epoch:21 step:16904 [D loss: 0.679227, acc.: 56.25%] [G loss: 0.831942]\n",
      "epoch:21 step:16905 [D loss: 0.680403, acc.: 54.69%] [G loss: 0.768350]\n",
      "epoch:21 step:16906 [D loss: 0.641491, acc.: 64.06%] [G loss: 0.761256]\n",
      "epoch:21 step:16907 [D loss: 0.659292, acc.: 58.59%] [G loss: 0.805094]\n",
      "epoch:21 step:16908 [D loss: 0.690050, acc.: 52.34%] [G loss: 0.838554]\n",
      "epoch:21 step:16909 [D loss: 0.690927, acc.: 55.47%] [G loss: 0.835640]\n",
      "epoch:21 step:16910 [D loss: 0.734192, acc.: 40.62%] [G loss: 0.744667]\n",
      "epoch:21 step:16911 [D loss: 0.706403, acc.: 46.88%] [G loss: 0.791321]\n",
      "epoch:21 step:16912 [D loss: 0.692049, acc.: 46.09%] [G loss: 0.751785]\n",
      "epoch:21 step:16913 [D loss: 0.700807, acc.: 48.44%] [G loss: 0.763296]\n",
      "epoch:21 step:16914 [D loss: 0.718075, acc.: 46.09%] [G loss: 0.735211]\n",
      "epoch:21 step:16915 [D loss: 0.751860, acc.: 40.62%] [G loss: 0.686061]\n",
      "epoch:21 step:16916 [D loss: 0.669406, acc.: 57.03%] [G loss: 0.726205]\n",
      "epoch:21 step:16917 [D loss: 0.689829, acc.: 56.25%] [G loss: 0.707136]\n",
      "epoch:21 step:16918 [D loss: 0.675903, acc.: 53.91%] [G loss: 0.741205]\n",
      "epoch:21 step:16919 [D loss: 0.676090, acc.: 55.47%] [G loss: 0.685916]\n",
      "epoch:21 step:16920 [D loss: 0.710684, acc.: 42.97%] [G loss: 0.714696]\n",
      "epoch:21 step:16921 [D loss: 0.708019, acc.: 47.66%] [G loss: 0.713609]\n",
      "epoch:21 step:16922 [D loss: 0.655242, acc.: 63.28%] [G loss: 0.701379]\n",
      "epoch:21 step:16923 [D loss: 0.718628, acc.: 37.50%] [G loss: 0.783389]\n",
      "epoch:21 step:16924 [D loss: 0.680081, acc.: 60.16%] [G loss: 0.742464]\n",
      "epoch:21 step:16925 [D loss: 0.685511, acc.: 50.78%] [G loss: 0.756125]\n",
      "epoch:21 step:16926 [D loss: 0.681995, acc.: 60.16%] [G loss: 0.776988]\n",
      "epoch:21 step:16927 [D loss: 0.747124, acc.: 43.75%] [G loss: 0.713928]\n",
      "epoch:21 step:16928 [D loss: 0.671373, acc.: 57.03%] [G loss: 0.729473]\n",
      "epoch:21 step:16929 [D loss: 0.727628, acc.: 46.88%] [G loss: 0.736374]\n",
      "epoch:21 step:16930 [D loss: 0.649394, acc.: 66.41%] [G loss: 0.747381]\n",
      "epoch:21 step:16931 [D loss: 0.692821, acc.: 57.81%] [G loss: 0.749380]\n",
      "epoch:21 step:16932 [D loss: 0.656768, acc.: 63.28%] [G loss: 0.704065]\n",
      "epoch:21 step:16933 [D loss: 0.708425, acc.: 49.22%] [G loss: 0.741954]\n",
      "epoch:21 step:16934 [D loss: 0.738390, acc.: 37.50%] [G loss: 0.732874]\n",
      "epoch:21 step:16935 [D loss: 0.676744, acc.: 57.81%] [G loss: 0.756931]\n",
      "epoch:21 step:16936 [D loss: 0.682601, acc.: 56.25%] [G loss: 0.777600]\n",
      "epoch:21 step:16937 [D loss: 0.684726, acc.: 53.12%] [G loss: 0.722551]\n",
      "epoch:21 step:16938 [D loss: 0.727007, acc.: 40.62%] [G loss: 0.777021]\n",
      "epoch:21 step:16939 [D loss: 0.762594, acc.: 32.03%] [G loss: 0.741945]\n",
      "epoch:21 step:16940 [D loss: 0.693612, acc.: 51.56%] [G loss: 0.811567]\n",
      "epoch:21 step:16941 [D loss: 0.705352, acc.: 46.88%] [G loss: 0.740193]\n",
      "epoch:21 step:16942 [D loss: 0.714774, acc.: 45.31%] [G loss: 0.717834]\n",
      "epoch:21 step:16943 [D loss: 0.683383, acc.: 58.59%] [G loss: 0.800173]\n",
      "epoch:21 step:16944 [D loss: 0.655573, acc.: 60.16%] [G loss: 0.749827]\n",
      "epoch:21 step:16945 [D loss: 0.681410, acc.: 55.47%] [G loss: 0.783414]\n",
      "epoch:21 step:16946 [D loss: 0.641889, acc.: 67.97%] [G loss: 0.812419]\n",
      "epoch:21 step:16947 [D loss: 0.760690, acc.: 37.50%] [G loss: 0.739348]\n",
      "epoch:21 step:16948 [D loss: 0.685480, acc.: 57.81%] [G loss: 0.676107]\n",
      "epoch:21 step:16949 [D loss: 0.728145, acc.: 40.62%] [G loss: 0.774586]\n",
      "epoch:21 step:16950 [D loss: 0.701791, acc.: 46.09%] [G loss: 0.700334]\n",
      "epoch:21 step:16951 [D loss: 0.653730, acc.: 67.97%] [G loss: 0.774325]\n",
      "epoch:21 step:16952 [D loss: 0.693353, acc.: 53.12%] [G loss: 0.771093]\n",
      "epoch:21 step:16953 [D loss: 0.706482, acc.: 48.44%] [G loss: 0.773264]\n",
      "epoch:21 step:16954 [D loss: 0.700946, acc.: 45.31%] [G loss: 0.699191]\n",
      "epoch:21 step:16955 [D loss: 0.695990, acc.: 50.78%] [G loss: 0.754639]\n",
      "epoch:21 step:16956 [D loss: 0.691417, acc.: 56.25%] [G loss: 0.742144]\n",
      "epoch:21 step:16957 [D loss: 0.678778, acc.: 53.91%] [G loss: 0.784256]\n",
      "epoch:21 step:16958 [D loss: 0.686035, acc.: 58.59%] [G loss: 0.727863]\n",
      "epoch:21 step:16959 [D loss: 0.764328, acc.: 33.59%] [G loss: 0.715577]\n",
      "epoch:21 step:16960 [D loss: 0.670545, acc.: 59.38%] [G loss: 0.715060]\n",
      "epoch:21 step:16961 [D loss: 0.683805, acc.: 55.47%] [G loss: 0.737138]\n",
      "epoch:21 step:16962 [D loss: 0.713892, acc.: 46.09%] [G loss: 0.733283]\n",
      "epoch:21 step:16963 [D loss: 0.677975, acc.: 59.38%] [G loss: 0.774948]\n",
      "epoch:21 step:16964 [D loss: 0.697821, acc.: 54.69%] [G loss: 0.757835]\n",
      "epoch:21 step:16965 [D loss: 0.736851, acc.: 39.06%] [G loss: 0.766918]\n",
      "epoch:21 step:16966 [D loss: 0.651948, acc.: 67.19%] [G loss: 0.754433]\n",
      "epoch:21 step:16967 [D loss: 0.704107, acc.: 50.78%] [G loss: 0.726417]\n",
      "epoch:21 step:16968 [D loss: 0.671817, acc.: 58.59%] [G loss: 0.795910]\n",
      "epoch:21 step:16969 [D loss: 0.675811, acc.: 58.59%] [G loss: 0.793365]\n",
      "epoch:21 step:16970 [D loss: 0.707724, acc.: 46.09%] [G loss: 0.826144]\n",
      "epoch:21 step:16971 [D loss: 0.690719, acc.: 59.38%] [G loss: 0.764703]\n",
      "epoch:21 step:16972 [D loss: 0.711861, acc.: 44.53%] [G loss: 0.744423]\n",
      "epoch:21 step:16973 [D loss: 0.668500, acc.: 60.94%] [G loss: 0.776626]\n",
      "epoch:21 step:16974 [D loss: 0.687996, acc.: 50.78%] [G loss: 0.777229]\n",
      "epoch:21 step:16975 [D loss: 0.716673, acc.: 52.34%] [G loss: 0.740494]\n",
      "epoch:21 step:16976 [D loss: 0.786134, acc.: 29.69%] [G loss: 0.759934]\n",
      "epoch:21 step:16977 [D loss: 0.706396, acc.: 52.34%] [G loss: 0.738378]\n",
      "epoch:21 step:16978 [D loss: 0.701161, acc.: 52.34%] [G loss: 0.730652]\n",
      "epoch:21 step:16979 [D loss: 0.630324, acc.: 65.62%] [G loss: 0.776767]\n",
      "epoch:21 step:16980 [D loss: 0.692334, acc.: 57.81%] [G loss: 0.781868]\n",
      "epoch:21 step:16981 [D loss: 0.682847, acc.: 59.38%] [G loss: 0.756520]\n",
      "epoch:21 step:16982 [D loss: 0.698955, acc.: 49.22%] [G loss: 0.717245]\n",
      "epoch:21 step:16983 [D loss: 0.714785, acc.: 45.31%] [G loss: 0.734247]\n",
      "epoch:21 step:16984 [D loss: 0.693890, acc.: 50.78%] [G loss: 0.690991]\n",
      "epoch:21 step:16985 [D loss: 0.658266, acc.: 62.50%] [G loss: 0.838271]\n",
      "epoch:21 step:16986 [D loss: 0.679493, acc.: 53.91%] [G loss: 0.831196]\n",
      "epoch:21 step:16987 [D loss: 0.704318, acc.: 46.09%] [G loss: 0.726069]\n",
      "epoch:21 step:16988 [D loss: 0.633196, acc.: 67.19%] [G loss: 0.797674]\n",
      "epoch:21 step:16989 [D loss: 0.660925, acc.: 58.59%] [G loss: 0.771951]\n",
      "epoch:21 step:16990 [D loss: 0.630937, acc.: 75.00%] [G loss: 0.792999]\n",
      "epoch:21 step:16991 [D loss: 0.698315, acc.: 55.47%] [G loss: 0.801045]\n",
      "epoch:21 step:16992 [D loss: 0.668985, acc.: 56.25%] [G loss: 0.861740]\n",
      "epoch:21 step:16993 [D loss: 0.707361, acc.: 53.91%] [G loss: 0.773855]\n",
      "epoch:21 step:16994 [D loss: 0.715683, acc.: 52.34%] [G loss: 0.807636]\n",
      "epoch:21 step:16995 [D loss: 0.668996, acc.: 60.94%] [G loss: 0.721956]\n",
      "epoch:21 step:16996 [D loss: 0.699805, acc.: 49.22%] [G loss: 0.711509]\n",
      "epoch:21 step:16997 [D loss: 0.693270, acc.: 49.22%] [G loss: 0.779363]\n",
      "epoch:21 step:16998 [D loss: 0.737631, acc.: 41.41%] [G loss: 0.771517]\n",
      "epoch:21 step:16999 [D loss: 0.680165, acc.: 58.59%] [G loss: 0.747196]\n",
      "epoch:21 step:17000 [D loss: 0.716542, acc.: 42.97%] [G loss: 0.725434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17001 [D loss: 0.674612, acc.: 66.41%] [G loss: 0.732789]\n",
      "epoch:21 step:17002 [D loss: 0.719292, acc.: 41.41%] [G loss: 0.747414]\n",
      "epoch:21 step:17003 [D loss: 0.672638, acc.: 60.94%] [G loss: 0.735756]\n",
      "epoch:21 step:17004 [D loss: 0.718962, acc.: 42.97%] [G loss: 0.731658]\n",
      "epoch:21 step:17005 [D loss: 0.703019, acc.: 57.81%] [G loss: 0.774576]\n",
      "epoch:21 step:17006 [D loss: 0.704519, acc.: 55.47%] [G loss: 0.722604]\n",
      "epoch:21 step:17007 [D loss: 0.712533, acc.: 51.56%] [G loss: 0.779163]\n",
      "epoch:21 step:17008 [D loss: 0.636264, acc.: 68.75%] [G loss: 0.755192]\n",
      "epoch:21 step:17009 [D loss: 0.664577, acc.: 63.28%] [G loss: 0.767732]\n",
      "epoch:21 step:17010 [D loss: 0.688372, acc.: 54.69%] [G loss: 0.771378]\n",
      "epoch:21 step:17011 [D loss: 0.641436, acc.: 71.88%] [G loss: 0.757614]\n",
      "epoch:21 step:17012 [D loss: 0.700752, acc.: 49.22%] [G loss: 0.730520]\n",
      "epoch:21 step:17013 [D loss: 0.701437, acc.: 47.66%] [G loss: 0.726232]\n",
      "epoch:21 step:17014 [D loss: 0.735666, acc.: 34.38%] [G loss: 0.671955]\n",
      "epoch:21 step:17015 [D loss: 0.733535, acc.: 45.31%] [G loss: 0.662192]\n",
      "epoch:21 step:17016 [D loss: 0.677674, acc.: 56.25%] [G loss: 0.732714]\n",
      "epoch:21 step:17017 [D loss: 0.723107, acc.: 38.28%] [G loss: 0.742331]\n",
      "epoch:21 step:17018 [D loss: 0.683330, acc.: 56.25%] [G loss: 0.796634]\n",
      "epoch:21 step:17019 [D loss: 0.677867, acc.: 60.16%] [G loss: 0.776530]\n",
      "epoch:21 step:17020 [D loss: 0.698261, acc.: 50.78%] [G loss: 0.743456]\n",
      "epoch:21 step:17021 [D loss: 0.682715, acc.: 52.34%] [G loss: 0.836419]\n",
      "epoch:21 step:17022 [D loss: 0.653891, acc.: 61.72%] [G loss: 0.815601]\n",
      "epoch:21 step:17023 [D loss: 0.685335, acc.: 56.25%] [G loss: 0.713654]\n",
      "epoch:21 step:17024 [D loss: 0.699841, acc.: 49.22%] [G loss: 0.768720]\n",
      "epoch:21 step:17025 [D loss: 0.743383, acc.: 29.69%] [G loss: 0.698954]\n",
      "epoch:21 step:17026 [D loss: 0.693924, acc.: 52.34%] [G loss: 0.695143]\n",
      "epoch:21 step:17027 [D loss: 0.699474, acc.: 49.22%] [G loss: 0.697278]\n",
      "epoch:21 step:17028 [D loss: 0.688600, acc.: 53.91%] [G loss: 0.749180]\n",
      "epoch:21 step:17029 [D loss: 0.658142, acc.: 66.41%] [G loss: 0.772087]\n",
      "epoch:21 step:17030 [D loss: 0.702935, acc.: 56.25%] [G loss: 0.730276]\n",
      "epoch:21 step:17031 [D loss: 0.708755, acc.: 46.88%] [G loss: 0.687093]\n",
      "epoch:21 step:17032 [D loss: 0.715543, acc.: 42.19%] [G loss: 0.774410]\n",
      "epoch:21 step:17033 [D loss: 0.670085, acc.: 61.72%] [G loss: 0.757435]\n",
      "epoch:21 step:17034 [D loss: 0.720039, acc.: 39.84%] [G loss: 0.729878]\n",
      "epoch:21 step:17035 [D loss: 0.746169, acc.: 34.38%] [G loss: 0.688176]\n",
      "epoch:21 step:17036 [D loss: 0.692654, acc.: 53.12%] [G loss: 0.715095]\n",
      "epoch:21 step:17037 [D loss: 0.649525, acc.: 68.75%] [G loss: 0.796798]\n",
      "epoch:21 step:17038 [D loss: 0.673014, acc.: 58.59%] [G loss: 0.782015]\n",
      "epoch:21 step:17039 [D loss: 0.698144, acc.: 52.34%] [G loss: 0.761518]\n",
      "epoch:21 step:17040 [D loss: 0.729025, acc.: 42.19%] [G loss: 0.735664]\n",
      "epoch:21 step:17041 [D loss: 0.668031, acc.: 60.16%] [G loss: 0.787163]\n",
      "epoch:21 step:17042 [D loss: 0.738359, acc.: 35.94%] [G loss: 0.729710]\n",
      "epoch:21 step:17043 [D loss: 0.683266, acc.: 56.25%] [G loss: 0.797745]\n",
      "epoch:21 step:17044 [D loss: 0.667491, acc.: 60.94%] [G loss: 0.792231]\n",
      "epoch:21 step:17045 [D loss: 0.656668, acc.: 67.97%] [G loss: 0.688868]\n",
      "epoch:21 step:17046 [D loss: 0.643288, acc.: 68.75%] [G loss: 0.748151]\n",
      "epoch:21 step:17047 [D loss: 0.742527, acc.: 41.41%] [G loss: 0.761124]\n",
      "epoch:21 step:17048 [D loss: 0.717987, acc.: 52.34%] [G loss: 0.712953]\n",
      "epoch:21 step:17049 [D loss: 0.696553, acc.: 49.22%] [G loss: 0.704064]\n",
      "epoch:21 step:17050 [D loss: 0.662721, acc.: 58.59%] [G loss: 0.688843]\n",
      "epoch:21 step:17051 [D loss: 0.726192, acc.: 49.22%] [G loss: 0.692336]\n",
      "epoch:21 step:17052 [D loss: 0.705764, acc.: 44.53%] [G loss: 0.718614]\n",
      "epoch:21 step:17053 [D loss: 0.661223, acc.: 64.06%] [G loss: 0.732897]\n",
      "epoch:21 step:17054 [D loss: 0.701280, acc.: 51.56%] [G loss: 0.712131]\n",
      "epoch:21 step:17055 [D loss: 0.687466, acc.: 56.25%] [G loss: 0.711132]\n",
      "epoch:21 step:17056 [D loss: 0.693963, acc.: 51.56%] [G loss: 0.755669]\n",
      "epoch:21 step:17057 [D loss: 0.693722, acc.: 52.34%] [G loss: 0.741909]\n",
      "epoch:21 step:17058 [D loss: 0.693863, acc.: 51.56%] [G loss: 0.723907]\n",
      "epoch:21 step:17059 [D loss: 0.697340, acc.: 50.00%] [G loss: 0.781300]\n",
      "epoch:21 step:17060 [D loss: 0.683495, acc.: 55.47%] [G loss: 0.803780]\n",
      "epoch:21 step:17061 [D loss: 0.664563, acc.: 61.72%] [G loss: 0.838733]\n",
      "epoch:21 step:17062 [D loss: 0.704044, acc.: 47.66%] [G loss: 0.724912]\n",
      "epoch:21 step:17063 [D loss: 0.678436, acc.: 62.50%] [G loss: 0.789316]\n",
      "epoch:21 step:17064 [D loss: 0.719112, acc.: 44.53%] [G loss: 0.771819]\n",
      "epoch:21 step:17065 [D loss: 0.663052, acc.: 59.38%] [G loss: 0.777549]\n",
      "epoch:21 step:17066 [D loss: 0.654650, acc.: 64.84%] [G loss: 0.773159]\n",
      "epoch:21 step:17067 [D loss: 0.608433, acc.: 72.66%] [G loss: 0.785538]\n",
      "epoch:21 step:17068 [D loss: 0.662620, acc.: 60.94%] [G loss: 0.735941]\n",
      "epoch:21 step:17069 [D loss: 0.628844, acc.: 71.88%] [G loss: 0.723180]\n",
      "epoch:21 step:17070 [D loss: 0.697976, acc.: 51.56%] [G loss: 0.691472]\n",
      "epoch:21 step:17071 [D loss: 0.650170, acc.: 63.28%] [G loss: 0.806086]\n",
      "epoch:21 step:17072 [D loss: 0.727475, acc.: 46.88%] [G loss: 0.725544]\n",
      "epoch:21 step:17073 [D loss: 0.657728, acc.: 64.84%] [G loss: 0.770665]\n",
      "epoch:21 step:17074 [D loss: 0.709318, acc.: 51.56%] [G loss: 0.701867]\n",
      "epoch:21 step:17075 [D loss: 0.685320, acc.: 51.56%] [G loss: 0.688307]\n",
      "epoch:21 step:17076 [D loss: 0.688402, acc.: 53.12%] [G loss: 0.656023]\n",
      "epoch:21 step:17077 [D loss: 0.637667, acc.: 70.31%] [G loss: 0.689936]\n",
      "epoch:21 step:17078 [D loss: 0.695553, acc.: 48.44%] [G loss: 0.665229]\n",
      "epoch:21 step:17079 [D loss: 0.708120, acc.: 46.88%] [G loss: 0.720781]\n",
      "epoch:21 step:17080 [D loss: 0.671954, acc.: 62.50%] [G loss: 0.716855]\n",
      "epoch:21 step:17081 [D loss: 0.698292, acc.: 55.47%] [G loss: 0.723293]\n",
      "epoch:21 step:17082 [D loss: 0.746670, acc.: 47.66%] [G loss: 0.697127]\n",
      "epoch:21 step:17083 [D loss: 0.686374, acc.: 57.81%] [G loss: 0.754458]\n",
      "epoch:21 step:17084 [D loss: 0.669357, acc.: 59.38%] [G loss: 0.739649]\n",
      "epoch:21 step:17085 [D loss: 0.684341, acc.: 50.00%] [G loss: 0.831232]\n",
      "epoch:21 step:17086 [D loss: 0.687836, acc.: 50.78%] [G loss: 0.801658]\n",
      "epoch:21 step:17087 [D loss: 0.681970, acc.: 56.25%] [G loss: 0.838022]\n",
      "epoch:21 step:17088 [D loss: 0.675479, acc.: 58.59%] [G loss: 0.840100]\n",
      "epoch:21 step:17089 [D loss: 0.677831, acc.: 57.81%] [G loss: 0.795001]\n",
      "epoch:21 step:17090 [D loss: 0.663268, acc.: 57.81%] [G loss: 0.861639]\n",
      "epoch:21 step:17091 [D loss: 0.676365, acc.: 57.81%] [G loss: 0.752442]\n",
      "epoch:21 step:17092 [D loss: 0.604416, acc.: 77.34%] [G loss: 0.754948]\n",
      "epoch:21 step:17093 [D loss: 0.733520, acc.: 41.41%] [G loss: 0.736108]\n",
      "epoch:21 step:17094 [D loss: 0.651571, acc.: 63.28%] [G loss: 0.725213]\n",
      "epoch:21 step:17095 [D loss: 0.635885, acc.: 69.53%] [G loss: 0.719065]\n",
      "epoch:21 step:17096 [D loss: 0.681982, acc.: 58.59%] [G loss: 0.753063]\n",
      "epoch:21 step:17097 [D loss: 0.682877, acc.: 60.16%] [G loss: 0.741794]\n",
      "epoch:21 step:17098 [D loss: 0.687676, acc.: 54.69%] [G loss: 0.723331]\n",
      "epoch:21 step:17099 [D loss: 0.575846, acc.: 78.91%] [G loss: 0.769387]\n",
      "epoch:21 step:17100 [D loss: 0.693231, acc.: 50.78%] [G loss: 0.698268]\n",
      "epoch:21 step:17101 [D loss: 0.650927, acc.: 64.84%] [G loss: 0.707991]\n",
      "epoch:21 step:17102 [D loss: 0.629173, acc.: 68.75%] [G loss: 0.699077]\n",
      "epoch:21 step:17103 [D loss: 0.741103, acc.: 46.88%] [G loss: 0.720200]\n",
      "epoch:21 step:17104 [D loss: 0.758500, acc.: 37.50%] [G loss: 0.629217]\n",
      "epoch:21 step:17105 [D loss: 0.746238, acc.: 39.06%] [G loss: 0.759961]\n",
      "epoch:21 step:17106 [D loss: 0.673487, acc.: 57.03%] [G loss: 0.699185]\n",
      "epoch:21 step:17107 [D loss: 0.676994, acc.: 57.81%] [G loss: 0.790917]\n",
      "epoch:21 step:17108 [D loss: 0.751223, acc.: 34.38%] [G loss: 0.770418]\n",
      "epoch:21 step:17109 [D loss: 0.722500, acc.: 40.62%] [G loss: 0.777552]\n",
      "epoch:21 step:17110 [D loss: 0.696726, acc.: 51.56%] [G loss: 0.760035]\n",
      "epoch:21 step:17111 [D loss: 0.710936, acc.: 49.22%] [G loss: 0.758662]\n",
      "epoch:21 step:17112 [D loss: 0.693128, acc.: 52.34%] [G loss: 0.823573]\n",
      "epoch:21 step:17113 [D loss: 0.667953, acc.: 57.03%] [G loss: 0.809745]\n",
      "epoch:21 step:17114 [D loss: 0.669871, acc.: 57.03%] [G loss: 0.712644]\n",
      "epoch:21 step:17115 [D loss: 0.700132, acc.: 55.47%] [G loss: 0.771864]\n",
      "epoch:21 step:17116 [D loss: 0.610872, acc.: 73.44%] [G loss: 0.825350]\n",
      "epoch:21 step:17117 [D loss: 0.660249, acc.: 67.19%] [G loss: 0.748042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17118 [D loss: 0.708560, acc.: 47.66%] [G loss: 0.792045]\n",
      "epoch:21 step:17119 [D loss: 0.642279, acc.: 67.19%] [G loss: 0.771318]\n",
      "epoch:21 step:17120 [D loss: 0.697221, acc.: 50.78%] [G loss: 0.738042]\n",
      "epoch:21 step:17121 [D loss: 0.664671, acc.: 63.28%] [G loss: 0.747617]\n",
      "epoch:21 step:17122 [D loss: 0.653539, acc.: 60.16%] [G loss: 0.704027]\n",
      "epoch:21 step:17123 [D loss: 0.697018, acc.: 54.69%] [G loss: 0.673473]\n",
      "epoch:21 step:17124 [D loss: 0.727775, acc.: 42.19%] [G loss: 0.635006]\n",
      "epoch:21 step:17125 [D loss: 0.706925, acc.: 56.25%] [G loss: 0.701301]\n",
      "epoch:21 step:17126 [D loss: 0.692236, acc.: 53.12%] [G loss: 0.666543]\n",
      "epoch:21 step:17127 [D loss: 0.686760, acc.: 53.12%] [G loss: 0.704484]\n",
      "epoch:21 step:17128 [D loss: 0.678577, acc.: 52.34%] [G loss: 0.824963]\n",
      "epoch:21 step:17129 [D loss: 0.714444, acc.: 47.66%] [G loss: 0.713028]\n",
      "epoch:21 step:17130 [D loss: 0.703529, acc.: 54.69%] [G loss: 0.811952]\n",
      "epoch:21 step:17131 [D loss: 0.715117, acc.: 46.88%] [G loss: 0.747266]\n",
      "epoch:21 step:17132 [D loss: 0.733770, acc.: 41.41%] [G loss: 0.694928]\n",
      "epoch:21 step:17133 [D loss: 0.708978, acc.: 48.44%] [G loss: 0.752232]\n",
      "epoch:21 step:17134 [D loss: 0.703301, acc.: 51.56%] [G loss: 0.765102]\n",
      "epoch:21 step:17135 [D loss: 0.680664, acc.: 60.16%] [G loss: 0.741455]\n",
      "epoch:21 step:17136 [D loss: 0.722461, acc.: 46.88%] [G loss: 0.753329]\n",
      "epoch:21 step:17137 [D loss: 0.654200, acc.: 64.06%] [G loss: 0.856384]\n",
      "epoch:21 step:17138 [D loss: 0.688765, acc.: 56.25%] [G loss: 0.830923]\n",
      "epoch:21 step:17139 [D loss: 0.713641, acc.: 52.34%] [G loss: 0.752454]\n",
      "epoch:21 step:17140 [D loss: 0.747276, acc.: 37.50%] [G loss: 0.746990]\n",
      "epoch:21 step:17141 [D loss: 0.711402, acc.: 46.09%] [G loss: 0.736875]\n",
      "epoch:21 step:17142 [D loss: 0.684950, acc.: 56.25%] [G loss: 0.807785]\n",
      "epoch:21 step:17143 [D loss: 0.671791, acc.: 60.94%] [G loss: 0.805598]\n",
      "epoch:21 step:17144 [D loss: 0.718877, acc.: 43.75%] [G loss: 0.703787]\n",
      "epoch:21 step:17145 [D loss: 0.701326, acc.: 50.00%] [G loss: 0.790271]\n",
      "epoch:21 step:17146 [D loss: 0.674469, acc.: 58.59%] [G loss: 0.692700]\n",
      "epoch:21 step:17147 [D loss: 0.703131, acc.: 50.00%] [G loss: 0.689045]\n",
      "epoch:21 step:17148 [D loss: 0.691381, acc.: 57.03%] [G loss: 0.686789]\n",
      "epoch:21 step:17149 [D loss: 0.710697, acc.: 49.22%] [G loss: 0.738133]\n",
      "epoch:21 step:17150 [D loss: 0.696563, acc.: 53.91%] [G loss: 0.711845]\n",
      "epoch:21 step:17151 [D loss: 0.677921, acc.: 60.16%] [G loss: 0.738903]\n",
      "epoch:21 step:17152 [D loss: 0.729786, acc.: 40.62%] [G loss: 0.745792]\n",
      "epoch:21 step:17153 [D loss: 0.710815, acc.: 53.12%] [G loss: 0.756178]\n",
      "epoch:21 step:17154 [D loss: 0.693737, acc.: 53.12%] [G loss: 0.745973]\n",
      "epoch:21 step:17155 [D loss: 0.679464, acc.: 57.81%] [G loss: 0.774994]\n",
      "epoch:21 step:17156 [D loss: 0.703590, acc.: 57.81%] [G loss: 0.710923]\n",
      "epoch:21 step:17157 [D loss: 0.716180, acc.: 48.44%] [G loss: 0.816024]\n",
      "epoch:21 step:17158 [D loss: 0.684507, acc.: 49.22%] [G loss: 0.804543]\n",
      "epoch:21 step:17159 [D loss: 0.712182, acc.: 44.53%] [G loss: 0.778319]\n",
      "epoch:21 step:17160 [D loss: 0.676806, acc.: 60.94%] [G loss: 0.787385]\n",
      "epoch:21 step:17161 [D loss: 0.678807, acc.: 57.81%] [G loss: 0.833817]\n",
      "epoch:21 step:17162 [D loss: 0.644102, acc.: 68.75%] [G loss: 0.783810]\n",
      "epoch:21 step:17163 [D loss: 0.701316, acc.: 50.00%] [G loss: 0.762870]\n",
      "epoch:21 step:17164 [D loss: 0.662179, acc.: 60.16%] [G loss: 0.776676]\n",
      "epoch:21 step:17165 [D loss: 0.728886, acc.: 37.50%] [G loss: 0.762069]\n",
      "epoch:21 step:17166 [D loss: 0.618091, acc.: 73.44%] [G loss: 0.714975]\n",
      "epoch:21 step:17167 [D loss: 0.698903, acc.: 50.00%] [G loss: 0.719313]\n",
      "epoch:21 step:17168 [D loss: 0.646744, acc.: 67.97%] [G loss: 0.763350]\n",
      "epoch:21 step:17169 [D loss: 0.692587, acc.: 52.34%] [G loss: 0.712492]\n",
      "epoch:21 step:17170 [D loss: 0.671653, acc.: 60.16%] [G loss: 0.732563]\n",
      "epoch:21 step:17171 [D loss: 0.737331, acc.: 48.44%] [G loss: 0.797096]\n",
      "epoch:21 step:17172 [D loss: 0.688101, acc.: 50.78%] [G loss: 0.812686]\n",
      "epoch:21 step:17173 [D loss: 0.675457, acc.: 54.69%] [G loss: 0.817575]\n",
      "epoch:21 step:17174 [D loss: 0.678712, acc.: 63.28%] [G loss: 0.751366]\n",
      "epoch:21 step:17175 [D loss: 0.682285, acc.: 57.81%] [G loss: 0.734217]\n",
      "epoch:21 step:17176 [D loss: 0.697192, acc.: 53.91%] [G loss: 0.710977]\n",
      "epoch:21 step:17177 [D loss: 0.710791, acc.: 52.34%] [G loss: 0.697858]\n",
      "epoch:21 step:17178 [D loss: 0.658302, acc.: 64.06%] [G loss: 0.742650]\n",
      "epoch:21 step:17179 [D loss: 0.634124, acc.: 70.31%] [G loss: 0.782074]\n",
      "epoch:21 step:17180 [D loss: 0.678013, acc.: 60.16%] [G loss: 0.805443]\n",
      "epoch:21 step:17181 [D loss: 0.712933, acc.: 42.97%] [G loss: 0.661335]\n",
      "epoch:21 step:17182 [D loss: 0.670371, acc.: 60.16%] [G loss: 0.782944]\n",
      "epoch:22 step:17183 [D loss: 0.663390, acc.: 63.28%] [G loss: 0.823606]\n",
      "epoch:22 step:17184 [D loss: 0.725943, acc.: 47.66%] [G loss: 0.787271]\n",
      "epoch:22 step:17185 [D loss: 0.717953, acc.: 46.09%] [G loss: 0.766420]\n",
      "epoch:22 step:17186 [D loss: 0.699170, acc.: 51.56%] [G loss: 0.756695]\n",
      "epoch:22 step:17187 [D loss: 0.729603, acc.: 43.75%] [G loss: 0.816475]\n",
      "epoch:22 step:17188 [D loss: 0.710543, acc.: 46.09%] [G loss: 0.805050]\n",
      "epoch:22 step:17189 [D loss: 0.705941, acc.: 47.66%] [G loss: 0.742183]\n",
      "epoch:22 step:17190 [D loss: 0.729830, acc.: 42.19%] [G loss: 0.805331]\n",
      "epoch:22 step:17191 [D loss: 0.663567, acc.: 60.94%] [G loss: 0.808726]\n",
      "epoch:22 step:17192 [D loss: 0.633148, acc.: 62.50%] [G loss: 0.797805]\n",
      "epoch:22 step:17193 [D loss: 0.691243, acc.: 54.69%] [G loss: 0.798168]\n",
      "epoch:22 step:17194 [D loss: 0.687874, acc.: 54.69%] [G loss: 0.787929]\n",
      "epoch:22 step:17195 [D loss: 0.661243, acc.: 58.59%] [G loss: 0.836560]\n",
      "epoch:22 step:17196 [D loss: 0.702211, acc.: 51.56%] [G loss: 0.759701]\n",
      "epoch:22 step:17197 [D loss: 0.693676, acc.: 53.91%] [G loss: 0.805232]\n",
      "epoch:22 step:17198 [D loss: 0.742837, acc.: 41.41%] [G loss: 0.723218]\n",
      "epoch:22 step:17199 [D loss: 0.692876, acc.: 52.34%] [G loss: 0.728091]\n",
      "epoch:22 step:17200 [D loss: 0.701133, acc.: 51.56%] [G loss: 0.738417]\n",
      "epoch:22 step:17201 [D loss: 0.699265, acc.: 57.81%] [G loss: 0.766108]\n",
      "epoch:22 step:17202 [D loss: 0.746241, acc.: 46.88%] [G loss: 0.773756]\n",
      "epoch:22 step:17203 [D loss: 0.719107, acc.: 47.66%] [G loss: 0.777529]\n",
      "epoch:22 step:17204 [D loss: 0.749161, acc.: 42.97%] [G loss: 0.757484]\n",
      "epoch:22 step:17205 [D loss: 0.719707, acc.: 50.00%] [G loss: 0.735837]\n",
      "epoch:22 step:17206 [D loss: 0.694970, acc.: 54.69%] [G loss: 0.788412]\n",
      "epoch:22 step:17207 [D loss: 0.760580, acc.: 40.62%] [G loss: 0.773097]\n",
      "epoch:22 step:17208 [D loss: 0.698755, acc.: 50.00%] [G loss: 0.757997]\n",
      "epoch:22 step:17209 [D loss: 0.647028, acc.: 66.41%] [G loss: 0.775671]\n",
      "epoch:22 step:17210 [D loss: 0.701664, acc.: 50.00%] [G loss: 0.733988]\n",
      "epoch:22 step:17211 [D loss: 0.684503, acc.: 56.25%] [G loss: 0.675290]\n",
      "epoch:22 step:17212 [D loss: 0.714595, acc.: 41.41%] [G loss: 0.746481]\n",
      "epoch:22 step:17213 [D loss: 0.667429, acc.: 60.16%] [G loss: 0.772520]\n",
      "epoch:22 step:17214 [D loss: 0.704083, acc.: 57.03%] [G loss: 0.757767]\n",
      "epoch:22 step:17215 [D loss: 0.717100, acc.: 47.66%] [G loss: 0.741350]\n",
      "epoch:22 step:17216 [D loss: 0.687310, acc.: 58.59%] [G loss: 0.769441]\n",
      "epoch:22 step:17217 [D loss: 0.720786, acc.: 49.22%] [G loss: 0.733848]\n",
      "epoch:22 step:17218 [D loss: 0.706176, acc.: 43.75%] [G loss: 0.799148]\n",
      "epoch:22 step:17219 [D loss: 0.735642, acc.: 40.62%] [G loss: 0.694177]\n",
      "epoch:22 step:17220 [D loss: 0.689471, acc.: 59.38%] [G loss: 0.702710]\n",
      "epoch:22 step:17221 [D loss: 0.666572, acc.: 64.06%] [G loss: 0.755978]\n",
      "epoch:22 step:17222 [D loss: 0.641913, acc.: 71.88%] [G loss: 0.758988]\n",
      "epoch:22 step:17223 [D loss: 0.648372, acc.: 66.41%] [G loss: 0.748352]\n",
      "epoch:22 step:17224 [D loss: 0.654503, acc.: 62.50%] [G loss: 0.746266]\n",
      "epoch:22 step:17225 [D loss: 0.695547, acc.: 55.47%] [G loss: 0.700985]\n",
      "epoch:22 step:17226 [D loss: 0.724700, acc.: 46.88%] [G loss: 0.699763]\n",
      "epoch:22 step:17227 [D loss: 0.689655, acc.: 50.78%] [G loss: 0.774779]\n",
      "epoch:22 step:17228 [D loss: 0.642214, acc.: 71.09%] [G loss: 0.824429]\n",
      "epoch:22 step:17229 [D loss: 0.699086, acc.: 54.69%] [G loss: 0.685738]\n",
      "epoch:22 step:17230 [D loss: 0.655743, acc.: 63.28%] [G loss: 0.844408]\n",
      "epoch:22 step:17231 [D loss: 0.666152, acc.: 57.81%] [G loss: 0.873629]\n",
      "epoch:22 step:17232 [D loss: 0.686546, acc.: 57.81%] [G loss: 0.771982]\n",
      "epoch:22 step:17233 [D loss: 0.632762, acc.: 69.53%] [G loss: 0.791225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17234 [D loss: 0.662979, acc.: 61.72%] [G loss: 0.813481]\n",
      "epoch:22 step:17235 [D loss: 0.709202, acc.: 47.66%] [G loss: 0.750222]\n",
      "epoch:22 step:17236 [D loss: 0.741287, acc.: 45.31%] [G loss: 0.762766]\n",
      "epoch:22 step:17237 [D loss: 0.663090, acc.: 61.72%] [G loss: 0.819205]\n",
      "epoch:22 step:17238 [D loss: 0.668438, acc.: 56.25%] [G loss: 0.823268]\n",
      "epoch:22 step:17239 [D loss: 0.699164, acc.: 51.56%] [G loss: 0.788398]\n",
      "epoch:22 step:17240 [D loss: 0.683507, acc.: 53.91%] [G loss: 0.792944]\n",
      "epoch:22 step:17241 [D loss: 0.708115, acc.: 51.56%] [G loss: 0.739518]\n",
      "epoch:22 step:17242 [D loss: 0.663092, acc.: 61.72%] [G loss: 0.811014]\n",
      "epoch:22 step:17243 [D loss: 0.691420, acc.: 53.12%] [G loss: 0.800047]\n",
      "epoch:22 step:17244 [D loss: 0.676360, acc.: 58.59%] [G loss: 0.820225]\n",
      "epoch:22 step:17245 [D loss: 0.681033, acc.: 59.38%] [G loss: 0.812909]\n",
      "epoch:22 step:17246 [D loss: 0.681827, acc.: 52.34%] [G loss: 0.783461]\n",
      "epoch:22 step:17247 [D loss: 0.668811, acc.: 60.94%] [G loss: 0.781057]\n",
      "epoch:22 step:17248 [D loss: 0.698608, acc.: 46.88%] [G loss: 0.790326]\n",
      "epoch:22 step:17249 [D loss: 0.718496, acc.: 49.22%] [G loss: 0.788887]\n",
      "epoch:22 step:17250 [D loss: 0.732293, acc.: 46.88%] [G loss: 0.769431]\n",
      "epoch:22 step:17251 [D loss: 0.670486, acc.: 63.28%] [G loss: 0.756370]\n",
      "epoch:22 step:17252 [D loss: 0.726974, acc.: 42.19%] [G loss: 0.692306]\n",
      "epoch:22 step:17253 [D loss: 0.711408, acc.: 50.78%] [G loss: 0.783069]\n",
      "epoch:22 step:17254 [D loss: 0.711897, acc.: 51.56%] [G loss: 0.755218]\n",
      "epoch:22 step:17255 [D loss: 0.685953, acc.: 51.56%] [G loss: 0.755341]\n",
      "epoch:22 step:17256 [D loss: 0.656421, acc.: 59.38%] [G loss: 0.707099]\n",
      "epoch:22 step:17257 [D loss: 0.642521, acc.: 69.53%] [G loss: 0.839471]\n",
      "epoch:22 step:17258 [D loss: 0.661782, acc.: 60.94%] [G loss: 0.767007]\n",
      "epoch:22 step:17259 [D loss: 0.701002, acc.: 53.12%] [G loss: 0.799279]\n",
      "epoch:22 step:17260 [D loss: 0.672688, acc.: 60.94%] [G loss: 0.763916]\n",
      "epoch:22 step:17261 [D loss: 0.672011, acc.: 61.72%] [G loss: 0.803011]\n",
      "epoch:22 step:17262 [D loss: 0.710614, acc.: 48.44%] [G loss: 0.706602]\n",
      "epoch:22 step:17263 [D loss: 0.724261, acc.: 42.97%] [G loss: 0.715956]\n",
      "epoch:22 step:17264 [D loss: 0.674662, acc.: 61.72%] [G loss: 0.717811]\n",
      "epoch:22 step:17265 [D loss: 0.675190, acc.: 55.47%] [G loss: 0.781872]\n",
      "epoch:22 step:17266 [D loss: 0.706865, acc.: 48.44%] [G loss: 0.750212]\n",
      "epoch:22 step:17267 [D loss: 0.664194, acc.: 62.50%] [G loss: 0.783932]\n",
      "epoch:22 step:17268 [D loss: 0.697148, acc.: 54.69%] [G loss: 0.704875]\n",
      "epoch:22 step:17269 [D loss: 0.703159, acc.: 45.31%] [G loss: 0.792605]\n",
      "epoch:22 step:17270 [D loss: 0.686269, acc.: 55.47%] [G loss: 0.684855]\n",
      "epoch:22 step:17271 [D loss: 0.731887, acc.: 41.41%] [G loss: 0.735813]\n",
      "epoch:22 step:17272 [D loss: 0.708989, acc.: 48.44%] [G loss: 0.759786]\n",
      "epoch:22 step:17273 [D loss: 0.690153, acc.: 53.91%] [G loss: 0.740657]\n",
      "epoch:22 step:17274 [D loss: 0.724454, acc.: 43.75%] [G loss: 0.706844]\n",
      "epoch:22 step:17275 [D loss: 0.700334, acc.: 50.78%] [G loss: 0.692750]\n",
      "epoch:22 step:17276 [D loss: 0.705050, acc.: 49.22%] [G loss: 0.746482]\n",
      "epoch:22 step:17277 [D loss: 0.733172, acc.: 41.41%] [G loss: 0.709358]\n",
      "epoch:22 step:17278 [D loss: 0.720447, acc.: 45.31%] [G loss: 0.822359]\n",
      "epoch:22 step:17279 [D loss: 0.696150, acc.: 51.56%] [G loss: 0.767777]\n",
      "epoch:22 step:17280 [D loss: 0.729562, acc.: 46.09%] [G loss: 0.762673]\n",
      "epoch:22 step:17281 [D loss: 0.703584, acc.: 54.69%] [G loss: 0.833423]\n",
      "epoch:22 step:17282 [D loss: 0.727425, acc.: 42.97%] [G loss: 0.782999]\n",
      "epoch:22 step:17283 [D loss: 0.702254, acc.: 50.78%] [G loss: 0.800595]\n",
      "epoch:22 step:17284 [D loss: 0.725987, acc.: 42.19%] [G loss: 0.757959]\n",
      "epoch:22 step:17285 [D loss: 0.738595, acc.: 42.97%] [G loss: 0.766516]\n",
      "epoch:22 step:17286 [D loss: 0.651944, acc.: 66.41%] [G loss: 0.726860]\n",
      "epoch:22 step:17287 [D loss: 0.651039, acc.: 64.06%] [G loss: 0.757659]\n",
      "epoch:22 step:17288 [D loss: 0.726857, acc.: 44.53%] [G loss: 0.771331]\n",
      "epoch:22 step:17289 [D loss: 0.685886, acc.: 57.81%] [G loss: 0.788615]\n",
      "epoch:22 step:17290 [D loss: 0.726365, acc.: 46.09%] [G loss: 0.716844]\n",
      "epoch:22 step:17291 [D loss: 0.710559, acc.: 49.22%] [G loss: 0.662337]\n",
      "epoch:22 step:17292 [D loss: 0.722639, acc.: 46.09%] [G loss: 0.698937]\n",
      "epoch:22 step:17293 [D loss: 0.690049, acc.: 51.56%] [G loss: 0.735130]\n",
      "epoch:22 step:17294 [D loss: 0.699609, acc.: 52.34%] [G loss: 0.781405]\n",
      "epoch:22 step:17295 [D loss: 0.651285, acc.: 66.41%] [G loss: 0.746565]\n",
      "epoch:22 step:17296 [D loss: 0.646858, acc.: 64.84%] [G loss: 0.883043]\n",
      "epoch:22 step:17297 [D loss: 0.663339, acc.: 61.72%] [G loss: 0.776179]\n",
      "epoch:22 step:17298 [D loss: 0.663686, acc.: 63.28%] [G loss: 0.683050]\n",
      "epoch:22 step:17299 [D loss: 0.702193, acc.: 52.34%] [G loss: 0.745455]\n",
      "epoch:22 step:17300 [D loss: 0.674266, acc.: 56.25%] [G loss: 0.841198]\n",
      "epoch:22 step:17301 [D loss: 0.685090, acc.: 52.34%] [G loss: 0.827114]\n",
      "epoch:22 step:17302 [D loss: 0.700089, acc.: 49.22%] [G loss: 0.799428]\n",
      "epoch:22 step:17303 [D loss: 0.641215, acc.: 65.62%] [G loss: 0.759177]\n",
      "epoch:22 step:17304 [D loss: 0.737779, acc.: 46.88%] [G loss: 0.693111]\n",
      "epoch:22 step:17305 [D loss: 0.719799, acc.: 49.22%] [G loss: 0.733293]\n",
      "epoch:22 step:17306 [D loss: 0.701013, acc.: 48.44%] [G loss: 0.716245]\n",
      "epoch:22 step:17307 [D loss: 0.736325, acc.: 41.41%] [G loss: 0.748716]\n",
      "epoch:22 step:17308 [D loss: 0.702414, acc.: 49.22%] [G loss: 0.706036]\n",
      "epoch:22 step:17309 [D loss: 0.673089, acc.: 52.34%] [G loss: 0.697925]\n",
      "epoch:22 step:17310 [D loss: 0.674205, acc.: 55.47%] [G loss: 0.717790]\n",
      "epoch:22 step:17311 [D loss: 0.657355, acc.: 60.16%] [G loss: 0.760889]\n",
      "epoch:22 step:17312 [D loss: 0.712171, acc.: 50.00%] [G loss: 0.755896]\n",
      "epoch:22 step:17313 [D loss: 0.687741, acc.: 53.12%] [G loss: 0.767041]\n",
      "epoch:22 step:17314 [D loss: 0.665285, acc.: 59.38%] [G loss: 0.769702]\n",
      "epoch:22 step:17315 [D loss: 0.673265, acc.: 55.47%] [G loss: 0.781809]\n",
      "epoch:22 step:17316 [D loss: 0.734571, acc.: 44.53%] [G loss: 0.757397]\n",
      "epoch:22 step:17317 [D loss: 0.747634, acc.: 45.31%] [G loss: 0.795755]\n",
      "epoch:22 step:17318 [D loss: 0.717629, acc.: 47.66%] [G loss: 0.721019]\n",
      "epoch:22 step:17319 [D loss: 0.720771, acc.: 45.31%] [G loss: 0.670614]\n",
      "epoch:22 step:17320 [D loss: 0.710467, acc.: 46.09%] [G loss: 0.692580]\n",
      "epoch:22 step:17321 [D loss: 0.665182, acc.: 60.94%] [G loss: 0.683139]\n",
      "epoch:22 step:17322 [D loss: 0.693539, acc.: 48.44%] [G loss: 0.795343]\n",
      "epoch:22 step:17323 [D loss: 0.662634, acc.: 62.50%] [G loss: 0.756589]\n",
      "epoch:22 step:17324 [D loss: 0.689344, acc.: 56.25%] [G loss: 0.761521]\n",
      "epoch:22 step:17325 [D loss: 0.715446, acc.: 43.75%] [G loss: 0.699255]\n",
      "epoch:22 step:17326 [D loss: 0.682309, acc.: 54.69%] [G loss: 0.710492]\n",
      "epoch:22 step:17327 [D loss: 0.691066, acc.: 52.34%] [G loss: 0.751440]\n",
      "epoch:22 step:17328 [D loss: 0.665436, acc.: 60.16%] [G loss: 0.739131]\n",
      "epoch:22 step:17329 [D loss: 0.672150, acc.: 60.94%] [G loss: 0.774619]\n",
      "epoch:22 step:17330 [D loss: 0.702227, acc.: 54.69%] [G loss: 0.722907]\n",
      "epoch:22 step:17331 [D loss: 0.692030, acc.: 56.25%] [G loss: 0.776951]\n",
      "epoch:22 step:17332 [D loss: 0.677719, acc.: 64.84%] [G loss: 0.734332]\n",
      "epoch:22 step:17333 [D loss: 0.662793, acc.: 62.50%] [G loss: 0.764836]\n",
      "epoch:22 step:17334 [D loss: 0.678652, acc.: 56.25%] [G loss: 0.767703]\n",
      "epoch:22 step:17335 [D loss: 0.701106, acc.: 50.00%] [G loss: 0.749316]\n",
      "epoch:22 step:17336 [D loss: 0.694101, acc.: 53.12%] [G loss: 0.684245]\n",
      "epoch:22 step:17337 [D loss: 0.734153, acc.: 40.62%] [G loss: 0.694810]\n",
      "epoch:22 step:17338 [D loss: 0.676002, acc.: 60.16%] [G loss: 0.721952]\n",
      "epoch:22 step:17339 [D loss: 0.699975, acc.: 56.25%] [G loss: 0.774459]\n",
      "epoch:22 step:17340 [D loss: 0.716939, acc.: 53.91%] [G loss: 0.754715]\n",
      "epoch:22 step:17341 [D loss: 0.706132, acc.: 50.78%] [G loss: 0.722734]\n",
      "epoch:22 step:17342 [D loss: 0.708056, acc.: 52.34%] [G loss: 0.784148]\n",
      "epoch:22 step:17343 [D loss: 0.700558, acc.: 53.91%] [G loss: 0.797486]\n",
      "epoch:22 step:17344 [D loss: 0.662654, acc.: 59.38%] [G loss: 0.795895]\n",
      "epoch:22 step:17345 [D loss: 0.722754, acc.: 43.75%] [G loss: 0.745034]\n",
      "epoch:22 step:17346 [D loss: 0.700546, acc.: 53.91%] [G loss: 0.777324]\n",
      "epoch:22 step:17347 [D loss: 0.673600, acc.: 55.47%] [G loss: 0.783675]\n",
      "epoch:22 step:17348 [D loss: 0.693487, acc.: 53.12%] [G loss: 0.783524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17349 [D loss: 0.701355, acc.: 53.91%] [G loss: 0.751827]\n",
      "epoch:22 step:17350 [D loss: 0.632213, acc.: 64.06%] [G loss: 0.756330]\n",
      "epoch:22 step:17351 [D loss: 0.719886, acc.: 44.53%] [G loss: 0.778407]\n",
      "epoch:22 step:17352 [D loss: 0.663605, acc.: 66.41%] [G loss: 0.847742]\n",
      "epoch:22 step:17353 [D loss: 0.677150, acc.: 56.25%] [G loss: 0.896528]\n",
      "epoch:22 step:17354 [D loss: 0.693877, acc.: 55.47%] [G loss: 0.814019]\n",
      "epoch:22 step:17355 [D loss: 0.694707, acc.: 51.56%] [G loss: 0.823131]\n",
      "epoch:22 step:17356 [D loss: 0.697245, acc.: 46.88%] [G loss: 0.790699]\n",
      "epoch:22 step:17357 [D loss: 0.695163, acc.: 55.47%] [G loss: 0.729662]\n",
      "epoch:22 step:17358 [D loss: 0.697206, acc.: 53.91%] [G loss: 0.817393]\n",
      "epoch:22 step:17359 [D loss: 0.673481, acc.: 62.50%] [G loss: 0.786495]\n",
      "epoch:22 step:17360 [D loss: 0.713800, acc.: 45.31%] [G loss: 0.797018]\n",
      "epoch:22 step:17361 [D loss: 0.649698, acc.: 59.38%] [G loss: 0.713589]\n",
      "epoch:22 step:17362 [D loss: 0.721534, acc.: 46.88%] [G loss: 0.682437]\n",
      "epoch:22 step:17363 [D loss: 0.689786, acc.: 54.69%] [G loss: 0.723354]\n",
      "epoch:22 step:17364 [D loss: 0.710976, acc.: 45.31%] [G loss: 0.678394]\n",
      "epoch:22 step:17365 [D loss: 0.659548, acc.: 61.72%] [G loss: 0.797984]\n",
      "epoch:22 step:17366 [D loss: 0.693052, acc.: 51.56%] [G loss: 0.714092]\n",
      "epoch:22 step:17367 [D loss: 0.718950, acc.: 41.41%] [G loss: 0.709583]\n",
      "epoch:22 step:17368 [D loss: 0.704228, acc.: 49.22%] [G loss: 0.733095]\n",
      "epoch:22 step:17369 [D loss: 0.709389, acc.: 47.66%] [G loss: 0.724713]\n",
      "epoch:22 step:17370 [D loss: 0.689053, acc.: 53.91%] [G loss: 0.790830]\n",
      "epoch:22 step:17371 [D loss: 0.654770, acc.: 67.97%] [G loss: 0.762125]\n",
      "epoch:22 step:17372 [D loss: 0.718500, acc.: 43.75%] [G loss: 0.787287]\n",
      "epoch:22 step:17373 [D loss: 0.696453, acc.: 53.12%] [G loss: 0.731807]\n",
      "epoch:22 step:17374 [D loss: 0.703643, acc.: 50.00%] [G loss: 0.783264]\n",
      "epoch:22 step:17375 [D loss: 0.717237, acc.: 46.09%] [G loss: 0.785559]\n",
      "epoch:22 step:17376 [D loss: 0.759556, acc.: 42.19%] [G loss: 0.701874]\n",
      "epoch:22 step:17377 [D loss: 0.739782, acc.: 40.62%] [G loss: 0.766006]\n",
      "epoch:22 step:17378 [D loss: 0.684156, acc.: 55.47%] [G loss: 0.795032]\n",
      "epoch:22 step:17379 [D loss: 0.721405, acc.: 43.75%] [G loss: 0.753349]\n",
      "epoch:22 step:17380 [D loss: 0.684258, acc.: 58.59%] [G loss: 0.841649]\n",
      "epoch:22 step:17381 [D loss: 0.716175, acc.: 50.78%] [G loss: 0.785520]\n",
      "epoch:22 step:17382 [D loss: 0.703533, acc.: 53.91%] [G loss: 0.770932]\n",
      "epoch:22 step:17383 [D loss: 0.682010, acc.: 59.38%] [G loss: 0.797548]\n",
      "epoch:22 step:17384 [D loss: 0.737109, acc.: 41.41%] [G loss: 0.799217]\n",
      "epoch:22 step:17385 [D loss: 0.669715, acc.: 61.72%] [G loss: 0.751919]\n",
      "epoch:22 step:17386 [D loss: 0.704177, acc.: 46.88%] [G loss: 0.811664]\n",
      "epoch:22 step:17387 [D loss: 0.700021, acc.: 53.12%] [G loss: 0.817580]\n",
      "epoch:22 step:17388 [D loss: 0.709339, acc.: 47.66%] [G loss: 0.813179]\n",
      "epoch:22 step:17389 [D loss: 0.608452, acc.: 74.22%] [G loss: 0.858345]\n",
      "epoch:22 step:17390 [D loss: 0.660994, acc.: 60.16%] [G loss: 0.786794]\n",
      "epoch:22 step:17391 [D loss: 0.714520, acc.: 49.22%] [G loss: 0.802882]\n",
      "epoch:22 step:17392 [D loss: 0.707241, acc.: 49.22%] [G loss: 0.724158]\n",
      "epoch:22 step:17393 [D loss: 0.676637, acc.: 58.59%] [G loss: 0.740749]\n",
      "epoch:22 step:17394 [D loss: 0.711603, acc.: 49.22%] [G loss: 0.783298]\n",
      "epoch:22 step:17395 [D loss: 0.735567, acc.: 38.28%] [G loss: 0.748838]\n",
      "epoch:22 step:17396 [D loss: 0.721772, acc.: 45.31%] [G loss: 0.686951]\n",
      "epoch:22 step:17397 [D loss: 0.716884, acc.: 47.66%] [G loss: 0.768542]\n",
      "epoch:22 step:17398 [D loss: 0.710122, acc.: 50.00%] [G loss: 0.703808]\n",
      "epoch:22 step:17399 [D loss: 0.687546, acc.: 57.81%] [G loss: 0.689034]\n",
      "epoch:22 step:17400 [D loss: 0.748420, acc.: 35.94%] [G loss: 0.710589]\n",
      "epoch:22 step:17401 [D loss: 0.721503, acc.: 42.19%] [G loss: 0.717308]\n",
      "epoch:22 step:17402 [D loss: 0.637342, acc.: 68.75%] [G loss: 0.813415]\n",
      "epoch:22 step:17403 [D loss: 0.698041, acc.: 53.91%] [G loss: 0.698955]\n",
      "epoch:22 step:17404 [D loss: 0.693723, acc.: 53.91%] [G loss: 0.740663]\n",
      "epoch:22 step:17405 [D loss: 0.724460, acc.: 41.41%] [G loss: 0.756158]\n",
      "epoch:22 step:17406 [D loss: 0.666178, acc.: 57.03%] [G loss: 0.758563]\n",
      "epoch:22 step:17407 [D loss: 0.687340, acc.: 54.69%] [G loss: 0.812872]\n",
      "epoch:22 step:17408 [D loss: 0.678695, acc.: 62.50%] [G loss: 0.767963]\n",
      "epoch:22 step:17409 [D loss: 0.653289, acc.: 64.06%] [G loss: 0.790308]\n",
      "epoch:22 step:17410 [D loss: 0.715324, acc.: 49.22%] [G loss: 0.824102]\n",
      "epoch:22 step:17411 [D loss: 0.696011, acc.: 50.00%] [G loss: 0.766058]\n",
      "epoch:22 step:17412 [D loss: 0.700709, acc.: 54.69%] [G loss: 0.746529]\n",
      "epoch:22 step:17413 [D loss: 0.655699, acc.: 65.62%] [G loss: 0.805790]\n",
      "epoch:22 step:17414 [D loss: 0.675841, acc.: 59.38%] [G loss: 0.755932]\n",
      "epoch:22 step:17415 [D loss: 0.666219, acc.: 59.38%] [G loss: 0.778160]\n",
      "epoch:22 step:17416 [D loss: 0.769974, acc.: 35.16%] [G loss: 0.726054]\n",
      "epoch:22 step:17417 [D loss: 0.705017, acc.: 46.88%] [G loss: 0.737811]\n",
      "epoch:22 step:17418 [D loss: 0.720114, acc.: 50.00%] [G loss: 0.678093]\n",
      "epoch:22 step:17419 [D loss: 0.759997, acc.: 42.19%] [G loss: 0.655038]\n",
      "epoch:22 step:17420 [D loss: 0.674849, acc.: 61.72%] [G loss: 0.688741]\n",
      "epoch:22 step:17421 [D loss: 0.671690, acc.: 55.47%] [G loss: 0.796302]\n",
      "epoch:22 step:17422 [D loss: 0.719773, acc.: 50.00%] [G loss: 0.748854]\n",
      "epoch:22 step:17423 [D loss: 0.684931, acc.: 52.34%] [G loss: 0.756176]\n",
      "epoch:22 step:17424 [D loss: 0.721948, acc.: 50.00%] [G loss: 0.738471]\n",
      "epoch:22 step:17425 [D loss: 0.685995, acc.: 53.12%] [G loss: 0.750708]\n",
      "epoch:22 step:17426 [D loss: 0.705637, acc.: 45.31%] [G loss: 0.715120]\n",
      "epoch:22 step:17427 [D loss: 0.709643, acc.: 50.00%] [G loss: 0.771548]\n",
      "epoch:22 step:17428 [D loss: 0.712191, acc.: 50.78%] [G loss: 0.711782]\n",
      "epoch:22 step:17429 [D loss: 0.713279, acc.: 48.44%] [G loss: 0.750226]\n",
      "epoch:22 step:17430 [D loss: 0.711430, acc.: 50.00%] [G loss: 0.746525]\n",
      "epoch:22 step:17431 [D loss: 0.681980, acc.: 59.38%] [G loss: 0.769417]\n",
      "epoch:22 step:17432 [D loss: 0.698765, acc.: 54.69%] [G loss: 0.683797]\n",
      "epoch:22 step:17433 [D loss: 0.670725, acc.: 59.38%] [G loss: 0.780001]\n",
      "epoch:22 step:17434 [D loss: 0.706954, acc.: 50.00%] [G loss: 0.731503]\n",
      "epoch:22 step:17435 [D loss: 0.705965, acc.: 48.44%] [G loss: 0.716789]\n",
      "epoch:22 step:17436 [D loss: 0.734724, acc.: 39.06%] [G loss: 0.700502]\n",
      "epoch:22 step:17437 [D loss: 0.728779, acc.: 49.22%] [G loss: 0.734329]\n",
      "epoch:22 step:17438 [D loss: 0.676020, acc.: 51.56%] [G loss: 0.706479]\n",
      "epoch:22 step:17439 [D loss: 0.676699, acc.: 56.25%] [G loss: 0.688631]\n",
      "epoch:22 step:17440 [D loss: 0.698509, acc.: 46.09%] [G loss: 0.692987]\n",
      "epoch:22 step:17441 [D loss: 0.748212, acc.: 38.28%] [G loss: 0.769508]\n",
      "epoch:22 step:17442 [D loss: 0.681454, acc.: 52.34%] [G loss: 0.822461]\n",
      "epoch:22 step:17443 [D loss: 0.678600, acc.: 53.12%] [G loss: 0.826324]\n",
      "epoch:22 step:17444 [D loss: 0.719553, acc.: 42.97%] [G loss: 0.856641]\n",
      "epoch:22 step:17445 [D loss: 0.666772, acc.: 62.50%] [G loss: 0.866511]\n",
      "epoch:22 step:17446 [D loss: 0.655499, acc.: 63.28%] [G loss: 0.872355]\n",
      "epoch:22 step:17447 [D loss: 0.737645, acc.: 44.53%] [G loss: 0.839681]\n",
      "epoch:22 step:17448 [D loss: 0.704723, acc.: 54.69%] [G loss: 0.775355]\n",
      "epoch:22 step:17449 [D loss: 0.687039, acc.: 57.81%] [G loss: 0.808872]\n",
      "epoch:22 step:17450 [D loss: 0.661612, acc.: 61.72%] [G loss: 0.812665]\n",
      "epoch:22 step:17451 [D loss: 0.643245, acc.: 69.53%] [G loss: 0.716280]\n",
      "epoch:22 step:17452 [D loss: 0.709979, acc.: 43.75%] [G loss: 0.752194]\n",
      "epoch:22 step:17453 [D loss: 0.710941, acc.: 52.34%] [G loss: 0.760927]\n",
      "epoch:22 step:17454 [D loss: 0.699472, acc.: 50.00%] [G loss: 0.748358]\n",
      "epoch:22 step:17455 [D loss: 0.702760, acc.: 47.66%] [G loss: 0.752295]\n",
      "epoch:22 step:17456 [D loss: 0.639582, acc.: 62.50%] [G loss: 0.768916]\n",
      "epoch:22 step:17457 [D loss: 0.728563, acc.: 39.06%] [G loss: 0.764557]\n",
      "epoch:22 step:17458 [D loss: 0.703199, acc.: 47.66%] [G loss: 0.807305]\n",
      "epoch:22 step:17459 [D loss: 0.743750, acc.: 36.72%] [G loss: 0.720354]\n",
      "epoch:22 step:17460 [D loss: 0.699597, acc.: 50.00%] [G loss: 0.708783]\n",
      "epoch:22 step:17461 [D loss: 0.712690, acc.: 47.66%] [G loss: 0.692972]\n",
      "epoch:22 step:17462 [D loss: 0.725510, acc.: 45.31%] [G loss: 0.799775]\n",
      "epoch:22 step:17463 [D loss: 0.708718, acc.: 50.00%] [G loss: 0.756908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17464 [D loss: 0.697375, acc.: 56.25%] [G loss: 0.756714]\n",
      "epoch:22 step:17465 [D loss: 0.691217, acc.: 52.34%] [G loss: 0.753599]\n",
      "epoch:22 step:17466 [D loss: 0.666702, acc.: 53.12%] [G loss: 0.810616]\n",
      "epoch:22 step:17467 [D loss: 0.700353, acc.: 51.56%] [G loss: 0.781044]\n",
      "epoch:22 step:17468 [D loss: 0.687529, acc.: 49.22%] [G loss: 0.793313]\n",
      "epoch:22 step:17469 [D loss: 0.679740, acc.: 51.56%] [G loss: 0.749243]\n",
      "epoch:22 step:17470 [D loss: 0.705321, acc.: 50.78%] [G loss: 0.738152]\n",
      "epoch:22 step:17471 [D loss: 0.694957, acc.: 55.47%] [G loss: 0.793872]\n",
      "epoch:22 step:17472 [D loss: 0.661276, acc.: 67.97%] [G loss: 0.765196]\n",
      "epoch:22 step:17473 [D loss: 0.733654, acc.: 46.09%] [G loss: 0.722271]\n",
      "epoch:22 step:17474 [D loss: 0.705109, acc.: 53.91%] [G loss: 0.807968]\n",
      "epoch:22 step:17475 [D loss: 0.705618, acc.: 46.09%] [G loss: 0.730038]\n",
      "epoch:22 step:17476 [D loss: 0.675628, acc.: 57.03%] [G loss: 0.741795]\n",
      "epoch:22 step:17477 [D loss: 0.688833, acc.: 56.25%] [G loss: 0.747953]\n",
      "epoch:22 step:17478 [D loss: 0.676733, acc.: 57.03%] [G loss: 0.776563]\n",
      "epoch:22 step:17479 [D loss: 0.706247, acc.: 51.56%] [G loss: 0.703445]\n",
      "epoch:22 step:17480 [D loss: 0.704992, acc.: 52.34%] [G loss: 0.747247]\n",
      "epoch:22 step:17481 [D loss: 0.682079, acc.: 60.16%] [G loss: 0.736645]\n",
      "epoch:22 step:17482 [D loss: 0.715667, acc.: 46.88%] [G loss: 0.764103]\n",
      "epoch:22 step:17483 [D loss: 0.694951, acc.: 53.91%] [G loss: 0.769615]\n",
      "epoch:22 step:17484 [D loss: 0.690692, acc.: 53.91%] [G loss: 0.816020]\n",
      "epoch:22 step:17485 [D loss: 0.720797, acc.: 35.16%] [G loss: 0.705830]\n",
      "epoch:22 step:17486 [D loss: 0.684624, acc.: 58.59%] [G loss: 0.775020]\n",
      "epoch:22 step:17487 [D loss: 0.682937, acc.: 57.81%] [G loss: 0.772838]\n",
      "epoch:22 step:17488 [D loss: 0.727055, acc.: 37.50%] [G loss: 0.759872]\n",
      "epoch:22 step:17489 [D loss: 0.655285, acc.: 61.72%] [G loss: 0.757099]\n",
      "epoch:22 step:17490 [D loss: 0.659510, acc.: 58.59%] [G loss: 0.745980]\n",
      "epoch:22 step:17491 [D loss: 0.690470, acc.: 59.38%] [G loss: 0.768156]\n",
      "epoch:22 step:17492 [D loss: 0.668379, acc.: 60.16%] [G loss: 0.820202]\n",
      "epoch:22 step:17493 [D loss: 0.711566, acc.: 54.69%] [G loss: 0.782202]\n",
      "epoch:22 step:17494 [D loss: 0.744578, acc.: 39.84%] [G loss: 0.738449]\n",
      "epoch:22 step:17495 [D loss: 0.719037, acc.: 49.22%] [G loss: 0.736152]\n",
      "epoch:22 step:17496 [D loss: 0.716317, acc.: 43.75%] [G loss: 0.792928]\n",
      "epoch:22 step:17497 [D loss: 0.747236, acc.: 35.16%] [G loss: 0.758498]\n",
      "epoch:22 step:17498 [D loss: 0.666638, acc.: 60.94%] [G loss: 0.796747]\n",
      "epoch:22 step:17499 [D loss: 0.664833, acc.: 57.81%] [G loss: 0.817669]\n",
      "epoch:22 step:17500 [D loss: 0.644209, acc.: 69.53%] [G loss: 0.790650]\n",
      "epoch:22 step:17501 [D loss: 0.688323, acc.: 53.91%] [G loss: 0.749081]\n",
      "epoch:22 step:17502 [D loss: 0.680907, acc.: 59.38%] [G loss: 0.773194]\n",
      "epoch:22 step:17503 [D loss: 0.678102, acc.: 57.03%] [G loss: 0.774328]\n",
      "epoch:22 step:17504 [D loss: 0.680502, acc.: 57.03%] [G loss: 0.715266]\n",
      "epoch:22 step:17505 [D loss: 0.739111, acc.: 39.84%] [G loss: 0.699996]\n",
      "epoch:22 step:17506 [D loss: 0.652310, acc.: 66.41%] [G loss: 0.813422]\n",
      "epoch:22 step:17507 [D loss: 0.647433, acc.: 64.84%] [G loss: 0.758806]\n",
      "epoch:22 step:17508 [D loss: 0.713581, acc.: 45.31%] [G loss: 0.823803]\n",
      "epoch:22 step:17509 [D loss: 0.654330, acc.: 64.84%] [G loss: 0.848147]\n",
      "epoch:22 step:17510 [D loss: 0.633150, acc.: 63.28%] [G loss: 0.817161]\n",
      "epoch:22 step:17511 [D loss: 0.713307, acc.: 42.97%] [G loss: 0.748615]\n",
      "epoch:22 step:17512 [D loss: 0.699797, acc.: 46.88%] [G loss: 0.756106]\n",
      "epoch:22 step:17513 [D loss: 0.711057, acc.: 48.44%] [G loss: 0.804748]\n",
      "epoch:22 step:17514 [D loss: 0.634942, acc.: 67.19%] [G loss: 0.788525]\n",
      "epoch:22 step:17515 [D loss: 0.683493, acc.: 53.12%] [G loss: 0.794284]\n",
      "epoch:22 step:17516 [D loss: 0.702760, acc.: 50.78%] [G loss: 0.804601]\n",
      "epoch:22 step:17517 [D loss: 0.694986, acc.: 53.91%] [G loss: 0.769656]\n",
      "epoch:22 step:17518 [D loss: 0.654028, acc.: 64.84%] [G loss: 0.818426]\n",
      "epoch:22 step:17519 [D loss: 0.730203, acc.: 45.31%] [G loss: 0.764818]\n",
      "epoch:22 step:17520 [D loss: 0.715487, acc.: 47.66%] [G loss: 0.752997]\n",
      "epoch:22 step:17521 [D loss: 0.674266, acc.: 62.50%] [G loss: 0.716950]\n",
      "epoch:22 step:17522 [D loss: 0.705604, acc.: 46.88%] [G loss: 0.691075]\n",
      "epoch:22 step:17523 [D loss: 0.674668, acc.: 60.16%] [G loss: 0.720677]\n",
      "epoch:22 step:17524 [D loss: 0.705473, acc.: 52.34%] [G loss: 0.744076]\n",
      "epoch:22 step:17525 [D loss: 0.685470, acc.: 52.34%] [G loss: 0.757711]\n",
      "epoch:22 step:17526 [D loss: 0.706568, acc.: 46.09%] [G loss: 0.742052]\n",
      "epoch:22 step:17527 [D loss: 0.737438, acc.: 43.75%] [G loss: 0.684478]\n",
      "epoch:22 step:17528 [D loss: 0.740424, acc.: 42.97%] [G loss: 0.752629]\n",
      "epoch:22 step:17529 [D loss: 0.690112, acc.: 53.91%] [G loss: 0.769552]\n",
      "epoch:22 step:17530 [D loss: 0.694802, acc.: 48.44%] [G loss: 0.770087]\n",
      "epoch:22 step:17531 [D loss: 0.732167, acc.: 42.19%] [G loss: 0.834049]\n",
      "epoch:22 step:17532 [D loss: 0.821372, acc.: 29.69%] [G loss: 0.747202]\n",
      "epoch:22 step:17533 [D loss: 0.676524, acc.: 55.47%] [G loss: 0.706559]\n",
      "epoch:22 step:17534 [D loss: 0.668169, acc.: 59.38%] [G loss: 0.746733]\n",
      "epoch:22 step:17535 [D loss: 0.675838, acc.: 62.50%] [G loss: 0.754435]\n",
      "epoch:22 step:17536 [D loss: 0.664143, acc.: 62.50%] [G loss: 0.791266]\n",
      "epoch:22 step:17537 [D loss: 0.708874, acc.: 42.19%] [G loss: 0.768347]\n",
      "epoch:22 step:17538 [D loss: 0.701311, acc.: 53.12%] [G loss: 0.754212]\n",
      "epoch:22 step:17539 [D loss: 0.684731, acc.: 57.03%] [G loss: 0.770166]\n",
      "epoch:22 step:17540 [D loss: 0.703317, acc.: 51.56%] [G loss: 0.696484]\n",
      "epoch:22 step:17541 [D loss: 0.732555, acc.: 43.75%] [G loss: 0.747005]\n",
      "epoch:22 step:17542 [D loss: 0.692739, acc.: 50.00%] [G loss: 0.712928]\n",
      "epoch:22 step:17543 [D loss: 0.679997, acc.: 57.03%] [G loss: 0.768589]\n",
      "epoch:22 step:17544 [D loss: 0.669998, acc.: 58.59%] [G loss: 0.737470]\n",
      "epoch:22 step:17545 [D loss: 0.705414, acc.: 47.66%] [G loss: 0.720157]\n",
      "epoch:22 step:17546 [D loss: 0.722864, acc.: 42.97%] [G loss: 0.673208]\n",
      "epoch:22 step:17547 [D loss: 0.690280, acc.: 54.69%] [G loss: 0.759693]\n",
      "epoch:22 step:17548 [D loss: 0.674880, acc.: 56.25%] [G loss: 0.743819]\n",
      "epoch:22 step:17549 [D loss: 0.666230, acc.: 67.97%] [G loss: 0.769228]\n",
      "epoch:22 step:17550 [D loss: 0.714666, acc.: 45.31%] [G loss: 0.749788]\n",
      "epoch:22 step:17551 [D loss: 0.638668, acc.: 72.66%] [G loss: 0.752827]\n",
      "epoch:22 step:17552 [D loss: 0.648096, acc.: 70.31%] [G loss: 0.764031]\n",
      "epoch:22 step:17553 [D loss: 0.694500, acc.: 57.81%] [G loss: 0.692097]\n",
      "epoch:22 step:17554 [D loss: 0.705331, acc.: 48.44%] [G loss: 0.705996]\n",
      "epoch:22 step:17555 [D loss: 0.675605, acc.: 57.81%] [G loss: 0.762190]\n",
      "epoch:22 step:17556 [D loss: 0.718756, acc.: 46.09%] [G loss: 0.756054]\n",
      "epoch:22 step:17557 [D loss: 0.746039, acc.: 41.41%] [G loss: 0.760014]\n",
      "epoch:22 step:17558 [D loss: 0.702145, acc.: 52.34%] [G loss: 0.732535]\n",
      "epoch:22 step:17559 [D loss: 0.630928, acc.: 73.44%] [G loss: 0.763661]\n",
      "epoch:22 step:17560 [D loss: 0.699840, acc.: 47.66%] [G loss: 0.658905]\n",
      "epoch:22 step:17561 [D loss: 0.706761, acc.: 46.88%] [G loss: 0.711469]\n",
      "epoch:22 step:17562 [D loss: 0.694071, acc.: 48.44%] [G loss: 0.728839]\n",
      "epoch:22 step:17563 [D loss: 0.680551, acc.: 54.69%] [G loss: 0.745760]\n",
      "epoch:22 step:17564 [D loss: 0.699877, acc.: 50.00%] [G loss: 0.702418]\n",
      "epoch:22 step:17565 [D loss: 0.688128, acc.: 57.03%] [G loss: 0.756983]\n",
      "epoch:22 step:17566 [D loss: 0.745349, acc.: 44.53%] [G loss: 0.712383]\n",
      "epoch:22 step:17567 [D loss: 0.678923, acc.: 58.59%] [G loss: 0.788434]\n",
      "epoch:22 step:17568 [D loss: 0.657878, acc.: 60.16%] [G loss: 0.702461]\n",
      "epoch:22 step:17569 [D loss: 0.690803, acc.: 55.47%] [G loss: 0.754011]\n",
      "epoch:22 step:17570 [D loss: 0.724610, acc.: 44.53%] [G loss: 0.728988]\n",
      "epoch:22 step:17571 [D loss: 0.748221, acc.: 41.41%] [G loss: 0.806619]\n",
      "epoch:22 step:17572 [D loss: 0.644962, acc.: 63.28%] [G loss: 0.800608]\n",
      "epoch:22 step:17573 [D loss: 0.722669, acc.: 46.88%] [G loss: 0.740161]\n",
      "epoch:22 step:17574 [D loss: 0.716736, acc.: 46.88%] [G loss: 0.717250]\n",
      "epoch:22 step:17575 [D loss: 0.700928, acc.: 56.25%] [G loss: 0.745270]\n",
      "epoch:22 step:17576 [D loss: 0.715125, acc.: 50.00%] [G loss: 0.750798]\n",
      "epoch:22 step:17577 [D loss: 0.711065, acc.: 41.41%] [G loss: 0.760008]\n",
      "epoch:22 step:17578 [D loss: 0.652107, acc.: 67.97%] [G loss: 0.794765]\n",
      "epoch:22 step:17579 [D loss: 0.674097, acc.: 57.03%] [G loss: 0.769058]\n",
      "epoch:22 step:17580 [D loss: 0.758507, acc.: 39.06%] [G loss: 0.727145]\n",
      "epoch:22 step:17581 [D loss: 0.683111, acc.: 57.03%] [G loss: 0.791311]\n",
      "epoch:22 step:17582 [D loss: 0.693053, acc.: 54.69%] [G loss: 0.779468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17583 [D loss: 0.648220, acc.: 69.53%] [G loss: 0.753773]\n",
      "epoch:22 step:17584 [D loss: 0.658370, acc.: 62.50%] [G loss: 0.798916]\n",
      "epoch:22 step:17585 [D loss: 0.642561, acc.: 64.84%] [G loss: 0.776109]\n",
      "epoch:22 step:17586 [D loss: 0.683824, acc.: 56.25%] [G loss: 0.777055]\n",
      "epoch:22 step:17587 [D loss: 0.746280, acc.: 45.31%] [G loss: 0.746399]\n",
      "epoch:22 step:17588 [D loss: 0.696125, acc.: 53.12%] [G loss: 0.708860]\n",
      "epoch:22 step:17589 [D loss: 0.709948, acc.: 50.00%] [G loss: 0.672780]\n",
      "epoch:22 step:17590 [D loss: 0.700440, acc.: 52.34%] [G loss: 0.755418]\n",
      "epoch:22 step:17591 [D loss: 0.660602, acc.: 64.06%] [G loss: 0.762390]\n",
      "epoch:22 step:17592 [D loss: 0.682271, acc.: 57.03%] [G loss: 0.794567]\n",
      "epoch:22 step:17593 [D loss: 0.748812, acc.: 38.28%] [G loss: 0.702420]\n",
      "epoch:22 step:17594 [D loss: 0.684550, acc.: 55.47%] [G loss: 0.708156]\n",
      "epoch:22 step:17595 [D loss: 0.684965, acc.: 57.81%] [G loss: 0.771337]\n",
      "epoch:22 step:17596 [D loss: 0.690777, acc.: 53.12%] [G loss: 0.807028]\n",
      "epoch:22 step:17597 [D loss: 0.741501, acc.: 39.06%] [G loss: 0.651511]\n",
      "epoch:22 step:17598 [D loss: 0.646945, acc.: 63.28%] [G loss: 0.755533]\n",
      "epoch:22 step:17599 [D loss: 0.683221, acc.: 62.50%] [G loss: 0.749746]\n",
      "epoch:22 step:17600 [D loss: 0.703636, acc.: 46.88%] [G loss: 0.780655]\n",
      "epoch:22 step:17601 [D loss: 0.690545, acc.: 55.47%] [G loss: 0.776399]\n",
      "epoch:22 step:17602 [D loss: 0.696612, acc.: 50.78%] [G loss: 0.760169]\n",
      "epoch:22 step:17603 [D loss: 0.737373, acc.: 44.53%] [G loss: 0.759197]\n",
      "epoch:22 step:17604 [D loss: 0.694078, acc.: 52.34%] [G loss: 0.785790]\n",
      "epoch:22 step:17605 [D loss: 0.743840, acc.: 39.06%] [G loss: 0.750375]\n",
      "epoch:22 step:17606 [D loss: 0.723144, acc.: 46.09%] [G loss: 0.730508]\n",
      "epoch:22 step:17607 [D loss: 0.709261, acc.: 48.44%] [G loss: 0.664858]\n",
      "epoch:22 step:17608 [D loss: 0.725084, acc.: 45.31%] [G loss: 0.667209]\n",
      "epoch:22 step:17609 [D loss: 0.697464, acc.: 47.66%] [G loss: 0.722826]\n",
      "epoch:22 step:17610 [D loss: 0.761257, acc.: 35.16%] [G loss: 0.706117]\n",
      "epoch:22 step:17611 [D loss: 0.675385, acc.: 58.59%] [G loss: 0.766769]\n",
      "epoch:22 step:17612 [D loss: 0.757515, acc.: 44.53%] [G loss: 0.726870]\n",
      "epoch:22 step:17613 [D loss: 0.727730, acc.: 42.97%] [G loss: 0.730382]\n",
      "epoch:22 step:17614 [D loss: 0.674853, acc.: 53.91%] [G loss: 0.769821]\n",
      "epoch:22 step:17615 [D loss: 0.709954, acc.: 46.09%] [G loss: 0.789474]\n",
      "epoch:22 step:17616 [D loss: 0.698047, acc.: 55.47%] [G loss: 0.767371]\n",
      "epoch:22 step:17617 [D loss: 0.717558, acc.: 43.75%] [G loss: 0.731311]\n",
      "epoch:22 step:17618 [D loss: 0.679348, acc.: 57.03%] [G loss: 0.831180]\n",
      "epoch:22 step:17619 [D loss: 0.724301, acc.: 41.41%] [G loss: 0.773079]\n",
      "epoch:22 step:17620 [D loss: 0.703387, acc.: 51.56%] [G loss: 0.807741]\n",
      "epoch:22 step:17621 [D loss: 0.665257, acc.: 60.94%] [G loss: 0.823204]\n",
      "epoch:22 step:17622 [D loss: 0.670129, acc.: 57.81%] [G loss: 0.849437]\n",
      "epoch:22 step:17623 [D loss: 0.663296, acc.: 61.72%] [G loss: 0.832363]\n",
      "epoch:22 step:17624 [D loss: 0.677811, acc.: 51.56%] [G loss: 0.790600]\n",
      "epoch:22 step:17625 [D loss: 0.647545, acc.: 64.84%] [G loss: 0.787628]\n",
      "epoch:22 step:17626 [D loss: 0.682514, acc.: 59.38%] [G loss: 0.728247]\n",
      "epoch:22 step:17627 [D loss: 0.716887, acc.: 44.53%] [G loss: 0.782920]\n",
      "epoch:22 step:17628 [D loss: 0.718909, acc.: 39.06%] [G loss: 0.746318]\n",
      "epoch:22 step:17629 [D loss: 0.670391, acc.: 57.03%] [G loss: 0.740059]\n",
      "epoch:22 step:17630 [D loss: 0.689426, acc.: 60.16%] [G loss: 0.711151]\n",
      "epoch:22 step:17631 [D loss: 0.713607, acc.: 44.53%] [G loss: 0.775591]\n",
      "epoch:22 step:17632 [D loss: 0.722971, acc.: 49.22%] [G loss: 0.770528]\n",
      "epoch:22 step:17633 [D loss: 0.674239, acc.: 57.81%] [G loss: 0.767886]\n",
      "epoch:22 step:17634 [D loss: 0.711571, acc.: 53.91%] [G loss: 0.824765]\n",
      "epoch:22 step:17635 [D loss: 0.706268, acc.: 46.88%] [G loss: 0.812442]\n",
      "epoch:22 step:17636 [D loss: 0.693610, acc.: 52.34%] [G loss: 0.774872]\n",
      "epoch:22 step:17637 [D loss: 0.713238, acc.: 54.69%] [G loss: 0.772838]\n",
      "epoch:22 step:17638 [D loss: 0.732923, acc.: 45.31%] [G loss: 0.798735]\n",
      "epoch:22 step:17639 [D loss: 0.712630, acc.: 46.09%] [G loss: 0.781900]\n",
      "epoch:22 step:17640 [D loss: 0.726806, acc.: 43.75%] [G loss: 0.716057]\n",
      "epoch:22 step:17641 [D loss: 0.730435, acc.: 46.09%] [G loss: 0.802184]\n",
      "epoch:22 step:17642 [D loss: 0.689335, acc.: 51.56%] [G loss: 0.767556]\n",
      "epoch:22 step:17643 [D loss: 0.679806, acc.: 53.12%] [G loss: 0.819131]\n",
      "epoch:22 step:17644 [D loss: 0.681729, acc.: 53.12%] [G loss: 0.775600]\n",
      "epoch:22 step:17645 [D loss: 0.673913, acc.: 56.25%] [G loss: 0.788839]\n",
      "epoch:22 step:17646 [D loss: 0.692570, acc.: 52.34%] [G loss: 0.805228]\n",
      "epoch:22 step:17647 [D loss: 0.686948, acc.: 52.34%] [G loss: 0.796555]\n",
      "epoch:22 step:17648 [D loss: 0.640991, acc.: 67.19%] [G loss: 0.861750]\n",
      "epoch:22 step:17649 [D loss: 0.697483, acc.: 50.78%] [G loss: 0.741901]\n",
      "epoch:22 step:17650 [D loss: 0.681712, acc.: 50.78%] [G loss: 0.825150]\n",
      "epoch:22 step:17651 [D loss: 0.685232, acc.: 56.25%] [G loss: 0.807652]\n",
      "epoch:22 step:17652 [D loss: 0.697052, acc.: 52.34%] [G loss: 0.786435]\n",
      "epoch:22 step:17653 [D loss: 0.658627, acc.: 56.25%] [G loss: 0.862060]\n",
      "epoch:22 step:17654 [D loss: 0.709439, acc.: 53.12%] [G loss: 0.779401]\n",
      "epoch:22 step:17655 [D loss: 0.750380, acc.: 47.66%] [G loss: 0.761965]\n",
      "epoch:22 step:17656 [D loss: 0.674442, acc.: 55.47%] [G loss: 0.691999]\n",
      "epoch:22 step:17657 [D loss: 0.699256, acc.: 46.88%] [G loss: 0.684328]\n",
      "epoch:22 step:17658 [D loss: 0.672648, acc.: 58.59%] [G loss: 0.744401]\n",
      "epoch:22 step:17659 [D loss: 0.673659, acc.: 53.91%] [G loss: 0.767848]\n",
      "epoch:22 step:17660 [D loss: 0.685212, acc.: 57.03%] [G loss: 0.764065]\n",
      "epoch:22 step:17661 [D loss: 0.689162, acc.: 56.25%] [G loss: 0.779123]\n",
      "epoch:22 step:17662 [D loss: 0.665132, acc.: 66.41%] [G loss: 0.788187]\n",
      "epoch:22 step:17663 [D loss: 0.682653, acc.: 55.47%] [G loss: 0.727724]\n",
      "epoch:22 step:17664 [D loss: 0.714124, acc.: 50.00%] [G loss: 0.787472]\n",
      "epoch:22 step:17665 [D loss: 0.736396, acc.: 41.41%] [G loss: 0.758034]\n",
      "epoch:22 step:17666 [D loss: 0.688997, acc.: 52.34%] [G loss: 0.703384]\n",
      "epoch:22 step:17667 [D loss: 0.684924, acc.: 57.81%] [G loss: 0.735177]\n",
      "epoch:22 step:17668 [D loss: 0.652506, acc.: 64.84%] [G loss: 0.697613]\n",
      "epoch:22 step:17669 [D loss: 0.700142, acc.: 47.66%] [G loss: 0.707384]\n",
      "epoch:22 step:17670 [D loss: 0.671022, acc.: 56.25%] [G loss: 0.751433]\n",
      "epoch:22 step:17671 [D loss: 0.734196, acc.: 46.88%] [G loss: 0.734604]\n",
      "epoch:22 step:17672 [D loss: 0.657568, acc.: 57.81%] [G loss: 0.723976]\n",
      "epoch:22 step:17673 [D loss: 0.694337, acc.: 50.00%] [G loss: 0.696153]\n",
      "epoch:22 step:17674 [D loss: 0.727967, acc.: 48.44%] [G loss: 0.774347]\n",
      "epoch:22 step:17675 [D loss: 0.655043, acc.: 64.84%] [G loss: 0.787550]\n",
      "epoch:22 step:17676 [D loss: 0.624738, acc.: 75.00%] [G loss: 0.769503]\n",
      "epoch:22 step:17677 [D loss: 0.684425, acc.: 61.72%] [G loss: 0.807699]\n",
      "epoch:22 step:17678 [D loss: 0.695078, acc.: 53.12%] [G loss: 0.793489]\n",
      "epoch:22 step:17679 [D loss: 0.652692, acc.: 64.84%] [G loss: 0.769385]\n",
      "epoch:22 step:17680 [D loss: 0.712354, acc.: 45.31%] [G loss: 0.764912]\n",
      "epoch:22 step:17681 [D loss: 0.678499, acc.: 58.59%] [G loss: 0.708990]\n",
      "epoch:22 step:17682 [D loss: 0.666856, acc.: 53.12%] [G loss: 0.724686]\n",
      "epoch:22 step:17683 [D loss: 0.692510, acc.: 53.12%] [G loss: 0.774717]\n",
      "epoch:22 step:17684 [D loss: 0.708847, acc.: 56.25%] [G loss: 0.754035]\n",
      "epoch:22 step:17685 [D loss: 0.705927, acc.: 46.88%] [G loss: 0.802352]\n",
      "epoch:22 step:17686 [D loss: 0.687042, acc.: 53.91%] [G loss: 0.726681]\n",
      "epoch:22 step:17687 [D loss: 0.680357, acc.: 62.50%] [G loss: 0.701709]\n",
      "epoch:22 step:17688 [D loss: 0.652270, acc.: 66.41%] [G loss: 0.745735]\n",
      "epoch:22 step:17689 [D loss: 0.693144, acc.: 59.38%] [G loss: 0.775821]\n",
      "epoch:22 step:17690 [D loss: 0.712285, acc.: 40.62%] [G loss: 0.741180]\n",
      "epoch:22 step:17691 [D loss: 0.658224, acc.: 64.84%] [G loss: 0.696478]\n",
      "epoch:22 step:17692 [D loss: 0.722076, acc.: 42.19%] [G loss: 0.683666]\n",
      "epoch:22 step:17693 [D loss: 0.719076, acc.: 46.88%] [G loss: 0.699132]\n",
      "epoch:22 step:17694 [D loss: 0.752831, acc.: 41.41%] [G loss: 0.685110]\n",
      "epoch:22 step:17695 [D loss: 0.689952, acc.: 57.81%] [G loss: 0.694482]\n",
      "epoch:22 step:17696 [D loss: 0.736808, acc.: 39.06%] [G loss: 0.709328]\n",
      "epoch:22 step:17697 [D loss: 0.673944, acc.: 61.72%] [G loss: 0.697526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17698 [D loss: 0.703660, acc.: 53.91%] [G loss: 0.768179]\n",
      "epoch:22 step:17699 [D loss: 0.690472, acc.: 56.25%] [G loss: 0.736548]\n",
      "epoch:22 step:17700 [D loss: 0.681041, acc.: 59.38%] [G loss: 0.745425]\n",
      "epoch:22 step:17701 [D loss: 0.690111, acc.: 57.81%] [G loss: 0.764421]\n",
      "epoch:22 step:17702 [D loss: 0.684996, acc.: 54.69%] [G loss: 0.729697]\n",
      "epoch:22 step:17703 [D loss: 0.658456, acc.: 63.28%] [G loss: 0.772205]\n",
      "epoch:22 step:17704 [D loss: 0.673068, acc.: 60.94%] [G loss: 0.816823]\n",
      "epoch:22 step:17705 [D loss: 0.654032, acc.: 63.28%] [G loss: 0.797744]\n",
      "epoch:22 step:17706 [D loss: 0.714472, acc.: 52.34%] [G loss: 0.799863]\n",
      "epoch:22 step:17707 [D loss: 0.686728, acc.: 58.59%] [G loss: 0.773811]\n",
      "epoch:22 step:17708 [D loss: 0.793507, acc.: 36.72%] [G loss: 0.791062]\n",
      "epoch:22 step:17709 [D loss: 0.716136, acc.: 47.66%] [G loss: 0.762285]\n",
      "epoch:22 step:17710 [D loss: 0.700312, acc.: 50.00%] [G loss: 0.739568]\n",
      "epoch:22 step:17711 [D loss: 0.679223, acc.: 59.38%] [G loss: 0.737309]\n",
      "epoch:22 step:17712 [D loss: 0.705325, acc.: 49.22%] [G loss: 0.774090]\n",
      "epoch:22 step:17713 [D loss: 0.681133, acc.: 57.81%] [G loss: 0.824584]\n",
      "epoch:22 step:17714 [D loss: 0.722429, acc.: 45.31%] [G loss: 0.768277]\n",
      "epoch:22 step:17715 [D loss: 0.717682, acc.: 45.31%] [G loss: 0.777932]\n",
      "epoch:22 step:17716 [D loss: 0.689206, acc.: 54.69%] [G loss: 0.729159]\n",
      "epoch:22 step:17717 [D loss: 0.669676, acc.: 51.56%] [G loss: 0.758215]\n",
      "epoch:22 step:17718 [D loss: 0.666873, acc.: 64.06%] [G loss: 0.763051]\n",
      "epoch:22 step:17719 [D loss: 0.716002, acc.: 45.31%] [G loss: 0.790949]\n",
      "epoch:22 step:17720 [D loss: 0.715722, acc.: 52.34%] [G loss: 0.783178]\n",
      "epoch:22 step:17721 [D loss: 0.704867, acc.: 46.09%] [G loss: 0.797937]\n",
      "epoch:22 step:17722 [D loss: 0.712849, acc.: 47.66%] [G loss: 0.732204]\n",
      "epoch:22 step:17723 [D loss: 0.680296, acc.: 55.47%] [G loss: 0.779416]\n",
      "epoch:22 step:17724 [D loss: 0.722121, acc.: 49.22%] [G loss: 0.761670]\n",
      "epoch:22 step:17725 [D loss: 0.697216, acc.: 53.12%] [G loss: 0.859398]\n",
      "epoch:22 step:17726 [D loss: 0.678038, acc.: 53.12%] [G loss: 0.845213]\n",
      "epoch:22 step:17727 [D loss: 0.610592, acc.: 73.44%] [G loss: 0.838313]\n",
      "epoch:22 step:17728 [D loss: 0.756018, acc.: 39.84%] [G loss: 0.767546]\n",
      "epoch:22 step:17729 [D loss: 0.659378, acc.: 58.59%] [G loss: 0.730962]\n",
      "epoch:22 step:17730 [D loss: 0.666438, acc.: 61.72%] [G loss: 0.803820]\n",
      "epoch:22 step:17731 [D loss: 0.668706, acc.: 60.94%] [G loss: 0.747505]\n",
      "epoch:22 step:17732 [D loss: 0.733182, acc.: 41.41%] [G loss: 0.770180]\n",
      "epoch:22 step:17733 [D loss: 0.720772, acc.: 46.09%] [G loss: 0.745343]\n",
      "epoch:22 step:17734 [D loss: 0.739436, acc.: 39.06%] [G loss: 0.740315]\n",
      "epoch:22 step:17735 [D loss: 0.710300, acc.: 50.00%] [G loss: 0.767405]\n",
      "epoch:22 step:17736 [D loss: 0.669046, acc.: 55.47%] [G loss: 0.791372]\n",
      "epoch:22 step:17737 [D loss: 0.684384, acc.: 54.69%] [G loss: 0.805918]\n",
      "epoch:22 step:17738 [D loss: 0.694893, acc.: 57.81%] [G loss: 0.758677]\n",
      "epoch:22 step:17739 [D loss: 0.726419, acc.: 46.09%] [G loss: 0.727904]\n",
      "epoch:22 step:17740 [D loss: 0.690840, acc.: 57.03%] [G loss: 0.692988]\n",
      "epoch:22 step:17741 [D loss: 0.674994, acc.: 54.69%] [G loss: 0.766849]\n",
      "epoch:22 step:17742 [D loss: 0.725779, acc.: 41.41%] [G loss: 0.723115]\n",
      "epoch:22 step:17743 [D loss: 0.700143, acc.: 53.12%] [G loss: 0.747033]\n",
      "epoch:22 step:17744 [D loss: 0.678202, acc.: 54.69%] [G loss: 0.802555]\n",
      "epoch:22 step:17745 [D loss: 0.702346, acc.: 54.69%] [G loss: 0.730233]\n",
      "epoch:22 step:17746 [D loss: 0.711121, acc.: 47.66%] [G loss: 0.743882]\n",
      "epoch:22 step:17747 [D loss: 0.700017, acc.: 42.97%] [G loss: 0.776568]\n",
      "epoch:22 step:17748 [D loss: 0.711583, acc.: 45.31%] [G loss: 0.731671]\n",
      "epoch:22 step:17749 [D loss: 0.680158, acc.: 52.34%] [G loss: 0.762826]\n",
      "epoch:22 step:17750 [D loss: 0.628108, acc.: 67.97%] [G loss: 0.817905]\n",
      "epoch:22 step:17751 [D loss: 0.673603, acc.: 59.38%] [G loss: 0.779546]\n",
      "epoch:22 step:17752 [D loss: 0.667258, acc.: 60.16%] [G loss: 0.796290]\n",
      "epoch:22 step:17753 [D loss: 0.716472, acc.: 54.69%] [G loss: 0.716979]\n",
      "epoch:22 step:17754 [D loss: 0.696981, acc.: 57.03%] [G loss: 0.766928]\n",
      "epoch:22 step:17755 [D loss: 0.687519, acc.: 50.00%] [G loss: 0.752987]\n",
      "epoch:22 step:17756 [D loss: 0.725722, acc.: 40.62%] [G loss: 0.723668]\n",
      "epoch:22 step:17757 [D loss: 0.710125, acc.: 45.31%] [G loss: 0.688643]\n",
      "epoch:22 step:17758 [D loss: 0.651065, acc.: 67.97%] [G loss: 0.747705]\n",
      "epoch:22 step:17759 [D loss: 0.690400, acc.: 47.66%] [G loss: 0.740566]\n",
      "epoch:22 step:17760 [D loss: 0.690489, acc.: 53.91%] [G loss: 0.710911]\n",
      "epoch:22 step:17761 [D loss: 0.711031, acc.: 49.22%] [G loss: 0.766004]\n",
      "epoch:22 step:17762 [D loss: 0.719418, acc.: 41.41%] [G loss: 0.725560]\n",
      "epoch:22 step:17763 [D loss: 0.669047, acc.: 56.25%] [G loss: 0.737769]\n",
      "epoch:22 step:17764 [D loss: 0.685231, acc.: 53.12%] [G loss: 0.769082]\n",
      "epoch:22 step:17765 [D loss: 0.653045, acc.: 60.94%] [G loss: 0.725915]\n",
      "epoch:22 step:17766 [D loss: 0.677338, acc.: 55.47%] [G loss: 0.736910]\n",
      "epoch:22 step:17767 [D loss: 0.658456, acc.: 65.62%] [G loss: 0.762996]\n",
      "epoch:22 step:17768 [D loss: 0.695170, acc.: 50.78%] [G loss: 0.731598]\n",
      "epoch:22 step:17769 [D loss: 0.662358, acc.: 61.72%] [G loss: 0.776284]\n",
      "epoch:22 step:17770 [D loss: 0.739652, acc.: 42.19%] [G loss: 0.709526]\n",
      "epoch:22 step:17771 [D loss: 0.678516, acc.: 53.91%] [G loss: 0.732793]\n",
      "epoch:22 step:17772 [D loss: 0.682484, acc.: 61.72%] [G loss: 0.759657]\n",
      "epoch:22 step:17773 [D loss: 0.676758, acc.: 52.34%] [G loss: 0.844894]\n",
      "epoch:22 step:17774 [D loss: 0.643137, acc.: 72.66%] [G loss: 0.830957]\n",
      "epoch:22 step:17775 [D loss: 0.722584, acc.: 44.53%] [G loss: 0.812835]\n",
      "epoch:22 step:17776 [D loss: 0.705163, acc.: 50.00%] [G loss: 0.750140]\n",
      "epoch:22 step:17777 [D loss: 0.651580, acc.: 67.19%] [G loss: 0.785716]\n",
      "epoch:22 step:17778 [D loss: 0.693986, acc.: 46.88%] [G loss: 0.765173]\n",
      "epoch:22 step:17779 [D loss: 0.687208, acc.: 53.12%] [G loss: 0.770133]\n",
      "epoch:22 step:17780 [D loss: 0.626357, acc.: 68.75%] [G loss: 0.811403]\n",
      "epoch:22 step:17781 [D loss: 0.676429, acc.: 54.69%] [G loss: 0.828791]\n",
      "epoch:22 step:17782 [D loss: 0.707197, acc.: 54.69%] [G loss: 0.749739]\n",
      "epoch:22 step:17783 [D loss: 0.709994, acc.: 45.31%] [G loss: 0.788817]\n",
      "epoch:22 step:17784 [D loss: 0.673193, acc.: 57.03%] [G loss: 0.779590]\n",
      "epoch:22 step:17785 [D loss: 0.668503, acc.: 56.25%] [G loss: 0.756855]\n",
      "epoch:22 step:17786 [D loss: 0.731740, acc.: 45.31%] [G loss: 0.750287]\n",
      "epoch:22 step:17787 [D loss: 0.681487, acc.: 57.81%] [G loss: 0.693079]\n",
      "epoch:22 step:17788 [D loss: 0.699174, acc.: 54.69%] [G loss: 0.694203]\n",
      "epoch:22 step:17789 [D loss: 0.692552, acc.: 50.78%] [G loss: 0.673119]\n",
      "epoch:22 step:17790 [D loss: 0.707114, acc.: 50.00%] [G loss: 0.778163]\n",
      "epoch:22 step:17791 [D loss: 0.719434, acc.: 47.66%] [G loss: 0.710444]\n",
      "epoch:22 step:17792 [D loss: 0.656955, acc.: 61.72%] [G loss: 0.717369]\n",
      "epoch:22 step:17793 [D loss: 0.694547, acc.: 57.81%] [G loss: 0.742670]\n",
      "epoch:22 step:17794 [D loss: 0.704479, acc.: 53.12%] [G loss: 0.706453]\n",
      "epoch:22 step:17795 [D loss: 0.763820, acc.: 35.94%] [G loss: 0.723432]\n",
      "epoch:22 step:17796 [D loss: 0.720044, acc.: 47.66%] [G loss: 0.689874]\n",
      "epoch:22 step:17797 [D loss: 0.649733, acc.: 64.84%] [G loss: 0.741184]\n",
      "epoch:22 step:17798 [D loss: 0.706344, acc.: 51.56%] [G loss: 0.697824]\n",
      "epoch:22 step:17799 [D loss: 0.682371, acc.: 58.59%] [G loss: 0.709781]\n",
      "epoch:22 step:17800 [D loss: 0.692711, acc.: 46.88%] [G loss: 0.720524]\n",
      "epoch:22 step:17801 [D loss: 0.737807, acc.: 41.41%] [G loss: 0.697294]\n",
      "epoch:22 step:17802 [D loss: 0.650060, acc.: 66.41%] [G loss: 0.786429]\n",
      "epoch:22 step:17803 [D loss: 0.696731, acc.: 50.00%] [G loss: 0.831462]\n",
      "epoch:22 step:17804 [D loss: 0.697877, acc.: 53.91%] [G loss: 0.786715]\n",
      "epoch:22 step:17805 [D loss: 0.727151, acc.: 42.19%] [G loss: 0.684299]\n",
      "epoch:22 step:17806 [D loss: 0.703161, acc.: 51.56%] [G loss: 0.744403]\n",
      "epoch:22 step:17807 [D loss: 0.716901, acc.: 46.09%] [G loss: 0.761706]\n",
      "epoch:22 step:17808 [D loss: 0.682495, acc.: 53.91%] [G loss: 0.792176]\n",
      "epoch:22 step:17809 [D loss: 0.688459, acc.: 52.34%] [G loss: 0.731901]\n",
      "epoch:22 step:17810 [D loss: 0.637432, acc.: 72.66%] [G loss: 0.769440]\n",
      "epoch:22 step:17811 [D loss: 0.685987, acc.: 55.47%] [G loss: 0.775335]\n",
      "epoch:22 step:17812 [D loss: 0.656189, acc.: 67.97%] [G loss: 0.790837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17813 [D loss: 0.713420, acc.: 47.66%] [G loss: 0.719219]\n",
      "epoch:22 step:17814 [D loss: 0.697482, acc.: 47.66%] [G loss: 0.757816]\n",
      "epoch:22 step:17815 [D loss: 0.700837, acc.: 54.69%] [G loss: 0.725668]\n",
      "epoch:22 step:17816 [D loss: 0.741551, acc.: 42.97%] [G loss: 0.755696]\n",
      "epoch:22 step:17817 [D loss: 0.739328, acc.: 46.88%] [G loss: 0.755158]\n",
      "epoch:22 step:17818 [D loss: 0.718026, acc.: 46.09%] [G loss: 0.739513]\n",
      "epoch:22 step:17819 [D loss: 0.720174, acc.: 41.41%] [G loss: 0.674111]\n",
      "epoch:22 step:17820 [D loss: 0.718234, acc.: 45.31%] [G loss: 0.774113]\n",
      "epoch:22 step:17821 [D loss: 0.693277, acc.: 53.12%] [G loss: 0.772967]\n",
      "epoch:22 step:17822 [D loss: 0.687748, acc.: 54.69%] [G loss: 0.796729]\n",
      "epoch:22 step:17823 [D loss: 0.685483, acc.: 49.22%] [G loss: 0.728227]\n",
      "epoch:22 step:17824 [D loss: 0.728331, acc.: 39.84%] [G loss: 0.742669]\n",
      "epoch:22 step:17825 [D loss: 0.707191, acc.: 44.53%] [G loss: 0.696407]\n",
      "epoch:22 step:17826 [D loss: 0.731560, acc.: 46.88%] [G loss: 0.706096]\n",
      "epoch:22 step:17827 [D loss: 0.680353, acc.: 55.47%] [G loss: 0.794350]\n",
      "epoch:22 step:17828 [D loss: 0.692116, acc.: 53.12%] [G loss: 0.792682]\n",
      "epoch:22 step:17829 [D loss: 0.711010, acc.: 53.91%] [G loss: 0.755035]\n",
      "epoch:22 step:17830 [D loss: 0.690295, acc.: 50.00%] [G loss: 0.742102]\n",
      "epoch:22 step:17831 [D loss: 0.683711, acc.: 52.34%] [G loss: 0.723047]\n",
      "epoch:22 step:17832 [D loss: 0.732654, acc.: 40.62%] [G loss: 0.715538]\n",
      "epoch:22 step:17833 [D loss: 0.688450, acc.: 57.81%] [G loss: 0.702961]\n",
      "epoch:22 step:17834 [D loss: 0.709104, acc.: 50.78%] [G loss: 0.731156]\n",
      "epoch:22 step:17835 [D loss: 0.725809, acc.: 45.31%] [G loss: 0.729682]\n",
      "epoch:22 step:17836 [D loss: 0.662699, acc.: 60.16%] [G loss: 0.738265]\n",
      "epoch:22 step:17837 [D loss: 0.753875, acc.: 35.16%] [G loss: 0.710883]\n",
      "epoch:22 step:17838 [D loss: 0.711629, acc.: 50.00%] [G loss: 0.757522]\n",
      "epoch:22 step:17839 [D loss: 0.739235, acc.: 43.75%] [G loss: 0.750530]\n",
      "epoch:22 step:17840 [D loss: 0.685251, acc.: 53.12%] [G loss: 0.786625]\n",
      "epoch:22 step:17841 [D loss: 0.688964, acc.: 54.69%] [G loss: 0.860323]\n",
      "epoch:22 step:17842 [D loss: 0.703695, acc.: 46.88%] [G loss: 0.839153]\n",
      "epoch:22 step:17843 [D loss: 0.691475, acc.: 54.69%] [G loss: 0.784972]\n",
      "epoch:22 step:17844 [D loss: 0.682970, acc.: 53.12%] [G loss: 0.747469]\n",
      "epoch:22 step:17845 [D loss: 0.686878, acc.: 51.56%] [G loss: 0.776198]\n",
      "epoch:22 step:17846 [D loss: 0.664548, acc.: 64.06%] [G loss: 0.808480]\n",
      "epoch:22 step:17847 [D loss: 0.680731, acc.: 53.91%] [G loss: 0.774653]\n",
      "epoch:22 step:17848 [D loss: 0.677200, acc.: 53.12%] [G loss: 0.790162]\n",
      "epoch:22 step:17849 [D loss: 0.720437, acc.: 46.88%] [G loss: 0.719708]\n",
      "epoch:22 step:17850 [D loss: 0.674109, acc.: 60.16%] [G loss: 0.803733]\n",
      "epoch:22 step:17851 [D loss: 0.723722, acc.: 47.66%] [G loss: 0.738459]\n",
      "epoch:22 step:17852 [D loss: 0.680690, acc.: 52.34%] [G loss: 0.837110]\n",
      "epoch:22 step:17853 [D loss: 0.721263, acc.: 50.00%] [G loss: 0.792207]\n",
      "epoch:22 step:17854 [D loss: 0.712188, acc.: 50.78%] [G loss: 0.801309]\n",
      "epoch:22 step:17855 [D loss: 0.639394, acc.: 68.75%] [G loss: 0.904028]\n",
      "epoch:22 step:17856 [D loss: 0.674858, acc.: 60.16%] [G loss: 0.809746]\n",
      "epoch:22 step:17857 [D loss: 0.699118, acc.: 51.56%] [G loss: 0.771530]\n",
      "epoch:22 step:17858 [D loss: 0.711384, acc.: 46.88%] [G loss: 0.723458]\n",
      "epoch:22 step:17859 [D loss: 0.669243, acc.: 56.25%] [G loss: 0.704275]\n",
      "epoch:22 step:17860 [D loss: 0.711960, acc.: 49.22%] [G loss: 0.750744]\n",
      "epoch:22 step:17861 [D loss: 0.658669, acc.: 64.84%] [G loss: 0.725240]\n",
      "epoch:22 step:17862 [D loss: 0.666609, acc.: 57.03%] [G loss: 0.779192]\n",
      "epoch:22 step:17863 [D loss: 0.679596, acc.: 55.47%] [G loss: 0.751858]\n",
      "epoch:22 step:17864 [D loss: 0.695493, acc.: 53.12%] [G loss: 0.750132]\n",
      "epoch:22 step:17865 [D loss: 0.677715, acc.: 54.69%] [G loss: 0.776750]\n",
      "epoch:22 step:17866 [D loss: 0.689571, acc.: 56.25%] [G loss: 0.749135]\n",
      "epoch:22 step:17867 [D loss: 0.699219, acc.: 53.12%] [G loss: 0.740388]\n",
      "epoch:22 step:17868 [D loss: 0.730753, acc.: 40.62%] [G loss: 0.693334]\n",
      "epoch:22 step:17869 [D loss: 0.693838, acc.: 50.78%] [G loss: 0.727099]\n",
      "epoch:22 step:17870 [D loss: 0.684004, acc.: 50.00%] [G loss: 0.697434]\n",
      "epoch:22 step:17871 [D loss: 0.703261, acc.: 46.09%] [G loss: 0.697894]\n",
      "epoch:22 step:17872 [D loss: 0.651101, acc.: 66.41%] [G loss: 0.748692]\n",
      "epoch:22 step:17873 [D loss: 0.656294, acc.: 62.50%] [G loss: 0.768403]\n",
      "epoch:22 step:17874 [D loss: 0.760276, acc.: 33.59%] [G loss: 0.694457]\n",
      "epoch:22 step:17875 [D loss: 0.696926, acc.: 55.47%] [G loss: 0.736661]\n",
      "epoch:22 step:17876 [D loss: 0.687793, acc.: 49.22%] [G loss: 0.731035]\n",
      "epoch:22 step:17877 [D loss: 0.676985, acc.: 54.69%] [G loss: 0.716656]\n",
      "epoch:22 step:17878 [D loss: 0.694059, acc.: 55.47%] [G loss: 0.729054]\n",
      "epoch:22 step:17879 [D loss: 0.661601, acc.: 59.38%] [G loss: 0.729351]\n",
      "epoch:22 step:17880 [D loss: 0.666951, acc.: 58.59%] [G loss: 0.747681]\n",
      "epoch:22 step:17881 [D loss: 0.666960, acc.: 67.19%] [G loss: 0.722966]\n",
      "epoch:22 step:17882 [D loss: 0.691498, acc.: 47.66%] [G loss: 0.837041]\n",
      "epoch:22 step:17883 [D loss: 0.678057, acc.: 57.03%] [G loss: 0.751241]\n",
      "epoch:22 step:17884 [D loss: 0.675950, acc.: 57.03%] [G loss: 0.770813]\n",
      "epoch:22 step:17885 [D loss: 0.697694, acc.: 50.00%] [G loss: 0.746780]\n",
      "epoch:22 step:17886 [D loss: 0.697143, acc.: 50.78%] [G loss: 0.709664]\n",
      "epoch:22 step:17887 [D loss: 0.699324, acc.: 49.22%] [G loss: 0.736841]\n",
      "epoch:22 step:17888 [D loss: 0.736961, acc.: 38.28%] [G loss: 0.711530]\n",
      "epoch:22 step:17889 [D loss: 0.720060, acc.: 46.09%] [G loss: 0.769988]\n",
      "epoch:22 step:17890 [D loss: 0.715310, acc.: 50.00%] [G loss: 0.761781]\n",
      "epoch:22 step:17891 [D loss: 0.692245, acc.: 53.12%] [G loss: 0.687068]\n",
      "epoch:22 step:17892 [D loss: 0.666666, acc.: 57.81%] [G loss: 0.785693]\n",
      "epoch:22 step:17893 [D loss: 0.665177, acc.: 64.06%] [G loss: 0.748166]\n",
      "epoch:22 step:17894 [D loss: 0.685802, acc.: 55.47%] [G loss: 0.753749]\n",
      "epoch:22 step:17895 [D loss: 0.689748, acc.: 57.81%] [G loss: 0.756863]\n",
      "epoch:22 step:17896 [D loss: 0.702604, acc.: 49.22%] [G loss: 0.738686]\n",
      "epoch:22 step:17897 [D loss: 0.679911, acc.: 56.25%] [G loss: 0.729042]\n",
      "epoch:22 step:17898 [D loss: 0.636158, acc.: 64.06%] [G loss: 0.810049]\n",
      "epoch:22 step:17899 [D loss: 0.671709, acc.: 57.81%] [G loss: 0.762742]\n",
      "epoch:22 step:17900 [D loss: 0.682847, acc.: 60.94%] [G loss: 0.776927]\n",
      "epoch:22 step:17901 [D loss: 0.681927, acc.: 53.12%] [G loss: 0.816066]\n",
      "epoch:22 step:17902 [D loss: 0.721728, acc.: 48.44%] [G loss: 0.756263]\n",
      "epoch:22 step:17903 [D loss: 0.707921, acc.: 50.00%] [G loss: 0.745335]\n",
      "epoch:22 step:17904 [D loss: 0.704623, acc.: 44.53%] [G loss: 0.698568]\n",
      "epoch:22 step:17905 [D loss: 0.764985, acc.: 37.50%] [G loss: 0.665732]\n",
      "epoch:22 step:17906 [D loss: 0.705554, acc.: 50.00%] [G loss: 0.665011]\n",
      "epoch:22 step:17907 [D loss: 0.699745, acc.: 56.25%] [G loss: 0.671988]\n",
      "epoch:22 step:17908 [D loss: 0.670532, acc.: 53.12%] [G loss: 0.764120]\n",
      "epoch:22 step:17909 [D loss: 0.685011, acc.: 55.47%] [G loss: 0.780936]\n",
      "epoch:22 step:17910 [D loss: 0.725651, acc.: 41.41%] [G loss: 0.762190]\n",
      "epoch:22 step:17911 [D loss: 0.672340, acc.: 58.59%] [G loss: 0.809358]\n",
      "epoch:22 step:17912 [D loss: 0.725453, acc.: 43.75%] [G loss: 0.817740]\n",
      "epoch:22 step:17913 [D loss: 0.677746, acc.: 64.06%] [G loss: 0.792257]\n",
      "epoch:22 step:17914 [D loss: 0.653137, acc.: 66.41%] [G loss: 0.754499]\n",
      "epoch:22 step:17915 [D loss: 0.694959, acc.: 51.56%] [G loss: 0.716024]\n",
      "epoch:22 step:17916 [D loss: 0.661039, acc.: 60.16%] [G loss: 0.743237]\n",
      "epoch:22 step:17917 [D loss: 0.729182, acc.: 42.19%] [G loss: 0.801355]\n",
      "epoch:22 step:17918 [D loss: 0.668789, acc.: 60.16%] [G loss: 0.737893]\n",
      "epoch:22 step:17919 [D loss: 0.673788, acc.: 59.38%] [G loss: 0.794035]\n",
      "epoch:22 step:17920 [D loss: 0.667851, acc.: 59.38%] [G loss: 0.737787]\n",
      "epoch:22 step:17921 [D loss: 0.725751, acc.: 41.41%] [G loss: 0.706045]\n",
      "epoch:22 step:17922 [D loss: 0.657774, acc.: 57.03%] [G loss: 0.747473]\n",
      "epoch:22 step:17923 [D loss: 0.663103, acc.: 62.50%] [G loss: 0.807352]\n",
      "epoch:22 step:17924 [D loss: 0.716391, acc.: 46.09%] [G loss: 0.758901]\n",
      "epoch:22 step:17925 [D loss: 0.667215, acc.: 58.59%] [G loss: 0.745812]\n",
      "epoch:22 step:17926 [D loss: 0.668122, acc.: 64.84%] [G loss: 0.786594]\n",
      "epoch:22 step:17927 [D loss: 0.695032, acc.: 56.25%] [G loss: 0.788399]\n",
      "epoch:22 step:17928 [D loss: 0.685069, acc.: 53.12%] [G loss: 0.745547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17929 [D loss: 0.693249, acc.: 51.56%] [G loss: 0.699465]\n",
      "epoch:22 step:17930 [D loss: 0.692424, acc.: 52.34%] [G loss: 0.750867]\n",
      "epoch:22 step:17931 [D loss: 0.707873, acc.: 46.88%] [G loss: 0.730061]\n",
      "epoch:22 step:17932 [D loss: 0.659104, acc.: 63.28%] [G loss: 0.761168]\n",
      "epoch:22 step:17933 [D loss: 0.674743, acc.: 57.81%] [G loss: 0.714175]\n",
      "epoch:22 step:17934 [D loss: 0.640511, acc.: 64.84%] [G loss: 0.734746]\n",
      "epoch:22 step:17935 [D loss: 0.727783, acc.: 48.44%] [G loss: 0.690583]\n",
      "epoch:22 step:17936 [D loss: 0.676811, acc.: 56.25%] [G loss: 0.795981]\n",
      "epoch:22 step:17937 [D loss: 0.724755, acc.: 48.44%] [G loss: 0.756426]\n",
      "epoch:22 step:17938 [D loss: 0.721539, acc.: 47.66%] [G loss: 0.740967]\n",
      "epoch:22 step:17939 [D loss: 0.690280, acc.: 60.94%] [G loss: 0.778090]\n",
      "epoch:22 step:17940 [D loss: 0.712381, acc.: 47.66%] [G loss: 0.742831]\n",
      "epoch:22 step:17941 [D loss: 0.687995, acc.: 50.78%] [G loss: 0.741256]\n",
      "epoch:22 step:17942 [D loss: 0.700992, acc.: 54.69%] [G loss: 0.768543]\n",
      "epoch:22 step:17943 [D loss: 0.666167, acc.: 60.16%] [G loss: 0.764288]\n",
      "epoch:22 step:17944 [D loss: 0.694990, acc.: 50.78%] [G loss: 0.786140]\n",
      "epoch:22 step:17945 [D loss: 0.714501, acc.: 43.75%] [G loss: 0.715703]\n",
      "epoch:22 step:17946 [D loss: 0.718120, acc.: 42.19%] [G loss: 0.715725]\n",
      "epoch:22 step:17947 [D loss: 0.654181, acc.: 63.28%] [G loss: 0.784920]\n",
      "epoch:22 step:17948 [D loss: 0.707488, acc.: 52.34%] [G loss: 0.744466]\n",
      "epoch:22 step:17949 [D loss: 0.667764, acc.: 58.59%] [G loss: 0.767996]\n",
      "epoch:22 step:17950 [D loss: 0.698371, acc.: 45.31%] [G loss: 0.733027]\n",
      "epoch:22 step:17951 [D loss: 0.623516, acc.: 69.53%] [G loss: 0.827674]\n",
      "epoch:22 step:17952 [D loss: 0.708112, acc.: 47.66%] [G loss: 0.803590]\n",
      "epoch:22 step:17953 [D loss: 0.695297, acc.: 53.12%] [G loss: 0.811429]\n",
      "epoch:22 step:17954 [D loss: 0.703329, acc.: 50.00%] [G loss: 0.793080]\n",
      "epoch:22 step:17955 [D loss: 0.710840, acc.: 48.44%] [G loss: 0.736369]\n",
      "epoch:22 step:17956 [D loss: 0.655845, acc.: 63.28%] [G loss: 0.786438]\n",
      "epoch:22 step:17957 [D loss: 0.678720, acc.: 57.03%] [G loss: 0.775654]\n",
      "epoch:22 step:17958 [D loss: 0.638547, acc.: 70.31%] [G loss: 0.824822]\n",
      "epoch:22 step:17959 [D loss: 0.708001, acc.: 50.00%] [G loss: 0.733428]\n",
      "epoch:22 step:17960 [D loss: 0.688702, acc.: 53.12%] [G loss: 0.779135]\n",
      "epoch:22 step:17961 [D loss: 0.717784, acc.: 40.62%] [G loss: 0.728904]\n",
      "epoch:22 step:17962 [D loss: 0.732757, acc.: 46.09%] [G loss: 0.711852]\n",
      "epoch:22 step:17963 [D loss: 0.671417, acc.: 55.47%] [G loss: 0.762936]\n",
      "epoch:23 step:17964 [D loss: 0.661434, acc.: 67.19%] [G loss: 0.698268]\n",
      "epoch:23 step:17965 [D loss: 0.725648, acc.: 50.00%] [G loss: 0.739235]\n",
      "epoch:23 step:17966 [D loss: 0.692804, acc.: 55.47%] [G loss: 0.856427]\n",
      "epoch:23 step:17967 [D loss: 0.717993, acc.: 45.31%] [G loss: 0.673472]\n",
      "epoch:23 step:17968 [D loss: 0.721564, acc.: 47.66%] [G loss: 0.722831]\n",
      "epoch:23 step:17969 [D loss: 0.687978, acc.: 56.25%] [G loss: 0.721331]\n",
      "epoch:23 step:17970 [D loss: 0.698430, acc.: 50.78%] [G loss: 0.739784]\n",
      "epoch:23 step:17971 [D loss: 0.703010, acc.: 48.44%] [G loss: 0.769512]\n",
      "epoch:23 step:17972 [D loss: 0.689029, acc.: 53.12%] [G loss: 0.844361]\n",
      "epoch:23 step:17973 [D loss: 0.695613, acc.: 55.47%] [G loss: 0.838087]\n",
      "epoch:23 step:17974 [D loss: 0.670727, acc.: 58.59%] [G loss: 0.751242]\n",
      "epoch:23 step:17975 [D loss: 0.704835, acc.: 48.44%] [G loss: 0.744915]\n",
      "epoch:23 step:17976 [D loss: 0.688998, acc.: 53.12%] [G loss: 0.739371]\n",
      "epoch:23 step:17977 [D loss: 0.695652, acc.: 50.00%] [G loss: 0.782032]\n",
      "epoch:23 step:17978 [D loss: 0.700348, acc.: 52.34%] [G loss: 0.772114]\n",
      "epoch:23 step:17979 [D loss: 0.694999, acc.: 48.44%] [G loss: 0.827452]\n",
      "epoch:23 step:17980 [D loss: 0.726794, acc.: 38.28%] [G loss: 0.788923]\n",
      "epoch:23 step:17981 [D loss: 0.687569, acc.: 56.25%] [G loss: 0.786827]\n",
      "epoch:23 step:17982 [D loss: 0.665983, acc.: 57.81%] [G loss: 0.788969]\n",
      "epoch:23 step:17983 [D loss: 0.677356, acc.: 58.59%] [G loss: 0.772025]\n",
      "epoch:23 step:17984 [D loss: 0.681856, acc.: 52.34%] [G loss: 0.857657]\n",
      "epoch:23 step:17985 [D loss: 0.601391, acc.: 72.66%] [G loss: 0.831430]\n",
      "epoch:23 step:17986 [D loss: 0.703750, acc.: 46.88%] [G loss: 0.755895]\n",
      "epoch:23 step:17987 [D loss: 0.665551, acc.: 57.81%] [G loss: 0.742057]\n",
      "epoch:23 step:17988 [D loss: 0.717071, acc.: 46.88%] [G loss: 0.769098]\n",
      "epoch:23 step:17989 [D loss: 0.755199, acc.: 37.50%] [G loss: 0.759564]\n",
      "epoch:23 step:17990 [D loss: 0.669878, acc.: 57.81%] [G loss: 0.758319]\n",
      "epoch:23 step:17991 [D loss: 0.713160, acc.: 52.34%] [G loss: 0.732153]\n",
      "epoch:23 step:17992 [D loss: 0.689312, acc.: 53.91%] [G loss: 0.762152]\n",
      "epoch:23 step:17993 [D loss: 0.683589, acc.: 55.47%] [G loss: 0.763999]\n",
      "epoch:23 step:17994 [D loss: 0.703918, acc.: 45.31%] [G loss: 0.830990]\n",
      "epoch:23 step:17995 [D loss: 0.717496, acc.: 46.09%] [G loss: 0.751990]\n",
      "epoch:23 step:17996 [D loss: 0.725908, acc.: 46.88%] [G loss: 0.762427]\n",
      "epoch:23 step:17997 [D loss: 0.647980, acc.: 66.41%] [G loss: 0.799090]\n",
      "epoch:23 step:17998 [D loss: 0.690810, acc.: 50.78%] [G loss: 0.765334]\n",
      "epoch:23 step:17999 [D loss: 0.720721, acc.: 42.97%] [G loss: 0.734339]\n",
      "epoch:23 step:18000 [D loss: 0.693303, acc.: 60.16%] [G loss: 0.799870]\n",
      "epoch:23 step:18001 [D loss: 0.688933, acc.: 57.03%] [G loss: 0.679056]\n",
      "epoch:23 step:18002 [D loss: 0.705143, acc.: 52.34%] [G loss: 0.684389]\n",
      "epoch:23 step:18003 [D loss: 0.702453, acc.: 50.00%] [G loss: 0.774157]\n",
      "epoch:23 step:18004 [D loss: 0.675567, acc.: 57.81%] [G loss: 0.777210]\n",
      "epoch:23 step:18005 [D loss: 0.705920, acc.: 48.44%] [G loss: 0.676035]\n",
      "epoch:23 step:18006 [D loss: 0.706541, acc.: 48.44%] [G loss: 0.731054]\n",
      "epoch:23 step:18007 [D loss: 0.692334, acc.: 53.91%] [G loss: 0.695333]\n",
      "epoch:23 step:18008 [D loss: 0.694092, acc.: 55.47%] [G loss: 0.783684]\n",
      "epoch:23 step:18009 [D loss: 0.688025, acc.: 51.56%] [G loss: 0.769425]\n",
      "epoch:23 step:18010 [D loss: 0.712815, acc.: 47.66%] [G loss: 0.825761]\n",
      "epoch:23 step:18011 [D loss: 0.684756, acc.: 55.47%] [G loss: 0.721393]\n",
      "epoch:23 step:18012 [D loss: 0.675459, acc.: 64.84%] [G loss: 0.795534]\n",
      "epoch:23 step:18013 [D loss: 0.752855, acc.: 36.72%] [G loss: 0.735411]\n",
      "epoch:23 step:18014 [D loss: 0.645753, acc.: 71.09%] [G loss: 0.773721]\n",
      "epoch:23 step:18015 [D loss: 0.692740, acc.: 57.03%] [G loss: 0.784269]\n",
      "epoch:23 step:18016 [D loss: 0.668561, acc.: 59.38%] [G loss: 0.742412]\n",
      "epoch:23 step:18017 [D loss: 0.691592, acc.: 53.91%] [G loss: 0.759319]\n",
      "epoch:23 step:18018 [D loss: 0.685615, acc.: 46.09%] [G loss: 0.735880]\n",
      "epoch:23 step:18019 [D loss: 0.717810, acc.: 50.00%] [G loss: 0.732616]\n",
      "epoch:23 step:18020 [D loss: 0.629350, acc.: 71.88%] [G loss: 0.783361]\n",
      "epoch:23 step:18021 [D loss: 0.653003, acc.: 58.59%] [G loss: 0.799446]\n",
      "epoch:23 step:18022 [D loss: 0.721972, acc.: 42.97%] [G loss: 0.794208]\n",
      "epoch:23 step:18023 [D loss: 0.666080, acc.: 59.38%] [G loss: 0.801755]\n",
      "epoch:23 step:18024 [D loss: 0.664554, acc.: 64.06%] [G loss: 0.866481]\n",
      "epoch:23 step:18025 [D loss: 0.645717, acc.: 66.41%] [G loss: 0.823609]\n",
      "epoch:23 step:18026 [D loss: 0.688472, acc.: 57.03%] [G loss: 0.767821]\n",
      "epoch:23 step:18027 [D loss: 0.704453, acc.: 50.00%] [G loss: 0.769328]\n",
      "epoch:23 step:18028 [D loss: 0.687572, acc.: 50.00%] [G loss: 0.835976]\n",
      "epoch:23 step:18029 [D loss: 0.745254, acc.: 44.53%] [G loss: 0.771626]\n",
      "epoch:23 step:18030 [D loss: 0.710155, acc.: 46.88%] [G loss: 0.705124]\n",
      "epoch:23 step:18031 [D loss: 0.696171, acc.: 52.34%] [G loss: 0.801624]\n",
      "epoch:23 step:18032 [D loss: 0.710206, acc.: 44.53%] [G loss: 0.781954]\n",
      "epoch:23 step:18033 [D loss: 0.773570, acc.: 28.91%] [G loss: 0.687424]\n",
      "epoch:23 step:18034 [D loss: 0.712376, acc.: 50.00%] [G loss: 0.747919]\n",
      "epoch:23 step:18035 [D loss: 0.686733, acc.: 57.81%] [G loss: 0.697879]\n",
      "epoch:23 step:18036 [D loss: 0.708743, acc.: 54.69%] [G loss: 0.746095]\n",
      "epoch:23 step:18037 [D loss: 0.647214, acc.: 66.41%] [G loss: 0.746356]\n",
      "epoch:23 step:18038 [D loss: 0.655808, acc.: 64.84%] [G loss: 0.774394]\n",
      "epoch:23 step:18039 [D loss: 0.665693, acc.: 56.25%] [G loss: 0.737543]\n",
      "epoch:23 step:18040 [D loss: 0.661434, acc.: 65.62%] [G loss: 0.699930]\n",
      "epoch:23 step:18041 [D loss: 0.688597, acc.: 50.00%] [G loss: 0.724804]\n",
      "epoch:23 step:18042 [D loss: 0.657954, acc.: 71.09%] [G loss: 0.735280]\n",
      "epoch:23 step:18043 [D loss: 0.682506, acc.: 58.59%] [G loss: 0.739957]\n",
      "epoch:23 step:18044 [D loss: 0.682137, acc.: 58.59%] [G loss: 0.780641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18045 [D loss: 0.689825, acc.: 52.34%] [G loss: 0.694843]\n",
      "epoch:23 step:18046 [D loss: 0.743602, acc.: 40.62%] [G loss: 0.739715]\n",
      "epoch:23 step:18047 [D loss: 0.725052, acc.: 41.41%] [G loss: 0.707925]\n",
      "epoch:23 step:18048 [D loss: 0.681007, acc.: 58.59%] [G loss: 0.766459]\n",
      "epoch:23 step:18049 [D loss: 0.666056, acc.: 59.38%] [G loss: 0.768189]\n",
      "epoch:23 step:18050 [D loss: 0.704264, acc.: 48.44%] [G loss: 0.687906]\n",
      "epoch:23 step:18051 [D loss: 0.694583, acc.: 54.69%] [G loss: 0.763439]\n",
      "epoch:23 step:18052 [D loss: 0.677495, acc.: 59.38%] [G loss: 0.730194]\n",
      "epoch:23 step:18053 [D loss: 0.695057, acc.: 50.00%] [G loss: 0.810577]\n",
      "epoch:23 step:18054 [D loss: 0.722785, acc.: 46.09%] [G loss: 0.787135]\n",
      "epoch:23 step:18055 [D loss: 0.757556, acc.: 39.06%] [G loss: 0.726071]\n",
      "epoch:23 step:18056 [D loss: 0.689735, acc.: 54.69%] [G loss: 0.733986]\n",
      "epoch:23 step:18057 [D loss: 0.687675, acc.: 52.34%] [G loss: 0.753637]\n",
      "epoch:23 step:18058 [D loss: 0.704143, acc.: 52.34%] [G loss: 0.678793]\n",
      "epoch:23 step:18059 [D loss: 0.717186, acc.: 45.31%] [G loss: 0.771976]\n",
      "epoch:23 step:18060 [D loss: 0.729147, acc.: 39.06%] [G loss: 0.757386]\n",
      "epoch:23 step:18061 [D loss: 0.659313, acc.: 65.62%] [G loss: 0.851235]\n",
      "epoch:23 step:18062 [D loss: 0.662514, acc.: 60.94%] [G loss: 0.816002]\n",
      "epoch:23 step:18063 [D loss: 0.671758, acc.: 58.59%] [G loss: 0.823176]\n",
      "epoch:23 step:18064 [D loss: 0.733514, acc.: 43.75%] [G loss: 0.783775]\n",
      "epoch:23 step:18065 [D loss: 0.745009, acc.: 36.72%] [G loss: 0.748998]\n",
      "epoch:23 step:18066 [D loss: 0.661611, acc.: 61.72%] [G loss: 0.772629]\n",
      "epoch:23 step:18067 [D loss: 0.698878, acc.: 53.12%] [G loss: 0.723847]\n",
      "epoch:23 step:18068 [D loss: 0.685878, acc.: 54.69%] [G loss: 0.752052]\n",
      "epoch:23 step:18069 [D loss: 0.693603, acc.: 55.47%] [G loss: 0.746375]\n",
      "epoch:23 step:18070 [D loss: 0.695909, acc.: 50.00%] [G loss: 0.727927]\n",
      "epoch:23 step:18071 [D loss: 0.683923, acc.: 52.34%] [G loss: 0.689889]\n",
      "epoch:23 step:18072 [D loss: 0.736740, acc.: 43.75%] [G loss: 0.691657]\n",
      "epoch:23 step:18073 [D loss: 0.677839, acc.: 57.81%] [G loss: 0.761953]\n",
      "epoch:23 step:18074 [D loss: 0.702716, acc.: 53.12%] [G loss: 0.690359]\n",
      "epoch:23 step:18075 [D loss: 0.674763, acc.: 60.16%] [G loss: 0.751477]\n",
      "epoch:23 step:18076 [D loss: 0.703641, acc.: 52.34%] [G loss: 0.719326]\n",
      "epoch:23 step:18077 [D loss: 0.701287, acc.: 57.81%] [G loss: 0.733921]\n",
      "epoch:23 step:18078 [D loss: 0.672343, acc.: 57.03%] [G loss: 0.736141]\n",
      "epoch:23 step:18079 [D loss: 0.730905, acc.: 41.41%] [G loss: 0.729874]\n",
      "epoch:23 step:18080 [D loss: 0.711985, acc.: 41.41%] [G loss: 0.758234]\n",
      "epoch:23 step:18081 [D loss: 0.662008, acc.: 63.28%] [G loss: 0.789243]\n",
      "epoch:23 step:18082 [D loss: 0.665943, acc.: 57.81%] [G loss: 0.743874]\n",
      "epoch:23 step:18083 [D loss: 0.675589, acc.: 57.81%] [G loss: 0.672712]\n",
      "epoch:23 step:18084 [D loss: 0.688598, acc.: 52.34%] [G loss: 0.784873]\n",
      "epoch:23 step:18085 [D loss: 0.723096, acc.: 49.22%] [G loss: 0.722207]\n",
      "epoch:23 step:18086 [D loss: 0.688411, acc.: 53.12%] [G loss: 0.797125]\n",
      "epoch:23 step:18087 [D loss: 0.750297, acc.: 40.62%] [G loss: 0.796697]\n",
      "epoch:23 step:18088 [D loss: 0.751493, acc.: 35.94%] [G loss: 0.785728]\n",
      "epoch:23 step:18089 [D loss: 0.702059, acc.: 54.69%] [G loss: 0.722006]\n",
      "epoch:23 step:18090 [D loss: 0.652430, acc.: 64.84%] [G loss: 0.762953]\n",
      "epoch:23 step:18091 [D loss: 0.703804, acc.: 53.91%] [G loss: 0.711492]\n",
      "epoch:23 step:18092 [D loss: 0.687871, acc.: 53.91%] [G loss: 0.770641]\n",
      "epoch:23 step:18093 [D loss: 0.744115, acc.: 39.06%] [G loss: 0.732095]\n",
      "epoch:23 step:18094 [D loss: 0.679950, acc.: 64.06%] [G loss: 0.744938]\n",
      "epoch:23 step:18095 [D loss: 0.638162, acc.: 70.31%] [G loss: 0.717896]\n",
      "epoch:23 step:18096 [D loss: 0.682295, acc.: 53.12%] [G loss: 0.824371]\n",
      "epoch:23 step:18097 [D loss: 0.672601, acc.: 58.59%] [G loss: 0.831363]\n",
      "epoch:23 step:18098 [D loss: 0.731281, acc.: 40.62%] [G loss: 0.797269]\n",
      "epoch:23 step:18099 [D loss: 0.647667, acc.: 62.50%] [G loss: 0.779492]\n",
      "epoch:23 step:18100 [D loss: 0.658719, acc.: 62.50%] [G loss: 0.762187]\n",
      "epoch:23 step:18101 [D loss: 0.721993, acc.: 46.09%] [G loss: 0.738850]\n",
      "epoch:23 step:18102 [D loss: 0.665143, acc.: 60.16%] [G loss: 0.790016]\n",
      "epoch:23 step:18103 [D loss: 0.706218, acc.: 50.00%] [G loss: 0.762983]\n",
      "epoch:23 step:18104 [D loss: 0.672077, acc.: 60.16%] [G loss: 0.700347]\n",
      "epoch:23 step:18105 [D loss: 0.686813, acc.: 57.81%] [G loss: 0.731004]\n",
      "epoch:23 step:18106 [D loss: 0.699621, acc.: 47.66%] [G loss: 0.746379]\n",
      "epoch:23 step:18107 [D loss: 0.704839, acc.: 46.09%] [G loss: 0.718344]\n",
      "epoch:23 step:18108 [D loss: 0.628547, acc.: 69.53%] [G loss: 0.757801]\n",
      "epoch:23 step:18109 [D loss: 0.686304, acc.: 57.03%] [G loss: 0.752979]\n",
      "epoch:23 step:18110 [D loss: 0.665014, acc.: 61.72%] [G loss: 0.747013]\n",
      "epoch:23 step:18111 [D loss: 0.684065, acc.: 60.94%] [G loss: 0.744207]\n",
      "epoch:23 step:18112 [D loss: 0.746837, acc.: 39.06%] [G loss: 0.724654]\n",
      "epoch:23 step:18113 [D loss: 0.701371, acc.: 53.91%] [G loss: 0.779147]\n",
      "epoch:23 step:18114 [D loss: 0.658108, acc.: 59.38%] [G loss: 0.807793]\n",
      "epoch:23 step:18115 [D loss: 0.643520, acc.: 66.41%] [G loss: 0.809663]\n",
      "epoch:23 step:18116 [D loss: 0.681283, acc.: 50.78%] [G loss: 0.765588]\n",
      "epoch:23 step:18117 [D loss: 0.669934, acc.: 53.91%] [G loss: 0.722442]\n",
      "epoch:23 step:18118 [D loss: 0.600666, acc.: 76.56%] [G loss: 0.788064]\n",
      "epoch:23 step:18119 [D loss: 0.642309, acc.: 73.44%] [G loss: 0.755375]\n",
      "epoch:23 step:18120 [D loss: 0.660416, acc.: 61.72%] [G loss: 0.727439]\n",
      "epoch:23 step:18121 [D loss: 0.671545, acc.: 57.03%] [G loss: 0.710757]\n",
      "epoch:23 step:18122 [D loss: 0.705152, acc.: 44.53%] [G loss: 0.700813]\n",
      "epoch:23 step:18123 [D loss: 0.676618, acc.: 57.03%] [G loss: 0.765425]\n",
      "epoch:23 step:18124 [D loss: 0.701929, acc.: 49.22%] [G loss: 0.691868]\n",
      "epoch:23 step:18125 [D loss: 0.773370, acc.: 32.81%] [G loss: 0.731889]\n",
      "epoch:23 step:18126 [D loss: 0.676774, acc.: 53.91%] [G loss: 0.751403]\n",
      "epoch:23 step:18127 [D loss: 0.694931, acc.: 49.22%] [G loss: 0.748936]\n",
      "epoch:23 step:18128 [D loss: 0.679308, acc.: 60.94%] [G loss: 0.774834]\n",
      "epoch:23 step:18129 [D loss: 0.773632, acc.: 39.06%] [G loss: 0.712466]\n",
      "epoch:23 step:18130 [D loss: 0.671679, acc.: 56.25%] [G loss: 0.690868]\n",
      "epoch:23 step:18131 [D loss: 0.641063, acc.: 67.97%] [G loss: 0.725549]\n",
      "epoch:23 step:18132 [D loss: 0.711822, acc.: 47.66%] [G loss: 0.715275]\n",
      "epoch:23 step:18133 [D loss: 0.673251, acc.: 60.16%] [G loss: 0.784723]\n",
      "epoch:23 step:18134 [D loss: 0.701929, acc.: 49.22%] [G loss: 0.847939]\n",
      "epoch:23 step:18135 [D loss: 0.715859, acc.: 48.44%] [G loss: 0.824341]\n",
      "epoch:23 step:18136 [D loss: 0.712968, acc.: 45.31%] [G loss: 0.835255]\n",
      "epoch:23 step:18137 [D loss: 0.691279, acc.: 50.78%] [G loss: 0.764582]\n",
      "epoch:23 step:18138 [D loss: 0.667641, acc.: 58.59%] [G loss: 0.801281]\n",
      "epoch:23 step:18139 [D loss: 0.681149, acc.: 62.50%] [G loss: 0.814551]\n",
      "epoch:23 step:18140 [D loss: 0.676561, acc.: 57.03%] [G loss: 0.782173]\n",
      "epoch:23 step:18141 [D loss: 0.646374, acc.: 63.28%] [G loss: 0.807380]\n",
      "epoch:23 step:18142 [D loss: 0.651236, acc.: 67.97%] [G loss: 0.736281]\n",
      "epoch:23 step:18143 [D loss: 0.638483, acc.: 66.41%] [G loss: 0.796245]\n",
      "epoch:23 step:18144 [D loss: 0.677172, acc.: 59.38%] [G loss: 0.718293]\n",
      "epoch:23 step:18145 [D loss: 0.664787, acc.: 59.38%] [G loss: 0.726389]\n",
      "epoch:23 step:18146 [D loss: 0.669046, acc.: 59.38%] [G loss: 0.788837]\n",
      "epoch:23 step:18147 [D loss: 0.679944, acc.: 55.47%] [G loss: 0.729125]\n",
      "epoch:23 step:18148 [D loss: 0.614782, acc.: 72.66%] [G loss: 0.729695]\n",
      "epoch:23 step:18149 [D loss: 0.729859, acc.: 46.88%] [G loss: 0.699776]\n",
      "epoch:23 step:18150 [D loss: 0.724175, acc.: 46.88%] [G loss: 0.744731]\n",
      "epoch:23 step:18151 [D loss: 0.739177, acc.: 43.75%] [G loss: 0.806710]\n",
      "epoch:23 step:18152 [D loss: 0.634417, acc.: 75.78%] [G loss: 0.803902]\n",
      "epoch:23 step:18153 [D loss: 0.763878, acc.: 32.03%] [G loss: 0.756492]\n",
      "epoch:23 step:18154 [D loss: 0.697015, acc.: 54.69%] [G loss: 0.727760]\n",
      "epoch:23 step:18155 [D loss: 0.691518, acc.: 54.69%] [G loss: 0.773397]\n",
      "epoch:23 step:18156 [D loss: 0.730253, acc.: 46.09%] [G loss: 0.719163]\n",
      "epoch:23 step:18157 [D loss: 0.694165, acc.: 59.38%] [G loss: 0.811983]\n",
      "epoch:23 step:18158 [D loss: 0.740293, acc.: 41.41%] [G loss: 0.672377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18159 [D loss: 0.721803, acc.: 42.97%] [G loss: 0.742161]\n",
      "epoch:23 step:18160 [D loss: 0.710012, acc.: 47.66%] [G loss: 0.793119]\n",
      "epoch:23 step:18161 [D loss: 0.712822, acc.: 46.88%] [G loss: 0.699238]\n",
      "epoch:23 step:18162 [D loss: 0.729579, acc.: 46.88%] [G loss: 0.713491]\n",
      "epoch:23 step:18163 [D loss: 0.708417, acc.: 50.00%] [G loss: 0.744436]\n",
      "epoch:23 step:18164 [D loss: 0.683807, acc.: 58.59%] [G loss: 0.747775]\n",
      "epoch:23 step:18165 [D loss: 0.716801, acc.: 38.28%] [G loss: 0.777934]\n",
      "epoch:23 step:18166 [D loss: 0.681945, acc.: 55.47%] [G loss: 0.727517]\n",
      "epoch:23 step:18167 [D loss: 0.685138, acc.: 51.56%] [G loss: 0.840695]\n",
      "epoch:23 step:18168 [D loss: 0.668329, acc.: 61.72%] [G loss: 0.776696]\n",
      "epoch:23 step:18169 [D loss: 0.687209, acc.: 53.91%] [G loss: 0.759235]\n",
      "epoch:23 step:18170 [D loss: 0.609498, acc.: 75.78%] [G loss: 0.846208]\n",
      "epoch:23 step:18171 [D loss: 0.710827, acc.: 50.00%] [G loss: 0.734333]\n",
      "epoch:23 step:18172 [D loss: 0.660159, acc.: 64.06%] [G loss: 0.767772]\n",
      "epoch:23 step:18173 [D loss: 0.721441, acc.: 44.53%] [G loss: 0.748448]\n",
      "epoch:23 step:18174 [D loss: 0.655926, acc.: 67.19%] [G loss: 0.771829]\n",
      "epoch:23 step:18175 [D loss: 0.667687, acc.: 60.16%] [G loss: 0.778735]\n",
      "epoch:23 step:18176 [D loss: 0.707341, acc.: 48.44%] [G loss: 0.794997]\n",
      "epoch:23 step:18177 [D loss: 0.706056, acc.: 47.66%] [G loss: 0.700599]\n",
      "epoch:23 step:18178 [D loss: 0.649395, acc.: 67.19%] [G loss: 0.720305]\n",
      "epoch:23 step:18179 [D loss: 0.687592, acc.: 50.78%] [G loss: 0.714184]\n",
      "epoch:23 step:18180 [D loss: 0.702923, acc.: 52.34%] [G loss: 0.733395]\n",
      "epoch:23 step:18181 [D loss: 0.706808, acc.: 47.66%] [G loss: 0.713732]\n",
      "epoch:23 step:18182 [D loss: 0.679203, acc.: 54.69%] [G loss: 0.802887]\n",
      "epoch:23 step:18183 [D loss: 0.676791, acc.: 57.81%] [G loss: 0.668075]\n",
      "epoch:23 step:18184 [D loss: 0.716635, acc.: 46.88%] [G loss: 0.742260]\n",
      "epoch:23 step:18185 [D loss: 0.710650, acc.: 50.00%] [G loss: 0.688342]\n",
      "epoch:23 step:18186 [D loss: 0.688511, acc.: 54.69%] [G loss: 0.711226]\n",
      "epoch:23 step:18187 [D loss: 0.702209, acc.: 53.91%] [G loss: 0.721195]\n",
      "epoch:23 step:18188 [D loss: 0.728464, acc.: 41.41%] [G loss: 0.716912]\n",
      "epoch:23 step:18189 [D loss: 0.684695, acc.: 57.03%] [G loss: 0.740154]\n",
      "epoch:23 step:18190 [D loss: 0.720714, acc.: 47.66%] [G loss: 0.836358]\n",
      "epoch:23 step:18191 [D loss: 0.758464, acc.: 36.72%] [G loss: 0.801346]\n",
      "epoch:23 step:18192 [D loss: 0.696252, acc.: 50.78%] [G loss: 0.747020]\n",
      "epoch:23 step:18193 [D loss: 0.693942, acc.: 58.59%] [G loss: 0.743049]\n",
      "epoch:23 step:18194 [D loss: 0.722612, acc.: 49.22%] [G loss: 0.660022]\n",
      "epoch:23 step:18195 [D loss: 0.718746, acc.: 46.09%] [G loss: 0.754950]\n",
      "epoch:23 step:18196 [D loss: 0.627433, acc.: 73.44%] [G loss: 0.821089]\n",
      "epoch:23 step:18197 [D loss: 0.687079, acc.: 51.56%] [G loss: 0.774107]\n",
      "epoch:23 step:18198 [D loss: 0.748193, acc.: 32.81%] [G loss: 0.719719]\n",
      "epoch:23 step:18199 [D loss: 0.639878, acc.: 65.62%] [G loss: 0.701891]\n",
      "epoch:23 step:18200 [D loss: 0.671061, acc.: 57.03%] [G loss: 0.728439]\n",
      "epoch:23 step:18201 [D loss: 0.661822, acc.: 60.94%] [G loss: 0.730942]\n",
      "epoch:23 step:18202 [D loss: 0.705084, acc.: 50.00%] [G loss: 0.731604]\n",
      "epoch:23 step:18203 [D loss: 0.651544, acc.: 64.06%] [G loss: 0.784420]\n",
      "epoch:23 step:18204 [D loss: 0.679246, acc.: 54.69%] [G loss: 0.726036]\n",
      "epoch:23 step:18205 [D loss: 0.717792, acc.: 50.78%] [G loss: 0.728108]\n",
      "epoch:23 step:18206 [D loss: 0.676702, acc.: 59.38%] [G loss: 0.797804]\n",
      "epoch:23 step:18207 [D loss: 0.607501, acc.: 76.56%] [G loss: 0.738387]\n",
      "epoch:23 step:18208 [D loss: 0.709855, acc.: 46.88%] [G loss: 0.749602]\n",
      "epoch:23 step:18209 [D loss: 0.662831, acc.: 64.84%] [G loss: 0.659762]\n",
      "epoch:23 step:18210 [D loss: 0.649265, acc.: 65.62%] [G loss: 0.651025]\n",
      "epoch:23 step:18211 [D loss: 0.668334, acc.: 57.03%] [G loss: 0.695217]\n",
      "epoch:23 step:18212 [D loss: 0.716336, acc.: 49.22%] [G loss: 0.689392]\n",
      "epoch:23 step:18213 [D loss: 0.736416, acc.: 46.88%] [G loss: 0.709854]\n",
      "epoch:23 step:18214 [D loss: 0.664753, acc.: 62.50%] [G loss: 0.705264]\n",
      "epoch:23 step:18215 [D loss: 0.655946, acc.: 67.19%] [G loss: 0.818672]\n",
      "epoch:23 step:18216 [D loss: 0.710896, acc.: 43.75%] [G loss: 0.733351]\n",
      "epoch:23 step:18217 [D loss: 0.694842, acc.: 57.81%] [G loss: 0.741635]\n",
      "epoch:23 step:18218 [D loss: 0.737624, acc.: 39.84%] [G loss: 0.751086]\n",
      "epoch:23 step:18219 [D loss: 0.725911, acc.: 47.66%] [G loss: 0.780735]\n",
      "epoch:23 step:18220 [D loss: 0.714814, acc.: 45.31%] [G loss: 0.774281]\n",
      "epoch:23 step:18221 [D loss: 0.662544, acc.: 61.72%] [G loss: 0.715045]\n",
      "epoch:23 step:18222 [D loss: 0.724022, acc.: 50.78%] [G loss: 0.744933]\n",
      "epoch:23 step:18223 [D loss: 0.658220, acc.: 63.28%] [G loss: 0.782830]\n",
      "epoch:23 step:18224 [D loss: 0.679347, acc.: 52.34%] [G loss: 0.794149]\n",
      "epoch:23 step:18225 [D loss: 0.729493, acc.: 36.72%] [G loss: 0.815706]\n",
      "epoch:23 step:18226 [D loss: 0.723486, acc.: 37.50%] [G loss: 0.755349]\n",
      "epoch:23 step:18227 [D loss: 0.634347, acc.: 66.41%] [G loss: 0.742675]\n",
      "epoch:23 step:18228 [D loss: 0.738334, acc.: 35.94%] [G loss: 0.656103]\n",
      "epoch:23 step:18229 [D loss: 0.658626, acc.: 59.38%] [G loss: 0.757790]\n",
      "epoch:23 step:18230 [D loss: 0.703576, acc.: 53.91%] [G loss: 0.730099]\n",
      "epoch:23 step:18231 [D loss: 0.612168, acc.: 69.53%] [G loss: 0.727421]\n",
      "epoch:23 step:18232 [D loss: 0.675211, acc.: 58.59%] [G loss: 0.685088]\n",
      "epoch:23 step:18233 [D loss: 0.674238, acc.: 59.38%] [G loss: 0.720446]\n",
      "epoch:23 step:18234 [D loss: 0.659814, acc.: 56.25%] [G loss: 0.784115]\n",
      "epoch:23 step:18235 [D loss: 0.682564, acc.: 59.38%] [G loss: 0.713902]\n",
      "epoch:23 step:18236 [D loss: 0.684861, acc.: 56.25%] [G loss: 0.781573]\n",
      "epoch:23 step:18237 [D loss: 0.741486, acc.: 36.72%] [G loss: 0.695849]\n",
      "epoch:23 step:18238 [D loss: 0.701866, acc.: 53.12%] [G loss: 0.718809]\n",
      "epoch:23 step:18239 [D loss: 0.691790, acc.: 53.12%] [G loss: 0.728581]\n",
      "epoch:23 step:18240 [D loss: 0.806895, acc.: 28.12%] [G loss: 0.685876]\n",
      "epoch:23 step:18241 [D loss: 0.660596, acc.: 60.94%] [G loss: 0.723743]\n",
      "epoch:23 step:18242 [D loss: 0.685001, acc.: 46.88%] [G loss: 0.753422]\n",
      "epoch:23 step:18243 [D loss: 0.695147, acc.: 50.78%] [G loss: 0.727672]\n",
      "epoch:23 step:18244 [D loss: 0.719080, acc.: 42.19%] [G loss: 0.767035]\n",
      "epoch:23 step:18245 [D loss: 0.792948, acc.: 33.59%] [G loss: 0.776330]\n",
      "epoch:23 step:18246 [D loss: 0.686425, acc.: 48.44%] [G loss: 0.795560]\n",
      "epoch:23 step:18247 [D loss: 0.704944, acc.: 53.12%] [G loss: 0.799110]\n",
      "epoch:23 step:18248 [D loss: 0.696944, acc.: 48.44%] [G loss: 0.857178]\n",
      "epoch:23 step:18249 [D loss: 0.659678, acc.: 60.16%] [G loss: 0.860741]\n",
      "epoch:23 step:18250 [D loss: 0.731542, acc.: 40.62%] [G loss: 0.733548]\n",
      "epoch:23 step:18251 [D loss: 0.744855, acc.: 41.41%] [G loss: 0.728635]\n",
      "epoch:23 step:18252 [D loss: 0.676901, acc.: 57.03%] [G loss: 0.785962]\n",
      "epoch:23 step:18253 [D loss: 0.679751, acc.: 59.38%] [G loss: 0.807536]\n",
      "epoch:23 step:18254 [D loss: 0.755604, acc.: 42.97%] [G loss: 0.769579]\n",
      "epoch:23 step:18255 [D loss: 0.698174, acc.: 52.34%] [G loss: 0.773328]\n",
      "epoch:23 step:18256 [D loss: 0.745334, acc.: 37.50%] [G loss: 0.732504]\n",
      "epoch:23 step:18257 [D loss: 0.680089, acc.: 63.28%] [G loss: 0.788589]\n",
      "epoch:23 step:18258 [D loss: 0.683821, acc.: 59.38%] [G loss: 0.798170]\n",
      "epoch:23 step:18259 [D loss: 0.698112, acc.: 51.56%] [G loss: 0.735702]\n",
      "epoch:23 step:18260 [D loss: 0.673797, acc.: 57.03%] [G loss: 0.723155]\n",
      "epoch:23 step:18261 [D loss: 0.701512, acc.: 50.00%] [G loss: 0.749023]\n",
      "epoch:23 step:18262 [D loss: 0.699170, acc.: 48.44%] [G loss: 0.745810]\n",
      "epoch:23 step:18263 [D loss: 0.702216, acc.: 52.34%] [G loss: 0.700122]\n",
      "epoch:23 step:18264 [D loss: 0.671489, acc.: 60.94%] [G loss: 0.755972]\n",
      "epoch:23 step:18265 [D loss: 0.693282, acc.: 57.81%] [G loss: 0.711228]\n",
      "epoch:23 step:18266 [D loss: 0.674287, acc.: 60.16%] [G loss: 0.782809]\n",
      "epoch:23 step:18267 [D loss: 0.658847, acc.: 64.84%] [G loss: 0.738454]\n",
      "epoch:23 step:18268 [D loss: 0.737063, acc.: 43.75%] [G loss: 0.727093]\n",
      "epoch:23 step:18269 [D loss: 0.660144, acc.: 67.97%] [G loss: 0.712259]\n",
      "epoch:23 step:18270 [D loss: 0.719342, acc.: 43.75%] [G loss: 0.759925]\n",
      "epoch:23 step:18271 [D loss: 0.666285, acc.: 58.59%] [G loss: 0.721125]\n",
      "epoch:23 step:18272 [D loss: 0.696292, acc.: 50.78%] [G loss: 0.797989]\n",
      "epoch:23 step:18273 [D loss: 0.660917, acc.: 64.06%] [G loss: 0.797482]\n",
      "epoch:23 step:18274 [D loss: 0.738856, acc.: 37.50%] [G loss: 0.735222]\n",
      "epoch:23 step:18275 [D loss: 0.687929, acc.: 50.78%] [G loss: 0.735495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18276 [D loss: 0.661146, acc.: 58.59%] [G loss: 0.761687]\n",
      "epoch:23 step:18277 [D loss: 0.682331, acc.: 53.91%] [G loss: 0.802007]\n",
      "epoch:23 step:18278 [D loss: 0.703146, acc.: 52.34%] [G loss: 0.756053]\n",
      "epoch:23 step:18279 [D loss: 0.677750, acc.: 53.91%] [G loss: 0.713243]\n",
      "epoch:23 step:18280 [D loss: 0.738414, acc.: 37.50%] [G loss: 0.662000]\n",
      "epoch:23 step:18281 [D loss: 0.672758, acc.: 57.81%] [G loss: 0.735102]\n",
      "epoch:23 step:18282 [D loss: 0.711789, acc.: 46.88%] [G loss: 0.847654]\n",
      "epoch:23 step:18283 [D loss: 0.680793, acc.: 53.91%] [G loss: 0.757563]\n",
      "epoch:23 step:18284 [D loss: 0.678468, acc.: 55.47%] [G loss: 0.700503]\n",
      "epoch:23 step:18285 [D loss: 0.682749, acc.: 60.16%] [G loss: 0.693654]\n",
      "epoch:23 step:18286 [D loss: 0.635318, acc.: 71.88%] [G loss: 0.707836]\n",
      "epoch:23 step:18287 [D loss: 0.672080, acc.: 60.16%] [G loss: 0.672176]\n",
      "epoch:23 step:18288 [D loss: 0.674563, acc.: 57.03%] [G loss: 0.744131]\n",
      "epoch:23 step:18289 [D loss: 0.709692, acc.: 46.88%] [G loss: 0.739032]\n",
      "epoch:23 step:18290 [D loss: 0.680257, acc.: 59.38%] [G loss: 0.780267]\n",
      "epoch:23 step:18291 [D loss: 0.691875, acc.: 49.22%] [G loss: 0.754043]\n",
      "epoch:23 step:18292 [D loss: 0.725380, acc.: 47.66%] [G loss: 0.668835]\n",
      "epoch:23 step:18293 [D loss: 0.682259, acc.: 56.25%] [G loss: 0.688300]\n",
      "epoch:23 step:18294 [D loss: 0.756574, acc.: 38.28%] [G loss: 0.690609]\n",
      "epoch:23 step:18295 [D loss: 0.683736, acc.: 57.81%] [G loss: 0.737573]\n",
      "epoch:23 step:18296 [D loss: 0.635885, acc.: 69.53%] [G loss: 0.769538]\n",
      "epoch:23 step:18297 [D loss: 0.710974, acc.: 46.09%] [G loss: 0.754544]\n",
      "epoch:23 step:18298 [D loss: 0.672920, acc.: 60.16%] [G loss: 0.659462]\n",
      "epoch:23 step:18299 [D loss: 0.698153, acc.: 55.47%] [G loss: 0.699700]\n",
      "epoch:23 step:18300 [D loss: 0.694289, acc.: 53.91%] [G loss: 0.757306]\n",
      "epoch:23 step:18301 [D loss: 0.750972, acc.: 39.06%] [G loss: 0.774230]\n",
      "epoch:23 step:18302 [D loss: 0.715313, acc.: 53.12%] [G loss: 0.739791]\n",
      "epoch:23 step:18303 [D loss: 0.723393, acc.: 43.75%] [G loss: 0.708619]\n",
      "epoch:23 step:18304 [D loss: 0.650003, acc.: 66.41%] [G loss: 0.735537]\n",
      "epoch:23 step:18305 [D loss: 0.678818, acc.: 58.59%] [G loss: 0.796328]\n",
      "epoch:23 step:18306 [D loss: 0.703994, acc.: 50.78%] [G loss: 0.754365]\n",
      "epoch:23 step:18307 [D loss: 0.688591, acc.: 53.91%] [G loss: 0.806646]\n",
      "epoch:23 step:18308 [D loss: 0.655143, acc.: 61.72%] [G loss: 0.777070]\n",
      "epoch:23 step:18309 [D loss: 0.663304, acc.: 60.16%] [G loss: 0.801313]\n",
      "epoch:23 step:18310 [D loss: 0.696334, acc.: 52.34%] [G loss: 0.801640]\n",
      "epoch:23 step:18311 [D loss: 0.726545, acc.: 44.53%] [G loss: 0.794944]\n",
      "epoch:23 step:18312 [D loss: 0.666402, acc.: 58.59%] [G loss: 0.768426]\n",
      "epoch:23 step:18313 [D loss: 0.691037, acc.: 57.03%] [G loss: 0.751901]\n",
      "epoch:23 step:18314 [D loss: 0.659534, acc.: 66.41%] [G loss: 0.818814]\n",
      "epoch:23 step:18315 [D loss: 0.644670, acc.: 67.19%] [G loss: 0.795944]\n",
      "epoch:23 step:18316 [D loss: 0.646951, acc.: 65.62%] [G loss: 0.780547]\n",
      "epoch:23 step:18317 [D loss: 0.668370, acc.: 55.47%] [G loss: 0.805084]\n",
      "epoch:23 step:18318 [D loss: 0.655027, acc.: 64.06%] [G loss: 0.750461]\n",
      "epoch:23 step:18319 [D loss: 0.666710, acc.: 58.59%] [G loss: 0.763798]\n",
      "epoch:23 step:18320 [D loss: 0.700673, acc.: 49.22%] [G loss: 0.769823]\n",
      "epoch:23 step:18321 [D loss: 0.698477, acc.: 53.91%] [G loss: 0.703024]\n",
      "epoch:23 step:18322 [D loss: 0.733685, acc.: 41.41%] [G loss: 0.682443]\n",
      "epoch:23 step:18323 [D loss: 0.716817, acc.: 44.53%] [G loss: 0.685920]\n",
      "epoch:23 step:18324 [D loss: 0.693595, acc.: 54.69%] [G loss: 0.729452]\n",
      "epoch:23 step:18325 [D loss: 0.734408, acc.: 41.41%] [G loss: 0.691796]\n",
      "epoch:23 step:18326 [D loss: 0.698003, acc.: 50.00%] [G loss: 0.707772]\n",
      "epoch:23 step:18327 [D loss: 0.711568, acc.: 51.56%] [G loss: 0.709713]\n",
      "epoch:23 step:18328 [D loss: 0.666867, acc.: 60.16%] [G loss: 0.730406]\n",
      "epoch:23 step:18329 [D loss: 0.710778, acc.: 43.75%] [G loss: 0.699531]\n",
      "epoch:23 step:18330 [D loss: 0.723935, acc.: 48.44%] [G loss: 0.742191]\n",
      "epoch:23 step:18331 [D loss: 0.661449, acc.: 60.94%] [G loss: 0.727348]\n",
      "epoch:23 step:18332 [D loss: 0.691386, acc.: 50.00%] [G loss: 0.788033]\n",
      "epoch:23 step:18333 [D loss: 0.658674, acc.: 64.06%] [G loss: 0.755461]\n",
      "epoch:23 step:18334 [D loss: 0.702555, acc.: 45.31%] [G loss: 0.817450]\n",
      "epoch:23 step:18335 [D loss: 0.710546, acc.: 50.00%] [G loss: 0.800823]\n",
      "epoch:23 step:18336 [D loss: 0.707282, acc.: 46.88%] [G loss: 0.766450]\n",
      "epoch:23 step:18337 [D loss: 0.713235, acc.: 44.53%] [G loss: 0.793621]\n",
      "epoch:23 step:18338 [D loss: 0.664406, acc.: 60.94%] [G loss: 0.850305]\n",
      "epoch:23 step:18339 [D loss: 0.690742, acc.: 50.78%] [G loss: 0.803931]\n",
      "epoch:23 step:18340 [D loss: 0.672631, acc.: 62.50%] [G loss: 0.773476]\n",
      "epoch:23 step:18341 [D loss: 0.662178, acc.: 58.59%] [G loss: 0.776601]\n",
      "epoch:23 step:18342 [D loss: 0.631384, acc.: 64.84%] [G loss: 0.835714]\n",
      "epoch:23 step:18343 [D loss: 0.659070, acc.: 63.28%] [G loss: 0.857241]\n",
      "epoch:23 step:18344 [D loss: 0.621146, acc.: 69.53%] [G loss: 0.784777]\n",
      "epoch:23 step:18345 [D loss: 0.691802, acc.: 49.22%] [G loss: 0.856493]\n",
      "epoch:23 step:18346 [D loss: 0.689976, acc.: 53.91%] [G loss: 0.808982]\n",
      "epoch:23 step:18347 [D loss: 0.709204, acc.: 42.19%] [G loss: 0.752509]\n",
      "epoch:23 step:18348 [D loss: 0.648906, acc.: 67.97%] [G loss: 0.774429]\n",
      "epoch:23 step:18349 [D loss: 0.681255, acc.: 54.69%] [G loss: 0.752572]\n",
      "epoch:23 step:18350 [D loss: 0.681864, acc.: 53.91%] [G loss: 0.733810]\n",
      "epoch:23 step:18351 [D loss: 0.701711, acc.: 46.88%] [G loss: 0.695269]\n",
      "epoch:23 step:18352 [D loss: 0.700772, acc.: 53.12%] [G loss: 0.769358]\n",
      "epoch:23 step:18353 [D loss: 0.703406, acc.: 50.78%] [G loss: 0.712166]\n",
      "epoch:23 step:18354 [D loss: 0.759989, acc.: 38.28%] [G loss: 0.725151]\n",
      "epoch:23 step:18355 [D loss: 0.729081, acc.: 41.41%] [G loss: 0.739120]\n",
      "epoch:23 step:18356 [D loss: 0.724538, acc.: 41.41%] [G loss: 0.704972]\n",
      "epoch:23 step:18357 [D loss: 0.743169, acc.: 42.19%] [G loss: 0.746398]\n",
      "epoch:23 step:18358 [D loss: 0.731929, acc.: 49.22%] [G loss: 0.723507]\n",
      "epoch:23 step:18359 [D loss: 0.686621, acc.: 56.25%] [G loss: 0.746585]\n",
      "epoch:23 step:18360 [D loss: 0.724209, acc.: 43.75%] [G loss: 0.734499]\n",
      "epoch:23 step:18361 [D loss: 0.733449, acc.: 38.28%] [G loss: 0.741022]\n",
      "epoch:23 step:18362 [D loss: 0.689812, acc.: 57.03%] [G loss: 0.738427]\n",
      "epoch:23 step:18363 [D loss: 0.728117, acc.: 42.97%] [G loss: 0.760608]\n",
      "epoch:23 step:18364 [D loss: 0.664607, acc.: 60.16%] [G loss: 0.773237]\n",
      "epoch:23 step:18365 [D loss: 0.679696, acc.: 58.59%] [G loss: 0.794286]\n",
      "epoch:23 step:18366 [D loss: 0.669500, acc.: 58.59%] [G loss: 0.823410]\n",
      "epoch:23 step:18367 [D loss: 0.716429, acc.: 46.09%] [G loss: 0.795202]\n",
      "epoch:23 step:18368 [D loss: 0.735557, acc.: 39.06%] [G loss: 0.827275]\n",
      "epoch:23 step:18369 [D loss: 0.702338, acc.: 50.00%] [G loss: 0.839365]\n",
      "epoch:23 step:18370 [D loss: 0.678144, acc.: 61.72%] [G loss: 0.784390]\n",
      "epoch:23 step:18371 [D loss: 0.723252, acc.: 42.97%] [G loss: 0.723065]\n",
      "epoch:23 step:18372 [D loss: 0.684183, acc.: 57.81%] [G loss: 0.770932]\n",
      "epoch:23 step:18373 [D loss: 0.668618, acc.: 57.81%] [G loss: 0.761998]\n",
      "epoch:23 step:18374 [D loss: 0.713935, acc.: 50.00%] [G loss: 0.803355]\n",
      "epoch:23 step:18375 [D loss: 0.720025, acc.: 46.09%] [G loss: 0.765966]\n",
      "epoch:23 step:18376 [D loss: 0.710705, acc.: 50.00%] [G loss: 0.751536]\n",
      "epoch:23 step:18377 [D loss: 0.692445, acc.: 53.91%] [G loss: 0.751513]\n",
      "epoch:23 step:18378 [D loss: 0.651333, acc.: 70.31%] [G loss: 0.779566]\n",
      "epoch:23 step:18379 [D loss: 0.695944, acc.: 51.56%] [G loss: 0.791350]\n",
      "epoch:23 step:18380 [D loss: 0.731554, acc.: 35.16%] [G loss: 0.734396]\n",
      "epoch:23 step:18381 [D loss: 0.663850, acc.: 62.50%] [G loss: 0.791774]\n",
      "epoch:23 step:18382 [D loss: 0.693755, acc.: 50.78%] [G loss: 0.789730]\n",
      "epoch:23 step:18383 [D loss: 0.659416, acc.: 66.41%] [G loss: 0.786654]\n",
      "epoch:23 step:18384 [D loss: 0.674962, acc.: 59.38%] [G loss: 0.793828]\n",
      "epoch:23 step:18385 [D loss: 0.705398, acc.: 50.00%] [G loss: 0.812931]\n",
      "epoch:23 step:18386 [D loss: 0.699058, acc.: 53.91%] [G loss: 0.752607]\n",
      "epoch:23 step:18387 [D loss: 0.740687, acc.: 43.75%] [G loss: 0.786811]\n",
      "epoch:23 step:18388 [D loss: 0.678257, acc.: 57.81%] [G loss: 0.724150]\n",
      "epoch:23 step:18389 [D loss: 0.698752, acc.: 56.25%] [G loss: 0.754950]\n",
      "epoch:23 step:18390 [D loss: 0.687997, acc.: 57.81%] [G loss: 0.742050]\n",
      "epoch:23 step:18391 [D loss: 0.726595, acc.: 42.97%] [G loss: 0.677461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18392 [D loss: 0.748721, acc.: 41.41%] [G loss: 0.671352]\n",
      "epoch:23 step:18393 [D loss: 0.677912, acc.: 57.03%] [G loss: 0.735746]\n",
      "epoch:23 step:18394 [D loss: 0.718053, acc.: 42.19%] [G loss: 0.790923]\n",
      "epoch:23 step:18395 [D loss: 0.677130, acc.: 58.59%] [G loss: 0.823919]\n",
      "epoch:23 step:18396 [D loss: 0.645290, acc.: 63.28%] [G loss: 0.839812]\n",
      "epoch:23 step:18397 [D loss: 0.715719, acc.: 51.56%] [G loss: 0.773090]\n",
      "epoch:23 step:18398 [D loss: 0.688493, acc.: 55.47%] [G loss: 0.732728]\n",
      "epoch:23 step:18399 [D loss: 0.742011, acc.: 41.41%] [G loss: 0.783028]\n",
      "epoch:23 step:18400 [D loss: 0.737196, acc.: 41.41%] [G loss: 0.777927]\n",
      "epoch:23 step:18401 [D loss: 0.665066, acc.: 61.72%] [G loss: 0.788125]\n",
      "epoch:23 step:18402 [D loss: 0.703219, acc.: 52.34%] [G loss: 0.723798]\n",
      "epoch:23 step:18403 [D loss: 0.728279, acc.: 37.50%] [G loss: 0.708317]\n",
      "epoch:23 step:18404 [D loss: 0.674920, acc.: 52.34%] [G loss: 0.769204]\n",
      "epoch:23 step:18405 [D loss: 0.704855, acc.: 47.66%] [G loss: 0.747494]\n",
      "epoch:23 step:18406 [D loss: 0.678152, acc.: 58.59%] [G loss: 0.701861]\n",
      "epoch:23 step:18407 [D loss: 0.662135, acc.: 57.81%] [G loss: 0.764097]\n",
      "epoch:23 step:18408 [D loss: 0.678836, acc.: 60.16%] [G loss: 0.760744]\n",
      "epoch:23 step:18409 [D loss: 0.724161, acc.: 42.97%] [G loss: 0.727119]\n",
      "epoch:23 step:18410 [D loss: 0.675134, acc.: 60.16%] [G loss: 0.777732]\n",
      "epoch:23 step:18411 [D loss: 0.667124, acc.: 63.28%] [G loss: 0.813325]\n",
      "epoch:23 step:18412 [D loss: 0.640823, acc.: 64.84%] [G loss: 0.783659]\n",
      "epoch:23 step:18413 [D loss: 0.696336, acc.: 58.59%] [G loss: 0.768075]\n",
      "epoch:23 step:18414 [D loss: 0.663942, acc.: 60.16%] [G loss: 0.809169]\n",
      "epoch:23 step:18415 [D loss: 0.684331, acc.: 53.12%] [G loss: 0.751741]\n",
      "epoch:23 step:18416 [D loss: 0.710449, acc.: 46.09%] [G loss: 0.750482]\n",
      "epoch:23 step:18417 [D loss: 0.686902, acc.: 56.25%] [G loss: 0.847470]\n",
      "epoch:23 step:18418 [D loss: 0.677454, acc.: 55.47%] [G loss: 0.751802]\n",
      "epoch:23 step:18419 [D loss: 0.743381, acc.: 39.84%] [G loss: 0.766105]\n",
      "epoch:23 step:18420 [D loss: 0.710176, acc.: 50.78%] [G loss: 0.724111]\n",
      "epoch:23 step:18421 [D loss: 0.687857, acc.: 50.78%] [G loss: 0.756589]\n",
      "epoch:23 step:18422 [D loss: 0.702670, acc.: 50.78%] [G loss: 0.764450]\n",
      "epoch:23 step:18423 [D loss: 0.730885, acc.: 42.97%] [G loss: 0.752435]\n",
      "epoch:23 step:18424 [D loss: 0.702810, acc.: 49.22%] [G loss: 0.726912]\n",
      "epoch:23 step:18425 [D loss: 0.690177, acc.: 52.34%] [G loss: 0.743052]\n",
      "epoch:23 step:18426 [D loss: 0.732751, acc.: 46.09%] [G loss: 0.757106]\n",
      "epoch:23 step:18427 [D loss: 0.653643, acc.: 65.62%] [G loss: 0.814552]\n",
      "epoch:23 step:18428 [D loss: 0.685325, acc.: 57.03%] [G loss: 0.748906]\n",
      "epoch:23 step:18429 [D loss: 0.705034, acc.: 52.34%] [G loss: 0.744163]\n",
      "epoch:23 step:18430 [D loss: 0.657029, acc.: 64.06%] [G loss: 0.795824]\n",
      "epoch:23 step:18431 [D loss: 0.701037, acc.: 47.66%] [G loss: 0.836577]\n",
      "epoch:23 step:18432 [D loss: 0.682730, acc.: 51.56%] [G loss: 0.781826]\n",
      "epoch:23 step:18433 [D loss: 0.734340, acc.: 39.84%] [G loss: 0.746432]\n",
      "epoch:23 step:18434 [D loss: 0.665178, acc.: 58.59%] [G loss: 0.925000]\n",
      "epoch:23 step:18435 [D loss: 0.672131, acc.: 63.28%] [G loss: 0.792404]\n",
      "epoch:23 step:18436 [D loss: 0.765050, acc.: 40.62%] [G loss: 0.717254]\n",
      "epoch:23 step:18437 [D loss: 0.685015, acc.: 53.12%] [G loss: 0.772269]\n",
      "epoch:23 step:18438 [D loss: 0.741263, acc.: 42.19%] [G loss: 0.727474]\n",
      "epoch:23 step:18439 [D loss: 0.659192, acc.: 63.28%] [G loss: 0.757859]\n",
      "epoch:23 step:18440 [D loss: 0.671972, acc.: 54.69%] [G loss: 0.741871]\n",
      "epoch:23 step:18441 [D loss: 0.634756, acc.: 72.66%] [G loss: 0.796292]\n",
      "epoch:23 step:18442 [D loss: 0.698414, acc.: 57.03%] [G loss: 0.771626]\n",
      "epoch:23 step:18443 [D loss: 0.677644, acc.: 56.25%] [G loss: 0.867040]\n",
      "epoch:23 step:18444 [D loss: 0.753901, acc.: 35.16%] [G loss: 0.758492]\n",
      "epoch:23 step:18445 [D loss: 0.750611, acc.: 36.72%] [G loss: 0.731464]\n",
      "epoch:23 step:18446 [D loss: 0.672838, acc.: 55.47%] [G loss: 0.755174]\n",
      "epoch:23 step:18447 [D loss: 0.700494, acc.: 49.22%] [G loss: 0.768060]\n",
      "epoch:23 step:18448 [D loss: 0.665121, acc.: 60.16%] [G loss: 0.737367]\n",
      "epoch:23 step:18449 [D loss: 0.637354, acc.: 70.31%] [G loss: 0.797402]\n",
      "epoch:23 step:18450 [D loss: 0.712234, acc.: 44.53%] [G loss: 0.655517]\n",
      "epoch:23 step:18451 [D loss: 0.699264, acc.: 51.56%] [G loss: 0.756726]\n",
      "epoch:23 step:18452 [D loss: 0.672103, acc.: 60.16%] [G loss: 0.705833]\n",
      "epoch:23 step:18453 [D loss: 0.689481, acc.: 53.91%] [G loss: 0.754401]\n",
      "epoch:23 step:18454 [D loss: 0.703752, acc.: 48.44%] [G loss: 0.723237]\n",
      "epoch:23 step:18455 [D loss: 0.735341, acc.: 39.06%] [G loss: 0.685863]\n",
      "epoch:23 step:18456 [D loss: 0.693393, acc.: 53.12%] [G loss: 0.724312]\n",
      "epoch:23 step:18457 [D loss: 0.652507, acc.: 67.97%] [G loss: 0.699513]\n",
      "epoch:23 step:18458 [D loss: 0.699747, acc.: 44.53%] [G loss: 0.770633]\n",
      "epoch:23 step:18459 [D loss: 0.675140, acc.: 56.25%] [G loss: 0.744655]\n",
      "epoch:23 step:18460 [D loss: 0.664909, acc.: 60.94%] [G loss: 0.751093]\n",
      "epoch:23 step:18461 [D loss: 0.669434, acc.: 63.28%] [G loss: 0.707812]\n",
      "epoch:23 step:18462 [D loss: 0.645929, acc.: 69.53%] [G loss: 0.782444]\n",
      "epoch:23 step:18463 [D loss: 0.729674, acc.: 43.75%] [G loss: 0.706198]\n",
      "epoch:23 step:18464 [D loss: 0.712643, acc.: 45.31%] [G loss: 0.746511]\n",
      "epoch:23 step:18465 [D loss: 0.711949, acc.: 49.22%] [G loss: 0.728996]\n",
      "epoch:23 step:18466 [D loss: 0.697525, acc.: 53.91%] [G loss: 0.787495]\n",
      "epoch:23 step:18467 [D loss: 0.703130, acc.: 50.78%] [G loss: 0.738433]\n",
      "epoch:23 step:18468 [D loss: 0.696220, acc.: 48.44%] [G loss: 0.761941]\n",
      "epoch:23 step:18469 [D loss: 0.706898, acc.: 52.34%] [G loss: 0.781958]\n",
      "epoch:23 step:18470 [D loss: 0.678802, acc.: 55.47%] [G loss: 0.793378]\n",
      "epoch:23 step:18471 [D loss: 0.740475, acc.: 40.62%] [G loss: 0.785548]\n",
      "epoch:23 step:18472 [D loss: 0.706454, acc.: 46.88%] [G loss: 0.810526]\n",
      "epoch:23 step:18473 [D loss: 0.665526, acc.: 62.50%] [G loss: 0.751715]\n",
      "epoch:23 step:18474 [D loss: 0.724409, acc.: 43.75%] [G loss: 0.740942]\n",
      "epoch:23 step:18475 [D loss: 0.753338, acc.: 37.50%] [G loss: 0.722023]\n",
      "epoch:23 step:18476 [D loss: 0.735089, acc.: 42.97%] [G loss: 0.719936]\n",
      "epoch:23 step:18477 [D loss: 0.748292, acc.: 39.84%] [G loss: 0.688479]\n",
      "epoch:23 step:18478 [D loss: 0.673740, acc.: 53.91%] [G loss: 0.717767]\n",
      "epoch:23 step:18479 [D loss: 0.683147, acc.: 57.03%] [G loss: 0.719469]\n",
      "epoch:23 step:18480 [D loss: 0.732641, acc.: 42.97%] [G loss: 0.763879]\n",
      "epoch:23 step:18481 [D loss: 0.648306, acc.: 64.06%] [G loss: 0.766693]\n",
      "epoch:23 step:18482 [D loss: 0.722532, acc.: 46.88%] [G loss: 0.776250]\n",
      "epoch:23 step:18483 [D loss: 0.662014, acc.: 67.19%] [G loss: 0.845248]\n",
      "epoch:23 step:18484 [D loss: 0.647142, acc.: 60.94%] [G loss: 0.801100]\n",
      "epoch:23 step:18485 [D loss: 0.729929, acc.: 38.28%] [G loss: 0.737637]\n",
      "epoch:23 step:18486 [D loss: 0.728746, acc.: 43.75%] [G loss: 0.718288]\n",
      "epoch:23 step:18487 [D loss: 0.652477, acc.: 60.16%] [G loss: 0.836415]\n",
      "epoch:23 step:18488 [D loss: 0.648933, acc.: 64.06%] [G loss: 0.770856]\n",
      "epoch:23 step:18489 [D loss: 0.788943, acc.: 35.16%] [G loss: 0.762188]\n",
      "epoch:23 step:18490 [D loss: 0.694936, acc.: 51.56%] [G loss: 0.731654]\n",
      "epoch:23 step:18491 [D loss: 0.748755, acc.: 40.62%] [G loss: 0.690884]\n",
      "epoch:23 step:18492 [D loss: 0.671069, acc.: 63.28%] [G loss: 0.728221]\n",
      "epoch:23 step:18493 [D loss: 0.648866, acc.: 61.72%] [G loss: 0.713907]\n",
      "epoch:23 step:18494 [D loss: 0.656761, acc.: 63.28%] [G loss: 0.770818]\n",
      "epoch:23 step:18495 [D loss: 0.697638, acc.: 52.34%] [G loss: 0.791042]\n",
      "epoch:23 step:18496 [D loss: 0.705781, acc.: 45.31%] [G loss: 0.699441]\n",
      "epoch:23 step:18497 [D loss: 0.676845, acc.: 55.47%] [G loss: 0.720322]\n",
      "epoch:23 step:18498 [D loss: 0.667640, acc.: 60.16%] [G loss: 0.729598]\n",
      "epoch:23 step:18499 [D loss: 0.638146, acc.: 74.22%] [G loss: 0.804265]\n",
      "epoch:23 step:18500 [D loss: 0.665416, acc.: 57.81%] [G loss: 0.727982]\n",
      "epoch:23 step:18501 [D loss: 0.711929, acc.: 46.09%] [G loss: 0.743579]\n",
      "epoch:23 step:18502 [D loss: 0.704166, acc.: 49.22%] [G loss: 0.729704]\n",
      "epoch:23 step:18503 [D loss: 0.704011, acc.: 51.56%] [G loss: 0.687104]\n",
      "epoch:23 step:18504 [D loss: 0.683043, acc.: 59.38%] [G loss: 0.719475]\n",
      "epoch:23 step:18505 [D loss: 0.691887, acc.: 51.56%] [G loss: 0.821192]\n",
      "epoch:23 step:18506 [D loss: 0.708462, acc.: 46.88%] [G loss: 0.705567]\n",
      "epoch:23 step:18507 [D loss: 0.690998, acc.: 53.91%] [G loss: 0.733328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18508 [D loss: 0.666829, acc.: 57.81%] [G loss: 0.756648]\n",
      "epoch:23 step:18509 [D loss: 0.744940, acc.: 40.62%] [G loss: 0.758389]\n",
      "epoch:23 step:18510 [D loss: 0.679595, acc.: 57.81%] [G loss: 0.775977]\n",
      "epoch:23 step:18511 [D loss: 0.687350, acc.: 59.38%] [G loss: 0.805367]\n",
      "epoch:23 step:18512 [D loss: 0.680164, acc.: 56.25%] [G loss: 0.818781]\n",
      "epoch:23 step:18513 [D loss: 0.714212, acc.: 46.88%] [G loss: 0.724766]\n",
      "epoch:23 step:18514 [D loss: 0.740858, acc.: 39.84%] [G loss: 0.785810]\n",
      "epoch:23 step:18515 [D loss: 0.724660, acc.: 42.97%] [G loss: 0.760715]\n",
      "epoch:23 step:18516 [D loss: 0.683969, acc.: 54.69%] [G loss: 0.759069]\n",
      "epoch:23 step:18517 [D loss: 0.686662, acc.: 50.00%] [G loss: 0.861633]\n",
      "epoch:23 step:18518 [D loss: 0.711111, acc.: 43.75%] [G loss: 0.848596]\n",
      "epoch:23 step:18519 [D loss: 0.686871, acc.: 56.25%] [G loss: 0.792514]\n",
      "epoch:23 step:18520 [D loss: 0.693684, acc.: 50.00%] [G loss: 0.718144]\n",
      "epoch:23 step:18521 [D loss: 0.679130, acc.: 54.69%] [G loss: 0.749378]\n",
      "epoch:23 step:18522 [D loss: 0.664102, acc.: 61.72%] [G loss: 0.786828]\n",
      "epoch:23 step:18523 [D loss: 0.670359, acc.: 56.25%] [G loss: 0.661026]\n",
      "epoch:23 step:18524 [D loss: 0.667943, acc.: 57.03%] [G loss: 0.730812]\n",
      "epoch:23 step:18525 [D loss: 0.653157, acc.: 57.81%] [G loss: 0.752150]\n",
      "epoch:23 step:18526 [D loss: 0.720434, acc.: 46.09%] [G loss: 0.747072]\n",
      "epoch:23 step:18527 [D loss: 0.666187, acc.: 55.47%] [G loss: 0.741804]\n",
      "epoch:23 step:18528 [D loss: 0.688472, acc.: 55.47%] [G loss: 0.815277]\n",
      "epoch:23 step:18529 [D loss: 0.694720, acc.: 53.12%] [G loss: 0.764018]\n",
      "epoch:23 step:18530 [D loss: 0.719540, acc.: 50.00%] [G loss: 0.821806]\n",
      "epoch:23 step:18531 [D loss: 0.640890, acc.: 67.19%] [G loss: 0.822190]\n",
      "epoch:23 step:18532 [D loss: 0.696268, acc.: 47.66%] [G loss: 0.780923]\n",
      "epoch:23 step:18533 [D loss: 0.697381, acc.: 50.78%] [G loss: 0.806282]\n",
      "epoch:23 step:18534 [D loss: 0.722481, acc.: 46.88%] [G loss: 0.739616]\n",
      "epoch:23 step:18535 [D loss: 0.669138, acc.: 57.03%] [G loss: 0.769683]\n",
      "epoch:23 step:18536 [D loss: 0.697908, acc.: 52.34%] [G loss: 0.788318]\n",
      "epoch:23 step:18537 [D loss: 0.738882, acc.: 36.72%] [G loss: 0.725888]\n",
      "epoch:23 step:18538 [D loss: 0.704963, acc.: 52.34%] [G loss: 0.712745]\n",
      "epoch:23 step:18539 [D loss: 0.678388, acc.: 58.59%] [G loss: 0.689268]\n",
      "epoch:23 step:18540 [D loss: 0.744607, acc.: 42.19%] [G loss: 0.692327]\n",
      "epoch:23 step:18541 [D loss: 0.703992, acc.: 49.22%] [G loss: 0.750823]\n",
      "epoch:23 step:18542 [D loss: 0.702141, acc.: 46.88%] [G loss: 0.728018]\n",
      "epoch:23 step:18543 [D loss: 0.699848, acc.: 52.34%] [G loss: 0.723961]\n",
      "epoch:23 step:18544 [D loss: 0.733283, acc.: 42.97%] [G loss: 0.692835]\n",
      "epoch:23 step:18545 [D loss: 0.671576, acc.: 57.81%] [G loss: 0.768525]\n",
      "epoch:23 step:18546 [D loss: 0.696948, acc.: 50.00%] [G loss: 0.831641]\n",
      "epoch:23 step:18547 [D loss: 0.653560, acc.: 64.84%] [G loss: 0.823729]\n",
      "epoch:23 step:18548 [D loss: 0.701466, acc.: 50.00%] [G loss: 0.718329]\n",
      "epoch:23 step:18549 [D loss: 0.709711, acc.: 52.34%] [G loss: 0.831596]\n",
      "epoch:23 step:18550 [D loss: 0.664458, acc.: 59.38%] [G loss: 0.833506]\n",
      "epoch:23 step:18551 [D loss: 0.668514, acc.: 53.91%] [G loss: 0.780126]\n",
      "epoch:23 step:18552 [D loss: 0.649177, acc.: 71.88%] [G loss: 0.739085]\n",
      "epoch:23 step:18553 [D loss: 0.700543, acc.: 52.34%] [G loss: 0.759170]\n",
      "epoch:23 step:18554 [D loss: 0.675332, acc.: 56.25%] [G loss: 0.744758]\n",
      "epoch:23 step:18555 [D loss: 0.694880, acc.: 52.34%] [G loss: 0.788947]\n",
      "epoch:23 step:18556 [D loss: 0.705735, acc.: 50.00%] [G loss: 0.757099]\n",
      "epoch:23 step:18557 [D loss: 0.684319, acc.: 54.69%] [G loss: 0.715588]\n",
      "epoch:23 step:18558 [D loss: 0.653865, acc.: 64.06%] [G loss: 0.746943]\n",
      "epoch:23 step:18559 [D loss: 0.703438, acc.: 50.00%] [G loss: 0.755817]\n",
      "epoch:23 step:18560 [D loss: 0.717757, acc.: 48.44%] [G loss: 0.772752]\n",
      "epoch:23 step:18561 [D loss: 0.687892, acc.: 55.47%] [G loss: 0.765640]\n",
      "epoch:23 step:18562 [D loss: 0.650091, acc.: 62.50%] [G loss: 0.781882]\n",
      "epoch:23 step:18563 [D loss: 0.699968, acc.: 57.03%] [G loss: 0.781069]\n",
      "epoch:23 step:18564 [D loss: 0.672291, acc.: 63.28%] [G loss: 0.755753]\n",
      "epoch:23 step:18565 [D loss: 0.662066, acc.: 61.72%] [G loss: 0.799320]\n",
      "epoch:23 step:18566 [D loss: 0.693823, acc.: 52.34%] [G loss: 0.749531]\n",
      "epoch:23 step:18567 [D loss: 0.711535, acc.: 47.66%] [G loss: 0.760802]\n",
      "epoch:23 step:18568 [D loss: 0.670611, acc.: 60.16%] [G loss: 0.806785]\n",
      "epoch:23 step:18569 [D loss: 0.682968, acc.: 55.47%] [G loss: 0.727571]\n",
      "epoch:23 step:18570 [D loss: 0.678375, acc.: 57.81%] [G loss: 0.724387]\n",
      "epoch:23 step:18571 [D loss: 0.634528, acc.: 67.19%] [G loss: 0.859879]\n",
      "epoch:23 step:18572 [D loss: 0.719804, acc.: 47.66%] [G loss: 0.748211]\n",
      "epoch:23 step:18573 [D loss: 0.672762, acc.: 61.72%] [G loss: 0.777831]\n",
      "epoch:23 step:18574 [D loss: 0.749293, acc.: 40.62%] [G loss: 0.754341]\n",
      "epoch:23 step:18575 [D loss: 0.702377, acc.: 51.56%] [G loss: 0.792118]\n",
      "epoch:23 step:18576 [D loss: 0.724888, acc.: 45.31%] [G loss: 0.802054]\n",
      "epoch:23 step:18577 [D loss: 0.687094, acc.: 57.81%] [G loss: 0.767238]\n",
      "epoch:23 step:18578 [D loss: 0.706329, acc.: 50.00%] [G loss: 0.717386]\n",
      "epoch:23 step:18579 [D loss: 0.702596, acc.: 49.22%] [G loss: 0.760120]\n",
      "epoch:23 step:18580 [D loss: 0.668939, acc.: 56.25%] [G loss: 0.734470]\n",
      "epoch:23 step:18581 [D loss: 0.619841, acc.: 71.88%] [G loss: 0.751651]\n",
      "epoch:23 step:18582 [D loss: 0.718350, acc.: 43.75%] [G loss: 0.769758]\n",
      "epoch:23 step:18583 [D loss: 0.659944, acc.: 63.28%] [G loss: 0.770154]\n",
      "epoch:23 step:18584 [D loss: 0.660778, acc.: 63.28%] [G loss: 0.794027]\n",
      "epoch:23 step:18585 [D loss: 0.680827, acc.: 57.03%] [G loss: 0.841761]\n",
      "epoch:23 step:18586 [D loss: 0.703240, acc.: 50.78%] [G loss: 0.794319]\n",
      "epoch:23 step:18587 [D loss: 0.682002, acc.: 53.91%] [G loss: 0.687806]\n",
      "epoch:23 step:18588 [D loss: 0.715433, acc.: 44.53%] [G loss: 0.745262]\n",
      "epoch:23 step:18589 [D loss: 0.755249, acc.: 34.38%] [G loss: 0.683698]\n",
      "epoch:23 step:18590 [D loss: 0.722153, acc.: 52.34%] [G loss: 0.658455]\n",
      "epoch:23 step:18591 [D loss: 0.642987, acc.: 67.19%] [G loss: 0.808901]\n",
      "epoch:23 step:18592 [D loss: 0.697848, acc.: 53.12%] [G loss: 0.847803]\n",
      "epoch:23 step:18593 [D loss: 0.664571, acc.: 57.81%] [G loss: 0.784578]\n",
      "epoch:23 step:18594 [D loss: 0.669825, acc.: 55.47%] [G loss: 0.759755]\n",
      "epoch:23 step:18595 [D loss: 0.629570, acc.: 71.88%] [G loss: 0.737696]\n",
      "epoch:23 step:18596 [D loss: 0.711643, acc.: 46.88%] [G loss: 0.833595]\n",
      "epoch:23 step:18597 [D loss: 0.638585, acc.: 67.97%] [G loss: 0.762135]\n",
      "epoch:23 step:18598 [D loss: 0.693994, acc.: 56.25%] [G loss: 0.778382]\n",
      "epoch:23 step:18599 [D loss: 0.722631, acc.: 46.09%] [G loss: 0.712958]\n",
      "epoch:23 step:18600 [D loss: 0.687771, acc.: 58.59%] [G loss: 0.779281]\n",
      "epoch:23 step:18601 [D loss: 0.681294, acc.: 52.34%] [G loss: 0.723597]\n",
      "epoch:23 step:18602 [D loss: 0.653993, acc.: 60.94%] [G loss: 0.721105]\n",
      "epoch:23 step:18603 [D loss: 0.776078, acc.: 38.28%] [G loss: 0.650274]\n",
      "epoch:23 step:18604 [D loss: 0.715764, acc.: 55.47%] [G loss: 0.713103]\n",
      "epoch:23 step:18605 [D loss: 0.714196, acc.: 47.66%] [G loss: 0.667153]\n",
      "epoch:23 step:18606 [D loss: 0.718540, acc.: 46.88%] [G loss: 0.780137]\n",
      "epoch:23 step:18607 [D loss: 0.697501, acc.: 52.34%] [G loss: 0.777569]\n",
      "epoch:23 step:18608 [D loss: 0.698992, acc.: 53.12%] [G loss: 0.848446]\n",
      "epoch:23 step:18609 [D loss: 0.717395, acc.: 47.66%] [G loss: 0.773298]\n",
      "epoch:23 step:18610 [D loss: 0.715979, acc.: 45.31%] [G loss: 0.714152]\n",
      "epoch:23 step:18611 [D loss: 0.734432, acc.: 39.06%] [G loss: 0.693718]\n",
      "epoch:23 step:18612 [D loss: 0.676129, acc.: 58.59%] [G loss: 0.719564]\n",
      "epoch:23 step:18613 [D loss: 0.686790, acc.: 58.59%] [G loss: 0.758773]\n",
      "epoch:23 step:18614 [D loss: 0.703139, acc.: 56.25%] [G loss: 0.753137]\n",
      "epoch:23 step:18615 [D loss: 0.677801, acc.: 57.03%] [G loss: 0.752316]\n",
      "epoch:23 step:18616 [D loss: 0.692133, acc.: 53.91%] [G loss: 0.779493]\n",
      "epoch:23 step:18617 [D loss: 0.663064, acc.: 58.59%] [G loss: 0.786865]\n",
      "epoch:23 step:18618 [D loss: 0.652348, acc.: 62.50%] [G loss: 0.756629]\n",
      "epoch:23 step:18619 [D loss: 0.694994, acc.: 51.56%] [G loss: 0.769136]\n",
      "epoch:23 step:18620 [D loss: 0.693412, acc.: 57.03%] [G loss: 0.766273]\n",
      "epoch:23 step:18621 [D loss: 0.724683, acc.: 46.88%] [G loss: 0.736108]\n",
      "epoch:23 step:18622 [D loss: 0.645889, acc.: 62.50%] [G loss: 0.784405]\n",
      "epoch:23 step:18623 [D loss: 0.686159, acc.: 53.12%] [G loss: 0.749722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18624 [D loss: 0.701980, acc.: 46.88%] [G loss: 0.811262]\n",
      "epoch:23 step:18625 [D loss: 0.641053, acc.: 67.97%] [G loss: 0.816548]\n",
      "epoch:23 step:18626 [D loss: 0.681391, acc.: 54.69%] [G loss: 0.792635]\n",
      "epoch:23 step:18627 [D loss: 0.659840, acc.: 59.38%] [G loss: 0.802206]\n",
      "epoch:23 step:18628 [D loss: 0.656566, acc.: 67.19%] [G loss: 0.725761]\n",
      "epoch:23 step:18629 [D loss: 0.663316, acc.: 63.28%] [G loss: 0.761491]\n",
      "epoch:23 step:18630 [D loss: 0.721241, acc.: 44.53%] [G loss: 0.662533]\n",
      "epoch:23 step:18631 [D loss: 0.722904, acc.: 46.09%] [G loss: 0.768612]\n",
      "epoch:23 step:18632 [D loss: 0.681484, acc.: 53.91%] [G loss: 0.786867]\n",
      "epoch:23 step:18633 [D loss: 0.698539, acc.: 54.69%] [G loss: 0.759235]\n",
      "epoch:23 step:18634 [D loss: 0.726783, acc.: 37.50%] [G loss: 0.698193]\n",
      "epoch:23 step:18635 [D loss: 0.710110, acc.: 50.00%] [G loss: 0.786810]\n",
      "epoch:23 step:18636 [D loss: 0.682573, acc.: 57.81%] [G loss: 0.780020]\n",
      "epoch:23 step:18637 [D loss: 0.687378, acc.: 52.34%] [G loss: 0.850217]\n",
      "epoch:23 step:18638 [D loss: 0.727191, acc.: 41.41%] [G loss: 0.778540]\n",
      "epoch:23 step:18639 [D loss: 0.718613, acc.: 50.00%] [G loss: 0.791900]\n",
      "epoch:23 step:18640 [D loss: 0.666897, acc.: 57.03%] [G loss: 0.756372]\n",
      "epoch:23 step:18641 [D loss: 0.720847, acc.: 43.75%] [G loss: 0.747405]\n",
      "epoch:23 step:18642 [D loss: 0.677345, acc.: 60.16%] [G loss: 0.808116]\n",
      "epoch:23 step:18643 [D loss: 0.708242, acc.: 49.22%] [G loss: 0.757636]\n",
      "epoch:23 step:18644 [D loss: 0.681645, acc.: 55.47%] [G loss: 0.824151]\n",
      "epoch:23 step:18645 [D loss: 0.699819, acc.: 52.34%] [G loss: 0.863466]\n",
      "epoch:23 step:18646 [D loss: 0.616006, acc.: 71.09%] [G loss: 0.761577]\n",
      "epoch:23 step:18647 [D loss: 0.726245, acc.: 46.88%] [G loss: 0.771600]\n",
      "epoch:23 step:18648 [D loss: 0.676942, acc.: 54.69%] [G loss: 0.791856]\n",
      "epoch:23 step:18649 [D loss: 0.688481, acc.: 60.16%] [G loss: 0.757161]\n",
      "epoch:23 step:18650 [D loss: 0.654875, acc.: 68.75%] [G loss: 0.782182]\n",
      "epoch:23 step:18651 [D loss: 0.695523, acc.: 52.34%] [G loss: 0.760278]\n",
      "epoch:23 step:18652 [D loss: 0.716178, acc.: 46.09%] [G loss: 0.787949]\n",
      "epoch:23 step:18653 [D loss: 0.649640, acc.: 67.97%] [G loss: 0.770481]\n",
      "epoch:23 step:18654 [D loss: 0.645710, acc.: 64.84%] [G loss: 0.755235]\n",
      "epoch:23 step:18655 [D loss: 0.793868, acc.: 30.47%] [G loss: 0.741850]\n",
      "epoch:23 step:18656 [D loss: 0.674577, acc.: 54.69%] [G loss: 0.673164]\n",
      "epoch:23 step:18657 [D loss: 0.723686, acc.: 39.84%] [G loss: 0.718390]\n",
      "epoch:23 step:18658 [D loss: 0.701920, acc.: 46.09%] [G loss: 0.756603]\n",
      "epoch:23 step:18659 [D loss: 0.744359, acc.: 46.09%] [G loss: 0.764133]\n",
      "epoch:23 step:18660 [D loss: 0.761459, acc.: 40.62%] [G loss: 0.704435]\n",
      "epoch:23 step:18661 [D loss: 0.662599, acc.: 60.94%] [G loss: 0.716422]\n",
      "epoch:23 step:18662 [D loss: 0.632273, acc.: 69.53%] [G loss: 0.742368]\n",
      "epoch:23 step:18663 [D loss: 0.689112, acc.: 54.69%] [G loss: 0.732905]\n",
      "epoch:23 step:18664 [D loss: 0.704406, acc.: 45.31%] [G loss: 0.709054]\n",
      "epoch:23 step:18665 [D loss: 0.654714, acc.: 61.72%] [G loss: 0.707325]\n",
      "epoch:23 step:18666 [D loss: 0.732969, acc.: 47.66%] [G loss: 0.752505]\n",
      "epoch:23 step:18667 [D loss: 0.658799, acc.: 64.84%] [G loss: 0.813906]\n",
      "epoch:23 step:18668 [D loss: 0.727903, acc.: 44.53%] [G loss: 0.788036]\n",
      "epoch:23 step:18669 [D loss: 0.718996, acc.: 49.22%] [G loss: 0.780961]\n",
      "epoch:23 step:18670 [D loss: 0.697119, acc.: 46.88%] [G loss: 0.879876]\n",
      "epoch:23 step:18671 [D loss: 0.654157, acc.: 66.41%] [G loss: 0.828017]\n",
      "epoch:23 step:18672 [D loss: 0.697813, acc.: 50.00%] [G loss: 0.691422]\n",
      "epoch:23 step:18673 [D loss: 0.727461, acc.: 47.66%] [G loss: 0.739826]\n",
      "epoch:23 step:18674 [D loss: 0.653987, acc.: 64.06%] [G loss: 0.801772]\n",
      "epoch:23 step:18675 [D loss: 0.678095, acc.: 57.03%] [G loss: 0.814169]\n",
      "epoch:23 step:18676 [D loss: 0.651560, acc.: 67.19%] [G loss: 0.759952]\n",
      "epoch:23 step:18677 [D loss: 0.669611, acc.: 60.94%] [G loss: 0.783976]\n",
      "epoch:23 step:18678 [D loss: 0.645185, acc.: 69.53%] [G loss: 0.803055]\n",
      "epoch:23 step:18679 [D loss: 0.681207, acc.: 60.16%] [G loss: 0.752850]\n",
      "epoch:23 step:18680 [D loss: 0.683912, acc.: 56.25%] [G loss: 0.700107]\n",
      "epoch:23 step:18681 [D loss: 0.657615, acc.: 66.41%] [G loss: 0.718723]\n",
      "epoch:23 step:18682 [D loss: 0.686738, acc.: 53.91%] [G loss: 0.678220]\n",
      "epoch:23 step:18683 [D loss: 0.689073, acc.: 53.91%] [G loss: 0.812287]\n",
      "epoch:23 step:18684 [D loss: 0.664792, acc.: 62.50%] [G loss: 0.811345]\n",
      "epoch:23 step:18685 [D loss: 0.672535, acc.: 55.47%] [G loss: 0.713707]\n",
      "epoch:23 step:18686 [D loss: 0.771202, acc.: 33.59%] [G loss: 0.744895]\n",
      "epoch:23 step:18687 [D loss: 0.663696, acc.: 57.81%] [G loss: 0.697737]\n",
      "epoch:23 step:18688 [D loss: 0.725802, acc.: 41.41%] [G loss: 0.796625]\n",
      "epoch:23 step:18689 [D loss: 0.668912, acc.: 60.16%] [G loss: 0.788409]\n",
      "epoch:23 step:18690 [D loss: 0.701856, acc.: 50.78%] [G loss: 0.745603]\n",
      "epoch:23 step:18691 [D loss: 0.692531, acc.: 53.12%] [G loss: 0.812273]\n",
      "epoch:23 step:18692 [D loss: 0.744825, acc.: 36.72%] [G loss: 0.783276]\n",
      "epoch:23 step:18693 [D loss: 0.724397, acc.: 41.41%] [G loss: 0.773954]\n",
      "epoch:23 step:18694 [D loss: 0.685098, acc.: 55.47%] [G loss: 0.823263]\n",
      "epoch:23 step:18695 [D loss: 0.690736, acc.: 54.69%] [G loss: 0.768254]\n",
      "epoch:23 step:18696 [D loss: 0.696318, acc.: 50.78%] [G loss: 0.727800]\n",
      "epoch:23 step:18697 [D loss: 0.670582, acc.: 63.28%] [G loss: 0.802419]\n",
      "epoch:23 step:18698 [D loss: 0.707207, acc.: 46.09%] [G loss: 0.735511]\n",
      "epoch:23 step:18699 [D loss: 0.651159, acc.: 63.28%] [G loss: 0.858794]\n",
      "epoch:23 step:18700 [D loss: 0.719373, acc.: 46.88%] [G loss: 0.819149]\n",
      "epoch:23 step:18701 [D loss: 0.693900, acc.: 48.44%] [G loss: 0.732641]\n",
      "epoch:23 step:18702 [D loss: 0.725545, acc.: 44.53%] [G loss: 0.774510]\n",
      "epoch:23 step:18703 [D loss: 0.730952, acc.: 43.75%] [G loss: 0.788320]\n",
      "epoch:23 step:18704 [D loss: 0.703362, acc.: 46.09%] [G loss: 0.736207]\n",
      "epoch:23 step:18705 [D loss: 0.733930, acc.: 39.06%] [G loss: 0.710572]\n",
      "epoch:23 step:18706 [D loss: 0.712671, acc.: 47.66%] [G loss: 0.798912]\n",
      "epoch:23 step:18707 [D loss: 0.690406, acc.: 51.56%] [G loss: 0.838767]\n",
      "epoch:23 step:18708 [D loss: 0.680139, acc.: 62.50%] [G loss: 0.771359]\n",
      "epoch:23 step:18709 [D loss: 0.650161, acc.: 64.06%] [G loss: 0.815369]\n",
      "epoch:23 step:18710 [D loss: 0.694868, acc.: 53.12%] [G loss: 0.730929]\n",
      "epoch:23 step:18711 [D loss: 0.695430, acc.: 57.81%] [G loss: 0.795494]\n",
      "epoch:23 step:18712 [D loss: 0.688845, acc.: 54.69%] [G loss: 0.782640]\n",
      "epoch:23 step:18713 [D loss: 0.656352, acc.: 63.28%] [G loss: 0.733700]\n",
      "epoch:23 step:18714 [D loss: 0.632110, acc.: 68.75%] [G loss: 0.769138]\n",
      "epoch:23 step:18715 [D loss: 0.681590, acc.: 53.91%] [G loss: 0.741672]\n",
      "epoch:23 step:18716 [D loss: 0.710582, acc.: 45.31%] [G loss: 0.751073]\n",
      "epoch:23 step:18717 [D loss: 0.717881, acc.: 48.44%] [G loss: 0.766035]\n",
      "epoch:23 step:18718 [D loss: 0.694077, acc.: 56.25%] [G loss: 0.822730]\n",
      "epoch:23 step:18719 [D loss: 0.657004, acc.: 60.16%] [G loss: 0.826510]\n",
      "epoch:23 step:18720 [D loss: 0.690073, acc.: 58.59%] [G loss: 0.753178]\n",
      "epoch:23 step:18721 [D loss: 0.672555, acc.: 57.03%] [G loss: 0.764630]\n",
      "epoch:23 step:18722 [D loss: 0.690491, acc.: 49.22%] [G loss: 0.800228]\n",
      "epoch:23 step:18723 [D loss: 0.730096, acc.: 47.66%] [G loss: 0.713582]\n",
      "epoch:23 step:18724 [D loss: 0.667549, acc.: 60.94%] [G loss: 0.731469]\n",
      "epoch:23 step:18725 [D loss: 0.712812, acc.: 46.88%] [G loss: 0.779250]\n",
      "epoch:23 step:18726 [D loss: 0.719682, acc.: 48.44%] [G loss: 0.735300]\n",
      "epoch:23 step:18727 [D loss: 0.684115, acc.: 56.25%] [G loss: 0.790937]\n",
      "epoch:23 step:18728 [D loss: 0.740923, acc.: 39.06%] [G loss: 0.737425]\n",
      "epoch:23 step:18729 [D loss: 0.749385, acc.: 38.28%] [G loss: 0.794385]\n",
      "epoch:23 step:18730 [D loss: 0.704377, acc.: 52.34%] [G loss: 0.755056]\n",
      "epoch:23 step:18731 [D loss: 0.689206, acc.: 53.91%] [G loss: 0.775580]\n",
      "epoch:23 step:18732 [D loss: 0.718239, acc.: 48.44%] [G loss: 0.756136]\n",
      "epoch:23 step:18733 [D loss: 0.662522, acc.: 56.25%] [G loss: 0.759595]\n",
      "epoch:23 step:18734 [D loss: 0.703118, acc.: 47.66%] [G loss: 0.764883]\n",
      "epoch:23 step:18735 [D loss: 0.661292, acc.: 60.94%] [G loss: 0.774411]\n",
      "epoch:23 step:18736 [D loss: 0.706321, acc.: 48.44%] [G loss: 0.714574]\n",
      "epoch:23 step:18737 [D loss: 0.651270, acc.: 64.84%] [G loss: 0.802521]\n",
      "epoch:23 step:18738 [D loss: 0.699130, acc.: 52.34%] [G loss: 0.746726]\n",
      "epoch:23 step:18739 [D loss: 0.695158, acc.: 50.00%] [G loss: 0.773973]\n",
      "epoch:23 step:18740 [D loss: 0.722409, acc.: 47.66%] [G loss: 0.723608]\n",
      "epoch:23 step:18741 [D loss: 0.690008, acc.: 53.12%] [G loss: 0.748234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18742 [D loss: 0.688750, acc.: 53.12%] [G loss: 0.715104]\n",
      "epoch:23 step:18743 [D loss: 0.715394, acc.: 49.22%] [G loss: 0.715431]\n",
      "epoch:23 step:18744 [D loss: 0.664384, acc.: 60.16%] [G loss: 0.701439]\n",
      "epoch:24 step:18745 [D loss: 0.677975, acc.: 57.81%] [G loss: 0.748420]\n",
      "epoch:24 step:18746 [D loss: 0.647893, acc.: 64.84%] [G loss: 0.757107]\n",
      "epoch:24 step:18747 [D loss: 0.706113, acc.: 50.00%] [G loss: 0.755895]\n",
      "epoch:24 step:18748 [D loss: 0.720550, acc.: 42.19%] [G loss: 0.841495]\n",
      "epoch:24 step:18749 [D loss: 0.689602, acc.: 55.47%] [G loss: 0.698272]\n",
      "epoch:24 step:18750 [D loss: 0.659340, acc.: 60.94%] [G loss: 0.738206]\n",
      "epoch:24 step:18751 [D loss: 0.702577, acc.: 47.66%] [G loss: 0.794166]\n",
      "epoch:24 step:18752 [D loss: 0.724985, acc.: 42.19%] [G loss: 0.791810]\n",
      "epoch:24 step:18753 [D loss: 0.669124, acc.: 67.19%] [G loss: 0.794481]\n",
      "epoch:24 step:18754 [D loss: 0.681436, acc.: 54.69%] [G loss: 0.718160]\n",
      "epoch:24 step:18755 [D loss: 0.712395, acc.: 47.66%] [G loss: 0.754189]\n",
      "epoch:24 step:18756 [D loss: 0.661496, acc.: 60.94%] [G loss: 0.845561]\n",
      "epoch:24 step:18757 [D loss: 0.661979, acc.: 64.84%] [G loss: 0.808004]\n",
      "epoch:24 step:18758 [D loss: 0.669077, acc.: 57.81%] [G loss: 0.766179]\n",
      "epoch:24 step:18759 [D loss: 0.718477, acc.: 44.53%] [G loss: 0.806497]\n",
      "epoch:24 step:18760 [D loss: 0.688680, acc.: 52.34%] [G loss: 0.801390]\n",
      "epoch:24 step:18761 [D loss: 0.712452, acc.: 44.53%] [G loss: 0.722039]\n",
      "epoch:24 step:18762 [D loss: 0.710377, acc.: 48.44%] [G loss: 0.730182]\n",
      "epoch:24 step:18763 [D loss: 0.635214, acc.: 69.53%] [G loss: 0.800896]\n",
      "epoch:24 step:18764 [D loss: 0.665821, acc.: 61.72%] [G loss: 0.771283]\n",
      "epoch:24 step:18765 [D loss: 0.719952, acc.: 42.19%] [G loss: 0.690393]\n",
      "epoch:24 step:18766 [D loss: 0.659225, acc.: 61.72%] [G loss: 0.751947]\n",
      "epoch:24 step:18767 [D loss: 0.688020, acc.: 53.91%] [G loss: 0.777833]\n",
      "epoch:24 step:18768 [D loss: 0.682325, acc.: 54.69%] [G loss: 0.793981]\n",
      "epoch:24 step:18769 [D loss: 0.705971, acc.: 53.12%] [G loss: 0.713587]\n",
      "epoch:24 step:18770 [D loss: 0.680538, acc.: 59.38%] [G loss: 0.783845]\n",
      "epoch:24 step:18771 [D loss: 0.708891, acc.: 49.22%] [G loss: 0.733895]\n",
      "epoch:24 step:18772 [D loss: 0.697241, acc.: 53.91%] [G loss: 0.785239]\n",
      "epoch:24 step:18773 [D loss: 0.737116, acc.: 43.75%] [G loss: 0.777055]\n",
      "epoch:24 step:18774 [D loss: 0.666165, acc.: 59.38%] [G loss: 0.818193]\n",
      "epoch:24 step:18775 [D loss: 0.705694, acc.: 52.34%] [G loss: 0.814751]\n",
      "epoch:24 step:18776 [D loss: 0.680076, acc.: 53.91%] [G loss: 0.809612]\n",
      "epoch:24 step:18777 [D loss: 0.686810, acc.: 46.88%] [G loss: 0.762591]\n",
      "epoch:24 step:18778 [D loss: 0.659691, acc.: 68.75%] [G loss: 0.771851]\n",
      "epoch:24 step:18779 [D loss: 0.681791, acc.: 57.03%] [G loss: 0.768868]\n",
      "epoch:24 step:18780 [D loss: 0.676252, acc.: 54.69%] [G loss: 0.800684]\n",
      "epoch:24 step:18781 [D loss: 0.677780, acc.: 53.91%] [G loss: 0.769607]\n",
      "epoch:24 step:18782 [D loss: 0.676058, acc.: 60.16%] [G loss: 0.812509]\n",
      "epoch:24 step:18783 [D loss: 0.683733, acc.: 52.34%] [G loss: 0.806036]\n",
      "epoch:24 step:18784 [D loss: 0.620678, acc.: 75.78%] [G loss: 0.793327]\n",
      "epoch:24 step:18785 [D loss: 0.695043, acc.: 53.12%] [G loss: 0.706639]\n",
      "epoch:24 step:18786 [D loss: 0.666036, acc.: 66.41%] [G loss: 0.776178]\n",
      "epoch:24 step:18787 [D loss: 0.729087, acc.: 42.97%] [G loss: 0.764164]\n",
      "epoch:24 step:18788 [D loss: 0.696421, acc.: 54.69%] [G loss: 0.767148]\n",
      "epoch:24 step:18789 [D loss: 0.677774, acc.: 60.16%] [G loss: 0.768200]\n",
      "epoch:24 step:18790 [D loss: 0.677751, acc.: 59.38%] [G loss: 0.764268]\n",
      "epoch:24 step:18791 [D loss: 0.722385, acc.: 51.56%] [G loss: 0.745077]\n",
      "epoch:24 step:18792 [D loss: 0.682984, acc.: 55.47%] [G loss: 0.774742]\n",
      "epoch:24 step:18793 [D loss: 0.698760, acc.: 50.78%] [G loss: 0.736494]\n",
      "epoch:24 step:18794 [D loss: 0.692705, acc.: 56.25%] [G loss: 0.752518]\n",
      "epoch:24 step:18795 [D loss: 0.685991, acc.: 53.12%] [G loss: 0.719282]\n",
      "epoch:24 step:18796 [D loss: 0.695325, acc.: 57.81%] [G loss: 0.715629]\n",
      "epoch:24 step:18797 [D loss: 0.709653, acc.: 50.00%] [G loss: 0.702808]\n",
      "epoch:24 step:18798 [D loss: 0.710728, acc.: 50.78%] [G loss: 0.742498]\n",
      "epoch:24 step:18799 [D loss: 0.710925, acc.: 46.88%] [G loss: 0.645924]\n",
      "epoch:24 step:18800 [D loss: 0.746060, acc.: 39.06%] [G loss: 0.752201]\n",
      "epoch:24 step:18801 [D loss: 0.695305, acc.: 48.44%] [G loss: 0.770593]\n",
      "epoch:24 step:18802 [D loss: 0.726380, acc.: 41.41%] [G loss: 0.702379]\n",
      "epoch:24 step:18803 [D loss: 0.719915, acc.: 47.66%] [G loss: 0.752538]\n",
      "epoch:24 step:18804 [D loss: 0.641633, acc.: 66.41%] [G loss: 0.808310]\n",
      "epoch:24 step:18805 [D loss: 0.669202, acc.: 56.25%] [G loss: 0.883371]\n",
      "epoch:24 step:18806 [D loss: 0.711749, acc.: 50.00%] [G loss: 0.783864]\n",
      "epoch:24 step:18807 [D loss: 0.765603, acc.: 33.59%] [G loss: 0.800568]\n",
      "epoch:24 step:18808 [D loss: 0.749106, acc.: 35.94%] [G loss: 0.797828]\n",
      "epoch:24 step:18809 [D loss: 0.646739, acc.: 59.38%] [G loss: 0.879161]\n",
      "epoch:24 step:18810 [D loss: 0.651512, acc.: 65.62%] [G loss: 0.830241]\n",
      "epoch:24 step:18811 [D loss: 0.667172, acc.: 59.38%] [G loss: 0.817932]\n",
      "epoch:24 step:18812 [D loss: 0.741450, acc.: 40.62%] [G loss: 0.733118]\n",
      "epoch:24 step:18813 [D loss: 0.673029, acc.: 57.81%] [G loss: 0.814236]\n",
      "epoch:24 step:18814 [D loss: 0.750475, acc.: 39.84%] [G loss: 0.784568]\n",
      "epoch:24 step:18815 [D loss: 0.741092, acc.: 47.66%] [G loss: 0.697114]\n",
      "epoch:24 step:18816 [D loss: 0.710474, acc.: 47.66%] [G loss: 0.759332]\n",
      "epoch:24 step:18817 [D loss: 0.704861, acc.: 46.88%] [G loss: 0.734816]\n",
      "epoch:24 step:18818 [D loss: 0.635140, acc.: 67.97%] [G loss: 0.756472]\n",
      "epoch:24 step:18819 [D loss: 0.682674, acc.: 52.34%] [G loss: 0.701355]\n",
      "epoch:24 step:18820 [D loss: 0.691115, acc.: 47.66%] [G loss: 0.746475]\n",
      "epoch:24 step:18821 [D loss: 0.654943, acc.: 58.59%] [G loss: 0.809395]\n",
      "epoch:24 step:18822 [D loss: 0.725844, acc.: 41.41%] [G loss: 0.726029]\n",
      "epoch:24 step:18823 [D loss: 0.660087, acc.: 60.16%] [G loss: 0.764363]\n",
      "epoch:24 step:18824 [D loss: 0.674535, acc.: 54.69%] [G loss: 0.791698]\n",
      "epoch:24 step:18825 [D loss: 0.688116, acc.: 56.25%] [G loss: 0.814142]\n",
      "epoch:24 step:18826 [D loss: 0.682017, acc.: 52.34%] [G loss: 0.786310]\n",
      "epoch:24 step:18827 [D loss: 0.684345, acc.: 56.25%] [G loss: 0.805678]\n",
      "epoch:24 step:18828 [D loss: 0.711916, acc.: 47.66%] [G loss: 0.773983]\n",
      "epoch:24 step:18829 [D loss: 0.696512, acc.: 54.69%] [G loss: 0.776476]\n",
      "epoch:24 step:18830 [D loss: 0.675643, acc.: 52.34%] [G loss: 0.726367]\n",
      "epoch:24 step:18831 [D loss: 0.692281, acc.: 50.00%] [G loss: 0.773902]\n",
      "epoch:24 step:18832 [D loss: 0.706207, acc.: 49.22%] [G loss: 0.702036]\n",
      "epoch:24 step:18833 [D loss: 0.662435, acc.: 67.97%] [G loss: 0.771358]\n",
      "epoch:24 step:18834 [D loss: 0.716046, acc.: 53.91%] [G loss: 0.762278]\n",
      "epoch:24 step:18835 [D loss: 0.696765, acc.: 53.12%] [G loss: 0.736726]\n",
      "epoch:24 step:18836 [D loss: 0.699876, acc.: 50.78%] [G loss: 0.692168]\n",
      "epoch:24 step:18837 [D loss: 0.683449, acc.: 53.91%] [G loss: 0.774553]\n",
      "epoch:24 step:18838 [D loss: 0.651465, acc.: 60.16%] [G loss: 0.786218]\n",
      "epoch:24 step:18839 [D loss: 0.746243, acc.: 42.19%] [G loss: 0.776744]\n",
      "epoch:24 step:18840 [D loss: 0.661343, acc.: 67.19%] [G loss: 0.808496]\n",
      "epoch:24 step:18841 [D loss: 0.708663, acc.: 51.56%] [G loss: 0.781064]\n",
      "epoch:24 step:18842 [D loss: 0.685546, acc.: 53.12%] [G loss: 0.885762]\n",
      "epoch:24 step:18843 [D loss: 0.678279, acc.: 60.16%] [G loss: 0.783042]\n",
      "epoch:24 step:18844 [D loss: 0.679509, acc.: 56.25%] [G loss: 0.828933]\n",
      "epoch:24 step:18845 [D loss: 0.689739, acc.: 57.03%] [G loss: 0.800198]\n",
      "epoch:24 step:18846 [D loss: 0.668736, acc.: 60.16%] [G loss: 0.825886]\n",
      "epoch:24 step:18847 [D loss: 0.696285, acc.: 53.12%] [G loss: 0.863241]\n",
      "epoch:24 step:18848 [D loss: 0.651175, acc.: 64.84%] [G loss: 0.767947]\n",
      "epoch:24 step:18849 [D loss: 0.690562, acc.: 58.59%] [G loss: 0.743258]\n",
      "epoch:24 step:18850 [D loss: 0.680644, acc.: 62.50%] [G loss: 0.718260]\n",
      "epoch:24 step:18851 [D loss: 0.673566, acc.: 58.59%] [G loss: 0.755173]\n",
      "epoch:24 step:18852 [D loss: 0.753182, acc.: 34.38%] [G loss: 0.748157]\n",
      "epoch:24 step:18853 [D loss: 0.736686, acc.: 44.53%] [G loss: 0.689194]\n",
      "epoch:24 step:18854 [D loss: 0.683812, acc.: 57.03%] [G loss: 0.697407]\n",
      "epoch:24 step:18855 [D loss: 0.681156, acc.: 55.47%] [G loss: 0.726986]\n",
      "epoch:24 step:18856 [D loss: 0.669035, acc.: 66.41%] [G loss: 0.762084]\n",
      "epoch:24 step:18857 [D loss: 0.680433, acc.: 53.12%] [G loss: 0.732901]\n",
      "epoch:24 step:18858 [D loss: 0.667336, acc.: 61.72%] [G loss: 0.722607]\n",
      "epoch:24 step:18859 [D loss: 0.693725, acc.: 54.69%] [G loss: 0.680065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18860 [D loss: 0.733267, acc.: 37.50%] [G loss: 0.717119]\n",
      "epoch:24 step:18861 [D loss: 0.698240, acc.: 53.91%] [G loss: 0.719949]\n",
      "epoch:24 step:18862 [D loss: 0.673637, acc.: 58.59%] [G loss: 0.738135]\n",
      "epoch:24 step:18863 [D loss: 0.670795, acc.: 60.94%] [G loss: 0.750847]\n",
      "epoch:24 step:18864 [D loss: 0.704460, acc.: 50.78%] [G loss: 0.742714]\n",
      "epoch:24 step:18865 [D loss: 0.698671, acc.: 50.78%] [G loss: 0.755846]\n",
      "epoch:24 step:18866 [D loss: 0.662977, acc.: 60.16%] [G loss: 0.730960]\n",
      "epoch:24 step:18867 [D loss: 0.743425, acc.: 38.28%] [G loss: 0.701441]\n",
      "epoch:24 step:18868 [D loss: 0.726964, acc.: 42.19%] [G loss: 0.720499]\n",
      "epoch:24 step:18869 [D loss: 0.745641, acc.: 32.03%] [G loss: 0.763232]\n",
      "epoch:24 step:18870 [D loss: 0.753120, acc.: 38.28%] [G loss: 0.710314]\n",
      "epoch:24 step:18871 [D loss: 0.679700, acc.: 55.47%] [G loss: 0.762704]\n",
      "epoch:24 step:18872 [D loss: 0.712687, acc.: 45.31%] [G loss: 0.810323]\n",
      "epoch:24 step:18873 [D loss: 0.630756, acc.: 66.41%] [G loss: 0.843962]\n",
      "epoch:24 step:18874 [D loss: 0.663819, acc.: 60.16%] [G loss: 0.776602]\n",
      "epoch:24 step:18875 [D loss: 0.647423, acc.: 67.19%] [G loss: 0.800114]\n",
      "epoch:24 step:18876 [D loss: 0.683386, acc.: 53.91%] [G loss: 0.719362]\n",
      "epoch:24 step:18877 [D loss: 0.661337, acc.: 60.94%] [G loss: 0.805310]\n",
      "epoch:24 step:18878 [D loss: 0.716683, acc.: 47.66%] [G loss: 0.818691]\n",
      "epoch:24 step:18879 [D loss: 0.704204, acc.: 53.12%] [G loss: 0.791946]\n",
      "epoch:24 step:18880 [D loss: 0.681701, acc.: 53.12%] [G loss: 0.770028]\n",
      "epoch:24 step:18881 [D loss: 0.705626, acc.: 49.22%] [G loss: 0.747360]\n",
      "epoch:24 step:18882 [D loss: 0.692805, acc.: 55.47%] [G loss: 0.771561]\n",
      "epoch:24 step:18883 [D loss: 0.691314, acc.: 50.00%] [G loss: 0.706843]\n",
      "epoch:24 step:18884 [D loss: 0.680622, acc.: 56.25%] [G loss: 0.762534]\n",
      "epoch:24 step:18885 [D loss: 0.657226, acc.: 62.50%] [G loss: 0.785984]\n",
      "epoch:24 step:18886 [D loss: 0.657138, acc.: 60.16%] [G loss: 0.808219]\n",
      "epoch:24 step:18887 [D loss: 0.749714, acc.: 46.09%] [G loss: 0.708217]\n",
      "epoch:24 step:18888 [D loss: 0.700543, acc.: 49.22%] [G loss: 0.755322]\n",
      "epoch:24 step:18889 [D loss: 0.684642, acc.: 53.12%] [G loss: 0.752679]\n",
      "epoch:24 step:18890 [D loss: 0.668276, acc.: 59.38%] [G loss: 0.812724]\n",
      "epoch:24 step:18891 [D loss: 0.688869, acc.: 54.69%] [G loss: 0.844572]\n",
      "epoch:24 step:18892 [D loss: 0.684554, acc.: 57.81%] [G loss: 0.766333]\n",
      "epoch:24 step:18893 [D loss: 0.671771, acc.: 56.25%] [G loss: 0.729387]\n",
      "epoch:24 step:18894 [D loss: 0.699269, acc.: 49.22%] [G loss: 0.765901]\n",
      "epoch:24 step:18895 [D loss: 0.719042, acc.: 48.44%] [G loss: 0.752314]\n",
      "epoch:24 step:18896 [D loss: 0.722651, acc.: 46.88%] [G loss: 0.760402]\n",
      "epoch:24 step:18897 [D loss: 0.682025, acc.: 53.12%] [G loss: 0.772000]\n",
      "epoch:24 step:18898 [D loss: 0.674097, acc.: 58.59%] [G loss: 0.720823]\n",
      "epoch:24 step:18899 [D loss: 0.669170, acc.: 61.72%] [G loss: 0.815895]\n",
      "epoch:24 step:18900 [D loss: 0.685002, acc.: 53.12%] [G loss: 0.683301]\n",
      "epoch:24 step:18901 [D loss: 0.680615, acc.: 55.47%] [G loss: 0.782183]\n",
      "epoch:24 step:18902 [D loss: 0.645591, acc.: 68.75%] [G loss: 0.803327]\n",
      "epoch:24 step:18903 [D loss: 0.669567, acc.: 57.81%] [G loss: 0.813644]\n",
      "epoch:24 step:18904 [D loss: 0.670791, acc.: 64.06%] [G loss: 0.756760]\n",
      "epoch:24 step:18905 [D loss: 0.683997, acc.: 58.59%] [G loss: 0.698148]\n",
      "epoch:24 step:18906 [D loss: 0.679292, acc.: 53.12%] [G loss: 0.723019]\n",
      "epoch:24 step:18907 [D loss: 0.712303, acc.: 46.88%] [G loss: 0.674865]\n",
      "epoch:24 step:18908 [D loss: 0.658198, acc.: 60.94%] [G loss: 0.745626]\n",
      "epoch:24 step:18909 [D loss: 0.737887, acc.: 35.94%] [G loss: 0.698800]\n",
      "epoch:24 step:18910 [D loss: 0.708291, acc.: 46.09%] [G loss: 0.758945]\n",
      "epoch:24 step:18911 [D loss: 0.686819, acc.: 53.12%] [G loss: 0.732674]\n",
      "epoch:24 step:18912 [D loss: 0.682641, acc.: 58.59%] [G loss: 0.725087]\n",
      "epoch:24 step:18913 [D loss: 0.693804, acc.: 58.59%] [G loss: 0.767060]\n",
      "epoch:24 step:18914 [D loss: 0.701354, acc.: 48.44%] [G loss: 0.808088]\n",
      "epoch:24 step:18915 [D loss: 0.687690, acc.: 59.38%] [G loss: 0.792424]\n",
      "epoch:24 step:18916 [D loss: 0.661684, acc.: 60.16%] [G loss: 0.829703]\n",
      "epoch:24 step:18917 [D loss: 0.667480, acc.: 61.72%] [G loss: 0.782088]\n",
      "epoch:24 step:18918 [D loss: 0.686279, acc.: 47.66%] [G loss: 0.812126]\n",
      "epoch:24 step:18919 [D loss: 0.623587, acc.: 69.53%] [G loss: 0.834793]\n",
      "epoch:24 step:18920 [D loss: 0.690188, acc.: 53.12%] [G loss: 0.829463]\n",
      "epoch:24 step:18921 [D loss: 0.645589, acc.: 66.41%] [G loss: 0.801201]\n",
      "epoch:24 step:18922 [D loss: 0.745771, acc.: 39.06%] [G loss: 0.792764]\n",
      "epoch:24 step:18923 [D loss: 0.679547, acc.: 57.81%] [G loss: 0.771113]\n",
      "epoch:24 step:18924 [D loss: 0.637590, acc.: 70.31%] [G loss: 0.802453]\n",
      "epoch:24 step:18925 [D loss: 0.666755, acc.: 64.06%] [G loss: 0.725734]\n",
      "epoch:24 step:18926 [D loss: 0.697232, acc.: 51.56%] [G loss: 0.764320]\n",
      "epoch:24 step:18927 [D loss: 0.660959, acc.: 66.41%] [G loss: 0.756836]\n",
      "epoch:24 step:18928 [D loss: 0.693080, acc.: 53.12%] [G loss: 0.807224]\n",
      "epoch:24 step:18929 [D loss: 0.727936, acc.: 46.09%] [G loss: 0.775102]\n",
      "epoch:24 step:18930 [D loss: 0.711602, acc.: 47.66%] [G loss: 0.728337]\n",
      "epoch:24 step:18931 [D loss: 0.731861, acc.: 41.41%] [G loss: 0.764163]\n",
      "epoch:24 step:18932 [D loss: 0.715103, acc.: 44.53%] [G loss: 0.781040]\n",
      "epoch:24 step:18933 [D loss: 0.744460, acc.: 45.31%] [G loss: 0.742580]\n",
      "epoch:24 step:18934 [D loss: 0.699630, acc.: 53.12%] [G loss: 0.791678]\n",
      "epoch:24 step:18935 [D loss: 0.686369, acc.: 55.47%] [G loss: 0.717981]\n",
      "epoch:24 step:18936 [D loss: 0.738680, acc.: 44.53%] [G loss: 0.784459]\n",
      "epoch:24 step:18937 [D loss: 0.737949, acc.: 43.75%] [G loss: 0.731415]\n",
      "epoch:24 step:18938 [D loss: 0.717882, acc.: 47.66%] [G loss: 0.734961]\n",
      "epoch:24 step:18939 [D loss: 0.687592, acc.: 56.25%] [G loss: 0.753234]\n",
      "epoch:24 step:18940 [D loss: 0.672106, acc.: 57.81%] [G loss: 0.784921]\n",
      "epoch:24 step:18941 [D loss: 0.700378, acc.: 50.78%] [G loss: 0.809502]\n",
      "epoch:24 step:18942 [D loss: 0.672219, acc.: 57.03%] [G loss: 0.765585]\n",
      "epoch:24 step:18943 [D loss: 0.692414, acc.: 50.78%] [G loss: 0.778554]\n",
      "epoch:24 step:18944 [D loss: 0.694523, acc.: 52.34%] [G loss: 0.661639]\n",
      "epoch:24 step:18945 [D loss: 0.648693, acc.: 64.06%] [G loss: 0.794227]\n",
      "epoch:24 step:18946 [D loss: 0.705556, acc.: 50.00%] [G loss: 0.707713]\n",
      "epoch:24 step:18947 [D loss: 0.696886, acc.: 52.34%] [G loss: 0.783104]\n",
      "epoch:24 step:18948 [D loss: 0.689358, acc.: 54.69%] [G loss: 0.940623]\n",
      "epoch:24 step:18949 [D loss: 0.645303, acc.: 64.84%] [G loss: 0.826887]\n",
      "epoch:24 step:18950 [D loss: 0.736043, acc.: 42.19%] [G loss: 0.777775]\n",
      "epoch:24 step:18951 [D loss: 0.705507, acc.: 51.56%] [G loss: 0.694564]\n",
      "epoch:24 step:18952 [D loss: 0.702776, acc.: 50.00%] [G loss: 0.806559]\n",
      "epoch:24 step:18953 [D loss: 0.668428, acc.: 57.81%] [G loss: 0.729387]\n",
      "epoch:24 step:18954 [D loss: 0.718265, acc.: 45.31%] [G loss: 0.744570]\n",
      "epoch:24 step:18955 [D loss: 0.668647, acc.: 56.25%] [G loss: 0.707106]\n",
      "epoch:24 step:18956 [D loss: 0.743121, acc.: 37.50%] [G loss: 0.668805]\n",
      "epoch:24 step:18957 [D loss: 0.709521, acc.: 42.97%] [G loss: 0.734599]\n",
      "epoch:24 step:18958 [D loss: 0.668720, acc.: 61.72%] [G loss: 0.705480]\n",
      "epoch:24 step:18959 [D loss: 0.702135, acc.: 51.56%] [G loss: 0.736697]\n",
      "epoch:24 step:18960 [D loss: 0.686270, acc.: 50.00%] [G loss: 0.707461]\n",
      "epoch:24 step:18961 [D loss: 0.667861, acc.: 60.16%] [G loss: 0.744327]\n",
      "epoch:24 step:18962 [D loss: 0.685763, acc.: 52.34%] [G loss: 0.730835]\n",
      "epoch:24 step:18963 [D loss: 0.638646, acc.: 64.84%] [G loss: 0.821199]\n",
      "epoch:24 step:18964 [D loss: 0.678005, acc.: 58.59%] [G loss: 0.715752]\n",
      "epoch:24 step:18965 [D loss: 0.658620, acc.: 66.41%] [G loss: 0.783790]\n",
      "epoch:24 step:18966 [D loss: 0.644012, acc.: 65.62%] [G loss: 0.800753]\n",
      "epoch:24 step:18967 [D loss: 0.643138, acc.: 65.62%] [G loss: 0.786890]\n",
      "epoch:24 step:18968 [D loss: 0.689655, acc.: 50.78%] [G loss: 0.708693]\n",
      "epoch:24 step:18969 [D loss: 0.681438, acc.: 52.34%] [G loss: 0.722224]\n",
      "epoch:24 step:18970 [D loss: 0.653365, acc.: 64.06%] [G loss: 0.743753]\n",
      "epoch:24 step:18971 [D loss: 0.727296, acc.: 46.09%] [G loss: 0.749618]\n",
      "epoch:24 step:18972 [D loss: 0.712195, acc.: 50.78%] [G loss: 0.803295]\n",
      "epoch:24 step:18973 [D loss: 0.732545, acc.: 42.19%] [G loss: 0.847974]\n",
      "epoch:24 step:18974 [D loss: 0.689090, acc.: 50.00%] [G loss: 0.748708]\n",
      "epoch:24 step:18975 [D loss: 0.656813, acc.: 60.16%] [G loss: 0.795415]\n",
      "epoch:24 step:18976 [D loss: 0.678923, acc.: 57.81%] [G loss: 0.771301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18977 [D loss: 0.685313, acc.: 57.03%] [G loss: 0.724624]\n",
      "epoch:24 step:18978 [D loss: 0.715455, acc.: 46.09%] [G loss: 0.796803]\n",
      "epoch:24 step:18979 [D loss: 0.745645, acc.: 35.16%] [G loss: 0.682302]\n",
      "epoch:24 step:18980 [D loss: 0.644657, acc.: 61.72%] [G loss: 0.740999]\n",
      "epoch:24 step:18981 [D loss: 0.670638, acc.: 54.69%] [G loss: 0.771113]\n",
      "epoch:24 step:18982 [D loss: 0.655398, acc.: 65.62%] [G loss: 0.723468]\n",
      "epoch:24 step:18983 [D loss: 0.649945, acc.: 65.62%] [G loss: 0.666798]\n",
      "epoch:24 step:18984 [D loss: 0.711658, acc.: 48.44%] [G loss: 0.723479]\n",
      "epoch:24 step:18985 [D loss: 0.694942, acc.: 53.12%] [G loss: 0.692230]\n",
      "epoch:24 step:18986 [D loss: 0.683461, acc.: 51.56%] [G loss: 0.726427]\n",
      "epoch:24 step:18987 [D loss: 0.650865, acc.: 64.84%] [G loss: 0.769194]\n",
      "epoch:24 step:18988 [D loss: 0.709297, acc.: 51.56%] [G loss: 0.732709]\n",
      "epoch:24 step:18989 [D loss: 0.701289, acc.: 52.34%] [G loss: 0.750572]\n",
      "epoch:24 step:18990 [D loss: 0.739861, acc.: 45.31%] [G loss: 0.806842]\n",
      "epoch:24 step:18991 [D loss: 0.700179, acc.: 53.91%] [G loss: 0.761052]\n",
      "epoch:24 step:18992 [D loss: 0.629762, acc.: 69.53%] [G loss: 0.836998]\n",
      "epoch:24 step:18993 [D loss: 0.720739, acc.: 49.22%] [G loss: 0.697671]\n",
      "epoch:24 step:18994 [D loss: 0.666237, acc.: 61.72%] [G loss: 0.811995]\n",
      "epoch:24 step:18995 [D loss: 0.711134, acc.: 49.22%] [G loss: 0.752106]\n",
      "epoch:24 step:18996 [D loss: 0.699369, acc.: 58.59%] [G loss: 0.801511]\n",
      "epoch:24 step:18997 [D loss: 0.715001, acc.: 46.88%] [G loss: 0.717397]\n",
      "epoch:24 step:18998 [D loss: 0.719270, acc.: 50.78%] [G loss: 0.737186]\n",
      "epoch:24 step:18999 [D loss: 0.670260, acc.: 60.16%] [G loss: 0.744537]\n",
      "epoch:24 step:19000 [D loss: 0.722776, acc.: 47.66%] [G loss: 0.669249]\n",
      "epoch:24 step:19001 [D loss: 0.711026, acc.: 49.22%] [G loss: 0.708050]\n",
      "epoch:24 step:19002 [D loss: 0.712354, acc.: 53.91%] [G loss: 0.669647]\n",
      "epoch:24 step:19003 [D loss: 0.658877, acc.: 57.03%] [G loss: 0.704630]\n",
      "epoch:24 step:19004 [D loss: 0.673314, acc.: 60.16%] [G loss: 0.688175]\n",
      "epoch:24 step:19005 [D loss: 0.740763, acc.: 46.88%] [G loss: 0.697691]\n",
      "epoch:24 step:19006 [D loss: 0.691757, acc.: 51.56%] [G loss: 0.812907]\n",
      "epoch:24 step:19007 [D loss: 0.666357, acc.: 62.50%] [G loss: 0.810852]\n",
      "epoch:24 step:19008 [D loss: 0.714176, acc.: 42.97%] [G loss: 0.739575]\n",
      "epoch:24 step:19009 [D loss: 0.672839, acc.: 56.25%] [G loss: 0.757621]\n",
      "epoch:24 step:19010 [D loss: 0.664528, acc.: 55.47%] [G loss: 0.753641]\n",
      "epoch:24 step:19011 [D loss: 0.746899, acc.: 40.62%] [G loss: 0.743006]\n",
      "epoch:24 step:19012 [D loss: 0.679772, acc.: 52.34%] [G loss: 0.791877]\n",
      "epoch:24 step:19013 [D loss: 0.702020, acc.: 46.09%] [G loss: 0.728612]\n",
      "epoch:24 step:19014 [D loss: 0.677034, acc.: 54.69%] [G loss: 0.748430]\n",
      "epoch:24 step:19015 [D loss: 0.692678, acc.: 53.91%] [G loss: 0.813832]\n",
      "epoch:24 step:19016 [D loss: 0.702849, acc.: 46.09%] [G loss: 0.707117]\n",
      "epoch:24 step:19017 [D loss: 0.654859, acc.: 64.84%] [G loss: 0.863390]\n",
      "epoch:24 step:19018 [D loss: 0.694476, acc.: 52.34%] [G loss: 0.730782]\n",
      "epoch:24 step:19019 [D loss: 0.719260, acc.: 46.09%] [G loss: 0.748044]\n",
      "epoch:24 step:19020 [D loss: 0.719328, acc.: 42.97%] [G loss: 0.751939]\n",
      "epoch:24 step:19021 [D loss: 0.726141, acc.: 44.53%] [G loss: 0.763870]\n",
      "epoch:24 step:19022 [D loss: 0.698414, acc.: 53.91%] [G loss: 0.798231]\n",
      "epoch:24 step:19023 [D loss: 0.688360, acc.: 57.03%] [G loss: 0.764589]\n",
      "epoch:24 step:19024 [D loss: 0.693855, acc.: 55.47%] [G loss: 0.771582]\n",
      "epoch:24 step:19025 [D loss: 0.660523, acc.: 69.53%] [G loss: 0.744872]\n",
      "epoch:24 step:19026 [D loss: 0.667479, acc.: 60.16%] [G loss: 0.759009]\n",
      "epoch:24 step:19027 [D loss: 0.667985, acc.: 64.84%] [G loss: 0.793190]\n",
      "epoch:24 step:19028 [D loss: 0.669444, acc.: 63.28%] [G loss: 0.774141]\n",
      "epoch:24 step:19029 [D loss: 0.687724, acc.: 55.47%] [G loss: 0.779317]\n",
      "epoch:24 step:19030 [D loss: 0.630315, acc.: 66.41%] [G loss: 0.846005]\n",
      "epoch:24 step:19031 [D loss: 0.700206, acc.: 55.47%] [G loss: 0.771197]\n",
      "epoch:24 step:19032 [D loss: 0.713371, acc.: 50.78%] [G loss: 0.805592]\n",
      "epoch:24 step:19033 [D loss: 0.703546, acc.: 52.34%] [G loss: 0.780084]\n",
      "epoch:24 step:19034 [D loss: 0.654724, acc.: 57.03%] [G loss: 0.755783]\n",
      "epoch:24 step:19035 [D loss: 0.694369, acc.: 49.22%] [G loss: 0.815156]\n",
      "epoch:24 step:19036 [D loss: 0.721373, acc.: 46.88%] [G loss: 0.800540]\n",
      "epoch:24 step:19037 [D loss: 0.691417, acc.: 55.47%] [G loss: 0.728615]\n",
      "epoch:24 step:19038 [D loss: 0.695183, acc.: 55.47%] [G loss: 0.747714]\n",
      "epoch:24 step:19039 [D loss: 0.717630, acc.: 42.97%] [G loss: 0.754640]\n",
      "epoch:24 step:19040 [D loss: 0.748296, acc.: 41.41%] [G loss: 0.728905]\n",
      "epoch:24 step:19041 [D loss: 0.660457, acc.: 60.16%] [G loss: 0.763212]\n",
      "epoch:24 step:19042 [D loss: 0.700446, acc.: 50.78%] [G loss: 0.746399]\n",
      "epoch:24 step:19043 [D loss: 0.642499, acc.: 63.28%] [G loss: 0.744619]\n",
      "epoch:24 step:19044 [D loss: 0.664801, acc.: 60.16%] [G loss: 0.770479]\n",
      "epoch:24 step:19045 [D loss: 0.675629, acc.: 57.81%] [G loss: 0.722684]\n",
      "epoch:24 step:19046 [D loss: 0.686252, acc.: 54.69%] [G loss: 0.684594]\n",
      "epoch:24 step:19047 [D loss: 0.707556, acc.: 51.56%] [G loss: 0.762103]\n",
      "epoch:24 step:19048 [D loss: 0.704923, acc.: 55.47%] [G loss: 0.751684]\n",
      "epoch:24 step:19049 [D loss: 0.689986, acc.: 52.34%] [G loss: 0.760257]\n",
      "epoch:24 step:19050 [D loss: 0.646017, acc.: 65.62%] [G loss: 0.759819]\n",
      "epoch:24 step:19051 [D loss: 0.690664, acc.: 53.91%] [G loss: 0.746543]\n",
      "epoch:24 step:19052 [D loss: 0.688547, acc.: 57.03%] [G loss: 0.797825]\n",
      "epoch:24 step:19053 [D loss: 0.673633, acc.: 57.81%] [G loss: 0.810636]\n",
      "epoch:24 step:19054 [D loss: 0.686341, acc.: 53.91%] [G loss: 0.845903]\n",
      "epoch:24 step:19055 [D loss: 0.682786, acc.: 54.69%] [G loss: 0.817877]\n",
      "epoch:24 step:19056 [D loss: 0.693200, acc.: 53.91%] [G loss: 0.850082]\n",
      "epoch:24 step:19057 [D loss: 0.665537, acc.: 57.81%] [G loss: 0.806179]\n",
      "epoch:24 step:19058 [D loss: 0.689530, acc.: 51.56%] [G loss: 0.729252]\n",
      "epoch:24 step:19059 [D loss: 0.699986, acc.: 55.47%] [G loss: 0.775555]\n",
      "epoch:24 step:19060 [D loss: 0.741836, acc.: 46.09%] [G loss: 0.754655]\n",
      "epoch:24 step:19061 [D loss: 0.711621, acc.: 51.56%] [G loss: 0.700139]\n",
      "epoch:24 step:19062 [D loss: 0.686678, acc.: 59.38%] [G loss: 0.755930]\n",
      "epoch:24 step:19063 [D loss: 0.761831, acc.: 34.38%] [G loss: 0.657597]\n",
      "epoch:24 step:19064 [D loss: 0.690526, acc.: 49.22%] [G loss: 0.771584]\n",
      "epoch:24 step:19065 [D loss: 0.705758, acc.: 49.22%] [G loss: 0.732858]\n",
      "epoch:24 step:19066 [D loss: 0.690352, acc.: 54.69%] [G loss: 0.688855]\n",
      "epoch:24 step:19067 [D loss: 0.698079, acc.: 55.47%] [G loss: 0.733115]\n",
      "epoch:24 step:19068 [D loss: 0.662866, acc.: 57.81%] [G loss: 0.760616]\n",
      "epoch:24 step:19069 [D loss: 0.712978, acc.: 50.00%] [G loss: 0.739988]\n",
      "epoch:24 step:19070 [D loss: 0.741633, acc.: 37.50%] [G loss: 0.814068]\n",
      "epoch:24 step:19071 [D loss: 0.685120, acc.: 54.69%] [G loss: 0.850387]\n",
      "epoch:24 step:19072 [D loss: 0.701106, acc.: 54.69%] [G loss: 0.751356]\n",
      "epoch:24 step:19073 [D loss: 0.715610, acc.: 46.09%] [G loss: 0.730471]\n",
      "epoch:24 step:19074 [D loss: 0.722325, acc.: 39.84%] [G loss: 0.652906]\n",
      "epoch:24 step:19075 [D loss: 0.673660, acc.: 58.59%] [G loss: 0.753045]\n",
      "epoch:24 step:19076 [D loss: 0.692535, acc.: 46.09%] [G loss: 0.699782]\n",
      "epoch:24 step:19077 [D loss: 0.688651, acc.: 57.03%] [G loss: 0.729575]\n",
      "epoch:24 step:19078 [D loss: 0.699690, acc.: 50.78%] [G loss: 0.777950]\n",
      "epoch:24 step:19079 [D loss: 0.585772, acc.: 78.12%] [G loss: 0.850625]\n",
      "epoch:24 step:19080 [D loss: 0.695969, acc.: 48.44%] [G loss: 0.734989]\n",
      "epoch:24 step:19081 [D loss: 0.684665, acc.: 53.12%] [G loss: 0.765824]\n",
      "epoch:24 step:19082 [D loss: 0.737322, acc.: 43.75%] [G loss: 0.713506]\n",
      "epoch:24 step:19083 [D loss: 0.671901, acc.: 59.38%] [G loss: 0.803658]\n",
      "epoch:24 step:19084 [D loss: 0.691741, acc.: 54.69%] [G loss: 0.768170]\n",
      "epoch:24 step:19085 [D loss: 0.670539, acc.: 60.94%] [G loss: 0.773735]\n",
      "epoch:24 step:19086 [D loss: 0.686585, acc.: 53.12%] [G loss: 0.826979]\n",
      "epoch:24 step:19087 [D loss: 0.724579, acc.: 48.44%] [G loss: 0.741466]\n",
      "epoch:24 step:19088 [D loss: 0.680038, acc.: 56.25%] [G loss: 0.813806]\n",
      "epoch:24 step:19089 [D loss: 0.699080, acc.: 51.56%] [G loss: 0.814006]\n",
      "epoch:24 step:19090 [D loss: 0.651657, acc.: 61.72%] [G loss: 0.740104]\n",
      "epoch:24 step:19091 [D loss: 0.694357, acc.: 54.69%] [G loss: 0.771591]\n",
      "epoch:24 step:19092 [D loss: 0.708085, acc.: 48.44%] [G loss: 0.759479]\n",
      "epoch:24 step:19093 [D loss: 0.648204, acc.: 73.44%] [G loss: 0.854790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19094 [D loss: 0.772594, acc.: 35.94%] [G loss: 0.708262]\n",
      "epoch:24 step:19095 [D loss: 0.720352, acc.: 45.31%] [G loss: 0.723516]\n",
      "epoch:24 step:19096 [D loss: 0.714658, acc.: 42.19%] [G loss: 0.720267]\n",
      "epoch:24 step:19097 [D loss: 0.675602, acc.: 53.12%] [G loss: 0.721899]\n",
      "epoch:24 step:19098 [D loss: 0.702839, acc.: 55.47%] [G loss: 0.729354]\n",
      "epoch:24 step:19099 [D loss: 0.680207, acc.: 57.81%] [G loss: 0.834056]\n",
      "epoch:24 step:19100 [D loss: 0.664145, acc.: 62.50%] [G loss: 0.745842]\n",
      "epoch:24 step:19101 [D loss: 0.698204, acc.: 53.91%] [G loss: 0.802661]\n",
      "epoch:24 step:19102 [D loss: 0.691048, acc.: 52.34%] [G loss: 0.860548]\n",
      "epoch:24 step:19103 [D loss: 0.700144, acc.: 46.88%] [G loss: 0.803719]\n",
      "epoch:24 step:19104 [D loss: 0.672485, acc.: 54.69%] [G loss: 0.767031]\n",
      "epoch:24 step:19105 [D loss: 0.674594, acc.: 56.25%] [G loss: 0.782234]\n",
      "epoch:24 step:19106 [D loss: 0.665046, acc.: 57.81%] [G loss: 0.717227]\n",
      "epoch:24 step:19107 [D loss: 0.731781, acc.: 41.41%] [G loss: 0.731344]\n",
      "epoch:24 step:19108 [D loss: 0.670217, acc.: 59.38%] [G loss: 0.731395]\n",
      "epoch:24 step:19109 [D loss: 0.664646, acc.: 58.59%] [G loss: 0.772396]\n",
      "epoch:24 step:19110 [D loss: 0.663469, acc.: 60.16%] [G loss: 0.738206]\n",
      "epoch:24 step:19111 [D loss: 0.703443, acc.: 53.12%] [G loss: 0.738408]\n",
      "epoch:24 step:19112 [D loss: 0.692530, acc.: 54.69%] [G loss: 0.733468]\n",
      "epoch:24 step:19113 [D loss: 0.701522, acc.: 53.12%] [G loss: 0.814322]\n",
      "epoch:24 step:19114 [D loss: 0.649414, acc.: 66.41%] [G loss: 0.793679]\n",
      "epoch:24 step:19115 [D loss: 0.655274, acc.: 64.06%] [G loss: 0.806318]\n",
      "epoch:24 step:19116 [D loss: 0.652043, acc.: 64.06%] [G loss: 0.809077]\n",
      "epoch:24 step:19117 [D loss: 0.720701, acc.: 42.97%] [G loss: 0.775619]\n",
      "epoch:24 step:19118 [D loss: 0.661930, acc.: 57.81%] [G loss: 0.752279]\n",
      "epoch:24 step:19119 [D loss: 0.702633, acc.: 58.59%] [G loss: 0.731387]\n",
      "epoch:24 step:19120 [D loss: 0.726331, acc.: 40.62%] [G loss: 0.758031]\n",
      "epoch:24 step:19121 [D loss: 0.680378, acc.: 54.69%] [G loss: 0.761070]\n",
      "epoch:24 step:19122 [D loss: 0.666378, acc.: 63.28%] [G loss: 0.770034]\n",
      "epoch:24 step:19123 [D loss: 0.637951, acc.: 68.75%] [G loss: 0.771918]\n",
      "epoch:24 step:19124 [D loss: 0.687664, acc.: 51.56%] [G loss: 0.665032]\n",
      "epoch:24 step:19125 [D loss: 0.574312, acc.: 88.28%] [G loss: 0.754616]\n",
      "epoch:24 step:19126 [D loss: 0.656654, acc.: 61.72%] [G loss: 0.744968]\n",
      "epoch:24 step:19127 [D loss: 0.686437, acc.: 52.34%] [G loss: 0.686618]\n",
      "epoch:24 step:19128 [D loss: 0.648753, acc.: 62.50%] [G loss: 0.740849]\n",
      "epoch:24 step:19129 [D loss: 0.749845, acc.: 37.50%] [G loss: 0.699074]\n",
      "epoch:24 step:19130 [D loss: 0.676452, acc.: 60.94%] [G loss: 0.757298]\n",
      "epoch:24 step:19131 [D loss: 0.678528, acc.: 55.47%] [G loss: 0.794748]\n",
      "epoch:24 step:19132 [D loss: 0.698468, acc.: 54.69%] [G loss: 0.829938]\n",
      "epoch:24 step:19133 [D loss: 0.759778, acc.: 29.69%] [G loss: 0.782963]\n",
      "epoch:24 step:19134 [D loss: 0.705524, acc.: 46.88%] [G loss: 0.781900]\n",
      "epoch:24 step:19135 [D loss: 0.756236, acc.: 36.72%] [G loss: 0.782347]\n",
      "epoch:24 step:19136 [D loss: 0.698740, acc.: 58.59%] [G loss: 0.828889]\n",
      "epoch:24 step:19137 [D loss: 0.681811, acc.: 60.16%] [G loss: 0.787785]\n",
      "epoch:24 step:19138 [D loss: 0.674650, acc.: 59.38%] [G loss: 0.748201]\n",
      "epoch:24 step:19139 [D loss: 0.687678, acc.: 53.91%] [G loss: 0.755126]\n",
      "epoch:24 step:19140 [D loss: 0.657502, acc.: 58.59%] [G loss: 0.796397]\n",
      "epoch:24 step:19141 [D loss: 0.666496, acc.: 62.50%] [G loss: 0.790908]\n",
      "epoch:24 step:19142 [D loss: 0.675028, acc.: 54.69%] [G loss: 0.791004]\n",
      "epoch:24 step:19143 [D loss: 0.680043, acc.: 54.69%] [G loss: 0.750213]\n",
      "epoch:24 step:19144 [D loss: 0.710431, acc.: 48.44%] [G loss: 0.774395]\n",
      "epoch:24 step:19145 [D loss: 0.730538, acc.: 40.62%] [G loss: 0.746552]\n",
      "epoch:24 step:19146 [D loss: 0.645900, acc.: 69.53%] [G loss: 0.799195]\n",
      "epoch:24 step:19147 [D loss: 0.679365, acc.: 58.59%] [G loss: 0.757488]\n",
      "epoch:24 step:19148 [D loss: 0.715709, acc.: 50.00%] [G loss: 0.802466]\n",
      "epoch:24 step:19149 [D loss: 0.678982, acc.: 53.12%] [G loss: 0.791284]\n",
      "epoch:24 step:19150 [D loss: 0.688557, acc.: 53.12%] [G loss: 0.835728]\n",
      "epoch:24 step:19151 [D loss: 0.665053, acc.: 54.69%] [G loss: 0.797043]\n",
      "epoch:24 step:19152 [D loss: 0.679907, acc.: 57.81%] [G loss: 0.776545]\n",
      "epoch:24 step:19153 [D loss: 0.692889, acc.: 54.69%] [G loss: 0.850579]\n",
      "epoch:24 step:19154 [D loss: 0.650574, acc.: 64.84%] [G loss: 0.784548]\n",
      "epoch:24 step:19155 [D loss: 0.699344, acc.: 51.56%] [G loss: 0.763764]\n",
      "epoch:24 step:19156 [D loss: 0.703038, acc.: 46.09%] [G loss: 0.759693]\n",
      "epoch:24 step:19157 [D loss: 0.675999, acc.: 59.38%] [G loss: 0.705565]\n",
      "epoch:24 step:19158 [D loss: 0.677518, acc.: 55.47%] [G loss: 0.757578]\n",
      "epoch:24 step:19159 [D loss: 0.711420, acc.: 54.69%] [G loss: 0.733700]\n",
      "epoch:24 step:19160 [D loss: 0.655533, acc.: 60.94%] [G loss: 0.732346]\n",
      "epoch:24 step:19161 [D loss: 0.741541, acc.: 37.50%] [G loss: 0.706840]\n",
      "epoch:24 step:19162 [D loss: 0.692593, acc.: 50.00%] [G loss: 0.784026]\n",
      "epoch:24 step:19163 [D loss: 0.675604, acc.: 62.50%] [G loss: 0.866527]\n",
      "epoch:24 step:19164 [D loss: 0.719693, acc.: 48.44%] [G loss: 0.823394]\n",
      "epoch:24 step:19165 [D loss: 0.630762, acc.: 71.09%] [G loss: 0.841938]\n",
      "epoch:24 step:19166 [D loss: 0.673052, acc.: 59.38%] [G loss: 0.805438]\n",
      "epoch:24 step:19167 [D loss: 0.707363, acc.: 45.31%] [G loss: 0.818681]\n",
      "epoch:24 step:19168 [D loss: 0.748363, acc.: 41.41%] [G loss: 0.742569]\n",
      "epoch:24 step:19169 [D loss: 0.667912, acc.: 60.94%] [G loss: 0.762440]\n",
      "epoch:24 step:19170 [D loss: 0.712055, acc.: 46.09%] [G loss: 0.706244]\n",
      "epoch:24 step:19171 [D loss: 0.684835, acc.: 60.16%] [G loss: 0.685239]\n",
      "epoch:24 step:19172 [D loss: 0.727739, acc.: 45.31%] [G loss: 0.729285]\n",
      "epoch:24 step:19173 [D loss: 0.766488, acc.: 33.59%] [G loss: 0.693516]\n",
      "epoch:24 step:19174 [D loss: 0.673672, acc.: 54.69%] [G loss: 0.709327]\n",
      "epoch:24 step:19175 [D loss: 0.708969, acc.: 50.78%] [G loss: 0.735287]\n",
      "epoch:24 step:19176 [D loss: 0.652645, acc.: 63.28%] [G loss: 0.770886]\n",
      "epoch:24 step:19177 [D loss: 0.713519, acc.: 48.44%] [G loss: 0.808237]\n",
      "epoch:24 step:19178 [D loss: 0.706454, acc.: 50.00%] [G loss: 0.772648]\n",
      "epoch:24 step:19179 [D loss: 0.774812, acc.: 42.19%] [G loss: 0.735210]\n",
      "epoch:24 step:19180 [D loss: 0.789075, acc.: 31.25%] [G loss: 0.773736]\n",
      "epoch:24 step:19181 [D loss: 0.699043, acc.: 49.22%] [G loss: 0.779048]\n",
      "epoch:24 step:19182 [D loss: 0.717164, acc.: 40.62%] [G loss: 0.715159]\n",
      "epoch:24 step:19183 [D loss: 0.728305, acc.: 44.53%] [G loss: 0.687149]\n",
      "epoch:24 step:19184 [D loss: 0.723875, acc.: 42.19%] [G loss: 0.767834]\n",
      "epoch:24 step:19185 [D loss: 0.698621, acc.: 46.09%] [G loss: 0.753240]\n",
      "epoch:24 step:19186 [D loss: 0.697756, acc.: 48.44%] [G loss: 0.769340]\n",
      "epoch:24 step:19187 [D loss: 0.653466, acc.: 65.62%] [G loss: 0.793370]\n",
      "epoch:24 step:19188 [D loss: 0.651192, acc.: 59.38%] [G loss: 0.847657]\n",
      "epoch:24 step:19189 [D loss: 0.673990, acc.: 61.72%] [G loss: 0.852279]\n",
      "epoch:24 step:19190 [D loss: 0.748237, acc.: 41.41%] [G loss: 0.803555]\n",
      "epoch:24 step:19191 [D loss: 0.709560, acc.: 52.34%] [G loss: 0.731968]\n",
      "epoch:24 step:19192 [D loss: 0.707480, acc.: 45.31%] [G loss: 0.793048]\n",
      "epoch:24 step:19193 [D loss: 0.689045, acc.: 57.81%] [G loss: 0.768018]\n",
      "epoch:24 step:19194 [D loss: 0.659125, acc.: 61.72%] [G loss: 0.832543]\n",
      "epoch:24 step:19195 [D loss: 0.679841, acc.: 53.91%] [G loss: 0.769236]\n",
      "epoch:24 step:19196 [D loss: 0.649416, acc.: 64.06%] [G loss: 0.802233]\n",
      "epoch:24 step:19197 [D loss: 0.701934, acc.: 49.22%] [G loss: 0.748176]\n",
      "epoch:24 step:19198 [D loss: 0.702603, acc.: 47.66%] [G loss: 0.741225]\n",
      "epoch:24 step:19199 [D loss: 0.680887, acc.: 62.50%] [G loss: 0.719834]\n",
      "epoch:24 step:19200 [D loss: 0.657908, acc.: 58.59%] [G loss: 0.769268]\n",
      "epoch:24 step:19201 [D loss: 0.656840, acc.: 65.62%] [G loss: 0.728660]\n",
      "epoch:24 step:19202 [D loss: 0.680067, acc.: 57.03%] [G loss: 0.805604]\n",
      "epoch:24 step:19203 [D loss: 0.743459, acc.: 42.19%] [G loss: 0.746362]\n",
      "epoch:24 step:19204 [D loss: 0.698904, acc.: 50.78%] [G loss: 0.723461]\n",
      "epoch:24 step:19205 [D loss: 0.715642, acc.: 46.09%] [G loss: 0.757869]\n",
      "epoch:24 step:19206 [D loss: 0.692458, acc.: 53.12%] [G loss: 0.782117]\n",
      "epoch:24 step:19207 [D loss: 0.764371, acc.: 29.69%] [G loss: 0.722297]\n",
      "epoch:24 step:19208 [D loss: 0.681464, acc.: 57.03%] [G loss: 0.767391]\n",
      "epoch:24 step:19209 [D loss: 0.700342, acc.: 52.34%] [G loss: 0.754739]\n",
      "epoch:24 step:19210 [D loss: 0.705329, acc.: 46.09%] [G loss: 0.775092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19211 [D loss: 0.692859, acc.: 50.78%] [G loss: 0.780663]\n",
      "epoch:24 step:19212 [D loss: 0.695589, acc.: 50.78%] [G loss: 0.809887]\n",
      "epoch:24 step:19213 [D loss: 0.667942, acc.: 57.81%] [G loss: 0.756568]\n",
      "epoch:24 step:19214 [D loss: 0.681538, acc.: 60.94%] [G loss: 0.777485]\n",
      "epoch:24 step:19215 [D loss: 0.671561, acc.: 60.16%] [G loss: 0.742829]\n",
      "epoch:24 step:19216 [D loss: 0.724124, acc.: 41.41%] [G loss: 0.735512]\n",
      "epoch:24 step:19217 [D loss: 0.794824, acc.: 38.28%] [G loss: 0.737609]\n",
      "epoch:24 step:19218 [D loss: 0.734961, acc.: 35.94%] [G loss: 0.706149]\n",
      "epoch:24 step:19219 [D loss: 0.707732, acc.: 51.56%] [G loss: 0.713568]\n",
      "epoch:24 step:19220 [D loss: 0.675386, acc.: 60.16%] [G loss: 0.748076]\n",
      "epoch:24 step:19221 [D loss: 0.664781, acc.: 61.72%] [G loss: 0.736619]\n",
      "epoch:24 step:19222 [D loss: 0.661400, acc.: 59.38%] [G loss: 0.956161]\n",
      "epoch:24 step:19223 [D loss: 0.679199, acc.: 53.12%] [G loss: 0.827823]\n",
      "epoch:24 step:19224 [D loss: 0.649318, acc.: 64.06%] [G loss: 0.788170]\n",
      "epoch:24 step:19225 [D loss: 0.685427, acc.: 50.00%] [G loss: 0.796086]\n",
      "epoch:24 step:19226 [D loss: 0.718886, acc.: 45.31%] [G loss: 0.777380]\n",
      "epoch:24 step:19227 [D loss: 0.715827, acc.: 43.75%] [G loss: 0.745104]\n",
      "epoch:24 step:19228 [D loss: 0.692422, acc.: 51.56%] [G loss: 0.740819]\n",
      "epoch:24 step:19229 [D loss: 0.668752, acc.: 57.03%] [G loss: 0.710589]\n",
      "epoch:24 step:19230 [D loss: 0.704217, acc.: 48.44%] [G loss: 0.812262]\n",
      "epoch:24 step:19231 [D loss: 0.722684, acc.: 46.09%] [G loss: 0.713207]\n",
      "epoch:24 step:19232 [D loss: 0.709392, acc.: 46.88%] [G loss: 0.755639]\n",
      "epoch:24 step:19233 [D loss: 0.730024, acc.: 39.84%] [G loss: 0.660732]\n",
      "epoch:24 step:19234 [D loss: 0.688659, acc.: 50.78%] [G loss: 0.751268]\n",
      "epoch:24 step:19235 [D loss: 0.681923, acc.: 58.59%] [G loss: 0.703578]\n",
      "epoch:24 step:19236 [D loss: 0.704518, acc.: 49.22%] [G loss: 0.749684]\n",
      "epoch:24 step:19237 [D loss: 0.683269, acc.: 53.91%] [G loss: 0.742372]\n",
      "epoch:24 step:19238 [D loss: 0.683929, acc.: 57.81%] [G loss: 0.726260]\n",
      "epoch:24 step:19239 [D loss: 0.639840, acc.: 68.75%] [G loss: 0.807894]\n",
      "epoch:24 step:19240 [D loss: 0.689452, acc.: 55.47%] [G loss: 0.735160]\n",
      "epoch:24 step:19241 [D loss: 0.683334, acc.: 50.78%] [G loss: 0.766203]\n",
      "epoch:24 step:19242 [D loss: 0.681556, acc.: 57.03%] [G loss: 0.787488]\n",
      "epoch:24 step:19243 [D loss: 0.673932, acc.: 57.03%] [G loss: 0.790669]\n",
      "epoch:24 step:19244 [D loss: 0.634043, acc.: 64.84%] [G loss: 0.777089]\n",
      "epoch:24 step:19245 [D loss: 0.689455, acc.: 51.56%] [G loss: 0.784576]\n",
      "epoch:24 step:19246 [D loss: 0.678297, acc.: 56.25%] [G loss: 0.771743]\n",
      "epoch:24 step:19247 [D loss: 0.698344, acc.: 53.12%] [G loss: 0.818483]\n",
      "epoch:24 step:19248 [D loss: 0.705303, acc.: 54.69%] [G loss: 0.758988]\n",
      "epoch:24 step:19249 [D loss: 0.674899, acc.: 56.25%] [G loss: 0.835233]\n",
      "epoch:24 step:19250 [D loss: 0.716931, acc.: 46.09%] [G loss: 0.759732]\n",
      "epoch:24 step:19251 [D loss: 0.680747, acc.: 57.03%] [G loss: 0.760852]\n",
      "epoch:24 step:19252 [D loss: 0.712952, acc.: 51.56%] [G loss: 0.796263]\n",
      "epoch:24 step:19253 [D loss: 0.705262, acc.: 48.44%] [G loss: 0.774590]\n",
      "epoch:24 step:19254 [D loss: 0.683414, acc.: 54.69%] [G loss: 0.765516]\n",
      "epoch:24 step:19255 [D loss: 0.680424, acc.: 51.56%] [G loss: 0.816579]\n",
      "epoch:24 step:19256 [D loss: 0.700529, acc.: 53.91%] [G loss: 0.794995]\n",
      "epoch:24 step:19257 [D loss: 0.727562, acc.: 46.09%] [G loss: 0.780360]\n",
      "epoch:24 step:19258 [D loss: 0.752906, acc.: 45.31%] [G loss: 0.695196]\n",
      "epoch:24 step:19259 [D loss: 0.688813, acc.: 52.34%] [G loss: 0.699399]\n",
      "epoch:24 step:19260 [D loss: 0.661478, acc.: 63.28%] [G loss: 0.766909]\n",
      "epoch:24 step:19261 [D loss: 0.687366, acc.: 50.78%] [G loss: 0.723421]\n",
      "epoch:24 step:19262 [D loss: 0.688068, acc.: 53.12%] [G loss: 0.738902]\n",
      "epoch:24 step:19263 [D loss: 0.635793, acc.: 68.75%] [G loss: 0.752237]\n",
      "epoch:24 step:19264 [D loss: 0.662795, acc.: 60.16%] [G loss: 0.788939]\n",
      "epoch:24 step:19265 [D loss: 0.641659, acc.: 66.41%] [G loss: 0.798055]\n",
      "epoch:24 step:19266 [D loss: 0.684919, acc.: 51.56%] [G loss: 0.723229]\n",
      "epoch:24 step:19267 [D loss: 0.729884, acc.: 40.62%] [G loss: 0.786385]\n",
      "epoch:24 step:19268 [D loss: 0.660504, acc.: 67.19%] [G loss: 0.788381]\n",
      "epoch:24 step:19269 [D loss: 0.744966, acc.: 36.72%] [G loss: 0.780988]\n",
      "epoch:24 step:19270 [D loss: 0.756734, acc.: 43.75%] [G loss: 0.751649]\n",
      "epoch:24 step:19271 [D loss: 0.681553, acc.: 57.81%] [G loss: 0.691395]\n",
      "epoch:24 step:19272 [D loss: 0.728757, acc.: 42.19%] [G loss: 0.703583]\n",
      "epoch:24 step:19273 [D loss: 0.673248, acc.: 59.38%] [G loss: 0.693576]\n",
      "epoch:24 step:19274 [D loss: 0.639769, acc.: 70.31%] [G loss: 0.715021]\n",
      "epoch:24 step:19275 [D loss: 0.706412, acc.: 51.56%] [G loss: 0.681475]\n",
      "epoch:24 step:19276 [D loss: 0.672518, acc.: 59.38%] [G loss: 0.798584]\n",
      "epoch:24 step:19277 [D loss: 0.690905, acc.: 57.03%] [G loss: 0.775171]\n",
      "epoch:24 step:19278 [D loss: 0.704427, acc.: 52.34%] [G loss: 0.766833]\n",
      "epoch:24 step:19279 [D loss: 0.692756, acc.: 52.34%] [G loss: 0.749550]\n",
      "epoch:24 step:19280 [D loss: 0.691426, acc.: 52.34%] [G loss: 0.744731]\n",
      "epoch:24 step:19281 [D loss: 0.670687, acc.: 60.94%] [G loss: 0.809229]\n",
      "epoch:24 step:19282 [D loss: 0.698829, acc.: 47.66%] [G loss: 0.785335]\n",
      "epoch:24 step:19283 [D loss: 0.722926, acc.: 41.41%] [G loss: 0.835981]\n",
      "epoch:24 step:19284 [D loss: 0.678921, acc.: 55.47%] [G loss: 0.800984]\n",
      "epoch:24 step:19285 [D loss: 0.670594, acc.: 57.81%] [G loss: 0.799599]\n",
      "epoch:24 step:19286 [D loss: 0.695280, acc.: 53.12%] [G loss: 0.831905]\n",
      "epoch:24 step:19287 [D loss: 0.665696, acc.: 54.69%] [G loss: 0.783759]\n",
      "epoch:24 step:19288 [D loss: 0.643990, acc.: 64.06%] [G loss: 0.807730]\n",
      "epoch:24 step:19289 [D loss: 0.665141, acc.: 66.41%] [G loss: 0.814292]\n",
      "epoch:24 step:19290 [D loss: 0.778374, acc.: 32.81%] [G loss: 0.765216]\n",
      "epoch:24 step:19291 [D loss: 0.676228, acc.: 53.91%] [G loss: 0.764207]\n",
      "epoch:24 step:19292 [D loss: 0.692409, acc.: 54.69%] [G loss: 0.815905]\n",
      "epoch:24 step:19293 [D loss: 0.651327, acc.: 64.06%] [G loss: 0.772188]\n",
      "epoch:24 step:19294 [D loss: 0.696444, acc.: 46.09%] [G loss: 0.749158]\n",
      "epoch:24 step:19295 [D loss: 0.658088, acc.: 64.06%] [G loss: 0.811004]\n",
      "epoch:24 step:19296 [D loss: 0.698354, acc.: 53.91%] [G loss: 0.766247]\n",
      "epoch:24 step:19297 [D loss: 0.684072, acc.: 53.91%] [G loss: 0.711439]\n",
      "epoch:24 step:19298 [D loss: 0.690046, acc.: 54.69%] [G loss: 0.761417]\n",
      "epoch:24 step:19299 [D loss: 0.693544, acc.: 57.03%] [G loss: 0.800273]\n",
      "epoch:24 step:19300 [D loss: 0.694389, acc.: 50.00%] [G loss: 0.737271]\n",
      "epoch:24 step:19301 [D loss: 0.678425, acc.: 53.12%] [G loss: 0.793130]\n",
      "epoch:24 step:19302 [D loss: 0.655222, acc.: 69.53%] [G loss: 0.831648]\n",
      "epoch:24 step:19303 [D loss: 0.670214, acc.: 60.16%] [G loss: 0.787405]\n",
      "epoch:24 step:19304 [D loss: 0.682279, acc.: 51.56%] [G loss: 0.742496]\n",
      "epoch:24 step:19305 [D loss: 0.714837, acc.: 45.31%] [G loss: 0.821511]\n",
      "epoch:24 step:19306 [D loss: 0.694135, acc.: 53.12%] [G loss: 0.838814]\n",
      "epoch:24 step:19307 [D loss: 0.730276, acc.: 42.19%] [G loss: 0.811942]\n",
      "epoch:24 step:19308 [D loss: 0.696683, acc.: 52.34%] [G loss: 0.784212]\n",
      "epoch:24 step:19309 [D loss: 0.677982, acc.: 58.59%] [G loss: 0.741751]\n",
      "epoch:24 step:19310 [D loss: 0.727691, acc.: 43.75%] [G loss: 0.802605]\n",
      "epoch:24 step:19311 [D loss: 0.710024, acc.: 50.00%] [G loss: 0.809260]\n",
      "epoch:24 step:19312 [D loss: 0.683925, acc.: 56.25%] [G loss: 0.741915]\n",
      "epoch:24 step:19313 [D loss: 0.725580, acc.: 40.62%] [G loss: 0.786880]\n",
      "epoch:24 step:19314 [D loss: 0.666096, acc.: 57.03%] [G loss: 0.762262]\n",
      "epoch:24 step:19315 [D loss: 0.718009, acc.: 47.66%] [G loss: 0.783761]\n",
      "epoch:24 step:19316 [D loss: 0.651754, acc.: 64.06%] [G loss: 0.719996]\n",
      "epoch:24 step:19317 [D loss: 0.693588, acc.: 53.12%] [G loss: 0.731210]\n",
      "epoch:24 step:19318 [D loss: 0.735269, acc.: 46.88%] [G loss: 0.707031]\n",
      "epoch:24 step:19319 [D loss: 0.721004, acc.: 47.66%] [G loss: 0.706981]\n",
      "epoch:24 step:19320 [D loss: 0.648851, acc.: 67.97%] [G loss: 0.746407]\n",
      "epoch:24 step:19321 [D loss: 0.710922, acc.: 42.97%] [G loss: 0.737724]\n",
      "epoch:24 step:19322 [D loss: 0.633894, acc.: 73.44%] [G loss: 0.749468]\n",
      "epoch:24 step:19323 [D loss: 0.705699, acc.: 48.44%] [G loss: 0.732137]\n",
      "epoch:24 step:19324 [D loss: 0.760332, acc.: 36.72%] [G loss: 0.688835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19325 [D loss: 0.677083, acc.: 56.25%] [G loss: 0.721485]\n",
      "epoch:24 step:19326 [D loss: 0.712927, acc.: 51.56%] [G loss: 0.745201]\n",
      "epoch:24 step:19327 [D loss: 0.712019, acc.: 49.22%] [G loss: 0.770303]\n",
      "epoch:24 step:19328 [D loss: 0.693307, acc.: 55.47%] [G loss: 0.819387]\n",
      "epoch:24 step:19329 [D loss: 0.675655, acc.: 56.25%] [G loss: 0.746767]\n",
      "epoch:24 step:19330 [D loss: 0.709955, acc.: 45.31%] [G loss: 0.789007]\n",
      "epoch:24 step:19331 [D loss: 0.658259, acc.: 60.16%] [G loss: 0.797937]\n",
      "epoch:24 step:19332 [D loss: 0.678190, acc.: 51.56%] [G loss: 0.737101]\n",
      "epoch:24 step:19333 [D loss: 0.712974, acc.: 50.00%] [G loss: 0.780320]\n",
      "epoch:24 step:19334 [D loss: 0.694672, acc.: 54.69%] [G loss: 0.753148]\n",
      "epoch:24 step:19335 [D loss: 0.749924, acc.: 38.28%] [G loss: 0.809436]\n",
      "epoch:24 step:19336 [D loss: 0.684915, acc.: 56.25%] [G loss: 0.797644]\n",
      "epoch:24 step:19337 [D loss: 0.707565, acc.: 50.78%] [G loss: 0.771488]\n",
      "epoch:24 step:19338 [D loss: 0.705875, acc.: 47.66%] [G loss: 0.753411]\n",
      "epoch:24 step:19339 [D loss: 0.663586, acc.: 57.03%] [G loss: 0.784543]\n",
      "epoch:24 step:19340 [D loss: 0.706445, acc.: 49.22%] [G loss: 0.716034]\n",
      "epoch:24 step:19341 [D loss: 0.678930, acc.: 50.78%] [G loss: 0.765050]\n",
      "epoch:24 step:19342 [D loss: 0.698282, acc.: 54.69%] [G loss: 0.750663]\n",
      "epoch:24 step:19343 [D loss: 0.699439, acc.: 50.78%] [G loss: 0.753661]\n",
      "epoch:24 step:19344 [D loss: 0.687163, acc.: 54.69%] [G loss: 0.753195]\n",
      "epoch:24 step:19345 [D loss: 0.697469, acc.: 48.44%] [G loss: 0.785743]\n",
      "epoch:24 step:19346 [D loss: 0.610854, acc.: 78.12%] [G loss: 0.731396]\n",
      "epoch:24 step:19347 [D loss: 0.735472, acc.: 43.75%] [G loss: 0.784609]\n",
      "epoch:24 step:19348 [D loss: 0.681983, acc.: 61.72%] [G loss: 0.773356]\n",
      "epoch:24 step:19349 [D loss: 0.652584, acc.: 62.50%] [G loss: 0.763109]\n",
      "epoch:24 step:19350 [D loss: 0.693098, acc.: 54.69%] [G loss: 0.714231]\n",
      "epoch:24 step:19351 [D loss: 0.696710, acc.: 55.47%] [G loss: 0.632564]\n",
      "epoch:24 step:19352 [D loss: 0.682728, acc.: 60.16%] [G loss: 0.738418]\n",
      "epoch:24 step:19353 [D loss: 0.714551, acc.: 46.88%] [G loss: 0.734527]\n",
      "epoch:24 step:19354 [D loss: 0.667658, acc.: 61.72%] [G loss: 0.785795]\n",
      "epoch:24 step:19355 [D loss: 0.701936, acc.: 53.12%] [G loss: 0.735925]\n",
      "epoch:24 step:19356 [D loss: 0.706984, acc.: 46.09%] [G loss: 0.745042]\n",
      "epoch:24 step:19357 [D loss: 0.707905, acc.: 50.78%] [G loss: 0.731395]\n",
      "epoch:24 step:19358 [D loss: 0.689145, acc.: 52.34%] [G loss: 0.768459]\n",
      "epoch:24 step:19359 [D loss: 0.676859, acc.: 57.03%] [G loss: 0.738397]\n",
      "epoch:24 step:19360 [D loss: 0.691069, acc.: 53.91%] [G loss: 0.731069]\n",
      "epoch:24 step:19361 [D loss: 0.705173, acc.: 52.34%] [G loss: 0.704894]\n",
      "epoch:24 step:19362 [D loss: 0.686072, acc.: 62.50%] [G loss: 0.701735]\n",
      "epoch:24 step:19363 [D loss: 0.688658, acc.: 53.12%] [G loss: 0.686671]\n",
      "epoch:24 step:19364 [D loss: 0.690300, acc.: 49.22%] [G loss: 0.763760]\n",
      "epoch:24 step:19365 [D loss: 0.659232, acc.: 63.28%] [G loss: 0.754026]\n",
      "epoch:24 step:19366 [D loss: 0.737935, acc.: 43.75%] [G loss: 0.766983]\n",
      "epoch:24 step:19367 [D loss: 0.709057, acc.: 52.34%] [G loss: 0.777180]\n",
      "epoch:24 step:19368 [D loss: 0.698508, acc.: 51.56%] [G loss: 0.797706]\n",
      "epoch:24 step:19369 [D loss: 0.700215, acc.: 56.25%] [G loss: 0.778382]\n",
      "epoch:24 step:19370 [D loss: 0.700560, acc.: 46.88%] [G loss: 0.814554]\n",
      "epoch:24 step:19371 [D loss: 0.673902, acc.: 56.25%] [G loss: 0.873642]\n",
      "epoch:24 step:19372 [D loss: 0.680619, acc.: 55.47%] [G loss: 0.753118]\n",
      "epoch:24 step:19373 [D loss: 0.685251, acc.: 58.59%] [G loss: 0.819506]\n",
      "epoch:24 step:19374 [D loss: 0.660277, acc.: 57.81%] [G loss: 0.817746]\n",
      "epoch:24 step:19375 [D loss: 0.713062, acc.: 51.56%] [G loss: 0.755349]\n",
      "epoch:24 step:19376 [D loss: 0.681638, acc.: 56.25%] [G loss: 0.758776]\n",
      "epoch:24 step:19377 [D loss: 0.720220, acc.: 39.84%] [G loss: 0.696861]\n",
      "epoch:24 step:19378 [D loss: 0.715305, acc.: 42.97%] [G loss: 0.704822]\n",
      "epoch:24 step:19379 [D loss: 0.695170, acc.: 50.78%] [G loss: 0.669712]\n",
      "epoch:24 step:19380 [D loss: 0.682101, acc.: 56.25%] [G loss: 0.764525]\n",
      "epoch:24 step:19381 [D loss: 0.652194, acc.: 59.38%] [G loss: 0.794609]\n",
      "epoch:24 step:19382 [D loss: 0.679690, acc.: 59.38%] [G loss: 0.795938]\n",
      "epoch:24 step:19383 [D loss: 0.701707, acc.: 48.44%] [G loss: 0.712783]\n",
      "epoch:24 step:19384 [D loss: 0.690987, acc.: 46.09%] [G loss: 0.812715]\n",
      "epoch:24 step:19385 [D loss: 0.669551, acc.: 63.28%] [G loss: 0.736071]\n",
      "epoch:24 step:19386 [D loss: 0.708296, acc.: 51.56%] [G loss: 0.758988]\n",
      "epoch:24 step:19387 [D loss: 0.694441, acc.: 50.00%] [G loss: 0.745819]\n",
      "epoch:24 step:19388 [D loss: 0.670894, acc.: 65.62%] [G loss: 0.759823]\n",
      "epoch:24 step:19389 [D loss: 0.664206, acc.: 64.06%] [G loss: 0.761093]\n",
      "epoch:24 step:19390 [D loss: 0.729371, acc.: 37.50%] [G loss: 0.799923]\n",
      "epoch:24 step:19391 [D loss: 0.714240, acc.: 48.44%] [G loss: 0.719538]\n",
      "epoch:24 step:19392 [D loss: 0.707389, acc.: 47.66%] [G loss: 0.713401]\n",
      "epoch:24 step:19393 [D loss: 0.691962, acc.: 53.12%] [G loss: 0.759835]\n",
      "epoch:24 step:19394 [D loss: 0.680848, acc.: 55.47%] [G loss: 0.765959]\n",
      "epoch:24 step:19395 [D loss: 0.748306, acc.: 41.41%] [G loss: 0.728227]\n",
      "epoch:24 step:19396 [D loss: 0.679948, acc.: 57.81%] [G loss: 0.728992]\n",
      "epoch:24 step:19397 [D loss: 0.680212, acc.: 58.59%] [G loss: 0.795638]\n",
      "epoch:24 step:19398 [D loss: 0.736496, acc.: 39.84%] [G loss: 0.812864]\n",
      "epoch:24 step:19399 [D loss: 0.705835, acc.: 52.34%] [G loss: 0.770230]\n",
      "epoch:24 step:19400 [D loss: 0.631341, acc.: 69.53%] [G loss: 0.809934]\n",
      "epoch:24 step:19401 [D loss: 0.715715, acc.: 48.44%] [G loss: 0.842715]\n",
      "epoch:24 step:19402 [D loss: 0.630470, acc.: 71.88%] [G loss: 0.783686]\n",
      "epoch:24 step:19403 [D loss: 0.654813, acc.: 64.06%] [G loss: 0.833150]\n",
      "epoch:24 step:19404 [D loss: 0.694766, acc.: 53.12%] [G loss: 0.782393]\n",
      "epoch:24 step:19405 [D loss: 0.672184, acc.: 59.38%] [G loss: 0.765872]\n",
      "epoch:24 step:19406 [D loss: 0.721194, acc.: 49.22%] [G loss: 0.737474]\n",
      "epoch:24 step:19407 [D loss: 0.643281, acc.: 68.75%] [G loss: 0.824813]\n",
      "epoch:24 step:19408 [D loss: 0.649085, acc.: 67.97%] [G loss: 0.778659]\n",
      "epoch:24 step:19409 [D loss: 0.661318, acc.: 64.84%] [G loss: 0.773775]\n",
      "epoch:24 step:19410 [D loss: 0.645378, acc.: 63.28%] [G loss: 0.814877]\n",
      "epoch:24 step:19411 [D loss: 0.661330, acc.: 60.94%] [G loss: 0.807338]\n",
      "epoch:24 step:19412 [D loss: 0.676349, acc.: 61.72%] [G loss: 0.770902]\n",
      "epoch:24 step:19413 [D loss: 0.668135, acc.: 60.16%] [G loss: 0.745610]\n",
      "epoch:24 step:19414 [D loss: 0.695402, acc.: 57.81%] [G loss: 0.784851]\n",
      "epoch:24 step:19415 [D loss: 0.681723, acc.: 57.81%] [G loss: 0.774056]\n",
      "epoch:24 step:19416 [D loss: 0.674890, acc.: 60.94%] [G loss: 0.742553]\n",
      "epoch:24 step:19417 [D loss: 0.676209, acc.: 57.81%] [G loss: 0.759662]\n",
      "epoch:24 step:19418 [D loss: 0.761093, acc.: 33.59%] [G loss: 0.673171]\n",
      "epoch:24 step:19419 [D loss: 0.681675, acc.: 57.03%] [G loss: 0.739143]\n",
      "epoch:24 step:19420 [D loss: 0.703713, acc.: 54.69%] [G loss: 0.688926]\n",
      "epoch:24 step:19421 [D loss: 0.663516, acc.: 58.59%] [G loss: 0.678262]\n",
      "epoch:24 step:19422 [D loss: 0.714118, acc.: 42.97%] [G loss: 0.748803]\n",
      "epoch:24 step:19423 [D loss: 0.672492, acc.: 58.59%] [G loss: 0.761874]\n",
      "epoch:24 step:19424 [D loss: 0.676397, acc.: 56.25%] [G loss: 0.735173]\n",
      "epoch:24 step:19425 [D loss: 0.678607, acc.: 57.03%] [G loss: 0.765797]\n",
      "epoch:24 step:19426 [D loss: 0.712864, acc.: 46.09%] [G loss: 0.771363]\n",
      "epoch:24 step:19427 [D loss: 0.737663, acc.: 39.84%] [G loss: 0.704044]\n",
      "epoch:24 step:19428 [D loss: 0.697759, acc.: 56.25%] [G loss: 0.780963]\n",
      "epoch:24 step:19429 [D loss: 0.758036, acc.: 29.69%] [G loss: 0.765310]\n",
      "epoch:24 step:19430 [D loss: 0.778100, acc.: 30.47%] [G loss: 0.761349]\n",
      "epoch:24 step:19431 [D loss: 0.664443, acc.: 60.16%] [G loss: 0.804437]\n",
      "epoch:24 step:19432 [D loss: 0.731175, acc.: 43.75%] [G loss: 0.792604]\n",
      "epoch:24 step:19433 [D loss: 0.697254, acc.: 57.81%] [G loss: 0.836126]\n",
      "epoch:24 step:19434 [D loss: 0.683946, acc.: 55.47%] [G loss: 0.821514]\n",
      "epoch:24 step:19435 [D loss: 0.695822, acc.: 44.53%] [G loss: 0.783726]\n",
      "epoch:24 step:19436 [D loss: 0.741475, acc.: 48.44%] [G loss: 0.768135]\n",
      "epoch:24 step:19437 [D loss: 0.698105, acc.: 50.00%] [G loss: 0.696515]\n",
      "epoch:24 step:19438 [D loss: 0.672478, acc.: 58.59%] [G loss: 0.695368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19439 [D loss: 0.676416, acc.: 63.28%] [G loss: 0.722494]\n",
      "epoch:24 step:19440 [D loss: 0.698695, acc.: 55.47%] [G loss: 0.698104]\n",
      "epoch:24 step:19441 [D loss: 0.739513, acc.: 40.62%] [G loss: 0.696555]\n",
      "epoch:24 step:19442 [D loss: 0.625204, acc.: 67.97%] [G loss: 0.684460]\n",
      "epoch:24 step:19443 [D loss: 0.698597, acc.: 50.00%] [G loss: 0.712360]\n",
      "epoch:24 step:19444 [D loss: 0.642671, acc.: 65.62%] [G loss: 0.742750]\n",
      "epoch:24 step:19445 [D loss: 0.684604, acc.: 57.81%] [G loss: 0.783543]\n",
      "epoch:24 step:19446 [D loss: 0.689237, acc.: 56.25%] [G loss: 0.744136]\n",
      "epoch:24 step:19447 [D loss: 0.743284, acc.: 39.84%] [G loss: 0.715969]\n",
      "epoch:24 step:19448 [D loss: 0.755504, acc.: 32.81%] [G loss: 0.721919]\n",
      "epoch:24 step:19449 [D loss: 0.677490, acc.: 58.59%] [G loss: 0.761118]\n",
      "epoch:24 step:19450 [D loss: 0.658847, acc.: 62.50%] [G loss: 0.725852]\n",
      "epoch:24 step:19451 [D loss: 0.690821, acc.: 53.91%] [G loss: 0.737182]\n",
      "epoch:24 step:19452 [D loss: 0.682913, acc.: 57.81%] [G loss: 0.718264]\n",
      "epoch:24 step:19453 [D loss: 0.686114, acc.: 59.38%] [G loss: 0.691449]\n",
      "epoch:24 step:19454 [D loss: 0.704303, acc.: 48.44%] [G loss: 0.763262]\n",
      "epoch:24 step:19455 [D loss: 0.694199, acc.: 51.56%] [G loss: 0.746073]\n",
      "epoch:24 step:19456 [D loss: 0.650174, acc.: 61.72%] [G loss: 0.800831]\n",
      "epoch:24 step:19457 [D loss: 0.698273, acc.: 46.88%] [G loss: 0.825278]\n",
      "epoch:24 step:19458 [D loss: 0.676734, acc.: 57.03%] [G loss: 0.845098]\n",
      "epoch:24 step:19459 [D loss: 0.671446, acc.: 56.25%] [G loss: 0.833727]\n",
      "epoch:24 step:19460 [D loss: 0.677315, acc.: 62.50%] [G loss: 0.783497]\n",
      "epoch:24 step:19461 [D loss: 0.648156, acc.: 67.19%] [G loss: 0.817297]\n",
      "epoch:24 step:19462 [D loss: 0.680874, acc.: 57.81%] [G loss: 0.731341]\n",
      "epoch:24 step:19463 [D loss: 0.653989, acc.: 62.50%] [G loss: 0.778985]\n",
      "epoch:24 step:19464 [D loss: 0.706478, acc.: 51.56%] [G loss: 0.669171]\n",
      "epoch:24 step:19465 [D loss: 0.731503, acc.: 44.53%] [G loss: 0.719669]\n",
      "epoch:24 step:19466 [D loss: 0.687592, acc.: 55.47%] [G loss: 0.778628]\n",
      "epoch:24 step:19467 [D loss: 0.713246, acc.: 49.22%] [G loss: 0.719866]\n",
      "epoch:24 step:19468 [D loss: 0.678544, acc.: 60.16%] [G loss: 0.697772]\n",
      "epoch:24 step:19469 [D loss: 0.693048, acc.: 54.69%] [G loss: 0.725839]\n",
      "epoch:24 step:19470 [D loss: 0.624947, acc.: 71.09%] [G loss: 0.717524]\n",
      "epoch:24 step:19471 [D loss: 0.687774, acc.: 57.03%] [G loss: 0.790669]\n",
      "epoch:24 step:19472 [D loss: 0.703136, acc.: 53.91%] [G loss: 0.793069]\n",
      "epoch:24 step:19473 [D loss: 0.662606, acc.: 59.38%] [G loss: 0.788912]\n",
      "epoch:24 step:19474 [D loss: 0.687406, acc.: 56.25%] [G loss: 0.676805]\n",
      "epoch:24 step:19475 [D loss: 0.724401, acc.: 42.97%] [G loss: 0.747560]\n",
      "epoch:24 step:19476 [D loss: 0.656355, acc.: 60.94%] [G loss: 0.750995]\n",
      "epoch:24 step:19477 [D loss: 0.714820, acc.: 48.44%] [G loss: 0.773528]\n",
      "epoch:24 step:19478 [D loss: 0.715923, acc.: 47.66%] [G loss: 0.733440]\n",
      "epoch:24 step:19479 [D loss: 0.710210, acc.: 47.66%] [G loss: 0.795542]\n",
      "epoch:24 step:19480 [D loss: 0.648220, acc.: 71.09%] [G loss: 0.805656]\n",
      "epoch:24 step:19481 [D loss: 0.699265, acc.: 46.88%] [G loss: 0.771628]\n",
      "epoch:24 step:19482 [D loss: 0.716846, acc.: 45.31%] [G loss: 0.794483]\n",
      "epoch:24 step:19483 [D loss: 0.717140, acc.: 49.22%] [G loss: 0.773540]\n",
      "epoch:24 step:19484 [D loss: 0.676193, acc.: 58.59%] [G loss: 0.807566]\n",
      "epoch:24 step:19485 [D loss: 0.643042, acc.: 63.28%] [G loss: 0.766566]\n",
      "epoch:24 step:19486 [D loss: 0.669258, acc.: 63.28%] [G loss: 0.762193]\n",
      "epoch:24 step:19487 [D loss: 0.666467, acc.: 55.47%] [G loss: 0.701196]\n",
      "epoch:24 step:19488 [D loss: 0.636341, acc.: 67.19%] [G loss: 0.704561]\n",
      "epoch:24 step:19489 [D loss: 0.746806, acc.: 32.81%] [G loss: 0.706686]\n",
      "epoch:24 step:19490 [D loss: 0.685325, acc.: 60.16%] [G loss: 0.758590]\n",
      "epoch:24 step:19491 [D loss: 0.672559, acc.: 57.03%] [G loss: 0.676363]\n",
      "epoch:24 step:19492 [D loss: 0.697547, acc.: 50.78%] [G loss: 0.722096]\n",
      "epoch:24 step:19493 [D loss: 0.703572, acc.: 53.12%] [G loss: 0.715054]\n",
      "epoch:24 step:19494 [D loss: 0.675222, acc.: 58.59%] [G loss: 0.695921]\n",
      "epoch:24 step:19495 [D loss: 0.657988, acc.: 64.84%] [G loss: 0.717477]\n",
      "epoch:24 step:19496 [D loss: 0.685049, acc.: 57.03%] [G loss: 0.751926]\n",
      "epoch:24 step:19497 [D loss: 0.713897, acc.: 41.41%] [G loss: 0.771426]\n",
      "epoch:24 step:19498 [D loss: 0.695448, acc.: 51.56%] [G loss: 0.726187]\n",
      "epoch:24 step:19499 [D loss: 0.711385, acc.: 50.00%] [G loss: 0.689821]\n",
      "epoch:24 step:19500 [D loss: 0.678465, acc.: 60.16%] [G loss: 0.710144]\n",
      "epoch:24 step:19501 [D loss: 0.684585, acc.: 48.44%] [G loss: 0.758875]\n",
      "epoch:24 step:19502 [D loss: 0.745087, acc.: 41.41%] [G loss: 0.722877]\n",
      "epoch:24 step:19503 [D loss: 0.729764, acc.: 46.09%] [G loss: 0.719017]\n",
      "epoch:24 step:19504 [D loss: 0.733001, acc.: 42.19%] [G loss: 0.685658]\n",
      "epoch:24 step:19505 [D loss: 0.682275, acc.: 51.56%] [G loss: 0.821782]\n",
      "epoch:24 step:19506 [D loss: 0.711339, acc.: 43.75%] [G loss: 0.782899]\n",
      "epoch:24 step:19507 [D loss: 0.721610, acc.: 50.00%] [G loss: 0.828002]\n",
      "epoch:24 step:19508 [D loss: 0.705261, acc.: 49.22%] [G loss: 0.839038]\n",
      "epoch:24 step:19509 [D loss: 0.699118, acc.: 50.78%] [G loss: 0.850281]\n",
      "epoch:24 step:19510 [D loss: 0.712244, acc.: 50.00%] [G loss: 0.848941]\n",
      "epoch:24 step:19511 [D loss: 0.681540, acc.: 54.69%] [G loss: 0.782049]\n",
      "epoch:24 step:19512 [D loss: 0.676554, acc.: 57.81%] [G loss: 0.778330]\n",
      "epoch:24 step:19513 [D loss: 0.668104, acc.: 61.72%] [G loss: 0.863734]\n",
      "epoch:24 step:19514 [D loss: 0.685030, acc.: 53.12%] [G loss: 0.817103]\n",
      "epoch:24 step:19515 [D loss: 0.717321, acc.: 41.41%] [G loss: 0.851025]\n",
      "epoch:24 step:19516 [D loss: 0.710011, acc.: 48.44%] [G loss: 0.775299]\n",
      "epoch:24 step:19517 [D loss: 0.677651, acc.: 55.47%] [G loss: 0.741521]\n",
      "epoch:24 step:19518 [D loss: 0.652008, acc.: 68.75%] [G loss: 0.753029]\n",
      "epoch:24 step:19519 [D loss: 0.685535, acc.: 53.12%] [G loss: 0.746594]\n",
      "epoch:24 step:19520 [D loss: 0.706033, acc.: 52.34%] [G loss: 0.763567]\n",
      "epoch:24 step:19521 [D loss: 0.655036, acc.: 64.06%] [G loss: 0.733454]\n",
      "epoch:24 step:19522 [D loss: 0.716960, acc.: 50.00%] [G loss: 0.789225]\n",
      "epoch:24 step:19523 [D loss: 0.716075, acc.: 50.78%] [G loss: 0.767215]\n",
      "epoch:24 step:19524 [D loss: 0.692029, acc.: 53.12%] [G loss: 0.794992]\n",
      "epoch:24 step:19525 [D loss: 0.672816, acc.: 57.03%] [G loss: 0.853875]\n",
      "epoch:25 step:19526 [D loss: 0.686924, acc.: 57.81%] [G loss: 0.725684]\n",
      "epoch:25 step:19527 [D loss: 0.689369, acc.: 54.69%] [G loss: 0.785342]\n",
      "epoch:25 step:19528 [D loss: 0.665140, acc.: 60.16%] [G loss: 0.695998]\n",
      "epoch:25 step:19529 [D loss: 0.665908, acc.: 64.06%] [G loss: 0.826645]\n",
      "epoch:25 step:19530 [D loss: 0.736848, acc.: 46.09%] [G loss: 0.731553]\n",
      "epoch:25 step:19531 [D loss: 0.710095, acc.: 48.44%] [G loss: 0.694942]\n",
      "epoch:25 step:19532 [D loss: 0.696553, acc.: 48.44%] [G loss: 0.758241]\n",
      "epoch:25 step:19533 [D loss: 0.684625, acc.: 57.81%] [G loss: 0.791034]\n",
      "epoch:25 step:19534 [D loss: 0.648523, acc.: 64.06%] [G loss: 0.816467]\n",
      "epoch:25 step:19535 [D loss: 0.692798, acc.: 57.03%] [G loss: 0.711838]\n",
      "epoch:25 step:19536 [D loss: 0.675012, acc.: 57.03%] [G loss: 0.711641]\n",
      "epoch:25 step:19537 [D loss: 0.713497, acc.: 46.88%] [G loss: 0.657489]\n",
      "epoch:25 step:19538 [D loss: 0.690814, acc.: 53.12%] [G loss: 0.738926]\n",
      "epoch:25 step:19539 [D loss: 0.694103, acc.: 50.00%] [G loss: 0.746118]\n",
      "epoch:25 step:19540 [D loss: 0.722508, acc.: 47.66%] [G loss: 0.777308]\n",
      "epoch:25 step:19541 [D loss: 0.680356, acc.: 58.59%] [G loss: 0.749202]\n",
      "epoch:25 step:19542 [D loss: 0.743759, acc.: 39.06%] [G loss: 0.753276]\n",
      "epoch:25 step:19543 [D loss: 0.687567, acc.: 58.59%] [G loss: 0.773247]\n",
      "epoch:25 step:19544 [D loss: 0.674835, acc.: 57.81%] [G loss: 0.778561]\n",
      "epoch:25 step:19545 [D loss: 0.700929, acc.: 52.34%] [G loss: 0.785560]\n",
      "epoch:25 step:19546 [D loss: 0.710448, acc.: 49.22%] [G loss: 0.805002]\n",
      "epoch:25 step:19547 [D loss: 0.686351, acc.: 53.12%] [G loss: 0.768314]\n",
      "epoch:25 step:19548 [D loss: 0.695613, acc.: 50.78%] [G loss: 0.847124]\n",
      "epoch:25 step:19549 [D loss: 0.681888, acc.: 54.69%] [G loss: 0.819354]\n",
      "epoch:25 step:19550 [D loss: 0.700206, acc.: 57.81%] [G loss: 0.754957]\n",
      "epoch:25 step:19551 [D loss: 0.731627, acc.: 44.53%] [G loss: 0.753116]\n",
      "epoch:25 step:19552 [D loss: 0.656904, acc.: 64.84%] [G loss: 0.800317]\n",
      "epoch:25 step:19553 [D loss: 0.626055, acc.: 72.66%] [G loss: 0.830626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19554 [D loss: 0.660775, acc.: 60.94%] [G loss: 0.810292]\n",
      "epoch:25 step:19555 [D loss: 0.684168, acc.: 58.59%] [G loss: 0.748021]\n",
      "epoch:25 step:19556 [D loss: 0.667000, acc.: 57.03%] [G loss: 0.800472]\n",
      "epoch:25 step:19557 [D loss: 0.640880, acc.: 64.84%] [G loss: 0.842160]\n",
      "epoch:25 step:19558 [D loss: 0.645854, acc.: 64.06%] [G loss: 0.814168]\n",
      "epoch:25 step:19559 [D loss: 0.665733, acc.: 64.84%] [G loss: 0.758457]\n",
      "epoch:25 step:19560 [D loss: 0.700252, acc.: 47.66%] [G loss: 0.756940]\n",
      "epoch:25 step:19561 [D loss: 0.690233, acc.: 52.34%] [G loss: 0.755696]\n",
      "epoch:25 step:19562 [D loss: 0.683000, acc.: 54.69%] [G loss: 0.792961]\n",
      "epoch:25 step:19563 [D loss: 0.684781, acc.: 56.25%] [G loss: 0.755768]\n",
      "epoch:25 step:19564 [D loss: 0.671253, acc.: 60.94%] [G loss: 0.761389]\n",
      "epoch:25 step:19565 [D loss: 0.694378, acc.: 50.00%] [G loss: 0.772945]\n",
      "epoch:25 step:19566 [D loss: 0.667221, acc.: 59.38%] [G loss: 0.745397]\n",
      "epoch:25 step:19567 [D loss: 0.654911, acc.: 67.19%] [G loss: 0.791029]\n",
      "epoch:25 step:19568 [D loss: 0.716933, acc.: 47.66%] [G loss: 0.724359]\n",
      "epoch:25 step:19569 [D loss: 0.746318, acc.: 39.84%] [G loss: 0.745440]\n",
      "epoch:25 step:19570 [D loss: 0.704955, acc.: 55.47%] [G loss: 0.752041]\n",
      "epoch:25 step:19571 [D loss: 0.701472, acc.: 52.34%] [G loss: 0.709834]\n",
      "epoch:25 step:19572 [D loss: 0.740991, acc.: 37.50%] [G loss: 0.698839]\n",
      "epoch:25 step:19573 [D loss: 0.695686, acc.: 55.47%] [G loss: 0.780493]\n",
      "epoch:25 step:19574 [D loss: 0.712656, acc.: 43.75%] [G loss: 0.643622]\n",
      "epoch:25 step:19575 [D loss: 0.722352, acc.: 42.19%] [G loss: 0.653399]\n",
      "epoch:25 step:19576 [D loss: 0.737055, acc.: 43.75%] [G loss: 0.689189]\n",
      "epoch:25 step:19577 [D loss: 0.663622, acc.: 60.16%] [G loss: 0.791322]\n",
      "epoch:25 step:19578 [D loss: 0.724147, acc.: 47.66%] [G loss: 0.760988]\n",
      "epoch:25 step:19579 [D loss: 0.724738, acc.: 49.22%] [G loss: 0.818043]\n",
      "epoch:25 step:19580 [D loss: 0.676129, acc.: 55.47%] [G loss: 0.864370]\n",
      "epoch:25 step:19581 [D loss: 0.700286, acc.: 51.56%] [G loss: 0.810813]\n",
      "epoch:25 step:19582 [D loss: 0.701643, acc.: 49.22%] [G loss: 0.792522]\n",
      "epoch:25 step:19583 [D loss: 0.679609, acc.: 56.25%] [G loss: 0.758160]\n",
      "epoch:25 step:19584 [D loss: 0.658956, acc.: 63.28%] [G loss: 0.785794]\n",
      "epoch:25 step:19585 [D loss: 0.659092, acc.: 60.94%] [G loss: 0.914294]\n",
      "epoch:25 step:19586 [D loss: 0.704157, acc.: 49.22%] [G loss: 0.816338]\n",
      "epoch:25 step:19587 [D loss: 0.687026, acc.: 51.56%] [G loss: 0.859436]\n",
      "epoch:25 step:19588 [D loss: 0.659088, acc.: 62.50%] [G loss: 0.881747]\n",
      "epoch:25 step:19589 [D loss: 0.667630, acc.: 60.16%] [G loss: 0.834009]\n",
      "epoch:25 step:19590 [D loss: 0.687660, acc.: 58.59%] [G loss: 0.854589]\n",
      "epoch:25 step:19591 [D loss: 0.693911, acc.: 51.56%] [G loss: 0.776590]\n",
      "epoch:25 step:19592 [D loss: 0.718582, acc.: 43.75%] [G loss: 0.757007]\n",
      "epoch:25 step:19593 [D loss: 0.677606, acc.: 61.72%] [G loss: 0.759707]\n",
      "epoch:25 step:19594 [D loss: 0.693806, acc.: 52.34%] [G loss: 0.805709]\n",
      "epoch:25 step:19595 [D loss: 0.714404, acc.: 49.22%] [G loss: 0.761571]\n",
      "epoch:25 step:19596 [D loss: 0.669075, acc.: 60.16%] [G loss: 0.726109]\n",
      "epoch:25 step:19597 [D loss: 0.712226, acc.: 42.97%] [G loss: 0.759363]\n",
      "epoch:25 step:19598 [D loss: 0.667805, acc.: 58.59%] [G loss: 0.770482]\n",
      "epoch:25 step:19599 [D loss: 0.653903, acc.: 64.84%] [G loss: 0.838004]\n",
      "epoch:25 step:19600 [D loss: 0.650458, acc.: 64.84%] [G loss: 0.762084]\n",
      "epoch:25 step:19601 [D loss: 0.729839, acc.: 48.44%] [G loss: 0.776260]\n",
      "epoch:25 step:19602 [D loss: 0.728890, acc.: 46.88%] [G loss: 0.769074]\n",
      "epoch:25 step:19603 [D loss: 0.714136, acc.: 45.31%] [G loss: 0.802383]\n",
      "epoch:25 step:19604 [D loss: 0.674227, acc.: 64.06%] [G loss: 0.827266]\n",
      "epoch:25 step:19605 [D loss: 0.717101, acc.: 45.31%] [G loss: 0.738718]\n",
      "epoch:25 step:19606 [D loss: 0.702504, acc.: 55.47%] [G loss: 0.690741]\n",
      "epoch:25 step:19607 [D loss: 0.707175, acc.: 45.31%] [G loss: 0.758212]\n",
      "epoch:25 step:19608 [D loss: 0.649034, acc.: 61.72%] [G loss: 0.782293]\n",
      "epoch:25 step:19609 [D loss: 0.710386, acc.: 52.34%] [G loss: 0.748277]\n",
      "epoch:25 step:19610 [D loss: 0.660524, acc.: 60.16%] [G loss: 0.776896]\n",
      "epoch:25 step:19611 [D loss: 0.671145, acc.: 58.59%] [G loss: 0.673218]\n",
      "epoch:25 step:19612 [D loss: 0.689140, acc.: 52.34%] [G loss: 0.786909]\n",
      "epoch:25 step:19613 [D loss: 0.666951, acc.: 58.59%] [G loss: 0.787379]\n",
      "epoch:25 step:19614 [D loss: 0.722555, acc.: 49.22%] [G loss: 0.760018]\n",
      "epoch:25 step:19615 [D loss: 0.681749, acc.: 52.34%] [G loss: 0.807906]\n",
      "epoch:25 step:19616 [D loss: 0.727334, acc.: 48.44%] [G loss: 0.798819]\n",
      "epoch:25 step:19617 [D loss: 0.679039, acc.: 60.94%] [G loss: 0.792431]\n",
      "epoch:25 step:19618 [D loss: 0.687242, acc.: 53.91%] [G loss: 0.748728]\n",
      "epoch:25 step:19619 [D loss: 0.676436, acc.: 55.47%] [G loss: 0.775218]\n",
      "epoch:25 step:19620 [D loss: 0.706250, acc.: 53.12%] [G loss: 0.743030]\n",
      "epoch:25 step:19621 [D loss: 0.698423, acc.: 55.47%] [G loss: 0.793579]\n",
      "epoch:25 step:19622 [D loss: 0.671780, acc.: 60.94%] [G loss: 0.853816]\n",
      "epoch:25 step:19623 [D loss: 0.719473, acc.: 45.31%] [G loss: 0.768198]\n",
      "epoch:25 step:19624 [D loss: 0.693593, acc.: 57.81%] [G loss: 0.807688]\n",
      "epoch:25 step:19625 [D loss: 0.729421, acc.: 43.75%] [G loss: 0.763025]\n",
      "epoch:25 step:19626 [D loss: 0.708248, acc.: 47.66%] [G loss: 0.762175]\n",
      "epoch:25 step:19627 [D loss: 0.693439, acc.: 52.34%] [G loss: 0.804195]\n",
      "epoch:25 step:19628 [D loss: 0.718264, acc.: 45.31%] [G loss: 0.736744]\n",
      "epoch:25 step:19629 [D loss: 0.709008, acc.: 50.00%] [G loss: 0.718658]\n",
      "epoch:25 step:19630 [D loss: 0.684236, acc.: 54.69%] [G loss: 0.809711]\n",
      "epoch:25 step:19631 [D loss: 0.667144, acc.: 57.81%] [G loss: 0.838175]\n",
      "epoch:25 step:19632 [D loss: 0.685561, acc.: 55.47%] [G loss: 0.769959]\n",
      "epoch:25 step:19633 [D loss: 0.727503, acc.: 42.19%] [G loss: 0.783310]\n",
      "epoch:25 step:19634 [D loss: 0.649075, acc.: 64.84%] [G loss: 0.732562]\n",
      "epoch:25 step:19635 [D loss: 0.659288, acc.: 64.84%] [G loss: 0.718460]\n",
      "epoch:25 step:19636 [D loss: 0.686542, acc.: 57.81%] [G loss: 0.767227]\n",
      "epoch:25 step:19637 [D loss: 0.722918, acc.: 55.47%] [G loss: 0.765097]\n",
      "epoch:25 step:19638 [D loss: 0.655298, acc.: 62.50%] [G loss: 0.746816]\n",
      "epoch:25 step:19639 [D loss: 0.678912, acc.: 56.25%] [G loss: 0.758198]\n",
      "epoch:25 step:19640 [D loss: 0.715553, acc.: 44.53%] [G loss: 0.767940]\n",
      "epoch:25 step:19641 [D loss: 0.699989, acc.: 49.22%] [G loss: 0.734709]\n",
      "epoch:25 step:19642 [D loss: 0.723696, acc.: 42.19%] [G loss: 0.710225]\n",
      "epoch:25 step:19643 [D loss: 0.688884, acc.: 53.91%] [G loss: 0.725315]\n",
      "epoch:25 step:19644 [D loss: 0.688966, acc.: 53.12%] [G loss: 0.691297]\n",
      "epoch:25 step:19645 [D loss: 0.695774, acc.: 56.25%] [G loss: 0.725464]\n",
      "epoch:25 step:19646 [D loss: 0.695434, acc.: 60.16%] [G loss: 0.781197]\n",
      "epoch:25 step:19647 [D loss: 0.691223, acc.: 53.12%] [G loss: 0.756045]\n",
      "epoch:25 step:19648 [D loss: 0.676545, acc.: 57.03%] [G loss: 0.727537]\n",
      "epoch:25 step:19649 [D loss: 0.705478, acc.: 51.56%] [G loss: 0.718340]\n",
      "epoch:25 step:19650 [D loss: 0.719678, acc.: 47.66%] [G loss: 0.707443]\n",
      "epoch:25 step:19651 [D loss: 0.737953, acc.: 44.53%] [G loss: 0.727167]\n",
      "epoch:25 step:19652 [D loss: 0.706893, acc.: 45.31%] [G loss: 0.724369]\n",
      "epoch:25 step:19653 [D loss: 0.716065, acc.: 40.62%] [G loss: 0.673698]\n",
      "epoch:25 step:19654 [D loss: 0.707573, acc.: 51.56%] [G loss: 0.777658]\n",
      "epoch:25 step:19655 [D loss: 0.712928, acc.: 46.09%] [G loss: 0.722136]\n",
      "epoch:25 step:19656 [D loss: 0.668859, acc.: 57.03%] [G loss: 0.717154]\n",
      "epoch:25 step:19657 [D loss: 0.664663, acc.: 58.59%] [G loss: 0.822782]\n",
      "epoch:25 step:19658 [D loss: 0.700776, acc.: 47.66%] [G loss: 0.755671]\n",
      "epoch:25 step:19659 [D loss: 0.682866, acc.: 57.03%] [G loss: 0.767129]\n",
      "epoch:25 step:19660 [D loss: 0.694157, acc.: 54.69%] [G loss: 0.757471]\n",
      "epoch:25 step:19661 [D loss: 0.682035, acc.: 58.59%] [G loss: 0.804930]\n",
      "epoch:25 step:19662 [D loss: 0.753564, acc.: 39.84%] [G loss: 0.727098]\n",
      "epoch:25 step:19663 [D loss: 0.718351, acc.: 50.00%] [G loss: 0.755898]\n",
      "epoch:25 step:19664 [D loss: 0.657943, acc.: 68.75%] [G loss: 0.699202]\n",
      "epoch:25 step:19665 [D loss: 0.726954, acc.: 46.88%] [G loss: 0.725663]\n",
      "epoch:25 step:19666 [D loss: 0.623814, acc.: 68.75%] [G loss: 0.804558]\n",
      "epoch:25 step:19667 [D loss: 0.703144, acc.: 50.00%] [G loss: 0.712418]\n",
      "epoch:25 step:19668 [D loss: 0.697584, acc.: 48.44%] [G loss: 0.767470]\n",
      "epoch:25 step:19669 [D loss: 0.717845, acc.: 42.19%] [G loss: 0.793665]\n",
      "epoch:25 step:19670 [D loss: 0.693542, acc.: 53.91%] [G loss: 0.817868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19671 [D loss: 0.632384, acc.: 68.75%] [G loss: 0.776727]\n",
      "epoch:25 step:19672 [D loss: 0.646546, acc.: 63.28%] [G loss: 0.780066]\n",
      "epoch:25 step:19673 [D loss: 0.703811, acc.: 53.12%] [G loss: 0.780240]\n",
      "epoch:25 step:19674 [D loss: 0.672153, acc.: 55.47%] [G loss: 0.740568]\n",
      "epoch:25 step:19675 [D loss: 0.672508, acc.: 62.50%] [G loss: 0.734198]\n",
      "epoch:25 step:19676 [D loss: 0.685332, acc.: 60.16%] [G loss: 0.700942]\n",
      "epoch:25 step:19677 [D loss: 0.720921, acc.: 42.97%] [G loss: 0.726585]\n",
      "epoch:25 step:19678 [D loss: 0.690574, acc.: 56.25%] [G loss: 0.723214]\n",
      "epoch:25 step:19679 [D loss: 0.661413, acc.: 59.38%] [G loss: 0.734859]\n",
      "epoch:25 step:19680 [D loss: 0.686404, acc.: 55.47%] [G loss: 0.768663]\n",
      "epoch:25 step:19681 [D loss: 0.740351, acc.: 40.62%] [G loss: 0.763389]\n",
      "epoch:25 step:19682 [D loss: 0.676740, acc.: 55.47%] [G loss: 0.750075]\n",
      "epoch:25 step:19683 [D loss: 0.690130, acc.: 50.00%] [G loss: 0.745116]\n",
      "epoch:25 step:19684 [D loss: 0.653683, acc.: 56.25%] [G loss: 0.813273]\n",
      "epoch:25 step:19685 [D loss: 0.656113, acc.: 60.94%] [G loss: 0.802392]\n",
      "epoch:25 step:19686 [D loss: 0.748654, acc.: 36.72%] [G loss: 0.780799]\n",
      "epoch:25 step:19687 [D loss: 0.692105, acc.: 49.22%] [G loss: 0.762329]\n",
      "epoch:25 step:19688 [D loss: 0.688880, acc.: 57.81%] [G loss: 0.790144]\n",
      "epoch:25 step:19689 [D loss: 0.660982, acc.: 62.50%] [G loss: 0.764342]\n",
      "epoch:25 step:19690 [D loss: 0.690677, acc.: 50.00%] [G loss: 0.783329]\n",
      "epoch:25 step:19691 [D loss: 0.695643, acc.: 56.25%] [G loss: 0.767441]\n",
      "epoch:25 step:19692 [D loss: 0.716343, acc.: 43.75%] [G loss: 0.734274]\n",
      "epoch:25 step:19693 [D loss: 0.705984, acc.: 48.44%] [G loss: 0.809580]\n",
      "epoch:25 step:19694 [D loss: 0.688527, acc.: 53.91%] [G loss: 0.748888]\n",
      "epoch:25 step:19695 [D loss: 0.675523, acc.: 56.25%] [G loss: 0.798395]\n",
      "epoch:25 step:19696 [D loss: 0.721808, acc.: 45.31%] [G loss: 0.760418]\n",
      "epoch:25 step:19697 [D loss: 0.703609, acc.: 51.56%] [G loss: 0.799659]\n",
      "epoch:25 step:19698 [D loss: 0.738049, acc.: 37.50%] [G loss: 0.748455]\n",
      "epoch:25 step:19699 [D loss: 0.689877, acc.: 56.25%] [G loss: 0.873270]\n",
      "epoch:25 step:19700 [D loss: 0.680878, acc.: 59.38%] [G loss: 0.721623]\n",
      "epoch:25 step:19701 [D loss: 0.675355, acc.: 57.81%] [G loss: 0.803783]\n",
      "epoch:25 step:19702 [D loss: 0.652245, acc.: 67.19%] [G loss: 0.776305]\n",
      "epoch:25 step:19703 [D loss: 0.707527, acc.: 48.44%] [G loss: 0.759462]\n",
      "epoch:25 step:19704 [D loss: 0.697470, acc.: 47.66%] [G loss: 0.795415]\n",
      "epoch:25 step:19705 [D loss: 0.698984, acc.: 50.78%] [G loss: 0.736488]\n",
      "epoch:25 step:19706 [D loss: 0.635547, acc.: 69.53%] [G loss: 0.781014]\n",
      "epoch:25 step:19707 [D loss: 0.785538, acc.: 35.16%] [G loss: 0.678740]\n",
      "epoch:25 step:19708 [D loss: 0.726100, acc.: 41.41%] [G loss: 0.701627]\n",
      "epoch:25 step:19709 [D loss: 0.673931, acc.: 57.03%] [G loss: 0.785710]\n",
      "epoch:25 step:19710 [D loss: 0.678249, acc.: 58.59%] [G loss: 0.806713]\n",
      "epoch:25 step:19711 [D loss: 0.694430, acc.: 50.00%] [G loss: 0.791813]\n",
      "epoch:25 step:19712 [D loss: 0.668075, acc.: 58.59%] [G loss: 0.787067]\n",
      "epoch:25 step:19713 [D loss: 0.732776, acc.: 43.75%] [G loss: 0.741662]\n",
      "epoch:25 step:19714 [D loss: 0.664441, acc.: 58.59%] [G loss: 0.719803]\n",
      "epoch:25 step:19715 [D loss: 0.671378, acc.: 52.34%] [G loss: 0.786579]\n",
      "epoch:25 step:19716 [D loss: 0.674098, acc.: 60.16%] [G loss: 0.753746]\n",
      "epoch:25 step:19717 [D loss: 0.703507, acc.: 50.78%] [G loss: 0.748232]\n",
      "epoch:25 step:19718 [D loss: 0.748653, acc.: 42.19%] [G loss: 0.781111]\n",
      "epoch:25 step:19719 [D loss: 0.717487, acc.: 47.66%] [G loss: 0.731489]\n",
      "epoch:25 step:19720 [D loss: 0.746290, acc.: 35.94%] [G loss: 0.766525]\n",
      "epoch:25 step:19721 [D loss: 0.703678, acc.: 50.78%] [G loss: 0.776597]\n",
      "epoch:25 step:19722 [D loss: 0.679552, acc.: 50.78%] [G loss: 0.762836]\n",
      "epoch:25 step:19723 [D loss: 0.669382, acc.: 57.03%] [G loss: 0.749098]\n",
      "epoch:25 step:19724 [D loss: 0.698280, acc.: 55.47%] [G loss: 0.719571]\n",
      "epoch:25 step:19725 [D loss: 0.671403, acc.: 62.50%] [G loss: 0.798265]\n",
      "epoch:25 step:19726 [D loss: 0.665253, acc.: 64.84%] [G loss: 0.788480]\n",
      "epoch:25 step:19727 [D loss: 0.726164, acc.: 50.00%] [G loss: 0.788286]\n",
      "epoch:25 step:19728 [D loss: 0.658376, acc.: 64.06%] [G loss: 0.821248]\n",
      "epoch:25 step:19729 [D loss: 0.694492, acc.: 51.56%] [G loss: 0.758207]\n",
      "epoch:25 step:19730 [D loss: 0.693345, acc.: 53.12%] [G loss: 0.778926]\n",
      "epoch:25 step:19731 [D loss: 0.707190, acc.: 48.44%] [G loss: 0.781841]\n",
      "epoch:25 step:19732 [D loss: 0.647893, acc.: 68.75%] [G loss: 0.799204]\n",
      "epoch:25 step:19733 [D loss: 0.698720, acc.: 50.00%] [G loss: 0.755752]\n",
      "epoch:25 step:19734 [D loss: 0.675038, acc.: 58.59%] [G loss: 0.770526]\n",
      "epoch:25 step:19735 [D loss: 0.648362, acc.: 61.72%] [G loss: 0.850051]\n",
      "epoch:25 step:19736 [D loss: 0.662437, acc.: 61.72%] [G loss: 0.825618]\n",
      "epoch:25 step:19737 [D loss: 0.700899, acc.: 45.31%] [G loss: 0.728779]\n",
      "epoch:25 step:19738 [D loss: 0.711564, acc.: 48.44%] [G loss: 0.735432]\n",
      "epoch:25 step:19739 [D loss: 0.706681, acc.: 52.34%] [G loss: 0.768865]\n",
      "epoch:25 step:19740 [D loss: 0.653689, acc.: 66.41%] [G loss: 0.752505]\n",
      "epoch:25 step:19741 [D loss: 0.693630, acc.: 53.12%] [G loss: 0.720921]\n",
      "epoch:25 step:19742 [D loss: 0.650166, acc.: 62.50%] [G loss: 0.751358]\n",
      "epoch:25 step:19743 [D loss: 0.723700, acc.: 42.97%] [G loss: 0.792510]\n",
      "epoch:25 step:19744 [D loss: 0.642032, acc.: 64.06%] [G loss: 0.805560]\n",
      "epoch:25 step:19745 [D loss: 0.646935, acc.: 65.62%] [G loss: 0.781898]\n",
      "epoch:25 step:19746 [D loss: 0.695506, acc.: 59.38%] [G loss: 0.730948]\n",
      "epoch:25 step:19747 [D loss: 0.698612, acc.: 55.47%] [G loss: 0.720206]\n",
      "epoch:25 step:19748 [D loss: 0.741019, acc.: 41.41%] [G loss: 0.682331]\n",
      "epoch:25 step:19749 [D loss: 0.632280, acc.: 68.75%] [G loss: 0.714866]\n",
      "epoch:25 step:19750 [D loss: 0.716416, acc.: 50.00%] [G loss: 0.735322]\n",
      "epoch:25 step:19751 [D loss: 0.721281, acc.: 46.88%] [G loss: 0.734545]\n",
      "epoch:25 step:19752 [D loss: 0.703963, acc.: 53.91%] [G loss: 0.757104]\n",
      "epoch:25 step:19753 [D loss: 0.688221, acc.: 59.38%] [G loss: 0.744201]\n",
      "epoch:25 step:19754 [D loss: 0.681445, acc.: 53.12%] [G loss: 0.776487]\n",
      "epoch:25 step:19755 [D loss: 0.704221, acc.: 48.44%] [G loss: 0.716814]\n",
      "epoch:25 step:19756 [D loss: 0.697987, acc.: 54.69%] [G loss: 0.818878]\n",
      "epoch:25 step:19757 [D loss: 0.726841, acc.: 47.66%] [G loss: 0.737905]\n",
      "epoch:25 step:19758 [D loss: 0.678273, acc.: 64.06%] [G loss: 0.770430]\n",
      "epoch:25 step:19759 [D loss: 0.722656, acc.: 45.31%] [G loss: 0.776933]\n",
      "epoch:25 step:19760 [D loss: 0.681433, acc.: 56.25%] [G loss: 0.774074]\n",
      "epoch:25 step:19761 [D loss: 0.694869, acc.: 58.59%] [G loss: 0.708250]\n",
      "epoch:25 step:19762 [D loss: 0.717381, acc.: 46.88%] [G loss: 0.713822]\n",
      "epoch:25 step:19763 [D loss: 0.701911, acc.: 57.03%] [G loss: 0.729933]\n",
      "epoch:25 step:19764 [D loss: 0.633554, acc.: 69.53%] [G loss: 0.824606]\n",
      "epoch:25 step:19765 [D loss: 0.679734, acc.: 62.50%] [G loss: 0.773908]\n",
      "epoch:25 step:19766 [D loss: 0.728903, acc.: 41.41%] [G loss: 0.752653]\n",
      "epoch:25 step:19767 [D loss: 0.663776, acc.: 64.84%] [G loss: 0.759444]\n",
      "epoch:25 step:19768 [D loss: 0.704103, acc.: 50.78%] [G loss: 0.777720]\n",
      "epoch:25 step:19769 [D loss: 0.642423, acc.: 71.88%] [G loss: 0.743102]\n",
      "epoch:25 step:19770 [D loss: 0.698865, acc.: 46.09%] [G loss: 0.772788]\n",
      "epoch:25 step:19771 [D loss: 0.674858, acc.: 58.59%] [G loss: 0.759851]\n",
      "epoch:25 step:19772 [D loss: 0.652080, acc.: 66.41%] [G loss: 0.730439]\n",
      "epoch:25 step:19773 [D loss: 0.686393, acc.: 57.81%] [G loss: 0.695738]\n",
      "epoch:25 step:19774 [D loss: 0.720305, acc.: 51.56%] [G loss: 0.735836]\n",
      "epoch:25 step:19775 [D loss: 0.707581, acc.: 47.66%] [G loss: 0.687012]\n",
      "epoch:25 step:19776 [D loss: 0.674185, acc.: 59.38%] [G loss: 0.707184]\n",
      "epoch:25 step:19777 [D loss: 0.667953, acc.: 61.72%] [G loss: 0.708883]\n",
      "epoch:25 step:19778 [D loss: 0.671556, acc.: 57.81%] [G loss: 0.716965]\n",
      "epoch:25 step:19779 [D loss: 0.704477, acc.: 46.88%] [G loss: 0.811292]\n",
      "epoch:25 step:19780 [D loss: 0.695132, acc.: 53.12%] [G loss: 0.733482]\n",
      "epoch:25 step:19781 [D loss: 0.721566, acc.: 45.31%] [G loss: 0.736037]\n",
      "epoch:25 step:19782 [D loss: 0.700321, acc.: 56.25%] [G loss: 0.784992]\n",
      "epoch:25 step:19783 [D loss: 0.691164, acc.: 46.09%] [G loss: 0.780567]\n",
      "epoch:25 step:19784 [D loss: 0.677666, acc.: 58.59%] [G loss: 0.805251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19785 [D loss: 0.673489, acc.: 60.94%] [G loss: 0.803849]\n",
      "epoch:25 step:19786 [D loss: 0.707170, acc.: 52.34%] [G loss: 0.765816]\n",
      "epoch:25 step:19787 [D loss: 0.677038, acc.: 54.69%] [G loss: 0.788912]\n",
      "epoch:25 step:19788 [D loss: 0.718053, acc.: 43.75%] [G loss: 0.782819]\n",
      "epoch:25 step:19789 [D loss: 0.707637, acc.: 45.31%] [G loss: 0.789603]\n",
      "epoch:25 step:19790 [D loss: 0.707205, acc.: 45.31%] [G loss: 0.791691]\n",
      "epoch:25 step:19791 [D loss: 0.709932, acc.: 43.75%] [G loss: 0.715990]\n",
      "epoch:25 step:19792 [D loss: 0.772089, acc.: 35.94%] [G loss: 0.691057]\n",
      "epoch:25 step:19793 [D loss: 0.698593, acc.: 51.56%] [G loss: 0.729533]\n",
      "epoch:25 step:19794 [D loss: 0.671983, acc.: 60.94%] [G loss: 0.726754]\n",
      "epoch:25 step:19795 [D loss: 0.739872, acc.: 44.53%] [G loss: 0.668856]\n",
      "epoch:25 step:19796 [D loss: 0.692813, acc.: 48.44%] [G loss: 0.722535]\n",
      "epoch:25 step:19797 [D loss: 0.681531, acc.: 51.56%] [G loss: 0.789020]\n",
      "epoch:25 step:19798 [D loss: 0.697837, acc.: 46.88%] [G loss: 0.771950]\n",
      "epoch:25 step:19799 [D loss: 0.724704, acc.: 46.09%] [G loss: 0.712860]\n",
      "epoch:25 step:19800 [D loss: 0.705929, acc.: 46.88%] [G loss: 0.800631]\n",
      "epoch:25 step:19801 [D loss: 0.678191, acc.: 60.16%] [G loss: 0.814711]\n",
      "epoch:25 step:19802 [D loss: 0.744768, acc.: 48.44%] [G loss: 0.708536]\n",
      "epoch:25 step:19803 [D loss: 0.660848, acc.: 63.28%] [G loss: 0.799636]\n",
      "epoch:25 step:19804 [D loss: 0.724078, acc.: 50.00%] [G loss: 0.766069]\n",
      "epoch:25 step:19805 [D loss: 0.683636, acc.: 58.59%] [G loss: 0.793749]\n",
      "epoch:25 step:19806 [D loss: 0.749517, acc.: 42.97%] [G loss: 0.763399]\n",
      "epoch:25 step:19807 [D loss: 0.702008, acc.: 53.12%] [G loss: 0.772998]\n",
      "epoch:25 step:19808 [D loss: 0.665571, acc.: 60.16%] [G loss: 0.787233]\n",
      "epoch:25 step:19809 [D loss: 0.705483, acc.: 51.56%] [G loss: 0.782710]\n",
      "epoch:25 step:19810 [D loss: 0.712843, acc.: 41.41%] [G loss: 0.751431]\n",
      "epoch:25 step:19811 [D loss: 0.708202, acc.: 48.44%] [G loss: 0.785558]\n",
      "epoch:25 step:19812 [D loss: 0.702404, acc.: 51.56%] [G loss: 0.784309]\n",
      "epoch:25 step:19813 [D loss: 0.651350, acc.: 63.28%] [G loss: 0.733958]\n",
      "epoch:25 step:19814 [D loss: 0.687658, acc.: 50.78%] [G loss: 0.749285]\n",
      "epoch:25 step:19815 [D loss: 0.669754, acc.: 62.50%] [G loss: 0.769784]\n",
      "epoch:25 step:19816 [D loss: 0.703166, acc.: 51.56%] [G loss: 0.763449]\n",
      "epoch:25 step:19817 [D loss: 0.702081, acc.: 47.66%] [G loss: 0.706650]\n",
      "epoch:25 step:19818 [D loss: 0.723897, acc.: 49.22%] [G loss: 0.692420]\n",
      "epoch:25 step:19819 [D loss: 0.739309, acc.: 40.62%] [G loss: 0.730094]\n",
      "epoch:25 step:19820 [D loss: 0.692489, acc.: 53.12%] [G loss: 0.796705]\n",
      "epoch:25 step:19821 [D loss: 0.703053, acc.: 50.00%] [G loss: 0.787282]\n",
      "epoch:25 step:19822 [D loss: 0.675210, acc.: 58.59%] [G loss: 0.792929]\n",
      "epoch:25 step:19823 [D loss: 0.750075, acc.: 42.19%] [G loss: 0.690300]\n",
      "epoch:25 step:19824 [D loss: 0.695170, acc.: 49.22%] [G loss: 0.704142]\n",
      "epoch:25 step:19825 [D loss: 0.711532, acc.: 46.88%] [G loss: 0.748537]\n",
      "epoch:25 step:19826 [D loss: 0.686643, acc.: 54.69%] [G loss: 0.708341]\n",
      "epoch:25 step:19827 [D loss: 0.670233, acc.: 62.50%] [G loss: 0.810283]\n",
      "epoch:25 step:19828 [D loss: 0.662918, acc.: 64.06%] [G loss: 0.820531]\n",
      "epoch:25 step:19829 [D loss: 0.720683, acc.: 49.22%] [G loss: 0.776676]\n",
      "epoch:25 step:19830 [D loss: 0.697582, acc.: 51.56%] [G loss: 0.776963]\n",
      "epoch:25 step:19831 [D loss: 0.653137, acc.: 64.84%] [G loss: 0.805173]\n",
      "epoch:25 step:19832 [D loss: 0.668037, acc.: 59.38%] [G loss: 0.759857]\n",
      "epoch:25 step:19833 [D loss: 0.665499, acc.: 60.94%] [G loss: 0.791965]\n",
      "epoch:25 step:19834 [D loss: 0.717592, acc.: 52.34%] [G loss: 0.757648]\n",
      "epoch:25 step:19835 [D loss: 0.684156, acc.: 52.34%] [G loss: 0.793300]\n",
      "epoch:25 step:19836 [D loss: 0.715198, acc.: 50.00%] [G loss: 0.804391]\n",
      "epoch:25 step:19837 [D loss: 0.676102, acc.: 57.81%] [G loss: 0.744829]\n",
      "epoch:25 step:19838 [D loss: 0.703579, acc.: 49.22%] [G loss: 0.800774]\n",
      "epoch:25 step:19839 [D loss: 0.722490, acc.: 46.09%] [G loss: 0.801778]\n",
      "epoch:25 step:19840 [D loss: 0.706337, acc.: 50.00%] [G loss: 0.817682]\n",
      "epoch:25 step:19841 [D loss: 0.656348, acc.: 57.03%] [G loss: 0.778043]\n",
      "epoch:25 step:19842 [D loss: 0.650815, acc.: 62.50%] [G loss: 0.733875]\n",
      "epoch:25 step:19843 [D loss: 0.650530, acc.: 66.41%] [G loss: 0.806916]\n",
      "epoch:25 step:19844 [D loss: 0.663019, acc.: 60.16%] [G loss: 0.868262]\n",
      "epoch:25 step:19845 [D loss: 0.691381, acc.: 52.34%] [G loss: 0.808791]\n",
      "epoch:25 step:19846 [D loss: 0.695410, acc.: 50.78%] [G loss: 0.830248]\n",
      "epoch:25 step:19847 [D loss: 0.629270, acc.: 64.06%] [G loss: 0.860500]\n",
      "epoch:25 step:19848 [D loss: 0.649637, acc.: 66.41%] [G loss: 0.820587]\n",
      "epoch:25 step:19849 [D loss: 0.645078, acc.: 70.31%] [G loss: 0.750532]\n",
      "epoch:25 step:19850 [D loss: 0.685110, acc.: 55.47%] [G loss: 0.772240]\n",
      "epoch:25 step:19851 [D loss: 0.671133, acc.: 60.94%] [G loss: 0.815784]\n",
      "epoch:25 step:19852 [D loss: 0.645838, acc.: 67.19%] [G loss: 0.789875]\n",
      "epoch:25 step:19853 [D loss: 0.680465, acc.: 61.72%] [G loss: 0.817689]\n",
      "epoch:25 step:19854 [D loss: 0.702979, acc.: 56.25%] [G loss: 0.741109]\n",
      "epoch:25 step:19855 [D loss: 0.722204, acc.: 42.19%] [G loss: 0.765547]\n",
      "epoch:25 step:19856 [D loss: 0.721827, acc.: 45.31%] [G loss: 0.831888]\n",
      "epoch:25 step:19857 [D loss: 0.683543, acc.: 51.56%] [G loss: 0.808601]\n",
      "epoch:25 step:19858 [D loss: 0.692057, acc.: 51.56%] [G loss: 0.773089]\n",
      "epoch:25 step:19859 [D loss: 0.723264, acc.: 43.75%] [G loss: 0.810216]\n",
      "epoch:25 step:19860 [D loss: 0.722090, acc.: 46.09%] [G loss: 0.728363]\n",
      "epoch:25 step:19861 [D loss: 0.661497, acc.: 67.19%] [G loss: 0.787499]\n",
      "epoch:25 step:19862 [D loss: 0.719198, acc.: 39.84%] [G loss: 0.728020]\n",
      "epoch:25 step:19863 [D loss: 0.695281, acc.: 53.91%] [G loss: 0.750018]\n",
      "epoch:25 step:19864 [D loss: 0.716864, acc.: 44.53%] [G loss: 0.694927]\n",
      "epoch:25 step:19865 [D loss: 0.710402, acc.: 52.34%] [G loss: 0.661867]\n",
      "epoch:25 step:19866 [D loss: 0.681989, acc.: 57.81%] [G loss: 0.678575]\n",
      "epoch:25 step:19867 [D loss: 0.692317, acc.: 55.47%] [G loss: 0.748213]\n",
      "epoch:25 step:19868 [D loss: 0.738694, acc.: 42.97%] [G loss: 0.732648]\n",
      "epoch:25 step:19869 [D loss: 0.669226, acc.: 60.94%] [G loss: 0.782049]\n",
      "epoch:25 step:19870 [D loss: 0.713915, acc.: 50.00%] [G loss: 0.709479]\n",
      "epoch:25 step:19871 [D loss: 0.725978, acc.: 44.53%] [G loss: 0.694447]\n",
      "epoch:25 step:19872 [D loss: 0.700740, acc.: 51.56%] [G loss: 0.750999]\n",
      "epoch:25 step:19873 [D loss: 0.715408, acc.: 53.91%] [G loss: 0.730690]\n",
      "epoch:25 step:19874 [D loss: 0.694790, acc.: 49.22%] [G loss: 0.831916]\n",
      "epoch:25 step:19875 [D loss: 0.709395, acc.: 50.78%] [G loss: 0.803984]\n",
      "epoch:25 step:19876 [D loss: 0.723433, acc.: 41.41%] [G loss: 0.721940]\n",
      "epoch:25 step:19877 [D loss: 0.644150, acc.: 65.62%] [G loss: 0.744167]\n",
      "epoch:25 step:19878 [D loss: 0.664322, acc.: 61.72%] [G loss: 0.827045]\n",
      "epoch:25 step:19879 [D loss: 0.701997, acc.: 49.22%] [G loss: 0.773757]\n",
      "epoch:25 step:19880 [D loss: 0.671766, acc.: 62.50%] [G loss: 0.752458]\n",
      "epoch:25 step:19881 [D loss: 0.646153, acc.: 70.31%] [G loss: 0.831364]\n",
      "epoch:25 step:19882 [D loss: 0.688563, acc.: 54.69%] [G loss: 0.807572]\n",
      "epoch:25 step:19883 [D loss: 0.690263, acc.: 53.91%] [G loss: 0.777434]\n",
      "epoch:25 step:19884 [D loss: 0.717787, acc.: 46.88%] [G loss: 0.741452]\n",
      "epoch:25 step:19885 [D loss: 0.668572, acc.: 63.28%] [G loss: 0.753869]\n",
      "epoch:25 step:19886 [D loss: 0.664882, acc.: 57.03%] [G loss: 0.813185]\n",
      "epoch:25 step:19887 [D loss: 0.695836, acc.: 49.22%] [G loss: 0.708309]\n",
      "epoch:25 step:19888 [D loss: 0.702271, acc.: 46.09%] [G loss: 0.721029]\n",
      "epoch:25 step:19889 [D loss: 0.717952, acc.: 45.31%] [G loss: 0.686606]\n",
      "epoch:25 step:19890 [D loss: 0.670205, acc.: 53.12%] [G loss: 0.727353]\n",
      "epoch:25 step:19891 [D loss: 0.715048, acc.: 44.53%] [G loss: 0.705693]\n",
      "epoch:25 step:19892 [D loss: 0.748071, acc.: 50.00%] [G loss: 0.718382]\n",
      "epoch:25 step:19893 [D loss: 0.646600, acc.: 67.19%] [G loss: 0.760472]\n",
      "epoch:25 step:19894 [D loss: 0.719758, acc.: 46.88%] [G loss: 0.689151]\n",
      "epoch:25 step:19895 [D loss: 0.682938, acc.: 50.78%] [G loss: 0.769342]\n",
      "epoch:25 step:19896 [D loss: 0.654570, acc.: 63.28%] [G loss: 0.809333]\n",
      "epoch:25 step:19897 [D loss: 0.676132, acc.: 58.59%] [G loss: 0.719497]\n",
      "epoch:25 step:19898 [D loss: 0.749936, acc.: 46.09%] [G loss: 0.685727]\n",
      "epoch:25 step:19899 [D loss: 0.699970, acc.: 52.34%] [G loss: 0.754194]\n",
      "epoch:25 step:19900 [D loss: 0.750441, acc.: 40.62%] [G loss: 0.729766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19901 [D loss: 0.671871, acc.: 57.03%] [G loss: 0.759350]\n",
      "epoch:25 step:19902 [D loss: 0.738312, acc.: 39.84%] [G loss: 0.783703]\n",
      "epoch:25 step:19903 [D loss: 0.694950, acc.: 48.44%] [G loss: 0.781954]\n",
      "epoch:25 step:19904 [D loss: 0.652812, acc.: 64.06%] [G loss: 0.884539]\n",
      "epoch:25 step:19905 [D loss: 0.732678, acc.: 43.75%] [G loss: 0.781219]\n",
      "epoch:25 step:19906 [D loss: 0.663972, acc.: 63.28%] [G loss: 0.786904]\n",
      "epoch:25 step:19907 [D loss: 0.684636, acc.: 64.06%] [G loss: 0.765709]\n",
      "epoch:25 step:19908 [D loss: 0.677808, acc.: 60.94%] [G loss: 0.789475]\n",
      "epoch:25 step:19909 [D loss: 0.667771, acc.: 61.72%] [G loss: 0.777649]\n",
      "epoch:25 step:19910 [D loss: 0.682964, acc.: 57.81%] [G loss: 0.747186]\n",
      "epoch:25 step:19911 [D loss: 0.667978, acc.: 63.28%] [G loss: 0.800338]\n",
      "epoch:25 step:19912 [D loss: 0.720298, acc.: 47.66%] [G loss: 0.784069]\n",
      "epoch:25 step:19913 [D loss: 0.744124, acc.: 33.59%] [G loss: 0.798155]\n",
      "epoch:25 step:19914 [D loss: 0.701216, acc.: 49.22%] [G loss: 0.852230]\n",
      "epoch:25 step:19915 [D loss: 0.657021, acc.: 67.19%] [G loss: 0.733578]\n",
      "epoch:25 step:19916 [D loss: 0.723834, acc.: 45.31%] [G loss: 0.757065]\n",
      "epoch:25 step:19917 [D loss: 0.688537, acc.: 57.03%] [G loss: 0.685839]\n",
      "epoch:25 step:19918 [D loss: 0.661304, acc.: 60.16%] [G loss: 0.769959]\n",
      "epoch:25 step:19919 [D loss: 0.638372, acc.: 67.19%] [G loss: 0.753388]\n",
      "epoch:25 step:19920 [D loss: 0.714654, acc.: 46.88%] [G loss: 0.704227]\n",
      "epoch:25 step:19921 [D loss: 0.673274, acc.: 56.25%] [G loss: 0.728125]\n",
      "epoch:25 step:19922 [D loss: 0.682720, acc.: 57.81%] [G loss: 0.733489]\n",
      "epoch:25 step:19923 [D loss: 0.692456, acc.: 48.44%] [G loss: 0.742238]\n",
      "epoch:25 step:19924 [D loss: 0.665697, acc.: 61.72%] [G loss: 0.670753]\n",
      "epoch:25 step:19925 [D loss: 0.704545, acc.: 50.78%] [G loss: 0.719944]\n",
      "epoch:25 step:19926 [D loss: 0.711862, acc.: 49.22%] [G loss: 0.792168]\n",
      "epoch:25 step:19927 [D loss: 0.662141, acc.: 64.06%] [G loss: 0.750474]\n",
      "epoch:25 step:19928 [D loss: 0.683127, acc.: 55.47%] [G loss: 0.717343]\n",
      "epoch:25 step:19929 [D loss: 0.697783, acc.: 59.38%] [G loss: 0.720098]\n",
      "epoch:25 step:19930 [D loss: 0.702443, acc.: 56.25%] [G loss: 0.813187]\n",
      "epoch:25 step:19931 [D loss: 0.699672, acc.: 57.81%] [G loss: 0.798363]\n",
      "epoch:25 step:19932 [D loss: 0.677162, acc.: 57.81%] [G loss: 0.798234]\n",
      "epoch:25 step:19933 [D loss: 0.757967, acc.: 34.38%] [G loss: 0.796587]\n",
      "epoch:25 step:19934 [D loss: 0.676227, acc.: 55.47%] [G loss: 0.780516]\n",
      "epoch:25 step:19935 [D loss: 0.653135, acc.: 62.50%] [G loss: 0.802868]\n",
      "epoch:25 step:19936 [D loss: 0.753632, acc.: 38.28%] [G loss: 0.758726]\n",
      "epoch:25 step:19937 [D loss: 0.717742, acc.: 50.00%] [G loss: 0.710230]\n",
      "epoch:25 step:19938 [D loss: 0.723290, acc.: 38.28%] [G loss: 0.747617]\n",
      "epoch:25 step:19939 [D loss: 0.711790, acc.: 47.66%] [G loss: 0.767503]\n",
      "epoch:25 step:19940 [D loss: 0.658095, acc.: 60.16%] [G loss: 0.771624]\n",
      "epoch:25 step:19941 [D loss: 0.682384, acc.: 58.59%] [G loss: 0.778582]\n",
      "epoch:25 step:19942 [D loss: 0.723428, acc.: 38.28%] [G loss: 0.739370]\n",
      "epoch:25 step:19943 [D loss: 0.662527, acc.: 62.50%] [G loss: 0.774221]\n",
      "epoch:25 step:19944 [D loss: 0.725889, acc.: 45.31%] [G loss: 0.724332]\n",
      "epoch:25 step:19945 [D loss: 0.708374, acc.: 49.22%] [G loss: 0.764325]\n",
      "epoch:25 step:19946 [D loss: 0.727329, acc.: 42.97%] [G loss: 0.738252]\n",
      "epoch:25 step:19947 [D loss: 0.695847, acc.: 53.12%] [G loss: 0.767849]\n",
      "epoch:25 step:19948 [D loss: 0.694950, acc.: 51.56%] [G loss: 0.779427]\n",
      "epoch:25 step:19949 [D loss: 0.686025, acc.: 54.69%] [G loss: 0.775111]\n",
      "epoch:25 step:19950 [D loss: 0.671608, acc.: 51.56%] [G loss: 0.789515]\n",
      "epoch:25 step:19951 [D loss: 0.717326, acc.: 46.88%] [G loss: 0.747375]\n",
      "epoch:25 step:19952 [D loss: 0.709925, acc.: 44.53%] [G loss: 0.772341]\n",
      "epoch:25 step:19953 [D loss: 0.689313, acc.: 49.22%] [G loss: 0.796342]\n",
      "epoch:25 step:19954 [D loss: 0.670262, acc.: 57.03%] [G loss: 0.760955]\n",
      "epoch:25 step:19955 [D loss: 0.697887, acc.: 47.66%] [G loss: 0.703226]\n",
      "epoch:25 step:19956 [D loss: 0.744820, acc.: 40.62%] [G loss: 0.734217]\n",
      "epoch:25 step:19957 [D loss: 0.685560, acc.: 60.16%] [G loss: 0.753272]\n",
      "epoch:25 step:19958 [D loss: 0.667080, acc.: 64.84%] [G loss: 0.770531]\n",
      "epoch:25 step:19959 [D loss: 0.669066, acc.: 54.69%] [G loss: 0.756873]\n",
      "epoch:25 step:19960 [D loss: 0.739628, acc.: 37.50%] [G loss: 0.779622]\n",
      "epoch:25 step:19961 [D loss: 0.690991, acc.: 60.94%] [G loss: 0.775230]\n",
      "epoch:25 step:19962 [D loss: 0.712900, acc.: 46.88%] [G loss: 0.748863]\n",
      "epoch:25 step:19963 [D loss: 0.654793, acc.: 56.25%] [G loss: 0.717421]\n",
      "epoch:25 step:19964 [D loss: 0.713999, acc.: 45.31%] [G loss: 0.767697]\n",
      "epoch:25 step:19965 [D loss: 0.720811, acc.: 47.66%] [G loss: 0.722205]\n",
      "epoch:25 step:19966 [D loss: 0.689413, acc.: 58.59%] [G loss: 0.789564]\n",
      "epoch:25 step:19967 [D loss: 0.700937, acc.: 49.22%] [G loss: 0.830617]\n",
      "epoch:25 step:19968 [D loss: 0.681579, acc.: 54.69%] [G loss: 0.749899]\n",
      "epoch:25 step:19969 [D loss: 0.691461, acc.: 48.44%] [G loss: 0.767298]\n",
      "epoch:25 step:19970 [D loss: 0.738727, acc.: 37.50%] [G loss: 0.771624]\n",
      "epoch:25 step:19971 [D loss: 0.738017, acc.: 41.41%] [G loss: 0.764207]\n",
      "epoch:25 step:19972 [D loss: 0.692807, acc.: 52.34%] [G loss: 0.753577]\n",
      "epoch:25 step:19973 [D loss: 0.680284, acc.: 57.81%] [G loss: 0.734133]\n",
      "epoch:25 step:19974 [D loss: 0.685038, acc.: 58.59%] [G loss: 0.833957]\n",
      "epoch:25 step:19975 [D loss: 0.658813, acc.: 60.94%] [G loss: 0.758837]\n",
      "epoch:25 step:19976 [D loss: 0.657570, acc.: 60.16%] [G loss: 0.822704]\n",
      "epoch:25 step:19977 [D loss: 0.666756, acc.: 67.97%] [G loss: 0.764186]\n",
      "epoch:25 step:19978 [D loss: 0.683460, acc.: 55.47%] [G loss: 0.821513]\n",
      "epoch:25 step:19979 [D loss: 0.701878, acc.: 45.31%] [G loss: 0.811380]\n",
      "epoch:25 step:19980 [D loss: 0.717498, acc.: 47.66%] [G loss: 0.759642]\n",
      "epoch:25 step:19981 [D loss: 0.686725, acc.: 55.47%] [G loss: 0.751316]\n",
      "epoch:25 step:19982 [D loss: 0.724183, acc.: 46.88%] [G loss: 0.743939]\n",
      "epoch:25 step:19983 [D loss: 0.695061, acc.: 51.56%] [G loss: 0.771361]\n",
      "epoch:25 step:19984 [D loss: 0.720334, acc.: 46.09%] [G loss: 0.780864]\n",
      "epoch:25 step:19985 [D loss: 0.690066, acc.: 53.12%] [G loss: 0.763657]\n",
      "epoch:25 step:19986 [D loss: 0.680490, acc.: 57.81%] [G loss: 0.825838]\n",
      "epoch:25 step:19987 [D loss: 0.700485, acc.: 46.09%] [G loss: 0.804957]\n",
      "epoch:25 step:19988 [D loss: 0.735545, acc.: 43.75%] [G loss: 0.766756]\n",
      "epoch:25 step:19989 [D loss: 0.658734, acc.: 62.50%] [G loss: 0.830911]\n",
      "epoch:25 step:19990 [D loss: 0.675934, acc.: 59.38%] [G loss: 0.768461]\n",
      "epoch:25 step:19991 [D loss: 0.669045, acc.: 59.38%] [G loss: 0.808831]\n",
      "epoch:25 step:19992 [D loss: 0.709005, acc.: 47.66%] [G loss: 0.707314]\n",
      "epoch:25 step:19993 [D loss: 0.714907, acc.: 42.19%] [G loss: 0.757145]\n",
      "epoch:25 step:19994 [D loss: 0.679323, acc.: 57.03%] [G loss: 0.767866]\n",
      "epoch:25 step:19995 [D loss: 0.675993, acc.: 53.91%] [G loss: 0.775431]\n",
      "epoch:25 step:19996 [D loss: 0.710521, acc.: 46.09%] [G loss: 0.810956]\n",
      "epoch:25 step:19997 [D loss: 0.711971, acc.: 47.66%] [G loss: 0.695600]\n",
      "epoch:25 step:19998 [D loss: 0.768387, acc.: 38.28%] [G loss: 0.737549]\n",
      "epoch:25 step:19999 [D loss: 0.689449, acc.: 50.00%] [G loss: 0.697640]\n",
      "epoch:25 step:20000 [D loss: 0.687034, acc.: 56.25%] [G loss: 0.761955]\n",
      "epoch:25 step:20001 [D loss: 0.690886, acc.: 52.34%] [G loss: 0.722051]\n",
      "epoch:25 step:20002 [D loss: 0.643323, acc.: 66.41%] [G loss: 0.720808]\n",
      "epoch:25 step:20003 [D loss: 0.658432, acc.: 67.19%] [G loss: 0.748803]\n",
      "epoch:25 step:20004 [D loss: 0.711438, acc.: 50.78%] [G loss: 0.778862]\n",
      "epoch:25 step:20005 [D loss: 0.657677, acc.: 60.16%] [G loss: 0.807549]\n",
      "epoch:25 step:20006 [D loss: 0.698475, acc.: 49.22%] [G loss: 0.811148]\n",
      "epoch:25 step:20007 [D loss: 0.710088, acc.: 50.00%] [G loss: 0.799965]\n",
      "epoch:25 step:20008 [D loss: 0.658344, acc.: 62.50%] [G loss: 0.861351]\n",
      "epoch:25 step:20009 [D loss: 0.715384, acc.: 50.00%] [G loss: 0.744547]\n",
      "epoch:25 step:20010 [D loss: 0.650859, acc.: 63.28%] [G loss: 0.777572]\n",
      "epoch:25 step:20011 [D loss: 0.654729, acc.: 62.50%] [G loss: 0.771849]\n",
      "epoch:25 step:20012 [D loss: 0.689634, acc.: 51.56%] [G loss: 0.778916]\n",
      "epoch:25 step:20013 [D loss: 0.670079, acc.: 60.94%] [G loss: 0.751104]\n",
      "epoch:25 step:20014 [D loss: 0.702666, acc.: 50.78%] [G loss: 0.803449]\n",
      "epoch:25 step:20015 [D loss: 0.655229, acc.: 64.06%] [G loss: 0.753082]\n",
      "epoch:25 step:20016 [D loss: 0.720233, acc.: 42.97%] [G loss: 0.717028]\n",
      "epoch:25 step:20017 [D loss: 0.688347, acc.: 54.69%] [G loss: 0.732708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20018 [D loss: 0.677788, acc.: 57.81%] [G loss: 0.740935]\n",
      "epoch:25 step:20019 [D loss: 0.632495, acc.: 73.44%] [G loss: 0.668902]\n",
      "epoch:25 step:20020 [D loss: 0.656437, acc.: 64.06%] [G loss: 0.744954]\n",
      "epoch:25 step:20021 [D loss: 0.721602, acc.: 47.66%] [G loss: 0.676818]\n",
      "epoch:25 step:20022 [D loss: 0.644059, acc.: 70.31%] [G loss: 0.762195]\n",
      "epoch:25 step:20023 [D loss: 0.653845, acc.: 60.94%] [G loss: 0.679422]\n",
      "epoch:25 step:20024 [D loss: 0.620542, acc.: 71.09%] [G loss: 0.803317]\n",
      "epoch:25 step:20025 [D loss: 0.685466, acc.: 54.69%] [G loss: 0.728804]\n",
      "epoch:25 step:20026 [D loss: 0.688995, acc.: 57.03%] [G loss: 0.768900]\n",
      "epoch:25 step:20027 [D loss: 0.737085, acc.: 39.06%] [G loss: 0.767270]\n",
      "epoch:25 step:20028 [D loss: 0.690961, acc.: 59.38%] [G loss: 0.783263]\n",
      "epoch:25 step:20029 [D loss: 0.682650, acc.: 55.47%] [G loss: 0.771396]\n",
      "epoch:25 step:20030 [D loss: 0.695185, acc.: 52.34%] [G loss: 0.753805]\n",
      "epoch:25 step:20031 [D loss: 0.664631, acc.: 60.94%] [G loss: 0.807661]\n",
      "epoch:25 step:20032 [D loss: 0.669911, acc.: 58.59%] [G loss: 0.815027]\n",
      "epoch:25 step:20033 [D loss: 0.693133, acc.: 54.69%] [G loss: 0.776100]\n",
      "epoch:25 step:20034 [D loss: 0.724161, acc.: 49.22%] [G loss: 0.764753]\n",
      "epoch:25 step:20035 [D loss: 0.636812, acc.: 67.19%] [G loss: 0.792555]\n",
      "epoch:25 step:20036 [D loss: 0.667854, acc.: 61.72%] [G loss: 0.759364]\n",
      "epoch:25 step:20037 [D loss: 0.723516, acc.: 45.31%] [G loss: 0.772929]\n",
      "epoch:25 step:20038 [D loss: 0.743150, acc.: 39.84%] [G loss: 0.755564]\n",
      "epoch:25 step:20039 [D loss: 0.743288, acc.: 44.53%] [G loss: 0.669097]\n",
      "epoch:25 step:20040 [D loss: 0.702422, acc.: 56.25%] [G loss: 0.700570]\n",
      "epoch:25 step:20041 [D loss: 0.678736, acc.: 50.78%] [G loss: 0.775745]\n",
      "epoch:25 step:20042 [D loss: 0.690890, acc.: 53.12%] [G loss: 0.745832]\n",
      "epoch:25 step:20043 [D loss: 0.713491, acc.: 47.66%] [G loss: 0.699761]\n",
      "epoch:25 step:20044 [D loss: 0.710446, acc.: 48.44%] [G loss: 0.779947]\n",
      "epoch:25 step:20045 [D loss: 0.718023, acc.: 43.75%] [G loss: 0.820428]\n",
      "epoch:25 step:20046 [D loss: 0.664656, acc.: 64.06%] [G loss: 0.800210]\n",
      "epoch:25 step:20047 [D loss: 0.693722, acc.: 52.34%] [G loss: 0.786481]\n",
      "epoch:25 step:20048 [D loss: 0.722807, acc.: 43.75%] [G loss: 0.776458]\n",
      "epoch:25 step:20049 [D loss: 0.692750, acc.: 53.12%] [G loss: 0.818029]\n",
      "epoch:25 step:20050 [D loss: 0.624599, acc.: 73.44%] [G loss: 0.771959]\n",
      "epoch:25 step:20051 [D loss: 0.759063, acc.: 42.97%] [G loss: 0.719813]\n",
      "epoch:25 step:20052 [D loss: 0.675909, acc.: 58.59%] [G loss: 0.703606]\n",
      "epoch:25 step:20053 [D loss: 0.695695, acc.: 47.66%] [G loss: 0.728236]\n",
      "epoch:25 step:20054 [D loss: 0.646023, acc.: 71.09%] [G loss: 0.768861]\n",
      "epoch:25 step:20055 [D loss: 0.703852, acc.: 55.47%] [G loss: 0.699842]\n",
      "epoch:25 step:20056 [D loss: 0.662764, acc.: 62.50%] [G loss: 0.789333]\n",
      "epoch:25 step:20057 [D loss: 0.699508, acc.: 50.78%] [G loss: 0.787317]\n",
      "epoch:25 step:20058 [D loss: 0.695103, acc.: 53.12%] [G loss: 0.847532]\n",
      "epoch:25 step:20059 [D loss: 0.674322, acc.: 57.81%] [G loss: 0.768519]\n",
      "epoch:25 step:20060 [D loss: 0.701709, acc.: 53.12%] [G loss: 0.770968]\n",
      "epoch:25 step:20061 [D loss: 0.697702, acc.: 54.69%] [G loss: 0.795070]\n",
      "epoch:25 step:20062 [D loss: 0.698216, acc.: 49.22%] [G loss: 0.803123]\n",
      "epoch:25 step:20063 [D loss: 0.681696, acc.: 53.12%] [G loss: 0.739845]\n",
      "epoch:25 step:20064 [D loss: 0.715649, acc.: 48.44%] [G loss: 0.746635]\n",
      "epoch:25 step:20065 [D loss: 0.726611, acc.: 42.19%] [G loss: 0.742848]\n",
      "epoch:25 step:20066 [D loss: 0.690777, acc.: 50.78%] [G loss: 0.691743]\n",
      "epoch:25 step:20067 [D loss: 0.691334, acc.: 53.91%] [G loss: 0.715647]\n",
      "epoch:25 step:20068 [D loss: 0.665386, acc.: 60.16%] [G loss: 0.775159]\n",
      "epoch:25 step:20069 [D loss: 0.699445, acc.: 46.88%] [G loss: 0.740621]\n",
      "epoch:25 step:20070 [D loss: 0.662660, acc.: 65.62%] [G loss: 0.783280]\n",
      "epoch:25 step:20071 [D loss: 0.729855, acc.: 41.41%] [G loss: 0.763169]\n",
      "epoch:25 step:20072 [D loss: 0.633402, acc.: 67.97%] [G loss: 0.750896]\n",
      "epoch:25 step:20073 [D loss: 0.692411, acc.: 50.78%] [G loss: 0.794304]\n",
      "epoch:25 step:20074 [D loss: 0.644528, acc.: 60.94%] [G loss: 0.760329]\n",
      "epoch:25 step:20075 [D loss: 0.730163, acc.: 41.41%] [G loss: 0.768005]\n",
      "epoch:25 step:20076 [D loss: 0.660247, acc.: 64.84%] [G loss: 0.835669]\n",
      "epoch:25 step:20077 [D loss: 0.676793, acc.: 53.12%] [G loss: 0.811874]\n",
      "epoch:25 step:20078 [D loss: 0.651404, acc.: 65.62%] [G loss: 0.841321]\n",
      "epoch:25 step:20079 [D loss: 0.681945, acc.: 56.25%] [G loss: 0.770670]\n",
      "epoch:25 step:20080 [D loss: 0.642111, acc.: 66.41%] [G loss: 0.802281]\n",
      "epoch:25 step:20081 [D loss: 0.690136, acc.: 54.69%] [G loss: 0.753759]\n",
      "epoch:25 step:20082 [D loss: 0.672524, acc.: 55.47%] [G loss: 0.798501]\n",
      "epoch:25 step:20083 [D loss: 0.682909, acc.: 57.81%] [G loss: 0.840550]\n",
      "epoch:25 step:20084 [D loss: 0.646950, acc.: 60.94%] [G loss: 0.767236]\n",
      "epoch:25 step:20085 [D loss: 0.688484, acc.: 53.12%] [G loss: 0.727195]\n",
      "epoch:25 step:20086 [D loss: 0.683091, acc.: 54.69%] [G loss: 0.771281]\n",
      "epoch:25 step:20087 [D loss: 0.671854, acc.: 61.72%] [G loss: 0.789229]\n",
      "epoch:25 step:20088 [D loss: 0.662189, acc.: 60.94%] [G loss: 0.769617]\n",
      "epoch:25 step:20089 [D loss: 0.671658, acc.: 56.25%] [G loss: 0.764232]\n",
      "epoch:25 step:20090 [D loss: 0.680896, acc.: 64.06%] [G loss: 0.739717]\n",
      "epoch:25 step:20091 [D loss: 0.709487, acc.: 53.12%] [G loss: 0.698822]\n",
      "epoch:25 step:20092 [D loss: 0.683625, acc.: 52.34%] [G loss: 0.736717]\n",
      "epoch:25 step:20093 [D loss: 0.656368, acc.: 60.94%] [G loss: 0.767070]\n",
      "epoch:25 step:20094 [D loss: 0.722285, acc.: 47.66%] [G loss: 0.768805]\n",
      "epoch:25 step:20095 [D loss: 0.657809, acc.: 64.06%] [G loss: 0.699053]\n",
      "epoch:25 step:20096 [D loss: 0.694694, acc.: 49.22%] [G loss: 0.794094]\n",
      "epoch:25 step:20097 [D loss: 0.712457, acc.: 52.34%] [G loss: 0.804180]\n",
      "epoch:25 step:20098 [D loss: 0.712402, acc.: 49.22%] [G loss: 0.755954]\n",
      "epoch:25 step:20099 [D loss: 0.704187, acc.: 52.34%] [G loss: 0.809223]\n",
      "epoch:25 step:20100 [D loss: 0.682125, acc.: 57.03%] [G loss: 0.775112]\n",
      "epoch:25 step:20101 [D loss: 0.674589, acc.: 54.69%] [G loss: 0.682672]\n",
      "epoch:25 step:20102 [D loss: 0.649925, acc.: 59.38%] [G loss: 0.851113]\n",
      "epoch:25 step:20103 [D loss: 0.653752, acc.: 67.19%] [G loss: 0.792189]\n",
      "epoch:25 step:20104 [D loss: 0.712942, acc.: 46.09%] [G loss: 0.759887]\n",
      "epoch:25 step:20105 [D loss: 0.708782, acc.: 46.09%] [G loss: 0.743671]\n",
      "epoch:25 step:20106 [D loss: 0.702698, acc.: 47.66%] [G loss: 0.731641]\n",
      "epoch:25 step:20107 [D loss: 0.684338, acc.: 56.25%] [G loss: 0.735826]\n",
      "epoch:25 step:20108 [D loss: 0.721933, acc.: 47.66%] [G loss: 0.779079]\n",
      "epoch:25 step:20109 [D loss: 0.720916, acc.: 49.22%] [G loss: 0.781532]\n",
      "epoch:25 step:20110 [D loss: 0.669356, acc.: 57.03%] [G loss: 0.742190]\n",
      "epoch:25 step:20111 [D loss: 0.687734, acc.: 59.38%] [G loss: 0.735968]\n",
      "epoch:25 step:20112 [D loss: 0.653530, acc.: 60.94%] [G loss: 0.831395]\n",
      "epoch:25 step:20113 [D loss: 0.650748, acc.: 65.62%] [G loss: 0.761201]\n",
      "epoch:25 step:20114 [D loss: 0.649819, acc.: 62.50%] [G loss: 0.812019]\n",
      "epoch:25 step:20115 [D loss: 0.683551, acc.: 59.38%] [G loss: 0.815134]\n",
      "epoch:25 step:20116 [D loss: 0.713845, acc.: 46.09%] [G loss: 0.811596]\n",
      "epoch:25 step:20117 [D loss: 0.730204, acc.: 42.19%] [G loss: 0.801932]\n",
      "epoch:25 step:20118 [D loss: 0.672210, acc.: 54.69%] [G loss: 0.801226]\n",
      "epoch:25 step:20119 [D loss: 0.679378, acc.: 60.94%] [G loss: 0.730005]\n",
      "epoch:25 step:20120 [D loss: 0.669021, acc.: 60.94%] [G loss: 0.807299]\n",
      "epoch:25 step:20121 [D loss: 0.697687, acc.: 50.00%] [G loss: 0.696427]\n",
      "epoch:25 step:20122 [D loss: 0.712191, acc.: 51.56%] [G loss: 0.788173]\n",
      "epoch:25 step:20123 [D loss: 0.627208, acc.: 69.53%] [G loss: 0.828017]\n",
      "epoch:25 step:20124 [D loss: 0.721026, acc.: 42.97%] [G loss: 0.748860]\n",
      "epoch:25 step:20125 [D loss: 0.679593, acc.: 57.03%] [G loss: 0.726417]\n",
      "epoch:25 step:20126 [D loss: 0.713938, acc.: 48.44%] [G loss: 0.774526]\n",
      "epoch:25 step:20127 [D loss: 0.674272, acc.: 60.16%] [G loss: 0.766763]\n",
      "epoch:25 step:20128 [D loss: 0.758884, acc.: 40.62%] [G loss: 0.728901]\n",
      "epoch:25 step:20129 [D loss: 0.711175, acc.: 56.25%] [G loss: 0.774151]\n",
      "epoch:25 step:20130 [D loss: 0.729227, acc.: 49.22%] [G loss: 0.724069]\n",
      "epoch:25 step:20131 [D loss: 0.686031, acc.: 55.47%] [G loss: 0.744740]\n",
      "epoch:25 step:20132 [D loss: 0.673604, acc.: 55.47%] [G loss: 0.765274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20133 [D loss: 0.711018, acc.: 47.66%] [G loss: 0.721227]\n",
      "epoch:25 step:20134 [D loss: 0.695526, acc.: 53.12%] [G loss: 0.687045]\n",
      "epoch:25 step:20135 [D loss: 0.689556, acc.: 56.25%] [G loss: 0.747048]\n",
      "epoch:25 step:20136 [D loss: 0.720710, acc.: 42.19%] [G loss: 0.744419]\n",
      "epoch:25 step:20137 [D loss: 0.700579, acc.: 49.22%] [G loss: 0.727490]\n",
      "epoch:25 step:20138 [D loss: 0.726301, acc.: 54.69%] [G loss: 0.775923]\n",
      "epoch:25 step:20139 [D loss: 0.765493, acc.: 35.94%] [G loss: 0.711433]\n",
      "epoch:25 step:20140 [D loss: 0.711348, acc.: 51.56%] [G loss: 0.777992]\n",
      "epoch:25 step:20141 [D loss: 0.693499, acc.: 59.38%] [G loss: 0.801971]\n",
      "epoch:25 step:20142 [D loss: 0.676697, acc.: 57.81%] [G loss: 0.708872]\n",
      "epoch:25 step:20143 [D loss: 0.696088, acc.: 51.56%] [G loss: 0.740498]\n",
      "epoch:25 step:20144 [D loss: 0.625654, acc.: 72.66%] [G loss: 0.732705]\n",
      "epoch:25 step:20145 [D loss: 0.689252, acc.: 57.81%] [G loss: 0.773047]\n",
      "epoch:25 step:20146 [D loss: 0.717409, acc.: 48.44%] [G loss: 0.780464]\n",
      "epoch:25 step:20147 [D loss: 0.700417, acc.: 50.78%] [G loss: 0.734952]\n",
      "epoch:25 step:20148 [D loss: 0.702554, acc.: 44.53%] [G loss: 0.740387]\n",
      "epoch:25 step:20149 [D loss: 0.680998, acc.: 55.47%] [G loss: 0.758270]\n",
      "epoch:25 step:20150 [D loss: 0.702586, acc.: 51.56%] [G loss: 0.745917]\n",
      "epoch:25 step:20151 [D loss: 0.716572, acc.: 47.66%] [G loss: 0.713695]\n",
      "epoch:25 step:20152 [D loss: 0.709838, acc.: 45.31%] [G loss: 0.732298]\n",
      "epoch:25 step:20153 [D loss: 0.660276, acc.: 64.84%] [G loss: 0.750277]\n",
      "epoch:25 step:20154 [D loss: 0.700358, acc.: 54.69%] [G loss: 0.794263]\n",
      "epoch:25 step:20155 [D loss: 0.717465, acc.: 44.53%] [G loss: 0.766776]\n",
      "epoch:25 step:20156 [D loss: 0.697943, acc.: 50.00%] [G loss: 0.749306]\n",
      "epoch:25 step:20157 [D loss: 0.682942, acc.: 52.34%] [G loss: 0.767607]\n",
      "epoch:25 step:20158 [D loss: 0.699782, acc.: 51.56%] [G loss: 0.711363]\n",
      "epoch:25 step:20159 [D loss: 0.664066, acc.: 62.50%] [G loss: 0.779304]\n",
      "epoch:25 step:20160 [D loss: 0.682882, acc.: 54.69%] [G loss: 0.742625]\n",
      "epoch:25 step:20161 [D loss: 0.680370, acc.: 57.81%] [G loss: 0.712661]\n",
      "epoch:25 step:20162 [D loss: 0.719098, acc.: 47.66%] [G loss: 0.751772]\n",
      "epoch:25 step:20163 [D loss: 0.725547, acc.: 44.53%] [G loss: 0.756635]\n",
      "epoch:25 step:20164 [D loss: 0.730974, acc.: 41.41%] [G loss: 0.682398]\n",
      "epoch:25 step:20165 [D loss: 0.702547, acc.: 51.56%] [G loss: 0.777487]\n",
      "epoch:25 step:20166 [D loss: 0.685032, acc.: 55.47%] [G loss: 0.798605]\n",
      "epoch:25 step:20167 [D loss: 0.700696, acc.: 46.09%] [G loss: 0.758567]\n",
      "epoch:25 step:20168 [D loss: 0.689455, acc.: 50.78%] [G loss: 0.722650]\n",
      "epoch:25 step:20169 [D loss: 0.663016, acc.: 60.16%] [G loss: 0.728311]\n",
      "epoch:25 step:20170 [D loss: 0.684677, acc.: 56.25%] [G loss: 0.761350]\n",
      "epoch:25 step:20171 [D loss: 0.670497, acc.: 59.38%] [G loss: 0.782159]\n",
      "epoch:25 step:20172 [D loss: 0.727303, acc.: 42.97%] [G loss: 0.734788]\n",
      "epoch:25 step:20173 [D loss: 0.656747, acc.: 57.03%] [G loss: 0.684893]\n",
      "epoch:25 step:20174 [D loss: 0.702263, acc.: 48.44%] [G loss: 0.723709]\n",
      "epoch:25 step:20175 [D loss: 0.674907, acc.: 59.38%] [G loss: 0.847881]\n",
      "epoch:25 step:20176 [D loss: 0.661862, acc.: 59.38%] [G loss: 0.855929]\n",
      "epoch:25 step:20177 [D loss: 0.666277, acc.: 60.94%] [G loss: 0.814788]\n",
      "epoch:25 step:20178 [D loss: 0.672470, acc.: 59.38%] [G loss: 0.787219]\n",
      "epoch:25 step:20179 [D loss: 0.709769, acc.: 46.88%] [G loss: 0.688732]\n",
      "epoch:25 step:20180 [D loss: 0.688659, acc.: 53.91%] [G loss: 0.739620]\n",
      "epoch:25 step:20181 [D loss: 0.728500, acc.: 43.75%] [G loss: 0.720644]\n",
      "epoch:25 step:20182 [D loss: 0.694720, acc.: 53.91%] [G loss: 0.718074]\n",
      "epoch:25 step:20183 [D loss: 0.634343, acc.: 66.41%] [G loss: 0.810595]\n",
      "epoch:25 step:20184 [D loss: 0.689771, acc.: 53.12%] [G loss: 0.730877]\n",
      "epoch:25 step:20185 [D loss: 0.707353, acc.: 50.00%] [G loss: 0.779141]\n",
      "epoch:25 step:20186 [D loss: 0.689134, acc.: 54.69%] [G loss: 0.777265]\n",
      "epoch:25 step:20187 [D loss: 0.762675, acc.: 40.62%] [G loss: 0.745445]\n",
      "epoch:25 step:20188 [D loss: 0.655947, acc.: 64.06%] [G loss: 0.759954]\n",
      "epoch:25 step:20189 [D loss: 0.689793, acc.: 52.34%] [G loss: 0.838492]\n",
      "epoch:25 step:20190 [D loss: 0.662745, acc.: 62.50%] [G loss: 0.824908]\n",
      "epoch:25 step:20191 [D loss: 0.638367, acc.: 66.41%] [G loss: 0.785181]\n",
      "epoch:25 step:20192 [D loss: 0.695735, acc.: 56.25%] [G loss: 0.844987]\n",
      "epoch:25 step:20193 [D loss: 0.714000, acc.: 49.22%] [G loss: 0.775586]\n",
      "epoch:25 step:20194 [D loss: 0.724093, acc.: 48.44%] [G loss: 0.751960]\n",
      "epoch:25 step:20195 [D loss: 0.697805, acc.: 47.66%] [G loss: 0.785556]\n",
      "epoch:25 step:20196 [D loss: 0.698934, acc.: 48.44%] [G loss: 0.816555]\n",
      "epoch:25 step:20197 [D loss: 0.715759, acc.: 39.84%] [G loss: 0.758298]\n",
      "epoch:25 step:20198 [D loss: 0.695712, acc.: 50.00%] [G loss: 0.773796]\n",
      "epoch:25 step:20199 [D loss: 0.704809, acc.: 51.56%] [G loss: 0.840296]\n",
      "epoch:25 step:20200 [D loss: 0.686754, acc.: 56.25%] [G loss: 0.780367]\n",
      "epoch:25 step:20201 [D loss: 0.732232, acc.: 46.88%] [G loss: 0.759326]\n",
      "epoch:25 step:20202 [D loss: 0.696442, acc.: 51.56%] [G loss: 0.716405]\n",
      "epoch:25 step:20203 [D loss: 0.743879, acc.: 35.94%] [G loss: 0.715087]\n",
      "epoch:25 step:20204 [D loss: 0.635662, acc.: 71.09%] [G loss: 0.774873]\n",
      "epoch:25 step:20205 [D loss: 0.681610, acc.: 59.38%] [G loss: 0.753353]\n",
      "epoch:25 step:20206 [D loss: 0.691879, acc.: 56.25%] [G loss: 0.752381]\n",
      "epoch:25 step:20207 [D loss: 0.656787, acc.: 64.06%] [G loss: 0.773434]\n",
      "epoch:25 step:20208 [D loss: 0.708596, acc.: 53.12%] [G loss: 0.767244]\n",
      "epoch:25 step:20209 [D loss: 0.714124, acc.: 46.09%] [G loss: 0.735393]\n",
      "epoch:25 step:20210 [D loss: 0.706630, acc.: 43.75%] [G loss: 0.789961]\n",
      "epoch:25 step:20211 [D loss: 0.691028, acc.: 51.56%] [G loss: 0.695291]\n",
      "epoch:25 step:20212 [D loss: 0.670549, acc.: 61.72%] [G loss: 0.720601]\n",
      "epoch:25 step:20213 [D loss: 0.680715, acc.: 53.91%] [G loss: 0.742134]\n",
      "epoch:25 step:20214 [D loss: 0.688889, acc.: 55.47%] [G loss: 0.745313]\n",
      "epoch:25 step:20215 [D loss: 0.647893, acc.: 61.72%] [G loss: 0.788715]\n",
      "epoch:25 step:20216 [D loss: 0.693972, acc.: 52.34%] [G loss: 0.713601]\n",
      "epoch:25 step:20217 [D loss: 0.698367, acc.: 52.34%] [G loss: 0.730943]\n",
      "epoch:25 step:20218 [D loss: 0.699628, acc.: 50.78%] [G loss: 0.721348]\n",
      "epoch:25 step:20219 [D loss: 0.673864, acc.: 65.62%] [G loss: 0.738599]\n",
      "epoch:25 step:20220 [D loss: 0.719670, acc.: 45.31%] [G loss: 0.756100]\n",
      "epoch:25 step:20221 [D loss: 0.719815, acc.: 48.44%] [G loss: 0.739181]\n",
      "epoch:25 step:20222 [D loss: 0.663995, acc.: 60.94%] [G loss: 0.754394]\n",
      "epoch:25 step:20223 [D loss: 0.635020, acc.: 67.97%] [G loss: 0.755181]\n",
      "epoch:25 step:20224 [D loss: 0.695354, acc.: 55.47%] [G loss: 0.796607]\n",
      "epoch:25 step:20225 [D loss: 0.653384, acc.: 64.84%] [G loss: 0.821402]\n",
      "epoch:25 step:20226 [D loss: 0.667840, acc.: 59.38%] [G loss: 0.759917]\n",
      "epoch:25 step:20227 [D loss: 0.695202, acc.: 56.25%] [G loss: 0.785375]\n",
      "epoch:25 step:20228 [D loss: 0.732328, acc.: 42.19%] [G loss: 0.716370]\n",
      "epoch:25 step:20229 [D loss: 0.728139, acc.: 38.28%] [G loss: 0.739531]\n",
      "epoch:25 step:20230 [D loss: 0.682142, acc.: 57.81%] [G loss: 0.758524]\n",
      "epoch:25 step:20231 [D loss: 0.670182, acc.: 57.03%] [G loss: 0.748991]\n",
      "epoch:25 step:20232 [D loss: 0.698972, acc.: 49.22%] [G loss: 0.663427]\n",
      "epoch:25 step:20233 [D loss: 0.719893, acc.: 48.44%] [G loss: 0.682115]\n",
      "epoch:25 step:20234 [D loss: 0.648071, acc.: 64.06%] [G loss: 0.799508]\n",
      "epoch:25 step:20235 [D loss: 0.718309, acc.: 46.88%] [G loss: 0.776715]\n",
      "epoch:25 step:20236 [D loss: 0.700585, acc.: 50.00%] [G loss: 0.780300]\n",
      "epoch:25 step:20237 [D loss: 0.710694, acc.: 45.31%] [G loss: 0.764825]\n",
      "epoch:25 step:20238 [D loss: 0.738882, acc.: 44.53%] [G loss: 0.767246]\n",
      "epoch:25 step:20239 [D loss: 0.703705, acc.: 54.69%] [G loss: 0.790200]\n",
      "epoch:25 step:20240 [D loss: 0.731528, acc.: 42.19%] [G loss: 0.780781]\n",
      "epoch:25 step:20241 [D loss: 0.682121, acc.: 53.91%] [G loss: 0.781232]\n",
      "epoch:25 step:20242 [D loss: 0.653815, acc.: 62.50%] [G loss: 0.806657]\n",
      "epoch:25 step:20243 [D loss: 0.668689, acc.: 60.16%] [G loss: 0.752773]\n",
      "epoch:25 step:20244 [D loss: 0.695179, acc.: 56.25%] [G loss: 0.798175]\n",
      "epoch:25 step:20245 [D loss: 0.700346, acc.: 53.12%] [G loss: 0.759692]\n",
      "epoch:25 step:20246 [D loss: 0.720931, acc.: 46.88%] [G loss: 0.757082]\n",
      "epoch:25 step:20247 [D loss: 0.657188, acc.: 59.38%] [G loss: 0.741706]\n",
      "epoch:25 step:20248 [D loss: 0.759509, acc.: 35.16%] [G loss: 0.793920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20249 [D loss: 0.724015, acc.: 46.88%] [G loss: 0.751287]\n",
      "epoch:25 step:20250 [D loss: 0.660348, acc.: 61.72%] [G loss: 0.765143]\n",
      "epoch:25 step:20251 [D loss: 0.677321, acc.: 56.25%] [G loss: 0.737512]\n",
      "epoch:25 step:20252 [D loss: 0.680005, acc.: 57.03%] [G loss: 0.799349]\n",
      "epoch:25 step:20253 [D loss: 0.690968, acc.: 57.03%] [G loss: 0.805776]\n",
      "epoch:25 step:20254 [D loss: 0.686335, acc.: 53.91%] [G loss: 0.754887]\n",
      "epoch:25 step:20255 [D loss: 0.676883, acc.: 60.94%] [G loss: 0.732558]\n",
      "epoch:25 step:20256 [D loss: 0.705864, acc.: 52.34%] [G loss: 0.693854]\n",
      "epoch:25 step:20257 [D loss: 0.692089, acc.: 50.00%] [G loss: 0.823729]\n",
      "epoch:25 step:20258 [D loss: 0.738677, acc.: 41.41%] [G loss: 0.781652]\n",
      "epoch:25 step:20259 [D loss: 0.717632, acc.: 48.44%] [G loss: 0.759868]\n",
      "epoch:25 step:20260 [D loss: 0.698596, acc.: 49.22%] [G loss: 0.789503]\n",
      "epoch:25 step:20261 [D loss: 0.654245, acc.: 62.50%] [G loss: 0.752563]\n",
      "epoch:25 step:20262 [D loss: 0.678155, acc.: 53.91%] [G loss: 0.814983]\n",
      "epoch:25 step:20263 [D loss: 0.648534, acc.: 70.31%] [G loss: 0.783056]\n",
      "epoch:25 step:20264 [D loss: 0.715520, acc.: 49.22%] [G loss: 0.749692]\n",
      "epoch:25 step:20265 [D loss: 0.683836, acc.: 60.16%] [G loss: 0.692286]\n",
      "epoch:25 step:20266 [D loss: 0.644998, acc.: 64.06%] [G loss: 0.789871]\n",
      "epoch:25 step:20267 [D loss: 0.681791, acc.: 54.69%] [G loss: 0.757294]\n",
      "epoch:25 step:20268 [D loss: 0.696761, acc.: 57.03%] [G loss: 0.681060]\n",
      "epoch:25 step:20269 [D loss: 0.669681, acc.: 59.38%] [G loss: 0.799232]\n",
      "epoch:25 step:20270 [D loss: 0.689628, acc.: 53.12%] [G loss: 0.798016]\n",
      "epoch:25 step:20271 [D loss: 0.750350, acc.: 35.16%] [G loss: 0.730349]\n",
      "epoch:25 step:20272 [D loss: 0.703619, acc.: 52.34%] [G loss: 0.682492]\n",
      "epoch:25 step:20273 [D loss: 0.680941, acc.: 53.12%] [G loss: 0.843928]\n",
      "epoch:25 step:20274 [D loss: 0.708761, acc.: 50.78%] [G loss: 0.749779]\n",
      "epoch:25 step:20275 [D loss: 0.694829, acc.: 49.22%] [G loss: 0.827350]\n",
      "epoch:25 step:20276 [D loss: 0.700594, acc.: 53.91%] [G loss: 0.758428]\n",
      "epoch:25 step:20277 [D loss: 0.703600, acc.: 49.22%] [G loss: 0.736141]\n",
      "epoch:25 step:20278 [D loss: 0.675042, acc.: 57.03%] [G loss: 0.850919]\n",
      "epoch:25 step:20279 [D loss: 0.650163, acc.: 63.28%] [G loss: 0.826613]\n",
      "epoch:25 step:20280 [D loss: 0.695823, acc.: 46.09%] [G loss: 0.751946]\n",
      "epoch:25 step:20281 [D loss: 0.673925, acc.: 56.25%] [G loss: 0.720349]\n",
      "epoch:25 step:20282 [D loss: 0.712926, acc.: 41.41%] [G loss: 0.772026]\n",
      "epoch:25 step:20283 [D loss: 0.681988, acc.: 50.78%] [G loss: 0.820248]\n",
      "epoch:25 step:20284 [D loss: 0.708099, acc.: 53.12%] [G loss: 0.790509]\n",
      "epoch:25 step:20285 [D loss: 0.700092, acc.: 55.47%] [G loss: 0.753643]\n",
      "epoch:25 step:20286 [D loss: 0.672886, acc.: 61.72%] [G loss: 0.751042]\n",
      "epoch:25 step:20287 [D loss: 0.688274, acc.: 53.12%] [G loss: 0.796724]\n",
      "epoch:25 step:20288 [D loss: 0.667221, acc.: 57.81%] [G loss: 0.828227]\n",
      "epoch:25 step:20289 [D loss: 0.679108, acc.: 56.25%] [G loss: 0.789413]\n",
      "epoch:25 step:20290 [D loss: 0.620300, acc.: 71.88%] [G loss: 0.790068]\n",
      "epoch:25 step:20291 [D loss: 0.717154, acc.: 47.66%] [G loss: 0.753316]\n",
      "epoch:25 step:20292 [D loss: 0.708876, acc.: 51.56%] [G loss: 0.775268]\n",
      "epoch:25 step:20293 [D loss: 0.671895, acc.: 59.38%] [G loss: 0.804173]\n",
      "epoch:25 step:20294 [D loss: 0.721381, acc.: 44.53%] [G loss: 0.766059]\n",
      "epoch:25 step:20295 [D loss: 0.677052, acc.: 60.16%] [G loss: 0.788174]\n",
      "epoch:25 step:20296 [D loss: 0.716863, acc.: 50.00%] [G loss: 0.711717]\n",
      "epoch:25 step:20297 [D loss: 0.706897, acc.: 51.56%] [G loss: 0.742800]\n",
      "epoch:25 step:20298 [D loss: 0.745961, acc.: 39.06%] [G loss: 0.699416]\n",
      "epoch:25 step:20299 [D loss: 0.686990, acc.: 57.81%] [G loss: 0.753633]\n",
      "epoch:25 step:20300 [D loss: 0.683231, acc.: 51.56%] [G loss: 0.765267]\n",
      "epoch:25 step:20301 [D loss: 0.706665, acc.: 51.56%] [G loss: 0.755685]\n",
      "epoch:25 step:20302 [D loss: 0.698932, acc.: 46.88%] [G loss: 0.728829]\n",
      "epoch:25 step:20303 [D loss: 0.685897, acc.: 56.25%] [G loss: 0.733420]\n",
      "epoch:25 step:20304 [D loss: 0.693321, acc.: 49.22%] [G loss: 0.715343]\n",
      "epoch:25 step:20305 [D loss: 0.746630, acc.: 38.28%] [G loss: 0.724764]\n",
      "epoch:25 step:20306 [D loss: 0.664284, acc.: 59.38%] [G loss: 0.736979]\n",
      "epoch:26 step:20307 [D loss: 0.632491, acc.: 70.31%] [G loss: 0.748761]\n",
      "epoch:26 step:20308 [D loss: 0.714861, acc.: 46.88%] [G loss: 0.734663]\n",
      "epoch:26 step:20309 [D loss: 0.695031, acc.: 50.78%] [G loss: 0.759312]\n",
      "epoch:26 step:20310 [D loss: 0.776830, acc.: 33.59%] [G loss: 0.729221]\n",
      "epoch:26 step:20311 [D loss: 0.724572, acc.: 52.34%] [G loss: 0.725655]\n",
      "epoch:26 step:20312 [D loss: 0.680184, acc.: 60.16%] [G loss: 0.797345]\n",
      "epoch:26 step:20313 [D loss: 0.680615, acc.: 62.50%] [G loss: 0.807198]\n",
      "epoch:26 step:20314 [D loss: 0.711951, acc.: 44.53%] [G loss: 0.732976]\n",
      "epoch:26 step:20315 [D loss: 0.681004, acc.: 53.12%] [G loss: 0.710043]\n",
      "epoch:26 step:20316 [D loss: 0.695589, acc.: 53.91%] [G loss: 0.766884]\n",
      "epoch:26 step:20317 [D loss: 0.736945, acc.: 44.53%] [G loss: 0.792019]\n",
      "epoch:26 step:20318 [D loss: 0.709018, acc.: 50.00%] [G loss: 0.835899]\n",
      "epoch:26 step:20319 [D loss: 0.693487, acc.: 50.78%] [G loss: 0.764435]\n",
      "epoch:26 step:20320 [D loss: 0.726491, acc.: 46.09%] [G loss: 0.803005]\n",
      "epoch:26 step:20321 [D loss: 0.658163, acc.: 60.94%] [G loss: 0.812606]\n",
      "epoch:26 step:20322 [D loss: 0.701345, acc.: 48.44%] [G loss: 0.835147]\n",
      "epoch:26 step:20323 [D loss: 0.677487, acc.: 51.56%] [G loss: 0.803840]\n",
      "epoch:26 step:20324 [D loss: 0.683917, acc.: 56.25%] [G loss: 0.815233]\n",
      "epoch:26 step:20325 [D loss: 0.656356, acc.: 64.06%] [G loss: 0.762077]\n",
      "epoch:26 step:20326 [D loss: 0.679537, acc.: 53.91%] [G loss: 0.818931]\n",
      "epoch:26 step:20327 [D loss: 0.696219, acc.: 51.56%] [G loss: 0.767723]\n",
      "epoch:26 step:20328 [D loss: 0.703723, acc.: 54.69%] [G loss: 0.778526]\n",
      "epoch:26 step:20329 [D loss: 0.705193, acc.: 46.09%] [G loss: 0.761444]\n",
      "epoch:26 step:20330 [D loss: 0.672879, acc.: 58.59%] [G loss: 0.778865]\n",
      "epoch:26 step:20331 [D loss: 0.696310, acc.: 50.78%] [G loss: 0.767938]\n",
      "epoch:26 step:20332 [D loss: 0.743806, acc.: 40.62%] [G loss: 0.751242]\n",
      "epoch:26 step:20333 [D loss: 0.680672, acc.: 53.12%] [G loss: 0.737626]\n",
      "epoch:26 step:20334 [D loss: 0.673025, acc.: 56.25%] [G loss: 0.781312]\n",
      "epoch:26 step:20335 [D loss: 0.666159, acc.: 57.81%] [G loss: 0.750594]\n",
      "epoch:26 step:20336 [D loss: 0.657053, acc.: 60.94%] [G loss: 0.753465]\n",
      "epoch:26 step:20337 [D loss: 0.698736, acc.: 52.34%] [G loss: 0.825599]\n",
      "epoch:26 step:20338 [D loss: 0.690393, acc.: 50.78%] [G loss: 0.780383]\n",
      "epoch:26 step:20339 [D loss: 0.681165, acc.: 60.94%] [G loss: 0.822563]\n",
      "epoch:26 step:20340 [D loss: 0.702392, acc.: 51.56%] [G loss: 0.738156]\n",
      "epoch:26 step:20341 [D loss: 0.696430, acc.: 50.00%] [G loss: 0.674869]\n",
      "epoch:26 step:20342 [D loss: 0.692702, acc.: 52.34%] [G loss: 0.709333]\n",
      "epoch:26 step:20343 [D loss: 0.658928, acc.: 63.28%] [G loss: 0.701871]\n",
      "epoch:26 step:20344 [D loss: 0.680249, acc.: 54.69%] [G loss: 0.749151]\n",
      "epoch:26 step:20345 [D loss: 0.671390, acc.: 58.59%] [G loss: 0.704761]\n",
      "epoch:26 step:20346 [D loss: 0.664223, acc.: 60.16%] [G loss: 0.749041]\n",
      "epoch:26 step:20347 [D loss: 0.663901, acc.: 60.16%] [G loss: 0.740073]\n",
      "epoch:26 step:20348 [D loss: 0.664749, acc.: 57.81%] [G loss: 0.751661]\n",
      "epoch:26 step:20349 [D loss: 0.716951, acc.: 42.19%] [G loss: 0.755953]\n",
      "epoch:26 step:20350 [D loss: 0.716175, acc.: 42.97%] [G loss: 0.763732]\n",
      "epoch:26 step:20351 [D loss: 0.696239, acc.: 47.66%] [G loss: 0.789029]\n",
      "epoch:26 step:20352 [D loss: 0.663165, acc.: 60.94%] [G loss: 0.774438]\n",
      "epoch:26 step:20353 [D loss: 0.680894, acc.: 57.03%] [G loss: 0.775501]\n",
      "epoch:26 step:20354 [D loss: 0.702707, acc.: 50.78%] [G loss: 0.762055]\n",
      "epoch:26 step:20355 [D loss: 0.642457, acc.: 65.62%] [G loss: 0.776515]\n",
      "epoch:26 step:20356 [D loss: 0.719303, acc.: 50.78%] [G loss: 0.748676]\n",
      "epoch:26 step:20357 [D loss: 0.638164, acc.: 66.41%] [G loss: 0.760363]\n",
      "epoch:26 step:20358 [D loss: 0.653278, acc.: 64.06%] [G loss: 0.758963]\n",
      "epoch:26 step:20359 [D loss: 0.674884, acc.: 62.50%] [G loss: 0.801588]\n",
      "epoch:26 step:20360 [D loss: 0.721840, acc.: 47.66%] [G loss: 0.708991]\n",
      "epoch:26 step:20361 [D loss: 0.688916, acc.: 54.69%] [G loss: 0.680849]\n",
      "epoch:26 step:20362 [D loss: 0.680083, acc.: 61.72%] [G loss: 0.704666]\n",
      "epoch:26 step:20363 [D loss: 0.686814, acc.: 54.69%] [G loss: 0.729506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20364 [D loss: 0.691246, acc.: 51.56%] [G loss: 0.805337]\n",
      "epoch:26 step:20365 [D loss: 0.625766, acc.: 71.09%] [G loss: 0.767993]\n",
      "epoch:26 step:20366 [D loss: 0.721208, acc.: 42.97%] [G loss: 0.699287]\n",
      "epoch:26 step:20367 [D loss: 0.698380, acc.: 53.91%] [G loss: 0.786736]\n",
      "epoch:26 step:20368 [D loss: 0.693162, acc.: 61.72%] [G loss: 0.813438]\n",
      "epoch:26 step:20369 [D loss: 0.689431, acc.: 53.91%] [G loss: 0.735682]\n",
      "epoch:26 step:20370 [D loss: 0.669430, acc.: 57.03%] [G loss: 0.794344]\n",
      "epoch:26 step:20371 [D loss: 0.647755, acc.: 61.72%] [G loss: 0.786191]\n",
      "epoch:26 step:20372 [D loss: 0.692067, acc.: 51.56%] [G loss: 0.876716]\n",
      "epoch:26 step:20373 [D loss: 0.656042, acc.: 67.19%] [G loss: 0.836547]\n",
      "epoch:26 step:20374 [D loss: 0.705238, acc.: 51.56%] [G loss: 0.766927]\n",
      "epoch:26 step:20375 [D loss: 0.728261, acc.: 45.31%] [G loss: 0.785820]\n",
      "epoch:26 step:20376 [D loss: 0.714039, acc.: 45.31%] [G loss: 0.688756]\n",
      "epoch:26 step:20377 [D loss: 0.750531, acc.: 33.59%] [G loss: 0.682302]\n",
      "epoch:26 step:20378 [D loss: 0.702844, acc.: 46.88%] [G loss: 0.683885]\n",
      "epoch:26 step:20379 [D loss: 0.706059, acc.: 52.34%] [G loss: 0.709012]\n",
      "epoch:26 step:20380 [D loss: 0.685143, acc.: 53.91%] [G loss: 0.673070]\n",
      "epoch:26 step:20381 [D loss: 0.652521, acc.: 61.72%] [G loss: 0.734237]\n",
      "epoch:26 step:20382 [D loss: 0.732991, acc.: 39.06%] [G loss: 0.693641]\n",
      "epoch:26 step:20383 [D loss: 0.774659, acc.: 38.28%] [G loss: 0.677543]\n",
      "epoch:26 step:20384 [D loss: 0.681730, acc.: 53.12%] [G loss: 0.722444]\n",
      "epoch:26 step:20385 [D loss: 0.660390, acc.: 62.50%] [G loss: 0.800460]\n",
      "epoch:26 step:20386 [D loss: 0.684382, acc.: 53.12%] [G loss: 0.705967]\n",
      "epoch:26 step:20387 [D loss: 0.708755, acc.: 44.53%] [G loss: 0.768792]\n",
      "epoch:26 step:20388 [D loss: 0.731448, acc.: 43.75%] [G loss: 0.724002]\n",
      "epoch:26 step:20389 [D loss: 0.669061, acc.: 61.72%] [G loss: 0.738414]\n",
      "epoch:26 step:20390 [D loss: 0.688965, acc.: 55.47%] [G loss: 0.851091]\n",
      "epoch:26 step:20391 [D loss: 0.695542, acc.: 51.56%] [G loss: 0.757685]\n",
      "epoch:26 step:20392 [D loss: 0.703201, acc.: 47.66%] [G loss: 0.823349]\n",
      "epoch:26 step:20393 [D loss: 0.687736, acc.: 54.69%] [G loss: 0.792575]\n",
      "epoch:26 step:20394 [D loss: 0.655065, acc.: 64.06%] [G loss: 0.749548]\n",
      "epoch:26 step:20395 [D loss: 0.666959, acc.: 57.81%] [G loss: 0.771797]\n",
      "epoch:26 step:20396 [D loss: 0.677912, acc.: 53.12%] [G loss: 0.840817]\n",
      "epoch:26 step:20397 [D loss: 0.702501, acc.: 56.25%] [G loss: 0.741141]\n",
      "epoch:26 step:20398 [D loss: 0.668021, acc.: 53.12%] [G loss: 0.780932]\n",
      "epoch:26 step:20399 [D loss: 0.713290, acc.: 50.00%] [G loss: 0.768047]\n",
      "epoch:26 step:20400 [D loss: 0.695042, acc.: 48.44%] [G loss: 0.762469]\n",
      "epoch:26 step:20401 [D loss: 0.705833, acc.: 49.22%] [G loss: 0.728268]\n",
      "epoch:26 step:20402 [D loss: 0.660637, acc.: 63.28%] [G loss: 0.772230]\n",
      "epoch:26 step:20403 [D loss: 0.675060, acc.: 61.72%] [G loss: 0.834157]\n",
      "epoch:26 step:20404 [D loss: 0.691940, acc.: 51.56%] [G loss: 0.777710]\n",
      "epoch:26 step:20405 [D loss: 0.661849, acc.: 65.62%] [G loss: 0.842798]\n",
      "epoch:26 step:20406 [D loss: 0.689570, acc.: 53.12%] [G loss: 0.753666]\n",
      "epoch:26 step:20407 [D loss: 0.653795, acc.: 61.72%] [G loss: 0.787883]\n",
      "epoch:26 step:20408 [D loss: 0.642099, acc.: 65.62%] [G loss: 0.700580]\n",
      "epoch:26 step:20409 [D loss: 0.675030, acc.: 57.81%] [G loss: 0.722924]\n",
      "epoch:26 step:20410 [D loss: 0.669715, acc.: 58.59%] [G loss: 0.717337]\n",
      "epoch:26 step:20411 [D loss: 0.667352, acc.: 50.78%] [G loss: 0.785045]\n",
      "epoch:26 step:20412 [D loss: 0.692872, acc.: 53.91%] [G loss: 0.774361]\n",
      "epoch:26 step:20413 [D loss: 0.625898, acc.: 70.31%] [G loss: 0.799708]\n",
      "epoch:26 step:20414 [D loss: 0.701334, acc.: 48.44%] [G loss: 0.847101]\n",
      "epoch:26 step:20415 [D loss: 0.693042, acc.: 50.00%] [G loss: 0.733477]\n",
      "epoch:26 step:20416 [D loss: 0.738279, acc.: 43.75%] [G loss: 0.746050]\n",
      "epoch:26 step:20417 [D loss: 0.704936, acc.: 51.56%] [G loss: 0.835063]\n",
      "epoch:26 step:20418 [D loss: 0.654107, acc.: 66.41%] [G loss: 0.762118]\n",
      "epoch:26 step:20419 [D loss: 0.686437, acc.: 57.03%] [G loss: 0.783288]\n",
      "epoch:26 step:20420 [D loss: 0.657672, acc.: 64.06%] [G loss: 0.782190]\n",
      "epoch:26 step:20421 [D loss: 0.721958, acc.: 44.53%] [G loss: 0.829501]\n",
      "epoch:26 step:20422 [D loss: 0.692925, acc.: 53.12%] [G loss: 0.733458]\n",
      "epoch:26 step:20423 [D loss: 0.710931, acc.: 47.66%] [G loss: 0.687957]\n",
      "epoch:26 step:20424 [D loss: 0.671048, acc.: 59.38%] [G loss: 0.790042]\n",
      "epoch:26 step:20425 [D loss: 0.649292, acc.: 63.28%] [G loss: 0.714142]\n",
      "epoch:26 step:20426 [D loss: 0.708025, acc.: 52.34%] [G loss: 0.749012]\n",
      "epoch:26 step:20427 [D loss: 0.668448, acc.: 58.59%] [G loss: 0.770403]\n",
      "epoch:26 step:20428 [D loss: 0.688433, acc.: 47.66%] [G loss: 0.698443]\n",
      "epoch:26 step:20429 [D loss: 0.712158, acc.: 48.44%] [G loss: 0.769725]\n",
      "epoch:26 step:20430 [D loss: 0.694782, acc.: 50.78%] [G loss: 0.750826]\n",
      "epoch:26 step:20431 [D loss: 0.713966, acc.: 49.22%] [G loss: 0.778472]\n",
      "epoch:26 step:20432 [D loss: 0.712113, acc.: 46.09%] [G loss: 0.753599]\n",
      "epoch:26 step:20433 [D loss: 0.638170, acc.: 69.53%] [G loss: 0.752986]\n",
      "epoch:26 step:20434 [D loss: 0.723275, acc.: 50.78%] [G loss: 0.692221]\n",
      "epoch:26 step:20435 [D loss: 0.718025, acc.: 47.66%] [G loss: 0.683850]\n",
      "epoch:26 step:20436 [D loss: 0.718711, acc.: 40.62%] [G loss: 0.714212]\n",
      "epoch:26 step:20437 [D loss: 0.696008, acc.: 52.34%] [G loss: 0.685764]\n",
      "epoch:26 step:20438 [D loss: 0.678761, acc.: 58.59%] [G loss: 0.709796]\n",
      "epoch:26 step:20439 [D loss: 0.662230, acc.: 63.28%] [G loss: 0.687815]\n",
      "epoch:26 step:20440 [D loss: 0.710234, acc.: 46.09%] [G loss: 0.734913]\n",
      "epoch:26 step:20441 [D loss: 0.731997, acc.: 49.22%] [G loss: 0.715270]\n",
      "epoch:26 step:20442 [D loss: 0.698330, acc.: 49.22%] [G loss: 0.671928]\n",
      "epoch:26 step:20443 [D loss: 0.699742, acc.: 51.56%] [G loss: 0.708266]\n",
      "epoch:26 step:20444 [D loss: 0.712499, acc.: 46.88%] [G loss: 0.710351]\n",
      "epoch:26 step:20445 [D loss: 0.678514, acc.: 57.81%] [G loss: 0.682397]\n",
      "epoch:26 step:20446 [D loss: 0.698972, acc.: 51.56%] [G loss: 0.791822]\n",
      "epoch:26 step:20447 [D loss: 0.712949, acc.: 47.66%] [G loss: 0.794450]\n",
      "epoch:26 step:20448 [D loss: 0.692781, acc.: 53.91%] [G loss: 0.852774]\n",
      "epoch:26 step:20449 [D loss: 0.686543, acc.: 54.69%] [G loss: 0.815585]\n",
      "epoch:26 step:20450 [D loss: 0.687055, acc.: 57.03%] [G loss: 0.815821]\n",
      "epoch:26 step:20451 [D loss: 0.658808, acc.: 60.94%] [G loss: 0.849453]\n",
      "epoch:26 step:20452 [D loss: 0.662502, acc.: 60.94%] [G loss: 0.812310]\n",
      "epoch:26 step:20453 [D loss: 0.699425, acc.: 50.00%] [G loss: 0.779288]\n",
      "epoch:26 step:20454 [D loss: 0.658107, acc.: 61.72%] [G loss: 0.799225]\n",
      "epoch:26 step:20455 [D loss: 0.725308, acc.: 45.31%] [G loss: 0.739481]\n",
      "epoch:26 step:20456 [D loss: 0.648031, acc.: 64.84%] [G loss: 0.847640]\n",
      "epoch:26 step:20457 [D loss: 0.744313, acc.: 42.19%] [G loss: 0.793441]\n",
      "epoch:26 step:20458 [D loss: 0.674425, acc.: 62.50%] [G loss: 0.750119]\n",
      "epoch:26 step:20459 [D loss: 0.635641, acc.: 64.06%] [G loss: 0.792352]\n",
      "epoch:26 step:20460 [D loss: 0.652233, acc.: 67.19%] [G loss: 0.797390]\n",
      "epoch:26 step:20461 [D loss: 0.670175, acc.: 59.38%] [G loss: 0.757846]\n",
      "epoch:26 step:20462 [D loss: 0.663399, acc.: 57.03%] [G loss: 0.750250]\n",
      "epoch:26 step:20463 [D loss: 0.658537, acc.: 60.16%] [G loss: 0.713455]\n",
      "epoch:26 step:20464 [D loss: 0.685532, acc.: 54.69%] [G loss: 0.716927]\n",
      "epoch:26 step:20465 [D loss: 0.675013, acc.: 59.38%] [G loss: 0.780276]\n",
      "epoch:26 step:20466 [D loss: 0.653415, acc.: 61.72%] [G loss: 0.748113]\n",
      "epoch:26 step:20467 [D loss: 0.698459, acc.: 53.91%] [G loss: 0.676269]\n",
      "epoch:26 step:20468 [D loss: 0.691461, acc.: 54.69%] [G loss: 0.753917]\n",
      "epoch:26 step:20469 [D loss: 0.699338, acc.: 52.34%] [G loss: 0.774064]\n",
      "epoch:26 step:20470 [D loss: 0.671709, acc.: 54.69%] [G loss: 0.726968]\n",
      "epoch:26 step:20471 [D loss: 0.742526, acc.: 39.06%] [G loss: 0.783507]\n",
      "epoch:26 step:20472 [D loss: 0.655808, acc.: 58.59%] [G loss: 0.769706]\n",
      "epoch:26 step:20473 [D loss: 0.694032, acc.: 54.69%] [G loss: 0.733528]\n",
      "epoch:26 step:20474 [D loss: 0.681242, acc.: 56.25%] [G loss: 0.727178]\n",
      "epoch:26 step:20475 [D loss: 0.678218, acc.: 52.34%] [G loss: 0.808024]\n",
      "epoch:26 step:20476 [D loss: 0.693061, acc.: 53.12%] [G loss: 0.854232]\n",
      "epoch:26 step:20477 [D loss: 0.716918, acc.: 43.75%] [G loss: 0.766767]\n",
      "epoch:26 step:20478 [D loss: 0.729246, acc.: 46.09%] [G loss: 0.815135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20479 [D loss: 0.710450, acc.: 51.56%] [G loss: 0.818817]\n",
      "epoch:26 step:20480 [D loss: 0.716169, acc.: 46.09%] [G loss: 0.803809]\n",
      "epoch:26 step:20481 [D loss: 0.707297, acc.: 49.22%] [G loss: 0.813520]\n",
      "epoch:26 step:20482 [D loss: 0.683342, acc.: 54.69%] [G loss: 0.792952]\n",
      "epoch:26 step:20483 [D loss: 0.693150, acc.: 55.47%] [G loss: 0.705226]\n",
      "epoch:26 step:20484 [D loss: 0.699147, acc.: 51.56%] [G loss: 0.739878]\n",
      "epoch:26 step:20485 [D loss: 0.719281, acc.: 41.41%] [G loss: 0.769040]\n",
      "epoch:26 step:20486 [D loss: 0.666901, acc.: 58.59%] [G loss: 0.726746]\n",
      "epoch:26 step:20487 [D loss: 0.689960, acc.: 52.34%] [G loss: 0.766772]\n",
      "epoch:26 step:20488 [D loss: 0.724360, acc.: 46.88%] [G loss: 0.802094]\n",
      "epoch:26 step:20489 [D loss: 0.671497, acc.: 56.25%] [G loss: 0.760898]\n",
      "epoch:26 step:20490 [D loss: 0.698697, acc.: 54.69%] [G loss: 0.780655]\n",
      "epoch:26 step:20491 [D loss: 0.689443, acc.: 50.78%] [G loss: 0.819337]\n",
      "epoch:26 step:20492 [D loss: 0.707227, acc.: 46.09%] [G loss: 0.788124]\n",
      "epoch:26 step:20493 [D loss: 0.641075, acc.: 64.84%] [G loss: 0.812334]\n",
      "epoch:26 step:20494 [D loss: 0.730649, acc.: 45.31%] [G loss: 0.748870]\n",
      "epoch:26 step:20495 [D loss: 0.644435, acc.: 64.84%] [G loss: 0.718504]\n",
      "epoch:26 step:20496 [D loss: 0.698563, acc.: 54.69%] [G loss: 0.768998]\n",
      "epoch:26 step:20497 [D loss: 0.677114, acc.: 60.94%] [G loss: 0.771752]\n",
      "epoch:26 step:20498 [D loss: 0.662461, acc.: 64.84%] [G loss: 0.760635]\n",
      "epoch:26 step:20499 [D loss: 0.701762, acc.: 49.22%] [G loss: 0.721700]\n",
      "epoch:26 step:20500 [D loss: 0.793724, acc.: 32.03%] [G loss: 0.739240]\n",
      "epoch:26 step:20501 [D loss: 0.670977, acc.: 56.25%] [G loss: 0.836190]\n",
      "epoch:26 step:20502 [D loss: 0.668164, acc.: 61.72%] [G loss: 0.814716]\n",
      "epoch:26 step:20503 [D loss: 0.715756, acc.: 44.53%] [G loss: 0.750760]\n",
      "epoch:26 step:20504 [D loss: 0.666988, acc.: 60.16%] [G loss: 0.761613]\n",
      "epoch:26 step:20505 [D loss: 0.734650, acc.: 42.97%] [G loss: 0.736035]\n",
      "epoch:26 step:20506 [D loss: 0.739368, acc.: 33.59%] [G loss: 0.717857]\n",
      "epoch:26 step:20507 [D loss: 0.653656, acc.: 64.84%] [G loss: 0.744665]\n",
      "epoch:26 step:20508 [D loss: 0.700029, acc.: 54.69%] [G loss: 0.792186]\n",
      "epoch:26 step:20509 [D loss: 0.680903, acc.: 59.38%] [G loss: 0.746620]\n",
      "epoch:26 step:20510 [D loss: 0.692856, acc.: 52.34%] [G loss: 0.735683]\n",
      "epoch:26 step:20511 [D loss: 0.745239, acc.: 39.06%] [G loss: 0.771388]\n",
      "epoch:26 step:20512 [D loss: 0.709537, acc.: 48.44%] [G loss: 0.714488]\n",
      "epoch:26 step:20513 [D loss: 0.675619, acc.: 58.59%] [G loss: 0.745119]\n",
      "epoch:26 step:20514 [D loss: 0.675922, acc.: 58.59%] [G loss: 0.805823]\n",
      "epoch:26 step:20515 [D loss: 0.676514, acc.: 51.56%] [G loss: 0.721089]\n",
      "epoch:26 step:20516 [D loss: 0.689653, acc.: 53.91%] [G loss: 0.863001]\n",
      "epoch:26 step:20517 [D loss: 0.634946, acc.: 66.41%] [G loss: 0.843301]\n",
      "epoch:26 step:20518 [D loss: 0.648185, acc.: 62.50%] [G loss: 0.890495]\n",
      "epoch:26 step:20519 [D loss: 0.738264, acc.: 44.53%] [G loss: 0.742236]\n",
      "epoch:26 step:20520 [D loss: 0.697535, acc.: 54.69%] [G loss: 0.792185]\n",
      "epoch:26 step:20521 [D loss: 0.696112, acc.: 53.91%] [G loss: 0.714614]\n",
      "epoch:26 step:20522 [D loss: 0.684248, acc.: 50.78%] [G loss: 0.735522]\n",
      "epoch:26 step:20523 [D loss: 0.685568, acc.: 53.12%] [G loss: 0.714469]\n",
      "epoch:26 step:20524 [D loss: 0.721252, acc.: 43.75%] [G loss: 0.754253]\n",
      "epoch:26 step:20525 [D loss: 0.717374, acc.: 46.88%] [G loss: 0.682008]\n",
      "epoch:26 step:20526 [D loss: 0.647516, acc.: 63.28%] [G loss: 0.762139]\n",
      "epoch:26 step:20527 [D loss: 0.699426, acc.: 55.47%] [G loss: 0.739277]\n",
      "epoch:26 step:20528 [D loss: 0.665565, acc.: 59.38%] [G loss: 0.809968]\n",
      "epoch:26 step:20529 [D loss: 0.683515, acc.: 55.47%] [G loss: 0.797668]\n",
      "epoch:26 step:20530 [D loss: 0.628133, acc.: 68.75%] [G loss: 0.766603]\n",
      "epoch:26 step:20531 [D loss: 0.652678, acc.: 64.84%] [G loss: 0.759231]\n",
      "epoch:26 step:20532 [D loss: 0.731875, acc.: 45.31%] [G loss: 0.682835]\n",
      "epoch:26 step:20533 [D loss: 0.652481, acc.: 63.28%] [G loss: 0.737542]\n",
      "epoch:26 step:20534 [D loss: 0.696382, acc.: 53.91%] [G loss: 0.728782]\n",
      "epoch:26 step:20535 [D loss: 0.659791, acc.: 62.50%] [G loss: 0.788469]\n",
      "epoch:26 step:20536 [D loss: 0.745404, acc.: 38.28%] [G loss: 0.715509]\n",
      "epoch:26 step:20537 [D loss: 0.668268, acc.: 60.94%] [G loss: 0.760835]\n",
      "epoch:26 step:20538 [D loss: 0.693315, acc.: 57.03%] [G loss: 0.717375]\n",
      "epoch:26 step:20539 [D loss: 0.675586, acc.: 62.50%] [G loss: 0.799694]\n",
      "epoch:26 step:20540 [D loss: 0.662089, acc.: 59.38%] [G loss: 0.745622]\n",
      "epoch:26 step:20541 [D loss: 0.745868, acc.: 37.50%] [G loss: 0.729417]\n",
      "epoch:26 step:20542 [D loss: 0.665670, acc.: 63.28%] [G loss: 0.709103]\n",
      "epoch:26 step:20543 [D loss: 0.682604, acc.: 57.03%] [G loss: 0.731382]\n",
      "epoch:26 step:20544 [D loss: 0.674903, acc.: 58.59%] [G loss: 0.794717]\n",
      "epoch:26 step:20545 [D loss: 0.728601, acc.: 50.00%] [G loss: 0.754065]\n",
      "epoch:26 step:20546 [D loss: 0.724831, acc.: 45.31%] [G loss: 0.830497]\n",
      "epoch:26 step:20547 [D loss: 0.738978, acc.: 43.75%] [G loss: 0.785909]\n",
      "epoch:26 step:20548 [D loss: 0.677113, acc.: 56.25%] [G loss: 0.832853]\n",
      "epoch:26 step:20549 [D loss: 0.698168, acc.: 56.25%] [G loss: 0.823286]\n",
      "epoch:26 step:20550 [D loss: 0.717970, acc.: 45.31%] [G loss: 0.703053]\n",
      "epoch:26 step:20551 [D loss: 0.703345, acc.: 50.00%] [G loss: 0.753683]\n",
      "epoch:26 step:20552 [D loss: 0.697650, acc.: 52.34%] [G loss: 0.838753]\n",
      "epoch:26 step:20553 [D loss: 0.649844, acc.: 71.09%] [G loss: 0.803135]\n",
      "epoch:26 step:20554 [D loss: 0.696267, acc.: 53.91%] [G loss: 0.723906]\n",
      "epoch:26 step:20555 [D loss: 0.679097, acc.: 57.03%] [G loss: 0.736996]\n",
      "epoch:26 step:20556 [D loss: 0.688020, acc.: 57.81%] [G loss: 0.784283]\n",
      "epoch:26 step:20557 [D loss: 0.659208, acc.: 67.19%] [G loss: 0.698125]\n",
      "epoch:26 step:20558 [D loss: 0.680285, acc.: 59.38%] [G loss: 0.782738]\n",
      "epoch:26 step:20559 [D loss: 0.703319, acc.: 48.44%] [G loss: 0.762298]\n",
      "epoch:26 step:20560 [D loss: 0.684904, acc.: 55.47%] [G loss: 0.745463]\n",
      "epoch:26 step:20561 [D loss: 0.745751, acc.: 38.28%] [G loss: 0.774597]\n",
      "epoch:26 step:20562 [D loss: 0.708985, acc.: 46.88%] [G loss: 0.722631]\n",
      "epoch:26 step:20563 [D loss: 0.736863, acc.: 46.09%] [G loss: 0.723015]\n",
      "epoch:26 step:20564 [D loss: 0.691572, acc.: 50.78%] [G loss: 0.824696]\n",
      "epoch:26 step:20565 [D loss: 0.675814, acc.: 55.47%] [G loss: 0.816222]\n",
      "epoch:26 step:20566 [D loss: 0.672034, acc.: 56.25%] [G loss: 0.789753]\n",
      "epoch:26 step:20567 [D loss: 0.712355, acc.: 46.88%] [G loss: 0.791529]\n",
      "epoch:26 step:20568 [D loss: 0.704187, acc.: 52.34%] [G loss: 0.871116]\n",
      "epoch:26 step:20569 [D loss: 0.669594, acc.: 57.03%] [G loss: 0.910980]\n",
      "epoch:26 step:20570 [D loss: 0.704808, acc.: 55.47%] [G loss: 0.842148]\n",
      "epoch:26 step:20571 [D loss: 0.672614, acc.: 56.25%] [G loss: 0.841899]\n",
      "epoch:26 step:20572 [D loss: 0.686188, acc.: 54.69%] [G loss: 0.778550]\n",
      "epoch:26 step:20573 [D loss: 0.730848, acc.: 44.53%] [G loss: 0.813517]\n",
      "epoch:26 step:20574 [D loss: 0.712693, acc.: 51.56%] [G loss: 0.739974]\n",
      "epoch:26 step:20575 [D loss: 0.659729, acc.: 59.38%] [G loss: 0.797506]\n",
      "epoch:26 step:20576 [D loss: 0.697669, acc.: 49.22%] [G loss: 0.751696]\n",
      "epoch:26 step:20577 [D loss: 0.634993, acc.: 64.84%] [G loss: 0.757049]\n",
      "epoch:26 step:20578 [D loss: 0.663980, acc.: 62.50%] [G loss: 0.767634]\n",
      "epoch:26 step:20579 [D loss: 0.675899, acc.: 59.38%] [G loss: 0.778987]\n",
      "epoch:26 step:20580 [D loss: 0.680637, acc.: 56.25%] [G loss: 0.720096]\n",
      "epoch:26 step:20581 [D loss: 0.733933, acc.: 42.97%] [G loss: 0.809036]\n",
      "epoch:26 step:20582 [D loss: 0.693763, acc.: 52.34%] [G loss: 0.757998]\n",
      "epoch:26 step:20583 [D loss: 0.792193, acc.: 33.59%] [G loss: 0.695867]\n",
      "epoch:26 step:20584 [D loss: 0.715004, acc.: 42.97%] [G loss: 0.714848]\n",
      "epoch:26 step:20585 [D loss: 0.646837, acc.: 65.62%] [G loss: 0.779132]\n",
      "epoch:26 step:20586 [D loss: 0.687176, acc.: 55.47%] [G loss: 0.693274]\n",
      "epoch:26 step:20587 [D loss: 0.685127, acc.: 53.91%] [G loss: 0.819074]\n",
      "epoch:26 step:20588 [D loss: 0.664521, acc.: 58.59%] [G loss: 0.772120]\n",
      "epoch:26 step:20589 [D loss: 0.684030, acc.: 51.56%] [G loss: 0.786637]\n",
      "epoch:26 step:20590 [D loss: 0.692005, acc.: 52.34%] [G loss: 0.795498]\n",
      "epoch:26 step:20591 [D loss: 0.673868, acc.: 60.16%] [G loss: 0.785975]\n",
      "epoch:26 step:20592 [D loss: 0.668572, acc.: 56.25%] [G loss: 0.837413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20593 [D loss: 0.714647, acc.: 50.78%] [G loss: 0.822575]\n",
      "epoch:26 step:20594 [D loss: 0.700954, acc.: 53.12%] [G loss: 0.743564]\n",
      "epoch:26 step:20595 [D loss: 0.694339, acc.: 55.47%] [G loss: 0.827693]\n",
      "epoch:26 step:20596 [D loss: 0.682041, acc.: 55.47%] [G loss: 0.798398]\n",
      "epoch:26 step:20597 [D loss: 0.682866, acc.: 51.56%] [G loss: 0.746678]\n",
      "epoch:26 step:20598 [D loss: 0.744195, acc.: 42.97%] [G loss: 0.707142]\n",
      "epoch:26 step:20599 [D loss: 0.667204, acc.: 62.50%] [G loss: 0.699149]\n",
      "epoch:26 step:20600 [D loss: 0.691263, acc.: 53.91%] [G loss: 0.710917]\n",
      "epoch:26 step:20601 [D loss: 0.680200, acc.: 63.28%] [G loss: 0.701906]\n",
      "epoch:26 step:20602 [D loss: 0.654468, acc.: 64.84%] [G loss: 0.775616]\n",
      "epoch:26 step:20603 [D loss: 0.686068, acc.: 52.34%] [G loss: 0.783394]\n",
      "epoch:26 step:20604 [D loss: 0.679294, acc.: 57.81%] [G loss: 0.780637]\n",
      "epoch:26 step:20605 [D loss: 0.717667, acc.: 47.66%] [G loss: 0.721962]\n",
      "epoch:26 step:20606 [D loss: 0.694834, acc.: 46.88%] [G loss: 0.743454]\n",
      "epoch:26 step:20607 [D loss: 0.698042, acc.: 58.59%] [G loss: 0.707352]\n",
      "epoch:26 step:20608 [D loss: 0.693800, acc.: 54.69%] [G loss: 0.753583]\n",
      "epoch:26 step:20609 [D loss: 0.705375, acc.: 47.66%] [G loss: 0.782525]\n",
      "epoch:26 step:20610 [D loss: 0.712545, acc.: 46.09%] [G loss: 0.689736]\n",
      "epoch:26 step:20611 [D loss: 0.737633, acc.: 40.62%] [G loss: 0.719068]\n",
      "epoch:26 step:20612 [D loss: 0.714403, acc.: 42.97%] [G loss: 0.759989]\n",
      "epoch:26 step:20613 [D loss: 0.664637, acc.: 65.62%] [G loss: 0.737219]\n",
      "epoch:26 step:20614 [D loss: 0.614976, acc.: 74.22%] [G loss: 0.693620]\n",
      "epoch:26 step:20615 [D loss: 0.700441, acc.: 57.03%] [G loss: 0.743327]\n",
      "epoch:26 step:20616 [D loss: 0.656871, acc.: 60.16%] [G loss: 0.778943]\n",
      "epoch:26 step:20617 [D loss: 0.691297, acc.: 53.91%] [G loss: 0.844159]\n",
      "epoch:26 step:20618 [D loss: 0.681168, acc.: 53.12%] [G loss: 0.760717]\n",
      "epoch:26 step:20619 [D loss: 0.692556, acc.: 56.25%] [G loss: 0.788184]\n",
      "epoch:26 step:20620 [D loss: 0.719014, acc.: 48.44%] [G loss: 0.781578]\n",
      "epoch:26 step:20621 [D loss: 0.766947, acc.: 34.38%] [G loss: 0.798500]\n",
      "epoch:26 step:20622 [D loss: 0.698280, acc.: 53.91%] [G loss: 0.795595]\n",
      "epoch:26 step:20623 [D loss: 0.719111, acc.: 37.50%] [G loss: 0.756011]\n",
      "epoch:26 step:20624 [D loss: 0.718929, acc.: 39.84%] [G loss: 0.756194]\n",
      "epoch:26 step:20625 [D loss: 0.688150, acc.: 52.34%] [G loss: 0.768607]\n",
      "epoch:26 step:20626 [D loss: 0.660572, acc.: 65.62%] [G loss: 0.792326]\n",
      "epoch:26 step:20627 [D loss: 0.743584, acc.: 38.28%] [G loss: 0.752200]\n",
      "epoch:26 step:20628 [D loss: 0.677854, acc.: 54.69%] [G loss: 0.793699]\n",
      "epoch:26 step:20629 [D loss: 0.687166, acc.: 57.03%] [G loss: 0.785672]\n",
      "epoch:26 step:20630 [D loss: 0.698312, acc.: 49.22%] [G loss: 0.746507]\n",
      "epoch:26 step:20631 [D loss: 0.721670, acc.: 44.53%] [G loss: 0.798384]\n",
      "epoch:26 step:20632 [D loss: 0.688885, acc.: 55.47%] [G loss: 0.781842]\n",
      "epoch:26 step:20633 [D loss: 0.723139, acc.: 40.62%] [G loss: 0.748847]\n",
      "epoch:26 step:20634 [D loss: 0.750762, acc.: 41.41%] [G loss: 0.787801]\n",
      "epoch:26 step:20635 [D loss: 0.721690, acc.: 50.00%] [G loss: 0.788640]\n",
      "epoch:26 step:20636 [D loss: 0.722649, acc.: 43.75%] [G loss: 0.816596]\n",
      "epoch:26 step:20637 [D loss: 0.725142, acc.: 48.44%] [G loss: 0.733509]\n",
      "epoch:26 step:20638 [D loss: 0.700809, acc.: 52.34%] [G loss: 0.721495]\n",
      "epoch:26 step:20639 [D loss: 0.623211, acc.: 72.66%] [G loss: 0.830334]\n",
      "epoch:26 step:20640 [D loss: 0.671991, acc.: 55.47%] [G loss: 0.806829]\n",
      "epoch:26 step:20641 [D loss: 0.717286, acc.: 49.22%] [G loss: 0.744261]\n",
      "epoch:26 step:20642 [D loss: 0.651877, acc.: 63.28%] [G loss: 0.801646]\n",
      "epoch:26 step:20643 [D loss: 0.712712, acc.: 43.75%] [G loss: 0.774998]\n",
      "epoch:26 step:20644 [D loss: 0.755054, acc.: 31.25%] [G loss: 0.688671]\n",
      "epoch:26 step:20645 [D loss: 0.701027, acc.: 52.34%] [G loss: 0.717234]\n",
      "epoch:26 step:20646 [D loss: 0.738845, acc.: 39.84%] [G loss: 0.730916]\n",
      "epoch:26 step:20647 [D loss: 0.624417, acc.: 75.00%] [G loss: 0.862154]\n",
      "epoch:26 step:20648 [D loss: 0.690926, acc.: 57.03%] [G loss: 0.798799]\n",
      "epoch:26 step:20649 [D loss: 0.692312, acc.: 57.81%] [G loss: 0.730307]\n",
      "epoch:26 step:20650 [D loss: 0.639916, acc.: 67.97%] [G loss: 0.801265]\n",
      "epoch:26 step:20651 [D loss: 0.680451, acc.: 60.16%] [G loss: 0.834835]\n",
      "epoch:26 step:20652 [D loss: 0.718750, acc.: 39.06%] [G loss: 0.717157]\n",
      "epoch:26 step:20653 [D loss: 0.658566, acc.: 61.72%] [G loss: 0.726500]\n",
      "epoch:26 step:20654 [D loss: 0.697539, acc.: 50.00%] [G loss: 0.806474]\n",
      "epoch:26 step:20655 [D loss: 0.693683, acc.: 52.34%] [G loss: 0.759760]\n",
      "epoch:26 step:20656 [D loss: 0.684585, acc.: 56.25%] [G loss: 0.771678]\n",
      "epoch:26 step:20657 [D loss: 0.685154, acc.: 50.00%] [G loss: 0.770224]\n",
      "epoch:26 step:20658 [D loss: 0.658256, acc.: 64.06%] [G loss: 0.811880]\n",
      "epoch:26 step:20659 [D loss: 0.709142, acc.: 47.66%] [G loss: 0.753100]\n",
      "epoch:26 step:20660 [D loss: 0.772730, acc.: 36.72%] [G loss: 0.691801]\n",
      "epoch:26 step:20661 [D loss: 0.697701, acc.: 55.47%] [G loss: 0.764697]\n",
      "epoch:26 step:20662 [D loss: 0.639828, acc.: 68.75%] [G loss: 0.809808]\n",
      "epoch:26 step:20663 [D loss: 0.736052, acc.: 43.75%] [G loss: 0.797260]\n",
      "epoch:26 step:20664 [D loss: 0.666940, acc.: 55.47%] [G loss: 0.851717]\n",
      "epoch:26 step:20665 [D loss: 0.690636, acc.: 53.91%] [G loss: 0.786555]\n",
      "epoch:26 step:20666 [D loss: 0.695091, acc.: 57.03%] [G loss: 0.804531]\n",
      "epoch:26 step:20667 [D loss: 0.693340, acc.: 49.22%] [G loss: 0.758950]\n",
      "epoch:26 step:20668 [D loss: 0.681756, acc.: 57.03%] [G loss: 0.833832]\n",
      "epoch:26 step:20669 [D loss: 0.739606, acc.: 46.88%] [G loss: 0.681117]\n",
      "epoch:26 step:20670 [D loss: 0.743249, acc.: 39.06%] [G loss: 0.715432]\n",
      "epoch:26 step:20671 [D loss: 0.690910, acc.: 50.00%] [G loss: 0.743040]\n",
      "epoch:26 step:20672 [D loss: 0.737513, acc.: 47.66%] [G loss: 0.724202]\n",
      "epoch:26 step:20673 [D loss: 0.653916, acc.: 61.72%] [G loss: 0.758659]\n",
      "epoch:26 step:20674 [D loss: 0.689434, acc.: 59.38%] [G loss: 0.735745]\n",
      "epoch:26 step:20675 [D loss: 0.681977, acc.: 54.69%] [G loss: 0.845475]\n",
      "epoch:26 step:20676 [D loss: 0.695531, acc.: 53.12%] [G loss: 0.784312]\n",
      "epoch:26 step:20677 [D loss: 0.689174, acc.: 55.47%] [G loss: 0.848178]\n",
      "epoch:26 step:20678 [D loss: 0.681097, acc.: 54.69%] [G loss: 0.846591]\n",
      "epoch:26 step:20679 [D loss: 0.714524, acc.: 46.88%] [G loss: 0.821331]\n",
      "epoch:26 step:20680 [D loss: 0.721918, acc.: 44.53%] [G loss: 0.788463]\n",
      "epoch:26 step:20681 [D loss: 0.681104, acc.: 57.81%] [G loss: 0.818996]\n",
      "epoch:26 step:20682 [D loss: 0.653027, acc.: 60.94%] [G loss: 0.803781]\n",
      "epoch:26 step:20683 [D loss: 0.719898, acc.: 48.44%] [G loss: 0.753764]\n",
      "epoch:26 step:20684 [D loss: 0.676659, acc.: 60.94%] [G loss: 0.828209]\n",
      "epoch:26 step:20685 [D loss: 0.659568, acc.: 63.28%] [G loss: 0.680301]\n",
      "epoch:26 step:20686 [D loss: 0.701691, acc.: 51.56%] [G loss: 0.794099]\n",
      "epoch:26 step:20687 [D loss: 0.664696, acc.: 60.16%] [G loss: 0.802711]\n",
      "epoch:26 step:20688 [D loss: 0.672195, acc.: 58.59%] [G loss: 0.779003]\n",
      "epoch:26 step:20689 [D loss: 0.646093, acc.: 65.62%] [G loss: 0.742662]\n",
      "epoch:26 step:20690 [D loss: 0.690193, acc.: 53.91%] [G loss: 0.706074]\n",
      "epoch:26 step:20691 [D loss: 0.698048, acc.: 50.78%] [G loss: 0.745807]\n",
      "epoch:26 step:20692 [D loss: 0.640341, acc.: 66.41%] [G loss: 0.819981]\n",
      "epoch:26 step:20693 [D loss: 0.704057, acc.: 46.88%] [G loss: 0.781153]\n",
      "epoch:26 step:20694 [D loss: 0.745041, acc.: 34.38%] [G loss: 0.763658]\n",
      "epoch:26 step:20695 [D loss: 0.703505, acc.: 52.34%] [G loss: 0.846703]\n",
      "epoch:26 step:20696 [D loss: 0.688309, acc.: 54.69%] [G loss: 0.810556]\n",
      "epoch:26 step:20697 [D loss: 0.777858, acc.: 38.28%] [G loss: 0.750003]\n",
      "epoch:26 step:20698 [D loss: 0.680482, acc.: 55.47%] [G loss: 0.699956]\n",
      "epoch:26 step:20699 [D loss: 0.687399, acc.: 51.56%] [G loss: 0.723071]\n",
      "epoch:26 step:20700 [D loss: 0.664271, acc.: 61.72%] [G loss: 0.731362]\n",
      "epoch:26 step:20701 [D loss: 0.639515, acc.: 64.06%] [G loss: 0.688586]\n",
      "epoch:26 step:20702 [D loss: 0.689026, acc.: 50.78%] [G loss: 0.689871]\n",
      "epoch:26 step:20703 [D loss: 0.686460, acc.: 61.72%] [G loss: 0.717338]\n",
      "epoch:26 step:20704 [D loss: 0.718455, acc.: 44.53%] [G loss: 0.725920]\n",
      "epoch:26 step:20705 [D loss: 0.666084, acc.: 65.62%] [G loss: 0.714698]\n",
      "epoch:26 step:20706 [D loss: 0.731400, acc.: 39.84%] [G loss: 0.692102]\n",
      "epoch:26 step:20707 [D loss: 0.618481, acc.: 71.88%] [G loss: 0.730041]\n",
      "epoch:26 step:20708 [D loss: 0.659037, acc.: 59.38%] [G loss: 0.809570]\n",
      "epoch:26 step:20709 [D loss: 0.687166, acc.: 53.12%] [G loss: 0.747141]\n",
      "epoch:26 step:20710 [D loss: 0.666363, acc.: 59.38%] [G loss: 0.709983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20711 [D loss: 0.709834, acc.: 52.34%] [G loss: 0.803501]\n",
      "epoch:26 step:20712 [D loss: 0.676855, acc.: 58.59%] [G loss: 0.795518]\n",
      "epoch:26 step:20713 [D loss: 0.671048, acc.: 56.25%] [G loss: 0.767063]\n",
      "epoch:26 step:20714 [D loss: 0.705474, acc.: 50.00%] [G loss: 0.773056]\n",
      "epoch:26 step:20715 [D loss: 0.726490, acc.: 42.19%] [G loss: 0.722770]\n",
      "epoch:26 step:20716 [D loss: 0.689822, acc.: 59.38%] [G loss: 0.725374]\n",
      "epoch:26 step:20717 [D loss: 0.661316, acc.: 58.59%] [G loss: 0.740557]\n",
      "epoch:26 step:20718 [D loss: 0.710083, acc.: 46.09%] [G loss: 0.714963]\n",
      "epoch:26 step:20719 [D loss: 0.703973, acc.: 48.44%] [G loss: 0.707461]\n",
      "epoch:26 step:20720 [D loss: 0.726937, acc.: 45.31%] [G loss: 0.724313]\n",
      "epoch:26 step:20721 [D loss: 0.644600, acc.: 67.97%] [G loss: 0.750462]\n",
      "epoch:26 step:20722 [D loss: 0.661635, acc.: 59.38%] [G loss: 0.876789]\n",
      "epoch:26 step:20723 [D loss: 0.659329, acc.: 60.94%] [G loss: 0.818091]\n",
      "epoch:26 step:20724 [D loss: 0.667018, acc.: 58.59%] [G loss: 0.793049]\n",
      "epoch:26 step:20725 [D loss: 0.696663, acc.: 50.00%] [G loss: 0.736430]\n",
      "epoch:26 step:20726 [D loss: 0.682760, acc.: 62.50%] [G loss: 0.767082]\n",
      "epoch:26 step:20727 [D loss: 0.711777, acc.: 46.09%] [G loss: 0.717207]\n",
      "epoch:26 step:20728 [D loss: 0.682673, acc.: 57.03%] [G loss: 0.773776]\n",
      "epoch:26 step:20729 [D loss: 0.671558, acc.: 61.72%] [G loss: 0.773013]\n",
      "epoch:26 step:20730 [D loss: 0.753678, acc.: 39.84%] [G loss: 0.746896]\n",
      "epoch:26 step:20731 [D loss: 0.652534, acc.: 59.38%] [G loss: 0.738439]\n",
      "epoch:26 step:20732 [D loss: 0.749905, acc.: 38.28%] [G loss: 0.763430]\n",
      "epoch:26 step:20733 [D loss: 0.734501, acc.: 39.84%] [G loss: 0.767885]\n",
      "epoch:26 step:20734 [D loss: 0.703186, acc.: 56.25%] [G loss: 0.702257]\n",
      "epoch:26 step:20735 [D loss: 0.730332, acc.: 42.19%] [G loss: 0.762294]\n",
      "epoch:26 step:20736 [D loss: 0.683402, acc.: 50.78%] [G loss: 0.736893]\n",
      "epoch:26 step:20737 [D loss: 0.727796, acc.: 42.19%] [G loss: 0.754110]\n",
      "epoch:26 step:20738 [D loss: 0.678752, acc.: 54.69%] [G loss: 0.784779]\n",
      "epoch:26 step:20739 [D loss: 0.718518, acc.: 46.88%] [G loss: 0.806632]\n",
      "epoch:26 step:20740 [D loss: 0.707104, acc.: 46.88%] [G loss: 0.763063]\n",
      "epoch:26 step:20741 [D loss: 0.670286, acc.: 57.03%] [G loss: 0.781103]\n",
      "epoch:26 step:20742 [D loss: 0.709086, acc.: 45.31%] [G loss: 0.805011]\n",
      "epoch:26 step:20743 [D loss: 0.684136, acc.: 54.69%] [G loss: 0.849761]\n",
      "epoch:26 step:20744 [D loss: 0.658192, acc.: 60.16%] [G loss: 0.853569]\n",
      "epoch:26 step:20745 [D loss: 0.689084, acc.: 52.34%] [G loss: 0.871477]\n",
      "epoch:26 step:20746 [D loss: 0.689418, acc.: 54.69%] [G loss: 0.812698]\n",
      "epoch:26 step:20747 [D loss: 0.650889, acc.: 59.38%] [G loss: 0.821492]\n",
      "epoch:26 step:20748 [D loss: 0.729610, acc.: 39.84%] [G loss: 0.817790]\n",
      "epoch:26 step:20749 [D loss: 0.681641, acc.: 56.25%] [G loss: 0.771184]\n",
      "epoch:26 step:20750 [D loss: 0.700275, acc.: 49.22%] [G loss: 0.797627]\n",
      "epoch:26 step:20751 [D loss: 0.688571, acc.: 47.66%] [G loss: 0.869259]\n",
      "epoch:26 step:20752 [D loss: 0.695712, acc.: 48.44%] [G loss: 0.781038]\n",
      "epoch:26 step:20753 [D loss: 0.678892, acc.: 57.81%] [G loss: 0.783946]\n",
      "epoch:26 step:20754 [D loss: 0.697745, acc.: 55.47%] [G loss: 0.777774]\n",
      "epoch:26 step:20755 [D loss: 0.671126, acc.: 57.81%] [G loss: 0.760997]\n",
      "epoch:26 step:20756 [D loss: 0.661040, acc.: 63.28%] [G loss: 0.797569]\n",
      "epoch:26 step:20757 [D loss: 0.655360, acc.: 64.84%] [G loss: 0.763390]\n",
      "epoch:26 step:20758 [D loss: 0.687680, acc.: 54.69%] [G loss: 0.741533]\n",
      "epoch:26 step:20759 [D loss: 0.754482, acc.: 35.16%] [G loss: 0.739287]\n",
      "epoch:26 step:20760 [D loss: 0.708485, acc.: 46.88%] [G loss: 0.774429]\n",
      "epoch:26 step:20761 [D loss: 0.725094, acc.: 41.41%] [G loss: 0.769769]\n",
      "epoch:26 step:20762 [D loss: 0.662553, acc.: 66.41%] [G loss: 0.792951]\n",
      "epoch:26 step:20763 [D loss: 0.711898, acc.: 46.88%] [G loss: 0.793506]\n",
      "epoch:26 step:20764 [D loss: 0.692734, acc.: 49.22%] [G loss: 0.802859]\n",
      "epoch:26 step:20765 [D loss: 0.716536, acc.: 48.44%] [G loss: 0.690580]\n",
      "epoch:26 step:20766 [D loss: 0.695862, acc.: 53.91%] [G loss: 0.710030]\n",
      "epoch:26 step:20767 [D loss: 0.685756, acc.: 52.34%] [G loss: 0.785682]\n",
      "epoch:26 step:20768 [D loss: 0.678016, acc.: 56.25%] [G loss: 0.800296]\n",
      "epoch:26 step:20769 [D loss: 0.695160, acc.: 53.12%] [G loss: 0.878534]\n",
      "epoch:26 step:20770 [D loss: 0.708775, acc.: 44.53%] [G loss: 0.647772]\n",
      "epoch:26 step:20771 [D loss: 0.688234, acc.: 54.69%] [G loss: 0.763647]\n",
      "epoch:26 step:20772 [D loss: 0.653721, acc.: 66.41%] [G loss: 0.801029]\n",
      "epoch:26 step:20773 [D loss: 0.717563, acc.: 48.44%] [G loss: 0.777104]\n",
      "epoch:26 step:20774 [D loss: 0.681831, acc.: 53.12%] [G loss: 0.743379]\n",
      "epoch:26 step:20775 [D loss: 0.660351, acc.: 60.94%] [G loss: 0.780039]\n",
      "epoch:26 step:20776 [D loss: 0.692298, acc.: 54.69%] [G loss: 0.811852]\n",
      "epoch:26 step:20777 [D loss: 0.708577, acc.: 50.78%] [G loss: 0.784476]\n",
      "epoch:26 step:20778 [D loss: 0.675607, acc.: 60.94%] [G loss: 0.671447]\n",
      "epoch:26 step:20779 [D loss: 0.792344, acc.: 35.94%] [G loss: 0.815268]\n",
      "epoch:26 step:20780 [D loss: 0.643862, acc.: 67.19%] [G loss: 0.731367]\n",
      "epoch:26 step:20781 [D loss: 0.726155, acc.: 42.19%] [G loss: 0.692798]\n",
      "epoch:26 step:20782 [D loss: 0.702483, acc.: 51.56%] [G loss: 0.699158]\n",
      "epoch:26 step:20783 [D loss: 0.628255, acc.: 73.44%] [G loss: 0.775896]\n",
      "epoch:26 step:20784 [D loss: 0.680389, acc.: 53.12%] [G loss: 0.743870]\n",
      "epoch:26 step:20785 [D loss: 0.701555, acc.: 48.44%] [G loss: 0.747659]\n",
      "epoch:26 step:20786 [D loss: 0.706254, acc.: 43.75%] [G loss: 0.729438]\n",
      "epoch:26 step:20787 [D loss: 0.673659, acc.: 55.47%] [G loss: 0.785908]\n",
      "epoch:26 step:20788 [D loss: 0.732384, acc.: 50.00%] [G loss: 0.780962]\n",
      "epoch:26 step:20789 [D loss: 0.692517, acc.: 54.69%] [G loss: 0.754793]\n",
      "epoch:26 step:20790 [D loss: 0.719881, acc.: 48.44%] [G loss: 0.752482]\n",
      "epoch:26 step:20791 [D loss: 0.630373, acc.: 65.62%] [G loss: 0.735485]\n",
      "epoch:26 step:20792 [D loss: 0.704658, acc.: 48.44%] [G loss: 0.733438]\n",
      "epoch:26 step:20793 [D loss: 0.705625, acc.: 53.91%] [G loss: 0.795494]\n",
      "epoch:26 step:20794 [D loss: 0.696942, acc.: 49.22%] [G loss: 0.777616]\n",
      "epoch:26 step:20795 [D loss: 0.727706, acc.: 46.09%] [G loss: 0.734120]\n",
      "epoch:26 step:20796 [D loss: 0.714294, acc.: 48.44%] [G loss: 0.695250]\n",
      "epoch:26 step:20797 [D loss: 0.654379, acc.: 58.59%] [G loss: 0.797651]\n",
      "epoch:26 step:20798 [D loss: 0.696191, acc.: 48.44%] [G loss: 0.715974]\n",
      "epoch:26 step:20799 [D loss: 0.649142, acc.: 63.28%] [G loss: 0.727281]\n",
      "epoch:26 step:20800 [D loss: 0.695511, acc.: 50.78%] [G loss: 0.759819]\n",
      "epoch:26 step:20801 [D loss: 0.679114, acc.: 53.12%] [G loss: 0.772837]\n",
      "epoch:26 step:20802 [D loss: 0.703062, acc.: 49.22%] [G loss: 0.779345]\n",
      "epoch:26 step:20803 [D loss: 0.694025, acc.: 54.69%] [G loss: 0.675972]\n",
      "epoch:26 step:20804 [D loss: 0.690172, acc.: 51.56%] [G loss: 0.678277]\n",
      "epoch:26 step:20805 [D loss: 0.655926, acc.: 59.38%] [G loss: 0.737965]\n",
      "epoch:26 step:20806 [D loss: 0.710128, acc.: 49.22%] [G loss: 0.706070]\n",
      "epoch:26 step:20807 [D loss: 0.666047, acc.: 60.94%] [G loss: 0.748144]\n",
      "epoch:26 step:20808 [D loss: 0.709207, acc.: 50.00%] [G loss: 0.770938]\n",
      "epoch:26 step:20809 [D loss: 0.695651, acc.: 53.12%] [G loss: 0.754749]\n",
      "epoch:26 step:20810 [D loss: 0.695341, acc.: 50.78%] [G loss: 0.824070]\n",
      "epoch:26 step:20811 [D loss: 0.674079, acc.: 60.94%] [G loss: 0.754205]\n",
      "epoch:26 step:20812 [D loss: 0.678692, acc.: 60.94%] [G loss: 0.771771]\n",
      "epoch:26 step:20813 [D loss: 0.678470, acc.: 54.69%] [G loss: 0.817141]\n",
      "epoch:26 step:20814 [D loss: 0.707366, acc.: 52.34%] [G loss: 0.825155]\n",
      "epoch:26 step:20815 [D loss: 0.674873, acc.: 55.47%] [G loss: 0.770478]\n",
      "epoch:26 step:20816 [D loss: 0.675988, acc.: 57.81%] [G loss: 0.731188]\n",
      "epoch:26 step:20817 [D loss: 0.677894, acc.: 56.25%] [G loss: 0.713459]\n",
      "epoch:26 step:20818 [D loss: 0.715818, acc.: 51.56%] [G loss: 0.801788]\n",
      "epoch:26 step:20819 [D loss: 0.775993, acc.: 33.59%] [G loss: 0.723429]\n",
      "epoch:26 step:20820 [D loss: 0.702783, acc.: 57.03%] [G loss: 0.684303]\n",
      "epoch:26 step:20821 [D loss: 0.692322, acc.: 56.25%] [G loss: 0.710743]\n",
      "epoch:26 step:20822 [D loss: 0.679875, acc.: 54.69%] [G loss: 0.739288]\n",
      "epoch:26 step:20823 [D loss: 0.714050, acc.: 48.44%] [G loss: 0.686453]\n",
      "epoch:26 step:20824 [D loss: 0.701282, acc.: 54.69%] [G loss: 0.696493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20825 [D loss: 0.675760, acc.: 58.59%] [G loss: 0.770048]\n",
      "epoch:26 step:20826 [D loss: 0.719737, acc.: 42.97%] [G loss: 0.730139]\n",
      "epoch:26 step:20827 [D loss: 0.677597, acc.: 55.47%] [G loss: 0.750954]\n",
      "epoch:26 step:20828 [D loss: 0.722560, acc.: 43.75%] [G loss: 0.721338]\n",
      "epoch:26 step:20829 [D loss: 0.673726, acc.: 56.25%] [G loss: 0.764971]\n",
      "epoch:26 step:20830 [D loss: 0.679216, acc.: 56.25%] [G loss: 0.783305]\n",
      "epoch:26 step:20831 [D loss: 0.658706, acc.: 60.94%] [G loss: 0.746548]\n",
      "epoch:26 step:20832 [D loss: 0.740706, acc.: 46.88%] [G loss: 0.731731]\n",
      "epoch:26 step:20833 [D loss: 0.687534, acc.: 50.78%] [G loss: 0.736437]\n",
      "epoch:26 step:20834 [D loss: 0.711526, acc.: 50.78%] [G loss: 0.745908]\n",
      "epoch:26 step:20835 [D loss: 0.681408, acc.: 53.91%] [G loss: 0.726195]\n",
      "epoch:26 step:20836 [D loss: 0.695085, acc.: 54.69%] [G loss: 0.783773]\n",
      "epoch:26 step:20837 [D loss: 0.718188, acc.: 41.41%] [G loss: 0.783553]\n",
      "epoch:26 step:20838 [D loss: 0.715663, acc.: 45.31%] [G loss: 0.719377]\n",
      "epoch:26 step:20839 [D loss: 0.665732, acc.: 60.94%] [G loss: 0.845676]\n",
      "epoch:26 step:20840 [D loss: 0.647044, acc.: 67.97%] [G loss: 0.806981]\n",
      "epoch:26 step:20841 [D loss: 0.750872, acc.: 42.97%] [G loss: 0.783436]\n",
      "epoch:26 step:20842 [D loss: 0.695725, acc.: 51.56%] [G loss: 0.735956]\n",
      "epoch:26 step:20843 [D loss: 0.697962, acc.: 49.22%] [G loss: 0.739351]\n",
      "epoch:26 step:20844 [D loss: 0.675373, acc.: 55.47%] [G loss: 0.732268]\n",
      "epoch:26 step:20845 [D loss: 0.725866, acc.: 45.31%] [G loss: 0.733925]\n",
      "epoch:26 step:20846 [D loss: 0.684274, acc.: 53.91%] [G loss: 0.800093]\n",
      "epoch:26 step:20847 [D loss: 0.670002, acc.: 58.59%] [G loss: 0.722232]\n",
      "epoch:26 step:20848 [D loss: 0.709172, acc.: 48.44%] [G loss: 0.735528]\n",
      "epoch:26 step:20849 [D loss: 0.679064, acc.: 54.69%] [G loss: 0.770323]\n",
      "epoch:26 step:20850 [D loss: 0.693393, acc.: 51.56%] [G loss: 0.732044]\n",
      "epoch:26 step:20851 [D loss: 0.636188, acc.: 68.75%] [G loss: 0.759503]\n",
      "epoch:26 step:20852 [D loss: 0.764149, acc.: 38.28%] [G loss: 0.730834]\n",
      "epoch:26 step:20853 [D loss: 0.704810, acc.: 51.56%] [G loss: 0.677745]\n",
      "epoch:26 step:20854 [D loss: 0.731587, acc.: 40.62%] [G loss: 0.691216]\n",
      "epoch:26 step:20855 [D loss: 0.672008, acc.: 58.59%] [G loss: 0.726725]\n",
      "epoch:26 step:20856 [D loss: 0.699982, acc.: 51.56%] [G loss: 0.737159]\n",
      "epoch:26 step:20857 [D loss: 0.667883, acc.: 59.38%] [G loss: 0.741479]\n",
      "epoch:26 step:20858 [D loss: 0.717682, acc.: 48.44%] [G loss: 0.738801]\n",
      "epoch:26 step:20859 [D loss: 0.700206, acc.: 56.25%] [G loss: 0.821874]\n",
      "epoch:26 step:20860 [D loss: 0.698393, acc.: 53.91%] [G loss: 0.834381]\n",
      "epoch:26 step:20861 [D loss: 0.693721, acc.: 50.00%] [G loss: 0.801598]\n",
      "epoch:26 step:20862 [D loss: 0.648941, acc.: 62.50%] [G loss: 0.776452]\n",
      "epoch:26 step:20863 [D loss: 0.671683, acc.: 60.94%] [G loss: 0.794715]\n",
      "epoch:26 step:20864 [D loss: 0.705284, acc.: 50.78%] [G loss: 0.736698]\n",
      "epoch:26 step:20865 [D loss: 0.624128, acc.: 66.41%] [G loss: 0.821349]\n",
      "epoch:26 step:20866 [D loss: 0.736380, acc.: 46.09%] [G loss: 0.809489]\n",
      "epoch:26 step:20867 [D loss: 0.684106, acc.: 57.03%] [G loss: 0.809629]\n",
      "epoch:26 step:20868 [D loss: 0.674014, acc.: 57.81%] [G loss: 0.753742]\n",
      "epoch:26 step:20869 [D loss: 0.679240, acc.: 62.50%] [G loss: 0.737916]\n",
      "epoch:26 step:20870 [D loss: 0.687039, acc.: 53.12%] [G loss: 0.802131]\n",
      "epoch:26 step:20871 [D loss: 0.699468, acc.: 55.47%] [G loss: 0.691245]\n",
      "epoch:26 step:20872 [D loss: 0.659971, acc.: 57.81%] [G loss: 0.807183]\n",
      "epoch:26 step:20873 [D loss: 0.704734, acc.: 45.31%] [G loss: 0.771786]\n",
      "epoch:26 step:20874 [D loss: 0.653747, acc.: 61.72%] [G loss: 0.804262]\n",
      "epoch:26 step:20875 [D loss: 0.674413, acc.: 60.16%] [G loss: 0.796329]\n",
      "epoch:26 step:20876 [D loss: 0.694900, acc.: 53.91%] [G loss: 0.699302]\n",
      "epoch:26 step:20877 [D loss: 0.716896, acc.: 42.97%] [G loss: 0.759901]\n",
      "epoch:26 step:20878 [D loss: 0.674720, acc.: 54.69%] [G loss: 0.740198]\n",
      "epoch:26 step:20879 [D loss: 0.715003, acc.: 42.97%] [G loss: 0.788909]\n",
      "epoch:26 step:20880 [D loss: 0.684989, acc.: 56.25%] [G loss: 0.762634]\n",
      "epoch:26 step:20881 [D loss: 0.753588, acc.: 35.94%] [G loss: 0.778519]\n",
      "epoch:26 step:20882 [D loss: 0.673043, acc.: 61.72%] [G loss: 0.759208]\n",
      "epoch:26 step:20883 [D loss: 0.722347, acc.: 43.75%] [G loss: 0.760659]\n",
      "epoch:26 step:20884 [D loss: 0.688345, acc.: 56.25%] [G loss: 0.762456]\n",
      "epoch:26 step:20885 [D loss: 0.665642, acc.: 63.28%] [G loss: 0.742918]\n",
      "epoch:26 step:20886 [D loss: 0.722605, acc.: 40.62%] [G loss: 0.687875]\n",
      "epoch:26 step:20887 [D loss: 0.671491, acc.: 54.69%] [G loss: 0.721253]\n",
      "epoch:26 step:20888 [D loss: 0.686951, acc.: 53.91%] [G loss: 0.689202]\n",
      "epoch:26 step:20889 [D loss: 0.658934, acc.: 63.28%] [G loss: 0.753382]\n",
      "epoch:26 step:20890 [D loss: 0.685221, acc.: 57.03%] [G loss: 0.722141]\n",
      "epoch:26 step:20891 [D loss: 0.649244, acc.: 67.97%] [G loss: 0.823972]\n",
      "epoch:26 step:20892 [D loss: 0.687288, acc.: 58.59%] [G loss: 0.787071]\n",
      "epoch:26 step:20893 [D loss: 0.653958, acc.: 64.84%] [G loss: 0.762806]\n",
      "epoch:26 step:20894 [D loss: 0.732813, acc.: 46.09%] [G loss: 0.732375]\n",
      "epoch:26 step:20895 [D loss: 0.668229, acc.: 57.81%] [G loss: 0.733448]\n",
      "epoch:26 step:20896 [D loss: 0.682106, acc.: 53.12%] [G loss: 0.813663]\n",
      "epoch:26 step:20897 [D loss: 0.678162, acc.: 58.59%] [G loss: 0.785880]\n",
      "epoch:26 step:20898 [D loss: 0.704561, acc.: 49.22%] [G loss: 0.821247]\n",
      "epoch:26 step:20899 [D loss: 0.717919, acc.: 44.53%] [G loss: 0.792638]\n",
      "epoch:26 step:20900 [D loss: 0.701489, acc.: 53.12%] [G loss: 0.798283]\n",
      "epoch:26 step:20901 [D loss: 0.660908, acc.: 64.84%] [G loss: 0.765710]\n",
      "epoch:26 step:20902 [D loss: 0.719093, acc.: 47.66%] [G loss: 0.816748]\n",
      "epoch:26 step:20903 [D loss: 0.694551, acc.: 47.66%] [G loss: 0.786185]\n",
      "epoch:26 step:20904 [D loss: 0.678836, acc.: 57.81%] [G loss: 0.769279]\n",
      "epoch:26 step:20905 [D loss: 0.725951, acc.: 42.97%] [G loss: 0.813288]\n",
      "epoch:26 step:20906 [D loss: 0.696886, acc.: 56.25%] [G loss: 0.743152]\n",
      "epoch:26 step:20907 [D loss: 0.656871, acc.: 60.16%] [G loss: 0.797090]\n",
      "epoch:26 step:20908 [D loss: 0.668935, acc.: 59.38%] [G loss: 0.781264]\n",
      "epoch:26 step:20909 [D loss: 0.722432, acc.: 42.19%] [G loss: 0.793105]\n",
      "epoch:26 step:20910 [D loss: 0.697891, acc.: 53.12%] [G loss: 0.731215]\n",
      "epoch:26 step:20911 [D loss: 0.707551, acc.: 51.56%] [G loss: 0.693887]\n",
      "epoch:26 step:20912 [D loss: 0.693570, acc.: 57.03%] [G loss: 0.751584]\n",
      "epoch:26 step:20913 [D loss: 0.686107, acc.: 54.69%] [G loss: 0.683106]\n",
      "epoch:26 step:20914 [D loss: 0.647436, acc.: 69.53%] [G loss: 0.753606]\n",
      "epoch:26 step:20915 [D loss: 0.741170, acc.: 44.53%] [G loss: 0.818621]\n",
      "epoch:26 step:20916 [D loss: 0.695343, acc.: 53.91%] [G loss: 0.807264]\n",
      "epoch:26 step:20917 [D loss: 0.684625, acc.: 57.81%] [G loss: 0.813764]\n",
      "epoch:26 step:20918 [D loss: 0.681471, acc.: 51.56%] [G loss: 0.746776]\n",
      "epoch:26 step:20919 [D loss: 0.736311, acc.: 47.66%] [G loss: 0.703326]\n",
      "epoch:26 step:20920 [D loss: 0.689452, acc.: 53.91%] [G loss: 0.756852]\n",
      "epoch:26 step:20921 [D loss: 0.709618, acc.: 53.12%] [G loss: 0.766956]\n",
      "epoch:26 step:20922 [D loss: 0.657272, acc.: 67.19%] [G loss: 0.793232]\n",
      "epoch:26 step:20923 [D loss: 0.662860, acc.: 53.12%] [G loss: 0.773417]\n",
      "epoch:26 step:20924 [D loss: 0.666023, acc.: 63.28%] [G loss: 0.740059]\n",
      "epoch:26 step:20925 [D loss: 0.671658, acc.: 58.59%] [G loss: 0.745580]\n",
      "epoch:26 step:20926 [D loss: 0.667195, acc.: 61.72%] [G loss: 0.758026]\n",
      "epoch:26 step:20927 [D loss: 0.685642, acc.: 58.59%] [G loss: 0.829459]\n",
      "epoch:26 step:20928 [D loss: 0.665422, acc.: 57.03%] [G loss: 0.773790]\n",
      "epoch:26 step:20929 [D loss: 0.679641, acc.: 55.47%] [G loss: 0.851375]\n",
      "epoch:26 step:20930 [D loss: 0.700764, acc.: 48.44%] [G loss: 0.787511]\n",
      "epoch:26 step:20931 [D loss: 0.733130, acc.: 42.97%] [G loss: 0.795123]\n",
      "epoch:26 step:20932 [D loss: 0.730589, acc.: 42.97%] [G loss: 0.701069]\n",
      "epoch:26 step:20933 [D loss: 0.678447, acc.: 57.03%] [G loss: 0.735463]\n",
      "epoch:26 step:20934 [D loss: 0.680003, acc.: 64.06%] [G loss: 0.778728]\n",
      "epoch:26 step:20935 [D loss: 0.691562, acc.: 58.59%] [G loss: 0.692388]\n",
      "epoch:26 step:20936 [D loss: 0.655490, acc.: 64.84%] [G loss: 0.713452]\n",
      "epoch:26 step:20937 [D loss: 0.680193, acc.: 56.25%] [G loss: 0.777370]\n",
      "epoch:26 step:20938 [D loss: 0.665170, acc.: 62.50%] [G loss: 0.746484]\n",
      "epoch:26 step:20939 [D loss: 0.723982, acc.: 41.41%] [G loss: 0.727194]\n",
      "epoch:26 step:20940 [D loss: 0.688305, acc.: 50.00%] [G loss: 0.727799]\n",
      "epoch:26 step:20941 [D loss: 0.688925, acc.: 50.00%] [G loss: 0.712925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20942 [D loss: 0.668917, acc.: 57.81%] [G loss: 0.721238]\n",
      "epoch:26 step:20943 [D loss: 0.696901, acc.: 50.00%] [G loss: 0.816679]\n",
      "epoch:26 step:20944 [D loss: 0.674246, acc.: 59.38%] [G loss: 0.796063]\n",
      "epoch:26 step:20945 [D loss: 0.733102, acc.: 45.31%] [G loss: 0.758667]\n",
      "epoch:26 step:20946 [D loss: 0.637949, acc.: 64.06%] [G loss: 0.829859]\n",
      "epoch:26 step:20947 [D loss: 0.724541, acc.: 48.44%] [G loss: 0.749835]\n",
      "epoch:26 step:20948 [D loss: 0.693491, acc.: 52.34%] [G loss: 0.801296]\n",
      "epoch:26 step:20949 [D loss: 0.741841, acc.: 38.28%] [G loss: 0.689938]\n",
      "epoch:26 step:20950 [D loss: 0.669293, acc.: 59.38%] [G loss: 0.763144]\n",
      "epoch:26 step:20951 [D loss: 0.666359, acc.: 59.38%] [G loss: 0.768915]\n",
      "epoch:26 step:20952 [D loss: 0.729693, acc.: 42.19%] [G loss: 0.825682]\n",
      "epoch:26 step:20953 [D loss: 0.698734, acc.: 52.34%] [G loss: 0.702956]\n",
      "epoch:26 step:20954 [D loss: 0.695499, acc.: 53.91%] [G loss: 0.793963]\n",
      "epoch:26 step:20955 [D loss: 0.722241, acc.: 49.22%] [G loss: 0.777840]\n",
      "epoch:26 step:20956 [D loss: 0.713187, acc.: 49.22%] [G loss: 0.737114]\n",
      "epoch:26 step:20957 [D loss: 0.669778, acc.: 53.12%] [G loss: 0.766083]\n",
      "epoch:26 step:20958 [D loss: 0.646775, acc.: 63.28%] [G loss: 0.762897]\n",
      "epoch:26 step:20959 [D loss: 0.687205, acc.: 58.59%] [G loss: 0.749508]\n",
      "epoch:26 step:20960 [D loss: 0.704605, acc.: 51.56%] [G loss: 0.690484]\n",
      "epoch:26 step:20961 [D loss: 0.720384, acc.: 46.09%] [G loss: 0.725278]\n",
      "epoch:26 step:20962 [D loss: 0.709316, acc.: 47.66%] [G loss: 0.711446]\n",
      "epoch:26 step:20963 [D loss: 0.657853, acc.: 61.72%] [G loss: 0.767967]\n",
      "epoch:26 step:20964 [D loss: 0.693650, acc.: 50.78%] [G loss: 0.783300]\n",
      "epoch:26 step:20965 [D loss: 0.712888, acc.: 49.22%] [G loss: 0.827718]\n",
      "epoch:26 step:20966 [D loss: 0.715182, acc.: 47.66%] [G loss: 0.782861]\n",
      "epoch:26 step:20967 [D loss: 0.686302, acc.: 53.91%] [G loss: 0.804468]\n",
      "epoch:26 step:20968 [D loss: 0.679080, acc.: 54.69%] [G loss: 0.818821]\n",
      "epoch:26 step:20969 [D loss: 0.664512, acc.: 60.94%] [G loss: 0.738899]\n",
      "epoch:26 step:20970 [D loss: 0.666339, acc.: 57.81%] [G loss: 0.737046]\n",
      "epoch:26 step:20971 [D loss: 0.669525, acc.: 60.94%] [G loss: 0.759111]\n",
      "epoch:26 step:20972 [D loss: 0.644168, acc.: 69.53%] [G loss: 0.788579]\n",
      "epoch:26 step:20973 [D loss: 0.672670, acc.: 62.50%] [G loss: 0.758609]\n",
      "epoch:26 step:20974 [D loss: 0.705412, acc.: 54.69%] [G loss: 0.714856]\n",
      "epoch:26 step:20975 [D loss: 0.682074, acc.: 53.91%] [G loss: 0.709595]\n",
      "epoch:26 step:20976 [D loss: 0.679772, acc.: 56.25%] [G loss: 0.779421]\n",
      "epoch:26 step:20977 [D loss: 0.683172, acc.: 54.69%] [G loss: 0.757988]\n",
      "epoch:26 step:20978 [D loss: 0.659246, acc.: 63.28%] [G loss: 0.708220]\n",
      "epoch:26 step:20979 [D loss: 0.680290, acc.: 59.38%] [G loss: 0.811470]\n",
      "epoch:26 step:20980 [D loss: 0.697099, acc.: 54.69%] [G loss: 0.776897]\n",
      "epoch:26 step:20981 [D loss: 0.726421, acc.: 42.97%] [G loss: 0.830977]\n",
      "epoch:26 step:20982 [D loss: 0.709170, acc.: 49.22%] [G loss: 0.803503]\n",
      "epoch:26 step:20983 [D loss: 0.688793, acc.: 52.34%] [G loss: 0.720075]\n",
      "epoch:26 step:20984 [D loss: 0.725959, acc.: 46.88%] [G loss: 0.811089]\n",
      "epoch:26 step:20985 [D loss: 0.663271, acc.: 61.72%] [G loss: 0.752528]\n",
      "epoch:26 step:20986 [D loss: 0.686762, acc.: 57.81%] [G loss: 0.730084]\n",
      "epoch:26 step:20987 [D loss: 0.643214, acc.: 63.28%] [G loss: 0.753680]\n",
      "epoch:26 step:20988 [D loss: 0.749579, acc.: 42.19%] [G loss: 0.730530]\n",
      "epoch:26 step:20989 [D loss: 0.696045, acc.: 50.78%] [G loss: 0.713412]\n",
      "epoch:26 step:20990 [D loss: 0.659455, acc.: 65.62%] [G loss: 0.758130]\n",
      "epoch:26 step:20991 [D loss: 0.704608, acc.: 47.66%] [G loss: 0.725689]\n",
      "epoch:26 step:20992 [D loss: 0.702729, acc.: 51.56%] [G loss: 0.752934]\n",
      "epoch:26 step:20993 [D loss: 0.693470, acc.: 52.34%] [G loss: 0.728019]\n",
      "epoch:26 step:20994 [D loss: 0.716930, acc.: 46.09%] [G loss: 0.737950]\n",
      "epoch:26 step:20995 [D loss: 0.724917, acc.: 43.75%] [G loss: 0.777773]\n",
      "epoch:26 step:20996 [D loss: 0.678494, acc.: 57.81%] [G loss: 0.827103]\n",
      "epoch:26 step:20997 [D loss: 0.676063, acc.: 57.81%] [G loss: 0.753876]\n",
      "epoch:26 step:20998 [D loss: 0.802523, acc.: 35.16%] [G loss: 0.731706]\n",
      "epoch:26 step:20999 [D loss: 0.674389, acc.: 60.16%] [G loss: 0.732960]\n",
      "epoch:26 step:21000 [D loss: 0.676573, acc.: 54.69%] [G loss: 0.723101]\n",
      "epoch:26 step:21001 [D loss: 0.672950, acc.: 62.50%] [G loss: 0.738989]\n",
      "epoch:26 step:21002 [D loss: 0.687829, acc.: 56.25%] [G loss: 0.769547]\n",
      "epoch:26 step:21003 [D loss: 0.694493, acc.: 50.00%] [G loss: 0.702891]\n",
      "epoch:26 step:21004 [D loss: 0.689351, acc.: 57.81%] [G loss: 0.725184]\n",
      "epoch:26 step:21005 [D loss: 0.658008, acc.: 64.84%] [G loss: 0.767398]\n",
      "epoch:26 step:21006 [D loss: 0.685103, acc.: 51.56%] [G loss: 0.730424]\n",
      "epoch:26 step:21007 [D loss: 0.676128, acc.: 59.38%] [G loss: 0.767493]\n",
      "epoch:26 step:21008 [D loss: 0.686383, acc.: 45.31%] [G loss: 0.734471]\n",
      "epoch:26 step:21009 [D loss: 0.739485, acc.: 40.62%] [G loss: 0.718226]\n",
      "epoch:26 step:21010 [D loss: 0.679455, acc.: 59.38%] [G loss: 0.719380]\n",
      "epoch:26 step:21011 [D loss: 0.708964, acc.: 46.09%] [G loss: 0.734975]\n",
      "epoch:26 step:21012 [D loss: 0.667295, acc.: 58.59%] [G loss: 0.764222]\n",
      "epoch:26 step:21013 [D loss: 0.736185, acc.: 37.50%] [G loss: 0.750260]\n",
      "epoch:26 step:21014 [D loss: 0.749352, acc.: 42.97%] [G loss: 0.728114]\n",
      "epoch:26 step:21015 [D loss: 0.691522, acc.: 51.56%] [G loss: 0.779561]\n",
      "epoch:26 step:21016 [D loss: 0.673581, acc.: 63.28%] [G loss: 0.803132]\n",
      "epoch:26 step:21017 [D loss: 0.691585, acc.: 54.69%] [G loss: 0.800890]\n",
      "epoch:26 step:21018 [D loss: 0.687234, acc.: 56.25%] [G loss: 0.795873]\n",
      "epoch:26 step:21019 [D loss: 0.734474, acc.: 38.28%] [G loss: 0.811143]\n",
      "epoch:26 step:21020 [D loss: 0.686974, acc.: 50.00%] [G loss: 0.827520]\n",
      "epoch:26 step:21021 [D loss: 0.681620, acc.: 53.91%] [G loss: 0.880603]\n",
      "epoch:26 step:21022 [D loss: 0.683241, acc.: 56.25%] [G loss: 0.818808]\n",
      "epoch:26 step:21023 [D loss: 0.674786, acc.: 57.03%] [G loss: 0.774734]\n",
      "epoch:26 step:21024 [D loss: 0.640183, acc.: 68.75%] [G loss: 0.773262]\n",
      "epoch:26 step:21025 [D loss: 0.686427, acc.: 57.81%] [G loss: 0.715440]\n",
      "epoch:26 step:21026 [D loss: 0.724304, acc.: 42.97%] [G loss: 0.741189]\n",
      "epoch:26 step:21027 [D loss: 0.737408, acc.: 38.28%] [G loss: 0.766012]\n",
      "epoch:26 step:21028 [D loss: 0.720305, acc.: 45.31%] [G loss: 0.749080]\n",
      "epoch:26 step:21029 [D loss: 0.743814, acc.: 43.75%] [G loss: 0.725669]\n",
      "epoch:26 step:21030 [D loss: 0.693913, acc.: 51.56%] [G loss: 0.790611]\n",
      "epoch:26 step:21031 [D loss: 0.696215, acc.: 52.34%] [G loss: 0.749196]\n",
      "epoch:26 step:21032 [D loss: 0.681116, acc.: 51.56%] [G loss: 0.744082]\n",
      "epoch:26 step:21033 [D loss: 0.690002, acc.: 59.38%] [G loss: 0.707311]\n",
      "epoch:26 step:21034 [D loss: 0.735672, acc.: 45.31%] [G loss: 0.700970]\n",
      "epoch:26 step:21035 [D loss: 0.647786, acc.: 69.53%] [G loss: 0.755567]\n",
      "epoch:26 step:21036 [D loss: 0.676690, acc.: 52.34%] [G loss: 0.756099]\n",
      "epoch:26 step:21037 [D loss: 0.717015, acc.: 52.34%] [G loss: 0.800110]\n",
      "epoch:26 step:21038 [D loss: 0.709610, acc.: 49.22%] [G loss: 0.715598]\n",
      "epoch:26 step:21039 [D loss: 0.682497, acc.: 53.12%] [G loss: 0.714161]\n",
      "epoch:26 step:21040 [D loss: 0.657814, acc.: 64.84%] [G loss: 0.798052]\n",
      "epoch:26 step:21041 [D loss: 0.689661, acc.: 57.03%] [G loss: 0.717973]\n",
      "epoch:26 step:21042 [D loss: 0.640729, acc.: 67.97%] [G loss: 0.739226]\n",
      "epoch:26 step:21043 [D loss: 0.702866, acc.: 50.78%] [G loss: 0.787271]\n",
      "epoch:26 step:21044 [D loss: 0.713362, acc.: 44.53%] [G loss: 0.737621]\n",
      "epoch:26 step:21045 [D loss: 0.718369, acc.: 42.19%] [G loss: 0.756460]\n",
      "epoch:26 step:21046 [D loss: 0.657251, acc.: 63.28%] [G loss: 0.808376]\n",
      "epoch:26 step:21047 [D loss: 0.636957, acc.: 65.62%] [G loss: 0.767298]\n",
      "epoch:26 step:21048 [D loss: 0.692054, acc.: 55.47%] [G loss: 0.779919]\n",
      "epoch:26 step:21049 [D loss: 0.637519, acc.: 68.75%] [G loss: 0.812811]\n",
      "epoch:26 step:21050 [D loss: 0.685714, acc.: 56.25%] [G loss: 0.771050]\n",
      "epoch:26 step:21051 [D loss: 0.692378, acc.: 52.34%] [G loss: 0.694373]\n",
      "epoch:26 step:21052 [D loss: 0.671935, acc.: 59.38%] [G loss: 0.781905]\n",
      "epoch:26 step:21053 [D loss: 0.682761, acc.: 56.25%] [G loss: 0.703490]\n",
      "epoch:26 step:21054 [D loss: 0.684661, acc.: 53.12%] [G loss: 0.758097]\n",
      "epoch:26 step:21055 [D loss: 0.700565, acc.: 56.25%] [G loss: 0.734711]\n",
      "epoch:26 step:21056 [D loss: 0.724169, acc.: 45.31%] [G loss: 0.703075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:21057 [D loss: 0.663511, acc.: 59.38%] [G loss: 0.750973]\n",
      "epoch:26 step:21058 [D loss: 0.674693, acc.: 57.03%] [G loss: 0.727801]\n",
      "epoch:26 step:21059 [D loss: 0.665104, acc.: 62.50%] [G loss: 0.786169]\n",
      "epoch:26 step:21060 [D loss: 0.720521, acc.: 46.09%] [G loss: 0.734133]\n",
      "epoch:26 step:21061 [D loss: 0.722195, acc.: 43.75%] [G loss: 0.711721]\n",
      "epoch:26 step:21062 [D loss: 0.690893, acc.: 53.12%] [G loss: 0.745638]\n",
      "epoch:26 step:21063 [D loss: 0.653786, acc.: 64.84%] [G loss: 0.855603]\n",
      "epoch:26 step:21064 [D loss: 0.679428, acc.: 57.81%] [G loss: 0.781750]\n",
      "epoch:26 step:21065 [D loss: 0.712986, acc.: 45.31%] [G loss: 0.733982]\n",
      "epoch:26 step:21066 [D loss: 0.700026, acc.: 50.00%] [G loss: 0.757376]\n",
      "epoch:26 step:21067 [D loss: 0.649728, acc.: 64.06%] [G loss: 0.792550]\n",
      "epoch:26 step:21068 [D loss: 0.702054, acc.: 49.22%] [G loss: 0.806319]\n",
      "epoch:26 step:21069 [D loss: 0.700050, acc.: 50.00%] [G loss: 0.721507]\n",
      "epoch:26 step:21070 [D loss: 0.702562, acc.: 52.34%] [G loss: 0.729255]\n",
      "epoch:26 step:21071 [D loss: 0.706825, acc.: 55.47%] [G loss: 0.734840]\n",
      "epoch:26 step:21072 [D loss: 0.719321, acc.: 47.66%] [G loss: 0.710153]\n",
      "epoch:26 step:21073 [D loss: 0.755279, acc.: 38.28%] [G loss: 0.751869]\n",
      "epoch:26 step:21074 [D loss: 0.677742, acc.: 57.03%] [G loss: 0.787367]\n",
      "epoch:26 step:21075 [D loss: 0.692672, acc.: 52.34%] [G loss: 0.808093]\n",
      "epoch:26 step:21076 [D loss: 0.662196, acc.: 64.06%] [G loss: 0.736047]\n",
      "epoch:26 step:21077 [D loss: 0.758806, acc.: 35.94%] [G loss: 0.753791]\n",
      "epoch:26 step:21078 [D loss: 0.704867, acc.: 49.22%] [G loss: 0.786441]\n",
      "epoch:26 step:21079 [D loss: 0.683232, acc.: 52.34%] [G loss: 0.787499]\n",
      "epoch:26 step:21080 [D loss: 0.731104, acc.: 48.44%] [G loss: 0.756587]\n",
      "epoch:26 step:21081 [D loss: 0.702011, acc.: 44.53%] [G loss: 0.758382]\n",
      "epoch:26 step:21082 [D loss: 0.718079, acc.: 42.19%] [G loss: 0.779223]\n",
      "epoch:26 step:21083 [D loss: 0.697214, acc.: 52.34%] [G loss: 0.758632]\n",
      "epoch:26 step:21084 [D loss: 0.671320, acc.: 58.59%] [G loss: 0.727532]\n",
      "epoch:26 step:21085 [D loss: 0.684022, acc.: 56.25%] [G loss: 0.780190]\n",
      "epoch:26 step:21086 [D loss: 0.719569, acc.: 43.75%] [G loss: 0.709378]\n",
      "epoch:26 step:21087 [D loss: 0.673125, acc.: 57.81%] [G loss: 0.807999]\n",
      "epoch:27 step:21088 [D loss: 0.688152, acc.: 56.25%] [G loss: 0.739923]\n",
      "epoch:27 step:21089 [D loss: 0.746628, acc.: 41.41%] [G loss: 0.756884]\n",
      "epoch:27 step:21090 [D loss: 0.727237, acc.: 43.75%] [G loss: 0.740409]\n",
      "epoch:27 step:21091 [D loss: 0.678900, acc.: 59.38%] [G loss: 0.714061]\n",
      "epoch:27 step:21092 [D loss: 0.693847, acc.: 55.47%] [G loss: 0.784349]\n",
      "epoch:27 step:21093 [D loss: 0.676192, acc.: 54.69%] [G loss: 0.788331]\n",
      "epoch:27 step:21094 [D loss: 0.661296, acc.: 59.38%] [G loss: 0.811886]\n",
      "epoch:27 step:21095 [D loss: 0.729095, acc.: 46.88%] [G loss: 0.733781]\n",
      "epoch:27 step:21096 [D loss: 0.690935, acc.: 53.12%] [G loss: 0.825362]\n",
      "epoch:27 step:21097 [D loss: 0.702112, acc.: 53.91%] [G loss: 0.759474]\n",
      "epoch:27 step:21098 [D loss: 0.688823, acc.: 54.69%] [G loss: 0.790335]\n",
      "epoch:27 step:21099 [D loss: 0.698530, acc.: 50.00%] [G loss: 0.812435]\n",
      "epoch:27 step:21100 [D loss: 0.654406, acc.: 64.06%] [G loss: 0.744323]\n",
      "epoch:27 step:21101 [D loss: 0.706295, acc.: 47.66%] [G loss: 0.760403]\n",
      "epoch:27 step:21102 [D loss: 0.731171, acc.: 39.06%] [G loss: 0.770831]\n",
      "epoch:27 step:21103 [D loss: 0.729863, acc.: 36.72%] [G loss: 0.780536]\n",
      "epoch:27 step:21104 [D loss: 0.686443, acc.: 57.81%] [G loss: 0.738129]\n",
      "epoch:27 step:21105 [D loss: 0.733712, acc.: 41.41%] [G loss: 0.758469]\n",
      "epoch:27 step:21106 [D loss: 0.678680, acc.: 59.38%] [G loss: 0.776224]\n",
      "epoch:27 step:21107 [D loss: 0.707815, acc.: 49.22%] [G loss: 0.732998]\n",
      "epoch:27 step:21108 [D loss: 0.685580, acc.: 60.16%] [G loss: 0.809476]\n",
      "epoch:27 step:21109 [D loss: 0.652089, acc.: 62.50%] [G loss: 0.772628]\n",
      "epoch:27 step:21110 [D loss: 0.656537, acc.: 66.41%] [G loss: 0.746346]\n",
      "epoch:27 step:21111 [D loss: 0.714071, acc.: 51.56%] [G loss: 0.741329]\n",
      "epoch:27 step:21112 [D loss: 0.696199, acc.: 51.56%] [G loss: 0.750342]\n",
      "epoch:27 step:21113 [D loss: 0.722575, acc.: 43.75%] [G loss: 0.763674]\n",
      "epoch:27 step:21114 [D loss: 0.669166, acc.: 60.94%] [G loss: 0.712023]\n",
      "epoch:27 step:21115 [D loss: 0.643537, acc.: 64.84%] [G loss: 0.774203]\n",
      "epoch:27 step:21116 [D loss: 0.676320, acc.: 59.38%] [G loss: 0.728755]\n",
      "epoch:27 step:21117 [D loss: 0.724231, acc.: 43.75%] [G loss: 0.705655]\n",
      "epoch:27 step:21118 [D loss: 0.693597, acc.: 50.78%] [G loss: 0.788386]\n",
      "epoch:27 step:21119 [D loss: 0.701470, acc.: 58.59%] [G loss: 0.763954]\n",
      "epoch:27 step:21120 [D loss: 0.710918, acc.: 49.22%] [G loss: 0.713209]\n",
      "epoch:27 step:21121 [D loss: 0.652437, acc.: 70.31%] [G loss: 0.762268]\n",
      "epoch:27 step:21122 [D loss: 0.692070, acc.: 51.56%] [G loss: 0.703331]\n",
      "epoch:27 step:21123 [D loss: 0.731798, acc.: 41.41%] [G loss: 0.688554]\n",
      "epoch:27 step:21124 [D loss: 0.695351, acc.: 52.34%] [G loss: 0.779428]\n",
      "epoch:27 step:21125 [D loss: 0.667817, acc.: 57.81%] [G loss: 0.730473]\n",
      "epoch:27 step:21126 [D loss: 0.680124, acc.: 50.78%] [G loss: 0.781282]\n",
      "epoch:27 step:21127 [D loss: 0.736202, acc.: 39.84%] [G loss: 0.692055]\n",
      "epoch:27 step:21128 [D loss: 0.656590, acc.: 63.28%] [G loss: 0.690551]\n",
      "epoch:27 step:21129 [D loss: 0.667083, acc.: 58.59%] [G loss: 0.726639]\n",
      "epoch:27 step:21130 [D loss: 0.707944, acc.: 50.00%] [G loss: 0.722266]\n",
      "epoch:27 step:21131 [D loss: 0.667256, acc.: 60.16%] [G loss: 0.753608]\n",
      "epoch:27 step:21132 [D loss: 0.667499, acc.: 64.06%] [G loss: 0.772118]\n",
      "epoch:27 step:21133 [D loss: 0.700576, acc.: 50.78%] [G loss: 0.790977]\n",
      "epoch:27 step:21134 [D loss: 0.678170, acc.: 58.59%] [G loss: 0.776294]\n",
      "epoch:27 step:21135 [D loss: 0.657337, acc.: 62.50%] [G loss: 0.781957]\n",
      "epoch:27 step:21136 [D loss: 0.686797, acc.: 60.94%] [G loss: 0.739293]\n",
      "epoch:27 step:21137 [D loss: 0.662746, acc.: 62.50%] [G loss: 0.794287]\n",
      "epoch:27 step:21138 [D loss: 0.705677, acc.: 50.78%] [G loss: 0.719982]\n",
      "epoch:27 step:21139 [D loss: 0.685370, acc.: 60.94%] [G loss: 0.695421]\n",
      "epoch:27 step:21140 [D loss: 0.662033, acc.: 62.50%] [G loss: 0.700855]\n",
      "epoch:27 step:21141 [D loss: 0.687682, acc.: 52.34%] [G loss: 0.708090]\n",
      "epoch:27 step:21142 [D loss: 0.701136, acc.: 51.56%] [G loss: 0.750848]\n",
      "epoch:27 step:21143 [D loss: 0.714541, acc.: 45.31%] [G loss: 0.668374]\n",
      "epoch:27 step:21144 [D loss: 0.692632, acc.: 52.34%] [G loss: 0.753086]\n",
      "epoch:27 step:21145 [D loss: 0.726135, acc.: 44.53%] [G loss: 0.814080]\n",
      "epoch:27 step:21146 [D loss: 0.667939, acc.: 57.03%] [G loss: 0.763165]\n",
      "epoch:27 step:21147 [D loss: 0.688262, acc.: 51.56%] [G loss: 0.820991]\n",
      "epoch:27 step:21148 [D loss: 0.694703, acc.: 50.78%] [G loss: 0.813029]\n",
      "epoch:27 step:21149 [D loss: 0.677345, acc.: 56.25%] [G loss: 0.882830]\n",
      "epoch:27 step:21150 [D loss: 0.744736, acc.: 42.97%] [G loss: 0.772592]\n",
      "epoch:27 step:21151 [D loss: 0.693263, acc.: 53.12%] [G loss: 0.812175]\n",
      "epoch:27 step:21152 [D loss: 0.751867, acc.: 35.16%] [G loss: 0.761269]\n",
      "epoch:27 step:21153 [D loss: 0.673775, acc.: 60.94%] [G loss: 0.762801]\n",
      "epoch:27 step:21154 [D loss: 0.665350, acc.: 60.16%] [G loss: 0.789599]\n",
      "epoch:27 step:21155 [D loss: 0.702432, acc.: 48.44%] [G loss: 0.747713]\n",
      "epoch:27 step:21156 [D loss: 0.716587, acc.: 50.78%] [G loss: 0.725098]\n",
      "epoch:27 step:21157 [D loss: 0.685107, acc.: 53.91%] [G loss: 0.723480]\n",
      "epoch:27 step:21158 [D loss: 0.691788, acc.: 59.38%] [G loss: 0.749843]\n",
      "epoch:27 step:21159 [D loss: 0.679563, acc.: 54.69%] [G loss: 0.741505]\n",
      "epoch:27 step:21160 [D loss: 0.671480, acc.: 60.16%] [G loss: 0.732549]\n",
      "epoch:27 step:21161 [D loss: 0.703723, acc.: 55.47%] [G loss: 0.716596]\n",
      "epoch:27 step:21162 [D loss: 0.666274, acc.: 57.81%] [G loss: 0.822214]\n",
      "epoch:27 step:21163 [D loss: 0.673105, acc.: 56.25%] [G loss: 0.776278]\n",
      "epoch:27 step:21164 [D loss: 0.644356, acc.: 63.28%] [G loss: 0.764692]\n",
      "epoch:27 step:21165 [D loss: 0.711698, acc.: 46.09%] [G loss: 0.710824]\n",
      "epoch:27 step:21166 [D loss: 0.708894, acc.: 48.44%] [G loss: 0.737495]\n",
      "epoch:27 step:21167 [D loss: 0.659540, acc.: 59.38%] [G loss: 0.778129]\n",
      "epoch:27 step:21168 [D loss: 0.659857, acc.: 64.84%] [G loss: 0.722687]\n",
      "epoch:27 step:21169 [D loss: 0.698921, acc.: 50.00%] [G loss: 0.724689]\n",
      "epoch:27 step:21170 [D loss: 0.710807, acc.: 52.34%] [G loss: 0.738090]\n",
      "epoch:27 step:21171 [D loss: 0.703233, acc.: 44.53%] [G loss: 0.741459]\n",
      "epoch:27 step:21172 [D loss: 0.702314, acc.: 51.56%] [G loss: 0.812770]\n",
      "epoch:27 step:21173 [D loss: 0.675479, acc.: 55.47%] [G loss: 0.735656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21174 [D loss: 0.662784, acc.: 65.62%] [G loss: 0.811439]\n",
      "epoch:27 step:21175 [D loss: 0.678392, acc.: 54.69%] [G loss: 0.860011]\n",
      "epoch:27 step:21176 [D loss: 0.664158, acc.: 55.47%] [G loss: 0.851991]\n",
      "epoch:27 step:21177 [D loss: 0.723076, acc.: 44.53%] [G loss: 0.817880]\n",
      "epoch:27 step:21178 [D loss: 0.697393, acc.: 53.12%] [G loss: 0.812041]\n",
      "epoch:27 step:21179 [D loss: 0.675403, acc.: 57.03%] [G loss: 0.776494]\n",
      "epoch:27 step:21180 [D loss: 0.660389, acc.: 57.03%] [G loss: 0.743479]\n",
      "epoch:27 step:21181 [D loss: 0.676432, acc.: 57.03%] [G loss: 0.780091]\n",
      "epoch:27 step:21182 [D loss: 0.704958, acc.: 58.59%] [G loss: 0.737325]\n",
      "epoch:27 step:21183 [D loss: 0.686974, acc.: 60.94%] [G loss: 0.820822]\n",
      "epoch:27 step:21184 [D loss: 0.721241, acc.: 43.75%] [G loss: 0.715997]\n",
      "epoch:27 step:21185 [D loss: 0.666784, acc.: 64.84%] [G loss: 0.811489]\n",
      "epoch:27 step:21186 [D loss: 0.707597, acc.: 43.75%] [G loss: 0.785511]\n",
      "epoch:27 step:21187 [D loss: 0.701023, acc.: 50.78%] [G loss: 0.793286]\n",
      "epoch:27 step:21188 [D loss: 0.661560, acc.: 64.84%] [G loss: 0.742722]\n",
      "epoch:27 step:21189 [D loss: 0.677803, acc.: 55.47%] [G loss: 0.830442]\n",
      "epoch:27 step:21190 [D loss: 0.732030, acc.: 41.41%] [G loss: 0.716919]\n",
      "epoch:27 step:21191 [D loss: 0.696044, acc.: 47.66%] [G loss: 0.695385]\n",
      "epoch:27 step:21192 [D loss: 0.669915, acc.: 58.59%] [G loss: 0.748713]\n",
      "epoch:27 step:21193 [D loss: 0.687427, acc.: 54.69%] [G loss: 0.790209]\n",
      "epoch:27 step:21194 [D loss: 0.707719, acc.: 50.00%] [G loss: 0.773452]\n",
      "epoch:27 step:21195 [D loss: 0.721707, acc.: 46.09%] [G loss: 0.832751]\n",
      "epoch:27 step:21196 [D loss: 0.663839, acc.: 64.84%] [G loss: 0.808586]\n",
      "epoch:27 step:21197 [D loss: 0.656121, acc.: 64.84%] [G loss: 0.756486]\n",
      "epoch:27 step:21198 [D loss: 0.737398, acc.: 36.72%] [G loss: 0.703866]\n",
      "epoch:27 step:21199 [D loss: 0.703341, acc.: 51.56%] [G loss: 0.717138]\n",
      "epoch:27 step:21200 [D loss: 0.717482, acc.: 43.75%] [G loss: 0.773797]\n",
      "epoch:27 step:21201 [D loss: 0.735925, acc.: 42.19%] [G loss: 0.778518]\n",
      "epoch:27 step:21202 [D loss: 0.730320, acc.: 50.00%] [G loss: 0.803711]\n",
      "epoch:27 step:21203 [D loss: 0.727832, acc.: 48.44%] [G loss: 0.735866]\n",
      "epoch:27 step:21204 [D loss: 0.709125, acc.: 50.78%] [G loss: 0.713101]\n",
      "epoch:27 step:21205 [D loss: 0.664058, acc.: 62.50%] [G loss: 0.780785]\n",
      "epoch:27 step:21206 [D loss: 0.687813, acc.: 56.25%] [G loss: 0.750773]\n",
      "epoch:27 step:21207 [D loss: 0.749239, acc.: 32.81%] [G loss: 0.768938]\n",
      "epoch:27 step:21208 [D loss: 0.712020, acc.: 46.88%] [G loss: 0.760723]\n",
      "epoch:27 step:21209 [D loss: 0.710751, acc.: 48.44%] [G loss: 0.728199]\n",
      "epoch:27 step:21210 [D loss: 0.708534, acc.: 51.56%] [G loss: 0.780989]\n",
      "epoch:27 step:21211 [D loss: 0.717986, acc.: 46.88%] [G loss: 0.796453]\n",
      "epoch:27 step:21212 [D loss: 0.747368, acc.: 32.03%] [G loss: 0.692938]\n",
      "epoch:27 step:21213 [D loss: 0.717639, acc.: 49.22%] [G loss: 0.787663]\n",
      "epoch:27 step:21214 [D loss: 0.725491, acc.: 50.78%] [G loss: 0.819957]\n",
      "epoch:27 step:21215 [D loss: 0.714960, acc.: 47.66%] [G loss: 0.711749]\n",
      "epoch:27 step:21216 [D loss: 0.736891, acc.: 45.31%] [G loss: 0.701925]\n",
      "epoch:27 step:21217 [D loss: 0.674897, acc.: 63.28%] [G loss: 0.845077]\n",
      "epoch:27 step:21218 [D loss: 0.682833, acc.: 56.25%] [G loss: 0.734977]\n",
      "epoch:27 step:21219 [D loss: 0.657550, acc.: 61.72%] [G loss: 0.847803]\n",
      "epoch:27 step:21220 [D loss: 0.675432, acc.: 59.38%] [G loss: 0.791085]\n",
      "epoch:27 step:21221 [D loss: 0.730237, acc.: 41.41%] [G loss: 0.883407]\n",
      "epoch:27 step:21222 [D loss: 0.755495, acc.: 44.53%] [G loss: 0.750694]\n",
      "epoch:27 step:21223 [D loss: 0.656989, acc.: 64.84%] [G loss: 0.790225]\n",
      "epoch:27 step:21224 [D loss: 0.699762, acc.: 55.47%] [G loss: 0.844097]\n",
      "epoch:27 step:21225 [D loss: 0.680004, acc.: 56.25%] [G loss: 0.789975]\n",
      "epoch:27 step:21226 [D loss: 0.694719, acc.: 50.00%] [G loss: 0.785951]\n",
      "epoch:27 step:21227 [D loss: 0.663054, acc.: 61.72%] [G loss: 0.753522]\n",
      "epoch:27 step:21228 [D loss: 0.696479, acc.: 50.00%] [G loss: 0.804403]\n",
      "epoch:27 step:21229 [D loss: 0.647035, acc.: 62.50%] [G loss: 0.810234]\n",
      "epoch:27 step:21230 [D loss: 0.691326, acc.: 56.25%] [G loss: 0.790142]\n",
      "epoch:27 step:21231 [D loss: 0.646537, acc.: 67.19%] [G loss: 0.777929]\n",
      "epoch:27 step:21232 [D loss: 0.698444, acc.: 53.12%] [G loss: 0.744108]\n",
      "epoch:27 step:21233 [D loss: 0.708305, acc.: 51.56%] [G loss: 0.780172]\n",
      "epoch:27 step:21234 [D loss: 0.654575, acc.: 60.94%] [G loss: 0.785277]\n",
      "epoch:27 step:21235 [D loss: 0.706540, acc.: 50.78%] [G loss: 0.773017]\n",
      "epoch:27 step:21236 [D loss: 0.734556, acc.: 44.53%] [G loss: 0.752445]\n",
      "epoch:27 step:21237 [D loss: 0.726690, acc.: 45.31%] [G loss: 0.758442]\n",
      "epoch:27 step:21238 [D loss: 0.699788, acc.: 50.00%] [G loss: 0.737753]\n",
      "epoch:27 step:21239 [D loss: 0.682148, acc.: 57.81%] [G loss: 0.719236]\n",
      "epoch:27 step:21240 [D loss: 0.711679, acc.: 46.09%] [G loss: 0.702203]\n",
      "epoch:27 step:21241 [D loss: 0.732504, acc.: 45.31%] [G loss: 0.689919]\n",
      "epoch:27 step:21242 [D loss: 0.704928, acc.: 50.00%] [G loss: 0.756839]\n",
      "epoch:27 step:21243 [D loss: 0.670807, acc.: 57.03%] [G loss: 0.757160]\n",
      "epoch:27 step:21244 [D loss: 0.658072, acc.: 61.72%] [G loss: 0.850577]\n",
      "epoch:27 step:21245 [D loss: 0.702180, acc.: 51.56%] [G loss: 0.786902]\n",
      "epoch:27 step:21246 [D loss: 0.676734, acc.: 60.94%] [G loss: 0.782398]\n",
      "epoch:27 step:21247 [D loss: 0.681139, acc.: 57.03%] [G loss: 0.718891]\n",
      "epoch:27 step:21248 [D loss: 0.725193, acc.: 42.97%] [G loss: 0.753870]\n",
      "epoch:27 step:21249 [D loss: 0.661864, acc.: 58.59%] [G loss: 0.798498]\n",
      "epoch:27 step:21250 [D loss: 0.687611, acc.: 55.47%] [G loss: 0.770949]\n",
      "epoch:27 step:21251 [D loss: 0.707191, acc.: 46.88%] [G loss: 0.744879]\n",
      "epoch:27 step:21252 [D loss: 0.736792, acc.: 42.97%] [G loss: 0.800986]\n",
      "epoch:27 step:21253 [D loss: 0.697559, acc.: 54.69%] [G loss: 0.770432]\n",
      "epoch:27 step:21254 [D loss: 0.691185, acc.: 54.69%] [G loss: 0.771155]\n",
      "epoch:27 step:21255 [D loss: 0.675774, acc.: 59.38%] [G loss: 0.719615]\n",
      "epoch:27 step:21256 [D loss: 0.689306, acc.: 53.12%] [G loss: 0.855854]\n",
      "epoch:27 step:21257 [D loss: 0.691127, acc.: 55.47%] [G loss: 0.799992]\n",
      "epoch:27 step:21258 [D loss: 0.694736, acc.: 52.34%] [G loss: 0.868128]\n",
      "epoch:27 step:21259 [D loss: 0.682867, acc.: 58.59%] [G loss: 0.754142]\n",
      "epoch:27 step:21260 [D loss: 0.734550, acc.: 39.84%] [G loss: 0.802252]\n",
      "epoch:27 step:21261 [D loss: 0.718731, acc.: 46.88%] [G loss: 0.753365]\n",
      "epoch:27 step:21262 [D loss: 0.681045, acc.: 52.34%] [G loss: 0.792259]\n",
      "epoch:27 step:21263 [D loss: 0.687204, acc.: 54.69%] [G loss: 0.772585]\n",
      "epoch:27 step:21264 [D loss: 0.693887, acc.: 47.66%] [G loss: 0.794082]\n",
      "epoch:27 step:21265 [D loss: 0.731086, acc.: 45.31%] [G loss: 0.795780]\n",
      "epoch:27 step:21266 [D loss: 0.676577, acc.: 53.12%] [G loss: 0.824032]\n",
      "epoch:27 step:21267 [D loss: 0.663196, acc.: 67.19%] [G loss: 0.763297]\n",
      "epoch:27 step:21268 [D loss: 0.668565, acc.: 56.25%] [G loss: 0.817943]\n",
      "epoch:27 step:21269 [D loss: 0.757945, acc.: 43.75%] [G loss: 0.777556]\n",
      "epoch:27 step:21270 [D loss: 0.661662, acc.: 60.94%] [G loss: 0.766702]\n",
      "epoch:27 step:21271 [D loss: 0.671734, acc.: 57.03%] [G loss: 0.710541]\n",
      "epoch:27 step:21272 [D loss: 0.672173, acc.: 54.69%] [G loss: 0.765628]\n",
      "epoch:27 step:21273 [D loss: 0.673852, acc.: 55.47%] [G loss: 0.790210]\n",
      "epoch:27 step:21274 [D loss: 0.636892, acc.: 67.97%] [G loss: 0.802604]\n",
      "epoch:27 step:21275 [D loss: 0.774963, acc.: 35.16%] [G loss: 0.727562]\n",
      "epoch:27 step:21276 [D loss: 0.675234, acc.: 54.69%] [G loss: 0.691367]\n",
      "epoch:27 step:21277 [D loss: 0.692776, acc.: 57.03%] [G loss: 0.766565]\n",
      "epoch:27 step:21278 [D loss: 0.643076, acc.: 70.31%] [G loss: 0.792472]\n",
      "epoch:27 step:21279 [D loss: 0.740873, acc.: 35.94%] [G loss: 0.762817]\n",
      "epoch:27 step:21280 [D loss: 0.710534, acc.: 50.00%] [G loss: 0.792656]\n",
      "epoch:27 step:21281 [D loss: 0.690891, acc.: 53.91%] [G loss: 0.744096]\n",
      "epoch:27 step:21282 [D loss: 0.709499, acc.: 43.75%] [G loss: 0.708762]\n",
      "epoch:27 step:21283 [D loss: 0.686018, acc.: 50.78%] [G loss: 0.731661]\n",
      "epoch:27 step:21284 [D loss: 0.669621, acc.: 62.50%] [G loss: 0.820235]\n",
      "epoch:27 step:21285 [D loss: 0.719685, acc.: 45.31%] [G loss: 0.753511]\n",
      "epoch:27 step:21286 [D loss: 0.713167, acc.: 45.31%] [G loss: 0.745088]\n",
      "epoch:27 step:21287 [D loss: 0.672804, acc.: 60.16%] [G loss: 0.723818]\n",
      "epoch:27 step:21288 [D loss: 0.651381, acc.: 61.72%] [G loss: 0.704918]\n",
      "epoch:27 step:21289 [D loss: 0.675735, acc.: 56.25%] [G loss: 0.862319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21290 [D loss: 0.691363, acc.: 53.12%] [G loss: 0.751349]\n",
      "epoch:27 step:21291 [D loss: 0.688670, acc.: 50.00%] [G loss: 0.826359]\n",
      "epoch:27 step:21292 [D loss: 0.714712, acc.: 50.00%] [G loss: 0.765293]\n",
      "epoch:27 step:21293 [D loss: 0.694674, acc.: 51.56%] [G loss: 0.745395]\n",
      "epoch:27 step:21294 [D loss: 0.645419, acc.: 68.75%] [G loss: 0.823586]\n",
      "epoch:27 step:21295 [D loss: 0.690352, acc.: 51.56%] [G loss: 0.729209]\n",
      "epoch:27 step:21296 [D loss: 0.696799, acc.: 55.47%] [G loss: 0.724138]\n",
      "epoch:27 step:21297 [D loss: 0.707929, acc.: 46.88%] [G loss: 0.734489]\n",
      "epoch:27 step:21298 [D loss: 0.686157, acc.: 55.47%] [G loss: 0.741224]\n",
      "epoch:27 step:21299 [D loss: 0.659445, acc.: 64.06%] [G loss: 0.788403]\n",
      "epoch:27 step:21300 [D loss: 0.701980, acc.: 44.53%] [G loss: 0.711568]\n",
      "epoch:27 step:21301 [D loss: 0.694889, acc.: 51.56%] [G loss: 0.769030]\n",
      "epoch:27 step:21302 [D loss: 0.706681, acc.: 46.88%] [G loss: 0.768944]\n",
      "epoch:27 step:21303 [D loss: 0.651921, acc.: 67.19%] [G loss: 0.836303]\n",
      "epoch:27 step:21304 [D loss: 0.708204, acc.: 49.22%] [G loss: 0.735196]\n",
      "epoch:27 step:21305 [D loss: 0.672464, acc.: 57.81%] [G loss: 0.788216]\n",
      "epoch:27 step:21306 [D loss: 0.681088, acc.: 59.38%] [G loss: 0.821873]\n",
      "epoch:27 step:21307 [D loss: 0.661322, acc.: 64.06%] [G loss: 0.803158]\n",
      "epoch:27 step:21308 [D loss: 0.681502, acc.: 57.81%] [G loss: 0.740993]\n",
      "epoch:27 step:21309 [D loss: 0.697137, acc.: 50.00%] [G loss: 0.680449]\n",
      "epoch:27 step:21310 [D loss: 0.703216, acc.: 47.66%] [G loss: 0.747047]\n",
      "epoch:27 step:21311 [D loss: 0.653303, acc.: 65.62%] [G loss: 0.740920]\n",
      "epoch:27 step:21312 [D loss: 0.676277, acc.: 59.38%] [G loss: 0.704763]\n",
      "epoch:27 step:21313 [D loss: 0.689210, acc.: 55.47%] [G loss: 0.707420]\n",
      "epoch:27 step:21314 [D loss: 0.673068, acc.: 57.03%] [G loss: 0.732659]\n",
      "epoch:27 step:21315 [D loss: 0.677737, acc.: 58.59%] [G loss: 0.715492]\n",
      "epoch:27 step:21316 [D loss: 0.677093, acc.: 53.91%] [G loss: 0.715936]\n",
      "epoch:27 step:21317 [D loss: 0.650470, acc.: 59.38%] [G loss: 0.775443]\n",
      "epoch:27 step:21318 [D loss: 0.664631, acc.: 57.81%] [G loss: 0.793971]\n",
      "epoch:27 step:21319 [D loss: 0.722696, acc.: 46.09%] [G loss: 0.754498]\n",
      "epoch:27 step:21320 [D loss: 0.692609, acc.: 53.91%] [G loss: 0.767338]\n",
      "epoch:27 step:21321 [D loss: 0.684184, acc.: 51.56%] [G loss: 0.761396]\n",
      "epoch:27 step:21322 [D loss: 0.759000, acc.: 38.28%] [G loss: 0.718274]\n",
      "epoch:27 step:21323 [D loss: 0.723518, acc.: 39.84%] [G loss: 0.641671]\n",
      "epoch:27 step:21324 [D loss: 0.709114, acc.: 49.22%] [G loss: 0.721753]\n",
      "epoch:27 step:21325 [D loss: 0.677173, acc.: 54.69%] [G loss: 0.683248]\n",
      "epoch:27 step:21326 [D loss: 0.695167, acc.: 49.22%] [G loss: 0.741416]\n",
      "epoch:27 step:21327 [D loss: 0.693523, acc.: 56.25%] [G loss: 0.756403]\n",
      "epoch:27 step:21328 [D loss: 0.729919, acc.: 42.19%] [G loss: 0.792008]\n",
      "epoch:27 step:21329 [D loss: 0.694608, acc.: 53.91%] [G loss: 0.702482]\n",
      "epoch:27 step:21330 [D loss: 0.700443, acc.: 53.12%] [G loss: 0.745100]\n",
      "epoch:27 step:21331 [D loss: 0.674960, acc.: 53.91%] [G loss: 0.734733]\n",
      "epoch:27 step:21332 [D loss: 0.713284, acc.: 49.22%] [G loss: 0.786314]\n",
      "epoch:27 step:21333 [D loss: 0.716781, acc.: 50.78%] [G loss: 0.741161]\n",
      "epoch:27 step:21334 [D loss: 0.660498, acc.: 61.72%] [G loss: 0.783506]\n",
      "epoch:27 step:21335 [D loss: 0.714383, acc.: 47.66%] [G loss: 0.803833]\n",
      "epoch:27 step:21336 [D loss: 0.675740, acc.: 57.03%] [G loss: 0.763338]\n",
      "epoch:27 step:21337 [D loss: 0.689841, acc.: 55.47%] [G loss: 0.792753]\n",
      "epoch:27 step:21338 [D loss: 0.722511, acc.: 43.75%] [G loss: 0.728099]\n",
      "epoch:27 step:21339 [D loss: 0.682232, acc.: 53.12%] [G loss: 0.767765]\n",
      "epoch:27 step:21340 [D loss: 0.707122, acc.: 49.22%] [G loss: 0.751808]\n",
      "epoch:27 step:21341 [D loss: 0.724546, acc.: 44.53%] [G loss: 0.761873]\n",
      "epoch:27 step:21342 [D loss: 0.708824, acc.: 51.56%] [G loss: 0.759684]\n",
      "epoch:27 step:21343 [D loss: 0.754823, acc.: 35.16%] [G loss: 0.701261]\n",
      "epoch:27 step:21344 [D loss: 0.694925, acc.: 52.34%] [G loss: 0.809724]\n",
      "epoch:27 step:21345 [D loss: 0.659712, acc.: 64.06%] [G loss: 0.758706]\n",
      "epoch:27 step:21346 [D loss: 0.715589, acc.: 47.66%] [G loss: 0.820312]\n",
      "epoch:27 step:21347 [D loss: 0.677181, acc.: 58.59%] [G loss: 0.811448]\n",
      "epoch:27 step:21348 [D loss: 0.702697, acc.: 48.44%] [G loss: 0.790407]\n",
      "epoch:27 step:21349 [D loss: 0.690995, acc.: 52.34%] [G loss: 0.833842]\n",
      "epoch:27 step:21350 [D loss: 0.639291, acc.: 68.75%] [G loss: 0.877084]\n",
      "epoch:27 step:21351 [D loss: 0.682134, acc.: 62.50%] [G loss: 0.819659]\n",
      "epoch:27 step:21352 [D loss: 0.685452, acc.: 51.56%] [G loss: 0.845354]\n",
      "epoch:27 step:21353 [D loss: 0.731699, acc.: 44.53%] [G loss: 0.783337]\n",
      "epoch:27 step:21354 [D loss: 0.735496, acc.: 48.44%] [G loss: 0.763200]\n",
      "epoch:27 step:21355 [D loss: 0.655653, acc.: 63.28%] [G loss: 0.783276]\n",
      "epoch:27 step:21356 [D loss: 0.673187, acc.: 64.06%] [G loss: 0.719889]\n",
      "epoch:27 step:21357 [D loss: 0.699467, acc.: 52.34%] [G loss: 0.755130]\n",
      "epoch:27 step:21358 [D loss: 0.667676, acc.: 62.50%] [G loss: 0.710672]\n",
      "epoch:27 step:21359 [D loss: 0.679021, acc.: 58.59%] [G loss: 0.845482]\n",
      "epoch:27 step:21360 [D loss: 0.717003, acc.: 42.97%] [G loss: 0.765939]\n",
      "epoch:27 step:21361 [D loss: 0.625814, acc.: 71.88%] [G loss: 0.787996]\n",
      "epoch:27 step:21362 [D loss: 0.735458, acc.: 39.84%] [G loss: 0.720297]\n",
      "epoch:27 step:21363 [D loss: 0.721306, acc.: 45.31%] [G loss: 0.772633]\n",
      "epoch:27 step:21364 [D loss: 0.699404, acc.: 46.88%] [G loss: 0.725340]\n",
      "epoch:27 step:21365 [D loss: 0.699106, acc.: 50.00%] [G loss: 0.746820]\n",
      "epoch:27 step:21366 [D loss: 0.676214, acc.: 57.03%] [G loss: 0.805287]\n",
      "epoch:27 step:21367 [D loss: 0.695174, acc.: 53.91%] [G loss: 0.827457]\n",
      "epoch:27 step:21368 [D loss: 0.663983, acc.: 57.03%] [G loss: 0.792618]\n",
      "epoch:27 step:21369 [D loss: 0.704537, acc.: 42.97%] [G loss: 0.755235]\n",
      "epoch:27 step:21370 [D loss: 0.660476, acc.: 64.84%] [G loss: 0.814183]\n",
      "epoch:27 step:21371 [D loss: 0.693879, acc.: 57.81%] [G loss: 0.748878]\n",
      "epoch:27 step:21372 [D loss: 0.674799, acc.: 57.81%] [G loss: 0.839262]\n",
      "epoch:27 step:21373 [D loss: 0.696020, acc.: 55.47%] [G loss: 0.811779]\n",
      "epoch:27 step:21374 [D loss: 0.708947, acc.: 53.12%] [G loss: 0.777760]\n",
      "epoch:27 step:21375 [D loss: 0.726867, acc.: 40.62%] [G loss: 0.700605]\n",
      "epoch:27 step:21376 [D loss: 0.693703, acc.: 53.12%] [G loss: 0.779182]\n",
      "epoch:27 step:21377 [D loss: 0.648600, acc.: 64.06%] [G loss: 0.728507]\n",
      "epoch:27 step:21378 [D loss: 0.736527, acc.: 39.06%] [G loss: 0.744111]\n",
      "epoch:27 step:21379 [D loss: 0.717657, acc.: 46.09%] [G loss: 0.729125]\n",
      "epoch:27 step:21380 [D loss: 0.685657, acc.: 53.12%] [G loss: 0.745136]\n",
      "epoch:27 step:21381 [D loss: 0.731716, acc.: 43.75%] [G loss: 0.691785]\n",
      "epoch:27 step:21382 [D loss: 0.702399, acc.: 50.00%] [G loss: 0.756738]\n",
      "epoch:27 step:21383 [D loss: 0.731071, acc.: 40.62%] [G loss: 0.739864]\n",
      "epoch:27 step:21384 [D loss: 0.700561, acc.: 52.34%] [G loss: 0.723325]\n",
      "epoch:27 step:21385 [D loss: 0.719737, acc.: 45.31%] [G loss: 0.734102]\n",
      "epoch:27 step:21386 [D loss: 0.663220, acc.: 60.16%] [G loss: 0.785446]\n",
      "epoch:27 step:21387 [D loss: 0.771356, acc.: 37.50%] [G loss: 0.746572]\n",
      "epoch:27 step:21388 [D loss: 0.647523, acc.: 67.97%] [G loss: 0.773850]\n",
      "epoch:27 step:21389 [D loss: 0.687872, acc.: 57.03%] [G loss: 0.741479]\n",
      "epoch:27 step:21390 [D loss: 0.686932, acc.: 56.25%] [G loss: 0.739304]\n",
      "epoch:27 step:21391 [D loss: 0.728562, acc.: 47.66%] [G loss: 0.701846]\n",
      "epoch:27 step:21392 [D loss: 0.722562, acc.: 45.31%] [G loss: 0.753158]\n",
      "epoch:27 step:21393 [D loss: 0.688302, acc.: 53.91%] [G loss: 0.761689]\n",
      "epoch:27 step:21394 [D loss: 0.684346, acc.: 53.12%] [G loss: 0.766380]\n",
      "epoch:27 step:21395 [D loss: 0.683969, acc.: 59.38%] [G loss: 0.718988]\n",
      "epoch:27 step:21396 [D loss: 0.681191, acc.: 55.47%] [G loss: 0.753468]\n",
      "epoch:27 step:21397 [D loss: 0.700689, acc.: 51.56%] [G loss: 0.759467]\n",
      "epoch:27 step:21398 [D loss: 0.676892, acc.: 54.69%] [G loss: 0.725441]\n",
      "epoch:27 step:21399 [D loss: 0.693019, acc.: 54.69%] [G loss: 0.744088]\n",
      "epoch:27 step:21400 [D loss: 0.676522, acc.: 53.91%] [G loss: 0.747402]\n",
      "epoch:27 step:21401 [D loss: 0.742893, acc.: 45.31%] [G loss: 0.697497]\n",
      "epoch:27 step:21402 [D loss: 0.717129, acc.: 43.75%] [G loss: 0.775040]\n",
      "epoch:27 step:21403 [D loss: 0.691677, acc.: 53.91%] [G loss: 0.788422]\n",
      "epoch:27 step:21404 [D loss: 0.684043, acc.: 59.38%] [G loss: 0.744303]\n",
      "epoch:27 step:21405 [D loss: 0.675248, acc.: 55.47%] [G loss: 0.788587]\n",
      "epoch:27 step:21406 [D loss: 0.678189, acc.: 55.47%] [G loss: 0.759846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21407 [D loss: 0.663777, acc.: 61.72%] [G loss: 0.843722]\n",
      "epoch:27 step:21408 [D loss: 0.679540, acc.: 60.16%] [G loss: 0.747332]\n",
      "epoch:27 step:21409 [D loss: 0.717329, acc.: 50.78%] [G loss: 0.727232]\n",
      "epoch:27 step:21410 [D loss: 0.726831, acc.: 37.50%] [G loss: 0.758671]\n",
      "epoch:27 step:21411 [D loss: 0.664081, acc.: 57.03%] [G loss: 0.755306]\n",
      "epoch:27 step:21412 [D loss: 0.718899, acc.: 42.97%] [G loss: 0.774354]\n",
      "epoch:27 step:21413 [D loss: 0.676271, acc.: 51.56%] [G loss: 0.791396]\n",
      "epoch:27 step:21414 [D loss: 0.669646, acc.: 56.25%] [G loss: 0.854521]\n",
      "epoch:27 step:21415 [D loss: 0.686784, acc.: 47.66%] [G loss: 0.852606]\n",
      "epoch:27 step:21416 [D loss: 0.696749, acc.: 49.22%] [G loss: 0.760499]\n",
      "epoch:27 step:21417 [D loss: 0.680036, acc.: 55.47%] [G loss: 0.781820]\n",
      "epoch:27 step:21418 [D loss: 0.725903, acc.: 42.19%] [G loss: 0.745872]\n",
      "epoch:27 step:21419 [D loss: 0.697822, acc.: 51.56%] [G loss: 0.708319]\n",
      "epoch:27 step:21420 [D loss: 0.672995, acc.: 60.94%] [G loss: 0.732185]\n",
      "epoch:27 step:21421 [D loss: 0.681920, acc.: 60.16%] [G loss: 0.768190]\n",
      "epoch:27 step:21422 [D loss: 0.655688, acc.: 61.72%] [G loss: 0.796911]\n",
      "epoch:27 step:21423 [D loss: 0.660147, acc.: 58.59%] [G loss: 0.714483]\n",
      "epoch:27 step:21424 [D loss: 0.690480, acc.: 53.12%] [G loss: 0.769665]\n",
      "epoch:27 step:21425 [D loss: 0.731979, acc.: 42.19%] [G loss: 0.735642]\n",
      "epoch:27 step:21426 [D loss: 0.675787, acc.: 60.16%] [G loss: 0.765716]\n",
      "epoch:27 step:21427 [D loss: 0.730563, acc.: 48.44%] [G loss: 0.710923]\n",
      "epoch:27 step:21428 [D loss: 0.683359, acc.: 54.69%] [G loss: 0.753022]\n",
      "epoch:27 step:21429 [D loss: 0.720069, acc.: 46.09%] [G loss: 0.706277]\n",
      "epoch:27 step:21430 [D loss: 0.678285, acc.: 61.72%] [G loss: 0.798781]\n",
      "epoch:27 step:21431 [D loss: 0.673639, acc.: 57.03%] [G loss: 0.745144]\n",
      "epoch:27 step:21432 [D loss: 0.648434, acc.: 64.06%] [G loss: 0.786908]\n",
      "epoch:27 step:21433 [D loss: 0.718105, acc.: 42.97%] [G loss: 0.784757]\n",
      "epoch:27 step:21434 [D loss: 0.702215, acc.: 53.12%] [G loss: 0.759758]\n",
      "epoch:27 step:21435 [D loss: 0.730362, acc.: 39.84%] [G loss: 0.774856]\n",
      "epoch:27 step:21436 [D loss: 0.678311, acc.: 55.47%] [G loss: 0.760136]\n",
      "epoch:27 step:21437 [D loss: 0.702542, acc.: 50.00%] [G loss: 0.780939]\n",
      "epoch:27 step:21438 [D loss: 0.699994, acc.: 50.00%] [G loss: 0.830214]\n",
      "epoch:27 step:21439 [D loss: 0.702682, acc.: 53.12%] [G loss: 0.740922]\n",
      "epoch:27 step:21440 [D loss: 0.673018, acc.: 57.03%] [G loss: 0.783984]\n",
      "epoch:27 step:21441 [D loss: 0.695210, acc.: 53.91%] [G loss: 0.747345]\n",
      "epoch:27 step:21442 [D loss: 0.715882, acc.: 48.44%] [G loss: 0.787996]\n",
      "epoch:27 step:21443 [D loss: 0.666168, acc.: 60.16%] [G loss: 0.824648]\n",
      "epoch:27 step:21444 [D loss: 0.686665, acc.: 53.91%] [G loss: 0.790404]\n",
      "epoch:27 step:21445 [D loss: 0.697285, acc.: 52.34%] [G loss: 0.759498]\n",
      "epoch:27 step:21446 [D loss: 0.691344, acc.: 54.69%] [G loss: 0.712522]\n",
      "epoch:27 step:21447 [D loss: 0.702247, acc.: 48.44%] [G loss: 0.789430]\n",
      "epoch:27 step:21448 [D loss: 0.652406, acc.: 62.50%] [G loss: 0.865152]\n",
      "epoch:27 step:21449 [D loss: 0.628212, acc.: 70.31%] [G loss: 0.788925]\n",
      "epoch:27 step:21450 [D loss: 0.738303, acc.: 37.50%] [G loss: 0.726482]\n",
      "epoch:27 step:21451 [D loss: 0.702100, acc.: 52.34%] [G loss: 0.745070]\n",
      "epoch:27 step:21452 [D loss: 0.660736, acc.: 60.94%] [G loss: 0.806233]\n",
      "epoch:27 step:21453 [D loss: 0.700043, acc.: 48.44%] [G loss: 0.741145]\n",
      "epoch:27 step:21454 [D loss: 0.650642, acc.: 66.41%] [G loss: 0.812681]\n",
      "epoch:27 step:21455 [D loss: 0.690444, acc.: 57.81%] [G loss: 0.871769]\n",
      "epoch:27 step:21456 [D loss: 0.694413, acc.: 47.66%] [G loss: 0.843389]\n",
      "epoch:27 step:21457 [D loss: 0.672769, acc.: 67.97%] [G loss: 0.758046]\n",
      "epoch:27 step:21458 [D loss: 0.676551, acc.: 54.69%] [G loss: 0.785859]\n",
      "epoch:27 step:21459 [D loss: 0.692183, acc.: 55.47%] [G loss: 0.710844]\n",
      "epoch:27 step:21460 [D loss: 0.743110, acc.: 36.72%] [G loss: 0.806305]\n",
      "epoch:27 step:21461 [D loss: 0.726706, acc.: 41.41%] [G loss: 0.786334]\n",
      "epoch:27 step:21462 [D loss: 0.709068, acc.: 50.00%] [G loss: 0.812612]\n",
      "epoch:27 step:21463 [D loss: 0.659895, acc.: 67.19%] [G loss: 0.754895]\n",
      "epoch:27 step:21464 [D loss: 0.634313, acc.: 64.06%] [G loss: 0.727454]\n",
      "epoch:27 step:21465 [D loss: 0.698685, acc.: 54.69%] [G loss: 0.757205]\n",
      "epoch:27 step:21466 [D loss: 0.677105, acc.: 57.81%] [G loss: 0.767334]\n",
      "epoch:27 step:21467 [D loss: 0.684156, acc.: 54.69%] [G loss: 0.775133]\n",
      "epoch:27 step:21468 [D loss: 0.666268, acc.: 62.50%] [G loss: 0.803730]\n",
      "epoch:27 step:21469 [D loss: 0.713962, acc.: 44.53%] [G loss: 0.772266]\n",
      "epoch:27 step:21470 [D loss: 0.684744, acc.: 55.47%] [G loss: 0.787343]\n",
      "epoch:27 step:21471 [D loss: 0.726123, acc.: 41.41%] [G loss: 0.750772]\n",
      "epoch:27 step:21472 [D loss: 0.681165, acc.: 54.69%] [G loss: 0.748296]\n",
      "epoch:27 step:21473 [D loss: 0.657609, acc.: 60.94%] [G loss: 0.760328]\n",
      "epoch:27 step:21474 [D loss: 0.664600, acc.: 57.81%] [G loss: 0.774879]\n",
      "epoch:27 step:21475 [D loss: 0.701678, acc.: 45.31%] [G loss: 0.860283]\n",
      "epoch:27 step:21476 [D loss: 0.647567, acc.: 63.28%] [G loss: 0.820182]\n",
      "epoch:27 step:21477 [D loss: 0.681876, acc.: 55.47%] [G loss: 0.827480]\n",
      "epoch:27 step:21478 [D loss: 0.729655, acc.: 45.31%] [G loss: 0.753804]\n",
      "epoch:27 step:21479 [D loss: 0.749013, acc.: 46.88%] [G loss: 0.755588]\n",
      "epoch:27 step:21480 [D loss: 0.724299, acc.: 46.88%] [G loss: 0.738265]\n",
      "epoch:27 step:21481 [D loss: 0.693930, acc.: 51.56%] [G loss: 0.759403]\n",
      "epoch:27 step:21482 [D loss: 0.714349, acc.: 46.88%] [G loss: 0.739914]\n",
      "epoch:27 step:21483 [D loss: 0.670621, acc.: 61.72%] [G loss: 0.742330]\n",
      "epoch:27 step:21484 [D loss: 0.668647, acc.: 59.38%] [G loss: 0.755442]\n",
      "epoch:27 step:21485 [D loss: 0.693435, acc.: 57.81%] [G loss: 0.696981]\n",
      "epoch:27 step:21486 [D loss: 0.640022, acc.: 67.19%] [G loss: 0.816445]\n",
      "epoch:27 step:21487 [D loss: 0.671515, acc.: 57.03%] [G loss: 0.718333]\n",
      "epoch:27 step:21488 [D loss: 0.663731, acc.: 58.59%] [G loss: 0.778682]\n",
      "epoch:27 step:21489 [D loss: 0.663880, acc.: 60.94%] [G loss: 0.729895]\n",
      "epoch:27 step:21490 [D loss: 0.647573, acc.: 62.50%] [G loss: 0.768878]\n",
      "epoch:27 step:21491 [D loss: 0.695143, acc.: 50.78%] [G loss: 0.762711]\n",
      "epoch:27 step:21492 [D loss: 0.690427, acc.: 56.25%] [G loss: 0.829134]\n",
      "epoch:27 step:21493 [D loss: 0.624310, acc.: 73.44%] [G loss: 0.850403]\n",
      "epoch:27 step:21494 [D loss: 0.670627, acc.: 50.78%] [G loss: 0.849904]\n",
      "epoch:27 step:21495 [D loss: 0.714816, acc.: 46.09%] [G loss: 0.785566]\n",
      "epoch:27 step:21496 [D loss: 0.674367, acc.: 58.59%] [G loss: 0.789736]\n",
      "epoch:27 step:21497 [D loss: 0.694138, acc.: 52.34%] [G loss: 0.744873]\n",
      "epoch:27 step:21498 [D loss: 0.734558, acc.: 43.75%] [G loss: 0.726364]\n",
      "epoch:27 step:21499 [D loss: 0.734633, acc.: 35.16%] [G loss: 0.714489]\n",
      "epoch:27 step:21500 [D loss: 0.709547, acc.: 53.91%] [G loss: 0.723152]\n",
      "epoch:27 step:21501 [D loss: 0.707439, acc.: 46.09%] [G loss: 0.711745]\n",
      "epoch:27 step:21502 [D loss: 0.629726, acc.: 67.97%] [G loss: 0.682657]\n",
      "epoch:27 step:21503 [D loss: 0.699350, acc.: 49.22%] [G loss: 0.713917]\n",
      "epoch:27 step:21504 [D loss: 0.744133, acc.: 38.28%] [G loss: 0.781413]\n",
      "epoch:27 step:21505 [D loss: 0.688240, acc.: 52.34%] [G loss: 0.804799]\n",
      "epoch:27 step:21506 [D loss: 0.658446, acc.: 57.81%] [G loss: 0.871822]\n",
      "epoch:27 step:21507 [D loss: 0.732907, acc.: 47.66%] [G loss: 0.774156]\n",
      "epoch:27 step:21508 [D loss: 0.685720, acc.: 53.12%] [G loss: 0.796072]\n",
      "epoch:27 step:21509 [D loss: 0.706931, acc.: 46.09%] [G loss: 0.760899]\n",
      "epoch:27 step:21510 [D loss: 0.726563, acc.: 42.19%] [G loss: 0.769662]\n",
      "epoch:27 step:21511 [D loss: 0.755293, acc.: 42.19%] [G loss: 0.762658]\n",
      "epoch:27 step:21512 [D loss: 0.681161, acc.: 60.16%] [G loss: 0.783253]\n",
      "epoch:27 step:21513 [D loss: 0.669378, acc.: 56.25%] [G loss: 0.779857]\n",
      "epoch:27 step:21514 [D loss: 0.704906, acc.: 50.78%] [G loss: 0.787457]\n",
      "epoch:27 step:21515 [D loss: 0.705996, acc.: 46.88%] [G loss: 0.748600]\n",
      "epoch:27 step:21516 [D loss: 0.720638, acc.: 39.84%] [G loss: 0.705280]\n",
      "epoch:27 step:21517 [D loss: 0.665095, acc.: 57.03%] [G loss: 0.722675]\n",
      "epoch:27 step:21518 [D loss: 0.709819, acc.: 46.09%] [G loss: 0.790091]\n",
      "epoch:27 step:21519 [D loss: 0.664394, acc.: 59.38%] [G loss: 0.773130]\n",
      "epoch:27 step:21520 [D loss: 0.688722, acc.: 52.34%] [G loss: 0.788512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21521 [D loss: 0.701936, acc.: 46.09%] [G loss: 0.863078]\n",
      "epoch:27 step:21522 [D loss: 0.717186, acc.: 47.66%] [G loss: 0.846796]\n",
      "epoch:27 step:21523 [D loss: 0.710170, acc.: 53.91%] [G loss: 0.749506]\n",
      "epoch:27 step:21524 [D loss: 0.716365, acc.: 46.09%] [G loss: 0.848880]\n",
      "epoch:27 step:21525 [D loss: 0.656435, acc.: 56.25%] [G loss: 0.770754]\n",
      "epoch:27 step:21526 [D loss: 0.661654, acc.: 57.81%] [G loss: 0.721382]\n",
      "epoch:27 step:21527 [D loss: 0.659940, acc.: 61.72%] [G loss: 0.813924]\n",
      "epoch:27 step:21528 [D loss: 0.698316, acc.: 51.56%] [G loss: 0.797568]\n",
      "epoch:27 step:21529 [D loss: 0.665024, acc.: 60.94%] [G loss: 0.757643]\n",
      "epoch:27 step:21530 [D loss: 0.639740, acc.: 70.31%] [G loss: 0.757173]\n",
      "epoch:27 step:21531 [D loss: 0.673535, acc.: 59.38%] [G loss: 0.802586]\n",
      "epoch:27 step:21532 [D loss: 0.664247, acc.: 60.16%] [G loss: 0.817745]\n",
      "epoch:27 step:21533 [D loss: 0.732251, acc.: 39.84%] [G loss: 0.784154]\n",
      "epoch:27 step:21534 [D loss: 0.678440, acc.: 63.28%] [G loss: 0.714282]\n",
      "epoch:27 step:21535 [D loss: 0.636276, acc.: 69.53%] [G loss: 0.754307]\n",
      "epoch:27 step:21536 [D loss: 0.687914, acc.: 54.69%] [G loss: 0.786762]\n",
      "epoch:27 step:21537 [D loss: 0.672448, acc.: 60.16%] [G loss: 0.828207]\n",
      "epoch:27 step:21538 [D loss: 0.676727, acc.: 55.47%] [G loss: 0.805948]\n",
      "epoch:27 step:21539 [D loss: 0.639958, acc.: 68.75%] [G loss: 0.778725]\n",
      "epoch:27 step:21540 [D loss: 0.754015, acc.: 36.72%] [G loss: 0.688457]\n",
      "epoch:27 step:21541 [D loss: 0.711967, acc.: 49.22%] [G loss: 0.756705]\n",
      "epoch:27 step:21542 [D loss: 0.750491, acc.: 39.84%] [G loss: 0.722855]\n",
      "epoch:27 step:21543 [D loss: 0.681477, acc.: 56.25%] [G loss: 0.717844]\n",
      "epoch:27 step:21544 [D loss: 0.695805, acc.: 50.78%] [G loss: 0.746195]\n",
      "epoch:27 step:21545 [D loss: 0.738488, acc.: 39.06%] [G loss: 0.745612]\n",
      "epoch:27 step:21546 [D loss: 0.705539, acc.: 50.00%] [G loss: 0.750310]\n",
      "epoch:27 step:21547 [D loss: 0.707877, acc.: 49.22%] [G loss: 0.738858]\n",
      "epoch:27 step:21548 [D loss: 0.684979, acc.: 50.78%] [G loss: 0.781145]\n",
      "epoch:27 step:21549 [D loss: 0.706128, acc.: 49.22%] [G loss: 0.738451]\n",
      "epoch:27 step:21550 [D loss: 0.695986, acc.: 49.22%] [G loss: 0.788596]\n",
      "epoch:27 step:21551 [D loss: 0.655485, acc.: 64.06%] [G loss: 0.803412]\n",
      "epoch:27 step:21552 [D loss: 0.668452, acc.: 63.28%] [G loss: 0.795497]\n",
      "epoch:27 step:21553 [D loss: 0.652892, acc.: 65.62%] [G loss: 0.780510]\n",
      "epoch:27 step:21554 [D loss: 0.753956, acc.: 36.72%] [G loss: 0.789445]\n",
      "epoch:27 step:21555 [D loss: 0.645389, acc.: 63.28%] [G loss: 0.798572]\n",
      "epoch:27 step:21556 [D loss: 0.671551, acc.: 62.50%] [G loss: 0.779693]\n",
      "epoch:27 step:21557 [D loss: 0.692969, acc.: 57.03%] [G loss: 0.745909]\n",
      "epoch:27 step:21558 [D loss: 0.696446, acc.: 49.22%] [G loss: 0.760251]\n",
      "epoch:27 step:21559 [D loss: 0.687692, acc.: 54.69%] [G loss: 0.747689]\n",
      "epoch:27 step:21560 [D loss: 0.715003, acc.: 41.41%] [G loss: 0.746637]\n",
      "epoch:27 step:21561 [D loss: 0.710405, acc.: 46.88%] [G loss: 0.749860]\n",
      "epoch:27 step:21562 [D loss: 0.768097, acc.: 40.62%] [G loss: 0.703404]\n",
      "epoch:27 step:21563 [D loss: 0.696215, acc.: 50.78%] [G loss: 0.749884]\n",
      "epoch:27 step:21564 [D loss: 0.682381, acc.: 58.59%] [G loss: 0.778423]\n",
      "epoch:27 step:21565 [D loss: 0.660169, acc.: 65.62%] [G loss: 0.749005]\n",
      "epoch:27 step:21566 [D loss: 0.704872, acc.: 53.12%] [G loss: 0.800909]\n",
      "epoch:27 step:21567 [D loss: 0.707663, acc.: 53.91%] [G loss: 0.756882]\n",
      "epoch:27 step:21568 [D loss: 0.705915, acc.: 49.22%] [G loss: 0.717892]\n",
      "epoch:27 step:21569 [D loss: 0.750359, acc.: 42.19%] [G loss: 0.784254]\n",
      "epoch:27 step:21570 [D loss: 0.711320, acc.: 46.88%] [G loss: 0.703892]\n",
      "epoch:27 step:21571 [D loss: 0.722156, acc.: 45.31%] [G loss: 0.723289]\n",
      "epoch:27 step:21572 [D loss: 0.664207, acc.: 64.06%] [G loss: 0.686066]\n",
      "epoch:27 step:21573 [D loss: 0.696354, acc.: 50.00%] [G loss: 0.747542]\n",
      "epoch:27 step:21574 [D loss: 0.726535, acc.: 46.09%] [G loss: 0.735419]\n",
      "epoch:27 step:21575 [D loss: 0.716780, acc.: 43.75%] [G loss: 0.783228]\n",
      "epoch:27 step:21576 [D loss: 0.739842, acc.: 37.50%] [G loss: 0.734236]\n",
      "epoch:27 step:21577 [D loss: 0.653293, acc.: 66.41%] [G loss: 0.771880]\n",
      "epoch:27 step:21578 [D loss: 0.710313, acc.: 43.75%] [G loss: 0.755085]\n",
      "epoch:27 step:21579 [D loss: 0.712860, acc.: 50.00%] [G loss: 0.736558]\n",
      "epoch:27 step:21580 [D loss: 0.707545, acc.: 46.88%] [G loss: 0.758977]\n",
      "epoch:27 step:21581 [D loss: 0.700816, acc.: 49.22%] [G loss: 0.760326]\n",
      "epoch:27 step:21582 [D loss: 0.664274, acc.: 59.38%] [G loss: 0.809303]\n",
      "epoch:27 step:21583 [D loss: 0.662029, acc.: 57.03%] [G loss: 0.787649]\n",
      "epoch:27 step:21584 [D loss: 0.694516, acc.: 50.78%] [G loss: 0.749223]\n",
      "epoch:27 step:21585 [D loss: 0.699365, acc.: 51.56%] [G loss: 0.766139]\n",
      "epoch:27 step:21586 [D loss: 0.695576, acc.: 50.78%] [G loss: 0.774198]\n",
      "epoch:27 step:21587 [D loss: 0.682108, acc.: 54.69%] [G loss: 0.750426]\n",
      "epoch:27 step:21588 [D loss: 0.676568, acc.: 63.28%] [G loss: 0.754954]\n",
      "epoch:27 step:21589 [D loss: 0.670088, acc.: 64.06%] [G loss: 0.747141]\n",
      "epoch:27 step:21590 [D loss: 0.650585, acc.: 62.50%] [G loss: 0.819840]\n",
      "epoch:27 step:21591 [D loss: 0.676007, acc.: 60.94%] [G loss: 0.759838]\n",
      "epoch:27 step:21592 [D loss: 0.681585, acc.: 52.34%] [G loss: 0.788729]\n",
      "epoch:27 step:21593 [D loss: 0.658063, acc.: 69.53%] [G loss: 0.803733]\n",
      "epoch:27 step:21594 [D loss: 0.676408, acc.: 54.69%] [G loss: 0.791106]\n",
      "epoch:27 step:21595 [D loss: 0.732034, acc.: 43.75%] [G loss: 0.727665]\n",
      "epoch:27 step:21596 [D loss: 0.709181, acc.: 45.31%] [G loss: 0.862733]\n",
      "epoch:27 step:21597 [D loss: 0.689586, acc.: 51.56%] [G loss: 0.796538]\n",
      "epoch:27 step:21598 [D loss: 0.691362, acc.: 54.69%] [G loss: 0.823267]\n",
      "epoch:27 step:21599 [D loss: 0.691656, acc.: 53.12%] [G loss: 0.785487]\n",
      "epoch:27 step:21600 [D loss: 0.748901, acc.: 37.50%] [G loss: 0.759645]\n",
      "epoch:27 step:21601 [D loss: 0.738255, acc.: 43.75%] [G loss: 0.740591]\n",
      "epoch:27 step:21602 [D loss: 0.656525, acc.: 66.41%] [G loss: 0.669009]\n",
      "epoch:27 step:21603 [D loss: 0.678385, acc.: 53.12%] [G loss: 0.722531]\n",
      "epoch:27 step:21604 [D loss: 0.711498, acc.: 41.41%] [G loss: 0.642076]\n",
      "epoch:27 step:21605 [D loss: 0.658604, acc.: 59.38%] [G loss: 0.653170]\n",
      "epoch:27 step:21606 [D loss: 0.678371, acc.: 57.81%] [G loss: 0.676329]\n",
      "epoch:27 step:21607 [D loss: 0.703046, acc.: 50.78%] [G loss: 0.720223]\n",
      "epoch:27 step:21608 [D loss: 0.685971, acc.: 54.69%] [G loss: 0.721090]\n",
      "epoch:27 step:21609 [D loss: 0.710571, acc.: 46.09%] [G loss: 0.739315]\n",
      "epoch:27 step:21610 [D loss: 0.660337, acc.: 66.41%] [G loss: 0.819593]\n",
      "epoch:27 step:21611 [D loss: 0.677722, acc.: 51.56%] [G loss: 0.788202]\n",
      "epoch:27 step:21612 [D loss: 0.668749, acc.: 59.38%] [G loss: 0.801887]\n",
      "epoch:27 step:21613 [D loss: 0.755800, acc.: 43.75%] [G loss: 0.731737]\n",
      "epoch:27 step:21614 [D loss: 0.657696, acc.: 60.94%] [G loss: 0.742428]\n",
      "epoch:27 step:21615 [D loss: 0.697429, acc.: 54.69%] [G loss: 0.720194]\n",
      "epoch:27 step:21616 [D loss: 0.660694, acc.: 64.06%] [G loss: 0.695990]\n",
      "epoch:27 step:21617 [D loss: 0.671116, acc.: 60.16%] [G loss: 0.756347]\n",
      "epoch:27 step:21618 [D loss: 0.694479, acc.: 51.56%] [G loss: 0.774358]\n",
      "epoch:27 step:21619 [D loss: 0.671948, acc.: 57.03%] [G loss: 0.755647]\n",
      "epoch:27 step:21620 [D loss: 0.671565, acc.: 60.94%] [G loss: 0.793677]\n",
      "epoch:27 step:21621 [D loss: 0.689801, acc.: 57.81%] [G loss: 0.765174]\n",
      "epoch:27 step:21622 [D loss: 0.733340, acc.: 44.53%] [G loss: 0.713301]\n",
      "epoch:27 step:21623 [D loss: 0.652059, acc.: 65.62%] [G loss: 0.840330]\n",
      "epoch:27 step:21624 [D loss: 0.707547, acc.: 51.56%] [G loss: 0.740706]\n",
      "epoch:27 step:21625 [D loss: 0.704296, acc.: 50.78%] [G loss: 0.713258]\n",
      "epoch:27 step:21626 [D loss: 0.711122, acc.: 37.50%] [G loss: 0.682007]\n",
      "epoch:27 step:21627 [D loss: 0.708933, acc.: 48.44%] [G loss: 0.802072]\n",
      "epoch:27 step:21628 [D loss: 0.643503, acc.: 69.53%] [G loss: 0.649862]\n",
      "epoch:27 step:21629 [D loss: 0.708372, acc.: 47.66%] [G loss: 0.773818]\n",
      "epoch:27 step:21630 [D loss: 0.640804, acc.: 69.53%] [G loss: 0.712578]\n",
      "epoch:27 step:21631 [D loss: 0.669698, acc.: 63.28%] [G loss: 0.797147]\n",
      "epoch:27 step:21632 [D loss: 0.641796, acc.: 69.53%] [G loss: 0.802137]\n",
      "epoch:27 step:21633 [D loss: 0.759886, acc.: 42.19%] [G loss: 0.715827]\n",
      "epoch:27 step:21634 [D loss: 0.643395, acc.: 60.16%] [G loss: 0.767451]\n",
      "epoch:27 step:21635 [D loss: 0.679547, acc.: 56.25%] [G loss: 0.810805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21636 [D loss: 0.678652, acc.: 57.03%] [G loss: 0.717529]\n",
      "epoch:27 step:21637 [D loss: 0.681132, acc.: 57.03%] [G loss: 0.744148]\n",
      "epoch:27 step:21638 [D loss: 0.699064, acc.: 54.69%] [G loss: 0.735470]\n",
      "epoch:27 step:21639 [D loss: 0.756983, acc.: 34.38%] [G loss: 0.757260]\n",
      "epoch:27 step:21640 [D loss: 0.685514, acc.: 57.81%] [G loss: 0.788619]\n",
      "epoch:27 step:21641 [D loss: 0.701247, acc.: 48.44%] [G loss: 0.784551]\n",
      "epoch:27 step:21642 [D loss: 0.712668, acc.: 48.44%] [G loss: 0.802428]\n",
      "epoch:27 step:21643 [D loss: 0.717427, acc.: 48.44%] [G loss: 0.748683]\n",
      "epoch:27 step:21644 [D loss: 0.711045, acc.: 52.34%] [G loss: 0.743284]\n",
      "epoch:27 step:21645 [D loss: 0.655109, acc.: 64.06%] [G loss: 0.785585]\n",
      "epoch:27 step:21646 [D loss: 0.650986, acc.: 64.06%] [G loss: 0.735164]\n",
      "epoch:27 step:21647 [D loss: 0.712583, acc.: 40.62%] [G loss: 0.696827]\n",
      "epoch:27 step:21648 [D loss: 0.723044, acc.: 46.09%] [G loss: 0.746945]\n",
      "epoch:27 step:21649 [D loss: 0.688308, acc.: 49.22%] [G loss: 0.789602]\n",
      "epoch:27 step:21650 [D loss: 0.746610, acc.: 34.38%] [G loss: 0.744482]\n",
      "epoch:27 step:21651 [D loss: 0.673655, acc.: 60.16%] [G loss: 0.737345]\n",
      "epoch:27 step:21652 [D loss: 0.721180, acc.: 48.44%] [G loss: 0.779412]\n",
      "epoch:27 step:21653 [D loss: 0.704789, acc.: 46.88%] [G loss: 0.738382]\n",
      "epoch:27 step:21654 [D loss: 0.658588, acc.: 60.94%] [G loss: 0.760069]\n",
      "epoch:27 step:21655 [D loss: 0.681397, acc.: 51.56%] [G loss: 0.814634]\n",
      "epoch:27 step:21656 [D loss: 0.689467, acc.: 47.66%] [G loss: 0.837082]\n",
      "epoch:27 step:21657 [D loss: 0.706943, acc.: 53.91%] [G loss: 0.782483]\n",
      "epoch:27 step:21658 [D loss: 0.702432, acc.: 51.56%] [G loss: 0.801914]\n",
      "epoch:27 step:21659 [D loss: 0.702217, acc.: 50.00%] [G loss: 0.741268]\n",
      "epoch:27 step:21660 [D loss: 0.684703, acc.: 52.34%] [G loss: 0.782192]\n",
      "epoch:27 step:21661 [D loss: 0.674205, acc.: 60.16%] [G loss: 0.756127]\n",
      "epoch:27 step:21662 [D loss: 0.710228, acc.: 46.88%] [G loss: 0.735247]\n",
      "epoch:27 step:21663 [D loss: 0.705077, acc.: 51.56%] [G loss: 0.700378]\n",
      "epoch:27 step:21664 [D loss: 0.711796, acc.: 51.56%] [G loss: 0.728412]\n",
      "epoch:27 step:21665 [D loss: 0.685798, acc.: 57.81%] [G loss: 0.713998]\n",
      "epoch:27 step:21666 [D loss: 0.667414, acc.: 54.69%] [G loss: 0.688967]\n",
      "epoch:27 step:21667 [D loss: 0.723694, acc.: 48.44%] [G loss: 0.716675]\n",
      "epoch:27 step:21668 [D loss: 0.713775, acc.: 51.56%] [G loss: 0.751309]\n",
      "epoch:27 step:21669 [D loss: 0.657870, acc.: 59.38%] [G loss: 0.758041]\n",
      "epoch:27 step:21670 [D loss: 0.703670, acc.: 52.34%] [G loss: 0.732627]\n",
      "epoch:27 step:21671 [D loss: 0.689571, acc.: 54.69%] [G loss: 0.782928]\n",
      "epoch:27 step:21672 [D loss: 0.645384, acc.: 67.19%] [G loss: 0.827168]\n",
      "epoch:27 step:21673 [D loss: 0.667800, acc.: 58.59%] [G loss: 0.770381]\n",
      "epoch:27 step:21674 [D loss: 0.659740, acc.: 62.50%] [G loss: 0.774455]\n",
      "epoch:27 step:21675 [D loss: 0.659502, acc.: 59.38%] [G loss: 0.762785]\n",
      "epoch:27 step:21676 [D loss: 0.657329, acc.: 64.84%] [G loss: 0.715907]\n",
      "epoch:27 step:21677 [D loss: 0.711136, acc.: 47.66%] [G loss: 0.708224]\n",
      "epoch:27 step:21678 [D loss: 0.699601, acc.: 56.25%] [G loss: 0.745845]\n",
      "epoch:27 step:21679 [D loss: 0.677436, acc.: 56.25%] [G loss: 0.782982]\n",
      "epoch:27 step:21680 [D loss: 0.706603, acc.: 54.69%] [G loss: 0.739131]\n",
      "epoch:27 step:21681 [D loss: 0.667403, acc.: 60.94%] [G loss: 0.785177]\n",
      "epoch:27 step:21682 [D loss: 0.655844, acc.: 63.28%] [G loss: 0.859936]\n",
      "epoch:27 step:21683 [D loss: 0.697300, acc.: 56.25%] [G loss: 0.821737]\n",
      "epoch:27 step:21684 [D loss: 0.678940, acc.: 59.38%] [G loss: 0.761156]\n",
      "epoch:27 step:21685 [D loss: 0.688709, acc.: 55.47%] [G loss: 0.757511]\n",
      "epoch:27 step:21686 [D loss: 0.684574, acc.: 53.91%] [G loss: 0.883651]\n",
      "epoch:27 step:21687 [D loss: 0.689943, acc.: 64.06%] [G loss: 0.792928]\n",
      "epoch:27 step:21688 [D loss: 0.679994, acc.: 50.78%] [G loss: 0.702948]\n",
      "epoch:27 step:21689 [D loss: 0.687737, acc.: 50.00%] [G loss: 0.811800]\n",
      "epoch:27 step:21690 [D loss: 0.710010, acc.: 44.53%] [G loss: 0.788210]\n",
      "epoch:27 step:21691 [D loss: 0.665631, acc.: 60.16%] [G loss: 0.811862]\n",
      "epoch:27 step:21692 [D loss: 0.675699, acc.: 53.91%] [G loss: 0.742451]\n",
      "epoch:27 step:21693 [D loss: 0.640820, acc.: 67.97%] [G loss: 0.780857]\n",
      "epoch:27 step:21694 [D loss: 0.665344, acc.: 60.94%] [G loss: 0.757081]\n",
      "epoch:27 step:21695 [D loss: 0.685431, acc.: 53.12%] [G loss: 0.836450]\n",
      "epoch:27 step:21696 [D loss: 0.673948, acc.: 61.72%] [G loss: 0.786338]\n",
      "epoch:27 step:21697 [D loss: 0.698679, acc.: 50.00%] [G loss: 0.776014]\n",
      "epoch:27 step:21698 [D loss: 0.687247, acc.: 55.47%] [G loss: 0.834794]\n",
      "epoch:27 step:21699 [D loss: 0.669451, acc.: 62.50%] [G loss: 0.835954]\n",
      "epoch:27 step:21700 [D loss: 0.740098, acc.: 47.66%] [G loss: 0.777317]\n",
      "epoch:27 step:21701 [D loss: 0.698464, acc.: 55.47%] [G loss: 0.759791]\n",
      "epoch:27 step:21702 [D loss: 0.682281, acc.: 58.59%] [G loss: 0.822944]\n",
      "epoch:27 step:21703 [D loss: 0.637110, acc.: 64.84%] [G loss: 0.788774]\n",
      "epoch:27 step:21704 [D loss: 0.708354, acc.: 49.22%] [G loss: 0.752190]\n",
      "epoch:27 step:21705 [D loss: 0.674439, acc.: 54.69%] [G loss: 0.764714]\n",
      "epoch:27 step:21706 [D loss: 0.704205, acc.: 54.69%] [G loss: 0.789461]\n",
      "epoch:27 step:21707 [D loss: 0.643117, acc.: 64.06%] [G loss: 0.805000]\n",
      "epoch:27 step:21708 [D loss: 0.702378, acc.: 46.09%] [G loss: 0.854301]\n",
      "epoch:27 step:21709 [D loss: 0.661159, acc.: 61.72%] [G loss: 0.725772]\n",
      "epoch:27 step:21710 [D loss: 0.705129, acc.: 50.78%] [G loss: 0.827378]\n",
      "epoch:27 step:21711 [D loss: 0.689986, acc.: 52.34%] [G loss: 0.750960]\n",
      "epoch:27 step:21712 [D loss: 0.683660, acc.: 53.12%] [G loss: 0.756196]\n",
      "epoch:27 step:21713 [D loss: 0.715692, acc.: 42.97%] [G loss: 0.757882]\n",
      "epoch:27 step:21714 [D loss: 0.698942, acc.: 54.69%] [G loss: 0.702791]\n",
      "epoch:27 step:21715 [D loss: 0.633072, acc.: 72.66%] [G loss: 0.816041]\n",
      "epoch:27 step:21716 [D loss: 0.740952, acc.: 43.75%] [G loss: 0.714565]\n",
      "epoch:27 step:21717 [D loss: 0.660081, acc.: 59.38%] [G loss: 0.765495]\n",
      "epoch:27 step:21718 [D loss: 0.687579, acc.: 50.00%] [G loss: 0.779073]\n",
      "epoch:27 step:21719 [D loss: 0.705122, acc.: 46.88%] [G loss: 0.780778]\n",
      "epoch:27 step:21720 [D loss: 0.726521, acc.: 45.31%] [G loss: 0.735444]\n",
      "epoch:27 step:21721 [D loss: 0.709043, acc.: 48.44%] [G loss: 0.759591]\n",
      "epoch:27 step:21722 [D loss: 0.709530, acc.: 46.88%] [G loss: 0.790083]\n",
      "epoch:27 step:21723 [D loss: 0.690445, acc.: 51.56%] [G loss: 0.730594]\n",
      "epoch:27 step:21724 [D loss: 0.685088, acc.: 51.56%] [G loss: 0.766871]\n",
      "epoch:27 step:21725 [D loss: 0.697061, acc.: 47.66%] [G loss: 0.733010]\n",
      "epoch:27 step:21726 [D loss: 0.720726, acc.: 43.75%] [G loss: 0.788971]\n",
      "epoch:27 step:21727 [D loss: 0.682019, acc.: 58.59%] [G loss: 0.804757]\n",
      "epoch:27 step:21728 [D loss: 0.652230, acc.: 64.84%] [G loss: 0.782559]\n",
      "epoch:27 step:21729 [D loss: 0.710947, acc.: 46.88%] [G loss: 0.763652]\n",
      "epoch:27 step:21730 [D loss: 0.721607, acc.: 49.22%] [G loss: 0.715567]\n",
      "epoch:27 step:21731 [D loss: 0.646413, acc.: 69.53%] [G loss: 0.733074]\n",
      "epoch:27 step:21732 [D loss: 0.706015, acc.: 47.66%] [G loss: 0.745440]\n",
      "epoch:27 step:21733 [D loss: 0.644479, acc.: 66.41%] [G loss: 0.752689]\n",
      "epoch:27 step:21734 [D loss: 0.673179, acc.: 60.94%] [G loss: 0.712683]\n",
      "epoch:27 step:21735 [D loss: 0.697514, acc.: 53.12%] [G loss: 0.778266]\n",
      "epoch:27 step:21736 [D loss: 0.676723, acc.: 58.59%] [G loss: 0.738784]\n",
      "epoch:27 step:21737 [D loss: 0.700880, acc.: 52.34%] [G loss: 0.777511]\n",
      "epoch:27 step:21738 [D loss: 0.650140, acc.: 65.62%] [G loss: 0.790676]\n",
      "epoch:27 step:21739 [D loss: 0.664460, acc.: 65.62%] [G loss: 0.786609]\n",
      "epoch:27 step:21740 [D loss: 0.713335, acc.: 40.62%] [G loss: 0.718852]\n",
      "epoch:27 step:21741 [D loss: 0.700053, acc.: 53.12%] [G loss: 0.774714]\n",
      "epoch:27 step:21742 [D loss: 0.735499, acc.: 40.62%] [G loss: 0.763146]\n",
      "epoch:27 step:21743 [D loss: 0.708262, acc.: 46.09%] [G loss: 0.758254]\n",
      "epoch:27 step:21744 [D loss: 0.711650, acc.: 44.53%] [G loss: 0.716593]\n",
      "epoch:27 step:21745 [D loss: 0.706421, acc.: 52.34%] [G loss: 0.713250]\n",
      "epoch:27 step:21746 [D loss: 0.672552, acc.: 64.06%] [G loss: 0.733900]\n",
      "epoch:27 step:21747 [D loss: 0.686662, acc.: 55.47%] [G loss: 0.756457]\n",
      "epoch:27 step:21748 [D loss: 0.667084, acc.: 58.59%] [G loss: 0.729042]\n",
      "epoch:27 step:21749 [D loss: 0.674562, acc.: 63.28%] [G loss: 0.740347]\n",
      "epoch:27 step:21750 [D loss: 0.669082, acc.: 57.81%] [G loss: 0.755646]\n",
      "epoch:27 step:21751 [D loss: 0.723168, acc.: 42.97%] [G loss: 0.768216]\n",
      "epoch:27 step:21752 [D loss: 0.696620, acc.: 53.12%] [G loss: 0.772640]\n",
      "epoch:27 step:21753 [D loss: 0.688001, acc.: 53.91%] [G loss: 0.741068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21754 [D loss: 0.699493, acc.: 54.69%] [G loss: 0.804770]\n",
      "epoch:27 step:21755 [D loss: 0.680540, acc.: 55.47%] [G loss: 0.728811]\n",
      "epoch:27 step:21756 [D loss: 0.684924, acc.: 59.38%] [G loss: 0.735614]\n",
      "epoch:27 step:21757 [D loss: 0.713104, acc.: 49.22%] [G loss: 0.742002]\n",
      "epoch:27 step:21758 [D loss: 0.708238, acc.: 51.56%] [G loss: 0.791218]\n",
      "epoch:27 step:21759 [D loss: 0.728263, acc.: 39.84%] [G loss: 0.832617]\n",
      "epoch:27 step:21760 [D loss: 0.638470, acc.: 67.97%] [G loss: 0.830991]\n",
      "epoch:27 step:21761 [D loss: 0.689341, acc.: 56.25%] [G loss: 0.817252]\n",
      "epoch:27 step:21762 [D loss: 0.718394, acc.: 48.44%] [G loss: 0.755397]\n",
      "epoch:27 step:21763 [D loss: 0.681207, acc.: 55.47%] [G loss: 0.776816]\n",
      "epoch:27 step:21764 [D loss: 0.698620, acc.: 53.91%] [G loss: 0.743421]\n",
      "epoch:27 step:21765 [D loss: 0.652739, acc.: 63.28%] [G loss: 0.791528]\n",
      "epoch:27 step:21766 [D loss: 0.657708, acc.: 62.50%] [G loss: 0.729839]\n",
      "epoch:27 step:21767 [D loss: 0.672271, acc.: 59.38%] [G loss: 0.836738]\n",
      "epoch:27 step:21768 [D loss: 0.684533, acc.: 52.34%] [G loss: 0.748918]\n",
      "epoch:27 step:21769 [D loss: 0.685980, acc.: 54.69%] [G loss: 0.759064]\n",
      "epoch:27 step:21770 [D loss: 0.702100, acc.: 48.44%] [G loss: 0.729000]\n",
      "epoch:27 step:21771 [D loss: 0.690641, acc.: 50.78%] [G loss: 0.830134]\n",
      "epoch:27 step:21772 [D loss: 0.676165, acc.: 58.59%] [G loss: 0.784784]\n",
      "epoch:27 step:21773 [D loss: 0.678141, acc.: 58.59%] [G loss: 0.765003]\n",
      "epoch:27 step:21774 [D loss: 0.657743, acc.: 66.41%] [G loss: 0.749766]\n",
      "epoch:27 step:21775 [D loss: 0.690845, acc.: 55.47%] [G loss: 0.779385]\n",
      "epoch:27 step:21776 [D loss: 0.681913, acc.: 60.16%] [G loss: 0.716047]\n",
      "epoch:27 step:21777 [D loss: 0.694667, acc.: 53.91%] [G loss: 0.731814]\n",
      "epoch:27 step:21778 [D loss: 0.703502, acc.: 44.53%] [G loss: 0.715283]\n",
      "epoch:27 step:21779 [D loss: 0.748011, acc.: 34.38%] [G loss: 0.717746]\n",
      "epoch:27 step:21780 [D loss: 0.716093, acc.: 47.66%] [G loss: 0.735264]\n",
      "epoch:27 step:21781 [D loss: 0.711846, acc.: 48.44%] [G loss: 0.659591]\n",
      "epoch:27 step:21782 [D loss: 0.697342, acc.: 50.78%] [G loss: 0.690442]\n",
      "epoch:27 step:21783 [D loss: 0.725375, acc.: 43.75%] [G loss: 0.749972]\n",
      "epoch:27 step:21784 [D loss: 0.680607, acc.: 56.25%] [G loss: 0.663951]\n",
      "epoch:27 step:21785 [D loss: 0.755179, acc.: 37.50%] [G loss: 0.687046]\n",
      "epoch:27 step:21786 [D loss: 0.736865, acc.: 46.88%] [G loss: 0.712948]\n",
      "epoch:27 step:21787 [D loss: 0.738761, acc.: 41.41%] [G loss: 0.743407]\n",
      "epoch:27 step:21788 [D loss: 0.681599, acc.: 53.12%] [G loss: 0.769509]\n",
      "epoch:27 step:21789 [D loss: 0.677077, acc.: 56.25%] [G loss: 0.784406]\n",
      "epoch:27 step:21790 [D loss: 0.659450, acc.: 61.72%] [G loss: 0.792914]\n",
      "epoch:27 step:21791 [D loss: 0.688660, acc.: 49.22%] [G loss: 0.802430]\n",
      "epoch:27 step:21792 [D loss: 0.680787, acc.: 58.59%] [G loss: 0.778709]\n",
      "epoch:27 step:21793 [D loss: 0.739265, acc.: 47.66%] [G loss: 0.794569]\n",
      "epoch:27 step:21794 [D loss: 0.675509, acc.: 54.69%] [G loss: 0.734870]\n",
      "epoch:27 step:21795 [D loss: 0.681897, acc.: 57.81%] [G loss: 0.852732]\n",
      "epoch:27 step:21796 [D loss: 0.672108, acc.: 60.94%] [G loss: 0.811239]\n",
      "epoch:27 step:21797 [D loss: 0.702917, acc.: 50.00%] [G loss: 0.791133]\n",
      "epoch:27 step:21798 [D loss: 0.667329, acc.: 59.38%] [G loss: 0.857392]\n",
      "epoch:27 step:21799 [D loss: 0.667922, acc.: 61.72%] [G loss: 0.818473]\n",
      "epoch:27 step:21800 [D loss: 0.675996, acc.: 66.41%] [G loss: 0.788306]\n",
      "epoch:27 step:21801 [D loss: 0.663849, acc.: 61.72%] [G loss: 0.792575]\n",
      "epoch:27 step:21802 [D loss: 0.698726, acc.: 52.34%] [G loss: 0.807212]\n",
      "epoch:27 step:21803 [D loss: 0.625733, acc.: 74.22%] [G loss: 0.813016]\n",
      "epoch:27 step:21804 [D loss: 0.685910, acc.: 57.03%] [G loss: 0.741998]\n",
      "epoch:27 step:21805 [D loss: 0.624316, acc.: 73.44%] [G loss: 0.809268]\n",
      "epoch:27 step:21806 [D loss: 0.655087, acc.: 64.84%] [G loss: 0.748802]\n",
      "epoch:27 step:21807 [D loss: 0.655101, acc.: 58.59%] [G loss: 0.758855]\n",
      "epoch:27 step:21808 [D loss: 0.738720, acc.: 46.09%] [G loss: 0.758293]\n",
      "epoch:27 step:21809 [D loss: 0.667007, acc.: 64.84%] [G loss: 0.718032]\n",
      "epoch:27 step:21810 [D loss: 0.750709, acc.: 40.62%] [G loss: 0.741646]\n",
      "epoch:27 step:21811 [D loss: 0.691615, acc.: 50.78%] [G loss: 0.737551]\n",
      "epoch:27 step:21812 [D loss: 0.669750, acc.: 54.69%] [G loss: 0.712890]\n",
      "epoch:27 step:21813 [D loss: 0.751625, acc.: 37.50%] [G loss: 0.647681]\n",
      "epoch:27 step:21814 [D loss: 0.694076, acc.: 52.34%] [G loss: 0.785587]\n",
      "epoch:27 step:21815 [D loss: 0.700586, acc.: 46.88%] [G loss: 0.742396]\n",
      "epoch:27 step:21816 [D loss: 0.682149, acc.: 55.47%] [G loss: 0.760647]\n",
      "epoch:27 step:21817 [D loss: 0.715941, acc.: 47.66%] [G loss: 0.718128]\n",
      "epoch:27 step:21818 [D loss: 0.722610, acc.: 50.00%] [G loss: 0.746670]\n",
      "epoch:27 step:21819 [D loss: 0.708095, acc.: 47.66%] [G loss: 0.773929]\n",
      "epoch:27 step:21820 [D loss: 0.699771, acc.: 50.00%] [G loss: 0.749521]\n",
      "epoch:27 step:21821 [D loss: 0.673192, acc.: 60.16%] [G loss: 0.754566]\n",
      "epoch:27 step:21822 [D loss: 0.739702, acc.: 37.50%] [G loss: 0.697651]\n",
      "epoch:27 step:21823 [D loss: 0.676286, acc.: 56.25%] [G loss: 0.699312]\n",
      "epoch:27 step:21824 [D loss: 0.679054, acc.: 60.94%] [G loss: 0.755289]\n",
      "epoch:27 step:21825 [D loss: 0.646789, acc.: 64.84%] [G loss: 0.813392]\n",
      "epoch:27 step:21826 [D loss: 0.698325, acc.: 56.25%] [G loss: 0.798188]\n",
      "epoch:27 step:21827 [D loss: 0.671890, acc.: 59.38%] [G loss: 0.822335]\n",
      "epoch:27 step:21828 [D loss: 0.672029, acc.: 57.03%] [G loss: 0.812224]\n",
      "epoch:27 step:21829 [D loss: 0.630829, acc.: 67.19%] [G loss: 0.926818]\n",
      "epoch:27 step:21830 [D loss: 0.665954, acc.: 57.03%] [G loss: 0.777866]\n",
      "epoch:27 step:21831 [D loss: 0.671940, acc.: 57.81%] [G loss: 0.825674]\n",
      "epoch:27 step:21832 [D loss: 0.669659, acc.: 56.25%] [G loss: 0.795337]\n",
      "epoch:27 step:21833 [D loss: 0.669459, acc.: 55.47%] [G loss: 0.776658]\n",
      "epoch:27 step:21834 [D loss: 0.712448, acc.: 49.22%] [G loss: 0.721906]\n",
      "epoch:27 step:21835 [D loss: 0.695983, acc.: 54.69%] [G loss: 0.739794]\n",
      "epoch:27 step:21836 [D loss: 0.659693, acc.: 66.41%] [G loss: 0.771218]\n",
      "epoch:27 step:21837 [D loss: 0.673820, acc.: 56.25%] [G loss: 0.764442]\n",
      "epoch:27 step:21838 [D loss: 0.689124, acc.: 55.47%] [G loss: 0.727499]\n",
      "epoch:27 step:21839 [D loss: 0.682896, acc.: 57.81%] [G loss: 0.815868]\n",
      "epoch:27 step:21840 [D loss: 0.691370, acc.: 53.91%] [G loss: 0.687296]\n",
      "epoch:27 step:21841 [D loss: 0.720403, acc.: 43.75%] [G loss: 0.742259]\n",
      "epoch:27 step:21842 [D loss: 0.677993, acc.: 53.91%] [G loss: 0.798084]\n",
      "epoch:27 step:21843 [D loss: 0.665813, acc.: 53.91%] [G loss: 0.810906]\n",
      "epoch:27 step:21844 [D loss: 0.702530, acc.: 44.53%] [G loss: 0.711282]\n",
      "epoch:27 step:21845 [D loss: 0.694278, acc.: 50.78%] [G loss: 0.757900]\n",
      "epoch:27 step:21846 [D loss: 0.721439, acc.: 42.97%] [G loss: 0.728639]\n",
      "epoch:27 step:21847 [D loss: 0.687055, acc.: 54.69%] [G loss: 0.753479]\n",
      "epoch:27 step:21848 [D loss: 0.670932, acc.: 57.03%] [G loss: 0.787985]\n",
      "epoch:27 step:21849 [D loss: 0.741129, acc.: 36.72%] [G loss: 0.753824]\n",
      "epoch:27 step:21850 [D loss: 0.685747, acc.: 58.59%] [G loss: 0.750009]\n",
      "epoch:27 step:21851 [D loss: 0.703202, acc.: 48.44%] [G loss: 0.773309]\n",
      "epoch:27 step:21852 [D loss: 0.715333, acc.: 47.66%] [G loss: 0.747766]\n",
      "epoch:27 step:21853 [D loss: 0.673932, acc.: 59.38%] [G loss: 0.726642]\n",
      "epoch:27 step:21854 [D loss: 0.706403, acc.: 47.66%] [G loss: 0.726646]\n",
      "epoch:27 step:21855 [D loss: 0.700991, acc.: 46.88%] [G loss: 0.816979]\n",
      "epoch:27 step:21856 [D loss: 0.755043, acc.: 41.41%] [G loss: 0.780361]\n",
      "epoch:27 step:21857 [D loss: 0.691334, acc.: 53.91%] [G loss: 0.837928]\n",
      "epoch:27 step:21858 [D loss: 0.756579, acc.: 41.41%] [G loss: 0.753311]\n",
      "epoch:27 step:21859 [D loss: 0.706764, acc.: 47.66%] [G loss: 0.807799]\n",
      "epoch:27 step:21860 [D loss: 0.740520, acc.: 39.06%] [G loss: 0.776113]\n",
      "epoch:27 step:21861 [D loss: 0.703602, acc.: 50.00%] [G loss: 0.785246]\n",
      "epoch:27 step:21862 [D loss: 0.673336, acc.: 54.69%] [G loss: 0.823284]\n",
      "epoch:27 step:21863 [D loss: 0.653659, acc.: 61.72%] [G loss: 0.825521]\n",
      "epoch:27 step:21864 [D loss: 0.695102, acc.: 53.91%] [G loss: 0.817294]\n",
      "epoch:27 step:21865 [D loss: 0.700991, acc.: 54.69%] [G loss: 0.663126]\n",
      "epoch:27 step:21866 [D loss: 0.675896, acc.: 57.81%] [G loss: 0.722703]\n",
      "epoch:27 step:21867 [D loss: 0.749735, acc.: 35.16%] [G loss: 0.738349]\n",
      "epoch:27 step:21868 [D loss: 0.654752, acc.: 60.94%] [G loss: 0.729288]\n",
      "epoch:28 step:21869 [D loss: 0.703461, acc.: 59.38%] [G loss: 0.758606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21870 [D loss: 0.665393, acc.: 57.81%] [G loss: 0.766805]\n",
      "epoch:28 step:21871 [D loss: 0.644777, acc.: 63.28%] [G loss: 0.778628]\n",
      "epoch:28 step:21872 [D loss: 0.682974, acc.: 50.78%] [G loss: 0.833349]\n",
      "epoch:28 step:21873 [D loss: 0.733585, acc.: 45.31%] [G loss: 0.839322]\n",
      "epoch:28 step:21874 [D loss: 0.668913, acc.: 60.94%] [G loss: 0.831484]\n",
      "epoch:28 step:21875 [D loss: 0.679375, acc.: 57.03%] [G loss: 0.877602]\n",
      "epoch:28 step:21876 [D loss: 0.672057, acc.: 57.03%] [G loss: 0.842519]\n",
      "epoch:28 step:21877 [D loss: 0.697080, acc.: 50.78%] [G loss: 0.815113]\n",
      "epoch:28 step:21878 [D loss: 0.668353, acc.: 58.59%] [G loss: 0.764742]\n",
      "epoch:28 step:21879 [D loss: 0.680974, acc.: 53.91%] [G loss: 0.756436]\n",
      "epoch:28 step:21880 [D loss: 0.738608, acc.: 39.84%] [G loss: 0.740639]\n",
      "epoch:28 step:21881 [D loss: 0.686664, acc.: 57.03%] [G loss: 0.731331]\n",
      "epoch:28 step:21882 [D loss: 0.695708, acc.: 56.25%] [G loss: 0.763077]\n",
      "epoch:28 step:21883 [D loss: 0.743416, acc.: 46.09%] [G loss: 0.811506]\n",
      "epoch:28 step:21884 [D loss: 0.657804, acc.: 57.81%] [G loss: 0.776116]\n",
      "epoch:28 step:21885 [D loss: 0.727356, acc.: 46.09%] [G loss: 0.765026]\n",
      "epoch:28 step:21886 [D loss: 0.665625, acc.: 59.38%] [G loss: 0.773636]\n",
      "epoch:28 step:21887 [D loss: 0.682079, acc.: 59.38%] [G loss: 0.747777]\n",
      "epoch:28 step:21888 [D loss: 0.680639, acc.: 55.47%] [G loss: 0.756227]\n",
      "epoch:28 step:21889 [D loss: 0.724055, acc.: 49.22%] [G loss: 0.693110]\n",
      "epoch:28 step:21890 [D loss: 0.694902, acc.: 48.44%] [G loss: 0.721087]\n",
      "epoch:28 step:21891 [D loss: 0.662624, acc.: 62.50%] [G loss: 0.759474]\n",
      "epoch:28 step:21892 [D loss: 0.715734, acc.: 42.97%] [G loss: 0.734315]\n",
      "epoch:28 step:21893 [D loss: 0.679744, acc.: 57.03%] [G loss: 0.775561]\n",
      "epoch:28 step:21894 [D loss: 0.713412, acc.: 47.66%] [G loss: 0.719031]\n",
      "epoch:28 step:21895 [D loss: 0.689414, acc.: 53.12%] [G loss: 0.761711]\n",
      "epoch:28 step:21896 [D loss: 0.693818, acc.: 50.78%] [G loss: 0.770294]\n",
      "epoch:28 step:21897 [D loss: 0.695267, acc.: 53.91%] [G loss: 0.873851]\n",
      "epoch:28 step:21898 [D loss: 0.690682, acc.: 51.56%] [G loss: 0.804460]\n",
      "epoch:28 step:21899 [D loss: 0.727540, acc.: 44.53%] [G loss: 0.742862]\n",
      "epoch:28 step:21900 [D loss: 0.693743, acc.: 56.25%] [G loss: 0.795332]\n",
      "epoch:28 step:21901 [D loss: 0.689611, acc.: 51.56%] [G loss: 0.783619]\n",
      "epoch:28 step:21902 [D loss: 0.706019, acc.: 53.91%] [G loss: 0.803121]\n",
      "epoch:28 step:21903 [D loss: 0.720936, acc.: 46.09%] [G loss: 0.781198]\n",
      "epoch:28 step:21904 [D loss: 0.739922, acc.: 43.75%] [G loss: 0.756608]\n",
      "epoch:28 step:21905 [D loss: 0.703170, acc.: 53.91%] [G loss: 0.818549]\n",
      "epoch:28 step:21906 [D loss: 0.708764, acc.: 50.00%] [G loss: 0.692769]\n",
      "epoch:28 step:21907 [D loss: 0.690526, acc.: 53.12%] [G loss: 0.756535]\n",
      "epoch:28 step:21908 [D loss: 0.708011, acc.: 46.88%] [G loss: 0.663883]\n",
      "epoch:28 step:21909 [D loss: 0.658602, acc.: 60.94%] [G loss: 0.746347]\n",
      "epoch:28 step:21910 [D loss: 0.706419, acc.: 50.78%] [G loss: 0.729732]\n",
      "epoch:28 step:21911 [D loss: 0.696615, acc.: 53.91%] [G loss: 0.707023]\n",
      "epoch:28 step:21912 [D loss: 0.712728, acc.: 53.12%] [G loss: 0.704343]\n",
      "epoch:28 step:21913 [D loss: 0.673879, acc.: 56.25%] [G loss: 0.692666]\n",
      "epoch:28 step:21914 [D loss: 0.651025, acc.: 67.19%] [G loss: 0.761871]\n",
      "epoch:28 step:21915 [D loss: 0.675764, acc.: 53.91%] [G loss: 0.742153]\n",
      "epoch:28 step:21916 [D loss: 0.698277, acc.: 54.69%] [G loss: 0.713198]\n",
      "epoch:28 step:21917 [D loss: 0.714317, acc.: 53.12%] [G loss: 0.726683]\n",
      "epoch:28 step:21918 [D loss: 0.713297, acc.: 49.22%] [G loss: 0.791458]\n",
      "epoch:28 step:21919 [D loss: 0.660912, acc.: 60.94%] [G loss: 0.728857]\n",
      "epoch:28 step:21920 [D loss: 0.631839, acc.: 72.66%] [G loss: 0.813406]\n",
      "epoch:28 step:21921 [D loss: 0.683255, acc.: 60.16%] [G loss: 0.747027]\n",
      "epoch:28 step:21922 [D loss: 0.707795, acc.: 45.31%] [G loss: 0.790405]\n",
      "epoch:28 step:21923 [D loss: 0.694150, acc.: 48.44%] [G loss: 0.685839]\n",
      "epoch:28 step:21924 [D loss: 0.622239, acc.: 75.78%] [G loss: 0.790509]\n",
      "epoch:28 step:21925 [D loss: 0.654469, acc.: 64.06%] [G loss: 0.740484]\n",
      "epoch:28 step:21926 [D loss: 0.696246, acc.: 50.00%] [G loss: 0.780240]\n",
      "epoch:28 step:21927 [D loss: 0.696981, acc.: 52.34%] [G loss: 0.779770]\n",
      "epoch:28 step:21928 [D loss: 0.660021, acc.: 54.69%] [G loss: 0.861807]\n",
      "epoch:28 step:21929 [D loss: 0.667479, acc.: 62.50%] [G loss: 0.777906]\n",
      "epoch:28 step:21930 [D loss: 0.674825, acc.: 58.59%] [G loss: 0.780907]\n",
      "epoch:28 step:21931 [D loss: 0.703458, acc.: 54.69%] [G loss: 0.841800]\n",
      "epoch:28 step:21932 [D loss: 0.652235, acc.: 68.75%] [G loss: 0.799346]\n",
      "epoch:28 step:21933 [D loss: 0.715368, acc.: 43.75%] [G loss: 0.732910]\n",
      "epoch:28 step:21934 [D loss: 0.707664, acc.: 46.88%] [G loss: 0.822194]\n",
      "epoch:28 step:21935 [D loss: 0.681106, acc.: 54.69%] [G loss: 0.792590]\n",
      "epoch:28 step:21936 [D loss: 0.664049, acc.: 60.94%] [G loss: 0.742945]\n",
      "epoch:28 step:21937 [D loss: 0.742320, acc.: 35.94%] [G loss: 0.754132]\n",
      "epoch:28 step:21938 [D loss: 0.758710, acc.: 39.06%] [G loss: 0.673114]\n",
      "epoch:28 step:21939 [D loss: 0.692628, acc.: 52.34%] [G loss: 0.664804]\n",
      "epoch:28 step:21940 [D loss: 0.705660, acc.: 46.88%] [G loss: 0.693776]\n",
      "epoch:28 step:21941 [D loss: 0.643456, acc.: 63.28%] [G loss: 0.732006]\n",
      "epoch:28 step:21942 [D loss: 0.618918, acc.: 65.62%] [G loss: 0.788880]\n",
      "epoch:28 step:21943 [D loss: 0.651755, acc.: 53.91%] [G loss: 0.700124]\n",
      "epoch:28 step:21944 [D loss: 0.691721, acc.: 53.91%] [G loss: 0.670939]\n",
      "epoch:28 step:21945 [D loss: 0.664490, acc.: 58.59%] [G loss: 0.759816]\n",
      "epoch:28 step:21946 [D loss: 0.665122, acc.: 62.50%] [G loss: 0.750391]\n",
      "epoch:28 step:21947 [D loss: 0.629917, acc.: 66.41%] [G loss: 0.841835]\n",
      "epoch:28 step:21948 [D loss: 0.660976, acc.: 60.16%] [G loss: 0.786798]\n",
      "epoch:28 step:21949 [D loss: 0.689376, acc.: 53.91%] [G loss: 0.869819]\n",
      "epoch:28 step:21950 [D loss: 0.647982, acc.: 64.06%] [G loss: 0.797391]\n",
      "epoch:28 step:21951 [D loss: 0.679479, acc.: 57.81%] [G loss: 0.757824]\n",
      "epoch:28 step:21952 [D loss: 0.682329, acc.: 55.47%] [G loss: 0.860613]\n",
      "epoch:28 step:21953 [D loss: 0.722870, acc.: 45.31%] [G loss: 0.726926]\n",
      "epoch:28 step:21954 [D loss: 0.645238, acc.: 67.19%] [G loss: 0.779388]\n",
      "epoch:28 step:21955 [D loss: 0.688734, acc.: 52.34%] [G loss: 0.771405]\n",
      "epoch:28 step:21956 [D loss: 0.674556, acc.: 57.81%] [G loss: 0.763822]\n",
      "epoch:28 step:21957 [D loss: 0.658288, acc.: 64.84%] [G loss: 0.730249]\n",
      "epoch:28 step:21958 [D loss: 0.711673, acc.: 46.88%] [G loss: 0.712858]\n",
      "epoch:28 step:21959 [D loss: 0.666872, acc.: 63.28%] [G loss: 0.734354]\n",
      "epoch:28 step:21960 [D loss: 0.677061, acc.: 57.03%] [G loss: 0.700399]\n",
      "epoch:28 step:21961 [D loss: 0.650831, acc.: 63.28%] [G loss: 0.711798]\n",
      "epoch:28 step:21962 [D loss: 0.642784, acc.: 70.31%] [G loss: 0.789040]\n",
      "epoch:28 step:21963 [D loss: 0.718469, acc.: 46.09%] [G loss: 0.816644]\n",
      "epoch:28 step:21964 [D loss: 0.710339, acc.: 46.88%] [G loss: 0.871392]\n",
      "epoch:28 step:21965 [D loss: 0.673447, acc.: 59.38%] [G loss: 0.800170]\n",
      "epoch:28 step:21966 [D loss: 0.694066, acc.: 50.78%] [G loss: 0.862044]\n",
      "epoch:28 step:21967 [D loss: 0.685992, acc.: 57.81%] [G loss: 0.758436]\n",
      "epoch:28 step:21968 [D loss: 0.723352, acc.: 43.75%] [G loss: 0.772725]\n",
      "epoch:28 step:21969 [D loss: 0.714702, acc.: 45.31%] [G loss: 0.796594]\n",
      "epoch:28 step:21970 [D loss: 0.701166, acc.: 50.78%] [G loss: 0.748202]\n",
      "epoch:28 step:21971 [D loss: 0.697536, acc.: 50.00%] [G loss: 0.776112]\n",
      "epoch:28 step:21972 [D loss: 0.710525, acc.: 46.88%] [G loss: 0.780819]\n",
      "epoch:28 step:21973 [D loss: 0.723356, acc.: 39.06%] [G loss: 0.712710]\n",
      "epoch:28 step:21974 [D loss: 0.674797, acc.: 53.12%] [G loss: 0.768023]\n",
      "epoch:28 step:21975 [D loss: 0.714022, acc.: 47.66%] [G loss: 0.762647]\n",
      "epoch:28 step:21976 [D loss: 0.750238, acc.: 40.62%] [G loss: 0.749941]\n",
      "epoch:28 step:21977 [D loss: 0.709386, acc.: 49.22%] [G loss: 0.772140]\n",
      "epoch:28 step:21978 [D loss: 0.688709, acc.: 50.78%] [G loss: 0.738404]\n",
      "epoch:28 step:21979 [D loss: 0.681113, acc.: 55.47%] [G loss: 0.718323]\n",
      "epoch:28 step:21980 [D loss: 0.681137, acc.: 63.28%] [G loss: 0.779467]\n",
      "epoch:28 step:21981 [D loss: 0.676496, acc.: 59.38%] [G loss: 0.740128]\n",
      "epoch:28 step:21982 [D loss: 0.671351, acc.: 60.16%] [G loss: 0.767226]\n",
      "epoch:28 step:21983 [D loss: 0.630843, acc.: 71.09%] [G loss: 0.790101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21984 [D loss: 0.693684, acc.: 51.56%] [G loss: 0.754666]\n",
      "epoch:28 step:21985 [D loss: 0.679686, acc.: 53.12%] [G loss: 0.794637]\n",
      "epoch:28 step:21986 [D loss: 0.635469, acc.: 68.75%] [G loss: 0.785557]\n",
      "epoch:28 step:21987 [D loss: 0.682941, acc.: 59.38%] [G loss: 0.789769]\n",
      "epoch:28 step:21988 [D loss: 0.659523, acc.: 65.62%] [G loss: 0.785806]\n",
      "epoch:28 step:21989 [D loss: 0.655078, acc.: 64.06%] [G loss: 0.843131]\n",
      "epoch:28 step:21990 [D loss: 0.676959, acc.: 60.94%] [G loss: 0.744258]\n",
      "epoch:28 step:21991 [D loss: 0.698523, acc.: 50.78%] [G loss: 0.739091]\n",
      "epoch:28 step:21992 [D loss: 0.717060, acc.: 52.34%] [G loss: 0.699396]\n",
      "epoch:28 step:21993 [D loss: 0.727765, acc.: 43.75%] [G loss: 0.728953]\n",
      "epoch:28 step:21994 [D loss: 0.763250, acc.: 33.59%] [G loss: 0.669422]\n",
      "epoch:28 step:21995 [D loss: 0.741658, acc.: 48.44%] [G loss: 0.684893]\n",
      "epoch:28 step:21996 [D loss: 0.699143, acc.: 47.66%] [G loss: 0.675080]\n",
      "epoch:28 step:21997 [D loss: 0.710884, acc.: 52.34%] [G loss: 0.674611]\n",
      "epoch:28 step:21998 [D loss: 0.676496, acc.: 57.81%] [G loss: 0.750719]\n",
      "epoch:28 step:21999 [D loss: 0.651458, acc.: 60.94%] [G loss: 0.782385]\n",
      "epoch:28 step:22000 [D loss: 0.632985, acc.: 70.31%] [G loss: 0.760725]\n",
      "epoch:28 step:22001 [D loss: 0.636250, acc.: 69.53%] [G loss: 0.721735]\n",
      "epoch:28 step:22002 [D loss: 0.704911, acc.: 44.53%] [G loss: 0.772646]\n",
      "epoch:28 step:22003 [D loss: 0.712404, acc.: 47.66%] [G loss: 0.783334]\n",
      "epoch:28 step:22004 [D loss: 0.683654, acc.: 53.91%] [G loss: 0.715751]\n",
      "epoch:28 step:22005 [D loss: 0.707237, acc.: 48.44%] [G loss: 0.725520]\n",
      "epoch:28 step:22006 [D loss: 0.665162, acc.: 62.50%] [G loss: 0.794611]\n",
      "epoch:28 step:22007 [D loss: 0.711986, acc.: 51.56%] [G loss: 0.769462]\n",
      "epoch:28 step:22008 [D loss: 0.682720, acc.: 63.28%] [G loss: 0.803874]\n",
      "epoch:28 step:22009 [D loss: 0.681832, acc.: 56.25%] [G loss: 0.852657]\n",
      "epoch:28 step:22010 [D loss: 0.694754, acc.: 50.00%] [G loss: 0.765508]\n",
      "epoch:28 step:22011 [D loss: 0.692946, acc.: 53.12%] [G loss: 0.886030]\n",
      "epoch:28 step:22012 [D loss: 0.706140, acc.: 48.44%] [G loss: 0.797752]\n",
      "epoch:28 step:22013 [D loss: 0.663177, acc.: 52.34%] [G loss: 0.724521]\n",
      "epoch:28 step:22014 [D loss: 0.658507, acc.: 61.72%] [G loss: 0.771011]\n",
      "epoch:28 step:22015 [D loss: 0.665190, acc.: 56.25%] [G loss: 0.803196]\n",
      "epoch:28 step:22016 [D loss: 0.640634, acc.: 65.62%] [G loss: 0.749530]\n",
      "epoch:28 step:22017 [D loss: 0.645795, acc.: 65.62%] [G loss: 0.809933]\n",
      "epoch:28 step:22018 [D loss: 0.694049, acc.: 55.47%] [G loss: 0.764287]\n",
      "epoch:28 step:22019 [D loss: 0.673616, acc.: 60.16%] [G loss: 0.769340]\n",
      "epoch:28 step:22020 [D loss: 0.670190, acc.: 60.94%] [G loss: 0.748699]\n",
      "epoch:28 step:22021 [D loss: 0.704863, acc.: 51.56%] [G loss: 0.751627]\n",
      "epoch:28 step:22022 [D loss: 0.678484, acc.: 60.16%] [G loss: 0.814689]\n",
      "epoch:28 step:22023 [D loss: 0.652385, acc.: 66.41%] [G loss: 0.757639]\n",
      "epoch:28 step:22024 [D loss: 0.678946, acc.: 58.59%] [G loss: 0.748868]\n",
      "epoch:28 step:22025 [D loss: 0.739593, acc.: 41.41%] [G loss: 0.781526]\n",
      "epoch:28 step:22026 [D loss: 0.694977, acc.: 54.69%] [G loss: 0.824877]\n",
      "epoch:28 step:22027 [D loss: 0.608380, acc.: 74.22%] [G loss: 0.725244]\n",
      "epoch:28 step:22028 [D loss: 0.629878, acc.: 67.19%] [G loss: 0.675476]\n",
      "epoch:28 step:22029 [D loss: 0.702990, acc.: 47.66%] [G loss: 0.632572]\n",
      "epoch:28 step:22030 [D loss: 0.690085, acc.: 50.78%] [G loss: 0.689700]\n",
      "epoch:28 step:22031 [D loss: 0.678808, acc.: 54.69%] [G loss: 0.757825]\n",
      "epoch:28 step:22032 [D loss: 0.682734, acc.: 63.28%] [G loss: 0.801209]\n",
      "epoch:28 step:22033 [D loss: 0.664501, acc.: 57.81%] [G loss: 0.755555]\n",
      "epoch:28 step:22034 [D loss: 0.736970, acc.: 44.53%] [G loss: 0.735749]\n",
      "epoch:28 step:22035 [D loss: 0.722031, acc.: 48.44%] [G loss: 0.739409]\n",
      "epoch:28 step:22036 [D loss: 0.677280, acc.: 57.81%] [G loss: 0.766027]\n",
      "epoch:28 step:22037 [D loss: 0.719076, acc.: 48.44%] [G loss: 0.760657]\n",
      "epoch:28 step:22038 [D loss: 0.673997, acc.: 53.12%] [G loss: 0.848995]\n",
      "epoch:28 step:22039 [D loss: 0.695823, acc.: 54.69%] [G loss: 0.760782]\n",
      "epoch:28 step:22040 [D loss: 0.697284, acc.: 51.56%] [G loss: 0.783241]\n",
      "epoch:28 step:22041 [D loss: 0.662267, acc.: 60.94%] [G loss: 0.742762]\n",
      "epoch:28 step:22042 [D loss: 0.720360, acc.: 46.09%] [G loss: 0.755055]\n",
      "epoch:28 step:22043 [D loss: 0.730335, acc.: 46.09%] [G loss: 0.718547]\n",
      "epoch:28 step:22044 [D loss: 0.658251, acc.: 62.50%] [G loss: 0.745503]\n",
      "epoch:28 step:22045 [D loss: 0.709043, acc.: 51.56%] [G loss: 0.756365]\n",
      "epoch:28 step:22046 [D loss: 0.685914, acc.: 50.00%] [G loss: 0.781068]\n",
      "epoch:28 step:22047 [D loss: 0.652674, acc.: 66.41%] [G loss: 0.797314]\n",
      "epoch:28 step:22048 [D loss: 0.636770, acc.: 67.19%] [G loss: 0.817169]\n",
      "epoch:28 step:22049 [D loss: 0.686685, acc.: 55.47%] [G loss: 0.710276]\n",
      "epoch:28 step:22050 [D loss: 0.749611, acc.: 39.84%] [G loss: 0.740750]\n",
      "epoch:28 step:22051 [D loss: 0.655081, acc.: 64.84%] [G loss: 0.799238]\n",
      "epoch:28 step:22052 [D loss: 0.645691, acc.: 64.84%] [G loss: 0.764559]\n",
      "epoch:28 step:22053 [D loss: 0.691088, acc.: 50.78%] [G loss: 0.791001]\n",
      "epoch:28 step:22054 [D loss: 0.725821, acc.: 40.62%] [G loss: 0.716973]\n",
      "epoch:28 step:22055 [D loss: 0.673658, acc.: 60.94%] [G loss: 0.752634]\n",
      "epoch:28 step:22056 [D loss: 0.750672, acc.: 33.59%] [G loss: 0.740644]\n",
      "epoch:28 step:22057 [D loss: 0.675107, acc.: 59.38%] [G loss: 0.762637]\n",
      "epoch:28 step:22058 [D loss: 0.691401, acc.: 53.12%] [G loss: 0.785347]\n",
      "epoch:28 step:22059 [D loss: 0.711423, acc.: 48.44%] [G loss: 0.705769]\n",
      "epoch:28 step:22060 [D loss: 0.721674, acc.: 39.84%] [G loss: 0.758496]\n",
      "epoch:28 step:22061 [D loss: 0.719677, acc.: 45.31%] [G loss: 0.696482]\n",
      "epoch:28 step:22062 [D loss: 0.690384, acc.: 53.91%] [G loss: 0.735512]\n",
      "epoch:28 step:22063 [D loss: 0.710231, acc.: 43.75%] [G loss: 0.763809]\n",
      "epoch:28 step:22064 [D loss: 0.657787, acc.: 58.59%] [G loss: 0.815596]\n",
      "epoch:28 step:22065 [D loss: 0.713990, acc.: 51.56%] [G loss: 0.748979]\n",
      "epoch:28 step:22066 [D loss: 0.701900, acc.: 50.78%] [G loss: 0.706802]\n",
      "epoch:28 step:22067 [D loss: 0.675625, acc.: 59.38%] [G loss: 0.726804]\n",
      "epoch:28 step:22068 [D loss: 0.707859, acc.: 53.12%] [G loss: 0.745311]\n",
      "epoch:28 step:22069 [D loss: 0.620426, acc.: 67.19%] [G loss: 0.781561]\n",
      "epoch:28 step:22070 [D loss: 0.736224, acc.: 40.62%] [G loss: 0.779068]\n",
      "epoch:28 step:22071 [D loss: 0.656084, acc.: 59.38%] [G loss: 0.826124]\n",
      "epoch:28 step:22072 [D loss: 0.645140, acc.: 59.38%] [G loss: 0.805309]\n",
      "epoch:28 step:22073 [D loss: 0.747988, acc.: 42.19%] [G loss: 0.800103]\n",
      "epoch:28 step:22074 [D loss: 0.686357, acc.: 59.38%] [G loss: 0.768627]\n",
      "epoch:28 step:22075 [D loss: 0.607008, acc.: 77.34%] [G loss: 0.737035]\n",
      "epoch:28 step:22076 [D loss: 0.687934, acc.: 56.25%] [G loss: 0.740131]\n",
      "epoch:28 step:22077 [D loss: 0.680396, acc.: 60.16%] [G loss: 0.778757]\n",
      "epoch:28 step:22078 [D loss: 0.689922, acc.: 54.69%] [G loss: 0.831340]\n",
      "epoch:28 step:22079 [D loss: 0.675493, acc.: 58.59%] [G loss: 0.760937]\n",
      "epoch:28 step:22080 [D loss: 0.687402, acc.: 57.03%] [G loss: 0.857552]\n",
      "epoch:28 step:22081 [D loss: 0.696398, acc.: 51.56%] [G loss: 0.762944]\n",
      "epoch:28 step:22082 [D loss: 0.675769, acc.: 57.03%] [G loss: 0.878019]\n",
      "epoch:28 step:22083 [D loss: 0.682330, acc.: 57.03%] [G loss: 0.728750]\n",
      "epoch:28 step:22084 [D loss: 0.705111, acc.: 41.41%] [G loss: 0.764688]\n",
      "epoch:28 step:22085 [D loss: 0.655294, acc.: 65.62%] [G loss: 0.772538]\n",
      "epoch:28 step:22086 [D loss: 0.671066, acc.: 62.50%] [G loss: 0.700455]\n",
      "epoch:28 step:22087 [D loss: 0.678555, acc.: 56.25%] [G loss: 0.776824]\n",
      "epoch:28 step:22088 [D loss: 0.701911, acc.: 50.78%] [G loss: 0.754850]\n",
      "epoch:28 step:22089 [D loss: 0.704869, acc.: 46.09%] [G loss: 0.737741]\n",
      "epoch:28 step:22090 [D loss: 0.690323, acc.: 55.47%] [G loss: 0.720223]\n",
      "epoch:28 step:22091 [D loss: 0.688238, acc.: 58.59%] [G loss: 0.689734]\n",
      "epoch:28 step:22092 [D loss: 0.701514, acc.: 54.69%] [G loss: 0.769695]\n",
      "epoch:28 step:22093 [D loss: 0.686339, acc.: 57.81%] [G loss: 0.748515]\n",
      "epoch:28 step:22094 [D loss: 0.696385, acc.: 53.91%] [G loss: 0.739434]\n",
      "epoch:28 step:22095 [D loss: 0.681360, acc.: 57.03%] [G loss: 0.770003]\n",
      "epoch:28 step:22096 [D loss: 0.707436, acc.: 51.56%] [G loss: 0.711962]\n",
      "epoch:28 step:22097 [D loss: 0.703813, acc.: 50.78%] [G loss: 0.785180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22098 [D loss: 0.760845, acc.: 37.50%] [G loss: 0.753965]\n",
      "epoch:28 step:22099 [D loss: 0.670542, acc.: 57.81%] [G loss: 0.781086]\n",
      "epoch:28 step:22100 [D loss: 0.782833, acc.: 33.59%] [G loss: 0.713914]\n",
      "epoch:28 step:22101 [D loss: 0.667768, acc.: 63.28%] [G loss: 0.793241]\n",
      "epoch:28 step:22102 [D loss: 0.747382, acc.: 44.53%] [G loss: 0.765325]\n",
      "epoch:28 step:22103 [D loss: 0.729645, acc.: 46.09%] [G loss: 0.725478]\n",
      "epoch:28 step:22104 [D loss: 0.681054, acc.: 52.34%] [G loss: 0.735552]\n",
      "epoch:28 step:22105 [D loss: 0.682898, acc.: 54.69%] [G loss: 0.723069]\n",
      "epoch:28 step:22106 [D loss: 0.715025, acc.: 48.44%] [G loss: 0.767874]\n",
      "epoch:28 step:22107 [D loss: 0.686365, acc.: 56.25%] [G loss: 0.822869]\n",
      "epoch:28 step:22108 [D loss: 0.687525, acc.: 49.22%] [G loss: 0.853219]\n",
      "epoch:28 step:22109 [D loss: 0.648010, acc.: 67.19%] [G loss: 0.821804]\n",
      "epoch:28 step:22110 [D loss: 0.685376, acc.: 57.81%] [G loss: 0.739477]\n",
      "epoch:28 step:22111 [D loss: 0.669862, acc.: 59.38%] [G loss: 0.724245]\n",
      "epoch:28 step:22112 [D loss: 0.656705, acc.: 64.06%] [G loss: 0.776618]\n",
      "epoch:28 step:22113 [D loss: 0.714663, acc.: 47.66%] [G loss: 0.722460]\n",
      "epoch:28 step:22114 [D loss: 0.659681, acc.: 65.62%] [G loss: 0.680151]\n",
      "epoch:28 step:22115 [D loss: 0.661853, acc.: 64.84%] [G loss: 0.672625]\n",
      "epoch:28 step:22116 [D loss: 0.669743, acc.: 61.72%] [G loss: 0.798341]\n",
      "epoch:28 step:22117 [D loss: 0.764589, acc.: 35.94%] [G loss: 0.668775]\n",
      "epoch:28 step:22118 [D loss: 0.612063, acc.: 76.56%] [G loss: 0.766492]\n",
      "epoch:28 step:22119 [D loss: 0.690611, acc.: 53.91%] [G loss: 0.768632]\n",
      "epoch:28 step:22120 [D loss: 0.625615, acc.: 70.31%] [G loss: 0.709847]\n",
      "epoch:28 step:22121 [D loss: 0.752790, acc.: 34.38%] [G loss: 0.724407]\n",
      "epoch:28 step:22122 [D loss: 0.690339, acc.: 55.47%] [G loss: 0.859075]\n",
      "epoch:28 step:22123 [D loss: 0.712665, acc.: 49.22%] [G loss: 0.759291]\n",
      "epoch:28 step:22124 [D loss: 0.716478, acc.: 48.44%] [G loss: 0.736834]\n",
      "epoch:28 step:22125 [D loss: 0.701090, acc.: 53.12%] [G loss: 0.699295]\n",
      "epoch:28 step:22126 [D loss: 0.694513, acc.: 51.56%] [G loss: 0.852575]\n",
      "epoch:28 step:22127 [D loss: 0.708094, acc.: 54.69%] [G loss: 0.749770]\n",
      "epoch:28 step:22128 [D loss: 0.661042, acc.: 57.81%] [G loss: 0.827284]\n",
      "epoch:28 step:22129 [D loss: 0.675669, acc.: 53.91%] [G loss: 0.809201]\n",
      "epoch:28 step:22130 [D loss: 0.671164, acc.: 50.78%] [G loss: 0.796653]\n",
      "epoch:28 step:22131 [D loss: 0.646802, acc.: 64.84%] [G loss: 0.714419]\n",
      "epoch:28 step:22132 [D loss: 0.724734, acc.: 44.53%] [G loss: 0.730697]\n",
      "epoch:28 step:22133 [D loss: 0.683994, acc.: 53.12%] [G loss: 0.726978]\n",
      "epoch:28 step:22134 [D loss: 0.676958, acc.: 60.94%] [G loss: 0.835822]\n",
      "epoch:28 step:22135 [D loss: 0.757235, acc.: 42.19%] [G loss: 0.822373]\n",
      "epoch:28 step:22136 [D loss: 0.666398, acc.: 59.38%] [G loss: 0.753914]\n",
      "epoch:28 step:22137 [D loss: 0.680493, acc.: 52.34%] [G loss: 0.755804]\n",
      "epoch:28 step:22138 [D loss: 0.667456, acc.: 63.28%] [G loss: 0.729373]\n",
      "epoch:28 step:22139 [D loss: 0.717136, acc.: 47.66%] [G loss: 0.807458]\n",
      "epoch:28 step:22140 [D loss: 0.659142, acc.: 60.16%] [G loss: 0.762090]\n",
      "epoch:28 step:22141 [D loss: 0.694565, acc.: 43.75%] [G loss: 0.743185]\n",
      "epoch:28 step:22142 [D loss: 0.689181, acc.: 53.91%] [G loss: 0.797505]\n",
      "epoch:28 step:22143 [D loss: 0.662284, acc.: 58.59%] [G loss: 0.755809]\n",
      "epoch:28 step:22144 [D loss: 0.658746, acc.: 67.19%] [G loss: 0.757342]\n",
      "epoch:28 step:22145 [D loss: 0.723484, acc.: 43.75%] [G loss: 0.763700]\n",
      "epoch:28 step:22146 [D loss: 0.603591, acc.: 77.34%] [G loss: 0.799119]\n",
      "epoch:28 step:22147 [D loss: 0.618229, acc.: 67.97%] [G loss: 0.773939]\n",
      "epoch:28 step:22148 [D loss: 0.696727, acc.: 50.78%] [G loss: 0.706170]\n",
      "epoch:28 step:22149 [D loss: 0.695484, acc.: 55.47%] [G loss: 0.799449]\n",
      "epoch:28 step:22150 [D loss: 0.719425, acc.: 47.66%] [G loss: 0.719222]\n",
      "epoch:28 step:22151 [D loss: 0.622852, acc.: 69.53%] [G loss: 0.777587]\n",
      "epoch:28 step:22152 [D loss: 0.663869, acc.: 59.38%] [G loss: 0.755059]\n",
      "epoch:28 step:22153 [D loss: 0.688869, acc.: 55.47%] [G loss: 0.724606]\n",
      "epoch:28 step:22154 [D loss: 0.653400, acc.: 64.06%] [G loss: 0.794173]\n",
      "epoch:28 step:22155 [D loss: 0.750098, acc.: 40.62%] [G loss: 0.787159]\n",
      "epoch:28 step:22156 [D loss: 0.781669, acc.: 34.38%] [G loss: 0.743315]\n",
      "epoch:28 step:22157 [D loss: 0.714057, acc.: 47.66%] [G loss: 0.803348]\n",
      "epoch:28 step:22158 [D loss: 0.670242, acc.: 60.16%] [G loss: 0.798421]\n",
      "epoch:28 step:22159 [D loss: 0.768853, acc.: 30.47%] [G loss: 0.783471]\n",
      "epoch:28 step:22160 [D loss: 0.661697, acc.: 65.62%] [G loss: 0.797244]\n",
      "epoch:28 step:22161 [D loss: 0.665720, acc.: 59.38%] [G loss: 0.796849]\n",
      "epoch:28 step:22162 [D loss: 0.722361, acc.: 45.31%] [G loss: 0.753141]\n",
      "epoch:28 step:22163 [D loss: 0.711400, acc.: 51.56%] [G loss: 0.790619]\n",
      "epoch:28 step:22164 [D loss: 0.696503, acc.: 49.22%] [G loss: 0.761261]\n",
      "epoch:28 step:22165 [D loss: 0.662103, acc.: 59.38%] [G loss: 0.729315]\n",
      "epoch:28 step:22166 [D loss: 0.688843, acc.: 52.34%] [G loss: 0.825322]\n",
      "epoch:28 step:22167 [D loss: 0.619855, acc.: 71.09%] [G loss: 0.817167]\n",
      "epoch:28 step:22168 [D loss: 0.700608, acc.: 50.78%] [G loss: 0.781004]\n",
      "epoch:28 step:22169 [D loss: 0.704480, acc.: 50.78%] [G loss: 0.747180]\n",
      "epoch:28 step:22170 [D loss: 0.685279, acc.: 59.38%] [G loss: 0.763174]\n",
      "epoch:28 step:22171 [D loss: 0.687439, acc.: 58.59%] [G loss: 0.777168]\n",
      "epoch:28 step:22172 [D loss: 0.634272, acc.: 67.97%] [G loss: 0.786167]\n",
      "epoch:28 step:22173 [D loss: 0.685977, acc.: 57.03%] [G loss: 0.802015]\n",
      "epoch:28 step:22174 [D loss: 0.651716, acc.: 64.06%] [G loss: 0.677499]\n",
      "epoch:28 step:22175 [D loss: 0.707129, acc.: 57.03%] [G loss: 0.809564]\n",
      "epoch:28 step:22176 [D loss: 0.643723, acc.: 57.03%] [G loss: 0.765902]\n",
      "epoch:28 step:22177 [D loss: 0.642435, acc.: 67.19%] [G loss: 0.785839]\n",
      "epoch:28 step:22178 [D loss: 0.733621, acc.: 39.84%] [G loss: 0.722110]\n",
      "epoch:28 step:22179 [D loss: 0.683597, acc.: 59.38%] [G loss: 0.762531]\n",
      "epoch:28 step:22180 [D loss: 0.664680, acc.: 62.50%] [G loss: 0.765672]\n",
      "epoch:28 step:22181 [D loss: 0.657262, acc.: 69.53%] [G loss: 0.764587]\n",
      "epoch:28 step:22182 [D loss: 0.732138, acc.: 40.62%] [G loss: 0.715985]\n",
      "epoch:28 step:22183 [D loss: 0.678616, acc.: 58.59%] [G loss: 0.725145]\n",
      "epoch:28 step:22184 [D loss: 0.678793, acc.: 60.94%] [G loss: 0.713218]\n",
      "epoch:28 step:22185 [D loss: 0.721560, acc.: 45.31%] [G loss: 0.695509]\n",
      "epoch:28 step:22186 [D loss: 0.675994, acc.: 57.03%] [G loss: 0.724550]\n",
      "epoch:28 step:22187 [D loss: 0.749740, acc.: 37.50%] [G loss: 0.766181]\n",
      "epoch:28 step:22188 [D loss: 0.649780, acc.: 59.38%] [G loss: 0.798391]\n",
      "epoch:28 step:22189 [D loss: 0.704690, acc.: 57.03%] [G loss: 0.767306]\n",
      "epoch:28 step:22190 [D loss: 0.678469, acc.: 51.56%] [G loss: 0.776076]\n",
      "epoch:28 step:22191 [D loss: 0.722749, acc.: 43.75%] [G loss: 0.784170]\n",
      "epoch:28 step:22192 [D loss: 0.642323, acc.: 67.97%] [G loss: 0.751416]\n",
      "epoch:28 step:22193 [D loss: 0.685805, acc.: 54.69%] [G loss: 0.792963]\n",
      "epoch:28 step:22194 [D loss: 0.656624, acc.: 64.06%] [G loss: 0.802977]\n",
      "epoch:28 step:22195 [D loss: 0.702938, acc.: 53.12%] [G loss: 0.738060]\n",
      "epoch:28 step:22196 [D loss: 0.673753, acc.: 62.50%] [G loss: 0.806236]\n",
      "epoch:28 step:22197 [D loss: 0.652303, acc.: 62.50%] [G loss: 0.727670]\n",
      "epoch:28 step:22198 [D loss: 0.714238, acc.: 46.09%] [G loss: 0.697878]\n",
      "epoch:28 step:22199 [D loss: 0.682240, acc.: 56.25%] [G loss: 0.747978]\n",
      "epoch:28 step:22200 [D loss: 0.702649, acc.: 50.00%] [G loss: 0.725388]\n",
      "epoch:28 step:22201 [D loss: 0.655995, acc.: 64.06%] [G loss: 0.734768]\n",
      "epoch:28 step:22202 [D loss: 0.689975, acc.: 56.25%] [G loss: 0.788965]\n",
      "epoch:28 step:22203 [D loss: 0.659927, acc.: 62.50%] [G loss: 0.795693]\n",
      "epoch:28 step:22204 [D loss: 0.733738, acc.: 37.50%] [G loss: 0.692234]\n",
      "epoch:28 step:22205 [D loss: 0.705063, acc.: 53.91%] [G loss: 0.700883]\n",
      "epoch:28 step:22206 [D loss: 0.747739, acc.: 37.50%] [G loss: 0.725820]\n",
      "epoch:28 step:22207 [D loss: 0.749383, acc.: 43.75%] [G loss: 0.709239]\n",
      "epoch:28 step:22208 [D loss: 0.735192, acc.: 36.72%] [G loss: 0.629015]\n",
      "epoch:28 step:22209 [D loss: 0.667252, acc.: 60.16%] [G loss: 0.797395]\n",
      "epoch:28 step:22210 [D loss: 0.722635, acc.: 51.56%] [G loss: 0.822167]\n",
      "epoch:28 step:22211 [D loss: 0.724193, acc.: 48.44%] [G loss: 0.751164]\n",
      "epoch:28 step:22212 [D loss: 0.657215, acc.: 62.50%] [G loss: 0.825687]\n",
      "epoch:28 step:22213 [D loss: 0.700960, acc.: 53.12%] [G loss: 0.742671]\n",
      "epoch:28 step:22214 [D loss: 0.672156, acc.: 60.94%] [G loss: 0.816002]\n",
      "epoch:28 step:22215 [D loss: 0.734653, acc.: 44.53%] [G loss: 0.706541]\n",
      "epoch:28 step:22216 [D loss: 0.662883, acc.: 58.59%] [G loss: 0.785921]\n",
      "epoch:28 step:22217 [D loss: 0.652312, acc.: 67.19%] [G loss: 0.836519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22218 [D loss: 0.773993, acc.: 39.84%] [G loss: 0.753544]\n",
      "epoch:28 step:22219 [D loss: 0.704457, acc.: 47.66%] [G loss: 0.742901]\n",
      "epoch:28 step:22220 [D loss: 0.717318, acc.: 50.78%] [G loss: 0.843759]\n",
      "epoch:28 step:22221 [D loss: 0.624434, acc.: 71.09%] [G loss: 0.859096]\n",
      "epoch:28 step:22222 [D loss: 0.706757, acc.: 50.78%] [G loss: 0.784780]\n",
      "epoch:28 step:22223 [D loss: 0.671674, acc.: 60.16%] [G loss: 0.744944]\n",
      "epoch:28 step:22224 [D loss: 0.652105, acc.: 64.06%] [G loss: 0.806330]\n",
      "epoch:28 step:22225 [D loss: 0.642651, acc.: 65.62%] [G loss: 0.737234]\n",
      "epoch:28 step:22226 [D loss: 0.739901, acc.: 39.06%] [G loss: 0.765639]\n",
      "epoch:28 step:22227 [D loss: 0.728257, acc.: 40.62%] [G loss: 0.752907]\n",
      "epoch:28 step:22228 [D loss: 0.695598, acc.: 54.69%] [G loss: 0.777425]\n",
      "epoch:28 step:22229 [D loss: 0.688362, acc.: 55.47%] [G loss: 0.766865]\n",
      "epoch:28 step:22230 [D loss: 0.676389, acc.: 53.91%] [G loss: 0.766127]\n",
      "epoch:28 step:22231 [D loss: 0.727598, acc.: 47.66%] [G loss: 0.687881]\n",
      "epoch:28 step:22232 [D loss: 0.709174, acc.: 46.88%] [G loss: 0.691439]\n",
      "epoch:28 step:22233 [D loss: 0.648567, acc.: 64.84%] [G loss: 0.725597]\n",
      "epoch:28 step:22234 [D loss: 0.717533, acc.: 45.31%] [G loss: 0.694866]\n",
      "epoch:28 step:22235 [D loss: 0.691925, acc.: 57.81%] [G loss: 0.792753]\n",
      "epoch:28 step:22236 [D loss: 0.722709, acc.: 46.88%] [G loss: 0.735373]\n",
      "epoch:28 step:22237 [D loss: 0.692055, acc.: 51.56%] [G loss: 0.725665]\n",
      "epoch:28 step:22238 [D loss: 0.657276, acc.: 61.72%] [G loss: 0.729790]\n",
      "epoch:28 step:22239 [D loss: 0.708612, acc.: 53.91%] [G loss: 0.788470]\n",
      "epoch:28 step:22240 [D loss: 0.656640, acc.: 64.06%] [G loss: 0.711029]\n",
      "epoch:28 step:22241 [D loss: 0.675994, acc.: 52.34%] [G loss: 0.779531]\n",
      "epoch:28 step:22242 [D loss: 0.675512, acc.: 56.25%] [G loss: 0.783215]\n",
      "epoch:28 step:22243 [D loss: 0.669682, acc.: 62.50%] [G loss: 0.746455]\n",
      "epoch:28 step:22244 [D loss: 0.665479, acc.: 57.81%] [G loss: 0.740755]\n",
      "epoch:28 step:22245 [D loss: 0.708226, acc.: 51.56%] [G loss: 0.748729]\n",
      "epoch:28 step:22246 [D loss: 0.673887, acc.: 57.03%] [G loss: 0.715479]\n",
      "epoch:28 step:22247 [D loss: 0.661372, acc.: 66.41%] [G loss: 0.810559]\n",
      "epoch:28 step:22248 [D loss: 0.719612, acc.: 44.53%] [G loss: 0.756601]\n",
      "epoch:28 step:22249 [D loss: 0.653949, acc.: 61.72%] [G loss: 0.734781]\n",
      "epoch:28 step:22250 [D loss: 0.680010, acc.: 53.12%] [G loss: 0.755682]\n",
      "epoch:28 step:22251 [D loss: 0.700588, acc.: 48.44%] [G loss: 0.703103]\n",
      "epoch:28 step:22252 [D loss: 0.642428, acc.: 67.19%] [G loss: 0.762542]\n",
      "epoch:28 step:22253 [D loss: 0.715822, acc.: 44.53%] [G loss: 0.735968]\n",
      "epoch:28 step:22254 [D loss: 0.682928, acc.: 53.91%] [G loss: 0.798153]\n",
      "epoch:28 step:22255 [D loss: 0.703034, acc.: 52.34%] [G loss: 0.730626]\n",
      "epoch:28 step:22256 [D loss: 0.698219, acc.: 50.78%] [G loss: 0.774479]\n",
      "epoch:28 step:22257 [D loss: 0.671709, acc.: 59.38%] [G loss: 0.819858]\n",
      "epoch:28 step:22258 [D loss: 0.629817, acc.: 69.53%] [G loss: 0.751003]\n",
      "epoch:28 step:22259 [D loss: 0.788966, acc.: 35.16%] [G loss: 0.788137]\n",
      "epoch:28 step:22260 [D loss: 0.661122, acc.: 64.06%] [G loss: 0.725902]\n",
      "epoch:28 step:22261 [D loss: 0.694015, acc.: 54.69%] [G loss: 0.709825]\n",
      "epoch:28 step:22262 [D loss: 0.622419, acc.: 69.53%] [G loss: 0.694821]\n",
      "epoch:28 step:22263 [D loss: 0.716977, acc.: 42.19%] [G loss: 0.746097]\n",
      "epoch:28 step:22264 [D loss: 0.644695, acc.: 60.94%] [G loss: 0.758321]\n",
      "epoch:28 step:22265 [D loss: 0.695629, acc.: 52.34%] [G loss: 0.789124]\n",
      "epoch:28 step:22266 [D loss: 0.659900, acc.: 64.06%] [G loss: 0.738633]\n",
      "epoch:28 step:22267 [D loss: 0.680654, acc.: 55.47%] [G loss: 0.766140]\n",
      "epoch:28 step:22268 [D loss: 0.710319, acc.: 50.78%] [G loss: 0.737854]\n",
      "epoch:28 step:22269 [D loss: 0.642400, acc.: 64.06%] [G loss: 0.739052]\n",
      "epoch:28 step:22270 [D loss: 0.669648, acc.: 57.03%] [G loss: 0.768026]\n",
      "epoch:28 step:22271 [D loss: 0.690454, acc.: 58.59%] [G loss: 0.761004]\n",
      "epoch:28 step:22272 [D loss: 0.691265, acc.: 49.22%] [G loss: 0.763687]\n",
      "epoch:28 step:22273 [D loss: 0.739353, acc.: 41.41%] [G loss: 0.802431]\n",
      "epoch:28 step:22274 [D loss: 0.703723, acc.: 49.22%] [G loss: 0.685531]\n",
      "epoch:28 step:22275 [D loss: 0.675681, acc.: 60.16%] [G loss: 0.725053]\n",
      "epoch:28 step:22276 [D loss: 0.711048, acc.: 46.88%] [G loss: 0.818115]\n",
      "epoch:28 step:22277 [D loss: 0.723089, acc.: 39.06%] [G loss: 0.757058]\n",
      "epoch:28 step:22278 [D loss: 0.704785, acc.: 53.12%] [G loss: 0.750791]\n",
      "epoch:28 step:22279 [D loss: 0.720739, acc.: 46.88%] [G loss: 0.786221]\n",
      "epoch:28 step:22280 [D loss: 0.716049, acc.: 43.75%] [G loss: 0.742553]\n",
      "epoch:28 step:22281 [D loss: 0.717076, acc.: 42.97%] [G loss: 0.700979]\n",
      "epoch:28 step:22282 [D loss: 0.677655, acc.: 58.59%] [G loss: 0.701070]\n",
      "epoch:28 step:22283 [D loss: 0.671088, acc.: 62.50%] [G loss: 0.781030]\n",
      "epoch:28 step:22284 [D loss: 0.655364, acc.: 64.84%] [G loss: 0.782668]\n",
      "epoch:28 step:22285 [D loss: 0.716788, acc.: 48.44%] [G loss: 0.769354]\n",
      "epoch:28 step:22286 [D loss: 0.668806, acc.: 59.38%] [G loss: 0.767277]\n",
      "epoch:28 step:22287 [D loss: 0.690791, acc.: 53.12%] [G loss: 0.753163]\n",
      "epoch:28 step:22288 [D loss: 0.685323, acc.: 53.91%] [G loss: 0.739491]\n",
      "epoch:28 step:22289 [D loss: 0.681040, acc.: 55.47%] [G loss: 0.730068]\n",
      "epoch:28 step:22290 [D loss: 0.671890, acc.: 55.47%] [G loss: 0.763832]\n",
      "epoch:28 step:22291 [D loss: 0.744263, acc.: 39.84%] [G loss: 0.789568]\n",
      "epoch:28 step:22292 [D loss: 0.715619, acc.: 45.31%] [G loss: 0.758134]\n",
      "epoch:28 step:22293 [D loss: 0.609836, acc.: 77.34%] [G loss: 0.763433]\n",
      "epoch:28 step:22294 [D loss: 0.679189, acc.: 58.59%] [G loss: 0.805693]\n",
      "epoch:28 step:22295 [D loss: 0.712318, acc.: 50.78%] [G loss: 0.778677]\n",
      "epoch:28 step:22296 [D loss: 0.678356, acc.: 52.34%] [G loss: 0.759356]\n",
      "epoch:28 step:22297 [D loss: 0.700801, acc.: 50.00%] [G loss: 0.671342]\n",
      "epoch:28 step:22298 [D loss: 0.689563, acc.: 53.91%] [G loss: 0.724813]\n",
      "epoch:28 step:22299 [D loss: 0.723552, acc.: 41.41%] [G loss: 0.758214]\n",
      "epoch:28 step:22300 [D loss: 0.716956, acc.: 47.66%] [G loss: 0.708737]\n",
      "epoch:28 step:22301 [D loss: 0.696888, acc.: 53.12%] [G loss: 0.818652]\n",
      "epoch:28 step:22302 [D loss: 0.712258, acc.: 49.22%] [G loss: 0.742298]\n",
      "epoch:28 step:22303 [D loss: 0.724277, acc.: 40.62%] [G loss: 0.761305]\n",
      "epoch:28 step:22304 [D loss: 0.708752, acc.: 46.09%] [G loss: 0.784378]\n",
      "epoch:28 step:22305 [D loss: 0.728161, acc.: 48.44%] [G loss: 0.752214]\n",
      "epoch:28 step:22306 [D loss: 0.685041, acc.: 57.03%] [G loss: 0.750317]\n",
      "epoch:28 step:22307 [D loss: 0.658467, acc.: 62.50%] [G loss: 0.776535]\n",
      "epoch:28 step:22308 [D loss: 0.721062, acc.: 39.84%] [G loss: 0.793628]\n",
      "epoch:28 step:22309 [D loss: 0.716447, acc.: 46.09%] [G loss: 0.792296]\n",
      "epoch:28 step:22310 [D loss: 0.715395, acc.: 44.53%] [G loss: 0.782846]\n",
      "epoch:28 step:22311 [D loss: 0.714044, acc.: 47.66%] [G loss: 0.817389]\n",
      "epoch:28 step:22312 [D loss: 0.705411, acc.: 50.00%] [G loss: 0.719227]\n",
      "epoch:28 step:22313 [D loss: 0.699595, acc.: 53.91%] [G loss: 0.811390]\n",
      "epoch:28 step:22314 [D loss: 0.724144, acc.: 44.53%] [G loss: 0.770796]\n",
      "epoch:28 step:22315 [D loss: 0.722512, acc.: 45.31%] [G loss: 0.737910]\n",
      "epoch:28 step:22316 [D loss: 0.702524, acc.: 49.22%] [G loss: 0.742145]\n",
      "epoch:28 step:22317 [D loss: 0.667680, acc.: 55.47%] [G loss: 0.751125]\n",
      "epoch:28 step:22318 [D loss: 0.678992, acc.: 60.94%] [G loss: 0.843764]\n",
      "epoch:28 step:22319 [D loss: 0.700082, acc.: 53.12%] [G loss: 0.718245]\n",
      "epoch:28 step:22320 [D loss: 0.683070, acc.: 53.91%] [G loss: 0.794042]\n",
      "epoch:28 step:22321 [D loss: 0.734074, acc.: 43.75%] [G loss: 0.679691]\n",
      "epoch:28 step:22322 [D loss: 0.645332, acc.: 67.97%] [G loss: 0.747866]\n",
      "epoch:28 step:22323 [D loss: 0.706667, acc.: 52.34%] [G loss: 0.774527]\n",
      "epoch:28 step:22324 [D loss: 0.699657, acc.: 49.22%] [G loss: 0.696450]\n",
      "epoch:28 step:22325 [D loss: 0.675664, acc.: 60.94%] [G loss: 0.792817]\n",
      "epoch:28 step:22326 [D loss: 0.685843, acc.: 60.94%] [G loss: 0.794577]\n",
      "epoch:28 step:22327 [D loss: 0.767927, acc.: 31.25%] [G loss: 0.738544]\n",
      "epoch:28 step:22328 [D loss: 0.669312, acc.: 59.38%] [G loss: 0.713523]\n",
      "epoch:28 step:22329 [D loss: 0.675359, acc.: 51.56%] [G loss: 0.739843]\n",
      "epoch:28 step:22330 [D loss: 0.683058, acc.: 54.69%] [G loss: 0.759355]\n",
      "epoch:28 step:22331 [D loss: 0.669966, acc.: 57.81%] [G loss: 0.769138]\n",
      "epoch:28 step:22332 [D loss: 0.694911, acc.: 53.12%] [G loss: 0.759032]\n",
      "epoch:28 step:22333 [D loss: 0.692253, acc.: 51.56%] [G loss: 0.764122]\n",
      "epoch:28 step:22334 [D loss: 0.630940, acc.: 70.31%] [G loss: 0.820348]\n",
      "epoch:28 step:22335 [D loss: 0.684405, acc.: 56.25%] [G loss: 0.863496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22336 [D loss: 0.689220, acc.: 49.22%] [G loss: 0.811240]\n",
      "epoch:28 step:22337 [D loss: 0.681388, acc.: 56.25%] [G loss: 0.837271]\n",
      "epoch:28 step:22338 [D loss: 0.722661, acc.: 39.06%] [G loss: 0.720029]\n",
      "epoch:28 step:22339 [D loss: 0.689323, acc.: 55.47%] [G loss: 0.774376]\n",
      "epoch:28 step:22340 [D loss: 0.674528, acc.: 54.69%] [G loss: 0.755964]\n",
      "epoch:28 step:22341 [D loss: 0.734522, acc.: 47.66%] [G loss: 0.701115]\n",
      "epoch:28 step:22342 [D loss: 0.667455, acc.: 57.03%] [G loss: 0.718991]\n",
      "epoch:28 step:22343 [D loss: 0.705193, acc.: 50.78%] [G loss: 0.731289]\n",
      "epoch:28 step:22344 [D loss: 0.673246, acc.: 60.94%] [G loss: 0.751813]\n",
      "epoch:28 step:22345 [D loss: 0.711163, acc.: 49.22%] [G loss: 0.754748]\n",
      "epoch:28 step:22346 [D loss: 0.670875, acc.: 60.94%] [G loss: 0.799719]\n",
      "epoch:28 step:22347 [D loss: 0.695989, acc.: 50.00%] [G loss: 0.815505]\n",
      "epoch:28 step:22348 [D loss: 0.701201, acc.: 49.22%] [G loss: 0.794514]\n",
      "epoch:28 step:22349 [D loss: 0.718171, acc.: 48.44%] [G loss: 0.743495]\n",
      "epoch:28 step:22350 [D loss: 0.684721, acc.: 60.94%] [G loss: 0.751148]\n",
      "epoch:28 step:22351 [D loss: 0.727045, acc.: 42.19%] [G loss: 0.768622]\n",
      "epoch:28 step:22352 [D loss: 0.709072, acc.: 49.22%] [G loss: 0.759124]\n",
      "epoch:28 step:22353 [D loss: 0.636517, acc.: 71.88%] [G loss: 0.750857]\n",
      "epoch:28 step:22354 [D loss: 0.609282, acc.: 68.75%] [G loss: 0.835163]\n",
      "epoch:28 step:22355 [D loss: 0.736183, acc.: 42.19%] [G loss: 0.726161]\n",
      "epoch:28 step:22356 [D loss: 0.687038, acc.: 57.03%] [G loss: 0.761372]\n",
      "epoch:28 step:22357 [D loss: 0.664549, acc.: 62.50%] [G loss: 0.743693]\n",
      "epoch:28 step:22358 [D loss: 0.698296, acc.: 53.91%] [G loss: 0.726817]\n",
      "epoch:28 step:22359 [D loss: 0.701038, acc.: 50.00%] [G loss: 0.691241]\n",
      "epoch:28 step:22360 [D loss: 0.675616, acc.: 64.06%] [G loss: 0.789257]\n",
      "epoch:28 step:22361 [D loss: 0.687498, acc.: 52.34%] [G loss: 0.710837]\n",
      "epoch:28 step:22362 [D loss: 0.649666, acc.: 64.84%] [G loss: 0.718422]\n",
      "epoch:28 step:22363 [D loss: 0.666981, acc.: 57.03%] [G loss: 0.762966]\n",
      "epoch:28 step:22364 [D loss: 0.694594, acc.: 50.78%] [G loss: 0.838107]\n",
      "epoch:28 step:22365 [D loss: 0.692179, acc.: 50.00%] [G loss: 0.812996]\n",
      "epoch:28 step:22366 [D loss: 0.643128, acc.: 64.84%] [G loss: 0.755331]\n",
      "epoch:28 step:22367 [D loss: 0.645498, acc.: 63.28%] [G loss: 0.738400]\n",
      "epoch:28 step:22368 [D loss: 0.637069, acc.: 66.41%] [G loss: 0.707052]\n",
      "epoch:28 step:22369 [D loss: 0.667212, acc.: 59.38%] [G loss: 0.770181]\n",
      "epoch:28 step:22370 [D loss: 0.656143, acc.: 64.84%] [G loss: 0.799875]\n",
      "epoch:28 step:22371 [D loss: 0.668580, acc.: 60.94%] [G loss: 0.829490]\n",
      "epoch:28 step:22372 [D loss: 0.675674, acc.: 61.72%] [G loss: 0.795616]\n",
      "epoch:28 step:22373 [D loss: 0.676332, acc.: 62.50%] [G loss: 0.788664]\n",
      "epoch:28 step:22374 [D loss: 0.684004, acc.: 54.69%] [G loss: 0.847624]\n",
      "epoch:28 step:22375 [D loss: 0.665021, acc.: 57.03%] [G loss: 0.821224]\n",
      "epoch:28 step:22376 [D loss: 0.729734, acc.: 40.62%] [G loss: 0.784714]\n",
      "epoch:28 step:22377 [D loss: 0.690755, acc.: 50.78%] [G loss: 0.740431]\n",
      "epoch:28 step:22378 [D loss: 0.656031, acc.: 63.28%] [G loss: 0.799213]\n",
      "epoch:28 step:22379 [D loss: 0.646933, acc.: 64.84%] [G loss: 0.768806]\n",
      "epoch:28 step:22380 [D loss: 0.684582, acc.: 59.38%] [G loss: 0.742704]\n",
      "epoch:28 step:22381 [D loss: 0.757011, acc.: 41.41%] [G loss: 0.737644]\n",
      "epoch:28 step:22382 [D loss: 0.733521, acc.: 45.31%] [G loss: 0.676719]\n",
      "epoch:28 step:22383 [D loss: 0.645006, acc.: 64.84%] [G loss: 0.657515]\n",
      "epoch:28 step:22384 [D loss: 0.630870, acc.: 71.09%] [G loss: 0.745388]\n",
      "epoch:28 step:22385 [D loss: 0.698621, acc.: 50.78%] [G loss: 0.697839]\n",
      "epoch:28 step:22386 [D loss: 0.590085, acc.: 78.91%] [G loss: 0.735530]\n",
      "epoch:28 step:22387 [D loss: 0.628238, acc.: 72.66%] [G loss: 0.828380]\n",
      "epoch:28 step:22388 [D loss: 0.708942, acc.: 50.00%] [G loss: 0.718932]\n",
      "epoch:28 step:22389 [D loss: 0.641766, acc.: 71.09%] [G loss: 0.747348]\n",
      "epoch:28 step:22390 [D loss: 0.734002, acc.: 44.53%] [G loss: 0.691594]\n",
      "epoch:28 step:22391 [D loss: 0.688658, acc.: 52.34%] [G loss: 0.756672]\n",
      "epoch:28 step:22392 [D loss: 0.749695, acc.: 35.16%] [G loss: 0.766488]\n",
      "epoch:28 step:22393 [D loss: 0.644634, acc.: 71.09%] [G loss: 0.737411]\n",
      "epoch:28 step:22394 [D loss: 0.777782, acc.: 39.84%] [G loss: 0.708564]\n",
      "epoch:28 step:22395 [D loss: 0.655005, acc.: 62.50%] [G loss: 0.751199]\n",
      "epoch:28 step:22396 [D loss: 0.721094, acc.: 41.41%] [G loss: 0.711274]\n",
      "epoch:28 step:22397 [D loss: 0.700868, acc.: 49.22%] [G loss: 0.756478]\n",
      "epoch:28 step:22398 [D loss: 0.617121, acc.: 81.25%] [G loss: 0.706392]\n",
      "epoch:28 step:22399 [D loss: 0.660384, acc.: 64.84%] [G loss: 0.743288]\n",
      "epoch:28 step:22400 [D loss: 0.655400, acc.: 57.81%] [G loss: 0.794198]\n",
      "epoch:28 step:22401 [D loss: 0.623615, acc.: 67.19%] [G loss: 0.842284]\n",
      "epoch:28 step:22402 [D loss: 0.679688, acc.: 53.12%] [G loss: 0.832772]\n",
      "epoch:28 step:22403 [D loss: 0.654957, acc.: 60.16%] [G loss: 0.791090]\n",
      "epoch:28 step:22404 [D loss: 0.670696, acc.: 60.16%] [G loss: 0.833276]\n",
      "epoch:28 step:22405 [D loss: 0.728772, acc.: 46.09%] [G loss: 0.746210]\n",
      "epoch:28 step:22406 [D loss: 0.658652, acc.: 60.16%] [G loss: 0.710468]\n",
      "epoch:28 step:22407 [D loss: 0.676170, acc.: 57.81%] [G loss: 0.732868]\n",
      "epoch:28 step:22408 [D loss: 0.767853, acc.: 34.38%] [G loss: 0.656923]\n",
      "epoch:28 step:22409 [D loss: 0.715402, acc.: 53.12%] [G loss: 0.726484]\n",
      "epoch:28 step:22410 [D loss: 0.647963, acc.: 64.06%] [G loss: 0.755971]\n",
      "epoch:28 step:22411 [D loss: 0.724826, acc.: 44.53%] [G loss: 0.715029]\n",
      "epoch:28 step:22412 [D loss: 0.667548, acc.: 59.38%] [G loss: 0.759214]\n",
      "epoch:28 step:22413 [D loss: 0.637594, acc.: 70.31%] [G loss: 0.786126]\n",
      "epoch:28 step:22414 [D loss: 0.786393, acc.: 42.97%] [G loss: 0.776808]\n",
      "epoch:28 step:22415 [D loss: 0.674733, acc.: 59.38%] [G loss: 0.753386]\n",
      "epoch:28 step:22416 [D loss: 0.734252, acc.: 46.09%] [G loss: 0.791592]\n",
      "epoch:28 step:22417 [D loss: 0.678491, acc.: 57.81%] [G loss: 0.832216]\n",
      "epoch:28 step:22418 [D loss: 0.715450, acc.: 44.53%] [G loss: 0.829272]\n",
      "epoch:28 step:22419 [D loss: 0.678884, acc.: 54.69%] [G loss: 0.790898]\n",
      "epoch:28 step:22420 [D loss: 0.704918, acc.: 47.66%] [G loss: 0.732316]\n",
      "epoch:28 step:22421 [D loss: 0.668043, acc.: 61.72%] [G loss: 0.820024]\n",
      "epoch:28 step:22422 [D loss: 0.655696, acc.: 64.84%] [G loss: 0.795622]\n",
      "epoch:28 step:22423 [D loss: 0.668292, acc.: 58.59%] [G loss: 0.815922]\n",
      "epoch:28 step:22424 [D loss: 0.706655, acc.: 51.56%] [G loss: 0.837587]\n",
      "epoch:28 step:22425 [D loss: 0.691514, acc.: 53.91%] [G loss: 0.754157]\n",
      "epoch:28 step:22426 [D loss: 0.692972, acc.: 53.12%] [G loss: 0.775125]\n",
      "epoch:28 step:22427 [D loss: 0.655280, acc.: 60.94%] [G loss: 0.798573]\n",
      "epoch:28 step:22428 [D loss: 0.701701, acc.: 50.00%] [G loss: 0.800972]\n",
      "epoch:28 step:22429 [D loss: 0.676630, acc.: 57.03%] [G loss: 0.700536]\n",
      "epoch:28 step:22430 [D loss: 0.681580, acc.: 54.69%] [G loss: 0.796323]\n",
      "epoch:28 step:22431 [D loss: 0.659548, acc.: 67.19%] [G loss: 0.856014]\n",
      "epoch:28 step:22432 [D loss: 0.666540, acc.: 59.38%] [G loss: 0.749456]\n",
      "epoch:28 step:22433 [D loss: 0.708460, acc.: 44.53%] [G loss: 0.775428]\n",
      "epoch:28 step:22434 [D loss: 0.692667, acc.: 52.34%] [G loss: 0.736230]\n",
      "epoch:28 step:22435 [D loss: 0.686803, acc.: 50.78%] [G loss: 0.822907]\n",
      "epoch:28 step:22436 [D loss: 0.698721, acc.: 50.78%] [G loss: 0.730068]\n",
      "epoch:28 step:22437 [D loss: 0.667951, acc.: 59.38%] [G loss: 0.745958]\n",
      "epoch:28 step:22438 [D loss: 0.681083, acc.: 52.34%] [G loss: 0.751747]\n",
      "epoch:28 step:22439 [D loss: 0.663919, acc.: 62.50%] [G loss: 0.701206]\n",
      "epoch:28 step:22440 [D loss: 0.686877, acc.: 57.03%] [G loss: 0.727660]\n",
      "epoch:28 step:22441 [D loss: 0.771744, acc.: 35.94%] [G loss: 0.719867]\n",
      "epoch:28 step:22442 [D loss: 0.713720, acc.: 49.22%] [G loss: 0.723078]\n",
      "epoch:28 step:22443 [D loss: 0.653786, acc.: 65.62%] [G loss: 0.788156]\n",
      "epoch:28 step:22444 [D loss: 0.674975, acc.: 59.38%] [G loss: 0.767024]\n",
      "epoch:28 step:22445 [D loss: 0.691467, acc.: 46.88%] [G loss: 0.816919]\n",
      "epoch:28 step:22446 [D loss: 0.683105, acc.: 57.81%] [G loss: 0.735277]\n",
      "epoch:28 step:22447 [D loss: 0.657444, acc.: 66.41%] [G loss: 0.734043]\n",
      "epoch:28 step:22448 [D loss: 0.704156, acc.: 48.44%] [G loss: 0.767363]\n",
      "epoch:28 step:22449 [D loss: 0.704896, acc.: 52.34%] [G loss: 0.713348]\n",
      "epoch:28 step:22450 [D loss: 0.703752, acc.: 56.25%] [G loss: 0.748577]\n",
      "epoch:28 step:22451 [D loss: 0.641772, acc.: 64.84%] [G loss: 0.697395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22452 [D loss: 0.716282, acc.: 48.44%] [G loss: 0.749832]\n",
      "epoch:28 step:22453 [D loss: 0.643824, acc.: 62.50%] [G loss: 0.755214]\n",
      "epoch:28 step:22454 [D loss: 0.623765, acc.: 75.00%] [G loss: 0.723135]\n",
      "epoch:28 step:22455 [D loss: 0.634338, acc.: 68.75%] [G loss: 0.811782]\n",
      "epoch:28 step:22456 [D loss: 0.690351, acc.: 53.91%] [G loss: 0.803569]\n",
      "epoch:28 step:22457 [D loss: 0.658869, acc.: 61.72%] [G loss: 0.727565]\n",
      "epoch:28 step:22458 [D loss: 0.681547, acc.: 57.81%] [G loss: 0.765595]\n",
      "epoch:28 step:22459 [D loss: 0.680557, acc.: 55.47%] [G loss: 0.848995]\n",
      "epoch:28 step:22460 [D loss: 0.703817, acc.: 53.91%] [G loss: 0.797690]\n",
      "epoch:28 step:22461 [D loss: 0.722426, acc.: 45.31%] [G loss: 0.824219]\n",
      "epoch:28 step:22462 [D loss: 0.638785, acc.: 68.75%] [G loss: 0.797206]\n",
      "epoch:28 step:22463 [D loss: 0.650626, acc.: 68.75%] [G loss: 0.804563]\n",
      "epoch:28 step:22464 [D loss: 0.672591, acc.: 60.94%] [G loss: 0.715652]\n",
      "epoch:28 step:22465 [D loss: 0.668796, acc.: 61.72%] [G loss: 0.683131]\n",
      "epoch:28 step:22466 [D loss: 0.658725, acc.: 60.94%] [G loss: 0.793349]\n",
      "epoch:28 step:22467 [D loss: 0.720603, acc.: 48.44%] [G loss: 0.757027]\n",
      "epoch:28 step:22468 [D loss: 0.663527, acc.: 60.94%] [G loss: 0.795496]\n",
      "epoch:28 step:22469 [D loss: 0.702677, acc.: 53.12%] [G loss: 0.804122]\n",
      "epoch:28 step:22470 [D loss: 0.651664, acc.: 67.19%] [G loss: 0.732100]\n",
      "epoch:28 step:22471 [D loss: 0.759480, acc.: 33.59%] [G loss: 0.700061]\n",
      "epoch:28 step:22472 [D loss: 0.674280, acc.: 62.50%] [G loss: 0.729877]\n",
      "epoch:28 step:22473 [D loss: 0.705444, acc.: 50.78%] [G loss: 0.778596]\n",
      "epoch:28 step:22474 [D loss: 0.766538, acc.: 35.94%] [G loss: 0.679381]\n",
      "epoch:28 step:22475 [D loss: 0.662141, acc.: 60.94%] [G loss: 0.741813]\n",
      "epoch:28 step:22476 [D loss: 0.700692, acc.: 51.56%] [G loss: 0.708537]\n",
      "epoch:28 step:22477 [D loss: 0.697011, acc.: 53.12%] [G loss: 0.700292]\n",
      "epoch:28 step:22478 [D loss: 0.655785, acc.: 65.62%] [G loss: 0.806265]\n",
      "epoch:28 step:22479 [D loss: 0.712682, acc.: 50.00%] [G loss: 0.758259]\n",
      "epoch:28 step:22480 [D loss: 0.668283, acc.: 59.38%] [G loss: 0.789288]\n",
      "epoch:28 step:22481 [D loss: 0.833305, acc.: 26.56%] [G loss: 0.752237]\n",
      "epoch:28 step:22482 [D loss: 0.713009, acc.: 51.56%] [G loss: 0.757459]\n",
      "epoch:28 step:22483 [D loss: 0.687931, acc.: 55.47%] [G loss: 0.760700]\n",
      "epoch:28 step:22484 [D loss: 0.657667, acc.: 61.72%] [G loss: 0.730648]\n",
      "epoch:28 step:22485 [D loss: 0.707699, acc.: 47.66%] [G loss: 0.690109]\n",
      "epoch:28 step:22486 [D loss: 0.637797, acc.: 75.00%] [G loss: 0.749738]\n",
      "epoch:28 step:22487 [D loss: 0.678592, acc.: 52.34%] [G loss: 0.740836]\n",
      "epoch:28 step:22488 [D loss: 0.696155, acc.: 50.00%] [G loss: 0.763799]\n",
      "epoch:28 step:22489 [D loss: 0.683317, acc.: 55.47%] [G loss: 0.755362]\n",
      "epoch:28 step:22490 [D loss: 0.679620, acc.: 55.47%] [G loss: 0.776002]\n",
      "epoch:28 step:22491 [D loss: 0.699729, acc.: 50.78%] [G loss: 0.788468]\n",
      "epoch:28 step:22492 [D loss: 0.696033, acc.: 55.47%] [G loss: 0.806847]\n",
      "epoch:28 step:22493 [D loss: 0.711611, acc.: 50.00%] [G loss: 0.776015]\n",
      "epoch:28 step:22494 [D loss: 0.741688, acc.: 44.53%] [G loss: 0.755400]\n",
      "epoch:28 step:22495 [D loss: 0.723499, acc.: 39.06%] [G loss: 0.806900]\n",
      "epoch:28 step:22496 [D loss: 0.688963, acc.: 56.25%] [G loss: 0.913059]\n",
      "epoch:28 step:22497 [D loss: 0.688628, acc.: 52.34%] [G loss: 0.764617]\n",
      "epoch:28 step:22498 [D loss: 0.691447, acc.: 54.69%] [G loss: 0.857984]\n",
      "epoch:28 step:22499 [D loss: 0.774428, acc.: 30.47%] [G loss: 0.775324]\n",
      "epoch:28 step:22500 [D loss: 0.641919, acc.: 66.41%] [G loss: 0.782753]\n",
      "epoch:28 step:22501 [D loss: 0.745215, acc.: 42.19%] [G loss: 0.728734]\n",
      "epoch:28 step:22502 [D loss: 0.698270, acc.: 53.91%] [G loss: 0.704038]\n",
      "epoch:28 step:22503 [D loss: 0.682204, acc.: 54.69%] [G loss: 0.752060]\n",
      "epoch:28 step:22504 [D loss: 0.672625, acc.: 58.59%] [G loss: 0.786299]\n",
      "epoch:28 step:22505 [D loss: 0.667834, acc.: 56.25%] [G loss: 0.763677]\n",
      "epoch:28 step:22506 [D loss: 0.663312, acc.: 58.59%] [G loss: 0.724370]\n",
      "epoch:28 step:22507 [D loss: 0.667613, acc.: 57.03%] [G loss: 0.729362]\n",
      "epoch:28 step:22508 [D loss: 0.691848, acc.: 57.81%] [G loss: 0.773607]\n",
      "epoch:28 step:22509 [D loss: 0.714988, acc.: 46.88%] [G loss: 0.748087]\n",
      "epoch:28 step:22510 [D loss: 0.717743, acc.: 45.31%] [G loss: 0.807147]\n",
      "epoch:28 step:22511 [D loss: 0.755835, acc.: 38.28%] [G loss: 0.780735]\n",
      "epoch:28 step:22512 [D loss: 0.658900, acc.: 63.28%] [G loss: 0.722035]\n",
      "epoch:28 step:22513 [D loss: 0.751768, acc.: 37.50%] [G loss: 0.743431]\n",
      "epoch:28 step:22514 [D loss: 0.680488, acc.: 60.16%] [G loss: 0.766536]\n",
      "epoch:28 step:22515 [D loss: 0.689955, acc.: 57.03%] [G loss: 0.712703]\n",
      "epoch:28 step:22516 [D loss: 0.664593, acc.: 61.72%] [G loss: 0.791105]\n",
      "epoch:28 step:22517 [D loss: 0.711138, acc.: 48.44%] [G loss: 0.725588]\n",
      "epoch:28 step:22518 [D loss: 0.675512, acc.: 53.91%] [G loss: 0.711677]\n",
      "epoch:28 step:22519 [D loss: 0.663285, acc.: 59.38%] [G loss: 0.710403]\n",
      "epoch:28 step:22520 [D loss: 0.662807, acc.: 57.03%] [G loss: 0.692832]\n",
      "epoch:28 step:22521 [D loss: 0.694495, acc.: 54.69%] [G loss: 0.780703]\n",
      "epoch:28 step:22522 [D loss: 0.710140, acc.: 50.00%] [G loss: 0.749949]\n",
      "epoch:28 step:22523 [D loss: 0.735048, acc.: 38.28%] [G loss: 0.715993]\n",
      "epoch:28 step:22524 [D loss: 0.696747, acc.: 52.34%] [G loss: 0.721508]\n",
      "epoch:28 step:22525 [D loss: 0.637014, acc.: 66.41%] [G loss: 0.729032]\n",
      "epoch:28 step:22526 [D loss: 0.668880, acc.: 60.16%] [G loss: 0.822223]\n",
      "epoch:28 step:22527 [D loss: 0.727726, acc.: 40.62%] [G loss: 0.747420]\n",
      "epoch:28 step:22528 [D loss: 0.755061, acc.: 42.97%] [G loss: 0.757083]\n",
      "epoch:28 step:22529 [D loss: 0.655802, acc.: 65.62%] [G loss: 0.759096]\n",
      "epoch:28 step:22530 [D loss: 0.693902, acc.: 50.00%] [G loss: 0.780722]\n",
      "epoch:28 step:22531 [D loss: 0.657109, acc.: 60.94%] [G loss: 0.846538]\n",
      "epoch:28 step:22532 [D loss: 0.687729, acc.: 50.00%] [G loss: 0.763200]\n",
      "epoch:28 step:22533 [D loss: 0.648573, acc.: 60.94%] [G loss: 0.792162]\n",
      "epoch:28 step:22534 [D loss: 0.708359, acc.: 45.31%] [G loss: 0.785970]\n",
      "epoch:28 step:22535 [D loss: 0.652689, acc.: 61.72%] [G loss: 0.800297]\n",
      "epoch:28 step:22536 [D loss: 0.727258, acc.: 45.31%] [G loss: 0.707798]\n",
      "epoch:28 step:22537 [D loss: 0.743662, acc.: 42.19%] [G loss: 0.780783]\n",
      "epoch:28 step:22538 [D loss: 0.699493, acc.: 51.56%] [G loss: 0.742850]\n",
      "epoch:28 step:22539 [D loss: 0.725813, acc.: 47.66%] [G loss: 0.668192]\n",
      "epoch:28 step:22540 [D loss: 0.708536, acc.: 45.31%] [G loss: 0.751036]\n",
      "epoch:28 step:22541 [D loss: 0.694647, acc.: 51.56%] [G loss: 0.713159]\n",
      "epoch:28 step:22542 [D loss: 0.728154, acc.: 44.53%] [G loss: 0.722670]\n",
      "epoch:28 step:22543 [D loss: 0.687456, acc.: 57.81%] [G loss: 0.783415]\n",
      "epoch:28 step:22544 [D loss: 0.678428, acc.: 57.03%] [G loss: 0.692175]\n",
      "epoch:28 step:22545 [D loss: 0.665271, acc.: 61.72%] [G loss: 0.765663]\n",
      "epoch:28 step:22546 [D loss: 0.702331, acc.: 53.12%] [G loss: 0.758822]\n",
      "epoch:28 step:22547 [D loss: 0.686439, acc.: 52.34%] [G loss: 0.770918]\n",
      "epoch:28 step:22548 [D loss: 0.635713, acc.: 69.53%] [G loss: 0.785944]\n",
      "epoch:28 step:22549 [D loss: 0.623282, acc.: 65.62%] [G loss: 0.794339]\n",
      "epoch:28 step:22550 [D loss: 0.701747, acc.: 48.44%] [G loss: 0.760148]\n",
      "epoch:28 step:22551 [D loss: 0.697701, acc.: 50.78%] [G loss: 0.740453]\n",
      "epoch:28 step:22552 [D loss: 0.681742, acc.: 55.47%] [G loss: 0.703856]\n",
      "epoch:28 step:22553 [D loss: 0.674392, acc.: 54.69%] [G loss: 0.805338]\n",
      "epoch:28 step:22554 [D loss: 0.750245, acc.: 40.62%] [G loss: 0.727811]\n",
      "epoch:28 step:22555 [D loss: 0.731253, acc.: 38.28%] [G loss: 0.691434]\n",
      "epoch:28 step:22556 [D loss: 0.711701, acc.: 41.41%] [G loss: 0.717129]\n",
      "epoch:28 step:22557 [D loss: 0.723803, acc.: 43.75%] [G loss: 0.705704]\n",
      "epoch:28 step:22558 [D loss: 0.705384, acc.: 51.56%] [G loss: 0.678228]\n",
      "epoch:28 step:22559 [D loss: 0.696807, acc.: 53.12%] [G loss: 0.729888]\n",
      "epoch:28 step:22560 [D loss: 0.796364, acc.: 33.59%] [G loss: 0.741143]\n",
      "epoch:28 step:22561 [D loss: 0.677376, acc.: 52.34%] [G loss: 0.818062]\n",
      "epoch:28 step:22562 [D loss: 0.711748, acc.: 46.09%] [G loss: 0.752481]\n",
      "epoch:28 step:22563 [D loss: 0.653841, acc.: 62.50%] [G loss: 0.707116]\n",
      "epoch:28 step:22564 [D loss: 0.712533, acc.: 49.22%] [G loss: 0.748255]\n",
      "epoch:28 step:22565 [D loss: 0.776126, acc.: 37.50%] [G loss: 0.738459]\n",
      "epoch:28 step:22566 [D loss: 0.687609, acc.: 55.47%] [G loss: 0.684847]\n",
      "epoch:28 step:22567 [D loss: 0.768301, acc.: 34.38%] [G loss: 0.678345]\n",
      "epoch:28 step:22568 [D loss: 0.641875, acc.: 64.84%] [G loss: 0.732882]\n",
      "epoch:28 step:22569 [D loss: 0.723553, acc.: 38.28%] [G loss: 0.767955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22570 [D loss: 0.688703, acc.: 56.25%] [G loss: 0.760720]\n",
      "epoch:28 step:22571 [D loss: 0.650655, acc.: 65.62%] [G loss: 0.783582]\n",
      "epoch:28 step:22572 [D loss: 0.674027, acc.: 56.25%] [G loss: 0.725733]\n",
      "epoch:28 step:22573 [D loss: 0.654415, acc.: 68.75%] [G loss: 0.763563]\n",
      "epoch:28 step:22574 [D loss: 0.669430, acc.: 59.38%] [G loss: 0.833554]\n",
      "epoch:28 step:22575 [D loss: 0.685387, acc.: 57.81%] [G loss: 0.718162]\n",
      "epoch:28 step:22576 [D loss: 0.703298, acc.: 45.31%] [G loss: 0.784758]\n",
      "epoch:28 step:22577 [D loss: 0.674240, acc.: 57.03%] [G loss: 0.809309]\n",
      "epoch:28 step:22578 [D loss: 0.720685, acc.: 47.66%] [G loss: 0.747579]\n",
      "epoch:28 step:22579 [D loss: 0.703183, acc.: 50.78%] [G loss: 0.782014]\n",
      "epoch:28 step:22580 [D loss: 0.673928, acc.: 60.94%] [G loss: 0.809381]\n",
      "epoch:28 step:22581 [D loss: 0.608552, acc.: 73.44%] [G loss: 0.831965]\n",
      "epoch:28 step:22582 [D loss: 0.667689, acc.: 57.03%] [G loss: 0.830949]\n",
      "epoch:28 step:22583 [D loss: 0.742462, acc.: 37.50%] [G loss: 0.783119]\n",
      "epoch:28 step:22584 [D loss: 0.671840, acc.: 63.28%] [G loss: 0.792732]\n",
      "epoch:28 step:22585 [D loss: 0.722186, acc.: 46.88%] [G loss: 0.806472]\n",
      "epoch:28 step:22586 [D loss: 0.690182, acc.: 50.78%] [G loss: 0.811873]\n",
      "epoch:28 step:22587 [D loss: 0.684733, acc.: 57.03%] [G loss: 0.771748]\n",
      "epoch:28 step:22588 [D loss: 0.736258, acc.: 45.31%] [G loss: 0.725204]\n",
      "epoch:28 step:22589 [D loss: 0.682050, acc.: 56.25%] [G loss: 0.694700]\n",
      "epoch:28 step:22590 [D loss: 0.631801, acc.: 69.53%] [G loss: 0.692977]\n",
      "epoch:28 step:22591 [D loss: 0.761959, acc.: 38.28%] [G loss: 0.740361]\n",
      "epoch:28 step:22592 [D loss: 0.745508, acc.: 46.09%] [G loss: 0.747158]\n",
      "epoch:28 step:22593 [D loss: 0.656664, acc.: 60.94%] [G loss: 0.731893]\n",
      "epoch:28 step:22594 [D loss: 0.713586, acc.: 52.34%] [G loss: 0.765800]\n",
      "epoch:28 step:22595 [D loss: 0.687283, acc.: 56.25%] [G loss: 0.719482]\n",
      "epoch:28 step:22596 [D loss: 0.757699, acc.: 35.16%] [G loss: 0.739567]\n",
      "epoch:28 step:22597 [D loss: 0.661123, acc.: 65.62%] [G loss: 0.731011]\n",
      "epoch:28 step:22598 [D loss: 0.680928, acc.: 56.25%] [G loss: 0.789043]\n",
      "epoch:28 step:22599 [D loss: 0.676170, acc.: 53.12%] [G loss: 0.746949]\n",
      "epoch:28 step:22600 [D loss: 0.711305, acc.: 48.44%] [G loss: 0.797242]\n",
      "epoch:28 step:22601 [D loss: 0.679989, acc.: 55.47%] [G loss: 0.754591]\n",
      "epoch:28 step:22602 [D loss: 0.701666, acc.: 47.66%] [G loss: 0.757988]\n",
      "epoch:28 step:22603 [D loss: 0.683725, acc.: 59.38%] [G loss: 0.773089]\n",
      "epoch:28 step:22604 [D loss: 0.689645, acc.: 52.34%] [G loss: 0.736380]\n",
      "epoch:28 step:22605 [D loss: 0.677215, acc.: 53.12%] [G loss: 0.804257]\n",
      "epoch:28 step:22606 [D loss: 0.666703, acc.: 57.81%] [G loss: 0.731775]\n",
      "epoch:28 step:22607 [D loss: 0.720829, acc.: 45.31%] [G loss: 0.695779]\n",
      "epoch:28 step:22608 [D loss: 0.655697, acc.: 65.62%] [G loss: 0.681416]\n",
      "epoch:28 step:22609 [D loss: 0.661355, acc.: 60.94%] [G loss: 0.750324]\n",
      "epoch:28 step:22610 [D loss: 0.720005, acc.: 40.62%] [G loss: 0.796330]\n",
      "epoch:28 step:22611 [D loss: 0.730960, acc.: 42.19%] [G loss: 0.804812]\n",
      "epoch:28 step:22612 [D loss: 0.689188, acc.: 57.81%] [G loss: 0.761451]\n",
      "epoch:28 step:22613 [D loss: 0.691224, acc.: 60.16%] [G loss: 0.675550]\n",
      "epoch:28 step:22614 [D loss: 0.699455, acc.: 52.34%] [G loss: 0.801900]\n",
      "epoch:28 step:22615 [D loss: 0.693074, acc.: 52.34%] [G loss: 0.753106]\n",
      "epoch:28 step:22616 [D loss: 0.696055, acc.: 52.34%] [G loss: 0.800274]\n",
      "epoch:28 step:22617 [D loss: 0.721907, acc.: 46.88%] [G loss: 0.785032]\n",
      "epoch:28 step:22618 [D loss: 0.703257, acc.: 51.56%] [G loss: 0.777504]\n",
      "epoch:28 step:22619 [D loss: 0.663134, acc.: 59.38%] [G loss: 0.698837]\n",
      "epoch:28 step:22620 [D loss: 0.720761, acc.: 45.31%] [G loss: 0.768354]\n",
      "epoch:28 step:22621 [D loss: 0.648045, acc.: 67.97%] [G loss: 0.785252]\n",
      "epoch:28 step:22622 [D loss: 0.665384, acc.: 64.06%] [G loss: 0.724716]\n",
      "epoch:28 step:22623 [D loss: 0.680944, acc.: 52.34%] [G loss: 0.811590]\n",
      "epoch:28 step:22624 [D loss: 0.698517, acc.: 50.78%] [G loss: 0.779905]\n",
      "epoch:28 step:22625 [D loss: 0.665936, acc.: 58.59%] [G loss: 0.828264]\n",
      "epoch:28 step:22626 [D loss: 0.681032, acc.: 54.69%] [G loss: 0.833030]\n",
      "epoch:28 step:22627 [D loss: 0.686903, acc.: 53.91%] [G loss: 0.736671]\n",
      "epoch:28 step:22628 [D loss: 0.696566, acc.: 50.78%] [G loss: 0.778157]\n",
      "epoch:28 step:22629 [D loss: 0.688875, acc.: 50.00%] [G loss: 0.745909]\n",
      "epoch:28 step:22630 [D loss: 0.670253, acc.: 58.59%] [G loss: 0.798101]\n",
      "epoch:28 step:22631 [D loss: 0.722700, acc.: 50.00%] [G loss: 0.776816]\n",
      "epoch:28 step:22632 [D loss: 0.707163, acc.: 49.22%] [G loss: 0.745722]\n",
      "epoch:28 step:22633 [D loss: 0.675412, acc.: 62.50%] [G loss: 0.798048]\n",
      "epoch:28 step:22634 [D loss: 0.664166, acc.: 60.16%] [G loss: 0.760481]\n",
      "epoch:28 step:22635 [D loss: 0.689928, acc.: 57.03%] [G loss: 0.735139]\n",
      "epoch:28 step:22636 [D loss: 0.692453, acc.: 53.91%] [G loss: 0.794782]\n",
      "epoch:28 step:22637 [D loss: 0.724152, acc.: 40.62%] [G loss: 0.748945]\n",
      "epoch:28 step:22638 [D loss: 0.740674, acc.: 35.94%] [G loss: 0.781340]\n",
      "epoch:28 step:22639 [D loss: 0.678093, acc.: 57.03%] [G loss: 0.804637]\n",
      "epoch:28 step:22640 [D loss: 0.697468, acc.: 53.12%] [G loss: 0.712527]\n",
      "epoch:28 step:22641 [D loss: 0.650230, acc.: 63.28%] [G loss: 0.756381]\n",
      "epoch:28 step:22642 [D loss: 0.663767, acc.: 62.50%] [G loss: 0.711577]\n",
      "epoch:28 step:22643 [D loss: 0.691079, acc.: 55.47%] [G loss: 0.783460]\n",
      "epoch:28 step:22644 [D loss: 0.728883, acc.: 44.53%] [G loss: 0.796716]\n",
      "epoch:28 step:22645 [D loss: 0.653734, acc.: 63.28%] [G loss: 0.731737]\n",
      "epoch:28 step:22646 [D loss: 0.724733, acc.: 46.09%] [G loss: 0.703440]\n",
      "epoch:28 step:22647 [D loss: 0.719526, acc.: 42.97%] [G loss: 0.758248]\n",
      "epoch:28 step:22648 [D loss: 0.681128, acc.: 54.69%] [G loss: 0.828283]\n",
      "epoch:28 step:22649 [D loss: 0.676925, acc.: 55.47%] [G loss: 0.818055]\n",
      "epoch:29 step:22650 [D loss: 0.646390, acc.: 70.31%] [G loss: 0.788444]\n",
      "epoch:29 step:22651 [D loss: 0.712079, acc.: 50.78%] [G loss: 0.734899]\n",
      "epoch:29 step:22652 [D loss: 0.657827, acc.: 59.38%] [G loss: 0.734464]\n",
      "epoch:29 step:22653 [D loss: 0.667428, acc.: 60.94%] [G loss: 0.782370]\n",
      "epoch:29 step:22654 [D loss: 0.651634, acc.: 60.16%] [G loss: 0.767716]\n",
      "epoch:29 step:22655 [D loss: 0.659940, acc.: 60.94%] [G loss: 0.821632]\n",
      "epoch:29 step:22656 [D loss: 0.675138, acc.: 56.25%] [G loss: 0.804061]\n",
      "epoch:29 step:22657 [D loss: 0.688699, acc.: 47.66%] [G loss: 0.772812]\n",
      "epoch:29 step:22658 [D loss: 0.677540, acc.: 57.03%] [G loss: 0.750371]\n",
      "epoch:29 step:22659 [D loss: 0.647655, acc.: 64.06%] [G loss: 0.832243]\n",
      "epoch:29 step:22660 [D loss: 0.683198, acc.: 57.81%] [G loss: 0.761903]\n",
      "epoch:29 step:22661 [D loss: 0.677452, acc.: 60.94%] [G loss: 0.782439]\n",
      "epoch:29 step:22662 [D loss: 0.721604, acc.: 45.31%] [G loss: 0.763923]\n",
      "epoch:29 step:22663 [D loss: 0.727651, acc.: 45.31%] [G loss: 0.746622]\n",
      "epoch:29 step:22664 [D loss: 0.722998, acc.: 46.88%] [G loss: 0.769443]\n",
      "epoch:29 step:22665 [D loss: 0.705157, acc.: 50.00%] [G loss: 0.783520]\n",
      "epoch:29 step:22666 [D loss: 0.726877, acc.: 44.53%] [G loss: 0.767175]\n",
      "epoch:29 step:22667 [D loss: 0.738666, acc.: 42.19%] [G loss: 0.713600]\n",
      "epoch:29 step:22668 [D loss: 0.698180, acc.: 48.44%] [G loss: 0.738626]\n",
      "epoch:29 step:22669 [D loss: 0.684230, acc.: 60.16%] [G loss: 0.718057]\n",
      "epoch:29 step:22670 [D loss: 0.701655, acc.: 46.88%] [G loss: 0.763629]\n",
      "epoch:29 step:22671 [D loss: 0.633399, acc.: 69.53%] [G loss: 0.820631]\n",
      "epoch:29 step:22672 [D loss: 0.733125, acc.: 44.53%] [G loss: 0.782422]\n",
      "epoch:29 step:22673 [D loss: 0.693316, acc.: 53.91%] [G loss: 0.809510]\n",
      "epoch:29 step:22674 [D loss: 0.718293, acc.: 49.22%] [G loss: 0.761470]\n",
      "epoch:29 step:22675 [D loss: 0.690313, acc.: 52.34%] [G loss: 0.764712]\n",
      "epoch:29 step:22676 [D loss: 0.704161, acc.: 46.88%] [G loss: 0.778939]\n",
      "epoch:29 step:22677 [D loss: 0.679513, acc.: 55.47%] [G loss: 0.740258]\n",
      "epoch:29 step:22678 [D loss: 0.729707, acc.: 42.19%] [G loss: 0.737130]\n",
      "epoch:29 step:22679 [D loss: 0.683253, acc.: 56.25%] [G loss: 0.790778]\n",
      "epoch:29 step:22680 [D loss: 0.662860, acc.: 60.94%] [G loss: 0.776711]\n",
      "epoch:29 step:22681 [D loss: 0.686133, acc.: 53.12%] [G loss: 0.772127]\n",
      "epoch:29 step:22682 [D loss: 0.689858, acc.: 53.12%] [G loss: 0.706587]\n",
      "epoch:29 step:22683 [D loss: 0.737882, acc.: 42.97%] [G loss: 0.727340]\n",
      "epoch:29 step:22684 [D loss: 0.702409, acc.: 50.78%] [G loss: 0.788003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22685 [D loss: 0.675517, acc.: 57.03%] [G loss: 0.777931]\n",
      "epoch:29 step:22686 [D loss: 0.722234, acc.: 48.44%] [G loss: 0.681970]\n",
      "epoch:29 step:22687 [D loss: 0.640194, acc.: 67.97%] [G loss: 0.820879]\n",
      "epoch:29 step:22688 [D loss: 0.637043, acc.: 69.53%] [G loss: 0.774444]\n",
      "epoch:29 step:22689 [D loss: 0.672252, acc.: 57.81%] [G loss: 0.808183]\n",
      "epoch:29 step:22690 [D loss: 0.636908, acc.: 71.88%] [G loss: 0.742641]\n",
      "epoch:29 step:22691 [D loss: 0.700643, acc.: 50.00%] [G loss: 0.816721]\n",
      "epoch:29 step:22692 [D loss: 0.703921, acc.: 53.91%] [G loss: 0.736149]\n",
      "epoch:29 step:22693 [D loss: 0.725714, acc.: 39.84%] [G loss: 0.667654]\n",
      "epoch:29 step:22694 [D loss: 0.682067, acc.: 55.47%] [G loss: 0.688698]\n",
      "epoch:29 step:22695 [D loss: 0.659754, acc.: 63.28%] [G loss: 0.717605]\n",
      "epoch:29 step:22696 [D loss: 0.698691, acc.: 48.44%] [G loss: 0.698785]\n",
      "epoch:29 step:22697 [D loss: 0.689741, acc.: 55.47%] [G loss: 0.683971]\n",
      "epoch:29 step:22698 [D loss: 0.679392, acc.: 57.03%] [G loss: 0.707595]\n",
      "epoch:29 step:22699 [D loss: 0.773405, acc.: 37.50%] [G loss: 0.679431]\n",
      "epoch:29 step:22700 [D loss: 0.670802, acc.: 57.03%] [G loss: 0.753576]\n",
      "epoch:29 step:22701 [D loss: 0.677629, acc.: 57.03%] [G loss: 0.752663]\n",
      "epoch:29 step:22702 [D loss: 0.718126, acc.: 46.88%] [G loss: 0.759103]\n",
      "epoch:29 step:22703 [D loss: 0.736683, acc.: 34.38%] [G loss: 0.770618]\n",
      "epoch:29 step:22704 [D loss: 0.705400, acc.: 50.00%] [G loss: 0.764503]\n",
      "epoch:29 step:22705 [D loss: 0.642432, acc.: 67.97%] [G loss: 0.791111]\n",
      "epoch:29 step:22706 [D loss: 0.651453, acc.: 65.62%] [G loss: 0.712929]\n",
      "epoch:29 step:22707 [D loss: 0.685934, acc.: 55.47%] [G loss: 0.792681]\n",
      "epoch:29 step:22708 [D loss: 0.662696, acc.: 59.38%] [G loss: 0.833581]\n",
      "epoch:29 step:22709 [D loss: 0.690521, acc.: 52.34%] [G loss: 0.741948]\n",
      "epoch:29 step:22710 [D loss: 0.713420, acc.: 42.19%] [G loss: 0.774635]\n",
      "epoch:29 step:22711 [D loss: 0.656163, acc.: 62.50%] [G loss: 0.850479]\n",
      "epoch:29 step:22712 [D loss: 0.649552, acc.: 60.94%] [G loss: 0.841869]\n",
      "epoch:29 step:22713 [D loss: 0.723909, acc.: 47.66%] [G loss: 0.760038]\n",
      "epoch:29 step:22714 [D loss: 0.671050, acc.: 53.12%] [G loss: 0.820226]\n",
      "epoch:29 step:22715 [D loss: 0.694992, acc.: 56.25%] [G loss: 0.780644]\n",
      "epoch:29 step:22716 [D loss: 0.694129, acc.: 53.12%] [G loss: 0.712833]\n",
      "epoch:29 step:22717 [D loss: 0.717103, acc.: 50.78%] [G loss: 0.772018]\n",
      "epoch:29 step:22718 [D loss: 0.716422, acc.: 41.41%] [G loss: 0.791103]\n",
      "epoch:29 step:22719 [D loss: 0.707457, acc.: 48.44%] [G loss: 0.743730]\n",
      "epoch:29 step:22720 [D loss: 0.693812, acc.: 51.56%] [G loss: 0.755961]\n",
      "epoch:29 step:22721 [D loss: 0.668181, acc.: 59.38%] [G loss: 0.761080]\n",
      "epoch:29 step:22722 [D loss: 0.651127, acc.: 64.06%] [G loss: 0.745483]\n",
      "epoch:29 step:22723 [D loss: 0.687173, acc.: 58.59%] [G loss: 0.692658]\n",
      "epoch:29 step:22724 [D loss: 0.714208, acc.: 50.00%] [G loss: 0.714112]\n",
      "epoch:29 step:22725 [D loss: 0.644030, acc.: 71.09%] [G loss: 0.768557]\n",
      "epoch:29 step:22726 [D loss: 0.655763, acc.: 60.94%] [G loss: 0.757532]\n",
      "epoch:29 step:22727 [D loss: 0.684959, acc.: 61.72%] [G loss: 0.695963]\n",
      "epoch:29 step:22728 [D loss: 0.725181, acc.: 46.88%] [G loss: 0.791321]\n",
      "epoch:29 step:22729 [D loss: 0.647922, acc.: 65.62%] [G loss: 0.799361]\n",
      "epoch:29 step:22730 [D loss: 0.659459, acc.: 57.81%] [G loss: 0.804537]\n",
      "epoch:29 step:22731 [D loss: 0.657717, acc.: 62.50%] [G loss: 0.771913]\n",
      "epoch:29 step:22732 [D loss: 0.719357, acc.: 43.75%] [G loss: 0.777740]\n",
      "epoch:29 step:22733 [D loss: 0.673740, acc.: 57.03%] [G loss: 0.814624]\n",
      "epoch:29 step:22734 [D loss: 0.678509, acc.: 59.38%] [G loss: 0.789006]\n",
      "epoch:29 step:22735 [D loss: 0.622828, acc.: 73.44%] [G loss: 0.779692]\n",
      "epoch:29 step:22736 [D loss: 0.708127, acc.: 50.00%] [G loss: 0.777554]\n",
      "epoch:29 step:22737 [D loss: 0.696941, acc.: 47.66%] [G loss: 0.728938]\n",
      "epoch:29 step:22738 [D loss: 0.619924, acc.: 77.34%] [G loss: 0.774051]\n",
      "epoch:29 step:22739 [D loss: 0.692647, acc.: 55.47%] [G loss: 0.750724]\n",
      "epoch:29 step:22740 [D loss: 0.678145, acc.: 58.59%] [G loss: 0.727204]\n",
      "epoch:29 step:22741 [D loss: 0.670608, acc.: 57.81%] [G loss: 0.778960]\n",
      "epoch:29 step:22742 [D loss: 0.669481, acc.: 54.69%] [G loss: 0.840761]\n",
      "epoch:29 step:22743 [D loss: 0.642019, acc.: 68.75%] [G loss: 0.816927]\n",
      "epoch:29 step:22744 [D loss: 0.674767, acc.: 57.81%] [G loss: 0.836270]\n",
      "epoch:29 step:22745 [D loss: 0.671775, acc.: 59.38%] [G loss: 0.763635]\n",
      "epoch:29 step:22746 [D loss: 0.693390, acc.: 55.47%] [G loss: 0.816810]\n",
      "epoch:29 step:22747 [D loss: 0.660653, acc.: 56.25%] [G loss: 0.841324]\n",
      "epoch:29 step:22748 [D loss: 0.697588, acc.: 51.56%] [G loss: 0.821714]\n",
      "epoch:29 step:22749 [D loss: 0.675722, acc.: 60.16%] [G loss: 0.735594]\n",
      "epoch:29 step:22750 [D loss: 0.677187, acc.: 54.69%] [G loss: 0.774339]\n",
      "epoch:29 step:22751 [D loss: 0.689263, acc.: 48.44%] [G loss: 0.845593]\n",
      "epoch:29 step:22752 [D loss: 0.773221, acc.: 38.28%] [G loss: 0.822334]\n",
      "epoch:29 step:22753 [D loss: 0.706850, acc.: 48.44%] [G loss: 0.748853]\n",
      "epoch:29 step:22754 [D loss: 0.670098, acc.: 60.94%] [G loss: 0.785886]\n",
      "epoch:29 step:22755 [D loss: 0.682870, acc.: 58.59%] [G loss: 0.703681]\n",
      "epoch:29 step:22756 [D loss: 0.668113, acc.: 55.47%] [G loss: 0.811301]\n",
      "epoch:29 step:22757 [D loss: 0.773739, acc.: 32.03%] [G loss: 0.692031]\n",
      "epoch:29 step:22758 [D loss: 0.689388, acc.: 52.34%] [G loss: 0.756546]\n",
      "epoch:29 step:22759 [D loss: 0.673889, acc.: 62.50%] [G loss: 0.741839]\n",
      "epoch:29 step:22760 [D loss: 0.697582, acc.: 54.69%] [G loss: 0.720351]\n",
      "epoch:29 step:22761 [D loss: 0.635836, acc.: 73.44%] [G loss: 0.768561]\n",
      "epoch:29 step:22762 [D loss: 0.707579, acc.: 52.34%] [G loss: 0.749216]\n",
      "epoch:29 step:22763 [D loss: 0.664870, acc.: 62.50%] [G loss: 0.753452]\n",
      "epoch:29 step:22764 [D loss: 0.656876, acc.: 62.50%] [G loss: 0.777210]\n",
      "epoch:29 step:22765 [D loss: 0.704379, acc.: 53.12%] [G loss: 0.752817]\n",
      "epoch:29 step:22766 [D loss: 0.697559, acc.: 50.78%] [G loss: 0.718852]\n",
      "epoch:29 step:22767 [D loss: 0.650740, acc.: 65.62%] [G loss: 0.716451]\n",
      "epoch:29 step:22768 [D loss: 0.646399, acc.: 58.59%] [G loss: 0.750558]\n",
      "epoch:29 step:22769 [D loss: 0.650195, acc.: 66.41%] [G loss: 0.692011]\n",
      "epoch:29 step:22770 [D loss: 0.630833, acc.: 64.84%] [G loss: 0.776127]\n",
      "epoch:29 step:22771 [D loss: 0.656378, acc.: 64.84%] [G loss: 0.749065]\n",
      "epoch:29 step:22772 [D loss: 0.729127, acc.: 44.53%] [G loss: 0.672054]\n",
      "epoch:29 step:22773 [D loss: 0.741382, acc.: 39.84%] [G loss: 0.770103]\n",
      "epoch:29 step:22774 [D loss: 0.719557, acc.: 45.31%] [G loss: 0.751170]\n",
      "epoch:29 step:22775 [D loss: 0.636484, acc.: 61.72%] [G loss: 0.795650]\n",
      "epoch:29 step:22776 [D loss: 0.713038, acc.: 49.22%] [G loss: 0.696565]\n",
      "epoch:29 step:22777 [D loss: 0.678766, acc.: 58.59%] [G loss: 0.724452]\n",
      "epoch:29 step:22778 [D loss: 0.698383, acc.: 53.12%] [G loss: 0.756224]\n",
      "epoch:29 step:22779 [D loss: 0.689921, acc.: 54.69%] [G loss: 0.831045]\n",
      "epoch:29 step:22780 [D loss: 0.682462, acc.: 54.69%] [G loss: 0.757608]\n",
      "epoch:29 step:22781 [D loss: 0.696835, acc.: 54.69%] [G loss: 0.796147]\n",
      "epoch:29 step:22782 [D loss: 0.718320, acc.: 44.53%] [G loss: 0.759178]\n",
      "epoch:29 step:22783 [D loss: 0.712296, acc.: 47.66%] [G loss: 0.770675]\n",
      "epoch:29 step:22784 [D loss: 0.760647, acc.: 45.31%] [G loss: 0.710417]\n",
      "epoch:29 step:22785 [D loss: 0.651651, acc.: 64.06%] [G loss: 0.707564]\n",
      "epoch:29 step:22786 [D loss: 0.725612, acc.: 45.31%] [G loss: 0.712100]\n",
      "epoch:29 step:22787 [D loss: 0.711702, acc.: 46.09%] [G loss: 0.737236]\n",
      "epoch:29 step:22788 [D loss: 0.688474, acc.: 50.78%] [G loss: 0.776092]\n",
      "epoch:29 step:22789 [D loss: 0.682478, acc.: 58.59%] [G loss: 0.767360]\n",
      "epoch:29 step:22790 [D loss: 0.626398, acc.: 64.84%] [G loss: 0.856170]\n",
      "epoch:29 step:22791 [D loss: 0.758061, acc.: 33.59%] [G loss: 0.790289]\n",
      "epoch:29 step:22792 [D loss: 0.744674, acc.: 40.62%] [G loss: 0.733961]\n",
      "epoch:29 step:22793 [D loss: 0.721866, acc.: 43.75%] [G loss: 0.746701]\n",
      "epoch:29 step:22794 [D loss: 0.683405, acc.: 57.81%] [G loss: 0.787669]\n",
      "epoch:29 step:22795 [D loss: 0.661997, acc.: 61.72%] [G loss: 0.676244]\n",
      "epoch:29 step:22796 [D loss: 0.690252, acc.: 46.88%] [G loss: 0.777062]\n",
      "epoch:29 step:22797 [D loss: 0.731771, acc.: 44.53%] [G loss: 0.735028]\n",
      "epoch:29 step:22798 [D loss: 0.709995, acc.: 53.91%] [G loss: 0.787673]\n",
      "epoch:29 step:22799 [D loss: 0.718474, acc.: 43.75%] [G loss: 0.749165]\n",
      "epoch:29 step:22800 [D loss: 0.670645, acc.: 57.81%] [G loss: 0.801331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22801 [D loss: 0.686231, acc.: 56.25%] [G loss: 0.746031]\n",
      "epoch:29 step:22802 [D loss: 0.648774, acc.: 69.53%] [G loss: 0.803561]\n",
      "epoch:29 step:22803 [D loss: 0.686364, acc.: 53.91%] [G loss: 0.796293]\n",
      "epoch:29 step:22804 [D loss: 0.697198, acc.: 53.12%] [G loss: 0.818550]\n",
      "epoch:29 step:22805 [D loss: 0.673879, acc.: 60.94%] [G loss: 0.791900]\n",
      "epoch:29 step:22806 [D loss: 0.634082, acc.: 68.75%] [G loss: 0.754606]\n",
      "epoch:29 step:22807 [D loss: 0.664587, acc.: 60.16%] [G loss: 0.776628]\n",
      "epoch:29 step:22808 [D loss: 0.678337, acc.: 55.47%] [G loss: 0.779244]\n",
      "epoch:29 step:22809 [D loss: 0.657885, acc.: 60.16%] [G loss: 0.819564]\n",
      "epoch:29 step:22810 [D loss: 0.700927, acc.: 48.44%] [G loss: 0.719092]\n",
      "epoch:29 step:22811 [D loss: 0.665193, acc.: 59.38%] [G loss: 0.778228]\n",
      "epoch:29 step:22812 [D loss: 0.674273, acc.: 57.81%] [G loss: 0.747755]\n",
      "epoch:29 step:22813 [D loss: 0.679796, acc.: 56.25%] [G loss: 0.764078]\n",
      "epoch:29 step:22814 [D loss: 0.649612, acc.: 64.06%] [G loss: 0.828958]\n",
      "epoch:29 step:22815 [D loss: 0.695551, acc.: 57.03%] [G loss: 0.831466]\n",
      "epoch:29 step:22816 [D loss: 0.658590, acc.: 61.72%] [G loss: 0.745100]\n",
      "epoch:29 step:22817 [D loss: 0.714234, acc.: 48.44%] [G loss: 0.693566]\n",
      "epoch:29 step:22818 [D loss: 0.657704, acc.: 59.38%] [G loss: 0.778737]\n",
      "epoch:29 step:22819 [D loss: 0.689679, acc.: 56.25%] [G loss: 0.752859]\n",
      "epoch:29 step:22820 [D loss: 0.649675, acc.: 71.09%] [G loss: 0.834025]\n",
      "epoch:29 step:22821 [D loss: 0.692285, acc.: 50.00%] [G loss: 0.766489]\n",
      "epoch:29 step:22822 [D loss: 0.706900, acc.: 51.56%] [G loss: 0.737787]\n",
      "epoch:29 step:22823 [D loss: 0.682078, acc.: 53.91%] [G loss: 0.766455]\n",
      "epoch:29 step:22824 [D loss: 0.671005, acc.: 65.62%] [G loss: 0.733316]\n",
      "epoch:29 step:22825 [D loss: 0.688377, acc.: 47.66%] [G loss: 0.751771]\n",
      "epoch:29 step:22826 [D loss: 0.639524, acc.: 70.31%] [G loss: 0.767289]\n",
      "epoch:29 step:22827 [D loss: 0.720551, acc.: 42.19%] [G loss: 0.703200]\n",
      "epoch:29 step:22828 [D loss: 0.665018, acc.: 63.28%] [G loss: 0.777748]\n",
      "epoch:29 step:22829 [D loss: 0.672123, acc.: 54.69%] [G loss: 0.733742]\n",
      "epoch:29 step:22830 [D loss: 0.652906, acc.: 61.72%] [G loss: 0.819264]\n",
      "epoch:29 step:22831 [D loss: 0.775133, acc.: 40.62%] [G loss: 0.771598]\n",
      "epoch:29 step:22832 [D loss: 0.709917, acc.: 47.66%] [G loss: 0.785983]\n",
      "epoch:29 step:22833 [D loss: 0.710224, acc.: 44.53%] [G loss: 0.719631]\n",
      "epoch:29 step:22834 [D loss: 0.700605, acc.: 50.78%] [G loss: 0.751437]\n",
      "epoch:29 step:22835 [D loss: 0.720138, acc.: 45.31%] [G loss: 0.723832]\n",
      "epoch:29 step:22836 [D loss: 0.711870, acc.: 52.34%] [G loss: 0.758237]\n",
      "epoch:29 step:22837 [D loss: 0.694814, acc.: 55.47%] [G loss: 0.673716]\n",
      "epoch:29 step:22838 [D loss: 0.656061, acc.: 67.97%] [G loss: 0.774568]\n",
      "epoch:29 step:22839 [D loss: 0.743124, acc.: 42.19%] [G loss: 0.737965]\n",
      "epoch:29 step:22840 [D loss: 0.665531, acc.: 59.38%] [G loss: 0.751837]\n",
      "epoch:29 step:22841 [D loss: 0.695460, acc.: 53.91%] [G loss: 0.810563]\n",
      "epoch:29 step:22842 [D loss: 0.726847, acc.: 39.06%] [G loss: 0.806071]\n",
      "epoch:29 step:22843 [D loss: 0.741377, acc.: 44.53%] [G loss: 0.714355]\n",
      "epoch:29 step:22844 [D loss: 0.708410, acc.: 47.66%] [G loss: 0.795843]\n",
      "epoch:29 step:22845 [D loss: 0.684439, acc.: 46.88%] [G loss: 0.832777]\n",
      "epoch:29 step:22846 [D loss: 0.691403, acc.: 56.25%] [G loss: 0.758727]\n",
      "epoch:29 step:22847 [D loss: 0.629896, acc.: 69.53%] [G loss: 0.801139]\n",
      "epoch:29 step:22848 [D loss: 0.695468, acc.: 53.12%] [G loss: 0.825293]\n",
      "epoch:29 step:22849 [D loss: 0.682570, acc.: 56.25%] [G loss: 0.779915]\n",
      "epoch:29 step:22850 [D loss: 0.637132, acc.: 65.62%] [G loss: 0.858127]\n",
      "epoch:29 step:22851 [D loss: 0.671163, acc.: 54.69%] [G loss: 0.690122]\n",
      "epoch:29 step:22852 [D loss: 0.679979, acc.: 62.50%] [G loss: 0.779356]\n",
      "epoch:29 step:22853 [D loss: 0.670291, acc.: 60.16%] [G loss: 0.746468]\n",
      "epoch:29 step:22854 [D loss: 0.696142, acc.: 57.03%] [G loss: 0.841017]\n",
      "epoch:29 step:22855 [D loss: 0.729464, acc.: 46.88%] [G loss: 0.791022]\n",
      "epoch:29 step:22856 [D loss: 0.606928, acc.: 76.56%] [G loss: 0.722432]\n",
      "epoch:29 step:22857 [D loss: 0.668327, acc.: 55.47%] [G loss: 0.744296]\n",
      "epoch:29 step:22858 [D loss: 0.725432, acc.: 47.66%] [G loss: 0.789905]\n",
      "epoch:29 step:22859 [D loss: 0.664054, acc.: 63.28%] [G loss: 0.818808]\n",
      "epoch:29 step:22860 [D loss: 0.677964, acc.: 55.47%] [G loss: 0.742054]\n",
      "epoch:29 step:22861 [D loss: 0.678585, acc.: 59.38%] [G loss: 0.793862]\n",
      "epoch:29 step:22862 [D loss: 0.698682, acc.: 52.34%] [G loss: 0.794752]\n",
      "epoch:29 step:22863 [D loss: 0.713784, acc.: 48.44%] [G loss: 0.746923]\n",
      "epoch:29 step:22864 [D loss: 0.730220, acc.: 37.50%] [G loss: 0.720260]\n",
      "epoch:29 step:22865 [D loss: 0.688661, acc.: 53.91%] [G loss: 0.744769]\n",
      "epoch:29 step:22866 [D loss: 0.731121, acc.: 42.97%] [G loss: 0.717022]\n",
      "epoch:29 step:22867 [D loss: 0.719584, acc.: 45.31%] [G loss: 0.714211]\n",
      "epoch:29 step:22868 [D loss: 0.676994, acc.: 63.28%] [G loss: 0.756914]\n",
      "epoch:29 step:22869 [D loss: 0.706872, acc.: 51.56%] [G loss: 0.702570]\n",
      "epoch:29 step:22870 [D loss: 0.708372, acc.: 45.31%] [G loss: 0.738140]\n",
      "epoch:29 step:22871 [D loss: 0.716460, acc.: 41.41%] [G loss: 0.781303]\n",
      "epoch:29 step:22872 [D loss: 0.691620, acc.: 50.78%] [G loss: 0.718790]\n",
      "epoch:29 step:22873 [D loss: 0.629456, acc.: 65.62%] [G loss: 0.789627]\n",
      "epoch:29 step:22874 [D loss: 0.658181, acc.: 61.72%] [G loss: 0.821485]\n",
      "epoch:29 step:22875 [D loss: 0.745597, acc.: 39.84%] [G loss: 0.740556]\n",
      "epoch:29 step:22876 [D loss: 0.710125, acc.: 45.31%] [G loss: 0.779515]\n",
      "epoch:29 step:22877 [D loss: 0.687037, acc.: 59.38%] [G loss: 0.833660]\n",
      "epoch:29 step:22878 [D loss: 0.634901, acc.: 67.97%] [G loss: 0.762522]\n",
      "epoch:29 step:22879 [D loss: 0.713461, acc.: 52.34%] [G loss: 0.762089]\n",
      "epoch:29 step:22880 [D loss: 0.627450, acc.: 71.88%] [G loss: 0.740702]\n",
      "epoch:29 step:22881 [D loss: 0.703069, acc.: 48.44%] [G loss: 0.735333]\n",
      "epoch:29 step:22882 [D loss: 0.694268, acc.: 56.25%] [G loss: 0.771409]\n",
      "epoch:29 step:22883 [D loss: 0.688761, acc.: 53.12%] [G loss: 0.693328]\n",
      "epoch:29 step:22884 [D loss: 0.722799, acc.: 56.25%] [G loss: 0.671471]\n",
      "epoch:29 step:22885 [D loss: 0.705541, acc.: 50.78%] [G loss: 0.697993]\n",
      "epoch:29 step:22886 [D loss: 0.704773, acc.: 46.88%] [G loss: 0.658098]\n",
      "epoch:29 step:22887 [D loss: 0.681366, acc.: 56.25%] [G loss: 0.686927]\n",
      "epoch:29 step:22888 [D loss: 0.667609, acc.: 57.03%] [G loss: 0.680794]\n",
      "epoch:29 step:22889 [D loss: 0.719329, acc.: 46.88%] [G loss: 0.641572]\n",
      "epoch:29 step:22890 [D loss: 0.716074, acc.: 42.19%] [G loss: 0.721316]\n",
      "epoch:29 step:22891 [D loss: 0.717175, acc.: 42.19%] [G loss: 0.735411]\n",
      "epoch:29 step:22892 [D loss: 0.689566, acc.: 58.59%] [G loss: 0.740247]\n",
      "epoch:29 step:22893 [D loss: 0.649448, acc.: 64.84%] [G loss: 0.777368]\n",
      "epoch:29 step:22894 [D loss: 0.696496, acc.: 53.91%] [G loss: 0.756040]\n",
      "epoch:29 step:22895 [D loss: 0.714802, acc.: 46.09%] [G loss: 0.732769]\n",
      "epoch:29 step:22896 [D loss: 0.708690, acc.: 46.88%] [G loss: 0.748423]\n",
      "epoch:29 step:22897 [D loss: 0.681481, acc.: 57.03%] [G loss: 0.707830]\n",
      "epoch:29 step:22898 [D loss: 0.685838, acc.: 53.91%] [G loss: 0.727845]\n",
      "epoch:29 step:22899 [D loss: 0.660158, acc.: 64.84%] [G loss: 0.795037]\n",
      "epoch:29 step:22900 [D loss: 0.701013, acc.: 48.44%] [G loss: 0.774859]\n",
      "epoch:29 step:22901 [D loss: 0.673633, acc.: 57.03%] [G loss: 0.760150]\n",
      "epoch:29 step:22902 [D loss: 0.696106, acc.: 48.44%] [G loss: 0.794010]\n",
      "epoch:29 step:22903 [D loss: 0.743846, acc.: 43.75%] [G loss: 0.718886]\n",
      "epoch:29 step:22904 [D loss: 0.649257, acc.: 61.72%] [G loss: 0.787582]\n",
      "epoch:29 step:22905 [D loss: 0.678402, acc.: 53.12%] [G loss: 0.757778]\n",
      "epoch:29 step:22906 [D loss: 0.660074, acc.: 55.47%] [G loss: 0.773271]\n",
      "epoch:29 step:22907 [D loss: 0.707390, acc.: 50.78%] [G loss: 0.770132]\n",
      "epoch:29 step:22908 [D loss: 0.666562, acc.: 60.94%] [G loss: 0.819804]\n",
      "epoch:29 step:22909 [D loss: 0.656428, acc.: 65.62%] [G loss: 0.806394]\n",
      "epoch:29 step:22910 [D loss: 0.683815, acc.: 53.91%] [G loss: 0.834575]\n",
      "epoch:29 step:22911 [D loss: 0.684346, acc.: 54.69%] [G loss: 0.826440]\n",
      "epoch:29 step:22912 [D loss: 0.703880, acc.: 53.12%] [G loss: 0.820657]\n",
      "epoch:29 step:22913 [D loss: 0.720646, acc.: 47.66%] [G loss: 0.835689]\n",
      "epoch:29 step:22914 [D loss: 0.720477, acc.: 42.19%] [G loss: 0.719414]\n",
      "epoch:29 step:22915 [D loss: 0.690860, acc.: 54.69%] [G loss: 0.767502]\n",
      "epoch:29 step:22916 [D loss: 0.701786, acc.: 50.78%] [G loss: 0.763448]\n",
      "epoch:29 step:22917 [D loss: 0.664863, acc.: 57.03%] [G loss: 0.734633]\n",
      "epoch:29 step:22918 [D loss: 0.638269, acc.: 65.62%] [G loss: 0.756375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22919 [D loss: 0.700109, acc.: 53.91%] [G loss: 0.824616]\n",
      "epoch:29 step:22920 [D loss: 0.711078, acc.: 49.22%] [G loss: 0.741616]\n",
      "epoch:29 step:22921 [D loss: 0.663414, acc.: 56.25%] [G loss: 0.799944]\n",
      "epoch:29 step:22922 [D loss: 0.749353, acc.: 42.97%] [G loss: 0.796487]\n",
      "epoch:29 step:22923 [D loss: 0.677816, acc.: 53.91%] [G loss: 0.862604]\n",
      "epoch:29 step:22924 [D loss: 0.651534, acc.: 61.72%] [G loss: 0.802566]\n",
      "epoch:29 step:22925 [D loss: 0.691739, acc.: 47.66%] [G loss: 0.748277]\n",
      "epoch:29 step:22926 [D loss: 0.734831, acc.: 42.97%] [G loss: 0.751262]\n",
      "epoch:29 step:22927 [D loss: 0.653036, acc.: 65.62%] [G loss: 0.767746]\n",
      "epoch:29 step:22928 [D loss: 0.720280, acc.: 50.78%] [G loss: 0.696624]\n",
      "epoch:29 step:22929 [D loss: 0.704793, acc.: 53.91%] [G loss: 0.766560]\n",
      "epoch:29 step:22930 [D loss: 0.729117, acc.: 46.88%] [G loss: 0.727626]\n",
      "epoch:29 step:22931 [D loss: 0.701385, acc.: 52.34%] [G loss: 0.762789]\n",
      "epoch:29 step:22932 [D loss: 0.676467, acc.: 52.34%] [G loss: 0.745431]\n",
      "epoch:29 step:22933 [D loss: 0.667639, acc.: 59.38%] [G loss: 0.794969]\n",
      "epoch:29 step:22934 [D loss: 0.698890, acc.: 53.91%] [G loss: 0.748462]\n",
      "epoch:29 step:22935 [D loss: 0.673894, acc.: 60.16%] [G loss: 0.757302]\n",
      "epoch:29 step:22936 [D loss: 0.693317, acc.: 51.56%] [G loss: 0.764065]\n",
      "epoch:29 step:22937 [D loss: 0.654924, acc.: 62.50%] [G loss: 0.764620]\n",
      "epoch:29 step:22938 [D loss: 0.690734, acc.: 55.47%] [G loss: 0.754819]\n",
      "epoch:29 step:22939 [D loss: 0.666851, acc.: 56.25%] [G loss: 0.780794]\n",
      "epoch:29 step:22940 [D loss: 0.701999, acc.: 52.34%] [G loss: 0.759394]\n",
      "epoch:29 step:22941 [D loss: 0.730866, acc.: 50.00%] [G loss: 0.737189]\n",
      "epoch:29 step:22942 [D loss: 0.684523, acc.: 59.38%] [G loss: 0.691473]\n",
      "epoch:29 step:22943 [D loss: 0.688937, acc.: 53.91%] [G loss: 0.740785]\n",
      "epoch:29 step:22944 [D loss: 0.704626, acc.: 50.78%] [G loss: 0.726807]\n",
      "epoch:29 step:22945 [D loss: 0.669802, acc.: 62.50%] [G loss: 0.768772]\n",
      "epoch:29 step:22946 [D loss: 0.681239, acc.: 56.25%] [G loss: 0.728425]\n",
      "epoch:29 step:22947 [D loss: 0.736049, acc.: 46.88%] [G loss: 0.717879]\n",
      "epoch:29 step:22948 [D loss: 0.695319, acc.: 50.78%] [G loss: 0.703166]\n",
      "epoch:29 step:22949 [D loss: 0.738465, acc.: 42.19%] [G loss: 0.722398]\n",
      "epoch:29 step:22950 [D loss: 0.708149, acc.: 50.78%] [G loss: 0.744358]\n",
      "epoch:29 step:22951 [D loss: 0.733847, acc.: 45.31%] [G loss: 0.682973]\n",
      "epoch:29 step:22952 [D loss: 0.698507, acc.: 50.00%] [G loss: 0.696253]\n",
      "epoch:29 step:22953 [D loss: 0.672034, acc.: 55.47%] [G loss: 0.761926]\n",
      "epoch:29 step:22954 [D loss: 0.683120, acc.: 51.56%] [G loss: 0.721270]\n",
      "epoch:29 step:22955 [D loss: 0.696085, acc.: 51.56%] [G loss: 0.725727]\n",
      "epoch:29 step:22956 [D loss: 0.670108, acc.: 57.03%] [G loss: 0.774184]\n",
      "epoch:29 step:22957 [D loss: 0.660389, acc.: 60.16%] [G loss: 0.800632]\n",
      "epoch:29 step:22958 [D loss: 0.678392, acc.: 59.38%] [G loss: 0.736615]\n",
      "epoch:29 step:22959 [D loss: 0.659092, acc.: 63.28%] [G loss: 0.807032]\n",
      "epoch:29 step:22960 [D loss: 0.693177, acc.: 53.91%] [G loss: 0.814587]\n",
      "epoch:29 step:22961 [D loss: 0.689029, acc.: 55.47%] [G loss: 0.767507]\n",
      "epoch:29 step:22962 [D loss: 0.695806, acc.: 50.00%] [G loss: 0.810387]\n",
      "epoch:29 step:22963 [D loss: 0.697490, acc.: 53.91%] [G loss: 0.765448]\n",
      "epoch:29 step:22964 [D loss: 0.733021, acc.: 48.44%] [G loss: 0.797233]\n",
      "epoch:29 step:22965 [D loss: 0.666914, acc.: 63.28%] [G loss: 0.779221]\n",
      "epoch:29 step:22966 [D loss: 0.683674, acc.: 54.69%] [G loss: 0.752746]\n",
      "epoch:29 step:22967 [D loss: 0.692456, acc.: 53.91%] [G loss: 0.679737]\n",
      "epoch:29 step:22968 [D loss: 0.682518, acc.: 53.12%] [G loss: 0.684666]\n",
      "epoch:29 step:22969 [D loss: 0.694093, acc.: 59.38%] [G loss: 0.751325]\n",
      "epoch:29 step:22970 [D loss: 0.700773, acc.: 55.47%] [G loss: 0.770493]\n",
      "epoch:29 step:22971 [D loss: 0.712087, acc.: 52.34%] [G loss: 0.720487]\n",
      "epoch:29 step:22972 [D loss: 0.717204, acc.: 44.53%] [G loss: 0.777742]\n",
      "epoch:29 step:22973 [D loss: 0.706696, acc.: 47.66%] [G loss: 0.735967]\n",
      "epoch:29 step:22974 [D loss: 0.656076, acc.: 60.94%] [G loss: 0.809782]\n",
      "epoch:29 step:22975 [D loss: 0.686700, acc.: 56.25%] [G loss: 0.710399]\n",
      "epoch:29 step:22976 [D loss: 0.694433, acc.: 54.69%] [G loss: 0.818743]\n",
      "epoch:29 step:22977 [D loss: 0.628036, acc.: 69.53%] [G loss: 0.795626]\n",
      "epoch:29 step:22978 [D loss: 0.735183, acc.: 43.75%] [G loss: 0.780267]\n",
      "epoch:29 step:22979 [D loss: 0.736605, acc.: 48.44%] [G loss: 0.731057]\n",
      "epoch:29 step:22980 [D loss: 0.715648, acc.: 48.44%] [G loss: 0.767572]\n",
      "epoch:29 step:22981 [D loss: 0.686685, acc.: 51.56%] [G loss: 0.749993]\n",
      "epoch:29 step:22982 [D loss: 0.682952, acc.: 54.69%] [G loss: 0.801868]\n",
      "epoch:29 step:22983 [D loss: 0.691663, acc.: 53.12%] [G loss: 0.754082]\n",
      "epoch:29 step:22984 [D loss: 0.642390, acc.: 67.19%] [G loss: 0.747306]\n",
      "epoch:29 step:22985 [D loss: 0.631821, acc.: 67.19%] [G loss: 0.785877]\n",
      "epoch:29 step:22986 [D loss: 0.677315, acc.: 55.47%] [G loss: 0.723392]\n",
      "epoch:29 step:22987 [D loss: 0.739500, acc.: 37.50%] [G loss: 0.761598]\n",
      "epoch:29 step:22988 [D loss: 0.705905, acc.: 50.00%] [G loss: 0.743147]\n",
      "epoch:29 step:22989 [D loss: 0.678762, acc.: 60.16%] [G loss: 0.885441]\n",
      "epoch:29 step:22990 [D loss: 0.678677, acc.: 57.03%] [G loss: 0.889933]\n",
      "epoch:29 step:22991 [D loss: 0.690904, acc.: 50.78%] [G loss: 0.794511]\n",
      "epoch:29 step:22992 [D loss: 0.687638, acc.: 53.91%] [G loss: 0.748618]\n",
      "epoch:29 step:22993 [D loss: 0.644786, acc.: 67.97%] [G loss: 0.785145]\n",
      "epoch:29 step:22994 [D loss: 0.697169, acc.: 52.34%] [G loss: 0.703386]\n",
      "epoch:29 step:22995 [D loss: 0.690495, acc.: 51.56%] [G loss: 0.734464]\n",
      "epoch:29 step:22996 [D loss: 0.731759, acc.: 45.31%] [G loss: 0.800533]\n",
      "epoch:29 step:22997 [D loss: 0.727257, acc.: 48.44%] [G loss: 0.824469]\n",
      "epoch:29 step:22998 [D loss: 0.671139, acc.: 56.25%] [G loss: 0.852991]\n",
      "epoch:29 step:22999 [D loss: 0.697743, acc.: 50.78%] [G loss: 0.853214]\n",
      "epoch:29 step:23000 [D loss: 0.703493, acc.: 46.09%] [G loss: 0.735071]\n",
      "epoch:29 step:23001 [D loss: 0.678473, acc.: 60.94%] [G loss: 0.770748]\n",
      "epoch:29 step:23002 [D loss: 0.642467, acc.: 60.94%] [G loss: 0.753846]\n",
      "epoch:29 step:23003 [D loss: 0.710657, acc.: 47.66%] [G loss: 0.703477]\n",
      "epoch:29 step:23004 [D loss: 0.701081, acc.: 50.00%] [G loss: 0.744374]\n",
      "epoch:29 step:23005 [D loss: 0.664115, acc.: 57.03%] [G loss: 0.853067]\n",
      "epoch:29 step:23006 [D loss: 0.693980, acc.: 53.91%] [G loss: 0.816774]\n",
      "epoch:29 step:23007 [D loss: 0.679747, acc.: 62.50%] [G loss: 0.733988]\n",
      "epoch:29 step:23008 [D loss: 0.715012, acc.: 48.44%] [G loss: 0.789411]\n",
      "epoch:29 step:23009 [D loss: 0.711367, acc.: 50.00%] [G loss: 0.781803]\n",
      "epoch:29 step:23010 [D loss: 0.642249, acc.: 65.62%] [G loss: 0.823806]\n",
      "epoch:29 step:23011 [D loss: 0.636070, acc.: 67.19%] [G loss: 0.724083]\n",
      "epoch:29 step:23012 [D loss: 0.695595, acc.: 46.09%] [G loss: 0.765731]\n",
      "epoch:29 step:23013 [D loss: 0.728378, acc.: 46.88%] [G loss: 0.747273]\n",
      "epoch:29 step:23014 [D loss: 0.694599, acc.: 52.34%] [G loss: 0.749312]\n",
      "epoch:29 step:23015 [D loss: 0.651812, acc.: 64.84%] [G loss: 0.784494]\n",
      "epoch:29 step:23016 [D loss: 0.638553, acc.: 68.75%] [G loss: 0.755057]\n",
      "epoch:29 step:23017 [D loss: 0.675732, acc.: 53.91%] [G loss: 0.753780]\n",
      "epoch:29 step:23018 [D loss: 0.648981, acc.: 61.72%] [G loss: 0.802588]\n",
      "epoch:29 step:23019 [D loss: 0.689022, acc.: 50.00%] [G loss: 0.738800]\n",
      "epoch:29 step:23020 [D loss: 0.690281, acc.: 54.69%] [G loss: 0.777907]\n",
      "epoch:29 step:23021 [D loss: 0.650410, acc.: 67.19%] [G loss: 0.808453]\n",
      "epoch:29 step:23022 [D loss: 0.710826, acc.: 51.56%] [G loss: 0.832238]\n",
      "epoch:29 step:23023 [D loss: 0.613479, acc.: 67.97%] [G loss: 0.769581]\n",
      "epoch:29 step:23024 [D loss: 0.698463, acc.: 54.69%] [G loss: 0.731944]\n",
      "epoch:29 step:23025 [D loss: 0.639539, acc.: 69.53%] [G loss: 0.782405]\n",
      "epoch:29 step:23026 [D loss: 0.661657, acc.: 60.94%] [G loss: 0.770490]\n",
      "epoch:29 step:23027 [D loss: 0.678163, acc.: 60.16%] [G loss: 0.723745]\n",
      "epoch:29 step:23028 [D loss: 0.712021, acc.: 51.56%] [G loss: 0.727624]\n",
      "epoch:29 step:23029 [D loss: 0.726404, acc.: 45.31%] [G loss: 0.847475]\n",
      "epoch:29 step:23030 [D loss: 0.676930, acc.: 58.59%] [G loss: 0.806857]\n",
      "epoch:29 step:23031 [D loss: 0.692067, acc.: 52.34%] [G loss: 0.809667]\n",
      "epoch:29 step:23032 [D loss: 0.660528, acc.: 61.72%] [G loss: 0.768203]\n",
      "epoch:29 step:23033 [D loss: 0.692604, acc.: 50.78%] [G loss: 0.840302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23034 [D loss: 0.673113, acc.: 56.25%] [G loss: 0.787739]\n",
      "epoch:29 step:23035 [D loss: 0.686531, acc.: 50.00%] [G loss: 0.727005]\n",
      "epoch:29 step:23036 [D loss: 0.710444, acc.: 50.00%] [G loss: 0.754819]\n",
      "epoch:29 step:23037 [D loss: 0.713446, acc.: 48.44%] [G loss: 0.740110]\n",
      "epoch:29 step:23038 [D loss: 0.701737, acc.: 49.22%] [G loss: 0.889541]\n",
      "epoch:29 step:23039 [D loss: 0.690013, acc.: 49.22%] [G loss: 0.780794]\n",
      "epoch:29 step:23040 [D loss: 0.750769, acc.: 45.31%] [G loss: 0.821230]\n",
      "epoch:29 step:23041 [D loss: 0.691878, acc.: 58.59%] [G loss: 0.764830]\n",
      "epoch:29 step:23042 [D loss: 0.710536, acc.: 50.78%] [G loss: 0.690538]\n",
      "epoch:29 step:23043 [D loss: 0.720001, acc.: 46.88%] [G loss: 0.728669]\n",
      "epoch:29 step:23044 [D loss: 0.656994, acc.: 63.28%] [G loss: 0.776821]\n",
      "epoch:29 step:23045 [D loss: 0.712280, acc.: 46.09%] [G loss: 0.717566]\n",
      "epoch:29 step:23046 [D loss: 0.688585, acc.: 59.38%] [G loss: 0.836403]\n",
      "epoch:29 step:23047 [D loss: 0.671327, acc.: 59.38%] [G loss: 0.715562]\n",
      "epoch:29 step:23048 [D loss: 0.670850, acc.: 55.47%] [G loss: 0.720611]\n",
      "epoch:29 step:23049 [D loss: 0.699835, acc.: 50.00%] [G loss: 0.809605]\n",
      "epoch:29 step:23050 [D loss: 0.641898, acc.: 70.31%] [G loss: 0.770896]\n",
      "epoch:29 step:23051 [D loss: 0.603034, acc.: 80.47%] [G loss: 0.768291]\n",
      "epoch:29 step:23052 [D loss: 0.657278, acc.: 66.41%] [G loss: 0.776022]\n",
      "epoch:29 step:23053 [D loss: 0.685087, acc.: 52.34%] [G loss: 0.781495]\n",
      "epoch:29 step:23054 [D loss: 0.710695, acc.: 45.31%] [G loss: 0.726039]\n",
      "epoch:29 step:23055 [D loss: 0.650122, acc.: 61.72%] [G loss: 0.798414]\n",
      "epoch:29 step:23056 [D loss: 0.683875, acc.: 54.69%] [G loss: 0.748758]\n",
      "epoch:29 step:23057 [D loss: 0.705513, acc.: 50.78%] [G loss: 0.735938]\n",
      "epoch:29 step:23058 [D loss: 0.673544, acc.: 56.25%] [G loss: 0.687533]\n",
      "epoch:29 step:23059 [D loss: 0.679414, acc.: 60.16%] [G loss: 0.736634]\n",
      "epoch:29 step:23060 [D loss: 0.660970, acc.: 62.50%] [G loss: 0.751888]\n",
      "epoch:29 step:23061 [D loss: 0.709713, acc.: 49.22%] [G loss: 0.732999]\n",
      "epoch:29 step:23062 [D loss: 0.683997, acc.: 57.03%] [G loss: 0.682134]\n",
      "epoch:29 step:23063 [D loss: 0.698998, acc.: 53.91%] [G loss: 0.709643]\n",
      "epoch:29 step:23064 [D loss: 0.695940, acc.: 53.12%] [G loss: 0.717692]\n",
      "epoch:29 step:23065 [D loss: 0.730859, acc.: 46.88%] [G loss: 0.704639]\n",
      "epoch:29 step:23066 [D loss: 0.694083, acc.: 50.78%] [G loss: 0.841172]\n",
      "epoch:29 step:23067 [D loss: 0.663555, acc.: 62.50%] [G loss: 0.784166]\n",
      "epoch:29 step:23068 [D loss: 0.633154, acc.: 65.62%] [G loss: 0.785140]\n",
      "epoch:29 step:23069 [D loss: 0.728628, acc.: 42.97%] [G loss: 0.769362]\n",
      "epoch:29 step:23070 [D loss: 0.727644, acc.: 44.53%] [G loss: 0.709332]\n",
      "epoch:29 step:23071 [D loss: 0.723302, acc.: 42.97%] [G loss: 0.808419]\n",
      "epoch:29 step:23072 [D loss: 0.704373, acc.: 50.78%] [G loss: 0.726150]\n",
      "epoch:29 step:23073 [D loss: 0.681418, acc.: 60.94%] [G loss: 0.766937]\n",
      "epoch:29 step:23074 [D loss: 0.709216, acc.: 50.00%] [G loss: 0.723904]\n",
      "epoch:29 step:23075 [D loss: 0.738594, acc.: 48.44%] [G loss: 0.712149]\n",
      "epoch:29 step:23076 [D loss: 0.695687, acc.: 53.91%] [G loss: 0.738221]\n",
      "epoch:29 step:23077 [D loss: 0.686300, acc.: 54.69%] [G loss: 0.738057]\n",
      "epoch:29 step:23078 [D loss: 0.692074, acc.: 56.25%] [G loss: 0.720990]\n",
      "epoch:29 step:23079 [D loss: 0.647807, acc.: 67.97%] [G loss: 0.784455]\n",
      "epoch:29 step:23080 [D loss: 0.676260, acc.: 53.91%] [G loss: 0.855448]\n",
      "epoch:29 step:23081 [D loss: 0.683489, acc.: 57.03%] [G loss: 0.818450]\n",
      "epoch:29 step:23082 [D loss: 0.653612, acc.: 60.16%] [G loss: 0.810430]\n",
      "epoch:29 step:23083 [D loss: 0.730390, acc.: 44.53%] [G loss: 0.789941]\n",
      "epoch:29 step:23084 [D loss: 0.717217, acc.: 43.75%] [G loss: 0.780582]\n",
      "epoch:29 step:23085 [D loss: 0.701718, acc.: 53.12%] [G loss: 0.774374]\n",
      "epoch:29 step:23086 [D loss: 0.694457, acc.: 54.69%] [G loss: 0.801028]\n",
      "epoch:29 step:23087 [D loss: 0.706610, acc.: 46.09%] [G loss: 0.752004]\n",
      "epoch:29 step:23088 [D loss: 0.685044, acc.: 59.38%] [G loss: 0.767086]\n",
      "epoch:29 step:23089 [D loss: 0.742623, acc.: 44.53%] [G loss: 0.787854]\n",
      "epoch:29 step:23090 [D loss: 0.675015, acc.: 61.72%] [G loss: 0.783180]\n",
      "epoch:29 step:23091 [D loss: 0.722708, acc.: 43.75%] [G loss: 0.793569]\n",
      "epoch:29 step:23092 [D loss: 0.708926, acc.: 46.09%] [G loss: 0.837614]\n",
      "epoch:29 step:23093 [D loss: 0.690033, acc.: 55.47%] [G loss: 0.818861]\n",
      "epoch:29 step:23094 [D loss: 0.736092, acc.: 39.06%] [G loss: 0.811934]\n",
      "epoch:29 step:23095 [D loss: 0.710301, acc.: 43.75%] [G loss: 0.824620]\n",
      "epoch:29 step:23096 [D loss: 0.674828, acc.: 51.56%] [G loss: 0.754171]\n",
      "epoch:29 step:23097 [D loss: 0.641593, acc.: 64.06%] [G loss: 0.747160]\n",
      "epoch:29 step:23098 [D loss: 0.667027, acc.: 63.28%] [G loss: 0.701766]\n",
      "epoch:29 step:23099 [D loss: 0.677212, acc.: 59.38%] [G loss: 0.758225]\n",
      "epoch:29 step:23100 [D loss: 0.667459, acc.: 55.47%] [G loss: 0.784361]\n",
      "epoch:29 step:23101 [D loss: 0.678195, acc.: 57.03%] [G loss: 0.744577]\n",
      "epoch:29 step:23102 [D loss: 0.663863, acc.: 61.72%] [G loss: 0.719037]\n",
      "epoch:29 step:23103 [D loss: 0.690272, acc.: 53.91%] [G loss: 0.697412]\n",
      "epoch:29 step:23104 [D loss: 0.617246, acc.: 72.66%] [G loss: 0.768491]\n",
      "epoch:29 step:23105 [D loss: 0.628656, acc.: 71.09%] [G loss: 0.738447]\n",
      "epoch:29 step:23106 [D loss: 0.655221, acc.: 61.72%] [G loss: 0.716878]\n",
      "epoch:29 step:23107 [D loss: 0.702059, acc.: 48.44%] [G loss: 0.722344]\n",
      "epoch:29 step:23108 [D loss: 0.731500, acc.: 42.19%] [G loss: 0.707464]\n",
      "epoch:29 step:23109 [D loss: 0.711128, acc.: 45.31%] [G loss: 0.723736]\n",
      "epoch:29 step:23110 [D loss: 0.642372, acc.: 67.97%] [G loss: 0.699811]\n",
      "epoch:29 step:23111 [D loss: 0.694323, acc.: 49.22%] [G loss: 0.803360]\n",
      "epoch:29 step:23112 [D loss: 0.767160, acc.: 28.12%] [G loss: 0.696731]\n",
      "epoch:29 step:23113 [D loss: 0.651583, acc.: 65.62%] [G loss: 0.811571]\n",
      "epoch:29 step:23114 [D loss: 0.674524, acc.: 57.03%] [G loss: 0.796782]\n",
      "epoch:29 step:23115 [D loss: 0.621213, acc.: 72.66%] [G loss: 0.881297]\n",
      "epoch:29 step:23116 [D loss: 0.660695, acc.: 60.16%] [G loss: 0.816640]\n",
      "epoch:29 step:23117 [D loss: 0.678100, acc.: 53.91%] [G loss: 0.863149]\n",
      "epoch:29 step:23118 [D loss: 0.682473, acc.: 57.03%] [G loss: 0.845231]\n",
      "epoch:29 step:23119 [D loss: 0.733353, acc.: 40.62%] [G loss: 0.769210]\n",
      "epoch:29 step:23120 [D loss: 0.680360, acc.: 54.69%] [G loss: 0.831011]\n",
      "epoch:29 step:23121 [D loss: 0.693873, acc.: 52.34%] [G loss: 0.808094]\n",
      "epoch:29 step:23122 [D loss: 0.733284, acc.: 46.88%] [G loss: 0.738946]\n",
      "epoch:29 step:23123 [D loss: 0.671203, acc.: 57.03%] [G loss: 0.831353]\n",
      "epoch:29 step:23124 [D loss: 0.684459, acc.: 54.69%] [G loss: 0.816936]\n",
      "epoch:29 step:23125 [D loss: 0.663492, acc.: 59.38%] [G loss: 0.761561]\n",
      "epoch:29 step:23126 [D loss: 0.718301, acc.: 50.00%] [G loss: 0.807091]\n",
      "epoch:29 step:23127 [D loss: 0.669828, acc.: 66.41%] [G loss: 0.798915]\n",
      "epoch:29 step:23128 [D loss: 0.696812, acc.: 49.22%] [G loss: 0.810706]\n",
      "epoch:29 step:23129 [D loss: 0.671909, acc.: 54.69%] [G loss: 0.781380]\n",
      "epoch:29 step:23130 [D loss: 0.682331, acc.: 56.25%] [G loss: 0.796008]\n",
      "epoch:29 step:23131 [D loss: 0.704820, acc.: 54.69%] [G loss: 0.729606]\n",
      "epoch:29 step:23132 [D loss: 0.723320, acc.: 46.88%] [G loss: 0.716668]\n",
      "epoch:29 step:23133 [D loss: 0.662797, acc.: 57.03%] [G loss: 0.711834]\n",
      "epoch:29 step:23134 [D loss: 0.717654, acc.: 52.34%] [G loss: 0.732337]\n",
      "epoch:29 step:23135 [D loss: 0.686581, acc.: 53.12%] [G loss: 0.770020]\n",
      "epoch:29 step:23136 [D loss: 0.726700, acc.: 45.31%] [G loss: 0.745766]\n",
      "epoch:29 step:23137 [D loss: 0.677874, acc.: 56.25%] [G loss: 0.762530]\n",
      "epoch:29 step:23138 [D loss: 0.665583, acc.: 64.84%] [G loss: 0.742383]\n",
      "epoch:29 step:23139 [D loss: 0.698908, acc.: 50.78%] [G loss: 0.772707]\n",
      "epoch:29 step:23140 [D loss: 0.704597, acc.: 47.66%] [G loss: 0.798856]\n",
      "epoch:29 step:23141 [D loss: 0.691384, acc.: 54.69%] [G loss: 0.785301]\n",
      "epoch:29 step:23142 [D loss: 0.660903, acc.: 62.50%] [G loss: 0.745080]\n",
      "epoch:29 step:23143 [D loss: 0.672154, acc.: 60.16%] [G loss: 0.767744]\n",
      "epoch:29 step:23144 [D loss: 0.685380, acc.: 58.59%] [G loss: 0.738811]\n",
      "epoch:29 step:23145 [D loss: 0.672290, acc.: 59.38%] [G loss: 0.800573]\n",
      "epoch:29 step:23146 [D loss: 0.665135, acc.: 64.84%] [G loss: 0.735759]\n",
      "epoch:29 step:23147 [D loss: 0.702743, acc.: 54.69%] [G loss: 0.845683]\n",
      "epoch:29 step:23148 [D loss: 0.646231, acc.: 64.84%] [G loss: 0.734601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23149 [D loss: 0.693592, acc.: 56.25%] [G loss: 0.787048]\n",
      "epoch:29 step:23150 [D loss: 0.695363, acc.: 50.00%] [G loss: 0.796642]\n",
      "epoch:29 step:23151 [D loss: 0.653810, acc.: 60.16%] [G loss: 0.802730]\n",
      "epoch:29 step:23152 [D loss: 0.676325, acc.: 57.81%] [G loss: 0.882421]\n",
      "epoch:29 step:23153 [D loss: 0.703605, acc.: 49.22%] [G loss: 0.777698]\n",
      "epoch:29 step:23154 [D loss: 0.645269, acc.: 63.28%] [G loss: 0.812683]\n",
      "epoch:29 step:23155 [D loss: 0.701565, acc.: 46.88%] [G loss: 0.801770]\n",
      "epoch:29 step:23156 [D loss: 0.750578, acc.: 39.06%] [G loss: 0.733493]\n",
      "epoch:29 step:23157 [D loss: 0.729187, acc.: 45.31%] [G loss: 0.752007]\n",
      "epoch:29 step:23158 [D loss: 0.648480, acc.: 60.94%] [G loss: 0.743302]\n",
      "epoch:29 step:23159 [D loss: 0.676874, acc.: 53.12%] [G loss: 0.774054]\n",
      "epoch:29 step:23160 [D loss: 0.654599, acc.: 63.28%] [G loss: 0.735986]\n",
      "epoch:29 step:23161 [D loss: 0.692690, acc.: 53.12%] [G loss: 0.732708]\n",
      "epoch:29 step:23162 [D loss: 0.702089, acc.: 46.09%] [G loss: 0.714776]\n",
      "epoch:29 step:23163 [D loss: 0.704330, acc.: 45.31%] [G loss: 0.688582]\n",
      "epoch:29 step:23164 [D loss: 0.698532, acc.: 54.69%] [G loss: 0.762450]\n",
      "epoch:29 step:23165 [D loss: 0.698587, acc.: 53.91%] [G loss: 0.734548]\n",
      "epoch:29 step:23166 [D loss: 0.640181, acc.: 65.62%] [G loss: 0.772086]\n",
      "epoch:29 step:23167 [D loss: 0.652892, acc.: 63.28%] [G loss: 0.730906]\n",
      "epoch:29 step:23168 [D loss: 0.708094, acc.: 53.12%] [G loss: 0.764624]\n",
      "epoch:29 step:23169 [D loss: 0.644084, acc.: 64.84%] [G loss: 0.808980]\n",
      "epoch:29 step:23170 [D loss: 0.631903, acc.: 64.84%] [G loss: 0.785910]\n",
      "epoch:29 step:23171 [D loss: 0.720812, acc.: 51.56%] [G loss: 0.777098]\n",
      "epoch:29 step:23172 [D loss: 0.655600, acc.: 67.19%] [G loss: 0.736276]\n",
      "epoch:29 step:23173 [D loss: 0.710323, acc.: 53.12%] [G loss: 0.808271]\n",
      "epoch:29 step:23174 [D loss: 0.654488, acc.: 61.72%] [G loss: 0.844185]\n",
      "epoch:29 step:23175 [D loss: 0.718370, acc.: 43.75%] [G loss: 0.699320]\n",
      "epoch:29 step:23176 [D loss: 0.686844, acc.: 61.72%] [G loss: 0.709320]\n",
      "epoch:29 step:23177 [D loss: 0.696008, acc.: 53.91%] [G loss: 0.678899]\n",
      "epoch:29 step:23178 [D loss: 0.656173, acc.: 60.16%] [G loss: 0.828698]\n",
      "epoch:29 step:23179 [D loss: 0.676207, acc.: 58.59%] [G loss: 0.764643]\n",
      "epoch:29 step:23180 [D loss: 0.665459, acc.: 67.97%] [G loss: 0.771394]\n",
      "epoch:29 step:23181 [D loss: 0.678517, acc.: 48.44%] [G loss: 0.784910]\n",
      "epoch:29 step:23182 [D loss: 0.762022, acc.: 36.72%] [G loss: 0.762859]\n",
      "epoch:29 step:23183 [D loss: 0.653334, acc.: 64.84%] [G loss: 0.843466]\n",
      "epoch:29 step:23184 [D loss: 0.602257, acc.: 78.91%] [G loss: 0.780359]\n",
      "epoch:29 step:23185 [D loss: 0.725511, acc.: 42.97%] [G loss: 0.840050]\n",
      "epoch:29 step:23186 [D loss: 0.711611, acc.: 48.44%] [G loss: 0.781794]\n",
      "epoch:29 step:23187 [D loss: 0.650974, acc.: 65.62%] [G loss: 0.775450]\n",
      "epoch:29 step:23188 [D loss: 0.738787, acc.: 40.62%] [G loss: 0.792069]\n",
      "epoch:29 step:23189 [D loss: 0.699215, acc.: 54.69%] [G loss: 0.839152]\n",
      "epoch:29 step:23190 [D loss: 0.688636, acc.: 56.25%] [G loss: 0.850322]\n",
      "epoch:29 step:23191 [D loss: 0.690594, acc.: 51.56%] [G loss: 0.780550]\n",
      "epoch:29 step:23192 [D loss: 0.704547, acc.: 42.97%] [G loss: 0.783859]\n",
      "epoch:29 step:23193 [D loss: 0.702379, acc.: 51.56%] [G loss: 0.798568]\n",
      "epoch:29 step:23194 [D loss: 0.640371, acc.: 63.28%] [G loss: 0.737462]\n",
      "epoch:29 step:23195 [D loss: 0.693226, acc.: 56.25%] [G loss: 0.797918]\n",
      "epoch:29 step:23196 [D loss: 0.663866, acc.: 63.28%] [G loss: 0.797517]\n",
      "epoch:29 step:23197 [D loss: 0.685111, acc.: 50.78%] [G loss: 0.846291]\n",
      "epoch:29 step:23198 [D loss: 0.705664, acc.: 50.78%] [G loss: 0.814222]\n",
      "epoch:29 step:23199 [D loss: 0.710263, acc.: 47.66%] [G loss: 0.761805]\n",
      "epoch:29 step:23200 [D loss: 0.705378, acc.: 48.44%] [G loss: 0.765385]\n",
      "epoch:29 step:23201 [D loss: 0.713425, acc.: 48.44%] [G loss: 0.853779]\n",
      "epoch:29 step:23202 [D loss: 0.658195, acc.: 57.03%] [G loss: 0.865778]\n",
      "epoch:29 step:23203 [D loss: 0.653982, acc.: 64.06%] [G loss: 0.793597]\n",
      "epoch:29 step:23204 [D loss: 0.674698, acc.: 59.38%] [G loss: 0.814764]\n",
      "epoch:29 step:23205 [D loss: 0.680194, acc.: 51.56%] [G loss: 0.769424]\n",
      "epoch:29 step:23206 [D loss: 0.668970, acc.: 49.22%] [G loss: 0.796244]\n",
      "epoch:29 step:23207 [D loss: 0.612574, acc.: 71.88%] [G loss: 0.807793]\n",
      "epoch:29 step:23208 [D loss: 0.671391, acc.: 55.47%] [G loss: 0.850082]\n",
      "epoch:29 step:23209 [D loss: 0.683105, acc.: 58.59%] [G loss: 0.791332]\n",
      "epoch:29 step:23210 [D loss: 0.741580, acc.: 42.97%] [G loss: 0.760294]\n",
      "epoch:29 step:23211 [D loss: 0.651014, acc.: 66.41%] [G loss: 0.760960]\n",
      "epoch:29 step:23212 [D loss: 0.683261, acc.: 56.25%] [G loss: 0.708292]\n",
      "epoch:29 step:23213 [D loss: 0.686546, acc.: 55.47%] [G loss: 0.754289]\n",
      "epoch:29 step:23214 [D loss: 0.719821, acc.: 50.00%] [G loss: 0.740198]\n",
      "epoch:29 step:23215 [D loss: 0.671462, acc.: 63.28%] [G loss: 0.797143]\n",
      "epoch:29 step:23216 [D loss: 0.637497, acc.: 69.53%] [G loss: 0.786792]\n",
      "epoch:29 step:23217 [D loss: 0.651839, acc.: 62.50%] [G loss: 0.791030]\n",
      "epoch:29 step:23218 [D loss: 0.694869, acc.: 53.91%] [G loss: 0.799183]\n",
      "epoch:29 step:23219 [D loss: 0.637086, acc.: 67.19%] [G loss: 0.781534]\n",
      "epoch:29 step:23220 [D loss: 0.650629, acc.: 65.62%] [G loss: 0.843520]\n",
      "epoch:29 step:23221 [D loss: 0.726912, acc.: 43.75%] [G loss: 0.761528]\n",
      "epoch:29 step:23222 [D loss: 0.739770, acc.: 42.19%] [G loss: 0.724429]\n",
      "epoch:29 step:23223 [D loss: 0.742103, acc.: 44.53%] [G loss: 0.702004]\n",
      "epoch:29 step:23224 [D loss: 0.728070, acc.: 50.00%] [G loss: 0.743636]\n",
      "epoch:29 step:23225 [D loss: 0.697458, acc.: 54.69%] [G loss: 0.845036]\n",
      "epoch:29 step:23226 [D loss: 0.730021, acc.: 41.41%] [G loss: 0.751179]\n",
      "epoch:29 step:23227 [D loss: 0.706093, acc.: 54.69%] [G loss: 0.764054]\n",
      "epoch:29 step:23228 [D loss: 0.685072, acc.: 51.56%] [G loss: 0.720739]\n",
      "epoch:29 step:23229 [D loss: 0.713358, acc.: 44.53%] [G loss: 0.777273]\n",
      "epoch:29 step:23230 [D loss: 0.696694, acc.: 46.88%] [G loss: 0.771146]\n",
      "epoch:29 step:23231 [D loss: 0.691093, acc.: 51.56%] [G loss: 0.774417]\n",
      "epoch:29 step:23232 [D loss: 0.670956, acc.: 64.84%] [G loss: 0.766807]\n",
      "epoch:29 step:23233 [D loss: 0.664433, acc.: 60.94%] [G loss: 0.757705]\n",
      "epoch:29 step:23234 [D loss: 0.694812, acc.: 50.00%] [G loss: 0.753985]\n",
      "epoch:29 step:23235 [D loss: 0.683735, acc.: 58.59%] [G loss: 0.705430]\n",
      "epoch:29 step:23236 [D loss: 0.675457, acc.: 58.59%] [G loss: 0.752638]\n",
      "epoch:29 step:23237 [D loss: 0.704013, acc.: 48.44%] [G loss: 0.724742]\n",
      "epoch:29 step:23238 [D loss: 0.655426, acc.: 63.28%] [G loss: 0.787239]\n",
      "epoch:29 step:23239 [D loss: 0.711621, acc.: 50.78%] [G loss: 0.807232]\n",
      "epoch:29 step:23240 [D loss: 0.679340, acc.: 60.16%] [G loss: 0.760763]\n",
      "epoch:29 step:23241 [D loss: 0.707868, acc.: 52.34%] [G loss: 0.814860]\n",
      "epoch:29 step:23242 [D loss: 0.723547, acc.: 46.09%] [G loss: 0.736231]\n",
      "epoch:29 step:23243 [D loss: 0.665550, acc.: 57.03%] [G loss: 0.768895]\n",
      "epoch:29 step:23244 [D loss: 0.639576, acc.: 64.84%] [G loss: 0.793987]\n",
      "epoch:29 step:23245 [D loss: 0.657109, acc.: 63.28%] [G loss: 0.832713]\n",
      "epoch:29 step:23246 [D loss: 0.656416, acc.: 63.28%] [G loss: 0.742755]\n",
      "epoch:29 step:23247 [D loss: 0.691283, acc.: 50.78%] [G loss: 0.687907]\n",
      "epoch:29 step:23248 [D loss: 0.739568, acc.: 42.19%] [G loss: 0.748672]\n",
      "epoch:29 step:23249 [D loss: 0.727144, acc.: 48.44%] [G loss: 0.748367]\n",
      "epoch:29 step:23250 [D loss: 0.705344, acc.: 42.97%] [G loss: 0.843189]\n",
      "epoch:29 step:23251 [D loss: 0.695253, acc.: 52.34%] [G loss: 0.870287]\n",
      "epoch:29 step:23252 [D loss: 0.702673, acc.: 50.00%] [G loss: 0.783548]\n",
      "epoch:29 step:23253 [D loss: 0.676801, acc.: 57.03%] [G loss: 0.757934]\n",
      "epoch:29 step:23254 [D loss: 0.718507, acc.: 43.75%] [G loss: 0.802259]\n",
      "epoch:29 step:23255 [D loss: 0.728212, acc.: 43.75%] [G loss: 0.780306]\n",
      "epoch:29 step:23256 [D loss: 0.668682, acc.: 57.81%] [G loss: 0.768886]\n",
      "epoch:29 step:23257 [D loss: 0.654104, acc.: 61.72%] [G loss: 0.749231]\n",
      "epoch:29 step:23258 [D loss: 0.721913, acc.: 47.66%] [G loss: 0.781529]\n",
      "epoch:29 step:23259 [D loss: 0.698017, acc.: 43.75%] [G loss: 0.791770]\n",
      "epoch:29 step:23260 [D loss: 0.702628, acc.: 41.41%] [G loss: 0.743407]\n",
      "epoch:29 step:23261 [D loss: 0.726458, acc.: 44.53%] [G loss: 0.734626]\n",
      "epoch:29 step:23262 [D loss: 0.719159, acc.: 43.75%] [G loss: 0.746636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23263 [D loss: 0.684846, acc.: 53.91%] [G loss: 0.710331]\n",
      "epoch:29 step:23264 [D loss: 0.728305, acc.: 44.53%] [G loss: 0.788290]\n",
      "epoch:29 step:23265 [D loss: 0.671493, acc.: 60.16%] [G loss: 0.776803]\n",
      "epoch:29 step:23266 [D loss: 0.717326, acc.: 51.56%] [G loss: 0.779772]\n",
      "epoch:29 step:23267 [D loss: 0.650506, acc.: 67.19%] [G loss: 0.765190]\n",
      "epoch:29 step:23268 [D loss: 0.662720, acc.: 60.94%] [G loss: 0.845166]\n",
      "epoch:29 step:23269 [D loss: 0.697305, acc.: 52.34%] [G loss: 0.827473]\n",
      "epoch:29 step:23270 [D loss: 0.703786, acc.: 53.91%] [G loss: 0.828709]\n",
      "epoch:29 step:23271 [D loss: 0.679903, acc.: 57.81%] [G loss: 0.789054]\n",
      "epoch:29 step:23272 [D loss: 0.679756, acc.: 53.91%] [G loss: 0.771452]\n",
      "epoch:29 step:23273 [D loss: 0.674452, acc.: 55.47%] [G loss: 0.770121]\n",
      "epoch:29 step:23274 [D loss: 0.705146, acc.: 49.22%] [G loss: 0.712179]\n",
      "epoch:29 step:23275 [D loss: 0.697050, acc.: 56.25%] [G loss: 0.751058]\n",
      "epoch:29 step:23276 [D loss: 0.734846, acc.: 40.62%] [G loss: 0.737162]\n",
      "epoch:29 step:23277 [D loss: 0.603540, acc.: 77.34%] [G loss: 0.803743]\n",
      "epoch:29 step:23278 [D loss: 0.649202, acc.: 61.72%] [G loss: 0.906073]\n",
      "epoch:29 step:23279 [D loss: 0.645860, acc.: 62.50%] [G loss: 0.756527]\n",
      "epoch:29 step:23280 [D loss: 0.698517, acc.: 49.22%] [G loss: 0.760211]\n",
      "epoch:29 step:23281 [D loss: 0.692533, acc.: 52.34%] [G loss: 0.754320]\n",
      "epoch:29 step:23282 [D loss: 0.708901, acc.: 48.44%] [G loss: 0.738152]\n",
      "epoch:29 step:23283 [D loss: 0.724068, acc.: 50.00%] [G loss: 0.731410]\n",
      "epoch:29 step:23284 [D loss: 0.680893, acc.: 53.91%] [G loss: 0.697081]\n",
      "epoch:29 step:23285 [D loss: 0.672763, acc.: 59.38%] [G loss: 0.757818]\n",
      "epoch:29 step:23286 [D loss: 0.706182, acc.: 51.56%] [G loss: 0.762384]\n",
      "epoch:29 step:23287 [D loss: 0.746581, acc.: 44.53%] [G loss: 0.741570]\n",
      "epoch:29 step:23288 [D loss: 0.667457, acc.: 60.16%] [G loss: 0.721069]\n",
      "epoch:29 step:23289 [D loss: 0.682768, acc.: 55.47%] [G loss: 0.738857]\n",
      "epoch:29 step:23290 [D loss: 0.663109, acc.: 61.72%] [G loss: 0.718104]\n",
      "epoch:29 step:23291 [D loss: 0.690478, acc.: 53.91%] [G loss: 0.780232]\n",
      "epoch:29 step:23292 [D loss: 0.707345, acc.: 49.22%] [G loss: 0.756265]\n",
      "epoch:29 step:23293 [D loss: 0.689161, acc.: 51.56%] [G loss: 0.687608]\n",
      "epoch:29 step:23294 [D loss: 0.741245, acc.: 36.72%] [G loss: 0.737992]\n",
      "epoch:29 step:23295 [D loss: 0.677007, acc.: 56.25%] [G loss: 0.906689]\n",
      "epoch:29 step:23296 [D loss: 0.696519, acc.: 53.12%] [G loss: 0.829144]\n",
      "epoch:29 step:23297 [D loss: 0.653453, acc.: 60.16%] [G loss: 0.843458]\n",
      "epoch:29 step:23298 [D loss: 0.679505, acc.: 53.91%] [G loss: 0.869131]\n",
      "epoch:29 step:23299 [D loss: 0.664858, acc.: 60.16%] [G loss: 0.836529]\n",
      "epoch:29 step:23300 [D loss: 0.711011, acc.: 50.00%] [G loss: 0.795461]\n",
      "epoch:29 step:23301 [D loss: 0.666664, acc.: 62.50%] [G loss: 0.770857]\n",
      "epoch:29 step:23302 [D loss: 0.689343, acc.: 58.59%] [G loss: 0.731343]\n",
      "epoch:29 step:23303 [D loss: 0.654284, acc.: 64.84%] [G loss: 0.753333]\n",
      "epoch:29 step:23304 [D loss: 0.698164, acc.: 55.47%] [G loss: 0.694071]\n",
      "epoch:29 step:23305 [D loss: 0.682183, acc.: 58.59%] [G loss: 0.650586]\n",
      "epoch:29 step:23306 [D loss: 0.715527, acc.: 45.31%] [G loss: 0.709712]\n",
      "epoch:29 step:23307 [D loss: 0.696313, acc.: 46.88%] [G loss: 0.826050]\n",
      "epoch:29 step:23308 [D loss: 0.668290, acc.: 58.59%] [G loss: 0.823161]\n",
      "epoch:29 step:23309 [D loss: 0.807427, acc.: 21.88%] [G loss: 0.785221]\n",
      "epoch:29 step:23310 [D loss: 0.680942, acc.: 56.25%] [G loss: 0.782380]\n",
      "epoch:29 step:23311 [D loss: 0.674853, acc.: 57.03%] [G loss: 0.792045]\n",
      "epoch:29 step:23312 [D loss: 0.646066, acc.: 65.62%] [G loss: 0.868680]\n",
      "epoch:29 step:23313 [D loss: 0.697973, acc.: 51.56%] [G loss: 0.800731]\n",
      "epoch:29 step:23314 [D loss: 0.689336, acc.: 57.81%] [G loss: 0.739850]\n",
      "epoch:29 step:23315 [D loss: 0.687601, acc.: 57.81%] [G loss: 0.824533]\n",
      "epoch:29 step:23316 [D loss: 0.635819, acc.: 68.75%] [G loss: 0.822784]\n",
      "epoch:29 step:23317 [D loss: 0.708247, acc.: 50.00%] [G loss: 0.681872]\n",
      "epoch:29 step:23318 [D loss: 0.679074, acc.: 48.44%] [G loss: 0.795766]\n",
      "epoch:29 step:23319 [D loss: 0.710369, acc.: 46.88%] [G loss: 0.811712]\n",
      "epoch:29 step:23320 [D loss: 0.724581, acc.: 46.88%] [G loss: 0.742043]\n",
      "epoch:29 step:23321 [D loss: 0.693470, acc.: 51.56%] [G loss: 0.743036]\n",
      "epoch:29 step:23322 [D loss: 0.635294, acc.: 70.31%] [G loss: 0.843953]\n",
      "epoch:29 step:23323 [D loss: 0.717856, acc.: 45.31%] [G loss: 0.776532]\n",
      "epoch:29 step:23324 [D loss: 0.679248, acc.: 54.69%] [G loss: 0.806704]\n",
      "epoch:29 step:23325 [D loss: 0.698620, acc.: 50.78%] [G loss: 0.800020]\n",
      "epoch:29 step:23326 [D loss: 0.712695, acc.: 45.31%] [G loss: 0.763533]\n",
      "epoch:29 step:23327 [D loss: 0.686298, acc.: 53.12%] [G loss: 0.768557]\n",
      "epoch:29 step:23328 [D loss: 0.675555, acc.: 55.47%] [G loss: 0.691221]\n",
      "epoch:29 step:23329 [D loss: 0.705558, acc.: 48.44%] [G loss: 0.753786]\n",
      "epoch:29 step:23330 [D loss: 0.710480, acc.: 57.81%] [G loss: 0.793126]\n",
      "epoch:29 step:23331 [D loss: 0.652284, acc.: 62.50%] [G loss: 0.773118]\n",
      "epoch:29 step:23332 [D loss: 0.646223, acc.: 66.41%] [G loss: 0.767848]\n",
      "epoch:29 step:23333 [D loss: 0.675951, acc.: 60.16%] [G loss: 0.774546]\n",
      "epoch:29 step:23334 [D loss: 0.714298, acc.: 47.66%] [G loss: 0.747092]\n",
      "epoch:29 step:23335 [D loss: 0.689246, acc.: 55.47%] [G loss: 0.750720]\n",
      "epoch:29 step:23336 [D loss: 0.719803, acc.: 43.75%] [G loss: 0.783687]\n",
      "epoch:29 step:23337 [D loss: 0.728378, acc.: 47.66%] [G loss: 0.688918]\n",
      "epoch:29 step:23338 [D loss: 0.723215, acc.: 50.00%] [G loss: 0.780592]\n",
      "epoch:29 step:23339 [D loss: 0.668333, acc.: 60.94%] [G loss: 0.718423]\n",
      "epoch:29 step:23340 [D loss: 0.718810, acc.: 42.97%] [G loss: 0.761395]\n",
      "epoch:29 step:23341 [D loss: 0.716962, acc.: 46.88%] [G loss: 0.745623]\n",
      "epoch:29 step:23342 [D loss: 0.760934, acc.: 42.97%] [G loss: 0.684837]\n",
      "epoch:29 step:23343 [D loss: 0.648931, acc.: 63.28%] [G loss: 0.744716]\n",
      "epoch:29 step:23344 [D loss: 0.686644, acc.: 58.59%] [G loss: 0.698062]\n",
      "epoch:29 step:23345 [D loss: 0.679054, acc.: 54.69%] [G loss: 0.781045]\n",
      "epoch:29 step:23346 [D loss: 0.688610, acc.: 57.03%] [G loss: 0.749085]\n",
      "epoch:29 step:23347 [D loss: 0.627223, acc.: 68.75%] [G loss: 0.772301]\n",
      "epoch:29 step:23348 [D loss: 0.712971, acc.: 47.66%] [G loss: 0.752534]\n",
      "epoch:29 step:23349 [D loss: 0.644857, acc.: 64.84%] [G loss: 0.803064]\n",
      "epoch:29 step:23350 [D loss: 0.659122, acc.: 63.28%] [G loss: 0.793162]\n",
      "epoch:29 step:23351 [D loss: 0.711547, acc.: 47.66%] [G loss: 0.757385]\n",
      "epoch:29 step:23352 [D loss: 0.725725, acc.: 48.44%] [G loss: 0.705374]\n",
      "epoch:29 step:23353 [D loss: 0.667801, acc.: 64.06%] [G loss: 0.763629]\n",
      "epoch:29 step:23354 [D loss: 0.709780, acc.: 54.69%] [G loss: 0.708818]\n",
      "epoch:29 step:23355 [D loss: 0.635387, acc.: 65.62%] [G loss: 0.798986]\n",
      "epoch:29 step:23356 [D loss: 0.697662, acc.: 50.78%] [G loss: 0.712485]\n",
      "epoch:29 step:23357 [D loss: 0.684784, acc.: 52.34%] [G loss: 0.699366]\n",
      "epoch:29 step:23358 [D loss: 0.705482, acc.: 52.34%] [G loss: 0.663712]\n",
      "epoch:29 step:23359 [D loss: 0.714391, acc.: 55.47%] [G loss: 0.832880]\n",
      "epoch:29 step:23360 [D loss: 0.681432, acc.: 57.81%] [G loss: 0.790198]\n",
      "epoch:29 step:23361 [D loss: 0.681791, acc.: 55.47%] [G loss: 0.757628]\n",
      "epoch:29 step:23362 [D loss: 0.675210, acc.: 56.25%] [G loss: 0.788642]\n",
      "epoch:29 step:23363 [D loss: 0.695453, acc.: 53.12%] [G loss: 0.820317]\n",
      "epoch:29 step:23364 [D loss: 0.660933, acc.: 58.59%] [G loss: 0.783286]\n",
      "epoch:29 step:23365 [D loss: 0.694809, acc.: 57.81%] [G loss: 0.748084]\n",
      "epoch:29 step:23366 [D loss: 0.730668, acc.: 49.22%] [G loss: 0.745811]\n",
      "epoch:29 step:23367 [D loss: 0.650777, acc.: 60.16%] [G loss: 0.812703]\n",
      "epoch:29 step:23368 [D loss: 0.685092, acc.: 57.03%] [G loss: 0.771964]\n",
      "epoch:29 step:23369 [D loss: 0.734303, acc.: 41.41%] [G loss: 0.731626]\n",
      "epoch:29 step:23370 [D loss: 0.708144, acc.: 44.53%] [G loss: 0.797033]\n",
      "epoch:29 step:23371 [D loss: 0.659302, acc.: 65.62%] [G loss: 0.785904]\n",
      "epoch:29 step:23372 [D loss: 0.745495, acc.: 37.50%] [G loss: 0.737218]\n",
      "epoch:29 step:23373 [D loss: 0.695181, acc.: 50.00%] [G loss: 0.747512]\n",
      "epoch:29 step:23374 [D loss: 0.694919, acc.: 51.56%] [G loss: 0.749683]\n",
      "epoch:29 step:23375 [D loss: 0.693501, acc.: 55.47%] [G loss: 0.712444]\n",
      "epoch:29 step:23376 [D loss: 0.657629, acc.: 62.50%] [G loss: 0.795839]\n",
      "epoch:29 step:23377 [D loss: 0.679218, acc.: 60.94%] [G loss: 0.719270]\n",
      "epoch:29 step:23378 [D loss: 0.694537, acc.: 53.12%] [G loss: 0.718688]\n",
      "epoch:29 step:23379 [D loss: 0.684204, acc.: 55.47%] [G loss: 0.724137]\n",
      "epoch:29 step:23380 [D loss: 0.676627, acc.: 55.47%] [G loss: 0.745544]\n",
      "epoch:29 step:23381 [D loss: 0.701773, acc.: 51.56%] [G loss: 0.752667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23382 [D loss: 0.704168, acc.: 52.34%] [G loss: 0.698086]\n",
      "epoch:29 step:23383 [D loss: 0.721163, acc.: 51.56%] [G loss: 0.758939]\n",
      "epoch:29 step:23384 [D loss: 0.673681, acc.: 59.38%] [G loss: 0.759634]\n",
      "epoch:29 step:23385 [D loss: 0.692836, acc.: 51.56%] [G loss: 0.758798]\n",
      "epoch:29 step:23386 [D loss: 0.685909, acc.: 53.12%] [G loss: 0.776344]\n",
      "epoch:29 step:23387 [D loss: 0.650501, acc.: 69.53%] [G loss: 0.764060]\n",
      "epoch:29 step:23388 [D loss: 0.663304, acc.: 60.16%] [G loss: 0.736475]\n",
      "epoch:29 step:23389 [D loss: 0.650004, acc.: 63.28%] [G loss: 0.781617]\n",
      "epoch:29 step:23390 [D loss: 0.676647, acc.: 56.25%] [G loss: 0.859228]\n",
      "epoch:29 step:23391 [D loss: 0.657990, acc.: 62.50%] [G loss: 0.806628]\n",
      "epoch:29 step:23392 [D loss: 0.695174, acc.: 53.12%] [G loss: 0.769959]\n",
      "epoch:29 step:23393 [D loss: 0.684286, acc.: 55.47%] [G loss: 0.786451]\n",
      "epoch:29 step:23394 [D loss: 0.715732, acc.: 42.19%] [G loss: 0.771803]\n",
      "epoch:29 step:23395 [D loss: 0.698866, acc.: 47.66%] [G loss: 0.778775]\n",
      "epoch:29 step:23396 [D loss: 0.733759, acc.: 42.19%] [G loss: 0.720534]\n",
      "epoch:29 step:23397 [D loss: 0.740112, acc.: 42.97%] [G loss: 0.735168]\n",
      "epoch:29 step:23398 [D loss: 0.751167, acc.: 40.62%] [G loss: 0.728785]\n",
      "epoch:29 step:23399 [D loss: 0.709773, acc.: 46.88%] [G loss: 0.834818]\n",
      "epoch:29 step:23400 [D loss: 0.700204, acc.: 57.81%] [G loss: 0.837198]\n",
      "epoch:29 step:23401 [D loss: 0.717495, acc.: 45.31%] [G loss: 0.743635]\n",
      "epoch:29 step:23402 [D loss: 0.652151, acc.: 61.72%] [G loss: 0.750710]\n",
      "epoch:29 step:23403 [D loss: 0.664612, acc.: 59.38%] [G loss: 0.781889]\n",
      "epoch:29 step:23404 [D loss: 0.704851, acc.: 47.66%] [G loss: 0.764483]\n",
      "epoch:29 step:23405 [D loss: 0.700522, acc.: 46.09%] [G loss: 0.744370]\n",
      "epoch:29 step:23406 [D loss: 0.718166, acc.: 39.06%] [G loss: 0.765455]\n",
      "epoch:29 step:23407 [D loss: 0.684214, acc.: 54.69%] [G loss: 0.776991]\n",
      "epoch:29 step:23408 [D loss: 0.705614, acc.: 50.78%] [G loss: 0.795210]\n",
      "epoch:29 step:23409 [D loss: 0.749470, acc.: 46.88%] [G loss: 0.799170]\n",
      "epoch:29 step:23410 [D loss: 0.676164, acc.: 57.03%] [G loss: 0.828226]\n",
      "epoch:29 step:23411 [D loss: 0.684356, acc.: 53.12%] [G loss: 0.864588]\n",
      "epoch:29 step:23412 [D loss: 0.689997, acc.: 56.25%] [G loss: 0.819300]\n",
      "epoch:29 step:23413 [D loss: 0.727634, acc.: 41.41%] [G loss: 0.817377]\n",
      "epoch:29 step:23414 [D loss: 0.656157, acc.: 64.06%] [G loss: 0.842739]\n",
      "epoch:29 step:23415 [D loss: 0.662902, acc.: 60.16%] [G loss: 0.827523]\n",
      "epoch:29 step:23416 [D loss: 0.672783, acc.: 68.75%] [G loss: 0.845948]\n",
      "epoch:29 step:23417 [D loss: 0.669983, acc.: 60.16%] [G loss: 0.842350]\n",
      "epoch:29 step:23418 [D loss: 0.675565, acc.: 58.59%] [G loss: 0.747589]\n",
      "epoch:29 step:23419 [D loss: 0.678282, acc.: 60.94%] [G loss: 0.823943]\n",
      "epoch:29 step:23420 [D loss: 0.698175, acc.: 53.12%] [G loss: 0.807033]\n",
      "epoch:29 step:23421 [D loss: 0.700849, acc.: 50.78%] [G loss: 0.831527]\n",
      "epoch:29 step:23422 [D loss: 0.703608, acc.: 50.00%] [G loss: 0.744772]\n",
      "epoch:29 step:23423 [D loss: 0.691704, acc.: 50.00%] [G loss: 0.704829]\n",
      "epoch:29 step:23424 [D loss: 0.656472, acc.: 64.06%] [G loss: 0.778104]\n",
      "epoch:29 step:23425 [D loss: 0.634824, acc.: 71.09%] [G loss: 0.766446]\n",
      "epoch:29 step:23426 [D loss: 0.703013, acc.: 55.47%] [G loss: 0.730914]\n",
      "epoch:29 step:23427 [D loss: 0.683191, acc.: 56.25%] [G loss: 0.752158]\n",
      "epoch:29 step:23428 [D loss: 0.675747, acc.: 55.47%] [G loss: 0.773904]\n",
      "epoch:29 step:23429 [D loss: 0.720996, acc.: 45.31%] [G loss: 0.750053]\n",
      "epoch:29 step:23430 [D loss: 0.642454, acc.: 66.41%] [G loss: 0.699153]\n",
      "epoch:30 step:23431 [D loss: 0.617706, acc.: 71.88%] [G loss: 0.786439]\n",
      "epoch:30 step:23432 [D loss: 0.660829, acc.: 62.50%] [G loss: 0.791598]\n",
      "epoch:30 step:23433 [D loss: 0.717196, acc.: 41.41%] [G loss: 0.678921]\n",
      "epoch:30 step:23434 [D loss: 0.661662, acc.: 59.38%] [G loss: 0.793444]\n",
      "epoch:30 step:23435 [D loss: 0.696499, acc.: 50.78%] [G loss: 0.773020]\n",
      "epoch:30 step:23436 [D loss: 0.688798, acc.: 50.00%] [G loss: 0.749849]\n",
      "epoch:30 step:23437 [D loss: 0.656966, acc.: 59.38%] [G loss: 0.838736]\n",
      "epoch:30 step:23438 [D loss: 0.673987, acc.: 59.38%] [G loss: 0.861894]\n",
      "epoch:30 step:23439 [D loss: 0.711512, acc.: 48.44%] [G loss: 0.790656]\n",
      "epoch:30 step:23440 [D loss: 0.636387, acc.: 67.97%] [G loss: 0.784945]\n",
      "epoch:30 step:23441 [D loss: 0.691444, acc.: 53.12%] [G loss: 0.786518]\n",
      "epoch:30 step:23442 [D loss: 0.674972, acc.: 54.69%] [G loss: 0.726604]\n",
      "epoch:30 step:23443 [D loss: 0.665146, acc.: 64.06%] [G loss: 0.706236]\n",
      "epoch:30 step:23444 [D loss: 0.671133, acc.: 58.59%] [G loss: 0.832792]\n",
      "epoch:30 step:23445 [D loss: 0.662449, acc.: 59.38%] [G loss: 0.854933]\n",
      "epoch:30 step:23446 [D loss: 0.689981, acc.: 52.34%] [G loss: 0.743976]\n",
      "epoch:30 step:23447 [D loss: 0.711278, acc.: 52.34%] [G loss: 0.743861]\n",
      "epoch:30 step:23448 [D loss: 0.712776, acc.: 55.47%] [G loss: 0.681214]\n",
      "epoch:30 step:23449 [D loss: 0.691871, acc.: 44.53%] [G loss: 0.729019]\n",
      "epoch:30 step:23450 [D loss: 0.655224, acc.: 64.06%] [G loss: 0.746897]\n",
      "epoch:30 step:23451 [D loss: 0.718410, acc.: 45.31%] [G loss: 0.796305]\n",
      "epoch:30 step:23452 [D loss: 0.631993, acc.: 66.41%] [G loss: 0.802403]\n",
      "epoch:30 step:23453 [D loss: 0.635130, acc.: 64.84%] [G loss: 0.737014]\n",
      "epoch:30 step:23454 [D loss: 0.680902, acc.: 51.56%] [G loss: 0.818608]\n",
      "epoch:30 step:23455 [D loss: 0.703819, acc.: 52.34%] [G loss: 0.761174]\n",
      "epoch:30 step:23456 [D loss: 0.681939, acc.: 55.47%] [G loss: 0.836754]\n",
      "epoch:30 step:23457 [D loss: 0.626043, acc.: 70.31%] [G loss: 0.874439]\n",
      "epoch:30 step:23458 [D loss: 0.664120, acc.: 61.72%] [G loss: 0.769460]\n",
      "epoch:30 step:23459 [D loss: 0.721128, acc.: 46.09%] [G loss: 0.782700]\n",
      "epoch:30 step:23460 [D loss: 0.740581, acc.: 43.75%] [G loss: 0.723161]\n",
      "epoch:30 step:23461 [D loss: 0.670181, acc.: 57.81%] [G loss: 0.812799]\n",
      "epoch:30 step:23462 [D loss: 0.717095, acc.: 45.31%] [G loss: 0.774822]\n",
      "epoch:30 step:23463 [D loss: 0.697512, acc.: 51.56%] [G loss: 0.791417]\n",
      "epoch:30 step:23464 [D loss: 0.756741, acc.: 32.81%] [G loss: 0.737997]\n",
      "epoch:30 step:23465 [D loss: 0.691510, acc.: 53.12%] [G loss: 0.723455]\n",
      "epoch:30 step:23466 [D loss: 0.684568, acc.: 50.78%] [G loss: 0.706912]\n",
      "epoch:30 step:23467 [D loss: 0.676211, acc.: 55.47%] [G loss: 0.727072]\n",
      "epoch:30 step:23468 [D loss: 0.712331, acc.: 47.66%] [G loss: 0.749367]\n",
      "epoch:30 step:23469 [D loss: 0.696806, acc.: 51.56%] [G loss: 0.727683]\n",
      "epoch:30 step:23470 [D loss: 0.683388, acc.: 55.47%] [G loss: 0.814881]\n",
      "epoch:30 step:23471 [D loss: 0.668672, acc.: 59.38%] [G loss: 0.730999]\n",
      "epoch:30 step:23472 [D loss: 0.692921, acc.: 51.56%] [G loss: 0.725948]\n",
      "epoch:30 step:23473 [D loss: 0.695901, acc.: 55.47%] [G loss: 0.759918]\n",
      "epoch:30 step:23474 [D loss: 0.697036, acc.: 54.69%] [G loss: 0.748218]\n",
      "epoch:30 step:23475 [D loss: 0.666421, acc.: 58.59%] [G loss: 0.793109]\n",
      "epoch:30 step:23476 [D loss: 0.712898, acc.: 44.53%] [G loss: 0.732504]\n",
      "epoch:30 step:23477 [D loss: 0.752938, acc.: 32.81%] [G loss: 0.764159]\n",
      "epoch:30 step:23478 [D loss: 0.665502, acc.: 59.38%] [G loss: 0.764694]\n",
      "epoch:30 step:23479 [D loss: 0.663864, acc.: 58.59%] [G loss: 0.857193]\n",
      "epoch:30 step:23480 [D loss: 0.705157, acc.: 50.78%] [G loss: 0.723639]\n",
      "epoch:30 step:23481 [D loss: 0.705095, acc.: 50.00%] [G loss: 0.775429]\n",
      "epoch:30 step:23482 [D loss: 0.637385, acc.: 67.19%] [G loss: 0.774118]\n",
      "epoch:30 step:23483 [D loss: 0.680401, acc.: 56.25%] [G loss: 0.728593]\n",
      "epoch:30 step:23484 [D loss: 0.737160, acc.: 44.53%] [G loss: 0.651292]\n",
      "epoch:30 step:23485 [D loss: 0.651807, acc.: 67.19%] [G loss: 0.699455]\n",
      "epoch:30 step:23486 [D loss: 0.711810, acc.: 48.44%] [G loss: 0.769364]\n",
      "epoch:30 step:23487 [D loss: 0.715895, acc.: 46.88%] [G loss: 0.764918]\n",
      "epoch:30 step:23488 [D loss: 0.680178, acc.: 57.03%] [G loss: 0.800721]\n",
      "epoch:30 step:23489 [D loss: 0.622625, acc.: 73.44%] [G loss: 0.828827]\n",
      "epoch:30 step:23490 [D loss: 0.683623, acc.: 57.03%] [G loss: 0.805468]\n",
      "epoch:30 step:23491 [D loss: 0.657521, acc.: 57.81%] [G loss: 0.835884]\n",
      "epoch:30 step:23492 [D loss: 0.655794, acc.: 60.16%] [G loss: 0.867890]\n",
      "epoch:30 step:23493 [D loss: 0.697134, acc.: 46.09%] [G loss: 0.797859]\n",
      "epoch:30 step:23494 [D loss: 0.685677, acc.: 55.47%] [G loss: 0.788360]\n",
      "epoch:30 step:23495 [D loss: 0.705898, acc.: 48.44%] [G loss: 0.831731]\n",
      "epoch:30 step:23496 [D loss: 0.729507, acc.: 42.97%] [G loss: 0.796976]\n",
      "epoch:30 step:23497 [D loss: 0.685965, acc.: 53.12%] [G loss: 0.860962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23498 [D loss: 0.710255, acc.: 44.53%] [G loss: 0.788440]\n",
      "epoch:30 step:23499 [D loss: 0.728979, acc.: 35.16%] [G loss: 0.738031]\n",
      "epoch:30 step:23500 [D loss: 0.701603, acc.: 58.59%] [G loss: 0.753209]\n",
      "epoch:30 step:23501 [D loss: 0.714115, acc.: 44.53%] [G loss: 0.706071]\n",
      "epoch:30 step:23502 [D loss: 0.681324, acc.: 59.38%] [G loss: 0.688203]\n",
      "epoch:30 step:23503 [D loss: 0.658594, acc.: 60.16%] [G loss: 0.714669]\n",
      "epoch:30 step:23504 [D loss: 0.668471, acc.: 59.38%] [G loss: 0.748692]\n",
      "epoch:30 step:23505 [D loss: 0.632643, acc.: 61.72%] [G loss: 0.709317]\n",
      "epoch:30 step:23506 [D loss: 0.694115, acc.: 53.12%] [G loss: 0.744135]\n",
      "epoch:30 step:23507 [D loss: 0.641091, acc.: 64.06%] [G loss: 0.716827]\n",
      "epoch:30 step:23508 [D loss: 0.725021, acc.: 42.97%] [G loss: 0.690311]\n",
      "epoch:30 step:23509 [D loss: 0.710135, acc.: 48.44%] [G loss: 0.773225]\n",
      "epoch:30 step:23510 [D loss: 0.681216, acc.: 56.25%] [G loss: 0.809211]\n",
      "epoch:30 step:23511 [D loss: 0.671197, acc.: 57.81%] [G loss: 0.775871]\n",
      "epoch:30 step:23512 [D loss: 0.686778, acc.: 52.34%] [G loss: 0.765573]\n",
      "epoch:30 step:23513 [D loss: 0.697474, acc.: 52.34%] [G loss: 0.744714]\n",
      "epoch:30 step:23514 [D loss: 0.659660, acc.: 60.16%] [G loss: 0.798325]\n",
      "epoch:30 step:23515 [D loss: 0.684070, acc.: 60.94%] [G loss: 0.755056]\n",
      "epoch:30 step:23516 [D loss: 0.596555, acc.: 76.56%] [G loss: 0.777373]\n",
      "epoch:30 step:23517 [D loss: 0.656012, acc.: 62.50%] [G loss: 0.806071]\n",
      "epoch:30 step:23518 [D loss: 0.648584, acc.: 68.75%] [G loss: 0.810822]\n",
      "epoch:30 step:23519 [D loss: 0.638723, acc.: 65.62%] [G loss: 0.783853]\n",
      "epoch:30 step:23520 [D loss: 0.681067, acc.: 51.56%] [G loss: 0.867977]\n",
      "epoch:30 step:23521 [D loss: 0.667726, acc.: 60.94%] [G loss: 0.760316]\n",
      "epoch:30 step:23522 [D loss: 0.660670, acc.: 60.94%] [G loss: 0.692516]\n",
      "epoch:30 step:23523 [D loss: 0.704918, acc.: 52.34%] [G loss: 0.744156]\n",
      "epoch:30 step:23524 [D loss: 0.692652, acc.: 53.91%] [G loss: 0.730562]\n",
      "epoch:30 step:23525 [D loss: 0.684470, acc.: 50.78%] [G loss: 0.707882]\n",
      "epoch:30 step:23526 [D loss: 0.732579, acc.: 43.75%] [G loss: 0.756384]\n",
      "epoch:30 step:23527 [D loss: 0.802452, acc.: 28.12%] [G loss: 0.720766]\n",
      "epoch:30 step:23528 [D loss: 0.660981, acc.: 55.47%] [G loss: 0.811909]\n",
      "epoch:30 step:23529 [D loss: 0.661026, acc.: 58.59%] [G loss: 0.872840]\n",
      "epoch:30 step:23530 [D loss: 0.719404, acc.: 49.22%] [G loss: 0.758711]\n",
      "epoch:30 step:23531 [D loss: 0.698234, acc.: 55.47%] [G loss: 0.793712]\n",
      "epoch:30 step:23532 [D loss: 0.710790, acc.: 46.09%] [G loss: 0.788622]\n",
      "epoch:30 step:23533 [D loss: 0.754115, acc.: 42.97%] [G loss: 0.763483]\n",
      "epoch:30 step:23534 [D loss: 0.702333, acc.: 51.56%] [G loss: 0.785633]\n",
      "epoch:30 step:23535 [D loss: 0.695706, acc.: 55.47%] [G loss: 0.693807]\n",
      "epoch:30 step:23536 [D loss: 0.711953, acc.: 46.88%] [G loss: 0.786657]\n",
      "epoch:30 step:23537 [D loss: 0.642577, acc.: 63.28%] [G loss: 0.758574]\n",
      "epoch:30 step:23538 [D loss: 0.765404, acc.: 35.94%] [G loss: 0.742922]\n",
      "epoch:30 step:23539 [D loss: 0.668190, acc.: 63.28%] [G loss: 0.696697]\n",
      "epoch:30 step:23540 [D loss: 0.763934, acc.: 34.38%] [G loss: 0.730690]\n",
      "epoch:30 step:23541 [D loss: 0.714060, acc.: 43.75%] [G loss: 0.656947]\n",
      "epoch:30 step:23542 [D loss: 0.668078, acc.: 59.38%] [G loss: 0.715506]\n",
      "epoch:30 step:23543 [D loss: 0.734680, acc.: 47.66%] [G loss: 0.735793]\n",
      "epoch:30 step:23544 [D loss: 0.691717, acc.: 52.34%] [G loss: 0.764433]\n",
      "epoch:30 step:23545 [D loss: 0.717256, acc.: 49.22%] [G loss: 0.799663]\n",
      "epoch:30 step:23546 [D loss: 0.706865, acc.: 46.88%] [G loss: 0.831495]\n",
      "epoch:30 step:23547 [D loss: 0.727657, acc.: 42.19%] [G loss: 0.715883]\n",
      "epoch:30 step:23548 [D loss: 0.679065, acc.: 59.38%] [G loss: 0.754530]\n",
      "epoch:30 step:23549 [D loss: 0.632336, acc.: 70.31%] [G loss: 0.753653]\n",
      "epoch:30 step:23550 [D loss: 0.633144, acc.: 71.09%] [G loss: 0.748549]\n",
      "epoch:30 step:23551 [D loss: 0.690769, acc.: 50.00%] [G loss: 0.708620]\n",
      "epoch:30 step:23552 [D loss: 0.624136, acc.: 64.84%] [G loss: 0.804229]\n",
      "epoch:30 step:23553 [D loss: 0.756580, acc.: 39.06%] [G loss: 0.652437]\n",
      "epoch:30 step:23554 [D loss: 0.682006, acc.: 57.03%] [G loss: 0.714950]\n",
      "epoch:30 step:23555 [D loss: 0.740066, acc.: 39.84%] [G loss: 0.691233]\n",
      "epoch:30 step:23556 [D loss: 0.732017, acc.: 42.97%] [G loss: 0.650974]\n",
      "epoch:30 step:23557 [D loss: 0.673488, acc.: 57.03%] [G loss: 0.703701]\n",
      "epoch:30 step:23558 [D loss: 0.688476, acc.: 56.25%] [G loss: 0.791969]\n",
      "epoch:30 step:23559 [D loss: 0.691334, acc.: 57.81%] [G loss: 0.785039]\n",
      "epoch:30 step:23560 [D loss: 0.722149, acc.: 44.53%] [G loss: 0.771017]\n",
      "epoch:30 step:23561 [D loss: 0.664664, acc.: 57.81%] [G loss: 0.754298]\n",
      "epoch:30 step:23562 [D loss: 0.653489, acc.: 64.84%] [G loss: 0.735918]\n",
      "epoch:30 step:23563 [D loss: 0.720970, acc.: 45.31%] [G loss: 0.800495]\n",
      "epoch:30 step:23564 [D loss: 0.700115, acc.: 50.00%] [G loss: 0.758911]\n",
      "epoch:30 step:23565 [D loss: 0.714991, acc.: 46.09%] [G loss: 0.733122]\n",
      "epoch:30 step:23566 [D loss: 0.647101, acc.: 63.28%] [G loss: 0.786302]\n",
      "epoch:30 step:23567 [D loss: 0.709176, acc.: 50.78%] [G loss: 0.809524]\n",
      "epoch:30 step:23568 [D loss: 0.686187, acc.: 53.91%] [G loss: 0.818106]\n",
      "epoch:30 step:23569 [D loss: 0.658632, acc.: 59.38%] [G loss: 0.791182]\n",
      "epoch:30 step:23570 [D loss: 0.739239, acc.: 41.41%] [G loss: 0.803438]\n",
      "epoch:30 step:23571 [D loss: 0.704100, acc.: 59.38%] [G loss: 0.803392]\n",
      "epoch:30 step:23572 [D loss: 0.699610, acc.: 51.56%] [G loss: 0.795308]\n",
      "epoch:30 step:23573 [D loss: 0.700995, acc.: 50.00%] [G loss: 0.769940]\n",
      "epoch:30 step:23574 [D loss: 0.709975, acc.: 52.34%] [G loss: 0.758456]\n",
      "epoch:30 step:23575 [D loss: 0.660810, acc.: 55.47%] [G loss: 0.820794]\n",
      "epoch:30 step:23576 [D loss: 0.650434, acc.: 64.06%] [G loss: 0.798496]\n",
      "epoch:30 step:23577 [D loss: 0.643135, acc.: 62.50%] [G loss: 0.773333]\n",
      "epoch:30 step:23578 [D loss: 0.719084, acc.: 46.09%] [G loss: 0.738099]\n",
      "epoch:30 step:23579 [D loss: 0.708997, acc.: 53.12%] [G loss: 0.748930]\n",
      "epoch:30 step:23580 [D loss: 0.698381, acc.: 50.78%] [G loss: 0.769171]\n",
      "epoch:30 step:23581 [D loss: 0.721061, acc.: 47.66%] [G loss: 0.799649]\n",
      "epoch:30 step:23582 [D loss: 0.673050, acc.: 52.34%] [G loss: 0.815024]\n",
      "epoch:30 step:23583 [D loss: 0.673099, acc.: 56.25%] [G loss: 0.743833]\n",
      "epoch:30 step:23584 [D loss: 0.711100, acc.: 46.88%] [G loss: 0.805742]\n",
      "epoch:30 step:23585 [D loss: 0.684085, acc.: 57.03%] [G loss: 0.859492]\n",
      "epoch:30 step:23586 [D loss: 0.745752, acc.: 42.97%] [G loss: 0.779703]\n",
      "epoch:30 step:23587 [D loss: 0.695075, acc.: 53.12%] [G loss: 0.796658]\n",
      "epoch:30 step:23588 [D loss: 0.699317, acc.: 52.34%] [G loss: 0.784693]\n",
      "epoch:30 step:23589 [D loss: 0.673839, acc.: 56.25%] [G loss: 0.822379]\n",
      "epoch:30 step:23590 [D loss: 0.726354, acc.: 49.22%] [G loss: 0.723037]\n",
      "epoch:30 step:23591 [D loss: 0.704767, acc.: 49.22%] [G loss: 0.777971]\n",
      "epoch:30 step:23592 [D loss: 0.708501, acc.: 46.88%] [G loss: 0.732154]\n",
      "epoch:30 step:23593 [D loss: 0.645859, acc.: 64.06%] [G loss: 0.832637]\n",
      "epoch:30 step:23594 [D loss: 0.686651, acc.: 52.34%] [G loss: 0.763650]\n",
      "epoch:30 step:23595 [D loss: 0.654527, acc.: 63.28%] [G loss: 0.866036]\n",
      "epoch:30 step:23596 [D loss: 0.676375, acc.: 56.25%] [G loss: 0.835595]\n",
      "epoch:30 step:23597 [D loss: 0.712134, acc.: 50.00%] [G loss: 0.807279]\n",
      "epoch:30 step:23598 [D loss: 0.667343, acc.: 59.38%] [G loss: 0.852479]\n",
      "epoch:30 step:23599 [D loss: 0.668100, acc.: 58.59%] [G loss: 0.828119]\n",
      "epoch:30 step:23600 [D loss: 0.694255, acc.: 54.69%] [G loss: 0.758804]\n",
      "epoch:30 step:23601 [D loss: 0.657320, acc.: 57.81%] [G loss: 0.788974]\n",
      "epoch:30 step:23602 [D loss: 0.701863, acc.: 55.47%] [G loss: 0.783249]\n",
      "epoch:30 step:23603 [D loss: 0.692844, acc.: 50.78%] [G loss: 0.793680]\n",
      "epoch:30 step:23604 [D loss: 0.688136, acc.: 55.47%] [G loss: 0.732373]\n",
      "epoch:30 step:23605 [D loss: 0.695652, acc.: 53.91%] [G loss: 0.720500]\n",
      "epoch:30 step:23606 [D loss: 0.690316, acc.: 46.88%] [G loss: 0.696448]\n",
      "epoch:30 step:23607 [D loss: 0.700876, acc.: 52.34%] [G loss: 0.757069]\n",
      "epoch:30 step:23608 [D loss: 0.730539, acc.: 42.97%] [G loss: 0.740247]\n",
      "epoch:30 step:23609 [D loss: 0.671394, acc.: 58.59%] [G loss: 0.764921]\n",
      "epoch:30 step:23610 [D loss: 0.671050, acc.: 58.59%] [G loss: 0.808521]\n",
      "epoch:30 step:23611 [D loss: 0.669571, acc.: 59.38%] [G loss: 0.751007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23612 [D loss: 0.740929, acc.: 45.31%] [G loss: 0.788971]\n",
      "epoch:30 step:23613 [D loss: 0.718063, acc.: 47.66%] [G loss: 0.754264]\n",
      "epoch:30 step:23614 [D loss: 0.692995, acc.: 48.44%] [G loss: 0.825180]\n",
      "epoch:30 step:23615 [D loss: 0.697499, acc.: 52.34%] [G loss: 0.759256]\n",
      "epoch:30 step:23616 [D loss: 0.689430, acc.: 54.69%] [G loss: 0.753649]\n",
      "epoch:30 step:23617 [D loss: 0.690284, acc.: 49.22%] [G loss: 0.719691]\n",
      "epoch:30 step:23618 [D loss: 0.689560, acc.: 56.25%] [G loss: 0.695256]\n",
      "epoch:30 step:23619 [D loss: 0.705491, acc.: 48.44%] [G loss: 0.772236]\n",
      "epoch:30 step:23620 [D loss: 0.711102, acc.: 52.34%] [G loss: 0.719806]\n",
      "epoch:30 step:23621 [D loss: 0.757573, acc.: 38.28%] [G loss: 0.774481]\n",
      "epoch:30 step:23622 [D loss: 0.704491, acc.: 48.44%] [G loss: 0.817861]\n",
      "epoch:30 step:23623 [D loss: 0.669049, acc.: 59.38%] [G loss: 0.743478]\n",
      "epoch:30 step:23624 [D loss: 0.646740, acc.: 66.41%] [G loss: 0.747468]\n",
      "epoch:30 step:23625 [D loss: 0.694327, acc.: 50.00%] [G loss: 0.795774]\n",
      "epoch:30 step:23626 [D loss: 0.662027, acc.: 65.62%] [G loss: 0.730455]\n",
      "epoch:30 step:23627 [D loss: 0.693066, acc.: 54.69%] [G loss: 0.708742]\n",
      "epoch:30 step:23628 [D loss: 0.655007, acc.: 63.28%] [G loss: 0.710108]\n",
      "epoch:30 step:23629 [D loss: 0.723532, acc.: 43.75%] [G loss: 0.755941]\n",
      "epoch:30 step:23630 [D loss: 0.664026, acc.: 59.38%] [G loss: 0.721869]\n",
      "epoch:30 step:23631 [D loss: 0.641023, acc.: 65.62%] [G loss: 0.788281]\n",
      "epoch:30 step:23632 [D loss: 0.779486, acc.: 31.25%] [G loss: 0.734182]\n",
      "epoch:30 step:23633 [D loss: 0.691498, acc.: 53.12%] [G loss: 0.693960]\n",
      "epoch:30 step:23634 [D loss: 0.642081, acc.: 58.59%] [G loss: 0.804838]\n",
      "epoch:30 step:23635 [D loss: 0.723723, acc.: 46.88%] [G loss: 0.830838]\n",
      "epoch:30 step:23636 [D loss: 0.685187, acc.: 50.78%] [G loss: 0.719991]\n",
      "epoch:30 step:23637 [D loss: 0.664384, acc.: 58.59%] [G loss: 0.766833]\n",
      "epoch:30 step:23638 [D loss: 0.689548, acc.: 53.12%] [G loss: 0.751165]\n",
      "epoch:30 step:23639 [D loss: 0.655020, acc.: 63.28%] [G loss: 0.757123]\n",
      "epoch:30 step:23640 [D loss: 0.665578, acc.: 62.50%] [G loss: 0.726459]\n",
      "epoch:30 step:23641 [D loss: 0.674055, acc.: 60.94%] [G loss: 0.800588]\n",
      "epoch:30 step:23642 [D loss: 0.737890, acc.: 38.28%] [G loss: 0.773665]\n",
      "epoch:30 step:23643 [D loss: 0.657671, acc.: 69.53%] [G loss: 0.771602]\n",
      "epoch:30 step:23644 [D loss: 0.676219, acc.: 60.16%] [G loss: 0.777365]\n",
      "epoch:30 step:23645 [D loss: 0.672908, acc.: 60.16%] [G loss: 0.744298]\n",
      "epoch:30 step:23646 [D loss: 0.698799, acc.: 50.78%] [G loss: 0.820733]\n",
      "epoch:30 step:23647 [D loss: 0.707854, acc.: 49.22%] [G loss: 0.681735]\n",
      "epoch:30 step:23648 [D loss: 0.689110, acc.: 54.69%] [G loss: 0.672332]\n",
      "epoch:30 step:23649 [D loss: 0.654981, acc.: 64.06%] [G loss: 0.766926]\n",
      "epoch:30 step:23650 [D loss: 0.662819, acc.: 61.72%] [G loss: 0.711756]\n",
      "epoch:30 step:23651 [D loss: 0.652439, acc.: 61.72%] [G loss: 0.773173]\n",
      "epoch:30 step:23652 [D loss: 0.661432, acc.: 59.38%] [G loss: 0.743109]\n",
      "epoch:30 step:23653 [D loss: 0.682663, acc.: 53.91%] [G loss: 0.727887]\n",
      "epoch:30 step:23654 [D loss: 0.676474, acc.: 61.72%] [G loss: 0.705366]\n",
      "epoch:30 step:23655 [D loss: 0.672845, acc.: 54.69%] [G loss: 0.781301]\n",
      "epoch:30 step:23656 [D loss: 0.717034, acc.: 47.66%] [G loss: 0.803796]\n",
      "epoch:30 step:23657 [D loss: 0.615525, acc.: 72.66%] [G loss: 0.754890]\n",
      "epoch:30 step:23658 [D loss: 0.733287, acc.: 39.84%] [G loss: 0.727516]\n",
      "epoch:30 step:23659 [D loss: 0.650824, acc.: 66.41%] [G loss: 0.766142]\n",
      "epoch:30 step:23660 [D loss: 0.745398, acc.: 40.62%] [G loss: 0.767128]\n",
      "epoch:30 step:23661 [D loss: 0.696766, acc.: 55.47%] [G loss: 0.751472]\n",
      "epoch:30 step:23662 [D loss: 0.732127, acc.: 46.88%] [G loss: 0.721202]\n",
      "epoch:30 step:23663 [D loss: 0.706955, acc.: 48.44%] [G loss: 0.699982]\n",
      "epoch:30 step:23664 [D loss: 0.731799, acc.: 52.34%] [G loss: 0.703040]\n",
      "epoch:30 step:23665 [D loss: 0.720694, acc.: 43.75%] [G loss: 0.728914]\n",
      "epoch:30 step:23666 [D loss: 0.715889, acc.: 46.88%] [G loss: 0.692087]\n",
      "epoch:30 step:23667 [D loss: 0.687741, acc.: 48.44%] [G loss: 0.721812]\n",
      "epoch:30 step:23668 [D loss: 0.697116, acc.: 50.78%] [G loss: 0.752239]\n",
      "epoch:30 step:23669 [D loss: 0.631534, acc.: 68.75%] [G loss: 0.895902]\n",
      "epoch:30 step:23670 [D loss: 0.714364, acc.: 48.44%] [G loss: 0.857625]\n",
      "epoch:30 step:23671 [D loss: 0.693820, acc.: 55.47%] [G loss: 0.862648]\n",
      "epoch:30 step:23672 [D loss: 0.726783, acc.: 50.78%] [G loss: 0.803750]\n",
      "epoch:30 step:23673 [D loss: 0.656819, acc.: 57.81%] [G loss: 0.906582]\n",
      "epoch:30 step:23674 [D loss: 0.674937, acc.: 63.28%] [G loss: 0.871032]\n",
      "epoch:30 step:23675 [D loss: 0.657446, acc.: 60.16%] [G loss: 0.867393]\n",
      "epoch:30 step:23676 [D loss: 0.720569, acc.: 47.66%] [G loss: 0.751479]\n",
      "epoch:30 step:23677 [D loss: 0.708043, acc.: 56.25%] [G loss: 0.794790]\n",
      "epoch:30 step:23678 [D loss: 0.671316, acc.: 58.59%] [G loss: 0.733626]\n",
      "epoch:30 step:23679 [D loss: 0.659111, acc.: 61.72%] [G loss: 0.781739]\n",
      "epoch:30 step:23680 [D loss: 0.652022, acc.: 65.62%] [G loss: 0.806791]\n",
      "epoch:30 step:23681 [D loss: 0.709840, acc.: 55.47%] [G loss: 0.816274]\n",
      "epoch:30 step:23682 [D loss: 0.697924, acc.: 56.25%] [G loss: 0.796450]\n",
      "epoch:30 step:23683 [D loss: 0.697073, acc.: 51.56%] [G loss: 0.832063]\n",
      "epoch:30 step:23684 [D loss: 0.702997, acc.: 51.56%] [G loss: 0.753495]\n",
      "epoch:30 step:23685 [D loss: 0.650476, acc.: 63.28%] [G loss: 0.773408]\n",
      "epoch:30 step:23686 [D loss: 0.742653, acc.: 43.75%] [G loss: 0.745157]\n",
      "epoch:30 step:23687 [D loss: 0.673126, acc.: 57.03%] [G loss: 0.781597]\n",
      "epoch:30 step:23688 [D loss: 0.689423, acc.: 52.34%] [G loss: 0.842012]\n",
      "epoch:30 step:23689 [D loss: 0.696968, acc.: 53.91%] [G loss: 0.747509]\n",
      "epoch:30 step:23690 [D loss: 0.671884, acc.: 61.72%] [G loss: 0.842632]\n",
      "epoch:30 step:23691 [D loss: 0.672220, acc.: 56.25%] [G loss: 0.803414]\n",
      "epoch:30 step:23692 [D loss: 0.683668, acc.: 56.25%] [G loss: 0.789638]\n",
      "epoch:30 step:23693 [D loss: 0.736702, acc.: 41.41%] [G loss: 0.772963]\n",
      "epoch:30 step:23694 [D loss: 0.692192, acc.: 53.12%] [G loss: 0.832444]\n",
      "epoch:30 step:23695 [D loss: 0.729724, acc.: 43.75%] [G loss: 0.783505]\n",
      "epoch:30 step:23696 [D loss: 0.745504, acc.: 40.62%] [G loss: 0.709270]\n",
      "epoch:30 step:23697 [D loss: 0.768610, acc.: 34.38%] [G loss: 0.768924]\n",
      "epoch:30 step:23698 [D loss: 0.668033, acc.: 55.47%] [G loss: 0.714926]\n",
      "epoch:30 step:23699 [D loss: 0.702914, acc.: 52.34%] [G loss: 0.726242]\n",
      "epoch:30 step:23700 [D loss: 0.685305, acc.: 52.34%] [G loss: 0.774296]\n",
      "epoch:30 step:23701 [D loss: 0.701693, acc.: 51.56%] [G loss: 0.777250]\n",
      "epoch:30 step:23702 [D loss: 0.709642, acc.: 50.00%] [G loss: 0.750889]\n",
      "epoch:30 step:23703 [D loss: 0.690427, acc.: 53.91%] [G loss: 0.755977]\n",
      "epoch:30 step:23704 [D loss: 0.660412, acc.: 62.50%] [G loss: 0.775355]\n",
      "epoch:30 step:23705 [D loss: 0.690656, acc.: 50.00%] [G loss: 0.801390]\n",
      "epoch:30 step:23706 [D loss: 0.719368, acc.: 46.09%] [G loss: 0.803261]\n",
      "epoch:30 step:23707 [D loss: 0.745465, acc.: 43.75%] [G loss: 0.804736]\n",
      "epoch:30 step:23708 [D loss: 0.691877, acc.: 51.56%] [G loss: 0.753846]\n",
      "epoch:30 step:23709 [D loss: 0.730533, acc.: 43.75%] [G loss: 0.708829]\n",
      "epoch:30 step:23710 [D loss: 0.695898, acc.: 53.91%] [G loss: 0.759031]\n",
      "epoch:30 step:23711 [D loss: 0.676319, acc.: 56.25%] [G loss: 0.714256]\n",
      "epoch:30 step:23712 [D loss: 0.709126, acc.: 44.53%] [G loss: 0.763541]\n",
      "epoch:30 step:23713 [D loss: 0.639451, acc.: 60.94%] [G loss: 0.886706]\n",
      "epoch:30 step:23714 [D loss: 0.674096, acc.: 57.81%] [G loss: 0.797500]\n",
      "epoch:30 step:23715 [D loss: 0.686897, acc.: 50.78%] [G loss: 0.733427]\n",
      "epoch:30 step:23716 [D loss: 0.693033, acc.: 50.78%] [G loss: 0.772021]\n",
      "epoch:30 step:23717 [D loss: 0.704990, acc.: 49.22%] [G loss: 0.752861]\n",
      "epoch:30 step:23718 [D loss: 0.677052, acc.: 59.38%] [G loss: 0.734153]\n",
      "epoch:30 step:23719 [D loss: 0.678380, acc.: 58.59%] [G loss: 0.726485]\n",
      "epoch:30 step:23720 [D loss: 0.651091, acc.: 68.75%] [G loss: 0.741675]\n",
      "epoch:30 step:23721 [D loss: 0.665256, acc.: 60.16%] [G loss: 0.722299]\n",
      "epoch:30 step:23722 [D loss: 0.694061, acc.: 54.69%] [G loss: 0.807276]\n",
      "epoch:30 step:23723 [D loss: 0.733982, acc.: 43.75%] [G loss: 0.785225]\n",
      "epoch:30 step:23724 [D loss: 0.679124, acc.: 60.94%] [G loss: 0.811295]\n",
      "epoch:30 step:23725 [D loss: 0.679296, acc.: 56.25%] [G loss: 0.784073]\n",
      "epoch:30 step:23726 [D loss: 0.713161, acc.: 46.09%] [G loss: 0.696235]\n",
      "epoch:30 step:23727 [D loss: 0.702277, acc.: 50.78%] [G loss: 0.703050]\n",
      "epoch:30 step:23728 [D loss: 0.709742, acc.: 47.66%] [G loss: 0.707978]\n",
      "epoch:30 step:23729 [D loss: 0.682621, acc.: 52.34%] [G loss: 0.662952]\n",
      "epoch:30 step:23730 [D loss: 0.722498, acc.: 46.88%] [G loss: 0.711168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23731 [D loss: 0.708156, acc.: 49.22%] [G loss: 0.715734]\n",
      "epoch:30 step:23732 [D loss: 0.690794, acc.: 56.25%] [G loss: 0.767857]\n",
      "epoch:30 step:23733 [D loss: 0.719799, acc.: 44.53%] [G loss: 0.737313]\n",
      "epoch:30 step:23734 [D loss: 0.672535, acc.: 60.16%] [G loss: 0.774663]\n",
      "epoch:30 step:23735 [D loss: 0.734473, acc.: 45.31%] [G loss: 0.741607]\n",
      "epoch:30 step:23736 [D loss: 0.681927, acc.: 53.91%] [G loss: 0.737605]\n",
      "epoch:30 step:23737 [D loss: 0.656984, acc.: 60.16%] [G loss: 0.839420]\n",
      "epoch:30 step:23738 [D loss: 0.646181, acc.: 69.53%] [G loss: 0.771518]\n",
      "epoch:30 step:23739 [D loss: 0.694085, acc.: 53.91%] [G loss: 0.813844]\n",
      "epoch:30 step:23740 [D loss: 0.675033, acc.: 52.34%] [G loss: 0.838700]\n",
      "epoch:30 step:23741 [D loss: 0.691742, acc.: 48.44%] [G loss: 0.783128]\n",
      "epoch:30 step:23742 [D loss: 0.720119, acc.: 49.22%] [G loss: 0.766567]\n",
      "epoch:30 step:23743 [D loss: 0.716722, acc.: 49.22%] [G loss: 0.727274]\n",
      "epoch:30 step:23744 [D loss: 0.687874, acc.: 53.12%] [G loss: 0.710917]\n",
      "epoch:30 step:23745 [D loss: 0.706990, acc.: 54.69%] [G loss: 0.722666]\n",
      "epoch:30 step:23746 [D loss: 0.659501, acc.: 64.06%] [G loss: 0.801059]\n",
      "epoch:30 step:23747 [D loss: 0.703228, acc.: 47.66%] [G loss: 0.716463]\n",
      "epoch:30 step:23748 [D loss: 0.662173, acc.: 64.84%] [G loss: 0.741081]\n",
      "epoch:30 step:23749 [D loss: 0.649086, acc.: 60.94%] [G loss: 0.696269]\n",
      "epoch:30 step:23750 [D loss: 0.657577, acc.: 62.50%] [G loss: 0.788659]\n",
      "epoch:30 step:23751 [D loss: 0.653483, acc.: 64.84%] [G loss: 0.800380]\n",
      "epoch:30 step:23752 [D loss: 0.644645, acc.: 60.94%] [G loss: 0.755887]\n",
      "epoch:30 step:23753 [D loss: 0.684309, acc.: 55.47%] [G loss: 0.734803]\n",
      "epoch:30 step:23754 [D loss: 0.657523, acc.: 58.59%] [G loss: 0.675779]\n",
      "epoch:30 step:23755 [D loss: 0.708419, acc.: 46.09%] [G loss: 0.752001]\n",
      "epoch:30 step:23756 [D loss: 0.666783, acc.: 62.50%] [G loss: 0.742114]\n",
      "epoch:30 step:23757 [D loss: 0.691728, acc.: 53.12%] [G loss: 0.760939]\n",
      "epoch:30 step:23758 [D loss: 0.647838, acc.: 67.19%] [G loss: 0.811941]\n",
      "epoch:30 step:23759 [D loss: 0.688814, acc.: 53.12%] [G loss: 0.719068]\n",
      "epoch:30 step:23760 [D loss: 0.730595, acc.: 39.06%] [G loss: 0.733638]\n",
      "epoch:30 step:23761 [D loss: 0.687146, acc.: 52.34%] [G loss: 0.761170]\n",
      "epoch:30 step:23762 [D loss: 0.728093, acc.: 49.22%] [G loss: 0.763450]\n",
      "epoch:30 step:23763 [D loss: 0.632351, acc.: 67.19%] [G loss: 0.732206]\n",
      "epoch:30 step:23764 [D loss: 0.699811, acc.: 55.47%] [G loss: 0.764603]\n",
      "epoch:30 step:23765 [D loss: 0.696210, acc.: 54.69%] [G loss: 0.770222]\n",
      "epoch:30 step:23766 [D loss: 0.647019, acc.: 59.38%] [G loss: 0.712033]\n",
      "epoch:30 step:23767 [D loss: 0.712709, acc.: 50.00%] [G loss: 0.721255]\n",
      "epoch:30 step:23768 [D loss: 0.708884, acc.: 45.31%] [G loss: 0.767666]\n",
      "epoch:30 step:23769 [D loss: 0.711014, acc.: 50.00%] [G loss: 0.719666]\n",
      "epoch:30 step:23770 [D loss: 0.697028, acc.: 53.91%] [G loss: 0.827587]\n",
      "epoch:30 step:23771 [D loss: 0.708500, acc.: 44.53%] [G loss: 0.661599]\n",
      "epoch:30 step:23772 [D loss: 0.722613, acc.: 49.22%] [G loss: 0.765131]\n",
      "epoch:30 step:23773 [D loss: 0.708498, acc.: 46.09%] [G loss: 0.802577]\n",
      "epoch:30 step:23774 [D loss: 0.702358, acc.: 50.00%] [G loss: 0.802505]\n",
      "epoch:30 step:23775 [D loss: 0.722706, acc.: 43.75%] [G loss: 0.772045]\n",
      "epoch:30 step:23776 [D loss: 0.727942, acc.: 44.53%] [G loss: 0.805342]\n",
      "epoch:30 step:23777 [D loss: 0.704721, acc.: 48.44%] [G loss: 0.836642]\n",
      "epoch:30 step:23778 [D loss: 0.710416, acc.: 49.22%] [G loss: 0.845846]\n",
      "epoch:30 step:23779 [D loss: 0.662205, acc.: 57.81%] [G loss: 0.828569]\n",
      "epoch:30 step:23780 [D loss: 0.740177, acc.: 43.75%] [G loss: 0.820935]\n",
      "epoch:30 step:23781 [D loss: 0.688072, acc.: 56.25%] [G loss: 0.791218]\n",
      "epoch:30 step:23782 [D loss: 0.729835, acc.: 50.00%] [G loss: 0.787671]\n",
      "epoch:30 step:23783 [D loss: 0.624628, acc.: 71.09%] [G loss: 0.785904]\n",
      "epoch:30 step:23784 [D loss: 0.671570, acc.: 59.38%] [G loss: 0.893546]\n",
      "epoch:30 step:23785 [D loss: 0.684013, acc.: 60.16%] [G loss: 0.806408]\n",
      "epoch:30 step:23786 [D loss: 0.660123, acc.: 61.72%] [G loss: 0.756087]\n",
      "epoch:30 step:23787 [D loss: 0.616315, acc.: 64.84%] [G loss: 0.839748]\n",
      "epoch:30 step:23788 [D loss: 0.677236, acc.: 54.69%] [G loss: 0.753792]\n",
      "epoch:30 step:23789 [D loss: 0.674611, acc.: 57.81%] [G loss: 0.834346]\n",
      "epoch:30 step:23790 [D loss: 0.702318, acc.: 51.56%] [G loss: 0.745836]\n",
      "epoch:30 step:23791 [D loss: 0.657548, acc.: 64.06%] [G loss: 0.764871]\n",
      "epoch:30 step:23792 [D loss: 0.631731, acc.: 66.41%] [G loss: 0.760602]\n",
      "epoch:30 step:23793 [D loss: 0.717851, acc.: 43.75%] [G loss: 0.738602]\n",
      "epoch:30 step:23794 [D loss: 0.662231, acc.: 64.06%] [G loss: 0.739051]\n",
      "epoch:30 step:23795 [D loss: 0.668343, acc.: 59.38%] [G loss: 0.755640]\n",
      "epoch:30 step:23796 [D loss: 0.711834, acc.: 50.78%] [G loss: 0.700411]\n",
      "epoch:30 step:23797 [D loss: 0.672382, acc.: 54.69%] [G loss: 0.773295]\n",
      "epoch:30 step:23798 [D loss: 0.668953, acc.: 59.38%] [G loss: 0.823175]\n",
      "epoch:30 step:23799 [D loss: 0.691203, acc.: 56.25%] [G loss: 0.808308]\n",
      "epoch:30 step:23800 [D loss: 0.673591, acc.: 55.47%] [G loss: 0.865373]\n",
      "epoch:30 step:23801 [D loss: 0.686141, acc.: 55.47%] [G loss: 0.732854]\n",
      "epoch:30 step:23802 [D loss: 0.641949, acc.: 70.31%] [G loss: 0.782676]\n",
      "epoch:30 step:23803 [D loss: 0.714204, acc.: 49.22%] [G loss: 0.729399]\n",
      "epoch:30 step:23804 [D loss: 0.697955, acc.: 50.78%] [G loss: 0.721992]\n",
      "epoch:30 step:23805 [D loss: 0.725277, acc.: 51.56%] [G loss: 0.710460]\n",
      "epoch:30 step:23806 [D loss: 0.651338, acc.: 67.97%] [G loss: 0.805966]\n",
      "epoch:30 step:23807 [D loss: 0.723309, acc.: 42.97%] [G loss: 0.705194]\n",
      "epoch:30 step:23808 [D loss: 0.680525, acc.: 55.47%] [G loss: 0.761409]\n",
      "epoch:30 step:23809 [D loss: 0.690912, acc.: 55.47%] [G loss: 0.761013]\n",
      "epoch:30 step:23810 [D loss: 0.725416, acc.: 39.06%] [G loss: 0.694803]\n",
      "epoch:30 step:23811 [D loss: 0.682073, acc.: 57.81%] [G loss: 0.748056]\n",
      "epoch:30 step:23812 [D loss: 0.719239, acc.: 49.22%] [G loss: 0.755203]\n",
      "epoch:30 step:23813 [D loss: 0.694704, acc.: 55.47%] [G loss: 0.723007]\n",
      "epoch:30 step:23814 [D loss: 0.683321, acc.: 57.81%] [G loss: 0.804377]\n",
      "epoch:30 step:23815 [D loss: 0.737610, acc.: 41.41%] [G loss: 0.761362]\n",
      "epoch:30 step:23816 [D loss: 0.642606, acc.: 64.06%] [G loss: 0.746778]\n",
      "epoch:30 step:23817 [D loss: 0.664597, acc.: 61.72%] [G loss: 0.778238]\n",
      "epoch:30 step:23818 [D loss: 0.742942, acc.: 35.94%] [G loss: 0.806431]\n",
      "epoch:30 step:23819 [D loss: 0.659197, acc.: 58.59%] [G loss: 0.811776]\n",
      "epoch:30 step:23820 [D loss: 0.677387, acc.: 61.72%] [G loss: 0.750126]\n",
      "epoch:30 step:23821 [D loss: 0.721270, acc.: 50.78%] [G loss: 0.719478]\n",
      "epoch:30 step:23822 [D loss: 0.728741, acc.: 50.00%] [G loss: 0.684916]\n",
      "epoch:30 step:23823 [D loss: 0.645617, acc.: 59.38%] [G loss: 0.725899]\n",
      "epoch:30 step:23824 [D loss: 0.698417, acc.: 52.34%] [G loss: 0.703675]\n",
      "epoch:30 step:23825 [D loss: 0.706160, acc.: 48.44%] [G loss: 0.709372]\n",
      "epoch:30 step:23826 [D loss: 0.662306, acc.: 57.81%] [G loss: 0.813761]\n",
      "epoch:30 step:23827 [D loss: 0.687749, acc.: 53.12%] [G loss: 0.747297]\n",
      "epoch:30 step:23828 [D loss: 0.644513, acc.: 68.75%] [G loss: 0.741896]\n",
      "epoch:30 step:23829 [D loss: 0.697794, acc.: 52.34%] [G loss: 0.767699]\n",
      "epoch:30 step:23830 [D loss: 0.724700, acc.: 52.34%] [G loss: 0.820812]\n",
      "epoch:30 step:23831 [D loss: 0.652030, acc.: 61.72%] [G loss: 0.747277]\n",
      "epoch:30 step:23832 [D loss: 0.672108, acc.: 57.03%] [G loss: 0.767500]\n",
      "epoch:30 step:23833 [D loss: 0.692005, acc.: 55.47%] [G loss: 0.729408]\n",
      "epoch:30 step:23834 [D loss: 0.650195, acc.: 64.84%] [G loss: 0.741704]\n",
      "epoch:30 step:23835 [D loss: 0.679477, acc.: 59.38%] [G loss: 0.735600]\n",
      "epoch:30 step:23836 [D loss: 0.663935, acc.: 57.03%] [G loss: 0.788313]\n",
      "epoch:30 step:23837 [D loss: 0.684701, acc.: 52.34%] [G loss: 0.679210]\n",
      "epoch:30 step:23838 [D loss: 0.654779, acc.: 62.50%] [G loss: 0.793723]\n",
      "epoch:30 step:23839 [D loss: 0.650149, acc.: 62.50%] [G loss: 0.722917]\n",
      "epoch:30 step:23840 [D loss: 0.648264, acc.: 61.72%] [G loss: 0.685692]\n",
      "epoch:30 step:23841 [D loss: 0.718083, acc.: 45.31%] [G loss: 0.737844]\n",
      "epoch:30 step:23842 [D loss: 0.672881, acc.: 60.16%] [G loss: 0.721977]\n",
      "epoch:30 step:23843 [D loss: 0.698110, acc.: 50.00%] [G loss: 0.772003]\n",
      "epoch:30 step:23844 [D loss: 0.716142, acc.: 52.34%] [G loss: 0.776181]\n",
      "epoch:30 step:23845 [D loss: 0.677393, acc.: 55.47%] [G loss: 0.748390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23846 [D loss: 0.647812, acc.: 65.62%] [G loss: 0.782256]\n",
      "epoch:30 step:23847 [D loss: 0.728190, acc.: 46.88%] [G loss: 0.748757]\n",
      "epoch:30 step:23848 [D loss: 0.743031, acc.: 45.31%] [G loss: 0.722152]\n",
      "epoch:30 step:23849 [D loss: 0.694445, acc.: 45.31%] [G loss: 0.739512]\n",
      "epoch:30 step:23850 [D loss: 0.662257, acc.: 64.84%] [G loss: 0.796136]\n",
      "epoch:30 step:23851 [D loss: 0.679943, acc.: 55.47%] [G loss: 0.764845]\n",
      "epoch:30 step:23852 [D loss: 0.718137, acc.: 49.22%] [G loss: 0.825350]\n",
      "epoch:30 step:23853 [D loss: 0.708081, acc.: 49.22%] [G loss: 0.759489]\n",
      "epoch:30 step:23854 [D loss: 0.778036, acc.: 33.59%] [G loss: 0.706414]\n",
      "epoch:30 step:23855 [D loss: 0.687393, acc.: 54.69%] [G loss: 0.794886]\n",
      "epoch:30 step:23856 [D loss: 0.711295, acc.: 49.22%] [G loss: 0.752032]\n",
      "epoch:30 step:23857 [D loss: 0.668762, acc.: 60.16%] [G loss: 0.802456]\n",
      "epoch:30 step:23858 [D loss: 0.738910, acc.: 42.97%] [G loss: 0.679533]\n",
      "epoch:30 step:23859 [D loss: 0.650892, acc.: 63.28%] [G loss: 0.738249]\n",
      "epoch:30 step:23860 [D loss: 0.654597, acc.: 60.94%] [G loss: 0.733399]\n",
      "epoch:30 step:23861 [D loss: 0.697796, acc.: 47.66%] [G loss: 0.779534]\n",
      "epoch:30 step:23862 [D loss: 0.710817, acc.: 53.12%] [G loss: 0.794643]\n",
      "epoch:30 step:23863 [D loss: 0.708306, acc.: 53.12%] [G loss: 0.821460]\n",
      "epoch:30 step:23864 [D loss: 0.652391, acc.: 63.28%] [G loss: 0.751353]\n",
      "epoch:30 step:23865 [D loss: 0.691371, acc.: 55.47%] [G loss: 0.759202]\n",
      "epoch:30 step:23866 [D loss: 0.723049, acc.: 43.75%] [G loss: 0.808986]\n",
      "epoch:30 step:23867 [D loss: 0.725028, acc.: 46.88%] [G loss: 0.753684]\n",
      "epoch:30 step:23868 [D loss: 0.674124, acc.: 56.25%] [G loss: 0.727999]\n",
      "epoch:30 step:23869 [D loss: 0.695731, acc.: 50.78%] [G loss: 0.783787]\n",
      "epoch:30 step:23870 [D loss: 0.668865, acc.: 57.81%] [G loss: 0.806186]\n",
      "epoch:30 step:23871 [D loss: 0.696040, acc.: 47.66%] [G loss: 0.741745]\n",
      "epoch:30 step:23872 [D loss: 0.698537, acc.: 50.00%] [G loss: 0.804624]\n",
      "epoch:30 step:23873 [D loss: 0.622321, acc.: 71.88%] [G loss: 0.775517]\n",
      "epoch:30 step:23874 [D loss: 0.713018, acc.: 44.53%] [G loss: 0.706739]\n",
      "epoch:30 step:23875 [D loss: 0.674320, acc.: 61.72%] [G loss: 0.814405]\n",
      "epoch:30 step:23876 [D loss: 0.679794, acc.: 57.81%] [G loss: 0.810037]\n",
      "epoch:30 step:23877 [D loss: 0.679352, acc.: 60.94%] [G loss: 0.760976]\n",
      "epoch:30 step:23878 [D loss: 0.688754, acc.: 53.91%] [G loss: 0.759731]\n",
      "epoch:30 step:23879 [D loss: 0.671315, acc.: 61.72%] [G loss: 0.783240]\n",
      "epoch:30 step:23880 [D loss: 0.729115, acc.: 46.09%] [G loss: 0.724637]\n",
      "epoch:30 step:23881 [D loss: 0.666976, acc.: 60.16%] [G loss: 0.846367]\n",
      "epoch:30 step:23882 [D loss: 0.671661, acc.: 58.59%] [G loss: 0.839081]\n",
      "epoch:30 step:23883 [D loss: 0.708147, acc.: 47.66%] [G loss: 0.826690]\n",
      "epoch:30 step:23884 [D loss: 0.707949, acc.: 48.44%] [G loss: 0.788642]\n",
      "epoch:30 step:23885 [D loss: 0.667405, acc.: 58.59%] [G loss: 0.752566]\n",
      "epoch:30 step:23886 [D loss: 0.703936, acc.: 52.34%] [G loss: 0.736384]\n",
      "epoch:30 step:23887 [D loss: 0.648193, acc.: 69.53%] [G loss: 0.753979]\n",
      "epoch:30 step:23888 [D loss: 0.649262, acc.: 60.94%] [G loss: 0.788169]\n",
      "epoch:30 step:23889 [D loss: 0.700136, acc.: 50.78%] [G loss: 0.691595]\n",
      "epoch:30 step:23890 [D loss: 0.687181, acc.: 57.81%] [G loss: 0.782914]\n",
      "epoch:30 step:23891 [D loss: 0.717079, acc.: 45.31%] [G loss: 0.739421]\n",
      "epoch:30 step:23892 [D loss: 0.682381, acc.: 54.69%] [G loss: 0.760688]\n",
      "epoch:30 step:23893 [D loss: 0.713271, acc.: 54.69%] [G loss: 0.844066]\n",
      "epoch:30 step:23894 [D loss: 0.664122, acc.: 63.28%] [G loss: 0.761004]\n",
      "epoch:30 step:23895 [D loss: 0.668350, acc.: 61.72%] [G loss: 0.830592]\n",
      "epoch:30 step:23896 [D loss: 0.628514, acc.: 71.09%] [G loss: 0.797728]\n",
      "epoch:30 step:23897 [D loss: 0.716910, acc.: 46.09%] [G loss: 0.802081]\n",
      "epoch:30 step:23898 [D loss: 0.686278, acc.: 60.16%] [G loss: 0.695866]\n",
      "epoch:30 step:23899 [D loss: 0.711038, acc.: 45.31%] [G loss: 0.831469]\n",
      "epoch:30 step:23900 [D loss: 0.670133, acc.: 57.81%] [G loss: 0.830460]\n",
      "epoch:30 step:23901 [D loss: 0.731928, acc.: 38.28%] [G loss: 0.868208]\n",
      "epoch:30 step:23902 [D loss: 0.690676, acc.: 53.91%] [G loss: 0.747757]\n",
      "epoch:30 step:23903 [D loss: 0.756379, acc.: 42.97%] [G loss: 0.797284]\n",
      "epoch:30 step:23904 [D loss: 0.653542, acc.: 63.28%] [G loss: 0.751920]\n",
      "epoch:30 step:23905 [D loss: 0.730316, acc.: 40.62%] [G loss: 0.761037]\n",
      "epoch:30 step:23906 [D loss: 0.612535, acc.: 71.88%] [G loss: 0.849360]\n",
      "epoch:30 step:23907 [D loss: 0.713882, acc.: 47.66%] [G loss: 0.731172]\n",
      "epoch:30 step:23908 [D loss: 0.629586, acc.: 70.31%] [G loss: 0.818514]\n",
      "epoch:30 step:23909 [D loss: 0.718728, acc.: 45.31%] [G loss: 0.756954]\n",
      "epoch:30 step:23910 [D loss: 0.637296, acc.: 67.19%] [G loss: 0.764009]\n",
      "epoch:30 step:23911 [D loss: 0.726816, acc.: 49.22%] [G loss: 0.817096]\n",
      "epoch:30 step:23912 [D loss: 0.702300, acc.: 45.31%] [G loss: 0.751475]\n",
      "epoch:30 step:23913 [D loss: 0.666781, acc.: 55.47%] [G loss: 0.831836]\n",
      "epoch:30 step:23914 [D loss: 0.728748, acc.: 50.78%] [G loss: 0.751427]\n",
      "epoch:30 step:23915 [D loss: 0.672273, acc.: 59.38%] [G loss: 0.783346]\n",
      "epoch:30 step:23916 [D loss: 0.691963, acc.: 53.91%] [G loss: 0.770976]\n",
      "epoch:30 step:23917 [D loss: 0.712687, acc.: 42.97%] [G loss: 0.809949]\n",
      "epoch:30 step:23918 [D loss: 0.688952, acc.: 57.03%] [G loss: 0.831201]\n",
      "epoch:30 step:23919 [D loss: 0.619175, acc.: 74.22%] [G loss: 0.817618]\n",
      "epoch:30 step:23920 [D loss: 0.683556, acc.: 56.25%] [G loss: 0.774494]\n",
      "epoch:30 step:23921 [D loss: 0.670884, acc.: 53.12%] [G loss: 0.861753]\n",
      "epoch:30 step:23922 [D loss: 0.637205, acc.: 66.41%] [G loss: 0.763110]\n",
      "epoch:30 step:23923 [D loss: 0.673258, acc.: 63.28%] [G loss: 0.777854]\n",
      "epoch:30 step:23924 [D loss: 0.669641, acc.: 60.16%] [G loss: 0.812766]\n",
      "epoch:30 step:23925 [D loss: 0.667359, acc.: 63.28%] [G loss: 0.842495]\n",
      "epoch:30 step:23926 [D loss: 0.669057, acc.: 56.25%] [G loss: 0.850279]\n",
      "epoch:30 step:23927 [D loss: 0.718072, acc.: 50.00%] [G loss: 0.716276]\n",
      "epoch:30 step:23928 [D loss: 0.718883, acc.: 46.09%] [G loss: 0.755363]\n",
      "epoch:30 step:23929 [D loss: 0.690925, acc.: 57.03%] [G loss: 0.786625]\n",
      "epoch:30 step:23930 [D loss: 0.711089, acc.: 45.31%] [G loss: 0.733501]\n",
      "epoch:30 step:23931 [D loss: 0.704877, acc.: 49.22%] [G loss: 0.771936]\n",
      "epoch:30 step:23932 [D loss: 0.706918, acc.: 53.91%] [G loss: 0.735358]\n",
      "epoch:30 step:23933 [D loss: 0.716872, acc.: 50.00%] [G loss: 0.792134]\n",
      "epoch:30 step:23934 [D loss: 0.708868, acc.: 49.22%] [G loss: 0.770945]\n",
      "epoch:30 step:23935 [D loss: 0.683856, acc.: 55.47%] [G loss: 0.839324]\n",
      "epoch:30 step:23936 [D loss: 0.710105, acc.: 49.22%] [G loss: 0.763437]\n",
      "epoch:30 step:23937 [D loss: 0.712908, acc.: 47.66%] [G loss: 0.778863]\n",
      "epoch:30 step:23938 [D loss: 0.738109, acc.: 43.75%] [G loss: 0.710855]\n",
      "epoch:30 step:23939 [D loss: 0.698466, acc.: 49.22%] [G loss: 0.750013]\n",
      "epoch:30 step:23940 [D loss: 0.713237, acc.: 46.88%] [G loss: 0.699432]\n",
      "epoch:30 step:23941 [D loss: 0.670745, acc.: 56.25%] [G loss: 0.820719]\n",
      "epoch:30 step:23942 [D loss: 0.715281, acc.: 45.31%] [G loss: 0.836648]\n",
      "epoch:30 step:23943 [D loss: 0.717643, acc.: 51.56%] [G loss: 0.664775]\n",
      "epoch:30 step:23944 [D loss: 0.837454, acc.: 26.56%] [G loss: 0.644772]\n",
      "epoch:30 step:23945 [D loss: 0.752337, acc.: 40.62%] [G loss: 0.705328]\n",
      "epoch:30 step:23946 [D loss: 0.650412, acc.: 61.72%] [G loss: 0.774136]\n",
      "epoch:30 step:23947 [D loss: 0.661750, acc.: 63.28%] [G loss: 0.783342]\n",
      "epoch:30 step:23948 [D loss: 0.654814, acc.: 66.41%] [G loss: 0.782475]\n",
      "epoch:30 step:23949 [D loss: 0.683974, acc.: 60.16%] [G loss: 0.799261]\n",
      "epoch:30 step:23950 [D loss: 0.705302, acc.: 50.78%] [G loss: 0.832489]\n",
      "epoch:30 step:23951 [D loss: 0.676213, acc.: 57.81%] [G loss: 0.767195]\n",
      "epoch:30 step:23952 [D loss: 0.699683, acc.: 47.66%] [G loss: 0.798738]\n",
      "epoch:30 step:23953 [D loss: 0.705907, acc.: 50.78%] [G loss: 0.786241]\n",
      "epoch:30 step:23954 [D loss: 0.704084, acc.: 48.44%] [G loss: 0.775756]\n",
      "epoch:30 step:23955 [D loss: 0.678604, acc.: 57.81%] [G loss: 0.815090]\n",
      "epoch:30 step:23956 [D loss: 0.766263, acc.: 39.06%] [G loss: 0.725518]\n",
      "epoch:30 step:23957 [D loss: 0.677300, acc.: 52.34%] [G loss: 0.782865]\n",
      "epoch:30 step:23958 [D loss: 0.650518, acc.: 62.50%] [G loss: 0.732332]\n",
      "epoch:30 step:23959 [D loss: 0.690151, acc.: 53.12%] [G loss: 0.753749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23960 [D loss: 0.652566, acc.: 65.62%] [G loss: 0.699068]\n",
      "epoch:30 step:23961 [D loss: 0.607349, acc.: 82.81%] [G loss: 0.818651]\n",
      "epoch:30 step:23962 [D loss: 0.754881, acc.: 46.88%] [G loss: 0.804575]\n",
      "epoch:30 step:23963 [D loss: 0.715102, acc.: 44.53%] [G loss: 0.740622]\n",
      "epoch:30 step:23964 [D loss: 0.669166, acc.: 57.03%] [G loss: 0.816524]\n",
      "epoch:30 step:23965 [D loss: 0.672502, acc.: 60.16%] [G loss: 0.819126]\n",
      "epoch:30 step:23966 [D loss: 0.638611, acc.: 67.97%] [G loss: 0.841474]\n",
      "epoch:30 step:23967 [D loss: 0.705928, acc.: 52.34%] [G loss: 0.756250]\n",
      "epoch:30 step:23968 [D loss: 0.663571, acc.: 61.72%] [G loss: 0.744676]\n",
      "epoch:30 step:23969 [D loss: 0.663339, acc.: 67.19%] [G loss: 0.774119]\n",
      "epoch:30 step:23970 [D loss: 0.707179, acc.: 52.34%] [G loss: 0.728183]\n",
      "epoch:30 step:23971 [D loss: 0.667747, acc.: 58.59%] [G loss: 0.722366]\n",
      "epoch:30 step:23972 [D loss: 0.680529, acc.: 54.69%] [G loss: 0.761719]\n",
      "epoch:30 step:23973 [D loss: 0.718486, acc.: 46.88%] [G loss: 0.684724]\n",
      "epoch:30 step:23974 [D loss: 0.691085, acc.: 53.12%] [G loss: 0.741043]\n",
      "epoch:30 step:23975 [D loss: 0.640435, acc.: 68.75%] [G loss: 0.839401]\n",
      "epoch:30 step:23976 [D loss: 0.756289, acc.: 42.19%] [G loss: 0.844956]\n",
      "epoch:30 step:23977 [D loss: 0.633931, acc.: 68.75%] [G loss: 0.747428]\n",
      "epoch:30 step:23978 [D loss: 0.686053, acc.: 53.12%] [G loss: 0.708368]\n",
      "epoch:30 step:23979 [D loss: 0.720900, acc.: 39.84%] [G loss: 0.750575]\n",
      "epoch:30 step:23980 [D loss: 0.634221, acc.: 68.75%] [G loss: 0.813473]\n",
      "epoch:30 step:23981 [D loss: 0.658990, acc.: 64.84%] [G loss: 0.838246]\n",
      "epoch:30 step:23982 [D loss: 0.687560, acc.: 57.81%] [G loss: 0.721843]\n",
      "epoch:30 step:23983 [D loss: 0.697106, acc.: 51.56%] [G loss: 0.763756]\n",
      "epoch:30 step:23984 [D loss: 0.661077, acc.: 53.91%] [G loss: 0.798078]\n",
      "epoch:30 step:23985 [D loss: 0.640995, acc.: 67.19%] [G loss: 0.775870]\n",
      "epoch:30 step:23986 [D loss: 0.713486, acc.: 50.00%] [G loss: 0.749202]\n",
      "epoch:30 step:23987 [D loss: 0.699627, acc.: 55.47%] [G loss: 0.805529]\n",
      "epoch:30 step:23988 [D loss: 0.728706, acc.: 47.66%] [G loss: 0.758868]\n",
      "epoch:30 step:23989 [D loss: 0.657224, acc.: 60.16%] [G loss: 0.782306]\n",
      "epoch:30 step:23990 [D loss: 0.690176, acc.: 57.81%] [G loss: 0.746734]\n",
      "epoch:30 step:23991 [D loss: 0.721607, acc.: 41.41%] [G loss: 0.721386]\n",
      "epoch:30 step:23992 [D loss: 0.689390, acc.: 50.78%] [G loss: 0.721948]\n",
      "epoch:30 step:23993 [D loss: 0.670376, acc.: 60.94%] [G loss: 0.768102]\n",
      "epoch:30 step:23994 [D loss: 0.678693, acc.: 60.94%] [G loss: 0.768933]\n",
      "epoch:30 step:23995 [D loss: 0.637221, acc.: 61.72%] [G loss: 0.804510]\n",
      "epoch:30 step:23996 [D loss: 0.690137, acc.: 53.12%] [G loss: 0.781269]\n",
      "epoch:30 step:23997 [D loss: 0.747322, acc.: 34.38%] [G loss: 0.709172]\n",
      "epoch:30 step:23998 [D loss: 0.686776, acc.: 57.03%] [G loss: 0.826790]\n",
      "epoch:30 step:23999 [D loss: 0.694013, acc.: 51.56%] [G loss: 0.759028]\n",
      "epoch:30 step:24000 [D loss: 0.673533, acc.: 58.59%] [G loss: 0.740656]\n",
      "epoch:30 step:24001 [D loss: 0.678570, acc.: 53.91%] [G loss: 0.714021]\n",
      "epoch:30 step:24002 [D loss: 0.692923, acc.: 53.91%] [G loss: 0.747838]\n",
      "epoch:30 step:24003 [D loss: 0.675300, acc.: 60.94%] [G loss: 0.721428]\n",
      "epoch:30 step:24004 [D loss: 0.725691, acc.: 50.78%] [G loss: 0.738167]\n",
      "epoch:30 step:24005 [D loss: 0.710322, acc.: 42.97%] [G loss: 0.667171]\n",
      "epoch:30 step:24006 [D loss: 0.658742, acc.: 59.38%] [G loss: 0.758030]\n",
      "epoch:30 step:24007 [D loss: 0.686614, acc.: 47.66%] [G loss: 0.710339]\n",
      "epoch:30 step:24008 [D loss: 0.667866, acc.: 61.72%] [G loss: 0.746781]\n",
      "epoch:30 step:24009 [D loss: 0.705965, acc.: 52.34%] [G loss: 0.732570]\n",
      "epoch:30 step:24010 [D loss: 0.722297, acc.: 47.66%] [G loss: 0.721963]\n",
      "epoch:30 step:24011 [D loss: 0.700254, acc.: 46.88%] [G loss: 0.737218]\n",
      "epoch:30 step:24012 [D loss: 0.674572, acc.: 57.81%] [G loss: 0.707013]\n",
      "epoch:30 step:24013 [D loss: 0.665531, acc.: 60.94%] [G loss: 0.772211]\n",
      "epoch:30 step:24014 [D loss: 0.668570, acc.: 59.38%] [G loss: 0.790067]\n",
      "epoch:30 step:24015 [D loss: 0.693242, acc.: 50.00%] [G loss: 0.737702]\n",
      "epoch:30 step:24016 [D loss: 0.636512, acc.: 66.41%] [G loss: 0.798985]\n",
      "epoch:30 step:24017 [D loss: 0.634407, acc.: 70.31%] [G loss: 0.754463]\n",
      "epoch:30 step:24018 [D loss: 0.620397, acc.: 75.78%] [G loss: 0.827622]\n",
      "epoch:30 step:24019 [D loss: 0.674139, acc.: 52.34%] [G loss: 0.803040]\n",
      "epoch:30 step:24020 [D loss: 0.691162, acc.: 50.00%] [G loss: 0.778597]\n",
      "epoch:30 step:24021 [D loss: 0.683106, acc.: 54.69%] [G loss: 0.817592]\n",
      "epoch:30 step:24022 [D loss: 0.704769, acc.: 55.47%] [G loss: 0.829517]\n",
      "epoch:30 step:24023 [D loss: 0.694403, acc.: 48.44%] [G loss: 0.767464]\n",
      "epoch:30 step:24024 [D loss: 0.718896, acc.: 47.66%] [G loss: 0.798696]\n",
      "epoch:30 step:24025 [D loss: 0.622978, acc.: 71.88%] [G loss: 0.781242]\n",
      "epoch:30 step:24026 [D loss: 0.704845, acc.: 45.31%] [G loss: 0.783244]\n",
      "epoch:30 step:24027 [D loss: 0.687468, acc.: 53.91%] [G loss: 0.852365]\n",
      "epoch:30 step:24028 [D loss: 0.661157, acc.: 61.72%] [G loss: 0.760809]\n",
      "epoch:30 step:24029 [D loss: 0.666982, acc.: 60.16%] [G loss: 0.798706]\n",
      "epoch:30 step:24030 [D loss: 0.719718, acc.: 47.66%] [G loss: 0.689791]\n",
      "epoch:30 step:24031 [D loss: 0.706129, acc.: 53.12%] [G loss: 0.724317]\n",
      "epoch:30 step:24032 [D loss: 0.690509, acc.: 53.91%] [G loss: 0.698255]\n",
      "epoch:30 step:24033 [D loss: 0.744328, acc.: 34.38%] [G loss: 0.704386]\n",
      "epoch:30 step:24034 [D loss: 0.682946, acc.: 52.34%] [G loss: 0.789929]\n",
      "epoch:30 step:24035 [D loss: 0.699388, acc.: 50.00%] [G loss: 0.745265]\n",
      "epoch:30 step:24036 [D loss: 0.718694, acc.: 47.66%] [G loss: 0.711589]\n",
      "epoch:30 step:24037 [D loss: 0.682747, acc.: 54.69%] [G loss: 0.702717]\n",
      "epoch:30 step:24038 [D loss: 0.667955, acc.: 65.62%] [G loss: 0.786907]\n",
      "epoch:30 step:24039 [D loss: 0.667686, acc.: 50.00%] [G loss: 0.765458]\n",
      "epoch:30 step:24040 [D loss: 0.705566, acc.: 46.09%] [G loss: 0.714224]\n",
      "epoch:30 step:24041 [D loss: 0.750012, acc.: 41.41%] [G loss: 0.674393]\n",
      "epoch:30 step:24042 [D loss: 0.730264, acc.: 42.19%] [G loss: 0.832487]\n",
      "epoch:30 step:24043 [D loss: 0.686979, acc.: 52.34%] [G loss: 0.810802]\n",
      "epoch:30 step:24044 [D loss: 0.722555, acc.: 46.88%] [G loss: 0.694930]\n",
      "epoch:30 step:24045 [D loss: 0.715807, acc.: 45.31%] [G loss: 0.746239]\n",
      "epoch:30 step:24046 [D loss: 0.697322, acc.: 51.56%] [G loss: 0.801104]\n",
      "epoch:30 step:24047 [D loss: 0.663251, acc.: 65.62%] [G loss: 0.850102]\n",
      "epoch:30 step:24048 [D loss: 0.627044, acc.: 70.31%] [G loss: 0.863597]\n",
      "epoch:30 step:24049 [D loss: 0.716603, acc.: 51.56%] [G loss: 0.764544]\n",
      "epoch:30 step:24050 [D loss: 0.705794, acc.: 53.12%] [G loss: 0.806903]\n",
      "epoch:30 step:24051 [D loss: 0.688177, acc.: 53.12%] [G loss: 0.807889]\n",
      "epoch:30 step:24052 [D loss: 0.682699, acc.: 51.56%] [G loss: 0.748008]\n",
      "epoch:30 step:24053 [D loss: 0.680708, acc.: 54.69%] [G loss: 0.821910]\n",
      "epoch:30 step:24054 [D loss: 0.654272, acc.: 60.94%] [G loss: 0.747949]\n",
      "epoch:30 step:24055 [D loss: 0.696424, acc.: 51.56%] [G loss: 0.740136]\n",
      "epoch:30 step:24056 [D loss: 0.715807, acc.: 44.53%] [G loss: 0.716274]\n",
      "epoch:30 step:24057 [D loss: 0.694278, acc.: 45.31%] [G loss: 0.756795]\n",
      "epoch:30 step:24058 [D loss: 0.676383, acc.: 60.94%] [G loss: 0.757192]\n",
      "epoch:30 step:24059 [D loss: 0.737782, acc.: 44.53%] [G loss: 0.745903]\n",
      "epoch:30 step:24060 [D loss: 0.694149, acc.: 57.03%] [G loss: 0.752887]\n",
      "epoch:30 step:24061 [D loss: 0.748823, acc.: 39.84%] [G loss: 0.828579]\n",
      "epoch:30 step:24062 [D loss: 0.646198, acc.: 69.53%] [G loss: 0.759064]\n",
      "epoch:30 step:24063 [D loss: 0.718153, acc.: 51.56%] [G loss: 0.731141]\n",
      "epoch:30 step:24064 [D loss: 0.731237, acc.: 46.09%] [G loss: 0.739127]\n",
      "epoch:30 step:24065 [D loss: 0.722518, acc.: 51.56%] [G loss: 0.744346]\n",
      "epoch:30 step:24066 [D loss: 0.675952, acc.: 58.59%] [G loss: 0.708736]\n",
      "epoch:30 step:24067 [D loss: 0.662888, acc.: 59.38%] [G loss: 0.800960]\n",
      "epoch:30 step:24068 [D loss: 0.707697, acc.: 42.19%] [G loss: 0.726931]\n",
      "epoch:30 step:24069 [D loss: 0.676628, acc.: 54.69%] [G loss: 0.710736]\n",
      "epoch:30 step:24070 [D loss: 0.716604, acc.: 46.88%] [G loss: 0.727915]\n",
      "epoch:30 step:24071 [D loss: 0.666673, acc.: 58.59%] [G loss: 0.698209]\n",
      "epoch:30 step:24072 [D loss: 0.686147, acc.: 53.12%] [G loss: 0.907581]\n",
      "epoch:30 step:24073 [D loss: 0.697258, acc.: 48.44%] [G loss: 0.761158]\n",
      "epoch:30 step:24074 [D loss: 0.701800, acc.: 50.00%] [G loss: 0.723123]\n",
      "epoch:30 step:24075 [D loss: 0.657724, acc.: 57.03%] [G loss: 0.761205]\n",
      "epoch:30 step:24076 [D loss: 0.667503, acc.: 57.81%] [G loss: 0.823333]\n",
      "epoch:30 step:24077 [D loss: 0.750842, acc.: 45.31%] [G loss: 0.786771]\n",
      "epoch:30 step:24078 [D loss: 0.690407, acc.: 54.69%] [G loss: 0.765724]\n",
      "epoch:30 step:24079 [D loss: 0.665988, acc.: 57.03%] [G loss: 0.719038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24080 [D loss: 0.683230, acc.: 52.34%] [G loss: 0.750847]\n",
      "epoch:30 step:24081 [D loss: 0.641442, acc.: 66.41%] [G loss: 0.749231]\n",
      "epoch:30 step:24082 [D loss: 0.646636, acc.: 72.66%] [G loss: 0.795179]\n",
      "epoch:30 step:24083 [D loss: 0.691274, acc.: 53.91%] [G loss: 0.807981]\n",
      "epoch:30 step:24084 [D loss: 0.708843, acc.: 46.09%] [G loss: 0.698762]\n",
      "epoch:30 step:24085 [D loss: 0.679026, acc.: 57.81%] [G loss: 0.718261]\n",
      "epoch:30 step:24086 [D loss: 0.677995, acc.: 56.25%] [G loss: 0.756793]\n",
      "epoch:30 step:24087 [D loss: 0.676998, acc.: 60.94%] [G loss: 0.814451]\n",
      "epoch:30 step:24088 [D loss: 0.666288, acc.: 57.03%] [G loss: 0.826388]\n",
      "epoch:30 step:24089 [D loss: 0.684945, acc.: 53.91%] [G loss: 0.742835]\n",
      "epoch:30 step:24090 [D loss: 0.720693, acc.: 44.53%] [G loss: 0.712822]\n",
      "epoch:30 step:24091 [D loss: 0.687396, acc.: 56.25%] [G loss: 0.767354]\n",
      "epoch:30 step:24092 [D loss: 0.680117, acc.: 53.12%] [G loss: 0.693948]\n",
      "epoch:30 step:24093 [D loss: 0.674003, acc.: 54.69%] [G loss: 0.725308]\n",
      "epoch:30 step:24094 [D loss: 0.691705, acc.: 55.47%] [G loss: 0.667141]\n",
      "epoch:30 step:24095 [D loss: 0.699085, acc.: 53.12%] [G loss: 0.715261]\n",
      "epoch:30 step:24096 [D loss: 0.682104, acc.: 59.38%] [G loss: 0.708485]\n",
      "epoch:30 step:24097 [D loss: 0.716337, acc.: 39.06%] [G loss: 0.795392]\n",
      "epoch:30 step:24098 [D loss: 0.717737, acc.: 46.88%] [G loss: 0.703637]\n",
      "epoch:30 step:24099 [D loss: 0.684918, acc.: 50.78%] [G loss: 0.768357]\n",
      "epoch:30 step:24100 [D loss: 0.654916, acc.: 63.28%] [G loss: 0.816847]\n",
      "epoch:30 step:24101 [D loss: 0.715299, acc.: 52.34%] [G loss: 0.757314]\n",
      "epoch:30 step:24102 [D loss: 0.730704, acc.: 49.22%] [G loss: 0.740813]\n",
      "epoch:30 step:24103 [D loss: 0.634798, acc.: 68.75%] [G loss: 0.776435]\n",
      "epoch:30 step:24104 [D loss: 0.730805, acc.: 40.62%] [G loss: 0.868905]\n",
      "epoch:30 step:24105 [D loss: 0.690214, acc.: 57.03%] [G loss: 0.774916]\n",
      "epoch:30 step:24106 [D loss: 0.720877, acc.: 45.31%] [G loss: 0.843450]\n",
      "epoch:30 step:24107 [D loss: 0.688204, acc.: 52.34%] [G loss: 0.759747]\n",
      "epoch:30 step:24108 [D loss: 0.733624, acc.: 38.28%] [G loss: 0.860103]\n",
      "epoch:30 step:24109 [D loss: 0.650549, acc.: 66.41%] [G loss: 0.745200]\n",
      "epoch:30 step:24110 [D loss: 0.679223, acc.: 61.72%] [G loss: 0.848469]\n",
      "epoch:30 step:24111 [D loss: 0.687140, acc.: 50.78%] [G loss: 0.823863]\n",
      "epoch:30 step:24112 [D loss: 0.736734, acc.: 36.72%] [G loss: 0.793119]\n",
      "epoch:30 step:24113 [D loss: 0.702834, acc.: 46.88%] [G loss: 0.833857]\n",
      "epoch:30 step:24114 [D loss: 0.734020, acc.: 37.50%] [G loss: 0.769590]\n",
      "epoch:30 step:24115 [D loss: 0.688204, acc.: 53.91%] [G loss: 0.798653]\n",
      "epoch:30 step:24116 [D loss: 0.688223, acc.: 54.69%] [G loss: 0.749745]\n",
      "epoch:30 step:24117 [D loss: 0.682536, acc.: 51.56%] [G loss: 0.768923]\n",
      "epoch:30 step:24118 [D loss: 0.736377, acc.: 42.19%] [G loss: 0.767345]\n",
      "epoch:30 step:24119 [D loss: 0.691570, acc.: 54.69%] [G loss: 0.763219]\n",
      "epoch:30 step:24120 [D loss: 0.668078, acc.: 60.94%] [G loss: 0.771660]\n",
      "epoch:30 step:24121 [D loss: 0.670286, acc.: 60.16%] [G loss: 0.792956]\n",
      "epoch:30 step:24122 [D loss: 0.711389, acc.: 44.53%] [G loss: 0.753264]\n",
      "epoch:30 step:24123 [D loss: 0.651658, acc.: 62.50%] [G loss: 0.789484]\n",
      "epoch:30 step:24124 [D loss: 0.700819, acc.: 48.44%] [G loss: 0.746728]\n",
      "epoch:30 step:24125 [D loss: 0.693307, acc.: 57.81%] [G loss: 0.764326]\n",
      "epoch:30 step:24126 [D loss: 0.716968, acc.: 46.88%] [G loss: 0.720829]\n",
      "epoch:30 step:24127 [D loss: 0.671947, acc.: 59.38%] [G loss: 0.689545]\n",
      "epoch:30 step:24128 [D loss: 0.623604, acc.: 73.44%] [G loss: 0.764024]\n",
      "epoch:30 step:24129 [D loss: 0.721157, acc.: 42.97%] [G loss: 0.629863]\n",
      "epoch:30 step:24130 [D loss: 0.628733, acc.: 71.88%] [G loss: 0.773115]\n",
      "epoch:30 step:24131 [D loss: 0.713555, acc.: 46.88%] [G loss: 0.664205]\n",
      "epoch:30 step:24132 [D loss: 0.638255, acc.: 64.84%] [G loss: 0.794182]\n",
      "epoch:30 step:24133 [D loss: 0.717110, acc.: 50.78%] [G loss: 0.740708]\n",
      "epoch:30 step:24134 [D loss: 0.671503, acc.: 60.94%] [G loss: 0.688244]\n",
      "epoch:30 step:24135 [D loss: 0.687390, acc.: 58.59%] [G loss: 0.728727]\n",
      "epoch:30 step:24136 [D loss: 0.652741, acc.: 61.72%] [G loss: 0.839097]\n",
      "epoch:30 step:24137 [D loss: 0.725104, acc.: 42.97%] [G loss: 0.785250]\n",
      "epoch:30 step:24138 [D loss: 0.735429, acc.: 43.75%] [G loss: 0.730043]\n",
      "epoch:30 step:24139 [D loss: 0.714808, acc.: 45.31%] [G loss: 0.658650]\n",
      "epoch:30 step:24140 [D loss: 0.681568, acc.: 54.69%] [G loss: 0.772292]\n",
      "epoch:30 step:24141 [D loss: 0.642731, acc.: 73.44%] [G loss: 0.823722]\n",
      "epoch:30 step:24142 [D loss: 0.689880, acc.: 53.91%] [G loss: 0.710615]\n",
      "epoch:30 step:24143 [D loss: 0.697794, acc.: 57.03%] [G loss: 0.704396]\n",
      "epoch:30 step:24144 [D loss: 0.661339, acc.: 57.81%] [G loss: 0.759965]\n",
      "epoch:30 step:24145 [D loss: 0.658836, acc.: 63.28%] [G loss: 0.711612]\n",
      "epoch:30 step:24146 [D loss: 0.696588, acc.: 51.56%] [G loss: 0.753937]\n",
      "epoch:30 step:24147 [D loss: 0.689306, acc.: 59.38%] [G loss: 0.677879]\n",
      "epoch:30 step:24148 [D loss: 0.665734, acc.: 57.81%] [G loss: 0.732190]\n",
      "epoch:30 step:24149 [D loss: 0.672668, acc.: 60.16%] [G loss: 0.777261]\n",
      "epoch:30 step:24150 [D loss: 0.705147, acc.: 50.00%] [G loss: 0.703392]\n",
      "epoch:30 step:24151 [D loss: 0.708391, acc.: 53.12%] [G loss: 0.688740]\n",
      "epoch:30 step:24152 [D loss: 0.719109, acc.: 49.22%] [G loss: 0.710493]\n",
      "epoch:30 step:24153 [D loss: 0.777517, acc.: 32.03%] [G loss: 0.740567]\n",
      "epoch:30 step:24154 [D loss: 0.668772, acc.: 64.06%] [G loss: 0.789725]\n",
      "epoch:30 step:24155 [D loss: 0.662785, acc.: 59.38%] [G loss: 0.741921]\n",
      "epoch:30 step:24156 [D loss: 0.635556, acc.: 71.09%] [G loss: 0.678606]\n",
      "epoch:30 step:24157 [D loss: 0.694695, acc.: 49.22%] [G loss: 0.781349]\n",
      "epoch:30 step:24158 [D loss: 0.704773, acc.: 53.12%] [G loss: 0.769144]\n",
      "epoch:30 step:24159 [D loss: 0.663806, acc.: 60.94%] [G loss: 0.755098]\n",
      "epoch:30 step:24160 [D loss: 0.682233, acc.: 58.59%] [G loss: 0.768887]\n",
      "epoch:30 step:24161 [D loss: 0.675727, acc.: 57.81%] [G loss: 0.787599]\n",
      "epoch:30 step:24162 [D loss: 0.693538, acc.: 53.91%] [G loss: 0.800193]\n",
      "epoch:30 step:24163 [D loss: 0.688498, acc.: 58.59%] [G loss: 0.758854]\n",
      "epoch:30 step:24164 [D loss: 0.703635, acc.: 50.00%] [G loss: 0.730298]\n",
      "epoch:30 step:24165 [D loss: 0.726407, acc.: 42.19%] [G loss: 0.751793]\n",
      "epoch:30 step:24166 [D loss: 0.737671, acc.: 31.25%] [G loss: 0.771466]\n",
      "epoch:30 step:24167 [D loss: 0.700609, acc.: 49.22%] [G loss: 0.803779]\n",
      "epoch:30 step:24168 [D loss: 0.674485, acc.: 57.03%] [G loss: 0.748160]\n",
      "epoch:30 step:24169 [D loss: 0.671527, acc.: 58.59%] [G loss: 0.801917]\n",
      "epoch:30 step:24170 [D loss: 0.667034, acc.: 59.38%] [G loss: 0.791793]\n",
      "epoch:30 step:24171 [D loss: 0.604779, acc.: 68.75%] [G loss: 0.847816]\n",
      "epoch:30 step:24172 [D loss: 0.652646, acc.: 60.16%] [G loss: 0.813185]\n",
      "epoch:30 step:24173 [D loss: 0.690604, acc.: 50.00%] [G loss: 0.757978]\n",
      "epoch:30 step:24174 [D loss: 0.686342, acc.: 50.78%] [G loss: 0.781199]\n",
      "epoch:30 step:24175 [D loss: 0.655169, acc.: 60.94%] [G loss: 0.770253]\n",
      "epoch:30 step:24176 [D loss: 0.672783, acc.: 59.38%] [G loss: 0.793446]\n",
      "epoch:30 step:24177 [D loss: 0.668120, acc.: 59.38%] [G loss: 0.759496]\n",
      "epoch:30 step:24178 [D loss: 0.720806, acc.: 48.44%] [G loss: 0.766640]\n",
      "epoch:30 step:24179 [D loss: 0.700740, acc.: 51.56%] [G loss: 0.780569]\n",
      "epoch:30 step:24180 [D loss: 0.695935, acc.: 57.81%] [G loss: 0.727360]\n",
      "epoch:30 step:24181 [D loss: 0.676495, acc.: 55.47%] [G loss: 0.706683]\n",
      "epoch:30 step:24182 [D loss: 0.674890, acc.: 61.72%] [G loss: 0.756150]\n",
      "epoch:30 step:24183 [D loss: 0.651094, acc.: 64.06%] [G loss: 0.712804]\n",
      "epoch:30 step:24184 [D loss: 0.673667, acc.: 65.62%] [G loss: 0.706620]\n",
      "epoch:30 step:24185 [D loss: 0.702607, acc.: 46.09%] [G loss: 0.763426]\n",
      "epoch:30 step:24186 [D loss: 0.705440, acc.: 46.09%] [G loss: 0.774074]\n",
      "epoch:30 step:24187 [D loss: 0.736834, acc.: 47.66%] [G loss: 0.768992]\n",
      "epoch:30 step:24188 [D loss: 0.631278, acc.: 66.41%] [G loss: 0.819550]\n",
      "epoch:30 step:24189 [D loss: 0.692782, acc.: 50.78%] [G loss: 0.817700]\n",
      "epoch:30 step:24190 [D loss: 0.695543, acc.: 51.56%] [G loss: 0.791811]\n",
      "epoch:30 step:24191 [D loss: 0.648598, acc.: 60.94%] [G loss: 0.798710]\n",
      "epoch:30 step:24192 [D loss: 0.704901, acc.: 52.34%] [G loss: 0.787266]\n",
      "epoch:30 step:24193 [D loss: 0.754513, acc.: 37.50%] [G loss: 0.774072]\n",
      "epoch:30 step:24194 [D loss: 0.683512, acc.: 64.06%] [G loss: 0.795659]\n",
      "epoch:30 step:24195 [D loss: 0.696536, acc.: 55.47%] [G loss: 0.836579]\n",
      "epoch:30 step:24196 [D loss: 0.718914, acc.: 45.31%] [G loss: 0.821965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24197 [D loss: 0.684914, acc.: 50.00%] [G loss: 0.769885]\n",
      "epoch:30 step:24198 [D loss: 0.648364, acc.: 70.31%] [G loss: 0.853659]\n",
      "epoch:30 step:24199 [D loss: 0.684388, acc.: 52.34%] [G loss: 0.836161]\n",
      "epoch:30 step:24200 [D loss: 0.702158, acc.: 50.00%] [G loss: 0.786968]\n",
      "epoch:30 step:24201 [D loss: 0.670859, acc.: 55.47%] [G loss: 0.872362]\n",
      "epoch:30 step:24202 [D loss: 0.701339, acc.: 49.22%] [G loss: 0.813572]\n",
      "epoch:30 step:24203 [D loss: 0.641122, acc.: 68.75%] [G loss: 0.721002]\n",
      "epoch:30 step:24204 [D loss: 0.663076, acc.: 59.38%] [G loss: 0.842481]\n",
      "epoch:30 step:24205 [D loss: 0.656916, acc.: 58.59%] [G loss: 0.802449]\n",
      "epoch:30 step:24206 [D loss: 0.706800, acc.: 51.56%] [G loss: 0.777429]\n",
      "epoch:30 step:24207 [D loss: 0.702893, acc.: 44.53%] [G loss: 0.718227]\n",
      "epoch:30 step:24208 [D loss: 0.679222, acc.: 61.72%] [G loss: 0.813763]\n",
      "epoch:30 step:24209 [D loss: 0.673271, acc.: 60.16%] [G loss: 0.702060]\n",
      "epoch:30 step:24210 [D loss: 0.742743, acc.: 39.84%] [G loss: 0.733626]\n",
      "epoch:30 step:24211 [D loss: 0.629604, acc.: 69.53%] [G loss: 0.776871]\n",
      "epoch:31 step:24212 [D loss: 0.664769, acc.: 64.06%] [G loss: 0.775843]\n",
      "epoch:31 step:24213 [D loss: 0.681186, acc.: 59.38%] [G loss: 0.818011]\n",
      "epoch:31 step:24214 [D loss: 0.706565, acc.: 49.22%] [G loss: 0.729455]\n",
      "epoch:31 step:24215 [D loss: 0.692481, acc.: 53.12%] [G loss: 0.826481]\n",
      "epoch:31 step:24216 [D loss: 0.715084, acc.: 48.44%] [G loss: 0.749236]\n",
      "epoch:31 step:24217 [D loss: 0.642236, acc.: 68.75%] [G loss: 0.789128]\n",
      "epoch:31 step:24218 [D loss: 0.661109, acc.: 62.50%] [G loss: 0.853113]\n",
      "epoch:31 step:24219 [D loss: 0.682471, acc.: 51.56%] [G loss: 0.854550]\n",
      "epoch:31 step:24220 [D loss: 0.653537, acc.: 60.16%] [G loss: 0.809036]\n",
      "epoch:31 step:24221 [D loss: 0.686819, acc.: 52.34%] [G loss: 0.783455]\n",
      "epoch:31 step:24222 [D loss: 0.657851, acc.: 57.03%] [G loss: 0.819392]\n",
      "epoch:31 step:24223 [D loss: 0.732592, acc.: 46.88%] [G loss: 0.770121]\n",
      "epoch:31 step:24224 [D loss: 0.640831, acc.: 67.19%] [G loss: 0.819677]\n",
      "epoch:31 step:24225 [D loss: 0.668345, acc.: 53.91%] [G loss: 0.719439]\n",
      "epoch:31 step:24226 [D loss: 0.714832, acc.: 50.78%] [G loss: 0.828804]\n",
      "epoch:31 step:24227 [D loss: 0.643445, acc.: 65.62%] [G loss: 0.744355]\n",
      "epoch:31 step:24228 [D loss: 0.692967, acc.: 52.34%] [G loss: 0.723427]\n",
      "epoch:31 step:24229 [D loss: 0.708997, acc.: 52.34%] [G loss: 0.738518]\n",
      "epoch:31 step:24230 [D loss: 0.699156, acc.: 46.88%] [G loss: 0.765181]\n",
      "epoch:31 step:24231 [D loss: 0.661962, acc.: 68.75%] [G loss: 0.794438]\n",
      "epoch:31 step:24232 [D loss: 0.670930, acc.: 56.25%] [G loss: 0.759242]\n",
      "epoch:31 step:24233 [D loss: 0.644554, acc.: 67.19%] [G loss: 0.779292]\n",
      "epoch:31 step:24234 [D loss: 0.717101, acc.: 48.44%] [G loss: 0.750476]\n",
      "epoch:31 step:24235 [D loss: 0.659747, acc.: 64.84%] [G loss: 0.884402]\n",
      "epoch:31 step:24236 [D loss: 0.717548, acc.: 46.09%] [G loss: 0.813896]\n",
      "epoch:31 step:24237 [D loss: 0.673268, acc.: 50.78%] [G loss: 0.688841]\n",
      "epoch:31 step:24238 [D loss: 0.669111, acc.: 63.28%] [G loss: 0.756978]\n",
      "epoch:31 step:24239 [D loss: 0.689676, acc.: 53.12%] [G loss: 0.765332]\n",
      "epoch:31 step:24240 [D loss: 0.718168, acc.: 46.09%] [G loss: 0.692075]\n",
      "epoch:31 step:24241 [D loss: 0.664288, acc.: 58.59%] [G loss: 0.782331]\n",
      "epoch:31 step:24242 [D loss: 0.709727, acc.: 46.88%] [G loss: 0.796106]\n",
      "epoch:31 step:24243 [D loss: 0.725596, acc.: 44.53%] [G loss: 0.794192]\n",
      "epoch:31 step:24244 [D loss: 0.742095, acc.: 40.62%] [G loss: 0.764084]\n",
      "epoch:31 step:24245 [D loss: 0.673227, acc.: 62.50%] [G loss: 0.792954]\n",
      "epoch:31 step:24246 [D loss: 0.701111, acc.: 46.09%] [G loss: 0.756602]\n",
      "epoch:31 step:24247 [D loss: 0.739854, acc.: 44.53%] [G loss: 0.731827]\n",
      "epoch:31 step:24248 [D loss: 0.677451, acc.: 56.25%] [G loss: 0.768707]\n",
      "epoch:31 step:24249 [D loss: 0.712565, acc.: 46.88%] [G loss: 0.762855]\n",
      "epoch:31 step:24250 [D loss: 0.691145, acc.: 56.25%] [G loss: 0.765593]\n",
      "epoch:31 step:24251 [D loss: 0.715429, acc.: 47.66%] [G loss: 0.769556]\n",
      "epoch:31 step:24252 [D loss: 0.686950, acc.: 53.91%] [G loss: 0.743715]\n",
      "epoch:31 step:24253 [D loss: 0.674582, acc.: 59.38%] [G loss: 0.801401]\n",
      "epoch:31 step:24254 [D loss: 0.684576, acc.: 58.59%] [G loss: 0.653417]\n",
      "epoch:31 step:24255 [D loss: 0.711154, acc.: 50.78%] [G loss: 0.741972]\n",
      "epoch:31 step:24256 [D loss: 0.609412, acc.: 71.88%] [G loss: 0.799205]\n",
      "epoch:31 step:24257 [D loss: 0.663462, acc.: 56.25%] [G loss: 0.719104]\n",
      "epoch:31 step:24258 [D loss: 0.669672, acc.: 61.72%] [G loss: 0.759178]\n",
      "epoch:31 step:24259 [D loss: 0.671447, acc.: 48.44%] [G loss: 0.718528]\n",
      "epoch:31 step:24260 [D loss: 0.668571, acc.: 60.94%] [G loss: 0.666067]\n",
      "epoch:31 step:24261 [D loss: 0.666195, acc.: 58.59%] [G loss: 0.721320]\n",
      "epoch:31 step:24262 [D loss: 0.718224, acc.: 47.66%] [G loss: 0.667054]\n",
      "epoch:31 step:24263 [D loss: 0.644126, acc.: 64.84%] [G loss: 0.682904]\n",
      "epoch:31 step:24264 [D loss: 0.667857, acc.: 58.59%] [G loss: 0.778961]\n",
      "epoch:31 step:24265 [D loss: 0.710973, acc.: 47.66%] [G loss: 0.695856]\n",
      "epoch:31 step:24266 [D loss: 0.776632, acc.: 41.41%] [G loss: 0.721277]\n",
      "epoch:31 step:24267 [D loss: 0.676406, acc.: 62.50%] [G loss: 0.734480]\n",
      "epoch:31 step:24268 [D loss: 0.679549, acc.: 59.38%] [G loss: 0.808555]\n",
      "epoch:31 step:24269 [D loss: 0.697166, acc.: 53.12%] [G loss: 0.767061]\n",
      "epoch:31 step:24270 [D loss: 0.690340, acc.: 53.91%] [G loss: 0.828638]\n",
      "epoch:31 step:24271 [D loss: 0.636425, acc.: 69.53%] [G loss: 0.775848]\n",
      "epoch:31 step:24272 [D loss: 0.713043, acc.: 46.09%] [G loss: 0.772998]\n",
      "epoch:31 step:24273 [D loss: 0.660968, acc.: 58.59%] [G loss: 0.860016]\n",
      "epoch:31 step:24274 [D loss: 0.705557, acc.: 54.69%] [G loss: 0.797911]\n",
      "epoch:31 step:24275 [D loss: 0.685218, acc.: 53.12%] [G loss: 0.775792]\n",
      "epoch:31 step:24276 [D loss: 0.692714, acc.: 48.44%] [G loss: 0.807454]\n",
      "epoch:31 step:24277 [D loss: 0.727912, acc.: 42.97%] [G loss: 0.781368]\n",
      "epoch:31 step:24278 [D loss: 0.724712, acc.: 49.22%] [G loss: 0.805088]\n",
      "epoch:31 step:24279 [D loss: 0.680840, acc.: 57.81%] [G loss: 0.780523]\n",
      "epoch:31 step:24280 [D loss: 0.705956, acc.: 48.44%] [G loss: 0.794700]\n",
      "epoch:31 step:24281 [D loss: 0.685071, acc.: 58.59%] [G loss: 0.766617]\n",
      "epoch:31 step:24282 [D loss: 0.756246, acc.: 35.94%] [G loss: 0.748827]\n",
      "epoch:31 step:24283 [D loss: 0.670951, acc.: 58.59%] [G loss: 0.781760]\n",
      "epoch:31 step:24284 [D loss: 0.655103, acc.: 61.72%] [G loss: 0.755937]\n",
      "epoch:31 step:24285 [D loss: 0.675881, acc.: 58.59%] [G loss: 0.729687]\n",
      "epoch:31 step:24286 [D loss: 0.684591, acc.: 60.16%] [G loss: 0.780072]\n",
      "epoch:31 step:24287 [D loss: 0.651666, acc.: 61.72%] [G loss: 0.792529]\n",
      "epoch:31 step:24288 [D loss: 0.718877, acc.: 53.91%] [G loss: 0.691983]\n",
      "epoch:31 step:24289 [D loss: 0.695173, acc.: 50.78%] [G loss: 0.807260]\n",
      "epoch:31 step:24290 [D loss: 0.666070, acc.: 57.81%] [G loss: 0.814655]\n",
      "epoch:31 step:24291 [D loss: 0.662999, acc.: 55.47%] [G loss: 0.778925]\n",
      "epoch:31 step:24292 [D loss: 0.746151, acc.: 36.72%] [G loss: 0.755891]\n",
      "epoch:31 step:24293 [D loss: 0.682676, acc.: 52.34%] [G loss: 0.776459]\n",
      "epoch:31 step:24294 [D loss: 0.683779, acc.: 57.81%] [G loss: 0.758998]\n",
      "epoch:31 step:24295 [D loss: 0.662698, acc.: 60.94%] [G loss: 0.834094]\n",
      "epoch:31 step:24296 [D loss: 0.717563, acc.: 45.31%] [G loss: 0.775848]\n",
      "epoch:31 step:24297 [D loss: 0.670978, acc.: 57.03%] [G loss: 0.790995]\n",
      "epoch:31 step:24298 [D loss: 0.703060, acc.: 48.44%] [G loss: 0.786964]\n",
      "epoch:31 step:24299 [D loss: 0.703287, acc.: 54.69%] [G loss: 0.782850]\n",
      "epoch:31 step:24300 [D loss: 0.690995, acc.: 56.25%] [G loss: 0.782943]\n",
      "epoch:31 step:24301 [D loss: 0.701926, acc.: 54.69%] [G loss: 0.758404]\n",
      "epoch:31 step:24302 [D loss: 0.694089, acc.: 57.81%] [G loss: 0.785996]\n",
      "epoch:31 step:24303 [D loss: 0.699370, acc.: 47.66%] [G loss: 0.780394]\n",
      "epoch:31 step:24304 [D loss: 0.715017, acc.: 46.88%] [G loss: 0.767929]\n",
      "epoch:31 step:24305 [D loss: 0.723450, acc.: 43.75%] [G loss: 0.731056]\n",
      "epoch:31 step:24306 [D loss: 0.711486, acc.: 46.88%] [G loss: 0.776474]\n",
      "epoch:31 step:24307 [D loss: 0.699499, acc.: 49.22%] [G loss: 0.789793]\n",
      "epoch:31 step:24308 [D loss: 0.684568, acc.: 58.59%] [G loss: 0.816255]\n",
      "epoch:31 step:24309 [D loss: 0.683443, acc.: 55.47%] [G loss: 0.845801]\n",
      "epoch:31 step:24310 [D loss: 0.661485, acc.: 61.72%] [G loss: 0.785178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24311 [D loss: 0.670256, acc.: 60.16%] [G loss: 0.813280]\n",
      "epoch:31 step:24312 [D loss: 0.609459, acc.: 69.53%] [G loss: 0.818919]\n",
      "epoch:31 step:24313 [D loss: 0.698521, acc.: 53.91%] [G loss: 0.745737]\n",
      "epoch:31 step:24314 [D loss: 0.708883, acc.: 51.56%] [G loss: 0.783490]\n",
      "epoch:31 step:24315 [D loss: 0.721841, acc.: 46.09%] [G loss: 0.776341]\n",
      "epoch:31 step:24316 [D loss: 0.675584, acc.: 60.16%] [G loss: 0.749972]\n",
      "epoch:31 step:24317 [D loss: 0.715509, acc.: 47.66%] [G loss: 0.754321]\n",
      "epoch:31 step:24318 [D loss: 0.624029, acc.: 71.88%] [G loss: 0.785270]\n",
      "epoch:31 step:24319 [D loss: 0.724045, acc.: 45.31%] [G loss: 0.760993]\n",
      "epoch:31 step:24320 [D loss: 0.685296, acc.: 55.47%] [G loss: 0.748779]\n",
      "epoch:31 step:24321 [D loss: 0.700803, acc.: 47.66%] [G loss: 0.730018]\n",
      "epoch:31 step:24322 [D loss: 0.700343, acc.: 47.66%] [G loss: 0.655212]\n",
      "epoch:31 step:24323 [D loss: 0.685462, acc.: 57.03%] [G loss: 0.760193]\n",
      "epoch:31 step:24324 [D loss: 0.657330, acc.: 62.50%] [G loss: 0.758316]\n",
      "epoch:31 step:24325 [D loss: 0.658001, acc.: 64.06%] [G loss: 0.752620]\n",
      "epoch:31 step:24326 [D loss: 0.727240, acc.: 44.53%] [G loss: 0.762315]\n",
      "epoch:31 step:24327 [D loss: 0.736032, acc.: 45.31%] [G loss: 0.780657]\n",
      "epoch:31 step:24328 [D loss: 0.764615, acc.: 35.94%] [G loss: 0.729745]\n",
      "epoch:31 step:24329 [D loss: 0.685322, acc.: 57.03%] [G loss: 0.775005]\n",
      "epoch:31 step:24330 [D loss: 0.614985, acc.: 71.88%] [G loss: 0.777421]\n",
      "epoch:31 step:24331 [D loss: 0.690984, acc.: 51.56%] [G loss: 0.822877]\n",
      "epoch:31 step:24332 [D loss: 0.677186, acc.: 56.25%] [G loss: 0.781005]\n",
      "epoch:31 step:24333 [D loss: 0.722105, acc.: 46.09%] [G loss: 0.728408]\n",
      "epoch:31 step:24334 [D loss: 0.697194, acc.: 49.22%] [G loss: 0.777487]\n",
      "epoch:31 step:24335 [D loss: 0.641510, acc.: 60.94%] [G loss: 0.720027]\n",
      "epoch:31 step:24336 [D loss: 0.710483, acc.: 45.31%] [G loss: 0.713518]\n",
      "epoch:31 step:24337 [D loss: 0.665096, acc.: 60.94%] [G loss: 0.814679]\n",
      "epoch:31 step:24338 [D loss: 0.640176, acc.: 65.62%] [G loss: 0.763507]\n",
      "epoch:31 step:24339 [D loss: 0.679951, acc.: 54.69%] [G loss: 0.764026]\n",
      "epoch:31 step:24340 [D loss: 0.684310, acc.: 53.12%] [G loss: 0.792957]\n",
      "epoch:31 step:24341 [D loss: 0.683123, acc.: 48.44%] [G loss: 0.723874]\n",
      "epoch:31 step:24342 [D loss: 0.700189, acc.: 50.78%] [G loss: 0.722014]\n",
      "epoch:31 step:24343 [D loss: 0.664461, acc.: 61.72%] [G loss: 0.757654]\n",
      "epoch:31 step:24344 [D loss: 0.712687, acc.: 47.66%] [G loss: 0.717665]\n",
      "epoch:31 step:24345 [D loss: 0.693029, acc.: 55.47%] [G loss: 0.789370]\n",
      "epoch:31 step:24346 [D loss: 0.717295, acc.: 49.22%] [G loss: 0.779056]\n",
      "epoch:31 step:24347 [D loss: 0.665756, acc.: 60.94%] [G loss: 0.775001]\n",
      "epoch:31 step:24348 [D loss: 0.715036, acc.: 48.44%] [G loss: 0.878124]\n",
      "epoch:31 step:24349 [D loss: 0.689283, acc.: 56.25%] [G loss: 0.779636]\n",
      "epoch:31 step:24350 [D loss: 0.636001, acc.: 62.50%] [G loss: 0.815697]\n",
      "epoch:31 step:24351 [D loss: 0.692627, acc.: 50.00%] [G loss: 0.821833]\n",
      "epoch:31 step:24352 [D loss: 0.686267, acc.: 52.34%] [G loss: 0.763094]\n",
      "epoch:31 step:24353 [D loss: 0.667375, acc.: 57.03%] [G loss: 0.780856]\n",
      "epoch:31 step:24354 [D loss: 0.744325, acc.: 42.19%] [G loss: 0.782426]\n",
      "epoch:31 step:24355 [D loss: 0.710179, acc.: 46.88%] [G loss: 0.731372]\n",
      "epoch:31 step:24356 [D loss: 0.689384, acc.: 55.47%] [G loss: 0.735985]\n",
      "epoch:31 step:24357 [D loss: 0.636581, acc.: 69.53%] [G loss: 0.735493]\n",
      "epoch:31 step:24358 [D loss: 0.679460, acc.: 60.16%] [G loss: 0.765259]\n",
      "epoch:31 step:24359 [D loss: 0.667015, acc.: 58.59%] [G loss: 0.797345]\n",
      "epoch:31 step:24360 [D loss: 0.639276, acc.: 69.53%] [G loss: 0.820747]\n",
      "epoch:31 step:24361 [D loss: 0.705104, acc.: 49.22%] [G loss: 0.767605]\n",
      "epoch:31 step:24362 [D loss: 0.661896, acc.: 63.28%] [G loss: 0.802151]\n",
      "epoch:31 step:24363 [D loss: 0.630847, acc.: 71.09%] [G loss: 0.781277]\n",
      "epoch:31 step:24364 [D loss: 0.649289, acc.: 63.28%] [G loss: 0.763611]\n",
      "epoch:31 step:24365 [D loss: 0.703545, acc.: 54.69%] [G loss: 0.707165]\n",
      "epoch:31 step:24366 [D loss: 0.725120, acc.: 48.44%] [G loss: 0.760242]\n",
      "epoch:31 step:24367 [D loss: 0.705002, acc.: 50.78%] [G loss: 0.763215]\n",
      "epoch:31 step:24368 [D loss: 0.706330, acc.: 45.31%] [G loss: 0.705495]\n",
      "epoch:31 step:24369 [D loss: 0.660095, acc.: 63.28%] [G loss: 0.753263]\n",
      "epoch:31 step:24370 [D loss: 0.653286, acc.: 60.94%] [G loss: 0.727123]\n",
      "epoch:31 step:24371 [D loss: 0.647123, acc.: 64.06%] [G loss: 0.776751]\n",
      "epoch:31 step:24372 [D loss: 0.696977, acc.: 53.12%] [G loss: 0.746212]\n",
      "epoch:31 step:24373 [D loss: 0.673284, acc.: 58.59%] [G loss: 0.786281]\n",
      "epoch:31 step:24374 [D loss: 0.740175, acc.: 41.41%] [G loss: 0.737341]\n",
      "epoch:31 step:24375 [D loss: 0.697833, acc.: 48.44%] [G loss: 0.771897]\n",
      "epoch:31 step:24376 [D loss: 0.744738, acc.: 44.53%] [G loss: 0.759548]\n",
      "epoch:31 step:24377 [D loss: 0.688013, acc.: 50.00%] [G loss: 0.777676]\n",
      "epoch:31 step:24378 [D loss: 0.740673, acc.: 43.75%] [G loss: 0.732876]\n",
      "epoch:31 step:24379 [D loss: 0.653782, acc.: 61.72%] [G loss: 0.747559]\n",
      "epoch:31 step:24380 [D loss: 0.724371, acc.: 45.31%] [G loss: 0.711277]\n",
      "epoch:31 step:24381 [D loss: 0.641641, acc.: 67.19%] [G loss: 0.813133]\n",
      "epoch:31 step:24382 [D loss: 0.720559, acc.: 49.22%] [G loss: 0.792009]\n",
      "epoch:31 step:24383 [D loss: 0.675161, acc.: 58.59%] [G loss: 0.776407]\n",
      "epoch:31 step:24384 [D loss: 0.713206, acc.: 43.75%] [G loss: 0.790989]\n",
      "epoch:31 step:24385 [D loss: 0.674741, acc.: 56.25%] [G loss: 0.825876]\n",
      "epoch:31 step:24386 [D loss: 0.662841, acc.: 56.25%] [G loss: 0.826835]\n",
      "epoch:31 step:24387 [D loss: 0.644067, acc.: 64.06%] [G loss: 0.771998]\n",
      "epoch:31 step:24388 [D loss: 0.700779, acc.: 49.22%] [G loss: 0.812253]\n",
      "epoch:31 step:24389 [D loss: 0.697801, acc.: 53.91%] [G loss: 0.800191]\n",
      "epoch:31 step:24390 [D loss: 0.663207, acc.: 64.06%] [G loss: 0.774841]\n",
      "epoch:31 step:24391 [D loss: 0.657986, acc.: 60.94%] [G loss: 0.841561]\n",
      "epoch:31 step:24392 [D loss: 0.627272, acc.: 68.75%] [G loss: 0.759953]\n",
      "epoch:31 step:24393 [D loss: 0.729066, acc.: 44.53%] [G loss: 0.783252]\n",
      "epoch:31 step:24394 [D loss: 0.665602, acc.: 68.75%] [G loss: 0.741087]\n",
      "epoch:31 step:24395 [D loss: 0.696670, acc.: 50.00%] [G loss: 0.859199]\n",
      "epoch:31 step:24396 [D loss: 0.680034, acc.: 57.03%] [G loss: 0.838013]\n",
      "epoch:31 step:24397 [D loss: 0.700376, acc.: 53.12%] [G loss: 0.732590]\n",
      "epoch:31 step:24398 [D loss: 0.767149, acc.: 37.50%] [G loss: 0.738909]\n",
      "epoch:31 step:24399 [D loss: 0.693210, acc.: 50.78%] [G loss: 0.744016]\n",
      "epoch:31 step:24400 [D loss: 0.680041, acc.: 53.12%] [G loss: 0.820811]\n",
      "epoch:31 step:24401 [D loss: 0.750175, acc.: 35.16%] [G loss: 0.790091]\n",
      "epoch:31 step:24402 [D loss: 0.701134, acc.: 50.78%] [G loss: 0.735444]\n",
      "epoch:31 step:24403 [D loss: 0.658569, acc.: 60.94%] [G loss: 0.725510]\n",
      "epoch:31 step:24404 [D loss: 0.730871, acc.: 42.19%] [G loss: 0.797804]\n",
      "epoch:31 step:24405 [D loss: 0.668950, acc.: 58.59%] [G loss: 0.779962]\n",
      "epoch:31 step:24406 [D loss: 0.735160, acc.: 44.53%] [G loss: 0.822446]\n",
      "epoch:31 step:24407 [D loss: 0.652357, acc.: 59.38%] [G loss: 0.836282]\n",
      "epoch:31 step:24408 [D loss: 0.711208, acc.: 50.78%] [G loss: 0.831007]\n",
      "epoch:31 step:24409 [D loss: 0.653068, acc.: 60.16%] [G loss: 0.782562]\n",
      "epoch:31 step:24410 [D loss: 0.697982, acc.: 57.03%] [G loss: 0.741153]\n",
      "epoch:31 step:24411 [D loss: 0.670328, acc.: 60.94%] [G loss: 0.763853]\n",
      "epoch:31 step:24412 [D loss: 0.682163, acc.: 49.22%] [G loss: 0.747321]\n",
      "epoch:31 step:24413 [D loss: 0.659520, acc.: 58.59%] [G loss: 0.780699]\n",
      "epoch:31 step:24414 [D loss: 0.681148, acc.: 58.59%] [G loss: 0.798214]\n",
      "epoch:31 step:24415 [D loss: 0.637513, acc.: 63.28%] [G loss: 0.838980]\n",
      "epoch:31 step:24416 [D loss: 0.697292, acc.: 53.91%] [G loss: 0.792753]\n",
      "epoch:31 step:24417 [D loss: 0.697957, acc.: 46.09%] [G loss: 0.731722]\n",
      "epoch:31 step:24418 [D loss: 0.686912, acc.: 60.94%] [G loss: 0.814402]\n",
      "epoch:31 step:24419 [D loss: 0.675312, acc.: 57.03%] [G loss: 0.810906]\n",
      "epoch:31 step:24420 [D loss: 0.673605, acc.: 60.16%] [G loss: 0.807553]\n",
      "epoch:31 step:24421 [D loss: 0.628711, acc.: 72.66%] [G loss: 0.824499]\n",
      "epoch:31 step:24422 [D loss: 0.698453, acc.: 56.25%] [G loss: 0.791604]\n",
      "epoch:31 step:24423 [D loss: 0.691094, acc.: 52.34%] [G loss: 0.768338]\n",
      "epoch:31 step:24424 [D loss: 0.726044, acc.: 40.62%] [G loss: 0.731034]\n",
      "epoch:31 step:24425 [D loss: 0.710288, acc.: 49.22%] [G loss: 0.786391]\n",
      "epoch:31 step:24426 [D loss: 0.652485, acc.: 63.28%] [G loss: 0.816223]\n",
      "epoch:31 step:24427 [D loss: 0.690948, acc.: 56.25%] [G loss: 0.703897]\n",
      "epoch:31 step:24428 [D loss: 0.733139, acc.: 39.06%] [G loss: 0.729997]\n",
      "epoch:31 step:24429 [D loss: 0.703328, acc.: 53.12%] [G loss: 0.794859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24430 [D loss: 0.669072, acc.: 55.47%] [G loss: 0.751396]\n",
      "epoch:31 step:24431 [D loss: 0.674312, acc.: 56.25%] [G loss: 0.740726]\n",
      "epoch:31 step:24432 [D loss: 0.709432, acc.: 47.66%] [G loss: 0.780035]\n",
      "epoch:31 step:24433 [D loss: 0.688671, acc.: 52.34%] [G loss: 0.763410]\n",
      "epoch:31 step:24434 [D loss: 0.684455, acc.: 58.59%] [G loss: 0.762046]\n",
      "epoch:31 step:24435 [D loss: 0.709206, acc.: 48.44%] [G loss: 0.698895]\n",
      "epoch:31 step:24436 [D loss: 0.722967, acc.: 42.19%] [G loss: 0.733708]\n",
      "epoch:31 step:24437 [D loss: 0.724679, acc.: 47.66%] [G loss: 0.662679]\n",
      "epoch:31 step:24438 [D loss: 0.689659, acc.: 57.03%] [G loss: 0.778237]\n",
      "epoch:31 step:24439 [D loss: 0.661448, acc.: 59.38%] [G loss: 0.762348]\n",
      "epoch:31 step:24440 [D loss: 0.700631, acc.: 54.69%] [G loss: 0.775044]\n",
      "epoch:31 step:24441 [D loss: 0.687696, acc.: 57.81%] [G loss: 0.765434]\n",
      "epoch:31 step:24442 [D loss: 0.654710, acc.: 64.84%] [G loss: 0.735584]\n",
      "epoch:31 step:24443 [D loss: 0.692142, acc.: 53.91%] [G loss: 0.741566]\n",
      "epoch:31 step:24444 [D loss: 0.657514, acc.: 64.06%] [G loss: 0.765192]\n",
      "epoch:31 step:24445 [D loss: 0.750410, acc.: 41.41%] [G loss: 0.742952]\n",
      "epoch:31 step:24446 [D loss: 0.653795, acc.: 59.38%] [G loss: 0.664377]\n",
      "epoch:31 step:24447 [D loss: 0.667233, acc.: 61.72%] [G loss: 0.716886]\n",
      "epoch:31 step:24448 [D loss: 0.670297, acc.: 62.50%] [G loss: 0.690270]\n",
      "epoch:31 step:24449 [D loss: 0.737393, acc.: 46.88%] [G loss: 0.763744]\n",
      "epoch:31 step:24450 [D loss: 0.675849, acc.: 60.94%] [G loss: 0.715763]\n",
      "epoch:31 step:24451 [D loss: 0.646517, acc.: 64.06%] [G loss: 0.870449]\n",
      "epoch:31 step:24452 [D loss: 0.661663, acc.: 60.94%] [G loss: 0.839830]\n",
      "epoch:31 step:24453 [D loss: 0.663032, acc.: 58.59%] [G loss: 0.787729]\n",
      "epoch:31 step:24454 [D loss: 0.642180, acc.: 62.50%] [G loss: 0.779902]\n",
      "epoch:31 step:24455 [D loss: 0.706269, acc.: 46.88%] [G loss: 0.734012]\n",
      "epoch:31 step:24456 [D loss: 0.720459, acc.: 42.19%] [G loss: 0.764702]\n",
      "epoch:31 step:24457 [D loss: 0.677983, acc.: 55.47%] [G loss: 0.780342]\n",
      "epoch:31 step:24458 [D loss: 0.659237, acc.: 59.38%] [G loss: 0.778605]\n",
      "epoch:31 step:24459 [D loss: 0.711718, acc.: 50.78%] [G loss: 0.772869]\n",
      "epoch:31 step:24460 [D loss: 0.698655, acc.: 44.53%] [G loss: 0.769023]\n",
      "epoch:31 step:24461 [D loss: 0.651000, acc.: 63.28%] [G loss: 0.754780]\n",
      "epoch:31 step:24462 [D loss: 0.662144, acc.: 68.75%] [G loss: 0.714249]\n",
      "epoch:31 step:24463 [D loss: 0.697322, acc.: 54.69%] [G loss: 0.747410]\n",
      "epoch:31 step:24464 [D loss: 0.685284, acc.: 57.03%] [G loss: 0.754762]\n",
      "epoch:31 step:24465 [D loss: 0.708887, acc.: 51.56%] [G loss: 0.721574]\n",
      "epoch:31 step:24466 [D loss: 0.699175, acc.: 51.56%] [G loss: 0.717326]\n",
      "epoch:31 step:24467 [D loss: 0.687478, acc.: 56.25%] [G loss: 0.725716]\n",
      "epoch:31 step:24468 [D loss: 0.685338, acc.: 57.03%] [G loss: 0.759764]\n",
      "epoch:31 step:24469 [D loss: 0.640440, acc.: 67.97%] [G loss: 0.809022]\n",
      "epoch:31 step:24470 [D loss: 0.720951, acc.: 50.78%] [G loss: 0.783138]\n",
      "epoch:31 step:24471 [D loss: 0.668349, acc.: 60.16%] [G loss: 0.780287]\n",
      "epoch:31 step:24472 [D loss: 0.705137, acc.: 50.00%] [G loss: 0.772370]\n",
      "epoch:31 step:24473 [D loss: 0.692743, acc.: 50.78%] [G loss: 0.932864]\n",
      "epoch:31 step:24474 [D loss: 0.655483, acc.: 60.94%] [G loss: 0.864712]\n",
      "epoch:31 step:24475 [D loss: 0.660197, acc.: 57.03%] [G loss: 0.784101]\n",
      "epoch:31 step:24476 [D loss: 0.704759, acc.: 50.78%] [G loss: 0.804557]\n",
      "epoch:31 step:24477 [D loss: 0.753929, acc.: 35.94%] [G loss: 0.762684]\n",
      "epoch:31 step:24478 [D loss: 0.819618, acc.: 32.03%] [G loss: 0.773954]\n",
      "epoch:31 step:24479 [D loss: 0.694394, acc.: 48.44%] [G loss: 0.714322]\n",
      "epoch:31 step:24480 [D loss: 0.680211, acc.: 64.84%] [G loss: 0.765677]\n",
      "epoch:31 step:24481 [D loss: 0.703166, acc.: 56.25%] [G loss: 0.783632]\n",
      "epoch:31 step:24482 [D loss: 0.699870, acc.: 48.44%] [G loss: 0.787569]\n",
      "epoch:31 step:24483 [D loss: 0.718271, acc.: 46.09%] [G loss: 0.719755]\n",
      "epoch:31 step:24484 [D loss: 0.683089, acc.: 57.03%] [G loss: 0.783428]\n",
      "epoch:31 step:24485 [D loss: 0.653625, acc.: 60.94%] [G loss: 0.736747]\n",
      "epoch:31 step:24486 [D loss: 0.664482, acc.: 61.72%] [G loss: 0.727401]\n",
      "epoch:31 step:24487 [D loss: 0.676821, acc.: 57.81%] [G loss: 0.775276]\n",
      "epoch:31 step:24488 [D loss: 0.736231, acc.: 47.66%] [G loss: 0.716615]\n",
      "epoch:31 step:24489 [D loss: 0.682231, acc.: 53.91%] [G loss: 0.818818]\n",
      "epoch:31 step:24490 [D loss: 0.685883, acc.: 57.03%] [G loss: 0.761414]\n",
      "epoch:31 step:24491 [D loss: 0.679125, acc.: 57.03%] [G loss: 0.811205]\n",
      "epoch:31 step:24492 [D loss: 0.730334, acc.: 45.31%] [G loss: 0.710502]\n",
      "epoch:31 step:24493 [D loss: 0.631613, acc.: 69.53%] [G loss: 0.833417]\n",
      "epoch:31 step:24494 [D loss: 0.659571, acc.: 65.62%] [G loss: 0.812091]\n",
      "epoch:31 step:24495 [D loss: 0.662518, acc.: 62.50%] [G loss: 0.756223]\n",
      "epoch:31 step:24496 [D loss: 0.660690, acc.: 62.50%] [G loss: 0.842221]\n",
      "epoch:31 step:24497 [D loss: 0.718771, acc.: 44.53%] [G loss: 0.737435]\n",
      "epoch:31 step:24498 [D loss: 0.717904, acc.: 45.31%] [G loss: 0.774728]\n",
      "epoch:31 step:24499 [D loss: 0.665942, acc.: 60.16%] [G loss: 0.722977]\n",
      "epoch:31 step:24500 [D loss: 0.676040, acc.: 57.03%] [G loss: 0.896250]\n",
      "epoch:31 step:24501 [D loss: 0.663131, acc.: 60.16%] [G loss: 0.777782]\n",
      "epoch:31 step:24502 [D loss: 0.686001, acc.: 53.12%] [G loss: 0.852925]\n",
      "epoch:31 step:24503 [D loss: 0.678717, acc.: 63.28%] [G loss: 0.777320]\n",
      "epoch:31 step:24504 [D loss: 0.696458, acc.: 53.12%] [G loss: 0.745435]\n",
      "epoch:31 step:24505 [D loss: 0.675269, acc.: 57.03%] [G loss: 0.756541]\n",
      "epoch:31 step:24506 [D loss: 0.719940, acc.: 44.53%] [G loss: 0.709086]\n",
      "epoch:31 step:24507 [D loss: 0.671758, acc.: 57.81%] [G loss: 0.741120]\n",
      "epoch:31 step:24508 [D loss: 0.720388, acc.: 40.62%] [G loss: 0.726278]\n",
      "epoch:31 step:24509 [D loss: 0.679139, acc.: 53.91%] [G loss: 0.770235]\n",
      "epoch:31 step:24510 [D loss: 0.743349, acc.: 42.97%] [G loss: 0.763887]\n",
      "epoch:31 step:24511 [D loss: 0.750828, acc.: 39.84%] [G loss: 0.695491]\n",
      "epoch:31 step:24512 [D loss: 0.677813, acc.: 63.28%] [G loss: 0.764951]\n",
      "epoch:31 step:24513 [D loss: 0.648398, acc.: 67.97%] [G loss: 0.742054]\n",
      "epoch:31 step:24514 [D loss: 0.704372, acc.: 49.22%] [G loss: 0.747605]\n",
      "epoch:31 step:24515 [D loss: 0.721716, acc.: 42.97%] [G loss: 0.792795]\n",
      "epoch:31 step:24516 [D loss: 0.732088, acc.: 44.53%] [G loss: 0.732652]\n",
      "epoch:31 step:24517 [D loss: 0.701886, acc.: 50.00%] [G loss: 0.750722]\n",
      "epoch:31 step:24518 [D loss: 0.662929, acc.: 65.62%] [G loss: 0.772854]\n",
      "epoch:31 step:24519 [D loss: 0.646595, acc.: 64.06%] [G loss: 0.767644]\n",
      "epoch:31 step:24520 [D loss: 0.700708, acc.: 51.56%] [G loss: 0.759206]\n",
      "epoch:31 step:24521 [D loss: 0.673808, acc.: 61.72%] [G loss: 0.785496]\n",
      "epoch:31 step:24522 [D loss: 0.687883, acc.: 57.03%] [G loss: 0.759573]\n",
      "epoch:31 step:24523 [D loss: 0.713695, acc.: 48.44%] [G loss: 0.771246]\n",
      "epoch:31 step:24524 [D loss: 0.669024, acc.: 61.72%] [G loss: 0.821730]\n",
      "epoch:31 step:24525 [D loss: 0.738387, acc.: 41.41%] [G loss: 0.792770]\n",
      "epoch:31 step:24526 [D loss: 0.709740, acc.: 51.56%] [G loss: 0.761146]\n",
      "epoch:31 step:24527 [D loss: 0.704035, acc.: 50.00%] [G loss: 0.754682]\n",
      "epoch:31 step:24528 [D loss: 0.670062, acc.: 54.69%] [G loss: 0.706371]\n",
      "epoch:31 step:24529 [D loss: 0.653197, acc.: 67.19%] [G loss: 0.784137]\n",
      "epoch:31 step:24530 [D loss: 0.662080, acc.: 61.72%] [G loss: 0.752919]\n",
      "epoch:31 step:24531 [D loss: 0.657368, acc.: 58.59%] [G loss: 0.777475]\n",
      "epoch:31 step:24532 [D loss: 0.686509, acc.: 53.12%] [G loss: 0.776363]\n",
      "epoch:31 step:24533 [D loss: 0.739894, acc.: 41.41%] [G loss: 0.693776]\n",
      "epoch:31 step:24534 [D loss: 0.713495, acc.: 49.22%] [G loss: 0.761215]\n",
      "epoch:31 step:24535 [D loss: 0.682090, acc.: 53.12%] [G loss: 0.735223]\n",
      "epoch:31 step:24536 [D loss: 0.675204, acc.: 57.03%] [G loss: 0.729132]\n",
      "epoch:31 step:24537 [D loss: 0.707481, acc.: 52.34%] [G loss: 0.759858]\n",
      "epoch:31 step:24538 [D loss: 0.685570, acc.: 53.91%] [G loss: 0.760522]\n",
      "epoch:31 step:24539 [D loss: 0.672303, acc.: 59.38%] [G loss: 0.792175]\n",
      "epoch:31 step:24540 [D loss: 0.704315, acc.: 48.44%] [G loss: 0.819785]\n",
      "epoch:31 step:24541 [D loss: 0.695327, acc.: 50.78%] [G loss: 0.736146]\n",
      "epoch:31 step:24542 [D loss: 0.692034, acc.: 50.78%] [G loss: 0.837606]\n",
      "epoch:31 step:24543 [D loss: 0.669407, acc.: 59.38%] [G loss: 0.785551]\n",
      "epoch:31 step:24544 [D loss: 0.669302, acc.: 54.69%] [G loss: 0.866836]\n",
      "epoch:31 step:24545 [D loss: 0.718889, acc.: 50.00%] [G loss: 0.769579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24546 [D loss: 0.663847, acc.: 58.59%] [G loss: 0.723839]\n",
      "epoch:31 step:24547 [D loss: 0.653525, acc.: 67.19%] [G loss: 0.754368]\n",
      "epoch:31 step:24548 [D loss: 0.748861, acc.: 39.84%] [G loss: 0.702676]\n",
      "epoch:31 step:24549 [D loss: 0.747374, acc.: 39.84%] [G loss: 0.747012]\n",
      "epoch:31 step:24550 [D loss: 0.689678, acc.: 57.03%] [G loss: 0.710913]\n",
      "epoch:31 step:24551 [D loss: 0.712816, acc.: 50.00%] [G loss: 0.802646]\n",
      "epoch:31 step:24552 [D loss: 0.715258, acc.: 44.53%] [G loss: 0.686571]\n",
      "epoch:31 step:24553 [D loss: 0.773457, acc.: 39.06%] [G loss: 0.768652]\n",
      "epoch:31 step:24554 [D loss: 0.683525, acc.: 60.94%] [G loss: 0.759183]\n",
      "epoch:31 step:24555 [D loss: 0.674861, acc.: 54.69%] [G loss: 0.727611]\n",
      "epoch:31 step:24556 [D loss: 0.698118, acc.: 52.34%] [G loss: 0.785807]\n",
      "epoch:31 step:24557 [D loss: 0.714598, acc.: 42.97%] [G loss: 0.749265]\n",
      "epoch:31 step:24558 [D loss: 0.673217, acc.: 52.34%] [G loss: 0.800406]\n",
      "epoch:31 step:24559 [D loss: 0.706806, acc.: 54.69%] [G loss: 0.750803]\n",
      "epoch:31 step:24560 [D loss: 0.674906, acc.: 53.91%] [G loss: 0.829611]\n",
      "epoch:31 step:24561 [D loss: 0.772757, acc.: 34.38%] [G loss: 0.802715]\n",
      "epoch:31 step:24562 [D loss: 0.687336, acc.: 50.78%] [G loss: 0.818889]\n",
      "epoch:31 step:24563 [D loss: 0.684260, acc.: 57.03%] [G loss: 0.765696]\n",
      "epoch:31 step:24564 [D loss: 0.651373, acc.: 60.94%] [G loss: 0.801025]\n",
      "epoch:31 step:24565 [D loss: 0.628195, acc.: 64.06%] [G loss: 0.832047]\n",
      "epoch:31 step:24566 [D loss: 0.703081, acc.: 51.56%] [G loss: 0.845755]\n",
      "epoch:31 step:24567 [D loss: 0.697846, acc.: 50.78%] [G loss: 0.700834]\n",
      "epoch:31 step:24568 [D loss: 0.652900, acc.: 68.75%] [G loss: 0.755475]\n",
      "epoch:31 step:24569 [D loss: 0.705301, acc.: 52.34%] [G loss: 0.772448]\n",
      "epoch:31 step:24570 [D loss: 0.726043, acc.: 40.62%] [G loss: 0.747268]\n",
      "epoch:31 step:24571 [D loss: 0.667702, acc.: 66.41%] [G loss: 0.747151]\n",
      "epoch:31 step:24572 [D loss: 0.661450, acc.: 62.50%] [G loss: 0.797508]\n",
      "epoch:31 step:24573 [D loss: 0.694663, acc.: 52.34%] [G loss: 0.733178]\n",
      "epoch:31 step:24574 [D loss: 0.702531, acc.: 52.34%] [G loss: 0.739186]\n",
      "epoch:31 step:24575 [D loss: 0.680629, acc.: 59.38%] [G loss: 0.667811]\n",
      "epoch:31 step:24576 [D loss: 0.675648, acc.: 59.38%] [G loss: 0.779927]\n",
      "epoch:31 step:24577 [D loss: 0.714199, acc.: 48.44%] [G loss: 0.773468]\n",
      "epoch:31 step:24578 [D loss: 0.707242, acc.: 48.44%] [G loss: 0.730384]\n",
      "epoch:31 step:24579 [D loss: 0.647206, acc.: 67.97%] [G loss: 0.839130]\n",
      "epoch:31 step:24580 [D loss: 0.743469, acc.: 37.50%] [G loss: 0.678348]\n",
      "epoch:31 step:24581 [D loss: 0.664974, acc.: 61.72%] [G loss: 0.817388]\n",
      "epoch:31 step:24582 [D loss: 0.645229, acc.: 60.94%] [G loss: 0.796812]\n",
      "epoch:31 step:24583 [D loss: 0.653247, acc.: 66.41%] [G loss: 0.781251]\n",
      "epoch:31 step:24584 [D loss: 0.717032, acc.: 42.19%] [G loss: 0.814756]\n",
      "epoch:31 step:24585 [D loss: 0.650681, acc.: 62.50%] [G loss: 0.768242]\n",
      "epoch:31 step:24586 [D loss: 0.693516, acc.: 54.69%] [G loss: 0.799392]\n",
      "epoch:31 step:24587 [D loss: 0.641717, acc.: 59.38%] [G loss: 0.740125]\n",
      "epoch:31 step:24588 [D loss: 0.695211, acc.: 57.81%] [G loss: 0.746459]\n",
      "epoch:31 step:24589 [D loss: 0.634964, acc.: 70.31%] [G loss: 0.807679]\n",
      "epoch:31 step:24590 [D loss: 0.686309, acc.: 57.03%] [G loss: 0.760397]\n",
      "epoch:31 step:24591 [D loss: 0.647888, acc.: 66.41%] [G loss: 0.845877]\n",
      "epoch:31 step:24592 [D loss: 0.608464, acc.: 66.41%] [G loss: 0.781868]\n",
      "epoch:31 step:24593 [D loss: 0.713424, acc.: 50.00%] [G loss: 0.757142]\n",
      "epoch:31 step:24594 [D loss: 0.661347, acc.: 57.81%] [G loss: 0.827843]\n",
      "epoch:31 step:24595 [D loss: 0.673777, acc.: 54.69%] [G loss: 0.731509]\n",
      "epoch:31 step:24596 [D loss: 0.691986, acc.: 51.56%] [G loss: 0.810092]\n",
      "epoch:31 step:24597 [D loss: 0.632098, acc.: 61.72%] [G loss: 0.782877]\n",
      "epoch:31 step:24598 [D loss: 0.654282, acc.: 63.28%] [G loss: 0.839404]\n",
      "epoch:31 step:24599 [D loss: 0.741631, acc.: 36.72%] [G loss: 0.818272]\n",
      "epoch:31 step:24600 [D loss: 0.745034, acc.: 40.62%] [G loss: 0.789668]\n",
      "epoch:31 step:24601 [D loss: 0.683044, acc.: 52.34%] [G loss: 0.822565]\n",
      "epoch:31 step:24602 [D loss: 0.702196, acc.: 51.56%] [G loss: 0.774157]\n",
      "epoch:31 step:24603 [D loss: 0.690432, acc.: 53.91%] [G loss: 0.713804]\n",
      "epoch:31 step:24604 [D loss: 0.721814, acc.: 46.88%] [G loss: 0.675801]\n",
      "epoch:31 step:24605 [D loss: 0.717264, acc.: 47.66%] [G loss: 0.674147]\n",
      "epoch:31 step:24606 [D loss: 0.725460, acc.: 50.00%] [G loss: 0.752984]\n",
      "epoch:31 step:24607 [D loss: 0.673561, acc.: 64.06%] [G loss: 0.712066]\n",
      "epoch:31 step:24608 [D loss: 0.683724, acc.: 55.47%] [G loss: 0.772426]\n",
      "epoch:31 step:24609 [D loss: 0.681582, acc.: 53.12%] [G loss: 0.800814]\n",
      "epoch:31 step:24610 [D loss: 0.651017, acc.: 64.06%] [G loss: 0.756731]\n",
      "epoch:31 step:24611 [D loss: 0.745930, acc.: 42.19%] [G loss: 0.676721]\n",
      "epoch:31 step:24612 [D loss: 0.658445, acc.: 67.19%] [G loss: 0.719142]\n",
      "epoch:31 step:24613 [D loss: 0.729677, acc.: 36.72%] [G loss: 0.739998]\n",
      "epoch:31 step:24614 [D loss: 0.646879, acc.: 62.50%] [G loss: 0.740013]\n",
      "epoch:31 step:24615 [D loss: 0.679399, acc.: 53.91%] [G loss: 0.797933]\n",
      "epoch:31 step:24616 [D loss: 0.680110, acc.: 53.91%] [G loss: 0.775982]\n",
      "epoch:31 step:24617 [D loss: 0.665033, acc.: 57.81%] [G loss: 0.797258]\n",
      "epoch:31 step:24618 [D loss: 0.664944, acc.: 60.16%] [G loss: 0.832362]\n",
      "epoch:31 step:24619 [D loss: 0.689544, acc.: 55.47%] [G loss: 0.763131]\n",
      "epoch:31 step:24620 [D loss: 0.751399, acc.: 32.81%] [G loss: 0.740728]\n",
      "epoch:31 step:24621 [D loss: 0.668550, acc.: 57.03%] [G loss: 0.724241]\n",
      "epoch:31 step:24622 [D loss: 0.704156, acc.: 46.88%] [G loss: 0.741590]\n",
      "epoch:31 step:24623 [D loss: 0.723922, acc.: 48.44%] [G loss: 0.727044]\n",
      "epoch:31 step:24624 [D loss: 0.682979, acc.: 58.59%] [G loss: 0.793485]\n",
      "epoch:31 step:24625 [D loss: 0.714583, acc.: 46.09%] [G loss: 0.780740]\n",
      "epoch:31 step:24626 [D loss: 0.697723, acc.: 51.56%] [G loss: 0.711359]\n",
      "epoch:31 step:24627 [D loss: 0.672879, acc.: 61.72%] [G loss: 0.784869]\n",
      "epoch:31 step:24628 [D loss: 0.654135, acc.: 58.59%] [G loss: 0.747950]\n",
      "epoch:31 step:24629 [D loss: 0.690343, acc.: 54.69%] [G loss: 0.751083]\n",
      "epoch:31 step:24630 [D loss: 0.715362, acc.: 48.44%] [G loss: 0.773290]\n",
      "epoch:31 step:24631 [D loss: 0.693593, acc.: 53.12%] [G loss: 0.704903]\n",
      "epoch:31 step:24632 [D loss: 0.674484, acc.: 57.81%] [G loss: 0.808436]\n",
      "epoch:31 step:24633 [D loss: 0.729535, acc.: 42.19%] [G loss: 0.764277]\n",
      "epoch:31 step:24634 [D loss: 0.686594, acc.: 53.12%] [G loss: 0.828056]\n",
      "epoch:31 step:24635 [D loss: 0.722796, acc.: 46.09%] [G loss: 0.772503]\n",
      "epoch:31 step:24636 [D loss: 0.685812, acc.: 54.69%] [G loss: 0.750523]\n",
      "epoch:31 step:24637 [D loss: 0.698700, acc.: 49.22%] [G loss: 0.748818]\n",
      "epoch:31 step:24638 [D loss: 0.698833, acc.: 49.22%] [G loss: 0.840215]\n",
      "epoch:31 step:24639 [D loss: 0.747411, acc.: 45.31%] [G loss: 0.723311]\n",
      "epoch:31 step:24640 [D loss: 0.669109, acc.: 56.25%] [G loss: 0.748219]\n",
      "epoch:31 step:24641 [D loss: 0.676853, acc.: 53.12%] [G loss: 0.761574]\n",
      "epoch:31 step:24642 [D loss: 0.729468, acc.: 49.22%] [G loss: 0.838112]\n",
      "epoch:31 step:24643 [D loss: 0.653577, acc.: 64.84%] [G loss: 0.811390]\n",
      "epoch:31 step:24644 [D loss: 0.682882, acc.: 56.25%] [G loss: 0.728354]\n",
      "epoch:31 step:24645 [D loss: 0.685759, acc.: 60.16%] [G loss: 0.742137]\n",
      "epoch:31 step:24646 [D loss: 0.726324, acc.: 46.09%] [G loss: 0.824931]\n",
      "epoch:31 step:24647 [D loss: 0.676288, acc.: 54.69%] [G loss: 0.807957]\n",
      "epoch:31 step:24648 [D loss: 0.730053, acc.: 42.97%] [G loss: 0.767667]\n",
      "epoch:31 step:24649 [D loss: 0.677889, acc.: 56.25%] [G loss: 0.793834]\n",
      "epoch:31 step:24650 [D loss: 0.668477, acc.: 60.94%] [G loss: 0.737445]\n",
      "epoch:31 step:24651 [D loss: 0.681476, acc.: 57.81%] [G loss: 0.743216]\n",
      "epoch:31 step:24652 [D loss: 0.704681, acc.: 48.44%] [G loss: 0.856587]\n",
      "epoch:31 step:24653 [D loss: 0.690538, acc.: 56.25%] [G loss: 0.740249]\n",
      "epoch:31 step:24654 [D loss: 0.681750, acc.: 60.94%] [G loss: 0.803270]\n",
      "epoch:31 step:24655 [D loss: 0.684754, acc.: 57.81%] [G loss: 0.776259]\n",
      "epoch:31 step:24656 [D loss: 0.701298, acc.: 50.00%] [G loss: 0.806180]\n",
      "epoch:31 step:24657 [D loss: 0.720516, acc.: 45.31%] [G loss: 0.824973]\n",
      "epoch:31 step:24658 [D loss: 0.658787, acc.: 61.72%] [G loss: 0.757030]\n",
      "epoch:31 step:24659 [D loss: 0.685987, acc.: 55.47%] [G loss: 0.847246]\n",
      "epoch:31 step:24660 [D loss: 0.676552, acc.: 57.81%] [G loss: 0.829074]\n",
      "epoch:31 step:24661 [D loss: 0.691540, acc.: 48.44%] [G loss: 0.820642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24662 [D loss: 0.686486, acc.: 59.38%] [G loss: 0.853931]\n",
      "epoch:31 step:24663 [D loss: 0.672216, acc.: 58.59%] [G loss: 0.855760]\n",
      "epoch:31 step:24664 [D loss: 0.697844, acc.: 55.47%] [G loss: 0.797269]\n",
      "epoch:31 step:24665 [D loss: 0.664460, acc.: 64.84%] [G loss: 0.791564]\n",
      "epoch:31 step:24666 [D loss: 0.775287, acc.: 35.16%] [G loss: 0.726370]\n",
      "epoch:31 step:24667 [D loss: 0.709985, acc.: 51.56%] [G loss: 0.789270]\n",
      "epoch:31 step:24668 [D loss: 0.658420, acc.: 67.19%] [G loss: 0.826141]\n",
      "epoch:31 step:24669 [D loss: 0.732632, acc.: 39.84%] [G loss: 0.774225]\n",
      "epoch:31 step:24670 [D loss: 0.688601, acc.: 54.69%] [G loss: 0.860356]\n",
      "epoch:31 step:24671 [D loss: 0.702668, acc.: 50.00%] [G loss: 0.816084]\n",
      "epoch:31 step:24672 [D loss: 0.695924, acc.: 53.12%] [G loss: 0.785722]\n",
      "epoch:31 step:24673 [D loss: 0.656625, acc.: 60.94%] [G loss: 0.817566]\n",
      "epoch:31 step:24674 [D loss: 0.722945, acc.: 45.31%] [G loss: 0.781874]\n",
      "epoch:31 step:24675 [D loss: 0.637048, acc.: 65.62%] [G loss: 0.801992]\n",
      "epoch:31 step:24676 [D loss: 0.723966, acc.: 47.66%] [G loss: 0.684904]\n",
      "epoch:31 step:24677 [D loss: 0.644094, acc.: 70.31%] [G loss: 0.804893]\n",
      "epoch:31 step:24678 [D loss: 0.672820, acc.: 56.25%] [G loss: 0.813048]\n",
      "epoch:31 step:24679 [D loss: 0.647890, acc.: 60.94%] [G loss: 0.781216]\n",
      "epoch:31 step:24680 [D loss: 0.633883, acc.: 67.19%] [G loss: 0.873436]\n",
      "epoch:31 step:24681 [D loss: 0.673134, acc.: 60.94%] [G loss: 0.778577]\n",
      "epoch:31 step:24682 [D loss: 0.710593, acc.: 49.22%] [G loss: 0.766766]\n",
      "epoch:31 step:24683 [D loss: 0.720522, acc.: 43.75%] [G loss: 0.812598]\n",
      "epoch:31 step:24684 [D loss: 0.765633, acc.: 39.84%] [G loss: 0.787163]\n",
      "epoch:31 step:24685 [D loss: 0.690515, acc.: 57.81%] [G loss: 0.793049]\n",
      "epoch:31 step:24686 [D loss: 0.666000, acc.: 60.94%] [G loss: 0.771544]\n",
      "epoch:31 step:24687 [D loss: 0.681264, acc.: 49.22%] [G loss: 0.765451]\n",
      "epoch:31 step:24688 [D loss: 0.659579, acc.: 63.28%] [G loss: 0.832877]\n",
      "epoch:31 step:24689 [D loss: 0.675134, acc.: 57.03%] [G loss: 0.746925]\n",
      "epoch:31 step:24690 [D loss: 0.666961, acc.: 65.62%] [G loss: 0.851976]\n",
      "epoch:31 step:24691 [D loss: 0.674841, acc.: 58.59%] [G loss: 0.875372]\n",
      "epoch:31 step:24692 [D loss: 0.671819, acc.: 62.50%] [G loss: 0.775410]\n",
      "epoch:31 step:24693 [D loss: 0.718507, acc.: 48.44%] [G loss: 0.759926]\n",
      "epoch:31 step:24694 [D loss: 0.657347, acc.: 55.47%] [G loss: 0.830278]\n",
      "epoch:31 step:24695 [D loss: 0.654065, acc.: 55.47%] [G loss: 0.734401]\n",
      "epoch:31 step:24696 [D loss: 0.698908, acc.: 48.44%] [G loss: 0.724028]\n",
      "epoch:31 step:24697 [D loss: 0.651185, acc.: 56.25%] [G loss: 0.663571]\n",
      "epoch:31 step:24698 [D loss: 0.714774, acc.: 48.44%] [G loss: 0.716241]\n",
      "epoch:31 step:24699 [D loss: 0.675020, acc.: 54.69%] [G loss: 0.795940]\n",
      "epoch:31 step:24700 [D loss: 0.719986, acc.: 47.66%] [G loss: 0.636960]\n",
      "epoch:31 step:24701 [D loss: 0.686673, acc.: 50.00%] [G loss: 0.720962]\n",
      "epoch:31 step:24702 [D loss: 0.698934, acc.: 57.03%] [G loss: 0.762413]\n",
      "epoch:31 step:24703 [D loss: 0.664547, acc.: 60.94%] [G loss: 0.772629]\n",
      "epoch:31 step:24704 [D loss: 0.691226, acc.: 48.44%] [G loss: 0.731024]\n",
      "epoch:31 step:24705 [D loss: 0.663457, acc.: 58.59%] [G loss: 0.813385]\n",
      "epoch:31 step:24706 [D loss: 0.686058, acc.: 61.72%] [G loss: 0.756440]\n",
      "epoch:31 step:24707 [D loss: 0.703883, acc.: 43.75%] [G loss: 0.734822]\n",
      "epoch:31 step:24708 [D loss: 0.666540, acc.: 61.72%] [G loss: 0.751661]\n",
      "epoch:31 step:24709 [D loss: 0.646441, acc.: 67.19%] [G loss: 0.759055]\n",
      "epoch:31 step:24710 [D loss: 0.686749, acc.: 53.91%] [G loss: 0.741107]\n",
      "epoch:31 step:24711 [D loss: 0.684795, acc.: 48.44%] [G loss: 0.718071]\n",
      "epoch:31 step:24712 [D loss: 0.696307, acc.: 53.91%] [G loss: 0.799644]\n",
      "epoch:31 step:24713 [D loss: 0.633224, acc.: 69.53%] [G loss: 0.780157]\n",
      "epoch:31 step:24714 [D loss: 0.653778, acc.: 63.28%] [G loss: 0.778627]\n",
      "epoch:31 step:24715 [D loss: 0.688932, acc.: 53.91%] [G loss: 0.789507]\n",
      "epoch:31 step:24716 [D loss: 0.707521, acc.: 47.66%] [G loss: 0.739576]\n",
      "epoch:31 step:24717 [D loss: 0.696964, acc.: 51.56%] [G loss: 0.691613]\n",
      "epoch:31 step:24718 [D loss: 0.705320, acc.: 48.44%] [G loss: 0.800389]\n",
      "epoch:31 step:24719 [D loss: 0.715331, acc.: 46.88%] [G loss: 0.728718]\n",
      "epoch:31 step:24720 [D loss: 0.708397, acc.: 48.44%] [G loss: 0.756804]\n",
      "epoch:31 step:24721 [D loss: 0.678440, acc.: 56.25%] [G loss: 0.722858]\n",
      "epoch:31 step:24722 [D loss: 0.690161, acc.: 54.69%] [G loss: 0.749357]\n",
      "epoch:31 step:24723 [D loss: 0.672841, acc.: 57.81%] [G loss: 0.777582]\n",
      "epoch:31 step:24724 [D loss: 0.705531, acc.: 53.12%] [G loss: 0.673869]\n",
      "epoch:31 step:24725 [D loss: 0.738060, acc.: 35.94%] [G loss: 0.687077]\n",
      "epoch:31 step:24726 [D loss: 0.697867, acc.: 47.66%] [G loss: 0.791492]\n",
      "epoch:31 step:24727 [D loss: 0.693516, acc.: 51.56%] [G loss: 0.737979]\n",
      "epoch:31 step:24728 [D loss: 0.660684, acc.: 61.72%] [G loss: 0.715409]\n",
      "epoch:31 step:24729 [D loss: 0.666732, acc.: 57.81%] [G loss: 0.746644]\n",
      "epoch:31 step:24730 [D loss: 0.670908, acc.: 60.16%] [G loss: 0.792806]\n",
      "epoch:31 step:24731 [D loss: 0.703735, acc.: 53.91%] [G loss: 0.794497]\n",
      "epoch:31 step:24732 [D loss: 0.648719, acc.: 60.16%] [G loss: 0.876724]\n",
      "epoch:31 step:24733 [D loss: 0.730409, acc.: 46.09%] [G loss: 0.798444]\n",
      "epoch:31 step:24734 [D loss: 0.640412, acc.: 64.84%] [G loss: 0.781297]\n",
      "epoch:31 step:24735 [D loss: 0.706976, acc.: 51.56%] [G loss: 0.726433]\n",
      "epoch:31 step:24736 [D loss: 0.731195, acc.: 39.06%] [G loss: 0.749911]\n",
      "epoch:31 step:24737 [D loss: 0.756574, acc.: 42.97%] [G loss: 0.745406]\n",
      "epoch:31 step:24738 [D loss: 0.695372, acc.: 52.34%] [G loss: 0.711651]\n",
      "epoch:31 step:24739 [D loss: 0.722568, acc.: 46.09%] [G loss: 0.703783]\n",
      "epoch:31 step:24740 [D loss: 0.675479, acc.: 56.25%] [G loss: 0.805553]\n",
      "epoch:31 step:24741 [D loss: 0.665258, acc.: 59.38%] [G loss: 0.768318]\n",
      "epoch:31 step:24742 [D loss: 0.668962, acc.: 59.38%] [G loss: 0.764721]\n",
      "epoch:31 step:24743 [D loss: 0.714842, acc.: 48.44%] [G loss: 0.780348]\n",
      "epoch:31 step:24744 [D loss: 0.704448, acc.: 47.66%] [G loss: 0.772399]\n",
      "epoch:31 step:24745 [D loss: 0.666708, acc.: 59.38%] [G loss: 0.747013]\n",
      "epoch:31 step:24746 [D loss: 0.629888, acc.: 72.66%] [G loss: 0.752232]\n",
      "epoch:31 step:24747 [D loss: 0.630410, acc.: 65.62%] [G loss: 0.842962]\n",
      "epoch:31 step:24748 [D loss: 0.737737, acc.: 38.28%] [G loss: 0.715504]\n",
      "epoch:31 step:24749 [D loss: 0.673700, acc.: 61.72%] [G loss: 0.796777]\n",
      "epoch:31 step:24750 [D loss: 0.686498, acc.: 53.91%] [G loss: 0.834063]\n",
      "epoch:31 step:24751 [D loss: 0.706084, acc.: 54.69%] [G loss: 0.731035]\n",
      "epoch:31 step:24752 [D loss: 0.733017, acc.: 42.97%] [G loss: 0.735353]\n",
      "epoch:31 step:24753 [D loss: 0.720292, acc.: 49.22%] [G loss: 0.826453]\n",
      "epoch:31 step:24754 [D loss: 0.672344, acc.: 57.81%] [G loss: 0.748744]\n",
      "epoch:31 step:24755 [D loss: 0.674591, acc.: 58.59%] [G loss: 0.835392]\n",
      "epoch:31 step:24756 [D loss: 0.644594, acc.: 67.19%] [G loss: 0.769082]\n",
      "epoch:31 step:24757 [D loss: 0.738902, acc.: 45.31%] [G loss: 0.833958]\n",
      "epoch:31 step:24758 [D loss: 0.676481, acc.: 62.50%] [G loss: 0.838524]\n",
      "epoch:31 step:24759 [D loss: 0.654412, acc.: 65.62%] [G loss: 0.822672]\n",
      "epoch:31 step:24760 [D loss: 0.655530, acc.: 64.84%] [G loss: 0.832611]\n",
      "epoch:31 step:24761 [D loss: 0.661904, acc.: 60.94%] [G loss: 0.803429]\n",
      "epoch:31 step:24762 [D loss: 0.661856, acc.: 62.50%] [G loss: 0.771920]\n",
      "epoch:31 step:24763 [D loss: 0.686328, acc.: 52.34%] [G loss: 0.818945]\n",
      "epoch:31 step:24764 [D loss: 0.653446, acc.: 66.41%] [G loss: 0.768784]\n",
      "epoch:31 step:24765 [D loss: 0.643073, acc.: 67.97%] [G loss: 0.872215]\n",
      "epoch:31 step:24766 [D loss: 0.740205, acc.: 41.41%] [G loss: 0.758928]\n",
      "epoch:31 step:24767 [D loss: 0.710128, acc.: 46.88%] [G loss: 0.762629]\n",
      "epoch:31 step:24768 [D loss: 0.715697, acc.: 42.97%] [G loss: 0.827841]\n",
      "epoch:31 step:24769 [D loss: 0.661163, acc.: 60.94%] [G loss: 0.825970]\n",
      "epoch:31 step:24770 [D loss: 0.667475, acc.: 60.16%] [G loss: 0.781683]\n",
      "epoch:31 step:24771 [D loss: 0.679482, acc.: 54.69%] [G loss: 0.726226]\n",
      "epoch:31 step:24772 [D loss: 0.683978, acc.: 50.00%] [G loss: 0.783797]\n",
      "epoch:31 step:24773 [D loss: 0.726610, acc.: 45.31%] [G loss: 0.751220]\n",
      "epoch:31 step:24774 [D loss: 0.720424, acc.: 46.88%] [G loss: 0.753917]\n",
      "epoch:31 step:24775 [D loss: 0.644261, acc.: 68.75%] [G loss: 0.806345]\n",
      "epoch:31 step:24776 [D loss: 0.656920, acc.: 57.81%] [G loss: 0.797530]\n",
      "epoch:31 step:24777 [D loss: 0.676610, acc.: 57.81%] [G loss: 0.857699]\n",
      "epoch:31 step:24778 [D loss: 0.744503, acc.: 42.97%] [G loss: 0.841213]\n",
      "epoch:31 step:24779 [D loss: 0.649720, acc.: 66.41%] [G loss: 0.782903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24780 [D loss: 0.667678, acc.: 60.94%] [G loss: 0.772783]\n",
      "epoch:31 step:24781 [D loss: 0.661451, acc.: 59.38%] [G loss: 0.761154]\n",
      "epoch:31 step:24782 [D loss: 0.710870, acc.: 54.69%] [G loss: 0.749409]\n",
      "epoch:31 step:24783 [D loss: 0.724590, acc.: 46.09%] [G loss: 0.731635]\n",
      "epoch:31 step:24784 [D loss: 0.683954, acc.: 50.00%] [G loss: 0.780959]\n",
      "epoch:31 step:24785 [D loss: 0.666119, acc.: 64.06%] [G loss: 0.701851]\n",
      "epoch:31 step:24786 [D loss: 0.744144, acc.: 43.75%] [G loss: 0.713579]\n",
      "epoch:31 step:24787 [D loss: 0.669591, acc.: 53.91%] [G loss: 0.731125]\n",
      "epoch:31 step:24788 [D loss: 0.696982, acc.: 57.03%] [G loss: 0.760336]\n",
      "epoch:31 step:24789 [D loss: 0.682578, acc.: 55.47%] [G loss: 0.774952]\n",
      "epoch:31 step:24790 [D loss: 0.666052, acc.: 57.03%] [G loss: 0.690097]\n",
      "epoch:31 step:24791 [D loss: 0.700970, acc.: 54.69%] [G loss: 0.710026]\n",
      "epoch:31 step:24792 [D loss: 0.681269, acc.: 52.34%] [G loss: 0.709198]\n",
      "epoch:31 step:24793 [D loss: 0.706730, acc.: 53.91%] [G loss: 0.818957]\n",
      "epoch:31 step:24794 [D loss: 0.714893, acc.: 42.19%] [G loss: 0.693429]\n",
      "epoch:31 step:24795 [D loss: 0.677591, acc.: 56.25%] [G loss: 0.820205]\n",
      "epoch:31 step:24796 [D loss: 0.701093, acc.: 46.09%] [G loss: 0.751688]\n",
      "epoch:31 step:24797 [D loss: 0.652839, acc.: 64.84%] [G loss: 0.811224]\n",
      "epoch:31 step:24798 [D loss: 0.659991, acc.: 60.16%] [G loss: 0.857367]\n",
      "epoch:31 step:24799 [D loss: 0.686350, acc.: 53.91%] [G loss: 0.763932]\n",
      "epoch:31 step:24800 [D loss: 0.639921, acc.: 68.75%] [G loss: 0.760604]\n",
      "epoch:31 step:24801 [D loss: 0.659922, acc.: 59.38%] [G loss: 0.770564]\n",
      "epoch:31 step:24802 [D loss: 0.712975, acc.: 45.31%] [G loss: 0.733067]\n",
      "epoch:31 step:24803 [D loss: 0.721108, acc.: 50.00%] [G loss: 0.812863]\n",
      "epoch:31 step:24804 [D loss: 0.671429, acc.: 58.59%] [G loss: 0.837471]\n",
      "epoch:31 step:24805 [D loss: 0.668514, acc.: 60.16%] [G loss: 0.797350]\n",
      "epoch:31 step:24806 [D loss: 0.647560, acc.: 65.62%] [G loss: 0.810459]\n",
      "epoch:31 step:24807 [D loss: 0.717207, acc.: 42.97%] [G loss: 0.761797]\n",
      "epoch:31 step:24808 [D loss: 0.709731, acc.: 53.12%] [G loss: 0.803251]\n",
      "epoch:31 step:24809 [D loss: 0.663719, acc.: 61.72%] [G loss: 0.744227]\n",
      "epoch:31 step:24810 [D loss: 0.768601, acc.: 32.03%] [G loss: 0.731982]\n",
      "epoch:31 step:24811 [D loss: 0.722618, acc.: 44.53%] [G loss: 0.698201]\n",
      "epoch:31 step:24812 [D loss: 0.701215, acc.: 44.53%] [G loss: 0.782338]\n",
      "epoch:31 step:24813 [D loss: 0.635639, acc.: 67.97%] [G loss: 0.759912]\n",
      "epoch:31 step:24814 [D loss: 0.716365, acc.: 44.53%] [G loss: 0.769879]\n",
      "epoch:31 step:24815 [D loss: 0.660006, acc.: 59.38%] [G loss: 0.778681]\n",
      "epoch:31 step:24816 [D loss: 0.636729, acc.: 70.31%] [G loss: 0.802595]\n",
      "epoch:31 step:24817 [D loss: 0.704479, acc.: 55.47%] [G loss: 0.761801]\n",
      "epoch:31 step:24818 [D loss: 0.701365, acc.: 55.47%] [G loss: 0.785140]\n",
      "epoch:31 step:24819 [D loss: 0.625930, acc.: 71.88%] [G loss: 0.771612]\n",
      "epoch:31 step:24820 [D loss: 0.736604, acc.: 45.31%] [G loss: 0.784040]\n",
      "epoch:31 step:24821 [D loss: 0.665872, acc.: 54.69%] [G loss: 0.836719]\n",
      "epoch:31 step:24822 [D loss: 0.700190, acc.: 50.00%] [G loss: 0.830914]\n",
      "epoch:31 step:24823 [D loss: 0.685326, acc.: 54.69%] [G loss: 0.759324]\n",
      "epoch:31 step:24824 [D loss: 0.711504, acc.: 46.09%] [G loss: 0.771616]\n",
      "epoch:31 step:24825 [D loss: 0.717375, acc.: 49.22%] [G loss: 0.796097]\n",
      "epoch:31 step:24826 [D loss: 0.706199, acc.: 48.44%] [G loss: 0.758245]\n",
      "epoch:31 step:24827 [D loss: 0.683717, acc.: 53.91%] [G loss: 0.715693]\n",
      "epoch:31 step:24828 [D loss: 0.718178, acc.: 46.09%] [G loss: 0.788100]\n",
      "epoch:31 step:24829 [D loss: 0.661650, acc.: 62.50%] [G loss: 0.721082]\n",
      "epoch:31 step:24830 [D loss: 0.729189, acc.: 50.78%] [G loss: 0.892361]\n",
      "epoch:31 step:24831 [D loss: 0.614615, acc.: 75.00%] [G loss: 0.851895]\n",
      "epoch:31 step:24832 [D loss: 0.695742, acc.: 57.03%] [G loss: 0.780480]\n",
      "epoch:31 step:24833 [D loss: 0.698053, acc.: 49.22%] [G loss: 0.759585]\n",
      "epoch:31 step:24834 [D loss: 0.734290, acc.: 41.41%] [G loss: 0.832535]\n",
      "epoch:31 step:24835 [D loss: 0.653316, acc.: 66.41%] [G loss: 0.798176]\n",
      "epoch:31 step:24836 [D loss: 0.686613, acc.: 53.12%] [G loss: 0.765677]\n",
      "epoch:31 step:24837 [D loss: 0.658511, acc.: 62.50%] [G loss: 0.846339]\n",
      "epoch:31 step:24838 [D loss: 0.759928, acc.: 39.06%] [G loss: 0.804091]\n",
      "epoch:31 step:24839 [D loss: 0.617127, acc.: 74.22%] [G loss: 0.813192]\n",
      "epoch:31 step:24840 [D loss: 0.700447, acc.: 52.34%] [G loss: 0.872635]\n",
      "epoch:31 step:24841 [D loss: 0.686951, acc.: 52.34%] [G loss: 0.775015]\n",
      "epoch:31 step:24842 [D loss: 0.727247, acc.: 42.97%] [G loss: 0.749173]\n",
      "epoch:31 step:24843 [D loss: 0.677057, acc.: 56.25%] [G loss: 0.829832]\n",
      "epoch:31 step:24844 [D loss: 0.717393, acc.: 54.69%] [G loss: 0.793406]\n",
      "epoch:31 step:24845 [D loss: 0.703245, acc.: 54.69%] [G loss: 0.825300]\n",
      "epoch:31 step:24846 [D loss: 0.682400, acc.: 56.25%] [G loss: 0.716779]\n",
      "epoch:31 step:24847 [D loss: 0.675680, acc.: 58.59%] [G loss: 0.721639]\n",
      "epoch:31 step:24848 [D loss: 0.681556, acc.: 53.12%] [G loss: 0.793893]\n",
      "epoch:31 step:24849 [D loss: 0.718735, acc.: 44.53%] [G loss: 0.743404]\n",
      "epoch:31 step:24850 [D loss: 0.735476, acc.: 45.31%] [G loss: 0.697482]\n",
      "epoch:31 step:24851 [D loss: 0.670091, acc.: 61.72%] [G loss: 0.810025]\n",
      "epoch:31 step:24852 [D loss: 0.669531, acc.: 62.50%] [G loss: 0.796022]\n",
      "epoch:31 step:24853 [D loss: 0.726490, acc.: 46.09%] [G loss: 0.762936]\n",
      "epoch:31 step:24854 [D loss: 0.686398, acc.: 52.34%] [G loss: 0.799378]\n",
      "epoch:31 step:24855 [D loss: 0.665531, acc.: 57.03%] [G loss: 0.709922]\n",
      "epoch:31 step:24856 [D loss: 0.688136, acc.: 55.47%] [G loss: 0.809939]\n",
      "epoch:31 step:24857 [D loss: 0.719020, acc.: 49.22%] [G loss: 0.810175]\n",
      "epoch:31 step:24858 [D loss: 0.731851, acc.: 52.34%] [G loss: 0.809446]\n",
      "epoch:31 step:24859 [D loss: 0.642326, acc.: 68.75%] [G loss: 0.734969]\n",
      "epoch:31 step:24860 [D loss: 0.721516, acc.: 49.22%] [G loss: 0.776599]\n",
      "epoch:31 step:24861 [D loss: 0.624373, acc.: 69.53%] [G loss: 0.833673]\n",
      "epoch:31 step:24862 [D loss: 0.660443, acc.: 58.59%] [G loss: 0.846652]\n",
      "epoch:31 step:24863 [D loss: 0.728845, acc.: 46.88%] [G loss: 0.725292]\n",
      "epoch:31 step:24864 [D loss: 0.637868, acc.: 71.09%] [G loss: 0.879263]\n",
      "epoch:31 step:24865 [D loss: 0.712639, acc.: 49.22%] [G loss: 0.705892]\n",
      "epoch:31 step:24866 [D loss: 0.715366, acc.: 50.78%] [G loss: 0.786610]\n",
      "epoch:31 step:24867 [D loss: 0.698957, acc.: 50.00%] [G loss: 0.833442]\n",
      "epoch:31 step:24868 [D loss: 0.696159, acc.: 53.91%] [G loss: 0.837386]\n",
      "epoch:31 step:24869 [D loss: 0.640079, acc.: 65.62%] [G loss: 0.748670]\n",
      "epoch:31 step:24870 [D loss: 0.644868, acc.: 66.41%] [G loss: 0.803544]\n",
      "epoch:31 step:24871 [D loss: 0.682168, acc.: 57.03%] [G loss: 0.772835]\n",
      "epoch:31 step:24872 [D loss: 0.687573, acc.: 57.03%] [G loss: 0.767152]\n",
      "epoch:31 step:24873 [D loss: 0.657018, acc.: 64.06%] [G loss: 0.784599]\n",
      "epoch:31 step:24874 [D loss: 0.673976, acc.: 57.03%] [G loss: 0.736278]\n",
      "epoch:31 step:24875 [D loss: 0.630732, acc.: 67.19%] [G loss: 0.767426]\n",
      "epoch:31 step:24876 [D loss: 0.642519, acc.: 65.62%] [G loss: 0.851639]\n",
      "epoch:31 step:24877 [D loss: 0.672849, acc.: 60.16%] [G loss: 0.845002]\n",
      "epoch:31 step:24878 [D loss: 0.709865, acc.: 46.88%] [G loss: 0.818417]\n",
      "epoch:31 step:24879 [D loss: 0.678126, acc.: 55.47%] [G loss: 0.824060]\n",
      "epoch:31 step:24880 [D loss: 0.645641, acc.: 64.84%] [G loss: 0.772740]\n",
      "epoch:31 step:24881 [D loss: 0.680969, acc.: 57.81%] [G loss: 0.834549]\n",
      "epoch:31 step:24882 [D loss: 0.714818, acc.: 47.66%] [G loss: 0.717500]\n",
      "epoch:31 step:24883 [D loss: 0.671675, acc.: 57.81%] [G loss: 0.769193]\n",
      "epoch:31 step:24884 [D loss: 0.695485, acc.: 51.56%] [G loss: 0.751084]\n",
      "epoch:31 step:24885 [D loss: 0.674242, acc.: 54.69%] [G loss: 0.785446]\n",
      "epoch:31 step:24886 [D loss: 0.671368, acc.: 56.25%] [G loss: 0.800313]\n",
      "epoch:31 step:24887 [D loss: 0.654341, acc.: 58.59%] [G loss: 0.772465]\n",
      "epoch:31 step:24888 [D loss: 0.667711, acc.: 55.47%] [G loss: 0.723154]\n",
      "epoch:31 step:24889 [D loss: 0.720253, acc.: 41.41%] [G loss: 0.756852]\n",
      "epoch:31 step:24890 [D loss: 0.657827, acc.: 60.16%] [G loss: 0.817371]\n",
      "epoch:31 step:24891 [D loss: 0.670526, acc.: 55.47%] [G loss: 0.817815]\n",
      "epoch:31 step:24892 [D loss: 0.692317, acc.: 55.47%] [G loss: 0.687781]\n",
      "epoch:31 step:24893 [D loss: 0.674053, acc.: 58.59%] [G loss: 0.711701]\n",
      "epoch:31 step:24894 [D loss: 0.719776, acc.: 48.44%] [G loss: 0.723797]\n",
      "epoch:31 step:24895 [D loss: 0.724055, acc.: 42.19%] [G loss: 0.773049]\n",
      "epoch:31 step:24896 [D loss: 0.675577, acc.: 64.06%] [G loss: 0.767109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24897 [D loss: 0.728225, acc.: 50.00%] [G loss: 0.710458]\n",
      "epoch:31 step:24898 [D loss: 0.735792, acc.: 46.09%] [G loss: 0.756132]\n",
      "epoch:31 step:24899 [D loss: 0.741415, acc.: 46.88%] [G loss: 0.751032]\n",
      "epoch:31 step:24900 [D loss: 0.737901, acc.: 42.19%] [G loss: 0.834959]\n",
      "epoch:31 step:24901 [D loss: 0.631726, acc.: 68.75%] [G loss: 0.786925]\n",
      "epoch:31 step:24902 [D loss: 0.687805, acc.: 48.44%] [G loss: 0.769377]\n",
      "epoch:31 step:24903 [D loss: 0.730383, acc.: 45.31%] [G loss: 0.730972]\n",
      "epoch:31 step:24904 [D loss: 0.672921, acc.: 57.81%] [G loss: 0.750318]\n",
      "epoch:31 step:24905 [D loss: 0.686202, acc.: 52.34%] [G loss: 0.687008]\n",
      "epoch:31 step:24906 [D loss: 0.712427, acc.: 49.22%] [G loss: 0.750510]\n",
      "epoch:31 step:24907 [D loss: 0.685434, acc.: 56.25%] [G loss: 0.811339]\n",
      "epoch:31 step:24908 [D loss: 0.731370, acc.: 44.53%] [G loss: 0.710203]\n",
      "epoch:31 step:24909 [D loss: 0.647494, acc.: 65.62%] [G loss: 0.675947]\n",
      "epoch:31 step:24910 [D loss: 0.681593, acc.: 53.12%] [G loss: 0.790148]\n",
      "epoch:31 step:24911 [D loss: 0.635646, acc.: 64.06%] [G loss: 0.694055]\n",
      "epoch:31 step:24912 [D loss: 0.687579, acc.: 55.47%] [G loss: 0.772787]\n",
      "epoch:31 step:24913 [D loss: 0.719158, acc.: 45.31%] [G loss: 0.740341]\n",
      "epoch:31 step:24914 [D loss: 0.692967, acc.: 53.12%] [G loss: 0.779644]\n",
      "epoch:31 step:24915 [D loss: 0.663368, acc.: 59.38%] [G loss: 0.744025]\n",
      "epoch:31 step:24916 [D loss: 0.687156, acc.: 48.44%] [G loss: 0.787598]\n",
      "epoch:31 step:24917 [D loss: 0.697086, acc.: 53.12%] [G loss: 0.771749]\n",
      "epoch:31 step:24918 [D loss: 0.733742, acc.: 45.31%] [G loss: 0.742245]\n",
      "epoch:31 step:24919 [D loss: 0.728137, acc.: 47.66%] [G loss: 0.780291]\n",
      "epoch:31 step:24920 [D loss: 0.701661, acc.: 49.22%] [G loss: 0.786130]\n",
      "epoch:31 step:24921 [D loss: 0.757947, acc.: 37.50%] [G loss: 0.787063]\n",
      "epoch:31 step:24922 [D loss: 0.719085, acc.: 46.09%] [G loss: 0.769344]\n",
      "epoch:31 step:24923 [D loss: 0.680560, acc.: 52.34%] [G loss: 0.784579]\n",
      "epoch:31 step:24924 [D loss: 0.660880, acc.: 60.94%] [G loss: 0.801424]\n",
      "epoch:31 step:24925 [D loss: 0.675186, acc.: 57.81%] [G loss: 0.816078]\n",
      "epoch:31 step:24926 [D loss: 0.684431, acc.: 58.59%] [G loss: 0.780902]\n",
      "epoch:31 step:24927 [D loss: 0.708928, acc.: 53.12%] [G loss: 0.747009]\n",
      "epoch:31 step:24928 [D loss: 0.654714, acc.: 67.19%] [G loss: 0.751951]\n",
      "epoch:31 step:24929 [D loss: 0.665033, acc.: 60.94%] [G loss: 0.784997]\n",
      "epoch:31 step:24930 [D loss: 0.699762, acc.: 49.22%] [G loss: 0.842295]\n",
      "epoch:31 step:24931 [D loss: 0.669957, acc.: 55.47%] [G loss: 0.800318]\n",
      "epoch:31 step:24932 [D loss: 0.682024, acc.: 50.78%] [G loss: 0.752992]\n",
      "epoch:31 step:24933 [D loss: 0.684607, acc.: 54.69%] [G loss: 0.723641]\n",
      "epoch:31 step:24934 [D loss: 0.697742, acc.: 50.00%] [G loss: 0.734162]\n",
      "epoch:31 step:24935 [D loss: 0.736189, acc.: 47.66%] [G loss: 0.801226]\n",
      "epoch:31 step:24936 [D loss: 0.689045, acc.: 57.81%] [G loss: 0.720064]\n",
      "epoch:31 step:24937 [D loss: 0.718391, acc.: 50.00%] [G loss: 0.719347]\n",
      "epoch:31 step:24938 [D loss: 0.732941, acc.: 46.09%] [G loss: 0.730123]\n",
      "epoch:31 step:24939 [D loss: 0.725991, acc.: 42.97%] [G loss: 0.744077]\n",
      "epoch:31 step:24940 [D loss: 0.684867, acc.: 53.91%] [G loss: 0.775048]\n",
      "epoch:31 step:24941 [D loss: 0.696668, acc.: 48.44%] [G loss: 0.749940]\n",
      "epoch:31 step:24942 [D loss: 0.693226, acc.: 54.69%] [G loss: 0.800174]\n",
      "epoch:31 step:24943 [D loss: 0.722428, acc.: 45.31%] [G loss: 0.769006]\n",
      "epoch:31 step:24944 [D loss: 0.695097, acc.: 55.47%] [G loss: 0.757826]\n",
      "epoch:31 step:24945 [D loss: 0.706403, acc.: 46.88%] [G loss: 0.760656]\n",
      "epoch:31 step:24946 [D loss: 0.679621, acc.: 56.25%] [G loss: 0.746866]\n",
      "epoch:31 step:24947 [D loss: 0.648632, acc.: 64.84%] [G loss: 0.752465]\n",
      "epoch:31 step:24948 [D loss: 0.693127, acc.: 47.66%] [G loss: 0.766987]\n",
      "epoch:31 step:24949 [D loss: 0.645806, acc.: 64.06%] [G loss: 0.807370]\n",
      "epoch:31 step:24950 [D loss: 0.732530, acc.: 46.09%] [G loss: 0.777507]\n",
      "epoch:31 step:24951 [D loss: 0.674178, acc.: 57.81%] [G loss: 0.785601]\n",
      "epoch:31 step:24952 [D loss: 0.701929, acc.: 46.88%] [G loss: 0.797996]\n",
      "epoch:31 step:24953 [D loss: 0.703896, acc.: 51.56%] [G loss: 0.770988]\n",
      "epoch:31 step:24954 [D loss: 0.653722, acc.: 64.06%] [G loss: 0.727591]\n",
      "epoch:31 step:24955 [D loss: 0.675879, acc.: 56.25%] [G loss: 0.777146]\n",
      "epoch:31 step:24956 [D loss: 0.679637, acc.: 57.03%] [G loss: 0.751414]\n",
      "epoch:31 step:24957 [D loss: 0.646783, acc.: 66.41%] [G loss: 0.787036]\n",
      "epoch:31 step:24958 [D loss: 0.727330, acc.: 46.09%] [G loss: 0.764908]\n",
      "epoch:31 step:24959 [D loss: 0.693706, acc.: 54.69%] [G loss: 0.817256]\n",
      "epoch:31 step:24960 [D loss: 0.653589, acc.: 65.62%] [G loss: 0.787342]\n",
      "epoch:31 step:24961 [D loss: 0.684264, acc.: 57.03%] [G loss: 0.717156]\n",
      "epoch:31 step:24962 [D loss: 0.727622, acc.: 39.84%] [G loss: 0.707452]\n",
      "epoch:31 step:24963 [D loss: 0.681837, acc.: 53.91%] [G loss: 0.686360]\n",
      "epoch:31 step:24964 [D loss: 0.657975, acc.: 59.38%] [G loss: 0.760414]\n",
      "epoch:31 step:24965 [D loss: 0.659314, acc.: 57.81%] [G loss: 0.848897]\n",
      "epoch:31 step:24966 [D loss: 0.699818, acc.: 48.44%] [G loss: 0.803366]\n",
      "epoch:31 step:24967 [D loss: 0.675006, acc.: 60.16%] [G loss: 0.769439]\n",
      "epoch:31 step:24968 [D loss: 0.656799, acc.: 61.72%] [G loss: 0.907101]\n",
      "epoch:31 step:24969 [D loss: 0.696635, acc.: 57.03%] [G loss: 0.734863]\n",
      "epoch:31 step:24970 [D loss: 0.738486, acc.: 42.19%] [G loss: 0.707822]\n",
      "epoch:31 step:24971 [D loss: 0.747913, acc.: 42.97%] [G loss: 0.792371]\n",
      "epoch:31 step:24972 [D loss: 0.683205, acc.: 56.25%] [G loss: 0.806774]\n",
      "epoch:31 step:24973 [D loss: 0.729391, acc.: 40.62%] [G loss: 0.765238]\n",
      "epoch:31 step:24974 [D loss: 0.710974, acc.: 50.78%] [G loss: 0.794333]\n",
      "epoch:31 step:24975 [D loss: 0.673791, acc.: 55.47%] [G loss: 0.765561]\n",
      "epoch:31 step:24976 [D loss: 0.681966, acc.: 47.66%] [G loss: 0.752202]\n",
      "epoch:31 step:24977 [D loss: 0.641190, acc.: 68.75%] [G loss: 0.812733]\n",
      "epoch:31 step:24978 [D loss: 0.657867, acc.: 65.62%] [G loss: 0.819372]\n",
      "epoch:31 step:24979 [D loss: 0.639225, acc.: 64.84%] [G loss: 0.804207]\n",
      "epoch:31 step:24980 [D loss: 0.677809, acc.: 57.03%] [G loss: 0.791048]\n",
      "epoch:31 step:24981 [D loss: 0.669423, acc.: 60.94%] [G loss: 0.794327]\n",
      "epoch:31 step:24982 [D loss: 0.696833, acc.: 50.00%] [G loss: 0.763162]\n",
      "epoch:31 step:24983 [D loss: 0.689041, acc.: 53.12%] [G loss: 0.750856]\n",
      "epoch:31 step:24984 [D loss: 0.620414, acc.: 68.75%] [G loss: 0.800189]\n",
      "epoch:31 step:24985 [D loss: 0.719580, acc.: 49.22%] [G loss: 0.824155]\n",
      "epoch:31 step:24986 [D loss: 0.736574, acc.: 48.44%] [G loss: 0.817413]\n",
      "epoch:31 step:24987 [D loss: 0.695589, acc.: 54.69%] [G loss: 0.745892]\n",
      "epoch:31 step:24988 [D loss: 0.621989, acc.: 73.44%] [G loss: 0.831398]\n",
      "epoch:31 step:24989 [D loss: 0.651494, acc.: 66.41%] [G loss: 0.727697]\n",
      "epoch:31 step:24990 [D loss: 0.629786, acc.: 65.62%] [G loss: 0.741764]\n",
      "epoch:31 step:24991 [D loss: 0.693506, acc.: 53.12%] [G loss: 0.722216]\n",
      "epoch:31 step:24992 [D loss: 0.651582, acc.: 64.06%] [G loss: 0.748771]\n",
      "epoch:32 step:24993 [D loss: 0.657528, acc.: 57.81%] [G loss: 0.737828]\n",
      "epoch:32 step:24994 [D loss: 0.706038, acc.: 51.56%] [G loss: 0.755519]\n",
      "epoch:32 step:24995 [D loss: 0.722897, acc.: 42.97%] [G loss: 0.765660]\n",
      "epoch:32 step:24996 [D loss: 0.731090, acc.: 42.19%] [G loss: 0.783688]\n",
      "epoch:32 step:24997 [D loss: 0.663343, acc.: 59.38%] [G loss: 0.669160]\n",
      "epoch:32 step:24998 [D loss: 0.675996, acc.: 60.16%] [G loss: 0.879697]\n",
      "epoch:32 step:24999 [D loss: 0.680824, acc.: 53.91%] [G loss: 0.763001]\n",
      "epoch:32 step:25000 [D loss: 0.652486, acc.: 59.38%] [G loss: 0.777776]\n",
      "epoch:32 step:25001 [D loss: 0.712120, acc.: 46.09%] [G loss: 0.771051]\n",
      "epoch:32 step:25002 [D loss: 0.726831, acc.: 46.09%] [G loss: 0.791772]\n",
      "epoch:32 step:25003 [D loss: 0.731446, acc.: 47.66%] [G loss: 0.764672]\n",
      "epoch:32 step:25004 [D loss: 0.724882, acc.: 42.19%] [G loss: 0.775009]\n",
      "epoch:32 step:25005 [D loss: 0.702706, acc.: 45.31%] [G loss: 0.807992]\n",
      "epoch:32 step:25006 [D loss: 0.642919, acc.: 68.75%] [G loss: 0.812841]\n",
      "epoch:32 step:25007 [D loss: 0.709748, acc.: 43.75%] [G loss: 0.777994]\n",
      "epoch:32 step:25008 [D loss: 0.672783, acc.: 56.25%] [G loss: 0.819782]\n",
      "epoch:32 step:25009 [D loss: 0.691508, acc.: 53.91%] [G loss: 0.824947]\n",
      "epoch:32 step:25010 [D loss: 0.678057, acc.: 53.91%] [G loss: 0.763324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25011 [D loss: 0.681294, acc.: 59.38%] [G loss: 0.766507]\n",
      "epoch:32 step:25012 [D loss: 0.646158, acc.: 66.41%] [G loss: 0.816940]\n",
      "epoch:32 step:25013 [D loss: 0.713903, acc.: 53.91%] [G loss: 0.757301]\n",
      "epoch:32 step:25014 [D loss: 0.679628, acc.: 57.03%] [G loss: 0.761589]\n",
      "epoch:32 step:25015 [D loss: 0.702462, acc.: 49.22%] [G loss: 0.732357]\n",
      "epoch:32 step:25016 [D loss: 0.664038, acc.: 62.50%] [G loss: 0.848939]\n",
      "epoch:32 step:25017 [D loss: 0.699031, acc.: 53.91%] [G loss: 0.744828]\n",
      "epoch:32 step:25018 [D loss: 0.667837, acc.: 55.47%] [G loss: 0.693369]\n",
      "epoch:32 step:25019 [D loss: 0.698541, acc.: 50.78%] [G loss: 0.797992]\n",
      "epoch:32 step:25020 [D loss: 0.696640, acc.: 50.00%] [G loss: 0.679087]\n",
      "epoch:32 step:25021 [D loss: 0.678504, acc.: 56.25%] [G loss: 0.748146]\n",
      "epoch:32 step:25022 [D loss: 0.665881, acc.: 57.81%] [G loss: 0.729539]\n",
      "epoch:32 step:25023 [D loss: 0.706328, acc.: 47.66%] [G loss: 0.762761]\n",
      "epoch:32 step:25024 [D loss: 0.661188, acc.: 60.94%] [G loss: 0.751991]\n",
      "epoch:32 step:25025 [D loss: 0.711623, acc.: 47.66%] [G loss: 0.762569]\n",
      "epoch:32 step:25026 [D loss: 0.712293, acc.: 53.91%] [G loss: 0.687821]\n",
      "epoch:32 step:25027 [D loss: 0.675412, acc.: 60.94%] [G loss: 0.722427]\n",
      "epoch:32 step:25028 [D loss: 0.724905, acc.: 42.97%] [G loss: 0.770011]\n",
      "epoch:32 step:25029 [D loss: 0.687964, acc.: 53.91%] [G loss: 0.764822]\n",
      "epoch:32 step:25030 [D loss: 0.707077, acc.: 49.22%] [G loss: 0.761977]\n",
      "epoch:32 step:25031 [D loss: 0.681985, acc.: 58.59%] [G loss: 0.743775]\n",
      "epoch:32 step:25032 [D loss: 0.652782, acc.: 58.59%] [G loss: 0.809413]\n",
      "epoch:32 step:25033 [D loss: 0.693046, acc.: 51.56%] [G loss: 0.745600]\n",
      "epoch:32 step:25034 [D loss: 0.707068, acc.: 49.22%] [G loss: 0.722925]\n",
      "epoch:32 step:25035 [D loss: 0.706561, acc.: 50.78%] [G loss: 0.724440]\n",
      "epoch:32 step:25036 [D loss: 0.704952, acc.: 51.56%] [G loss: 0.752725]\n",
      "epoch:32 step:25037 [D loss: 0.644486, acc.: 60.16%] [G loss: 0.787480]\n",
      "epoch:32 step:25038 [D loss: 0.677171, acc.: 54.69%] [G loss: 0.803937]\n",
      "epoch:32 step:25039 [D loss: 0.740575, acc.: 46.09%] [G loss: 0.748187]\n",
      "epoch:32 step:25040 [D loss: 0.653769, acc.: 57.81%] [G loss: 0.812704]\n",
      "epoch:32 step:25041 [D loss: 0.700373, acc.: 53.91%] [G loss: 0.827358]\n",
      "epoch:32 step:25042 [D loss: 0.723182, acc.: 51.56%] [G loss: 0.822317]\n",
      "epoch:32 step:25043 [D loss: 0.641834, acc.: 65.62%] [G loss: 0.783609]\n",
      "epoch:32 step:25044 [D loss: 0.670769, acc.: 53.91%] [G loss: 0.779031]\n",
      "epoch:32 step:25045 [D loss: 0.681706, acc.: 60.16%] [G loss: 0.723435]\n",
      "epoch:32 step:25046 [D loss: 0.714092, acc.: 50.78%] [G loss: 0.803902]\n",
      "epoch:32 step:25047 [D loss: 0.646424, acc.: 66.41%] [G loss: 0.753593]\n",
      "epoch:32 step:25048 [D loss: 0.717212, acc.: 44.53%] [G loss: 0.722726]\n",
      "epoch:32 step:25049 [D loss: 0.675305, acc.: 61.72%] [G loss: 0.824991]\n",
      "epoch:32 step:25050 [D loss: 0.701649, acc.: 48.44%] [G loss: 0.763718]\n",
      "epoch:32 step:25051 [D loss: 0.668627, acc.: 57.81%] [G loss: 0.743119]\n",
      "epoch:32 step:25052 [D loss: 0.675652, acc.: 59.38%] [G loss: 0.804422]\n",
      "epoch:32 step:25053 [D loss: 0.677263, acc.: 59.38%] [G loss: 0.833265]\n",
      "epoch:32 step:25054 [D loss: 0.679593, acc.: 55.47%] [G loss: 0.741372]\n",
      "epoch:32 step:25055 [D loss: 0.728694, acc.: 39.06%] [G loss: 0.793263]\n",
      "epoch:32 step:25056 [D loss: 0.656976, acc.: 54.69%] [G loss: 0.859405]\n",
      "epoch:32 step:25057 [D loss: 0.695763, acc.: 56.25%] [G loss: 0.773498]\n",
      "epoch:32 step:25058 [D loss: 0.694220, acc.: 56.25%] [G loss: 0.809595]\n",
      "epoch:32 step:25059 [D loss: 0.668690, acc.: 57.81%] [G loss: 0.785365]\n",
      "epoch:32 step:25060 [D loss: 0.668797, acc.: 63.28%] [G loss: 0.832826]\n",
      "epoch:32 step:25061 [D loss: 0.707409, acc.: 45.31%] [G loss: 0.757977]\n",
      "epoch:32 step:25062 [D loss: 0.682456, acc.: 54.69%] [G loss: 0.764839]\n",
      "epoch:32 step:25063 [D loss: 0.666067, acc.: 59.38%] [G loss: 0.727098]\n",
      "epoch:32 step:25064 [D loss: 0.639312, acc.: 64.06%] [G loss: 0.726889]\n",
      "epoch:32 step:25065 [D loss: 0.666590, acc.: 64.84%] [G loss: 0.719747]\n",
      "epoch:32 step:25066 [D loss: 0.667884, acc.: 58.59%] [G loss: 0.715522]\n",
      "epoch:32 step:25067 [D loss: 0.639138, acc.: 64.06%] [G loss: 0.733425]\n",
      "epoch:32 step:25068 [D loss: 0.759063, acc.: 39.84%] [G loss: 0.760946]\n",
      "epoch:32 step:25069 [D loss: 0.650531, acc.: 61.72%] [G loss: 0.751021]\n",
      "epoch:32 step:25070 [D loss: 0.683698, acc.: 56.25%] [G loss: 0.788665]\n",
      "epoch:32 step:25071 [D loss: 0.650838, acc.: 61.72%] [G loss: 0.809190]\n",
      "epoch:32 step:25072 [D loss: 0.665247, acc.: 57.03%] [G loss: 0.743960]\n",
      "epoch:32 step:25073 [D loss: 0.721592, acc.: 46.09%] [G loss: 0.731726]\n",
      "epoch:32 step:25074 [D loss: 0.693446, acc.: 53.91%] [G loss: 0.795263]\n",
      "epoch:32 step:25075 [D loss: 0.670113, acc.: 57.81%] [G loss: 0.790606]\n",
      "epoch:32 step:25076 [D loss: 0.702702, acc.: 48.44%] [G loss: 0.802466]\n",
      "epoch:32 step:25077 [D loss: 0.709660, acc.: 49.22%] [G loss: 0.792910]\n",
      "epoch:32 step:25078 [D loss: 0.719719, acc.: 39.84%] [G loss: 0.785928]\n",
      "epoch:32 step:25079 [D loss: 0.658749, acc.: 69.53%] [G loss: 0.824800]\n",
      "epoch:32 step:25080 [D loss: 0.718467, acc.: 46.88%] [G loss: 0.698734]\n",
      "epoch:32 step:25081 [D loss: 0.716654, acc.: 51.56%] [G loss: 0.749429]\n",
      "epoch:32 step:25082 [D loss: 0.698206, acc.: 52.34%] [G loss: 0.753864]\n",
      "epoch:32 step:25083 [D loss: 0.626249, acc.: 67.97%] [G loss: 0.790968]\n",
      "epoch:32 step:25084 [D loss: 0.703374, acc.: 62.50%] [G loss: 0.733969]\n",
      "epoch:32 step:25085 [D loss: 0.684679, acc.: 56.25%] [G loss: 0.736815]\n",
      "epoch:32 step:25086 [D loss: 0.690419, acc.: 56.25%] [G loss: 0.705375]\n",
      "epoch:32 step:25087 [D loss: 0.717695, acc.: 49.22%] [G loss: 0.762720]\n",
      "epoch:32 step:25088 [D loss: 0.711272, acc.: 46.09%] [G loss: 0.816090]\n",
      "epoch:32 step:25089 [D loss: 0.675607, acc.: 58.59%] [G loss: 0.871214]\n",
      "epoch:32 step:25090 [D loss: 0.722495, acc.: 46.09%] [G loss: 0.756344]\n",
      "epoch:32 step:25091 [D loss: 0.681033, acc.: 54.69%] [G loss: 0.811705]\n",
      "epoch:32 step:25092 [D loss: 0.699217, acc.: 46.88%] [G loss: 0.783676]\n",
      "epoch:32 step:25093 [D loss: 0.728693, acc.: 46.09%] [G loss: 0.803475]\n",
      "epoch:32 step:25094 [D loss: 0.663086, acc.: 55.47%] [G loss: 0.750403]\n",
      "epoch:32 step:25095 [D loss: 0.788512, acc.: 34.38%] [G loss: 0.757977]\n",
      "epoch:32 step:25096 [D loss: 0.688635, acc.: 54.69%] [G loss: 0.764592]\n",
      "epoch:32 step:25097 [D loss: 0.707538, acc.: 53.12%] [G loss: 0.765063]\n",
      "epoch:32 step:25098 [D loss: 0.719358, acc.: 37.50%] [G loss: 0.826366]\n",
      "epoch:32 step:25099 [D loss: 0.650485, acc.: 60.94%] [G loss: 0.800982]\n",
      "epoch:32 step:25100 [D loss: 0.730248, acc.: 42.19%] [G loss: 0.693200]\n",
      "epoch:32 step:25101 [D loss: 0.677016, acc.: 53.12%] [G loss: 0.721927]\n",
      "epoch:32 step:25102 [D loss: 0.673008, acc.: 56.25%] [G loss: 0.688614]\n",
      "epoch:32 step:25103 [D loss: 0.692208, acc.: 50.78%] [G loss: 0.743544]\n",
      "epoch:32 step:25104 [D loss: 0.652139, acc.: 60.94%] [G loss: 0.753698]\n",
      "epoch:32 step:25105 [D loss: 0.747035, acc.: 42.97%] [G loss: 0.665047]\n",
      "epoch:32 step:25106 [D loss: 0.692439, acc.: 56.25%] [G loss: 0.737985]\n",
      "epoch:32 step:25107 [D loss: 0.724556, acc.: 46.88%] [G loss: 0.742725]\n",
      "epoch:32 step:25108 [D loss: 0.646006, acc.: 69.53%] [G loss: 0.783492]\n",
      "epoch:32 step:25109 [D loss: 0.681295, acc.: 55.47%] [G loss: 0.816450]\n",
      "epoch:32 step:25110 [D loss: 0.730274, acc.: 46.09%] [G loss: 0.760694]\n",
      "epoch:32 step:25111 [D loss: 0.740943, acc.: 44.53%] [G loss: 0.795694]\n",
      "epoch:32 step:25112 [D loss: 0.674330, acc.: 59.38%] [G loss: 0.749229]\n",
      "epoch:32 step:25113 [D loss: 0.720411, acc.: 47.66%] [G loss: 0.817735]\n",
      "epoch:32 step:25114 [D loss: 0.657893, acc.: 65.62%] [G loss: 0.786642]\n",
      "epoch:32 step:25115 [D loss: 0.696761, acc.: 53.12%] [G loss: 0.815876]\n",
      "epoch:32 step:25116 [D loss: 0.677243, acc.: 60.16%] [G loss: 0.796522]\n",
      "epoch:32 step:25117 [D loss: 0.704774, acc.: 48.44%] [G loss: 0.774492]\n",
      "epoch:32 step:25118 [D loss: 0.720020, acc.: 50.00%] [G loss: 0.758878]\n",
      "epoch:32 step:25119 [D loss: 0.658470, acc.: 64.06%] [G loss: 0.739273]\n",
      "epoch:32 step:25120 [D loss: 0.685951, acc.: 51.56%] [G loss: 0.708061]\n",
      "epoch:32 step:25121 [D loss: 0.656795, acc.: 63.28%] [G loss: 0.721853]\n",
      "epoch:32 step:25122 [D loss: 0.718022, acc.: 43.75%] [G loss: 0.688959]\n",
      "epoch:32 step:25123 [D loss: 0.691796, acc.: 47.66%] [G loss: 0.753767]\n",
      "epoch:32 step:25124 [D loss: 0.709472, acc.: 53.91%] [G loss: 0.812411]\n",
      "epoch:32 step:25125 [D loss: 0.719217, acc.: 44.53%] [G loss: 0.782918]\n",
      "epoch:32 step:25126 [D loss: 0.714120, acc.: 46.88%] [G loss: 0.879334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25127 [D loss: 0.693965, acc.: 58.59%] [G loss: 0.855657]\n",
      "epoch:32 step:25128 [D loss: 0.697243, acc.: 51.56%] [G loss: 0.745986]\n",
      "epoch:32 step:25129 [D loss: 0.705882, acc.: 50.00%] [G loss: 0.782814]\n",
      "epoch:32 step:25130 [D loss: 0.716132, acc.: 49.22%] [G loss: 0.753729]\n",
      "epoch:32 step:25131 [D loss: 0.699486, acc.: 50.78%] [G loss: 0.798858]\n",
      "epoch:32 step:25132 [D loss: 0.717575, acc.: 50.00%] [G loss: 0.788475]\n",
      "epoch:32 step:25133 [D loss: 0.688934, acc.: 56.25%] [G loss: 0.756678]\n",
      "epoch:32 step:25134 [D loss: 0.698293, acc.: 53.91%] [G loss: 0.746935]\n",
      "epoch:32 step:25135 [D loss: 0.676769, acc.: 55.47%] [G loss: 0.765614]\n",
      "epoch:32 step:25136 [D loss: 0.702959, acc.: 53.91%] [G loss: 0.777568]\n",
      "epoch:32 step:25137 [D loss: 0.661434, acc.: 59.38%] [G loss: 0.708391]\n",
      "epoch:32 step:25138 [D loss: 0.681475, acc.: 56.25%] [G loss: 0.788667]\n",
      "epoch:32 step:25139 [D loss: 0.692537, acc.: 53.91%] [G loss: 0.729995]\n",
      "epoch:32 step:25140 [D loss: 0.690247, acc.: 58.59%] [G loss: 0.735707]\n",
      "epoch:32 step:25141 [D loss: 0.719467, acc.: 39.84%] [G loss: 0.765463]\n",
      "epoch:32 step:25142 [D loss: 0.698672, acc.: 57.03%] [G loss: 0.790754]\n",
      "epoch:32 step:25143 [D loss: 0.679524, acc.: 57.03%] [G loss: 0.860125]\n",
      "epoch:32 step:25144 [D loss: 0.732005, acc.: 39.06%] [G loss: 0.714687]\n",
      "epoch:32 step:25145 [D loss: 0.706766, acc.: 46.88%] [G loss: 0.773106]\n",
      "epoch:32 step:25146 [D loss: 0.648255, acc.: 67.19%] [G loss: 0.765884]\n",
      "epoch:32 step:25147 [D loss: 0.647971, acc.: 64.84%] [G loss: 0.759686]\n",
      "epoch:32 step:25148 [D loss: 0.656006, acc.: 57.81%] [G loss: 0.855391]\n",
      "epoch:32 step:25149 [D loss: 0.704045, acc.: 46.88%] [G loss: 0.839237]\n",
      "epoch:32 step:25150 [D loss: 0.721405, acc.: 46.09%] [G loss: 0.844993]\n",
      "epoch:32 step:25151 [D loss: 0.672454, acc.: 62.50%] [G loss: 0.793752]\n",
      "epoch:32 step:25152 [D loss: 0.627227, acc.: 69.53%] [G loss: 0.792244]\n",
      "epoch:32 step:25153 [D loss: 0.740984, acc.: 45.31%] [G loss: 0.741843]\n",
      "epoch:32 step:25154 [D loss: 0.694693, acc.: 54.69%] [G loss: 0.748005]\n",
      "epoch:32 step:25155 [D loss: 0.649358, acc.: 64.84%] [G loss: 0.725221]\n",
      "epoch:32 step:25156 [D loss: 0.695370, acc.: 52.34%] [G loss: 0.862949]\n",
      "epoch:32 step:25157 [D loss: 0.694793, acc.: 51.56%] [G loss: 0.781721]\n",
      "epoch:32 step:25158 [D loss: 0.664846, acc.: 61.72%] [G loss: 0.728192]\n",
      "epoch:32 step:25159 [D loss: 0.697480, acc.: 50.78%] [G loss: 0.787246]\n",
      "epoch:32 step:25160 [D loss: 0.647395, acc.: 64.84%] [G loss: 0.807219]\n",
      "epoch:32 step:25161 [D loss: 0.711753, acc.: 51.56%] [G loss: 0.831381]\n",
      "epoch:32 step:25162 [D loss: 0.692968, acc.: 52.34%] [G loss: 0.833593]\n",
      "epoch:32 step:25163 [D loss: 0.702071, acc.: 48.44%] [G loss: 0.809493]\n",
      "epoch:32 step:25164 [D loss: 0.705228, acc.: 50.78%] [G loss: 0.725632]\n",
      "epoch:32 step:25165 [D loss: 0.690348, acc.: 50.78%] [G loss: 0.782650]\n",
      "epoch:32 step:25166 [D loss: 0.744642, acc.: 45.31%] [G loss: 0.742253]\n",
      "epoch:32 step:25167 [D loss: 0.632803, acc.: 68.75%] [G loss: 0.788373]\n",
      "epoch:32 step:25168 [D loss: 0.660901, acc.: 57.81%] [G loss: 0.834033]\n",
      "epoch:32 step:25169 [D loss: 0.704676, acc.: 49.22%] [G loss: 0.722968]\n",
      "epoch:32 step:25170 [D loss: 0.694481, acc.: 52.34%] [G loss: 0.720345]\n",
      "epoch:32 step:25171 [D loss: 0.687835, acc.: 58.59%] [G loss: 0.786561]\n",
      "epoch:32 step:25172 [D loss: 0.674590, acc.: 55.47%] [G loss: 0.805649]\n",
      "epoch:32 step:25173 [D loss: 0.700885, acc.: 48.44%] [G loss: 0.735843]\n",
      "epoch:32 step:25174 [D loss: 0.690231, acc.: 52.34%] [G loss: 0.753648]\n",
      "epoch:32 step:25175 [D loss: 0.697625, acc.: 49.22%] [G loss: 0.680077]\n",
      "epoch:32 step:25176 [D loss: 0.701929, acc.: 53.91%] [G loss: 0.780175]\n",
      "epoch:32 step:25177 [D loss: 0.701002, acc.: 48.44%] [G loss: 0.744855]\n",
      "epoch:32 step:25178 [D loss: 0.693467, acc.: 55.47%] [G loss: 0.738928]\n",
      "epoch:32 step:25179 [D loss: 0.643782, acc.: 70.31%] [G loss: 0.821704]\n",
      "epoch:32 step:25180 [D loss: 0.678747, acc.: 53.12%] [G loss: 0.759085]\n",
      "epoch:32 step:25181 [D loss: 0.676664, acc.: 58.59%] [G loss: 0.781693]\n",
      "epoch:32 step:25182 [D loss: 0.684834, acc.: 50.78%] [G loss: 0.789492]\n",
      "epoch:32 step:25183 [D loss: 0.644930, acc.: 69.53%] [G loss: 0.778201]\n",
      "epoch:32 step:25184 [D loss: 0.669719, acc.: 57.03%] [G loss: 0.779972]\n",
      "epoch:32 step:25185 [D loss: 0.720778, acc.: 49.22%] [G loss: 0.770892]\n",
      "epoch:32 step:25186 [D loss: 0.702502, acc.: 52.34%] [G loss: 0.774847]\n",
      "epoch:32 step:25187 [D loss: 0.723686, acc.: 45.31%] [G loss: 0.805826]\n",
      "epoch:32 step:25188 [D loss: 0.661660, acc.: 63.28%] [G loss: 0.841703]\n",
      "epoch:32 step:25189 [D loss: 0.718229, acc.: 46.09%] [G loss: 0.746548]\n",
      "epoch:32 step:25190 [D loss: 0.667099, acc.: 59.38%] [G loss: 0.777277]\n",
      "epoch:32 step:25191 [D loss: 0.694387, acc.: 50.00%] [G loss: 0.800041]\n",
      "epoch:32 step:25192 [D loss: 0.658735, acc.: 63.28%] [G loss: 0.785108]\n",
      "epoch:32 step:25193 [D loss: 0.692259, acc.: 53.12%] [G loss: 0.811512]\n",
      "epoch:32 step:25194 [D loss: 0.656235, acc.: 64.06%] [G loss: 0.790437]\n",
      "epoch:32 step:25195 [D loss: 0.663225, acc.: 60.94%] [G loss: 0.823292]\n",
      "epoch:32 step:25196 [D loss: 0.664525, acc.: 55.47%] [G loss: 0.833010]\n",
      "epoch:32 step:25197 [D loss: 0.700511, acc.: 52.34%] [G loss: 0.761063]\n",
      "epoch:32 step:25198 [D loss: 0.677268, acc.: 57.03%] [G loss: 0.868002]\n",
      "epoch:32 step:25199 [D loss: 0.620444, acc.: 75.00%] [G loss: 0.776803]\n",
      "epoch:32 step:25200 [D loss: 0.708672, acc.: 45.31%] [G loss: 0.714812]\n",
      "epoch:32 step:25201 [D loss: 0.711591, acc.: 50.00%] [G loss: 0.783432]\n",
      "epoch:32 step:25202 [D loss: 0.663387, acc.: 57.81%] [G loss: 0.854559]\n",
      "epoch:32 step:25203 [D loss: 0.682375, acc.: 57.81%] [G loss: 0.684384]\n",
      "epoch:32 step:25204 [D loss: 0.679617, acc.: 57.03%] [G loss: 0.782046]\n",
      "epoch:32 step:25205 [D loss: 0.715126, acc.: 53.12%] [G loss: 0.838416]\n",
      "epoch:32 step:25206 [D loss: 0.698458, acc.: 49.22%] [G loss: 0.792178]\n",
      "epoch:32 step:25207 [D loss: 0.712968, acc.: 53.12%] [G loss: 0.823164]\n",
      "epoch:32 step:25208 [D loss: 0.704177, acc.: 47.66%] [G loss: 0.676048]\n",
      "epoch:32 step:25209 [D loss: 0.697329, acc.: 56.25%] [G loss: 0.752628]\n",
      "epoch:32 step:25210 [D loss: 0.657909, acc.: 57.81%] [G loss: 0.769524]\n",
      "epoch:32 step:25211 [D loss: 0.671843, acc.: 58.59%] [G loss: 0.784643]\n",
      "epoch:32 step:25212 [D loss: 0.689220, acc.: 52.34%] [G loss: 0.748470]\n",
      "epoch:32 step:25213 [D loss: 0.696961, acc.: 51.56%] [G loss: 0.788448]\n",
      "epoch:32 step:25214 [D loss: 0.752081, acc.: 35.16%] [G loss: 0.712508]\n",
      "epoch:32 step:25215 [D loss: 0.688808, acc.: 54.69%] [G loss: 0.757164]\n",
      "epoch:32 step:25216 [D loss: 0.674874, acc.: 50.00%] [G loss: 0.726329]\n",
      "epoch:32 step:25217 [D loss: 0.680959, acc.: 65.62%] [G loss: 0.718143]\n",
      "epoch:32 step:25218 [D loss: 0.680026, acc.: 56.25%] [G loss: 0.739586]\n",
      "epoch:32 step:25219 [D loss: 0.702110, acc.: 53.12%] [G loss: 0.720905]\n",
      "epoch:32 step:25220 [D loss: 0.725811, acc.: 49.22%] [G loss: 0.768771]\n",
      "epoch:32 step:25221 [D loss: 0.743929, acc.: 45.31%] [G loss: 0.721906]\n",
      "epoch:32 step:25222 [D loss: 0.710049, acc.: 48.44%] [G loss: 0.723435]\n",
      "epoch:32 step:25223 [D loss: 0.676980, acc.: 56.25%] [G loss: 0.724880]\n",
      "epoch:32 step:25224 [D loss: 0.682426, acc.: 55.47%] [G loss: 0.755255]\n",
      "epoch:32 step:25225 [D loss: 0.698952, acc.: 49.22%] [G loss: 0.738490]\n",
      "epoch:32 step:25226 [D loss: 0.729425, acc.: 46.88%] [G loss: 0.821106]\n",
      "epoch:32 step:25227 [D loss: 0.756312, acc.: 41.41%] [G loss: 0.705613]\n",
      "epoch:32 step:25228 [D loss: 0.691955, acc.: 48.44%] [G loss: 0.736410]\n",
      "epoch:32 step:25229 [D loss: 0.669576, acc.: 57.03%] [G loss: 0.733106]\n",
      "epoch:32 step:25230 [D loss: 0.720030, acc.: 42.97%] [G loss: 0.738752]\n",
      "epoch:32 step:25231 [D loss: 0.672677, acc.: 55.47%] [G loss: 0.729597]\n",
      "epoch:32 step:25232 [D loss: 0.678697, acc.: 58.59%] [G loss: 0.818753]\n",
      "epoch:32 step:25233 [D loss: 0.610440, acc.: 74.22%] [G loss: 0.811868]\n",
      "epoch:32 step:25234 [D loss: 0.712139, acc.: 49.22%] [G loss: 0.798984]\n",
      "epoch:32 step:25235 [D loss: 0.688399, acc.: 52.34%] [G loss: 0.809368]\n",
      "epoch:32 step:25236 [D loss: 0.707021, acc.: 44.53%] [G loss: 0.721393]\n",
      "epoch:32 step:25237 [D loss: 0.718226, acc.: 47.66%] [G loss: 0.721600]\n",
      "epoch:32 step:25238 [D loss: 0.714498, acc.: 48.44%] [G loss: 0.825790]\n",
      "epoch:32 step:25239 [D loss: 0.684127, acc.: 59.38%] [G loss: 0.840543]\n",
      "epoch:32 step:25240 [D loss: 0.689240, acc.: 49.22%] [G loss: 0.749045]\n",
      "epoch:32 step:25241 [D loss: 0.661997, acc.: 57.81%] [G loss: 0.744315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25242 [D loss: 0.657261, acc.: 65.62%] [G loss: 0.762376]\n",
      "epoch:32 step:25243 [D loss: 0.716417, acc.: 50.00%] [G loss: 0.746070]\n",
      "epoch:32 step:25244 [D loss: 0.686247, acc.: 54.69%] [G loss: 0.753721]\n",
      "epoch:32 step:25245 [D loss: 0.694955, acc.: 52.34%] [G loss: 0.843639]\n",
      "epoch:32 step:25246 [D loss: 0.701664, acc.: 60.94%] [G loss: 0.774270]\n",
      "epoch:32 step:25247 [D loss: 0.681749, acc.: 55.47%] [G loss: 0.746881]\n",
      "epoch:32 step:25248 [D loss: 0.685092, acc.: 56.25%] [G loss: 0.684900]\n",
      "epoch:32 step:25249 [D loss: 0.699293, acc.: 49.22%] [G loss: 0.746310]\n",
      "epoch:32 step:25250 [D loss: 0.713284, acc.: 51.56%] [G loss: 0.689753]\n",
      "epoch:32 step:25251 [D loss: 0.696862, acc.: 53.12%] [G loss: 0.802034]\n",
      "epoch:32 step:25252 [D loss: 0.657153, acc.: 61.72%] [G loss: 0.786316]\n",
      "epoch:32 step:25253 [D loss: 0.711780, acc.: 54.69%] [G loss: 0.771713]\n",
      "epoch:32 step:25254 [D loss: 0.605710, acc.: 76.56%] [G loss: 0.823532]\n",
      "epoch:32 step:25255 [D loss: 0.700922, acc.: 53.91%] [G loss: 0.772472]\n",
      "epoch:32 step:25256 [D loss: 0.757969, acc.: 34.38%] [G loss: 0.757070]\n",
      "epoch:32 step:25257 [D loss: 0.677472, acc.: 62.50%] [G loss: 0.756112]\n",
      "epoch:32 step:25258 [D loss: 0.712379, acc.: 46.09%] [G loss: 0.774779]\n",
      "epoch:32 step:25259 [D loss: 0.729451, acc.: 46.09%] [G loss: 0.688725]\n",
      "epoch:32 step:25260 [D loss: 0.713414, acc.: 50.78%] [G loss: 0.781005]\n",
      "epoch:32 step:25261 [D loss: 0.692912, acc.: 60.16%] [G loss: 0.750907]\n",
      "epoch:32 step:25262 [D loss: 0.672074, acc.: 57.81%] [G loss: 0.791105]\n",
      "epoch:32 step:25263 [D loss: 0.716225, acc.: 45.31%] [G loss: 0.756165]\n",
      "epoch:32 step:25264 [D loss: 0.673080, acc.: 60.94%] [G loss: 0.784292]\n",
      "epoch:32 step:25265 [D loss: 0.689905, acc.: 57.81%] [G loss: 0.783231]\n",
      "epoch:32 step:25266 [D loss: 0.680709, acc.: 58.59%] [G loss: 0.755552]\n",
      "epoch:32 step:25267 [D loss: 0.672108, acc.: 57.03%] [G loss: 0.846074]\n",
      "epoch:32 step:25268 [D loss: 0.709637, acc.: 49.22%] [G loss: 0.760142]\n",
      "epoch:32 step:25269 [D loss: 0.717923, acc.: 46.09%] [G loss: 0.716634]\n",
      "epoch:32 step:25270 [D loss: 0.641930, acc.: 65.62%] [G loss: 0.750238]\n",
      "epoch:32 step:25271 [D loss: 0.690271, acc.: 57.03%] [G loss: 0.764537]\n",
      "epoch:32 step:25272 [D loss: 0.661063, acc.: 57.03%] [G loss: 0.756370]\n",
      "epoch:32 step:25273 [D loss: 0.695887, acc.: 50.00%] [G loss: 0.747932]\n",
      "epoch:32 step:25274 [D loss: 0.690557, acc.: 57.81%] [G loss: 0.774147]\n",
      "epoch:32 step:25275 [D loss: 0.657856, acc.: 64.84%] [G loss: 0.804832]\n",
      "epoch:32 step:25276 [D loss: 0.700076, acc.: 50.78%] [G loss: 0.854175]\n",
      "epoch:32 step:25277 [D loss: 0.671034, acc.: 57.03%] [G loss: 0.802684]\n",
      "epoch:32 step:25278 [D loss: 0.659170, acc.: 64.06%] [G loss: 0.807529]\n",
      "epoch:32 step:25279 [D loss: 0.745498, acc.: 48.44%] [G loss: 0.722543]\n",
      "epoch:32 step:25280 [D loss: 0.677988, acc.: 57.03%] [G loss: 0.747923]\n",
      "epoch:32 step:25281 [D loss: 0.711832, acc.: 46.09%] [G loss: 0.759640]\n",
      "epoch:32 step:25282 [D loss: 0.659616, acc.: 60.94%] [G loss: 0.783284]\n",
      "epoch:32 step:25283 [D loss: 0.701760, acc.: 49.22%] [G loss: 0.737141]\n",
      "epoch:32 step:25284 [D loss: 0.710436, acc.: 53.12%] [G loss: 0.735882]\n",
      "epoch:32 step:25285 [D loss: 0.667816, acc.: 56.25%] [G loss: 0.729116]\n",
      "epoch:32 step:25286 [D loss: 0.647409, acc.: 72.66%] [G loss: 0.801625]\n",
      "epoch:32 step:25287 [D loss: 0.717568, acc.: 46.88%] [G loss: 0.724178]\n",
      "epoch:32 step:25288 [D loss: 0.674104, acc.: 59.38%] [G loss: 0.784478]\n",
      "epoch:32 step:25289 [D loss: 0.688908, acc.: 53.91%] [G loss: 0.744335]\n",
      "epoch:32 step:25290 [D loss: 0.667129, acc.: 60.94%] [G loss: 0.755277]\n",
      "epoch:32 step:25291 [D loss: 0.698371, acc.: 53.91%] [G loss: 0.789854]\n",
      "epoch:32 step:25292 [D loss: 0.755646, acc.: 45.31%] [G loss: 0.668015]\n",
      "epoch:32 step:25293 [D loss: 0.726317, acc.: 50.78%] [G loss: 0.705651]\n",
      "epoch:32 step:25294 [D loss: 0.679261, acc.: 56.25%] [G loss: 0.695541]\n",
      "epoch:32 step:25295 [D loss: 0.627313, acc.: 66.41%] [G loss: 0.754513]\n",
      "epoch:32 step:25296 [D loss: 0.680485, acc.: 59.38%] [G loss: 0.781010]\n",
      "epoch:32 step:25297 [D loss: 0.716113, acc.: 46.88%] [G loss: 0.741038]\n",
      "epoch:32 step:25298 [D loss: 0.682238, acc.: 52.34%] [G loss: 0.809949]\n",
      "epoch:32 step:25299 [D loss: 0.653572, acc.: 67.19%] [G loss: 0.687136]\n",
      "epoch:32 step:25300 [D loss: 0.667523, acc.: 61.72%] [G loss: 0.744728]\n",
      "epoch:32 step:25301 [D loss: 0.684700, acc.: 57.81%] [G loss: 0.716188]\n",
      "epoch:32 step:25302 [D loss: 0.671673, acc.: 51.56%] [G loss: 0.675683]\n",
      "epoch:32 step:25303 [D loss: 0.700465, acc.: 53.12%] [G loss: 0.737934]\n",
      "epoch:32 step:25304 [D loss: 0.683252, acc.: 57.03%] [G loss: 0.750866]\n",
      "epoch:32 step:25305 [D loss: 0.665460, acc.: 64.84%] [G loss: 0.805041]\n",
      "epoch:32 step:25306 [D loss: 0.665877, acc.: 61.72%] [G loss: 0.756751]\n",
      "epoch:32 step:25307 [D loss: 0.729779, acc.: 44.53%] [G loss: 0.719811]\n",
      "epoch:32 step:25308 [D loss: 0.699807, acc.: 53.12%] [G loss: 0.765131]\n",
      "epoch:32 step:25309 [D loss: 0.759539, acc.: 32.81%] [G loss: 0.684001]\n",
      "epoch:32 step:25310 [D loss: 0.689851, acc.: 55.47%] [G loss: 0.665791]\n",
      "epoch:32 step:25311 [D loss: 0.671102, acc.: 57.03%] [G loss: 0.751350]\n",
      "epoch:32 step:25312 [D loss: 0.667789, acc.: 59.38%] [G loss: 0.708346]\n",
      "epoch:32 step:25313 [D loss: 0.647086, acc.: 61.72%] [G loss: 0.729189]\n",
      "epoch:32 step:25314 [D loss: 0.723760, acc.: 49.22%] [G loss: 0.734616]\n",
      "epoch:32 step:25315 [D loss: 0.708647, acc.: 48.44%] [G loss: 0.720643]\n",
      "epoch:32 step:25316 [D loss: 0.693444, acc.: 51.56%] [G loss: 0.719234]\n",
      "epoch:32 step:25317 [D loss: 0.684345, acc.: 59.38%] [G loss: 0.778796]\n",
      "epoch:32 step:25318 [D loss: 0.642600, acc.: 66.41%] [G loss: 0.744069]\n",
      "epoch:32 step:25319 [D loss: 0.694178, acc.: 53.91%] [G loss: 0.671073]\n",
      "epoch:32 step:25320 [D loss: 0.717727, acc.: 43.75%] [G loss: 0.728115]\n",
      "epoch:32 step:25321 [D loss: 0.760915, acc.: 29.69%] [G loss: 0.663948]\n",
      "epoch:32 step:25322 [D loss: 0.670900, acc.: 57.03%] [G loss: 0.692123]\n",
      "epoch:32 step:25323 [D loss: 0.686040, acc.: 55.47%] [G loss: 0.756181]\n",
      "epoch:32 step:25324 [D loss: 0.721746, acc.: 46.88%] [G loss: 0.709692]\n",
      "epoch:32 step:25325 [D loss: 0.684980, acc.: 52.34%] [G loss: 0.811250]\n",
      "epoch:32 step:25326 [D loss: 0.689707, acc.: 57.03%] [G loss: 0.761572]\n",
      "epoch:32 step:25327 [D loss: 0.687746, acc.: 48.44%] [G loss: 0.770002]\n",
      "epoch:32 step:25328 [D loss: 0.720690, acc.: 50.00%] [G loss: 0.808178]\n",
      "epoch:32 step:25329 [D loss: 0.653325, acc.: 64.06%] [G loss: 0.746901]\n",
      "epoch:32 step:25330 [D loss: 0.685395, acc.: 53.91%] [G loss: 0.731359]\n",
      "epoch:32 step:25331 [D loss: 0.692561, acc.: 55.47%] [G loss: 0.745166]\n",
      "epoch:32 step:25332 [D loss: 0.678993, acc.: 54.69%] [G loss: 0.740116]\n",
      "epoch:32 step:25333 [D loss: 0.659949, acc.: 66.41%] [G loss: 0.837124]\n",
      "epoch:32 step:25334 [D loss: 0.668853, acc.: 61.72%] [G loss: 0.786656]\n",
      "epoch:32 step:25335 [D loss: 0.697808, acc.: 52.34%] [G loss: 0.817259]\n",
      "epoch:32 step:25336 [D loss: 0.651833, acc.: 64.06%] [G loss: 0.747157]\n",
      "epoch:32 step:25337 [D loss: 0.661706, acc.: 55.47%] [G loss: 0.753313]\n",
      "epoch:32 step:25338 [D loss: 0.665807, acc.: 62.50%] [G loss: 0.771686]\n",
      "epoch:32 step:25339 [D loss: 0.722950, acc.: 43.75%] [G loss: 0.814293]\n",
      "epoch:32 step:25340 [D loss: 0.669963, acc.: 52.34%] [G loss: 0.818496]\n",
      "epoch:32 step:25341 [D loss: 0.655652, acc.: 60.94%] [G loss: 0.764095]\n",
      "epoch:32 step:25342 [D loss: 0.707917, acc.: 50.00%] [G loss: 0.863275]\n",
      "epoch:32 step:25343 [D loss: 0.691127, acc.: 53.91%] [G loss: 0.747506]\n",
      "epoch:32 step:25344 [D loss: 0.664750, acc.: 58.59%] [G loss: 0.834167]\n",
      "epoch:32 step:25345 [D loss: 0.668396, acc.: 61.72%] [G loss: 0.800129]\n",
      "epoch:32 step:25346 [D loss: 0.708441, acc.: 49.22%] [G loss: 0.716555]\n",
      "epoch:32 step:25347 [D loss: 0.695950, acc.: 56.25%] [G loss: 0.757237]\n",
      "epoch:32 step:25348 [D loss: 0.618715, acc.: 67.97%] [G loss: 0.803104]\n",
      "epoch:32 step:25349 [D loss: 0.724645, acc.: 51.56%] [G loss: 0.763252]\n",
      "epoch:32 step:25350 [D loss: 0.650234, acc.: 65.62%] [G loss: 0.805653]\n",
      "epoch:32 step:25351 [D loss: 0.732083, acc.: 43.75%] [G loss: 0.722263]\n",
      "epoch:32 step:25352 [D loss: 0.636348, acc.: 64.84%] [G loss: 0.847269]\n",
      "epoch:32 step:25353 [D loss: 0.681906, acc.: 54.69%] [G loss: 0.722063]\n",
      "epoch:32 step:25354 [D loss: 0.658130, acc.: 60.94%] [G loss: 0.754228]\n",
      "epoch:32 step:25355 [D loss: 0.763272, acc.: 35.16%] [G loss: 0.731447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25356 [D loss: 0.722326, acc.: 43.75%] [G loss: 0.717473]\n",
      "epoch:32 step:25357 [D loss: 0.699986, acc.: 46.88%] [G loss: 0.743903]\n",
      "epoch:32 step:25358 [D loss: 0.673580, acc.: 56.25%] [G loss: 0.772699]\n",
      "epoch:32 step:25359 [D loss: 0.676286, acc.: 61.72%] [G loss: 0.777294]\n",
      "epoch:32 step:25360 [D loss: 0.673547, acc.: 55.47%] [G loss: 0.768959]\n",
      "epoch:32 step:25361 [D loss: 0.702854, acc.: 49.22%] [G loss: 0.727717]\n",
      "epoch:32 step:25362 [D loss: 0.690137, acc.: 51.56%] [G loss: 0.773394]\n",
      "epoch:32 step:25363 [D loss: 0.691065, acc.: 55.47%] [G loss: 0.799722]\n",
      "epoch:32 step:25364 [D loss: 0.634592, acc.: 67.19%] [G loss: 0.818755]\n",
      "epoch:32 step:25365 [D loss: 0.726319, acc.: 41.41%] [G loss: 0.771062]\n",
      "epoch:32 step:25366 [D loss: 0.658266, acc.: 58.59%] [G loss: 0.773448]\n",
      "epoch:32 step:25367 [D loss: 0.694552, acc.: 59.38%] [G loss: 0.746359]\n",
      "epoch:32 step:25368 [D loss: 0.695967, acc.: 49.22%] [G loss: 0.738726]\n",
      "epoch:32 step:25369 [D loss: 0.729759, acc.: 45.31%] [G loss: 0.747102]\n",
      "epoch:32 step:25370 [D loss: 0.683990, acc.: 58.59%] [G loss: 0.742643]\n",
      "epoch:32 step:25371 [D loss: 0.675248, acc.: 58.59%] [G loss: 0.856868]\n",
      "epoch:32 step:25372 [D loss: 0.726291, acc.: 45.31%] [G loss: 0.776473]\n",
      "epoch:32 step:25373 [D loss: 0.638915, acc.: 64.06%] [G loss: 0.786595]\n",
      "epoch:32 step:25374 [D loss: 0.741703, acc.: 41.41%] [G loss: 0.801124]\n",
      "epoch:32 step:25375 [D loss: 0.628755, acc.: 69.53%] [G loss: 0.840963]\n",
      "epoch:32 step:25376 [D loss: 0.691520, acc.: 53.12%] [G loss: 0.825294]\n",
      "epoch:32 step:25377 [D loss: 0.700878, acc.: 48.44%] [G loss: 0.840201]\n",
      "epoch:32 step:25378 [D loss: 0.589987, acc.: 81.25%] [G loss: 0.889294]\n",
      "epoch:32 step:25379 [D loss: 0.627685, acc.: 71.09%] [G loss: 0.830361]\n",
      "epoch:32 step:25380 [D loss: 0.682245, acc.: 48.44%] [G loss: 0.832629]\n",
      "epoch:32 step:25381 [D loss: 0.773776, acc.: 30.47%] [G loss: 0.754235]\n",
      "epoch:32 step:25382 [D loss: 0.659232, acc.: 61.72%] [G loss: 0.941782]\n",
      "epoch:32 step:25383 [D loss: 0.750743, acc.: 50.00%] [G loss: 0.751230]\n",
      "epoch:32 step:25384 [D loss: 0.689941, acc.: 53.12%] [G loss: 0.808655]\n",
      "epoch:32 step:25385 [D loss: 0.666229, acc.: 58.59%] [G loss: 0.784363]\n",
      "epoch:32 step:25386 [D loss: 0.663211, acc.: 60.16%] [G loss: 0.801088]\n",
      "epoch:32 step:25387 [D loss: 0.722210, acc.: 44.53%] [G loss: 0.714796]\n",
      "epoch:32 step:25388 [D loss: 0.629077, acc.: 67.97%] [G loss: 0.801960]\n",
      "epoch:32 step:25389 [D loss: 0.709868, acc.: 50.78%] [G loss: 0.740885]\n",
      "epoch:32 step:25390 [D loss: 0.701172, acc.: 52.34%] [G loss: 0.833295]\n",
      "epoch:32 step:25391 [D loss: 0.669538, acc.: 61.72%] [G loss: 0.824251]\n",
      "epoch:32 step:25392 [D loss: 0.739214, acc.: 39.84%] [G loss: 0.694330]\n",
      "epoch:32 step:25393 [D loss: 0.705643, acc.: 53.12%] [G loss: 0.757422]\n",
      "epoch:32 step:25394 [D loss: 0.666662, acc.: 57.81%] [G loss: 0.762317]\n",
      "epoch:32 step:25395 [D loss: 0.682219, acc.: 53.91%] [G loss: 0.740627]\n",
      "epoch:32 step:25396 [D loss: 0.676453, acc.: 62.50%] [G loss: 0.710804]\n",
      "epoch:32 step:25397 [D loss: 0.714695, acc.: 49.22%] [G loss: 0.780555]\n",
      "epoch:32 step:25398 [D loss: 0.676123, acc.: 54.69%] [G loss: 0.791521]\n",
      "epoch:32 step:25399 [D loss: 0.638888, acc.: 65.62%] [G loss: 0.778878]\n",
      "epoch:32 step:25400 [D loss: 0.697940, acc.: 50.78%] [G loss: 0.782693]\n",
      "epoch:32 step:25401 [D loss: 0.699546, acc.: 48.44%] [G loss: 0.774570]\n",
      "epoch:32 step:25402 [D loss: 0.653056, acc.: 61.72%] [G loss: 0.748820]\n",
      "epoch:32 step:25403 [D loss: 0.746739, acc.: 42.97%] [G loss: 0.691983]\n",
      "epoch:32 step:25404 [D loss: 0.745132, acc.: 46.09%] [G loss: 0.747127]\n",
      "epoch:32 step:25405 [D loss: 0.623925, acc.: 75.00%] [G loss: 0.797477]\n",
      "epoch:32 step:25406 [D loss: 0.717070, acc.: 46.88%] [G loss: 0.719614]\n",
      "epoch:32 step:25407 [D loss: 0.648389, acc.: 67.19%] [G loss: 0.729538]\n",
      "epoch:32 step:25408 [D loss: 0.661097, acc.: 60.16%] [G loss: 0.797832]\n",
      "epoch:32 step:25409 [D loss: 0.680725, acc.: 62.50%] [G loss: 0.760818]\n",
      "epoch:32 step:25410 [D loss: 0.644625, acc.: 66.41%] [G loss: 0.834285]\n",
      "epoch:32 step:25411 [D loss: 0.697225, acc.: 48.44%] [G loss: 0.777467]\n",
      "epoch:32 step:25412 [D loss: 0.711218, acc.: 47.66%] [G loss: 0.790271]\n",
      "epoch:32 step:25413 [D loss: 0.666518, acc.: 61.72%] [G loss: 0.798102]\n",
      "epoch:32 step:25414 [D loss: 0.694246, acc.: 51.56%] [G loss: 0.737470]\n",
      "epoch:32 step:25415 [D loss: 0.705199, acc.: 58.59%] [G loss: 0.839771]\n",
      "epoch:32 step:25416 [D loss: 0.690774, acc.: 57.03%] [G loss: 0.767698]\n",
      "epoch:32 step:25417 [D loss: 0.678369, acc.: 61.72%] [G loss: 0.801821]\n",
      "epoch:32 step:25418 [D loss: 0.663396, acc.: 61.72%] [G loss: 0.746554]\n",
      "epoch:32 step:25419 [D loss: 0.659042, acc.: 67.19%] [G loss: 0.725750]\n",
      "epoch:32 step:25420 [D loss: 0.764458, acc.: 36.72%] [G loss: 0.692188]\n",
      "epoch:32 step:25421 [D loss: 0.699944, acc.: 50.78%] [G loss: 0.705657]\n",
      "epoch:32 step:25422 [D loss: 0.677940, acc.: 53.12%] [G loss: 0.704961]\n",
      "epoch:32 step:25423 [D loss: 0.715014, acc.: 46.88%] [G loss: 0.747686]\n",
      "epoch:32 step:25424 [D loss: 0.661440, acc.: 60.16%] [G loss: 0.789502]\n",
      "epoch:32 step:25425 [D loss: 0.690481, acc.: 46.88%] [G loss: 0.842040]\n",
      "epoch:32 step:25426 [D loss: 0.683231, acc.: 57.81%] [G loss: 0.811618]\n",
      "epoch:32 step:25427 [D loss: 0.662982, acc.: 56.25%] [G loss: 0.766665]\n",
      "epoch:32 step:25428 [D loss: 0.694342, acc.: 56.25%] [G loss: 0.780544]\n",
      "epoch:32 step:25429 [D loss: 0.682861, acc.: 55.47%] [G loss: 0.761129]\n",
      "epoch:32 step:25430 [D loss: 0.679630, acc.: 55.47%] [G loss: 0.707889]\n",
      "epoch:32 step:25431 [D loss: 0.709876, acc.: 53.91%] [G loss: 0.790272]\n",
      "epoch:32 step:25432 [D loss: 0.663495, acc.: 60.16%] [G loss: 0.764262]\n",
      "epoch:32 step:25433 [D loss: 0.703194, acc.: 57.81%] [G loss: 0.705353]\n",
      "epoch:32 step:25434 [D loss: 0.697758, acc.: 53.91%] [G loss: 0.724348]\n",
      "epoch:32 step:25435 [D loss: 0.641647, acc.: 65.62%] [G loss: 0.836842]\n",
      "epoch:32 step:25436 [D loss: 0.627388, acc.: 67.97%] [G loss: 0.753484]\n",
      "epoch:32 step:25437 [D loss: 0.721324, acc.: 47.66%] [G loss: 0.711482]\n",
      "epoch:32 step:25438 [D loss: 0.684617, acc.: 58.59%] [G loss: 0.814085]\n",
      "epoch:32 step:25439 [D loss: 0.720190, acc.: 42.97%] [G loss: 0.766709]\n",
      "epoch:32 step:25440 [D loss: 0.702587, acc.: 51.56%] [G loss: 0.730953]\n",
      "epoch:32 step:25441 [D loss: 0.729972, acc.: 46.09%] [G loss: 0.745659]\n",
      "epoch:32 step:25442 [D loss: 0.705609, acc.: 52.34%] [G loss: 0.772464]\n",
      "epoch:32 step:25443 [D loss: 0.701607, acc.: 52.34%] [G loss: 0.855010]\n",
      "epoch:32 step:25444 [D loss: 0.652514, acc.: 67.97%] [G loss: 0.824262]\n",
      "epoch:32 step:25445 [D loss: 0.692812, acc.: 47.66%] [G loss: 0.786009]\n",
      "epoch:32 step:25446 [D loss: 0.665211, acc.: 60.16%] [G loss: 0.856684]\n",
      "epoch:32 step:25447 [D loss: 0.690177, acc.: 50.78%] [G loss: 0.843180]\n",
      "epoch:32 step:25448 [D loss: 0.712385, acc.: 50.00%] [G loss: 0.809548]\n",
      "epoch:32 step:25449 [D loss: 0.685009, acc.: 49.22%] [G loss: 0.747005]\n",
      "epoch:32 step:25450 [D loss: 0.674242, acc.: 57.03%] [G loss: 0.775641]\n",
      "epoch:32 step:25451 [D loss: 0.729448, acc.: 50.78%] [G loss: 0.754129]\n",
      "epoch:32 step:25452 [D loss: 0.694433, acc.: 53.12%] [G loss: 0.780445]\n",
      "epoch:32 step:25453 [D loss: 0.673162, acc.: 53.91%] [G loss: 0.769047]\n",
      "epoch:32 step:25454 [D loss: 0.672762, acc.: 53.91%] [G loss: 0.803866]\n",
      "epoch:32 step:25455 [D loss: 0.692745, acc.: 58.59%] [G loss: 0.772075]\n",
      "epoch:32 step:25456 [D loss: 0.651504, acc.: 66.41%] [G loss: 0.858377]\n",
      "epoch:32 step:25457 [D loss: 0.663998, acc.: 62.50%] [G loss: 0.834268]\n",
      "epoch:32 step:25458 [D loss: 0.633591, acc.: 67.97%] [G loss: 0.810618]\n",
      "epoch:32 step:25459 [D loss: 0.688569, acc.: 51.56%] [G loss: 0.750598]\n",
      "epoch:32 step:25460 [D loss: 0.661084, acc.: 63.28%] [G loss: 0.769536]\n",
      "epoch:32 step:25461 [D loss: 0.702675, acc.: 50.00%] [G loss: 0.808499]\n",
      "epoch:32 step:25462 [D loss: 0.689306, acc.: 53.12%] [G loss: 0.767075]\n",
      "epoch:32 step:25463 [D loss: 0.710627, acc.: 48.44%] [G loss: 0.746776]\n",
      "epoch:32 step:25464 [D loss: 0.721719, acc.: 47.66%] [G loss: 0.743452]\n",
      "epoch:32 step:25465 [D loss: 0.782634, acc.: 35.16%] [G loss: 0.738613]\n",
      "epoch:32 step:25466 [D loss: 0.694954, acc.: 50.00%] [G loss: 0.775779]\n",
      "epoch:32 step:25467 [D loss: 0.681427, acc.: 58.59%] [G loss: 0.771590]\n",
      "epoch:32 step:25468 [D loss: 0.712283, acc.: 42.97%] [G loss: 0.714140]\n",
      "epoch:32 step:25469 [D loss: 0.657792, acc.: 60.16%] [G loss: 0.815246]\n",
      "epoch:32 step:25470 [D loss: 0.625978, acc.: 68.75%] [G loss: 0.776005]\n",
      "epoch:32 step:25471 [D loss: 0.637249, acc.: 64.84%] [G loss: 0.773194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25472 [D loss: 0.679691, acc.: 60.16%] [G loss: 0.745443]\n",
      "epoch:32 step:25473 [D loss: 0.647802, acc.: 65.62%] [G loss: 0.873577]\n",
      "epoch:32 step:25474 [D loss: 0.711302, acc.: 46.09%] [G loss: 0.707562]\n",
      "epoch:32 step:25475 [D loss: 0.693005, acc.: 54.69%] [G loss: 0.707073]\n",
      "epoch:32 step:25476 [D loss: 0.699362, acc.: 53.12%] [G loss: 0.698513]\n",
      "epoch:32 step:25477 [D loss: 0.666784, acc.: 60.94%] [G loss: 0.774273]\n",
      "epoch:32 step:25478 [D loss: 0.672130, acc.: 56.25%] [G loss: 0.780098]\n",
      "epoch:32 step:25479 [D loss: 0.637470, acc.: 68.75%] [G loss: 0.744737]\n",
      "epoch:32 step:25480 [D loss: 0.686995, acc.: 55.47%] [G loss: 0.813735]\n",
      "epoch:32 step:25481 [D loss: 0.658453, acc.: 59.38%] [G loss: 0.797768]\n",
      "epoch:32 step:25482 [D loss: 0.647827, acc.: 67.19%] [G loss: 0.776846]\n",
      "epoch:32 step:25483 [D loss: 0.690272, acc.: 53.91%] [G loss: 0.769687]\n",
      "epoch:32 step:25484 [D loss: 0.678723, acc.: 54.69%] [G loss: 0.747825]\n",
      "epoch:32 step:25485 [D loss: 0.657037, acc.: 60.16%] [G loss: 0.773096]\n",
      "epoch:32 step:25486 [D loss: 0.661677, acc.: 64.06%] [G loss: 0.776810]\n",
      "epoch:32 step:25487 [D loss: 0.668876, acc.: 57.81%] [G loss: 0.796236]\n",
      "epoch:32 step:25488 [D loss: 0.696872, acc.: 51.56%] [G loss: 0.706570]\n",
      "epoch:32 step:25489 [D loss: 0.694049, acc.: 54.69%] [G loss: 0.837376]\n",
      "epoch:32 step:25490 [D loss: 0.684695, acc.: 57.81%] [G loss: 0.736721]\n",
      "epoch:32 step:25491 [D loss: 0.656607, acc.: 61.72%] [G loss: 0.763265]\n",
      "epoch:32 step:25492 [D loss: 0.692399, acc.: 58.59%] [G loss: 0.676939]\n",
      "epoch:32 step:25493 [D loss: 0.700183, acc.: 53.12%] [G loss: 0.749036]\n",
      "epoch:32 step:25494 [D loss: 0.728532, acc.: 41.41%] [G loss: 0.771396]\n",
      "epoch:32 step:25495 [D loss: 0.687218, acc.: 58.59%] [G loss: 0.788755]\n",
      "epoch:32 step:25496 [D loss: 0.691795, acc.: 53.12%] [G loss: 0.795899]\n",
      "epoch:32 step:25497 [D loss: 0.725611, acc.: 42.97%] [G loss: 0.833512]\n",
      "epoch:32 step:25498 [D loss: 0.708661, acc.: 54.69%] [G loss: 0.770605]\n",
      "epoch:32 step:25499 [D loss: 0.660275, acc.: 61.72%] [G loss: 0.790683]\n",
      "epoch:32 step:25500 [D loss: 0.693220, acc.: 53.91%] [G loss: 0.763131]\n",
      "epoch:32 step:25501 [D loss: 0.711589, acc.: 52.34%] [G loss: 0.772856]\n",
      "epoch:32 step:25502 [D loss: 0.650635, acc.: 60.16%] [G loss: 0.752114]\n",
      "epoch:32 step:25503 [D loss: 0.664644, acc.: 54.69%] [G loss: 0.749481]\n",
      "epoch:32 step:25504 [D loss: 0.753585, acc.: 36.72%] [G loss: 0.699093]\n",
      "epoch:32 step:25505 [D loss: 0.654214, acc.: 65.62%] [G loss: 0.749806]\n",
      "epoch:32 step:25506 [D loss: 0.716706, acc.: 43.75%] [G loss: 0.753323]\n",
      "epoch:32 step:25507 [D loss: 0.693479, acc.: 54.69%] [G loss: 0.736487]\n",
      "epoch:32 step:25508 [D loss: 0.657468, acc.: 64.06%] [G loss: 0.778303]\n",
      "epoch:32 step:25509 [D loss: 0.695448, acc.: 54.69%] [G loss: 0.741965]\n",
      "epoch:32 step:25510 [D loss: 0.636613, acc.: 71.09%] [G loss: 0.726440]\n",
      "epoch:32 step:25511 [D loss: 0.725015, acc.: 46.88%] [G loss: 0.779271]\n",
      "epoch:32 step:25512 [D loss: 0.677296, acc.: 57.03%] [G loss: 0.758806]\n",
      "epoch:32 step:25513 [D loss: 0.671995, acc.: 59.38%] [G loss: 0.821342]\n",
      "epoch:32 step:25514 [D loss: 0.736396, acc.: 45.31%] [G loss: 0.796513]\n",
      "epoch:32 step:25515 [D loss: 0.676349, acc.: 56.25%] [G loss: 0.792560]\n",
      "epoch:32 step:25516 [D loss: 0.707770, acc.: 51.56%] [G loss: 0.828823]\n",
      "epoch:32 step:25517 [D loss: 0.647898, acc.: 71.09%] [G loss: 0.789169]\n",
      "epoch:32 step:25518 [D loss: 0.724231, acc.: 43.75%] [G loss: 0.781336]\n",
      "epoch:32 step:25519 [D loss: 0.714972, acc.: 47.66%] [G loss: 0.744975]\n",
      "epoch:32 step:25520 [D loss: 0.713865, acc.: 52.34%] [G loss: 0.760150]\n",
      "epoch:32 step:25521 [D loss: 0.660791, acc.: 65.62%] [G loss: 0.821739]\n",
      "epoch:32 step:25522 [D loss: 0.676419, acc.: 54.69%] [G loss: 0.765799]\n",
      "epoch:32 step:25523 [D loss: 0.670748, acc.: 59.38%] [G loss: 0.779486]\n",
      "epoch:32 step:25524 [D loss: 0.730391, acc.: 45.31%] [G loss: 0.798464]\n",
      "epoch:32 step:25525 [D loss: 0.680820, acc.: 57.81%] [G loss: 0.810510]\n",
      "epoch:32 step:25526 [D loss: 0.660764, acc.: 59.38%] [G loss: 0.782096]\n",
      "epoch:32 step:25527 [D loss: 0.698723, acc.: 55.47%] [G loss: 0.814554]\n",
      "epoch:32 step:25528 [D loss: 0.737043, acc.: 41.41%] [G loss: 0.789997]\n",
      "epoch:32 step:25529 [D loss: 0.729908, acc.: 46.88%] [G loss: 0.768961]\n",
      "epoch:32 step:25530 [D loss: 0.679549, acc.: 58.59%] [G loss: 0.724123]\n",
      "epoch:32 step:25531 [D loss: 0.677654, acc.: 60.94%] [G loss: 0.724257]\n",
      "epoch:32 step:25532 [D loss: 0.726455, acc.: 46.88%] [G loss: 0.772958]\n",
      "epoch:32 step:25533 [D loss: 0.706126, acc.: 51.56%] [G loss: 0.723136]\n",
      "epoch:32 step:25534 [D loss: 0.688207, acc.: 54.69%] [G loss: 0.765706]\n",
      "epoch:32 step:25535 [D loss: 0.717924, acc.: 43.75%] [G loss: 0.716915]\n",
      "epoch:32 step:25536 [D loss: 0.657667, acc.: 54.69%] [G loss: 0.899870]\n",
      "epoch:32 step:25537 [D loss: 0.679196, acc.: 53.12%] [G loss: 0.829829]\n",
      "epoch:32 step:25538 [D loss: 0.748137, acc.: 44.53%] [G loss: 0.719163]\n",
      "epoch:32 step:25539 [D loss: 0.704506, acc.: 48.44%] [G loss: 0.720556]\n",
      "epoch:32 step:25540 [D loss: 0.688871, acc.: 53.91%] [G loss: 0.830597]\n",
      "epoch:32 step:25541 [D loss: 0.655715, acc.: 63.28%] [G loss: 0.791324]\n",
      "epoch:32 step:25542 [D loss: 0.743487, acc.: 39.84%] [G loss: 0.652762]\n",
      "epoch:32 step:25543 [D loss: 0.688512, acc.: 50.78%] [G loss: 0.839305]\n",
      "epoch:32 step:25544 [D loss: 0.716570, acc.: 43.75%] [G loss: 0.810268]\n",
      "epoch:32 step:25545 [D loss: 0.686492, acc.: 57.03%] [G loss: 0.754534]\n",
      "epoch:32 step:25546 [D loss: 0.702327, acc.: 60.94%] [G loss: 0.763188]\n",
      "epoch:32 step:25547 [D loss: 0.737658, acc.: 40.62%] [G loss: 0.723106]\n",
      "epoch:32 step:25548 [D loss: 0.703204, acc.: 52.34%] [G loss: 0.854598]\n",
      "epoch:32 step:25549 [D loss: 0.674871, acc.: 57.03%] [G loss: 0.778450]\n",
      "epoch:32 step:25550 [D loss: 0.703329, acc.: 47.66%] [G loss: 0.739516]\n",
      "epoch:32 step:25551 [D loss: 0.666701, acc.: 63.28%] [G loss: 0.774438]\n",
      "epoch:32 step:25552 [D loss: 0.695450, acc.: 53.12%] [G loss: 0.765181]\n",
      "epoch:32 step:25553 [D loss: 0.697101, acc.: 53.91%] [G loss: 0.797109]\n",
      "epoch:32 step:25554 [D loss: 0.655052, acc.: 66.41%] [G loss: 0.773729]\n",
      "epoch:32 step:25555 [D loss: 0.685539, acc.: 58.59%] [G loss: 0.726868]\n",
      "epoch:32 step:25556 [D loss: 0.679343, acc.: 53.12%] [G loss: 0.732526]\n",
      "epoch:32 step:25557 [D loss: 0.696650, acc.: 57.81%] [G loss: 0.790005]\n",
      "epoch:32 step:25558 [D loss: 0.670263, acc.: 60.16%] [G loss: 0.855788]\n",
      "epoch:32 step:25559 [D loss: 0.718002, acc.: 48.44%] [G loss: 0.791938]\n",
      "epoch:32 step:25560 [D loss: 0.683339, acc.: 55.47%] [G loss: 0.762246]\n",
      "epoch:32 step:25561 [D loss: 0.722425, acc.: 42.19%] [G loss: 0.736942]\n",
      "epoch:32 step:25562 [D loss: 0.694123, acc.: 50.78%] [G loss: 0.817641]\n",
      "epoch:32 step:25563 [D loss: 0.707968, acc.: 48.44%] [G loss: 0.747976]\n",
      "epoch:32 step:25564 [D loss: 0.730010, acc.: 39.06%] [G loss: 0.708362]\n",
      "epoch:32 step:25565 [D loss: 0.695345, acc.: 51.56%] [G loss: 0.751859]\n",
      "epoch:32 step:25566 [D loss: 0.729676, acc.: 45.31%] [G loss: 0.708153]\n",
      "epoch:32 step:25567 [D loss: 0.675116, acc.: 58.59%] [G loss: 0.790540]\n",
      "epoch:32 step:25568 [D loss: 0.642128, acc.: 67.97%] [G loss: 0.752093]\n",
      "epoch:32 step:25569 [D loss: 0.659216, acc.: 61.72%] [G loss: 0.729058]\n",
      "epoch:32 step:25570 [D loss: 0.716117, acc.: 45.31%] [G loss: 0.672201]\n",
      "epoch:32 step:25571 [D loss: 0.700864, acc.: 51.56%] [G loss: 0.732283]\n",
      "epoch:32 step:25572 [D loss: 0.699610, acc.: 57.03%] [G loss: 0.827008]\n",
      "epoch:32 step:25573 [D loss: 0.717897, acc.: 50.00%] [G loss: 0.772572]\n",
      "epoch:32 step:25574 [D loss: 0.647763, acc.: 64.06%] [G loss: 0.736702]\n",
      "epoch:32 step:25575 [D loss: 0.707934, acc.: 50.00%] [G loss: 0.740277]\n",
      "epoch:32 step:25576 [D loss: 0.688939, acc.: 57.81%] [G loss: 0.736305]\n",
      "epoch:32 step:25577 [D loss: 0.658657, acc.: 62.50%] [G loss: 0.707856]\n",
      "epoch:32 step:25578 [D loss: 0.676267, acc.: 60.94%] [G loss: 0.743365]\n",
      "epoch:32 step:25579 [D loss: 0.614470, acc.: 70.31%] [G loss: 0.791930]\n",
      "epoch:32 step:25580 [D loss: 0.710761, acc.: 53.91%] [G loss: 0.767806]\n",
      "epoch:32 step:25581 [D loss: 0.655020, acc.: 64.84%] [G loss: 0.809899]\n",
      "epoch:32 step:25582 [D loss: 0.695575, acc.: 53.12%] [G loss: 0.772232]\n",
      "epoch:32 step:25583 [D loss: 0.657960, acc.: 64.06%] [G loss: 0.791104]\n",
      "epoch:32 step:25584 [D loss: 0.695342, acc.: 53.12%] [G loss: 0.788330]\n",
      "epoch:32 step:25585 [D loss: 0.662090, acc.: 57.03%] [G loss: 0.838292]\n",
      "epoch:32 step:25586 [D loss: 0.700889, acc.: 57.03%] [G loss: 0.801725]\n",
      "epoch:32 step:25587 [D loss: 0.651852, acc.: 62.50%] [G loss: 0.745764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25588 [D loss: 0.660873, acc.: 62.50%] [G loss: 0.711937]\n",
      "epoch:32 step:25589 [D loss: 0.703598, acc.: 47.66%] [G loss: 0.820243]\n",
      "epoch:32 step:25590 [D loss: 0.669237, acc.: 60.94%] [G loss: 0.808878]\n",
      "epoch:32 step:25591 [D loss: 0.713248, acc.: 46.88%] [G loss: 0.836044]\n",
      "epoch:32 step:25592 [D loss: 0.722531, acc.: 44.53%] [G loss: 0.704928]\n",
      "epoch:32 step:25593 [D loss: 0.704608, acc.: 49.22%] [G loss: 0.736516]\n",
      "epoch:32 step:25594 [D loss: 0.657623, acc.: 64.06%] [G loss: 0.792992]\n",
      "epoch:32 step:25595 [D loss: 0.739458, acc.: 38.28%] [G loss: 0.792355]\n",
      "epoch:32 step:25596 [D loss: 0.739346, acc.: 39.84%] [G loss: 0.723250]\n",
      "epoch:32 step:25597 [D loss: 0.673018, acc.: 58.59%] [G loss: 0.773694]\n",
      "epoch:32 step:25598 [D loss: 0.722614, acc.: 48.44%] [G loss: 0.731496]\n",
      "epoch:32 step:25599 [D loss: 0.708376, acc.: 46.88%] [G loss: 0.703482]\n",
      "epoch:32 step:25600 [D loss: 0.649156, acc.: 67.19%] [G loss: 0.782557]\n",
      "epoch:32 step:25601 [D loss: 0.676609, acc.: 55.47%] [G loss: 0.770896]\n",
      "epoch:32 step:25602 [D loss: 0.668551, acc.: 64.06%] [G loss: 0.797789]\n",
      "epoch:32 step:25603 [D loss: 0.669432, acc.: 61.72%] [G loss: 0.757319]\n",
      "epoch:32 step:25604 [D loss: 0.752555, acc.: 32.03%] [G loss: 0.822225]\n",
      "epoch:32 step:25605 [D loss: 0.750956, acc.: 38.28%] [G loss: 0.795825]\n",
      "epoch:32 step:25606 [D loss: 0.726388, acc.: 50.78%] [G loss: 0.737479]\n",
      "epoch:32 step:25607 [D loss: 0.678691, acc.: 59.38%] [G loss: 0.757650]\n",
      "epoch:32 step:25608 [D loss: 0.687832, acc.: 54.69%] [G loss: 0.776841]\n",
      "epoch:32 step:25609 [D loss: 0.704737, acc.: 43.75%] [G loss: 0.789274]\n",
      "epoch:32 step:25610 [D loss: 0.667104, acc.: 62.50%] [G loss: 0.814439]\n",
      "epoch:32 step:25611 [D loss: 0.700353, acc.: 50.00%] [G loss: 0.775684]\n",
      "epoch:32 step:25612 [D loss: 0.723418, acc.: 46.09%] [G loss: 0.777426]\n",
      "epoch:32 step:25613 [D loss: 0.655236, acc.: 63.28%] [G loss: 0.768956]\n",
      "epoch:32 step:25614 [D loss: 0.745542, acc.: 44.53%] [G loss: 0.762679]\n",
      "epoch:32 step:25615 [D loss: 0.691548, acc.: 56.25%] [G loss: 0.759485]\n",
      "epoch:32 step:25616 [D loss: 0.673996, acc.: 55.47%] [G loss: 0.823446]\n",
      "epoch:32 step:25617 [D loss: 0.687625, acc.: 57.81%] [G loss: 0.766929]\n",
      "epoch:32 step:25618 [D loss: 0.710231, acc.: 46.88%] [G loss: 0.749772]\n",
      "epoch:32 step:25619 [D loss: 0.666688, acc.: 52.34%] [G loss: 0.761783]\n",
      "epoch:32 step:25620 [D loss: 0.615382, acc.: 75.00%] [G loss: 0.770225]\n",
      "epoch:32 step:25621 [D loss: 0.696437, acc.: 46.09%] [G loss: 0.830510]\n",
      "epoch:32 step:25622 [D loss: 0.696097, acc.: 57.03%] [G loss: 0.840943]\n",
      "epoch:32 step:25623 [D loss: 0.686354, acc.: 52.34%] [G loss: 0.847740]\n",
      "epoch:32 step:25624 [D loss: 0.657601, acc.: 67.19%] [G loss: 0.856011]\n",
      "epoch:32 step:25625 [D loss: 0.710402, acc.: 53.12%] [G loss: 0.747904]\n",
      "epoch:32 step:25626 [D loss: 0.740817, acc.: 41.41%] [G loss: 0.708683]\n",
      "epoch:32 step:25627 [D loss: 0.702182, acc.: 49.22%] [G loss: 0.786808]\n",
      "epoch:32 step:25628 [D loss: 0.718162, acc.: 51.56%] [G loss: 0.760057]\n",
      "epoch:32 step:25629 [D loss: 0.678247, acc.: 58.59%] [G loss: 0.860509]\n",
      "epoch:32 step:25630 [D loss: 0.718541, acc.: 41.41%] [G loss: 0.803862]\n",
      "epoch:32 step:25631 [D loss: 0.671135, acc.: 57.03%] [G loss: 0.834465]\n",
      "epoch:32 step:25632 [D loss: 0.684552, acc.: 53.91%] [G loss: 0.745377]\n",
      "epoch:32 step:25633 [D loss: 0.688356, acc.: 57.81%] [G loss: 0.684921]\n",
      "epoch:32 step:25634 [D loss: 0.719664, acc.: 48.44%] [G loss: 0.787838]\n",
      "epoch:32 step:25635 [D loss: 0.711292, acc.: 46.88%] [G loss: 0.789016]\n",
      "epoch:32 step:25636 [D loss: 0.675786, acc.: 53.91%] [G loss: 0.794612]\n",
      "epoch:32 step:25637 [D loss: 0.653655, acc.: 64.06%] [G loss: 0.770987]\n",
      "epoch:32 step:25638 [D loss: 0.717732, acc.: 48.44%] [G loss: 0.762195]\n",
      "epoch:32 step:25639 [D loss: 0.765741, acc.: 35.16%] [G loss: 0.736647]\n",
      "epoch:32 step:25640 [D loss: 0.664349, acc.: 57.81%] [G loss: 0.773268]\n",
      "epoch:32 step:25641 [D loss: 0.730867, acc.: 47.66%] [G loss: 0.797579]\n",
      "epoch:32 step:25642 [D loss: 0.702282, acc.: 46.88%] [G loss: 0.793169]\n",
      "epoch:32 step:25643 [D loss: 0.660433, acc.: 60.94%] [G loss: 0.751413]\n",
      "epoch:32 step:25644 [D loss: 0.679509, acc.: 55.47%] [G loss: 0.724295]\n",
      "epoch:32 step:25645 [D loss: 0.699089, acc.: 47.66%] [G loss: 0.768150]\n",
      "epoch:32 step:25646 [D loss: 0.648741, acc.: 65.62%] [G loss: 0.772592]\n",
      "epoch:32 step:25647 [D loss: 0.686103, acc.: 56.25%] [G loss: 0.710797]\n",
      "epoch:32 step:25648 [D loss: 0.734570, acc.: 42.19%] [G loss: 0.738096]\n",
      "epoch:32 step:25649 [D loss: 0.694400, acc.: 47.66%] [G loss: 0.821200]\n",
      "epoch:32 step:25650 [D loss: 0.703641, acc.: 55.47%] [G loss: 0.842889]\n",
      "epoch:32 step:25651 [D loss: 0.751626, acc.: 36.72%] [G loss: 0.666482]\n",
      "epoch:32 step:25652 [D loss: 0.672625, acc.: 58.59%] [G loss: 0.892349]\n",
      "epoch:32 step:25653 [D loss: 0.588794, acc.: 76.56%] [G loss: 0.870970]\n",
      "epoch:32 step:25654 [D loss: 0.698303, acc.: 53.12%] [G loss: 0.780452]\n",
      "epoch:32 step:25655 [D loss: 0.702256, acc.: 55.47%] [G loss: 0.727888]\n",
      "epoch:32 step:25656 [D loss: 0.626771, acc.: 67.19%] [G loss: 0.816280]\n",
      "epoch:32 step:25657 [D loss: 0.734650, acc.: 48.44%] [G loss: 0.732425]\n",
      "epoch:32 step:25658 [D loss: 0.661337, acc.: 59.38%] [G loss: 0.850609]\n",
      "epoch:32 step:25659 [D loss: 0.662112, acc.: 60.94%] [G loss: 0.813271]\n",
      "epoch:32 step:25660 [D loss: 0.694687, acc.: 47.66%] [G loss: 0.728548]\n",
      "epoch:32 step:25661 [D loss: 0.671872, acc.: 55.47%] [G loss: 0.777372]\n",
      "epoch:32 step:25662 [D loss: 0.740268, acc.: 42.19%] [G loss: 0.753301]\n",
      "epoch:32 step:25663 [D loss: 0.741528, acc.: 39.84%] [G loss: 0.687878]\n",
      "epoch:32 step:25664 [D loss: 0.674216, acc.: 63.28%] [G loss: 0.702540]\n",
      "epoch:32 step:25665 [D loss: 0.709343, acc.: 46.88%] [G loss: 0.790276]\n",
      "epoch:32 step:25666 [D loss: 0.709495, acc.: 49.22%] [G loss: 0.727315]\n",
      "epoch:32 step:25667 [D loss: 0.751266, acc.: 38.28%] [G loss: 0.720274]\n",
      "epoch:32 step:25668 [D loss: 0.695087, acc.: 53.12%] [G loss: 0.769256]\n",
      "epoch:32 step:25669 [D loss: 0.683034, acc.: 53.12%] [G loss: 0.696045]\n",
      "epoch:32 step:25670 [D loss: 0.718013, acc.: 50.00%] [G loss: 0.827384]\n",
      "epoch:32 step:25671 [D loss: 0.668549, acc.: 59.38%] [G loss: 0.772064]\n",
      "epoch:32 step:25672 [D loss: 0.718111, acc.: 42.19%] [G loss: 0.857662]\n",
      "epoch:32 step:25673 [D loss: 0.723243, acc.: 42.97%] [G loss: 0.784548]\n",
      "epoch:32 step:25674 [D loss: 0.677558, acc.: 53.91%] [G loss: 0.805277]\n",
      "epoch:32 step:25675 [D loss: 0.726241, acc.: 45.31%] [G loss: 0.762359]\n",
      "epoch:32 step:25676 [D loss: 0.734061, acc.: 45.31%] [G loss: 0.763943]\n",
      "epoch:32 step:25677 [D loss: 0.655373, acc.: 64.06%] [G loss: 0.752951]\n",
      "epoch:32 step:25678 [D loss: 0.697306, acc.: 50.00%] [G loss: 0.774677]\n",
      "epoch:32 step:25679 [D loss: 0.679271, acc.: 58.59%] [G loss: 0.763696]\n",
      "epoch:32 step:25680 [D loss: 0.709077, acc.: 50.00%] [G loss: 0.781296]\n",
      "epoch:32 step:25681 [D loss: 0.666172, acc.: 58.59%] [G loss: 0.764752]\n",
      "epoch:32 step:25682 [D loss: 0.668974, acc.: 59.38%] [G loss: 0.807842]\n",
      "epoch:32 step:25683 [D loss: 0.664361, acc.: 65.62%] [G loss: 0.806799]\n",
      "epoch:32 step:25684 [D loss: 0.752668, acc.: 38.28%] [G loss: 0.729256]\n",
      "epoch:32 step:25685 [D loss: 0.706049, acc.: 49.22%] [G loss: 0.725918]\n",
      "epoch:32 step:25686 [D loss: 0.695049, acc.: 53.12%] [G loss: 0.699286]\n",
      "epoch:32 step:25687 [D loss: 0.694071, acc.: 50.00%] [G loss: 0.833493]\n",
      "epoch:32 step:25688 [D loss: 0.660520, acc.: 64.84%] [G loss: 0.767668]\n",
      "epoch:32 step:25689 [D loss: 0.717833, acc.: 48.44%] [G loss: 0.791133]\n",
      "epoch:32 step:25690 [D loss: 0.684372, acc.: 52.34%] [G loss: 0.777348]\n",
      "epoch:32 step:25691 [D loss: 0.669097, acc.: 53.91%] [G loss: 0.859316]\n",
      "epoch:32 step:25692 [D loss: 0.664318, acc.: 56.25%] [G loss: 0.768114]\n",
      "epoch:32 step:25693 [D loss: 0.731463, acc.: 45.31%] [G loss: 0.764232]\n",
      "epoch:32 step:25694 [D loss: 0.691073, acc.: 50.00%] [G loss: 0.700991]\n",
      "epoch:32 step:25695 [D loss: 0.697614, acc.: 50.78%] [G loss: 0.733306]\n",
      "epoch:32 step:25696 [D loss: 0.697297, acc.: 53.12%] [G loss: 0.732572]\n",
      "epoch:32 step:25697 [D loss: 0.735128, acc.: 42.97%] [G loss: 0.712655]\n",
      "epoch:32 step:25698 [D loss: 0.678506, acc.: 54.69%] [G loss: 0.696176]\n",
      "epoch:32 step:25699 [D loss: 0.679401, acc.: 53.91%] [G loss: 0.736046]\n",
      "epoch:32 step:25700 [D loss: 0.751288, acc.: 38.28%] [G loss: 0.757754]\n",
      "epoch:32 step:25701 [D loss: 0.651722, acc.: 60.94%] [G loss: 0.727318]\n",
      "epoch:32 step:25702 [D loss: 0.711100, acc.: 41.41%] [G loss: 0.799462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25703 [D loss: 0.675304, acc.: 58.59%] [G loss: 0.859288]\n",
      "epoch:32 step:25704 [D loss: 0.692679, acc.: 52.34%] [G loss: 0.776846]\n",
      "epoch:32 step:25705 [D loss: 0.664085, acc.: 60.94%] [G loss: 0.879575]\n",
      "epoch:32 step:25706 [D loss: 0.666143, acc.: 64.84%] [G loss: 0.811889]\n",
      "epoch:32 step:25707 [D loss: 0.724294, acc.: 44.53%] [G loss: 0.777866]\n",
      "epoch:32 step:25708 [D loss: 0.713069, acc.: 50.00%] [G loss: 0.757549]\n",
      "epoch:32 step:25709 [D loss: 0.681533, acc.: 59.38%] [G loss: 0.806207]\n",
      "epoch:32 step:25710 [D loss: 0.649846, acc.: 64.84%] [G loss: 0.856716]\n",
      "epoch:32 step:25711 [D loss: 0.657025, acc.: 64.84%] [G loss: 0.838811]\n",
      "epoch:32 step:25712 [D loss: 0.690882, acc.: 53.12%] [G loss: 0.812941]\n",
      "epoch:32 step:25713 [D loss: 0.685116, acc.: 56.25%] [G loss: 0.808143]\n",
      "epoch:32 step:25714 [D loss: 0.684143, acc.: 57.03%] [G loss: 0.845064]\n",
      "epoch:32 step:25715 [D loss: 0.772664, acc.: 34.38%] [G loss: 0.786752]\n",
      "epoch:32 step:25716 [D loss: 0.695438, acc.: 51.56%] [G loss: 0.685359]\n",
      "epoch:32 step:25717 [D loss: 0.671723, acc.: 56.25%] [G loss: 0.723053]\n",
      "epoch:32 step:25718 [D loss: 0.692887, acc.: 50.00%] [G loss: 0.746317]\n",
      "epoch:32 step:25719 [D loss: 0.685190, acc.: 53.12%] [G loss: 0.765079]\n",
      "epoch:32 step:25720 [D loss: 0.719959, acc.: 48.44%] [G loss: 0.775588]\n",
      "epoch:32 step:25721 [D loss: 0.711386, acc.: 54.69%] [G loss: 0.748830]\n",
      "epoch:32 step:25722 [D loss: 0.719440, acc.: 46.88%] [G loss: 0.789506]\n",
      "epoch:32 step:25723 [D loss: 0.703576, acc.: 52.34%] [G loss: 0.746748]\n",
      "epoch:32 step:25724 [D loss: 0.669871, acc.: 59.38%] [G loss: 0.762378]\n",
      "epoch:32 step:25725 [D loss: 0.728401, acc.: 45.31%] [G loss: 0.734614]\n",
      "epoch:32 step:25726 [D loss: 0.740317, acc.: 43.75%] [G loss: 0.760216]\n",
      "epoch:32 step:25727 [D loss: 0.719817, acc.: 48.44%] [G loss: 0.744401]\n",
      "epoch:32 step:25728 [D loss: 0.688375, acc.: 57.03%] [G loss: 0.860721]\n",
      "epoch:32 step:25729 [D loss: 0.718084, acc.: 42.97%] [G loss: 0.761603]\n",
      "epoch:32 step:25730 [D loss: 0.681016, acc.: 56.25%] [G loss: 0.772269]\n",
      "epoch:32 step:25731 [D loss: 0.737945, acc.: 45.31%] [G loss: 0.784436]\n",
      "epoch:32 step:25732 [D loss: 0.671156, acc.: 57.03%] [G loss: 0.781031]\n",
      "epoch:32 step:25733 [D loss: 0.690729, acc.: 54.69%] [G loss: 0.772202]\n",
      "epoch:32 step:25734 [D loss: 0.720928, acc.: 45.31%] [G loss: 0.731458]\n",
      "epoch:32 step:25735 [D loss: 0.690092, acc.: 53.12%] [G loss: 0.750623]\n",
      "epoch:32 step:25736 [D loss: 0.691056, acc.: 51.56%] [G loss: 0.859647]\n",
      "epoch:32 step:25737 [D loss: 0.648464, acc.: 68.75%] [G loss: 0.759096]\n",
      "epoch:32 step:25738 [D loss: 0.658346, acc.: 58.59%] [G loss: 0.763137]\n",
      "epoch:32 step:25739 [D loss: 0.656078, acc.: 59.38%] [G loss: 0.777435]\n",
      "epoch:32 step:25740 [D loss: 0.685358, acc.: 53.12%] [G loss: 0.803256]\n",
      "epoch:32 step:25741 [D loss: 0.682876, acc.: 53.12%] [G loss: 0.765944]\n",
      "epoch:32 step:25742 [D loss: 0.680967, acc.: 54.69%] [G loss: 0.776926]\n",
      "epoch:32 step:25743 [D loss: 0.695542, acc.: 56.25%] [G loss: 0.726441]\n",
      "epoch:32 step:25744 [D loss: 0.690715, acc.: 53.91%] [G loss: 0.777850]\n",
      "epoch:32 step:25745 [D loss: 0.653505, acc.: 57.81%] [G loss: 0.747104]\n",
      "epoch:32 step:25746 [D loss: 0.678495, acc.: 53.12%] [G loss: 0.772549]\n",
      "epoch:32 step:25747 [D loss: 0.737712, acc.: 41.41%] [G loss: 0.757007]\n",
      "epoch:32 step:25748 [D loss: 0.661979, acc.: 67.97%] [G loss: 0.818427]\n",
      "epoch:32 step:25749 [D loss: 0.662131, acc.: 61.72%] [G loss: 0.825274]\n",
      "epoch:32 step:25750 [D loss: 0.641684, acc.: 67.19%] [G loss: 0.795282]\n",
      "epoch:32 step:25751 [D loss: 0.660206, acc.: 60.16%] [G loss: 0.808716]\n",
      "epoch:32 step:25752 [D loss: 0.733790, acc.: 43.75%] [G loss: 0.740308]\n",
      "epoch:32 step:25753 [D loss: 0.662215, acc.: 58.59%] [G loss: 0.822035]\n",
      "epoch:32 step:25754 [D loss: 0.663004, acc.: 58.59%] [G loss: 0.799012]\n",
      "epoch:32 step:25755 [D loss: 0.677350, acc.: 57.81%] [G loss: 0.706943]\n",
      "epoch:32 step:25756 [D loss: 0.690336, acc.: 46.88%] [G loss: 0.820023]\n",
      "epoch:32 step:25757 [D loss: 0.669998, acc.: 57.81%] [G loss: 0.767202]\n",
      "epoch:32 step:25758 [D loss: 0.698298, acc.: 53.12%] [G loss: 0.785942]\n",
      "epoch:32 step:25759 [D loss: 0.679135, acc.: 61.72%] [G loss: 0.788372]\n",
      "epoch:32 step:25760 [D loss: 0.685435, acc.: 48.44%] [G loss: 0.712604]\n",
      "epoch:32 step:25761 [D loss: 0.698155, acc.: 46.88%] [G loss: 0.753556]\n",
      "epoch:32 step:25762 [D loss: 0.714640, acc.: 45.31%] [G loss: 0.756891]\n",
      "epoch:32 step:25763 [D loss: 0.720819, acc.: 45.31%] [G loss: 0.741509]\n",
      "epoch:32 step:25764 [D loss: 0.719710, acc.: 42.97%] [G loss: 0.755029]\n",
      "epoch:32 step:25765 [D loss: 0.655594, acc.: 60.94%] [G loss: 0.832188]\n",
      "epoch:32 step:25766 [D loss: 0.674188, acc.: 57.81%] [G loss: 0.802125]\n",
      "epoch:32 step:25767 [D loss: 0.693436, acc.: 50.78%] [G loss: 0.743720]\n",
      "epoch:32 step:25768 [D loss: 0.692382, acc.: 48.44%] [G loss: 0.791962]\n",
      "epoch:32 step:25769 [D loss: 0.709145, acc.: 53.12%] [G loss: 0.787100]\n",
      "epoch:32 step:25770 [D loss: 0.679842, acc.: 55.47%] [G loss: 0.744836]\n",
      "epoch:32 step:25771 [D loss: 0.686563, acc.: 56.25%] [G loss: 0.752586]\n",
      "epoch:32 step:25772 [D loss: 0.712677, acc.: 48.44%] [G loss: 0.753058]\n",
      "epoch:32 step:25773 [D loss: 0.640875, acc.: 66.41%] [G loss: 0.710508]\n",
      "epoch:33 step:25774 [D loss: 0.646478, acc.: 64.84%] [G loss: 0.785740]\n",
      "epoch:33 step:25775 [D loss: 0.730144, acc.: 45.31%] [G loss: 0.746791]\n",
      "epoch:33 step:25776 [D loss: 0.710496, acc.: 49.22%] [G loss: 0.810870]\n",
      "epoch:33 step:25777 [D loss: 0.667267, acc.: 63.28%] [G loss: 0.819872]\n",
      "epoch:33 step:25778 [D loss: 0.699871, acc.: 52.34%] [G loss: 0.796862]\n",
      "epoch:33 step:25779 [D loss: 0.691861, acc.: 56.25%] [G loss: 0.792551]\n",
      "epoch:33 step:25780 [D loss: 0.671908, acc.: 58.59%] [G loss: 0.801706]\n",
      "epoch:33 step:25781 [D loss: 0.684585, acc.: 49.22%] [G loss: 0.816913]\n",
      "epoch:33 step:25782 [D loss: 0.739714, acc.: 45.31%] [G loss: 0.800447]\n",
      "epoch:33 step:25783 [D loss: 0.680127, acc.: 60.16%] [G loss: 0.794361]\n",
      "epoch:33 step:25784 [D loss: 0.716559, acc.: 52.34%] [G loss: 0.842817]\n",
      "epoch:33 step:25785 [D loss: 0.678034, acc.: 60.94%] [G loss: 0.774883]\n",
      "epoch:33 step:25786 [D loss: 0.678989, acc.: 64.84%] [G loss: 0.800955]\n",
      "epoch:33 step:25787 [D loss: 0.650073, acc.: 64.06%] [G loss: 0.858875]\n",
      "epoch:33 step:25788 [D loss: 0.678167, acc.: 57.81%] [G loss: 0.785495]\n",
      "epoch:33 step:25789 [D loss: 0.648181, acc.: 62.50%] [G loss: 0.805149]\n",
      "epoch:33 step:25790 [D loss: 0.639987, acc.: 70.31%] [G loss: 0.839157]\n",
      "epoch:33 step:25791 [D loss: 0.709207, acc.: 48.44%] [G loss: 0.832851]\n",
      "epoch:33 step:25792 [D loss: 0.740351, acc.: 42.19%] [G loss: 0.760522]\n",
      "epoch:33 step:25793 [D loss: 0.647102, acc.: 66.41%] [G loss: 0.814444]\n",
      "epoch:33 step:25794 [D loss: 0.709919, acc.: 53.12%] [G loss: 0.813138]\n",
      "epoch:33 step:25795 [D loss: 0.639165, acc.: 66.41%] [G loss: 0.793777]\n",
      "epoch:33 step:25796 [D loss: 0.658098, acc.: 60.94%] [G loss: 0.840853]\n",
      "epoch:33 step:25797 [D loss: 0.769657, acc.: 32.03%] [G loss: 0.767039]\n",
      "epoch:33 step:25798 [D loss: 0.692310, acc.: 53.91%] [G loss: 0.747501]\n",
      "epoch:33 step:25799 [D loss: 0.700330, acc.: 53.12%] [G loss: 0.743919]\n",
      "epoch:33 step:25800 [D loss: 0.687121, acc.: 56.25%] [G loss: 0.745145]\n",
      "epoch:33 step:25801 [D loss: 0.724673, acc.: 46.09%] [G loss: 0.744650]\n",
      "epoch:33 step:25802 [D loss: 0.660788, acc.: 61.72%] [G loss: 0.768289]\n",
      "epoch:33 step:25803 [D loss: 0.644488, acc.: 64.84%] [G loss: 0.844788]\n",
      "epoch:33 step:25804 [D loss: 0.693848, acc.: 50.00%] [G loss: 0.808497]\n",
      "epoch:33 step:25805 [D loss: 0.682989, acc.: 56.25%] [G loss: 0.747737]\n",
      "epoch:33 step:25806 [D loss: 0.692145, acc.: 53.91%] [G loss: 0.800032]\n",
      "epoch:33 step:25807 [D loss: 0.662898, acc.: 64.84%] [G loss: 0.772198]\n",
      "epoch:33 step:25808 [D loss: 0.718532, acc.: 50.00%] [G loss: 0.737145]\n",
      "epoch:33 step:25809 [D loss: 0.724674, acc.: 41.41%] [G loss: 0.738246]\n",
      "epoch:33 step:25810 [D loss: 0.736000, acc.: 45.31%] [G loss: 0.755781]\n",
      "epoch:33 step:25811 [D loss: 0.717670, acc.: 50.00%] [G loss: 0.759109]\n",
      "epoch:33 step:25812 [D loss: 0.661720, acc.: 57.81%] [G loss: 0.837385]\n",
      "epoch:33 step:25813 [D loss: 0.673568, acc.: 52.34%] [G loss: 0.804669]\n",
      "epoch:33 step:25814 [D loss: 0.636150, acc.: 64.06%] [G loss: 0.903001]\n",
      "epoch:33 step:25815 [D loss: 0.678563, acc.: 59.38%] [G loss: 0.780565]\n",
      "epoch:33 step:25816 [D loss: 0.671147, acc.: 61.72%] [G loss: 0.708317]\n",
      "epoch:33 step:25817 [D loss: 0.679453, acc.: 56.25%] [G loss: 0.726796]\n",
      "epoch:33 step:25818 [D loss: 0.691529, acc.: 55.47%] [G loss: 0.713740]\n",
      "epoch:33 step:25819 [D loss: 0.711596, acc.: 48.44%] [G loss: 0.778650]\n",
      "epoch:33 step:25820 [D loss: 0.668676, acc.: 58.59%] [G loss: 0.955721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25821 [D loss: 0.691165, acc.: 50.78%] [G loss: 0.773372]\n",
      "epoch:33 step:25822 [D loss: 0.701019, acc.: 52.34%] [G loss: 0.781679]\n",
      "epoch:33 step:25823 [D loss: 0.740215, acc.: 42.19%] [G loss: 0.773730]\n",
      "epoch:33 step:25824 [D loss: 0.645394, acc.: 66.41%] [G loss: 0.778080]\n",
      "epoch:33 step:25825 [D loss: 0.647868, acc.: 64.84%] [G loss: 0.733772]\n",
      "epoch:33 step:25826 [D loss: 0.688234, acc.: 53.12%] [G loss: 0.785789]\n",
      "epoch:33 step:25827 [D loss: 0.674040, acc.: 65.62%] [G loss: 0.787073]\n",
      "epoch:33 step:25828 [D loss: 0.704354, acc.: 51.56%] [G loss: 0.795357]\n",
      "epoch:33 step:25829 [D loss: 0.643021, acc.: 64.06%] [G loss: 0.822280]\n",
      "epoch:33 step:25830 [D loss: 0.676716, acc.: 56.25%] [G loss: 0.778216]\n",
      "epoch:33 step:25831 [D loss: 0.686221, acc.: 54.69%] [G loss: 0.742905]\n",
      "epoch:33 step:25832 [D loss: 0.673444, acc.: 55.47%] [G loss: 0.806637]\n",
      "epoch:33 step:25833 [D loss: 0.701194, acc.: 49.22%] [G loss: 0.810058]\n",
      "epoch:33 step:25834 [D loss: 0.713129, acc.: 42.19%] [G loss: 0.772227]\n",
      "epoch:33 step:25835 [D loss: 0.675786, acc.: 61.72%] [G loss: 0.790028]\n",
      "epoch:33 step:25836 [D loss: 0.709834, acc.: 51.56%] [G loss: 0.853497]\n",
      "epoch:33 step:25837 [D loss: 0.639840, acc.: 61.72%] [G loss: 0.856457]\n",
      "epoch:33 step:25838 [D loss: 0.737226, acc.: 45.31%] [G loss: 0.791295]\n",
      "epoch:33 step:25839 [D loss: 0.721897, acc.: 49.22%] [G loss: 0.790199]\n",
      "epoch:33 step:25840 [D loss: 0.712797, acc.: 50.00%] [G loss: 0.894232]\n",
      "epoch:33 step:25841 [D loss: 0.693223, acc.: 53.12%] [G loss: 0.774183]\n",
      "epoch:33 step:25842 [D loss: 0.673331, acc.: 56.25%] [G loss: 0.745438]\n",
      "epoch:33 step:25843 [D loss: 0.704763, acc.: 52.34%] [G loss: 0.788797]\n",
      "epoch:33 step:25844 [D loss: 0.720944, acc.: 44.53%] [G loss: 0.783516]\n",
      "epoch:33 step:25845 [D loss: 0.694683, acc.: 51.56%] [G loss: 0.726025]\n",
      "epoch:33 step:25846 [D loss: 0.735602, acc.: 43.75%] [G loss: 0.708879]\n",
      "epoch:33 step:25847 [D loss: 0.678043, acc.: 51.56%] [G loss: 0.766516]\n",
      "epoch:33 step:25848 [D loss: 0.681737, acc.: 53.12%] [G loss: 0.801491]\n",
      "epoch:33 step:25849 [D loss: 0.677358, acc.: 58.59%] [G loss: 0.810863]\n",
      "epoch:33 step:25850 [D loss: 0.700905, acc.: 52.34%] [G loss: 0.715858]\n",
      "epoch:33 step:25851 [D loss: 0.689341, acc.: 55.47%] [G loss: 0.798504]\n",
      "epoch:33 step:25852 [D loss: 0.688165, acc.: 52.34%] [G loss: 0.762725]\n",
      "epoch:33 step:25853 [D loss: 0.672419, acc.: 56.25%] [G loss: 0.775959]\n",
      "epoch:33 step:25854 [D loss: 0.716461, acc.: 48.44%] [G loss: 0.795429]\n",
      "epoch:33 step:25855 [D loss: 0.695525, acc.: 53.12%] [G loss: 0.713757]\n",
      "epoch:33 step:25856 [D loss: 0.670346, acc.: 61.72%] [G loss: 0.793899]\n",
      "epoch:33 step:25857 [D loss: 0.690500, acc.: 53.12%] [G loss: 0.758345]\n",
      "epoch:33 step:25858 [D loss: 0.703676, acc.: 53.12%] [G loss: 0.761231]\n",
      "epoch:33 step:25859 [D loss: 0.670138, acc.: 60.94%] [G loss: 0.788116]\n",
      "epoch:33 step:25860 [D loss: 0.669944, acc.: 58.59%] [G loss: 0.768407]\n",
      "epoch:33 step:25861 [D loss: 0.703937, acc.: 53.12%] [G loss: 0.816934]\n",
      "epoch:33 step:25862 [D loss: 0.667327, acc.: 57.03%] [G loss: 0.829810]\n",
      "epoch:33 step:25863 [D loss: 0.685751, acc.: 54.69%] [G loss: 0.798509]\n",
      "epoch:33 step:25864 [D loss: 0.761153, acc.: 34.38%] [G loss: 0.747189]\n",
      "epoch:33 step:25865 [D loss: 0.730399, acc.: 42.97%] [G loss: 0.775682]\n",
      "epoch:33 step:25866 [D loss: 0.678573, acc.: 58.59%] [G loss: 0.796544]\n",
      "epoch:33 step:25867 [D loss: 0.654523, acc.: 64.06%] [G loss: 0.741218]\n",
      "epoch:33 step:25868 [D loss: 0.667918, acc.: 60.16%] [G loss: 0.678254]\n",
      "epoch:33 step:25869 [D loss: 0.748509, acc.: 43.75%] [G loss: 0.771203]\n",
      "epoch:33 step:25870 [D loss: 0.703474, acc.: 51.56%] [G loss: 0.773658]\n",
      "epoch:33 step:25871 [D loss: 0.648154, acc.: 61.72%] [G loss: 0.943887]\n",
      "epoch:33 step:25872 [D loss: 0.687491, acc.: 53.12%] [G loss: 0.802532]\n",
      "epoch:33 step:25873 [D loss: 0.657525, acc.: 53.91%] [G loss: 0.859230]\n",
      "epoch:33 step:25874 [D loss: 0.727357, acc.: 45.31%] [G loss: 0.757908]\n",
      "epoch:33 step:25875 [D loss: 0.679201, acc.: 56.25%] [G loss: 0.783570]\n",
      "epoch:33 step:25876 [D loss: 0.691104, acc.: 51.56%] [G loss: 0.751424]\n",
      "epoch:33 step:25877 [D loss: 0.700766, acc.: 44.53%] [G loss: 0.784213]\n",
      "epoch:33 step:25878 [D loss: 0.684784, acc.: 54.69%] [G loss: 0.797089]\n",
      "epoch:33 step:25879 [D loss: 0.696106, acc.: 47.66%] [G loss: 0.749430]\n",
      "epoch:33 step:25880 [D loss: 0.668641, acc.: 57.03%] [G loss: 0.725206]\n",
      "epoch:33 step:25881 [D loss: 0.724797, acc.: 50.78%] [G loss: 0.743567]\n",
      "epoch:33 step:25882 [D loss: 0.712036, acc.: 46.09%] [G loss: 0.750921]\n",
      "epoch:33 step:25883 [D loss: 0.661995, acc.: 65.62%] [G loss: 0.734005]\n",
      "epoch:33 step:25884 [D loss: 0.672106, acc.: 60.16%] [G loss: 0.773304]\n",
      "epoch:33 step:25885 [D loss: 0.653611, acc.: 60.94%] [G loss: 0.766676]\n",
      "epoch:33 step:25886 [D loss: 0.692813, acc.: 50.78%] [G loss: 0.688903]\n",
      "epoch:33 step:25887 [D loss: 0.633887, acc.: 66.41%] [G loss: 0.826864]\n",
      "epoch:33 step:25888 [D loss: 0.670686, acc.: 59.38%] [G loss: 0.780695]\n",
      "epoch:33 step:25889 [D loss: 0.694629, acc.: 51.56%] [G loss: 0.794112]\n",
      "epoch:33 step:25890 [D loss: 0.674657, acc.: 55.47%] [G loss: 0.739979]\n",
      "epoch:33 step:25891 [D loss: 0.707889, acc.: 47.66%] [G loss: 0.715910]\n",
      "epoch:33 step:25892 [D loss: 0.688294, acc.: 63.28%] [G loss: 0.751395]\n",
      "epoch:33 step:25893 [D loss: 0.657106, acc.: 64.84%] [G loss: 0.724117]\n",
      "epoch:33 step:25894 [D loss: 0.660775, acc.: 63.28%] [G loss: 0.709283]\n",
      "epoch:33 step:25895 [D loss: 0.705995, acc.: 48.44%] [G loss: 0.769620]\n",
      "epoch:33 step:25896 [D loss: 0.726783, acc.: 44.53%] [G loss: 0.775073]\n",
      "epoch:33 step:25897 [D loss: 0.675667, acc.: 57.81%] [G loss: 0.702464]\n",
      "epoch:33 step:25898 [D loss: 0.744269, acc.: 34.38%] [G loss: 0.732209]\n",
      "epoch:33 step:25899 [D loss: 0.706840, acc.: 46.88%] [G loss: 0.775212]\n",
      "epoch:33 step:25900 [D loss: 0.671959, acc.: 57.03%] [G loss: 0.775418]\n",
      "epoch:33 step:25901 [D loss: 0.686538, acc.: 58.59%] [G loss: 0.687012]\n",
      "epoch:33 step:25902 [D loss: 0.706793, acc.: 48.44%] [G loss: 0.708937]\n",
      "epoch:33 step:25903 [D loss: 0.718976, acc.: 51.56%] [G loss: 0.812354]\n",
      "epoch:33 step:25904 [D loss: 0.696546, acc.: 53.12%] [G loss: 0.707221]\n",
      "epoch:33 step:25905 [D loss: 0.696018, acc.: 57.03%] [G loss: 0.770390]\n",
      "epoch:33 step:25906 [D loss: 0.654540, acc.: 65.62%] [G loss: 0.776815]\n",
      "epoch:33 step:25907 [D loss: 0.695137, acc.: 50.00%] [G loss: 0.781758]\n",
      "epoch:33 step:25908 [D loss: 0.673225, acc.: 57.03%] [G loss: 0.821128]\n",
      "epoch:33 step:25909 [D loss: 0.720046, acc.: 46.09%] [G loss: 0.737046]\n",
      "epoch:33 step:25910 [D loss: 0.747203, acc.: 42.97%] [G loss: 0.751984]\n",
      "epoch:33 step:25911 [D loss: 0.679057, acc.: 53.12%] [G loss: 0.793345]\n",
      "epoch:33 step:25912 [D loss: 0.653866, acc.: 63.28%] [G loss: 0.831755]\n",
      "epoch:33 step:25913 [D loss: 0.675100, acc.: 51.56%] [G loss: 0.769468]\n",
      "epoch:33 step:25914 [D loss: 0.660042, acc.: 60.94%] [G loss: 0.808382]\n",
      "epoch:33 step:25915 [D loss: 0.695943, acc.: 48.44%] [G loss: 0.766240]\n",
      "epoch:33 step:25916 [D loss: 0.718891, acc.: 48.44%] [G loss: 0.796169]\n",
      "epoch:33 step:25917 [D loss: 0.725631, acc.: 50.00%] [G loss: 0.846521]\n",
      "epoch:33 step:25918 [D loss: 0.662582, acc.: 64.06%] [G loss: 0.773254]\n",
      "epoch:33 step:25919 [D loss: 0.634125, acc.: 71.88%] [G loss: 0.818592]\n",
      "epoch:33 step:25920 [D loss: 0.664649, acc.: 58.59%] [G loss: 0.810139]\n",
      "epoch:33 step:25921 [D loss: 0.655596, acc.: 65.62%] [G loss: 0.771068]\n",
      "epoch:33 step:25922 [D loss: 0.673856, acc.: 60.94%] [G loss: 0.729763]\n",
      "epoch:33 step:25923 [D loss: 0.676323, acc.: 55.47%] [G loss: 0.862697]\n",
      "epoch:33 step:25924 [D loss: 0.696313, acc.: 50.78%] [G loss: 0.789678]\n",
      "epoch:33 step:25925 [D loss: 0.692899, acc.: 46.88%] [G loss: 0.807256]\n",
      "epoch:33 step:25926 [D loss: 0.677419, acc.: 63.28%] [G loss: 0.792383]\n",
      "epoch:33 step:25927 [D loss: 0.671733, acc.: 58.59%] [G loss: 0.759373]\n",
      "epoch:33 step:25928 [D loss: 0.697612, acc.: 46.88%] [G loss: 0.795752]\n",
      "epoch:33 step:25929 [D loss: 0.642500, acc.: 65.62%] [G loss: 0.778182]\n",
      "epoch:33 step:25930 [D loss: 0.682845, acc.: 57.03%] [G loss: 0.723050]\n",
      "epoch:33 step:25931 [D loss: 0.705810, acc.: 52.34%] [G loss: 0.733442]\n",
      "epoch:33 step:25932 [D loss: 0.678760, acc.: 55.47%] [G loss: 0.758775]\n",
      "epoch:33 step:25933 [D loss: 0.716078, acc.: 53.12%] [G loss: 0.770090]\n",
      "epoch:33 step:25934 [D loss: 0.654429, acc.: 64.06%] [G loss: 0.809064]\n",
      "epoch:33 step:25935 [D loss: 0.686158, acc.: 53.91%] [G loss: 0.804883]\n",
      "epoch:33 step:25936 [D loss: 0.695477, acc.: 54.69%] [G loss: 0.788329]\n",
      "epoch:33 step:25937 [D loss: 0.722572, acc.: 46.88%] [G loss: 0.818447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25938 [D loss: 0.669603, acc.: 58.59%] [G loss: 0.776837]\n",
      "epoch:33 step:25939 [D loss: 0.728383, acc.: 46.88%] [G loss: 0.815235]\n",
      "epoch:33 step:25940 [D loss: 0.695645, acc.: 53.12%] [G loss: 0.717634]\n",
      "epoch:33 step:25941 [D loss: 0.653796, acc.: 64.06%] [G loss: 0.707985]\n",
      "epoch:33 step:25942 [D loss: 0.772619, acc.: 38.28%] [G loss: 0.778871]\n",
      "epoch:33 step:25943 [D loss: 0.635042, acc.: 67.97%] [G loss: 0.860306]\n",
      "epoch:33 step:25944 [D loss: 0.677582, acc.: 55.47%] [G loss: 0.854867]\n",
      "epoch:33 step:25945 [D loss: 0.691841, acc.: 52.34%] [G loss: 0.848091]\n",
      "epoch:33 step:25946 [D loss: 0.676598, acc.: 60.16%] [G loss: 0.877904]\n",
      "epoch:33 step:25947 [D loss: 0.696492, acc.: 51.56%] [G loss: 0.797308]\n",
      "epoch:33 step:25948 [D loss: 0.689033, acc.: 59.38%] [G loss: 0.759319]\n",
      "epoch:33 step:25949 [D loss: 0.701637, acc.: 50.00%] [G loss: 0.795206]\n",
      "epoch:33 step:25950 [D loss: 0.671842, acc.: 64.06%] [G loss: 0.796555]\n",
      "epoch:33 step:25951 [D loss: 0.677550, acc.: 55.47%] [G loss: 0.829629]\n",
      "epoch:33 step:25952 [D loss: 0.652823, acc.: 64.84%] [G loss: 0.829206]\n",
      "epoch:33 step:25953 [D loss: 0.656435, acc.: 63.28%] [G loss: 0.797178]\n",
      "epoch:33 step:25954 [D loss: 0.710810, acc.: 46.09%] [G loss: 0.755503]\n",
      "epoch:33 step:25955 [D loss: 0.720369, acc.: 46.09%] [G loss: 0.807337]\n",
      "epoch:33 step:25956 [D loss: 0.739012, acc.: 45.31%] [G loss: 0.794968]\n",
      "epoch:33 step:25957 [D loss: 0.634299, acc.: 63.28%] [G loss: 0.842828]\n",
      "epoch:33 step:25958 [D loss: 0.664061, acc.: 60.94%] [G loss: 0.783604]\n",
      "epoch:33 step:25959 [D loss: 0.707659, acc.: 53.91%] [G loss: 0.747008]\n",
      "epoch:33 step:25960 [D loss: 0.647957, acc.: 61.72%] [G loss: 0.835566]\n",
      "epoch:33 step:25961 [D loss: 0.645702, acc.: 67.97%] [G loss: 0.771181]\n",
      "epoch:33 step:25962 [D loss: 0.635236, acc.: 71.88%] [G loss: 0.786214]\n",
      "epoch:33 step:25963 [D loss: 0.690631, acc.: 58.59%] [G loss: 0.760753]\n",
      "epoch:33 step:25964 [D loss: 0.637238, acc.: 61.72%] [G loss: 0.793870]\n",
      "epoch:33 step:25965 [D loss: 0.705328, acc.: 45.31%] [G loss: 0.734704]\n",
      "epoch:33 step:25966 [D loss: 0.753966, acc.: 36.72%] [G loss: 0.738554]\n",
      "epoch:33 step:25967 [D loss: 0.757691, acc.: 44.53%] [G loss: 0.718403]\n",
      "epoch:33 step:25968 [D loss: 0.692439, acc.: 51.56%] [G loss: 0.715131]\n",
      "epoch:33 step:25969 [D loss: 0.696116, acc.: 52.34%] [G loss: 0.771429]\n",
      "epoch:33 step:25970 [D loss: 0.722205, acc.: 47.66%] [G loss: 0.759526]\n",
      "epoch:33 step:25971 [D loss: 0.687890, acc.: 58.59%] [G loss: 0.736424]\n",
      "epoch:33 step:25972 [D loss: 0.717789, acc.: 52.34%] [G loss: 0.735731]\n",
      "epoch:33 step:25973 [D loss: 0.697961, acc.: 50.00%] [G loss: 0.779360]\n",
      "epoch:33 step:25974 [D loss: 0.678697, acc.: 60.94%] [G loss: 0.653984]\n",
      "epoch:33 step:25975 [D loss: 0.763133, acc.: 38.28%] [G loss: 0.788201]\n",
      "epoch:33 step:25976 [D loss: 0.686789, acc.: 56.25%] [G loss: 0.728393]\n",
      "epoch:33 step:25977 [D loss: 0.707788, acc.: 47.66%] [G loss: 0.761643]\n",
      "epoch:33 step:25978 [D loss: 0.729192, acc.: 40.62%] [G loss: 0.780849]\n",
      "epoch:33 step:25979 [D loss: 0.648954, acc.: 64.06%] [G loss: 0.735548]\n",
      "epoch:33 step:25980 [D loss: 0.664221, acc.: 62.50%] [G loss: 0.759892]\n",
      "epoch:33 step:25981 [D loss: 0.629700, acc.: 70.31%] [G loss: 0.822635]\n",
      "epoch:33 step:25982 [D loss: 0.685659, acc.: 58.59%] [G loss: 0.767176]\n",
      "epoch:33 step:25983 [D loss: 0.634909, acc.: 71.09%] [G loss: 0.856295]\n",
      "epoch:33 step:25984 [D loss: 0.631437, acc.: 67.19%] [G loss: 0.795695]\n",
      "epoch:33 step:25985 [D loss: 0.669498, acc.: 57.03%] [G loss: 0.823670]\n",
      "epoch:33 step:25986 [D loss: 0.671180, acc.: 58.59%] [G loss: 0.874378]\n",
      "epoch:33 step:25987 [D loss: 0.702464, acc.: 49.22%] [G loss: 0.777692]\n",
      "epoch:33 step:25988 [D loss: 0.664270, acc.: 54.69%] [G loss: 0.897660]\n",
      "epoch:33 step:25989 [D loss: 0.697013, acc.: 55.47%] [G loss: 0.824807]\n",
      "epoch:33 step:25990 [D loss: 0.649714, acc.: 61.72%] [G loss: 0.866195]\n",
      "epoch:33 step:25991 [D loss: 0.698810, acc.: 56.25%] [G loss: 0.752459]\n",
      "epoch:33 step:25992 [D loss: 0.685736, acc.: 58.59%] [G loss: 0.765240]\n",
      "epoch:33 step:25993 [D loss: 0.695564, acc.: 48.44%] [G loss: 0.807417]\n",
      "epoch:33 step:25994 [D loss: 0.679444, acc.: 55.47%] [G loss: 0.755924]\n",
      "epoch:33 step:25995 [D loss: 0.708030, acc.: 46.09%] [G loss: 0.765290]\n",
      "epoch:33 step:25996 [D loss: 0.681464, acc.: 57.81%] [G loss: 0.757610]\n",
      "epoch:33 step:25997 [D loss: 0.645963, acc.: 67.97%] [G loss: 0.727631]\n",
      "epoch:33 step:25998 [D loss: 0.689753, acc.: 50.00%] [G loss: 0.761913]\n",
      "epoch:33 step:25999 [D loss: 0.698445, acc.: 53.12%] [G loss: 0.782287]\n",
      "epoch:33 step:26000 [D loss: 0.717737, acc.: 50.78%] [G loss: 0.781204]\n",
      "epoch:33 step:26001 [D loss: 0.703518, acc.: 54.69%] [G loss: 0.698625]\n",
      "epoch:33 step:26002 [D loss: 0.701452, acc.: 53.12%] [G loss: 0.757092]\n",
      "epoch:33 step:26003 [D loss: 0.744656, acc.: 39.84%] [G loss: 0.706760]\n",
      "epoch:33 step:26004 [D loss: 0.653168, acc.: 60.16%] [G loss: 0.788414]\n",
      "epoch:33 step:26005 [D loss: 0.708373, acc.: 46.09%] [G loss: 0.697417]\n",
      "epoch:33 step:26006 [D loss: 0.639677, acc.: 66.41%] [G loss: 0.738678]\n",
      "epoch:33 step:26007 [D loss: 0.747800, acc.: 39.06%] [G loss: 0.714685]\n",
      "epoch:33 step:26008 [D loss: 0.639917, acc.: 60.94%] [G loss: 0.716202]\n",
      "epoch:33 step:26009 [D loss: 0.644584, acc.: 66.41%] [G loss: 0.754280]\n",
      "epoch:33 step:26010 [D loss: 0.678918, acc.: 57.81%] [G loss: 0.752830]\n",
      "epoch:33 step:26011 [D loss: 0.678252, acc.: 61.72%] [G loss: 0.855872]\n",
      "epoch:33 step:26012 [D loss: 0.702561, acc.: 52.34%] [G loss: 0.793399]\n",
      "epoch:33 step:26013 [D loss: 0.689996, acc.: 56.25%] [G loss: 0.884323]\n",
      "epoch:33 step:26014 [D loss: 0.677418, acc.: 57.81%] [G loss: 0.815330]\n",
      "epoch:33 step:26015 [D loss: 0.677836, acc.: 59.38%] [G loss: 0.816338]\n",
      "epoch:33 step:26016 [D loss: 0.667166, acc.: 59.38%] [G loss: 0.815934]\n",
      "epoch:33 step:26017 [D loss: 0.629301, acc.: 67.19%] [G loss: 0.729070]\n",
      "epoch:33 step:26018 [D loss: 0.709110, acc.: 49.22%] [G loss: 0.814805]\n",
      "epoch:33 step:26019 [D loss: 0.644364, acc.: 63.28%] [G loss: 0.703388]\n",
      "epoch:33 step:26020 [D loss: 0.636670, acc.: 64.84%] [G loss: 0.694754]\n",
      "epoch:33 step:26021 [D loss: 0.594640, acc.: 74.22%] [G loss: 0.752976]\n",
      "epoch:33 step:26022 [D loss: 0.623657, acc.: 65.62%] [G loss: 0.675414]\n",
      "epoch:33 step:26023 [D loss: 0.708708, acc.: 54.69%] [G loss: 0.728616]\n",
      "epoch:33 step:26024 [D loss: 0.673526, acc.: 60.16%] [G loss: 0.732220]\n",
      "epoch:33 step:26025 [D loss: 0.669163, acc.: 60.16%] [G loss: 0.855986]\n",
      "epoch:33 step:26026 [D loss: 0.714266, acc.: 47.66%] [G loss: 0.779970]\n",
      "epoch:33 step:26027 [D loss: 0.632631, acc.: 65.62%] [G loss: 0.889400]\n",
      "epoch:33 step:26028 [D loss: 0.654645, acc.: 59.38%] [G loss: 0.817999]\n",
      "epoch:33 step:26029 [D loss: 0.739418, acc.: 40.62%] [G loss: 0.694974]\n",
      "epoch:33 step:26030 [D loss: 0.700112, acc.: 53.12%] [G loss: 0.829327]\n",
      "epoch:33 step:26031 [D loss: 0.670066, acc.: 60.16%] [G loss: 0.825816]\n",
      "epoch:33 step:26032 [D loss: 0.684305, acc.: 54.69%] [G loss: 0.798537]\n",
      "epoch:33 step:26033 [D loss: 0.641661, acc.: 65.62%] [G loss: 0.795852]\n",
      "epoch:33 step:26034 [D loss: 0.644642, acc.: 66.41%] [G loss: 0.835297]\n",
      "epoch:33 step:26035 [D loss: 0.729215, acc.: 42.97%] [G loss: 0.743232]\n",
      "epoch:33 step:26036 [D loss: 0.673523, acc.: 57.03%] [G loss: 0.795188]\n",
      "epoch:33 step:26037 [D loss: 0.765147, acc.: 34.38%] [G loss: 0.818436]\n",
      "epoch:33 step:26038 [D loss: 0.675303, acc.: 57.03%] [G loss: 0.745767]\n",
      "epoch:33 step:26039 [D loss: 0.708652, acc.: 49.22%] [G loss: 0.762194]\n",
      "epoch:33 step:26040 [D loss: 0.724137, acc.: 43.75%] [G loss: 0.815495]\n",
      "epoch:33 step:26041 [D loss: 0.675621, acc.: 57.81%] [G loss: 0.764504]\n",
      "epoch:33 step:26042 [D loss: 0.636563, acc.: 72.66%] [G loss: 0.841218]\n",
      "epoch:33 step:26043 [D loss: 0.692504, acc.: 50.00%] [G loss: 0.845079]\n",
      "epoch:33 step:26044 [D loss: 0.699630, acc.: 55.47%] [G loss: 0.831850]\n",
      "epoch:33 step:26045 [D loss: 0.693425, acc.: 51.56%] [G loss: 0.782538]\n",
      "epoch:33 step:26046 [D loss: 0.665402, acc.: 57.03%] [G loss: 0.797163]\n",
      "epoch:33 step:26047 [D loss: 0.694472, acc.: 57.81%] [G loss: 0.791252]\n",
      "epoch:33 step:26048 [D loss: 0.652515, acc.: 59.38%] [G loss: 0.764722]\n",
      "epoch:33 step:26049 [D loss: 0.644966, acc.: 66.41%] [G loss: 0.817993]\n",
      "epoch:33 step:26050 [D loss: 0.742716, acc.: 48.44%] [G loss: 0.764978]\n",
      "epoch:33 step:26051 [D loss: 0.691832, acc.: 55.47%] [G loss: 0.676455]\n",
      "epoch:33 step:26052 [D loss: 0.654557, acc.: 58.59%] [G loss: 0.799296]\n",
      "epoch:33 step:26053 [D loss: 0.635587, acc.: 68.75%] [G loss: 0.752240]\n",
      "epoch:33 step:26054 [D loss: 0.658185, acc.: 67.19%] [G loss: 0.714891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26055 [D loss: 0.652299, acc.: 66.41%] [G loss: 0.763641]\n",
      "epoch:33 step:26056 [D loss: 0.628492, acc.: 67.19%] [G loss: 0.752159]\n",
      "epoch:33 step:26057 [D loss: 0.674866, acc.: 57.81%] [G loss: 0.669760]\n",
      "epoch:33 step:26058 [D loss: 0.688001, acc.: 60.16%] [G loss: 0.725938]\n",
      "epoch:33 step:26059 [D loss: 0.748992, acc.: 42.19%] [G loss: 0.779781]\n",
      "epoch:33 step:26060 [D loss: 0.691784, acc.: 50.00%] [G loss: 0.680768]\n",
      "epoch:33 step:26061 [D loss: 0.702932, acc.: 52.34%] [G loss: 0.735697]\n",
      "epoch:33 step:26062 [D loss: 0.745735, acc.: 39.84%] [G loss: 0.722773]\n",
      "epoch:33 step:26063 [D loss: 0.690069, acc.: 58.59%] [G loss: 0.804183]\n",
      "epoch:33 step:26064 [D loss: 0.727004, acc.: 44.53%] [G loss: 0.779656]\n",
      "epoch:33 step:26065 [D loss: 0.727664, acc.: 46.09%] [G loss: 0.820827]\n",
      "epoch:33 step:26066 [D loss: 0.709145, acc.: 51.56%] [G loss: 0.713787]\n",
      "epoch:33 step:26067 [D loss: 0.668323, acc.: 64.06%] [G loss: 0.789206]\n",
      "epoch:33 step:26068 [D loss: 0.683958, acc.: 60.16%] [G loss: 0.876427]\n",
      "epoch:33 step:26069 [D loss: 0.672700, acc.: 57.81%] [G loss: 0.785746]\n",
      "epoch:33 step:26070 [D loss: 0.688164, acc.: 56.25%] [G loss: 0.771802]\n",
      "epoch:33 step:26071 [D loss: 0.720346, acc.: 44.53%] [G loss: 0.834683]\n",
      "epoch:33 step:26072 [D loss: 0.695318, acc.: 53.12%] [G loss: 0.846021]\n",
      "epoch:33 step:26073 [D loss: 0.752064, acc.: 42.19%] [G loss: 0.742857]\n",
      "epoch:33 step:26074 [D loss: 0.675883, acc.: 54.69%] [G loss: 0.774198]\n",
      "epoch:33 step:26075 [D loss: 0.710736, acc.: 50.00%] [G loss: 0.734894]\n",
      "epoch:33 step:26076 [D loss: 0.689687, acc.: 55.47%] [G loss: 0.872576]\n",
      "epoch:33 step:26077 [D loss: 0.637197, acc.: 68.75%] [G loss: 0.810652]\n",
      "epoch:33 step:26078 [D loss: 0.717388, acc.: 51.56%] [G loss: 0.747142]\n",
      "epoch:33 step:26079 [D loss: 0.693557, acc.: 51.56%] [G loss: 0.773502]\n",
      "epoch:33 step:26080 [D loss: 0.640983, acc.: 71.09%] [G loss: 0.737504]\n",
      "epoch:33 step:26081 [D loss: 0.653931, acc.: 61.72%] [G loss: 0.793407]\n",
      "epoch:33 step:26082 [D loss: 0.666212, acc.: 64.84%] [G loss: 0.772796]\n",
      "epoch:33 step:26083 [D loss: 0.698849, acc.: 53.91%] [G loss: 0.730122]\n",
      "epoch:33 step:26084 [D loss: 0.679161, acc.: 58.59%] [G loss: 0.781850]\n",
      "epoch:33 step:26085 [D loss: 0.649750, acc.: 65.62%] [G loss: 0.749303]\n",
      "epoch:33 step:26086 [D loss: 0.695112, acc.: 51.56%] [G loss: 0.709624]\n",
      "epoch:33 step:26087 [D loss: 0.679124, acc.: 50.78%] [G loss: 0.750284]\n",
      "epoch:33 step:26088 [D loss: 0.678045, acc.: 56.25%] [G loss: 0.759089]\n",
      "epoch:33 step:26089 [D loss: 0.693244, acc.: 54.69%] [G loss: 0.684423]\n",
      "epoch:33 step:26090 [D loss: 0.697049, acc.: 49.22%] [G loss: 0.743967]\n",
      "epoch:33 step:26091 [D loss: 0.633223, acc.: 70.31%] [G loss: 0.694634]\n",
      "epoch:33 step:26092 [D loss: 0.707810, acc.: 49.22%] [G loss: 0.697895]\n",
      "epoch:33 step:26093 [D loss: 0.682339, acc.: 55.47%] [G loss: 0.778215]\n",
      "epoch:33 step:26094 [D loss: 0.647552, acc.: 60.94%] [G loss: 0.778638]\n",
      "epoch:33 step:26095 [D loss: 0.667654, acc.: 61.72%] [G loss: 0.741781]\n",
      "epoch:33 step:26096 [D loss: 0.650338, acc.: 64.06%] [G loss: 0.728756]\n",
      "epoch:33 step:26097 [D loss: 0.686604, acc.: 57.03%] [G loss: 0.710833]\n",
      "epoch:33 step:26098 [D loss: 0.737101, acc.: 40.62%] [G loss: 0.733371]\n",
      "epoch:33 step:26099 [D loss: 0.688952, acc.: 57.03%] [G loss: 0.780414]\n",
      "epoch:33 step:26100 [D loss: 0.708942, acc.: 53.12%] [G loss: 0.878815]\n",
      "epoch:33 step:26101 [D loss: 0.706590, acc.: 56.25%] [G loss: 0.817894]\n",
      "epoch:33 step:26102 [D loss: 0.697874, acc.: 53.12%] [G loss: 0.725625]\n",
      "epoch:33 step:26103 [D loss: 0.753653, acc.: 42.97%] [G loss: 0.726914]\n",
      "epoch:33 step:26104 [D loss: 0.695802, acc.: 51.56%] [G loss: 0.807252]\n",
      "epoch:33 step:26105 [D loss: 0.677409, acc.: 59.38%] [G loss: 0.808232]\n",
      "epoch:33 step:26106 [D loss: 0.633667, acc.: 67.19%] [G loss: 0.811631]\n",
      "epoch:33 step:26107 [D loss: 0.732192, acc.: 45.31%] [G loss: 0.747312]\n",
      "epoch:33 step:26108 [D loss: 0.652838, acc.: 66.41%] [G loss: 0.761790]\n",
      "epoch:33 step:26109 [D loss: 0.653268, acc.: 66.41%] [G loss: 0.823862]\n",
      "epoch:33 step:26110 [D loss: 0.697929, acc.: 53.91%] [G loss: 0.733169]\n",
      "epoch:33 step:26111 [D loss: 0.706552, acc.: 47.66%] [G loss: 0.761277]\n",
      "epoch:33 step:26112 [D loss: 0.671133, acc.: 58.59%] [G loss: 0.786890]\n",
      "epoch:33 step:26113 [D loss: 0.664105, acc.: 59.38%] [G loss: 0.723593]\n",
      "epoch:33 step:26114 [D loss: 0.684523, acc.: 55.47%] [G loss: 0.789116]\n",
      "epoch:33 step:26115 [D loss: 0.621087, acc.: 71.09%] [G loss: 0.766561]\n",
      "epoch:33 step:26116 [D loss: 0.712215, acc.: 50.78%] [G loss: 0.789946]\n",
      "epoch:33 step:26117 [D loss: 0.685986, acc.: 60.94%] [G loss: 0.704208]\n",
      "epoch:33 step:26118 [D loss: 0.625920, acc.: 68.75%] [G loss: 0.676919]\n",
      "epoch:33 step:26119 [D loss: 0.751107, acc.: 39.06%] [G loss: 0.724769]\n",
      "epoch:33 step:26120 [D loss: 0.721067, acc.: 47.66%] [G loss: 0.790404]\n",
      "epoch:33 step:26121 [D loss: 0.715014, acc.: 48.44%] [G loss: 0.842391]\n",
      "epoch:33 step:26122 [D loss: 0.674539, acc.: 53.12%] [G loss: 0.773326]\n",
      "epoch:33 step:26123 [D loss: 0.692987, acc.: 57.81%] [G loss: 0.860242]\n",
      "epoch:33 step:26124 [D loss: 0.644313, acc.: 60.94%] [G loss: 0.758963]\n",
      "epoch:33 step:26125 [D loss: 0.656489, acc.: 59.38%] [G loss: 0.762269]\n",
      "epoch:33 step:26126 [D loss: 0.697544, acc.: 51.56%] [G loss: 0.791995]\n",
      "epoch:33 step:26127 [D loss: 0.658374, acc.: 60.16%] [G loss: 0.761261]\n",
      "epoch:33 step:26128 [D loss: 0.653376, acc.: 60.94%] [G loss: 0.771492]\n",
      "epoch:33 step:26129 [D loss: 0.724738, acc.: 47.66%] [G loss: 0.783340]\n",
      "epoch:33 step:26130 [D loss: 0.702773, acc.: 45.31%] [G loss: 0.777425]\n",
      "epoch:33 step:26131 [D loss: 0.690175, acc.: 56.25%] [G loss: 0.798468]\n",
      "epoch:33 step:26132 [D loss: 0.702062, acc.: 50.78%] [G loss: 0.847328]\n",
      "epoch:33 step:26133 [D loss: 0.643431, acc.: 64.84%] [G loss: 0.775418]\n",
      "epoch:33 step:26134 [D loss: 0.645830, acc.: 67.97%] [G loss: 0.813183]\n",
      "epoch:33 step:26135 [D loss: 0.696029, acc.: 53.91%] [G loss: 0.843695]\n",
      "epoch:33 step:26136 [D loss: 0.690112, acc.: 52.34%] [G loss: 0.722637]\n",
      "epoch:33 step:26137 [D loss: 0.667043, acc.: 64.06%] [G loss: 0.795202]\n",
      "epoch:33 step:26138 [D loss: 0.642560, acc.: 61.72%] [G loss: 0.874265]\n",
      "epoch:33 step:26139 [D loss: 0.633144, acc.: 67.97%] [G loss: 0.745845]\n",
      "epoch:33 step:26140 [D loss: 0.682694, acc.: 59.38%] [G loss: 0.800933]\n",
      "epoch:33 step:26141 [D loss: 0.680253, acc.: 60.94%] [G loss: 0.756623]\n",
      "epoch:33 step:26142 [D loss: 0.659626, acc.: 64.84%] [G loss: 0.802040]\n",
      "epoch:33 step:26143 [D loss: 0.704773, acc.: 54.69%] [G loss: 0.680253]\n",
      "epoch:33 step:26144 [D loss: 0.560683, acc.: 82.03%] [G loss: 0.823621]\n",
      "epoch:33 step:26145 [D loss: 0.711759, acc.: 52.34%] [G loss: 0.758739]\n",
      "epoch:33 step:26146 [D loss: 0.715537, acc.: 45.31%] [G loss: 0.730104]\n",
      "epoch:33 step:26147 [D loss: 0.712362, acc.: 47.66%] [G loss: 0.760346]\n",
      "epoch:33 step:26148 [D loss: 0.710013, acc.: 54.69%] [G loss: 0.777239]\n",
      "epoch:33 step:26149 [D loss: 0.651426, acc.: 60.16%] [G loss: 0.698267]\n",
      "epoch:33 step:26150 [D loss: 0.697041, acc.: 50.78%] [G loss: 0.696766]\n",
      "epoch:33 step:26151 [D loss: 0.745748, acc.: 42.19%] [G loss: 0.701811]\n",
      "epoch:33 step:26152 [D loss: 0.708588, acc.: 50.00%] [G loss: 0.791052]\n",
      "epoch:33 step:26153 [D loss: 0.717346, acc.: 43.75%] [G loss: 0.750180]\n",
      "epoch:33 step:26154 [D loss: 0.750714, acc.: 44.53%] [G loss: 0.759827]\n",
      "epoch:33 step:26155 [D loss: 0.673203, acc.: 55.47%] [G loss: 0.828726]\n",
      "epoch:33 step:26156 [D loss: 0.725498, acc.: 49.22%] [G loss: 0.764938]\n",
      "epoch:33 step:26157 [D loss: 0.675770, acc.: 50.78%] [G loss: 0.785175]\n",
      "epoch:33 step:26158 [D loss: 0.699912, acc.: 47.66%] [G loss: 0.767667]\n",
      "epoch:33 step:26159 [D loss: 0.686885, acc.: 53.12%] [G loss: 0.699484]\n",
      "epoch:33 step:26160 [D loss: 0.629061, acc.: 73.44%] [G loss: 0.814590]\n",
      "epoch:33 step:26161 [D loss: 0.701184, acc.: 49.22%] [G loss: 0.890782]\n",
      "epoch:33 step:26162 [D loss: 0.667016, acc.: 56.25%] [G loss: 0.837582]\n",
      "epoch:33 step:26163 [D loss: 0.602056, acc.: 75.78%] [G loss: 0.834739]\n",
      "epoch:33 step:26164 [D loss: 0.788728, acc.: 29.69%] [G loss: 0.748859]\n",
      "epoch:33 step:26165 [D loss: 0.669045, acc.: 60.16%] [G loss: 0.777873]\n",
      "epoch:33 step:26166 [D loss: 0.701701, acc.: 53.91%] [G loss: 0.708614]\n",
      "epoch:33 step:26167 [D loss: 0.630352, acc.: 68.75%] [G loss: 0.721009]\n",
      "epoch:33 step:26168 [D loss: 0.697667, acc.: 54.69%] [G loss: 0.746097]\n",
      "epoch:33 step:26169 [D loss: 0.668189, acc.: 56.25%] [G loss: 0.732109]\n",
      "epoch:33 step:26170 [D loss: 0.707733, acc.: 44.53%] [G loss: 0.750743]\n",
      "epoch:33 step:26171 [D loss: 0.701573, acc.: 50.78%] [G loss: 0.743482]\n",
      "epoch:33 step:26172 [D loss: 0.664042, acc.: 62.50%] [G loss: 0.723848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26173 [D loss: 0.699239, acc.: 57.81%] [G loss: 0.732259]\n",
      "epoch:33 step:26174 [D loss: 0.652025, acc.: 62.50%] [G loss: 0.720230]\n",
      "epoch:33 step:26175 [D loss: 0.620253, acc.: 70.31%] [G loss: 0.803779]\n",
      "epoch:33 step:26176 [D loss: 0.659223, acc.: 62.50%] [G loss: 0.806253]\n",
      "epoch:33 step:26177 [D loss: 0.652856, acc.: 70.31%] [G loss: 0.785538]\n",
      "epoch:33 step:26178 [D loss: 0.648131, acc.: 67.19%] [G loss: 0.733024]\n",
      "epoch:33 step:26179 [D loss: 0.655325, acc.: 60.94%] [G loss: 0.736239]\n",
      "epoch:33 step:26180 [D loss: 0.758676, acc.: 39.06%] [G loss: 0.669631]\n",
      "epoch:33 step:26181 [D loss: 0.718950, acc.: 45.31%] [G loss: 0.728966]\n",
      "epoch:33 step:26182 [D loss: 0.655968, acc.: 61.72%] [G loss: 0.725490]\n",
      "epoch:33 step:26183 [D loss: 0.678340, acc.: 54.69%] [G loss: 0.764359]\n",
      "epoch:33 step:26184 [D loss: 0.787109, acc.: 35.16%] [G loss: 0.724721]\n",
      "epoch:33 step:26185 [D loss: 0.763028, acc.: 35.16%] [G loss: 0.711129]\n",
      "epoch:33 step:26186 [D loss: 0.729932, acc.: 44.53%] [G loss: 0.783518]\n",
      "epoch:33 step:26187 [D loss: 0.703334, acc.: 50.00%] [G loss: 0.846200]\n",
      "epoch:33 step:26188 [D loss: 0.665512, acc.: 60.16%] [G loss: 0.710440]\n",
      "epoch:33 step:26189 [D loss: 0.701693, acc.: 53.12%] [G loss: 0.762245]\n",
      "epoch:33 step:26190 [D loss: 0.726440, acc.: 49.22%] [G loss: 0.773566]\n",
      "epoch:33 step:26191 [D loss: 0.661733, acc.: 60.94%] [G loss: 0.719163]\n",
      "epoch:33 step:26192 [D loss: 0.701469, acc.: 50.78%] [G loss: 0.709261]\n",
      "epoch:33 step:26193 [D loss: 0.716262, acc.: 50.78%] [G loss: 0.769954]\n",
      "epoch:33 step:26194 [D loss: 0.702401, acc.: 54.69%] [G loss: 0.738676]\n",
      "epoch:33 step:26195 [D loss: 0.736294, acc.: 46.09%] [G loss: 0.720064]\n",
      "epoch:33 step:26196 [D loss: 0.675167, acc.: 57.81%] [G loss: 0.805373]\n",
      "epoch:33 step:26197 [D loss: 0.727586, acc.: 48.44%] [G loss: 0.738627]\n",
      "epoch:33 step:26198 [D loss: 0.634527, acc.: 64.06%] [G loss: 0.819158]\n",
      "epoch:33 step:26199 [D loss: 0.723229, acc.: 46.88%] [G loss: 0.783045]\n",
      "epoch:33 step:26200 [D loss: 0.602472, acc.: 75.78%] [G loss: 0.813629]\n",
      "epoch:33 step:26201 [D loss: 0.678363, acc.: 58.59%] [G loss: 0.805475]\n",
      "epoch:33 step:26202 [D loss: 0.596617, acc.: 75.00%] [G loss: 0.782316]\n",
      "epoch:33 step:26203 [D loss: 0.719317, acc.: 44.53%] [G loss: 0.746439]\n",
      "epoch:33 step:26204 [D loss: 0.635692, acc.: 67.19%] [G loss: 0.829433]\n",
      "epoch:33 step:26205 [D loss: 0.664786, acc.: 59.38%] [G loss: 0.830694]\n",
      "epoch:33 step:26206 [D loss: 0.680008, acc.: 58.59%] [G loss: 0.786975]\n",
      "epoch:33 step:26207 [D loss: 0.713987, acc.: 51.56%] [G loss: 0.809703]\n",
      "epoch:33 step:26208 [D loss: 0.666826, acc.: 56.25%] [G loss: 0.803803]\n",
      "epoch:33 step:26209 [D loss: 0.704538, acc.: 51.56%] [G loss: 0.863548]\n",
      "epoch:33 step:26210 [D loss: 0.722552, acc.: 47.66%] [G loss: 0.743831]\n",
      "epoch:33 step:26211 [D loss: 0.631802, acc.: 65.62%] [G loss: 0.765201]\n",
      "epoch:33 step:26212 [D loss: 0.666752, acc.: 63.28%] [G loss: 0.703370]\n",
      "epoch:33 step:26213 [D loss: 0.719831, acc.: 44.53%] [G loss: 0.747737]\n",
      "epoch:33 step:26214 [D loss: 0.729433, acc.: 49.22%] [G loss: 0.758876]\n",
      "epoch:33 step:26215 [D loss: 0.709462, acc.: 46.88%] [G loss: 0.784239]\n",
      "epoch:33 step:26216 [D loss: 0.723614, acc.: 48.44%] [G loss: 0.764483]\n",
      "epoch:33 step:26217 [D loss: 0.654017, acc.: 59.38%] [G loss: 0.794479]\n",
      "epoch:33 step:26218 [D loss: 0.753699, acc.: 35.16%] [G loss: 0.762969]\n",
      "epoch:33 step:26219 [D loss: 0.702587, acc.: 50.00%] [G loss: 0.728442]\n",
      "epoch:33 step:26220 [D loss: 0.704618, acc.: 52.34%] [G loss: 0.756566]\n",
      "epoch:33 step:26221 [D loss: 0.685460, acc.: 54.69%] [G loss: 0.796063]\n",
      "epoch:33 step:26222 [D loss: 0.662649, acc.: 57.81%] [G loss: 0.757774]\n",
      "epoch:33 step:26223 [D loss: 0.676926, acc.: 60.94%] [G loss: 0.814861]\n",
      "epoch:33 step:26224 [D loss: 0.684894, acc.: 51.56%] [G loss: 0.776441]\n",
      "epoch:33 step:26225 [D loss: 0.693493, acc.: 56.25%] [G loss: 0.839480]\n",
      "epoch:33 step:26226 [D loss: 0.692754, acc.: 52.34%] [G loss: 0.821838]\n",
      "epoch:33 step:26227 [D loss: 0.680213, acc.: 58.59%] [G loss: 0.846090]\n",
      "epoch:33 step:26228 [D loss: 0.695509, acc.: 54.69%] [G loss: 0.751356]\n",
      "epoch:33 step:26229 [D loss: 0.700261, acc.: 56.25%] [G loss: 0.784352]\n",
      "epoch:33 step:26230 [D loss: 0.653883, acc.: 66.41%] [G loss: 0.794877]\n",
      "epoch:33 step:26231 [D loss: 0.668629, acc.: 54.69%] [G loss: 0.796701]\n",
      "epoch:33 step:26232 [D loss: 0.734150, acc.: 43.75%] [G loss: 0.786171]\n",
      "epoch:33 step:26233 [D loss: 0.712410, acc.: 51.56%] [G loss: 0.753297]\n",
      "epoch:33 step:26234 [D loss: 0.711970, acc.: 47.66%] [G loss: 0.822473]\n",
      "epoch:33 step:26235 [D loss: 0.668886, acc.: 56.25%] [G loss: 0.832164]\n",
      "epoch:33 step:26236 [D loss: 0.717554, acc.: 47.66%] [G loss: 0.750842]\n",
      "epoch:33 step:26237 [D loss: 0.664178, acc.: 60.94%] [G loss: 0.789789]\n",
      "epoch:33 step:26238 [D loss: 0.643142, acc.: 67.97%] [G loss: 0.802713]\n",
      "epoch:33 step:26239 [D loss: 0.655822, acc.: 58.59%] [G loss: 0.843779]\n",
      "epoch:33 step:26240 [D loss: 0.685519, acc.: 57.81%] [G loss: 0.826954]\n",
      "epoch:33 step:26241 [D loss: 0.694131, acc.: 53.91%] [G loss: 0.768967]\n",
      "epoch:33 step:26242 [D loss: 0.652970, acc.: 65.62%] [G loss: 0.852608]\n",
      "epoch:33 step:26243 [D loss: 0.694792, acc.: 53.12%] [G loss: 0.798714]\n",
      "epoch:33 step:26244 [D loss: 0.741823, acc.: 39.84%] [G loss: 0.833029]\n",
      "epoch:33 step:26245 [D loss: 0.706847, acc.: 57.03%] [G loss: 0.730285]\n",
      "epoch:33 step:26246 [D loss: 0.700870, acc.: 56.25%] [G loss: 0.794537]\n",
      "epoch:33 step:26247 [D loss: 0.696219, acc.: 52.34%] [G loss: 0.735820]\n",
      "epoch:33 step:26248 [D loss: 0.653963, acc.: 62.50%] [G loss: 0.759094]\n",
      "epoch:33 step:26249 [D loss: 0.642878, acc.: 68.75%] [G loss: 0.786475]\n",
      "epoch:33 step:26250 [D loss: 0.719541, acc.: 51.56%] [G loss: 0.754291]\n",
      "epoch:33 step:26251 [D loss: 0.640654, acc.: 66.41%] [G loss: 0.816167]\n",
      "epoch:33 step:26252 [D loss: 0.639192, acc.: 68.75%] [G loss: 0.869462]\n",
      "epoch:33 step:26253 [D loss: 0.626380, acc.: 69.53%] [G loss: 0.799062]\n",
      "epoch:33 step:26254 [D loss: 0.693100, acc.: 58.59%] [G loss: 0.819745]\n",
      "epoch:33 step:26255 [D loss: 0.733569, acc.: 42.19%] [G loss: 0.765212]\n",
      "epoch:33 step:26256 [D loss: 0.691870, acc.: 57.81%] [G loss: 0.765689]\n",
      "epoch:33 step:26257 [D loss: 0.722206, acc.: 41.41%] [G loss: 0.775182]\n",
      "epoch:33 step:26258 [D loss: 0.686088, acc.: 53.91%] [G loss: 0.717594]\n",
      "epoch:33 step:26259 [D loss: 0.695974, acc.: 55.47%] [G loss: 0.724570]\n",
      "epoch:33 step:26260 [D loss: 0.738522, acc.: 43.75%] [G loss: 0.742464]\n",
      "epoch:33 step:26261 [D loss: 0.710519, acc.: 48.44%] [G loss: 0.762468]\n",
      "epoch:33 step:26262 [D loss: 0.745601, acc.: 38.28%] [G loss: 0.675323]\n",
      "epoch:33 step:26263 [D loss: 0.671352, acc.: 57.81%] [G loss: 0.774669]\n",
      "epoch:33 step:26264 [D loss: 0.672476, acc.: 53.12%] [G loss: 0.734097]\n",
      "epoch:33 step:26265 [D loss: 0.690444, acc.: 51.56%] [G loss: 0.797112]\n",
      "epoch:33 step:26266 [D loss: 0.697806, acc.: 58.59%] [G loss: 0.737716]\n",
      "epoch:33 step:26267 [D loss: 0.668896, acc.: 58.59%] [G loss: 0.751555]\n",
      "epoch:33 step:26268 [D loss: 0.638626, acc.: 67.19%] [G loss: 0.776280]\n",
      "epoch:33 step:26269 [D loss: 0.697104, acc.: 53.12%] [G loss: 0.814558]\n",
      "epoch:33 step:26270 [D loss: 0.696015, acc.: 51.56%] [G loss: 0.810476]\n",
      "epoch:33 step:26271 [D loss: 0.671753, acc.: 56.25%] [G loss: 0.787953]\n",
      "epoch:33 step:26272 [D loss: 0.634763, acc.: 69.53%] [G loss: 0.755776]\n",
      "epoch:33 step:26273 [D loss: 0.701763, acc.: 50.78%] [G loss: 0.749278]\n",
      "epoch:33 step:26274 [D loss: 0.698789, acc.: 51.56%] [G loss: 0.797672]\n",
      "epoch:33 step:26275 [D loss: 0.698376, acc.: 55.47%] [G loss: 0.821500]\n",
      "epoch:33 step:26276 [D loss: 0.702532, acc.: 53.91%] [G loss: 0.745195]\n",
      "epoch:33 step:26277 [D loss: 0.689788, acc.: 48.44%] [G loss: 0.726702]\n",
      "epoch:33 step:26278 [D loss: 0.694161, acc.: 57.03%] [G loss: 0.798940]\n",
      "epoch:33 step:26279 [D loss: 0.672213, acc.: 59.38%] [G loss: 0.843245]\n",
      "epoch:33 step:26280 [D loss: 0.697377, acc.: 50.78%] [G loss: 0.786787]\n",
      "epoch:33 step:26281 [D loss: 0.740331, acc.: 46.09%] [G loss: 0.698902]\n",
      "epoch:33 step:26282 [D loss: 0.679716, acc.: 55.47%] [G loss: 0.766563]\n",
      "epoch:33 step:26283 [D loss: 0.702842, acc.: 45.31%] [G loss: 0.733244]\n",
      "epoch:33 step:26284 [D loss: 0.640881, acc.: 66.41%] [G loss: 0.811523]\n",
      "epoch:33 step:26285 [D loss: 0.705056, acc.: 50.00%] [G loss: 0.738634]\n",
      "epoch:33 step:26286 [D loss: 0.742612, acc.: 39.84%] [G loss: 0.766999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26287 [D loss: 0.798593, acc.: 36.72%] [G loss: 0.732059]\n",
      "epoch:33 step:26288 [D loss: 0.704175, acc.: 55.47%] [G loss: 0.778723]\n",
      "epoch:33 step:26289 [D loss: 0.651058, acc.: 60.94%] [G loss: 0.767162]\n",
      "epoch:33 step:26290 [D loss: 0.666221, acc.: 60.16%] [G loss: 0.768956]\n",
      "epoch:33 step:26291 [D loss: 0.669454, acc.: 60.94%] [G loss: 0.807238]\n",
      "epoch:33 step:26292 [D loss: 0.724194, acc.: 45.31%] [G loss: 0.760934]\n",
      "epoch:33 step:26293 [D loss: 0.733131, acc.: 42.19%] [G loss: 0.736888]\n",
      "epoch:33 step:26294 [D loss: 0.660995, acc.: 57.03%] [G loss: 0.844164]\n",
      "epoch:33 step:26295 [D loss: 0.692214, acc.: 53.12%] [G loss: 0.742686]\n",
      "epoch:33 step:26296 [D loss: 0.723709, acc.: 42.97%] [G loss: 0.772207]\n",
      "epoch:33 step:26297 [D loss: 0.727604, acc.: 44.53%] [G loss: 0.790975]\n",
      "epoch:33 step:26298 [D loss: 0.608441, acc.: 72.66%] [G loss: 0.810225]\n",
      "epoch:33 step:26299 [D loss: 0.769786, acc.: 39.06%] [G loss: 0.725480]\n",
      "epoch:33 step:26300 [D loss: 0.687140, acc.: 57.03%] [G loss: 0.745505]\n",
      "epoch:33 step:26301 [D loss: 0.734328, acc.: 42.19%] [G loss: 0.692178]\n",
      "epoch:33 step:26302 [D loss: 0.626931, acc.: 67.19%] [G loss: 0.731323]\n",
      "epoch:33 step:26303 [D loss: 0.652833, acc.: 60.94%] [G loss: 0.681913]\n",
      "epoch:33 step:26304 [D loss: 0.643213, acc.: 68.75%] [G loss: 0.778993]\n",
      "epoch:33 step:26305 [D loss: 0.679245, acc.: 53.91%] [G loss: 0.752637]\n",
      "epoch:33 step:26306 [D loss: 0.698315, acc.: 49.22%] [G loss: 0.781340]\n",
      "epoch:33 step:26307 [D loss: 0.693260, acc.: 50.00%] [G loss: 0.771702]\n",
      "epoch:33 step:26308 [D loss: 0.658935, acc.: 65.62%] [G loss: 0.761537]\n",
      "epoch:33 step:26309 [D loss: 0.663040, acc.: 62.50%] [G loss: 0.746543]\n",
      "epoch:33 step:26310 [D loss: 0.690334, acc.: 53.91%] [G loss: 0.810124]\n",
      "epoch:33 step:26311 [D loss: 0.652111, acc.: 64.84%] [G loss: 0.753879]\n",
      "epoch:33 step:26312 [D loss: 0.660104, acc.: 63.28%] [G loss: 0.775981]\n",
      "epoch:33 step:26313 [D loss: 0.705077, acc.: 52.34%] [G loss: 0.769727]\n",
      "epoch:33 step:26314 [D loss: 0.650257, acc.: 61.72%] [G loss: 0.710207]\n",
      "epoch:33 step:26315 [D loss: 0.677812, acc.: 55.47%] [G loss: 0.769794]\n",
      "epoch:33 step:26316 [D loss: 0.724702, acc.: 51.56%] [G loss: 0.670521]\n",
      "epoch:33 step:26317 [D loss: 0.692058, acc.: 57.03%] [G loss: 0.788282]\n",
      "epoch:33 step:26318 [D loss: 0.675898, acc.: 55.47%] [G loss: 0.709881]\n",
      "epoch:33 step:26319 [D loss: 0.776096, acc.: 38.28%] [G loss: 0.771292]\n",
      "epoch:33 step:26320 [D loss: 0.692206, acc.: 57.03%] [G loss: 0.791896]\n",
      "epoch:33 step:26321 [D loss: 0.696749, acc.: 54.69%] [G loss: 0.737112]\n",
      "epoch:33 step:26322 [D loss: 0.708412, acc.: 46.88%] [G loss: 0.730504]\n",
      "epoch:33 step:26323 [D loss: 0.688141, acc.: 51.56%] [G loss: 0.743747]\n",
      "epoch:33 step:26324 [D loss: 0.655537, acc.: 61.72%] [G loss: 0.818412]\n",
      "epoch:33 step:26325 [D loss: 0.687048, acc.: 53.12%] [G loss: 0.763400]\n",
      "epoch:33 step:26326 [D loss: 0.673924, acc.: 57.03%] [G loss: 0.885854]\n",
      "epoch:33 step:26327 [D loss: 0.678332, acc.: 57.03%] [G loss: 0.723721]\n",
      "epoch:33 step:26328 [D loss: 0.664406, acc.: 58.59%] [G loss: 0.809968]\n",
      "epoch:33 step:26329 [D loss: 0.730466, acc.: 47.66%] [G loss: 0.814445]\n",
      "epoch:33 step:26330 [D loss: 0.706052, acc.: 53.12%] [G loss: 0.694087]\n",
      "epoch:33 step:26331 [D loss: 0.650194, acc.: 66.41%] [G loss: 0.815750]\n",
      "epoch:33 step:26332 [D loss: 0.649353, acc.: 71.09%] [G loss: 0.740240]\n",
      "epoch:33 step:26333 [D loss: 0.673027, acc.: 59.38%] [G loss: 0.818430]\n",
      "epoch:33 step:26334 [D loss: 0.655561, acc.: 66.41%] [G loss: 0.833500]\n",
      "epoch:33 step:26335 [D loss: 0.667849, acc.: 53.91%] [G loss: 0.768070]\n",
      "epoch:33 step:26336 [D loss: 0.681762, acc.: 58.59%] [G loss: 0.737311]\n",
      "epoch:33 step:26337 [D loss: 0.668620, acc.: 57.81%] [G loss: 0.767816]\n",
      "epoch:33 step:26338 [D loss: 0.681683, acc.: 59.38%] [G loss: 0.788670]\n",
      "epoch:33 step:26339 [D loss: 0.697235, acc.: 46.09%] [G loss: 0.698590]\n",
      "epoch:33 step:26340 [D loss: 0.662300, acc.: 60.94%] [G loss: 0.804414]\n",
      "epoch:33 step:26341 [D loss: 0.770151, acc.: 38.28%] [G loss: 0.753820]\n",
      "epoch:33 step:26342 [D loss: 0.690150, acc.: 51.56%] [G loss: 0.728801]\n",
      "epoch:33 step:26343 [D loss: 0.618080, acc.: 74.22%] [G loss: 0.778312]\n",
      "epoch:33 step:26344 [D loss: 0.755711, acc.: 32.03%] [G loss: 0.798342]\n",
      "epoch:33 step:26345 [D loss: 0.661193, acc.: 62.50%] [G loss: 0.762431]\n",
      "epoch:33 step:26346 [D loss: 0.730366, acc.: 47.66%] [G loss: 0.803949]\n",
      "epoch:33 step:26347 [D loss: 0.717035, acc.: 51.56%] [G loss: 0.726276]\n",
      "epoch:33 step:26348 [D loss: 0.680000, acc.: 54.69%] [G loss: 0.710221]\n",
      "epoch:33 step:26349 [D loss: 0.619341, acc.: 71.09%] [G loss: 0.726718]\n",
      "epoch:33 step:26350 [D loss: 0.682307, acc.: 55.47%] [G loss: 0.686248]\n",
      "epoch:33 step:26351 [D loss: 0.694745, acc.: 59.38%] [G loss: 0.775839]\n",
      "epoch:33 step:26352 [D loss: 0.659754, acc.: 64.06%] [G loss: 0.720604]\n",
      "epoch:33 step:26353 [D loss: 0.716595, acc.: 45.31%] [G loss: 0.742650]\n",
      "epoch:33 step:26354 [D loss: 0.645154, acc.: 61.72%] [G loss: 0.753206]\n",
      "epoch:33 step:26355 [D loss: 0.651119, acc.: 64.84%] [G loss: 0.856644]\n",
      "epoch:33 step:26356 [D loss: 0.667049, acc.: 53.12%] [G loss: 0.734534]\n",
      "epoch:33 step:26357 [D loss: 0.676057, acc.: 57.81%] [G loss: 0.749058]\n",
      "epoch:33 step:26358 [D loss: 0.671441, acc.: 60.94%] [G loss: 0.770774]\n",
      "epoch:33 step:26359 [D loss: 0.662332, acc.: 62.50%] [G loss: 0.829048]\n",
      "epoch:33 step:26360 [D loss: 0.677827, acc.: 59.38%] [G loss: 0.743710]\n",
      "epoch:33 step:26361 [D loss: 0.682208, acc.: 55.47%] [G loss: 0.784894]\n",
      "epoch:33 step:26362 [D loss: 0.643046, acc.: 61.72%] [G loss: 0.770921]\n",
      "epoch:33 step:26363 [D loss: 0.733292, acc.: 46.09%] [G loss: 0.725411]\n",
      "epoch:33 step:26364 [D loss: 0.700057, acc.: 49.22%] [G loss: 0.815088]\n",
      "epoch:33 step:26365 [D loss: 0.686265, acc.: 52.34%] [G loss: 0.826505]\n",
      "epoch:33 step:26366 [D loss: 0.740937, acc.: 45.31%] [G loss: 0.860822]\n",
      "epoch:33 step:26367 [D loss: 0.646382, acc.: 60.94%] [G loss: 0.908735]\n",
      "epoch:33 step:26368 [D loss: 0.651150, acc.: 64.84%] [G loss: 0.867996]\n",
      "epoch:33 step:26369 [D loss: 0.679448, acc.: 54.69%] [G loss: 0.850098]\n",
      "epoch:33 step:26370 [D loss: 0.694937, acc.: 56.25%] [G loss: 0.747220]\n",
      "epoch:33 step:26371 [D loss: 0.722830, acc.: 48.44%] [G loss: 0.748281]\n",
      "epoch:33 step:26372 [D loss: 0.716414, acc.: 47.66%] [G loss: 0.769531]\n",
      "epoch:33 step:26373 [D loss: 0.683453, acc.: 60.94%] [G loss: 0.770629]\n",
      "epoch:33 step:26374 [D loss: 0.671324, acc.: 57.03%] [G loss: 0.770060]\n",
      "epoch:33 step:26375 [D loss: 0.655548, acc.: 65.62%] [G loss: 0.785637]\n",
      "epoch:33 step:26376 [D loss: 0.717232, acc.: 50.00%] [G loss: 0.776646]\n",
      "epoch:33 step:26377 [D loss: 0.679654, acc.: 56.25%] [G loss: 0.785921]\n",
      "epoch:33 step:26378 [D loss: 0.671592, acc.: 60.94%] [G loss: 0.759912]\n",
      "epoch:33 step:26379 [D loss: 0.692899, acc.: 55.47%] [G loss: 0.706226]\n",
      "epoch:33 step:26380 [D loss: 0.680651, acc.: 53.12%] [G loss: 0.693726]\n",
      "epoch:33 step:26381 [D loss: 0.648996, acc.: 67.97%] [G loss: 0.737346]\n",
      "epoch:33 step:26382 [D loss: 0.681020, acc.: 61.72%] [G loss: 0.767983]\n",
      "epoch:33 step:26383 [D loss: 0.693533, acc.: 53.12%] [G loss: 0.802168]\n",
      "epoch:33 step:26384 [D loss: 0.633080, acc.: 61.72%] [G loss: 0.838276]\n",
      "epoch:33 step:26385 [D loss: 0.691005, acc.: 53.12%] [G loss: 0.788810]\n",
      "epoch:33 step:26386 [D loss: 0.767620, acc.: 41.41%] [G loss: 0.785651]\n",
      "epoch:33 step:26387 [D loss: 0.682691, acc.: 57.81%] [G loss: 0.743645]\n",
      "epoch:33 step:26388 [D loss: 0.676464, acc.: 60.16%] [G loss: 0.794377]\n",
      "epoch:33 step:26389 [D loss: 0.665878, acc.: 57.03%] [G loss: 0.823356]\n",
      "epoch:33 step:26390 [D loss: 0.665135, acc.: 57.03%] [G loss: 0.729388]\n",
      "epoch:33 step:26391 [D loss: 0.645192, acc.: 69.53%] [G loss: 0.833072]\n",
      "epoch:33 step:26392 [D loss: 0.639527, acc.: 60.94%] [G loss: 0.821661]\n",
      "epoch:33 step:26393 [D loss: 0.627092, acc.: 71.88%] [G loss: 0.789328]\n",
      "epoch:33 step:26394 [D loss: 0.667715, acc.: 60.16%] [G loss: 0.767648]\n",
      "epoch:33 step:26395 [D loss: 0.686130, acc.: 57.03%] [G loss: 0.829059]\n",
      "epoch:33 step:26396 [D loss: 0.665698, acc.: 58.59%] [G loss: 0.769527]\n",
      "epoch:33 step:26397 [D loss: 0.662882, acc.: 63.28%] [G loss: 0.765392]\n",
      "epoch:33 step:26398 [D loss: 0.652970, acc.: 59.38%] [G loss: 0.796205]\n",
      "epoch:33 step:26399 [D loss: 0.697186, acc.: 50.00%] [G loss: 0.760905]\n",
      "epoch:33 step:26400 [D loss: 0.740793, acc.: 38.28%] [G loss: 0.816277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26401 [D loss: 0.683655, acc.: 55.47%] [G loss: 0.790381]\n",
      "epoch:33 step:26402 [D loss: 0.692982, acc.: 53.12%] [G loss: 0.797602]\n",
      "epoch:33 step:26403 [D loss: 0.684596, acc.: 56.25%] [G loss: 0.798031]\n",
      "epoch:33 step:26404 [D loss: 0.696789, acc.: 52.34%] [G loss: 0.803013]\n",
      "epoch:33 step:26405 [D loss: 0.720475, acc.: 49.22%] [G loss: 0.773017]\n",
      "epoch:33 step:26406 [D loss: 0.736578, acc.: 46.09%] [G loss: 0.747271]\n",
      "epoch:33 step:26407 [D loss: 0.687954, acc.: 58.59%] [G loss: 0.760762]\n",
      "epoch:33 step:26408 [D loss: 0.733698, acc.: 40.62%] [G loss: 0.745938]\n",
      "epoch:33 step:26409 [D loss: 0.689133, acc.: 53.12%] [G loss: 0.761757]\n",
      "epoch:33 step:26410 [D loss: 0.730397, acc.: 37.50%] [G loss: 0.775205]\n",
      "epoch:33 step:26411 [D loss: 0.692040, acc.: 51.56%] [G loss: 0.708943]\n",
      "epoch:33 step:26412 [D loss: 0.724746, acc.: 46.88%] [G loss: 0.809147]\n",
      "epoch:33 step:26413 [D loss: 0.681302, acc.: 51.56%] [G loss: 0.778433]\n",
      "epoch:33 step:26414 [D loss: 0.719012, acc.: 52.34%] [G loss: 0.712270]\n",
      "epoch:33 step:26415 [D loss: 0.688738, acc.: 51.56%] [G loss: 0.830014]\n",
      "epoch:33 step:26416 [D loss: 0.697471, acc.: 53.12%] [G loss: 0.700270]\n",
      "epoch:33 step:26417 [D loss: 0.655232, acc.: 67.19%] [G loss: 0.794237]\n",
      "epoch:33 step:26418 [D loss: 0.639522, acc.: 66.41%] [G loss: 0.904574]\n",
      "epoch:33 step:26419 [D loss: 0.698726, acc.: 52.34%] [G loss: 0.748537]\n",
      "epoch:33 step:26420 [D loss: 0.715919, acc.: 45.31%] [G loss: 0.757580]\n",
      "epoch:33 step:26421 [D loss: 0.684944, acc.: 57.03%] [G loss: 0.795485]\n",
      "epoch:33 step:26422 [D loss: 0.698400, acc.: 56.25%] [G loss: 0.755204]\n",
      "epoch:33 step:26423 [D loss: 0.712678, acc.: 53.91%] [G loss: 0.762183]\n",
      "epoch:33 step:26424 [D loss: 0.703676, acc.: 48.44%] [G loss: 0.749620]\n",
      "epoch:33 step:26425 [D loss: 0.595437, acc.: 74.22%] [G loss: 0.784285]\n",
      "epoch:33 step:26426 [D loss: 0.650438, acc.: 56.25%] [G loss: 0.791070]\n",
      "epoch:33 step:26427 [D loss: 0.685680, acc.: 54.69%] [G loss: 0.755440]\n",
      "epoch:33 step:26428 [D loss: 0.666739, acc.: 54.69%] [G loss: 0.753613]\n",
      "epoch:33 step:26429 [D loss: 0.689312, acc.: 57.81%] [G loss: 0.781643]\n",
      "epoch:33 step:26430 [D loss: 0.699188, acc.: 50.78%] [G loss: 0.747983]\n",
      "epoch:33 step:26431 [D loss: 0.722192, acc.: 44.53%] [G loss: 0.709340]\n",
      "epoch:33 step:26432 [D loss: 0.685218, acc.: 51.56%] [G loss: 0.761036]\n",
      "epoch:33 step:26433 [D loss: 0.674331, acc.: 56.25%] [G loss: 0.786973]\n",
      "epoch:33 step:26434 [D loss: 0.671942, acc.: 57.81%] [G loss: 0.792307]\n",
      "epoch:33 step:26435 [D loss: 0.655928, acc.: 63.28%] [G loss: 0.831967]\n",
      "epoch:33 step:26436 [D loss: 0.673748, acc.: 51.56%] [G loss: 0.837951]\n",
      "epoch:33 step:26437 [D loss: 0.718587, acc.: 45.31%] [G loss: 0.777003]\n",
      "epoch:33 step:26438 [D loss: 0.698192, acc.: 53.91%] [G loss: 0.723379]\n",
      "epoch:33 step:26439 [D loss: 0.668239, acc.: 67.19%] [G loss: 0.785550]\n",
      "epoch:33 step:26440 [D loss: 0.715944, acc.: 44.53%] [G loss: 0.749203]\n",
      "epoch:33 step:26441 [D loss: 0.731304, acc.: 46.88%] [G loss: 0.772260]\n",
      "epoch:33 step:26442 [D loss: 0.674731, acc.: 54.69%] [G loss: 0.795761]\n",
      "epoch:33 step:26443 [D loss: 0.704501, acc.: 53.12%] [G loss: 0.811525]\n",
      "epoch:33 step:26444 [D loss: 0.712930, acc.: 46.09%] [G loss: 0.798903]\n",
      "epoch:33 step:26445 [D loss: 0.654980, acc.: 65.62%] [G loss: 0.763270]\n",
      "epoch:33 step:26446 [D loss: 0.635912, acc.: 75.00%] [G loss: 0.837442]\n",
      "epoch:33 step:26447 [D loss: 0.712837, acc.: 50.00%] [G loss: 0.766724]\n",
      "epoch:33 step:26448 [D loss: 0.718324, acc.: 43.75%] [G loss: 0.744761]\n",
      "epoch:33 step:26449 [D loss: 0.684329, acc.: 53.12%] [G loss: 0.821250]\n",
      "epoch:33 step:26450 [D loss: 0.668857, acc.: 54.69%] [G loss: 0.790052]\n",
      "epoch:33 step:26451 [D loss: 0.729014, acc.: 43.75%] [G loss: 0.851857]\n",
      "epoch:33 step:26452 [D loss: 0.649438, acc.: 60.16%] [G loss: 0.822395]\n",
      "epoch:33 step:26453 [D loss: 0.666664, acc.: 60.94%] [G loss: 0.771969]\n",
      "epoch:33 step:26454 [D loss: 0.682020, acc.: 53.91%] [G loss: 0.832747]\n",
      "epoch:33 step:26455 [D loss: 0.687214, acc.: 56.25%] [G loss: 0.709341]\n",
      "epoch:33 step:26456 [D loss: 0.758077, acc.: 38.28%] [G loss: 0.713645]\n",
      "epoch:33 step:26457 [D loss: 0.704292, acc.: 48.44%] [G loss: 0.777873]\n",
      "epoch:33 step:26458 [D loss: 0.652667, acc.: 60.16%] [G loss: 0.775554]\n",
      "epoch:33 step:26459 [D loss: 0.669445, acc.: 53.91%] [G loss: 0.761183]\n",
      "epoch:33 step:26460 [D loss: 0.650513, acc.: 71.09%] [G loss: 0.766890]\n",
      "epoch:33 step:26461 [D loss: 0.689766, acc.: 50.00%] [G loss: 0.776604]\n",
      "epoch:33 step:26462 [D loss: 0.663389, acc.: 60.94%] [G loss: 0.747918]\n",
      "epoch:33 step:26463 [D loss: 0.622552, acc.: 70.31%] [G loss: 0.832573]\n",
      "epoch:33 step:26464 [D loss: 0.699947, acc.: 48.44%] [G loss: 0.709566]\n",
      "epoch:33 step:26465 [D loss: 0.739485, acc.: 39.84%] [G loss: 0.711198]\n",
      "epoch:33 step:26466 [D loss: 0.667368, acc.: 57.03%] [G loss: 0.724954]\n",
      "epoch:33 step:26467 [D loss: 0.732623, acc.: 43.75%] [G loss: 0.725532]\n",
      "epoch:33 step:26468 [D loss: 0.621406, acc.: 72.66%] [G loss: 0.790704]\n",
      "epoch:33 step:26469 [D loss: 0.704304, acc.: 49.22%] [G loss: 0.823753]\n",
      "epoch:33 step:26470 [D loss: 0.715028, acc.: 48.44%] [G loss: 0.744221]\n",
      "epoch:33 step:26471 [D loss: 0.729874, acc.: 46.09%] [G loss: 0.717167]\n",
      "epoch:33 step:26472 [D loss: 0.689640, acc.: 53.12%] [G loss: 0.771346]\n",
      "epoch:33 step:26473 [D loss: 0.676997, acc.: 57.03%] [G loss: 0.769841]\n",
      "epoch:33 step:26474 [D loss: 0.715315, acc.: 50.00%] [G loss: 0.772335]\n",
      "epoch:33 step:26475 [D loss: 0.669096, acc.: 61.72%] [G loss: 0.825801]\n",
      "epoch:33 step:26476 [D loss: 0.706933, acc.: 50.78%] [G loss: 0.720136]\n",
      "epoch:33 step:26477 [D loss: 0.689297, acc.: 57.81%] [G loss: 0.682774]\n",
      "epoch:33 step:26478 [D loss: 0.691842, acc.: 50.78%] [G loss: 0.777828]\n",
      "epoch:33 step:26479 [D loss: 0.675634, acc.: 58.59%] [G loss: 0.827108]\n",
      "epoch:33 step:26480 [D loss: 0.699865, acc.: 50.00%] [G loss: 0.842618]\n",
      "epoch:33 step:26481 [D loss: 0.657206, acc.: 64.84%] [G loss: 0.784897]\n",
      "epoch:33 step:26482 [D loss: 0.601369, acc.: 77.34%] [G loss: 0.792569]\n",
      "epoch:33 step:26483 [D loss: 0.664564, acc.: 65.62%] [G loss: 0.784436]\n",
      "epoch:33 step:26484 [D loss: 0.673747, acc.: 60.16%] [G loss: 0.780676]\n",
      "epoch:33 step:26485 [D loss: 0.650574, acc.: 67.19%] [G loss: 0.808622]\n",
      "epoch:33 step:26486 [D loss: 0.677440, acc.: 57.81%] [G loss: 0.841289]\n",
      "epoch:33 step:26487 [D loss: 0.641311, acc.: 67.19%] [G loss: 0.803717]\n",
      "epoch:33 step:26488 [D loss: 0.689173, acc.: 53.91%] [G loss: 0.776093]\n",
      "epoch:33 step:26489 [D loss: 0.686639, acc.: 57.03%] [G loss: 0.694986]\n",
      "epoch:33 step:26490 [D loss: 0.708644, acc.: 50.00%] [G loss: 0.744892]\n",
      "epoch:33 step:26491 [D loss: 0.636116, acc.: 63.28%] [G loss: 0.748763]\n",
      "epoch:33 step:26492 [D loss: 0.751194, acc.: 42.97%] [G loss: 0.784756]\n",
      "epoch:33 step:26493 [D loss: 0.703254, acc.: 49.22%] [G loss: 0.835337]\n",
      "epoch:33 step:26494 [D loss: 0.756936, acc.: 37.50%] [G loss: 0.727245]\n",
      "epoch:33 step:26495 [D loss: 0.669651, acc.: 54.69%] [G loss: 0.805080]\n",
      "epoch:33 step:26496 [D loss: 0.761483, acc.: 42.19%] [G loss: 0.698557]\n",
      "epoch:33 step:26497 [D loss: 0.657763, acc.: 65.62%] [G loss: 0.761616]\n",
      "epoch:33 step:26498 [D loss: 0.693889, acc.: 55.47%] [G loss: 0.756653]\n",
      "epoch:33 step:26499 [D loss: 0.626412, acc.: 71.09%] [G loss: 0.754974]\n",
      "epoch:33 step:26500 [D loss: 0.748499, acc.: 43.75%] [G loss: 0.698600]\n",
      "epoch:33 step:26501 [D loss: 0.705180, acc.: 48.44%] [G loss: 0.751910]\n",
      "epoch:33 step:26502 [D loss: 0.715320, acc.: 55.47%] [G loss: 0.700441]\n",
      "epoch:33 step:26503 [D loss: 0.701329, acc.: 50.00%] [G loss: 0.678564]\n",
      "epoch:33 step:26504 [D loss: 0.698509, acc.: 53.12%] [G loss: 0.715957]\n",
      "epoch:33 step:26505 [D loss: 0.758901, acc.: 39.84%] [G loss: 0.797900]\n",
      "epoch:33 step:26506 [D loss: 0.677368, acc.: 60.94%] [G loss: 0.741929]\n",
      "epoch:33 step:26507 [D loss: 0.691388, acc.: 51.56%] [G loss: 0.742329]\n",
      "epoch:33 step:26508 [D loss: 0.659793, acc.: 60.16%] [G loss: 0.747216]\n",
      "epoch:33 step:26509 [D loss: 0.705262, acc.: 50.00%] [G loss: 0.805484]\n",
      "epoch:33 step:26510 [D loss: 0.686091, acc.: 59.38%] [G loss: 0.772666]\n",
      "epoch:33 step:26511 [D loss: 0.646475, acc.: 61.72%] [G loss: 0.876527]\n",
      "epoch:33 step:26512 [D loss: 0.704824, acc.: 53.91%] [G loss: 0.794646]\n",
      "epoch:33 step:26513 [D loss: 0.671852, acc.: 55.47%] [G loss: 0.905658]\n",
      "epoch:33 step:26514 [D loss: 0.660747, acc.: 61.72%] [G loss: 0.813475]\n",
      "epoch:33 step:26515 [D loss: 0.680791, acc.: 61.72%] [G loss: 0.782575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26516 [D loss: 0.659036, acc.: 63.28%] [G loss: 0.711788]\n",
      "epoch:33 step:26517 [D loss: 0.649070, acc.: 64.84%] [G loss: 0.718241]\n",
      "epoch:33 step:26518 [D loss: 0.715694, acc.: 50.78%] [G loss: 0.833015]\n",
      "epoch:33 step:26519 [D loss: 0.717313, acc.: 50.78%] [G loss: 0.740194]\n",
      "epoch:33 step:26520 [D loss: 0.691347, acc.: 54.69%] [G loss: 0.722388]\n",
      "epoch:33 step:26521 [D loss: 0.665781, acc.: 60.16%] [G loss: 0.772611]\n",
      "epoch:33 step:26522 [D loss: 0.703450, acc.: 51.56%] [G loss: 0.787988]\n",
      "epoch:33 step:26523 [D loss: 0.762106, acc.: 42.19%] [G loss: 0.720065]\n",
      "epoch:33 step:26524 [D loss: 0.669111, acc.: 60.16%] [G loss: 0.777418]\n",
      "epoch:33 step:26525 [D loss: 0.719674, acc.: 46.09%] [G loss: 0.748916]\n",
      "epoch:33 step:26526 [D loss: 0.658158, acc.: 62.50%] [G loss: 0.786955]\n",
      "epoch:33 step:26527 [D loss: 0.669234, acc.: 61.72%] [G loss: 0.877616]\n",
      "epoch:33 step:26528 [D loss: 0.634388, acc.: 64.06%] [G loss: 0.841470]\n",
      "epoch:33 step:26529 [D loss: 0.681549, acc.: 55.47%] [G loss: 0.730065]\n",
      "epoch:33 step:26530 [D loss: 0.664730, acc.: 57.03%] [G loss: 0.856248]\n",
      "epoch:33 step:26531 [D loss: 0.687931, acc.: 54.69%] [G loss: 0.738158]\n",
      "epoch:33 step:26532 [D loss: 0.737377, acc.: 41.41%] [G loss: 0.714614]\n",
      "epoch:33 step:26533 [D loss: 0.678090, acc.: 57.03%] [G loss: 0.733538]\n",
      "epoch:33 step:26534 [D loss: 0.685152, acc.: 57.03%] [G loss: 0.708627]\n",
      "epoch:33 step:26535 [D loss: 0.680278, acc.: 55.47%] [G loss: 0.821257]\n",
      "epoch:33 step:26536 [D loss: 0.743438, acc.: 41.41%] [G loss: 0.714229]\n",
      "epoch:33 step:26537 [D loss: 0.681635, acc.: 53.12%] [G loss: 0.802064]\n",
      "epoch:33 step:26538 [D loss: 0.706201, acc.: 49.22%] [G loss: 0.800183]\n",
      "epoch:33 step:26539 [D loss: 0.708661, acc.: 48.44%] [G loss: 0.733988]\n",
      "epoch:33 step:26540 [D loss: 0.695947, acc.: 53.91%] [G loss: 0.782451]\n",
      "epoch:33 step:26541 [D loss: 0.735030, acc.: 43.75%] [G loss: 0.790414]\n",
      "epoch:33 step:26542 [D loss: 0.686485, acc.: 56.25%] [G loss: 0.778638]\n",
      "epoch:33 step:26543 [D loss: 0.718635, acc.: 48.44%] [G loss: 0.793069]\n",
      "epoch:33 step:26544 [D loss: 0.705096, acc.: 51.56%] [G loss: 0.798944]\n",
      "epoch:33 step:26545 [D loss: 0.724826, acc.: 43.75%] [G loss: 0.733977]\n",
      "epoch:33 step:26546 [D loss: 0.660142, acc.: 62.50%] [G loss: 0.808930]\n",
      "epoch:33 step:26547 [D loss: 0.653783, acc.: 55.47%] [G loss: 0.731211]\n",
      "epoch:33 step:26548 [D loss: 0.729169, acc.: 39.06%] [G loss: 0.695921]\n",
      "epoch:33 step:26549 [D loss: 0.697334, acc.: 47.66%] [G loss: 0.766820]\n",
      "epoch:33 step:26550 [D loss: 0.653054, acc.: 61.72%] [G loss: 0.748535]\n",
      "epoch:33 step:26551 [D loss: 0.705215, acc.: 51.56%] [G loss: 0.724070]\n",
      "epoch:33 step:26552 [D loss: 0.690420, acc.: 48.44%] [G loss: 0.753991]\n",
      "epoch:33 step:26553 [D loss: 0.655148, acc.: 60.94%] [G loss: 0.737494]\n",
      "epoch:33 step:26554 [D loss: 0.708506, acc.: 45.31%] [G loss: 0.823630]\n",
      "epoch:34 step:26555 [D loss: 0.652627, acc.: 64.84%] [G loss: 0.808236]\n",
      "epoch:34 step:26556 [D loss: 0.685818, acc.: 53.91%] [G loss: 0.805060]\n",
      "epoch:34 step:26557 [D loss: 0.696315, acc.: 48.44%] [G loss: 0.774702]\n",
      "epoch:34 step:26558 [D loss: 0.711500, acc.: 50.78%] [G loss: 0.768973]\n",
      "epoch:34 step:26559 [D loss: 0.652464, acc.: 65.62%] [G loss: 0.859142]\n",
      "epoch:34 step:26560 [D loss: 0.679795, acc.: 56.25%] [G loss: 0.768472]\n",
      "epoch:34 step:26561 [D loss: 0.742505, acc.: 35.94%] [G loss: 0.784306]\n",
      "epoch:34 step:26562 [D loss: 0.652962, acc.: 64.06%] [G loss: 0.851472]\n",
      "epoch:34 step:26563 [D loss: 0.734474, acc.: 42.19%] [G loss: 0.804429]\n",
      "epoch:34 step:26564 [D loss: 0.665635, acc.: 60.16%] [G loss: 0.904839]\n",
      "epoch:34 step:26565 [D loss: 0.662663, acc.: 60.16%] [G loss: 0.814346]\n",
      "epoch:34 step:26566 [D loss: 0.711893, acc.: 46.88%] [G loss: 0.765316]\n",
      "epoch:34 step:26567 [D loss: 0.667861, acc.: 57.81%] [G loss: 0.749461]\n",
      "epoch:34 step:26568 [D loss: 0.698520, acc.: 52.34%] [G loss: 0.841799]\n",
      "epoch:34 step:26569 [D loss: 0.719749, acc.: 46.88%] [G loss: 0.823083]\n",
      "epoch:34 step:26570 [D loss: 0.648824, acc.: 65.62%] [G loss: 0.829990]\n",
      "epoch:34 step:26571 [D loss: 0.717030, acc.: 40.62%] [G loss: 0.713663]\n",
      "epoch:34 step:26572 [D loss: 0.720064, acc.: 50.78%] [G loss: 0.775793]\n",
      "epoch:34 step:26573 [D loss: 0.713152, acc.: 43.75%] [G loss: 0.747165]\n",
      "epoch:34 step:26574 [D loss: 0.702310, acc.: 47.66%] [G loss: 0.792585]\n",
      "epoch:34 step:26575 [D loss: 0.700703, acc.: 53.91%] [G loss: 0.757263]\n",
      "epoch:34 step:26576 [D loss: 0.667828, acc.: 60.94%] [G loss: 0.843350]\n",
      "epoch:34 step:26577 [D loss: 0.674884, acc.: 57.81%] [G loss: 0.787180]\n",
      "epoch:34 step:26578 [D loss: 0.685970, acc.: 49.22%] [G loss: 0.827901]\n",
      "epoch:34 step:26579 [D loss: 0.690935, acc.: 56.25%] [G loss: 0.788608]\n",
      "epoch:34 step:26580 [D loss: 0.713575, acc.: 49.22%] [G loss: 0.813930]\n",
      "epoch:34 step:26581 [D loss: 0.681555, acc.: 54.69%] [G loss: 0.786808]\n",
      "epoch:34 step:26582 [D loss: 0.678481, acc.: 54.69%] [G loss: 0.772819]\n",
      "epoch:34 step:26583 [D loss: 0.652781, acc.: 70.31%] [G loss: 0.833754]\n",
      "epoch:34 step:26584 [D loss: 0.691854, acc.: 49.22%] [G loss: 0.823865]\n",
      "epoch:34 step:26585 [D loss: 0.660433, acc.: 57.03%] [G loss: 0.802624]\n",
      "epoch:34 step:26586 [D loss: 0.802639, acc.: 32.81%] [G loss: 0.702164]\n",
      "epoch:34 step:26587 [D loss: 0.735506, acc.: 47.66%] [G loss: 0.726263]\n",
      "epoch:34 step:26588 [D loss: 0.712801, acc.: 52.34%] [G loss: 0.814451]\n",
      "epoch:34 step:26589 [D loss: 0.660000, acc.: 56.25%] [G loss: 0.709930]\n",
      "epoch:34 step:26590 [D loss: 0.669149, acc.: 62.50%] [G loss: 0.772933]\n",
      "epoch:34 step:26591 [D loss: 0.661073, acc.: 61.72%] [G loss: 0.746241]\n",
      "epoch:34 step:26592 [D loss: 0.705309, acc.: 49.22%] [G loss: 0.693666]\n",
      "epoch:34 step:26593 [D loss: 0.702948, acc.: 47.66%] [G loss: 0.678771]\n",
      "epoch:34 step:26594 [D loss: 0.693575, acc.: 55.47%] [G loss: 0.780841]\n",
      "epoch:34 step:26595 [D loss: 0.632785, acc.: 67.97%] [G loss: 0.704786]\n",
      "epoch:34 step:26596 [D loss: 0.704752, acc.: 51.56%] [G loss: 0.703587]\n",
      "epoch:34 step:26597 [D loss: 0.691974, acc.: 48.44%] [G loss: 0.737833]\n",
      "epoch:34 step:26598 [D loss: 0.718873, acc.: 49.22%] [G loss: 0.733689]\n",
      "epoch:34 step:26599 [D loss: 0.695261, acc.: 53.12%] [G loss: 0.742279]\n",
      "epoch:34 step:26600 [D loss: 0.684200, acc.: 53.12%] [G loss: 0.776809]\n",
      "epoch:34 step:26601 [D loss: 0.641287, acc.: 70.31%] [G loss: 0.757412]\n",
      "epoch:34 step:26602 [D loss: 0.663997, acc.: 63.28%] [G loss: 0.708644]\n",
      "epoch:34 step:26603 [D loss: 0.687681, acc.: 50.78%] [G loss: 0.742113]\n",
      "epoch:34 step:26604 [D loss: 0.677248, acc.: 53.12%] [G loss: 0.708528]\n",
      "epoch:34 step:26605 [D loss: 0.702717, acc.: 53.91%] [G loss: 0.777080]\n",
      "epoch:34 step:26606 [D loss: 0.662267, acc.: 66.41%] [G loss: 0.708884]\n",
      "epoch:34 step:26607 [D loss: 0.686955, acc.: 49.22%] [G loss: 0.742031]\n",
      "epoch:34 step:26608 [D loss: 0.735064, acc.: 42.19%] [G loss: 0.749662]\n",
      "epoch:34 step:26609 [D loss: 0.716485, acc.: 53.12%] [G loss: 0.738130]\n",
      "epoch:34 step:26610 [D loss: 0.676842, acc.: 53.12%] [G loss: 0.772298]\n",
      "epoch:34 step:26611 [D loss: 0.658547, acc.: 62.50%] [G loss: 0.780262]\n",
      "epoch:34 step:26612 [D loss: 0.647130, acc.: 69.53%] [G loss: 0.787385]\n",
      "epoch:34 step:26613 [D loss: 0.703990, acc.: 42.19%] [G loss: 0.766062]\n",
      "epoch:34 step:26614 [D loss: 0.743011, acc.: 35.94%] [G loss: 0.760075]\n",
      "epoch:34 step:26615 [D loss: 0.627524, acc.: 70.31%] [G loss: 0.818274]\n",
      "epoch:34 step:26616 [D loss: 0.666853, acc.: 63.28%] [G loss: 0.883864]\n",
      "epoch:34 step:26617 [D loss: 0.678409, acc.: 57.03%] [G loss: 0.795107]\n",
      "epoch:34 step:26618 [D loss: 0.684474, acc.: 55.47%] [G loss: 0.768408]\n",
      "epoch:34 step:26619 [D loss: 0.691987, acc.: 52.34%] [G loss: 0.788491]\n",
      "epoch:34 step:26620 [D loss: 0.657423, acc.: 55.47%] [G loss: 0.845732]\n",
      "epoch:34 step:26621 [D loss: 0.661137, acc.: 63.28%] [G loss: 0.787915]\n",
      "epoch:34 step:26622 [D loss: 0.667263, acc.: 61.72%] [G loss: 0.810916]\n",
      "epoch:34 step:26623 [D loss: 0.687422, acc.: 54.69%] [G loss: 0.687747]\n",
      "epoch:34 step:26624 [D loss: 0.710739, acc.: 46.09%] [G loss: 0.776659]\n",
      "epoch:34 step:26625 [D loss: 0.722469, acc.: 42.97%] [G loss: 0.796437]\n",
      "epoch:34 step:26626 [D loss: 0.694895, acc.: 50.78%] [G loss: 0.729263]\n",
      "epoch:34 step:26627 [D loss: 0.698515, acc.: 47.66%] [G loss: 0.723064]\n",
      "epoch:34 step:26628 [D loss: 0.644910, acc.: 63.28%] [G loss: 0.770172]\n",
      "epoch:34 step:26629 [D loss: 0.711733, acc.: 47.66%] [G loss: 0.733198]\n",
      "epoch:34 step:26630 [D loss: 0.743566, acc.: 38.28%] [G loss: 0.738470]\n",
      "epoch:34 step:26631 [D loss: 0.706788, acc.: 51.56%] [G loss: 0.743223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26632 [D loss: 0.698898, acc.: 50.78%] [G loss: 0.744604]\n",
      "epoch:34 step:26633 [D loss: 0.657987, acc.: 61.72%] [G loss: 0.790954]\n",
      "epoch:34 step:26634 [D loss: 0.720730, acc.: 50.00%] [G loss: 0.753273]\n",
      "epoch:34 step:26635 [D loss: 0.665085, acc.: 62.50%] [G loss: 0.797161]\n",
      "epoch:34 step:26636 [D loss: 0.708633, acc.: 50.00%] [G loss: 0.776981]\n",
      "epoch:34 step:26637 [D loss: 0.713134, acc.: 46.09%] [G loss: 0.743176]\n",
      "epoch:34 step:26638 [D loss: 0.648722, acc.: 61.72%] [G loss: 0.776132]\n",
      "epoch:34 step:26639 [D loss: 0.733670, acc.: 39.84%] [G loss: 0.777556]\n",
      "epoch:34 step:26640 [D loss: 0.659077, acc.: 67.19%] [G loss: 0.792106]\n",
      "epoch:34 step:26641 [D loss: 0.715300, acc.: 49.22%] [G loss: 0.773030]\n",
      "epoch:34 step:26642 [D loss: 0.729427, acc.: 43.75%] [G loss: 0.716623]\n",
      "epoch:34 step:26643 [D loss: 0.694005, acc.: 49.22%] [G loss: 0.755876]\n",
      "epoch:34 step:26644 [D loss: 0.687505, acc.: 56.25%] [G loss: 0.761322]\n",
      "epoch:34 step:26645 [D loss: 0.735470, acc.: 39.84%] [G loss: 0.766745]\n",
      "epoch:34 step:26646 [D loss: 0.722217, acc.: 39.84%] [G loss: 0.747218]\n",
      "epoch:34 step:26647 [D loss: 0.692745, acc.: 52.34%] [G loss: 0.909845]\n",
      "epoch:34 step:26648 [D loss: 0.695236, acc.: 56.25%] [G loss: 0.762751]\n",
      "epoch:34 step:26649 [D loss: 0.701881, acc.: 55.47%] [G loss: 0.813521]\n",
      "epoch:34 step:26650 [D loss: 0.645838, acc.: 65.62%] [G loss: 0.841774]\n",
      "epoch:34 step:26651 [D loss: 0.655375, acc.: 64.84%] [G loss: 0.817258]\n",
      "epoch:34 step:26652 [D loss: 0.664145, acc.: 59.38%] [G loss: 0.836251]\n",
      "epoch:34 step:26653 [D loss: 0.670573, acc.: 60.94%] [G loss: 0.822907]\n",
      "epoch:34 step:26654 [D loss: 0.700802, acc.: 51.56%] [G loss: 0.771249]\n",
      "epoch:34 step:26655 [D loss: 0.732527, acc.: 45.31%] [G loss: 0.778762]\n",
      "epoch:34 step:26656 [D loss: 0.660575, acc.: 63.28%] [G loss: 0.776842]\n",
      "epoch:34 step:26657 [D loss: 0.701616, acc.: 50.00%] [G loss: 0.768959]\n",
      "epoch:34 step:26658 [D loss: 0.661984, acc.: 64.06%] [G loss: 0.742678]\n",
      "epoch:34 step:26659 [D loss: 0.665248, acc.: 59.38%] [G loss: 0.826607]\n",
      "epoch:34 step:26660 [D loss: 0.654713, acc.: 67.19%] [G loss: 0.792097]\n",
      "epoch:34 step:26661 [D loss: 0.667402, acc.: 57.81%] [G loss: 0.699554]\n",
      "epoch:34 step:26662 [D loss: 0.703333, acc.: 57.03%] [G loss: 0.768693]\n",
      "epoch:34 step:26663 [D loss: 0.643528, acc.: 69.53%] [G loss: 0.789865]\n",
      "epoch:34 step:26664 [D loss: 0.681430, acc.: 56.25%] [G loss: 0.810284]\n",
      "epoch:34 step:26665 [D loss: 0.660788, acc.: 57.03%] [G loss: 0.764019]\n",
      "epoch:34 step:26666 [D loss: 0.693908, acc.: 49.22%] [G loss: 0.771924]\n",
      "epoch:34 step:26667 [D loss: 0.666409, acc.: 61.72%] [G loss: 0.745054]\n",
      "epoch:34 step:26668 [D loss: 0.676272, acc.: 53.91%] [G loss: 0.709764]\n",
      "epoch:34 step:26669 [D loss: 0.704417, acc.: 47.66%] [G loss: 0.793776]\n",
      "epoch:34 step:26670 [D loss: 0.712091, acc.: 46.88%] [G loss: 0.748429]\n",
      "epoch:34 step:26671 [D loss: 0.726229, acc.: 50.00%] [G loss: 0.712705]\n",
      "epoch:34 step:26672 [D loss: 0.683407, acc.: 53.12%] [G loss: 0.757674]\n",
      "epoch:34 step:26673 [D loss: 0.649555, acc.: 68.75%] [G loss: 0.820723]\n",
      "epoch:34 step:26674 [D loss: 0.639463, acc.: 69.53%] [G loss: 0.711695]\n",
      "epoch:34 step:26675 [D loss: 0.686434, acc.: 53.91%] [G loss: 0.754229]\n",
      "epoch:34 step:26676 [D loss: 0.692803, acc.: 53.12%] [G loss: 0.687017]\n",
      "epoch:34 step:26677 [D loss: 0.740710, acc.: 43.75%] [G loss: 0.791126]\n",
      "epoch:34 step:26678 [D loss: 0.754535, acc.: 39.84%] [G loss: 0.698311]\n",
      "epoch:34 step:26679 [D loss: 0.697671, acc.: 55.47%] [G loss: 0.728252]\n",
      "epoch:34 step:26680 [D loss: 0.758048, acc.: 35.94%] [G loss: 0.669074]\n",
      "epoch:34 step:26681 [D loss: 0.614799, acc.: 67.19%] [G loss: 0.768261]\n",
      "epoch:34 step:26682 [D loss: 0.698641, acc.: 51.56%] [G loss: 0.713412]\n",
      "epoch:34 step:26683 [D loss: 0.692085, acc.: 58.59%] [G loss: 0.754317]\n",
      "epoch:34 step:26684 [D loss: 0.706775, acc.: 53.12%] [G loss: 0.757848]\n",
      "epoch:34 step:26685 [D loss: 0.681143, acc.: 56.25%] [G loss: 0.815547]\n",
      "epoch:34 step:26686 [D loss: 0.618482, acc.: 72.66%] [G loss: 0.809998]\n",
      "epoch:34 step:26687 [D loss: 0.688796, acc.: 57.03%] [G loss: 0.791990]\n",
      "epoch:34 step:26688 [D loss: 0.694134, acc.: 49.22%] [G loss: 0.798801]\n",
      "epoch:34 step:26689 [D loss: 0.691472, acc.: 50.78%] [G loss: 0.779828]\n",
      "epoch:34 step:26690 [D loss: 0.664802, acc.: 59.38%] [G loss: 0.778097]\n",
      "epoch:34 step:26691 [D loss: 0.731928, acc.: 44.53%] [G loss: 0.753510]\n",
      "epoch:34 step:26692 [D loss: 0.692868, acc.: 52.34%] [G loss: 0.793819]\n",
      "epoch:34 step:26693 [D loss: 0.725490, acc.: 44.53%] [G loss: 0.790653]\n",
      "epoch:34 step:26694 [D loss: 0.699210, acc.: 50.78%] [G loss: 0.748259]\n",
      "epoch:34 step:26695 [D loss: 0.702029, acc.: 53.12%] [G loss: 0.714832]\n",
      "epoch:34 step:26696 [D loss: 0.674892, acc.: 59.38%] [G loss: 0.712980]\n",
      "epoch:34 step:26697 [D loss: 0.664926, acc.: 61.72%] [G loss: 0.719382]\n",
      "epoch:34 step:26698 [D loss: 0.684101, acc.: 57.81%] [G loss: 0.890248]\n",
      "epoch:34 step:26699 [D loss: 0.711187, acc.: 49.22%] [G loss: 0.778749]\n",
      "epoch:34 step:26700 [D loss: 0.656299, acc.: 63.28%] [G loss: 0.754663]\n",
      "epoch:34 step:26701 [D loss: 0.666327, acc.: 61.72%] [G loss: 0.813740]\n",
      "epoch:34 step:26702 [D loss: 0.688072, acc.: 56.25%] [G loss: 0.758759]\n",
      "epoch:34 step:26703 [D loss: 0.661705, acc.: 58.59%] [G loss: 0.790062]\n",
      "epoch:34 step:26704 [D loss: 0.756895, acc.: 39.84%] [G loss: 0.798370]\n",
      "epoch:34 step:26705 [D loss: 0.686704, acc.: 52.34%] [G loss: 0.786560]\n",
      "epoch:34 step:26706 [D loss: 0.665827, acc.: 65.62%] [G loss: 0.860898]\n",
      "epoch:34 step:26707 [D loss: 0.701084, acc.: 46.09%] [G loss: 0.717775]\n",
      "epoch:34 step:26708 [D loss: 0.668275, acc.: 56.25%] [G loss: 0.762586]\n",
      "epoch:34 step:26709 [D loss: 0.687331, acc.: 57.03%] [G loss: 0.795340]\n",
      "epoch:34 step:26710 [D loss: 0.670450, acc.: 63.28%] [G loss: 0.775705]\n",
      "epoch:34 step:26711 [D loss: 0.681698, acc.: 58.59%] [G loss: 0.811701]\n",
      "epoch:34 step:26712 [D loss: 0.751741, acc.: 39.84%] [G loss: 0.740650]\n",
      "epoch:34 step:26713 [D loss: 0.704146, acc.: 51.56%] [G loss: 0.802756]\n",
      "epoch:34 step:26714 [D loss: 0.624070, acc.: 67.97%] [G loss: 0.763383]\n",
      "epoch:34 step:26715 [D loss: 0.702701, acc.: 52.34%] [G loss: 0.756994]\n",
      "epoch:34 step:26716 [D loss: 0.683131, acc.: 53.12%] [G loss: 0.837804]\n",
      "epoch:34 step:26717 [D loss: 0.636848, acc.: 65.62%] [G loss: 0.864428]\n",
      "epoch:34 step:26718 [D loss: 0.638748, acc.: 60.94%] [G loss: 0.817035]\n",
      "epoch:34 step:26719 [D loss: 0.664221, acc.: 63.28%] [G loss: 0.837218]\n",
      "epoch:34 step:26720 [D loss: 0.674889, acc.: 58.59%] [G loss: 0.864744]\n",
      "epoch:34 step:26721 [D loss: 0.714101, acc.: 46.09%] [G loss: 0.841819]\n",
      "epoch:34 step:26722 [D loss: 0.628454, acc.: 72.66%] [G loss: 0.883970]\n",
      "epoch:34 step:26723 [D loss: 0.671332, acc.: 57.03%] [G loss: 0.813328]\n",
      "epoch:34 step:26724 [D loss: 0.662174, acc.: 64.06%] [G loss: 0.874224]\n",
      "epoch:34 step:26725 [D loss: 0.651132, acc.: 58.59%] [G loss: 0.825276]\n",
      "epoch:34 step:26726 [D loss: 0.700471, acc.: 48.44%] [G loss: 0.803127]\n",
      "epoch:34 step:26727 [D loss: 0.641863, acc.: 65.62%] [G loss: 0.690997]\n",
      "epoch:34 step:26728 [D loss: 0.697977, acc.: 57.81%] [G loss: 0.776851]\n",
      "epoch:34 step:26729 [D loss: 0.682360, acc.: 60.94%] [G loss: 0.773066]\n",
      "epoch:34 step:26730 [D loss: 0.650091, acc.: 67.97%] [G loss: 0.869868]\n",
      "epoch:34 step:26731 [D loss: 0.729854, acc.: 46.09%] [G loss: 0.805268]\n",
      "epoch:34 step:26732 [D loss: 0.729077, acc.: 45.31%] [G loss: 0.848075]\n",
      "epoch:34 step:26733 [D loss: 0.658932, acc.: 61.72%] [G loss: 0.787477]\n",
      "epoch:34 step:26734 [D loss: 0.717257, acc.: 50.00%] [G loss: 0.785912]\n",
      "epoch:34 step:26735 [D loss: 0.672622, acc.: 64.84%] [G loss: 0.783401]\n",
      "epoch:34 step:26736 [D loss: 0.731134, acc.: 50.78%] [G loss: 0.868156]\n",
      "epoch:34 step:26737 [D loss: 0.630740, acc.: 72.66%] [G loss: 0.794891]\n",
      "epoch:34 step:26738 [D loss: 0.695723, acc.: 53.91%] [G loss: 0.769183]\n",
      "epoch:34 step:26739 [D loss: 0.672682, acc.: 59.38%] [G loss: 0.815546]\n",
      "epoch:34 step:26740 [D loss: 0.691516, acc.: 61.72%] [G loss: 0.868404]\n",
      "epoch:34 step:26741 [D loss: 0.661653, acc.: 61.72%] [G loss: 0.778798]\n",
      "epoch:34 step:26742 [D loss: 0.733471, acc.: 41.41%] [G loss: 0.763951]\n",
      "epoch:34 step:26743 [D loss: 0.630098, acc.: 69.53%] [G loss: 0.848395]\n",
      "epoch:34 step:26744 [D loss: 0.747320, acc.: 43.75%] [G loss: 0.823145]\n",
      "epoch:34 step:26745 [D loss: 0.664444, acc.: 61.72%] [G loss: 0.784375]\n",
      "epoch:34 step:26746 [D loss: 0.705568, acc.: 48.44%] [G loss: 0.875599]\n",
      "epoch:34 step:26747 [D loss: 0.702728, acc.: 53.12%] [G loss: 0.774504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26748 [D loss: 0.740221, acc.: 50.78%] [G loss: 0.803152]\n",
      "epoch:34 step:26749 [D loss: 0.709652, acc.: 50.00%] [G loss: 0.807484]\n",
      "epoch:34 step:26750 [D loss: 0.689744, acc.: 52.34%] [G loss: 0.783971]\n",
      "epoch:34 step:26751 [D loss: 0.661276, acc.: 60.16%] [G loss: 0.765797]\n",
      "epoch:34 step:26752 [D loss: 0.667859, acc.: 60.94%] [G loss: 0.803594]\n",
      "epoch:34 step:26753 [D loss: 0.694529, acc.: 53.91%] [G loss: 0.806756]\n",
      "epoch:34 step:26754 [D loss: 0.647462, acc.: 64.84%] [G loss: 0.791309]\n",
      "epoch:34 step:26755 [D loss: 0.688311, acc.: 58.59%] [G loss: 0.754475]\n",
      "epoch:34 step:26756 [D loss: 0.676555, acc.: 53.12%] [G loss: 0.751574]\n",
      "epoch:34 step:26757 [D loss: 0.626193, acc.: 71.09%] [G loss: 0.819754]\n",
      "epoch:34 step:26758 [D loss: 0.710933, acc.: 46.09%] [G loss: 0.753357]\n",
      "epoch:34 step:26759 [D loss: 0.686578, acc.: 55.47%] [G loss: 0.759661]\n",
      "epoch:34 step:26760 [D loss: 0.695633, acc.: 53.91%] [G loss: 0.706885]\n",
      "epoch:34 step:26761 [D loss: 0.622278, acc.: 73.44%] [G loss: 0.761039]\n",
      "epoch:34 step:26762 [D loss: 0.662366, acc.: 57.03%] [G loss: 0.781138]\n",
      "epoch:34 step:26763 [D loss: 0.650836, acc.: 63.28%] [G loss: 0.809842]\n",
      "epoch:34 step:26764 [D loss: 0.646529, acc.: 63.28%] [G loss: 0.795207]\n",
      "epoch:34 step:26765 [D loss: 0.691136, acc.: 52.34%] [G loss: 0.822795]\n",
      "epoch:34 step:26766 [D loss: 0.619393, acc.: 71.88%] [G loss: 0.848948]\n",
      "epoch:34 step:26767 [D loss: 0.725666, acc.: 49.22%] [G loss: 0.845068]\n",
      "epoch:34 step:26768 [D loss: 0.686960, acc.: 59.38%] [G loss: 0.763014]\n",
      "epoch:34 step:26769 [D loss: 0.667869, acc.: 60.94%] [G loss: 0.778738]\n",
      "epoch:34 step:26770 [D loss: 0.695004, acc.: 52.34%] [G loss: 0.825665]\n",
      "epoch:34 step:26771 [D loss: 0.692011, acc.: 50.00%] [G loss: 0.740294]\n",
      "epoch:34 step:26772 [D loss: 0.704064, acc.: 48.44%] [G loss: 0.815909]\n",
      "epoch:34 step:26773 [D loss: 0.698706, acc.: 47.66%] [G loss: 0.694697]\n",
      "epoch:34 step:26774 [D loss: 0.633216, acc.: 70.31%] [G loss: 0.759704]\n",
      "epoch:34 step:26775 [D loss: 0.688604, acc.: 57.81%] [G loss: 0.792809]\n",
      "epoch:34 step:26776 [D loss: 0.674267, acc.: 55.47%] [G loss: 0.746118]\n",
      "epoch:34 step:26777 [D loss: 0.703293, acc.: 44.53%] [G loss: 0.777599]\n",
      "epoch:34 step:26778 [D loss: 0.679316, acc.: 53.91%] [G loss: 0.748267]\n",
      "epoch:34 step:26779 [D loss: 0.710598, acc.: 50.00%] [G loss: 0.735099]\n",
      "epoch:34 step:26780 [D loss: 0.715307, acc.: 50.00%] [G loss: 0.739760]\n",
      "epoch:34 step:26781 [D loss: 0.666113, acc.: 58.59%] [G loss: 0.783368]\n",
      "epoch:34 step:26782 [D loss: 0.650623, acc.: 63.28%] [G loss: 0.822987]\n",
      "epoch:34 step:26783 [D loss: 0.680588, acc.: 53.91%] [G loss: 0.732793]\n",
      "epoch:34 step:26784 [D loss: 0.732228, acc.: 42.97%] [G loss: 0.807329]\n",
      "epoch:34 step:26785 [D loss: 0.618949, acc.: 69.53%] [G loss: 0.790441]\n",
      "epoch:34 step:26786 [D loss: 0.749238, acc.: 42.19%] [G loss: 0.789237]\n",
      "epoch:34 step:26787 [D loss: 0.728357, acc.: 51.56%] [G loss: 0.734907]\n",
      "epoch:34 step:26788 [D loss: 0.747925, acc.: 37.50%] [G loss: 0.746896]\n",
      "epoch:34 step:26789 [D loss: 0.725301, acc.: 49.22%] [G loss: 0.711459]\n",
      "epoch:34 step:26790 [D loss: 0.635056, acc.: 65.62%] [G loss: 0.699058]\n",
      "epoch:34 step:26791 [D loss: 0.682344, acc.: 55.47%] [G loss: 0.723353]\n",
      "epoch:34 step:26792 [D loss: 0.717864, acc.: 48.44%] [G loss: 0.779791]\n",
      "epoch:34 step:26793 [D loss: 0.674849, acc.: 55.47%] [G loss: 0.721472]\n",
      "epoch:34 step:26794 [D loss: 0.730020, acc.: 44.53%] [G loss: 0.780158]\n",
      "epoch:34 step:26795 [D loss: 0.694838, acc.: 54.69%] [G loss: 0.844009]\n",
      "epoch:34 step:26796 [D loss: 0.751703, acc.: 42.97%] [G loss: 0.706239]\n",
      "epoch:34 step:26797 [D loss: 0.653178, acc.: 61.72%] [G loss: 0.713019]\n",
      "epoch:34 step:26798 [D loss: 0.664737, acc.: 58.59%] [G loss: 0.802509]\n",
      "epoch:34 step:26799 [D loss: 0.695685, acc.: 50.78%] [G loss: 0.773656]\n",
      "epoch:34 step:26800 [D loss: 0.695197, acc.: 53.91%] [G loss: 0.762122]\n",
      "epoch:34 step:26801 [D loss: 0.675102, acc.: 56.25%] [G loss: 0.741205]\n",
      "epoch:34 step:26802 [D loss: 0.678161, acc.: 57.03%] [G loss: 0.760231]\n",
      "epoch:34 step:26803 [D loss: 0.740106, acc.: 44.53%] [G loss: 0.720818]\n",
      "epoch:34 step:26804 [D loss: 0.657684, acc.: 66.41%] [G loss: 0.759860]\n",
      "epoch:34 step:26805 [D loss: 0.678162, acc.: 53.91%] [G loss: 0.761847]\n",
      "epoch:34 step:26806 [D loss: 0.642821, acc.: 64.84%] [G loss: 0.856296]\n",
      "epoch:34 step:26807 [D loss: 0.725537, acc.: 45.31%] [G loss: 0.780482]\n",
      "epoch:34 step:26808 [D loss: 0.665294, acc.: 59.38%] [G loss: 0.785619]\n",
      "epoch:34 step:26809 [D loss: 0.678708, acc.: 57.03%] [G loss: 0.797290]\n",
      "epoch:34 step:26810 [D loss: 0.700399, acc.: 53.12%] [G loss: 0.795318]\n",
      "epoch:34 step:26811 [D loss: 0.690561, acc.: 51.56%] [G loss: 0.707106]\n",
      "epoch:34 step:26812 [D loss: 0.662932, acc.: 64.06%] [G loss: 0.770231]\n",
      "epoch:34 step:26813 [D loss: 0.658101, acc.: 64.06%] [G loss: 0.763619]\n",
      "epoch:34 step:26814 [D loss: 0.666613, acc.: 64.06%] [G loss: 0.801977]\n",
      "epoch:34 step:26815 [D loss: 0.696255, acc.: 50.78%] [G loss: 0.819320]\n",
      "epoch:34 step:26816 [D loss: 0.664493, acc.: 59.38%] [G loss: 0.744278]\n",
      "epoch:34 step:26817 [D loss: 0.631671, acc.: 67.97%] [G loss: 0.819861]\n",
      "epoch:34 step:26818 [D loss: 0.708994, acc.: 46.09%] [G loss: 0.814633]\n",
      "epoch:34 step:26819 [D loss: 0.704742, acc.: 47.66%] [G loss: 0.738185]\n",
      "epoch:34 step:26820 [D loss: 0.689205, acc.: 55.47%] [G loss: 0.795641]\n",
      "epoch:34 step:26821 [D loss: 0.753974, acc.: 40.62%] [G loss: 0.791907]\n",
      "epoch:34 step:26822 [D loss: 0.669080, acc.: 63.28%] [G loss: 0.774194]\n",
      "epoch:34 step:26823 [D loss: 0.687442, acc.: 54.69%] [G loss: 0.733133]\n",
      "epoch:34 step:26824 [D loss: 0.691464, acc.: 50.00%] [G loss: 0.792469]\n",
      "epoch:34 step:26825 [D loss: 0.651144, acc.: 66.41%] [G loss: 0.816608]\n",
      "epoch:34 step:26826 [D loss: 0.657609, acc.: 67.97%] [G loss: 0.761651]\n",
      "epoch:34 step:26827 [D loss: 0.693190, acc.: 48.44%] [G loss: 0.760751]\n",
      "epoch:34 step:26828 [D loss: 0.637497, acc.: 61.72%] [G loss: 0.807997]\n",
      "epoch:34 step:26829 [D loss: 0.681588, acc.: 59.38%] [G loss: 0.795660]\n",
      "epoch:34 step:26830 [D loss: 0.696470, acc.: 50.00%] [G loss: 0.790512]\n",
      "epoch:34 step:26831 [D loss: 0.740053, acc.: 42.19%] [G loss: 0.819825]\n",
      "epoch:34 step:26832 [D loss: 0.700193, acc.: 48.44%] [G loss: 0.735119]\n",
      "epoch:34 step:26833 [D loss: 0.699610, acc.: 48.44%] [G loss: 0.764207]\n",
      "epoch:34 step:26834 [D loss: 0.671887, acc.: 57.81%] [G loss: 0.824933]\n",
      "epoch:34 step:26835 [D loss: 0.721018, acc.: 46.09%] [G loss: 0.750726]\n",
      "epoch:34 step:26836 [D loss: 0.624238, acc.: 75.00%] [G loss: 0.822843]\n",
      "epoch:34 step:26837 [D loss: 0.683718, acc.: 57.81%] [G loss: 0.759251]\n",
      "epoch:34 step:26838 [D loss: 0.682834, acc.: 59.38%] [G loss: 0.747642]\n",
      "epoch:34 step:26839 [D loss: 0.682467, acc.: 54.69%] [G loss: 0.815371]\n",
      "epoch:34 step:26840 [D loss: 0.654561, acc.: 60.94%] [G loss: 0.791909]\n",
      "epoch:34 step:26841 [D loss: 0.710316, acc.: 45.31%] [G loss: 0.770514]\n",
      "epoch:34 step:26842 [D loss: 0.702021, acc.: 55.47%] [G loss: 0.807388]\n",
      "epoch:34 step:26843 [D loss: 0.653917, acc.: 58.59%] [G loss: 0.790516]\n",
      "epoch:34 step:26844 [D loss: 0.619243, acc.: 71.09%] [G loss: 0.886815]\n",
      "epoch:34 step:26845 [D loss: 0.733163, acc.: 45.31%] [G loss: 0.798773]\n",
      "epoch:34 step:26846 [D loss: 0.659555, acc.: 57.81%] [G loss: 0.793314]\n",
      "epoch:34 step:26847 [D loss: 0.667679, acc.: 61.72%] [G loss: 0.757677]\n",
      "epoch:34 step:26848 [D loss: 0.652418, acc.: 64.84%] [G loss: 0.761879]\n",
      "epoch:34 step:26849 [D loss: 0.710145, acc.: 47.66%] [G loss: 0.748272]\n",
      "epoch:34 step:26850 [D loss: 0.712858, acc.: 50.78%] [G loss: 0.731961]\n",
      "epoch:34 step:26851 [D loss: 0.674205, acc.: 58.59%] [G loss: 0.752014]\n",
      "epoch:34 step:26852 [D loss: 0.662165, acc.: 61.72%] [G loss: 0.732862]\n",
      "epoch:34 step:26853 [D loss: 0.694837, acc.: 59.38%] [G loss: 0.722682]\n",
      "epoch:34 step:26854 [D loss: 0.681648, acc.: 58.59%] [G loss: 0.717994]\n",
      "epoch:34 step:26855 [D loss: 0.704293, acc.: 57.03%] [G loss: 0.707031]\n",
      "epoch:34 step:26856 [D loss: 0.697180, acc.: 51.56%] [G loss: 0.731378]\n",
      "epoch:34 step:26857 [D loss: 0.656615, acc.: 63.28%] [G loss: 0.805140]\n",
      "epoch:34 step:26858 [D loss: 0.686985, acc.: 53.91%] [G loss: 0.745319]\n",
      "epoch:34 step:26859 [D loss: 0.705948, acc.: 53.12%] [G loss: 0.766010]\n",
      "epoch:34 step:26860 [D loss: 0.726828, acc.: 56.25%] [G loss: 0.731096]\n",
      "epoch:34 step:26861 [D loss: 0.717754, acc.: 44.53%] [G loss: 0.761761]\n",
      "epoch:34 step:26862 [D loss: 0.754525, acc.: 40.62%] [G loss: 0.741251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26863 [D loss: 0.707291, acc.: 50.00%] [G loss: 0.795808]\n",
      "epoch:34 step:26864 [D loss: 0.683903, acc.: 55.47%] [G loss: 0.810295]\n",
      "epoch:34 step:26865 [D loss: 0.692061, acc.: 53.91%] [G loss: 0.818249]\n",
      "epoch:34 step:26866 [D loss: 0.744365, acc.: 39.84%] [G loss: 0.798779]\n",
      "epoch:34 step:26867 [D loss: 0.745356, acc.: 45.31%] [G loss: 0.814880]\n",
      "epoch:34 step:26868 [D loss: 0.700025, acc.: 54.69%] [G loss: 0.778074]\n",
      "epoch:34 step:26869 [D loss: 0.722250, acc.: 47.66%] [G loss: 0.832687]\n",
      "epoch:34 step:26870 [D loss: 0.668166, acc.: 57.03%] [G loss: 0.754260]\n",
      "epoch:34 step:26871 [D loss: 0.708314, acc.: 46.88%] [G loss: 0.783680]\n",
      "epoch:34 step:26872 [D loss: 0.703631, acc.: 48.44%] [G loss: 0.771192]\n",
      "epoch:34 step:26873 [D loss: 0.699925, acc.: 52.34%] [G loss: 0.801141]\n",
      "epoch:34 step:26874 [D loss: 0.679192, acc.: 58.59%] [G loss: 0.905412]\n",
      "epoch:34 step:26875 [D loss: 0.711309, acc.: 47.66%] [G loss: 0.763311]\n",
      "epoch:34 step:26876 [D loss: 0.701615, acc.: 53.12%] [G loss: 0.784725]\n",
      "epoch:34 step:26877 [D loss: 0.648134, acc.: 64.06%] [G loss: 0.739862]\n",
      "epoch:34 step:26878 [D loss: 0.695621, acc.: 53.12%] [G loss: 0.768178]\n",
      "epoch:34 step:26879 [D loss: 0.683579, acc.: 55.47%] [G loss: 0.812972]\n",
      "epoch:34 step:26880 [D loss: 0.684390, acc.: 55.47%] [G loss: 0.788547]\n",
      "epoch:34 step:26881 [D loss: 0.732690, acc.: 42.19%] [G loss: 0.713742]\n",
      "epoch:34 step:26882 [D loss: 0.777019, acc.: 38.28%] [G loss: 0.772550]\n",
      "epoch:34 step:26883 [D loss: 0.680042, acc.: 57.81%] [G loss: 0.800499]\n",
      "epoch:34 step:26884 [D loss: 0.656642, acc.: 60.16%] [G loss: 0.759791]\n",
      "epoch:34 step:26885 [D loss: 0.695877, acc.: 53.12%] [G loss: 0.766106]\n",
      "epoch:34 step:26886 [D loss: 0.718538, acc.: 48.44%] [G loss: 0.739264]\n",
      "epoch:34 step:26887 [D loss: 0.707295, acc.: 50.00%] [G loss: 0.784227]\n",
      "epoch:34 step:26888 [D loss: 0.674299, acc.: 63.28%] [G loss: 0.746306]\n",
      "epoch:34 step:26889 [D loss: 0.679144, acc.: 60.94%] [G loss: 0.725113]\n",
      "epoch:34 step:26890 [D loss: 0.716678, acc.: 50.00%] [G loss: 0.696063]\n",
      "epoch:34 step:26891 [D loss: 0.641766, acc.: 67.19%] [G loss: 0.845118]\n",
      "epoch:34 step:26892 [D loss: 0.679327, acc.: 57.81%] [G loss: 0.805772]\n",
      "epoch:34 step:26893 [D loss: 0.709123, acc.: 46.88%] [G loss: 0.729921]\n",
      "epoch:34 step:26894 [D loss: 0.647522, acc.: 61.72%] [G loss: 0.824115]\n",
      "epoch:34 step:26895 [D loss: 0.654902, acc.: 59.38%] [G loss: 0.816309]\n",
      "epoch:34 step:26896 [D loss: 0.667366, acc.: 64.06%] [G loss: 0.790025]\n",
      "epoch:34 step:26897 [D loss: 0.702336, acc.: 52.34%] [G loss: 0.830360]\n",
      "epoch:34 step:26898 [D loss: 0.670876, acc.: 65.62%] [G loss: 0.751818]\n",
      "epoch:34 step:26899 [D loss: 0.687304, acc.: 50.00%] [G loss: 0.761140]\n",
      "epoch:34 step:26900 [D loss: 0.650537, acc.: 58.59%] [G loss: 0.847097]\n",
      "epoch:34 step:26901 [D loss: 0.678531, acc.: 60.94%] [G loss: 0.757502]\n",
      "epoch:34 step:26902 [D loss: 0.694280, acc.: 53.91%] [G loss: 0.856878]\n",
      "epoch:34 step:26903 [D loss: 0.676304, acc.: 53.12%] [G loss: 0.768824]\n",
      "epoch:34 step:26904 [D loss: 0.718898, acc.: 50.00%] [G loss: 0.769191]\n",
      "epoch:34 step:26905 [D loss: 0.648977, acc.: 64.06%] [G loss: 0.808160]\n",
      "epoch:34 step:26906 [D loss: 0.726390, acc.: 43.75%] [G loss: 0.810233]\n",
      "epoch:34 step:26907 [D loss: 0.698460, acc.: 55.47%] [G loss: 0.780418]\n",
      "epoch:34 step:26908 [D loss: 0.701528, acc.: 53.12%] [G loss: 0.769268]\n",
      "epoch:34 step:26909 [D loss: 0.664999, acc.: 57.81%] [G loss: 0.731151]\n",
      "epoch:34 step:26910 [D loss: 0.670675, acc.: 60.94%] [G loss: 0.786544]\n",
      "epoch:34 step:26911 [D loss: 0.673018, acc.: 58.59%] [G loss: 0.771090]\n",
      "epoch:34 step:26912 [D loss: 0.662991, acc.: 60.94%] [G loss: 0.776414]\n",
      "epoch:34 step:26913 [D loss: 0.648070, acc.: 63.28%] [G loss: 0.828286]\n",
      "epoch:34 step:26914 [D loss: 0.720289, acc.: 42.19%] [G loss: 0.802502]\n",
      "epoch:34 step:26915 [D loss: 0.617821, acc.: 78.91%] [G loss: 0.713790]\n",
      "epoch:34 step:26916 [D loss: 0.722469, acc.: 43.75%] [G loss: 0.756608]\n",
      "epoch:34 step:26917 [D loss: 0.699361, acc.: 51.56%] [G loss: 0.732229]\n",
      "epoch:34 step:26918 [D loss: 0.707196, acc.: 49.22%] [G loss: 0.731833]\n",
      "epoch:34 step:26919 [D loss: 0.675123, acc.: 53.12%] [G loss: 0.775506]\n",
      "epoch:34 step:26920 [D loss: 0.674892, acc.: 57.03%] [G loss: 0.748555]\n",
      "epoch:34 step:26921 [D loss: 0.672050, acc.: 60.16%] [G loss: 0.752346]\n",
      "epoch:34 step:26922 [D loss: 0.688453, acc.: 51.56%] [G loss: 0.757521]\n",
      "epoch:34 step:26923 [D loss: 0.731748, acc.: 42.19%] [G loss: 0.733660]\n",
      "epoch:34 step:26924 [D loss: 0.647170, acc.: 65.62%] [G loss: 0.745106]\n",
      "epoch:34 step:26925 [D loss: 0.683911, acc.: 52.34%] [G loss: 0.770717]\n",
      "epoch:34 step:26926 [D loss: 0.724656, acc.: 48.44%] [G loss: 0.817328]\n",
      "epoch:34 step:26927 [D loss: 0.652239, acc.: 60.94%] [G loss: 0.795892]\n",
      "epoch:34 step:26928 [D loss: 0.685790, acc.: 56.25%] [G loss: 0.785354]\n",
      "epoch:34 step:26929 [D loss: 0.708740, acc.: 46.09%] [G loss: 0.806415]\n",
      "epoch:34 step:26930 [D loss: 0.650695, acc.: 65.62%] [G loss: 0.773251]\n",
      "epoch:34 step:26931 [D loss: 0.711627, acc.: 47.66%] [G loss: 0.754015]\n",
      "epoch:34 step:26932 [D loss: 0.674512, acc.: 61.72%] [G loss: 0.774072]\n",
      "epoch:34 step:26933 [D loss: 0.699076, acc.: 53.91%] [G loss: 0.734096]\n",
      "epoch:34 step:26934 [D loss: 0.687274, acc.: 53.12%] [G loss: 0.828513]\n",
      "epoch:34 step:26935 [D loss: 0.641150, acc.: 66.41%] [G loss: 0.772031]\n",
      "epoch:34 step:26936 [D loss: 0.680919, acc.: 56.25%] [G loss: 0.806251]\n",
      "epoch:34 step:26937 [D loss: 0.674679, acc.: 57.03%] [G loss: 0.776267]\n",
      "epoch:34 step:26938 [D loss: 0.671628, acc.: 60.94%] [G loss: 0.826274]\n",
      "epoch:34 step:26939 [D loss: 0.696646, acc.: 50.78%] [G loss: 0.744680]\n",
      "epoch:34 step:26940 [D loss: 0.690336, acc.: 52.34%] [G loss: 0.691932]\n",
      "epoch:34 step:26941 [D loss: 0.710097, acc.: 53.91%] [G loss: 0.688836]\n",
      "epoch:34 step:26942 [D loss: 0.749219, acc.: 39.84%] [G loss: 0.741179]\n",
      "epoch:34 step:26943 [D loss: 0.659206, acc.: 62.50%] [G loss: 0.797037]\n",
      "epoch:34 step:26944 [D loss: 0.698252, acc.: 50.00%] [G loss: 0.795408]\n",
      "epoch:34 step:26945 [D loss: 0.716489, acc.: 48.44%] [G loss: 0.826115]\n",
      "epoch:34 step:26946 [D loss: 0.673916, acc.: 59.38%] [G loss: 0.788420]\n",
      "epoch:34 step:26947 [D loss: 0.694316, acc.: 51.56%] [G loss: 0.725480]\n",
      "epoch:34 step:26948 [D loss: 0.671110, acc.: 57.03%] [G loss: 0.717072]\n",
      "epoch:34 step:26949 [D loss: 0.721382, acc.: 46.88%] [G loss: 0.779433]\n",
      "epoch:34 step:26950 [D loss: 0.624501, acc.: 71.88%] [G loss: 0.794292]\n",
      "epoch:34 step:26951 [D loss: 0.678436, acc.: 50.78%] [G loss: 0.739602]\n",
      "epoch:34 step:26952 [D loss: 0.687842, acc.: 48.44%] [G loss: 0.805486]\n",
      "epoch:34 step:26953 [D loss: 0.680529, acc.: 58.59%] [G loss: 0.754422]\n",
      "epoch:34 step:26954 [D loss: 0.695098, acc.: 53.91%] [G loss: 0.756212]\n",
      "epoch:34 step:26955 [D loss: 0.628739, acc.: 64.06%] [G loss: 0.725125]\n",
      "epoch:34 step:26956 [D loss: 0.725186, acc.: 52.34%] [G loss: 0.709854]\n",
      "epoch:34 step:26957 [D loss: 0.664029, acc.: 61.72%] [G loss: 0.740524]\n",
      "epoch:34 step:26958 [D loss: 0.647934, acc.: 64.06%] [G loss: 0.697741]\n",
      "epoch:34 step:26959 [D loss: 0.680733, acc.: 56.25%] [G loss: 0.789756]\n",
      "epoch:34 step:26960 [D loss: 0.646037, acc.: 65.62%] [G loss: 0.769430]\n",
      "epoch:34 step:26961 [D loss: 0.654558, acc.: 67.19%] [G loss: 0.779209]\n",
      "epoch:34 step:26962 [D loss: 0.726405, acc.: 46.88%] [G loss: 0.736221]\n",
      "epoch:34 step:26963 [D loss: 0.693693, acc.: 53.91%] [G loss: 0.794589]\n",
      "epoch:34 step:26964 [D loss: 0.716832, acc.: 48.44%] [G loss: 0.671266]\n",
      "epoch:34 step:26965 [D loss: 0.725121, acc.: 42.97%] [G loss: 0.691372]\n",
      "epoch:34 step:26966 [D loss: 0.686833, acc.: 57.03%] [G loss: 0.723103]\n",
      "epoch:34 step:26967 [D loss: 0.691127, acc.: 57.81%] [G loss: 0.801507]\n",
      "epoch:34 step:26968 [D loss: 0.696617, acc.: 51.56%] [G loss: 0.763146]\n",
      "epoch:34 step:26969 [D loss: 0.615361, acc.: 74.22%] [G loss: 0.824054]\n",
      "epoch:34 step:26970 [D loss: 0.664671, acc.: 60.94%] [G loss: 0.779450]\n",
      "epoch:34 step:26971 [D loss: 0.706985, acc.: 47.66%] [G loss: 0.735270]\n",
      "epoch:34 step:26972 [D loss: 0.659601, acc.: 60.94%] [G loss: 0.740851]\n",
      "epoch:34 step:26973 [D loss: 0.700238, acc.: 55.47%] [G loss: 0.753662]\n",
      "epoch:34 step:26974 [D loss: 0.755863, acc.: 41.41%] [G loss: 0.752258]\n",
      "epoch:34 step:26975 [D loss: 0.710656, acc.: 42.97%] [G loss: 0.781461]\n",
      "epoch:34 step:26976 [D loss: 0.683649, acc.: 61.72%] [G loss: 0.833691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26977 [D loss: 0.705766, acc.: 50.00%] [G loss: 0.780764]\n",
      "epoch:34 step:26978 [D loss: 0.681640, acc.: 56.25%] [G loss: 0.796675]\n",
      "epoch:34 step:26979 [D loss: 0.704827, acc.: 50.00%] [G loss: 0.759910]\n",
      "epoch:34 step:26980 [D loss: 0.699959, acc.: 53.91%] [G loss: 0.764093]\n",
      "epoch:34 step:26981 [D loss: 0.683855, acc.: 53.12%] [G loss: 0.834115]\n",
      "epoch:34 step:26982 [D loss: 0.696647, acc.: 53.12%] [G loss: 0.730731]\n",
      "epoch:34 step:26983 [D loss: 0.718114, acc.: 46.88%] [G loss: 0.733838]\n",
      "epoch:34 step:26984 [D loss: 0.699970, acc.: 50.78%] [G loss: 0.752957]\n",
      "epoch:34 step:26985 [D loss: 0.724745, acc.: 42.97%] [G loss: 0.736054]\n",
      "epoch:34 step:26986 [D loss: 0.710095, acc.: 52.34%] [G loss: 0.747352]\n",
      "epoch:34 step:26987 [D loss: 0.690853, acc.: 56.25%] [G loss: 0.784072]\n",
      "epoch:34 step:26988 [D loss: 0.702274, acc.: 48.44%] [G loss: 0.781965]\n",
      "epoch:34 step:26989 [D loss: 0.659424, acc.: 55.47%] [G loss: 0.787911]\n",
      "epoch:34 step:26990 [D loss: 0.744719, acc.: 39.06%] [G loss: 0.712411]\n",
      "epoch:34 step:26991 [D loss: 0.692411, acc.: 55.47%] [G loss: 0.760011]\n",
      "epoch:34 step:26992 [D loss: 0.662760, acc.: 52.34%] [G loss: 0.759069]\n",
      "epoch:34 step:26993 [D loss: 0.639524, acc.: 67.97%] [G loss: 0.797284]\n",
      "epoch:34 step:26994 [D loss: 0.664255, acc.: 62.50%] [G loss: 0.729856]\n",
      "epoch:34 step:26995 [D loss: 0.732247, acc.: 42.19%] [G loss: 0.795529]\n",
      "epoch:34 step:26996 [D loss: 0.661914, acc.: 63.28%] [G loss: 0.774406]\n",
      "epoch:34 step:26997 [D loss: 0.677477, acc.: 59.38%] [G loss: 0.719531]\n",
      "epoch:34 step:26998 [D loss: 0.737293, acc.: 46.09%] [G loss: 0.810064]\n",
      "epoch:34 step:26999 [D loss: 0.747681, acc.: 45.31%] [G loss: 0.741686]\n",
      "epoch:34 step:27000 [D loss: 0.663186, acc.: 60.94%] [G loss: 0.793175]\n",
      "epoch:34 step:27001 [D loss: 0.645404, acc.: 67.19%] [G loss: 0.852796]\n",
      "epoch:34 step:27002 [D loss: 0.614020, acc.: 75.78%] [G loss: 0.772031]\n",
      "epoch:34 step:27003 [D loss: 0.672867, acc.: 57.81%] [G loss: 0.707891]\n",
      "epoch:34 step:27004 [D loss: 0.661700, acc.: 56.25%] [G loss: 0.751035]\n",
      "epoch:34 step:27005 [D loss: 0.748776, acc.: 39.84%] [G loss: 0.764628]\n",
      "epoch:34 step:27006 [D loss: 0.648446, acc.: 64.84%] [G loss: 0.842116]\n",
      "epoch:34 step:27007 [D loss: 0.737077, acc.: 47.66%] [G loss: 0.836623]\n",
      "epoch:34 step:27008 [D loss: 0.680701, acc.: 60.16%] [G loss: 0.823482]\n",
      "epoch:34 step:27009 [D loss: 0.713945, acc.: 46.88%] [G loss: 0.798573]\n",
      "epoch:34 step:27010 [D loss: 0.695184, acc.: 53.12%] [G loss: 0.792951]\n",
      "epoch:34 step:27011 [D loss: 0.638718, acc.: 71.88%] [G loss: 0.795518]\n",
      "epoch:34 step:27012 [D loss: 0.701244, acc.: 51.56%] [G loss: 0.765979]\n",
      "epoch:34 step:27013 [D loss: 0.686538, acc.: 55.47%] [G loss: 0.785485]\n",
      "epoch:34 step:27014 [D loss: 0.691389, acc.: 50.00%] [G loss: 0.798561]\n",
      "epoch:34 step:27015 [D loss: 0.694224, acc.: 48.44%] [G loss: 0.798187]\n",
      "epoch:34 step:27016 [D loss: 0.661195, acc.: 63.28%] [G loss: 0.811467]\n",
      "epoch:34 step:27017 [D loss: 0.662721, acc.: 60.94%] [G loss: 0.834780]\n",
      "epoch:34 step:27018 [D loss: 0.690887, acc.: 51.56%] [G loss: 0.812859]\n",
      "epoch:34 step:27019 [D loss: 0.668183, acc.: 65.62%] [G loss: 0.796227]\n",
      "epoch:34 step:27020 [D loss: 0.598884, acc.: 76.56%] [G loss: 0.752812]\n",
      "epoch:34 step:27021 [D loss: 0.697319, acc.: 57.03%] [G loss: 0.830019]\n",
      "epoch:34 step:27022 [D loss: 0.713266, acc.: 48.44%] [G loss: 0.719911]\n",
      "epoch:34 step:27023 [D loss: 0.680861, acc.: 54.69%] [G loss: 0.833581]\n",
      "epoch:34 step:27024 [D loss: 0.699729, acc.: 52.34%] [G loss: 0.779906]\n",
      "epoch:34 step:27025 [D loss: 0.695614, acc.: 57.03%] [G loss: 0.844629]\n",
      "epoch:34 step:27026 [D loss: 0.708334, acc.: 53.91%] [G loss: 0.686034]\n",
      "epoch:34 step:27027 [D loss: 0.725539, acc.: 49.22%] [G loss: 0.672976]\n",
      "epoch:34 step:27028 [D loss: 0.679639, acc.: 55.47%] [G loss: 0.719977]\n",
      "epoch:34 step:27029 [D loss: 0.745523, acc.: 36.72%] [G loss: 0.681439]\n",
      "epoch:34 step:27030 [D loss: 0.685801, acc.: 57.03%] [G loss: 0.773523]\n",
      "epoch:34 step:27031 [D loss: 0.702066, acc.: 50.78%] [G loss: 0.704806]\n",
      "epoch:34 step:27032 [D loss: 0.691257, acc.: 53.91%] [G loss: 0.677664]\n",
      "epoch:34 step:27033 [D loss: 0.678569, acc.: 54.69%] [G loss: 0.791069]\n",
      "epoch:34 step:27034 [D loss: 0.650940, acc.: 58.59%] [G loss: 0.752744]\n",
      "epoch:34 step:27035 [D loss: 0.683698, acc.: 57.03%] [G loss: 0.767508]\n",
      "epoch:34 step:27036 [D loss: 0.666145, acc.: 55.47%] [G loss: 0.779175]\n",
      "epoch:34 step:27037 [D loss: 0.673935, acc.: 57.03%] [G loss: 0.776944]\n",
      "epoch:34 step:27038 [D loss: 0.690264, acc.: 60.94%] [G loss: 0.757165]\n",
      "epoch:34 step:27039 [D loss: 0.701458, acc.: 46.88%] [G loss: 0.788251]\n",
      "epoch:34 step:27040 [D loss: 0.692842, acc.: 53.12%] [G loss: 0.769078]\n",
      "epoch:34 step:27041 [D loss: 0.745716, acc.: 45.31%] [G loss: 0.740835]\n",
      "epoch:34 step:27042 [D loss: 0.720869, acc.: 44.53%] [G loss: 0.773925]\n",
      "epoch:34 step:27043 [D loss: 0.730350, acc.: 42.97%] [G loss: 0.843136]\n",
      "epoch:34 step:27044 [D loss: 0.654561, acc.: 54.69%] [G loss: 0.892849]\n",
      "epoch:34 step:27045 [D loss: 0.681302, acc.: 60.16%] [G loss: 0.842257]\n",
      "epoch:34 step:27046 [D loss: 0.701774, acc.: 50.00%] [G loss: 0.800718]\n",
      "epoch:34 step:27047 [D loss: 0.706506, acc.: 51.56%] [G loss: 0.846717]\n",
      "epoch:34 step:27048 [D loss: 0.653589, acc.: 65.62%] [G loss: 0.845200]\n",
      "epoch:34 step:27049 [D loss: 0.703656, acc.: 46.88%] [G loss: 0.843372]\n",
      "epoch:34 step:27050 [D loss: 0.672467, acc.: 57.03%] [G loss: 0.807409]\n",
      "epoch:34 step:27051 [D loss: 0.656534, acc.: 57.03%] [G loss: 0.818858]\n",
      "epoch:34 step:27052 [D loss: 0.627771, acc.: 67.97%] [G loss: 0.771512]\n",
      "epoch:34 step:27053 [D loss: 0.654271, acc.: 57.81%] [G loss: 0.816741]\n",
      "epoch:34 step:27054 [D loss: 0.722988, acc.: 42.97%] [G loss: 0.788706]\n",
      "epoch:34 step:27055 [D loss: 0.697895, acc.: 53.91%] [G loss: 0.815551]\n",
      "epoch:34 step:27056 [D loss: 0.693389, acc.: 53.91%] [G loss: 0.835014]\n",
      "epoch:34 step:27057 [D loss: 0.740099, acc.: 38.28%] [G loss: 0.745579]\n",
      "epoch:34 step:27058 [D loss: 0.664536, acc.: 64.84%] [G loss: 0.752362]\n",
      "epoch:34 step:27059 [D loss: 0.670510, acc.: 65.62%] [G loss: 0.802531]\n",
      "epoch:34 step:27060 [D loss: 0.646583, acc.: 64.84%] [G loss: 0.762552]\n",
      "epoch:34 step:27061 [D loss: 0.689296, acc.: 52.34%] [G loss: 0.735909]\n",
      "epoch:34 step:27062 [D loss: 0.714767, acc.: 48.44%] [G loss: 0.710962]\n",
      "epoch:34 step:27063 [D loss: 0.760506, acc.: 39.06%] [G loss: 0.676190]\n",
      "epoch:34 step:27064 [D loss: 0.723957, acc.: 47.66%] [G loss: 0.712646]\n",
      "epoch:34 step:27065 [D loss: 0.714479, acc.: 46.88%] [G loss: 0.724444]\n",
      "epoch:34 step:27066 [D loss: 0.727951, acc.: 43.75%] [G loss: 0.783892]\n",
      "epoch:34 step:27067 [D loss: 0.792558, acc.: 33.59%] [G loss: 0.685255]\n",
      "epoch:34 step:27068 [D loss: 0.781080, acc.: 35.16%] [G loss: 0.749215]\n",
      "epoch:34 step:27069 [D loss: 0.690860, acc.: 55.47%] [G loss: 0.763818]\n",
      "epoch:34 step:27070 [D loss: 0.681392, acc.: 55.47%] [G loss: 0.866234]\n",
      "epoch:34 step:27071 [D loss: 0.651139, acc.: 61.72%] [G loss: 0.872664]\n",
      "epoch:34 step:27072 [D loss: 0.669796, acc.: 52.34%] [G loss: 0.804999]\n",
      "epoch:34 step:27073 [D loss: 0.733065, acc.: 46.09%] [G loss: 0.753637]\n",
      "epoch:34 step:27074 [D loss: 0.672963, acc.: 61.72%] [G loss: 0.831790]\n",
      "epoch:34 step:27075 [D loss: 0.681332, acc.: 55.47%] [G loss: 0.764679]\n",
      "epoch:34 step:27076 [D loss: 0.741146, acc.: 38.28%] [G loss: 0.822831]\n",
      "epoch:34 step:27077 [D loss: 0.652431, acc.: 61.72%] [G loss: 0.900205]\n",
      "epoch:34 step:27078 [D loss: 0.687319, acc.: 55.47%] [G loss: 0.843069]\n",
      "epoch:34 step:27079 [D loss: 0.677999, acc.: 56.25%] [G loss: 0.816785]\n",
      "epoch:34 step:27080 [D loss: 0.739254, acc.: 44.53%] [G loss: 0.754579]\n",
      "epoch:34 step:27081 [D loss: 0.667899, acc.: 61.72%] [G loss: 0.811644]\n",
      "epoch:34 step:27082 [D loss: 0.644041, acc.: 66.41%] [G loss: 0.722462]\n",
      "epoch:34 step:27083 [D loss: 0.700988, acc.: 53.91%] [G loss: 0.733039]\n",
      "epoch:34 step:27084 [D loss: 0.617127, acc.: 71.88%] [G loss: 0.710039]\n",
      "epoch:34 step:27085 [D loss: 0.642568, acc.: 65.62%] [G loss: 0.715270]\n",
      "epoch:34 step:27086 [D loss: 0.706485, acc.: 53.91%] [G loss: 0.756765]\n",
      "epoch:34 step:27087 [D loss: 0.687300, acc.: 60.94%] [G loss: 0.781647]\n",
      "epoch:34 step:27088 [D loss: 0.653300, acc.: 65.62%] [G loss: 0.808158]\n",
      "epoch:34 step:27089 [D loss: 0.686492, acc.: 57.03%] [G loss: 0.724213]\n",
      "epoch:34 step:27090 [D loss: 0.732039, acc.: 45.31%] [G loss: 0.752262]\n",
      "epoch:34 step:27091 [D loss: 0.729309, acc.: 44.53%] [G loss: 0.755691]\n",
      "epoch:34 step:27092 [D loss: 0.667053, acc.: 63.28%] [G loss: 0.772785]\n",
      "epoch:34 step:27093 [D loss: 0.677531, acc.: 54.69%] [G loss: 0.795152]\n",
      "epoch:34 step:27094 [D loss: 0.737207, acc.: 39.06%] [G loss: 0.728710]\n",
      "epoch:34 step:27095 [D loss: 0.696268, acc.: 46.88%] [G loss: 0.751865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27096 [D loss: 0.713450, acc.: 43.75%] [G loss: 0.735305]\n",
      "epoch:34 step:27097 [D loss: 0.629123, acc.: 73.44%] [G loss: 0.852989]\n",
      "epoch:34 step:27098 [D loss: 0.687764, acc.: 60.16%] [G loss: 0.817751]\n",
      "epoch:34 step:27099 [D loss: 0.734582, acc.: 40.62%] [G loss: 0.734378]\n",
      "epoch:34 step:27100 [D loss: 0.752894, acc.: 49.22%] [G loss: 0.773989]\n",
      "epoch:34 step:27101 [D loss: 0.707178, acc.: 46.09%] [G loss: 0.737301]\n",
      "epoch:34 step:27102 [D loss: 0.699298, acc.: 52.34%] [G loss: 0.735597]\n",
      "epoch:34 step:27103 [D loss: 0.733200, acc.: 43.75%] [G loss: 0.741513]\n",
      "epoch:34 step:27104 [D loss: 0.705076, acc.: 53.91%] [G loss: 0.726444]\n",
      "epoch:34 step:27105 [D loss: 0.673240, acc.: 60.16%] [G loss: 0.799079]\n",
      "epoch:34 step:27106 [D loss: 0.736584, acc.: 41.41%] [G loss: 0.741745]\n",
      "epoch:34 step:27107 [D loss: 0.644736, acc.: 64.06%] [G loss: 0.756631]\n",
      "epoch:34 step:27108 [D loss: 0.651474, acc.: 66.41%] [G loss: 0.755392]\n",
      "epoch:34 step:27109 [D loss: 0.684044, acc.: 55.47%] [G loss: 0.890099]\n",
      "epoch:34 step:27110 [D loss: 0.694249, acc.: 54.69%] [G loss: 0.781829]\n",
      "epoch:34 step:27111 [D loss: 0.683569, acc.: 57.81%] [G loss: 0.774774]\n",
      "epoch:34 step:27112 [D loss: 0.712292, acc.: 50.00%] [G loss: 0.782376]\n",
      "epoch:34 step:27113 [D loss: 0.628245, acc.: 71.88%] [G loss: 0.778532]\n",
      "epoch:34 step:27114 [D loss: 0.694278, acc.: 59.38%] [G loss: 0.772711]\n",
      "epoch:34 step:27115 [D loss: 0.695183, acc.: 52.34%] [G loss: 0.699813]\n",
      "epoch:34 step:27116 [D loss: 0.684643, acc.: 53.91%] [G loss: 0.741592]\n",
      "epoch:34 step:27117 [D loss: 0.703155, acc.: 47.66%] [G loss: 0.736257]\n",
      "epoch:34 step:27118 [D loss: 0.694258, acc.: 54.69%] [G loss: 0.733274]\n",
      "epoch:34 step:27119 [D loss: 0.696890, acc.: 59.38%] [G loss: 0.803013]\n",
      "epoch:34 step:27120 [D loss: 0.666323, acc.: 61.72%] [G loss: 0.777279]\n",
      "epoch:34 step:27121 [D loss: 0.640975, acc.: 65.62%] [G loss: 0.815016]\n",
      "epoch:34 step:27122 [D loss: 0.693027, acc.: 52.34%] [G loss: 0.806638]\n",
      "epoch:34 step:27123 [D loss: 0.709479, acc.: 44.53%] [G loss: 0.799399]\n",
      "epoch:34 step:27124 [D loss: 0.702170, acc.: 52.34%] [G loss: 0.851861]\n",
      "epoch:34 step:27125 [D loss: 0.702593, acc.: 54.69%] [G loss: 0.753221]\n",
      "epoch:34 step:27126 [D loss: 0.695445, acc.: 50.78%] [G loss: 0.773737]\n",
      "epoch:34 step:27127 [D loss: 0.751793, acc.: 36.72%] [G loss: 0.836835]\n",
      "epoch:34 step:27128 [D loss: 0.724484, acc.: 40.62%] [G loss: 0.780630]\n",
      "epoch:34 step:27129 [D loss: 0.706363, acc.: 48.44%] [G loss: 0.746330]\n",
      "epoch:34 step:27130 [D loss: 0.666658, acc.: 67.19%] [G loss: 0.783689]\n",
      "epoch:34 step:27131 [D loss: 0.669252, acc.: 62.50%] [G loss: 0.830104]\n",
      "epoch:34 step:27132 [D loss: 0.683367, acc.: 52.34%] [G loss: 0.727383]\n",
      "epoch:34 step:27133 [D loss: 0.676699, acc.: 60.16%] [G loss: 0.844160]\n",
      "epoch:34 step:27134 [D loss: 0.705849, acc.: 50.00%] [G loss: 0.768332]\n",
      "epoch:34 step:27135 [D loss: 0.679112, acc.: 54.69%] [G loss: 0.829695]\n",
      "epoch:34 step:27136 [D loss: 0.655225, acc.: 60.94%] [G loss: 0.776978]\n",
      "epoch:34 step:27137 [D loss: 0.656232, acc.: 57.03%] [G loss: 0.787452]\n",
      "epoch:34 step:27138 [D loss: 0.707541, acc.: 53.91%] [G loss: 0.838410]\n",
      "epoch:34 step:27139 [D loss: 0.685249, acc.: 50.00%] [G loss: 0.864713]\n",
      "epoch:34 step:27140 [D loss: 0.636429, acc.: 69.53%] [G loss: 0.822183]\n",
      "epoch:34 step:27141 [D loss: 0.665089, acc.: 63.28%] [G loss: 0.782640]\n",
      "epoch:34 step:27142 [D loss: 0.681650, acc.: 53.12%] [G loss: 0.756832]\n",
      "epoch:34 step:27143 [D loss: 0.637064, acc.: 68.75%] [G loss: 0.782744]\n",
      "epoch:34 step:27144 [D loss: 0.702666, acc.: 53.12%] [G loss: 0.768631]\n",
      "epoch:34 step:27145 [D loss: 0.677313, acc.: 57.03%] [G loss: 0.828664]\n",
      "epoch:34 step:27146 [D loss: 0.682421, acc.: 52.34%] [G loss: 0.699490]\n",
      "epoch:34 step:27147 [D loss: 0.731933, acc.: 35.94%] [G loss: 0.782953]\n",
      "epoch:34 step:27148 [D loss: 0.659404, acc.: 66.41%] [G loss: 0.772658]\n",
      "epoch:34 step:27149 [D loss: 0.602090, acc.: 74.22%] [G loss: 0.812304]\n",
      "epoch:34 step:27150 [D loss: 0.741194, acc.: 35.94%] [G loss: 0.717619]\n",
      "epoch:34 step:27151 [D loss: 0.621783, acc.: 73.44%] [G loss: 0.812717]\n",
      "epoch:34 step:27152 [D loss: 0.689337, acc.: 60.16%] [G loss: 0.802674]\n",
      "epoch:34 step:27153 [D loss: 0.704565, acc.: 47.66%] [G loss: 0.779171]\n",
      "epoch:34 step:27154 [D loss: 0.662896, acc.: 58.59%] [G loss: 0.858566]\n",
      "epoch:34 step:27155 [D loss: 0.675537, acc.: 56.25%] [G loss: 0.818285]\n",
      "epoch:34 step:27156 [D loss: 0.682123, acc.: 57.03%] [G loss: 0.759625]\n",
      "epoch:34 step:27157 [D loss: 0.681347, acc.: 58.59%] [G loss: 0.720035]\n",
      "epoch:34 step:27158 [D loss: 0.684492, acc.: 48.44%] [G loss: 0.737439]\n",
      "epoch:34 step:27159 [D loss: 0.651265, acc.: 60.94%] [G loss: 0.757368]\n",
      "epoch:34 step:27160 [D loss: 0.697107, acc.: 59.38%] [G loss: 0.796882]\n",
      "epoch:34 step:27161 [D loss: 0.651995, acc.: 59.38%] [G loss: 0.764515]\n",
      "epoch:34 step:27162 [D loss: 0.698796, acc.: 50.00%] [G loss: 0.808467]\n",
      "epoch:34 step:27163 [D loss: 0.703279, acc.: 51.56%] [G loss: 0.709635]\n",
      "epoch:34 step:27164 [D loss: 0.709590, acc.: 42.19%] [G loss: 0.739964]\n",
      "epoch:34 step:27165 [D loss: 0.685396, acc.: 55.47%] [G loss: 0.758179]\n",
      "epoch:34 step:27166 [D loss: 0.687176, acc.: 55.47%] [G loss: 0.772325]\n",
      "epoch:34 step:27167 [D loss: 0.688786, acc.: 49.22%] [G loss: 0.740075]\n",
      "epoch:34 step:27168 [D loss: 0.672211, acc.: 55.47%] [G loss: 0.749696]\n",
      "epoch:34 step:27169 [D loss: 0.711854, acc.: 48.44%] [G loss: 0.742099]\n",
      "epoch:34 step:27170 [D loss: 0.661992, acc.: 64.06%] [G loss: 0.835454]\n",
      "epoch:34 step:27171 [D loss: 0.692231, acc.: 53.12%] [G loss: 0.751269]\n",
      "epoch:34 step:27172 [D loss: 0.653654, acc.: 64.06%] [G loss: 0.765269]\n",
      "epoch:34 step:27173 [D loss: 0.650731, acc.: 64.84%] [G loss: 0.788426]\n",
      "epoch:34 step:27174 [D loss: 0.647917, acc.: 62.50%] [G loss: 0.787808]\n",
      "epoch:34 step:27175 [D loss: 0.680184, acc.: 61.72%] [G loss: 0.828989]\n",
      "epoch:34 step:27176 [D loss: 0.615080, acc.: 73.44%] [G loss: 0.868774]\n",
      "epoch:34 step:27177 [D loss: 0.733594, acc.: 40.62%] [G loss: 0.820749]\n",
      "epoch:34 step:27178 [D loss: 0.700059, acc.: 49.22%] [G loss: 0.767865]\n",
      "epoch:34 step:27179 [D loss: 0.712566, acc.: 46.88%] [G loss: 0.791963]\n",
      "epoch:34 step:27180 [D loss: 0.662035, acc.: 67.97%] [G loss: 0.762001]\n",
      "epoch:34 step:27181 [D loss: 0.718363, acc.: 46.09%] [G loss: 0.768636]\n",
      "epoch:34 step:27182 [D loss: 0.635809, acc.: 64.06%] [G loss: 0.738214]\n",
      "epoch:34 step:27183 [D loss: 0.650402, acc.: 62.50%] [G loss: 0.831715]\n",
      "epoch:34 step:27184 [D loss: 0.683354, acc.: 57.03%] [G loss: 0.835750]\n",
      "epoch:34 step:27185 [D loss: 0.674338, acc.: 52.34%] [G loss: 0.826469]\n",
      "epoch:34 step:27186 [D loss: 0.679792, acc.: 56.25%] [G loss: 0.855033]\n",
      "epoch:34 step:27187 [D loss: 0.691527, acc.: 52.34%] [G loss: 0.779330]\n",
      "epoch:34 step:27188 [D loss: 0.726414, acc.: 43.75%] [G loss: 0.770079]\n",
      "epoch:34 step:27189 [D loss: 0.680426, acc.: 56.25%] [G loss: 0.750896]\n",
      "epoch:34 step:27190 [D loss: 0.745009, acc.: 42.97%] [G loss: 0.663222]\n",
      "epoch:34 step:27191 [D loss: 0.695300, acc.: 53.91%] [G loss: 0.708955]\n",
      "epoch:34 step:27192 [D loss: 0.682187, acc.: 55.47%] [G loss: 0.717070]\n",
      "epoch:34 step:27193 [D loss: 0.709402, acc.: 44.53%] [G loss: 0.753441]\n",
      "epoch:34 step:27194 [D loss: 0.626178, acc.: 71.09%] [G loss: 0.762040]\n",
      "epoch:34 step:27195 [D loss: 0.708812, acc.: 47.66%] [G loss: 0.753191]\n",
      "epoch:34 step:27196 [D loss: 0.690984, acc.: 62.50%] [G loss: 0.785793]\n",
      "epoch:34 step:27197 [D loss: 0.693503, acc.: 52.34%] [G loss: 0.719549]\n",
      "epoch:34 step:27198 [D loss: 0.689469, acc.: 58.59%] [G loss: 0.755042]\n",
      "epoch:34 step:27199 [D loss: 0.604132, acc.: 75.78%] [G loss: 0.785883]\n",
      "epoch:34 step:27200 [D loss: 0.676082, acc.: 57.03%] [G loss: 0.769910]\n",
      "epoch:34 step:27201 [D loss: 0.697897, acc.: 53.12%] [G loss: 0.756658]\n",
      "epoch:34 step:27202 [D loss: 0.699578, acc.: 52.34%] [G loss: 0.801090]\n",
      "epoch:34 step:27203 [D loss: 0.656281, acc.: 59.38%] [G loss: 0.811511]\n",
      "epoch:34 step:27204 [D loss: 0.687675, acc.: 55.47%] [G loss: 0.761526]\n",
      "epoch:34 step:27205 [D loss: 0.637254, acc.: 63.28%] [G loss: 0.839086]\n",
      "epoch:34 step:27206 [D loss: 0.648548, acc.: 68.75%] [G loss: 0.802364]\n",
      "epoch:34 step:27207 [D loss: 0.654674, acc.: 61.72%] [G loss: 0.754208]\n",
      "epoch:34 step:27208 [D loss: 0.699352, acc.: 50.00%] [G loss: 0.771718]\n",
      "epoch:34 step:27209 [D loss: 0.711100, acc.: 55.47%] [G loss: 0.826057]\n",
      "epoch:34 step:27210 [D loss: 0.652519, acc.: 66.41%] [G loss: 0.890318]\n",
      "epoch:34 step:27211 [D loss: 0.660603, acc.: 60.16%] [G loss: 0.736191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27212 [D loss: 0.648706, acc.: 62.50%] [G loss: 0.754629]\n",
      "epoch:34 step:27213 [D loss: 0.682522, acc.: 53.12%] [G loss: 0.762791]\n",
      "epoch:34 step:27214 [D loss: 0.704507, acc.: 51.56%] [G loss: 0.747821]\n",
      "epoch:34 step:27215 [D loss: 0.659966, acc.: 62.50%] [G loss: 0.742220]\n",
      "epoch:34 step:27216 [D loss: 0.652723, acc.: 64.84%] [G loss: 0.765131]\n",
      "epoch:34 step:27217 [D loss: 0.679532, acc.: 57.03%] [G loss: 0.789875]\n",
      "epoch:34 step:27218 [D loss: 0.706708, acc.: 53.91%] [G loss: 0.818661]\n",
      "epoch:34 step:27219 [D loss: 0.664800, acc.: 63.28%] [G loss: 0.815111]\n",
      "epoch:34 step:27220 [D loss: 0.672756, acc.: 54.69%] [G loss: 0.748371]\n",
      "epoch:34 step:27221 [D loss: 0.704625, acc.: 51.56%] [G loss: 0.794110]\n",
      "epoch:34 step:27222 [D loss: 0.696885, acc.: 51.56%] [G loss: 0.767498]\n",
      "epoch:34 step:27223 [D loss: 0.738861, acc.: 45.31%] [G loss: 0.715742]\n",
      "epoch:34 step:27224 [D loss: 0.708262, acc.: 50.00%] [G loss: 0.826017]\n",
      "epoch:34 step:27225 [D loss: 0.693210, acc.: 47.66%] [G loss: 0.804143]\n",
      "epoch:34 step:27226 [D loss: 0.695071, acc.: 48.44%] [G loss: 0.795064]\n",
      "epoch:34 step:27227 [D loss: 0.698757, acc.: 49.22%] [G loss: 0.771714]\n",
      "epoch:34 step:27228 [D loss: 0.742510, acc.: 44.53%] [G loss: 0.724959]\n",
      "epoch:34 step:27229 [D loss: 0.687416, acc.: 53.12%] [G loss: 0.756718]\n",
      "epoch:34 step:27230 [D loss: 0.673358, acc.: 60.16%] [G loss: 0.812658]\n",
      "epoch:34 step:27231 [D loss: 0.682466, acc.: 53.91%] [G loss: 0.732181]\n",
      "epoch:34 step:27232 [D loss: 0.713105, acc.: 47.66%] [G loss: 0.792972]\n",
      "epoch:34 step:27233 [D loss: 0.710446, acc.: 49.22%] [G loss: 0.759822]\n",
      "epoch:34 step:27234 [D loss: 0.692453, acc.: 53.91%] [G loss: 0.735058]\n",
      "epoch:34 step:27235 [D loss: 0.669305, acc.: 57.81%] [G loss: 0.883401]\n",
      "epoch:34 step:27236 [D loss: 0.691549, acc.: 51.56%] [G loss: 0.823609]\n",
      "epoch:34 step:27237 [D loss: 0.644207, acc.: 60.16%] [G loss: 0.823550]\n",
      "epoch:34 step:27238 [D loss: 0.690917, acc.: 50.00%] [G loss: 0.775536]\n",
      "epoch:34 step:27239 [D loss: 0.636081, acc.: 64.06%] [G loss: 0.855798]\n",
      "epoch:34 step:27240 [D loss: 0.629471, acc.: 70.31%] [G loss: 0.824256]\n",
      "epoch:34 step:27241 [D loss: 0.660998, acc.: 60.16%] [G loss: 0.869223]\n",
      "epoch:34 step:27242 [D loss: 0.664735, acc.: 61.72%] [G loss: 0.772310]\n",
      "epoch:34 step:27243 [D loss: 0.639018, acc.: 68.75%] [G loss: 0.796483]\n",
      "epoch:34 step:27244 [D loss: 0.653978, acc.: 67.19%] [G loss: 0.886547]\n",
      "epoch:34 step:27245 [D loss: 0.648939, acc.: 65.62%] [G loss: 0.689783]\n",
      "epoch:34 step:27246 [D loss: 0.787997, acc.: 38.28%] [G loss: 0.727024]\n",
      "epoch:34 step:27247 [D loss: 0.673643, acc.: 63.28%] [G loss: 0.740953]\n",
      "epoch:34 step:27248 [D loss: 0.668982, acc.: 60.94%] [G loss: 0.704317]\n",
      "epoch:34 step:27249 [D loss: 0.603638, acc.: 71.09%] [G loss: 0.733884]\n",
      "epoch:34 step:27250 [D loss: 0.633165, acc.: 66.41%] [G loss: 0.721327]\n",
      "epoch:34 step:27251 [D loss: 0.659878, acc.: 57.81%] [G loss: 0.775809]\n",
      "epoch:34 step:27252 [D loss: 0.601773, acc.: 70.31%] [G loss: 0.796326]\n",
      "epoch:34 step:27253 [D loss: 0.708300, acc.: 46.09%] [G loss: 0.748301]\n",
      "epoch:34 step:27254 [D loss: 0.633354, acc.: 74.22%] [G loss: 0.746504]\n",
      "epoch:34 step:27255 [D loss: 0.730108, acc.: 48.44%] [G loss: 0.736296]\n",
      "epoch:34 step:27256 [D loss: 0.709264, acc.: 49.22%] [G loss: 0.740426]\n",
      "epoch:34 step:27257 [D loss: 0.720713, acc.: 45.31%] [G loss: 0.667709]\n",
      "epoch:34 step:27258 [D loss: 0.730500, acc.: 46.88%] [G loss: 0.663500]\n",
      "epoch:34 step:27259 [D loss: 0.659454, acc.: 57.03%] [G loss: 0.790457]\n",
      "epoch:34 step:27260 [D loss: 0.694378, acc.: 50.78%] [G loss: 0.753893]\n",
      "epoch:34 step:27261 [D loss: 0.801294, acc.: 30.47%] [G loss: 0.753806]\n",
      "epoch:34 step:27262 [D loss: 0.718458, acc.: 50.78%] [G loss: 0.730425]\n",
      "epoch:34 step:27263 [D loss: 0.706317, acc.: 48.44%] [G loss: 0.762340]\n",
      "epoch:34 step:27264 [D loss: 0.693041, acc.: 44.53%] [G loss: 0.805438]\n",
      "epoch:34 step:27265 [D loss: 0.669688, acc.: 60.16%] [G loss: 0.820651]\n",
      "epoch:34 step:27266 [D loss: 0.678918, acc.: 60.94%] [G loss: 0.802510]\n",
      "epoch:34 step:27267 [D loss: 0.663068, acc.: 60.16%] [G loss: 0.823761]\n",
      "epoch:34 step:27268 [D loss: 0.643549, acc.: 65.62%] [G loss: 0.837091]\n",
      "epoch:34 step:27269 [D loss: 0.737392, acc.: 45.31%] [G loss: 0.738999]\n",
      "epoch:34 step:27270 [D loss: 0.678291, acc.: 58.59%] [G loss: 0.860578]\n",
      "epoch:34 step:27271 [D loss: 0.672251, acc.: 53.12%] [G loss: 0.788452]\n",
      "epoch:34 step:27272 [D loss: 0.666123, acc.: 58.59%] [G loss: 0.752462]\n",
      "epoch:34 step:27273 [D loss: 0.676214, acc.: 68.75%] [G loss: 0.849512]\n",
      "epoch:34 step:27274 [D loss: 0.701360, acc.: 53.91%] [G loss: 0.767473]\n",
      "epoch:34 step:27275 [D loss: 0.685989, acc.: 60.16%] [G loss: 0.770214]\n",
      "epoch:34 step:27276 [D loss: 0.678033, acc.: 54.69%] [G loss: 0.795384]\n",
      "epoch:34 step:27277 [D loss: 0.735506, acc.: 44.53%] [G loss: 0.693971]\n",
      "epoch:34 step:27278 [D loss: 0.698468, acc.: 52.34%] [G loss: 0.699734]\n",
      "epoch:34 step:27279 [D loss: 0.695260, acc.: 47.66%] [G loss: 0.807548]\n",
      "epoch:34 step:27280 [D loss: 0.657980, acc.: 64.06%] [G loss: 0.771033]\n",
      "epoch:34 step:27281 [D loss: 0.674009, acc.: 57.03%] [G loss: 0.765873]\n",
      "epoch:34 step:27282 [D loss: 0.703127, acc.: 53.91%] [G loss: 0.694801]\n",
      "epoch:34 step:27283 [D loss: 0.708378, acc.: 53.12%] [G loss: 0.731637]\n",
      "epoch:34 step:27284 [D loss: 0.707027, acc.: 43.75%] [G loss: 0.737305]\n",
      "epoch:34 step:27285 [D loss: 0.679769, acc.: 57.03%] [G loss: 0.756012]\n",
      "epoch:34 step:27286 [D loss: 0.697505, acc.: 52.34%] [G loss: 0.742343]\n",
      "epoch:34 step:27287 [D loss: 0.736729, acc.: 42.97%] [G loss: 0.710731]\n",
      "epoch:34 step:27288 [D loss: 0.716356, acc.: 46.09%] [G loss: 0.708260]\n",
      "epoch:34 step:27289 [D loss: 0.673597, acc.: 58.59%] [G loss: 0.719305]\n",
      "epoch:34 step:27290 [D loss: 0.658008, acc.: 66.41%] [G loss: 0.790107]\n",
      "epoch:34 step:27291 [D loss: 0.722445, acc.: 46.09%] [G loss: 0.730740]\n",
      "epoch:34 step:27292 [D loss: 0.659988, acc.: 60.16%] [G loss: 0.861563]\n",
      "epoch:34 step:27293 [D loss: 0.684700, acc.: 57.03%] [G loss: 0.783332]\n",
      "epoch:34 step:27294 [D loss: 0.688678, acc.: 57.03%] [G loss: 0.854433]\n",
      "epoch:34 step:27295 [D loss: 0.686701, acc.: 55.47%] [G loss: 0.768648]\n",
      "epoch:34 step:27296 [D loss: 0.716173, acc.: 49.22%] [G loss: 0.784157]\n",
      "epoch:34 step:27297 [D loss: 0.639706, acc.: 67.19%] [G loss: 0.834262]\n",
      "epoch:34 step:27298 [D loss: 0.666191, acc.: 62.50%] [G loss: 0.785931]\n",
      "epoch:34 step:27299 [D loss: 0.696689, acc.: 55.47%] [G loss: 0.724496]\n",
      "epoch:34 step:27300 [D loss: 0.698211, acc.: 53.91%] [G loss: 0.733909]\n",
      "epoch:34 step:27301 [D loss: 0.678287, acc.: 56.25%] [G loss: 0.784877]\n",
      "epoch:34 step:27302 [D loss: 0.686182, acc.: 52.34%] [G loss: 0.767144]\n",
      "epoch:34 step:27303 [D loss: 0.657469, acc.: 64.84%] [G loss: 0.797514]\n",
      "epoch:34 step:27304 [D loss: 0.663370, acc.: 60.94%] [G loss: 0.806274]\n",
      "epoch:34 step:27305 [D loss: 0.675648, acc.: 57.03%] [G loss: 0.746559]\n",
      "epoch:34 step:27306 [D loss: 0.660501, acc.: 63.28%] [G loss: 0.838158]\n",
      "epoch:34 step:27307 [D loss: 0.618099, acc.: 71.88%] [G loss: 0.791358]\n",
      "epoch:34 step:27308 [D loss: 0.671068, acc.: 55.47%] [G loss: 0.805553]\n",
      "epoch:34 step:27309 [D loss: 0.667831, acc.: 57.03%] [G loss: 0.854533]\n",
      "epoch:34 step:27310 [D loss: 0.638333, acc.: 67.97%] [G loss: 0.870600]\n",
      "epoch:34 step:27311 [D loss: 0.670530, acc.: 57.03%] [G loss: 0.796750]\n",
      "epoch:34 step:27312 [D loss: 0.701329, acc.: 53.91%] [G loss: 0.774746]\n",
      "epoch:34 step:27313 [D loss: 0.677425, acc.: 60.16%] [G loss: 0.833871]\n",
      "epoch:34 step:27314 [D loss: 0.712782, acc.: 52.34%] [G loss: 0.767812]\n",
      "epoch:34 step:27315 [D loss: 0.694215, acc.: 53.12%] [G loss: 0.731206]\n",
      "epoch:34 step:27316 [D loss: 0.731737, acc.: 43.75%] [G loss: 0.708066]\n",
      "epoch:34 step:27317 [D loss: 0.652044, acc.: 57.81%] [G loss: 0.756052]\n",
      "epoch:34 step:27318 [D loss: 0.746482, acc.: 39.84%] [G loss: 0.719415]\n",
      "epoch:34 step:27319 [D loss: 0.688807, acc.: 53.91%] [G loss: 0.811830]\n",
      "epoch:34 step:27320 [D loss: 0.693108, acc.: 53.12%] [G loss: 0.754360]\n",
      "epoch:34 step:27321 [D loss: 0.690455, acc.: 53.12%] [G loss: 0.726158]\n",
      "epoch:34 step:27322 [D loss: 0.680602, acc.: 57.81%] [G loss: 0.815227]\n",
      "epoch:34 step:27323 [D loss: 0.695280, acc.: 49.22%] [G loss: 0.756534]\n",
      "epoch:34 step:27324 [D loss: 0.673605, acc.: 56.25%] [G loss: 0.850284]\n",
      "epoch:34 step:27325 [D loss: 0.719831, acc.: 47.66%] [G loss: 0.875612]\n",
      "epoch:34 step:27326 [D loss: 0.712863, acc.: 56.25%] [G loss: 0.832031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27327 [D loss: 0.713698, acc.: 49.22%] [G loss: 0.718965]\n",
      "epoch:34 step:27328 [D loss: 0.666423, acc.: 57.03%] [G loss: 0.760561]\n",
      "epoch:34 step:27329 [D loss: 0.696056, acc.: 50.00%] [G loss: 0.777718]\n",
      "epoch:34 step:27330 [D loss: 0.686789, acc.: 56.25%] [G loss: 0.736751]\n",
      "epoch:34 step:27331 [D loss: 0.652058, acc.: 64.84%] [G loss: 0.771098]\n",
      "epoch:34 step:27332 [D loss: 0.713564, acc.: 45.31%] [G loss: 0.708253]\n",
      "epoch:34 step:27333 [D loss: 0.640187, acc.: 67.19%] [G loss: 0.825776]\n",
      "epoch:34 step:27334 [D loss: 0.684742, acc.: 52.34%] [G loss: 0.698024]\n",
      "epoch:34 step:27335 [D loss: 0.655142, acc.: 57.03%] [G loss: 0.799265]\n",
      "epoch:35 step:27336 [D loss: 0.631699, acc.: 67.97%] [G loss: 0.797688]\n",
      "epoch:35 step:27337 [D loss: 0.673935, acc.: 57.81%] [G loss: 0.811640]\n",
      "epoch:35 step:27338 [D loss: 0.716419, acc.: 47.66%] [G loss: 0.722717]\n",
      "epoch:35 step:27339 [D loss: 0.677121, acc.: 60.94%] [G loss: 0.738760]\n",
      "epoch:35 step:27340 [D loss: 0.702282, acc.: 57.03%] [G loss: 0.771844]\n",
      "epoch:35 step:27341 [D loss: 0.660402, acc.: 60.16%] [G loss: 0.757662]\n",
      "epoch:35 step:27342 [D loss: 0.667152, acc.: 60.94%] [G loss: 0.736429]\n",
      "epoch:35 step:27343 [D loss: 0.649527, acc.: 65.62%] [G loss: 0.804167]\n",
      "epoch:35 step:27344 [D loss: 0.719536, acc.: 54.69%] [G loss: 0.784629]\n",
      "epoch:35 step:27345 [D loss: 0.683018, acc.: 56.25%] [G loss: 0.780408]\n",
      "epoch:35 step:27346 [D loss: 0.749562, acc.: 44.53%] [G loss: 0.705161]\n",
      "epoch:35 step:27347 [D loss: 0.729365, acc.: 47.66%] [G loss: 0.705080]\n",
      "epoch:35 step:27348 [D loss: 0.664592, acc.: 56.25%] [G loss: 0.763119]\n",
      "epoch:35 step:27349 [D loss: 0.623374, acc.: 71.88%] [G loss: 0.871485]\n",
      "epoch:35 step:27350 [D loss: 0.761966, acc.: 36.72%] [G loss: 0.729826]\n",
      "epoch:35 step:27351 [D loss: 0.646574, acc.: 64.84%] [G loss: 0.700859]\n",
      "epoch:35 step:27352 [D loss: 0.655129, acc.: 68.75%] [G loss: 0.821030]\n",
      "epoch:35 step:27353 [D loss: 0.737201, acc.: 48.44%] [G loss: 0.804287]\n",
      "epoch:35 step:27354 [D loss: 0.709945, acc.: 51.56%] [G loss: 0.710125]\n",
      "epoch:35 step:27355 [D loss: 0.674830, acc.: 52.34%] [G loss: 0.791214]\n",
      "epoch:35 step:27356 [D loss: 0.678434, acc.: 60.16%] [G loss: 0.807915]\n",
      "epoch:35 step:27357 [D loss: 0.679192, acc.: 60.16%] [G loss: 0.792680]\n",
      "epoch:35 step:27358 [D loss: 0.699779, acc.: 53.91%] [G loss: 0.779306]\n",
      "epoch:35 step:27359 [D loss: 0.688414, acc.: 56.25%] [G loss: 0.742495]\n",
      "epoch:35 step:27360 [D loss: 0.678133, acc.: 57.03%] [G loss: 0.741199]\n",
      "epoch:35 step:27361 [D loss: 0.675909, acc.: 58.59%] [G loss: 0.727644]\n",
      "epoch:35 step:27362 [D loss: 0.648153, acc.: 63.28%] [G loss: 0.788667]\n",
      "epoch:35 step:27363 [D loss: 0.662638, acc.: 64.84%] [G loss: 0.770627]\n",
      "epoch:35 step:27364 [D loss: 0.676580, acc.: 60.94%] [G loss: 0.795475]\n",
      "epoch:35 step:27365 [D loss: 0.617017, acc.: 70.31%] [G loss: 0.812576]\n",
      "epoch:35 step:27366 [D loss: 0.680702, acc.: 59.38%] [G loss: 0.863272]\n",
      "epoch:35 step:27367 [D loss: 0.664434, acc.: 54.69%] [G loss: 0.873155]\n",
      "epoch:35 step:27368 [D loss: 0.645513, acc.: 64.06%] [G loss: 0.828510]\n",
      "epoch:35 step:27369 [D loss: 0.644896, acc.: 66.41%] [G loss: 0.782528]\n",
      "epoch:35 step:27370 [D loss: 0.755336, acc.: 41.41%] [G loss: 0.717117]\n",
      "epoch:35 step:27371 [D loss: 0.724094, acc.: 44.53%] [G loss: 0.704014]\n",
      "epoch:35 step:27372 [D loss: 0.710811, acc.: 50.00%] [G loss: 0.777771]\n",
      "epoch:35 step:27373 [D loss: 0.708556, acc.: 50.00%] [G loss: 0.779508]\n",
      "epoch:35 step:27374 [D loss: 0.652812, acc.: 63.28%] [G loss: 0.732796]\n",
      "epoch:35 step:27375 [D loss: 0.715957, acc.: 50.78%] [G loss: 0.727185]\n",
      "epoch:35 step:27376 [D loss: 0.693158, acc.: 55.47%] [G loss: 0.796303]\n",
      "epoch:35 step:27377 [D loss: 0.779358, acc.: 38.28%] [G loss: 0.669151]\n",
      "epoch:35 step:27378 [D loss: 0.644393, acc.: 70.31%] [G loss: 0.725704]\n",
      "epoch:35 step:27379 [D loss: 0.705542, acc.: 50.00%] [G loss: 0.742260]\n",
      "epoch:35 step:27380 [D loss: 0.661347, acc.: 60.94%] [G loss: 0.733947]\n",
      "epoch:35 step:27381 [D loss: 0.663501, acc.: 58.59%] [G loss: 0.764342]\n",
      "epoch:35 step:27382 [D loss: 0.685855, acc.: 55.47%] [G loss: 0.740703]\n",
      "epoch:35 step:27383 [D loss: 0.675587, acc.: 56.25%] [G loss: 0.730495]\n",
      "epoch:35 step:27384 [D loss: 0.664215, acc.: 58.59%] [G loss: 0.681990]\n",
      "epoch:35 step:27385 [D loss: 0.721401, acc.: 48.44%] [G loss: 0.731516]\n",
      "epoch:35 step:27386 [D loss: 0.734497, acc.: 48.44%] [G loss: 0.764161]\n",
      "epoch:35 step:27387 [D loss: 0.652194, acc.: 60.16%] [G loss: 0.848314]\n",
      "epoch:35 step:27388 [D loss: 0.676542, acc.: 55.47%] [G loss: 0.730781]\n",
      "epoch:35 step:27389 [D loss: 0.771362, acc.: 35.16%] [G loss: 0.757739]\n",
      "epoch:35 step:27390 [D loss: 0.665371, acc.: 61.72%] [G loss: 0.797105]\n",
      "epoch:35 step:27391 [D loss: 0.732979, acc.: 43.75%] [G loss: 0.825118]\n",
      "epoch:35 step:27392 [D loss: 0.716998, acc.: 46.09%] [G loss: 0.847527]\n",
      "epoch:35 step:27393 [D loss: 0.689370, acc.: 50.00%] [G loss: 0.814421]\n",
      "epoch:35 step:27394 [D loss: 0.623775, acc.: 67.97%] [G loss: 0.905010]\n",
      "epoch:35 step:27395 [D loss: 0.614547, acc.: 71.88%] [G loss: 0.808389]\n",
      "epoch:35 step:27396 [D loss: 0.691473, acc.: 50.00%] [G loss: 0.863231]\n",
      "epoch:35 step:27397 [D loss: 0.664661, acc.: 62.50%] [G loss: 0.857716]\n",
      "epoch:35 step:27398 [D loss: 0.717418, acc.: 46.88%] [G loss: 0.846313]\n",
      "epoch:35 step:27399 [D loss: 0.674757, acc.: 53.12%] [G loss: 0.801947]\n",
      "epoch:35 step:27400 [D loss: 0.715488, acc.: 47.66%] [G loss: 0.756226]\n",
      "epoch:35 step:27401 [D loss: 0.707116, acc.: 52.34%] [G loss: 0.729989]\n",
      "epoch:35 step:27402 [D loss: 0.689421, acc.: 56.25%] [G loss: 0.730452]\n",
      "epoch:35 step:27403 [D loss: 0.661789, acc.: 64.84%] [G loss: 0.779667]\n",
      "epoch:35 step:27404 [D loss: 0.678016, acc.: 60.94%] [G loss: 0.839177]\n",
      "epoch:35 step:27405 [D loss: 0.725532, acc.: 42.19%] [G loss: 0.746451]\n",
      "epoch:35 step:27406 [D loss: 0.679160, acc.: 55.47%] [G loss: 0.749017]\n",
      "epoch:35 step:27407 [D loss: 0.667359, acc.: 52.34%] [G loss: 0.760341]\n",
      "epoch:35 step:27408 [D loss: 0.641397, acc.: 70.31%] [G loss: 0.751973]\n",
      "epoch:35 step:27409 [D loss: 0.656725, acc.: 64.06%] [G loss: 0.817843]\n",
      "epoch:35 step:27410 [D loss: 0.706337, acc.: 45.31%] [G loss: 0.731833]\n",
      "epoch:35 step:27411 [D loss: 0.713223, acc.: 49.22%] [G loss: 0.741734]\n",
      "epoch:35 step:27412 [D loss: 0.653968, acc.: 60.94%] [G loss: 0.712381]\n",
      "epoch:35 step:27413 [D loss: 0.702542, acc.: 49.22%] [G loss: 0.759411]\n",
      "epoch:35 step:27414 [D loss: 0.688125, acc.: 60.94%] [G loss: 0.780823]\n",
      "epoch:35 step:27415 [D loss: 0.683039, acc.: 53.91%] [G loss: 0.752642]\n",
      "epoch:35 step:27416 [D loss: 0.740935, acc.: 40.62%] [G loss: 0.728495]\n",
      "epoch:35 step:27417 [D loss: 0.683830, acc.: 52.34%] [G loss: 0.746449]\n",
      "epoch:35 step:27418 [D loss: 0.604437, acc.: 74.22%] [G loss: 0.819463]\n",
      "epoch:35 step:27419 [D loss: 0.715651, acc.: 45.31%] [G loss: 0.784778]\n",
      "epoch:35 step:27420 [D loss: 0.698386, acc.: 51.56%] [G loss: 0.770702]\n",
      "epoch:35 step:27421 [D loss: 0.639029, acc.: 65.62%] [G loss: 0.813220]\n",
      "epoch:35 step:27422 [D loss: 0.680435, acc.: 55.47%] [G loss: 0.805210]\n",
      "epoch:35 step:27423 [D loss: 0.691072, acc.: 50.78%] [G loss: 0.838927]\n",
      "epoch:35 step:27424 [D loss: 0.728789, acc.: 50.78%] [G loss: 0.833175]\n",
      "epoch:35 step:27425 [D loss: 0.702677, acc.: 50.00%] [G loss: 0.741611]\n",
      "epoch:35 step:27426 [D loss: 0.704536, acc.: 53.12%] [G loss: 0.737375]\n",
      "epoch:35 step:27427 [D loss: 0.684143, acc.: 46.88%] [G loss: 0.768163]\n",
      "epoch:35 step:27428 [D loss: 0.651891, acc.: 58.59%] [G loss: 0.822583]\n",
      "epoch:35 step:27429 [D loss: 0.650434, acc.: 67.19%] [G loss: 0.786632]\n",
      "epoch:35 step:27430 [D loss: 0.681460, acc.: 53.12%] [G loss: 0.812837]\n",
      "epoch:35 step:27431 [D loss: 0.695449, acc.: 53.12%] [G loss: 0.746480]\n",
      "epoch:35 step:27432 [D loss: 0.703912, acc.: 58.59%] [G loss: 0.833844]\n",
      "epoch:35 step:27433 [D loss: 0.617815, acc.: 75.78%] [G loss: 0.871197]\n",
      "epoch:35 step:27434 [D loss: 0.658346, acc.: 64.06%] [G loss: 0.843703]\n",
      "epoch:35 step:27435 [D loss: 0.686795, acc.: 53.12%] [G loss: 0.796253]\n",
      "epoch:35 step:27436 [D loss: 0.665423, acc.: 59.38%] [G loss: 0.826659]\n",
      "epoch:35 step:27437 [D loss: 0.646878, acc.: 68.75%] [G loss: 0.893896]\n",
      "epoch:35 step:27438 [D loss: 0.724488, acc.: 48.44%] [G loss: 0.795392]\n",
      "epoch:35 step:27439 [D loss: 0.714280, acc.: 51.56%] [G loss: 0.804457]\n",
      "epoch:35 step:27440 [D loss: 0.633993, acc.: 67.97%] [G loss: 0.750636]\n",
      "epoch:35 step:27441 [D loss: 0.677838, acc.: 53.91%] [G loss: 0.785602]\n",
      "epoch:35 step:27442 [D loss: 0.658163, acc.: 62.50%] [G loss: 0.787094]\n",
      "epoch:35 step:27443 [D loss: 0.733928, acc.: 46.88%] [G loss: 0.695697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27444 [D loss: 0.719351, acc.: 42.19%] [G loss: 0.653147]\n",
      "epoch:35 step:27445 [D loss: 0.678913, acc.: 58.59%] [G loss: 0.723381]\n",
      "epoch:35 step:27446 [D loss: 0.736640, acc.: 40.62%] [G loss: 0.698491]\n",
      "epoch:35 step:27447 [D loss: 0.665871, acc.: 57.81%] [G loss: 0.725724]\n",
      "epoch:35 step:27448 [D loss: 0.675560, acc.: 60.94%] [G loss: 0.763306]\n",
      "epoch:35 step:27449 [D loss: 0.637266, acc.: 75.78%] [G loss: 0.867917]\n",
      "epoch:35 step:27450 [D loss: 0.715775, acc.: 51.56%] [G loss: 0.773179]\n",
      "epoch:35 step:27451 [D loss: 0.658658, acc.: 58.59%] [G loss: 0.823096]\n",
      "epoch:35 step:27452 [D loss: 0.671166, acc.: 56.25%] [G loss: 0.699497]\n",
      "epoch:35 step:27453 [D loss: 0.703784, acc.: 50.00%] [G loss: 0.725981]\n",
      "epoch:35 step:27454 [D loss: 0.671394, acc.: 63.28%] [G loss: 0.678486]\n",
      "epoch:35 step:27455 [D loss: 0.677367, acc.: 57.81%] [G loss: 0.737231]\n",
      "epoch:35 step:27456 [D loss: 0.680576, acc.: 54.69%] [G loss: 0.768720]\n",
      "epoch:35 step:27457 [D loss: 0.740007, acc.: 40.62%] [G loss: 0.758315]\n",
      "epoch:35 step:27458 [D loss: 0.721965, acc.: 42.19%] [G loss: 0.826117]\n",
      "epoch:35 step:27459 [D loss: 0.687113, acc.: 57.03%] [G loss: 0.735635]\n",
      "epoch:35 step:27460 [D loss: 0.718127, acc.: 44.53%] [G loss: 0.685765]\n",
      "epoch:35 step:27461 [D loss: 0.686217, acc.: 52.34%] [G loss: 0.731395]\n",
      "epoch:35 step:27462 [D loss: 0.709019, acc.: 53.12%] [G loss: 0.773554]\n",
      "epoch:35 step:27463 [D loss: 0.673407, acc.: 60.16%] [G loss: 0.789683]\n",
      "epoch:35 step:27464 [D loss: 0.643993, acc.: 60.94%] [G loss: 0.779505]\n",
      "epoch:35 step:27465 [D loss: 0.670142, acc.: 53.12%] [G loss: 0.738959]\n",
      "epoch:35 step:27466 [D loss: 0.677574, acc.: 55.47%] [G loss: 0.797917]\n",
      "epoch:35 step:27467 [D loss: 0.680541, acc.: 61.72%] [G loss: 0.718718]\n",
      "epoch:35 step:27468 [D loss: 0.641890, acc.: 64.84%] [G loss: 0.807742]\n",
      "epoch:35 step:27469 [D loss: 0.685258, acc.: 54.69%] [G loss: 0.821881]\n",
      "epoch:35 step:27470 [D loss: 0.685501, acc.: 54.69%] [G loss: 0.778680]\n",
      "epoch:35 step:27471 [D loss: 0.679283, acc.: 54.69%] [G loss: 0.792246]\n",
      "epoch:35 step:27472 [D loss: 0.701101, acc.: 50.00%] [G loss: 0.833745]\n",
      "epoch:35 step:27473 [D loss: 0.740569, acc.: 42.19%] [G loss: 0.764967]\n",
      "epoch:35 step:27474 [D loss: 0.597675, acc.: 73.44%] [G loss: 0.741259]\n",
      "epoch:35 step:27475 [D loss: 0.692623, acc.: 53.91%] [G loss: 0.723763]\n",
      "epoch:35 step:27476 [D loss: 0.685339, acc.: 59.38%] [G loss: 0.806737]\n",
      "epoch:35 step:27477 [D loss: 0.650519, acc.: 67.97%] [G loss: 0.766278]\n",
      "epoch:35 step:27478 [D loss: 0.667301, acc.: 58.59%] [G loss: 0.822853]\n",
      "epoch:35 step:27479 [D loss: 0.713290, acc.: 44.53%] [G loss: 0.818490]\n",
      "epoch:35 step:27480 [D loss: 0.703981, acc.: 51.56%] [G loss: 0.703745]\n",
      "epoch:35 step:27481 [D loss: 0.649228, acc.: 62.50%] [G loss: 0.771369]\n",
      "epoch:35 step:27482 [D loss: 0.737448, acc.: 47.66%] [G loss: 0.755425]\n",
      "epoch:35 step:27483 [D loss: 0.692647, acc.: 50.78%] [G loss: 0.791029]\n",
      "epoch:35 step:27484 [D loss: 0.693033, acc.: 48.44%] [G loss: 0.771052]\n",
      "epoch:35 step:27485 [D loss: 0.768163, acc.: 33.59%] [G loss: 0.753049]\n",
      "epoch:35 step:27486 [D loss: 0.718668, acc.: 46.09%] [G loss: 0.753511]\n",
      "epoch:35 step:27487 [D loss: 0.663507, acc.: 59.38%] [G loss: 0.795148]\n",
      "epoch:35 step:27488 [D loss: 0.704837, acc.: 49.22%] [G loss: 0.764971]\n",
      "epoch:35 step:27489 [D loss: 0.647203, acc.: 64.84%] [G loss: 0.790150]\n",
      "epoch:35 step:27490 [D loss: 0.677977, acc.: 54.69%] [G loss: 0.816949]\n",
      "epoch:35 step:27491 [D loss: 0.701266, acc.: 50.00%] [G loss: 0.805919]\n",
      "epoch:35 step:27492 [D loss: 0.648998, acc.: 64.06%] [G loss: 0.803267]\n",
      "epoch:35 step:27493 [D loss: 0.656772, acc.: 60.94%] [G loss: 0.721268]\n",
      "epoch:35 step:27494 [D loss: 0.645416, acc.: 67.97%] [G loss: 0.835959]\n",
      "epoch:35 step:27495 [D loss: 0.664093, acc.: 63.28%] [G loss: 0.814561]\n",
      "epoch:35 step:27496 [D loss: 0.688373, acc.: 51.56%] [G loss: 0.796944]\n",
      "epoch:35 step:27497 [D loss: 0.702838, acc.: 50.78%] [G loss: 0.772788]\n",
      "epoch:35 step:27498 [D loss: 0.705227, acc.: 51.56%] [G loss: 0.799548]\n",
      "epoch:35 step:27499 [D loss: 0.644768, acc.: 65.62%] [G loss: 0.847394]\n",
      "epoch:35 step:27500 [D loss: 0.706333, acc.: 51.56%] [G loss: 0.770324]\n",
      "epoch:35 step:27501 [D loss: 0.606142, acc.: 69.53%] [G loss: 0.807322]\n",
      "epoch:35 step:27502 [D loss: 0.677685, acc.: 55.47%] [G loss: 0.810750]\n",
      "epoch:35 step:27503 [D loss: 0.651616, acc.: 60.94%] [G loss: 0.890307]\n",
      "epoch:35 step:27504 [D loss: 0.659819, acc.: 65.62%] [G loss: 0.784811]\n",
      "epoch:35 step:27505 [D loss: 0.662961, acc.: 60.94%] [G loss: 0.834806]\n",
      "epoch:35 step:27506 [D loss: 0.642169, acc.: 66.41%] [G loss: 0.815686]\n",
      "epoch:35 step:27507 [D loss: 0.716850, acc.: 46.09%] [G loss: 0.790706]\n",
      "epoch:35 step:27508 [D loss: 0.690053, acc.: 52.34%] [G loss: 0.796562]\n",
      "epoch:35 step:27509 [D loss: 0.690612, acc.: 55.47%] [G loss: 0.814408]\n",
      "epoch:35 step:27510 [D loss: 0.656876, acc.: 65.62%] [G loss: 0.702606]\n",
      "epoch:35 step:27511 [D loss: 0.682631, acc.: 63.28%] [G loss: 0.786957]\n",
      "epoch:35 step:27512 [D loss: 0.682698, acc.: 53.12%] [G loss: 0.771922]\n",
      "epoch:35 step:27513 [D loss: 0.735597, acc.: 46.09%] [G loss: 0.772928]\n",
      "epoch:35 step:27514 [D loss: 0.652911, acc.: 61.72%] [G loss: 0.777234]\n",
      "epoch:35 step:27515 [D loss: 0.687669, acc.: 59.38%] [G loss: 0.816878]\n",
      "epoch:35 step:27516 [D loss: 0.628395, acc.: 68.75%] [G loss: 0.769316]\n",
      "epoch:35 step:27517 [D loss: 0.685991, acc.: 53.91%] [G loss: 0.747765]\n",
      "epoch:35 step:27518 [D loss: 0.648340, acc.: 66.41%] [G loss: 0.750650]\n",
      "epoch:35 step:27519 [D loss: 0.695217, acc.: 49.22%] [G loss: 0.777481]\n",
      "epoch:35 step:27520 [D loss: 0.691832, acc.: 57.81%] [G loss: 0.782335]\n",
      "epoch:35 step:27521 [D loss: 0.712253, acc.: 50.00%] [G loss: 0.764688]\n",
      "epoch:35 step:27522 [D loss: 0.682185, acc.: 57.03%] [G loss: 0.836452]\n",
      "epoch:35 step:27523 [D loss: 0.686921, acc.: 56.25%] [G loss: 0.808290]\n",
      "epoch:35 step:27524 [D loss: 0.698525, acc.: 54.69%] [G loss: 0.735293]\n",
      "epoch:35 step:27525 [D loss: 0.701020, acc.: 54.69%] [G loss: 0.772599]\n",
      "epoch:35 step:27526 [D loss: 0.673877, acc.: 61.72%] [G loss: 0.773982]\n",
      "epoch:35 step:27527 [D loss: 0.655710, acc.: 66.41%] [G loss: 0.786452]\n",
      "epoch:35 step:27528 [D loss: 0.716381, acc.: 53.12%] [G loss: 0.722906]\n",
      "epoch:35 step:27529 [D loss: 0.728341, acc.: 46.09%] [G loss: 0.785356]\n",
      "epoch:35 step:27530 [D loss: 0.655532, acc.: 57.81%] [G loss: 0.814002]\n",
      "epoch:35 step:27531 [D loss: 0.690656, acc.: 53.91%] [G loss: 0.777862]\n",
      "epoch:35 step:27532 [D loss: 0.676178, acc.: 53.91%] [G loss: 0.793997]\n",
      "epoch:35 step:27533 [D loss: 0.656069, acc.: 63.28%] [G loss: 0.783410]\n",
      "epoch:35 step:27534 [D loss: 0.744722, acc.: 41.41%] [G loss: 0.741663]\n",
      "epoch:35 step:27535 [D loss: 0.649878, acc.: 64.06%] [G loss: 0.799762]\n",
      "epoch:35 step:27536 [D loss: 0.636142, acc.: 62.50%] [G loss: 0.887223]\n",
      "epoch:35 step:27537 [D loss: 0.735775, acc.: 39.06%] [G loss: 0.779330]\n",
      "epoch:35 step:27538 [D loss: 0.650298, acc.: 67.97%] [G loss: 0.809513]\n",
      "epoch:35 step:27539 [D loss: 0.681117, acc.: 52.34%] [G loss: 0.825305]\n",
      "epoch:35 step:27540 [D loss: 0.696135, acc.: 52.34%] [G loss: 0.774881]\n",
      "epoch:35 step:27541 [D loss: 0.660750, acc.: 60.94%] [G loss: 0.823919]\n",
      "epoch:35 step:27542 [D loss: 0.602375, acc.: 75.78%] [G loss: 0.809554]\n",
      "epoch:35 step:27543 [D loss: 0.715094, acc.: 47.66%] [G loss: 0.768619]\n",
      "epoch:35 step:27544 [D loss: 0.715430, acc.: 53.12%] [G loss: 0.778105]\n",
      "epoch:35 step:27545 [D loss: 0.677548, acc.: 55.47%] [G loss: 0.858539]\n",
      "epoch:35 step:27546 [D loss: 0.643060, acc.: 64.84%] [G loss: 0.819844]\n",
      "epoch:35 step:27547 [D loss: 0.657357, acc.: 60.94%] [G loss: 0.786163]\n",
      "epoch:35 step:27548 [D loss: 0.705228, acc.: 53.91%] [G loss: 0.802179]\n",
      "epoch:35 step:27549 [D loss: 0.698078, acc.: 52.34%] [G loss: 0.738467]\n",
      "epoch:35 step:27550 [D loss: 0.666671, acc.: 60.16%] [G loss: 0.767215]\n",
      "epoch:35 step:27551 [D loss: 0.717859, acc.: 46.88%] [G loss: 0.744406]\n",
      "epoch:35 step:27552 [D loss: 0.659166, acc.: 64.84%] [G loss: 0.798574]\n",
      "epoch:35 step:27553 [D loss: 0.703410, acc.: 53.91%] [G loss: 0.722933]\n",
      "epoch:35 step:27554 [D loss: 0.713808, acc.: 54.69%] [G loss: 0.787321]\n",
      "epoch:35 step:27555 [D loss: 0.665369, acc.: 59.38%] [G loss: 0.773637]\n",
      "epoch:35 step:27556 [D loss: 0.712313, acc.: 49.22%] [G loss: 0.744288]\n",
      "epoch:35 step:27557 [D loss: 0.753494, acc.: 36.72%] [G loss: 0.731675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27558 [D loss: 0.716092, acc.: 45.31%] [G loss: 0.696296]\n",
      "epoch:35 step:27559 [D loss: 0.686834, acc.: 57.81%] [G loss: 0.742349]\n",
      "epoch:35 step:27560 [D loss: 0.734529, acc.: 46.88%] [G loss: 0.786706]\n",
      "epoch:35 step:27561 [D loss: 0.704188, acc.: 53.12%] [G loss: 0.830743]\n",
      "epoch:35 step:27562 [D loss: 0.692222, acc.: 54.69%] [G loss: 0.814417]\n",
      "epoch:35 step:27563 [D loss: 0.726005, acc.: 46.88%] [G loss: 0.716093]\n",
      "epoch:35 step:27564 [D loss: 0.668419, acc.: 57.03%] [G loss: 0.791009]\n",
      "epoch:35 step:27565 [D loss: 0.740385, acc.: 43.75%] [G loss: 0.739752]\n",
      "epoch:35 step:27566 [D loss: 0.694096, acc.: 46.88%] [G loss: 0.799083]\n",
      "epoch:35 step:27567 [D loss: 0.712567, acc.: 50.00%] [G loss: 0.811052]\n",
      "epoch:35 step:27568 [D loss: 0.613281, acc.: 75.00%] [G loss: 0.820065]\n",
      "epoch:35 step:27569 [D loss: 0.708842, acc.: 50.78%] [G loss: 0.798550]\n",
      "epoch:35 step:27570 [D loss: 0.679524, acc.: 53.12%] [G loss: 0.758565]\n",
      "epoch:35 step:27571 [D loss: 0.710373, acc.: 51.56%] [G loss: 0.799785]\n",
      "epoch:35 step:27572 [D loss: 0.672941, acc.: 57.03%] [G loss: 0.750714]\n",
      "epoch:35 step:27573 [D loss: 0.724329, acc.: 42.97%] [G loss: 0.742580]\n",
      "epoch:35 step:27574 [D loss: 0.690543, acc.: 50.78%] [G loss: 0.856273]\n",
      "epoch:35 step:27575 [D loss: 0.659483, acc.: 61.72%] [G loss: 0.819856]\n",
      "epoch:35 step:27576 [D loss: 0.739892, acc.: 46.88%] [G loss: 0.786858]\n",
      "epoch:35 step:27577 [D loss: 0.701081, acc.: 53.12%] [G loss: 0.843384]\n",
      "epoch:35 step:27578 [D loss: 0.682542, acc.: 56.25%] [G loss: 0.827763]\n",
      "epoch:35 step:27579 [D loss: 0.697079, acc.: 56.25%] [G loss: 0.723296]\n",
      "epoch:35 step:27580 [D loss: 0.704254, acc.: 43.75%] [G loss: 0.726588]\n",
      "epoch:35 step:27581 [D loss: 0.690947, acc.: 50.00%] [G loss: 0.686972]\n",
      "epoch:35 step:27582 [D loss: 0.618915, acc.: 66.41%] [G loss: 0.764581]\n",
      "epoch:35 step:27583 [D loss: 0.667093, acc.: 60.94%] [G loss: 0.780661]\n",
      "epoch:35 step:27584 [D loss: 0.652669, acc.: 63.28%] [G loss: 0.791301]\n",
      "epoch:35 step:27585 [D loss: 0.647844, acc.: 61.72%] [G loss: 0.734070]\n",
      "epoch:35 step:27586 [D loss: 0.697347, acc.: 53.91%] [G loss: 0.762171]\n",
      "epoch:35 step:27587 [D loss: 0.666904, acc.: 59.38%] [G loss: 0.832730]\n",
      "epoch:35 step:27588 [D loss: 0.737882, acc.: 35.16%] [G loss: 0.740593]\n",
      "epoch:35 step:27589 [D loss: 0.692021, acc.: 50.78%] [G loss: 0.757664]\n",
      "epoch:35 step:27590 [D loss: 0.676127, acc.: 53.12%] [G loss: 0.835606]\n",
      "epoch:35 step:27591 [D loss: 0.716986, acc.: 49.22%] [G loss: 0.808932]\n",
      "epoch:35 step:27592 [D loss: 0.776442, acc.: 35.16%] [G loss: 0.706086]\n",
      "epoch:35 step:27593 [D loss: 0.646548, acc.: 60.94%] [G loss: 0.822651]\n",
      "epoch:35 step:27594 [D loss: 0.671817, acc.: 61.72%] [G loss: 0.845692]\n",
      "epoch:35 step:27595 [D loss: 0.666013, acc.: 59.38%] [G loss: 0.808581]\n",
      "epoch:35 step:27596 [D loss: 0.680137, acc.: 56.25%] [G loss: 0.932221]\n",
      "epoch:35 step:27597 [D loss: 0.639590, acc.: 67.19%] [G loss: 0.896951]\n",
      "epoch:35 step:27598 [D loss: 0.701067, acc.: 47.66%] [G loss: 0.803764]\n",
      "epoch:35 step:27599 [D loss: 0.684620, acc.: 57.03%] [G loss: 0.813060]\n",
      "epoch:35 step:27600 [D loss: 0.683740, acc.: 51.56%] [G loss: 0.770458]\n",
      "epoch:35 step:27601 [D loss: 0.645948, acc.: 61.72%] [G loss: 0.828501]\n",
      "epoch:35 step:27602 [D loss: 0.698243, acc.: 55.47%] [G loss: 0.816116]\n",
      "epoch:35 step:27603 [D loss: 0.674621, acc.: 55.47%] [G loss: 0.797488]\n",
      "epoch:35 step:27604 [D loss: 0.674033, acc.: 60.94%] [G loss: 0.769349]\n",
      "epoch:35 step:27605 [D loss: 0.717615, acc.: 48.44%] [G loss: 0.806533]\n",
      "epoch:35 step:27606 [D loss: 0.734847, acc.: 43.75%] [G loss: 0.817938]\n",
      "epoch:35 step:27607 [D loss: 0.658175, acc.: 61.72%] [G loss: 0.778683]\n",
      "epoch:35 step:27608 [D loss: 0.751529, acc.: 39.84%] [G loss: 0.764359]\n",
      "epoch:35 step:27609 [D loss: 0.674000, acc.: 54.69%] [G loss: 0.834852]\n",
      "epoch:35 step:27610 [D loss: 0.637854, acc.: 66.41%] [G loss: 0.818828]\n",
      "epoch:35 step:27611 [D loss: 0.614093, acc.: 72.66%] [G loss: 0.812403]\n",
      "epoch:35 step:27612 [D loss: 0.751945, acc.: 39.06%] [G loss: 0.848265]\n",
      "epoch:35 step:27613 [D loss: 0.719180, acc.: 44.53%] [G loss: 0.759632]\n",
      "epoch:35 step:27614 [D loss: 0.659910, acc.: 58.59%] [G loss: 0.773627]\n",
      "epoch:35 step:27615 [D loss: 0.674988, acc.: 60.16%] [G loss: 0.762672]\n",
      "epoch:35 step:27616 [D loss: 0.626571, acc.: 69.53%] [G loss: 0.785164]\n",
      "epoch:35 step:27617 [D loss: 0.721399, acc.: 46.09%] [G loss: 0.729004]\n",
      "epoch:35 step:27618 [D loss: 0.645371, acc.: 65.62%] [G loss: 0.856426]\n",
      "epoch:35 step:27619 [D loss: 0.677998, acc.: 60.94%] [G loss: 0.768007]\n",
      "epoch:35 step:27620 [D loss: 0.702778, acc.: 53.12%] [G loss: 0.754066]\n",
      "epoch:35 step:27621 [D loss: 0.670815, acc.: 63.28%] [G loss: 0.742626]\n",
      "epoch:35 step:27622 [D loss: 0.681116, acc.: 55.47%] [G loss: 0.786634]\n",
      "epoch:35 step:27623 [D loss: 0.709084, acc.: 53.12%] [G loss: 0.746361]\n",
      "epoch:35 step:27624 [D loss: 0.739491, acc.: 44.53%] [G loss: 0.819476]\n",
      "epoch:35 step:27625 [D loss: 0.656789, acc.: 65.62%] [G loss: 0.802656]\n",
      "epoch:35 step:27626 [D loss: 0.695848, acc.: 57.03%] [G loss: 0.770730]\n",
      "epoch:35 step:27627 [D loss: 0.720889, acc.: 46.88%] [G loss: 0.799053]\n",
      "epoch:35 step:27628 [D loss: 0.647534, acc.: 64.84%] [G loss: 0.775784]\n",
      "epoch:35 step:27629 [D loss: 0.692453, acc.: 55.47%] [G loss: 0.786425]\n",
      "epoch:35 step:27630 [D loss: 0.697706, acc.: 44.53%] [G loss: 0.813201]\n",
      "epoch:35 step:27631 [D loss: 0.687792, acc.: 52.34%] [G loss: 0.823131]\n",
      "epoch:35 step:27632 [D loss: 0.713822, acc.: 51.56%] [G loss: 0.725359]\n",
      "epoch:35 step:27633 [D loss: 0.703294, acc.: 47.66%] [G loss: 0.757289]\n",
      "epoch:35 step:27634 [D loss: 0.678629, acc.: 50.78%] [G loss: 0.769966]\n",
      "epoch:35 step:27635 [D loss: 0.745078, acc.: 46.09%] [G loss: 0.749952]\n",
      "epoch:35 step:27636 [D loss: 0.696290, acc.: 57.81%] [G loss: 0.867099]\n",
      "epoch:35 step:27637 [D loss: 0.681737, acc.: 61.72%] [G loss: 0.760488]\n",
      "epoch:35 step:27638 [D loss: 0.716619, acc.: 49.22%] [G loss: 0.631793]\n",
      "epoch:35 step:27639 [D loss: 0.663361, acc.: 62.50%] [G loss: 0.800273]\n",
      "epoch:35 step:27640 [D loss: 0.682319, acc.: 54.69%] [G loss: 0.791011]\n",
      "epoch:35 step:27641 [D loss: 0.639094, acc.: 62.50%] [G loss: 0.805500]\n",
      "epoch:35 step:27642 [D loss: 0.681987, acc.: 57.03%] [G loss: 0.772523]\n",
      "epoch:35 step:27643 [D loss: 0.683007, acc.: 53.12%] [G loss: 0.749763]\n",
      "epoch:35 step:27644 [D loss: 0.658098, acc.: 60.16%] [G loss: 0.757904]\n",
      "epoch:35 step:27645 [D loss: 0.664281, acc.: 63.28%] [G loss: 0.813694]\n",
      "epoch:35 step:27646 [D loss: 0.706138, acc.: 48.44%] [G loss: 0.855138]\n",
      "epoch:35 step:27647 [D loss: 0.734206, acc.: 45.31%] [G loss: 0.765443]\n",
      "epoch:35 step:27648 [D loss: 0.674420, acc.: 58.59%] [G loss: 0.775566]\n",
      "epoch:35 step:27649 [D loss: 0.659931, acc.: 61.72%] [G loss: 0.760317]\n",
      "epoch:35 step:27650 [D loss: 0.676762, acc.: 57.03%] [G loss: 0.791183]\n",
      "epoch:35 step:27651 [D loss: 0.674852, acc.: 56.25%] [G loss: 0.777724]\n",
      "epoch:35 step:27652 [D loss: 0.665962, acc.: 56.25%] [G loss: 0.703225]\n",
      "epoch:35 step:27653 [D loss: 0.678199, acc.: 61.72%] [G loss: 0.686931]\n",
      "epoch:35 step:27654 [D loss: 0.669122, acc.: 63.28%] [G loss: 0.722425]\n",
      "epoch:35 step:27655 [D loss: 0.675356, acc.: 63.28%] [G loss: 0.702869]\n",
      "epoch:35 step:27656 [D loss: 0.646159, acc.: 64.84%] [G loss: 0.783070]\n",
      "epoch:35 step:27657 [D loss: 0.655207, acc.: 64.06%] [G loss: 0.783982]\n",
      "epoch:35 step:27658 [D loss: 0.658193, acc.: 64.84%] [G loss: 0.802059]\n",
      "epoch:35 step:27659 [D loss: 0.651471, acc.: 65.62%] [G loss: 0.775009]\n",
      "epoch:35 step:27660 [D loss: 0.650171, acc.: 64.84%] [G loss: 0.880929]\n",
      "epoch:35 step:27661 [D loss: 0.707630, acc.: 51.56%] [G loss: 0.779051]\n",
      "epoch:35 step:27662 [D loss: 0.689197, acc.: 50.78%] [G loss: 0.680900]\n",
      "epoch:35 step:27663 [D loss: 0.709600, acc.: 48.44%] [G loss: 0.803708]\n",
      "epoch:35 step:27664 [D loss: 0.713816, acc.: 52.34%] [G loss: 0.755293]\n",
      "epoch:35 step:27665 [D loss: 0.681681, acc.: 59.38%] [G loss: 0.737006]\n",
      "epoch:35 step:27666 [D loss: 0.703838, acc.: 50.78%] [G loss: 0.731014]\n",
      "epoch:35 step:27667 [D loss: 0.681542, acc.: 51.56%] [G loss: 0.778685]\n",
      "epoch:35 step:27668 [D loss: 0.626166, acc.: 74.22%] [G loss: 0.800013]\n",
      "epoch:35 step:27669 [D loss: 0.636397, acc.: 68.75%] [G loss: 0.856499]\n",
      "epoch:35 step:27670 [D loss: 0.720602, acc.: 40.62%] [G loss: 0.775428]\n",
      "epoch:35 step:27671 [D loss: 0.711908, acc.: 47.66%] [G loss: 0.756855]\n",
      "epoch:35 step:27672 [D loss: 0.716076, acc.: 47.66%] [G loss: 0.721983]\n",
      "epoch:35 step:27673 [D loss: 0.710718, acc.: 45.31%] [G loss: 0.738031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27674 [D loss: 0.726072, acc.: 44.53%] [G loss: 0.755290]\n",
      "epoch:35 step:27675 [D loss: 0.719368, acc.: 48.44%] [G loss: 0.826623]\n",
      "epoch:35 step:27676 [D loss: 0.696860, acc.: 48.44%] [G loss: 0.798849]\n",
      "epoch:35 step:27677 [D loss: 0.706643, acc.: 52.34%] [G loss: 0.872590]\n",
      "epoch:35 step:27678 [D loss: 0.708575, acc.: 46.09%] [G loss: 0.752987]\n",
      "epoch:35 step:27679 [D loss: 0.732348, acc.: 42.19%] [G loss: 0.689729]\n",
      "epoch:35 step:27680 [D loss: 0.652464, acc.: 60.16%] [G loss: 0.781687]\n",
      "epoch:35 step:27681 [D loss: 0.681781, acc.: 55.47%] [G loss: 0.783253]\n",
      "epoch:35 step:27682 [D loss: 0.668395, acc.: 62.50%] [G loss: 0.761192]\n",
      "epoch:35 step:27683 [D loss: 0.684692, acc.: 53.12%] [G loss: 0.803184]\n",
      "epoch:35 step:27684 [D loss: 0.658099, acc.: 70.31%] [G loss: 0.792460]\n",
      "epoch:35 step:27685 [D loss: 0.698305, acc.: 53.12%] [G loss: 0.810681]\n",
      "epoch:35 step:27686 [D loss: 0.644300, acc.: 64.84%] [G loss: 0.833007]\n",
      "epoch:35 step:27687 [D loss: 0.675997, acc.: 55.47%] [G loss: 0.822163]\n",
      "epoch:35 step:27688 [D loss: 0.639247, acc.: 62.50%] [G loss: 0.809901]\n",
      "epoch:35 step:27689 [D loss: 0.672557, acc.: 61.72%] [G loss: 0.815906]\n",
      "epoch:35 step:27690 [D loss: 0.692907, acc.: 50.00%] [G loss: 0.810905]\n",
      "epoch:35 step:27691 [D loss: 0.684038, acc.: 57.03%] [G loss: 0.782163]\n",
      "epoch:35 step:27692 [D loss: 0.691234, acc.: 49.22%] [G loss: 0.778011]\n",
      "epoch:35 step:27693 [D loss: 0.697460, acc.: 51.56%] [G loss: 0.780250]\n",
      "epoch:35 step:27694 [D loss: 0.691531, acc.: 55.47%] [G loss: 0.795164]\n",
      "epoch:35 step:27695 [D loss: 0.728562, acc.: 50.00%] [G loss: 0.843002]\n",
      "epoch:35 step:27696 [D loss: 0.674236, acc.: 56.25%] [G loss: 0.891491]\n",
      "epoch:35 step:27697 [D loss: 0.651364, acc.: 63.28%] [G loss: 0.815438]\n",
      "epoch:35 step:27698 [D loss: 0.655669, acc.: 57.81%] [G loss: 0.765096]\n",
      "epoch:35 step:27699 [D loss: 0.671461, acc.: 57.81%] [G loss: 0.852920]\n",
      "epoch:35 step:27700 [D loss: 0.700669, acc.: 52.34%] [G loss: 0.844096]\n",
      "epoch:35 step:27701 [D loss: 0.666800, acc.: 60.94%] [G loss: 0.821555]\n",
      "epoch:35 step:27702 [D loss: 0.685408, acc.: 55.47%] [G loss: 0.797803]\n",
      "epoch:35 step:27703 [D loss: 0.615962, acc.: 73.44%] [G loss: 0.876005]\n",
      "epoch:35 step:27704 [D loss: 0.705146, acc.: 48.44%] [G loss: 0.795194]\n",
      "epoch:35 step:27705 [D loss: 0.646568, acc.: 67.97%] [G loss: 0.814259]\n",
      "epoch:35 step:27706 [D loss: 0.637711, acc.: 64.84%] [G loss: 0.883272]\n",
      "epoch:35 step:27707 [D loss: 0.688910, acc.: 53.91%] [G loss: 0.771354]\n",
      "epoch:35 step:27708 [D loss: 0.711427, acc.: 50.78%] [G loss: 0.774504]\n",
      "epoch:35 step:27709 [D loss: 0.673764, acc.: 56.25%] [G loss: 0.863271]\n",
      "epoch:35 step:27710 [D loss: 0.675059, acc.: 56.25%] [G loss: 0.927683]\n",
      "epoch:35 step:27711 [D loss: 0.660308, acc.: 57.81%] [G loss: 0.976444]\n",
      "epoch:35 step:27712 [D loss: 0.655783, acc.: 60.16%] [G loss: 0.928008]\n",
      "epoch:35 step:27713 [D loss: 0.647616, acc.: 60.16%] [G loss: 0.914320]\n",
      "epoch:35 step:27714 [D loss: 0.700717, acc.: 46.88%] [G loss: 0.819236]\n",
      "epoch:35 step:27715 [D loss: 0.713829, acc.: 53.12%] [G loss: 0.853741]\n",
      "epoch:35 step:27716 [D loss: 0.662402, acc.: 60.94%] [G loss: 0.819824]\n",
      "epoch:35 step:27717 [D loss: 0.702915, acc.: 51.56%] [G loss: 0.728613]\n",
      "epoch:35 step:27718 [D loss: 0.646933, acc.: 63.28%] [G loss: 0.824988]\n",
      "epoch:35 step:27719 [D loss: 0.674472, acc.: 58.59%] [G loss: 0.830885]\n",
      "epoch:35 step:27720 [D loss: 0.703269, acc.: 51.56%] [G loss: 0.809616]\n",
      "epoch:35 step:27721 [D loss: 0.678946, acc.: 53.12%] [G loss: 0.719873]\n",
      "epoch:35 step:27722 [D loss: 0.729666, acc.: 43.75%] [G loss: 0.798626]\n",
      "epoch:35 step:27723 [D loss: 0.697197, acc.: 50.00%] [G loss: 0.807595]\n",
      "epoch:35 step:27724 [D loss: 0.728214, acc.: 43.75%] [G loss: 0.805297]\n",
      "epoch:35 step:27725 [D loss: 0.695826, acc.: 53.91%] [G loss: 0.777517]\n",
      "epoch:35 step:27726 [D loss: 0.745192, acc.: 46.09%] [G loss: 0.844606]\n",
      "epoch:35 step:27727 [D loss: 0.720747, acc.: 46.09%] [G loss: 0.778175]\n",
      "epoch:35 step:27728 [D loss: 0.671317, acc.: 60.94%] [G loss: 0.760775]\n",
      "epoch:35 step:27729 [D loss: 0.675941, acc.: 57.81%] [G loss: 0.784239]\n",
      "epoch:35 step:27730 [D loss: 0.695618, acc.: 51.56%] [G loss: 0.778565]\n",
      "epoch:35 step:27731 [D loss: 0.673475, acc.: 58.59%] [G loss: 0.830162]\n",
      "epoch:35 step:27732 [D loss: 0.704451, acc.: 53.91%] [G loss: 0.816858]\n",
      "epoch:35 step:27733 [D loss: 0.694375, acc.: 50.78%] [G loss: 0.723581]\n",
      "epoch:35 step:27734 [D loss: 0.641833, acc.: 65.62%] [G loss: 0.830106]\n",
      "epoch:35 step:27735 [D loss: 0.693801, acc.: 51.56%] [G loss: 0.762323]\n",
      "epoch:35 step:27736 [D loss: 0.705691, acc.: 53.91%] [G loss: 0.832963]\n",
      "epoch:35 step:27737 [D loss: 0.612954, acc.: 71.88%] [G loss: 0.758323]\n",
      "epoch:35 step:27738 [D loss: 0.681407, acc.: 53.12%] [G loss: 0.852260]\n",
      "epoch:35 step:27739 [D loss: 0.610547, acc.: 69.53%] [G loss: 0.766384]\n",
      "epoch:35 step:27740 [D loss: 0.714255, acc.: 46.09%] [G loss: 0.750433]\n",
      "epoch:35 step:27741 [D loss: 0.662165, acc.: 61.72%] [G loss: 0.757836]\n",
      "epoch:35 step:27742 [D loss: 0.657848, acc.: 65.62%] [G loss: 0.736045]\n",
      "epoch:35 step:27743 [D loss: 0.731289, acc.: 45.31%] [G loss: 0.786777]\n",
      "epoch:35 step:27744 [D loss: 0.713124, acc.: 45.31%] [G loss: 0.708554]\n",
      "epoch:35 step:27745 [D loss: 0.693541, acc.: 59.38%] [G loss: 0.688477]\n",
      "epoch:35 step:27746 [D loss: 0.714749, acc.: 44.53%] [G loss: 0.693364]\n",
      "epoch:35 step:27747 [D loss: 0.666966, acc.: 58.59%] [G loss: 0.699008]\n",
      "epoch:35 step:27748 [D loss: 0.699007, acc.: 46.88%] [G loss: 0.716110]\n",
      "epoch:35 step:27749 [D loss: 0.703945, acc.: 50.00%] [G loss: 0.808076]\n",
      "epoch:35 step:27750 [D loss: 0.683123, acc.: 56.25%] [G loss: 0.844682]\n",
      "epoch:35 step:27751 [D loss: 0.644154, acc.: 62.50%] [G loss: 0.755041]\n",
      "epoch:35 step:27752 [D loss: 0.693300, acc.: 55.47%] [G loss: 0.838707]\n",
      "epoch:35 step:27753 [D loss: 0.663803, acc.: 56.25%] [G loss: 0.838384]\n",
      "epoch:35 step:27754 [D loss: 0.663401, acc.: 60.16%] [G loss: 0.742790]\n",
      "epoch:35 step:27755 [D loss: 0.707382, acc.: 53.12%] [G loss: 0.823634]\n",
      "epoch:35 step:27756 [D loss: 0.685258, acc.: 54.69%] [G loss: 0.730285]\n",
      "epoch:35 step:27757 [D loss: 0.697272, acc.: 53.12%] [G loss: 0.840856]\n",
      "epoch:35 step:27758 [D loss: 0.776676, acc.: 36.72%] [G loss: 0.790119]\n",
      "epoch:35 step:27759 [D loss: 0.727562, acc.: 44.53%] [G loss: 0.750914]\n",
      "epoch:35 step:27760 [D loss: 0.674559, acc.: 60.16%] [G loss: 0.782219]\n",
      "epoch:35 step:27761 [D loss: 0.673514, acc.: 57.81%] [G loss: 0.721884]\n",
      "epoch:35 step:27762 [D loss: 0.680852, acc.: 58.59%] [G loss: 0.739578]\n",
      "epoch:35 step:27763 [D loss: 0.681437, acc.: 57.03%] [G loss: 0.737662]\n",
      "epoch:35 step:27764 [D loss: 0.708811, acc.: 52.34%] [G loss: 0.656833]\n",
      "epoch:35 step:27765 [D loss: 0.694777, acc.: 55.47%] [G loss: 0.755696]\n",
      "epoch:35 step:27766 [D loss: 0.774560, acc.: 34.38%] [G loss: 0.822328]\n",
      "epoch:35 step:27767 [D loss: 0.686368, acc.: 60.16%] [G loss: 0.760561]\n",
      "epoch:35 step:27768 [D loss: 0.696028, acc.: 50.00%] [G loss: 0.736691]\n",
      "epoch:35 step:27769 [D loss: 0.643131, acc.: 64.06%] [G loss: 0.757857]\n",
      "epoch:35 step:27770 [D loss: 0.721414, acc.: 46.88%] [G loss: 0.753316]\n",
      "epoch:35 step:27771 [D loss: 0.689278, acc.: 50.78%] [G loss: 0.750471]\n",
      "epoch:35 step:27772 [D loss: 0.719566, acc.: 42.97%] [G loss: 0.783391]\n",
      "epoch:35 step:27773 [D loss: 0.632569, acc.: 63.28%] [G loss: 0.768782]\n",
      "epoch:35 step:27774 [D loss: 0.701941, acc.: 53.91%] [G loss: 0.772461]\n",
      "epoch:35 step:27775 [D loss: 0.705702, acc.: 48.44%] [G loss: 0.782765]\n",
      "epoch:35 step:27776 [D loss: 0.714054, acc.: 47.66%] [G loss: 0.809348]\n",
      "epoch:35 step:27777 [D loss: 0.695643, acc.: 52.34%] [G loss: 0.774028]\n",
      "epoch:35 step:27778 [D loss: 0.665429, acc.: 64.06%] [G loss: 0.827195]\n",
      "epoch:35 step:27779 [D loss: 0.651315, acc.: 68.75%] [G loss: 0.750065]\n",
      "epoch:35 step:27780 [D loss: 0.690091, acc.: 52.34%] [G loss: 0.750739]\n",
      "epoch:35 step:27781 [D loss: 0.677005, acc.: 57.03%] [G loss: 0.781194]\n",
      "epoch:35 step:27782 [D loss: 0.741201, acc.: 45.31%] [G loss: 0.749513]\n",
      "epoch:35 step:27783 [D loss: 0.738929, acc.: 39.84%] [G loss: 0.832316]\n",
      "epoch:35 step:27784 [D loss: 0.659652, acc.: 63.28%] [G loss: 0.755304]\n",
      "epoch:35 step:27785 [D loss: 0.718789, acc.: 46.88%] [G loss: 0.794205]\n",
      "epoch:35 step:27786 [D loss: 0.675731, acc.: 60.94%] [G loss: 0.802305]\n",
      "epoch:35 step:27787 [D loss: 0.668329, acc.: 57.81%] [G loss: 0.802455]\n",
      "epoch:35 step:27788 [D loss: 0.721213, acc.: 42.19%] [G loss: 0.816712]\n",
      "epoch:35 step:27789 [D loss: 0.705784, acc.: 49.22%] [G loss: 0.749593]\n",
      "epoch:35 step:27790 [D loss: 0.665653, acc.: 60.94%] [G loss: 0.760411]\n",
      "epoch:35 step:27791 [D loss: 0.704160, acc.: 53.12%] [G loss: 0.782919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27792 [D loss: 0.693317, acc.: 51.56%] [G loss: 0.783775]\n",
      "epoch:35 step:27793 [D loss: 0.713745, acc.: 47.66%] [G loss: 0.743054]\n",
      "epoch:35 step:27794 [D loss: 0.677872, acc.: 60.16%] [G loss: 0.814374]\n",
      "epoch:35 step:27795 [D loss: 0.661383, acc.: 63.28%] [G loss: 0.813892]\n",
      "epoch:35 step:27796 [D loss: 0.718134, acc.: 50.00%] [G loss: 0.803679]\n",
      "epoch:35 step:27797 [D loss: 0.685555, acc.: 53.91%] [G loss: 0.757003]\n",
      "epoch:35 step:27798 [D loss: 0.681813, acc.: 52.34%] [G loss: 0.786069]\n",
      "epoch:35 step:27799 [D loss: 0.676228, acc.: 57.03%] [G loss: 0.800655]\n",
      "epoch:35 step:27800 [D loss: 0.673769, acc.: 60.94%] [G loss: 0.783943]\n",
      "epoch:35 step:27801 [D loss: 0.601805, acc.: 73.44%] [G loss: 0.811380]\n",
      "epoch:35 step:27802 [D loss: 0.695177, acc.: 46.88%] [G loss: 0.869285]\n",
      "epoch:35 step:27803 [D loss: 0.660425, acc.: 60.94%] [G loss: 0.884188]\n",
      "epoch:35 step:27804 [D loss: 0.685514, acc.: 57.03%] [G loss: 0.820870]\n",
      "epoch:35 step:27805 [D loss: 0.682578, acc.: 54.69%] [G loss: 0.761819]\n",
      "epoch:35 step:27806 [D loss: 0.663967, acc.: 64.06%] [G loss: 0.881174]\n",
      "epoch:35 step:27807 [D loss: 0.671978, acc.: 57.81%] [G loss: 0.786122]\n",
      "epoch:35 step:27808 [D loss: 0.739699, acc.: 46.88%] [G loss: 0.712236]\n",
      "epoch:35 step:27809 [D loss: 0.724904, acc.: 41.41%] [G loss: 0.722711]\n",
      "epoch:35 step:27810 [D loss: 0.690444, acc.: 53.91%] [G loss: 0.753996]\n",
      "epoch:35 step:27811 [D loss: 0.642057, acc.: 66.41%] [G loss: 0.740750]\n",
      "epoch:35 step:27812 [D loss: 0.670054, acc.: 62.50%] [G loss: 0.789216]\n",
      "epoch:35 step:27813 [D loss: 0.669216, acc.: 57.81%] [G loss: 0.766084]\n",
      "epoch:35 step:27814 [D loss: 0.688556, acc.: 54.69%] [G loss: 0.820795]\n",
      "epoch:35 step:27815 [D loss: 0.691482, acc.: 51.56%] [G loss: 0.837669]\n",
      "epoch:35 step:27816 [D loss: 0.633014, acc.: 64.06%] [G loss: 0.818112]\n",
      "epoch:35 step:27817 [D loss: 0.693919, acc.: 51.56%] [G loss: 0.831491]\n",
      "epoch:35 step:27818 [D loss: 0.759206, acc.: 40.62%] [G loss: 0.763615]\n",
      "epoch:35 step:27819 [D loss: 0.689673, acc.: 53.91%] [G loss: 0.722133]\n",
      "epoch:35 step:27820 [D loss: 0.648700, acc.: 64.06%] [G loss: 0.806705]\n",
      "epoch:35 step:27821 [D loss: 0.692402, acc.: 53.91%] [G loss: 0.753933]\n",
      "epoch:35 step:27822 [D loss: 0.644455, acc.: 60.94%] [G loss: 0.823391]\n",
      "epoch:35 step:27823 [D loss: 0.711433, acc.: 52.34%] [G loss: 0.739627]\n",
      "epoch:35 step:27824 [D loss: 0.702535, acc.: 53.12%] [G loss: 0.709877]\n",
      "epoch:35 step:27825 [D loss: 0.680332, acc.: 57.03%] [G loss: 0.713798]\n",
      "epoch:35 step:27826 [D loss: 0.713312, acc.: 50.00%] [G loss: 0.823132]\n",
      "epoch:35 step:27827 [D loss: 0.711579, acc.: 46.88%] [G loss: 0.803128]\n",
      "epoch:35 step:27828 [D loss: 0.666752, acc.: 58.59%] [G loss: 0.783734]\n",
      "epoch:35 step:27829 [D loss: 0.622975, acc.: 69.53%] [G loss: 0.795450]\n",
      "epoch:35 step:27830 [D loss: 0.706908, acc.: 54.69%] [G loss: 0.804004]\n",
      "epoch:35 step:27831 [D loss: 0.718732, acc.: 47.66%] [G loss: 0.783265]\n",
      "epoch:35 step:27832 [D loss: 0.644388, acc.: 60.16%] [G loss: 0.787470]\n",
      "epoch:35 step:27833 [D loss: 0.666398, acc.: 61.72%] [G loss: 0.882329]\n",
      "epoch:35 step:27834 [D loss: 0.659173, acc.: 56.25%] [G loss: 0.777850]\n",
      "epoch:35 step:27835 [D loss: 0.704152, acc.: 50.78%] [G loss: 0.823571]\n",
      "epoch:35 step:27836 [D loss: 0.719862, acc.: 45.31%] [G loss: 0.840426]\n",
      "epoch:35 step:27837 [D loss: 0.690509, acc.: 45.31%] [G loss: 0.825000]\n",
      "epoch:35 step:27838 [D loss: 0.693717, acc.: 54.69%] [G loss: 0.741818]\n",
      "epoch:35 step:27839 [D loss: 0.645624, acc.: 63.28%] [G loss: 0.814063]\n",
      "epoch:35 step:27840 [D loss: 0.665913, acc.: 61.72%] [G loss: 0.797634]\n",
      "epoch:35 step:27841 [D loss: 0.672172, acc.: 57.03%] [G loss: 0.872913]\n",
      "epoch:35 step:27842 [D loss: 0.728101, acc.: 40.62%] [G loss: 0.825287]\n",
      "epoch:35 step:27843 [D loss: 0.696130, acc.: 53.91%] [G loss: 0.743254]\n",
      "epoch:35 step:27844 [D loss: 0.702717, acc.: 49.22%] [G loss: 0.776032]\n",
      "epoch:35 step:27845 [D loss: 0.673998, acc.: 57.03%] [G loss: 0.793211]\n",
      "epoch:35 step:27846 [D loss: 0.683250, acc.: 51.56%] [G loss: 0.757048]\n",
      "epoch:35 step:27847 [D loss: 0.723218, acc.: 45.31%] [G loss: 0.805624]\n",
      "epoch:35 step:27848 [D loss: 0.732544, acc.: 41.41%] [G loss: 0.723138]\n",
      "epoch:35 step:27849 [D loss: 0.750357, acc.: 46.88%] [G loss: 0.711114]\n",
      "epoch:35 step:27850 [D loss: 0.663751, acc.: 57.81%] [G loss: 0.813043]\n",
      "epoch:35 step:27851 [D loss: 0.637145, acc.: 66.41%] [G loss: 0.745407]\n",
      "epoch:35 step:27852 [D loss: 0.724856, acc.: 46.88%] [G loss: 0.733658]\n",
      "epoch:35 step:27853 [D loss: 0.659211, acc.: 57.03%] [G loss: 0.757005]\n",
      "epoch:35 step:27854 [D loss: 0.720781, acc.: 46.09%] [G loss: 0.774580]\n",
      "epoch:35 step:27855 [D loss: 0.674893, acc.: 54.69%] [G loss: 0.728762]\n",
      "epoch:35 step:27856 [D loss: 0.629471, acc.: 64.84%] [G loss: 0.759832]\n",
      "epoch:35 step:27857 [D loss: 0.694284, acc.: 55.47%] [G loss: 0.765034]\n",
      "epoch:35 step:27858 [D loss: 0.699302, acc.: 55.47%] [G loss: 0.776161]\n",
      "epoch:35 step:27859 [D loss: 0.706760, acc.: 52.34%] [G loss: 0.863839]\n",
      "epoch:35 step:27860 [D loss: 0.668872, acc.: 55.47%] [G loss: 0.838083]\n",
      "epoch:35 step:27861 [D loss: 0.776340, acc.: 37.50%] [G loss: 0.722092]\n",
      "epoch:35 step:27862 [D loss: 0.728787, acc.: 41.41%] [G loss: 0.745213]\n",
      "epoch:35 step:27863 [D loss: 0.658244, acc.: 61.72%] [G loss: 0.733234]\n",
      "epoch:35 step:27864 [D loss: 0.648698, acc.: 58.59%] [G loss: 0.767391]\n",
      "epoch:35 step:27865 [D loss: 0.655062, acc.: 59.38%] [G loss: 0.807963]\n",
      "epoch:35 step:27866 [D loss: 0.655997, acc.: 65.62%] [G loss: 0.791537]\n",
      "epoch:35 step:27867 [D loss: 0.679296, acc.: 55.47%] [G loss: 0.777173]\n",
      "epoch:35 step:27868 [D loss: 0.692836, acc.: 50.00%] [G loss: 0.807283]\n",
      "epoch:35 step:27869 [D loss: 0.642058, acc.: 69.53%] [G loss: 0.799220]\n",
      "epoch:35 step:27870 [D loss: 0.684233, acc.: 59.38%] [G loss: 0.769656]\n",
      "epoch:35 step:27871 [D loss: 0.757285, acc.: 35.16%] [G loss: 0.767520]\n",
      "epoch:35 step:27872 [D loss: 0.671648, acc.: 64.84%] [G loss: 0.801887]\n",
      "epoch:35 step:27873 [D loss: 0.677658, acc.: 54.69%] [G loss: 0.745298]\n",
      "epoch:35 step:27874 [D loss: 0.691407, acc.: 56.25%] [G loss: 0.733404]\n",
      "epoch:35 step:27875 [D loss: 0.673725, acc.: 53.91%] [G loss: 0.755404]\n",
      "epoch:35 step:27876 [D loss: 0.629318, acc.: 68.75%] [G loss: 0.688269]\n",
      "epoch:35 step:27877 [D loss: 0.671125, acc.: 57.03%] [G loss: 0.764033]\n",
      "epoch:35 step:27878 [D loss: 0.676792, acc.: 57.03%] [G loss: 0.752343]\n",
      "epoch:35 step:27879 [D loss: 0.691776, acc.: 50.00%] [G loss: 0.812584]\n",
      "epoch:35 step:27880 [D loss: 0.684063, acc.: 53.91%] [G loss: 0.840257]\n",
      "epoch:35 step:27881 [D loss: 0.731473, acc.: 49.22%] [G loss: 0.864610]\n",
      "epoch:35 step:27882 [D loss: 0.684911, acc.: 53.12%] [G loss: 0.836967]\n",
      "epoch:35 step:27883 [D loss: 0.717905, acc.: 40.62%] [G loss: 0.807949]\n",
      "epoch:35 step:27884 [D loss: 0.713092, acc.: 50.00%] [G loss: 0.779179]\n",
      "epoch:35 step:27885 [D loss: 0.701783, acc.: 54.69%] [G loss: 0.847684]\n",
      "epoch:35 step:27886 [D loss: 0.684270, acc.: 60.94%] [G loss: 0.845058]\n",
      "epoch:35 step:27887 [D loss: 0.722190, acc.: 46.88%] [G loss: 0.764208]\n",
      "epoch:35 step:27888 [D loss: 0.746141, acc.: 39.84%] [G loss: 0.776743]\n",
      "epoch:35 step:27889 [D loss: 0.681017, acc.: 54.69%] [G loss: 0.833132]\n",
      "epoch:35 step:27890 [D loss: 0.687890, acc.: 55.47%] [G loss: 0.792228]\n",
      "epoch:35 step:27891 [D loss: 0.716747, acc.: 49.22%] [G loss: 0.817754]\n",
      "epoch:35 step:27892 [D loss: 0.650694, acc.: 63.28%] [G loss: 0.783126]\n",
      "epoch:35 step:27893 [D loss: 0.682959, acc.: 54.69%] [G loss: 0.789504]\n",
      "epoch:35 step:27894 [D loss: 0.605991, acc.: 74.22%] [G loss: 0.828127]\n",
      "epoch:35 step:27895 [D loss: 0.725597, acc.: 44.53%] [G loss: 0.792308]\n",
      "epoch:35 step:27896 [D loss: 0.658610, acc.: 66.41%] [G loss: 0.760008]\n",
      "epoch:35 step:27897 [D loss: 0.617144, acc.: 72.66%] [G loss: 0.774645]\n",
      "epoch:35 step:27898 [D loss: 0.609536, acc.: 74.22%] [G loss: 0.782156]\n",
      "epoch:35 step:27899 [D loss: 0.688575, acc.: 51.56%] [G loss: 0.775447]\n",
      "epoch:35 step:27900 [D loss: 0.684382, acc.: 60.94%] [G loss: 0.802380]\n",
      "epoch:35 step:27901 [D loss: 0.700999, acc.: 52.34%] [G loss: 0.764657]\n",
      "epoch:35 step:27902 [D loss: 0.670571, acc.: 66.41%] [G loss: 0.807121]\n",
      "epoch:35 step:27903 [D loss: 0.667039, acc.: 56.25%] [G loss: 0.770096]\n",
      "epoch:35 step:27904 [D loss: 0.668169, acc.: 63.28%] [G loss: 0.748233]\n",
      "epoch:35 step:27905 [D loss: 0.658762, acc.: 65.62%] [G loss: 0.805540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27906 [D loss: 0.727748, acc.: 44.53%] [G loss: 0.752139]\n",
      "epoch:35 step:27907 [D loss: 0.682284, acc.: 56.25%] [G loss: 0.747143]\n",
      "epoch:35 step:27908 [D loss: 0.714742, acc.: 55.47%] [G loss: 0.806013]\n",
      "epoch:35 step:27909 [D loss: 0.685008, acc.: 58.59%] [G loss: 0.795608]\n",
      "epoch:35 step:27910 [D loss: 0.740514, acc.: 39.84%] [G loss: 0.763673]\n",
      "epoch:35 step:27911 [D loss: 0.682369, acc.: 56.25%] [G loss: 0.821239]\n",
      "epoch:35 step:27912 [D loss: 0.696652, acc.: 59.38%] [G loss: 0.804898]\n",
      "epoch:35 step:27913 [D loss: 0.649029, acc.: 67.97%] [G loss: 0.737273]\n",
      "epoch:35 step:27914 [D loss: 0.731281, acc.: 44.53%] [G loss: 0.830150]\n",
      "epoch:35 step:27915 [D loss: 0.700715, acc.: 50.00%] [G loss: 0.869928]\n",
      "epoch:35 step:27916 [D loss: 0.667698, acc.: 57.81%] [G loss: 0.769427]\n",
      "epoch:35 step:27917 [D loss: 0.646293, acc.: 67.97%] [G loss: 0.832757]\n",
      "epoch:35 step:27918 [D loss: 0.665330, acc.: 60.94%] [G loss: 0.844633]\n",
      "epoch:35 step:27919 [D loss: 0.686259, acc.: 50.78%] [G loss: 0.745784]\n",
      "epoch:35 step:27920 [D loss: 0.658056, acc.: 60.94%] [G loss: 0.790638]\n",
      "epoch:35 step:27921 [D loss: 0.632683, acc.: 68.75%] [G loss: 0.774269]\n",
      "epoch:35 step:27922 [D loss: 0.667939, acc.: 57.81%] [G loss: 0.793330]\n",
      "epoch:35 step:27923 [D loss: 0.628511, acc.: 67.97%] [G loss: 0.794894]\n",
      "epoch:35 step:27924 [D loss: 0.689982, acc.: 56.25%] [G loss: 0.701365]\n",
      "epoch:35 step:27925 [D loss: 0.692723, acc.: 53.12%] [G loss: 0.718421]\n",
      "epoch:35 step:27926 [D loss: 0.753853, acc.: 41.41%] [G loss: 0.741349]\n",
      "epoch:35 step:27927 [D loss: 0.695302, acc.: 53.91%] [G loss: 0.759301]\n",
      "epoch:35 step:27928 [D loss: 0.708151, acc.: 50.00%] [G loss: 0.776523]\n",
      "epoch:35 step:27929 [D loss: 0.686855, acc.: 53.91%] [G loss: 0.766851]\n",
      "epoch:35 step:27930 [D loss: 0.637534, acc.: 72.66%] [G loss: 0.845671]\n",
      "epoch:35 step:27931 [D loss: 0.713254, acc.: 52.34%] [G loss: 0.849902]\n",
      "epoch:35 step:27932 [D loss: 0.679530, acc.: 53.91%] [G loss: 0.810831]\n",
      "epoch:35 step:27933 [D loss: 0.656494, acc.: 64.84%] [G loss: 0.774602]\n",
      "epoch:35 step:27934 [D loss: 0.720408, acc.: 49.22%] [G loss: 0.704133]\n",
      "epoch:35 step:27935 [D loss: 0.667105, acc.: 59.38%] [G loss: 0.709336]\n",
      "epoch:35 step:27936 [D loss: 0.712322, acc.: 51.56%] [G loss: 0.768517]\n",
      "epoch:35 step:27937 [D loss: 0.644693, acc.: 63.28%] [G loss: 0.776299]\n",
      "epoch:35 step:27938 [D loss: 0.707339, acc.: 46.88%] [G loss: 0.708750]\n",
      "epoch:35 step:27939 [D loss: 0.740598, acc.: 42.19%] [G loss: 0.721821]\n",
      "epoch:35 step:27940 [D loss: 0.657009, acc.: 63.28%] [G loss: 0.774554]\n",
      "epoch:35 step:27941 [D loss: 0.668588, acc.: 56.25%] [G loss: 0.746929]\n",
      "epoch:35 step:27942 [D loss: 0.648686, acc.: 62.50%] [G loss: 0.785498]\n",
      "epoch:35 step:27943 [D loss: 0.639910, acc.: 68.75%] [G loss: 0.801363]\n",
      "epoch:35 step:27944 [D loss: 0.742082, acc.: 44.53%] [G loss: 0.748475]\n",
      "epoch:35 step:27945 [D loss: 0.673693, acc.: 53.91%] [G loss: 0.794525]\n",
      "epoch:35 step:27946 [D loss: 0.672918, acc.: 57.03%] [G loss: 0.839622]\n",
      "epoch:35 step:27947 [D loss: 0.677469, acc.: 56.25%] [G loss: 0.785885]\n",
      "epoch:35 step:27948 [D loss: 0.750566, acc.: 40.62%] [G loss: 0.724186]\n",
      "epoch:35 step:27949 [D loss: 0.671537, acc.: 57.81%] [G loss: 0.742364]\n",
      "epoch:35 step:27950 [D loss: 0.667071, acc.: 60.16%] [G loss: 0.721160]\n",
      "epoch:35 step:27951 [D loss: 0.654214, acc.: 60.94%] [G loss: 0.757463]\n",
      "epoch:35 step:27952 [D loss: 0.670669, acc.: 58.59%] [G loss: 0.744107]\n",
      "epoch:35 step:27953 [D loss: 0.677458, acc.: 58.59%] [G loss: 0.780464]\n",
      "epoch:35 step:27954 [D loss: 0.639296, acc.: 68.75%] [G loss: 0.761336]\n",
      "epoch:35 step:27955 [D loss: 0.669609, acc.: 56.25%] [G loss: 0.819883]\n",
      "epoch:35 step:27956 [D loss: 0.658129, acc.: 59.38%] [G loss: 0.793199]\n",
      "epoch:35 step:27957 [D loss: 0.699972, acc.: 46.09%] [G loss: 0.795523]\n",
      "epoch:35 step:27958 [D loss: 0.657580, acc.: 67.19%] [G loss: 0.737519]\n",
      "epoch:35 step:27959 [D loss: 0.662511, acc.: 61.72%] [G loss: 0.841873]\n",
      "epoch:35 step:27960 [D loss: 0.698623, acc.: 50.00%] [G loss: 0.737848]\n",
      "epoch:35 step:27961 [D loss: 0.701356, acc.: 53.12%] [G loss: 0.690020]\n",
      "epoch:35 step:27962 [D loss: 0.737953, acc.: 41.41%] [G loss: 0.816746]\n",
      "epoch:35 step:27963 [D loss: 0.702159, acc.: 51.56%] [G loss: 0.733482]\n",
      "epoch:35 step:27964 [D loss: 0.692489, acc.: 53.91%] [G loss: 0.777610]\n",
      "epoch:35 step:27965 [D loss: 0.684649, acc.: 62.50%] [G loss: 0.742039]\n",
      "epoch:35 step:27966 [D loss: 0.719307, acc.: 52.34%] [G loss: 0.746543]\n",
      "epoch:35 step:27967 [D loss: 0.644987, acc.: 64.84%] [G loss: 0.764707]\n",
      "epoch:35 step:27968 [D loss: 0.694836, acc.: 53.12%] [G loss: 0.829503]\n",
      "epoch:35 step:27969 [D loss: 0.723068, acc.: 47.66%] [G loss: 0.820740]\n",
      "epoch:35 step:27970 [D loss: 0.678829, acc.: 54.69%] [G loss: 0.721738]\n",
      "epoch:35 step:27971 [D loss: 0.682831, acc.: 57.03%] [G loss: 0.770240]\n",
      "epoch:35 step:27972 [D loss: 0.681487, acc.: 59.38%] [G loss: 0.766767]\n",
      "epoch:35 step:27973 [D loss: 0.716244, acc.: 47.66%] [G loss: 0.711266]\n",
      "epoch:35 step:27974 [D loss: 0.705272, acc.: 51.56%] [G loss: 0.782515]\n",
      "epoch:35 step:27975 [D loss: 0.687165, acc.: 52.34%] [G loss: 0.756524]\n",
      "epoch:35 step:27976 [D loss: 0.698395, acc.: 50.00%] [G loss: 0.776840]\n",
      "epoch:35 step:27977 [D loss: 0.694846, acc.: 43.75%] [G loss: 0.821077]\n",
      "epoch:35 step:27978 [D loss: 0.671929, acc.: 61.72%] [G loss: 0.748438]\n",
      "epoch:35 step:27979 [D loss: 0.693372, acc.: 56.25%] [G loss: 0.727499]\n",
      "epoch:35 step:27980 [D loss: 0.706629, acc.: 51.56%] [G loss: 0.783241]\n",
      "epoch:35 step:27981 [D loss: 0.713558, acc.: 46.88%] [G loss: 0.837074]\n",
      "epoch:35 step:27982 [D loss: 0.699030, acc.: 53.12%] [G loss: 0.830651]\n",
      "epoch:35 step:27983 [D loss: 0.665686, acc.: 59.38%] [G loss: 0.782216]\n",
      "epoch:35 step:27984 [D loss: 0.681004, acc.: 59.38%] [G loss: 0.839315]\n",
      "epoch:35 step:27985 [D loss: 0.702253, acc.: 52.34%] [G loss: 0.796251]\n",
      "epoch:35 step:27986 [D loss: 0.658515, acc.: 66.41%] [G loss: 0.800704]\n",
      "epoch:35 step:27987 [D loss: 0.633556, acc.: 64.06%] [G loss: 0.739377]\n",
      "epoch:35 step:27988 [D loss: 0.665582, acc.: 61.72%] [G loss: 0.727328]\n",
      "epoch:35 step:27989 [D loss: 0.657100, acc.: 56.25%] [G loss: 0.765087]\n",
      "epoch:35 step:27990 [D loss: 0.711278, acc.: 52.34%] [G loss: 0.686251]\n",
      "epoch:35 step:27991 [D loss: 0.699116, acc.: 54.69%] [G loss: 0.749728]\n",
      "epoch:35 step:27992 [D loss: 0.675537, acc.: 58.59%] [G loss: 0.771451]\n",
      "epoch:35 step:27993 [D loss: 0.625605, acc.: 72.66%] [G loss: 0.767716]\n",
      "epoch:35 step:27994 [D loss: 0.661540, acc.: 57.03%] [G loss: 0.779161]\n",
      "epoch:35 step:27995 [D loss: 0.684006, acc.: 54.69%] [G loss: 0.830949]\n",
      "epoch:35 step:27996 [D loss: 0.679560, acc.: 57.03%] [G loss: 0.721962]\n",
      "epoch:35 step:27997 [D loss: 0.690941, acc.: 52.34%] [G loss: 0.833406]\n",
      "epoch:35 step:27998 [D loss: 0.681345, acc.: 57.03%] [G loss: 0.814931]\n",
      "epoch:35 step:27999 [D loss: 0.674893, acc.: 56.25%] [G loss: 0.828197]\n",
      "epoch:35 step:28000 [D loss: 0.731829, acc.: 39.06%] [G loss: 0.819416]\n",
      "epoch:35 step:28001 [D loss: 0.718978, acc.: 59.38%] [G loss: 0.824188]\n",
      "epoch:35 step:28002 [D loss: 0.697187, acc.: 50.78%] [G loss: 0.772137]\n",
      "epoch:35 step:28003 [D loss: 0.721465, acc.: 46.09%] [G loss: 0.811340]\n",
      "epoch:35 step:28004 [D loss: 0.689783, acc.: 50.78%] [G loss: 0.826572]\n",
      "epoch:35 step:28005 [D loss: 0.692403, acc.: 63.28%] [G loss: 0.904642]\n",
      "epoch:35 step:28006 [D loss: 0.706277, acc.: 53.91%] [G loss: 0.894015]\n",
      "epoch:35 step:28007 [D loss: 0.732715, acc.: 42.97%] [G loss: 0.755622]\n",
      "epoch:35 step:28008 [D loss: 0.666373, acc.: 64.06%] [G loss: 0.750590]\n",
      "epoch:35 step:28009 [D loss: 0.735543, acc.: 40.62%] [G loss: 0.832420]\n",
      "epoch:35 step:28010 [D loss: 0.685847, acc.: 54.69%] [G loss: 0.774497]\n",
      "epoch:35 step:28011 [D loss: 0.688389, acc.: 55.47%] [G loss: 0.741969]\n",
      "epoch:35 step:28012 [D loss: 0.677482, acc.: 57.03%] [G loss: 0.801050]\n",
      "epoch:35 step:28013 [D loss: 0.722824, acc.: 42.19%] [G loss: 0.757463]\n",
      "epoch:35 step:28014 [D loss: 0.678073, acc.: 57.81%] [G loss: 0.791834]\n",
      "epoch:35 step:28015 [D loss: 0.677766, acc.: 62.50%] [G loss: 0.712249]\n",
      "epoch:35 step:28016 [D loss: 0.686187, acc.: 54.69%] [G loss: 0.754799]\n",
      "epoch:35 step:28017 [D loss: 0.711775, acc.: 46.88%] [G loss: 0.806711]\n",
      "epoch:35 step:28018 [D loss: 0.711576, acc.: 49.22%] [G loss: 0.692541]\n",
      "epoch:35 step:28019 [D loss: 0.660695, acc.: 64.06%] [G loss: 0.757703]\n",
      "epoch:35 step:28020 [D loss: 0.679838, acc.: 55.47%] [G loss: 0.791301]\n",
      "epoch:35 step:28021 [D loss: 0.706753, acc.: 46.88%] [G loss: 0.816943]\n",
      "epoch:35 step:28022 [D loss: 0.660710, acc.: 59.38%] [G loss: 0.774842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28023 [D loss: 0.689719, acc.: 60.16%] [G loss: 0.831653]\n",
      "epoch:35 step:28024 [D loss: 0.661829, acc.: 57.81%] [G loss: 0.831124]\n",
      "epoch:35 step:28025 [D loss: 0.645611, acc.: 67.19%] [G loss: 0.825227]\n",
      "epoch:35 step:28026 [D loss: 0.704218, acc.: 53.91%] [G loss: 0.754294]\n",
      "epoch:35 step:28027 [D loss: 0.741432, acc.: 44.53%] [G loss: 0.760621]\n",
      "epoch:35 step:28028 [D loss: 0.683160, acc.: 52.34%] [G loss: 0.830989]\n",
      "epoch:35 step:28029 [D loss: 0.673004, acc.: 57.81%] [G loss: 0.769110]\n",
      "epoch:35 step:28030 [D loss: 0.674866, acc.: 58.59%] [G loss: 0.719030]\n",
      "epoch:35 step:28031 [D loss: 0.701583, acc.: 50.78%] [G loss: 0.814608]\n",
      "epoch:35 step:28032 [D loss: 0.778449, acc.: 36.72%] [G loss: 0.735271]\n",
      "epoch:35 step:28033 [D loss: 0.695721, acc.: 48.44%] [G loss: 0.744602]\n",
      "epoch:35 step:28034 [D loss: 0.697165, acc.: 52.34%] [G loss: 0.732195]\n",
      "epoch:35 step:28035 [D loss: 0.625344, acc.: 68.75%] [G loss: 0.735190]\n",
      "epoch:35 step:28036 [D loss: 0.742819, acc.: 39.06%] [G loss: 0.719754]\n",
      "epoch:35 step:28037 [D loss: 0.655658, acc.: 57.03%] [G loss: 0.785237]\n",
      "epoch:35 step:28038 [D loss: 0.709319, acc.: 47.66%] [G loss: 0.833341]\n",
      "epoch:35 step:28039 [D loss: 0.703305, acc.: 52.34%] [G loss: 0.657878]\n",
      "epoch:35 step:28040 [D loss: 0.660646, acc.: 55.47%] [G loss: 0.804343]\n",
      "epoch:35 step:28041 [D loss: 0.688945, acc.: 56.25%] [G loss: 0.702700]\n",
      "epoch:35 step:28042 [D loss: 0.766475, acc.: 32.81%] [G loss: 0.767044]\n",
      "epoch:35 step:28043 [D loss: 0.727763, acc.: 44.53%] [G loss: 0.773592]\n",
      "epoch:35 step:28044 [D loss: 0.689722, acc.: 53.91%] [G loss: 0.772572]\n",
      "epoch:35 step:28045 [D loss: 0.687417, acc.: 55.47%] [G loss: 0.820765]\n",
      "epoch:35 step:28046 [D loss: 0.681648, acc.: 51.56%] [G loss: 0.811442]\n",
      "epoch:35 step:28047 [D loss: 0.693015, acc.: 57.03%] [G loss: 0.798723]\n",
      "epoch:35 step:28048 [D loss: 0.650717, acc.: 63.28%] [G loss: 0.914576]\n",
      "epoch:35 step:28049 [D loss: 0.705339, acc.: 52.34%] [G loss: 0.787163]\n",
      "epoch:35 step:28050 [D loss: 0.660347, acc.: 63.28%] [G loss: 0.719699]\n",
      "epoch:35 step:28051 [D loss: 0.709287, acc.: 46.09%] [G loss: 0.855912]\n",
      "epoch:35 step:28052 [D loss: 0.647630, acc.: 64.06%] [G loss: 0.840397]\n",
      "epoch:35 step:28053 [D loss: 0.666664, acc.: 60.16%] [G loss: 0.794576]\n",
      "epoch:35 step:28054 [D loss: 0.655418, acc.: 67.97%] [G loss: 0.741275]\n",
      "epoch:35 step:28055 [D loss: 0.687309, acc.: 53.12%] [G loss: 0.823830]\n",
      "epoch:35 step:28056 [D loss: 0.680296, acc.: 59.38%] [G loss: 0.794888]\n",
      "epoch:35 step:28057 [D loss: 0.695984, acc.: 55.47%] [G loss: 0.841550]\n",
      "epoch:35 step:28058 [D loss: 0.746654, acc.: 43.75%] [G loss: 0.755263]\n",
      "epoch:35 step:28059 [D loss: 0.721456, acc.: 44.53%] [G loss: 0.746153]\n",
      "epoch:35 step:28060 [D loss: 0.692509, acc.: 48.44%] [G loss: 0.797803]\n",
      "epoch:35 step:28061 [D loss: 0.655147, acc.: 63.28%] [G loss: 0.699532]\n",
      "epoch:35 step:28062 [D loss: 0.713278, acc.: 50.00%] [G loss: 0.718636]\n",
      "epoch:35 step:28063 [D loss: 0.670726, acc.: 57.81%] [G loss: 0.790722]\n",
      "epoch:35 step:28064 [D loss: 0.701291, acc.: 52.34%] [G loss: 0.762681]\n",
      "epoch:35 step:28065 [D loss: 0.705759, acc.: 48.44%] [G loss: 0.774079]\n",
      "epoch:35 step:28066 [D loss: 0.678479, acc.: 60.16%] [G loss: 0.776256]\n",
      "epoch:35 step:28067 [D loss: 0.712225, acc.: 47.66%] [G loss: 0.779817]\n",
      "epoch:35 step:28068 [D loss: 0.682255, acc.: 60.16%] [G loss: 0.787062]\n",
      "epoch:35 step:28069 [D loss: 0.730189, acc.: 43.75%] [G loss: 0.762882]\n",
      "epoch:35 step:28070 [D loss: 0.704827, acc.: 49.22%] [G loss: 0.740207]\n",
      "epoch:35 step:28071 [D loss: 0.707105, acc.: 53.91%] [G loss: 0.725020]\n",
      "epoch:35 step:28072 [D loss: 0.707213, acc.: 50.78%] [G loss: 0.892905]\n",
      "epoch:35 step:28073 [D loss: 0.697069, acc.: 49.22%] [G loss: 0.750986]\n",
      "epoch:35 step:28074 [D loss: 0.681598, acc.: 57.81%] [G loss: 0.670039]\n",
      "epoch:35 step:28075 [D loss: 0.654971, acc.: 61.72%] [G loss: 0.749024]\n",
      "epoch:35 step:28076 [D loss: 0.619989, acc.: 66.41%] [G loss: 0.801528]\n",
      "epoch:35 step:28077 [D loss: 0.675087, acc.: 57.03%] [G loss: 0.880709]\n",
      "epoch:35 step:28078 [D loss: 0.717899, acc.: 46.88%] [G loss: 0.686387]\n",
      "epoch:35 step:28079 [D loss: 0.691579, acc.: 52.34%] [G loss: 0.716483]\n",
      "epoch:35 step:28080 [D loss: 0.681834, acc.: 53.91%] [G loss: 0.699653]\n",
      "epoch:35 step:28081 [D loss: 0.691535, acc.: 53.91%] [G loss: 0.771870]\n",
      "epoch:35 step:28082 [D loss: 0.704512, acc.: 56.25%] [G loss: 0.722088]\n",
      "epoch:35 step:28083 [D loss: 0.662303, acc.: 63.28%] [G loss: 0.748124]\n",
      "epoch:35 step:28084 [D loss: 0.622956, acc.: 73.44%] [G loss: 0.666096]\n",
      "epoch:35 step:28085 [D loss: 0.691477, acc.: 55.47%] [G loss: 0.713082]\n",
      "epoch:35 step:28086 [D loss: 0.668328, acc.: 62.50%] [G loss: 0.775753]\n",
      "epoch:35 step:28087 [D loss: 0.693630, acc.: 51.56%] [G loss: 0.705587]\n",
      "epoch:35 step:28088 [D loss: 0.635218, acc.: 66.41%] [G loss: 0.839269]\n",
      "epoch:35 step:28089 [D loss: 0.672489, acc.: 55.47%] [G loss: 0.678614]\n",
      "epoch:35 step:28090 [D loss: 0.645306, acc.: 69.53%] [G loss: 0.778156]\n",
      "epoch:35 step:28091 [D loss: 0.701627, acc.: 48.44%] [G loss: 0.775195]\n",
      "epoch:35 step:28092 [D loss: 0.671838, acc.: 57.81%] [G loss: 0.806640]\n",
      "epoch:35 step:28093 [D loss: 0.666088, acc.: 64.84%] [G loss: 0.787015]\n",
      "epoch:35 step:28094 [D loss: 0.705003, acc.: 51.56%] [G loss: 0.833909]\n",
      "epoch:35 step:28095 [D loss: 0.669656, acc.: 57.03%] [G loss: 0.844172]\n",
      "epoch:35 step:28096 [D loss: 0.649221, acc.: 62.50%] [G loss: 0.745133]\n",
      "epoch:35 step:28097 [D loss: 0.709217, acc.: 48.44%] [G loss: 0.867364]\n",
      "epoch:35 step:28098 [D loss: 0.644282, acc.: 63.28%] [G loss: 0.747495]\n",
      "epoch:35 step:28099 [D loss: 0.710715, acc.: 49.22%] [G loss: 0.724345]\n",
      "epoch:35 step:28100 [D loss: 0.677416, acc.: 63.28%] [G loss: 0.716848]\n",
      "epoch:35 step:28101 [D loss: 0.667494, acc.: 58.59%] [G loss: 0.700614]\n",
      "epoch:35 step:28102 [D loss: 0.677778, acc.: 57.81%] [G loss: 0.822979]\n",
      "epoch:35 step:28103 [D loss: 0.664310, acc.: 62.50%] [G loss: 0.794303]\n",
      "epoch:35 step:28104 [D loss: 0.695694, acc.: 53.12%] [G loss: 0.759126]\n",
      "epoch:35 step:28105 [D loss: 0.690082, acc.: 50.78%] [G loss: 0.769603]\n",
      "epoch:35 step:28106 [D loss: 0.707692, acc.: 50.78%] [G loss: 0.760463]\n",
      "epoch:35 step:28107 [D loss: 0.696151, acc.: 54.69%] [G loss: 0.804053]\n",
      "epoch:35 step:28108 [D loss: 0.710906, acc.: 48.44%] [G loss: 0.711066]\n",
      "epoch:35 step:28109 [D loss: 0.749022, acc.: 40.62%] [G loss: 0.767480]\n",
      "epoch:35 step:28110 [D loss: 0.705019, acc.: 50.00%] [G loss: 0.766685]\n",
      "epoch:35 step:28111 [D loss: 0.689161, acc.: 52.34%] [G loss: 0.729031]\n",
      "epoch:35 step:28112 [D loss: 0.700068, acc.: 54.69%] [G loss: 0.818878]\n",
      "epoch:35 step:28113 [D loss: 0.690847, acc.: 52.34%] [G loss: 0.796178]\n",
      "epoch:35 step:28114 [D loss: 0.728047, acc.: 49.22%] [G loss: 0.778057]\n",
      "epoch:35 step:28115 [D loss: 0.705323, acc.: 53.12%] [G loss: 0.717381]\n",
      "epoch:35 step:28116 [D loss: 0.713657, acc.: 48.44%] [G loss: 0.706262]\n",
      "epoch:36 step:28117 [D loss: 0.611100, acc.: 74.22%] [G loss: 0.763959]\n",
      "epoch:36 step:28118 [D loss: 0.679308, acc.: 58.59%] [G loss: 0.844602]\n",
      "epoch:36 step:28119 [D loss: 0.683334, acc.: 55.47%] [G loss: 0.814656]\n",
      "epoch:36 step:28120 [D loss: 0.681041, acc.: 57.03%] [G loss: 0.867372]\n",
      "epoch:36 step:28121 [D loss: 0.666118, acc.: 60.94%] [G loss: 0.836742]\n",
      "epoch:36 step:28122 [D loss: 0.618863, acc.: 68.75%] [G loss: 0.858761]\n",
      "epoch:36 step:28123 [D loss: 0.644436, acc.: 70.31%] [G loss: 0.849511]\n",
      "epoch:36 step:28124 [D loss: 0.698637, acc.: 50.00%] [G loss: 0.799302]\n",
      "epoch:36 step:28125 [D loss: 0.739440, acc.: 45.31%] [G loss: 0.733840]\n",
      "epoch:36 step:28126 [D loss: 0.740084, acc.: 44.53%] [G loss: 0.767203]\n",
      "epoch:36 step:28127 [D loss: 0.714303, acc.: 46.09%] [G loss: 0.763392]\n",
      "epoch:36 step:28128 [D loss: 0.686878, acc.: 53.91%] [G loss: 0.802509]\n",
      "epoch:36 step:28129 [D loss: 0.655830, acc.: 65.62%] [G loss: 0.789282]\n",
      "epoch:36 step:28130 [D loss: 0.648034, acc.: 65.62%] [G loss: 0.877402]\n",
      "epoch:36 step:28131 [D loss: 0.753188, acc.: 35.94%] [G loss: 0.728756]\n",
      "epoch:36 step:28132 [D loss: 0.677525, acc.: 60.94%] [G loss: 0.768571]\n",
      "epoch:36 step:28133 [D loss: 0.681456, acc.: 53.12%] [G loss: 0.778510]\n",
      "epoch:36 step:28134 [D loss: 0.742086, acc.: 42.19%] [G loss: 0.769787]\n",
      "epoch:36 step:28135 [D loss: 0.717064, acc.: 47.66%] [G loss: 0.733112]\n",
      "epoch:36 step:28136 [D loss: 0.708107, acc.: 51.56%] [G loss: 0.825936]\n",
      "epoch:36 step:28137 [D loss: 0.705765, acc.: 50.78%] [G loss: 0.829747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28138 [D loss: 0.664713, acc.: 56.25%] [G loss: 0.848082]\n",
      "epoch:36 step:28139 [D loss: 0.672503, acc.: 61.72%] [G loss: 0.825674]\n",
      "epoch:36 step:28140 [D loss: 0.713522, acc.: 56.25%] [G loss: 0.766945]\n",
      "epoch:36 step:28141 [D loss: 0.739448, acc.: 41.41%] [G loss: 0.807394]\n",
      "epoch:36 step:28142 [D loss: 0.705031, acc.: 56.25%] [G loss: 0.749715]\n",
      "epoch:36 step:28143 [D loss: 0.699757, acc.: 50.78%] [G loss: 0.816985]\n",
      "epoch:36 step:28144 [D loss: 0.798125, acc.: 36.72%] [G loss: 0.753592]\n",
      "epoch:36 step:28145 [D loss: 0.647936, acc.: 64.84%] [G loss: 0.777231]\n",
      "epoch:36 step:28146 [D loss: 0.700516, acc.: 53.91%] [G loss: 0.729277]\n",
      "epoch:36 step:28147 [D loss: 0.697859, acc.: 49.22%] [G loss: 0.799332]\n",
      "epoch:36 step:28148 [D loss: 0.668815, acc.: 60.16%] [G loss: 0.778906]\n",
      "epoch:36 step:28149 [D loss: 0.724334, acc.: 43.75%] [G loss: 0.760120]\n",
      "epoch:36 step:28150 [D loss: 0.630134, acc.: 72.66%] [G loss: 0.819503]\n",
      "epoch:36 step:28151 [D loss: 0.680925, acc.: 54.69%] [G loss: 0.779746]\n",
      "epoch:36 step:28152 [D loss: 0.684353, acc.: 56.25%] [G loss: 0.733191]\n",
      "epoch:36 step:28153 [D loss: 0.758663, acc.: 43.75%] [G loss: 0.718645]\n",
      "epoch:36 step:28154 [D loss: 0.670789, acc.: 57.81%] [G loss: 0.728197]\n",
      "epoch:36 step:28155 [D loss: 0.711617, acc.: 49.22%] [G loss: 0.796746]\n",
      "epoch:36 step:28156 [D loss: 0.639642, acc.: 71.09%] [G loss: 0.875921]\n",
      "epoch:36 step:28157 [D loss: 0.683873, acc.: 58.59%] [G loss: 0.778728]\n",
      "epoch:36 step:28158 [D loss: 0.637041, acc.: 70.31%] [G loss: 0.825352]\n",
      "epoch:36 step:28159 [D loss: 0.711800, acc.: 50.00%] [G loss: 0.760072]\n",
      "epoch:36 step:28160 [D loss: 0.673684, acc.: 54.69%] [G loss: 0.767043]\n",
      "epoch:36 step:28161 [D loss: 0.624226, acc.: 71.88%] [G loss: 0.776251]\n",
      "epoch:36 step:28162 [D loss: 0.676316, acc.: 63.28%] [G loss: 0.792328]\n",
      "epoch:36 step:28163 [D loss: 0.630637, acc.: 70.31%] [G loss: 0.786229]\n",
      "epoch:36 step:28164 [D loss: 0.707597, acc.: 50.00%] [G loss: 0.799587]\n",
      "epoch:36 step:28165 [D loss: 0.672494, acc.: 54.69%] [G loss: 0.811165]\n",
      "epoch:36 step:28166 [D loss: 0.658530, acc.: 60.94%] [G loss: 0.858086]\n",
      "epoch:36 step:28167 [D loss: 0.625845, acc.: 71.09%] [G loss: 0.779910]\n",
      "epoch:36 step:28168 [D loss: 0.677918, acc.: 59.38%] [G loss: 0.814869]\n",
      "epoch:36 step:28169 [D loss: 0.668630, acc.: 56.25%] [G loss: 0.822853]\n",
      "epoch:36 step:28170 [D loss: 0.693560, acc.: 52.34%] [G loss: 0.748634]\n",
      "epoch:36 step:28171 [D loss: 0.684140, acc.: 54.69%] [G loss: 0.819613]\n",
      "epoch:36 step:28172 [D loss: 0.692707, acc.: 61.72%] [G loss: 0.769343]\n",
      "epoch:36 step:28173 [D loss: 0.664122, acc.: 59.38%] [G loss: 0.800415]\n",
      "epoch:36 step:28174 [D loss: 0.663895, acc.: 58.59%] [G loss: 0.792906]\n",
      "epoch:36 step:28175 [D loss: 0.711338, acc.: 50.00%] [G loss: 0.772384]\n",
      "epoch:36 step:28176 [D loss: 0.690885, acc.: 53.91%] [G loss: 0.844766]\n",
      "epoch:36 step:28177 [D loss: 0.710857, acc.: 45.31%] [G loss: 0.767112]\n",
      "epoch:36 step:28178 [D loss: 0.654793, acc.: 64.84%] [G loss: 0.812536]\n",
      "epoch:36 step:28179 [D loss: 0.696238, acc.: 53.91%] [G loss: 0.822522]\n",
      "epoch:36 step:28180 [D loss: 0.709747, acc.: 53.91%] [G loss: 0.786855]\n",
      "epoch:36 step:28181 [D loss: 0.729918, acc.: 47.66%] [G loss: 0.832124]\n",
      "epoch:36 step:28182 [D loss: 0.683868, acc.: 60.16%] [G loss: 0.770162]\n",
      "epoch:36 step:28183 [D loss: 0.700272, acc.: 57.03%] [G loss: 0.727647]\n",
      "epoch:36 step:28184 [D loss: 0.716912, acc.: 50.00%] [G loss: 0.786919]\n",
      "epoch:36 step:28185 [D loss: 0.696310, acc.: 52.34%] [G loss: 0.780824]\n",
      "epoch:36 step:28186 [D loss: 0.740791, acc.: 39.84%] [G loss: 0.829750]\n",
      "epoch:36 step:28187 [D loss: 0.695529, acc.: 53.12%] [G loss: 0.837502]\n",
      "epoch:36 step:28188 [D loss: 0.682508, acc.: 53.12%] [G loss: 0.734695]\n",
      "epoch:36 step:28189 [D loss: 0.689460, acc.: 61.72%] [G loss: 0.710243]\n",
      "epoch:36 step:28190 [D loss: 0.639386, acc.: 69.53%] [G loss: 0.788363]\n",
      "epoch:36 step:28191 [D loss: 0.750885, acc.: 42.97%] [G loss: 0.769794]\n",
      "epoch:36 step:28192 [D loss: 0.731904, acc.: 46.09%] [G loss: 0.774287]\n",
      "epoch:36 step:28193 [D loss: 0.655960, acc.: 69.53%] [G loss: 0.725083]\n",
      "epoch:36 step:28194 [D loss: 0.708045, acc.: 49.22%] [G loss: 0.759625]\n",
      "epoch:36 step:28195 [D loss: 0.674575, acc.: 55.47%] [G loss: 0.803752]\n",
      "epoch:36 step:28196 [D loss: 0.671616, acc.: 57.03%] [G loss: 0.721791]\n",
      "epoch:36 step:28197 [D loss: 0.729812, acc.: 41.41%] [G loss: 0.704460]\n",
      "epoch:36 step:28198 [D loss: 0.695483, acc.: 52.34%] [G loss: 0.733669]\n",
      "epoch:36 step:28199 [D loss: 0.715825, acc.: 49.22%] [G loss: 0.732086]\n",
      "epoch:36 step:28200 [D loss: 0.683239, acc.: 56.25%] [G loss: 0.788634]\n",
      "epoch:36 step:28201 [D loss: 0.634328, acc.: 65.62%] [G loss: 0.840278]\n",
      "epoch:36 step:28202 [D loss: 0.707943, acc.: 55.47%] [G loss: 0.791458]\n",
      "epoch:36 step:28203 [D loss: 0.626591, acc.: 70.31%] [G loss: 0.758164]\n",
      "epoch:36 step:28204 [D loss: 0.702418, acc.: 49.22%] [G loss: 0.768575]\n",
      "epoch:36 step:28205 [D loss: 0.695399, acc.: 44.53%] [G loss: 0.738315]\n",
      "epoch:36 step:28206 [D loss: 0.703383, acc.: 53.12%] [G loss: 0.837654]\n",
      "epoch:36 step:28207 [D loss: 0.746005, acc.: 36.72%] [G loss: 0.783575]\n",
      "epoch:36 step:28208 [D loss: 0.665482, acc.: 59.38%] [G loss: 0.765077]\n",
      "epoch:36 step:28209 [D loss: 0.650056, acc.: 64.84%] [G loss: 0.726366]\n",
      "epoch:36 step:28210 [D loss: 0.689029, acc.: 56.25%] [G loss: 0.733062]\n",
      "epoch:36 step:28211 [D loss: 0.660591, acc.: 57.81%] [G loss: 0.746596]\n",
      "epoch:36 step:28212 [D loss: 0.659347, acc.: 66.41%] [G loss: 0.776370]\n",
      "epoch:36 step:28213 [D loss: 0.706089, acc.: 50.00%] [G loss: 0.815452]\n",
      "epoch:36 step:28214 [D loss: 0.678577, acc.: 54.69%] [G loss: 0.826699]\n",
      "epoch:36 step:28215 [D loss: 0.702475, acc.: 52.34%] [G loss: 0.788043]\n",
      "epoch:36 step:28216 [D loss: 0.662810, acc.: 53.91%] [G loss: 0.748277]\n",
      "epoch:36 step:28217 [D loss: 0.748969, acc.: 46.88%] [G loss: 0.809698]\n",
      "epoch:36 step:28218 [D loss: 0.704181, acc.: 51.56%] [G loss: 0.762084]\n",
      "epoch:36 step:28219 [D loss: 0.714981, acc.: 50.00%] [G loss: 0.838617]\n",
      "epoch:36 step:28220 [D loss: 0.691108, acc.: 57.03%] [G loss: 0.882922]\n",
      "epoch:36 step:28221 [D loss: 0.636211, acc.: 68.75%] [G loss: 0.843466]\n",
      "epoch:36 step:28222 [D loss: 0.654747, acc.: 66.41%] [G loss: 0.877817]\n",
      "epoch:36 step:28223 [D loss: 0.702861, acc.: 52.34%] [G loss: 0.887558]\n",
      "epoch:36 step:28224 [D loss: 0.700745, acc.: 49.22%] [G loss: 0.771453]\n",
      "epoch:36 step:28225 [D loss: 0.701653, acc.: 51.56%] [G loss: 0.858775]\n",
      "epoch:36 step:28226 [D loss: 0.720806, acc.: 46.88%] [G loss: 0.801708]\n",
      "epoch:36 step:28227 [D loss: 0.695996, acc.: 48.44%] [G loss: 0.744880]\n",
      "epoch:36 step:28228 [D loss: 0.672104, acc.: 60.94%] [G loss: 0.739045]\n",
      "epoch:36 step:28229 [D loss: 0.697600, acc.: 53.12%] [G loss: 0.756337]\n",
      "epoch:36 step:28230 [D loss: 0.690495, acc.: 58.59%] [G loss: 0.808476]\n",
      "epoch:36 step:28231 [D loss: 0.704323, acc.: 49.22%] [G loss: 0.813951]\n",
      "epoch:36 step:28232 [D loss: 0.737169, acc.: 46.09%] [G loss: 0.824597]\n",
      "epoch:36 step:28233 [D loss: 0.703215, acc.: 50.78%] [G loss: 0.768202]\n",
      "epoch:36 step:28234 [D loss: 0.704669, acc.: 49.22%] [G loss: 0.754975]\n",
      "epoch:36 step:28235 [D loss: 0.715148, acc.: 51.56%] [G loss: 0.819794]\n",
      "epoch:36 step:28236 [D loss: 0.623625, acc.: 65.62%] [G loss: 0.853334]\n",
      "epoch:36 step:28237 [D loss: 0.682452, acc.: 49.22%] [G loss: 0.791385]\n",
      "epoch:36 step:28238 [D loss: 0.675082, acc.: 55.47%] [G loss: 0.859299]\n",
      "epoch:36 step:28239 [D loss: 0.738121, acc.: 39.84%] [G loss: 0.757289]\n",
      "epoch:36 step:28240 [D loss: 0.696981, acc.: 48.44%] [G loss: 0.787726]\n",
      "epoch:36 step:28241 [D loss: 0.730869, acc.: 45.31%] [G loss: 0.728632]\n",
      "epoch:36 step:28242 [D loss: 0.711436, acc.: 46.88%] [G loss: 0.806412]\n",
      "epoch:36 step:28243 [D loss: 0.607497, acc.: 75.78%] [G loss: 0.772665]\n",
      "epoch:36 step:28244 [D loss: 0.723433, acc.: 48.44%] [G loss: 0.769362]\n",
      "epoch:36 step:28245 [D loss: 0.705793, acc.: 52.34%] [G loss: 0.731905]\n",
      "epoch:36 step:28246 [D loss: 0.724607, acc.: 48.44%] [G loss: 0.734320]\n",
      "epoch:36 step:28247 [D loss: 0.648777, acc.: 59.38%] [G loss: 0.842142]\n",
      "epoch:36 step:28248 [D loss: 0.669076, acc.: 60.16%] [G loss: 0.785944]\n",
      "epoch:36 step:28249 [D loss: 0.688262, acc.: 52.34%] [G loss: 0.925517]\n",
      "epoch:36 step:28250 [D loss: 0.707020, acc.: 48.44%] [G loss: 0.881250]\n",
      "epoch:36 step:28251 [D loss: 0.717771, acc.: 49.22%] [G loss: 0.807646]\n",
      "epoch:36 step:28252 [D loss: 0.709989, acc.: 50.78%] [G loss: 0.871172]\n",
      "epoch:36 step:28253 [D loss: 0.723088, acc.: 42.97%] [G loss: 0.809440]\n",
      "epoch:36 step:28254 [D loss: 0.718688, acc.: 52.34%] [G loss: 0.732919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28255 [D loss: 0.623210, acc.: 71.88%] [G loss: 0.726254]\n",
      "epoch:36 step:28256 [D loss: 0.650279, acc.: 66.41%] [G loss: 0.736796]\n",
      "epoch:36 step:28257 [D loss: 0.675258, acc.: 59.38%] [G loss: 0.821469]\n",
      "epoch:36 step:28258 [D loss: 0.708868, acc.: 52.34%] [G loss: 0.754877]\n",
      "epoch:36 step:28259 [D loss: 0.660519, acc.: 57.81%] [G loss: 0.818447]\n",
      "epoch:36 step:28260 [D loss: 0.711975, acc.: 46.09%] [G loss: 0.712548]\n",
      "epoch:36 step:28261 [D loss: 0.726023, acc.: 46.09%] [G loss: 0.748973]\n",
      "epoch:36 step:28262 [D loss: 0.683194, acc.: 59.38%] [G loss: 0.836770]\n",
      "epoch:36 step:28263 [D loss: 0.712165, acc.: 46.09%] [G loss: 0.791536]\n",
      "epoch:36 step:28264 [D loss: 0.646827, acc.: 60.94%] [G loss: 0.824223]\n",
      "epoch:36 step:28265 [D loss: 0.648321, acc.: 58.59%] [G loss: 0.867146]\n",
      "epoch:36 step:28266 [D loss: 0.726137, acc.: 46.09%] [G loss: 0.785657]\n",
      "epoch:36 step:28267 [D loss: 0.683683, acc.: 60.94%] [G loss: 0.810657]\n",
      "epoch:36 step:28268 [D loss: 0.656504, acc.: 69.53%] [G loss: 0.839401]\n",
      "epoch:36 step:28269 [D loss: 0.656096, acc.: 61.72%] [G loss: 0.899898]\n",
      "epoch:36 step:28270 [D loss: 0.663500, acc.: 63.28%] [G loss: 0.821577]\n",
      "epoch:36 step:28271 [D loss: 0.682132, acc.: 54.69%] [G loss: 0.769905]\n",
      "epoch:36 step:28272 [D loss: 0.730301, acc.: 46.88%] [G loss: 0.820772]\n",
      "epoch:36 step:28273 [D loss: 0.642934, acc.: 60.94%] [G loss: 0.813461]\n",
      "epoch:36 step:28274 [D loss: 0.643184, acc.: 60.16%] [G loss: 0.806105]\n",
      "epoch:36 step:28275 [D loss: 0.678530, acc.: 60.94%] [G loss: 0.803609]\n",
      "epoch:36 step:28276 [D loss: 0.675015, acc.: 56.25%] [G loss: 0.813774]\n",
      "epoch:36 step:28277 [D loss: 0.663122, acc.: 60.16%] [G loss: 0.848159]\n",
      "epoch:36 step:28278 [D loss: 0.758587, acc.: 35.16%] [G loss: 0.787731]\n",
      "epoch:36 step:28279 [D loss: 0.664027, acc.: 56.25%] [G loss: 0.826623]\n",
      "epoch:36 step:28280 [D loss: 0.661991, acc.: 58.59%] [G loss: 0.834435]\n",
      "epoch:36 step:28281 [D loss: 0.696122, acc.: 50.78%] [G loss: 0.767956]\n",
      "epoch:36 step:28282 [D loss: 0.682773, acc.: 52.34%] [G loss: 0.802508]\n",
      "epoch:36 step:28283 [D loss: 0.715805, acc.: 49.22%] [G loss: 0.718394]\n",
      "epoch:36 step:28284 [D loss: 0.689019, acc.: 53.91%] [G loss: 0.830770]\n",
      "epoch:36 step:28285 [D loss: 0.716272, acc.: 47.66%] [G loss: 0.799569]\n",
      "epoch:36 step:28286 [D loss: 0.675995, acc.: 57.03%] [G loss: 0.733076]\n",
      "epoch:36 step:28287 [D loss: 0.638439, acc.: 67.19%] [G loss: 0.776441]\n",
      "epoch:36 step:28288 [D loss: 0.662177, acc.: 62.50%] [G loss: 0.811581]\n",
      "epoch:36 step:28289 [D loss: 0.747253, acc.: 42.19%] [G loss: 0.765125]\n",
      "epoch:36 step:28290 [D loss: 0.667681, acc.: 57.03%] [G loss: 0.844139]\n",
      "epoch:36 step:28291 [D loss: 0.740608, acc.: 41.41%] [G loss: 0.799666]\n",
      "epoch:36 step:28292 [D loss: 0.632266, acc.: 75.78%] [G loss: 0.772555]\n",
      "epoch:36 step:28293 [D loss: 0.684936, acc.: 57.03%] [G loss: 0.783616]\n",
      "epoch:36 step:28294 [D loss: 0.688008, acc.: 55.47%] [G loss: 0.784899]\n",
      "epoch:36 step:28295 [D loss: 0.679027, acc.: 59.38%] [G loss: 0.777783]\n",
      "epoch:36 step:28296 [D loss: 0.694353, acc.: 50.00%] [G loss: 0.798883]\n",
      "epoch:36 step:28297 [D loss: 0.628072, acc.: 72.66%] [G loss: 0.841975]\n",
      "epoch:36 step:28298 [D loss: 0.690907, acc.: 57.03%] [G loss: 0.816107]\n",
      "epoch:36 step:28299 [D loss: 0.695344, acc.: 55.47%] [G loss: 0.809289]\n",
      "epoch:36 step:28300 [D loss: 0.693135, acc.: 52.34%] [G loss: 0.806215]\n",
      "epoch:36 step:28301 [D loss: 0.680431, acc.: 59.38%] [G loss: 0.869289]\n",
      "epoch:36 step:28302 [D loss: 0.679347, acc.: 54.69%] [G loss: 0.742827]\n",
      "epoch:36 step:28303 [D loss: 0.696181, acc.: 50.00%] [G loss: 0.887472]\n",
      "epoch:36 step:28304 [D loss: 0.706371, acc.: 50.78%] [G loss: 0.720925]\n",
      "epoch:36 step:28305 [D loss: 0.645005, acc.: 66.41%] [G loss: 0.800424]\n",
      "epoch:36 step:28306 [D loss: 0.679522, acc.: 57.81%] [G loss: 0.796347]\n",
      "epoch:36 step:28307 [D loss: 0.639099, acc.: 62.50%] [G loss: 0.830937]\n",
      "epoch:36 step:28308 [D loss: 0.693536, acc.: 59.38%] [G loss: 0.801780]\n",
      "epoch:36 step:28309 [D loss: 0.691315, acc.: 56.25%] [G loss: 0.803147]\n",
      "epoch:36 step:28310 [D loss: 0.705734, acc.: 53.12%] [G loss: 0.837228]\n",
      "epoch:36 step:28311 [D loss: 0.673113, acc.: 61.72%] [G loss: 0.814127]\n",
      "epoch:36 step:28312 [D loss: 0.719796, acc.: 42.19%] [G loss: 0.801234]\n",
      "epoch:36 step:28313 [D loss: 0.634859, acc.: 66.41%] [G loss: 0.867863]\n",
      "epoch:36 step:28314 [D loss: 0.665692, acc.: 62.50%] [G loss: 0.792849]\n",
      "epoch:36 step:28315 [D loss: 0.651058, acc.: 67.19%] [G loss: 0.768726]\n",
      "epoch:36 step:28316 [D loss: 0.658496, acc.: 63.28%] [G loss: 0.850271]\n",
      "epoch:36 step:28317 [D loss: 0.613128, acc.: 72.66%] [G loss: 0.787787]\n",
      "epoch:36 step:28318 [D loss: 0.674659, acc.: 60.94%] [G loss: 0.819029]\n",
      "epoch:36 step:28319 [D loss: 0.682389, acc.: 57.81%] [G loss: 0.742079]\n",
      "epoch:36 step:28320 [D loss: 0.678273, acc.: 61.72%] [G loss: 0.779085]\n",
      "epoch:36 step:28321 [D loss: 0.742867, acc.: 42.19%] [G loss: 0.790323]\n",
      "epoch:36 step:28322 [D loss: 0.692424, acc.: 51.56%] [G loss: 0.834744]\n",
      "epoch:36 step:28323 [D loss: 0.625804, acc.: 71.09%] [G loss: 0.756665]\n",
      "epoch:36 step:28324 [D loss: 0.676160, acc.: 55.47%] [G loss: 0.845525]\n",
      "epoch:36 step:28325 [D loss: 0.679094, acc.: 55.47%] [G loss: 0.773741]\n",
      "epoch:36 step:28326 [D loss: 0.644686, acc.: 64.06%] [G loss: 0.816324]\n",
      "epoch:36 step:28327 [D loss: 0.702950, acc.: 52.34%] [G loss: 0.783397]\n",
      "epoch:36 step:28328 [D loss: 0.670708, acc.: 58.59%] [G loss: 0.731362]\n",
      "epoch:36 step:28329 [D loss: 0.674381, acc.: 60.94%] [G loss: 0.805960]\n",
      "epoch:36 step:28330 [D loss: 0.631558, acc.: 64.84%] [G loss: 0.800809]\n",
      "epoch:36 step:28331 [D loss: 0.670780, acc.: 60.94%] [G loss: 0.767709]\n",
      "epoch:36 step:28332 [D loss: 0.635747, acc.: 71.09%] [G loss: 0.739781]\n",
      "epoch:36 step:28333 [D loss: 0.704596, acc.: 51.56%] [G loss: 0.712190]\n",
      "epoch:36 step:28334 [D loss: 0.708201, acc.: 53.12%] [G loss: 0.706371]\n",
      "epoch:36 step:28335 [D loss: 0.633987, acc.: 67.19%] [G loss: 0.820207]\n",
      "epoch:36 step:28336 [D loss: 0.690577, acc.: 53.91%] [G loss: 0.733290]\n",
      "epoch:36 step:28337 [D loss: 0.622826, acc.: 72.66%] [G loss: 0.761606]\n",
      "epoch:36 step:28338 [D loss: 0.696970, acc.: 53.91%] [G loss: 0.781965]\n",
      "epoch:36 step:28339 [D loss: 0.627576, acc.: 71.09%] [G loss: 0.812716]\n",
      "epoch:36 step:28340 [D loss: 0.633770, acc.: 65.62%] [G loss: 0.755338]\n",
      "epoch:36 step:28341 [D loss: 0.649937, acc.: 64.84%] [G loss: 0.771951]\n",
      "epoch:36 step:28342 [D loss: 0.678369, acc.: 58.59%] [G loss: 0.790255]\n",
      "epoch:36 step:28343 [D loss: 0.673186, acc.: 61.72%] [G loss: 0.737534]\n",
      "epoch:36 step:28344 [D loss: 0.763577, acc.: 37.50%] [G loss: 0.736690]\n",
      "epoch:36 step:28345 [D loss: 0.756867, acc.: 34.38%] [G loss: 0.733553]\n",
      "epoch:36 step:28346 [D loss: 0.642455, acc.: 67.97%] [G loss: 0.753899]\n",
      "epoch:36 step:28347 [D loss: 0.629767, acc.: 65.62%] [G loss: 0.783279]\n",
      "epoch:36 step:28348 [D loss: 0.674339, acc.: 59.38%] [G loss: 0.806325]\n",
      "epoch:36 step:28349 [D loss: 0.686530, acc.: 49.22%] [G loss: 0.713103]\n",
      "epoch:36 step:28350 [D loss: 0.676526, acc.: 51.56%] [G loss: 0.653153]\n",
      "epoch:36 step:28351 [D loss: 0.653725, acc.: 63.28%] [G loss: 0.770602]\n",
      "epoch:36 step:28352 [D loss: 0.627931, acc.: 73.44%] [G loss: 0.851803]\n",
      "epoch:36 step:28353 [D loss: 0.699659, acc.: 53.12%] [G loss: 0.748356]\n",
      "epoch:36 step:28354 [D loss: 0.646103, acc.: 62.50%] [G loss: 0.780615]\n",
      "epoch:36 step:28355 [D loss: 0.644525, acc.: 65.62%] [G loss: 0.756338]\n",
      "epoch:36 step:28356 [D loss: 0.706395, acc.: 49.22%] [G loss: 0.735313]\n",
      "epoch:36 step:28357 [D loss: 0.671214, acc.: 57.03%] [G loss: 0.762777]\n",
      "epoch:36 step:28358 [D loss: 0.641323, acc.: 68.75%] [G loss: 0.784363]\n",
      "epoch:36 step:28359 [D loss: 0.661942, acc.: 56.25%] [G loss: 0.801570]\n",
      "epoch:36 step:28360 [D loss: 0.729683, acc.: 46.88%] [G loss: 0.746119]\n",
      "epoch:36 step:28361 [D loss: 0.760289, acc.: 40.62%] [G loss: 0.753740]\n",
      "epoch:36 step:28362 [D loss: 0.689179, acc.: 54.69%] [G loss: 0.782360]\n",
      "epoch:36 step:28363 [D loss: 0.684257, acc.: 55.47%] [G loss: 0.835286]\n",
      "epoch:36 step:28364 [D loss: 0.625154, acc.: 64.06%] [G loss: 0.880972]\n",
      "epoch:36 step:28365 [D loss: 0.701555, acc.: 46.88%] [G loss: 0.719772]\n",
      "epoch:36 step:28366 [D loss: 0.656068, acc.: 62.50%] [G loss: 0.743279]\n",
      "epoch:36 step:28367 [D loss: 0.707935, acc.: 56.25%] [G loss: 0.770906]\n",
      "epoch:36 step:28368 [D loss: 0.688239, acc.: 49.22%] [G loss: 0.786623]\n",
      "epoch:36 step:28369 [D loss: 0.803075, acc.: 35.94%] [G loss: 0.775169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28370 [D loss: 0.686546, acc.: 56.25%] [G loss: 0.844183]\n",
      "epoch:36 step:28371 [D loss: 0.684519, acc.: 52.34%] [G loss: 0.790887]\n",
      "epoch:36 step:28372 [D loss: 0.682692, acc.: 60.94%] [G loss: 0.858437]\n",
      "epoch:36 step:28373 [D loss: 0.694893, acc.: 49.22%] [G loss: 0.750264]\n",
      "epoch:36 step:28374 [D loss: 0.694346, acc.: 57.03%] [G loss: 0.791727]\n",
      "epoch:36 step:28375 [D loss: 0.673213, acc.: 57.81%] [G loss: 0.762868]\n",
      "epoch:36 step:28376 [D loss: 0.645618, acc.: 63.28%] [G loss: 0.850763]\n",
      "epoch:36 step:28377 [D loss: 0.679678, acc.: 53.12%] [G loss: 0.801961]\n",
      "epoch:36 step:28378 [D loss: 0.628502, acc.: 71.09%] [G loss: 0.854831]\n",
      "epoch:36 step:28379 [D loss: 0.669024, acc.: 58.59%] [G loss: 0.882057]\n",
      "epoch:36 step:28380 [D loss: 0.675556, acc.: 55.47%] [G loss: 0.809004]\n",
      "epoch:36 step:28381 [D loss: 0.698384, acc.: 54.69%] [G loss: 0.783644]\n",
      "epoch:36 step:28382 [D loss: 0.672665, acc.: 54.69%] [G loss: 0.741711]\n",
      "epoch:36 step:28383 [D loss: 0.739087, acc.: 48.44%] [G loss: 0.772214]\n",
      "epoch:36 step:28384 [D loss: 0.692432, acc.: 53.91%] [G loss: 0.728362]\n",
      "epoch:36 step:28385 [D loss: 0.632896, acc.: 71.09%] [G loss: 0.771012]\n",
      "epoch:36 step:28386 [D loss: 0.691571, acc.: 53.91%] [G loss: 0.810082]\n",
      "epoch:36 step:28387 [D loss: 0.646313, acc.: 65.62%] [G loss: 0.784566]\n",
      "epoch:36 step:28388 [D loss: 0.640497, acc.: 64.84%] [G loss: 0.832593]\n",
      "epoch:36 step:28389 [D loss: 0.748600, acc.: 35.94%] [G loss: 0.756883]\n",
      "epoch:36 step:28390 [D loss: 0.722973, acc.: 46.09%] [G loss: 0.794054]\n",
      "epoch:36 step:28391 [D loss: 0.694428, acc.: 49.22%] [G loss: 0.778125]\n",
      "epoch:36 step:28392 [D loss: 0.639342, acc.: 68.75%] [G loss: 0.856902]\n",
      "epoch:36 step:28393 [D loss: 0.659426, acc.: 63.28%] [G loss: 0.761412]\n",
      "epoch:36 step:28394 [D loss: 0.687252, acc.: 53.12%] [G loss: 0.740304]\n",
      "epoch:36 step:28395 [D loss: 0.720738, acc.: 40.62%] [G loss: 0.726816]\n",
      "epoch:36 step:28396 [D loss: 0.688221, acc.: 53.12%] [G loss: 0.836200]\n",
      "epoch:36 step:28397 [D loss: 0.714931, acc.: 50.00%] [G loss: 0.791602]\n",
      "epoch:36 step:28398 [D loss: 0.670962, acc.: 59.38%] [G loss: 0.842632]\n",
      "epoch:36 step:28399 [D loss: 0.653503, acc.: 61.72%] [G loss: 0.813478]\n",
      "epoch:36 step:28400 [D loss: 0.674070, acc.: 53.91%] [G loss: 0.860561]\n",
      "epoch:36 step:28401 [D loss: 0.681053, acc.: 59.38%] [G loss: 0.744558]\n",
      "epoch:36 step:28402 [D loss: 0.661252, acc.: 60.94%] [G loss: 0.788548]\n",
      "epoch:36 step:28403 [D loss: 0.696495, acc.: 55.47%] [G loss: 0.872252]\n",
      "epoch:36 step:28404 [D loss: 0.678840, acc.: 57.81%] [G loss: 0.805287]\n",
      "epoch:36 step:28405 [D loss: 0.674883, acc.: 63.28%] [G loss: 0.795018]\n",
      "epoch:36 step:28406 [D loss: 0.642178, acc.: 67.97%] [G loss: 0.795520]\n",
      "epoch:36 step:28407 [D loss: 0.698813, acc.: 50.00%] [G loss: 0.800526]\n",
      "epoch:36 step:28408 [D loss: 0.756377, acc.: 35.94%] [G loss: 0.710309]\n",
      "epoch:36 step:28409 [D loss: 0.656748, acc.: 58.59%] [G loss: 0.735977]\n",
      "epoch:36 step:28410 [D loss: 0.652525, acc.: 65.62%] [G loss: 0.847172]\n",
      "epoch:36 step:28411 [D loss: 0.703739, acc.: 50.78%] [G loss: 0.843521]\n",
      "epoch:36 step:28412 [D loss: 0.712309, acc.: 49.22%] [G loss: 0.742881]\n",
      "epoch:36 step:28413 [D loss: 0.687403, acc.: 53.12%] [G loss: 0.819943]\n",
      "epoch:36 step:28414 [D loss: 0.711916, acc.: 50.78%] [G loss: 0.731640]\n",
      "epoch:36 step:28415 [D loss: 0.668629, acc.: 60.16%] [G loss: 0.844619]\n",
      "epoch:36 step:28416 [D loss: 0.723985, acc.: 46.09%] [G loss: 0.793031]\n",
      "epoch:36 step:28417 [D loss: 0.698300, acc.: 48.44%] [G loss: 0.726260]\n",
      "epoch:36 step:28418 [D loss: 0.690513, acc.: 57.03%] [G loss: 0.785026]\n",
      "epoch:36 step:28419 [D loss: 0.610808, acc.: 71.09%] [G loss: 0.756341]\n",
      "epoch:36 step:28420 [D loss: 0.730453, acc.: 46.09%] [G loss: 0.768340]\n",
      "epoch:36 step:28421 [D loss: 0.691492, acc.: 57.81%] [G loss: 0.809613]\n",
      "epoch:36 step:28422 [D loss: 0.668640, acc.: 58.59%] [G loss: 0.748322]\n",
      "epoch:36 step:28423 [D loss: 0.645731, acc.: 66.41%] [G loss: 0.793574]\n",
      "epoch:36 step:28424 [D loss: 0.692660, acc.: 56.25%] [G loss: 0.708811]\n",
      "epoch:36 step:28425 [D loss: 0.769196, acc.: 35.94%] [G loss: 0.797535]\n",
      "epoch:36 step:28426 [D loss: 0.726835, acc.: 47.66%] [G loss: 0.794049]\n",
      "epoch:36 step:28427 [D loss: 0.741850, acc.: 42.19%] [G loss: 0.780650]\n",
      "epoch:36 step:28428 [D loss: 0.720859, acc.: 43.75%] [G loss: 0.853194]\n",
      "epoch:36 step:28429 [D loss: 0.722632, acc.: 47.66%] [G loss: 0.807788]\n",
      "epoch:36 step:28430 [D loss: 0.729236, acc.: 41.41%] [G loss: 0.768557]\n",
      "epoch:36 step:28431 [D loss: 0.758336, acc.: 41.41%] [G loss: 0.725378]\n",
      "epoch:36 step:28432 [D loss: 0.701695, acc.: 51.56%] [G loss: 0.742017]\n",
      "epoch:36 step:28433 [D loss: 0.714816, acc.: 48.44%] [G loss: 0.753286]\n",
      "epoch:36 step:28434 [D loss: 0.673935, acc.: 63.28%] [G loss: 0.734071]\n",
      "epoch:36 step:28435 [D loss: 0.688055, acc.: 50.00%] [G loss: 0.795189]\n",
      "epoch:36 step:28436 [D loss: 0.704535, acc.: 48.44%] [G loss: 0.788714]\n",
      "epoch:36 step:28437 [D loss: 0.707698, acc.: 52.34%] [G loss: 0.755174]\n",
      "epoch:36 step:28438 [D loss: 0.760180, acc.: 44.53%] [G loss: 0.694631]\n",
      "epoch:36 step:28439 [D loss: 0.673264, acc.: 62.50%] [G loss: 0.732894]\n",
      "epoch:36 step:28440 [D loss: 0.671118, acc.: 57.03%] [G loss: 0.752867]\n",
      "epoch:36 step:28441 [D loss: 0.701207, acc.: 47.66%] [G loss: 0.807273]\n",
      "epoch:36 step:28442 [D loss: 0.689900, acc.: 53.91%] [G loss: 0.796401]\n",
      "epoch:36 step:28443 [D loss: 0.670324, acc.: 59.38%] [G loss: 0.844291]\n",
      "epoch:36 step:28444 [D loss: 0.728424, acc.: 42.97%] [G loss: 0.765621]\n",
      "epoch:36 step:28445 [D loss: 0.722084, acc.: 47.66%] [G loss: 0.793054]\n",
      "epoch:36 step:28446 [D loss: 0.695001, acc.: 52.34%] [G loss: 0.776838]\n",
      "epoch:36 step:28447 [D loss: 0.724497, acc.: 46.88%] [G loss: 0.775406]\n",
      "epoch:36 step:28448 [D loss: 0.720208, acc.: 46.88%] [G loss: 0.708085]\n",
      "epoch:36 step:28449 [D loss: 0.708290, acc.: 45.31%] [G loss: 0.728938]\n",
      "epoch:36 step:28450 [D loss: 0.727031, acc.: 47.66%] [G loss: 0.663551]\n",
      "epoch:36 step:28451 [D loss: 0.701882, acc.: 46.88%] [G loss: 0.755756]\n",
      "epoch:36 step:28452 [D loss: 0.707639, acc.: 43.75%] [G loss: 0.736493]\n",
      "epoch:36 step:28453 [D loss: 0.663098, acc.: 64.06%] [G loss: 0.771837]\n",
      "epoch:36 step:28454 [D loss: 0.742942, acc.: 43.75%] [G loss: 0.782999]\n",
      "epoch:36 step:28455 [D loss: 0.689381, acc.: 56.25%] [G loss: 0.849774]\n",
      "epoch:36 step:28456 [D loss: 0.642755, acc.: 62.50%] [G loss: 0.762083]\n",
      "epoch:36 step:28457 [D loss: 0.711090, acc.: 46.88%] [G loss: 0.793920]\n",
      "epoch:36 step:28458 [D loss: 0.690012, acc.: 52.34%] [G loss: 0.721646]\n",
      "epoch:36 step:28459 [D loss: 0.699043, acc.: 49.22%] [G loss: 0.748009]\n",
      "epoch:36 step:28460 [D loss: 0.656206, acc.: 64.06%] [G loss: 0.742621]\n",
      "epoch:36 step:28461 [D loss: 0.636146, acc.: 64.84%] [G loss: 0.822305]\n",
      "epoch:36 step:28462 [D loss: 0.702469, acc.: 51.56%] [G loss: 0.767104]\n",
      "epoch:36 step:28463 [D loss: 0.641194, acc.: 65.62%] [G loss: 0.757172]\n",
      "epoch:36 step:28464 [D loss: 0.722360, acc.: 40.62%] [G loss: 0.813333]\n",
      "epoch:36 step:28465 [D loss: 0.656998, acc.: 67.97%] [G loss: 0.880815]\n",
      "epoch:36 step:28466 [D loss: 0.724944, acc.: 52.34%] [G loss: 0.820380]\n",
      "epoch:36 step:28467 [D loss: 0.660277, acc.: 59.38%] [G loss: 0.878779]\n",
      "epoch:36 step:28468 [D loss: 0.654571, acc.: 60.94%] [G loss: 0.813000]\n",
      "epoch:36 step:28469 [D loss: 0.624943, acc.: 71.09%] [G loss: 0.952213]\n",
      "epoch:36 step:28470 [D loss: 0.698296, acc.: 57.81%] [G loss: 0.828418]\n",
      "epoch:36 step:28471 [D loss: 0.695925, acc.: 45.31%] [G loss: 0.771831]\n",
      "epoch:36 step:28472 [D loss: 0.663453, acc.: 60.16%] [G loss: 0.780864]\n",
      "epoch:36 step:28473 [D loss: 0.668320, acc.: 56.25%] [G loss: 0.798992]\n",
      "epoch:36 step:28474 [D loss: 0.683892, acc.: 54.69%] [G loss: 0.875866]\n",
      "epoch:36 step:28475 [D loss: 0.704955, acc.: 51.56%] [G loss: 0.764701]\n",
      "epoch:36 step:28476 [D loss: 0.679224, acc.: 54.69%] [G loss: 0.744973]\n",
      "epoch:36 step:28477 [D loss: 0.636178, acc.: 67.19%] [G loss: 0.807432]\n",
      "epoch:36 step:28478 [D loss: 0.653682, acc.: 56.25%] [G loss: 0.771990]\n",
      "epoch:36 step:28479 [D loss: 0.678810, acc.: 60.94%] [G loss: 0.803086]\n",
      "epoch:36 step:28480 [D loss: 0.680122, acc.: 55.47%] [G loss: 0.796918]\n",
      "epoch:36 step:28481 [D loss: 0.687663, acc.: 51.56%] [G loss: 0.817393]\n",
      "epoch:36 step:28482 [D loss: 0.695699, acc.: 60.16%] [G loss: 0.783474]\n",
      "epoch:36 step:28483 [D loss: 0.694267, acc.: 50.78%] [G loss: 0.752613]\n",
      "epoch:36 step:28484 [D loss: 0.645632, acc.: 63.28%] [G loss: 0.779033]\n",
      "epoch:36 step:28485 [D loss: 0.728237, acc.: 40.62%] [G loss: 0.871919]\n",
      "epoch:36 step:28486 [D loss: 0.635216, acc.: 68.75%] [G loss: 0.882534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28487 [D loss: 0.603956, acc.: 75.00%] [G loss: 0.800151]\n",
      "epoch:36 step:28488 [D loss: 0.670269, acc.: 61.72%] [G loss: 0.846480]\n",
      "epoch:36 step:28489 [D loss: 0.714519, acc.: 44.53%] [G loss: 0.831127]\n",
      "epoch:36 step:28490 [D loss: 0.651837, acc.: 64.06%] [G loss: 0.886933]\n",
      "epoch:36 step:28491 [D loss: 0.688693, acc.: 58.59%] [G loss: 0.842310]\n",
      "epoch:36 step:28492 [D loss: 0.678789, acc.: 53.91%] [G loss: 0.761505]\n",
      "epoch:36 step:28493 [D loss: 0.650619, acc.: 60.94%] [G loss: 0.777061]\n",
      "epoch:36 step:28494 [D loss: 0.682407, acc.: 59.38%] [G loss: 0.751307]\n",
      "epoch:36 step:28495 [D loss: 0.666632, acc.: 64.06%] [G loss: 0.843212]\n",
      "epoch:36 step:28496 [D loss: 0.697556, acc.: 47.66%] [G loss: 0.742684]\n",
      "epoch:36 step:28497 [D loss: 0.646357, acc.: 62.50%] [G loss: 0.727249]\n",
      "epoch:36 step:28498 [D loss: 0.698748, acc.: 50.78%] [G loss: 0.788449]\n",
      "epoch:36 step:28499 [D loss: 0.638664, acc.: 67.97%] [G loss: 0.797048]\n",
      "epoch:36 step:28500 [D loss: 0.630392, acc.: 67.97%] [G loss: 0.702650]\n",
      "epoch:36 step:28501 [D loss: 0.699729, acc.: 50.00%] [G loss: 0.773817]\n",
      "epoch:36 step:28502 [D loss: 0.624608, acc.: 68.75%] [G loss: 0.826164]\n",
      "epoch:36 step:28503 [D loss: 0.704507, acc.: 53.12%] [G loss: 0.743285]\n",
      "epoch:36 step:28504 [D loss: 0.683935, acc.: 55.47%] [G loss: 0.753564]\n",
      "epoch:36 step:28505 [D loss: 0.704671, acc.: 57.03%] [G loss: 0.774641]\n",
      "epoch:36 step:28506 [D loss: 0.737290, acc.: 46.09%] [G loss: 0.781015]\n",
      "epoch:36 step:28507 [D loss: 0.730851, acc.: 48.44%] [G loss: 0.777414]\n",
      "epoch:36 step:28508 [D loss: 0.723602, acc.: 50.00%] [G loss: 0.736319]\n",
      "epoch:36 step:28509 [D loss: 0.668522, acc.: 61.72%] [G loss: 0.758053]\n",
      "epoch:36 step:28510 [D loss: 0.686766, acc.: 52.34%] [G loss: 0.741467]\n",
      "epoch:36 step:28511 [D loss: 0.675160, acc.: 63.28%] [G loss: 0.869754]\n",
      "epoch:36 step:28512 [D loss: 0.655181, acc.: 63.28%] [G loss: 0.720755]\n",
      "epoch:36 step:28513 [D loss: 0.654627, acc.: 63.28%] [G loss: 0.822890]\n",
      "epoch:36 step:28514 [D loss: 0.698797, acc.: 52.34%] [G loss: 0.754091]\n",
      "epoch:36 step:28515 [D loss: 0.645407, acc.: 66.41%] [G loss: 0.730178]\n",
      "epoch:36 step:28516 [D loss: 0.684853, acc.: 54.69%] [G loss: 0.767081]\n",
      "epoch:36 step:28517 [D loss: 0.713350, acc.: 49.22%] [G loss: 0.712796]\n",
      "epoch:36 step:28518 [D loss: 0.659459, acc.: 61.72%] [G loss: 0.698300]\n",
      "epoch:36 step:28519 [D loss: 0.667291, acc.: 60.16%] [G loss: 0.776324]\n",
      "epoch:36 step:28520 [D loss: 0.680720, acc.: 53.91%] [G loss: 0.711674]\n",
      "epoch:36 step:28521 [D loss: 0.675988, acc.: 60.94%] [G loss: 0.834702]\n",
      "epoch:36 step:28522 [D loss: 0.631787, acc.: 66.41%] [G loss: 0.836960]\n",
      "epoch:36 step:28523 [D loss: 0.665649, acc.: 60.94%] [G loss: 0.813597]\n",
      "epoch:36 step:28524 [D loss: 0.649471, acc.: 64.06%] [G loss: 0.776578]\n",
      "epoch:36 step:28525 [D loss: 0.665736, acc.: 60.94%] [G loss: 0.783895]\n",
      "epoch:36 step:28526 [D loss: 0.640183, acc.: 68.75%] [G loss: 0.756766]\n",
      "epoch:36 step:28527 [D loss: 0.728384, acc.: 45.31%] [G loss: 0.777646]\n",
      "epoch:36 step:28528 [D loss: 0.680318, acc.: 51.56%] [G loss: 0.746352]\n",
      "epoch:36 step:28529 [D loss: 0.707320, acc.: 52.34%] [G loss: 0.777805]\n",
      "epoch:36 step:28530 [D loss: 0.710784, acc.: 46.09%] [G loss: 0.805937]\n",
      "epoch:36 step:28531 [D loss: 0.656859, acc.: 66.41%] [G loss: 0.748969]\n",
      "epoch:36 step:28532 [D loss: 0.681250, acc.: 55.47%] [G loss: 0.778555]\n",
      "epoch:36 step:28533 [D loss: 0.675180, acc.: 60.94%] [G loss: 0.739656]\n",
      "epoch:36 step:28534 [D loss: 0.672375, acc.: 57.81%] [G loss: 0.773640]\n",
      "epoch:36 step:28535 [D loss: 0.691952, acc.: 54.69%] [G loss: 0.762783]\n",
      "epoch:36 step:28536 [D loss: 0.709318, acc.: 49.22%] [G loss: 0.801716]\n",
      "epoch:36 step:28537 [D loss: 0.657377, acc.: 67.19%] [G loss: 0.814672]\n",
      "epoch:36 step:28538 [D loss: 0.647498, acc.: 64.84%] [G loss: 0.746022]\n",
      "epoch:36 step:28539 [D loss: 0.676262, acc.: 58.59%] [G loss: 0.767562]\n",
      "epoch:36 step:28540 [D loss: 0.684240, acc.: 57.03%] [G loss: 0.700316]\n",
      "epoch:36 step:28541 [D loss: 0.640352, acc.: 66.41%] [G loss: 0.675275]\n",
      "epoch:36 step:28542 [D loss: 0.693059, acc.: 55.47%] [G loss: 0.800223]\n",
      "epoch:36 step:28543 [D loss: 0.722278, acc.: 45.31%] [G loss: 0.765774]\n",
      "epoch:36 step:28544 [D loss: 0.709584, acc.: 50.00%] [G loss: 0.667045]\n",
      "epoch:36 step:28545 [D loss: 0.668694, acc.: 61.72%] [G loss: 0.761768]\n",
      "epoch:36 step:28546 [D loss: 0.694687, acc.: 52.34%] [G loss: 0.736175]\n",
      "epoch:36 step:28547 [D loss: 0.730696, acc.: 46.88%] [G loss: 0.757407]\n",
      "epoch:36 step:28548 [D loss: 0.595069, acc.: 76.56%] [G loss: 0.686614]\n",
      "epoch:36 step:28549 [D loss: 0.710899, acc.: 43.75%] [G loss: 0.743477]\n",
      "epoch:36 step:28550 [D loss: 0.703546, acc.: 58.59%] [G loss: 0.778392]\n",
      "epoch:36 step:28551 [D loss: 0.702996, acc.: 50.78%] [G loss: 0.810045]\n",
      "epoch:36 step:28552 [D loss: 0.672131, acc.: 53.91%] [G loss: 0.768539]\n",
      "epoch:36 step:28553 [D loss: 0.715917, acc.: 47.66%] [G loss: 0.773813]\n",
      "epoch:36 step:28554 [D loss: 0.634864, acc.: 67.97%] [G loss: 0.833189]\n",
      "epoch:36 step:28555 [D loss: 0.694596, acc.: 57.81%] [G loss: 0.845878]\n",
      "epoch:36 step:28556 [D loss: 0.717996, acc.: 44.53%] [G loss: 0.804235]\n",
      "epoch:36 step:28557 [D loss: 0.705707, acc.: 53.91%] [G loss: 0.725498]\n",
      "epoch:36 step:28558 [D loss: 0.633770, acc.: 66.41%] [G loss: 0.778527]\n",
      "epoch:36 step:28559 [D loss: 0.669364, acc.: 58.59%] [G loss: 0.790820]\n",
      "epoch:36 step:28560 [D loss: 0.713079, acc.: 51.56%] [G loss: 0.815047]\n",
      "epoch:36 step:28561 [D loss: 0.729896, acc.: 41.41%] [G loss: 0.756715]\n",
      "epoch:36 step:28562 [D loss: 0.650717, acc.: 59.38%] [G loss: 0.741802]\n",
      "epoch:36 step:28563 [D loss: 0.703263, acc.: 47.66%] [G loss: 0.795327]\n",
      "epoch:36 step:28564 [D loss: 0.702568, acc.: 49.22%] [G loss: 0.820150]\n",
      "epoch:36 step:28565 [D loss: 0.646535, acc.: 63.28%] [G loss: 0.767622]\n",
      "epoch:36 step:28566 [D loss: 0.686323, acc.: 54.69%] [G loss: 0.822152]\n",
      "epoch:36 step:28567 [D loss: 0.687457, acc.: 55.47%] [G loss: 0.832241]\n",
      "epoch:36 step:28568 [D loss: 0.620879, acc.: 72.66%] [G loss: 0.855625]\n",
      "epoch:36 step:28569 [D loss: 0.688103, acc.: 50.78%] [G loss: 0.764165]\n",
      "epoch:36 step:28570 [D loss: 0.691052, acc.: 50.78%] [G loss: 0.748353]\n",
      "epoch:36 step:28571 [D loss: 0.680522, acc.: 57.81%] [G loss: 0.790776]\n",
      "epoch:36 step:28572 [D loss: 0.718440, acc.: 48.44%] [G loss: 0.759439]\n",
      "epoch:36 step:28573 [D loss: 0.720231, acc.: 48.44%] [G loss: 0.775537]\n",
      "epoch:36 step:28574 [D loss: 0.666793, acc.: 60.16%] [G loss: 0.696924]\n",
      "epoch:36 step:28575 [D loss: 0.748508, acc.: 43.75%] [G loss: 0.767109]\n",
      "epoch:36 step:28576 [D loss: 0.722620, acc.: 42.19%] [G loss: 0.742498]\n",
      "epoch:36 step:28577 [D loss: 0.677064, acc.: 59.38%] [G loss: 0.750948]\n",
      "epoch:36 step:28578 [D loss: 0.710322, acc.: 44.53%] [G loss: 0.806131]\n",
      "epoch:36 step:28579 [D loss: 0.701770, acc.: 50.00%] [G loss: 0.771180]\n",
      "epoch:36 step:28580 [D loss: 0.670155, acc.: 58.59%] [G loss: 0.740900]\n",
      "epoch:36 step:28581 [D loss: 0.691449, acc.: 53.12%] [G loss: 0.776718]\n",
      "epoch:36 step:28582 [D loss: 0.658889, acc.: 64.06%] [G loss: 0.779543]\n",
      "epoch:36 step:28583 [D loss: 0.670644, acc.: 60.94%] [G loss: 0.815906]\n",
      "epoch:36 step:28584 [D loss: 0.684417, acc.: 55.47%] [G loss: 0.758334]\n",
      "epoch:36 step:28585 [D loss: 0.657340, acc.: 71.88%] [G loss: 0.752698]\n",
      "epoch:36 step:28586 [D loss: 0.681029, acc.: 58.59%] [G loss: 0.779527]\n",
      "epoch:36 step:28587 [D loss: 0.747145, acc.: 41.41%] [G loss: 0.805142]\n",
      "epoch:36 step:28588 [D loss: 0.676745, acc.: 60.16%] [G loss: 0.802369]\n",
      "epoch:36 step:28589 [D loss: 0.674816, acc.: 53.91%] [G loss: 0.788820]\n",
      "epoch:36 step:28590 [D loss: 0.637168, acc.: 67.97%] [G loss: 0.757183]\n",
      "epoch:36 step:28591 [D loss: 0.705839, acc.: 47.66%] [G loss: 0.834576]\n",
      "epoch:36 step:28592 [D loss: 0.632982, acc.: 74.22%] [G loss: 0.810312]\n",
      "epoch:36 step:28593 [D loss: 0.696188, acc.: 53.91%] [G loss: 0.855519]\n",
      "epoch:36 step:28594 [D loss: 0.626653, acc.: 69.53%] [G loss: 0.814664]\n",
      "epoch:36 step:28595 [D loss: 0.720149, acc.: 52.34%] [G loss: 0.804809]\n",
      "epoch:36 step:28596 [D loss: 0.680659, acc.: 58.59%] [G loss: 0.789729]\n",
      "epoch:36 step:28597 [D loss: 0.684878, acc.: 53.91%] [G loss: 0.753924]\n",
      "epoch:36 step:28598 [D loss: 0.728611, acc.: 45.31%] [G loss: 0.832283]\n",
      "epoch:36 step:28599 [D loss: 0.660883, acc.: 57.81%] [G loss: 0.840471]\n",
      "epoch:36 step:28600 [D loss: 0.659124, acc.: 57.81%] [G loss: 0.718167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28601 [D loss: 0.693099, acc.: 56.25%] [G loss: 0.733004]\n",
      "epoch:36 step:28602 [D loss: 0.686184, acc.: 53.91%] [G loss: 0.764726]\n",
      "epoch:36 step:28603 [D loss: 0.689628, acc.: 55.47%] [G loss: 0.816891]\n",
      "epoch:36 step:28604 [D loss: 0.666928, acc.: 61.72%] [G loss: 0.810108]\n",
      "epoch:36 step:28605 [D loss: 0.706176, acc.: 54.69%] [G loss: 0.767914]\n",
      "epoch:36 step:28606 [D loss: 0.708326, acc.: 50.78%] [G loss: 0.667610]\n",
      "epoch:36 step:28607 [D loss: 0.644530, acc.: 65.62%] [G loss: 0.789082]\n",
      "epoch:36 step:28608 [D loss: 0.655036, acc.: 58.59%] [G loss: 0.890735]\n",
      "epoch:36 step:28609 [D loss: 0.628047, acc.: 65.62%] [G loss: 0.758940]\n",
      "epoch:36 step:28610 [D loss: 0.672656, acc.: 57.03%] [G loss: 0.839244]\n",
      "epoch:36 step:28611 [D loss: 0.649004, acc.: 64.06%] [G loss: 0.809392]\n",
      "epoch:36 step:28612 [D loss: 0.679766, acc.: 57.81%] [G loss: 0.853376]\n",
      "epoch:36 step:28613 [D loss: 0.738874, acc.: 43.75%] [G loss: 0.806806]\n",
      "epoch:36 step:28614 [D loss: 0.713241, acc.: 50.00%] [G loss: 0.820697]\n",
      "epoch:36 step:28615 [D loss: 0.655795, acc.: 60.16%] [G loss: 0.690031]\n",
      "epoch:36 step:28616 [D loss: 0.709725, acc.: 51.56%] [G loss: 0.721855]\n",
      "epoch:36 step:28617 [D loss: 0.683745, acc.: 53.12%] [G loss: 0.734841]\n",
      "epoch:36 step:28618 [D loss: 0.679234, acc.: 57.03%] [G loss: 0.878345]\n",
      "epoch:36 step:28619 [D loss: 0.670466, acc.: 55.47%] [G loss: 0.867983]\n",
      "epoch:36 step:28620 [D loss: 0.652765, acc.: 67.97%] [G loss: 0.874073]\n",
      "epoch:36 step:28621 [D loss: 0.676864, acc.: 57.81%] [G loss: 0.732190]\n",
      "epoch:36 step:28622 [D loss: 0.770095, acc.: 36.72%] [G loss: 0.733897]\n",
      "epoch:36 step:28623 [D loss: 0.641794, acc.: 64.06%] [G loss: 0.861832]\n",
      "epoch:36 step:28624 [D loss: 0.730412, acc.: 40.62%] [G loss: 0.764194]\n",
      "epoch:36 step:28625 [D loss: 0.728560, acc.: 39.84%] [G loss: 0.776652]\n",
      "epoch:36 step:28626 [D loss: 0.680782, acc.: 55.47%] [G loss: 0.723352]\n",
      "epoch:36 step:28627 [D loss: 0.749974, acc.: 38.28%] [G loss: 0.765107]\n",
      "epoch:36 step:28628 [D loss: 0.750997, acc.: 32.81%] [G loss: 0.710236]\n",
      "epoch:36 step:28629 [D loss: 0.787244, acc.: 29.69%] [G loss: 0.743880]\n",
      "epoch:36 step:28630 [D loss: 0.734744, acc.: 43.75%] [G loss: 0.713934]\n",
      "epoch:36 step:28631 [D loss: 0.687672, acc.: 56.25%] [G loss: 0.731906]\n",
      "epoch:36 step:28632 [D loss: 0.727585, acc.: 50.00%] [G loss: 0.791831]\n",
      "epoch:36 step:28633 [D loss: 0.608464, acc.: 73.44%] [G loss: 0.822144]\n",
      "epoch:36 step:28634 [D loss: 0.661380, acc.: 60.94%] [G loss: 0.797822]\n",
      "epoch:36 step:28635 [D loss: 0.697229, acc.: 52.34%] [G loss: 0.864018]\n",
      "epoch:36 step:28636 [D loss: 0.722270, acc.: 52.34%] [G loss: 0.791970]\n",
      "epoch:36 step:28637 [D loss: 0.659619, acc.: 63.28%] [G loss: 0.774426]\n",
      "epoch:36 step:28638 [D loss: 0.687895, acc.: 51.56%] [G loss: 0.753138]\n",
      "epoch:36 step:28639 [D loss: 0.675526, acc.: 58.59%] [G loss: 0.728075]\n",
      "epoch:36 step:28640 [D loss: 0.740269, acc.: 45.31%] [G loss: 0.802555]\n",
      "epoch:36 step:28641 [D loss: 0.704483, acc.: 49.22%] [G loss: 0.796996]\n",
      "epoch:36 step:28642 [D loss: 0.698782, acc.: 53.91%] [G loss: 0.829236]\n",
      "epoch:36 step:28643 [D loss: 0.717829, acc.: 50.00%] [G loss: 0.712952]\n",
      "epoch:36 step:28644 [D loss: 0.677148, acc.: 62.50%] [G loss: 0.727395]\n",
      "epoch:36 step:28645 [D loss: 0.663287, acc.: 53.91%] [G loss: 0.702562]\n",
      "epoch:36 step:28646 [D loss: 0.676894, acc.: 50.00%] [G loss: 0.806815]\n",
      "epoch:36 step:28647 [D loss: 0.648402, acc.: 63.28%] [G loss: 0.792934]\n",
      "epoch:36 step:28648 [D loss: 0.661116, acc.: 63.28%] [G loss: 0.817651]\n",
      "epoch:36 step:28649 [D loss: 0.671465, acc.: 60.16%] [G loss: 0.821002]\n",
      "epoch:36 step:28650 [D loss: 0.673885, acc.: 62.50%] [G loss: 0.803352]\n",
      "epoch:36 step:28651 [D loss: 0.631252, acc.: 68.75%] [G loss: 0.803943]\n",
      "epoch:36 step:28652 [D loss: 0.700802, acc.: 46.09%] [G loss: 0.825392]\n",
      "epoch:36 step:28653 [D loss: 0.676412, acc.: 56.25%] [G loss: 0.743375]\n",
      "epoch:36 step:28654 [D loss: 0.641967, acc.: 63.28%] [G loss: 0.775813]\n",
      "epoch:36 step:28655 [D loss: 0.710228, acc.: 52.34%] [G loss: 0.821489]\n",
      "epoch:36 step:28656 [D loss: 0.655899, acc.: 60.94%] [G loss: 0.717211]\n",
      "epoch:36 step:28657 [D loss: 0.642012, acc.: 65.62%] [G loss: 0.798230]\n",
      "epoch:36 step:28658 [D loss: 0.688549, acc.: 60.16%] [G loss: 0.779601]\n",
      "epoch:36 step:28659 [D loss: 0.689349, acc.: 54.69%] [G loss: 0.782445]\n",
      "epoch:36 step:28660 [D loss: 0.682405, acc.: 53.91%] [G loss: 0.803792]\n",
      "epoch:36 step:28661 [D loss: 0.660290, acc.: 63.28%] [G loss: 0.745311]\n",
      "epoch:36 step:28662 [D loss: 0.754225, acc.: 41.41%] [G loss: 0.776345]\n",
      "epoch:36 step:28663 [D loss: 0.679052, acc.: 54.69%] [G loss: 0.770792]\n",
      "epoch:36 step:28664 [D loss: 0.696318, acc.: 52.34%] [G loss: 0.789022]\n",
      "epoch:36 step:28665 [D loss: 0.655985, acc.: 62.50%] [G loss: 0.795290]\n",
      "epoch:36 step:28666 [D loss: 0.642635, acc.: 63.28%] [G loss: 0.777112]\n",
      "epoch:36 step:28667 [D loss: 0.733023, acc.: 46.88%] [G loss: 0.720196]\n",
      "epoch:36 step:28668 [D loss: 0.710379, acc.: 48.44%] [G loss: 0.746400]\n",
      "epoch:36 step:28669 [D loss: 0.654439, acc.: 67.19%] [G loss: 0.841007]\n",
      "epoch:36 step:28670 [D loss: 0.639759, acc.: 62.50%] [G loss: 0.896205]\n",
      "epoch:36 step:28671 [D loss: 0.609134, acc.: 74.22%] [G loss: 0.951045]\n",
      "epoch:36 step:28672 [D loss: 0.701061, acc.: 53.91%] [G loss: 0.763638]\n",
      "epoch:36 step:28673 [D loss: 0.742313, acc.: 39.06%] [G loss: 0.661337]\n",
      "epoch:36 step:28674 [D loss: 0.678392, acc.: 57.81%] [G loss: 0.800400]\n",
      "epoch:36 step:28675 [D loss: 0.648385, acc.: 60.94%] [G loss: 0.746242]\n",
      "epoch:36 step:28676 [D loss: 0.657226, acc.: 62.50%] [G loss: 0.774987]\n",
      "epoch:36 step:28677 [D loss: 0.712752, acc.: 46.88%] [G loss: 0.735842]\n",
      "epoch:36 step:28678 [D loss: 0.654085, acc.: 64.84%] [G loss: 0.769446]\n",
      "epoch:36 step:28679 [D loss: 0.667314, acc.: 65.62%] [G loss: 0.765336]\n",
      "epoch:36 step:28680 [D loss: 0.662707, acc.: 61.72%] [G loss: 0.771561]\n",
      "epoch:36 step:28681 [D loss: 0.728307, acc.: 49.22%] [G loss: 0.822945]\n",
      "epoch:36 step:28682 [D loss: 0.719863, acc.: 46.09%] [G loss: 0.783210]\n",
      "epoch:36 step:28683 [D loss: 0.723767, acc.: 49.22%] [G loss: 0.859215]\n",
      "epoch:36 step:28684 [D loss: 0.675372, acc.: 58.59%] [G loss: 0.842921]\n",
      "epoch:36 step:28685 [D loss: 0.686569, acc.: 53.12%] [G loss: 0.836785]\n",
      "epoch:36 step:28686 [D loss: 0.693921, acc.: 56.25%] [G loss: 0.714304]\n",
      "epoch:36 step:28687 [D loss: 0.740943, acc.: 46.09%] [G loss: 0.772642]\n",
      "epoch:36 step:28688 [D loss: 0.682064, acc.: 55.47%] [G loss: 0.765032]\n",
      "epoch:36 step:28689 [D loss: 0.700388, acc.: 50.78%] [G loss: 0.746114]\n",
      "epoch:36 step:28690 [D loss: 0.681671, acc.: 56.25%] [G loss: 0.758621]\n",
      "epoch:36 step:28691 [D loss: 0.750398, acc.: 40.62%] [G loss: 0.693341]\n",
      "epoch:36 step:28692 [D loss: 0.645576, acc.: 67.19%] [G loss: 0.743454]\n",
      "epoch:36 step:28693 [D loss: 0.712585, acc.: 46.09%] [G loss: 0.833364]\n",
      "epoch:36 step:28694 [D loss: 0.695944, acc.: 57.81%] [G loss: 0.848853]\n",
      "epoch:36 step:28695 [D loss: 0.696184, acc.: 46.88%] [G loss: 0.765015]\n",
      "epoch:36 step:28696 [D loss: 0.690469, acc.: 56.25%] [G loss: 0.850641]\n",
      "epoch:36 step:28697 [D loss: 0.667793, acc.: 59.38%] [G loss: 0.764737]\n",
      "epoch:36 step:28698 [D loss: 0.675684, acc.: 63.28%] [G loss: 0.770707]\n",
      "epoch:36 step:28699 [D loss: 0.641374, acc.: 67.97%] [G loss: 0.819502]\n",
      "epoch:36 step:28700 [D loss: 0.684607, acc.: 61.72%] [G loss: 0.839307]\n",
      "epoch:36 step:28701 [D loss: 0.654880, acc.: 66.41%] [G loss: 0.803811]\n",
      "epoch:36 step:28702 [D loss: 0.655812, acc.: 64.06%] [G loss: 0.895645]\n",
      "epoch:36 step:28703 [D loss: 0.620400, acc.: 72.66%] [G loss: 0.746817]\n",
      "epoch:36 step:28704 [D loss: 0.676327, acc.: 53.91%] [G loss: 0.834425]\n",
      "epoch:36 step:28705 [D loss: 0.639824, acc.: 66.41%] [G loss: 0.766577]\n",
      "epoch:36 step:28706 [D loss: 0.694072, acc.: 52.34%] [G loss: 0.844860]\n",
      "epoch:36 step:28707 [D loss: 0.695759, acc.: 52.34%] [G loss: 0.818203]\n",
      "epoch:36 step:28708 [D loss: 0.663370, acc.: 64.84%] [G loss: 0.778890]\n",
      "epoch:36 step:28709 [D loss: 0.647537, acc.: 61.72%] [G loss: 0.843275]\n",
      "epoch:36 step:28710 [D loss: 0.708649, acc.: 50.00%] [G loss: 0.707906]\n",
      "epoch:36 step:28711 [D loss: 0.663588, acc.: 62.50%] [G loss: 0.819947]\n",
      "epoch:36 step:28712 [D loss: 0.691833, acc.: 48.44%] [G loss: 0.853842]\n",
      "epoch:36 step:28713 [D loss: 0.688864, acc.: 50.00%] [G loss: 0.696785]\n",
      "epoch:36 step:28714 [D loss: 0.678991, acc.: 53.12%] [G loss: 0.715894]\n",
      "epoch:36 step:28715 [D loss: 0.675617, acc.: 51.56%] [G loss: 0.773941]\n",
      "epoch:36 step:28716 [D loss: 0.635041, acc.: 64.84%] [G loss: 0.868902]\n",
      "epoch:36 step:28717 [D loss: 0.701940, acc.: 45.31%] [G loss: 0.755961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28718 [D loss: 0.680831, acc.: 57.03%] [G loss: 0.803716]\n",
      "epoch:36 step:28719 [D loss: 0.722511, acc.: 46.09%] [G loss: 0.807660]\n",
      "epoch:36 step:28720 [D loss: 0.676284, acc.: 55.47%] [G loss: 0.690038]\n",
      "epoch:36 step:28721 [D loss: 0.695330, acc.: 47.66%] [G loss: 0.769622]\n",
      "epoch:36 step:28722 [D loss: 0.732500, acc.: 45.31%] [G loss: 0.782890]\n",
      "epoch:36 step:28723 [D loss: 0.627744, acc.: 69.53%] [G loss: 0.795521]\n",
      "epoch:36 step:28724 [D loss: 0.696395, acc.: 53.12%] [G loss: 0.749816]\n",
      "epoch:36 step:28725 [D loss: 0.682725, acc.: 56.25%] [G loss: 0.806198]\n",
      "epoch:36 step:28726 [D loss: 0.684575, acc.: 56.25%] [G loss: 0.824988]\n",
      "epoch:36 step:28727 [D loss: 0.713638, acc.: 49.22%] [G loss: 0.807276]\n",
      "epoch:36 step:28728 [D loss: 0.672397, acc.: 59.38%] [G loss: 0.759559]\n",
      "epoch:36 step:28729 [D loss: 0.675146, acc.: 59.38%] [G loss: 0.800143]\n",
      "epoch:36 step:28730 [D loss: 0.681088, acc.: 55.47%] [G loss: 0.867091]\n",
      "epoch:36 step:28731 [D loss: 0.652653, acc.: 62.50%] [G loss: 0.804648]\n",
      "epoch:36 step:28732 [D loss: 0.721850, acc.: 49.22%] [G loss: 0.851341]\n",
      "epoch:36 step:28733 [D loss: 0.689137, acc.: 52.34%] [G loss: 0.869521]\n",
      "epoch:36 step:28734 [D loss: 0.663082, acc.: 64.06%] [G loss: 0.800666]\n",
      "epoch:36 step:28735 [D loss: 0.680616, acc.: 56.25%] [G loss: 0.847271]\n",
      "epoch:36 step:28736 [D loss: 0.667737, acc.: 58.59%] [G loss: 0.801658]\n",
      "epoch:36 step:28737 [D loss: 0.667953, acc.: 62.50%] [G loss: 0.824600]\n",
      "epoch:36 step:28738 [D loss: 0.653348, acc.: 60.94%] [G loss: 0.833828]\n",
      "epoch:36 step:28739 [D loss: 0.719410, acc.: 47.66%] [G loss: 0.848402]\n",
      "epoch:36 step:28740 [D loss: 0.673154, acc.: 62.50%] [G loss: 0.847732]\n",
      "epoch:36 step:28741 [D loss: 0.696056, acc.: 54.69%] [G loss: 0.768087]\n",
      "epoch:36 step:28742 [D loss: 0.644950, acc.: 65.62%] [G loss: 0.765103]\n",
      "epoch:36 step:28743 [D loss: 0.740177, acc.: 43.75%] [G loss: 0.791774]\n",
      "epoch:36 step:28744 [D loss: 0.602184, acc.: 73.44%] [G loss: 0.828069]\n",
      "epoch:36 step:28745 [D loss: 0.684128, acc.: 53.12%] [G loss: 0.859557]\n",
      "epoch:36 step:28746 [D loss: 0.684497, acc.: 61.72%] [G loss: 0.788141]\n",
      "epoch:36 step:28747 [D loss: 0.703843, acc.: 54.69%] [G loss: 0.849638]\n",
      "epoch:36 step:28748 [D loss: 0.696215, acc.: 53.91%] [G loss: 0.731481]\n",
      "epoch:36 step:28749 [D loss: 0.691089, acc.: 54.69%] [G loss: 0.731150]\n",
      "epoch:36 step:28750 [D loss: 0.665664, acc.: 62.50%] [G loss: 0.851234]\n",
      "epoch:36 step:28751 [D loss: 0.677619, acc.: 56.25%] [G loss: 0.769297]\n",
      "epoch:36 step:28752 [D loss: 0.670494, acc.: 55.47%] [G loss: 0.815229]\n",
      "epoch:36 step:28753 [D loss: 0.700931, acc.: 52.34%] [G loss: 0.689261]\n",
      "epoch:36 step:28754 [D loss: 0.685870, acc.: 49.22%] [G loss: 0.773805]\n",
      "epoch:36 step:28755 [D loss: 0.727114, acc.: 47.66%] [G loss: 0.803427]\n",
      "epoch:36 step:28756 [D loss: 0.722023, acc.: 50.00%] [G loss: 0.734715]\n",
      "epoch:36 step:28757 [D loss: 0.681089, acc.: 58.59%] [G loss: 0.836037]\n",
      "epoch:36 step:28758 [D loss: 0.722498, acc.: 42.97%] [G loss: 0.734184]\n",
      "epoch:36 step:28759 [D loss: 0.737424, acc.: 41.41%] [G loss: 0.711013]\n",
      "epoch:36 step:28760 [D loss: 0.668065, acc.: 60.16%] [G loss: 0.766763]\n",
      "epoch:36 step:28761 [D loss: 0.700983, acc.: 54.69%] [G loss: 0.720300]\n",
      "epoch:36 step:28762 [D loss: 0.687137, acc.: 50.00%] [G loss: 0.781187]\n",
      "epoch:36 step:28763 [D loss: 0.701229, acc.: 46.88%] [G loss: 0.785455]\n",
      "epoch:36 step:28764 [D loss: 0.658456, acc.: 64.84%] [G loss: 0.780532]\n",
      "epoch:36 step:28765 [D loss: 0.655645, acc.: 63.28%] [G loss: 0.747133]\n",
      "epoch:36 step:28766 [D loss: 0.591531, acc.: 77.34%] [G loss: 0.846125]\n",
      "epoch:36 step:28767 [D loss: 0.657581, acc.: 60.94%] [G loss: 0.731675]\n",
      "epoch:36 step:28768 [D loss: 0.675529, acc.: 59.38%] [G loss: 0.744231]\n",
      "epoch:36 step:28769 [D loss: 0.696795, acc.: 51.56%] [G loss: 0.760024]\n",
      "epoch:36 step:28770 [D loss: 0.702975, acc.: 44.53%] [G loss: 0.734327]\n",
      "epoch:36 step:28771 [D loss: 0.723889, acc.: 44.53%] [G loss: 0.753578]\n",
      "epoch:36 step:28772 [D loss: 0.685397, acc.: 50.00%] [G loss: 0.785943]\n",
      "epoch:36 step:28773 [D loss: 0.674211, acc.: 57.81%] [G loss: 0.808766]\n",
      "epoch:36 step:28774 [D loss: 0.709738, acc.: 49.22%] [G loss: 0.763622]\n",
      "epoch:36 step:28775 [D loss: 0.668742, acc.: 57.81%] [G loss: 0.753109]\n",
      "epoch:36 step:28776 [D loss: 0.734726, acc.: 42.97%] [G loss: 0.751435]\n",
      "epoch:36 step:28777 [D loss: 0.709603, acc.: 48.44%] [G loss: 0.779796]\n",
      "epoch:36 step:28778 [D loss: 0.689986, acc.: 53.91%] [G loss: 0.779628]\n",
      "epoch:36 step:28779 [D loss: 0.681395, acc.: 60.16%] [G loss: 0.747719]\n",
      "epoch:36 step:28780 [D loss: 0.701108, acc.: 49.22%] [G loss: 0.779293]\n",
      "epoch:36 step:28781 [D loss: 0.742512, acc.: 44.53%] [G loss: 0.825727]\n",
      "epoch:36 step:28782 [D loss: 0.661988, acc.: 66.41%] [G loss: 0.841365]\n",
      "epoch:36 step:28783 [D loss: 0.735648, acc.: 42.19%] [G loss: 0.790843]\n",
      "epoch:36 step:28784 [D loss: 0.676757, acc.: 57.81%] [G loss: 0.758181]\n",
      "epoch:36 step:28785 [D loss: 0.699631, acc.: 56.25%] [G loss: 0.773480]\n",
      "epoch:36 step:28786 [D loss: 0.688503, acc.: 60.94%] [G loss: 0.834211]\n",
      "epoch:36 step:28787 [D loss: 0.717323, acc.: 50.00%] [G loss: 0.719260]\n",
      "epoch:36 step:28788 [D loss: 0.679469, acc.: 50.78%] [G loss: 0.854442]\n",
      "epoch:36 step:28789 [D loss: 0.620723, acc.: 71.88%] [G loss: 0.834987]\n",
      "epoch:36 step:28790 [D loss: 0.686722, acc.: 54.69%] [G loss: 0.936251]\n",
      "epoch:36 step:28791 [D loss: 0.653898, acc.: 65.62%] [G loss: 0.780537]\n",
      "epoch:36 step:28792 [D loss: 0.656629, acc.: 59.38%] [G loss: 0.794442]\n",
      "epoch:36 step:28793 [D loss: 0.665927, acc.: 61.72%] [G loss: 0.812846]\n",
      "epoch:36 step:28794 [D loss: 0.690910, acc.: 50.00%] [G loss: 0.773897]\n",
      "epoch:36 step:28795 [D loss: 0.630728, acc.: 69.53%] [G loss: 0.840974]\n",
      "epoch:36 step:28796 [D loss: 0.608172, acc.: 78.91%] [G loss: 0.767971]\n",
      "epoch:36 step:28797 [D loss: 0.603221, acc.: 74.22%] [G loss: 0.794126]\n",
      "epoch:36 step:28798 [D loss: 0.689071, acc.: 53.12%] [G loss: 0.785805]\n",
      "epoch:36 step:28799 [D loss: 0.661598, acc.: 64.84%] [G loss: 0.838593]\n",
      "epoch:36 step:28800 [D loss: 0.741196, acc.: 39.84%] [G loss: 0.850407]\n",
      "epoch:36 step:28801 [D loss: 0.722160, acc.: 47.66%] [G loss: 0.755223]\n",
      "epoch:36 step:28802 [D loss: 0.636255, acc.: 65.62%] [G loss: 0.759435]\n",
      "epoch:36 step:28803 [D loss: 0.696440, acc.: 56.25%] [G loss: 0.789004]\n",
      "epoch:36 step:28804 [D loss: 0.678505, acc.: 57.03%] [G loss: 0.791314]\n",
      "epoch:36 step:28805 [D loss: 0.667235, acc.: 59.38%] [G loss: 0.843684]\n",
      "epoch:36 step:28806 [D loss: 0.616766, acc.: 70.31%] [G loss: 0.753807]\n",
      "epoch:36 step:28807 [D loss: 0.661422, acc.: 59.38%] [G loss: 0.767833]\n",
      "epoch:36 step:28808 [D loss: 0.792439, acc.: 38.28%] [G loss: 0.675360]\n",
      "epoch:36 step:28809 [D loss: 0.696419, acc.: 53.12%] [G loss: 0.770230]\n",
      "epoch:36 step:28810 [D loss: 0.714126, acc.: 48.44%] [G loss: 0.760218]\n",
      "epoch:36 step:28811 [D loss: 0.683518, acc.: 57.03%] [G loss: 0.706086]\n",
      "epoch:36 step:28812 [D loss: 0.711082, acc.: 47.66%] [G loss: 0.790501]\n",
      "epoch:36 step:28813 [D loss: 0.667239, acc.: 57.81%] [G loss: 0.706176]\n",
      "epoch:36 step:28814 [D loss: 0.662020, acc.: 57.81%] [G loss: 0.685313]\n",
      "epoch:36 step:28815 [D loss: 0.687359, acc.: 60.94%] [G loss: 0.737397]\n",
      "epoch:36 step:28816 [D loss: 0.631199, acc.: 65.62%] [G loss: 0.766688]\n",
      "epoch:36 step:28817 [D loss: 0.672851, acc.: 55.47%] [G loss: 0.795996]\n",
      "epoch:36 step:28818 [D loss: 0.691280, acc.: 46.09%] [G loss: 0.738288]\n",
      "epoch:36 step:28819 [D loss: 0.684867, acc.: 58.59%] [G loss: 0.762728]\n",
      "epoch:36 step:28820 [D loss: 0.711487, acc.: 47.66%] [G loss: 0.768120]\n",
      "epoch:36 step:28821 [D loss: 0.688589, acc.: 56.25%] [G loss: 0.799832]\n",
      "epoch:36 step:28822 [D loss: 0.623079, acc.: 73.44%] [G loss: 0.806137]\n",
      "epoch:36 step:28823 [D loss: 0.772362, acc.: 39.06%] [G loss: 0.763216]\n",
      "epoch:36 step:28824 [D loss: 0.718390, acc.: 41.41%] [G loss: 0.779908]\n",
      "epoch:36 step:28825 [D loss: 0.689768, acc.: 46.88%] [G loss: 0.718900]\n",
      "epoch:36 step:28826 [D loss: 0.711150, acc.: 42.19%] [G loss: 0.765278]\n",
      "epoch:36 step:28827 [D loss: 0.730779, acc.: 48.44%] [G loss: 0.785917]\n",
      "epoch:36 step:28828 [D loss: 0.663078, acc.: 64.84%] [G loss: 0.890852]\n",
      "epoch:36 step:28829 [D loss: 0.686489, acc.: 49.22%] [G loss: 0.790024]\n",
      "epoch:36 step:28830 [D loss: 0.652420, acc.: 61.72%] [G loss: 0.782284]\n",
      "epoch:36 step:28831 [D loss: 0.704106, acc.: 49.22%] [G loss: 0.750345]\n",
      "epoch:36 step:28832 [D loss: 0.704834, acc.: 50.78%] [G loss: 0.850497]\n",
      "epoch:36 step:28833 [D loss: 0.712591, acc.: 51.56%] [G loss: 0.785655]\n",
      "epoch:36 step:28834 [D loss: 0.701209, acc.: 49.22%] [G loss: 0.807699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28835 [D loss: 0.689328, acc.: 58.59%] [G loss: 0.818575]\n",
      "epoch:36 step:28836 [D loss: 0.724840, acc.: 46.88%] [G loss: 0.756091]\n",
      "epoch:36 step:28837 [D loss: 0.727302, acc.: 50.78%] [G loss: 0.852051]\n",
      "epoch:36 step:28838 [D loss: 0.667044, acc.: 57.03%] [G loss: 0.754222]\n",
      "epoch:36 step:28839 [D loss: 0.753331, acc.: 42.97%] [G loss: 0.760974]\n",
      "epoch:36 step:28840 [D loss: 0.676326, acc.: 57.03%] [G loss: 0.732862]\n",
      "epoch:36 step:28841 [D loss: 0.650219, acc.: 67.19%] [G loss: 0.859267]\n",
      "epoch:36 step:28842 [D loss: 0.677545, acc.: 61.72%] [G loss: 0.849582]\n",
      "epoch:36 step:28843 [D loss: 0.688465, acc.: 57.03%] [G loss: 0.807678]\n",
      "epoch:36 step:28844 [D loss: 0.657020, acc.: 58.59%] [G loss: 0.756578]\n",
      "epoch:36 step:28845 [D loss: 0.684889, acc.: 55.47%] [G loss: 0.775794]\n",
      "epoch:36 step:28846 [D loss: 0.665064, acc.: 57.81%] [G loss: 0.770513]\n",
      "epoch:36 step:28847 [D loss: 0.653062, acc.: 58.59%] [G loss: 0.779161]\n",
      "epoch:36 step:28848 [D loss: 0.719746, acc.: 56.25%] [G loss: 0.722800]\n",
      "epoch:36 step:28849 [D loss: 0.669901, acc.: 59.38%] [G loss: 0.833566]\n",
      "epoch:36 step:28850 [D loss: 0.709684, acc.: 50.78%] [G loss: 0.787718]\n",
      "epoch:36 step:28851 [D loss: 0.718768, acc.: 48.44%] [G loss: 0.755520]\n",
      "epoch:36 step:28852 [D loss: 0.632421, acc.: 70.31%] [G loss: 0.782498]\n",
      "epoch:36 step:28853 [D loss: 0.674458, acc.: 52.34%] [G loss: 0.743402]\n",
      "epoch:36 step:28854 [D loss: 0.631000, acc.: 69.53%] [G loss: 0.780901]\n",
      "epoch:36 step:28855 [D loss: 0.706327, acc.: 52.34%] [G loss: 0.716321]\n",
      "epoch:36 step:28856 [D loss: 0.638513, acc.: 67.19%] [G loss: 0.768624]\n",
      "epoch:36 step:28857 [D loss: 0.631211, acc.: 67.19%] [G loss: 0.770779]\n",
      "epoch:36 step:28858 [D loss: 0.700886, acc.: 57.03%] [G loss: 0.811781]\n",
      "epoch:36 step:28859 [D loss: 0.650162, acc.: 66.41%] [G loss: 0.783143]\n",
      "epoch:36 step:28860 [D loss: 0.673092, acc.: 58.59%] [G loss: 0.856140]\n",
      "epoch:36 step:28861 [D loss: 0.673287, acc.: 60.16%] [G loss: 0.777172]\n",
      "epoch:36 step:28862 [D loss: 0.646555, acc.: 65.62%] [G loss: 0.763465]\n",
      "epoch:36 step:28863 [D loss: 0.691253, acc.: 53.91%] [G loss: 0.758099]\n",
      "epoch:36 step:28864 [D loss: 0.682794, acc.: 58.59%] [G loss: 0.794259]\n",
      "epoch:36 step:28865 [D loss: 0.697627, acc.: 50.78%] [G loss: 0.660100]\n",
      "epoch:36 step:28866 [D loss: 0.700026, acc.: 51.56%] [G loss: 0.708256]\n",
      "epoch:36 step:28867 [D loss: 0.688939, acc.: 52.34%] [G loss: 0.787423]\n",
      "epoch:36 step:28868 [D loss: 0.691056, acc.: 53.91%] [G loss: 0.760533]\n",
      "epoch:36 step:28869 [D loss: 0.624008, acc.: 65.62%] [G loss: 0.780721]\n",
      "epoch:36 step:28870 [D loss: 0.709279, acc.: 50.78%] [G loss: 0.811360]\n",
      "epoch:36 step:28871 [D loss: 0.673244, acc.: 60.16%] [G loss: 0.789808]\n",
      "epoch:36 step:28872 [D loss: 0.710537, acc.: 50.78%] [G loss: 0.853043]\n",
      "epoch:36 step:28873 [D loss: 0.637699, acc.: 65.62%] [G loss: 0.793335]\n",
      "epoch:36 step:28874 [D loss: 0.655553, acc.: 55.47%] [G loss: 0.826085]\n",
      "epoch:36 step:28875 [D loss: 0.651278, acc.: 60.94%] [G loss: 0.763346]\n",
      "epoch:36 step:28876 [D loss: 0.706588, acc.: 50.00%] [G loss: 0.742681]\n",
      "epoch:36 step:28877 [D loss: 0.727541, acc.: 43.75%] [G loss: 0.758588]\n",
      "epoch:36 step:28878 [D loss: 0.658708, acc.: 64.06%] [G loss: 0.743868]\n",
      "epoch:36 step:28879 [D loss: 0.688793, acc.: 52.34%] [G loss: 0.746092]\n",
      "epoch:36 step:28880 [D loss: 0.743784, acc.: 40.62%] [G loss: 0.732718]\n",
      "epoch:36 step:28881 [D loss: 0.658451, acc.: 63.28%] [G loss: 0.814763]\n",
      "epoch:36 step:28882 [D loss: 0.714205, acc.: 53.91%] [G loss: 0.784535]\n",
      "epoch:36 step:28883 [D loss: 0.714407, acc.: 46.09%] [G loss: 0.775272]\n",
      "epoch:36 step:28884 [D loss: 0.721485, acc.: 46.09%] [G loss: 0.786718]\n",
      "epoch:36 step:28885 [D loss: 0.657312, acc.: 66.41%] [G loss: 0.782602]\n",
      "epoch:36 step:28886 [D loss: 0.687562, acc.: 50.78%] [G loss: 0.817596]\n",
      "epoch:36 step:28887 [D loss: 0.703335, acc.: 46.09%] [G loss: 0.756888]\n",
      "epoch:36 step:28888 [D loss: 0.654295, acc.: 61.72%] [G loss: 0.790007]\n",
      "epoch:36 step:28889 [D loss: 0.641936, acc.: 64.06%] [G loss: 0.715198]\n",
      "epoch:36 step:28890 [D loss: 0.631027, acc.: 72.66%] [G loss: 0.766172]\n",
      "epoch:36 step:28891 [D loss: 0.657376, acc.: 62.50%] [G loss: 0.684062]\n",
      "epoch:36 step:28892 [D loss: 0.713917, acc.: 48.44%] [G loss: 0.774589]\n",
      "epoch:36 step:28893 [D loss: 0.668121, acc.: 55.47%] [G loss: 0.702513]\n",
      "epoch:36 step:28894 [D loss: 0.736787, acc.: 47.66%] [G loss: 0.726853]\n",
      "epoch:36 step:28895 [D loss: 0.694533, acc.: 56.25%] [G loss: 0.713118]\n",
      "epoch:36 step:28896 [D loss: 0.717659, acc.: 39.06%] [G loss: 0.762579]\n",
      "epoch:36 step:28897 [D loss: 0.690650, acc.: 51.56%] [G loss: 0.765738]\n",
      "epoch:37 step:28898 [D loss: 0.643211, acc.: 71.88%] [G loss: 0.811010]\n",
      "epoch:37 step:28899 [D loss: 0.665752, acc.: 64.06%] [G loss: 0.889118]\n",
      "epoch:37 step:28900 [D loss: 0.626731, acc.: 67.19%] [G loss: 0.799615]\n",
      "epoch:37 step:28901 [D loss: 0.676880, acc.: 52.34%] [G loss: 0.743552]\n",
      "epoch:37 step:28902 [D loss: 0.671208, acc.: 60.94%] [G loss: 0.907160]\n",
      "epoch:37 step:28903 [D loss: 0.681254, acc.: 53.91%] [G loss: 0.720822]\n",
      "epoch:37 step:28904 [D loss: 0.698130, acc.: 53.91%] [G loss: 0.782049]\n",
      "epoch:37 step:28905 [D loss: 0.647596, acc.: 68.75%] [G loss: 0.810025]\n",
      "epoch:37 step:28906 [D loss: 0.684487, acc.: 53.91%] [G loss: 0.739163]\n",
      "epoch:37 step:28907 [D loss: 0.697785, acc.: 57.03%] [G loss: 0.735207]\n",
      "epoch:37 step:28908 [D loss: 0.712695, acc.: 47.66%] [G loss: 0.712172]\n",
      "epoch:37 step:28909 [D loss: 0.713212, acc.: 44.53%] [G loss: 0.731615]\n",
      "epoch:37 step:28910 [D loss: 0.719539, acc.: 48.44%] [G loss: 0.818078]\n",
      "epoch:37 step:28911 [D loss: 0.642930, acc.: 66.41%] [G loss: 0.829963]\n",
      "epoch:37 step:28912 [D loss: 0.679340, acc.: 58.59%] [G loss: 0.791349]\n",
      "epoch:37 step:28913 [D loss: 0.699330, acc.: 50.00%] [G loss: 0.775691]\n",
      "epoch:37 step:28914 [D loss: 0.708455, acc.: 55.47%] [G loss: 0.791587]\n",
      "epoch:37 step:28915 [D loss: 0.652406, acc.: 56.25%] [G loss: 0.753949]\n",
      "epoch:37 step:28916 [D loss: 0.707729, acc.: 49.22%] [G loss: 0.802741]\n",
      "epoch:37 step:28917 [D loss: 0.647903, acc.: 64.84%] [G loss: 0.813242]\n",
      "epoch:37 step:28918 [D loss: 0.646825, acc.: 68.75%] [G loss: 0.852012]\n",
      "epoch:37 step:28919 [D loss: 0.686176, acc.: 51.56%] [G loss: 0.819576]\n",
      "epoch:37 step:28920 [D loss: 0.669012, acc.: 60.16%] [G loss: 0.781850]\n",
      "epoch:37 step:28921 [D loss: 0.660492, acc.: 61.72%] [G loss: 0.877030]\n",
      "epoch:37 step:28922 [D loss: 0.767424, acc.: 34.38%] [G loss: 0.707695]\n",
      "epoch:37 step:28923 [D loss: 0.696404, acc.: 50.78%] [G loss: 0.808402]\n",
      "epoch:37 step:28924 [D loss: 0.655641, acc.: 62.50%] [G loss: 0.717915]\n",
      "epoch:37 step:28925 [D loss: 0.704899, acc.: 50.78%] [G loss: 0.744726]\n",
      "epoch:37 step:28926 [D loss: 0.705804, acc.: 51.56%] [G loss: 0.679336]\n",
      "epoch:37 step:28927 [D loss: 0.679052, acc.: 52.34%] [G loss: 0.779260]\n",
      "epoch:37 step:28928 [D loss: 0.673428, acc.: 56.25%] [G loss: 0.728921]\n",
      "epoch:37 step:28929 [D loss: 0.705918, acc.: 50.78%] [G loss: 0.883411]\n",
      "epoch:37 step:28930 [D loss: 0.702552, acc.: 50.00%] [G loss: 0.815044]\n",
      "epoch:37 step:28931 [D loss: 0.635762, acc.: 71.88%] [G loss: 0.774511]\n",
      "epoch:37 step:28932 [D loss: 0.713682, acc.: 52.34%] [G loss: 0.755284]\n",
      "epoch:37 step:28933 [D loss: 0.694221, acc.: 51.56%] [G loss: 0.794011]\n",
      "epoch:37 step:28934 [D loss: 0.651007, acc.: 60.94%] [G loss: 0.813628]\n",
      "epoch:37 step:28935 [D loss: 0.680538, acc.: 55.47%] [G loss: 0.731912]\n",
      "epoch:37 step:28936 [D loss: 0.626985, acc.: 71.09%] [G loss: 0.764358]\n",
      "epoch:37 step:28937 [D loss: 0.643542, acc.: 69.53%] [G loss: 0.795646]\n",
      "epoch:37 step:28938 [D loss: 0.646393, acc.: 60.94%] [G loss: 0.778235]\n",
      "epoch:37 step:28939 [D loss: 0.687932, acc.: 57.81%] [G loss: 0.719772]\n",
      "epoch:37 step:28940 [D loss: 0.687939, acc.: 51.56%] [G loss: 0.765465]\n",
      "epoch:37 step:28941 [D loss: 0.691065, acc.: 50.78%] [G loss: 0.754131]\n",
      "epoch:37 step:28942 [D loss: 0.624790, acc.: 71.09%] [G loss: 0.651904]\n",
      "epoch:37 step:28943 [D loss: 0.671671, acc.: 60.16%] [G loss: 0.777108]\n",
      "epoch:37 step:28944 [D loss: 0.714564, acc.: 46.09%] [G loss: 0.764379]\n",
      "epoch:37 step:28945 [D loss: 0.736110, acc.: 48.44%] [G loss: 0.814433]\n",
      "epoch:37 step:28946 [D loss: 0.652135, acc.: 61.72%] [G loss: 0.833426]\n",
      "epoch:37 step:28947 [D loss: 0.645118, acc.: 62.50%] [G loss: 0.740352]\n",
      "epoch:37 step:28948 [D loss: 0.690541, acc.: 55.47%] [G loss: 0.817772]\n",
      "epoch:37 step:28949 [D loss: 0.605765, acc.: 75.00%] [G loss: 0.884988]\n",
      "epoch:37 step:28950 [D loss: 0.703746, acc.: 54.69%] [G loss: 0.909633]\n",
      "epoch:37 step:28951 [D loss: 0.690103, acc.: 50.00%] [G loss: 0.836617]\n",
      "epoch:37 step:28952 [D loss: 0.654873, acc.: 63.28%] [G loss: 0.800250]\n",
      "epoch:37 step:28953 [D loss: 0.707436, acc.: 46.09%] [G loss: 0.840504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:28954 [D loss: 0.654120, acc.: 66.41%] [G loss: 0.775786]\n",
      "epoch:37 step:28955 [D loss: 0.638394, acc.: 67.97%] [G loss: 0.870085]\n",
      "epoch:37 step:28956 [D loss: 0.727119, acc.: 47.66%] [G loss: 0.842752]\n",
      "epoch:37 step:28957 [D loss: 0.717526, acc.: 42.97%] [G loss: 0.835241]\n",
      "epoch:37 step:28958 [D loss: 0.718883, acc.: 44.53%] [G loss: 0.871636]\n",
      "epoch:37 step:28959 [D loss: 0.672543, acc.: 57.81%] [G loss: 0.775521]\n",
      "epoch:37 step:28960 [D loss: 0.626989, acc.: 65.62%] [G loss: 0.891676]\n",
      "epoch:37 step:28961 [D loss: 0.720828, acc.: 50.78%] [G loss: 0.831594]\n",
      "epoch:37 step:28962 [D loss: 0.737039, acc.: 43.75%] [G loss: 0.836942]\n",
      "epoch:37 step:28963 [D loss: 0.691440, acc.: 57.03%] [G loss: 0.868041]\n",
      "epoch:37 step:28964 [D loss: 0.644629, acc.: 67.19%] [G loss: 0.850866]\n",
      "epoch:37 step:28965 [D loss: 0.687730, acc.: 56.25%] [G loss: 0.811538]\n",
      "epoch:37 step:28966 [D loss: 0.705026, acc.: 48.44%] [G loss: 0.856227]\n",
      "epoch:37 step:28967 [D loss: 0.721110, acc.: 50.78%] [G loss: 0.745896]\n",
      "epoch:37 step:28968 [D loss: 0.688239, acc.: 57.03%] [G loss: 0.777258]\n",
      "epoch:37 step:28969 [D loss: 0.661886, acc.: 60.16%] [G loss: 0.777047]\n",
      "epoch:37 step:28970 [D loss: 0.718960, acc.: 48.44%] [G loss: 0.750236]\n",
      "epoch:37 step:28971 [D loss: 0.701605, acc.: 46.09%] [G loss: 0.770904]\n",
      "epoch:37 step:28972 [D loss: 0.723347, acc.: 47.66%] [G loss: 0.685161]\n",
      "epoch:37 step:28973 [D loss: 0.703394, acc.: 51.56%] [G loss: 0.745038]\n",
      "epoch:37 step:28974 [D loss: 0.645840, acc.: 67.19%] [G loss: 0.715738]\n",
      "epoch:37 step:28975 [D loss: 0.724320, acc.: 46.09%] [G loss: 0.725730]\n",
      "epoch:37 step:28976 [D loss: 0.661737, acc.: 61.72%] [G loss: 0.817865]\n",
      "epoch:37 step:28977 [D loss: 0.645558, acc.: 63.28%] [G loss: 0.822114]\n",
      "epoch:37 step:28978 [D loss: 0.759502, acc.: 41.41%] [G loss: 0.761898]\n",
      "epoch:37 step:28979 [D loss: 0.742181, acc.: 46.09%] [G loss: 0.782823]\n",
      "epoch:37 step:28980 [D loss: 0.769287, acc.: 33.59%] [G loss: 0.760768]\n",
      "epoch:37 step:28981 [D loss: 0.637122, acc.: 70.31%] [G loss: 0.854412]\n",
      "epoch:37 step:28982 [D loss: 0.676448, acc.: 59.38%] [G loss: 0.807543]\n",
      "epoch:37 step:28983 [D loss: 0.719294, acc.: 50.78%] [G loss: 0.754435]\n",
      "epoch:37 step:28984 [D loss: 0.677758, acc.: 60.16%] [G loss: 0.768369]\n",
      "epoch:37 step:28985 [D loss: 0.696325, acc.: 53.91%] [G loss: 0.786132]\n",
      "epoch:37 step:28986 [D loss: 0.660490, acc.: 57.81%] [G loss: 0.746064]\n",
      "epoch:37 step:28987 [D loss: 0.642393, acc.: 69.53%] [G loss: 0.728469]\n",
      "epoch:37 step:28988 [D loss: 0.669086, acc.: 60.16%] [G loss: 0.745328]\n",
      "epoch:37 step:28989 [D loss: 0.717587, acc.: 52.34%] [G loss: 0.839468]\n",
      "epoch:37 step:28990 [D loss: 0.726710, acc.: 43.75%] [G loss: 0.717689]\n",
      "epoch:37 step:28991 [D loss: 0.683879, acc.: 53.91%] [G loss: 0.727129]\n",
      "epoch:37 step:28992 [D loss: 0.692860, acc.: 56.25%] [G loss: 0.796058]\n",
      "epoch:37 step:28993 [D loss: 0.685956, acc.: 55.47%] [G loss: 0.763596]\n",
      "epoch:37 step:28994 [D loss: 0.685685, acc.: 54.69%] [G loss: 0.802424]\n",
      "epoch:37 step:28995 [D loss: 0.674151, acc.: 56.25%] [G loss: 0.890991]\n",
      "epoch:37 step:28996 [D loss: 0.653251, acc.: 64.06%] [G loss: 0.817121]\n",
      "epoch:37 step:28997 [D loss: 0.673527, acc.: 56.25%] [G loss: 0.865347]\n",
      "epoch:37 step:28998 [D loss: 0.724228, acc.: 48.44%] [G loss: 0.765436]\n",
      "epoch:37 step:28999 [D loss: 0.651228, acc.: 58.59%] [G loss: 0.761286]\n",
      "epoch:37 step:29000 [D loss: 0.710712, acc.: 43.75%] [G loss: 0.787827]\n",
      "epoch:37 step:29001 [D loss: 0.738171, acc.: 46.88%] [G loss: 0.810986]\n",
      "epoch:37 step:29002 [D loss: 0.631762, acc.: 66.41%] [G loss: 0.746460]\n",
      "epoch:37 step:29003 [D loss: 0.623421, acc.: 70.31%] [G loss: 0.869179]\n",
      "epoch:37 step:29004 [D loss: 0.676855, acc.: 57.81%] [G loss: 0.727698]\n",
      "epoch:37 step:29005 [D loss: 0.797270, acc.: 32.81%] [G loss: 0.706662]\n",
      "epoch:37 step:29006 [D loss: 0.701047, acc.: 52.34%] [G loss: 0.607021]\n",
      "epoch:37 step:29007 [D loss: 0.706072, acc.: 48.44%] [G loss: 0.751444]\n",
      "epoch:37 step:29008 [D loss: 0.640476, acc.: 61.72%] [G loss: 0.739515]\n",
      "epoch:37 step:29009 [D loss: 0.697084, acc.: 52.34%] [G loss: 0.717737]\n",
      "epoch:37 step:29010 [D loss: 0.637742, acc.: 68.75%] [G loss: 0.633604]\n",
      "epoch:37 step:29011 [D loss: 0.632218, acc.: 69.53%] [G loss: 0.740325]\n",
      "epoch:37 step:29012 [D loss: 0.738909, acc.: 35.16%] [G loss: 0.753433]\n",
      "epoch:37 step:29013 [D loss: 0.757822, acc.: 40.62%] [G loss: 0.713372]\n",
      "epoch:37 step:29014 [D loss: 0.666549, acc.: 56.25%] [G loss: 0.787513]\n",
      "epoch:37 step:29015 [D loss: 0.636523, acc.: 65.62%] [G loss: 0.757473]\n",
      "epoch:37 step:29016 [D loss: 0.683768, acc.: 56.25%] [G loss: 0.759163]\n",
      "epoch:37 step:29017 [D loss: 0.688207, acc.: 53.12%] [G loss: 0.806429]\n",
      "epoch:37 step:29018 [D loss: 0.677426, acc.: 53.91%] [G loss: 0.837403]\n",
      "epoch:37 step:29019 [D loss: 0.691303, acc.: 48.44%] [G loss: 0.769574]\n",
      "epoch:37 step:29020 [D loss: 0.659114, acc.: 57.81%] [G loss: 0.835619]\n",
      "epoch:37 step:29021 [D loss: 0.656000, acc.: 60.16%] [G loss: 0.715023]\n",
      "epoch:37 step:29022 [D loss: 0.699838, acc.: 53.91%] [G loss: 0.791063]\n",
      "epoch:37 step:29023 [D loss: 0.687382, acc.: 54.69%] [G loss: 0.724093]\n",
      "epoch:37 step:29024 [D loss: 0.658118, acc.: 60.94%] [G loss: 0.731526]\n",
      "epoch:37 step:29025 [D loss: 0.723168, acc.: 48.44%] [G loss: 0.714285]\n",
      "epoch:37 step:29026 [D loss: 0.699380, acc.: 48.44%] [G loss: 0.757481]\n",
      "epoch:37 step:29027 [D loss: 0.724336, acc.: 44.53%] [G loss: 0.707157]\n",
      "epoch:37 step:29028 [D loss: 0.610594, acc.: 74.22%] [G loss: 0.797718]\n",
      "epoch:37 step:29029 [D loss: 0.667009, acc.: 57.81%] [G loss: 0.815887]\n",
      "epoch:37 step:29030 [D loss: 0.612694, acc.: 76.56%] [G loss: 0.824577]\n",
      "epoch:37 step:29031 [D loss: 0.699862, acc.: 52.34%] [G loss: 0.803648]\n",
      "epoch:37 step:29032 [D loss: 0.705810, acc.: 51.56%] [G loss: 0.791448]\n",
      "epoch:37 step:29033 [D loss: 0.716111, acc.: 47.66%] [G loss: 0.851266]\n",
      "epoch:37 step:29034 [D loss: 0.765149, acc.: 35.16%] [G loss: 0.779863]\n",
      "epoch:37 step:29035 [D loss: 0.721088, acc.: 48.44%] [G loss: 0.820610]\n",
      "epoch:37 step:29036 [D loss: 0.696775, acc.: 52.34%] [G loss: 0.785846]\n",
      "epoch:37 step:29037 [D loss: 0.689646, acc.: 57.81%] [G loss: 0.733164]\n",
      "epoch:37 step:29038 [D loss: 0.668262, acc.: 58.59%] [G loss: 0.863602]\n",
      "epoch:37 step:29039 [D loss: 0.697787, acc.: 55.47%] [G loss: 0.808720]\n",
      "epoch:37 step:29040 [D loss: 0.712189, acc.: 47.66%] [G loss: 0.760483]\n",
      "epoch:37 step:29041 [D loss: 0.737473, acc.: 48.44%] [G loss: 0.813974]\n",
      "epoch:37 step:29042 [D loss: 0.697067, acc.: 53.12%] [G loss: 0.797343]\n",
      "epoch:37 step:29043 [D loss: 0.666291, acc.: 51.56%] [G loss: 0.794137]\n",
      "epoch:37 step:29044 [D loss: 0.631856, acc.: 67.19%] [G loss: 0.785481]\n",
      "epoch:37 step:29045 [D loss: 0.734125, acc.: 48.44%] [G loss: 0.774944]\n",
      "epoch:37 step:29046 [D loss: 0.718105, acc.: 51.56%] [G loss: 0.794247]\n",
      "epoch:37 step:29047 [D loss: 0.702406, acc.: 50.78%] [G loss: 0.783578]\n",
      "epoch:37 step:29048 [D loss: 0.650918, acc.: 63.28%] [G loss: 0.857317]\n",
      "epoch:37 step:29049 [D loss: 0.668675, acc.: 62.50%] [G loss: 0.764844]\n",
      "epoch:37 step:29050 [D loss: 0.678624, acc.: 54.69%] [G loss: 0.781615]\n",
      "epoch:37 step:29051 [D loss: 0.667006, acc.: 60.16%] [G loss: 0.734796]\n",
      "epoch:37 step:29052 [D loss: 0.655687, acc.: 61.72%] [G loss: 0.842664]\n",
      "epoch:37 step:29053 [D loss: 0.667110, acc.: 60.94%] [G loss: 0.862577]\n",
      "epoch:37 step:29054 [D loss: 0.688508, acc.: 60.94%] [G loss: 0.815568]\n",
      "epoch:37 step:29055 [D loss: 0.659539, acc.: 64.84%] [G loss: 0.798607]\n",
      "epoch:37 step:29056 [D loss: 0.705699, acc.: 46.09%] [G loss: 0.809647]\n",
      "epoch:37 step:29057 [D loss: 0.666732, acc.: 61.72%] [G loss: 0.772586]\n",
      "epoch:37 step:29058 [D loss: 0.681459, acc.: 52.34%] [G loss: 0.784876]\n",
      "epoch:37 step:29059 [D loss: 0.668403, acc.: 63.28%] [G loss: 0.753488]\n",
      "epoch:37 step:29060 [D loss: 0.638419, acc.: 71.88%] [G loss: 0.818140]\n",
      "epoch:37 step:29061 [D loss: 0.667523, acc.: 53.91%] [G loss: 0.824381]\n",
      "epoch:37 step:29062 [D loss: 0.653333, acc.: 66.41%] [G loss: 0.759188]\n",
      "epoch:37 step:29063 [D loss: 0.672728, acc.: 60.16%] [G loss: 0.821884]\n",
      "epoch:37 step:29064 [D loss: 0.622199, acc.: 66.41%] [G loss: 0.873446]\n",
      "epoch:37 step:29065 [D loss: 0.651707, acc.: 61.72%] [G loss: 0.842979]\n",
      "epoch:37 step:29066 [D loss: 0.649107, acc.: 60.16%] [G loss: 0.866091]\n",
      "epoch:37 step:29067 [D loss: 0.671000, acc.: 61.72%] [G loss: 0.789185]\n",
      "epoch:37 step:29068 [D loss: 0.723672, acc.: 43.75%] [G loss: 0.837455]\n",
      "epoch:37 step:29069 [D loss: 0.697266, acc.: 49.22%] [G loss: 0.784685]\n",
      "epoch:37 step:29070 [D loss: 0.691436, acc.: 51.56%] [G loss: 0.811473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29071 [D loss: 0.710472, acc.: 44.53%] [G loss: 0.782135]\n",
      "epoch:37 step:29072 [D loss: 0.668139, acc.: 67.97%] [G loss: 0.798441]\n",
      "epoch:37 step:29073 [D loss: 0.687717, acc.: 57.81%] [G loss: 0.787570]\n",
      "epoch:37 step:29074 [D loss: 0.656151, acc.: 67.19%] [G loss: 0.798259]\n",
      "epoch:37 step:29075 [D loss: 0.694054, acc.: 56.25%] [G loss: 0.807237]\n",
      "epoch:37 step:29076 [D loss: 0.649302, acc.: 63.28%] [G loss: 0.878029]\n",
      "epoch:37 step:29077 [D loss: 0.668229, acc.: 64.84%] [G loss: 0.789356]\n",
      "epoch:37 step:29078 [D loss: 0.674596, acc.: 60.94%] [G loss: 0.898825]\n",
      "epoch:37 step:29079 [D loss: 0.683887, acc.: 57.03%] [G loss: 0.842426]\n",
      "epoch:37 step:29080 [D loss: 0.759869, acc.: 32.81%] [G loss: 0.799854]\n",
      "epoch:37 step:29081 [D loss: 0.693918, acc.: 52.34%] [G loss: 0.802058]\n",
      "epoch:37 step:29082 [D loss: 0.562548, acc.: 81.25%] [G loss: 0.922921]\n",
      "epoch:37 step:29083 [D loss: 0.660933, acc.: 64.06%] [G loss: 0.801409]\n",
      "epoch:37 step:29084 [D loss: 0.742868, acc.: 50.78%] [G loss: 0.756822]\n",
      "epoch:37 step:29085 [D loss: 0.699880, acc.: 50.78%] [G loss: 0.799888]\n",
      "epoch:37 step:29086 [D loss: 0.665528, acc.: 62.50%] [G loss: 0.774195]\n",
      "epoch:37 step:29087 [D loss: 0.689593, acc.: 50.78%] [G loss: 0.865894]\n",
      "epoch:37 step:29088 [D loss: 0.694968, acc.: 51.56%] [G loss: 0.698905]\n",
      "epoch:37 step:29089 [D loss: 0.605312, acc.: 74.22%] [G loss: 0.872340]\n",
      "epoch:37 step:29090 [D loss: 0.687940, acc.: 57.03%] [G loss: 0.778846]\n",
      "epoch:37 step:29091 [D loss: 0.672376, acc.: 62.50%] [G loss: 0.770570]\n",
      "epoch:37 step:29092 [D loss: 0.664893, acc.: 61.72%] [G loss: 0.809948]\n",
      "epoch:37 step:29093 [D loss: 0.634756, acc.: 68.75%] [G loss: 0.900627]\n",
      "epoch:37 step:29094 [D loss: 0.655044, acc.: 63.28%] [G loss: 0.681680]\n",
      "epoch:37 step:29095 [D loss: 0.666373, acc.: 61.72%] [G loss: 0.750536]\n",
      "epoch:37 step:29096 [D loss: 0.768662, acc.: 42.19%] [G loss: 0.785995]\n",
      "epoch:37 step:29097 [D loss: 0.656018, acc.: 62.50%] [G loss: 0.769425]\n",
      "epoch:37 step:29098 [D loss: 0.629203, acc.: 71.88%] [G loss: 0.770054]\n",
      "epoch:37 step:29099 [D loss: 0.745954, acc.: 47.66%] [G loss: 0.718471]\n",
      "epoch:37 step:29100 [D loss: 0.751661, acc.: 43.75%] [G loss: 0.722406]\n",
      "epoch:37 step:29101 [D loss: 0.711179, acc.: 53.91%] [G loss: 0.825683]\n",
      "epoch:37 step:29102 [D loss: 0.725457, acc.: 45.31%] [G loss: 0.837202]\n",
      "epoch:37 step:29103 [D loss: 0.752764, acc.: 37.50%] [G loss: 0.748195]\n",
      "epoch:37 step:29104 [D loss: 0.728196, acc.: 42.97%] [G loss: 0.835562]\n",
      "epoch:37 step:29105 [D loss: 0.676918, acc.: 56.25%] [G loss: 0.799487]\n",
      "epoch:37 step:29106 [D loss: 0.667219, acc.: 60.94%] [G loss: 0.856049]\n",
      "epoch:37 step:29107 [D loss: 0.650721, acc.: 61.72%] [G loss: 0.709904]\n",
      "epoch:37 step:29108 [D loss: 0.689839, acc.: 57.03%] [G loss: 0.809202]\n",
      "epoch:37 step:29109 [D loss: 0.720508, acc.: 48.44%] [G loss: 0.785963]\n",
      "epoch:37 step:29110 [D loss: 0.746129, acc.: 35.16%] [G loss: 0.791331]\n",
      "epoch:37 step:29111 [D loss: 0.773182, acc.: 36.72%] [G loss: 0.714890]\n",
      "epoch:37 step:29112 [D loss: 0.646314, acc.: 60.16%] [G loss: 0.711126]\n",
      "epoch:37 step:29113 [D loss: 0.718801, acc.: 44.53%] [G loss: 0.752725]\n",
      "epoch:37 step:29114 [D loss: 0.712348, acc.: 46.88%] [G loss: 0.742106]\n",
      "epoch:37 step:29115 [D loss: 0.728046, acc.: 44.53%] [G loss: 0.763502]\n",
      "epoch:37 step:29116 [D loss: 0.717490, acc.: 44.53%] [G loss: 0.755252]\n",
      "epoch:37 step:29117 [D loss: 0.661465, acc.: 60.16%] [G loss: 0.810820]\n",
      "epoch:37 step:29118 [D loss: 0.701737, acc.: 50.78%] [G loss: 0.861847]\n",
      "epoch:37 step:29119 [D loss: 0.640349, acc.: 67.19%] [G loss: 0.777056]\n",
      "epoch:37 step:29120 [D loss: 0.667797, acc.: 58.59%] [G loss: 0.814138]\n",
      "epoch:37 step:29121 [D loss: 0.639980, acc.: 67.97%] [G loss: 0.739814]\n",
      "epoch:37 step:29122 [D loss: 0.642211, acc.: 67.97%] [G loss: 0.788686]\n",
      "epoch:37 step:29123 [D loss: 0.648724, acc.: 59.38%] [G loss: 0.829370]\n",
      "epoch:37 step:29124 [D loss: 0.650480, acc.: 56.25%] [G loss: 0.742818]\n",
      "epoch:37 step:29125 [D loss: 0.662329, acc.: 58.59%] [G loss: 0.795179]\n",
      "epoch:37 step:29126 [D loss: 0.713555, acc.: 46.09%] [G loss: 0.791449]\n",
      "epoch:37 step:29127 [D loss: 0.700696, acc.: 53.91%] [G loss: 0.826604]\n",
      "epoch:37 step:29128 [D loss: 0.608701, acc.: 71.88%] [G loss: 0.714418]\n",
      "epoch:37 step:29129 [D loss: 0.729691, acc.: 40.62%] [G loss: 0.792254]\n",
      "epoch:37 step:29130 [D loss: 0.671470, acc.: 60.16%] [G loss: 0.768658]\n",
      "epoch:37 step:29131 [D loss: 0.723347, acc.: 46.88%] [G loss: 0.757457]\n",
      "epoch:37 step:29132 [D loss: 0.721690, acc.: 49.22%] [G loss: 0.690156]\n",
      "epoch:37 step:29133 [D loss: 0.630171, acc.: 71.09%] [G loss: 0.666568]\n",
      "epoch:37 step:29134 [D loss: 0.740601, acc.: 46.09%] [G loss: 0.726326]\n",
      "epoch:37 step:29135 [D loss: 0.706904, acc.: 47.66%] [G loss: 0.754493]\n",
      "epoch:37 step:29136 [D loss: 0.734316, acc.: 47.66%] [G loss: 0.760447]\n",
      "epoch:37 step:29137 [D loss: 0.696103, acc.: 55.47%] [G loss: 0.802531]\n",
      "epoch:37 step:29138 [D loss: 0.649917, acc.: 63.28%] [G loss: 0.810664]\n",
      "epoch:37 step:29139 [D loss: 0.636754, acc.: 63.28%] [G loss: 0.784697]\n",
      "epoch:37 step:29140 [D loss: 0.744224, acc.: 42.19%] [G loss: 0.721298]\n",
      "epoch:37 step:29141 [D loss: 0.684202, acc.: 57.03%] [G loss: 0.678970]\n",
      "epoch:37 step:29142 [D loss: 0.727908, acc.: 39.06%] [G loss: 0.796101]\n",
      "epoch:37 step:29143 [D loss: 0.725813, acc.: 43.75%] [G loss: 0.767533]\n",
      "epoch:37 step:29144 [D loss: 0.643986, acc.: 69.53%] [G loss: 0.803354]\n",
      "epoch:37 step:29145 [D loss: 0.683177, acc.: 58.59%] [G loss: 0.708739]\n",
      "epoch:37 step:29146 [D loss: 0.605637, acc.: 74.22%] [G loss: 0.862511]\n",
      "epoch:37 step:29147 [D loss: 0.714963, acc.: 52.34%] [G loss: 0.747773]\n",
      "epoch:37 step:29148 [D loss: 0.620999, acc.: 68.75%] [G loss: 0.785078]\n",
      "epoch:37 step:29149 [D loss: 0.696677, acc.: 48.44%] [G loss: 0.803478]\n",
      "epoch:37 step:29150 [D loss: 0.699693, acc.: 51.56%] [G loss: 0.747366]\n",
      "epoch:37 step:29151 [D loss: 0.660867, acc.: 64.84%] [G loss: 0.770005]\n",
      "epoch:37 step:29152 [D loss: 0.677922, acc.: 59.38%] [G loss: 0.805667]\n",
      "epoch:37 step:29153 [D loss: 0.687285, acc.: 54.69%] [G loss: 0.772894]\n",
      "epoch:37 step:29154 [D loss: 0.670333, acc.: 57.81%] [G loss: 0.769737]\n",
      "epoch:37 step:29155 [D loss: 0.665188, acc.: 63.28%] [G loss: 0.884064]\n",
      "epoch:37 step:29156 [D loss: 0.648833, acc.: 57.81%] [G loss: 0.809883]\n",
      "epoch:37 step:29157 [D loss: 0.652470, acc.: 65.62%] [G loss: 0.771817]\n",
      "epoch:37 step:29158 [D loss: 0.683078, acc.: 60.16%] [G loss: 0.843346]\n",
      "epoch:37 step:29159 [D loss: 0.634643, acc.: 68.75%] [G loss: 0.920458]\n",
      "epoch:37 step:29160 [D loss: 0.660412, acc.: 60.16%] [G loss: 0.875709]\n",
      "epoch:37 step:29161 [D loss: 0.722698, acc.: 48.44%] [G loss: 0.854085]\n",
      "epoch:37 step:29162 [D loss: 0.664962, acc.: 60.94%] [G loss: 0.863517]\n",
      "epoch:37 step:29163 [D loss: 0.689562, acc.: 53.12%] [G loss: 0.866857]\n",
      "epoch:37 step:29164 [D loss: 0.710030, acc.: 45.31%] [G loss: 0.817474]\n",
      "epoch:37 step:29165 [D loss: 0.675462, acc.: 58.59%] [G loss: 0.823997]\n",
      "epoch:37 step:29166 [D loss: 0.653736, acc.: 70.31%] [G loss: 0.806953]\n",
      "epoch:37 step:29167 [D loss: 0.691420, acc.: 54.69%] [G loss: 0.725105]\n",
      "epoch:37 step:29168 [D loss: 0.715852, acc.: 50.78%] [G loss: 0.802640]\n",
      "epoch:37 step:29169 [D loss: 0.662373, acc.: 62.50%] [G loss: 0.806759]\n",
      "epoch:37 step:29170 [D loss: 0.700938, acc.: 49.22%] [G loss: 0.867178]\n",
      "epoch:37 step:29171 [D loss: 0.701781, acc.: 50.78%] [G loss: 0.808619]\n",
      "epoch:37 step:29172 [D loss: 0.672536, acc.: 58.59%] [G loss: 0.843546]\n",
      "epoch:37 step:29173 [D loss: 0.661750, acc.: 60.94%] [G loss: 0.766618]\n",
      "epoch:37 step:29174 [D loss: 0.746527, acc.: 46.88%] [G loss: 0.767140]\n",
      "epoch:37 step:29175 [D loss: 0.677664, acc.: 57.81%] [G loss: 0.850022]\n",
      "epoch:37 step:29176 [D loss: 0.672767, acc.: 60.94%] [G loss: 0.800317]\n",
      "epoch:37 step:29177 [D loss: 0.736891, acc.: 37.50%] [G loss: 0.742650]\n",
      "epoch:37 step:29178 [D loss: 0.671172, acc.: 60.16%] [G loss: 0.740984]\n",
      "epoch:37 step:29179 [D loss: 0.655806, acc.: 65.62%] [G loss: 0.793856]\n",
      "epoch:37 step:29180 [D loss: 0.608060, acc.: 71.88%] [G loss: 0.740463]\n",
      "epoch:37 step:29181 [D loss: 0.582323, acc.: 73.44%] [G loss: 0.770282]\n",
      "epoch:37 step:29182 [D loss: 0.642092, acc.: 64.84%] [G loss: 0.799120]\n",
      "epoch:37 step:29183 [D loss: 0.625282, acc.: 74.22%] [G loss: 0.770952]\n",
      "epoch:37 step:29184 [D loss: 0.703432, acc.: 49.22%] [G loss: 0.732559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29185 [D loss: 0.650345, acc.: 64.06%] [G loss: 0.803583]\n",
      "epoch:37 step:29186 [D loss: 0.659165, acc.: 58.59%] [G loss: 0.755535]\n",
      "epoch:37 step:29187 [D loss: 0.660951, acc.: 64.84%] [G loss: 0.814437]\n",
      "epoch:37 step:29188 [D loss: 0.773519, acc.: 37.50%] [G loss: 0.805815]\n",
      "epoch:37 step:29189 [D loss: 0.740529, acc.: 42.19%] [G loss: 0.779239]\n",
      "epoch:37 step:29190 [D loss: 0.690423, acc.: 55.47%] [G loss: 0.755123]\n",
      "epoch:37 step:29191 [D loss: 0.695286, acc.: 53.91%] [G loss: 0.704720]\n",
      "epoch:37 step:29192 [D loss: 0.694476, acc.: 52.34%] [G loss: 0.745167]\n",
      "epoch:37 step:29193 [D loss: 0.710288, acc.: 48.44%] [G loss: 0.754741]\n",
      "epoch:37 step:29194 [D loss: 0.704040, acc.: 58.59%] [G loss: 0.725159]\n",
      "epoch:37 step:29195 [D loss: 0.726216, acc.: 41.41%] [G loss: 0.787847]\n",
      "epoch:37 step:29196 [D loss: 0.692835, acc.: 52.34%] [G loss: 0.746716]\n",
      "epoch:37 step:29197 [D loss: 0.724257, acc.: 50.00%] [G loss: 0.776086]\n",
      "epoch:37 step:29198 [D loss: 0.725765, acc.: 44.53%] [G loss: 0.702098]\n",
      "epoch:37 step:29199 [D loss: 0.683017, acc.: 51.56%] [G loss: 0.838080]\n",
      "epoch:37 step:29200 [D loss: 0.662192, acc.: 62.50%] [G loss: 0.822715]\n",
      "epoch:37 step:29201 [D loss: 0.696303, acc.: 57.03%] [G loss: 0.800185]\n",
      "epoch:37 step:29202 [D loss: 0.694730, acc.: 49.22%] [G loss: 0.793975]\n",
      "epoch:37 step:29203 [D loss: 0.626367, acc.: 68.75%] [G loss: 0.737032]\n",
      "epoch:37 step:29204 [D loss: 0.642265, acc.: 67.19%] [G loss: 0.758986]\n",
      "epoch:37 step:29205 [D loss: 0.676691, acc.: 60.16%] [G loss: 0.783420]\n",
      "epoch:37 step:29206 [D loss: 0.656724, acc.: 62.50%] [G loss: 0.806037]\n",
      "epoch:37 step:29207 [D loss: 0.688251, acc.: 55.47%] [G loss: 0.844998]\n",
      "epoch:37 step:29208 [D loss: 0.605235, acc.: 65.62%] [G loss: 0.825332]\n",
      "epoch:37 step:29209 [D loss: 0.721535, acc.: 46.88%] [G loss: 0.723026]\n",
      "epoch:37 step:29210 [D loss: 0.657490, acc.: 60.94%] [G loss: 0.835052]\n",
      "epoch:37 step:29211 [D loss: 0.682851, acc.: 50.78%] [G loss: 0.659494]\n",
      "epoch:37 step:29212 [D loss: 0.629990, acc.: 67.19%] [G loss: 0.727826]\n",
      "epoch:37 step:29213 [D loss: 0.677306, acc.: 48.44%] [G loss: 0.636864]\n",
      "epoch:37 step:29214 [D loss: 0.764032, acc.: 45.31%] [G loss: 0.713621]\n",
      "epoch:37 step:29215 [D loss: 0.738773, acc.: 42.97%] [G loss: 0.680826]\n",
      "epoch:37 step:29216 [D loss: 0.744923, acc.: 38.28%] [G loss: 0.686451]\n",
      "epoch:37 step:29217 [D loss: 0.680441, acc.: 52.34%] [G loss: 0.716224]\n",
      "epoch:37 step:29218 [D loss: 0.659600, acc.: 65.62%] [G loss: 0.717489]\n",
      "epoch:37 step:29219 [D loss: 0.667773, acc.: 61.72%] [G loss: 0.847589]\n",
      "epoch:37 step:29220 [D loss: 0.714533, acc.: 52.34%] [G loss: 0.820508]\n",
      "epoch:37 step:29221 [D loss: 0.709058, acc.: 47.66%] [G loss: 0.714695]\n",
      "epoch:37 step:29222 [D loss: 0.736326, acc.: 46.09%] [G loss: 0.801833]\n",
      "epoch:37 step:29223 [D loss: 0.698443, acc.: 48.44%] [G loss: 0.798656]\n",
      "epoch:37 step:29224 [D loss: 0.741678, acc.: 42.97%] [G loss: 0.781036]\n",
      "epoch:37 step:29225 [D loss: 0.735603, acc.: 41.41%] [G loss: 0.726301]\n",
      "epoch:37 step:29226 [D loss: 0.680448, acc.: 60.16%] [G loss: 0.751246]\n",
      "epoch:37 step:29227 [D loss: 0.716914, acc.: 48.44%] [G loss: 0.719507]\n",
      "epoch:37 step:29228 [D loss: 0.676864, acc.: 55.47%] [G loss: 0.787515]\n",
      "epoch:37 step:29229 [D loss: 0.703584, acc.: 50.78%] [G loss: 0.761536]\n",
      "epoch:37 step:29230 [D loss: 0.646380, acc.: 61.72%] [G loss: 0.821068]\n",
      "epoch:37 step:29231 [D loss: 0.698620, acc.: 49.22%] [G loss: 0.744731]\n",
      "epoch:37 step:29232 [D loss: 0.647016, acc.: 62.50%] [G loss: 0.789710]\n",
      "epoch:37 step:29233 [D loss: 0.666913, acc.: 59.38%] [G loss: 0.795105]\n",
      "epoch:37 step:29234 [D loss: 0.682660, acc.: 54.69%] [G loss: 0.786652]\n",
      "epoch:37 step:29235 [D loss: 0.717614, acc.: 50.00%] [G loss: 0.696506]\n",
      "epoch:37 step:29236 [D loss: 0.678725, acc.: 57.03%] [G loss: 0.846911]\n",
      "epoch:37 step:29237 [D loss: 0.663918, acc.: 63.28%] [G loss: 0.673684]\n",
      "epoch:37 step:29238 [D loss: 0.688235, acc.: 53.91%] [G loss: 0.748321]\n",
      "epoch:37 step:29239 [D loss: 0.630337, acc.: 67.19%] [G loss: 0.758845]\n",
      "epoch:37 step:29240 [D loss: 0.688452, acc.: 51.56%] [G loss: 0.722611]\n",
      "epoch:37 step:29241 [D loss: 0.635283, acc.: 67.19%] [G loss: 0.752532]\n",
      "epoch:37 step:29242 [D loss: 0.633308, acc.: 68.75%] [G loss: 0.764514]\n",
      "epoch:37 step:29243 [D loss: 0.708632, acc.: 48.44%] [G loss: 0.691478]\n",
      "epoch:37 step:29244 [D loss: 0.716025, acc.: 47.66%] [G loss: 0.745107]\n",
      "epoch:37 step:29245 [D loss: 0.692459, acc.: 53.91%] [G loss: 0.825734]\n",
      "epoch:37 step:29246 [D loss: 0.668711, acc.: 61.72%] [G loss: 0.830211]\n",
      "epoch:37 step:29247 [D loss: 0.747278, acc.: 40.62%] [G loss: 0.842307]\n",
      "epoch:37 step:29248 [D loss: 0.716351, acc.: 47.66%] [G loss: 0.744285]\n",
      "epoch:37 step:29249 [D loss: 0.744677, acc.: 40.62%] [G loss: 0.760158]\n",
      "epoch:37 step:29250 [D loss: 0.642630, acc.: 64.84%] [G loss: 0.757502]\n",
      "epoch:37 step:29251 [D loss: 0.652595, acc.: 67.19%] [G loss: 0.757010]\n",
      "epoch:37 step:29252 [D loss: 0.702094, acc.: 50.78%] [G loss: 0.702834]\n",
      "epoch:37 step:29253 [D loss: 0.680569, acc.: 57.81%] [G loss: 0.770115]\n",
      "epoch:37 step:29254 [D loss: 0.684491, acc.: 54.69%] [G loss: 0.723508]\n",
      "epoch:37 step:29255 [D loss: 0.709819, acc.: 47.66%] [G loss: 0.756616]\n",
      "epoch:37 step:29256 [D loss: 0.670108, acc.: 61.72%] [G loss: 0.725017]\n",
      "epoch:37 step:29257 [D loss: 0.686453, acc.: 57.03%] [G loss: 0.746983]\n",
      "epoch:37 step:29258 [D loss: 0.667561, acc.: 59.38%] [G loss: 0.796107]\n",
      "epoch:37 step:29259 [D loss: 0.691275, acc.: 58.59%] [G loss: 0.845495]\n",
      "epoch:37 step:29260 [D loss: 0.728071, acc.: 51.56%] [G loss: 0.730565]\n",
      "epoch:37 step:29261 [D loss: 0.750769, acc.: 39.84%] [G loss: 0.792839]\n",
      "epoch:37 step:29262 [D loss: 0.646896, acc.: 64.06%] [G loss: 0.804098]\n",
      "epoch:37 step:29263 [D loss: 0.700223, acc.: 46.09%] [G loss: 0.818066]\n",
      "epoch:37 step:29264 [D loss: 0.685803, acc.: 57.03%] [G loss: 0.776273]\n",
      "epoch:37 step:29265 [D loss: 0.663438, acc.: 64.06%] [G loss: 0.860894]\n",
      "epoch:37 step:29266 [D loss: 0.761233, acc.: 32.81%] [G loss: 0.797593]\n",
      "epoch:37 step:29267 [D loss: 0.672059, acc.: 59.38%] [G loss: 0.780276]\n",
      "epoch:37 step:29268 [D loss: 0.638169, acc.: 63.28%] [G loss: 0.886203]\n",
      "epoch:37 step:29269 [D loss: 0.710128, acc.: 50.78%] [G loss: 0.862214]\n",
      "epoch:37 step:29270 [D loss: 0.680753, acc.: 53.12%] [G loss: 0.901161]\n",
      "epoch:37 step:29271 [D loss: 0.689899, acc.: 57.03%] [G loss: 0.823305]\n",
      "epoch:37 step:29272 [D loss: 0.753814, acc.: 41.41%] [G loss: 0.817751]\n",
      "epoch:37 step:29273 [D loss: 0.694770, acc.: 53.12%] [G loss: 0.762231]\n",
      "epoch:37 step:29274 [D loss: 0.657003, acc.: 64.84%] [G loss: 0.788972]\n",
      "epoch:37 step:29275 [D loss: 0.682871, acc.: 59.38%] [G loss: 0.748819]\n",
      "epoch:37 step:29276 [D loss: 0.686314, acc.: 56.25%] [G loss: 0.776375]\n",
      "epoch:37 step:29277 [D loss: 0.737967, acc.: 44.53%] [G loss: 0.876722]\n",
      "epoch:37 step:29278 [D loss: 0.613389, acc.: 74.22%] [G loss: 0.859464]\n",
      "epoch:37 step:29279 [D loss: 0.725054, acc.: 46.88%] [G loss: 0.834747]\n",
      "epoch:37 step:29280 [D loss: 0.700906, acc.: 51.56%] [G loss: 0.775506]\n",
      "epoch:37 step:29281 [D loss: 0.654136, acc.: 60.94%] [G loss: 0.749814]\n",
      "epoch:37 step:29282 [D loss: 0.704104, acc.: 48.44%] [G loss: 0.797544]\n",
      "epoch:37 step:29283 [D loss: 0.586661, acc.: 77.34%] [G loss: 0.928177]\n",
      "epoch:37 step:29284 [D loss: 0.717050, acc.: 43.75%] [G loss: 0.744930]\n",
      "epoch:37 step:29285 [D loss: 0.705615, acc.: 45.31%] [G loss: 0.840857]\n",
      "epoch:37 step:29286 [D loss: 0.766622, acc.: 35.94%] [G loss: 0.764705]\n",
      "epoch:37 step:29287 [D loss: 0.653847, acc.: 60.94%] [G loss: 0.822299]\n",
      "epoch:37 step:29288 [D loss: 0.775549, acc.: 34.38%] [G loss: 0.727050]\n",
      "epoch:37 step:29289 [D loss: 0.678129, acc.: 56.25%] [G loss: 0.706136]\n",
      "epoch:37 step:29290 [D loss: 0.694181, acc.: 55.47%] [G loss: 0.780908]\n",
      "epoch:37 step:29291 [D loss: 0.667564, acc.: 63.28%] [G loss: 0.706422]\n",
      "epoch:37 step:29292 [D loss: 0.753721, acc.: 44.53%] [G loss: 0.753827]\n",
      "epoch:37 step:29293 [D loss: 0.667563, acc.: 59.38%] [G loss: 0.789910]\n",
      "epoch:37 step:29294 [D loss: 0.707618, acc.: 50.00%] [G loss: 0.711182]\n",
      "epoch:37 step:29295 [D loss: 0.687643, acc.: 59.38%] [G loss: 0.728718]\n",
      "epoch:37 step:29296 [D loss: 0.638479, acc.: 68.75%] [G loss: 0.770007]\n",
      "epoch:37 step:29297 [D loss: 0.700976, acc.: 53.12%] [G loss: 0.811105]\n",
      "epoch:37 step:29298 [D loss: 0.643908, acc.: 65.62%] [G loss: 0.774618]\n",
      "epoch:37 step:29299 [D loss: 0.612948, acc.: 72.66%] [G loss: 0.879308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29300 [D loss: 0.643716, acc.: 64.06%] [G loss: 0.752452]\n",
      "epoch:37 step:29301 [D loss: 0.611912, acc.: 72.66%] [G loss: 0.821482]\n",
      "epoch:37 step:29302 [D loss: 0.698381, acc.: 54.69%] [G loss: 0.908706]\n",
      "epoch:37 step:29303 [D loss: 0.646645, acc.: 64.84%] [G loss: 0.790145]\n",
      "epoch:37 step:29304 [D loss: 0.694523, acc.: 57.81%] [G loss: 0.760656]\n",
      "epoch:37 step:29305 [D loss: 0.689352, acc.: 52.34%] [G loss: 0.752605]\n",
      "epoch:37 step:29306 [D loss: 0.682537, acc.: 55.47%] [G loss: 0.767167]\n",
      "epoch:37 step:29307 [D loss: 0.721749, acc.: 51.56%] [G loss: 0.780245]\n",
      "epoch:37 step:29308 [D loss: 0.776350, acc.: 36.72%] [G loss: 0.765624]\n",
      "epoch:37 step:29309 [D loss: 0.618088, acc.: 66.41%] [G loss: 0.797085]\n",
      "epoch:37 step:29310 [D loss: 0.731796, acc.: 47.66%] [G loss: 0.756431]\n",
      "epoch:37 step:29311 [D loss: 0.704477, acc.: 47.66%] [G loss: 0.822669]\n",
      "epoch:37 step:29312 [D loss: 0.609644, acc.: 73.44%] [G loss: 0.805843]\n",
      "epoch:37 step:29313 [D loss: 0.608120, acc.: 72.66%] [G loss: 0.772131]\n",
      "epoch:37 step:29314 [D loss: 0.649885, acc.: 64.06%] [G loss: 0.756769]\n",
      "epoch:37 step:29315 [D loss: 0.749809, acc.: 36.72%] [G loss: 0.659131]\n",
      "epoch:37 step:29316 [D loss: 0.700426, acc.: 48.44%] [G loss: 0.724180]\n",
      "epoch:37 step:29317 [D loss: 0.694547, acc.: 56.25%] [G loss: 0.744902]\n",
      "epoch:37 step:29318 [D loss: 0.687290, acc.: 57.81%] [G loss: 0.747985]\n",
      "epoch:37 step:29319 [D loss: 0.700365, acc.: 51.56%] [G loss: 0.837416]\n",
      "epoch:37 step:29320 [D loss: 0.704979, acc.: 49.22%] [G loss: 0.788265]\n",
      "epoch:37 step:29321 [D loss: 0.765247, acc.: 39.06%] [G loss: 0.755658]\n",
      "epoch:37 step:29322 [D loss: 0.661336, acc.: 60.16%] [G loss: 0.763368]\n",
      "epoch:37 step:29323 [D loss: 0.697473, acc.: 50.00%] [G loss: 0.852704]\n",
      "epoch:37 step:29324 [D loss: 0.639894, acc.: 65.62%] [G loss: 0.834547]\n",
      "epoch:37 step:29325 [D loss: 0.723308, acc.: 42.97%] [G loss: 0.745778]\n",
      "epoch:37 step:29326 [D loss: 0.710360, acc.: 50.00%] [G loss: 0.693731]\n",
      "epoch:37 step:29327 [D loss: 0.675233, acc.: 56.25%] [G loss: 0.872159]\n",
      "epoch:37 step:29328 [D loss: 0.754373, acc.: 39.06%] [G loss: 0.749795]\n",
      "epoch:37 step:29329 [D loss: 0.715742, acc.: 42.19%] [G loss: 0.732848]\n",
      "epoch:37 step:29330 [D loss: 0.670624, acc.: 61.72%] [G loss: 0.725939]\n",
      "epoch:37 step:29331 [D loss: 0.658527, acc.: 60.94%] [G loss: 0.760411]\n",
      "epoch:37 step:29332 [D loss: 0.683862, acc.: 53.12%] [G loss: 0.782431]\n",
      "epoch:37 step:29333 [D loss: 0.701257, acc.: 57.03%] [G loss: 0.812426]\n",
      "epoch:37 step:29334 [D loss: 0.711944, acc.: 51.56%] [G loss: 0.788673]\n",
      "epoch:37 step:29335 [D loss: 0.657516, acc.: 59.38%] [G loss: 0.811386]\n",
      "epoch:37 step:29336 [D loss: 0.686050, acc.: 59.38%] [G loss: 0.815301]\n",
      "epoch:37 step:29337 [D loss: 0.652666, acc.: 57.81%] [G loss: 0.770798]\n",
      "epoch:37 step:29338 [D loss: 0.728403, acc.: 43.75%] [G loss: 0.739767]\n",
      "epoch:37 step:29339 [D loss: 0.687114, acc.: 48.44%] [G loss: 0.751448]\n",
      "epoch:37 step:29340 [D loss: 0.669004, acc.: 52.34%] [G loss: 0.687511]\n",
      "epoch:37 step:29341 [D loss: 0.647117, acc.: 64.06%] [G loss: 0.808232]\n",
      "epoch:37 step:29342 [D loss: 0.691645, acc.: 56.25%] [G loss: 0.851808]\n",
      "epoch:37 step:29343 [D loss: 0.726110, acc.: 50.00%] [G loss: 0.715473]\n",
      "epoch:37 step:29344 [D loss: 0.693038, acc.: 53.91%] [G loss: 0.817888]\n",
      "epoch:37 step:29345 [D loss: 0.648450, acc.: 67.97%] [G loss: 0.790587]\n",
      "epoch:37 step:29346 [D loss: 0.593439, acc.: 71.88%] [G loss: 0.818979]\n",
      "epoch:37 step:29347 [D loss: 0.692169, acc.: 56.25%] [G loss: 0.728010]\n",
      "epoch:37 step:29348 [D loss: 0.669666, acc.: 60.16%] [G loss: 0.724697]\n",
      "epoch:37 step:29349 [D loss: 0.631755, acc.: 71.88%] [G loss: 0.853656]\n",
      "epoch:37 step:29350 [D loss: 0.678939, acc.: 53.91%] [G loss: 0.764677]\n",
      "epoch:37 step:29351 [D loss: 0.702550, acc.: 49.22%] [G loss: 0.776750]\n",
      "epoch:37 step:29352 [D loss: 0.737011, acc.: 45.31%] [G loss: 0.699178]\n",
      "epoch:37 step:29353 [D loss: 0.658427, acc.: 64.06%] [G loss: 0.772194]\n",
      "epoch:37 step:29354 [D loss: 0.698784, acc.: 52.34%] [G loss: 0.778652]\n",
      "epoch:37 step:29355 [D loss: 0.715258, acc.: 50.00%] [G loss: 0.737048]\n",
      "epoch:37 step:29356 [D loss: 0.724994, acc.: 50.78%] [G loss: 0.747007]\n",
      "epoch:37 step:29357 [D loss: 0.685353, acc.: 53.91%] [G loss: 0.765025]\n",
      "epoch:37 step:29358 [D loss: 0.662745, acc.: 60.94%] [G loss: 0.773290]\n",
      "epoch:37 step:29359 [D loss: 0.644576, acc.: 62.50%] [G loss: 0.858608]\n",
      "epoch:37 step:29360 [D loss: 0.661327, acc.: 63.28%] [G loss: 0.734179]\n",
      "epoch:37 step:29361 [D loss: 0.675051, acc.: 62.50%] [G loss: 0.747844]\n",
      "epoch:37 step:29362 [D loss: 0.712314, acc.: 42.97%] [G loss: 0.784826]\n",
      "epoch:37 step:29363 [D loss: 0.607959, acc.: 71.09%] [G loss: 0.782396]\n",
      "epoch:37 step:29364 [D loss: 0.745455, acc.: 45.31%] [G loss: 0.779818]\n",
      "epoch:37 step:29365 [D loss: 0.721804, acc.: 47.66%] [G loss: 0.759048]\n",
      "epoch:37 step:29366 [D loss: 0.699164, acc.: 51.56%] [G loss: 0.764614]\n",
      "epoch:37 step:29367 [D loss: 0.714344, acc.: 49.22%] [G loss: 0.775612]\n",
      "epoch:37 step:29368 [D loss: 0.666933, acc.: 63.28%] [G loss: 0.787822]\n",
      "epoch:37 step:29369 [D loss: 0.682908, acc.: 56.25%] [G loss: 0.898493]\n",
      "epoch:37 step:29370 [D loss: 0.706778, acc.: 53.12%] [G loss: 0.734695]\n",
      "epoch:37 step:29371 [D loss: 0.715543, acc.: 43.75%] [G loss: 0.774770]\n",
      "epoch:37 step:29372 [D loss: 0.646210, acc.: 67.97%] [G loss: 0.661396]\n",
      "epoch:37 step:29373 [D loss: 0.673601, acc.: 59.38%] [G loss: 0.768166]\n",
      "epoch:37 step:29374 [D loss: 0.644077, acc.: 65.62%] [G loss: 0.854055]\n",
      "epoch:37 step:29375 [D loss: 0.688798, acc.: 50.78%] [G loss: 0.742211]\n",
      "epoch:37 step:29376 [D loss: 0.700811, acc.: 53.12%] [G loss: 0.818206]\n",
      "epoch:37 step:29377 [D loss: 0.676275, acc.: 57.03%] [G loss: 0.784312]\n",
      "epoch:37 step:29378 [D loss: 0.755788, acc.: 39.84%] [G loss: 0.782601]\n",
      "epoch:37 step:29379 [D loss: 0.762519, acc.: 39.06%] [G loss: 0.740222]\n",
      "epoch:37 step:29380 [D loss: 0.654997, acc.: 62.50%] [G loss: 0.881533]\n",
      "epoch:37 step:29381 [D loss: 0.712717, acc.: 50.00%] [G loss: 0.782055]\n",
      "epoch:37 step:29382 [D loss: 0.594355, acc.: 73.44%] [G loss: 0.859401]\n",
      "epoch:37 step:29383 [D loss: 0.660521, acc.: 59.38%] [G loss: 0.706622]\n",
      "epoch:37 step:29384 [D loss: 0.715860, acc.: 53.12%] [G loss: 0.735992]\n",
      "epoch:37 step:29385 [D loss: 0.669130, acc.: 60.16%] [G loss: 0.790568]\n",
      "epoch:37 step:29386 [D loss: 0.697512, acc.: 54.69%] [G loss: 0.727471]\n",
      "epoch:37 step:29387 [D loss: 0.640720, acc.: 65.62%] [G loss: 0.755254]\n",
      "epoch:37 step:29388 [D loss: 0.701342, acc.: 54.69%] [G loss: 0.752318]\n",
      "epoch:37 step:29389 [D loss: 0.680132, acc.: 58.59%] [G loss: 0.702528]\n",
      "epoch:37 step:29390 [D loss: 0.695353, acc.: 51.56%] [G loss: 0.765112]\n",
      "epoch:37 step:29391 [D loss: 0.674425, acc.: 57.81%] [G loss: 0.794248]\n",
      "epoch:37 step:29392 [D loss: 0.707942, acc.: 50.00%] [G loss: 0.923405]\n",
      "epoch:37 step:29393 [D loss: 0.713996, acc.: 51.56%] [G loss: 0.771698]\n",
      "epoch:37 step:29394 [D loss: 0.703425, acc.: 46.88%] [G loss: 0.913551]\n",
      "epoch:37 step:29395 [D loss: 0.690800, acc.: 55.47%] [G loss: 0.796424]\n",
      "epoch:37 step:29396 [D loss: 0.656019, acc.: 59.38%] [G loss: 0.830768]\n",
      "epoch:37 step:29397 [D loss: 0.667617, acc.: 60.94%] [G loss: 0.760471]\n",
      "epoch:37 step:29398 [D loss: 0.663035, acc.: 59.38%] [G loss: 0.727484]\n",
      "epoch:37 step:29399 [D loss: 0.714266, acc.: 45.31%] [G loss: 0.815596]\n",
      "epoch:37 step:29400 [D loss: 0.671670, acc.: 59.38%] [G loss: 0.910500]\n",
      "epoch:37 step:29401 [D loss: 0.649258, acc.: 67.97%] [G loss: 0.822031]\n",
      "epoch:37 step:29402 [D loss: 0.692970, acc.: 57.81%] [G loss: 0.808903]\n",
      "epoch:37 step:29403 [D loss: 0.691547, acc.: 54.69%] [G loss: 0.817431]\n",
      "epoch:37 step:29404 [D loss: 0.659969, acc.: 63.28%] [G loss: 0.849837]\n",
      "epoch:37 step:29405 [D loss: 0.717255, acc.: 46.88%] [G loss: 0.782032]\n",
      "epoch:37 step:29406 [D loss: 0.715945, acc.: 46.09%] [G loss: 0.807733]\n",
      "epoch:37 step:29407 [D loss: 0.705877, acc.: 50.78%] [G loss: 0.842576]\n",
      "epoch:37 step:29408 [D loss: 0.688997, acc.: 47.66%] [G loss: 0.915882]\n",
      "epoch:37 step:29409 [D loss: 0.695473, acc.: 53.91%] [G loss: 0.779054]\n",
      "epoch:37 step:29410 [D loss: 0.685463, acc.: 55.47%] [G loss: 0.780562]\n",
      "epoch:37 step:29411 [D loss: 0.761823, acc.: 45.31%] [G loss: 0.679808]\n",
      "epoch:37 step:29412 [D loss: 0.679026, acc.: 53.12%] [G loss: 0.701736]\n",
      "epoch:37 step:29413 [D loss: 0.674262, acc.: 58.59%] [G loss: 0.697717]\n",
      "epoch:37 step:29414 [D loss: 0.677444, acc.: 64.84%] [G loss: 0.747970]\n",
      "epoch:37 step:29415 [D loss: 0.681264, acc.: 53.12%] [G loss: 0.714603]\n",
      "epoch:37 step:29416 [D loss: 0.757630, acc.: 36.72%] [G loss: 0.764109]\n",
      "epoch:37 step:29417 [D loss: 0.630742, acc.: 67.97%] [G loss: 0.762293]\n",
      "epoch:37 step:29418 [D loss: 0.672360, acc.: 56.25%] [G loss: 0.790841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29419 [D loss: 0.698997, acc.: 51.56%] [G loss: 0.757521]\n",
      "epoch:37 step:29420 [D loss: 0.657343, acc.: 60.94%] [G loss: 0.735185]\n",
      "epoch:37 step:29421 [D loss: 0.737624, acc.: 40.62%] [G loss: 0.750493]\n",
      "epoch:37 step:29422 [D loss: 0.675186, acc.: 58.59%] [G loss: 0.809038]\n",
      "epoch:37 step:29423 [D loss: 0.743952, acc.: 46.09%] [G loss: 0.731613]\n",
      "epoch:37 step:29424 [D loss: 0.715562, acc.: 46.88%] [G loss: 0.767122]\n",
      "epoch:37 step:29425 [D loss: 0.682277, acc.: 55.47%] [G loss: 0.756352]\n",
      "epoch:37 step:29426 [D loss: 0.666109, acc.: 58.59%] [G loss: 0.737229]\n",
      "epoch:37 step:29427 [D loss: 0.660098, acc.: 64.06%] [G loss: 0.806909]\n",
      "epoch:37 step:29428 [D loss: 0.643973, acc.: 67.19%] [G loss: 0.786644]\n",
      "epoch:37 step:29429 [D loss: 0.640066, acc.: 66.41%] [G loss: 0.813096]\n",
      "epoch:37 step:29430 [D loss: 0.687301, acc.: 51.56%] [G loss: 0.809149]\n",
      "epoch:37 step:29431 [D loss: 0.724304, acc.: 42.97%] [G loss: 0.826218]\n",
      "epoch:37 step:29432 [D loss: 0.632156, acc.: 66.41%] [G loss: 0.786646]\n",
      "epoch:37 step:29433 [D loss: 0.648052, acc.: 66.41%] [G loss: 0.834961]\n",
      "epoch:37 step:29434 [D loss: 0.724627, acc.: 50.00%] [G loss: 0.862235]\n",
      "epoch:37 step:29435 [D loss: 0.731190, acc.: 41.41%] [G loss: 0.755433]\n",
      "epoch:37 step:29436 [D loss: 0.642448, acc.: 66.41%] [G loss: 0.820135]\n",
      "epoch:37 step:29437 [D loss: 0.698916, acc.: 52.34%] [G loss: 0.850400]\n",
      "epoch:37 step:29438 [D loss: 0.629156, acc.: 67.19%] [G loss: 0.774347]\n",
      "epoch:37 step:29439 [D loss: 0.689454, acc.: 60.94%] [G loss: 0.755685]\n",
      "epoch:37 step:29440 [D loss: 0.720161, acc.: 51.56%] [G loss: 0.723244]\n",
      "epoch:37 step:29441 [D loss: 0.644307, acc.: 66.41%] [G loss: 0.742539]\n",
      "epoch:37 step:29442 [D loss: 0.676031, acc.: 57.03%] [G loss: 0.801191]\n",
      "epoch:37 step:29443 [D loss: 0.727053, acc.: 46.88%] [G loss: 0.783387]\n",
      "epoch:37 step:29444 [D loss: 0.676482, acc.: 60.16%] [G loss: 0.830491]\n",
      "epoch:37 step:29445 [D loss: 0.691958, acc.: 50.78%] [G loss: 0.765616]\n",
      "epoch:37 step:29446 [D loss: 0.607526, acc.: 68.75%] [G loss: 0.838328]\n",
      "epoch:37 step:29447 [D loss: 0.707682, acc.: 48.44%] [G loss: 0.742963]\n",
      "epoch:37 step:29448 [D loss: 0.644944, acc.: 67.19%] [G loss: 0.782080]\n",
      "epoch:37 step:29449 [D loss: 0.712831, acc.: 53.12%] [G loss: 0.756644]\n",
      "epoch:37 step:29450 [D loss: 0.668254, acc.: 60.16%] [G loss: 0.762413]\n",
      "epoch:37 step:29451 [D loss: 0.675594, acc.: 57.81%] [G loss: 0.720148]\n",
      "epoch:37 step:29452 [D loss: 0.657415, acc.: 64.06%] [G loss: 0.764230]\n",
      "epoch:37 step:29453 [D loss: 0.734309, acc.: 43.75%] [G loss: 0.748825]\n",
      "epoch:37 step:29454 [D loss: 0.646255, acc.: 64.06%] [G loss: 0.835227]\n",
      "epoch:37 step:29455 [D loss: 0.689580, acc.: 50.00%] [G loss: 0.866086]\n",
      "epoch:37 step:29456 [D loss: 0.694278, acc.: 51.56%] [G loss: 0.839243]\n",
      "epoch:37 step:29457 [D loss: 0.730291, acc.: 43.75%] [G loss: 0.778297]\n",
      "epoch:37 step:29458 [D loss: 0.652113, acc.: 63.28%] [G loss: 0.803179]\n",
      "epoch:37 step:29459 [D loss: 0.684571, acc.: 48.44%] [G loss: 0.786173]\n",
      "epoch:37 step:29460 [D loss: 0.642879, acc.: 65.62%] [G loss: 0.831703]\n",
      "epoch:37 step:29461 [D loss: 0.655614, acc.: 67.97%] [G loss: 0.768068]\n",
      "epoch:37 step:29462 [D loss: 0.707197, acc.: 53.91%] [G loss: 0.812751]\n",
      "epoch:37 step:29463 [D loss: 0.659195, acc.: 60.16%] [G loss: 0.886462]\n",
      "epoch:37 step:29464 [D loss: 0.652959, acc.: 64.06%] [G loss: 0.819370]\n",
      "epoch:37 step:29465 [D loss: 0.686231, acc.: 57.81%] [G loss: 0.699838]\n",
      "epoch:37 step:29466 [D loss: 0.639578, acc.: 67.97%] [G loss: 0.837574]\n",
      "epoch:37 step:29467 [D loss: 0.699489, acc.: 56.25%] [G loss: 0.757502]\n",
      "epoch:37 step:29468 [D loss: 0.731975, acc.: 39.06%] [G loss: 0.815178]\n",
      "epoch:37 step:29469 [D loss: 0.675939, acc.: 59.38%] [G loss: 0.751731]\n",
      "epoch:37 step:29470 [D loss: 0.689502, acc.: 54.69%] [G loss: 0.728539]\n",
      "epoch:37 step:29471 [D loss: 0.724094, acc.: 42.97%] [G loss: 0.712942]\n",
      "epoch:37 step:29472 [D loss: 0.661859, acc.: 57.03%] [G loss: 0.773552]\n",
      "epoch:37 step:29473 [D loss: 0.652895, acc.: 61.72%] [G loss: 0.755538]\n",
      "epoch:37 step:29474 [D loss: 0.687459, acc.: 52.34%] [G loss: 0.809472]\n",
      "epoch:37 step:29475 [D loss: 0.632698, acc.: 73.44%] [G loss: 0.750875]\n",
      "epoch:37 step:29476 [D loss: 0.685161, acc.: 57.81%] [G loss: 0.895681]\n",
      "epoch:37 step:29477 [D loss: 0.674673, acc.: 53.12%] [G loss: 0.840102]\n",
      "epoch:37 step:29478 [D loss: 0.704494, acc.: 51.56%] [G loss: 0.690564]\n",
      "epoch:37 step:29479 [D loss: 0.660164, acc.: 59.38%] [G loss: 0.805569]\n",
      "epoch:37 step:29480 [D loss: 0.686771, acc.: 58.59%] [G loss: 0.768893]\n",
      "epoch:37 step:29481 [D loss: 0.703039, acc.: 53.12%] [G loss: 0.744534]\n",
      "epoch:37 step:29482 [D loss: 0.679392, acc.: 55.47%] [G loss: 0.810246]\n",
      "epoch:37 step:29483 [D loss: 0.621629, acc.: 71.88%] [G loss: 0.778348]\n",
      "epoch:37 step:29484 [D loss: 0.619665, acc.: 71.88%] [G loss: 0.690088]\n",
      "epoch:37 step:29485 [D loss: 0.704631, acc.: 50.78%] [G loss: 0.824437]\n",
      "epoch:37 step:29486 [D loss: 0.689573, acc.: 50.78%] [G loss: 0.792381]\n",
      "epoch:37 step:29487 [D loss: 0.750926, acc.: 35.94%] [G loss: 0.783845]\n",
      "epoch:37 step:29488 [D loss: 0.655837, acc.: 64.84%] [G loss: 0.959981]\n",
      "epoch:37 step:29489 [D loss: 0.712517, acc.: 46.09%] [G loss: 0.743356]\n",
      "epoch:37 step:29490 [D loss: 0.653112, acc.: 60.16%] [G loss: 0.845408]\n",
      "epoch:37 step:29491 [D loss: 0.736765, acc.: 45.31%] [G loss: 0.759354]\n",
      "epoch:37 step:29492 [D loss: 0.673834, acc.: 61.72%] [G loss: 0.891935]\n",
      "epoch:37 step:29493 [D loss: 0.681837, acc.: 57.03%] [G loss: 0.834658]\n",
      "epoch:37 step:29494 [D loss: 0.711400, acc.: 50.00%] [G loss: 0.771671]\n",
      "epoch:37 step:29495 [D loss: 0.649183, acc.: 64.06%] [G loss: 0.831828]\n",
      "epoch:37 step:29496 [D loss: 0.679234, acc.: 56.25%] [G loss: 0.769529]\n",
      "epoch:37 step:29497 [D loss: 0.692406, acc.: 59.38%] [G loss: 0.729224]\n",
      "epoch:37 step:29498 [D loss: 0.674461, acc.: 59.38%] [G loss: 0.747124]\n",
      "epoch:37 step:29499 [D loss: 0.669349, acc.: 58.59%] [G loss: 0.815261]\n",
      "epoch:37 step:29500 [D loss: 0.735665, acc.: 37.50%] [G loss: 0.761341]\n",
      "epoch:37 step:29501 [D loss: 0.710501, acc.: 49.22%] [G loss: 0.780518]\n",
      "epoch:37 step:29502 [D loss: 0.728366, acc.: 46.09%] [G loss: 0.813827]\n",
      "epoch:37 step:29503 [D loss: 0.719048, acc.: 49.22%] [G loss: 0.779858]\n",
      "epoch:37 step:29504 [D loss: 0.654220, acc.: 56.25%] [G loss: 0.792263]\n",
      "epoch:37 step:29505 [D loss: 0.613085, acc.: 68.75%] [G loss: 0.753771]\n",
      "epoch:37 step:29506 [D loss: 0.651477, acc.: 62.50%] [G loss: 0.802197]\n",
      "epoch:37 step:29507 [D loss: 0.644879, acc.: 67.97%] [G loss: 0.692088]\n",
      "epoch:37 step:29508 [D loss: 0.740699, acc.: 39.06%] [G loss: 0.735704]\n",
      "epoch:37 step:29509 [D loss: 0.634197, acc.: 67.19%] [G loss: 0.739255]\n",
      "epoch:37 step:29510 [D loss: 0.775174, acc.: 33.59%] [G loss: 0.727510]\n",
      "epoch:37 step:29511 [D loss: 0.734703, acc.: 49.22%] [G loss: 0.758819]\n",
      "epoch:37 step:29512 [D loss: 0.646618, acc.: 67.19%] [G loss: 0.763367]\n",
      "epoch:37 step:29513 [D loss: 0.720550, acc.: 46.88%] [G loss: 0.768209]\n",
      "epoch:37 step:29514 [D loss: 0.641772, acc.: 67.19%] [G loss: 0.761721]\n",
      "epoch:37 step:29515 [D loss: 0.613625, acc.: 71.09%] [G loss: 0.871734]\n",
      "epoch:37 step:29516 [D loss: 0.651711, acc.: 62.50%] [G loss: 0.884784]\n",
      "epoch:37 step:29517 [D loss: 0.707457, acc.: 51.56%] [G loss: 0.861623]\n",
      "epoch:37 step:29518 [D loss: 0.664129, acc.: 61.72%] [G loss: 0.835947]\n",
      "epoch:37 step:29519 [D loss: 0.679278, acc.: 54.69%] [G loss: 0.845362]\n",
      "epoch:37 step:29520 [D loss: 0.663966, acc.: 56.25%] [G loss: 0.829618]\n",
      "epoch:37 step:29521 [D loss: 0.675018, acc.: 57.03%] [G loss: 0.829768]\n",
      "epoch:37 step:29522 [D loss: 0.682686, acc.: 58.59%] [G loss: 0.809877]\n",
      "epoch:37 step:29523 [D loss: 0.667784, acc.: 63.28%] [G loss: 0.770437]\n",
      "epoch:37 step:29524 [D loss: 0.673712, acc.: 53.91%] [G loss: 0.816104]\n",
      "epoch:37 step:29525 [D loss: 0.645451, acc.: 73.44%] [G loss: 0.824080]\n",
      "epoch:37 step:29526 [D loss: 0.734801, acc.: 43.75%] [G loss: 0.805330]\n",
      "epoch:37 step:29527 [D loss: 0.617505, acc.: 73.44%] [G loss: 0.859718]\n",
      "epoch:37 step:29528 [D loss: 0.702517, acc.: 58.59%] [G loss: 0.824624]\n",
      "epoch:37 step:29529 [D loss: 0.680143, acc.: 56.25%] [G loss: 0.801318]\n",
      "epoch:37 step:29530 [D loss: 0.696673, acc.: 54.69%] [G loss: 0.816596]\n",
      "epoch:37 step:29531 [D loss: 0.656486, acc.: 65.62%] [G loss: 0.783865]\n",
      "epoch:37 step:29532 [D loss: 0.650789, acc.: 63.28%] [G loss: 0.814491]\n",
      "epoch:37 step:29533 [D loss: 0.678008, acc.: 57.81%] [G loss: 0.714851]\n",
      "epoch:37 step:29534 [D loss: 0.722658, acc.: 46.88%] [G loss: 0.756680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29535 [D loss: 0.791877, acc.: 32.03%] [G loss: 0.770914]\n",
      "epoch:37 step:29536 [D loss: 0.707675, acc.: 51.56%] [G loss: 0.700312]\n",
      "epoch:37 step:29537 [D loss: 0.710302, acc.: 49.22%] [G loss: 0.769128]\n",
      "epoch:37 step:29538 [D loss: 0.697929, acc.: 46.88%] [G loss: 0.738341]\n",
      "epoch:37 step:29539 [D loss: 0.704455, acc.: 48.44%] [G loss: 0.795387]\n",
      "epoch:37 step:29540 [D loss: 0.691606, acc.: 51.56%] [G loss: 0.795703]\n",
      "epoch:37 step:29541 [D loss: 0.670448, acc.: 62.50%] [G loss: 0.817190]\n",
      "epoch:37 step:29542 [D loss: 0.634974, acc.: 65.62%] [G loss: 0.809098]\n",
      "epoch:37 step:29543 [D loss: 0.688524, acc.: 47.66%] [G loss: 0.805750]\n",
      "epoch:37 step:29544 [D loss: 0.709643, acc.: 49.22%] [G loss: 0.812286]\n",
      "epoch:37 step:29545 [D loss: 0.720518, acc.: 48.44%] [G loss: 0.750447]\n",
      "epoch:37 step:29546 [D loss: 0.679942, acc.: 59.38%] [G loss: 0.777717]\n",
      "epoch:37 step:29547 [D loss: 0.642732, acc.: 64.84%] [G loss: 0.809689]\n",
      "epoch:37 step:29548 [D loss: 0.691950, acc.: 57.81%] [G loss: 0.718071]\n",
      "epoch:37 step:29549 [D loss: 0.676788, acc.: 53.91%] [G loss: 0.796529]\n",
      "epoch:37 step:29550 [D loss: 0.624253, acc.: 68.75%] [G loss: 0.795649]\n",
      "epoch:37 step:29551 [D loss: 0.671784, acc.: 60.16%] [G loss: 0.719126]\n",
      "epoch:37 step:29552 [D loss: 0.703271, acc.: 50.78%] [G loss: 0.733571]\n",
      "epoch:37 step:29553 [D loss: 0.644590, acc.: 64.84%] [G loss: 0.813846]\n",
      "epoch:37 step:29554 [D loss: 0.700399, acc.: 53.12%] [G loss: 0.774427]\n",
      "epoch:37 step:29555 [D loss: 0.709024, acc.: 50.78%] [G loss: 0.758037]\n",
      "epoch:37 step:29556 [D loss: 0.669876, acc.: 62.50%] [G loss: 0.792479]\n",
      "epoch:37 step:29557 [D loss: 0.682300, acc.: 53.91%] [G loss: 0.783586]\n",
      "epoch:37 step:29558 [D loss: 0.642767, acc.: 65.62%] [G loss: 0.776386]\n",
      "epoch:37 step:29559 [D loss: 0.726044, acc.: 52.34%] [G loss: 0.824327]\n",
      "epoch:37 step:29560 [D loss: 0.641158, acc.: 64.06%] [G loss: 0.714074]\n",
      "epoch:37 step:29561 [D loss: 0.702837, acc.: 58.59%] [G loss: 0.725766]\n",
      "epoch:37 step:29562 [D loss: 0.759134, acc.: 34.38%] [G loss: 0.754539]\n",
      "epoch:37 step:29563 [D loss: 0.680779, acc.: 57.81%] [G loss: 0.838103]\n",
      "epoch:37 step:29564 [D loss: 0.665027, acc.: 55.47%] [G loss: 0.802086]\n",
      "epoch:37 step:29565 [D loss: 0.669397, acc.: 58.59%] [G loss: 0.785897]\n",
      "epoch:37 step:29566 [D loss: 0.742077, acc.: 39.84%] [G loss: 0.806435]\n",
      "epoch:37 step:29567 [D loss: 0.722939, acc.: 42.97%] [G loss: 0.760475]\n",
      "epoch:37 step:29568 [D loss: 0.662121, acc.: 62.50%] [G loss: 0.790933]\n",
      "epoch:37 step:29569 [D loss: 0.721702, acc.: 48.44%] [G loss: 0.800331]\n",
      "epoch:37 step:29570 [D loss: 0.645499, acc.: 64.06%] [G loss: 0.794240]\n",
      "epoch:37 step:29571 [D loss: 0.663586, acc.: 55.47%] [G loss: 0.832086]\n",
      "epoch:37 step:29572 [D loss: 0.675604, acc.: 58.59%] [G loss: 0.757916]\n",
      "epoch:37 step:29573 [D loss: 0.729725, acc.: 47.66%] [G loss: 0.802680]\n",
      "epoch:37 step:29574 [D loss: 0.688019, acc.: 54.69%] [G loss: 0.777376]\n",
      "epoch:37 step:29575 [D loss: 0.707753, acc.: 51.56%] [G loss: 0.711326]\n",
      "epoch:37 step:29576 [D loss: 0.697684, acc.: 55.47%] [G loss: 0.696219]\n",
      "epoch:37 step:29577 [D loss: 0.677355, acc.: 52.34%] [G loss: 0.773233]\n",
      "epoch:37 step:29578 [D loss: 0.699878, acc.: 47.66%] [G loss: 0.746298]\n",
      "epoch:37 step:29579 [D loss: 0.712100, acc.: 49.22%] [G loss: 0.786990]\n",
      "epoch:37 step:29580 [D loss: 0.690105, acc.: 48.44%] [G loss: 0.882445]\n",
      "epoch:37 step:29581 [D loss: 0.686486, acc.: 52.34%] [G loss: 0.840936]\n",
      "epoch:37 step:29582 [D loss: 0.701218, acc.: 54.69%] [G loss: 0.933689]\n",
      "epoch:37 step:29583 [D loss: 0.722510, acc.: 50.00%] [G loss: 0.814024]\n",
      "epoch:37 step:29584 [D loss: 0.706699, acc.: 49.22%] [G loss: 0.781788]\n",
      "epoch:37 step:29585 [D loss: 0.697777, acc.: 47.66%] [G loss: 0.860731]\n",
      "epoch:37 step:29586 [D loss: 0.698814, acc.: 48.44%] [G loss: 0.888038]\n",
      "epoch:37 step:29587 [D loss: 0.684368, acc.: 53.91%] [G loss: 0.804167]\n",
      "epoch:37 step:29588 [D loss: 0.668490, acc.: 57.03%] [G loss: 0.788639]\n",
      "epoch:37 step:29589 [D loss: 0.761132, acc.: 39.06%] [G loss: 0.741502]\n",
      "epoch:37 step:29590 [D loss: 0.694007, acc.: 53.12%] [G loss: 0.754535]\n",
      "epoch:37 step:29591 [D loss: 0.657115, acc.: 62.50%] [G loss: 0.758360]\n",
      "epoch:37 step:29592 [D loss: 0.685237, acc.: 59.38%] [G loss: 0.716770]\n",
      "epoch:37 step:29593 [D loss: 0.716407, acc.: 45.31%] [G loss: 0.795832]\n",
      "epoch:37 step:29594 [D loss: 0.700461, acc.: 54.69%] [G loss: 0.708016]\n",
      "epoch:37 step:29595 [D loss: 0.639589, acc.: 61.72%] [G loss: 0.719605]\n",
      "epoch:37 step:29596 [D loss: 0.696159, acc.: 54.69%] [G loss: 0.683887]\n",
      "epoch:37 step:29597 [D loss: 0.657752, acc.: 59.38%] [G loss: 0.704944]\n",
      "epoch:37 step:29598 [D loss: 0.638308, acc.: 68.75%] [G loss: 0.773710]\n",
      "epoch:37 step:29599 [D loss: 0.670806, acc.: 55.47%] [G loss: 0.794635]\n",
      "epoch:37 step:29600 [D loss: 0.643300, acc.: 62.50%] [G loss: 0.815324]\n",
      "epoch:37 step:29601 [D loss: 0.645052, acc.: 65.62%] [G loss: 0.823258]\n",
      "epoch:37 step:29602 [D loss: 0.690246, acc.: 49.22%] [G loss: 0.694668]\n",
      "epoch:37 step:29603 [D loss: 0.651782, acc.: 60.94%] [G loss: 0.889682]\n",
      "epoch:37 step:29604 [D loss: 0.712377, acc.: 50.00%] [G loss: 0.846783]\n",
      "epoch:37 step:29605 [D loss: 0.724999, acc.: 47.66%] [G loss: 0.786502]\n",
      "epoch:37 step:29606 [D loss: 0.659920, acc.: 57.81%] [G loss: 0.742248]\n",
      "epoch:37 step:29607 [D loss: 0.656305, acc.: 60.94%] [G loss: 0.779747]\n",
      "epoch:37 step:29608 [D loss: 0.697551, acc.: 48.44%] [G loss: 0.736113]\n",
      "epoch:37 step:29609 [D loss: 0.652180, acc.: 64.06%] [G loss: 0.842361]\n",
      "epoch:37 step:29610 [D loss: 0.689370, acc.: 56.25%] [G loss: 0.804688]\n",
      "epoch:37 step:29611 [D loss: 0.730912, acc.: 45.31%] [G loss: 0.876083]\n",
      "epoch:37 step:29612 [D loss: 0.680657, acc.: 56.25%] [G loss: 0.796802]\n",
      "epoch:37 step:29613 [D loss: 0.693379, acc.: 57.81%] [G loss: 0.769717]\n",
      "epoch:37 step:29614 [D loss: 0.679772, acc.: 49.22%] [G loss: 0.789013]\n",
      "epoch:37 step:29615 [D loss: 0.682115, acc.: 57.81%] [G loss: 0.922088]\n",
      "epoch:37 step:29616 [D loss: 0.684621, acc.: 56.25%] [G loss: 0.764273]\n",
      "epoch:37 step:29617 [D loss: 0.709982, acc.: 44.53%] [G loss: 0.812623]\n",
      "epoch:37 step:29618 [D loss: 0.705257, acc.: 45.31%] [G loss: 0.818919]\n",
      "epoch:37 step:29619 [D loss: 0.624269, acc.: 70.31%] [G loss: 0.799829]\n",
      "epoch:37 step:29620 [D loss: 0.738607, acc.: 44.53%] [G loss: 0.778686]\n",
      "epoch:37 step:29621 [D loss: 0.674774, acc.: 57.81%] [G loss: 0.781084]\n",
      "epoch:37 step:29622 [D loss: 0.669805, acc.: 57.03%] [G loss: 0.850557]\n",
      "epoch:37 step:29623 [D loss: 0.676318, acc.: 53.91%] [G loss: 0.694305]\n",
      "epoch:37 step:29624 [D loss: 0.684976, acc.: 50.78%] [G loss: 0.758572]\n",
      "epoch:37 step:29625 [D loss: 0.683262, acc.: 53.12%] [G loss: 0.777653]\n",
      "epoch:37 step:29626 [D loss: 0.712053, acc.: 51.56%] [G loss: 0.724209]\n",
      "epoch:37 step:29627 [D loss: 0.718653, acc.: 48.44%] [G loss: 0.771406]\n",
      "epoch:37 step:29628 [D loss: 0.649921, acc.: 66.41%] [G loss: 0.827209]\n",
      "epoch:37 step:29629 [D loss: 0.728045, acc.: 46.88%] [G loss: 0.799553]\n",
      "epoch:37 step:29630 [D loss: 0.658345, acc.: 60.16%] [G loss: 0.782680]\n",
      "epoch:37 step:29631 [D loss: 0.684043, acc.: 57.81%] [G loss: 0.723380]\n",
      "epoch:37 step:29632 [D loss: 0.696745, acc.: 53.12%] [G loss: 0.728169]\n",
      "epoch:37 step:29633 [D loss: 0.638251, acc.: 69.53%] [G loss: 0.763235]\n",
      "epoch:37 step:29634 [D loss: 0.709089, acc.: 43.75%] [G loss: 0.787954]\n",
      "epoch:37 step:29635 [D loss: 0.665799, acc.: 58.59%] [G loss: 0.782621]\n",
      "epoch:37 step:29636 [D loss: 0.693136, acc.: 48.44%] [G loss: 0.876021]\n",
      "epoch:37 step:29637 [D loss: 0.673363, acc.: 53.91%] [G loss: 0.809446]\n",
      "epoch:37 step:29638 [D loss: 0.690359, acc.: 52.34%] [G loss: 0.744079]\n",
      "epoch:37 step:29639 [D loss: 0.691384, acc.: 50.78%] [G loss: 0.805148]\n",
      "epoch:37 step:29640 [D loss: 0.647342, acc.: 66.41%] [G loss: 0.818483]\n",
      "epoch:37 step:29641 [D loss: 0.642764, acc.: 64.06%] [G loss: 0.795826]\n",
      "epoch:37 step:29642 [D loss: 0.688995, acc.: 56.25%] [G loss: 0.729389]\n",
      "epoch:37 step:29643 [D loss: 0.648860, acc.: 68.75%] [G loss: 0.798034]\n",
      "epoch:37 step:29644 [D loss: 0.676348, acc.: 61.72%] [G loss: 0.747777]\n",
      "epoch:37 step:29645 [D loss: 0.675400, acc.: 59.38%] [G loss: 0.773863]\n",
      "epoch:37 step:29646 [D loss: 0.717043, acc.: 53.91%] [G loss: 0.723383]\n",
      "epoch:37 step:29647 [D loss: 0.696661, acc.: 51.56%] [G loss: 0.745568]\n",
      "epoch:37 step:29648 [D loss: 0.704788, acc.: 48.44%] [G loss: 0.801806]\n",
      "epoch:37 step:29649 [D loss: 0.664601, acc.: 58.59%] [G loss: 0.831990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29650 [D loss: 0.643981, acc.: 63.28%] [G loss: 0.919373]\n",
      "epoch:37 step:29651 [D loss: 0.649719, acc.: 63.28%] [G loss: 0.920754]\n",
      "epoch:37 step:29652 [D loss: 0.676726, acc.: 64.84%] [G loss: 0.814286]\n",
      "epoch:37 step:29653 [D loss: 0.665374, acc.: 59.38%] [G loss: 0.847964]\n",
      "epoch:37 step:29654 [D loss: 0.674811, acc.: 53.91%] [G loss: 0.878302]\n",
      "epoch:37 step:29655 [D loss: 0.663267, acc.: 58.59%] [G loss: 0.688343]\n",
      "epoch:37 step:29656 [D loss: 0.694641, acc.: 57.81%] [G loss: 0.742656]\n",
      "epoch:37 step:29657 [D loss: 0.685232, acc.: 55.47%] [G loss: 0.748644]\n",
      "epoch:37 step:29658 [D loss: 0.660692, acc.: 61.72%] [G loss: 0.742863]\n",
      "epoch:37 step:29659 [D loss: 0.716422, acc.: 46.09%] [G loss: 0.705879]\n",
      "epoch:37 step:29660 [D loss: 0.653682, acc.: 67.97%] [G loss: 0.801088]\n",
      "epoch:37 step:29661 [D loss: 0.716139, acc.: 44.53%] [G loss: 0.739881]\n",
      "epoch:37 step:29662 [D loss: 0.644565, acc.: 64.06%] [G loss: 0.768091]\n",
      "epoch:37 step:29663 [D loss: 0.662769, acc.: 59.38%] [G loss: 0.848074]\n",
      "epoch:37 step:29664 [D loss: 0.672706, acc.: 64.84%] [G loss: 0.761701]\n",
      "epoch:37 step:29665 [D loss: 0.706148, acc.: 51.56%] [G loss: 0.722799]\n",
      "epoch:37 step:29666 [D loss: 0.715749, acc.: 49.22%] [G loss: 0.798588]\n",
      "epoch:37 step:29667 [D loss: 0.674173, acc.: 57.81%] [G loss: 0.787585]\n",
      "epoch:37 step:29668 [D loss: 0.676340, acc.: 55.47%] [G loss: 0.866387]\n",
      "epoch:37 step:29669 [D loss: 0.689552, acc.: 57.03%] [G loss: 0.782730]\n",
      "epoch:37 step:29670 [D loss: 0.718915, acc.: 50.78%] [G loss: 0.668452]\n",
      "epoch:37 step:29671 [D loss: 0.617008, acc.: 71.09%] [G loss: 0.768753]\n",
      "epoch:37 step:29672 [D loss: 0.721815, acc.: 46.09%] [G loss: 0.805626]\n",
      "epoch:37 step:29673 [D loss: 0.682546, acc.: 53.91%] [G loss: 0.790989]\n",
      "epoch:37 step:29674 [D loss: 0.676954, acc.: 57.81%] [G loss: 0.883122]\n",
      "epoch:37 step:29675 [D loss: 0.663235, acc.: 57.81%] [G loss: 0.754674]\n",
      "epoch:37 step:29676 [D loss: 0.662822, acc.: 57.03%] [G loss: 0.842359]\n",
      "epoch:37 step:29677 [D loss: 0.748048, acc.: 42.97%] [G loss: 0.740126]\n",
      "epoch:37 step:29678 [D loss: 0.672547, acc.: 58.59%] [G loss: 0.767566]\n",
      "epoch:38 step:29679 [D loss: 0.657556, acc.: 67.97%] [G loss: 0.770964]\n",
      "epoch:38 step:29680 [D loss: 0.672175, acc.: 54.69%] [G loss: 0.787883]\n",
      "epoch:38 step:29681 [D loss: 0.712227, acc.: 45.31%] [G loss: 0.811461]\n",
      "epoch:38 step:29682 [D loss: 0.652221, acc.: 67.19%] [G loss: 0.778447]\n",
      "epoch:38 step:29683 [D loss: 0.655468, acc.: 67.97%] [G loss: 0.769095]\n",
      "epoch:38 step:29684 [D loss: 0.578382, acc.: 76.56%] [G loss: 0.818861]\n",
      "epoch:38 step:29685 [D loss: 0.670767, acc.: 62.50%] [G loss: 0.745026]\n",
      "epoch:38 step:29686 [D loss: 0.646648, acc.: 65.62%] [G loss: 0.767260]\n",
      "epoch:38 step:29687 [D loss: 0.704059, acc.: 45.31%] [G loss: 0.746089]\n",
      "epoch:38 step:29688 [D loss: 0.697536, acc.: 56.25%] [G loss: 0.732592]\n",
      "epoch:38 step:29689 [D loss: 0.701445, acc.: 49.22%] [G loss: 0.809570]\n",
      "epoch:38 step:29690 [D loss: 0.719493, acc.: 46.09%] [G loss: 0.782123]\n",
      "epoch:38 step:29691 [D loss: 0.677197, acc.: 57.81%] [G loss: 0.667161]\n",
      "epoch:38 step:29692 [D loss: 0.736062, acc.: 42.19%] [G loss: 0.768804]\n",
      "epoch:38 step:29693 [D loss: 0.699795, acc.: 51.56%] [G loss: 0.771251]\n",
      "epoch:38 step:29694 [D loss: 0.732245, acc.: 36.72%] [G loss: 0.704738]\n",
      "epoch:38 step:29695 [D loss: 0.627879, acc.: 67.19%] [G loss: 0.810480]\n",
      "epoch:38 step:29696 [D loss: 0.777810, acc.: 36.72%] [G loss: 0.749539]\n",
      "epoch:38 step:29697 [D loss: 0.716029, acc.: 47.66%] [G loss: 0.836153]\n",
      "epoch:38 step:29698 [D loss: 0.602662, acc.: 75.78%] [G loss: 0.822979]\n",
      "epoch:38 step:29699 [D loss: 0.661831, acc.: 57.03%] [G loss: 0.799087]\n",
      "epoch:38 step:29700 [D loss: 0.685275, acc.: 53.12%] [G loss: 0.773916]\n",
      "epoch:38 step:29701 [D loss: 0.705626, acc.: 50.78%] [G loss: 0.745931]\n",
      "epoch:38 step:29702 [D loss: 0.689379, acc.: 51.56%] [G loss: 0.854163]\n",
      "epoch:38 step:29703 [D loss: 0.722983, acc.: 46.09%] [G loss: 0.803730]\n",
      "epoch:38 step:29704 [D loss: 0.676890, acc.: 57.81%] [G loss: 0.837981]\n",
      "epoch:38 step:29705 [D loss: 0.701728, acc.: 50.78%] [G loss: 0.835810]\n",
      "epoch:38 step:29706 [D loss: 0.678676, acc.: 57.81%] [G loss: 0.766806]\n",
      "epoch:38 step:29707 [D loss: 0.684793, acc.: 51.56%] [G loss: 0.893636]\n",
      "epoch:38 step:29708 [D loss: 0.679749, acc.: 60.16%] [G loss: 0.833617]\n",
      "epoch:38 step:29709 [D loss: 0.713648, acc.: 49.22%] [G loss: 0.788088]\n",
      "epoch:38 step:29710 [D loss: 0.679770, acc.: 59.38%] [G loss: 0.789240]\n",
      "epoch:38 step:29711 [D loss: 0.616913, acc.: 70.31%] [G loss: 0.817744]\n",
      "epoch:38 step:29712 [D loss: 0.641019, acc.: 66.41%] [G loss: 0.750715]\n",
      "epoch:38 step:29713 [D loss: 0.723706, acc.: 53.91%] [G loss: 0.698909]\n",
      "epoch:38 step:29714 [D loss: 0.686860, acc.: 53.91%] [G loss: 0.814445]\n",
      "epoch:38 step:29715 [D loss: 0.636522, acc.: 67.19%] [G loss: 0.823891]\n",
      "epoch:38 step:29716 [D loss: 0.721433, acc.: 47.66%] [G loss: 0.746235]\n",
      "epoch:38 step:29717 [D loss: 0.634551, acc.: 64.84%] [G loss: 0.719768]\n",
      "epoch:38 step:29718 [D loss: 0.712581, acc.: 48.44%] [G loss: 0.647352]\n",
      "epoch:38 step:29719 [D loss: 0.617735, acc.: 69.53%] [G loss: 0.774765]\n",
      "epoch:38 step:29720 [D loss: 0.701502, acc.: 48.44%] [G loss: 0.682706]\n",
      "epoch:38 step:29721 [D loss: 0.672507, acc.: 60.94%] [G loss: 0.777431]\n",
      "epoch:38 step:29722 [D loss: 0.678261, acc.: 57.81%] [G loss: 0.760971]\n",
      "epoch:38 step:29723 [D loss: 0.718676, acc.: 43.75%] [G loss: 0.697446]\n",
      "epoch:38 step:29724 [D loss: 0.640585, acc.: 62.50%] [G loss: 0.804004]\n",
      "epoch:38 step:29725 [D loss: 0.732844, acc.: 42.97%] [G loss: 0.747406]\n",
      "epoch:38 step:29726 [D loss: 0.672388, acc.: 57.81%] [G loss: 0.708517]\n",
      "epoch:38 step:29727 [D loss: 0.705867, acc.: 49.22%] [G loss: 0.749363]\n",
      "epoch:38 step:29728 [D loss: 0.685429, acc.: 52.34%] [G loss: 0.811574]\n",
      "epoch:38 step:29729 [D loss: 0.675638, acc.: 58.59%] [G loss: 0.765802]\n",
      "epoch:38 step:29730 [D loss: 0.695152, acc.: 50.78%] [G loss: 0.784622]\n",
      "epoch:38 step:29731 [D loss: 0.801040, acc.: 34.38%] [G loss: 0.716397]\n",
      "epoch:38 step:29732 [D loss: 0.728259, acc.: 52.34%] [G loss: 0.764875]\n",
      "epoch:38 step:29733 [D loss: 0.683201, acc.: 53.12%] [G loss: 0.816907]\n",
      "epoch:38 step:29734 [D loss: 0.675256, acc.: 60.94%] [G loss: 0.730072]\n",
      "epoch:38 step:29735 [D loss: 0.666269, acc.: 60.16%] [G loss: 0.782869]\n",
      "epoch:38 step:29736 [D loss: 0.701409, acc.: 49.22%] [G loss: 0.888464]\n",
      "epoch:38 step:29737 [D loss: 0.673605, acc.: 60.16%] [G loss: 0.728786]\n",
      "epoch:38 step:29738 [D loss: 0.680620, acc.: 49.22%] [G loss: 0.793531]\n",
      "epoch:38 step:29739 [D loss: 0.714839, acc.: 48.44%] [G loss: 0.804960]\n",
      "epoch:38 step:29740 [D loss: 0.712491, acc.: 56.25%] [G loss: 0.769282]\n",
      "epoch:38 step:29741 [D loss: 0.766989, acc.: 37.50%] [G loss: 0.713690]\n",
      "epoch:38 step:29742 [D loss: 0.729164, acc.: 48.44%] [G loss: 0.828377]\n",
      "epoch:38 step:29743 [D loss: 0.724930, acc.: 42.19%] [G loss: 0.740282]\n",
      "epoch:38 step:29744 [D loss: 0.716646, acc.: 46.09%] [G loss: 0.810518]\n",
      "epoch:38 step:29745 [D loss: 0.700598, acc.: 53.91%] [G loss: 0.810771]\n",
      "epoch:38 step:29746 [D loss: 0.713603, acc.: 44.53%] [G loss: 0.736053]\n",
      "epoch:38 step:29747 [D loss: 0.676035, acc.: 60.16%] [G loss: 0.741516]\n",
      "epoch:38 step:29748 [D loss: 0.652864, acc.: 60.94%] [G loss: 0.829277]\n",
      "epoch:38 step:29749 [D loss: 0.720116, acc.: 48.44%] [G loss: 0.793824]\n",
      "epoch:38 step:29750 [D loss: 0.714700, acc.: 46.09%] [G loss: 0.767462]\n",
      "epoch:38 step:29751 [D loss: 0.719492, acc.: 49.22%] [G loss: 0.867845]\n",
      "epoch:38 step:29752 [D loss: 0.698926, acc.: 50.00%] [G loss: 0.746520]\n",
      "epoch:38 step:29753 [D loss: 0.637923, acc.: 68.75%] [G loss: 0.832978]\n",
      "epoch:38 step:29754 [D loss: 0.716358, acc.: 47.66%] [G loss: 0.813420]\n",
      "epoch:38 step:29755 [D loss: 0.708483, acc.: 49.22%] [G loss: 0.768179]\n",
      "epoch:38 step:29756 [D loss: 0.686758, acc.: 58.59%] [G loss: 0.830252]\n",
      "epoch:38 step:29757 [D loss: 0.674116, acc.: 57.81%] [G loss: 0.821585]\n",
      "epoch:38 step:29758 [D loss: 0.701533, acc.: 45.31%] [G loss: 0.776545]\n",
      "epoch:38 step:29759 [D loss: 0.674253, acc.: 57.03%] [G loss: 0.865770]\n",
      "epoch:38 step:29760 [D loss: 0.717584, acc.: 50.00%] [G loss: 0.782610]\n",
      "epoch:38 step:29761 [D loss: 0.701022, acc.: 44.53%] [G loss: 0.777489]\n",
      "epoch:38 step:29762 [D loss: 0.669536, acc.: 65.62%] [G loss: 0.761136]\n",
      "epoch:38 step:29763 [D loss: 0.689105, acc.: 53.91%] [G loss: 0.900925]\n",
      "epoch:38 step:29764 [D loss: 0.649048, acc.: 64.06%] [G loss: 0.830111]\n",
      "epoch:38 step:29765 [D loss: 0.673101, acc.: 60.16%] [G loss: 0.777650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29766 [D loss: 0.684093, acc.: 53.91%] [G loss: 0.784013]\n",
      "epoch:38 step:29767 [D loss: 0.704164, acc.: 50.00%] [G loss: 0.789007]\n",
      "epoch:38 step:29768 [D loss: 0.735863, acc.: 46.09%] [G loss: 0.766211]\n",
      "epoch:38 step:29769 [D loss: 0.699623, acc.: 48.44%] [G loss: 0.761002]\n",
      "epoch:38 step:29770 [D loss: 0.720582, acc.: 46.09%] [G loss: 0.722868]\n",
      "epoch:38 step:29771 [D loss: 0.691100, acc.: 56.25%] [G loss: 0.727125]\n",
      "epoch:38 step:29772 [D loss: 0.717479, acc.: 46.88%] [G loss: 0.773257]\n",
      "epoch:38 step:29773 [D loss: 0.721607, acc.: 46.09%] [G loss: 0.704906]\n",
      "epoch:38 step:29774 [D loss: 0.747038, acc.: 39.06%] [G loss: 0.753801]\n",
      "epoch:38 step:29775 [D loss: 0.698728, acc.: 46.09%] [G loss: 0.811784]\n",
      "epoch:38 step:29776 [D loss: 0.708928, acc.: 50.00%] [G loss: 0.756708]\n",
      "epoch:38 step:29777 [D loss: 0.687834, acc.: 53.12%] [G loss: 0.825604]\n",
      "epoch:38 step:29778 [D loss: 0.711124, acc.: 50.00%] [G loss: 0.848342]\n",
      "epoch:38 step:29779 [D loss: 0.711850, acc.: 48.44%] [G loss: 0.697893]\n",
      "epoch:38 step:29780 [D loss: 0.703612, acc.: 48.44%] [G loss: 0.784132]\n",
      "epoch:38 step:29781 [D loss: 0.665686, acc.: 53.91%] [G loss: 0.765177]\n",
      "epoch:38 step:29782 [D loss: 0.642958, acc.: 64.84%] [G loss: 0.865183]\n",
      "epoch:38 step:29783 [D loss: 0.636283, acc.: 64.06%] [G loss: 0.773185]\n",
      "epoch:38 step:29784 [D loss: 0.728254, acc.: 44.53%] [G loss: 0.755876]\n",
      "epoch:38 step:29785 [D loss: 0.641398, acc.: 60.94%] [G loss: 0.853494]\n",
      "epoch:38 step:29786 [D loss: 0.729910, acc.: 50.00%] [G loss: 0.749633]\n",
      "epoch:38 step:29787 [D loss: 0.656255, acc.: 65.62%] [G loss: 0.796381]\n",
      "epoch:38 step:29788 [D loss: 0.737981, acc.: 46.09%] [G loss: 0.778275]\n",
      "epoch:38 step:29789 [D loss: 0.685479, acc.: 54.69%] [G loss: 0.712453]\n",
      "epoch:38 step:29790 [D loss: 0.667581, acc.: 57.03%] [G loss: 0.757670]\n",
      "epoch:38 step:29791 [D loss: 0.690627, acc.: 49.22%] [G loss: 0.773936]\n",
      "epoch:38 step:29792 [D loss: 0.623892, acc.: 73.44%] [G loss: 0.775452]\n",
      "epoch:38 step:29793 [D loss: 0.722279, acc.: 42.97%] [G loss: 0.766099]\n",
      "epoch:38 step:29794 [D loss: 0.717799, acc.: 44.53%] [G loss: 0.742823]\n",
      "epoch:38 step:29795 [D loss: 0.707613, acc.: 50.00%] [G loss: 0.702345]\n",
      "epoch:38 step:29796 [D loss: 0.702704, acc.: 42.19%] [G loss: 0.705484]\n",
      "epoch:38 step:29797 [D loss: 0.657631, acc.: 60.94%] [G loss: 0.751916]\n",
      "epoch:38 step:29798 [D loss: 0.683683, acc.: 55.47%] [G loss: 0.795203]\n",
      "epoch:38 step:29799 [D loss: 0.644726, acc.: 70.31%] [G loss: 0.808946]\n",
      "epoch:38 step:29800 [D loss: 0.744401, acc.: 44.53%] [G loss: 0.803599]\n",
      "epoch:38 step:29801 [D loss: 0.655547, acc.: 64.84%] [G loss: 0.757228]\n",
      "epoch:38 step:29802 [D loss: 0.674362, acc.: 55.47%] [G loss: 0.759554]\n",
      "epoch:38 step:29803 [D loss: 0.721402, acc.: 46.09%] [G loss: 0.788140]\n",
      "epoch:38 step:29804 [D loss: 0.764247, acc.: 35.16%] [G loss: 0.740938]\n",
      "epoch:38 step:29805 [D loss: 0.657868, acc.: 64.84%] [G loss: 0.844498]\n",
      "epoch:38 step:29806 [D loss: 0.707796, acc.: 52.34%] [G loss: 0.827863]\n",
      "epoch:38 step:29807 [D loss: 0.690419, acc.: 56.25%] [G loss: 0.859845]\n",
      "epoch:38 step:29808 [D loss: 0.695541, acc.: 52.34%] [G loss: 0.807537]\n",
      "epoch:38 step:29809 [D loss: 0.692081, acc.: 60.94%] [G loss: 0.806755]\n",
      "epoch:38 step:29810 [D loss: 0.562888, acc.: 82.81%] [G loss: 0.732978]\n",
      "epoch:38 step:29811 [D loss: 0.673817, acc.: 57.81%] [G loss: 0.857186]\n",
      "epoch:38 step:29812 [D loss: 0.688562, acc.: 61.72%] [G loss: 0.789488]\n",
      "epoch:38 step:29813 [D loss: 0.727537, acc.: 46.88%] [G loss: 0.646592]\n",
      "epoch:38 step:29814 [D loss: 0.689179, acc.: 59.38%] [G loss: 0.711940]\n",
      "epoch:38 step:29815 [D loss: 0.730250, acc.: 43.75%] [G loss: 0.716859]\n",
      "epoch:38 step:29816 [D loss: 0.683815, acc.: 58.59%] [G loss: 0.753847]\n",
      "epoch:38 step:29817 [D loss: 0.648174, acc.: 62.50%] [G loss: 0.801157]\n",
      "epoch:38 step:29818 [D loss: 0.725611, acc.: 45.31%] [G loss: 0.744500]\n",
      "epoch:38 step:29819 [D loss: 0.722296, acc.: 44.53%] [G loss: 0.759064]\n",
      "epoch:38 step:29820 [D loss: 0.696657, acc.: 56.25%] [G loss: 0.796260]\n",
      "epoch:38 step:29821 [D loss: 0.669158, acc.: 59.38%] [G loss: 0.780176]\n",
      "epoch:38 step:29822 [D loss: 0.736315, acc.: 45.31%] [G loss: 0.836247]\n",
      "epoch:38 step:29823 [D loss: 0.721526, acc.: 48.44%] [G loss: 0.847271]\n",
      "epoch:38 step:29824 [D loss: 0.736143, acc.: 42.19%] [G loss: 0.743086]\n",
      "epoch:38 step:29825 [D loss: 0.737552, acc.: 42.97%] [G loss: 0.769565]\n",
      "epoch:38 step:29826 [D loss: 0.718293, acc.: 52.34%] [G loss: 0.728764]\n",
      "epoch:38 step:29827 [D loss: 0.647909, acc.: 63.28%] [G loss: 0.854587]\n",
      "epoch:38 step:29828 [D loss: 0.706949, acc.: 46.09%] [G loss: 0.835819]\n",
      "epoch:38 step:29829 [D loss: 0.688396, acc.: 53.12%] [G loss: 0.863706]\n",
      "epoch:38 step:29830 [D loss: 0.667997, acc.: 57.03%] [G loss: 0.879942]\n",
      "epoch:38 step:29831 [D loss: 0.768228, acc.: 39.84%] [G loss: 0.811361]\n",
      "epoch:38 step:29832 [D loss: 0.651208, acc.: 64.06%] [G loss: 0.853933]\n",
      "epoch:38 step:29833 [D loss: 0.680871, acc.: 53.91%] [G loss: 0.753509]\n",
      "epoch:38 step:29834 [D loss: 0.718224, acc.: 46.09%] [G loss: 0.735972]\n",
      "epoch:38 step:29835 [D loss: 0.674421, acc.: 57.03%] [G loss: 0.796014]\n",
      "epoch:38 step:29836 [D loss: 0.648129, acc.: 64.06%] [G loss: 0.839287]\n",
      "epoch:38 step:29837 [D loss: 0.647845, acc.: 64.06%] [G loss: 0.775962]\n",
      "epoch:38 step:29838 [D loss: 0.639651, acc.: 64.06%] [G loss: 0.664597]\n",
      "epoch:38 step:29839 [D loss: 0.685974, acc.: 51.56%] [G loss: 0.743256]\n",
      "epoch:38 step:29840 [D loss: 0.712082, acc.: 44.53%] [G loss: 0.831743]\n",
      "epoch:38 step:29841 [D loss: 0.649811, acc.: 64.06%] [G loss: 0.886990]\n",
      "epoch:38 step:29842 [D loss: 0.724671, acc.: 50.00%] [G loss: 0.896819]\n",
      "epoch:38 step:29843 [D loss: 0.682192, acc.: 58.59%] [G loss: 0.867127]\n",
      "epoch:38 step:29844 [D loss: 0.691345, acc.: 57.81%] [G loss: 0.787065]\n",
      "epoch:38 step:29845 [D loss: 0.715478, acc.: 48.44%] [G loss: 0.784874]\n",
      "epoch:38 step:29846 [D loss: 0.610001, acc.: 79.69%] [G loss: 0.861600]\n",
      "epoch:38 step:29847 [D loss: 0.605311, acc.: 72.66%] [G loss: 0.795069]\n",
      "epoch:38 step:29848 [D loss: 0.629417, acc.: 66.41%] [G loss: 0.846587]\n",
      "epoch:38 step:29849 [D loss: 0.737984, acc.: 43.75%] [G loss: 0.784969]\n",
      "epoch:38 step:29850 [D loss: 0.717152, acc.: 46.09%] [G loss: 0.756664]\n",
      "epoch:38 step:29851 [D loss: 0.716979, acc.: 48.44%] [G loss: 0.754266]\n",
      "epoch:38 step:29852 [D loss: 0.663290, acc.: 60.16%] [G loss: 0.834622]\n",
      "epoch:38 step:29853 [D loss: 0.661701, acc.: 63.28%] [G loss: 0.790648]\n",
      "epoch:38 step:29854 [D loss: 0.729167, acc.: 45.31%] [G loss: 0.759699]\n",
      "epoch:38 step:29855 [D loss: 0.715075, acc.: 49.22%] [G loss: 0.780377]\n",
      "epoch:38 step:29856 [D loss: 0.727834, acc.: 44.53%] [G loss: 0.727656]\n",
      "epoch:38 step:29857 [D loss: 0.752615, acc.: 42.19%] [G loss: 0.822740]\n",
      "epoch:38 step:29858 [D loss: 0.694852, acc.: 49.22%] [G loss: 0.810347]\n",
      "epoch:38 step:29859 [D loss: 0.678539, acc.: 55.47%] [G loss: 0.823713]\n",
      "epoch:38 step:29860 [D loss: 0.712452, acc.: 46.09%] [G loss: 0.839667]\n",
      "epoch:38 step:29861 [D loss: 0.657376, acc.: 63.28%] [G loss: 0.802858]\n",
      "epoch:38 step:29862 [D loss: 0.659938, acc.: 60.94%] [G loss: 0.782768]\n",
      "epoch:38 step:29863 [D loss: 0.645971, acc.: 67.97%] [G loss: 0.811556]\n",
      "epoch:38 step:29864 [D loss: 0.687718, acc.: 53.12%] [G loss: 0.757812]\n",
      "epoch:38 step:29865 [D loss: 0.711735, acc.: 44.53%] [G loss: 0.787337]\n",
      "epoch:38 step:29866 [D loss: 0.675537, acc.: 59.38%] [G loss: 0.831017]\n",
      "epoch:38 step:29867 [D loss: 0.654541, acc.: 60.94%] [G loss: 0.813590]\n",
      "epoch:38 step:29868 [D loss: 0.664211, acc.: 57.81%] [G loss: 0.780584]\n",
      "epoch:38 step:29869 [D loss: 0.721097, acc.: 45.31%] [G loss: 0.766614]\n",
      "epoch:38 step:29870 [D loss: 0.685434, acc.: 55.47%] [G loss: 0.845656]\n",
      "epoch:38 step:29871 [D loss: 0.641868, acc.: 67.19%] [G loss: 0.833975]\n",
      "epoch:38 step:29872 [D loss: 0.722961, acc.: 47.66%] [G loss: 0.859696]\n",
      "epoch:38 step:29873 [D loss: 0.707482, acc.: 46.88%] [G loss: 0.774511]\n",
      "epoch:38 step:29874 [D loss: 0.652481, acc.: 63.28%] [G loss: 0.720543]\n",
      "epoch:38 step:29875 [D loss: 0.663547, acc.: 64.06%] [G loss: 0.798528]\n",
      "epoch:38 step:29876 [D loss: 0.700358, acc.: 53.91%] [G loss: 0.772657]\n",
      "epoch:38 step:29877 [D loss: 0.706492, acc.: 53.12%] [G loss: 0.691873]\n",
      "epoch:38 step:29878 [D loss: 0.702284, acc.: 50.00%] [G loss: 0.797159]\n",
      "epoch:38 step:29879 [D loss: 0.653360, acc.: 63.28%] [G loss: 0.700481]\n",
      "epoch:38 step:29880 [D loss: 0.709719, acc.: 56.25%] [G loss: 0.737377]\n",
      "epoch:38 step:29881 [D loss: 0.705873, acc.: 47.66%] [G loss: 0.757297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29882 [D loss: 0.707292, acc.: 47.66%] [G loss: 0.797040]\n",
      "epoch:38 step:29883 [D loss: 0.725505, acc.: 49.22%] [G loss: 0.829790]\n",
      "epoch:38 step:29884 [D loss: 0.721835, acc.: 41.41%] [G loss: 0.753757]\n",
      "epoch:38 step:29885 [D loss: 0.652597, acc.: 62.50%] [G loss: 0.774164]\n",
      "epoch:38 step:29886 [D loss: 0.625882, acc.: 67.19%] [G loss: 0.737477]\n",
      "epoch:38 step:29887 [D loss: 0.637175, acc.: 66.41%] [G loss: 0.788233]\n",
      "epoch:38 step:29888 [D loss: 0.684306, acc.: 53.91%] [G loss: 0.817080]\n",
      "epoch:38 step:29889 [D loss: 0.695848, acc.: 52.34%] [G loss: 0.754721]\n",
      "epoch:38 step:29890 [D loss: 0.706924, acc.: 53.91%] [G loss: 0.821402]\n",
      "epoch:38 step:29891 [D loss: 0.680576, acc.: 55.47%] [G loss: 0.871124]\n",
      "epoch:38 step:29892 [D loss: 0.703166, acc.: 46.88%] [G loss: 0.718243]\n",
      "epoch:38 step:29893 [D loss: 0.653083, acc.: 66.41%] [G loss: 0.779365]\n",
      "epoch:38 step:29894 [D loss: 0.712388, acc.: 46.09%] [G loss: 0.827685]\n",
      "epoch:38 step:29895 [D loss: 0.671692, acc.: 58.59%] [G loss: 0.792917]\n",
      "epoch:38 step:29896 [D loss: 0.712593, acc.: 50.00%] [G loss: 0.817704]\n",
      "epoch:38 step:29897 [D loss: 0.638874, acc.: 59.38%] [G loss: 0.805271]\n",
      "epoch:38 step:29898 [D loss: 0.662804, acc.: 58.59%] [G loss: 0.719418]\n",
      "epoch:38 step:29899 [D loss: 0.687448, acc.: 52.34%] [G loss: 0.796629]\n",
      "epoch:38 step:29900 [D loss: 0.683817, acc.: 56.25%] [G loss: 0.772111]\n",
      "epoch:38 step:29901 [D loss: 0.706437, acc.: 53.12%] [G loss: 0.754097]\n",
      "epoch:38 step:29902 [D loss: 0.649843, acc.: 60.94%] [G loss: 0.821095]\n",
      "epoch:38 step:29903 [D loss: 0.661145, acc.: 57.81%] [G loss: 0.744089]\n",
      "epoch:38 step:29904 [D loss: 0.718839, acc.: 50.78%] [G loss: 0.742909]\n",
      "epoch:38 step:29905 [D loss: 0.652307, acc.: 63.28%] [G loss: 0.740073]\n",
      "epoch:38 step:29906 [D loss: 0.715024, acc.: 50.78%] [G loss: 0.791222]\n",
      "epoch:38 step:29907 [D loss: 0.654657, acc.: 61.72%] [G loss: 0.811694]\n",
      "epoch:38 step:29908 [D loss: 0.724313, acc.: 42.97%] [G loss: 0.728042]\n",
      "epoch:38 step:29909 [D loss: 0.690515, acc.: 56.25%] [G loss: 0.788884]\n",
      "epoch:38 step:29910 [D loss: 0.711737, acc.: 50.78%] [G loss: 0.708897]\n",
      "epoch:38 step:29911 [D loss: 0.652142, acc.: 64.84%] [G loss: 0.692923]\n",
      "epoch:38 step:29912 [D loss: 0.735492, acc.: 44.53%] [G loss: 0.782018]\n",
      "epoch:38 step:29913 [D loss: 0.699801, acc.: 52.34%] [G loss: 0.765587]\n",
      "epoch:38 step:29914 [D loss: 0.668146, acc.: 55.47%] [G loss: 0.693142]\n",
      "epoch:38 step:29915 [D loss: 0.747721, acc.: 41.41%] [G loss: 0.705426]\n",
      "epoch:38 step:29916 [D loss: 0.732751, acc.: 42.97%] [G loss: 0.737153]\n",
      "epoch:38 step:29917 [D loss: 0.708289, acc.: 46.09%] [G loss: 0.741640]\n",
      "epoch:38 step:29918 [D loss: 0.706942, acc.: 47.66%] [G loss: 0.796749]\n",
      "epoch:38 step:29919 [D loss: 0.706137, acc.: 54.69%] [G loss: 0.780364]\n",
      "epoch:38 step:29920 [D loss: 0.682267, acc.: 57.03%] [G loss: 0.824803]\n",
      "epoch:38 step:29921 [D loss: 0.666715, acc.: 57.03%] [G loss: 0.785052]\n",
      "epoch:38 step:29922 [D loss: 0.681433, acc.: 53.91%] [G loss: 0.860502]\n",
      "epoch:38 step:29923 [D loss: 0.719014, acc.: 47.66%] [G loss: 0.752050]\n",
      "epoch:38 step:29924 [D loss: 0.680795, acc.: 58.59%] [G loss: 0.842872]\n",
      "epoch:38 step:29925 [D loss: 0.683722, acc.: 55.47%] [G loss: 0.820988]\n",
      "epoch:38 step:29926 [D loss: 0.663040, acc.: 62.50%] [G loss: 0.790949]\n",
      "epoch:38 step:29927 [D loss: 0.691538, acc.: 50.00%] [G loss: 0.821324]\n",
      "epoch:38 step:29928 [D loss: 0.617547, acc.: 70.31%] [G loss: 0.833859]\n",
      "epoch:38 step:29929 [D loss: 0.618253, acc.: 64.84%] [G loss: 0.811335]\n",
      "epoch:38 step:29930 [D loss: 0.724099, acc.: 52.34%] [G loss: 0.843540]\n",
      "epoch:38 step:29931 [D loss: 0.704590, acc.: 50.78%] [G loss: 0.797224]\n",
      "epoch:38 step:29932 [D loss: 0.745042, acc.: 42.19%] [G loss: 0.841936]\n",
      "epoch:38 step:29933 [D loss: 0.675204, acc.: 57.81%] [G loss: 0.761961]\n",
      "epoch:38 step:29934 [D loss: 0.662014, acc.: 60.94%] [G loss: 0.786530]\n",
      "epoch:38 step:29935 [D loss: 0.695141, acc.: 52.34%] [G loss: 0.743677]\n",
      "epoch:38 step:29936 [D loss: 0.747028, acc.: 42.19%] [G loss: 0.768974]\n",
      "epoch:38 step:29937 [D loss: 0.686152, acc.: 55.47%] [G loss: 0.738271]\n",
      "epoch:38 step:29938 [D loss: 0.745566, acc.: 45.31%] [G loss: 0.813222]\n",
      "epoch:38 step:29939 [D loss: 0.624564, acc.: 67.19%] [G loss: 0.807825]\n",
      "epoch:38 step:29940 [D loss: 0.655740, acc.: 60.94%] [G loss: 0.834220]\n",
      "epoch:38 step:29941 [D loss: 0.718128, acc.: 42.19%] [G loss: 0.842656]\n",
      "epoch:38 step:29942 [D loss: 0.704530, acc.: 52.34%] [G loss: 0.865032]\n",
      "epoch:38 step:29943 [D loss: 0.673595, acc.: 52.34%] [G loss: 0.894812]\n",
      "epoch:38 step:29944 [D loss: 0.638868, acc.: 67.97%] [G loss: 0.856543]\n",
      "epoch:38 step:29945 [D loss: 0.767433, acc.: 46.88%] [G loss: 0.879842]\n",
      "epoch:38 step:29946 [D loss: 0.677295, acc.: 49.22%] [G loss: 0.779956]\n",
      "epoch:38 step:29947 [D loss: 0.633451, acc.: 69.53%] [G loss: 0.766362]\n",
      "epoch:38 step:29948 [D loss: 0.726375, acc.: 46.88%] [G loss: 0.750608]\n",
      "epoch:38 step:29949 [D loss: 0.702308, acc.: 51.56%] [G loss: 0.844297]\n",
      "epoch:38 step:29950 [D loss: 0.631525, acc.: 67.19%] [G loss: 0.822462]\n",
      "epoch:38 step:29951 [D loss: 0.693042, acc.: 56.25%] [G loss: 0.784695]\n",
      "epoch:38 step:29952 [D loss: 0.660504, acc.: 57.81%] [G loss: 0.838331]\n",
      "epoch:38 step:29953 [D loss: 0.692158, acc.: 55.47%] [G loss: 0.841205]\n",
      "epoch:38 step:29954 [D loss: 0.721241, acc.: 46.88%] [G loss: 0.747309]\n",
      "epoch:38 step:29955 [D loss: 0.729088, acc.: 46.88%] [G loss: 0.829859]\n",
      "epoch:38 step:29956 [D loss: 0.653049, acc.: 64.84%] [G loss: 0.863936]\n",
      "epoch:38 step:29957 [D loss: 0.668451, acc.: 58.59%] [G loss: 0.798960]\n",
      "epoch:38 step:29958 [D loss: 0.670214, acc.: 54.69%] [G loss: 0.764480]\n",
      "epoch:38 step:29959 [D loss: 0.660025, acc.: 60.94%] [G loss: 0.741010]\n",
      "epoch:38 step:29960 [D loss: 0.715353, acc.: 50.00%] [G loss: 0.777677]\n",
      "epoch:38 step:29961 [D loss: 0.700264, acc.: 52.34%] [G loss: 0.767931]\n",
      "epoch:38 step:29962 [D loss: 0.652969, acc.: 61.72%] [G loss: 0.773108]\n",
      "epoch:38 step:29963 [D loss: 0.629727, acc.: 67.19%] [G loss: 0.773048]\n",
      "epoch:38 step:29964 [D loss: 0.630794, acc.: 68.75%] [G loss: 0.820020]\n",
      "epoch:38 step:29965 [D loss: 0.672682, acc.: 60.94%] [G loss: 0.808847]\n",
      "epoch:38 step:29966 [D loss: 0.680055, acc.: 57.81%] [G loss: 0.787352]\n",
      "epoch:38 step:29967 [D loss: 0.764108, acc.: 38.28%] [G loss: 0.822631]\n",
      "epoch:38 step:29968 [D loss: 0.713681, acc.: 46.88%] [G loss: 0.729055]\n",
      "epoch:38 step:29969 [D loss: 0.702039, acc.: 50.78%] [G loss: 0.774629]\n",
      "epoch:38 step:29970 [D loss: 0.688640, acc.: 54.69%] [G loss: 0.771714]\n",
      "epoch:38 step:29971 [D loss: 0.677895, acc.: 57.03%] [G loss: 0.797461]\n",
      "epoch:38 step:29972 [D loss: 0.637342, acc.: 66.41%] [G loss: 0.772831]\n",
      "epoch:38 step:29973 [D loss: 0.736437, acc.: 43.75%] [G loss: 0.762838]\n",
      "epoch:38 step:29974 [D loss: 0.674994, acc.: 62.50%] [G loss: 0.797601]\n",
      "epoch:38 step:29975 [D loss: 0.685637, acc.: 53.12%] [G loss: 0.762551]\n",
      "epoch:38 step:29976 [D loss: 0.709927, acc.: 53.12%] [G loss: 0.786530]\n",
      "epoch:38 step:29977 [D loss: 0.712861, acc.: 50.78%] [G loss: 0.837334]\n",
      "epoch:38 step:29978 [D loss: 0.662133, acc.: 59.38%] [G loss: 0.810528]\n",
      "epoch:38 step:29979 [D loss: 0.742651, acc.: 39.84%] [G loss: 0.785896]\n",
      "epoch:38 step:29980 [D loss: 0.695006, acc.: 50.00%] [G loss: 0.788257]\n",
      "epoch:38 step:29981 [D loss: 0.663539, acc.: 59.38%] [G loss: 0.776965]\n",
      "epoch:38 step:29982 [D loss: 0.676810, acc.: 54.69%] [G loss: 0.773078]\n",
      "epoch:38 step:29983 [D loss: 0.729864, acc.: 43.75%] [G loss: 0.818235]\n",
      "epoch:38 step:29984 [D loss: 0.702691, acc.: 53.12%] [G loss: 0.758190]\n",
      "epoch:38 step:29985 [D loss: 0.663045, acc.: 59.38%] [G loss: 0.812917]\n",
      "epoch:38 step:29986 [D loss: 0.752186, acc.: 46.09%] [G loss: 0.785212]\n",
      "epoch:38 step:29987 [D loss: 0.710911, acc.: 51.56%] [G loss: 0.716598]\n",
      "epoch:38 step:29988 [D loss: 0.674552, acc.: 59.38%] [G loss: 0.910245]\n",
      "epoch:38 step:29989 [D loss: 0.695042, acc.: 50.00%] [G loss: 0.749895]\n",
      "epoch:38 step:29990 [D loss: 0.738622, acc.: 44.53%] [G loss: 0.781999]\n",
      "epoch:38 step:29991 [D loss: 0.738992, acc.: 38.28%] [G loss: 0.774940]\n",
      "epoch:38 step:29992 [D loss: 0.718793, acc.: 42.19%] [G loss: 0.746750]\n",
      "epoch:38 step:29993 [D loss: 0.716619, acc.: 47.66%] [G loss: 0.813431]\n",
      "epoch:38 step:29994 [D loss: 0.677915, acc.: 60.94%] [G loss: 0.708426]\n",
      "epoch:38 step:29995 [D loss: 0.716489, acc.: 42.97%] [G loss: 0.756972]\n",
      "epoch:38 step:29996 [D loss: 0.707366, acc.: 53.91%] [G loss: 0.730601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29997 [D loss: 0.653637, acc.: 63.28%] [G loss: 0.836897]\n",
      "epoch:38 step:29998 [D loss: 0.685834, acc.: 57.81%] [G loss: 0.851265]\n",
      "epoch:38 step:29999 [D loss: 0.700860, acc.: 45.31%] [G loss: 0.732917]\n",
      "epoch:38 step:30000 [D loss: 0.780076, acc.: 34.38%] [G loss: 0.733913]\n",
      "epoch:38 step:30001 [D loss: 0.666219, acc.: 61.72%] [G loss: 0.770728]\n",
      "epoch:38 step:30002 [D loss: 0.684443, acc.: 56.25%] [G loss: 0.739935]\n",
      "epoch:38 step:30003 [D loss: 0.631494, acc.: 67.97%] [G loss: 0.779865]\n",
      "epoch:38 step:30004 [D loss: 0.660221, acc.: 59.38%] [G loss: 0.830272]\n",
      "epoch:38 step:30005 [D loss: 0.709110, acc.: 50.78%] [G loss: 0.859843]\n",
      "epoch:38 step:30006 [D loss: 0.673160, acc.: 60.16%] [G loss: 0.806867]\n",
      "epoch:38 step:30007 [D loss: 0.723385, acc.: 53.12%] [G loss: 0.783051]\n",
      "epoch:38 step:30008 [D loss: 0.693601, acc.: 55.47%] [G loss: 0.747946]\n",
      "epoch:38 step:30009 [D loss: 0.724037, acc.: 44.53%] [G loss: 0.730557]\n",
      "epoch:38 step:30010 [D loss: 0.690798, acc.: 48.44%] [G loss: 0.739535]\n",
      "epoch:38 step:30011 [D loss: 0.701881, acc.: 49.22%] [G loss: 0.780750]\n",
      "epoch:38 step:30012 [D loss: 0.684998, acc.: 56.25%] [G loss: 0.733702]\n",
      "epoch:38 step:30013 [D loss: 0.667555, acc.: 63.28%] [G loss: 0.813559]\n",
      "epoch:38 step:30014 [D loss: 0.636983, acc.: 62.50%] [G loss: 0.787112]\n",
      "epoch:38 step:30015 [D loss: 0.674039, acc.: 52.34%] [G loss: 0.806529]\n",
      "epoch:38 step:30016 [D loss: 0.712296, acc.: 50.00%] [G loss: 0.738081]\n",
      "epoch:38 step:30017 [D loss: 0.686130, acc.: 53.12%] [G loss: 0.699060]\n",
      "epoch:38 step:30018 [D loss: 0.722107, acc.: 50.78%] [G loss: 0.709930]\n",
      "epoch:38 step:30019 [D loss: 0.698381, acc.: 54.69%] [G loss: 0.748597]\n",
      "epoch:38 step:30020 [D loss: 0.670433, acc.: 61.72%] [G loss: 0.834859]\n",
      "epoch:38 step:30021 [D loss: 0.647382, acc.: 61.72%] [G loss: 0.829982]\n",
      "epoch:38 step:30022 [D loss: 0.672741, acc.: 57.03%] [G loss: 0.768544]\n",
      "epoch:38 step:30023 [D loss: 0.699131, acc.: 51.56%] [G loss: 0.744730]\n",
      "epoch:38 step:30024 [D loss: 0.682416, acc.: 57.03%] [G loss: 0.829083]\n",
      "epoch:38 step:30025 [D loss: 0.699246, acc.: 46.09%] [G loss: 0.745466]\n",
      "epoch:38 step:30026 [D loss: 0.708291, acc.: 53.12%] [G loss: 0.776309]\n",
      "epoch:38 step:30027 [D loss: 0.649195, acc.: 60.16%] [G loss: 0.856492]\n",
      "epoch:38 step:30028 [D loss: 0.705856, acc.: 47.66%] [G loss: 0.888786]\n",
      "epoch:38 step:30029 [D loss: 0.681619, acc.: 55.47%] [G loss: 0.804928]\n",
      "epoch:38 step:30030 [D loss: 0.654645, acc.: 62.50%] [G loss: 0.890009]\n",
      "epoch:38 step:30031 [D loss: 0.652113, acc.: 62.50%] [G loss: 0.837925]\n",
      "epoch:38 step:30032 [D loss: 0.700536, acc.: 54.69%] [G loss: 0.771582]\n",
      "epoch:38 step:30033 [D loss: 0.615434, acc.: 70.31%] [G loss: 0.853597]\n",
      "epoch:38 step:30034 [D loss: 0.667098, acc.: 59.38%] [G loss: 0.934031]\n",
      "epoch:38 step:30035 [D loss: 0.619047, acc.: 68.75%] [G loss: 0.862486]\n",
      "epoch:38 step:30036 [D loss: 0.683645, acc.: 48.44%] [G loss: 0.846535]\n",
      "epoch:38 step:30037 [D loss: 0.700817, acc.: 50.00%] [G loss: 0.813035]\n",
      "epoch:38 step:30038 [D loss: 0.664277, acc.: 57.81%] [G loss: 0.825226]\n",
      "epoch:38 step:30039 [D loss: 0.656429, acc.: 52.34%] [G loss: 0.823205]\n",
      "epoch:38 step:30040 [D loss: 0.671708, acc.: 58.59%] [G loss: 0.813628]\n",
      "epoch:38 step:30041 [D loss: 0.731849, acc.: 43.75%] [G loss: 0.784877]\n",
      "epoch:38 step:30042 [D loss: 0.732660, acc.: 42.19%] [G loss: 0.770081]\n",
      "epoch:38 step:30043 [D loss: 0.695727, acc.: 54.69%] [G loss: 0.755111]\n",
      "epoch:38 step:30044 [D loss: 0.665134, acc.: 60.16%] [G loss: 0.770643]\n",
      "epoch:38 step:30045 [D loss: 0.645213, acc.: 62.50%] [G loss: 0.783337]\n",
      "epoch:38 step:30046 [D loss: 0.677828, acc.: 56.25%] [G loss: 0.807833]\n",
      "epoch:38 step:30047 [D loss: 0.726804, acc.: 48.44%] [G loss: 0.803953]\n",
      "epoch:38 step:30048 [D loss: 0.687814, acc.: 53.91%] [G loss: 0.743653]\n",
      "epoch:38 step:30049 [D loss: 0.661308, acc.: 61.72%] [G loss: 0.792965]\n",
      "epoch:38 step:30050 [D loss: 0.672229, acc.: 58.59%] [G loss: 0.832937]\n",
      "epoch:38 step:30051 [D loss: 0.689724, acc.: 51.56%] [G loss: 0.814210]\n",
      "epoch:38 step:30052 [D loss: 0.708147, acc.: 50.78%] [G loss: 0.808224]\n",
      "epoch:38 step:30053 [D loss: 0.658545, acc.: 65.62%] [G loss: 0.800027]\n",
      "epoch:38 step:30054 [D loss: 0.701019, acc.: 50.00%] [G loss: 0.766369]\n",
      "epoch:38 step:30055 [D loss: 0.659820, acc.: 63.28%] [G loss: 0.869819]\n",
      "epoch:38 step:30056 [D loss: 0.641361, acc.: 66.41%] [G loss: 0.856799]\n",
      "epoch:38 step:30057 [D loss: 0.638332, acc.: 66.41%] [G loss: 0.871015]\n",
      "epoch:38 step:30058 [D loss: 0.708332, acc.: 53.12%] [G loss: 0.854983]\n",
      "epoch:38 step:30059 [D loss: 0.663104, acc.: 62.50%] [G loss: 0.830000]\n",
      "epoch:38 step:30060 [D loss: 0.712457, acc.: 43.75%] [G loss: 0.777913]\n",
      "epoch:38 step:30061 [D loss: 0.611632, acc.: 70.31%] [G loss: 0.850862]\n",
      "epoch:38 step:30062 [D loss: 0.644505, acc.: 66.41%] [G loss: 0.741954]\n",
      "epoch:38 step:30063 [D loss: 0.744452, acc.: 35.94%] [G loss: 0.684826]\n",
      "epoch:38 step:30064 [D loss: 0.667178, acc.: 60.16%] [G loss: 0.739133]\n",
      "epoch:38 step:30065 [D loss: 0.664639, acc.: 59.38%] [G loss: 0.822713]\n",
      "epoch:38 step:30066 [D loss: 0.663661, acc.: 62.50%] [G loss: 0.893231]\n",
      "epoch:38 step:30067 [D loss: 0.638386, acc.: 64.06%] [G loss: 0.869570]\n",
      "epoch:38 step:30068 [D loss: 0.632704, acc.: 64.06%] [G loss: 0.819180]\n",
      "epoch:38 step:30069 [D loss: 0.715945, acc.: 46.09%] [G loss: 0.799984]\n",
      "epoch:38 step:30070 [D loss: 0.761536, acc.: 35.16%] [G loss: 0.786150]\n",
      "epoch:38 step:30071 [D loss: 0.665608, acc.: 63.28%] [G loss: 0.646389]\n",
      "epoch:38 step:30072 [D loss: 0.611777, acc.: 75.78%] [G loss: 0.744949]\n",
      "epoch:38 step:30073 [D loss: 0.711626, acc.: 46.88%] [G loss: 0.695366]\n",
      "epoch:38 step:30074 [D loss: 0.692571, acc.: 53.91%] [G loss: 0.786516]\n",
      "epoch:38 step:30075 [D loss: 0.656201, acc.: 65.62%] [G loss: 0.775589]\n",
      "epoch:38 step:30076 [D loss: 0.703870, acc.: 50.78%] [G loss: 0.815725]\n",
      "epoch:38 step:30077 [D loss: 0.647239, acc.: 68.75%] [G loss: 0.753268]\n",
      "epoch:38 step:30078 [D loss: 0.668784, acc.: 57.81%] [G loss: 0.810722]\n",
      "epoch:38 step:30079 [D loss: 0.626186, acc.: 70.31%] [G loss: 0.701671]\n",
      "epoch:38 step:30080 [D loss: 0.644942, acc.: 65.62%] [G loss: 0.735491]\n",
      "epoch:38 step:30081 [D loss: 0.662877, acc.: 60.16%] [G loss: 0.817662]\n",
      "epoch:38 step:30082 [D loss: 0.656469, acc.: 71.88%] [G loss: 0.824477]\n",
      "epoch:38 step:30083 [D loss: 0.697492, acc.: 52.34%] [G loss: 0.776284]\n",
      "epoch:38 step:30084 [D loss: 0.696806, acc.: 51.56%] [G loss: 0.805296]\n",
      "epoch:38 step:30085 [D loss: 0.615880, acc.: 71.09%] [G loss: 0.783375]\n",
      "epoch:38 step:30086 [D loss: 0.707580, acc.: 50.00%] [G loss: 0.804658]\n",
      "epoch:38 step:30087 [D loss: 0.679339, acc.: 54.69%] [G loss: 0.789596]\n",
      "epoch:38 step:30088 [D loss: 0.665947, acc.: 60.94%] [G loss: 0.784062]\n",
      "epoch:38 step:30089 [D loss: 0.764592, acc.: 42.19%] [G loss: 0.751254]\n",
      "epoch:38 step:30090 [D loss: 0.686733, acc.: 53.12%] [G loss: 0.732981]\n",
      "epoch:38 step:30091 [D loss: 0.700936, acc.: 50.00%] [G loss: 0.742270]\n",
      "epoch:38 step:30092 [D loss: 0.696602, acc.: 51.56%] [G loss: 0.826130]\n",
      "epoch:38 step:30093 [D loss: 0.641635, acc.: 65.62%] [G loss: 0.804547]\n",
      "epoch:38 step:30094 [D loss: 0.678228, acc.: 57.03%] [G loss: 0.678730]\n",
      "epoch:38 step:30095 [D loss: 0.669965, acc.: 60.94%] [G loss: 0.816561]\n",
      "epoch:38 step:30096 [D loss: 0.657359, acc.: 63.28%] [G loss: 0.825960]\n",
      "epoch:38 step:30097 [D loss: 0.686497, acc.: 56.25%] [G loss: 0.666677]\n",
      "epoch:38 step:30098 [D loss: 0.724689, acc.: 50.78%] [G loss: 0.802696]\n",
      "epoch:38 step:30099 [D loss: 0.709001, acc.: 44.53%] [G loss: 0.721178]\n",
      "epoch:38 step:30100 [D loss: 0.691999, acc.: 56.25%] [G loss: 0.827092]\n",
      "epoch:38 step:30101 [D loss: 0.657186, acc.: 64.84%] [G loss: 0.766527]\n",
      "epoch:38 step:30102 [D loss: 0.674878, acc.: 58.59%] [G loss: 0.837454]\n",
      "epoch:38 step:30103 [D loss: 0.623957, acc.: 69.53%] [G loss: 0.822465]\n",
      "epoch:38 step:30104 [D loss: 0.695322, acc.: 47.66%] [G loss: 0.772762]\n",
      "epoch:38 step:30105 [D loss: 0.737660, acc.: 42.97%] [G loss: 0.809134]\n",
      "epoch:38 step:30106 [D loss: 0.678442, acc.: 59.38%] [G loss: 0.812023]\n",
      "epoch:38 step:30107 [D loss: 0.654545, acc.: 60.94%] [G loss: 0.713840]\n",
      "epoch:38 step:30108 [D loss: 0.636883, acc.: 64.84%] [G loss: 0.818597]\n",
      "epoch:38 step:30109 [D loss: 0.747855, acc.: 32.03%] [G loss: 0.732592]\n",
      "epoch:38 step:30110 [D loss: 0.665250, acc.: 63.28%] [G loss: 0.834130]\n",
      "epoch:38 step:30111 [D loss: 0.703980, acc.: 53.12%] [G loss: 0.835540]\n",
      "epoch:38 step:30112 [D loss: 0.683888, acc.: 58.59%] [G loss: 0.877534]\n",
      "epoch:38 step:30113 [D loss: 0.702726, acc.: 52.34%] [G loss: 0.740325]\n",
      "epoch:38 step:30114 [D loss: 0.755017, acc.: 34.38%] [G loss: 0.740338]\n",
      "epoch:38 step:30115 [D loss: 0.700272, acc.: 56.25%] [G loss: 0.764488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30116 [D loss: 0.627218, acc.: 63.28%] [G loss: 0.794752]\n",
      "epoch:38 step:30117 [D loss: 0.721775, acc.: 42.19%] [G loss: 0.731554]\n",
      "epoch:38 step:30118 [D loss: 0.745381, acc.: 39.06%] [G loss: 0.787568]\n",
      "epoch:38 step:30119 [D loss: 0.691506, acc.: 51.56%] [G loss: 0.764597]\n",
      "epoch:38 step:30120 [D loss: 0.749078, acc.: 38.28%] [G loss: 0.752176]\n",
      "epoch:38 step:30121 [D loss: 0.665981, acc.: 60.94%] [G loss: 0.774830]\n",
      "epoch:38 step:30122 [D loss: 0.699386, acc.: 54.69%] [G loss: 0.779350]\n",
      "epoch:38 step:30123 [D loss: 0.686188, acc.: 52.34%] [G loss: 0.722703]\n",
      "epoch:38 step:30124 [D loss: 0.715671, acc.: 48.44%] [G loss: 0.804536]\n",
      "epoch:38 step:30125 [D loss: 0.712892, acc.: 49.22%] [G loss: 0.760257]\n",
      "epoch:38 step:30126 [D loss: 0.707412, acc.: 50.78%] [G loss: 0.714606]\n",
      "epoch:38 step:30127 [D loss: 0.709568, acc.: 54.69%] [G loss: 0.697320]\n",
      "epoch:38 step:30128 [D loss: 0.664380, acc.: 59.38%] [G loss: 0.807406]\n",
      "epoch:38 step:30129 [D loss: 0.699073, acc.: 57.81%] [G loss: 0.777380]\n",
      "epoch:38 step:30130 [D loss: 0.645848, acc.: 64.06%] [G loss: 0.897067]\n",
      "epoch:38 step:30131 [D loss: 0.681751, acc.: 52.34%] [G loss: 0.847964]\n",
      "epoch:38 step:30132 [D loss: 0.722412, acc.: 46.09%] [G loss: 0.857111]\n",
      "epoch:38 step:30133 [D loss: 0.677520, acc.: 59.38%] [G loss: 0.767533]\n",
      "epoch:38 step:30134 [D loss: 0.694639, acc.: 57.81%] [G loss: 0.834493]\n",
      "epoch:38 step:30135 [D loss: 0.699777, acc.: 50.78%] [G loss: 0.778099]\n",
      "epoch:38 step:30136 [D loss: 0.662066, acc.: 61.72%] [G loss: 0.787168]\n",
      "epoch:38 step:30137 [D loss: 0.761419, acc.: 41.41%] [G loss: 0.729683]\n",
      "epoch:38 step:30138 [D loss: 0.716105, acc.: 47.66%] [G loss: 0.772618]\n",
      "epoch:38 step:30139 [D loss: 0.698877, acc.: 55.47%] [G loss: 0.834665]\n",
      "epoch:38 step:30140 [D loss: 0.680024, acc.: 56.25%] [G loss: 0.782441]\n",
      "epoch:38 step:30141 [D loss: 0.711186, acc.: 55.47%] [G loss: 0.861977]\n",
      "epoch:38 step:30142 [D loss: 0.680280, acc.: 60.16%] [G loss: 0.792767]\n",
      "epoch:38 step:30143 [D loss: 0.685827, acc.: 59.38%] [G loss: 0.807821]\n",
      "epoch:38 step:30144 [D loss: 0.628833, acc.: 68.75%] [G loss: 0.850694]\n",
      "epoch:38 step:30145 [D loss: 0.675665, acc.: 56.25%] [G loss: 0.808899]\n",
      "epoch:38 step:30146 [D loss: 0.656177, acc.: 61.72%] [G loss: 0.879127]\n",
      "epoch:38 step:30147 [D loss: 0.623267, acc.: 67.19%] [G loss: 0.902835]\n",
      "epoch:38 step:30148 [D loss: 0.684104, acc.: 53.91%] [G loss: 0.770320]\n",
      "epoch:38 step:30149 [D loss: 0.742299, acc.: 43.75%] [G loss: 0.768791]\n",
      "epoch:38 step:30150 [D loss: 0.700547, acc.: 53.12%] [G loss: 0.852580]\n",
      "epoch:38 step:30151 [D loss: 0.757020, acc.: 49.22%] [G loss: 0.882546]\n",
      "epoch:38 step:30152 [D loss: 0.676127, acc.: 53.91%] [G loss: 0.858467]\n",
      "epoch:38 step:30153 [D loss: 0.685146, acc.: 57.81%] [G loss: 0.709364]\n",
      "epoch:38 step:30154 [D loss: 0.613773, acc.: 70.31%] [G loss: 0.806221]\n",
      "epoch:38 step:30155 [D loss: 0.695544, acc.: 64.06%] [G loss: 0.800413]\n",
      "epoch:38 step:30156 [D loss: 0.640181, acc.: 65.62%] [G loss: 0.849878]\n",
      "epoch:38 step:30157 [D loss: 0.672032, acc.: 61.72%] [G loss: 0.790530]\n",
      "epoch:38 step:30158 [D loss: 0.637887, acc.: 67.97%] [G loss: 0.784595]\n",
      "epoch:38 step:30159 [D loss: 0.695544, acc.: 53.12%] [G loss: 0.855709]\n",
      "epoch:38 step:30160 [D loss: 0.703983, acc.: 53.12%] [G loss: 0.782987]\n",
      "epoch:38 step:30161 [D loss: 0.672727, acc.: 59.38%] [G loss: 0.889654]\n",
      "epoch:38 step:30162 [D loss: 0.691579, acc.: 56.25%] [G loss: 0.751276]\n",
      "epoch:38 step:30163 [D loss: 0.720648, acc.: 49.22%] [G loss: 0.695761]\n",
      "epoch:38 step:30164 [D loss: 0.691667, acc.: 56.25%] [G loss: 0.750576]\n",
      "epoch:38 step:30165 [D loss: 0.663007, acc.: 60.16%] [G loss: 0.784565]\n",
      "epoch:38 step:30166 [D loss: 0.730425, acc.: 42.97%] [G loss: 0.820413]\n",
      "epoch:38 step:30167 [D loss: 0.710127, acc.: 54.69%] [G loss: 0.708571]\n",
      "epoch:38 step:30168 [D loss: 0.654658, acc.: 64.84%] [G loss: 0.737702]\n",
      "epoch:38 step:30169 [D loss: 0.702081, acc.: 50.78%] [G loss: 0.819795]\n",
      "epoch:38 step:30170 [D loss: 0.715165, acc.: 53.91%] [G loss: 0.751162]\n",
      "epoch:38 step:30171 [D loss: 0.773031, acc.: 36.72%] [G loss: 0.746098]\n",
      "epoch:38 step:30172 [D loss: 0.669601, acc.: 57.81%] [G loss: 0.736802]\n",
      "epoch:38 step:30173 [D loss: 0.621003, acc.: 67.97%] [G loss: 0.826377]\n",
      "epoch:38 step:30174 [D loss: 0.708390, acc.: 49.22%] [G loss: 0.760216]\n",
      "epoch:38 step:30175 [D loss: 0.692716, acc.: 52.34%] [G loss: 0.727393]\n",
      "epoch:38 step:30176 [D loss: 0.650346, acc.: 64.84%] [G loss: 0.860607]\n",
      "epoch:38 step:30177 [D loss: 0.627604, acc.: 71.88%] [G loss: 0.734531]\n",
      "epoch:38 step:30178 [D loss: 0.702342, acc.: 49.22%] [G loss: 0.790161]\n",
      "epoch:38 step:30179 [D loss: 0.676540, acc.: 57.03%] [G loss: 0.842029]\n",
      "epoch:38 step:30180 [D loss: 0.643025, acc.: 65.62%] [G loss: 0.810384]\n",
      "epoch:38 step:30181 [D loss: 0.719785, acc.: 46.09%] [G loss: 0.788591]\n",
      "epoch:38 step:30182 [D loss: 0.687690, acc.: 53.12%] [G loss: 0.813846]\n",
      "epoch:38 step:30183 [D loss: 0.669425, acc.: 60.16%] [G loss: 0.802692]\n",
      "epoch:38 step:30184 [D loss: 0.650426, acc.: 60.16%] [G loss: 0.764880]\n",
      "epoch:38 step:30185 [D loss: 0.614027, acc.: 75.78%] [G loss: 0.732438]\n",
      "epoch:38 step:30186 [D loss: 0.653759, acc.: 62.50%] [G loss: 0.812583]\n",
      "epoch:38 step:30187 [D loss: 0.731335, acc.: 45.31%] [G loss: 0.838294]\n",
      "epoch:38 step:30188 [D loss: 0.686666, acc.: 53.12%] [G loss: 0.759830]\n",
      "epoch:38 step:30189 [D loss: 0.698600, acc.: 51.56%] [G loss: 0.770669]\n",
      "epoch:38 step:30190 [D loss: 0.680736, acc.: 57.81%] [G loss: 0.829866]\n",
      "epoch:38 step:30191 [D loss: 0.735604, acc.: 46.88%] [G loss: 0.754174]\n",
      "epoch:38 step:30192 [D loss: 0.705850, acc.: 53.12%] [G loss: 0.745957]\n",
      "epoch:38 step:30193 [D loss: 0.684614, acc.: 53.12%] [G loss: 0.687223]\n",
      "epoch:38 step:30194 [D loss: 0.614775, acc.: 71.88%] [G loss: 0.735731]\n",
      "epoch:38 step:30195 [D loss: 0.680947, acc.: 50.78%] [G loss: 0.787926]\n",
      "epoch:38 step:30196 [D loss: 0.622506, acc.: 71.88%] [G loss: 0.822080]\n",
      "epoch:38 step:30197 [D loss: 0.726511, acc.: 51.56%] [G loss: 0.782182]\n",
      "epoch:38 step:30198 [D loss: 0.745153, acc.: 42.19%] [G loss: 0.687142]\n",
      "epoch:38 step:30199 [D loss: 0.672001, acc.: 60.16%] [G loss: 0.821988]\n",
      "epoch:38 step:30200 [D loss: 0.723299, acc.: 49.22%] [G loss: 0.788906]\n",
      "epoch:38 step:30201 [D loss: 0.670451, acc.: 60.16%] [G loss: 0.772117]\n",
      "epoch:38 step:30202 [D loss: 0.729194, acc.: 44.53%] [G loss: 0.790572]\n",
      "epoch:38 step:30203 [D loss: 0.674697, acc.: 58.59%] [G loss: 0.750650]\n",
      "epoch:38 step:30204 [D loss: 0.709344, acc.: 47.66%] [G loss: 0.819509]\n",
      "epoch:38 step:30205 [D loss: 0.671374, acc.: 61.72%] [G loss: 0.713809]\n",
      "epoch:38 step:30206 [D loss: 0.698920, acc.: 51.56%] [G loss: 0.756477]\n",
      "epoch:38 step:30207 [D loss: 0.693444, acc.: 54.69%] [G loss: 0.777603]\n",
      "epoch:38 step:30208 [D loss: 0.611814, acc.: 73.44%] [G loss: 0.780062]\n",
      "epoch:38 step:30209 [D loss: 0.604091, acc.: 76.56%] [G loss: 0.821694]\n",
      "epoch:38 step:30210 [D loss: 0.656055, acc.: 65.62%] [G loss: 0.712687]\n",
      "epoch:38 step:30211 [D loss: 0.691738, acc.: 46.88%] [G loss: 0.922752]\n",
      "epoch:38 step:30212 [D loss: 0.684366, acc.: 56.25%] [G loss: 0.748031]\n",
      "epoch:38 step:30213 [D loss: 0.656209, acc.: 63.28%] [G loss: 0.810837]\n",
      "epoch:38 step:30214 [D loss: 0.700174, acc.: 57.03%] [G loss: 0.725669]\n",
      "epoch:38 step:30215 [D loss: 0.713411, acc.: 51.56%] [G loss: 0.798824]\n",
      "epoch:38 step:30216 [D loss: 0.671929, acc.: 60.94%] [G loss: 0.740356]\n",
      "epoch:38 step:30217 [D loss: 0.711250, acc.: 49.22%] [G loss: 0.863708]\n",
      "epoch:38 step:30218 [D loss: 0.716046, acc.: 50.00%] [G loss: 0.872992]\n",
      "epoch:38 step:30219 [D loss: 0.651029, acc.: 60.94%] [G loss: 0.822839]\n",
      "epoch:38 step:30220 [D loss: 0.678702, acc.: 55.47%] [G loss: 0.835337]\n",
      "epoch:38 step:30221 [D loss: 0.672926, acc.: 53.91%] [G loss: 0.712137]\n",
      "epoch:38 step:30222 [D loss: 0.685526, acc.: 57.81%] [G loss: 0.875023]\n",
      "epoch:38 step:30223 [D loss: 0.658089, acc.: 62.50%] [G loss: 0.940877]\n",
      "epoch:38 step:30224 [D loss: 0.745004, acc.: 43.75%] [G loss: 0.794921]\n",
      "epoch:38 step:30225 [D loss: 0.706152, acc.: 50.00%] [G loss: 0.879352]\n",
      "epoch:38 step:30226 [D loss: 0.643963, acc.: 62.50%] [G loss: 0.893580]\n",
      "epoch:38 step:30227 [D loss: 0.676932, acc.: 53.91%] [G loss: 0.890888]\n",
      "epoch:38 step:30228 [D loss: 0.710416, acc.: 56.25%] [G loss: 0.767699]\n",
      "epoch:38 step:30229 [D loss: 0.664979, acc.: 57.03%] [G loss: 0.805049]\n",
      "epoch:38 step:30230 [D loss: 0.675041, acc.: 56.25%] [G loss: 0.780492]\n",
      "epoch:38 step:30231 [D loss: 0.672514, acc.: 57.03%] [G loss: 0.769358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30232 [D loss: 0.576529, acc.: 81.25%] [G loss: 0.797812]\n",
      "epoch:38 step:30233 [D loss: 0.651591, acc.: 76.56%] [G loss: 0.766821]\n",
      "epoch:38 step:30234 [D loss: 0.704466, acc.: 46.88%] [G loss: 0.694085]\n",
      "epoch:38 step:30235 [D loss: 0.677316, acc.: 60.16%] [G loss: 0.812209]\n",
      "epoch:38 step:30236 [D loss: 0.674058, acc.: 57.03%] [G loss: 0.778253]\n",
      "epoch:38 step:30237 [D loss: 0.629727, acc.: 71.88%] [G loss: 0.837660]\n",
      "epoch:38 step:30238 [D loss: 0.710341, acc.: 47.66%] [G loss: 0.759562]\n",
      "epoch:38 step:30239 [D loss: 0.670525, acc.: 57.81%] [G loss: 0.727859]\n",
      "epoch:38 step:30240 [D loss: 0.713620, acc.: 50.78%] [G loss: 0.790006]\n",
      "epoch:38 step:30241 [D loss: 0.724008, acc.: 48.44%] [G loss: 0.745237]\n",
      "epoch:38 step:30242 [D loss: 0.644211, acc.: 65.62%] [G loss: 0.730632]\n",
      "epoch:38 step:30243 [D loss: 0.674873, acc.: 63.28%] [G loss: 0.775602]\n",
      "epoch:38 step:30244 [D loss: 0.695101, acc.: 54.69%] [G loss: 0.729061]\n",
      "epoch:38 step:30245 [D loss: 0.686071, acc.: 54.69%] [G loss: 0.753940]\n",
      "epoch:38 step:30246 [D loss: 0.634659, acc.: 67.19%] [G loss: 0.785696]\n",
      "epoch:38 step:30247 [D loss: 0.645185, acc.: 66.41%] [G loss: 0.871779]\n",
      "epoch:38 step:30248 [D loss: 0.681658, acc.: 53.12%] [G loss: 0.776629]\n",
      "epoch:38 step:30249 [D loss: 0.670758, acc.: 61.72%] [G loss: 0.762732]\n",
      "epoch:38 step:30250 [D loss: 0.706641, acc.: 51.56%] [G loss: 0.722083]\n",
      "epoch:38 step:30251 [D loss: 0.694673, acc.: 53.91%] [G loss: 0.758431]\n",
      "epoch:38 step:30252 [D loss: 0.708200, acc.: 49.22%] [G loss: 0.759841]\n",
      "epoch:38 step:30253 [D loss: 0.773802, acc.: 35.16%] [G loss: 0.693824]\n",
      "epoch:38 step:30254 [D loss: 0.650811, acc.: 65.62%] [G loss: 0.791075]\n",
      "epoch:38 step:30255 [D loss: 0.693756, acc.: 59.38%] [G loss: 0.709071]\n",
      "epoch:38 step:30256 [D loss: 0.662382, acc.: 59.38%] [G loss: 0.820063]\n",
      "epoch:38 step:30257 [D loss: 0.677322, acc.: 54.69%] [G loss: 0.809405]\n",
      "epoch:38 step:30258 [D loss: 0.645967, acc.: 64.84%] [G loss: 0.767954]\n",
      "epoch:38 step:30259 [D loss: 0.721646, acc.: 42.97%] [G loss: 0.746362]\n",
      "epoch:38 step:30260 [D loss: 0.658934, acc.: 60.94%] [G loss: 0.733234]\n",
      "epoch:38 step:30261 [D loss: 0.667885, acc.: 60.94%] [G loss: 0.755501]\n",
      "epoch:38 step:30262 [D loss: 0.679545, acc.: 62.50%] [G loss: 0.772678]\n",
      "epoch:38 step:30263 [D loss: 0.612260, acc.: 76.56%] [G loss: 0.732035]\n",
      "epoch:38 step:30264 [D loss: 0.639623, acc.: 67.97%] [G loss: 0.744558]\n",
      "epoch:38 step:30265 [D loss: 0.640016, acc.: 67.97%] [G loss: 0.798739]\n",
      "epoch:38 step:30266 [D loss: 0.706899, acc.: 47.66%] [G loss: 0.780737]\n",
      "epoch:38 step:30267 [D loss: 0.691355, acc.: 50.78%] [G loss: 0.766878]\n",
      "epoch:38 step:30268 [D loss: 0.709253, acc.: 49.22%] [G loss: 0.743588]\n",
      "epoch:38 step:30269 [D loss: 0.712163, acc.: 51.56%] [G loss: 0.724178]\n",
      "epoch:38 step:30270 [D loss: 0.690697, acc.: 55.47%] [G loss: 0.764825]\n",
      "epoch:38 step:30271 [D loss: 0.745524, acc.: 35.94%] [G loss: 0.719151]\n",
      "epoch:38 step:30272 [D loss: 0.688540, acc.: 55.47%] [G loss: 0.715541]\n",
      "epoch:38 step:30273 [D loss: 0.636486, acc.: 64.84%] [G loss: 0.741481]\n",
      "epoch:38 step:30274 [D loss: 0.652689, acc.: 62.50%] [G loss: 0.755940]\n",
      "epoch:38 step:30275 [D loss: 0.708356, acc.: 53.12%] [G loss: 0.757757]\n",
      "epoch:38 step:30276 [D loss: 0.696416, acc.: 50.78%] [G loss: 0.785603]\n",
      "epoch:38 step:30277 [D loss: 0.694353, acc.: 53.91%] [G loss: 0.721064]\n",
      "epoch:38 step:30278 [D loss: 0.716182, acc.: 50.78%] [G loss: 0.864215]\n",
      "epoch:38 step:30279 [D loss: 0.615396, acc.: 71.88%] [G loss: 0.819607]\n",
      "epoch:38 step:30280 [D loss: 0.664543, acc.: 64.84%] [G loss: 0.691380]\n",
      "epoch:38 step:30281 [D loss: 0.696164, acc.: 52.34%] [G loss: 0.798076]\n",
      "epoch:38 step:30282 [D loss: 0.649866, acc.: 64.84%] [G loss: 0.837586]\n",
      "epoch:38 step:30283 [D loss: 0.700058, acc.: 52.34%] [G loss: 0.796641]\n",
      "epoch:38 step:30284 [D loss: 0.680214, acc.: 54.69%] [G loss: 0.848499]\n",
      "epoch:38 step:30285 [D loss: 0.680090, acc.: 56.25%] [G loss: 0.771534]\n",
      "epoch:38 step:30286 [D loss: 0.656992, acc.: 64.84%] [G loss: 0.778507]\n",
      "epoch:38 step:30287 [D loss: 0.717960, acc.: 45.31%] [G loss: 0.804291]\n",
      "epoch:38 step:30288 [D loss: 0.633674, acc.: 68.75%] [G loss: 0.824946]\n",
      "epoch:38 step:30289 [D loss: 0.725502, acc.: 49.22%] [G loss: 0.858483]\n",
      "epoch:38 step:30290 [D loss: 0.641909, acc.: 64.06%] [G loss: 0.803941]\n",
      "epoch:38 step:30291 [D loss: 0.762907, acc.: 42.97%] [G loss: 0.744141]\n",
      "epoch:38 step:30292 [D loss: 0.651096, acc.: 64.06%] [G loss: 0.698375]\n",
      "epoch:38 step:30293 [D loss: 0.677414, acc.: 59.38%] [G loss: 0.739520]\n",
      "epoch:38 step:30294 [D loss: 0.709526, acc.: 51.56%] [G loss: 0.804425]\n",
      "epoch:38 step:30295 [D loss: 0.695332, acc.: 53.12%] [G loss: 0.746294]\n",
      "epoch:38 step:30296 [D loss: 0.608296, acc.: 78.12%] [G loss: 0.871020]\n",
      "epoch:38 step:30297 [D loss: 0.673801, acc.: 58.59%] [G loss: 0.746830]\n",
      "epoch:38 step:30298 [D loss: 0.735948, acc.: 40.62%] [G loss: 0.756100]\n",
      "epoch:38 step:30299 [D loss: 0.710421, acc.: 49.22%] [G loss: 0.835814]\n",
      "epoch:38 step:30300 [D loss: 0.692894, acc.: 52.34%] [G loss: 0.824365]\n",
      "epoch:38 step:30301 [D loss: 0.667868, acc.: 60.94%] [G loss: 0.812476]\n",
      "epoch:38 step:30302 [D loss: 0.730169, acc.: 43.75%] [G loss: 0.849511]\n",
      "epoch:38 step:30303 [D loss: 0.674906, acc.: 60.94%] [G loss: 0.934869]\n",
      "epoch:38 step:30304 [D loss: 0.690336, acc.: 60.94%] [G loss: 0.846504]\n",
      "epoch:38 step:30305 [D loss: 0.712142, acc.: 47.66%] [G loss: 0.814418]\n",
      "epoch:38 step:30306 [D loss: 0.673084, acc.: 62.50%] [G loss: 0.800326]\n",
      "epoch:38 step:30307 [D loss: 0.715763, acc.: 44.53%] [G loss: 0.804632]\n",
      "epoch:38 step:30308 [D loss: 0.660502, acc.: 65.62%] [G loss: 0.731398]\n",
      "epoch:38 step:30309 [D loss: 0.727855, acc.: 36.72%] [G loss: 0.812968]\n",
      "epoch:38 step:30310 [D loss: 0.644926, acc.: 67.97%] [G loss: 0.768985]\n",
      "epoch:38 step:30311 [D loss: 0.662504, acc.: 57.03%] [G loss: 0.743876]\n",
      "epoch:38 step:30312 [D loss: 0.638798, acc.: 64.84%] [G loss: 0.870893]\n",
      "epoch:38 step:30313 [D loss: 0.701344, acc.: 49.22%] [G loss: 0.690802]\n",
      "epoch:38 step:30314 [D loss: 0.694812, acc.: 54.69%] [G loss: 0.824221]\n",
      "epoch:38 step:30315 [D loss: 0.709249, acc.: 54.69%] [G loss: 0.736764]\n",
      "epoch:38 step:30316 [D loss: 0.725261, acc.: 51.56%] [G loss: 0.739808]\n",
      "epoch:38 step:30317 [D loss: 0.630602, acc.: 71.09%] [G loss: 0.812483]\n",
      "epoch:38 step:30318 [D loss: 0.703900, acc.: 48.44%] [G loss: 0.768050]\n",
      "epoch:38 step:30319 [D loss: 0.689274, acc.: 53.12%] [G loss: 0.724430]\n",
      "epoch:38 step:30320 [D loss: 0.683367, acc.: 58.59%] [G loss: 0.881742]\n",
      "epoch:38 step:30321 [D loss: 0.653765, acc.: 57.03%] [G loss: 0.790089]\n",
      "epoch:38 step:30322 [D loss: 0.700824, acc.: 53.91%] [G loss: 0.800845]\n",
      "epoch:38 step:30323 [D loss: 0.674631, acc.: 57.03%] [G loss: 0.836718]\n",
      "epoch:38 step:30324 [D loss: 0.676372, acc.: 57.81%] [G loss: 0.782515]\n",
      "epoch:38 step:30325 [D loss: 0.759724, acc.: 39.06%] [G loss: 0.780329]\n",
      "epoch:38 step:30326 [D loss: 0.679784, acc.: 58.59%] [G loss: 0.767432]\n",
      "epoch:38 step:30327 [D loss: 0.740701, acc.: 39.06%] [G loss: 0.750663]\n",
      "epoch:38 step:30328 [D loss: 0.647540, acc.: 57.03%] [G loss: 0.813179]\n",
      "epoch:38 step:30329 [D loss: 0.661142, acc.: 60.16%] [G loss: 0.736944]\n",
      "epoch:38 step:30330 [D loss: 0.658372, acc.: 63.28%] [G loss: 0.780171]\n",
      "epoch:38 step:30331 [D loss: 0.717579, acc.: 46.88%] [G loss: 0.766381]\n",
      "epoch:38 step:30332 [D loss: 0.659384, acc.: 61.72%] [G loss: 0.923799]\n",
      "epoch:38 step:30333 [D loss: 0.715786, acc.: 43.75%] [G loss: 0.784151]\n",
      "epoch:38 step:30334 [D loss: 0.696963, acc.: 54.69%] [G loss: 0.819501]\n",
      "epoch:38 step:30335 [D loss: 0.661702, acc.: 59.38%] [G loss: 0.815154]\n",
      "epoch:38 step:30336 [D loss: 0.670158, acc.: 57.03%] [G loss: 0.824098]\n",
      "epoch:38 step:30337 [D loss: 0.708528, acc.: 49.22%] [G loss: 0.813049]\n",
      "epoch:38 step:30338 [D loss: 0.778074, acc.: 32.03%] [G loss: 0.791545]\n",
      "epoch:38 step:30339 [D loss: 0.634359, acc.: 67.97%] [G loss: 0.850686]\n",
      "epoch:38 step:30340 [D loss: 0.720487, acc.: 49.22%] [G loss: 0.845797]\n",
      "epoch:38 step:30341 [D loss: 0.634601, acc.: 60.16%] [G loss: 0.777922]\n",
      "epoch:38 step:30342 [D loss: 0.677331, acc.: 56.25%] [G loss: 0.788840]\n",
      "epoch:38 step:30343 [D loss: 0.690072, acc.: 50.00%] [G loss: 0.761368]\n",
      "epoch:38 step:30344 [D loss: 0.650849, acc.: 60.94%] [G loss: 0.810902]\n",
      "epoch:38 step:30345 [D loss: 0.711659, acc.: 50.78%] [G loss: 0.805054]\n",
      "epoch:38 step:30346 [D loss: 0.699386, acc.: 57.03%] [G loss: 0.821247]\n",
      "epoch:38 step:30347 [D loss: 0.724076, acc.: 42.19%] [G loss: 0.733045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30348 [D loss: 0.700224, acc.: 54.69%] [G loss: 0.837083]\n",
      "epoch:38 step:30349 [D loss: 0.709182, acc.: 47.66%] [G loss: 0.705034]\n",
      "epoch:38 step:30350 [D loss: 0.660325, acc.: 60.16%] [G loss: 0.783877]\n",
      "epoch:38 step:30351 [D loss: 0.633647, acc.: 67.19%] [G loss: 0.789539]\n",
      "epoch:38 step:30352 [D loss: 0.710058, acc.: 54.69%] [G loss: 0.756025]\n",
      "epoch:38 step:30353 [D loss: 0.714156, acc.: 52.34%] [G loss: 0.777232]\n",
      "epoch:38 step:30354 [D loss: 0.710636, acc.: 52.34%] [G loss: 0.750835]\n",
      "epoch:38 step:30355 [D loss: 0.663677, acc.: 62.50%] [G loss: 0.790108]\n",
      "epoch:38 step:30356 [D loss: 0.726615, acc.: 42.19%] [G loss: 0.728083]\n",
      "epoch:38 step:30357 [D loss: 0.630201, acc.: 64.84%] [G loss: 0.797946]\n",
      "epoch:38 step:30358 [D loss: 0.657842, acc.: 67.19%] [G loss: 0.759617]\n",
      "epoch:38 step:30359 [D loss: 0.652809, acc.: 60.16%] [G loss: 0.794675]\n",
      "epoch:38 step:30360 [D loss: 0.706278, acc.: 50.00%] [G loss: 0.737961]\n",
      "epoch:38 step:30361 [D loss: 0.705671, acc.: 52.34%] [G loss: 0.861303]\n",
      "epoch:38 step:30362 [D loss: 0.681290, acc.: 60.16%] [G loss: 0.739023]\n",
      "epoch:38 step:30363 [D loss: 0.691139, acc.: 46.88%] [G loss: 0.856420]\n",
      "epoch:38 step:30364 [D loss: 0.705710, acc.: 52.34%] [G loss: 0.828508]\n",
      "epoch:38 step:30365 [D loss: 0.659265, acc.: 62.50%] [G loss: 0.807191]\n",
      "epoch:38 step:30366 [D loss: 0.703562, acc.: 46.09%] [G loss: 0.799440]\n",
      "epoch:38 step:30367 [D loss: 0.653551, acc.: 60.94%] [G loss: 0.799021]\n",
      "epoch:38 step:30368 [D loss: 0.613198, acc.: 70.31%] [G loss: 0.796754]\n",
      "epoch:38 step:30369 [D loss: 0.629978, acc.: 68.75%] [G loss: 0.778375]\n",
      "epoch:38 step:30370 [D loss: 0.765236, acc.: 40.62%] [G loss: 0.786621]\n",
      "epoch:38 step:30371 [D loss: 0.655123, acc.: 62.50%] [G loss: 0.738134]\n",
      "epoch:38 step:30372 [D loss: 0.722610, acc.: 42.97%] [G loss: 0.742020]\n",
      "epoch:38 step:30373 [D loss: 0.660515, acc.: 61.72%] [G loss: 0.734506]\n",
      "epoch:38 step:30374 [D loss: 0.755214, acc.: 46.88%] [G loss: 0.799954]\n",
      "epoch:38 step:30375 [D loss: 0.686363, acc.: 50.00%] [G loss: 0.706001]\n",
      "epoch:38 step:30376 [D loss: 0.654609, acc.: 55.47%] [G loss: 0.746166]\n",
      "epoch:38 step:30377 [D loss: 0.703705, acc.: 53.12%] [G loss: 0.736384]\n",
      "epoch:38 step:30378 [D loss: 0.665136, acc.: 56.25%] [G loss: 0.745938]\n",
      "epoch:38 step:30379 [D loss: 0.732737, acc.: 37.50%] [G loss: 0.741660]\n",
      "epoch:38 step:30380 [D loss: 0.673901, acc.: 56.25%] [G loss: 0.705089]\n",
      "epoch:38 step:30381 [D loss: 0.694799, acc.: 50.00%] [G loss: 0.790535]\n",
      "epoch:38 step:30382 [D loss: 0.649217, acc.: 61.72%] [G loss: 0.838310]\n",
      "epoch:38 step:30383 [D loss: 0.652100, acc.: 61.72%] [G loss: 0.797058]\n",
      "epoch:38 step:30384 [D loss: 0.640328, acc.: 66.41%] [G loss: 0.718624]\n",
      "epoch:38 step:30385 [D loss: 0.694083, acc.: 53.91%] [G loss: 0.810702]\n",
      "epoch:38 step:30386 [D loss: 0.634066, acc.: 70.31%] [G loss: 0.807580]\n",
      "epoch:38 step:30387 [D loss: 0.626699, acc.: 68.75%] [G loss: 0.741625]\n",
      "epoch:38 step:30388 [D loss: 0.664217, acc.: 64.06%] [G loss: 0.812459]\n",
      "epoch:38 step:30389 [D loss: 0.598729, acc.: 75.78%] [G loss: 0.813242]\n",
      "epoch:38 step:30390 [D loss: 0.702422, acc.: 49.22%] [G loss: 0.769513]\n",
      "epoch:38 step:30391 [D loss: 0.649320, acc.: 66.41%] [G loss: 0.787865]\n",
      "epoch:38 step:30392 [D loss: 0.596068, acc.: 73.44%] [G loss: 0.851384]\n",
      "epoch:38 step:30393 [D loss: 0.717934, acc.: 47.66%] [G loss: 0.817016]\n",
      "epoch:38 step:30394 [D loss: 0.605261, acc.: 74.22%] [G loss: 0.836120]\n",
      "epoch:38 step:30395 [D loss: 0.609949, acc.: 78.91%] [G loss: 0.867335]\n",
      "epoch:38 step:30396 [D loss: 0.612979, acc.: 70.31%] [G loss: 0.775796]\n",
      "epoch:38 step:30397 [D loss: 0.690202, acc.: 54.69%] [G loss: 0.698683]\n",
      "epoch:38 step:30398 [D loss: 0.644916, acc.: 64.84%] [G loss: 0.766295]\n",
      "epoch:38 step:30399 [D loss: 0.739341, acc.: 39.84%] [G loss: 0.754168]\n",
      "epoch:38 step:30400 [D loss: 0.667747, acc.: 60.16%] [G loss: 0.690611]\n",
      "epoch:38 step:30401 [D loss: 0.764835, acc.: 42.19%] [G loss: 0.768614]\n",
      "epoch:38 step:30402 [D loss: 0.708757, acc.: 44.53%] [G loss: 0.690280]\n",
      "epoch:38 step:30403 [D loss: 0.686660, acc.: 57.03%] [G loss: 0.737820]\n",
      "epoch:38 step:30404 [D loss: 0.660808, acc.: 59.38%] [G loss: 0.735245]\n",
      "epoch:38 step:30405 [D loss: 0.813322, acc.: 28.12%] [G loss: 0.722918]\n",
      "epoch:38 step:30406 [D loss: 0.730108, acc.: 49.22%] [G loss: 0.729266]\n",
      "epoch:38 step:30407 [D loss: 0.739643, acc.: 44.53%] [G loss: 0.718689]\n",
      "epoch:38 step:30408 [D loss: 0.688403, acc.: 57.03%] [G loss: 0.741735]\n",
      "epoch:38 step:30409 [D loss: 0.700147, acc.: 50.78%] [G loss: 0.712826]\n",
      "epoch:38 step:30410 [D loss: 0.819120, acc.: 27.34%] [G loss: 0.744590]\n",
      "epoch:38 step:30411 [D loss: 0.743793, acc.: 39.84%] [G loss: 0.802552]\n",
      "epoch:38 step:30412 [D loss: 0.706392, acc.: 47.66%] [G loss: 0.840895]\n",
      "epoch:38 step:30413 [D loss: 0.708610, acc.: 45.31%] [G loss: 0.792327]\n",
      "epoch:38 step:30414 [D loss: 0.685248, acc.: 60.16%] [G loss: 0.806719]\n",
      "epoch:38 step:30415 [D loss: 0.681329, acc.: 59.38%] [G loss: 0.838742]\n",
      "epoch:38 step:30416 [D loss: 0.665632, acc.: 59.38%] [G loss: 0.769105]\n",
      "epoch:38 step:30417 [D loss: 0.676104, acc.: 53.91%] [G loss: 0.794676]\n",
      "epoch:38 step:30418 [D loss: 0.665747, acc.: 58.59%] [G loss: 0.783598]\n",
      "epoch:38 step:30419 [D loss: 0.659172, acc.: 57.03%] [G loss: 0.783712]\n",
      "epoch:38 step:30420 [D loss: 0.691131, acc.: 53.91%] [G loss: 0.808733]\n",
      "epoch:38 step:30421 [D loss: 0.650837, acc.: 57.81%] [G loss: 0.763843]\n",
      "epoch:38 step:30422 [D loss: 0.639699, acc.: 62.50%] [G loss: 0.810372]\n",
      "epoch:38 step:30423 [D loss: 0.694936, acc.: 57.03%] [G loss: 0.752308]\n",
      "epoch:38 step:30424 [D loss: 0.665563, acc.: 57.81%] [G loss: 0.730172]\n",
      "epoch:38 step:30425 [D loss: 0.660594, acc.: 59.38%] [G loss: 0.779156]\n",
      "epoch:38 step:30426 [D loss: 0.658812, acc.: 60.16%] [G loss: 0.797007]\n",
      "epoch:38 step:30427 [D loss: 0.633707, acc.: 63.28%] [G loss: 0.694082]\n",
      "epoch:38 step:30428 [D loss: 0.635748, acc.: 63.28%] [G loss: 0.753848]\n",
      "epoch:38 step:30429 [D loss: 0.644369, acc.: 63.28%] [G loss: 0.690244]\n",
      "epoch:38 step:30430 [D loss: 0.676143, acc.: 57.03%] [G loss: 0.810725]\n",
      "epoch:38 step:30431 [D loss: 0.678879, acc.: 56.25%] [G loss: 0.666888]\n",
      "epoch:38 step:30432 [D loss: 0.651017, acc.: 63.28%] [G loss: 0.721181]\n",
      "epoch:38 step:30433 [D loss: 0.634172, acc.: 67.19%] [G loss: 0.769157]\n",
      "epoch:38 step:30434 [D loss: 0.688745, acc.: 54.69%] [G loss: 0.775984]\n",
      "epoch:38 step:30435 [D loss: 0.688291, acc.: 58.59%] [G loss: 0.727160]\n",
      "epoch:38 step:30436 [D loss: 0.668883, acc.: 60.94%] [G loss: 0.819232]\n",
      "epoch:38 step:30437 [D loss: 0.717420, acc.: 50.00%] [G loss: 0.754022]\n",
      "epoch:38 step:30438 [D loss: 0.707439, acc.: 49.22%] [G loss: 0.699906]\n",
      "epoch:38 step:30439 [D loss: 0.709109, acc.: 48.44%] [G loss: 0.704759]\n",
      "epoch:38 step:30440 [D loss: 0.731627, acc.: 41.41%] [G loss: 0.785026]\n",
      "epoch:38 step:30441 [D loss: 0.667887, acc.: 60.16%] [G loss: 0.852539]\n",
      "epoch:38 step:30442 [D loss: 0.691566, acc.: 50.78%] [G loss: 0.743741]\n",
      "epoch:38 step:30443 [D loss: 0.629566, acc.: 71.09%] [G loss: 0.813063]\n",
      "epoch:38 step:30444 [D loss: 0.728295, acc.: 45.31%] [G loss: 0.771623]\n",
      "epoch:38 step:30445 [D loss: 0.614583, acc.: 68.75%] [G loss: 0.785247]\n",
      "epoch:38 step:30446 [D loss: 0.626419, acc.: 67.97%] [G loss: 0.780304]\n",
      "epoch:38 step:30447 [D loss: 0.616983, acc.: 74.22%] [G loss: 0.854999]\n",
      "epoch:38 step:30448 [D loss: 0.646126, acc.: 63.28%] [G loss: 0.945569]\n",
      "epoch:38 step:30449 [D loss: 0.677777, acc.: 52.34%] [G loss: 0.841471]\n",
      "epoch:38 step:30450 [D loss: 0.714476, acc.: 39.84%] [G loss: 0.777736]\n",
      "epoch:38 step:30451 [D loss: 0.640553, acc.: 66.41%] [G loss: 0.841759]\n",
      "epoch:38 step:30452 [D loss: 0.635325, acc.: 66.41%] [G loss: 0.718116]\n",
      "epoch:38 step:30453 [D loss: 0.696651, acc.: 53.91%] [G loss: 0.705120]\n",
      "epoch:38 step:30454 [D loss: 0.694604, acc.: 50.00%] [G loss: 0.704584]\n",
      "epoch:38 step:30455 [D loss: 0.615422, acc.: 71.09%] [G loss: 0.740544]\n",
      "epoch:38 step:30456 [D loss: 0.655942, acc.: 60.94%] [G loss: 0.722555]\n",
      "epoch:38 step:30457 [D loss: 0.652985, acc.: 55.47%] [G loss: 0.717188]\n",
      "epoch:38 step:30458 [D loss: 0.726115, acc.: 46.88%] [G loss: 0.682276]\n",
      "epoch:38 step:30459 [D loss: 0.691412, acc.: 57.03%] [G loss: 0.725165]\n",
      "epoch:39 step:30460 [D loss: 0.602101, acc.: 67.19%] [G loss: 0.824036]\n",
      "epoch:39 step:30461 [D loss: 0.730705, acc.: 47.66%] [G loss: 0.727338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30462 [D loss: 0.692783, acc.: 53.91%] [G loss: 0.771851]\n",
      "epoch:39 step:30463 [D loss: 0.681106, acc.: 56.25%] [G loss: 0.794017]\n",
      "epoch:39 step:30464 [D loss: 0.715457, acc.: 52.34%] [G loss: 0.850586]\n",
      "epoch:39 step:30465 [D loss: 0.679981, acc.: 52.34%] [G loss: 0.850998]\n",
      "epoch:39 step:30466 [D loss: 0.706468, acc.: 52.34%] [G loss: 0.764479]\n",
      "epoch:39 step:30467 [D loss: 0.674178, acc.: 53.91%] [G loss: 1.013395]\n",
      "epoch:39 step:30468 [D loss: 0.724066, acc.: 52.34%] [G loss: 0.908053]\n",
      "epoch:39 step:30469 [D loss: 0.718282, acc.: 42.97%] [G loss: 0.948577]\n",
      "epoch:39 step:30470 [D loss: 0.659749, acc.: 60.94%] [G loss: 0.862016]\n",
      "epoch:39 step:30471 [D loss: 0.649367, acc.: 66.41%] [G loss: 0.838178]\n",
      "epoch:39 step:30472 [D loss: 0.683216, acc.: 57.81%] [G loss: 0.888614]\n",
      "epoch:39 step:30473 [D loss: 0.674792, acc.: 63.28%] [G loss: 0.756529]\n",
      "epoch:39 step:30474 [D loss: 0.659773, acc.: 57.03%] [G loss: 0.778582]\n",
      "epoch:39 step:30475 [D loss: 0.707434, acc.: 50.00%] [G loss: 0.836781]\n",
      "epoch:39 step:30476 [D loss: 0.701293, acc.: 57.81%] [G loss: 0.856943]\n",
      "epoch:39 step:30477 [D loss: 0.661929, acc.: 57.03%] [G loss: 0.806006]\n",
      "epoch:39 step:30478 [D loss: 0.700767, acc.: 50.00%] [G loss: 0.797976]\n",
      "epoch:39 step:30479 [D loss: 0.613586, acc.: 75.78%] [G loss: 0.770750]\n",
      "epoch:39 step:30480 [D loss: 0.701913, acc.: 49.22%] [G loss: 0.789852]\n",
      "epoch:39 step:30481 [D loss: 0.674523, acc.: 57.03%] [G loss: 0.771498]\n",
      "epoch:39 step:30482 [D loss: 0.653773, acc.: 62.50%] [G loss: 0.756316]\n",
      "epoch:39 step:30483 [D loss: 0.740611, acc.: 43.75%] [G loss: 0.773565]\n",
      "epoch:39 step:30484 [D loss: 0.710893, acc.: 48.44%] [G loss: 0.819785]\n",
      "epoch:39 step:30485 [D loss: 0.700715, acc.: 52.34%] [G loss: 0.788548]\n",
      "epoch:39 step:30486 [D loss: 0.658120, acc.: 64.84%] [G loss: 0.779119]\n",
      "epoch:39 step:30487 [D loss: 0.674266, acc.: 62.50%] [G loss: 0.750242]\n",
      "epoch:39 step:30488 [D loss: 0.699686, acc.: 53.12%] [G loss: 0.763935]\n",
      "epoch:39 step:30489 [D loss: 0.672020, acc.: 57.81%] [G loss: 0.817585]\n",
      "epoch:39 step:30490 [D loss: 0.745053, acc.: 46.09%] [G loss: 0.778115]\n",
      "epoch:39 step:30491 [D loss: 0.701804, acc.: 51.56%] [G loss: 0.781006]\n",
      "epoch:39 step:30492 [D loss: 0.683178, acc.: 55.47%] [G loss: 0.710886]\n",
      "epoch:39 step:30493 [D loss: 0.659351, acc.: 61.72%] [G loss: 0.718120]\n",
      "epoch:39 step:30494 [D loss: 0.649698, acc.: 61.72%] [G loss: 0.755432]\n",
      "epoch:39 step:30495 [D loss: 0.725440, acc.: 46.09%] [G loss: 0.759541]\n",
      "epoch:39 step:30496 [D loss: 0.704408, acc.: 47.66%] [G loss: 0.725297]\n",
      "epoch:39 step:30497 [D loss: 0.733861, acc.: 42.97%] [G loss: 0.817090]\n",
      "epoch:39 step:30498 [D loss: 0.644938, acc.: 69.53%] [G loss: 0.767212]\n",
      "epoch:39 step:30499 [D loss: 0.686445, acc.: 58.59%] [G loss: 0.799975]\n",
      "epoch:39 step:30500 [D loss: 0.637685, acc.: 62.50%] [G loss: 0.770676]\n",
      "epoch:39 step:30501 [D loss: 0.617896, acc.: 68.75%] [G loss: 0.829172]\n",
      "epoch:39 step:30502 [D loss: 0.655956, acc.: 62.50%] [G loss: 0.760492]\n",
      "epoch:39 step:30503 [D loss: 0.709539, acc.: 49.22%] [G loss: 0.857272]\n",
      "epoch:39 step:30504 [D loss: 0.648357, acc.: 65.62%] [G loss: 0.836390]\n",
      "epoch:39 step:30505 [D loss: 0.713124, acc.: 50.00%] [G loss: 0.842830]\n",
      "epoch:39 step:30506 [D loss: 0.671850, acc.: 54.69%] [G loss: 0.792778]\n",
      "epoch:39 step:30507 [D loss: 0.641599, acc.: 61.72%] [G loss: 0.785449]\n",
      "epoch:39 step:30508 [D loss: 0.700098, acc.: 53.12%] [G loss: 0.814842]\n",
      "epoch:39 step:30509 [D loss: 0.656618, acc.: 63.28%] [G loss: 0.748932]\n",
      "epoch:39 step:30510 [D loss: 0.621140, acc.: 78.12%] [G loss: 0.783458]\n",
      "epoch:39 step:30511 [D loss: 0.682624, acc.: 50.78%] [G loss: 0.829698]\n",
      "epoch:39 step:30512 [D loss: 0.674351, acc.: 61.72%] [G loss: 0.766367]\n",
      "epoch:39 step:30513 [D loss: 0.723624, acc.: 46.88%] [G loss: 0.800539]\n",
      "epoch:39 step:30514 [D loss: 0.690494, acc.: 53.12%] [G loss: 0.825853]\n",
      "epoch:39 step:30515 [D loss: 0.658480, acc.: 57.81%] [G loss: 0.862483]\n",
      "epoch:39 step:30516 [D loss: 0.613680, acc.: 71.09%] [G loss: 0.859983]\n",
      "epoch:39 step:30517 [D loss: 0.722602, acc.: 48.44%] [G loss: 0.791976]\n",
      "epoch:39 step:30518 [D loss: 0.625817, acc.: 70.31%] [G loss: 0.761940]\n",
      "epoch:39 step:30519 [D loss: 0.672412, acc.: 64.06%] [G loss: 0.818489]\n",
      "epoch:39 step:30520 [D loss: 0.691372, acc.: 55.47%] [G loss: 0.841065]\n",
      "epoch:39 step:30521 [D loss: 0.663071, acc.: 57.81%] [G loss: 0.784044]\n",
      "epoch:39 step:30522 [D loss: 0.664107, acc.: 59.38%] [G loss: 0.871146]\n",
      "epoch:39 step:30523 [D loss: 0.738980, acc.: 46.09%] [G loss: 0.783725]\n",
      "epoch:39 step:30524 [D loss: 0.709939, acc.: 44.53%] [G loss: 0.786528]\n",
      "epoch:39 step:30525 [D loss: 0.763429, acc.: 35.94%] [G loss: 0.764521]\n",
      "epoch:39 step:30526 [D loss: 0.636536, acc.: 66.41%] [G loss: 0.860568]\n",
      "epoch:39 step:30527 [D loss: 0.706528, acc.: 55.47%] [G loss: 0.827957]\n",
      "epoch:39 step:30528 [D loss: 0.706102, acc.: 47.66%] [G loss: 0.776118]\n",
      "epoch:39 step:30529 [D loss: 0.707727, acc.: 48.44%] [G loss: 0.784628]\n",
      "epoch:39 step:30530 [D loss: 0.700827, acc.: 51.56%] [G loss: 0.821645]\n",
      "epoch:39 step:30531 [D loss: 0.730805, acc.: 44.53%] [G loss: 0.767951]\n",
      "epoch:39 step:30532 [D loss: 0.757301, acc.: 39.84%] [G loss: 0.761844]\n",
      "epoch:39 step:30533 [D loss: 0.685863, acc.: 54.69%] [G loss: 0.735539]\n",
      "epoch:39 step:30534 [D loss: 0.691692, acc.: 53.12%] [G loss: 0.755156]\n",
      "epoch:39 step:30535 [D loss: 0.697225, acc.: 53.12%] [G loss: 0.697319]\n",
      "epoch:39 step:30536 [D loss: 0.657939, acc.: 54.69%] [G loss: 0.725188]\n",
      "epoch:39 step:30537 [D loss: 0.735500, acc.: 46.09%] [G loss: 0.825575]\n",
      "epoch:39 step:30538 [D loss: 0.671006, acc.: 63.28%] [G loss: 0.814747]\n",
      "epoch:39 step:30539 [D loss: 0.657871, acc.: 58.59%] [G loss: 0.879184]\n",
      "epoch:39 step:30540 [D loss: 0.690174, acc.: 50.00%] [G loss: 0.799083]\n",
      "epoch:39 step:30541 [D loss: 0.654744, acc.: 63.28%] [G loss: 0.782774]\n",
      "epoch:39 step:30542 [D loss: 0.704787, acc.: 49.22%] [G loss: 0.824700]\n",
      "epoch:39 step:30543 [D loss: 0.714984, acc.: 46.88%] [G loss: 0.852144]\n",
      "epoch:39 step:30544 [D loss: 0.673291, acc.: 55.47%] [G loss: 0.743316]\n",
      "epoch:39 step:30545 [D loss: 0.688483, acc.: 55.47%] [G loss: 0.836613]\n",
      "epoch:39 step:30546 [D loss: 0.647135, acc.: 61.72%] [G loss: 0.873027]\n",
      "epoch:39 step:30547 [D loss: 0.759880, acc.: 39.06%] [G loss: 0.828955]\n",
      "epoch:39 step:30548 [D loss: 0.616493, acc.: 71.09%] [G loss: 0.835414]\n",
      "epoch:39 step:30549 [D loss: 0.679580, acc.: 53.91%] [G loss: 0.812850]\n",
      "epoch:39 step:30550 [D loss: 0.605244, acc.: 71.09%] [G loss: 0.828929]\n",
      "epoch:39 step:30551 [D loss: 0.697171, acc.: 51.56%] [G loss: 0.678353]\n",
      "epoch:39 step:30552 [D loss: 0.617088, acc.: 70.31%] [G loss: 0.805220]\n",
      "epoch:39 step:30553 [D loss: 0.652012, acc.: 60.16%] [G loss: 0.713398]\n",
      "epoch:39 step:30554 [D loss: 0.721008, acc.: 54.69%] [G loss: 0.688767]\n",
      "epoch:39 step:30555 [D loss: 0.627246, acc.: 70.31%] [G loss: 0.743757]\n",
      "epoch:39 step:30556 [D loss: 0.694098, acc.: 53.91%] [G loss: 0.722031]\n",
      "epoch:39 step:30557 [D loss: 0.775129, acc.: 31.25%] [G loss: 0.726360]\n",
      "epoch:39 step:30558 [D loss: 0.710394, acc.: 43.75%] [G loss: 0.748528]\n",
      "epoch:39 step:30559 [D loss: 0.720071, acc.: 46.09%] [G loss: 0.731969]\n",
      "epoch:39 step:30560 [D loss: 0.728996, acc.: 43.75%] [G loss: 0.784845]\n",
      "epoch:39 step:30561 [D loss: 0.682091, acc.: 50.78%] [G loss: 0.817821]\n",
      "epoch:39 step:30562 [D loss: 0.762861, acc.: 41.41%] [G loss: 0.824178]\n",
      "epoch:39 step:30563 [D loss: 0.675399, acc.: 58.59%] [G loss: 0.747177]\n",
      "epoch:39 step:30564 [D loss: 0.638257, acc.: 60.94%] [G loss: 0.845679]\n",
      "epoch:39 step:30565 [D loss: 0.730728, acc.: 42.97%] [G loss: 0.763940]\n",
      "epoch:39 step:30566 [D loss: 0.693665, acc.: 49.22%] [G loss: 0.741851]\n",
      "epoch:39 step:30567 [D loss: 0.733964, acc.: 41.41%] [G loss: 0.792574]\n",
      "epoch:39 step:30568 [D loss: 0.688482, acc.: 54.69%] [G loss: 0.724508]\n",
      "epoch:39 step:30569 [D loss: 0.668466, acc.: 60.16%] [G loss: 0.784001]\n",
      "epoch:39 step:30570 [D loss: 0.700300, acc.: 53.12%] [G loss: 0.772019]\n",
      "epoch:39 step:30571 [D loss: 0.727830, acc.: 44.53%] [G loss: 0.839816]\n",
      "epoch:39 step:30572 [D loss: 0.699627, acc.: 54.69%] [G loss: 0.721473]\n",
      "epoch:39 step:30573 [D loss: 0.540516, acc.: 87.50%] [G loss: 0.854450]\n",
      "epoch:39 step:30574 [D loss: 0.721168, acc.: 49.22%] [G loss: 0.770801]\n",
      "epoch:39 step:30575 [D loss: 0.728031, acc.: 46.88%] [G loss: 0.743509]\n",
      "epoch:39 step:30576 [D loss: 0.635445, acc.: 71.09%] [G loss: 0.845455]\n",
      "epoch:39 step:30577 [D loss: 0.656304, acc.: 65.62%] [G loss: 0.814901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30578 [D loss: 0.739507, acc.: 51.56%] [G loss: 0.754608]\n",
      "epoch:39 step:30579 [D loss: 0.684471, acc.: 52.34%] [G loss: 0.730375]\n",
      "epoch:39 step:30580 [D loss: 0.635245, acc.: 63.28%] [G loss: 0.800306]\n",
      "epoch:39 step:30581 [D loss: 0.669155, acc.: 57.81%] [G loss: 0.816940]\n",
      "epoch:39 step:30582 [D loss: 0.726081, acc.: 42.97%] [G loss: 0.728937]\n",
      "epoch:39 step:30583 [D loss: 0.625155, acc.: 71.88%] [G loss: 0.822080]\n",
      "epoch:39 step:30584 [D loss: 0.657665, acc.: 59.38%] [G loss: 0.788406]\n",
      "epoch:39 step:30585 [D loss: 0.735562, acc.: 40.62%] [G loss: 0.619854]\n",
      "epoch:39 step:30586 [D loss: 0.689021, acc.: 49.22%] [G loss: 0.761226]\n",
      "epoch:39 step:30587 [D loss: 0.620228, acc.: 66.41%] [G loss: 0.721545]\n",
      "epoch:39 step:30588 [D loss: 0.741320, acc.: 47.66%] [G loss: 0.749538]\n",
      "epoch:39 step:30589 [D loss: 0.719847, acc.: 46.09%] [G loss: 0.715487]\n",
      "epoch:39 step:30590 [D loss: 0.694843, acc.: 55.47%] [G loss: 0.765284]\n",
      "epoch:39 step:30591 [D loss: 0.645647, acc.: 71.09%] [G loss: 0.784855]\n",
      "epoch:39 step:30592 [D loss: 0.720663, acc.: 45.31%] [G loss: 0.764782]\n",
      "epoch:39 step:30593 [D loss: 0.679294, acc.: 55.47%] [G loss: 0.817447]\n",
      "epoch:39 step:30594 [D loss: 0.685239, acc.: 57.03%] [G loss: 0.805984]\n",
      "epoch:39 step:30595 [D loss: 0.704997, acc.: 50.00%] [G loss: 0.735277]\n",
      "epoch:39 step:30596 [D loss: 0.668008, acc.: 56.25%] [G loss: 0.826791]\n",
      "epoch:39 step:30597 [D loss: 0.729512, acc.: 45.31%] [G loss: 0.766103]\n",
      "epoch:39 step:30598 [D loss: 0.678041, acc.: 59.38%] [G loss: 0.784757]\n",
      "epoch:39 step:30599 [D loss: 0.761389, acc.: 45.31%] [G loss: 0.797322]\n",
      "epoch:39 step:30600 [D loss: 0.674256, acc.: 57.03%] [G loss: 0.796962]\n",
      "epoch:39 step:30601 [D loss: 0.690955, acc.: 56.25%] [G loss: 0.899371]\n",
      "epoch:39 step:30602 [D loss: 0.699510, acc.: 50.00%] [G loss: 0.848227]\n",
      "epoch:39 step:30603 [D loss: 0.692723, acc.: 58.59%] [G loss: 0.895833]\n",
      "epoch:39 step:30604 [D loss: 0.671461, acc.: 53.12%] [G loss: 0.845100]\n",
      "epoch:39 step:30605 [D loss: 0.675353, acc.: 60.94%] [G loss: 0.773232]\n",
      "epoch:39 step:30606 [D loss: 0.613360, acc.: 71.09%] [G loss: 0.871361]\n",
      "epoch:39 step:30607 [D loss: 0.700322, acc.: 51.56%] [G loss: 0.755740]\n",
      "epoch:39 step:30608 [D loss: 0.671886, acc.: 57.81%] [G loss: 0.790154]\n",
      "epoch:39 step:30609 [D loss: 0.769313, acc.: 39.06%] [G loss: 0.746080]\n",
      "epoch:39 step:30610 [D loss: 0.643852, acc.: 64.84%] [G loss: 0.817588]\n",
      "epoch:39 step:30611 [D loss: 0.682666, acc.: 53.12%] [G loss: 0.777492]\n",
      "epoch:39 step:30612 [D loss: 0.679505, acc.: 57.03%] [G loss: 0.713603]\n",
      "epoch:39 step:30613 [D loss: 0.696312, acc.: 53.91%] [G loss: 0.814651]\n",
      "epoch:39 step:30614 [D loss: 0.622903, acc.: 74.22%] [G loss: 0.829735]\n",
      "epoch:39 step:30615 [D loss: 0.675310, acc.: 58.59%] [G loss: 0.767062]\n",
      "epoch:39 step:30616 [D loss: 0.632869, acc.: 64.06%] [G loss: 0.751719]\n",
      "epoch:39 step:30617 [D loss: 0.796984, acc.: 35.16%] [G loss: 0.742230]\n",
      "epoch:39 step:30618 [D loss: 0.667717, acc.: 56.25%] [G loss: 0.787098]\n",
      "epoch:39 step:30619 [D loss: 0.669481, acc.: 63.28%] [G loss: 0.776241]\n",
      "epoch:39 step:30620 [D loss: 0.716744, acc.: 45.31%] [G loss: 0.884003]\n",
      "epoch:39 step:30621 [D loss: 0.658831, acc.: 60.94%] [G loss: 0.877378]\n",
      "epoch:39 step:30622 [D loss: 0.674901, acc.: 57.81%] [G loss: 0.873270]\n",
      "epoch:39 step:30623 [D loss: 0.708280, acc.: 46.88%] [G loss: 0.809307]\n",
      "epoch:39 step:30624 [D loss: 0.738859, acc.: 41.41%] [G loss: 0.885760]\n",
      "epoch:39 step:30625 [D loss: 0.680540, acc.: 58.59%] [G loss: 0.862308]\n",
      "epoch:39 step:30626 [D loss: 0.713526, acc.: 52.34%] [G loss: 0.741986]\n",
      "epoch:39 step:30627 [D loss: 0.675330, acc.: 56.25%] [G loss: 0.872090]\n",
      "epoch:39 step:30628 [D loss: 0.748640, acc.: 41.41%] [G loss: 0.791785]\n",
      "epoch:39 step:30629 [D loss: 0.690071, acc.: 54.69%] [G loss: 0.819046]\n",
      "epoch:39 step:30630 [D loss: 0.689013, acc.: 53.12%] [G loss: 0.884712]\n",
      "epoch:39 step:30631 [D loss: 0.696602, acc.: 50.00%] [G loss: 0.858830]\n",
      "epoch:39 step:30632 [D loss: 0.760138, acc.: 41.41%] [G loss: 0.736279]\n",
      "epoch:39 step:30633 [D loss: 0.660683, acc.: 60.94%] [G loss: 0.774394]\n",
      "epoch:39 step:30634 [D loss: 0.685272, acc.: 57.81%] [G loss: 0.836035]\n",
      "epoch:39 step:30635 [D loss: 0.680789, acc.: 52.34%] [G loss: 0.801385]\n",
      "epoch:39 step:30636 [D loss: 0.673906, acc.: 59.38%] [G loss: 0.881254]\n",
      "epoch:39 step:30637 [D loss: 0.705001, acc.: 52.34%] [G loss: 0.857102]\n",
      "epoch:39 step:30638 [D loss: 0.652058, acc.: 64.06%] [G loss: 0.789554]\n",
      "epoch:39 step:30639 [D loss: 0.717605, acc.: 50.78%] [G loss: 0.773030]\n",
      "epoch:39 step:30640 [D loss: 0.681872, acc.: 56.25%] [G loss: 0.785669]\n",
      "epoch:39 step:30641 [D loss: 0.675781, acc.: 52.34%] [G loss: 0.824225]\n",
      "epoch:39 step:30642 [D loss: 0.641388, acc.: 65.62%] [G loss: 0.836161]\n",
      "epoch:39 step:30643 [D loss: 0.651865, acc.: 63.28%] [G loss: 0.851367]\n",
      "epoch:39 step:30644 [D loss: 0.649980, acc.: 65.62%] [G loss: 0.795167]\n",
      "epoch:39 step:30645 [D loss: 0.715042, acc.: 52.34%] [G loss: 0.741904]\n",
      "epoch:39 step:30646 [D loss: 0.699346, acc.: 51.56%] [G loss: 0.775568]\n",
      "epoch:39 step:30647 [D loss: 0.763695, acc.: 39.84%] [G loss: 0.800843]\n",
      "epoch:39 step:30648 [D loss: 0.576730, acc.: 78.91%] [G loss: 0.776903]\n",
      "epoch:39 step:30649 [D loss: 0.753623, acc.: 35.94%] [G loss: 0.756844]\n",
      "epoch:39 step:30650 [D loss: 0.649867, acc.: 64.06%] [G loss: 0.797782]\n",
      "epoch:39 step:30651 [D loss: 0.745459, acc.: 44.53%] [G loss: 0.651876]\n",
      "epoch:39 step:30652 [D loss: 0.733326, acc.: 46.88%] [G loss: 0.786273]\n",
      "epoch:39 step:30653 [D loss: 0.685234, acc.: 55.47%] [G loss: 0.757702]\n",
      "epoch:39 step:30654 [D loss: 0.691129, acc.: 54.69%] [G loss: 0.849881]\n",
      "epoch:39 step:30655 [D loss: 0.667124, acc.: 59.38%] [G loss: 0.738691]\n",
      "epoch:39 step:30656 [D loss: 0.683896, acc.: 55.47%] [G loss: 0.813887]\n",
      "epoch:39 step:30657 [D loss: 0.717472, acc.: 50.78%] [G loss: 0.739766]\n",
      "epoch:39 step:30658 [D loss: 0.709364, acc.: 52.34%] [G loss: 0.750684]\n",
      "epoch:39 step:30659 [D loss: 0.654405, acc.: 63.28%] [G loss: 0.764707]\n",
      "epoch:39 step:30660 [D loss: 0.654766, acc.: 63.28%] [G loss: 0.811098]\n",
      "epoch:39 step:30661 [D loss: 0.711684, acc.: 45.31%] [G loss: 0.750091]\n",
      "epoch:39 step:30662 [D loss: 0.664724, acc.: 65.62%] [G loss: 0.778364]\n",
      "epoch:39 step:30663 [D loss: 0.745545, acc.: 34.38%] [G loss: 0.711754]\n",
      "epoch:39 step:30664 [D loss: 0.673274, acc.: 56.25%] [G loss: 0.804126]\n",
      "epoch:39 step:30665 [D loss: 0.715455, acc.: 43.75%] [G loss: 0.788505]\n",
      "epoch:39 step:30666 [D loss: 0.633504, acc.: 65.62%] [G loss: 0.784811]\n",
      "epoch:39 step:30667 [D loss: 0.669040, acc.: 59.38%] [G loss: 0.812508]\n",
      "epoch:39 step:30668 [D loss: 0.673599, acc.: 59.38%] [G loss: 0.764994]\n",
      "epoch:39 step:30669 [D loss: 0.686782, acc.: 53.91%] [G loss: 0.739069]\n",
      "epoch:39 step:30670 [D loss: 0.724069, acc.: 45.31%] [G loss: 0.817853]\n",
      "epoch:39 step:30671 [D loss: 0.652647, acc.: 63.28%] [G loss: 0.807182]\n",
      "epoch:39 step:30672 [D loss: 0.743284, acc.: 42.97%] [G loss: 0.755419]\n",
      "epoch:39 step:30673 [D loss: 0.647339, acc.: 62.50%] [G loss: 0.807991]\n",
      "epoch:39 step:30674 [D loss: 0.675849, acc.: 58.59%] [G loss: 0.812027]\n",
      "epoch:39 step:30675 [D loss: 0.743085, acc.: 41.41%] [G loss: 0.821185]\n",
      "epoch:39 step:30676 [D loss: 0.680557, acc.: 52.34%] [G loss: 0.750886]\n",
      "epoch:39 step:30677 [D loss: 0.701788, acc.: 50.00%] [G loss: 0.762138]\n",
      "epoch:39 step:30678 [D loss: 0.686214, acc.: 52.34%] [G loss: 0.777928]\n",
      "epoch:39 step:30679 [D loss: 0.704631, acc.: 51.56%] [G loss: 0.874952]\n",
      "epoch:39 step:30680 [D loss: 0.675803, acc.: 57.81%] [G loss: 0.722615]\n",
      "epoch:39 step:30681 [D loss: 0.654325, acc.: 62.50%] [G loss: 0.741678]\n",
      "epoch:39 step:30682 [D loss: 0.623180, acc.: 67.19%] [G loss: 0.763519]\n",
      "epoch:39 step:30683 [D loss: 0.665701, acc.: 57.81%] [G loss: 0.756601]\n",
      "epoch:39 step:30684 [D loss: 0.675321, acc.: 57.81%] [G loss: 0.788902]\n",
      "epoch:39 step:30685 [D loss: 0.733723, acc.: 44.53%] [G loss: 0.727158]\n",
      "epoch:39 step:30686 [D loss: 0.688207, acc.: 54.69%] [G loss: 0.766410]\n",
      "epoch:39 step:30687 [D loss: 0.710337, acc.: 51.56%] [G loss: 0.735220]\n",
      "epoch:39 step:30688 [D loss: 0.695460, acc.: 50.00%] [G loss: 0.731526]\n",
      "epoch:39 step:30689 [D loss: 0.737871, acc.: 45.31%] [G loss: 0.726520]\n",
      "epoch:39 step:30690 [D loss: 0.702298, acc.: 47.66%] [G loss: 0.788810]\n",
      "epoch:39 step:30691 [D loss: 0.688004, acc.: 55.47%] [G loss: 0.753212]\n",
      "epoch:39 step:30692 [D loss: 0.674511, acc.: 62.50%] [G loss: 0.798609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30693 [D loss: 0.758759, acc.: 41.41%] [G loss: 0.772647]\n",
      "epoch:39 step:30694 [D loss: 0.648070, acc.: 65.62%] [G loss: 0.733905]\n",
      "epoch:39 step:30695 [D loss: 0.704110, acc.: 51.56%] [G loss: 0.752772]\n",
      "epoch:39 step:30696 [D loss: 0.687648, acc.: 57.03%] [G loss: 0.676612]\n",
      "epoch:39 step:30697 [D loss: 0.701977, acc.: 48.44%] [G loss: 0.817777]\n",
      "epoch:39 step:30698 [D loss: 0.661371, acc.: 60.16%] [G loss: 0.789168]\n",
      "epoch:39 step:30699 [D loss: 0.709507, acc.: 49.22%] [G loss: 0.795996]\n",
      "epoch:39 step:30700 [D loss: 0.653001, acc.: 67.97%] [G loss: 0.781802]\n",
      "epoch:39 step:30701 [D loss: 0.638466, acc.: 64.06%] [G loss: 0.621072]\n",
      "epoch:39 step:30702 [D loss: 0.699560, acc.: 54.69%] [G loss: 0.746573]\n",
      "epoch:39 step:30703 [D loss: 0.700710, acc.: 54.69%] [G loss: 0.763567]\n",
      "epoch:39 step:30704 [D loss: 0.724430, acc.: 45.31%] [G loss: 0.763523]\n",
      "epoch:39 step:30705 [D loss: 0.748556, acc.: 41.41%] [G loss: 0.819276]\n",
      "epoch:39 step:30706 [D loss: 0.657684, acc.: 59.38%] [G loss: 0.668054]\n",
      "epoch:39 step:30707 [D loss: 0.632249, acc.: 69.53%] [G loss: 0.811164]\n",
      "epoch:39 step:30708 [D loss: 0.690801, acc.: 58.59%] [G loss: 0.772267]\n",
      "epoch:39 step:30709 [D loss: 0.655713, acc.: 61.72%] [G loss: 0.842731]\n",
      "epoch:39 step:30710 [D loss: 0.656559, acc.: 64.84%] [G loss: 0.927134]\n",
      "epoch:39 step:30711 [D loss: 0.700150, acc.: 52.34%] [G loss: 0.801402]\n",
      "epoch:39 step:30712 [D loss: 0.673279, acc.: 53.12%] [G loss: 0.907920]\n",
      "epoch:39 step:30713 [D loss: 0.692016, acc.: 59.38%] [G loss: 0.807368]\n",
      "epoch:39 step:30714 [D loss: 0.666641, acc.: 58.59%] [G loss: 0.780947]\n",
      "epoch:39 step:30715 [D loss: 0.726645, acc.: 46.88%] [G loss: 0.777045]\n",
      "epoch:39 step:30716 [D loss: 0.652218, acc.: 63.28%] [G loss: 0.807230]\n",
      "epoch:39 step:30717 [D loss: 0.725654, acc.: 43.75%] [G loss: 0.741570]\n",
      "epoch:39 step:30718 [D loss: 0.691002, acc.: 56.25%] [G loss: 0.773963]\n",
      "epoch:39 step:30719 [D loss: 0.665607, acc.: 60.94%] [G loss: 0.709131]\n",
      "epoch:39 step:30720 [D loss: 0.688582, acc.: 57.81%] [G loss: 0.822853]\n",
      "epoch:39 step:30721 [D loss: 0.674854, acc.: 61.72%] [G loss: 0.892886]\n",
      "epoch:39 step:30722 [D loss: 0.707438, acc.: 50.78%] [G loss: 0.830693]\n",
      "epoch:39 step:30723 [D loss: 0.665990, acc.: 64.84%] [G loss: 0.858253]\n",
      "epoch:39 step:30724 [D loss: 0.651978, acc.: 64.84%] [G loss: 0.821984]\n",
      "epoch:39 step:30725 [D loss: 0.755691, acc.: 44.53%] [G loss: 0.728945]\n",
      "epoch:39 step:30726 [D loss: 0.752875, acc.: 47.66%] [G loss: 0.751576]\n",
      "epoch:39 step:30727 [D loss: 0.670392, acc.: 62.50%] [G loss: 0.746434]\n",
      "epoch:39 step:30728 [D loss: 0.672018, acc.: 63.28%] [G loss: 0.777651]\n",
      "epoch:39 step:30729 [D loss: 0.698768, acc.: 48.44%] [G loss: 0.824795]\n",
      "epoch:39 step:30730 [D loss: 0.755946, acc.: 39.06%] [G loss: 0.799151]\n",
      "epoch:39 step:30731 [D loss: 0.658563, acc.: 58.59%] [G loss: 0.792578]\n",
      "epoch:39 step:30732 [D loss: 0.686677, acc.: 56.25%] [G loss: 0.781218]\n",
      "epoch:39 step:30733 [D loss: 0.709721, acc.: 53.91%] [G loss: 0.816773]\n",
      "epoch:39 step:30734 [D loss: 0.709454, acc.: 52.34%] [G loss: 0.768234]\n",
      "epoch:39 step:30735 [D loss: 0.638587, acc.: 70.31%] [G loss: 0.849024]\n",
      "epoch:39 step:30736 [D loss: 0.731580, acc.: 49.22%] [G loss: 0.820694]\n",
      "epoch:39 step:30737 [D loss: 0.656764, acc.: 63.28%] [G loss: 0.781929]\n",
      "epoch:39 step:30738 [D loss: 0.668926, acc.: 62.50%] [G loss: 0.711091]\n",
      "epoch:39 step:30739 [D loss: 0.703483, acc.: 50.00%] [G loss: 0.747690]\n",
      "epoch:39 step:30740 [D loss: 0.689938, acc.: 54.69%] [G loss: 0.751064]\n",
      "epoch:39 step:30741 [D loss: 0.642279, acc.: 64.84%] [G loss: 0.827170]\n",
      "epoch:39 step:30742 [D loss: 0.685155, acc.: 55.47%] [G loss: 0.794338]\n",
      "epoch:39 step:30743 [D loss: 0.649954, acc.: 63.28%] [G loss: 0.832103]\n",
      "epoch:39 step:30744 [D loss: 0.671168, acc.: 57.81%] [G loss: 0.774856]\n",
      "epoch:39 step:30745 [D loss: 0.664841, acc.: 62.50%] [G loss: 0.804251]\n",
      "epoch:39 step:30746 [D loss: 0.697743, acc.: 50.78%] [G loss: 0.799551]\n",
      "epoch:39 step:30747 [D loss: 0.689789, acc.: 53.12%] [G loss: 0.734249]\n",
      "epoch:39 step:30748 [D loss: 0.690553, acc.: 53.91%] [G loss: 0.721091]\n",
      "epoch:39 step:30749 [D loss: 0.647139, acc.: 67.19%] [G loss: 0.915184]\n",
      "epoch:39 step:30750 [D loss: 0.667961, acc.: 57.81%] [G loss: 0.819079]\n",
      "epoch:39 step:30751 [D loss: 0.735776, acc.: 47.66%] [G loss: 0.718743]\n",
      "epoch:39 step:30752 [D loss: 0.714638, acc.: 44.53%] [G loss: 0.826679]\n",
      "epoch:39 step:30753 [D loss: 0.680283, acc.: 56.25%] [G loss: 0.825573]\n",
      "epoch:39 step:30754 [D loss: 0.664105, acc.: 58.59%] [G loss: 0.786693]\n",
      "epoch:39 step:30755 [D loss: 0.667865, acc.: 64.84%] [G loss: 0.782686]\n",
      "epoch:39 step:30756 [D loss: 0.675275, acc.: 57.81%] [G loss: 0.738656]\n",
      "epoch:39 step:30757 [D loss: 0.676868, acc.: 63.28%] [G loss: 0.876235]\n",
      "epoch:39 step:30758 [D loss: 0.736891, acc.: 42.19%] [G loss: 0.740165]\n",
      "epoch:39 step:30759 [D loss: 0.703500, acc.: 44.53%] [G loss: 0.776782]\n",
      "epoch:39 step:30760 [D loss: 0.672004, acc.: 60.16%] [G loss: 0.749175]\n",
      "epoch:39 step:30761 [D loss: 0.689540, acc.: 57.81%] [G loss: 0.755420]\n",
      "epoch:39 step:30762 [D loss: 0.665261, acc.: 61.72%] [G loss: 0.733499]\n",
      "epoch:39 step:30763 [D loss: 0.688697, acc.: 55.47%] [G loss: 0.735454]\n",
      "epoch:39 step:30764 [D loss: 0.683118, acc.: 54.69%] [G loss: 0.803754]\n",
      "epoch:39 step:30765 [D loss: 0.684753, acc.: 55.47%] [G loss: 0.760681]\n",
      "epoch:39 step:30766 [D loss: 0.637853, acc.: 62.50%] [G loss: 0.745718]\n",
      "epoch:39 step:30767 [D loss: 0.654053, acc.: 61.72%] [G loss: 0.730974]\n",
      "epoch:39 step:30768 [D loss: 0.699481, acc.: 50.78%] [G loss: 0.738503]\n",
      "epoch:39 step:30769 [D loss: 0.686417, acc.: 57.81%] [G loss: 0.778189]\n",
      "epoch:39 step:30770 [D loss: 0.667466, acc.: 60.94%] [G loss: 0.764274]\n",
      "epoch:39 step:30771 [D loss: 0.667146, acc.: 56.25%] [G loss: 0.753194]\n",
      "epoch:39 step:30772 [D loss: 0.676004, acc.: 55.47%] [G loss: 0.858389]\n",
      "epoch:39 step:30773 [D loss: 0.737035, acc.: 42.19%] [G loss: 0.709323]\n",
      "epoch:39 step:30774 [D loss: 0.711976, acc.: 45.31%] [G loss: 0.782978]\n",
      "epoch:39 step:30775 [D loss: 0.692731, acc.: 49.22%] [G loss: 0.785270]\n",
      "epoch:39 step:30776 [D loss: 0.629199, acc.: 65.62%] [G loss: 0.749848]\n",
      "epoch:39 step:30777 [D loss: 0.697544, acc.: 55.47%] [G loss: 0.810935]\n",
      "epoch:39 step:30778 [D loss: 0.692650, acc.: 49.22%] [G loss: 0.721369]\n",
      "epoch:39 step:30779 [D loss: 0.654189, acc.: 60.16%] [G loss: 0.700259]\n",
      "epoch:39 step:30780 [D loss: 0.665058, acc.: 59.38%] [G loss: 0.792128]\n",
      "epoch:39 step:30781 [D loss: 0.687013, acc.: 55.47%] [G loss: 0.695937]\n",
      "epoch:39 step:30782 [D loss: 0.698183, acc.: 53.91%] [G loss: 0.774352]\n",
      "epoch:39 step:30783 [D loss: 0.633174, acc.: 68.75%] [G loss: 0.816253]\n",
      "epoch:39 step:30784 [D loss: 0.655386, acc.: 63.28%] [G loss: 0.905235]\n",
      "epoch:39 step:30785 [D loss: 0.656602, acc.: 60.94%] [G loss: 0.896418]\n",
      "epoch:39 step:30786 [D loss: 0.661171, acc.: 59.38%] [G loss: 0.825340]\n",
      "epoch:39 step:30787 [D loss: 0.671895, acc.: 62.50%] [G loss: 0.766502]\n",
      "epoch:39 step:30788 [D loss: 0.622030, acc.: 68.75%] [G loss: 0.869729]\n",
      "epoch:39 step:30789 [D loss: 0.686519, acc.: 53.12%] [G loss: 0.832672]\n",
      "epoch:39 step:30790 [D loss: 0.693480, acc.: 49.22%] [G loss: 0.858784]\n",
      "epoch:39 step:30791 [D loss: 0.756675, acc.: 42.19%] [G loss: 0.790183]\n",
      "epoch:39 step:30792 [D loss: 0.647096, acc.: 63.28%] [G loss: 0.784201]\n",
      "epoch:39 step:30793 [D loss: 0.670230, acc.: 59.38%] [G loss: 0.764734]\n",
      "epoch:39 step:30794 [D loss: 0.697506, acc.: 53.12%] [G loss: 0.738933]\n",
      "epoch:39 step:30795 [D loss: 0.713720, acc.: 52.34%] [G loss: 0.812142]\n",
      "epoch:39 step:30796 [D loss: 0.671380, acc.: 54.69%] [G loss: 0.739335]\n",
      "epoch:39 step:30797 [D loss: 0.796164, acc.: 34.38%] [G loss: 0.769124]\n",
      "epoch:39 step:30798 [D loss: 0.690261, acc.: 56.25%] [G loss: 0.782434]\n",
      "epoch:39 step:30799 [D loss: 0.717158, acc.: 53.12%] [G loss: 0.778504]\n",
      "epoch:39 step:30800 [D loss: 0.664060, acc.: 57.81%] [G loss: 0.776449]\n",
      "epoch:39 step:30801 [D loss: 0.652951, acc.: 64.06%] [G loss: 0.693796]\n",
      "epoch:39 step:30802 [D loss: 0.658224, acc.: 60.16%] [G loss: 0.791262]\n",
      "epoch:39 step:30803 [D loss: 0.677374, acc.: 57.03%] [G loss: 0.757556]\n",
      "epoch:39 step:30804 [D loss: 0.685812, acc.: 53.91%] [G loss: 0.717709]\n",
      "epoch:39 step:30805 [D loss: 0.739183, acc.: 42.97%] [G loss: 0.779846]\n",
      "epoch:39 step:30806 [D loss: 0.663171, acc.: 60.16%] [G loss: 0.853968]\n",
      "epoch:39 step:30807 [D loss: 0.730851, acc.: 47.66%] [G loss: 0.674096]\n",
      "epoch:39 step:30808 [D loss: 0.663150, acc.: 64.84%] [G loss: 0.844210]\n",
      "epoch:39 step:30809 [D loss: 0.726970, acc.: 43.75%] [G loss: 0.862912]\n",
      "epoch:39 step:30810 [D loss: 0.702320, acc.: 51.56%] [G loss: 0.787064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30811 [D loss: 0.619166, acc.: 70.31%] [G loss: 0.804779]\n",
      "epoch:39 step:30812 [D loss: 0.649174, acc.: 61.72%] [G loss: 0.792038]\n",
      "epoch:39 step:30813 [D loss: 0.681822, acc.: 53.91%] [G loss: 0.791608]\n",
      "epoch:39 step:30814 [D loss: 0.690483, acc.: 53.91%] [G loss: 0.878215]\n",
      "epoch:39 step:30815 [D loss: 0.618874, acc.: 68.75%] [G loss: 0.813967]\n",
      "epoch:39 step:30816 [D loss: 0.695818, acc.: 52.34%] [G loss: 0.782157]\n",
      "epoch:39 step:30817 [D loss: 0.703790, acc.: 50.00%] [G loss: 0.827511]\n",
      "epoch:39 step:30818 [D loss: 0.687393, acc.: 57.81%] [G loss: 0.756518]\n",
      "epoch:39 step:30819 [D loss: 0.691743, acc.: 53.91%] [G loss: 0.759071]\n",
      "epoch:39 step:30820 [D loss: 0.668728, acc.: 63.28%] [G loss: 0.759416]\n",
      "epoch:39 step:30821 [D loss: 0.662321, acc.: 62.50%] [G loss: 0.722642]\n",
      "epoch:39 step:30822 [D loss: 0.729057, acc.: 48.44%] [G loss: 0.795122]\n",
      "epoch:39 step:30823 [D loss: 0.672609, acc.: 55.47%] [G loss: 0.773322]\n",
      "epoch:39 step:30824 [D loss: 0.678324, acc.: 57.03%] [G loss: 0.752691]\n",
      "epoch:39 step:30825 [D loss: 0.679362, acc.: 57.81%] [G loss: 0.772472]\n",
      "epoch:39 step:30826 [D loss: 0.683337, acc.: 57.03%] [G loss: 0.696476]\n",
      "epoch:39 step:30827 [D loss: 0.665081, acc.: 63.28%] [G loss: 0.759014]\n",
      "epoch:39 step:30828 [D loss: 0.687628, acc.: 56.25%] [G loss: 0.766773]\n",
      "epoch:39 step:30829 [D loss: 0.715363, acc.: 46.09%] [G loss: 0.835780]\n",
      "epoch:39 step:30830 [D loss: 0.671485, acc.: 53.91%] [G loss: 0.812808]\n",
      "epoch:39 step:30831 [D loss: 0.662348, acc.: 61.72%] [G loss: 0.791273]\n",
      "epoch:39 step:30832 [D loss: 0.707964, acc.: 50.78%] [G loss: 0.809201]\n",
      "epoch:39 step:30833 [D loss: 0.692530, acc.: 47.66%] [G loss: 0.815773]\n",
      "epoch:39 step:30834 [D loss: 0.679374, acc.: 57.81%] [G loss: 0.700698]\n",
      "epoch:39 step:30835 [D loss: 0.729583, acc.: 46.88%] [G loss: 0.714012]\n",
      "epoch:39 step:30836 [D loss: 0.628456, acc.: 70.31%] [G loss: 0.812274]\n",
      "epoch:39 step:30837 [D loss: 0.651678, acc.: 67.19%] [G loss: 0.779446]\n",
      "epoch:39 step:30838 [D loss: 0.690888, acc.: 58.59%] [G loss: 0.717147]\n",
      "epoch:39 step:30839 [D loss: 0.718855, acc.: 47.66%] [G loss: 0.720603]\n",
      "epoch:39 step:30840 [D loss: 0.643080, acc.: 62.50%] [G loss: 0.751006]\n",
      "epoch:39 step:30841 [D loss: 0.653051, acc.: 60.94%] [G loss: 0.794632]\n",
      "epoch:39 step:30842 [D loss: 0.663826, acc.: 60.16%] [G loss: 0.780048]\n",
      "epoch:39 step:30843 [D loss: 0.662448, acc.: 61.72%] [G loss: 0.763180]\n",
      "epoch:39 step:30844 [D loss: 0.681363, acc.: 55.47%] [G loss: 0.798088]\n",
      "epoch:39 step:30845 [D loss: 0.706809, acc.: 53.91%] [G loss: 0.742711]\n",
      "epoch:39 step:30846 [D loss: 0.672812, acc.: 56.25%] [G loss: 0.730568]\n",
      "epoch:39 step:30847 [D loss: 0.705497, acc.: 47.66%] [G loss: 0.836065]\n",
      "epoch:39 step:30848 [D loss: 0.695112, acc.: 53.91%] [G loss: 0.843717]\n",
      "epoch:39 step:30849 [D loss: 0.685875, acc.: 53.91%] [G loss: 0.853819]\n",
      "epoch:39 step:30850 [D loss: 0.758047, acc.: 42.19%] [G loss: 0.851570]\n",
      "epoch:39 step:30851 [D loss: 0.660070, acc.: 62.50%] [G loss: 0.784577]\n",
      "epoch:39 step:30852 [D loss: 0.649435, acc.: 62.50%] [G loss: 0.714195]\n",
      "epoch:39 step:30853 [D loss: 0.679642, acc.: 61.72%] [G loss: 0.717462]\n",
      "epoch:39 step:30854 [D loss: 0.620601, acc.: 73.44%] [G loss: 0.815198]\n",
      "epoch:39 step:30855 [D loss: 0.728475, acc.: 45.31%] [G loss: 0.806031]\n",
      "epoch:39 step:30856 [D loss: 0.690324, acc.: 55.47%] [G loss: 0.766557]\n",
      "epoch:39 step:30857 [D loss: 0.649036, acc.: 69.53%] [G loss: 0.834052]\n",
      "epoch:39 step:30858 [D loss: 0.635348, acc.: 67.97%] [G loss: 0.768105]\n",
      "epoch:39 step:30859 [D loss: 0.671909, acc.: 53.91%] [G loss: 0.736370]\n",
      "epoch:39 step:30860 [D loss: 0.646692, acc.: 67.97%] [G loss: 0.847497]\n",
      "epoch:39 step:30861 [D loss: 0.661246, acc.: 61.72%] [G loss: 0.797581]\n",
      "epoch:39 step:30862 [D loss: 0.661644, acc.: 63.28%] [G loss: 0.775345]\n",
      "epoch:39 step:30863 [D loss: 0.676621, acc.: 57.03%] [G loss: 0.827455]\n",
      "epoch:39 step:30864 [D loss: 0.702309, acc.: 48.44%] [G loss: 0.773275]\n",
      "epoch:39 step:30865 [D loss: 0.670006, acc.: 63.28%] [G loss: 0.772592]\n",
      "epoch:39 step:30866 [D loss: 0.631996, acc.: 66.41%] [G loss: 0.854843]\n",
      "epoch:39 step:30867 [D loss: 0.707101, acc.: 50.00%] [G loss: 0.740583]\n",
      "epoch:39 step:30868 [D loss: 0.652677, acc.: 60.16%] [G loss: 0.803671]\n",
      "epoch:39 step:30869 [D loss: 0.692219, acc.: 53.91%] [G loss: 0.772934]\n",
      "epoch:39 step:30870 [D loss: 0.793522, acc.: 29.69%] [G loss: 0.754354]\n",
      "epoch:39 step:30871 [D loss: 0.700280, acc.: 52.34%] [G loss: 0.749386]\n",
      "epoch:39 step:30872 [D loss: 0.730170, acc.: 50.78%] [G loss: 0.769304]\n",
      "epoch:39 step:30873 [D loss: 0.688871, acc.: 54.69%] [G loss: 0.795490]\n",
      "epoch:39 step:30874 [D loss: 0.633590, acc.: 62.50%] [G loss: 0.783328]\n",
      "epoch:39 step:30875 [D loss: 0.677228, acc.: 63.28%] [G loss: 0.865507]\n",
      "epoch:39 step:30876 [D loss: 0.703148, acc.: 54.69%] [G loss: 0.747837]\n",
      "epoch:39 step:30877 [D loss: 0.713735, acc.: 48.44%] [G loss: 0.760970]\n",
      "epoch:39 step:30878 [D loss: 0.649078, acc.: 71.88%] [G loss: 0.826102]\n",
      "epoch:39 step:30879 [D loss: 0.728799, acc.: 43.75%] [G loss: 0.795909]\n",
      "epoch:39 step:30880 [D loss: 0.719651, acc.: 48.44%] [G loss: 0.784337]\n",
      "epoch:39 step:30881 [D loss: 0.651192, acc.: 61.72%] [G loss: 0.811617]\n",
      "epoch:39 step:30882 [D loss: 0.740359, acc.: 42.97%] [G loss: 0.767539]\n",
      "epoch:39 step:30883 [D loss: 0.748482, acc.: 42.19%] [G loss: 0.774155]\n",
      "epoch:39 step:30884 [D loss: 0.680644, acc.: 54.69%] [G loss: 0.813370]\n",
      "epoch:39 step:30885 [D loss: 0.680746, acc.: 55.47%] [G loss: 0.798673]\n",
      "epoch:39 step:30886 [D loss: 0.705947, acc.: 50.78%] [G loss: 0.737524]\n",
      "epoch:39 step:30887 [D loss: 0.733882, acc.: 39.84%] [G loss: 0.741268]\n",
      "epoch:39 step:30888 [D loss: 0.662279, acc.: 60.94%] [G loss: 0.817067]\n",
      "epoch:39 step:30889 [D loss: 0.645270, acc.: 60.94%] [G loss: 0.758160]\n",
      "epoch:39 step:30890 [D loss: 0.682666, acc.: 52.34%] [G loss: 0.804161]\n",
      "epoch:39 step:30891 [D loss: 0.632830, acc.: 67.19%] [G loss: 0.784767]\n",
      "epoch:39 step:30892 [D loss: 0.666219, acc.: 65.62%] [G loss: 0.810157]\n",
      "epoch:39 step:30893 [D loss: 0.699627, acc.: 50.78%] [G loss: 0.768503]\n",
      "epoch:39 step:30894 [D loss: 0.733349, acc.: 48.44%] [G loss: 0.813426]\n",
      "epoch:39 step:30895 [D loss: 0.704334, acc.: 50.00%] [G loss: 0.879081]\n",
      "epoch:39 step:30896 [D loss: 0.739005, acc.: 40.62%] [G loss: 0.831134]\n",
      "epoch:39 step:30897 [D loss: 0.648288, acc.: 64.84%] [G loss: 0.885145]\n",
      "epoch:39 step:30898 [D loss: 0.690296, acc.: 50.78%] [G loss: 0.773849]\n",
      "epoch:39 step:30899 [D loss: 0.687211, acc.: 55.47%] [G loss: 0.780904]\n",
      "epoch:39 step:30900 [D loss: 0.707352, acc.: 51.56%] [G loss: 0.791845]\n",
      "epoch:39 step:30901 [D loss: 0.653574, acc.: 64.06%] [G loss: 0.802914]\n",
      "epoch:39 step:30902 [D loss: 0.725515, acc.: 50.00%] [G loss: 0.879771]\n",
      "epoch:39 step:30903 [D loss: 0.705702, acc.: 54.69%] [G loss: 0.796793]\n",
      "epoch:39 step:30904 [D loss: 0.737039, acc.: 43.75%] [G loss: 0.783504]\n",
      "epoch:39 step:30905 [D loss: 0.713837, acc.: 44.53%] [G loss: 0.844867]\n",
      "epoch:39 step:30906 [D loss: 0.655265, acc.: 64.06%] [G loss: 0.784575]\n",
      "epoch:39 step:30907 [D loss: 0.655940, acc.: 61.72%] [G loss: 0.815827]\n",
      "epoch:39 step:30908 [D loss: 0.675542, acc.: 58.59%] [G loss: 0.798106]\n",
      "epoch:39 step:30909 [D loss: 0.688790, acc.: 53.91%] [G loss: 0.834642]\n",
      "epoch:39 step:30910 [D loss: 0.641257, acc.: 65.62%] [G loss: 0.861801]\n",
      "epoch:39 step:30911 [D loss: 0.644993, acc.: 64.06%] [G loss: 0.891284]\n",
      "epoch:39 step:30912 [D loss: 0.676895, acc.: 57.03%] [G loss: 0.791406]\n",
      "epoch:39 step:30913 [D loss: 0.675120, acc.: 57.81%] [G loss: 0.778244]\n",
      "epoch:39 step:30914 [D loss: 0.689388, acc.: 57.03%] [G loss: 0.859823]\n",
      "epoch:39 step:30915 [D loss: 0.672659, acc.: 58.59%] [G loss: 0.761432]\n",
      "epoch:39 step:30916 [D loss: 0.673889, acc.: 54.69%] [G loss: 0.759714]\n",
      "epoch:39 step:30917 [D loss: 0.673457, acc.: 57.81%] [G loss: 0.775027]\n",
      "epoch:39 step:30918 [D loss: 0.748763, acc.: 42.97%] [G loss: 0.747986]\n",
      "epoch:39 step:30919 [D loss: 0.682225, acc.: 53.12%] [G loss: 0.712640]\n",
      "epoch:39 step:30920 [D loss: 0.666933, acc.: 59.38%] [G loss: 0.817738]\n",
      "epoch:39 step:30921 [D loss: 0.677475, acc.: 57.81%] [G loss: 0.805722]\n",
      "epoch:39 step:30922 [D loss: 0.690447, acc.: 52.34%] [G loss: 0.794146]\n",
      "epoch:39 step:30923 [D loss: 0.655001, acc.: 62.50%] [G loss: 0.798441]\n",
      "epoch:39 step:30924 [D loss: 0.696370, acc.: 57.03%] [G loss: 0.742041]\n",
      "epoch:39 step:30925 [D loss: 0.590493, acc.: 80.47%] [G loss: 0.857343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30926 [D loss: 0.684005, acc.: 60.94%] [G loss: 0.806649]\n",
      "epoch:39 step:30927 [D loss: 0.679581, acc.: 53.91%] [G loss: 0.768402]\n",
      "epoch:39 step:30928 [D loss: 0.679627, acc.: 60.16%] [G loss: 0.781827]\n",
      "epoch:39 step:30929 [D loss: 0.716324, acc.: 47.66%] [G loss: 0.772338]\n",
      "epoch:39 step:30930 [D loss: 0.690789, acc.: 53.12%] [G loss: 0.790151]\n",
      "epoch:39 step:30931 [D loss: 0.679129, acc.: 61.72%] [G loss: 0.872933]\n",
      "epoch:39 step:30932 [D loss: 0.713798, acc.: 54.69%] [G loss: 0.740914]\n",
      "epoch:39 step:30933 [D loss: 0.695716, acc.: 50.78%] [G loss: 0.767499]\n",
      "epoch:39 step:30934 [D loss: 0.730324, acc.: 43.75%] [G loss: 0.794931]\n",
      "epoch:39 step:30935 [D loss: 0.657392, acc.: 66.41%] [G loss: 0.852148]\n",
      "epoch:39 step:30936 [D loss: 0.691385, acc.: 56.25%] [G loss: 0.743042]\n",
      "epoch:39 step:30937 [D loss: 0.646398, acc.: 68.75%] [G loss: 0.903022]\n",
      "epoch:39 step:30938 [D loss: 0.694805, acc.: 50.78%] [G loss: 0.797760]\n",
      "epoch:39 step:30939 [D loss: 0.683569, acc.: 58.59%] [G loss: 0.740519]\n",
      "epoch:39 step:30940 [D loss: 0.666589, acc.: 58.59%] [G loss: 0.736686]\n",
      "epoch:39 step:30941 [D loss: 0.695137, acc.: 50.78%] [G loss: 0.758071]\n",
      "epoch:39 step:30942 [D loss: 0.705705, acc.: 46.88%] [G loss: 0.781965]\n",
      "epoch:39 step:30943 [D loss: 0.665120, acc.: 59.38%] [G loss: 0.745520]\n",
      "epoch:39 step:30944 [D loss: 0.613356, acc.: 71.88%] [G loss: 0.793411]\n",
      "epoch:39 step:30945 [D loss: 0.679112, acc.: 58.59%] [G loss: 0.775174]\n",
      "epoch:39 step:30946 [D loss: 0.650548, acc.: 59.38%] [G loss: 0.799731]\n",
      "epoch:39 step:30947 [D loss: 0.672809, acc.: 55.47%] [G loss: 0.722084]\n",
      "epoch:39 step:30948 [D loss: 0.723245, acc.: 45.31%] [G loss: 0.749280]\n",
      "epoch:39 step:30949 [D loss: 0.654345, acc.: 63.28%] [G loss: 0.867800]\n",
      "epoch:39 step:30950 [D loss: 0.661049, acc.: 60.94%] [G loss: 0.759305]\n",
      "epoch:39 step:30951 [D loss: 0.666754, acc.: 59.38%] [G loss: 0.771384]\n",
      "epoch:39 step:30952 [D loss: 0.685530, acc.: 59.38%] [G loss: 0.699996]\n",
      "epoch:39 step:30953 [D loss: 0.678071, acc.: 58.59%] [G loss: 0.802641]\n",
      "epoch:39 step:30954 [D loss: 0.674339, acc.: 58.59%] [G loss: 0.863924]\n",
      "epoch:39 step:30955 [D loss: 0.670192, acc.: 57.81%] [G loss: 0.897731]\n",
      "epoch:39 step:30956 [D loss: 0.650489, acc.: 63.28%] [G loss: 0.918491]\n",
      "epoch:39 step:30957 [D loss: 0.640029, acc.: 65.62%] [G loss: 0.784968]\n",
      "epoch:39 step:30958 [D loss: 0.685718, acc.: 56.25%] [G loss: 0.858029]\n",
      "epoch:39 step:30959 [D loss: 0.667481, acc.: 57.81%] [G loss: 0.774006]\n",
      "epoch:39 step:30960 [D loss: 0.656769, acc.: 60.94%] [G loss: 0.795005]\n",
      "epoch:39 step:30961 [D loss: 0.682056, acc.: 54.69%] [G loss: 0.732326]\n",
      "epoch:39 step:30962 [D loss: 0.719483, acc.: 44.53%] [G loss: 0.755097]\n",
      "epoch:39 step:30963 [D loss: 0.674315, acc.: 58.59%] [G loss: 0.707931]\n",
      "epoch:39 step:30964 [D loss: 0.678181, acc.: 66.41%] [G loss: 0.856278]\n",
      "epoch:39 step:30965 [D loss: 0.620231, acc.: 74.22%] [G loss: 0.861590]\n",
      "epoch:39 step:30966 [D loss: 0.627765, acc.: 66.41%] [G loss: 0.884009]\n",
      "epoch:39 step:30967 [D loss: 0.727871, acc.: 47.66%] [G loss: 0.781086]\n",
      "epoch:39 step:30968 [D loss: 0.683229, acc.: 55.47%] [G loss: 0.802672]\n",
      "epoch:39 step:30969 [D loss: 0.717560, acc.: 45.31%] [G loss: 0.788739]\n",
      "epoch:39 step:30970 [D loss: 0.683738, acc.: 60.16%] [G loss: 0.796933]\n",
      "epoch:39 step:30971 [D loss: 0.777481, acc.: 30.47%] [G loss: 0.732532]\n",
      "epoch:39 step:30972 [D loss: 0.738926, acc.: 46.09%] [G loss: 0.728422]\n",
      "epoch:39 step:30973 [D loss: 0.668984, acc.: 57.03%] [G loss: 0.760697]\n",
      "epoch:39 step:30974 [D loss: 0.664680, acc.: 69.53%] [G loss: 0.720735]\n",
      "epoch:39 step:30975 [D loss: 0.708241, acc.: 43.75%] [G loss: 0.766194]\n",
      "epoch:39 step:30976 [D loss: 0.678624, acc.: 54.69%] [G loss: 0.769970]\n",
      "epoch:39 step:30977 [D loss: 0.616023, acc.: 74.22%] [G loss: 0.899527]\n",
      "epoch:39 step:30978 [D loss: 0.684862, acc.: 56.25%] [G loss: 0.876546]\n",
      "epoch:39 step:30979 [D loss: 0.736239, acc.: 46.09%] [G loss: 0.742223]\n",
      "epoch:39 step:30980 [D loss: 0.663820, acc.: 59.38%] [G loss: 0.754550]\n",
      "epoch:39 step:30981 [D loss: 0.684904, acc.: 56.25%] [G loss: 0.767938]\n",
      "epoch:39 step:30982 [D loss: 0.690495, acc.: 50.78%] [G loss: 0.845325]\n",
      "epoch:39 step:30983 [D loss: 0.679956, acc.: 57.03%] [G loss: 0.794680]\n",
      "epoch:39 step:30984 [D loss: 0.688830, acc.: 50.78%] [G loss: 0.741111]\n",
      "epoch:39 step:30985 [D loss: 0.746047, acc.: 51.56%] [G loss: 0.747095]\n",
      "epoch:39 step:30986 [D loss: 0.732625, acc.: 37.50%] [G loss: 0.757132]\n",
      "epoch:39 step:30987 [D loss: 0.736245, acc.: 40.62%] [G loss: 0.688702]\n",
      "epoch:39 step:30988 [D loss: 0.665645, acc.: 61.72%] [G loss: 0.726635]\n",
      "epoch:39 step:30989 [D loss: 0.684982, acc.: 62.50%] [G loss: 0.754688]\n",
      "epoch:39 step:30990 [D loss: 0.692379, acc.: 50.78%] [G loss: 0.724950]\n",
      "epoch:39 step:30991 [D loss: 0.681127, acc.: 52.34%] [G loss: 0.777293]\n",
      "epoch:39 step:30992 [D loss: 0.703807, acc.: 44.53%] [G loss: 0.836220]\n",
      "epoch:39 step:30993 [D loss: 0.688855, acc.: 59.38%] [G loss: 0.742168]\n",
      "epoch:39 step:30994 [D loss: 0.684218, acc.: 53.12%] [G loss: 0.801541]\n",
      "epoch:39 step:30995 [D loss: 0.691240, acc.: 53.12%] [G loss: 0.840797]\n",
      "epoch:39 step:30996 [D loss: 0.691866, acc.: 53.12%] [G loss: 0.777587]\n",
      "epoch:39 step:30997 [D loss: 0.704165, acc.: 48.44%] [G loss: 0.711481]\n",
      "epoch:39 step:30998 [D loss: 0.714016, acc.: 48.44%] [G loss: 0.779920]\n",
      "epoch:39 step:30999 [D loss: 0.743432, acc.: 41.41%] [G loss: 0.744001]\n",
      "epoch:39 step:31000 [D loss: 0.681811, acc.: 58.59%] [G loss: 0.681581]\n",
      "epoch:39 step:31001 [D loss: 0.734938, acc.: 46.88%] [G loss: 0.670226]\n",
      "epoch:39 step:31002 [D loss: 0.662643, acc.: 57.81%] [G loss: 0.733717]\n",
      "epoch:39 step:31003 [D loss: 0.636090, acc.: 65.62%] [G loss: 0.859312]\n",
      "epoch:39 step:31004 [D loss: 0.672612, acc.: 58.59%] [G loss: 0.866154]\n",
      "epoch:39 step:31005 [D loss: 0.768553, acc.: 36.72%] [G loss: 0.818545]\n",
      "epoch:39 step:31006 [D loss: 0.651549, acc.: 64.84%] [G loss: 0.763643]\n",
      "epoch:39 step:31007 [D loss: 0.629406, acc.: 67.19%] [G loss: 0.908807]\n",
      "epoch:39 step:31008 [D loss: 0.691579, acc.: 52.34%] [G loss: 0.773667]\n",
      "epoch:39 step:31009 [D loss: 0.652917, acc.: 60.16%] [G loss: 0.875702]\n",
      "epoch:39 step:31010 [D loss: 0.660395, acc.: 55.47%] [G loss: 0.846299]\n",
      "epoch:39 step:31011 [D loss: 0.710091, acc.: 50.78%] [G loss: 0.845871]\n",
      "epoch:39 step:31012 [D loss: 0.678940, acc.: 54.69%] [G loss: 0.752590]\n",
      "epoch:39 step:31013 [D loss: 0.666666, acc.: 70.31%] [G loss: 0.761511]\n",
      "epoch:39 step:31014 [D loss: 0.737022, acc.: 45.31%] [G loss: 0.761014]\n",
      "epoch:39 step:31015 [D loss: 0.702290, acc.: 50.00%] [G loss: 0.897144]\n",
      "epoch:39 step:31016 [D loss: 0.694444, acc.: 57.03%] [G loss: 0.740407]\n",
      "epoch:39 step:31017 [D loss: 0.673492, acc.: 58.59%] [G loss: 0.860943]\n",
      "epoch:39 step:31018 [D loss: 0.633341, acc.: 67.19%] [G loss: 0.827572]\n",
      "epoch:39 step:31019 [D loss: 0.609871, acc.: 69.53%] [G loss: 0.802715]\n",
      "epoch:39 step:31020 [D loss: 0.700978, acc.: 52.34%] [G loss: 0.749845]\n",
      "epoch:39 step:31021 [D loss: 0.668106, acc.: 63.28%] [G loss: 0.805287]\n",
      "epoch:39 step:31022 [D loss: 0.693181, acc.: 51.56%] [G loss: 0.778616]\n",
      "epoch:39 step:31023 [D loss: 0.655697, acc.: 57.81%] [G loss: 0.855979]\n",
      "epoch:39 step:31024 [D loss: 0.689376, acc.: 60.16%] [G loss: 0.824736]\n",
      "epoch:39 step:31025 [D loss: 0.653911, acc.: 60.94%] [G loss: 0.862642]\n",
      "epoch:39 step:31026 [D loss: 0.735378, acc.: 42.97%] [G loss: 0.900141]\n",
      "epoch:39 step:31027 [D loss: 0.651633, acc.: 62.50%] [G loss: 0.810121]\n",
      "epoch:39 step:31028 [D loss: 0.663294, acc.: 60.16%] [G loss: 0.795880]\n",
      "epoch:39 step:31029 [D loss: 0.662006, acc.: 58.59%] [G loss: 0.830185]\n",
      "epoch:39 step:31030 [D loss: 0.698292, acc.: 53.91%] [G loss: 0.832159]\n",
      "epoch:39 step:31031 [D loss: 0.653070, acc.: 60.94%] [G loss: 0.844096]\n",
      "epoch:39 step:31032 [D loss: 0.701426, acc.: 53.91%] [G loss: 0.830609]\n",
      "epoch:39 step:31033 [D loss: 0.699368, acc.: 53.91%] [G loss: 0.782504]\n",
      "epoch:39 step:31034 [D loss: 0.722526, acc.: 46.88%] [G loss: 0.814135]\n",
      "epoch:39 step:31035 [D loss: 0.663607, acc.: 56.25%] [G loss: 0.808305]\n",
      "epoch:39 step:31036 [D loss: 0.754406, acc.: 39.84%] [G loss: 0.728677]\n",
      "epoch:39 step:31037 [D loss: 0.659624, acc.: 60.94%] [G loss: 0.836028]\n",
      "epoch:39 step:31038 [D loss: 0.750147, acc.: 35.94%] [G loss: 0.757501]\n",
      "epoch:39 step:31039 [D loss: 0.721414, acc.: 44.53%] [G loss: 0.757765]\n",
      "epoch:39 step:31040 [D loss: 0.717669, acc.: 45.31%] [G loss: 0.682855]\n",
      "epoch:39 step:31041 [D loss: 0.660322, acc.: 60.16%] [G loss: 0.813500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31042 [D loss: 0.676276, acc.: 59.38%] [G loss: 0.808032]\n",
      "epoch:39 step:31043 [D loss: 0.659532, acc.: 63.28%] [G loss: 0.780352]\n",
      "epoch:39 step:31044 [D loss: 0.671049, acc.: 56.25%] [G loss: 0.767971]\n",
      "epoch:39 step:31045 [D loss: 0.687209, acc.: 56.25%] [G loss: 0.752284]\n",
      "epoch:39 step:31046 [D loss: 0.632868, acc.: 61.72%] [G loss: 0.779727]\n",
      "epoch:39 step:31047 [D loss: 0.699084, acc.: 53.12%] [G loss: 0.755464]\n",
      "epoch:39 step:31048 [D loss: 0.640143, acc.: 63.28%] [G loss: 0.848470]\n",
      "epoch:39 step:31049 [D loss: 0.675350, acc.: 57.81%] [G loss: 0.840785]\n",
      "epoch:39 step:31050 [D loss: 0.641586, acc.: 65.62%] [G loss: 0.792629]\n",
      "epoch:39 step:31051 [D loss: 0.657076, acc.: 65.62%] [G loss: 0.795370]\n",
      "epoch:39 step:31052 [D loss: 0.706724, acc.: 52.34%] [G loss: 0.795547]\n",
      "epoch:39 step:31053 [D loss: 0.741112, acc.: 37.50%] [G loss: 0.806521]\n",
      "epoch:39 step:31054 [D loss: 0.626481, acc.: 69.53%] [G loss: 0.704263]\n",
      "epoch:39 step:31055 [D loss: 0.611930, acc.: 70.31%] [G loss: 0.870770]\n",
      "epoch:39 step:31056 [D loss: 0.614008, acc.: 77.34%] [G loss: 0.760402]\n",
      "epoch:39 step:31057 [D loss: 0.637696, acc.: 64.84%] [G loss: 0.736618]\n",
      "epoch:39 step:31058 [D loss: 0.658653, acc.: 57.03%] [G loss: 0.755343]\n",
      "epoch:39 step:31059 [D loss: 0.668808, acc.: 59.38%] [G loss: 0.733286]\n",
      "epoch:39 step:31060 [D loss: 0.655508, acc.: 60.94%] [G loss: 0.742940]\n",
      "epoch:39 step:31061 [D loss: 0.635773, acc.: 67.19%] [G loss: 0.744166]\n",
      "epoch:39 step:31062 [D loss: 0.662896, acc.: 58.59%] [G loss: 0.793255]\n",
      "epoch:39 step:31063 [D loss: 0.697968, acc.: 51.56%] [G loss: 0.778477]\n",
      "epoch:39 step:31064 [D loss: 0.681548, acc.: 58.59%] [G loss: 0.721125]\n",
      "epoch:39 step:31065 [D loss: 0.672593, acc.: 58.59%] [G loss: 0.738624]\n",
      "epoch:39 step:31066 [D loss: 0.635398, acc.: 67.97%] [G loss: 0.706953]\n",
      "epoch:39 step:31067 [D loss: 0.580455, acc.: 76.56%] [G loss: 0.752006]\n",
      "epoch:39 step:31068 [D loss: 0.687177, acc.: 57.81%] [G loss: 0.732533]\n",
      "epoch:39 step:31069 [D loss: 0.653360, acc.: 67.19%] [G loss: 0.712018]\n",
      "epoch:39 step:31070 [D loss: 0.667664, acc.: 63.28%] [G loss: 0.686729]\n",
      "epoch:39 step:31071 [D loss: 0.704995, acc.: 52.34%] [G loss: 0.814192]\n",
      "epoch:39 step:31072 [D loss: 0.731498, acc.: 42.97%] [G loss: 0.791851]\n",
      "epoch:39 step:31073 [D loss: 0.674434, acc.: 63.28%] [G loss: 0.874747]\n",
      "epoch:39 step:31074 [D loss: 0.619829, acc.: 67.19%] [G loss: 0.872025]\n",
      "epoch:39 step:31075 [D loss: 0.698977, acc.: 52.34%] [G loss: 0.743130]\n",
      "epoch:39 step:31076 [D loss: 0.677512, acc.: 55.47%] [G loss: 0.796351]\n",
      "epoch:39 step:31077 [D loss: 0.615969, acc.: 76.56%] [G loss: 0.758907]\n",
      "epoch:39 step:31078 [D loss: 0.679975, acc.: 56.25%] [G loss: 0.829582]\n",
      "epoch:39 step:31079 [D loss: 0.631631, acc.: 66.41%] [G loss: 0.841165]\n",
      "epoch:39 step:31080 [D loss: 0.658102, acc.: 63.28%] [G loss: 0.924438]\n",
      "epoch:39 step:31081 [D loss: 0.638110, acc.: 67.19%] [G loss: 0.864170]\n",
      "epoch:39 step:31082 [D loss: 0.700527, acc.: 53.91%] [G loss: 0.780657]\n",
      "epoch:39 step:31083 [D loss: 0.671347, acc.: 54.69%] [G loss: 0.873674]\n",
      "epoch:39 step:31084 [D loss: 0.644325, acc.: 67.19%] [G loss: 0.760184]\n",
      "epoch:39 step:31085 [D loss: 0.644055, acc.: 64.06%] [G loss: 0.812998]\n",
      "epoch:39 step:31086 [D loss: 0.637898, acc.: 64.06%] [G loss: 0.754488]\n",
      "epoch:39 step:31087 [D loss: 0.660727, acc.: 65.62%] [G loss: 0.874097]\n",
      "epoch:39 step:31088 [D loss: 0.682482, acc.: 57.81%] [G loss: 0.835443]\n",
      "epoch:39 step:31089 [D loss: 0.655605, acc.: 64.84%] [G loss: 0.763323]\n",
      "epoch:39 step:31090 [D loss: 0.695584, acc.: 51.56%] [G loss: 0.695779]\n",
      "epoch:39 step:31091 [D loss: 0.639678, acc.: 67.19%] [G loss: 0.801730]\n",
      "epoch:39 step:31092 [D loss: 0.670537, acc.: 57.03%] [G loss: 0.733935]\n",
      "epoch:39 step:31093 [D loss: 0.701718, acc.: 53.12%] [G loss: 0.796329]\n",
      "epoch:39 step:31094 [D loss: 0.657871, acc.: 57.81%] [G loss: 0.785333]\n",
      "epoch:39 step:31095 [D loss: 0.655569, acc.: 63.28%] [G loss: 0.724939]\n",
      "epoch:39 step:31096 [D loss: 0.701854, acc.: 53.12%] [G loss: 0.785504]\n",
      "epoch:39 step:31097 [D loss: 0.617692, acc.: 71.09%] [G loss: 0.727177]\n",
      "epoch:39 step:31098 [D loss: 0.727268, acc.: 43.75%] [G loss: 0.744904]\n",
      "epoch:39 step:31099 [D loss: 0.679247, acc.: 56.25%] [G loss: 0.799623]\n",
      "epoch:39 step:31100 [D loss: 0.702835, acc.: 46.88%] [G loss: 0.791605]\n",
      "epoch:39 step:31101 [D loss: 0.707535, acc.: 47.66%] [G loss: 0.780881]\n",
      "epoch:39 step:31102 [D loss: 0.659252, acc.: 61.72%] [G loss: 0.817291]\n",
      "epoch:39 step:31103 [D loss: 0.663648, acc.: 64.84%] [G loss: 0.780390]\n",
      "epoch:39 step:31104 [D loss: 0.718559, acc.: 49.22%] [G loss: 0.867633]\n",
      "epoch:39 step:31105 [D loss: 0.698067, acc.: 52.34%] [G loss: 0.917704]\n",
      "epoch:39 step:31106 [D loss: 0.678843, acc.: 55.47%] [G loss: 0.810339]\n",
      "epoch:39 step:31107 [D loss: 0.719250, acc.: 53.91%] [G loss: 0.694733]\n",
      "epoch:39 step:31108 [D loss: 0.652728, acc.: 64.84%] [G loss: 0.821399]\n",
      "epoch:39 step:31109 [D loss: 0.667027, acc.: 59.38%] [G loss: 0.741012]\n",
      "epoch:39 step:31110 [D loss: 0.698363, acc.: 53.91%] [G loss: 0.778837]\n",
      "epoch:39 step:31111 [D loss: 0.658411, acc.: 57.03%] [G loss: 0.780683]\n",
      "epoch:39 step:31112 [D loss: 0.748042, acc.: 42.97%] [G loss: 0.745620]\n",
      "epoch:39 step:31113 [D loss: 0.694166, acc.: 51.56%] [G loss: 0.817119]\n",
      "epoch:39 step:31114 [D loss: 0.704182, acc.: 49.22%] [G loss: 0.818386]\n",
      "epoch:39 step:31115 [D loss: 0.727913, acc.: 36.72%] [G loss: 0.754888]\n",
      "epoch:39 step:31116 [D loss: 0.705309, acc.: 50.00%] [G loss: 0.731793]\n",
      "epoch:39 step:31117 [D loss: 0.658318, acc.: 57.81%] [G loss: 0.838799]\n",
      "epoch:39 step:31118 [D loss: 0.655702, acc.: 67.19%] [G loss: 0.809444]\n",
      "epoch:39 step:31119 [D loss: 0.728948, acc.: 45.31%] [G loss: 0.744431]\n",
      "epoch:39 step:31120 [D loss: 0.660193, acc.: 62.50%] [G loss: 0.716730]\n",
      "epoch:39 step:31121 [D loss: 0.743554, acc.: 39.06%] [G loss: 0.737329]\n",
      "epoch:39 step:31122 [D loss: 0.713392, acc.: 52.34%] [G loss: 0.829490]\n",
      "epoch:39 step:31123 [D loss: 0.711458, acc.: 50.00%] [G loss: 0.806434]\n",
      "epoch:39 step:31124 [D loss: 0.690703, acc.: 56.25%] [G loss: 0.859655]\n",
      "epoch:39 step:31125 [D loss: 0.669005, acc.: 59.38%] [G loss: 0.869238]\n",
      "epoch:39 step:31126 [D loss: 0.706921, acc.: 49.22%] [G loss: 0.902164]\n",
      "epoch:39 step:31127 [D loss: 0.729943, acc.: 48.44%] [G loss: 0.819085]\n",
      "epoch:39 step:31128 [D loss: 0.722954, acc.: 44.53%] [G loss: 0.819371]\n",
      "epoch:39 step:31129 [D loss: 0.721868, acc.: 47.66%] [G loss: 0.839346]\n",
      "epoch:39 step:31130 [D loss: 0.672970, acc.: 53.91%] [G loss: 0.778531]\n",
      "epoch:39 step:31131 [D loss: 0.764225, acc.: 39.06%] [G loss: 0.849945]\n",
      "epoch:39 step:31132 [D loss: 0.659352, acc.: 67.19%] [G loss: 0.848471]\n",
      "epoch:39 step:31133 [D loss: 0.735715, acc.: 44.53%] [G loss: 0.787020]\n",
      "epoch:39 step:31134 [D loss: 0.645364, acc.: 66.41%] [G loss: 0.769056]\n",
      "epoch:39 step:31135 [D loss: 0.682691, acc.: 51.56%] [G loss: 0.707117]\n",
      "epoch:39 step:31136 [D loss: 0.652610, acc.: 61.72%] [G loss: 0.787557]\n",
      "epoch:39 step:31137 [D loss: 0.704478, acc.: 50.00%] [G loss: 0.731393]\n",
      "epoch:39 step:31138 [D loss: 0.656573, acc.: 58.59%] [G loss: 0.792511]\n",
      "epoch:39 step:31139 [D loss: 0.605734, acc.: 72.66%] [G loss: 0.851077]\n",
      "epoch:39 step:31140 [D loss: 0.722686, acc.: 43.75%] [G loss: 0.802767]\n",
      "epoch:39 step:31141 [D loss: 0.665506, acc.: 58.59%] [G loss: 0.783334]\n",
      "epoch:39 step:31142 [D loss: 0.648897, acc.: 61.72%] [G loss: 0.814123]\n",
      "epoch:39 step:31143 [D loss: 0.671687, acc.: 60.16%] [G loss: 0.750458]\n",
      "epoch:39 step:31144 [D loss: 0.656240, acc.: 62.50%] [G loss: 0.771797]\n",
      "epoch:39 step:31145 [D loss: 0.737660, acc.: 39.84%] [G loss: 0.782671]\n",
      "epoch:39 step:31146 [D loss: 0.684140, acc.: 56.25%] [G loss: 0.695025]\n",
      "epoch:39 step:31147 [D loss: 0.721822, acc.: 51.56%] [G loss: 0.783391]\n",
      "epoch:39 step:31148 [D loss: 0.653426, acc.: 60.94%] [G loss: 0.757130]\n",
      "epoch:39 step:31149 [D loss: 0.670512, acc.: 58.59%] [G loss: 0.805252]\n",
      "epoch:39 step:31150 [D loss: 0.658189, acc.: 66.41%] [G loss: 0.792705]\n",
      "epoch:39 step:31151 [D loss: 0.765878, acc.: 39.84%] [G loss: 0.747743]\n",
      "epoch:39 step:31152 [D loss: 0.653451, acc.: 63.28%] [G loss: 0.776066]\n",
      "epoch:39 step:31153 [D loss: 0.654192, acc.: 67.19%] [G loss: 0.798896]\n",
      "epoch:39 step:31154 [D loss: 0.609772, acc.: 70.31%] [G loss: 0.789413]\n",
      "epoch:39 step:31155 [D loss: 0.732132, acc.: 45.31%] [G loss: 0.724388]\n",
      "epoch:39 step:31156 [D loss: 0.731138, acc.: 41.41%] [G loss: 0.717291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31157 [D loss: 0.670873, acc.: 52.34%] [G loss: 0.777666]\n",
      "epoch:39 step:31158 [D loss: 0.693912, acc.: 53.12%] [G loss: 0.758168]\n",
      "epoch:39 step:31159 [D loss: 0.617768, acc.: 71.88%] [G loss: 0.690725]\n",
      "epoch:39 step:31160 [D loss: 0.745698, acc.: 39.06%] [G loss: 0.777923]\n",
      "epoch:39 step:31161 [D loss: 0.662439, acc.: 61.72%] [G loss: 0.828685]\n",
      "epoch:39 step:31162 [D loss: 0.717244, acc.: 45.31%] [G loss: 0.755177]\n",
      "epoch:39 step:31163 [D loss: 0.653475, acc.: 69.53%] [G loss: 0.728476]\n",
      "epoch:39 step:31164 [D loss: 0.702076, acc.: 52.34%] [G loss: 0.788724]\n",
      "epoch:39 step:31165 [D loss: 0.725185, acc.: 45.31%] [G loss: 0.821583]\n",
      "epoch:39 step:31166 [D loss: 0.680669, acc.: 57.81%] [G loss: 0.800495]\n",
      "epoch:39 step:31167 [D loss: 0.661880, acc.: 62.50%] [G loss: 0.838010]\n",
      "epoch:39 step:31168 [D loss: 0.704343, acc.: 50.78%] [G loss: 0.719718]\n",
      "epoch:39 step:31169 [D loss: 0.672559, acc.: 60.16%] [G loss: 0.775089]\n",
      "epoch:39 step:31170 [D loss: 0.727064, acc.: 42.97%] [G loss: 0.662713]\n",
      "epoch:39 step:31171 [D loss: 0.657419, acc.: 64.84%] [G loss: 0.775330]\n",
      "epoch:39 step:31172 [D loss: 0.663351, acc.: 61.72%] [G loss: 0.830454]\n",
      "epoch:39 step:31173 [D loss: 0.663361, acc.: 59.38%] [G loss: 0.834143]\n",
      "epoch:39 step:31174 [D loss: 0.692514, acc.: 60.94%] [G loss: 0.823905]\n",
      "epoch:39 step:31175 [D loss: 0.741600, acc.: 44.53%] [G loss: 0.776109]\n",
      "epoch:39 step:31176 [D loss: 0.640249, acc.: 61.72%] [G loss: 0.773054]\n",
      "epoch:39 step:31177 [D loss: 0.723092, acc.: 41.41%] [G loss: 0.721783]\n",
      "epoch:39 step:31178 [D loss: 0.628922, acc.: 69.53%] [G loss: 0.823216]\n",
      "epoch:39 step:31179 [D loss: 0.708979, acc.: 53.91%] [G loss: 0.813421]\n",
      "epoch:39 step:31180 [D loss: 0.700436, acc.: 54.69%] [G loss: 0.841147]\n",
      "epoch:39 step:31181 [D loss: 0.696717, acc.: 53.12%] [G loss: 0.805230]\n",
      "epoch:39 step:31182 [D loss: 0.757294, acc.: 39.84%] [G loss: 0.796789]\n",
      "epoch:39 step:31183 [D loss: 0.678548, acc.: 51.56%] [G loss: 0.787430]\n",
      "epoch:39 step:31184 [D loss: 0.705680, acc.: 50.78%] [G loss: 0.814765]\n",
      "epoch:39 step:31185 [D loss: 0.659349, acc.: 57.81%] [G loss: 0.811582]\n",
      "epoch:39 step:31186 [D loss: 0.668834, acc.: 57.81%] [G loss: 0.774389]\n",
      "epoch:39 step:31187 [D loss: 0.685220, acc.: 52.34%] [G loss: 0.803796]\n",
      "epoch:39 step:31188 [D loss: 0.678071, acc.: 58.59%] [G loss: 0.717362]\n",
      "epoch:39 step:31189 [D loss: 0.682246, acc.: 56.25%] [G loss: 0.676540]\n",
      "epoch:39 step:31190 [D loss: 0.684250, acc.: 57.03%] [G loss: 0.717025]\n",
      "epoch:39 step:31191 [D loss: 0.721287, acc.: 53.91%] [G loss: 0.788570]\n",
      "epoch:39 step:31192 [D loss: 0.633550, acc.: 69.53%] [G loss: 0.788224]\n",
      "epoch:39 step:31193 [D loss: 0.713429, acc.: 42.97%] [G loss: 0.803067]\n",
      "epoch:39 step:31194 [D loss: 0.652477, acc.: 60.16%] [G loss: 0.814586]\n",
      "epoch:39 step:31195 [D loss: 0.616825, acc.: 74.22%] [G loss: 0.854796]\n",
      "epoch:39 step:31196 [D loss: 0.684724, acc.: 54.69%] [G loss: 0.765103]\n",
      "epoch:39 step:31197 [D loss: 0.674372, acc.: 53.91%] [G loss: 0.771319]\n",
      "epoch:39 step:31198 [D loss: 0.689960, acc.: 59.38%] [G loss: 0.794098]\n",
      "epoch:39 step:31199 [D loss: 0.658996, acc.: 59.38%] [G loss: 0.825485]\n",
      "epoch:39 step:31200 [D loss: 0.649766, acc.: 60.94%] [G loss: 0.805156]\n",
      "epoch:39 step:31201 [D loss: 0.670315, acc.: 50.78%] [G loss: 0.788881]\n",
      "epoch:39 step:31202 [D loss: 0.703431, acc.: 53.91%] [G loss: 0.776917]\n",
      "epoch:39 step:31203 [D loss: 0.682110, acc.: 49.22%] [G loss: 0.730122]\n",
      "epoch:39 step:31204 [D loss: 0.626155, acc.: 69.53%] [G loss: 0.806953]\n",
      "epoch:39 step:31205 [D loss: 0.670505, acc.: 58.59%] [G loss: 0.664326]\n",
      "epoch:39 step:31206 [D loss: 0.705543, acc.: 51.56%] [G loss: 0.720852]\n",
      "epoch:39 step:31207 [D loss: 0.696414, acc.: 52.34%] [G loss: 0.767731]\n",
      "epoch:39 step:31208 [D loss: 0.693439, acc.: 53.91%] [G loss: 0.830411]\n",
      "epoch:39 step:31209 [D loss: 0.690742, acc.: 56.25%] [G loss: 0.735505]\n",
      "epoch:39 step:31210 [D loss: 0.644324, acc.: 63.28%] [G loss: 0.773881]\n",
      "epoch:39 step:31211 [D loss: 0.669633, acc.: 59.38%] [G loss: 0.754009]\n",
      "epoch:39 step:31212 [D loss: 0.661679, acc.: 53.91%] [G loss: 0.730125]\n",
      "epoch:39 step:31213 [D loss: 0.671974, acc.: 57.03%] [G loss: 0.733996]\n",
      "epoch:39 step:31214 [D loss: 0.704759, acc.: 46.88%] [G loss: 0.733249]\n",
      "epoch:39 step:31215 [D loss: 0.714768, acc.: 53.12%] [G loss: 0.785987]\n",
      "epoch:39 step:31216 [D loss: 0.692126, acc.: 52.34%] [G loss: 0.804785]\n",
      "epoch:39 step:31217 [D loss: 0.665372, acc.: 56.25%] [G loss: 0.834383]\n",
      "epoch:39 step:31218 [D loss: 0.743742, acc.: 39.06%] [G loss: 0.818278]\n",
      "epoch:39 step:31219 [D loss: 0.662941, acc.: 57.03%] [G loss: 0.832238]\n",
      "epoch:39 step:31220 [D loss: 0.704177, acc.: 54.69%] [G loss: 0.815601]\n",
      "epoch:39 step:31221 [D loss: 0.716239, acc.: 50.78%] [G loss: 0.819256]\n",
      "epoch:39 step:31222 [D loss: 0.687354, acc.: 57.81%] [G loss: 0.834214]\n",
      "epoch:39 step:31223 [D loss: 0.711183, acc.: 50.00%] [G loss: 0.903460]\n",
      "epoch:39 step:31224 [D loss: 0.632602, acc.: 69.53%] [G loss: 0.774648]\n",
      "epoch:39 step:31225 [D loss: 0.729793, acc.: 46.88%] [G loss: 0.729420]\n",
      "epoch:39 step:31226 [D loss: 0.675222, acc.: 53.91%] [G loss: 0.779230]\n",
      "epoch:39 step:31227 [D loss: 0.644905, acc.: 67.97%] [G loss: 0.777997]\n",
      "epoch:39 step:31228 [D loss: 0.675886, acc.: 53.91%] [G loss: 0.802961]\n",
      "epoch:39 step:31229 [D loss: 0.719348, acc.: 43.75%] [G loss: 0.711144]\n",
      "epoch:39 step:31230 [D loss: 0.745488, acc.: 43.75%] [G loss: 0.737134]\n",
      "epoch:39 step:31231 [D loss: 0.763150, acc.: 40.62%] [G loss: 0.777393]\n",
      "epoch:39 step:31232 [D loss: 0.679546, acc.: 58.59%] [G loss: 0.797965]\n",
      "epoch:39 step:31233 [D loss: 0.667333, acc.: 60.94%] [G loss: 0.771949]\n",
      "epoch:39 step:31234 [D loss: 0.661109, acc.: 58.59%] [G loss: 0.868597]\n",
      "epoch:39 step:31235 [D loss: 0.617266, acc.: 71.88%] [G loss: 0.794516]\n",
      "epoch:39 step:31236 [D loss: 0.675710, acc.: 57.03%] [G loss: 0.793855]\n",
      "epoch:39 step:31237 [D loss: 0.638043, acc.: 67.97%] [G loss: 0.801072]\n",
      "epoch:39 step:31238 [D loss: 0.612074, acc.: 68.75%] [G loss: 0.823655]\n",
      "epoch:39 step:31239 [D loss: 0.709220, acc.: 53.12%] [G loss: 0.809006]\n",
      "epoch:39 step:31240 [D loss: 0.636256, acc.: 63.28%] [G loss: 0.773901]\n",
      "epoch:40 step:31241 [D loss: 0.655494, acc.: 66.41%] [G loss: 0.843594]\n",
      "epoch:40 step:31242 [D loss: 0.614777, acc.: 69.53%] [G loss: 0.851348]\n",
      "epoch:40 step:31243 [D loss: 0.679606, acc.: 57.81%] [G loss: 0.839746]\n",
      "epoch:40 step:31244 [D loss: 0.670477, acc.: 57.81%] [G loss: 0.780927]\n",
      "epoch:40 step:31245 [D loss: 0.720523, acc.: 51.56%] [G loss: 0.719245]\n",
      "epoch:40 step:31246 [D loss: 0.709059, acc.: 52.34%] [G loss: 0.839464]\n",
      "epoch:40 step:31247 [D loss: 0.687810, acc.: 52.34%] [G loss: 0.902035]\n",
      "epoch:40 step:31248 [D loss: 0.681725, acc.: 55.47%] [G loss: 0.939612]\n",
      "epoch:40 step:31249 [D loss: 0.710696, acc.: 45.31%] [G loss: 0.754562]\n",
      "epoch:40 step:31250 [D loss: 0.647019, acc.: 62.50%] [G loss: 0.836024]\n",
      "epoch:40 step:31251 [D loss: 0.729279, acc.: 43.75%] [G loss: 0.773500]\n",
      "epoch:40 step:31252 [D loss: 0.668323, acc.: 60.16%] [G loss: 0.843656]\n",
      "epoch:40 step:31253 [D loss: 0.616856, acc.: 76.56%] [G loss: 0.857125]\n",
      "epoch:40 step:31254 [D loss: 0.712754, acc.: 51.56%] [G loss: 0.868711]\n",
      "epoch:40 step:31255 [D loss: 0.704133, acc.: 52.34%] [G loss: 0.751365]\n",
      "epoch:40 step:31256 [D loss: 0.670779, acc.: 52.34%] [G loss: 0.708091]\n",
      "epoch:40 step:31257 [D loss: 0.690127, acc.: 57.03%] [G loss: 0.845149]\n",
      "epoch:40 step:31258 [D loss: 0.682339, acc.: 60.94%] [G loss: 0.787627]\n",
      "epoch:40 step:31259 [D loss: 0.673443, acc.: 56.25%] [G loss: 0.762067]\n",
      "epoch:40 step:31260 [D loss: 0.645234, acc.: 67.19%] [G loss: 0.757592]\n",
      "epoch:40 step:31261 [D loss: 0.690898, acc.: 55.47%] [G loss: 0.910356]\n",
      "epoch:40 step:31262 [D loss: 0.631386, acc.: 69.53%] [G loss: 0.751167]\n",
      "epoch:40 step:31263 [D loss: 0.742404, acc.: 39.84%] [G loss: 0.756973]\n",
      "epoch:40 step:31264 [D loss: 0.691530, acc.: 53.12%] [G loss: 0.695354]\n",
      "epoch:40 step:31265 [D loss: 0.660792, acc.: 62.50%] [G loss: 0.756285]\n",
      "epoch:40 step:31266 [D loss: 0.764973, acc.: 35.16%] [G loss: 0.663278]\n",
      "epoch:40 step:31267 [D loss: 0.655564, acc.: 61.72%] [G loss: 0.718650]\n",
      "epoch:40 step:31268 [D loss: 0.716154, acc.: 53.12%] [G loss: 0.775487]\n",
      "epoch:40 step:31269 [D loss: 0.713563, acc.: 47.66%] [G loss: 0.757008]\n",
      "epoch:40 step:31270 [D loss: 0.683974, acc.: 57.03%] [G loss: 0.749586]\n",
      "epoch:40 step:31271 [D loss: 0.665690, acc.: 62.50%] [G loss: 0.736724]\n",
      "epoch:40 step:31272 [D loss: 0.692311, acc.: 51.56%] [G loss: 0.790950]\n",
      "epoch:40 step:31273 [D loss: 0.659725, acc.: 58.59%] [G loss: 0.784348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31274 [D loss: 0.658730, acc.: 64.06%] [G loss: 0.743590]\n",
      "epoch:40 step:31275 [D loss: 0.757858, acc.: 43.75%] [G loss: 0.670286]\n",
      "epoch:40 step:31276 [D loss: 0.696849, acc.: 51.56%] [G loss: 0.819331]\n",
      "epoch:40 step:31277 [D loss: 0.652533, acc.: 59.38%] [G loss: 0.753065]\n",
      "epoch:40 step:31278 [D loss: 0.706823, acc.: 52.34%] [G loss: 0.750356]\n",
      "epoch:40 step:31279 [D loss: 0.616380, acc.: 66.41%] [G loss: 0.732154]\n",
      "epoch:40 step:31280 [D loss: 0.669824, acc.: 60.94%] [G loss: 0.748288]\n",
      "epoch:40 step:31281 [D loss: 0.707949, acc.: 50.00%] [G loss: 0.788682]\n",
      "epoch:40 step:31282 [D loss: 0.617928, acc.: 69.53%] [G loss: 0.770067]\n",
      "epoch:40 step:31283 [D loss: 0.702821, acc.: 50.78%] [G loss: 0.717086]\n",
      "epoch:40 step:31284 [D loss: 0.690074, acc.: 57.03%] [G loss: 0.735304]\n",
      "epoch:40 step:31285 [D loss: 0.582066, acc.: 78.12%] [G loss: 0.741829]\n",
      "epoch:40 step:31286 [D loss: 0.672336, acc.: 57.81%] [G loss: 0.703279]\n",
      "epoch:40 step:31287 [D loss: 0.677390, acc.: 60.94%] [G loss: 0.744794]\n",
      "epoch:40 step:31288 [D loss: 0.681550, acc.: 59.38%] [G loss: 0.753743]\n",
      "epoch:40 step:31289 [D loss: 0.757527, acc.: 39.84%] [G loss: 0.740477]\n",
      "epoch:40 step:31290 [D loss: 0.714247, acc.: 58.59%] [G loss: 0.709455]\n",
      "epoch:40 step:31291 [D loss: 0.698425, acc.: 55.47%] [G loss: 0.707038]\n",
      "epoch:40 step:31292 [D loss: 0.708961, acc.: 50.78%] [G loss: 0.695699]\n",
      "epoch:40 step:31293 [D loss: 0.762907, acc.: 39.06%] [G loss: 0.713317]\n",
      "epoch:40 step:31294 [D loss: 0.742966, acc.: 41.41%] [G loss: 0.702192]\n",
      "epoch:40 step:31295 [D loss: 0.722923, acc.: 50.00%] [G loss: 0.706510]\n",
      "epoch:40 step:31296 [D loss: 0.665481, acc.: 60.94%] [G loss: 0.732526]\n",
      "epoch:40 step:31297 [D loss: 0.723332, acc.: 46.09%] [G loss: 0.747894]\n",
      "epoch:40 step:31298 [D loss: 0.725759, acc.: 42.19%] [G loss: 0.777584]\n",
      "epoch:40 step:31299 [D loss: 0.655349, acc.: 59.38%] [G loss: 0.745031]\n",
      "epoch:40 step:31300 [D loss: 0.624283, acc.: 70.31%] [G loss: 0.872349]\n",
      "epoch:40 step:31301 [D loss: 0.705538, acc.: 50.78%] [G loss: 0.885907]\n",
      "epoch:40 step:31302 [D loss: 0.659013, acc.: 57.81%] [G loss: 0.852575]\n",
      "epoch:40 step:31303 [D loss: 0.636715, acc.: 66.41%] [G loss: 0.945161]\n",
      "epoch:40 step:31304 [D loss: 0.667527, acc.: 57.81%] [G loss: 0.945933]\n",
      "epoch:40 step:31305 [D loss: 0.707104, acc.: 52.34%] [G loss: 0.935221]\n",
      "epoch:40 step:31306 [D loss: 0.762547, acc.: 40.62%] [G loss: 0.819487]\n",
      "epoch:40 step:31307 [D loss: 0.674348, acc.: 60.16%] [G loss: 0.867000]\n",
      "epoch:40 step:31308 [D loss: 0.669195, acc.: 61.72%] [G loss: 0.814744]\n",
      "epoch:40 step:31309 [D loss: 0.690247, acc.: 55.47%] [G loss: 0.844831]\n",
      "epoch:40 step:31310 [D loss: 0.735060, acc.: 40.62%] [G loss: 0.801685]\n",
      "epoch:40 step:31311 [D loss: 0.673842, acc.: 58.59%] [G loss: 0.803656]\n",
      "epoch:40 step:31312 [D loss: 0.667807, acc.: 64.06%] [G loss: 0.716566]\n",
      "epoch:40 step:31313 [D loss: 0.593823, acc.: 74.22%] [G loss: 0.746825]\n",
      "epoch:40 step:31314 [D loss: 0.647568, acc.: 66.41%] [G loss: 0.698276]\n",
      "epoch:40 step:31315 [D loss: 0.618552, acc.: 66.41%] [G loss: 0.713272]\n",
      "epoch:40 step:31316 [D loss: 0.717656, acc.: 49.22%] [G loss: 0.740184]\n",
      "epoch:40 step:31317 [D loss: 0.722615, acc.: 50.00%] [G loss: 0.708394]\n",
      "epoch:40 step:31318 [D loss: 0.675652, acc.: 60.94%] [G loss: 0.666436]\n",
      "epoch:40 step:31319 [D loss: 0.667219, acc.: 57.03%] [G loss: 0.811873]\n",
      "epoch:40 step:31320 [D loss: 0.696914, acc.: 53.12%] [G loss: 0.699175]\n",
      "epoch:40 step:31321 [D loss: 0.695969, acc.: 49.22%] [G loss: 0.664713]\n",
      "epoch:40 step:31322 [D loss: 0.705712, acc.: 49.22%] [G loss: 0.724440]\n",
      "epoch:40 step:31323 [D loss: 0.722125, acc.: 46.88%] [G loss: 0.796117]\n",
      "epoch:40 step:31324 [D loss: 0.696412, acc.: 50.78%] [G loss: 0.915326]\n",
      "epoch:40 step:31325 [D loss: 0.685623, acc.: 55.47%] [G loss: 0.847854]\n",
      "epoch:40 step:31326 [D loss: 0.750077, acc.: 42.97%] [G loss: 0.739080]\n",
      "epoch:40 step:31327 [D loss: 0.684843, acc.: 58.59%] [G loss: 0.846806]\n",
      "epoch:40 step:31328 [D loss: 0.739507, acc.: 39.06%] [G loss: 0.694620]\n",
      "epoch:40 step:31329 [D loss: 0.648561, acc.: 65.62%] [G loss: 0.830381]\n",
      "epoch:40 step:31330 [D loss: 0.696243, acc.: 53.91%] [G loss: 0.819584]\n",
      "epoch:40 step:31331 [D loss: 0.699665, acc.: 45.31%] [G loss: 0.792453]\n",
      "epoch:40 step:31332 [D loss: 0.699434, acc.: 49.22%] [G loss: 0.818382]\n",
      "epoch:40 step:31333 [D loss: 0.723261, acc.: 47.66%] [G loss: 0.800577]\n",
      "epoch:40 step:31334 [D loss: 0.673051, acc.: 60.16%] [G loss: 0.713853]\n",
      "epoch:40 step:31335 [D loss: 0.724345, acc.: 46.88%] [G loss: 0.755463]\n",
      "epoch:40 step:31336 [D loss: 0.652370, acc.: 64.06%] [G loss: 0.754106]\n",
      "epoch:40 step:31337 [D loss: 0.688559, acc.: 50.00%] [G loss: 0.793512]\n",
      "epoch:40 step:31338 [D loss: 0.622114, acc.: 68.75%] [G loss: 0.777601]\n",
      "epoch:40 step:31339 [D loss: 0.707859, acc.: 50.00%] [G loss: 0.878726]\n",
      "epoch:40 step:31340 [D loss: 0.590477, acc.: 75.78%] [G loss: 0.831697]\n",
      "epoch:40 step:31341 [D loss: 0.616591, acc.: 71.09%] [G loss: 0.886293]\n",
      "epoch:40 step:31342 [D loss: 0.666102, acc.: 59.38%] [G loss: 0.731088]\n",
      "epoch:40 step:31343 [D loss: 0.682223, acc.: 56.25%] [G loss: 0.790938]\n",
      "epoch:40 step:31344 [D loss: 0.737433, acc.: 46.88%] [G loss: 0.724730]\n",
      "epoch:40 step:31345 [D loss: 0.651190, acc.: 62.50%] [G loss: 0.809670]\n",
      "epoch:40 step:31346 [D loss: 0.610512, acc.: 71.09%] [G loss: 0.832979]\n",
      "epoch:40 step:31347 [D loss: 0.654577, acc.: 60.16%] [G loss: 0.839177]\n",
      "epoch:40 step:31348 [D loss: 0.701403, acc.: 50.00%] [G loss: 0.807676]\n",
      "epoch:40 step:31349 [D loss: 0.700209, acc.: 58.59%] [G loss: 0.762636]\n",
      "epoch:40 step:31350 [D loss: 0.669965, acc.: 58.59%] [G loss: 0.784016]\n",
      "epoch:40 step:31351 [D loss: 0.692599, acc.: 53.12%] [G loss: 0.748613]\n",
      "epoch:40 step:31352 [D loss: 0.655115, acc.: 60.16%] [G loss: 0.718459]\n",
      "epoch:40 step:31353 [D loss: 0.693998, acc.: 51.56%] [G loss: 0.789090]\n",
      "epoch:40 step:31354 [D loss: 0.706751, acc.: 45.31%] [G loss: 0.741485]\n",
      "epoch:40 step:31355 [D loss: 0.647526, acc.: 60.94%] [G loss: 0.783915]\n",
      "epoch:40 step:31356 [D loss: 0.730407, acc.: 44.53%] [G loss: 0.776457]\n",
      "epoch:40 step:31357 [D loss: 0.684163, acc.: 59.38%] [G loss: 0.775089]\n",
      "epoch:40 step:31358 [D loss: 0.699319, acc.: 53.91%] [G loss: 0.802129]\n",
      "epoch:40 step:31359 [D loss: 0.658029, acc.: 63.28%] [G loss: 0.761196]\n",
      "epoch:40 step:31360 [D loss: 0.717903, acc.: 47.66%] [G loss: 0.756945]\n",
      "epoch:40 step:31361 [D loss: 0.664662, acc.: 59.38%] [G loss: 0.841944]\n",
      "epoch:40 step:31362 [D loss: 0.772262, acc.: 36.72%] [G loss: 0.683865]\n",
      "epoch:40 step:31363 [D loss: 0.672406, acc.: 54.69%] [G loss: 0.826052]\n",
      "epoch:40 step:31364 [D loss: 0.669117, acc.: 59.38%] [G loss: 0.774871]\n",
      "epoch:40 step:31365 [D loss: 0.739659, acc.: 43.75%] [G loss: 0.813540]\n",
      "epoch:40 step:31366 [D loss: 0.652261, acc.: 60.94%] [G loss: 0.705774]\n",
      "epoch:40 step:31367 [D loss: 0.627543, acc.: 63.28%] [G loss: 0.702142]\n",
      "epoch:40 step:31368 [D loss: 0.654552, acc.: 61.72%] [G loss: 0.662107]\n",
      "epoch:40 step:31369 [D loss: 0.684248, acc.: 51.56%] [G loss: 0.729277]\n",
      "epoch:40 step:31370 [D loss: 0.638263, acc.: 64.84%] [G loss: 0.762013]\n",
      "epoch:40 step:31371 [D loss: 0.621261, acc.: 67.19%] [G loss: 0.804442]\n",
      "epoch:40 step:31372 [D loss: 0.674333, acc.: 63.28%] [G loss: 0.753643]\n",
      "epoch:40 step:31373 [D loss: 0.705242, acc.: 51.56%] [G loss: 0.743546]\n",
      "epoch:40 step:31374 [D loss: 0.698242, acc.: 51.56%] [G loss: 0.779844]\n",
      "epoch:40 step:31375 [D loss: 0.688754, acc.: 53.91%] [G loss: 0.751055]\n",
      "epoch:40 step:31376 [D loss: 0.721173, acc.: 50.78%] [G loss: 0.736236]\n",
      "epoch:40 step:31377 [D loss: 0.714575, acc.: 43.75%] [G loss: 0.673391]\n",
      "epoch:40 step:31378 [D loss: 0.710710, acc.: 46.88%] [G loss: 0.773834]\n",
      "epoch:40 step:31379 [D loss: 0.711678, acc.: 49.22%] [G loss: 0.695765]\n",
      "epoch:40 step:31380 [D loss: 0.706155, acc.: 50.78%] [G loss: 0.740826]\n",
      "epoch:40 step:31381 [D loss: 0.641643, acc.: 64.06%] [G loss: 0.754627]\n",
      "epoch:40 step:31382 [D loss: 0.678317, acc.: 62.50%] [G loss: 0.812939]\n",
      "epoch:40 step:31383 [D loss: 0.662857, acc.: 60.16%] [G loss: 0.826000]\n",
      "epoch:40 step:31384 [D loss: 0.724151, acc.: 47.66%] [G loss: 0.780262]\n",
      "epoch:40 step:31385 [D loss: 0.664881, acc.: 62.50%] [G loss: 0.771130]\n",
      "epoch:40 step:31386 [D loss: 0.637894, acc.: 68.75%] [G loss: 0.739597]\n",
      "epoch:40 step:31387 [D loss: 0.656493, acc.: 59.38%] [G loss: 0.737828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31388 [D loss: 0.699107, acc.: 50.00%] [G loss: 0.821725]\n",
      "epoch:40 step:31389 [D loss: 0.640211, acc.: 64.06%] [G loss: 0.763884]\n",
      "epoch:40 step:31390 [D loss: 0.707858, acc.: 53.91%] [G loss: 0.846258]\n",
      "epoch:40 step:31391 [D loss: 0.705303, acc.: 51.56%] [G loss: 0.781321]\n",
      "epoch:40 step:31392 [D loss: 0.676200, acc.: 56.25%] [G loss: 0.777688]\n",
      "epoch:40 step:31393 [D loss: 0.703259, acc.: 46.88%] [G loss: 0.814633]\n",
      "epoch:40 step:31394 [D loss: 0.684311, acc.: 60.94%] [G loss: 0.815138]\n",
      "epoch:40 step:31395 [D loss: 0.677836, acc.: 59.38%] [G loss: 0.823980]\n",
      "epoch:40 step:31396 [D loss: 0.701396, acc.: 51.56%] [G loss: 0.764464]\n",
      "epoch:40 step:31397 [D loss: 0.732366, acc.: 43.75%] [G loss: 0.807797]\n",
      "epoch:40 step:31398 [D loss: 0.661640, acc.: 60.16%] [G loss: 0.771749]\n",
      "epoch:40 step:31399 [D loss: 0.675720, acc.: 54.69%] [G loss: 0.797235]\n",
      "epoch:40 step:31400 [D loss: 0.686917, acc.: 60.16%] [G loss: 0.708368]\n",
      "epoch:40 step:31401 [D loss: 0.715216, acc.: 49.22%] [G loss: 0.684138]\n",
      "epoch:40 step:31402 [D loss: 0.691251, acc.: 54.69%] [G loss: 0.730974]\n",
      "epoch:40 step:31403 [D loss: 0.715631, acc.: 52.34%] [G loss: 0.704095]\n",
      "epoch:40 step:31404 [D loss: 0.715492, acc.: 44.53%] [G loss: 0.852386]\n",
      "epoch:40 step:31405 [D loss: 0.731218, acc.: 48.44%] [G loss: 0.807019]\n",
      "epoch:40 step:31406 [D loss: 0.614408, acc.: 69.53%] [G loss: 0.834252]\n",
      "epoch:40 step:31407 [D loss: 0.655537, acc.: 61.72%] [G loss: 0.907740]\n",
      "epoch:40 step:31408 [D loss: 0.682344, acc.: 59.38%] [G loss: 0.807229]\n",
      "epoch:40 step:31409 [D loss: 0.761498, acc.: 38.28%] [G loss: 0.788284]\n",
      "epoch:40 step:31410 [D loss: 0.652879, acc.: 62.50%] [G loss: 0.887888]\n",
      "epoch:40 step:31411 [D loss: 0.721585, acc.: 48.44%] [G loss: 0.885539]\n",
      "epoch:40 step:31412 [D loss: 0.636435, acc.: 64.84%] [G loss: 0.796492]\n",
      "epoch:40 step:31413 [D loss: 0.711223, acc.: 46.09%] [G loss: 0.832134]\n",
      "epoch:40 step:31414 [D loss: 0.700080, acc.: 51.56%] [G loss: 0.850389]\n",
      "epoch:40 step:31415 [D loss: 0.706443, acc.: 53.12%] [G loss: 0.799473]\n",
      "epoch:40 step:31416 [D loss: 0.721635, acc.: 43.75%] [G loss: 0.857481]\n",
      "epoch:40 step:31417 [D loss: 0.704167, acc.: 47.66%] [G loss: 0.942960]\n",
      "epoch:40 step:31418 [D loss: 0.693167, acc.: 52.34%] [G loss: 0.797987]\n",
      "epoch:40 step:31419 [D loss: 0.680244, acc.: 53.12%] [G loss: 0.733356]\n",
      "epoch:40 step:31420 [D loss: 0.731811, acc.: 50.00%] [G loss: 0.809670]\n",
      "epoch:40 step:31421 [D loss: 0.646510, acc.: 67.97%] [G loss: 0.738272]\n",
      "epoch:40 step:31422 [D loss: 0.720411, acc.: 55.47%] [G loss: 0.813761]\n",
      "epoch:40 step:31423 [D loss: 0.669974, acc.: 63.28%] [G loss: 0.666855]\n",
      "epoch:40 step:31424 [D loss: 0.724092, acc.: 46.88%] [G loss: 0.871725]\n",
      "epoch:40 step:31425 [D loss: 0.664515, acc.: 53.12%] [G loss: 0.838088]\n",
      "epoch:40 step:31426 [D loss: 0.630379, acc.: 68.75%] [G loss: 0.758370]\n",
      "epoch:40 step:31427 [D loss: 0.632464, acc.: 66.41%] [G loss: 0.792932]\n",
      "epoch:40 step:31428 [D loss: 0.689721, acc.: 55.47%] [G loss: 0.823329]\n",
      "epoch:40 step:31429 [D loss: 0.686258, acc.: 59.38%] [G loss: 0.803954]\n",
      "epoch:40 step:31430 [D loss: 0.683168, acc.: 55.47%] [G loss: 0.752734]\n",
      "epoch:40 step:31431 [D loss: 0.745680, acc.: 39.84%] [G loss: 0.772396]\n",
      "epoch:40 step:31432 [D loss: 0.682838, acc.: 59.38%] [G loss: 0.780984]\n",
      "epoch:40 step:31433 [D loss: 0.690933, acc.: 57.03%] [G loss: 0.798151]\n",
      "epoch:40 step:31434 [D loss: 0.686979, acc.: 54.69%] [G loss: 0.791260]\n",
      "epoch:40 step:31435 [D loss: 0.748765, acc.: 40.62%] [G loss: 0.792718]\n",
      "epoch:40 step:31436 [D loss: 0.680212, acc.: 57.81%] [G loss: 0.845301]\n",
      "epoch:40 step:31437 [D loss: 0.644721, acc.: 67.19%] [G loss: 0.833365]\n",
      "epoch:40 step:31438 [D loss: 0.698652, acc.: 50.78%] [G loss: 0.815987]\n",
      "epoch:40 step:31439 [D loss: 0.696549, acc.: 51.56%] [G loss: 0.831919]\n",
      "epoch:40 step:31440 [D loss: 0.649512, acc.: 56.25%] [G loss: 0.785963]\n",
      "epoch:40 step:31441 [D loss: 0.619448, acc.: 65.62%] [G loss: 0.838446]\n",
      "epoch:40 step:31442 [D loss: 0.678928, acc.: 57.03%] [G loss: 0.821785]\n",
      "epoch:40 step:31443 [D loss: 0.646886, acc.: 62.50%] [G loss: 0.736410]\n",
      "epoch:40 step:31444 [D loss: 0.762730, acc.: 39.06%] [G loss: 0.717598]\n",
      "epoch:40 step:31445 [D loss: 0.673527, acc.: 57.81%] [G loss: 0.847988]\n",
      "epoch:40 step:31446 [D loss: 0.686616, acc.: 53.12%] [G loss: 0.882959]\n",
      "epoch:40 step:31447 [D loss: 0.659532, acc.: 62.50%] [G loss: 0.775931]\n",
      "epoch:40 step:31448 [D loss: 0.714650, acc.: 51.56%] [G loss: 0.744216]\n",
      "epoch:40 step:31449 [D loss: 0.652814, acc.: 61.72%] [G loss: 0.878562]\n",
      "epoch:40 step:31450 [D loss: 0.651608, acc.: 62.50%] [G loss: 0.851781]\n",
      "epoch:40 step:31451 [D loss: 0.615538, acc.: 69.53%] [G loss: 0.803040]\n",
      "epoch:40 step:31452 [D loss: 0.595908, acc.: 75.78%] [G loss: 0.879784]\n",
      "epoch:40 step:31453 [D loss: 0.700741, acc.: 57.03%] [G loss: 0.817684]\n",
      "epoch:40 step:31454 [D loss: 0.701919, acc.: 52.34%] [G loss: 0.735869]\n",
      "epoch:40 step:31455 [D loss: 0.644924, acc.: 67.19%] [G loss: 0.857716]\n",
      "epoch:40 step:31456 [D loss: 0.764957, acc.: 35.16%] [G loss: 0.777114]\n",
      "epoch:40 step:31457 [D loss: 0.681192, acc.: 53.91%] [G loss: 0.744924]\n",
      "epoch:40 step:31458 [D loss: 0.724568, acc.: 42.19%] [G loss: 0.721813]\n",
      "epoch:40 step:31459 [D loss: 0.718538, acc.: 46.09%] [G loss: 0.751501]\n",
      "epoch:40 step:31460 [D loss: 0.679070, acc.: 54.69%] [G loss: 0.696093]\n",
      "epoch:40 step:31461 [D loss: 0.689633, acc.: 54.69%] [G loss: 0.715904]\n",
      "epoch:40 step:31462 [D loss: 0.695851, acc.: 53.91%] [G loss: 0.773889]\n",
      "epoch:40 step:31463 [D loss: 0.668196, acc.: 57.81%] [G loss: 0.769346]\n",
      "epoch:40 step:31464 [D loss: 0.629829, acc.: 71.88%] [G loss: 0.738531]\n",
      "epoch:40 step:31465 [D loss: 0.730586, acc.: 40.62%] [G loss: 0.667777]\n",
      "epoch:40 step:31466 [D loss: 0.702297, acc.: 55.47%] [G loss: 0.792339]\n",
      "epoch:40 step:31467 [D loss: 0.715413, acc.: 49.22%] [G loss: 0.767471]\n",
      "epoch:40 step:31468 [D loss: 0.726702, acc.: 43.75%] [G loss: 0.801002]\n",
      "epoch:40 step:31469 [D loss: 0.675517, acc.: 52.34%] [G loss: 0.812005]\n",
      "epoch:40 step:31470 [D loss: 0.704594, acc.: 53.91%] [G loss: 0.704801]\n",
      "epoch:40 step:31471 [D loss: 0.643249, acc.: 61.72%] [G loss: 0.744754]\n",
      "epoch:40 step:31472 [D loss: 0.728045, acc.: 48.44%] [G loss: 0.634194]\n",
      "epoch:40 step:31473 [D loss: 0.702137, acc.: 57.81%] [G loss: 0.716404]\n",
      "epoch:40 step:31474 [D loss: 0.744389, acc.: 39.06%] [G loss: 0.681143]\n",
      "epoch:40 step:31475 [D loss: 0.685678, acc.: 47.66%] [G loss: 0.759322]\n",
      "epoch:40 step:31476 [D loss: 0.718396, acc.: 46.09%] [G loss: 0.705135]\n",
      "epoch:40 step:31477 [D loss: 0.642014, acc.: 63.28%] [G loss: 0.787278]\n",
      "epoch:40 step:31478 [D loss: 0.677348, acc.: 56.25%] [G loss: 0.781843]\n",
      "epoch:40 step:31479 [D loss: 0.651373, acc.: 70.31%] [G loss: 0.773984]\n",
      "epoch:40 step:31480 [D loss: 0.693721, acc.: 53.12%] [G loss: 0.740179]\n",
      "epoch:40 step:31481 [D loss: 0.710817, acc.: 43.75%] [G loss: 0.774249]\n",
      "epoch:40 step:31482 [D loss: 0.645274, acc.: 71.09%] [G loss: 0.820285]\n",
      "epoch:40 step:31483 [D loss: 0.678651, acc.: 53.91%] [G loss: 0.811009]\n",
      "epoch:40 step:31484 [D loss: 0.691111, acc.: 51.56%] [G loss: 0.765221]\n",
      "epoch:40 step:31485 [D loss: 0.689352, acc.: 52.34%] [G loss: 0.847386]\n",
      "epoch:40 step:31486 [D loss: 0.699946, acc.: 60.16%] [G loss: 0.778318]\n",
      "epoch:40 step:31487 [D loss: 0.620337, acc.: 69.53%] [G loss: 0.825134]\n",
      "epoch:40 step:31488 [D loss: 0.741081, acc.: 44.53%] [G loss: 0.832702]\n",
      "epoch:40 step:31489 [D loss: 0.695642, acc.: 58.59%] [G loss: 0.885335]\n",
      "epoch:40 step:31490 [D loss: 0.673640, acc.: 58.59%] [G loss: 0.877801]\n",
      "epoch:40 step:31491 [D loss: 0.650252, acc.: 68.75%] [G loss: 0.837359]\n",
      "epoch:40 step:31492 [D loss: 0.602624, acc.: 73.44%] [G loss: 0.909738]\n",
      "epoch:40 step:31493 [D loss: 0.714507, acc.: 54.69%] [G loss: 0.840320]\n",
      "epoch:40 step:31494 [D loss: 0.716980, acc.: 52.34%] [G loss: 0.803383]\n",
      "epoch:40 step:31495 [D loss: 0.687971, acc.: 51.56%] [G loss: 0.760654]\n",
      "epoch:40 step:31496 [D loss: 0.672151, acc.: 56.25%] [G loss: 0.708874]\n",
      "epoch:40 step:31497 [D loss: 0.679013, acc.: 59.38%] [G loss: 0.784789]\n",
      "epoch:40 step:31498 [D loss: 0.680350, acc.: 57.81%] [G loss: 0.759542]\n",
      "epoch:40 step:31499 [D loss: 0.638401, acc.: 70.31%] [G loss: 0.743377]\n",
      "epoch:40 step:31500 [D loss: 0.650965, acc.: 67.97%] [G loss: 0.765143]\n",
      "epoch:40 step:31501 [D loss: 0.666721, acc.: 62.50%] [G loss: 0.900811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31502 [D loss: 0.657737, acc.: 61.72%] [G loss: 0.827934]\n",
      "epoch:40 step:31503 [D loss: 0.684820, acc.: 50.00%] [G loss: 0.796535]\n",
      "epoch:40 step:31504 [D loss: 0.712620, acc.: 48.44%] [G loss: 0.787669]\n",
      "epoch:40 step:31505 [D loss: 0.728948, acc.: 42.97%] [G loss: 0.838320]\n",
      "epoch:40 step:31506 [D loss: 0.688921, acc.: 58.59%] [G loss: 0.830254]\n",
      "epoch:40 step:31507 [D loss: 0.745968, acc.: 50.78%] [G loss: 0.743954]\n",
      "epoch:40 step:31508 [D loss: 0.619418, acc.: 73.44%] [G loss: 0.801714]\n",
      "epoch:40 step:31509 [D loss: 0.611943, acc.: 75.00%] [G loss: 0.798959]\n",
      "epoch:40 step:31510 [D loss: 0.652695, acc.: 57.03%] [G loss: 0.799319]\n",
      "epoch:40 step:31511 [D loss: 0.692380, acc.: 53.12%] [G loss: 0.820962]\n",
      "epoch:40 step:31512 [D loss: 0.686479, acc.: 55.47%] [G loss: 0.760772]\n",
      "epoch:40 step:31513 [D loss: 0.692302, acc.: 55.47%] [G loss: 0.881365]\n",
      "epoch:40 step:31514 [D loss: 0.687045, acc.: 57.03%] [G loss: 0.859024]\n",
      "epoch:40 step:31515 [D loss: 0.694446, acc.: 50.78%] [G loss: 0.778265]\n",
      "epoch:40 step:31516 [D loss: 0.620650, acc.: 71.09%] [G loss: 0.724570]\n",
      "epoch:40 step:31517 [D loss: 0.698840, acc.: 57.03%] [G loss: 0.819662]\n",
      "epoch:40 step:31518 [D loss: 0.712647, acc.: 46.88%] [G loss: 0.610242]\n",
      "epoch:40 step:31519 [D loss: 0.714017, acc.: 49.22%] [G loss: 0.712916]\n",
      "epoch:40 step:31520 [D loss: 0.668210, acc.: 58.59%] [G loss: 0.839028]\n",
      "epoch:40 step:31521 [D loss: 0.641665, acc.: 64.84%] [G loss: 0.891858]\n",
      "epoch:40 step:31522 [D loss: 0.703626, acc.: 52.34%] [G loss: 0.866906]\n",
      "epoch:40 step:31523 [D loss: 0.685041, acc.: 57.81%] [G loss: 0.757165]\n",
      "epoch:40 step:31524 [D loss: 0.681295, acc.: 54.69%] [G loss: 0.889180]\n",
      "epoch:40 step:31525 [D loss: 0.700066, acc.: 51.56%] [G loss: 0.828166]\n",
      "epoch:40 step:31526 [D loss: 0.683153, acc.: 53.91%] [G loss: 0.837361]\n",
      "epoch:40 step:31527 [D loss: 0.700118, acc.: 56.25%] [G loss: 0.871882]\n",
      "epoch:40 step:31528 [D loss: 0.654914, acc.: 59.38%] [G loss: 0.783005]\n",
      "epoch:40 step:31529 [D loss: 0.689941, acc.: 51.56%] [G loss: 0.837433]\n",
      "epoch:40 step:31530 [D loss: 0.658271, acc.: 65.62%] [G loss: 0.843068]\n",
      "epoch:40 step:31531 [D loss: 0.715741, acc.: 48.44%] [G loss: 0.744188]\n",
      "epoch:40 step:31532 [D loss: 0.688189, acc.: 52.34%] [G loss: 0.863697]\n",
      "epoch:40 step:31533 [D loss: 0.676570, acc.: 57.81%] [G loss: 0.699081]\n",
      "epoch:40 step:31534 [D loss: 0.673020, acc.: 57.03%] [G loss: 0.772481]\n",
      "epoch:40 step:31535 [D loss: 0.667741, acc.: 57.81%] [G loss: 0.746108]\n",
      "epoch:40 step:31536 [D loss: 0.670849, acc.: 60.94%] [G loss: 0.803198]\n",
      "epoch:40 step:31537 [D loss: 0.738688, acc.: 47.66%] [G loss: 0.754869]\n",
      "epoch:40 step:31538 [D loss: 0.690215, acc.: 53.12%] [G loss: 0.728784]\n",
      "epoch:40 step:31539 [D loss: 0.711924, acc.: 48.44%] [G loss: 0.835507]\n",
      "epoch:40 step:31540 [D loss: 0.714022, acc.: 44.53%] [G loss: 0.752702]\n",
      "epoch:40 step:31541 [D loss: 0.720244, acc.: 46.09%] [G loss: 0.762024]\n",
      "epoch:40 step:31542 [D loss: 0.687442, acc.: 56.25%] [G loss: 0.740214]\n",
      "epoch:40 step:31543 [D loss: 0.724405, acc.: 46.09%] [G loss: 0.789494]\n",
      "epoch:40 step:31544 [D loss: 0.720392, acc.: 46.88%] [G loss: 0.767558]\n",
      "epoch:40 step:31545 [D loss: 0.703291, acc.: 53.12%] [G loss: 0.713531]\n",
      "epoch:40 step:31546 [D loss: 0.636573, acc.: 67.19%] [G loss: 0.816283]\n",
      "epoch:40 step:31547 [D loss: 0.664147, acc.: 56.25%] [G loss: 0.701025]\n",
      "epoch:40 step:31548 [D loss: 0.648653, acc.: 63.28%] [G loss: 0.757481]\n",
      "epoch:40 step:31549 [D loss: 0.715598, acc.: 50.00%] [G loss: 0.758101]\n",
      "epoch:40 step:31550 [D loss: 0.670530, acc.: 57.03%] [G loss: 0.789744]\n",
      "epoch:40 step:31551 [D loss: 0.696299, acc.: 52.34%] [G loss: 0.838798]\n",
      "epoch:40 step:31552 [D loss: 0.733318, acc.: 46.09%] [G loss: 0.799639]\n",
      "epoch:40 step:31553 [D loss: 0.688938, acc.: 57.03%] [G loss: 0.799993]\n",
      "epoch:40 step:31554 [D loss: 0.704604, acc.: 53.12%] [G loss: 0.844783]\n",
      "epoch:40 step:31555 [D loss: 0.715367, acc.: 50.00%] [G loss: 0.814149]\n",
      "epoch:40 step:31556 [D loss: 0.686365, acc.: 57.03%] [G loss: 0.720237]\n",
      "epoch:40 step:31557 [D loss: 0.649175, acc.: 57.81%] [G loss: 0.805683]\n",
      "epoch:40 step:31558 [D loss: 0.749983, acc.: 42.97%] [G loss: 0.829616]\n",
      "epoch:40 step:31559 [D loss: 0.643767, acc.: 67.97%] [G loss: 0.835450]\n",
      "epoch:40 step:31560 [D loss: 0.681418, acc.: 57.81%] [G loss: 0.928762]\n",
      "epoch:40 step:31561 [D loss: 0.673285, acc.: 56.25%] [G loss: 0.829003]\n",
      "epoch:40 step:31562 [D loss: 0.744186, acc.: 43.75%] [G loss: 0.741861]\n",
      "epoch:40 step:31563 [D loss: 0.692989, acc.: 48.44%] [G loss: 0.822755]\n",
      "epoch:40 step:31564 [D loss: 0.689405, acc.: 52.34%] [G loss: 0.708910]\n",
      "epoch:40 step:31565 [D loss: 0.703891, acc.: 55.47%] [G loss: 0.807793]\n",
      "epoch:40 step:31566 [D loss: 0.669514, acc.: 56.25%] [G loss: 0.796583]\n",
      "epoch:40 step:31567 [D loss: 0.695675, acc.: 53.12%] [G loss: 0.791549]\n",
      "epoch:40 step:31568 [D loss: 0.695097, acc.: 55.47%] [G loss: 0.808780]\n",
      "epoch:40 step:31569 [D loss: 0.719598, acc.: 52.34%] [G loss: 0.733814]\n",
      "epoch:40 step:31570 [D loss: 0.666081, acc.: 59.38%] [G loss: 0.668897]\n",
      "epoch:40 step:31571 [D loss: 0.733183, acc.: 44.53%] [G loss: 0.836114]\n",
      "epoch:40 step:31572 [D loss: 0.713646, acc.: 46.88%] [G loss: 0.786161]\n",
      "epoch:40 step:31573 [D loss: 0.667470, acc.: 62.50%] [G loss: 0.714290]\n",
      "epoch:40 step:31574 [D loss: 0.695973, acc.: 48.44%] [G loss: 0.799719]\n",
      "epoch:40 step:31575 [D loss: 0.712368, acc.: 48.44%] [G loss: 0.796112]\n",
      "epoch:40 step:31576 [D loss: 0.641290, acc.: 61.72%] [G loss: 0.856586]\n",
      "epoch:40 step:31577 [D loss: 0.719820, acc.: 50.78%] [G loss: 0.681074]\n",
      "epoch:40 step:31578 [D loss: 0.732215, acc.: 48.44%] [G loss: 0.727857]\n",
      "epoch:40 step:31579 [D loss: 0.680390, acc.: 58.59%] [G loss: 0.813411]\n",
      "epoch:40 step:31580 [D loss: 0.686005, acc.: 53.91%] [G loss: 0.828440]\n",
      "epoch:40 step:31581 [D loss: 0.651052, acc.: 67.19%] [G loss: 0.839662]\n",
      "epoch:40 step:31582 [D loss: 0.686620, acc.: 60.94%] [G loss: 0.710696]\n",
      "epoch:40 step:31583 [D loss: 0.629654, acc.: 71.09%] [G loss: 0.784209]\n",
      "epoch:40 step:31584 [D loss: 0.650189, acc.: 69.53%] [G loss: 0.833412]\n",
      "epoch:40 step:31585 [D loss: 0.656284, acc.: 63.28%] [G loss: 0.804412]\n",
      "epoch:40 step:31586 [D loss: 0.724477, acc.: 46.88%] [G loss: 0.808489]\n",
      "epoch:40 step:31587 [D loss: 0.635548, acc.: 69.53%] [G loss: 0.769939]\n",
      "epoch:40 step:31588 [D loss: 0.688141, acc.: 56.25%] [G loss: 0.828586]\n",
      "epoch:40 step:31589 [D loss: 0.682903, acc.: 60.16%] [G loss: 0.843020]\n",
      "epoch:40 step:31590 [D loss: 0.730443, acc.: 45.31%] [G loss: 0.827152]\n",
      "epoch:40 step:31591 [D loss: 0.723367, acc.: 45.31%] [G loss: 0.801806]\n",
      "epoch:40 step:31592 [D loss: 0.675940, acc.: 57.03%] [G loss: 0.919840]\n",
      "epoch:40 step:31593 [D loss: 0.678422, acc.: 53.91%] [G loss: 0.837882]\n",
      "epoch:40 step:31594 [D loss: 0.711010, acc.: 48.44%] [G loss: 0.761596]\n",
      "epoch:40 step:31595 [D loss: 0.720967, acc.: 42.97%] [G loss: 0.732243]\n",
      "epoch:40 step:31596 [D loss: 0.728033, acc.: 41.41%] [G loss: 0.703867]\n",
      "epoch:40 step:31597 [D loss: 0.671862, acc.: 57.03%] [G loss: 0.754681]\n",
      "epoch:40 step:31598 [D loss: 0.687326, acc.: 58.59%] [G loss: 0.789508]\n",
      "epoch:40 step:31599 [D loss: 0.720282, acc.: 44.53%] [G loss: 0.761342]\n",
      "epoch:40 step:31600 [D loss: 0.644446, acc.: 65.62%] [G loss: 0.762358]\n",
      "epoch:40 step:31601 [D loss: 0.631923, acc.: 67.19%] [G loss: 0.834351]\n",
      "epoch:40 step:31602 [D loss: 0.694462, acc.: 55.47%] [G loss: 0.772052]\n",
      "epoch:40 step:31603 [D loss: 0.692740, acc.: 52.34%] [G loss: 0.826287]\n",
      "epoch:40 step:31604 [D loss: 0.754585, acc.: 44.53%] [G loss: 0.742552]\n",
      "epoch:40 step:31605 [D loss: 0.686929, acc.: 51.56%] [G loss: 0.734965]\n",
      "epoch:40 step:31606 [D loss: 0.641313, acc.: 66.41%] [G loss: 0.797118]\n",
      "epoch:40 step:31607 [D loss: 0.717258, acc.: 52.34%] [G loss: 0.801422]\n",
      "epoch:40 step:31608 [D loss: 0.640531, acc.: 65.62%] [G loss: 0.851516]\n",
      "epoch:40 step:31609 [D loss: 0.707958, acc.: 53.91%] [G loss: 0.745244]\n",
      "epoch:40 step:31610 [D loss: 0.615332, acc.: 71.09%] [G loss: 0.806321]\n",
      "epoch:40 step:31611 [D loss: 0.600079, acc.: 74.22%] [G loss: 0.856284]\n",
      "epoch:40 step:31612 [D loss: 0.724044, acc.: 45.31%] [G loss: 0.757467]\n",
      "epoch:40 step:31613 [D loss: 0.668471, acc.: 63.28%] [G loss: 0.856380]\n",
      "epoch:40 step:31614 [D loss: 0.700602, acc.: 50.00%] [G loss: 0.874353]\n",
      "epoch:40 step:31615 [D loss: 0.705350, acc.: 55.47%] [G loss: 0.771634]\n",
      "epoch:40 step:31616 [D loss: 0.619339, acc.: 74.22%] [G loss: 0.848886]\n",
      "epoch:40 step:31617 [D loss: 0.682469, acc.: 57.81%] [G loss: 0.887644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31618 [D loss: 0.632071, acc.: 70.31%] [G loss: 0.763153]\n",
      "epoch:40 step:31619 [D loss: 0.692496, acc.: 57.03%] [G loss: 0.848963]\n",
      "epoch:40 step:31620 [D loss: 0.661601, acc.: 61.72%] [G loss: 0.890908]\n",
      "epoch:40 step:31621 [D loss: 0.593981, acc.: 68.75%] [G loss: 0.832579]\n",
      "epoch:40 step:31622 [D loss: 0.678776, acc.: 58.59%] [G loss: 0.780032]\n",
      "epoch:40 step:31623 [D loss: 0.616716, acc.: 71.88%] [G loss: 0.850496]\n",
      "epoch:40 step:31624 [D loss: 0.646396, acc.: 67.97%] [G loss: 0.818444]\n",
      "epoch:40 step:31625 [D loss: 0.709978, acc.: 48.44%] [G loss: 0.780469]\n",
      "epoch:40 step:31626 [D loss: 0.646019, acc.: 64.84%] [G loss: 0.820183]\n",
      "epoch:40 step:31627 [D loss: 0.690742, acc.: 56.25%] [G loss: 0.795179]\n",
      "epoch:40 step:31628 [D loss: 0.744777, acc.: 41.41%] [G loss: 0.803956]\n",
      "epoch:40 step:31629 [D loss: 0.736972, acc.: 43.75%] [G loss: 0.760807]\n",
      "epoch:40 step:31630 [D loss: 0.665876, acc.: 59.38%] [G loss: 0.834458]\n",
      "epoch:40 step:31631 [D loss: 0.702333, acc.: 53.12%] [G loss: 0.832605]\n",
      "epoch:40 step:31632 [D loss: 0.658958, acc.: 57.81%] [G loss: 0.804743]\n",
      "epoch:40 step:31633 [D loss: 0.653447, acc.: 62.50%] [G loss: 0.736349]\n",
      "epoch:40 step:31634 [D loss: 0.631145, acc.: 63.28%] [G loss: 0.807002]\n",
      "epoch:40 step:31635 [D loss: 0.699601, acc.: 51.56%] [G loss: 0.766387]\n",
      "epoch:40 step:31636 [D loss: 0.728793, acc.: 43.75%] [G loss: 0.763829]\n",
      "epoch:40 step:31637 [D loss: 0.689519, acc.: 52.34%] [G loss: 0.837245]\n",
      "epoch:40 step:31638 [D loss: 0.714688, acc.: 44.53%] [G loss: 0.724810]\n",
      "epoch:40 step:31639 [D loss: 0.692523, acc.: 52.34%] [G loss: 0.846081]\n",
      "epoch:40 step:31640 [D loss: 0.685128, acc.: 56.25%] [G loss: 0.872892]\n",
      "epoch:40 step:31641 [D loss: 0.652737, acc.: 63.28%] [G loss: 0.767406]\n",
      "epoch:40 step:31642 [D loss: 0.665758, acc.: 63.28%] [G loss: 0.773123]\n",
      "epoch:40 step:31643 [D loss: 0.685023, acc.: 55.47%] [G loss: 0.804348]\n",
      "epoch:40 step:31644 [D loss: 0.685926, acc.: 53.91%] [G loss: 0.797835]\n",
      "epoch:40 step:31645 [D loss: 0.681095, acc.: 55.47%] [G loss: 0.852438]\n",
      "epoch:40 step:31646 [D loss: 0.705273, acc.: 47.66%] [G loss: 0.826312]\n",
      "epoch:40 step:31647 [D loss: 0.669764, acc.: 57.03%] [G loss: 0.752358]\n",
      "epoch:40 step:31648 [D loss: 0.700199, acc.: 53.12%] [G loss: 0.779069]\n",
      "epoch:40 step:31649 [D loss: 0.741130, acc.: 41.41%] [G loss: 0.708349]\n",
      "epoch:40 step:31650 [D loss: 0.681025, acc.: 57.81%] [G loss: 0.834233]\n",
      "epoch:40 step:31651 [D loss: 0.708124, acc.: 47.66%] [G loss: 0.821994]\n",
      "epoch:40 step:31652 [D loss: 0.738298, acc.: 43.75%] [G loss: 0.818052]\n",
      "epoch:40 step:31653 [D loss: 0.664591, acc.: 57.03%] [G loss: 0.796280]\n",
      "epoch:40 step:31654 [D loss: 0.689616, acc.: 57.03%] [G loss: 0.765562]\n",
      "epoch:40 step:31655 [D loss: 0.641396, acc.: 66.41%] [G loss: 0.731031]\n",
      "epoch:40 step:31656 [D loss: 0.671728, acc.: 59.38%] [G loss: 0.817820]\n",
      "epoch:40 step:31657 [D loss: 0.668518, acc.: 52.34%] [G loss: 0.771788]\n",
      "epoch:40 step:31658 [D loss: 0.676296, acc.: 57.81%] [G loss: 0.881913]\n",
      "epoch:40 step:31659 [D loss: 0.679907, acc.: 57.81%] [G loss: 0.792796]\n",
      "epoch:40 step:31660 [D loss: 0.767745, acc.: 31.25%] [G loss: 0.753220]\n",
      "epoch:40 step:31661 [D loss: 0.657741, acc.: 66.41%] [G loss: 0.739747]\n",
      "epoch:40 step:31662 [D loss: 0.656951, acc.: 59.38%] [G loss: 0.836622]\n",
      "epoch:40 step:31663 [D loss: 0.687401, acc.: 56.25%] [G loss: 0.799432]\n",
      "epoch:40 step:31664 [D loss: 0.696611, acc.: 50.78%] [G loss: 0.782561]\n",
      "epoch:40 step:31665 [D loss: 0.686575, acc.: 52.34%] [G loss: 0.751003]\n",
      "epoch:40 step:31666 [D loss: 0.648852, acc.: 61.72%] [G loss: 0.714813]\n",
      "epoch:40 step:31667 [D loss: 0.699975, acc.: 54.69%] [G loss: 0.727792]\n",
      "epoch:40 step:31668 [D loss: 0.676982, acc.: 54.69%] [G loss: 0.762201]\n",
      "epoch:40 step:31669 [D loss: 0.645034, acc.: 60.16%] [G loss: 0.680224]\n",
      "epoch:40 step:31670 [D loss: 0.626069, acc.: 67.19%] [G loss: 0.770154]\n",
      "epoch:40 step:31671 [D loss: 0.734942, acc.: 46.09%] [G loss: 0.715278]\n",
      "epoch:40 step:31672 [D loss: 0.667621, acc.: 55.47%] [G loss: 0.784853]\n",
      "epoch:40 step:31673 [D loss: 0.673973, acc.: 58.59%] [G loss: 0.767646]\n",
      "epoch:40 step:31674 [D loss: 0.715137, acc.: 45.31%] [G loss: 0.757576]\n",
      "epoch:40 step:31675 [D loss: 0.748605, acc.: 36.72%] [G loss: 0.813797]\n",
      "epoch:40 step:31676 [D loss: 0.712814, acc.: 49.22%] [G loss: 0.850118]\n",
      "epoch:40 step:31677 [D loss: 0.705589, acc.: 48.44%] [G loss: 0.835608]\n",
      "epoch:40 step:31678 [D loss: 0.656322, acc.: 60.16%] [G loss: 0.811652]\n",
      "epoch:40 step:31679 [D loss: 0.690422, acc.: 53.91%] [G loss: 0.831815]\n",
      "epoch:40 step:31680 [D loss: 0.659640, acc.: 58.59%] [G loss: 0.937435]\n",
      "epoch:40 step:31681 [D loss: 0.707763, acc.: 49.22%] [G loss: 0.822613]\n",
      "epoch:40 step:31682 [D loss: 0.714061, acc.: 44.53%] [G loss: 0.728362]\n",
      "epoch:40 step:31683 [D loss: 0.706784, acc.: 50.00%] [G loss: 0.775830]\n",
      "epoch:40 step:31684 [D loss: 0.699239, acc.: 57.03%] [G loss: 0.803155]\n",
      "epoch:40 step:31685 [D loss: 0.690779, acc.: 50.78%] [G loss: 0.795909]\n",
      "epoch:40 step:31686 [D loss: 0.727621, acc.: 43.75%] [G loss: 0.780361]\n",
      "epoch:40 step:31687 [D loss: 0.663658, acc.: 61.72%] [G loss: 0.799753]\n",
      "epoch:40 step:31688 [D loss: 0.681306, acc.: 57.81%] [G loss: 0.846114]\n",
      "epoch:40 step:31689 [D loss: 0.703180, acc.: 57.03%] [G loss: 0.848870]\n",
      "epoch:40 step:31690 [D loss: 0.724678, acc.: 48.44%] [G loss: 0.852992]\n",
      "epoch:40 step:31691 [D loss: 0.682313, acc.: 53.91%] [G loss: 0.832804]\n",
      "epoch:40 step:31692 [D loss: 0.662132, acc.: 61.72%] [G loss: 0.786580]\n",
      "epoch:40 step:31693 [D loss: 0.685497, acc.: 58.59%] [G loss: 0.790869]\n",
      "epoch:40 step:31694 [D loss: 0.673071, acc.: 57.03%] [G loss: 0.833189]\n",
      "epoch:40 step:31695 [D loss: 0.681651, acc.: 53.91%] [G loss: 0.731903]\n",
      "epoch:40 step:31696 [D loss: 0.720364, acc.: 46.09%] [G loss: 0.781469]\n",
      "epoch:40 step:31697 [D loss: 0.716807, acc.: 45.31%] [G loss: 0.744637]\n",
      "epoch:40 step:31698 [D loss: 0.703116, acc.: 53.12%] [G loss: 0.860413]\n",
      "epoch:40 step:31699 [D loss: 0.743264, acc.: 47.66%] [G loss: 0.824487]\n",
      "epoch:40 step:31700 [D loss: 0.719317, acc.: 44.53%] [G loss: 0.748397]\n",
      "epoch:40 step:31701 [D loss: 0.690287, acc.: 53.12%] [G loss: 0.811154]\n",
      "epoch:40 step:31702 [D loss: 0.680822, acc.: 58.59%] [G loss: 0.832293]\n",
      "epoch:40 step:31703 [D loss: 0.704013, acc.: 48.44%] [G loss: 0.881856]\n",
      "epoch:40 step:31704 [D loss: 0.724946, acc.: 48.44%] [G loss: 0.694561]\n",
      "epoch:40 step:31705 [D loss: 0.662529, acc.: 63.28%] [G loss: 0.841687]\n",
      "epoch:40 step:31706 [D loss: 0.614708, acc.: 73.44%] [G loss: 0.837413]\n",
      "epoch:40 step:31707 [D loss: 0.679153, acc.: 52.34%] [G loss: 0.857188]\n",
      "epoch:40 step:31708 [D loss: 0.661488, acc.: 60.94%] [G loss: 0.839555]\n",
      "epoch:40 step:31709 [D loss: 0.646322, acc.: 61.72%] [G loss: 0.918657]\n",
      "epoch:40 step:31710 [D loss: 0.702924, acc.: 53.12%] [G loss: 0.744460]\n",
      "epoch:40 step:31711 [D loss: 0.675611, acc.: 55.47%] [G loss: 0.824560]\n",
      "epoch:40 step:31712 [D loss: 0.690618, acc.: 55.47%] [G loss: 0.751943]\n",
      "epoch:40 step:31713 [D loss: 0.703297, acc.: 53.91%] [G loss: 0.765799]\n",
      "epoch:40 step:31714 [D loss: 0.654192, acc.: 62.50%] [G loss: 0.754189]\n",
      "epoch:40 step:31715 [D loss: 0.719084, acc.: 46.88%] [G loss: 0.699892]\n",
      "epoch:40 step:31716 [D loss: 0.661847, acc.: 67.97%] [G loss: 0.794639]\n",
      "epoch:40 step:31717 [D loss: 0.686374, acc.: 60.16%] [G loss: 0.775066]\n",
      "epoch:40 step:31718 [D loss: 0.612585, acc.: 70.31%] [G loss: 0.786292]\n",
      "epoch:40 step:31719 [D loss: 0.685447, acc.: 60.94%] [G loss: 0.831682]\n",
      "epoch:40 step:31720 [D loss: 0.633817, acc.: 65.62%] [G loss: 0.783065]\n",
      "epoch:40 step:31721 [D loss: 0.648868, acc.: 67.19%] [G loss: 0.746605]\n",
      "epoch:40 step:31722 [D loss: 0.659210, acc.: 59.38%] [G loss: 0.685099]\n",
      "epoch:40 step:31723 [D loss: 0.739268, acc.: 42.19%] [G loss: 0.705344]\n",
      "epoch:40 step:31724 [D loss: 0.729036, acc.: 49.22%] [G loss: 0.750412]\n",
      "epoch:40 step:31725 [D loss: 0.683998, acc.: 50.78%] [G loss: 0.700467]\n",
      "epoch:40 step:31726 [D loss: 0.721439, acc.: 46.88%] [G loss: 0.782674]\n",
      "epoch:40 step:31727 [D loss: 0.710200, acc.: 46.09%] [G loss: 0.764626]\n",
      "epoch:40 step:31728 [D loss: 0.726507, acc.: 42.97%] [G loss: 0.756716]\n",
      "epoch:40 step:31729 [D loss: 0.721186, acc.: 46.88%] [G loss: 0.763554]\n",
      "epoch:40 step:31730 [D loss: 0.674682, acc.: 53.91%] [G loss: 0.762755]\n",
      "epoch:40 step:31731 [D loss: 0.723828, acc.: 49.22%] [G loss: 0.762229]\n",
      "epoch:40 step:31732 [D loss: 0.660605, acc.: 60.94%] [G loss: 0.763057]\n",
      "epoch:40 step:31733 [D loss: 0.662708, acc.: 60.16%] [G loss: 0.740599]\n",
      "epoch:40 step:31734 [D loss: 0.654904, acc.: 58.59%] [G loss: 0.692282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31735 [D loss: 0.701999, acc.: 53.12%] [G loss: 0.727190]\n",
      "epoch:40 step:31736 [D loss: 0.646541, acc.: 67.97%] [G loss: 0.826984]\n",
      "epoch:40 step:31737 [D loss: 0.667318, acc.: 56.25%] [G loss: 0.822601]\n",
      "epoch:40 step:31738 [D loss: 0.646828, acc.: 65.62%] [G loss: 0.767563]\n",
      "epoch:40 step:31739 [D loss: 0.607013, acc.: 71.88%] [G loss: 0.849276]\n",
      "epoch:40 step:31740 [D loss: 0.639592, acc.: 67.97%] [G loss: 0.816927]\n",
      "epoch:40 step:31741 [D loss: 0.663906, acc.: 61.72%] [G loss: 0.849792]\n",
      "epoch:40 step:31742 [D loss: 0.692166, acc.: 56.25%] [G loss: 0.845925]\n",
      "epoch:40 step:31743 [D loss: 0.646873, acc.: 64.84%] [G loss: 0.910823]\n",
      "epoch:40 step:31744 [D loss: 0.654933, acc.: 64.06%] [G loss: 0.803874]\n",
      "epoch:40 step:31745 [D loss: 0.656810, acc.: 64.84%] [G loss: 0.860032]\n",
      "epoch:40 step:31746 [D loss: 0.639808, acc.: 71.88%] [G loss: 0.786452]\n",
      "epoch:40 step:31747 [D loss: 0.652759, acc.: 67.19%] [G loss: 0.743740]\n",
      "epoch:40 step:31748 [D loss: 0.720796, acc.: 48.44%] [G loss: 0.780649]\n",
      "epoch:40 step:31749 [D loss: 0.659463, acc.: 64.06%] [G loss: 0.753691]\n",
      "epoch:40 step:31750 [D loss: 0.641852, acc.: 64.84%] [G loss: 0.772575]\n",
      "epoch:40 step:31751 [D loss: 0.719609, acc.: 46.09%] [G loss: 0.767247]\n",
      "epoch:40 step:31752 [D loss: 0.749890, acc.: 41.41%] [G loss: 0.720060]\n",
      "epoch:40 step:31753 [D loss: 0.712489, acc.: 50.78%] [G loss: 0.745391]\n",
      "epoch:40 step:31754 [D loss: 0.639948, acc.: 63.28%] [G loss: 0.736722]\n",
      "epoch:40 step:31755 [D loss: 0.714148, acc.: 54.69%] [G loss: 0.671195]\n",
      "epoch:40 step:31756 [D loss: 0.659536, acc.: 60.16%] [G loss: 0.765923]\n",
      "epoch:40 step:31757 [D loss: 0.709739, acc.: 56.25%] [G loss: 0.764909]\n",
      "epoch:40 step:31758 [D loss: 0.600172, acc.: 72.66%] [G loss: 0.813008]\n",
      "epoch:40 step:31759 [D loss: 0.746385, acc.: 39.06%] [G loss: 0.893605]\n",
      "epoch:40 step:31760 [D loss: 0.704572, acc.: 50.00%] [G loss: 0.799927]\n",
      "epoch:40 step:31761 [D loss: 0.687744, acc.: 53.12%] [G loss: 0.828782]\n",
      "epoch:40 step:31762 [D loss: 0.677241, acc.: 54.69%] [G loss: 0.750543]\n",
      "epoch:40 step:31763 [D loss: 0.670358, acc.: 62.50%] [G loss: 0.722274]\n",
      "epoch:40 step:31764 [D loss: 0.706193, acc.: 53.12%] [G loss: 0.826441]\n",
      "epoch:40 step:31765 [D loss: 0.621768, acc.: 71.88%] [G loss: 0.794124]\n",
      "epoch:40 step:31766 [D loss: 0.794746, acc.: 32.81%] [G loss: 0.769667]\n",
      "epoch:40 step:31767 [D loss: 0.747288, acc.: 35.94%] [G loss: 0.700291]\n",
      "epoch:40 step:31768 [D loss: 0.702651, acc.: 53.12%] [G loss: 0.680012]\n",
      "epoch:40 step:31769 [D loss: 0.641105, acc.: 60.94%] [G loss: 0.699093]\n",
      "epoch:40 step:31770 [D loss: 0.624989, acc.: 74.22%] [G loss: 0.804008]\n",
      "epoch:40 step:31771 [D loss: 0.707151, acc.: 53.12%] [G loss: 0.825186]\n",
      "epoch:40 step:31772 [D loss: 0.728744, acc.: 50.00%] [G loss: 0.809675]\n",
      "epoch:40 step:31773 [D loss: 0.684758, acc.: 54.69%] [G loss: 0.793743]\n",
      "epoch:40 step:31774 [D loss: 0.668298, acc.: 62.50%] [G loss: 0.794029]\n",
      "epoch:40 step:31775 [D loss: 0.646863, acc.: 66.41%] [G loss: 0.816801]\n",
      "epoch:40 step:31776 [D loss: 0.673451, acc.: 60.94%] [G loss: 0.809526]\n",
      "epoch:40 step:31777 [D loss: 0.677420, acc.: 54.69%] [G loss: 0.829945]\n",
      "epoch:40 step:31778 [D loss: 0.678570, acc.: 52.34%] [G loss: 0.905400]\n",
      "epoch:40 step:31779 [D loss: 0.696707, acc.: 60.16%] [G loss: 0.807409]\n",
      "epoch:40 step:31780 [D loss: 0.700276, acc.: 47.66%] [G loss: 0.817413]\n",
      "epoch:40 step:31781 [D loss: 0.691645, acc.: 59.38%] [G loss: 0.817663]\n",
      "epoch:40 step:31782 [D loss: 0.656924, acc.: 66.41%] [G loss: 0.705046]\n",
      "epoch:40 step:31783 [D loss: 0.672704, acc.: 57.03%] [G loss: 0.749102]\n",
      "epoch:40 step:31784 [D loss: 0.715106, acc.: 51.56%] [G loss: 0.834826]\n",
      "epoch:40 step:31785 [D loss: 0.590618, acc.: 78.12%] [G loss: 0.753302]\n",
      "epoch:40 step:31786 [D loss: 0.735514, acc.: 43.75%] [G loss: 0.746757]\n",
      "epoch:40 step:31787 [D loss: 0.626700, acc.: 67.97%] [G loss: 0.828765]\n",
      "epoch:40 step:31788 [D loss: 0.675921, acc.: 57.81%] [G loss: 0.822704]\n",
      "epoch:40 step:31789 [D loss: 0.711200, acc.: 50.00%] [G loss: 0.805437]\n",
      "epoch:40 step:31790 [D loss: 0.684325, acc.: 57.03%] [G loss: 0.826040]\n",
      "epoch:40 step:31791 [D loss: 0.644361, acc.: 66.41%] [G loss: 0.900925]\n",
      "epoch:40 step:31792 [D loss: 0.710153, acc.: 46.09%] [G loss: 0.785117]\n",
      "epoch:40 step:31793 [D loss: 0.624492, acc.: 65.62%] [G loss: 0.821234]\n",
      "epoch:40 step:31794 [D loss: 0.628931, acc.: 64.84%] [G loss: 0.866355]\n",
      "epoch:40 step:31795 [D loss: 0.708459, acc.: 50.00%] [G loss: 0.808456]\n",
      "epoch:40 step:31796 [D loss: 0.736331, acc.: 51.56%] [G loss: 0.750697]\n",
      "epoch:40 step:31797 [D loss: 0.682961, acc.: 53.12%] [G loss: 0.756297]\n",
      "epoch:40 step:31798 [D loss: 0.677958, acc.: 54.69%] [G loss: 0.851620]\n",
      "epoch:40 step:31799 [D loss: 0.633535, acc.: 69.53%] [G loss: 0.853663]\n",
      "epoch:40 step:31800 [D loss: 0.639159, acc.: 58.59%] [G loss: 0.793844]\n",
      "epoch:40 step:31801 [D loss: 0.660067, acc.: 67.97%] [G loss: 0.735690]\n",
      "epoch:40 step:31802 [D loss: 0.649473, acc.: 63.28%] [G loss: 0.850704]\n",
      "epoch:40 step:31803 [D loss: 0.739991, acc.: 42.19%] [G loss: 0.761789]\n",
      "epoch:40 step:31804 [D loss: 0.682560, acc.: 55.47%] [G loss: 0.758050]\n",
      "epoch:40 step:31805 [D loss: 0.676974, acc.: 54.69%] [G loss: 0.808182]\n",
      "epoch:40 step:31806 [D loss: 0.678121, acc.: 58.59%] [G loss: 0.804773]\n",
      "epoch:40 step:31807 [D loss: 0.637459, acc.: 68.75%] [G loss: 0.804470]\n",
      "epoch:40 step:31808 [D loss: 0.633918, acc.: 71.88%] [G loss: 0.776140]\n",
      "epoch:40 step:31809 [D loss: 0.654394, acc.: 60.16%] [G loss: 0.807785]\n",
      "epoch:40 step:31810 [D loss: 0.679948, acc.: 58.59%] [G loss: 0.821452]\n",
      "epoch:40 step:31811 [D loss: 0.726604, acc.: 46.88%] [G loss: 0.742998]\n",
      "epoch:40 step:31812 [D loss: 0.680425, acc.: 56.25%] [G loss: 0.783997]\n",
      "epoch:40 step:31813 [D loss: 0.666406, acc.: 64.06%] [G loss: 0.844789]\n",
      "epoch:40 step:31814 [D loss: 0.698340, acc.: 50.00%] [G loss: 0.810727]\n",
      "epoch:40 step:31815 [D loss: 0.688596, acc.: 57.81%] [G loss: 0.806914]\n",
      "epoch:40 step:31816 [D loss: 0.628171, acc.: 71.09%] [G loss: 0.790524]\n",
      "epoch:40 step:31817 [D loss: 0.639295, acc.: 64.84%] [G loss: 0.903989]\n",
      "epoch:40 step:31818 [D loss: 0.626508, acc.: 74.22%] [G loss: 0.755633]\n",
      "epoch:40 step:31819 [D loss: 0.643781, acc.: 66.41%] [G loss: 0.756929]\n",
      "epoch:40 step:31820 [D loss: 0.683712, acc.: 52.34%] [G loss: 0.756952]\n",
      "epoch:40 step:31821 [D loss: 0.667928, acc.: 60.16%] [G loss: 0.786492]\n",
      "epoch:40 step:31822 [D loss: 0.670874, acc.: 61.72%] [G loss: 0.855241]\n",
      "epoch:40 step:31823 [D loss: 0.665250, acc.: 60.16%] [G loss: 0.762515]\n",
      "epoch:40 step:31824 [D loss: 0.651251, acc.: 59.38%] [G loss: 0.760380]\n",
      "epoch:40 step:31825 [D loss: 0.672032, acc.: 60.16%] [G loss: 0.832697]\n",
      "epoch:40 step:31826 [D loss: 0.673239, acc.: 56.25%] [G loss: 0.801518]\n",
      "epoch:40 step:31827 [D loss: 0.682611, acc.: 57.03%] [G loss: 0.765664]\n",
      "epoch:40 step:31828 [D loss: 0.655931, acc.: 62.50%] [G loss: 0.752223]\n",
      "epoch:40 step:31829 [D loss: 0.696253, acc.: 53.12%] [G loss: 0.728694]\n",
      "epoch:40 step:31830 [D loss: 0.715656, acc.: 48.44%] [G loss: 0.669488]\n",
      "epoch:40 step:31831 [D loss: 0.664652, acc.: 54.69%] [G loss: 0.830791]\n",
      "epoch:40 step:31832 [D loss: 0.643893, acc.: 67.19%] [G loss: 0.921193]\n",
      "epoch:40 step:31833 [D loss: 0.663808, acc.: 57.81%] [G loss: 0.856411]\n",
      "epoch:40 step:31834 [D loss: 0.662331, acc.: 57.03%] [G loss: 0.952262]\n",
      "epoch:40 step:31835 [D loss: 0.634372, acc.: 67.97%] [G loss: 0.807165]\n",
      "epoch:40 step:31836 [D loss: 0.694831, acc.: 48.44%] [G loss: 0.802919]\n",
      "epoch:40 step:31837 [D loss: 0.701181, acc.: 57.81%] [G loss: 0.789495]\n",
      "epoch:40 step:31838 [D loss: 0.690302, acc.: 54.69%] [G loss: 0.822083]\n",
      "epoch:40 step:31839 [D loss: 0.707127, acc.: 50.00%] [G loss: 0.769827]\n",
      "epoch:40 step:31840 [D loss: 0.675402, acc.: 52.34%] [G loss: 0.804319]\n",
      "epoch:40 step:31841 [D loss: 0.692192, acc.: 54.69%] [G loss: 0.790926]\n",
      "epoch:40 step:31842 [D loss: 0.669024, acc.: 60.94%] [G loss: 0.785103]\n",
      "epoch:40 step:31843 [D loss: 0.711192, acc.: 43.75%] [G loss: 0.781635]\n",
      "epoch:40 step:31844 [D loss: 0.709344, acc.: 48.44%] [G loss: 0.775661]\n",
      "epoch:40 step:31845 [D loss: 0.673057, acc.: 57.03%] [G loss: 0.800945]\n",
      "epoch:40 step:31846 [D loss: 0.664896, acc.: 60.16%] [G loss: 0.861938]\n",
      "epoch:40 step:31847 [D loss: 0.686511, acc.: 56.25%] [G loss: 0.781530]\n",
      "epoch:40 step:31848 [D loss: 0.704728, acc.: 47.66%] [G loss: 0.750179]\n",
      "epoch:40 step:31849 [D loss: 0.673403, acc.: 58.59%] [G loss: 0.749939]\n",
      "epoch:40 step:31850 [D loss: 0.734512, acc.: 50.00%] [G loss: 0.712441]\n",
      "epoch:40 step:31851 [D loss: 0.764848, acc.: 41.41%] [G loss: 0.794038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31852 [D loss: 0.661146, acc.: 60.16%] [G loss: 0.816320]\n",
      "epoch:40 step:31853 [D loss: 0.740043, acc.: 37.50%] [G loss: 0.783756]\n",
      "epoch:40 step:31854 [D loss: 0.676129, acc.: 57.03%] [G loss: 0.798459]\n",
      "epoch:40 step:31855 [D loss: 0.731039, acc.: 47.66%] [G loss: 0.807210]\n",
      "epoch:40 step:31856 [D loss: 0.643089, acc.: 61.72%] [G loss: 0.782590]\n",
      "epoch:40 step:31857 [D loss: 0.660828, acc.: 58.59%] [G loss: 0.808178]\n",
      "epoch:40 step:31858 [D loss: 0.690476, acc.: 63.28%] [G loss: 0.864756]\n",
      "epoch:40 step:31859 [D loss: 0.675195, acc.: 54.69%] [G loss: 0.762878]\n",
      "epoch:40 step:31860 [D loss: 0.764127, acc.: 35.16%] [G loss: 0.831472]\n",
      "epoch:40 step:31861 [D loss: 0.685241, acc.: 53.91%] [G loss: 0.792444]\n",
      "epoch:40 step:31862 [D loss: 0.685237, acc.: 57.81%] [G loss: 0.879395]\n",
      "epoch:40 step:31863 [D loss: 0.665568, acc.: 61.72%] [G loss: 0.794117]\n",
      "epoch:40 step:31864 [D loss: 0.700842, acc.: 53.12%] [G loss: 0.805319]\n",
      "epoch:40 step:31865 [D loss: 0.710721, acc.: 50.78%] [G loss: 0.746155]\n",
      "epoch:40 step:31866 [D loss: 0.672954, acc.: 60.16%] [G loss: 0.765448]\n",
      "epoch:40 step:31867 [D loss: 0.650838, acc.: 64.06%] [G loss: 0.802538]\n",
      "epoch:40 step:31868 [D loss: 0.680362, acc.: 64.06%] [G loss: 0.796981]\n",
      "epoch:40 step:31869 [D loss: 0.679282, acc.: 59.38%] [G loss: 0.830492]\n",
      "epoch:40 step:31870 [D loss: 0.656936, acc.: 61.72%] [G loss: 0.749678]\n",
      "epoch:40 step:31871 [D loss: 0.679024, acc.: 59.38%] [G loss: 0.767512]\n",
      "epoch:40 step:31872 [D loss: 0.665081, acc.: 59.38%] [G loss: 0.768703]\n",
      "epoch:40 step:31873 [D loss: 0.718821, acc.: 46.88%] [G loss: 0.700744]\n",
      "epoch:40 step:31874 [D loss: 0.699368, acc.: 52.34%] [G loss: 0.776400]\n",
      "epoch:40 step:31875 [D loss: 0.670587, acc.: 57.03%] [G loss: 0.784292]\n",
      "epoch:40 step:31876 [D loss: 0.704191, acc.: 50.78%] [G loss: 0.736295]\n",
      "epoch:40 step:31877 [D loss: 0.676153, acc.: 59.38%] [G loss: 0.698144]\n",
      "epoch:40 step:31878 [D loss: 0.675655, acc.: 55.47%] [G loss: 0.792595]\n",
      "epoch:40 step:31879 [D loss: 0.644000, acc.: 65.62%] [G loss: 0.843911]\n",
      "epoch:40 step:31880 [D loss: 0.678095, acc.: 54.69%] [G loss: 0.760075]\n",
      "epoch:40 step:31881 [D loss: 0.673802, acc.: 51.56%] [G loss: 0.799333]\n",
      "epoch:40 step:31882 [D loss: 0.683152, acc.: 55.47%] [G loss: 0.711846]\n",
      "epoch:40 step:31883 [D loss: 0.722109, acc.: 46.09%] [G loss: 0.772225]\n",
      "epoch:40 step:31884 [D loss: 0.666220, acc.: 67.19%] [G loss: 0.673787]\n",
      "epoch:40 step:31885 [D loss: 0.712045, acc.: 50.00%] [G loss: 0.754551]\n",
      "epoch:40 step:31886 [D loss: 0.677061, acc.: 53.12%] [G loss: 0.705558]\n",
      "epoch:40 step:31887 [D loss: 0.731435, acc.: 45.31%] [G loss: 0.690732]\n",
      "epoch:40 step:31888 [D loss: 0.625001, acc.: 71.09%] [G loss: 0.770440]\n",
      "epoch:40 step:31889 [D loss: 0.682545, acc.: 56.25%] [G loss: 0.775686]\n",
      "epoch:40 step:31890 [D loss: 0.661095, acc.: 64.06%] [G loss: 0.713664]\n",
      "epoch:40 step:31891 [D loss: 0.681221, acc.: 59.38%] [G loss: 0.763372]\n",
      "epoch:40 step:31892 [D loss: 0.611116, acc.: 67.97%] [G loss: 0.898917]\n",
      "epoch:40 step:31893 [D loss: 0.690417, acc.: 56.25%] [G loss: 0.866280]\n",
      "epoch:40 step:31894 [D loss: 0.674917, acc.: 59.38%] [G loss: 0.754081]\n",
      "epoch:40 step:31895 [D loss: 0.756343, acc.: 43.75%] [G loss: 0.704745]\n",
      "epoch:40 step:31896 [D loss: 0.732299, acc.: 40.62%] [G loss: 0.702400]\n",
      "epoch:40 step:31897 [D loss: 0.643759, acc.: 63.28%] [G loss: 0.788218]\n",
      "epoch:40 step:31898 [D loss: 0.671114, acc.: 61.72%] [G loss: 0.798223]\n",
      "epoch:40 step:31899 [D loss: 0.741443, acc.: 42.19%] [G loss: 0.801305]\n",
      "epoch:40 step:31900 [D loss: 0.675785, acc.: 60.16%] [G loss: 0.845353]\n",
      "epoch:40 step:31901 [D loss: 0.647766, acc.: 64.06%] [G loss: 0.823934]\n",
      "epoch:40 step:31902 [D loss: 0.701803, acc.: 51.56%] [G loss: 0.826737]\n",
      "epoch:40 step:31903 [D loss: 0.633483, acc.: 71.88%] [G loss: 0.774116]\n",
      "epoch:40 step:31904 [D loss: 0.690096, acc.: 46.88%] [G loss: 0.854558]\n",
      "epoch:40 step:31905 [D loss: 0.685809, acc.: 58.59%] [G loss: 0.705126]\n",
      "epoch:40 step:31906 [D loss: 0.625357, acc.: 71.09%] [G loss: 0.753807]\n",
      "epoch:40 step:31907 [D loss: 0.700946, acc.: 53.91%] [G loss: 0.757684]\n",
      "epoch:40 step:31908 [D loss: 0.675649, acc.: 60.94%] [G loss: 0.701678]\n",
      "epoch:40 step:31909 [D loss: 0.713080, acc.: 47.66%] [G loss: 0.798804]\n",
      "epoch:40 step:31910 [D loss: 0.728194, acc.: 49.22%] [G loss: 0.780048]\n",
      "epoch:40 step:31911 [D loss: 0.665558, acc.: 64.06%] [G loss: 0.822545]\n",
      "epoch:40 step:31912 [D loss: 0.689313, acc.: 47.66%] [G loss: 0.870360]\n",
      "epoch:40 step:31913 [D loss: 0.697090, acc.: 60.94%] [G loss: 0.862926]\n",
      "epoch:40 step:31914 [D loss: 0.676966, acc.: 56.25%] [G loss: 0.801200]\n",
      "epoch:40 step:31915 [D loss: 0.713414, acc.: 50.78%] [G loss: 0.829670]\n",
      "epoch:40 step:31916 [D loss: 0.768171, acc.: 39.06%] [G loss: 0.752684]\n",
      "epoch:40 step:31917 [D loss: 0.654844, acc.: 62.50%] [G loss: 0.811852]\n",
      "epoch:40 step:31918 [D loss: 0.668580, acc.: 60.16%] [G loss: 0.804645]\n",
      "epoch:40 step:31919 [D loss: 0.662764, acc.: 61.72%] [G loss: 0.850803]\n",
      "epoch:40 step:31920 [D loss: 0.667485, acc.: 59.38%] [G loss: 0.850324]\n",
      "epoch:40 step:31921 [D loss: 0.627485, acc.: 63.28%] [G loss: 0.925140]\n",
      "epoch:40 step:31922 [D loss: 0.707646, acc.: 51.56%] [G loss: 0.804317]\n",
      "epoch:40 step:31923 [D loss: 0.686557, acc.: 59.38%] [G loss: 0.855405]\n",
      "epoch:40 step:31924 [D loss: 0.679339, acc.: 54.69%] [G loss: 0.842807]\n",
      "epoch:40 step:31925 [D loss: 0.654883, acc.: 65.62%] [G loss: 0.860343]\n",
      "epoch:40 step:31926 [D loss: 0.687602, acc.: 54.69%] [G loss: 0.833377]\n",
      "epoch:40 step:31927 [D loss: 0.594158, acc.: 74.22%] [G loss: 0.857718]\n",
      "epoch:40 step:31928 [D loss: 0.663240, acc.: 57.03%] [G loss: 0.787255]\n",
      "epoch:40 step:31929 [D loss: 0.640774, acc.: 66.41%] [G loss: 0.729206]\n",
      "epoch:40 step:31930 [D loss: 0.614590, acc.: 75.78%] [G loss: 0.804723]\n",
      "epoch:40 step:31931 [D loss: 0.680982, acc.: 53.12%] [G loss: 0.827492]\n",
      "epoch:40 step:31932 [D loss: 0.844684, acc.: 32.03%] [G loss: 0.708789]\n",
      "epoch:40 step:31933 [D loss: 0.662452, acc.: 58.59%] [G loss: 0.686291]\n",
      "epoch:40 step:31934 [D loss: 0.646671, acc.: 61.72%] [G loss: 0.735160]\n",
      "epoch:40 step:31935 [D loss: 0.643544, acc.: 69.53%] [G loss: 0.743507]\n",
      "epoch:40 step:31936 [D loss: 0.742813, acc.: 36.72%] [G loss: 0.741731]\n",
      "epoch:40 step:31937 [D loss: 0.712976, acc.: 47.66%] [G loss: 0.713051]\n",
      "epoch:40 step:31938 [D loss: 0.674821, acc.: 53.91%] [G loss: 0.633855]\n",
      "epoch:40 step:31939 [D loss: 0.707414, acc.: 50.00%] [G loss: 0.749410]\n",
      "epoch:40 step:31940 [D loss: 0.611375, acc.: 74.22%] [G loss: 0.737853]\n",
      "epoch:40 step:31941 [D loss: 0.701130, acc.: 54.69%] [G loss: 0.742028]\n",
      "epoch:40 step:31942 [D loss: 0.737735, acc.: 39.84%] [G loss: 0.772593]\n",
      "epoch:40 step:31943 [D loss: 0.773292, acc.: 31.25%] [G loss: 0.678513]\n",
      "epoch:40 step:31944 [D loss: 0.636960, acc.: 68.75%] [G loss: 0.782515]\n",
      "epoch:40 step:31945 [D loss: 0.740969, acc.: 41.41%] [G loss: 0.754350]\n",
      "epoch:40 step:31946 [D loss: 0.660473, acc.: 64.06%] [G loss: 0.702889]\n",
      "epoch:40 step:31947 [D loss: 0.693660, acc.: 57.81%] [G loss: 0.706601]\n",
      "epoch:40 step:31948 [D loss: 0.732746, acc.: 42.19%] [G loss: 0.742961]\n",
      "epoch:40 step:31949 [D loss: 0.611143, acc.: 71.88%] [G loss: 0.804811]\n",
      "epoch:40 step:31950 [D loss: 0.641370, acc.: 72.66%] [G loss: 0.767093]\n",
      "epoch:40 step:31951 [D loss: 0.663770, acc.: 58.59%] [G loss: 0.779628]\n",
      "epoch:40 step:31952 [D loss: 0.653805, acc.: 62.50%] [G loss: 0.759647]\n",
      "epoch:40 step:31953 [D loss: 0.718726, acc.: 42.19%] [G loss: 0.781891]\n",
      "epoch:40 step:31954 [D loss: 0.657474, acc.: 59.38%] [G loss: 0.903326]\n",
      "epoch:40 step:31955 [D loss: 0.688523, acc.: 58.59%] [G loss: 0.809108]\n",
      "epoch:40 step:31956 [D loss: 0.656957, acc.: 64.06%] [G loss: 0.851949]\n",
      "epoch:40 step:31957 [D loss: 0.671004, acc.: 59.38%] [G loss: 0.795544]\n",
      "epoch:40 step:31958 [D loss: 0.701409, acc.: 51.56%] [G loss: 0.790877]\n",
      "epoch:40 step:31959 [D loss: 0.650276, acc.: 60.94%] [G loss: 0.789983]\n",
      "epoch:40 step:31960 [D loss: 0.732154, acc.: 50.78%] [G loss: 0.716732]\n",
      "epoch:40 step:31961 [D loss: 0.749450, acc.: 39.06%] [G loss: 0.784905]\n",
      "epoch:40 step:31962 [D loss: 0.709596, acc.: 50.78%] [G loss: 0.724769]\n",
      "epoch:40 step:31963 [D loss: 0.747741, acc.: 38.28%] [G loss: 0.741104]\n",
      "epoch:40 step:31964 [D loss: 0.666862, acc.: 54.69%] [G loss: 0.728859]\n",
      "epoch:40 step:31965 [D loss: 0.659142, acc.: 64.06%] [G loss: 0.782855]\n",
      "epoch:40 step:31966 [D loss: 0.643942, acc.: 66.41%] [G loss: 0.803629]\n",
      "epoch:40 step:31967 [D loss: 0.723178, acc.: 52.34%] [G loss: 0.783668]\n",
      "epoch:40 step:31968 [D loss: 0.640343, acc.: 65.62%] [G loss: 0.747615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31969 [D loss: 0.665821, acc.: 62.50%] [G loss: 0.697931]\n",
      "epoch:40 step:31970 [D loss: 0.705569, acc.: 51.56%] [G loss: 0.695990]\n",
      "epoch:40 step:31971 [D loss: 0.697192, acc.: 54.69%] [G loss: 0.716559]\n",
      "epoch:40 step:31972 [D loss: 0.678925, acc.: 55.47%] [G loss: 0.706458]\n",
      "epoch:40 step:31973 [D loss: 0.748055, acc.: 38.28%] [G loss: 0.687535]\n",
      "epoch:40 step:31974 [D loss: 0.710005, acc.: 49.22%] [G loss: 0.681913]\n",
      "epoch:40 step:31975 [D loss: 0.701592, acc.: 53.91%] [G loss: 0.841329]\n",
      "epoch:40 step:31976 [D loss: 0.658256, acc.: 56.25%] [G loss: 0.796319]\n",
      "epoch:40 step:31977 [D loss: 0.742688, acc.: 39.06%] [G loss: 0.774616]\n",
      "epoch:40 step:31978 [D loss: 0.711331, acc.: 49.22%] [G loss: 0.825139]\n",
      "epoch:40 step:31979 [D loss: 0.711981, acc.: 49.22%] [G loss: 0.843670]\n",
      "epoch:40 step:31980 [D loss: 0.668857, acc.: 56.25%] [G loss: 0.751151]\n",
      "epoch:40 step:31981 [D loss: 0.739500, acc.: 42.19%] [G loss: 0.775569]\n",
      "epoch:40 step:31982 [D loss: 0.678454, acc.: 56.25%] [G loss: 0.863900]\n",
      "epoch:40 step:31983 [D loss: 0.699448, acc.: 54.69%] [G loss: 0.712047]\n",
      "epoch:40 step:31984 [D loss: 0.650645, acc.: 63.28%] [G loss: 0.719550]\n",
      "epoch:40 step:31985 [D loss: 0.646482, acc.: 68.75%] [G loss: 0.730513]\n",
      "epoch:40 step:31986 [D loss: 0.691692, acc.: 57.03%] [G loss: 0.805607]\n",
      "epoch:40 step:31987 [D loss: 0.671346, acc.: 54.69%] [G loss: 0.792054]\n",
      "epoch:40 step:31988 [D loss: 0.655015, acc.: 60.94%] [G loss: 0.798327]\n",
      "epoch:40 step:31989 [D loss: 0.683000, acc.: 55.47%] [G loss: 0.767097]\n",
      "epoch:40 step:31990 [D loss: 0.660164, acc.: 62.50%] [G loss: 0.864548]\n",
      "epoch:40 step:31991 [D loss: 0.661659, acc.: 66.41%] [G loss: 0.809391]\n",
      "epoch:40 step:31992 [D loss: 0.684424, acc.: 53.12%] [G loss: 0.767131]\n",
      "epoch:40 step:31993 [D loss: 0.654194, acc.: 64.06%] [G loss: 0.734720]\n",
      "epoch:40 step:31994 [D loss: 0.661327, acc.: 64.06%] [G loss: 0.827981]\n",
      "epoch:40 step:31995 [D loss: 0.646778, acc.: 64.84%] [G loss: 0.778246]\n",
      "epoch:40 step:31996 [D loss: 0.697351, acc.: 49.22%] [G loss: 0.791903]\n",
      "epoch:40 step:31997 [D loss: 0.693218, acc.: 57.03%] [G loss: 0.741655]\n",
      "epoch:40 step:31998 [D loss: 0.694209, acc.: 59.38%] [G loss: 0.748704]\n",
      "epoch:40 step:31999 [D loss: 0.720506, acc.: 48.44%] [G loss: 0.786023]\n",
      "epoch:40 step:32000 [D loss: 0.680170, acc.: 55.47%] [G loss: 0.693748]\n",
      "epoch:40 step:32001 [D loss: 0.606586, acc.: 74.22%] [G loss: 0.757992]\n",
      "epoch:40 step:32002 [D loss: 0.790979, acc.: 33.59%] [G loss: 0.742551]\n",
      "epoch:40 step:32003 [D loss: 0.763613, acc.: 39.06%] [G loss: 0.729953]\n",
      "epoch:40 step:32004 [D loss: 0.693213, acc.: 53.91%] [G loss: 0.835152]\n",
      "epoch:40 step:32005 [D loss: 0.686717, acc.: 52.34%] [G loss: 0.816637]\n",
      "epoch:40 step:32006 [D loss: 0.666620, acc.: 57.81%] [G loss: 0.843319]\n",
      "epoch:40 step:32007 [D loss: 0.704366, acc.: 52.34%] [G loss: 0.859897]\n",
      "epoch:40 step:32008 [D loss: 0.675137, acc.: 61.72%] [G loss: 0.787372]\n",
      "epoch:40 step:32009 [D loss: 0.706711, acc.: 51.56%] [G loss: 0.854799]\n",
      "epoch:40 step:32010 [D loss: 0.614713, acc.: 66.41%] [G loss: 0.905787]\n",
      "epoch:40 step:32011 [D loss: 0.704544, acc.: 46.88%] [G loss: 0.850420]\n",
      "epoch:40 step:32012 [D loss: 0.693731, acc.: 55.47%] [G loss: 0.802475]\n",
      "epoch:40 step:32013 [D loss: 0.661315, acc.: 58.59%] [G loss: 0.869228]\n",
      "epoch:40 step:32014 [D loss: 0.712215, acc.: 48.44%] [G loss: 0.779636]\n",
      "epoch:40 step:32015 [D loss: 0.737774, acc.: 46.09%] [G loss: 0.750066]\n",
      "epoch:40 step:32016 [D loss: 0.694763, acc.: 56.25%] [G loss: 0.867203]\n",
      "epoch:40 step:32017 [D loss: 0.678409, acc.: 52.34%] [G loss: 0.756949]\n",
      "epoch:40 step:32018 [D loss: 0.658352, acc.: 61.72%] [G loss: 0.838833]\n",
      "epoch:40 step:32019 [D loss: 0.593851, acc.: 75.00%] [G loss: 0.787370]\n",
      "epoch:40 step:32020 [D loss: 0.699149, acc.: 52.34%] [G loss: 0.820944]\n",
      "epoch:40 step:32021 [D loss: 0.673729, acc.: 58.59%] [G loss: 0.819868]\n",
      "epoch:41 step:32022 [D loss: 0.649835, acc.: 64.84%] [G loss: 0.799227]\n",
      "epoch:41 step:32023 [D loss: 0.697586, acc.: 53.12%] [G loss: 0.778728]\n",
      "epoch:41 step:32024 [D loss: 0.661478, acc.: 64.84%] [G loss: 0.799038]\n",
      "epoch:41 step:32025 [D loss: 0.654452, acc.: 61.72%] [G loss: 0.771613]\n",
      "epoch:41 step:32026 [D loss: 0.674852, acc.: 54.69%] [G loss: 0.857854]\n",
      "epoch:41 step:32027 [D loss: 0.631906, acc.: 66.41%] [G loss: 0.784088]\n",
      "epoch:41 step:32028 [D loss: 0.676570, acc.: 57.81%] [G loss: 0.774296]\n",
      "epoch:41 step:32029 [D loss: 0.719790, acc.: 50.00%] [G loss: 0.764395]\n",
      "epoch:41 step:32030 [D loss: 0.726160, acc.: 40.62%] [G loss: 0.792925]\n",
      "epoch:41 step:32031 [D loss: 0.663234, acc.: 62.50%] [G loss: 0.744086]\n",
      "epoch:41 step:32032 [D loss: 0.738912, acc.: 42.19%] [G loss: 0.763318]\n",
      "epoch:41 step:32033 [D loss: 0.701099, acc.: 50.00%] [G loss: 0.786076]\n",
      "epoch:41 step:32034 [D loss: 0.697103, acc.: 61.72%] [G loss: 0.785756]\n",
      "epoch:41 step:32035 [D loss: 0.675295, acc.: 56.25%] [G loss: 0.735845]\n",
      "epoch:41 step:32036 [D loss: 0.720932, acc.: 45.31%] [G loss: 0.831729]\n",
      "epoch:41 step:32037 [D loss: 0.656514, acc.: 57.81%] [G loss: 0.816664]\n",
      "epoch:41 step:32038 [D loss: 0.631767, acc.: 68.75%] [G loss: 0.830684]\n",
      "epoch:41 step:32039 [D loss: 0.683830, acc.: 57.03%] [G loss: 0.796472]\n",
      "epoch:41 step:32040 [D loss: 0.721067, acc.: 46.09%] [G loss: 0.771154]\n",
      "epoch:41 step:32041 [D loss: 0.639491, acc.: 63.28%] [G loss: 0.822002]\n",
      "epoch:41 step:32042 [D loss: 0.680336, acc.: 58.59%] [G loss: 0.885323]\n",
      "epoch:41 step:32043 [D loss: 0.672868, acc.: 53.91%] [G loss: 0.784608]\n",
      "epoch:41 step:32044 [D loss: 0.700500, acc.: 54.69%] [G loss: 0.786188]\n",
      "epoch:41 step:32045 [D loss: 0.729260, acc.: 42.97%] [G loss: 0.798837]\n",
      "epoch:41 step:32046 [D loss: 0.716123, acc.: 52.34%] [G loss: 0.773810]\n",
      "epoch:41 step:32047 [D loss: 0.727057, acc.: 49.22%] [G loss: 0.693708]\n",
      "epoch:41 step:32048 [D loss: 0.617672, acc.: 71.88%] [G loss: 0.742331]\n",
      "epoch:41 step:32049 [D loss: 0.691213, acc.: 49.22%] [G loss: 0.857767]\n",
      "epoch:41 step:32050 [D loss: 0.697905, acc.: 51.56%] [G loss: 0.809521]\n",
      "epoch:41 step:32051 [D loss: 0.703382, acc.: 50.78%] [G loss: 0.729761]\n",
      "epoch:41 step:32052 [D loss: 0.647973, acc.: 60.94%] [G loss: 0.783148]\n",
      "epoch:41 step:32053 [D loss: 0.743506, acc.: 42.97%] [G loss: 0.814860]\n",
      "epoch:41 step:32054 [D loss: 0.611457, acc.: 71.88%] [G loss: 0.813530]\n",
      "epoch:41 step:32055 [D loss: 0.678294, acc.: 60.94%] [G loss: 0.783764]\n",
      "epoch:41 step:32056 [D loss: 0.722963, acc.: 48.44%] [G loss: 0.817741]\n",
      "epoch:41 step:32057 [D loss: 0.754784, acc.: 41.41%] [G loss: 0.748070]\n",
      "epoch:41 step:32058 [D loss: 0.709909, acc.: 53.91%] [G loss: 0.802848]\n",
      "epoch:41 step:32059 [D loss: 0.676533, acc.: 60.16%] [G loss: 0.848235]\n",
      "epoch:41 step:32060 [D loss: 0.685655, acc.: 53.12%] [G loss: 0.762841]\n",
      "epoch:41 step:32061 [D loss: 0.640376, acc.: 67.97%] [G loss: 0.746747]\n",
      "epoch:41 step:32062 [D loss: 0.685016, acc.: 48.44%] [G loss: 0.753875]\n",
      "epoch:41 step:32063 [D loss: 0.709020, acc.: 47.66%] [G loss: 0.740218]\n",
      "epoch:41 step:32064 [D loss: 0.685263, acc.: 56.25%] [G loss: 0.739103]\n",
      "epoch:41 step:32065 [D loss: 0.691601, acc.: 50.78%] [G loss: 0.842694]\n",
      "epoch:41 step:32066 [D loss: 0.680207, acc.: 53.91%] [G loss: 0.809296]\n",
      "epoch:41 step:32067 [D loss: 0.686136, acc.: 52.34%] [G loss: 0.796071]\n",
      "epoch:41 step:32068 [D loss: 0.685239, acc.: 56.25%] [G loss: 0.817263]\n",
      "epoch:41 step:32069 [D loss: 0.731063, acc.: 39.84%] [G loss: 0.697410]\n",
      "epoch:41 step:32070 [D loss: 0.621123, acc.: 65.62%] [G loss: 0.755719]\n",
      "epoch:41 step:32071 [D loss: 0.682903, acc.: 56.25%] [G loss: 0.706831]\n",
      "epoch:41 step:32072 [D loss: 0.661448, acc.: 57.03%] [G loss: 0.795048]\n",
      "epoch:41 step:32073 [D loss: 0.624740, acc.: 73.44%] [G loss: 0.752149]\n",
      "epoch:41 step:32074 [D loss: 0.710970, acc.: 46.88%] [G loss: 0.734591]\n",
      "epoch:41 step:32075 [D loss: 0.771129, acc.: 42.19%] [G loss: 0.749390]\n",
      "epoch:41 step:32076 [D loss: 0.650291, acc.: 65.62%] [G loss: 0.782800]\n",
      "epoch:41 step:32077 [D loss: 0.630698, acc.: 70.31%] [G loss: 0.899546]\n",
      "epoch:41 step:32078 [D loss: 0.650346, acc.: 59.38%] [G loss: 0.754551]\n",
      "epoch:41 step:32079 [D loss: 0.683602, acc.: 51.56%] [G loss: 0.794685]\n",
      "epoch:41 step:32080 [D loss: 0.651236, acc.: 63.28%] [G loss: 0.824012]\n",
      "epoch:41 step:32081 [D loss: 0.662148, acc.: 64.06%] [G loss: 0.805525]\n",
      "epoch:41 step:32082 [D loss: 0.707273, acc.: 52.34%] [G loss: 0.756774]\n",
      "epoch:41 step:32083 [D loss: 0.695504, acc.: 53.12%] [G loss: 0.791367]\n",
      "epoch:41 step:32084 [D loss: 0.638779, acc.: 67.97%] [G loss: 0.851946]\n",
      "epoch:41 step:32085 [D loss: 0.702324, acc.: 52.34%] [G loss: 0.892121]\n",
      "epoch:41 step:32086 [D loss: 0.756607, acc.: 35.94%] [G loss: 0.822548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32087 [D loss: 0.734784, acc.: 39.06%] [G loss: 0.843991]\n",
      "epoch:41 step:32088 [D loss: 0.701347, acc.: 52.34%] [G loss: 0.785557]\n",
      "epoch:41 step:32089 [D loss: 0.697062, acc.: 52.34%] [G loss: 0.930586]\n",
      "epoch:41 step:32090 [D loss: 0.710491, acc.: 49.22%] [G loss: 0.854902]\n",
      "epoch:41 step:32091 [D loss: 0.718964, acc.: 48.44%] [G loss: 0.702556]\n",
      "epoch:41 step:32092 [D loss: 0.726198, acc.: 47.66%] [G loss: 0.740373]\n",
      "epoch:41 step:32093 [D loss: 0.643978, acc.: 65.62%] [G loss: 0.761697]\n",
      "epoch:41 step:32094 [D loss: 0.654986, acc.: 57.81%] [G loss: 0.767964]\n",
      "epoch:41 step:32095 [D loss: 0.655955, acc.: 67.19%] [G loss: 0.775975]\n",
      "epoch:41 step:32096 [D loss: 0.713726, acc.: 52.34%] [G loss: 0.801179]\n",
      "epoch:41 step:32097 [D loss: 0.662468, acc.: 64.06%] [G loss: 0.820871]\n",
      "epoch:41 step:32098 [D loss: 0.653515, acc.: 63.28%] [G loss: 0.796066]\n",
      "epoch:41 step:32099 [D loss: 0.721378, acc.: 50.00%] [G loss: 0.683053]\n",
      "epoch:41 step:32100 [D loss: 0.694346, acc.: 56.25%] [G loss: 0.777921]\n",
      "epoch:41 step:32101 [D loss: 0.670839, acc.: 58.59%] [G loss: 0.884253]\n",
      "epoch:41 step:32102 [D loss: 0.724040, acc.: 53.12%] [G loss: 0.843683]\n",
      "epoch:41 step:32103 [D loss: 0.680517, acc.: 57.81%] [G loss: 0.843358]\n",
      "epoch:41 step:32104 [D loss: 0.671414, acc.: 60.16%] [G loss: 0.820948]\n",
      "epoch:41 step:32105 [D loss: 0.643436, acc.: 65.62%] [G loss: 0.859242]\n",
      "epoch:41 step:32106 [D loss: 0.702206, acc.: 57.03%] [G loss: 0.796785]\n",
      "epoch:41 step:32107 [D loss: 0.654365, acc.: 62.50%] [G loss: 0.797795]\n",
      "epoch:41 step:32108 [D loss: 0.655137, acc.: 60.16%] [G loss: 0.754707]\n",
      "epoch:41 step:32109 [D loss: 0.689777, acc.: 58.59%] [G loss: 0.770162]\n",
      "epoch:41 step:32110 [D loss: 0.708561, acc.: 47.66%] [G loss: 0.779333]\n",
      "epoch:41 step:32111 [D loss: 0.669995, acc.: 56.25%] [G loss: 0.908392]\n",
      "epoch:41 step:32112 [D loss: 0.714334, acc.: 47.66%] [G loss: 0.858100]\n",
      "epoch:41 step:32113 [D loss: 0.679125, acc.: 53.91%] [G loss: 0.901574]\n",
      "epoch:41 step:32114 [D loss: 0.722057, acc.: 45.31%] [G loss: 0.946768]\n",
      "epoch:41 step:32115 [D loss: 0.587409, acc.: 82.81%] [G loss: 0.962803]\n",
      "epoch:41 step:32116 [D loss: 0.631518, acc.: 64.84%] [G loss: 0.861881]\n",
      "epoch:41 step:32117 [D loss: 0.676999, acc.: 55.47%] [G loss: 0.841792]\n",
      "epoch:41 step:32118 [D loss: 0.681823, acc.: 57.81%] [G loss: 0.931100]\n",
      "epoch:41 step:32119 [D loss: 0.605062, acc.: 71.88%] [G loss: 0.872871]\n",
      "epoch:41 step:32120 [D loss: 0.698774, acc.: 47.66%] [G loss: 0.824239]\n",
      "epoch:41 step:32121 [D loss: 0.674429, acc.: 53.91%] [G loss: 0.943258]\n",
      "epoch:41 step:32122 [D loss: 0.684649, acc.: 57.81%] [G loss: 0.864323]\n",
      "epoch:41 step:32123 [D loss: 0.633210, acc.: 61.72%] [G loss: 0.805691]\n",
      "epoch:41 step:32124 [D loss: 0.663350, acc.: 57.03%] [G loss: 0.822513]\n",
      "epoch:41 step:32125 [D loss: 0.670547, acc.: 55.47%] [G loss: 0.696847]\n",
      "epoch:41 step:32126 [D loss: 0.634972, acc.: 68.75%] [G loss: 0.784434]\n",
      "epoch:41 step:32127 [D loss: 0.634784, acc.: 70.31%] [G loss: 0.735916]\n",
      "epoch:41 step:32128 [D loss: 0.656486, acc.: 62.50%] [G loss: 0.851990]\n",
      "epoch:41 step:32129 [D loss: 0.717165, acc.: 46.09%] [G loss: 0.689848]\n",
      "epoch:41 step:32130 [D loss: 0.705496, acc.: 47.66%] [G loss: 0.723165]\n",
      "epoch:41 step:32131 [D loss: 0.697650, acc.: 54.69%] [G loss: 0.679704]\n",
      "epoch:41 step:32132 [D loss: 0.660926, acc.: 60.94%] [G loss: 0.840680]\n",
      "epoch:41 step:32133 [D loss: 0.702635, acc.: 57.81%] [G loss: 0.839164]\n",
      "epoch:41 step:32134 [D loss: 0.633905, acc.: 70.31%] [G loss: 0.717307]\n",
      "epoch:41 step:32135 [D loss: 0.640614, acc.: 63.28%] [G loss: 0.703180]\n",
      "epoch:41 step:32136 [D loss: 0.661665, acc.: 65.62%] [G loss: 0.896617]\n",
      "epoch:41 step:32137 [D loss: 0.781842, acc.: 28.12%] [G loss: 0.755408]\n",
      "epoch:41 step:32138 [D loss: 0.628369, acc.: 74.22%] [G loss: 0.761706]\n",
      "epoch:41 step:32139 [D loss: 0.674344, acc.: 56.25%] [G loss: 0.720749]\n",
      "epoch:41 step:32140 [D loss: 0.673624, acc.: 57.81%] [G loss: 0.774761]\n",
      "epoch:41 step:32141 [D loss: 0.721292, acc.: 46.88%] [G loss: 0.781843]\n",
      "epoch:41 step:32142 [D loss: 0.665258, acc.: 59.38%] [G loss: 0.793351]\n",
      "epoch:41 step:32143 [D loss: 0.651858, acc.: 65.62%] [G loss: 0.735044]\n",
      "epoch:41 step:32144 [D loss: 0.708039, acc.: 48.44%] [G loss: 0.841540]\n",
      "epoch:41 step:32145 [D loss: 0.665590, acc.: 57.81%] [G loss: 0.798853]\n",
      "epoch:41 step:32146 [D loss: 0.695418, acc.: 52.34%] [G loss: 0.810968]\n",
      "epoch:41 step:32147 [D loss: 0.697550, acc.: 50.00%] [G loss: 0.778124]\n",
      "epoch:41 step:32148 [D loss: 0.621433, acc.: 71.88%] [G loss: 0.782032]\n",
      "epoch:41 step:32149 [D loss: 0.656329, acc.: 57.03%] [G loss: 0.803690]\n",
      "epoch:41 step:32150 [D loss: 0.700623, acc.: 53.12%] [G loss: 0.813117]\n",
      "epoch:41 step:32151 [D loss: 0.692645, acc.: 53.91%] [G loss: 0.758479]\n",
      "epoch:41 step:32152 [D loss: 0.719737, acc.: 45.31%] [G loss: 0.832096]\n",
      "epoch:41 step:32153 [D loss: 0.684370, acc.: 55.47%] [G loss: 0.802262]\n",
      "epoch:41 step:32154 [D loss: 0.652734, acc.: 61.72%] [G loss: 0.852370]\n",
      "epoch:41 step:32155 [D loss: 0.657766, acc.: 65.62%] [G loss: 0.847410]\n",
      "epoch:41 step:32156 [D loss: 0.692115, acc.: 53.91%] [G loss: 0.856543]\n",
      "epoch:41 step:32157 [D loss: 0.776989, acc.: 38.28%] [G loss: 0.791428]\n",
      "epoch:41 step:32158 [D loss: 0.727967, acc.: 46.88%] [G loss: 0.841706]\n",
      "epoch:41 step:32159 [D loss: 0.716403, acc.: 47.66%] [G loss: 0.892946]\n",
      "epoch:41 step:32160 [D loss: 0.719574, acc.: 49.22%] [G loss: 0.743138]\n",
      "epoch:41 step:32161 [D loss: 0.654068, acc.: 62.50%] [G loss: 0.791506]\n",
      "epoch:41 step:32162 [D loss: 0.702956, acc.: 52.34%] [G loss: 0.754600]\n",
      "epoch:41 step:32163 [D loss: 0.691675, acc.: 57.03%] [G loss: 0.809977]\n",
      "epoch:41 step:32164 [D loss: 0.685376, acc.: 53.91%] [G loss: 0.781702]\n",
      "epoch:41 step:32165 [D loss: 0.692284, acc.: 53.12%] [G loss: 0.728609]\n",
      "epoch:41 step:32166 [D loss: 0.643923, acc.: 64.06%] [G loss: 0.724072]\n",
      "epoch:41 step:32167 [D loss: 0.643388, acc.: 65.62%] [G loss: 0.728678]\n",
      "epoch:41 step:32168 [D loss: 0.688090, acc.: 53.12%] [G loss: 0.810894]\n",
      "epoch:41 step:32169 [D loss: 0.680031, acc.: 54.69%] [G loss: 0.726102]\n",
      "epoch:41 step:32170 [D loss: 0.645950, acc.: 65.62%] [G loss: 0.729335]\n",
      "epoch:41 step:32171 [D loss: 0.691839, acc.: 46.88%] [G loss: 0.764904]\n",
      "epoch:41 step:32172 [D loss: 0.663544, acc.: 61.72%] [G loss: 0.807640]\n",
      "epoch:41 step:32173 [D loss: 0.686651, acc.: 58.59%] [G loss: 0.841594]\n",
      "epoch:41 step:32174 [D loss: 0.704444, acc.: 57.03%] [G loss: 0.748119]\n",
      "epoch:41 step:32175 [D loss: 0.654833, acc.: 60.94%] [G loss: 0.817631]\n",
      "epoch:41 step:32176 [D loss: 0.663017, acc.: 60.16%] [G loss: 0.867215]\n",
      "epoch:41 step:32177 [D loss: 0.713058, acc.: 53.12%] [G loss: 0.757790]\n",
      "epoch:41 step:32178 [D loss: 0.694775, acc.: 48.44%] [G loss: 0.710805]\n",
      "epoch:41 step:32179 [D loss: 0.678501, acc.: 52.34%] [G loss: 0.742169]\n",
      "epoch:41 step:32180 [D loss: 0.736466, acc.: 45.31%] [G loss: 0.737932]\n",
      "epoch:41 step:32181 [D loss: 0.638303, acc.: 64.06%] [G loss: 0.756358]\n",
      "epoch:41 step:32182 [D loss: 0.734235, acc.: 45.31%] [G loss: 0.826632]\n",
      "epoch:41 step:32183 [D loss: 0.702665, acc.: 52.34%] [G loss: 0.764738]\n",
      "epoch:41 step:32184 [D loss: 0.687637, acc.: 54.69%] [G loss: 0.838174]\n",
      "epoch:41 step:32185 [D loss: 0.620761, acc.: 68.75%] [G loss: 0.863724]\n",
      "epoch:41 step:32186 [D loss: 0.698879, acc.: 54.69%] [G loss: 0.845219]\n",
      "epoch:41 step:32187 [D loss: 0.677637, acc.: 60.16%] [G loss: 0.828920]\n",
      "epoch:41 step:32188 [D loss: 0.674781, acc.: 58.59%] [G loss: 0.823604]\n",
      "epoch:41 step:32189 [D loss: 0.654916, acc.: 61.72%] [G loss: 0.797263]\n",
      "epoch:41 step:32190 [D loss: 0.638092, acc.: 59.38%] [G loss: 0.809186]\n",
      "epoch:41 step:32191 [D loss: 0.654992, acc.: 64.06%] [G loss: 0.768810]\n",
      "epoch:41 step:32192 [D loss: 0.742874, acc.: 37.50%] [G loss: 0.855606]\n",
      "epoch:41 step:32193 [D loss: 0.650656, acc.: 65.62%] [G loss: 0.795940]\n",
      "epoch:41 step:32194 [D loss: 0.675229, acc.: 57.81%] [G loss: 0.731079]\n",
      "epoch:41 step:32195 [D loss: 0.711729, acc.: 49.22%] [G loss: 0.827808]\n",
      "epoch:41 step:32196 [D loss: 0.716590, acc.: 50.00%] [G loss: 0.803532]\n",
      "epoch:41 step:32197 [D loss: 0.687053, acc.: 50.00%] [G loss: 0.823530]\n",
      "epoch:41 step:32198 [D loss: 0.724517, acc.: 52.34%] [G loss: 0.784411]\n",
      "epoch:41 step:32199 [D loss: 0.698586, acc.: 53.91%] [G loss: 0.754097]\n",
      "epoch:41 step:32200 [D loss: 0.646149, acc.: 63.28%] [G loss: 0.787867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32201 [D loss: 0.650966, acc.: 62.50%] [G loss: 0.764072]\n",
      "epoch:41 step:32202 [D loss: 0.690705, acc.: 57.03%] [G loss: 0.765864]\n",
      "epoch:41 step:32203 [D loss: 0.717568, acc.: 51.56%] [G loss: 0.715842]\n",
      "epoch:41 step:32204 [D loss: 0.660662, acc.: 63.28%] [G loss: 0.747756]\n",
      "epoch:41 step:32205 [D loss: 0.655325, acc.: 64.84%] [G loss: 0.822277]\n",
      "epoch:41 step:32206 [D loss: 0.620202, acc.: 69.53%] [G loss: 0.781911]\n",
      "epoch:41 step:32207 [D loss: 0.695313, acc.: 50.00%] [G loss: 0.713332]\n",
      "epoch:41 step:32208 [D loss: 0.704100, acc.: 50.78%] [G loss: 0.814409]\n",
      "epoch:41 step:32209 [D loss: 0.708986, acc.: 50.78%] [G loss: 0.853402]\n",
      "epoch:41 step:32210 [D loss: 0.670900, acc.: 60.16%] [G loss: 0.780088]\n",
      "epoch:41 step:32211 [D loss: 0.675314, acc.: 56.25%] [G loss: 0.861787]\n",
      "epoch:41 step:32212 [D loss: 0.719013, acc.: 46.09%] [G loss: 0.831318]\n",
      "epoch:41 step:32213 [D loss: 0.662814, acc.: 60.94%] [G loss: 0.824558]\n",
      "epoch:41 step:32214 [D loss: 0.662926, acc.: 57.81%] [G loss: 0.815207]\n",
      "epoch:41 step:32215 [D loss: 0.703396, acc.: 50.00%] [G loss: 0.853412]\n",
      "epoch:41 step:32216 [D loss: 0.756799, acc.: 38.28%] [G loss: 0.810212]\n",
      "epoch:41 step:32217 [D loss: 0.673732, acc.: 57.03%] [G loss: 0.795480]\n",
      "epoch:41 step:32218 [D loss: 0.677433, acc.: 63.28%] [G loss: 0.841531]\n",
      "epoch:41 step:32219 [D loss: 0.686163, acc.: 60.94%] [G loss: 0.843367]\n",
      "epoch:41 step:32220 [D loss: 0.682237, acc.: 54.69%] [G loss: 0.789026]\n",
      "epoch:41 step:32221 [D loss: 0.652395, acc.: 65.62%] [G loss: 0.754507]\n",
      "epoch:41 step:32222 [D loss: 0.690792, acc.: 51.56%] [G loss: 0.762497]\n",
      "epoch:41 step:32223 [D loss: 0.674226, acc.: 57.81%] [G loss: 0.793337]\n",
      "epoch:41 step:32224 [D loss: 0.717966, acc.: 45.31%] [G loss: 0.890328]\n",
      "epoch:41 step:32225 [D loss: 0.679001, acc.: 54.69%] [G loss: 0.850817]\n",
      "epoch:41 step:32226 [D loss: 0.680447, acc.: 55.47%] [G loss: 0.834365]\n",
      "epoch:41 step:32227 [D loss: 0.701723, acc.: 48.44%] [G loss: 0.821921]\n",
      "epoch:41 step:32228 [D loss: 0.577870, acc.: 77.34%] [G loss: 0.798998]\n",
      "epoch:41 step:32229 [D loss: 0.662016, acc.: 60.16%] [G loss: 0.844611]\n",
      "epoch:41 step:32230 [D loss: 0.670433, acc.: 61.72%] [G loss: 0.814183]\n",
      "epoch:41 step:32231 [D loss: 0.654328, acc.: 60.94%] [G loss: 0.790439]\n",
      "epoch:41 step:32232 [D loss: 0.671101, acc.: 58.59%] [G loss: 0.712781]\n",
      "epoch:41 step:32233 [D loss: 0.680729, acc.: 54.69%] [G loss: 0.900880]\n",
      "epoch:41 step:32234 [D loss: 0.638348, acc.: 68.75%] [G loss: 0.782690]\n",
      "epoch:41 step:32235 [D loss: 0.735548, acc.: 47.66%] [G loss: 0.782504]\n",
      "epoch:41 step:32236 [D loss: 0.702683, acc.: 46.88%] [G loss: 0.802304]\n",
      "epoch:41 step:32237 [D loss: 0.696064, acc.: 53.12%] [G loss: 0.765128]\n",
      "epoch:41 step:32238 [D loss: 0.667939, acc.: 61.72%] [G loss: 0.749875]\n",
      "epoch:41 step:32239 [D loss: 0.668220, acc.: 63.28%] [G loss: 0.757057]\n",
      "epoch:41 step:32240 [D loss: 0.693319, acc.: 57.03%] [G loss: 0.779514]\n",
      "epoch:41 step:32241 [D loss: 0.711306, acc.: 53.91%] [G loss: 0.774787]\n",
      "epoch:41 step:32242 [D loss: 0.673243, acc.: 56.25%] [G loss: 0.774941]\n",
      "epoch:41 step:32243 [D loss: 0.654747, acc.: 63.28%] [G loss: 0.880304]\n",
      "epoch:41 step:32244 [D loss: 0.710290, acc.: 52.34%] [G loss: 0.842623]\n",
      "epoch:41 step:32245 [D loss: 0.738241, acc.: 45.31%] [G loss: 0.771633]\n",
      "epoch:41 step:32246 [D loss: 0.682243, acc.: 55.47%] [G loss: 0.840359]\n",
      "epoch:41 step:32247 [D loss: 0.707055, acc.: 53.91%] [G loss: 0.801518]\n",
      "epoch:41 step:32248 [D loss: 0.655574, acc.: 62.50%] [G loss: 0.779792]\n",
      "epoch:41 step:32249 [D loss: 0.693670, acc.: 53.12%] [G loss: 0.808645]\n",
      "epoch:41 step:32250 [D loss: 0.777412, acc.: 34.38%] [G loss: 0.685436]\n",
      "epoch:41 step:32251 [D loss: 0.695829, acc.: 48.44%] [G loss: 0.760321]\n",
      "epoch:41 step:32252 [D loss: 0.667841, acc.: 57.81%] [G loss: 0.810535]\n",
      "epoch:41 step:32253 [D loss: 0.712794, acc.: 47.66%] [G loss: 0.771778]\n",
      "epoch:41 step:32254 [D loss: 0.626594, acc.: 72.66%] [G loss: 0.876612]\n",
      "epoch:41 step:32255 [D loss: 0.666467, acc.: 63.28%] [G loss: 0.862915]\n",
      "epoch:41 step:32256 [D loss: 0.735772, acc.: 44.53%] [G loss: 0.733301]\n",
      "epoch:41 step:32257 [D loss: 0.633967, acc.: 67.19%] [G loss: 0.768282]\n",
      "epoch:41 step:32258 [D loss: 0.725828, acc.: 45.31%] [G loss: 0.810525]\n",
      "epoch:41 step:32259 [D loss: 0.634311, acc.: 63.28%] [G loss: 0.825155]\n",
      "epoch:41 step:32260 [D loss: 0.671899, acc.: 60.94%] [G loss: 0.693147]\n",
      "epoch:41 step:32261 [D loss: 0.653350, acc.: 60.16%] [G loss: 0.735193]\n",
      "epoch:41 step:32262 [D loss: 0.710403, acc.: 53.91%] [G loss: 0.680200]\n",
      "epoch:41 step:32263 [D loss: 0.653966, acc.: 61.72%] [G loss: 0.782580]\n",
      "epoch:41 step:32264 [D loss: 0.677127, acc.: 53.91%] [G loss: 0.719716]\n",
      "epoch:41 step:32265 [D loss: 0.667493, acc.: 63.28%] [G loss: 0.682799]\n",
      "epoch:41 step:32266 [D loss: 0.660598, acc.: 57.03%] [G loss: 0.870200]\n",
      "epoch:41 step:32267 [D loss: 0.774615, acc.: 37.50%] [G loss: 0.800795]\n",
      "epoch:41 step:32268 [D loss: 0.633011, acc.: 67.97%] [G loss: 0.755539]\n",
      "epoch:41 step:32269 [D loss: 0.616065, acc.: 67.19%] [G loss: 0.750108]\n",
      "epoch:41 step:32270 [D loss: 0.710797, acc.: 54.69%] [G loss: 0.756585]\n",
      "epoch:41 step:32271 [D loss: 0.675981, acc.: 60.94%] [G loss: 0.845285]\n",
      "epoch:41 step:32272 [D loss: 0.678089, acc.: 57.03%] [G loss: 0.753874]\n",
      "epoch:41 step:32273 [D loss: 0.656565, acc.: 57.81%] [G loss: 0.849802]\n",
      "epoch:41 step:32274 [D loss: 0.693025, acc.: 53.12%] [G loss: 0.835980]\n",
      "epoch:41 step:32275 [D loss: 0.734696, acc.: 45.31%] [G loss: 0.796755]\n",
      "epoch:41 step:32276 [D loss: 0.710689, acc.: 52.34%] [G loss: 0.803138]\n",
      "epoch:41 step:32277 [D loss: 0.755437, acc.: 43.75%] [G loss: 0.723231]\n",
      "epoch:41 step:32278 [D loss: 0.744887, acc.: 46.09%] [G loss: 0.746592]\n",
      "epoch:41 step:32279 [D loss: 0.691816, acc.: 55.47%] [G loss: 0.816476]\n",
      "epoch:41 step:32280 [D loss: 0.666234, acc.: 65.62%] [G loss: 0.751527]\n",
      "epoch:41 step:32281 [D loss: 0.663636, acc.: 61.72%] [G loss: 0.762733]\n",
      "epoch:41 step:32282 [D loss: 0.632735, acc.: 64.06%] [G loss: 0.862170]\n",
      "epoch:41 step:32283 [D loss: 0.747630, acc.: 36.72%] [G loss: 0.750346]\n",
      "epoch:41 step:32284 [D loss: 0.705692, acc.: 52.34%] [G loss: 0.786086]\n",
      "epoch:41 step:32285 [D loss: 0.725963, acc.: 47.66%] [G loss: 0.759475]\n",
      "epoch:41 step:32286 [D loss: 0.663672, acc.: 57.03%] [G loss: 0.820497]\n",
      "epoch:41 step:32287 [D loss: 0.711198, acc.: 53.12%] [G loss: 0.743391]\n",
      "epoch:41 step:32288 [D loss: 0.711809, acc.: 50.00%] [G loss: 0.771764]\n",
      "epoch:41 step:32289 [D loss: 0.639978, acc.: 64.84%] [G loss: 0.796239]\n",
      "epoch:41 step:32290 [D loss: 0.714739, acc.: 42.97%] [G loss: 0.716182]\n",
      "epoch:41 step:32291 [D loss: 0.652951, acc.: 65.62%] [G loss: 0.764527]\n",
      "epoch:41 step:32292 [D loss: 0.712513, acc.: 50.78%] [G loss: 0.772882]\n",
      "epoch:41 step:32293 [D loss: 0.693687, acc.: 53.91%] [G loss: 0.847890]\n",
      "epoch:41 step:32294 [D loss: 0.703614, acc.: 52.34%] [G loss: 0.853076]\n",
      "epoch:41 step:32295 [D loss: 0.748590, acc.: 42.97%] [G loss: 0.865858]\n",
      "epoch:41 step:32296 [D loss: 0.718086, acc.: 43.75%] [G loss: 0.829815]\n",
      "epoch:41 step:32297 [D loss: 0.648916, acc.: 60.94%] [G loss: 0.845274]\n",
      "epoch:41 step:32298 [D loss: 0.718339, acc.: 51.56%] [G loss: 0.873493]\n",
      "epoch:41 step:32299 [D loss: 0.648891, acc.: 62.50%] [G loss: 0.738724]\n",
      "epoch:41 step:32300 [D loss: 0.693993, acc.: 56.25%] [G loss: 0.879473]\n",
      "epoch:41 step:32301 [D loss: 0.713839, acc.: 46.88%] [G loss: 0.751246]\n",
      "epoch:41 step:32302 [D loss: 0.767782, acc.: 40.62%] [G loss: 0.712466]\n",
      "epoch:41 step:32303 [D loss: 0.613451, acc.: 71.88%] [G loss: 0.818661]\n",
      "epoch:41 step:32304 [D loss: 0.669121, acc.: 60.16%] [G loss: 0.758367]\n",
      "epoch:41 step:32305 [D loss: 0.637247, acc.: 69.53%] [G loss: 0.851210]\n",
      "epoch:41 step:32306 [D loss: 0.693889, acc.: 57.03%] [G loss: 0.813801]\n",
      "epoch:41 step:32307 [D loss: 0.611354, acc.: 76.56%] [G loss: 0.809296]\n",
      "epoch:41 step:32308 [D loss: 0.733501, acc.: 50.00%] [G loss: 0.735949]\n",
      "epoch:41 step:32309 [D loss: 0.655823, acc.: 60.16%] [G loss: 0.749900]\n",
      "epoch:41 step:32310 [D loss: 0.700653, acc.: 50.00%] [G loss: 0.826482]\n",
      "epoch:41 step:32311 [D loss: 0.659925, acc.: 58.59%] [G loss: 0.857563]\n",
      "epoch:41 step:32312 [D loss: 0.745559, acc.: 40.62%] [G loss: 0.843751]\n",
      "epoch:41 step:32313 [D loss: 0.689233, acc.: 48.44%] [G loss: 0.805495]\n",
      "epoch:41 step:32314 [D loss: 0.686952, acc.: 58.59%] [G loss: 0.767433]\n",
      "epoch:41 step:32315 [D loss: 0.685886, acc.: 51.56%] [G loss: 0.791571]\n",
      "epoch:41 step:32316 [D loss: 0.695535, acc.: 56.25%] [G loss: 0.866294]\n",
      "epoch:41 step:32317 [D loss: 0.693249, acc.: 57.81%] [G loss: 0.824816]\n",
      "epoch:41 step:32318 [D loss: 0.671351, acc.: 58.59%] [G loss: 0.839787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32319 [D loss: 0.690113, acc.: 55.47%] [G loss: 0.826613]\n",
      "epoch:41 step:32320 [D loss: 0.699208, acc.: 58.59%] [G loss: 0.845199]\n",
      "epoch:41 step:32321 [D loss: 0.690380, acc.: 53.91%] [G loss: 0.864889]\n",
      "epoch:41 step:32322 [D loss: 0.639374, acc.: 65.62%] [G loss: 0.813728]\n",
      "epoch:41 step:32323 [D loss: 0.671220, acc.: 58.59%] [G loss: 0.790692]\n",
      "epoch:41 step:32324 [D loss: 0.666957, acc.: 64.84%] [G loss: 0.815640]\n",
      "epoch:41 step:32325 [D loss: 0.658968, acc.: 59.38%] [G loss: 0.888029]\n",
      "epoch:41 step:32326 [D loss: 0.640731, acc.: 66.41%] [G loss: 0.885010]\n",
      "epoch:41 step:32327 [D loss: 0.603730, acc.: 71.09%] [G loss: 0.869303]\n",
      "epoch:41 step:32328 [D loss: 0.670803, acc.: 56.25%] [G loss: 0.779181]\n",
      "epoch:41 step:32329 [D loss: 0.649523, acc.: 67.97%] [G loss: 0.902729]\n",
      "epoch:41 step:32330 [D loss: 0.646487, acc.: 64.06%] [G loss: 0.852974]\n",
      "epoch:41 step:32331 [D loss: 0.717426, acc.: 46.88%] [G loss: 0.801375]\n",
      "epoch:41 step:32332 [D loss: 0.675262, acc.: 67.19%] [G loss: 0.894217]\n",
      "epoch:41 step:32333 [D loss: 0.718571, acc.: 47.66%] [G loss: 0.737389]\n",
      "epoch:41 step:32334 [D loss: 0.672737, acc.: 60.94%] [G loss: 0.800269]\n",
      "epoch:41 step:32335 [D loss: 0.710780, acc.: 48.44%] [G loss: 0.708236]\n",
      "epoch:41 step:32336 [D loss: 0.681208, acc.: 51.56%] [G loss: 0.732340]\n",
      "epoch:41 step:32337 [D loss: 0.655617, acc.: 66.41%] [G loss: 0.853495]\n",
      "epoch:41 step:32338 [D loss: 0.727599, acc.: 45.31%] [G loss: 0.727262]\n",
      "epoch:41 step:32339 [D loss: 0.684303, acc.: 54.69%] [G loss: 0.807743]\n",
      "epoch:41 step:32340 [D loss: 0.686378, acc.: 55.47%] [G loss: 0.806411]\n",
      "epoch:41 step:32341 [D loss: 0.690442, acc.: 57.03%] [G loss: 0.791017]\n",
      "epoch:41 step:32342 [D loss: 0.689527, acc.: 52.34%] [G loss: 0.816721]\n",
      "epoch:41 step:32343 [D loss: 0.685391, acc.: 54.69%] [G loss: 0.775937]\n",
      "epoch:41 step:32344 [D loss: 0.684870, acc.: 57.03%] [G loss: 0.736067]\n",
      "epoch:41 step:32345 [D loss: 0.673764, acc.: 60.94%] [G loss: 0.801359]\n",
      "epoch:41 step:32346 [D loss: 0.670904, acc.: 57.81%] [G loss: 0.777298]\n",
      "epoch:41 step:32347 [D loss: 0.708030, acc.: 45.31%] [G loss: 0.753999]\n",
      "epoch:41 step:32348 [D loss: 0.647757, acc.: 60.94%] [G loss: 0.823476]\n",
      "epoch:41 step:32349 [D loss: 0.749783, acc.: 42.97%] [G loss: 0.801697]\n",
      "epoch:41 step:32350 [D loss: 0.684855, acc.: 52.34%] [G loss: 0.835213]\n",
      "epoch:41 step:32351 [D loss: 0.722609, acc.: 42.97%] [G loss: 0.712198]\n",
      "epoch:41 step:32352 [D loss: 0.739749, acc.: 42.97%] [G loss: 0.822397]\n",
      "epoch:41 step:32353 [D loss: 0.674760, acc.: 57.81%] [G loss: 0.823408]\n",
      "epoch:41 step:32354 [D loss: 0.686001, acc.: 55.47%] [G loss: 0.790774]\n",
      "epoch:41 step:32355 [D loss: 0.710619, acc.: 53.12%] [G loss: 0.803057]\n",
      "epoch:41 step:32356 [D loss: 0.682062, acc.: 54.69%] [G loss: 0.795920]\n",
      "epoch:41 step:32357 [D loss: 0.725500, acc.: 46.09%] [G loss: 0.771676]\n",
      "epoch:41 step:32358 [D loss: 0.654363, acc.: 67.19%] [G loss: 0.907351]\n",
      "epoch:41 step:32359 [D loss: 0.675858, acc.: 58.59%] [G loss: 0.825115]\n",
      "epoch:41 step:32360 [D loss: 0.672650, acc.: 63.28%] [G loss: 0.866686]\n",
      "epoch:41 step:32361 [D loss: 0.681504, acc.: 55.47%] [G loss: 0.739577]\n",
      "epoch:41 step:32362 [D loss: 0.676451, acc.: 57.03%] [G loss: 0.745670]\n",
      "epoch:41 step:32363 [D loss: 0.700534, acc.: 46.88%] [G loss: 0.906264]\n",
      "epoch:41 step:32364 [D loss: 0.673792, acc.: 57.03%] [G loss: 0.837949]\n",
      "epoch:41 step:32365 [D loss: 0.641305, acc.: 67.19%] [G loss: 0.795529]\n",
      "epoch:41 step:32366 [D loss: 0.652956, acc.: 64.84%] [G loss: 0.736663]\n",
      "epoch:41 step:32367 [D loss: 0.650663, acc.: 67.97%] [G loss: 0.784431]\n",
      "epoch:41 step:32368 [D loss: 0.677558, acc.: 55.47%] [G loss: 0.779954]\n",
      "epoch:41 step:32369 [D loss: 0.735035, acc.: 49.22%] [G loss: 0.767048]\n",
      "epoch:41 step:32370 [D loss: 0.632864, acc.: 67.19%] [G loss: 0.737532]\n",
      "epoch:41 step:32371 [D loss: 0.714980, acc.: 47.66%] [G loss: 0.826943]\n",
      "epoch:41 step:32372 [D loss: 0.699089, acc.: 50.00%] [G loss: 0.694986]\n",
      "epoch:41 step:32373 [D loss: 0.670918, acc.: 57.03%] [G loss: 0.742265]\n",
      "epoch:41 step:32374 [D loss: 0.708240, acc.: 48.44%] [G loss: 0.776724]\n",
      "epoch:41 step:32375 [D loss: 0.688978, acc.: 50.78%] [G loss: 0.834291]\n",
      "epoch:41 step:32376 [D loss: 0.723303, acc.: 47.66%] [G loss: 0.689067]\n",
      "epoch:41 step:32377 [D loss: 0.672307, acc.: 64.06%] [G loss: 0.848579]\n",
      "epoch:41 step:32378 [D loss: 0.636814, acc.: 70.31%] [G loss: 0.829205]\n",
      "epoch:41 step:32379 [D loss: 0.663320, acc.: 64.84%] [G loss: 0.769730]\n",
      "epoch:41 step:32380 [D loss: 0.684805, acc.: 53.12%] [G loss: 0.834904]\n",
      "epoch:41 step:32381 [D loss: 0.741255, acc.: 33.59%] [G loss: 0.728784]\n",
      "epoch:41 step:32382 [D loss: 0.707454, acc.: 50.78%] [G loss: 0.863781]\n",
      "epoch:41 step:32383 [D loss: 0.651374, acc.: 64.06%] [G loss: 0.719105]\n",
      "epoch:41 step:32384 [D loss: 0.759243, acc.: 41.41%] [G loss: 0.755595]\n",
      "epoch:41 step:32385 [D loss: 0.695998, acc.: 52.34%] [G loss: 0.723544]\n",
      "epoch:41 step:32386 [D loss: 0.675478, acc.: 53.12%] [G loss: 0.704326]\n",
      "epoch:41 step:32387 [D loss: 0.663953, acc.: 63.28%] [G loss: 0.746841]\n",
      "epoch:41 step:32388 [D loss: 0.712576, acc.: 46.09%] [G loss: 0.733137]\n",
      "epoch:41 step:32389 [D loss: 0.613765, acc.: 71.88%] [G loss: 0.791652]\n",
      "epoch:41 step:32390 [D loss: 0.663191, acc.: 57.03%] [G loss: 0.840697]\n",
      "epoch:41 step:32391 [D loss: 0.731703, acc.: 45.31%] [G loss: 0.794062]\n",
      "epoch:41 step:32392 [D loss: 0.646034, acc.: 61.72%] [G loss: 0.853730]\n",
      "epoch:41 step:32393 [D loss: 0.671629, acc.: 63.28%] [G loss: 0.881529]\n",
      "epoch:41 step:32394 [D loss: 0.676111, acc.: 57.03%] [G loss: 0.800586]\n",
      "epoch:41 step:32395 [D loss: 0.675840, acc.: 56.25%] [G loss: 0.815592]\n",
      "epoch:41 step:32396 [D loss: 0.689531, acc.: 54.69%] [G loss: 0.905627]\n",
      "epoch:41 step:32397 [D loss: 0.720546, acc.: 44.53%] [G loss: 0.852793]\n",
      "epoch:41 step:32398 [D loss: 0.657943, acc.: 59.38%] [G loss: 0.827582]\n",
      "epoch:41 step:32399 [D loss: 0.683207, acc.: 58.59%] [G loss: 0.795935]\n",
      "epoch:41 step:32400 [D loss: 0.619570, acc.: 69.53%] [G loss: 0.899635]\n",
      "epoch:41 step:32401 [D loss: 0.658963, acc.: 64.06%] [G loss: 0.798542]\n",
      "epoch:41 step:32402 [D loss: 0.630486, acc.: 70.31%] [G loss: 0.827804]\n",
      "epoch:41 step:32403 [D loss: 0.733258, acc.: 51.56%] [G loss: 0.754456]\n",
      "epoch:41 step:32404 [D loss: 0.643501, acc.: 59.38%] [G loss: 0.845234]\n",
      "epoch:41 step:32405 [D loss: 0.670529, acc.: 62.50%] [G loss: 0.760442]\n",
      "epoch:41 step:32406 [D loss: 0.732636, acc.: 41.41%] [G loss: 0.843809]\n",
      "epoch:41 step:32407 [D loss: 0.635912, acc.: 64.06%] [G loss: 0.803858]\n",
      "epoch:41 step:32408 [D loss: 0.595709, acc.: 77.34%] [G loss: 0.807856]\n",
      "epoch:41 step:32409 [D loss: 0.665595, acc.: 57.81%] [G loss: 0.802370]\n",
      "epoch:41 step:32410 [D loss: 0.739550, acc.: 42.19%] [G loss: 0.698192]\n",
      "epoch:41 step:32411 [D loss: 0.692375, acc.: 50.00%] [G loss: 0.736631]\n",
      "epoch:41 step:32412 [D loss: 0.722442, acc.: 49.22%] [G loss: 0.811230]\n",
      "epoch:41 step:32413 [D loss: 0.635580, acc.: 67.19%] [G loss: 0.741820]\n",
      "epoch:41 step:32414 [D loss: 0.659400, acc.: 61.72%] [G loss: 0.697145]\n",
      "epoch:41 step:32415 [D loss: 0.621405, acc.: 63.28%] [G loss: 0.753356]\n",
      "epoch:41 step:32416 [D loss: 0.709587, acc.: 50.00%] [G loss: 0.772833]\n",
      "epoch:41 step:32417 [D loss: 0.691480, acc.: 57.03%] [G loss: 0.831662]\n",
      "epoch:41 step:32418 [D loss: 0.658179, acc.: 54.69%] [G loss: 0.850986]\n",
      "epoch:41 step:32419 [D loss: 0.677559, acc.: 58.59%] [G loss: 0.709549]\n",
      "epoch:41 step:32420 [D loss: 0.630222, acc.: 64.06%] [G loss: 0.746353]\n",
      "epoch:41 step:32421 [D loss: 0.745528, acc.: 42.19%] [G loss: 0.775802]\n",
      "epoch:41 step:32422 [D loss: 0.692435, acc.: 53.91%] [G loss: 0.719681]\n",
      "epoch:41 step:32423 [D loss: 0.708161, acc.: 54.69%] [G loss: 0.779599]\n",
      "epoch:41 step:32424 [D loss: 0.679981, acc.: 61.72%] [G loss: 0.746599]\n",
      "epoch:41 step:32425 [D loss: 0.646953, acc.: 64.06%] [G loss: 0.820143]\n",
      "epoch:41 step:32426 [D loss: 0.687488, acc.: 54.69%] [G loss: 0.719772]\n",
      "epoch:41 step:32427 [D loss: 0.642336, acc.: 62.50%] [G loss: 0.799214]\n",
      "epoch:41 step:32428 [D loss: 0.621140, acc.: 71.09%] [G loss: 0.762325]\n",
      "epoch:41 step:32429 [D loss: 0.712651, acc.: 48.44%] [G loss: 0.799645]\n",
      "epoch:41 step:32430 [D loss: 0.656086, acc.: 63.28%] [G loss: 0.770107]\n",
      "epoch:41 step:32431 [D loss: 0.657805, acc.: 66.41%] [G loss: 0.797766]\n",
      "epoch:41 step:32432 [D loss: 0.726810, acc.: 49.22%] [G loss: 0.736297]\n",
      "epoch:41 step:32433 [D loss: 0.679712, acc.: 53.91%] [G loss: 0.755048]\n",
      "epoch:41 step:32434 [D loss: 0.631956, acc.: 72.66%] [G loss: 0.789156]\n",
      "epoch:41 step:32435 [D loss: 0.700768, acc.: 49.22%] [G loss: 0.735466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32436 [D loss: 0.671181, acc.: 56.25%] [G loss: 0.815439]\n",
      "epoch:41 step:32437 [D loss: 0.615170, acc.: 69.53%] [G loss: 0.738967]\n",
      "epoch:41 step:32438 [D loss: 0.696873, acc.: 53.12%] [G loss: 0.772395]\n",
      "epoch:41 step:32439 [D loss: 0.661529, acc.: 59.38%] [G loss: 0.806830]\n",
      "epoch:41 step:32440 [D loss: 0.715229, acc.: 46.09%] [G loss: 0.835598]\n",
      "epoch:41 step:32441 [D loss: 0.702671, acc.: 52.34%] [G loss: 0.771504]\n",
      "epoch:41 step:32442 [D loss: 0.636616, acc.: 69.53%] [G loss: 0.854191]\n",
      "epoch:41 step:32443 [D loss: 0.685619, acc.: 53.91%] [G loss: 0.752909]\n",
      "epoch:41 step:32444 [D loss: 0.686994, acc.: 60.94%] [G loss: 0.738585]\n",
      "epoch:41 step:32445 [D loss: 0.730154, acc.: 44.53%] [G loss: 0.860272]\n",
      "epoch:41 step:32446 [D loss: 0.701507, acc.: 47.66%] [G loss: 0.819189]\n",
      "epoch:41 step:32447 [D loss: 0.713902, acc.: 46.88%] [G loss: 0.771153]\n",
      "epoch:41 step:32448 [D loss: 0.629860, acc.: 63.28%] [G loss: 0.775462]\n",
      "epoch:41 step:32449 [D loss: 0.722177, acc.: 49.22%] [G loss: 0.750845]\n",
      "epoch:41 step:32450 [D loss: 0.649651, acc.: 60.94%] [G loss: 0.784099]\n",
      "epoch:41 step:32451 [D loss: 0.684767, acc.: 55.47%] [G loss: 0.775083]\n",
      "epoch:41 step:32452 [D loss: 0.731758, acc.: 42.97%] [G loss: 0.752412]\n",
      "epoch:41 step:32453 [D loss: 0.694833, acc.: 53.91%] [G loss: 0.651988]\n",
      "epoch:41 step:32454 [D loss: 0.713966, acc.: 49.22%] [G loss: 0.768501]\n",
      "epoch:41 step:32455 [D loss: 0.641472, acc.: 63.28%] [G loss: 0.755429]\n",
      "epoch:41 step:32456 [D loss: 0.677634, acc.: 60.94%] [G loss: 0.758287]\n",
      "epoch:41 step:32457 [D loss: 0.802078, acc.: 28.12%] [G loss: 0.763878]\n",
      "epoch:41 step:32458 [D loss: 0.762269, acc.: 39.06%] [G loss: 0.724214]\n",
      "epoch:41 step:32459 [D loss: 0.675478, acc.: 57.03%] [G loss: 0.753822]\n",
      "epoch:41 step:32460 [D loss: 0.712652, acc.: 49.22%] [G loss: 0.788732]\n",
      "epoch:41 step:32461 [D loss: 0.662935, acc.: 62.50%] [G loss: 0.897651]\n",
      "epoch:41 step:32462 [D loss: 0.713158, acc.: 43.75%] [G loss: 0.863151]\n",
      "epoch:41 step:32463 [D loss: 0.672736, acc.: 60.94%] [G loss: 0.836882]\n",
      "epoch:41 step:32464 [D loss: 0.674089, acc.: 58.59%] [G loss: 0.912963]\n",
      "epoch:41 step:32465 [D loss: 0.611140, acc.: 73.44%] [G loss: 0.790915]\n",
      "epoch:41 step:32466 [D loss: 0.724083, acc.: 43.75%] [G loss: 0.858081]\n",
      "epoch:41 step:32467 [D loss: 0.728833, acc.: 42.97%] [G loss: 0.778873]\n",
      "epoch:41 step:32468 [D loss: 0.672777, acc.: 60.94%] [G loss: 0.827314]\n",
      "epoch:41 step:32469 [D loss: 0.614956, acc.: 69.53%] [G loss: 0.876810]\n",
      "epoch:41 step:32470 [D loss: 0.676295, acc.: 58.59%] [G loss: 0.761338]\n",
      "epoch:41 step:32471 [D loss: 0.694809, acc.: 58.59%] [G loss: 0.734075]\n",
      "epoch:41 step:32472 [D loss: 0.673564, acc.: 60.16%] [G loss: 0.795470]\n",
      "epoch:41 step:32473 [D loss: 0.638169, acc.: 63.28%] [G loss: 0.841771]\n",
      "epoch:41 step:32474 [D loss: 0.662632, acc.: 60.16%] [G loss: 0.829040]\n",
      "epoch:41 step:32475 [D loss: 0.637923, acc.: 68.75%] [G loss: 0.799160]\n",
      "epoch:41 step:32476 [D loss: 0.686784, acc.: 52.34%] [G loss: 0.755292]\n",
      "epoch:41 step:32477 [D loss: 0.636541, acc.: 66.41%] [G loss: 0.775976]\n",
      "epoch:41 step:32478 [D loss: 0.659817, acc.: 62.50%] [G loss: 0.758101]\n",
      "epoch:41 step:32479 [D loss: 0.718168, acc.: 48.44%] [G loss: 0.783937]\n",
      "epoch:41 step:32480 [D loss: 0.771291, acc.: 30.47%] [G loss: 0.725672]\n",
      "epoch:41 step:32481 [D loss: 0.649407, acc.: 67.97%] [G loss: 0.758964]\n",
      "epoch:41 step:32482 [D loss: 0.640493, acc.: 63.28%] [G loss: 0.833274]\n",
      "epoch:41 step:32483 [D loss: 0.691927, acc.: 50.00%] [G loss: 0.802480]\n",
      "epoch:41 step:32484 [D loss: 0.681688, acc.: 51.56%] [G loss: 0.955009]\n",
      "epoch:41 step:32485 [D loss: 0.697552, acc.: 47.66%] [G loss: 0.861159]\n",
      "epoch:41 step:32486 [D loss: 0.694174, acc.: 55.47%] [G loss: 0.826731]\n",
      "epoch:41 step:32487 [D loss: 0.677279, acc.: 54.69%] [G loss: 0.807570]\n",
      "epoch:41 step:32488 [D loss: 0.706942, acc.: 48.44%] [G loss: 0.766924]\n",
      "epoch:41 step:32489 [D loss: 0.679263, acc.: 53.91%] [G loss: 0.853132]\n",
      "epoch:41 step:32490 [D loss: 0.637915, acc.: 67.97%] [G loss: 0.858340]\n",
      "epoch:41 step:32491 [D loss: 0.664150, acc.: 66.41%] [G loss: 0.783514]\n",
      "epoch:41 step:32492 [D loss: 0.711194, acc.: 46.09%] [G loss: 0.794604]\n",
      "epoch:41 step:32493 [D loss: 0.690826, acc.: 53.91%] [G loss: 0.810841]\n",
      "epoch:41 step:32494 [D loss: 0.725150, acc.: 50.00%] [G loss: 0.807447]\n",
      "epoch:41 step:32495 [D loss: 0.685640, acc.: 58.59%] [G loss: 0.796965]\n",
      "epoch:41 step:32496 [D loss: 0.698388, acc.: 50.78%] [G loss: 0.805889]\n",
      "epoch:41 step:32497 [D loss: 0.648177, acc.: 70.31%] [G loss: 0.850259]\n",
      "epoch:41 step:32498 [D loss: 0.649812, acc.: 60.16%] [G loss: 0.767498]\n",
      "epoch:41 step:32499 [D loss: 0.612381, acc.: 68.75%] [G loss: 0.840796]\n",
      "epoch:41 step:32500 [D loss: 0.621441, acc.: 63.28%] [G loss: 0.814765]\n",
      "epoch:41 step:32501 [D loss: 0.592830, acc.: 71.09%] [G loss: 0.848838]\n",
      "epoch:41 step:32502 [D loss: 0.718057, acc.: 50.00%] [G loss: 0.765268]\n",
      "epoch:41 step:32503 [D loss: 0.687172, acc.: 54.69%] [G loss: 0.786133]\n",
      "epoch:41 step:32504 [D loss: 0.674055, acc.: 61.72%] [G loss: 0.712552]\n",
      "epoch:41 step:32505 [D loss: 0.699479, acc.: 53.91%] [G loss: 0.697525]\n",
      "epoch:41 step:32506 [D loss: 0.654169, acc.: 63.28%] [G loss: 0.741419]\n",
      "epoch:41 step:32507 [D loss: 0.663398, acc.: 60.94%] [G loss: 0.732904]\n",
      "epoch:41 step:32508 [D loss: 0.680183, acc.: 60.16%] [G loss: 0.733367]\n",
      "epoch:41 step:32509 [D loss: 0.668021, acc.: 55.47%] [G loss: 0.744343]\n",
      "epoch:41 step:32510 [D loss: 0.647726, acc.: 59.38%] [G loss: 0.762040]\n",
      "epoch:41 step:32511 [D loss: 0.693006, acc.: 50.78%] [G loss: 0.798028]\n",
      "epoch:41 step:32512 [D loss: 0.693487, acc.: 54.69%] [G loss: 0.664471]\n",
      "epoch:41 step:32513 [D loss: 0.668970, acc.: 57.81%] [G loss: 0.723627]\n",
      "epoch:41 step:32514 [D loss: 0.690789, acc.: 50.78%] [G loss: 0.705495]\n",
      "epoch:41 step:32515 [D loss: 0.650475, acc.: 66.41%] [G loss: 0.796199]\n",
      "epoch:41 step:32516 [D loss: 0.638406, acc.: 67.19%] [G loss: 0.810628]\n",
      "epoch:41 step:32517 [D loss: 0.679569, acc.: 50.78%] [G loss: 0.802625]\n",
      "epoch:41 step:32518 [D loss: 0.638505, acc.: 67.19%] [G loss: 0.705979]\n",
      "epoch:41 step:32519 [D loss: 0.720330, acc.: 49.22%] [G loss: 0.693834]\n",
      "epoch:41 step:32520 [D loss: 0.657379, acc.: 64.84%] [G loss: 0.718706]\n",
      "epoch:41 step:32521 [D loss: 0.698985, acc.: 52.34%] [G loss: 0.746785]\n",
      "epoch:41 step:32522 [D loss: 0.722015, acc.: 46.88%] [G loss: 0.779989]\n",
      "epoch:41 step:32523 [D loss: 0.735953, acc.: 48.44%] [G loss: 0.785293]\n",
      "epoch:41 step:32524 [D loss: 0.699200, acc.: 59.38%] [G loss: 0.822565]\n",
      "epoch:41 step:32525 [D loss: 0.656611, acc.: 63.28%] [G loss: 0.813523]\n",
      "epoch:41 step:32526 [D loss: 0.647015, acc.: 63.28%] [G loss: 0.776840]\n",
      "epoch:41 step:32527 [D loss: 0.683529, acc.: 55.47%] [G loss: 0.805079]\n",
      "epoch:41 step:32528 [D loss: 0.735832, acc.: 46.09%] [G loss: 0.788502]\n",
      "epoch:41 step:32529 [D loss: 0.715506, acc.: 43.75%] [G loss: 0.805483]\n",
      "epoch:41 step:32530 [D loss: 0.685049, acc.: 55.47%] [G loss: 0.783672]\n",
      "epoch:41 step:32531 [D loss: 0.737149, acc.: 43.75%] [G loss: 0.683884]\n",
      "epoch:41 step:32532 [D loss: 0.727390, acc.: 46.88%] [G loss: 0.708843]\n",
      "epoch:41 step:32533 [D loss: 0.792221, acc.: 28.91%] [G loss: 0.728755]\n",
      "epoch:41 step:32534 [D loss: 0.722815, acc.: 48.44%] [G loss: 0.808956]\n",
      "epoch:41 step:32535 [D loss: 0.770266, acc.: 46.09%] [G loss: 0.803029]\n",
      "epoch:41 step:32536 [D loss: 0.689576, acc.: 52.34%] [G loss: 0.805279]\n",
      "epoch:41 step:32537 [D loss: 0.656807, acc.: 62.50%] [G loss: 0.813482]\n",
      "epoch:41 step:32538 [D loss: 0.649873, acc.: 56.25%] [G loss: 0.780231]\n",
      "epoch:41 step:32539 [D loss: 0.694145, acc.: 51.56%] [G loss: 0.843837]\n",
      "epoch:41 step:32540 [D loss: 0.656448, acc.: 60.94%] [G loss: 0.787239]\n",
      "epoch:41 step:32541 [D loss: 0.680786, acc.: 56.25%] [G loss: 0.728682]\n",
      "epoch:41 step:32542 [D loss: 0.665873, acc.: 60.16%] [G loss: 0.830926]\n",
      "epoch:41 step:32543 [D loss: 0.661636, acc.: 59.38%] [G loss: 0.825153]\n",
      "epoch:41 step:32544 [D loss: 0.703022, acc.: 53.91%] [G loss: 0.790310]\n",
      "epoch:41 step:32545 [D loss: 0.733006, acc.: 45.31%] [G loss: 0.779958]\n",
      "epoch:41 step:32546 [D loss: 0.657371, acc.: 63.28%] [G loss: 0.885165]\n",
      "epoch:41 step:32547 [D loss: 0.780469, acc.: 42.19%] [G loss: 0.690259]\n",
      "epoch:41 step:32548 [D loss: 0.723074, acc.: 41.41%] [G loss: 0.761964]\n",
      "epoch:41 step:32549 [D loss: 0.700101, acc.: 46.88%] [G loss: 0.825543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32550 [D loss: 0.659222, acc.: 64.84%] [G loss: 0.735190]\n",
      "epoch:41 step:32551 [D loss: 0.662720, acc.: 60.16%] [G loss: 0.799201]\n",
      "epoch:41 step:32552 [D loss: 0.643260, acc.: 67.97%] [G loss: 0.774705]\n",
      "epoch:41 step:32553 [D loss: 0.661275, acc.: 64.06%] [G loss: 0.824615]\n",
      "epoch:41 step:32554 [D loss: 0.695766, acc.: 53.12%] [G loss: 0.788352]\n",
      "epoch:41 step:32555 [D loss: 0.676583, acc.: 55.47%] [G loss: 0.790114]\n",
      "epoch:41 step:32556 [D loss: 0.651087, acc.: 64.84%] [G loss: 0.865125]\n",
      "epoch:41 step:32557 [D loss: 0.692227, acc.: 56.25%] [G loss: 0.767077]\n",
      "epoch:41 step:32558 [D loss: 0.672868, acc.: 56.25%] [G loss: 0.702073]\n",
      "epoch:41 step:32559 [D loss: 0.693861, acc.: 54.69%] [G loss: 0.784033]\n",
      "epoch:41 step:32560 [D loss: 0.679632, acc.: 54.69%] [G loss: 0.741031]\n",
      "epoch:41 step:32561 [D loss: 0.637102, acc.: 65.62%] [G loss: 0.829147]\n",
      "epoch:41 step:32562 [D loss: 0.676242, acc.: 57.03%] [G loss: 0.721959]\n",
      "epoch:41 step:32563 [D loss: 0.668662, acc.: 59.38%] [G loss: 0.754731]\n",
      "epoch:41 step:32564 [D loss: 0.692289, acc.: 54.69%] [G loss: 0.752912]\n",
      "epoch:41 step:32565 [D loss: 0.651610, acc.: 63.28%] [G loss: 0.765621]\n",
      "epoch:41 step:32566 [D loss: 0.629429, acc.: 65.62%] [G loss: 0.787920]\n",
      "epoch:41 step:32567 [D loss: 0.692621, acc.: 55.47%] [G loss: 0.873610]\n",
      "epoch:41 step:32568 [D loss: 0.707719, acc.: 50.00%] [G loss: 0.786278]\n",
      "epoch:41 step:32569 [D loss: 0.662915, acc.: 64.84%] [G loss: 0.819665]\n",
      "epoch:41 step:32570 [D loss: 0.654898, acc.: 64.06%] [G loss: 0.794869]\n",
      "epoch:41 step:32571 [D loss: 0.636435, acc.: 67.97%] [G loss: 0.765893]\n",
      "epoch:41 step:32572 [D loss: 0.684263, acc.: 50.00%] [G loss: 0.820669]\n",
      "epoch:41 step:32573 [D loss: 0.759351, acc.: 40.62%] [G loss: 0.851645]\n",
      "epoch:41 step:32574 [D loss: 0.699375, acc.: 48.44%] [G loss: 0.813292]\n",
      "epoch:41 step:32575 [D loss: 0.704720, acc.: 49.22%] [G loss: 0.782299]\n",
      "epoch:41 step:32576 [D loss: 0.657877, acc.: 60.94%] [G loss: 0.798790]\n",
      "epoch:41 step:32577 [D loss: 0.684927, acc.: 52.34%] [G loss: 0.812372]\n",
      "epoch:41 step:32578 [D loss: 0.708293, acc.: 51.56%] [G loss: 0.783598]\n",
      "epoch:41 step:32579 [D loss: 0.674808, acc.: 60.94%] [G loss: 0.825351]\n",
      "epoch:41 step:32580 [D loss: 0.654271, acc.: 60.16%] [G loss: 0.747599]\n",
      "epoch:41 step:32581 [D loss: 0.691845, acc.: 55.47%] [G loss: 0.856449]\n",
      "epoch:41 step:32582 [D loss: 0.740371, acc.: 40.62%] [G loss: 0.768890]\n",
      "epoch:41 step:32583 [D loss: 0.681630, acc.: 51.56%] [G loss: 0.802067]\n",
      "epoch:41 step:32584 [D loss: 0.666120, acc.: 61.72%] [G loss: 0.761036]\n",
      "epoch:41 step:32585 [D loss: 0.628573, acc.: 71.88%] [G loss: 0.871830]\n",
      "epoch:41 step:32586 [D loss: 0.665758, acc.: 59.38%] [G loss: 0.825644]\n",
      "epoch:41 step:32587 [D loss: 0.702111, acc.: 45.31%] [G loss: 0.733342]\n",
      "epoch:41 step:32588 [D loss: 0.695217, acc.: 48.44%] [G loss: 0.772496]\n",
      "epoch:41 step:32589 [D loss: 0.671132, acc.: 60.94%] [G loss: 0.815405]\n",
      "epoch:41 step:32590 [D loss: 0.696067, acc.: 56.25%] [G loss: 0.837042]\n",
      "epoch:41 step:32591 [D loss: 0.678031, acc.: 55.47%] [G loss: 0.737809]\n",
      "epoch:41 step:32592 [D loss: 0.687175, acc.: 53.12%] [G loss: 0.726701]\n",
      "epoch:41 step:32593 [D loss: 0.717971, acc.: 52.34%] [G loss: 0.756421]\n",
      "epoch:41 step:32594 [D loss: 0.694589, acc.: 50.78%] [G loss: 0.836234]\n",
      "epoch:41 step:32595 [D loss: 0.728433, acc.: 45.31%] [G loss: 0.735360]\n",
      "epoch:41 step:32596 [D loss: 0.716950, acc.: 46.09%] [G loss: 0.748430]\n",
      "epoch:41 step:32597 [D loss: 0.677151, acc.: 57.03%] [G loss: 0.837739]\n",
      "epoch:41 step:32598 [D loss: 0.712379, acc.: 48.44%] [G loss: 0.828886]\n",
      "epoch:41 step:32599 [D loss: 0.687837, acc.: 53.91%] [G loss: 0.855036]\n",
      "epoch:41 step:32600 [D loss: 0.692728, acc.: 53.12%] [G loss: 0.813857]\n",
      "epoch:41 step:32601 [D loss: 0.695261, acc.: 53.12%] [G loss: 0.776042]\n",
      "epoch:41 step:32602 [D loss: 0.681699, acc.: 52.34%] [G loss: 0.758675]\n",
      "epoch:41 step:32603 [D loss: 0.670427, acc.: 59.38%] [G loss: 0.882016]\n",
      "epoch:41 step:32604 [D loss: 0.674952, acc.: 57.81%] [G loss: 0.777816]\n",
      "epoch:41 step:32605 [D loss: 0.705155, acc.: 49.22%] [G loss: 0.822901]\n",
      "epoch:41 step:32606 [D loss: 0.678502, acc.: 57.03%] [G loss: 0.735334]\n",
      "epoch:41 step:32607 [D loss: 0.629576, acc.: 70.31%] [G loss: 0.767863]\n",
      "epoch:41 step:32608 [D loss: 0.637404, acc.: 68.75%] [G loss: 0.809511]\n",
      "epoch:41 step:32609 [D loss: 0.697512, acc.: 55.47%] [G loss: 0.780894]\n",
      "epoch:41 step:32610 [D loss: 0.671625, acc.: 61.72%] [G loss: 0.792535]\n",
      "epoch:41 step:32611 [D loss: 0.682515, acc.: 54.69%] [G loss: 0.770347]\n",
      "epoch:41 step:32612 [D loss: 0.718791, acc.: 46.88%] [G loss: 0.795473]\n",
      "epoch:41 step:32613 [D loss: 0.645093, acc.: 66.41%] [G loss: 0.855332]\n",
      "epoch:41 step:32614 [D loss: 0.721147, acc.: 50.78%] [G loss: 0.770724]\n",
      "epoch:41 step:32615 [D loss: 0.679026, acc.: 53.91%] [G loss: 0.906502]\n",
      "epoch:41 step:32616 [D loss: 0.621248, acc.: 76.56%] [G loss: 0.908870]\n",
      "epoch:41 step:32617 [D loss: 0.682395, acc.: 51.56%] [G loss: 0.795438]\n",
      "epoch:41 step:32618 [D loss: 0.717068, acc.: 42.97%] [G loss: 0.799471]\n",
      "epoch:41 step:32619 [D loss: 0.617688, acc.: 71.88%] [G loss: 0.847879]\n",
      "epoch:41 step:32620 [D loss: 0.695055, acc.: 53.91%] [G loss: 0.741053]\n",
      "epoch:41 step:32621 [D loss: 0.652985, acc.: 70.31%] [G loss: 0.788642]\n",
      "epoch:41 step:32622 [D loss: 0.702226, acc.: 53.91%] [G loss: 0.746389]\n",
      "epoch:41 step:32623 [D loss: 0.688519, acc.: 53.12%] [G loss: 0.830416]\n",
      "epoch:41 step:32624 [D loss: 0.702406, acc.: 46.09%] [G loss: 0.770332]\n",
      "epoch:41 step:32625 [D loss: 0.649453, acc.: 61.72%] [G loss: 0.839977]\n",
      "epoch:41 step:32626 [D loss: 0.678005, acc.: 57.03%] [G loss: 0.742823]\n",
      "epoch:41 step:32627 [D loss: 0.661414, acc.: 64.06%] [G loss: 0.671575]\n",
      "epoch:41 step:32628 [D loss: 0.654009, acc.: 64.06%] [G loss: 0.780394]\n",
      "epoch:41 step:32629 [D loss: 0.661758, acc.: 61.72%] [G loss: 0.786831]\n",
      "epoch:41 step:32630 [D loss: 0.688425, acc.: 53.91%] [G loss: 0.754937]\n",
      "epoch:41 step:32631 [D loss: 0.687708, acc.: 55.47%] [G loss: 0.749584]\n",
      "epoch:41 step:32632 [D loss: 0.681339, acc.: 52.34%] [G loss: 0.882466]\n",
      "epoch:41 step:32633 [D loss: 0.686490, acc.: 60.16%] [G loss: 0.755472]\n",
      "epoch:41 step:32634 [D loss: 0.705137, acc.: 54.69%] [G loss: 0.779744]\n",
      "epoch:41 step:32635 [D loss: 0.668934, acc.: 59.38%] [G loss: 0.807513]\n",
      "epoch:41 step:32636 [D loss: 0.673996, acc.: 57.03%] [G loss: 0.811648]\n",
      "epoch:41 step:32637 [D loss: 0.707683, acc.: 48.44%] [G loss: 0.723827]\n",
      "epoch:41 step:32638 [D loss: 0.670644, acc.: 61.72%] [G loss: 0.892441]\n",
      "epoch:41 step:32639 [D loss: 0.603186, acc.: 75.00%] [G loss: 0.834248]\n",
      "epoch:41 step:32640 [D loss: 0.706158, acc.: 48.44%] [G loss: 0.721429]\n",
      "epoch:41 step:32641 [D loss: 0.696177, acc.: 54.69%] [G loss: 0.778870]\n",
      "epoch:41 step:32642 [D loss: 0.662789, acc.: 60.16%] [G loss: 0.731631]\n",
      "epoch:41 step:32643 [D loss: 0.697318, acc.: 58.59%] [G loss: 0.771054]\n",
      "epoch:41 step:32644 [D loss: 0.645129, acc.: 59.38%] [G loss: 0.817779]\n",
      "epoch:41 step:32645 [D loss: 0.670912, acc.: 57.81%] [G loss: 0.695820]\n",
      "epoch:41 step:32646 [D loss: 0.731920, acc.: 40.62%] [G loss: 0.726584]\n",
      "epoch:41 step:32647 [D loss: 0.683088, acc.: 49.22%] [G loss: 0.711848]\n",
      "epoch:41 step:32648 [D loss: 0.693120, acc.: 55.47%] [G loss: 0.829973]\n",
      "epoch:41 step:32649 [D loss: 0.561113, acc.: 83.59%] [G loss: 0.896165]\n",
      "epoch:41 step:32650 [D loss: 0.680009, acc.: 57.81%] [G loss: 0.830002]\n",
      "epoch:41 step:32651 [D loss: 0.702732, acc.: 45.31%] [G loss: 0.699883]\n",
      "epoch:41 step:32652 [D loss: 0.687948, acc.: 47.66%] [G loss: 0.724992]\n",
      "epoch:41 step:32653 [D loss: 0.644343, acc.: 60.94%] [G loss: 0.850053]\n",
      "epoch:41 step:32654 [D loss: 0.740129, acc.: 46.09%] [G loss: 0.745309]\n",
      "epoch:41 step:32655 [D loss: 0.683697, acc.: 60.16%] [G loss: 0.798438]\n",
      "epoch:41 step:32656 [D loss: 0.620664, acc.: 71.09%] [G loss: 0.783939]\n",
      "epoch:41 step:32657 [D loss: 0.693588, acc.: 54.69%] [G loss: 0.751582]\n",
      "epoch:41 step:32658 [D loss: 0.672604, acc.: 53.91%] [G loss: 0.829607]\n",
      "epoch:41 step:32659 [D loss: 0.707027, acc.: 49.22%] [G loss: 0.784258]\n",
      "epoch:41 step:32660 [D loss: 0.664654, acc.: 63.28%] [G loss: 0.778097]\n",
      "epoch:41 step:32661 [D loss: 0.704960, acc.: 46.88%] [G loss: 0.702078]\n",
      "epoch:41 step:32662 [D loss: 0.658969, acc.: 64.84%] [G loss: 0.788974]\n",
      "epoch:41 step:32663 [D loss: 0.710427, acc.: 49.22%] [G loss: 0.804290]\n",
      "epoch:41 step:32664 [D loss: 0.673955, acc.: 54.69%] [G loss: 0.853886]\n",
      "epoch:41 step:32665 [D loss: 0.706597, acc.: 48.44%] [G loss: 0.774797]\n",
      "epoch:41 step:32666 [D loss: 0.640408, acc.: 64.84%] [G loss: 0.829145]\n",
      "epoch:41 step:32667 [D loss: 0.704048, acc.: 49.22%] [G loss: 0.900831]\n",
      "epoch:41 step:32668 [D loss: 0.752140, acc.: 40.62%] [G loss: 0.787588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32669 [D loss: 0.623158, acc.: 72.66%] [G loss: 0.799011]\n",
      "epoch:41 step:32670 [D loss: 0.643500, acc.: 63.28%] [G loss: 0.788088]\n",
      "epoch:41 step:32671 [D loss: 0.693769, acc.: 55.47%] [G loss: 0.783140]\n",
      "epoch:41 step:32672 [D loss: 0.720332, acc.: 47.66%] [G loss: 0.795388]\n",
      "epoch:41 step:32673 [D loss: 0.627300, acc.: 72.66%] [G loss: 0.867634]\n",
      "epoch:41 step:32674 [D loss: 0.722394, acc.: 48.44%] [G loss: 0.727737]\n",
      "epoch:41 step:32675 [D loss: 0.653372, acc.: 59.38%] [G loss: 0.771747]\n",
      "epoch:41 step:32676 [D loss: 0.666523, acc.: 59.38%] [G loss: 0.804863]\n",
      "epoch:41 step:32677 [D loss: 0.719528, acc.: 45.31%] [G loss: 0.799752]\n",
      "epoch:41 step:32678 [D loss: 0.688622, acc.: 58.59%] [G loss: 0.902631]\n",
      "epoch:41 step:32679 [D loss: 0.617367, acc.: 67.19%] [G loss: 1.003351]\n",
      "epoch:41 step:32680 [D loss: 0.669412, acc.: 57.81%] [G loss: 0.886428]\n",
      "epoch:41 step:32681 [D loss: 0.657467, acc.: 62.50%] [G loss: 0.889692]\n",
      "epoch:41 step:32682 [D loss: 0.625311, acc.: 70.31%] [G loss: 0.832447]\n",
      "epoch:41 step:32683 [D loss: 0.673519, acc.: 57.81%] [G loss: 0.769626]\n",
      "epoch:41 step:32684 [D loss: 0.647653, acc.: 62.50%] [G loss: 0.801832]\n",
      "epoch:41 step:32685 [D loss: 0.705583, acc.: 50.00%] [G loss: 0.803191]\n",
      "epoch:41 step:32686 [D loss: 0.625996, acc.: 66.41%] [G loss: 0.755644]\n",
      "epoch:41 step:32687 [D loss: 0.691380, acc.: 54.69%] [G loss: 0.682771]\n",
      "epoch:41 step:32688 [D loss: 0.679197, acc.: 51.56%] [G loss: 0.804373]\n",
      "epoch:41 step:32689 [D loss: 0.649497, acc.: 58.59%] [G loss: 0.776121]\n",
      "epoch:41 step:32690 [D loss: 0.703364, acc.: 38.28%] [G loss: 0.835463]\n",
      "epoch:41 step:32691 [D loss: 0.657602, acc.: 65.62%] [G loss: 0.830839]\n",
      "epoch:41 step:32692 [D loss: 0.705676, acc.: 54.69%] [G loss: 0.855550]\n",
      "epoch:41 step:32693 [D loss: 0.699700, acc.: 53.12%] [G loss: 0.792693]\n",
      "epoch:41 step:32694 [D loss: 0.715065, acc.: 52.34%] [G loss: 0.750305]\n",
      "epoch:41 step:32695 [D loss: 0.668252, acc.: 53.91%] [G loss: 0.775201]\n",
      "epoch:41 step:32696 [D loss: 0.707904, acc.: 51.56%] [G loss: 0.778901]\n",
      "epoch:41 step:32697 [D loss: 0.702286, acc.: 54.69%] [G loss: 0.745946]\n",
      "epoch:41 step:32698 [D loss: 0.716245, acc.: 53.12%] [G loss: 0.723149]\n",
      "epoch:41 step:32699 [D loss: 0.709440, acc.: 46.09%] [G loss: 0.775050]\n",
      "epoch:41 step:32700 [D loss: 0.641667, acc.: 64.84%] [G loss: 0.701301]\n",
      "epoch:41 step:32701 [D loss: 0.609201, acc.: 75.00%] [G loss: 0.855565]\n",
      "epoch:41 step:32702 [D loss: 0.673342, acc.: 61.72%] [G loss: 0.754640]\n",
      "epoch:41 step:32703 [D loss: 0.682858, acc.: 55.47%] [G loss: 0.740264]\n",
      "epoch:41 step:32704 [D loss: 0.686102, acc.: 53.91%] [G loss: 0.747445]\n",
      "epoch:41 step:32705 [D loss: 0.705915, acc.: 48.44%] [G loss: 0.770350]\n",
      "epoch:41 step:32706 [D loss: 0.691252, acc.: 55.47%] [G loss: 0.743665]\n",
      "epoch:41 step:32707 [D loss: 0.760659, acc.: 41.41%] [G loss: 0.802895]\n",
      "epoch:41 step:32708 [D loss: 0.656891, acc.: 64.84%] [G loss: 0.841220]\n",
      "epoch:41 step:32709 [D loss: 0.704326, acc.: 51.56%] [G loss: 0.748805]\n",
      "epoch:41 step:32710 [D loss: 0.635257, acc.: 67.19%] [G loss: 0.737121]\n",
      "epoch:41 step:32711 [D loss: 0.728406, acc.: 43.75%] [G loss: 0.645900]\n",
      "epoch:41 step:32712 [D loss: 0.683843, acc.: 54.69%] [G loss: 0.708741]\n",
      "epoch:41 step:32713 [D loss: 0.737047, acc.: 42.97%] [G loss: 0.791755]\n",
      "epoch:41 step:32714 [D loss: 0.711986, acc.: 50.00%] [G loss: 0.714271]\n",
      "epoch:41 step:32715 [D loss: 0.659425, acc.: 56.25%] [G loss: 0.842373]\n",
      "epoch:41 step:32716 [D loss: 0.693440, acc.: 56.25%] [G loss: 0.777882]\n",
      "epoch:41 step:32717 [D loss: 0.781477, acc.: 35.94%] [G loss: 0.806714]\n",
      "epoch:41 step:32718 [D loss: 0.763983, acc.: 39.06%] [G loss: 0.770744]\n",
      "epoch:41 step:32719 [D loss: 0.679576, acc.: 57.81%] [G loss: 0.843894]\n",
      "epoch:41 step:32720 [D loss: 0.662322, acc.: 63.28%] [G loss: 0.862383]\n",
      "epoch:41 step:32721 [D loss: 0.637045, acc.: 64.84%] [G loss: 0.743847]\n",
      "epoch:41 step:32722 [D loss: 0.711318, acc.: 45.31%] [G loss: 0.827727]\n",
      "epoch:41 step:32723 [D loss: 0.622706, acc.: 71.09%] [G loss: 0.892402]\n",
      "epoch:41 step:32724 [D loss: 0.696434, acc.: 48.44%] [G loss: 0.829860]\n",
      "epoch:41 step:32725 [D loss: 0.699970, acc.: 51.56%] [G loss: 0.884338]\n",
      "epoch:41 step:32726 [D loss: 0.733532, acc.: 50.78%] [G loss: 0.775978]\n",
      "epoch:41 step:32727 [D loss: 0.675389, acc.: 58.59%] [G loss: 0.771789]\n",
      "epoch:41 step:32728 [D loss: 0.720532, acc.: 53.91%] [G loss: 0.815607]\n",
      "epoch:41 step:32729 [D loss: 0.703479, acc.: 48.44%] [G loss: 0.754527]\n",
      "epoch:41 step:32730 [D loss: 0.672440, acc.: 54.69%] [G loss: 0.794459]\n",
      "epoch:41 step:32731 [D loss: 0.643186, acc.: 69.53%] [G loss: 0.756450]\n",
      "epoch:41 step:32732 [D loss: 0.680296, acc.: 54.69%] [G loss: 0.748138]\n",
      "epoch:41 step:32733 [D loss: 0.636849, acc.: 72.66%] [G loss: 0.791800]\n",
      "epoch:41 step:32734 [D loss: 0.707214, acc.: 52.34%] [G loss: 0.713447]\n",
      "epoch:41 step:32735 [D loss: 0.672481, acc.: 55.47%] [G loss: 0.740766]\n",
      "epoch:41 step:32736 [D loss: 0.691792, acc.: 51.56%] [G loss: 0.688939]\n",
      "epoch:41 step:32737 [D loss: 0.689194, acc.: 51.56%] [G loss: 0.856694]\n",
      "epoch:41 step:32738 [D loss: 0.690163, acc.: 59.38%] [G loss: 0.784578]\n",
      "epoch:41 step:32739 [D loss: 0.641363, acc.: 63.28%] [G loss: 0.857025]\n",
      "epoch:41 step:32740 [D loss: 0.624887, acc.: 67.97%] [G loss: 0.844695]\n",
      "epoch:41 step:32741 [D loss: 0.698155, acc.: 53.12%] [G loss: 0.798720]\n",
      "epoch:41 step:32742 [D loss: 0.762260, acc.: 41.41%] [G loss: 0.847354]\n",
      "epoch:41 step:32743 [D loss: 0.676183, acc.: 57.03%] [G loss: 0.747288]\n",
      "epoch:41 step:32744 [D loss: 0.752061, acc.: 42.19%] [G loss: 0.732125]\n",
      "epoch:41 step:32745 [D loss: 0.699440, acc.: 54.69%] [G loss: 0.797944]\n",
      "epoch:41 step:32746 [D loss: 0.705964, acc.: 43.75%] [G loss: 0.758963]\n",
      "epoch:41 step:32747 [D loss: 0.648457, acc.: 64.06%] [G loss: 0.762003]\n",
      "epoch:41 step:32748 [D loss: 0.762989, acc.: 34.38%] [G loss: 0.784335]\n",
      "epoch:41 step:32749 [D loss: 0.715906, acc.: 46.88%] [G loss: 0.760614]\n",
      "epoch:41 step:32750 [D loss: 0.690368, acc.: 52.34%] [G loss: 0.845928]\n",
      "epoch:41 step:32751 [D loss: 0.701085, acc.: 59.38%] [G loss: 0.757852]\n",
      "epoch:41 step:32752 [D loss: 0.682120, acc.: 55.47%] [G loss: 0.712432]\n",
      "epoch:41 step:32753 [D loss: 0.717991, acc.: 46.88%] [G loss: 0.840562]\n",
      "epoch:41 step:32754 [D loss: 0.744838, acc.: 45.31%] [G loss: 0.735402]\n",
      "epoch:41 step:32755 [D loss: 0.621453, acc.: 73.44%] [G loss: 0.802854]\n",
      "epoch:41 step:32756 [D loss: 0.683082, acc.: 53.12%] [G loss: 0.812351]\n",
      "epoch:41 step:32757 [D loss: 0.625372, acc.: 68.75%] [G loss: 0.819882]\n",
      "epoch:41 step:32758 [D loss: 0.691207, acc.: 55.47%] [G loss: 0.834262]\n",
      "epoch:41 step:32759 [D loss: 0.664166, acc.: 59.38%] [G loss: 0.790402]\n",
      "epoch:41 step:32760 [D loss: 0.655554, acc.: 64.06%] [G loss: 0.824943]\n",
      "epoch:41 step:32761 [D loss: 0.641400, acc.: 69.53%] [G loss: 0.759451]\n",
      "epoch:41 step:32762 [D loss: 0.606204, acc.: 74.22%] [G loss: 0.872196]\n",
      "epoch:41 step:32763 [D loss: 0.667016, acc.: 59.38%] [G loss: 0.753312]\n",
      "epoch:41 step:32764 [D loss: 0.686108, acc.: 59.38%] [G loss: 0.737166]\n",
      "epoch:41 step:32765 [D loss: 0.684952, acc.: 53.12%] [G loss: 0.714678]\n",
      "epoch:41 step:32766 [D loss: 0.686380, acc.: 57.81%] [G loss: 0.750231]\n",
      "epoch:41 step:32767 [D loss: 0.650382, acc.: 67.19%] [G loss: 0.829463]\n",
      "epoch:41 step:32768 [D loss: 0.635768, acc.: 68.75%] [G loss: 0.814540]\n",
      "epoch:41 step:32769 [D loss: 0.688787, acc.: 58.59%] [G loss: 0.806220]\n",
      "epoch:41 step:32770 [D loss: 0.678840, acc.: 57.81%] [G loss: 0.722919]\n",
      "epoch:41 step:32771 [D loss: 0.683838, acc.: 55.47%] [G loss: 0.834514]\n",
      "epoch:41 step:32772 [D loss: 0.693890, acc.: 51.56%] [G loss: 0.804452]\n",
      "epoch:41 step:32773 [D loss: 0.654814, acc.: 57.81%] [G loss: 0.820468]\n",
      "epoch:41 step:32774 [D loss: 0.657517, acc.: 60.94%] [G loss: 0.859268]\n",
      "epoch:41 step:32775 [D loss: 0.675594, acc.: 56.25%] [G loss: 0.820863]\n",
      "epoch:41 step:32776 [D loss: 0.728450, acc.: 46.09%] [G loss: 0.831696]\n",
      "epoch:41 step:32777 [D loss: 0.675974, acc.: 53.91%] [G loss: 0.816063]\n",
      "epoch:41 step:32778 [D loss: 0.709663, acc.: 48.44%] [G loss: 0.868830]\n",
      "epoch:41 step:32779 [D loss: 0.650036, acc.: 67.19%] [G loss: 0.856116]\n",
      "epoch:41 step:32780 [D loss: 0.776415, acc.: 42.19%] [G loss: 0.769888]\n",
      "epoch:41 step:32781 [D loss: 0.744182, acc.: 40.62%] [G loss: 0.744949]\n",
      "epoch:41 step:32782 [D loss: 0.697474, acc.: 51.56%] [G loss: 0.764378]\n",
      "epoch:41 step:32783 [D loss: 0.692302, acc.: 59.38%] [G loss: 0.806280]\n",
      "epoch:41 step:32784 [D loss: 0.723272, acc.: 49.22%] [G loss: 0.731415]\n",
      "epoch:41 step:32785 [D loss: 0.678136, acc.: 55.47%] [G loss: 0.773405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32786 [D loss: 0.672264, acc.: 59.38%] [G loss: 0.831850]\n",
      "epoch:41 step:32787 [D loss: 0.669290, acc.: 63.28%] [G loss: 0.720566]\n",
      "epoch:41 step:32788 [D loss: 0.661581, acc.: 60.94%] [G loss: 0.849751]\n",
      "epoch:41 step:32789 [D loss: 0.619920, acc.: 67.19%] [G loss: 0.847205]\n",
      "epoch:41 step:32790 [D loss: 0.679159, acc.: 53.12%] [G loss: 0.868144]\n",
      "epoch:41 step:32791 [D loss: 0.645386, acc.: 67.97%] [G loss: 0.798638]\n",
      "epoch:41 step:32792 [D loss: 0.738091, acc.: 47.66%] [G loss: 0.781859]\n",
      "epoch:41 step:32793 [D loss: 0.685316, acc.: 56.25%] [G loss: 0.789788]\n",
      "epoch:41 step:32794 [D loss: 0.657910, acc.: 66.41%] [G loss: 0.784327]\n",
      "epoch:41 step:32795 [D loss: 0.656287, acc.: 59.38%] [G loss: 0.832107]\n",
      "epoch:41 step:32796 [D loss: 0.682311, acc.: 53.12%] [G loss: 0.772284]\n",
      "epoch:41 step:32797 [D loss: 0.684618, acc.: 56.25%] [G loss: 0.809856]\n",
      "epoch:41 step:32798 [D loss: 0.705525, acc.: 49.22%] [G loss: 0.856053]\n",
      "epoch:41 step:32799 [D loss: 0.694324, acc.: 54.69%] [G loss: 0.814248]\n",
      "epoch:41 step:32800 [D loss: 0.654739, acc.: 62.50%] [G loss: 0.820523]\n",
      "epoch:41 step:32801 [D loss: 0.713994, acc.: 44.53%] [G loss: 0.873913]\n",
      "epoch:41 step:32802 [D loss: 0.581399, acc.: 78.91%] [G loss: 0.846907]\n",
      "epoch:42 step:32803 [D loss: 0.643801, acc.: 65.62%] [G loss: 0.773037]\n",
      "epoch:42 step:32804 [D loss: 0.672850, acc.: 53.12%] [G loss: 0.809526]\n",
      "epoch:42 step:32805 [D loss: 0.659782, acc.: 63.28%] [G loss: 0.703291]\n",
      "epoch:42 step:32806 [D loss: 0.692767, acc.: 54.69%] [G loss: 0.700321]\n",
      "epoch:42 step:32807 [D loss: 0.685408, acc.: 54.69%] [G loss: 0.866492]\n",
      "epoch:42 step:32808 [D loss: 0.676908, acc.: 60.16%] [G loss: 0.787769]\n",
      "epoch:42 step:32809 [D loss: 0.705250, acc.: 48.44%] [G loss: 0.820487]\n",
      "epoch:42 step:32810 [D loss: 0.705604, acc.: 50.78%] [G loss: 0.814489]\n",
      "epoch:42 step:32811 [D loss: 0.714815, acc.: 54.69%] [G loss: 0.862339]\n",
      "epoch:42 step:32812 [D loss: 0.719977, acc.: 44.53%] [G loss: 0.783725]\n",
      "epoch:42 step:32813 [D loss: 0.706090, acc.: 51.56%] [G loss: 0.829512]\n",
      "epoch:42 step:32814 [D loss: 0.713191, acc.: 53.12%] [G loss: 0.755734]\n",
      "epoch:42 step:32815 [D loss: 0.674295, acc.: 58.59%] [G loss: 0.866910]\n",
      "epoch:42 step:32816 [D loss: 0.708660, acc.: 50.00%] [G loss: 0.744558]\n",
      "epoch:42 step:32817 [D loss: 0.719200, acc.: 47.66%] [G loss: 0.805503]\n",
      "epoch:42 step:32818 [D loss: 0.680574, acc.: 57.03%] [G loss: 0.758310]\n",
      "epoch:42 step:32819 [D loss: 0.703453, acc.: 55.47%] [G loss: 0.707565]\n",
      "epoch:42 step:32820 [D loss: 0.739926, acc.: 47.66%] [G loss: 0.760192]\n",
      "epoch:42 step:32821 [D loss: 0.699379, acc.: 52.34%] [G loss: 0.729741]\n",
      "epoch:42 step:32822 [D loss: 0.729408, acc.: 46.09%] [G loss: 0.813769]\n",
      "epoch:42 step:32823 [D loss: 0.732772, acc.: 45.31%] [G loss: 0.816382]\n",
      "epoch:42 step:32824 [D loss: 0.664615, acc.: 58.59%] [G loss: 0.782988]\n",
      "epoch:42 step:32825 [D loss: 0.715527, acc.: 47.66%] [G loss: 0.835575]\n",
      "epoch:42 step:32826 [D loss: 0.718467, acc.: 50.00%] [G loss: 0.798006]\n",
      "epoch:42 step:32827 [D loss: 0.699663, acc.: 50.78%] [G loss: 0.741302]\n",
      "epoch:42 step:32828 [D loss: 0.677703, acc.: 53.12%] [G loss: 0.801876]\n",
      "epoch:42 step:32829 [D loss: 0.690416, acc.: 53.12%] [G loss: 0.826430]\n",
      "epoch:42 step:32830 [D loss: 0.717894, acc.: 51.56%] [G loss: 0.752665]\n",
      "epoch:42 step:32831 [D loss: 0.706245, acc.: 49.22%] [G loss: 0.780110]\n",
      "epoch:42 step:32832 [D loss: 0.709610, acc.: 55.47%] [G loss: 0.802461]\n",
      "epoch:42 step:32833 [D loss: 0.672199, acc.: 63.28%] [G loss: 0.787889]\n",
      "epoch:42 step:32834 [D loss: 0.670818, acc.: 57.03%] [G loss: 0.829982]\n",
      "epoch:42 step:32835 [D loss: 0.669396, acc.: 61.72%] [G loss: 0.870065]\n",
      "epoch:42 step:32836 [D loss: 0.637121, acc.: 64.84%] [G loss: 0.839262]\n",
      "epoch:42 step:32837 [D loss: 0.660903, acc.: 56.25%] [G loss: 0.714227]\n",
      "epoch:42 step:32838 [D loss: 0.696096, acc.: 54.69%] [G loss: 0.837479]\n",
      "epoch:42 step:32839 [D loss: 0.709307, acc.: 55.47%] [G loss: 0.847063]\n",
      "epoch:42 step:32840 [D loss: 0.677875, acc.: 57.81%] [G loss: 0.817100]\n",
      "epoch:42 step:32841 [D loss: 0.638950, acc.: 78.12%] [G loss: 0.820620]\n",
      "epoch:42 step:32842 [D loss: 0.683887, acc.: 60.16%] [G loss: 0.763887]\n",
      "epoch:42 step:32843 [D loss: 0.623055, acc.: 65.62%] [G loss: 0.832784]\n",
      "epoch:42 step:32844 [D loss: 0.639381, acc.: 64.84%] [G loss: 0.720437]\n",
      "epoch:42 step:32845 [D loss: 0.681629, acc.: 58.59%] [G loss: 0.786934]\n",
      "epoch:42 step:32846 [D loss: 0.727196, acc.: 48.44%] [G loss: 0.682256]\n",
      "epoch:42 step:32847 [D loss: 0.659613, acc.: 60.16%] [G loss: 0.824958]\n",
      "epoch:42 step:32848 [D loss: 0.672386, acc.: 54.69%] [G loss: 0.805282]\n",
      "epoch:42 step:32849 [D loss: 0.693269, acc.: 50.00%] [G loss: 0.807129]\n",
      "epoch:42 step:32850 [D loss: 0.629064, acc.: 69.53%] [G loss: 0.771966]\n",
      "epoch:42 step:32851 [D loss: 0.697853, acc.: 48.44%] [G loss: 0.753370]\n",
      "epoch:42 step:32852 [D loss: 0.763458, acc.: 42.19%] [G loss: 0.711267]\n",
      "epoch:42 step:32853 [D loss: 0.638254, acc.: 63.28%] [G loss: 0.758440]\n",
      "epoch:42 step:32854 [D loss: 0.603642, acc.: 74.22%] [G loss: 0.722316]\n",
      "epoch:42 step:32855 [D loss: 0.680471, acc.: 52.34%] [G loss: 0.726270]\n",
      "epoch:42 step:32856 [D loss: 0.693887, acc.: 52.34%] [G loss: 0.846432]\n",
      "epoch:42 step:32857 [D loss: 0.626051, acc.: 74.22%] [G loss: 0.735835]\n",
      "epoch:42 step:32858 [D loss: 0.664713, acc.: 58.59%] [G loss: 0.789201]\n",
      "epoch:42 step:32859 [D loss: 0.730270, acc.: 41.41%] [G loss: 0.833363]\n",
      "epoch:42 step:32860 [D loss: 0.683998, acc.: 54.69%] [G loss: 0.777583]\n",
      "epoch:42 step:32861 [D loss: 0.660686, acc.: 58.59%] [G loss: 0.774136]\n",
      "epoch:42 step:32862 [D loss: 0.689281, acc.: 55.47%] [G loss: 0.769674]\n",
      "epoch:42 step:32863 [D loss: 0.662066, acc.: 63.28%] [G loss: 0.791544]\n",
      "epoch:42 step:32864 [D loss: 0.635008, acc.: 69.53%] [G loss: 0.824215]\n",
      "epoch:42 step:32865 [D loss: 0.701745, acc.: 51.56%] [G loss: 0.860013]\n",
      "epoch:42 step:32866 [D loss: 0.679440, acc.: 57.81%] [G loss: 0.805014]\n",
      "epoch:42 step:32867 [D loss: 0.697899, acc.: 52.34%] [G loss: 0.765232]\n",
      "epoch:42 step:32868 [D loss: 0.730686, acc.: 47.66%] [G loss: 0.774372]\n",
      "epoch:42 step:32869 [D loss: 0.703886, acc.: 46.09%] [G loss: 0.796599]\n",
      "epoch:42 step:32870 [D loss: 0.689879, acc.: 54.69%] [G loss: 0.847063]\n",
      "epoch:42 step:32871 [D loss: 0.690537, acc.: 56.25%] [G loss: 0.808722]\n",
      "epoch:42 step:32872 [D loss: 0.721122, acc.: 49.22%] [G loss: 0.747991]\n",
      "epoch:42 step:32873 [D loss: 0.687402, acc.: 53.12%] [G loss: 0.844439]\n",
      "epoch:42 step:32874 [D loss: 0.678579, acc.: 59.38%] [G loss: 0.779962]\n",
      "epoch:42 step:32875 [D loss: 0.646989, acc.: 64.06%] [G loss: 0.761224]\n",
      "epoch:42 step:32876 [D loss: 0.594116, acc.: 74.22%] [G loss: 0.760154]\n",
      "epoch:42 step:32877 [D loss: 0.649967, acc.: 64.84%] [G loss: 0.890733]\n",
      "epoch:42 step:32878 [D loss: 0.729485, acc.: 47.66%] [G loss: 0.849116]\n",
      "epoch:42 step:32879 [D loss: 0.602808, acc.: 77.34%] [G loss: 0.738184]\n",
      "epoch:42 step:32880 [D loss: 0.653425, acc.: 64.84%] [G loss: 0.727378]\n",
      "epoch:42 step:32881 [D loss: 0.691239, acc.: 53.91%] [G loss: 0.829101]\n",
      "epoch:42 step:32882 [D loss: 0.678088, acc.: 53.91%] [G loss: 0.816363]\n",
      "epoch:42 step:32883 [D loss: 0.689141, acc.: 53.12%] [G loss: 0.841800]\n",
      "epoch:42 step:32884 [D loss: 0.696118, acc.: 53.12%] [G loss: 0.826441]\n",
      "epoch:42 step:32885 [D loss: 0.716675, acc.: 48.44%] [G loss: 0.791774]\n",
      "epoch:42 step:32886 [D loss: 0.643254, acc.: 64.84%] [G loss: 0.866513]\n",
      "epoch:42 step:32887 [D loss: 0.736186, acc.: 42.19%] [G loss: 0.748959]\n",
      "epoch:42 step:32888 [D loss: 0.689422, acc.: 52.34%] [G loss: 0.780339]\n",
      "epoch:42 step:32889 [D loss: 0.670283, acc.: 60.94%] [G loss: 0.700963]\n",
      "epoch:42 step:32890 [D loss: 0.726291, acc.: 43.75%] [G loss: 0.831170]\n",
      "epoch:42 step:32891 [D loss: 0.680783, acc.: 60.94%] [G loss: 0.812860]\n",
      "epoch:42 step:32892 [D loss: 0.645358, acc.: 64.06%] [G loss: 0.761416]\n",
      "epoch:42 step:32893 [D loss: 0.649871, acc.: 60.94%] [G loss: 0.837608]\n",
      "epoch:42 step:32894 [D loss: 0.702071, acc.: 53.91%] [G loss: 0.799507]\n",
      "epoch:42 step:32895 [D loss: 0.753999, acc.: 36.72%] [G loss: 0.791112]\n",
      "epoch:42 step:32896 [D loss: 0.693143, acc.: 53.12%] [G loss: 0.714356]\n",
      "epoch:42 step:32897 [D loss: 0.655028, acc.: 64.84%] [G loss: 0.804353]\n",
      "epoch:42 step:32898 [D loss: 0.636060, acc.: 66.41%] [G loss: 0.779307]\n",
      "epoch:42 step:32899 [D loss: 0.740889, acc.: 41.41%] [G loss: 0.772862]\n",
      "epoch:42 step:32900 [D loss: 0.697500, acc.: 57.03%] [G loss: 0.785243]\n",
      "epoch:42 step:32901 [D loss: 0.799411, acc.: 28.91%] [G loss: 0.648971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32902 [D loss: 0.664099, acc.: 62.50%] [G loss: 0.853734]\n",
      "epoch:42 step:32903 [D loss: 0.695695, acc.: 51.56%] [G loss: 0.862418]\n",
      "epoch:42 step:32904 [D loss: 0.729507, acc.: 46.88%] [G loss: 0.820120]\n",
      "epoch:42 step:32905 [D loss: 0.724801, acc.: 42.97%] [G loss: 0.773318]\n",
      "epoch:42 step:32906 [D loss: 0.703913, acc.: 51.56%] [G loss: 0.877525]\n",
      "epoch:42 step:32907 [D loss: 0.696788, acc.: 53.91%] [G loss: 0.819153]\n",
      "epoch:42 step:32908 [D loss: 0.660357, acc.: 63.28%] [G loss: 0.823529]\n",
      "epoch:42 step:32909 [D loss: 0.673919, acc.: 60.16%] [G loss: 0.875778]\n",
      "epoch:42 step:32910 [D loss: 0.689562, acc.: 57.03%] [G loss: 0.808084]\n",
      "epoch:42 step:32911 [D loss: 0.664470, acc.: 62.50%] [G loss: 0.798386]\n",
      "epoch:42 step:32912 [D loss: 0.682117, acc.: 55.47%] [G loss: 0.751724]\n",
      "epoch:42 step:32913 [D loss: 0.666065, acc.: 60.16%] [G loss: 0.756356]\n",
      "epoch:42 step:32914 [D loss: 0.643946, acc.: 64.06%] [G loss: 0.777757]\n",
      "epoch:42 step:32915 [D loss: 0.651173, acc.: 70.31%] [G loss: 0.833532]\n",
      "epoch:42 step:32916 [D loss: 0.607524, acc.: 77.34%] [G loss: 0.716211]\n",
      "epoch:42 step:32917 [D loss: 0.703845, acc.: 49.22%] [G loss: 0.794971]\n",
      "epoch:42 step:32918 [D loss: 0.681675, acc.: 56.25%] [G loss: 0.752521]\n",
      "epoch:42 step:32919 [D loss: 0.713587, acc.: 51.56%] [G loss: 0.688013]\n",
      "epoch:42 step:32920 [D loss: 0.678073, acc.: 63.28%] [G loss: 0.717059]\n",
      "epoch:42 step:32921 [D loss: 0.658429, acc.: 62.50%] [G loss: 0.808082]\n",
      "epoch:42 step:32922 [D loss: 0.665456, acc.: 60.16%] [G loss: 0.807083]\n",
      "epoch:42 step:32923 [D loss: 0.641501, acc.: 64.06%] [G loss: 0.792196]\n",
      "epoch:42 step:32924 [D loss: 0.671036, acc.: 53.91%] [G loss: 0.787229]\n",
      "epoch:42 step:32925 [D loss: 0.721869, acc.: 47.66%] [G loss: 0.789958]\n",
      "epoch:42 step:32926 [D loss: 0.650836, acc.: 64.84%] [G loss: 0.808105]\n",
      "epoch:42 step:32927 [D loss: 0.717697, acc.: 41.41%] [G loss: 0.815335]\n",
      "epoch:42 step:32928 [D loss: 0.685728, acc.: 53.91%] [G loss: 0.731690]\n",
      "epoch:42 step:32929 [D loss: 0.694851, acc.: 53.91%] [G loss: 0.759899]\n",
      "epoch:42 step:32930 [D loss: 0.613840, acc.: 70.31%] [G loss: 0.849154]\n",
      "epoch:42 step:32931 [D loss: 0.719449, acc.: 47.66%] [G loss: 0.819104]\n",
      "epoch:42 step:32932 [D loss: 0.666381, acc.: 60.16%] [G loss: 0.696478]\n",
      "epoch:42 step:32933 [D loss: 0.709572, acc.: 57.03%] [G loss: 0.788000]\n",
      "epoch:42 step:32934 [D loss: 0.599559, acc.: 77.34%] [G loss: 0.855151]\n",
      "epoch:42 step:32935 [D loss: 0.758712, acc.: 39.06%] [G loss: 0.781404]\n",
      "epoch:42 step:32936 [D loss: 0.684992, acc.: 57.03%] [G loss: 0.889897]\n",
      "epoch:42 step:32937 [D loss: 0.718113, acc.: 50.78%] [G loss: 0.818265]\n",
      "epoch:42 step:32938 [D loss: 0.714915, acc.: 48.44%] [G loss: 0.811276]\n",
      "epoch:42 step:32939 [D loss: 0.733317, acc.: 46.09%] [G loss: 0.753129]\n",
      "epoch:42 step:32940 [D loss: 0.733662, acc.: 43.75%] [G loss: 0.781104]\n",
      "epoch:42 step:32941 [D loss: 0.680691, acc.: 53.91%] [G loss: 0.750969]\n",
      "epoch:42 step:32942 [D loss: 0.668354, acc.: 56.25%] [G loss: 0.734393]\n",
      "epoch:42 step:32943 [D loss: 0.706923, acc.: 58.59%] [G loss: 0.796550]\n",
      "epoch:42 step:32944 [D loss: 0.655687, acc.: 62.50%] [G loss: 0.819954]\n",
      "epoch:42 step:32945 [D loss: 0.665354, acc.: 55.47%] [G loss: 0.853608]\n",
      "epoch:42 step:32946 [D loss: 0.630849, acc.: 69.53%] [G loss: 0.803930]\n",
      "epoch:42 step:32947 [D loss: 0.708448, acc.: 49.22%] [G loss: 0.811152]\n",
      "epoch:42 step:32948 [D loss: 0.662766, acc.: 59.38%] [G loss: 0.799620]\n",
      "epoch:42 step:32949 [D loss: 0.658847, acc.: 61.72%] [G loss: 0.758251]\n",
      "epoch:42 step:32950 [D loss: 0.733761, acc.: 46.09%] [G loss: 0.760953]\n",
      "epoch:42 step:32951 [D loss: 0.691284, acc.: 56.25%] [G loss: 0.758481]\n",
      "epoch:42 step:32952 [D loss: 0.696048, acc.: 48.44%] [G loss: 0.900797]\n",
      "epoch:42 step:32953 [D loss: 0.629903, acc.: 67.19%] [G loss: 0.881148]\n",
      "epoch:42 step:32954 [D loss: 0.678839, acc.: 57.81%] [G loss: 0.814942]\n",
      "epoch:42 step:32955 [D loss: 0.701915, acc.: 50.00%] [G loss: 0.909587]\n",
      "epoch:42 step:32956 [D loss: 0.686371, acc.: 49.22%] [G loss: 0.807697]\n",
      "epoch:42 step:32957 [D loss: 0.656065, acc.: 60.16%] [G loss: 0.897011]\n",
      "epoch:42 step:32958 [D loss: 0.700021, acc.: 52.34%] [G loss: 0.761234]\n",
      "epoch:42 step:32959 [D loss: 0.657766, acc.: 62.50%] [G loss: 0.837769]\n",
      "epoch:42 step:32960 [D loss: 0.696483, acc.: 57.81%] [G loss: 0.723125]\n",
      "epoch:42 step:32961 [D loss: 0.727326, acc.: 46.88%] [G loss: 0.709778]\n",
      "epoch:42 step:32962 [D loss: 0.623190, acc.: 71.09%] [G loss: 0.768010]\n",
      "epoch:42 step:32963 [D loss: 0.750996, acc.: 42.19%] [G loss: 0.688322]\n",
      "epoch:42 step:32964 [D loss: 0.727681, acc.: 46.88%] [G loss: 0.729359]\n",
      "epoch:42 step:32965 [D loss: 0.666871, acc.: 60.16%] [G loss: 0.839464]\n",
      "epoch:42 step:32966 [D loss: 0.710845, acc.: 47.66%] [G loss: 0.740969]\n",
      "epoch:42 step:32967 [D loss: 0.737547, acc.: 41.41%] [G loss: 0.846141]\n",
      "epoch:42 step:32968 [D loss: 0.702112, acc.: 53.12%] [G loss: 0.799857]\n",
      "epoch:42 step:32969 [D loss: 0.698541, acc.: 50.00%] [G loss: 0.883186]\n",
      "epoch:42 step:32970 [D loss: 0.670688, acc.: 60.94%] [G loss: 0.835407]\n",
      "epoch:42 step:32971 [D loss: 0.667110, acc.: 58.59%] [G loss: 0.868327]\n",
      "epoch:42 step:32972 [D loss: 0.722871, acc.: 53.91%] [G loss: 0.787581]\n",
      "epoch:42 step:32973 [D loss: 0.672464, acc.: 57.03%] [G loss: 0.796994]\n",
      "epoch:42 step:32974 [D loss: 0.731094, acc.: 42.19%] [G loss: 0.891819]\n",
      "epoch:42 step:32975 [D loss: 0.709608, acc.: 46.88%] [G loss: 0.789161]\n",
      "epoch:42 step:32976 [D loss: 0.743336, acc.: 42.19%] [G loss: 0.768540]\n",
      "epoch:42 step:32977 [D loss: 0.650198, acc.: 64.84%] [G loss: 0.829194]\n",
      "epoch:42 step:32978 [D loss: 0.686409, acc.: 57.03%] [G loss: 0.902720]\n",
      "epoch:42 step:32979 [D loss: 0.629141, acc.: 65.62%] [G loss: 0.925659]\n",
      "epoch:42 step:32980 [D loss: 0.776742, acc.: 32.81%] [G loss: 0.802964]\n",
      "epoch:42 step:32981 [D loss: 0.620130, acc.: 73.44%] [G loss: 0.753783]\n",
      "epoch:42 step:32982 [D loss: 0.646655, acc.: 64.06%] [G loss: 0.709400]\n",
      "epoch:42 step:32983 [D loss: 0.636024, acc.: 71.09%] [G loss: 0.799186]\n",
      "epoch:42 step:32984 [D loss: 0.771499, acc.: 34.38%] [G loss: 0.836733]\n",
      "epoch:42 step:32985 [D loss: 0.676052, acc.: 57.81%] [G loss: 0.755804]\n",
      "epoch:42 step:32986 [D loss: 0.690382, acc.: 49.22%] [G loss: 0.806039]\n",
      "epoch:42 step:32987 [D loss: 0.625371, acc.: 71.88%] [G loss: 0.852150]\n",
      "epoch:42 step:32988 [D loss: 0.721332, acc.: 50.00%] [G loss: 0.843108]\n",
      "epoch:42 step:32989 [D loss: 0.657061, acc.: 60.94%] [G loss: 0.781120]\n",
      "epoch:42 step:32990 [D loss: 0.696345, acc.: 50.00%] [G loss: 0.775672]\n",
      "epoch:42 step:32991 [D loss: 0.605372, acc.: 75.00%] [G loss: 0.859802]\n",
      "epoch:42 step:32992 [D loss: 0.704633, acc.: 53.91%] [G loss: 0.786383]\n",
      "epoch:42 step:32993 [D loss: 0.627901, acc.: 67.19%] [G loss: 0.794062]\n",
      "epoch:42 step:32994 [D loss: 0.680568, acc.: 57.03%] [G loss: 0.794409]\n",
      "epoch:42 step:32995 [D loss: 0.650030, acc.: 60.94%] [G loss: 0.868754]\n",
      "epoch:42 step:32996 [D loss: 0.709819, acc.: 46.09%] [G loss: 0.696211]\n",
      "epoch:42 step:32997 [D loss: 0.692918, acc.: 54.69%] [G loss: 0.802382]\n",
      "epoch:42 step:32998 [D loss: 0.653941, acc.: 67.19%] [G loss: 0.810114]\n",
      "epoch:42 step:32999 [D loss: 0.631781, acc.: 61.72%] [G loss: 0.734818]\n",
      "epoch:42 step:33000 [D loss: 0.668535, acc.: 57.81%] [G loss: 0.800011]\n",
      "epoch:42 step:33001 [D loss: 0.700052, acc.: 49.22%] [G loss: 0.722054]\n",
      "epoch:42 step:33002 [D loss: 0.675047, acc.: 56.25%] [G loss: 0.775150]\n",
      "epoch:42 step:33003 [D loss: 0.645732, acc.: 65.62%] [G loss: 0.672469]\n",
      "epoch:42 step:33004 [D loss: 0.692499, acc.: 54.69%] [G loss: 0.790696]\n",
      "epoch:42 step:33005 [D loss: 0.654230, acc.: 58.59%] [G loss: 0.813582]\n",
      "epoch:42 step:33006 [D loss: 0.704003, acc.: 52.34%] [G loss: 0.810278]\n",
      "epoch:42 step:33007 [D loss: 0.798763, acc.: 31.25%] [G loss: 0.753428]\n",
      "epoch:42 step:33008 [D loss: 0.653025, acc.: 62.50%] [G loss: 0.740010]\n",
      "epoch:42 step:33009 [D loss: 0.662774, acc.: 67.19%] [G loss: 0.805481]\n",
      "epoch:42 step:33010 [D loss: 0.678262, acc.: 61.72%] [G loss: 0.741729]\n",
      "epoch:42 step:33011 [D loss: 0.636571, acc.: 67.19%] [G loss: 0.778374]\n",
      "epoch:42 step:33012 [D loss: 0.601680, acc.: 74.22%] [G loss: 0.820860]\n",
      "epoch:42 step:33013 [D loss: 0.679130, acc.: 55.47%] [G loss: 0.710313]\n",
      "epoch:42 step:33014 [D loss: 0.673442, acc.: 56.25%] [G loss: 0.804862]\n",
      "epoch:42 step:33015 [D loss: 0.708975, acc.: 50.78%] [G loss: 0.836318]\n",
      "epoch:42 step:33016 [D loss: 0.700466, acc.: 52.34%] [G loss: 0.810536]\n",
      "epoch:42 step:33017 [D loss: 0.701464, acc.: 50.00%] [G loss: 0.845033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33018 [D loss: 0.658604, acc.: 64.06%] [G loss: 0.753951]\n",
      "epoch:42 step:33019 [D loss: 0.663799, acc.: 56.25%] [G loss: 0.708993]\n",
      "epoch:42 step:33020 [D loss: 0.652176, acc.: 67.19%] [G loss: 0.758057]\n",
      "epoch:42 step:33021 [D loss: 0.647329, acc.: 63.28%] [G loss: 0.734968]\n",
      "epoch:42 step:33022 [D loss: 0.716411, acc.: 47.66%] [G loss: 0.743134]\n",
      "epoch:42 step:33023 [D loss: 0.703557, acc.: 49.22%] [G loss: 0.770075]\n",
      "epoch:42 step:33024 [D loss: 0.689559, acc.: 50.78%] [G loss: 0.752947]\n",
      "epoch:42 step:33025 [D loss: 0.585105, acc.: 71.88%] [G loss: 0.730962]\n",
      "epoch:42 step:33026 [D loss: 0.671137, acc.: 59.38%] [G loss: 0.706468]\n",
      "epoch:42 step:33027 [D loss: 0.669532, acc.: 57.03%] [G loss: 0.728738]\n",
      "epoch:42 step:33028 [D loss: 0.696287, acc.: 53.91%] [G loss: 0.788115]\n",
      "epoch:42 step:33029 [D loss: 0.649279, acc.: 64.84%] [G loss: 0.877384]\n",
      "epoch:42 step:33030 [D loss: 0.686117, acc.: 57.03%] [G loss: 0.743142]\n",
      "epoch:42 step:33031 [D loss: 0.691089, acc.: 57.03%] [G loss: 0.738807]\n",
      "epoch:42 step:33032 [D loss: 0.756017, acc.: 42.19%] [G loss: 0.819064]\n",
      "epoch:42 step:33033 [D loss: 0.683372, acc.: 53.12%] [G loss: 0.818674]\n",
      "epoch:42 step:33034 [D loss: 0.663248, acc.: 58.59%] [G loss: 0.777602]\n",
      "epoch:42 step:33035 [D loss: 0.657060, acc.: 64.06%] [G loss: 0.863097]\n",
      "epoch:42 step:33036 [D loss: 0.734838, acc.: 45.31%] [G loss: 0.748981]\n",
      "epoch:42 step:33037 [D loss: 0.735347, acc.: 42.19%] [G loss: 0.689878]\n",
      "epoch:42 step:33038 [D loss: 0.802636, acc.: 36.72%] [G loss: 0.725410]\n",
      "epoch:42 step:33039 [D loss: 0.628630, acc.: 66.41%] [G loss: 0.739436]\n",
      "epoch:42 step:33040 [D loss: 0.742432, acc.: 42.19%] [G loss: 0.726769]\n",
      "epoch:42 step:33041 [D loss: 0.693020, acc.: 50.78%] [G loss: 0.816663]\n",
      "epoch:42 step:33042 [D loss: 0.710273, acc.: 51.56%] [G loss: 0.749782]\n",
      "epoch:42 step:33043 [D loss: 0.666396, acc.: 60.94%] [G loss: 0.841538]\n",
      "epoch:42 step:33044 [D loss: 0.692178, acc.: 55.47%] [G loss: 0.828004]\n",
      "epoch:42 step:33045 [D loss: 0.696139, acc.: 51.56%] [G loss: 0.815268]\n",
      "epoch:42 step:33046 [D loss: 0.698020, acc.: 50.78%] [G loss: 0.826495]\n",
      "epoch:42 step:33047 [D loss: 0.679528, acc.: 51.56%] [G loss: 0.804067]\n",
      "epoch:42 step:33048 [D loss: 0.656952, acc.: 62.50%] [G loss: 0.799012]\n",
      "epoch:42 step:33049 [D loss: 0.689893, acc.: 54.69%] [G loss: 0.690013]\n",
      "epoch:42 step:33050 [D loss: 0.596821, acc.: 75.78%] [G loss: 0.808087]\n",
      "epoch:42 step:33051 [D loss: 0.645241, acc.: 63.28%] [G loss: 0.736330]\n",
      "epoch:42 step:33052 [D loss: 0.594860, acc.: 79.69%] [G loss: 0.855424]\n",
      "epoch:42 step:33053 [D loss: 0.637445, acc.: 68.75%] [G loss: 0.758141]\n",
      "epoch:42 step:33054 [D loss: 0.703572, acc.: 53.91%] [G loss: 0.805652]\n",
      "epoch:42 step:33055 [D loss: 0.728945, acc.: 46.88%] [G loss: 0.759682]\n",
      "epoch:42 step:33056 [D loss: 0.749214, acc.: 39.06%] [G loss: 0.806446]\n",
      "epoch:42 step:33057 [D loss: 0.646319, acc.: 65.62%] [G loss: 0.761556]\n",
      "epoch:42 step:33058 [D loss: 0.659156, acc.: 61.72%] [G loss: 0.710117]\n",
      "epoch:42 step:33059 [D loss: 0.741572, acc.: 47.66%] [G loss: 0.797176]\n",
      "epoch:42 step:33060 [D loss: 0.715446, acc.: 51.56%] [G loss: 0.697966]\n",
      "epoch:42 step:33061 [D loss: 0.663797, acc.: 56.25%] [G loss: 0.790778]\n",
      "epoch:42 step:33062 [D loss: 0.702466, acc.: 48.44%] [G loss: 0.797511]\n",
      "epoch:42 step:33063 [D loss: 0.710599, acc.: 50.78%] [G loss: 0.753553]\n",
      "epoch:42 step:33064 [D loss: 0.692256, acc.: 53.91%] [G loss: 0.829038]\n",
      "epoch:42 step:33065 [D loss: 0.659215, acc.: 60.16%] [G loss: 0.803795]\n",
      "epoch:42 step:33066 [D loss: 0.640555, acc.: 60.16%] [G loss: 0.953523]\n",
      "epoch:42 step:33067 [D loss: 0.712057, acc.: 52.34%] [G loss: 0.767184]\n",
      "epoch:42 step:33068 [D loss: 0.663912, acc.: 58.59%] [G loss: 0.802821]\n",
      "epoch:42 step:33069 [D loss: 0.729148, acc.: 46.09%] [G loss: 0.772164]\n",
      "epoch:42 step:33070 [D loss: 0.660059, acc.: 61.72%] [G loss: 0.788091]\n",
      "epoch:42 step:33071 [D loss: 0.691637, acc.: 49.22%] [G loss: 0.683154]\n",
      "epoch:42 step:33072 [D loss: 0.703021, acc.: 52.34%] [G loss: 0.719275]\n",
      "epoch:42 step:33073 [D loss: 0.717598, acc.: 48.44%] [G loss: 0.759884]\n",
      "epoch:42 step:33074 [D loss: 0.666656, acc.: 56.25%] [G loss: 0.752735]\n",
      "epoch:42 step:33075 [D loss: 0.743749, acc.: 44.53%] [G loss: 0.821069]\n",
      "epoch:42 step:33076 [D loss: 0.726602, acc.: 46.09%] [G loss: 0.782599]\n",
      "epoch:42 step:33077 [D loss: 0.636511, acc.: 63.28%] [G loss: 0.852152]\n",
      "epoch:42 step:33078 [D loss: 0.713822, acc.: 46.09%] [G loss: 0.738671]\n",
      "epoch:42 step:33079 [D loss: 0.706629, acc.: 55.47%] [G loss: 0.737599]\n",
      "epoch:42 step:33080 [D loss: 0.680619, acc.: 55.47%] [G loss: 0.791472]\n",
      "epoch:42 step:33081 [D loss: 0.700233, acc.: 53.12%] [G loss: 0.806528]\n",
      "epoch:42 step:33082 [D loss: 0.702019, acc.: 48.44%] [G loss: 0.773848]\n",
      "epoch:42 step:33083 [D loss: 0.687022, acc.: 51.56%] [G loss: 0.737170]\n",
      "epoch:42 step:33084 [D loss: 0.634446, acc.: 64.06%] [G loss: 0.833348]\n",
      "epoch:42 step:33085 [D loss: 0.640654, acc.: 64.84%] [G loss: 0.865984]\n",
      "epoch:42 step:33086 [D loss: 0.637629, acc.: 65.62%] [G loss: 0.790855]\n",
      "epoch:42 step:33087 [D loss: 0.666619, acc.: 64.84%] [G loss: 0.829762]\n",
      "epoch:42 step:33088 [D loss: 0.649312, acc.: 64.06%] [G loss: 0.788446]\n",
      "epoch:42 step:33089 [D loss: 0.663981, acc.: 61.72%] [G loss: 0.763383]\n",
      "epoch:42 step:33090 [D loss: 0.649533, acc.: 63.28%] [G loss: 0.869935]\n",
      "epoch:42 step:33091 [D loss: 0.689587, acc.: 55.47%] [G loss: 0.861604]\n",
      "epoch:42 step:33092 [D loss: 0.633365, acc.: 63.28%] [G loss: 0.796375]\n",
      "epoch:42 step:33093 [D loss: 0.694011, acc.: 54.69%] [G loss: 0.719640]\n",
      "epoch:42 step:33094 [D loss: 0.710904, acc.: 53.91%] [G loss: 0.756204]\n",
      "epoch:42 step:33095 [D loss: 0.655760, acc.: 60.16%] [G loss: 0.803447]\n",
      "epoch:42 step:33096 [D loss: 0.695525, acc.: 52.34%] [G loss: 0.805335]\n",
      "epoch:42 step:33097 [D loss: 0.645640, acc.: 58.59%] [G loss: 0.854326]\n",
      "epoch:42 step:33098 [D loss: 0.704871, acc.: 48.44%] [G loss: 0.819130]\n",
      "epoch:42 step:33099 [D loss: 0.681376, acc.: 57.81%] [G loss: 0.809688]\n",
      "epoch:42 step:33100 [D loss: 0.719626, acc.: 48.44%] [G loss: 0.764925]\n",
      "epoch:42 step:33101 [D loss: 0.673986, acc.: 58.59%] [G loss: 0.803015]\n",
      "epoch:42 step:33102 [D loss: 0.663102, acc.: 58.59%] [G loss: 0.720388]\n",
      "epoch:42 step:33103 [D loss: 0.684304, acc.: 57.03%] [G loss: 0.729283]\n",
      "epoch:42 step:33104 [D loss: 0.663234, acc.: 58.59%] [G loss: 0.737249]\n",
      "epoch:42 step:33105 [D loss: 0.707395, acc.: 46.88%] [G loss: 0.765378]\n",
      "epoch:42 step:33106 [D loss: 0.703329, acc.: 54.69%] [G loss: 0.758238]\n",
      "epoch:42 step:33107 [D loss: 0.688142, acc.: 57.81%] [G loss: 0.769601]\n",
      "epoch:42 step:33108 [D loss: 0.654206, acc.: 59.38%] [G loss: 0.824412]\n",
      "epoch:42 step:33109 [D loss: 0.619502, acc.: 65.62%] [G loss: 0.796233]\n",
      "epoch:42 step:33110 [D loss: 0.638435, acc.: 64.06%] [G loss: 0.818682]\n",
      "epoch:42 step:33111 [D loss: 0.641422, acc.: 64.84%] [G loss: 0.785802]\n",
      "epoch:42 step:33112 [D loss: 0.641260, acc.: 61.72%] [G loss: 0.803059]\n",
      "epoch:42 step:33113 [D loss: 0.674741, acc.: 59.38%] [G loss: 0.776356]\n",
      "epoch:42 step:33114 [D loss: 0.757404, acc.: 42.97%] [G loss: 0.780366]\n",
      "epoch:42 step:33115 [D loss: 0.687423, acc.: 53.91%] [G loss: 0.820288]\n",
      "epoch:42 step:33116 [D loss: 0.669194, acc.: 60.16%] [G loss: 0.781609]\n",
      "epoch:42 step:33117 [D loss: 0.717417, acc.: 52.34%] [G loss: 0.791864]\n",
      "epoch:42 step:33118 [D loss: 0.635633, acc.: 62.50%] [G loss: 0.753302]\n",
      "epoch:42 step:33119 [D loss: 0.763676, acc.: 33.59%] [G loss: 0.784964]\n",
      "epoch:42 step:33120 [D loss: 0.645677, acc.: 64.06%] [G loss: 0.826922]\n",
      "epoch:42 step:33121 [D loss: 0.675446, acc.: 58.59%] [G loss: 0.773393]\n",
      "epoch:42 step:33122 [D loss: 0.698067, acc.: 53.12%] [G loss: 0.709274]\n",
      "epoch:42 step:33123 [D loss: 0.710360, acc.: 52.34%] [G loss: 0.857248]\n",
      "epoch:42 step:33124 [D loss: 0.687923, acc.: 57.81%] [G loss: 0.767177]\n",
      "epoch:42 step:33125 [D loss: 0.662810, acc.: 60.16%] [G loss: 0.833239]\n",
      "epoch:42 step:33126 [D loss: 0.659620, acc.: 62.50%] [G loss: 0.721347]\n",
      "epoch:42 step:33127 [D loss: 0.710045, acc.: 50.00%] [G loss: 0.803073]\n",
      "epoch:42 step:33128 [D loss: 0.705568, acc.: 45.31%] [G loss: 0.821742]\n",
      "epoch:42 step:33129 [D loss: 0.674034, acc.: 53.12%] [G loss: 0.810632]\n",
      "epoch:42 step:33130 [D loss: 0.677012, acc.: 55.47%] [G loss: 0.862415]\n",
      "epoch:42 step:33131 [D loss: 0.689770, acc.: 53.12%] [G loss: 0.771425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33132 [D loss: 0.699660, acc.: 50.78%] [G loss: 0.780064]\n",
      "epoch:42 step:33133 [D loss: 0.659703, acc.: 60.94%] [G loss: 0.782897]\n",
      "epoch:42 step:33134 [D loss: 0.662655, acc.: 55.47%] [G loss: 0.802421]\n",
      "epoch:42 step:33135 [D loss: 0.701795, acc.: 46.88%] [G loss: 0.771702]\n",
      "epoch:42 step:33136 [D loss: 0.687309, acc.: 53.12%] [G loss: 0.747278]\n",
      "epoch:42 step:33137 [D loss: 0.687829, acc.: 57.03%] [G loss: 0.852067]\n",
      "epoch:42 step:33138 [D loss: 0.649092, acc.: 67.97%] [G loss: 0.863899]\n",
      "epoch:42 step:33139 [D loss: 0.674631, acc.: 64.06%] [G loss: 0.831890]\n",
      "epoch:42 step:33140 [D loss: 0.778832, acc.: 32.03%] [G loss: 0.825690]\n",
      "epoch:42 step:33141 [D loss: 0.720562, acc.: 41.41%] [G loss: 0.731407]\n",
      "epoch:42 step:33142 [D loss: 0.616314, acc.: 71.09%] [G loss: 0.806673]\n",
      "epoch:42 step:33143 [D loss: 0.724656, acc.: 47.66%] [G loss: 0.752882]\n",
      "epoch:42 step:33144 [D loss: 0.695936, acc.: 50.78%] [G loss: 0.752533]\n",
      "epoch:42 step:33145 [D loss: 0.681524, acc.: 52.34%] [G loss: 0.778435]\n",
      "epoch:42 step:33146 [D loss: 0.651873, acc.: 57.81%] [G loss: 0.768989]\n",
      "epoch:42 step:33147 [D loss: 0.671977, acc.: 57.03%] [G loss: 0.765882]\n",
      "epoch:42 step:33148 [D loss: 0.755586, acc.: 42.19%] [G loss: 0.711231]\n",
      "epoch:42 step:33149 [D loss: 0.716171, acc.: 45.31%] [G loss: 0.757070]\n",
      "epoch:42 step:33150 [D loss: 0.747953, acc.: 39.84%] [G loss: 0.846611]\n",
      "epoch:42 step:33151 [D loss: 0.659958, acc.: 60.94%] [G loss: 0.927472]\n",
      "epoch:42 step:33152 [D loss: 0.703104, acc.: 52.34%] [G loss: 0.726014]\n",
      "epoch:42 step:33153 [D loss: 0.700260, acc.: 57.81%] [G loss: 0.800403]\n",
      "epoch:42 step:33154 [D loss: 0.675625, acc.: 53.91%] [G loss: 0.839172]\n",
      "epoch:42 step:33155 [D loss: 0.666323, acc.: 56.25%] [G loss: 0.781627]\n",
      "epoch:42 step:33156 [D loss: 0.693865, acc.: 47.66%] [G loss: 0.803260]\n",
      "epoch:42 step:33157 [D loss: 0.668299, acc.: 58.59%] [G loss: 0.873985]\n",
      "epoch:42 step:33158 [D loss: 0.673491, acc.: 56.25%] [G loss: 0.811898]\n",
      "epoch:42 step:33159 [D loss: 0.664637, acc.: 60.94%] [G loss: 0.850427]\n",
      "epoch:42 step:33160 [D loss: 0.719261, acc.: 46.09%] [G loss: 0.745745]\n",
      "epoch:42 step:33161 [D loss: 0.696252, acc.: 56.25%] [G loss: 0.798220]\n",
      "epoch:42 step:33162 [D loss: 0.702400, acc.: 55.47%] [G loss: 0.817293]\n",
      "epoch:42 step:33163 [D loss: 0.702828, acc.: 46.09%] [G loss: 0.843501]\n",
      "epoch:42 step:33164 [D loss: 0.684815, acc.: 53.12%] [G loss: 0.842575]\n",
      "epoch:42 step:33165 [D loss: 0.718929, acc.: 48.44%] [G loss: 0.767354]\n",
      "epoch:42 step:33166 [D loss: 0.689319, acc.: 55.47%] [G loss: 0.810583]\n",
      "epoch:42 step:33167 [D loss: 0.640105, acc.: 63.28%] [G loss: 0.824902]\n",
      "epoch:42 step:33168 [D loss: 0.666110, acc.: 57.81%] [G loss: 0.691000]\n",
      "epoch:42 step:33169 [D loss: 0.682720, acc.: 57.81%] [G loss: 0.765501]\n",
      "epoch:42 step:33170 [D loss: 0.671845, acc.: 57.81%] [G loss: 0.833620]\n",
      "epoch:42 step:33171 [D loss: 0.718476, acc.: 46.09%] [G loss: 0.804705]\n",
      "epoch:42 step:33172 [D loss: 0.711616, acc.: 44.53%] [G loss: 0.843604]\n",
      "epoch:42 step:33173 [D loss: 0.647768, acc.: 65.62%] [G loss: 0.780321]\n",
      "epoch:42 step:33174 [D loss: 0.671451, acc.: 66.41%] [G loss: 0.847550]\n",
      "epoch:42 step:33175 [D loss: 0.693021, acc.: 49.22%] [G loss: 0.875452]\n",
      "epoch:42 step:33176 [D loss: 0.715038, acc.: 51.56%] [G loss: 0.822463]\n",
      "epoch:42 step:33177 [D loss: 0.675121, acc.: 58.59%] [G loss: 0.716295]\n",
      "epoch:42 step:33178 [D loss: 0.658527, acc.: 57.03%] [G loss: 0.800933]\n",
      "epoch:42 step:33179 [D loss: 0.674769, acc.: 54.69%] [G loss: 0.861482]\n",
      "epoch:42 step:33180 [D loss: 0.649122, acc.: 60.16%] [G loss: 0.840077]\n",
      "epoch:42 step:33181 [D loss: 0.593068, acc.: 78.91%] [G loss: 0.804843]\n",
      "epoch:42 step:33182 [D loss: 0.679340, acc.: 63.28%] [G loss: 0.825325]\n",
      "epoch:42 step:33183 [D loss: 0.602645, acc.: 78.12%] [G loss: 0.843048]\n",
      "epoch:42 step:33184 [D loss: 0.640925, acc.: 66.41%] [G loss: 0.816956]\n",
      "epoch:42 step:33185 [D loss: 0.665626, acc.: 58.59%] [G loss: 0.849142]\n",
      "epoch:42 step:33186 [D loss: 0.707268, acc.: 47.66%] [G loss: 0.776502]\n",
      "epoch:42 step:33187 [D loss: 0.733449, acc.: 42.19%] [G loss: 0.768198]\n",
      "epoch:42 step:33188 [D loss: 0.657748, acc.: 64.84%] [G loss: 0.843948]\n",
      "epoch:42 step:33189 [D loss: 0.690349, acc.: 56.25%] [G loss: 0.850136]\n",
      "epoch:42 step:33190 [D loss: 0.709856, acc.: 49.22%] [G loss: 0.814214]\n",
      "epoch:42 step:33191 [D loss: 0.703666, acc.: 54.69%] [G loss: 0.748708]\n",
      "epoch:42 step:33192 [D loss: 0.671693, acc.: 58.59%] [G loss: 0.803054]\n",
      "epoch:42 step:33193 [D loss: 0.674180, acc.: 60.16%] [G loss: 0.834150]\n",
      "epoch:42 step:33194 [D loss: 0.660913, acc.: 58.59%] [G loss: 0.727072]\n",
      "epoch:42 step:33195 [D loss: 0.726678, acc.: 50.00%] [G loss: 0.720695]\n",
      "epoch:42 step:33196 [D loss: 0.691317, acc.: 50.78%] [G loss: 0.686015]\n",
      "epoch:42 step:33197 [D loss: 0.703832, acc.: 48.44%] [G loss: 0.778183]\n",
      "epoch:42 step:33198 [D loss: 0.652556, acc.: 64.84%] [G loss: 0.783113]\n",
      "epoch:42 step:33199 [D loss: 0.719242, acc.: 43.75%] [G loss: 0.734316]\n",
      "epoch:42 step:33200 [D loss: 0.694494, acc.: 53.12%] [G loss: 0.785723]\n",
      "epoch:42 step:33201 [D loss: 0.644882, acc.: 67.97%] [G loss: 0.808461]\n",
      "epoch:42 step:33202 [D loss: 0.653779, acc.: 60.94%] [G loss: 0.773175]\n",
      "epoch:42 step:33203 [D loss: 0.635976, acc.: 63.28%] [G loss: 0.843344]\n",
      "epoch:42 step:33204 [D loss: 0.688242, acc.: 55.47%] [G loss: 0.765270]\n",
      "epoch:42 step:33205 [D loss: 0.679322, acc.: 58.59%] [G loss: 0.836863]\n",
      "epoch:42 step:33206 [D loss: 0.608570, acc.: 71.88%] [G loss: 0.837258]\n",
      "epoch:42 step:33207 [D loss: 0.697247, acc.: 54.69%] [G loss: 0.760152]\n",
      "epoch:42 step:33208 [D loss: 0.700337, acc.: 51.56%] [G loss: 0.790187]\n",
      "epoch:42 step:33209 [D loss: 0.671003, acc.: 59.38%] [G loss: 0.780899]\n",
      "epoch:42 step:33210 [D loss: 0.715668, acc.: 44.53%] [G loss: 0.837453]\n",
      "epoch:42 step:33211 [D loss: 0.647362, acc.: 60.94%] [G loss: 0.952610]\n",
      "epoch:42 step:33212 [D loss: 0.621757, acc.: 67.97%] [G loss: 0.943932]\n",
      "epoch:42 step:33213 [D loss: 0.684337, acc.: 55.47%] [G loss: 0.823009]\n",
      "epoch:42 step:33214 [D loss: 0.722554, acc.: 46.09%] [G loss: 0.653757]\n",
      "epoch:42 step:33215 [D loss: 0.698194, acc.: 53.12%] [G loss: 0.790583]\n",
      "epoch:42 step:33216 [D loss: 0.740973, acc.: 42.19%] [G loss: 0.805773]\n",
      "epoch:42 step:33217 [D loss: 0.598491, acc.: 75.00%] [G loss: 0.828288]\n",
      "epoch:42 step:33218 [D loss: 0.733905, acc.: 46.09%] [G loss: 0.804896]\n",
      "epoch:42 step:33219 [D loss: 0.724378, acc.: 48.44%] [G loss: 0.842651]\n",
      "epoch:42 step:33220 [D loss: 0.714432, acc.: 41.41%] [G loss: 0.811476]\n",
      "epoch:42 step:33221 [D loss: 0.682496, acc.: 55.47%] [G loss: 0.818083]\n",
      "epoch:42 step:33222 [D loss: 0.699183, acc.: 52.34%] [G loss: 0.797669]\n",
      "epoch:42 step:33223 [D loss: 0.705024, acc.: 52.34%] [G loss: 0.707810]\n",
      "epoch:42 step:33224 [D loss: 0.689340, acc.: 58.59%] [G loss: 0.797383]\n",
      "epoch:42 step:33225 [D loss: 0.730883, acc.: 45.31%] [G loss: 0.796427]\n",
      "epoch:42 step:33226 [D loss: 0.723761, acc.: 42.97%] [G loss: 0.749034]\n",
      "epoch:42 step:33227 [D loss: 0.684282, acc.: 54.69%] [G loss: 0.717514]\n",
      "epoch:42 step:33228 [D loss: 0.694417, acc.: 57.03%] [G loss: 0.760091]\n",
      "epoch:42 step:33229 [D loss: 0.697717, acc.: 53.91%] [G loss: 0.771769]\n",
      "epoch:42 step:33230 [D loss: 0.732958, acc.: 51.56%] [G loss: 0.779308]\n",
      "epoch:42 step:33231 [D loss: 0.638123, acc.: 65.62%] [G loss: 0.755663]\n",
      "epoch:42 step:33232 [D loss: 0.666493, acc.: 59.38%] [G loss: 0.783225]\n",
      "epoch:42 step:33233 [D loss: 0.762152, acc.: 39.84%] [G loss: 0.787315]\n",
      "epoch:42 step:33234 [D loss: 0.719793, acc.: 47.66%] [G loss: 0.748082]\n",
      "epoch:42 step:33235 [D loss: 0.687983, acc.: 53.12%] [G loss: 0.795436]\n",
      "epoch:42 step:33236 [D loss: 0.679231, acc.: 56.25%] [G loss: 0.812481]\n",
      "epoch:42 step:33237 [D loss: 0.644245, acc.: 64.06%] [G loss: 0.833262]\n",
      "epoch:42 step:33238 [D loss: 0.728639, acc.: 47.66%] [G loss: 0.754890]\n",
      "epoch:42 step:33239 [D loss: 0.764063, acc.: 37.50%] [G loss: 0.714868]\n",
      "epoch:42 step:33240 [D loss: 0.670471, acc.: 49.22%] [G loss: 0.853261]\n",
      "epoch:42 step:33241 [D loss: 0.722045, acc.: 45.31%] [G loss: 0.818147]\n",
      "epoch:42 step:33242 [D loss: 0.622436, acc.: 68.75%] [G loss: 0.769847]\n",
      "epoch:42 step:33243 [D loss: 0.718650, acc.: 47.66%] [G loss: 0.788456]\n",
      "epoch:42 step:33244 [D loss: 0.712834, acc.: 50.78%] [G loss: 0.897088]\n",
      "epoch:42 step:33245 [D loss: 0.682302, acc.: 55.47%] [G loss: 0.771114]\n",
      "epoch:42 step:33246 [D loss: 0.667663, acc.: 59.38%] [G loss: 0.715788]\n",
      "epoch:42 step:33247 [D loss: 0.706472, acc.: 47.66%] [G loss: 0.813780]\n",
      "epoch:42 step:33248 [D loss: 0.657903, acc.: 61.72%] [G loss: 0.872980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33249 [D loss: 0.693466, acc.: 54.69%] [G loss: 0.817194]\n",
      "epoch:42 step:33250 [D loss: 0.613716, acc.: 75.78%] [G loss: 0.904774]\n",
      "epoch:42 step:33251 [D loss: 0.711541, acc.: 50.78%] [G loss: 0.794797]\n",
      "epoch:42 step:33252 [D loss: 0.731596, acc.: 44.53%] [G loss: 0.782537]\n",
      "epoch:42 step:33253 [D loss: 0.698801, acc.: 50.78%] [G loss: 0.804318]\n",
      "epoch:42 step:33254 [D loss: 0.609133, acc.: 77.34%] [G loss: 0.829803]\n",
      "epoch:42 step:33255 [D loss: 0.760436, acc.: 39.84%] [G loss: 0.791255]\n",
      "epoch:42 step:33256 [D loss: 0.693914, acc.: 53.91%] [G loss: 0.874280]\n",
      "epoch:42 step:33257 [D loss: 0.599932, acc.: 74.22%] [G loss: 0.766466]\n",
      "epoch:42 step:33258 [D loss: 0.684696, acc.: 57.81%] [G loss: 0.787901]\n",
      "epoch:42 step:33259 [D loss: 0.695458, acc.: 54.69%] [G loss: 0.877301]\n",
      "epoch:42 step:33260 [D loss: 0.697834, acc.: 53.91%] [G loss: 0.839716]\n",
      "epoch:42 step:33261 [D loss: 0.719673, acc.: 49.22%] [G loss: 0.812542]\n",
      "epoch:42 step:33262 [D loss: 0.686458, acc.: 57.81%] [G loss: 0.808335]\n",
      "epoch:42 step:33263 [D loss: 0.655249, acc.: 60.16%] [G loss: 0.733199]\n",
      "epoch:42 step:33264 [D loss: 0.680719, acc.: 58.59%] [G loss: 0.817622]\n",
      "epoch:42 step:33265 [D loss: 0.672481, acc.: 61.72%] [G loss: 0.775422]\n",
      "epoch:42 step:33266 [D loss: 0.688671, acc.: 61.72%] [G loss: 0.831692]\n",
      "epoch:42 step:33267 [D loss: 0.661611, acc.: 59.38%] [G loss: 0.866047]\n",
      "epoch:42 step:33268 [D loss: 0.616012, acc.: 72.66%] [G loss: 0.814911]\n",
      "epoch:42 step:33269 [D loss: 0.659474, acc.: 59.38%] [G loss: 0.822554]\n",
      "epoch:42 step:33270 [D loss: 0.672300, acc.: 57.81%] [G loss: 0.819971]\n",
      "epoch:42 step:33271 [D loss: 0.678951, acc.: 57.81%] [G loss: 0.766158]\n",
      "epoch:42 step:33272 [D loss: 0.652626, acc.: 59.38%] [G loss: 0.862558]\n",
      "epoch:42 step:33273 [D loss: 0.703672, acc.: 56.25%] [G loss: 0.740536]\n",
      "epoch:42 step:33274 [D loss: 0.673706, acc.: 61.72%] [G loss: 0.817695]\n",
      "epoch:42 step:33275 [D loss: 0.732819, acc.: 50.00%] [G loss: 0.823470]\n",
      "epoch:42 step:33276 [D loss: 0.653419, acc.: 66.41%] [G loss: 0.795028]\n",
      "epoch:42 step:33277 [D loss: 0.668829, acc.: 54.69%] [G loss: 0.719317]\n",
      "epoch:42 step:33278 [D loss: 0.687854, acc.: 55.47%] [G loss: 0.765951]\n",
      "epoch:42 step:33279 [D loss: 0.653644, acc.: 63.28%] [G loss: 0.876243]\n",
      "epoch:42 step:33280 [D loss: 0.607306, acc.: 79.69%] [G loss: 0.900401]\n",
      "epoch:42 step:33281 [D loss: 0.685296, acc.: 57.03%] [G loss: 0.855644]\n",
      "epoch:42 step:33282 [D loss: 0.635043, acc.: 67.19%] [G loss: 0.776698]\n",
      "epoch:42 step:33283 [D loss: 0.681157, acc.: 59.38%] [G loss: 0.811522]\n",
      "epoch:42 step:33284 [D loss: 0.712721, acc.: 48.44%] [G loss: 0.843380]\n",
      "epoch:42 step:33285 [D loss: 0.638821, acc.: 67.19%] [G loss: 0.791339]\n",
      "epoch:42 step:33286 [D loss: 0.686942, acc.: 57.81%] [G loss: 0.663515]\n",
      "epoch:42 step:33287 [D loss: 0.617942, acc.: 71.09%] [G loss: 0.777892]\n",
      "epoch:42 step:33288 [D loss: 0.632433, acc.: 69.53%] [G loss: 0.869491]\n",
      "epoch:42 step:33289 [D loss: 0.619506, acc.: 64.84%] [G loss: 0.795699]\n",
      "epoch:42 step:33290 [D loss: 0.720454, acc.: 43.75%] [G loss: 0.783678]\n",
      "epoch:42 step:33291 [D loss: 0.662299, acc.: 62.50%] [G loss: 0.836645]\n",
      "epoch:42 step:33292 [D loss: 0.595559, acc.: 75.78%] [G loss: 0.747948]\n",
      "epoch:42 step:33293 [D loss: 0.753107, acc.: 39.06%] [G loss: 0.779919]\n",
      "epoch:42 step:33294 [D loss: 0.686118, acc.: 53.91%] [G loss: 0.805252]\n",
      "epoch:42 step:33295 [D loss: 0.704141, acc.: 48.44%] [G loss: 0.707041]\n",
      "epoch:42 step:33296 [D loss: 0.680519, acc.: 56.25%] [G loss: 0.908251]\n",
      "epoch:42 step:33297 [D loss: 0.657548, acc.: 59.38%] [G loss: 0.812595]\n",
      "epoch:42 step:33298 [D loss: 0.705743, acc.: 48.44%] [G loss: 0.822630]\n",
      "epoch:42 step:33299 [D loss: 0.688275, acc.: 53.12%] [G loss: 0.729670]\n",
      "epoch:42 step:33300 [D loss: 0.682385, acc.: 57.81%] [G loss: 0.825953]\n",
      "epoch:42 step:33301 [D loss: 0.703426, acc.: 49.22%] [G loss: 0.767216]\n",
      "epoch:42 step:33302 [D loss: 0.594657, acc.: 70.31%] [G loss: 0.778573]\n",
      "epoch:42 step:33303 [D loss: 0.659751, acc.: 57.03%] [G loss: 0.864385]\n",
      "epoch:42 step:33304 [D loss: 0.696583, acc.: 53.91%] [G loss: 0.897419]\n",
      "epoch:42 step:33305 [D loss: 0.688779, acc.: 60.94%] [G loss: 0.798686]\n",
      "epoch:42 step:33306 [D loss: 0.654664, acc.: 62.50%] [G loss: 0.897347]\n",
      "epoch:42 step:33307 [D loss: 0.662535, acc.: 64.84%] [G loss: 0.833425]\n",
      "epoch:42 step:33308 [D loss: 0.709081, acc.: 53.12%] [G loss: 0.841671]\n",
      "epoch:42 step:33309 [D loss: 0.715751, acc.: 50.00%] [G loss: 0.783001]\n",
      "epoch:42 step:33310 [D loss: 0.746456, acc.: 43.75%] [G loss: 0.762350]\n",
      "epoch:42 step:33311 [D loss: 0.750464, acc.: 43.75%] [G loss: 0.732705]\n",
      "epoch:42 step:33312 [D loss: 0.665066, acc.: 59.38%] [G loss: 0.772245]\n",
      "epoch:42 step:33313 [D loss: 0.720908, acc.: 50.00%] [G loss: 0.746597]\n",
      "epoch:42 step:33314 [D loss: 0.719062, acc.: 46.88%] [G loss: 0.777063]\n",
      "epoch:42 step:33315 [D loss: 0.728742, acc.: 44.53%] [G loss: 0.747639]\n",
      "epoch:42 step:33316 [D loss: 0.679114, acc.: 59.38%] [G loss: 0.697683]\n",
      "epoch:42 step:33317 [D loss: 0.735413, acc.: 44.53%] [G loss: 0.696196]\n",
      "epoch:42 step:33318 [D loss: 0.661625, acc.: 59.38%] [G loss: 0.714218]\n",
      "epoch:42 step:33319 [D loss: 0.726830, acc.: 51.56%] [G loss: 0.715855]\n",
      "epoch:42 step:33320 [D loss: 0.650042, acc.: 64.84%] [G loss: 0.802243]\n",
      "epoch:42 step:33321 [D loss: 0.655424, acc.: 68.75%] [G loss: 0.873646]\n",
      "epoch:42 step:33322 [D loss: 0.674119, acc.: 55.47%] [G loss: 0.859922]\n",
      "epoch:42 step:33323 [D loss: 0.579568, acc.: 75.78%] [G loss: 0.842926]\n",
      "epoch:42 step:33324 [D loss: 0.660515, acc.: 65.62%] [G loss: 0.843970]\n",
      "epoch:42 step:33325 [D loss: 0.649733, acc.: 67.19%] [G loss: 0.823503]\n",
      "epoch:42 step:33326 [D loss: 0.683370, acc.: 53.91%] [G loss: 0.873536]\n",
      "epoch:42 step:33327 [D loss: 0.647435, acc.: 63.28%] [G loss: 0.862378]\n",
      "epoch:42 step:33328 [D loss: 0.734045, acc.: 56.25%] [G loss: 0.824164]\n",
      "epoch:42 step:33329 [D loss: 0.719546, acc.: 48.44%] [G loss: 0.782576]\n",
      "epoch:42 step:33330 [D loss: 0.674101, acc.: 54.69%] [G loss: 0.772935]\n",
      "epoch:42 step:33331 [D loss: 0.671108, acc.: 58.59%] [G loss: 0.769178]\n",
      "epoch:42 step:33332 [D loss: 0.666246, acc.: 57.81%] [G loss: 0.830068]\n",
      "epoch:42 step:33333 [D loss: 0.651228, acc.: 67.97%] [G loss: 0.930454]\n",
      "epoch:42 step:33334 [D loss: 0.677991, acc.: 55.47%] [G loss: 0.792818]\n",
      "epoch:42 step:33335 [D loss: 0.686427, acc.: 56.25%] [G loss: 0.832476]\n",
      "epoch:42 step:33336 [D loss: 0.725910, acc.: 51.56%] [G loss: 0.784112]\n",
      "epoch:42 step:33337 [D loss: 0.670584, acc.: 56.25%] [G loss: 0.787556]\n",
      "epoch:42 step:33338 [D loss: 0.703685, acc.: 50.78%] [G loss: 0.778159]\n",
      "epoch:42 step:33339 [D loss: 0.688080, acc.: 50.00%] [G loss: 0.766334]\n",
      "epoch:42 step:33340 [D loss: 0.636268, acc.: 65.62%] [G loss: 0.825356]\n",
      "epoch:42 step:33341 [D loss: 0.667131, acc.: 57.03%] [G loss: 0.870130]\n",
      "epoch:42 step:33342 [D loss: 0.693690, acc.: 54.69%] [G loss: 0.801431]\n",
      "epoch:42 step:33343 [D loss: 0.662473, acc.: 63.28%] [G loss: 0.816759]\n",
      "epoch:42 step:33344 [D loss: 0.772527, acc.: 40.62%] [G loss: 0.705281]\n",
      "epoch:42 step:33345 [D loss: 0.734279, acc.: 46.88%] [G loss: 0.723128]\n",
      "epoch:42 step:33346 [D loss: 0.637349, acc.: 68.75%] [G loss: 0.780305]\n",
      "epoch:42 step:33347 [D loss: 0.579187, acc.: 80.47%] [G loss: 0.891258]\n",
      "epoch:42 step:33348 [D loss: 0.798360, acc.: 38.28%] [G loss: 0.773927]\n",
      "epoch:42 step:33349 [D loss: 0.722348, acc.: 50.78%] [G loss: 0.792431]\n",
      "epoch:42 step:33350 [D loss: 0.699631, acc.: 53.91%] [G loss: 0.806294]\n",
      "epoch:42 step:33351 [D loss: 0.662929, acc.: 58.59%] [G loss: 0.757791]\n",
      "epoch:42 step:33352 [D loss: 0.639989, acc.: 65.62%] [G loss: 0.776752]\n",
      "epoch:42 step:33353 [D loss: 0.683051, acc.: 54.69%] [G loss: 0.828897]\n",
      "epoch:42 step:33354 [D loss: 0.762384, acc.: 39.84%] [G loss: 0.779174]\n",
      "epoch:42 step:33355 [D loss: 0.640063, acc.: 73.44%] [G loss: 0.788186]\n",
      "epoch:42 step:33356 [D loss: 0.683139, acc.: 53.12%] [G loss: 0.816835]\n",
      "epoch:42 step:33357 [D loss: 0.698897, acc.: 58.59%] [G loss: 0.825976]\n",
      "epoch:42 step:33358 [D loss: 0.691785, acc.: 55.47%] [G loss: 0.732609]\n",
      "epoch:42 step:33359 [D loss: 0.655220, acc.: 60.94%] [G loss: 0.860044]\n",
      "epoch:42 step:33360 [D loss: 0.677008, acc.: 62.50%] [G loss: 0.776434]\n",
      "epoch:42 step:33361 [D loss: 0.632467, acc.: 74.22%] [G loss: 0.809114]\n",
      "epoch:42 step:33362 [D loss: 0.674524, acc.: 60.16%] [G loss: 0.812703]\n",
      "epoch:42 step:33363 [D loss: 0.726907, acc.: 50.00%] [G loss: 0.827287]\n",
      "epoch:42 step:33364 [D loss: 0.703751, acc.: 51.56%] [G loss: 0.818158]\n",
      "epoch:42 step:33365 [D loss: 0.699521, acc.: 53.91%] [G loss: 0.733953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33366 [D loss: 0.704612, acc.: 46.09%] [G loss: 0.818306]\n",
      "epoch:42 step:33367 [D loss: 0.714004, acc.: 49.22%] [G loss: 0.864392]\n",
      "epoch:42 step:33368 [D loss: 0.702201, acc.: 59.38%] [G loss: 0.788917]\n",
      "epoch:42 step:33369 [D loss: 0.629530, acc.: 67.19%] [G loss: 0.806852]\n",
      "epoch:42 step:33370 [D loss: 0.656368, acc.: 60.94%] [G loss: 0.759797]\n",
      "epoch:42 step:33371 [D loss: 0.704671, acc.: 52.34%] [G loss: 0.766385]\n",
      "epoch:42 step:33372 [D loss: 0.690965, acc.: 52.34%] [G loss: 0.775229]\n",
      "epoch:42 step:33373 [D loss: 0.674671, acc.: 57.03%] [G loss: 0.780160]\n",
      "epoch:42 step:33374 [D loss: 0.704519, acc.: 52.34%] [G loss: 0.780252]\n",
      "epoch:42 step:33375 [D loss: 0.691338, acc.: 57.03%] [G loss: 0.725216]\n",
      "epoch:42 step:33376 [D loss: 0.743913, acc.: 40.62%] [G loss: 0.725969]\n",
      "epoch:42 step:33377 [D loss: 0.718643, acc.: 41.41%] [G loss: 0.813082]\n",
      "epoch:42 step:33378 [D loss: 0.629859, acc.: 69.53%] [G loss: 0.756226]\n",
      "epoch:42 step:33379 [D loss: 0.717468, acc.: 46.88%] [G loss: 0.833188]\n",
      "epoch:42 step:33380 [D loss: 0.677182, acc.: 57.81%] [G loss: 0.776183]\n",
      "epoch:42 step:33381 [D loss: 0.712409, acc.: 48.44%] [G loss: 0.847301]\n",
      "epoch:42 step:33382 [D loss: 0.641544, acc.: 65.62%] [G loss: 0.828786]\n",
      "epoch:42 step:33383 [D loss: 0.656028, acc.: 66.41%] [G loss: 0.681405]\n",
      "epoch:42 step:33384 [D loss: 0.637842, acc.: 61.72%] [G loss: 0.757354]\n",
      "epoch:42 step:33385 [D loss: 0.713501, acc.: 48.44%] [G loss: 0.790083]\n",
      "epoch:42 step:33386 [D loss: 0.703763, acc.: 53.91%] [G loss: 0.787469]\n",
      "epoch:42 step:33387 [D loss: 0.643795, acc.: 57.03%] [G loss: 0.817399]\n",
      "epoch:42 step:33388 [D loss: 0.635338, acc.: 67.19%] [G loss: 0.834734]\n",
      "epoch:42 step:33389 [D loss: 0.628179, acc.: 63.28%] [G loss: 0.763355]\n",
      "epoch:42 step:33390 [D loss: 0.661390, acc.: 56.25%] [G loss: 0.749377]\n",
      "epoch:42 step:33391 [D loss: 0.671706, acc.: 64.06%] [G loss: 0.797436]\n",
      "epoch:42 step:33392 [D loss: 0.711866, acc.: 46.09%] [G loss: 0.801678]\n",
      "epoch:42 step:33393 [D loss: 0.692013, acc.: 55.47%] [G loss: 0.747510]\n",
      "epoch:42 step:33394 [D loss: 0.669283, acc.: 55.47%] [G loss: 0.889920]\n",
      "epoch:42 step:33395 [D loss: 0.674666, acc.: 54.69%] [G loss: 0.814662]\n",
      "epoch:42 step:33396 [D loss: 0.667944, acc.: 60.94%] [G loss: 0.788471]\n",
      "epoch:42 step:33397 [D loss: 0.621583, acc.: 74.22%] [G loss: 0.897004]\n",
      "epoch:42 step:33398 [D loss: 0.657527, acc.: 63.28%] [G loss: 0.776363]\n",
      "epoch:42 step:33399 [D loss: 0.706161, acc.: 51.56%] [G loss: 0.865557]\n",
      "epoch:42 step:33400 [D loss: 0.666168, acc.: 58.59%] [G loss: 0.801380]\n",
      "epoch:42 step:33401 [D loss: 0.733181, acc.: 47.66%] [G loss: 0.841954]\n",
      "epoch:42 step:33402 [D loss: 0.673141, acc.: 53.91%] [G loss: 0.797330]\n",
      "epoch:42 step:33403 [D loss: 0.661953, acc.: 57.03%] [G loss: 0.892939]\n",
      "epoch:42 step:33404 [D loss: 0.695278, acc.: 55.47%] [G loss: 0.747637]\n",
      "epoch:42 step:33405 [D loss: 0.741833, acc.: 39.06%] [G loss: 0.832368]\n",
      "epoch:42 step:33406 [D loss: 0.630241, acc.: 68.75%] [G loss: 0.857074]\n",
      "epoch:42 step:33407 [D loss: 0.695178, acc.: 54.69%] [G loss: 0.771755]\n",
      "epoch:42 step:33408 [D loss: 0.702700, acc.: 50.78%] [G loss: 0.782438]\n",
      "epoch:42 step:33409 [D loss: 0.657608, acc.: 61.72%] [G loss: 0.767718]\n",
      "epoch:42 step:33410 [D loss: 0.645330, acc.: 63.28%] [G loss: 0.730805]\n",
      "epoch:42 step:33411 [D loss: 0.699052, acc.: 53.12%] [G loss: 0.744842]\n",
      "epoch:42 step:33412 [D loss: 0.685087, acc.: 58.59%] [G loss: 0.802979]\n",
      "epoch:42 step:33413 [D loss: 0.699390, acc.: 49.22%] [G loss: 0.878368]\n",
      "epoch:42 step:33414 [D loss: 0.657576, acc.: 60.16%] [G loss: 0.879285]\n",
      "epoch:42 step:33415 [D loss: 0.716034, acc.: 46.09%] [G loss: 0.791245]\n",
      "epoch:42 step:33416 [D loss: 0.702242, acc.: 51.56%] [G loss: 0.792021]\n",
      "epoch:42 step:33417 [D loss: 0.629596, acc.: 68.75%] [G loss: 0.836986]\n",
      "epoch:42 step:33418 [D loss: 0.687078, acc.: 54.69%] [G loss: 0.779564]\n",
      "epoch:42 step:33419 [D loss: 0.691677, acc.: 50.00%] [G loss: 0.834225]\n",
      "epoch:42 step:33420 [D loss: 0.628912, acc.: 68.75%] [G loss: 0.876954]\n",
      "epoch:42 step:33421 [D loss: 0.663686, acc.: 53.91%] [G loss: 0.846117]\n",
      "epoch:42 step:33422 [D loss: 0.657782, acc.: 61.72%] [G loss: 0.852481]\n",
      "epoch:42 step:33423 [D loss: 0.662366, acc.: 55.47%] [G loss: 0.777622]\n",
      "epoch:42 step:33424 [D loss: 0.685238, acc.: 53.12%] [G loss: 0.814401]\n",
      "epoch:42 step:33425 [D loss: 0.715083, acc.: 48.44%] [G loss: 0.736331]\n",
      "epoch:42 step:33426 [D loss: 0.688179, acc.: 61.72%] [G loss: 0.723060]\n",
      "epoch:42 step:33427 [D loss: 0.729072, acc.: 46.88%] [G loss: 0.701516]\n",
      "epoch:42 step:33428 [D loss: 0.727618, acc.: 45.31%] [G loss: 0.709623]\n",
      "epoch:42 step:33429 [D loss: 0.708161, acc.: 45.31%] [G loss: 0.860364]\n",
      "epoch:42 step:33430 [D loss: 0.655119, acc.: 65.62%] [G loss: 0.896099]\n",
      "epoch:42 step:33431 [D loss: 0.704919, acc.: 50.78%] [G loss: 0.749795]\n",
      "epoch:42 step:33432 [D loss: 0.677390, acc.: 54.69%] [G loss: 0.688839]\n",
      "epoch:42 step:33433 [D loss: 0.721864, acc.: 54.69%] [G loss: 0.785075]\n",
      "epoch:42 step:33434 [D loss: 0.675062, acc.: 58.59%] [G loss: 0.785330]\n",
      "epoch:42 step:33435 [D loss: 0.739042, acc.: 40.62%] [G loss: 0.757323]\n",
      "epoch:42 step:33436 [D loss: 0.714183, acc.: 49.22%] [G loss: 0.795752]\n",
      "epoch:42 step:33437 [D loss: 0.683431, acc.: 56.25%] [G loss: 0.755634]\n",
      "epoch:42 step:33438 [D loss: 0.680655, acc.: 53.91%] [G loss: 0.748625]\n",
      "epoch:42 step:33439 [D loss: 0.667884, acc.: 58.59%] [G loss: 0.834049]\n",
      "epoch:42 step:33440 [D loss: 0.690187, acc.: 57.81%] [G loss: 0.780535]\n",
      "epoch:42 step:33441 [D loss: 0.692131, acc.: 52.34%] [G loss: 0.752008]\n",
      "epoch:42 step:33442 [D loss: 0.693797, acc.: 49.22%] [G loss: 0.769966]\n",
      "epoch:42 step:33443 [D loss: 0.627902, acc.: 67.97%] [G loss: 0.760960]\n",
      "epoch:42 step:33444 [D loss: 0.661153, acc.: 60.16%] [G loss: 0.717936]\n",
      "epoch:42 step:33445 [D loss: 0.670099, acc.: 63.28%] [G loss: 0.831230]\n",
      "epoch:42 step:33446 [D loss: 0.672637, acc.: 53.91%] [G loss: 0.778401]\n",
      "epoch:42 step:33447 [D loss: 0.712043, acc.: 47.66%] [G loss: 0.777685]\n",
      "epoch:42 step:33448 [D loss: 0.693804, acc.: 53.91%] [G loss: 0.847770]\n",
      "epoch:42 step:33449 [D loss: 0.692083, acc.: 46.09%] [G loss: 0.817787]\n",
      "epoch:42 step:33450 [D loss: 0.625755, acc.: 71.88%] [G loss: 0.831499]\n",
      "epoch:42 step:33451 [D loss: 0.629257, acc.: 60.94%] [G loss: 0.807404]\n",
      "epoch:42 step:33452 [D loss: 0.669603, acc.: 57.81%] [G loss: 0.769601]\n",
      "epoch:42 step:33453 [D loss: 0.609651, acc.: 69.53%] [G loss: 0.709026]\n",
      "epoch:42 step:33454 [D loss: 0.648582, acc.: 64.84%] [G loss: 0.809007]\n",
      "epoch:42 step:33455 [D loss: 0.635445, acc.: 64.06%] [G loss: 0.820020]\n",
      "epoch:42 step:33456 [D loss: 0.669235, acc.: 58.59%] [G loss: 0.764173]\n",
      "epoch:42 step:33457 [D loss: 0.742038, acc.: 46.09%] [G loss: 0.825281]\n",
      "epoch:42 step:33458 [D loss: 0.665634, acc.: 57.81%] [G loss: 0.762646]\n",
      "epoch:42 step:33459 [D loss: 0.711126, acc.: 50.78%] [G loss: 0.845250]\n",
      "epoch:42 step:33460 [D loss: 0.649299, acc.: 64.06%] [G loss: 0.870969]\n",
      "epoch:42 step:33461 [D loss: 0.664850, acc.: 59.38%] [G loss: 0.799596]\n",
      "epoch:42 step:33462 [D loss: 0.735031, acc.: 42.19%] [G loss: 0.776646]\n",
      "epoch:42 step:33463 [D loss: 0.647717, acc.: 63.28%] [G loss: 0.820170]\n",
      "epoch:42 step:33464 [D loss: 0.692397, acc.: 57.81%] [G loss: 0.808194]\n",
      "epoch:42 step:33465 [D loss: 0.594746, acc.: 75.00%] [G loss: 0.863128]\n",
      "epoch:42 step:33466 [D loss: 0.662989, acc.: 60.94%] [G loss: 0.880451]\n",
      "epoch:42 step:33467 [D loss: 0.724869, acc.: 50.00%] [G loss: 0.763145]\n",
      "epoch:42 step:33468 [D loss: 0.663886, acc.: 63.28%] [G loss: 0.836149]\n",
      "epoch:42 step:33469 [D loss: 0.689122, acc.: 51.56%] [G loss: 0.801791]\n",
      "epoch:42 step:33470 [D loss: 0.705343, acc.: 52.34%] [G loss: 0.884005]\n",
      "epoch:42 step:33471 [D loss: 0.663723, acc.: 57.81%] [G loss: 0.888773]\n",
      "epoch:42 step:33472 [D loss: 0.693999, acc.: 53.91%] [G loss: 0.682439]\n",
      "epoch:42 step:33473 [D loss: 0.706555, acc.: 53.12%] [G loss: 0.855305]\n",
      "epoch:42 step:33474 [D loss: 0.715006, acc.: 48.44%] [G loss: 0.669372]\n",
      "epoch:42 step:33475 [D loss: 0.634466, acc.: 67.19%] [G loss: 0.827814]\n",
      "epoch:42 step:33476 [D loss: 0.691101, acc.: 53.12%] [G loss: 0.840901]\n",
      "epoch:42 step:33477 [D loss: 0.641678, acc.: 66.41%] [G loss: 0.810436]\n",
      "epoch:42 step:33478 [D loss: 0.700894, acc.: 48.44%] [G loss: 0.837087]\n",
      "epoch:42 step:33479 [D loss: 0.644463, acc.: 70.31%] [G loss: 0.799156]\n",
      "epoch:42 step:33480 [D loss: 0.659907, acc.: 60.94%] [G loss: 0.800341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33481 [D loss: 0.641702, acc.: 64.06%] [G loss: 0.848127]\n",
      "epoch:42 step:33482 [D loss: 0.634299, acc.: 69.53%] [G loss: 0.857080]\n",
      "epoch:42 step:33483 [D loss: 0.665864, acc.: 61.72%] [G loss: 0.804133]\n",
      "epoch:42 step:33484 [D loss: 0.723327, acc.: 46.88%] [G loss: 0.742051]\n",
      "epoch:42 step:33485 [D loss: 0.656329, acc.: 64.84%] [G loss: 0.886808]\n",
      "epoch:42 step:33486 [D loss: 0.716544, acc.: 46.88%] [G loss: 0.795190]\n",
      "epoch:42 step:33487 [D loss: 0.730575, acc.: 47.66%] [G loss: 0.793202]\n",
      "epoch:42 step:33488 [D loss: 0.746733, acc.: 46.09%] [G loss: 0.724857]\n",
      "epoch:42 step:33489 [D loss: 0.737165, acc.: 44.53%] [G loss: 0.790119]\n",
      "epoch:42 step:33490 [D loss: 0.686796, acc.: 53.12%] [G loss: 0.820706]\n",
      "epoch:42 step:33491 [D loss: 0.800057, acc.: 31.25%] [G loss: 0.741904]\n",
      "epoch:42 step:33492 [D loss: 0.675318, acc.: 63.28%] [G loss: 0.886630]\n",
      "epoch:42 step:33493 [D loss: 0.618398, acc.: 66.41%] [G loss: 0.869185]\n",
      "epoch:42 step:33494 [D loss: 0.751831, acc.: 50.00%] [G loss: 0.797182]\n",
      "epoch:42 step:33495 [D loss: 0.706073, acc.: 57.03%] [G loss: 0.735158]\n",
      "epoch:42 step:33496 [D loss: 0.673560, acc.: 61.72%] [G loss: 0.772507]\n",
      "epoch:42 step:33497 [D loss: 0.741033, acc.: 47.66%] [G loss: 0.725784]\n",
      "epoch:42 step:33498 [D loss: 0.728306, acc.: 45.31%] [G loss: 0.775843]\n",
      "epoch:42 step:33499 [D loss: 0.696328, acc.: 54.69%] [G loss: 0.722883]\n",
      "epoch:42 step:33500 [D loss: 0.706302, acc.: 45.31%] [G loss: 0.735128]\n",
      "epoch:42 step:33501 [D loss: 0.710068, acc.: 52.34%] [G loss: 0.765323]\n",
      "epoch:42 step:33502 [D loss: 0.593524, acc.: 75.00%] [G loss: 0.781292]\n",
      "epoch:42 step:33503 [D loss: 0.669969, acc.: 60.16%] [G loss: 0.885055]\n",
      "epoch:42 step:33504 [D loss: 0.661385, acc.: 60.94%] [G loss: 0.755364]\n",
      "epoch:42 step:33505 [D loss: 0.719389, acc.: 44.53%] [G loss: 0.766337]\n",
      "epoch:42 step:33506 [D loss: 0.621992, acc.: 71.09%] [G loss: 0.769912]\n",
      "epoch:42 step:33507 [D loss: 0.697023, acc.: 48.44%] [G loss: 0.831037]\n",
      "epoch:42 step:33508 [D loss: 0.649537, acc.: 61.72%] [G loss: 0.796174]\n",
      "epoch:42 step:33509 [D loss: 0.682553, acc.: 56.25%] [G loss: 0.806597]\n",
      "epoch:42 step:33510 [D loss: 0.678921, acc.: 61.72%] [G loss: 0.794995]\n",
      "epoch:42 step:33511 [D loss: 0.645896, acc.: 65.62%] [G loss: 0.789560]\n",
      "epoch:42 step:33512 [D loss: 0.662039, acc.: 60.94%] [G loss: 0.740312]\n",
      "epoch:42 step:33513 [D loss: 0.649234, acc.: 67.97%] [G loss: 0.795946]\n",
      "epoch:42 step:33514 [D loss: 0.700701, acc.: 51.56%] [G loss: 0.731221]\n",
      "epoch:42 step:33515 [D loss: 0.663559, acc.: 58.59%] [G loss: 0.755034]\n",
      "epoch:42 step:33516 [D loss: 0.693709, acc.: 53.12%] [G loss: 0.786471]\n",
      "epoch:42 step:33517 [D loss: 0.650448, acc.: 60.16%] [G loss: 0.892289]\n",
      "epoch:42 step:33518 [D loss: 0.681978, acc.: 57.81%] [G loss: 0.887226]\n",
      "epoch:42 step:33519 [D loss: 0.689449, acc.: 57.03%] [G loss: 0.789832]\n",
      "epoch:42 step:33520 [D loss: 0.632570, acc.: 72.66%] [G loss: 0.909990]\n",
      "epoch:42 step:33521 [D loss: 0.634141, acc.: 65.62%] [G loss: 0.836350]\n",
      "epoch:42 step:33522 [D loss: 0.755076, acc.: 35.94%] [G loss: 0.787425]\n",
      "epoch:42 step:33523 [D loss: 0.704785, acc.: 57.81%] [G loss: 0.807483]\n",
      "epoch:42 step:33524 [D loss: 0.706472, acc.: 48.44%] [G loss: 0.844161]\n",
      "epoch:42 step:33525 [D loss: 0.699738, acc.: 48.44%] [G loss: 0.833143]\n",
      "epoch:42 step:33526 [D loss: 0.688432, acc.: 48.44%] [G loss: 0.812488]\n",
      "epoch:42 step:33527 [D loss: 0.649768, acc.: 63.28%] [G loss: 0.811698]\n",
      "epoch:42 step:33528 [D loss: 0.681900, acc.: 54.69%] [G loss: 0.835021]\n",
      "epoch:42 step:33529 [D loss: 0.676007, acc.: 60.94%] [G loss: 0.792945]\n",
      "epoch:42 step:33530 [D loss: 0.670637, acc.: 54.69%] [G loss: 0.833123]\n",
      "epoch:42 step:33531 [D loss: 0.760678, acc.: 35.94%] [G loss: 0.785457]\n",
      "epoch:42 step:33532 [D loss: 0.651786, acc.: 60.16%] [G loss: 0.810925]\n",
      "epoch:42 step:33533 [D loss: 0.699556, acc.: 54.69%] [G loss: 0.707378]\n",
      "epoch:42 step:33534 [D loss: 0.670244, acc.: 56.25%] [G loss: 0.703509]\n",
      "epoch:42 step:33535 [D loss: 0.695390, acc.: 50.78%] [G loss: 0.819468]\n",
      "epoch:42 step:33536 [D loss: 0.758911, acc.: 33.59%] [G loss: 0.747801]\n",
      "epoch:42 step:33537 [D loss: 0.685111, acc.: 57.81%] [G loss: 0.805087]\n",
      "epoch:42 step:33538 [D loss: 0.694115, acc.: 53.91%] [G loss: 0.813182]\n",
      "epoch:42 step:33539 [D loss: 0.720659, acc.: 50.78%] [G loss: 0.910727]\n",
      "epoch:42 step:33540 [D loss: 0.701801, acc.: 46.88%] [G loss: 0.758449]\n",
      "epoch:42 step:33541 [D loss: 0.741873, acc.: 46.09%] [G loss: 0.813204]\n",
      "epoch:42 step:33542 [D loss: 0.662526, acc.: 55.47%] [G loss: 0.765947]\n",
      "epoch:42 step:33543 [D loss: 0.655724, acc.: 60.16%] [G loss: 0.806348]\n",
      "epoch:42 step:33544 [D loss: 0.729156, acc.: 44.53%] [G loss: 0.773393]\n",
      "epoch:42 step:33545 [D loss: 0.615564, acc.: 66.41%] [G loss: 0.817883]\n",
      "epoch:42 step:33546 [D loss: 0.658659, acc.: 57.81%] [G loss: 0.904352]\n",
      "epoch:42 step:33547 [D loss: 0.657464, acc.: 61.72%] [G loss: 0.835859]\n",
      "epoch:42 step:33548 [D loss: 0.672386, acc.: 62.50%] [G loss: 0.829325]\n",
      "epoch:42 step:33549 [D loss: 0.675245, acc.: 59.38%] [G loss: 0.761598]\n",
      "epoch:42 step:33550 [D loss: 0.677001, acc.: 57.81%] [G loss: 0.827998]\n",
      "epoch:42 step:33551 [D loss: 0.689780, acc.: 57.81%] [G loss: 0.813202]\n",
      "epoch:42 step:33552 [D loss: 0.634545, acc.: 64.06%] [G loss: 0.795148]\n",
      "epoch:42 step:33553 [D loss: 0.680828, acc.: 57.81%] [G loss: 0.744488]\n",
      "epoch:42 step:33554 [D loss: 0.694721, acc.: 57.03%] [G loss: 0.873253]\n",
      "epoch:42 step:33555 [D loss: 0.622206, acc.: 67.19%] [G loss: 0.845339]\n",
      "epoch:42 step:33556 [D loss: 0.707280, acc.: 46.88%] [G loss: 0.829480]\n",
      "epoch:42 step:33557 [D loss: 0.701246, acc.: 53.91%] [G loss: 0.728790]\n",
      "epoch:42 step:33558 [D loss: 0.691013, acc.: 57.81%] [G loss: 0.870041]\n",
      "epoch:42 step:33559 [D loss: 0.724132, acc.: 45.31%] [G loss: 0.789501]\n",
      "epoch:42 step:33560 [D loss: 0.727331, acc.: 49.22%] [G loss: 0.736144]\n",
      "epoch:42 step:33561 [D loss: 0.677125, acc.: 58.59%] [G loss: 0.804024]\n",
      "epoch:42 step:33562 [D loss: 0.649848, acc.: 67.97%] [G loss: 0.751079]\n",
      "epoch:42 step:33563 [D loss: 0.668068, acc.: 60.94%] [G loss: 0.781510]\n",
      "epoch:42 step:33564 [D loss: 0.682383, acc.: 54.69%] [G loss: 0.795349]\n",
      "epoch:42 step:33565 [D loss: 0.678007, acc.: 55.47%] [G loss: 0.762586]\n",
      "epoch:42 step:33566 [D loss: 0.730749, acc.: 43.75%] [G loss: 0.877117]\n",
      "epoch:42 step:33567 [D loss: 0.732299, acc.: 45.31%] [G loss: 0.748955]\n",
      "epoch:42 step:33568 [D loss: 0.702671, acc.: 53.12%] [G loss: 0.789870]\n",
      "epoch:42 step:33569 [D loss: 0.666760, acc.: 62.50%] [G loss: 0.837683]\n",
      "epoch:42 step:33570 [D loss: 0.633988, acc.: 67.19%] [G loss: 0.857655]\n",
      "epoch:42 step:33571 [D loss: 0.659487, acc.: 58.59%] [G loss: 0.777809]\n",
      "epoch:42 step:33572 [D loss: 0.703095, acc.: 47.66%] [G loss: 0.788445]\n",
      "epoch:42 step:33573 [D loss: 0.703412, acc.: 57.03%] [G loss: 0.829064]\n",
      "epoch:42 step:33574 [D loss: 0.626726, acc.: 67.97%] [G loss: 0.854171]\n",
      "epoch:42 step:33575 [D loss: 0.669105, acc.: 61.72%] [G loss: 0.851216]\n",
      "epoch:42 step:33576 [D loss: 0.660439, acc.: 61.72%] [G loss: 0.778719]\n",
      "epoch:42 step:33577 [D loss: 0.690047, acc.: 53.91%] [G loss: 0.823455]\n",
      "epoch:42 step:33578 [D loss: 0.665782, acc.: 61.72%] [G loss: 0.769112]\n",
      "epoch:42 step:33579 [D loss: 0.684526, acc.: 51.56%] [G loss: 0.777346]\n",
      "epoch:42 step:33580 [D loss: 0.688396, acc.: 52.34%] [G loss: 0.773355]\n",
      "epoch:42 step:33581 [D loss: 0.630219, acc.: 67.19%] [G loss: 0.758343]\n",
      "epoch:42 step:33582 [D loss: 0.697780, acc.: 55.47%] [G loss: 0.805730]\n",
      "epoch:42 step:33583 [D loss: 0.664148, acc.: 57.81%] [G loss: 0.765766]\n",
      "epoch:43 step:33584 [D loss: 0.641371, acc.: 67.19%] [G loss: 0.795268]\n",
      "epoch:43 step:33585 [D loss: 0.695896, acc.: 56.25%] [G loss: 0.745750]\n",
      "epoch:43 step:33586 [D loss: 0.722876, acc.: 46.09%] [G loss: 0.791480]\n",
      "epoch:43 step:33587 [D loss: 0.702280, acc.: 47.66%] [G loss: 0.783470]\n",
      "epoch:43 step:33588 [D loss: 0.761825, acc.: 39.06%] [G loss: 0.882026]\n",
      "epoch:43 step:33589 [D loss: 0.677211, acc.: 54.69%] [G loss: 0.801659]\n",
      "epoch:43 step:33590 [D loss: 0.683068, acc.: 60.94%] [G loss: 0.914177]\n",
      "epoch:43 step:33591 [D loss: 0.745561, acc.: 42.19%] [G loss: 0.781779]\n",
      "epoch:43 step:33592 [D loss: 0.764743, acc.: 41.41%] [G loss: 0.808869]\n",
      "epoch:43 step:33593 [D loss: 0.711252, acc.: 47.66%] [G loss: 0.774894]\n",
      "epoch:43 step:33594 [D loss: 0.696144, acc.: 52.34%] [G loss: 0.789029]\n",
      "epoch:43 step:33595 [D loss: 0.640164, acc.: 67.97%] [G loss: 0.878198]\n",
      "epoch:43 step:33596 [D loss: 0.694765, acc.: 60.16%] [G loss: 0.893283]\n",
      "epoch:43 step:33597 [D loss: 0.673763, acc.: 53.91%] [G loss: 0.835862]\n",
      "epoch:43 step:33598 [D loss: 0.643527, acc.: 66.41%] [G loss: 0.898719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33599 [D loss: 0.645763, acc.: 62.50%] [G loss: 0.931620]\n",
      "epoch:43 step:33600 [D loss: 0.670465, acc.: 56.25%] [G loss: 0.816780]\n",
      "epoch:43 step:33601 [D loss: 0.673468, acc.: 62.50%] [G loss: 0.759577]\n",
      "epoch:43 step:33602 [D loss: 0.677314, acc.: 56.25%] [G loss: 0.845223]\n",
      "epoch:43 step:33603 [D loss: 0.633497, acc.: 66.41%] [G loss: 0.809055]\n",
      "epoch:43 step:33604 [D loss: 0.717886, acc.: 45.31%] [G loss: 0.738438]\n",
      "epoch:43 step:33605 [D loss: 0.679102, acc.: 59.38%] [G loss: 0.843914]\n",
      "epoch:43 step:33606 [D loss: 0.743199, acc.: 53.91%] [G loss: 0.779835]\n",
      "epoch:43 step:33607 [D loss: 0.673902, acc.: 60.94%] [G loss: 0.875533]\n",
      "epoch:43 step:33608 [D loss: 0.693973, acc.: 54.69%] [G loss: 0.785366]\n",
      "epoch:43 step:33609 [D loss: 0.713657, acc.: 50.78%] [G loss: 0.653794]\n",
      "epoch:43 step:33610 [D loss: 0.703660, acc.: 47.66%] [G loss: 0.829502]\n",
      "epoch:43 step:33611 [D loss: 0.685216, acc.: 55.47%] [G loss: 0.793309]\n",
      "epoch:43 step:33612 [D loss: 0.707276, acc.: 50.78%] [G loss: 0.752631]\n",
      "epoch:43 step:33613 [D loss: 0.643199, acc.: 61.72%] [G loss: 0.824338]\n",
      "epoch:43 step:33614 [D loss: 0.701663, acc.: 56.25%] [G loss: 0.744320]\n",
      "epoch:43 step:33615 [D loss: 0.688988, acc.: 54.69%] [G loss: 0.773659]\n",
      "epoch:43 step:33616 [D loss: 0.638774, acc.: 70.31%] [G loss: 0.886124]\n",
      "epoch:43 step:33617 [D loss: 0.652283, acc.: 63.28%] [G loss: 0.789857]\n",
      "epoch:43 step:33618 [D loss: 0.712125, acc.: 54.69%] [G loss: 0.772383]\n",
      "epoch:43 step:33619 [D loss: 0.681365, acc.: 50.00%] [G loss: 0.813671]\n",
      "epoch:43 step:33620 [D loss: 0.679852, acc.: 60.16%] [G loss: 0.749404]\n",
      "epoch:43 step:33621 [D loss: 0.625335, acc.: 70.31%] [G loss: 0.827027]\n",
      "epoch:43 step:33622 [D loss: 0.760761, acc.: 41.41%] [G loss: 0.711968]\n",
      "epoch:43 step:33623 [D loss: 0.715531, acc.: 47.66%] [G loss: 0.798495]\n",
      "epoch:43 step:33624 [D loss: 0.685231, acc.: 59.38%] [G loss: 0.676223]\n",
      "epoch:43 step:33625 [D loss: 0.667161, acc.: 58.59%] [G loss: 0.772792]\n",
      "epoch:43 step:33626 [D loss: 0.673944, acc.: 57.81%] [G loss: 0.734671]\n",
      "epoch:43 step:33627 [D loss: 0.766179, acc.: 38.28%] [G loss: 0.793890]\n",
      "epoch:43 step:33628 [D loss: 0.658001, acc.: 63.28%] [G loss: 0.804150]\n",
      "epoch:43 step:33629 [D loss: 0.682095, acc.: 50.00%] [G loss: 0.812660]\n",
      "epoch:43 step:33630 [D loss: 0.663652, acc.: 60.94%] [G loss: 0.676053]\n",
      "epoch:43 step:33631 [D loss: 0.700887, acc.: 49.22%] [G loss: 0.806238]\n",
      "epoch:43 step:33632 [D loss: 0.700115, acc.: 49.22%] [G loss: 0.805480]\n",
      "epoch:43 step:33633 [D loss: 0.672682, acc.: 55.47%] [G loss: 0.798308]\n",
      "epoch:43 step:33634 [D loss: 0.631491, acc.: 70.31%] [G loss: 0.788588]\n",
      "epoch:43 step:33635 [D loss: 0.673846, acc.: 56.25%] [G loss: 0.754751]\n",
      "epoch:43 step:33636 [D loss: 0.688253, acc.: 53.91%] [G loss: 0.858050]\n",
      "epoch:43 step:33637 [D loss: 0.649520, acc.: 64.84%] [G loss: 0.746551]\n",
      "epoch:43 step:33638 [D loss: 0.682966, acc.: 55.47%] [G loss: 0.880185]\n",
      "epoch:43 step:33639 [D loss: 0.721521, acc.: 50.78%] [G loss: 0.854319]\n",
      "epoch:43 step:33640 [D loss: 0.679797, acc.: 59.38%] [G loss: 0.866503]\n",
      "epoch:43 step:33641 [D loss: 0.656480, acc.: 66.41%] [G loss: 0.871427]\n",
      "epoch:43 step:33642 [D loss: 0.640252, acc.: 69.53%] [G loss: 0.792491]\n",
      "epoch:43 step:33643 [D loss: 0.678724, acc.: 55.47%] [G loss: 0.821217]\n",
      "epoch:43 step:33644 [D loss: 0.676899, acc.: 54.69%] [G loss: 0.786904]\n",
      "epoch:43 step:33645 [D loss: 0.656252, acc.: 64.06%] [G loss: 0.785088]\n",
      "epoch:43 step:33646 [D loss: 0.675294, acc.: 60.16%] [G loss: 0.806854]\n",
      "epoch:43 step:33647 [D loss: 0.651500, acc.: 67.97%] [G loss: 0.828327]\n",
      "epoch:43 step:33648 [D loss: 0.737308, acc.: 41.41%] [G loss: 0.761034]\n",
      "epoch:43 step:33649 [D loss: 0.711745, acc.: 45.31%] [G loss: 0.847565]\n",
      "epoch:43 step:33650 [D loss: 0.622631, acc.: 72.66%] [G loss: 0.835820]\n",
      "epoch:43 step:33651 [D loss: 0.706660, acc.: 54.69%] [G loss: 0.793736]\n",
      "epoch:43 step:33652 [D loss: 0.633835, acc.: 65.62%] [G loss: 0.743177]\n",
      "epoch:43 step:33653 [D loss: 0.732942, acc.: 44.53%] [G loss: 0.713415]\n",
      "epoch:43 step:33654 [D loss: 0.690037, acc.: 53.12%] [G loss: 0.782386]\n",
      "epoch:43 step:33655 [D loss: 0.733550, acc.: 45.31%] [G loss: 0.792107]\n",
      "epoch:43 step:33656 [D loss: 0.651434, acc.: 62.50%] [G loss: 0.777294]\n",
      "epoch:43 step:33657 [D loss: 0.647521, acc.: 65.62%] [G loss: 0.873077]\n",
      "epoch:43 step:33658 [D loss: 0.687155, acc.: 58.59%] [G loss: 0.789350]\n",
      "epoch:43 step:33659 [D loss: 0.727200, acc.: 48.44%] [G loss: 0.767298]\n",
      "epoch:43 step:33660 [D loss: 0.674634, acc.: 60.94%] [G loss: 0.820864]\n",
      "epoch:43 step:33661 [D loss: 0.632678, acc.: 67.19%] [G loss: 0.880852]\n",
      "epoch:43 step:33662 [D loss: 0.708093, acc.: 54.69%] [G loss: 0.756942]\n",
      "epoch:43 step:33663 [D loss: 0.670367, acc.: 57.03%] [G loss: 0.851329]\n",
      "epoch:43 step:33664 [D loss: 0.640557, acc.: 58.59%] [G loss: 0.899277]\n",
      "epoch:43 step:33665 [D loss: 0.677088, acc.: 57.81%] [G loss: 0.728053]\n",
      "epoch:43 step:33666 [D loss: 0.631665, acc.: 61.72%] [G loss: 0.784610]\n",
      "epoch:43 step:33667 [D loss: 0.694035, acc.: 51.56%] [G loss: 0.847759]\n",
      "epoch:43 step:33668 [D loss: 0.701556, acc.: 50.78%] [G loss: 0.889584]\n",
      "epoch:43 step:33669 [D loss: 0.638308, acc.: 66.41%] [G loss: 0.808484]\n",
      "epoch:43 step:33670 [D loss: 0.678166, acc.: 59.38%] [G loss: 0.766214]\n",
      "epoch:43 step:33671 [D loss: 0.696852, acc.: 53.91%] [G loss: 0.782028]\n",
      "epoch:43 step:33672 [D loss: 0.586321, acc.: 76.56%] [G loss: 0.747262]\n",
      "epoch:43 step:33673 [D loss: 0.702090, acc.: 52.34%] [G loss: 0.723608]\n",
      "epoch:43 step:33674 [D loss: 0.739296, acc.: 48.44%] [G loss: 0.766261]\n",
      "epoch:43 step:33675 [D loss: 0.681182, acc.: 57.81%] [G loss: 0.705315]\n",
      "epoch:43 step:33676 [D loss: 0.647076, acc.: 64.84%] [G loss: 0.721141]\n",
      "epoch:43 step:33677 [D loss: 0.680438, acc.: 56.25%] [G loss: 0.737959]\n",
      "epoch:43 step:33678 [D loss: 0.699283, acc.: 53.12%] [G loss: 0.699982]\n",
      "epoch:43 step:33679 [D loss: 0.664080, acc.: 63.28%] [G loss: 0.786503]\n",
      "epoch:43 step:33680 [D loss: 0.697106, acc.: 57.03%] [G loss: 0.796855]\n",
      "epoch:43 step:33681 [D loss: 0.729656, acc.: 45.31%] [G loss: 0.867520]\n",
      "epoch:43 step:33682 [D loss: 0.674690, acc.: 54.69%] [G loss: 0.857446]\n",
      "epoch:43 step:33683 [D loss: 0.644274, acc.: 66.41%] [G loss: 0.813539]\n",
      "epoch:43 step:33684 [D loss: 0.707167, acc.: 50.78%] [G loss: 0.817115]\n",
      "epoch:43 step:33685 [D loss: 0.693794, acc.: 57.03%] [G loss: 0.781409]\n",
      "epoch:43 step:33686 [D loss: 0.797541, acc.: 34.38%] [G loss: 0.819013]\n",
      "epoch:43 step:33687 [D loss: 0.701971, acc.: 50.00%] [G loss: 0.850262]\n",
      "epoch:43 step:33688 [D loss: 0.682009, acc.: 59.38%] [G loss: 0.896690]\n",
      "epoch:43 step:33689 [D loss: 0.689355, acc.: 50.78%] [G loss: 0.759076]\n",
      "epoch:43 step:33690 [D loss: 0.653977, acc.: 60.94%] [G loss: 0.811054]\n",
      "epoch:43 step:33691 [D loss: 0.755433, acc.: 44.53%] [G loss: 0.702755]\n",
      "epoch:43 step:33692 [D loss: 0.722515, acc.: 44.53%] [G loss: 0.788244]\n",
      "epoch:43 step:33693 [D loss: 0.711710, acc.: 50.78%] [G loss: 0.847290]\n",
      "epoch:43 step:33694 [D loss: 0.619543, acc.: 66.41%] [G loss: 0.806457]\n",
      "epoch:43 step:33695 [D loss: 0.658087, acc.: 62.50%] [G loss: 0.770563]\n",
      "epoch:43 step:33696 [D loss: 0.659912, acc.: 63.28%] [G loss: 0.822843]\n",
      "epoch:43 step:33697 [D loss: 0.637609, acc.: 67.19%] [G loss: 0.820141]\n",
      "epoch:43 step:33698 [D loss: 0.666609, acc.: 60.94%] [G loss: 0.804166]\n",
      "epoch:43 step:33699 [D loss: 0.667957, acc.: 62.50%] [G loss: 0.802313]\n",
      "epoch:43 step:33700 [D loss: 0.628825, acc.: 67.19%] [G loss: 0.791785]\n",
      "epoch:43 step:33701 [D loss: 0.651853, acc.: 60.94%] [G loss: 0.844177]\n",
      "epoch:43 step:33702 [D loss: 0.706244, acc.: 50.78%] [G loss: 0.767585]\n",
      "epoch:43 step:33703 [D loss: 0.709903, acc.: 50.00%] [G loss: 0.735505]\n",
      "epoch:43 step:33704 [D loss: 0.617744, acc.: 71.88%] [G loss: 0.796225]\n",
      "epoch:43 step:33705 [D loss: 0.710601, acc.: 47.66%] [G loss: 0.804138]\n",
      "epoch:43 step:33706 [D loss: 0.653158, acc.: 60.16%] [G loss: 0.800408]\n",
      "epoch:43 step:33707 [D loss: 0.665036, acc.: 54.69%] [G loss: 0.815972]\n",
      "epoch:43 step:33708 [D loss: 0.751547, acc.: 41.41%] [G loss: 0.856853]\n",
      "epoch:43 step:33709 [D loss: 0.702348, acc.: 51.56%] [G loss: 0.933417]\n",
      "epoch:43 step:33710 [D loss: 0.655298, acc.: 60.16%] [G loss: 0.839602]\n",
      "epoch:43 step:33711 [D loss: 0.637103, acc.: 65.62%] [G loss: 0.808372]\n",
      "epoch:43 step:33712 [D loss: 0.662146, acc.: 60.94%] [G loss: 0.784870]\n",
      "epoch:43 step:33713 [D loss: 0.696658, acc.: 51.56%] [G loss: 0.722731]\n",
      "epoch:43 step:33714 [D loss: 0.660597, acc.: 61.72%] [G loss: 0.737152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33715 [D loss: 0.703584, acc.: 57.03%] [G loss: 0.819189]\n",
      "epoch:43 step:33716 [D loss: 0.593858, acc.: 75.00%] [G loss: 0.822148]\n",
      "epoch:43 step:33717 [D loss: 0.741201, acc.: 40.62%] [G loss: 0.782209]\n",
      "epoch:43 step:33718 [D loss: 0.748877, acc.: 44.53%] [G loss: 0.803433]\n",
      "epoch:43 step:33719 [D loss: 0.715325, acc.: 46.88%] [G loss: 0.890822]\n",
      "epoch:43 step:33720 [D loss: 0.740630, acc.: 43.75%] [G loss: 0.824635]\n",
      "epoch:43 step:33721 [D loss: 0.679584, acc.: 65.62%] [G loss: 0.799045]\n",
      "epoch:43 step:33722 [D loss: 0.591653, acc.: 76.56%] [G loss: 0.819527]\n",
      "epoch:43 step:33723 [D loss: 0.732518, acc.: 42.19%] [G loss: 0.799379]\n",
      "epoch:43 step:33724 [D loss: 0.623595, acc.: 68.75%] [G loss: 0.811519]\n",
      "epoch:43 step:33725 [D loss: 0.739861, acc.: 42.97%] [G loss: 0.769672]\n",
      "epoch:43 step:33726 [D loss: 0.651889, acc.: 59.38%] [G loss: 0.839481]\n",
      "epoch:43 step:33727 [D loss: 0.673453, acc.: 57.81%] [G loss: 0.745957]\n",
      "epoch:43 step:33728 [D loss: 0.706595, acc.: 55.47%] [G loss: 0.737127]\n",
      "epoch:43 step:33729 [D loss: 0.629722, acc.: 67.19%] [G loss: 0.752961]\n",
      "epoch:43 step:33730 [D loss: 0.652132, acc.: 65.62%] [G loss: 0.744034]\n",
      "epoch:43 step:33731 [D loss: 0.698065, acc.: 50.78%] [G loss: 0.710364]\n",
      "epoch:43 step:33732 [D loss: 0.670084, acc.: 56.25%] [G loss: 0.873038]\n",
      "epoch:43 step:33733 [D loss: 0.728175, acc.: 41.41%] [G loss: 0.844582]\n",
      "epoch:43 step:33734 [D loss: 0.662990, acc.: 60.94%] [G loss: 0.852811]\n",
      "epoch:43 step:33735 [D loss: 0.716576, acc.: 47.66%] [G loss: 0.744216]\n",
      "epoch:43 step:33736 [D loss: 0.620972, acc.: 73.44%] [G loss: 0.903085]\n",
      "epoch:43 step:33737 [D loss: 0.585961, acc.: 75.00%] [G loss: 0.856254]\n",
      "epoch:43 step:33738 [D loss: 0.646309, acc.: 65.62%] [G loss: 0.825827]\n",
      "epoch:43 step:33739 [D loss: 0.677781, acc.: 52.34%] [G loss: 0.838793]\n",
      "epoch:43 step:33740 [D loss: 0.676790, acc.: 57.81%] [G loss: 0.779129]\n",
      "epoch:43 step:33741 [D loss: 0.686120, acc.: 59.38%] [G loss: 0.816524]\n",
      "epoch:43 step:33742 [D loss: 0.626114, acc.: 67.97%] [G loss: 0.768798]\n",
      "epoch:43 step:33743 [D loss: 0.645200, acc.: 67.97%] [G loss: 0.725241]\n",
      "epoch:43 step:33744 [D loss: 0.663532, acc.: 64.06%] [G loss: 0.808133]\n",
      "epoch:43 step:33745 [D loss: 0.612456, acc.: 66.41%] [G loss: 0.742753]\n",
      "epoch:43 step:33746 [D loss: 0.682922, acc.: 57.81%] [G loss: 0.808236]\n",
      "epoch:43 step:33747 [D loss: 0.696106, acc.: 56.25%] [G loss: 0.831515]\n",
      "epoch:43 step:33748 [D loss: 0.727982, acc.: 43.75%] [G loss: 0.809945]\n",
      "epoch:43 step:33749 [D loss: 0.673917, acc.: 58.59%] [G loss: 0.862043]\n",
      "epoch:43 step:33750 [D loss: 0.635077, acc.: 71.88%] [G loss: 0.844523]\n",
      "epoch:43 step:33751 [D loss: 0.702242, acc.: 53.12%] [G loss: 0.842140]\n",
      "epoch:43 step:33752 [D loss: 0.687090, acc.: 57.03%] [G loss: 0.904682]\n",
      "epoch:43 step:33753 [D loss: 0.618715, acc.: 72.66%] [G loss: 0.779293]\n",
      "epoch:43 step:33754 [D loss: 0.650801, acc.: 60.16%] [G loss: 0.802375]\n",
      "epoch:43 step:33755 [D loss: 0.680041, acc.: 56.25%] [G loss: 0.807792]\n",
      "epoch:43 step:33756 [D loss: 0.689189, acc.: 54.69%] [G loss: 0.831940]\n",
      "epoch:43 step:33757 [D loss: 0.727897, acc.: 43.75%] [G loss: 0.791797]\n",
      "epoch:43 step:33758 [D loss: 0.646581, acc.: 60.94%] [G loss: 0.802188]\n",
      "epoch:43 step:33759 [D loss: 0.697172, acc.: 46.09%] [G loss: 0.918617]\n",
      "epoch:43 step:33760 [D loss: 0.637526, acc.: 61.72%] [G loss: 0.800346]\n",
      "epoch:43 step:33761 [D loss: 0.743216, acc.: 38.28%] [G loss: 0.854686]\n",
      "epoch:43 step:33762 [D loss: 0.712127, acc.: 53.12%] [G loss: 0.765980]\n",
      "epoch:43 step:33763 [D loss: 0.691063, acc.: 53.12%] [G loss: 0.834883]\n",
      "epoch:43 step:33764 [D loss: 0.648915, acc.: 65.62%] [G loss: 0.853417]\n",
      "epoch:43 step:33765 [D loss: 0.681530, acc.: 50.78%] [G loss: 0.830786]\n",
      "epoch:43 step:33766 [D loss: 0.701655, acc.: 48.44%] [G loss: 0.822518]\n",
      "epoch:43 step:33767 [D loss: 0.729962, acc.: 49.22%] [G loss: 0.801201]\n",
      "epoch:43 step:33768 [D loss: 0.665860, acc.: 65.62%] [G loss: 0.952690]\n",
      "epoch:43 step:33769 [D loss: 0.697142, acc.: 52.34%] [G loss: 0.883818]\n",
      "epoch:43 step:33770 [D loss: 0.726833, acc.: 46.88%] [G loss: 0.731108]\n",
      "epoch:43 step:33771 [D loss: 0.690609, acc.: 55.47%] [G loss: 0.781195]\n",
      "epoch:43 step:33772 [D loss: 0.681258, acc.: 56.25%] [G loss: 0.848574]\n",
      "epoch:43 step:33773 [D loss: 0.710654, acc.: 51.56%] [G loss: 0.815633]\n",
      "epoch:43 step:33774 [D loss: 0.713526, acc.: 50.78%] [G loss: 0.809190]\n",
      "epoch:43 step:33775 [D loss: 0.639112, acc.: 66.41%] [G loss: 0.770391]\n",
      "epoch:43 step:33776 [D loss: 0.651106, acc.: 62.50%] [G loss: 0.789131]\n",
      "epoch:43 step:33777 [D loss: 0.760790, acc.: 40.62%] [G loss: 0.793273]\n",
      "epoch:43 step:33778 [D loss: 0.706457, acc.: 52.34%] [G loss: 0.744978]\n",
      "epoch:43 step:33779 [D loss: 0.681223, acc.: 57.81%] [G loss: 0.868608]\n",
      "epoch:43 step:33780 [D loss: 0.686514, acc.: 55.47%] [G loss: 0.889773]\n",
      "epoch:43 step:33781 [D loss: 0.604921, acc.: 75.78%] [G loss: 0.911340]\n",
      "epoch:43 step:33782 [D loss: 0.635961, acc.: 64.84%] [G loss: 0.814798]\n",
      "epoch:43 step:33783 [D loss: 0.661739, acc.: 60.16%] [G loss: 0.825032]\n",
      "epoch:43 step:33784 [D loss: 0.664418, acc.: 60.94%] [G loss: 0.809854]\n",
      "epoch:43 step:33785 [D loss: 0.703563, acc.: 47.66%] [G loss: 0.815962]\n",
      "epoch:43 step:33786 [D loss: 0.681155, acc.: 59.38%] [G loss: 0.828904]\n",
      "epoch:43 step:33787 [D loss: 0.708453, acc.: 53.91%] [G loss: 0.834830]\n",
      "epoch:43 step:33788 [D loss: 0.756175, acc.: 40.62%] [G loss: 0.760424]\n",
      "epoch:43 step:33789 [D loss: 0.662389, acc.: 64.84%] [G loss: 0.828719]\n",
      "epoch:43 step:33790 [D loss: 0.606385, acc.: 75.00%] [G loss: 0.842308]\n",
      "epoch:43 step:33791 [D loss: 0.707919, acc.: 52.34%] [G loss: 0.771205]\n",
      "epoch:43 step:33792 [D loss: 0.687099, acc.: 54.69%] [G loss: 0.868171]\n",
      "epoch:43 step:33793 [D loss: 0.685306, acc.: 54.69%] [G loss: 0.789886]\n",
      "epoch:43 step:33794 [D loss: 0.692797, acc.: 55.47%] [G loss: 0.794916]\n",
      "epoch:43 step:33795 [D loss: 0.727346, acc.: 45.31%] [G loss: 0.709981]\n",
      "epoch:43 step:33796 [D loss: 0.737078, acc.: 42.97%] [G loss: 0.776830]\n",
      "epoch:43 step:33797 [D loss: 0.684862, acc.: 54.69%] [G loss: 0.822344]\n",
      "epoch:43 step:33798 [D loss: 0.699379, acc.: 56.25%] [G loss: 0.830342]\n",
      "epoch:43 step:33799 [D loss: 0.727439, acc.: 44.53%] [G loss: 0.759404]\n",
      "epoch:43 step:33800 [D loss: 0.663288, acc.: 57.03%] [G loss: 0.802487]\n",
      "epoch:43 step:33801 [D loss: 0.672201, acc.: 59.38%] [G loss: 0.842554]\n",
      "epoch:43 step:33802 [D loss: 0.652446, acc.: 64.84%] [G loss: 0.804284]\n",
      "epoch:43 step:33803 [D loss: 0.733271, acc.: 42.97%] [G loss: 0.762377]\n",
      "epoch:43 step:33804 [D loss: 0.708906, acc.: 48.44%] [G loss: 0.729080]\n",
      "epoch:43 step:33805 [D loss: 0.661211, acc.: 57.03%] [G loss: 0.815280]\n",
      "epoch:43 step:33806 [D loss: 0.704309, acc.: 51.56%] [G loss: 0.720035]\n",
      "epoch:43 step:33807 [D loss: 0.625553, acc.: 66.41%] [G loss: 0.802127]\n",
      "epoch:43 step:33808 [D loss: 0.724592, acc.: 41.41%] [G loss: 0.714806]\n",
      "epoch:43 step:33809 [D loss: 0.663839, acc.: 60.16%] [G loss: 0.686417]\n",
      "epoch:43 step:33810 [D loss: 0.663619, acc.: 58.59%] [G loss: 0.844985]\n",
      "epoch:43 step:33811 [D loss: 0.708080, acc.: 53.12%] [G loss: 0.751373]\n",
      "epoch:43 step:33812 [D loss: 0.697039, acc.: 53.91%] [G loss: 0.796685]\n",
      "epoch:43 step:33813 [D loss: 0.794607, acc.: 29.69%] [G loss: 0.705184]\n",
      "epoch:43 step:33814 [D loss: 0.662383, acc.: 61.72%] [G loss: 0.768041]\n",
      "epoch:43 step:33815 [D loss: 0.688896, acc.: 53.91%] [G loss: 0.784012]\n",
      "epoch:43 step:33816 [D loss: 0.657886, acc.: 60.16%] [G loss: 0.695768]\n",
      "epoch:43 step:33817 [D loss: 0.652469, acc.: 60.16%] [G loss: 0.817129]\n",
      "epoch:43 step:33818 [D loss: 0.710527, acc.: 46.88%] [G loss: 0.723632]\n",
      "epoch:43 step:33819 [D loss: 0.678418, acc.: 61.72%] [G loss: 0.752142]\n",
      "epoch:43 step:33820 [D loss: 0.710535, acc.: 49.22%] [G loss: 0.768146]\n",
      "epoch:43 step:33821 [D loss: 0.711465, acc.: 49.22%] [G loss: 0.764777]\n",
      "epoch:43 step:33822 [D loss: 0.693718, acc.: 54.69%] [G loss: 0.744974]\n",
      "epoch:43 step:33823 [D loss: 0.725371, acc.: 48.44%] [G loss: 0.755792]\n",
      "epoch:43 step:33824 [D loss: 0.693911, acc.: 53.12%] [G loss: 0.813609]\n",
      "epoch:43 step:33825 [D loss: 0.675878, acc.: 59.38%] [G loss: 0.832766]\n",
      "epoch:43 step:33826 [D loss: 0.716826, acc.: 53.12%] [G loss: 0.750562]\n",
      "epoch:43 step:33827 [D loss: 0.632952, acc.: 67.97%] [G loss: 0.639872]\n",
      "epoch:43 step:33828 [D loss: 0.723003, acc.: 46.09%] [G loss: 0.733330]\n",
      "epoch:43 step:33829 [D loss: 0.672725, acc.: 59.38%] [G loss: 0.648597]\n",
      "epoch:43 step:33830 [D loss: 0.639206, acc.: 67.19%] [G loss: 0.773500]\n",
      "epoch:43 step:33831 [D loss: 0.657413, acc.: 57.81%] [G loss: 0.753840]\n",
      "epoch:43 step:33832 [D loss: 0.616976, acc.: 76.56%] [G loss: 0.785094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33833 [D loss: 0.677667, acc.: 57.81%] [G loss: 0.798991]\n",
      "epoch:43 step:33834 [D loss: 0.702460, acc.: 48.44%] [G loss: 0.805870]\n",
      "epoch:43 step:33835 [D loss: 0.715717, acc.: 53.91%] [G loss: 0.791335]\n",
      "epoch:43 step:33836 [D loss: 0.700273, acc.: 53.91%] [G loss: 0.736297]\n",
      "epoch:43 step:33837 [D loss: 0.691212, acc.: 49.22%] [G loss: 0.811569]\n",
      "epoch:43 step:33838 [D loss: 0.760554, acc.: 34.38%] [G loss: 0.702107]\n",
      "epoch:43 step:33839 [D loss: 0.702504, acc.: 51.56%] [G loss: 0.732439]\n",
      "epoch:43 step:33840 [D loss: 0.757091, acc.: 39.06%] [G loss: 0.852356]\n",
      "epoch:43 step:33841 [D loss: 0.678845, acc.: 54.69%] [G loss: 0.827111]\n",
      "epoch:43 step:33842 [D loss: 0.723661, acc.: 48.44%] [G loss: 0.798997]\n",
      "epoch:43 step:33843 [D loss: 0.668575, acc.: 59.38%] [G loss: 0.754999]\n",
      "epoch:43 step:33844 [D loss: 0.637924, acc.: 72.66%] [G loss: 0.831806]\n",
      "epoch:43 step:33845 [D loss: 0.671570, acc.: 53.91%] [G loss: 0.934485]\n",
      "epoch:43 step:33846 [D loss: 0.691773, acc.: 52.34%] [G loss: 0.854788]\n",
      "epoch:43 step:33847 [D loss: 0.725627, acc.: 39.84%] [G loss: 0.891754]\n",
      "epoch:43 step:33848 [D loss: 0.710278, acc.: 49.22%] [G loss: 0.837506]\n",
      "epoch:43 step:33849 [D loss: 0.691326, acc.: 51.56%] [G loss: 0.790173]\n",
      "epoch:43 step:33850 [D loss: 0.764339, acc.: 35.94%] [G loss: 0.780666]\n",
      "epoch:43 step:33851 [D loss: 0.665431, acc.: 57.81%] [G loss: 0.824243]\n",
      "epoch:43 step:33852 [D loss: 0.619385, acc.: 75.00%] [G loss: 0.879402]\n",
      "epoch:43 step:33853 [D loss: 0.705375, acc.: 56.25%] [G loss: 0.857738]\n",
      "epoch:43 step:33854 [D loss: 0.655063, acc.: 67.97%] [G loss: 0.868629]\n",
      "epoch:43 step:33855 [D loss: 0.674326, acc.: 59.38%] [G loss: 0.836200]\n",
      "epoch:43 step:33856 [D loss: 0.755069, acc.: 39.84%] [G loss: 0.801342]\n",
      "epoch:43 step:33857 [D loss: 0.646135, acc.: 62.50%] [G loss: 0.869719]\n",
      "epoch:43 step:33858 [D loss: 0.656463, acc.: 60.16%] [G loss: 0.817592]\n",
      "epoch:43 step:33859 [D loss: 0.627874, acc.: 71.88%] [G loss: 0.827727]\n",
      "epoch:43 step:33860 [D loss: 0.788149, acc.: 37.50%] [G loss: 0.843875]\n",
      "epoch:43 step:33861 [D loss: 0.660793, acc.: 58.59%] [G loss: 0.736123]\n",
      "epoch:43 step:33862 [D loss: 0.694831, acc.: 53.12%] [G loss: 0.690962]\n",
      "epoch:43 step:33863 [D loss: 0.663267, acc.: 62.50%] [G loss: 0.777447]\n",
      "epoch:43 step:33864 [D loss: 0.712949, acc.: 47.66%] [G loss: 0.801770]\n",
      "epoch:43 step:33865 [D loss: 0.648848, acc.: 67.19%] [G loss: 0.782173]\n",
      "epoch:43 step:33866 [D loss: 0.595271, acc.: 77.34%] [G loss: 0.853079]\n",
      "epoch:43 step:33867 [D loss: 0.686842, acc.: 57.03%] [G loss: 0.815211]\n",
      "epoch:43 step:33868 [D loss: 0.701875, acc.: 53.91%] [G loss: 0.794395]\n",
      "epoch:43 step:33869 [D loss: 0.723367, acc.: 37.50%] [G loss: 0.824928]\n",
      "epoch:43 step:33870 [D loss: 0.669481, acc.: 58.59%] [G loss: 0.851660]\n",
      "epoch:43 step:33871 [D loss: 0.712718, acc.: 54.69%] [G loss: 0.824515]\n",
      "epoch:43 step:33872 [D loss: 0.679799, acc.: 54.69%] [G loss: 0.802580]\n",
      "epoch:43 step:33873 [D loss: 0.641226, acc.: 66.41%] [G loss: 0.789861]\n",
      "epoch:43 step:33874 [D loss: 0.774602, acc.: 34.38%] [G loss: 0.782438]\n",
      "epoch:43 step:33875 [D loss: 0.717872, acc.: 57.03%] [G loss: 0.811276]\n",
      "epoch:43 step:33876 [D loss: 0.707248, acc.: 50.00%] [G loss: 0.788977]\n",
      "epoch:43 step:33877 [D loss: 0.635967, acc.: 71.88%] [G loss: 0.774440]\n",
      "epoch:43 step:33878 [D loss: 0.612400, acc.: 72.66%] [G loss: 0.850864]\n",
      "epoch:43 step:33879 [D loss: 0.719001, acc.: 50.00%] [G loss: 0.779021]\n",
      "epoch:43 step:33880 [D loss: 0.660966, acc.: 62.50%] [G loss: 0.816741]\n",
      "epoch:43 step:33881 [D loss: 0.719837, acc.: 50.78%] [G loss: 0.831976]\n",
      "epoch:43 step:33882 [D loss: 0.702294, acc.: 53.12%] [G loss: 0.873924]\n",
      "epoch:43 step:33883 [D loss: 0.733361, acc.: 46.88%] [G loss: 0.879896]\n",
      "epoch:43 step:33884 [D loss: 0.683653, acc.: 57.03%] [G loss: 0.767774]\n",
      "epoch:43 step:33885 [D loss: 0.727710, acc.: 46.88%] [G loss: 0.705629]\n",
      "epoch:43 step:33886 [D loss: 0.623589, acc.: 72.66%] [G loss: 0.814411]\n",
      "epoch:43 step:33887 [D loss: 0.689612, acc.: 60.94%] [G loss: 0.742369]\n",
      "epoch:43 step:33888 [D loss: 0.691709, acc.: 56.25%] [G loss: 0.851997]\n",
      "epoch:43 step:33889 [D loss: 0.731420, acc.: 49.22%] [G loss: 0.759075]\n",
      "epoch:43 step:33890 [D loss: 0.631210, acc.: 63.28%] [G loss: 0.832524]\n",
      "epoch:43 step:33891 [D loss: 0.689081, acc.: 53.91%] [G loss: 0.841928]\n",
      "epoch:43 step:33892 [D loss: 0.667466, acc.: 63.28%] [G loss: 0.783336]\n",
      "epoch:43 step:33893 [D loss: 0.639480, acc.: 68.75%] [G loss: 0.712112]\n",
      "epoch:43 step:33894 [D loss: 0.707694, acc.: 53.12%] [G loss: 0.850514]\n",
      "epoch:43 step:33895 [D loss: 0.707892, acc.: 50.00%] [G loss: 0.743061]\n",
      "epoch:43 step:33896 [D loss: 0.687632, acc.: 51.56%] [G loss: 0.841062]\n",
      "epoch:43 step:33897 [D loss: 0.721686, acc.: 46.88%] [G loss: 0.840915]\n",
      "epoch:43 step:33898 [D loss: 0.738762, acc.: 44.53%] [G loss: 0.781988]\n",
      "epoch:43 step:33899 [D loss: 0.663549, acc.: 60.16%] [G loss: 0.739261]\n",
      "epoch:43 step:33900 [D loss: 0.634818, acc.: 67.97%] [G loss: 0.819876]\n",
      "epoch:43 step:33901 [D loss: 0.726497, acc.: 42.19%] [G loss: 0.771989]\n",
      "epoch:43 step:33902 [D loss: 0.738892, acc.: 42.19%] [G loss: 0.762376]\n",
      "epoch:43 step:33903 [D loss: 0.706793, acc.: 47.66%] [G loss: 0.772431]\n",
      "epoch:43 step:33904 [D loss: 0.671708, acc.: 58.59%] [G loss: 0.779143]\n",
      "epoch:43 step:33905 [D loss: 0.656314, acc.: 60.94%] [G loss: 0.846174]\n",
      "epoch:43 step:33906 [D loss: 0.706964, acc.: 53.12%] [G loss: 0.751905]\n",
      "epoch:43 step:33907 [D loss: 0.618591, acc.: 67.97%] [G loss: 0.764720]\n",
      "epoch:43 step:33908 [D loss: 0.684691, acc.: 57.81%] [G loss: 0.752467]\n",
      "epoch:43 step:33909 [D loss: 0.694980, acc.: 54.69%] [G loss: 0.770444]\n",
      "epoch:43 step:33910 [D loss: 0.716438, acc.: 55.47%] [G loss: 0.843308]\n",
      "epoch:43 step:33911 [D loss: 0.660436, acc.: 60.94%] [G loss: 0.864966]\n",
      "epoch:43 step:33912 [D loss: 0.719419, acc.: 48.44%] [G loss: 0.770223]\n",
      "epoch:43 step:33913 [D loss: 0.673392, acc.: 59.38%] [G loss: 0.788322]\n",
      "epoch:43 step:33914 [D loss: 0.788877, acc.: 32.03%] [G loss: 0.785995]\n",
      "epoch:43 step:33915 [D loss: 0.682555, acc.: 57.03%] [G loss: 0.810681]\n",
      "epoch:43 step:33916 [D loss: 0.630193, acc.: 73.44%] [G loss: 0.759487]\n",
      "epoch:43 step:33917 [D loss: 0.690930, acc.: 57.03%] [G loss: 0.780461]\n",
      "epoch:43 step:33918 [D loss: 0.724448, acc.: 46.88%] [G loss: 0.709625]\n",
      "epoch:43 step:33919 [D loss: 0.676084, acc.: 60.94%] [G loss: 0.727052]\n",
      "epoch:43 step:33920 [D loss: 0.754090, acc.: 36.72%] [G loss: 0.770489]\n",
      "epoch:43 step:33921 [D loss: 0.746416, acc.: 44.53%] [G loss: 0.813496]\n",
      "epoch:43 step:33922 [D loss: 0.676708, acc.: 56.25%] [G loss: 0.944120]\n",
      "epoch:43 step:33923 [D loss: 0.678461, acc.: 56.25%] [G loss: 0.857231]\n",
      "epoch:43 step:33924 [D loss: 0.702451, acc.: 53.91%] [G loss: 0.821930]\n",
      "epoch:43 step:33925 [D loss: 0.633976, acc.: 72.66%] [G loss: 0.818635]\n",
      "epoch:43 step:33926 [D loss: 0.657973, acc.: 65.62%] [G loss: 0.793326]\n",
      "epoch:43 step:33927 [D loss: 0.668806, acc.: 63.28%] [G loss: 0.823882]\n",
      "epoch:43 step:33928 [D loss: 0.641244, acc.: 69.53%] [G loss: 0.886381]\n",
      "epoch:43 step:33929 [D loss: 0.670693, acc.: 58.59%] [G loss: 0.821029]\n",
      "epoch:43 step:33930 [D loss: 0.673711, acc.: 58.59%] [G loss: 0.872183]\n",
      "epoch:43 step:33931 [D loss: 0.729912, acc.: 41.41%] [G loss: 0.806482]\n",
      "epoch:43 step:33932 [D loss: 0.642616, acc.: 65.62%] [G loss: 0.876201]\n",
      "epoch:43 step:33933 [D loss: 0.707410, acc.: 53.12%] [G loss: 0.782011]\n",
      "epoch:43 step:33934 [D loss: 0.694233, acc.: 53.12%] [G loss: 0.854328]\n",
      "epoch:43 step:33935 [D loss: 0.674146, acc.: 54.69%] [G loss: 0.812124]\n",
      "epoch:43 step:33936 [D loss: 0.672383, acc.: 56.25%] [G loss: 0.809791]\n",
      "epoch:43 step:33937 [D loss: 0.634629, acc.: 67.19%] [G loss: 0.839916]\n",
      "epoch:43 step:33938 [D loss: 0.596618, acc.: 77.34%] [G loss: 0.750903]\n",
      "epoch:43 step:33939 [D loss: 0.647406, acc.: 58.59%] [G loss: 0.754665]\n",
      "epoch:43 step:33940 [D loss: 0.691172, acc.: 56.25%] [G loss: 0.935383]\n",
      "epoch:43 step:33941 [D loss: 0.670807, acc.: 57.81%] [G loss: 0.859095]\n",
      "epoch:43 step:33942 [D loss: 0.712500, acc.: 46.09%] [G loss: 0.786294]\n",
      "epoch:43 step:33943 [D loss: 0.700282, acc.: 50.78%] [G loss: 0.829409]\n",
      "epoch:43 step:33944 [D loss: 0.720102, acc.: 53.12%] [G loss: 0.851995]\n",
      "epoch:43 step:33945 [D loss: 0.630611, acc.: 71.09%] [G loss: 0.744374]\n",
      "epoch:43 step:33946 [D loss: 0.699233, acc.: 56.25%] [G loss: 0.721843]\n",
      "epoch:43 step:33947 [D loss: 0.705905, acc.: 50.00%] [G loss: 0.806707]\n",
      "epoch:43 step:33948 [D loss: 0.671494, acc.: 60.94%] [G loss: 0.786016]\n",
      "epoch:43 step:33949 [D loss: 0.653834, acc.: 65.62%] [G loss: 0.735070]\n",
      "epoch:43 step:33950 [D loss: 0.668641, acc.: 63.28%] [G loss: 0.772497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33951 [D loss: 0.667789, acc.: 57.81%] [G loss: 0.850507]\n",
      "epoch:43 step:33952 [D loss: 0.698029, acc.: 59.38%] [G loss: 0.829287]\n",
      "epoch:43 step:33953 [D loss: 0.642895, acc.: 64.84%] [G loss: 0.797088]\n",
      "epoch:43 step:33954 [D loss: 0.598188, acc.: 76.56%] [G loss: 0.894261]\n",
      "epoch:43 step:33955 [D loss: 0.669242, acc.: 59.38%] [G loss: 0.735539]\n",
      "epoch:43 step:33956 [D loss: 0.648703, acc.: 55.47%] [G loss: 0.812126]\n",
      "epoch:43 step:33957 [D loss: 0.624885, acc.: 67.97%] [G loss: 0.861349]\n",
      "epoch:43 step:33958 [D loss: 0.740483, acc.: 42.97%] [G loss: 0.749975]\n",
      "epoch:43 step:33959 [D loss: 0.577069, acc.: 75.78%] [G loss: 0.932894]\n",
      "epoch:43 step:33960 [D loss: 0.705273, acc.: 52.34%] [G loss: 0.681138]\n",
      "epoch:43 step:33961 [D loss: 0.633727, acc.: 68.75%] [G loss: 0.906974]\n",
      "epoch:43 step:33962 [D loss: 0.670885, acc.: 58.59%] [G loss: 0.846144]\n",
      "epoch:43 step:33963 [D loss: 0.698953, acc.: 52.34%] [G loss: 0.783345]\n",
      "epoch:43 step:33964 [D loss: 0.649264, acc.: 58.59%] [G loss: 0.767335]\n",
      "epoch:43 step:33965 [D loss: 0.683995, acc.: 53.91%] [G loss: 0.823335]\n",
      "epoch:43 step:33966 [D loss: 0.653165, acc.: 67.97%] [G loss: 0.785236]\n",
      "epoch:43 step:33967 [D loss: 0.702963, acc.: 52.34%] [G loss: 0.862383]\n",
      "epoch:43 step:33968 [D loss: 0.702575, acc.: 47.66%] [G loss: 0.803798]\n",
      "epoch:43 step:33969 [D loss: 0.641041, acc.: 60.94%] [G loss: 0.803240]\n",
      "epoch:43 step:33970 [D loss: 0.638577, acc.: 65.62%] [G loss: 0.811297]\n",
      "epoch:43 step:33971 [D loss: 0.620650, acc.: 71.88%] [G loss: 0.924740]\n",
      "epoch:43 step:33972 [D loss: 0.695089, acc.: 55.47%] [G loss: 0.815910]\n",
      "epoch:43 step:33973 [D loss: 0.650166, acc.: 57.81%] [G loss: 0.915978]\n",
      "epoch:43 step:33974 [D loss: 0.766460, acc.: 46.88%] [G loss: 0.782038]\n",
      "epoch:43 step:33975 [D loss: 0.706525, acc.: 46.88%] [G loss: 0.656335]\n",
      "epoch:43 step:33976 [D loss: 0.725854, acc.: 54.69%] [G loss: 0.779797]\n",
      "epoch:43 step:33977 [D loss: 0.642433, acc.: 68.75%] [G loss: 0.748945]\n",
      "epoch:43 step:33978 [D loss: 0.668814, acc.: 54.69%] [G loss: 0.817162]\n",
      "epoch:43 step:33979 [D loss: 0.740758, acc.: 46.09%] [G loss: 0.778389]\n",
      "epoch:43 step:33980 [D loss: 0.673632, acc.: 59.38%] [G loss: 0.811323]\n",
      "epoch:43 step:33981 [D loss: 0.702413, acc.: 58.59%] [G loss: 0.736786]\n",
      "epoch:43 step:33982 [D loss: 0.647742, acc.: 58.59%] [G loss: 0.803327]\n",
      "epoch:43 step:33983 [D loss: 0.707999, acc.: 50.00%] [G loss: 0.761668]\n",
      "epoch:43 step:33984 [D loss: 0.649184, acc.: 65.62%] [G loss: 0.756482]\n",
      "epoch:43 step:33985 [D loss: 0.678100, acc.: 57.03%] [G loss: 0.801275]\n",
      "epoch:43 step:33986 [D loss: 0.651162, acc.: 62.50%] [G loss: 0.756661]\n",
      "epoch:43 step:33987 [D loss: 0.694285, acc.: 52.34%] [G loss: 0.764855]\n",
      "epoch:43 step:33988 [D loss: 0.699859, acc.: 52.34%] [G loss: 0.828745]\n",
      "epoch:43 step:33989 [D loss: 0.657263, acc.: 58.59%] [G loss: 0.814291]\n",
      "epoch:43 step:33990 [D loss: 0.619063, acc.: 67.97%] [G loss: 0.718861]\n",
      "epoch:43 step:33991 [D loss: 0.694487, acc.: 61.72%] [G loss: 0.791020]\n",
      "epoch:43 step:33992 [D loss: 0.686640, acc.: 57.81%] [G loss: 0.755494]\n",
      "epoch:43 step:33993 [D loss: 0.648108, acc.: 66.41%] [G loss: 0.797183]\n",
      "epoch:43 step:33994 [D loss: 0.698918, acc.: 53.91%] [G loss: 0.769644]\n",
      "epoch:43 step:33995 [D loss: 0.678907, acc.: 59.38%] [G loss: 0.774731]\n",
      "epoch:43 step:33996 [D loss: 0.661203, acc.: 63.28%] [G loss: 0.809469]\n",
      "epoch:43 step:33997 [D loss: 0.696339, acc.: 50.78%] [G loss: 0.689360]\n",
      "epoch:43 step:33998 [D loss: 0.637153, acc.: 67.19%] [G loss: 0.741857]\n",
      "epoch:43 step:33999 [D loss: 0.748685, acc.: 43.75%] [G loss: 0.772061]\n",
      "epoch:43 step:34000 [D loss: 0.728847, acc.: 53.12%] [G loss: 0.729349]\n",
      "epoch:43 step:34001 [D loss: 0.609371, acc.: 74.22%] [G loss: 0.865335]\n",
      "epoch:43 step:34002 [D loss: 0.601828, acc.: 69.53%] [G loss: 0.765786]\n",
      "epoch:43 step:34003 [D loss: 0.615777, acc.: 72.66%] [G loss: 0.762828]\n",
      "epoch:43 step:34004 [D loss: 0.685341, acc.: 57.81%] [G loss: 0.735714]\n",
      "epoch:43 step:34005 [D loss: 0.667103, acc.: 57.03%] [G loss: 0.876763]\n",
      "epoch:43 step:34006 [D loss: 0.678992, acc.: 57.81%] [G loss: 0.836859]\n",
      "epoch:43 step:34007 [D loss: 0.696257, acc.: 51.56%] [G loss: 0.760485]\n",
      "epoch:43 step:34008 [D loss: 0.647338, acc.: 57.03%] [G loss: 0.774014]\n",
      "epoch:43 step:34009 [D loss: 0.682536, acc.: 57.03%] [G loss: 0.790112]\n",
      "epoch:43 step:34010 [D loss: 0.673049, acc.: 60.16%] [G loss: 0.727305]\n",
      "epoch:43 step:34011 [D loss: 0.727823, acc.: 51.56%] [G loss: 0.742062]\n",
      "epoch:43 step:34012 [D loss: 0.689524, acc.: 50.00%] [G loss: 0.712627]\n",
      "epoch:43 step:34013 [D loss: 0.720330, acc.: 46.09%] [G loss: 0.793721]\n",
      "epoch:43 step:34014 [D loss: 0.791938, acc.: 31.25%] [G loss: 0.796386]\n",
      "epoch:43 step:34015 [D loss: 0.682712, acc.: 54.69%] [G loss: 0.802985]\n",
      "epoch:43 step:34016 [D loss: 0.763679, acc.: 35.94%] [G loss: 0.777712]\n",
      "epoch:43 step:34017 [D loss: 0.703329, acc.: 53.12%] [G loss: 0.846624]\n",
      "epoch:43 step:34018 [D loss: 0.706091, acc.: 44.53%] [G loss: 0.810488]\n",
      "epoch:43 step:34019 [D loss: 0.735146, acc.: 45.31%] [G loss: 0.854915]\n",
      "epoch:43 step:34020 [D loss: 0.691602, acc.: 53.91%] [G loss: 0.824345]\n",
      "epoch:43 step:34021 [D loss: 0.673129, acc.: 55.47%] [G loss: 0.841727]\n",
      "epoch:43 step:34022 [D loss: 0.708311, acc.: 50.78%] [G loss: 0.839955]\n",
      "epoch:43 step:34023 [D loss: 0.704113, acc.: 50.00%] [G loss: 0.758991]\n",
      "epoch:43 step:34024 [D loss: 0.748821, acc.: 46.88%] [G loss: 0.798845]\n",
      "epoch:43 step:34025 [D loss: 0.647332, acc.: 60.94%] [G loss: 0.829605]\n",
      "epoch:43 step:34026 [D loss: 0.714233, acc.: 44.53%] [G loss: 0.726876]\n",
      "epoch:43 step:34027 [D loss: 0.677437, acc.: 60.16%] [G loss: 0.859914]\n",
      "epoch:43 step:34028 [D loss: 0.659061, acc.: 61.72%] [G loss: 0.803460]\n",
      "epoch:43 step:34029 [D loss: 0.670709, acc.: 57.81%] [G loss: 0.774415]\n",
      "epoch:43 step:34030 [D loss: 0.657172, acc.: 57.03%] [G loss: 0.753667]\n",
      "epoch:43 step:34031 [D loss: 0.687256, acc.: 50.78%] [G loss: 0.755974]\n",
      "epoch:43 step:34032 [D loss: 0.647759, acc.: 60.94%] [G loss: 0.884457]\n",
      "epoch:43 step:34033 [D loss: 0.688697, acc.: 53.91%] [G loss: 0.870054]\n",
      "epoch:43 step:34034 [D loss: 0.698522, acc.: 53.12%] [G loss: 0.807666]\n",
      "epoch:43 step:34035 [D loss: 0.683834, acc.: 56.25%] [G loss: 0.792389]\n",
      "epoch:43 step:34036 [D loss: 0.698802, acc.: 47.66%] [G loss: 0.853695]\n",
      "epoch:43 step:34037 [D loss: 0.734256, acc.: 43.75%] [G loss: 0.855293]\n",
      "epoch:43 step:34038 [D loss: 0.677302, acc.: 57.81%] [G loss: 0.826900]\n",
      "epoch:43 step:34039 [D loss: 0.701209, acc.: 52.34%] [G loss: 0.816785]\n",
      "epoch:43 step:34040 [D loss: 0.652801, acc.: 57.03%] [G loss: 0.846924]\n",
      "epoch:43 step:34041 [D loss: 0.719428, acc.: 46.09%] [G loss: 0.836044]\n",
      "epoch:43 step:34042 [D loss: 0.683668, acc.: 59.38%] [G loss: 0.754337]\n",
      "epoch:43 step:34043 [D loss: 0.676900, acc.: 58.59%] [G loss: 0.885569]\n",
      "epoch:43 step:34044 [D loss: 0.727718, acc.: 43.75%] [G loss: 0.821743]\n",
      "epoch:43 step:34045 [D loss: 0.685793, acc.: 53.91%] [G loss: 0.823495]\n",
      "epoch:43 step:34046 [D loss: 0.740310, acc.: 45.31%] [G loss: 0.762238]\n",
      "epoch:43 step:34047 [D loss: 0.703705, acc.: 46.88%] [G loss: 0.838573]\n",
      "epoch:43 step:34048 [D loss: 0.698311, acc.: 52.34%] [G loss: 0.761042]\n",
      "epoch:43 step:34049 [D loss: 0.622298, acc.: 67.97%] [G loss: 0.845756]\n",
      "epoch:43 step:34050 [D loss: 0.687312, acc.: 52.34%] [G loss: 0.888489]\n",
      "epoch:43 step:34051 [D loss: 0.671347, acc.: 62.50%] [G loss: 0.796358]\n",
      "epoch:43 step:34052 [D loss: 0.590575, acc.: 78.12%] [G loss: 0.904457]\n",
      "epoch:43 step:34053 [D loss: 0.688954, acc.: 52.34%] [G loss: 0.880391]\n",
      "epoch:43 step:34054 [D loss: 0.726473, acc.: 48.44%] [G loss: 0.846599]\n",
      "epoch:43 step:34055 [D loss: 0.714880, acc.: 49.22%] [G loss: 0.794063]\n",
      "epoch:43 step:34056 [D loss: 0.756328, acc.: 53.12%] [G loss: 0.780372]\n",
      "epoch:43 step:34057 [D loss: 0.687047, acc.: 55.47%] [G loss: 0.825751]\n",
      "epoch:43 step:34058 [D loss: 0.688168, acc.: 53.91%] [G loss: 0.746969]\n",
      "epoch:43 step:34059 [D loss: 0.612397, acc.: 74.22%] [G loss: 0.818111]\n",
      "epoch:43 step:34060 [D loss: 0.727086, acc.: 49.22%] [G loss: 0.749959]\n",
      "epoch:43 step:34061 [D loss: 0.637293, acc.: 67.19%] [G loss: 0.786493]\n",
      "epoch:43 step:34062 [D loss: 0.663367, acc.: 59.38%] [G loss: 0.743180]\n",
      "epoch:43 step:34063 [D loss: 0.598807, acc.: 77.34%] [G loss: 0.829639]\n",
      "epoch:43 step:34064 [D loss: 0.726314, acc.: 44.53%] [G loss: 0.774969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34065 [D loss: 0.699469, acc.: 53.91%] [G loss: 0.786226]\n",
      "epoch:43 step:34066 [D loss: 0.753953, acc.: 38.28%] [G loss: 0.864962]\n",
      "epoch:43 step:34067 [D loss: 0.690548, acc.: 47.66%] [G loss: 0.792786]\n",
      "epoch:43 step:34068 [D loss: 0.643827, acc.: 67.97%] [G loss: 0.806039]\n",
      "epoch:43 step:34069 [D loss: 0.593587, acc.: 75.00%] [G loss: 0.895515]\n",
      "epoch:43 step:34070 [D loss: 0.650222, acc.: 62.50%] [G loss: 0.708856]\n",
      "epoch:43 step:34071 [D loss: 0.670725, acc.: 55.47%] [G loss: 0.783922]\n",
      "epoch:43 step:34072 [D loss: 0.730131, acc.: 46.09%] [G loss: 0.773124]\n",
      "epoch:43 step:34073 [D loss: 0.643000, acc.: 63.28%] [G loss: 0.746703]\n",
      "epoch:43 step:34074 [D loss: 0.646985, acc.: 65.62%] [G loss: 0.798735]\n",
      "epoch:43 step:34075 [D loss: 0.678773, acc.: 60.16%] [G loss: 0.795993]\n",
      "epoch:43 step:34076 [D loss: 0.710783, acc.: 46.88%] [G loss: 0.801020]\n",
      "epoch:43 step:34077 [D loss: 0.669170, acc.: 57.81%] [G loss: 0.728237]\n",
      "epoch:43 step:34078 [D loss: 0.696205, acc.: 56.25%] [G loss: 0.768553]\n",
      "epoch:43 step:34079 [D loss: 0.690585, acc.: 53.91%] [G loss: 0.853723]\n",
      "epoch:43 step:34080 [D loss: 0.684262, acc.: 50.00%] [G loss: 0.702161]\n",
      "epoch:43 step:34081 [D loss: 0.636288, acc.: 73.44%] [G loss: 0.815411]\n",
      "epoch:43 step:34082 [D loss: 0.602083, acc.: 73.44%] [G loss: 0.798730]\n",
      "epoch:43 step:34083 [D loss: 0.668920, acc.: 53.91%] [G loss: 0.799187]\n",
      "epoch:43 step:34084 [D loss: 0.703708, acc.: 50.00%] [G loss: 0.840771]\n",
      "epoch:43 step:34085 [D loss: 0.673198, acc.: 56.25%] [G loss: 0.881560]\n",
      "epoch:43 step:34086 [D loss: 0.760262, acc.: 40.62%] [G loss: 0.769732]\n",
      "epoch:43 step:34087 [D loss: 0.688842, acc.: 56.25%] [G loss: 0.812550]\n",
      "epoch:43 step:34088 [D loss: 0.596546, acc.: 79.69%] [G loss: 0.773688]\n",
      "epoch:43 step:34089 [D loss: 0.629155, acc.: 66.41%] [G loss: 0.743880]\n",
      "epoch:43 step:34090 [D loss: 0.647185, acc.: 62.50%] [G loss: 0.793949]\n",
      "epoch:43 step:34091 [D loss: 0.624663, acc.: 67.19%] [G loss: 0.826408]\n",
      "epoch:43 step:34092 [D loss: 0.683107, acc.: 56.25%] [G loss: 0.852817]\n",
      "epoch:43 step:34093 [D loss: 0.631143, acc.: 67.97%] [G loss: 0.725918]\n",
      "epoch:43 step:34094 [D loss: 0.665525, acc.: 53.12%] [G loss: 0.749603]\n",
      "epoch:43 step:34095 [D loss: 0.705026, acc.: 47.66%] [G loss: 0.683502]\n",
      "epoch:43 step:34096 [D loss: 0.743012, acc.: 45.31%] [G loss: 0.758351]\n",
      "epoch:43 step:34097 [D loss: 0.776106, acc.: 33.59%] [G loss: 0.724212]\n",
      "epoch:43 step:34098 [D loss: 0.705757, acc.: 51.56%] [G loss: 0.678257]\n",
      "epoch:43 step:34099 [D loss: 0.706909, acc.: 45.31%] [G loss: 0.720062]\n",
      "epoch:43 step:34100 [D loss: 0.655041, acc.: 60.94%] [G loss: 0.816366]\n",
      "epoch:43 step:34101 [D loss: 0.594764, acc.: 71.09%] [G loss: 0.793026]\n",
      "epoch:43 step:34102 [D loss: 0.711370, acc.: 50.78%] [G loss: 0.782820]\n",
      "epoch:43 step:34103 [D loss: 0.721612, acc.: 45.31%] [G loss: 0.767044]\n",
      "epoch:43 step:34104 [D loss: 0.694061, acc.: 56.25%] [G loss: 0.793835]\n",
      "epoch:43 step:34105 [D loss: 0.712194, acc.: 43.75%] [G loss: 0.761063]\n",
      "epoch:43 step:34106 [D loss: 0.664298, acc.: 60.94%] [G loss: 0.829694]\n",
      "epoch:43 step:34107 [D loss: 0.728762, acc.: 46.88%] [G loss: 0.848145]\n",
      "epoch:43 step:34108 [D loss: 0.678071, acc.: 54.69%] [G loss: 0.732983]\n",
      "epoch:43 step:34109 [D loss: 0.793157, acc.: 37.50%] [G loss: 0.773290]\n",
      "epoch:43 step:34110 [D loss: 0.704426, acc.: 52.34%] [G loss: 0.751445]\n",
      "epoch:43 step:34111 [D loss: 0.682609, acc.: 57.81%] [G loss: 0.812598]\n",
      "epoch:43 step:34112 [D loss: 0.624804, acc.: 65.62%] [G loss: 0.837547]\n",
      "epoch:43 step:34113 [D loss: 0.629755, acc.: 63.28%] [G loss: 0.756662]\n",
      "epoch:43 step:34114 [D loss: 0.669862, acc.: 59.38%] [G loss: 0.816215]\n",
      "epoch:43 step:34115 [D loss: 0.732027, acc.: 50.00%] [G loss: 0.804488]\n",
      "epoch:43 step:34116 [D loss: 0.730360, acc.: 43.75%] [G loss: 0.719583]\n",
      "epoch:43 step:34117 [D loss: 0.670965, acc.: 57.03%] [G loss: 0.850157]\n",
      "epoch:43 step:34118 [D loss: 0.647392, acc.: 61.72%] [G loss: 0.847215]\n",
      "epoch:43 step:34119 [D loss: 0.680458, acc.: 60.94%] [G loss: 0.713721]\n",
      "epoch:43 step:34120 [D loss: 0.666657, acc.: 55.47%] [G loss: 0.752114]\n",
      "epoch:43 step:34121 [D loss: 0.602773, acc.: 73.44%] [G loss: 0.771869]\n",
      "epoch:43 step:34122 [D loss: 0.618630, acc.: 67.97%] [G loss: 0.766533]\n",
      "epoch:43 step:34123 [D loss: 0.729949, acc.: 43.75%] [G loss: 0.721900]\n",
      "epoch:43 step:34124 [D loss: 0.664590, acc.: 60.94%] [G loss: 0.779728]\n",
      "epoch:43 step:34125 [D loss: 0.645786, acc.: 62.50%] [G loss: 0.736309]\n",
      "epoch:43 step:34126 [D loss: 0.720498, acc.: 46.09%] [G loss: 0.751235]\n",
      "epoch:43 step:34127 [D loss: 0.718026, acc.: 47.66%] [G loss: 0.805298]\n",
      "epoch:43 step:34128 [D loss: 0.677385, acc.: 61.72%] [G loss: 0.808597]\n",
      "epoch:43 step:34129 [D loss: 0.772713, acc.: 37.50%] [G loss: 0.819541]\n",
      "epoch:43 step:34130 [D loss: 0.715096, acc.: 49.22%] [G loss: 0.831896]\n",
      "epoch:43 step:34131 [D loss: 0.630042, acc.: 71.09%] [G loss: 0.877882]\n",
      "epoch:43 step:34132 [D loss: 0.686507, acc.: 50.00%] [G loss: 0.796770]\n",
      "epoch:43 step:34133 [D loss: 0.662762, acc.: 65.62%] [G loss: 0.859005]\n",
      "epoch:43 step:34134 [D loss: 0.737160, acc.: 51.56%] [G loss: 0.768954]\n",
      "epoch:43 step:34135 [D loss: 0.683874, acc.: 50.00%] [G loss: 0.773080]\n",
      "epoch:43 step:34136 [D loss: 0.651843, acc.: 64.84%] [G loss: 0.824669]\n",
      "epoch:43 step:34137 [D loss: 0.647928, acc.: 67.97%] [G loss: 0.760032]\n",
      "epoch:43 step:34138 [D loss: 0.649338, acc.: 57.81%] [G loss: 0.819577]\n",
      "epoch:43 step:34139 [D loss: 0.676950, acc.: 57.81%] [G loss: 0.816538]\n",
      "epoch:43 step:34140 [D loss: 0.701052, acc.: 53.12%] [G loss: 0.781938]\n",
      "epoch:43 step:34141 [D loss: 0.746328, acc.: 42.97%] [G loss: 0.745027]\n",
      "epoch:43 step:34142 [D loss: 0.637779, acc.: 68.75%] [G loss: 0.769648]\n",
      "epoch:43 step:34143 [D loss: 0.728316, acc.: 46.09%] [G loss: 0.830340]\n",
      "epoch:43 step:34144 [D loss: 0.706220, acc.: 52.34%] [G loss: 0.758005]\n",
      "epoch:43 step:34145 [D loss: 0.661656, acc.: 63.28%] [G loss: 0.848984]\n",
      "epoch:43 step:34146 [D loss: 0.637118, acc.: 70.31%] [G loss: 0.796708]\n",
      "epoch:43 step:34147 [D loss: 0.685957, acc.: 54.69%] [G loss: 0.793357]\n",
      "epoch:43 step:34148 [D loss: 0.698576, acc.: 52.34%] [G loss: 0.827537]\n",
      "epoch:43 step:34149 [D loss: 0.718628, acc.: 49.22%] [G loss: 0.796583]\n",
      "epoch:43 step:34150 [D loss: 0.686389, acc.: 57.03%] [G loss: 0.876135]\n",
      "epoch:43 step:34151 [D loss: 0.653875, acc.: 67.19%] [G loss: 0.801239]\n",
      "epoch:43 step:34152 [D loss: 0.628407, acc.: 68.75%] [G loss: 0.807446]\n",
      "epoch:43 step:34153 [D loss: 0.692199, acc.: 53.12%] [G loss: 0.728161]\n",
      "epoch:43 step:34154 [D loss: 0.709960, acc.: 44.53%] [G loss: 0.826773]\n",
      "epoch:43 step:34155 [D loss: 0.711036, acc.: 55.47%] [G loss: 0.898504]\n",
      "epoch:43 step:34156 [D loss: 0.729569, acc.: 46.09%] [G loss: 0.804712]\n",
      "epoch:43 step:34157 [D loss: 0.690981, acc.: 51.56%] [G loss: 0.824507]\n",
      "epoch:43 step:34158 [D loss: 0.721570, acc.: 43.75%] [G loss: 0.785758]\n",
      "epoch:43 step:34159 [D loss: 0.671024, acc.: 63.28%] [G loss: 0.805932]\n",
      "epoch:43 step:34160 [D loss: 0.738302, acc.: 46.88%] [G loss: 0.747214]\n",
      "epoch:43 step:34161 [D loss: 0.677273, acc.: 56.25%] [G loss: 0.794211]\n",
      "epoch:43 step:34162 [D loss: 0.705836, acc.: 50.00%] [G loss: 0.787000]\n",
      "epoch:43 step:34163 [D loss: 0.665909, acc.: 56.25%] [G loss: 0.737600]\n",
      "epoch:43 step:34164 [D loss: 0.658962, acc.: 59.38%] [G loss: 0.772249]\n",
      "epoch:43 step:34165 [D loss: 0.636159, acc.: 70.31%] [G loss: 0.754357]\n",
      "epoch:43 step:34166 [D loss: 0.690026, acc.: 58.59%] [G loss: 0.805460]\n",
      "epoch:43 step:34167 [D loss: 0.659716, acc.: 61.72%] [G loss: 0.696643]\n",
      "epoch:43 step:34168 [D loss: 0.663646, acc.: 62.50%] [G loss: 0.760320]\n",
      "epoch:43 step:34169 [D loss: 0.679485, acc.: 58.59%] [G loss: 0.713047]\n",
      "epoch:43 step:34170 [D loss: 0.663531, acc.: 59.38%] [G loss: 0.795721]\n",
      "epoch:43 step:34171 [D loss: 0.665729, acc.: 57.81%] [G loss: 0.919456]\n",
      "epoch:43 step:34172 [D loss: 0.675970, acc.: 57.81%] [G loss: 0.848965]\n",
      "epoch:43 step:34173 [D loss: 0.717779, acc.: 46.09%] [G loss: 0.858994]\n",
      "epoch:43 step:34174 [D loss: 0.696555, acc.: 48.44%] [G loss: 0.805963]\n",
      "epoch:43 step:34175 [D loss: 0.691110, acc.: 54.69%] [G loss: 0.668243]\n",
      "epoch:43 step:34176 [D loss: 0.691213, acc.: 53.91%] [G loss: 0.799500]\n",
      "epoch:43 step:34177 [D loss: 0.647113, acc.: 60.94%] [G loss: 0.835134]\n",
      "epoch:43 step:34178 [D loss: 0.650812, acc.: 66.41%] [G loss: 0.870157]\n",
      "epoch:43 step:34179 [D loss: 0.622851, acc.: 67.19%] [G loss: 0.888672]\n",
      "epoch:43 step:34180 [D loss: 0.667311, acc.: 61.72%] [G loss: 0.852788]\n",
      "epoch:43 step:34181 [D loss: 0.671095, acc.: 62.50%] [G loss: 0.906213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34182 [D loss: 0.678430, acc.: 55.47%] [G loss: 0.816029]\n",
      "epoch:43 step:34183 [D loss: 0.629760, acc.: 67.97%] [G loss: 0.810791]\n",
      "epoch:43 step:34184 [D loss: 0.711041, acc.: 50.00%] [G loss: 0.705276]\n",
      "epoch:43 step:34185 [D loss: 0.600065, acc.: 76.56%] [G loss: 0.854037]\n",
      "epoch:43 step:34186 [D loss: 0.765511, acc.: 38.28%] [G loss: 0.781072]\n",
      "epoch:43 step:34187 [D loss: 0.650614, acc.: 62.50%] [G loss: 0.781556]\n",
      "epoch:43 step:34188 [D loss: 0.662501, acc.: 62.50%] [G loss: 0.783230]\n",
      "epoch:43 step:34189 [D loss: 0.715332, acc.: 53.91%] [G loss: 0.758738]\n",
      "epoch:43 step:34190 [D loss: 0.641845, acc.: 64.84%] [G loss: 0.758643]\n",
      "epoch:43 step:34191 [D loss: 0.641637, acc.: 65.62%] [G loss: 0.777931]\n",
      "epoch:43 step:34192 [D loss: 0.659597, acc.: 56.25%] [G loss: 0.802109]\n",
      "epoch:43 step:34193 [D loss: 0.651435, acc.: 60.16%] [G loss: 0.782093]\n",
      "epoch:43 step:34194 [D loss: 0.683030, acc.: 60.16%] [G loss: 0.795041]\n",
      "epoch:43 step:34195 [D loss: 0.647733, acc.: 60.94%] [G loss: 0.734706]\n",
      "epoch:43 step:34196 [D loss: 0.742525, acc.: 48.44%] [G loss: 0.740660]\n",
      "epoch:43 step:34197 [D loss: 0.667854, acc.: 57.03%] [G loss: 0.778522]\n",
      "epoch:43 step:34198 [D loss: 0.628316, acc.: 62.50%] [G loss: 0.750470]\n",
      "epoch:43 step:34199 [D loss: 0.713795, acc.: 49.22%] [G loss: 0.798699]\n",
      "epoch:43 step:34200 [D loss: 0.708430, acc.: 49.22%] [G loss: 0.737670]\n",
      "epoch:43 step:34201 [D loss: 0.621454, acc.: 71.09%] [G loss: 0.858374]\n",
      "epoch:43 step:34202 [D loss: 0.645943, acc.: 65.62%] [G loss: 0.779162]\n",
      "epoch:43 step:34203 [D loss: 0.681446, acc.: 60.16%] [G loss: 0.815530]\n",
      "epoch:43 step:34204 [D loss: 0.772989, acc.: 35.94%] [G loss: 0.766535]\n",
      "epoch:43 step:34205 [D loss: 0.680284, acc.: 60.16%] [G loss: 0.841430]\n",
      "epoch:43 step:34206 [D loss: 0.707904, acc.: 50.78%] [G loss: 0.882022]\n",
      "epoch:43 step:34207 [D loss: 0.680347, acc.: 57.03%] [G loss: 0.851071]\n",
      "epoch:43 step:34208 [D loss: 0.731924, acc.: 44.53%] [G loss: 0.814872]\n",
      "epoch:43 step:34209 [D loss: 0.725171, acc.: 52.34%] [G loss: 0.796896]\n",
      "epoch:43 step:34210 [D loss: 0.715173, acc.: 50.78%] [G loss: 0.813863]\n",
      "epoch:43 step:34211 [D loss: 0.671841, acc.: 60.16%] [G loss: 0.786000]\n",
      "epoch:43 step:34212 [D loss: 0.645162, acc.: 57.03%] [G loss: 0.970388]\n",
      "epoch:43 step:34213 [D loss: 0.671878, acc.: 57.03%] [G loss: 0.796265]\n",
      "epoch:43 step:34214 [D loss: 0.693139, acc.: 58.59%] [G loss: 0.822533]\n",
      "epoch:43 step:34215 [D loss: 0.678906, acc.: 60.16%] [G loss: 0.784131]\n",
      "epoch:43 step:34216 [D loss: 0.795511, acc.: 34.38%] [G loss: 0.689929]\n",
      "epoch:43 step:34217 [D loss: 0.697880, acc.: 53.91%] [G loss: 0.757236]\n",
      "epoch:43 step:34218 [D loss: 0.662352, acc.: 60.94%] [G loss: 0.743375]\n",
      "epoch:43 step:34219 [D loss: 0.635011, acc.: 66.41%] [G loss: 0.722061]\n",
      "epoch:43 step:34220 [D loss: 0.687138, acc.: 54.69%] [G loss: 0.718231]\n",
      "epoch:43 step:34221 [D loss: 0.706670, acc.: 56.25%] [G loss: 0.803611]\n",
      "epoch:43 step:34222 [D loss: 0.732110, acc.: 44.53%] [G loss: 0.744145]\n",
      "epoch:43 step:34223 [D loss: 0.681884, acc.: 55.47%] [G loss: 0.746514]\n",
      "epoch:43 step:34224 [D loss: 0.716168, acc.: 51.56%] [G loss: 0.732537]\n",
      "epoch:43 step:34225 [D loss: 0.689650, acc.: 57.03%] [G loss: 0.740997]\n",
      "epoch:43 step:34226 [D loss: 0.725408, acc.: 46.88%] [G loss: 0.770186]\n",
      "epoch:43 step:34227 [D loss: 0.616708, acc.: 67.97%] [G loss: 0.816901]\n",
      "epoch:43 step:34228 [D loss: 0.664851, acc.: 53.91%] [G loss: 0.829975]\n",
      "epoch:43 step:34229 [D loss: 0.695873, acc.: 57.03%] [G loss: 0.792188]\n",
      "epoch:43 step:34230 [D loss: 0.780770, acc.: 39.84%] [G loss: 0.802561]\n",
      "epoch:43 step:34231 [D loss: 0.611109, acc.: 69.53%] [G loss: 0.764752]\n",
      "epoch:43 step:34232 [D loss: 0.634103, acc.: 71.09%] [G loss: 0.816311]\n",
      "epoch:43 step:34233 [D loss: 0.656795, acc.: 59.38%] [G loss: 0.805419]\n",
      "epoch:43 step:34234 [D loss: 0.661142, acc.: 55.47%] [G loss: 0.830397]\n",
      "epoch:43 step:34235 [D loss: 0.626263, acc.: 70.31%] [G loss: 0.753919]\n",
      "epoch:43 step:34236 [D loss: 0.711385, acc.: 50.00%] [G loss: 0.697719]\n",
      "epoch:43 step:34237 [D loss: 0.731202, acc.: 46.09%] [G loss: 0.678871]\n",
      "epoch:43 step:34238 [D loss: 0.649944, acc.: 63.28%] [G loss: 0.810333]\n",
      "epoch:43 step:34239 [D loss: 0.697914, acc.: 50.78%] [G loss: 0.793989]\n",
      "epoch:43 step:34240 [D loss: 0.655535, acc.: 61.72%] [G loss: 0.819186]\n",
      "epoch:43 step:34241 [D loss: 0.600668, acc.: 72.66%] [G loss: 0.840962]\n",
      "epoch:43 step:34242 [D loss: 0.641379, acc.: 55.47%] [G loss: 0.835376]\n",
      "epoch:43 step:34243 [D loss: 0.647027, acc.: 64.06%] [G loss: 0.842024]\n",
      "epoch:43 step:34244 [D loss: 0.719521, acc.: 51.56%] [G loss: 0.831884]\n",
      "epoch:43 step:34245 [D loss: 0.697688, acc.: 52.34%] [G loss: 0.821526]\n",
      "epoch:43 step:34246 [D loss: 0.635131, acc.: 63.28%] [G loss: 0.861444]\n",
      "epoch:43 step:34247 [D loss: 0.682010, acc.: 54.69%] [G loss: 0.801791]\n",
      "epoch:43 step:34248 [D loss: 0.687949, acc.: 51.56%] [G loss: 0.914342]\n",
      "epoch:43 step:34249 [D loss: 0.664344, acc.: 60.16%] [G loss: 0.943143]\n",
      "epoch:43 step:34250 [D loss: 0.653710, acc.: 60.16%] [G loss: 0.829884]\n",
      "epoch:43 step:34251 [D loss: 0.733958, acc.: 38.28%] [G loss: 0.794340]\n",
      "epoch:43 step:34252 [D loss: 0.712957, acc.: 47.66%] [G loss: 0.749884]\n",
      "epoch:43 step:34253 [D loss: 0.701529, acc.: 52.34%] [G loss: 0.783695]\n",
      "epoch:43 step:34254 [D loss: 0.682322, acc.: 57.03%] [G loss: 0.796525]\n",
      "epoch:43 step:34255 [D loss: 0.658388, acc.: 60.94%] [G loss: 0.770178]\n",
      "epoch:43 step:34256 [D loss: 0.653015, acc.: 60.16%] [G loss: 0.789976]\n",
      "epoch:43 step:34257 [D loss: 0.714218, acc.: 48.44%] [G loss: 0.776860]\n",
      "epoch:43 step:34258 [D loss: 0.720013, acc.: 47.66%] [G loss: 0.750955]\n",
      "epoch:43 step:34259 [D loss: 0.708356, acc.: 48.44%] [G loss: 0.843617]\n",
      "epoch:43 step:34260 [D loss: 0.630724, acc.: 63.28%] [G loss: 0.828161]\n",
      "epoch:43 step:34261 [D loss: 0.677647, acc.: 57.81%] [G loss: 0.914548]\n",
      "epoch:43 step:34262 [D loss: 0.683351, acc.: 61.72%] [G loss: 0.742149]\n",
      "epoch:43 step:34263 [D loss: 0.625040, acc.: 70.31%] [G loss: 0.810588]\n",
      "epoch:43 step:34264 [D loss: 0.668184, acc.: 55.47%] [G loss: 0.872545]\n",
      "epoch:43 step:34265 [D loss: 0.739055, acc.: 47.66%] [G loss: 0.817963]\n",
      "epoch:43 step:34266 [D loss: 0.705330, acc.: 51.56%] [G loss: 0.822684]\n",
      "epoch:43 step:34267 [D loss: 0.705598, acc.: 56.25%] [G loss: 0.789102]\n",
      "epoch:43 step:34268 [D loss: 0.768484, acc.: 38.28%] [G loss: 0.724552]\n",
      "epoch:43 step:34269 [D loss: 0.708569, acc.: 48.44%] [G loss: 0.695012]\n",
      "epoch:43 step:34270 [D loss: 0.693466, acc.: 56.25%] [G loss: 0.736393]\n",
      "epoch:43 step:34271 [D loss: 0.725322, acc.: 46.09%] [G loss: 0.780206]\n",
      "epoch:43 step:34272 [D loss: 0.705477, acc.: 48.44%] [G loss: 0.825875]\n",
      "epoch:43 step:34273 [D loss: 0.719114, acc.: 50.78%] [G loss: 0.702388]\n",
      "epoch:43 step:34274 [D loss: 0.642936, acc.: 64.84%] [G loss: 0.828910]\n",
      "epoch:43 step:34275 [D loss: 0.748623, acc.: 43.75%] [G loss: 0.779806]\n",
      "epoch:43 step:34276 [D loss: 0.696671, acc.: 47.66%] [G loss: 0.755891]\n",
      "epoch:43 step:34277 [D loss: 0.682126, acc.: 53.12%] [G loss: 0.752352]\n",
      "epoch:43 step:34278 [D loss: 0.618033, acc.: 75.00%] [G loss: 0.750189]\n",
      "epoch:43 step:34279 [D loss: 0.719713, acc.: 50.00%] [G loss: 0.844827]\n",
      "epoch:43 step:34280 [D loss: 0.682047, acc.: 56.25%] [G loss: 0.731068]\n",
      "epoch:43 step:34281 [D loss: 0.695998, acc.: 56.25%] [G loss: 0.789847]\n",
      "epoch:43 step:34282 [D loss: 0.703484, acc.: 46.09%] [G loss: 0.814538]\n",
      "epoch:43 step:34283 [D loss: 0.660974, acc.: 63.28%] [G loss: 0.808494]\n",
      "epoch:43 step:34284 [D loss: 0.699089, acc.: 48.44%] [G loss: 0.779921]\n",
      "epoch:43 step:34285 [D loss: 0.651158, acc.: 63.28%] [G loss: 0.785856]\n",
      "epoch:43 step:34286 [D loss: 0.697273, acc.: 54.69%] [G loss: 0.778521]\n",
      "epoch:43 step:34287 [D loss: 0.673713, acc.: 57.03%] [G loss: 0.832794]\n",
      "epoch:43 step:34288 [D loss: 0.725712, acc.: 38.28%] [G loss: 0.881600]\n",
      "epoch:43 step:34289 [D loss: 0.680900, acc.: 57.81%] [G loss: 0.872596]\n",
      "epoch:43 step:34290 [D loss: 0.678476, acc.: 61.72%] [G loss: 0.742889]\n",
      "epoch:43 step:34291 [D loss: 0.710633, acc.: 50.78%] [G loss: 0.772764]\n",
      "epoch:43 step:34292 [D loss: 0.674372, acc.: 55.47%] [G loss: 0.805850]\n",
      "epoch:43 step:34293 [D loss: 0.640803, acc.: 64.84%] [G loss: 0.764555]\n",
      "epoch:43 step:34294 [D loss: 0.631703, acc.: 67.97%] [G loss: 0.872081]\n",
      "epoch:43 step:34295 [D loss: 0.715481, acc.: 45.31%] [G loss: 0.825995]\n",
      "epoch:43 step:34296 [D loss: 0.624401, acc.: 71.88%] [G loss: 0.769191]\n",
      "epoch:43 step:34297 [D loss: 0.666817, acc.: 56.25%] [G loss: 0.868526]\n",
      "epoch:43 step:34298 [D loss: 0.623760, acc.: 70.31%] [G loss: 0.750934]\n",
      "epoch:43 step:34299 [D loss: 0.675576, acc.: 53.12%] [G loss: 0.746343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34300 [D loss: 0.716653, acc.: 50.78%] [G loss: 0.767240]\n",
      "epoch:43 step:34301 [D loss: 0.707456, acc.: 50.78%] [G loss: 0.735396]\n",
      "epoch:43 step:34302 [D loss: 0.651099, acc.: 68.75%] [G loss: 0.872391]\n",
      "epoch:43 step:34303 [D loss: 0.720056, acc.: 46.88%] [G loss: 0.753646]\n",
      "epoch:43 step:34304 [D loss: 0.718055, acc.: 50.78%] [G loss: 0.738535]\n",
      "epoch:43 step:34305 [D loss: 0.709530, acc.: 53.91%] [G loss: 0.841180]\n",
      "epoch:43 step:34306 [D loss: 0.707670, acc.: 51.56%] [G loss: 0.792599]\n",
      "epoch:43 step:34307 [D loss: 0.633268, acc.: 66.41%] [G loss: 0.844479]\n",
      "epoch:43 step:34308 [D loss: 0.656457, acc.: 60.94%] [G loss: 0.811851]\n",
      "epoch:43 step:34309 [D loss: 0.679838, acc.: 53.91%] [G loss: 0.748696]\n",
      "epoch:43 step:34310 [D loss: 0.748369, acc.: 40.62%] [G loss: 0.716996]\n",
      "epoch:43 step:34311 [D loss: 0.651505, acc.: 62.50%] [G loss: 0.839058]\n",
      "epoch:43 step:34312 [D loss: 0.673865, acc.: 57.81%] [G loss: 0.765976]\n",
      "epoch:43 step:34313 [D loss: 0.740392, acc.: 40.62%] [G loss: 0.708060]\n",
      "epoch:43 step:34314 [D loss: 0.680275, acc.: 59.38%] [G loss: 0.807476]\n",
      "epoch:43 step:34315 [D loss: 0.684750, acc.: 55.47%] [G loss: 0.799863]\n",
      "epoch:43 step:34316 [D loss: 0.647326, acc.: 67.97%] [G loss: 0.842410]\n",
      "epoch:43 step:34317 [D loss: 0.710030, acc.: 54.69%] [G loss: 0.726604]\n",
      "epoch:43 step:34318 [D loss: 0.679738, acc.: 53.91%] [G loss: 0.787130]\n",
      "epoch:43 step:34319 [D loss: 0.638966, acc.: 69.53%] [G loss: 0.826500]\n",
      "epoch:43 step:34320 [D loss: 0.664335, acc.: 63.28%] [G loss: 0.833106]\n",
      "epoch:43 step:34321 [D loss: 0.654768, acc.: 60.94%] [G loss: 0.931687]\n",
      "epoch:43 step:34322 [D loss: 0.701265, acc.: 51.56%] [G loss: 0.872842]\n",
      "epoch:43 step:34323 [D loss: 0.678155, acc.: 50.78%] [G loss: 0.826656]\n",
      "epoch:43 step:34324 [D loss: 0.608152, acc.: 75.78%] [G loss: 0.878478]\n",
      "epoch:43 step:34325 [D loss: 0.687694, acc.: 53.12%] [G loss: 0.818674]\n",
      "epoch:43 step:34326 [D loss: 0.681925, acc.: 59.38%] [G loss: 0.824573]\n",
      "epoch:43 step:34327 [D loss: 0.684739, acc.: 57.03%] [G loss: 0.722011]\n",
      "epoch:43 step:34328 [D loss: 0.668577, acc.: 57.81%] [G loss: 0.827937]\n",
      "epoch:43 step:34329 [D loss: 0.632629, acc.: 69.53%] [G loss: 0.801144]\n",
      "epoch:43 step:34330 [D loss: 0.698978, acc.: 49.22%] [G loss: 0.731930]\n",
      "epoch:43 step:34331 [D loss: 0.709065, acc.: 50.78%] [G loss: 0.800648]\n",
      "epoch:43 step:34332 [D loss: 0.650450, acc.: 67.97%] [G loss: 0.724982]\n",
      "epoch:43 step:34333 [D loss: 0.673723, acc.: 62.50%] [G loss: 0.692769]\n",
      "epoch:43 step:34334 [D loss: 0.744195, acc.: 45.31%] [G loss: 0.782077]\n",
      "epoch:43 step:34335 [D loss: 0.679441, acc.: 60.16%] [G loss: 0.730375]\n",
      "epoch:43 step:34336 [D loss: 0.696401, acc.: 63.28%] [G loss: 0.762172]\n",
      "epoch:43 step:34337 [D loss: 0.674774, acc.: 55.47%] [G loss: 0.803051]\n",
      "epoch:43 step:34338 [D loss: 0.678352, acc.: 60.16%] [G loss: 0.785628]\n",
      "epoch:43 step:34339 [D loss: 0.668375, acc.: 57.03%] [G loss: 0.790096]\n",
      "epoch:43 step:34340 [D loss: 0.696577, acc.: 50.78%] [G loss: 0.814867]\n",
      "epoch:43 step:34341 [D loss: 0.679262, acc.: 55.47%] [G loss: 0.807879]\n",
      "epoch:43 step:34342 [D loss: 0.682709, acc.: 59.38%] [G loss: 0.747316]\n",
      "epoch:43 step:34343 [D loss: 0.690511, acc.: 56.25%] [G loss: 0.843794]\n",
      "epoch:43 step:34344 [D loss: 0.638128, acc.: 63.28%] [G loss: 0.802623]\n",
      "epoch:43 step:34345 [D loss: 0.759785, acc.: 35.16%] [G loss: 0.811561]\n",
      "epoch:43 step:34346 [D loss: 0.675392, acc.: 58.59%] [G loss: 0.810405]\n",
      "epoch:43 step:34347 [D loss: 0.722050, acc.: 50.00%] [G loss: 0.813417]\n",
      "epoch:43 step:34348 [D loss: 0.641387, acc.: 58.59%] [G loss: 0.835627]\n",
      "epoch:43 step:34349 [D loss: 0.720437, acc.: 42.97%] [G loss: 0.756801]\n",
      "epoch:43 step:34350 [D loss: 0.657489, acc.: 67.19%] [G loss: 0.761683]\n",
      "epoch:43 step:34351 [D loss: 0.673604, acc.: 61.72%] [G loss: 0.860688]\n",
      "epoch:43 step:34352 [D loss: 0.675888, acc.: 55.47%] [G loss: 0.935027]\n",
      "epoch:43 step:34353 [D loss: 0.696594, acc.: 53.12%] [G loss: 0.793979]\n",
      "epoch:43 step:34354 [D loss: 0.691780, acc.: 54.69%] [G loss: 0.844318]\n",
      "epoch:43 step:34355 [D loss: 0.695319, acc.: 53.12%] [G loss: 0.842082]\n",
      "epoch:43 step:34356 [D loss: 0.643022, acc.: 64.06%] [G loss: 0.782703]\n",
      "epoch:43 step:34357 [D loss: 0.631992, acc.: 67.19%] [G loss: 0.776528]\n",
      "epoch:43 step:34358 [D loss: 0.642902, acc.: 63.28%] [G loss: 0.815331]\n",
      "epoch:43 step:34359 [D loss: 0.702745, acc.: 50.78%] [G loss: 0.829508]\n",
      "epoch:43 step:34360 [D loss: 0.646960, acc.: 64.06%] [G loss: 0.764883]\n",
      "epoch:43 step:34361 [D loss: 0.685011, acc.: 56.25%] [G loss: 0.817499]\n",
      "epoch:43 step:34362 [D loss: 0.619501, acc.: 68.75%] [G loss: 0.864794]\n",
      "epoch:43 step:34363 [D loss: 0.688061, acc.: 53.91%] [G loss: 0.821921]\n",
      "epoch:43 step:34364 [D loss: 0.653430, acc.: 69.53%] [G loss: 0.775183]\n",
      "epoch:44 step:34365 [D loss: 0.631798, acc.: 71.88%] [G loss: 0.913544]\n",
      "epoch:44 step:34366 [D loss: 0.689938, acc.: 54.69%] [G loss: 0.772642]\n",
      "epoch:44 step:34367 [D loss: 0.666462, acc.: 60.94%] [G loss: 0.863481]\n",
      "epoch:44 step:34368 [D loss: 0.633644, acc.: 64.84%] [G loss: 0.800715]\n",
      "epoch:44 step:34369 [D loss: 0.647993, acc.: 57.03%] [G loss: 0.827373]\n",
      "epoch:44 step:34370 [D loss: 0.628515, acc.: 66.41%] [G loss: 0.870151]\n",
      "epoch:44 step:34371 [D loss: 0.646436, acc.: 65.62%] [G loss: 0.860643]\n",
      "epoch:44 step:34372 [D loss: 0.685022, acc.: 59.38%] [G loss: 0.760276]\n",
      "epoch:44 step:34373 [D loss: 0.709624, acc.: 53.12%] [G loss: 0.817674]\n",
      "epoch:44 step:34374 [D loss: 0.687144, acc.: 50.00%] [G loss: 0.917981]\n",
      "epoch:44 step:34375 [D loss: 0.671630, acc.: 55.47%] [G loss: 0.807376]\n",
      "epoch:44 step:34376 [D loss: 0.687269, acc.: 54.69%] [G loss: 0.832309]\n",
      "epoch:44 step:34377 [D loss: 0.642755, acc.: 67.19%] [G loss: 0.835746]\n",
      "epoch:44 step:34378 [D loss: 0.732318, acc.: 50.00%] [G loss: 0.824202]\n",
      "epoch:44 step:34379 [D loss: 0.706050, acc.: 46.88%] [G loss: 0.807148]\n",
      "epoch:44 step:34380 [D loss: 0.672692, acc.: 64.84%] [G loss: 0.792343]\n",
      "epoch:44 step:34381 [D loss: 0.688513, acc.: 57.03%] [G loss: 0.818454]\n",
      "epoch:44 step:34382 [D loss: 0.747279, acc.: 50.00%] [G loss: 0.712885]\n",
      "epoch:44 step:34383 [D loss: 0.660284, acc.: 62.50%] [G loss: 0.773786]\n",
      "epoch:44 step:34384 [D loss: 0.729711, acc.: 46.88%] [G loss: 0.762263]\n",
      "epoch:44 step:34385 [D loss: 0.718490, acc.: 51.56%] [G loss: 0.771450]\n",
      "epoch:44 step:34386 [D loss: 0.657212, acc.: 59.38%] [G loss: 0.859610]\n",
      "epoch:44 step:34387 [D loss: 0.740689, acc.: 40.62%] [G loss: 0.802390]\n",
      "epoch:44 step:34388 [D loss: 0.689709, acc.: 50.00%] [G loss: 0.767321]\n",
      "epoch:44 step:34389 [D loss: 0.733147, acc.: 44.53%] [G loss: 0.750507]\n",
      "epoch:44 step:34390 [D loss: 0.679450, acc.: 58.59%] [G loss: 0.843449]\n",
      "epoch:44 step:34391 [D loss: 0.669998, acc.: 60.94%] [G loss: 0.765095]\n",
      "epoch:44 step:34392 [D loss: 0.738514, acc.: 41.41%] [G loss: 0.839472]\n",
      "epoch:44 step:34393 [D loss: 0.608390, acc.: 73.44%] [G loss: 0.806836]\n",
      "epoch:44 step:34394 [D loss: 0.698467, acc.: 50.78%] [G loss: 0.831377]\n",
      "epoch:44 step:34395 [D loss: 0.700396, acc.: 57.03%] [G loss: 0.756071]\n",
      "epoch:44 step:34396 [D loss: 0.681862, acc.: 56.25%] [G loss: 0.741431]\n",
      "epoch:44 step:34397 [D loss: 0.715165, acc.: 51.56%] [G loss: 0.776390]\n",
      "epoch:44 step:34398 [D loss: 0.633238, acc.: 69.53%] [G loss: 0.725234]\n",
      "epoch:44 step:34399 [D loss: 0.720745, acc.: 41.41%] [G loss: 0.815684]\n",
      "epoch:44 step:34400 [D loss: 0.669820, acc.: 57.81%] [G loss: 0.772255]\n",
      "epoch:44 step:34401 [D loss: 0.660504, acc.: 56.25%] [G loss: 0.730966]\n",
      "epoch:44 step:34402 [D loss: 0.706531, acc.: 46.88%] [G loss: 0.819075]\n",
      "epoch:44 step:34403 [D loss: 0.672334, acc.: 56.25%] [G loss: 0.849225]\n",
      "epoch:44 step:34404 [D loss: 0.664427, acc.: 60.16%] [G loss: 0.757805]\n",
      "epoch:44 step:34405 [D loss: 0.671942, acc.: 58.59%] [G loss: 0.821888]\n",
      "epoch:44 step:34406 [D loss: 0.676287, acc.: 55.47%] [G loss: 0.882306]\n",
      "epoch:44 step:34407 [D loss: 0.714708, acc.: 45.31%] [G loss: 0.736207]\n",
      "epoch:44 step:34408 [D loss: 0.740056, acc.: 46.09%] [G loss: 0.706519]\n",
      "epoch:44 step:34409 [D loss: 0.667653, acc.: 62.50%] [G loss: 0.829342]\n",
      "epoch:44 step:34410 [D loss: 0.692013, acc.: 47.66%] [G loss: 0.800739]\n",
      "epoch:44 step:34411 [D loss: 0.685685, acc.: 53.12%] [G loss: 0.752448]\n",
      "epoch:44 step:34412 [D loss: 0.663095, acc.: 62.50%] [G loss: 0.807281]\n",
      "epoch:44 step:34413 [D loss: 0.665471, acc.: 63.28%] [G loss: 0.803869]\n",
      "epoch:44 step:34414 [D loss: 0.693774, acc.: 52.34%] [G loss: 0.815531]\n",
      "epoch:44 step:34415 [D loss: 0.660368, acc.: 62.50%] [G loss: 0.866422]\n",
      "epoch:44 step:34416 [D loss: 0.646087, acc.: 61.72%] [G loss: 0.876530]\n",
      "epoch:44 step:34417 [D loss: 0.641959, acc.: 63.28%] [G loss: 0.890106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34418 [D loss: 0.693986, acc.: 52.34%] [G loss: 0.789820]\n",
      "epoch:44 step:34419 [D loss: 0.617395, acc.: 70.31%] [G loss: 0.762016]\n",
      "epoch:44 step:34420 [D loss: 0.698774, acc.: 55.47%] [G loss: 0.834061]\n",
      "epoch:44 step:34421 [D loss: 0.632968, acc.: 67.97%] [G loss: 0.796981]\n",
      "epoch:44 step:34422 [D loss: 0.685379, acc.: 55.47%] [G loss: 0.797184]\n",
      "epoch:44 step:34423 [D loss: 0.686029, acc.: 54.69%] [G loss: 0.737691]\n",
      "epoch:44 step:34424 [D loss: 0.636378, acc.: 66.41%] [G loss: 0.825514]\n",
      "epoch:44 step:34425 [D loss: 0.662365, acc.: 59.38%] [G loss: 0.842033]\n",
      "epoch:44 step:34426 [D loss: 0.665012, acc.: 60.16%] [G loss: 0.863931]\n",
      "epoch:44 step:34427 [D loss: 0.720367, acc.: 46.09%] [G loss: 0.807628]\n",
      "epoch:44 step:34428 [D loss: 0.673723, acc.: 60.16%] [G loss: 0.794650]\n",
      "epoch:44 step:34429 [D loss: 0.713632, acc.: 45.31%] [G loss: 0.733234]\n",
      "epoch:44 step:34430 [D loss: 0.709546, acc.: 47.66%] [G loss: 0.751919]\n",
      "epoch:44 step:34431 [D loss: 0.710672, acc.: 44.53%] [G loss: 0.870392]\n",
      "epoch:44 step:34432 [D loss: 0.650021, acc.: 59.38%] [G loss: 0.908176]\n",
      "epoch:44 step:34433 [D loss: 0.655901, acc.: 67.97%] [G loss: 0.832703]\n",
      "epoch:44 step:34434 [D loss: 0.673752, acc.: 64.06%] [G loss: 0.830674]\n",
      "epoch:44 step:34435 [D loss: 0.668265, acc.: 61.72%] [G loss: 0.731615]\n",
      "epoch:44 step:34436 [D loss: 0.710684, acc.: 50.00%] [G loss: 0.827044]\n",
      "epoch:44 step:34437 [D loss: 0.642675, acc.: 66.41%] [G loss: 0.796180]\n",
      "epoch:44 step:34438 [D loss: 0.663903, acc.: 62.50%] [G loss: 0.738995]\n",
      "epoch:44 step:34439 [D loss: 0.673432, acc.: 50.00%] [G loss: 0.710524]\n",
      "epoch:44 step:34440 [D loss: 0.678967, acc.: 61.72%] [G loss: 0.765263]\n",
      "epoch:44 step:34441 [D loss: 0.687473, acc.: 54.69%] [G loss: 0.789263]\n",
      "epoch:44 step:34442 [D loss: 0.611344, acc.: 71.09%] [G loss: 0.702149]\n",
      "epoch:44 step:34443 [D loss: 0.628705, acc.: 70.31%] [G loss: 0.861517]\n",
      "epoch:44 step:34444 [D loss: 0.657208, acc.: 60.94%] [G loss: 0.838666]\n",
      "epoch:44 step:34445 [D loss: 0.730223, acc.: 46.88%] [G loss: 0.850146]\n",
      "epoch:44 step:34446 [D loss: 0.657914, acc.: 60.16%] [G loss: 0.810566]\n",
      "epoch:44 step:34447 [D loss: 0.758191, acc.: 39.84%] [G loss: 0.807899]\n",
      "epoch:44 step:34448 [D loss: 0.687284, acc.: 53.12%] [G loss: 0.768734]\n",
      "epoch:44 step:34449 [D loss: 0.711843, acc.: 48.44%] [G loss: 0.876813]\n",
      "epoch:44 step:34450 [D loss: 0.740994, acc.: 46.09%] [G loss: 0.790783]\n",
      "epoch:44 step:34451 [D loss: 0.629773, acc.: 67.19%] [G loss: 0.822449]\n",
      "epoch:44 step:34452 [D loss: 0.704676, acc.: 52.34%] [G loss: 0.839943]\n",
      "epoch:44 step:34453 [D loss: 0.656241, acc.: 61.72%] [G loss: 0.776963]\n",
      "epoch:44 step:34454 [D loss: 0.698915, acc.: 57.81%] [G loss: 0.880165]\n",
      "epoch:44 step:34455 [D loss: 0.707672, acc.: 54.69%] [G loss: 0.680431]\n",
      "epoch:44 step:34456 [D loss: 0.695720, acc.: 53.91%] [G loss: 0.715071]\n",
      "epoch:44 step:34457 [D loss: 0.705914, acc.: 50.00%] [G loss: 0.738858]\n",
      "epoch:44 step:34458 [D loss: 0.695088, acc.: 54.69%] [G loss: 0.730492]\n",
      "epoch:44 step:34459 [D loss: 0.726377, acc.: 47.66%] [G loss: 0.807785]\n",
      "epoch:44 step:34460 [D loss: 0.685019, acc.: 55.47%] [G loss: 0.789255]\n",
      "epoch:44 step:34461 [D loss: 0.687061, acc.: 52.34%] [G loss: 0.731239]\n",
      "epoch:44 step:34462 [D loss: 0.730948, acc.: 42.19%] [G loss: 0.826876]\n",
      "epoch:44 step:34463 [D loss: 0.673381, acc.: 61.72%] [G loss: 0.839932]\n",
      "epoch:44 step:34464 [D loss: 0.691435, acc.: 52.34%] [G loss: 0.803981]\n",
      "epoch:44 step:34465 [D loss: 0.698915, acc.: 51.56%] [G loss: 0.783166]\n",
      "epoch:44 step:34466 [D loss: 0.672189, acc.: 57.03%] [G loss: 0.814162]\n",
      "epoch:44 step:34467 [D loss: 0.735406, acc.: 47.66%] [G loss: 0.691177]\n",
      "epoch:44 step:34468 [D loss: 0.728615, acc.: 48.44%] [G loss: 0.781867]\n",
      "epoch:44 step:34469 [D loss: 0.640260, acc.: 65.62%] [G loss: 0.778876]\n",
      "epoch:44 step:34470 [D loss: 0.649167, acc.: 64.06%] [G loss: 0.852038]\n",
      "epoch:44 step:34471 [D loss: 0.673888, acc.: 53.91%] [G loss: 0.815875]\n",
      "epoch:44 step:34472 [D loss: 0.727212, acc.: 50.00%] [G loss: 0.754704]\n",
      "epoch:44 step:34473 [D loss: 0.708988, acc.: 50.00%] [G loss: 0.758316]\n",
      "epoch:44 step:34474 [D loss: 0.668781, acc.: 57.03%] [G loss: 0.757350]\n",
      "epoch:44 step:34475 [D loss: 0.691533, acc.: 49.22%] [G loss: 0.706734]\n",
      "epoch:44 step:34476 [D loss: 0.668331, acc.: 54.69%] [G loss: 0.762121]\n",
      "epoch:44 step:34477 [D loss: 0.762688, acc.: 36.72%] [G loss: 0.705813]\n",
      "epoch:44 step:34478 [D loss: 0.647908, acc.: 66.41%] [G loss: 0.799943]\n",
      "epoch:44 step:34479 [D loss: 0.707394, acc.: 59.38%] [G loss: 0.747915]\n",
      "epoch:44 step:34480 [D loss: 0.694690, acc.: 53.12%] [G loss: 0.842336]\n",
      "epoch:44 step:34481 [D loss: 0.717538, acc.: 50.78%] [G loss: 0.856077]\n",
      "epoch:44 step:34482 [D loss: 0.706073, acc.: 53.91%] [G loss: 0.813745]\n",
      "epoch:44 step:34483 [D loss: 0.655845, acc.: 65.62%] [G loss: 0.922442]\n",
      "epoch:44 step:34484 [D loss: 0.750982, acc.: 38.28%] [G loss: 0.807153]\n",
      "epoch:44 step:34485 [D loss: 0.675158, acc.: 60.94%] [G loss: 0.830374]\n",
      "epoch:44 step:34486 [D loss: 0.657332, acc.: 62.50%] [G loss: 0.823269]\n",
      "epoch:44 step:34487 [D loss: 0.694655, acc.: 47.66%] [G loss: 0.760259]\n",
      "epoch:44 step:34488 [D loss: 0.661775, acc.: 61.72%] [G loss: 0.870962]\n",
      "epoch:44 step:34489 [D loss: 0.776668, acc.: 35.16%] [G loss: 0.795147]\n",
      "epoch:44 step:34490 [D loss: 0.698897, acc.: 49.22%] [G loss: 0.773399]\n",
      "epoch:44 step:34491 [D loss: 0.706819, acc.: 52.34%] [G loss: 0.770415]\n",
      "epoch:44 step:34492 [D loss: 0.691943, acc.: 59.38%] [G loss: 0.706882]\n",
      "epoch:44 step:34493 [D loss: 0.721498, acc.: 45.31%] [G loss: 0.818586]\n",
      "epoch:44 step:34494 [D loss: 0.718067, acc.: 54.69%] [G loss: 0.702562]\n",
      "epoch:44 step:34495 [D loss: 0.693190, acc.: 57.03%] [G loss: 0.767072]\n",
      "epoch:44 step:34496 [D loss: 0.683338, acc.: 54.69%] [G loss: 0.726537]\n",
      "epoch:44 step:34497 [D loss: 0.725523, acc.: 50.00%] [G loss: 0.767401]\n",
      "epoch:44 step:34498 [D loss: 0.722458, acc.: 44.53%] [G loss: 0.953095]\n",
      "epoch:44 step:34499 [D loss: 0.723774, acc.: 47.66%] [G loss: 0.774612]\n",
      "epoch:44 step:34500 [D loss: 0.662735, acc.: 57.81%] [G loss: 0.842693]\n",
      "epoch:44 step:34501 [D loss: 0.737004, acc.: 42.19%] [G loss: 0.846456]\n",
      "epoch:44 step:34502 [D loss: 0.738219, acc.: 44.53%] [G loss: 0.810402]\n",
      "epoch:44 step:34503 [D loss: 0.694894, acc.: 51.56%] [G loss: 0.832818]\n",
      "epoch:44 step:34504 [D loss: 0.705869, acc.: 52.34%] [G loss: 0.806217]\n",
      "epoch:44 step:34505 [D loss: 0.676991, acc.: 60.16%] [G loss: 0.820862]\n",
      "epoch:44 step:34506 [D loss: 0.719181, acc.: 48.44%] [G loss: 0.758716]\n",
      "epoch:44 step:34507 [D loss: 0.656875, acc.: 64.06%] [G loss: 0.829625]\n",
      "epoch:44 step:34508 [D loss: 0.678322, acc.: 58.59%] [G loss: 0.756025]\n",
      "epoch:44 step:34509 [D loss: 0.626354, acc.: 71.09%] [G loss: 0.858512]\n",
      "epoch:44 step:34510 [D loss: 0.608196, acc.: 69.53%] [G loss: 0.825718]\n",
      "epoch:44 step:34511 [D loss: 0.675370, acc.: 53.91%] [G loss: 0.853921]\n",
      "epoch:44 step:34512 [D loss: 0.629509, acc.: 65.62%] [G loss: 0.786134]\n",
      "epoch:44 step:34513 [D loss: 0.633990, acc.: 66.41%] [G loss: 0.787935]\n",
      "epoch:44 step:34514 [D loss: 0.718395, acc.: 51.56%] [G loss: 0.746983]\n",
      "epoch:44 step:34515 [D loss: 0.633008, acc.: 71.88%] [G loss: 0.793815]\n",
      "epoch:44 step:34516 [D loss: 0.664475, acc.: 56.25%] [G loss: 0.800309]\n",
      "epoch:44 step:34517 [D loss: 0.657441, acc.: 60.16%] [G loss: 0.766836]\n",
      "epoch:44 step:34518 [D loss: 0.675157, acc.: 53.12%] [G loss: 0.847156]\n",
      "epoch:44 step:34519 [D loss: 0.740714, acc.: 36.72%] [G loss: 0.787465]\n",
      "epoch:44 step:34520 [D loss: 0.692837, acc.: 50.00%] [G loss: 0.816142]\n",
      "epoch:44 step:34521 [D loss: 0.700296, acc.: 57.81%] [G loss: 0.833478]\n",
      "epoch:44 step:34522 [D loss: 0.643662, acc.: 64.84%] [G loss: 0.848583]\n",
      "epoch:44 step:34523 [D loss: 0.675502, acc.: 57.03%] [G loss: 0.767296]\n",
      "epoch:44 step:34524 [D loss: 0.650969, acc.: 71.09%] [G loss: 0.800544]\n",
      "epoch:44 step:34525 [D loss: 0.676393, acc.: 57.03%] [G loss: 0.761438]\n",
      "epoch:44 step:34526 [D loss: 0.688075, acc.: 50.00%] [G loss: 0.795307]\n",
      "epoch:44 step:34527 [D loss: 0.674469, acc.: 57.81%] [G loss: 0.811243]\n",
      "epoch:44 step:34528 [D loss: 0.680008, acc.: 55.47%] [G loss: 0.755755]\n",
      "epoch:44 step:34529 [D loss: 0.686642, acc.: 53.91%] [G loss: 0.846207]\n",
      "epoch:44 step:34530 [D loss: 0.728444, acc.: 42.97%] [G loss: 0.844757]\n",
      "epoch:44 step:34531 [D loss: 0.739190, acc.: 42.19%] [G loss: 0.730546]\n",
      "epoch:44 step:34532 [D loss: 0.652883, acc.: 64.84%] [G loss: 0.831475]\n",
      "epoch:44 step:34533 [D loss: 0.682152, acc.: 57.03%] [G loss: 0.764904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34534 [D loss: 0.624341, acc.: 71.09%] [G loss: 0.817077]\n",
      "epoch:44 step:34535 [D loss: 0.697405, acc.: 53.12%] [G loss: 0.825613]\n",
      "epoch:44 step:34536 [D loss: 0.707473, acc.: 51.56%] [G loss: 0.814122]\n",
      "epoch:44 step:34537 [D loss: 0.698833, acc.: 53.12%] [G loss: 0.786438]\n",
      "epoch:44 step:34538 [D loss: 0.760407, acc.: 39.06%] [G loss: 0.852496]\n",
      "epoch:44 step:34539 [D loss: 0.652702, acc.: 62.50%] [G loss: 0.794813]\n",
      "epoch:44 step:34540 [D loss: 0.596810, acc.: 79.69%] [G loss: 0.887410]\n",
      "epoch:44 step:34541 [D loss: 0.648968, acc.: 65.62%] [G loss: 0.825822]\n",
      "epoch:44 step:34542 [D loss: 0.780302, acc.: 39.06%] [G loss: 0.744399]\n",
      "epoch:44 step:34543 [D loss: 0.596314, acc.: 71.88%] [G loss: 0.850947]\n",
      "epoch:44 step:34544 [D loss: 0.721154, acc.: 44.53%] [G loss: 0.805618]\n",
      "epoch:44 step:34545 [D loss: 0.713751, acc.: 47.66%] [G loss: 0.815075]\n",
      "epoch:44 step:34546 [D loss: 0.717033, acc.: 49.22%] [G loss: 0.828408]\n",
      "epoch:44 step:34547 [D loss: 0.674603, acc.: 57.81%] [G loss: 0.769142]\n",
      "epoch:44 step:34548 [D loss: 0.666364, acc.: 62.50%] [G loss: 0.786870]\n",
      "epoch:44 step:34549 [D loss: 0.627099, acc.: 67.19%] [G loss: 0.750609]\n",
      "epoch:44 step:34550 [D loss: 0.728791, acc.: 52.34%] [G loss: 0.822732]\n",
      "epoch:44 step:34551 [D loss: 0.647874, acc.: 67.19%] [G loss: 0.891497]\n",
      "epoch:44 step:34552 [D loss: 0.643377, acc.: 62.50%] [G loss: 0.831815]\n",
      "epoch:44 step:34553 [D loss: 0.594323, acc.: 74.22%] [G loss: 0.837865]\n",
      "epoch:44 step:34554 [D loss: 0.740720, acc.: 39.84%] [G loss: 0.778395]\n",
      "epoch:44 step:34555 [D loss: 0.656061, acc.: 58.59%] [G loss: 0.802678]\n",
      "epoch:44 step:34556 [D loss: 0.721694, acc.: 50.00%] [G loss: 0.811382]\n",
      "epoch:44 step:34557 [D loss: 0.640718, acc.: 64.84%] [G loss: 0.833600]\n",
      "epoch:44 step:34558 [D loss: 0.696209, acc.: 53.91%] [G loss: 0.801221]\n",
      "epoch:44 step:34559 [D loss: 0.679972, acc.: 60.94%] [G loss: 0.794996]\n",
      "epoch:44 step:34560 [D loss: 0.694461, acc.: 56.25%] [G loss: 0.831108]\n",
      "epoch:44 step:34561 [D loss: 0.695491, acc.: 53.12%] [G loss: 0.823223]\n",
      "epoch:44 step:34562 [D loss: 0.628123, acc.: 67.97%] [G loss: 0.828478]\n",
      "epoch:44 step:34563 [D loss: 0.700551, acc.: 50.78%] [G loss: 0.764726]\n",
      "epoch:44 step:34564 [D loss: 0.726697, acc.: 50.78%] [G loss: 0.730206]\n",
      "epoch:44 step:34565 [D loss: 0.628159, acc.: 61.72%] [G loss: 0.795420]\n",
      "epoch:44 step:34566 [D loss: 0.705259, acc.: 43.75%] [G loss: 0.807892]\n",
      "epoch:44 step:34567 [D loss: 0.715693, acc.: 46.09%] [G loss: 0.867600]\n",
      "epoch:44 step:34568 [D loss: 0.713816, acc.: 45.31%] [G loss: 0.813549]\n",
      "epoch:44 step:34569 [D loss: 0.672325, acc.: 58.59%] [G loss: 0.729547]\n",
      "epoch:44 step:34570 [D loss: 0.647587, acc.: 60.16%] [G loss: 0.766441]\n",
      "epoch:44 step:34571 [D loss: 0.639752, acc.: 63.28%] [G loss: 0.754355]\n",
      "epoch:44 step:34572 [D loss: 0.713729, acc.: 47.66%] [G loss: 0.862912]\n",
      "epoch:44 step:34573 [D loss: 0.723771, acc.: 49.22%] [G loss: 0.882795]\n",
      "epoch:44 step:34574 [D loss: 0.624324, acc.: 71.88%] [G loss: 0.862248]\n",
      "epoch:44 step:34575 [D loss: 0.661546, acc.: 64.06%] [G loss: 0.737329]\n",
      "epoch:44 step:34576 [D loss: 0.616055, acc.: 71.09%] [G loss: 0.841129]\n",
      "epoch:44 step:34577 [D loss: 0.703420, acc.: 56.25%] [G loss: 0.831814]\n",
      "epoch:44 step:34578 [D loss: 0.743614, acc.: 35.94%] [G loss: 0.756647]\n",
      "epoch:44 step:34579 [D loss: 0.638675, acc.: 66.41%] [G loss: 0.777631]\n",
      "epoch:44 step:34580 [D loss: 0.732863, acc.: 44.53%] [G loss: 0.758418]\n",
      "epoch:44 step:34581 [D loss: 0.638031, acc.: 66.41%] [G loss: 0.799354]\n",
      "epoch:44 step:34582 [D loss: 0.687046, acc.: 57.81%] [G loss: 0.786623]\n",
      "epoch:44 step:34583 [D loss: 0.674199, acc.: 57.81%] [G loss: 0.818248]\n",
      "epoch:44 step:34584 [D loss: 0.655810, acc.: 61.72%] [G loss: 0.795913]\n",
      "epoch:44 step:34585 [D loss: 0.650410, acc.: 60.94%] [G loss: 0.835389]\n",
      "epoch:44 step:34586 [D loss: 0.698061, acc.: 50.00%] [G loss: 0.736937]\n",
      "epoch:44 step:34587 [D loss: 0.660290, acc.: 63.28%] [G loss: 0.753743]\n",
      "epoch:44 step:34588 [D loss: 0.667947, acc.: 61.72%] [G loss: 0.727764]\n",
      "epoch:44 step:34589 [D loss: 0.658366, acc.: 58.59%] [G loss: 0.734354]\n",
      "epoch:44 step:34590 [D loss: 0.712815, acc.: 53.91%] [G loss: 0.730750]\n",
      "epoch:44 step:34591 [D loss: 0.663050, acc.: 60.94%] [G loss: 0.755303]\n",
      "epoch:44 step:34592 [D loss: 0.698352, acc.: 55.47%] [G loss: 0.687723]\n",
      "epoch:44 step:34593 [D loss: 0.701275, acc.: 46.88%] [G loss: 0.815566]\n",
      "epoch:44 step:34594 [D loss: 0.764229, acc.: 39.84%] [G loss: 0.690791]\n",
      "epoch:44 step:34595 [D loss: 0.661691, acc.: 61.72%] [G loss: 0.760571]\n",
      "epoch:44 step:34596 [D loss: 0.702044, acc.: 49.22%] [G loss: 0.723925]\n",
      "epoch:44 step:34597 [D loss: 0.690156, acc.: 57.81%] [G loss: 0.780658]\n",
      "epoch:44 step:34598 [D loss: 0.672122, acc.: 58.59%] [G loss: 0.731097]\n",
      "epoch:44 step:34599 [D loss: 0.700387, acc.: 51.56%] [G loss: 0.756117]\n",
      "epoch:44 step:34600 [D loss: 0.681053, acc.: 51.56%] [G loss: 0.743693]\n",
      "epoch:44 step:34601 [D loss: 0.712248, acc.: 53.12%] [G loss: 0.741953]\n",
      "epoch:44 step:34602 [D loss: 0.677746, acc.: 59.38%] [G loss: 0.725751]\n",
      "epoch:44 step:34603 [D loss: 0.669861, acc.: 55.47%] [G loss: 0.702406]\n",
      "epoch:44 step:34604 [D loss: 0.729747, acc.: 51.56%] [G loss: 0.898440]\n",
      "epoch:44 step:34605 [D loss: 0.669370, acc.: 63.28%] [G loss: 0.784901]\n",
      "epoch:44 step:34606 [D loss: 0.617219, acc.: 69.53%] [G loss: 0.836096]\n",
      "epoch:44 step:34607 [D loss: 0.750987, acc.: 44.53%] [G loss: 0.829749]\n",
      "epoch:44 step:34608 [D loss: 0.622431, acc.: 71.09%] [G loss: 0.854212]\n",
      "epoch:44 step:34609 [D loss: 0.701621, acc.: 53.91%] [G loss: 0.759448]\n",
      "epoch:44 step:34610 [D loss: 0.672933, acc.: 60.16%] [G loss: 0.847026]\n",
      "epoch:44 step:34611 [D loss: 0.658680, acc.: 59.38%] [G loss: 0.858401]\n",
      "epoch:44 step:34612 [D loss: 0.648113, acc.: 62.50%] [G loss: 0.833822]\n",
      "epoch:44 step:34613 [D loss: 0.639123, acc.: 63.28%] [G loss: 0.856833]\n",
      "epoch:44 step:34614 [D loss: 0.633759, acc.: 66.41%] [G loss: 0.871413]\n",
      "epoch:44 step:34615 [D loss: 0.692192, acc.: 57.03%] [G loss: 0.671977]\n",
      "epoch:44 step:34616 [D loss: 0.677163, acc.: 55.47%] [G loss: 0.778013]\n",
      "epoch:44 step:34617 [D loss: 0.710302, acc.: 45.31%] [G loss: 0.770234]\n",
      "epoch:44 step:34618 [D loss: 0.784115, acc.: 34.38%] [G loss: 0.701942]\n",
      "epoch:44 step:34619 [D loss: 0.757001, acc.: 41.41%] [G loss: 0.759312]\n",
      "epoch:44 step:34620 [D loss: 0.650963, acc.: 66.41%] [G loss: 0.797296]\n",
      "epoch:44 step:34621 [D loss: 0.680458, acc.: 57.81%] [G loss: 0.788394]\n",
      "epoch:44 step:34622 [D loss: 0.706817, acc.: 47.66%] [G loss: 0.771459]\n",
      "epoch:44 step:34623 [D loss: 0.694378, acc.: 49.22%] [G loss: 0.778537]\n",
      "epoch:44 step:34624 [D loss: 0.730110, acc.: 46.88%] [G loss: 0.860428]\n",
      "epoch:44 step:34625 [D loss: 0.647463, acc.: 62.50%] [G loss: 0.917933]\n",
      "epoch:44 step:34626 [D loss: 0.741529, acc.: 43.75%] [G loss: 0.906759]\n",
      "epoch:44 step:34627 [D loss: 0.711842, acc.: 50.00%] [G loss: 0.931851]\n",
      "epoch:44 step:34628 [D loss: 0.714768, acc.: 52.34%] [G loss: 0.934517]\n",
      "epoch:44 step:34629 [D loss: 0.674765, acc.: 56.25%] [G loss: 0.929561]\n",
      "epoch:44 step:34630 [D loss: 0.702321, acc.: 52.34%] [G loss: 0.799514]\n",
      "epoch:44 step:34631 [D loss: 0.721169, acc.: 50.00%] [G loss: 0.828788]\n",
      "epoch:44 step:34632 [D loss: 0.674113, acc.: 59.38%] [G loss: 0.795701]\n",
      "epoch:44 step:34633 [D loss: 0.661218, acc.: 58.59%] [G loss: 0.860699]\n",
      "epoch:44 step:34634 [D loss: 0.643027, acc.: 64.06%] [G loss: 0.926407]\n",
      "epoch:44 step:34635 [D loss: 0.727356, acc.: 42.97%] [G loss: 0.715849]\n",
      "epoch:44 step:34636 [D loss: 0.643540, acc.: 64.84%] [G loss: 0.848099]\n",
      "epoch:44 step:34637 [D loss: 0.697577, acc.: 54.69%] [G loss: 0.723941]\n",
      "epoch:44 step:34638 [D loss: 0.640795, acc.: 65.62%] [G loss: 0.799251]\n",
      "epoch:44 step:34639 [D loss: 0.652030, acc.: 61.72%] [G loss: 0.831536]\n",
      "epoch:44 step:34640 [D loss: 0.658030, acc.: 60.94%] [G loss: 0.790412]\n",
      "epoch:44 step:34641 [D loss: 0.673894, acc.: 57.81%] [G loss: 0.786164]\n",
      "epoch:44 step:34642 [D loss: 0.678284, acc.: 60.16%] [G loss: 0.702688]\n",
      "epoch:44 step:34643 [D loss: 0.672996, acc.: 61.72%] [G loss: 0.761243]\n",
      "epoch:44 step:34644 [D loss: 0.606463, acc.: 70.31%] [G loss: 0.774993]\n",
      "epoch:44 step:34645 [D loss: 0.668680, acc.: 62.50%] [G loss: 0.781461]\n",
      "epoch:44 step:34646 [D loss: 0.722597, acc.: 41.41%] [G loss: 0.745946]\n",
      "epoch:44 step:34647 [D loss: 0.697963, acc.: 59.38%] [G loss: 0.842647]\n",
      "epoch:44 step:34648 [D loss: 0.667206, acc.: 61.72%] [G loss: 0.822658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34649 [D loss: 0.685716, acc.: 58.59%] [G loss: 0.892098]\n",
      "epoch:44 step:34650 [D loss: 0.672529, acc.: 64.06%] [G loss: 0.842474]\n",
      "epoch:44 step:34651 [D loss: 0.710644, acc.: 50.78%] [G loss: 0.840500]\n",
      "epoch:44 step:34652 [D loss: 0.679294, acc.: 53.12%] [G loss: 0.799429]\n",
      "epoch:44 step:34653 [D loss: 0.718357, acc.: 50.78%] [G loss: 0.750808]\n",
      "epoch:44 step:34654 [D loss: 0.632447, acc.: 67.97%] [G loss: 0.845298]\n",
      "epoch:44 step:34655 [D loss: 0.686549, acc.: 54.69%] [G loss: 0.808496]\n",
      "epoch:44 step:34656 [D loss: 0.666363, acc.: 60.16%] [G loss: 0.803022]\n",
      "epoch:44 step:34657 [D loss: 0.671731, acc.: 54.69%] [G loss: 0.842646]\n",
      "epoch:44 step:34658 [D loss: 0.652436, acc.: 61.72%] [G loss: 0.806594]\n",
      "epoch:44 step:34659 [D loss: 0.673781, acc.: 57.03%] [G loss: 0.849182]\n",
      "epoch:44 step:34660 [D loss: 0.678529, acc.: 57.81%] [G loss: 0.793797]\n",
      "epoch:44 step:34661 [D loss: 0.688684, acc.: 64.84%] [G loss: 0.754216]\n",
      "epoch:44 step:34662 [D loss: 0.710904, acc.: 48.44%] [G loss: 0.795642]\n",
      "epoch:44 step:34663 [D loss: 0.706814, acc.: 47.66%] [G loss: 0.725554]\n",
      "epoch:44 step:34664 [D loss: 0.701270, acc.: 53.91%] [G loss: 0.741732]\n",
      "epoch:44 step:34665 [D loss: 0.733537, acc.: 42.97%] [G loss: 0.760428]\n",
      "epoch:44 step:34666 [D loss: 0.648058, acc.: 62.50%] [G loss: 0.831764]\n",
      "epoch:44 step:34667 [D loss: 0.672099, acc.: 65.62%] [G loss: 0.860409]\n",
      "epoch:44 step:34668 [D loss: 0.680820, acc.: 57.81%] [G loss: 0.819728]\n",
      "epoch:44 step:34669 [D loss: 0.654498, acc.: 59.38%] [G loss: 0.830582]\n",
      "epoch:44 step:34670 [D loss: 0.655263, acc.: 63.28%] [G loss: 0.802107]\n",
      "epoch:44 step:34671 [D loss: 0.651201, acc.: 61.72%] [G loss: 0.743442]\n",
      "epoch:44 step:34672 [D loss: 0.659738, acc.: 64.06%] [G loss: 0.751058]\n",
      "epoch:44 step:34673 [D loss: 0.638648, acc.: 63.28%] [G loss: 0.866660]\n",
      "epoch:44 step:34674 [D loss: 0.673834, acc.: 57.03%] [G loss: 0.686553]\n",
      "epoch:44 step:34675 [D loss: 0.646272, acc.: 62.50%] [G loss: 0.683944]\n",
      "epoch:44 step:34676 [D loss: 0.737926, acc.: 47.66%] [G loss: 0.799562]\n",
      "epoch:44 step:34677 [D loss: 0.701787, acc.: 48.44%] [G loss: 0.717739]\n",
      "epoch:44 step:34678 [D loss: 0.708645, acc.: 50.00%] [G loss: 0.739474]\n",
      "epoch:44 step:34679 [D loss: 0.769716, acc.: 35.94%] [G loss: 0.735382]\n",
      "epoch:44 step:34680 [D loss: 0.662536, acc.: 63.28%] [G loss: 0.743519]\n",
      "epoch:44 step:34681 [D loss: 0.705457, acc.: 52.34%] [G loss: 0.730499]\n",
      "epoch:44 step:34682 [D loss: 0.690507, acc.: 53.12%] [G loss: 0.754273]\n",
      "epoch:44 step:34683 [D loss: 0.648611, acc.: 66.41%] [G loss: 0.720561]\n",
      "epoch:44 step:34684 [D loss: 0.762212, acc.: 39.84%] [G loss: 0.766199]\n",
      "epoch:44 step:34685 [D loss: 0.652189, acc.: 60.94%] [G loss: 0.778853]\n",
      "epoch:44 step:34686 [D loss: 0.680806, acc.: 57.03%] [G loss: 0.803472]\n",
      "epoch:44 step:34687 [D loss: 0.763827, acc.: 41.41%] [G loss: 0.745480]\n",
      "epoch:44 step:34688 [D loss: 0.660363, acc.: 59.38%] [G loss: 0.721696]\n",
      "epoch:44 step:34689 [D loss: 0.604391, acc.: 75.00%] [G loss: 0.793382]\n",
      "epoch:44 step:34690 [D loss: 0.669090, acc.: 54.69%] [G loss: 0.804485]\n",
      "epoch:44 step:34691 [D loss: 0.598881, acc.: 75.78%] [G loss: 0.775979]\n",
      "epoch:44 step:34692 [D loss: 0.697475, acc.: 51.56%] [G loss: 0.711093]\n",
      "epoch:44 step:34693 [D loss: 0.685890, acc.: 52.34%] [G loss: 0.686294]\n",
      "epoch:44 step:34694 [D loss: 0.654026, acc.: 56.25%] [G loss: 0.749269]\n",
      "epoch:44 step:34695 [D loss: 0.709618, acc.: 53.91%] [G loss: 0.820362]\n",
      "epoch:44 step:34696 [D loss: 0.673533, acc.: 59.38%] [G loss: 0.749890]\n",
      "epoch:44 step:34697 [D loss: 0.677048, acc.: 53.12%] [G loss: 0.815345]\n",
      "epoch:44 step:34698 [D loss: 0.650846, acc.: 68.75%] [G loss: 0.811867]\n",
      "epoch:44 step:34699 [D loss: 0.659376, acc.: 56.25%] [G loss: 0.708880]\n",
      "epoch:44 step:34700 [D loss: 0.726309, acc.: 47.66%] [G loss: 0.783861]\n",
      "epoch:44 step:34701 [D loss: 0.727948, acc.: 50.78%] [G loss: 0.867082]\n",
      "epoch:44 step:34702 [D loss: 0.738415, acc.: 44.53%] [G loss: 0.788945]\n",
      "epoch:44 step:34703 [D loss: 0.746511, acc.: 40.62%] [G loss: 0.794814]\n",
      "epoch:44 step:34704 [D loss: 0.696957, acc.: 50.00%] [G loss: 0.824377]\n",
      "epoch:44 step:34705 [D loss: 0.706445, acc.: 50.00%] [G loss: 0.782930]\n",
      "epoch:44 step:34706 [D loss: 0.663781, acc.: 64.84%] [G loss: 0.796805]\n",
      "epoch:44 step:34707 [D loss: 0.658979, acc.: 59.38%] [G loss: 0.765884]\n",
      "epoch:44 step:34708 [D loss: 0.693100, acc.: 51.56%] [G loss: 0.706203]\n",
      "epoch:44 step:34709 [D loss: 0.689472, acc.: 53.91%] [G loss: 0.807796]\n",
      "epoch:44 step:34710 [D loss: 0.687465, acc.: 54.69%] [G loss: 0.764807]\n",
      "epoch:44 step:34711 [D loss: 0.743634, acc.: 39.06%] [G loss: 0.719871]\n",
      "epoch:44 step:34712 [D loss: 0.710556, acc.: 47.66%] [G loss: 0.808253]\n",
      "epoch:44 step:34713 [D loss: 0.668470, acc.: 57.81%] [G loss: 0.787402]\n",
      "epoch:44 step:34714 [D loss: 0.749328, acc.: 42.19%] [G loss: 0.780704]\n",
      "epoch:44 step:34715 [D loss: 0.681095, acc.: 58.59%] [G loss: 0.843715]\n",
      "epoch:44 step:34716 [D loss: 0.710899, acc.: 49.22%] [G loss: 0.833039]\n",
      "epoch:44 step:34717 [D loss: 0.645371, acc.: 61.72%] [G loss: 0.704585]\n",
      "epoch:44 step:34718 [D loss: 0.701618, acc.: 48.44%] [G loss: 0.873516]\n",
      "epoch:44 step:34719 [D loss: 0.717449, acc.: 50.00%] [G loss: 0.850640]\n",
      "epoch:44 step:34720 [D loss: 0.695903, acc.: 53.91%] [G loss: 0.815575]\n",
      "epoch:44 step:34721 [D loss: 0.670371, acc.: 60.16%] [G loss: 0.853846]\n",
      "epoch:44 step:34722 [D loss: 0.716717, acc.: 51.56%] [G loss: 0.883445]\n",
      "epoch:44 step:34723 [D loss: 0.643785, acc.: 66.41%] [G loss: 0.915705]\n",
      "epoch:44 step:34724 [D loss: 0.760455, acc.: 36.72%] [G loss: 0.811281]\n",
      "epoch:44 step:34725 [D loss: 0.676000, acc.: 59.38%] [G loss: 0.895748]\n",
      "epoch:44 step:34726 [D loss: 0.611345, acc.: 71.09%] [G loss: 0.814452]\n",
      "epoch:44 step:34727 [D loss: 0.707571, acc.: 53.12%] [G loss: 0.736725]\n",
      "epoch:44 step:34728 [D loss: 0.798802, acc.: 35.16%] [G loss: 0.834076]\n",
      "epoch:44 step:34729 [D loss: 0.695927, acc.: 51.56%] [G loss: 0.818268]\n",
      "epoch:44 step:34730 [D loss: 0.687846, acc.: 56.25%] [G loss: 0.752966]\n",
      "epoch:44 step:34731 [D loss: 0.721850, acc.: 45.31%] [G loss: 0.798543]\n",
      "epoch:44 step:34732 [D loss: 0.651985, acc.: 63.28%] [G loss: 0.829166]\n",
      "epoch:44 step:34733 [D loss: 0.689720, acc.: 50.78%] [G loss: 0.809516]\n",
      "epoch:44 step:34734 [D loss: 0.699744, acc.: 51.56%] [G loss: 0.833418]\n",
      "epoch:44 step:34735 [D loss: 0.636597, acc.: 63.28%] [G loss: 0.813427]\n",
      "epoch:44 step:34736 [D loss: 0.660499, acc.: 58.59%] [G loss: 0.743322]\n",
      "epoch:44 step:34737 [D loss: 0.729228, acc.: 48.44%] [G loss: 0.824112]\n",
      "epoch:44 step:34738 [D loss: 0.689684, acc.: 53.12%] [G loss: 0.815872]\n",
      "epoch:44 step:34739 [D loss: 0.641313, acc.: 63.28%] [G loss: 0.709963]\n",
      "epoch:44 step:34740 [D loss: 0.687739, acc.: 54.69%] [G loss: 0.790770]\n",
      "epoch:44 step:34741 [D loss: 0.698391, acc.: 51.56%] [G loss: 0.858975]\n",
      "epoch:44 step:34742 [D loss: 0.641125, acc.: 67.97%] [G loss: 0.743479]\n",
      "epoch:44 step:34743 [D loss: 0.692306, acc.: 59.38%] [G loss: 0.782558]\n",
      "epoch:44 step:34744 [D loss: 0.674216, acc.: 60.16%] [G loss: 0.745743]\n",
      "epoch:44 step:34745 [D loss: 0.614822, acc.: 70.31%] [G loss: 0.732307]\n",
      "epoch:44 step:34746 [D loss: 0.681245, acc.: 60.16%] [G loss: 0.869445]\n",
      "epoch:44 step:34747 [D loss: 0.683978, acc.: 57.03%] [G loss: 0.780654]\n",
      "epoch:44 step:34748 [D loss: 0.619780, acc.: 71.88%] [G loss: 0.777591]\n",
      "epoch:44 step:34749 [D loss: 0.661926, acc.: 65.62%] [G loss: 0.837496]\n",
      "epoch:44 step:34750 [D loss: 0.623156, acc.: 73.44%] [G loss: 0.791723]\n",
      "epoch:44 step:34751 [D loss: 0.611861, acc.: 76.56%] [G loss: 0.850408]\n",
      "epoch:44 step:34752 [D loss: 0.682032, acc.: 60.16%] [G loss: 0.892412]\n",
      "epoch:44 step:34753 [D loss: 0.709230, acc.: 48.44%] [G loss: 0.885005]\n",
      "epoch:44 step:34754 [D loss: 0.681460, acc.: 53.91%] [G loss: 0.901107]\n",
      "epoch:44 step:34755 [D loss: 0.711092, acc.: 53.12%] [G loss: 0.762553]\n",
      "epoch:44 step:34756 [D loss: 0.728133, acc.: 46.09%] [G loss: 0.829969]\n",
      "epoch:44 step:34757 [D loss: 0.663319, acc.: 63.28%] [G loss: 0.837547]\n",
      "epoch:44 step:34758 [D loss: 0.670670, acc.: 57.03%] [G loss: 0.793528]\n",
      "epoch:44 step:34759 [D loss: 0.686154, acc.: 55.47%] [G loss: 0.768806]\n",
      "epoch:44 step:34760 [D loss: 0.644129, acc.: 66.41%] [G loss: 0.838768]\n",
      "epoch:44 step:34761 [D loss: 0.697459, acc.: 56.25%] [G loss: 0.753753]\n",
      "epoch:44 step:34762 [D loss: 0.709119, acc.: 52.34%] [G loss: 0.741466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34763 [D loss: 0.624548, acc.: 67.97%] [G loss: 0.834736]\n",
      "epoch:44 step:34764 [D loss: 0.659862, acc.: 60.94%] [G loss: 0.821195]\n",
      "epoch:44 step:34765 [D loss: 0.672650, acc.: 57.81%] [G loss: 0.768943]\n",
      "epoch:44 step:34766 [D loss: 0.645439, acc.: 62.50%] [G loss: 0.762048]\n",
      "epoch:44 step:34767 [D loss: 0.665157, acc.: 58.59%] [G loss: 0.779694]\n",
      "epoch:44 step:34768 [D loss: 0.664718, acc.: 61.72%] [G loss: 0.791635]\n",
      "epoch:44 step:34769 [D loss: 0.662527, acc.: 59.38%] [G loss: 0.894736]\n",
      "epoch:44 step:34770 [D loss: 0.724068, acc.: 46.09%] [G loss: 0.850240]\n",
      "epoch:44 step:34771 [D loss: 0.694228, acc.: 50.00%] [G loss: 0.850604]\n",
      "epoch:44 step:34772 [D loss: 0.749240, acc.: 44.53%] [G loss: 0.774692]\n",
      "epoch:44 step:34773 [D loss: 0.695437, acc.: 54.69%] [G loss: 0.798970]\n",
      "epoch:44 step:34774 [D loss: 0.586414, acc.: 79.69%] [G loss: 0.844407]\n",
      "epoch:44 step:34775 [D loss: 0.773124, acc.: 38.28%] [G loss: 0.760150]\n",
      "epoch:44 step:34776 [D loss: 0.729391, acc.: 47.66%] [G loss: 0.800073]\n",
      "epoch:44 step:34777 [D loss: 0.667082, acc.: 59.38%] [G loss: 0.699290]\n",
      "epoch:44 step:34778 [D loss: 0.723885, acc.: 46.09%] [G loss: 0.680757]\n",
      "epoch:44 step:34779 [D loss: 0.681447, acc.: 60.94%] [G loss: 0.777160]\n",
      "epoch:44 step:34780 [D loss: 0.683097, acc.: 53.12%] [G loss: 0.783810]\n",
      "epoch:44 step:34781 [D loss: 0.656669, acc.: 63.28%] [G loss: 0.819281]\n",
      "epoch:44 step:34782 [D loss: 0.693630, acc.: 61.72%] [G loss: 0.785917]\n",
      "epoch:44 step:34783 [D loss: 0.683902, acc.: 54.69%] [G loss: 0.841560]\n",
      "epoch:44 step:34784 [D loss: 0.681966, acc.: 57.81%] [G loss: 0.775676]\n",
      "epoch:44 step:34785 [D loss: 0.687373, acc.: 54.69%] [G loss: 0.819937]\n",
      "epoch:44 step:34786 [D loss: 0.726100, acc.: 48.44%] [G loss: 0.833471]\n",
      "epoch:44 step:34787 [D loss: 0.702075, acc.: 50.00%] [G loss: 0.805384]\n",
      "epoch:44 step:34788 [D loss: 0.702519, acc.: 51.56%] [G loss: 0.763437]\n",
      "epoch:44 step:34789 [D loss: 0.668947, acc.: 53.12%] [G loss: 0.774728]\n",
      "epoch:44 step:34790 [D loss: 0.677237, acc.: 54.69%] [G loss: 0.768919]\n",
      "epoch:44 step:34791 [D loss: 0.697132, acc.: 57.03%] [G loss: 0.695524]\n",
      "epoch:44 step:34792 [D loss: 0.712490, acc.: 47.66%] [G loss: 0.759069]\n",
      "epoch:44 step:34793 [D loss: 0.611758, acc.: 74.22%] [G loss: 0.723443]\n",
      "epoch:44 step:34794 [D loss: 0.700955, acc.: 53.12%] [G loss: 0.794132]\n",
      "epoch:44 step:34795 [D loss: 0.741977, acc.: 41.41%] [G loss: 0.765288]\n",
      "epoch:44 step:34796 [D loss: 0.642624, acc.: 66.41%] [G loss: 0.775975]\n",
      "epoch:44 step:34797 [D loss: 0.705305, acc.: 46.88%] [G loss: 0.853183]\n",
      "epoch:44 step:34798 [D loss: 0.706853, acc.: 47.66%] [G loss: 0.783809]\n",
      "epoch:44 step:34799 [D loss: 0.721083, acc.: 45.31%] [G loss: 0.710255]\n",
      "epoch:44 step:34800 [D loss: 0.718379, acc.: 51.56%] [G loss: 0.830141]\n",
      "epoch:44 step:34801 [D loss: 0.708302, acc.: 49.22%] [G loss: 0.750228]\n",
      "epoch:44 step:34802 [D loss: 0.645716, acc.: 64.06%] [G loss: 0.797038]\n",
      "epoch:44 step:34803 [D loss: 0.657943, acc.: 62.50%] [G loss: 0.814584]\n",
      "epoch:44 step:34804 [D loss: 0.665998, acc.: 57.81%] [G loss: 0.787230]\n",
      "epoch:44 step:34805 [D loss: 0.688644, acc.: 54.69%] [G loss: 0.792301]\n",
      "epoch:44 step:34806 [D loss: 0.668305, acc.: 59.38%] [G loss: 0.802038]\n",
      "epoch:44 step:34807 [D loss: 0.648615, acc.: 63.28%] [G loss: 0.849114]\n",
      "epoch:44 step:34808 [D loss: 0.652877, acc.: 64.06%] [G loss: 0.756160]\n",
      "epoch:44 step:34809 [D loss: 0.667281, acc.: 59.38%] [G loss: 0.868773]\n",
      "epoch:44 step:34810 [D loss: 0.737028, acc.: 40.62%] [G loss: 0.829015]\n",
      "epoch:44 step:34811 [D loss: 0.662172, acc.: 59.38%] [G loss: 0.783813]\n",
      "epoch:44 step:34812 [D loss: 0.650476, acc.: 64.06%] [G loss: 0.796265]\n",
      "epoch:44 step:34813 [D loss: 0.682545, acc.: 58.59%] [G loss: 0.798302]\n",
      "epoch:44 step:34814 [D loss: 0.729548, acc.: 46.88%] [G loss: 0.822825]\n",
      "epoch:44 step:34815 [D loss: 0.732191, acc.: 46.09%] [G loss: 0.803815]\n",
      "epoch:44 step:34816 [D loss: 0.635203, acc.: 62.50%] [G loss: 0.862423]\n",
      "epoch:44 step:34817 [D loss: 0.730390, acc.: 50.00%] [G loss: 0.796291]\n",
      "epoch:44 step:34818 [D loss: 0.676359, acc.: 64.06%] [G loss: 0.828716]\n",
      "epoch:44 step:34819 [D loss: 0.693541, acc.: 50.78%] [G loss: 0.758511]\n",
      "epoch:44 step:34820 [D loss: 0.704096, acc.: 51.56%] [G loss: 0.791183]\n",
      "epoch:44 step:34821 [D loss: 0.658950, acc.: 64.06%] [G loss: 0.769391]\n",
      "epoch:44 step:34822 [D loss: 0.692421, acc.: 54.69%] [G loss: 0.741306]\n",
      "epoch:44 step:34823 [D loss: 0.694953, acc.: 54.69%] [G loss: 0.763829]\n",
      "epoch:44 step:34824 [D loss: 0.649239, acc.: 65.62%] [G loss: 0.846366]\n",
      "epoch:44 step:34825 [D loss: 0.677842, acc.: 60.94%] [G loss: 0.832409]\n",
      "epoch:44 step:34826 [D loss: 0.687243, acc.: 55.47%] [G loss: 0.798189]\n",
      "epoch:44 step:34827 [D loss: 0.641161, acc.: 65.62%] [G loss: 0.833503]\n",
      "epoch:44 step:34828 [D loss: 0.652678, acc.: 57.81%] [G loss: 0.805169]\n",
      "epoch:44 step:34829 [D loss: 0.647551, acc.: 57.81%] [G loss: 0.783823]\n",
      "epoch:44 step:34830 [D loss: 0.611311, acc.: 71.09%] [G loss: 0.861650]\n",
      "epoch:44 step:34831 [D loss: 0.689612, acc.: 53.12%] [G loss: 0.903160]\n",
      "epoch:44 step:34832 [D loss: 0.662201, acc.: 65.62%] [G loss: 0.898001]\n",
      "epoch:44 step:34833 [D loss: 0.627160, acc.: 67.19%] [G loss: 0.774513]\n",
      "epoch:44 step:34834 [D loss: 0.688722, acc.: 59.38%] [G loss: 0.932653]\n",
      "epoch:44 step:34835 [D loss: 0.687475, acc.: 56.25%] [G loss: 0.762884]\n",
      "epoch:44 step:34836 [D loss: 0.713012, acc.: 51.56%] [G loss: 0.794178]\n",
      "epoch:44 step:34837 [D loss: 0.772394, acc.: 40.62%] [G loss: 0.723713]\n",
      "epoch:44 step:34838 [D loss: 0.684534, acc.: 57.03%] [G loss: 0.790550]\n",
      "epoch:44 step:34839 [D loss: 0.728416, acc.: 46.09%] [G loss: 0.792978]\n",
      "epoch:44 step:34840 [D loss: 0.657419, acc.: 65.62%] [G loss: 0.825503]\n",
      "epoch:44 step:34841 [D loss: 0.659149, acc.: 60.94%] [G loss: 0.781650]\n",
      "epoch:44 step:34842 [D loss: 0.584255, acc.: 80.47%] [G loss: 0.887774]\n",
      "epoch:44 step:34843 [D loss: 0.677872, acc.: 54.69%] [G loss: 0.836076]\n",
      "epoch:44 step:34844 [D loss: 0.663276, acc.: 63.28%] [G loss: 0.777110]\n",
      "epoch:44 step:34845 [D loss: 0.687930, acc.: 51.56%] [G loss: 0.765118]\n",
      "epoch:44 step:34846 [D loss: 0.727417, acc.: 50.00%] [G loss: 0.749765]\n",
      "epoch:44 step:34847 [D loss: 0.652679, acc.: 57.03%] [G loss: 0.802082]\n",
      "epoch:44 step:34848 [D loss: 0.636752, acc.: 64.84%] [G loss: 0.755501]\n",
      "epoch:44 step:34849 [D loss: 0.652493, acc.: 59.38%] [G loss: 0.792668]\n",
      "epoch:44 step:34850 [D loss: 0.596408, acc.: 71.88%] [G loss: 0.740041]\n",
      "epoch:44 step:34851 [D loss: 0.667359, acc.: 64.06%] [G loss: 0.861443]\n",
      "epoch:44 step:34852 [D loss: 0.707507, acc.: 52.34%] [G loss: 0.736360]\n",
      "epoch:44 step:34853 [D loss: 0.714767, acc.: 52.34%] [G loss: 0.699700]\n",
      "epoch:44 step:34854 [D loss: 0.668376, acc.: 60.16%] [G loss: 0.736661]\n",
      "epoch:44 step:34855 [D loss: 0.652120, acc.: 66.41%] [G loss: 0.821043]\n",
      "epoch:44 step:34856 [D loss: 0.650910, acc.: 64.84%] [G loss: 0.733537]\n",
      "epoch:44 step:34857 [D loss: 0.678251, acc.: 61.72%] [G loss: 0.820428]\n",
      "epoch:44 step:34858 [D loss: 0.661973, acc.: 59.38%] [G loss: 0.755723]\n",
      "epoch:44 step:34859 [D loss: 0.693022, acc.: 55.47%] [G loss: 0.848357]\n",
      "epoch:44 step:34860 [D loss: 0.703435, acc.: 57.03%] [G loss: 0.783708]\n",
      "epoch:44 step:34861 [D loss: 0.654127, acc.: 57.03%] [G loss: 0.880451]\n",
      "epoch:44 step:34862 [D loss: 0.651485, acc.: 60.16%] [G loss: 0.784467]\n",
      "epoch:44 step:34863 [D loss: 0.687062, acc.: 57.81%] [G loss: 0.859993]\n",
      "epoch:44 step:34864 [D loss: 0.692307, acc.: 57.03%] [G loss: 0.841681]\n",
      "epoch:44 step:34865 [D loss: 0.683895, acc.: 54.69%] [G loss: 0.779590]\n",
      "epoch:44 step:34866 [D loss: 0.669540, acc.: 61.72%] [G loss: 0.850628]\n",
      "epoch:44 step:34867 [D loss: 0.648722, acc.: 59.38%] [G loss: 0.881670]\n",
      "epoch:44 step:34868 [D loss: 0.719266, acc.: 50.00%] [G loss: 0.745090]\n",
      "epoch:44 step:34869 [D loss: 0.713704, acc.: 47.66%] [G loss: 0.797450]\n",
      "epoch:44 step:34870 [D loss: 0.703204, acc.: 56.25%] [G loss: 0.843442]\n",
      "epoch:44 step:34871 [D loss: 0.695434, acc.: 55.47%] [G loss: 0.823343]\n",
      "epoch:44 step:34872 [D loss: 0.702070, acc.: 51.56%] [G loss: 0.722647]\n",
      "epoch:44 step:34873 [D loss: 0.712049, acc.: 50.78%] [G loss: 0.825971]\n",
      "epoch:44 step:34874 [D loss: 0.686464, acc.: 57.81%] [G loss: 0.702998]\n",
      "epoch:44 step:34875 [D loss: 0.752886, acc.: 43.75%] [G loss: 0.755334]\n",
      "epoch:44 step:34876 [D loss: 0.714892, acc.: 52.34%] [G loss: 0.753192]\n",
      "epoch:44 step:34877 [D loss: 0.714618, acc.: 46.88%] [G loss: 0.692283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34878 [D loss: 0.701020, acc.: 58.59%] [G loss: 0.772200]\n",
      "epoch:44 step:34879 [D loss: 0.637969, acc.: 70.31%] [G loss: 0.747218]\n",
      "epoch:44 step:34880 [D loss: 0.641416, acc.: 67.97%] [G loss: 0.796119]\n",
      "epoch:44 step:34881 [D loss: 0.624715, acc.: 66.41%] [G loss: 0.730291]\n",
      "epoch:44 step:34882 [D loss: 0.640195, acc.: 71.09%] [G loss: 0.711292]\n",
      "epoch:44 step:34883 [D loss: 0.685139, acc.: 50.78%] [G loss: 0.706048]\n",
      "epoch:44 step:34884 [D loss: 0.713855, acc.: 48.44%] [G loss: 0.782258]\n",
      "epoch:44 step:34885 [D loss: 0.655650, acc.: 67.19%] [G loss: 0.761452]\n",
      "epoch:44 step:34886 [D loss: 0.702531, acc.: 50.78%] [G loss: 0.719580]\n",
      "epoch:44 step:34887 [D loss: 0.671355, acc.: 53.91%] [G loss: 0.758235]\n",
      "epoch:44 step:34888 [D loss: 0.695208, acc.: 54.69%] [G loss: 0.786335]\n",
      "epoch:44 step:34889 [D loss: 0.689577, acc.: 57.03%] [G loss: 0.832096]\n",
      "epoch:44 step:34890 [D loss: 0.807394, acc.: 31.25%] [G loss: 0.728935]\n",
      "epoch:44 step:34891 [D loss: 0.686823, acc.: 57.03%] [G loss: 0.800815]\n",
      "epoch:44 step:34892 [D loss: 0.710490, acc.: 47.66%] [G loss: 0.779091]\n",
      "epoch:44 step:34893 [D loss: 0.635574, acc.: 62.50%] [G loss: 0.774135]\n",
      "epoch:44 step:34894 [D loss: 0.697261, acc.: 57.81%] [G loss: 0.819639]\n",
      "epoch:44 step:34895 [D loss: 0.733348, acc.: 46.88%] [G loss: 0.739772]\n",
      "epoch:44 step:34896 [D loss: 0.688721, acc.: 55.47%] [G loss: 0.890585]\n",
      "epoch:44 step:34897 [D loss: 0.725000, acc.: 46.09%] [G loss: 0.864345]\n",
      "epoch:44 step:34898 [D loss: 0.676185, acc.: 63.28%] [G loss: 0.809197]\n",
      "epoch:44 step:34899 [D loss: 0.677563, acc.: 57.81%] [G loss: 0.828890]\n",
      "epoch:44 step:34900 [D loss: 0.759680, acc.: 41.41%] [G loss: 0.794089]\n",
      "epoch:44 step:34901 [D loss: 0.671169, acc.: 58.59%] [G loss: 0.842519]\n",
      "epoch:44 step:34902 [D loss: 0.647355, acc.: 66.41%] [G loss: 0.808564]\n",
      "epoch:44 step:34903 [D loss: 0.710953, acc.: 49.22%] [G loss: 0.771582]\n",
      "epoch:44 step:34904 [D loss: 0.673803, acc.: 60.16%] [G loss: 0.756377]\n",
      "epoch:44 step:34905 [D loss: 0.620932, acc.: 66.41%] [G loss: 0.827279]\n",
      "epoch:44 step:34906 [D loss: 0.672635, acc.: 56.25%] [G loss: 0.805500]\n",
      "epoch:44 step:34907 [D loss: 0.662767, acc.: 58.59%] [G loss: 0.818346]\n",
      "epoch:44 step:34908 [D loss: 0.711808, acc.: 46.09%] [G loss: 0.787300]\n",
      "epoch:44 step:34909 [D loss: 0.680569, acc.: 60.94%] [G loss: 0.872342]\n",
      "epoch:44 step:34910 [D loss: 0.706525, acc.: 55.47%] [G loss: 0.848871]\n",
      "epoch:44 step:34911 [D loss: 0.665804, acc.: 61.72%] [G loss: 0.914437]\n",
      "epoch:44 step:34912 [D loss: 0.720874, acc.: 46.09%] [G loss: 0.734732]\n",
      "epoch:44 step:34913 [D loss: 0.645039, acc.: 59.38%] [G loss: 0.872535]\n",
      "epoch:44 step:34914 [D loss: 0.710876, acc.: 52.34%] [G loss: 0.826972]\n",
      "epoch:44 step:34915 [D loss: 0.699595, acc.: 52.34%] [G loss: 0.869006]\n",
      "epoch:44 step:34916 [D loss: 0.723101, acc.: 45.31%] [G loss: 0.769192]\n",
      "epoch:44 step:34917 [D loss: 0.647202, acc.: 68.75%] [G loss: 0.820585]\n",
      "epoch:44 step:34918 [D loss: 0.673654, acc.: 64.06%] [G loss: 0.795719]\n",
      "epoch:44 step:34919 [D loss: 0.646080, acc.: 63.28%] [G loss: 0.853683]\n",
      "epoch:44 step:34920 [D loss: 0.769521, acc.: 39.06%] [G loss: 0.760300]\n",
      "epoch:44 step:34921 [D loss: 0.696786, acc.: 58.59%] [G loss: 0.801585]\n",
      "epoch:44 step:34922 [D loss: 0.720950, acc.: 47.66%] [G loss: 0.924939]\n",
      "epoch:44 step:34923 [D loss: 0.594946, acc.: 73.44%] [G loss: 0.837998]\n",
      "epoch:44 step:34924 [D loss: 0.698737, acc.: 51.56%] [G loss: 0.792525]\n",
      "epoch:44 step:34925 [D loss: 0.685896, acc.: 55.47%] [G loss: 0.829235]\n",
      "epoch:44 step:34926 [D loss: 0.642208, acc.: 64.84%] [G loss: 0.791205]\n",
      "epoch:44 step:34927 [D loss: 0.700522, acc.: 58.59%] [G loss: 0.765545]\n",
      "epoch:44 step:34928 [D loss: 0.678159, acc.: 53.91%] [G loss: 0.766322]\n",
      "epoch:44 step:34929 [D loss: 0.624427, acc.: 68.75%] [G loss: 0.773443]\n",
      "epoch:44 step:34930 [D loss: 0.702202, acc.: 51.56%] [G loss: 0.812254]\n",
      "epoch:44 step:34931 [D loss: 0.648492, acc.: 64.84%] [G loss: 0.827430]\n",
      "epoch:44 step:34932 [D loss: 0.679810, acc.: 54.69%] [G loss: 0.764467]\n",
      "epoch:44 step:34933 [D loss: 0.663510, acc.: 59.38%] [G loss: 0.767074]\n",
      "epoch:44 step:34934 [D loss: 0.702984, acc.: 52.34%] [G loss: 0.834511]\n",
      "epoch:44 step:34935 [D loss: 0.655899, acc.: 64.06%] [G loss: 0.868616]\n",
      "epoch:44 step:34936 [D loss: 0.695793, acc.: 53.12%] [G loss: 0.803653]\n",
      "epoch:44 step:34937 [D loss: 0.696108, acc.: 50.00%] [G loss: 0.727334]\n",
      "epoch:44 step:34938 [D loss: 0.676764, acc.: 58.59%] [G loss: 0.792723]\n",
      "epoch:44 step:34939 [D loss: 0.795821, acc.: 33.59%] [G loss: 0.770069]\n",
      "epoch:44 step:34940 [D loss: 0.690000, acc.: 57.81%] [G loss: 0.808573]\n",
      "epoch:44 step:34941 [D loss: 0.628603, acc.: 70.31%] [G loss: 0.794909]\n",
      "epoch:44 step:34942 [D loss: 0.688030, acc.: 57.03%] [G loss: 0.796130]\n",
      "epoch:44 step:34943 [D loss: 0.688597, acc.: 54.69%] [G loss: 0.770387]\n",
      "epoch:44 step:34944 [D loss: 0.708860, acc.: 53.12%] [G loss: 0.774537]\n",
      "epoch:44 step:34945 [D loss: 0.667821, acc.: 58.59%] [G loss: 0.847391]\n",
      "epoch:44 step:34946 [D loss: 0.638475, acc.: 64.06%] [G loss: 0.806475]\n",
      "epoch:44 step:34947 [D loss: 0.664039, acc.: 57.81%] [G loss: 0.829234]\n",
      "epoch:44 step:34948 [D loss: 0.689258, acc.: 53.12%] [G loss: 0.820237]\n",
      "epoch:44 step:34949 [D loss: 0.586872, acc.: 73.44%] [G loss: 0.888714]\n",
      "epoch:44 step:34950 [D loss: 0.685415, acc.: 57.81%] [G loss: 0.915124]\n",
      "epoch:44 step:34951 [D loss: 0.620990, acc.: 68.75%] [G loss: 0.853828]\n",
      "epoch:44 step:34952 [D loss: 0.666007, acc.: 57.81%] [G loss: 0.861990]\n",
      "epoch:44 step:34953 [D loss: 0.647352, acc.: 61.72%] [G loss: 0.841284]\n",
      "epoch:44 step:34954 [D loss: 0.646594, acc.: 65.62%] [G loss: 0.838654]\n",
      "epoch:44 step:34955 [D loss: 0.621713, acc.: 70.31%] [G loss: 0.819451]\n",
      "epoch:44 step:34956 [D loss: 0.620146, acc.: 67.97%] [G loss: 0.911134]\n",
      "epoch:44 step:34957 [D loss: 0.732058, acc.: 45.31%] [G loss: 0.885259]\n",
      "epoch:44 step:34958 [D loss: 0.652918, acc.: 65.62%] [G loss: 0.748541]\n",
      "epoch:44 step:34959 [D loss: 0.590022, acc.: 75.00%] [G loss: 0.864093]\n",
      "epoch:44 step:34960 [D loss: 0.696825, acc.: 50.78%] [G loss: 0.872041]\n",
      "epoch:44 step:34961 [D loss: 0.688016, acc.: 57.81%] [G loss: 0.786913]\n",
      "epoch:44 step:34962 [D loss: 0.724110, acc.: 50.00%] [G loss: 0.860212]\n",
      "epoch:44 step:34963 [D loss: 0.721715, acc.: 50.78%] [G loss: 0.799329]\n",
      "epoch:44 step:34964 [D loss: 0.650348, acc.: 59.38%] [G loss: 0.823782]\n",
      "epoch:44 step:34965 [D loss: 0.732770, acc.: 52.34%] [G loss: 0.759473]\n",
      "epoch:44 step:34966 [D loss: 0.614042, acc.: 71.88%] [G loss: 0.850176]\n",
      "epoch:44 step:34967 [D loss: 0.678228, acc.: 51.56%] [G loss: 0.775180]\n",
      "epoch:44 step:34968 [D loss: 0.675553, acc.: 62.50%] [G loss: 0.837671]\n",
      "epoch:44 step:34969 [D loss: 0.721309, acc.: 50.00%] [G loss: 0.858170]\n",
      "epoch:44 step:34970 [D loss: 0.666255, acc.: 64.84%] [G loss: 0.787246]\n",
      "epoch:44 step:34971 [D loss: 0.645785, acc.: 64.84%] [G loss: 0.801915]\n",
      "epoch:44 step:34972 [D loss: 0.783137, acc.: 39.84%] [G loss: 0.746456]\n",
      "epoch:44 step:34973 [D loss: 0.716952, acc.: 45.31%] [G loss: 0.815747]\n",
      "epoch:44 step:34974 [D loss: 0.659264, acc.: 57.03%] [G loss: 0.993563]\n",
      "epoch:44 step:34975 [D loss: 0.714996, acc.: 43.75%] [G loss: 0.910677]\n",
      "epoch:44 step:34976 [D loss: 0.635544, acc.: 60.16%] [G loss: 0.933652]\n",
      "epoch:44 step:34977 [D loss: 0.673817, acc.: 61.72%] [G loss: 0.847034]\n",
      "epoch:44 step:34978 [D loss: 0.702735, acc.: 52.34%] [G loss: 0.911888]\n",
      "epoch:44 step:34979 [D loss: 0.620154, acc.: 71.09%] [G loss: 0.810653]\n",
      "epoch:44 step:34980 [D loss: 0.624611, acc.: 69.53%] [G loss: 0.816443]\n",
      "epoch:44 step:34981 [D loss: 0.753860, acc.: 40.62%] [G loss: 0.812594]\n",
      "epoch:44 step:34982 [D loss: 0.671658, acc.: 59.38%] [G loss: 0.842027]\n",
      "epoch:44 step:34983 [D loss: 0.685022, acc.: 54.69%] [G loss: 0.788175]\n",
      "epoch:44 step:34984 [D loss: 0.648460, acc.: 61.72%] [G loss: 0.843205]\n",
      "epoch:44 step:34985 [D loss: 0.666845, acc.: 60.94%] [G loss: 0.867546]\n",
      "epoch:44 step:34986 [D loss: 0.681195, acc.: 55.47%] [G loss: 0.922692]\n",
      "epoch:44 step:34987 [D loss: 0.712848, acc.: 57.03%] [G loss: 0.848343]\n",
      "epoch:44 step:34988 [D loss: 0.662331, acc.: 64.06%] [G loss: 0.852208]\n",
      "epoch:44 step:34989 [D loss: 0.651273, acc.: 66.41%] [G loss: 0.825355]\n",
      "epoch:44 step:34990 [D loss: 0.662287, acc.: 55.47%] [G loss: 0.708311]\n",
      "epoch:44 step:34991 [D loss: 0.615482, acc.: 72.66%] [G loss: 0.855701]\n",
      "epoch:44 step:34992 [D loss: 0.562211, acc.: 82.03%] [G loss: 0.837115]\n",
      "epoch:44 step:34993 [D loss: 0.705675, acc.: 53.12%] [G loss: 0.866584]\n",
      "epoch:44 step:34994 [D loss: 0.748280, acc.: 44.53%] [G loss: 0.831047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34995 [D loss: 0.697088, acc.: 56.25%] [G loss: 0.825181]\n",
      "epoch:44 step:34996 [D loss: 0.640066, acc.: 64.06%] [G loss: 0.878518]\n",
      "epoch:44 step:34997 [D loss: 0.637091, acc.: 66.41%] [G loss: 0.764975]\n",
      "epoch:44 step:34998 [D loss: 0.699841, acc.: 58.59%] [G loss: 0.738270]\n",
      "epoch:44 step:34999 [D loss: 0.688511, acc.: 46.88%] [G loss: 0.703499]\n",
      "epoch:44 step:35000 [D loss: 0.651112, acc.: 61.72%] [G loss: 0.753420]\n",
      "epoch:44 step:35001 [D loss: 0.639086, acc.: 67.97%] [G loss: 0.889830]\n",
      "epoch:44 step:35002 [D loss: 0.700620, acc.: 53.12%] [G loss: 0.775453]\n",
      "epoch:44 step:35003 [D loss: 0.689680, acc.: 50.78%] [G loss: 0.783471]\n",
      "epoch:44 step:35004 [D loss: 0.641124, acc.: 67.97%] [G loss: 0.814366]\n",
      "epoch:44 step:35005 [D loss: 0.660641, acc.: 57.03%] [G loss: 0.855801]\n",
      "epoch:44 step:35006 [D loss: 0.663029, acc.: 67.97%] [G loss: 0.779053]\n",
      "epoch:44 step:35007 [D loss: 0.739886, acc.: 41.41%] [G loss: 0.725499]\n",
      "epoch:44 step:35008 [D loss: 0.632908, acc.: 61.72%] [G loss: 0.711068]\n",
      "epoch:44 step:35009 [D loss: 0.661447, acc.: 60.94%] [G loss: 0.766515]\n",
      "epoch:44 step:35010 [D loss: 0.674284, acc.: 58.59%] [G loss: 0.705080]\n",
      "epoch:44 step:35011 [D loss: 0.588581, acc.: 75.00%] [G loss: 0.822470]\n",
      "epoch:44 step:35012 [D loss: 0.654158, acc.: 64.06%] [G loss: 0.756713]\n",
      "epoch:44 step:35013 [D loss: 0.688147, acc.: 53.12%] [G loss: 0.847879]\n",
      "epoch:44 step:35014 [D loss: 0.634965, acc.: 68.75%] [G loss: 0.700366]\n",
      "epoch:44 step:35015 [D loss: 0.752301, acc.: 39.06%] [G loss: 0.729215]\n",
      "epoch:44 step:35016 [D loss: 0.677492, acc.: 49.22%] [G loss: 0.789362]\n",
      "epoch:44 step:35017 [D loss: 0.718315, acc.: 44.53%] [G loss: 0.749295]\n",
      "epoch:44 step:35018 [D loss: 0.647355, acc.: 60.16%] [G loss: 0.838657]\n",
      "epoch:44 step:35019 [D loss: 0.732039, acc.: 46.88%] [G loss: 0.756295]\n",
      "epoch:44 step:35020 [D loss: 0.682448, acc.: 51.56%] [G loss: 0.760474]\n",
      "epoch:44 step:35021 [D loss: 0.693515, acc.: 50.00%] [G loss: 0.808430]\n",
      "epoch:44 step:35022 [D loss: 0.700900, acc.: 50.00%] [G loss: 0.725471]\n",
      "epoch:44 step:35023 [D loss: 0.631821, acc.: 69.53%] [G loss: 0.732426]\n",
      "epoch:44 step:35024 [D loss: 0.724181, acc.: 46.88%] [G loss: 0.741628]\n",
      "epoch:44 step:35025 [D loss: 0.659202, acc.: 61.72%] [G loss: 0.804765]\n",
      "epoch:44 step:35026 [D loss: 0.677567, acc.: 54.69%] [G loss: 0.844543]\n",
      "epoch:44 step:35027 [D loss: 0.690536, acc.: 53.91%] [G loss: 0.822310]\n",
      "epoch:44 step:35028 [D loss: 0.655815, acc.: 59.38%] [G loss: 0.916456]\n",
      "epoch:44 step:35029 [D loss: 0.682425, acc.: 54.69%] [G loss: 0.888342]\n",
      "epoch:44 step:35030 [D loss: 0.737786, acc.: 47.66%] [G loss: 0.735294]\n",
      "epoch:44 step:35031 [D loss: 0.669321, acc.: 62.50%] [G loss: 0.763931]\n",
      "epoch:44 step:35032 [D loss: 0.694135, acc.: 50.78%] [G loss: 0.801466]\n",
      "epoch:44 step:35033 [D loss: 0.608208, acc.: 75.00%] [G loss: 0.809561]\n",
      "epoch:44 step:35034 [D loss: 0.677201, acc.: 57.03%] [G loss: 0.759216]\n",
      "epoch:44 step:35035 [D loss: 0.739795, acc.: 46.88%] [G loss: 0.735816]\n",
      "epoch:44 step:35036 [D loss: 0.656649, acc.: 67.19%] [G loss: 0.785738]\n",
      "epoch:44 step:35037 [D loss: 0.656849, acc.: 63.28%] [G loss: 0.838177]\n",
      "epoch:44 step:35038 [D loss: 0.706892, acc.: 49.22%] [G loss: 0.713194]\n",
      "epoch:44 step:35039 [D loss: 0.659455, acc.: 60.16%] [G loss: 0.766060]\n",
      "epoch:44 step:35040 [D loss: 0.730189, acc.: 46.88%] [G loss: 0.734146]\n",
      "epoch:44 step:35041 [D loss: 0.699944, acc.: 50.78%] [G loss: 0.767440]\n",
      "epoch:44 step:35042 [D loss: 0.688306, acc.: 54.69%] [G loss: 0.776814]\n",
      "epoch:44 step:35043 [D loss: 0.617304, acc.: 73.44%] [G loss: 0.825429]\n",
      "epoch:44 step:35044 [D loss: 0.673435, acc.: 60.94%] [G loss: 0.847888]\n",
      "epoch:44 step:35045 [D loss: 0.668071, acc.: 61.72%] [G loss: 0.846195]\n",
      "epoch:44 step:35046 [D loss: 0.695389, acc.: 53.12%] [G loss: 0.818082]\n",
      "epoch:44 step:35047 [D loss: 0.673595, acc.: 56.25%] [G loss: 0.801140]\n",
      "epoch:44 step:35048 [D loss: 0.687054, acc.: 50.78%] [G loss: 0.923155]\n",
      "epoch:44 step:35049 [D loss: 0.659124, acc.: 64.84%] [G loss: 0.787574]\n",
      "epoch:44 step:35050 [D loss: 0.677791, acc.: 56.25%] [G loss: 0.788786]\n",
      "epoch:44 step:35051 [D loss: 0.667367, acc.: 60.94%] [G loss: 0.817690]\n",
      "epoch:44 step:35052 [D loss: 0.702364, acc.: 50.78%] [G loss: 0.742000]\n",
      "epoch:44 step:35053 [D loss: 0.664042, acc.: 60.16%] [G loss: 0.767183]\n",
      "epoch:44 step:35054 [D loss: 0.681242, acc.: 58.59%] [G loss: 0.836629]\n",
      "epoch:44 step:35055 [D loss: 0.679755, acc.: 53.91%] [G loss: 0.804242]\n",
      "epoch:44 step:35056 [D loss: 0.681515, acc.: 53.91%] [G loss: 0.786349]\n",
      "epoch:44 step:35057 [D loss: 0.674558, acc.: 57.81%] [G loss: 0.808743]\n",
      "epoch:44 step:35058 [D loss: 0.661437, acc.: 60.94%] [G loss: 0.714961]\n",
      "epoch:44 step:35059 [D loss: 0.634570, acc.: 69.53%] [G loss: 0.779270]\n",
      "epoch:44 step:35060 [D loss: 0.759475, acc.: 34.38%] [G loss: 0.727537]\n",
      "epoch:44 step:35061 [D loss: 0.760894, acc.: 42.19%] [G loss: 0.731323]\n",
      "epoch:44 step:35062 [D loss: 0.662549, acc.: 60.16%] [G loss: 0.759061]\n",
      "epoch:44 step:35063 [D loss: 0.721122, acc.: 42.97%] [G loss: 0.797978]\n",
      "epoch:44 step:35064 [D loss: 0.701387, acc.: 50.00%] [G loss: 0.743440]\n",
      "epoch:44 step:35065 [D loss: 0.718127, acc.: 48.44%] [G loss: 0.790763]\n",
      "epoch:44 step:35066 [D loss: 0.684049, acc.: 50.78%] [G loss: 0.784424]\n",
      "epoch:44 step:35067 [D loss: 0.653073, acc.: 62.50%] [G loss: 0.799007]\n",
      "epoch:44 step:35068 [D loss: 0.702907, acc.: 56.25%] [G loss: 0.839274]\n",
      "epoch:44 step:35069 [D loss: 0.625210, acc.: 68.75%] [G loss: 0.870399]\n",
      "epoch:44 step:35070 [D loss: 0.685921, acc.: 53.12%] [G loss: 0.885771]\n",
      "epoch:44 step:35071 [D loss: 0.663269, acc.: 59.38%] [G loss: 0.830819]\n",
      "epoch:44 step:35072 [D loss: 0.733618, acc.: 50.00%] [G loss: 0.794382]\n",
      "epoch:44 step:35073 [D loss: 0.653626, acc.: 60.94%] [G loss: 0.649419]\n",
      "epoch:44 step:35074 [D loss: 0.712849, acc.: 54.69%] [G loss: 0.775640]\n",
      "epoch:44 step:35075 [D loss: 0.629859, acc.: 74.22%] [G loss: 0.891735]\n",
      "epoch:44 step:35076 [D loss: 0.669804, acc.: 56.25%] [G loss: 0.862316]\n",
      "epoch:44 step:35077 [D loss: 0.666992, acc.: 54.69%] [G loss: 0.818223]\n",
      "epoch:44 step:35078 [D loss: 0.693034, acc.: 50.00%] [G loss: 0.838610]\n",
      "epoch:44 step:35079 [D loss: 0.634873, acc.: 64.06%] [G loss: 0.822943]\n",
      "epoch:44 step:35080 [D loss: 0.657193, acc.: 63.28%] [G loss: 0.817547]\n",
      "epoch:44 step:35081 [D loss: 0.706991, acc.: 57.81%] [G loss: 0.757978]\n",
      "epoch:44 step:35082 [D loss: 0.673718, acc.: 60.94%] [G loss: 0.725649]\n",
      "epoch:44 step:35083 [D loss: 0.716934, acc.: 45.31%] [G loss: 0.777890]\n",
      "epoch:44 step:35084 [D loss: 0.659693, acc.: 58.59%] [G loss: 0.787334]\n",
      "epoch:44 step:35085 [D loss: 0.744328, acc.: 46.09%] [G loss: 0.828831]\n",
      "epoch:44 step:35086 [D loss: 0.682108, acc.: 57.03%] [G loss: 0.768673]\n",
      "epoch:44 step:35087 [D loss: 0.635181, acc.: 69.53%] [G loss: 0.750552]\n",
      "epoch:44 step:35088 [D loss: 0.656203, acc.: 58.59%] [G loss: 0.715904]\n",
      "epoch:44 step:35089 [D loss: 0.699728, acc.: 50.78%] [G loss: 0.804682]\n",
      "epoch:44 step:35090 [D loss: 0.660952, acc.: 56.25%] [G loss: 0.860169]\n",
      "epoch:44 step:35091 [D loss: 0.710429, acc.: 46.09%] [G loss: 0.910243]\n",
      "epoch:44 step:35092 [D loss: 0.725882, acc.: 42.19%] [G loss: 0.792774]\n",
      "epoch:44 step:35093 [D loss: 0.710343, acc.: 50.78%] [G loss: 0.817875]\n",
      "epoch:44 step:35094 [D loss: 0.685221, acc.: 56.25%] [G loss: 0.834830]\n",
      "epoch:44 step:35095 [D loss: 0.637916, acc.: 66.41%] [G loss: 0.862675]\n",
      "epoch:44 step:35096 [D loss: 0.705894, acc.: 56.25%] [G loss: 0.790072]\n",
      "epoch:44 step:35097 [D loss: 0.662775, acc.: 59.38%] [G loss: 0.782976]\n",
      "epoch:44 step:35098 [D loss: 0.713135, acc.: 43.75%] [G loss: 0.796436]\n",
      "epoch:44 step:35099 [D loss: 0.715571, acc.: 52.34%] [G loss: 0.817049]\n",
      "epoch:44 step:35100 [D loss: 0.637956, acc.: 67.97%] [G loss: 0.795516]\n",
      "epoch:44 step:35101 [D loss: 0.696211, acc.: 57.03%] [G loss: 0.811080]\n",
      "epoch:44 step:35102 [D loss: 0.646344, acc.: 62.50%] [G loss: 0.799914]\n",
      "epoch:44 step:35103 [D loss: 0.705517, acc.: 54.69%] [G loss: 0.897466]\n",
      "epoch:44 step:35104 [D loss: 0.695937, acc.: 52.34%] [G loss: 0.810028]\n",
      "epoch:44 step:35105 [D loss: 0.655804, acc.: 61.72%] [G loss: 0.770311]\n",
      "epoch:44 step:35106 [D loss: 0.669395, acc.: 58.59%] [G loss: 0.766675]\n",
      "epoch:44 step:35107 [D loss: 0.669850, acc.: 60.94%] [G loss: 0.771741]\n",
      "epoch:44 step:35108 [D loss: 0.712016, acc.: 39.84%] [G loss: 0.792374]\n",
      "epoch:44 step:35109 [D loss: 0.613117, acc.: 70.31%] [G loss: 0.776345]\n",
      "epoch:44 step:35110 [D loss: 0.637087, acc.: 64.06%] [G loss: 0.814390]\n",
      "epoch:44 step:35111 [D loss: 0.688341, acc.: 58.59%] [G loss: 0.768035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35112 [D loss: 0.632095, acc.: 65.62%] [G loss: 0.839546]\n",
      "epoch:44 step:35113 [D loss: 0.651181, acc.: 62.50%] [G loss: 0.773658]\n",
      "epoch:44 step:35114 [D loss: 0.670971, acc.: 59.38%] [G loss: 0.757195]\n",
      "epoch:44 step:35115 [D loss: 0.709392, acc.: 55.47%] [G loss: 0.851591]\n",
      "epoch:44 step:35116 [D loss: 0.663608, acc.: 59.38%] [G loss: 0.862377]\n",
      "epoch:44 step:35117 [D loss: 0.638937, acc.: 65.62%] [G loss: 0.835800]\n",
      "epoch:44 step:35118 [D loss: 0.650958, acc.: 64.84%] [G loss: 0.864905]\n",
      "epoch:44 step:35119 [D loss: 0.668361, acc.: 57.81%] [G loss: 0.791090]\n",
      "epoch:44 step:35120 [D loss: 0.684492, acc.: 54.69%] [G loss: 0.707852]\n",
      "epoch:44 step:35121 [D loss: 0.644363, acc.: 62.50%] [G loss: 0.808759]\n",
      "epoch:44 step:35122 [D loss: 0.620658, acc.: 70.31%] [G loss: 0.840524]\n",
      "epoch:44 step:35123 [D loss: 0.742048, acc.: 43.75%] [G loss: 0.679932]\n",
      "epoch:44 step:35124 [D loss: 0.693477, acc.: 57.81%] [G loss: 0.771981]\n",
      "epoch:44 step:35125 [D loss: 0.658973, acc.: 54.69%] [G loss: 0.773178]\n",
      "epoch:44 step:35126 [D loss: 0.699428, acc.: 50.78%] [G loss: 0.734722]\n",
      "epoch:44 step:35127 [D loss: 0.667082, acc.: 58.59%] [G loss: 0.741122]\n",
      "epoch:44 step:35128 [D loss: 0.664930, acc.: 67.97%] [G loss: 0.804117]\n",
      "epoch:44 step:35129 [D loss: 0.638577, acc.: 67.19%] [G loss: 0.706764]\n",
      "epoch:44 step:35130 [D loss: 0.692430, acc.: 51.56%] [G loss: 0.819732]\n",
      "epoch:44 step:35131 [D loss: 0.679975, acc.: 59.38%] [G loss: 0.843192]\n",
      "epoch:44 step:35132 [D loss: 0.661552, acc.: 62.50%] [G loss: 0.826970]\n",
      "epoch:44 step:35133 [D loss: 0.682497, acc.: 60.94%] [G loss: 0.809551]\n",
      "epoch:44 step:35134 [D loss: 0.646157, acc.: 64.84%] [G loss: 0.785519]\n",
      "epoch:44 step:35135 [D loss: 0.659611, acc.: 61.72%] [G loss: 0.791791]\n",
      "epoch:44 step:35136 [D loss: 0.668620, acc.: 57.81%] [G loss: 0.769662]\n",
      "epoch:44 step:35137 [D loss: 0.649742, acc.: 66.41%] [G loss: 0.832367]\n",
      "epoch:44 step:35138 [D loss: 0.654656, acc.: 62.50%] [G loss: 0.799293]\n",
      "epoch:44 step:35139 [D loss: 0.679273, acc.: 59.38%] [G loss: 0.782068]\n",
      "epoch:44 step:35140 [D loss: 0.702726, acc.: 54.69%] [G loss: 0.809397]\n",
      "epoch:44 step:35141 [D loss: 0.683570, acc.: 57.81%] [G loss: 0.724622]\n",
      "epoch:44 step:35142 [D loss: 0.699719, acc.: 50.78%] [G loss: 0.800688]\n",
      "epoch:44 step:35143 [D loss: 0.724468, acc.: 43.75%] [G loss: 0.782758]\n",
      "epoch:44 step:35144 [D loss: 0.742146, acc.: 42.19%] [G loss: 0.829710]\n",
      "epoch:44 step:35145 [D loss: 0.614456, acc.: 72.66%] [G loss: 0.871481]\n",
      "epoch:45 step:35146 [D loss: 0.662986, acc.: 57.81%] [G loss: 0.839890]\n",
      "epoch:45 step:35147 [D loss: 0.691247, acc.: 50.78%] [G loss: 0.772054]\n",
      "epoch:45 step:35148 [D loss: 0.609456, acc.: 69.53%] [G loss: 0.800659]\n",
      "epoch:45 step:35149 [D loss: 0.628508, acc.: 71.88%] [G loss: 0.744500]\n",
      "epoch:45 step:35150 [D loss: 0.641034, acc.: 63.28%] [G loss: 0.767968]\n",
      "epoch:45 step:35151 [D loss: 0.642403, acc.: 66.41%] [G loss: 0.751266]\n",
      "epoch:45 step:35152 [D loss: 0.673844, acc.: 54.69%] [G loss: 0.912991]\n",
      "epoch:45 step:35153 [D loss: 0.647200, acc.: 64.84%] [G loss: 0.878365]\n",
      "epoch:45 step:35154 [D loss: 0.700986, acc.: 48.44%] [G loss: 0.911949]\n",
      "epoch:45 step:35155 [D loss: 0.682825, acc.: 56.25%] [G loss: 0.801896]\n",
      "epoch:45 step:35156 [D loss: 0.716099, acc.: 54.69%] [G loss: 0.839459]\n",
      "epoch:45 step:35157 [D loss: 0.660437, acc.: 55.47%] [G loss: 0.916315]\n",
      "epoch:45 step:35158 [D loss: 0.691355, acc.: 52.34%] [G loss: 0.852735]\n",
      "epoch:45 step:35159 [D loss: 0.653263, acc.: 61.72%] [G loss: 0.896056]\n",
      "epoch:45 step:35160 [D loss: 0.800014, acc.: 28.91%] [G loss: 0.725069]\n",
      "epoch:45 step:35161 [D loss: 0.693838, acc.: 52.34%] [G loss: 0.813221]\n",
      "epoch:45 step:35162 [D loss: 0.666742, acc.: 62.50%] [G loss: 0.822775]\n",
      "epoch:45 step:35163 [D loss: 0.676573, acc.: 57.03%] [G loss: 0.797039]\n",
      "epoch:45 step:35164 [D loss: 0.661153, acc.: 60.16%] [G loss: 0.855728]\n",
      "epoch:45 step:35165 [D loss: 0.704737, acc.: 55.47%] [G loss: 0.758814]\n",
      "epoch:45 step:35166 [D loss: 0.707282, acc.: 50.00%] [G loss: 0.797503]\n",
      "epoch:45 step:35167 [D loss: 0.702364, acc.: 51.56%] [G loss: 0.879175]\n",
      "epoch:45 step:35168 [D loss: 0.694545, acc.: 53.91%] [G loss: 0.792872]\n",
      "epoch:45 step:35169 [D loss: 0.675334, acc.: 58.59%] [G loss: 0.808447]\n",
      "epoch:45 step:35170 [D loss: 0.752079, acc.: 39.06%] [G loss: 0.707792]\n",
      "epoch:45 step:35171 [D loss: 0.701028, acc.: 51.56%] [G loss: 0.862517]\n",
      "epoch:45 step:35172 [D loss: 0.704802, acc.: 54.69%] [G loss: 0.846382]\n",
      "epoch:45 step:35173 [D loss: 0.688101, acc.: 50.78%] [G loss: 0.805542]\n",
      "epoch:45 step:35174 [D loss: 0.672831, acc.: 56.25%] [G loss: 0.804609]\n",
      "epoch:45 step:35175 [D loss: 0.669001, acc.: 62.50%] [G loss: 0.810351]\n",
      "epoch:45 step:35176 [D loss: 0.648351, acc.: 66.41%] [G loss: 0.811310]\n",
      "epoch:45 step:35177 [D loss: 0.693488, acc.: 56.25%] [G loss: 0.811677]\n",
      "epoch:45 step:35178 [D loss: 0.688094, acc.: 57.81%] [G loss: 0.778288]\n",
      "epoch:45 step:35179 [D loss: 0.698012, acc.: 53.91%] [G loss: 0.744128]\n",
      "epoch:45 step:35180 [D loss: 0.732379, acc.: 46.88%] [G loss: 0.815513]\n",
      "epoch:45 step:35181 [D loss: 0.689627, acc.: 50.78%] [G loss: 0.788973]\n",
      "epoch:45 step:35182 [D loss: 0.744409, acc.: 50.00%] [G loss: 0.769893]\n",
      "epoch:45 step:35183 [D loss: 0.593549, acc.: 74.22%] [G loss: 0.864815]\n",
      "epoch:45 step:35184 [D loss: 0.687174, acc.: 57.81%] [G loss: 0.793720]\n",
      "epoch:45 step:35185 [D loss: 0.698448, acc.: 52.34%] [G loss: 0.827119]\n",
      "epoch:45 step:35186 [D loss: 0.743269, acc.: 44.53%] [G loss: 0.906732]\n",
      "epoch:45 step:35187 [D loss: 0.616758, acc.: 71.09%] [G loss: 0.865300]\n",
      "epoch:45 step:35188 [D loss: 0.619785, acc.: 67.97%] [G loss: 0.816116]\n",
      "epoch:45 step:35189 [D loss: 0.701824, acc.: 50.78%] [G loss: 0.786213]\n",
      "epoch:45 step:35190 [D loss: 0.645711, acc.: 61.72%] [G loss: 0.849029]\n",
      "epoch:45 step:35191 [D loss: 0.683708, acc.: 60.94%] [G loss: 0.765305]\n",
      "epoch:45 step:35192 [D loss: 0.674135, acc.: 61.72%] [G loss: 0.803271]\n",
      "epoch:45 step:35193 [D loss: 0.656199, acc.: 64.84%] [G loss: 0.752734]\n",
      "epoch:45 step:35194 [D loss: 0.599077, acc.: 73.44%] [G loss: 0.783706]\n",
      "epoch:45 step:35195 [D loss: 0.661708, acc.: 58.59%] [G loss: 0.661738]\n",
      "epoch:45 step:35196 [D loss: 0.647244, acc.: 67.19%] [G loss: 0.695698]\n",
      "epoch:45 step:35197 [D loss: 0.587146, acc.: 76.56%] [G loss: 0.772092]\n",
      "epoch:45 step:35198 [D loss: 0.670561, acc.: 55.47%] [G loss: 0.812626]\n",
      "epoch:45 step:35199 [D loss: 0.697222, acc.: 56.25%] [G loss: 0.775749]\n",
      "epoch:45 step:35200 [D loss: 0.623537, acc.: 64.06%] [G loss: 0.694375]\n",
      "epoch:45 step:35201 [D loss: 0.669218, acc.: 62.50%] [G loss: 0.705506]\n",
      "epoch:45 step:35202 [D loss: 0.709477, acc.: 53.91%] [G loss: 0.777879]\n",
      "epoch:45 step:35203 [D loss: 0.693645, acc.: 53.91%] [G loss: 0.797109]\n",
      "epoch:45 step:35204 [D loss: 0.711678, acc.: 50.78%] [G loss: 0.815223]\n",
      "epoch:45 step:35205 [D loss: 0.619959, acc.: 71.09%] [G loss: 0.800915]\n",
      "epoch:45 step:35206 [D loss: 0.629538, acc.: 64.84%] [G loss: 0.867090]\n",
      "epoch:45 step:35207 [D loss: 0.664669, acc.: 66.41%] [G loss: 0.728723]\n",
      "epoch:45 step:35208 [D loss: 0.668391, acc.: 57.03%] [G loss: 0.791071]\n",
      "epoch:45 step:35209 [D loss: 0.704240, acc.: 50.00%] [G loss: 0.861754]\n",
      "epoch:45 step:35210 [D loss: 0.683859, acc.: 54.69%] [G loss: 0.853469]\n",
      "epoch:45 step:35211 [D loss: 0.759003, acc.: 35.94%] [G loss: 0.734863]\n",
      "epoch:45 step:35212 [D loss: 0.722505, acc.: 44.53%] [G loss: 0.809352]\n",
      "epoch:45 step:35213 [D loss: 0.712378, acc.: 50.00%] [G loss: 0.798797]\n",
      "epoch:45 step:35214 [D loss: 0.693940, acc.: 53.12%] [G loss: 0.812420]\n",
      "epoch:45 step:35215 [D loss: 0.662913, acc.: 61.72%] [G loss: 0.820198]\n",
      "epoch:45 step:35216 [D loss: 0.712106, acc.: 52.34%] [G loss: 0.741642]\n",
      "epoch:45 step:35217 [D loss: 0.685816, acc.: 54.69%] [G loss: 0.691181]\n",
      "epoch:45 step:35218 [D loss: 0.670906, acc.: 54.69%] [G loss: 0.750434]\n",
      "epoch:45 step:35219 [D loss: 0.608160, acc.: 70.31%] [G loss: 0.751421]\n",
      "epoch:45 step:35220 [D loss: 0.666991, acc.: 63.28%] [G loss: 0.792601]\n",
      "epoch:45 step:35221 [D loss: 0.643751, acc.: 60.16%] [G loss: 0.822676]\n",
      "epoch:45 step:35222 [D loss: 0.729118, acc.: 50.00%] [G loss: 0.810550]\n",
      "epoch:45 step:35223 [D loss: 0.644111, acc.: 67.19%] [G loss: 0.731799]\n",
      "epoch:45 step:35224 [D loss: 0.678708, acc.: 57.03%] [G loss: 0.801337]\n",
      "epoch:45 step:35225 [D loss: 0.693267, acc.: 55.47%] [G loss: 0.820907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35226 [D loss: 0.675471, acc.: 60.16%] [G loss: 0.781241]\n",
      "epoch:45 step:35227 [D loss: 0.624386, acc.: 65.62%] [G loss: 0.762830]\n",
      "epoch:45 step:35228 [D loss: 0.708099, acc.: 50.78%] [G loss: 0.810404]\n",
      "epoch:45 step:35229 [D loss: 0.658614, acc.: 63.28%] [G loss: 0.826849]\n",
      "epoch:45 step:35230 [D loss: 0.689555, acc.: 58.59%] [G loss: 0.768853]\n",
      "epoch:45 step:35231 [D loss: 0.663789, acc.: 61.72%] [G loss: 0.856509]\n",
      "epoch:45 step:35232 [D loss: 0.696870, acc.: 53.91%] [G loss: 0.815656]\n",
      "epoch:45 step:35233 [D loss: 0.769863, acc.: 38.28%] [G loss: 0.866343]\n",
      "epoch:45 step:35234 [D loss: 0.723068, acc.: 46.09%] [G loss: 0.975418]\n",
      "epoch:45 step:35235 [D loss: 0.678558, acc.: 52.34%] [G loss: 0.846720]\n",
      "epoch:45 step:35236 [D loss: 0.692944, acc.: 52.34%] [G loss: 0.860713]\n",
      "epoch:45 step:35237 [D loss: 0.714001, acc.: 48.44%] [G loss: 0.733146]\n",
      "epoch:45 step:35238 [D loss: 0.681043, acc.: 60.94%] [G loss: 0.759830]\n",
      "epoch:45 step:35239 [D loss: 0.605549, acc.: 71.88%] [G loss: 0.748959]\n",
      "epoch:45 step:35240 [D loss: 0.719217, acc.: 46.88%] [G loss: 0.782035]\n",
      "epoch:45 step:35241 [D loss: 0.616950, acc.: 67.97%] [G loss: 0.833447]\n",
      "epoch:45 step:35242 [D loss: 0.722387, acc.: 45.31%] [G loss: 0.855869]\n",
      "epoch:45 step:35243 [D loss: 0.601808, acc.: 77.34%] [G loss: 0.819045]\n",
      "epoch:45 step:35244 [D loss: 0.719121, acc.: 46.88%] [G loss: 0.962772]\n",
      "epoch:45 step:35245 [D loss: 0.735534, acc.: 41.41%] [G loss: 0.800464]\n",
      "epoch:45 step:35246 [D loss: 0.675498, acc.: 57.81%] [G loss: 0.807662]\n",
      "epoch:45 step:35247 [D loss: 0.712834, acc.: 50.78%] [G loss: 0.808860]\n",
      "epoch:45 step:35248 [D loss: 0.721292, acc.: 50.00%] [G loss: 0.860658]\n",
      "epoch:45 step:35249 [D loss: 0.678945, acc.: 59.38%] [G loss: 0.842762]\n",
      "epoch:45 step:35250 [D loss: 0.681396, acc.: 54.69%] [G loss: 0.776353]\n",
      "epoch:45 step:35251 [D loss: 0.721530, acc.: 52.34%] [G loss: 0.788379]\n",
      "epoch:45 step:35252 [D loss: 0.648748, acc.: 61.72%] [G loss: 0.843734]\n",
      "epoch:45 step:35253 [D loss: 0.674114, acc.: 52.34%] [G loss: 0.855090]\n",
      "epoch:45 step:35254 [D loss: 0.658010, acc.: 60.16%] [G loss: 0.905667]\n",
      "epoch:45 step:35255 [D loss: 0.728516, acc.: 43.75%] [G loss: 0.793749]\n",
      "epoch:45 step:35256 [D loss: 0.690288, acc.: 48.44%] [G loss: 0.813141]\n",
      "epoch:45 step:35257 [D loss: 0.669231, acc.: 55.47%] [G loss: 0.795536]\n",
      "epoch:45 step:35258 [D loss: 0.697985, acc.: 59.38%] [G loss: 0.818482]\n",
      "epoch:45 step:35259 [D loss: 0.600338, acc.: 72.66%] [G loss: 0.832763]\n",
      "epoch:45 step:35260 [D loss: 0.670244, acc.: 59.38%] [G loss: 0.837735]\n",
      "epoch:45 step:35261 [D loss: 0.707393, acc.: 51.56%] [G loss: 0.814217]\n",
      "epoch:45 step:35262 [D loss: 0.645474, acc.: 63.28%] [G loss: 0.852770]\n",
      "epoch:45 step:35263 [D loss: 0.709277, acc.: 50.78%] [G loss: 0.786058]\n",
      "epoch:45 step:35264 [D loss: 0.648284, acc.: 65.62%] [G loss: 0.835985]\n",
      "epoch:45 step:35265 [D loss: 0.668013, acc.: 61.72%] [G loss: 0.816820]\n",
      "epoch:45 step:35266 [D loss: 0.637240, acc.: 69.53%] [G loss: 0.848663]\n",
      "epoch:45 step:35267 [D loss: 0.716714, acc.: 53.12%] [G loss: 0.755934]\n",
      "epoch:45 step:35268 [D loss: 0.722784, acc.: 45.31%] [G loss: 0.781488]\n",
      "epoch:45 step:35269 [D loss: 0.599277, acc.: 67.97%] [G loss: 0.939295]\n",
      "epoch:45 step:35270 [D loss: 0.717270, acc.: 49.22%] [G loss: 0.843000]\n",
      "epoch:45 step:35271 [D loss: 0.729283, acc.: 50.78%] [G loss: 0.791989]\n",
      "epoch:45 step:35272 [D loss: 0.700758, acc.: 50.78%] [G loss: 0.826926]\n",
      "epoch:45 step:35273 [D loss: 0.696473, acc.: 52.34%] [G loss: 0.818632]\n",
      "epoch:45 step:35274 [D loss: 0.764393, acc.: 41.41%] [G loss: 0.842154]\n",
      "epoch:45 step:35275 [D loss: 0.747886, acc.: 46.88%] [G loss: 0.734672]\n",
      "epoch:45 step:35276 [D loss: 0.694204, acc.: 57.81%] [G loss: 0.844848]\n",
      "epoch:45 step:35277 [D loss: 0.667842, acc.: 60.94%] [G loss: 0.805663]\n",
      "epoch:45 step:35278 [D loss: 0.750247, acc.: 37.50%] [G loss: 0.701997]\n",
      "epoch:45 step:35279 [D loss: 0.664587, acc.: 56.25%] [G loss: 0.778842]\n",
      "epoch:45 step:35280 [D loss: 0.717158, acc.: 53.91%] [G loss: 0.860894]\n",
      "epoch:45 step:35281 [D loss: 0.661570, acc.: 63.28%] [G loss: 0.751522]\n",
      "epoch:45 step:35282 [D loss: 0.751188, acc.: 39.84%] [G loss: 0.783851]\n",
      "epoch:45 step:35283 [D loss: 0.764789, acc.: 46.88%] [G loss: 0.803248]\n",
      "epoch:45 step:35284 [D loss: 0.690941, acc.: 52.34%] [G loss: 0.803114]\n",
      "epoch:45 step:35285 [D loss: 0.691800, acc.: 54.69%] [G loss: 0.755167]\n",
      "epoch:45 step:35286 [D loss: 0.701343, acc.: 53.91%] [G loss: 0.727686]\n",
      "epoch:45 step:35287 [D loss: 0.694748, acc.: 56.25%] [G loss: 0.781459]\n",
      "epoch:45 step:35288 [D loss: 0.700687, acc.: 48.44%] [G loss: 0.775455]\n",
      "epoch:45 step:35289 [D loss: 0.705337, acc.: 50.00%] [G loss: 0.710689]\n",
      "epoch:45 step:35290 [D loss: 0.699725, acc.: 46.88%] [G loss: 0.799449]\n",
      "epoch:45 step:35291 [D loss: 0.629032, acc.: 66.41%] [G loss: 0.894176]\n",
      "epoch:45 step:35292 [D loss: 0.685181, acc.: 46.88%] [G loss: 0.853509]\n",
      "epoch:45 step:35293 [D loss: 0.722768, acc.: 45.31%] [G loss: 0.895908]\n",
      "epoch:45 step:35294 [D loss: 0.622801, acc.: 70.31%] [G loss: 0.854759]\n",
      "epoch:45 step:35295 [D loss: 0.710522, acc.: 47.66%] [G loss: 0.799849]\n",
      "epoch:45 step:35296 [D loss: 0.678030, acc.: 58.59%] [G loss: 0.868384]\n",
      "epoch:45 step:35297 [D loss: 0.610481, acc.: 71.09%] [G loss: 0.730410]\n",
      "epoch:45 step:35298 [D loss: 0.653941, acc.: 61.72%] [G loss: 0.830229]\n",
      "epoch:45 step:35299 [D loss: 0.684382, acc.: 53.91%] [G loss: 0.826633]\n",
      "epoch:45 step:35300 [D loss: 0.668633, acc.: 54.69%] [G loss: 0.738588]\n",
      "epoch:45 step:35301 [D loss: 0.668679, acc.: 59.38%] [G loss: 0.898030]\n",
      "epoch:45 step:35302 [D loss: 0.672469, acc.: 60.94%] [G loss: 0.746015]\n",
      "epoch:45 step:35303 [D loss: 0.655129, acc.: 56.25%] [G loss: 0.786071]\n",
      "epoch:45 step:35304 [D loss: 0.638054, acc.: 64.06%] [G loss: 0.784015]\n",
      "epoch:45 step:35305 [D loss: 0.633983, acc.: 64.84%] [G loss: 0.765182]\n",
      "epoch:45 step:35306 [D loss: 0.749854, acc.: 45.31%] [G loss: 0.767110]\n",
      "epoch:45 step:35307 [D loss: 0.663486, acc.: 58.59%] [G loss: 0.766109]\n",
      "epoch:45 step:35308 [D loss: 0.693531, acc.: 52.34%] [G loss: 0.719175]\n",
      "epoch:45 step:35309 [D loss: 0.705229, acc.: 52.34%] [G loss: 0.785431]\n",
      "epoch:45 step:35310 [D loss: 0.662515, acc.: 63.28%] [G loss: 0.791143]\n",
      "epoch:45 step:35311 [D loss: 0.680339, acc.: 59.38%] [G loss: 0.765377]\n",
      "epoch:45 step:35312 [D loss: 0.648016, acc.: 60.16%] [G loss: 0.804169]\n",
      "epoch:45 step:35313 [D loss: 0.747726, acc.: 43.75%] [G loss: 0.759492]\n",
      "epoch:45 step:35314 [D loss: 0.712481, acc.: 47.66%] [G loss: 0.724641]\n",
      "epoch:45 step:35315 [D loss: 0.707737, acc.: 48.44%] [G loss: 0.805994]\n",
      "epoch:45 step:35316 [D loss: 0.719727, acc.: 55.47%] [G loss: 0.828837]\n",
      "epoch:45 step:35317 [D loss: 0.694848, acc.: 50.78%] [G loss: 0.878610]\n",
      "epoch:45 step:35318 [D loss: 0.700732, acc.: 50.78%] [G loss: 0.836532]\n",
      "epoch:45 step:35319 [D loss: 0.718701, acc.: 46.09%] [G loss: 0.966281]\n",
      "epoch:45 step:35320 [D loss: 0.611618, acc.: 73.44%] [G loss: 0.842711]\n",
      "epoch:45 step:35321 [D loss: 0.633437, acc.: 70.31%] [G loss: 0.839898]\n",
      "epoch:45 step:35322 [D loss: 0.650915, acc.: 61.72%] [G loss: 0.902583]\n",
      "epoch:45 step:35323 [D loss: 0.697865, acc.: 50.78%] [G loss: 0.900312]\n",
      "epoch:45 step:35324 [D loss: 0.639865, acc.: 67.19%] [G loss: 0.809120]\n",
      "epoch:45 step:35325 [D loss: 0.662334, acc.: 62.50%] [G loss: 0.802917]\n",
      "epoch:45 step:35326 [D loss: 0.604644, acc.: 74.22%] [G loss: 0.828591]\n",
      "epoch:45 step:35327 [D loss: 0.667267, acc.: 58.59%] [G loss: 0.780781]\n",
      "epoch:45 step:35328 [D loss: 0.697969, acc.: 50.78%] [G loss: 0.734153]\n",
      "epoch:45 step:35329 [D loss: 0.707422, acc.: 50.78%] [G loss: 0.723507]\n",
      "epoch:45 step:35330 [D loss: 0.714564, acc.: 46.09%] [G loss: 0.815096]\n",
      "epoch:45 step:35331 [D loss: 0.681818, acc.: 55.47%] [G loss: 0.898728]\n",
      "epoch:45 step:35332 [D loss: 0.715189, acc.: 49.22%] [G loss: 0.867981]\n",
      "epoch:45 step:35333 [D loss: 0.751597, acc.: 37.50%] [G loss: 0.779059]\n",
      "epoch:45 step:35334 [D loss: 0.625957, acc.: 67.19%] [G loss: 0.878271]\n",
      "epoch:45 step:35335 [D loss: 0.717917, acc.: 47.66%] [G loss: 0.724587]\n",
      "epoch:45 step:35336 [D loss: 0.697343, acc.: 51.56%] [G loss: 0.780388]\n",
      "epoch:45 step:35337 [D loss: 0.680797, acc.: 53.91%] [G loss: 0.848340]\n",
      "epoch:45 step:35338 [D loss: 0.701794, acc.: 51.56%] [G loss: 0.862037]\n",
      "epoch:45 step:35339 [D loss: 0.674760, acc.: 55.47%] [G loss: 0.896919]\n",
      "epoch:45 step:35340 [D loss: 0.661424, acc.: 62.50%] [G loss: 0.831823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35341 [D loss: 0.655980, acc.: 58.59%] [G loss: 0.896458]\n",
      "epoch:45 step:35342 [D loss: 0.695933, acc.: 53.12%] [G loss: 0.859147]\n",
      "epoch:45 step:35343 [D loss: 0.717964, acc.: 49.22%] [G loss: 0.758920]\n",
      "epoch:45 step:35344 [D loss: 0.734113, acc.: 52.34%] [G loss: 0.748212]\n",
      "epoch:45 step:35345 [D loss: 0.666680, acc.: 62.50%] [G loss: 0.821966]\n",
      "epoch:45 step:35346 [D loss: 0.688525, acc.: 55.47%] [G loss: 0.892931]\n",
      "epoch:45 step:35347 [D loss: 0.706549, acc.: 52.34%] [G loss: 0.806864]\n",
      "epoch:45 step:35348 [D loss: 0.680129, acc.: 60.16%] [G loss: 0.815583]\n",
      "epoch:45 step:35349 [D loss: 0.678691, acc.: 51.56%] [G loss: 0.735798]\n",
      "epoch:45 step:35350 [D loss: 0.727210, acc.: 49.22%] [G loss: 0.895978]\n",
      "epoch:45 step:35351 [D loss: 0.664827, acc.: 61.72%] [G loss: 0.850699]\n",
      "epoch:45 step:35352 [D loss: 0.565466, acc.: 78.12%] [G loss: 0.894161]\n",
      "epoch:45 step:35353 [D loss: 0.699202, acc.: 52.34%] [G loss: 0.787399]\n",
      "epoch:45 step:35354 [D loss: 0.760417, acc.: 42.97%] [G loss: 0.793634]\n",
      "epoch:45 step:35355 [D loss: 0.616630, acc.: 68.75%] [G loss: 0.716988]\n",
      "epoch:45 step:35356 [D loss: 0.660731, acc.: 60.16%] [G loss: 0.763540]\n",
      "epoch:45 step:35357 [D loss: 0.684355, acc.: 60.16%] [G loss: 0.942606]\n",
      "epoch:45 step:35358 [D loss: 0.730746, acc.: 46.09%] [G loss: 0.821234]\n",
      "epoch:45 step:35359 [D loss: 0.717785, acc.: 50.78%] [G loss: 0.778180]\n",
      "epoch:45 step:35360 [D loss: 0.687098, acc.: 53.12%] [G loss: 0.792124]\n",
      "epoch:45 step:35361 [D loss: 0.653569, acc.: 64.06%] [G loss: 0.822176]\n",
      "epoch:45 step:35362 [D loss: 0.603627, acc.: 73.44%] [G loss: 0.811370]\n",
      "epoch:45 step:35363 [D loss: 0.746377, acc.: 43.75%] [G loss: 0.820639]\n",
      "epoch:45 step:35364 [D loss: 0.660743, acc.: 64.06%] [G loss: 0.848745]\n",
      "epoch:45 step:35365 [D loss: 0.636146, acc.: 63.28%] [G loss: 0.784888]\n",
      "epoch:45 step:35366 [D loss: 0.757365, acc.: 37.50%] [G loss: 0.746509]\n",
      "epoch:45 step:35367 [D loss: 0.646173, acc.: 67.19%] [G loss: 0.731126]\n",
      "epoch:45 step:35368 [D loss: 0.748322, acc.: 43.75%] [G loss: 0.747374]\n",
      "epoch:45 step:35369 [D loss: 0.699714, acc.: 50.00%] [G loss: 0.648408]\n",
      "epoch:45 step:35370 [D loss: 0.626275, acc.: 62.50%] [G loss: 0.847014]\n",
      "epoch:45 step:35371 [D loss: 0.723967, acc.: 41.41%] [G loss: 0.645905]\n",
      "epoch:45 step:35372 [D loss: 0.669806, acc.: 53.91%] [G loss: 0.787992]\n",
      "epoch:45 step:35373 [D loss: 0.698106, acc.: 52.34%] [G loss: 0.787035]\n",
      "epoch:45 step:35374 [D loss: 0.742001, acc.: 46.09%] [G loss: 0.734686]\n",
      "epoch:45 step:35375 [D loss: 0.738664, acc.: 42.19%] [G loss: 0.831352]\n",
      "epoch:45 step:35376 [D loss: 0.648522, acc.: 65.62%] [G loss: 0.705528]\n",
      "epoch:45 step:35377 [D loss: 0.739906, acc.: 45.31%] [G loss: 0.729890]\n",
      "epoch:45 step:35378 [D loss: 0.632576, acc.: 67.19%] [G loss: 0.799724]\n",
      "epoch:45 step:35379 [D loss: 0.724586, acc.: 45.31%] [G loss: 0.793594]\n",
      "epoch:45 step:35380 [D loss: 0.658718, acc.: 58.59%] [G loss: 0.750112]\n",
      "epoch:45 step:35381 [D loss: 0.756872, acc.: 43.75%] [G loss: 0.706253]\n",
      "epoch:45 step:35382 [D loss: 0.710216, acc.: 50.78%] [G loss: 0.688849]\n",
      "epoch:45 step:35383 [D loss: 0.697091, acc.: 55.47%] [G loss: 0.736877]\n",
      "epoch:45 step:35384 [D loss: 0.650808, acc.: 67.19%] [G loss: 0.812873]\n",
      "epoch:45 step:35385 [D loss: 0.685146, acc.: 61.72%] [G loss: 0.796534]\n",
      "epoch:45 step:35386 [D loss: 0.699287, acc.: 52.34%] [G loss: 0.826819]\n",
      "epoch:45 step:35387 [D loss: 0.705047, acc.: 46.88%] [G loss: 0.780636]\n",
      "epoch:45 step:35388 [D loss: 0.699497, acc.: 50.00%] [G loss: 0.725325]\n",
      "epoch:45 step:35389 [D loss: 0.626277, acc.: 69.53%] [G loss: 0.844195]\n",
      "epoch:45 step:35390 [D loss: 0.683351, acc.: 50.78%] [G loss: 0.928075]\n",
      "epoch:45 step:35391 [D loss: 0.725761, acc.: 51.56%] [G loss: 0.756085]\n",
      "epoch:45 step:35392 [D loss: 0.599624, acc.: 72.66%] [G loss: 0.815628]\n",
      "epoch:45 step:35393 [D loss: 0.604772, acc.: 69.53%] [G loss: 0.898650]\n",
      "epoch:45 step:35394 [D loss: 0.620851, acc.: 71.09%] [G loss: 0.797505]\n",
      "epoch:45 step:35395 [D loss: 0.638458, acc.: 64.06%] [G loss: 0.716663]\n",
      "epoch:45 step:35396 [D loss: 0.662177, acc.: 57.81%] [G loss: 0.795009]\n",
      "epoch:45 step:35397 [D loss: 0.661135, acc.: 62.50%] [G loss: 0.750067]\n",
      "epoch:45 step:35398 [D loss: 0.691757, acc.: 53.12%] [G loss: 0.807304]\n",
      "epoch:45 step:35399 [D loss: 0.719986, acc.: 48.44%] [G loss: 0.826588]\n",
      "epoch:45 step:35400 [D loss: 0.742241, acc.: 43.75%] [G loss: 0.892699]\n",
      "epoch:45 step:35401 [D loss: 0.657383, acc.: 60.16%] [G loss: 0.798055]\n",
      "epoch:45 step:35402 [D loss: 0.662423, acc.: 59.38%] [G loss: 0.748638]\n",
      "epoch:45 step:35403 [D loss: 0.638704, acc.: 67.19%] [G loss: 0.776404]\n",
      "epoch:45 step:35404 [D loss: 0.747157, acc.: 39.84%] [G loss: 0.873942]\n",
      "epoch:45 step:35405 [D loss: 0.682151, acc.: 57.81%] [G loss: 0.841503]\n",
      "epoch:45 step:35406 [D loss: 0.625801, acc.: 69.53%] [G loss: 0.846597]\n",
      "epoch:45 step:35407 [D loss: 0.699553, acc.: 53.91%] [G loss: 0.898487]\n",
      "epoch:45 step:35408 [D loss: 0.713934, acc.: 52.34%] [G loss: 0.841402]\n",
      "epoch:45 step:35409 [D loss: 0.685365, acc.: 55.47%] [G loss: 0.741950]\n",
      "epoch:45 step:35410 [D loss: 0.699620, acc.: 52.34%] [G loss: 0.803197]\n",
      "epoch:45 step:35411 [D loss: 0.665748, acc.: 60.94%] [G loss: 0.825065]\n",
      "epoch:45 step:35412 [D loss: 0.770658, acc.: 38.28%] [G loss: 0.765169]\n",
      "epoch:45 step:35413 [D loss: 0.671968, acc.: 52.34%] [G loss: 0.836928]\n",
      "epoch:45 step:35414 [D loss: 0.609143, acc.: 71.88%] [G loss: 0.866091]\n",
      "epoch:45 step:35415 [D loss: 0.709198, acc.: 50.78%] [G loss: 0.772961]\n",
      "epoch:45 step:35416 [D loss: 0.706585, acc.: 51.56%] [G loss: 0.795325]\n",
      "epoch:45 step:35417 [D loss: 0.610680, acc.: 74.22%] [G loss: 0.838920]\n",
      "epoch:45 step:35418 [D loss: 0.662262, acc.: 64.06%] [G loss: 0.841246]\n",
      "epoch:45 step:35419 [D loss: 0.705071, acc.: 51.56%] [G loss: 0.837869]\n",
      "epoch:45 step:35420 [D loss: 0.660025, acc.: 64.84%] [G loss: 0.862584]\n",
      "epoch:45 step:35421 [D loss: 0.639207, acc.: 65.62%] [G loss: 0.853510]\n",
      "epoch:45 step:35422 [D loss: 0.727778, acc.: 52.34%] [G loss: 0.809423]\n",
      "epoch:45 step:35423 [D loss: 0.628349, acc.: 68.75%] [G loss: 0.754558]\n",
      "epoch:45 step:35424 [D loss: 0.640280, acc.: 64.84%] [G loss: 0.781184]\n",
      "epoch:45 step:35425 [D loss: 0.728597, acc.: 48.44%] [G loss: 0.768663]\n",
      "epoch:45 step:35426 [D loss: 0.712688, acc.: 51.56%] [G loss: 0.829951]\n",
      "epoch:45 step:35427 [D loss: 0.640630, acc.: 65.62%] [G loss: 0.750065]\n",
      "epoch:45 step:35428 [D loss: 0.576038, acc.: 79.69%] [G loss: 0.928392]\n",
      "epoch:45 step:35429 [D loss: 0.652629, acc.: 64.84%] [G loss: 0.796282]\n",
      "epoch:45 step:35430 [D loss: 0.624493, acc.: 66.41%] [G loss: 0.858360]\n",
      "epoch:45 step:35431 [D loss: 0.616651, acc.: 71.09%] [G loss: 0.834476]\n",
      "epoch:45 step:35432 [D loss: 0.686772, acc.: 55.47%] [G loss: 0.728527]\n",
      "epoch:45 step:35433 [D loss: 0.724332, acc.: 50.00%] [G loss: 0.801161]\n",
      "epoch:45 step:35434 [D loss: 0.680834, acc.: 54.69%] [G loss: 0.724899]\n",
      "epoch:45 step:35435 [D loss: 0.693393, acc.: 55.47%] [G loss: 0.710261]\n",
      "epoch:45 step:35436 [D loss: 0.783736, acc.: 36.72%] [G loss: 0.828211]\n",
      "epoch:45 step:35437 [D loss: 0.702144, acc.: 52.34%] [G loss: 0.792870]\n",
      "epoch:45 step:35438 [D loss: 0.667545, acc.: 59.38%] [G loss: 0.846887]\n",
      "epoch:45 step:35439 [D loss: 0.665356, acc.: 61.72%] [G loss: 0.883191]\n",
      "epoch:45 step:35440 [D loss: 0.670792, acc.: 56.25%] [G loss: 0.849465]\n",
      "epoch:45 step:35441 [D loss: 0.673185, acc.: 52.34%] [G loss: 0.820295]\n",
      "epoch:45 step:35442 [D loss: 0.629979, acc.: 73.44%] [G loss: 0.784090]\n",
      "epoch:45 step:35443 [D loss: 0.654529, acc.: 63.28%] [G loss: 0.735423]\n",
      "epoch:45 step:35444 [D loss: 0.682947, acc.: 57.81%] [G loss: 0.769148]\n",
      "epoch:45 step:35445 [D loss: 0.745885, acc.: 42.19%] [G loss: 0.783935]\n",
      "epoch:45 step:35446 [D loss: 0.699203, acc.: 53.91%] [G loss: 0.776999]\n",
      "epoch:45 step:35447 [D loss: 0.646983, acc.: 64.06%] [G loss: 0.833755]\n",
      "epoch:45 step:35448 [D loss: 0.621372, acc.: 70.31%] [G loss: 0.838862]\n",
      "epoch:45 step:35449 [D loss: 0.702557, acc.: 55.47%] [G loss: 0.807554]\n",
      "epoch:45 step:35450 [D loss: 0.638577, acc.: 66.41%] [G loss: 0.785246]\n",
      "epoch:45 step:35451 [D loss: 0.620718, acc.: 66.41%] [G loss: 0.697382]\n",
      "epoch:45 step:35452 [D loss: 0.648529, acc.: 60.16%] [G loss: 0.754903]\n",
      "epoch:45 step:35453 [D loss: 0.680028, acc.: 52.34%] [G loss: 0.778974]\n",
      "epoch:45 step:35454 [D loss: 0.645849, acc.: 68.75%] [G loss: 0.792869]\n",
      "epoch:45 step:35455 [D loss: 0.674186, acc.: 62.50%] [G loss: 0.854785]\n",
      "epoch:45 step:35456 [D loss: 0.681897, acc.: 53.12%] [G loss: 0.773592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35457 [D loss: 0.704221, acc.: 47.66%] [G loss: 0.691804]\n",
      "epoch:45 step:35458 [D loss: 0.674336, acc.: 62.50%] [G loss: 0.790602]\n",
      "epoch:45 step:35459 [D loss: 0.715439, acc.: 48.44%] [G loss: 0.858617]\n",
      "epoch:45 step:35460 [D loss: 0.692006, acc.: 54.69%] [G loss: 0.772034]\n",
      "epoch:45 step:35461 [D loss: 0.690363, acc.: 56.25%] [G loss: 0.771454]\n",
      "epoch:45 step:35462 [D loss: 0.738836, acc.: 46.88%] [G loss: 0.806346]\n",
      "epoch:45 step:35463 [D loss: 0.679550, acc.: 51.56%] [G loss: 0.772709]\n",
      "epoch:45 step:35464 [D loss: 0.708811, acc.: 50.78%] [G loss: 0.824232]\n",
      "epoch:45 step:35465 [D loss: 0.683351, acc.: 57.03%] [G loss: 0.811543]\n",
      "epoch:45 step:35466 [D loss: 0.679495, acc.: 57.81%] [G loss: 0.848266]\n",
      "epoch:45 step:35467 [D loss: 0.739669, acc.: 43.75%] [G loss: 0.788802]\n",
      "epoch:45 step:35468 [D loss: 0.683164, acc.: 56.25%] [G loss: 0.826457]\n",
      "epoch:45 step:35469 [D loss: 0.662861, acc.: 59.38%] [G loss: 0.831798]\n",
      "epoch:45 step:35470 [D loss: 0.658085, acc.: 63.28%] [G loss: 0.788799]\n",
      "epoch:45 step:35471 [D loss: 0.613302, acc.: 73.44%] [G loss: 0.797002]\n",
      "epoch:45 step:35472 [D loss: 0.598802, acc.: 78.12%] [G loss: 0.779187]\n",
      "epoch:45 step:35473 [D loss: 0.722353, acc.: 46.88%] [G loss: 0.737205]\n",
      "epoch:45 step:35474 [D loss: 0.702712, acc.: 51.56%] [G loss: 0.863005]\n",
      "epoch:45 step:35475 [D loss: 0.697171, acc.: 47.66%] [G loss: 0.735517]\n",
      "epoch:45 step:35476 [D loss: 0.712076, acc.: 50.78%] [G loss: 0.775555]\n",
      "epoch:45 step:35477 [D loss: 0.670774, acc.: 57.03%] [G loss: 0.724024]\n",
      "epoch:45 step:35478 [D loss: 0.642468, acc.: 68.75%] [G loss: 0.707466]\n",
      "epoch:45 step:35479 [D loss: 0.791394, acc.: 37.50%] [G loss: 0.779969]\n",
      "epoch:45 step:35480 [D loss: 0.635660, acc.: 63.28%] [G loss: 0.751240]\n",
      "epoch:45 step:35481 [D loss: 0.734197, acc.: 48.44%] [G loss: 0.727962]\n",
      "epoch:45 step:35482 [D loss: 0.671436, acc.: 57.81%] [G loss: 0.744400]\n",
      "epoch:45 step:35483 [D loss: 0.751267, acc.: 39.06%] [G loss: 0.716039]\n",
      "epoch:45 step:35484 [D loss: 0.651372, acc.: 61.72%] [G loss: 0.862750]\n",
      "epoch:45 step:35485 [D loss: 0.714313, acc.: 55.47%] [G loss: 0.746190]\n",
      "epoch:45 step:35486 [D loss: 0.667393, acc.: 57.81%] [G loss: 0.851802]\n",
      "epoch:45 step:35487 [D loss: 0.663745, acc.: 58.59%] [G loss: 0.686850]\n",
      "epoch:45 step:35488 [D loss: 0.673729, acc.: 57.03%] [G loss: 0.803593]\n",
      "epoch:45 step:35489 [D loss: 0.665349, acc.: 57.03%] [G loss: 0.700417]\n",
      "epoch:45 step:35490 [D loss: 0.657292, acc.: 65.62%] [G loss: 0.780271]\n",
      "epoch:45 step:35491 [D loss: 0.725733, acc.: 47.66%] [G loss: 0.792172]\n",
      "epoch:45 step:35492 [D loss: 0.700461, acc.: 51.56%] [G loss: 0.864076]\n",
      "epoch:45 step:35493 [D loss: 0.701702, acc.: 50.78%] [G loss: 0.728900]\n",
      "epoch:45 step:35494 [D loss: 0.714385, acc.: 48.44%] [G loss: 0.835551]\n",
      "epoch:45 step:35495 [D loss: 0.663219, acc.: 59.38%] [G loss: 0.886081]\n",
      "epoch:45 step:35496 [D loss: 0.681182, acc.: 57.81%] [G loss: 0.749532]\n",
      "epoch:45 step:35497 [D loss: 0.681993, acc.: 57.81%] [G loss: 0.846746]\n",
      "epoch:45 step:35498 [D loss: 0.633479, acc.: 69.53%] [G loss: 0.859488]\n",
      "epoch:45 step:35499 [D loss: 0.657078, acc.: 57.03%] [G loss: 0.781372]\n",
      "epoch:45 step:35500 [D loss: 0.686805, acc.: 61.72%] [G loss: 0.822205]\n",
      "epoch:45 step:35501 [D loss: 0.664591, acc.: 57.03%] [G loss: 0.741721]\n",
      "epoch:45 step:35502 [D loss: 0.755743, acc.: 38.28%] [G loss: 0.709938]\n",
      "epoch:45 step:35503 [D loss: 0.704861, acc.: 48.44%] [G loss: 0.782969]\n",
      "epoch:45 step:35504 [D loss: 0.626812, acc.: 73.44%] [G loss: 0.792258]\n",
      "epoch:45 step:35505 [D loss: 0.715926, acc.: 45.31%] [G loss: 0.726065]\n",
      "epoch:45 step:35506 [D loss: 0.720778, acc.: 49.22%] [G loss: 0.757062]\n",
      "epoch:45 step:35507 [D loss: 0.581743, acc.: 78.12%] [G loss: 0.840558]\n",
      "epoch:45 step:35508 [D loss: 0.690973, acc.: 53.12%] [G loss: 0.719863]\n",
      "epoch:45 step:35509 [D loss: 0.706609, acc.: 47.66%] [G loss: 0.795060]\n",
      "epoch:45 step:35510 [D loss: 0.696993, acc.: 52.34%] [G loss: 0.758592]\n",
      "epoch:45 step:35511 [D loss: 0.735826, acc.: 49.22%] [G loss: 0.730556]\n",
      "epoch:45 step:35512 [D loss: 0.674675, acc.: 56.25%] [G loss: 0.831140]\n",
      "epoch:45 step:35513 [D loss: 0.698822, acc.: 51.56%] [G loss: 0.762575]\n",
      "epoch:45 step:35514 [D loss: 0.734056, acc.: 48.44%] [G loss: 0.796821]\n",
      "epoch:45 step:35515 [D loss: 0.639924, acc.: 65.62%] [G loss: 0.825892]\n",
      "epoch:45 step:35516 [D loss: 0.680204, acc.: 60.94%] [G loss: 0.775235]\n",
      "epoch:45 step:35517 [D loss: 0.629158, acc.: 67.19%] [G loss: 0.895285]\n",
      "epoch:45 step:35518 [D loss: 0.709326, acc.: 50.00%] [G loss: 0.876179]\n",
      "epoch:45 step:35519 [D loss: 0.703603, acc.: 46.88%] [G loss: 0.787861]\n",
      "epoch:45 step:35520 [D loss: 0.699391, acc.: 52.34%] [G loss: 0.814390]\n",
      "epoch:45 step:35521 [D loss: 0.672633, acc.: 57.81%] [G loss: 0.815237]\n",
      "epoch:45 step:35522 [D loss: 0.687832, acc.: 56.25%] [G loss: 0.796859]\n",
      "epoch:45 step:35523 [D loss: 0.678997, acc.: 57.03%] [G loss: 0.820783]\n",
      "epoch:45 step:35524 [D loss: 0.624639, acc.: 72.66%] [G loss: 0.815271]\n",
      "epoch:45 step:35525 [D loss: 0.709258, acc.: 52.34%] [G loss: 0.778767]\n",
      "epoch:45 step:35526 [D loss: 0.540764, acc.: 84.38%] [G loss: 0.878711]\n",
      "epoch:45 step:35527 [D loss: 0.752803, acc.: 42.97%] [G loss: 0.823179]\n",
      "epoch:45 step:35528 [D loss: 0.597485, acc.: 73.44%] [G loss: 0.899326]\n",
      "epoch:45 step:35529 [D loss: 0.634270, acc.: 66.41%] [G loss: 0.910154]\n",
      "epoch:45 step:35530 [D loss: 0.687282, acc.: 55.47%] [G loss: 0.874484]\n",
      "epoch:45 step:35531 [D loss: 0.585137, acc.: 78.12%] [G loss: 0.873217]\n",
      "epoch:45 step:35532 [D loss: 0.624294, acc.: 69.53%] [G loss: 0.905794]\n",
      "epoch:45 step:35533 [D loss: 0.694379, acc.: 56.25%] [G loss: 0.892530]\n",
      "epoch:45 step:35534 [D loss: 0.657510, acc.: 60.94%] [G loss: 0.888581]\n",
      "epoch:45 step:35535 [D loss: 0.655062, acc.: 58.59%] [G loss: 0.804075]\n",
      "epoch:45 step:35536 [D loss: 0.662265, acc.: 57.03%] [G loss: 0.919746]\n",
      "epoch:45 step:35537 [D loss: 0.697673, acc.: 52.34%] [G loss: 0.805363]\n",
      "epoch:45 step:35538 [D loss: 0.656295, acc.: 63.28%] [G loss: 0.777340]\n",
      "epoch:45 step:35539 [D loss: 0.635267, acc.: 63.28%] [G loss: 0.729878]\n",
      "epoch:45 step:35540 [D loss: 0.696681, acc.: 57.03%] [G loss: 0.708577]\n",
      "epoch:45 step:35541 [D loss: 0.732745, acc.: 49.22%] [G loss: 0.810183]\n",
      "epoch:45 step:35542 [D loss: 0.655546, acc.: 59.38%] [G loss: 0.729765]\n",
      "epoch:45 step:35543 [D loss: 0.678508, acc.: 57.03%] [G loss: 0.798317]\n",
      "epoch:45 step:35544 [D loss: 0.622846, acc.: 70.31%] [G loss: 0.774980]\n",
      "epoch:45 step:35545 [D loss: 0.743898, acc.: 45.31%] [G loss: 0.722774]\n",
      "epoch:45 step:35546 [D loss: 0.606714, acc.: 71.09%] [G loss: 0.686812]\n",
      "epoch:45 step:35547 [D loss: 0.635983, acc.: 71.09%] [G loss: 0.743597]\n",
      "epoch:45 step:35548 [D loss: 0.679129, acc.: 57.81%] [G loss: 0.693846]\n",
      "epoch:45 step:35549 [D loss: 0.687794, acc.: 55.47%] [G loss: 0.696304]\n",
      "epoch:45 step:35550 [D loss: 0.725635, acc.: 42.19%] [G loss: 0.836127]\n",
      "epoch:45 step:35551 [D loss: 0.694633, acc.: 55.47%] [G loss: 0.831686]\n",
      "epoch:45 step:35552 [D loss: 0.681401, acc.: 51.56%] [G loss: 0.699562]\n",
      "epoch:45 step:35553 [D loss: 0.727223, acc.: 39.84%] [G loss: 0.871327]\n",
      "epoch:45 step:35554 [D loss: 0.710508, acc.: 46.88%] [G loss: 0.804705]\n",
      "epoch:45 step:35555 [D loss: 0.675149, acc.: 55.47%] [G loss: 0.900579]\n",
      "epoch:45 step:35556 [D loss: 0.667111, acc.: 64.06%] [G loss: 0.838636]\n",
      "epoch:45 step:35557 [D loss: 0.731828, acc.: 46.88%] [G loss: 0.661313]\n",
      "epoch:45 step:35558 [D loss: 0.726460, acc.: 47.66%] [G loss: 0.762880]\n",
      "epoch:45 step:35559 [D loss: 0.682756, acc.: 60.94%] [G loss: 0.830816]\n",
      "epoch:45 step:35560 [D loss: 0.701427, acc.: 54.69%] [G loss: 0.785671]\n",
      "epoch:45 step:35561 [D loss: 0.637697, acc.: 65.62%] [G loss: 0.778519]\n",
      "epoch:45 step:35562 [D loss: 0.716458, acc.: 46.88%] [G loss: 0.852981]\n",
      "epoch:45 step:35563 [D loss: 0.665369, acc.: 57.81%] [G loss: 0.786434]\n",
      "epoch:45 step:35564 [D loss: 0.679568, acc.: 57.03%] [G loss: 0.868572]\n",
      "epoch:45 step:35565 [D loss: 0.746629, acc.: 46.09%] [G loss: 0.679278]\n",
      "epoch:45 step:35566 [D loss: 0.654139, acc.: 64.06%] [G loss: 0.833004]\n",
      "epoch:45 step:35567 [D loss: 0.708138, acc.: 51.56%] [G loss: 0.878587]\n",
      "epoch:45 step:35568 [D loss: 0.644051, acc.: 63.28%] [G loss: 0.919292]\n",
      "epoch:45 step:35569 [D loss: 0.746406, acc.: 45.31%] [G loss: 0.835639]\n",
      "epoch:45 step:35570 [D loss: 0.643732, acc.: 68.75%] [G loss: 0.790272]\n",
      "epoch:45 step:35571 [D loss: 0.715485, acc.: 46.88%] [G loss: 0.808695]\n",
      "epoch:45 step:35572 [D loss: 0.588889, acc.: 76.56%] [G loss: 0.777025]\n",
      "epoch:45 step:35573 [D loss: 0.727613, acc.: 54.69%] [G loss: 0.758311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35574 [D loss: 0.628467, acc.: 67.97%] [G loss: 0.782582]\n",
      "epoch:45 step:35575 [D loss: 0.638712, acc.: 67.97%] [G loss: 0.733984]\n",
      "epoch:45 step:35576 [D loss: 0.707428, acc.: 46.09%] [G loss: 0.783864]\n",
      "epoch:45 step:35577 [D loss: 0.667606, acc.: 57.03%] [G loss: 0.787393]\n",
      "epoch:45 step:35578 [D loss: 0.621179, acc.: 68.75%] [G loss: 0.834460]\n",
      "epoch:45 step:35579 [D loss: 0.660743, acc.: 60.16%] [G loss: 0.766353]\n",
      "epoch:45 step:35580 [D loss: 0.646091, acc.: 62.50%] [G loss: 0.722476]\n",
      "epoch:45 step:35581 [D loss: 0.787492, acc.: 38.28%] [G loss: 0.773957]\n",
      "epoch:45 step:35582 [D loss: 0.682212, acc.: 53.91%] [G loss: 0.949700]\n",
      "epoch:45 step:35583 [D loss: 0.656817, acc.: 61.72%] [G loss: 0.857619]\n",
      "epoch:45 step:35584 [D loss: 0.700603, acc.: 56.25%] [G loss: 0.857413]\n",
      "epoch:45 step:35585 [D loss: 0.601921, acc.: 67.97%] [G loss: 0.821768]\n",
      "epoch:45 step:35586 [D loss: 0.718745, acc.: 51.56%] [G loss: 0.806633]\n",
      "epoch:45 step:35587 [D loss: 0.596269, acc.: 75.78%] [G loss: 0.816711]\n",
      "epoch:45 step:35588 [D loss: 0.636329, acc.: 63.28%] [G loss: 0.854236]\n",
      "epoch:45 step:35589 [D loss: 0.702191, acc.: 51.56%] [G loss: 0.835015]\n",
      "epoch:45 step:35590 [D loss: 0.693441, acc.: 51.56%] [G loss: 0.838372]\n",
      "epoch:45 step:35591 [D loss: 0.707171, acc.: 50.78%] [G loss: 0.803671]\n",
      "epoch:45 step:35592 [D loss: 0.747159, acc.: 43.75%] [G loss: 0.723732]\n",
      "epoch:45 step:35593 [D loss: 0.688580, acc.: 54.69%] [G loss: 0.770968]\n",
      "epoch:45 step:35594 [D loss: 0.756568, acc.: 44.53%] [G loss: 0.754997]\n",
      "epoch:45 step:35595 [D loss: 0.712818, acc.: 46.88%] [G loss: 0.722520]\n",
      "epoch:45 step:35596 [D loss: 0.710421, acc.: 51.56%] [G loss: 0.830606]\n",
      "epoch:45 step:35597 [D loss: 0.676642, acc.: 57.03%] [G loss: 0.875541]\n",
      "epoch:45 step:35598 [D loss: 0.716822, acc.: 48.44%] [G loss: 0.773427]\n",
      "epoch:45 step:35599 [D loss: 0.685119, acc.: 60.16%] [G loss: 0.854257]\n",
      "epoch:45 step:35600 [D loss: 0.658971, acc.: 62.50%] [G loss: 0.803901]\n",
      "epoch:45 step:35601 [D loss: 0.633390, acc.: 63.28%] [G loss: 0.905541]\n",
      "epoch:45 step:35602 [D loss: 0.715225, acc.: 48.44%] [G loss: 0.819076]\n",
      "epoch:45 step:35603 [D loss: 0.695754, acc.: 50.78%] [G loss: 0.862204]\n",
      "epoch:45 step:35604 [D loss: 0.724724, acc.: 50.00%] [G loss: 0.825960]\n",
      "epoch:45 step:35605 [D loss: 0.632987, acc.: 65.62%] [G loss: 0.850628]\n",
      "epoch:45 step:35606 [D loss: 0.704983, acc.: 48.44%] [G loss: 0.747528]\n",
      "epoch:45 step:35607 [D loss: 0.651971, acc.: 61.72%] [G loss: 0.886267]\n",
      "epoch:45 step:35608 [D loss: 0.651735, acc.: 62.50%] [G loss: 0.881178]\n",
      "epoch:45 step:35609 [D loss: 0.637483, acc.: 62.50%] [G loss: 0.831751]\n",
      "epoch:45 step:35610 [D loss: 0.641449, acc.: 64.06%] [G loss: 0.824908]\n",
      "epoch:45 step:35611 [D loss: 0.669991, acc.: 61.72%] [G loss: 0.901985]\n",
      "epoch:45 step:35612 [D loss: 0.715852, acc.: 51.56%] [G loss: 0.811559]\n",
      "epoch:45 step:35613 [D loss: 0.659191, acc.: 58.59%] [G loss: 0.836078]\n",
      "epoch:45 step:35614 [D loss: 0.669743, acc.: 55.47%] [G loss: 0.854554]\n",
      "epoch:45 step:35615 [D loss: 0.656056, acc.: 64.06%] [G loss: 0.836968]\n",
      "epoch:45 step:35616 [D loss: 0.727014, acc.: 42.19%] [G loss: 0.765335]\n",
      "epoch:45 step:35617 [D loss: 0.634607, acc.: 68.75%] [G loss: 0.897654]\n",
      "epoch:45 step:35618 [D loss: 0.761533, acc.: 41.41%] [G loss: 0.756256]\n",
      "epoch:45 step:35619 [D loss: 0.687865, acc.: 55.47%] [G loss: 0.768908]\n",
      "epoch:45 step:35620 [D loss: 0.702894, acc.: 54.69%] [G loss: 0.763215]\n",
      "epoch:45 step:35621 [D loss: 0.636230, acc.: 65.62%] [G loss: 0.819647]\n",
      "epoch:45 step:35622 [D loss: 0.713842, acc.: 52.34%] [G loss: 0.733436]\n",
      "epoch:45 step:35623 [D loss: 0.567726, acc.: 85.94%] [G loss: 0.851561]\n",
      "epoch:45 step:35624 [D loss: 0.755109, acc.: 39.06%] [G loss: 0.799378]\n",
      "epoch:45 step:35625 [D loss: 0.631831, acc.: 71.09%] [G loss: 0.904743]\n",
      "epoch:45 step:35626 [D loss: 0.710583, acc.: 50.78%] [G loss: 0.762656]\n",
      "epoch:45 step:35627 [D loss: 0.729616, acc.: 43.75%] [G loss: 0.759678]\n",
      "epoch:45 step:35628 [D loss: 0.711035, acc.: 45.31%] [G loss: 0.790571]\n",
      "epoch:45 step:35629 [D loss: 0.701877, acc.: 53.91%] [G loss: 0.706993]\n",
      "epoch:45 step:35630 [D loss: 0.646728, acc.: 64.06%] [G loss: 0.667735]\n",
      "epoch:45 step:35631 [D loss: 0.713444, acc.: 46.09%] [G loss: 0.809448]\n",
      "epoch:45 step:35632 [D loss: 0.677147, acc.: 52.34%] [G loss: 0.801623]\n",
      "epoch:45 step:35633 [D loss: 0.721937, acc.: 47.66%] [G loss: 0.689130]\n",
      "epoch:45 step:35634 [D loss: 0.652876, acc.: 67.19%] [G loss: 0.814821]\n",
      "epoch:45 step:35635 [D loss: 0.653676, acc.: 62.50%] [G loss: 0.733710]\n",
      "epoch:45 step:35636 [D loss: 0.684630, acc.: 56.25%] [G loss: 0.782233]\n",
      "epoch:45 step:35637 [D loss: 0.681792, acc.: 54.69%] [G loss: 0.776629]\n",
      "epoch:45 step:35638 [D loss: 0.659944, acc.: 66.41%] [G loss: 0.768969]\n",
      "epoch:45 step:35639 [D loss: 0.711654, acc.: 49.22%] [G loss: 0.732998]\n",
      "epoch:45 step:35640 [D loss: 0.679648, acc.: 56.25%] [G loss: 0.878401]\n",
      "epoch:45 step:35641 [D loss: 0.660502, acc.: 60.94%] [G loss: 0.840802]\n",
      "epoch:45 step:35642 [D loss: 0.676059, acc.: 56.25%] [G loss: 0.811009]\n",
      "epoch:45 step:35643 [D loss: 0.631852, acc.: 68.75%] [G loss: 0.914847]\n",
      "epoch:45 step:35644 [D loss: 0.678651, acc.: 54.69%] [G loss: 0.756773]\n",
      "epoch:45 step:35645 [D loss: 0.636814, acc.: 60.16%] [G loss: 0.762928]\n",
      "epoch:45 step:35646 [D loss: 0.675677, acc.: 60.16%] [G loss: 0.812263]\n",
      "epoch:45 step:35647 [D loss: 0.676794, acc.: 53.91%] [G loss: 0.749889]\n",
      "epoch:45 step:35648 [D loss: 0.690553, acc.: 53.91%] [G loss: 0.762922]\n",
      "epoch:45 step:35649 [D loss: 0.708529, acc.: 53.12%] [G loss: 0.826985]\n",
      "epoch:45 step:35650 [D loss: 0.631066, acc.: 67.97%] [G loss: 0.803642]\n",
      "epoch:45 step:35651 [D loss: 0.700196, acc.: 52.34%] [G loss: 0.825185]\n",
      "epoch:45 step:35652 [D loss: 0.666151, acc.: 63.28%] [G loss: 0.825548]\n",
      "epoch:45 step:35653 [D loss: 0.656808, acc.: 61.72%] [G loss: 0.804209]\n",
      "epoch:45 step:35654 [D loss: 0.669224, acc.: 54.69%] [G loss: 0.744624]\n",
      "epoch:45 step:35655 [D loss: 0.615696, acc.: 72.66%] [G loss: 0.801899]\n",
      "epoch:45 step:35656 [D loss: 0.753943, acc.: 43.75%] [G loss: 0.699852]\n",
      "epoch:45 step:35657 [D loss: 0.664737, acc.: 59.38%] [G loss: 0.890643]\n",
      "epoch:45 step:35658 [D loss: 0.724800, acc.: 45.31%] [G loss: 0.772429]\n",
      "epoch:45 step:35659 [D loss: 0.796466, acc.: 35.16%] [G loss: 0.675488]\n",
      "epoch:45 step:35660 [D loss: 0.676462, acc.: 57.03%] [G loss: 0.792149]\n",
      "epoch:45 step:35661 [D loss: 0.703547, acc.: 56.25%] [G loss: 0.752585]\n",
      "epoch:45 step:35662 [D loss: 0.678275, acc.: 58.59%] [G loss: 0.743045]\n",
      "epoch:45 step:35663 [D loss: 0.631827, acc.: 64.84%] [G loss: 0.768289]\n",
      "epoch:45 step:35664 [D loss: 0.750384, acc.: 41.41%] [G loss: 0.723553]\n",
      "epoch:45 step:35665 [D loss: 0.673391, acc.: 60.94%] [G loss: 0.811685]\n",
      "epoch:45 step:35666 [D loss: 0.684663, acc.: 55.47%] [G loss: 0.766930]\n",
      "epoch:45 step:35667 [D loss: 0.768385, acc.: 39.84%] [G loss: 0.825735]\n",
      "epoch:45 step:35668 [D loss: 0.662999, acc.: 58.59%] [G loss: 0.798114]\n",
      "epoch:45 step:35669 [D loss: 0.674483, acc.: 60.94%] [G loss: 0.768901]\n",
      "epoch:45 step:35670 [D loss: 0.688843, acc.: 51.56%] [G loss: 0.824682]\n",
      "epoch:45 step:35671 [D loss: 0.604787, acc.: 74.22%] [G loss: 0.819654]\n",
      "epoch:45 step:35672 [D loss: 0.704741, acc.: 52.34%] [G loss: 0.800576]\n",
      "epoch:45 step:35673 [D loss: 0.689860, acc.: 57.03%] [G loss: 0.733424]\n",
      "epoch:45 step:35674 [D loss: 0.640531, acc.: 64.84%] [G loss: 0.738565]\n",
      "epoch:45 step:35675 [D loss: 0.598807, acc.: 72.66%] [G loss: 0.826635]\n",
      "epoch:45 step:35676 [D loss: 0.619947, acc.: 71.09%] [G loss: 0.791642]\n",
      "epoch:45 step:35677 [D loss: 0.675338, acc.: 54.69%] [G loss: 0.876187]\n",
      "epoch:45 step:35678 [D loss: 0.653333, acc.: 66.41%] [G loss: 0.898203]\n",
      "epoch:45 step:35679 [D loss: 0.694993, acc.: 51.56%] [G loss: 0.826736]\n",
      "epoch:45 step:35680 [D loss: 0.665522, acc.: 62.50%] [G loss: 0.799973]\n",
      "epoch:45 step:35681 [D loss: 0.731938, acc.: 47.66%] [G loss: 0.768274]\n",
      "epoch:45 step:35682 [D loss: 0.688004, acc.: 55.47%] [G loss: 0.837924]\n",
      "epoch:45 step:35683 [D loss: 0.621480, acc.: 63.28%] [G loss: 0.769813]\n",
      "epoch:45 step:35684 [D loss: 0.663714, acc.: 57.81%] [G loss: 0.728398]\n",
      "epoch:45 step:35685 [D loss: 0.653205, acc.: 57.03%] [G loss: 0.799555]\n",
      "epoch:45 step:35686 [D loss: 0.608240, acc.: 73.44%] [G loss: 0.758586]\n",
      "epoch:45 step:35687 [D loss: 0.656610, acc.: 61.72%] [G loss: 0.761075]\n",
      "epoch:45 step:35688 [D loss: 0.658935, acc.: 64.84%] [G loss: 0.809963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35689 [D loss: 0.695636, acc.: 50.78%] [G loss: 0.819144]\n",
      "epoch:45 step:35690 [D loss: 0.613397, acc.: 67.19%] [G loss: 0.868304]\n",
      "epoch:45 step:35691 [D loss: 0.692447, acc.: 54.69%] [G loss: 0.826377]\n",
      "epoch:45 step:35692 [D loss: 0.642888, acc.: 67.97%] [G loss: 0.858449]\n",
      "epoch:45 step:35693 [D loss: 0.712744, acc.: 46.88%] [G loss: 0.773402]\n",
      "epoch:45 step:35694 [D loss: 0.630755, acc.: 70.31%] [G loss: 0.943506]\n",
      "epoch:45 step:35695 [D loss: 0.654006, acc.: 64.84%] [G loss: 0.797495]\n",
      "epoch:45 step:35696 [D loss: 0.707765, acc.: 50.00%] [G loss: 0.731445]\n",
      "epoch:45 step:35697 [D loss: 0.746445, acc.: 39.06%] [G loss: 0.777950]\n",
      "epoch:45 step:35698 [D loss: 0.708871, acc.: 56.25%] [G loss: 0.694245]\n",
      "epoch:45 step:35699 [D loss: 0.717430, acc.: 52.34%] [G loss: 0.955187]\n",
      "epoch:45 step:35700 [D loss: 0.647284, acc.: 68.75%] [G loss: 0.793044]\n",
      "epoch:45 step:35701 [D loss: 0.704634, acc.: 51.56%] [G loss: 0.829659]\n",
      "epoch:45 step:35702 [D loss: 0.622213, acc.: 66.41%] [G loss: 0.881947]\n",
      "epoch:45 step:35703 [D loss: 0.762584, acc.: 42.19%] [G loss: 0.784996]\n",
      "epoch:45 step:35704 [D loss: 0.655905, acc.: 57.81%] [G loss: 0.817289]\n",
      "epoch:45 step:35705 [D loss: 0.683182, acc.: 53.91%] [G loss: 0.806161]\n",
      "epoch:45 step:35706 [D loss: 0.728454, acc.: 49.22%] [G loss: 0.805160]\n",
      "epoch:45 step:35707 [D loss: 0.676539, acc.: 59.38%] [G loss: 0.814299]\n",
      "epoch:45 step:35708 [D loss: 0.647050, acc.: 70.31%] [G loss: 0.830047]\n",
      "epoch:45 step:35709 [D loss: 0.665382, acc.: 53.12%] [G loss: 0.820897]\n",
      "epoch:45 step:35710 [D loss: 0.635299, acc.: 69.53%] [G loss: 0.900777]\n",
      "epoch:45 step:35711 [D loss: 0.775867, acc.: 32.81%] [G loss: 0.761170]\n",
      "epoch:45 step:35712 [D loss: 0.731118, acc.: 44.53%] [G loss: 0.787515]\n",
      "epoch:45 step:35713 [D loss: 0.629223, acc.: 69.53%] [G loss: 0.798439]\n",
      "epoch:45 step:35714 [D loss: 0.657123, acc.: 57.03%] [G loss: 0.929565]\n",
      "epoch:45 step:35715 [D loss: 0.795522, acc.: 34.38%] [G loss: 0.699899]\n",
      "epoch:45 step:35716 [D loss: 0.792716, acc.: 33.59%] [G loss: 0.731316]\n",
      "epoch:45 step:35717 [D loss: 0.708031, acc.: 47.66%] [G loss: 0.689211]\n",
      "epoch:45 step:35718 [D loss: 0.701403, acc.: 51.56%] [G loss: 0.796510]\n",
      "epoch:45 step:35719 [D loss: 0.673466, acc.: 57.03%] [G loss: 0.777194]\n",
      "epoch:45 step:35720 [D loss: 0.779349, acc.: 39.84%] [G loss: 0.771520]\n",
      "epoch:45 step:35721 [D loss: 0.702465, acc.: 53.12%] [G loss: 0.668308]\n",
      "epoch:45 step:35722 [D loss: 0.705820, acc.: 53.91%] [G loss: 0.720402]\n",
      "epoch:45 step:35723 [D loss: 0.665026, acc.: 63.28%] [G loss: 0.767007]\n",
      "epoch:45 step:35724 [D loss: 0.634991, acc.: 67.97%] [G loss: 0.714040]\n",
      "epoch:45 step:35725 [D loss: 0.657824, acc.: 57.81%] [G loss: 0.818328]\n",
      "epoch:45 step:35726 [D loss: 0.672174, acc.: 58.59%] [G loss: 0.739411]\n",
      "epoch:45 step:35727 [D loss: 0.632221, acc.: 66.41%] [G loss: 0.840992]\n",
      "epoch:45 step:35728 [D loss: 0.640075, acc.: 66.41%] [G loss: 0.772756]\n",
      "epoch:45 step:35729 [D loss: 0.725344, acc.: 39.84%] [G loss: 0.808814]\n",
      "epoch:45 step:35730 [D loss: 0.650742, acc.: 65.62%] [G loss: 0.719674]\n",
      "epoch:45 step:35731 [D loss: 0.597170, acc.: 76.56%] [G loss: 0.909544]\n",
      "epoch:45 step:35732 [D loss: 0.618227, acc.: 72.66%] [G loss: 0.701564]\n",
      "epoch:45 step:35733 [D loss: 0.655716, acc.: 62.50%] [G loss: 0.742828]\n",
      "epoch:45 step:35734 [D loss: 0.666047, acc.: 59.38%] [G loss: 0.873561]\n",
      "epoch:45 step:35735 [D loss: 0.663163, acc.: 57.81%] [G loss: 0.877600]\n",
      "epoch:45 step:35736 [D loss: 0.706198, acc.: 54.69%] [G loss: 0.830417]\n",
      "epoch:45 step:35737 [D loss: 0.659928, acc.: 59.38%] [G loss: 0.830540]\n",
      "epoch:45 step:35738 [D loss: 0.651703, acc.: 59.38%] [G loss: 0.871838]\n",
      "epoch:45 step:35739 [D loss: 0.723643, acc.: 48.44%] [G loss: 0.774222]\n",
      "epoch:45 step:35740 [D loss: 0.569694, acc.: 78.91%] [G loss: 0.893511]\n",
      "epoch:45 step:35741 [D loss: 0.671278, acc.: 60.16%] [G loss: 0.758225]\n",
      "epoch:45 step:35742 [D loss: 0.681546, acc.: 62.50%] [G loss: 0.761093]\n",
      "epoch:45 step:35743 [D loss: 0.737023, acc.: 50.78%] [G loss: 0.841841]\n",
      "epoch:45 step:35744 [D loss: 0.672880, acc.: 60.94%] [G loss: 0.894737]\n",
      "epoch:45 step:35745 [D loss: 0.623092, acc.: 65.62%] [G loss: 0.809603]\n",
      "epoch:45 step:35746 [D loss: 0.681478, acc.: 57.03%] [G loss: 0.815566]\n",
      "epoch:45 step:35747 [D loss: 0.676120, acc.: 58.59%] [G loss: 0.802960]\n",
      "epoch:45 step:35748 [D loss: 0.730869, acc.: 42.97%] [G loss: 0.743572]\n",
      "epoch:45 step:35749 [D loss: 0.698087, acc.: 50.00%] [G loss: 0.802500]\n",
      "epoch:45 step:35750 [D loss: 0.692673, acc.: 57.03%] [G loss: 0.760606]\n",
      "epoch:45 step:35751 [D loss: 0.648108, acc.: 64.06%] [G loss: 0.928131]\n",
      "epoch:45 step:35752 [D loss: 0.703051, acc.: 52.34%] [G loss: 0.696635]\n",
      "epoch:45 step:35753 [D loss: 0.688631, acc.: 57.03%] [G loss: 0.864232]\n",
      "epoch:45 step:35754 [D loss: 0.667855, acc.: 53.91%] [G loss: 0.876177]\n",
      "epoch:45 step:35755 [D loss: 0.668474, acc.: 58.59%] [G loss: 0.783400]\n",
      "epoch:45 step:35756 [D loss: 0.636274, acc.: 66.41%] [G loss: 0.728566]\n",
      "epoch:45 step:35757 [D loss: 0.721763, acc.: 49.22%] [G loss: 0.849194]\n",
      "epoch:45 step:35758 [D loss: 0.716973, acc.: 53.12%] [G loss: 0.746017]\n",
      "epoch:45 step:35759 [D loss: 0.712393, acc.: 49.22%] [G loss: 0.786827]\n",
      "epoch:45 step:35760 [D loss: 0.648586, acc.: 70.31%] [G loss: 0.806434]\n",
      "epoch:45 step:35761 [D loss: 0.681332, acc.: 60.94%] [G loss: 0.732249]\n",
      "epoch:45 step:35762 [D loss: 0.678688, acc.: 53.91%] [G loss: 0.814134]\n",
      "epoch:45 step:35763 [D loss: 0.646801, acc.: 62.50%] [G loss: 0.694160]\n",
      "epoch:45 step:35764 [D loss: 0.614214, acc.: 67.19%] [G loss: 0.747233]\n",
      "epoch:45 step:35765 [D loss: 0.678168, acc.: 53.91%] [G loss: 0.851557]\n",
      "epoch:45 step:35766 [D loss: 0.635740, acc.: 66.41%] [G loss: 0.727053]\n",
      "epoch:45 step:35767 [D loss: 0.682015, acc.: 54.69%] [G loss: 0.798113]\n",
      "epoch:45 step:35768 [D loss: 0.668931, acc.: 59.38%] [G loss: 0.921755]\n",
      "epoch:45 step:35769 [D loss: 0.604030, acc.: 75.00%] [G loss: 0.904241]\n",
      "epoch:45 step:35770 [D loss: 0.654197, acc.: 64.84%] [G loss: 0.895800]\n",
      "epoch:45 step:35771 [D loss: 0.685770, acc.: 53.91%] [G loss: 0.870536]\n",
      "epoch:45 step:35772 [D loss: 0.656206, acc.: 66.41%] [G loss: 0.831508]\n",
      "epoch:45 step:35773 [D loss: 0.618917, acc.: 73.44%] [G loss: 0.824674]\n",
      "epoch:45 step:35774 [D loss: 0.725094, acc.: 55.47%] [G loss: 0.815233]\n",
      "epoch:45 step:35775 [D loss: 0.642657, acc.: 63.28%] [G loss: 0.847331]\n",
      "epoch:45 step:35776 [D loss: 0.717044, acc.: 50.78%] [G loss: 0.905765]\n",
      "epoch:45 step:35777 [D loss: 0.662878, acc.: 59.38%] [G loss: 0.735892]\n",
      "epoch:45 step:35778 [D loss: 0.663522, acc.: 61.72%] [G loss: 0.793101]\n",
      "epoch:45 step:35779 [D loss: 0.693832, acc.: 50.78%] [G loss: 0.749165]\n",
      "epoch:45 step:35780 [D loss: 0.647452, acc.: 61.72%] [G loss: 0.771994]\n",
      "epoch:45 step:35781 [D loss: 0.683440, acc.: 51.56%] [G loss: 0.730669]\n",
      "epoch:45 step:35782 [D loss: 0.638393, acc.: 64.06%] [G loss: 0.694644]\n",
      "epoch:45 step:35783 [D loss: 0.711013, acc.: 53.12%] [G loss: 0.749453]\n",
      "epoch:45 step:35784 [D loss: 0.689429, acc.: 59.38%] [G loss: 0.677689]\n",
      "epoch:45 step:35785 [D loss: 0.663038, acc.: 57.81%] [G loss: 0.823881]\n",
      "epoch:45 step:35786 [D loss: 0.745017, acc.: 44.53%] [G loss: 0.740742]\n",
      "epoch:45 step:35787 [D loss: 0.736338, acc.: 47.66%] [G loss: 0.805204]\n",
      "epoch:45 step:35788 [D loss: 0.620017, acc.: 67.97%] [G loss: 0.889261]\n",
      "epoch:45 step:35789 [D loss: 0.714289, acc.: 49.22%] [G loss: 0.810071]\n",
      "epoch:45 step:35790 [D loss: 0.664483, acc.: 63.28%] [G loss: 0.898702]\n",
      "epoch:45 step:35791 [D loss: 0.712175, acc.: 52.34%] [G loss: 0.747152]\n",
      "epoch:45 step:35792 [D loss: 0.680686, acc.: 58.59%] [G loss: 0.845714]\n",
      "epoch:45 step:35793 [D loss: 0.648387, acc.: 64.06%] [G loss: 0.761627]\n",
      "epoch:45 step:35794 [D loss: 0.664682, acc.: 62.50%] [G loss: 0.874400]\n",
      "epoch:45 step:35795 [D loss: 0.643782, acc.: 67.97%] [G loss: 0.820261]\n",
      "epoch:45 step:35796 [D loss: 0.725972, acc.: 50.00%] [G loss: 0.713798]\n",
      "epoch:45 step:35797 [D loss: 0.613666, acc.: 69.53%] [G loss: 0.723265]\n",
      "epoch:45 step:35798 [D loss: 0.690402, acc.: 55.47%] [G loss: 0.794407]\n",
      "epoch:45 step:35799 [D loss: 0.697539, acc.: 56.25%] [G loss: 0.815657]\n",
      "epoch:45 step:35800 [D loss: 0.700860, acc.: 55.47%] [G loss: 0.828884]\n",
      "epoch:45 step:35801 [D loss: 0.660600, acc.: 60.16%] [G loss: 0.827251]\n",
      "epoch:45 step:35802 [D loss: 0.627347, acc.: 68.75%] [G loss: 0.891831]\n",
      "epoch:45 step:35803 [D loss: 0.721284, acc.: 47.66%] [G loss: 0.889082]\n",
      "epoch:45 step:35804 [D loss: 0.674464, acc.: 54.69%] [G loss: 0.891922]\n",
      "epoch:45 step:35805 [D loss: 0.705696, acc.: 49.22%] [G loss: 0.761758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35806 [D loss: 0.654077, acc.: 65.62%] [G loss: 0.728115]\n",
      "epoch:45 step:35807 [D loss: 0.688637, acc.: 54.69%] [G loss: 0.790509]\n",
      "epoch:45 step:35808 [D loss: 0.630373, acc.: 68.75%] [G loss: 0.787600]\n",
      "epoch:45 step:35809 [D loss: 0.747673, acc.: 42.97%] [G loss: 0.732493]\n",
      "epoch:45 step:35810 [D loss: 0.653865, acc.: 65.62%] [G loss: 0.850670]\n",
      "epoch:45 step:35811 [D loss: 0.657378, acc.: 65.62%] [G loss: 0.853747]\n",
      "epoch:45 step:35812 [D loss: 0.663453, acc.: 58.59%] [G loss: 0.921934]\n",
      "epoch:45 step:35813 [D loss: 0.636473, acc.: 61.72%] [G loss: 0.835429]\n",
      "epoch:45 step:35814 [D loss: 0.705983, acc.: 50.78%] [G loss: 0.916206]\n",
      "epoch:45 step:35815 [D loss: 0.678664, acc.: 56.25%] [G loss: 0.754398]\n",
      "epoch:45 step:35816 [D loss: 0.690184, acc.: 57.81%] [G loss: 0.815147]\n",
      "epoch:45 step:35817 [D loss: 0.645598, acc.: 61.72%] [G loss: 0.826890]\n",
      "epoch:45 step:35818 [D loss: 0.675275, acc.: 56.25%] [G loss: 0.917526]\n",
      "epoch:45 step:35819 [D loss: 0.755213, acc.: 46.88%] [G loss: 0.844882]\n",
      "epoch:45 step:35820 [D loss: 0.679742, acc.: 56.25%] [G loss: 0.885811]\n",
      "epoch:45 step:35821 [D loss: 0.702857, acc.: 50.78%] [G loss: 0.818770]\n",
      "epoch:45 step:35822 [D loss: 0.645684, acc.: 64.06%] [G loss: 0.831465]\n",
      "epoch:45 step:35823 [D loss: 0.633505, acc.: 66.41%] [G loss: 0.748333]\n",
      "epoch:45 step:35824 [D loss: 0.692601, acc.: 53.12%] [G loss: 0.684790]\n",
      "epoch:45 step:35825 [D loss: 0.633421, acc.: 70.31%] [G loss: 0.845727]\n",
      "epoch:45 step:35826 [D loss: 0.686843, acc.: 56.25%] [G loss: 0.855385]\n",
      "epoch:45 step:35827 [D loss: 0.743034, acc.: 46.09%] [G loss: 0.761732]\n",
      "epoch:45 step:35828 [D loss: 0.677004, acc.: 59.38%] [G loss: 0.805462]\n",
      "epoch:45 step:35829 [D loss: 0.690414, acc.: 54.69%] [G loss: 0.808687]\n",
      "epoch:45 step:35830 [D loss: 0.731006, acc.: 50.78%] [G loss: 0.775217]\n",
      "epoch:45 step:35831 [D loss: 0.687944, acc.: 53.91%] [G loss: 0.823400]\n",
      "epoch:45 step:35832 [D loss: 0.635912, acc.: 64.84%] [G loss: 0.795698]\n",
      "epoch:45 step:35833 [D loss: 0.681230, acc.: 57.81%] [G loss: 0.781706]\n",
      "epoch:45 step:35834 [D loss: 0.710064, acc.: 49.22%] [G loss: 0.837725]\n",
      "epoch:45 step:35835 [D loss: 0.689731, acc.: 46.88%] [G loss: 0.759574]\n",
      "epoch:45 step:35836 [D loss: 0.642877, acc.: 62.50%] [G loss: 0.802281]\n",
      "epoch:45 step:35837 [D loss: 0.809432, acc.: 33.59%] [G loss: 0.702340]\n",
      "epoch:45 step:35838 [D loss: 0.697651, acc.: 53.12%] [G loss: 0.828885]\n",
      "epoch:45 step:35839 [D loss: 0.674061, acc.: 59.38%] [G loss: 0.797433]\n",
      "epoch:45 step:35840 [D loss: 0.699768, acc.: 50.00%] [G loss: 0.798811]\n",
      "epoch:45 step:35841 [D loss: 0.756281, acc.: 40.62%] [G loss: 0.671627]\n",
      "epoch:45 step:35842 [D loss: 0.650176, acc.: 57.81%] [G loss: 0.787411]\n",
      "epoch:45 step:35843 [D loss: 0.679397, acc.: 57.03%] [G loss: 0.785861]\n",
      "epoch:45 step:35844 [D loss: 0.709962, acc.: 46.09%] [G loss: 0.815446]\n",
      "epoch:45 step:35845 [D loss: 0.663748, acc.: 60.16%] [G loss: 0.774986]\n",
      "epoch:45 step:35846 [D loss: 0.692641, acc.: 53.91%] [G loss: 0.840479]\n",
      "epoch:45 step:35847 [D loss: 0.687488, acc.: 53.91%] [G loss: 0.793360]\n",
      "epoch:45 step:35848 [D loss: 0.720239, acc.: 53.12%] [G loss: 0.763016]\n",
      "epoch:45 step:35849 [D loss: 0.673024, acc.: 61.72%] [G loss: 0.791288]\n",
      "epoch:45 step:35850 [D loss: 0.646976, acc.: 64.84%] [G loss: 0.826280]\n",
      "epoch:45 step:35851 [D loss: 0.688477, acc.: 52.34%] [G loss: 0.747182]\n",
      "epoch:45 step:35852 [D loss: 0.734571, acc.: 38.28%] [G loss: 0.673900]\n",
      "epoch:45 step:35853 [D loss: 0.666296, acc.: 61.72%] [G loss: 0.809156]\n",
      "epoch:45 step:35854 [D loss: 0.733251, acc.: 48.44%] [G loss: 0.784777]\n",
      "epoch:45 step:35855 [D loss: 0.673474, acc.: 57.81%] [G loss: 0.773749]\n",
      "epoch:45 step:35856 [D loss: 0.659908, acc.: 56.25%] [G loss: 0.842038]\n",
      "epoch:45 step:35857 [D loss: 0.689190, acc.: 54.69%] [G loss: 0.773935]\n",
      "epoch:45 step:35858 [D loss: 0.656792, acc.: 61.72%] [G loss: 0.806993]\n",
      "epoch:45 step:35859 [D loss: 0.669002, acc.: 57.03%] [G loss: 0.807057]\n",
      "epoch:45 step:35860 [D loss: 0.688979, acc.: 57.81%] [G loss: 0.764702]\n",
      "epoch:45 step:35861 [D loss: 0.708712, acc.: 51.56%] [G loss: 0.826263]\n",
      "epoch:45 step:35862 [D loss: 0.730565, acc.: 50.78%] [G loss: 0.769083]\n",
      "epoch:45 step:35863 [D loss: 0.715073, acc.: 52.34%] [G loss: 0.729357]\n",
      "epoch:45 step:35864 [D loss: 0.654947, acc.: 63.28%] [G loss: 0.850861]\n",
      "epoch:45 step:35865 [D loss: 0.709498, acc.: 47.66%] [G loss: 0.909638]\n",
      "epoch:45 step:35866 [D loss: 0.703246, acc.: 51.56%] [G loss: 0.915829]\n",
      "epoch:45 step:35867 [D loss: 0.648387, acc.: 64.84%] [G loss: 0.851547]\n",
      "epoch:45 step:35868 [D loss: 0.668247, acc.: 61.72%] [G loss: 0.808941]\n",
      "epoch:45 step:35869 [D loss: 0.724212, acc.: 45.31%] [G loss: 0.852203]\n",
      "epoch:45 step:35870 [D loss: 0.646880, acc.: 60.94%] [G loss: 0.760679]\n",
      "epoch:45 step:35871 [D loss: 0.673872, acc.: 57.03%] [G loss: 0.796940]\n",
      "epoch:45 step:35872 [D loss: 0.695220, acc.: 51.56%] [G loss: 0.838385]\n",
      "epoch:45 step:35873 [D loss: 0.621324, acc.: 71.09%] [G loss: 0.798119]\n",
      "epoch:45 step:35874 [D loss: 0.721719, acc.: 49.22%] [G loss: 0.791528]\n",
      "epoch:45 step:35875 [D loss: 0.652324, acc.: 62.50%] [G loss: 0.907562]\n",
      "epoch:45 step:35876 [D loss: 0.623585, acc.: 70.31%] [G loss: 0.830573]\n",
      "epoch:45 step:35877 [D loss: 0.694748, acc.: 54.69%] [G loss: 0.851740]\n",
      "epoch:45 step:35878 [D loss: 0.736162, acc.: 44.53%] [G loss: 0.753154]\n",
      "epoch:45 step:35879 [D loss: 0.721599, acc.: 51.56%] [G loss: 0.815596]\n",
      "epoch:45 step:35880 [D loss: 0.710698, acc.: 46.88%] [G loss: 0.760921]\n",
      "epoch:45 step:35881 [D loss: 0.630975, acc.: 68.75%] [G loss: 0.747733]\n",
      "epoch:45 step:35882 [D loss: 0.685210, acc.: 57.81%] [G loss: 0.846432]\n",
      "epoch:45 step:35883 [D loss: 0.747874, acc.: 46.88%] [G loss: 0.835048]\n",
      "epoch:45 step:35884 [D loss: 0.709049, acc.: 53.91%] [G loss: 0.810322]\n",
      "epoch:45 step:35885 [D loss: 0.646353, acc.: 61.72%] [G loss: 0.815681]\n",
      "epoch:45 step:35886 [D loss: 0.643672, acc.: 61.72%] [G loss: 0.922612]\n",
      "epoch:45 step:35887 [D loss: 0.659116, acc.: 59.38%] [G loss: 0.778758]\n",
      "epoch:45 step:35888 [D loss: 0.730112, acc.: 46.88%] [G loss: 0.798524]\n",
      "epoch:45 step:35889 [D loss: 0.666559, acc.: 60.94%] [G loss: 0.797092]\n",
      "epoch:45 step:35890 [D loss: 0.723936, acc.: 45.31%] [G loss: 0.804781]\n",
      "epoch:45 step:35891 [D loss: 0.713254, acc.: 53.12%] [G loss: 0.869688]\n",
      "epoch:45 step:35892 [D loss: 0.664445, acc.: 63.28%] [G loss: 0.719077]\n",
      "epoch:45 step:35893 [D loss: 0.676417, acc.: 57.81%] [G loss: 0.781351]\n",
      "epoch:45 step:35894 [D loss: 0.722688, acc.: 44.53%] [G loss: 0.770073]\n",
      "epoch:45 step:35895 [D loss: 0.682453, acc.: 56.25%] [G loss: 0.817923]\n",
      "epoch:45 step:35896 [D loss: 0.672205, acc.: 57.81%] [G loss: 0.752495]\n",
      "epoch:45 step:35897 [D loss: 0.646882, acc.: 60.16%] [G loss: 0.824138]\n",
      "epoch:45 step:35898 [D loss: 0.662977, acc.: 59.38%] [G loss: 0.760840]\n",
      "epoch:45 step:35899 [D loss: 0.698198, acc.: 53.12%] [G loss: 0.826573]\n",
      "epoch:45 step:35900 [D loss: 0.734290, acc.: 49.22%] [G loss: 0.919576]\n",
      "epoch:45 step:35901 [D loss: 0.630804, acc.: 64.84%] [G loss: 0.892459]\n",
      "epoch:45 step:35902 [D loss: 0.702203, acc.: 50.00%] [G loss: 0.880292]\n",
      "epoch:45 step:35903 [D loss: 0.691269, acc.: 55.47%] [G loss: 0.929638]\n",
      "epoch:45 step:35904 [D loss: 0.687534, acc.: 53.12%] [G loss: 0.764934]\n",
      "epoch:45 step:35905 [D loss: 0.762504, acc.: 35.16%] [G loss: 0.842367]\n",
      "epoch:45 step:35906 [D loss: 0.658461, acc.: 58.59%] [G loss: 0.806440]\n",
      "epoch:45 step:35907 [D loss: 0.725299, acc.: 49.22%] [G loss: 0.802644]\n",
      "epoch:45 step:35908 [D loss: 0.734797, acc.: 45.31%] [G loss: 0.746006]\n",
      "epoch:45 step:35909 [D loss: 0.749219, acc.: 42.97%] [G loss: 0.791954]\n",
      "epoch:45 step:35910 [D loss: 0.699243, acc.: 52.34%] [G loss: 0.760653]\n",
      "epoch:45 step:35911 [D loss: 0.655962, acc.: 63.28%] [G loss: 0.861744]\n",
      "epoch:45 step:35912 [D loss: 0.628569, acc.: 71.09%] [G loss: 0.832847]\n",
      "epoch:45 step:35913 [D loss: 0.665264, acc.: 57.81%] [G loss: 0.955396]\n",
      "epoch:45 step:35914 [D loss: 0.604627, acc.: 73.44%] [G loss: 0.794456]\n",
      "epoch:45 step:35915 [D loss: 0.688955, acc.: 53.12%] [G loss: 0.832273]\n",
      "epoch:45 step:35916 [D loss: 0.726792, acc.: 46.09%] [G loss: 0.841205]\n",
      "epoch:45 step:35917 [D loss: 0.661570, acc.: 61.72%] [G loss: 1.014668]\n",
      "epoch:45 step:35918 [D loss: 0.630453, acc.: 66.41%] [G loss: 0.846028]\n",
      "epoch:45 step:35919 [D loss: 0.673749, acc.: 60.16%] [G loss: 0.782243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35920 [D loss: 0.659856, acc.: 60.94%] [G loss: 0.810248]\n",
      "epoch:45 step:35921 [D loss: 0.677941, acc.: 62.50%] [G loss: 0.798687]\n",
      "epoch:45 step:35922 [D loss: 0.666869, acc.: 60.94%] [G loss: 0.768261]\n",
      "epoch:45 step:35923 [D loss: 0.677716, acc.: 53.91%] [G loss: 0.969118]\n",
      "epoch:45 step:35924 [D loss: 0.684327, acc.: 55.47%] [G loss: 0.749798]\n",
      "epoch:45 step:35925 [D loss: 0.714753, acc.: 50.78%] [G loss: 0.803886]\n",
      "epoch:45 step:35926 [D loss: 0.643397, acc.: 68.75%] [G loss: 0.744026]\n",
      "epoch:46 step:35927 [D loss: 0.635928, acc.: 62.50%] [G loss: 0.796761]\n",
      "epoch:46 step:35928 [D loss: 0.639491, acc.: 67.97%] [G loss: 0.834324]\n",
      "epoch:46 step:35929 [D loss: 0.715268, acc.: 45.31%] [G loss: 0.747151]\n",
      "epoch:46 step:35930 [D loss: 0.692481, acc.: 54.69%] [G loss: 0.829827]\n",
      "epoch:46 step:35931 [D loss: 0.690052, acc.: 57.03%] [G loss: 0.797285]\n",
      "epoch:46 step:35932 [D loss: 0.639956, acc.: 68.75%] [G loss: 0.804119]\n",
      "epoch:46 step:35933 [D loss: 0.722116, acc.: 44.53%] [G loss: 0.823234]\n",
      "epoch:46 step:35934 [D loss: 0.681934, acc.: 57.03%] [G loss: 0.941094]\n",
      "epoch:46 step:35935 [D loss: 0.726388, acc.: 46.09%] [G loss: 0.866645]\n",
      "epoch:46 step:35936 [D loss: 0.703611, acc.: 51.56%] [G loss: 0.789200]\n",
      "epoch:46 step:35937 [D loss: 0.736085, acc.: 45.31%] [G loss: 0.831261]\n",
      "epoch:46 step:35938 [D loss: 0.685848, acc.: 57.03%] [G loss: 0.809285]\n",
      "epoch:46 step:35939 [D loss: 0.634048, acc.: 67.19%] [G loss: 0.768609]\n",
      "epoch:46 step:35940 [D loss: 0.722437, acc.: 49.22%] [G loss: 0.806727]\n",
      "epoch:46 step:35941 [D loss: 0.717497, acc.: 50.00%] [G loss: 0.768407]\n",
      "epoch:46 step:35942 [D loss: 0.696398, acc.: 50.78%] [G loss: 0.814788]\n",
      "epoch:46 step:35943 [D loss: 0.679281, acc.: 56.25%] [G loss: 0.821826]\n",
      "epoch:46 step:35944 [D loss: 0.709553, acc.: 43.75%] [G loss: 0.782179]\n",
      "epoch:46 step:35945 [D loss: 0.703306, acc.: 50.78%] [G loss: 0.824893]\n",
      "epoch:46 step:35946 [D loss: 0.708265, acc.: 53.12%] [G loss: 0.767443]\n",
      "epoch:46 step:35947 [D loss: 0.705933, acc.: 50.78%] [G loss: 0.825836]\n",
      "epoch:46 step:35948 [D loss: 0.643803, acc.: 67.19%] [G loss: 0.799095]\n",
      "epoch:46 step:35949 [D loss: 0.725886, acc.: 44.53%] [G loss: 0.867315]\n",
      "epoch:46 step:35950 [D loss: 0.663016, acc.: 59.38%] [G loss: 0.768174]\n",
      "epoch:46 step:35951 [D loss: 0.724306, acc.: 50.00%] [G loss: 0.808717]\n",
      "epoch:46 step:35952 [D loss: 0.710909, acc.: 50.78%] [G loss: 0.712720]\n",
      "epoch:46 step:35953 [D loss: 0.617876, acc.: 73.44%] [G loss: 0.806009]\n",
      "epoch:46 step:35954 [D loss: 0.716711, acc.: 50.78%] [G loss: 0.792859]\n",
      "epoch:46 step:35955 [D loss: 0.704210, acc.: 57.03%] [G loss: 0.797544]\n",
      "epoch:46 step:35956 [D loss: 0.665863, acc.: 60.94%] [G loss: 0.871778]\n",
      "epoch:46 step:35957 [D loss: 0.739225, acc.: 39.84%] [G loss: 0.760980]\n",
      "epoch:46 step:35958 [D loss: 0.656522, acc.: 55.47%] [G loss: 0.734734]\n",
      "epoch:46 step:35959 [D loss: 0.681051, acc.: 52.34%] [G loss: 0.764478]\n",
      "epoch:46 step:35960 [D loss: 0.623671, acc.: 68.75%] [G loss: 0.893197]\n",
      "epoch:46 step:35961 [D loss: 0.706793, acc.: 50.00%] [G loss: 0.689700]\n",
      "epoch:46 step:35962 [D loss: 0.750967, acc.: 37.50%] [G loss: 0.779384]\n",
      "epoch:46 step:35963 [D loss: 0.669464, acc.: 58.59%] [G loss: 0.854859]\n",
      "epoch:46 step:35964 [D loss: 0.709486, acc.: 46.88%] [G loss: 0.751951]\n",
      "epoch:46 step:35965 [D loss: 0.680892, acc.: 57.03%] [G loss: 0.829213]\n",
      "epoch:46 step:35966 [D loss: 0.727337, acc.: 46.09%] [G loss: 0.817499]\n",
      "epoch:46 step:35967 [D loss: 0.677876, acc.: 62.50%] [G loss: 0.852757]\n",
      "epoch:46 step:35968 [D loss: 0.669709, acc.: 51.56%] [G loss: 0.773556]\n",
      "epoch:46 step:35969 [D loss: 0.667951, acc.: 56.25%] [G loss: 0.829555]\n",
      "epoch:46 step:35970 [D loss: 0.668868, acc.: 58.59%] [G loss: 0.822974]\n",
      "epoch:46 step:35971 [D loss: 0.680476, acc.: 54.69%] [G loss: 0.804557]\n",
      "epoch:46 step:35972 [D loss: 0.695195, acc.: 50.00%] [G loss: 0.765870]\n",
      "epoch:46 step:35973 [D loss: 0.680787, acc.: 57.81%] [G loss: 0.777615]\n",
      "epoch:46 step:35974 [D loss: 0.666512, acc.: 61.72%] [G loss: 0.866174]\n",
      "epoch:46 step:35975 [D loss: 0.632172, acc.: 67.19%] [G loss: 0.832607]\n",
      "epoch:46 step:35976 [D loss: 0.752809, acc.: 45.31%] [G loss: 0.745011]\n",
      "epoch:46 step:35977 [D loss: 0.623088, acc.: 69.53%] [G loss: 0.904527]\n",
      "epoch:46 step:35978 [D loss: 0.624487, acc.: 73.44%] [G loss: 0.829293]\n",
      "epoch:46 step:35979 [D loss: 0.710031, acc.: 50.00%] [G loss: 0.821017]\n",
      "epoch:46 step:35980 [D loss: 0.711185, acc.: 49.22%] [G loss: 0.685114]\n",
      "epoch:46 step:35981 [D loss: 0.637850, acc.: 60.94%] [G loss: 0.757009]\n",
      "epoch:46 step:35982 [D loss: 0.703531, acc.: 53.91%] [G loss: 0.766027]\n",
      "epoch:46 step:35983 [D loss: 0.682185, acc.: 53.12%] [G loss: 0.696632]\n",
      "epoch:46 step:35984 [D loss: 0.664529, acc.: 58.59%] [G loss: 0.846754]\n",
      "epoch:46 step:35985 [D loss: 0.679066, acc.: 57.81%] [G loss: 0.849230]\n",
      "epoch:46 step:35986 [D loss: 0.678950, acc.: 58.59%] [G loss: 0.801934]\n",
      "epoch:46 step:35987 [D loss: 0.697267, acc.: 46.88%] [G loss: 0.860283]\n",
      "epoch:46 step:35988 [D loss: 0.644722, acc.: 60.94%] [G loss: 0.846713]\n",
      "epoch:46 step:35989 [D loss: 0.666439, acc.: 59.38%] [G loss: 0.802137]\n",
      "epoch:46 step:35990 [D loss: 0.681781, acc.: 55.47%] [G loss: 0.798905]\n",
      "epoch:46 step:35991 [D loss: 0.708157, acc.: 56.25%] [G loss: 0.848125]\n",
      "epoch:46 step:35992 [D loss: 0.803708, acc.: 28.91%] [G loss: 0.754989]\n",
      "epoch:46 step:35993 [D loss: 0.693425, acc.: 52.34%] [G loss: 0.785837]\n",
      "epoch:46 step:35994 [D loss: 0.668720, acc.: 60.94%] [G loss: 0.832240]\n",
      "epoch:46 step:35995 [D loss: 0.685076, acc.: 55.47%] [G loss: 0.808097]\n",
      "epoch:46 step:35996 [D loss: 0.723122, acc.: 46.88%] [G loss: 0.807114]\n",
      "epoch:46 step:35997 [D loss: 0.684756, acc.: 51.56%] [G loss: 0.867162]\n",
      "epoch:46 step:35998 [D loss: 0.749857, acc.: 43.75%] [G loss: 0.853886]\n",
      "epoch:46 step:35999 [D loss: 0.651080, acc.: 63.28%] [G loss: 0.843884]\n",
      "epoch:46 step:36000 [D loss: 0.667977, acc.: 60.94%] [G loss: 0.929564]\n",
      "epoch:46 step:36001 [D loss: 0.639534, acc.: 64.84%] [G loss: 0.746962]\n",
      "epoch:46 step:36002 [D loss: 0.690843, acc.: 50.78%] [G loss: 0.695241]\n",
      "epoch:46 step:36003 [D loss: 0.608447, acc.: 75.00%] [G loss: 0.824174]\n",
      "epoch:46 step:36004 [D loss: 0.719895, acc.: 53.12%] [G loss: 0.715367]\n",
      "epoch:46 step:36005 [D loss: 0.645283, acc.: 65.62%] [G loss: 0.753370]\n",
      "epoch:46 step:36006 [D loss: 0.655390, acc.: 60.16%] [G loss: 0.808682]\n",
      "epoch:46 step:36007 [D loss: 0.672278, acc.: 59.38%] [G loss: 0.782002]\n",
      "epoch:46 step:36008 [D loss: 0.675636, acc.: 56.25%] [G loss: 0.782560]\n",
      "epoch:46 step:36009 [D loss: 0.635968, acc.: 67.97%] [G loss: 0.781387]\n",
      "epoch:46 step:36010 [D loss: 0.648164, acc.: 65.62%] [G loss: 0.809949]\n",
      "epoch:46 step:36011 [D loss: 0.702403, acc.: 47.66%] [G loss: 0.863576]\n",
      "epoch:46 step:36012 [D loss: 0.695669, acc.: 56.25%] [G loss: 0.806827]\n",
      "epoch:46 step:36013 [D loss: 0.671789, acc.: 55.47%] [G loss: 0.724587]\n",
      "epoch:46 step:36014 [D loss: 0.688275, acc.: 54.69%] [G loss: 0.742201]\n",
      "epoch:46 step:36015 [D loss: 0.671820, acc.: 59.38%] [G loss: 0.841329]\n",
      "epoch:46 step:36016 [D loss: 0.692454, acc.: 53.91%] [G loss: 0.803053]\n",
      "epoch:46 step:36017 [D loss: 0.719202, acc.: 49.22%] [G loss: 0.865665]\n",
      "epoch:46 step:36018 [D loss: 0.647923, acc.: 68.75%] [G loss: 0.828635]\n",
      "epoch:46 step:36019 [D loss: 0.641418, acc.: 59.38%] [G loss: 0.821063]\n",
      "epoch:46 step:36020 [D loss: 0.631023, acc.: 67.97%] [G loss: 0.765747]\n",
      "epoch:46 step:36021 [D loss: 0.707027, acc.: 47.66%] [G loss: 0.785282]\n",
      "epoch:46 step:36022 [D loss: 0.679358, acc.: 57.81%] [G loss: 0.852954]\n",
      "epoch:46 step:36023 [D loss: 0.732266, acc.: 45.31%] [G loss: 0.823861]\n",
      "epoch:46 step:36024 [D loss: 0.647884, acc.: 64.06%] [G loss: 0.845680]\n",
      "epoch:46 step:36025 [D loss: 0.643535, acc.: 64.84%] [G loss: 0.951860]\n",
      "epoch:46 step:36026 [D loss: 0.658199, acc.: 57.03%] [G loss: 0.866908]\n",
      "epoch:46 step:36027 [D loss: 0.692157, acc.: 57.03%] [G loss: 0.846709]\n",
      "epoch:46 step:36028 [D loss: 0.704797, acc.: 53.12%] [G loss: 0.741181]\n",
      "epoch:46 step:36029 [D loss: 0.686545, acc.: 60.94%] [G loss: 0.986779]\n",
      "epoch:46 step:36030 [D loss: 0.634482, acc.: 68.75%] [G loss: 0.765863]\n",
      "epoch:46 step:36031 [D loss: 0.769954, acc.: 32.81%] [G loss: 0.702782]\n",
      "epoch:46 step:36032 [D loss: 0.703189, acc.: 51.56%] [G loss: 0.782406]\n",
      "epoch:46 step:36033 [D loss: 0.674546, acc.: 57.81%] [G loss: 0.801286]\n",
      "epoch:46 step:36034 [D loss: 0.773592, acc.: 42.97%] [G loss: 0.750863]\n",
      "epoch:46 step:36035 [D loss: 0.687020, acc.: 55.47%] [G loss: 0.771690]\n",
      "epoch:46 step:36036 [D loss: 0.602170, acc.: 75.78%] [G loss: 0.841595]\n",
      "epoch:46 step:36037 [D loss: 0.714064, acc.: 50.78%] [G loss: 0.788235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36038 [D loss: 0.700692, acc.: 49.22%] [G loss: 0.759052]\n",
      "epoch:46 step:36039 [D loss: 0.706044, acc.: 50.78%] [G loss: 0.712117]\n",
      "epoch:46 step:36040 [D loss: 0.626840, acc.: 67.97%] [G loss: 0.771622]\n",
      "epoch:46 step:36041 [D loss: 0.767473, acc.: 37.50%] [G loss: 0.785207]\n",
      "epoch:46 step:36042 [D loss: 0.728067, acc.: 48.44%] [G loss: 0.874267]\n",
      "epoch:46 step:36043 [D loss: 0.698849, acc.: 49.22%] [G loss: 0.822485]\n",
      "epoch:46 step:36044 [D loss: 0.694344, acc.: 53.12%] [G loss: 0.756494]\n",
      "epoch:46 step:36045 [D loss: 0.617196, acc.: 75.00%] [G loss: 0.807575]\n",
      "epoch:46 step:36046 [D loss: 0.715046, acc.: 49.22%] [G loss: 0.800761]\n",
      "epoch:46 step:36047 [D loss: 0.617364, acc.: 70.31%] [G loss: 0.857303]\n",
      "epoch:46 step:36048 [D loss: 0.622563, acc.: 65.62%] [G loss: 0.834694]\n",
      "epoch:46 step:36049 [D loss: 0.674844, acc.: 53.12%] [G loss: 0.798474]\n",
      "epoch:46 step:36050 [D loss: 0.662827, acc.: 64.06%] [G loss: 0.775471]\n",
      "epoch:46 step:36051 [D loss: 0.719862, acc.: 47.66%] [G loss: 0.782436]\n",
      "epoch:46 step:36052 [D loss: 0.739873, acc.: 50.00%] [G loss: 0.763174]\n",
      "epoch:46 step:36053 [D loss: 0.687670, acc.: 53.91%] [G loss: 0.667245]\n",
      "epoch:46 step:36054 [D loss: 0.676476, acc.: 58.59%] [G loss: 0.719107]\n",
      "epoch:46 step:36055 [D loss: 0.685393, acc.: 59.38%] [G loss: 0.847947]\n",
      "epoch:46 step:36056 [D loss: 0.686446, acc.: 57.81%] [G loss: 0.768682]\n",
      "epoch:46 step:36057 [D loss: 0.684404, acc.: 51.56%] [G loss: 0.770859]\n",
      "epoch:46 step:36058 [D loss: 0.635018, acc.: 63.28%] [G loss: 0.786331]\n",
      "epoch:46 step:36059 [D loss: 0.653263, acc.: 64.06%] [G loss: 0.818598]\n",
      "epoch:46 step:36060 [D loss: 0.690275, acc.: 57.03%] [G loss: 0.758067]\n",
      "epoch:46 step:36061 [D loss: 0.708322, acc.: 51.56%] [G loss: 0.762090]\n",
      "epoch:46 step:36062 [D loss: 0.739697, acc.: 46.88%] [G loss: 0.700751]\n",
      "epoch:46 step:36063 [D loss: 0.667619, acc.: 57.03%] [G loss: 0.867318]\n",
      "epoch:46 step:36064 [D loss: 0.736076, acc.: 45.31%] [G loss: 0.725469]\n",
      "epoch:46 step:36065 [D loss: 0.653449, acc.: 66.41%] [G loss: 0.847660]\n",
      "epoch:46 step:36066 [D loss: 0.718955, acc.: 50.00%] [G loss: 0.771474]\n",
      "epoch:46 step:36067 [D loss: 0.722510, acc.: 48.44%] [G loss: 0.845856]\n",
      "epoch:46 step:36068 [D loss: 0.686757, acc.: 53.91%] [G loss: 0.812486]\n",
      "epoch:46 step:36069 [D loss: 0.647850, acc.: 63.28%] [G loss: 0.870437]\n",
      "epoch:46 step:36070 [D loss: 0.715778, acc.: 50.00%] [G loss: 0.791696]\n",
      "epoch:46 step:36071 [D loss: 0.732728, acc.: 42.97%] [G loss: 0.790232]\n",
      "epoch:46 step:36072 [D loss: 0.640537, acc.: 59.38%] [G loss: 0.840629]\n",
      "epoch:46 step:36073 [D loss: 0.652124, acc.: 62.50%] [G loss: 0.789577]\n",
      "epoch:46 step:36074 [D loss: 0.683685, acc.: 60.94%] [G loss: 0.852705]\n",
      "epoch:46 step:36075 [D loss: 0.662800, acc.: 60.94%] [G loss: 0.763446]\n",
      "epoch:46 step:36076 [D loss: 0.675515, acc.: 57.81%] [G loss: 0.768586]\n",
      "epoch:46 step:36077 [D loss: 0.740645, acc.: 46.09%] [G loss: 0.752254]\n",
      "epoch:46 step:36078 [D loss: 0.684700, acc.: 56.25%] [G loss: 0.877892]\n",
      "epoch:46 step:36079 [D loss: 0.696210, acc.: 50.78%] [G loss: 0.811529]\n",
      "epoch:46 step:36080 [D loss: 0.671311, acc.: 60.94%] [G loss: 0.801543]\n",
      "epoch:46 step:36081 [D loss: 0.680875, acc.: 58.59%] [G loss: 0.820424]\n",
      "epoch:46 step:36082 [D loss: 0.654901, acc.: 62.50%] [G loss: 0.816896]\n",
      "epoch:46 step:36083 [D loss: 0.660393, acc.: 64.06%] [G loss: 0.794111]\n",
      "epoch:46 step:36084 [D loss: 0.635374, acc.: 61.72%] [G loss: 0.791561]\n",
      "epoch:46 step:36085 [D loss: 0.699356, acc.: 57.03%] [G loss: 0.821240]\n",
      "epoch:46 step:36086 [D loss: 0.619017, acc.: 71.88%] [G loss: 0.840326]\n",
      "epoch:46 step:36087 [D loss: 0.706450, acc.: 50.78%] [G loss: 0.853893]\n",
      "epoch:46 step:36088 [D loss: 0.679185, acc.: 51.56%] [G loss: 0.803826]\n",
      "epoch:46 step:36089 [D loss: 0.661120, acc.: 67.19%] [G loss: 0.912660]\n",
      "epoch:46 step:36090 [D loss: 0.667176, acc.: 56.25%] [G loss: 0.848658]\n",
      "epoch:46 step:36091 [D loss: 0.670259, acc.: 63.28%] [G loss: 0.877803]\n",
      "epoch:46 step:36092 [D loss: 0.720085, acc.: 48.44%] [G loss: 0.821177]\n",
      "epoch:46 step:36093 [D loss: 0.688031, acc.: 51.56%] [G loss: 0.835539]\n",
      "epoch:46 step:36094 [D loss: 0.620016, acc.: 64.84%] [G loss: 0.830315]\n",
      "epoch:46 step:36095 [D loss: 0.669804, acc.: 59.38%] [G loss: 0.842847]\n",
      "epoch:46 step:36096 [D loss: 0.686830, acc.: 57.81%] [G loss: 0.689397]\n",
      "epoch:46 step:36097 [D loss: 0.724722, acc.: 41.41%] [G loss: 0.810807]\n",
      "epoch:46 step:36098 [D loss: 0.650899, acc.: 66.41%] [G loss: 0.839529]\n",
      "epoch:46 step:36099 [D loss: 0.685367, acc.: 55.47%] [G loss: 0.815536]\n",
      "epoch:46 step:36100 [D loss: 0.694367, acc.: 50.00%] [G loss: 0.790226]\n",
      "epoch:46 step:36101 [D loss: 0.713029, acc.: 53.91%] [G loss: 0.857632]\n",
      "epoch:46 step:36102 [D loss: 0.682716, acc.: 57.81%] [G loss: 0.876750]\n",
      "epoch:46 step:36103 [D loss: 0.660007, acc.: 56.25%] [G loss: 0.829159]\n",
      "epoch:46 step:36104 [D loss: 0.667173, acc.: 62.50%] [G loss: 0.789704]\n",
      "epoch:46 step:36105 [D loss: 0.671039, acc.: 50.78%] [G loss: 0.728017]\n",
      "epoch:46 step:36106 [D loss: 0.717531, acc.: 46.88%] [G loss: 0.798060]\n",
      "epoch:46 step:36107 [D loss: 0.627504, acc.: 60.16%] [G loss: 0.738800]\n",
      "epoch:46 step:36108 [D loss: 0.741704, acc.: 42.97%] [G loss: 0.788512]\n",
      "epoch:46 step:36109 [D loss: 0.625787, acc.: 71.88%] [G loss: 0.764020]\n",
      "epoch:46 step:36110 [D loss: 0.653549, acc.: 58.59%] [G loss: 0.827911]\n",
      "epoch:46 step:36111 [D loss: 0.617177, acc.: 72.66%] [G loss: 0.853850]\n",
      "epoch:46 step:36112 [D loss: 0.636572, acc.: 62.50%] [G loss: 0.832732]\n",
      "epoch:46 step:36113 [D loss: 0.656868, acc.: 65.62%] [G loss: 0.813521]\n",
      "epoch:46 step:36114 [D loss: 0.688052, acc.: 54.69%] [G loss: 0.809550]\n",
      "epoch:46 step:36115 [D loss: 0.696287, acc.: 55.47%] [G loss: 0.753019]\n",
      "epoch:46 step:36116 [D loss: 0.685822, acc.: 51.56%] [G loss: 0.852020]\n",
      "epoch:46 step:36117 [D loss: 0.741084, acc.: 39.84%] [G loss: 0.859796]\n",
      "epoch:46 step:36118 [D loss: 0.647369, acc.: 63.28%] [G loss: 0.791353]\n",
      "epoch:46 step:36119 [D loss: 0.660810, acc.: 59.38%] [G loss: 0.898139]\n",
      "epoch:46 step:36120 [D loss: 0.650141, acc.: 64.06%] [G loss: 0.757124]\n",
      "epoch:46 step:36121 [D loss: 0.736021, acc.: 46.88%] [G loss: 0.781625]\n",
      "epoch:46 step:36122 [D loss: 0.655115, acc.: 60.16%] [G loss: 0.808030]\n",
      "epoch:46 step:36123 [D loss: 0.663096, acc.: 61.72%] [G loss: 0.949634]\n",
      "epoch:46 step:36124 [D loss: 0.737724, acc.: 42.19%] [G loss: 0.749203]\n",
      "epoch:46 step:36125 [D loss: 0.716672, acc.: 49.22%] [G loss: 0.758278]\n",
      "epoch:46 step:36126 [D loss: 0.698643, acc.: 51.56%] [G loss: 0.727244]\n",
      "epoch:46 step:36127 [D loss: 0.680997, acc.: 50.78%] [G loss: 0.788596]\n",
      "epoch:46 step:36128 [D loss: 0.702523, acc.: 58.59%] [G loss: 0.805489]\n",
      "epoch:46 step:36129 [D loss: 0.728875, acc.: 50.00%] [G loss: 0.830105]\n",
      "epoch:46 step:36130 [D loss: 0.736907, acc.: 45.31%] [G loss: 0.734556]\n",
      "epoch:46 step:36131 [D loss: 0.744365, acc.: 42.19%] [G loss: 0.809079]\n",
      "epoch:46 step:36132 [D loss: 0.720380, acc.: 47.66%] [G loss: 0.796675]\n",
      "epoch:46 step:36133 [D loss: 0.620407, acc.: 67.97%] [G loss: 0.779289]\n",
      "epoch:46 step:36134 [D loss: 0.654718, acc.: 63.28%] [G loss: 0.862678]\n",
      "epoch:46 step:36135 [D loss: 0.625934, acc.: 62.50%] [G loss: 1.002085]\n",
      "epoch:46 step:36136 [D loss: 0.674738, acc.: 54.69%] [G loss: 0.898011]\n",
      "epoch:46 step:36137 [D loss: 0.709698, acc.: 52.34%] [G loss: 0.794182]\n",
      "epoch:46 step:36138 [D loss: 0.645414, acc.: 60.94%] [G loss: 0.926993]\n",
      "epoch:46 step:36139 [D loss: 0.690392, acc.: 51.56%] [G loss: 0.869464]\n",
      "epoch:46 step:36140 [D loss: 0.675459, acc.: 56.25%] [G loss: 0.910376]\n",
      "epoch:46 step:36141 [D loss: 0.683746, acc.: 55.47%] [G loss: 0.826204]\n",
      "epoch:46 step:36142 [D loss: 0.657114, acc.: 60.94%] [G loss: 0.821889]\n",
      "epoch:46 step:36143 [D loss: 0.671456, acc.: 53.91%] [G loss: 0.714088]\n",
      "epoch:46 step:36144 [D loss: 0.669603, acc.: 58.59%] [G loss: 0.779645]\n",
      "epoch:46 step:36145 [D loss: 0.701538, acc.: 50.78%] [G loss: 0.807323]\n",
      "epoch:46 step:36146 [D loss: 0.670644, acc.: 64.84%] [G loss: 0.833881]\n",
      "epoch:46 step:36147 [D loss: 0.727952, acc.: 40.62%] [G loss: 0.816942]\n",
      "epoch:46 step:36148 [D loss: 0.646060, acc.: 65.62%] [G loss: 0.771731]\n",
      "epoch:46 step:36149 [D loss: 0.685396, acc.: 50.00%] [G loss: 0.839943]\n",
      "epoch:46 step:36150 [D loss: 0.647814, acc.: 64.06%] [G loss: 0.838044]\n",
      "epoch:46 step:36151 [D loss: 0.627448, acc.: 67.97%] [G loss: 0.831208]\n",
      "epoch:46 step:36152 [D loss: 0.655380, acc.: 64.06%] [G loss: 0.784244]\n",
      "epoch:46 step:36153 [D loss: 0.699731, acc.: 53.91%] [G loss: 0.751039]\n",
      "epoch:46 step:36154 [D loss: 0.712301, acc.: 47.66%] [G loss: 0.778742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36155 [D loss: 0.695693, acc.: 55.47%] [G loss: 0.819187]\n",
      "epoch:46 step:36156 [D loss: 0.689782, acc.: 53.91%] [G loss: 0.772906]\n",
      "epoch:46 step:36157 [D loss: 0.663291, acc.: 60.16%] [G loss: 0.873701]\n",
      "epoch:46 step:36158 [D loss: 0.710608, acc.: 54.69%] [G loss: 0.798662]\n",
      "epoch:46 step:36159 [D loss: 0.642089, acc.: 70.31%] [G loss: 0.844726]\n",
      "epoch:46 step:36160 [D loss: 0.707848, acc.: 46.88%] [G loss: 0.746015]\n",
      "epoch:46 step:36161 [D loss: 0.594043, acc.: 72.66%] [G loss: 0.776972]\n",
      "epoch:46 step:36162 [D loss: 0.693078, acc.: 55.47%] [G loss: 0.810909]\n",
      "epoch:46 step:36163 [D loss: 0.661222, acc.: 61.72%] [G loss: 0.779056]\n",
      "epoch:46 step:36164 [D loss: 0.751825, acc.: 38.28%] [G loss: 0.753573]\n",
      "epoch:46 step:36165 [D loss: 0.727932, acc.: 45.31%] [G loss: 0.775364]\n",
      "epoch:46 step:36166 [D loss: 0.695956, acc.: 51.56%] [G loss: 0.769769]\n",
      "epoch:46 step:36167 [D loss: 0.640470, acc.: 62.50%] [G loss: 0.828429]\n",
      "epoch:46 step:36168 [D loss: 0.656695, acc.: 61.72%] [G loss: 0.712817]\n",
      "epoch:46 step:36169 [D loss: 0.697077, acc.: 53.91%] [G loss: 0.780985]\n",
      "epoch:46 step:36170 [D loss: 0.710878, acc.: 44.53%] [G loss: 0.869392]\n",
      "epoch:46 step:36171 [D loss: 0.761437, acc.: 39.06%] [G loss: 0.803962]\n",
      "epoch:46 step:36172 [D loss: 0.710615, acc.: 49.22%] [G loss: 0.919240]\n",
      "epoch:46 step:36173 [D loss: 0.651385, acc.: 64.84%] [G loss: 0.843758]\n",
      "epoch:46 step:36174 [D loss: 0.691739, acc.: 53.12%] [G loss: 0.823482]\n",
      "epoch:46 step:36175 [D loss: 0.698774, acc.: 53.12%] [G loss: 0.768608]\n",
      "epoch:46 step:36176 [D loss: 0.738077, acc.: 48.44%] [G loss: 0.800790]\n",
      "epoch:46 step:36177 [D loss: 0.734757, acc.: 40.62%] [G loss: 0.822110]\n",
      "epoch:46 step:36178 [D loss: 0.693792, acc.: 51.56%] [G loss: 0.900456]\n",
      "epoch:46 step:36179 [D loss: 0.715926, acc.: 46.09%] [G loss: 0.828188]\n",
      "epoch:46 step:36180 [D loss: 0.700997, acc.: 50.00%] [G loss: 0.766217]\n",
      "epoch:46 step:36181 [D loss: 0.733734, acc.: 48.44%] [G loss: 0.843384]\n",
      "epoch:46 step:36182 [D loss: 0.671545, acc.: 57.81%] [G loss: 0.844140]\n",
      "epoch:46 step:36183 [D loss: 0.677685, acc.: 58.59%] [G loss: 0.814275]\n",
      "epoch:46 step:36184 [D loss: 0.621179, acc.: 69.53%] [G loss: 0.907983]\n",
      "epoch:46 step:36185 [D loss: 0.653964, acc.: 60.16%] [G loss: 0.884302]\n",
      "epoch:46 step:36186 [D loss: 0.698065, acc.: 60.94%] [G loss: 0.884420]\n",
      "epoch:46 step:36187 [D loss: 0.648667, acc.: 64.06%] [G loss: 0.719017]\n",
      "epoch:46 step:36188 [D loss: 0.649426, acc.: 62.50%] [G loss: 0.907299]\n",
      "epoch:46 step:36189 [D loss: 0.611326, acc.: 69.53%] [G loss: 0.896988]\n",
      "epoch:46 step:36190 [D loss: 0.656657, acc.: 58.59%] [G loss: 0.748239]\n",
      "epoch:46 step:36191 [D loss: 0.663233, acc.: 57.81%] [G loss: 0.751612]\n",
      "epoch:46 step:36192 [D loss: 0.736147, acc.: 41.41%] [G loss: 0.854770]\n",
      "epoch:46 step:36193 [D loss: 0.807380, acc.: 27.34%] [G loss: 0.868032]\n",
      "epoch:46 step:36194 [D loss: 0.695703, acc.: 59.38%] [G loss: 0.708267]\n",
      "epoch:46 step:36195 [D loss: 0.603945, acc.: 73.44%] [G loss: 0.762679]\n",
      "epoch:46 step:36196 [D loss: 0.695925, acc.: 52.34%] [G loss: 0.845631]\n",
      "epoch:46 step:36197 [D loss: 0.644410, acc.: 65.62%] [G loss: 0.871341]\n",
      "epoch:46 step:36198 [D loss: 0.671704, acc.: 61.72%] [G loss: 0.804657]\n",
      "epoch:46 step:36199 [D loss: 0.728004, acc.: 46.09%] [G loss: 0.839239]\n",
      "epoch:46 step:36200 [D loss: 0.672900, acc.: 61.72%] [G loss: 0.832045]\n",
      "epoch:46 step:36201 [D loss: 0.693861, acc.: 56.25%] [G loss: 0.832787]\n",
      "epoch:46 step:36202 [D loss: 0.738446, acc.: 42.19%] [G loss: 0.757744]\n",
      "epoch:46 step:36203 [D loss: 0.691707, acc.: 53.12%] [G loss: 0.916056]\n",
      "epoch:46 step:36204 [D loss: 0.624700, acc.: 67.97%] [G loss: 0.878110]\n",
      "epoch:46 step:36205 [D loss: 0.677983, acc.: 51.56%] [G loss: 0.812166]\n",
      "epoch:46 step:36206 [D loss: 0.624569, acc.: 70.31%] [G loss: 0.804217]\n",
      "epoch:46 step:36207 [D loss: 0.715923, acc.: 53.91%] [G loss: 0.849548]\n",
      "epoch:46 step:36208 [D loss: 0.654257, acc.: 62.50%] [G loss: 0.871337]\n",
      "epoch:46 step:36209 [D loss: 0.637596, acc.: 69.53%] [G loss: 0.898790]\n",
      "epoch:46 step:36210 [D loss: 0.640881, acc.: 60.16%] [G loss: 0.913135]\n",
      "epoch:46 step:36211 [D loss: 0.664001, acc.: 61.72%] [G loss: 0.784256]\n",
      "epoch:46 step:36212 [D loss: 0.641814, acc.: 63.28%] [G loss: 0.820332]\n",
      "epoch:46 step:36213 [D loss: 0.688042, acc.: 54.69%] [G loss: 0.835854]\n",
      "epoch:46 step:36214 [D loss: 0.683960, acc.: 53.91%] [G loss: 0.742980]\n",
      "epoch:46 step:36215 [D loss: 0.737112, acc.: 50.78%] [G loss: 0.695650]\n",
      "epoch:46 step:36216 [D loss: 0.691928, acc.: 54.69%] [G loss: 0.819329]\n",
      "epoch:46 step:36217 [D loss: 0.663787, acc.: 61.72%] [G loss: 0.816270]\n",
      "epoch:46 step:36218 [D loss: 0.680812, acc.: 53.12%] [G loss: 0.856058]\n",
      "epoch:46 step:36219 [D loss: 0.642986, acc.: 62.50%] [G loss: 0.792754]\n",
      "epoch:46 step:36220 [D loss: 0.622994, acc.: 67.19%] [G loss: 0.843816]\n",
      "epoch:46 step:36221 [D loss: 0.627751, acc.: 67.97%] [G loss: 0.827327]\n",
      "epoch:46 step:36222 [D loss: 0.646354, acc.: 63.28%] [G loss: 0.772058]\n",
      "epoch:46 step:36223 [D loss: 0.704657, acc.: 51.56%] [G loss: 0.768158]\n",
      "epoch:46 step:36224 [D loss: 0.698503, acc.: 57.03%] [G loss: 0.794644]\n",
      "epoch:46 step:36225 [D loss: 0.700389, acc.: 54.69%] [G loss: 0.775577]\n",
      "epoch:46 step:36226 [D loss: 0.721188, acc.: 43.75%] [G loss: 0.790351]\n",
      "epoch:46 step:36227 [D loss: 0.690889, acc.: 49.22%] [G loss: 0.827606]\n",
      "epoch:46 step:36228 [D loss: 0.708299, acc.: 56.25%] [G loss: 0.830875]\n",
      "epoch:46 step:36229 [D loss: 0.725481, acc.: 44.53%] [G loss: 0.772818]\n",
      "epoch:46 step:36230 [D loss: 0.665717, acc.: 60.16%] [G loss: 0.818061]\n",
      "epoch:46 step:36231 [D loss: 0.668427, acc.: 57.03%] [G loss: 0.814694]\n",
      "epoch:46 step:36232 [D loss: 0.714868, acc.: 48.44%] [G loss: 0.745826]\n",
      "epoch:46 step:36233 [D loss: 0.669146, acc.: 60.16%] [G loss: 0.747974]\n",
      "epoch:46 step:36234 [D loss: 0.654081, acc.: 63.28%] [G loss: 0.735774]\n",
      "epoch:46 step:36235 [D loss: 0.644947, acc.: 60.94%] [G loss: 0.723918]\n",
      "epoch:46 step:36236 [D loss: 0.638520, acc.: 66.41%] [G loss: 0.777262]\n",
      "epoch:46 step:36237 [D loss: 0.691184, acc.: 60.16%] [G loss: 0.723282]\n",
      "epoch:46 step:36238 [D loss: 0.666562, acc.: 60.16%] [G loss: 0.732164]\n",
      "epoch:46 step:36239 [D loss: 0.707168, acc.: 49.22%] [G loss: 0.739374]\n",
      "epoch:46 step:36240 [D loss: 0.701563, acc.: 55.47%] [G loss: 0.729604]\n",
      "epoch:46 step:36241 [D loss: 0.695219, acc.: 50.78%] [G loss: 0.748510]\n",
      "epoch:46 step:36242 [D loss: 0.704312, acc.: 50.00%] [G loss: 0.821517]\n",
      "epoch:46 step:36243 [D loss: 0.688270, acc.: 49.22%] [G loss: 0.794239]\n",
      "epoch:46 step:36244 [D loss: 0.720491, acc.: 46.88%] [G loss: 0.726862]\n",
      "epoch:46 step:36245 [D loss: 0.662204, acc.: 61.72%] [G loss: 0.778984]\n",
      "epoch:46 step:36246 [D loss: 0.675485, acc.: 58.59%] [G loss: 0.788171]\n",
      "epoch:46 step:36247 [D loss: 0.655347, acc.: 54.69%] [G loss: 0.797689]\n",
      "epoch:46 step:36248 [D loss: 0.659313, acc.: 60.16%] [G loss: 0.774228]\n",
      "epoch:46 step:36249 [D loss: 0.705334, acc.: 49.22%] [G loss: 0.764031]\n",
      "epoch:46 step:36250 [D loss: 0.709744, acc.: 50.00%] [G loss: 0.686772]\n",
      "epoch:46 step:36251 [D loss: 0.667625, acc.: 60.94%] [G loss: 0.683689]\n",
      "epoch:46 step:36252 [D loss: 0.646267, acc.: 64.84%] [G loss: 0.875215]\n",
      "epoch:46 step:36253 [D loss: 0.664087, acc.: 59.38%] [G loss: 0.862398]\n",
      "epoch:46 step:36254 [D loss: 0.713229, acc.: 50.78%] [G loss: 0.733268]\n",
      "epoch:46 step:36255 [D loss: 0.746180, acc.: 42.97%] [G loss: 0.721390]\n",
      "epoch:46 step:36256 [D loss: 0.700250, acc.: 51.56%] [G loss: 0.735838]\n",
      "epoch:46 step:36257 [D loss: 0.722652, acc.: 47.66%] [G loss: 0.750274]\n",
      "epoch:46 step:36258 [D loss: 0.690888, acc.: 55.47%] [G loss: 0.771864]\n",
      "epoch:46 step:36259 [D loss: 0.615324, acc.: 67.19%] [G loss: 0.826346]\n",
      "epoch:46 step:36260 [D loss: 0.671956, acc.: 58.59%] [G loss: 0.752907]\n",
      "epoch:46 step:36261 [D loss: 0.646315, acc.: 61.72%] [G loss: 0.755223]\n",
      "epoch:46 step:36262 [D loss: 0.704692, acc.: 59.38%] [G loss: 0.736972]\n",
      "epoch:46 step:36263 [D loss: 0.643928, acc.: 64.06%] [G loss: 0.728346]\n",
      "epoch:46 step:36264 [D loss: 0.764999, acc.: 30.47%] [G loss: 0.763520]\n",
      "epoch:46 step:36265 [D loss: 0.696338, acc.: 57.81%] [G loss: 0.729684]\n",
      "epoch:46 step:36266 [D loss: 0.677059, acc.: 56.25%] [G loss: 0.767762]\n",
      "epoch:46 step:36267 [D loss: 0.645187, acc.: 64.84%] [G loss: 0.786837]\n",
      "epoch:46 step:36268 [D loss: 0.585217, acc.: 74.22%] [G loss: 0.748300]\n",
      "epoch:46 step:36269 [D loss: 0.667389, acc.: 57.81%] [G loss: 0.829648]\n",
      "epoch:46 step:36270 [D loss: 0.717425, acc.: 50.00%] [G loss: 0.771119]\n",
      "epoch:46 step:36271 [D loss: 0.639643, acc.: 64.06%] [G loss: 0.849154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36272 [D loss: 0.678165, acc.: 57.03%] [G loss: 0.880701]\n",
      "epoch:46 step:36273 [D loss: 0.668774, acc.: 55.47%] [G loss: 0.780751]\n",
      "epoch:46 step:36274 [D loss: 0.679628, acc.: 60.16%] [G loss: 0.803713]\n",
      "epoch:46 step:36275 [D loss: 0.658860, acc.: 64.06%] [G loss: 0.795425]\n",
      "epoch:46 step:36276 [D loss: 0.627755, acc.: 69.53%] [G loss: 0.791528]\n",
      "epoch:46 step:36277 [D loss: 0.733794, acc.: 50.00%] [G loss: 0.810513]\n",
      "epoch:46 step:36278 [D loss: 0.702375, acc.: 50.78%] [G loss: 0.835451]\n",
      "epoch:46 step:36279 [D loss: 0.707701, acc.: 48.44%] [G loss: 0.927974]\n",
      "epoch:46 step:36280 [D loss: 0.657136, acc.: 62.50%] [G loss: 0.832937]\n",
      "epoch:46 step:36281 [D loss: 0.697072, acc.: 49.22%] [G loss: 0.763448]\n",
      "epoch:46 step:36282 [D loss: 0.724016, acc.: 44.53%] [G loss: 0.848032]\n",
      "epoch:46 step:36283 [D loss: 0.649819, acc.: 64.06%] [G loss: 0.762517]\n",
      "epoch:46 step:36284 [D loss: 0.705254, acc.: 54.69%] [G loss: 0.766138]\n",
      "epoch:46 step:36285 [D loss: 0.711222, acc.: 46.09%] [G loss: 0.789387]\n",
      "epoch:46 step:36286 [D loss: 0.646264, acc.: 64.06%] [G loss: 0.817380]\n",
      "epoch:46 step:36287 [D loss: 0.635883, acc.: 64.06%] [G loss: 0.778028]\n",
      "epoch:46 step:36288 [D loss: 0.653283, acc.: 58.59%] [G loss: 0.796371]\n",
      "epoch:46 step:36289 [D loss: 0.747648, acc.: 48.44%] [G loss: 0.678962]\n",
      "epoch:46 step:36290 [D loss: 0.740273, acc.: 41.41%] [G loss: 0.791100]\n",
      "epoch:46 step:36291 [D loss: 0.666597, acc.: 61.72%] [G loss: 0.801485]\n",
      "epoch:46 step:36292 [D loss: 0.676945, acc.: 53.91%] [G loss: 0.820444]\n",
      "epoch:46 step:36293 [D loss: 0.677767, acc.: 60.94%] [G loss: 0.805722]\n",
      "epoch:46 step:36294 [D loss: 0.710391, acc.: 52.34%] [G loss: 0.826052]\n",
      "epoch:46 step:36295 [D loss: 0.702534, acc.: 47.66%] [G loss: 0.910706]\n",
      "epoch:46 step:36296 [D loss: 0.689380, acc.: 55.47%] [G loss: 0.764510]\n",
      "epoch:46 step:36297 [D loss: 0.641119, acc.: 57.81%] [G loss: 0.789722]\n",
      "epoch:46 step:36298 [D loss: 0.657834, acc.: 62.50%] [G loss: 0.758613]\n",
      "epoch:46 step:36299 [D loss: 0.707251, acc.: 46.09%] [G loss: 0.819877]\n",
      "epoch:46 step:36300 [D loss: 0.695386, acc.: 51.56%] [G loss: 0.769441]\n",
      "epoch:46 step:36301 [D loss: 0.718643, acc.: 48.44%] [G loss: 0.802144]\n",
      "epoch:46 step:36302 [D loss: 0.690894, acc.: 52.34%] [G loss: 0.785097]\n",
      "epoch:46 step:36303 [D loss: 0.701310, acc.: 48.44%] [G loss: 0.851979]\n",
      "epoch:46 step:36304 [D loss: 0.669654, acc.: 60.94%] [G loss: 0.843313]\n",
      "epoch:46 step:36305 [D loss: 0.623174, acc.: 68.75%] [G loss: 0.923821]\n",
      "epoch:46 step:36306 [D loss: 0.683241, acc.: 57.81%] [G loss: 0.905501]\n",
      "epoch:46 step:36307 [D loss: 0.669521, acc.: 59.38%] [G loss: 0.773789]\n",
      "epoch:46 step:36308 [D loss: 0.688294, acc.: 57.81%] [G loss: 0.737142]\n",
      "epoch:46 step:36309 [D loss: 0.649044, acc.: 55.47%] [G loss: 0.795592]\n",
      "epoch:46 step:36310 [D loss: 0.645208, acc.: 62.50%] [G loss: 0.795232]\n",
      "epoch:46 step:36311 [D loss: 0.698681, acc.: 53.12%] [G loss: 0.709996]\n",
      "epoch:46 step:36312 [D loss: 0.647497, acc.: 62.50%] [G loss: 0.741888]\n",
      "epoch:46 step:36313 [D loss: 0.648399, acc.: 63.28%] [G loss: 0.760166]\n",
      "epoch:46 step:36314 [D loss: 0.676562, acc.: 60.94%] [G loss: 0.812731]\n",
      "epoch:46 step:36315 [D loss: 0.700762, acc.: 48.44%] [G loss: 0.748254]\n",
      "epoch:46 step:36316 [D loss: 0.672679, acc.: 55.47%] [G loss: 0.778200]\n",
      "epoch:46 step:36317 [D loss: 0.711937, acc.: 57.81%] [G loss: 0.759193]\n",
      "epoch:46 step:36318 [D loss: 0.657341, acc.: 57.03%] [G loss: 0.702604]\n",
      "epoch:46 step:36319 [D loss: 0.698580, acc.: 53.12%] [G loss: 0.703925]\n",
      "epoch:46 step:36320 [D loss: 0.622622, acc.: 71.09%] [G loss: 0.815943]\n",
      "epoch:46 step:36321 [D loss: 0.752758, acc.: 36.72%] [G loss: 0.765933]\n",
      "epoch:46 step:36322 [D loss: 0.737222, acc.: 43.75%] [G loss: 0.676874]\n",
      "epoch:46 step:36323 [D loss: 0.665538, acc.: 60.94%] [G loss: 0.770059]\n",
      "epoch:46 step:36324 [D loss: 0.677310, acc.: 58.59%] [G loss: 0.868556]\n",
      "epoch:46 step:36325 [D loss: 0.670198, acc.: 53.12%] [G loss: 0.785787]\n",
      "epoch:46 step:36326 [D loss: 0.681530, acc.: 55.47%] [G loss: 0.749269]\n",
      "epoch:46 step:36327 [D loss: 0.592378, acc.: 75.00%] [G loss: 0.774427]\n",
      "epoch:46 step:36328 [D loss: 0.636878, acc.: 67.19%] [G loss: 0.784709]\n",
      "epoch:46 step:36329 [D loss: 0.594630, acc.: 75.78%] [G loss: 0.775975]\n",
      "epoch:46 step:36330 [D loss: 0.599936, acc.: 74.22%] [G loss: 0.789295]\n",
      "epoch:46 step:36331 [D loss: 0.716634, acc.: 49.22%] [G loss: 0.691894]\n",
      "epoch:46 step:36332 [D loss: 0.663175, acc.: 58.59%] [G loss: 0.776100]\n",
      "epoch:46 step:36333 [D loss: 0.639765, acc.: 67.19%] [G loss: 0.876357]\n",
      "epoch:46 step:36334 [D loss: 0.645637, acc.: 64.06%] [G loss: 0.865487]\n",
      "epoch:46 step:36335 [D loss: 0.691910, acc.: 53.12%] [G loss: 0.798341]\n",
      "epoch:46 step:36336 [D loss: 0.678064, acc.: 57.81%] [G loss: 0.868394]\n",
      "epoch:46 step:36337 [D loss: 0.690045, acc.: 52.34%] [G loss: 0.767036]\n",
      "epoch:46 step:36338 [D loss: 0.662627, acc.: 57.81%] [G loss: 0.702000]\n",
      "epoch:46 step:36339 [D loss: 0.703158, acc.: 54.69%] [G loss: 0.761790]\n",
      "epoch:46 step:36340 [D loss: 0.728959, acc.: 41.41%] [G loss: 0.723132]\n",
      "epoch:46 step:36341 [D loss: 0.641136, acc.: 67.97%] [G loss: 0.843357]\n",
      "epoch:46 step:36342 [D loss: 0.647619, acc.: 64.06%] [G loss: 0.769244]\n",
      "epoch:46 step:36343 [D loss: 0.725749, acc.: 49.22%] [G loss: 0.834625]\n",
      "epoch:46 step:36344 [D loss: 0.647889, acc.: 69.53%] [G loss: 0.801890]\n",
      "epoch:46 step:36345 [D loss: 0.660133, acc.: 59.38%] [G loss: 0.891057]\n",
      "epoch:46 step:36346 [D loss: 0.665517, acc.: 58.59%] [G loss: 0.789235]\n",
      "epoch:46 step:36347 [D loss: 0.679637, acc.: 56.25%] [G loss: 0.814174]\n",
      "epoch:46 step:36348 [D loss: 0.756859, acc.: 39.84%] [G loss: 0.755794]\n",
      "epoch:46 step:36349 [D loss: 0.715145, acc.: 44.53%] [G loss: 0.747010]\n",
      "epoch:46 step:36350 [D loss: 0.713499, acc.: 50.78%] [G loss: 0.816060]\n",
      "epoch:46 step:36351 [D loss: 0.667086, acc.: 58.59%] [G loss: 0.734652]\n",
      "epoch:46 step:36352 [D loss: 0.663664, acc.: 60.16%] [G loss: 0.803188]\n",
      "epoch:46 step:36353 [D loss: 0.716610, acc.: 56.25%] [G loss: 0.770442]\n",
      "epoch:46 step:36354 [D loss: 0.692926, acc.: 53.12%] [G loss: 0.776013]\n",
      "epoch:46 step:36355 [D loss: 0.686960, acc.: 53.91%] [G loss: 0.664509]\n",
      "epoch:46 step:36356 [D loss: 0.679496, acc.: 58.59%] [G loss: 0.712103]\n",
      "epoch:46 step:36357 [D loss: 0.685687, acc.: 50.78%] [G loss: 0.843391]\n",
      "epoch:46 step:36358 [D loss: 0.718480, acc.: 48.44%] [G loss: 0.739301]\n",
      "epoch:46 step:36359 [D loss: 0.665286, acc.: 60.16%] [G loss: 0.748412]\n",
      "epoch:46 step:36360 [D loss: 0.656172, acc.: 66.41%] [G loss: 0.753381]\n",
      "epoch:46 step:36361 [D loss: 0.737889, acc.: 39.84%] [G loss: 0.757480]\n",
      "epoch:46 step:36362 [D loss: 0.819660, acc.: 25.00%] [G loss: 0.755115]\n",
      "epoch:46 step:36363 [D loss: 0.729355, acc.: 49.22%] [G loss: 0.768588]\n",
      "epoch:46 step:36364 [D loss: 0.676443, acc.: 59.38%] [G loss: 0.775138]\n",
      "epoch:46 step:36365 [D loss: 0.751351, acc.: 40.62%] [G loss: 0.735361]\n",
      "epoch:46 step:36366 [D loss: 0.628410, acc.: 74.22%] [G loss: 0.768528]\n",
      "epoch:46 step:36367 [D loss: 0.738041, acc.: 46.88%] [G loss: 0.898609]\n",
      "epoch:46 step:36368 [D loss: 0.675882, acc.: 54.69%] [G loss: 0.834833]\n",
      "epoch:46 step:36369 [D loss: 0.675326, acc.: 60.16%] [G loss: 0.865319]\n",
      "epoch:46 step:36370 [D loss: 0.687386, acc.: 56.25%] [G loss: 0.867125]\n",
      "epoch:46 step:36371 [D loss: 0.739126, acc.: 40.62%] [G loss: 0.913939]\n",
      "epoch:46 step:36372 [D loss: 0.769052, acc.: 43.75%] [G loss: 0.811925]\n",
      "epoch:46 step:36373 [D loss: 0.647806, acc.: 64.84%] [G loss: 0.770092]\n",
      "epoch:46 step:36374 [D loss: 0.671570, acc.: 62.50%] [G loss: 0.735209]\n",
      "epoch:46 step:36375 [D loss: 0.645927, acc.: 63.28%] [G loss: 0.761080]\n",
      "epoch:46 step:36376 [D loss: 0.657734, acc.: 64.06%] [G loss: 0.761754]\n",
      "epoch:46 step:36377 [D loss: 0.702706, acc.: 53.91%] [G loss: 0.792440]\n",
      "epoch:46 step:36378 [D loss: 0.683101, acc.: 57.81%] [G loss: 0.815737]\n",
      "epoch:46 step:36379 [D loss: 0.646121, acc.: 64.06%] [G loss: 0.792950]\n",
      "epoch:46 step:36380 [D loss: 0.680378, acc.: 61.72%] [G loss: 0.830577]\n",
      "epoch:46 step:36381 [D loss: 0.722650, acc.: 47.66%] [G loss: 0.789379]\n",
      "epoch:46 step:36382 [D loss: 0.711227, acc.: 52.34%] [G loss: 0.723916]\n",
      "epoch:46 step:36383 [D loss: 0.727684, acc.: 47.66%] [G loss: 0.856685]\n",
      "epoch:46 step:36384 [D loss: 0.702959, acc.: 50.00%] [G loss: 0.838904]\n",
      "epoch:46 step:36385 [D loss: 0.732006, acc.: 44.53%] [G loss: 0.909387]\n",
      "epoch:46 step:36386 [D loss: 0.668562, acc.: 56.25%] [G loss: 0.842633]\n",
      "epoch:46 step:36387 [D loss: 0.654469, acc.: 58.59%] [G loss: 0.920512]\n",
      "epoch:46 step:36388 [D loss: 0.704505, acc.: 50.78%] [G loss: 0.828521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36389 [D loss: 0.669096, acc.: 60.16%] [G loss: 0.921615]\n",
      "epoch:46 step:36390 [D loss: 0.625307, acc.: 64.06%] [G loss: 0.954502]\n",
      "epoch:46 step:36391 [D loss: 0.652490, acc.: 64.84%] [G loss: 0.795001]\n",
      "epoch:46 step:36392 [D loss: 0.623704, acc.: 75.78%] [G loss: 0.818202]\n",
      "epoch:46 step:36393 [D loss: 0.625679, acc.: 71.88%] [G loss: 0.885816]\n",
      "epoch:46 step:36394 [D loss: 0.681776, acc.: 55.47%] [G loss: 0.869560]\n",
      "epoch:46 step:36395 [D loss: 0.631779, acc.: 62.50%] [G loss: 0.841943]\n",
      "epoch:46 step:36396 [D loss: 0.714104, acc.: 47.66%] [G loss: 0.753329]\n",
      "epoch:46 step:36397 [D loss: 0.655838, acc.: 59.38%] [G loss: 0.936978]\n",
      "epoch:46 step:36398 [D loss: 0.693184, acc.: 48.44%] [G loss: 0.743306]\n",
      "epoch:46 step:36399 [D loss: 0.709027, acc.: 50.78%] [G loss: 0.814708]\n",
      "epoch:46 step:36400 [D loss: 0.676305, acc.: 56.25%] [G loss: 0.738889]\n",
      "epoch:46 step:36401 [D loss: 0.696659, acc.: 49.22%] [G loss: 0.875644]\n",
      "epoch:46 step:36402 [D loss: 0.664238, acc.: 58.59%] [G loss: 0.789739]\n",
      "epoch:46 step:36403 [D loss: 0.664268, acc.: 60.94%] [G loss: 0.766501]\n",
      "epoch:46 step:36404 [D loss: 0.629196, acc.: 69.53%] [G loss: 0.787755]\n",
      "epoch:46 step:36405 [D loss: 0.687078, acc.: 55.47%] [G loss: 0.790202]\n",
      "epoch:46 step:36406 [D loss: 0.653724, acc.: 60.94%] [G loss: 0.840194]\n",
      "epoch:46 step:36407 [D loss: 0.658195, acc.: 56.25%] [G loss: 0.799702]\n",
      "epoch:46 step:36408 [D loss: 0.658330, acc.: 60.94%] [G loss: 0.781376]\n",
      "epoch:46 step:36409 [D loss: 0.617222, acc.: 68.75%] [G loss: 0.807073]\n",
      "epoch:46 step:36410 [D loss: 0.667903, acc.: 62.50%] [G loss: 0.776746]\n",
      "epoch:46 step:36411 [D loss: 0.654155, acc.: 64.06%] [G loss: 0.725172]\n",
      "epoch:46 step:36412 [D loss: 0.668252, acc.: 61.72%] [G loss: 0.812305]\n",
      "epoch:46 step:36413 [D loss: 0.689354, acc.: 53.12%] [G loss: 0.767948]\n",
      "epoch:46 step:36414 [D loss: 0.669645, acc.: 57.03%] [G loss: 0.805914]\n",
      "epoch:46 step:36415 [D loss: 0.687144, acc.: 51.56%] [G loss: 0.854104]\n",
      "epoch:46 step:36416 [D loss: 0.622758, acc.: 71.09%] [G loss: 0.803986]\n",
      "epoch:46 step:36417 [D loss: 0.718896, acc.: 52.34%] [G loss: 0.842464]\n",
      "epoch:46 step:36418 [D loss: 0.669549, acc.: 56.25%] [G loss: 0.854871]\n",
      "epoch:46 step:36419 [D loss: 0.677371, acc.: 53.12%] [G loss: 0.769464]\n",
      "epoch:46 step:36420 [D loss: 0.693271, acc.: 53.91%] [G loss: 0.865855]\n",
      "epoch:46 step:36421 [D loss: 0.661854, acc.: 61.72%] [G loss: 0.820431]\n",
      "epoch:46 step:36422 [D loss: 0.626884, acc.: 64.06%] [G loss: 0.871623]\n",
      "epoch:46 step:36423 [D loss: 0.643349, acc.: 61.72%] [G loss: 0.793281]\n",
      "epoch:46 step:36424 [D loss: 0.631728, acc.: 69.53%] [G loss: 0.859650]\n",
      "epoch:46 step:36425 [D loss: 0.633259, acc.: 66.41%] [G loss: 0.712635]\n",
      "epoch:46 step:36426 [D loss: 0.599838, acc.: 76.56%] [G loss: 0.869707]\n",
      "epoch:46 step:36427 [D loss: 0.690376, acc.: 57.81%] [G loss: 0.853077]\n",
      "epoch:46 step:36428 [D loss: 0.672522, acc.: 60.16%] [G loss: 0.890064]\n",
      "epoch:46 step:36429 [D loss: 0.712803, acc.: 50.78%] [G loss: 0.826353]\n",
      "epoch:46 step:36430 [D loss: 0.663424, acc.: 61.72%] [G loss: 0.899368]\n",
      "epoch:46 step:36431 [D loss: 0.695497, acc.: 53.12%] [G loss: 0.727693]\n",
      "epoch:46 step:36432 [D loss: 0.679132, acc.: 58.59%] [G loss: 0.838536]\n",
      "epoch:46 step:36433 [D loss: 0.703899, acc.: 55.47%] [G loss: 0.834854]\n",
      "epoch:46 step:36434 [D loss: 0.701953, acc.: 53.12%] [G loss: 0.786374]\n",
      "epoch:46 step:36435 [D loss: 0.660554, acc.: 61.72%] [G loss: 0.770349]\n",
      "epoch:46 step:36436 [D loss: 0.692180, acc.: 57.81%] [G loss: 0.802102]\n",
      "epoch:46 step:36437 [D loss: 0.697576, acc.: 55.47%] [G loss: 0.723838]\n",
      "epoch:46 step:36438 [D loss: 0.688614, acc.: 57.81%] [G loss: 0.795809]\n",
      "epoch:46 step:36439 [D loss: 0.724818, acc.: 49.22%] [G loss: 0.759680]\n",
      "epoch:46 step:36440 [D loss: 0.741146, acc.: 46.88%] [G loss: 0.720487]\n",
      "epoch:46 step:36441 [D loss: 0.644405, acc.: 67.19%] [G loss: 0.874934]\n",
      "epoch:46 step:36442 [D loss: 0.622022, acc.: 66.41%] [G loss: 0.884161]\n",
      "epoch:46 step:36443 [D loss: 0.661605, acc.: 60.94%] [G loss: 0.808414]\n",
      "epoch:46 step:36444 [D loss: 0.665787, acc.: 63.28%] [G loss: 0.876743]\n",
      "epoch:46 step:36445 [D loss: 0.783329, acc.: 37.50%] [G loss: 0.718605]\n",
      "epoch:46 step:36446 [D loss: 0.712041, acc.: 52.34%] [G loss: 0.792078]\n",
      "epoch:46 step:36447 [D loss: 0.692134, acc.: 50.78%] [G loss: 0.873186]\n",
      "epoch:46 step:36448 [D loss: 0.680898, acc.: 58.59%] [G loss: 0.786434]\n",
      "epoch:46 step:36449 [D loss: 0.651218, acc.: 60.94%] [G loss: 0.854148]\n",
      "epoch:46 step:36450 [D loss: 0.661626, acc.: 57.81%] [G loss: 0.780891]\n",
      "epoch:46 step:36451 [D loss: 0.721441, acc.: 50.78%] [G loss: 0.747968]\n",
      "epoch:46 step:36452 [D loss: 0.670913, acc.: 56.25%] [G loss: 0.790059]\n",
      "epoch:46 step:36453 [D loss: 0.655707, acc.: 60.94%] [G loss: 0.955543]\n",
      "epoch:46 step:36454 [D loss: 0.727407, acc.: 46.88%] [G loss: 0.769947]\n",
      "epoch:46 step:36455 [D loss: 0.655806, acc.: 59.38%] [G loss: 0.834848]\n",
      "epoch:46 step:36456 [D loss: 0.649137, acc.: 63.28%] [G loss: 0.766566]\n",
      "epoch:46 step:36457 [D loss: 0.675992, acc.: 59.38%] [G loss: 0.870012]\n",
      "epoch:46 step:36458 [D loss: 0.654434, acc.: 58.59%] [G loss: 0.879866]\n",
      "epoch:46 step:36459 [D loss: 0.624584, acc.: 68.75%] [G loss: 0.868960]\n",
      "epoch:46 step:36460 [D loss: 0.651644, acc.: 64.84%] [G loss: 0.881646]\n",
      "epoch:46 step:36461 [D loss: 0.624505, acc.: 69.53%] [G loss: 0.837550]\n",
      "epoch:46 step:36462 [D loss: 0.640047, acc.: 61.72%] [G loss: 0.888523]\n",
      "epoch:46 step:36463 [D loss: 0.709252, acc.: 50.00%] [G loss: 0.834942]\n",
      "epoch:46 step:36464 [D loss: 0.704909, acc.: 52.34%] [G loss: 0.822546]\n",
      "epoch:46 step:36465 [D loss: 0.724950, acc.: 45.31%] [G loss: 0.783991]\n",
      "epoch:46 step:36466 [D loss: 0.651137, acc.: 62.50%] [G loss: 0.804420]\n",
      "epoch:46 step:36467 [D loss: 0.651014, acc.: 67.97%] [G loss: 0.792407]\n",
      "epoch:46 step:36468 [D loss: 0.644590, acc.: 63.28%] [G loss: 0.762853]\n",
      "epoch:46 step:36469 [D loss: 0.684599, acc.: 52.34%] [G loss: 0.746654]\n",
      "epoch:46 step:36470 [D loss: 0.671119, acc.: 54.69%] [G loss: 0.759367]\n",
      "epoch:46 step:36471 [D loss: 0.642191, acc.: 67.19%] [G loss: 0.807516]\n",
      "epoch:46 step:36472 [D loss: 0.671363, acc.: 57.81%] [G loss: 0.837458]\n",
      "epoch:46 step:36473 [D loss: 0.656013, acc.: 62.50%] [G loss: 0.751474]\n",
      "epoch:46 step:36474 [D loss: 0.720096, acc.: 47.66%] [G loss: 0.769330]\n",
      "epoch:46 step:36475 [D loss: 0.662600, acc.: 55.47%] [G loss: 0.749102]\n",
      "epoch:46 step:36476 [D loss: 0.631842, acc.: 66.41%] [G loss: 0.783643]\n",
      "epoch:46 step:36477 [D loss: 0.673935, acc.: 60.16%] [G loss: 0.763597]\n",
      "epoch:46 step:36478 [D loss: 0.678006, acc.: 62.50%] [G loss: 0.674279]\n",
      "epoch:46 step:36479 [D loss: 0.636222, acc.: 68.75%] [G loss: 0.753698]\n",
      "epoch:46 step:36480 [D loss: 0.646066, acc.: 71.09%] [G loss: 0.804826]\n",
      "epoch:46 step:36481 [D loss: 0.699312, acc.: 49.22%] [G loss: 0.797389]\n",
      "epoch:46 step:36482 [D loss: 0.712525, acc.: 52.34%] [G loss: 0.766790]\n",
      "epoch:46 step:36483 [D loss: 0.749192, acc.: 43.75%] [G loss: 0.771718]\n",
      "epoch:46 step:36484 [D loss: 0.635345, acc.: 67.19%] [G loss: 0.756737]\n",
      "epoch:46 step:36485 [D loss: 0.644763, acc.: 62.50%] [G loss: 0.831462]\n",
      "epoch:46 step:36486 [D loss: 0.623221, acc.: 71.09%] [G loss: 0.840092]\n",
      "epoch:46 step:36487 [D loss: 0.734522, acc.: 42.19%] [G loss: 0.687029]\n",
      "epoch:46 step:36488 [D loss: 0.668554, acc.: 58.59%] [G loss: 0.851134]\n",
      "epoch:46 step:36489 [D loss: 0.715182, acc.: 46.88%] [G loss: 0.762744]\n",
      "epoch:46 step:36490 [D loss: 0.687300, acc.: 57.81%] [G loss: 0.796661]\n",
      "epoch:46 step:36491 [D loss: 0.630507, acc.: 70.31%] [G loss: 0.717948]\n",
      "epoch:46 step:36492 [D loss: 0.707187, acc.: 49.22%] [G loss: 0.777832]\n",
      "epoch:46 step:36493 [D loss: 0.650164, acc.: 60.94%] [G loss: 0.873214]\n",
      "epoch:46 step:36494 [D loss: 0.609824, acc.: 67.97%] [G loss: 0.820223]\n",
      "epoch:46 step:36495 [D loss: 0.716143, acc.: 42.19%] [G loss: 0.858407]\n",
      "epoch:46 step:36496 [D loss: 0.683933, acc.: 57.03%] [G loss: 0.796212]\n",
      "epoch:46 step:36497 [D loss: 0.735730, acc.: 46.09%] [G loss: 0.777157]\n",
      "epoch:46 step:36498 [D loss: 0.770386, acc.: 42.97%] [G loss: 0.735818]\n",
      "epoch:46 step:36499 [D loss: 0.692348, acc.: 51.56%] [G loss: 0.835846]\n",
      "epoch:46 step:36500 [D loss: 0.751381, acc.: 48.44%] [G loss: 0.749461]\n",
      "epoch:46 step:36501 [D loss: 0.654194, acc.: 64.06%] [G loss: 0.817410]\n",
      "epoch:46 step:36502 [D loss: 0.673485, acc.: 59.38%] [G loss: 0.823140]\n",
      "epoch:46 step:36503 [D loss: 0.744289, acc.: 39.84%] [G loss: 0.819888]\n",
      "epoch:46 step:36504 [D loss: 0.637817, acc.: 68.75%] [G loss: 0.837382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36505 [D loss: 0.619032, acc.: 71.88%] [G loss: 0.786807]\n",
      "epoch:46 step:36506 [D loss: 0.670582, acc.: 57.81%] [G loss: 0.852701]\n",
      "epoch:46 step:36507 [D loss: 0.684085, acc.: 53.12%] [G loss: 0.792443]\n",
      "epoch:46 step:36508 [D loss: 0.649065, acc.: 64.84%] [G loss: 0.764481]\n",
      "epoch:46 step:36509 [D loss: 0.658819, acc.: 57.03%] [G loss: 0.837634]\n",
      "epoch:46 step:36510 [D loss: 0.712087, acc.: 50.00%] [G loss: 0.743598]\n",
      "epoch:46 step:36511 [D loss: 0.693071, acc.: 57.81%] [G loss: 0.843534]\n",
      "epoch:46 step:36512 [D loss: 0.719311, acc.: 47.66%] [G loss: 0.732617]\n",
      "epoch:46 step:36513 [D loss: 0.603728, acc.: 73.44%] [G loss: 0.813333]\n",
      "epoch:46 step:36514 [D loss: 0.616274, acc.: 70.31%] [G loss: 0.801025]\n",
      "epoch:46 step:36515 [D loss: 0.682414, acc.: 57.81%] [G loss: 0.873803]\n",
      "epoch:46 step:36516 [D loss: 0.674332, acc.: 55.47%] [G loss: 0.833119]\n",
      "epoch:46 step:36517 [D loss: 0.660626, acc.: 57.03%] [G loss: 0.875898]\n",
      "epoch:46 step:36518 [D loss: 0.629282, acc.: 67.19%] [G loss: 0.866587]\n",
      "epoch:46 step:36519 [D loss: 0.733879, acc.: 47.66%] [G loss: 0.877372]\n",
      "epoch:46 step:36520 [D loss: 0.615793, acc.: 73.44%] [G loss: 0.775043]\n",
      "epoch:46 step:36521 [D loss: 0.619713, acc.: 68.75%] [G loss: 0.845644]\n",
      "epoch:46 step:36522 [D loss: 0.775521, acc.: 37.50%] [G loss: 0.733765]\n",
      "epoch:46 step:36523 [D loss: 0.652054, acc.: 59.38%] [G loss: 0.785995]\n",
      "epoch:46 step:36524 [D loss: 0.718234, acc.: 42.97%] [G loss: 0.820714]\n",
      "epoch:46 step:36525 [D loss: 0.721707, acc.: 45.31%] [G loss: 0.854296]\n",
      "epoch:46 step:36526 [D loss: 0.608469, acc.: 73.44%] [G loss: 0.860015]\n",
      "epoch:46 step:36527 [D loss: 0.627731, acc.: 70.31%] [G loss: 0.855627]\n",
      "epoch:46 step:36528 [D loss: 0.598571, acc.: 75.00%] [G loss: 0.764742]\n",
      "epoch:46 step:36529 [D loss: 0.702262, acc.: 50.00%] [G loss: 0.927960]\n",
      "epoch:46 step:36530 [D loss: 0.664893, acc.: 60.94%] [G loss: 0.849562]\n",
      "epoch:46 step:36531 [D loss: 0.691595, acc.: 54.69%] [G loss: 0.809947]\n",
      "epoch:46 step:36532 [D loss: 0.635611, acc.: 66.41%] [G loss: 0.820598]\n",
      "epoch:46 step:36533 [D loss: 0.681863, acc.: 57.81%] [G loss: 0.729973]\n",
      "epoch:46 step:36534 [D loss: 0.685100, acc.: 57.81%] [G loss: 0.775156]\n",
      "epoch:46 step:36535 [D loss: 0.668444, acc.: 57.03%] [G loss: 0.754148]\n",
      "epoch:46 step:36536 [D loss: 0.672013, acc.: 60.94%] [G loss: 0.939654]\n",
      "epoch:46 step:36537 [D loss: 0.676644, acc.: 58.59%] [G loss: 0.752532]\n",
      "epoch:46 step:36538 [D loss: 0.664955, acc.: 53.91%] [G loss: 0.805532]\n",
      "epoch:46 step:36539 [D loss: 0.682575, acc.: 57.81%] [G loss: 0.762599]\n",
      "epoch:46 step:36540 [D loss: 0.663474, acc.: 63.28%] [G loss: 0.794717]\n",
      "epoch:46 step:36541 [D loss: 0.665792, acc.: 65.62%] [G loss: 0.789638]\n",
      "epoch:46 step:36542 [D loss: 0.692463, acc.: 50.78%] [G loss: 0.896375]\n",
      "epoch:46 step:36543 [D loss: 0.697222, acc.: 51.56%] [G loss: 0.805609]\n",
      "epoch:46 step:36544 [D loss: 0.642228, acc.: 69.53%] [G loss: 0.744034]\n",
      "epoch:46 step:36545 [D loss: 0.635734, acc.: 66.41%] [G loss: 0.784537]\n",
      "epoch:46 step:36546 [D loss: 0.715089, acc.: 50.78%] [G loss: 0.787024]\n",
      "epoch:46 step:36547 [D loss: 0.676322, acc.: 57.81%] [G loss: 0.784589]\n",
      "epoch:46 step:36548 [D loss: 0.680786, acc.: 61.72%] [G loss: 0.870924]\n",
      "epoch:46 step:36549 [D loss: 0.708632, acc.: 53.12%] [G loss: 0.771035]\n",
      "epoch:46 step:36550 [D loss: 0.681413, acc.: 57.81%] [G loss: 0.822379]\n",
      "epoch:46 step:36551 [D loss: 0.722066, acc.: 46.88%] [G loss: 0.826680]\n",
      "epoch:46 step:36552 [D loss: 0.637291, acc.: 64.06%] [G loss: 0.910512]\n",
      "epoch:46 step:36553 [D loss: 0.657494, acc.: 61.72%] [G loss: 0.856496]\n",
      "epoch:46 step:36554 [D loss: 0.620729, acc.: 74.22%] [G loss: 0.829138]\n",
      "epoch:46 step:36555 [D loss: 0.720365, acc.: 46.09%] [G loss: 0.869813]\n",
      "epoch:46 step:36556 [D loss: 0.740944, acc.: 38.28%] [G loss: 0.769162]\n",
      "epoch:46 step:36557 [D loss: 0.646746, acc.: 65.62%] [G loss: 0.925978]\n",
      "epoch:46 step:36558 [D loss: 0.662432, acc.: 59.38%] [G loss: 0.822615]\n",
      "epoch:46 step:36559 [D loss: 0.684160, acc.: 57.03%] [G loss: 0.755881]\n",
      "epoch:46 step:36560 [D loss: 0.701195, acc.: 54.69%] [G loss: 0.895013]\n",
      "epoch:46 step:36561 [D loss: 0.643596, acc.: 67.97%] [G loss: 0.868692]\n",
      "epoch:46 step:36562 [D loss: 0.712233, acc.: 56.25%] [G loss: 0.861830]\n",
      "epoch:46 step:36563 [D loss: 0.662167, acc.: 60.94%] [G loss: 0.870991]\n",
      "epoch:46 step:36564 [D loss: 0.696329, acc.: 53.12%] [G loss: 0.781698]\n",
      "epoch:46 step:36565 [D loss: 0.709573, acc.: 48.44%] [G loss: 0.800631]\n",
      "epoch:46 step:36566 [D loss: 0.681811, acc.: 52.34%] [G loss: 0.820390]\n",
      "epoch:46 step:36567 [D loss: 0.711007, acc.: 49.22%] [G loss: 0.825741]\n",
      "epoch:46 step:36568 [D loss: 0.684321, acc.: 47.66%] [G loss: 0.791868]\n",
      "epoch:46 step:36569 [D loss: 0.681268, acc.: 54.69%] [G loss: 0.855013]\n",
      "epoch:46 step:36570 [D loss: 0.670309, acc.: 57.03%] [G loss: 0.808443]\n",
      "epoch:46 step:36571 [D loss: 0.616871, acc.: 71.88%] [G loss: 0.737681]\n",
      "epoch:46 step:36572 [D loss: 0.695210, acc.: 48.44%] [G loss: 0.847837]\n",
      "epoch:46 step:36573 [D loss: 0.710037, acc.: 60.16%] [G loss: 0.836897]\n",
      "epoch:46 step:36574 [D loss: 0.644282, acc.: 60.94%] [G loss: 0.746449]\n",
      "epoch:46 step:36575 [D loss: 0.651816, acc.: 61.72%] [G loss: 0.710316]\n",
      "epoch:46 step:36576 [D loss: 0.665690, acc.: 58.59%] [G loss: 0.814272]\n",
      "epoch:46 step:36577 [D loss: 0.617223, acc.: 72.66%] [G loss: 0.776445]\n",
      "epoch:46 step:36578 [D loss: 0.584810, acc.: 76.56%] [G loss: 0.849507]\n",
      "epoch:46 step:36579 [D loss: 0.691132, acc.: 55.47%] [G loss: 0.753824]\n",
      "epoch:46 step:36580 [D loss: 0.721963, acc.: 46.09%] [G loss: 0.851538]\n",
      "epoch:46 step:36581 [D loss: 0.702836, acc.: 49.22%] [G loss: 0.765108]\n",
      "epoch:46 step:36582 [D loss: 0.666072, acc.: 57.03%] [G loss: 0.712138]\n",
      "epoch:46 step:36583 [D loss: 0.710709, acc.: 46.88%] [G loss: 0.762478]\n",
      "epoch:46 step:36584 [D loss: 0.641812, acc.: 63.28%] [G loss: 0.755447]\n",
      "epoch:46 step:36585 [D loss: 0.701114, acc.: 44.53%] [G loss: 0.761318]\n",
      "epoch:46 step:36586 [D loss: 0.708662, acc.: 50.00%] [G loss: 0.861636]\n",
      "epoch:46 step:36587 [D loss: 0.632557, acc.: 65.62%] [G loss: 0.873731]\n",
      "epoch:46 step:36588 [D loss: 0.641410, acc.: 71.09%] [G loss: 0.833551]\n",
      "epoch:46 step:36589 [D loss: 0.607536, acc.: 67.97%] [G loss: 0.890072]\n",
      "epoch:46 step:36590 [D loss: 0.714031, acc.: 46.88%] [G loss: 0.775016]\n",
      "epoch:46 step:36591 [D loss: 0.717652, acc.: 49.22%] [G loss: 0.865276]\n",
      "epoch:46 step:36592 [D loss: 0.694328, acc.: 52.34%] [G loss: 0.908801]\n",
      "epoch:46 step:36593 [D loss: 0.688154, acc.: 50.00%] [G loss: 0.831707]\n",
      "epoch:46 step:36594 [D loss: 0.632588, acc.: 68.75%] [G loss: 0.720168]\n",
      "epoch:46 step:36595 [D loss: 0.673665, acc.: 60.94%] [G loss: 0.761636]\n",
      "epoch:46 step:36596 [D loss: 0.652267, acc.: 64.06%] [G loss: 0.835870]\n",
      "epoch:46 step:36597 [D loss: 0.729482, acc.: 42.97%] [G loss: 0.703426]\n",
      "epoch:46 step:36598 [D loss: 0.696434, acc.: 55.47%] [G loss: 0.826944]\n",
      "epoch:46 step:36599 [D loss: 0.630963, acc.: 71.09%] [G loss: 0.800319]\n",
      "epoch:46 step:36600 [D loss: 0.687828, acc.: 55.47%] [G loss: 0.798770]\n",
      "epoch:46 step:36601 [D loss: 0.697677, acc.: 57.03%] [G loss: 0.824800]\n",
      "epoch:46 step:36602 [D loss: 0.718845, acc.: 46.88%] [G loss: 0.690152]\n",
      "epoch:46 step:36603 [D loss: 0.671284, acc.: 59.38%] [G loss: 0.754511]\n",
      "epoch:46 step:36604 [D loss: 0.694339, acc.: 58.59%] [G loss: 0.811229]\n",
      "epoch:46 step:36605 [D loss: 0.669998, acc.: 53.91%] [G loss: 0.752185]\n",
      "epoch:46 step:36606 [D loss: 0.648168, acc.: 65.62%] [G loss: 0.827450]\n",
      "epoch:46 step:36607 [D loss: 0.709612, acc.: 52.34%] [G loss: 0.834999]\n",
      "epoch:46 step:36608 [D loss: 0.675274, acc.: 60.94%] [G loss: 0.846022]\n",
      "epoch:46 step:36609 [D loss: 0.600228, acc.: 76.56%] [G loss: 0.821078]\n",
      "epoch:46 step:36610 [D loss: 0.648488, acc.: 63.28%] [G loss: 0.746881]\n",
      "epoch:46 step:36611 [D loss: 0.653911, acc.: 57.81%] [G loss: 0.952650]\n",
      "epoch:46 step:36612 [D loss: 0.689382, acc.: 53.12%] [G loss: 0.794626]\n",
      "epoch:46 step:36613 [D loss: 0.630682, acc.: 72.66%] [G loss: 0.855068]\n",
      "epoch:46 step:36614 [D loss: 0.652599, acc.: 63.28%] [G loss: 0.785421]\n",
      "epoch:46 step:36615 [D loss: 0.661618, acc.: 57.81%] [G loss: 0.806597]\n",
      "epoch:46 step:36616 [D loss: 0.642696, acc.: 61.72%] [G loss: 0.746323]\n",
      "epoch:46 step:36617 [D loss: 0.689598, acc.: 53.12%] [G loss: 0.865797]\n",
      "epoch:46 step:36618 [D loss: 0.709819, acc.: 51.56%] [G loss: 0.735491]\n",
      "epoch:46 step:36619 [D loss: 0.701188, acc.: 53.12%] [G loss: 0.806907]\n",
      "epoch:46 step:36620 [D loss: 0.658213, acc.: 62.50%] [G loss: 0.835742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36621 [D loss: 0.607080, acc.: 73.44%] [G loss: 0.890082]\n",
      "epoch:46 step:36622 [D loss: 0.703561, acc.: 50.00%] [G loss: 0.742396]\n",
      "epoch:46 step:36623 [D loss: 0.799215, acc.: 35.16%] [G loss: 0.695094]\n",
      "epoch:46 step:36624 [D loss: 0.624610, acc.: 64.84%] [G loss: 0.769061]\n",
      "epoch:46 step:36625 [D loss: 0.636316, acc.: 69.53%] [G loss: 0.717190]\n",
      "epoch:46 step:36626 [D loss: 0.657897, acc.: 53.91%] [G loss: 0.684293]\n",
      "epoch:46 step:36627 [D loss: 0.747393, acc.: 38.28%] [G loss: 0.709841]\n",
      "epoch:46 step:36628 [D loss: 0.702533, acc.: 53.12%] [G loss: 0.676667]\n",
      "epoch:46 step:36629 [D loss: 0.707963, acc.: 50.00%] [G loss: 0.772512]\n",
      "epoch:46 step:36630 [D loss: 0.667166, acc.: 64.84%] [G loss: 0.824403]\n",
      "epoch:46 step:36631 [D loss: 0.705742, acc.: 49.22%] [G loss: 0.804366]\n",
      "epoch:46 step:36632 [D loss: 0.665624, acc.: 63.28%] [G loss: 0.724223]\n",
      "epoch:46 step:36633 [D loss: 0.688532, acc.: 57.81%] [G loss: 0.832045]\n",
      "epoch:46 step:36634 [D loss: 0.781487, acc.: 34.38%] [G loss: 0.695111]\n",
      "epoch:46 step:36635 [D loss: 0.698374, acc.: 53.91%] [G loss: 0.786706]\n",
      "epoch:46 step:36636 [D loss: 0.614187, acc.: 69.53%] [G loss: 0.799197]\n",
      "epoch:46 step:36637 [D loss: 0.603874, acc.: 70.31%] [G loss: 0.846767]\n",
      "epoch:46 step:36638 [D loss: 0.652303, acc.: 60.16%] [G loss: 0.883883]\n",
      "epoch:46 step:36639 [D loss: 0.674411, acc.: 57.03%] [G loss: 0.886854]\n",
      "epoch:46 step:36640 [D loss: 0.707833, acc.: 43.75%] [G loss: 0.774526]\n",
      "epoch:46 step:36641 [D loss: 0.687790, acc.: 57.81%] [G loss: 0.806594]\n",
      "epoch:46 step:36642 [D loss: 0.645747, acc.: 61.72%] [G loss: 0.895969]\n",
      "epoch:46 step:36643 [D loss: 0.642623, acc.: 62.50%] [G loss: 0.945273]\n",
      "epoch:46 step:36644 [D loss: 0.695055, acc.: 50.78%] [G loss: 0.887483]\n",
      "epoch:46 step:36645 [D loss: 0.680019, acc.: 60.16%] [G loss: 0.819948]\n",
      "epoch:46 step:36646 [D loss: 0.687083, acc.: 58.59%] [G loss: 0.826943]\n",
      "epoch:46 step:36647 [D loss: 0.792531, acc.: 35.16%] [G loss: 0.721194]\n",
      "epoch:46 step:36648 [D loss: 0.716519, acc.: 48.44%] [G loss: 0.776206]\n",
      "epoch:46 step:36649 [D loss: 0.686077, acc.: 52.34%] [G loss: 0.829663]\n",
      "epoch:46 step:36650 [D loss: 0.687649, acc.: 57.03%] [G loss: 0.842935]\n",
      "epoch:46 step:36651 [D loss: 0.693649, acc.: 51.56%] [G loss: 0.764785]\n",
      "epoch:46 step:36652 [D loss: 0.655424, acc.: 58.59%] [G loss: 0.686166]\n",
      "epoch:46 step:36653 [D loss: 0.714890, acc.: 54.69%] [G loss: 0.831005]\n",
      "epoch:46 step:36654 [D loss: 0.642881, acc.: 65.62%] [G loss: 0.756671]\n",
      "epoch:46 step:36655 [D loss: 0.774369, acc.: 39.06%] [G loss: 0.736464]\n",
      "epoch:46 step:36656 [D loss: 0.679127, acc.: 62.50%] [G loss: 0.831714]\n",
      "epoch:46 step:36657 [D loss: 0.652707, acc.: 64.84%] [G loss: 0.873209]\n",
      "epoch:46 step:36658 [D loss: 0.675903, acc.: 55.47%] [G loss: 0.757168]\n",
      "epoch:46 step:36659 [D loss: 0.698118, acc.: 52.34%] [G loss: 0.796692]\n",
      "epoch:46 step:36660 [D loss: 0.732132, acc.: 39.06%] [G loss: 0.834086]\n",
      "epoch:46 step:36661 [D loss: 0.660758, acc.: 59.38%] [G loss: 0.723593]\n",
      "epoch:46 step:36662 [D loss: 0.629028, acc.: 71.09%] [G loss: 0.900987]\n",
      "epoch:46 step:36663 [D loss: 0.682171, acc.: 54.69%] [G loss: 0.845790]\n",
      "epoch:46 step:36664 [D loss: 0.688188, acc.: 57.81%] [G loss: 0.839253]\n",
      "epoch:46 step:36665 [D loss: 0.690973, acc.: 54.69%] [G loss: 0.844921]\n",
      "epoch:46 step:36666 [D loss: 0.641293, acc.: 64.84%] [G loss: 0.815122]\n",
      "epoch:46 step:36667 [D loss: 0.672235, acc.: 63.28%] [G loss: 0.655865]\n",
      "epoch:46 step:36668 [D loss: 0.661351, acc.: 60.16%] [G loss: 0.740473]\n",
      "epoch:46 step:36669 [D loss: 0.678396, acc.: 64.06%] [G loss: 0.863627]\n",
      "epoch:46 step:36670 [D loss: 0.655166, acc.: 60.16%] [G loss: 0.853332]\n",
      "epoch:46 step:36671 [D loss: 0.635839, acc.: 64.84%] [G loss: 0.898635]\n",
      "epoch:46 step:36672 [D loss: 0.647209, acc.: 61.72%] [G loss: 0.792775]\n",
      "epoch:46 step:36673 [D loss: 0.657466, acc.: 62.50%] [G loss: 0.788548]\n",
      "epoch:46 step:36674 [D loss: 0.735073, acc.: 46.09%] [G loss: 0.790232]\n",
      "epoch:46 step:36675 [D loss: 0.592307, acc.: 75.00%] [G loss: 0.846125]\n",
      "epoch:46 step:36676 [D loss: 0.741409, acc.: 40.62%] [G loss: 0.687361]\n",
      "epoch:46 step:36677 [D loss: 0.674075, acc.: 53.91%] [G loss: 0.801583]\n",
      "epoch:46 step:36678 [D loss: 0.641294, acc.: 65.62%] [G loss: 0.799075]\n",
      "epoch:46 step:36679 [D loss: 0.709759, acc.: 53.91%] [G loss: 0.754411]\n",
      "epoch:46 step:36680 [D loss: 0.718467, acc.: 51.56%] [G loss: 0.852522]\n",
      "epoch:46 step:36681 [D loss: 0.658613, acc.: 59.38%] [G loss: 0.884037]\n",
      "epoch:46 step:36682 [D loss: 0.653703, acc.: 62.50%] [G loss: 0.875501]\n",
      "epoch:46 step:36683 [D loss: 0.644749, acc.: 67.19%] [G loss: 0.949912]\n",
      "epoch:46 step:36684 [D loss: 0.710118, acc.: 51.56%] [G loss: 0.715210]\n",
      "epoch:46 step:36685 [D loss: 0.720890, acc.: 49.22%] [G loss: 0.794523]\n",
      "epoch:46 step:36686 [D loss: 0.650073, acc.: 64.06%] [G loss: 0.864353]\n",
      "epoch:46 step:36687 [D loss: 0.658480, acc.: 56.25%] [G loss: 0.849380]\n",
      "epoch:46 step:36688 [D loss: 0.698298, acc.: 52.34%] [G loss: 0.817372]\n",
      "epoch:46 step:36689 [D loss: 0.705671, acc.: 54.69%] [G loss: 0.823979]\n",
      "epoch:46 step:36690 [D loss: 0.721614, acc.: 46.09%] [G loss: 0.772555]\n",
      "epoch:46 step:36691 [D loss: 0.613924, acc.: 71.88%] [G loss: 0.826214]\n",
      "epoch:46 step:36692 [D loss: 0.692352, acc.: 53.12%] [G loss: 0.796620]\n",
      "epoch:46 step:36693 [D loss: 0.659625, acc.: 60.16%] [G loss: 0.785299]\n",
      "epoch:46 step:36694 [D loss: 0.662280, acc.: 57.03%] [G loss: 0.880785]\n",
      "epoch:46 step:36695 [D loss: 0.654354, acc.: 64.84%] [G loss: 0.833979]\n",
      "epoch:46 step:36696 [D loss: 0.680566, acc.: 54.69%] [G loss: 0.863385]\n",
      "epoch:46 step:36697 [D loss: 0.687027, acc.: 51.56%] [G loss: 0.771705]\n",
      "epoch:46 step:36698 [D loss: 0.665677, acc.: 64.84%] [G loss: 0.841106]\n",
      "epoch:46 step:36699 [D loss: 0.682027, acc.: 57.81%] [G loss: 0.817066]\n",
      "epoch:46 step:36700 [D loss: 0.672686, acc.: 62.50%] [G loss: 0.808725]\n",
      "epoch:46 step:36701 [D loss: 0.703564, acc.: 50.78%] [G loss: 0.820194]\n",
      "epoch:46 step:36702 [D loss: 0.718073, acc.: 49.22%] [G loss: 0.772279]\n",
      "epoch:46 step:36703 [D loss: 0.643012, acc.: 65.62%] [G loss: 0.910888]\n",
      "epoch:46 step:36704 [D loss: 0.674487, acc.: 57.81%] [G loss: 0.818634]\n",
      "epoch:46 step:36705 [D loss: 0.726792, acc.: 51.56%] [G loss: 0.793723]\n",
      "epoch:46 step:36706 [D loss: 0.698474, acc.: 48.44%] [G loss: 0.707148]\n",
      "epoch:46 step:36707 [D loss: 0.691275, acc.: 47.66%] [G loss: 0.777902]\n",
      "epoch:47 step:36708 [D loss: 0.578065, acc.: 78.91%] [G loss: 0.858834]\n",
      "epoch:47 step:36709 [D loss: 0.666481, acc.: 60.16%] [G loss: 0.888740]\n",
      "epoch:47 step:36710 [D loss: 0.664568, acc.: 61.72%] [G loss: 0.776736]\n",
      "epoch:47 step:36711 [D loss: 0.679578, acc.: 57.81%] [G loss: 0.767089]\n",
      "epoch:47 step:36712 [D loss: 0.746996, acc.: 43.75%] [G loss: 0.720110]\n",
      "epoch:47 step:36713 [D loss: 0.640543, acc.: 65.62%] [G loss: 0.722994]\n",
      "epoch:47 step:36714 [D loss: 0.679099, acc.: 57.81%] [G loss: 0.817225]\n",
      "epoch:47 step:36715 [D loss: 0.734297, acc.: 47.66%] [G loss: 0.851996]\n",
      "epoch:47 step:36716 [D loss: 0.694142, acc.: 53.91%] [G loss: 0.873554]\n",
      "epoch:47 step:36717 [D loss: 0.706466, acc.: 51.56%] [G loss: 0.820930]\n",
      "epoch:47 step:36718 [D loss: 0.680322, acc.: 57.81%] [G loss: 0.793981]\n",
      "epoch:47 step:36719 [D loss: 0.700032, acc.: 50.78%] [G loss: 0.782146]\n",
      "epoch:47 step:36720 [D loss: 0.692683, acc.: 53.91%] [G loss: 0.748195]\n",
      "epoch:47 step:36721 [D loss: 0.653642, acc.: 64.06%] [G loss: 0.950937]\n",
      "epoch:47 step:36722 [D loss: 0.732293, acc.: 42.19%] [G loss: 0.763891]\n",
      "epoch:47 step:36723 [D loss: 0.681680, acc.: 55.47%] [G loss: 0.811072]\n",
      "epoch:47 step:36724 [D loss: 0.724107, acc.: 46.88%] [G loss: 0.853816]\n",
      "epoch:47 step:36725 [D loss: 0.744835, acc.: 45.31%] [G loss: 0.771313]\n",
      "epoch:47 step:36726 [D loss: 0.677867, acc.: 57.03%] [G loss: 0.793588]\n",
      "epoch:47 step:36727 [D loss: 0.666305, acc.: 60.94%] [G loss: 0.815916]\n",
      "epoch:47 step:36728 [D loss: 0.672526, acc.: 61.72%] [G loss: 0.906309]\n",
      "epoch:47 step:36729 [D loss: 0.645466, acc.: 64.06%] [G loss: 0.899254]\n",
      "epoch:47 step:36730 [D loss: 0.676884, acc.: 64.06%] [G loss: 0.773344]\n",
      "epoch:47 step:36731 [D loss: 0.658954, acc.: 61.72%] [G loss: 0.784364]\n",
      "epoch:47 step:36732 [D loss: 0.693836, acc.: 56.25%] [G loss: 0.762212]\n",
      "epoch:47 step:36733 [D loss: 0.731365, acc.: 47.66%] [G loss: 0.818142]\n",
      "epoch:47 step:36734 [D loss: 0.661405, acc.: 65.62%] [G loss: 0.803589]\n",
      "epoch:47 step:36735 [D loss: 0.656705, acc.: 56.25%] [G loss: 0.715340]\n",
      "epoch:47 step:36736 [D loss: 0.666429, acc.: 60.16%] [G loss: 0.740390]\n",
      "epoch:47 step:36737 [D loss: 0.649541, acc.: 67.97%] [G loss: 0.785761]\n",
      "epoch:47 step:36738 [D loss: 0.634835, acc.: 71.88%] [G loss: 0.886038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36739 [D loss: 0.687470, acc.: 54.69%] [G loss: 0.842098]\n",
      "epoch:47 step:36740 [D loss: 0.690698, acc.: 50.78%] [G loss: 0.781256]\n",
      "epoch:47 step:36741 [D loss: 0.635392, acc.: 67.97%] [G loss: 0.837089]\n",
      "epoch:47 step:36742 [D loss: 0.708510, acc.: 51.56%] [G loss: 0.774062]\n",
      "epoch:47 step:36743 [D loss: 0.726235, acc.: 47.66%] [G loss: 0.791526]\n",
      "epoch:47 step:36744 [D loss: 0.655494, acc.: 60.16%] [G loss: 0.823629]\n",
      "epoch:47 step:36745 [D loss: 0.680038, acc.: 56.25%] [G loss: 0.776884]\n",
      "epoch:47 step:36746 [D loss: 0.671163, acc.: 54.69%] [G loss: 0.761528]\n",
      "epoch:47 step:36747 [D loss: 0.700294, acc.: 53.12%] [G loss: 0.773313]\n",
      "epoch:47 step:36748 [D loss: 0.658886, acc.: 60.94%] [G loss: 0.817394]\n",
      "epoch:47 step:36749 [D loss: 0.680192, acc.: 59.38%] [G loss: 0.778777]\n",
      "epoch:47 step:36750 [D loss: 0.682373, acc.: 61.72%] [G loss: 0.798494]\n",
      "epoch:47 step:36751 [D loss: 0.679627, acc.: 61.72%] [G loss: 0.790013]\n",
      "epoch:47 step:36752 [D loss: 0.682979, acc.: 55.47%] [G loss: 0.878232]\n",
      "epoch:47 step:36753 [D loss: 0.697769, acc.: 50.78%] [G loss: 0.805250]\n",
      "epoch:47 step:36754 [D loss: 0.719618, acc.: 53.12%] [G loss: 0.700806]\n",
      "epoch:47 step:36755 [D loss: 0.655019, acc.: 58.59%] [G loss: 0.676412]\n",
      "epoch:47 step:36756 [D loss: 0.676689, acc.: 55.47%] [G loss: 0.700131]\n",
      "epoch:47 step:36757 [D loss: 0.642172, acc.: 60.94%] [G loss: 0.714406]\n",
      "epoch:47 step:36758 [D loss: 0.626895, acc.: 71.09%] [G loss: 0.768928]\n",
      "epoch:47 step:36759 [D loss: 0.623953, acc.: 67.19%] [G loss: 0.866185]\n",
      "epoch:47 step:36760 [D loss: 0.680152, acc.: 54.69%] [G loss: 0.826948]\n",
      "epoch:47 step:36761 [D loss: 0.710006, acc.: 46.88%] [G loss: 0.712595]\n",
      "epoch:47 step:36762 [D loss: 0.674695, acc.: 59.38%] [G loss: 0.739026]\n",
      "epoch:47 step:36763 [D loss: 0.682894, acc.: 60.94%] [G loss: 0.801403]\n",
      "epoch:47 step:36764 [D loss: 0.711467, acc.: 47.66%] [G loss: 0.812225]\n",
      "epoch:47 step:36765 [D loss: 0.699152, acc.: 56.25%] [G loss: 0.771491]\n",
      "epoch:47 step:36766 [D loss: 0.645603, acc.: 62.50%] [G loss: 0.848134]\n",
      "epoch:47 step:36767 [D loss: 0.692395, acc.: 52.34%] [G loss: 0.815212]\n",
      "epoch:47 step:36768 [D loss: 0.669417, acc.: 57.03%] [G loss: 0.870234]\n",
      "epoch:47 step:36769 [D loss: 0.612509, acc.: 71.09%] [G loss: 0.869955]\n",
      "epoch:47 step:36770 [D loss: 0.691874, acc.: 53.91%] [G loss: 0.806463]\n",
      "epoch:47 step:36771 [D loss: 0.733138, acc.: 45.31%] [G loss: 0.819724]\n",
      "epoch:47 step:36772 [D loss: 0.698594, acc.: 51.56%] [G loss: 0.795642]\n",
      "epoch:47 step:36773 [D loss: 0.697833, acc.: 51.56%] [G loss: 0.771713]\n",
      "epoch:47 step:36774 [D loss: 0.634233, acc.: 70.31%] [G loss: 0.809116]\n",
      "epoch:47 step:36775 [D loss: 0.680628, acc.: 55.47%] [G loss: 0.911888]\n",
      "epoch:47 step:36776 [D loss: 0.679033, acc.: 57.03%] [G loss: 0.836725]\n",
      "epoch:47 step:36777 [D loss: 0.689126, acc.: 54.69%] [G loss: 0.750679]\n",
      "epoch:47 step:36778 [D loss: 0.723456, acc.: 51.56%] [G loss: 0.724019]\n",
      "epoch:47 step:36779 [D loss: 0.734834, acc.: 47.66%] [G loss: 0.641505]\n",
      "epoch:47 step:36780 [D loss: 0.674217, acc.: 60.94%] [G loss: 0.742440]\n",
      "epoch:47 step:36781 [D loss: 0.661677, acc.: 64.06%] [G loss: 0.782341]\n",
      "epoch:47 step:36782 [D loss: 0.704318, acc.: 48.44%] [G loss: 0.745984]\n",
      "epoch:47 step:36783 [D loss: 0.612206, acc.: 71.09%] [G loss: 0.785116]\n",
      "epoch:47 step:36784 [D loss: 0.659653, acc.: 59.38%] [G loss: 0.823682]\n",
      "epoch:47 step:36785 [D loss: 0.684322, acc.: 49.22%] [G loss: 0.810595]\n",
      "epoch:47 step:36786 [D loss: 0.608935, acc.: 76.56%] [G loss: 0.826609]\n",
      "epoch:47 step:36787 [D loss: 0.689072, acc.: 55.47%] [G loss: 0.750774]\n",
      "epoch:47 step:36788 [D loss: 0.709540, acc.: 46.09%] [G loss: 0.825198]\n",
      "epoch:47 step:36789 [D loss: 0.674405, acc.: 61.72%] [G loss: 0.781058]\n",
      "epoch:47 step:36790 [D loss: 0.697246, acc.: 52.34%] [G loss: 0.825031]\n",
      "epoch:47 step:36791 [D loss: 0.730839, acc.: 46.88%] [G loss: 0.808984]\n",
      "epoch:47 step:36792 [D loss: 0.679632, acc.: 53.91%] [G loss: 0.815747]\n",
      "epoch:47 step:36793 [D loss: 0.666404, acc.: 57.81%] [G loss: 0.731071]\n",
      "epoch:47 step:36794 [D loss: 0.709215, acc.: 56.25%] [G loss: 0.820227]\n",
      "epoch:47 step:36795 [D loss: 0.702428, acc.: 49.22%] [G loss: 0.810809]\n",
      "epoch:47 step:36796 [D loss: 0.747654, acc.: 45.31%] [G loss: 0.743903]\n",
      "epoch:47 step:36797 [D loss: 0.654345, acc.: 60.94%] [G loss: 0.793021]\n",
      "epoch:47 step:36798 [D loss: 0.711075, acc.: 51.56%] [G loss: 0.724484]\n",
      "epoch:47 step:36799 [D loss: 0.682270, acc.: 51.56%] [G loss: 0.808410]\n",
      "epoch:47 step:36800 [D loss: 0.760973, acc.: 40.62%] [G loss: 0.798362]\n",
      "epoch:47 step:36801 [D loss: 0.697987, acc.: 56.25%] [G loss: 0.837206]\n",
      "epoch:47 step:36802 [D loss: 0.663206, acc.: 64.84%] [G loss: 0.867368]\n",
      "epoch:47 step:36803 [D loss: 0.703721, acc.: 50.00%] [G loss: 0.788496]\n",
      "epoch:47 step:36804 [D loss: 0.642328, acc.: 66.41%] [G loss: 0.879322]\n",
      "epoch:47 step:36805 [D loss: 0.711370, acc.: 53.91%] [G loss: 0.897600]\n",
      "epoch:47 step:36806 [D loss: 0.677014, acc.: 57.03%] [G loss: 0.745206]\n",
      "epoch:47 step:36807 [D loss: 0.699177, acc.: 59.38%] [G loss: 0.926861]\n",
      "epoch:47 step:36808 [D loss: 0.676004, acc.: 53.91%] [G loss: 0.830897]\n",
      "epoch:47 step:36809 [D loss: 0.686511, acc.: 52.34%] [G loss: 0.767705]\n",
      "epoch:47 step:36810 [D loss: 0.610519, acc.: 66.41%] [G loss: 0.897083]\n",
      "epoch:47 step:36811 [D loss: 0.676532, acc.: 64.06%] [G loss: 0.897594]\n",
      "epoch:47 step:36812 [D loss: 0.661600, acc.: 60.94%] [G loss: 0.774452]\n",
      "epoch:47 step:36813 [D loss: 0.647804, acc.: 61.72%] [G loss: 0.777689]\n",
      "epoch:47 step:36814 [D loss: 0.686146, acc.: 56.25%] [G loss: 0.710542]\n",
      "epoch:47 step:36815 [D loss: 0.747876, acc.: 44.53%] [G loss: 0.745860]\n",
      "epoch:47 step:36816 [D loss: 0.625030, acc.: 66.41%] [G loss: 0.724587]\n",
      "epoch:47 step:36817 [D loss: 0.658327, acc.: 60.16%] [G loss: 0.739102]\n",
      "epoch:47 step:36818 [D loss: 0.704044, acc.: 53.12%] [G loss: 0.843632]\n",
      "epoch:47 step:36819 [D loss: 0.647187, acc.: 66.41%] [G loss: 0.829369]\n",
      "epoch:47 step:36820 [D loss: 0.663977, acc.: 58.59%] [G loss: 0.824840]\n",
      "epoch:47 step:36821 [D loss: 0.616881, acc.: 70.31%] [G loss: 0.778458]\n",
      "epoch:47 step:36822 [D loss: 0.717700, acc.: 48.44%] [G loss: 0.774119]\n",
      "epoch:47 step:36823 [D loss: 0.716291, acc.: 47.66%] [G loss: 0.808722]\n",
      "epoch:47 step:36824 [D loss: 0.688659, acc.: 60.16%] [G loss: 0.842648]\n",
      "epoch:47 step:36825 [D loss: 0.689001, acc.: 53.12%] [G loss: 0.762696]\n",
      "epoch:47 step:36826 [D loss: 0.646268, acc.: 62.50%] [G loss: 0.724379]\n",
      "epoch:47 step:36827 [D loss: 0.710868, acc.: 50.00%] [G loss: 0.780070]\n",
      "epoch:47 step:36828 [D loss: 0.692927, acc.: 50.78%] [G loss: 0.880281]\n",
      "epoch:47 step:36829 [D loss: 0.685200, acc.: 54.69%] [G loss: 0.810073]\n",
      "epoch:47 step:36830 [D loss: 0.684949, acc.: 53.12%] [G loss: 0.785974]\n",
      "epoch:47 step:36831 [D loss: 0.658591, acc.: 57.81%] [G loss: 0.753496]\n",
      "epoch:47 step:36832 [D loss: 0.675201, acc.: 56.25%] [G loss: 0.823479]\n",
      "epoch:47 step:36833 [D loss: 0.755131, acc.: 41.41%] [G loss: 0.729229]\n",
      "epoch:47 step:36834 [D loss: 0.629664, acc.: 65.62%] [G loss: 0.840926]\n",
      "epoch:47 step:36835 [D loss: 0.682979, acc.: 60.16%] [G loss: 0.789199]\n",
      "epoch:47 step:36836 [D loss: 0.714146, acc.: 45.31%] [G loss: 0.752710]\n",
      "epoch:47 step:36837 [D loss: 0.700008, acc.: 53.12%] [G loss: 0.735905]\n",
      "epoch:47 step:36838 [D loss: 0.668210, acc.: 60.16%] [G loss: 0.819317]\n",
      "epoch:47 step:36839 [D loss: 0.640789, acc.: 65.62%] [G loss: 0.805142]\n",
      "epoch:47 step:36840 [D loss: 0.640476, acc.: 64.06%] [G loss: 0.866245]\n",
      "epoch:47 step:36841 [D loss: 0.654951, acc.: 57.81%] [G loss: 0.867746]\n",
      "epoch:47 step:36842 [D loss: 0.677120, acc.: 57.03%] [G loss: 0.860922]\n",
      "epoch:47 step:36843 [D loss: 0.749828, acc.: 42.97%] [G loss: 0.712192]\n",
      "epoch:47 step:36844 [D loss: 0.704798, acc.: 55.47%] [G loss: 0.799069]\n",
      "epoch:47 step:36845 [D loss: 0.745969, acc.: 40.62%] [G loss: 0.743254]\n",
      "epoch:47 step:36846 [D loss: 0.727941, acc.: 50.78%] [G loss: 0.741811]\n",
      "epoch:47 step:36847 [D loss: 0.710729, acc.: 50.78%] [G loss: 0.768845]\n",
      "epoch:47 step:36848 [D loss: 0.690187, acc.: 55.47%] [G loss: 0.756133]\n",
      "epoch:47 step:36849 [D loss: 0.691450, acc.: 60.94%] [G loss: 0.721719]\n",
      "epoch:47 step:36850 [D loss: 0.633765, acc.: 67.19%] [G loss: 0.779554]\n",
      "epoch:47 step:36851 [D loss: 0.643068, acc.: 60.94%] [G loss: 0.787627]\n",
      "epoch:47 step:36852 [D loss: 0.704258, acc.: 52.34%] [G loss: 0.770169]\n",
      "epoch:47 step:36853 [D loss: 0.648985, acc.: 64.06%] [G loss: 0.811984]\n",
      "epoch:47 step:36854 [D loss: 0.691951, acc.: 53.12%] [G loss: 0.772749]\n",
      "epoch:47 step:36855 [D loss: 0.684344, acc.: 60.16%] [G loss: 0.785326]\n",
      "epoch:47 step:36856 [D loss: 0.588240, acc.: 75.00%] [G loss: 0.800721]\n",
      "epoch:47 step:36857 [D loss: 0.721575, acc.: 48.44%] [G loss: 0.679021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36858 [D loss: 0.667821, acc.: 65.62%] [G loss: 0.756038]\n",
      "epoch:47 step:36859 [D loss: 0.701832, acc.: 50.00%] [G loss: 0.827094]\n",
      "epoch:47 step:36860 [D loss: 0.679998, acc.: 57.81%] [G loss: 0.773435]\n",
      "epoch:47 step:36861 [D loss: 0.664563, acc.: 62.50%] [G loss: 0.765039]\n",
      "epoch:47 step:36862 [D loss: 0.707109, acc.: 52.34%] [G loss: 0.875042]\n",
      "epoch:47 step:36863 [D loss: 0.696125, acc.: 54.69%] [G loss: 0.908975]\n",
      "epoch:47 step:36864 [D loss: 0.708197, acc.: 46.88%] [G loss: 0.815110]\n",
      "epoch:47 step:36865 [D loss: 0.606864, acc.: 69.53%] [G loss: 0.887074]\n",
      "epoch:47 step:36866 [D loss: 0.687611, acc.: 57.03%] [G loss: 0.778827]\n",
      "epoch:47 step:36867 [D loss: 0.670200, acc.: 61.72%] [G loss: 0.827876]\n",
      "epoch:47 step:36868 [D loss: 0.637624, acc.: 61.72%] [G loss: 0.799115]\n",
      "epoch:47 step:36869 [D loss: 0.723039, acc.: 45.31%] [G loss: 0.757648]\n",
      "epoch:47 step:36870 [D loss: 0.642074, acc.: 66.41%] [G loss: 0.729459]\n",
      "epoch:47 step:36871 [D loss: 0.715186, acc.: 48.44%] [G loss: 0.800832]\n",
      "epoch:47 step:36872 [D loss: 0.662649, acc.: 59.38%] [G loss: 0.840235]\n",
      "epoch:47 step:36873 [D loss: 0.656683, acc.: 60.94%] [G loss: 0.790046]\n",
      "epoch:47 step:36874 [D loss: 0.648244, acc.: 61.72%] [G loss: 0.866552]\n",
      "epoch:47 step:36875 [D loss: 0.653034, acc.: 64.06%] [G loss: 0.876395]\n",
      "epoch:47 step:36876 [D loss: 0.642635, acc.: 60.94%] [G loss: 0.888242]\n",
      "epoch:47 step:36877 [D loss: 0.673636, acc.: 62.50%] [G loss: 0.806495]\n",
      "epoch:47 step:36878 [D loss: 0.630269, acc.: 64.06%] [G loss: 0.973861]\n",
      "epoch:47 step:36879 [D loss: 0.702016, acc.: 53.91%] [G loss: 0.786911]\n",
      "epoch:47 step:36880 [D loss: 0.645758, acc.: 64.06%] [G loss: 0.833378]\n",
      "epoch:47 step:36881 [D loss: 0.635753, acc.: 64.06%] [G loss: 0.802930]\n",
      "epoch:47 step:36882 [D loss: 0.642088, acc.: 65.62%] [G loss: 0.879827]\n",
      "epoch:47 step:36883 [D loss: 0.637950, acc.: 67.19%] [G loss: 0.807202]\n",
      "epoch:47 step:36884 [D loss: 0.697705, acc.: 54.69%] [G loss: 0.801274]\n",
      "epoch:47 step:36885 [D loss: 0.658305, acc.: 64.84%] [G loss: 0.839114]\n",
      "epoch:47 step:36886 [D loss: 0.606806, acc.: 70.31%] [G loss: 0.811256]\n",
      "epoch:47 step:36887 [D loss: 0.672997, acc.: 57.81%] [G loss: 0.726238]\n",
      "epoch:47 step:36888 [D loss: 0.606464, acc.: 74.22%] [G loss: 0.776586]\n",
      "epoch:47 step:36889 [D loss: 0.731178, acc.: 41.41%] [G loss: 0.792227]\n",
      "epoch:47 step:36890 [D loss: 0.700576, acc.: 49.22%] [G loss: 0.742436]\n",
      "epoch:47 step:36891 [D loss: 0.740906, acc.: 46.09%] [G loss: 0.753271]\n",
      "epoch:47 step:36892 [D loss: 0.649455, acc.: 67.97%] [G loss: 0.692899]\n",
      "epoch:47 step:36893 [D loss: 0.696975, acc.: 53.91%] [G loss: 0.802754]\n",
      "epoch:47 step:36894 [D loss: 0.660362, acc.: 60.94%] [G loss: 0.861154]\n",
      "epoch:47 step:36895 [D loss: 0.672681, acc.: 56.25%] [G loss: 0.742469]\n",
      "epoch:47 step:36896 [D loss: 0.628774, acc.: 67.19%] [G loss: 0.782402]\n",
      "epoch:47 step:36897 [D loss: 0.767507, acc.: 36.72%] [G loss: 0.791069]\n",
      "epoch:47 step:36898 [D loss: 0.728240, acc.: 50.78%] [G loss: 0.891113]\n",
      "epoch:47 step:36899 [D loss: 0.669664, acc.: 57.81%] [G loss: 0.832014]\n",
      "epoch:47 step:36900 [D loss: 0.696775, acc.: 54.69%] [G loss: 0.926204]\n",
      "epoch:47 step:36901 [D loss: 0.661288, acc.: 59.38%] [G loss: 0.810140]\n",
      "epoch:47 step:36902 [D loss: 0.658712, acc.: 64.06%] [G loss: 0.895830]\n",
      "epoch:47 step:36903 [D loss: 0.647523, acc.: 64.84%] [G loss: 0.841130]\n",
      "epoch:47 step:36904 [D loss: 0.672903, acc.: 56.25%] [G loss: 0.886504]\n",
      "epoch:47 step:36905 [D loss: 0.701178, acc.: 53.91%] [G loss: 0.850710]\n",
      "epoch:47 step:36906 [D loss: 0.660110, acc.: 59.38%] [G loss: 0.787313]\n",
      "epoch:47 step:36907 [D loss: 0.624649, acc.: 67.97%] [G loss: 0.786613]\n",
      "epoch:47 step:36908 [D loss: 0.683731, acc.: 53.91%] [G loss: 0.687157]\n",
      "epoch:47 step:36909 [D loss: 0.662334, acc.: 58.59%] [G loss: 0.765082]\n",
      "epoch:47 step:36910 [D loss: 0.691909, acc.: 60.94%] [G loss: 0.719899]\n",
      "epoch:47 step:36911 [D loss: 0.775261, acc.: 38.28%] [G loss: 0.690279]\n",
      "epoch:47 step:36912 [D loss: 0.737094, acc.: 42.19%] [G loss: 0.696016]\n",
      "epoch:47 step:36913 [D loss: 0.613136, acc.: 66.41%] [G loss: 0.842135]\n",
      "epoch:47 step:36914 [D loss: 0.542423, acc.: 84.38%] [G loss: 0.797885]\n",
      "epoch:47 step:36915 [D loss: 0.654793, acc.: 62.50%] [G loss: 0.801599]\n",
      "epoch:47 step:36916 [D loss: 0.720120, acc.: 50.78%] [G loss: 0.799965]\n",
      "epoch:47 step:36917 [D loss: 0.600679, acc.: 74.22%] [G loss: 0.885823]\n",
      "epoch:47 step:36918 [D loss: 0.646528, acc.: 60.94%] [G loss: 0.815415]\n",
      "epoch:47 step:36919 [D loss: 0.665561, acc.: 63.28%] [G loss: 0.818919]\n",
      "epoch:47 step:36920 [D loss: 0.735753, acc.: 40.62%] [G loss: 0.750454]\n",
      "epoch:47 step:36921 [D loss: 0.663270, acc.: 59.38%] [G loss: 0.735325]\n",
      "epoch:47 step:36922 [D loss: 0.703567, acc.: 53.91%] [G loss: 0.733705]\n",
      "epoch:47 step:36923 [D loss: 0.749854, acc.: 43.75%] [G loss: 0.753427]\n",
      "epoch:47 step:36924 [D loss: 0.651517, acc.: 61.72%] [G loss: 0.705668]\n",
      "epoch:47 step:36925 [D loss: 0.683838, acc.: 54.69%] [G loss: 0.763451]\n",
      "epoch:47 step:36926 [D loss: 0.685069, acc.: 51.56%] [G loss: 0.758759]\n",
      "epoch:47 step:36927 [D loss: 0.651431, acc.: 60.94%] [G loss: 0.839079]\n",
      "epoch:47 step:36928 [D loss: 0.731489, acc.: 45.31%] [G loss: 0.804036]\n",
      "epoch:47 step:36929 [D loss: 0.646321, acc.: 67.97%] [G loss: 0.816286]\n",
      "epoch:47 step:36930 [D loss: 0.683187, acc.: 53.12%] [G loss: 0.782766]\n",
      "epoch:47 step:36931 [D loss: 0.689947, acc.: 56.25%] [G loss: 0.785874]\n",
      "epoch:47 step:36932 [D loss: 0.679630, acc.: 57.03%] [G loss: 0.782127]\n",
      "epoch:47 step:36933 [D loss: 0.659106, acc.: 63.28%] [G loss: 0.870350]\n",
      "epoch:47 step:36934 [D loss: 0.667685, acc.: 62.50%] [G loss: 0.809260]\n",
      "epoch:47 step:36935 [D loss: 0.648774, acc.: 65.62%] [G loss: 0.719969]\n",
      "epoch:47 step:36936 [D loss: 0.621771, acc.: 68.75%] [G loss: 0.755196]\n",
      "epoch:47 step:36937 [D loss: 0.633930, acc.: 69.53%] [G loss: 0.773793]\n",
      "epoch:47 step:36938 [D loss: 0.635029, acc.: 62.50%] [G loss: 0.834534]\n",
      "epoch:47 step:36939 [D loss: 0.695032, acc.: 57.03%] [G loss: 0.807376]\n",
      "epoch:47 step:36940 [D loss: 0.639350, acc.: 67.97%] [G loss: 0.786129]\n",
      "epoch:47 step:36941 [D loss: 0.711122, acc.: 47.66%] [G loss: 0.747794]\n",
      "epoch:47 step:36942 [D loss: 0.650753, acc.: 58.59%] [G loss: 0.731346]\n",
      "epoch:47 step:36943 [D loss: 0.700458, acc.: 51.56%] [G loss: 0.770058]\n",
      "epoch:47 step:36944 [D loss: 0.600858, acc.: 68.75%] [G loss: 0.912250]\n",
      "epoch:47 step:36945 [D loss: 0.666278, acc.: 58.59%] [G loss: 0.813872]\n",
      "epoch:47 step:36946 [D loss: 0.606509, acc.: 72.66%] [G loss: 0.822117]\n",
      "epoch:47 step:36947 [D loss: 0.699739, acc.: 49.22%] [G loss: 0.788037]\n",
      "epoch:47 step:36948 [D loss: 0.719136, acc.: 45.31%] [G loss: 0.821680]\n",
      "epoch:47 step:36949 [D loss: 0.694879, acc.: 57.81%] [G loss: 0.773875]\n",
      "epoch:47 step:36950 [D loss: 0.642069, acc.: 62.50%] [G loss: 0.852078]\n",
      "epoch:47 step:36951 [D loss: 0.645965, acc.: 67.97%] [G loss: 0.733743]\n",
      "epoch:47 step:36952 [D loss: 0.738880, acc.: 46.09%] [G loss: 0.773444]\n",
      "epoch:47 step:36953 [D loss: 0.704920, acc.: 47.66%] [G loss: 0.724449]\n",
      "epoch:47 step:36954 [D loss: 0.791305, acc.: 35.94%] [G loss: 0.702431]\n",
      "epoch:47 step:36955 [D loss: 0.728478, acc.: 46.09%] [G loss: 0.795535]\n",
      "epoch:47 step:36956 [D loss: 0.737112, acc.: 49.22%] [G loss: 0.768667]\n",
      "epoch:47 step:36957 [D loss: 0.623759, acc.: 70.31%] [G loss: 0.847552]\n",
      "epoch:47 step:36958 [D loss: 0.746719, acc.: 43.75%] [G loss: 0.856592]\n",
      "epoch:47 step:36959 [D loss: 0.685779, acc.: 55.47%] [G loss: 0.851811]\n",
      "epoch:47 step:36960 [D loss: 0.742201, acc.: 45.31%] [G loss: 0.842483]\n",
      "epoch:47 step:36961 [D loss: 0.688450, acc.: 56.25%] [G loss: 0.888416]\n",
      "epoch:47 step:36962 [D loss: 0.642912, acc.: 64.06%] [G loss: 0.823613]\n",
      "epoch:47 step:36963 [D loss: 0.653651, acc.: 64.84%] [G loss: 0.843622]\n",
      "epoch:47 step:36964 [D loss: 0.652130, acc.: 62.50%] [G loss: 0.830820]\n",
      "epoch:47 step:36965 [D loss: 0.685799, acc.: 53.12%] [G loss: 0.808188]\n",
      "epoch:47 step:36966 [D loss: 0.657679, acc.: 60.16%] [G loss: 0.785733]\n",
      "epoch:47 step:36967 [D loss: 0.683225, acc.: 57.03%] [G loss: 0.775861]\n",
      "epoch:47 step:36968 [D loss: 0.701407, acc.: 50.00%] [G loss: 0.866689]\n",
      "epoch:47 step:36969 [D loss: 0.646143, acc.: 60.94%] [G loss: 0.915678]\n",
      "epoch:47 step:36970 [D loss: 0.616191, acc.: 70.31%] [G loss: 0.892779]\n",
      "epoch:47 step:36971 [D loss: 0.701752, acc.: 53.91%] [G loss: 0.791813]\n",
      "epoch:47 step:36972 [D loss: 0.676502, acc.: 56.25%] [G loss: 0.882023]\n",
      "epoch:47 step:36973 [D loss: 0.658731, acc.: 59.38%] [G loss: 0.784542]\n",
      "epoch:47 step:36974 [D loss: 0.706183, acc.: 54.69%] [G loss: 0.827372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36975 [D loss: 0.739064, acc.: 42.97%] [G loss: 0.852819]\n",
      "epoch:47 step:36976 [D loss: 0.627276, acc.: 67.97%] [G loss: 0.852817]\n",
      "epoch:47 step:36977 [D loss: 0.727090, acc.: 46.09%] [G loss: 0.794894]\n",
      "epoch:47 step:36978 [D loss: 0.688678, acc.: 55.47%] [G loss: 0.845097]\n",
      "epoch:47 step:36979 [D loss: 0.625861, acc.: 66.41%] [G loss: 0.836785]\n",
      "epoch:47 step:36980 [D loss: 0.694668, acc.: 60.16%] [G loss: 0.769953]\n",
      "epoch:47 step:36981 [D loss: 0.654763, acc.: 56.25%] [G loss: 0.767667]\n",
      "epoch:47 step:36982 [D loss: 0.665930, acc.: 64.06%] [G loss: 0.815723]\n",
      "epoch:47 step:36983 [D loss: 0.725806, acc.: 49.22%] [G loss: 0.743384]\n",
      "epoch:47 step:36984 [D loss: 0.715693, acc.: 47.66%] [G loss: 0.742479]\n",
      "epoch:47 step:36985 [D loss: 0.728281, acc.: 46.09%] [G loss: 0.634607]\n",
      "epoch:47 step:36986 [D loss: 0.658934, acc.: 56.25%] [G loss: 0.782540]\n",
      "epoch:47 step:36987 [D loss: 0.755415, acc.: 45.31%] [G loss: 0.735493]\n",
      "epoch:47 step:36988 [D loss: 0.728063, acc.: 48.44%] [G loss: 0.758932]\n",
      "epoch:47 step:36989 [D loss: 0.668043, acc.: 58.59%] [G loss: 0.798018]\n",
      "epoch:47 step:36990 [D loss: 0.654965, acc.: 61.72%] [G loss: 0.746002]\n",
      "epoch:47 step:36991 [D loss: 0.734196, acc.: 47.66%] [G loss: 0.764459]\n",
      "epoch:47 step:36992 [D loss: 0.642779, acc.: 64.06%] [G loss: 0.757278]\n",
      "epoch:47 step:36993 [D loss: 0.687430, acc.: 57.03%] [G loss: 0.839758]\n",
      "epoch:47 step:36994 [D loss: 0.718411, acc.: 47.66%] [G loss: 0.794451]\n",
      "epoch:47 step:36995 [D loss: 0.669503, acc.: 57.81%] [G loss: 0.880431]\n",
      "epoch:47 step:36996 [D loss: 0.706846, acc.: 57.03%] [G loss: 0.862615]\n",
      "epoch:47 step:36997 [D loss: 0.742789, acc.: 46.09%] [G loss: 0.742738]\n",
      "epoch:47 step:36998 [D loss: 0.709779, acc.: 50.00%] [G loss: 0.816176]\n",
      "epoch:47 step:36999 [D loss: 0.744321, acc.: 42.97%] [G loss: 0.731863]\n",
      "epoch:47 step:37000 [D loss: 0.676979, acc.: 62.50%] [G loss: 0.827292]\n",
      "epoch:47 step:37001 [D loss: 0.655058, acc.: 63.28%] [G loss: 0.858434]\n",
      "epoch:47 step:37002 [D loss: 0.683389, acc.: 52.34%] [G loss: 0.915410]\n",
      "epoch:47 step:37003 [D loss: 0.688706, acc.: 56.25%] [G loss: 0.825757]\n",
      "epoch:47 step:37004 [D loss: 0.733843, acc.: 45.31%] [G loss: 0.793608]\n",
      "epoch:47 step:37005 [D loss: 0.688883, acc.: 59.38%] [G loss: 0.769212]\n",
      "epoch:47 step:37006 [D loss: 0.650291, acc.: 60.16%] [G loss: 0.801856]\n",
      "epoch:47 step:37007 [D loss: 0.670876, acc.: 55.47%] [G loss: 0.878728]\n",
      "epoch:47 step:37008 [D loss: 0.701238, acc.: 50.78%] [G loss: 0.821139]\n",
      "epoch:47 step:37009 [D loss: 0.677711, acc.: 56.25%] [G loss: 0.730190]\n",
      "epoch:47 step:37010 [D loss: 0.651190, acc.: 59.38%] [G loss: 0.780251]\n",
      "epoch:47 step:37011 [D loss: 0.675898, acc.: 52.34%] [G loss: 0.791694]\n",
      "epoch:47 step:37012 [D loss: 0.641791, acc.: 65.62%] [G loss: 0.810274]\n",
      "epoch:47 step:37013 [D loss: 0.647126, acc.: 57.03%] [G loss: 0.790675]\n",
      "epoch:47 step:37014 [D loss: 0.574320, acc.: 74.22%] [G loss: 0.733591]\n",
      "epoch:47 step:37015 [D loss: 0.652479, acc.: 67.19%] [G loss: 0.840669]\n",
      "epoch:47 step:37016 [D loss: 0.642927, acc.: 68.75%] [G loss: 0.776143]\n",
      "epoch:47 step:37017 [D loss: 0.717688, acc.: 50.78%] [G loss: 0.773794]\n",
      "epoch:47 step:37018 [D loss: 0.647604, acc.: 65.62%] [G loss: 0.789573]\n",
      "epoch:47 step:37019 [D loss: 0.685092, acc.: 53.12%] [G loss: 0.960201]\n",
      "epoch:47 step:37020 [D loss: 0.753518, acc.: 42.19%] [G loss: 0.749250]\n",
      "epoch:47 step:37021 [D loss: 0.667212, acc.: 54.69%] [G loss: 0.819843]\n",
      "epoch:47 step:37022 [D loss: 0.752762, acc.: 42.19%] [G loss: 0.696925]\n",
      "epoch:47 step:37023 [D loss: 0.615637, acc.: 75.00%] [G loss: 0.746076]\n",
      "epoch:47 step:37024 [D loss: 0.692740, acc.: 46.88%] [G loss: 0.753830]\n",
      "epoch:47 step:37025 [D loss: 0.689586, acc.: 56.25%] [G loss: 0.716199]\n",
      "epoch:47 step:37026 [D loss: 0.644256, acc.: 63.28%] [G loss: 0.800470]\n",
      "epoch:47 step:37027 [D loss: 0.676871, acc.: 60.94%] [G loss: 0.862243]\n",
      "epoch:47 step:37028 [D loss: 0.626176, acc.: 67.97%] [G loss: 0.835082]\n",
      "epoch:47 step:37029 [D loss: 0.689363, acc.: 57.81%] [G loss: 0.749322]\n",
      "epoch:47 step:37030 [D loss: 0.700562, acc.: 51.56%] [G loss: 0.715390]\n",
      "epoch:47 step:37031 [D loss: 0.689161, acc.: 54.69%] [G loss: 0.800851]\n",
      "epoch:47 step:37032 [D loss: 0.652573, acc.: 60.16%] [G loss: 0.843652]\n",
      "epoch:47 step:37033 [D loss: 0.639117, acc.: 68.75%] [G loss: 0.857203]\n",
      "epoch:47 step:37034 [D loss: 0.693345, acc.: 51.56%] [G loss: 0.828805]\n",
      "epoch:47 step:37035 [D loss: 0.679682, acc.: 54.69%] [G loss: 0.827743]\n",
      "epoch:47 step:37036 [D loss: 0.615607, acc.: 71.88%] [G loss: 0.784993]\n",
      "epoch:47 step:37037 [D loss: 0.679339, acc.: 57.03%] [G loss: 0.703115]\n",
      "epoch:47 step:37038 [D loss: 0.739697, acc.: 47.66%] [G loss: 0.805887]\n",
      "epoch:47 step:37039 [D loss: 0.652686, acc.: 58.59%] [G loss: 0.744731]\n",
      "epoch:47 step:37040 [D loss: 0.641461, acc.: 63.28%] [G loss: 0.782432]\n",
      "epoch:47 step:37041 [D loss: 0.693146, acc.: 55.47%] [G loss: 0.813798]\n",
      "epoch:47 step:37042 [D loss: 0.665707, acc.: 60.16%] [G loss: 0.815860]\n",
      "epoch:47 step:37043 [D loss: 0.657879, acc.: 60.94%] [G loss: 0.865287]\n",
      "epoch:47 step:37044 [D loss: 0.744437, acc.: 45.31%] [G loss: 0.843965]\n",
      "epoch:47 step:37045 [D loss: 0.684771, acc.: 51.56%] [G loss: 0.811647]\n",
      "epoch:47 step:37046 [D loss: 0.683919, acc.: 57.03%] [G loss: 0.778986]\n",
      "epoch:47 step:37047 [D loss: 0.698713, acc.: 54.69%] [G loss: 0.825173]\n",
      "epoch:47 step:37048 [D loss: 0.674865, acc.: 55.47%] [G loss: 0.868039]\n",
      "epoch:47 step:37049 [D loss: 0.643410, acc.: 64.06%] [G loss: 0.743150]\n",
      "epoch:47 step:37050 [D loss: 0.709550, acc.: 46.88%] [G loss: 0.751365]\n",
      "epoch:47 step:37051 [D loss: 0.632228, acc.: 68.75%] [G loss: 0.809485]\n",
      "epoch:47 step:37052 [D loss: 0.710492, acc.: 47.66%] [G loss: 0.736125]\n",
      "epoch:47 step:37053 [D loss: 0.676501, acc.: 57.81%] [G loss: 0.775663]\n",
      "epoch:47 step:37054 [D loss: 0.637033, acc.: 67.19%] [G loss: 0.813079]\n",
      "epoch:47 step:37055 [D loss: 0.631986, acc.: 65.62%] [G loss: 0.823215]\n",
      "epoch:47 step:37056 [D loss: 0.631964, acc.: 70.31%] [G loss: 0.827328]\n",
      "epoch:47 step:37057 [D loss: 0.718232, acc.: 53.12%] [G loss: 0.705191]\n",
      "epoch:47 step:37058 [D loss: 0.759405, acc.: 42.19%] [G loss: 0.712467]\n",
      "epoch:47 step:37059 [D loss: 0.694505, acc.: 60.94%] [G loss: 0.843936]\n",
      "epoch:47 step:37060 [D loss: 0.723353, acc.: 46.09%] [G loss: 0.770414]\n",
      "epoch:47 step:37061 [D loss: 0.639826, acc.: 66.41%] [G loss: 0.885242]\n",
      "epoch:47 step:37062 [D loss: 0.673437, acc.: 57.81%] [G loss: 0.894656]\n",
      "epoch:47 step:37063 [D loss: 0.686878, acc.: 57.03%] [G loss: 0.753044]\n",
      "epoch:47 step:37064 [D loss: 0.642646, acc.: 62.50%] [G loss: 0.912817]\n",
      "epoch:47 step:37065 [D loss: 0.755775, acc.: 41.41%] [G loss: 0.876616]\n",
      "epoch:47 step:37066 [D loss: 0.717187, acc.: 47.66%] [G loss: 0.878459]\n",
      "epoch:47 step:37067 [D loss: 0.677960, acc.: 60.94%] [G loss: 0.781974]\n",
      "epoch:47 step:37068 [D loss: 0.686371, acc.: 64.06%] [G loss: 0.824446]\n",
      "epoch:47 step:37069 [D loss: 0.706885, acc.: 57.81%] [G loss: 0.741592]\n",
      "epoch:47 step:37070 [D loss: 0.698617, acc.: 53.12%] [G loss: 0.736950]\n",
      "epoch:47 step:37071 [D loss: 0.667564, acc.: 59.38%] [G loss: 0.803015]\n",
      "epoch:47 step:37072 [D loss: 0.668524, acc.: 60.94%] [G loss: 0.824685]\n",
      "epoch:47 step:37073 [D loss: 0.693295, acc.: 51.56%] [G loss: 0.770641]\n",
      "epoch:47 step:37074 [D loss: 0.724444, acc.: 46.88%] [G loss: 0.735562]\n",
      "epoch:47 step:37075 [D loss: 0.672589, acc.: 58.59%] [G loss: 0.853479]\n",
      "epoch:47 step:37076 [D loss: 0.694581, acc.: 52.34%] [G loss: 0.789606]\n",
      "epoch:47 step:37077 [D loss: 0.684945, acc.: 53.12%] [G loss: 0.815982]\n",
      "epoch:47 step:37078 [D loss: 0.689419, acc.: 52.34%] [G loss: 0.795751]\n",
      "epoch:47 step:37079 [D loss: 0.648020, acc.: 62.50%] [G loss: 0.746729]\n",
      "epoch:47 step:37080 [D loss: 0.691510, acc.: 50.78%] [G loss: 0.824075]\n",
      "epoch:47 step:37081 [D loss: 0.679276, acc.: 53.91%] [G loss: 0.753104]\n",
      "epoch:47 step:37082 [D loss: 0.683388, acc.: 53.12%] [G loss: 0.722788]\n",
      "epoch:47 step:37083 [D loss: 0.640862, acc.: 67.19%] [G loss: 0.826249]\n",
      "epoch:47 step:37084 [D loss: 0.679552, acc.: 52.34%] [G loss: 0.735844]\n",
      "epoch:47 step:37085 [D loss: 0.703455, acc.: 53.91%] [G loss: 0.881439]\n",
      "epoch:47 step:37086 [D loss: 0.672651, acc.: 63.28%] [G loss: 0.833631]\n",
      "epoch:47 step:37087 [D loss: 0.681043, acc.: 60.94%] [G loss: 0.909736]\n",
      "epoch:47 step:37088 [D loss: 0.598351, acc.: 72.66%] [G loss: 0.772359]\n",
      "epoch:47 step:37089 [D loss: 0.650134, acc.: 62.50%] [G loss: 0.812736]\n",
      "epoch:47 step:37090 [D loss: 0.648393, acc.: 61.72%] [G loss: 0.790393]\n",
      "epoch:47 step:37091 [D loss: 0.662310, acc.: 68.75%] [G loss: 0.811834]\n",
      "epoch:47 step:37092 [D loss: 0.645565, acc.: 60.94%] [G loss: 0.840168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37093 [D loss: 0.696463, acc.: 58.59%] [G loss: 0.832707]\n",
      "epoch:47 step:37094 [D loss: 0.672689, acc.: 60.16%] [G loss: 0.810819]\n",
      "epoch:47 step:37095 [D loss: 0.634989, acc.: 66.41%] [G loss: 0.845184]\n",
      "epoch:47 step:37096 [D loss: 0.715708, acc.: 46.09%] [G loss: 0.849974]\n",
      "epoch:47 step:37097 [D loss: 0.699556, acc.: 56.25%] [G loss: 0.834366]\n",
      "epoch:47 step:37098 [D loss: 0.740459, acc.: 47.66%] [G loss: 0.849302]\n",
      "epoch:47 step:37099 [D loss: 0.727285, acc.: 47.66%] [G loss: 0.824126]\n",
      "epoch:47 step:37100 [D loss: 0.657207, acc.: 58.59%] [G loss: 0.774660]\n",
      "epoch:47 step:37101 [D loss: 0.735114, acc.: 43.75%] [G loss: 0.819561]\n",
      "epoch:47 step:37102 [D loss: 0.675395, acc.: 55.47%] [G loss: 0.753816]\n",
      "epoch:47 step:37103 [D loss: 0.658447, acc.: 64.06%] [G loss: 0.833824]\n",
      "epoch:47 step:37104 [D loss: 0.724482, acc.: 41.41%] [G loss: 0.710029]\n",
      "epoch:47 step:37105 [D loss: 0.733472, acc.: 50.00%] [G loss: 0.775728]\n",
      "epoch:47 step:37106 [D loss: 0.666022, acc.: 58.59%] [G loss: 0.789411]\n",
      "epoch:47 step:37107 [D loss: 0.716449, acc.: 46.88%] [G loss: 0.615664]\n",
      "epoch:47 step:37108 [D loss: 0.575923, acc.: 76.56%] [G loss: 0.776774]\n",
      "epoch:47 step:37109 [D loss: 0.649019, acc.: 59.38%] [G loss: 0.736721]\n",
      "epoch:47 step:37110 [D loss: 0.642153, acc.: 65.62%] [G loss: 0.755172]\n",
      "epoch:47 step:37111 [D loss: 0.630837, acc.: 63.28%] [G loss: 0.880748]\n",
      "epoch:47 step:37112 [D loss: 0.717120, acc.: 52.34%] [G loss: 0.745806]\n",
      "epoch:47 step:37113 [D loss: 0.723520, acc.: 48.44%] [G loss: 0.844397]\n",
      "epoch:47 step:37114 [D loss: 0.680618, acc.: 50.78%] [G loss: 0.775641]\n",
      "epoch:47 step:37115 [D loss: 0.721416, acc.: 47.66%] [G loss: 0.771641]\n",
      "epoch:47 step:37116 [D loss: 0.666668, acc.: 60.94%] [G loss: 0.777780]\n",
      "epoch:47 step:37117 [D loss: 0.675940, acc.: 60.94%] [G loss: 0.817228]\n",
      "epoch:47 step:37118 [D loss: 0.690820, acc.: 53.91%] [G loss: 0.826668]\n",
      "epoch:47 step:37119 [D loss: 0.737809, acc.: 42.97%] [G loss: 0.742040]\n",
      "epoch:47 step:37120 [D loss: 0.745398, acc.: 42.19%] [G loss: 0.723157]\n",
      "epoch:47 step:37121 [D loss: 0.688482, acc.: 50.00%] [G loss: 0.796633]\n",
      "epoch:47 step:37122 [D loss: 0.776628, acc.: 39.84%] [G loss: 0.735497]\n",
      "epoch:47 step:37123 [D loss: 0.669842, acc.: 59.38%] [G loss: 0.816445]\n",
      "epoch:47 step:37124 [D loss: 0.697666, acc.: 53.12%] [G loss: 0.808203]\n",
      "epoch:47 step:37125 [D loss: 0.702890, acc.: 53.12%] [G loss: 0.841122]\n",
      "epoch:47 step:37126 [D loss: 0.621900, acc.: 71.09%] [G loss: 0.807471]\n",
      "epoch:47 step:37127 [D loss: 0.712312, acc.: 46.09%] [G loss: 0.799139]\n",
      "epoch:47 step:37128 [D loss: 0.704041, acc.: 44.53%] [G loss: 0.774376]\n",
      "epoch:47 step:37129 [D loss: 0.648235, acc.: 67.19%] [G loss: 0.804138]\n",
      "epoch:47 step:37130 [D loss: 0.666004, acc.: 59.38%] [G loss: 0.849436]\n",
      "epoch:47 step:37131 [D loss: 0.735736, acc.: 44.53%] [G loss: 0.767543]\n",
      "epoch:47 step:37132 [D loss: 0.645695, acc.: 64.84%] [G loss: 0.858028]\n",
      "epoch:47 step:37133 [D loss: 0.674689, acc.: 59.38%] [G loss: 0.766369]\n",
      "epoch:47 step:37134 [D loss: 0.740152, acc.: 51.56%] [G loss: 0.785471]\n",
      "epoch:47 step:37135 [D loss: 0.652319, acc.: 67.19%] [G loss: 0.838696]\n",
      "epoch:47 step:37136 [D loss: 0.689539, acc.: 57.03%] [G loss: 0.735212]\n",
      "epoch:47 step:37137 [D loss: 0.659896, acc.: 63.28%] [G loss: 0.843467]\n",
      "epoch:47 step:37138 [D loss: 0.749669, acc.: 39.06%] [G loss: 0.793738]\n",
      "epoch:47 step:37139 [D loss: 0.667053, acc.: 60.94%] [G loss: 0.794549]\n",
      "epoch:47 step:37140 [D loss: 0.669418, acc.: 61.72%] [G loss: 0.844632]\n",
      "epoch:47 step:37141 [D loss: 0.741349, acc.: 46.09%] [G loss: 0.806861]\n",
      "epoch:47 step:37142 [D loss: 0.652935, acc.: 64.06%] [G loss: 0.863668]\n",
      "epoch:47 step:37143 [D loss: 0.756286, acc.: 41.41%] [G loss: 0.830915]\n",
      "epoch:47 step:37144 [D loss: 0.681455, acc.: 54.69%] [G loss: 0.910643]\n",
      "epoch:47 step:37145 [D loss: 0.732849, acc.: 42.19%] [G loss: 0.752763]\n",
      "epoch:47 step:37146 [D loss: 0.689246, acc.: 55.47%] [G loss: 0.795044]\n",
      "epoch:47 step:37147 [D loss: 0.685151, acc.: 50.78%] [G loss: 0.956715]\n",
      "epoch:47 step:37148 [D loss: 0.635375, acc.: 64.84%] [G loss: 0.820535]\n",
      "epoch:47 step:37149 [D loss: 0.685104, acc.: 57.03%] [G loss: 0.795115]\n",
      "epoch:47 step:37150 [D loss: 0.639939, acc.: 67.97%] [G loss: 0.841738]\n",
      "epoch:47 step:37151 [D loss: 0.711777, acc.: 47.66%] [G loss: 0.739491]\n",
      "epoch:47 step:37152 [D loss: 0.680843, acc.: 57.81%] [G loss: 0.764866]\n",
      "epoch:47 step:37153 [D loss: 0.704404, acc.: 50.00%] [G loss: 0.861283]\n",
      "epoch:47 step:37154 [D loss: 0.717031, acc.: 50.00%] [G loss: 0.765462]\n",
      "epoch:47 step:37155 [D loss: 0.669898, acc.: 56.25%] [G loss: 0.800497]\n",
      "epoch:47 step:37156 [D loss: 0.711686, acc.: 52.34%] [G loss: 0.676758]\n",
      "epoch:47 step:37157 [D loss: 0.660196, acc.: 63.28%] [G loss: 0.775257]\n",
      "epoch:47 step:37158 [D loss: 0.712965, acc.: 50.00%] [G loss: 0.815611]\n",
      "epoch:47 step:37159 [D loss: 0.663637, acc.: 58.59%] [G loss: 0.844270]\n",
      "epoch:47 step:37160 [D loss: 0.661475, acc.: 57.03%] [G loss: 0.867472]\n",
      "epoch:47 step:37161 [D loss: 0.685248, acc.: 51.56%] [G loss: 0.850196]\n",
      "epoch:47 step:37162 [D loss: 0.669005, acc.: 57.03%] [G loss: 0.894083]\n",
      "epoch:47 step:37163 [D loss: 0.671103, acc.: 59.38%] [G loss: 0.801064]\n",
      "epoch:47 step:37164 [D loss: 0.709373, acc.: 51.56%] [G loss: 0.823889]\n",
      "epoch:47 step:37165 [D loss: 0.663782, acc.: 61.72%] [G loss: 0.780787]\n",
      "epoch:47 step:37166 [D loss: 0.780820, acc.: 38.28%] [G loss: 0.838133]\n",
      "epoch:47 step:37167 [D loss: 0.701711, acc.: 50.00%] [G loss: 0.841239]\n",
      "epoch:47 step:37168 [D loss: 0.718205, acc.: 46.09%] [G loss: 0.842392]\n",
      "epoch:47 step:37169 [D loss: 0.584928, acc.: 75.78%] [G loss: 0.789363]\n",
      "epoch:47 step:37170 [D loss: 0.695949, acc.: 56.25%] [G loss: 0.834138]\n",
      "epoch:47 step:37171 [D loss: 0.672757, acc.: 59.38%] [G loss: 0.804085]\n",
      "epoch:47 step:37172 [D loss: 0.647556, acc.: 64.06%] [G loss: 0.824089]\n",
      "epoch:47 step:37173 [D loss: 0.582048, acc.: 73.44%] [G loss: 0.909537]\n",
      "epoch:47 step:37174 [D loss: 0.700169, acc.: 55.47%] [G loss: 0.783999]\n",
      "epoch:47 step:37175 [D loss: 0.686114, acc.: 51.56%] [G loss: 0.793175]\n",
      "epoch:47 step:37176 [D loss: 0.683672, acc.: 53.12%] [G loss: 0.812632]\n",
      "epoch:47 step:37177 [D loss: 0.644034, acc.: 66.41%] [G loss: 0.900064]\n",
      "epoch:47 step:37178 [D loss: 0.689168, acc.: 53.12%] [G loss: 0.776384]\n",
      "epoch:47 step:37179 [D loss: 0.689803, acc.: 53.91%] [G loss: 0.800296]\n",
      "epoch:47 step:37180 [D loss: 0.746382, acc.: 39.06%] [G loss: 0.741989]\n",
      "epoch:47 step:37181 [D loss: 0.700850, acc.: 53.91%] [G loss: 0.768111]\n",
      "epoch:47 step:37182 [D loss: 0.690931, acc.: 55.47%] [G loss: 0.827104]\n",
      "epoch:47 step:37183 [D loss: 0.650107, acc.: 62.50%] [G loss: 0.937378]\n",
      "epoch:47 step:37184 [D loss: 0.662455, acc.: 60.16%] [G loss: 0.859967]\n",
      "epoch:47 step:37185 [D loss: 0.637257, acc.: 69.53%] [G loss: 0.846504]\n",
      "epoch:47 step:37186 [D loss: 0.738094, acc.: 40.62%] [G loss: 0.792192]\n",
      "epoch:47 step:37187 [D loss: 0.695415, acc.: 56.25%] [G loss: 0.865159]\n",
      "epoch:47 step:37188 [D loss: 0.662286, acc.: 61.72%] [G loss: 0.891298]\n",
      "epoch:47 step:37189 [D loss: 0.740413, acc.: 45.31%] [G loss: 0.889878]\n",
      "epoch:47 step:37190 [D loss: 0.719305, acc.: 45.31%] [G loss: 0.835921]\n",
      "epoch:47 step:37191 [D loss: 0.691393, acc.: 51.56%] [G loss: 0.739733]\n",
      "epoch:47 step:37192 [D loss: 0.630593, acc.: 72.66%] [G loss: 0.857037]\n",
      "epoch:47 step:37193 [D loss: 0.729734, acc.: 44.53%] [G loss: 0.841555]\n",
      "epoch:47 step:37194 [D loss: 0.714548, acc.: 44.53%] [G loss: 0.775552]\n",
      "epoch:47 step:37195 [D loss: 0.699571, acc.: 49.22%] [G loss: 0.801174]\n",
      "epoch:47 step:37196 [D loss: 0.710181, acc.: 52.34%] [G loss: 0.814196]\n",
      "epoch:47 step:37197 [D loss: 0.641698, acc.: 66.41%] [G loss: 0.898428]\n",
      "epoch:47 step:37198 [D loss: 0.720177, acc.: 46.09%] [G loss: 0.879187]\n",
      "epoch:47 step:37199 [D loss: 0.658944, acc.: 57.03%] [G loss: 0.746418]\n",
      "epoch:47 step:37200 [D loss: 0.627030, acc.: 64.84%] [G loss: 0.819686]\n",
      "epoch:47 step:37201 [D loss: 0.631032, acc.: 63.28%] [G loss: 0.928057]\n",
      "epoch:47 step:37202 [D loss: 0.698575, acc.: 53.12%] [G loss: 0.786925]\n",
      "epoch:47 step:37203 [D loss: 0.697668, acc.: 53.12%] [G loss: 0.817001]\n",
      "epoch:47 step:37204 [D loss: 0.678828, acc.: 54.69%] [G loss: 0.797190]\n",
      "epoch:47 step:37205 [D loss: 0.648923, acc.: 67.97%] [G loss: 0.820796]\n",
      "epoch:47 step:37206 [D loss: 0.665211, acc.: 59.38%] [G loss: 0.858865]\n",
      "epoch:47 step:37207 [D loss: 0.646395, acc.: 66.41%] [G loss: 0.818492]\n",
      "epoch:47 step:37208 [D loss: 0.687402, acc.: 53.12%] [G loss: 0.784637]\n",
      "epoch:47 step:37209 [D loss: 0.690358, acc.: 50.00%] [G loss: 0.827507]\n",
      "epoch:47 step:37210 [D loss: 0.665749, acc.: 59.38%] [G loss: 0.741095]\n",
      "epoch:47 step:37211 [D loss: 0.635162, acc.: 65.62%] [G loss: 0.845923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37212 [D loss: 0.618688, acc.: 73.44%] [G loss: 0.864291]\n",
      "epoch:47 step:37213 [D loss: 0.693557, acc.: 54.69%] [G loss: 0.881721]\n",
      "epoch:47 step:37214 [D loss: 0.703932, acc.: 49.22%] [G loss: 0.836171]\n",
      "epoch:47 step:37215 [D loss: 0.712714, acc.: 47.66%] [G loss: 0.747359]\n",
      "epoch:47 step:37216 [D loss: 0.686413, acc.: 51.56%] [G loss: 0.802473]\n",
      "epoch:47 step:37217 [D loss: 0.624159, acc.: 70.31%] [G loss: 0.754696]\n",
      "epoch:47 step:37218 [D loss: 0.667401, acc.: 60.94%] [G loss: 0.758254]\n",
      "epoch:47 step:37219 [D loss: 0.723482, acc.: 45.31%] [G loss: 0.778757]\n",
      "epoch:47 step:37220 [D loss: 0.721274, acc.: 49.22%] [G loss: 0.784768]\n",
      "epoch:47 step:37221 [D loss: 0.771467, acc.: 39.06%] [G loss: 0.726346]\n",
      "epoch:47 step:37222 [D loss: 0.672397, acc.: 57.03%] [G loss: 0.738076]\n",
      "epoch:47 step:37223 [D loss: 0.672120, acc.: 65.62%] [G loss: 0.759642]\n",
      "epoch:47 step:37224 [D loss: 0.695663, acc.: 59.38%] [G loss: 0.856551]\n",
      "epoch:47 step:37225 [D loss: 0.609465, acc.: 72.66%] [G loss: 0.802221]\n",
      "epoch:47 step:37226 [D loss: 0.707086, acc.: 51.56%] [G loss: 0.727979]\n",
      "epoch:47 step:37227 [D loss: 0.665815, acc.: 64.06%] [G loss: 0.798392]\n",
      "epoch:47 step:37228 [D loss: 0.621154, acc.: 67.19%] [G loss: 0.755402]\n",
      "epoch:47 step:37229 [D loss: 0.658120, acc.: 64.06%] [G loss: 0.775911]\n",
      "epoch:47 step:37230 [D loss: 0.635544, acc.: 67.19%] [G loss: 0.711407]\n",
      "epoch:47 step:37231 [D loss: 0.643680, acc.: 64.06%] [G loss: 0.745966]\n",
      "epoch:47 step:37232 [D loss: 0.642875, acc.: 67.19%] [G loss: 0.757996]\n",
      "epoch:47 step:37233 [D loss: 0.691339, acc.: 53.91%] [G loss: 0.800501]\n",
      "epoch:47 step:37234 [D loss: 0.660969, acc.: 60.94%] [G loss: 0.693040]\n",
      "epoch:47 step:37235 [D loss: 0.719157, acc.: 53.91%] [G loss: 0.720886]\n",
      "epoch:47 step:37236 [D loss: 0.650707, acc.: 61.72%] [G loss: 0.770594]\n",
      "epoch:47 step:37237 [D loss: 0.639539, acc.: 67.97%] [G loss: 0.727269]\n",
      "epoch:47 step:37238 [D loss: 0.636735, acc.: 65.62%] [G loss: 0.889839]\n",
      "epoch:47 step:37239 [D loss: 0.653353, acc.: 60.94%] [G loss: 0.796397]\n",
      "epoch:47 step:37240 [D loss: 0.687284, acc.: 50.00%] [G loss: 0.878746]\n",
      "epoch:47 step:37241 [D loss: 0.665265, acc.: 59.38%] [G loss: 0.823032]\n",
      "epoch:47 step:37242 [D loss: 0.670442, acc.: 60.16%] [G loss: 0.832798]\n",
      "epoch:47 step:37243 [D loss: 0.665800, acc.: 64.06%] [G loss: 0.788712]\n",
      "epoch:47 step:37244 [D loss: 0.648608, acc.: 65.62%] [G loss: 0.828129]\n",
      "epoch:47 step:37245 [D loss: 0.593485, acc.: 71.88%] [G loss: 0.858713]\n",
      "epoch:47 step:37246 [D loss: 0.633846, acc.: 66.41%] [G loss: 0.870062]\n",
      "epoch:47 step:37247 [D loss: 0.676115, acc.: 59.38%] [G loss: 0.856377]\n",
      "epoch:47 step:37248 [D loss: 0.641397, acc.: 66.41%] [G loss: 0.793903]\n",
      "epoch:47 step:37249 [D loss: 0.644397, acc.: 58.59%] [G loss: 0.788110]\n",
      "epoch:47 step:37250 [D loss: 0.682743, acc.: 50.00%] [G loss: 0.722399]\n",
      "epoch:47 step:37251 [D loss: 0.678365, acc.: 57.03%] [G loss: 0.765232]\n",
      "epoch:47 step:37252 [D loss: 0.658748, acc.: 63.28%] [G loss: 0.888175]\n",
      "epoch:47 step:37253 [D loss: 0.809792, acc.: 31.25%] [G loss: 0.798934]\n",
      "epoch:47 step:37254 [D loss: 0.644992, acc.: 64.84%] [G loss: 0.735478]\n",
      "epoch:47 step:37255 [D loss: 0.595047, acc.: 74.22%] [G loss: 0.754723]\n",
      "epoch:47 step:37256 [D loss: 0.648359, acc.: 62.50%] [G loss: 0.815824]\n",
      "epoch:47 step:37257 [D loss: 0.659452, acc.: 59.38%] [G loss: 0.749056]\n",
      "epoch:47 step:37258 [D loss: 0.729487, acc.: 48.44%] [G loss: 0.727307]\n",
      "epoch:47 step:37259 [D loss: 0.737762, acc.: 48.44%] [G loss: 0.813328]\n",
      "epoch:47 step:37260 [D loss: 0.649147, acc.: 64.84%] [G loss: 0.839513]\n",
      "epoch:47 step:37261 [D loss: 0.653731, acc.: 64.06%] [G loss: 0.831680]\n",
      "epoch:47 step:37262 [D loss: 0.676864, acc.: 57.81%] [G loss: 0.797550]\n",
      "epoch:47 step:37263 [D loss: 0.748943, acc.: 42.19%] [G loss: 0.783869]\n",
      "epoch:47 step:37264 [D loss: 0.633029, acc.: 67.97%] [G loss: 0.837361]\n",
      "epoch:47 step:37265 [D loss: 0.691530, acc.: 56.25%] [G loss: 0.841214]\n",
      "epoch:47 step:37266 [D loss: 0.590177, acc.: 71.09%] [G loss: 0.850783]\n",
      "epoch:47 step:37267 [D loss: 0.696269, acc.: 53.12%] [G loss: 0.760181]\n",
      "epoch:47 step:37268 [D loss: 0.666326, acc.: 64.06%] [G loss: 0.689688]\n",
      "epoch:47 step:37269 [D loss: 0.664829, acc.: 57.03%] [G loss: 0.758049]\n",
      "epoch:47 step:37270 [D loss: 0.655365, acc.: 64.06%] [G loss: 0.901654]\n",
      "epoch:47 step:37271 [D loss: 0.633113, acc.: 62.50%] [G loss: 0.894320]\n",
      "epoch:47 step:37272 [D loss: 0.739065, acc.: 42.97%] [G loss: 0.828888]\n",
      "epoch:47 step:37273 [D loss: 0.622692, acc.: 68.75%] [G loss: 0.815455]\n",
      "epoch:47 step:37274 [D loss: 0.697992, acc.: 49.22%] [G loss: 0.767399]\n",
      "epoch:47 step:37275 [D loss: 0.638463, acc.: 61.72%] [G loss: 0.898519]\n",
      "epoch:47 step:37276 [D loss: 0.700296, acc.: 46.88%] [G loss: 0.796003]\n",
      "epoch:47 step:37277 [D loss: 0.711272, acc.: 51.56%] [G loss: 0.866907]\n",
      "epoch:47 step:37278 [D loss: 0.653120, acc.: 64.06%] [G loss: 0.830811]\n",
      "epoch:47 step:37279 [D loss: 0.687251, acc.: 60.16%] [G loss: 0.769157]\n",
      "epoch:47 step:37280 [D loss: 0.662984, acc.: 53.91%] [G loss: 0.816987]\n",
      "epoch:47 step:37281 [D loss: 0.744078, acc.: 51.56%] [G loss: 0.900913]\n",
      "epoch:47 step:37282 [D loss: 0.708679, acc.: 49.22%] [G loss: 0.820913]\n",
      "epoch:47 step:37283 [D loss: 0.661265, acc.: 64.84%] [G loss: 0.808612]\n",
      "epoch:47 step:37284 [D loss: 0.736888, acc.: 46.09%] [G loss: 0.821527]\n",
      "epoch:47 step:37285 [D loss: 0.635242, acc.: 61.72%] [G loss: 0.884261]\n",
      "epoch:47 step:37286 [D loss: 0.666335, acc.: 59.38%] [G loss: 0.744183]\n",
      "epoch:47 step:37287 [D loss: 0.697358, acc.: 53.91%] [G loss: 0.760316]\n",
      "epoch:47 step:37288 [D loss: 0.748942, acc.: 42.97%] [G loss: 0.752034]\n",
      "epoch:47 step:37289 [D loss: 0.671355, acc.: 56.25%] [G loss: 0.831920]\n",
      "epoch:47 step:37290 [D loss: 0.695670, acc.: 55.47%] [G loss: 0.869078]\n",
      "epoch:47 step:37291 [D loss: 0.742319, acc.: 44.53%] [G loss: 0.827600]\n",
      "epoch:47 step:37292 [D loss: 0.659984, acc.: 58.59%] [G loss: 0.797459]\n",
      "epoch:47 step:37293 [D loss: 0.612916, acc.: 68.75%] [G loss: 0.871638]\n",
      "epoch:47 step:37294 [D loss: 0.605688, acc.: 68.75%] [G loss: 0.746635]\n",
      "epoch:47 step:37295 [D loss: 0.591040, acc.: 70.31%] [G loss: 0.864887]\n",
      "epoch:47 step:37296 [D loss: 0.649310, acc.: 64.06%] [G loss: 0.904422]\n",
      "epoch:47 step:37297 [D loss: 0.709611, acc.: 51.56%] [G loss: 0.916217]\n",
      "epoch:47 step:37298 [D loss: 0.641386, acc.: 64.84%] [G loss: 0.839526]\n",
      "epoch:47 step:37299 [D loss: 0.686174, acc.: 57.81%] [G loss: 0.765921]\n",
      "epoch:47 step:37300 [D loss: 0.636189, acc.: 66.41%] [G loss: 0.879528]\n",
      "epoch:47 step:37301 [D loss: 0.619430, acc.: 69.53%] [G loss: 0.849081]\n",
      "epoch:47 step:37302 [D loss: 0.617913, acc.: 74.22%] [G loss: 0.868060]\n",
      "epoch:47 step:37303 [D loss: 0.778613, acc.: 36.72%] [G loss: 0.826566]\n",
      "epoch:47 step:37304 [D loss: 0.639837, acc.: 64.06%] [G loss: 0.895563]\n",
      "epoch:47 step:37305 [D loss: 0.702789, acc.: 52.34%] [G loss: 0.882042]\n",
      "epoch:47 step:37306 [D loss: 0.664181, acc.: 60.94%] [G loss: 0.834488]\n",
      "epoch:47 step:37307 [D loss: 0.621959, acc.: 64.06%] [G loss: 0.864359]\n",
      "epoch:47 step:37308 [D loss: 0.710870, acc.: 48.44%] [G loss: 0.857162]\n",
      "epoch:47 step:37309 [D loss: 0.616680, acc.: 68.75%] [G loss: 0.824110]\n",
      "epoch:47 step:37310 [D loss: 0.657736, acc.: 55.47%] [G loss: 0.819769]\n",
      "epoch:47 step:37311 [D loss: 0.680490, acc.: 53.12%] [G loss: 0.750123]\n",
      "epoch:47 step:37312 [D loss: 0.648346, acc.: 67.19%] [G loss: 0.804208]\n",
      "epoch:47 step:37313 [D loss: 0.640098, acc.: 67.19%] [G loss: 0.875594]\n",
      "epoch:47 step:37314 [D loss: 0.668958, acc.: 55.47%] [G loss: 0.870542]\n",
      "epoch:47 step:37315 [D loss: 0.720615, acc.: 52.34%] [G loss: 0.722244]\n",
      "epoch:47 step:37316 [D loss: 0.676982, acc.: 52.34%] [G loss: 0.820085]\n",
      "epoch:47 step:37317 [D loss: 0.682332, acc.: 52.34%] [G loss: 0.861444]\n",
      "epoch:47 step:37318 [D loss: 0.683395, acc.: 53.12%] [G loss: 0.735034]\n",
      "epoch:47 step:37319 [D loss: 0.717821, acc.: 48.44%] [G loss: 0.761543]\n",
      "epoch:47 step:37320 [D loss: 0.618132, acc.: 67.19%] [G loss: 0.828042]\n",
      "epoch:47 step:37321 [D loss: 0.674037, acc.: 56.25%] [G loss: 0.854866]\n",
      "epoch:47 step:37322 [D loss: 0.708824, acc.: 46.88%] [G loss: 0.862692]\n",
      "epoch:47 step:37323 [D loss: 0.672039, acc.: 64.06%] [G loss: 0.710725]\n",
      "epoch:47 step:37324 [D loss: 0.697817, acc.: 50.00%] [G loss: 0.824303]\n",
      "epoch:47 step:37325 [D loss: 0.651192, acc.: 58.59%] [G loss: 0.820247]\n",
      "epoch:47 step:37326 [D loss: 0.741925, acc.: 50.00%] [G loss: 0.748141]\n",
      "epoch:47 step:37327 [D loss: 0.691734, acc.: 53.91%] [G loss: 0.889583]\n",
      "epoch:47 step:37328 [D loss: 0.656959, acc.: 60.94%] [G loss: 0.871857]\n",
      "epoch:47 step:37329 [D loss: 0.679742, acc.: 59.38%] [G loss: 0.792993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37330 [D loss: 0.658995, acc.: 67.19%] [G loss: 0.857940]\n",
      "epoch:47 step:37331 [D loss: 0.673446, acc.: 54.69%] [G loss: 0.828107]\n",
      "epoch:47 step:37332 [D loss: 0.677557, acc.: 58.59%] [G loss: 0.871373]\n",
      "epoch:47 step:37333 [D loss: 0.695016, acc.: 54.69%] [G loss: 0.802741]\n",
      "epoch:47 step:37334 [D loss: 0.692092, acc.: 56.25%] [G loss: 0.791555]\n",
      "epoch:47 step:37335 [D loss: 0.574325, acc.: 79.69%] [G loss: 0.878526]\n",
      "epoch:47 step:37336 [D loss: 0.714466, acc.: 47.66%] [G loss: 0.833893]\n",
      "epoch:47 step:37337 [D loss: 0.740176, acc.: 41.41%] [G loss: 0.806361]\n",
      "epoch:47 step:37338 [D loss: 0.711385, acc.: 50.00%] [G loss: 0.711191]\n",
      "epoch:47 step:37339 [D loss: 0.661045, acc.: 59.38%] [G loss: 0.896601]\n",
      "epoch:47 step:37340 [D loss: 0.737026, acc.: 46.09%] [G loss: 0.736824]\n",
      "epoch:47 step:37341 [D loss: 0.741853, acc.: 43.75%] [G loss: 0.829709]\n",
      "epoch:47 step:37342 [D loss: 0.649050, acc.: 64.84%] [G loss: 0.813695]\n",
      "epoch:47 step:37343 [D loss: 0.663862, acc.: 64.84%] [G loss: 0.764588]\n",
      "epoch:47 step:37344 [D loss: 0.614322, acc.: 68.75%] [G loss: 0.802211]\n",
      "epoch:47 step:37345 [D loss: 0.685316, acc.: 60.16%] [G loss: 0.707174]\n",
      "epoch:47 step:37346 [D loss: 0.613850, acc.: 75.00%] [G loss: 0.853157]\n",
      "epoch:47 step:37347 [D loss: 0.710561, acc.: 52.34%] [G loss: 0.763621]\n",
      "epoch:47 step:37348 [D loss: 0.675258, acc.: 59.38%] [G loss: 0.721822]\n",
      "epoch:47 step:37349 [D loss: 0.720032, acc.: 37.50%] [G loss: 0.762051]\n",
      "epoch:47 step:37350 [D loss: 0.709651, acc.: 53.91%] [G loss: 0.771958]\n",
      "epoch:47 step:37351 [D loss: 0.636904, acc.: 68.75%] [G loss: 0.777021]\n",
      "epoch:47 step:37352 [D loss: 0.692900, acc.: 49.22%] [G loss: 0.799023]\n",
      "epoch:47 step:37353 [D loss: 0.623557, acc.: 70.31%] [G loss: 0.807425]\n",
      "epoch:47 step:37354 [D loss: 0.704498, acc.: 52.34%] [G loss: 0.872912]\n",
      "epoch:47 step:37355 [D loss: 0.625988, acc.: 65.62%] [G loss: 0.727461]\n",
      "epoch:47 step:37356 [D loss: 0.666143, acc.: 53.91%] [G loss: 0.849324]\n",
      "epoch:47 step:37357 [D loss: 0.646187, acc.: 62.50%] [G loss: 0.773201]\n",
      "epoch:47 step:37358 [D loss: 0.657232, acc.: 64.84%] [G loss: 0.793978]\n",
      "epoch:47 step:37359 [D loss: 0.678462, acc.: 55.47%] [G loss: 0.879879]\n",
      "epoch:47 step:37360 [D loss: 0.731690, acc.: 48.44%] [G loss: 0.812921]\n",
      "epoch:47 step:37361 [D loss: 0.717098, acc.: 44.53%] [G loss: 0.843884]\n",
      "epoch:47 step:37362 [D loss: 0.742052, acc.: 46.09%] [G loss: 0.833044]\n",
      "epoch:47 step:37363 [D loss: 0.674028, acc.: 60.16%] [G loss: 0.864014]\n",
      "epoch:47 step:37364 [D loss: 0.654511, acc.: 60.16%] [G loss: 0.799500]\n",
      "epoch:47 step:37365 [D loss: 0.624893, acc.: 67.19%] [G loss: 0.785765]\n",
      "epoch:47 step:37366 [D loss: 0.680681, acc.: 52.34%] [G loss: 0.906218]\n",
      "epoch:47 step:37367 [D loss: 0.716259, acc.: 46.88%] [G loss: 0.781930]\n",
      "epoch:47 step:37368 [D loss: 0.692331, acc.: 50.78%] [G loss: 0.789406]\n",
      "epoch:47 step:37369 [D loss: 0.686228, acc.: 50.78%] [G loss: 0.789500]\n",
      "epoch:47 step:37370 [D loss: 0.627584, acc.: 68.75%] [G loss: 0.833690]\n",
      "epoch:47 step:37371 [D loss: 0.685674, acc.: 54.69%] [G loss: 0.779798]\n",
      "epoch:47 step:37372 [D loss: 0.666824, acc.: 55.47%] [G loss: 0.807684]\n",
      "epoch:47 step:37373 [D loss: 0.701917, acc.: 54.69%] [G loss: 0.829493]\n",
      "epoch:47 step:37374 [D loss: 0.681303, acc.: 61.72%] [G loss: 0.843959]\n",
      "epoch:47 step:37375 [D loss: 0.706459, acc.: 50.78%] [G loss: 0.813123]\n",
      "epoch:47 step:37376 [D loss: 0.632894, acc.: 64.84%] [G loss: 0.883632]\n",
      "epoch:47 step:37377 [D loss: 0.687792, acc.: 53.91%] [G loss: 0.983291]\n",
      "epoch:47 step:37378 [D loss: 0.687012, acc.: 53.91%] [G loss: 0.857290]\n",
      "epoch:47 step:37379 [D loss: 0.740546, acc.: 43.75%] [G loss: 0.886442]\n",
      "epoch:47 step:37380 [D loss: 0.671865, acc.: 65.62%] [G loss: 0.762189]\n",
      "epoch:47 step:37381 [D loss: 0.779799, acc.: 39.06%] [G loss: 0.821754]\n",
      "epoch:47 step:37382 [D loss: 0.727406, acc.: 44.53%] [G loss: 0.746887]\n",
      "epoch:47 step:37383 [D loss: 0.662015, acc.: 60.16%] [G loss: 0.771764]\n",
      "epoch:47 step:37384 [D loss: 0.648049, acc.: 64.06%] [G loss: 0.785921]\n",
      "epoch:47 step:37385 [D loss: 0.684154, acc.: 54.69%] [G loss: 0.823936]\n",
      "epoch:47 step:37386 [D loss: 0.660201, acc.: 57.03%] [G loss: 0.974439]\n",
      "epoch:47 step:37387 [D loss: 0.663834, acc.: 64.84%] [G loss: 0.832095]\n",
      "epoch:47 step:37388 [D loss: 0.689981, acc.: 53.12%] [G loss: 0.750593]\n",
      "epoch:47 step:37389 [D loss: 0.668435, acc.: 64.84%] [G loss: 0.811860]\n",
      "epoch:47 step:37390 [D loss: 0.621886, acc.: 70.31%] [G loss: 0.864521]\n",
      "epoch:47 step:37391 [D loss: 0.636986, acc.: 67.97%] [G loss: 0.958696]\n",
      "epoch:47 step:37392 [D loss: 0.764886, acc.: 42.97%] [G loss: 0.820121]\n",
      "epoch:47 step:37393 [D loss: 0.711019, acc.: 49.22%] [G loss: 0.783382]\n",
      "epoch:47 step:37394 [D loss: 0.699414, acc.: 56.25%] [G loss: 0.878424]\n",
      "epoch:47 step:37395 [D loss: 0.690014, acc.: 48.44%] [G loss: 0.808733]\n",
      "epoch:47 step:37396 [D loss: 0.675341, acc.: 59.38%] [G loss: 0.811708]\n",
      "epoch:47 step:37397 [D loss: 0.694262, acc.: 57.81%] [G loss: 0.887267]\n",
      "epoch:47 step:37398 [D loss: 0.663435, acc.: 60.94%] [G loss: 0.796633]\n",
      "epoch:47 step:37399 [D loss: 0.774650, acc.: 40.62%] [G loss: 0.785114]\n",
      "epoch:47 step:37400 [D loss: 0.746575, acc.: 39.06%] [G loss: 0.782257]\n",
      "epoch:47 step:37401 [D loss: 0.656245, acc.: 56.25%] [G loss: 0.760680]\n",
      "epoch:47 step:37402 [D loss: 0.669692, acc.: 58.59%] [G loss: 0.809918]\n",
      "epoch:47 step:37403 [D loss: 0.712590, acc.: 46.09%] [G loss: 0.798295]\n",
      "epoch:47 step:37404 [D loss: 0.702328, acc.: 53.12%] [G loss: 0.752269]\n",
      "epoch:47 step:37405 [D loss: 0.648697, acc.: 61.72%] [G loss: 0.727754]\n",
      "epoch:47 step:37406 [D loss: 0.712275, acc.: 48.44%] [G loss: 0.732977]\n",
      "epoch:47 step:37407 [D loss: 0.632418, acc.: 67.19%] [G loss: 0.751054]\n",
      "epoch:47 step:37408 [D loss: 0.673887, acc.: 56.25%] [G loss: 0.747696]\n",
      "epoch:47 step:37409 [D loss: 0.667261, acc.: 56.25%] [G loss: 0.748596]\n",
      "epoch:47 step:37410 [D loss: 0.667498, acc.: 55.47%] [G loss: 0.794635]\n",
      "epoch:47 step:37411 [D loss: 0.711053, acc.: 44.53%] [G loss: 0.784355]\n",
      "epoch:47 step:37412 [D loss: 0.665256, acc.: 58.59%] [G loss: 0.870010]\n",
      "epoch:47 step:37413 [D loss: 0.671422, acc.: 57.03%] [G loss: 0.862520]\n",
      "epoch:47 step:37414 [D loss: 0.716223, acc.: 47.66%] [G loss: 0.705309]\n",
      "epoch:47 step:37415 [D loss: 0.725091, acc.: 42.97%] [G loss: 0.779611]\n",
      "epoch:47 step:37416 [D loss: 0.699172, acc.: 51.56%] [G loss: 0.732009]\n",
      "epoch:47 step:37417 [D loss: 0.662101, acc.: 60.94%] [G loss: 0.777395]\n",
      "epoch:47 step:37418 [D loss: 0.609163, acc.: 67.19%] [G loss: 0.845994]\n",
      "epoch:47 step:37419 [D loss: 0.655939, acc.: 63.28%] [G loss: 0.891090]\n",
      "epoch:47 step:37420 [D loss: 0.685901, acc.: 53.12%] [G loss: 0.786931]\n",
      "epoch:47 step:37421 [D loss: 0.649891, acc.: 62.50%] [G loss: 0.691042]\n",
      "epoch:47 step:37422 [D loss: 0.673667, acc.: 55.47%] [G loss: 0.704298]\n",
      "epoch:47 step:37423 [D loss: 0.642563, acc.: 64.06%] [G loss: 0.755348]\n",
      "epoch:47 step:37424 [D loss: 0.640016, acc.: 65.62%] [G loss: 0.774516]\n",
      "epoch:47 step:37425 [D loss: 0.634577, acc.: 64.06%] [G loss: 0.801349]\n",
      "epoch:47 step:37426 [D loss: 0.735002, acc.: 46.09%] [G loss: 0.710796]\n",
      "epoch:47 step:37427 [D loss: 0.680661, acc.: 60.94%] [G loss: 0.754105]\n",
      "epoch:47 step:37428 [D loss: 0.691239, acc.: 57.03%] [G loss: 0.721695]\n",
      "epoch:47 step:37429 [D loss: 0.665956, acc.: 62.50%] [G loss: 0.753195]\n",
      "epoch:47 step:37430 [D loss: 0.723024, acc.: 50.00%] [G loss: 0.788432]\n",
      "epoch:47 step:37431 [D loss: 0.645533, acc.: 64.06%] [G loss: 0.785215]\n",
      "epoch:47 step:37432 [D loss: 0.676755, acc.: 52.34%] [G loss: 0.780609]\n",
      "epoch:47 step:37433 [D loss: 0.692668, acc.: 55.47%] [G loss: 0.844625]\n",
      "epoch:47 step:37434 [D loss: 0.701727, acc.: 52.34%] [G loss: 0.765698]\n",
      "epoch:47 step:37435 [D loss: 0.659417, acc.: 60.94%] [G loss: 0.851254]\n",
      "epoch:47 step:37436 [D loss: 0.665762, acc.: 61.72%] [G loss: 0.825024]\n",
      "epoch:47 step:37437 [D loss: 0.640259, acc.: 60.94%] [G loss: 0.870226]\n",
      "epoch:47 step:37438 [D loss: 0.662575, acc.: 64.06%] [G loss: 0.807276]\n",
      "epoch:47 step:37439 [D loss: 0.692134, acc.: 51.56%] [G loss: 0.754707]\n",
      "epoch:47 step:37440 [D loss: 0.675556, acc.: 57.03%] [G loss: 0.758000]\n",
      "epoch:47 step:37441 [D loss: 0.712120, acc.: 46.88%] [G loss: 0.729849]\n",
      "epoch:47 step:37442 [D loss: 0.628038, acc.: 69.53%] [G loss: 0.766477]\n",
      "epoch:47 step:37443 [D loss: 0.675023, acc.: 56.25%] [G loss: 0.781457]\n",
      "epoch:47 step:37444 [D loss: 0.772361, acc.: 35.94%] [G loss: 0.711696]\n",
      "epoch:47 step:37445 [D loss: 0.614440, acc.: 72.66%] [G loss: 0.709308]\n",
      "epoch:47 step:37446 [D loss: 0.653767, acc.: 61.72%] [G loss: 0.854112]\n",
      "epoch:47 step:37447 [D loss: 0.678737, acc.: 56.25%] [G loss: 0.798934]\n",
      "epoch:47 step:37448 [D loss: 0.618296, acc.: 68.75%] [G loss: 0.895168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37449 [D loss: 0.707700, acc.: 53.12%] [G loss: 0.808245]\n",
      "epoch:47 step:37450 [D loss: 0.648429, acc.: 64.84%] [G loss: 0.767824]\n",
      "epoch:47 step:37451 [D loss: 0.698897, acc.: 50.00%] [G loss: 0.780683]\n",
      "epoch:47 step:37452 [D loss: 0.725487, acc.: 46.88%] [G loss: 0.881176]\n",
      "epoch:47 step:37453 [D loss: 0.707669, acc.: 53.91%] [G loss: 0.754690]\n",
      "epoch:47 step:37454 [D loss: 0.711739, acc.: 54.69%] [G loss: 0.889167]\n",
      "epoch:47 step:37455 [D loss: 0.615516, acc.: 71.09%] [G loss: 0.815070]\n",
      "epoch:47 step:37456 [D loss: 0.714705, acc.: 44.53%] [G loss: 0.811337]\n",
      "epoch:47 step:37457 [D loss: 0.705586, acc.: 57.03%] [G loss: 0.786725]\n",
      "epoch:47 step:37458 [D loss: 0.682754, acc.: 54.69%] [G loss: 0.737441]\n",
      "epoch:47 step:37459 [D loss: 0.704064, acc.: 48.44%] [G loss: 0.750077]\n",
      "epoch:47 step:37460 [D loss: 0.578271, acc.: 78.91%] [G loss: 0.825266]\n",
      "epoch:47 step:37461 [D loss: 0.616053, acc.: 72.66%] [G loss: 0.848329]\n",
      "epoch:47 step:37462 [D loss: 0.661591, acc.: 62.50%] [G loss: 0.849583]\n",
      "epoch:47 step:37463 [D loss: 0.641282, acc.: 67.19%] [G loss: 0.817356]\n",
      "epoch:47 step:37464 [D loss: 0.717691, acc.: 46.88%] [G loss: 0.855238]\n",
      "epoch:47 step:37465 [D loss: 0.622043, acc.: 66.41%] [G loss: 0.940048]\n",
      "epoch:47 step:37466 [D loss: 0.707714, acc.: 50.78%] [G loss: 0.824877]\n",
      "epoch:47 step:37467 [D loss: 0.668470, acc.: 61.72%] [G loss: 0.873575]\n",
      "epoch:47 step:37468 [D loss: 0.669477, acc.: 63.28%] [G loss: 0.777584]\n",
      "epoch:47 step:37469 [D loss: 0.728648, acc.: 46.88%] [G loss: 0.801576]\n",
      "epoch:47 step:37470 [D loss: 0.634006, acc.: 65.62%] [G loss: 0.920738]\n",
      "epoch:47 step:37471 [D loss: 0.704835, acc.: 53.91%] [G loss: 0.785048]\n",
      "epoch:47 step:37472 [D loss: 0.672601, acc.: 54.69%] [G loss: 0.836189]\n",
      "epoch:47 step:37473 [D loss: 0.645565, acc.: 65.62%] [G loss: 0.822476]\n",
      "epoch:47 step:37474 [D loss: 0.673038, acc.: 60.94%] [G loss: 0.830785]\n",
      "epoch:47 step:37475 [D loss: 0.697401, acc.: 53.91%] [G loss: 0.842036]\n",
      "epoch:47 step:37476 [D loss: 0.630381, acc.: 60.16%] [G loss: 0.803321]\n",
      "epoch:47 step:37477 [D loss: 0.638019, acc.: 60.94%] [G loss: 0.782206]\n",
      "epoch:47 step:37478 [D loss: 0.702792, acc.: 57.03%] [G loss: 0.808495]\n",
      "epoch:47 step:37479 [D loss: 0.703421, acc.: 51.56%] [G loss: 0.773965]\n",
      "epoch:47 step:37480 [D loss: 0.685959, acc.: 50.78%] [G loss: 0.711581]\n",
      "epoch:47 step:37481 [D loss: 0.665060, acc.: 60.94%] [G loss: 0.749792]\n",
      "epoch:47 step:37482 [D loss: 0.714861, acc.: 48.44%] [G loss: 0.844971]\n",
      "epoch:47 step:37483 [D loss: 0.672094, acc.: 57.03%] [G loss: 0.880779]\n",
      "epoch:47 step:37484 [D loss: 0.701218, acc.: 50.00%] [G loss: 0.700890]\n",
      "epoch:47 step:37485 [D loss: 0.765408, acc.: 37.50%] [G loss: 0.773674]\n",
      "epoch:47 step:37486 [D loss: 0.592702, acc.: 74.22%] [G loss: 0.743784]\n",
      "epoch:47 step:37487 [D loss: 0.722142, acc.: 50.78%] [G loss: 0.815866]\n",
      "epoch:47 step:37488 [D loss: 0.669758, acc.: 57.03%] [G loss: 0.843147]\n",
      "epoch:48 step:37489 [D loss: 0.662397, acc.: 62.50%] [G loss: 0.727351]\n",
      "epoch:48 step:37490 [D loss: 0.727473, acc.: 48.44%] [G loss: 0.823981]\n",
      "epoch:48 step:37491 [D loss: 0.685600, acc.: 50.00%] [G loss: 0.795392]\n",
      "epoch:48 step:37492 [D loss: 0.673736, acc.: 53.91%] [G loss: 0.847674]\n",
      "epoch:48 step:37493 [D loss: 0.704574, acc.: 54.69%] [G loss: 0.776964]\n",
      "epoch:48 step:37494 [D loss: 0.573154, acc.: 74.22%] [G loss: 0.828708]\n",
      "epoch:48 step:37495 [D loss: 0.681120, acc.: 53.12%] [G loss: 0.738579]\n",
      "epoch:48 step:37496 [D loss: 0.666086, acc.: 57.81%] [G loss: 0.757556]\n",
      "epoch:48 step:37497 [D loss: 0.698817, acc.: 50.78%] [G loss: 0.791754]\n",
      "epoch:48 step:37498 [D loss: 0.669303, acc.: 60.94%] [G loss: 0.764592]\n",
      "epoch:48 step:37499 [D loss: 0.669948, acc.: 54.69%] [G loss: 0.873803]\n",
      "epoch:48 step:37500 [D loss: 0.658549, acc.: 60.16%] [G loss: 0.825174]\n",
      "epoch:48 step:37501 [D loss: 0.679095, acc.: 57.81%] [G loss: 0.782124]\n",
      "epoch:48 step:37502 [D loss: 0.671948, acc.: 59.38%] [G loss: 0.835086]\n",
      "epoch:48 step:37503 [D loss: 0.714793, acc.: 53.91%] [G loss: 0.745647]\n",
      "epoch:48 step:37504 [D loss: 0.695308, acc.: 50.78%] [G loss: 0.785602]\n",
      "epoch:48 step:37505 [D loss: 0.657290, acc.: 62.50%] [G loss: 0.868546]\n",
      "epoch:48 step:37506 [D loss: 0.687139, acc.: 57.03%] [G loss: 0.773759]\n",
      "epoch:48 step:37507 [D loss: 0.686887, acc.: 58.59%] [G loss: 0.794834]\n",
      "epoch:48 step:37508 [D loss: 0.688960, acc.: 54.69%] [G loss: 0.746303]\n",
      "epoch:48 step:37509 [D loss: 0.652359, acc.: 59.38%] [G loss: 0.792762]\n",
      "epoch:48 step:37510 [D loss: 0.676845, acc.: 54.69%] [G loss: 0.837284]\n",
      "epoch:48 step:37511 [D loss: 0.706649, acc.: 48.44%] [G loss: 0.803041]\n",
      "epoch:48 step:37512 [D loss: 0.726807, acc.: 46.09%] [G loss: 0.788602]\n",
      "epoch:48 step:37513 [D loss: 0.688469, acc.: 57.03%] [G loss: 0.791996]\n",
      "epoch:48 step:37514 [D loss: 0.670482, acc.: 60.16%] [G loss: 0.833611]\n",
      "epoch:48 step:37515 [D loss: 0.657387, acc.: 60.94%] [G loss: 0.870698]\n",
      "epoch:48 step:37516 [D loss: 0.656281, acc.: 62.50%] [G loss: 0.833705]\n",
      "epoch:48 step:37517 [D loss: 0.666727, acc.: 62.50%] [G loss: 0.810059]\n",
      "epoch:48 step:37518 [D loss: 0.680339, acc.: 50.00%] [G loss: 0.769949]\n",
      "epoch:48 step:37519 [D loss: 0.722524, acc.: 43.75%] [G loss: 0.760239]\n",
      "epoch:48 step:37520 [D loss: 0.733279, acc.: 45.31%] [G loss: 0.807269]\n",
      "epoch:48 step:37521 [D loss: 0.645359, acc.: 64.84%] [G loss: 0.819374]\n",
      "epoch:48 step:37522 [D loss: 0.641025, acc.: 66.41%] [G loss: 0.703863]\n",
      "epoch:48 step:37523 [D loss: 0.692103, acc.: 53.91%] [G loss: 0.777988]\n",
      "epoch:48 step:37524 [D loss: 0.721546, acc.: 48.44%] [G loss: 0.740984]\n",
      "epoch:48 step:37525 [D loss: 0.725700, acc.: 46.09%] [G loss: 0.800055]\n",
      "epoch:48 step:37526 [D loss: 0.734573, acc.: 50.78%] [G loss: 0.740403]\n",
      "epoch:48 step:37527 [D loss: 0.751285, acc.: 45.31%] [G loss: 0.725453]\n",
      "epoch:48 step:37528 [D loss: 0.634511, acc.: 69.53%] [G loss: 0.864300]\n",
      "epoch:48 step:37529 [D loss: 0.655517, acc.: 59.38%] [G loss: 0.869958]\n",
      "epoch:48 step:37530 [D loss: 0.732004, acc.: 46.09%] [G loss: 0.827881]\n",
      "epoch:48 step:37531 [D loss: 0.725497, acc.: 43.75%] [G loss: 0.817858]\n",
      "epoch:48 step:37532 [D loss: 0.652483, acc.: 60.94%] [G loss: 0.915757]\n",
      "epoch:48 step:37533 [D loss: 0.646501, acc.: 65.62%] [G loss: 0.848253]\n",
      "epoch:48 step:37534 [D loss: 0.690505, acc.: 54.69%] [G loss: 0.788134]\n",
      "epoch:48 step:37535 [D loss: 0.705104, acc.: 51.56%] [G loss: 0.885351]\n",
      "epoch:48 step:37536 [D loss: 0.677058, acc.: 54.69%] [G loss: 0.876531]\n",
      "epoch:48 step:37537 [D loss: 0.634414, acc.: 67.19%] [G loss: 0.759203]\n",
      "epoch:48 step:37538 [D loss: 0.686028, acc.: 53.91%] [G loss: 0.742638]\n",
      "epoch:48 step:37539 [D loss: 0.639931, acc.: 71.88%] [G loss: 0.844055]\n",
      "epoch:48 step:37540 [D loss: 0.645609, acc.: 64.06%] [G loss: 0.806567]\n",
      "epoch:48 step:37541 [D loss: 0.729766, acc.: 42.19%] [G loss: 0.742448]\n",
      "epoch:48 step:37542 [D loss: 0.682110, acc.: 56.25%] [G loss: 0.854306]\n",
      "epoch:48 step:37543 [D loss: 0.668885, acc.: 62.50%] [G loss: 0.832001]\n",
      "epoch:48 step:37544 [D loss: 0.693153, acc.: 56.25%] [G loss: 0.858334]\n",
      "epoch:48 step:37545 [D loss: 0.629875, acc.: 67.97%] [G loss: 0.790843]\n",
      "epoch:48 step:37546 [D loss: 0.689599, acc.: 56.25%] [G loss: 0.756320]\n",
      "epoch:48 step:37547 [D loss: 0.630627, acc.: 66.41%] [G loss: 0.853876]\n",
      "epoch:48 step:37548 [D loss: 0.679597, acc.: 56.25%] [G loss: 0.851095]\n",
      "epoch:48 step:37549 [D loss: 0.709055, acc.: 51.56%] [G loss: 0.823264]\n",
      "epoch:48 step:37550 [D loss: 0.616915, acc.: 75.78%] [G loss: 0.914956]\n",
      "epoch:48 step:37551 [D loss: 0.734294, acc.: 46.88%] [G loss: 0.792850]\n",
      "epoch:48 step:37552 [D loss: 0.663194, acc.: 58.59%] [G loss: 0.849946]\n",
      "epoch:48 step:37553 [D loss: 0.685741, acc.: 55.47%] [G loss: 0.837836]\n",
      "epoch:48 step:37554 [D loss: 0.641301, acc.: 64.84%] [G loss: 0.870026]\n",
      "epoch:48 step:37555 [D loss: 0.632026, acc.: 68.75%] [G loss: 0.958842]\n",
      "epoch:48 step:37556 [D loss: 0.666533, acc.: 56.25%] [G loss: 0.848281]\n",
      "epoch:48 step:37557 [D loss: 0.683693, acc.: 58.59%] [G loss: 0.780895]\n",
      "epoch:48 step:37558 [D loss: 0.732421, acc.: 50.78%] [G loss: 0.911844]\n",
      "epoch:48 step:37559 [D loss: 0.746134, acc.: 36.72%] [G loss: 0.673433]\n",
      "epoch:48 step:37560 [D loss: 0.658828, acc.: 60.16%] [G loss: 0.714882]\n",
      "epoch:48 step:37561 [D loss: 0.707008, acc.: 53.91%] [G loss: 0.867201]\n",
      "epoch:48 step:37562 [D loss: 0.642616, acc.: 61.72%] [G loss: 0.841148]\n",
      "epoch:48 step:37563 [D loss: 0.619156, acc.: 66.41%] [G loss: 0.778581]\n",
      "epoch:48 step:37564 [D loss: 0.724642, acc.: 48.44%] [G loss: 0.848274]\n",
      "epoch:48 step:37565 [D loss: 0.688209, acc.: 63.28%] [G loss: 0.757941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37566 [D loss: 0.686462, acc.: 53.91%] [G loss: 0.867551]\n",
      "epoch:48 step:37567 [D loss: 0.679640, acc.: 62.50%] [G loss: 0.823735]\n",
      "epoch:48 step:37568 [D loss: 0.694813, acc.: 55.47%] [G loss: 0.885447]\n",
      "epoch:48 step:37569 [D loss: 0.741468, acc.: 44.53%] [G loss: 0.796202]\n",
      "epoch:48 step:37570 [D loss: 0.606326, acc.: 75.00%] [G loss: 0.782679]\n",
      "epoch:48 step:37571 [D loss: 0.643575, acc.: 64.06%] [G loss: 0.857376]\n",
      "epoch:48 step:37572 [D loss: 0.680933, acc.: 60.16%] [G loss: 0.771381]\n",
      "epoch:48 step:37573 [D loss: 0.721124, acc.: 50.78%] [G loss: 0.776308]\n",
      "epoch:48 step:37574 [D loss: 0.679368, acc.: 63.28%] [G loss: 0.801642]\n",
      "epoch:48 step:37575 [D loss: 0.672160, acc.: 61.72%] [G loss: 0.776978]\n",
      "epoch:48 step:37576 [D loss: 0.723282, acc.: 49.22%] [G loss: 0.766110]\n",
      "epoch:48 step:37577 [D loss: 0.725503, acc.: 47.66%] [G loss: 0.819077]\n",
      "epoch:48 step:37578 [D loss: 0.653344, acc.: 61.72%] [G loss: 0.836368]\n",
      "epoch:48 step:37579 [D loss: 0.734415, acc.: 43.75%] [G loss: 0.808777]\n",
      "epoch:48 step:37580 [D loss: 0.639157, acc.: 64.84%] [G loss: 0.718369]\n",
      "epoch:48 step:37581 [D loss: 0.735095, acc.: 46.88%] [G loss: 0.773128]\n",
      "epoch:48 step:37582 [D loss: 0.669967, acc.: 59.38%] [G loss: 0.870105]\n",
      "epoch:48 step:37583 [D loss: 0.707592, acc.: 51.56%] [G loss: 0.831927]\n",
      "epoch:48 step:37584 [D loss: 0.648053, acc.: 69.53%] [G loss: 0.888255]\n",
      "epoch:48 step:37585 [D loss: 0.710294, acc.: 50.78%] [G loss: 0.806490]\n",
      "epoch:48 step:37586 [D loss: 0.689572, acc.: 52.34%] [G loss: 0.904018]\n",
      "epoch:48 step:37587 [D loss: 0.703806, acc.: 53.12%] [G loss: 0.762809]\n",
      "epoch:48 step:37588 [D loss: 0.671051, acc.: 60.16%] [G loss: 0.833055]\n",
      "epoch:48 step:37589 [D loss: 0.715968, acc.: 52.34%] [G loss: 0.745559]\n",
      "epoch:48 step:37590 [D loss: 0.663582, acc.: 57.81%] [G loss: 0.798438]\n",
      "epoch:48 step:37591 [D loss: 0.686813, acc.: 56.25%] [G loss: 0.766211]\n",
      "epoch:48 step:37592 [D loss: 0.695535, acc.: 55.47%] [G loss: 0.840208]\n",
      "epoch:48 step:37593 [D loss: 0.727120, acc.: 45.31%] [G loss: 0.752078]\n",
      "epoch:48 step:37594 [D loss: 0.692293, acc.: 53.12%] [G loss: 0.754404]\n",
      "epoch:48 step:37595 [D loss: 0.612567, acc.: 72.66%] [G loss: 0.788569]\n",
      "epoch:48 step:37596 [D loss: 0.674513, acc.: 56.25%] [G loss: 0.861166]\n",
      "epoch:48 step:37597 [D loss: 0.671351, acc.: 55.47%] [G loss: 0.742966]\n",
      "epoch:48 step:37598 [D loss: 0.718514, acc.: 51.56%] [G loss: 0.803592]\n",
      "epoch:48 step:37599 [D loss: 0.692838, acc.: 57.03%] [G loss: 0.803450]\n",
      "epoch:48 step:37600 [D loss: 0.656028, acc.: 64.06%] [G loss: 0.706046]\n",
      "epoch:48 step:37601 [D loss: 0.730301, acc.: 44.53%] [G loss: 0.751530]\n",
      "epoch:48 step:37602 [D loss: 0.637716, acc.: 70.31%] [G loss: 0.863281]\n",
      "epoch:48 step:37603 [D loss: 0.712919, acc.: 50.00%] [G loss: 0.848338]\n",
      "epoch:48 step:37604 [D loss: 0.644260, acc.: 59.38%] [G loss: 0.873676]\n",
      "epoch:48 step:37605 [D loss: 0.669892, acc.: 62.50%] [G loss: 0.806844]\n",
      "epoch:48 step:37606 [D loss: 0.700587, acc.: 52.34%] [G loss: 0.742133]\n",
      "epoch:48 step:37607 [D loss: 0.691598, acc.: 52.34%] [G loss: 0.709691]\n",
      "epoch:48 step:37608 [D loss: 0.668059, acc.: 58.59%] [G loss: 0.726404]\n",
      "epoch:48 step:37609 [D loss: 0.702829, acc.: 46.09%] [G loss: 0.676813]\n",
      "epoch:48 step:37610 [D loss: 0.693060, acc.: 56.25%] [G loss: 0.753543]\n",
      "epoch:48 step:37611 [D loss: 0.712791, acc.: 52.34%] [G loss: 0.685233]\n",
      "epoch:48 step:37612 [D loss: 0.724530, acc.: 44.53%] [G loss: 0.666760]\n",
      "epoch:48 step:37613 [D loss: 0.734758, acc.: 42.97%] [G loss: 0.758163]\n",
      "epoch:48 step:37614 [D loss: 0.705414, acc.: 50.78%] [G loss: 0.812059]\n",
      "epoch:48 step:37615 [D loss: 0.651843, acc.: 61.72%] [G loss: 0.689372]\n",
      "epoch:48 step:37616 [D loss: 0.625530, acc.: 67.19%] [G loss: 0.862758]\n",
      "epoch:48 step:37617 [D loss: 0.691025, acc.: 56.25%] [G loss: 0.754925]\n",
      "epoch:48 step:37618 [D loss: 0.723026, acc.: 52.34%] [G loss: 0.833905]\n",
      "epoch:48 step:37619 [D loss: 0.746182, acc.: 49.22%] [G loss: 0.846332]\n",
      "epoch:48 step:37620 [D loss: 0.738263, acc.: 40.62%] [G loss: 0.817960]\n",
      "epoch:48 step:37621 [D loss: 0.676942, acc.: 53.12%] [G loss: 0.861404]\n",
      "epoch:48 step:37622 [D loss: 0.723915, acc.: 46.88%] [G loss: 0.831497]\n",
      "epoch:48 step:37623 [D loss: 0.734594, acc.: 44.53%] [G loss: 0.817820]\n",
      "epoch:48 step:37624 [D loss: 0.683379, acc.: 57.03%] [G loss: 0.802857]\n",
      "epoch:48 step:37625 [D loss: 0.736479, acc.: 39.06%] [G loss: 0.767303]\n",
      "epoch:48 step:37626 [D loss: 0.726663, acc.: 46.09%] [G loss: 0.702163]\n",
      "epoch:48 step:37627 [D loss: 0.640780, acc.: 66.41%] [G loss: 0.814195]\n",
      "epoch:48 step:37628 [D loss: 0.698839, acc.: 56.25%] [G loss: 0.795614]\n",
      "epoch:48 step:37629 [D loss: 0.706344, acc.: 54.69%] [G loss: 0.769019]\n",
      "epoch:48 step:37630 [D loss: 0.703110, acc.: 53.91%] [G loss: 0.812597]\n",
      "epoch:48 step:37631 [D loss: 0.650525, acc.: 61.72%] [G loss: 0.891067]\n",
      "epoch:48 step:37632 [D loss: 0.633562, acc.: 67.19%] [G loss: 0.817594]\n",
      "epoch:48 step:37633 [D loss: 0.706933, acc.: 51.56%] [G loss: 0.777921]\n",
      "epoch:48 step:37634 [D loss: 0.676410, acc.: 60.94%] [G loss: 0.818215]\n",
      "epoch:48 step:37635 [D loss: 0.649826, acc.: 60.16%] [G loss: 0.776161]\n",
      "epoch:48 step:37636 [D loss: 0.635506, acc.: 67.19%] [G loss: 0.808418]\n",
      "epoch:48 step:37637 [D loss: 0.646459, acc.: 60.16%] [G loss: 0.801341]\n",
      "epoch:48 step:37638 [D loss: 0.702352, acc.: 48.44%] [G loss: 0.798092]\n",
      "epoch:48 step:37639 [D loss: 0.683623, acc.: 57.03%] [G loss: 0.832519]\n",
      "epoch:48 step:37640 [D loss: 0.673771, acc.: 54.69%] [G loss: 0.874117]\n",
      "epoch:48 step:37641 [D loss: 0.660218, acc.: 58.59%] [G loss: 0.849304]\n",
      "epoch:48 step:37642 [D loss: 0.666369, acc.: 60.94%] [G loss: 0.805701]\n",
      "epoch:48 step:37643 [D loss: 0.697877, acc.: 53.91%] [G loss: 0.804663]\n",
      "epoch:48 step:37644 [D loss: 0.635461, acc.: 71.09%] [G loss: 0.776932]\n",
      "epoch:48 step:37645 [D loss: 0.659135, acc.: 63.28%] [G loss: 0.803058]\n",
      "epoch:48 step:37646 [D loss: 0.633427, acc.: 60.16%] [G loss: 0.776420]\n",
      "epoch:48 step:37647 [D loss: 0.643872, acc.: 60.16%] [G loss: 0.797504]\n",
      "epoch:48 step:37648 [D loss: 0.692226, acc.: 58.59%] [G loss: 0.787391]\n",
      "epoch:48 step:37649 [D loss: 0.686453, acc.: 57.03%] [G loss: 0.800778]\n",
      "epoch:48 step:37650 [D loss: 0.681232, acc.: 57.81%] [G loss: 0.765962]\n",
      "epoch:48 step:37651 [D loss: 0.679692, acc.: 55.47%] [G loss: 0.771274]\n",
      "epoch:48 step:37652 [D loss: 0.761281, acc.: 39.06%] [G loss: 0.730594]\n",
      "epoch:48 step:37653 [D loss: 0.682669, acc.: 46.09%] [G loss: 0.839309]\n",
      "epoch:48 step:37654 [D loss: 0.711278, acc.: 44.53%] [G loss: 0.859577]\n",
      "epoch:48 step:37655 [D loss: 0.664926, acc.: 59.38%] [G loss: 0.789016]\n",
      "epoch:48 step:37656 [D loss: 0.688926, acc.: 58.59%] [G loss: 0.851061]\n",
      "epoch:48 step:37657 [D loss: 0.695107, acc.: 52.34%] [G loss: 0.900336]\n",
      "epoch:48 step:37658 [D loss: 0.641604, acc.: 59.38%] [G loss: 1.002844]\n",
      "epoch:48 step:37659 [D loss: 0.680238, acc.: 56.25%] [G loss: 0.804067]\n",
      "epoch:48 step:37660 [D loss: 0.643626, acc.: 67.97%] [G loss: 0.863799]\n",
      "epoch:48 step:37661 [D loss: 0.643309, acc.: 62.50%] [G loss: 0.818359]\n",
      "epoch:48 step:37662 [D loss: 0.763692, acc.: 43.75%] [G loss: 0.941625]\n",
      "epoch:48 step:37663 [D loss: 0.679069, acc.: 53.91%] [G loss: 0.879388]\n",
      "epoch:48 step:37664 [D loss: 0.608732, acc.: 71.88%] [G loss: 0.841078]\n",
      "epoch:48 step:37665 [D loss: 0.672848, acc.: 55.47%] [G loss: 0.893561]\n",
      "epoch:48 step:37666 [D loss: 0.715651, acc.: 52.34%] [G loss: 0.795264]\n",
      "epoch:48 step:37667 [D loss: 0.686553, acc.: 57.03%] [G loss: 0.771838]\n",
      "epoch:48 step:37668 [D loss: 0.710776, acc.: 51.56%] [G loss: 0.789603]\n",
      "epoch:48 step:37669 [D loss: 0.685472, acc.: 57.81%] [G loss: 0.772289]\n",
      "epoch:48 step:37670 [D loss: 0.676047, acc.: 53.91%] [G loss: 0.952342]\n",
      "epoch:48 step:37671 [D loss: 0.672984, acc.: 57.81%] [G loss: 0.808880]\n",
      "epoch:48 step:37672 [D loss: 0.651060, acc.: 60.94%] [G loss: 0.911577]\n",
      "epoch:48 step:37673 [D loss: 0.661626, acc.: 60.94%] [G loss: 0.831683]\n",
      "epoch:48 step:37674 [D loss: 0.692992, acc.: 54.69%] [G loss: 0.946714]\n",
      "epoch:48 step:37675 [D loss: 0.711939, acc.: 47.66%] [G loss: 0.867834]\n",
      "epoch:48 step:37676 [D loss: 0.716628, acc.: 46.88%] [G loss: 0.911361]\n",
      "epoch:48 step:37677 [D loss: 0.622004, acc.: 70.31%] [G loss: 0.917112]\n",
      "epoch:48 step:37678 [D loss: 0.781883, acc.: 35.16%] [G loss: 0.681471]\n",
      "epoch:48 step:37679 [D loss: 0.672937, acc.: 62.50%] [G loss: 0.847447]\n",
      "epoch:48 step:37680 [D loss: 0.654108, acc.: 68.75%] [G loss: 0.815923]\n",
      "epoch:48 step:37681 [D loss: 0.698564, acc.: 53.91%] [G loss: 0.869337]\n",
      "epoch:48 step:37682 [D loss: 0.649488, acc.: 60.16%] [G loss: 0.814643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37683 [D loss: 0.698371, acc.: 52.34%] [G loss: 0.649081]\n",
      "epoch:48 step:37684 [D loss: 0.671023, acc.: 59.38%] [G loss: 0.837708]\n",
      "epoch:48 step:37685 [D loss: 0.689206, acc.: 53.12%] [G loss: 0.867651]\n",
      "epoch:48 step:37686 [D loss: 0.709264, acc.: 53.12%] [G loss: 0.713454]\n",
      "epoch:48 step:37687 [D loss: 0.735339, acc.: 49.22%] [G loss: 0.782510]\n",
      "epoch:48 step:37688 [D loss: 0.633358, acc.: 67.97%] [G loss: 0.886881]\n",
      "epoch:48 step:37689 [D loss: 0.637328, acc.: 68.75%] [G loss: 0.840579]\n",
      "epoch:48 step:37690 [D loss: 0.676327, acc.: 57.03%] [G loss: 0.840231]\n",
      "epoch:48 step:37691 [D loss: 0.678242, acc.: 53.91%] [G loss: 0.897360]\n",
      "epoch:48 step:37692 [D loss: 0.679499, acc.: 52.34%] [G loss: 0.781175]\n",
      "epoch:48 step:37693 [D loss: 0.758450, acc.: 41.41%] [G loss: 0.844262]\n",
      "epoch:48 step:37694 [D loss: 0.655334, acc.: 63.28%] [G loss: 0.822075]\n",
      "epoch:48 step:37695 [D loss: 0.555508, acc.: 82.03%] [G loss: 0.870560]\n",
      "epoch:48 step:37696 [D loss: 0.676951, acc.: 57.81%] [G loss: 0.838262]\n",
      "epoch:48 step:37697 [D loss: 0.673670, acc.: 53.91%] [G loss: 0.850852]\n",
      "epoch:48 step:37698 [D loss: 0.609074, acc.: 72.66%] [G loss: 0.904073]\n",
      "epoch:48 step:37699 [D loss: 0.683512, acc.: 54.69%] [G loss: 0.745982]\n",
      "epoch:48 step:37700 [D loss: 0.670096, acc.: 60.94%] [G loss: 0.788295]\n",
      "epoch:48 step:37701 [D loss: 0.732787, acc.: 46.09%] [G loss: 0.736997]\n",
      "epoch:48 step:37702 [D loss: 0.713058, acc.: 51.56%] [G loss: 0.840883]\n",
      "epoch:48 step:37703 [D loss: 0.685823, acc.: 57.03%] [G loss: 0.713054]\n",
      "epoch:48 step:37704 [D loss: 0.730762, acc.: 42.97%] [G loss: 0.703945]\n",
      "epoch:48 step:37705 [D loss: 0.679602, acc.: 54.69%] [G loss: 0.782879]\n",
      "epoch:48 step:37706 [D loss: 0.640182, acc.: 63.28%] [G loss: 0.806880]\n",
      "epoch:48 step:37707 [D loss: 0.640939, acc.: 61.72%] [G loss: 0.834882]\n",
      "epoch:48 step:37708 [D loss: 0.742367, acc.: 46.09%] [G loss: 0.695695]\n",
      "epoch:48 step:37709 [D loss: 0.672396, acc.: 59.38%] [G loss: 0.796448]\n",
      "epoch:48 step:37710 [D loss: 0.649644, acc.: 62.50%] [G loss: 0.855396]\n",
      "epoch:48 step:37711 [D loss: 0.681729, acc.: 59.38%] [G loss: 0.794642]\n",
      "epoch:48 step:37712 [D loss: 0.675598, acc.: 57.81%] [G loss: 0.760727]\n",
      "epoch:48 step:37713 [D loss: 0.701645, acc.: 50.78%] [G loss: 0.770460]\n",
      "epoch:48 step:37714 [D loss: 0.636765, acc.: 63.28%] [G loss: 0.776968]\n",
      "epoch:48 step:37715 [D loss: 0.607273, acc.: 67.97%] [G loss: 0.771896]\n",
      "epoch:48 step:37716 [D loss: 0.642928, acc.: 64.84%] [G loss: 0.868568]\n",
      "epoch:48 step:37717 [D loss: 0.661832, acc.: 61.72%] [G loss: 0.734746]\n",
      "epoch:48 step:37718 [D loss: 0.759945, acc.: 38.28%] [G loss: 0.835177]\n",
      "epoch:48 step:37719 [D loss: 0.680914, acc.: 53.91%] [G loss: 0.909030]\n",
      "epoch:48 step:37720 [D loss: 0.705471, acc.: 54.69%] [G loss: 0.864541]\n",
      "epoch:48 step:37721 [D loss: 0.698388, acc.: 54.69%] [G loss: 0.740472]\n",
      "epoch:48 step:37722 [D loss: 0.691330, acc.: 52.34%] [G loss: 0.814658]\n",
      "epoch:48 step:37723 [D loss: 0.655735, acc.: 53.91%] [G loss: 0.791482]\n",
      "epoch:48 step:37724 [D loss: 0.702678, acc.: 53.12%] [G loss: 0.815587]\n",
      "epoch:48 step:37725 [D loss: 0.716096, acc.: 46.09%] [G loss: 0.782386]\n",
      "epoch:48 step:37726 [D loss: 0.667731, acc.: 60.16%] [G loss: 0.816449]\n",
      "epoch:48 step:37727 [D loss: 0.666514, acc.: 57.81%] [G loss: 0.746618]\n",
      "epoch:48 step:37728 [D loss: 0.708132, acc.: 50.00%] [G loss: 0.834008]\n",
      "epoch:48 step:37729 [D loss: 0.750444, acc.: 44.53%] [G loss: 0.805601]\n",
      "epoch:48 step:37730 [D loss: 0.662289, acc.: 59.38%] [G loss: 0.893769]\n",
      "epoch:48 step:37731 [D loss: 0.636896, acc.: 65.62%] [G loss: 0.856625]\n",
      "epoch:48 step:37732 [D loss: 0.697918, acc.: 50.78%] [G loss: 0.725339]\n",
      "epoch:48 step:37733 [D loss: 0.671637, acc.: 56.25%] [G loss: 0.730949]\n",
      "epoch:48 step:37734 [D loss: 0.721514, acc.: 46.88%] [G loss: 0.718972]\n",
      "epoch:48 step:37735 [D loss: 0.713251, acc.: 51.56%] [G loss: 0.770490]\n",
      "epoch:48 step:37736 [D loss: 0.672482, acc.: 57.03%] [G loss: 0.810014]\n",
      "epoch:48 step:37737 [D loss: 0.658467, acc.: 56.25%] [G loss: 0.800993]\n",
      "epoch:48 step:37738 [D loss: 0.641037, acc.: 65.62%] [G loss: 0.762038]\n",
      "epoch:48 step:37739 [D loss: 0.674255, acc.: 59.38%] [G loss: 0.912152]\n",
      "epoch:48 step:37740 [D loss: 0.645990, acc.: 60.94%] [G loss: 0.845526]\n",
      "epoch:48 step:37741 [D loss: 0.716671, acc.: 49.22%] [G loss: 0.823933]\n",
      "epoch:48 step:37742 [D loss: 0.720611, acc.: 52.34%] [G loss: 0.850482]\n",
      "epoch:48 step:37743 [D loss: 0.656011, acc.: 60.16%] [G loss: 0.787348]\n",
      "epoch:48 step:37744 [D loss: 0.673182, acc.: 60.16%] [G loss: 0.841557]\n",
      "epoch:48 step:37745 [D loss: 0.707570, acc.: 52.34%] [G loss: 0.803257]\n",
      "epoch:48 step:37746 [D loss: 0.593923, acc.: 73.44%] [G loss: 0.872513]\n",
      "epoch:48 step:37747 [D loss: 0.700307, acc.: 46.88%] [G loss: 0.757852]\n",
      "epoch:48 step:37748 [D loss: 0.600998, acc.: 74.22%] [G loss: 0.833961]\n",
      "epoch:48 step:37749 [D loss: 0.668602, acc.: 58.59%] [G loss: 0.870575]\n",
      "epoch:48 step:37750 [D loss: 0.683312, acc.: 56.25%] [G loss: 0.819698]\n",
      "epoch:48 step:37751 [D loss: 0.661193, acc.: 60.16%] [G loss: 0.778787]\n",
      "epoch:48 step:37752 [D loss: 0.680788, acc.: 53.91%] [G loss: 0.878110]\n",
      "epoch:48 step:37753 [D loss: 0.590366, acc.: 73.44%] [G loss: 0.841109]\n",
      "epoch:48 step:37754 [D loss: 0.665010, acc.: 62.50%] [G loss: 0.812178]\n",
      "epoch:48 step:37755 [D loss: 0.759127, acc.: 43.75%] [G loss: 0.799843]\n",
      "epoch:48 step:37756 [D loss: 0.753696, acc.: 39.84%] [G loss: 0.739203]\n",
      "epoch:48 step:37757 [D loss: 0.635766, acc.: 67.97%] [G loss: 0.727032]\n",
      "epoch:48 step:37758 [D loss: 0.647359, acc.: 61.72%] [G loss: 0.816419]\n",
      "epoch:48 step:37759 [D loss: 0.688956, acc.: 57.03%] [G loss: 0.826064]\n",
      "epoch:48 step:37760 [D loss: 0.607378, acc.: 69.53%] [G loss: 0.951939]\n",
      "epoch:48 step:37761 [D loss: 0.720533, acc.: 50.78%] [G loss: 0.807008]\n",
      "epoch:48 step:37762 [D loss: 0.647147, acc.: 60.94%] [G loss: 0.867196]\n",
      "epoch:48 step:37763 [D loss: 0.653283, acc.: 62.50%] [G loss: 0.788598]\n",
      "epoch:48 step:37764 [D loss: 0.725233, acc.: 49.22%] [G loss: 0.739086]\n",
      "epoch:48 step:37765 [D loss: 0.734517, acc.: 47.66%] [G loss: 0.750053]\n",
      "epoch:48 step:37766 [D loss: 0.630839, acc.: 68.75%] [G loss: 0.755870]\n",
      "epoch:48 step:37767 [D loss: 0.653457, acc.: 59.38%] [G loss: 0.792529]\n",
      "epoch:48 step:37768 [D loss: 0.699776, acc.: 48.44%] [G loss: 0.671782]\n",
      "epoch:48 step:37769 [D loss: 0.711906, acc.: 49.22%] [G loss: 0.865114]\n",
      "epoch:48 step:37770 [D loss: 0.653294, acc.: 63.28%] [G loss: 0.781338]\n",
      "epoch:48 step:37771 [D loss: 0.611652, acc.: 67.97%] [G loss: 0.843867]\n",
      "epoch:48 step:37772 [D loss: 0.715173, acc.: 46.88%] [G loss: 0.789396]\n",
      "epoch:48 step:37773 [D loss: 0.686858, acc.: 55.47%] [G loss: 0.861664]\n",
      "epoch:48 step:37774 [D loss: 0.687595, acc.: 50.00%] [G loss: 0.786237]\n",
      "epoch:48 step:37775 [D loss: 0.705051, acc.: 53.12%] [G loss: 0.769953]\n",
      "epoch:48 step:37776 [D loss: 0.644299, acc.: 64.06%] [G loss: 0.743684]\n",
      "epoch:48 step:37777 [D loss: 0.694101, acc.: 56.25%] [G loss: 0.755033]\n",
      "epoch:48 step:37778 [D loss: 0.672960, acc.: 60.16%] [G loss: 0.894377]\n",
      "epoch:48 step:37779 [D loss: 0.735905, acc.: 43.75%] [G loss: 0.819456]\n",
      "epoch:48 step:37780 [D loss: 0.687488, acc.: 57.03%] [G loss: 0.785807]\n",
      "epoch:48 step:37781 [D loss: 0.622437, acc.: 72.66%] [G loss: 0.911517]\n",
      "epoch:48 step:37782 [D loss: 0.620845, acc.: 69.53%] [G loss: 0.881389]\n",
      "epoch:48 step:37783 [D loss: 0.671799, acc.: 55.47%] [G loss: 0.830469]\n",
      "epoch:48 step:37784 [D loss: 0.661070, acc.: 63.28%] [G loss: 0.815266]\n",
      "epoch:48 step:37785 [D loss: 0.750933, acc.: 42.19%] [G loss: 0.767932]\n",
      "epoch:48 step:37786 [D loss: 0.636398, acc.: 67.97%] [G loss: 0.809041]\n",
      "epoch:48 step:37787 [D loss: 0.675642, acc.: 55.47%] [G loss: 0.714958]\n",
      "epoch:48 step:37788 [D loss: 0.657412, acc.: 57.81%] [G loss: 0.809763]\n",
      "epoch:48 step:37789 [D loss: 0.670504, acc.: 56.25%] [G loss: 0.783620]\n",
      "epoch:48 step:37790 [D loss: 0.621130, acc.: 69.53%] [G loss: 0.793850]\n",
      "epoch:48 step:37791 [D loss: 0.683245, acc.: 58.59%] [G loss: 0.830059]\n",
      "epoch:48 step:37792 [D loss: 0.694853, acc.: 54.69%] [G loss: 0.880289]\n",
      "epoch:48 step:37793 [D loss: 0.780793, acc.: 40.62%] [G loss: 0.749476]\n",
      "epoch:48 step:37794 [D loss: 0.598807, acc.: 77.34%] [G loss: 0.826503]\n",
      "epoch:48 step:37795 [D loss: 0.580857, acc.: 79.69%] [G loss: 0.806208]\n",
      "epoch:48 step:37796 [D loss: 0.700322, acc.: 57.81%] [G loss: 0.707225]\n",
      "epoch:48 step:37797 [D loss: 0.626495, acc.: 71.88%] [G loss: 0.798289]\n",
      "epoch:48 step:37798 [D loss: 0.717823, acc.: 53.91%] [G loss: 0.810810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37799 [D loss: 0.674243, acc.: 61.72%] [G loss: 0.786767]\n",
      "epoch:48 step:37800 [D loss: 0.702505, acc.: 48.44%] [G loss: 0.753978]\n",
      "epoch:48 step:37801 [D loss: 0.745874, acc.: 47.66%] [G loss: 0.802945]\n",
      "epoch:48 step:37802 [D loss: 0.710808, acc.: 53.91%] [G loss: 0.824173]\n",
      "epoch:48 step:37803 [D loss: 0.758210, acc.: 42.19%] [G loss: 0.750147]\n",
      "epoch:48 step:37804 [D loss: 0.678530, acc.: 53.91%] [G loss: 0.872503]\n",
      "epoch:48 step:37805 [D loss: 0.682870, acc.: 57.81%] [G loss: 0.842344]\n",
      "epoch:48 step:37806 [D loss: 0.659263, acc.: 63.28%] [G loss: 0.891034]\n",
      "epoch:48 step:37807 [D loss: 0.651799, acc.: 62.50%] [G loss: 0.753636]\n",
      "epoch:48 step:37808 [D loss: 0.629629, acc.: 67.19%] [G loss: 0.875336]\n",
      "epoch:48 step:37809 [D loss: 0.666433, acc.: 61.72%] [G loss: 0.805858]\n",
      "epoch:48 step:37810 [D loss: 0.686060, acc.: 52.34%] [G loss: 0.828654]\n",
      "epoch:48 step:37811 [D loss: 0.701787, acc.: 55.47%] [G loss: 0.774674]\n",
      "epoch:48 step:37812 [D loss: 0.685273, acc.: 55.47%] [G loss: 0.858771]\n",
      "epoch:48 step:37813 [D loss: 0.720179, acc.: 51.56%] [G loss: 0.741985]\n",
      "epoch:48 step:37814 [D loss: 0.666306, acc.: 58.59%] [G loss: 0.840643]\n",
      "epoch:48 step:37815 [D loss: 0.572503, acc.: 78.12%] [G loss: 0.860866]\n",
      "epoch:48 step:37816 [D loss: 0.731988, acc.: 47.66%] [G loss: 0.811277]\n",
      "epoch:48 step:37817 [D loss: 0.720387, acc.: 49.22%] [G loss: 0.743410]\n",
      "epoch:48 step:37818 [D loss: 0.676652, acc.: 53.12%] [G loss: 0.726058]\n",
      "epoch:48 step:37819 [D loss: 0.771741, acc.: 35.94%] [G loss: 0.734720]\n",
      "epoch:48 step:37820 [D loss: 0.729011, acc.: 45.31%] [G loss: 0.819740]\n",
      "epoch:48 step:37821 [D loss: 0.674814, acc.: 53.12%] [G loss: 0.850643]\n",
      "epoch:48 step:37822 [D loss: 0.669027, acc.: 59.38%] [G loss: 0.754759]\n",
      "epoch:48 step:37823 [D loss: 0.624774, acc.: 67.19%] [G loss: 0.812377]\n",
      "epoch:48 step:37824 [D loss: 0.687845, acc.: 48.44%] [G loss: 0.761543]\n",
      "epoch:48 step:37825 [D loss: 0.625795, acc.: 63.28%] [G loss: 0.859201]\n",
      "epoch:48 step:37826 [D loss: 0.689117, acc.: 54.69%] [G loss: 0.849233]\n",
      "epoch:48 step:37827 [D loss: 0.665630, acc.: 62.50%] [G loss: 0.738652]\n",
      "epoch:48 step:37828 [D loss: 0.638410, acc.: 60.16%] [G loss: 0.766151]\n",
      "epoch:48 step:37829 [D loss: 0.647101, acc.: 64.84%] [G loss: 0.837487]\n",
      "epoch:48 step:37830 [D loss: 0.671285, acc.: 56.25%] [G loss: 0.860078]\n",
      "epoch:48 step:37831 [D loss: 0.683872, acc.: 53.91%] [G loss: 0.926938]\n",
      "epoch:48 step:37832 [D loss: 0.645556, acc.: 67.97%] [G loss: 0.817286]\n",
      "epoch:48 step:37833 [D loss: 0.701990, acc.: 52.34%] [G loss: 0.764586]\n",
      "epoch:48 step:37834 [D loss: 0.701773, acc.: 53.12%] [G loss: 0.765553]\n",
      "epoch:48 step:37835 [D loss: 0.651042, acc.: 63.28%] [G loss: 0.838437]\n",
      "epoch:48 step:37836 [D loss: 0.743198, acc.: 46.09%] [G loss: 0.776083]\n",
      "epoch:48 step:37837 [D loss: 0.729707, acc.: 39.84%] [G loss: 0.800661]\n",
      "epoch:48 step:37838 [D loss: 0.667907, acc.: 58.59%] [G loss: 0.735690]\n",
      "epoch:48 step:37839 [D loss: 0.694425, acc.: 51.56%] [G loss: 0.835208]\n",
      "epoch:48 step:37840 [D loss: 0.661910, acc.: 60.94%] [G loss: 0.859954]\n",
      "epoch:48 step:37841 [D loss: 0.620620, acc.: 68.75%] [G loss: 0.805740]\n",
      "epoch:48 step:37842 [D loss: 0.696967, acc.: 54.69%] [G loss: 0.885914]\n",
      "epoch:48 step:37843 [D loss: 0.684683, acc.: 61.72%] [G loss: 0.882239]\n",
      "epoch:48 step:37844 [D loss: 0.731615, acc.: 44.53%] [G loss: 0.780666]\n",
      "epoch:48 step:37845 [D loss: 0.671473, acc.: 60.16%] [G loss: 0.745591]\n",
      "epoch:48 step:37846 [D loss: 0.677845, acc.: 57.03%] [G loss: 0.795703]\n",
      "epoch:48 step:37847 [D loss: 0.700084, acc.: 53.12%] [G loss: 0.756009]\n",
      "epoch:48 step:37848 [D loss: 0.768616, acc.: 41.41%] [G loss: 0.877525]\n",
      "epoch:48 step:37849 [D loss: 0.650038, acc.: 61.72%] [G loss: 0.793609]\n",
      "epoch:48 step:37850 [D loss: 0.690264, acc.: 58.59%] [G loss: 0.841644]\n",
      "epoch:48 step:37851 [D loss: 0.639386, acc.: 64.06%] [G loss: 0.759495]\n",
      "epoch:48 step:37852 [D loss: 0.703556, acc.: 53.91%] [G loss: 0.740612]\n",
      "epoch:48 step:37853 [D loss: 0.604288, acc.: 67.19%] [G loss: 0.758921]\n",
      "epoch:48 step:37854 [D loss: 0.661313, acc.: 60.16%] [G loss: 0.738950]\n",
      "epoch:48 step:37855 [D loss: 0.800515, acc.: 37.50%] [G loss: 0.775297]\n",
      "epoch:48 step:37856 [D loss: 0.727705, acc.: 50.78%] [G loss: 0.877623]\n",
      "epoch:48 step:37857 [D loss: 0.697713, acc.: 53.12%] [G loss: 0.751602]\n",
      "epoch:48 step:37858 [D loss: 0.617312, acc.: 67.19%] [G loss: 0.850162]\n",
      "epoch:48 step:37859 [D loss: 0.710164, acc.: 48.44%] [G loss: 0.809969]\n",
      "epoch:48 step:37860 [D loss: 0.628718, acc.: 69.53%] [G loss: 0.845464]\n",
      "epoch:48 step:37861 [D loss: 0.677352, acc.: 56.25%] [G loss: 0.890450]\n",
      "epoch:48 step:37862 [D loss: 0.633374, acc.: 64.06%] [G loss: 0.844638]\n",
      "epoch:48 step:37863 [D loss: 0.668616, acc.: 60.94%] [G loss: 0.787966]\n",
      "epoch:48 step:37864 [D loss: 0.664009, acc.: 60.16%] [G loss: 0.781144]\n",
      "epoch:48 step:37865 [D loss: 0.676871, acc.: 57.81%] [G loss: 0.896308]\n",
      "epoch:48 step:37866 [D loss: 0.659154, acc.: 64.06%] [G loss: 0.820469]\n",
      "epoch:48 step:37867 [D loss: 0.625249, acc.: 66.41%] [G loss: 0.804879]\n",
      "epoch:48 step:37868 [D loss: 0.714527, acc.: 52.34%] [G loss: 0.837582]\n",
      "epoch:48 step:37869 [D loss: 0.586974, acc.: 75.00%] [G loss: 0.778994]\n",
      "epoch:48 step:37870 [D loss: 0.759018, acc.: 39.84%] [G loss: 0.929873]\n",
      "epoch:48 step:37871 [D loss: 0.581610, acc.: 78.12%] [G loss: 0.882167]\n",
      "epoch:48 step:37872 [D loss: 0.782654, acc.: 32.81%] [G loss: 0.780326]\n",
      "epoch:48 step:37873 [D loss: 0.673034, acc.: 59.38%] [G loss: 0.837760]\n",
      "epoch:48 step:37874 [D loss: 0.625750, acc.: 70.31%] [G loss: 0.844674]\n",
      "epoch:48 step:37875 [D loss: 0.672181, acc.: 60.94%] [G loss: 0.668392]\n",
      "epoch:48 step:37876 [D loss: 0.739150, acc.: 42.19%] [G loss: 0.837063]\n",
      "epoch:48 step:37877 [D loss: 0.681487, acc.: 60.94%] [G loss: 0.796118]\n",
      "epoch:48 step:37878 [D loss: 0.706749, acc.: 50.78%] [G loss: 0.850690]\n",
      "epoch:48 step:37879 [D loss: 0.734147, acc.: 47.66%] [G loss: 0.889872]\n",
      "epoch:48 step:37880 [D loss: 0.620253, acc.: 62.50%] [G loss: 0.884830]\n",
      "epoch:48 step:37881 [D loss: 0.630494, acc.: 71.88%] [G loss: 0.757749]\n",
      "epoch:48 step:37882 [D loss: 0.630576, acc.: 63.28%] [G loss: 0.842166]\n",
      "epoch:48 step:37883 [D loss: 0.726061, acc.: 50.78%] [G loss: 0.827375]\n",
      "epoch:48 step:37884 [D loss: 0.634559, acc.: 67.97%] [G loss: 0.722282]\n",
      "epoch:48 step:37885 [D loss: 0.747618, acc.: 42.19%] [G loss: 0.726931]\n",
      "epoch:48 step:37886 [D loss: 0.706361, acc.: 51.56%] [G loss: 0.840419]\n",
      "epoch:48 step:37887 [D loss: 0.660047, acc.: 64.84%] [G loss: 0.731984]\n",
      "epoch:48 step:37888 [D loss: 0.730467, acc.: 43.75%] [G loss: 0.734309]\n",
      "epoch:48 step:37889 [D loss: 0.588843, acc.: 78.12%] [G loss: 0.850983]\n",
      "epoch:48 step:37890 [D loss: 0.666716, acc.: 58.59%] [G loss: 0.700527]\n",
      "epoch:48 step:37891 [D loss: 0.638732, acc.: 61.72%] [G loss: 0.918087]\n",
      "epoch:48 step:37892 [D loss: 0.638179, acc.: 67.19%] [G loss: 0.809153]\n",
      "epoch:48 step:37893 [D loss: 0.684056, acc.: 57.81%] [G loss: 0.852259]\n",
      "epoch:48 step:37894 [D loss: 0.684252, acc.: 54.69%] [G loss: 0.853362]\n",
      "epoch:48 step:37895 [D loss: 0.677221, acc.: 60.16%] [G loss: 0.835475]\n",
      "epoch:48 step:37896 [D loss: 0.734160, acc.: 49.22%] [G loss: 0.685497]\n",
      "epoch:48 step:37897 [D loss: 0.723793, acc.: 49.22%] [G loss: 0.801202]\n",
      "epoch:48 step:37898 [D loss: 0.668301, acc.: 64.06%] [G loss: 0.826174]\n",
      "epoch:48 step:37899 [D loss: 0.675604, acc.: 57.81%] [G loss: 0.860167]\n",
      "epoch:48 step:37900 [D loss: 0.659514, acc.: 57.03%] [G loss: 0.741281]\n",
      "epoch:48 step:37901 [D loss: 0.704832, acc.: 52.34%] [G loss: 0.757906]\n",
      "epoch:48 step:37902 [D loss: 0.690585, acc.: 57.03%] [G loss: 0.728868]\n",
      "epoch:48 step:37903 [D loss: 0.626897, acc.: 66.41%] [G loss: 0.866489]\n",
      "epoch:48 step:37904 [D loss: 0.674400, acc.: 57.03%] [G loss: 0.854750]\n",
      "epoch:48 step:37905 [D loss: 0.711122, acc.: 50.78%] [G loss: 0.756502]\n",
      "epoch:48 step:37906 [D loss: 0.709203, acc.: 51.56%] [G loss: 0.790410]\n",
      "epoch:48 step:37907 [D loss: 0.640702, acc.: 64.06%] [G loss: 0.795697]\n",
      "epoch:48 step:37908 [D loss: 0.658566, acc.: 67.97%] [G loss: 0.709770]\n",
      "epoch:48 step:37909 [D loss: 0.645597, acc.: 61.72%] [G loss: 0.835051]\n",
      "epoch:48 step:37910 [D loss: 0.643943, acc.: 65.62%] [G loss: 0.821519]\n",
      "epoch:48 step:37911 [D loss: 0.713532, acc.: 51.56%] [G loss: 0.757984]\n",
      "epoch:48 step:37912 [D loss: 0.722021, acc.: 44.53%] [G loss: 0.761760]\n",
      "epoch:48 step:37913 [D loss: 0.692855, acc.: 53.12%] [G loss: 0.755168]\n",
      "epoch:48 step:37914 [D loss: 0.674561, acc.: 57.03%] [G loss: 0.846214]\n",
      "epoch:48 step:37915 [D loss: 0.640431, acc.: 66.41%] [G loss: 0.832446]\n",
      "epoch:48 step:37916 [D loss: 0.690259, acc.: 52.34%] [G loss: 0.857394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37917 [D loss: 0.682103, acc.: 56.25%] [G loss: 0.758343]\n",
      "epoch:48 step:37918 [D loss: 0.665586, acc.: 57.81%] [G loss: 0.826138]\n",
      "epoch:48 step:37919 [D loss: 0.750062, acc.: 46.09%] [G loss: 0.742408]\n",
      "epoch:48 step:37920 [D loss: 0.733941, acc.: 48.44%] [G loss: 0.655501]\n",
      "epoch:48 step:37921 [D loss: 0.710281, acc.: 46.88%] [G loss: 0.791950]\n",
      "epoch:48 step:37922 [D loss: 0.654728, acc.: 59.38%] [G loss: 0.747185]\n",
      "epoch:48 step:37923 [D loss: 0.723626, acc.: 43.75%] [G loss: 0.871770]\n",
      "epoch:48 step:37924 [D loss: 0.715473, acc.: 44.53%] [G loss: 0.924428]\n",
      "epoch:48 step:37925 [D loss: 0.803323, acc.: 34.38%] [G loss: 0.736402]\n",
      "epoch:48 step:37926 [D loss: 0.663402, acc.: 54.69%] [G loss: 0.779813]\n",
      "epoch:48 step:37927 [D loss: 0.727659, acc.: 45.31%] [G loss: 0.843565]\n",
      "epoch:48 step:37928 [D loss: 0.684130, acc.: 53.91%] [G loss: 0.886935]\n",
      "epoch:48 step:37929 [D loss: 0.706897, acc.: 46.09%] [G loss: 0.765707]\n",
      "epoch:48 step:37930 [D loss: 0.734101, acc.: 51.56%] [G loss: 0.728848]\n",
      "epoch:48 step:37931 [D loss: 0.646520, acc.: 64.06%] [G loss: 0.814045]\n",
      "epoch:48 step:37932 [D loss: 0.649620, acc.: 65.62%] [G loss: 0.795760]\n",
      "epoch:48 step:37933 [D loss: 0.661640, acc.: 57.03%] [G loss: 0.869811]\n",
      "epoch:48 step:37934 [D loss: 0.635968, acc.: 67.19%] [G loss: 0.792768]\n",
      "epoch:48 step:37935 [D loss: 0.722846, acc.: 50.00%] [G loss: 0.778911]\n",
      "epoch:48 step:37936 [D loss: 0.635167, acc.: 67.19%] [G loss: 0.716064]\n",
      "epoch:48 step:37937 [D loss: 0.687175, acc.: 56.25%] [G loss: 0.833747]\n",
      "epoch:48 step:37938 [D loss: 0.667681, acc.: 61.72%] [G loss: 0.834297]\n",
      "epoch:48 step:37939 [D loss: 0.656844, acc.: 58.59%] [G loss: 0.858945]\n",
      "epoch:48 step:37940 [D loss: 0.683904, acc.: 58.59%] [G loss: 0.901345]\n",
      "epoch:48 step:37941 [D loss: 0.654463, acc.: 61.72%] [G loss: 0.824841]\n",
      "epoch:48 step:37942 [D loss: 0.654784, acc.: 67.19%] [G loss: 0.863857]\n",
      "epoch:48 step:37943 [D loss: 0.705233, acc.: 50.00%] [G loss: 0.813346]\n",
      "epoch:48 step:37944 [D loss: 0.758373, acc.: 47.66%] [G loss: 0.870500]\n",
      "epoch:48 step:37945 [D loss: 0.675580, acc.: 60.94%] [G loss: 0.780474]\n",
      "epoch:48 step:37946 [D loss: 0.641019, acc.: 66.41%] [G loss: 0.875254]\n",
      "epoch:48 step:37947 [D loss: 0.660605, acc.: 60.16%] [G loss: 0.817148]\n",
      "epoch:48 step:37948 [D loss: 0.658198, acc.: 64.06%] [G loss: 0.762879]\n",
      "epoch:48 step:37949 [D loss: 0.663005, acc.: 62.50%] [G loss: 0.866089]\n",
      "epoch:48 step:37950 [D loss: 0.601136, acc.: 67.97%] [G loss: 0.866924]\n",
      "epoch:48 step:37951 [D loss: 0.669112, acc.: 55.47%] [G loss: 0.842620]\n",
      "epoch:48 step:37952 [D loss: 0.712119, acc.: 53.12%] [G loss: 0.810812]\n",
      "epoch:48 step:37953 [D loss: 0.622793, acc.: 67.19%] [G loss: 0.766023]\n",
      "epoch:48 step:37954 [D loss: 0.574541, acc.: 78.91%] [G loss: 0.898597]\n",
      "epoch:48 step:37955 [D loss: 0.671115, acc.: 59.38%] [G loss: 0.718090]\n",
      "epoch:48 step:37956 [D loss: 0.641755, acc.: 63.28%] [G loss: 0.913632]\n",
      "epoch:48 step:37957 [D loss: 0.620243, acc.: 69.53%] [G loss: 0.813927]\n",
      "epoch:48 step:37958 [D loss: 0.747158, acc.: 42.19%] [G loss: 0.794054]\n",
      "epoch:48 step:37959 [D loss: 0.663868, acc.: 63.28%] [G loss: 0.875815]\n",
      "epoch:48 step:37960 [D loss: 0.685793, acc.: 55.47%] [G loss: 0.787265]\n",
      "epoch:48 step:37961 [D loss: 0.730715, acc.: 50.78%] [G loss: 0.762576]\n",
      "epoch:48 step:37962 [D loss: 0.675080, acc.: 55.47%] [G loss: 0.772517]\n",
      "epoch:48 step:37963 [D loss: 0.710016, acc.: 51.56%] [G loss: 0.861512]\n",
      "epoch:48 step:37964 [D loss: 0.682542, acc.: 55.47%] [G loss: 0.799182]\n",
      "epoch:48 step:37965 [D loss: 0.740509, acc.: 50.00%] [G loss: 0.856266]\n",
      "epoch:48 step:37966 [D loss: 0.660209, acc.: 60.16%] [G loss: 0.799052]\n",
      "epoch:48 step:37967 [D loss: 0.689760, acc.: 51.56%] [G loss: 0.873782]\n",
      "epoch:48 step:37968 [D loss: 0.681963, acc.: 57.03%] [G loss: 0.828314]\n",
      "epoch:48 step:37969 [D loss: 0.640206, acc.: 63.28%] [G loss: 0.890769]\n",
      "epoch:48 step:37970 [D loss: 0.687506, acc.: 53.91%] [G loss: 0.847521]\n",
      "epoch:48 step:37971 [D loss: 0.688646, acc.: 57.81%] [G loss: 0.771049]\n",
      "epoch:48 step:37972 [D loss: 0.647479, acc.: 63.28%] [G loss: 0.766331]\n",
      "epoch:48 step:37973 [D loss: 0.683121, acc.: 55.47%] [G loss: 0.768292]\n",
      "epoch:48 step:37974 [D loss: 0.651737, acc.: 60.94%] [G loss: 0.775733]\n",
      "epoch:48 step:37975 [D loss: 0.659949, acc.: 59.38%] [G loss: 0.811350]\n",
      "epoch:48 step:37976 [D loss: 0.653572, acc.: 59.38%] [G loss: 0.775317]\n",
      "epoch:48 step:37977 [D loss: 0.728593, acc.: 43.75%] [G loss: 0.767326]\n",
      "epoch:48 step:37978 [D loss: 0.657827, acc.: 57.81%] [G loss: 0.877638]\n",
      "epoch:48 step:37979 [D loss: 0.687935, acc.: 54.69%] [G loss: 0.848827]\n",
      "epoch:48 step:37980 [D loss: 0.665689, acc.: 62.50%] [G loss: 0.793678]\n",
      "epoch:48 step:37981 [D loss: 0.609438, acc.: 67.97%] [G loss: 0.838048]\n",
      "epoch:48 step:37982 [D loss: 0.635159, acc.: 61.72%] [G loss: 0.879673]\n",
      "epoch:48 step:37983 [D loss: 0.642651, acc.: 62.50%] [G loss: 0.823006]\n",
      "epoch:48 step:37984 [D loss: 0.670554, acc.: 57.81%] [G loss: 0.876377]\n",
      "epoch:48 step:37985 [D loss: 0.707213, acc.: 53.91%] [G loss: 0.758937]\n",
      "epoch:48 step:37986 [D loss: 0.684559, acc.: 53.91%] [G loss: 0.754884]\n",
      "epoch:48 step:37987 [D loss: 0.637000, acc.: 68.75%] [G loss: 0.776809]\n",
      "epoch:48 step:37988 [D loss: 0.680686, acc.: 51.56%] [G loss: 0.878987]\n",
      "epoch:48 step:37989 [D loss: 0.663971, acc.: 60.94%] [G loss: 0.695354]\n",
      "epoch:48 step:37990 [D loss: 0.653239, acc.: 64.84%] [G loss: 0.791814]\n",
      "epoch:48 step:37991 [D loss: 0.710410, acc.: 55.47%] [G loss: 0.825231]\n",
      "epoch:48 step:37992 [D loss: 0.677737, acc.: 60.94%] [G loss: 0.811057]\n",
      "epoch:48 step:37993 [D loss: 0.638353, acc.: 73.44%] [G loss: 0.748470]\n",
      "epoch:48 step:37994 [D loss: 0.710361, acc.: 51.56%] [G loss: 0.779916]\n",
      "epoch:48 step:37995 [D loss: 0.760571, acc.: 47.66%] [G loss: 0.767276]\n",
      "epoch:48 step:37996 [D loss: 0.773860, acc.: 32.81%] [G loss: 0.810175]\n",
      "epoch:48 step:37997 [D loss: 0.706999, acc.: 52.34%] [G loss: 0.821221]\n",
      "epoch:48 step:37998 [D loss: 0.667326, acc.: 64.06%] [G loss: 0.854880]\n",
      "epoch:48 step:37999 [D loss: 0.698038, acc.: 55.47%] [G loss: 0.876222]\n",
      "epoch:48 step:38000 [D loss: 0.661908, acc.: 58.59%] [G loss: 0.862769]\n",
      "epoch:48 step:38001 [D loss: 0.647043, acc.: 61.72%] [G loss: 0.862613]\n",
      "epoch:48 step:38002 [D loss: 0.725451, acc.: 49.22%] [G loss: 0.748468]\n",
      "epoch:48 step:38003 [D loss: 0.602643, acc.: 77.34%] [G loss: 0.828891]\n",
      "epoch:48 step:38004 [D loss: 0.617534, acc.: 69.53%] [G loss: 0.786900]\n",
      "epoch:48 step:38005 [D loss: 0.671624, acc.: 57.03%] [G loss: 0.858603]\n",
      "epoch:48 step:38006 [D loss: 0.661291, acc.: 60.16%] [G loss: 0.804612]\n",
      "epoch:48 step:38007 [D loss: 0.722174, acc.: 42.97%] [G loss: 0.769324]\n",
      "epoch:48 step:38008 [D loss: 0.735545, acc.: 44.53%] [G loss: 0.792101]\n",
      "epoch:48 step:38009 [D loss: 0.640404, acc.: 66.41%] [G loss: 0.839565]\n",
      "epoch:48 step:38010 [D loss: 0.697090, acc.: 56.25%] [G loss: 0.826228]\n",
      "epoch:48 step:38011 [D loss: 0.735827, acc.: 43.75%] [G loss: 0.793464]\n",
      "epoch:48 step:38012 [D loss: 0.685332, acc.: 54.69%] [G loss: 0.772274]\n",
      "epoch:48 step:38013 [D loss: 0.696714, acc.: 53.91%] [G loss: 0.791997]\n",
      "epoch:48 step:38014 [D loss: 0.701153, acc.: 52.34%] [G loss: 0.846442]\n",
      "epoch:48 step:38015 [D loss: 0.701356, acc.: 53.12%] [G loss: 0.773538]\n",
      "epoch:48 step:38016 [D loss: 0.698613, acc.: 47.66%] [G loss: 0.822830]\n",
      "epoch:48 step:38017 [D loss: 0.603187, acc.: 68.75%] [G loss: 0.763363]\n",
      "epoch:48 step:38018 [D loss: 0.592113, acc.: 75.00%] [G loss: 0.744370]\n",
      "epoch:48 step:38019 [D loss: 0.698631, acc.: 50.00%] [G loss: 0.795844]\n",
      "epoch:48 step:38020 [D loss: 0.712079, acc.: 50.00%] [G loss: 0.753775]\n",
      "epoch:48 step:38021 [D loss: 0.714513, acc.: 49.22%] [G loss: 0.755415]\n",
      "epoch:48 step:38022 [D loss: 0.659334, acc.: 58.59%] [G loss: 0.809370]\n",
      "epoch:48 step:38023 [D loss: 0.690498, acc.: 54.69%] [G loss: 0.788639]\n",
      "epoch:48 step:38024 [D loss: 0.629014, acc.: 66.41%] [G loss: 0.743392]\n",
      "epoch:48 step:38025 [D loss: 0.624274, acc.: 70.31%] [G loss: 0.818936]\n",
      "epoch:48 step:38026 [D loss: 0.694909, acc.: 52.34%] [G loss: 0.859941]\n",
      "epoch:48 step:38027 [D loss: 0.748749, acc.: 38.28%] [G loss: 0.694949]\n",
      "epoch:48 step:38028 [D loss: 0.641576, acc.: 60.16%] [G loss: 0.802689]\n",
      "epoch:48 step:38029 [D loss: 0.706578, acc.: 53.91%] [G loss: 0.807826]\n",
      "epoch:48 step:38030 [D loss: 0.699293, acc.: 53.91%] [G loss: 0.889735]\n",
      "epoch:48 step:38031 [D loss: 0.673036, acc.: 55.47%] [G loss: 0.811577]\n",
      "epoch:48 step:38032 [D loss: 0.679137, acc.: 60.16%] [G loss: 0.847637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38033 [D loss: 0.655074, acc.: 57.81%] [G loss: 0.856277]\n",
      "epoch:48 step:38034 [D loss: 0.740472, acc.: 46.09%] [G loss: 0.823767]\n",
      "epoch:48 step:38035 [D loss: 0.684040, acc.: 53.12%] [G loss: 0.899344]\n",
      "epoch:48 step:38036 [D loss: 0.666317, acc.: 60.16%] [G loss: 0.793810]\n",
      "epoch:48 step:38037 [D loss: 0.662288, acc.: 57.03%] [G loss: 0.904145]\n",
      "epoch:48 step:38038 [D loss: 0.636788, acc.: 67.97%] [G loss: 0.857957]\n",
      "epoch:48 step:38039 [D loss: 0.639630, acc.: 60.94%] [G loss: 0.833488]\n",
      "epoch:48 step:38040 [D loss: 0.764544, acc.: 39.06%] [G loss: 0.717533]\n",
      "epoch:48 step:38041 [D loss: 0.653016, acc.: 65.62%] [G loss: 0.722690]\n",
      "epoch:48 step:38042 [D loss: 0.638986, acc.: 68.75%] [G loss: 0.739287]\n",
      "epoch:48 step:38043 [D loss: 0.679554, acc.: 60.16%] [G loss: 0.877361]\n",
      "epoch:48 step:38044 [D loss: 0.709009, acc.: 51.56%] [G loss: 0.818545]\n",
      "epoch:48 step:38045 [D loss: 0.662496, acc.: 56.25%] [G loss: 0.861921]\n",
      "epoch:48 step:38046 [D loss: 0.688357, acc.: 57.03%] [G loss: 0.814136]\n",
      "epoch:48 step:38047 [D loss: 0.601283, acc.: 70.31%] [G loss: 0.827540]\n",
      "epoch:48 step:38048 [D loss: 0.646536, acc.: 56.25%] [G loss: 0.832003]\n",
      "epoch:48 step:38049 [D loss: 0.639562, acc.: 65.62%] [G loss: 0.815809]\n",
      "epoch:48 step:38050 [D loss: 0.715428, acc.: 49.22%] [G loss: 0.727258]\n",
      "epoch:48 step:38051 [D loss: 0.719479, acc.: 52.34%] [G loss: 0.702351]\n",
      "epoch:48 step:38052 [D loss: 0.665892, acc.: 62.50%] [G loss: 0.884326]\n",
      "epoch:48 step:38053 [D loss: 0.705634, acc.: 49.22%] [G loss: 0.649370]\n",
      "epoch:48 step:38054 [D loss: 0.655858, acc.: 59.38%] [G loss: 0.807055]\n",
      "epoch:48 step:38055 [D loss: 0.653325, acc.: 68.75%] [G loss: 0.738743]\n",
      "epoch:48 step:38056 [D loss: 0.663311, acc.: 58.59%] [G loss: 0.775839]\n",
      "epoch:48 step:38057 [D loss: 0.672634, acc.: 55.47%] [G loss: 0.774236]\n",
      "epoch:48 step:38058 [D loss: 0.594995, acc.: 75.00%] [G loss: 0.806826]\n",
      "epoch:48 step:38059 [D loss: 0.730021, acc.: 50.78%] [G loss: 0.730630]\n",
      "epoch:48 step:38060 [D loss: 0.682122, acc.: 50.78%] [G loss: 0.814036]\n",
      "epoch:48 step:38061 [D loss: 0.741808, acc.: 45.31%] [G loss: 0.720247]\n",
      "epoch:48 step:38062 [D loss: 0.683272, acc.: 54.69%] [G loss: 0.753485]\n",
      "epoch:48 step:38063 [D loss: 0.675693, acc.: 60.16%] [G loss: 0.776704]\n",
      "epoch:48 step:38064 [D loss: 0.607117, acc.: 74.22%] [G loss: 0.752011]\n",
      "epoch:48 step:38065 [D loss: 0.657769, acc.: 60.94%] [G loss: 0.667522]\n",
      "epoch:48 step:38066 [D loss: 0.689999, acc.: 56.25%] [G loss: 0.755566]\n",
      "epoch:48 step:38067 [D loss: 0.675713, acc.: 58.59%] [G loss: 0.917051]\n",
      "epoch:48 step:38068 [D loss: 0.685468, acc.: 54.69%] [G loss: 0.830068]\n",
      "epoch:48 step:38069 [D loss: 0.679674, acc.: 58.59%] [G loss: 0.797719]\n",
      "epoch:48 step:38070 [D loss: 0.681530, acc.: 60.94%] [G loss: 0.870063]\n",
      "epoch:48 step:38071 [D loss: 0.617786, acc.: 71.88%] [G loss: 0.830352]\n",
      "epoch:48 step:38072 [D loss: 0.630829, acc.: 71.09%] [G loss: 0.873490]\n",
      "epoch:48 step:38073 [D loss: 0.660657, acc.: 55.47%] [G loss: 0.846998]\n",
      "epoch:48 step:38074 [D loss: 0.625017, acc.: 70.31%] [G loss: 0.753438]\n",
      "epoch:48 step:38075 [D loss: 0.614640, acc.: 71.09%] [G loss: 0.886855]\n",
      "epoch:48 step:38076 [D loss: 0.639923, acc.: 61.72%] [G loss: 0.815105]\n",
      "epoch:48 step:38077 [D loss: 0.604899, acc.: 72.66%] [G loss: 0.767620]\n",
      "epoch:48 step:38078 [D loss: 0.650810, acc.: 57.81%] [G loss: 0.886683]\n",
      "epoch:48 step:38079 [D loss: 0.675669, acc.: 55.47%] [G loss: 0.758253]\n",
      "epoch:48 step:38080 [D loss: 0.670400, acc.: 58.59%] [G loss: 0.776653]\n",
      "epoch:48 step:38081 [D loss: 0.704240, acc.: 58.59%] [G loss: 0.863178]\n",
      "epoch:48 step:38082 [D loss: 0.615930, acc.: 72.66%] [G loss: 0.789279]\n",
      "epoch:48 step:38083 [D loss: 0.560596, acc.: 79.69%] [G loss: 0.805993]\n",
      "epoch:48 step:38084 [D loss: 0.784635, acc.: 34.38%] [G loss: 0.737393]\n",
      "epoch:48 step:38085 [D loss: 0.685308, acc.: 56.25%] [G loss: 0.789838]\n",
      "epoch:48 step:38086 [D loss: 0.664792, acc.: 57.03%] [G loss: 0.818001]\n",
      "epoch:48 step:38087 [D loss: 0.675985, acc.: 56.25%] [G loss: 0.804768]\n",
      "epoch:48 step:38088 [D loss: 0.661420, acc.: 59.38%] [G loss: 0.801248]\n",
      "epoch:48 step:38089 [D loss: 0.673688, acc.: 52.34%] [G loss: 0.813638]\n",
      "epoch:48 step:38090 [D loss: 0.608496, acc.: 74.22%] [G loss: 0.893872]\n",
      "epoch:48 step:38091 [D loss: 0.687700, acc.: 55.47%] [G loss: 0.750911]\n",
      "epoch:48 step:38092 [D loss: 0.694154, acc.: 54.69%] [G loss: 0.747356]\n",
      "epoch:48 step:38093 [D loss: 0.632320, acc.: 62.50%] [G loss: 0.827117]\n",
      "epoch:48 step:38094 [D loss: 0.778289, acc.: 40.62%] [G loss: 0.830472]\n",
      "epoch:48 step:38095 [D loss: 0.722068, acc.: 44.53%] [G loss: 0.769107]\n",
      "epoch:48 step:38096 [D loss: 0.733544, acc.: 46.09%] [G loss: 0.711513]\n",
      "epoch:48 step:38097 [D loss: 0.741760, acc.: 46.88%] [G loss: 0.776222]\n",
      "epoch:48 step:38098 [D loss: 0.621540, acc.: 68.75%] [G loss: 0.832398]\n",
      "epoch:48 step:38099 [D loss: 0.701038, acc.: 50.00%] [G loss: 0.801781]\n",
      "epoch:48 step:38100 [D loss: 0.691860, acc.: 58.59%] [G loss: 0.847898]\n",
      "epoch:48 step:38101 [D loss: 0.723645, acc.: 49.22%] [G loss: 0.770358]\n",
      "epoch:48 step:38102 [D loss: 0.711947, acc.: 46.88%] [G loss: 0.763954]\n",
      "epoch:48 step:38103 [D loss: 0.704091, acc.: 51.56%] [G loss: 0.864248]\n",
      "epoch:48 step:38104 [D loss: 0.689091, acc.: 53.12%] [G loss: 0.928936]\n",
      "epoch:48 step:38105 [D loss: 0.733138, acc.: 46.88%] [G loss: 0.804360]\n",
      "epoch:48 step:38106 [D loss: 0.632363, acc.: 70.31%] [G loss: 0.896784]\n",
      "epoch:48 step:38107 [D loss: 0.727640, acc.: 50.00%] [G loss: 0.923511]\n",
      "epoch:48 step:38108 [D loss: 0.642516, acc.: 66.41%] [G loss: 0.736130]\n",
      "epoch:48 step:38109 [D loss: 0.593834, acc.: 76.56%] [G loss: 0.982395]\n",
      "epoch:48 step:38110 [D loss: 0.683446, acc.: 60.94%] [G loss: 0.849856]\n",
      "epoch:48 step:38111 [D loss: 0.747953, acc.: 46.09%] [G loss: 0.625757]\n",
      "epoch:48 step:38112 [D loss: 0.670274, acc.: 59.38%] [G loss: 0.778621]\n",
      "epoch:48 step:38113 [D loss: 0.759840, acc.: 44.53%] [G loss: 0.708379]\n",
      "epoch:48 step:38114 [D loss: 0.677131, acc.: 53.12%] [G loss: 0.850439]\n",
      "epoch:48 step:38115 [D loss: 0.708345, acc.: 54.69%] [G loss: 0.771327]\n",
      "epoch:48 step:38116 [D loss: 0.616703, acc.: 74.22%] [G loss: 0.759591]\n",
      "epoch:48 step:38117 [D loss: 0.706654, acc.: 52.34%] [G loss: 0.779828]\n",
      "epoch:48 step:38118 [D loss: 0.684475, acc.: 54.69%] [G loss: 0.879448]\n",
      "epoch:48 step:38119 [D loss: 0.686891, acc.: 56.25%] [G loss: 0.822533]\n",
      "epoch:48 step:38120 [D loss: 0.652857, acc.: 57.03%] [G loss: 0.868003]\n",
      "epoch:48 step:38121 [D loss: 0.749767, acc.: 42.19%] [G loss: 0.757234]\n",
      "epoch:48 step:38122 [D loss: 0.714633, acc.: 44.53%] [G loss: 0.784363]\n",
      "epoch:48 step:38123 [D loss: 0.645297, acc.: 62.50%] [G loss: 0.691565]\n",
      "epoch:48 step:38124 [D loss: 0.668370, acc.: 61.72%] [G loss: 0.850032]\n",
      "epoch:48 step:38125 [D loss: 0.679432, acc.: 59.38%] [G loss: 0.796761]\n",
      "epoch:48 step:38126 [D loss: 0.734695, acc.: 42.19%] [G loss: 0.696977]\n",
      "epoch:48 step:38127 [D loss: 0.698277, acc.: 53.12%] [G loss: 0.887719]\n",
      "epoch:48 step:38128 [D loss: 0.723318, acc.: 48.44%] [G loss: 0.744505]\n",
      "epoch:48 step:38129 [D loss: 0.739100, acc.: 42.97%] [G loss: 0.699938]\n",
      "epoch:48 step:38130 [D loss: 0.684229, acc.: 57.03%] [G loss: 0.796696]\n",
      "epoch:48 step:38131 [D loss: 0.694578, acc.: 46.88%] [G loss: 0.879791]\n",
      "epoch:48 step:38132 [D loss: 0.631619, acc.: 68.75%] [G loss: 0.733543]\n",
      "epoch:48 step:38133 [D loss: 0.655781, acc.: 58.59%] [G loss: 0.767845]\n",
      "epoch:48 step:38134 [D loss: 0.693941, acc.: 57.03%] [G loss: 0.811737]\n",
      "epoch:48 step:38135 [D loss: 0.671326, acc.: 53.91%] [G loss: 0.814883]\n",
      "epoch:48 step:38136 [D loss: 0.736527, acc.: 42.97%] [G loss: 0.832121]\n",
      "epoch:48 step:38137 [D loss: 0.718013, acc.: 54.69%] [G loss: 0.861650]\n",
      "epoch:48 step:38138 [D loss: 0.653074, acc.: 67.97%] [G loss: 0.882159]\n",
      "epoch:48 step:38139 [D loss: 0.642317, acc.: 65.62%] [G loss: 0.891995]\n",
      "epoch:48 step:38140 [D loss: 0.624590, acc.: 69.53%] [G loss: 0.839837]\n",
      "epoch:48 step:38141 [D loss: 0.660013, acc.: 60.94%] [G loss: 0.793390]\n",
      "epoch:48 step:38142 [D loss: 0.644651, acc.: 63.28%] [G loss: 0.777190]\n",
      "epoch:48 step:38143 [D loss: 0.769468, acc.: 32.81%] [G loss: 0.699490]\n",
      "epoch:48 step:38144 [D loss: 0.657132, acc.: 62.50%] [G loss: 0.844915]\n",
      "epoch:48 step:38145 [D loss: 0.664287, acc.: 67.19%] [G loss: 0.726350]\n",
      "epoch:48 step:38146 [D loss: 0.638739, acc.: 65.62%] [G loss: 0.803593]\n",
      "epoch:48 step:38147 [D loss: 0.709573, acc.: 50.78%] [G loss: 0.854719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38148 [D loss: 0.699969, acc.: 49.22%] [G loss: 0.783506]\n",
      "epoch:48 step:38149 [D loss: 0.670089, acc.: 59.38%] [G loss: 0.839692]\n",
      "epoch:48 step:38150 [D loss: 0.599747, acc.: 72.66%] [G loss: 0.827158]\n",
      "epoch:48 step:38151 [D loss: 0.648774, acc.: 64.84%] [G loss: 0.687042]\n",
      "epoch:48 step:38152 [D loss: 0.703572, acc.: 48.44%] [G loss: 0.754566]\n",
      "epoch:48 step:38153 [D loss: 0.629830, acc.: 71.88%] [G loss: 0.752740]\n",
      "epoch:48 step:38154 [D loss: 0.604712, acc.: 73.44%] [G loss: 0.827820]\n",
      "epoch:48 step:38155 [D loss: 0.629338, acc.: 66.41%] [G loss: 0.824240]\n",
      "epoch:48 step:38156 [D loss: 0.678896, acc.: 57.03%] [G loss: 0.789510]\n",
      "epoch:48 step:38157 [D loss: 0.678562, acc.: 56.25%] [G loss: 0.814407]\n",
      "epoch:48 step:38158 [D loss: 0.703400, acc.: 56.25%] [G loss: 0.827303]\n",
      "epoch:48 step:38159 [D loss: 0.646341, acc.: 66.41%] [G loss: 0.805777]\n",
      "epoch:48 step:38160 [D loss: 0.699479, acc.: 52.34%] [G loss: 0.732510]\n",
      "epoch:48 step:38161 [D loss: 0.623882, acc.: 67.97%] [G loss: 0.998915]\n",
      "epoch:48 step:38162 [D loss: 0.774015, acc.: 37.50%] [G loss: 0.880215]\n",
      "epoch:48 step:38163 [D loss: 0.676968, acc.: 58.59%] [G loss: 0.877299]\n",
      "epoch:48 step:38164 [D loss: 0.678662, acc.: 49.22%] [G loss: 0.742959]\n",
      "epoch:48 step:38165 [D loss: 0.644971, acc.: 63.28%] [G loss: 0.841448]\n",
      "epoch:48 step:38166 [D loss: 0.705849, acc.: 53.12%] [G loss: 0.794987]\n",
      "epoch:48 step:38167 [D loss: 0.660817, acc.: 57.81%] [G loss: 0.790916]\n",
      "epoch:48 step:38168 [D loss: 0.642177, acc.: 64.84%] [G loss: 0.815769]\n",
      "epoch:48 step:38169 [D loss: 0.632523, acc.: 65.62%] [G loss: 0.854296]\n",
      "epoch:48 step:38170 [D loss: 0.690559, acc.: 50.78%] [G loss: 0.769422]\n",
      "epoch:48 step:38171 [D loss: 0.683548, acc.: 59.38%] [G loss: 0.750653]\n",
      "epoch:48 step:38172 [D loss: 0.698178, acc.: 51.56%] [G loss: 0.918347]\n",
      "epoch:48 step:38173 [D loss: 0.682198, acc.: 54.69%] [G loss: 0.790758]\n",
      "epoch:48 step:38174 [D loss: 0.742523, acc.: 45.31%] [G loss: 0.771664]\n",
      "epoch:48 step:38175 [D loss: 0.644181, acc.: 62.50%] [G loss: 0.853788]\n",
      "epoch:48 step:38176 [D loss: 0.693357, acc.: 54.69%] [G loss: 0.820067]\n",
      "epoch:48 step:38177 [D loss: 0.633384, acc.: 62.50%] [G loss: 0.875455]\n",
      "epoch:48 step:38178 [D loss: 0.695900, acc.: 56.25%] [G loss: 0.852409]\n",
      "epoch:48 step:38179 [D loss: 0.641726, acc.: 63.28%] [G loss: 0.870380]\n",
      "epoch:48 step:38180 [D loss: 0.663237, acc.: 60.94%] [G loss: 0.830136]\n",
      "epoch:48 step:38181 [D loss: 0.643082, acc.: 67.19%] [G loss: 0.773123]\n",
      "epoch:48 step:38182 [D loss: 0.675649, acc.: 57.81%] [G loss: 0.721511]\n",
      "epoch:48 step:38183 [D loss: 0.607235, acc.: 68.75%] [G loss: 0.757477]\n",
      "epoch:48 step:38184 [D loss: 0.740779, acc.: 44.53%] [G loss: 0.766916]\n",
      "epoch:48 step:38185 [D loss: 0.685358, acc.: 55.47%] [G loss: 0.699569]\n",
      "epoch:48 step:38186 [D loss: 0.663908, acc.: 57.81%] [G loss: 0.863813]\n",
      "epoch:48 step:38187 [D loss: 0.750631, acc.: 42.97%] [G loss: 0.726140]\n",
      "epoch:48 step:38188 [D loss: 0.661179, acc.: 64.06%] [G loss: 0.944663]\n",
      "epoch:48 step:38189 [D loss: 0.701766, acc.: 53.12%] [G loss: 0.720212]\n",
      "epoch:48 step:38190 [D loss: 0.764827, acc.: 42.97%] [G loss: 0.754102]\n",
      "epoch:48 step:38191 [D loss: 0.713537, acc.: 46.88%] [G loss: 0.770536]\n",
      "epoch:48 step:38192 [D loss: 0.747330, acc.: 41.41%] [G loss: 0.817676]\n",
      "epoch:48 step:38193 [D loss: 0.683839, acc.: 55.47%] [G loss: 0.790234]\n",
      "epoch:48 step:38194 [D loss: 0.697316, acc.: 51.56%] [G loss: 0.714832]\n",
      "epoch:48 step:38195 [D loss: 0.715091, acc.: 50.78%] [G loss: 0.768216]\n",
      "epoch:48 step:38196 [D loss: 0.740234, acc.: 41.41%] [G loss: 0.769043]\n",
      "epoch:48 step:38197 [D loss: 0.679397, acc.: 56.25%] [G loss: 0.805005]\n",
      "epoch:48 step:38198 [D loss: 0.581511, acc.: 82.03%] [G loss: 0.803629]\n",
      "epoch:48 step:38199 [D loss: 0.682775, acc.: 55.47%] [G loss: 0.783308]\n",
      "epoch:48 step:38200 [D loss: 0.735718, acc.: 44.53%] [G loss: 0.816048]\n",
      "epoch:48 step:38201 [D loss: 0.683215, acc.: 57.03%] [G loss: 0.764637]\n",
      "epoch:48 step:38202 [D loss: 0.727752, acc.: 48.44%] [G loss: 0.765795]\n",
      "epoch:48 step:38203 [D loss: 0.671786, acc.: 60.94%] [G loss: 0.799806]\n",
      "epoch:48 step:38204 [D loss: 0.680119, acc.: 56.25%] [G loss: 0.848290]\n",
      "epoch:48 step:38205 [D loss: 0.662806, acc.: 63.28%] [G loss: 0.809755]\n",
      "epoch:48 step:38206 [D loss: 0.673328, acc.: 64.06%] [G loss: 0.854471]\n",
      "epoch:48 step:38207 [D loss: 0.666173, acc.: 60.16%] [G loss: 0.885740]\n",
      "epoch:48 step:38208 [D loss: 0.684902, acc.: 57.03%] [G loss: 0.843096]\n",
      "epoch:48 step:38209 [D loss: 0.695664, acc.: 55.47%] [G loss: 0.792267]\n",
      "epoch:48 step:38210 [D loss: 0.745108, acc.: 41.41%] [G loss: 0.790297]\n",
      "epoch:48 step:38211 [D loss: 0.741639, acc.: 42.97%] [G loss: 0.704247]\n",
      "epoch:48 step:38212 [D loss: 0.628449, acc.: 72.66%] [G loss: 0.843585]\n",
      "epoch:48 step:38213 [D loss: 0.626360, acc.: 66.41%] [G loss: 0.736102]\n",
      "epoch:48 step:38214 [D loss: 0.617304, acc.: 67.19%] [G loss: 0.807735]\n",
      "epoch:48 step:38215 [D loss: 0.763894, acc.: 42.97%] [G loss: 0.702461]\n",
      "epoch:48 step:38216 [D loss: 0.653056, acc.: 56.25%] [G loss: 0.765520]\n",
      "epoch:48 step:38217 [D loss: 0.736780, acc.: 47.66%] [G loss: 0.726066]\n",
      "epoch:48 step:38218 [D loss: 0.609455, acc.: 63.28%] [G loss: 0.745339]\n",
      "epoch:48 step:38219 [D loss: 0.618936, acc.: 72.66%] [G loss: 0.830343]\n",
      "epoch:48 step:38220 [D loss: 0.682934, acc.: 57.03%] [G loss: 0.787263]\n",
      "epoch:48 step:38221 [D loss: 0.672840, acc.: 58.59%] [G loss: 0.700583]\n",
      "epoch:48 step:38222 [D loss: 0.630618, acc.: 60.94%] [G loss: 0.789378]\n",
      "epoch:48 step:38223 [D loss: 0.607896, acc.: 72.66%] [G loss: 0.831777]\n",
      "epoch:48 step:38224 [D loss: 0.661023, acc.: 60.94%] [G loss: 0.873422]\n",
      "epoch:48 step:38225 [D loss: 0.686184, acc.: 55.47%] [G loss: 0.815046]\n",
      "epoch:48 step:38226 [D loss: 0.705521, acc.: 48.44%] [G loss: 0.719188]\n",
      "epoch:48 step:38227 [D loss: 0.736902, acc.: 43.75%] [G loss: 0.819894]\n",
      "epoch:48 step:38228 [D loss: 0.625220, acc.: 66.41%] [G loss: 0.813358]\n",
      "epoch:48 step:38229 [D loss: 0.682405, acc.: 60.16%] [G loss: 0.763384]\n",
      "epoch:48 step:38230 [D loss: 0.692347, acc.: 56.25%] [G loss: 0.696016]\n",
      "epoch:48 step:38231 [D loss: 0.684568, acc.: 57.81%] [G loss: 0.745328]\n",
      "epoch:48 step:38232 [D loss: 0.589321, acc.: 75.00%] [G loss: 0.753375]\n",
      "epoch:48 step:38233 [D loss: 0.704164, acc.: 56.25%] [G loss: 0.835324]\n",
      "epoch:48 step:38234 [D loss: 0.678387, acc.: 53.12%] [G loss: 0.762744]\n",
      "epoch:48 step:38235 [D loss: 0.684152, acc.: 55.47%] [G loss: 0.762685]\n",
      "epoch:48 step:38236 [D loss: 0.671690, acc.: 55.47%] [G loss: 0.760106]\n",
      "epoch:48 step:38237 [D loss: 0.728295, acc.: 48.44%] [G loss: 0.748252]\n",
      "epoch:48 step:38238 [D loss: 0.650006, acc.: 60.94%] [G loss: 0.681151]\n",
      "epoch:48 step:38239 [D loss: 0.672149, acc.: 58.59%] [G loss: 0.796942]\n",
      "epoch:48 step:38240 [D loss: 0.688197, acc.: 53.12%] [G loss: 0.816690]\n",
      "epoch:48 step:38241 [D loss: 0.686529, acc.: 53.91%] [G loss: 0.841372]\n",
      "epoch:48 step:38242 [D loss: 0.694015, acc.: 53.12%] [G loss: 0.809579]\n",
      "epoch:48 step:38243 [D loss: 0.646872, acc.: 62.50%] [G loss: 0.913172]\n",
      "epoch:48 step:38244 [D loss: 0.688039, acc.: 55.47%] [G loss: 0.864188]\n",
      "epoch:48 step:38245 [D loss: 0.630120, acc.: 68.75%] [G loss: 0.936086]\n",
      "epoch:48 step:38246 [D loss: 0.682355, acc.: 57.81%] [G loss: 0.775554]\n",
      "epoch:48 step:38247 [D loss: 0.730307, acc.: 46.09%] [G loss: 0.847674]\n",
      "epoch:48 step:38248 [D loss: 0.660689, acc.: 57.81%] [G loss: 0.967845]\n",
      "epoch:48 step:38249 [D loss: 0.687202, acc.: 57.03%] [G loss: 0.809985]\n",
      "epoch:48 step:38250 [D loss: 0.693025, acc.: 55.47%] [G loss: 0.874863]\n",
      "epoch:48 step:38251 [D loss: 0.673864, acc.: 60.94%] [G loss: 0.750211]\n",
      "epoch:48 step:38252 [D loss: 0.664002, acc.: 62.50%] [G loss: 0.799104]\n",
      "epoch:48 step:38253 [D loss: 0.651337, acc.: 60.94%] [G loss: 0.800067]\n",
      "epoch:48 step:38254 [D loss: 0.714378, acc.: 50.00%] [G loss: 0.832057]\n",
      "epoch:48 step:38255 [D loss: 0.630365, acc.: 66.41%] [G loss: 0.823905]\n",
      "epoch:48 step:38256 [D loss: 0.631074, acc.: 66.41%] [G loss: 0.827645]\n",
      "epoch:48 step:38257 [D loss: 0.668850, acc.: 59.38%] [G loss: 0.874906]\n",
      "epoch:48 step:38258 [D loss: 0.676584, acc.: 62.50%] [G loss: 0.734529]\n",
      "epoch:48 step:38259 [D loss: 0.690514, acc.: 53.12%] [G loss: 0.685676]\n",
      "epoch:48 step:38260 [D loss: 0.641631, acc.: 63.28%] [G loss: 0.785100]\n",
      "epoch:48 step:38261 [D loss: 0.632015, acc.: 64.84%] [G loss: 0.748619]\n",
      "epoch:48 step:38262 [D loss: 0.609893, acc.: 70.31%] [G loss: 0.865772]\n",
      "epoch:48 step:38263 [D loss: 0.621505, acc.: 71.09%] [G loss: 0.770004]\n",
      "epoch:48 step:38264 [D loss: 0.692172, acc.: 50.78%] [G loss: 0.821706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38265 [D loss: 0.657508, acc.: 64.06%] [G loss: 0.707629]\n",
      "epoch:48 step:38266 [D loss: 0.678367, acc.: 57.03%] [G loss: 0.816910]\n",
      "epoch:48 step:38267 [D loss: 0.651975, acc.: 61.72%] [G loss: 0.832750]\n",
      "epoch:48 step:38268 [D loss: 0.697554, acc.: 53.91%] [G loss: 0.718893]\n",
      "epoch:48 step:38269 [D loss: 0.708931, acc.: 53.12%] [G loss: 0.835864]\n",
      "epoch:49 step:38270 [D loss: 0.634831, acc.: 63.28%] [G loss: 0.739995]\n",
      "epoch:49 step:38271 [D loss: 0.686576, acc.: 53.91%] [G loss: 0.749071]\n",
      "epoch:49 step:38272 [D loss: 0.667668, acc.: 61.72%] [G loss: 0.870267]\n",
      "epoch:49 step:38273 [D loss: 0.694018, acc.: 51.56%] [G loss: 0.819561]\n",
      "epoch:49 step:38274 [D loss: 0.737081, acc.: 43.75%] [G loss: 0.799404]\n",
      "epoch:49 step:38275 [D loss: 0.603131, acc.: 75.78%] [G loss: 0.871540]\n",
      "epoch:49 step:38276 [D loss: 0.770255, acc.: 35.16%] [G loss: 0.833155]\n",
      "epoch:49 step:38277 [D loss: 0.644044, acc.: 65.62%] [G loss: 0.780430]\n",
      "epoch:49 step:38278 [D loss: 0.724146, acc.: 47.66%] [G loss: 0.816128]\n",
      "epoch:49 step:38279 [D loss: 0.633512, acc.: 69.53%] [G loss: 0.781296]\n",
      "epoch:49 step:38280 [D loss: 0.727018, acc.: 50.00%] [G loss: 0.815818]\n",
      "epoch:49 step:38281 [D loss: 0.671807, acc.: 59.38%] [G loss: 0.769812]\n",
      "epoch:49 step:38282 [D loss: 0.690257, acc.: 54.69%] [G loss: 0.771062]\n",
      "epoch:49 step:38283 [D loss: 0.662475, acc.: 65.62%] [G loss: 0.853545]\n",
      "epoch:49 step:38284 [D loss: 0.656843, acc.: 62.50%] [G loss: 0.836733]\n",
      "epoch:49 step:38285 [D loss: 0.616930, acc.: 68.75%] [G loss: 0.822256]\n",
      "epoch:49 step:38286 [D loss: 0.688980, acc.: 53.12%] [G loss: 0.856563]\n",
      "epoch:49 step:38287 [D loss: 0.729313, acc.: 51.56%] [G loss: 0.782273]\n",
      "epoch:49 step:38288 [D loss: 0.619697, acc.: 68.75%] [G loss: 0.866389]\n",
      "epoch:49 step:38289 [D loss: 0.618238, acc.: 72.66%] [G loss: 0.855844]\n",
      "epoch:49 step:38290 [D loss: 0.663491, acc.: 67.97%] [G loss: 0.918461]\n",
      "epoch:49 step:38291 [D loss: 0.667576, acc.: 55.47%] [G loss: 0.821551]\n",
      "epoch:49 step:38292 [D loss: 0.710369, acc.: 50.00%] [G loss: 0.787680]\n",
      "epoch:49 step:38293 [D loss: 0.705267, acc.: 53.12%] [G loss: 0.831580]\n",
      "epoch:49 step:38294 [D loss: 0.631388, acc.: 61.72%] [G loss: 0.780698]\n",
      "epoch:49 step:38295 [D loss: 0.727960, acc.: 48.44%] [G loss: 0.828386]\n",
      "epoch:49 step:38296 [D loss: 0.687698, acc.: 53.91%] [G loss: 0.808758]\n",
      "epoch:49 step:38297 [D loss: 0.716247, acc.: 50.78%] [G loss: 0.677274]\n",
      "epoch:49 step:38298 [D loss: 0.692465, acc.: 60.94%] [G loss: 0.797785]\n",
      "epoch:49 step:38299 [D loss: 0.659158, acc.: 57.03%] [G loss: 0.877092]\n",
      "epoch:49 step:38300 [D loss: 0.682692, acc.: 56.25%] [G loss: 0.829470]\n",
      "epoch:49 step:38301 [D loss: 0.649695, acc.: 64.84%] [G loss: 0.872977]\n",
      "epoch:49 step:38302 [D loss: 0.725482, acc.: 50.00%] [G loss: 0.876934]\n",
      "epoch:49 step:38303 [D loss: 0.700558, acc.: 50.00%] [G loss: 0.753603]\n",
      "epoch:49 step:38304 [D loss: 0.703496, acc.: 53.12%] [G loss: 0.865119]\n",
      "epoch:49 step:38305 [D loss: 0.712568, acc.: 48.44%] [G loss: 0.719314]\n",
      "epoch:49 step:38306 [D loss: 0.685410, acc.: 53.91%] [G loss: 0.786361]\n",
      "epoch:49 step:38307 [D loss: 0.734565, acc.: 41.41%] [G loss: 0.823808]\n",
      "epoch:49 step:38308 [D loss: 0.656600, acc.: 62.50%] [G loss: 0.820118]\n",
      "epoch:49 step:38309 [D loss: 0.599886, acc.: 77.34%] [G loss: 0.771260]\n",
      "epoch:49 step:38310 [D loss: 0.679930, acc.: 57.03%] [G loss: 0.821567]\n",
      "epoch:49 step:38311 [D loss: 0.662921, acc.: 61.72%] [G loss: 0.786617]\n",
      "epoch:49 step:38312 [D loss: 0.720232, acc.: 48.44%] [G loss: 0.720283]\n",
      "epoch:49 step:38313 [D loss: 0.706090, acc.: 46.88%] [G loss: 0.786935]\n",
      "epoch:49 step:38314 [D loss: 0.652341, acc.: 64.06%] [G loss: 0.809187]\n",
      "epoch:49 step:38315 [D loss: 0.681282, acc.: 59.38%] [G loss: 0.893600]\n",
      "epoch:49 step:38316 [D loss: 0.740214, acc.: 47.66%] [G loss: 0.774912]\n",
      "epoch:49 step:38317 [D loss: 0.690731, acc.: 56.25%] [G loss: 0.839925]\n",
      "epoch:49 step:38318 [D loss: 0.603423, acc.: 70.31%] [G loss: 0.770994]\n",
      "epoch:49 step:38319 [D loss: 0.684774, acc.: 55.47%] [G loss: 0.815012]\n",
      "epoch:49 step:38320 [D loss: 0.686776, acc.: 57.03%] [G loss: 0.685231]\n",
      "epoch:49 step:38321 [D loss: 0.670866, acc.: 58.59%] [G loss: 0.867231]\n",
      "epoch:49 step:38322 [D loss: 0.656750, acc.: 62.50%] [G loss: 0.831988]\n",
      "epoch:49 step:38323 [D loss: 0.688366, acc.: 56.25%] [G loss: 0.777181]\n",
      "epoch:49 step:38324 [D loss: 0.659528, acc.: 60.94%] [G loss: 0.796818]\n",
      "epoch:49 step:38325 [D loss: 0.691619, acc.: 59.38%] [G loss: 0.842353]\n",
      "epoch:49 step:38326 [D loss: 0.653745, acc.: 64.06%] [G loss: 0.818117]\n",
      "epoch:49 step:38327 [D loss: 0.709062, acc.: 48.44%] [G loss: 0.768965]\n",
      "epoch:49 step:38328 [D loss: 0.648716, acc.: 63.28%] [G loss: 0.800375]\n",
      "epoch:49 step:38329 [D loss: 0.712573, acc.: 46.88%] [G loss: 0.863684]\n",
      "epoch:49 step:38330 [D loss: 0.638934, acc.: 65.62%] [G loss: 0.837534]\n",
      "epoch:49 step:38331 [D loss: 0.632773, acc.: 67.19%] [G loss: 0.813809]\n",
      "epoch:49 step:38332 [D loss: 0.689684, acc.: 57.03%] [G loss: 0.770171]\n",
      "epoch:49 step:38333 [D loss: 0.694834, acc.: 53.91%] [G loss: 0.791855]\n",
      "epoch:49 step:38334 [D loss: 0.713046, acc.: 54.69%] [G loss: 0.809711]\n",
      "epoch:49 step:38335 [D loss: 0.671999, acc.: 60.94%] [G loss: 0.876273]\n",
      "epoch:49 step:38336 [D loss: 0.682954, acc.: 52.34%] [G loss: 0.736975]\n",
      "epoch:49 step:38337 [D loss: 0.687400, acc.: 57.81%] [G loss: 0.776528]\n",
      "epoch:49 step:38338 [D loss: 0.756399, acc.: 36.72%] [G loss: 0.830294]\n",
      "epoch:49 step:38339 [D loss: 0.745526, acc.: 45.31%] [G loss: 0.745527]\n",
      "epoch:49 step:38340 [D loss: 0.696107, acc.: 53.91%] [G loss: 0.766946]\n",
      "epoch:49 step:38341 [D loss: 0.696845, acc.: 55.47%] [G loss: 0.852708]\n",
      "epoch:49 step:38342 [D loss: 0.720480, acc.: 49.22%] [G loss: 0.764434]\n",
      "epoch:49 step:38343 [D loss: 0.682729, acc.: 59.38%] [G loss: 0.710967]\n",
      "epoch:49 step:38344 [D loss: 0.593391, acc.: 74.22%] [G loss: 0.855490]\n",
      "epoch:49 step:38345 [D loss: 0.728744, acc.: 46.09%] [G loss: 0.883091]\n",
      "epoch:49 step:38346 [D loss: 0.674660, acc.: 62.50%] [G loss: 0.884962]\n",
      "epoch:49 step:38347 [D loss: 0.693813, acc.: 57.81%] [G loss: 0.743583]\n",
      "epoch:49 step:38348 [D loss: 0.674745, acc.: 55.47%] [G loss: 0.809000]\n",
      "epoch:49 step:38349 [D loss: 0.645810, acc.: 61.72%] [G loss: 0.879573]\n",
      "epoch:49 step:38350 [D loss: 0.727490, acc.: 49.22%] [G loss: 0.811225]\n",
      "epoch:49 step:38351 [D loss: 0.700650, acc.: 54.69%] [G loss: 0.814570]\n",
      "epoch:49 step:38352 [D loss: 0.691563, acc.: 50.78%] [G loss: 0.822285]\n",
      "epoch:49 step:38353 [D loss: 0.643788, acc.: 64.06%] [G loss: 0.894040]\n",
      "epoch:49 step:38354 [D loss: 0.644297, acc.: 61.72%] [G loss: 0.869514]\n",
      "epoch:49 step:38355 [D loss: 0.708941, acc.: 53.12%] [G loss: 0.758536]\n",
      "epoch:49 step:38356 [D loss: 0.633205, acc.: 60.16%] [G loss: 0.772678]\n",
      "epoch:49 step:38357 [D loss: 0.719951, acc.: 49.22%] [G loss: 0.777410]\n",
      "epoch:49 step:38358 [D loss: 0.710486, acc.: 47.66%] [G loss: 0.782779]\n",
      "epoch:49 step:38359 [D loss: 0.670501, acc.: 51.56%] [G loss: 0.816825]\n",
      "epoch:49 step:38360 [D loss: 0.743869, acc.: 44.53%] [G loss: 0.654966]\n",
      "epoch:49 step:38361 [D loss: 0.711357, acc.: 53.91%] [G loss: 0.817553]\n",
      "epoch:49 step:38362 [D loss: 0.729391, acc.: 48.44%] [G loss: 0.756698]\n",
      "epoch:49 step:38363 [D loss: 0.642764, acc.: 64.84%] [G loss: 0.739949]\n",
      "epoch:49 step:38364 [D loss: 0.701509, acc.: 54.69%] [G loss: 0.839745]\n",
      "epoch:49 step:38365 [D loss: 0.693793, acc.: 60.94%] [G loss: 0.763264]\n",
      "epoch:49 step:38366 [D loss: 0.688212, acc.: 57.81%] [G loss: 0.885350]\n",
      "epoch:49 step:38367 [D loss: 0.694536, acc.: 56.25%] [G loss: 0.858326]\n",
      "epoch:49 step:38368 [D loss: 0.658350, acc.: 64.06%] [G loss: 0.843916]\n",
      "epoch:49 step:38369 [D loss: 0.667758, acc.: 62.50%] [G loss: 0.832274]\n",
      "epoch:49 step:38370 [D loss: 0.673106, acc.: 58.59%] [G loss: 0.821521]\n",
      "epoch:49 step:38371 [D loss: 0.650420, acc.: 59.38%] [G loss: 0.843177]\n",
      "epoch:49 step:38372 [D loss: 0.667556, acc.: 57.81%] [G loss: 0.742263]\n",
      "epoch:49 step:38373 [D loss: 0.733677, acc.: 46.88%] [G loss: 0.742239]\n",
      "epoch:49 step:38374 [D loss: 0.677418, acc.: 58.59%] [G loss: 0.771689]\n",
      "epoch:49 step:38375 [D loss: 0.713239, acc.: 52.34%] [G loss: 0.915704]\n",
      "epoch:49 step:38376 [D loss: 0.656831, acc.: 57.81%] [G loss: 0.808330]\n",
      "epoch:49 step:38377 [D loss: 0.739094, acc.: 42.97%] [G loss: 0.749242]\n",
      "epoch:49 step:38378 [D loss: 0.659504, acc.: 63.28%] [G loss: 0.774985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38379 [D loss: 0.641790, acc.: 67.97%] [G loss: 0.890350]\n",
      "epoch:49 step:38380 [D loss: 0.685587, acc.: 60.16%] [G loss: 0.783596]\n",
      "epoch:49 step:38381 [D loss: 0.657872, acc.: 61.72%] [G loss: 0.857267]\n",
      "epoch:49 step:38382 [D loss: 0.581535, acc.: 77.34%] [G loss: 0.769189]\n",
      "epoch:49 step:38383 [D loss: 0.590393, acc.: 78.12%] [G loss: 0.892947]\n",
      "epoch:49 step:38384 [D loss: 0.699115, acc.: 50.78%] [G loss: 0.789956]\n",
      "epoch:49 step:38385 [D loss: 0.699835, acc.: 52.34%] [G loss: 0.815934]\n",
      "epoch:49 step:38386 [D loss: 0.671044, acc.: 60.16%] [G loss: 0.863828]\n",
      "epoch:49 step:38387 [D loss: 0.656404, acc.: 60.16%] [G loss: 0.821603]\n",
      "epoch:49 step:38388 [D loss: 0.699071, acc.: 50.00%] [G loss: 0.799510]\n",
      "epoch:49 step:38389 [D loss: 0.672494, acc.: 57.81%] [G loss: 0.848881]\n",
      "epoch:49 step:38390 [D loss: 0.615355, acc.: 69.53%] [G loss: 0.885687]\n",
      "epoch:49 step:38391 [D loss: 0.624114, acc.: 71.88%] [G loss: 0.785539]\n",
      "epoch:49 step:38392 [D loss: 0.683385, acc.: 55.47%] [G loss: 0.857910]\n",
      "epoch:49 step:38393 [D loss: 0.582590, acc.: 74.22%] [G loss: 0.808546]\n",
      "epoch:49 step:38394 [D loss: 0.731160, acc.: 46.88%] [G loss: 0.724065]\n",
      "epoch:49 step:38395 [D loss: 0.723849, acc.: 50.00%] [G loss: 0.741722]\n",
      "epoch:49 step:38396 [D loss: 0.673867, acc.: 56.25%] [G loss: 0.793990]\n",
      "epoch:49 step:38397 [D loss: 0.714873, acc.: 51.56%] [G loss: 0.741487]\n",
      "epoch:49 step:38398 [D loss: 0.713214, acc.: 47.66%] [G loss: 0.736532]\n",
      "epoch:49 step:38399 [D loss: 0.680161, acc.: 57.03%] [G loss: 0.732548]\n",
      "epoch:49 step:38400 [D loss: 0.642485, acc.: 60.94%] [G loss: 0.821747]\n",
      "epoch:49 step:38401 [D loss: 0.708977, acc.: 52.34%] [G loss: 0.905356]\n",
      "epoch:49 step:38402 [D loss: 0.656017, acc.: 60.16%] [G loss: 0.873697]\n",
      "epoch:49 step:38403 [D loss: 0.716766, acc.: 46.88%] [G loss: 0.881898]\n",
      "epoch:49 step:38404 [D loss: 0.741868, acc.: 47.66%] [G loss: 0.788272]\n",
      "epoch:49 step:38405 [D loss: 0.709551, acc.: 46.88%] [G loss: 0.816629]\n",
      "epoch:49 step:38406 [D loss: 0.747889, acc.: 41.41%] [G loss: 0.732034]\n",
      "epoch:49 step:38407 [D loss: 0.659992, acc.: 60.94%] [G loss: 0.807150]\n",
      "epoch:49 step:38408 [D loss: 0.697355, acc.: 53.12%] [G loss: 0.753682]\n",
      "epoch:49 step:38409 [D loss: 0.690337, acc.: 51.56%] [G loss: 0.701062]\n",
      "epoch:49 step:38410 [D loss: 0.663143, acc.: 60.94%] [G loss: 0.795985]\n",
      "epoch:49 step:38411 [D loss: 0.682153, acc.: 57.81%] [G loss: 0.769330]\n",
      "epoch:49 step:38412 [D loss: 0.647229, acc.: 64.06%] [G loss: 0.826551]\n",
      "epoch:49 step:38413 [D loss: 0.640270, acc.: 59.38%] [G loss: 0.762197]\n",
      "epoch:49 step:38414 [D loss: 0.685412, acc.: 54.69%] [G loss: 0.804870]\n",
      "epoch:49 step:38415 [D loss: 0.656055, acc.: 59.38%] [G loss: 0.767917]\n",
      "epoch:49 step:38416 [D loss: 0.640385, acc.: 67.19%] [G loss: 0.830162]\n",
      "epoch:49 step:38417 [D loss: 0.671677, acc.: 59.38%] [G loss: 0.798495]\n",
      "epoch:49 step:38418 [D loss: 0.606289, acc.: 72.66%] [G loss: 0.764491]\n",
      "epoch:49 step:38419 [D loss: 0.645662, acc.: 67.19%] [G loss: 0.793595]\n",
      "epoch:49 step:38420 [D loss: 0.689540, acc.: 55.47%] [G loss: 0.788931]\n",
      "epoch:49 step:38421 [D loss: 0.681287, acc.: 57.81%] [G loss: 0.793962]\n",
      "epoch:49 step:38422 [D loss: 0.645065, acc.: 61.72%] [G loss: 0.807184]\n",
      "epoch:49 step:38423 [D loss: 0.735224, acc.: 48.44%] [G loss: 0.735606]\n",
      "epoch:49 step:38424 [D loss: 0.707675, acc.: 50.00%] [G loss: 0.809044]\n",
      "epoch:49 step:38425 [D loss: 0.687577, acc.: 55.47%] [G loss: 0.765221]\n",
      "epoch:49 step:38426 [D loss: 0.638368, acc.: 60.16%] [G loss: 0.794703]\n",
      "epoch:49 step:38427 [D loss: 0.672143, acc.: 63.28%] [G loss: 0.838647]\n",
      "epoch:49 step:38428 [D loss: 0.629624, acc.: 64.84%] [G loss: 0.769696]\n",
      "epoch:49 step:38429 [D loss: 0.745274, acc.: 45.31%] [G loss: 0.705832]\n",
      "epoch:49 step:38430 [D loss: 0.685380, acc.: 55.47%] [G loss: 0.756044]\n",
      "epoch:49 step:38431 [D loss: 0.756038, acc.: 46.09%] [G loss: 0.857948]\n",
      "epoch:49 step:38432 [D loss: 0.696467, acc.: 51.56%] [G loss: 0.780040]\n",
      "epoch:49 step:38433 [D loss: 0.725601, acc.: 46.09%] [G loss: 0.787861]\n",
      "epoch:49 step:38434 [D loss: 0.772592, acc.: 35.16%] [G loss: 0.820206]\n",
      "epoch:49 step:38435 [D loss: 0.636519, acc.: 61.72%] [G loss: 0.885891]\n",
      "epoch:49 step:38436 [D loss: 0.635757, acc.: 68.75%] [G loss: 0.840251]\n",
      "epoch:49 step:38437 [D loss: 0.652460, acc.: 66.41%] [G loss: 0.845367]\n",
      "epoch:49 step:38438 [D loss: 0.753592, acc.: 40.62%] [G loss: 0.817989]\n",
      "epoch:49 step:38439 [D loss: 0.695499, acc.: 49.22%] [G loss: 0.705896]\n",
      "epoch:49 step:38440 [D loss: 0.655056, acc.: 61.72%] [G loss: 0.752440]\n",
      "epoch:49 step:38441 [D loss: 0.609460, acc.: 69.53%] [G loss: 0.801613]\n",
      "epoch:49 step:38442 [D loss: 0.674830, acc.: 56.25%] [G loss: 0.919894]\n",
      "epoch:49 step:38443 [D loss: 0.696865, acc.: 51.56%] [G loss: 0.790917]\n",
      "epoch:49 step:38444 [D loss: 0.715261, acc.: 56.25%] [G loss: 0.813090]\n",
      "epoch:49 step:38445 [D loss: 0.660776, acc.: 60.94%] [G loss: 0.918134]\n",
      "epoch:49 step:38446 [D loss: 0.614247, acc.: 67.97%] [G loss: 0.932131]\n",
      "epoch:49 step:38447 [D loss: 0.727274, acc.: 48.44%] [G loss: 0.887213]\n",
      "epoch:49 step:38448 [D loss: 0.638581, acc.: 57.81%] [G loss: 0.851871]\n",
      "epoch:49 step:38449 [D loss: 0.709279, acc.: 47.66%] [G loss: 0.837767]\n",
      "epoch:49 step:38450 [D loss: 0.625868, acc.: 67.19%] [G loss: 0.867897]\n",
      "epoch:49 step:38451 [D loss: 0.623829, acc.: 64.84%] [G loss: 0.803895]\n",
      "epoch:49 step:38452 [D loss: 0.690432, acc.: 57.81%] [G loss: 0.768593]\n",
      "epoch:49 step:38453 [D loss: 0.712081, acc.: 45.31%] [G loss: 0.894852]\n",
      "epoch:49 step:38454 [D loss: 0.673242, acc.: 54.69%] [G loss: 0.827719]\n",
      "epoch:49 step:38455 [D loss: 0.715823, acc.: 51.56%] [G loss: 0.806928]\n",
      "epoch:49 step:38456 [D loss: 0.671915, acc.: 58.59%] [G loss: 0.690581]\n",
      "epoch:49 step:38457 [D loss: 0.706646, acc.: 49.22%] [G loss: 0.796552]\n",
      "epoch:49 step:38458 [D loss: 0.624944, acc.: 73.44%] [G loss: 0.784947]\n",
      "epoch:49 step:38459 [D loss: 0.678814, acc.: 52.34%] [G loss: 0.810782]\n",
      "epoch:49 step:38460 [D loss: 0.706776, acc.: 53.91%] [G loss: 0.820559]\n",
      "epoch:49 step:38461 [D loss: 0.663861, acc.: 58.59%] [G loss: 0.822955]\n",
      "epoch:49 step:38462 [D loss: 0.674250, acc.: 58.59%] [G loss: 0.822918]\n",
      "epoch:49 step:38463 [D loss: 0.713064, acc.: 49.22%] [G loss: 0.752035]\n",
      "epoch:49 step:38464 [D loss: 0.687972, acc.: 56.25%] [G loss: 0.805847]\n",
      "epoch:49 step:38465 [D loss: 0.661851, acc.: 63.28%] [G loss: 0.945418]\n",
      "epoch:49 step:38466 [D loss: 0.683372, acc.: 57.03%] [G loss: 0.827039]\n",
      "epoch:49 step:38467 [D loss: 0.703068, acc.: 51.56%] [G loss: 0.884960]\n",
      "epoch:49 step:38468 [D loss: 0.721948, acc.: 44.53%] [G loss: 0.843398]\n",
      "epoch:49 step:38469 [D loss: 0.629344, acc.: 65.62%] [G loss: 0.801390]\n",
      "epoch:49 step:38470 [D loss: 0.690589, acc.: 55.47%] [G loss: 0.751065]\n",
      "epoch:49 step:38471 [D loss: 0.728678, acc.: 50.78%] [G loss: 0.771714]\n",
      "epoch:49 step:38472 [D loss: 0.683603, acc.: 50.78%] [G loss: 0.835425]\n",
      "epoch:49 step:38473 [D loss: 0.687973, acc.: 53.91%] [G loss: 0.834762]\n",
      "epoch:49 step:38474 [D loss: 0.776913, acc.: 38.28%] [G loss: 0.773358]\n",
      "epoch:49 step:38475 [D loss: 0.668339, acc.: 59.38%] [G loss: 0.905647]\n",
      "epoch:49 step:38476 [D loss: 0.616270, acc.: 73.44%] [G loss: 0.879390]\n",
      "epoch:49 step:38477 [D loss: 0.644152, acc.: 64.06%] [G loss: 0.730333]\n",
      "epoch:49 step:38478 [D loss: 0.649915, acc.: 64.06%] [G loss: 0.834443]\n",
      "epoch:49 step:38479 [D loss: 0.648280, acc.: 64.84%] [G loss: 0.887863]\n",
      "epoch:49 step:38480 [D loss: 0.707139, acc.: 51.56%] [G loss: 0.853123]\n",
      "epoch:49 step:38481 [D loss: 0.664751, acc.: 59.38%] [G loss: 0.833740]\n",
      "epoch:49 step:38482 [D loss: 0.639564, acc.: 67.97%] [G loss: 0.926671]\n",
      "epoch:49 step:38483 [D loss: 0.770998, acc.: 39.06%] [G loss: 0.796243]\n",
      "epoch:49 step:38484 [D loss: 0.645616, acc.: 60.16%] [G loss: 0.817920]\n",
      "epoch:49 step:38485 [D loss: 0.770812, acc.: 41.41%] [G loss: 0.660316]\n",
      "epoch:49 step:38486 [D loss: 0.675877, acc.: 52.34%] [G loss: 0.780882]\n",
      "epoch:49 step:38487 [D loss: 0.686456, acc.: 53.12%] [G loss: 0.903785]\n",
      "epoch:49 step:38488 [D loss: 0.689305, acc.: 55.47%] [G loss: 0.805278]\n",
      "epoch:49 step:38489 [D loss: 0.704311, acc.: 55.47%] [G loss: 0.743277]\n",
      "epoch:49 step:38490 [D loss: 0.636138, acc.: 65.62%] [G loss: 0.784677]\n",
      "epoch:49 step:38491 [D loss: 0.696894, acc.: 55.47%] [G loss: 0.723214]\n",
      "epoch:49 step:38492 [D loss: 0.724243, acc.: 47.66%] [G loss: 0.742274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38493 [D loss: 0.662819, acc.: 60.16%] [G loss: 0.847551]\n",
      "epoch:49 step:38494 [D loss: 0.654999, acc.: 64.06%] [G loss: 0.803167]\n",
      "epoch:49 step:38495 [D loss: 0.647962, acc.: 58.59%] [G loss: 0.842927]\n",
      "epoch:49 step:38496 [D loss: 0.653284, acc.: 56.25%] [G loss: 0.867637]\n",
      "epoch:49 step:38497 [D loss: 0.669294, acc.: 57.81%] [G loss: 0.767002]\n",
      "epoch:49 step:38498 [D loss: 0.704292, acc.: 51.56%] [G loss: 0.870259]\n",
      "epoch:49 step:38499 [D loss: 0.671814, acc.: 60.94%] [G loss: 0.757873]\n",
      "epoch:49 step:38500 [D loss: 0.653363, acc.: 59.38%] [G loss: 0.824414]\n",
      "epoch:49 step:38501 [D loss: 0.693555, acc.: 52.34%] [G loss: 0.814218]\n",
      "epoch:49 step:38502 [D loss: 0.687538, acc.: 48.44%] [G loss: 0.782080]\n",
      "epoch:49 step:38503 [D loss: 0.677917, acc.: 59.38%] [G loss: 0.789251]\n",
      "epoch:49 step:38504 [D loss: 0.686319, acc.: 45.31%] [G loss: 0.787591]\n",
      "epoch:49 step:38505 [D loss: 0.655578, acc.: 61.72%] [G loss: 0.759894]\n",
      "epoch:49 step:38506 [D loss: 0.661702, acc.: 62.50%] [G loss: 0.780556]\n",
      "epoch:49 step:38507 [D loss: 0.749799, acc.: 41.41%] [G loss: 0.801773]\n",
      "epoch:49 step:38508 [D loss: 0.715898, acc.: 53.12%] [G loss: 0.743757]\n",
      "epoch:49 step:38509 [D loss: 0.705983, acc.: 50.78%] [G loss: 0.845324]\n",
      "epoch:49 step:38510 [D loss: 0.669482, acc.: 55.47%] [G loss: 0.879752]\n",
      "epoch:49 step:38511 [D loss: 0.716867, acc.: 50.00%] [G loss: 0.816849]\n",
      "epoch:49 step:38512 [D loss: 0.698862, acc.: 50.78%] [G loss: 0.804739]\n",
      "epoch:49 step:38513 [D loss: 0.645128, acc.: 63.28%] [G loss: 0.843814]\n",
      "epoch:49 step:38514 [D loss: 0.661128, acc.: 57.03%] [G loss: 0.788858]\n",
      "epoch:49 step:38515 [D loss: 0.706577, acc.: 50.00%] [G loss: 0.784615]\n",
      "epoch:49 step:38516 [D loss: 0.654379, acc.: 59.38%] [G loss: 0.713897]\n",
      "epoch:49 step:38517 [D loss: 0.662066, acc.: 64.06%] [G loss: 0.830590]\n",
      "epoch:49 step:38518 [D loss: 0.673839, acc.: 58.59%] [G loss: 0.777909]\n",
      "epoch:49 step:38519 [D loss: 0.691658, acc.: 56.25%] [G loss: 0.712546]\n",
      "epoch:49 step:38520 [D loss: 0.693996, acc.: 56.25%] [G loss: 0.702702]\n",
      "epoch:49 step:38521 [D loss: 0.683527, acc.: 53.91%] [G loss: 0.820575]\n",
      "epoch:49 step:38522 [D loss: 0.765120, acc.: 42.19%] [G loss: 0.840038]\n",
      "epoch:49 step:38523 [D loss: 0.720426, acc.: 47.66%] [G loss: 0.804242]\n",
      "epoch:49 step:38524 [D loss: 0.746417, acc.: 46.09%] [G loss: 0.667488]\n",
      "epoch:49 step:38525 [D loss: 0.699646, acc.: 55.47%] [G loss: 0.850135]\n",
      "epoch:49 step:38526 [D loss: 0.685869, acc.: 53.91%] [G loss: 0.847157]\n",
      "epoch:49 step:38527 [D loss: 0.641759, acc.: 64.06%] [G loss: 0.778798]\n",
      "epoch:49 step:38528 [D loss: 0.694454, acc.: 55.47%] [G loss: 0.691934]\n",
      "epoch:49 step:38529 [D loss: 0.612776, acc.: 75.00%] [G loss: 0.771493]\n",
      "epoch:49 step:38530 [D loss: 0.744727, acc.: 44.53%] [G loss: 0.866400]\n",
      "epoch:49 step:38531 [D loss: 0.731090, acc.: 49.22%] [G loss: 0.893198]\n",
      "epoch:49 step:38532 [D loss: 0.669278, acc.: 58.59%] [G loss: 0.844348]\n",
      "epoch:49 step:38533 [D loss: 0.690363, acc.: 57.81%] [G loss: 0.806145]\n",
      "epoch:49 step:38534 [D loss: 0.679974, acc.: 55.47%] [G loss: 0.733142]\n",
      "epoch:49 step:38535 [D loss: 0.700232, acc.: 50.78%] [G loss: 0.804778]\n",
      "epoch:49 step:38536 [D loss: 0.742893, acc.: 45.31%] [G loss: 0.778784]\n",
      "epoch:49 step:38537 [D loss: 0.779223, acc.: 35.16%] [G loss: 0.789528]\n",
      "epoch:49 step:38538 [D loss: 0.645593, acc.: 64.06%] [G loss: 0.881386]\n",
      "epoch:49 step:38539 [D loss: 0.696853, acc.: 50.78%] [G loss: 0.865951]\n",
      "epoch:49 step:38540 [D loss: 0.668552, acc.: 60.16%] [G loss: 0.947732]\n",
      "epoch:49 step:38541 [D loss: 0.666695, acc.: 59.38%] [G loss: 0.858374]\n",
      "epoch:49 step:38542 [D loss: 0.635068, acc.: 63.28%] [G loss: 0.974097]\n",
      "epoch:49 step:38543 [D loss: 0.630880, acc.: 68.75%] [G loss: 0.924387]\n",
      "epoch:49 step:38544 [D loss: 0.654320, acc.: 59.38%] [G loss: 0.926173]\n",
      "epoch:49 step:38545 [D loss: 0.700882, acc.: 53.12%] [G loss: 0.911094]\n",
      "epoch:49 step:38546 [D loss: 0.630544, acc.: 64.84%] [G loss: 0.784323]\n",
      "epoch:49 step:38547 [D loss: 0.698344, acc.: 52.34%] [G loss: 0.804994]\n",
      "epoch:49 step:38548 [D loss: 0.648557, acc.: 67.19%] [G loss: 0.780005]\n",
      "epoch:49 step:38549 [D loss: 0.653722, acc.: 61.72%] [G loss: 0.867994]\n",
      "epoch:49 step:38550 [D loss: 0.665794, acc.: 60.94%] [G loss: 0.954134]\n",
      "epoch:49 step:38551 [D loss: 0.660795, acc.: 64.84%] [G loss: 0.804403]\n",
      "epoch:49 step:38552 [D loss: 0.645684, acc.: 64.84%] [G loss: 0.757779]\n",
      "epoch:49 step:38553 [D loss: 0.636979, acc.: 64.06%] [G loss: 0.837401]\n",
      "epoch:49 step:38554 [D loss: 0.641709, acc.: 67.97%] [G loss: 0.735795]\n",
      "epoch:49 step:38555 [D loss: 0.606401, acc.: 69.53%] [G loss: 0.911951]\n",
      "epoch:49 step:38556 [D loss: 0.716616, acc.: 51.56%] [G loss: 0.831438]\n",
      "epoch:49 step:38557 [D loss: 0.675458, acc.: 54.69%] [G loss: 0.845350]\n",
      "epoch:49 step:38558 [D loss: 0.701327, acc.: 50.78%] [G loss: 0.781101]\n",
      "epoch:49 step:38559 [D loss: 0.672618, acc.: 60.16%] [G loss: 0.844473]\n",
      "epoch:49 step:38560 [D loss: 0.729676, acc.: 47.66%] [G loss: 0.769273]\n",
      "epoch:49 step:38561 [D loss: 0.655375, acc.: 60.16%] [G loss: 0.797462]\n",
      "epoch:49 step:38562 [D loss: 0.631955, acc.: 69.53%] [G loss: 0.847933]\n",
      "epoch:49 step:38563 [D loss: 0.684819, acc.: 57.03%] [G loss: 0.813800]\n",
      "epoch:49 step:38564 [D loss: 0.678203, acc.: 57.81%] [G loss: 0.771953]\n",
      "epoch:49 step:38565 [D loss: 0.619028, acc.: 64.06%] [G loss: 0.869750]\n",
      "epoch:49 step:38566 [D loss: 0.646075, acc.: 65.62%] [G loss: 0.804979]\n",
      "epoch:49 step:38567 [D loss: 0.681180, acc.: 57.81%] [G loss: 0.832131]\n",
      "epoch:49 step:38568 [D loss: 0.665390, acc.: 60.16%] [G loss: 0.745983]\n",
      "epoch:49 step:38569 [D loss: 0.698560, acc.: 50.78%] [G loss: 0.758274]\n",
      "epoch:49 step:38570 [D loss: 0.634685, acc.: 61.72%] [G loss: 0.768904]\n",
      "epoch:49 step:38571 [D loss: 0.621113, acc.: 72.66%] [G loss: 0.785945]\n",
      "epoch:49 step:38572 [D loss: 0.691369, acc.: 53.91%] [G loss: 0.729589]\n",
      "epoch:49 step:38573 [D loss: 0.744761, acc.: 42.97%] [G loss: 0.723411]\n",
      "epoch:49 step:38574 [D loss: 0.687164, acc.: 52.34%] [G loss: 0.767183]\n",
      "epoch:49 step:38575 [D loss: 0.608271, acc.: 73.44%] [G loss: 0.730396]\n",
      "epoch:49 step:38576 [D loss: 0.650269, acc.: 57.81%] [G loss: 0.847295]\n",
      "epoch:49 step:38577 [D loss: 0.636007, acc.: 71.88%] [G loss: 0.823034]\n",
      "epoch:49 step:38578 [D loss: 0.672112, acc.: 57.03%] [G loss: 0.801099]\n",
      "epoch:49 step:38579 [D loss: 0.636030, acc.: 69.53%] [G loss: 0.817351]\n",
      "epoch:49 step:38580 [D loss: 0.649288, acc.: 64.06%] [G loss: 0.931800]\n",
      "epoch:49 step:38581 [D loss: 0.748140, acc.: 46.09%] [G loss: 0.790092]\n",
      "epoch:49 step:38582 [D loss: 0.738075, acc.: 48.44%] [G loss: 0.781357]\n",
      "epoch:49 step:38583 [D loss: 0.693091, acc.: 52.34%] [G loss: 0.834636]\n",
      "epoch:49 step:38584 [D loss: 0.714191, acc.: 54.69%] [G loss: 0.801136]\n",
      "epoch:49 step:38585 [D loss: 0.702172, acc.: 57.81%] [G loss: 0.789918]\n",
      "epoch:49 step:38586 [D loss: 0.676316, acc.: 57.81%] [G loss: 0.858403]\n",
      "epoch:49 step:38587 [D loss: 0.634918, acc.: 65.62%] [G loss: 0.852421]\n",
      "epoch:49 step:38588 [D loss: 0.611831, acc.: 72.66%] [G loss: 0.791471]\n",
      "epoch:49 step:38589 [D loss: 0.669407, acc.: 57.03%] [G loss: 0.778475]\n",
      "epoch:49 step:38590 [D loss: 0.645788, acc.: 66.41%] [G loss: 0.784161]\n",
      "epoch:49 step:38591 [D loss: 0.696211, acc.: 50.78%] [G loss: 0.820613]\n",
      "epoch:49 step:38592 [D loss: 0.725011, acc.: 44.53%] [G loss: 0.745995]\n",
      "epoch:49 step:38593 [D loss: 0.677879, acc.: 58.59%] [G loss: 0.775684]\n",
      "epoch:49 step:38594 [D loss: 0.709991, acc.: 50.00%] [G loss: 0.836702]\n",
      "epoch:49 step:38595 [D loss: 0.602332, acc.: 71.09%] [G loss: 0.855007]\n",
      "epoch:49 step:38596 [D loss: 0.626915, acc.: 68.75%] [G loss: 0.889795]\n",
      "epoch:49 step:38597 [D loss: 0.673083, acc.: 57.03%] [G loss: 0.805291]\n",
      "epoch:49 step:38598 [D loss: 0.703196, acc.: 54.69%] [G loss: 0.727013]\n",
      "epoch:49 step:38599 [D loss: 0.694090, acc.: 49.22%] [G loss: 0.679927]\n",
      "epoch:49 step:38600 [D loss: 0.791137, acc.: 36.72%] [G loss: 0.698007]\n",
      "epoch:49 step:38601 [D loss: 0.676270, acc.: 56.25%] [G loss: 0.800617]\n",
      "epoch:49 step:38602 [D loss: 0.677922, acc.: 60.94%] [G loss: 0.735061]\n",
      "epoch:49 step:38603 [D loss: 0.708203, acc.: 55.47%] [G loss: 0.755357]\n",
      "epoch:49 step:38604 [D loss: 0.646203, acc.: 64.06%] [G loss: 0.816947]\n",
      "epoch:49 step:38605 [D loss: 0.699775, acc.: 56.25%] [G loss: 0.767230]\n",
      "epoch:49 step:38606 [D loss: 0.676767, acc.: 57.03%] [G loss: 0.840632]\n",
      "epoch:49 step:38607 [D loss: 0.718717, acc.: 49.22%] [G loss: 0.803772]\n",
      "epoch:49 step:38608 [D loss: 0.648357, acc.: 67.19%] [G loss: 0.828147]\n",
      "epoch:49 step:38609 [D loss: 0.681098, acc.: 56.25%] [G loss: 0.782742]\n",
      "epoch:49 step:38610 [D loss: 0.650046, acc.: 64.06%] [G loss: 0.815496]\n",
      "epoch:49 step:38611 [D loss: 0.671549, acc.: 55.47%] [G loss: 0.772167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38612 [D loss: 0.665636, acc.: 58.59%] [G loss: 0.731770]\n",
      "epoch:49 step:38613 [D loss: 0.658682, acc.: 64.84%] [G loss: 0.818649]\n",
      "epoch:49 step:38614 [D loss: 0.574202, acc.: 82.81%] [G loss: 0.871652]\n",
      "epoch:49 step:38615 [D loss: 0.749854, acc.: 39.84%] [G loss: 0.718161]\n",
      "epoch:49 step:38616 [D loss: 0.654669, acc.: 63.28%] [G loss: 0.774578]\n",
      "epoch:49 step:38617 [D loss: 0.706486, acc.: 51.56%] [G loss: 0.927627]\n",
      "epoch:49 step:38618 [D loss: 0.656552, acc.: 60.16%] [G loss: 0.822591]\n",
      "epoch:49 step:38619 [D loss: 0.673927, acc.: 53.12%] [G loss: 0.782825]\n",
      "epoch:49 step:38620 [D loss: 0.641640, acc.: 67.97%] [G loss: 0.903858]\n",
      "epoch:49 step:38621 [D loss: 0.689270, acc.: 51.56%] [G loss: 0.861012]\n",
      "epoch:49 step:38622 [D loss: 0.554374, acc.: 77.34%] [G loss: 0.875010]\n",
      "epoch:49 step:38623 [D loss: 0.677173, acc.: 57.03%] [G loss: 0.797936]\n",
      "epoch:49 step:38624 [D loss: 0.677899, acc.: 57.03%] [G loss: 0.781470]\n",
      "epoch:49 step:38625 [D loss: 0.636378, acc.: 64.06%] [G loss: 0.739967]\n",
      "epoch:49 step:38626 [D loss: 0.667553, acc.: 60.94%] [G loss: 0.766954]\n",
      "epoch:49 step:38627 [D loss: 0.728288, acc.: 45.31%] [G loss: 0.766573]\n",
      "epoch:49 step:38628 [D loss: 0.680624, acc.: 58.59%] [G loss: 0.886385]\n",
      "epoch:49 step:38629 [D loss: 0.654587, acc.: 61.72%] [G loss: 0.827634]\n",
      "epoch:49 step:38630 [D loss: 0.632733, acc.: 63.28%] [G loss: 0.815498]\n",
      "epoch:49 step:38631 [D loss: 0.597200, acc.: 70.31%] [G loss: 0.752125]\n",
      "epoch:49 step:38632 [D loss: 0.658435, acc.: 60.94%] [G loss: 0.847481]\n",
      "epoch:49 step:38633 [D loss: 0.679836, acc.: 59.38%] [G loss: 0.778917]\n",
      "epoch:49 step:38634 [D loss: 0.611957, acc.: 67.97%] [G loss: 0.862602]\n",
      "epoch:49 step:38635 [D loss: 0.653054, acc.: 60.16%] [G loss: 0.815271]\n",
      "epoch:49 step:38636 [D loss: 0.709258, acc.: 54.69%] [G loss: 0.778715]\n",
      "epoch:49 step:38637 [D loss: 0.675862, acc.: 56.25%] [G loss: 0.862008]\n",
      "epoch:49 step:38638 [D loss: 0.641526, acc.: 64.06%] [G loss: 0.879718]\n",
      "epoch:49 step:38639 [D loss: 0.720485, acc.: 46.88%] [G loss: 0.798962]\n",
      "epoch:49 step:38640 [D loss: 0.644989, acc.: 67.97%] [G loss: 0.768920]\n",
      "epoch:49 step:38641 [D loss: 0.649870, acc.: 61.72%] [G loss: 0.776001]\n",
      "epoch:49 step:38642 [D loss: 0.701918, acc.: 51.56%] [G loss: 0.877012]\n",
      "epoch:49 step:38643 [D loss: 0.671975, acc.: 55.47%] [G loss: 0.716859]\n",
      "epoch:49 step:38644 [D loss: 0.772994, acc.: 37.50%] [G loss: 0.734371]\n",
      "epoch:49 step:38645 [D loss: 0.655469, acc.: 60.94%] [G loss: 0.803835]\n",
      "epoch:49 step:38646 [D loss: 0.631315, acc.: 69.53%] [G loss: 0.871675]\n",
      "epoch:49 step:38647 [D loss: 0.712289, acc.: 43.75%] [G loss: 0.805436]\n",
      "epoch:49 step:38648 [D loss: 0.686399, acc.: 54.69%] [G loss: 0.834518]\n",
      "epoch:49 step:38649 [D loss: 0.701775, acc.: 46.88%] [G loss: 0.829170]\n",
      "epoch:49 step:38650 [D loss: 0.603650, acc.: 73.44%] [G loss: 0.893096]\n",
      "epoch:49 step:38651 [D loss: 0.702405, acc.: 52.34%] [G loss: 0.878573]\n",
      "epoch:49 step:38652 [D loss: 0.654747, acc.: 61.72%] [G loss: 0.838677]\n",
      "epoch:49 step:38653 [D loss: 0.626989, acc.: 68.75%] [G loss: 0.855875]\n",
      "epoch:49 step:38654 [D loss: 0.738834, acc.: 47.66%] [G loss: 0.863222]\n",
      "epoch:49 step:38655 [D loss: 0.653799, acc.: 64.06%] [G loss: 0.776875]\n",
      "epoch:49 step:38656 [D loss: 0.580163, acc.: 77.34%] [G loss: 1.008492]\n",
      "epoch:49 step:38657 [D loss: 0.699751, acc.: 59.38%] [G loss: 0.811705]\n",
      "epoch:49 step:38658 [D loss: 0.729709, acc.: 46.88%] [G loss: 0.867456]\n",
      "epoch:49 step:38659 [D loss: 0.700610, acc.: 52.34%] [G loss: 0.819344]\n",
      "epoch:49 step:38660 [D loss: 0.756584, acc.: 44.53%] [G loss: 0.762979]\n",
      "epoch:49 step:38661 [D loss: 0.683427, acc.: 59.38%] [G loss: 0.809118]\n",
      "epoch:49 step:38662 [D loss: 0.715263, acc.: 50.00%] [G loss: 0.955008]\n",
      "epoch:49 step:38663 [D loss: 0.658054, acc.: 57.81%] [G loss: 0.875032]\n",
      "epoch:49 step:38664 [D loss: 0.655458, acc.: 61.72%] [G loss: 0.866305]\n",
      "epoch:49 step:38665 [D loss: 0.656670, acc.: 62.50%] [G loss: 0.826923]\n",
      "epoch:49 step:38666 [D loss: 0.671835, acc.: 60.16%] [G loss: 0.777645]\n",
      "epoch:49 step:38667 [D loss: 0.690219, acc.: 54.69%] [G loss: 0.804584]\n",
      "epoch:49 step:38668 [D loss: 0.634435, acc.: 65.62%] [G loss: 0.850115]\n",
      "epoch:49 step:38669 [D loss: 0.681672, acc.: 63.28%] [G loss: 0.819092]\n",
      "epoch:49 step:38670 [D loss: 0.564935, acc.: 76.56%] [G loss: 0.871183]\n",
      "epoch:49 step:38671 [D loss: 0.689549, acc.: 53.12%] [G loss: 0.873121]\n",
      "epoch:49 step:38672 [D loss: 0.611060, acc.: 70.31%] [G loss: 0.812897]\n",
      "epoch:49 step:38673 [D loss: 0.597353, acc.: 69.53%] [G loss: 0.829682]\n",
      "epoch:49 step:38674 [D loss: 0.760606, acc.: 42.19%] [G loss: 0.833647]\n",
      "epoch:49 step:38675 [D loss: 0.682659, acc.: 53.12%] [G loss: 0.781292]\n",
      "epoch:49 step:38676 [D loss: 0.623644, acc.: 71.09%] [G loss: 0.774526]\n",
      "epoch:49 step:38677 [D loss: 0.666512, acc.: 57.03%] [G loss: 0.812387]\n",
      "epoch:49 step:38678 [D loss: 0.684399, acc.: 53.12%] [G loss: 0.741540]\n",
      "epoch:49 step:38679 [D loss: 0.628459, acc.: 68.75%] [G loss: 0.773073]\n",
      "epoch:49 step:38680 [D loss: 0.738999, acc.: 42.97%] [G loss: 0.811589]\n",
      "epoch:49 step:38681 [D loss: 0.738019, acc.: 46.88%] [G loss: 0.728947]\n",
      "epoch:49 step:38682 [D loss: 0.670198, acc.: 51.56%] [G loss: 0.847100]\n",
      "epoch:49 step:38683 [D loss: 0.713678, acc.: 47.66%] [G loss: 0.764509]\n",
      "epoch:49 step:38684 [D loss: 0.657066, acc.: 69.53%] [G loss: 0.828480]\n",
      "epoch:49 step:38685 [D loss: 0.611003, acc.: 72.66%] [G loss: 0.781760]\n",
      "epoch:49 step:38686 [D loss: 0.716149, acc.: 51.56%] [G loss: 0.851908]\n",
      "epoch:49 step:38687 [D loss: 0.713372, acc.: 50.78%] [G loss: 0.763842]\n",
      "epoch:49 step:38688 [D loss: 0.687415, acc.: 56.25%] [G loss: 0.834913]\n",
      "epoch:49 step:38689 [D loss: 0.696448, acc.: 52.34%] [G loss: 0.809750]\n",
      "epoch:49 step:38690 [D loss: 0.659431, acc.: 59.38%] [G loss: 0.726681]\n",
      "epoch:49 step:38691 [D loss: 0.654604, acc.: 63.28%] [G loss: 0.895969]\n",
      "epoch:49 step:38692 [D loss: 0.686637, acc.: 55.47%] [G loss: 0.786787]\n",
      "epoch:49 step:38693 [D loss: 0.727965, acc.: 42.97%] [G loss: 0.774135]\n",
      "epoch:49 step:38694 [D loss: 0.719374, acc.: 48.44%] [G loss: 0.726670]\n",
      "epoch:49 step:38695 [D loss: 0.675775, acc.: 54.69%] [G loss: 0.770264]\n",
      "epoch:49 step:38696 [D loss: 0.599768, acc.: 67.19%] [G loss: 0.863380]\n",
      "epoch:49 step:38697 [D loss: 0.685879, acc.: 55.47%] [G loss: 0.771847]\n",
      "epoch:49 step:38698 [D loss: 0.576216, acc.: 75.00%] [G loss: 0.841194]\n",
      "epoch:49 step:38699 [D loss: 0.669600, acc.: 60.16%] [G loss: 0.807521]\n",
      "epoch:49 step:38700 [D loss: 0.680460, acc.: 54.69%] [G loss: 0.827780]\n",
      "epoch:49 step:38701 [D loss: 0.692827, acc.: 53.12%] [G loss: 0.813054]\n",
      "epoch:49 step:38702 [D loss: 0.646261, acc.: 58.59%] [G loss: 0.830346]\n",
      "epoch:49 step:38703 [D loss: 0.653653, acc.: 64.06%] [G loss: 0.872536]\n",
      "epoch:49 step:38704 [D loss: 0.631363, acc.: 67.97%] [G loss: 0.849686]\n",
      "epoch:49 step:38705 [D loss: 0.716834, acc.: 52.34%] [G loss: 0.900560]\n",
      "epoch:49 step:38706 [D loss: 0.705046, acc.: 47.66%] [G loss: 0.899984]\n",
      "epoch:49 step:38707 [D loss: 0.690404, acc.: 55.47%] [G loss: 0.748326]\n",
      "epoch:49 step:38708 [D loss: 0.663140, acc.: 57.81%] [G loss: 0.912542]\n",
      "epoch:49 step:38709 [D loss: 0.711851, acc.: 52.34%] [G loss: 0.828826]\n",
      "epoch:49 step:38710 [D loss: 0.688618, acc.: 57.81%] [G loss: 0.852255]\n",
      "epoch:49 step:38711 [D loss: 0.623285, acc.: 64.06%] [G loss: 0.820003]\n",
      "epoch:49 step:38712 [D loss: 0.661426, acc.: 57.81%] [G loss: 0.828484]\n",
      "epoch:49 step:38713 [D loss: 0.695176, acc.: 46.88%] [G loss: 0.689799]\n",
      "epoch:49 step:38714 [D loss: 0.667479, acc.: 59.38%] [G loss: 0.744363]\n",
      "epoch:49 step:38715 [D loss: 0.709777, acc.: 52.34%] [G loss: 0.758851]\n",
      "epoch:49 step:38716 [D loss: 0.663594, acc.: 60.94%] [G loss: 0.692911]\n",
      "epoch:49 step:38717 [D loss: 0.713329, acc.: 50.00%] [G loss: 0.864621]\n",
      "epoch:49 step:38718 [D loss: 0.651167, acc.: 60.16%] [G loss: 0.862851]\n",
      "epoch:49 step:38719 [D loss: 0.648491, acc.: 64.06%] [G loss: 0.894388]\n",
      "epoch:49 step:38720 [D loss: 0.596261, acc.: 67.97%] [G loss: 0.911449]\n",
      "epoch:49 step:38721 [D loss: 0.638487, acc.: 62.50%] [G loss: 0.861948]\n",
      "epoch:49 step:38722 [D loss: 0.721066, acc.: 45.31%] [G loss: 0.833365]\n",
      "epoch:49 step:38723 [D loss: 0.566915, acc.: 81.25%] [G loss: 0.976531]\n",
      "epoch:49 step:38724 [D loss: 0.695388, acc.: 53.91%] [G loss: 0.804898]\n",
      "epoch:49 step:38725 [D loss: 0.655156, acc.: 57.81%] [G loss: 0.915017]\n",
      "epoch:49 step:38726 [D loss: 0.633976, acc.: 66.41%] [G loss: 0.806992]\n",
      "epoch:49 step:38727 [D loss: 0.661865, acc.: 59.38%] [G loss: 0.738273]\n",
      "epoch:49 step:38728 [D loss: 0.765465, acc.: 41.41%] [G loss: 0.732882]\n",
      "epoch:49 step:38729 [D loss: 0.657654, acc.: 67.19%] [G loss: 0.785105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38730 [D loss: 0.644332, acc.: 60.94%] [G loss: 0.762947]\n",
      "epoch:49 step:38731 [D loss: 0.677957, acc.: 57.03%] [G loss: 0.836508]\n",
      "epoch:49 step:38732 [D loss: 0.658176, acc.: 57.81%] [G loss: 0.942433]\n",
      "epoch:49 step:38733 [D loss: 0.643545, acc.: 67.19%] [G loss: 0.864327]\n",
      "epoch:49 step:38734 [D loss: 0.653879, acc.: 67.19%] [G loss: 0.977155]\n",
      "epoch:49 step:38735 [D loss: 0.610818, acc.: 71.09%] [G loss: 0.845646]\n",
      "epoch:49 step:38736 [D loss: 0.634470, acc.: 68.75%] [G loss: 0.872694]\n",
      "epoch:49 step:38737 [D loss: 0.693738, acc.: 57.81%] [G loss: 0.876287]\n",
      "epoch:49 step:38738 [D loss: 0.685161, acc.: 53.91%] [G loss: 0.828178]\n",
      "epoch:49 step:38739 [D loss: 0.671295, acc.: 63.28%] [G loss: 0.873466]\n",
      "epoch:49 step:38740 [D loss: 0.616603, acc.: 67.19%] [G loss: 0.862315]\n",
      "epoch:49 step:38741 [D loss: 0.716193, acc.: 51.56%] [G loss: 0.717585]\n",
      "epoch:49 step:38742 [D loss: 0.790442, acc.: 35.16%] [G loss: 0.772085]\n",
      "epoch:49 step:38743 [D loss: 0.686054, acc.: 57.81%] [G loss: 0.799432]\n",
      "epoch:49 step:38744 [D loss: 0.647692, acc.: 67.97%] [G loss: 0.915875]\n",
      "epoch:49 step:38745 [D loss: 0.679595, acc.: 53.91%] [G loss: 0.818986]\n",
      "epoch:49 step:38746 [D loss: 0.736121, acc.: 44.53%] [G loss: 0.806215]\n",
      "epoch:49 step:38747 [D loss: 0.677330, acc.: 59.38%] [G loss: 0.813685]\n",
      "epoch:49 step:38748 [D loss: 0.656994, acc.: 66.41%] [G loss: 0.867224]\n",
      "epoch:49 step:38749 [D loss: 0.709966, acc.: 48.44%] [G loss: 0.809653]\n",
      "epoch:49 step:38750 [D loss: 0.673479, acc.: 57.81%] [G loss: 0.845241]\n",
      "epoch:49 step:38751 [D loss: 0.774887, acc.: 33.59%] [G loss: 0.773182]\n",
      "epoch:49 step:38752 [D loss: 0.693643, acc.: 56.25%] [G loss: 0.806143]\n",
      "epoch:49 step:38753 [D loss: 0.654518, acc.: 55.47%] [G loss: 0.879680]\n",
      "epoch:49 step:38754 [D loss: 0.614466, acc.: 70.31%] [G loss: 0.738014]\n",
      "epoch:49 step:38755 [D loss: 0.734967, acc.: 43.75%] [G loss: 0.695020]\n",
      "epoch:49 step:38756 [D loss: 0.654020, acc.: 62.50%] [G loss: 0.800982]\n",
      "epoch:49 step:38757 [D loss: 0.654871, acc.: 64.06%] [G loss: 0.730199]\n",
      "epoch:49 step:38758 [D loss: 0.667046, acc.: 59.38%] [G loss: 0.811016]\n",
      "epoch:49 step:38759 [D loss: 0.629094, acc.: 69.53%] [G loss: 0.794569]\n",
      "epoch:49 step:38760 [D loss: 0.689830, acc.: 57.03%] [G loss: 0.754385]\n",
      "epoch:49 step:38761 [D loss: 0.631084, acc.: 65.62%] [G loss: 0.835683]\n",
      "epoch:49 step:38762 [D loss: 0.654566, acc.: 64.06%] [G loss: 0.835486]\n",
      "epoch:49 step:38763 [D loss: 0.608048, acc.: 71.88%] [G loss: 0.850650]\n",
      "epoch:49 step:38764 [D loss: 0.639509, acc.: 60.16%] [G loss: 0.794267]\n",
      "epoch:49 step:38765 [D loss: 0.658084, acc.: 64.06%] [G loss: 0.787634]\n",
      "epoch:49 step:38766 [D loss: 0.711277, acc.: 50.00%] [G loss: 0.852306]\n",
      "epoch:49 step:38767 [D loss: 0.690663, acc.: 56.25%] [G loss: 0.787541]\n",
      "epoch:49 step:38768 [D loss: 0.646809, acc.: 60.16%] [G loss: 0.776352]\n",
      "epoch:49 step:38769 [D loss: 0.726882, acc.: 46.88%] [G loss: 0.804899]\n",
      "epoch:49 step:38770 [D loss: 0.667467, acc.: 58.59%] [G loss: 0.873228]\n",
      "epoch:49 step:38771 [D loss: 0.671915, acc.: 60.16%] [G loss: 0.859963]\n",
      "epoch:49 step:38772 [D loss: 0.706218, acc.: 56.25%] [G loss: 0.751067]\n",
      "epoch:49 step:38773 [D loss: 0.735988, acc.: 46.09%] [G loss: 0.767423]\n",
      "epoch:49 step:38774 [D loss: 0.609068, acc.: 67.19%] [G loss: 0.732036]\n",
      "epoch:49 step:38775 [D loss: 0.643884, acc.: 61.72%] [G loss: 0.878812]\n",
      "epoch:49 step:38776 [D loss: 0.669738, acc.: 57.81%] [G loss: 0.896277]\n",
      "epoch:49 step:38777 [D loss: 0.704616, acc.: 51.56%] [G loss: 0.840896]\n",
      "epoch:49 step:38778 [D loss: 0.701229, acc.: 50.78%] [G loss: 0.722845]\n",
      "epoch:49 step:38779 [D loss: 0.656596, acc.: 66.41%] [G loss: 0.730581]\n",
      "epoch:49 step:38780 [D loss: 0.772678, acc.: 39.06%] [G loss: 0.760300]\n",
      "epoch:49 step:38781 [D loss: 0.705889, acc.: 57.03%] [G loss: 0.860220]\n",
      "epoch:49 step:38782 [D loss: 0.677833, acc.: 54.69%] [G loss: 0.772693]\n",
      "epoch:49 step:38783 [D loss: 0.773508, acc.: 34.38%] [G loss: 0.721222]\n",
      "epoch:49 step:38784 [D loss: 0.698271, acc.: 57.81%] [G loss: 0.640568]\n",
      "epoch:49 step:38785 [D loss: 0.768393, acc.: 39.84%] [G loss: 0.722912]\n",
      "epoch:49 step:38786 [D loss: 0.621222, acc.: 67.19%] [G loss: 0.809787]\n",
      "epoch:49 step:38787 [D loss: 0.650076, acc.: 61.72%] [G loss: 0.851051]\n",
      "epoch:49 step:38788 [D loss: 0.713149, acc.: 50.78%] [G loss: 0.847762]\n",
      "epoch:49 step:38789 [D loss: 0.728177, acc.: 47.66%] [G loss: 0.814073]\n",
      "epoch:49 step:38790 [D loss: 0.634633, acc.: 66.41%] [G loss: 0.825230]\n",
      "epoch:49 step:38791 [D loss: 0.654993, acc.: 62.50%] [G loss: 0.847592]\n",
      "epoch:49 step:38792 [D loss: 0.655924, acc.: 64.06%] [G loss: 0.857665]\n",
      "epoch:49 step:38793 [D loss: 0.712367, acc.: 47.66%] [G loss: 0.857809]\n",
      "epoch:49 step:38794 [D loss: 0.626673, acc.: 64.06%] [G loss: 0.802442]\n",
      "epoch:49 step:38795 [D loss: 0.696684, acc.: 50.00%] [G loss: 0.782097]\n",
      "epoch:49 step:38796 [D loss: 0.723499, acc.: 42.97%] [G loss: 0.700705]\n",
      "epoch:49 step:38797 [D loss: 0.606548, acc.: 68.75%] [G loss: 0.845872]\n",
      "epoch:49 step:38798 [D loss: 0.671008, acc.: 52.34%] [G loss: 0.825887]\n",
      "epoch:49 step:38799 [D loss: 0.665141, acc.: 64.84%] [G loss: 0.831263]\n",
      "epoch:49 step:38800 [D loss: 0.691637, acc.: 48.44%] [G loss: 0.815439]\n",
      "epoch:49 step:38801 [D loss: 0.665800, acc.: 64.06%] [G loss: 0.853197]\n",
      "epoch:49 step:38802 [D loss: 0.698139, acc.: 50.00%] [G loss: 0.799239]\n",
      "epoch:49 step:38803 [D loss: 0.754913, acc.: 44.53%] [G loss: 0.756301]\n",
      "epoch:49 step:38804 [D loss: 0.646341, acc.: 60.94%] [G loss: 0.857746]\n",
      "epoch:49 step:38805 [D loss: 0.643945, acc.: 64.84%] [G loss: 0.824647]\n",
      "epoch:49 step:38806 [D loss: 0.588452, acc.: 73.44%] [G loss: 0.862279]\n",
      "epoch:49 step:38807 [D loss: 0.710914, acc.: 53.12%] [G loss: 0.774078]\n",
      "epoch:49 step:38808 [D loss: 0.633622, acc.: 64.84%] [G loss: 0.838149]\n",
      "epoch:49 step:38809 [D loss: 0.705955, acc.: 54.69%] [G loss: 0.798199]\n",
      "epoch:49 step:38810 [D loss: 0.620566, acc.: 70.31%] [G loss: 0.804551]\n",
      "epoch:49 step:38811 [D loss: 0.654975, acc.: 66.41%] [G loss: 0.818518]\n",
      "epoch:49 step:38812 [D loss: 0.664390, acc.: 60.16%] [G loss: 0.803820]\n",
      "epoch:49 step:38813 [D loss: 0.595255, acc.: 74.22%] [G loss: 0.824185]\n",
      "epoch:49 step:38814 [D loss: 0.676586, acc.: 57.03%] [G loss: 0.817455]\n",
      "epoch:49 step:38815 [D loss: 0.671992, acc.: 58.59%] [G loss: 0.855852]\n",
      "epoch:49 step:38816 [D loss: 0.695395, acc.: 52.34%] [G loss: 0.786617]\n",
      "epoch:49 step:38817 [D loss: 0.618727, acc.: 70.31%] [G loss: 0.864369]\n",
      "epoch:49 step:38818 [D loss: 0.670574, acc.: 60.16%] [G loss: 0.775972]\n",
      "epoch:49 step:38819 [D loss: 0.692201, acc.: 54.69%] [G loss: 0.715257]\n",
      "epoch:49 step:38820 [D loss: 0.670610, acc.: 53.91%] [G loss: 0.865669]\n",
      "epoch:49 step:38821 [D loss: 0.712659, acc.: 49.22%] [G loss: 0.868649]\n",
      "epoch:49 step:38822 [D loss: 0.699182, acc.: 58.59%] [G loss: 0.736011]\n",
      "epoch:49 step:38823 [D loss: 0.658847, acc.: 65.62%] [G loss: 0.709738]\n",
      "epoch:49 step:38824 [D loss: 0.670323, acc.: 53.12%] [G loss: 0.746353]\n",
      "epoch:49 step:38825 [D loss: 0.721745, acc.: 49.22%] [G loss: 0.922894]\n",
      "epoch:49 step:38826 [D loss: 0.722073, acc.: 50.00%] [G loss: 0.841996]\n",
      "epoch:49 step:38827 [D loss: 0.584175, acc.: 76.56%] [G loss: 0.881946]\n",
      "epoch:49 step:38828 [D loss: 0.641216, acc.: 67.97%] [G loss: 0.779305]\n",
      "epoch:49 step:38829 [D loss: 0.689047, acc.: 57.03%] [G loss: 0.865548]\n",
      "epoch:49 step:38830 [D loss: 0.624905, acc.: 66.41%] [G loss: 0.904149]\n",
      "epoch:49 step:38831 [D loss: 0.759575, acc.: 41.41%] [G loss: 0.717817]\n",
      "epoch:49 step:38832 [D loss: 0.670378, acc.: 57.03%] [G loss: 0.915111]\n",
      "epoch:49 step:38833 [D loss: 0.724180, acc.: 49.22%] [G loss: 0.812816]\n",
      "epoch:49 step:38834 [D loss: 0.675107, acc.: 57.03%] [G loss: 0.774164]\n",
      "epoch:49 step:38835 [D loss: 0.703473, acc.: 48.44%] [G loss: 0.750357]\n",
      "epoch:49 step:38836 [D loss: 0.680647, acc.: 54.69%] [G loss: 0.868948]\n",
      "epoch:49 step:38837 [D loss: 0.666401, acc.: 60.16%] [G loss: 0.771224]\n",
      "epoch:49 step:38838 [D loss: 0.689784, acc.: 53.12%] [G loss: 0.747605]\n",
      "epoch:49 step:38839 [D loss: 0.688640, acc.: 52.34%] [G loss: 0.784432]\n",
      "epoch:49 step:38840 [D loss: 0.720737, acc.: 51.56%] [G loss: 0.875308]\n",
      "epoch:49 step:38841 [D loss: 0.667861, acc.: 54.69%] [G loss: 0.901843]\n",
      "epoch:49 step:38842 [D loss: 0.652004, acc.: 62.50%] [G loss: 0.815946]\n",
      "epoch:49 step:38843 [D loss: 0.722797, acc.: 51.56%] [G loss: 0.813464]\n",
      "epoch:49 step:38844 [D loss: 0.677774, acc.: 57.81%] [G loss: 0.787741]\n",
      "epoch:49 step:38845 [D loss: 0.586694, acc.: 73.44%] [G loss: 0.685417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38846 [D loss: 0.669747, acc.: 58.59%] [G loss: 0.718268]\n",
      "epoch:49 step:38847 [D loss: 0.725824, acc.: 53.12%] [G loss: 0.755168]\n",
      "epoch:49 step:38848 [D loss: 0.728088, acc.: 46.09%] [G loss: 0.787704]\n",
      "epoch:49 step:38849 [D loss: 0.667380, acc.: 59.38%] [G loss: 0.812979]\n",
      "epoch:49 step:38850 [D loss: 0.676259, acc.: 57.03%] [G loss: 0.727385]\n",
      "epoch:49 step:38851 [D loss: 0.662524, acc.: 56.25%] [G loss: 0.889846]\n",
      "epoch:49 step:38852 [D loss: 0.647420, acc.: 66.41%] [G loss: 0.724281]\n",
      "epoch:49 step:38853 [D loss: 0.699800, acc.: 52.34%] [G loss: 0.762827]\n",
      "epoch:49 step:38854 [D loss: 0.715671, acc.: 50.78%] [G loss: 0.775583]\n",
      "epoch:49 step:38855 [D loss: 0.670076, acc.: 64.84%] [G loss: 0.770119]\n",
      "epoch:49 step:38856 [D loss: 0.660226, acc.: 53.91%] [G loss: 0.856166]\n",
      "epoch:49 step:38857 [D loss: 0.735791, acc.: 37.50%] [G loss: 0.596944]\n",
      "epoch:49 step:38858 [D loss: 0.675175, acc.: 60.16%] [G loss: 0.817858]\n",
      "epoch:49 step:38859 [D loss: 0.671845, acc.: 60.16%] [G loss: 0.838993]\n",
      "epoch:49 step:38860 [D loss: 0.702565, acc.: 50.00%] [G loss: 0.869370]\n",
      "epoch:49 step:38861 [D loss: 0.650536, acc.: 61.72%] [G loss: 0.831449]\n",
      "epoch:49 step:38862 [D loss: 0.694550, acc.: 57.03%] [G loss: 0.879418]\n",
      "epoch:49 step:38863 [D loss: 0.690369, acc.: 57.81%] [G loss: 0.832845]\n",
      "epoch:49 step:38864 [D loss: 0.618329, acc.: 65.62%] [G loss: 0.878499]\n",
      "epoch:49 step:38865 [D loss: 0.690658, acc.: 57.03%] [G loss: 0.746661]\n",
      "epoch:49 step:38866 [D loss: 0.723365, acc.: 45.31%] [G loss: 0.800473]\n",
      "epoch:49 step:38867 [D loss: 0.679276, acc.: 57.03%] [G loss: 0.801982]\n",
      "epoch:49 step:38868 [D loss: 0.724407, acc.: 47.66%] [G loss: 0.820014]\n",
      "epoch:49 step:38869 [D loss: 0.610563, acc.: 70.31%] [G loss: 0.805419]\n",
      "epoch:49 step:38870 [D loss: 0.634572, acc.: 67.97%] [G loss: 0.832889]\n",
      "epoch:49 step:38871 [D loss: 0.605337, acc.: 76.56%] [G loss: 0.827274]\n",
      "epoch:49 step:38872 [D loss: 0.682361, acc.: 54.69%] [G loss: 0.826171]\n",
      "epoch:49 step:38873 [D loss: 0.702146, acc.: 55.47%] [G loss: 0.884507]\n",
      "epoch:49 step:38874 [D loss: 0.672168, acc.: 57.81%] [G loss: 0.896810]\n",
      "epoch:49 step:38875 [D loss: 0.641209, acc.: 61.72%] [G loss: 0.805887]\n",
      "epoch:49 step:38876 [D loss: 0.684423, acc.: 57.81%] [G loss: 0.778337]\n",
      "epoch:49 step:38877 [D loss: 0.669184, acc.: 60.16%] [G loss: 0.865969]\n",
      "epoch:49 step:38878 [D loss: 0.776425, acc.: 39.84%] [G loss: 0.777175]\n",
      "epoch:49 step:38879 [D loss: 0.585717, acc.: 75.00%] [G loss: 0.942945]\n",
      "epoch:49 step:38880 [D loss: 0.683247, acc.: 51.56%] [G loss: 0.834612]\n",
      "epoch:49 step:38881 [D loss: 0.669638, acc.: 60.94%] [G loss: 0.768142]\n",
      "epoch:49 step:38882 [D loss: 0.741192, acc.: 50.78%] [G loss: 0.762543]\n",
      "epoch:49 step:38883 [D loss: 0.700801, acc.: 53.12%] [G loss: 0.856984]\n",
      "epoch:49 step:38884 [D loss: 0.724008, acc.: 53.12%] [G loss: 0.833706]\n",
      "epoch:49 step:38885 [D loss: 0.630869, acc.: 66.41%] [G loss: 0.884065]\n",
      "epoch:49 step:38886 [D loss: 0.685056, acc.: 58.59%] [G loss: 0.840868]\n",
      "epoch:49 step:38887 [D loss: 0.613133, acc.: 73.44%] [G loss: 0.967485]\n",
      "epoch:49 step:38888 [D loss: 0.666538, acc.: 57.03%] [G loss: 0.762370]\n",
      "epoch:49 step:38889 [D loss: 0.649240, acc.: 70.31%] [G loss: 0.749569]\n",
      "epoch:49 step:38890 [D loss: 0.696517, acc.: 51.56%] [G loss: 0.974790]\n",
      "epoch:49 step:38891 [D loss: 0.674313, acc.: 54.69%] [G loss: 0.789344]\n",
      "epoch:49 step:38892 [D loss: 0.655352, acc.: 57.81%] [G loss: 0.786530]\n",
      "epoch:49 step:38893 [D loss: 0.661416, acc.: 62.50%] [G loss: 0.769710]\n",
      "epoch:49 step:38894 [D loss: 0.666233, acc.: 59.38%] [G loss: 0.835005]\n",
      "epoch:49 step:38895 [D loss: 0.615958, acc.: 76.56%] [G loss: 0.868687]\n",
      "epoch:49 step:38896 [D loss: 0.675071, acc.: 53.91%] [G loss: 0.712138]\n",
      "epoch:49 step:38897 [D loss: 0.637709, acc.: 70.31%] [G loss: 0.690202]\n",
      "epoch:49 step:38898 [D loss: 0.577510, acc.: 78.12%] [G loss: 0.857054]\n",
      "epoch:49 step:38899 [D loss: 0.654970, acc.: 64.84%] [G loss: 0.779158]\n",
      "epoch:49 step:38900 [D loss: 0.698367, acc.: 49.22%] [G loss: 0.838808]\n",
      "epoch:49 step:38901 [D loss: 0.685258, acc.: 57.03%] [G loss: 0.816773]\n",
      "epoch:49 step:38902 [D loss: 0.698807, acc.: 50.00%] [G loss: 0.715444]\n",
      "epoch:49 step:38903 [D loss: 0.706092, acc.: 57.03%] [G loss: 0.757053]\n",
      "epoch:49 step:38904 [D loss: 0.713501, acc.: 46.88%] [G loss: 0.750748]\n",
      "epoch:49 step:38905 [D loss: 0.648879, acc.: 61.72%] [G loss: 0.896926]\n",
      "epoch:49 step:38906 [D loss: 0.579705, acc.: 75.78%] [G loss: 0.858029]\n",
      "epoch:49 step:38907 [D loss: 0.693476, acc.: 54.69%] [G loss: 0.829687]\n",
      "epoch:49 step:38908 [D loss: 0.697235, acc.: 57.03%] [G loss: 0.858882]\n",
      "epoch:49 step:38909 [D loss: 0.725540, acc.: 49.22%] [G loss: 0.818450]\n",
      "epoch:49 step:38910 [D loss: 0.687748, acc.: 59.38%] [G loss: 0.915602]\n",
      "epoch:49 step:38911 [D loss: 0.650000, acc.: 64.84%] [G loss: 0.873401]\n",
      "epoch:49 step:38912 [D loss: 0.697493, acc.: 53.91%] [G loss: 0.716399]\n",
      "epoch:49 step:38913 [D loss: 0.644315, acc.: 64.06%] [G loss: 0.859834]\n",
      "epoch:49 step:38914 [D loss: 0.656864, acc.: 56.25%] [G loss: 0.681970]\n",
      "epoch:49 step:38915 [D loss: 0.660081, acc.: 57.03%] [G loss: 0.799978]\n",
      "epoch:49 step:38916 [D loss: 0.754255, acc.: 43.75%] [G loss: 0.789786]\n",
      "epoch:49 step:38917 [D loss: 0.671407, acc.: 55.47%] [G loss: 0.845856]\n",
      "epoch:49 step:38918 [D loss: 0.668746, acc.: 61.72%] [G loss: 0.724784]\n",
      "epoch:49 step:38919 [D loss: 0.730642, acc.: 46.09%] [G loss: 0.880365]\n",
      "epoch:49 step:38920 [D loss: 0.664271, acc.: 58.59%] [G loss: 0.723029]\n",
      "epoch:49 step:38921 [D loss: 0.590155, acc.: 74.22%] [G loss: 0.796614]\n",
      "epoch:49 step:38922 [D loss: 0.671158, acc.: 52.34%] [G loss: 0.889392]\n",
      "epoch:49 step:38923 [D loss: 0.720410, acc.: 43.75%] [G loss: 0.808745]\n",
      "epoch:49 step:38924 [D loss: 0.732872, acc.: 44.53%] [G loss: 0.785070]\n",
      "epoch:49 step:38925 [D loss: 0.763623, acc.: 39.06%] [G loss: 0.693892]\n",
      "epoch:49 step:38926 [D loss: 0.648555, acc.: 58.59%] [G loss: 0.798348]\n",
      "epoch:49 step:38927 [D loss: 0.594390, acc.: 71.09%] [G loss: 0.880167]\n",
      "epoch:49 step:38928 [D loss: 0.703849, acc.: 52.34%] [G loss: 0.818346]\n",
      "epoch:49 step:38929 [D loss: 0.709713, acc.: 48.44%] [G loss: 0.962959]\n",
      "epoch:49 step:38930 [D loss: 0.686813, acc.: 53.12%] [G loss: 0.769260]\n",
      "epoch:49 step:38931 [D loss: 0.692450, acc.: 46.09%] [G loss: 0.921483]\n",
      "epoch:49 step:38932 [D loss: 0.612811, acc.: 69.53%] [G loss: 0.899045]\n",
      "epoch:49 step:38933 [D loss: 0.644604, acc.: 64.84%] [G loss: 0.766765]\n",
      "epoch:49 step:38934 [D loss: 0.657988, acc.: 67.97%] [G loss: 0.789673]\n",
      "epoch:49 step:38935 [D loss: 0.676607, acc.: 59.38%] [G loss: 0.821126]\n",
      "epoch:49 step:38936 [D loss: 0.738772, acc.: 48.44%] [G loss: 0.802910]\n",
      "epoch:49 step:38937 [D loss: 0.691344, acc.: 57.03%] [G loss: 0.907615]\n",
      "epoch:49 step:38938 [D loss: 0.620222, acc.: 65.62%] [G loss: 0.779740]\n",
      "epoch:49 step:38939 [D loss: 0.629178, acc.: 67.97%] [G loss: 0.883931]\n",
      "epoch:49 step:38940 [D loss: 0.726836, acc.: 48.44%] [G loss: 0.805216]\n",
      "epoch:49 step:38941 [D loss: 0.774947, acc.: 38.28%] [G loss: 0.785280]\n",
      "epoch:49 step:38942 [D loss: 0.627991, acc.: 68.75%] [G loss: 0.732526]\n",
      "epoch:49 step:38943 [D loss: 0.714042, acc.: 43.75%] [G loss: 0.793234]\n",
      "epoch:49 step:38944 [D loss: 0.672316, acc.: 66.41%] [G loss: 0.781045]\n",
      "epoch:49 step:38945 [D loss: 0.697473, acc.: 50.00%] [G loss: 0.732254]\n",
      "epoch:49 step:38946 [D loss: 0.706707, acc.: 53.12%] [G loss: 0.783958]\n",
      "epoch:49 step:38947 [D loss: 0.607835, acc.: 71.88%] [G loss: 0.828107]\n",
      "epoch:49 step:38948 [D loss: 0.652667, acc.: 64.84%] [G loss: 0.784885]\n",
      "epoch:49 step:38949 [D loss: 0.595000, acc.: 73.44%] [G loss: 0.770822]\n",
      "epoch:49 step:38950 [D loss: 0.650544, acc.: 65.62%] [G loss: 0.823276]\n",
      "epoch:49 step:38951 [D loss: 0.717254, acc.: 50.78%] [G loss: 0.739307]\n",
      "epoch:49 step:38952 [D loss: 0.694224, acc.: 50.78%] [G loss: 0.760271]\n",
      "epoch:49 step:38953 [D loss: 0.663103, acc.: 63.28%] [G loss: 0.708303]\n",
      "epoch:49 step:38954 [D loss: 0.750120, acc.: 38.28%] [G loss: 0.836684]\n",
      "epoch:49 step:38955 [D loss: 0.761694, acc.: 44.53%] [G loss: 0.759800]\n",
      "epoch:49 step:38956 [D loss: 0.627482, acc.: 68.75%] [G loss: 0.826714]\n",
      "epoch:49 step:38957 [D loss: 0.708235, acc.: 55.47%] [G loss: 0.862255]\n",
      "epoch:49 step:38958 [D loss: 0.695938, acc.: 50.00%] [G loss: 0.725666]\n",
      "epoch:49 step:38959 [D loss: 0.678058, acc.: 57.03%] [G loss: 0.785986]\n",
      "epoch:49 step:38960 [D loss: 0.679955, acc.: 60.16%] [G loss: 0.763566]\n",
      "epoch:49 step:38961 [D loss: 0.667989, acc.: 59.38%] [G loss: 0.735574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38962 [D loss: 0.687806, acc.: 52.34%] [G loss: 0.807060]\n",
      "epoch:49 step:38963 [D loss: 0.657792, acc.: 64.84%] [G loss: 0.750479]\n",
      "epoch:49 step:38964 [D loss: 0.682771, acc.: 60.16%] [G loss: 0.764958]\n",
      "epoch:49 step:38965 [D loss: 0.718460, acc.: 49.22%] [G loss: 0.748587]\n",
      "epoch:49 step:38966 [D loss: 0.670081, acc.: 59.38%] [G loss: 0.817547]\n",
      "epoch:49 step:38967 [D loss: 0.598827, acc.: 70.31%] [G loss: 0.748736]\n",
      "epoch:49 step:38968 [D loss: 0.702013, acc.: 46.88%] [G loss: 0.693338]\n",
      "epoch:49 step:38969 [D loss: 0.646073, acc.: 64.06%] [G loss: 0.723900]\n",
      "epoch:49 step:38970 [D loss: 0.727249, acc.: 42.97%] [G loss: 0.870928]\n",
      "epoch:49 step:38971 [D loss: 0.705734, acc.: 53.91%] [G loss: 0.743513]\n",
      "epoch:49 step:38972 [D loss: 0.712405, acc.: 47.66%] [G loss: 0.813561]\n",
      "epoch:49 step:38973 [D loss: 0.675239, acc.: 60.94%] [G loss: 0.822988]\n",
      "epoch:49 step:38974 [D loss: 0.762452, acc.: 41.41%] [G loss: 0.821248]\n",
      "epoch:49 step:38975 [D loss: 0.637307, acc.: 64.06%] [G loss: 0.914423]\n",
      "epoch:49 step:38976 [D loss: 0.714123, acc.: 49.22%] [G loss: 0.815189]\n",
      "epoch:49 step:38977 [D loss: 0.651770, acc.: 64.84%] [G loss: 0.773163]\n",
      "epoch:49 step:38978 [D loss: 0.741381, acc.: 46.09%] [G loss: 0.765784]\n",
      "epoch:49 step:38979 [D loss: 0.664660, acc.: 61.72%] [G loss: 0.760573]\n",
      "epoch:49 step:38980 [D loss: 0.616606, acc.: 73.44%] [G loss: 0.836575]\n",
      "epoch:49 step:38981 [D loss: 0.730484, acc.: 50.78%] [G loss: 0.880894]\n",
      "epoch:49 step:38982 [D loss: 0.714503, acc.: 46.09%] [G loss: 0.853590]\n",
      "epoch:49 step:38983 [D loss: 0.640793, acc.: 62.50%] [G loss: 0.747922]\n",
      "epoch:49 step:38984 [D loss: 0.678657, acc.: 57.03%] [G loss: 0.804824]\n",
      "epoch:49 step:38985 [D loss: 0.701442, acc.: 51.56%] [G loss: 0.818162]\n",
      "epoch:49 step:38986 [D loss: 0.661534, acc.: 58.59%] [G loss: 0.766646]\n",
      "epoch:49 step:38987 [D loss: 0.646575, acc.: 64.06%] [G loss: 0.802463]\n",
      "epoch:49 step:38988 [D loss: 0.656320, acc.: 65.62%] [G loss: 0.900827]\n",
      "epoch:49 step:38989 [D loss: 0.646898, acc.: 64.06%] [G loss: 0.756245]\n",
      "epoch:49 step:38990 [D loss: 0.628229, acc.: 68.75%] [G loss: 0.766154]\n",
      "epoch:49 step:38991 [D loss: 0.708983, acc.: 49.22%] [G loss: 0.878374]\n",
      "epoch:49 step:38992 [D loss: 0.672282, acc.: 61.72%] [G loss: 0.757567]\n",
      "epoch:49 step:38993 [D loss: 0.640097, acc.: 61.72%] [G loss: 0.795906]\n",
      "epoch:49 step:38994 [D loss: 0.661773, acc.: 63.28%] [G loss: 0.827401]\n",
      "epoch:49 step:38995 [D loss: 0.689210, acc.: 57.81%] [G loss: 0.699298]\n",
      "epoch:49 step:38996 [D loss: 0.693745, acc.: 53.91%] [G loss: 0.692427]\n",
      "epoch:49 step:38997 [D loss: 0.655925, acc.: 64.06%] [G loss: 0.775985]\n",
      "epoch:49 step:38998 [D loss: 0.703555, acc.: 50.00%] [G loss: 0.769597]\n",
      "epoch:49 step:38999 [D loss: 0.650195, acc.: 59.38%] [G loss: 0.744804]\n",
      "epoch:49 step:39000 [D loss: 0.692501, acc.: 54.69%] [G loss: 0.846486]\n",
      "epoch:49 step:39001 [D loss: 0.675466, acc.: 56.25%] [G loss: 0.727321]\n",
      "epoch:49 step:39002 [D loss: 0.676804, acc.: 57.81%] [G loss: 0.818954]\n",
      "epoch:49 step:39003 [D loss: 0.742615, acc.: 39.84%] [G loss: 0.768211]\n",
      "epoch:49 step:39004 [D loss: 0.614119, acc.: 69.53%] [G loss: 0.909834]\n",
      "epoch:49 step:39005 [D loss: 0.711253, acc.: 53.91%] [G loss: 0.840642]\n",
      "epoch:49 step:39006 [D loss: 0.730938, acc.: 43.75%] [G loss: 0.772974]\n",
      "epoch:49 step:39007 [D loss: 0.731629, acc.: 46.09%] [G loss: 0.733989]\n",
      "epoch:49 step:39008 [D loss: 0.735497, acc.: 49.22%] [G loss: 0.866541]\n",
      "epoch:49 step:39009 [D loss: 0.646723, acc.: 61.72%] [G loss: 0.866092]\n",
      "epoch:49 step:39010 [D loss: 0.706421, acc.: 54.69%] [G loss: 0.858238]\n",
      "epoch:49 step:39011 [D loss: 0.655135, acc.: 65.62%] [G loss: 0.853770]\n",
      "epoch:49 step:39012 [D loss: 0.616334, acc.: 67.97%] [G loss: 0.903388]\n",
      "epoch:49 step:39013 [D loss: 0.667019, acc.: 60.16%] [G loss: 0.719876]\n",
      "epoch:49 step:39014 [D loss: 0.658683, acc.: 60.94%] [G loss: 0.854702]\n",
      "epoch:49 step:39015 [D loss: 0.615970, acc.: 64.84%] [G loss: 0.814328]\n",
      "epoch:49 step:39016 [D loss: 0.758734, acc.: 41.41%] [G loss: 0.764723]\n",
      "epoch:49 step:39017 [D loss: 0.654169, acc.: 61.72%] [G loss: 0.776096]\n",
      "epoch:49 step:39018 [D loss: 0.691739, acc.: 52.34%] [G loss: 0.831712]\n",
      "epoch:49 step:39019 [D loss: 0.661593, acc.: 58.59%] [G loss: 0.844193]\n",
      "epoch:49 step:39020 [D loss: 0.652861, acc.: 61.72%] [G loss: 0.822754]\n",
      "epoch:49 step:39021 [D loss: 0.691700, acc.: 57.03%] [G loss: 0.850572]\n",
      "epoch:49 step:39022 [D loss: 0.641443, acc.: 65.62%] [G loss: 0.744099]\n",
      "epoch:49 step:39023 [D loss: 0.677021, acc.: 57.81%] [G loss: 0.720973]\n",
      "epoch:49 step:39024 [D loss: 0.710321, acc.: 50.00%] [G loss: 0.791386]\n",
      "epoch:49 step:39025 [D loss: 0.650503, acc.: 60.16%] [G loss: 0.775809]\n",
      "epoch:49 step:39026 [D loss: 0.693103, acc.: 53.91%] [G loss: 0.829670]\n",
      "epoch:49 step:39027 [D loss: 0.657327, acc.: 59.38%] [G loss: 0.871934]\n",
      "epoch:49 step:39028 [D loss: 0.653545, acc.: 59.38%] [G loss: 0.852616]\n",
      "epoch:49 step:39029 [D loss: 0.641460, acc.: 66.41%] [G loss: 0.840180]\n",
      "epoch:49 step:39030 [D loss: 0.645455, acc.: 66.41%] [G loss: 0.820464]\n",
      "epoch:49 step:39031 [D loss: 0.696535, acc.: 50.00%] [G loss: 0.719550]\n",
      "epoch:49 step:39032 [D loss: 0.726175, acc.: 49.22%] [G loss: 0.752264]\n",
      "epoch:49 step:39033 [D loss: 0.678392, acc.: 55.47%] [G loss: 0.747158]\n",
      "epoch:49 step:39034 [D loss: 0.679370, acc.: 56.25%] [G loss: 0.756501]\n",
      "epoch:49 step:39035 [D loss: 0.696323, acc.: 57.03%] [G loss: 0.849240]\n",
      "epoch:49 step:39036 [D loss: 0.680446, acc.: 61.72%] [G loss: 0.716120]\n",
      "epoch:49 step:39037 [D loss: 0.760002, acc.: 39.06%] [G loss: 0.781117]\n",
      "epoch:49 step:39038 [D loss: 0.652839, acc.: 60.94%] [G loss: 0.850868]\n",
      "epoch:49 step:39039 [D loss: 0.774080, acc.: 35.16%] [G loss: 0.834371]\n",
      "epoch:49 step:39040 [D loss: 0.766240, acc.: 34.38%] [G loss: 0.837192]\n",
      "epoch:49 step:39041 [D loss: 0.686429, acc.: 57.03%] [G loss: 0.781209]\n",
      "epoch:49 step:39042 [D loss: 0.691725, acc.: 57.03%] [G loss: 0.843865]\n",
      "epoch:49 step:39043 [D loss: 0.625623, acc.: 67.97%] [G loss: 0.891851]\n",
      "epoch:49 step:39044 [D loss: 0.680961, acc.: 57.81%] [G loss: 0.801669]\n",
      "epoch:49 step:39045 [D loss: 0.641233, acc.: 68.75%] [G loss: 0.910598]\n",
      "epoch:49 step:39046 [D loss: 0.642149, acc.: 67.97%] [G loss: 0.804247]\n",
      "epoch:49 step:39047 [D loss: 0.659501, acc.: 62.50%] [G loss: 0.736214]\n",
      "epoch:49 step:39048 [D loss: 0.655020, acc.: 63.28%] [G loss: 0.863453]\n",
      "epoch:49 step:39049 [D loss: 0.731780, acc.: 45.31%] [G loss: 0.741497]\n",
      "epoch:49 step:39050 [D loss: 0.681748, acc.: 54.69%] [G loss: 0.898876]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        img=img.reshape([3,32,32])\n",
    "        return img\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "model = model.cifar10(128)\n",
    "model.load_state_dict(torch.load('./log/default/best-85.pth'))\n",
    "model.cuda()\n",
    "def get_mean_var(y_logit):\n",
    "    y_logit=np.abs(y_logit-0.1)\n",
    "    return np.mean(y_logit,axis=1)\n",
    "\n",
    "def get_possibility(images):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=100, shuffle=True)\n",
    "    y_logits = []\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "        y_logits=np.array(y_logits)\n",
    "    return y_logits\n",
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('dcgan')):\n",
    "    os.mkdir('saved_models_{}'.format('dcgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('dcgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "import cv2\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, _) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps = []\n",
    "        values = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "\n",
    "                if global_step % save_interval == 0:\n",
    "                    self.mode_drop(epoch, global_step)\n",
    "                    \n",
    "\n",
    "    def mode_drop(self, epoch, global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        # sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        y_logits = get_possibility(gen_imgs)\n",
    "        metrics = get_mean_var(y_logits)\n",
    "\n",
    "\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('global_step:' + str(global_step))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in metrics)\n",
    "        f.writelines('\\n')\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=50, batch_size=64, save_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
