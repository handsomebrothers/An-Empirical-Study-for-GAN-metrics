{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f71c47052b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# #指定使用那块GUP训练\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "# 设置最大占有GPU不超过显存的70%\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 \n",
    "# # 重点：设置动态分配GPU\n",
    "config.gpu_options.allow_growth = True\n",
    "# 创建session时\n",
    "tf.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 389,184\n",
      "Trainable params: 388,800\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,051,779\n",
      "Trainable params: 1,051,139\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "epoch:0 step:1[D loss: 0.627056, acc: 40.62%, op_acc: 7.03%] [G loss: 0.839755]\n",
      "epoch:0 step:2[D loss: 0.643240, acc: 46.09%, op_acc: 3.12%] [G loss: 0.854467]\n",
      "epoch:0 step:3[D loss: 0.599361, acc: 51.56%, op_acc: 6.25%] [G loss: 0.804238]\n",
      "epoch:0 step:4[D loss: 0.609001, acc: 46.88%, op_acc: 10.16%] [G loss: 0.824697]\n",
      "epoch:0 step:5[D loss: 0.555449, acc: 60.16%, op_acc: 10.16%] [G loss: 0.771318]\n",
      "epoch:0 step:6[D loss: 0.566488, acc: 56.25%, op_acc: 7.03%] [G loss: 0.878951]\n",
      "epoch:0 step:7[D loss: 0.576455, acc: 52.34%, op_acc: 14.84%] [G loss: 0.841459]\n",
      "epoch:0 step:8[D loss: 0.536276, acc: 65.62%, op_acc: 15.62%] [G loss: 0.852179]\n",
      "epoch:0 step:9[D loss: 0.567625, acc: 60.94%, op_acc: 9.38%] [G loss: 0.891037]\n",
      "epoch:0 step:10[D loss: 0.550269, acc: 62.50%, op_acc: 11.72%] [G loss: 1.013274]\n",
      "epoch:0 step:11[D loss: 0.530076, acc: 60.16%, op_acc: 13.28%] [G loss: 0.920893]\n",
      "epoch:0 step:12[D loss: 0.554168, acc: 58.59%, op_acc: 16.41%] [G loss: 0.882393]\n",
      "epoch:0 step:13[D loss: 0.550646, acc: 65.62%, op_acc: 12.50%] [G loss: 1.031241]\n",
      "epoch:0 step:14[D loss: 0.517335, acc: 67.19%, op_acc: 15.62%] [G loss: 1.032408]\n",
      "epoch:0 step:15[D loss: 0.522856, acc: 65.62%, op_acc: 9.38%] [G loss: 0.979315]\n",
      "epoch:0 step:16[D loss: 0.541869, acc: 65.62%, op_acc: 15.62%] [G loss: 0.885717]\n",
      "epoch:0 step:17[D loss: 0.501092, acc: 66.41%, op_acc: 16.41%] [G loss: 0.923005]\n",
      "epoch:0 step:18[D loss: 0.482260, acc: 71.09%, op_acc: 11.72%] [G loss: 1.039099]\n",
      "epoch:0 step:19[D loss: 0.466244, acc: 71.09%, op_acc: 20.31%] [G loss: 1.101441]\n",
      "epoch:0 step:20[D loss: 0.515453, acc: 64.06%, op_acc: 10.94%] [G loss: 0.995736]\n",
      "epoch:0 step:21[D loss: 0.499211, acc: 68.75%, op_acc: 13.28%] [G loss: 1.082071]\n",
      "epoch:0 step:22[D loss: 0.493161, acc: 71.09%, op_acc: 19.53%] [G loss: 1.084404]\n",
      "epoch:0 step:23[D loss: 0.481065, acc: 73.44%, op_acc: 14.84%] [G loss: 1.116456]\n",
      "epoch:0 step:24[D loss: 0.491173, acc: 68.75%, op_acc: 18.75%] [G loss: 1.083252]\n",
      "epoch:0 step:25[D loss: 0.500800, acc: 71.88%, op_acc: 10.94%] [G loss: 1.155059]\n",
      "epoch:0 step:26[D loss: 0.476962, acc: 73.44%, op_acc: 18.75%] [G loss: 1.279305]\n",
      "epoch:0 step:27[D loss: 0.519753, acc: 64.84%, op_acc: 14.84%] [G loss: 1.102986]\n",
      "epoch:0 step:28[D loss: 0.479483, acc: 70.31%, op_acc: 14.84%] [G loss: 1.308831]\n",
      "epoch:0 step:29[D loss: 0.469712, acc: 68.75%, op_acc: 17.97%] [G loss: 1.213127]\n",
      "epoch:0 step:30[D loss: 0.534080, acc: 55.47%, op_acc: 15.62%] [G loss: 1.200033]\n",
      "epoch:0 step:31[D loss: 0.478293, acc: 70.31%, op_acc: 15.62%] [G loss: 1.136039]\n",
      "epoch:0 step:32[D loss: 0.562429, acc: 61.72%, op_acc: 15.62%] [G loss: 0.983211]\n",
      "epoch:0 step:33[D loss: 0.535087, acc: 64.84%, op_acc: 17.97%] [G loss: 1.022690]\n",
      "epoch:0 step:34[D loss: 0.468621, acc: 74.22%, op_acc: 14.06%] [G loss: 1.033994]\n",
      "epoch:0 step:35[D loss: 0.473437, acc: 71.09%, op_acc: 16.41%] [G loss: 1.183675]\n",
      "epoch:0 step:36[D loss: 0.554570, acc: 59.38%, op_acc: 18.75%] [G loss: 1.090540]\n",
      "epoch:0 step:37[D loss: 0.458746, acc: 73.44%, op_acc: 21.09%] [G loss: 1.210298]\n",
      "epoch:0 step:38[D loss: 0.453482, acc: 70.31%, op_acc: 22.66%] [G loss: 1.163013]\n",
      "epoch:0 step:39[D loss: 0.527591, acc: 60.16%, op_acc: 17.19%] [G loss: 1.153060]\n",
      "epoch:0 step:40[D loss: 0.556451, acc: 59.38%, op_acc: 20.31%] [G loss: 1.056972]\n",
      "epoch:0 step:41[D loss: 0.474826, acc: 67.19%, op_acc: 19.53%] [G loss: 1.038928]\n",
      "epoch:0 step:42[D loss: 0.525232, acc: 66.41%, op_acc: 19.53%] [G loss: 1.062182]\n",
      "epoch:0 step:43[D loss: 0.495475, acc: 69.53%, op_acc: 11.72%] [G loss: 1.306793]\n",
      "epoch:0 step:44[D loss: 0.468519, acc: 71.09%, op_acc: 14.06%] [G loss: 1.353902]\n",
      "epoch:0 step:45[D loss: 0.450664, acc: 74.22%, op_acc: 21.09%] [G loss: 1.145522]\n",
      "epoch:0 step:46[D loss: 0.504513, acc: 63.28%, op_acc: 21.09%] [G loss: 1.248324]\n",
      "epoch:0 step:47[D loss: 0.476120, acc: 72.66%, op_acc: 19.53%] [G loss: 1.196981]\n",
      "epoch:0 step:48[D loss: 0.497258, acc: 67.97%, op_acc: 22.66%] [G loss: 1.110841]\n",
      "epoch:0 step:49[D loss: 0.511229, acc: 66.41%, op_acc: 19.53%] [G loss: 1.210703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:50[D loss: 0.510624, acc: 64.06%, op_acc: 17.97%] [G loss: 1.152895]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:41: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:51[D loss: 0.489091, acc: 69.53%, op_acc: 23.44%] [G loss: 1.192231]\n",
      "epoch:0 step:52[D loss: 0.523982, acc: 62.50%, op_acc: 22.66%] [G loss: 1.034576]\n",
      "epoch:0 step:53[D loss: 0.498565, acc: 64.06%, op_acc: 21.09%] [G loss: 1.202705]\n",
      "epoch:0 step:54[D loss: 0.494002, acc: 67.19%, op_acc: 17.97%] [G loss: 1.295278]\n",
      "epoch:0 step:55[D loss: 0.480611, acc: 67.97%, op_acc: 21.88%] [G loss: 1.144008]\n",
      "epoch:0 step:56[D loss: 0.442948, acc: 75.78%, op_acc: 16.41%] [G loss: 1.158432]\n",
      "epoch:0 step:57[D loss: 0.467681, acc: 70.31%, op_acc: 19.53%] [G loss: 1.278177]\n",
      "epoch:0 step:58[D loss: 0.555404, acc: 54.69%, op_acc: 21.88%] [G loss: 1.058065]\n",
      "epoch:0 step:59[D loss: 0.451221, acc: 74.22%, op_acc: 21.88%] [G loss: 1.167421]\n",
      "epoch:0 step:60[D loss: 0.426566, acc: 81.25%, op_acc: 17.97%] [G loss: 1.252789]\n",
      "epoch:0 step:61[D loss: 0.559624, acc: 58.59%, op_acc: 17.19%] [G loss: 1.143166]\n",
      "epoch:0 step:62[D loss: 0.492029, acc: 69.53%, op_acc: 21.09%] [G loss: 1.090529]\n",
      "epoch:0 step:63[D loss: 0.475641, acc: 68.75%, op_acc: 19.53%] [G loss: 1.278408]\n",
      "epoch:0 step:64[D loss: 0.491328, acc: 62.50%, op_acc: 18.75%] [G loss: 1.396296]\n",
      "epoch:0 step:65[D loss: 0.399224, acc: 83.59%, op_acc: 21.09%] [G loss: 1.286651]\n",
      "epoch:0 step:66[D loss: 0.443032, acc: 75.00%, op_acc: 18.75%] [G loss: 1.157748]\n",
      "epoch:0 step:67[D loss: 0.525717, acc: 64.06%, op_acc: 28.91%] [G loss: 1.287083]\n",
      "epoch:0 step:68[D loss: 0.492793, acc: 66.41%, op_acc: 18.75%] [G loss: 1.155504]\n",
      "epoch:0 step:69[D loss: 0.482511, acc: 75.00%, op_acc: 20.31%] [G loss: 1.280797]\n",
      "epoch:0 step:70[D loss: 0.455455, acc: 76.56%, op_acc: 19.53%] [G loss: 1.160076]\n",
      "epoch:0 step:71[D loss: 0.507225, acc: 64.84%, op_acc: 21.09%] [G loss: 1.076580]\n",
      "epoch:0 step:72[D loss: 0.478687, acc: 61.72%, op_acc: 21.88%] [G loss: 1.021790]\n",
      "epoch:0 step:73[D loss: 0.479614, acc: 63.28%, op_acc: 19.53%] [G loss: 1.347885]\n",
      "epoch:0 step:74[D loss: 0.449573, acc: 71.09%, op_acc: 23.44%] [G loss: 1.280373]\n",
      "epoch:0 step:75[D loss: 0.488349, acc: 70.31%, op_acc: 22.66%] [G loss: 1.332164]\n",
      "epoch:0 step:76[D loss: 0.487391, acc: 71.09%, op_acc: 20.31%] [G loss: 1.354542]\n",
      "epoch:0 step:77[D loss: 0.503451, acc: 64.84%, op_acc: 17.97%] [G loss: 1.337100]\n",
      "epoch:0 step:78[D loss: 0.441027, acc: 76.56%, op_acc: 17.97%] [G loss: 1.410167]\n",
      "epoch:0 step:79[D loss: 0.484031, acc: 72.66%, op_acc: 18.75%] [G loss: 1.271275]\n",
      "epoch:0 step:80[D loss: 0.463718, acc: 75.00%, op_acc: 15.62%] [G loss: 1.194895]\n",
      "epoch:0 step:81[D loss: 0.448306, acc: 78.12%, op_acc: 19.53%] [G loss: 1.284314]\n",
      "epoch:0 step:82[D loss: 0.506113, acc: 66.41%, op_acc: 17.19%] [G loss: 1.337056]\n",
      "epoch:0 step:83[D loss: 0.521080, acc: 65.62%, op_acc: 16.41%] [G loss: 1.212135]\n",
      "epoch:0 step:84[D loss: 0.443766, acc: 71.09%, op_acc: 21.09%] [G loss: 1.329822]\n",
      "epoch:0 step:85[D loss: 0.503291, acc: 64.06%, op_acc: 22.66%] [G loss: 1.215450]\n",
      "epoch:0 step:86[D loss: 0.472306, acc: 73.44%, op_acc: 17.19%] [G loss: 1.281427]\n",
      "epoch:0 step:87[D loss: 0.432280, acc: 75.00%, op_acc: 25.00%] [G loss: 1.150122]\n",
      "epoch:0 step:88[D loss: 0.485001, acc: 64.84%, op_acc: 19.53%] [G loss: 1.272885]\n",
      "epoch:0 step:89[D loss: 0.410126, acc: 78.91%, op_acc: 25.00%] [G loss: 1.474307]\n",
      "epoch:0 step:90[D loss: 0.431476, acc: 81.25%, op_acc: 18.75%] [G loss: 1.426355]\n",
      "epoch:0 step:91[D loss: 0.458375, acc: 74.22%, op_acc: 23.44%] [G loss: 1.357655]\n",
      "epoch:0 step:92[D loss: 0.431630, acc: 74.22%, op_acc: 22.66%] [G loss: 1.369899]\n",
      "epoch:0 step:93[D loss: 0.451497, acc: 71.88%, op_acc: 17.19%] [G loss: 1.228984]\n",
      "epoch:0 step:94[D loss: 0.421811, acc: 76.56%, op_acc: 21.09%] [G loss: 1.380638]\n",
      "epoch:0 step:95[D loss: 0.393874, acc: 84.38%, op_acc: 23.44%] [G loss: 1.458222]\n",
      "epoch:0 step:96[D loss: 0.475294, acc: 65.62%, op_acc: 20.31%] [G loss: 1.376799]\n",
      "epoch:0 step:97[D loss: 0.405524, acc: 75.00%, op_acc: 25.00%] [G loss: 1.460117]\n",
      "epoch:0 step:98[D loss: 0.411827, acc: 78.12%, op_acc: 23.44%] [G loss: 1.470923]\n",
      "epoch:0 step:99[D loss: 0.409635, acc: 82.03%, op_acc: 25.00%] [G loss: 1.542182]\n",
      "epoch:0 step:100[D loss: 0.436149, acc: 76.56%, op_acc: 23.44%] [G loss: 1.550481]\n",
      "epoch:0 step:101[D loss: 0.399760, acc: 78.12%, op_acc: 21.88%] [G loss: 1.343331]\n",
      "epoch:0 step:102[D loss: 0.415450, acc: 75.78%, op_acc: 23.44%] [G loss: 1.404708]\n",
      "epoch:0 step:103[D loss: 0.405834, acc: 81.25%, op_acc: 21.09%] [G loss: 1.623125]\n",
      "epoch:0 step:104[D loss: 0.414312, acc: 79.69%, op_acc: 21.88%] [G loss: 1.501623]\n",
      "epoch:0 step:105[D loss: 0.459874, acc: 71.88%, op_acc: 25.78%] [G loss: 1.393687]\n",
      "epoch:0 step:106[D loss: 0.378258, acc: 80.47%, op_acc: 31.25%] [G loss: 1.562064]\n",
      "epoch:0 step:107[D loss: 0.416760, acc: 78.91%, op_acc: 24.22%] [G loss: 1.512834]\n",
      "epoch:0 step:108[D loss: 0.449806, acc: 73.44%, op_acc: 16.41%] [G loss: 1.487022]\n",
      "epoch:0 step:109[D loss: 0.396171, acc: 83.59%, op_acc: 19.53%] [G loss: 1.589707]\n",
      "epoch:0 step:110[D loss: 0.388523, acc: 84.38%, op_acc: 25.00%] [G loss: 1.745908]\n",
      "epoch:0 step:111[D loss: 0.327987, acc: 87.50%, op_acc: 25.00%] [G loss: 1.649945]\n",
      "epoch:0 step:112[D loss: 0.377136, acc: 83.59%, op_acc: 29.69%] [G loss: 1.533380]\n",
      "epoch:0 step:113[D loss: 0.391075, acc: 82.03%, op_acc: 27.34%] [G loss: 1.693893]\n",
      "epoch:0 step:114[D loss: 0.335371, acc: 88.28%, op_acc: 35.94%] [G loss: 1.795610]\n",
      "epoch:0 step:115[D loss: 0.356186, acc: 85.94%, op_acc: 20.31%] [G loss: 1.718868]\n",
      "epoch:0 step:116[D loss: 0.377038, acc: 82.81%, op_acc: 28.12%] [G loss: 1.877725]\n",
      "epoch:0 step:117[D loss: 0.348188, acc: 87.50%, op_acc: 35.16%] [G loss: 1.785019]\n",
      "epoch:0 step:118[D loss: 0.340776, acc: 89.06%, op_acc: 25.78%] [G loss: 1.799496]\n",
      "epoch:0 step:119[D loss: 0.376427, acc: 86.72%, op_acc: 30.47%] [G loss: 1.801971]\n",
      "epoch:0 step:120[D loss: 0.415791, acc: 75.78%, op_acc: 21.88%] [G loss: 1.889401]\n",
      "epoch:0 step:121[D loss: 0.336668, acc: 90.62%, op_acc: 35.16%] [G loss: 1.768558]\n",
      "epoch:0 step:122[D loss: 0.364314, acc: 85.94%, op_acc: 31.25%] [G loss: 1.925702]\n",
      "epoch:0 step:123[D loss: 0.349855, acc: 87.50%, op_acc: 34.38%] [G loss: 1.808074]\n",
      "epoch:0 step:124[D loss: 0.317306, acc: 88.28%, op_acc: 28.91%] [G loss: 1.887377]\n",
      "epoch:0 step:125[D loss: 0.330967, acc: 89.84%, op_acc: 35.16%] [G loss: 2.137048]\n",
      "epoch:0 step:126[D loss: 0.321688, acc: 91.41%, op_acc: 31.25%] [G loss: 2.033363]\n",
      "epoch:0 step:127[D loss: 0.316027, acc: 90.62%, op_acc: 35.16%] [G loss: 2.014094]\n",
      "epoch:0 step:128[D loss: 0.325288, acc: 89.06%, op_acc: 38.28%] [G loss: 1.932175]\n",
      "epoch:0 step:129[D loss: 0.314396, acc: 91.41%, op_acc: 36.72%] [G loss: 1.990048]\n",
      "epoch:0 step:130[D loss: 0.309886, acc: 89.06%, op_acc: 33.59%] [G loss: 2.163132]\n",
      "epoch:0 step:131[D loss: 0.338685, acc: 92.19%, op_acc: 25.00%] [G loss: 2.007796]\n",
      "epoch:0 step:132[D loss: 0.312413, acc: 92.19%, op_acc: 35.94%] [G loss: 2.271754]\n",
      "epoch:0 step:133[D loss: 0.324017, acc: 90.62%, op_acc: 33.59%] [G loss: 2.176312]\n",
      "epoch:0 step:134[D loss: 0.305596, acc: 90.62%, op_acc: 35.94%] [G loss: 2.224750]\n",
      "epoch:0 step:135[D loss: 0.287913, acc: 96.09%, op_acc: 34.38%] [G loss: 2.351749]\n",
      "epoch:0 step:136[D loss: 0.271588, acc: 96.88%, op_acc: 37.50%] [G loss: 2.220562]\n",
      "epoch:0 step:137[D loss: 0.307497, acc: 92.97%, op_acc: 38.28%] [G loss: 2.332533]\n",
      "epoch:0 step:138[D loss: 0.278047, acc: 94.53%, op_acc: 41.41%] [G loss: 2.488060]\n",
      "epoch:0 step:139[D loss: 0.295612, acc: 92.97%, op_acc: 41.41%] [G loss: 2.268878]\n",
      "epoch:0 step:140[D loss: 0.320067, acc: 92.97%, op_acc: 39.84%] [G loss: 2.329127]\n",
      "epoch:0 step:141[D loss: 0.301948, acc: 96.88%, op_acc: 40.62%] [G loss: 2.462780]\n",
      "epoch:0 step:142[D loss: 0.321058, acc: 89.06%, op_acc: 39.84%] [G loss: 2.358896]\n",
      "epoch:0 step:143[D loss: 0.302427, acc: 92.19%, op_acc: 36.72%] [G loss: 2.298460]\n",
      "epoch:0 step:144[D loss: 0.294892, acc: 91.41%, op_acc: 35.16%] [G loss: 2.225134]\n",
      "epoch:0 step:145[D loss: 0.301836, acc: 92.97%, op_acc: 39.84%] [G loss: 2.368206]\n",
      "epoch:0 step:146[D loss: 0.275814, acc: 95.31%, op_acc: 39.06%] [G loss: 2.377817]\n",
      "epoch:0 step:147[D loss: 0.233411, acc: 97.66%, op_acc: 44.53%] [G loss: 2.458922]\n",
      "epoch:0 step:148[D loss: 0.293885, acc: 94.53%, op_acc: 46.09%] [G loss: 2.444318]\n",
      "epoch:0 step:149[D loss: 0.241627, acc: 96.09%, op_acc: 47.66%] [G loss: 2.620741]\n",
      "epoch:0 step:150[D loss: 0.267208, acc: 92.97%, op_acc: 53.91%] [G loss: 2.528666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:151[D loss: 0.244175, acc: 96.09%, op_acc: 51.56%] [G loss: 2.483858]\n",
      "epoch:0 step:152[D loss: 0.272119, acc: 95.31%, op_acc: 48.44%] [G loss: 2.578873]\n",
      "epoch:0 step:153[D loss: 0.289902, acc: 91.41%, op_acc: 46.88%] [G loss: 2.482602]\n",
      "epoch:0 step:154[D loss: 0.257405, acc: 95.31%, op_acc: 46.88%] [G loss: 2.288687]\n",
      "epoch:0 step:155[D loss: 0.289838, acc: 92.19%, op_acc: 47.66%] [G loss: 2.215502]\n",
      "epoch:0 step:156[D loss: 0.280411, acc: 94.53%, op_acc: 41.41%] [G loss: 2.453908]\n",
      "epoch:0 step:157[D loss: 0.260478, acc: 92.19%, op_acc: 51.56%] [G loss: 2.424006]\n",
      "epoch:0 step:158[D loss: 0.306065, acc: 92.19%, op_acc: 44.53%] [G loss: 2.462677]\n",
      "epoch:0 step:159[D loss: 0.274901, acc: 93.75%, op_acc: 44.53%] [G loss: 2.631100]\n",
      "epoch:0 step:160[D loss: 0.288442, acc: 93.75%, op_acc: 46.09%] [G loss: 2.291822]\n",
      "epoch:0 step:161[D loss: 0.341343, acc: 82.81%, op_acc: 53.12%] [G loss: 2.251153]\n",
      "epoch:0 step:162[D loss: 0.274917, acc: 95.31%, op_acc: 43.75%] [G loss: 2.605448]\n",
      "epoch:0 step:163[D loss: 0.314494, acc: 90.62%, op_acc: 42.19%] [G loss: 2.613817]\n",
      "epoch:0 step:164[D loss: 0.361894, acc: 87.50%, op_acc: 31.25%] [G loss: 1.980978]\n",
      "epoch:0 step:165[D loss: 0.289953, acc: 92.19%, op_acc: 50.78%] [G loss: 2.193928]\n",
      "epoch:0 step:166[D loss: 0.388203, acc: 82.03%, op_acc: 29.69%] [G loss: 1.876815]\n",
      "epoch:0 step:167[D loss: 0.292180, acc: 90.62%, op_acc: 41.41%] [G loss: 1.951963]\n",
      "epoch:0 step:168[D loss: 0.304209, acc: 88.28%, op_acc: 41.41%] [G loss: 1.924448]\n",
      "epoch:0 step:169[D loss: 0.369771, acc: 82.81%, op_acc: 32.81%] [G loss: 1.766457]\n",
      "epoch:0 step:170[D loss: 0.363923, acc: 80.47%, op_acc: 42.19%] [G loss: 1.832025]\n",
      "epoch:0 step:171[D loss: 0.447831, acc: 72.66%, op_acc: 31.25%] [G loss: 1.748342]\n",
      "epoch:0 step:172[D loss: 0.320165, acc: 88.28%, op_acc: 42.19%] [G loss: 1.998835]\n",
      "epoch:0 step:173[D loss: 0.321701, acc: 86.72%, op_acc: 34.38%] [G loss: 1.847719]\n",
      "epoch:0 step:174[D loss: 0.474667, acc: 72.66%, op_acc: 29.69%] [G loss: 1.651159]\n",
      "epoch:0 step:175[D loss: 0.470355, acc: 70.31%, op_acc: 26.56%] [G loss: 1.799179]\n",
      "epoch:0 step:176[D loss: 0.403589, acc: 80.47%, op_acc: 24.22%] [G loss: 1.628800]\n",
      "epoch:0 step:177[D loss: 0.427369, acc: 77.34%, op_acc: 29.69%] [G loss: 2.100964]\n",
      "epoch:0 step:178[D loss: 0.433190, acc: 73.44%, op_acc: 28.91%] [G loss: 1.922569]\n",
      "epoch:0 step:179[D loss: 0.391519, acc: 77.34%, op_acc: 35.94%] [G loss: 1.668888]\n",
      "epoch:0 step:180[D loss: 0.514620, acc: 72.66%, op_acc: 21.88%] [G loss: 1.630713]\n",
      "epoch:0 step:181[D loss: 0.398021, acc: 77.34%, op_acc: 28.91%] [G loss: 1.864608]\n",
      "epoch:0 step:182[D loss: 0.415812, acc: 76.56%, op_acc: 33.59%] [G loss: 1.817877]\n",
      "epoch:0 step:183[D loss: 0.527084, acc: 62.50%, op_acc: 24.22%] [G loss: 1.549371]\n",
      "epoch:0 step:184[D loss: 0.479181, acc: 71.09%, op_acc: 28.91%] [G loss: 1.538121]\n",
      "epoch:0 step:185[D loss: 0.557086, acc: 59.38%, op_acc: 20.31%] [G loss: 1.426259]\n",
      "epoch:0 step:186[D loss: 0.468752, acc: 72.66%, op_acc: 18.75%] [G loss: 1.636685]\n",
      "epoch:0 step:187[D loss: 0.486579, acc: 69.53%, op_acc: 28.12%] [G loss: 2.055177]\n",
      "epoch:0 step:188[D loss: 0.511062, acc: 67.97%, op_acc: 26.56%] [G loss: 1.689931]\n",
      "epoch:0 step:189[D loss: 0.395374, acc: 81.25%, op_acc: 26.56%] [G loss: 1.861080]\n",
      "epoch:0 step:190[D loss: 0.598764, acc: 55.47%, op_acc: 20.31%] [G loss: 1.556129]\n",
      "epoch:0 step:191[D loss: 0.510974, acc: 61.72%, op_acc: 25.78%] [G loss: 1.850026]\n",
      "epoch:0 step:192[D loss: 0.580224, acc: 58.59%, op_acc: 20.31%] [G loss: 1.368953]\n",
      "epoch:0 step:193[D loss: 0.599053, acc: 56.25%, op_acc: 17.97%] [G loss: 1.584227]\n",
      "epoch:0 step:194[D loss: 0.493299, acc: 64.84%, op_acc: 21.09%] [G loss: 1.437993]\n",
      "epoch:0 step:195[D loss: 0.585257, acc: 56.25%, op_acc: 18.75%] [G loss: 1.634174]\n",
      "epoch:0 step:196[D loss: 0.468893, acc: 75.78%, op_acc: 19.53%] [G loss: 1.679391]\n",
      "epoch:0 step:197[D loss: 0.546321, acc: 60.16%, op_acc: 20.31%] [G loss: 1.484767]\n",
      "epoch:0 step:198[D loss: 0.523072, acc: 61.72%, op_acc: 22.66%] [G loss: 1.433181]\n",
      "epoch:0 step:199[D loss: 0.601200, acc: 53.91%, op_acc: 16.41%] [G loss: 1.555894]\n",
      "epoch:0 step:200[D loss: 0.496559, acc: 70.31%, op_acc: 19.53%] [G loss: 1.490766]\n",
      "epoch:0 step:201[D loss: 0.577043, acc: 57.03%, op_acc: 22.66%] [G loss: 1.442910]\n",
      "epoch:0 step:202[D loss: 0.523443, acc: 65.62%, op_acc: 24.22%] [G loss: 1.978307]\n",
      "epoch:0 step:203[D loss: 0.531213, acc: 65.62%, op_acc: 21.88%] [G loss: 1.801083]\n",
      "epoch:0 step:204[D loss: 0.481573, acc: 67.19%, op_acc: 23.44%] [G loss: 1.645556]\n",
      "epoch:0 step:205[D loss: 0.521496, acc: 64.06%, op_acc: 28.91%] [G loss: 1.480218]\n",
      "epoch:0 step:206[D loss: 0.614827, acc: 57.03%, op_acc: 15.62%] [G loss: 1.413429]\n",
      "epoch:0 step:207[D loss: 0.441161, acc: 72.66%, op_acc: 32.81%] [G loss: 1.539613]\n",
      "epoch:0 step:208[D loss: 0.550244, acc: 57.81%, op_acc: 22.66%] [G loss: 1.428232]\n",
      "epoch:0 step:209[D loss: 0.486896, acc: 73.44%, op_acc: 24.22%] [G loss: 1.672318]\n",
      "epoch:0 step:210[D loss: 0.543830, acc: 60.94%, op_acc: 12.50%] [G loss: 1.287207]\n",
      "epoch:0 step:211[D loss: 0.468908, acc: 66.41%, op_acc: 23.44%] [G loss: 1.644967]\n",
      "epoch:0 step:212[D loss: 0.504062, acc: 71.09%, op_acc: 19.53%] [G loss: 2.011341]\n",
      "epoch:0 step:213[D loss: 0.528388, acc: 68.75%, op_acc: 23.44%] [G loss: 1.843935]\n",
      "epoch:0 step:214[D loss: 0.521844, acc: 65.62%, op_acc: 27.34%] [G loss: 1.376477]\n",
      "epoch:0 step:215[D loss: 0.446140, acc: 71.88%, op_acc: 31.25%] [G loss: 1.443146]\n",
      "epoch:0 step:216[D loss: 0.568754, acc: 61.72%, op_acc: 23.44%] [G loss: 1.485051]\n",
      "epoch:0 step:217[D loss: 0.399220, acc: 78.12%, op_acc: 26.56%] [G loss: 2.087165]\n",
      "epoch:0 step:218[D loss: 0.568375, acc: 60.16%, op_acc: 18.75%] [G loss: 1.686896]\n",
      "epoch:0 step:219[D loss: 0.468837, acc: 73.44%, op_acc: 26.56%] [G loss: 1.710839]\n",
      "epoch:0 step:220[D loss: 0.441828, acc: 75.78%, op_acc: 22.66%] [G loss: 2.026073]\n",
      "epoch:0 step:221[D loss: 0.546391, acc: 66.41%, op_acc: 28.91%] [G loss: 1.708619]\n",
      "epoch:0 step:222[D loss: 0.473405, acc: 70.31%, op_acc: 28.91%] [G loss: 1.723906]\n",
      "epoch:0 step:223[D loss: 0.454985, acc: 71.09%, op_acc: 25.78%] [G loss: 1.441565]\n",
      "epoch:0 step:224[D loss: 0.473899, acc: 67.19%, op_acc: 24.22%] [G loss: 1.356845]\n",
      "epoch:0 step:225[D loss: 0.479048, acc: 68.75%, op_acc: 25.00%] [G loss: 1.290180]\n",
      "epoch:0 step:226[D loss: 0.418171, acc: 76.56%, op_acc: 32.03%] [G loss: 1.462335]\n",
      "epoch:0 step:227[D loss: 0.586261, acc: 54.69%, op_acc: 21.09%] [G loss: 1.139261]\n",
      "epoch:0 step:228[D loss: 0.538098, acc: 62.50%, op_acc: 26.56%] [G loss: 1.335075]\n",
      "epoch:0 step:229[D loss: 0.523572, acc: 55.47%, op_acc: 19.53%] [G loss: 1.677536]\n",
      "epoch:0 step:230[D loss: 0.683554, acc: 48.44%, op_acc: 9.38%] [G loss: 1.508781]\n",
      "epoch:0 step:231[D loss: 0.548910, acc: 58.59%, op_acc: 21.88%] [G loss: 1.894861]\n",
      "epoch:0 step:232[D loss: 0.583635, acc: 61.72%, op_acc: 21.09%] [G loss: 1.750082]\n",
      "epoch:0 step:233[D loss: 0.536015, acc: 65.62%, op_acc: 16.41%] [G loss: 1.829836]\n",
      "epoch:0 step:234[D loss: 0.509986, acc: 67.19%, op_acc: 24.22%] [G loss: 1.866788]\n",
      "epoch:0 step:235[D loss: 0.598924, acc: 52.34%, op_acc: 14.06%] [G loss: 1.393011]\n",
      "epoch:0 step:236[D loss: 0.586956, acc: 60.16%, op_acc: 22.66%] [G loss: 1.822142]\n",
      "epoch:0 step:237[D loss: 0.486340, acc: 71.09%, op_acc: 32.81%] [G loss: 1.971364]\n",
      "epoch:0 step:238[D loss: 0.437865, acc: 78.12%, op_acc: 42.19%] [G loss: 2.095642]\n",
      "epoch:0 step:239[D loss: 0.386967, acc: 83.59%, op_acc: 45.31%] [G loss: 2.333906]\n",
      "epoch:0 step:240[D loss: 0.346356, acc: 83.59%, op_acc: 39.84%] [G loss: 2.154822]\n",
      "epoch:0 step:241[D loss: 0.380279, acc: 83.59%, op_acc: 27.34%] [G loss: 1.932681]\n",
      "epoch:0 step:242[D loss: 0.390388, acc: 81.25%, op_acc: 33.59%] [G loss: 1.961415]\n",
      "epoch:0 step:243[D loss: 0.481582, acc: 65.62%, op_acc: 26.56%] [G loss: 1.670446]\n",
      "epoch:0 step:244[D loss: 0.503224, acc: 70.31%, op_acc: 14.06%] [G loss: 2.027956]\n",
      "epoch:0 step:245[D loss: 0.499442, acc: 60.16%, op_acc: 20.31%] [G loss: 1.569292]\n",
      "epoch:0 step:246[D loss: 0.535923, acc: 60.16%, op_acc: 23.44%] [G loss: 1.874093]\n",
      "epoch:0 step:247[D loss: 0.466539, acc: 68.75%, op_acc: 30.47%] [G loss: 1.915135]\n",
      "epoch:0 step:248[D loss: 0.385495, acc: 78.91%, op_acc: 27.34%] [G loss: 2.188340]\n",
      "epoch:0 step:249[D loss: 0.476283, acc: 62.50%, op_acc: 25.78%] [G loss: 1.544067]\n",
      "epoch:0 step:250[D loss: 0.538204, acc: 64.06%, op_acc: 15.62%] [G loss: 1.249216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:251[D loss: 0.452787, acc: 73.44%, op_acc: 24.22%] [G loss: 1.385255]\n",
      "epoch:0 step:252[D loss: 0.476259, acc: 68.75%, op_acc: 31.25%] [G loss: 1.705414]\n",
      "epoch:0 step:253[D loss: 0.505292, acc: 60.16%, op_acc: 25.78%] [G loss: 1.347419]\n",
      "epoch:0 step:254[D loss: 0.551590, acc: 56.25%, op_acc: 18.75%] [G loss: 1.468898]\n",
      "epoch:0 step:255[D loss: 0.536353, acc: 64.84%, op_acc: 16.41%] [G loss: 1.597313]\n",
      "epoch:0 step:256[D loss: 0.509947, acc: 64.84%, op_acc: 23.44%] [G loss: 1.747908]\n",
      "epoch:0 step:257[D loss: 0.465563, acc: 70.31%, op_acc: 22.66%] [G loss: 1.516749]\n",
      "epoch:0 step:258[D loss: 0.503895, acc: 60.16%, op_acc: 21.88%] [G loss: 1.344178]\n",
      "epoch:0 step:259[D loss: 0.498142, acc: 68.75%, op_acc: 21.09%] [G loss: 1.365490]\n",
      "epoch:0 step:260[D loss: 0.531822, acc: 60.94%, op_acc: 24.22%] [G loss: 1.423837]\n",
      "epoch:0 step:261[D loss: 0.500346, acc: 67.97%, op_acc: 25.00%] [G loss: 1.410203]\n",
      "epoch:0 step:262[D loss: 0.456414, acc: 68.75%, op_acc: 28.91%] [G loss: 1.406452]\n",
      "epoch:0 step:263[D loss: 0.471141, acc: 67.97%, op_acc: 28.91%] [G loss: 1.197152]\n",
      "epoch:0 step:264[D loss: 0.489301, acc: 67.19%, op_acc: 23.44%] [G loss: 1.160850]\n",
      "epoch:0 step:265[D loss: 0.479206, acc: 67.19%, op_acc: 23.44%] [G loss: 1.167388]\n",
      "epoch:0 step:266[D loss: 0.543806, acc: 57.81%, op_acc: 25.78%] [G loss: 1.429041]\n",
      "epoch:0 step:267[D loss: 0.546750, acc: 60.16%, op_acc: 24.22%] [G loss: 1.449096]\n",
      "epoch:0 step:268[D loss: 0.507194, acc: 64.06%, op_acc: 18.75%] [G loss: 1.549680]\n",
      "epoch:0 step:269[D loss: 0.493023, acc: 67.97%, op_acc: 30.47%] [G loss: 1.431898]\n",
      "epoch:0 step:270[D loss: 0.485503, acc: 66.41%, op_acc: 27.34%] [G loss: 1.395078]\n",
      "epoch:0 step:271[D loss: 0.554232, acc: 63.28%, op_acc: 28.91%] [G loss: 1.427526]\n",
      "epoch:0 step:272[D loss: 0.469762, acc: 71.88%, op_acc: 26.56%] [G loss: 1.662660]\n",
      "epoch:0 step:273[D loss: 0.451817, acc: 73.44%, op_acc: 25.00%] [G loss: 1.477738]\n",
      "epoch:0 step:274[D loss: 0.526446, acc: 66.41%, op_acc: 27.34%] [G loss: 1.348640]\n",
      "epoch:0 step:275[D loss: 0.486265, acc: 68.75%, op_acc: 23.44%] [G loss: 1.367915]\n",
      "epoch:0 step:276[D loss: 0.408187, acc: 77.34%, op_acc: 21.88%] [G loss: 1.815692]\n",
      "epoch:0 step:277[D loss: 0.469999, acc: 74.22%, op_acc: 29.69%] [G loss: 1.717949]\n",
      "epoch:0 step:278[D loss: 0.418195, acc: 75.00%, op_acc: 32.03%] [G loss: 1.820113]\n",
      "epoch:0 step:279[D loss: 0.440810, acc: 68.75%, op_acc: 24.22%] [G loss: 1.641555]\n",
      "epoch:0 step:280[D loss: 0.507763, acc: 63.28%, op_acc: 30.47%] [G loss: 1.379073]\n",
      "epoch:0 step:281[D loss: 0.561638, acc: 55.47%, op_acc: 28.12%] [G loss: 1.189750]\n",
      "epoch:0 step:282[D loss: 0.565628, acc: 57.81%, op_acc: 21.09%] [G loss: 1.181331]\n",
      "epoch:0 step:283[D loss: 0.467780, acc: 67.97%, op_acc: 22.66%] [G loss: 1.175989]\n",
      "epoch:0 step:284[D loss: 0.456506, acc: 70.31%, op_acc: 21.88%] [G loss: 1.498773]\n",
      "epoch:0 step:285[D loss: 0.465288, acc: 67.19%, op_acc: 24.22%] [G loss: 1.428819]\n",
      "epoch:0 step:286[D loss: 0.528466, acc: 57.03%, op_acc: 32.03%] [G loss: 1.093166]\n",
      "epoch:0 step:287[D loss: 0.580613, acc: 57.03%, op_acc: 17.97%] [G loss: 1.181504]\n",
      "epoch:0 step:288[D loss: 0.518071, acc: 60.16%, op_acc: 22.66%] [G loss: 1.160019]\n",
      "epoch:0 step:289[D loss: 0.544810, acc: 57.81%, op_acc: 15.62%] [G loss: 1.608155]\n",
      "epoch:0 step:290[D loss: 0.514327, acc: 63.28%, op_acc: 24.22%] [G loss: 1.472576]\n",
      "epoch:0 step:291[D loss: 0.548336, acc: 61.72%, op_acc: 16.41%] [G loss: 1.368658]\n",
      "epoch:0 step:292[D loss: 0.512398, acc: 68.75%, op_acc: 21.88%] [G loss: 1.583973]\n",
      "epoch:0 step:293[D loss: 0.434795, acc: 75.78%, op_acc: 21.09%] [G loss: 1.779006]\n",
      "epoch:0 step:294[D loss: 0.443301, acc: 67.97%, op_acc: 29.69%] [G loss: 1.635298]\n",
      "epoch:0 step:295[D loss: 0.464429, acc: 68.75%, op_acc: 18.75%] [G loss: 1.655636]\n",
      "epoch:0 step:296[D loss: 0.471860, acc: 66.41%, op_acc: 32.81%] [G loss: 1.344933]\n",
      "epoch:0 step:297[D loss: 0.472910, acc: 67.97%, op_acc: 25.78%] [G loss: 1.347421]\n",
      "epoch:0 step:298[D loss: 0.461567, acc: 71.09%, op_acc: 31.25%] [G loss: 1.479712]\n",
      "epoch:0 step:299[D loss: 0.456349, acc: 70.31%, op_acc: 28.12%] [G loss: 1.337768]\n",
      "epoch:0 step:300[D loss: 0.539023, acc: 59.38%, op_acc: 19.53%] [G loss: 1.154652]\n",
      "epoch:0 step:301[D loss: 0.542582, acc: 54.69%, op_acc: 21.09%] [G loss: 0.969334]\n",
      "epoch:0 step:302[D loss: 0.563318, acc: 55.47%, op_acc: 18.75%] [G loss: 1.199290]\n",
      "epoch:0 step:303[D loss: 0.594528, acc: 50.78%, op_acc: 24.22%] [G loss: 1.256064]\n",
      "epoch:0 step:304[D loss: 0.535900, acc: 55.47%, op_acc: 26.56%] [G loss: 1.286446]\n",
      "epoch:0 step:305[D loss: 0.609956, acc: 47.66%, op_acc: 24.22%] [G loss: 1.107802]\n",
      "epoch:0 step:306[D loss: 0.588089, acc: 51.56%, op_acc: 17.19%] [G loss: 1.414655]\n",
      "epoch:0 step:307[D loss: 0.526007, acc: 60.16%, op_acc: 19.53%] [G loss: 1.149958]\n",
      "epoch:0 step:308[D loss: 0.557469, acc: 53.12%, op_acc: 25.78%] [G loss: 1.292642]\n",
      "epoch:0 step:309[D loss: 0.553528, acc: 51.56%, op_acc: 22.66%] [G loss: 1.049018]\n",
      "epoch:0 step:310[D loss: 0.447515, acc: 63.28%, op_acc: 25.00%] [G loss: 1.235916]\n",
      "epoch:0 step:311[D loss: 0.517914, acc: 57.03%, op_acc: 20.31%] [G loss: 1.213372]\n",
      "epoch:0 step:312[D loss: 0.578182, acc: 54.69%, op_acc: 21.88%] [G loss: 1.017489]\n",
      "epoch:0 step:313[D loss: 0.606559, acc: 48.44%, op_acc: 20.31%] [G loss: 0.989878]\n",
      "epoch:0 step:314[D loss: 0.530935, acc: 57.03%, op_acc: 22.66%] [G loss: 1.138005]\n",
      "epoch:0 step:315[D loss: 0.630363, acc: 44.53%, op_acc: 15.62%] [G loss: 1.035247]\n",
      "epoch:0 step:316[D loss: 0.552456, acc: 52.34%, op_acc: 19.53%] [G loss: 1.123195]\n",
      "epoch:0 step:317[D loss: 0.584835, acc: 53.12%, op_acc: 22.66%] [G loss: 1.153465]\n",
      "epoch:0 step:318[D loss: 0.500453, acc: 65.62%, op_acc: 21.09%] [G loss: 1.215409]\n",
      "epoch:0 step:319[D loss: 0.507883, acc: 57.03%, op_acc: 22.66%] [G loss: 1.047576]\n",
      "epoch:0 step:320[D loss: 0.585867, acc: 50.00%, op_acc: 17.97%] [G loss: 1.110490]\n",
      "epoch:0 step:321[D loss: 0.571383, acc: 53.91%, op_acc: 19.53%] [G loss: 1.225680]\n",
      "epoch:0 step:322[D loss: 0.523836, acc: 58.59%, op_acc: 24.22%] [G loss: 1.121705]\n",
      "epoch:0 step:323[D loss: 0.579104, acc: 49.22%, op_acc: 18.75%] [G loss: 1.135490]\n",
      "epoch:0 step:324[D loss: 0.549198, acc: 53.12%, op_acc: 27.34%] [G loss: 1.018529]\n",
      "epoch:0 step:325[D loss: 0.595664, acc: 43.75%, op_acc: 25.00%] [G loss: 1.066380]\n",
      "epoch:0 step:326[D loss: 0.611292, acc: 47.66%, op_acc: 19.53%] [G loss: 1.169836]\n",
      "epoch:0 step:327[D loss: 0.549966, acc: 52.34%, op_acc: 20.31%] [G loss: 1.229803]\n",
      "epoch:0 step:328[D loss: 0.525818, acc: 57.81%, op_acc: 28.12%] [G loss: 1.104151]\n",
      "epoch:0 step:329[D loss: 0.468432, acc: 67.97%, op_acc: 23.44%] [G loss: 1.034805]\n",
      "epoch:0 step:330[D loss: 0.533459, acc: 61.72%, op_acc: 20.31%] [G loss: 1.021714]\n",
      "epoch:0 step:331[D loss: 0.499138, acc: 58.59%, op_acc: 29.69%] [G loss: 1.254428]\n",
      "epoch:0 step:332[D loss: 0.508950, acc: 58.59%, op_acc: 30.47%] [G loss: 1.141086]\n",
      "epoch:0 step:333[D loss: 0.492379, acc: 57.81%, op_acc: 29.69%] [G loss: 1.117831]\n",
      "epoch:0 step:334[D loss: 0.545304, acc: 53.91%, op_acc: 19.53%] [G loss: 1.025144]\n",
      "epoch:0 step:335[D loss: 0.571303, acc: 53.12%, op_acc: 21.88%] [G loss: 1.086597]\n",
      "epoch:0 step:336[D loss: 0.510824, acc: 61.72%, op_acc: 28.12%] [G loss: 1.126379]\n",
      "epoch:0 step:337[D loss: 0.573895, acc: 50.00%, op_acc: 17.97%] [G loss: 1.106371]\n",
      "epoch:0 step:338[D loss: 0.557557, acc: 47.66%, op_acc: 26.56%] [G loss: 1.017080]\n",
      "epoch:0 step:339[D loss: 0.537011, acc: 62.50%, op_acc: 17.97%] [G loss: 1.024403]\n",
      "epoch:0 step:340[D loss: 0.569947, acc: 46.09%, op_acc: 23.44%] [G loss: 1.028232]\n",
      "epoch:0 step:341[D loss: 0.580387, acc: 47.66%, op_acc: 19.53%] [G loss: 0.978212]\n",
      "epoch:0 step:342[D loss: 0.579355, acc: 50.78%, op_acc: 21.09%] [G loss: 1.047177]\n",
      "epoch:0 step:343[D loss: 0.553570, acc: 47.66%, op_acc: 22.66%] [G loss: 1.050022]\n",
      "epoch:0 step:344[D loss: 0.535325, acc: 51.56%, op_acc: 23.44%] [G loss: 0.949707]\n",
      "epoch:0 step:345[D loss: 0.555794, acc: 58.59%, op_acc: 22.66%] [G loss: 1.021675]\n",
      "epoch:0 step:346[D loss: 0.559222, acc: 46.09%, op_acc: 25.00%] [G loss: 1.007546]\n",
      "epoch:0 step:347[D loss: 0.547620, acc: 58.59%, op_acc: 19.53%] [G loss: 1.057607]\n",
      "epoch:0 step:348[D loss: 0.495649, acc: 60.94%, op_acc: 21.09%] [G loss: 1.014859]\n",
      "epoch:0 step:349[D loss: 0.532927, acc: 54.69%, op_acc: 17.19%] [G loss: 1.163151]\n",
      "epoch:0 step:350[D loss: 0.513271, acc: 57.03%, op_acc: 23.44%] [G loss: 1.176482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:351[D loss: 0.544276, acc: 56.25%, op_acc: 19.53%] [G loss: 0.956764]\n",
      "epoch:0 step:352[D loss: 0.528885, acc: 56.25%, op_acc: 15.62%] [G loss: 0.918341]\n",
      "epoch:0 step:353[D loss: 0.553585, acc: 51.56%, op_acc: 25.78%] [G loss: 1.028179]\n",
      "epoch:0 step:354[D loss: 0.539570, acc: 53.12%, op_acc: 21.09%] [G loss: 0.951219]\n",
      "epoch:0 step:355[D loss: 0.524248, acc: 53.91%, op_acc: 21.88%] [G loss: 1.005767]\n",
      "epoch:0 step:356[D loss: 0.520790, acc: 60.94%, op_acc: 23.44%] [G loss: 1.117892]\n",
      "epoch:0 step:357[D loss: 0.484798, acc: 55.47%, op_acc: 28.91%] [G loss: 1.033076]\n",
      "epoch:0 step:358[D loss: 0.524389, acc: 58.59%, op_acc: 25.00%] [G loss: 1.165622]\n",
      "epoch:0 step:359[D loss: 0.530779, acc: 55.47%, op_acc: 18.75%] [G loss: 1.101836]\n",
      "epoch:0 step:360[D loss: 0.516707, acc: 60.16%, op_acc: 26.56%] [G loss: 1.132044]\n",
      "epoch:0 step:361[D loss: 0.577650, acc: 43.75%, op_acc: 20.31%] [G loss: 0.959431]\n",
      "epoch:0 step:362[D loss: 0.511881, acc: 59.38%, op_acc: 21.09%] [G loss: 1.037040]\n",
      "epoch:0 step:363[D loss: 0.579455, acc: 51.56%, op_acc: 17.97%] [G loss: 0.956284]\n",
      "epoch:0 step:364[D loss: 0.548179, acc: 50.78%, op_acc: 28.12%] [G loss: 1.061556]\n",
      "epoch:0 step:365[D loss: 0.502185, acc: 53.12%, op_acc: 27.34%] [G loss: 0.991578]\n",
      "epoch:0 step:366[D loss: 0.531043, acc: 50.00%, op_acc: 21.88%] [G loss: 1.009842]\n",
      "epoch:0 step:367[D loss: 0.535942, acc: 53.91%, op_acc: 17.97%] [G loss: 1.113577]\n",
      "epoch:0 step:368[D loss: 0.534160, acc: 53.91%, op_acc: 25.00%] [G loss: 0.961791]\n",
      "epoch:0 step:369[D loss: 0.548130, acc: 50.00%, op_acc: 23.44%] [G loss: 0.969319]\n",
      "epoch:0 step:370[D loss: 0.540928, acc: 50.00%, op_acc: 21.09%] [G loss: 1.036797]\n",
      "epoch:0 step:371[D loss: 0.529927, acc: 50.78%, op_acc: 32.03%] [G loss: 0.942031]\n",
      "epoch:0 step:372[D loss: 0.571152, acc: 47.66%, op_acc: 19.53%] [G loss: 1.071577]\n",
      "epoch:0 step:373[D loss: 0.498072, acc: 66.41%, op_acc: 28.12%] [G loss: 1.078485]\n",
      "epoch:0 step:374[D loss: 0.514809, acc: 59.38%, op_acc: 24.22%] [G loss: 1.004139]\n",
      "epoch:0 step:375[D loss: 0.558932, acc: 47.66%, op_acc: 25.78%] [G loss: 1.025079]\n",
      "epoch:0 step:376[D loss: 0.479654, acc: 63.28%, op_acc: 23.44%] [G loss: 0.980632]\n",
      "epoch:0 step:377[D loss: 0.507417, acc: 59.38%, op_acc: 26.56%] [G loss: 1.022123]\n",
      "epoch:0 step:378[D loss: 0.518216, acc: 55.47%, op_acc: 19.53%] [G loss: 0.897389]\n",
      "epoch:0 step:379[D loss: 0.491496, acc: 62.50%, op_acc: 26.56%] [G loss: 1.066873]\n",
      "epoch:0 step:380[D loss: 0.519337, acc: 54.69%, op_acc: 29.69%] [G loss: 1.144484]\n",
      "epoch:0 step:381[D loss: 0.519799, acc: 56.25%, op_acc: 25.00%] [G loss: 1.092223]\n",
      "epoch:0 step:382[D loss: 0.493881, acc: 58.59%, op_acc: 28.91%] [G loss: 1.151769]\n",
      "epoch:0 step:383[D loss: 0.481510, acc: 58.59%, op_acc: 27.34%] [G loss: 1.177956]\n",
      "epoch:0 step:384[D loss: 0.515396, acc: 55.47%, op_acc: 21.88%] [G loss: 1.132391]\n",
      "epoch:0 step:385[D loss: 0.494922, acc: 61.72%, op_acc: 22.66%] [G loss: 1.105616]\n",
      "epoch:0 step:386[D loss: 0.524803, acc: 52.34%, op_acc: 25.78%] [G loss: 0.983918]\n",
      "epoch:0 step:387[D loss: 0.529949, acc: 57.03%, op_acc: 23.44%] [G loss: 1.073303]\n",
      "epoch:0 step:388[D loss: 0.509188, acc: 59.38%, op_acc: 21.09%] [G loss: 0.904262]\n",
      "epoch:0 step:389[D loss: 0.542045, acc: 53.12%, op_acc: 21.88%] [G loss: 1.075906]\n",
      "epoch:0 step:390[D loss: 0.523570, acc: 57.03%, op_acc: 22.66%] [G loss: 0.941411]\n",
      "epoch:0 step:391[D loss: 0.513769, acc: 57.03%, op_acc: 21.88%] [G loss: 1.012367]\n",
      "epoch:0 step:392[D loss: 0.498946, acc: 62.50%, op_acc: 25.78%] [G loss: 0.984208]\n",
      "epoch:0 step:393[D loss: 0.483394, acc: 56.25%, op_acc: 27.34%] [G loss: 0.978991]\n",
      "epoch:0 step:394[D loss: 0.529400, acc: 54.69%, op_acc: 18.75%] [G loss: 0.910774]\n",
      "epoch:0 step:395[D loss: 0.531236, acc: 53.91%, op_acc: 20.31%] [G loss: 1.042004]\n",
      "epoch:0 step:396[D loss: 0.543397, acc: 51.56%, op_acc: 26.56%] [G loss: 1.048291]\n",
      "epoch:0 step:397[D loss: 0.496044, acc: 60.94%, op_acc: 22.66%] [G loss: 1.119102]\n",
      "epoch:0 step:398[D loss: 0.530970, acc: 57.81%, op_acc: 24.22%] [G loss: 1.001361]\n",
      "epoch:0 step:399[D loss: 0.503335, acc: 57.81%, op_acc: 25.00%] [G loss: 0.932148]\n",
      "epoch:0 step:400[D loss: 0.465158, acc: 62.50%, op_acc: 23.44%] [G loss: 1.031475]\n",
      "epoch:0 step:401[D loss: 0.539243, acc: 53.12%, op_acc: 17.19%] [G loss: 0.984471]\n",
      "epoch:0 step:402[D loss: 0.486054, acc: 62.50%, op_acc: 25.78%] [G loss: 0.961983]\n",
      "epoch:0 step:403[D loss: 0.557290, acc: 51.56%, op_acc: 20.31%] [G loss: 0.993797]\n",
      "epoch:0 step:404[D loss: 0.488841, acc: 64.84%, op_acc: 28.12%] [G loss: 1.056323]\n",
      "epoch:0 step:405[D loss: 0.529981, acc: 56.25%, op_acc: 20.31%] [G loss: 1.045068]\n",
      "epoch:0 step:406[D loss: 0.501799, acc: 58.59%, op_acc: 23.44%] [G loss: 1.084624]\n",
      "epoch:0 step:407[D loss: 0.461392, acc: 67.97%, op_acc: 23.44%] [G loss: 1.086259]\n",
      "epoch:0 step:408[D loss: 0.453741, acc: 66.41%, op_acc: 26.56%] [G loss: 1.177189]\n",
      "epoch:0 step:409[D loss: 0.455788, acc: 68.75%, op_acc: 28.12%] [G loss: 1.207851]\n",
      "epoch:0 step:410[D loss: 0.437382, acc: 69.53%, op_acc: 29.69%] [G loss: 1.051174]\n",
      "epoch:0 step:411[D loss: 0.541511, acc: 57.03%, op_acc: 21.09%] [G loss: 1.087903]\n",
      "epoch:0 step:412[D loss: 0.529755, acc: 57.81%, op_acc: 23.44%] [G loss: 1.042975]\n",
      "epoch:0 step:413[D loss: 0.557928, acc: 49.22%, op_acc: 17.97%] [G loss: 1.065989]\n",
      "epoch:0 step:414[D loss: 0.591679, acc: 43.75%, op_acc: 22.66%] [G loss: 0.946108]\n",
      "epoch:0 step:415[D loss: 0.525657, acc: 57.81%, op_acc: 25.00%] [G loss: 1.041811]\n",
      "epoch:0 step:416[D loss: 0.510205, acc: 56.25%, op_acc: 23.44%] [G loss: 1.047675]\n",
      "epoch:0 step:417[D loss: 0.478684, acc: 64.06%, op_acc: 25.00%] [G loss: 1.195500]\n",
      "epoch:0 step:418[D loss: 0.476690, acc: 62.50%, op_acc: 27.34%] [G loss: 1.168748]\n",
      "epoch:0 step:419[D loss: 0.521074, acc: 53.12%, op_acc: 18.75%] [G loss: 1.188650]\n",
      "epoch:0 step:420[D loss: 0.539379, acc: 50.78%, op_acc: 24.22%] [G loss: 0.998450]\n",
      "epoch:0 step:421[D loss: 0.515322, acc: 61.72%, op_acc: 21.88%] [G loss: 1.066135]\n",
      "epoch:0 step:422[D loss: 0.511419, acc: 59.38%, op_acc: 24.22%] [G loss: 1.079608]\n",
      "epoch:0 step:423[D loss: 0.518469, acc: 54.69%, op_acc: 22.66%] [G loss: 0.980393]\n",
      "epoch:0 step:424[D loss: 0.516822, acc: 54.69%, op_acc: 25.78%] [G loss: 1.008012]\n",
      "epoch:0 step:425[D loss: 0.508449, acc: 50.78%, op_acc: 19.53%] [G loss: 1.008558]\n",
      "epoch:0 step:426[D loss: 0.532162, acc: 53.91%, op_acc: 17.97%] [G loss: 0.965808]\n",
      "epoch:0 step:427[D loss: 0.502699, acc: 57.81%, op_acc: 21.09%] [G loss: 0.955717]\n",
      "epoch:0 step:428[D loss: 0.524846, acc: 56.25%, op_acc: 21.09%] [G loss: 1.163702]\n",
      "epoch:0 step:429[D loss: 0.499971, acc: 56.25%, op_acc: 24.22%] [G loss: 0.981322]\n",
      "epoch:0 step:430[D loss: 0.508642, acc: 53.91%, op_acc: 27.34%] [G loss: 1.049443]\n",
      "epoch:0 step:431[D loss: 0.530595, acc: 52.34%, op_acc: 21.88%] [G loss: 1.035532]\n",
      "epoch:0 step:432[D loss: 0.501158, acc: 59.38%, op_acc: 23.44%] [G loss: 1.018601]\n",
      "epoch:0 step:433[D loss: 0.491851, acc: 63.28%, op_acc: 18.75%] [G loss: 1.014766]\n",
      "epoch:0 step:434[D loss: 0.537151, acc: 46.88%, op_acc: 21.88%] [G loss: 0.996890]\n",
      "epoch:0 step:435[D loss: 0.513535, acc: 55.47%, op_acc: 22.66%] [G loss: 1.028711]\n",
      "epoch:0 step:436[D loss: 0.541219, acc: 56.25%, op_acc: 16.41%] [G loss: 1.096585]\n",
      "epoch:0 step:437[D loss: 0.487046, acc: 65.62%, op_acc: 24.22%] [G loss: 1.142048]\n",
      "epoch:0 step:438[D loss: 0.517856, acc: 57.81%, op_acc: 27.34%] [G loss: 1.088047]\n",
      "epoch:0 step:439[D loss: 0.541032, acc: 55.47%, op_acc: 17.19%] [G loss: 1.028544]\n",
      "epoch:0 step:440[D loss: 0.527634, acc: 53.91%, op_acc: 20.31%] [G loss: 1.042353]\n",
      "epoch:0 step:441[D loss: 0.509151, acc: 58.59%, op_acc: 21.88%] [G loss: 1.032999]\n",
      "epoch:0 step:442[D loss: 0.509411, acc: 56.25%, op_acc: 25.78%] [G loss: 1.014630]\n",
      "epoch:0 step:443[D loss: 0.493692, acc: 60.16%, op_acc: 28.12%] [G loss: 0.939152]\n",
      "epoch:0 step:444[D loss: 0.531400, acc: 64.84%, op_acc: 21.88%] [G loss: 1.012437]\n",
      "epoch:0 step:445[D loss: 0.509538, acc: 59.38%, op_acc: 24.22%] [G loss: 1.001681]\n",
      "epoch:0 step:446[D loss: 0.532137, acc: 60.16%, op_acc: 21.88%] [G loss: 1.040046]\n",
      "epoch:0 step:447[D loss: 0.501968, acc: 57.81%, op_acc: 21.88%] [G loss: 1.058394]\n",
      "epoch:0 step:448[D loss: 0.524878, acc: 56.25%, op_acc: 22.66%] [G loss: 0.978216]\n",
      "epoch:0 step:449[D loss: 0.471589, acc: 59.38%, op_acc: 26.56%] [G loss: 1.001202]\n",
      "epoch:0 step:450[D loss: 0.512166, acc: 53.12%, op_acc: 22.66%] [G loss: 1.015723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:451[D loss: 0.471333, acc: 62.50%, op_acc: 35.94%] [G loss: 1.113441]\n",
      "epoch:0 step:452[D loss: 0.508477, acc: 55.47%, op_acc: 25.00%] [G loss: 0.954997]\n",
      "epoch:0 step:453[D loss: 0.493635, acc: 60.16%, op_acc: 24.22%] [G loss: 1.090540]\n",
      "epoch:0 step:454[D loss: 0.515685, acc: 57.03%, op_acc: 24.22%] [G loss: 1.044207]\n",
      "epoch:0 step:455[D loss: 0.473193, acc: 65.62%, op_acc: 24.22%] [G loss: 0.972622]\n",
      "epoch:0 step:456[D loss: 0.502879, acc: 60.94%, op_acc: 21.88%] [G loss: 0.982441]\n",
      "epoch:0 step:457[D loss: 0.490703, acc: 63.28%, op_acc: 21.09%] [G loss: 1.157100]\n",
      "epoch:0 step:458[D loss: 0.465898, acc: 61.72%, op_acc: 28.91%] [G loss: 1.068530]\n",
      "epoch:0 step:459[D loss: 0.494230, acc: 58.59%, op_acc: 26.56%] [G loss: 1.089680]\n",
      "epoch:0 step:460[D loss: 0.470120, acc: 61.72%, op_acc: 23.44%] [G loss: 1.053160]\n",
      "epoch:0 step:461[D loss: 0.487992, acc: 60.16%, op_acc: 20.31%] [G loss: 1.137210]\n",
      "epoch:0 step:462[D loss: 0.468673, acc: 67.97%, op_acc: 27.34%] [G loss: 1.116147]\n",
      "epoch:0 step:463[D loss: 0.472197, acc: 62.50%, op_acc: 28.12%] [G loss: 1.029382]\n",
      "epoch:0 step:464[D loss: 0.529844, acc: 55.47%, op_acc: 20.31%] [G loss: 0.931207]\n",
      "epoch:0 step:465[D loss: 0.474468, acc: 65.62%, op_acc: 25.00%] [G loss: 1.137978]\n",
      "epoch:0 step:466[D loss: 0.468871, acc: 67.97%, op_acc: 27.34%] [G loss: 1.042198]\n",
      "epoch:0 step:467[D loss: 0.502044, acc: 60.94%, op_acc: 22.66%] [G loss: 1.048212]\n",
      "epoch:0 step:468[D loss: 0.504935, acc: 56.25%, op_acc: 26.56%] [G loss: 0.902622]\n",
      "epoch:0 step:469[D loss: 0.482965, acc: 62.50%, op_acc: 26.56%] [G loss: 0.988456]\n",
      "epoch:0 step:470[D loss: 0.464628, acc: 65.62%, op_acc: 28.91%] [G loss: 0.985613]\n",
      "epoch:0 step:471[D loss: 0.508765, acc: 50.78%, op_acc: 27.34%] [G loss: 1.066839]\n",
      "epoch:0 step:472[D loss: 0.483166, acc: 66.41%, op_acc: 20.31%] [G loss: 1.065065]\n",
      "epoch:0 step:473[D loss: 0.482661, acc: 61.72%, op_acc: 25.78%] [G loss: 0.932227]\n",
      "epoch:0 step:474[D loss: 0.472216, acc: 66.41%, op_acc: 24.22%] [G loss: 1.060409]\n",
      "epoch:0 step:475[D loss: 0.440111, acc: 65.62%, op_acc: 32.81%] [G loss: 1.117848]\n",
      "epoch:0 step:476[D loss: 0.474541, acc: 64.84%, op_acc: 26.56%] [G loss: 1.082951]\n",
      "epoch:0 step:477[D loss: 0.432240, acc: 66.41%, op_acc: 25.78%] [G loss: 1.070499]\n",
      "epoch:0 step:478[D loss: 0.484612, acc: 60.16%, op_acc: 28.12%] [G loss: 0.990388]\n",
      "epoch:0 step:479[D loss: 0.519300, acc: 57.81%, op_acc: 21.09%] [G loss: 0.924022]\n",
      "epoch:0 step:480[D loss: 0.503262, acc: 57.81%, op_acc: 16.41%] [G loss: 0.951214]\n",
      "epoch:0 step:481[D loss: 0.476555, acc: 67.97%, op_acc: 26.56%] [G loss: 1.053725]\n",
      "epoch:0 step:482[D loss: 0.504426, acc: 53.12%, op_acc: 26.56%] [G loss: 1.101792]\n",
      "epoch:0 step:483[D loss: 0.477517, acc: 62.50%, op_acc: 21.88%] [G loss: 1.247591]\n",
      "epoch:0 step:484[D loss: 0.458451, acc: 57.03%, op_acc: 31.25%] [G loss: 1.227151]\n",
      "epoch:0 step:485[D loss: 0.481851, acc: 64.84%, op_acc: 28.91%] [G loss: 1.154999]\n",
      "epoch:0 step:486[D loss: 0.478033, acc: 55.47%, op_acc: 28.91%] [G loss: 1.069968]\n",
      "epoch:0 step:487[D loss: 0.539760, acc: 56.25%, op_acc: 23.44%] [G loss: 1.014485]\n",
      "epoch:0 step:488[D loss: 0.557876, acc: 52.34%, op_acc: 17.97%] [G loss: 0.994753]\n",
      "epoch:0 step:489[D loss: 0.434542, acc: 78.12%, op_acc: 30.47%] [G loss: 1.007844]\n",
      "epoch:0 step:490[D loss: 0.469963, acc: 64.06%, op_acc: 24.22%] [G loss: 0.985260]\n",
      "epoch:0 step:491[D loss: 0.509754, acc: 58.59%, op_acc: 17.19%] [G loss: 1.003625]\n",
      "epoch:0 step:492[D loss: 0.541781, acc: 58.59%, op_acc: 21.09%] [G loss: 1.070125]\n",
      "epoch:0 step:493[D loss: 0.484982, acc: 63.28%, op_acc: 16.41%] [G loss: 1.179896]\n",
      "epoch:0 step:494[D loss: 0.468044, acc: 64.84%, op_acc: 28.12%] [G loss: 1.028134]\n",
      "epoch:0 step:495[D loss: 0.519756, acc: 50.78%, op_acc: 22.66%] [G loss: 1.097847]\n",
      "epoch:0 step:496[D loss: 0.502864, acc: 60.16%, op_acc: 24.22%] [G loss: 1.136274]\n",
      "epoch:0 step:497[D loss: 0.473306, acc: 68.75%, op_acc: 23.44%] [G loss: 1.181798]\n",
      "epoch:0 step:498[D loss: 0.518672, acc: 57.81%, op_acc: 25.78%] [G loss: 1.121058]\n",
      "epoch:0 step:499[D loss: 0.488024, acc: 68.75%, op_acc: 21.88%] [G loss: 1.064965]\n",
      "epoch:0 step:500[D loss: 0.421820, acc: 71.88%, op_acc: 28.12%] [G loss: 1.020180]\n",
      "epoch:0 step:501[D loss: 0.528137, acc: 54.69%, op_acc: 25.78%] [G loss: 1.082713]\n",
      "epoch:0 step:502[D loss: 0.512411, acc: 57.03%, op_acc: 24.22%] [G loss: 1.130599]\n",
      "epoch:0 step:503[D loss: 0.459573, acc: 66.41%, op_acc: 22.66%] [G loss: 1.182322]\n",
      "epoch:0 step:504[D loss: 0.482724, acc: 65.62%, op_acc: 21.88%] [G loss: 1.208704]\n",
      "epoch:0 step:505[D loss: 0.509290, acc: 60.16%, op_acc: 21.09%] [G loss: 1.075926]\n",
      "epoch:0 step:506[D loss: 0.447551, acc: 69.53%, op_acc: 27.34%] [G loss: 1.194231]\n",
      "epoch:0 step:507[D loss: 0.499600, acc: 55.47%, op_acc: 25.78%] [G loss: 1.002644]\n",
      "epoch:0 step:508[D loss: 0.475571, acc: 64.84%, op_acc: 27.34%] [G loss: 0.994192]\n",
      "epoch:0 step:509[D loss: 0.539651, acc: 53.12%, op_acc: 16.41%] [G loss: 1.093756]\n",
      "epoch:0 step:510[D loss: 0.477990, acc: 60.94%, op_acc: 30.47%] [G loss: 1.070942]\n",
      "epoch:0 step:511[D loss: 0.444417, acc: 70.31%, op_acc: 28.12%] [G loss: 1.074137]\n",
      "epoch:0 step:512[D loss: 0.518897, acc: 64.06%, op_acc: 22.66%] [G loss: 1.012295]\n",
      "epoch:0 step:513[D loss: 0.498610, acc: 63.28%, op_acc: 22.66%] [G loss: 1.045983]\n",
      "epoch:0 step:514[D loss: 0.453724, acc: 67.97%, op_acc: 21.09%] [G loss: 1.136000]\n",
      "epoch:0 step:515[D loss: 0.508979, acc: 58.59%, op_acc: 17.97%] [G loss: 0.924236]\n",
      "epoch:0 step:516[D loss: 0.466632, acc: 64.06%, op_acc: 25.78%] [G loss: 0.994060]\n",
      "epoch:0 step:517[D loss: 0.458923, acc: 70.31%, op_acc: 21.88%] [G loss: 0.918134]\n",
      "epoch:0 step:518[D loss: 0.470029, acc: 61.72%, op_acc: 28.12%] [G loss: 1.004702]\n",
      "epoch:0 step:519[D loss: 0.450135, acc: 67.19%, op_acc: 30.47%] [G loss: 1.103754]\n",
      "epoch:0 step:520[D loss: 0.443217, acc: 66.41%, op_acc: 22.66%] [G loss: 1.034581]\n",
      "epoch:0 step:521[D loss: 0.531790, acc: 55.47%, op_acc: 27.34%] [G loss: 1.037979]\n",
      "epoch:0 step:522[D loss: 0.469458, acc: 69.53%, op_acc: 24.22%] [G loss: 1.069821]\n",
      "epoch:0 step:523[D loss: 0.508412, acc: 61.72%, op_acc: 24.22%] [G loss: 1.132583]\n",
      "epoch:0 step:524[D loss: 0.507312, acc: 59.38%, op_acc: 21.88%] [G loss: 1.135177]\n",
      "epoch:0 step:525[D loss: 0.491426, acc: 61.72%, op_acc: 25.00%] [G loss: 1.105361]\n",
      "epoch:0 step:526[D loss: 0.520851, acc: 60.94%, op_acc: 20.31%] [G loss: 1.137704]\n",
      "epoch:0 step:527[D loss: 0.495009, acc: 59.38%, op_acc: 20.31%] [G loss: 1.118407]\n",
      "epoch:0 step:528[D loss: 0.512977, acc: 54.69%, op_acc: 31.25%] [G loss: 1.070418]\n",
      "epoch:0 step:529[D loss: 0.468089, acc: 62.50%, op_acc: 26.56%] [G loss: 1.163679]\n",
      "epoch:0 step:530[D loss: 0.536707, acc: 53.91%, op_acc: 25.78%] [G loss: 0.997444]\n",
      "epoch:0 step:531[D loss: 0.460989, acc: 61.72%, op_acc: 27.34%] [G loss: 1.152742]\n",
      "epoch:0 step:532[D loss: 0.516148, acc: 56.25%, op_acc: 32.03%] [G loss: 1.178870]\n",
      "epoch:0 step:533[D loss: 0.469870, acc: 62.50%, op_acc: 27.34%] [G loss: 1.039249]\n",
      "epoch:0 step:534[D loss: 0.438314, acc: 65.62%, op_acc: 26.56%] [G loss: 1.186080]\n",
      "epoch:0 step:535[D loss: 0.461674, acc: 65.62%, op_acc: 28.12%] [G loss: 1.054636]\n",
      "epoch:0 step:536[D loss: 0.468237, acc: 62.50%, op_acc: 25.78%] [G loss: 1.077031]\n",
      "epoch:0 step:537[D loss: 0.487830, acc: 66.41%, op_acc: 21.09%] [G loss: 1.043331]\n",
      "epoch:0 step:538[D loss: 0.490407, acc: 64.06%, op_acc: 26.56%] [G loss: 1.048647]\n",
      "epoch:0 step:539[D loss: 0.523096, acc: 59.38%, op_acc: 17.97%] [G loss: 0.989321]\n",
      "epoch:0 step:540[D loss: 0.439600, acc: 67.97%, op_acc: 25.00%] [G loss: 1.052904]\n",
      "epoch:0 step:541[D loss: 0.468647, acc: 60.94%, op_acc: 28.91%] [G loss: 1.122890]\n",
      "epoch:0 step:542[D loss: 0.483904, acc: 60.94%, op_acc: 28.12%] [G loss: 1.033525]\n",
      "epoch:0 step:543[D loss: 0.481320, acc: 62.50%, op_acc: 19.53%] [G loss: 1.119777]\n",
      "epoch:0 step:544[D loss: 0.498314, acc: 52.34%, op_acc: 27.34%] [G loss: 1.113804]\n",
      "epoch:0 step:545[D loss: 0.481789, acc: 63.28%, op_acc: 25.00%] [G loss: 1.183268]\n",
      "epoch:0 step:546[D loss: 0.454761, acc: 60.16%, op_acc: 25.78%] [G loss: 1.032277]\n",
      "epoch:0 step:547[D loss: 0.506116, acc: 62.50%, op_acc: 24.22%] [G loss: 1.131652]\n",
      "epoch:0 step:548[D loss: 0.534165, acc: 53.12%, op_acc: 27.34%] [G loss: 1.061434]\n",
      "epoch:0 step:549[D loss: 0.479448, acc: 64.84%, op_acc: 22.66%] [G loss: 0.992949]\n",
      "epoch:0 step:550[D loss: 0.471295, acc: 64.06%, op_acc: 27.34%] [G loss: 1.155869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:551[D loss: 0.470456, acc: 64.84%, op_acc: 24.22%] [G loss: 1.045982]\n",
      "epoch:0 step:552[D loss: 0.460589, acc: 67.97%, op_acc: 26.56%] [G loss: 1.123879]\n",
      "epoch:0 step:553[D loss: 0.447936, acc: 66.41%, op_acc: 29.69%] [G loss: 1.078868]\n",
      "epoch:0 step:554[D loss: 0.487433, acc: 61.72%, op_acc: 22.66%] [G loss: 0.994869]\n",
      "epoch:0 step:555[D loss: 0.433528, acc: 67.19%, op_acc: 28.91%] [G loss: 1.293636]\n",
      "epoch:0 step:556[D loss: 0.483184, acc: 59.38%, op_acc: 22.66%] [G loss: 0.910397]\n",
      "epoch:0 step:557[D loss: 0.509218, acc: 57.03%, op_acc: 17.97%] [G loss: 1.168392]\n",
      "epoch:0 step:558[D loss: 0.501781, acc: 54.69%, op_acc: 23.44%] [G loss: 1.146221]\n",
      "epoch:0 step:559[D loss: 0.460932, acc: 70.31%, op_acc: 22.66%] [G loss: 1.109721]\n",
      "epoch:0 step:560[D loss: 0.478386, acc: 63.28%, op_acc: 26.56%] [G loss: 1.291178]\n",
      "epoch:0 step:561[D loss: 0.464828, acc: 61.72%, op_acc: 30.47%] [G loss: 1.233485]\n",
      "epoch:0 step:562[D loss: 0.389671, acc: 75.78%, op_acc: 30.47%] [G loss: 1.251609]\n",
      "epoch:0 step:563[D loss: 0.450294, acc: 67.19%, op_acc: 28.91%] [G loss: 1.183817]\n",
      "epoch:0 step:564[D loss: 0.482197, acc: 60.16%, op_acc: 23.44%] [G loss: 1.085543]\n",
      "epoch:0 step:565[D loss: 0.459306, acc: 64.06%, op_acc: 25.00%] [G loss: 1.086030]\n",
      "epoch:0 step:566[D loss: 0.510631, acc: 60.16%, op_acc: 21.88%] [G loss: 1.123845]\n",
      "epoch:0 step:567[D loss: 0.479405, acc: 66.41%, op_acc: 25.00%] [G loss: 1.157227]\n",
      "epoch:0 step:568[D loss: 0.493826, acc: 58.59%, op_acc: 27.34%] [G loss: 1.035324]\n",
      "epoch:0 step:569[D loss: 0.519288, acc: 56.25%, op_acc: 31.25%] [G loss: 1.125776]\n",
      "epoch:0 step:570[D loss: 0.465925, acc: 64.84%, op_acc: 30.47%] [G loss: 1.207479]\n",
      "epoch:0 step:571[D loss: 0.481656, acc: 64.84%, op_acc: 32.03%] [G loss: 1.198057]\n",
      "epoch:0 step:572[D loss: 0.452570, acc: 64.06%, op_acc: 35.16%] [G loss: 1.304970]\n",
      "epoch:0 step:573[D loss: 0.418902, acc: 68.75%, op_acc: 34.38%] [G loss: 1.416805]\n",
      "epoch:0 step:574[D loss: 0.468785, acc: 68.75%, op_acc: 26.56%] [G loss: 1.160691]\n",
      "epoch:0 step:575[D loss: 0.443279, acc: 64.06%, op_acc: 27.34%] [G loss: 1.214178]\n",
      "epoch:0 step:576[D loss: 0.446586, acc: 71.09%, op_acc: 28.91%] [G loss: 1.168461]\n",
      "epoch:0 step:577[D loss: 0.488200, acc: 62.50%, op_acc: 23.44%] [G loss: 0.999054]\n",
      "epoch:0 step:578[D loss: 0.527603, acc: 50.78%, op_acc: 25.00%] [G loss: 1.080330]\n",
      "epoch:0 step:579[D loss: 0.465613, acc: 54.69%, op_acc: 28.91%] [G loss: 1.252133]\n",
      "epoch:0 step:580[D loss: 0.490076, acc: 64.06%, op_acc: 22.66%] [G loss: 1.268553]\n",
      "epoch:0 step:581[D loss: 0.462401, acc: 67.19%, op_acc: 29.69%] [G loss: 1.030219]\n",
      "epoch:0 step:582[D loss: 0.502351, acc: 60.94%, op_acc: 23.44%] [G loss: 0.983613]\n",
      "epoch:0 step:583[D loss: 0.453799, acc: 64.06%, op_acc: 28.12%] [G loss: 1.050038]\n",
      "epoch:0 step:584[D loss: 0.472747, acc: 67.19%, op_acc: 22.66%] [G loss: 1.237529]\n",
      "epoch:0 step:585[D loss: 0.497631, acc: 58.59%, op_acc: 28.12%] [G loss: 1.146833]\n",
      "epoch:0 step:586[D loss: 0.419722, acc: 75.78%, op_acc: 29.69%] [G loss: 1.176841]\n",
      "epoch:0 step:587[D loss: 0.461062, acc: 67.19%, op_acc: 23.44%] [G loss: 1.010557]\n",
      "epoch:0 step:588[D loss: 0.509056, acc: 59.38%, op_acc: 26.56%] [G loss: 1.223347]\n",
      "epoch:0 step:589[D loss: 0.448280, acc: 64.06%, op_acc: 24.22%] [G loss: 0.981418]\n",
      "epoch:0 step:590[D loss: 0.429909, acc: 77.34%, op_acc: 25.78%] [G loss: 1.250776]\n",
      "epoch:0 step:591[D loss: 0.499274, acc: 59.38%, op_acc: 25.78%] [G loss: 1.081110]\n",
      "epoch:0 step:592[D loss: 0.432236, acc: 71.09%, op_acc: 25.00%] [G loss: 1.057319]\n",
      "epoch:0 step:593[D loss: 0.482706, acc: 59.38%, op_acc: 25.00%] [G loss: 1.106139]\n",
      "epoch:0 step:594[D loss: 0.508227, acc: 57.81%, op_acc: 21.88%] [G loss: 1.023225]\n",
      "epoch:0 step:595[D loss: 0.498106, acc: 56.25%, op_acc: 24.22%] [G loss: 1.153160]\n",
      "epoch:0 step:596[D loss: 0.457558, acc: 68.75%, op_acc: 24.22%] [G loss: 1.130697]\n",
      "epoch:0 step:597[D loss: 0.543535, acc: 53.91%, op_acc: 25.78%] [G loss: 0.906656]\n",
      "epoch:0 step:598[D loss: 0.485966, acc: 62.50%, op_acc: 26.56%] [G loss: 1.060477]\n",
      "epoch:0 step:599[D loss: 0.469048, acc: 64.06%, op_acc: 31.25%] [G loss: 1.012305]\n",
      "epoch:0 step:600[D loss: 0.456855, acc: 64.06%, op_acc: 26.56%] [G loss: 1.039120]\n",
      "epoch:0 step:601[D loss: 0.446894, acc: 68.75%, op_acc: 26.56%] [G loss: 1.069312]\n",
      "epoch:0 step:602[D loss: 0.407086, acc: 78.91%, op_acc: 32.81%] [G loss: 1.180888]\n",
      "epoch:0 step:603[D loss: 0.465551, acc: 62.50%, op_acc: 32.03%] [G loss: 1.174178]\n",
      "epoch:0 step:604[D loss: 0.514043, acc: 61.72%, op_acc: 20.31%] [G loss: 1.156078]\n",
      "epoch:0 step:605[D loss: 0.496833, acc: 62.50%, op_acc: 22.66%] [G loss: 0.983701]\n",
      "epoch:0 step:606[D loss: 0.463782, acc: 64.84%, op_acc: 21.88%] [G loss: 1.131399]\n",
      "epoch:0 step:607[D loss: 0.429452, acc: 65.62%, op_acc: 38.28%] [G loss: 1.182734]\n",
      "epoch:0 step:608[D loss: 0.406914, acc: 78.91%, op_acc: 29.69%] [G loss: 1.165074]\n",
      "epoch:0 step:609[D loss: 0.461761, acc: 64.84%, op_acc: 26.56%] [G loss: 1.163817]\n",
      "epoch:0 step:610[D loss: 0.501400, acc: 62.50%, op_acc: 17.19%] [G loss: 1.067177]\n",
      "epoch:0 step:611[D loss: 0.478596, acc: 65.62%, op_acc: 26.56%] [G loss: 1.063471]\n",
      "epoch:0 step:612[D loss: 0.489253, acc: 64.84%, op_acc: 32.81%] [G loss: 1.116327]\n",
      "epoch:0 step:613[D loss: 0.508334, acc: 53.91%, op_acc: 21.88%] [G loss: 1.135732]\n",
      "epoch:0 step:614[D loss: 0.397528, acc: 80.47%, op_acc: 28.12%] [G loss: 1.197217]\n",
      "epoch:0 step:615[D loss: 0.464636, acc: 66.41%, op_acc: 29.69%] [G loss: 1.227124]\n",
      "epoch:0 step:616[D loss: 0.471544, acc: 59.38%, op_acc: 25.00%] [G loss: 1.015386]\n",
      "epoch:0 step:617[D loss: 0.518008, acc: 58.59%, op_acc: 22.66%] [G loss: 1.092085]\n",
      "epoch:0 step:618[D loss: 0.454035, acc: 67.19%, op_acc: 25.00%] [G loss: 0.913908]\n",
      "epoch:0 step:619[D loss: 0.443099, acc: 72.66%, op_acc: 21.88%] [G loss: 1.090850]\n",
      "epoch:0 step:620[D loss: 0.428981, acc: 73.44%, op_acc: 27.34%] [G loss: 1.098608]\n",
      "epoch:0 step:621[D loss: 0.454425, acc: 65.62%, op_acc: 25.78%] [G loss: 1.230574]\n",
      "epoch:0 step:622[D loss: 0.437825, acc: 74.22%, op_acc: 27.34%] [G loss: 1.205811]\n",
      "epoch:0 step:623[D loss: 0.474232, acc: 64.84%, op_acc: 24.22%] [G loss: 1.151685]\n",
      "epoch:0 step:624[D loss: 0.484980, acc: 60.16%, op_acc: 29.69%] [G loss: 1.170084]\n",
      "epoch:0 step:625[D loss: 0.491439, acc: 58.59%, op_acc: 32.03%] [G loss: 1.114317]\n",
      "epoch:0 step:626[D loss: 0.469334, acc: 62.50%, op_acc: 28.91%] [G loss: 1.156722]\n",
      "epoch:0 step:627[D loss: 0.468007, acc: 66.41%, op_acc: 28.91%] [G loss: 1.223355]\n",
      "epoch:0 step:628[D loss: 0.428526, acc: 73.44%, op_acc: 25.00%] [G loss: 1.214833]\n",
      "epoch:0 step:629[D loss: 0.513534, acc: 57.03%, op_acc: 27.34%] [G loss: 1.139907]\n",
      "epoch:0 step:630[D loss: 0.457996, acc: 66.41%, op_acc: 19.53%] [G loss: 1.188158]\n",
      "epoch:0 step:631[D loss: 0.521308, acc: 46.88%, op_acc: 23.44%] [G loss: 1.031764]\n",
      "epoch:0 step:632[D loss: 0.444650, acc: 70.31%, op_acc: 25.78%] [G loss: 1.116856]\n",
      "epoch:0 step:633[D loss: 0.495587, acc: 63.28%, op_acc: 29.69%] [G loss: 1.143715]\n",
      "epoch:0 step:634[D loss: 0.484306, acc: 64.06%, op_acc: 29.69%] [G loss: 1.076720]\n",
      "epoch:0 step:635[D loss: 0.525653, acc: 53.91%, op_acc: 25.78%] [G loss: 1.073809]\n",
      "epoch:0 step:636[D loss: 0.520956, acc: 56.25%, op_acc: 21.09%] [G loss: 1.000782]\n",
      "epoch:0 step:637[D loss: 0.494450, acc: 63.28%, op_acc: 23.44%] [G loss: 1.092007]\n",
      "epoch:0 step:638[D loss: 0.459517, acc: 64.06%, op_acc: 32.81%] [G loss: 1.091504]\n",
      "epoch:0 step:639[D loss: 0.490911, acc: 60.94%, op_acc: 27.34%] [G loss: 1.095098]\n",
      "epoch:0 step:640[D loss: 0.511954, acc: 57.03%, op_acc: 31.25%] [G loss: 1.234748]\n",
      "epoch:0 step:641[D loss: 0.538352, acc: 55.47%, op_acc: 26.56%] [G loss: 1.024262]\n",
      "epoch:0 step:642[D loss: 0.449246, acc: 68.75%, op_acc: 30.47%] [G loss: 1.116830]\n",
      "epoch:0 step:643[D loss: 0.495642, acc: 60.94%, op_acc: 16.41%] [G loss: 1.051488]\n",
      "epoch:0 step:644[D loss: 0.455775, acc: 65.62%, op_acc: 35.16%] [G loss: 1.265556]\n",
      "epoch:0 step:645[D loss: 0.456177, acc: 67.19%, op_acc: 25.00%] [G loss: 1.151542]\n",
      "epoch:0 step:646[D loss: 0.497764, acc: 64.84%, op_acc: 27.34%] [G loss: 1.026909]\n",
      "epoch:0 step:647[D loss: 0.493893, acc: 56.25%, op_acc: 28.91%] [G loss: 1.194650]\n",
      "epoch:0 step:648[D loss: 0.475602, acc: 68.75%, op_acc: 31.25%] [G loss: 1.117142]\n",
      "epoch:0 step:649[D loss: 0.524791, acc: 57.81%, op_acc: 23.44%] [G loss: 0.964251]\n",
      "epoch:0 step:650[D loss: 0.490087, acc: 63.28%, op_acc: 25.00%] [G loss: 1.095699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:651[D loss: 0.458640, acc: 63.28%, op_acc: 28.91%] [G loss: 1.219983]\n",
      "epoch:0 step:652[D loss: 0.442502, acc: 69.53%, op_acc: 29.69%] [G loss: 1.100445]\n",
      "epoch:0 step:653[D loss: 0.459625, acc: 61.72%, op_acc: 26.56%] [G loss: 1.005440]\n",
      "epoch:0 step:654[D loss: 0.442213, acc: 64.06%, op_acc: 28.91%] [G loss: 1.076478]\n",
      "epoch:0 step:655[D loss: 0.466841, acc: 64.84%, op_acc: 27.34%] [G loss: 1.183554]\n",
      "epoch:0 step:656[D loss: 0.497939, acc: 61.72%, op_acc: 22.66%] [G loss: 1.081822]\n",
      "epoch:0 step:657[D loss: 0.530075, acc: 57.81%, op_acc: 23.44%] [G loss: 1.142821]\n",
      "epoch:0 step:658[D loss: 0.495711, acc: 59.38%, op_acc: 29.69%] [G loss: 1.144785]\n",
      "epoch:0 step:659[D loss: 0.486712, acc: 63.28%, op_acc: 24.22%] [G loss: 1.253490]\n",
      "epoch:0 step:660[D loss: 0.446354, acc: 66.41%, op_acc: 25.00%] [G loss: 1.175632]\n",
      "epoch:0 step:661[D loss: 0.472029, acc: 57.81%, op_acc: 26.56%] [G loss: 1.161270]\n",
      "epoch:0 step:662[D loss: 0.479741, acc: 58.59%, op_acc: 30.47%] [G loss: 1.190275]\n",
      "epoch:0 step:663[D loss: 0.468196, acc: 57.03%, op_acc: 32.81%] [G loss: 1.148402]\n",
      "epoch:0 step:664[D loss: 0.445073, acc: 63.28%, op_acc: 25.78%] [G loss: 1.066402]\n",
      "epoch:0 step:665[D loss: 0.490762, acc: 65.62%, op_acc: 26.56%] [G loss: 1.253261]\n",
      "epoch:0 step:666[D loss: 0.505435, acc: 58.59%, op_acc: 18.75%] [G loss: 1.040136]\n",
      "epoch:0 step:667[D loss: 0.452947, acc: 68.75%, op_acc: 21.88%] [G loss: 1.199621]\n",
      "epoch:0 step:668[D loss: 0.479764, acc: 60.94%, op_acc: 18.75%] [G loss: 1.110466]\n",
      "epoch:0 step:669[D loss: 0.491367, acc: 64.06%, op_acc: 23.44%] [G loss: 1.168179]\n",
      "epoch:0 step:670[D loss: 0.463301, acc: 66.41%, op_acc: 28.12%] [G loss: 1.181911]\n",
      "epoch:0 step:671[D loss: 0.485409, acc: 64.84%, op_acc: 21.09%] [G loss: 1.188324]\n",
      "epoch:0 step:672[D loss: 0.416060, acc: 69.53%, op_acc: 27.34%] [G loss: 1.186602]\n",
      "epoch:0 step:673[D loss: 0.445685, acc: 65.62%, op_acc: 33.59%] [G loss: 1.109800]\n",
      "epoch:0 step:674[D loss: 0.524324, acc: 56.25%, op_acc: 27.34%] [G loss: 1.086018]\n",
      "epoch:0 step:675[D loss: 0.489198, acc: 62.50%, op_acc: 25.00%] [G loss: 1.067832]\n",
      "epoch:0 step:676[D loss: 0.530655, acc: 54.69%, op_acc: 21.09%] [G loss: 0.887577]\n",
      "epoch:0 step:677[D loss: 0.501580, acc: 57.81%, op_acc: 30.47%] [G loss: 1.068986]\n",
      "epoch:0 step:678[D loss: 0.481363, acc: 64.06%, op_acc: 26.56%] [G loss: 1.283907]\n",
      "epoch:0 step:679[D loss: 0.465356, acc: 62.50%, op_acc: 26.56%] [G loss: 1.198563]\n",
      "epoch:0 step:680[D loss: 0.533463, acc: 50.78%, op_acc: 18.75%] [G loss: 1.191126]\n",
      "epoch:0 step:681[D loss: 0.548322, acc: 57.03%, op_acc: 16.41%] [G loss: 1.114239]\n",
      "epoch:0 step:682[D loss: 0.461956, acc: 65.62%, op_acc: 32.03%] [G loss: 1.161126]\n",
      "epoch:0 step:683[D loss: 0.480560, acc: 61.72%, op_acc: 22.66%] [G loss: 1.197075]\n",
      "epoch:0 step:684[D loss: 0.500653, acc: 56.25%, op_acc: 22.66%] [G loss: 1.123105]\n",
      "epoch:0 step:685[D loss: 0.491755, acc: 62.50%, op_acc: 20.31%] [G loss: 1.213168]\n",
      "epoch:0 step:686[D loss: 0.502775, acc: 64.84%, op_acc: 17.19%] [G loss: 1.020808]\n",
      "epoch:0 step:687[D loss: 0.457344, acc: 61.72%, op_acc: 32.81%] [G loss: 1.143135]\n",
      "epoch:0 step:688[D loss: 0.486749, acc: 64.84%, op_acc: 28.91%] [G loss: 1.255579]\n",
      "epoch:0 step:689[D loss: 0.438644, acc: 68.75%, op_acc: 25.00%] [G loss: 1.200854]\n",
      "epoch:0 step:690[D loss: 0.478381, acc: 64.06%, op_acc: 28.91%] [G loss: 1.266272]\n",
      "epoch:0 step:691[D loss: 0.487869, acc: 61.72%, op_acc: 24.22%] [G loss: 1.209597]\n",
      "epoch:0 step:692[D loss: 0.487920, acc: 64.06%, op_acc: 24.22%] [G loss: 1.255638]\n",
      "epoch:0 step:693[D loss: 0.454707, acc: 66.41%, op_acc: 23.44%] [G loss: 1.031355]\n",
      "epoch:0 step:694[D loss: 0.490236, acc: 60.94%, op_acc: 25.00%] [G loss: 1.126047]\n",
      "epoch:0 step:695[D loss: 0.428397, acc: 73.44%, op_acc: 28.12%] [G loss: 1.140702]\n",
      "epoch:0 step:696[D loss: 0.525981, acc: 59.38%, op_acc: 23.44%] [G loss: 1.066416]\n",
      "epoch:0 step:697[D loss: 0.508575, acc: 53.91%, op_acc: 22.66%] [G loss: 1.095424]\n",
      "epoch:0 step:698[D loss: 0.483812, acc: 60.94%, op_acc: 24.22%] [G loss: 1.185734]\n",
      "epoch:0 step:699[D loss: 0.448222, acc: 64.84%, op_acc: 29.69%] [G loss: 1.080984]\n",
      "epoch:0 step:700[D loss: 0.478855, acc: 61.72%, op_acc: 29.69%] [G loss: 1.170066]\n",
      "epoch:0 step:701[D loss: 0.488052, acc: 61.72%, op_acc: 24.22%] [G loss: 1.090344]\n",
      "epoch:0 step:702[D loss: 0.491220, acc: 64.06%, op_acc: 26.56%] [G loss: 1.054443]\n",
      "epoch:0 step:703[D loss: 0.469083, acc: 63.28%, op_acc: 31.25%] [G loss: 1.008223]\n",
      "epoch:0 step:704[D loss: 0.484174, acc: 59.38%, op_acc: 28.12%] [G loss: 1.047035]\n",
      "epoch:0 step:705[D loss: 0.480552, acc: 61.72%, op_acc: 25.00%] [G loss: 1.074981]\n",
      "epoch:0 step:706[D loss: 0.486766, acc: 58.59%, op_acc: 29.69%] [G loss: 1.082216]\n",
      "epoch:0 step:707[D loss: 0.482145, acc: 66.41%, op_acc: 19.53%] [G loss: 1.136406]\n",
      "epoch:0 step:708[D loss: 0.509741, acc: 58.59%, op_acc: 22.66%] [G loss: 1.263456]\n",
      "epoch:0 step:709[D loss: 0.476590, acc: 64.06%, op_acc: 26.56%] [G loss: 1.217949]\n",
      "epoch:0 step:710[D loss: 0.410210, acc: 73.44%, op_acc: 29.69%] [G loss: 1.147078]\n",
      "epoch:0 step:711[D loss: 0.459672, acc: 64.84%, op_acc: 24.22%] [G loss: 1.174385]\n",
      "epoch:0 step:712[D loss: 0.431045, acc: 67.97%, op_acc: 32.81%] [G loss: 1.179873]\n",
      "epoch:0 step:713[D loss: 0.495630, acc: 54.69%, op_acc: 28.12%] [G loss: 1.213238]\n",
      "epoch:0 step:714[D loss: 0.457529, acc: 66.41%, op_acc: 25.00%] [G loss: 1.052109]\n",
      "epoch:0 step:715[D loss: 0.420092, acc: 71.09%, op_acc: 28.91%] [G loss: 1.200660]\n",
      "epoch:0 step:716[D loss: 0.470808, acc: 65.62%, op_acc: 28.12%] [G loss: 1.150806]\n",
      "epoch:0 step:717[D loss: 0.448494, acc: 66.41%, op_acc: 32.03%] [G loss: 1.211103]\n",
      "epoch:0 step:718[D loss: 0.469150, acc: 64.84%, op_acc: 28.91%] [G loss: 1.099289]\n",
      "epoch:0 step:719[D loss: 0.412338, acc: 72.66%, op_acc: 32.81%] [G loss: 1.272910]\n",
      "epoch:0 step:720[D loss: 0.447302, acc: 67.19%, op_acc: 29.69%] [G loss: 0.975730]\n",
      "epoch:0 step:721[D loss: 0.469949, acc: 63.28%, op_acc: 27.34%] [G loss: 1.145870]\n",
      "epoch:0 step:722[D loss: 0.467513, acc: 59.38%, op_acc: 26.56%] [G loss: 1.271437]\n",
      "epoch:0 step:723[D loss: 0.481964, acc: 57.81%, op_acc: 25.78%] [G loss: 1.120717]\n",
      "epoch:0 step:724[D loss: 0.514362, acc: 58.59%, op_acc: 21.09%] [G loss: 1.035980]\n",
      "epoch:0 step:725[D loss: 0.447057, acc: 68.75%, op_acc: 28.91%] [G loss: 1.079283]\n",
      "epoch:0 step:726[D loss: 0.492243, acc: 60.16%, op_acc: 25.00%] [G loss: 1.123830]\n",
      "epoch:0 step:727[D loss: 0.474409, acc: 64.06%, op_acc: 21.09%] [G loss: 1.058450]\n",
      "epoch:0 step:728[D loss: 0.459419, acc: 69.53%, op_acc: 26.56%] [G loss: 1.101180]\n",
      "epoch:0 step:729[D loss: 0.448279, acc: 70.31%, op_acc: 25.00%] [G loss: 1.082603]\n",
      "epoch:0 step:730[D loss: 0.482033, acc: 60.94%, op_acc: 25.78%] [G loss: 1.089036]\n",
      "epoch:0 step:731[D loss: 0.456433, acc: 63.28%, op_acc: 33.59%] [G loss: 0.993129]\n",
      "epoch:0 step:732[D loss: 0.495447, acc: 64.06%, op_acc: 24.22%] [G loss: 1.135059]\n",
      "epoch:0 step:733[D loss: 0.463057, acc: 67.97%, op_acc: 26.56%] [G loss: 1.291430]\n",
      "epoch:0 step:734[D loss: 0.467907, acc: 66.41%, op_acc: 30.47%] [G loss: 1.202572]\n",
      "epoch:0 step:735[D loss: 0.468982, acc: 63.28%, op_acc: 23.44%] [G loss: 1.283488]\n",
      "epoch:0 step:736[D loss: 0.474863, acc: 66.41%, op_acc: 28.12%] [G loss: 1.173302]\n",
      "epoch:0 step:737[D loss: 0.480954, acc: 62.50%, op_acc: 25.78%] [G loss: 1.031138]\n",
      "epoch:0 step:738[D loss: 0.523013, acc: 57.81%, op_acc: 22.66%] [G loss: 1.125101]\n",
      "epoch:0 step:739[D loss: 0.487694, acc: 56.25%, op_acc: 27.34%] [G loss: 1.034024]\n",
      "epoch:0 step:740[D loss: 0.487523, acc: 57.81%, op_acc: 28.12%] [G loss: 1.049764]\n",
      "epoch:0 step:741[D loss: 0.465066, acc: 66.41%, op_acc: 29.69%] [G loss: 1.135587]\n",
      "epoch:0 step:742[D loss: 0.499805, acc: 58.59%, op_acc: 24.22%] [G loss: 1.045426]\n",
      "epoch:0 step:743[D loss: 0.522514, acc: 54.69%, op_acc: 22.66%] [G loss: 1.178668]\n",
      "epoch:0 step:744[D loss: 0.455801, acc: 61.72%, op_acc: 29.69%] [G loss: 1.163076]\n",
      "epoch:0 step:745[D loss: 0.443063, acc: 69.53%, op_acc: 32.03%] [G loss: 0.942893]\n",
      "epoch:0 step:746[D loss: 0.450858, acc: 64.06%, op_acc: 28.91%] [G loss: 1.167288]\n",
      "epoch:0 step:747[D loss: 0.460310, acc: 64.84%, op_acc: 32.03%] [G loss: 1.096995]\n",
      "epoch:0 step:748[D loss: 0.506683, acc: 67.19%, op_acc: 16.41%] [G loss: 0.879135]\n",
      "epoch:0 step:749[D loss: 0.502045, acc: 61.72%, op_acc: 25.78%] [G loss: 1.119331]\n",
      "epoch:0 step:750[D loss: 0.470932, acc: 62.50%, op_acc: 28.12%] [G loss: 1.122035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:751[D loss: 0.532579, acc: 60.94%, op_acc: 24.22%] [G loss: 1.066895]\n",
      "epoch:0 step:752[D loss: 0.452515, acc: 63.28%, op_acc: 29.69%] [G loss: 1.029226]\n",
      "epoch:0 step:753[D loss: 0.436559, acc: 60.16%, op_acc: 24.22%] [G loss: 1.132739]\n",
      "epoch:0 step:754[D loss: 0.476439, acc: 59.38%, op_acc: 30.47%] [G loss: 1.086953]\n",
      "epoch:0 step:755[D loss: 0.467820, acc: 60.16%, op_acc: 25.78%] [G loss: 1.124396]\n",
      "epoch:0 step:756[D loss: 0.480798, acc: 57.03%, op_acc: 35.16%] [G loss: 1.041107]\n",
      "epoch:0 step:757[D loss: 0.518644, acc: 57.81%, op_acc: 22.66%] [G loss: 0.995951]\n",
      "epoch:0 step:758[D loss: 0.502534, acc: 57.81%, op_acc: 27.34%] [G loss: 1.023506]\n",
      "epoch:0 step:759[D loss: 0.506174, acc: 53.12%, op_acc: 22.66%] [G loss: 1.036385]\n",
      "epoch:0 step:760[D loss: 0.498837, acc: 60.94%, op_acc: 26.56%] [G loss: 0.989630]\n",
      "epoch:0 step:761[D loss: 0.452465, acc: 67.19%, op_acc: 32.03%] [G loss: 1.157427]\n",
      "epoch:0 step:762[D loss: 0.488791, acc: 60.94%, op_acc: 30.47%] [G loss: 1.104458]\n",
      "epoch:0 step:763[D loss: 0.512688, acc: 53.91%, op_acc: 26.56%] [G loss: 1.030241]\n",
      "epoch:0 step:764[D loss: 0.465383, acc: 64.06%, op_acc: 26.56%] [G loss: 1.145287]\n",
      "epoch:0 step:765[D loss: 0.496548, acc: 55.47%, op_acc: 30.47%] [G loss: 1.190405]\n",
      "epoch:0 step:766[D loss: 0.496411, acc: 64.06%, op_acc: 23.44%] [G loss: 1.136746]\n",
      "epoch:0 step:767[D loss: 0.469866, acc: 61.72%, op_acc: 28.91%] [G loss: 1.006932]\n",
      "epoch:0 step:768[D loss: 0.460468, acc: 64.84%, op_acc: 22.66%] [G loss: 1.064244]\n",
      "epoch:0 step:769[D loss: 0.455755, acc: 67.19%, op_acc: 30.47%] [G loss: 1.071111]\n",
      "epoch:0 step:770[D loss: 0.425222, acc: 72.66%, op_acc: 26.56%] [G loss: 1.279046]\n",
      "epoch:0 step:771[D loss: 0.480061, acc: 64.84%, op_acc: 22.66%] [G loss: 1.141361]\n",
      "epoch:0 step:772[D loss: 0.485029, acc: 59.38%, op_acc: 26.56%] [G loss: 0.974859]\n",
      "epoch:0 step:773[D loss: 0.511539, acc: 52.34%, op_acc: 32.03%] [G loss: 1.007529]\n",
      "epoch:0 step:774[D loss: 0.458849, acc: 60.94%, op_acc: 28.12%] [G loss: 1.154685]\n",
      "epoch:0 step:775[D loss: 0.535480, acc: 53.91%, op_acc: 20.31%] [G loss: 1.067516]\n",
      "epoch:0 step:776[D loss: 0.457338, acc: 62.50%, op_acc: 28.12%] [G loss: 1.123854]\n",
      "epoch:0 step:777[D loss: 0.495256, acc: 60.16%, op_acc: 28.91%] [G loss: 1.144654]\n",
      "epoch:0 step:778[D loss: 0.434278, acc: 63.28%, op_acc: 31.25%] [G loss: 1.061102]\n",
      "epoch:0 step:779[D loss: 0.523837, acc: 55.47%, op_acc: 29.69%] [G loss: 1.141555]\n",
      "epoch:0 step:780[D loss: 0.471920, acc: 60.16%, op_acc: 30.47%] [G loss: 1.115577]\n",
      "epoch:0 step:781[D loss: 0.466099, acc: 65.62%, op_acc: 25.78%] [G loss: 1.083101]\n",
      "epoch:1 step:782[D loss: 0.484586, acc: 61.72%, op_acc: 26.56%] [G loss: 1.182106]\n",
      "epoch:1 step:783[D loss: 0.496582, acc: 57.03%, op_acc: 25.78%] [G loss: 1.039504]\n",
      "epoch:1 step:784[D loss: 0.496335, acc: 55.47%, op_acc: 28.91%] [G loss: 1.116294]\n",
      "epoch:1 step:785[D loss: 0.445436, acc: 63.28%, op_acc: 22.66%] [G loss: 0.939503]\n",
      "epoch:1 step:786[D loss: 0.451692, acc: 67.97%, op_acc: 35.16%] [G loss: 1.142770]\n",
      "epoch:1 step:787[D loss: 0.499926, acc: 57.81%, op_acc: 28.12%] [G loss: 1.189955]\n",
      "epoch:1 step:788[D loss: 0.444913, acc: 68.75%, op_acc: 28.12%] [G loss: 1.265457]\n",
      "epoch:1 step:789[D loss: 0.432590, acc: 67.19%, op_acc: 32.03%] [G loss: 1.158602]\n",
      "epoch:1 step:790[D loss: 0.452265, acc: 67.97%, op_acc: 35.16%] [G loss: 1.184255]\n",
      "epoch:1 step:791[D loss: 0.454730, acc: 68.75%, op_acc: 31.25%] [G loss: 1.278024]\n",
      "epoch:1 step:792[D loss: 0.491704, acc: 62.50%, op_acc: 30.47%] [G loss: 1.115851]\n",
      "epoch:1 step:793[D loss: 0.433495, acc: 71.09%, op_acc: 27.34%] [G loss: 1.090634]\n",
      "epoch:1 step:794[D loss: 0.470287, acc: 63.28%, op_acc: 24.22%] [G loss: 1.124859]\n",
      "epoch:1 step:795[D loss: 0.493120, acc: 60.94%, op_acc: 26.56%] [G loss: 0.954927]\n",
      "epoch:1 step:796[D loss: 0.479265, acc: 60.16%, op_acc: 28.91%] [G loss: 1.059199]\n",
      "epoch:1 step:797[D loss: 0.463509, acc: 61.72%, op_acc: 28.12%] [G loss: 1.176262]\n",
      "epoch:1 step:798[D loss: 0.482061, acc: 57.03%, op_acc: 27.34%] [G loss: 1.120767]\n",
      "epoch:1 step:799[D loss: 0.493012, acc: 57.03%, op_acc: 27.34%] [G loss: 0.991707]\n",
      "epoch:1 step:800[D loss: 0.480682, acc: 57.81%, op_acc: 28.12%] [G loss: 1.056463]\n",
      "epoch:1 step:801[D loss: 0.458965, acc: 67.97%, op_acc: 25.78%] [G loss: 1.072640]\n",
      "epoch:1 step:802[D loss: 0.466676, acc: 67.19%, op_acc: 24.22%] [G loss: 1.164616]\n",
      "epoch:1 step:803[D loss: 0.454544, acc: 61.72%, op_acc: 32.81%] [G loss: 1.074874]\n",
      "epoch:1 step:804[D loss: 0.463543, acc: 66.41%, op_acc: 28.91%] [G loss: 1.041856]\n",
      "epoch:1 step:805[D loss: 0.522714, acc: 53.91%, op_acc: 22.66%] [G loss: 1.119173]\n",
      "epoch:1 step:806[D loss: 0.478612, acc: 60.94%, op_acc: 21.88%] [G loss: 0.979779]\n",
      "epoch:1 step:807[D loss: 0.456285, acc: 66.41%, op_acc: 33.59%] [G loss: 1.140431]\n",
      "epoch:1 step:808[D loss: 0.415040, acc: 70.31%, op_acc: 30.47%] [G loss: 1.056012]\n",
      "epoch:1 step:809[D loss: 0.509525, acc: 55.47%, op_acc: 21.88%] [G loss: 1.088134]\n",
      "epoch:1 step:810[D loss: 0.470448, acc: 58.59%, op_acc: 26.56%] [G loss: 1.099782]\n",
      "epoch:1 step:811[D loss: 0.457371, acc: 63.28%, op_acc: 32.81%] [G loss: 1.163360]\n",
      "epoch:1 step:812[D loss: 0.487420, acc: 71.88%, op_acc: 22.66%] [G loss: 1.183766]\n",
      "epoch:1 step:813[D loss: 0.506940, acc: 57.03%, op_acc: 23.44%] [G loss: 1.145310]\n",
      "epoch:1 step:814[D loss: 0.494105, acc: 57.81%, op_acc: 30.47%] [G loss: 1.185705]\n",
      "epoch:1 step:815[D loss: 0.458066, acc: 65.62%, op_acc: 25.00%] [G loss: 1.083537]\n",
      "epoch:1 step:816[D loss: 0.465013, acc: 60.16%, op_acc: 28.91%] [G loss: 1.401186]\n",
      "epoch:1 step:817[D loss: 0.454585, acc: 59.38%, op_acc: 34.38%] [G loss: 1.260350]\n",
      "epoch:1 step:818[D loss: 0.461845, acc: 67.19%, op_acc: 23.44%] [G loss: 1.111819]\n",
      "epoch:1 step:819[D loss: 0.447253, acc: 64.84%, op_acc: 33.59%] [G loss: 1.033832]\n",
      "epoch:1 step:820[D loss: 0.445751, acc: 62.50%, op_acc: 23.44%] [G loss: 1.066282]\n",
      "epoch:1 step:821[D loss: 0.456894, acc: 65.62%, op_acc: 23.44%] [G loss: 1.115882]\n",
      "epoch:1 step:822[D loss: 0.464920, acc: 62.50%, op_acc: 32.81%] [G loss: 1.124314]\n",
      "epoch:1 step:823[D loss: 0.474179, acc: 60.94%, op_acc: 28.91%] [G loss: 1.042434]\n",
      "epoch:1 step:824[D loss: 0.506633, acc: 57.81%, op_acc: 25.78%] [G loss: 0.986601]\n",
      "epoch:1 step:825[D loss: 0.454710, acc: 64.84%, op_acc: 25.78%] [G loss: 1.037340]\n",
      "epoch:1 step:826[D loss: 0.464072, acc: 60.16%, op_acc: 35.16%] [G loss: 1.194266]\n",
      "epoch:1 step:827[D loss: 0.502482, acc: 57.81%, op_acc: 28.91%] [G loss: 1.053092]\n",
      "epoch:1 step:828[D loss: 0.450224, acc: 66.41%, op_acc: 24.22%] [G loss: 1.117618]\n",
      "epoch:1 step:829[D loss: 0.509941, acc: 59.38%, op_acc: 25.78%] [G loss: 0.956843]\n",
      "epoch:1 step:830[D loss: 0.480541, acc: 63.28%, op_acc: 32.03%] [G loss: 1.077999]\n",
      "epoch:1 step:831[D loss: 0.536418, acc: 53.91%, op_acc: 20.31%] [G loss: 1.020445]\n",
      "epoch:1 step:832[D loss: 0.539002, acc: 50.78%, op_acc: 25.78%] [G loss: 1.041561]\n",
      "epoch:1 step:833[D loss: 0.479556, acc: 52.34%, op_acc: 32.03%] [G loss: 1.048072]\n",
      "epoch:1 step:834[D loss: 0.452520, acc: 67.97%, op_acc: 26.56%] [G loss: 1.143520]\n",
      "epoch:1 step:835[D loss: 0.508702, acc: 56.25%, op_acc: 22.66%] [G loss: 0.994103]\n",
      "epoch:1 step:836[D loss: 0.475272, acc: 59.38%, op_acc: 31.25%] [G loss: 1.173040]\n",
      "epoch:1 step:837[D loss: 0.436519, acc: 70.31%, op_acc: 28.91%] [G loss: 1.109567]\n",
      "epoch:1 step:838[D loss: 0.543000, acc: 54.69%, op_acc: 22.66%] [G loss: 0.778684]\n",
      "epoch:1 step:839[D loss: 0.425176, acc: 70.31%, op_acc: 28.12%] [G loss: 1.029094]\n",
      "epoch:1 step:840[D loss: 0.430484, acc: 70.31%, op_acc: 28.12%] [G loss: 1.089911]\n",
      "epoch:1 step:841[D loss: 0.483781, acc: 62.50%, op_acc: 24.22%] [G loss: 0.959025]\n",
      "epoch:1 step:842[D loss: 0.502168, acc: 58.59%, op_acc: 23.44%] [G loss: 1.087650]\n",
      "epoch:1 step:843[D loss: 0.527865, acc: 55.47%, op_acc: 27.34%] [G loss: 1.175723]\n",
      "epoch:1 step:844[D loss: 0.499502, acc: 55.47%, op_acc: 30.47%] [G loss: 1.114553]\n",
      "epoch:1 step:845[D loss: 0.489554, acc: 55.47%, op_acc: 34.38%] [G loss: 1.255837]\n",
      "epoch:1 step:846[D loss: 0.465971, acc: 61.72%, op_acc: 32.03%] [G loss: 1.083348]\n",
      "epoch:1 step:847[D loss: 0.445131, acc: 68.75%, op_acc: 31.25%] [G loss: 0.952863]\n",
      "epoch:1 step:848[D loss: 0.478590, acc: 66.41%, op_acc: 28.91%] [G loss: 1.151163]\n",
      "epoch:1 step:849[D loss: 0.468876, acc: 60.94%, op_acc: 25.00%] [G loss: 1.140320]\n",
      "epoch:1 step:850[D loss: 0.454639, acc: 64.84%, op_acc: 33.59%] [G loss: 1.022611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:851[D loss: 0.481818, acc: 60.16%, op_acc: 30.47%] [G loss: 1.044773]\n",
      "epoch:1 step:852[D loss: 0.502100, acc: 63.28%, op_acc: 22.66%] [G loss: 1.189681]\n",
      "epoch:1 step:853[D loss: 0.403861, acc: 72.66%, op_acc: 32.81%] [G loss: 1.098159]\n",
      "epoch:1 step:854[D loss: 0.476267, acc: 62.50%, op_acc: 29.69%] [G loss: 1.003153]\n",
      "epoch:1 step:855[D loss: 0.450096, acc: 64.06%, op_acc: 31.25%] [G loss: 1.002014]\n",
      "epoch:1 step:856[D loss: 0.424333, acc: 69.53%, op_acc: 27.34%] [G loss: 0.953626]\n",
      "epoch:1 step:857[D loss: 0.476668, acc: 60.16%, op_acc: 24.22%] [G loss: 1.114347]\n",
      "epoch:1 step:858[D loss: 0.475449, acc: 61.72%, op_acc: 31.25%] [G loss: 1.166765]\n",
      "epoch:1 step:859[D loss: 0.474084, acc: 62.50%, op_acc: 28.12%] [G loss: 1.121991]\n",
      "epoch:1 step:860[D loss: 0.436062, acc: 69.53%, op_acc: 27.34%] [G loss: 1.169894]\n",
      "epoch:1 step:861[D loss: 0.507692, acc: 62.50%, op_acc: 24.22%] [G loss: 1.131616]\n",
      "epoch:1 step:862[D loss: 0.509399, acc: 57.81%, op_acc: 28.91%] [G loss: 1.003160]\n",
      "epoch:1 step:863[D loss: 0.472817, acc: 66.41%, op_acc: 31.25%] [G loss: 1.034645]\n",
      "epoch:1 step:864[D loss: 0.503323, acc: 57.03%, op_acc: 28.91%] [G loss: 1.032875]\n",
      "epoch:1 step:865[D loss: 0.467883, acc: 63.28%, op_acc: 30.47%] [G loss: 1.123262]\n",
      "epoch:1 step:866[D loss: 0.479216, acc: 59.38%, op_acc: 23.44%] [G loss: 1.032896]\n",
      "epoch:1 step:867[D loss: 0.515603, acc: 53.12%, op_acc: 26.56%] [G loss: 1.175405]\n",
      "epoch:1 step:868[D loss: 0.494292, acc: 61.72%, op_acc: 28.91%] [G loss: 1.064051]\n",
      "epoch:1 step:869[D loss: 0.478550, acc: 57.03%, op_acc: 32.81%] [G loss: 1.106211]\n",
      "epoch:1 step:870[D loss: 0.504067, acc: 55.47%, op_acc: 21.09%] [G loss: 0.950046]\n",
      "epoch:1 step:871[D loss: 0.477246, acc: 59.38%, op_acc: 29.69%] [G loss: 0.958969]\n",
      "epoch:1 step:872[D loss: 0.502470, acc: 63.28%, op_acc: 17.19%] [G loss: 1.084725]\n",
      "epoch:1 step:873[D loss: 0.433008, acc: 64.84%, op_acc: 25.78%] [G loss: 1.094577]\n",
      "epoch:1 step:874[D loss: 0.494748, acc: 57.81%, op_acc: 25.00%] [G loss: 1.110522]\n",
      "epoch:1 step:875[D loss: 0.474480, acc: 59.38%, op_acc: 28.91%] [G loss: 1.015409]\n",
      "epoch:1 step:876[D loss: 0.460303, acc: 66.41%, op_acc: 25.78%] [G loss: 1.169122]\n",
      "epoch:1 step:877[D loss: 0.478428, acc: 60.94%, op_acc: 22.66%] [G loss: 1.104324]\n",
      "epoch:1 step:878[D loss: 0.519820, acc: 53.91%, op_acc: 30.47%] [G loss: 1.039353]\n",
      "epoch:1 step:879[D loss: 0.476264, acc: 63.28%, op_acc: 22.66%] [G loss: 1.077570]\n",
      "epoch:1 step:880[D loss: 0.489430, acc: 50.00%, op_acc: 31.25%] [G loss: 1.130868]\n",
      "epoch:1 step:881[D loss: 0.477297, acc: 59.38%, op_acc: 31.25%] [G loss: 1.066741]\n",
      "epoch:1 step:882[D loss: 0.417073, acc: 75.78%, op_acc: 31.25%] [G loss: 1.120448]\n",
      "epoch:1 step:883[D loss: 0.456747, acc: 66.41%, op_acc: 30.47%] [G loss: 1.196899]\n",
      "epoch:1 step:884[D loss: 0.519091, acc: 56.25%, op_acc: 27.34%] [G loss: 0.946487]\n",
      "epoch:1 step:885[D loss: 0.488285, acc: 64.06%, op_acc: 25.78%] [G loss: 1.040081]\n",
      "epoch:1 step:886[D loss: 0.475822, acc: 61.72%, op_acc: 23.44%] [G loss: 0.990033]\n",
      "epoch:1 step:887[D loss: 0.457030, acc: 66.41%, op_acc: 21.09%] [G loss: 1.025909]\n",
      "epoch:1 step:888[D loss: 0.465421, acc: 56.25%, op_acc: 27.34%] [G loss: 1.034426]\n",
      "epoch:1 step:889[D loss: 0.548487, acc: 49.22%, op_acc: 25.00%] [G loss: 1.060683]\n",
      "epoch:1 step:890[D loss: 0.476182, acc: 62.50%, op_acc: 25.00%] [G loss: 1.086410]\n",
      "epoch:1 step:891[D loss: 0.447007, acc: 62.50%, op_acc: 26.56%] [G loss: 1.216474]\n",
      "epoch:1 step:892[D loss: 0.489513, acc: 60.16%, op_acc: 20.31%] [G loss: 1.229445]\n",
      "epoch:1 step:893[D loss: 0.514248, acc: 51.56%, op_acc: 28.91%] [G loss: 1.052708]\n",
      "epoch:1 step:894[D loss: 0.453580, acc: 67.97%, op_acc: 21.09%] [G loss: 1.121715]\n",
      "epoch:1 step:895[D loss: 0.451000, acc: 66.41%, op_acc: 37.50%] [G loss: 1.120650]\n",
      "epoch:1 step:896[D loss: 0.486750, acc: 57.81%, op_acc: 27.34%] [G loss: 1.070575]\n",
      "epoch:1 step:897[D loss: 0.464502, acc: 65.62%, op_acc: 22.66%] [G loss: 1.027734]\n",
      "epoch:1 step:898[D loss: 0.483444, acc: 62.50%, op_acc: 24.22%] [G loss: 1.007473]\n",
      "epoch:1 step:899[D loss: 0.481929, acc: 58.59%, op_acc: 28.12%] [G loss: 1.008155]\n",
      "epoch:1 step:900[D loss: 0.514053, acc: 57.03%, op_acc: 21.09%] [G loss: 0.979043]\n",
      "epoch:1 step:901[D loss: 0.504920, acc: 62.50%, op_acc: 25.00%] [G loss: 0.934486]\n",
      "epoch:1 step:902[D loss: 0.508005, acc: 60.94%, op_acc: 25.78%] [G loss: 1.059271]\n",
      "epoch:1 step:903[D loss: 0.475065, acc: 58.59%, op_acc: 30.47%] [G loss: 1.075117]\n",
      "epoch:1 step:904[D loss: 0.518753, acc: 58.59%, op_acc: 25.00%] [G loss: 0.966478]\n",
      "epoch:1 step:905[D loss: 0.526235, acc: 46.09%, op_acc: 28.91%] [G loss: 1.021096]\n",
      "epoch:1 step:906[D loss: 0.496585, acc: 60.16%, op_acc: 22.66%] [G loss: 0.986320]\n",
      "epoch:1 step:907[D loss: 0.487738, acc: 60.16%, op_acc: 26.56%] [G loss: 1.081161]\n",
      "epoch:1 step:908[D loss: 0.472211, acc: 66.41%, op_acc: 28.91%] [G loss: 1.208001]\n",
      "epoch:1 step:909[D loss: 0.487171, acc: 50.78%, op_acc: 28.12%] [G loss: 1.238208]\n",
      "epoch:1 step:910[D loss: 0.465470, acc: 64.84%, op_acc: 24.22%] [G loss: 1.161915]\n",
      "epoch:1 step:911[D loss: 0.479882, acc: 62.50%, op_acc: 29.69%] [G loss: 1.069379]\n",
      "epoch:1 step:912[D loss: 0.513903, acc: 59.38%, op_acc: 25.78%] [G loss: 1.011097]\n",
      "epoch:1 step:913[D loss: 0.458078, acc: 62.50%, op_acc: 28.91%] [G loss: 0.916633]\n",
      "epoch:1 step:914[D loss: 0.508697, acc: 60.94%, op_acc: 25.78%] [G loss: 0.944914]\n",
      "epoch:1 step:915[D loss: 0.438554, acc: 65.62%, op_acc: 22.66%] [G loss: 0.939371]\n",
      "epoch:1 step:916[D loss: 0.484413, acc: 58.59%, op_acc: 32.81%] [G loss: 0.991397]\n",
      "epoch:1 step:917[D loss: 0.416407, acc: 63.28%, op_acc: 33.59%] [G loss: 0.948861]\n",
      "epoch:1 step:918[D loss: 0.463237, acc: 59.38%, op_acc: 28.12%] [G loss: 1.052844]\n",
      "epoch:1 step:919[D loss: 0.517185, acc: 56.25%, op_acc: 25.78%] [G loss: 1.048430]\n",
      "epoch:1 step:920[D loss: 0.513872, acc: 56.25%, op_acc: 27.34%] [G loss: 1.040691]\n",
      "epoch:1 step:921[D loss: 0.488366, acc: 64.84%, op_acc: 25.78%] [G loss: 1.039453]\n",
      "epoch:1 step:922[D loss: 0.555674, acc: 51.56%, op_acc: 25.00%] [G loss: 1.021337]\n",
      "epoch:1 step:923[D loss: 0.503881, acc: 50.78%, op_acc: 28.91%] [G loss: 1.042690]\n",
      "epoch:1 step:924[D loss: 0.458808, acc: 64.06%, op_acc: 30.47%] [G loss: 1.113887]\n",
      "epoch:1 step:925[D loss: 0.522774, acc: 51.56%, op_acc: 24.22%] [G loss: 1.188751]\n",
      "epoch:1 step:926[D loss: 0.494160, acc: 62.50%, op_acc: 29.69%] [G loss: 1.068477]\n",
      "epoch:1 step:927[D loss: 0.477992, acc: 63.28%, op_acc: 28.91%] [G loss: 1.077198]\n",
      "epoch:1 step:928[D loss: 0.451161, acc: 71.88%, op_acc: 32.81%] [G loss: 1.107144]\n",
      "epoch:1 step:929[D loss: 0.500889, acc: 60.94%, op_acc: 24.22%] [G loss: 1.009190]\n",
      "epoch:1 step:930[D loss: 0.485658, acc: 58.59%, op_acc: 26.56%] [G loss: 0.955166]\n",
      "epoch:1 step:931[D loss: 0.472442, acc: 64.06%, op_acc: 30.47%] [G loss: 1.159446]\n",
      "epoch:1 step:932[D loss: 0.541466, acc: 54.69%, op_acc: 21.09%] [G loss: 0.917041]\n",
      "epoch:1 step:933[D loss: 0.519076, acc: 53.91%, op_acc: 25.00%] [G loss: 1.014248]\n",
      "epoch:1 step:934[D loss: 0.534126, acc: 52.34%, op_acc: 23.44%] [G loss: 0.891203]\n",
      "epoch:1 step:935[D loss: 0.433404, acc: 68.75%, op_acc: 29.69%] [G loss: 1.036256]\n",
      "epoch:1 step:936[D loss: 0.469575, acc: 62.50%, op_acc: 25.00%] [G loss: 1.018502]\n",
      "epoch:1 step:937[D loss: 0.442142, acc: 67.97%, op_acc: 32.81%] [G loss: 1.147367]\n",
      "epoch:1 step:938[D loss: 0.456003, acc: 65.62%, op_acc: 28.91%] [G loss: 1.015222]\n",
      "epoch:1 step:939[D loss: 0.451330, acc: 64.84%, op_acc: 32.03%] [G loss: 1.105700]\n",
      "epoch:1 step:940[D loss: 0.478163, acc: 63.28%, op_acc: 27.34%] [G loss: 0.996127]\n",
      "epoch:1 step:941[D loss: 0.448349, acc: 67.97%, op_acc: 35.16%] [G loss: 1.054627]\n",
      "epoch:1 step:942[D loss: 0.474763, acc: 63.28%, op_acc: 23.44%] [G loss: 0.998766]\n",
      "epoch:1 step:943[D loss: 0.475453, acc: 62.50%, op_acc: 32.03%] [G loss: 0.973738]\n",
      "epoch:1 step:944[D loss: 0.427260, acc: 67.19%, op_acc: 29.69%] [G loss: 1.009164]\n",
      "epoch:1 step:945[D loss: 0.473373, acc: 57.81%, op_acc: 25.78%] [G loss: 0.946603]\n",
      "epoch:1 step:946[D loss: 0.411808, acc: 71.88%, op_acc: 26.56%] [G loss: 1.123716]\n",
      "epoch:1 step:947[D loss: 0.514449, acc: 50.00%, op_acc: 23.44%] [G loss: 0.913942]\n",
      "epoch:1 step:948[D loss: 0.456332, acc: 60.16%, op_acc: 24.22%] [G loss: 1.037722]\n",
      "epoch:1 step:949[D loss: 0.449291, acc: 58.59%, op_acc: 29.69%] [G loss: 1.017038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:950[D loss: 0.443065, acc: 67.19%, op_acc: 35.16%] [G loss: 1.012110]\n",
      "epoch:1 step:951[D loss: 0.472043, acc: 61.72%, op_acc: 32.03%] [G loss: 1.051703]\n",
      "epoch:1 step:952[D loss: 0.476747, acc: 61.72%, op_acc: 25.00%] [G loss: 0.978451]\n",
      "epoch:1 step:953[D loss: 0.473416, acc: 56.25%, op_acc: 24.22%] [G loss: 1.024220]\n",
      "epoch:1 step:954[D loss: 0.457046, acc: 68.75%, op_acc: 23.44%] [G loss: 1.060832]\n",
      "epoch:1 step:955[D loss: 0.507320, acc: 60.94%, op_acc: 28.91%] [G loss: 1.030923]\n",
      "epoch:1 step:956[D loss: 0.477637, acc: 61.72%, op_acc: 27.34%] [G loss: 1.076347]\n",
      "epoch:1 step:957[D loss: 0.466500, acc: 61.72%, op_acc: 30.47%] [G loss: 1.105029]\n",
      "epoch:1 step:958[D loss: 0.447488, acc: 65.62%, op_acc: 32.03%] [G loss: 1.061111]\n",
      "epoch:1 step:959[D loss: 0.500761, acc: 58.59%, op_acc: 27.34%] [G loss: 1.197635]\n",
      "epoch:1 step:960[D loss: 0.517262, acc: 53.91%, op_acc: 23.44%] [G loss: 1.096656]\n",
      "epoch:1 step:961[D loss: 0.457301, acc: 63.28%, op_acc: 31.25%] [G loss: 1.038792]\n",
      "epoch:1 step:962[D loss: 0.433570, acc: 71.09%, op_acc: 23.44%] [G loss: 1.047667]\n",
      "epoch:1 step:963[D loss: 0.453547, acc: 61.72%, op_acc: 32.03%] [G loss: 1.161952]\n",
      "epoch:1 step:964[D loss: 0.479329, acc: 60.94%, op_acc: 25.00%] [G loss: 1.029123]\n",
      "epoch:1 step:965[D loss: 0.442920, acc: 67.19%, op_acc: 32.03%] [G loss: 1.007016]\n",
      "epoch:1 step:966[D loss: 0.420332, acc: 69.53%, op_acc: 29.69%] [G loss: 1.140215]\n",
      "epoch:1 step:967[D loss: 0.436255, acc: 70.31%, op_acc: 28.91%] [G loss: 1.109277]\n",
      "epoch:1 step:968[D loss: 0.465940, acc: 67.19%, op_acc: 20.31%] [G loss: 1.222348]\n",
      "epoch:1 step:969[D loss: 0.491376, acc: 55.47%, op_acc: 30.47%] [G loss: 0.953287]\n",
      "epoch:1 step:970[D loss: 0.465746, acc: 59.38%, op_acc: 24.22%] [G loss: 1.122718]\n",
      "epoch:1 step:971[D loss: 0.463208, acc: 64.06%, op_acc: 21.88%] [G loss: 1.034865]\n",
      "epoch:1 step:972[D loss: 0.456081, acc: 60.16%, op_acc: 28.91%] [G loss: 1.116264]\n",
      "epoch:1 step:973[D loss: 0.476346, acc: 64.84%, op_acc: 26.56%] [G loss: 1.275292]\n",
      "epoch:1 step:974[D loss: 0.479134, acc: 61.72%, op_acc: 28.12%] [G loss: 1.118992]\n",
      "epoch:1 step:975[D loss: 0.526940, acc: 50.00%, op_acc: 25.00%] [G loss: 0.920452]\n",
      "epoch:1 step:976[D loss: 0.474018, acc: 57.81%, op_acc: 31.25%] [G loss: 1.021923]\n",
      "epoch:1 step:977[D loss: 0.465720, acc: 69.53%, op_acc: 24.22%] [G loss: 0.961872]\n",
      "epoch:1 step:978[D loss: 0.496370, acc: 57.03%, op_acc: 25.78%] [G loss: 1.061344]\n",
      "epoch:1 step:979[D loss: 0.440281, acc: 65.62%, op_acc: 31.25%] [G loss: 1.158901]\n",
      "epoch:1 step:980[D loss: 0.504264, acc: 57.81%, op_acc: 30.47%] [G loss: 1.061373]\n",
      "epoch:1 step:981[D loss: 0.480735, acc: 61.72%, op_acc: 28.12%] [G loss: 0.978437]\n",
      "epoch:1 step:982[D loss: 0.459029, acc: 63.28%, op_acc: 25.00%] [G loss: 1.032050]\n",
      "epoch:1 step:983[D loss: 0.487207, acc: 60.94%, op_acc: 29.69%] [G loss: 1.070395]\n",
      "epoch:1 step:984[D loss: 0.479954, acc: 60.16%, op_acc: 25.00%] [G loss: 0.958777]\n",
      "epoch:1 step:985[D loss: 0.465586, acc: 64.06%, op_acc: 32.81%] [G loss: 1.115138]\n",
      "epoch:1 step:986[D loss: 0.463993, acc: 66.41%, op_acc: 25.00%] [G loss: 1.127606]\n",
      "epoch:1 step:987[D loss: 0.484639, acc: 60.94%, op_acc: 23.44%] [G loss: 1.087422]\n",
      "epoch:1 step:988[D loss: 0.456118, acc: 59.38%, op_acc: 30.47%] [G loss: 1.114859]\n",
      "epoch:1 step:989[D loss: 0.519801, acc: 56.25%, op_acc: 25.00%] [G loss: 1.025241]\n",
      "epoch:1 step:990[D loss: 0.524492, acc: 50.78%, op_acc: 28.12%] [G loss: 1.126402]\n",
      "epoch:1 step:991[D loss: 0.484965, acc: 58.59%, op_acc: 28.12%] [G loss: 1.163862]\n",
      "epoch:1 step:992[D loss: 0.454645, acc: 60.94%, op_acc: 30.47%] [G loss: 1.178821]\n",
      "epoch:1 step:993[D loss: 0.479024, acc: 58.59%, op_acc: 28.91%] [G loss: 1.139993]\n",
      "epoch:1 step:994[D loss: 0.481438, acc: 57.81%, op_acc: 26.56%] [G loss: 1.075890]\n",
      "epoch:1 step:995[D loss: 0.497619, acc: 64.06%, op_acc: 24.22%] [G loss: 1.183716]\n",
      "epoch:1 step:996[D loss: 0.489634, acc: 56.25%, op_acc: 24.22%] [G loss: 0.988669]\n",
      "epoch:1 step:997[D loss: 0.484693, acc: 60.16%, op_acc: 27.34%] [G loss: 1.119871]\n",
      "epoch:1 step:998[D loss: 0.492173, acc: 58.59%, op_acc: 21.88%] [G loss: 1.151382]\n",
      "epoch:1 step:999[D loss: 0.496591, acc: 53.91%, op_acc: 23.44%] [G loss: 0.990863]\n",
      "epoch:1 step:1000[D loss: 0.490137, acc: 56.25%, op_acc: 28.12%] [G loss: 1.011598]\n",
      "epoch:1 step:1001[D loss: 0.476731, acc: 58.59%, op_acc: 32.81%] [G loss: 0.935095]\n",
      "epoch:1 step:1002[D loss: 0.472445, acc: 62.50%, op_acc: 20.31%] [G loss: 1.163727]\n",
      "epoch:1 step:1003[D loss: 0.498403, acc: 59.38%, op_acc: 21.09%] [G loss: 1.038147]\n",
      "epoch:1 step:1004[D loss: 0.488713, acc: 57.03%, op_acc: 25.78%] [G loss: 1.070256]\n",
      "epoch:1 step:1005[D loss: 0.504274, acc: 58.59%, op_acc: 22.66%] [G loss: 1.165360]\n",
      "epoch:1 step:1006[D loss: 0.505281, acc: 53.12%, op_acc: 25.78%] [G loss: 0.951101]\n",
      "epoch:1 step:1007[D loss: 0.473534, acc: 60.94%, op_acc: 25.78%] [G loss: 0.914638]\n",
      "epoch:1 step:1008[D loss: 0.484448, acc: 62.50%, op_acc: 25.78%] [G loss: 1.052776]\n",
      "epoch:1 step:1009[D loss: 0.466222, acc: 60.94%, op_acc: 28.12%] [G loss: 0.951822]\n",
      "epoch:1 step:1010[D loss: 0.476483, acc: 66.41%, op_acc: 29.69%] [G loss: 0.933140]\n",
      "epoch:1 step:1011[D loss: 0.470451, acc: 70.31%, op_acc: 23.44%] [G loss: 0.998144]\n",
      "epoch:1 step:1012[D loss: 0.492617, acc: 57.03%, op_acc: 29.69%] [G loss: 0.997601]\n",
      "epoch:1 step:1013[D loss: 0.493285, acc: 60.16%, op_acc: 22.66%] [G loss: 1.073485]\n",
      "epoch:1 step:1014[D loss: 0.484850, acc: 61.72%, op_acc: 30.47%] [G loss: 1.064160]\n",
      "epoch:1 step:1015[D loss: 0.504414, acc: 62.50%, op_acc: 17.19%] [G loss: 0.988887]\n",
      "epoch:1 step:1016[D loss: 0.529776, acc: 54.69%, op_acc: 24.22%] [G loss: 1.063795]\n",
      "epoch:1 step:1017[D loss: 0.491938, acc: 62.50%, op_acc: 24.22%] [G loss: 1.111792]\n",
      "epoch:1 step:1018[D loss: 0.479451, acc: 62.50%, op_acc: 25.00%] [G loss: 1.074467]\n",
      "epoch:1 step:1019[D loss: 0.488805, acc: 59.38%, op_acc: 22.66%] [G loss: 1.024835]\n",
      "epoch:1 step:1020[D loss: 0.451012, acc: 67.97%, op_acc: 29.69%] [G loss: 1.030231]\n",
      "epoch:1 step:1021[D loss: 0.475924, acc: 62.50%, op_acc: 28.91%] [G loss: 1.035763]\n",
      "epoch:1 step:1022[D loss: 0.519783, acc: 56.25%, op_acc: 24.22%] [G loss: 1.013094]\n",
      "epoch:1 step:1023[D loss: 0.479159, acc: 62.50%, op_acc: 29.69%] [G loss: 0.908895]\n",
      "epoch:1 step:1024[D loss: 0.475161, acc: 62.50%, op_acc: 28.12%] [G loss: 1.064235]\n",
      "epoch:1 step:1025[D loss: 0.497816, acc: 63.28%, op_acc: 24.22%] [G loss: 1.104429]\n",
      "epoch:1 step:1026[D loss: 0.423103, acc: 70.31%, op_acc: 35.94%] [G loss: 1.056159]\n",
      "epoch:1 step:1027[D loss: 0.482794, acc: 64.06%, op_acc: 26.56%] [G loss: 0.988111]\n",
      "epoch:1 step:1028[D loss: 0.480172, acc: 58.59%, op_acc: 28.91%] [G loss: 1.082959]\n",
      "epoch:1 step:1029[D loss: 0.501237, acc: 61.72%, op_acc: 23.44%] [G loss: 0.947008]\n",
      "epoch:1 step:1030[D loss: 0.477657, acc: 66.41%, op_acc: 26.56%] [G loss: 1.097824]\n",
      "epoch:1 step:1031[D loss: 0.510958, acc: 56.25%, op_acc: 24.22%] [G loss: 0.946442]\n",
      "epoch:1 step:1032[D loss: 0.437568, acc: 69.53%, op_acc: 32.81%] [G loss: 0.929427]\n",
      "epoch:1 step:1033[D loss: 0.433197, acc: 66.41%, op_acc: 32.81%] [G loss: 1.008367]\n",
      "epoch:1 step:1034[D loss: 0.566776, acc: 50.78%, op_acc: 24.22%] [G loss: 0.928028]\n",
      "epoch:1 step:1035[D loss: 0.465136, acc: 60.94%, op_acc: 27.34%] [G loss: 0.966761]\n",
      "epoch:1 step:1036[D loss: 0.529679, acc: 52.34%, op_acc: 22.66%] [G loss: 0.958287]\n",
      "epoch:1 step:1037[D loss: 0.492668, acc: 57.03%, op_acc: 28.91%] [G loss: 1.035293]\n",
      "epoch:1 step:1038[D loss: 0.468476, acc: 60.94%, op_acc: 26.56%] [G loss: 1.052336]\n",
      "epoch:1 step:1039[D loss: 0.448422, acc: 65.62%, op_acc: 31.25%] [G loss: 1.189057]\n",
      "epoch:1 step:1040[D loss: 0.447098, acc: 72.66%, op_acc: 25.78%] [G loss: 1.097185]\n",
      "epoch:1 step:1041[D loss: 0.509174, acc: 55.47%, op_acc: 26.56%] [G loss: 1.040551]\n",
      "epoch:1 step:1042[D loss: 0.466624, acc: 62.50%, op_acc: 33.59%] [G loss: 1.013559]\n",
      "epoch:1 step:1043[D loss: 0.465896, acc: 53.91%, op_acc: 29.69%] [G loss: 1.058414]\n",
      "epoch:1 step:1044[D loss: 0.453333, acc: 60.16%, op_acc: 32.81%] [G loss: 1.147392]\n",
      "epoch:1 step:1045[D loss: 0.483848, acc: 66.41%, op_acc: 27.34%] [G loss: 1.088263]\n",
      "epoch:1 step:1046[D loss: 0.422765, acc: 64.06%, op_acc: 32.03%] [G loss: 1.090983]\n",
      "epoch:1 step:1047[D loss: 0.458232, acc: 66.41%, op_acc: 26.56%] [G loss: 0.941352]\n",
      "epoch:1 step:1048[D loss: 0.448530, acc: 65.62%, op_acc: 28.12%] [G loss: 1.098519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1049[D loss: 0.444101, acc: 62.50%, op_acc: 25.78%] [G loss: 1.050954]\n",
      "epoch:1 step:1050[D loss: 0.473706, acc: 62.50%, op_acc: 26.56%] [G loss: 0.964092]\n",
      "epoch:1 step:1051[D loss: 0.491734, acc: 55.47%, op_acc: 29.69%] [G loss: 0.959306]\n",
      "epoch:1 step:1052[D loss: 0.497483, acc: 59.38%, op_acc: 29.69%] [G loss: 0.984322]\n",
      "epoch:1 step:1053[D loss: 0.464959, acc: 60.94%, op_acc: 32.03%] [G loss: 1.098103]\n",
      "epoch:1 step:1054[D loss: 0.455089, acc: 65.62%, op_acc: 24.22%] [G loss: 0.939102]\n",
      "epoch:1 step:1055[D loss: 0.470672, acc: 65.62%, op_acc: 29.69%] [G loss: 1.016345]\n",
      "epoch:1 step:1056[D loss: 0.477902, acc: 62.50%, op_acc: 26.56%] [G loss: 1.082942]\n",
      "epoch:1 step:1057[D loss: 0.488758, acc: 53.12%, op_acc: 25.00%] [G loss: 0.820569]\n",
      "epoch:1 step:1058[D loss: 0.513107, acc: 57.81%, op_acc: 28.91%] [G loss: 0.990897]\n",
      "epoch:1 step:1059[D loss: 0.470974, acc: 66.41%, op_acc: 23.44%] [G loss: 1.052551]\n",
      "epoch:1 step:1060[D loss: 0.456112, acc: 60.94%, op_acc: 30.47%] [G loss: 0.953582]\n",
      "epoch:1 step:1061[D loss: 0.453028, acc: 60.16%, op_acc: 29.69%] [G loss: 1.053382]\n",
      "epoch:1 step:1062[D loss: 0.484502, acc: 59.38%, op_acc: 29.69%] [G loss: 1.074181]\n",
      "epoch:1 step:1063[D loss: 0.478536, acc: 52.34%, op_acc: 30.47%] [G loss: 1.017990]\n",
      "epoch:1 step:1064[D loss: 0.499146, acc: 56.25%, op_acc: 28.12%] [G loss: 0.878554]\n",
      "epoch:1 step:1065[D loss: 0.480818, acc: 60.94%, op_acc: 27.34%] [G loss: 1.000253]\n",
      "epoch:1 step:1066[D loss: 0.453152, acc: 62.50%, op_acc: 25.00%] [G loss: 1.017178]\n",
      "epoch:1 step:1067[D loss: 0.453495, acc: 63.28%, op_acc: 31.25%] [G loss: 1.009353]\n",
      "epoch:1 step:1068[D loss: 0.510771, acc: 54.69%, op_acc: 28.12%] [G loss: 0.993089]\n",
      "epoch:1 step:1069[D loss: 0.464717, acc: 60.94%, op_acc: 25.00%] [G loss: 1.033947]\n",
      "epoch:1 step:1070[D loss: 0.456349, acc: 65.62%, op_acc: 23.44%] [G loss: 0.955894]\n",
      "epoch:1 step:1071[D loss: 0.540765, acc: 52.34%, op_acc: 21.88%] [G loss: 0.897630]\n",
      "epoch:1 step:1072[D loss: 0.440069, acc: 67.19%, op_acc: 29.69%] [G loss: 0.986300]\n",
      "epoch:1 step:1073[D loss: 0.479736, acc: 62.50%, op_acc: 26.56%] [G loss: 1.033047]\n",
      "epoch:1 step:1074[D loss: 0.475550, acc: 60.94%, op_acc: 35.16%] [G loss: 1.025504]\n",
      "epoch:1 step:1075[D loss: 0.459605, acc: 64.06%, op_acc: 27.34%] [G loss: 1.064586]\n",
      "epoch:1 step:1076[D loss: 0.485568, acc: 53.12%, op_acc: 21.88%] [G loss: 1.010914]\n",
      "epoch:1 step:1077[D loss: 0.455261, acc: 62.50%, op_acc: 32.81%] [G loss: 1.010290]\n",
      "epoch:1 step:1078[D loss: 0.449597, acc: 65.62%, op_acc: 30.47%] [G loss: 1.044141]\n",
      "epoch:1 step:1079[D loss: 0.469255, acc: 64.06%, op_acc: 31.25%] [G loss: 1.047846]\n",
      "epoch:1 step:1080[D loss: 0.446954, acc: 62.50%, op_acc: 30.47%] [G loss: 1.033569]\n",
      "epoch:1 step:1081[D loss: 0.510229, acc: 58.59%, op_acc: 29.69%] [G loss: 0.994143]\n",
      "epoch:1 step:1082[D loss: 0.473551, acc: 58.59%, op_acc: 21.09%] [G loss: 0.874124]\n",
      "epoch:1 step:1083[D loss: 0.448336, acc: 66.41%, op_acc: 32.81%] [G loss: 1.098637]\n",
      "epoch:1 step:1084[D loss: 0.437952, acc: 69.53%, op_acc: 32.03%] [G loss: 0.980736]\n",
      "epoch:1 step:1085[D loss: 0.475426, acc: 59.38%, op_acc: 29.69%] [G loss: 0.918885]\n",
      "epoch:1 step:1086[D loss: 0.490962, acc: 57.81%, op_acc: 25.00%] [G loss: 1.003678]\n",
      "epoch:1 step:1087[D loss: 0.486311, acc: 66.41%, op_acc: 21.88%] [G loss: 1.058283]\n",
      "epoch:1 step:1088[D loss: 0.477812, acc: 58.59%, op_acc: 32.03%] [G loss: 1.079548]\n",
      "epoch:1 step:1089[D loss: 0.471968, acc: 60.94%, op_acc: 32.03%] [G loss: 1.056507]\n",
      "epoch:1 step:1090[D loss: 0.487159, acc: 60.16%, op_acc: 25.78%] [G loss: 1.067597]\n",
      "epoch:1 step:1091[D loss: 0.520160, acc: 51.56%, op_acc: 21.88%] [G loss: 0.904826]\n",
      "epoch:1 step:1092[D loss: 0.502442, acc: 61.72%, op_acc: 27.34%] [G loss: 1.096046]\n",
      "epoch:1 step:1093[D loss: 0.497011, acc: 51.56%, op_acc: 31.25%] [G loss: 1.055808]\n",
      "epoch:1 step:1094[D loss: 0.458325, acc: 66.41%, op_acc: 25.78%] [G loss: 1.024554]\n",
      "epoch:1 step:1095[D loss: 0.499775, acc: 53.12%, op_acc: 28.12%] [G loss: 1.149831]\n",
      "epoch:1 step:1096[D loss: 0.477301, acc: 57.03%, op_acc: 28.12%] [G loss: 0.966247]\n",
      "epoch:1 step:1097[D loss: 0.435659, acc: 65.62%, op_acc: 31.25%] [G loss: 1.191954]\n",
      "epoch:1 step:1098[D loss: 0.462109, acc: 61.72%, op_acc: 31.25%] [G loss: 1.142051]\n",
      "epoch:1 step:1099[D loss: 0.462153, acc: 67.97%, op_acc: 23.44%] [G loss: 1.004713]\n",
      "epoch:1 step:1100[D loss: 0.441090, acc: 67.19%, op_acc: 27.34%] [G loss: 1.089092]\n",
      "epoch:1 step:1101[D loss: 0.492108, acc: 59.38%, op_acc: 26.56%] [G loss: 1.080000]\n",
      "epoch:1 step:1102[D loss: 0.544794, acc: 49.22%, op_acc: 22.66%] [G loss: 0.836829]\n",
      "epoch:1 step:1103[D loss: 0.519547, acc: 57.03%, op_acc: 25.00%] [G loss: 0.916888]\n",
      "epoch:1 step:1104[D loss: 0.483112, acc: 60.16%, op_acc: 30.47%] [G loss: 0.922132]\n",
      "epoch:1 step:1105[D loss: 0.498127, acc: 58.59%, op_acc: 25.00%] [G loss: 0.955957]\n",
      "epoch:1 step:1106[D loss: 0.493854, acc: 56.25%, op_acc: 32.81%] [G loss: 0.992691]\n",
      "epoch:1 step:1107[D loss: 0.467509, acc: 62.50%, op_acc: 32.03%] [G loss: 1.091035]\n",
      "epoch:1 step:1108[D loss: 0.470709, acc: 62.50%, op_acc: 27.34%] [G loss: 1.061374]\n",
      "epoch:1 step:1109[D loss: 0.502960, acc: 55.47%, op_acc: 29.69%] [G loss: 1.055480]\n",
      "epoch:1 step:1110[D loss: 0.462941, acc: 60.94%, op_acc: 28.91%] [G loss: 1.017395]\n",
      "epoch:1 step:1111[D loss: 0.495670, acc: 57.03%, op_acc: 25.78%] [G loss: 0.948108]\n",
      "epoch:1 step:1112[D loss: 0.441113, acc: 61.72%, op_acc: 25.00%] [G loss: 1.089180]\n",
      "epoch:1 step:1113[D loss: 0.470837, acc: 67.19%, op_acc: 26.56%] [G loss: 1.092326]\n",
      "epoch:1 step:1114[D loss: 0.449209, acc: 70.31%, op_acc: 29.69%] [G loss: 1.076147]\n",
      "epoch:1 step:1115[D loss: 0.458908, acc: 63.28%, op_acc: 32.03%] [G loss: 1.009798]\n",
      "epoch:1 step:1116[D loss: 0.458922, acc: 60.16%, op_acc: 30.47%] [G loss: 1.031387]\n",
      "epoch:1 step:1117[D loss: 0.486561, acc: 60.16%, op_acc: 25.78%] [G loss: 0.955016]\n",
      "epoch:1 step:1118[D loss: 0.476215, acc: 59.38%, op_acc: 28.12%] [G loss: 1.088083]\n",
      "epoch:1 step:1119[D loss: 0.492713, acc: 57.03%, op_acc: 33.59%] [G loss: 1.015503]\n",
      "epoch:1 step:1120[D loss: 0.433010, acc: 66.41%, op_acc: 23.44%] [G loss: 1.067887]\n",
      "epoch:1 step:1121[D loss: 0.454615, acc: 69.53%, op_acc: 28.12%] [G loss: 1.078558]\n",
      "epoch:1 step:1122[D loss: 0.460481, acc: 65.62%, op_acc: 27.34%] [G loss: 1.109744]\n",
      "epoch:1 step:1123[D loss: 0.478752, acc: 50.78%, op_acc: 35.16%] [G loss: 1.116644]\n",
      "epoch:1 step:1124[D loss: 0.480131, acc: 57.03%, op_acc: 26.56%] [G loss: 1.099568]\n",
      "epoch:1 step:1125[D loss: 0.488163, acc: 62.50%, op_acc: 32.03%] [G loss: 1.067618]\n",
      "epoch:1 step:1126[D loss: 0.466880, acc: 63.28%, op_acc: 28.91%] [G loss: 0.958128]\n",
      "epoch:1 step:1127[D loss: 0.443945, acc: 65.62%, op_acc: 31.25%] [G loss: 1.139044]\n",
      "epoch:1 step:1128[D loss: 0.498423, acc: 58.59%, op_acc: 28.12%] [G loss: 0.964685]\n",
      "epoch:1 step:1129[D loss: 0.494423, acc: 57.03%, op_acc: 24.22%] [G loss: 1.074438]\n",
      "epoch:1 step:1130[D loss: 0.460069, acc: 57.03%, op_acc: 33.59%] [G loss: 0.960560]\n",
      "epoch:1 step:1131[D loss: 0.498449, acc: 60.16%, op_acc: 28.12%] [G loss: 0.984033]\n",
      "epoch:1 step:1132[D loss: 0.487839, acc: 56.25%, op_acc: 27.34%] [G loss: 1.057591]\n",
      "epoch:1 step:1133[D loss: 0.434406, acc: 64.06%, op_acc: 32.81%] [G loss: 1.040975]\n",
      "epoch:1 step:1134[D loss: 0.463236, acc: 58.59%, op_acc: 27.34%] [G loss: 0.941193]\n",
      "epoch:1 step:1135[D loss: 0.463031, acc: 63.28%, op_acc: 31.25%] [G loss: 1.135296]\n",
      "epoch:1 step:1136[D loss: 0.460191, acc: 56.25%, op_acc: 31.25%] [G loss: 0.943253]\n",
      "epoch:1 step:1137[D loss: 0.482087, acc: 57.81%, op_acc: 25.00%] [G loss: 0.895648]\n",
      "epoch:1 step:1138[D loss: 0.476553, acc: 60.94%, op_acc: 28.12%] [G loss: 1.100336]\n",
      "epoch:1 step:1139[D loss: 0.481311, acc: 64.84%, op_acc: 22.66%] [G loss: 0.958753]\n",
      "epoch:1 step:1140[D loss: 0.470304, acc: 62.50%, op_acc: 26.56%] [G loss: 1.067935]\n",
      "epoch:1 step:1141[D loss: 0.488759, acc: 61.72%, op_acc: 22.66%] [G loss: 1.071417]\n",
      "epoch:1 step:1142[D loss: 0.432579, acc: 69.53%, op_acc: 27.34%] [G loss: 1.090981]\n",
      "epoch:1 step:1143[D loss: 0.446217, acc: 64.06%, op_acc: 29.69%] [G loss: 1.058874]\n",
      "epoch:1 step:1144[D loss: 0.462606, acc: 64.84%, op_acc: 26.56%] [G loss: 1.025628]\n",
      "epoch:1 step:1145[D loss: 0.485219, acc: 56.25%, op_acc: 30.47%] [G loss: 1.105253]\n",
      "epoch:1 step:1146[D loss: 0.414464, acc: 65.62%, op_acc: 40.62%] [G loss: 1.049778]\n",
      "epoch:1 step:1147[D loss: 0.480180, acc: 58.59%, op_acc: 31.25%] [G loss: 1.036380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1148[D loss: 0.500881, acc: 60.94%, op_acc: 21.88%] [G loss: 0.981690]\n",
      "epoch:1 step:1149[D loss: 0.506744, acc: 60.16%, op_acc: 25.78%] [G loss: 0.932387]\n",
      "epoch:1 step:1150[D loss: 0.444331, acc: 66.41%, op_acc: 35.94%] [G loss: 1.021404]\n",
      "epoch:1 step:1151[D loss: 0.445985, acc: 63.28%, op_acc: 28.91%] [G loss: 1.034029]\n",
      "epoch:1 step:1152[D loss: 0.455972, acc: 60.16%, op_acc: 28.12%] [G loss: 0.996768]\n",
      "epoch:1 step:1153[D loss: 0.469489, acc: 61.72%, op_acc: 27.34%] [G loss: 0.960732]\n",
      "epoch:1 step:1154[D loss: 0.457073, acc: 64.06%, op_acc: 33.59%] [G loss: 1.116888]\n",
      "epoch:1 step:1155[D loss: 0.462529, acc: 63.28%, op_acc: 31.25%] [G loss: 1.125329]\n",
      "epoch:1 step:1156[D loss: 0.459205, acc: 65.62%, op_acc: 28.12%] [G loss: 0.968087]\n",
      "epoch:1 step:1157[D loss: 0.470476, acc: 56.25%, op_acc: 28.91%] [G loss: 1.005250]\n",
      "epoch:1 step:1158[D loss: 0.464746, acc: 66.41%, op_acc: 25.00%] [G loss: 1.078522]\n",
      "epoch:1 step:1159[D loss: 0.461304, acc: 56.25%, op_acc: 25.78%] [G loss: 1.015896]\n",
      "epoch:1 step:1160[D loss: 0.448206, acc: 63.28%, op_acc: 28.91%] [G loss: 0.986149]\n",
      "epoch:1 step:1161[D loss: 0.497921, acc: 62.50%, op_acc: 23.44%] [G loss: 1.112727]\n",
      "epoch:1 step:1162[D loss: 0.442682, acc: 65.62%, op_acc: 24.22%] [G loss: 1.247719]\n",
      "epoch:1 step:1163[D loss: 0.431974, acc: 61.72%, op_acc: 32.03%] [G loss: 1.085100]\n",
      "epoch:1 step:1164[D loss: 0.434784, acc: 68.75%, op_acc: 33.59%] [G loss: 0.976513]\n",
      "epoch:1 step:1165[D loss: 0.426710, acc: 67.97%, op_acc: 32.03%] [G loss: 1.077366]\n",
      "epoch:1 step:1166[D loss: 0.447571, acc: 63.28%, op_acc: 30.47%] [G loss: 1.128453]\n",
      "epoch:1 step:1167[D loss: 0.476581, acc: 58.59%, op_acc: 27.34%] [G loss: 0.989135]\n",
      "epoch:1 step:1168[D loss: 0.450041, acc: 64.84%, op_acc: 29.69%] [G loss: 1.151530]\n",
      "epoch:1 step:1169[D loss: 0.462544, acc: 66.41%, op_acc: 28.12%] [G loss: 1.052914]\n",
      "epoch:1 step:1170[D loss: 0.475509, acc: 61.72%, op_acc: 25.78%] [G loss: 0.974052]\n",
      "epoch:1 step:1171[D loss: 0.471369, acc: 58.59%, op_acc: 35.94%] [G loss: 1.052149]\n",
      "epoch:1 step:1172[D loss: 0.461170, acc: 60.16%, op_acc: 28.12%] [G loss: 0.957398]\n",
      "epoch:1 step:1173[D loss: 0.488146, acc: 53.91%, op_acc: 26.56%] [G loss: 1.061129]\n",
      "epoch:1 step:1174[D loss: 0.432517, acc: 71.09%, op_acc: 37.50%] [G loss: 1.153807]\n",
      "epoch:1 step:1175[D loss: 0.466862, acc: 56.25%, op_acc: 31.25%] [G loss: 0.970433]\n",
      "epoch:1 step:1176[D loss: 0.476666, acc: 58.59%, op_acc: 25.00%] [G loss: 0.963990]\n",
      "epoch:1 step:1177[D loss: 0.440606, acc: 62.50%, op_acc: 31.25%] [G loss: 1.058621]\n",
      "epoch:1 step:1178[D loss: 0.505412, acc: 56.25%, op_acc: 26.56%] [G loss: 1.004696]\n",
      "epoch:1 step:1179[D loss: 0.476355, acc: 63.28%, op_acc: 21.09%] [G loss: 1.079554]\n",
      "epoch:1 step:1180[D loss: 0.499510, acc: 54.69%, op_acc: 27.34%] [G loss: 1.100270]\n",
      "epoch:1 step:1181[D loss: 0.443975, acc: 63.28%, op_acc: 31.25%] [G loss: 1.093748]\n",
      "epoch:1 step:1182[D loss: 0.510674, acc: 55.47%, op_acc: 26.56%] [G loss: 1.015824]\n",
      "epoch:1 step:1183[D loss: 0.524720, acc: 53.12%, op_acc: 25.78%] [G loss: 0.976835]\n",
      "epoch:1 step:1184[D loss: 0.431703, acc: 70.31%, op_acc: 24.22%] [G loss: 1.044720]\n",
      "epoch:1 step:1185[D loss: 0.477472, acc: 60.16%, op_acc: 30.47%] [G loss: 1.027929]\n",
      "epoch:1 step:1186[D loss: 0.503227, acc: 59.38%, op_acc: 26.56%] [G loss: 0.977619]\n",
      "epoch:1 step:1187[D loss: 0.443791, acc: 67.97%, op_acc: 29.69%] [G loss: 1.007777]\n",
      "epoch:1 step:1188[D loss: 0.467804, acc: 60.94%, op_acc: 25.78%] [G loss: 1.041736]\n",
      "epoch:1 step:1189[D loss: 0.444271, acc: 61.72%, op_acc: 37.50%] [G loss: 1.197815]\n",
      "epoch:1 step:1190[D loss: 0.466596, acc: 63.28%, op_acc: 25.78%] [G loss: 1.098111]\n",
      "epoch:1 step:1191[D loss: 0.419318, acc: 67.97%, op_acc: 31.25%] [G loss: 0.938468]\n",
      "epoch:1 step:1192[D loss: 0.497539, acc: 57.03%, op_acc: 26.56%] [G loss: 0.930560]\n",
      "epoch:1 step:1193[D loss: 0.476101, acc: 60.16%, op_acc: 30.47%] [G loss: 0.915810]\n",
      "epoch:1 step:1194[D loss: 0.484527, acc: 60.16%, op_acc: 28.91%] [G loss: 1.012479]\n",
      "epoch:1 step:1195[D loss: 0.480770, acc: 56.25%, op_acc: 25.78%] [G loss: 1.054641]\n",
      "epoch:1 step:1196[D loss: 0.448225, acc: 64.06%, op_acc: 31.25%] [G loss: 0.992082]\n",
      "epoch:1 step:1197[D loss: 0.432002, acc: 67.19%, op_acc: 32.03%] [G loss: 1.059662]\n",
      "epoch:1 step:1198[D loss: 0.458256, acc: 60.94%, op_acc: 25.78%] [G loss: 1.032754]\n",
      "epoch:1 step:1199[D loss: 0.466484, acc: 58.59%, op_acc: 30.47%] [G loss: 0.959569]\n",
      "epoch:1 step:1200[D loss: 0.490524, acc: 57.81%, op_acc: 27.34%] [G loss: 1.065173]\n",
      "epoch:1 step:1201[D loss: 0.489540, acc: 67.97%, op_acc: 25.78%] [G loss: 1.009452]\n",
      "epoch:1 step:1202[D loss: 0.517327, acc: 61.72%, op_acc: 22.66%] [G loss: 1.023715]\n",
      "epoch:1 step:1203[D loss: 0.488914, acc: 64.06%, op_acc: 28.91%] [G loss: 0.968925]\n",
      "epoch:1 step:1204[D loss: 0.500262, acc: 60.16%, op_acc: 19.53%] [G loss: 1.113781]\n",
      "epoch:1 step:1205[D loss: 0.480244, acc: 60.94%, op_acc: 28.91%] [G loss: 1.010178]\n",
      "epoch:1 step:1206[D loss: 0.452937, acc: 59.38%, op_acc: 28.12%] [G loss: 1.107264]\n",
      "epoch:1 step:1207[D loss: 0.451472, acc: 64.84%, op_acc: 28.12%] [G loss: 1.071736]\n",
      "epoch:1 step:1208[D loss: 0.478766, acc: 60.94%, op_acc: 20.31%] [G loss: 1.082114]\n",
      "epoch:1 step:1209[D loss: 0.501559, acc: 53.91%, op_acc: 30.47%] [G loss: 0.932957]\n",
      "epoch:1 step:1210[D loss: 0.459636, acc: 63.28%, op_acc: 31.25%] [G loss: 1.071399]\n",
      "epoch:1 step:1211[D loss: 0.492121, acc: 54.69%, op_acc: 28.12%] [G loss: 0.946381]\n",
      "epoch:1 step:1212[D loss: 0.453572, acc: 67.19%, op_acc: 26.56%] [G loss: 1.009506]\n",
      "epoch:1 step:1213[D loss: 0.461137, acc: 65.62%, op_acc: 32.81%] [G loss: 0.999344]\n",
      "epoch:1 step:1214[D loss: 0.466454, acc: 62.50%, op_acc: 28.12%] [G loss: 1.043041]\n",
      "epoch:1 step:1215[D loss: 0.510374, acc: 48.44%, op_acc: 28.91%] [G loss: 0.988757]\n",
      "epoch:1 step:1216[D loss: 0.447024, acc: 64.84%, op_acc: 30.47%] [G loss: 1.053596]\n",
      "epoch:1 step:1217[D loss: 0.470878, acc: 60.16%, op_acc: 25.00%] [G loss: 0.987806]\n",
      "epoch:1 step:1218[D loss: 0.444582, acc: 68.75%, op_acc: 25.00%] [G loss: 1.062303]\n",
      "epoch:1 step:1219[D loss: 0.472297, acc: 65.62%, op_acc: 22.66%] [G loss: 1.052507]\n",
      "epoch:1 step:1220[D loss: 0.502135, acc: 52.34%, op_acc: 25.00%] [G loss: 1.071982]\n",
      "epoch:1 step:1221[D loss: 0.495107, acc: 62.50%, op_acc: 25.00%] [G loss: 1.118628]\n",
      "epoch:1 step:1222[D loss: 0.512321, acc: 57.03%, op_acc: 23.44%] [G loss: 1.030571]\n",
      "epoch:1 step:1223[D loss: 0.426132, acc: 66.41%, op_acc: 30.47%] [G loss: 1.158363]\n",
      "epoch:1 step:1224[D loss: 0.463867, acc: 66.41%, op_acc: 24.22%] [G loss: 1.025001]\n",
      "epoch:1 step:1225[D loss: 0.466362, acc: 56.25%, op_acc: 32.03%] [G loss: 0.991970]\n",
      "epoch:1 step:1226[D loss: 0.472177, acc: 61.72%, op_acc: 25.78%] [G loss: 0.885461]\n",
      "epoch:1 step:1227[D loss: 0.505857, acc: 57.81%, op_acc: 20.31%] [G loss: 1.086256]\n",
      "epoch:1 step:1228[D loss: 0.497066, acc: 56.25%, op_acc: 22.66%] [G loss: 1.043393]\n",
      "epoch:1 step:1229[D loss: 0.494141, acc: 53.91%, op_acc: 30.47%] [G loss: 0.994213]\n",
      "epoch:1 step:1230[D loss: 0.454993, acc: 64.84%, op_acc: 27.34%] [G loss: 1.054739]\n",
      "epoch:1 step:1231[D loss: 0.520376, acc: 52.34%, op_acc: 32.81%] [G loss: 0.914823]\n",
      "epoch:1 step:1232[D loss: 0.434490, acc: 61.72%, op_acc: 37.50%] [G loss: 0.991787]\n",
      "epoch:1 step:1233[D loss: 0.458819, acc: 60.16%, op_acc: 25.00%] [G loss: 0.969260]\n",
      "epoch:1 step:1234[D loss: 0.474039, acc: 63.28%, op_acc: 31.25%] [G loss: 1.066652]\n",
      "epoch:1 step:1235[D loss: 0.470981, acc: 61.72%, op_acc: 25.00%] [G loss: 1.129065]\n",
      "epoch:1 step:1236[D loss: 0.489648, acc: 59.38%, op_acc: 26.56%] [G loss: 1.070070]\n",
      "epoch:1 step:1237[D loss: 0.452926, acc: 66.41%, op_acc: 28.12%] [G loss: 1.065544]\n",
      "epoch:1 step:1238[D loss: 0.482170, acc: 59.38%, op_acc: 28.12%] [G loss: 1.042815]\n",
      "epoch:1 step:1239[D loss: 0.503445, acc: 54.69%, op_acc: 25.00%] [G loss: 1.019761]\n",
      "epoch:1 step:1240[D loss: 0.480875, acc: 53.91%, op_acc: 26.56%] [G loss: 1.014791]\n",
      "epoch:1 step:1241[D loss: 0.438447, acc: 67.19%, op_acc: 25.78%] [G loss: 1.042990]\n",
      "epoch:1 step:1242[D loss: 0.448508, acc: 67.19%, op_acc: 28.12%] [G loss: 0.957674]\n",
      "epoch:1 step:1243[D loss: 0.485009, acc: 52.34%, op_acc: 25.00%] [G loss: 1.100294]\n",
      "epoch:1 step:1244[D loss: 0.454032, acc: 60.16%, op_acc: 31.25%] [G loss: 0.909352]\n",
      "epoch:1 step:1245[D loss: 0.488633, acc: 60.16%, op_acc: 25.00%] [G loss: 1.150583]\n",
      "epoch:1 step:1246[D loss: 0.471410, acc: 60.16%, op_acc: 22.66%] [G loss: 1.025343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1247[D loss: 0.452148, acc: 63.28%, op_acc: 27.34%] [G loss: 1.069741]\n",
      "epoch:1 step:1248[D loss: 0.472544, acc: 67.19%, op_acc: 25.00%] [G loss: 1.072810]\n",
      "epoch:1 step:1249[D loss: 0.435838, acc: 67.19%, op_acc: 31.25%] [G loss: 1.008821]\n",
      "epoch:1 step:1250[D loss: 0.463452, acc: 60.16%, op_acc: 33.59%] [G loss: 0.974285]\n",
      "epoch:1 step:1251[D loss: 0.451477, acc: 64.06%, op_acc: 28.91%] [G loss: 0.974795]\n",
      "epoch:1 step:1252[D loss: 0.466475, acc: 55.47%, op_acc: 30.47%] [G loss: 0.964403]\n",
      "epoch:1 step:1253[D loss: 0.520484, acc: 53.91%, op_acc: 20.31%] [G loss: 1.017828]\n",
      "epoch:1 step:1254[D loss: 0.471667, acc: 61.72%, op_acc: 26.56%] [G loss: 0.971380]\n",
      "epoch:1 step:1255[D loss: 0.459226, acc: 66.41%, op_acc: 21.88%] [G loss: 0.985074]\n",
      "epoch:1 step:1256[D loss: 0.484321, acc: 57.03%, op_acc: 28.91%] [G loss: 1.080214]\n",
      "epoch:1 step:1257[D loss: 0.488662, acc: 59.38%, op_acc: 23.44%] [G loss: 1.016477]\n",
      "epoch:1 step:1258[D loss: 0.429489, acc: 70.31%, op_acc: 26.56%] [G loss: 1.218936]\n",
      "epoch:1 step:1259[D loss: 0.460977, acc: 61.72%, op_acc: 28.91%] [G loss: 1.061582]\n",
      "epoch:1 step:1260[D loss: 0.482629, acc: 61.72%, op_acc: 24.22%] [G loss: 0.952509]\n",
      "epoch:1 step:1261[D loss: 0.459762, acc: 62.50%, op_acc: 28.12%] [G loss: 1.064362]\n",
      "epoch:1 step:1262[D loss: 0.492488, acc: 53.91%, op_acc: 26.56%] [G loss: 1.017529]\n",
      "epoch:1 step:1263[D loss: 0.471453, acc: 60.94%, op_acc: 30.47%] [G loss: 1.135638]\n",
      "epoch:1 step:1264[D loss: 0.494231, acc: 53.91%, op_acc: 28.91%] [G loss: 1.071427]\n",
      "epoch:1 step:1265[D loss: 0.464608, acc: 58.59%, op_acc: 35.94%] [G loss: 1.033373]\n",
      "epoch:1 step:1266[D loss: 0.470812, acc: 62.50%, op_acc: 30.47%] [G loss: 1.088995]\n",
      "epoch:1 step:1267[D loss: 0.476158, acc: 55.47%, op_acc: 28.91%] [G loss: 0.908447]\n",
      "epoch:1 step:1268[D loss: 0.496221, acc: 51.56%, op_acc: 32.81%] [G loss: 1.083194]\n",
      "epoch:1 step:1269[D loss: 0.470024, acc: 58.59%, op_acc: 33.59%] [G loss: 0.986846]\n",
      "epoch:1 step:1270[D loss: 0.452443, acc: 64.84%, op_acc: 28.12%] [G loss: 0.963202]\n",
      "epoch:1 step:1271[D loss: 0.447407, acc: 61.72%, op_acc: 38.28%] [G loss: 1.057477]\n",
      "epoch:1 step:1272[D loss: 0.462364, acc: 69.53%, op_acc: 34.38%] [G loss: 1.027391]\n",
      "epoch:1 step:1273[D loss: 0.490662, acc: 53.91%, op_acc: 27.34%] [G loss: 0.966616]\n",
      "epoch:1 step:1274[D loss: 0.465289, acc: 65.62%, op_acc: 20.31%] [G loss: 1.072652]\n",
      "epoch:1 step:1275[D loss: 0.445974, acc: 60.16%, op_acc: 32.81%] [G loss: 1.067139]\n",
      "epoch:1 step:1276[D loss: 0.466220, acc: 58.59%, op_acc: 32.81%] [G loss: 1.166152]\n",
      "epoch:1 step:1277[D loss: 0.472216, acc: 59.38%, op_acc: 28.12%] [G loss: 0.998148]\n",
      "epoch:1 step:1278[D loss: 0.500994, acc: 53.12%, op_acc: 28.12%] [G loss: 1.107441]\n",
      "epoch:1 step:1279[D loss: 0.493415, acc: 59.38%, op_acc: 27.34%] [G loss: 1.048976]\n",
      "epoch:1 step:1280[D loss: 0.502749, acc: 59.38%, op_acc: 25.00%] [G loss: 1.064631]\n",
      "epoch:1 step:1281[D loss: 0.470567, acc: 60.94%, op_acc: 30.47%] [G loss: 1.029738]\n",
      "epoch:1 step:1282[D loss: 0.459966, acc: 68.75%, op_acc: 28.91%] [G loss: 1.156454]\n",
      "epoch:1 step:1283[D loss: 0.481613, acc: 57.03%, op_acc: 28.12%] [G loss: 1.227356]\n",
      "epoch:1 step:1284[D loss: 0.401757, acc: 71.88%, op_acc: 31.25%] [G loss: 1.144679]\n",
      "epoch:1 step:1285[D loss: 0.491657, acc: 64.84%, op_acc: 25.78%] [G loss: 1.034175]\n",
      "epoch:1 step:1286[D loss: 0.446823, acc: 68.75%, op_acc: 32.81%] [G loss: 1.040591]\n",
      "epoch:1 step:1287[D loss: 0.499543, acc: 60.94%, op_acc: 30.47%] [G loss: 1.025714]\n",
      "epoch:1 step:1288[D loss: 0.487032, acc: 60.94%, op_acc: 33.59%] [G loss: 1.075548]\n",
      "epoch:1 step:1289[D loss: 0.449975, acc: 64.84%, op_acc: 29.69%] [G loss: 1.064489]\n",
      "epoch:1 step:1290[D loss: 0.449763, acc: 68.75%, op_acc: 23.44%] [G loss: 1.201315]\n",
      "epoch:1 step:1291[D loss: 0.417220, acc: 69.53%, op_acc: 28.91%] [G loss: 1.048913]\n",
      "epoch:1 step:1292[D loss: 0.530221, acc: 53.91%, op_acc: 19.53%] [G loss: 0.879538]\n",
      "epoch:1 step:1293[D loss: 0.480256, acc: 63.28%, op_acc: 23.44%] [G loss: 0.948348]\n",
      "epoch:1 step:1294[D loss: 0.468221, acc: 63.28%, op_acc: 27.34%] [G loss: 1.115617]\n",
      "epoch:1 step:1295[D loss: 0.485135, acc: 55.47%, op_acc: 29.69%] [G loss: 1.044807]\n",
      "epoch:1 step:1296[D loss: 0.492254, acc: 60.94%, op_acc: 23.44%] [G loss: 0.935325]\n",
      "epoch:1 step:1297[D loss: 0.472425, acc: 57.03%, op_acc: 33.59%] [G loss: 0.990732]\n",
      "epoch:1 step:1298[D loss: 0.502596, acc: 51.56%, op_acc: 25.78%] [G loss: 0.883434]\n",
      "epoch:1 step:1299[D loss: 0.431979, acc: 67.97%, op_acc: 33.59%] [G loss: 0.959514]\n",
      "epoch:1 step:1300[D loss: 0.458017, acc: 63.28%, op_acc: 32.81%] [G loss: 1.032304]\n",
      "epoch:1 step:1301[D loss: 0.470833, acc: 60.94%, op_acc: 31.25%] [G loss: 0.986328]\n",
      "epoch:1 step:1302[D loss: 0.455789, acc: 67.97%, op_acc: 25.78%] [G loss: 0.970875]\n",
      "epoch:1 step:1303[D loss: 0.436814, acc: 66.41%, op_acc: 32.81%] [G loss: 1.136949]\n",
      "epoch:1 step:1304[D loss: 0.483732, acc: 63.28%, op_acc: 25.00%] [G loss: 0.943140]\n",
      "epoch:1 step:1305[D loss: 0.459810, acc: 67.19%, op_acc: 26.56%] [G loss: 1.068155]\n",
      "epoch:1 step:1306[D loss: 0.441523, acc: 61.72%, op_acc: 28.91%] [G loss: 1.114069]\n",
      "epoch:1 step:1307[D loss: 0.536504, acc: 57.03%, op_acc: 22.66%] [G loss: 0.900113]\n",
      "epoch:1 step:1308[D loss: 0.471666, acc: 61.72%, op_acc: 32.03%] [G loss: 0.951834]\n",
      "epoch:1 step:1309[D loss: 0.526225, acc: 42.97%, op_acc: 28.91%] [G loss: 0.974823]\n",
      "epoch:1 step:1310[D loss: 0.441272, acc: 66.41%, op_acc: 29.69%] [G loss: 1.050312]\n",
      "epoch:1 step:1311[D loss: 0.485408, acc: 54.69%, op_acc: 25.00%] [G loss: 0.933380]\n",
      "epoch:1 step:1312[D loss: 0.500421, acc: 55.47%, op_acc: 29.69%] [G loss: 0.961057]\n",
      "epoch:1 step:1313[D loss: 0.470694, acc: 65.62%, op_acc: 27.34%] [G loss: 1.061505]\n",
      "epoch:1 step:1314[D loss: 0.460244, acc: 54.69%, op_acc: 30.47%] [G loss: 1.016238]\n",
      "epoch:1 step:1315[D loss: 0.440417, acc: 67.19%, op_acc: 25.00%] [G loss: 1.157897]\n",
      "epoch:1 step:1316[D loss: 0.505070, acc: 56.25%, op_acc: 25.00%] [G loss: 1.063574]\n",
      "epoch:1 step:1317[D loss: 0.452545, acc: 63.28%, op_acc: 35.16%] [G loss: 0.872949]\n",
      "epoch:1 step:1318[D loss: 0.485247, acc: 57.03%, op_acc: 24.22%] [G loss: 1.030234]\n",
      "epoch:1 step:1319[D loss: 0.548230, acc: 51.56%, op_acc: 26.56%] [G loss: 0.987580]\n",
      "epoch:1 step:1320[D loss: 0.514543, acc: 53.91%, op_acc: 22.66%] [G loss: 0.963568]\n",
      "epoch:1 step:1321[D loss: 0.508251, acc: 54.69%, op_acc: 27.34%] [G loss: 0.915797]\n",
      "epoch:1 step:1322[D loss: 0.417163, acc: 71.88%, op_acc: 28.91%] [G loss: 1.124324]\n",
      "epoch:1 step:1323[D loss: 0.464599, acc: 64.84%, op_acc: 21.88%] [G loss: 0.948561]\n",
      "epoch:1 step:1324[D loss: 0.482721, acc: 51.56%, op_acc: 25.00%] [G loss: 1.025103]\n",
      "epoch:1 step:1325[D loss: 0.489046, acc: 57.81%, op_acc: 25.00%] [G loss: 0.973652]\n",
      "epoch:1 step:1326[D loss: 0.475857, acc: 60.94%, op_acc: 27.34%] [G loss: 1.038235]\n",
      "epoch:1 step:1327[D loss: 0.472723, acc: 56.25%, op_acc: 28.91%] [G loss: 0.957386]\n",
      "epoch:1 step:1328[D loss: 0.489942, acc: 57.03%, op_acc: 26.56%] [G loss: 1.067930]\n",
      "epoch:1 step:1329[D loss: 0.464436, acc: 63.28%, op_acc: 30.47%] [G loss: 1.106338]\n",
      "epoch:1 step:1330[D loss: 0.480438, acc: 59.38%, op_acc: 26.56%] [G loss: 1.089921]\n",
      "epoch:1 step:1331[D loss: 0.490354, acc: 57.03%, op_acc: 30.47%] [G loss: 0.874621]\n",
      "epoch:1 step:1332[D loss: 0.464541, acc: 62.50%, op_acc: 26.56%] [G loss: 1.098116]\n",
      "epoch:1 step:1333[D loss: 0.477214, acc: 64.06%, op_acc: 28.91%] [G loss: 1.063782]\n",
      "epoch:1 step:1334[D loss: 0.457332, acc: 59.38%, op_acc: 28.12%] [G loss: 1.000478]\n",
      "epoch:1 step:1335[D loss: 0.491941, acc: 52.34%, op_acc: 23.44%] [G loss: 1.011024]\n",
      "epoch:1 step:1336[D loss: 0.443706, acc: 59.38%, op_acc: 35.94%] [G loss: 1.058303]\n",
      "epoch:1 step:1337[D loss: 0.468220, acc: 60.16%, op_acc: 27.34%] [G loss: 1.039882]\n",
      "epoch:1 step:1338[D loss: 0.480222, acc: 65.62%, op_acc: 23.44%] [G loss: 1.100090]\n",
      "epoch:1 step:1339[D loss: 0.465308, acc: 69.53%, op_acc: 28.12%] [G loss: 1.034865]\n",
      "epoch:1 step:1340[D loss: 0.478558, acc: 58.59%, op_acc: 28.91%] [G loss: 1.024032]\n",
      "epoch:1 step:1341[D loss: 0.491771, acc: 56.25%, op_acc: 26.56%] [G loss: 0.905998]\n",
      "epoch:1 step:1342[D loss: 0.468717, acc: 57.81%, op_acc: 28.91%] [G loss: 0.989481]\n",
      "epoch:1 step:1343[D loss: 0.490508, acc: 53.91%, op_acc: 25.78%] [G loss: 0.979878]\n",
      "epoch:1 step:1344[D loss: 0.463901, acc: 67.97%, op_acc: 29.69%] [G loss: 0.947690]\n",
      "epoch:1 step:1345[D loss: 0.458704, acc: 58.59%, op_acc: 28.91%] [G loss: 1.066778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1346[D loss: 0.486570, acc: 58.59%, op_acc: 30.47%] [G loss: 0.965396]\n",
      "epoch:1 step:1347[D loss: 0.494508, acc: 57.03%, op_acc: 26.56%] [G loss: 0.901528]\n",
      "epoch:1 step:1348[D loss: 0.469304, acc: 60.94%, op_acc: 33.59%] [G loss: 0.930234]\n",
      "epoch:1 step:1349[D loss: 0.462382, acc: 60.94%, op_acc: 25.78%] [G loss: 0.990282]\n",
      "epoch:1 step:1350[D loss: 0.473334, acc: 60.16%, op_acc: 31.25%] [G loss: 1.014892]\n",
      "epoch:1 step:1351[D loss: 0.473173, acc: 61.72%, op_acc: 27.34%] [G loss: 1.096618]\n",
      "epoch:1 step:1352[D loss: 0.444468, acc: 58.59%, op_acc: 31.25%] [G loss: 0.994157]\n",
      "epoch:1 step:1353[D loss: 0.452624, acc: 61.72%, op_acc: 31.25%] [G loss: 1.033498]\n",
      "epoch:1 step:1354[D loss: 0.467860, acc: 59.38%, op_acc: 35.94%] [G loss: 0.978889]\n",
      "epoch:1 step:1355[D loss: 0.477982, acc: 63.28%, op_acc: 28.91%] [G loss: 1.149917]\n",
      "epoch:1 step:1356[D loss: 0.459399, acc: 62.50%, op_acc: 30.47%] [G loss: 1.076619]\n",
      "epoch:1 step:1357[D loss: 0.450311, acc: 65.62%, op_acc: 32.81%] [G loss: 0.991163]\n",
      "epoch:1 step:1358[D loss: 0.506820, acc: 52.34%, op_acc: 25.78%] [G loss: 0.897766]\n",
      "epoch:1 step:1359[D loss: 0.466363, acc: 71.09%, op_acc: 25.78%] [G loss: 1.016093]\n",
      "epoch:1 step:1360[D loss: 0.451604, acc: 64.06%, op_acc: 28.12%] [G loss: 0.963092]\n",
      "epoch:1 step:1361[D loss: 0.508137, acc: 44.53%, op_acc: 25.00%] [G loss: 0.977906]\n",
      "epoch:1 step:1362[D loss: 0.485930, acc: 55.47%, op_acc: 22.66%] [G loss: 0.961077]\n",
      "epoch:1 step:1363[D loss: 0.483165, acc: 56.25%, op_acc: 29.69%] [G loss: 1.031263]\n",
      "epoch:1 step:1364[D loss: 0.472933, acc: 60.16%, op_acc: 28.91%] [G loss: 1.051065]\n",
      "epoch:1 step:1365[D loss: 0.469041, acc: 67.97%, op_acc: 27.34%] [G loss: 0.996280]\n",
      "epoch:1 step:1366[D loss: 0.494381, acc: 52.34%, op_acc: 28.91%] [G loss: 1.006646]\n",
      "epoch:1 step:1367[D loss: 0.438172, acc: 72.66%, op_acc: 21.88%] [G loss: 1.093298]\n",
      "epoch:1 step:1368[D loss: 0.458940, acc: 63.28%, op_acc: 26.56%] [G loss: 1.060749]\n",
      "epoch:1 step:1369[D loss: 0.476646, acc: 56.25%, op_acc: 30.47%] [G loss: 1.019485]\n",
      "epoch:1 step:1370[D loss: 0.423232, acc: 68.75%, op_acc: 28.91%] [G loss: 1.086699]\n",
      "epoch:1 step:1371[D loss: 0.460919, acc: 69.53%, op_acc: 25.00%] [G loss: 1.151037]\n",
      "epoch:1 step:1372[D loss: 0.483227, acc: 57.81%, op_acc: 30.47%] [G loss: 0.997087]\n",
      "epoch:1 step:1373[D loss: 0.477324, acc: 57.03%, op_acc: 28.12%] [G loss: 0.864340]\n",
      "epoch:1 step:1374[D loss: 0.532245, acc: 50.00%, op_acc: 25.78%] [G loss: 1.045617]\n",
      "epoch:1 step:1375[D loss: 0.503429, acc: 53.12%, op_acc: 25.78%] [G loss: 1.000699]\n",
      "epoch:1 step:1376[D loss: 0.486596, acc: 60.16%, op_acc: 26.56%] [G loss: 1.015219]\n",
      "epoch:1 step:1377[D loss: 0.481909, acc: 60.94%, op_acc: 28.12%] [G loss: 1.029187]\n",
      "epoch:1 step:1378[D loss: 0.453725, acc: 62.50%, op_acc: 28.12%] [G loss: 1.157322]\n",
      "epoch:1 step:1379[D loss: 0.493169, acc: 53.91%, op_acc: 30.47%] [G loss: 1.015070]\n",
      "epoch:1 step:1380[D loss: 0.483865, acc: 59.38%, op_acc: 28.12%] [G loss: 1.096998]\n",
      "epoch:1 step:1381[D loss: 0.480690, acc: 64.06%, op_acc: 25.78%] [G loss: 0.896160]\n",
      "epoch:1 step:1382[D loss: 0.456520, acc: 65.62%, op_acc: 28.12%] [G loss: 1.017404]\n",
      "epoch:1 step:1383[D loss: 0.468758, acc: 60.16%, op_acc: 28.12%] [G loss: 1.027779]\n",
      "epoch:1 step:1384[D loss: 0.441381, acc: 59.38%, op_acc: 36.72%] [G loss: 0.894557]\n",
      "epoch:1 step:1385[D loss: 0.515121, acc: 52.34%, op_acc: 25.78%] [G loss: 0.974858]\n",
      "epoch:1 step:1386[D loss: 0.469562, acc: 63.28%, op_acc: 27.34%] [G loss: 1.082529]\n",
      "epoch:1 step:1387[D loss: 0.456986, acc: 61.72%, op_acc: 32.81%] [G loss: 1.122579]\n",
      "epoch:1 step:1388[D loss: 0.459617, acc: 58.59%, op_acc: 35.16%] [G loss: 0.967811]\n",
      "epoch:1 step:1389[D loss: 0.445582, acc: 59.38%, op_acc: 28.91%] [G loss: 0.897758]\n",
      "epoch:1 step:1390[D loss: 0.510014, acc: 51.56%, op_acc: 25.78%] [G loss: 0.920254]\n",
      "epoch:1 step:1391[D loss: 0.458430, acc: 61.72%, op_acc: 25.00%] [G loss: 1.099660]\n",
      "epoch:1 step:1392[D loss: 0.462520, acc: 69.53%, op_acc: 25.78%] [G loss: 1.062252]\n",
      "epoch:1 step:1393[D loss: 0.465416, acc: 67.97%, op_acc: 28.91%] [G loss: 1.113659]\n",
      "epoch:1 step:1394[D loss: 0.495786, acc: 57.03%, op_acc: 22.66%] [G loss: 0.978449]\n",
      "epoch:1 step:1395[D loss: 0.422214, acc: 64.84%, op_acc: 28.12%] [G loss: 0.987858]\n",
      "epoch:1 step:1396[D loss: 0.499025, acc: 59.38%, op_acc: 32.03%] [G loss: 1.128003]\n",
      "epoch:1 step:1397[D loss: 0.453298, acc: 67.97%, op_acc: 31.25%] [G loss: 1.006015]\n",
      "epoch:1 step:1398[D loss: 0.485600, acc: 57.03%, op_acc: 28.91%] [G loss: 1.028917]\n",
      "epoch:1 step:1399[D loss: 0.461538, acc: 59.38%, op_acc: 30.47%] [G loss: 1.059059]\n",
      "epoch:1 step:1400[D loss: 0.453763, acc: 63.28%, op_acc: 26.56%] [G loss: 1.121246]\n",
      "epoch:1 step:1401[D loss: 0.471396, acc: 65.62%, op_acc: 27.34%] [G loss: 1.053073]\n",
      "epoch:1 step:1402[D loss: 0.482359, acc: 55.47%, op_acc: 31.25%] [G loss: 1.101861]\n",
      "epoch:1 step:1403[D loss: 0.490250, acc: 57.81%, op_acc: 29.69%] [G loss: 1.140576]\n",
      "epoch:1 step:1404[D loss: 0.470909, acc: 57.03%, op_acc: 28.91%] [G loss: 0.963453]\n",
      "epoch:1 step:1405[D loss: 0.487110, acc: 58.59%, op_acc: 27.34%] [G loss: 0.942426]\n",
      "epoch:1 step:1406[D loss: 0.489590, acc: 58.59%, op_acc: 30.47%] [G loss: 0.938473]\n",
      "epoch:1 step:1407[D loss: 0.519640, acc: 46.88%, op_acc: 27.34%] [G loss: 1.024747]\n",
      "epoch:1 step:1408[D loss: 0.468343, acc: 53.12%, op_acc: 29.69%] [G loss: 0.893045]\n",
      "epoch:1 step:1409[D loss: 0.481023, acc: 56.25%, op_acc: 25.00%] [G loss: 1.128590]\n",
      "epoch:1 step:1410[D loss: 0.511333, acc: 54.69%, op_acc: 25.78%] [G loss: 0.965890]\n",
      "epoch:1 step:1411[D loss: 0.437500, acc: 67.19%, op_acc: 27.34%] [G loss: 1.048265]\n",
      "epoch:1 step:1412[D loss: 0.472074, acc: 61.72%, op_acc: 35.16%] [G loss: 1.044745]\n",
      "epoch:1 step:1413[D loss: 0.472409, acc: 62.50%, op_acc: 24.22%] [G loss: 0.997562]\n",
      "epoch:1 step:1414[D loss: 0.452585, acc: 65.62%, op_acc: 28.12%] [G loss: 0.984287]\n",
      "epoch:1 step:1415[D loss: 0.463523, acc: 57.81%, op_acc: 32.81%] [G loss: 0.918493]\n",
      "epoch:1 step:1416[D loss: 0.479156, acc: 59.38%, op_acc: 27.34%] [G loss: 0.946056]\n",
      "epoch:1 step:1417[D loss: 0.441219, acc: 61.72%, op_acc: 30.47%] [G loss: 1.027027]\n",
      "epoch:1 step:1418[D loss: 0.465750, acc: 64.84%, op_acc: 23.44%] [G loss: 1.220541]\n",
      "epoch:1 step:1419[D loss: 0.451958, acc: 66.41%, op_acc: 28.91%] [G loss: 1.011213]\n",
      "epoch:1 step:1420[D loss: 0.479524, acc: 59.38%, op_acc: 23.44%] [G loss: 1.073463]\n",
      "epoch:1 step:1421[D loss: 0.497255, acc: 55.47%, op_acc: 26.56%] [G loss: 0.994154]\n",
      "epoch:1 step:1422[D loss: 0.505448, acc: 58.59%, op_acc: 26.56%] [G loss: 0.930304]\n",
      "epoch:1 step:1423[D loss: 0.480653, acc: 64.84%, op_acc: 25.78%] [G loss: 0.979375]\n",
      "epoch:1 step:1424[D loss: 0.480550, acc: 62.50%, op_acc: 25.00%] [G loss: 0.974567]\n",
      "epoch:1 step:1425[D loss: 0.428922, acc: 67.19%, op_acc: 31.25%] [G loss: 0.957047]\n",
      "epoch:1 step:1426[D loss: 0.468162, acc: 58.59%, op_acc: 28.91%] [G loss: 0.937594]\n",
      "epoch:1 step:1427[D loss: 0.472531, acc: 60.94%, op_acc: 27.34%] [G loss: 1.069493]\n",
      "epoch:1 step:1428[D loss: 0.476728, acc: 53.91%, op_acc: 25.00%] [G loss: 0.928449]\n",
      "epoch:1 step:1429[D loss: 0.493069, acc: 55.47%, op_acc: 23.44%] [G loss: 0.924747]\n",
      "epoch:1 step:1430[D loss: 0.473034, acc: 62.50%, op_acc: 30.47%] [G loss: 0.956971]\n",
      "epoch:1 step:1431[D loss: 0.501100, acc: 60.94%, op_acc: 20.31%] [G loss: 1.044191]\n",
      "epoch:1 step:1432[D loss: 0.449433, acc: 70.31%, op_acc: 31.25%] [G loss: 1.126281]\n",
      "epoch:1 step:1433[D loss: 0.444055, acc: 65.62%, op_acc: 29.69%] [G loss: 1.004686]\n",
      "epoch:1 step:1434[D loss: 0.492363, acc: 56.25%, op_acc: 36.72%] [G loss: 1.044523]\n",
      "epoch:1 step:1435[D loss: 0.466238, acc: 59.38%, op_acc: 28.91%] [G loss: 1.019372]\n",
      "epoch:1 step:1436[D loss: 0.473637, acc: 59.38%, op_acc: 30.47%] [G loss: 1.033558]\n",
      "epoch:1 step:1437[D loss: 0.479970, acc: 52.34%, op_acc: 32.81%] [G loss: 1.159219]\n",
      "epoch:1 step:1438[D loss: 0.451820, acc: 67.19%, op_acc: 29.69%] [G loss: 1.205340]\n",
      "epoch:1 step:1439[D loss: 0.489163, acc: 63.28%, op_acc: 27.34%] [G loss: 1.019321]\n",
      "epoch:1 step:1440[D loss: 0.492704, acc: 61.72%, op_acc: 28.91%] [G loss: 0.928657]\n",
      "epoch:1 step:1441[D loss: 0.447937, acc: 58.59%, op_acc: 28.91%] [G loss: 1.054657]\n",
      "epoch:1 step:1442[D loss: 0.475476, acc: 67.97%, op_acc: 30.47%] [G loss: 0.936881]\n",
      "epoch:1 step:1443[D loss: 0.461262, acc: 58.59%, op_acc: 33.59%] [G loss: 1.138620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1444[D loss: 0.452613, acc: 60.94%, op_acc: 30.47%] [G loss: 0.988634]\n",
      "epoch:1 step:1445[D loss: 0.437074, acc: 64.84%, op_acc: 28.12%] [G loss: 0.994502]\n",
      "epoch:1 step:1446[D loss: 0.522273, acc: 54.69%, op_acc: 26.56%] [G loss: 0.930868]\n",
      "epoch:1 step:1447[D loss: 0.506454, acc: 58.59%, op_acc: 28.12%] [G loss: 0.954460]\n",
      "epoch:1 step:1448[D loss: 0.446261, acc: 66.41%, op_acc: 23.44%] [G loss: 1.105558]\n",
      "epoch:1 step:1449[D loss: 0.470118, acc: 59.38%, op_acc: 24.22%] [G loss: 1.031171]\n",
      "epoch:1 step:1450[D loss: 0.484065, acc: 63.28%, op_acc: 28.12%] [G loss: 0.990303]\n",
      "epoch:1 step:1451[D loss: 0.499979, acc: 53.91%, op_acc: 26.56%] [G loss: 0.958882]\n",
      "epoch:1 step:1452[D loss: 0.526139, acc: 51.56%, op_acc: 21.09%] [G loss: 0.967776]\n",
      "epoch:1 step:1453[D loss: 0.432258, acc: 67.19%, op_acc: 31.25%] [G loss: 1.047307]\n",
      "epoch:1 step:1454[D loss: 0.462889, acc: 63.28%, op_acc: 34.38%] [G loss: 0.994216]\n",
      "epoch:1 step:1455[D loss: 0.480401, acc: 59.38%, op_acc: 35.16%] [G loss: 1.033843]\n",
      "epoch:1 step:1456[D loss: 0.436316, acc: 62.50%, op_acc: 31.25%] [G loss: 1.007941]\n",
      "epoch:1 step:1457[D loss: 0.520992, acc: 54.69%, op_acc: 25.78%] [G loss: 0.961068]\n",
      "epoch:1 step:1458[D loss: 0.476882, acc: 62.50%, op_acc: 35.16%] [G loss: 1.097757]\n",
      "epoch:1 step:1459[D loss: 0.458092, acc: 58.59%, op_acc: 28.12%] [G loss: 1.038615]\n",
      "epoch:1 step:1460[D loss: 0.438955, acc: 66.41%, op_acc: 31.25%] [G loss: 1.054127]\n",
      "epoch:1 step:1461[D loss: 0.485904, acc: 56.25%, op_acc: 26.56%] [G loss: 0.886323]\n",
      "epoch:1 step:1462[D loss: 0.506671, acc: 56.25%, op_acc: 23.44%] [G loss: 0.938842]\n",
      "epoch:1 step:1463[D loss: 0.436555, acc: 64.84%, op_acc: 28.12%] [G loss: 0.992975]\n",
      "epoch:1 step:1464[D loss: 0.416317, acc: 67.19%, op_acc: 35.16%] [G loss: 1.059435]\n",
      "epoch:1 step:1465[D loss: 0.469408, acc: 57.03%, op_acc: 31.25%] [G loss: 1.061701]\n",
      "epoch:1 step:1466[D loss: 0.478691, acc: 60.94%, op_acc: 21.09%] [G loss: 1.086859]\n",
      "epoch:1 step:1467[D loss: 0.486720, acc: 58.59%, op_acc: 25.78%] [G loss: 1.023295]\n",
      "epoch:1 step:1468[D loss: 0.431567, acc: 67.19%, op_acc: 34.38%] [G loss: 0.924211]\n",
      "epoch:1 step:1469[D loss: 0.435667, acc: 67.19%, op_acc: 26.56%] [G loss: 0.994057]\n",
      "epoch:1 step:1470[D loss: 0.481530, acc: 56.25%, op_acc: 28.12%] [G loss: 0.952869]\n",
      "epoch:1 step:1471[D loss: 0.444555, acc: 64.06%, op_acc: 31.25%] [G loss: 0.878175]\n",
      "epoch:1 step:1472[D loss: 0.446193, acc: 63.28%, op_acc: 32.03%] [G loss: 0.982307]\n",
      "epoch:1 step:1473[D loss: 0.504069, acc: 61.72%, op_acc: 28.91%] [G loss: 0.938810]\n",
      "epoch:1 step:1474[D loss: 0.498967, acc: 59.38%, op_acc: 18.75%] [G loss: 0.940949]\n",
      "epoch:1 step:1475[D loss: 0.492722, acc: 60.94%, op_acc: 21.88%] [G loss: 1.006063]\n",
      "epoch:1 step:1476[D loss: 0.457997, acc: 64.06%, op_acc: 27.34%] [G loss: 1.128654]\n",
      "epoch:1 step:1477[D loss: 0.484767, acc: 62.50%, op_acc: 23.44%] [G loss: 1.067869]\n",
      "epoch:1 step:1478[D loss: 0.453026, acc: 64.84%, op_acc: 25.78%] [G loss: 1.026860]\n",
      "epoch:1 step:1479[D loss: 0.430855, acc: 72.66%, op_acc: 28.91%] [G loss: 0.949244]\n",
      "epoch:1 step:1480[D loss: 0.448734, acc: 57.03%, op_acc: 38.28%] [G loss: 0.965657]\n",
      "epoch:1 step:1481[D loss: 0.475056, acc: 58.59%, op_acc: 29.69%] [G loss: 0.995987]\n",
      "epoch:1 step:1482[D loss: 0.511774, acc: 57.81%, op_acc: 23.44%] [G loss: 0.981508]\n",
      "epoch:1 step:1483[D loss: 0.461331, acc: 65.62%, op_acc: 28.91%] [G loss: 1.120918]\n",
      "epoch:1 step:1484[D loss: 0.453131, acc: 61.72%, op_acc: 24.22%] [G loss: 0.929899]\n",
      "epoch:1 step:1485[D loss: 0.431886, acc: 67.19%, op_acc: 32.81%] [G loss: 1.165651]\n",
      "epoch:1 step:1486[D loss: 0.482115, acc: 53.91%, op_acc: 27.34%] [G loss: 0.939068]\n",
      "epoch:1 step:1487[D loss: 0.495541, acc: 50.78%, op_acc: 25.78%] [G loss: 1.081856]\n",
      "epoch:1 step:1488[D loss: 0.455344, acc: 65.62%, op_acc: 24.22%] [G loss: 1.029886]\n",
      "epoch:1 step:1489[D loss: 0.496366, acc: 54.69%, op_acc: 26.56%] [G loss: 0.949661]\n",
      "epoch:1 step:1490[D loss: 0.469834, acc: 62.50%, op_acc: 28.91%] [G loss: 1.102030]\n",
      "epoch:1 step:1491[D loss: 0.450566, acc: 62.50%, op_acc: 33.59%] [G loss: 1.023634]\n",
      "epoch:1 step:1492[D loss: 0.462583, acc: 64.06%, op_acc: 25.78%] [G loss: 0.995196]\n",
      "epoch:1 step:1493[D loss: 0.509069, acc: 50.78%, op_acc: 32.81%] [G loss: 0.934387]\n",
      "epoch:1 step:1494[D loss: 0.502743, acc: 51.56%, op_acc: 28.91%] [G loss: 0.852573]\n",
      "epoch:1 step:1495[D loss: 0.490487, acc: 53.91%, op_acc: 24.22%] [G loss: 1.010687]\n",
      "epoch:1 step:1496[D loss: 0.497176, acc: 53.12%, op_acc: 26.56%] [G loss: 1.106966]\n",
      "epoch:1 step:1497[D loss: 0.472116, acc: 56.25%, op_acc: 28.12%] [G loss: 1.056274]\n",
      "epoch:1 step:1498[D loss: 0.406455, acc: 75.00%, op_acc: 31.25%] [G loss: 1.059785]\n",
      "epoch:1 step:1499[D loss: 0.494939, acc: 60.94%, op_acc: 28.12%] [G loss: 1.048110]\n",
      "epoch:1 step:1500[D loss: 0.489500, acc: 47.66%, op_acc: 31.25%] [G loss: 1.005802]\n",
      "epoch:1 step:1501[D loss: 0.417516, acc: 69.53%, op_acc: 33.59%] [G loss: 1.138803]\n",
      "epoch:1 step:1502[D loss: 0.480227, acc: 57.81%, op_acc: 29.69%] [G loss: 1.002244]\n",
      "epoch:1 step:1503[D loss: 0.489498, acc: 54.69%, op_acc: 27.34%] [G loss: 1.018110]\n",
      "epoch:1 step:1504[D loss: 0.488838, acc: 53.91%, op_acc: 24.22%] [G loss: 0.995064]\n",
      "epoch:1 step:1505[D loss: 0.494924, acc: 61.72%, op_acc: 23.44%] [G loss: 1.055226]\n",
      "epoch:1 step:1506[D loss: 0.448219, acc: 66.41%, op_acc: 27.34%] [G loss: 0.995745]\n",
      "epoch:1 step:1507[D loss: 0.428755, acc: 69.53%, op_acc: 31.25%] [G loss: 1.046604]\n",
      "epoch:1 step:1508[D loss: 0.522986, acc: 57.81%, op_acc: 25.00%] [G loss: 0.954897]\n",
      "epoch:1 step:1509[D loss: 0.486560, acc: 63.28%, op_acc: 17.19%] [G loss: 0.912468]\n",
      "epoch:1 step:1510[D loss: 0.442256, acc: 64.06%, op_acc: 31.25%] [G loss: 1.076181]\n",
      "epoch:1 step:1511[D loss: 0.462473, acc: 61.72%, op_acc: 34.38%] [G loss: 1.010574]\n",
      "epoch:1 step:1512[D loss: 0.458353, acc: 62.50%, op_acc: 25.78%] [G loss: 0.933234]\n",
      "epoch:1 step:1513[D loss: 0.450540, acc: 62.50%, op_acc: 25.00%] [G loss: 0.975583]\n",
      "epoch:1 step:1514[D loss: 0.473547, acc: 53.12%, op_acc: 28.12%] [G loss: 1.038998]\n",
      "epoch:1 step:1515[D loss: 0.471554, acc: 60.16%, op_acc: 29.69%] [G loss: 0.973077]\n",
      "epoch:1 step:1516[D loss: 0.438763, acc: 71.09%, op_acc: 26.56%] [G loss: 1.050000]\n",
      "epoch:1 step:1517[D loss: 0.452421, acc: 67.19%, op_acc: 32.03%] [G loss: 1.162755]\n",
      "epoch:1 step:1518[D loss: 0.426170, acc: 61.72%, op_acc: 34.38%] [G loss: 1.162539]\n",
      "epoch:1 step:1519[D loss: 0.442978, acc: 61.72%, op_acc: 31.25%] [G loss: 1.030359]\n",
      "epoch:1 step:1520[D loss: 0.437978, acc: 62.50%, op_acc: 28.91%] [G loss: 1.054275]\n",
      "epoch:1 step:1521[D loss: 0.496411, acc: 53.12%, op_acc: 31.25%] [G loss: 0.970814]\n",
      "epoch:1 step:1522[D loss: 0.449605, acc: 70.31%, op_acc: 28.91%] [G loss: 1.029415]\n",
      "epoch:1 step:1523[D loss: 0.485897, acc: 58.59%, op_acc: 21.09%] [G loss: 1.145885]\n",
      "epoch:1 step:1524[D loss: 0.521405, acc: 55.47%, op_acc: 26.56%] [G loss: 0.886356]\n",
      "epoch:1 step:1525[D loss: 0.466194, acc: 59.38%, op_acc: 25.78%] [G loss: 0.819859]\n",
      "epoch:1 step:1526[D loss: 0.495055, acc: 49.22%, op_acc: 29.69%] [G loss: 0.953573]\n",
      "epoch:1 step:1527[D loss: 0.450199, acc: 58.59%, op_acc: 32.03%] [G loss: 1.023690]\n",
      "epoch:1 step:1528[D loss: 0.410536, acc: 71.88%, op_acc: 37.50%] [G loss: 1.001179]\n",
      "epoch:1 step:1529[D loss: 0.490093, acc: 67.97%, op_acc: 25.00%] [G loss: 1.104251]\n",
      "epoch:1 step:1530[D loss: 0.471326, acc: 58.59%, op_acc: 29.69%] [G loss: 1.062452]\n",
      "epoch:1 step:1531[D loss: 0.483748, acc: 55.47%, op_acc: 28.12%] [G loss: 1.061937]\n",
      "epoch:1 step:1532[D loss: 0.516783, acc: 60.94%, op_acc: 23.44%] [G loss: 0.935778]\n",
      "epoch:1 step:1533[D loss: 0.433335, acc: 68.75%, op_acc: 26.56%] [G loss: 1.007851]\n",
      "epoch:1 step:1534[D loss: 0.444805, acc: 63.28%, op_acc: 32.81%] [G loss: 1.011845]\n",
      "epoch:1 step:1535[D loss: 0.483858, acc: 57.03%, op_acc: 28.91%] [G loss: 1.076465]\n",
      "epoch:1 step:1536[D loss: 0.439587, acc: 61.72%, op_acc: 32.03%] [G loss: 1.023368]\n",
      "epoch:1 step:1537[D loss: 0.479937, acc: 53.91%, op_acc: 31.25%] [G loss: 0.984626]\n",
      "epoch:1 step:1538[D loss: 0.451922, acc: 64.06%, op_acc: 25.00%] [G loss: 0.929806]\n",
      "epoch:1 step:1539[D loss: 0.491516, acc: 52.34%, op_acc: 31.25%] [G loss: 0.931545]\n",
      "epoch:1 step:1540[D loss: 0.465826, acc: 63.28%, op_acc: 25.00%] [G loss: 0.987508]\n",
      "epoch:1 step:1541[D loss: 0.462521, acc: 62.50%, op_acc: 30.47%] [G loss: 1.095398]\n",
      "epoch:1 step:1542[D loss: 0.433676, acc: 67.97%, op_acc: 32.03%] [G loss: 1.018047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1543[D loss: 0.450871, acc: 67.19%, op_acc: 26.56%] [G loss: 1.034138]\n",
      "epoch:1 step:1544[D loss: 0.467953, acc: 63.28%, op_acc: 33.59%] [G loss: 1.082352]\n",
      "epoch:1 step:1545[D loss: 0.448765, acc: 61.72%, op_acc: 28.12%] [G loss: 0.920559]\n",
      "epoch:1 step:1546[D loss: 0.487939, acc: 59.38%, op_acc: 24.22%] [G loss: 1.057801]\n",
      "epoch:1 step:1547[D loss: 0.461281, acc: 63.28%, op_acc: 23.44%] [G loss: 0.975678]\n",
      "epoch:1 step:1548[D loss: 0.473415, acc: 51.56%, op_acc: 25.78%] [G loss: 1.034218]\n",
      "epoch:1 step:1549[D loss: 0.467500, acc: 60.16%, op_acc: 28.91%] [G loss: 1.150393]\n",
      "epoch:1 step:1550[D loss: 0.411526, acc: 69.53%, op_acc: 39.06%] [G loss: 1.063960]\n",
      "epoch:1 step:1551[D loss: 0.443694, acc: 62.50%, op_acc: 27.34%] [G loss: 0.997491]\n",
      "epoch:1 step:1552[D loss: 0.474519, acc: 60.16%, op_acc: 25.78%] [G loss: 1.023559]\n",
      "epoch:1 step:1553[D loss: 0.490623, acc: 50.78%, op_acc: 23.44%] [G loss: 1.038915]\n",
      "epoch:1 step:1554[D loss: 0.427357, acc: 66.41%, op_acc: 35.16%] [G loss: 1.083258]\n",
      "epoch:1 step:1555[D loss: 0.451961, acc: 64.84%, op_acc: 32.03%] [G loss: 0.998016]\n",
      "epoch:1 step:1556[D loss: 0.484158, acc: 62.50%, op_acc: 25.78%] [G loss: 1.018623]\n",
      "epoch:1 step:1557[D loss: 0.481479, acc: 56.25%, op_acc: 29.69%] [G loss: 1.021544]\n",
      "epoch:1 step:1558[D loss: 0.471818, acc: 60.94%, op_acc: 21.88%] [G loss: 1.035986]\n",
      "epoch:1 step:1559[D loss: 0.463383, acc: 60.16%, op_acc: 36.72%] [G loss: 1.004751]\n",
      "epoch:1 step:1560[D loss: 0.453059, acc: 59.38%, op_acc: 36.72%] [G loss: 1.081444]\n",
      "epoch:1 step:1561[D loss: 0.459740, acc: 60.16%, op_acc: 32.81%] [G loss: 0.961912]\n",
      "epoch:1 step:1562[D loss: 0.486987, acc: 63.28%, op_acc: 25.78%] [G loss: 1.054255]\n",
      "epoch:2 step:1563[D loss: 0.478022, acc: 59.38%, op_acc: 33.59%] [G loss: 0.901603]\n",
      "epoch:2 step:1564[D loss: 0.458902, acc: 53.91%, op_acc: 25.78%] [G loss: 0.983728]\n",
      "epoch:2 step:1565[D loss: 0.466065, acc: 57.03%, op_acc: 30.47%] [G loss: 0.944802]\n",
      "epoch:2 step:1566[D loss: 0.407521, acc: 62.50%, op_acc: 33.59%] [G loss: 1.005878]\n",
      "epoch:2 step:1567[D loss: 0.466280, acc: 55.47%, op_acc: 37.50%] [G loss: 1.036727]\n",
      "epoch:2 step:1568[D loss: 0.441875, acc: 66.41%, op_acc: 21.88%] [G loss: 1.024360]\n",
      "epoch:2 step:1569[D loss: 0.490249, acc: 53.12%, op_acc: 28.12%] [G loss: 0.930544]\n",
      "epoch:2 step:1570[D loss: 0.450675, acc: 64.84%, op_acc: 32.03%] [G loss: 1.043312]\n",
      "epoch:2 step:1571[D loss: 0.467634, acc: 60.16%, op_acc: 34.38%] [G loss: 1.017868]\n",
      "epoch:2 step:1572[D loss: 0.448182, acc: 71.88%, op_acc: 28.91%] [G loss: 0.941254]\n",
      "epoch:2 step:1573[D loss: 0.517164, acc: 57.03%, op_acc: 22.66%] [G loss: 0.943048]\n",
      "epoch:2 step:1574[D loss: 0.459277, acc: 60.94%, op_acc: 22.66%] [G loss: 0.975083]\n",
      "epoch:2 step:1575[D loss: 0.446870, acc: 65.62%, op_acc: 33.59%] [G loss: 1.179041]\n",
      "epoch:2 step:1576[D loss: 0.467452, acc: 61.72%, op_acc: 29.69%] [G loss: 1.040220]\n",
      "epoch:2 step:1577[D loss: 0.457810, acc: 62.50%, op_acc: 31.25%] [G loss: 1.114616]\n",
      "epoch:2 step:1578[D loss: 0.469334, acc: 60.94%, op_acc: 28.91%] [G loss: 1.030972]\n",
      "epoch:2 step:1579[D loss: 0.466606, acc: 60.94%, op_acc: 34.38%] [G loss: 1.032803]\n",
      "epoch:2 step:1580[D loss: 0.451639, acc: 60.16%, op_acc: 28.12%] [G loss: 1.058008]\n",
      "epoch:2 step:1581[D loss: 0.462123, acc: 64.06%, op_acc: 25.78%] [G loss: 1.145393]\n",
      "epoch:2 step:1582[D loss: 0.438909, acc: 67.19%, op_acc: 30.47%] [G loss: 1.071498]\n",
      "epoch:2 step:1583[D loss: 0.466533, acc: 60.16%, op_acc: 26.56%] [G loss: 1.104052]\n",
      "epoch:2 step:1584[D loss: 0.438712, acc: 60.94%, op_acc: 32.03%] [G loss: 1.004535]\n",
      "epoch:2 step:1585[D loss: 0.449281, acc: 64.84%, op_acc: 30.47%] [G loss: 0.994242]\n",
      "epoch:2 step:1586[D loss: 0.485426, acc: 60.16%, op_acc: 28.91%] [G loss: 1.149000]\n",
      "epoch:2 step:1587[D loss: 0.453263, acc: 63.28%, op_acc: 25.78%] [G loss: 1.039152]\n",
      "epoch:2 step:1588[D loss: 0.449726, acc: 60.16%, op_acc: 39.06%] [G loss: 0.980464]\n",
      "epoch:2 step:1589[D loss: 0.446932, acc: 59.38%, op_acc: 32.81%] [G loss: 1.001317]\n",
      "epoch:2 step:1590[D loss: 0.461811, acc: 63.28%, op_acc: 27.34%] [G loss: 0.981929]\n",
      "epoch:2 step:1591[D loss: 0.499078, acc: 55.47%, op_acc: 28.91%] [G loss: 0.970325]\n",
      "epoch:2 step:1592[D loss: 0.403261, acc: 70.31%, op_acc: 37.50%] [G loss: 1.107220]\n",
      "epoch:2 step:1593[D loss: 0.479743, acc: 64.06%, op_acc: 27.34%] [G loss: 1.083495]\n",
      "epoch:2 step:1594[D loss: 0.521108, acc: 53.91%, op_acc: 25.00%] [G loss: 1.037402]\n",
      "epoch:2 step:1595[D loss: 0.454865, acc: 63.28%, op_acc: 27.34%] [G loss: 1.093614]\n",
      "epoch:2 step:1596[D loss: 0.440370, acc: 67.97%, op_acc: 35.94%] [G loss: 0.948353]\n",
      "epoch:2 step:1597[D loss: 0.471687, acc: 55.47%, op_acc: 31.25%] [G loss: 0.977932]\n",
      "epoch:2 step:1598[D loss: 0.461851, acc: 55.47%, op_acc: 27.34%] [G loss: 0.958907]\n",
      "epoch:2 step:1599[D loss: 0.495674, acc: 52.34%, op_acc: 25.00%] [G loss: 0.930317]\n",
      "epoch:2 step:1600[D loss: 0.440353, acc: 60.16%, op_acc: 35.94%] [G loss: 1.055003]\n",
      "epoch:2 step:1601[D loss: 0.411705, acc: 67.97%, op_acc: 33.59%] [G loss: 1.099602]\n",
      "epoch:2 step:1602[D loss: 0.462935, acc: 62.50%, op_acc: 28.91%] [G loss: 1.126912]\n",
      "epoch:2 step:1603[D loss: 0.480739, acc: 55.47%, op_acc: 24.22%] [G loss: 0.986050]\n",
      "epoch:2 step:1604[D loss: 0.452102, acc: 66.41%, op_acc: 32.81%] [G loss: 1.055719]\n",
      "epoch:2 step:1605[D loss: 0.472911, acc: 60.16%, op_acc: 26.56%] [G loss: 0.955189]\n",
      "epoch:2 step:1606[D loss: 0.503535, acc: 53.91%, op_acc: 25.00%] [G loss: 0.830557]\n",
      "epoch:2 step:1607[D loss: 0.463289, acc: 53.91%, op_acc: 28.91%] [G loss: 0.981870]\n",
      "epoch:2 step:1608[D loss: 0.475714, acc: 57.03%, op_acc: 29.69%] [G loss: 1.073947]\n",
      "epoch:2 step:1609[D loss: 0.458764, acc: 64.84%, op_acc: 28.91%] [G loss: 1.057546]\n",
      "epoch:2 step:1610[D loss: 0.472007, acc: 61.72%, op_acc: 29.69%] [G loss: 1.028120]\n",
      "epoch:2 step:1611[D loss: 0.480107, acc: 60.94%, op_acc: 28.91%] [G loss: 1.049800]\n",
      "epoch:2 step:1612[D loss: 0.503410, acc: 62.50%, op_acc: 27.34%] [G loss: 1.095914]\n",
      "epoch:2 step:1613[D loss: 0.482783, acc: 53.91%, op_acc: 31.25%] [G loss: 0.988101]\n",
      "epoch:2 step:1614[D loss: 0.485812, acc: 56.25%, op_acc: 23.44%] [G loss: 1.024276]\n",
      "epoch:2 step:1615[D loss: 0.442097, acc: 65.62%, op_acc: 28.12%] [G loss: 1.074972]\n",
      "epoch:2 step:1616[D loss: 0.529045, acc: 51.56%, op_acc: 32.81%] [G loss: 1.025846]\n",
      "epoch:2 step:1617[D loss: 0.434530, acc: 65.62%, op_acc: 32.81%] [G loss: 0.971337]\n",
      "epoch:2 step:1618[D loss: 0.446332, acc: 63.28%, op_acc: 27.34%] [G loss: 1.103400]\n",
      "epoch:2 step:1619[D loss: 0.478674, acc: 59.38%, op_acc: 28.91%] [G loss: 0.953553]\n",
      "epoch:2 step:1620[D loss: 0.470031, acc: 56.25%, op_acc: 34.38%] [G loss: 0.949059]\n",
      "epoch:2 step:1621[D loss: 0.469218, acc: 54.69%, op_acc: 29.69%] [G loss: 0.896778]\n",
      "epoch:2 step:1622[D loss: 0.454640, acc: 62.50%, op_acc: 33.59%] [G loss: 1.017987]\n",
      "epoch:2 step:1623[D loss: 0.476931, acc: 61.72%, op_acc: 32.03%] [G loss: 1.018805]\n",
      "epoch:2 step:1624[D loss: 0.494583, acc: 58.59%, op_acc: 22.66%] [G loss: 0.975296]\n",
      "epoch:2 step:1625[D loss: 0.497555, acc: 57.81%, op_acc: 24.22%] [G loss: 1.043933]\n",
      "epoch:2 step:1626[D loss: 0.471871, acc: 59.38%, op_acc: 27.34%] [G loss: 0.973879]\n",
      "epoch:2 step:1627[D loss: 0.473439, acc: 58.59%, op_acc: 25.78%] [G loss: 0.957612]\n",
      "epoch:2 step:1628[D loss: 0.457815, acc: 62.50%, op_acc: 29.69%] [G loss: 1.067976]\n",
      "epoch:2 step:1629[D loss: 0.462070, acc: 61.72%, op_acc: 24.22%] [G loss: 1.006229]\n",
      "epoch:2 step:1630[D loss: 0.481841, acc: 52.34%, op_acc: 28.12%] [G loss: 0.936328]\n",
      "epoch:2 step:1631[D loss: 0.439771, acc: 60.94%, op_acc: 29.69%] [G loss: 1.075243]\n",
      "epoch:2 step:1632[D loss: 0.455148, acc: 64.84%, op_acc: 25.00%] [G loss: 1.064091]\n",
      "epoch:2 step:1633[D loss: 0.512794, acc: 61.72%, op_acc: 25.78%] [G loss: 1.083659]\n",
      "epoch:2 step:1634[D loss: 0.486245, acc: 58.59%, op_acc: 28.91%] [G loss: 0.905343]\n",
      "epoch:2 step:1635[D loss: 0.438320, acc: 65.62%, op_acc: 32.81%] [G loss: 0.947147]\n",
      "epoch:2 step:1636[D loss: 0.445259, acc: 63.28%, op_acc: 32.03%] [G loss: 1.029698]\n",
      "epoch:2 step:1637[D loss: 0.468728, acc: 64.06%, op_acc: 27.34%] [G loss: 1.009808]\n",
      "epoch:2 step:1638[D loss: 0.456658, acc: 68.75%, op_acc: 33.59%] [G loss: 1.021318]\n",
      "epoch:2 step:1639[D loss: 0.476791, acc: 60.16%, op_acc: 32.81%] [G loss: 1.061296]\n",
      "epoch:2 step:1640[D loss: 0.467084, acc: 66.41%, op_acc: 23.44%] [G loss: 1.050783]\n",
      "epoch:2 step:1641[D loss: 0.468761, acc: 60.94%, op_acc: 33.59%] [G loss: 0.877444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1642[D loss: 0.487624, acc: 57.81%, op_acc: 21.09%] [G loss: 0.929199]\n",
      "epoch:2 step:1643[D loss: 0.487234, acc: 60.16%, op_acc: 31.25%] [G loss: 1.101806]\n",
      "epoch:2 step:1644[D loss: 0.458578, acc: 65.62%, op_acc: 25.00%] [G loss: 1.049286]\n",
      "epoch:2 step:1645[D loss: 0.474343, acc: 57.03%, op_acc: 29.69%] [G loss: 1.038970]\n",
      "epoch:2 step:1646[D loss: 0.462922, acc: 60.94%, op_acc: 30.47%] [G loss: 0.991396]\n",
      "epoch:2 step:1647[D loss: 0.451621, acc: 64.84%, op_acc: 29.69%] [G loss: 1.030249]\n",
      "epoch:2 step:1648[D loss: 0.434143, acc: 61.72%, op_acc: 34.38%] [G loss: 1.177269]\n",
      "epoch:2 step:1649[D loss: 0.487993, acc: 59.38%, op_acc: 35.16%] [G loss: 0.977002]\n",
      "epoch:2 step:1650[D loss: 0.469102, acc: 60.16%, op_acc: 34.38%] [G loss: 0.953161]\n",
      "epoch:2 step:1651[D loss: 0.500287, acc: 54.69%, op_acc: 25.00%] [G loss: 1.020588]\n",
      "epoch:2 step:1652[D loss: 0.484476, acc: 58.59%, op_acc: 33.59%] [G loss: 1.007657]\n",
      "epoch:2 step:1653[D loss: 0.495521, acc: 59.38%, op_acc: 21.88%] [G loss: 0.885289]\n",
      "epoch:2 step:1654[D loss: 0.476953, acc: 55.47%, op_acc: 37.50%] [G loss: 0.959418]\n",
      "epoch:2 step:1655[D loss: 0.443888, acc: 56.25%, op_acc: 34.38%] [G loss: 1.109180]\n",
      "epoch:2 step:1656[D loss: 0.465919, acc: 59.38%, op_acc: 28.12%] [G loss: 0.982213]\n",
      "epoch:2 step:1657[D loss: 0.444418, acc: 57.81%, op_acc: 30.47%] [G loss: 0.970965]\n",
      "epoch:2 step:1658[D loss: 0.491776, acc: 56.25%, op_acc: 28.12%] [G loss: 0.911985]\n",
      "epoch:2 step:1659[D loss: 0.413108, acc: 74.22%, op_acc: 30.47%] [G loss: 1.115675]\n",
      "epoch:2 step:1660[D loss: 0.506465, acc: 51.56%, op_acc: 25.00%] [G loss: 0.836599]\n",
      "epoch:2 step:1661[D loss: 0.458919, acc: 61.72%, op_acc: 32.03%] [G loss: 0.980970]\n",
      "epoch:2 step:1662[D loss: 0.453602, acc: 59.38%, op_acc: 32.03%] [G loss: 1.072295]\n",
      "epoch:2 step:1663[D loss: 0.449125, acc: 64.84%, op_acc: 30.47%] [G loss: 1.083553]\n",
      "epoch:2 step:1664[D loss: 0.452992, acc: 62.50%, op_acc: 27.34%] [G loss: 0.941170]\n",
      "epoch:2 step:1665[D loss: 0.458118, acc: 63.28%, op_acc: 32.81%] [G loss: 1.015701]\n",
      "epoch:2 step:1666[D loss: 0.462607, acc: 66.41%, op_acc: 27.34%] [G loss: 0.972312]\n",
      "epoch:2 step:1667[D loss: 0.450520, acc: 59.38%, op_acc: 27.34%] [G loss: 0.803687]\n",
      "epoch:2 step:1668[D loss: 0.427209, acc: 64.06%, op_acc: 36.72%] [G loss: 1.019774]\n",
      "epoch:2 step:1669[D loss: 0.429449, acc: 64.06%, op_acc: 32.81%] [G loss: 1.057997]\n",
      "epoch:2 step:1670[D loss: 0.485016, acc: 54.69%, op_acc: 28.12%] [G loss: 0.971376]\n",
      "epoch:2 step:1671[D loss: 0.445962, acc: 65.62%, op_acc: 28.12%] [G loss: 1.080260]\n",
      "epoch:2 step:1672[D loss: 0.428892, acc: 69.53%, op_acc: 37.50%] [G loss: 0.943249]\n",
      "epoch:2 step:1673[D loss: 0.439703, acc: 66.41%, op_acc: 27.34%] [G loss: 0.842512]\n",
      "epoch:2 step:1674[D loss: 0.448447, acc: 64.06%, op_acc: 32.81%] [G loss: 1.026692]\n",
      "epoch:2 step:1675[D loss: 0.496323, acc: 52.34%, op_acc: 27.34%] [G loss: 0.858602]\n",
      "epoch:2 step:1676[D loss: 0.413829, acc: 67.97%, op_acc: 33.59%] [G loss: 1.044103]\n",
      "epoch:2 step:1677[D loss: 0.445724, acc: 57.81%, op_acc: 33.59%] [G loss: 1.082085]\n",
      "epoch:2 step:1678[D loss: 0.503023, acc: 54.69%, op_acc: 21.88%] [G loss: 1.096531]\n",
      "epoch:2 step:1679[D loss: 0.446864, acc: 62.50%, op_acc: 29.69%] [G loss: 1.145194]\n",
      "epoch:2 step:1680[D loss: 0.451460, acc: 62.50%, op_acc: 32.03%] [G loss: 1.268330]\n",
      "epoch:2 step:1681[D loss: 0.445086, acc: 67.19%, op_acc: 24.22%] [G loss: 1.300915]\n",
      "epoch:2 step:1682[D loss: 0.456273, acc: 64.06%, op_acc: 28.12%] [G loss: 1.178774]\n",
      "epoch:2 step:1683[D loss: 0.505717, acc: 61.72%, op_acc: 21.09%] [G loss: 1.097939]\n",
      "epoch:2 step:1684[D loss: 0.484623, acc: 57.81%, op_acc: 22.66%] [G loss: 0.982331]\n",
      "epoch:2 step:1685[D loss: 0.486804, acc: 50.78%, op_acc: 26.56%] [G loss: 0.868428]\n",
      "epoch:2 step:1686[D loss: 0.469683, acc: 54.69%, op_acc: 28.12%] [G loss: 0.961065]\n",
      "epoch:2 step:1687[D loss: 0.494224, acc: 57.03%, op_acc: 25.78%] [G loss: 0.933596]\n",
      "epoch:2 step:1688[D loss: 0.453140, acc: 65.62%, op_acc: 25.00%] [G loss: 1.015353]\n",
      "epoch:2 step:1689[D loss: 0.464306, acc: 64.06%, op_acc: 26.56%] [G loss: 0.971221]\n",
      "epoch:2 step:1690[D loss: 0.443338, acc: 57.03%, op_acc: 30.47%] [G loss: 1.017979]\n",
      "epoch:2 step:1691[D loss: 0.477586, acc: 58.59%, op_acc: 26.56%] [G loss: 1.097340]\n",
      "epoch:2 step:1692[D loss: 0.470501, acc: 57.81%, op_acc: 29.69%] [G loss: 0.977411]\n",
      "epoch:2 step:1693[D loss: 0.509511, acc: 53.91%, op_acc: 28.91%] [G loss: 0.881964]\n",
      "epoch:2 step:1694[D loss: 0.463912, acc: 53.91%, op_acc: 31.25%] [G loss: 0.973106]\n",
      "epoch:2 step:1695[D loss: 0.517423, acc: 60.16%, op_acc: 24.22%] [G loss: 0.954136]\n",
      "epoch:2 step:1696[D loss: 0.484891, acc: 57.03%, op_acc: 28.91%] [G loss: 0.992484]\n",
      "epoch:2 step:1697[D loss: 0.470023, acc: 56.25%, op_acc: 28.12%] [G loss: 1.000499]\n",
      "epoch:2 step:1698[D loss: 0.472007, acc: 50.78%, op_acc: 32.03%] [G loss: 0.910716]\n",
      "epoch:2 step:1699[D loss: 0.514305, acc: 53.12%, op_acc: 28.12%] [G loss: 0.968756]\n",
      "epoch:2 step:1700[D loss: 0.486289, acc: 57.81%, op_acc: 27.34%] [G loss: 0.859509]\n",
      "epoch:2 step:1701[D loss: 0.439190, acc: 67.19%, op_acc: 30.47%] [G loss: 0.946764]\n",
      "epoch:2 step:1702[D loss: 0.500890, acc: 56.25%, op_acc: 27.34%] [G loss: 1.015524]\n",
      "epoch:2 step:1703[D loss: 0.520458, acc: 52.34%, op_acc: 22.66%] [G loss: 0.912921]\n",
      "epoch:2 step:1704[D loss: 0.450801, acc: 64.06%, op_acc: 23.44%] [G loss: 0.962648]\n",
      "epoch:2 step:1705[D loss: 0.464828, acc: 59.38%, op_acc: 28.91%] [G loss: 1.151901]\n",
      "epoch:2 step:1706[D loss: 0.467847, acc: 57.03%, op_acc: 31.25%] [G loss: 1.057908]\n",
      "epoch:2 step:1707[D loss: 0.452586, acc: 61.72%, op_acc: 27.34%] [G loss: 0.915846]\n",
      "epoch:2 step:1708[D loss: 0.454225, acc: 62.50%, op_acc: 38.28%] [G loss: 1.062150]\n",
      "epoch:2 step:1709[D loss: 0.453352, acc: 59.38%, op_acc: 32.03%] [G loss: 1.120180]\n",
      "epoch:2 step:1710[D loss: 0.521862, acc: 56.25%, op_acc: 26.56%] [G loss: 0.965304]\n",
      "epoch:2 step:1711[D loss: 0.454796, acc: 57.03%, op_acc: 34.38%] [G loss: 1.035615]\n",
      "epoch:2 step:1712[D loss: 0.453067, acc: 64.06%, op_acc: 28.12%] [G loss: 1.110572]\n",
      "epoch:2 step:1713[D loss: 0.448379, acc: 64.06%, op_acc: 29.69%] [G loss: 0.951213]\n",
      "epoch:2 step:1714[D loss: 0.467235, acc: 61.72%, op_acc: 32.03%] [G loss: 0.989622]\n",
      "epoch:2 step:1715[D loss: 0.445504, acc: 64.84%, op_acc: 28.91%] [G loss: 1.000861]\n",
      "epoch:2 step:1716[D loss: 0.440769, acc: 62.50%, op_acc: 30.47%] [G loss: 1.029805]\n",
      "epoch:2 step:1717[D loss: 0.484936, acc: 55.47%, op_acc: 25.00%] [G loss: 0.971505]\n",
      "epoch:2 step:1718[D loss: 0.492717, acc: 51.56%, op_acc: 28.91%] [G loss: 0.920332]\n",
      "epoch:2 step:1719[D loss: 0.434071, acc: 67.97%, op_acc: 30.47%] [G loss: 0.989866]\n",
      "epoch:2 step:1720[D loss: 0.417987, acc: 68.75%, op_acc: 32.81%] [G loss: 1.013687]\n",
      "epoch:2 step:1721[D loss: 0.468733, acc: 61.72%, op_acc: 34.38%] [G loss: 0.932246]\n",
      "epoch:2 step:1722[D loss: 0.512939, acc: 50.78%, op_acc: 23.44%] [G loss: 0.995897]\n",
      "epoch:2 step:1723[D loss: 0.460534, acc: 64.84%, op_acc: 25.00%] [G loss: 0.994275]\n",
      "epoch:2 step:1724[D loss: 0.415405, acc: 72.66%, op_acc: 30.47%] [G loss: 1.044028]\n",
      "epoch:2 step:1725[D loss: 0.445352, acc: 64.06%, op_acc: 28.12%] [G loss: 1.084993]\n",
      "epoch:2 step:1726[D loss: 0.452613, acc: 61.72%, op_acc: 25.78%] [G loss: 1.050550]\n",
      "epoch:2 step:1727[D loss: 0.476455, acc: 55.47%, op_acc: 31.25%] [G loss: 1.099220]\n",
      "epoch:2 step:1728[D loss: 0.490573, acc: 57.81%, op_acc: 23.44%] [G loss: 1.050536]\n",
      "epoch:2 step:1729[D loss: 0.498089, acc: 53.12%, op_acc: 29.69%] [G loss: 1.011431]\n",
      "epoch:2 step:1730[D loss: 0.458642, acc: 57.81%, op_acc: 32.03%] [G loss: 1.059973]\n",
      "epoch:2 step:1731[D loss: 0.434788, acc: 68.75%, op_acc: 35.16%] [G loss: 0.986144]\n",
      "epoch:2 step:1732[D loss: 0.444349, acc: 68.75%, op_acc: 32.81%] [G loss: 0.969975]\n",
      "epoch:2 step:1733[D loss: 0.447132, acc: 66.41%, op_acc: 28.12%] [G loss: 0.880729]\n",
      "epoch:2 step:1734[D loss: 0.414572, acc: 69.53%, op_acc: 31.25%] [G loss: 0.925309]\n",
      "epoch:2 step:1735[D loss: 0.446030, acc: 67.97%, op_acc: 25.00%] [G loss: 1.029798]\n",
      "epoch:2 step:1736[D loss: 0.500577, acc: 57.03%, op_acc: 26.56%] [G loss: 0.920040]\n",
      "epoch:2 step:1737[D loss: 0.466593, acc: 64.06%, op_acc: 21.88%] [G loss: 1.018858]\n",
      "epoch:2 step:1738[D loss: 0.444908, acc: 59.38%, op_acc: 30.47%] [G loss: 1.069978]\n",
      "epoch:2 step:1739[D loss: 0.477368, acc: 55.47%, op_acc: 28.91%] [G loss: 0.986426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1740[D loss: 0.468671, acc: 62.50%, op_acc: 24.22%] [G loss: 1.139979]\n",
      "epoch:2 step:1741[D loss: 0.470663, acc: 58.59%, op_acc: 28.12%] [G loss: 0.978240]\n",
      "epoch:2 step:1742[D loss: 0.438777, acc: 63.28%, op_acc: 29.69%] [G loss: 1.129241]\n",
      "epoch:2 step:1743[D loss: 0.416809, acc: 64.84%, op_acc: 28.91%] [G loss: 1.043395]\n",
      "epoch:2 step:1744[D loss: 0.500318, acc: 55.47%, op_acc: 27.34%] [G loss: 1.119288]\n",
      "epoch:2 step:1745[D loss: 0.452902, acc: 64.84%, op_acc: 27.34%] [G loss: 1.052617]\n",
      "epoch:2 step:1746[D loss: 0.453764, acc: 59.38%, op_acc: 30.47%] [G loss: 0.972665]\n",
      "epoch:2 step:1747[D loss: 0.464439, acc: 65.62%, op_acc: 27.34%] [G loss: 1.016524]\n",
      "epoch:2 step:1748[D loss: 0.456531, acc: 64.06%, op_acc: 32.81%] [G loss: 1.065437]\n",
      "epoch:2 step:1749[D loss: 0.445173, acc: 66.41%, op_acc: 24.22%] [G loss: 1.038211]\n",
      "epoch:2 step:1750[D loss: 0.503632, acc: 53.91%, op_acc: 31.25%] [G loss: 0.907865]\n",
      "epoch:2 step:1751[D loss: 0.473840, acc: 57.81%, op_acc: 28.91%] [G loss: 0.949620]\n",
      "epoch:2 step:1752[D loss: 0.471574, acc: 57.81%, op_acc: 28.91%] [G loss: 1.003678]\n",
      "epoch:2 step:1753[D loss: 0.428888, acc: 68.75%, op_acc: 33.59%] [G loss: 1.128544]\n",
      "epoch:2 step:1754[D loss: 0.450158, acc: 67.97%, op_acc: 27.34%] [G loss: 0.982418]\n",
      "epoch:2 step:1755[D loss: 0.513124, acc: 52.34%, op_acc: 24.22%] [G loss: 0.923096]\n",
      "epoch:2 step:1756[D loss: 0.489759, acc: 60.16%, op_acc: 22.66%] [G loss: 1.031048]\n",
      "epoch:2 step:1757[D loss: 0.482917, acc: 56.25%, op_acc: 24.22%] [G loss: 1.014702]\n",
      "epoch:2 step:1758[D loss: 0.479274, acc: 59.38%, op_acc: 26.56%] [G loss: 0.972021]\n",
      "epoch:2 step:1759[D loss: 0.476486, acc: 64.06%, op_acc: 27.34%] [G loss: 0.966618]\n",
      "epoch:2 step:1760[D loss: 0.474734, acc: 64.84%, op_acc: 29.69%] [G loss: 0.962679]\n",
      "epoch:2 step:1761[D loss: 0.471938, acc: 56.25%, op_acc: 32.03%] [G loss: 0.940346]\n",
      "epoch:2 step:1762[D loss: 0.475412, acc: 55.47%, op_acc: 28.12%] [G loss: 0.992461]\n",
      "epoch:2 step:1763[D loss: 0.424583, acc: 67.97%, op_acc: 32.81%] [G loss: 1.052768]\n",
      "epoch:2 step:1764[D loss: 0.442947, acc: 72.66%, op_acc: 30.47%] [G loss: 1.021921]\n",
      "epoch:2 step:1765[D loss: 0.453723, acc: 63.28%, op_acc: 32.03%] [G loss: 0.974747]\n",
      "epoch:2 step:1766[D loss: 0.465186, acc: 63.28%, op_acc: 30.47%] [G loss: 0.893950]\n",
      "epoch:2 step:1767[D loss: 0.467228, acc: 64.06%, op_acc: 31.25%] [G loss: 0.877013]\n",
      "epoch:2 step:1768[D loss: 0.489132, acc: 57.03%, op_acc: 25.00%] [G loss: 1.077917]\n",
      "epoch:2 step:1769[D loss: 0.459316, acc: 57.03%, op_acc: 29.69%] [G loss: 0.919452]\n",
      "epoch:2 step:1770[D loss: 0.501594, acc: 64.06%, op_acc: 33.59%] [G loss: 0.962646]\n",
      "epoch:2 step:1771[D loss: 0.459848, acc: 59.38%, op_acc: 27.34%] [G loss: 1.027387]\n",
      "epoch:2 step:1772[D loss: 0.476444, acc: 58.59%, op_acc: 29.69%] [G loss: 1.018943]\n",
      "epoch:2 step:1773[D loss: 0.454183, acc: 60.16%, op_acc: 29.69%] [G loss: 1.006232]\n",
      "epoch:2 step:1774[D loss: 0.441545, acc: 65.62%, op_acc: 32.81%] [G loss: 1.070377]\n",
      "epoch:2 step:1775[D loss: 0.489224, acc: 51.56%, op_acc: 28.12%] [G loss: 0.903303]\n",
      "epoch:2 step:1776[D loss: 0.471326, acc: 63.28%, op_acc: 30.47%] [G loss: 0.969278]\n",
      "epoch:2 step:1777[D loss: 0.460513, acc: 67.97%, op_acc: 29.69%] [G loss: 0.948681]\n",
      "epoch:2 step:1778[D loss: 0.474558, acc: 64.06%, op_acc: 26.56%] [G loss: 1.066724]\n",
      "epoch:2 step:1779[D loss: 0.440550, acc: 66.41%, op_acc: 28.12%] [G loss: 0.907028]\n",
      "epoch:2 step:1780[D loss: 0.430932, acc: 67.97%, op_acc: 31.25%] [G loss: 1.039956]\n",
      "epoch:2 step:1781[D loss: 0.458027, acc: 61.72%, op_acc: 27.34%] [G loss: 0.977529]\n",
      "epoch:2 step:1782[D loss: 0.462278, acc: 60.94%, op_acc: 28.91%] [G loss: 0.984193]\n",
      "epoch:2 step:1783[D loss: 0.479876, acc: 57.81%, op_acc: 22.66%] [G loss: 0.961628]\n",
      "epoch:2 step:1784[D loss: 0.450253, acc: 64.84%, op_acc: 26.56%] [G loss: 1.042872]\n",
      "epoch:2 step:1785[D loss: 0.466650, acc: 48.44%, op_acc: 31.25%] [G loss: 0.890014]\n",
      "epoch:2 step:1786[D loss: 0.490474, acc: 57.03%, op_acc: 19.53%] [G loss: 0.902763]\n",
      "epoch:2 step:1787[D loss: 0.468908, acc: 58.59%, op_acc: 31.25%] [G loss: 0.936477]\n",
      "epoch:2 step:1788[D loss: 0.481967, acc: 54.69%, op_acc: 24.22%] [G loss: 1.015797]\n",
      "epoch:2 step:1789[D loss: 0.447487, acc: 69.53%, op_acc: 29.69%] [G loss: 1.006610]\n",
      "epoch:2 step:1790[D loss: 0.439531, acc: 65.62%, op_acc: 32.03%] [G loss: 0.963462]\n",
      "epoch:2 step:1791[D loss: 0.460721, acc: 65.62%, op_acc: 26.56%] [G loss: 1.095016]\n",
      "epoch:2 step:1792[D loss: 0.462393, acc: 67.97%, op_acc: 25.00%] [G loss: 0.991191]\n",
      "epoch:2 step:1793[D loss: 0.462070, acc: 60.94%, op_acc: 36.72%] [G loss: 0.985109]\n",
      "epoch:2 step:1794[D loss: 0.487133, acc: 53.12%, op_acc: 28.12%] [G loss: 0.925751]\n",
      "epoch:2 step:1795[D loss: 0.449038, acc: 64.84%, op_acc: 29.69%] [G loss: 1.157117]\n",
      "epoch:2 step:1796[D loss: 0.459271, acc: 65.62%, op_acc: 24.22%] [G loss: 1.007811]\n",
      "epoch:2 step:1797[D loss: 0.472197, acc: 57.81%, op_acc: 25.78%] [G loss: 0.987403]\n",
      "epoch:2 step:1798[D loss: 0.476513, acc: 62.50%, op_acc: 21.09%] [G loss: 0.930853]\n",
      "epoch:2 step:1799[D loss: 0.468364, acc: 62.50%, op_acc: 30.47%] [G loss: 0.951199]\n",
      "epoch:2 step:1800[D loss: 0.487790, acc: 56.25%, op_acc: 31.25%] [G loss: 1.013104]\n",
      "epoch:2 step:1801[D loss: 0.440086, acc: 61.72%, op_acc: 28.12%] [G loss: 1.059456]\n",
      "epoch:2 step:1802[D loss: 0.456834, acc: 61.72%, op_acc: 29.69%] [G loss: 1.015588]\n",
      "epoch:2 step:1803[D loss: 0.425740, acc: 70.31%, op_acc: 33.59%] [G loss: 1.115414]\n",
      "epoch:2 step:1804[D loss: 0.479706, acc: 60.94%, op_acc: 28.12%] [G loss: 0.916920]\n",
      "epoch:2 step:1805[D loss: 0.481825, acc: 56.25%, op_acc: 30.47%] [G loss: 0.938995]\n",
      "epoch:2 step:1806[D loss: 0.478848, acc: 69.53%, op_acc: 26.56%] [G loss: 0.935012]\n",
      "epoch:2 step:1807[D loss: 0.469974, acc: 58.59%, op_acc: 34.38%] [G loss: 1.033729]\n",
      "epoch:2 step:1808[D loss: 0.498400, acc: 53.12%, op_acc: 26.56%] [G loss: 1.004163]\n",
      "epoch:2 step:1809[D loss: 0.445558, acc: 69.53%, op_acc: 32.81%] [G loss: 1.100169]\n",
      "epoch:2 step:1810[D loss: 0.476900, acc: 62.50%, op_acc: 24.22%] [G loss: 1.003781]\n",
      "epoch:2 step:1811[D loss: 0.444222, acc: 71.09%, op_acc: 29.69%] [G loss: 1.057358]\n",
      "epoch:2 step:1812[D loss: 0.460286, acc: 59.38%, op_acc: 32.03%] [G loss: 1.006111]\n",
      "epoch:2 step:1813[D loss: 0.431880, acc: 68.75%, op_acc: 33.59%] [G loss: 1.125574]\n",
      "epoch:2 step:1814[D loss: 0.466716, acc: 64.06%, op_acc: 25.78%] [G loss: 1.066131]\n",
      "epoch:2 step:1815[D loss: 0.462645, acc: 64.06%, op_acc: 27.34%] [G loss: 1.077518]\n",
      "epoch:2 step:1816[D loss: 0.475977, acc: 64.06%, op_acc: 25.78%] [G loss: 1.046704]\n",
      "epoch:2 step:1817[D loss: 0.474010, acc: 60.94%, op_acc: 28.12%] [G loss: 0.928088]\n",
      "epoch:2 step:1818[D loss: 0.479706, acc: 60.16%, op_acc: 27.34%] [G loss: 1.123295]\n",
      "epoch:2 step:1819[D loss: 0.433335, acc: 66.41%, op_acc: 32.81%] [G loss: 1.070921]\n",
      "epoch:2 step:1820[D loss: 0.457364, acc: 59.38%, op_acc: 35.94%] [G loss: 0.927507]\n",
      "epoch:2 step:1821[D loss: 0.455349, acc: 61.72%, op_acc: 28.12%] [G loss: 0.940388]\n",
      "epoch:2 step:1822[D loss: 0.457617, acc: 67.97%, op_acc: 33.59%] [G loss: 1.011528]\n",
      "epoch:2 step:1823[D loss: 0.435499, acc: 60.16%, op_acc: 38.28%] [G loss: 0.972599]\n",
      "epoch:2 step:1824[D loss: 0.469678, acc: 61.72%, op_acc: 24.22%] [G loss: 1.046547]\n",
      "epoch:2 step:1825[D loss: 0.434191, acc: 71.09%, op_acc: 30.47%] [G loss: 0.986413]\n",
      "epoch:2 step:1826[D loss: 0.451759, acc: 60.16%, op_acc: 30.47%] [G loss: 0.955024]\n",
      "epoch:2 step:1827[D loss: 0.462974, acc: 56.25%, op_acc: 34.38%] [G loss: 0.979514]\n",
      "epoch:2 step:1828[D loss: 0.486023, acc: 62.50%, op_acc: 30.47%] [G loss: 1.152595]\n",
      "epoch:2 step:1829[D loss: 0.486564, acc: 59.38%, op_acc: 27.34%] [G loss: 0.997136]\n",
      "epoch:2 step:1830[D loss: 0.469513, acc: 56.25%, op_acc: 27.34%] [G loss: 1.082137]\n",
      "epoch:2 step:1831[D loss: 0.424272, acc: 59.38%, op_acc: 32.03%] [G loss: 1.056400]\n",
      "epoch:2 step:1832[D loss: 0.446796, acc: 62.50%, op_acc: 25.78%] [G loss: 1.043193]\n",
      "epoch:2 step:1833[D loss: 0.464130, acc: 60.16%, op_acc: 28.91%] [G loss: 0.910578]\n",
      "epoch:2 step:1834[D loss: 0.445644, acc: 70.31%, op_acc: 27.34%] [G loss: 1.062087]\n",
      "epoch:2 step:1835[D loss: 0.446395, acc: 63.28%, op_acc: 27.34%] [G loss: 0.973590]\n",
      "epoch:2 step:1836[D loss: 0.450140, acc: 59.38%, op_acc: 28.91%] [G loss: 0.976978]\n",
      "epoch:2 step:1837[D loss: 0.444883, acc: 64.84%, op_acc: 32.03%] [G loss: 1.076445]\n",
      "epoch:2 step:1838[D loss: 0.436564, acc: 62.50%, op_acc: 34.38%] [G loss: 1.074043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1839[D loss: 0.500819, acc: 57.81%, op_acc: 22.66%] [G loss: 0.951656]\n",
      "epoch:2 step:1840[D loss: 0.467676, acc: 65.62%, op_acc: 26.56%] [G loss: 1.020972]\n",
      "epoch:2 step:1841[D loss: 0.465590, acc: 58.59%, op_acc: 28.91%] [G loss: 0.969684]\n",
      "epoch:2 step:1842[D loss: 0.450729, acc: 58.59%, op_acc: 32.81%] [G loss: 1.048725]\n",
      "epoch:2 step:1843[D loss: 0.476119, acc: 58.59%, op_acc: 26.56%] [G loss: 0.994889]\n",
      "epoch:2 step:1844[D loss: 0.487655, acc: 55.47%, op_acc: 25.78%] [G loss: 0.916003]\n",
      "epoch:2 step:1845[D loss: 0.443426, acc: 61.72%, op_acc: 26.56%] [G loss: 1.046452]\n",
      "epoch:2 step:1846[D loss: 0.480405, acc: 60.94%, op_acc: 27.34%] [G loss: 1.035597]\n",
      "epoch:2 step:1847[D loss: 0.434856, acc: 65.62%, op_acc: 30.47%] [G loss: 1.157158]\n",
      "epoch:2 step:1848[D loss: 0.427642, acc: 69.53%, op_acc: 32.81%] [G loss: 1.066375]\n",
      "epoch:2 step:1849[D loss: 0.486807, acc: 57.81%, op_acc: 30.47%] [G loss: 1.050674]\n",
      "epoch:2 step:1850[D loss: 0.461459, acc: 62.50%, op_acc: 26.56%] [G loss: 1.032578]\n",
      "epoch:2 step:1851[D loss: 0.451568, acc: 61.72%, op_acc: 27.34%] [G loss: 1.005636]\n",
      "epoch:2 step:1852[D loss: 0.477449, acc: 58.59%, op_acc: 33.59%] [G loss: 0.964658]\n",
      "epoch:2 step:1853[D loss: 0.484837, acc: 57.03%, op_acc: 28.91%] [G loss: 0.912194]\n",
      "epoch:2 step:1854[D loss: 0.446586, acc: 64.84%, op_acc: 24.22%] [G loss: 0.994253]\n",
      "epoch:2 step:1855[D loss: 0.426196, acc: 68.75%, op_acc: 31.25%] [G loss: 1.022123]\n",
      "epoch:2 step:1856[D loss: 0.485562, acc: 61.72%, op_acc: 28.12%] [G loss: 1.028176]\n",
      "epoch:2 step:1857[D loss: 0.489349, acc: 50.00%, op_acc: 30.47%] [G loss: 0.946584]\n",
      "epoch:2 step:1858[D loss: 0.456390, acc: 59.38%, op_acc: 36.72%] [G loss: 1.030370]\n",
      "epoch:2 step:1859[D loss: 0.454731, acc: 60.16%, op_acc: 35.94%] [G loss: 1.004136]\n",
      "epoch:2 step:1860[D loss: 0.436442, acc: 66.41%, op_acc: 36.72%] [G loss: 1.125061]\n",
      "epoch:2 step:1861[D loss: 0.473013, acc: 60.16%, op_acc: 25.78%] [G loss: 0.946843]\n",
      "epoch:2 step:1862[D loss: 0.472999, acc: 64.06%, op_acc: 31.25%] [G loss: 0.971873]\n",
      "epoch:2 step:1863[D loss: 0.459129, acc: 64.06%, op_acc: 23.44%] [G loss: 1.097389]\n",
      "epoch:2 step:1864[D loss: 0.429529, acc: 63.28%, op_acc: 26.56%] [G loss: 0.976220]\n",
      "epoch:2 step:1865[D loss: 0.462531, acc: 60.16%, op_acc: 26.56%] [G loss: 0.987620]\n",
      "epoch:2 step:1866[D loss: 0.461232, acc: 56.25%, op_acc: 28.91%] [G loss: 0.996046]\n",
      "epoch:2 step:1867[D loss: 0.482360, acc: 53.91%, op_acc: 30.47%] [G loss: 1.097323]\n",
      "epoch:2 step:1868[D loss: 0.441608, acc: 67.97%, op_acc: 33.59%] [G loss: 1.150923]\n",
      "epoch:2 step:1869[D loss: 0.427633, acc: 61.72%, op_acc: 32.81%] [G loss: 1.103832]\n",
      "epoch:2 step:1870[D loss: 0.460744, acc: 64.06%, op_acc: 25.00%] [G loss: 0.966462]\n",
      "epoch:2 step:1871[D loss: 0.485547, acc: 62.50%, op_acc: 26.56%] [G loss: 0.998102]\n",
      "epoch:2 step:1872[D loss: 0.463620, acc: 63.28%, op_acc: 25.78%] [G loss: 1.042559]\n",
      "epoch:2 step:1873[D loss: 0.458509, acc: 61.72%, op_acc: 28.91%] [G loss: 1.010049]\n",
      "epoch:2 step:1874[D loss: 0.479973, acc: 53.91%, op_acc: 28.12%] [G loss: 0.964713]\n",
      "epoch:2 step:1875[D loss: 0.476613, acc: 64.84%, op_acc: 32.81%] [G loss: 1.039118]\n",
      "epoch:2 step:1876[D loss: 0.457033, acc: 62.50%, op_acc: 25.78%] [G loss: 1.103677]\n",
      "epoch:2 step:1877[D loss: 0.467661, acc: 58.59%, op_acc: 25.78%] [G loss: 0.990651]\n",
      "epoch:2 step:1878[D loss: 0.476458, acc: 57.03%, op_acc: 27.34%] [G loss: 0.935845]\n",
      "epoch:2 step:1879[D loss: 0.493741, acc: 49.22%, op_acc: 25.78%] [G loss: 0.887159]\n",
      "epoch:2 step:1880[D loss: 0.452542, acc: 59.38%, op_acc: 28.91%] [G loss: 1.048067]\n",
      "epoch:2 step:1881[D loss: 0.492380, acc: 52.34%, op_acc: 29.69%] [G loss: 1.028460]\n",
      "epoch:2 step:1882[D loss: 0.485159, acc: 62.50%, op_acc: 28.91%] [G loss: 1.135049]\n",
      "epoch:2 step:1883[D loss: 0.469170, acc: 61.72%, op_acc: 30.47%] [G loss: 1.150997]\n",
      "epoch:2 step:1884[D loss: 0.489111, acc: 53.91%, op_acc: 32.81%] [G loss: 1.147988]\n",
      "epoch:2 step:1885[D loss: 0.444992, acc: 64.84%, op_acc: 29.69%] [G loss: 1.205520]\n",
      "epoch:2 step:1886[D loss: 0.432593, acc: 67.19%, op_acc: 28.91%] [G loss: 1.161584]\n",
      "epoch:2 step:1887[D loss: 0.457551, acc: 68.75%, op_acc: 32.81%] [G loss: 1.221816]\n",
      "epoch:2 step:1888[D loss: 0.432147, acc: 67.19%, op_acc: 28.91%] [G loss: 1.069123]\n",
      "epoch:2 step:1889[D loss: 0.460675, acc: 62.50%, op_acc: 37.50%] [G loss: 1.137924]\n",
      "epoch:2 step:1890[D loss: 0.435260, acc: 64.06%, op_acc: 31.25%] [G loss: 1.054060]\n",
      "epoch:2 step:1891[D loss: 0.439674, acc: 61.72%, op_acc: 31.25%] [G loss: 1.157536]\n",
      "epoch:2 step:1892[D loss: 0.497172, acc: 58.59%, op_acc: 32.81%] [G loss: 1.064523]\n",
      "epoch:2 step:1893[D loss: 0.445745, acc: 68.75%, op_acc: 32.03%] [G loss: 0.960967]\n",
      "epoch:2 step:1894[D loss: 0.436081, acc: 66.41%, op_acc: 29.69%] [G loss: 1.149888]\n",
      "epoch:2 step:1895[D loss: 0.471983, acc: 61.72%, op_acc: 22.66%] [G loss: 1.007965]\n",
      "epoch:2 step:1896[D loss: 0.462223, acc: 58.59%, op_acc: 38.28%] [G loss: 1.185730]\n",
      "epoch:2 step:1897[D loss: 0.445911, acc: 65.62%, op_acc: 30.47%] [G loss: 1.036986]\n",
      "epoch:2 step:1898[D loss: 0.469950, acc: 64.84%, op_acc: 29.69%] [G loss: 1.017039]\n",
      "epoch:2 step:1899[D loss: 0.474204, acc: 61.72%, op_acc: 33.59%] [G loss: 1.125541]\n",
      "epoch:2 step:1900[D loss: 0.425814, acc: 61.72%, op_acc: 32.81%] [G loss: 1.124352]\n",
      "epoch:2 step:1901[D loss: 0.443126, acc: 63.28%, op_acc: 34.38%] [G loss: 1.006006]\n",
      "epoch:2 step:1902[D loss: 0.451382, acc: 64.84%, op_acc: 28.12%] [G loss: 1.001353]\n",
      "epoch:2 step:1903[D loss: 0.485302, acc: 64.06%, op_acc: 31.25%] [G loss: 0.951432]\n",
      "epoch:2 step:1904[D loss: 0.474745, acc: 60.94%, op_acc: 23.44%] [G loss: 1.060884]\n",
      "epoch:2 step:1905[D loss: 0.482432, acc: 58.59%, op_acc: 31.25%] [G loss: 1.000717]\n",
      "epoch:2 step:1906[D loss: 0.456640, acc: 60.16%, op_acc: 25.00%] [G loss: 0.957370]\n",
      "epoch:2 step:1907[D loss: 0.483668, acc: 56.25%, op_acc: 30.47%] [G loss: 1.029028]\n",
      "epoch:2 step:1908[D loss: 0.471336, acc: 60.16%, op_acc: 28.12%] [G loss: 0.989036]\n",
      "epoch:2 step:1909[D loss: 0.505253, acc: 50.00%, op_acc: 30.47%] [G loss: 1.012201]\n",
      "epoch:2 step:1910[D loss: 0.457285, acc: 60.16%, op_acc: 30.47%] [G loss: 1.044502]\n",
      "epoch:2 step:1911[D loss: 0.466173, acc: 62.50%, op_acc: 28.91%] [G loss: 1.171019]\n",
      "epoch:2 step:1912[D loss: 0.451234, acc: 60.94%, op_acc: 28.91%] [G loss: 1.084903]\n",
      "epoch:2 step:1913[D loss: 0.463641, acc: 59.38%, op_acc: 28.12%] [G loss: 1.062094]\n",
      "epoch:2 step:1914[D loss: 0.462529, acc: 63.28%, op_acc: 25.00%] [G loss: 0.870529]\n",
      "epoch:2 step:1915[D loss: 0.461528, acc: 61.72%, op_acc: 29.69%] [G loss: 0.979963]\n",
      "epoch:2 step:1916[D loss: 0.465761, acc: 59.38%, op_acc: 27.34%] [G loss: 1.069980]\n",
      "epoch:2 step:1917[D loss: 0.479533, acc: 56.25%, op_acc: 29.69%] [G loss: 0.951396]\n",
      "epoch:2 step:1918[D loss: 0.446889, acc: 63.28%, op_acc: 30.47%] [G loss: 1.055752]\n",
      "epoch:2 step:1919[D loss: 0.463689, acc: 58.59%, op_acc: 32.03%] [G loss: 0.974730]\n",
      "epoch:2 step:1920[D loss: 0.477444, acc: 57.81%, op_acc: 26.56%] [G loss: 1.016320]\n",
      "epoch:2 step:1921[D loss: 0.458246, acc: 60.16%, op_acc: 28.12%] [G loss: 1.036873]\n",
      "epoch:2 step:1922[D loss: 0.491041, acc: 54.69%, op_acc: 26.56%] [G loss: 1.055094]\n",
      "epoch:2 step:1923[D loss: 0.456672, acc: 64.84%, op_acc: 33.59%] [G loss: 1.058727]\n",
      "epoch:2 step:1924[D loss: 0.461564, acc: 54.69%, op_acc: 32.81%] [G loss: 1.132270]\n",
      "epoch:2 step:1925[D loss: 0.488528, acc: 58.59%, op_acc: 27.34%] [G loss: 0.977323]\n",
      "epoch:2 step:1926[D loss: 0.440457, acc: 67.19%, op_acc: 32.03%] [G loss: 1.024438]\n",
      "epoch:2 step:1927[D loss: 0.451480, acc: 63.28%, op_acc: 30.47%] [G loss: 0.994033]\n",
      "epoch:2 step:1928[D loss: 0.428797, acc: 70.31%, op_acc: 33.59%] [G loss: 1.046908]\n",
      "epoch:2 step:1929[D loss: 0.473871, acc: 64.84%, op_acc: 28.91%] [G loss: 1.007652]\n",
      "epoch:2 step:1930[D loss: 0.480451, acc: 54.69%, op_acc: 29.69%] [G loss: 0.968301]\n",
      "epoch:2 step:1931[D loss: 0.464945, acc: 62.50%, op_acc: 30.47%] [G loss: 0.962729]\n",
      "epoch:2 step:1932[D loss: 0.466053, acc: 60.94%, op_acc: 22.66%] [G loss: 0.930283]\n",
      "epoch:2 step:1933[D loss: 0.438977, acc: 57.03%, op_acc: 32.81%] [G loss: 1.012966]\n",
      "epoch:2 step:1934[D loss: 0.483756, acc: 54.69%, op_acc: 25.00%] [G loss: 0.951118]\n",
      "epoch:2 step:1935[D loss: 0.441822, acc: 61.72%, op_acc: 32.03%] [G loss: 1.063192]\n",
      "epoch:2 step:1936[D loss: 0.477480, acc: 57.81%, op_acc: 35.16%] [G loss: 1.042655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1937[D loss: 0.465586, acc: 60.16%, op_acc: 25.00%] [G loss: 1.111814]\n",
      "epoch:2 step:1938[D loss: 0.464942, acc: 57.81%, op_acc: 28.91%] [G loss: 1.029108]\n",
      "epoch:2 step:1939[D loss: 0.451827, acc: 65.62%, op_acc: 31.25%] [G loss: 0.910325]\n",
      "epoch:2 step:1940[D loss: 0.424542, acc: 62.50%, op_acc: 32.81%] [G loss: 1.114357]\n",
      "epoch:2 step:1941[D loss: 0.444388, acc: 60.94%, op_acc: 30.47%] [G loss: 0.978943]\n",
      "epoch:2 step:1942[D loss: 0.471137, acc: 63.28%, op_acc: 27.34%] [G loss: 1.002107]\n",
      "epoch:2 step:1943[D loss: 0.501164, acc: 51.56%, op_acc: 32.03%] [G loss: 1.164874]\n",
      "epoch:2 step:1944[D loss: 0.405358, acc: 70.31%, op_acc: 34.38%] [G loss: 1.174195]\n",
      "epoch:2 step:1945[D loss: 0.458650, acc: 64.06%, op_acc: 28.12%] [G loss: 0.980801]\n",
      "epoch:2 step:1946[D loss: 0.446711, acc: 64.84%, op_acc: 31.25%] [G loss: 0.988302]\n",
      "epoch:2 step:1947[D loss: 0.422088, acc: 66.41%, op_acc: 32.81%] [G loss: 1.105319]\n",
      "epoch:2 step:1948[D loss: 0.439550, acc: 64.84%, op_acc: 27.34%] [G loss: 0.984028]\n",
      "epoch:2 step:1949[D loss: 0.460253, acc: 64.06%, op_acc: 27.34%] [G loss: 0.974775]\n",
      "epoch:2 step:1950[D loss: 0.472724, acc: 62.50%, op_acc: 23.44%] [G loss: 1.061896]\n",
      "epoch:2 step:1951[D loss: 0.454086, acc: 64.06%, op_acc: 29.69%] [G loss: 1.163411]\n",
      "epoch:2 step:1952[D loss: 0.434103, acc: 64.06%, op_acc: 32.03%] [G loss: 1.041915]\n",
      "epoch:2 step:1953[D loss: 0.468968, acc: 56.25%, op_acc: 26.56%] [G loss: 0.967013]\n",
      "epoch:2 step:1954[D loss: 0.422033, acc: 67.19%, op_acc: 30.47%] [G loss: 1.053201]\n",
      "epoch:2 step:1955[D loss: 0.438918, acc: 63.28%, op_acc: 28.91%] [G loss: 1.091737]\n",
      "epoch:2 step:1956[D loss: 0.443616, acc: 63.28%, op_acc: 30.47%] [G loss: 0.942889]\n",
      "epoch:2 step:1957[D loss: 0.462700, acc: 63.28%, op_acc: 20.31%] [G loss: 1.171747]\n",
      "epoch:2 step:1958[D loss: 0.428984, acc: 63.28%, op_acc: 39.06%] [G loss: 1.081485]\n",
      "epoch:2 step:1959[D loss: 0.495327, acc: 52.34%, op_acc: 32.81%] [G loss: 0.988071]\n",
      "epoch:2 step:1960[D loss: 0.487984, acc: 58.59%, op_acc: 21.09%] [G loss: 0.977343]\n",
      "epoch:2 step:1961[D loss: 0.449620, acc: 62.50%, op_acc: 32.81%] [G loss: 0.955745]\n",
      "epoch:2 step:1962[D loss: 0.453369, acc: 63.28%, op_acc: 29.69%] [G loss: 1.096981]\n",
      "epoch:2 step:1963[D loss: 0.434518, acc: 69.53%, op_acc: 35.94%] [G loss: 1.035124]\n",
      "epoch:2 step:1964[D loss: 0.459980, acc: 57.81%, op_acc: 35.94%] [G loss: 1.054556]\n",
      "epoch:2 step:1965[D loss: 0.481312, acc: 57.03%, op_acc: 25.00%] [G loss: 0.970670]\n",
      "epoch:2 step:1966[D loss: 0.467461, acc: 55.47%, op_acc: 33.59%] [G loss: 1.044248]\n",
      "epoch:2 step:1967[D loss: 0.486830, acc: 61.72%, op_acc: 25.00%] [G loss: 1.008940]\n",
      "epoch:2 step:1968[D loss: 0.462994, acc: 59.38%, op_acc: 30.47%] [G loss: 0.995864]\n",
      "epoch:2 step:1969[D loss: 0.428730, acc: 64.06%, op_acc: 28.91%] [G loss: 0.954730]\n",
      "epoch:2 step:1970[D loss: 0.442504, acc: 63.28%, op_acc: 30.47%] [G loss: 1.010492]\n",
      "epoch:2 step:1971[D loss: 0.503457, acc: 52.34%, op_acc: 22.66%] [G loss: 1.051442]\n",
      "epoch:2 step:1972[D loss: 0.437693, acc: 64.06%, op_acc: 33.59%] [G loss: 0.967621]\n",
      "epoch:2 step:1973[D loss: 0.471449, acc: 59.38%, op_acc: 29.69%] [G loss: 1.019129]\n",
      "epoch:2 step:1974[D loss: 0.444704, acc: 64.06%, op_acc: 30.47%] [G loss: 1.131745]\n",
      "epoch:2 step:1975[D loss: 0.480364, acc: 59.38%, op_acc: 31.25%] [G loss: 0.963108]\n",
      "epoch:2 step:1976[D loss: 0.525230, acc: 52.34%, op_acc: 28.12%] [G loss: 0.955331]\n",
      "epoch:2 step:1977[D loss: 0.484426, acc: 53.91%, op_acc: 31.25%] [G loss: 0.877093]\n",
      "epoch:2 step:1978[D loss: 0.445647, acc: 60.94%, op_acc: 30.47%] [G loss: 0.945222]\n",
      "epoch:2 step:1979[D loss: 0.496461, acc: 56.25%, op_acc: 25.78%] [G loss: 0.974101]\n",
      "epoch:2 step:1980[D loss: 0.412548, acc: 70.31%, op_acc: 29.69%] [G loss: 0.992575]\n",
      "epoch:2 step:1981[D loss: 0.454963, acc: 63.28%, op_acc: 30.47%] [G loss: 1.112961]\n",
      "epoch:2 step:1982[D loss: 0.454937, acc: 69.53%, op_acc: 29.69%] [G loss: 1.027405]\n",
      "epoch:2 step:1983[D loss: 0.454360, acc: 61.72%, op_acc: 33.59%] [G loss: 1.033429]\n",
      "epoch:2 step:1984[D loss: 0.414088, acc: 68.75%, op_acc: 34.38%] [G loss: 1.110360]\n",
      "epoch:2 step:1985[D loss: 0.473206, acc: 61.72%, op_acc: 25.00%] [G loss: 1.034282]\n",
      "epoch:2 step:1986[D loss: 0.431107, acc: 65.62%, op_acc: 28.91%] [G loss: 1.029916]\n",
      "epoch:2 step:1987[D loss: 0.458772, acc: 57.81%, op_acc: 30.47%] [G loss: 0.955044]\n",
      "epoch:2 step:1988[D loss: 0.464001, acc: 64.84%, op_acc: 27.34%] [G loss: 0.980629]\n",
      "epoch:2 step:1989[D loss: 0.447388, acc: 62.50%, op_acc: 29.69%] [G loss: 1.033982]\n",
      "epoch:2 step:1990[D loss: 0.482275, acc: 55.47%, op_acc: 31.25%] [G loss: 1.017830]\n",
      "epoch:2 step:1991[D loss: 0.454151, acc: 62.50%, op_acc: 30.47%] [G loss: 0.952077]\n",
      "epoch:2 step:1992[D loss: 0.459234, acc: 64.84%, op_acc: 29.69%] [G loss: 0.973784]\n",
      "epoch:2 step:1993[D loss: 0.445083, acc: 64.84%, op_acc: 31.25%] [G loss: 1.006510]\n",
      "epoch:2 step:1994[D loss: 0.449139, acc: 60.16%, op_acc: 28.91%] [G loss: 0.987277]\n",
      "epoch:2 step:1995[D loss: 0.468388, acc: 63.28%, op_acc: 25.78%] [G loss: 0.885319]\n",
      "epoch:2 step:1996[D loss: 0.456860, acc: 63.28%, op_acc: 35.16%] [G loss: 0.978977]\n",
      "epoch:2 step:1997[D loss: 0.464522, acc: 59.38%, op_acc: 30.47%] [G loss: 0.965251]\n",
      "epoch:2 step:1998[D loss: 0.484358, acc: 60.94%, op_acc: 27.34%] [G loss: 0.974037]\n",
      "epoch:2 step:1999[D loss: 0.493056, acc: 51.56%, op_acc: 28.12%] [G loss: 0.953906]\n",
      "epoch:2 step:2000[D loss: 0.475947, acc: 61.72%, op_acc: 29.69%] [G loss: 0.910388]\n",
      "epoch:2 step:2001[D loss: 0.442715, acc: 61.72%, op_acc: 35.16%] [G loss: 1.018688]\n",
      "epoch:2 step:2002[D loss: 0.464070, acc: 59.38%, op_acc: 29.69%] [G loss: 1.083334]\n",
      "epoch:2 step:2003[D loss: 0.487659, acc: 50.78%, op_acc: 32.81%] [G loss: 0.910364]\n",
      "epoch:2 step:2004[D loss: 0.411725, acc: 71.09%, op_acc: 35.16%] [G loss: 0.923460]\n",
      "epoch:2 step:2005[D loss: 0.469135, acc: 63.28%, op_acc: 27.34%] [G loss: 1.072993]\n",
      "epoch:2 step:2006[D loss: 0.463604, acc: 59.38%, op_acc: 28.12%] [G loss: 0.962450]\n",
      "epoch:2 step:2007[D loss: 0.455061, acc: 60.16%, op_acc: 32.03%] [G loss: 0.991273]\n",
      "epoch:2 step:2008[D loss: 0.507818, acc: 56.25%, op_acc: 33.59%] [G loss: 1.029887]\n",
      "epoch:2 step:2009[D loss: 0.465991, acc: 65.62%, op_acc: 27.34%] [G loss: 1.039283]\n",
      "epoch:2 step:2010[D loss: 0.447416, acc: 57.03%, op_acc: 34.38%] [G loss: 0.967774]\n",
      "epoch:2 step:2011[D loss: 0.437764, acc: 61.72%, op_acc: 30.47%] [G loss: 0.975907]\n",
      "epoch:2 step:2012[D loss: 0.466778, acc: 61.72%, op_acc: 28.12%] [G loss: 1.045609]\n",
      "epoch:2 step:2013[D loss: 0.439024, acc: 59.38%, op_acc: 35.16%] [G loss: 1.061712]\n",
      "epoch:2 step:2014[D loss: 0.390270, acc: 71.09%, op_acc: 35.16%] [G loss: 0.927968]\n",
      "epoch:2 step:2015[D loss: 0.437203, acc: 64.84%, op_acc: 35.94%] [G loss: 1.006652]\n",
      "epoch:2 step:2016[D loss: 0.420036, acc: 75.00%, op_acc: 22.66%] [G loss: 1.117018]\n",
      "epoch:2 step:2017[D loss: 0.425931, acc: 74.22%, op_acc: 33.59%] [G loss: 1.084483]\n",
      "epoch:2 step:2018[D loss: 0.422673, acc: 68.75%, op_acc: 31.25%] [G loss: 1.117999]\n",
      "epoch:2 step:2019[D loss: 0.410024, acc: 74.22%, op_acc: 39.06%] [G loss: 1.142713]\n",
      "epoch:2 step:2020[D loss: 0.467998, acc: 57.03%, op_acc: 30.47%] [G loss: 1.046130]\n",
      "epoch:2 step:2021[D loss: 0.468855, acc: 52.34%, op_acc: 28.91%] [G loss: 0.993017]\n",
      "epoch:2 step:2022[D loss: 0.430169, acc: 70.31%, op_acc: 32.03%] [G loss: 1.118915]\n",
      "epoch:2 step:2023[D loss: 0.447412, acc: 67.19%, op_acc: 21.88%] [G loss: 1.011652]\n",
      "epoch:2 step:2024[D loss: 0.456880, acc: 64.84%, op_acc: 34.38%] [G loss: 0.962003]\n",
      "epoch:2 step:2025[D loss: 0.461853, acc: 59.38%, op_acc: 34.38%] [G loss: 0.961173]\n",
      "epoch:2 step:2026[D loss: 0.418491, acc: 68.75%, op_acc: 32.03%] [G loss: 1.242170]\n",
      "epoch:2 step:2027[D loss: 0.419736, acc: 71.88%, op_acc: 29.69%] [G loss: 1.104574]\n",
      "epoch:2 step:2028[D loss: 0.405049, acc: 75.00%, op_acc: 29.69%] [G loss: 1.168491]\n",
      "epoch:2 step:2029[D loss: 0.467954, acc: 61.72%, op_acc: 28.91%] [G loss: 0.981745]\n",
      "epoch:2 step:2030[D loss: 0.453561, acc: 62.50%, op_acc: 25.78%] [G loss: 0.991224]\n",
      "epoch:2 step:2031[D loss: 0.467087, acc: 58.59%, op_acc: 27.34%] [G loss: 0.979121]\n",
      "epoch:2 step:2032[D loss: 0.475441, acc: 60.94%, op_acc: 28.91%] [G loss: 0.968369]\n",
      "epoch:2 step:2033[D loss: 0.491702, acc: 56.25%, op_acc: 26.56%] [G loss: 0.971836]\n",
      "epoch:2 step:2034[D loss: 0.476446, acc: 61.72%, op_acc: 24.22%] [G loss: 0.918384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2035[D loss: 0.456006, acc: 55.47%, op_acc: 38.28%] [G loss: 1.083638]\n",
      "epoch:2 step:2036[D loss: 0.453767, acc: 63.28%, op_acc: 33.59%] [G loss: 1.140828]\n",
      "epoch:2 step:2037[D loss: 0.445205, acc: 62.50%, op_acc: 37.50%] [G loss: 1.158940]\n",
      "epoch:2 step:2038[D loss: 0.485483, acc: 60.94%, op_acc: 27.34%] [G loss: 1.009578]\n",
      "epoch:2 step:2039[D loss: 0.453668, acc: 57.81%, op_acc: 33.59%] [G loss: 1.042325]\n",
      "epoch:2 step:2040[D loss: 0.470926, acc: 58.59%, op_acc: 33.59%] [G loss: 0.982889]\n",
      "epoch:2 step:2041[D loss: 0.495540, acc: 57.03%, op_acc: 24.22%] [G loss: 1.038488]\n",
      "epoch:2 step:2042[D loss: 0.461232, acc: 61.72%, op_acc: 31.25%] [G loss: 1.060820]\n",
      "epoch:2 step:2043[D loss: 0.471884, acc: 64.06%, op_acc: 27.34%] [G loss: 0.952791]\n",
      "epoch:2 step:2044[D loss: 0.466441, acc: 61.72%, op_acc: 27.34%] [G loss: 1.036248]\n",
      "epoch:2 step:2045[D loss: 0.464844, acc: 61.72%, op_acc: 27.34%] [G loss: 0.973052]\n",
      "epoch:2 step:2046[D loss: 0.460331, acc: 53.12%, op_acc: 35.16%] [G loss: 1.049237]\n",
      "epoch:2 step:2047[D loss: 0.467535, acc: 61.72%, op_acc: 27.34%] [G loss: 0.885919]\n",
      "epoch:2 step:2048[D loss: 0.431369, acc: 61.72%, op_acc: 36.72%] [G loss: 0.944456]\n",
      "epoch:2 step:2049[D loss: 0.503055, acc: 56.25%, op_acc: 26.56%] [G loss: 0.963864]\n",
      "epoch:2 step:2050[D loss: 0.478079, acc: 58.59%, op_acc: 32.03%] [G loss: 0.917308]\n",
      "epoch:2 step:2051[D loss: 0.453500, acc: 66.41%, op_acc: 32.81%] [G loss: 0.973427]\n",
      "epoch:2 step:2052[D loss: 0.451234, acc: 58.59%, op_acc: 37.50%] [G loss: 0.987064]\n",
      "epoch:2 step:2053[D loss: 0.477978, acc: 60.94%, op_acc: 29.69%] [G loss: 0.952592]\n",
      "epoch:2 step:2054[D loss: 0.481720, acc: 57.81%, op_acc: 30.47%] [G loss: 1.034846]\n",
      "epoch:2 step:2055[D loss: 0.453305, acc: 59.38%, op_acc: 32.03%] [G loss: 0.944294]\n",
      "epoch:2 step:2056[D loss: 0.476085, acc: 65.62%, op_acc: 28.12%] [G loss: 0.949235]\n",
      "epoch:2 step:2057[D loss: 0.461297, acc: 62.50%, op_acc: 30.47%] [G loss: 0.946063]\n",
      "epoch:2 step:2058[D loss: 0.448216, acc: 66.41%, op_acc: 25.00%] [G loss: 0.967250]\n",
      "epoch:2 step:2059[D loss: 0.443853, acc: 64.06%, op_acc: 30.47%] [G loss: 0.976123]\n",
      "epoch:2 step:2060[D loss: 0.496656, acc: 57.81%, op_acc: 25.00%] [G loss: 0.995028]\n",
      "epoch:2 step:2061[D loss: 0.456380, acc: 64.06%, op_acc: 32.03%] [G loss: 1.013358]\n",
      "epoch:2 step:2062[D loss: 0.449589, acc: 68.75%, op_acc: 35.16%] [G loss: 1.043459]\n",
      "epoch:2 step:2063[D loss: 0.480181, acc: 61.72%, op_acc: 32.03%] [G loss: 0.994205]\n",
      "epoch:2 step:2064[D loss: 0.500028, acc: 56.25%, op_acc: 25.00%] [G loss: 0.866368]\n",
      "epoch:2 step:2065[D loss: 0.460436, acc: 64.06%, op_acc: 25.78%] [G loss: 1.025211]\n",
      "epoch:2 step:2066[D loss: 0.441193, acc: 64.84%, op_acc: 37.50%] [G loss: 1.028058]\n",
      "epoch:2 step:2067[D loss: 0.434721, acc: 71.88%, op_acc: 29.69%] [G loss: 1.020489]\n",
      "epoch:2 step:2068[D loss: 0.414538, acc: 69.53%, op_acc: 36.72%] [G loss: 0.994185]\n",
      "epoch:2 step:2069[D loss: 0.416489, acc: 70.31%, op_acc: 34.38%] [G loss: 1.211674]\n",
      "epoch:2 step:2070[D loss: 0.484572, acc: 51.56%, op_acc: 32.81%] [G loss: 1.022716]\n",
      "epoch:2 step:2071[D loss: 0.470861, acc: 60.16%, op_acc: 26.56%] [G loss: 0.949312]\n",
      "epoch:2 step:2072[D loss: 0.470281, acc: 57.03%, op_acc: 32.03%] [G loss: 1.002481]\n",
      "epoch:2 step:2073[D loss: 0.468892, acc: 65.62%, op_acc: 30.47%] [G loss: 0.984708]\n",
      "epoch:2 step:2074[D loss: 0.480279, acc: 56.25%, op_acc: 31.25%] [G loss: 1.030679]\n",
      "epoch:2 step:2075[D loss: 0.484366, acc: 58.59%, op_acc: 29.69%] [G loss: 0.960943]\n",
      "epoch:2 step:2076[D loss: 0.465105, acc: 61.72%, op_acc: 35.94%] [G loss: 0.988489]\n",
      "epoch:2 step:2077[D loss: 0.460185, acc: 63.28%, op_acc: 27.34%] [G loss: 0.972782]\n",
      "epoch:2 step:2078[D loss: 0.452170, acc: 63.28%, op_acc: 31.25%] [G loss: 0.913725]\n",
      "epoch:2 step:2079[D loss: 0.514854, acc: 54.69%, op_acc: 28.91%] [G loss: 0.843996]\n",
      "epoch:2 step:2080[D loss: 0.463581, acc: 56.25%, op_acc: 32.03%] [G loss: 0.945547]\n",
      "epoch:2 step:2081[D loss: 0.450539, acc: 61.72%, op_acc: 31.25%] [G loss: 1.010040]\n",
      "epoch:2 step:2082[D loss: 0.507354, acc: 54.69%, op_acc: 25.00%] [G loss: 1.031501]\n",
      "epoch:2 step:2083[D loss: 0.499189, acc: 52.34%, op_acc: 27.34%] [G loss: 0.978190]\n",
      "epoch:2 step:2084[D loss: 0.455937, acc: 64.06%, op_acc: 25.00%] [G loss: 1.046937]\n",
      "epoch:2 step:2085[D loss: 0.511907, acc: 48.44%, op_acc: 28.91%] [G loss: 0.966001]\n",
      "epoch:2 step:2086[D loss: 0.444186, acc: 59.38%, op_acc: 30.47%] [G loss: 1.027526]\n",
      "epoch:2 step:2087[D loss: 0.481517, acc: 60.94%, op_acc: 23.44%] [G loss: 0.997015]\n",
      "epoch:2 step:2088[D loss: 0.499370, acc: 60.16%, op_acc: 24.22%] [G loss: 1.061666]\n",
      "epoch:2 step:2089[D loss: 0.472419, acc: 64.84%, op_acc: 25.00%] [G loss: 0.982506]\n",
      "epoch:2 step:2090[D loss: 0.475852, acc: 53.12%, op_acc: 29.69%] [G loss: 0.992696]\n",
      "epoch:2 step:2091[D loss: 0.452995, acc: 60.94%, op_acc: 32.03%] [G loss: 1.003681]\n",
      "epoch:2 step:2092[D loss: 0.443122, acc: 67.19%, op_acc: 28.12%] [G loss: 1.119638]\n",
      "epoch:2 step:2093[D loss: 0.463275, acc: 58.59%, op_acc: 32.03%] [G loss: 1.003514]\n",
      "epoch:2 step:2094[D loss: 0.459922, acc: 63.28%, op_acc: 26.56%] [G loss: 1.150981]\n",
      "epoch:2 step:2095[D loss: 0.475928, acc: 60.16%, op_acc: 32.81%] [G loss: 0.987114]\n",
      "epoch:2 step:2096[D loss: 0.475595, acc: 55.47%, op_acc: 32.03%] [G loss: 1.025717]\n",
      "epoch:2 step:2097[D loss: 0.481823, acc: 51.56%, op_acc: 27.34%] [G loss: 0.931889]\n",
      "epoch:2 step:2098[D loss: 0.445789, acc: 57.03%, op_acc: 33.59%] [G loss: 0.998984]\n",
      "epoch:2 step:2099[D loss: 0.494665, acc: 57.81%, op_acc: 25.78%] [G loss: 0.908934]\n",
      "epoch:2 step:2100[D loss: 0.453454, acc: 60.16%, op_acc: 36.72%] [G loss: 0.907973]\n",
      "epoch:2 step:2101[D loss: 0.473300, acc: 55.47%, op_acc: 21.88%] [G loss: 0.911583]\n",
      "epoch:2 step:2102[D loss: 0.429608, acc: 63.28%, op_acc: 32.03%] [G loss: 0.958192]\n",
      "epoch:2 step:2103[D loss: 0.421443, acc: 71.09%, op_acc: 31.25%] [G loss: 0.952822]\n",
      "epoch:2 step:2104[D loss: 0.489625, acc: 54.69%, op_acc: 27.34%] [G loss: 0.862135]\n",
      "epoch:2 step:2105[D loss: 0.444305, acc: 62.50%, op_acc: 32.03%] [G loss: 1.074104]\n",
      "epoch:2 step:2106[D loss: 0.418014, acc: 67.19%, op_acc: 33.59%] [G loss: 1.059365]\n",
      "epoch:2 step:2107[D loss: 0.422962, acc: 66.41%, op_acc: 34.38%] [G loss: 1.137140]\n",
      "epoch:2 step:2108[D loss: 0.483155, acc: 56.25%, op_acc: 31.25%] [G loss: 1.012838]\n",
      "epoch:2 step:2109[D loss: 0.489294, acc: 61.72%, op_acc: 23.44%] [G loss: 0.948622]\n",
      "epoch:2 step:2110[D loss: 0.464529, acc: 58.59%, op_acc: 32.03%] [G loss: 1.049053]\n",
      "epoch:2 step:2111[D loss: 0.471377, acc: 58.59%, op_acc: 28.12%] [G loss: 1.093077]\n",
      "epoch:2 step:2112[D loss: 0.433646, acc: 64.84%, op_acc: 33.59%] [G loss: 1.056849]\n",
      "epoch:2 step:2113[D loss: 0.475678, acc: 56.25%, op_acc: 35.16%] [G loss: 0.953294]\n",
      "epoch:2 step:2114[D loss: 0.486938, acc: 64.84%, op_acc: 26.56%] [G loss: 1.017125]\n",
      "epoch:2 step:2115[D loss: 0.417433, acc: 67.19%, op_acc: 29.69%] [G loss: 1.023503]\n",
      "epoch:2 step:2116[D loss: 0.460531, acc: 66.41%, op_acc: 22.66%] [G loss: 1.052403]\n",
      "epoch:2 step:2117[D loss: 0.448709, acc: 60.16%, op_acc: 35.16%] [G loss: 1.015170]\n",
      "epoch:2 step:2118[D loss: 0.474496, acc: 55.47%, op_acc: 24.22%] [G loss: 1.018745]\n",
      "epoch:2 step:2119[D loss: 0.475945, acc: 59.38%, op_acc: 26.56%] [G loss: 1.060685]\n",
      "epoch:2 step:2120[D loss: 0.476072, acc: 60.94%, op_acc: 29.69%] [G loss: 1.013175]\n",
      "epoch:2 step:2121[D loss: 0.467030, acc: 59.38%, op_acc: 30.47%] [G loss: 0.981872]\n",
      "epoch:2 step:2122[D loss: 0.526506, acc: 53.12%, op_acc: 25.78%] [G loss: 0.934665]\n",
      "epoch:2 step:2123[D loss: 0.467784, acc: 60.16%, op_acc: 24.22%] [G loss: 0.850242]\n",
      "epoch:2 step:2124[D loss: 0.447291, acc: 57.81%, op_acc: 25.00%] [G loss: 0.964205]\n",
      "epoch:2 step:2125[D loss: 0.484963, acc: 50.00%, op_acc: 31.25%] [G loss: 0.925281]\n",
      "epoch:2 step:2126[D loss: 0.447800, acc: 61.72%, op_acc: 32.81%] [G loss: 1.012236]\n",
      "epoch:2 step:2127[D loss: 0.454559, acc: 61.72%, op_acc: 33.59%] [G loss: 1.009461]\n",
      "epoch:2 step:2128[D loss: 0.470324, acc: 60.94%, op_acc: 32.03%] [G loss: 1.104352]\n",
      "epoch:2 step:2129[D loss: 0.441079, acc: 63.28%, op_acc: 35.94%] [G loss: 0.994320]\n",
      "epoch:2 step:2130[D loss: 0.428618, acc: 67.97%, op_acc: 29.69%] [G loss: 1.013543]\n",
      "epoch:2 step:2131[D loss: 0.452235, acc: 64.06%, op_acc: 32.81%] [G loss: 0.959108]\n",
      "epoch:2 step:2132[D loss: 0.445776, acc: 62.50%, op_acc: 32.03%] [G loss: 1.023350]\n",
      "epoch:2 step:2133[D loss: 0.487945, acc: 57.03%, op_acc: 29.69%] [G loss: 0.973716]\n",
      "epoch:2 step:2134[D loss: 0.417448, acc: 68.75%, op_acc: 30.47%] [G loss: 0.982663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2135[D loss: 0.466833, acc: 58.59%, op_acc: 35.94%] [G loss: 0.956745]\n",
      "epoch:2 step:2136[D loss: 0.490050, acc: 58.59%, op_acc: 28.12%] [G loss: 0.948977]\n",
      "epoch:2 step:2137[D loss: 0.428994, acc: 71.09%, op_acc: 28.12%] [G loss: 0.919154]\n",
      "epoch:2 step:2138[D loss: 0.455515, acc: 59.38%, op_acc: 31.25%] [G loss: 0.945178]\n",
      "epoch:2 step:2139[D loss: 0.440933, acc: 64.84%, op_acc: 31.25%] [G loss: 0.891402]\n",
      "epoch:2 step:2140[D loss: 0.453086, acc: 66.41%, op_acc: 28.12%] [G loss: 0.956262]\n",
      "epoch:2 step:2141[D loss: 0.432391, acc: 60.16%, op_acc: 31.25%] [G loss: 1.048769]\n",
      "epoch:2 step:2142[D loss: 0.456869, acc: 60.94%, op_acc: 28.91%] [G loss: 1.020088]\n",
      "epoch:2 step:2143[D loss: 0.469949, acc: 59.38%, op_acc: 25.00%] [G loss: 0.973517]\n",
      "epoch:2 step:2144[D loss: 0.477217, acc: 57.03%, op_acc: 25.00%] [G loss: 0.900591]\n",
      "epoch:2 step:2145[D loss: 0.490909, acc: 51.56%, op_acc: 27.34%] [G loss: 0.896913]\n",
      "epoch:2 step:2146[D loss: 0.474419, acc: 64.84%, op_acc: 26.56%] [G loss: 1.060436]\n",
      "epoch:2 step:2147[D loss: 0.453637, acc: 57.03%, op_acc: 42.19%] [G loss: 1.080195]\n",
      "epoch:2 step:2148[D loss: 0.504684, acc: 53.91%, op_acc: 28.12%] [G loss: 0.877540]\n",
      "epoch:2 step:2149[D loss: 0.427097, acc: 67.19%, op_acc: 23.44%] [G loss: 1.009797]\n",
      "epoch:2 step:2150[D loss: 0.454547, acc: 59.38%, op_acc: 31.25%] [G loss: 0.969709]\n",
      "epoch:2 step:2151[D loss: 0.444415, acc: 65.62%, op_acc: 31.25%] [G loss: 1.028526]\n",
      "epoch:2 step:2152[D loss: 0.501597, acc: 49.22%, op_acc: 29.69%] [G loss: 1.040499]\n",
      "epoch:2 step:2153[D loss: 0.478045, acc: 58.59%, op_acc: 31.25%] [G loss: 0.989508]\n",
      "epoch:2 step:2154[D loss: 0.451016, acc: 61.72%, op_acc: 28.91%] [G loss: 1.008211]\n",
      "epoch:2 step:2155[D loss: 0.474542, acc: 56.25%, op_acc: 30.47%] [G loss: 0.935181]\n",
      "epoch:2 step:2156[D loss: 0.453815, acc: 69.53%, op_acc: 26.56%] [G loss: 1.033352]\n",
      "epoch:2 step:2157[D loss: 0.427950, acc: 67.97%, op_acc: 28.12%] [G loss: 1.042625]\n",
      "epoch:2 step:2158[D loss: 0.477680, acc: 58.59%, op_acc: 29.69%] [G loss: 0.974300]\n",
      "epoch:2 step:2159[D loss: 0.451577, acc: 64.06%, op_acc: 31.25%] [G loss: 1.058193]\n",
      "epoch:2 step:2160[D loss: 0.424134, acc: 72.66%, op_acc: 36.72%] [G loss: 1.033952]\n",
      "epoch:2 step:2161[D loss: 0.446366, acc: 68.75%, op_acc: 32.81%] [G loss: 1.021883]\n",
      "epoch:2 step:2162[D loss: 0.477206, acc: 64.06%, op_acc: 32.03%] [G loss: 1.046254]\n",
      "epoch:2 step:2163[D loss: 0.460990, acc: 61.72%, op_acc: 32.03%] [G loss: 0.955855]\n",
      "epoch:2 step:2164[D loss: 0.399746, acc: 69.53%, op_acc: 35.94%] [G loss: 1.049464]\n",
      "epoch:2 step:2165[D loss: 0.387474, acc: 71.88%, op_acc: 35.94%] [G loss: 1.096095]\n",
      "epoch:2 step:2166[D loss: 0.501619, acc: 60.16%, op_acc: 25.78%] [G loss: 1.041805]\n",
      "epoch:2 step:2167[D loss: 0.417806, acc: 67.19%, op_acc: 34.38%] [G loss: 1.082788]\n",
      "epoch:2 step:2168[D loss: 0.455463, acc: 62.50%, op_acc: 31.25%] [G loss: 1.039755]\n",
      "epoch:2 step:2169[D loss: 0.444851, acc: 59.38%, op_acc: 42.97%] [G loss: 1.012349]\n",
      "epoch:2 step:2170[D loss: 0.461016, acc: 61.72%, op_acc: 27.34%] [G loss: 0.992484]\n",
      "epoch:2 step:2171[D loss: 0.482651, acc: 55.47%, op_acc: 32.03%] [G loss: 0.936245]\n",
      "epoch:2 step:2172[D loss: 0.432019, acc: 65.62%, op_acc: 32.03%] [G loss: 0.976416]\n",
      "epoch:2 step:2173[D loss: 0.426848, acc: 65.62%, op_acc: 39.06%] [G loss: 0.976485]\n",
      "epoch:2 step:2174[D loss: 0.428141, acc: 67.97%, op_acc: 33.59%] [G loss: 0.999478]\n",
      "epoch:2 step:2175[D loss: 0.487307, acc: 63.28%, op_acc: 28.12%] [G loss: 1.077502]\n",
      "epoch:2 step:2176[D loss: 0.427734, acc: 66.41%, op_acc: 29.69%] [G loss: 0.960028]\n",
      "epoch:2 step:2177[D loss: 0.480826, acc: 62.50%, op_acc: 28.12%] [G loss: 0.903570]\n",
      "epoch:2 step:2178[D loss: 0.443125, acc: 66.41%, op_acc: 31.25%] [G loss: 0.897258]\n",
      "epoch:2 step:2179[D loss: 0.468631, acc: 63.28%, op_acc: 28.12%] [G loss: 1.023965]\n",
      "epoch:2 step:2180[D loss: 0.435768, acc: 66.41%, op_acc: 30.47%] [G loss: 1.036857]\n",
      "epoch:2 step:2181[D loss: 0.463869, acc: 62.50%, op_acc: 29.69%] [G loss: 0.948354]\n",
      "epoch:2 step:2182[D loss: 0.467205, acc: 61.72%, op_acc: 19.53%] [G loss: 0.985217]\n",
      "epoch:2 step:2183[D loss: 0.468282, acc: 61.72%, op_acc: 32.03%] [G loss: 1.105195]\n",
      "epoch:2 step:2184[D loss: 0.489681, acc: 54.69%, op_acc: 27.34%] [G loss: 0.998229]\n",
      "epoch:2 step:2185[D loss: 0.502331, acc: 50.00%, op_acc: 30.47%] [G loss: 1.070104]\n",
      "epoch:2 step:2186[D loss: 0.460880, acc: 60.16%, op_acc: 26.56%] [G loss: 1.030067]\n",
      "epoch:2 step:2187[D loss: 0.477469, acc: 57.03%, op_acc: 30.47%] [G loss: 1.001306]\n",
      "epoch:2 step:2188[D loss: 0.455536, acc: 60.94%, op_acc: 31.25%] [G loss: 0.921667]\n",
      "epoch:2 step:2189[D loss: 0.457135, acc: 61.72%, op_acc: 35.94%] [G loss: 1.031936]\n",
      "epoch:2 step:2190[D loss: 0.498981, acc: 52.34%, op_acc: 25.78%] [G loss: 1.008067]\n",
      "epoch:2 step:2191[D loss: 0.468031, acc: 56.25%, op_acc: 30.47%] [G loss: 0.979802]\n",
      "epoch:2 step:2192[D loss: 0.446652, acc: 58.59%, op_acc: 32.81%] [G loss: 0.969849]\n",
      "epoch:2 step:2193[D loss: 0.454032, acc: 55.47%, op_acc: 31.25%] [G loss: 0.943541]\n",
      "epoch:2 step:2194[D loss: 0.469123, acc: 65.62%, op_acc: 26.56%] [G loss: 1.079778]\n",
      "epoch:2 step:2195[D loss: 0.477501, acc: 58.59%, op_acc: 28.91%] [G loss: 0.927327]\n",
      "epoch:2 step:2196[D loss: 0.419131, acc: 68.75%, op_acc: 37.50%] [G loss: 0.963528]\n",
      "epoch:2 step:2197[D loss: 0.462116, acc: 61.72%, op_acc: 32.03%] [G loss: 1.032320]\n",
      "epoch:2 step:2198[D loss: 0.452695, acc: 59.38%, op_acc: 32.03%] [G loss: 0.976519]\n",
      "epoch:2 step:2199[D loss: 0.480158, acc: 58.59%, op_acc: 26.56%] [G loss: 0.989711]\n",
      "epoch:2 step:2200[D loss: 0.432720, acc: 64.84%, op_acc: 32.03%] [G loss: 0.934719]\n",
      "epoch:2 step:2201[D loss: 0.468847, acc: 66.41%, op_acc: 29.69%] [G loss: 0.857173]\n",
      "epoch:2 step:2202[D loss: 0.454535, acc: 62.50%, op_acc: 30.47%] [G loss: 1.040992]\n",
      "epoch:2 step:2203[D loss: 0.493827, acc: 52.34%, op_acc: 25.78%] [G loss: 0.955089]\n",
      "epoch:2 step:2204[D loss: 0.440277, acc: 67.19%, op_acc: 23.44%] [G loss: 0.890276]\n",
      "epoch:2 step:2205[D loss: 0.457347, acc: 65.62%, op_acc: 30.47%] [G loss: 1.049369]\n",
      "epoch:2 step:2206[D loss: 0.430465, acc: 72.66%, op_acc: 32.81%] [G loss: 1.052933]\n",
      "epoch:2 step:2207[D loss: 0.473357, acc: 60.16%, op_acc: 25.78%] [G loss: 0.977646]\n",
      "epoch:2 step:2208[D loss: 0.497969, acc: 60.16%, op_acc: 26.56%] [G loss: 1.075325]\n",
      "epoch:2 step:2209[D loss: 0.441966, acc: 59.38%, op_acc: 33.59%] [G loss: 0.988077]\n",
      "epoch:2 step:2210[D loss: 0.469601, acc: 55.47%, op_acc: 26.56%] [G loss: 0.942131]\n",
      "epoch:2 step:2211[D loss: 0.477486, acc: 60.16%, op_acc: 28.91%] [G loss: 0.906718]\n",
      "epoch:2 step:2212[D loss: 0.495459, acc: 56.25%, op_acc: 28.12%] [G loss: 0.908873]\n",
      "epoch:2 step:2213[D loss: 0.447989, acc: 65.62%, op_acc: 32.81%] [G loss: 1.084391]\n",
      "epoch:2 step:2214[D loss: 0.445938, acc: 59.38%, op_acc: 33.59%] [G loss: 0.938871]\n",
      "epoch:2 step:2215[D loss: 0.427444, acc: 63.28%, op_acc: 36.72%] [G loss: 1.019279]\n",
      "epoch:2 step:2216[D loss: 0.437032, acc: 65.62%, op_acc: 30.47%] [G loss: 1.069021]\n",
      "epoch:2 step:2217[D loss: 0.450909, acc: 63.28%, op_acc: 31.25%] [G loss: 0.966847]\n",
      "epoch:2 step:2218[D loss: 0.444539, acc: 62.50%, op_acc: 32.81%] [G loss: 1.027850]\n",
      "epoch:2 step:2219[D loss: 0.453250, acc: 64.06%, op_acc: 25.00%] [G loss: 0.962481]\n",
      "epoch:2 step:2220[D loss: 0.437918, acc: 68.75%, op_acc: 32.81%] [G loss: 1.046936]\n",
      "epoch:2 step:2221[D loss: 0.471413, acc: 63.28%, op_acc: 23.44%] [G loss: 1.040665]\n",
      "epoch:2 step:2222[D loss: 0.414985, acc: 66.41%, op_acc: 31.25%] [G loss: 1.010167]\n",
      "epoch:2 step:2223[D loss: 0.446292, acc: 61.72%, op_acc: 31.25%] [G loss: 1.005835]\n",
      "epoch:2 step:2224[D loss: 0.416053, acc: 67.19%, op_acc: 37.50%] [G loss: 0.941808]\n",
      "epoch:2 step:2225[D loss: 0.446886, acc: 55.47%, op_acc: 31.25%] [G loss: 0.986994]\n",
      "epoch:2 step:2226[D loss: 0.420693, acc: 67.97%, op_acc: 29.69%] [G loss: 1.015070]\n",
      "epoch:2 step:2227[D loss: 0.473918, acc: 65.62%, op_acc: 24.22%] [G loss: 1.049482]\n",
      "epoch:2 step:2228[D loss: 0.481212, acc: 65.62%, op_acc: 25.78%] [G loss: 1.026110]\n",
      "epoch:2 step:2229[D loss: 0.492750, acc: 55.47%, op_acc: 33.59%] [G loss: 1.021549]\n",
      "epoch:2 step:2230[D loss: 0.445255, acc: 65.62%, op_acc: 32.81%] [G loss: 1.067899]\n",
      "epoch:2 step:2231[D loss: 0.453341, acc: 66.41%, op_acc: 30.47%] [G loss: 1.027884]\n",
      "epoch:2 step:2232[D loss: 0.478546, acc: 51.56%, op_acc: 26.56%] [G loss: 0.984231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2233[D loss: 0.474240, acc: 63.28%, op_acc: 21.09%] [G loss: 1.035838]\n",
      "epoch:2 step:2234[D loss: 0.483277, acc: 55.47%, op_acc: 28.12%] [G loss: 0.876501]\n",
      "epoch:2 step:2235[D loss: 0.484242, acc: 58.59%, op_acc: 27.34%] [G loss: 0.966202]\n",
      "epoch:2 step:2236[D loss: 0.478808, acc: 49.22%, op_acc: 31.25%] [G loss: 1.022949]\n",
      "epoch:2 step:2237[D loss: 0.428187, acc: 64.84%, op_acc: 32.03%] [G loss: 1.073142]\n",
      "epoch:2 step:2238[D loss: 0.502267, acc: 57.81%, op_acc: 21.88%] [G loss: 1.092515]\n",
      "epoch:2 step:2239[D loss: 0.457108, acc: 66.41%, op_acc: 31.25%] [G loss: 0.912956]\n",
      "epoch:2 step:2240[D loss: 0.465557, acc: 57.03%, op_acc: 33.59%] [G loss: 1.031466]\n",
      "epoch:2 step:2241[D loss: 0.459368, acc: 62.50%, op_acc: 30.47%] [G loss: 0.969539]\n",
      "epoch:2 step:2242[D loss: 0.453881, acc: 64.06%, op_acc: 26.56%] [G loss: 1.139231]\n",
      "epoch:2 step:2243[D loss: 0.510669, acc: 58.59%, op_acc: 24.22%] [G loss: 1.003520]\n",
      "epoch:2 step:2244[D loss: 0.444276, acc: 61.72%, op_acc: 31.25%] [G loss: 0.933769]\n",
      "epoch:2 step:2245[D loss: 0.438692, acc: 59.38%, op_acc: 32.81%] [G loss: 1.073684]\n",
      "epoch:2 step:2246[D loss: 0.478186, acc: 59.38%, op_acc: 30.47%] [G loss: 1.076254]\n",
      "epoch:2 step:2247[D loss: 0.456103, acc: 64.84%, op_acc: 28.91%] [G loss: 1.069595]\n",
      "epoch:2 step:2248[D loss: 0.455966, acc: 61.72%, op_acc: 24.22%] [G loss: 0.960882]\n",
      "epoch:2 step:2249[D loss: 0.438802, acc: 63.28%, op_acc: 28.12%] [G loss: 0.964767]\n",
      "epoch:2 step:2250[D loss: 0.459009, acc: 61.72%, op_acc: 34.38%] [G loss: 0.967731]\n",
      "epoch:2 step:2251[D loss: 0.423462, acc: 67.19%, op_acc: 28.12%] [G loss: 0.996156]\n",
      "epoch:2 step:2252[D loss: 0.443584, acc: 67.97%, op_acc: 33.59%] [G loss: 1.046550]\n",
      "epoch:2 step:2253[D loss: 0.459397, acc: 64.84%, op_acc: 28.12%] [G loss: 1.006879]\n",
      "epoch:2 step:2254[D loss: 0.495862, acc: 49.22%, op_acc: 25.78%] [G loss: 0.890679]\n",
      "epoch:2 step:2255[D loss: 0.460673, acc: 64.84%, op_acc: 28.12%] [G loss: 0.957377]\n",
      "epoch:2 step:2256[D loss: 0.469516, acc: 60.94%, op_acc: 32.03%] [G loss: 1.138162]\n",
      "epoch:2 step:2257[D loss: 0.418996, acc: 71.88%, op_acc: 30.47%] [G loss: 1.016413]\n",
      "epoch:2 step:2258[D loss: 0.477115, acc: 58.59%, op_acc: 27.34%] [G loss: 0.941681]\n",
      "epoch:2 step:2259[D loss: 0.475791, acc: 61.72%, op_acc: 28.12%] [G loss: 0.882278]\n",
      "epoch:2 step:2260[D loss: 0.435800, acc: 68.75%, op_acc: 32.81%] [G loss: 0.921789]\n",
      "epoch:2 step:2261[D loss: 0.466520, acc: 56.25%, op_acc: 28.91%] [G loss: 0.953908]\n",
      "epoch:2 step:2262[D loss: 0.473560, acc: 59.38%, op_acc: 28.91%] [G loss: 0.991298]\n",
      "epoch:2 step:2263[D loss: 0.477468, acc: 57.81%, op_acc: 24.22%] [G loss: 1.035803]\n",
      "epoch:2 step:2264[D loss: 0.462073, acc: 59.38%, op_acc: 32.03%] [G loss: 1.041576]\n",
      "epoch:2 step:2265[D loss: 0.435944, acc: 62.50%, op_acc: 35.94%] [G loss: 1.065682]\n",
      "epoch:2 step:2266[D loss: 0.464507, acc: 61.72%, op_acc: 32.03%] [G loss: 0.956267]\n",
      "epoch:2 step:2267[D loss: 0.464271, acc: 54.69%, op_acc: 30.47%] [G loss: 0.954788]\n",
      "epoch:2 step:2268[D loss: 0.450601, acc: 57.81%, op_acc: 30.47%] [G loss: 0.969737]\n",
      "epoch:2 step:2269[D loss: 0.455231, acc: 60.16%, op_acc: 27.34%] [G loss: 0.971817]\n",
      "epoch:2 step:2270[D loss: 0.448335, acc: 62.50%, op_acc: 31.25%] [G loss: 0.961651]\n",
      "epoch:2 step:2271[D loss: 0.420787, acc: 66.41%, op_acc: 35.94%] [G loss: 1.044233]\n",
      "epoch:2 step:2272[D loss: 0.411752, acc: 65.62%, op_acc: 34.38%] [G loss: 0.974194]\n",
      "epoch:2 step:2273[D loss: 0.463531, acc: 60.94%, op_acc: 32.81%] [G loss: 0.995339]\n",
      "epoch:2 step:2274[D loss: 0.426407, acc: 60.94%, op_acc: 35.94%] [G loss: 1.057984]\n",
      "epoch:2 step:2275[D loss: 0.458815, acc: 57.81%, op_acc: 31.25%] [G loss: 1.031239]\n",
      "epoch:2 step:2276[D loss: 0.449354, acc: 60.16%, op_acc: 30.47%] [G loss: 0.957821]\n",
      "epoch:2 step:2277[D loss: 0.510923, acc: 45.31%, op_acc: 25.00%] [G loss: 0.842528]\n",
      "epoch:2 step:2278[D loss: 0.477039, acc: 61.72%, op_acc: 25.78%] [G loss: 0.947359]\n",
      "epoch:2 step:2279[D loss: 0.458451, acc: 62.50%, op_acc: 35.16%] [G loss: 1.007503]\n",
      "epoch:2 step:2280[D loss: 0.526293, acc: 54.69%, op_acc: 28.12%] [G loss: 0.985816]\n",
      "epoch:2 step:2281[D loss: 0.434527, acc: 72.66%, op_acc: 25.78%] [G loss: 1.044669]\n",
      "epoch:2 step:2282[D loss: 0.490555, acc: 56.25%, op_acc: 30.47%] [G loss: 0.990694]\n",
      "epoch:2 step:2283[D loss: 0.430383, acc: 57.81%, op_acc: 34.38%] [G loss: 1.006564]\n",
      "epoch:2 step:2284[D loss: 0.435394, acc: 64.06%, op_acc: 33.59%] [G loss: 1.068090]\n",
      "epoch:2 step:2285[D loss: 0.437372, acc: 60.16%, op_acc: 33.59%] [G loss: 0.986311]\n",
      "epoch:2 step:2286[D loss: 0.497720, acc: 59.38%, op_acc: 21.88%] [G loss: 0.965617]\n",
      "epoch:2 step:2287[D loss: 0.453890, acc: 62.50%, op_acc: 32.81%] [G loss: 0.941618]\n",
      "epoch:2 step:2288[D loss: 0.432796, acc: 64.84%, op_acc: 30.47%] [G loss: 0.994950]\n",
      "epoch:2 step:2289[D loss: 0.475006, acc: 66.41%, op_acc: 19.53%] [G loss: 1.012908]\n",
      "epoch:2 step:2290[D loss: 0.456337, acc: 67.97%, op_acc: 21.09%] [G loss: 1.068939]\n",
      "epoch:2 step:2291[D loss: 0.440830, acc: 59.38%, op_acc: 31.25%] [G loss: 0.973755]\n",
      "epoch:2 step:2292[D loss: 0.443550, acc: 66.41%, op_acc: 35.94%] [G loss: 1.060526]\n",
      "epoch:2 step:2293[D loss: 0.476927, acc: 50.00%, op_acc: 32.03%] [G loss: 0.950991]\n",
      "epoch:2 step:2294[D loss: 0.494094, acc: 53.12%, op_acc: 30.47%] [G loss: 1.016141]\n",
      "epoch:2 step:2295[D loss: 0.457696, acc: 57.81%, op_acc: 32.03%] [G loss: 0.917848]\n",
      "epoch:2 step:2296[D loss: 0.457927, acc: 54.69%, op_acc: 31.25%] [G loss: 0.977770]\n",
      "epoch:2 step:2297[D loss: 0.442643, acc: 69.53%, op_acc: 31.25%] [G loss: 1.030618]\n",
      "epoch:2 step:2298[D loss: 0.441064, acc: 68.75%, op_acc: 34.38%] [G loss: 1.055777]\n",
      "epoch:2 step:2299[D loss: 0.445466, acc: 60.16%, op_acc: 34.38%] [G loss: 0.960609]\n",
      "epoch:2 step:2300[D loss: 0.437400, acc: 62.50%, op_acc: 32.81%] [G loss: 0.935935]\n",
      "epoch:2 step:2301[D loss: 0.436473, acc: 60.16%, op_acc: 33.59%] [G loss: 0.960905]\n",
      "epoch:2 step:2302[D loss: 0.420944, acc: 67.97%, op_acc: 33.59%] [G loss: 0.881152]\n",
      "epoch:2 step:2303[D loss: 0.445342, acc: 62.50%, op_acc: 25.78%] [G loss: 1.013587]\n",
      "epoch:2 step:2304[D loss: 0.455024, acc: 60.94%, op_acc: 25.78%] [G loss: 0.913128]\n",
      "epoch:2 step:2305[D loss: 0.506917, acc: 57.03%, op_acc: 25.78%] [G loss: 0.952745]\n",
      "epoch:2 step:2306[D loss: 0.442315, acc: 57.03%, op_acc: 41.41%] [G loss: 0.965428]\n",
      "epoch:2 step:2307[D loss: 0.455166, acc: 59.38%, op_acc: 28.91%] [G loss: 0.919270]\n",
      "epoch:2 step:2308[D loss: 0.475446, acc: 53.91%, op_acc: 30.47%] [G loss: 0.995934]\n",
      "epoch:2 step:2309[D loss: 0.458412, acc: 57.03%, op_acc: 35.94%] [G loss: 1.062501]\n",
      "epoch:2 step:2310[D loss: 0.442140, acc: 63.28%, op_acc: 31.25%] [G loss: 0.968809]\n",
      "epoch:2 step:2311[D loss: 0.472272, acc: 59.38%, op_acc: 30.47%] [G loss: 1.046664]\n",
      "epoch:2 step:2312[D loss: 0.450026, acc: 57.03%, op_acc: 35.16%] [G loss: 1.011231]\n",
      "epoch:2 step:2313[D loss: 0.473347, acc: 64.84%, op_acc: 28.91%] [G loss: 1.044028]\n",
      "epoch:2 step:2314[D loss: 0.438974, acc: 68.75%, op_acc: 30.47%] [G loss: 1.092071]\n",
      "epoch:2 step:2315[D loss: 0.490296, acc: 58.59%, op_acc: 29.69%] [G loss: 0.991386]\n",
      "epoch:2 step:2316[D loss: 0.430255, acc: 70.31%, op_acc: 34.38%] [G loss: 0.890880]\n",
      "epoch:2 step:2317[D loss: 0.451781, acc: 63.28%, op_acc: 26.56%] [G loss: 0.859928]\n",
      "epoch:2 step:2318[D loss: 0.457619, acc: 57.81%, op_acc: 33.59%] [G loss: 0.930173]\n",
      "epoch:2 step:2319[D loss: 0.439390, acc: 64.06%, op_acc: 31.25%] [G loss: 1.104016]\n",
      "epoch:2 step:2320[D loss: 0.435477, acc: 65.62%, op_acc: 27.34%] [G loss: 1.126159]\n",
      "epoch:2 step:2321[D loss: 0.441871, acc: 60.94%, op_acc: 32.81%] [G loss: 1.124350]\n",
      "epoch:2 step:2322[D loss: 0.451566, acc: 60.16%, op_acc: 32.81%] [G loss: 0.899263]\n",
      "epoch:2 step:2323[D loss: 0.414133, acc: 64.84%, op_acc: 31.25%] [G loss: 0.965574]\n",
      "epoch:2 step:2324[D loss: 0.470731, acc: 57.81%, op_acc: 31.25%] [G loss: 0.997309]\n",
      "epoch:2 step:2325[D loss: 0.421462, acc: 69.53%, op_acc: 33.59%] [G loss: 1.129661]\n",
      "epoch:2 step:2326[D loss: 0.446716, acc: 58.59%, op_acc: 30.47%] [G loss: 0.986792]\n",
      "epoch:2 step:2327[D loss: 0.452020, acc: 60.16%, op_acc: 32.03%] [G loss: 1.041095]\n",
      "epoch:2 step:2328[D loss: 0.457236, acc: 59.38%, op_acc: 26.56%] [G loss: 1.079419]\n",
      "epoch:2 step:2329[D loss: 0.463573, acc: 55.47%, op_acc: 29.69%] [G loss: 1.036605]\n",
      "epoch:2 step:2330[D loss: 0.412347, acc: 72.66%, op_acc: 28.12%] [G loss: 1.087784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2331[D loss: 0.395824, acc: 73.44%, op_acc: 41.41%] [G loss: 1.148236]\n",
      "epoch:2 step:2332[D loss: 0.438002, acc: 65.62%, op_acc: 32.03%] [G loss: 1.044152]\n",
      "epoch:2 step:2333[D loss: 0.454464, acc: 63.28%, op_acc: 28.91%] [G loss: 1.036279]\n",
      "epoch:2 step:2334[D loss: 0.478035, acc: 60.16%, op_acc: 27.34%] [G loss: 1.029374]\n",
      "epoch:2 step:2335[D loss: 0.462509, acc: 64.06%, op_acc: 36.72%] [G loss: 1.049663]\n",
      "epoch:2 step:2336[D loss: 0.394441, acc: 73.44%, op_acc: 35.16%] [G loss: 1.018922]\n",
      "epoch:2 step:2337[D loss: 0.439497, acc: 67.19%, op_acc: 30.47%] [G loss: 0.968083]\n",
      "epoch:2 step:2338[D loss: 0.391851, acc: 73.44%, op_acc: 39.06%] [G loss: 1.061759]\n",
      "epoch:2 step:2339[D loss: 0.525059, acc: 48.44%, op_acc: 23.44%] [G loss: 1.095134]\n",
      "epoch:2 step:2340[D loss: 0.447068, acc: 64.06%, op_acc: 32.81%] [G loss: 0.996460]\n",
      "epoch:2 step:2341[D loss: 0.448255, acc: 59.38%, op_acc: 30.47%] [G loss: 0.936461]\n",
      "epoch:2 step:2342[D loss: 0.478605, acc: 53.12%, op_acc: 35.16%] [G loss: 0.993272]\n",
      "epoch:2 step:2343[D loss: 0.450394, acc: 60.94%, op_acc: 32.81%] [G loss: 0.935405]\n",
      "epoch:3 step:2344[D loss: 0.461713, acc: 54.69%, op_acc: 32.81%] [G loss: 1.084254]\n",
      "epoch:3 step:2345[D loss: 0.478908, acc: 59.38%, op_acc: 28.91%] [G loss: 1.057029]\n",
      "epoch:3 step:2346[D loss: 0.455103, acc: 63.28%, op_acc: 34.38%] [G loss: 1.055145]\n",
      "epoch:3 step:2347[D loss: 0.440212, acc: 61.72%, op_acc: 29.69%] [G loss: 0.964995]\n",
      "epoch:3 step:2348[D loss: 0.460443, acc: 57.81%, op_acc: 33.59%] [G loss: 0.963503]\n",
      "epoch:3 step:2349[D loss: 0.465404, acc: 54.69%, op_acc: 29.69%] [G loss: 1.011150]\n",
      "epoch:3 step:2350[D loss: 0.456744, acc: 62.50%, op_acc: 33.59%] [G loss: 1.011096]\n",
      "epoch:3 step:2351[D loss: 0.475841, acc: 56.25%, op_acc: 28.91%] [G loss: 0.946534]\n",
      "epoch:3 step:2352[D loss: 0.431925, acc: 62.50%, op_acc: 34.38%] [G loss: 1.023496]\n",
      "epoch:3 step:2353[D loss: 0.450515, acc: 57.81%, op_acc: 32.81%] [G loss: 1.096732]\n",
      "epoch:3 step:2354[D loss: 0.481857, acc: 57.03%, op_acc: 35.16%] [G loss: 1.006523]\n",
      "epoch:3 step:2355[D loss: 0.488373, acc: 58.59%, op_acc: 31.25%] [G loss: 1.048147]\n",
      "epoch:3 step:2356[D loss: 0.445486, acc: 64.06%, op_acc: 32.03%] [G loss: 1.039533]\n",
      "epoch:3 step:2357[D loss: 0.451180, acc: 61.72%, op_acc: 28.91%] [G loss: 1.067479]\n",
      "epoch:3 step:2358[D loss: 0.443642, acc: 59.38%, op_acc: 32.03%] [G loss: 1.075487]\n",
      "epoch:3 step:2359[D loss: 0.442929, acc: 60.94%, op_acc: 31.25%] [G loss: 1.063836]\n",
      "epoch:3 step:2360[D loss: 0.463182, acc: 61.72%, op_acc: 27.34%] [G loss: 1.052938]\n",
      "epoch:3 step:2361[D loss: 0.427772, acc: 67.19%, op_acc: 32.03%] [G loss: 1.043102]\n",
      "epoch:3 step:2362[D loss: 0.472828, acc: 59.38%, op_acc: 25.78%] [G loss: 1.018111]\n",
      "epoch:3 step:2363[D loss: 0.455490, acc: 58.59%, op_acc: 35.16%] [G loss: 1.013352]\n",
      "epoch:3 step:2364[D loss: 0.466961, acc: 63.28%, op_acc: 25.78%] [G loss: 0.953232]\n",
      "epoch:3 step:2365[D loss: 0.458577, acc: 62.50%, op_acc: 31.25%] [G loss: 0.993977]\n",
      "epoch:3 step:2366[D loss: 0.467703, acc: 52.34%, op_acc: 35.94%] [G loss: 0.993868]\n",
      "epoch:3 step:2367[D loss: 0.463679, acc: 63.28%, op_acc: 27.34%] [G loss: 1.075307]\n",
      "epoch:3 step:2368[D loss: 0.461899, acc: 60.16%, op_acc: 32.81%] [G loss: 1.023858]\n",
      "epoch:3 step:2369[D loss: 0.448884, acc: 60.94%, op_acc: 30.47%] [G loss: 1.048180]\n",
      "epoch:3 step:2370[D loss: 0.453702, acc: 65.62%, op_acc: 35.16%] [G loss: 0.977459]\n",
      "epoch:3 step:2371[D loss: 0.469169, acc: 59.38%, op_acc: 29.69%] [G loss: 1.080617]\n",
      "epoch:3 step:2372[D loss: 0.442627, acc: 67.97%, op_acc: 31.25%] [G loss: 0.935335]\n",
      "epoch:3 step:2373[D loss: 0.476877, acc: 51.56%, op_acc: 33.59%] [G loss: 0.923642]\n",
      "epoch:3 step:2374[D loss: 0.477162, acc: 64.84%, op_acc: 20.31%] [G loss: 1.030599]\n",
      "epoch:3 step:2375[D loss: 0.509902, acc: 54.69%, op_acc: 27.34%] [G loss: 1.029888]\n",
      "epoch:3 step:2376[D loss: 0.466330, acc: 57.03%, op_acc: 33.59%] [G loss: 1.059394]\n",
      "epoch:3 step:2377[D loss: 0.427922, acc: 65.62%, op_acc: 32.03%] [G loss: 0.935547]\n",
      "epoch:3 step:2378[D loss: 0.440178, acc: 63.28%, op_acc: 29.69%] [G loss: 0.963078]\n",
      "epoch:3 step:2379[D loss: 0.442386, acc: 62.50%, op_acc: 28.12%] [G loss: 1.057836]\n",
      "epoch:3 step:2380[D loss: 0.461024, acc: 64.84%, op_acc: 27.34%] [G loss: 0.942958]\n",
      "epoch:3 step:2381[D loss: 0.460477, acc: 60.16%, op_acc: 32.03%] [G loss: 1.004750]\n",
      "epoch:3 step:2382[D loss: 0.448236, acc: 61.72%, op_acc: 25.78%] [G loss: 1.050242]\n",
      "epoch:3 step:2383[D loss: 0.443254, acc: 70.31%, op_acc: 22.66%] [G loss: 0.987386]\n",
      "epoch:3 step:2384[D loss: 0.475413, acc: 57.03%, op_acc: 35.16%] [G loss: 0.901313]\n",
      "epoch:3 step:2385[D loss: 0.456442, acc: 67.19%, op_acc: 34.38%] [G loss: 1.041699]\n",
      "epoch:3 step:2386[D loss: 0.463929, acc: 60.94%, op_acc: 19.53%] [G loss: 0.869227]\n",
      "epoch:3 step:2387[D loss: 0.468205, acc: 59.38%, op_acc: 24.22%] [G loss: 0.995413]\n",
      "epoch:3 step:2388[D loss: 0.410179, acc: 68.75%, op_acc: 32.03%] [G loss: 0.955796]\n",
      "epoch:3 step:2389[D loss: 0.450130, acc: 59.38%, op_acc: 33.59%] [G loss: 1.013602]\n",
      "epoch:3 step:2390[D loss: 0.456082, acc: 65.62%, op_acc: 28.91%] [G loss: 0.853947]\n",
      "epoch:3 step:2391[D loss: 0.466687, acc: 63.28%, op_acc: 32.03%] [G loss: 0.956443]\n",
      "epoch:3 step:2392[D loss: 0.433136, acc: 65.62%, op_acc: 34.38%] [G loss: 1.012524]\n",
      "epoch:3 step:2393[D loss: 0.501561, acc: 53.91%, op_acc: 25.00%] [G loss: 1.076237]\n",
      "epoch:3 step:2394[D loss: 0.432057, acc: 70.31%, op_acc: 32.81%] [G loss: 1.069931]\n",
      "epoch:3 step:2395[D loss: 0.488113, acc: 57.81%, op_acc: 27.34%] [G loss: 0.982970]\n",
      "epoch:3 step:2396[D loss: 0.486261, acc: 54.69%, op_acc: 28.91%] [G loss: 1.029575]\n",
      "epoch:3 step:2397[D loss: 0.487308, acc: 59.38%, op_acc: 28.91%] [G loss: 0.921156]\n",
      "epoch:3 step:2398[D loss: 0.437983, acc: 58.59%, op_acc: 32.03%] [G loss: 0.968681]\n",
      "epoch:3 step:2399[D loss: 0.461789, acc: 59.38%, op_acc: 35.94%] [G loss: 1.021792]\n",
      "epoch:3 step:2400[D loss: 0.480972, acc: 61.72%, op_acc: 28.12%] [G loss: 1.024673]\n",
      "epoch:3 step:2401[D loss: 0.444360, acc: 59.38%, op_acc: 33.59%] [G loss: 1.006781]\n",
      "epoch:3 step:2402[D loss: 0.440810, acc: 65.62%, op_acc: 32.81%] [G loss: 1.053870]\n",
      "epoch:3 step:2403[D loss: 0.435201, acc: 62.50%, op_acc: 27.34%] [G loss: 0.955753]\n",
      "epoch:3 step:2404[D loss: 0.461554, acc: 67.19%, op_acc: 30.47%] [G loss: 1.075375]\n",
      "epoch:3 step:2405[D loss: 0.442317, acc: 70.31%, op_acc: 31.25%] [G loss: 0.957506]\n",
      "epoch:3 step:2406[D loss: 0.486732, acc: 53.12%, op_acc: 31.25%] [G loss: 0.980105]\n",
      "epoch:3 step:2407[D loss: 0.459443, acc: 55.47%, op_acc: 32.03%] [G loss: 1.002615]\n",
      "epoch:3 step:2408[D loss: 0.467295, acc: 64.06%, op_acc: 31.25%] [G loss: 0.931412]\n",
      "epoch:3 step:2409[D loss: 0.437279, acc: 60.94%, op_acc: 33.59%] [G loss: 1.090253]\n",
      "epoch:3 step:2410[D loss: 0.425817, acc: 64.84%, op_acc: 32.03%] [G loss: 1.062906]\n",
      "epoch:3 step:2411[D loss: 0.451922, acc: 64.84%, op_acc: 32.81%] [G loss: 1.121532]\n",
      "epoch:3 step:2412[D loss: 0.396311, acc: 65.62%, op_acc: 39.84%] [G loss: 1.045185]\n",
      "epoch:3 step:2413[D loss: 0.464249, acc: 63.28%, op_acc: 23.44%] [G loss: 1.125137]\n",
      "epoch:3 step:2414[D loss: 0.497117, acc: 67.19%, op_acc: 25.00%] [G loss: 1.001628]\n",
      "epoch:3 step:2415[D loss: 0.485630, acc: 55.47%, op_acc: 27.34%] [G loss: 1.008539]\n",
      "epoch:3 step:2416[D loss: 0.447426, acc: 57.03%, op_acc: 32.03%] [G loss: 1.059938]\n",
      "epoch:3 step:2417[D loss: 0.433343, acc: 60.16%, op_acc: 32.03%] [G loss: 1.000127]\n",
      "epoch:3 step:2418[D loss: 0.449118, acc: 62.50%, op_acc: 28.12%] [G loss: 0.897329]\n",
      "epoch:3 step:2419[D loss: 0.473236, acc: 59.38%, op_acc: 33.59%] [G loss: 0.868558]\n",
      "epoch:3 step:2420[D loss: 0.455809, acc: 62.50%, op_acc: 30.47%] [G loss: 0.979199]\n",
      "epoch:3 step:2421[D loss: 0.507958, acc: 57.03%, op_acc: 25.78%] [G loss: 0.925619]\n",
      "epoch:3 step:2422[D loss: 0.442729, acc: 59.38%, op_acc: 29.69%] [G loss: 0.991784]\n",
      "epoch:3 step:2423[D loss: 0.480043, acc: 57.81%, op_acc: 30.47%] [G loss: 0.957315]\n",
      "epoch:3 step:2424[D loss: 0.501739, acc: 53.91%, op_acc: 30.47%] [G loss: 1.059639]\n",
      "epoch:3 step:2425[D loss: 0.448083, acc: 60.94%, op_acc: 35.16%] [G loss: 0.898019]\n",
      "epoch:3 step:2426[D loss: 0.424847, acc: 64.84%, op_acc: 33.59%] [G loss: 0.931439]\n",
      "epoch:3 step:2427[D loss: 0.449089, acc: 61.72%, op_acc: 34.38%] [G loss: 0.948725]\n",
      "epoch:3 step:2428[D loss: 0.501147, acc: 53.91%, op_acc: 26.56%] [G loss: 0.857743]\n",
      "epoch:3 step:2429[D loss: 0.473200, acc: 57.81%, op_acc: 34.38%] [G loss: 1.100050]\n",
      "epoch:3 step:2430[D loss: 0.413988, acc: 69.53%, op_acc: 35.94%] [G loss: 1.046516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2431[D loss: 0.433901, acc: 63.28%, op_acc: 35.16%] [G loss: 1.037930]\n",
      "epoch:3 step:2432[D loss: 0.466753, acc: 59.38%, op_acc: 23.44%] [G loss: 1.091010]\n",
      "epoch:3 step:2433[D loss: 0.441204, acc: 63.28%, op_acc: 29.69%] [G loss: 1.042565]\n",
      "epoch:3 step:2434[D loss: 0.437129, acc: 67.97%, op_acc: 28.12%] [G loss: 0.937448]\n",
      "epoch:3 step:2435[D loss: 0.451039, acc: 58.59%, op_acc: 32.03%] [G loss: 0.991019]\n",
      "epoch:3 step:2436[D loss: 0.450445, acc: 56.25%, op_acc: 35.16%] [G loss: 0.988809]\n",
      "epoch:3 step:2437[D loss: 0.446808, acc: 64.06%, op_acc: 31.25%] [G loss: 1.011820]\n",
      "epoch:3 step:2438[D loss: 0.417694, acc: 64.06%, op_acc: 33.59%] [G loss: 1.018106]\n",
      "epoch:3 step:2439[D loss: 0.450191, acc: 64.84%, op_acc: 31.25%] [G loss: 1.151824]\n",
      "epoch:3 step:2440[D loss: 0.432394, acc: 62.50%, op_acc: 37.50%] [G loss: 1.086177]\n",
      "epoch:3 step:2441[D loss: 0.450436, acc: 64.84%, op_acc: 31.25%] [G loss: 0.979389]\n",
      "epoch:3 step:2442[D loss: 0.447717, acc: 59.38%, op_acc: 32.03%] [G loss: 1.065735]\n",
      "epoch:3 step:2443[D loss: 0.468340, acc: 58.59%, op_acc: 25.78%] [G loss: 1.053418]\n",
      "epoch:3 step:2444[D loss: 0.443334, acc: 61.72%, op_acc: 32.03%] [G loss: 1.062899]\n",
      "epoch:3 step:2445[D loss: 0.442941, acc: 67.97%, op_acc: 30.47%] [G loss: 1.018390]\n",
      "epoch:3 step:2446[D loss: 0.451210, acc: 60.16%, op_acc: 32.81%] [G loss: 0.969548]\n",
      "epoch:3 step:2447[D loss: 0.441858, acc: 68.75%, op_acc: 25.00%] [G loss: 1.082228]\n",
      "epoch:3 step:2448[D loss: 0.446792, acc: 67.19%, op_acc: 34.38%] [G loss: 1.027015]\n",
      "epoch:3 step:2449[D loss: 0.418431, acc: 65.62%, op_acc: 33.59%] [G loss: 0.902631]\n",
      "epoch:3 step:2450[D loss: 0.452874, acc: 60.16%, op_acc: 35.16%] [G loss: 1.019472]\n",
      "epoch:3 step:2451[D loss: 0.456347, acc: 64.06%, op_acc: 27.34%] [G loss: 1.119874]\n",
      "epoch:3 step:2452[D loss: 0.443629, acc: 56.25%, op_acc: 27.34%] [G loss: 1.005250]\n",
      "epoch:3 step:2453[D loss: 0.449071, acc: 64.06%, op_acc: 31.25%] [G loss: 0.934917]\n",
      "epoch:3 step:2454[D loss: 0.448172, acc: 62.50%, op_acc: 34.38%] [G loss: 1.012505]\n",
      "epoch:3 step:2455[D loss: 0.449479, acc: 61.72%, op_acc: 31.25%] [G loss: 1.030042]\n",
      "epoch:3 step:2456[D loss: 0.470434, acc: 60.16%, op_acc: 28.12%] [G loss: 0.964938]\n",
      "epoch:3 step:2457[D loss: 0.417995, acc: 60.16%, op_acc: 37.50%] [G loss: 0.991111]\n",
      "epoch:3 step:2458[D loss: 0.419711, acc: 67.19%, op_acc: 37.50%] [G loss: 1.046630]\n",
      "epoch:3 step:2459[D loss: 0.487639, acc: 58.59%, op_acc: 29.69%] [G loss: 0.991473]\n",
      "epoch:3 step:2460[D loss: 0.453008, acc: 60.16%, op_acc: 26.56%] [G loss: 1.121681]\n",
      "epoch:3 step:2461[D loss: 0.433013, acc: 63.28%, op_acc: 31.25%] [G loss: 1.081225]\n",
      "epoch:3 step:2462[D loss: 0.464455, acc: 64.06%, op_acc: 28.12%] [G loss: 1.066797]\n",
      "epoch:3 step:2463[D loss: 0.460135, acc: 60.16%, op_acc: 27.34%] [G loss: 0.965360]\n",
      "epoch:3 step:2464[D loss: 0.479131, acc: 61.72%, op_acc: 27.34%] [G loss: 1.146112]\n",
      "epoch:3 step:2465[D loss: 0.423989, acc: 67.19%, op_acc: 32.03%] [G loss: 1.124732]\n",
      "epoch:3 step:2466[D loss: 0.486974, acc: 60.16%, op_acc: 28.12%] [G loss: 0.921094]\n",
      "epoch:3 step:2467[D loss: 0.465606, acc: 59.38%, op_acc: 35.16%] [G loss: 1.040875]\n",
      "epoch:3 step:2468[D loss: 0.469952, acc: 59.38%, op_acc: 28.12%] [G loss: 0.930023]\n",
      "epoch:3 step:2469[D loss: 0.455242, acc: 62.50%, op_acc: 30.47%] [G loss: 0.928236]\n",
      "epoch:3 step:2470[D loss: 0.453059, acc: 66.41%, op_acc: 34.38%] [G loss: 0.965257]\n",
      "epoch:3 step:2471[D loss: 0.489128, acc: 57.03%, op_acc: 26.56%] [G loss: 0.972614]\n",
      "epoch:3 step:2472[D loss: 0.480794, acc: 59.38%, op_acc: 25.00%] [G loss: 0.985913]\n",
      "epoch:3 step:2473[D loss: 0.467543, acc: 58.59%, op_acc: 31.25%] [G loss: 0.951138]\n",
      "epoch:3 step:2474[D loss: 0.445165, acc: 59.38%, op_acc: 29.69%] [G loss: 0.984628]\n",
      "epoch:3 step:2475[D loss: 0.426656, acc: 66.41%, op_acc: 33.59%] [G loss: 0.925633]\n",
      "epoch:3 step:2476[D loss: 0.457909, acc: 60.94%, op_acc: 34.38%] [G loss: 0.987515]\n",
      "epoch:3 step:2477[D loss: 0.454790, acc: 60.16%, op_acc: 32.03%] [G loss: 0.989805]\n",
      "epoch:3 step:2478[D loss: 0.458422, acc: 63.28%, op_acc: 28.12%] [G loss: 0.978313]\n",
      "epoch:3 step:2479[D loss: 0.462935, acc: 60.94%, op_acc: 31.25%] [G loss: 0.881127]\n",
      "epoch:3 step:2480[D loss: 0.469209, acc: 54.69%, op_acc: 29.69%] [G loss: 0.913228]\n",
      "epoch:3 step:2481[D loss: 0.462210, acc: 59.38%, op_acc: 31.25%] [G loss: 1.056741]\n",
      "epoch:3 step:2482[D loss: 0.425065, acc: 68.75%, op_acc: 28.12%] [G loss: 1.058810]\n",
      "epoch:3 step:2483[D loss: 0.475242, acc: 62.50%, op_acc: 28.91%] [G loss: 1.029689]\n",
      "epoch:3 step:2484[D loss: 0.479650, acc: 60.16%, op_acc: 30.47%] [G loss: 1.013512]\n",
      "epoch:3 step:2485[D loss: 0.442647, acc: 63.28%, op_acc: 28.91%] [G loss: 0.912307]\n",
      "epoch:3 step:2486[D loss: 0.497630, acc: 53.91%, op_acc: 28.12%] [G loss: 0.968376]\n",
      "epoch:3 step:2487[D loss: 0.434385, acc: 65.62%, op_acc: 38.28%] [G loss: 1.082221]\n",
      "epoch:3 step:2488[D loss: 0.479312, acc: 57.03%, op_acc: 28.12%] [G loss: 0.842492]\n",
      "epoch:3 step:2489[D loss: 0.437427, acc: 63.28%, op_acc: 32.03%] [G loss: 0.991852]\n",
      "epoch:3 step:2490[D loss: 0.415208, acc: 69.53%, op_acc: 41.41%] [G loss: 0.999910]\n",
      "epoch:3 step:2491[D loss: 0.470485, acc: 59.38%, op_acc: 28.12%] [G loss: 0.900618]\n",
      "epoch:3 step:2492[D loss: 0.478911, acc: 49.22%, op_acc: 34.38%] [G loss: 0.930497]\n",
      "epoch:3 step:2493[D loss: 0.452067, acc: 56.25%, op_acc: 30.47%] [G loss: 1.009244]\n",
      "epoch:3 step:2494[D loss: 0.461280, acc: 59.38%, op_acc: 29.69%] [G loss: 0.909688]\n",
      "epoch:3 step:2495[D loss: 0.498863, acc: 57.03%, op_acc: 28.91%] [G loss: 1.099708]\n",
      "epoch:3 step:2496[D loss: 0.492098, acc: 52.34%, op_acc: 31.25%] [G loss: 1.053418]\n",
      "epoch:3 step:2497[D loss: 0.409844, acc: 71.88%, op_acc: 39.84%] [G loss: 0.996433]\n",
      "epoch:3 step:2498[D loss: 0.460362, acc: 57.81%, op_acc: 28.12%] [G loss: 0.934546]\n",
      "epoch:3 step:2499[D loss: 0.455750, acc: 57.03%, op_acc: 33.59%] [G loss: 0.903577]\n",
      "epoch:3 step:2500[D loss: 0.428759, acc: 62.50%, op_acc: 36.72%] [G loss: 1.063239]\n",
      "epoch:3 step:2501[D loss: 0.446553, acc: 61.72%, op_acc: 31.25%] [G loss: 0.939673]\n",
      "epoch:3 step:2502[D loss: 0.485502, acc: 56.25%, op_acc: 27.34%] [G loss: 1.002729]\n",
      "epoch:3 step:2503[D loss: 0.467499, acc: 65.62%, op_acc: 25.00%] [G loss: 1.050585]\n",
      "epoch:3 step:2504[D loss: 0.467903, acc: 55.47%, op_acc: 28.91%] [G loss: 1.006239]\n",
      "epoch:3 step:2505[D loss: 0.429306, acc: 64.84%, op_acc: 32.81%] [G loss: 0.916141]\n",
      "epoch:3 step:2506[D loss: 0.469068, acc: 60.94%, op_acc: 28.12%] [G loss: 0.971122]\n",
      "epoch:3 step:2507[D loss: 0.452710, acc: 63.28%, op_acc: 34.38%] [G loss: 1.060743]\n",
      "epoch:3 step:2508[D loss: 0.438135, acc: 62.50%, op_acc: 37.50%] [G loss: 1.081603]\n",
      "epoch:3 step:2509[D loss: 0.490548, acc: 53.91%, op_acc: 28.12%] [G loss: 0.954818]\n",
      "epoch:3 step:2510[D loss: 0.476322, acc: 61.72%, op_acc: 30.47%] [G loss: 1.022129]\n",
      "epoch:3 step:2511[D loss: 0.472583, acc: 53.12%, op_acc: 32.81%] [G loss: 0.983060]\n",
      "epoch:3 step:2512[D loss: 0.431930, acc: 65.62%, op_acc: 34.38%] [G loss: 1.022554]\n",
      "epoch:3 step:2513[D loss: 0.441815, acc: 63.28%, op_acc: 32.81%] [G loss: 0.930231]\n",
      "epoch:3 step:2514[D loss: 0.458071, acc: 63.28%, op_acc: 32.03%] [G loss: 1.052770]\n",
      "epoch:3 step:2515[D loss: 0.412483, acc: 70.31%, op_acc: 35.94%] [G loss: 0.979145]\n",
      "epoch:3 step:2516[D loss: 0.414276, acc: 72.66%, op_acc: 29.69%] [G loss: 1.144922]\n",
      "epoch:3 step:2517[D loss: 0.471797, acc: 60.94%, op_acc: 27.34%] [G loss: 1.005736]\n",
      "epoch:3 step:2518[D loss: 0.408910, acc: 67.97%, op_acc: 36.72%] [G loss: 0.978021]\n",
      "epoch:3 step:2519[D loss: 0.436199, acc: 64.84%, op_acc: 34.38%] [G loss: 0.975751]\n",
      "epoch:3 step:2520[D loss: 0.421689, acc: 70.31%, op_acc: 28.91%] [G loss: 0.985088]\n",
      "epoch:3 step:2521[D loss: 0.440958, acc: 64.84%, op_acc: 39.84%] [G loss: 1.004987]\n",
      "epoch:3 step:2522[D loss: 0.444438, acc: 60.94%, op_acc: 32.03%] [G loss: 0.916554]\n",
      "epoch:3 step:2523[D loss: 0.471007, acc: 57.81%, op_acc: 28.12%] [G loss: 0.948997]\n",
      "epoch:3 step:2524[D loss: 0.450981, acc: 57.81%, op_acc: 27.34%] [G loss: 1.015559]\n",
      "epoch:3 step:2525[D loss: 0.453562, acc: 63.28%, op_acc: 29.69%] [G loss: 0.955912]\n",
      "epoch:3 step:2526[D loss: 0.487823, acc: 57.03%, op_acc: 28.12%] [G loss: 0.907895]\n",
      "epoch:3 step:2527[D loss: 0.442482, acc: 60.16%, op_acc: 32.81%] [G loss: 0.924961]\n",
      "epoch:3 step:2528[D loss: 0.473857, acc: 59.38%, op_acc: 28.91%] [G loss: 0.945770]\n",
      "epoch:3 step:2529[D loss: 0.477908, acc: 60.94%, op_acc: 25.78%] [G loss: 0.985632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2530[D loss: 0.473380, acc: 57.03%, op_acc: 32.81%] [G loss: 0.884043]\n",
      "epoch:3 step:2531[D loss: 0.495872, acc: 50.78%, op_acc: 30.47%] [G loss: 0.912128]\n",
      "epoch:3 step:2532[D loss: 0.439245, acc: 65.62%, op_acc: 32.81%] [G loss: 0.981963]\n",
      "epoch:3 step:2533[D loss: 0.445510, acc: 69.53%, op_acc: 28.91%] [G loss: 1.019632]\n",
      "epoch:3 step:2534[D loss: 0.413265, acc: 64.84%, op_acc: 38.28%] [G loss: 0.914915]\n",
      "epoch:3 step:2535[D loss: 0.474138, acc: 67.19%, op_acc: 30.47%] [G loss: 0.998614]\n",
      "epoch:3 step:2536[D loss: 0.451280, acc: 69.53%, op_acc: 30.47%] [G loss: 1.071313]\n",
      "epoch:3 step:2537[D loss: 0.492419, acc: 54.69%, op_acc: 32.81%] [G loss: 0.967227]\n",
      "epoch:3 step:2538[D loss: 0.470459, acc: 62.50%, op_acc: 32.03%] [G loss: 0.866582]\n",
      "epoch:3 step:2539[D loss: 0.462861, acc: 64.84%, op_acc: 32.81%] [G loss: 1.037542]\n",
      "epoch:3 step:2540[D loss: 0.485084, acc: 56.25%, op_acc: 32.03%] [G loss: 0.882440]\n",
      "epoch:3 step:2541[D loss: 0.491434, acc: 62.50%, op_acc: 27.34%] [G loss: 0.882143]\n",
      "epoch:3 step:2542[D loss: 0.427388, acc: 68.75%, op_acc: 31.25%] [G loss: 1.008908]\n",
      "epoch:3 step:2543[D loss: 0.468264, acc: 65.62%, op_acc: 28.12%] [G loss: 0.944886]\n",
      "epoch:3 step:2544[D loss: 0.453365, acc: 54.69%, op_acc: 32.81%] [G loss: 0.974089]\n",
      "epoch:3 step:2545[D loss: 0.454162, acc: 65.62%, op_acc: 32.81%] [G loss: 0.965456]\n",
      "epoch:3 step:2546[D loss: 0.451283, acc: 68.75%, op_acc: 26.56%] [G loss: 1.004535]\n",
      "epoch:3 step:2547[D loss: 0.443409, acc: 67.97%, op_acc: 28.91%] [G loss: 0.984161]\n",
      "epoch:3 step:2548[D loss: 0.442748, acc: 64.84%, op_acc: 29.69%] [G loss: 0.940550]\n",
      "epoch:3 step:2549[D loss: 0.465780, acc: 57.03%, op_acc: 33.59%] [G loss: 1.072566]\n",
      "epoch:3 step:2550[D loss: 0.444954, acc: 61.72%, op_acc: 33.59%] [G loss: 1.113993]\n",
      "epoch:3 step:2551[D loss: 0.460844, acc: 59.38%, op_acc: 30.47%] [G loss: 1.018038]\n",
      "epoch:3 step:2552[D loss: 0.442075, acc: 61.72%, op_acc: 33.59%] [G loss: 1.079751]\n",
      "epoch:3 step:2553[D loss: 0.454712, acc: 65.62%, op_acc: 31.25%] [G loss: 1.037403]\n",
      "epoch:3 step:2554[D loss: 0.403944, acc: 71.88%, op_acc: 39.84%] [G loss: 1.003038]\n",
      "epoch:3 step:2555[D loss: 0.429604, acc: 62.50%, op_acc: 35.94%] [G loss: 1.065616]\n",
      "epoch:3 step:2556[D loss: 0.446920, acc: 57.81%, op_acc: 33.59%] [G loss: 1.030477]\n",
      "epoch:3 step:2557[D loss: 0.457216, acc: 64.06%, op_acc: 28.12%] [G loss: 0.917037]\n",
      "epoch:3 step:2558[D loss: 0.472779, acc: 62.50%, op_acc: 27.34%] [G loss: 0.948840]\n",
      "epoch:3 step:2559[D loss: 0.456994, acc: 61.72%, op_acc: 30.47%] [G loss: 0.991765]\n",
      "epoch:3 step:2560[D loss: 0.485393, acc: 59.38%, op_acc: 30.47%] [G loss: 0.936682]\n",
      "epoch:3 step:2561[D loss: 0.473705, acc: 55.47%, op_acc: 36.72%] [G loss: 1.044603]\n",
      "epoch:3 step:2562[D loss: 0.463957, acc: 57.81%, op_acc: 32.81%] [G loss: 0.991928]\n",
      "epoch:3 step:2563[D loss: 0.494358, acc: 52.34%, op_acc: 32.81%] [G loss: 1.014854]\n",
      "epoch:3 step:2564[D loss: 0.487843, acc: 55.47%, op_acc: 28.12%] [G loss: 1.071057]\n",
      "epoch:3 step:2565[D loss: 0.465280, acc: 64.06%, op_acc: 25.00%] [G loss: 0.996377]\n",
      "epoch:3 step:2566[D loss: 0.504944, acc: 50.78%, op_acc: 25.78%] [G loss: 0.943382]\n",
      "epoch:3 step:2567[D loss: 0.477391, acc: 60.94%, op_acc: 24.22%] [G loss: 0.869928]\n",
      "epoch:3 step:2568[D loss: 0.464203, acc: 61.72%, op_acc: 30.47%] [G loss: 1.014885]\n",
      "epoch:3 step:2569[D loss: 0.418949, acc: 69.53%, op_acc: 29.69%] [G loss: 0.999702]\n",
      "epoch:3 step:2570[D loss: 0.456236, acc: 57.81%, op_acc: 32.81%] [G loss: 0.948662]\n",
      "epoch:3 step:2571[D loss: 0.442905, acc: 67.19%, op_acc: 30.47%] [G loss: 0.934441]\n",
      "epoch:3 step:2572[D loss: 0.448963, acc: 60.94%, op_acc: 32.81%] [G loss: 0.926910]\n",
      "epoch:3 step:2573[D loss: 0.436195, acc: 66.41%, op_acc: 32.03%] [G loss: 0.995638]\n",
      "epoch:3 step:2574[D loss: 0.432863, acc: 63.28%, op_acc: 43.75%] [G loss: 1.026746]\n",
      "epoch:3 step:2575[D loss: 0.495683, acc: 57.03%, op_acc: 23.44%] [G loss: 0.849280]\n",
      "epoch:3 step:2576[D loss: 0.445472, acc: 64.06%, op_acc: 28.12%] [G loss: 0.911007]\n",
      "epoch:3 step:2577[D loss: 0.458093, acc: 63.28%, op_acc: 25.78%] [G loss: 0.965516]\n",
      "epoch:3 step:2578[D loss: 0.446506, acc: 60.94%, op_acc: 34.38%] [G loss: 1.036227]\n",
      "epoch:3 step:2579[D loss: 0.466069, acc: 64.84%, op_acc: 27.34%] [G loss: 1.021940]\n",
      "epoch:3 step:2580[D loss: 0.460629, acc: 59.38%, op_acc: 32.81%] [G loss: 0.982882]\n",
      "epoch:3 step:2581[D loss: 0.464830, acc: 56.25%, op_acc: 30.47%] [G loss: 1.040059]\n",
      "epoch:3 step:2582[D loss: 0.408849, acc: 71.88%, op_acc: 37.50%] [G loss: 0.993311]\n",
      "epoch:3 step:2583[D loss: 0.448399, acc: 64.06%, op_acc: 32.03%] [G loss: 0.961863]\n",
      "epoch:3 step:2584[D loss: 0.459079, acc: 61.72%, op_acc: 29.69%] [G loss: 0.956045]\n",
      "epoch:3 step:2585[D loss: 0.413691, acc: 69.53%, op_acc: 33.59%] [G loss: 0.948195]\n",
      "epoch:3 step:2586[D loss: 0.441204, acc: 64.06%, op_acc: 38.28%] [G loss: 1.010587]\n",
      "epoch:3 step:2587[D loss: 0.423612, acc: 67.19%, op_acc: 32.81%] [G loss: 0.964754]\n",
      "epoch:3 step:2588[D loss: 0.425664, acc: 60.16%, op_acc: 35.94%] [G loss: 1.000240]\n",
      "epoch:3 step:2589[D loss: 0.452579, acc: 63.28%, op_acc: 31.25%] [G loss: 0.979683]\n",
      "epoch:3 step:2590[D loss: 0.459369, acc: 64.84%, op_acc: 31.25%] [G loss: 1.069913]\n",
      "epoch:3 step:2591[D loss: 0.455607, acc: 60.16%, op_acc: 29.69%] [G loss: 0.989209]\n",
      "epoch:3 step:2592[D loss: 0.471607, acc: 56.25%, op_acc: 34.38%] [G loss: 0.961967]\n",
      "epoch:3 step:2593[D loss: 0.493719, acc: 60.16%, op_acc: 26.56%] [G loss: 0.885820]\n",
      "epoch:3 step:2594[D loss: 0.444321, acc: 57.03%, op_acc: 32.03%] [G loss: 0.970128]\n",
      "epoch:3 step:2595[D loss: 0.470552, acc: 56.25%, op_acc: 29.69%] [G loss: 1.016071]\n",
      "epoch:3 step:2596[D loss: 0.469178, acc: 58.59%, op_acc: 28.91%] [G loss: 0.998063]\n",
      "epoch:3 step:2597[D loss: 0.480812, acc: 54.69%, op_acc: 28.91%] [G loss: 0.951764]\n",
      "epoch:3 step:2598[D loss: 0.466360, acc: 56.25%, op_acc: 32.81%] [G loss: 0.887775]\n",
      "epoch:3 step:2599[D loss: 0.468711, acc: 59.38%, op_acc: 32.81%] [G loss: 1.063052]\n",
      "epoch:3 step:2600[D loss: 0.462275, acc: 64.06%, op_acc: 32.81%] [G loss: 1.031996]\n",
      "epoch:3 step:2601[D loss: 0.457395, acc: 55.47%, op_acc: 33.59%] [G loss: 0.957078]\n",
      "epoch:3 step:2602[D loss: 0.446569, acc: 57.81%, op_acc: 25.78%] [G loss: 1.036107]\n",
      "epoch:3 step:2603[D loss: 0.459447, acc: 63.28%, op_acc: 31.25%] [G loss: 1.137219]\n",
      "epoch:3 step:2604[D loss: 0.425929, acc: 70.31%, op_acc: 34.38%] [G loss: 1.074031]\n",
      "epoch:3 step:2605[D loss: 0.437633, acc: 67.19%, op_acc: 26.56%] [G loss: 1.083773]\n",
      "epoch:3 step:2606[D loss: 0.455158, acc: 65.62%, op_acc: 32.03%] [G loss: 1.093386]\n",
      "epoch:3 step:2607[D loss: 0.470174, acc: 57.81%, op_acc: 27.34%] [G loss: 1.034507]\n",
      "epoch:3 step:2608[D loss: 0.444275, acc: 61.72%, op_acc: 35.16%] [G loss: 0.978848]\n",
      "epoch:3 step:2609[D loss: 0.421477, acc: 69.53%, op_acc: 32.81%] [G loss: 0.987212]\n",
      "epoch:3 step:2610[D loss: 0.456210, acc: 64.84%, op_acc: 22.66%] [G loss: 0.961819]\n",
      "epoch:3 step:2611[D loss: 0.414128, acc: 61.72%, op_acc: 39.06%] [G loss: 0.943799]\n",
      "epoch:3 step:2612[D loss: 0.435167, acc: 64.84%, op_acc: 32.81%] [G loss: 1.014577]\n",
      "epoch:3 step:2613[D loss: 0.442071, acc: 64.84%, op_acc: 35.16%] [G loss: 0.974973]\n",
      "epoch:3 step:2614[D loss: 0.465854, acc: 57.81%, op_acc: 31.25%] [G loss: 0.985263]\n",
      "epoch:3 step:2615[D loss: 0.458881, acc: 56.25%, op_acc: 29.69%] [G loss: 0.866791]\n",
      "epoch:3 step:2616[D loss: 0.436918, acc: 63.28%, op_acc: 37.50%] [G loss: 1.060696]\n",
      "epoch:3 step:2617[D loss: 0.526160, acc: 46.88%, op_acc: 31.25%] [G loss: 0.956593]\n",
      "epoch:3 step:2618[D loss: 0.435603, acc: 64.84%, op_acc: 29.69%] [G loss: 1.034108]\n",
      "epoch:3 step:2619[D loss: 0.484826, acc: 55.47%, op_acc: 32.03%] [G loss: 0.890789]\n",
      "epoch:3 step:2620[D loss: 0.469038, acc: 59.38%, op_acc: 31.25%] [G loss: 0.962966]\n",
      "epoch:3 step:2621[D loss: 0.463933, acc: 59.38%, op_acc: 34.38%] [G loss: 1.057931]\n",
      "epoch:3 step:2622[D loss: 0.429147, acc: 67.19%, op_acc: 32.03%] [G loss: 0.979888]\n",
      "epoch:3 step:2623[D loss: 0.439078, acc: 57.03%, op_acc: 34.38%] [G loss: 0.916312]\n",
      "epoch:3 step:2624[D loss: 0.444192, acc: 59.38%, op_acc: 32.81%] [G loss: 0.998793]\n",
      "epoch:3 step:2625[D loss: 0.482615, acc: 53.12%, op_acc: 35.94%] [G loss: 0.918291]\n",
      "epoch:3 step:2626[D loss: 0.423857, acc: 58.59%, op_acc: 36.72%] [G loss: 1.000082]\n",
      "epoch:3 step:2627[D loss: 0.467708, acc: 60.16%, op_acc: 32.03%] [G loss: 1.013616]\n",
      "epoch:3 step:2628[D loss: 0.445634, acc: 61.72%, op_acc: 32.81%] [G loss: 1.054515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2629[D loss: 0.438855, acc: 63.28%, op_acc: 28.91%] [G loss: 1.029693]\n",
      "epoch:3 step:2630[D loss: 0.505569, acc: 54.69%, op_acc: 32.03%] [G loss: 0.934566]\n",
      "epoch:3 step:2631[D loss: 0.407285, acc: 66.41%, op_acc: 35.94%] [G loss: 0.989568]\n",
      "epoch:3 step:2632[D loss: 0.466672, acc: 61.72%, op_acc: 26.56%] [G loss: 1.076038]\n",
      "epoch:3 step:2633[D loss: 0.445415, acc: 64.06%, op_acc: 28.12%] [G loss: 1.039602]\n",
      "epoch:3 step:2634[D loss: 0.493340, acc: 52.34%, op_acc: 28.91%] [G loss: 1.060139]\n",
      "epoch:3 step:2635[D loss: 0.470689, acc: 61.72%, op_acc: 27.34%] [G loss: 0.922040]\n",
      "epoch:3 step:2636[D loss: 0.427118, acc: 69.53%, op_acc: 33.59%] [G loss: 1.020801]\n",
      "epoch:3 step:2637[D loss: 0.507169, acc: 48.44%, op_acc: 31.25%] [G loss: 0.878976]\n",
      "epoch:3 step:2638[D loss: 0.445596, acc: 67.19%, op_acc: 31.25%] [G loss: 0.955549]\n",
      "epoch:3 step:2639[D loss: 0.442282, acc: 62.50%, op_acc: 32.81%] [G loss: 0.975919]\n",
      "epoch:3 step:2640[D loss: 0.450963, acc: 64.06%, op_acc: 32.81%] [G loss: 0.962956]\n",
      "epoch:3 step:2641[D loss: 0.407854, acc: 67.97%, op_acc: 35.16%] [G loss: 0.997684]\n",
      "epoch:3 step:2642[D loss: 0.453069, acc: 64.06%, op_acc: 32.81%] [G loss: 0.924710]\n",
      "epoch:3 step:2643[D loss: 0.457350, acc: 64.06%, op_acc: 28.91%] [G loss: 1.081634]\n",
      "epoch:3 step:2644[D loss: 0.431480, acc: 67.97%, op_acc: 31.25%] [G loss: 1.059391]\n",
      "epoch:3 step:2645[D loss: 0.431144, acc: 67.97%, op_acc: 32.03%] [G loss: 1.078196]\n",
      "epoch:3 step:2646[D loss: 0.440244, acc: 61.72%, op_acc: 28.12%] [G loss: 1.025026]\n",
      "epoch:3 step:2647[D loss: 0.418622, acc: 67.97%, op_acc: 32.81%] [G loss: 1.049475]\n",
      "epoch:3 step:2648[D loss: 0.431503, acc: 67.97%, op_acc: 34.38%] [G loss: 0.952440]\n",
      "epoch:3 step:2649[D loss: 0.452466, acc: 68.75%, op_acc: 28.12%] [G loss: 1.005528]\n",
      "epoch:3 step:2650[D loss: 0.412889, acc: 63.28%, op_acc: 35.16%] [G loss: 0.987155]\n",
      "epoch:3 step:2651[D loss: 0.428867, acc: 67.97%, op_acc: 31.25%] [G loss: 1.034752]\n",
      "epoch:3 step:2652[D loss: 0.482269, acc: 63.28%, op_acc: 28.12%] [G loss: 1.012505]\n",
      "epoch:3 step:2653[D loss: 0.479414, acc: 58.59%, op_acc: 24.22%] [G loss: 1.042320]\n",
      "epoch:3 step:2654[D loss: 0.426840, acc: 67.19%, op_acc: 29.69%] [G loss: 1.075237]\n",
      "epoch:3 step:2655[D loss: 0.494774, acc: 53.12%, op_acc: 32.81%] [G loss: 0.962011]\n",
      "epoch:3 step:2656[D loss: 0.472652, acc: 63.28%, op_acc: 22.66%] [G loss: 1.005059]\n",
      "epoch:3 step:2657[D loss: 0.488257, acc: 56.25%, op_acc: 28.12%] [G loss: 0.930442]\n",
      "epoch:3 step:2658[D loss: 0.450596, acc: 60.94%, op_acc: 28.91%] [G loss: 1.055934]\n",
      "epoch:3 step:2659[D loss: 0.455613, acc: 60.94%, op_acc: 29.69%] [G loss: 0.924913]\n",
      "epoch:3 step:2660[D loss: 0.473656, acc: 60.94%, op_acc: 28.91%] [G loss: 0.927870]\n",
      "epoch:3 step:2661[D loss: 0.464570, acc: 65.62%, op_acc: 25.00%] [G loss: 1.027185]\n",
      "epoch:3 step:2662[D loss: 0.447001, acc: 64.06%, op_acc: 33.59%] [G loss: 1.047248]\n",
      "epoch:3 step:2663[D loss: 0.448551, acc: 59.38%, op_acc: 32.81%] [G loss: 1.093582]\n",
      "epoch:3 step:2664[D loss: 0.455516, acc: 64.84%, op_acc: 28.91%] [G loss: 1.100796]\n",
      "epoch:3 step:2665[D loss: 0.452861, acc: 65.62%, op_acc: 29.69%] [G loss: 1.133524]\n",
      "epoch:3 step:2666[D loss: 0.421807, acc: 64.84%, op_acc: 32.03%] [G loss: 1.027932]\n",
      "epoch:3 step:2667[D loss: 0.431099, acc: 60.94%, op_acc: 31.25%] [G loss: 1.145609]\n",
      "epoch:3 step:2668[D loss: 0.425835, acc: 70.31%, op_acc: 35.16%] [G loss: 1.090760]\n",
      "epoch:3 step:2669[D loss: 0.426812, acc: 65.62%, op_acc: 34.38%] [G loss: 1.033108]\n",
      "epoch:3 step:2670[D loss: 0.401883, acc: 68.75%, op_acc: 34.38%] [G loss: 1.100387]\n",
      "epoch:3 step:2671[D loss: 0.398421, acc: 72.66%, op_acc: 35.16%] [G loss: 1.189027]\n",
      "epoch:3 step:2672[D loss: 0.472312, acc: 56.25%, op_acc: 28.91%] [G loss: 1.017538]\n",
      "epoch:3 step:2673[D loss: 0.431859, acc: 65.62%, op_acc: 34.38%] [G loss: 1.068151]\n",
      "epoch:3 step:2674[D loss: 0.433515, acc: 64.06%, op_acc: 30.47%] [G loss: 0.950642]\n",
      "epoch:3 step:2675[D loss: 0.427993, acc: 61.72%, op_acc: 33.59%] [G loss: 0.994550]\n",
      "epoch:3 step:2676[D loss: 0.459380, acc: 60.94%, op_acc: 31.25%] [G loss: 1.076387]\n",
      "epoch:3 step:2677[D loss: 0.440190, acc: 66.41%, op_acc: 35.94%] [G loss: 1.025738]\n",
      "epoch:3 step:2678[D loss: 0.444880, acc: 67.97%, op_acc: 28.91%] [G loss: 0.991365]\n",
      "epoch:3 step:2679[D loss: 0.465800, acc: 63.28%, op_acc: 32.81%] [G loss: 0.968349]\n",
      "epoch:3 step:2680[D loss: 0.455084, acc: 65.62%, op_acc: 31.25%] [G loss: 1.094607]\n",
      "epoch:3 step:2681[D loss: 0.471283, acc: 53.12%, op_acc: 32.81%] [G loss: 0.976809]\n",
      "epoch:3 step:2682[D loss: 0.429136, acc: 67.19%, op_acc: 33.59%] [G loss: 1.074674]\n",
      "epoch:3 step:2683[D loss: 0.483514, acc: 56.25%, op_acc: 33.59%] [G loss: 0.960185]\n",
      "epoch:3 step:2684[D loss: 0.479641, acc: 58.59%, op_acc: 30.47%] [G loss: 1.029922]\n",
      "epoch:3 step:2685[D loss: 0.485694, acc: 52.34%, op_acc: 29.69%] [G loss: 1.025746]\n",
      "epoch:3 step:2686[D loss: 0.488765, acc: 53.91%, op_acc: 35.16%] [G loss: 1.017229]\n",
      "epoch:3 step:2687[D loss: 0.490244, acc: 55.47%, op_acc: 28.91%] [G loss: 0.997277]\n",
      "epoch:3 step:2688[D loss: 0.477850, acc: 56.25%, op_acc: 28.12%] [G loss: 1.029388]\n",
      "epoch:3 step:2689[D loss: 0.443630, acc: 65.62%, op_acc: 29.69%] [G loss: 1.040933]\n",
      "epoch:3 step:2690[D loss: 0.466262, acc: 57.03%, op_acc: 28.91%] [G loss: 1.007195]\n",
      "epoch:3 step:2691[D loss: 0.446192, acc: 65.62%, op_acc: 32.81%] [G loss: 0.897304]\n",
      "epoch:3 step:2692[D loss: 0.463261, acc: 54.69%, op_acc: 35.16%] [G loss: 1.091136]\n",
      "epoch:3 step:2693[D loss: 0.456751, acc: 59.38%, op_acc: 37.50%] [G loss: 0.877009]\n",
      "epoch:3 step:2694[D loss: 0.483952, acc: 55.47%, op_acc: 27.34%] [G loss: 0.953842]\n",
      "epoch:3 step:2695[D loss: 0.458277, acc: 61.72%, op_acc: 26.56%] [G loss: 1.043406]\n",
      "epoch:3 step:2696[D loss: 0.418387, acc: 64.84%, op_acc: 37.50%] [G loss: 0.902627]\n",
      "epoch:3 step:2697[D loss: 0.456262, acc: 64.84%, op_acc: 29.69%] [G loss: 0.997245]\n",
      "epoch:3 step:2698[D loss: 0.442284, acc: 63.28%, op_acc: 38.28%] [G loss: 0.954949]\n",
      "epoch:3 step:2699[D loss: 0.476669, acc: 53.91%, op_acc: 32.03%] [G loss: 0.980839]\n",
      "epoch:3 step:2700[D loss: 0.421612, acc: 67.97%, op_acc: 33.59%] [G loss: 1.047225]\n",
      "epoch:3 step:2701[D loss: 0.440772, acc: 67.97%, op_acc: 32.81%] [G loss: 0.953927]\n",
      "epoch:3 step:2702[D loss: 0.437654, acc: 64.84%, op_acc: 28.12%] [G loss: 0.991602]\n",
      "epoch:3 step:2703[D loss: 0.454048, acc: 61.72%, op_acc: 32.03%] [G loss: 0.952270]\n",
      "epoch:3 step:2704[D loss: 0.474322, acc: 58.59%, op_acc: 32.81%] [G loss: 0.996715]\n",
      "epoch:3 step:2705[D loss: 0.409124, acc: 67.19%, op_acc: 32.03%] [G loss: 0.958653]\n",
      "epoch:3 step:2706[D loss: 0.485306, acc: 56.25%, op_acc: 29.69%] [G loss: 1.053760]\n",
      "epoch:3 step:2707[D loss: 0.482549, acc: 53.12%, op_acc: 36.72%] [G loss: 0.926338]\n",
      "epoch:3 step:2708[D loss: 0.445293, acc: 57.81%, op_acc: 33.59%] [G loss: 0.992583]\n",
      "epoch:3 step:2709[D loss: 0.459721, acc: 57.81%, op_acc: 35.94%] [G loss: 1.090955]\n",
      "epoch:3 step:2710[D loss: 0.473987, acc: 64.06%, op_acc: 25.78%] [G loss: 0.837206]\n",
      "epoch:3 step:2711[D loss: 0.480967, acc: 64.06%, op_acc: 27.34%] [G loss: 1.070416]\n",
      "epoch:3 step:2712[D loss: 0.461634, acc: 63.28%, op_acc: 35.94%] [G loss: 1.056855]\n",
      "epoch:3 step:2713[D loss: 0.461574, acc: 62.50%, op_acc: 32.81%] [G loss: 1.143914]\n",
      "epoch:3 step:2714[D loss: 0.416032, acc: 68.75%, op_acc: 31.25%] [G loss: 1.079302]\n",
      "epoch:3 step:2715[D loss: 0.393880, acc: 72.66%, op_acc: 37.50%] [G loss: 1.107479]\n",
      "epoch:3 step:2716[D loss: 0.424825, acc: 67.97%, op_acc: 32.81%] [G loss: 1.115575]\n",
      "epoch:3 step:2717[D loss: 0.408137, acc: 67.97%, op_acc: 35.16%] [G loss: 1.200275]\n",
      "epoch:3 step:2718[D loss: 0.394264, acc: 75.00%, op_acc: 32.81%] [G loss: 1.145127]\n",
      "epoch:3 step:2719[D loss: 0.421277, acc: 68.75%, op_acc: 31.25%] [G loss: 1.082952]\n",
      "epoch:3 step:2720[D loss: 0.422753, acc: 67.19%, op_acc: 32.81%] [G loss: 1.041999]\n",
      "epoch:3 step:2721[D loss: 0.459995, acc: 59.38%, op_acc: 27.34%] [G loss: 1.025798]\n",
      "epoch:3 step:2722[D loss: 0.410069, acc: 71.09%, op_acc: 39.06%] [G loss: 1.071669]\n",
      "epoch:3 step:2723[D loss: 0.477969, acc: 59.38%, op_acc: 28.91%] [G loss: 1.029385]\n",
      "epoch:3 step:2724[D loss: 0.436074, acc: 64.84%, op_acc: 29.69%] [G loss: 1.000912]\n",
      "epoch:3 step:2725[D loss: 0.429613, acc: 57.03%, op_acc: 36.72%] [G loss: 1.080499]\n",
      "epoch:3 step:2726[D loss: 0.428161, acc: 67.19%, op_acc: 38.28%] [G loss: 1.171226]\n",
      "epoch:3 step:2727[D loss: 0.437700, acc: 64.84%, op_acc: 38.28%] [G loss: 1.185733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2728[D loss: 0.429793, acc: 64.84%, op_acc: 38.28%] [G loss: 1.142340]\n",
      "epoch:3 step:2729[D loss: 0.432522, acc: 65.62%, op_acc: 34.38%] [G loss: 1.036275]\n",
      "epoch:3 step:2730[D loss: 0.455367, acc: 63.28%, op_acc: 28.91%] [G loss: 1.079293]\n",
      "epoch:3 step:2731[D loss: 0.466640, acc: 62.50%, op_acc: 27.34%] [G loss: 1.094530]\n",
      "epoch:3 step:2732[D loss: 0.421163, acc: 71.09%, op_acc: 34.38%] [G loss: 1.125778]\n",
      "epoch:3 step:2733[D loss: 0.451849, acc: 64.06%, op_acc: 32.03%] [G loss: 0.935701]\n",
      "epoch:3 step:2734[D loss: 0.433956, acc: 60.16%, op_acc: 38.28%] [G loss: 0.993382]\n",
      "epoch:3 step:2735[D loss: 0.428886, acc: 67.97%, op_acc: 36.72%] [G loss: 1.076453]\n",
      "epoch:3 step:2736[D loss: 0.506477, acc: 53.12%, op_acc: 31.25%] [G loss: 0.919512]\n",
      "epoch:3 step:2737[D loss: 0.440577, acc: 62.50%, op_acc: 33.59%] [G loss: 1.075443]\n",
      "epoch:3 step:2738[D loss: 0.459724, acc: 64.06%, op_acc: 29.69%] [G loss: 0.948945]\n",
      "epoch:3 step:2739[D loss: 0.464680, acc: 56.25%, op_acc: 38.28%] [G loss: 1.059330]\n",
      "epoch:3 step:2740[D loss: 0.444802, acc: 64.06%, op_acc: 33.59%] [G loss: 0.994837]\n",
      "epoch:3 step:2741[D loss: 0.470258, acc: 63.28%, op_acc: 30.47%] [G loss: 0.971761]\n",
      "epoch:3 step:2742[D loss: 0.452199, acc: 59.38%, op_acc: 32.03%] [G loss: 1.019259]\n",
      "epoch:3 step:2743[D loss: 0.415924, acc: 71.88%, op_acc: 32.81%] [G loss: 1.034594]\n",
      "epoch:3 step:2744[D loss: 0.436453, acc: 60.94%, op_acc: 33.59%] [G loss: 1.063058]\n",
      "epoch:3 step:2745[D loss: 0.471415, acc: 56.25%, op_acc: 31.25%] [G loss: 1.051677]\n",
      "epoch:3 step:2746[D loss: 0.447481, acc: 63.28%, op_acc: 35.94%] [G loss: 0.886468]\n",
      "epoch:3 step:2747[D loss: 0.438979, acc: 60.94%, op_acc: 35.94%] [G loss: 0.923496]\n",
      "epoch:3 step:2748[D loss: 0.485053, acc: 54.69%, op_acc: 32.81%] [G loss: 1.020534]\n",
      "epoch:3 step:2749[D loss: 0.439830, acc: 57.81%, op_acc: 29.69%] [G loss: 1.017488]\n",
      "epoch:3 step:2750[D loss: 0.432994, acc: 66.41%, op_acc: 28.12%] [G loss: 0.973737]\n",
      "epoch:3 step:2751[D loss: 0.460161, acc: 57.03%, op_acc: 32.03%] [G loss: 0.998488]\n",
      "epoch:3 step:2752[D loss: 0.482933, acc: 53.12%, op_acc: 34.38%] [G loss: 0.999927]\n",
      "epoch:3 step:2753[D loss: 0.388468, acc: 64.84%, op_acc: 41.41%] [G loss: 0.925837]\n",
      "epoch:3 step:2754[D loss: 0.513697, acc: 50.78%, op_acc: 29.69%] [G loss: 0.917711]\n",
      "epoch:3 step:2755[D loss: 0.426717, acc: 66.41%, op_acc: 39.84%] [G loss: 0.932822]\n",
      "epoch:3 step:2756[D loss: 0.470658, acc: 61.72%, op_acc: 30.47%] [G loss: 0.968941]\n",
      "epoch:3 step:2757[D loss: 0.457387, acc: 58.59%, op_acc: 31.25%] [G loss: 1.095789]\n",
      "epoch:3 step:2758[D loss: 0.447580, acc: 60.94%, op_acc: 36.72%] [G loss: 1.017173]\n",
      "epoch:3 step:2759[D loss: 0.420655, acc: 70.31%, op_acc: 31.25%] [G loss: 1.107106]\n",
      "epoch:3 step:2760[D loss: 0.468550, acc: 64.06%, op_acc: 31.25%] [G loss: 0.999730]\n",
      "epoch:3 step:2761[D loss: 0.415283, acc: 66.41%, op_acc: 35.16%] [G loss: 0.952926]\n",
      "epoch:3 step:2762[D loss: 0.463707, acc: 62.50%, op_acc: 34.38%] [G loss: 1.037412]\n",
      "epoch:3 step:2763[D loss: 0.443045, acc: 62.50%, op_acc: 34.38%] [G loss: 1.137159]\n",
      "epoch:3 step:2764[D loss: 0.439565, acc: 68.75%, op_acc: 35.94%] [G loss: 1.037847]\n",
      "epoch:3 step:2765[D loss: 0.434898, acc: 58.59%, op_acc: 37.50%] [G loss: 1.095159]\n",
      "epoch:3 step:2766[D loss: 0.461055, acc: 62.50%, op_acc: 27.34%] [G loss: 1.028353]\n",
      "epoch:3 step:2767[D loss: 0.458167, acc: 64.06%, op_acc: 31.25%] [G loss: 0.984958]\n",
      "epoch:3 step:2768[D loss: 0.461288, acc: 61.72%, op_acc: 32.81%] [G loss: 0.999821]\n",
      "epoch:3 step:2769[D loss: 0.485172, acc: 57.81%, op_acc: 34.38%] [G loss: 0.868634]\n",
      "epoch:3 step:2770[D loss: 0.446544, acc: 62.50%, op_acc: 29.69%] [G loss: 0.925270]\n",
      "epoch:3 step:2771[D loss: 0.457315, acc: 60.94%, op_acc: 31.25%] [G loss: 0.830182]\n",
      "epoch:3 step:2772[D loss: 0.491465, acc: 55.47%, op_acc: 32.81%] [G loss: 0.919263]\n",
      "epoch:3 step:2773[D loss: 0.467990, acc: 59.38%, op_acc: 27.34%] [G loss: 0.935407]\n",
      "epoch:3 step:2774[D loss: 0.451668, acc: 60.94%, op_acc: 31.25%] [G loss: 1.024021]\n",
      "epoch:3 step:2775[D loss: 0.434365, acc: 61.72%, op_acc: 36.72%] [G loss: 0.986530]\n",
      "epoch:3 step:2776[D loss: 0.442646, acc: 66.41%, op_acc: 31.25%] [G loss: 0.995900]\n",
      "epoch:3 step:2777[D loss: 0.468522, acc: 55.47%, op_acc: 34.38%] [G loss: 0.896924]\n",
      "epoch:3 step:2778[D loss: 0.441157, acc: 64.84%, op_acc: 32.03%] [G loss: 1.065674]\n",
      "epoch:3 step:2779[D loss: 0.446817, acc: 59.38%, op_acc: 28.91%] [G loss: 0.965251]\n",
      "epoch:3 step:2780[D loss: 0.491082, acc: 53.12%, op_acc: 35.16%] [G loss: 1.007285]\n",
      "epoch:3 step:2781[D loss: 0.438047, acc: 67.19%, op_acc: 31.25%] [G loss: 1.060600]\n",
      "epoch:3 step:2782[D loss: 0.421953, acc: 63.28%, op_acc: 32.81%] [G loss: 1.151133]\n",
      "epoch:3 step:2783[D loss: 0.428699, acc: 67.19%, op_acc: 31.25%] [G loss: 1.115286]\n",
      "epoch:3 step:2784[D loss: 0.453993, acc: 61.72%, op_acc: 32.81%] [G loss: 0.925146]\n",
      "epoch:3 step:2785[D loss: 0.440094, acc: 62.50%, op_acc: 30.47%] [G loss: 1.054144]\n",
      "epoch:3 step:2786[D loss: 0.427567, acc: 67.97%, op_acc: 32.03%] [G loss: 1.138224]\n",
      "epoch:3 step:2787[D loss: 0.402254, acc: 73.44%, op_acc: 32.03%] [G loss: 1.041851]\n",
      "epoch:3 step:2788[D loss: 0.441611, acc: 68.75%, op_acc: 28.12%] [G loss: 1.048739]\n",
      "epoch:3 step:2789[D loss: 0.467692, acc: 57.03%, op_acc: 31.25%] [G loss: 0.993500]\n",
      "epoch:3 step:2790[D loss: 0.452813, acc: 69.53%, op_acc: 30.47%] [G loss: 1.024041]\n",
      "epoch:3 step:2791[D loss: 0.438641, acc: 60.94%, op_acc: 33.59%] [G loss: 1.016344]\n",
      "epoch:3 step:2792[D loss: 0.474398, acc: 57.81%, op_acc: 25.78%] [G loss: 1.081565]\n",
      "epoch:3 step:2793[D loss: 0.477753, acc: 53.91%, op_acc: 25.78%] [G loss: 0.959049]\n",
      "epoch:3 step:2794[D loss: 0.444612, acc: 61.72%, op_acc: 34.38%] [G loss: 1.003015]\n",
      "epoch:3 step:2795[D loss: 0.426666, acc: 61.72%, op_acc: 35.94%] [G loss: 0.985561]\n",
      "epoch:3 step:2796[D loss: 0.435140, acc: 54.69%, op_acc: 35.16%] [G loss: 0.984752]\n",
      "epoch:3 step:2797[D loss: 0.423140, acc: 71.09%, op_acc: 31.25%] [G loss: 1.035402]\n",
      "epoch:3 step:2798[D loss: 0.472041, acc: 60.94%, op_acc: 25.78%] [G loss: 0.926490]\n",
      "epoch:3 step:2799[D loss: 0.478817, acc: 56.25%, op_acc: 32.81%] [G loss: 0.917203]\n",
      "epoch:3 step:2800[D loss: 0.427531, acc: 67.97%, op_acc: 33.59%] [G loss: 1.062147]\n",
      "epoch:3 step:2801[D loss: 0.469753, acc: 54.69%, op_acc: 33.59%] [G loss: 0.988231]\n",
      "epoch:3 step:2802[D loss: 0.436154, acc: 60.94%, op_acc: 34.38%] [G loss: 1.035861]\n",
      "epoch:3 step:2803[D loss: 0.404780, acc: 67.97%, op_acc: 34.38%] [G loss: 0.961221]\n",
      "epoch:3 step:2804[D loss: 0.426606, acc: 70.31%, op_acc: 34.38%] [G loss: 0.983895]\n",
      "epoch:3 step:2805[D loss: 0.441519, acc: 65.62%, op_acc: 31.25%] [G loss: 1.157725]\n",
      "epoch:3 step:2806[D loss: 0.448445, acc: 64.06%, op_acc: 34.38%] [G loss: 1.124457]\n",
      "epoch:3 step:2807[D loss: 0.435762, acc: 71.88%, op_acc: 35.16%] [G loss: 1.181357]\n",
      "epoch:3 step:2808[D loss: 0.406961, acc: 72.66%, op_acc: 28.91%] [G loss: 1.097658]\n",
      "epoch:3 step:2809[D loss: 0.427026, acc: 58.59%, op_acc: 39.84%] [G loss: 1.151301]\n",
      "epoch:3 step:2810[D loss: 0.457337, acc: 61.72%, op_acc: 32.03%] [G loss: 0.992480]\n",
      "epoch:3 step:2811[D loss: 0.454621, acc: 62.50%, op_acc: 28.91%] [G loss: 1.001011]\n",
      "epoch:3 step:2812[D loss: 0.456448, acc: 60.16%, op_acc: 27.34%] [G loss: 0.940061]\n",
      "epoch:3 step:2813[D loss: 0.450382, acc: 61.72%, op_acc: 39.06%] [G loss: 1.024526]\n",
      "epoch:3 step:2814[D loss: 0.449636, acc: 58.59%, op_acc: 32.81%] [G loss: 0.991540]\n",
      "epoch:3 step:2815[D loss: 0.464672, acc: 59.38%, op_acc: 29.69%] [G loss: 0.976247]\n",
      "epoch:3 step:2816[D loss: 0.461575, acc: 55.47%, op_acc: 33.59%] [G loss: 0.928963]\n",
      "epoch:3 step:2817[D loss: 0.438914, acc: 67.97%, op_acc: 30.47%] [G loss: 1.020553]\n",
      "epoch:3 step:2818[D loss: 0.458477, acc: 60.16%, op_acc: 34.38%] [G loss: 0.991239]\n",
      "epoch:3 step:2819[D loss: 0.493628, acc: 54.69%, op_acc: 25.00%] [G loss: 0.949886]\n",
      "epoch:3 step:2820[D loss: 0.422770, acc: 68.75%, op_acc: 32.81%] [G loss: 1.039440]\n",
      "epoch:3 step:2821[D loss: 0.457993, acc: 51.56%, op_acc: 35.94%] [G loss: 1.109634]\n",
      "epoch:3 step:2822[D loss: 0.443072, acc: 67.97%, op_acc: 28.12%] [G loss: 1.032897]\n",
      "epoch:3 step:2823[D loss: 0.444951, acc: 65.62%, op_acc: 32.81%] [G loss: 1.145265]\n",
      "epoch:3 step:2824[D loss: 0.479272, acc: 59.38%, op_acc: 30.47%] [G loss: 0.963097]\n",
      "epoch:3 step:2825[D loss: 0.449611, acc: 63.28%, op_acc: 33.59%] [G loss: 1.000085]\n",
      "epoch:3 step:2826[D loss: 0.422668, acc: 65.62%, op_acc: 30.47%] [G loss: 1.117854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2827[D loss: 0.433515, acc: 59.38%, op_acc: 35.94%] [G loss: 1.038402]\n",
      "epoch:3 step:2828[D loss: 0.425912, acc: 64.84%, op_acc: 38.28%] [G loss: 0.981671]\n",
      "epoch:3 step:2829[D loss: 0.400605, acc: 71.09%, op_acc: 37.50%] [G loss: 1.084472]\n",
      "epoch:3 step:2830[D loss: 0.434481, acc: 64.06%, op_acc: 33.59%] [G loss: 1.063565]\n",
      "epoch:3 step:2831[D loss: 0.394220, acc: 71.88%, op_acc: 33.59%] [G loss: 1.084015]\n",
      "epoch:3 step:2832[D loss: 0.449640, acc: 57.81%, op_acc: 39.84%] [G loss: 1.159770]\n",
      "epoch:3 step:2833[D loss: 0.419975, acc: 67.19%, op_acc: 32.81%] [G loss: 0.969717]\n",
      "epoch:3 step:2834[D loss: 0.431676, acc: 65.62%, op_acc: 33.59%] [G loss: 1.038278]\n",
      "epoch:3 step:2835[D loss: 0.433902, acc: 66.41%, op_acc: 37.50%] [G loss: 1.046083]\n",
      "epoch:3 step:2836[D loss: 0.433475, acc: 66.41%, op_acc: 32.81%] [G loss: 0.899577]\n",
      "epoch:3 step:2837[D loss: 0.446676, acc: 64.06%, op_acc: 25.78%] [G loss: 0.918420]\n",
      "epoch:3 step:2838[D loss: 0.456545, acc: 57.03%, op_acc: 32.81%] [G loss: 0.919553]\n",
      "epoch:3 step:2839[D loss: 0.437367, acc: 64.84%, op_acc: 29.69%] [G loss: 0.954362]\n",
      "epoch:3 step:2840[D loss: 0.434104, acc: 63.28%, op_acc: 35.16%] [G loss: 0.990706]\n",
      "epoch:3 step:2841[D loss: 0.469123, acc: 62.50%, op_acc: 30.47%] [G loss: 1.020785]\n",
      "epoch:3 step:2842[D loss: 0.504738, acc: 51.56%, op_acc: 32.03%] [G loss: 1.007181]\n",
      "epoch:3 step:2843[D loss: 0.438539, acc: 60.94%, op_acc: 35.94%] [G loss: 0.967114]\n",
      "epoch:3 step:2844[D loss: 0.455205, acc: 65.62%, op_acc: 34.38%] [G loss: 0.982454]\n",
      "epoch:3 step:2845[D loss: 0.435755, acc: 67.97%, op_acc: 29.69%] [G loss: 1.039395]\n",
      "epoch:3 step:2846[D loss: 0.425604, acc: 65.62%, op_acc: 32.03%] [G loss: 0.996892]\n",
      "epoch:3 step:2847[D loss: 0.474713, acc: 53.12%, op_acc: 31.25%] [G loss: 1.097389]\n",
      "epoch:3 step:2848[D loss: 0.455185, acc: 64.84%, op_acc: 36.72%] [G loss: 1.035263]\n",
      "epoch:3 step:2849[D loss: 0.500393, acc: 53.91%, op_acc: 30.47%] [G loss: 0.953470]\n",
      "epoch:3 step:2850[D loss: 0.422373, acc: 64.84%, op_acc: 29.69%] [G loss: 1.136556]\n",
      "epoch:3 step:2851[D loss: 0.410622, acc: 66.41%, op_acc: 32.81%] [G loss: 1.066336]\n",
      "epoch:3 step:2852[D loss: 0.487548, acc: 60.16%, op_acc: 35.16%] [G loss: 1.123383]\n",
      "epoch:3 step:2853[D loss: 0.454924, acc: 63.28%, op_acc: 39.06%] [G loss: 1.039562]\n",
      "epoch:3 step:2854[D loss: 0.444847, acc: 64.84%, op_acc: 30.47%] [G loss: 1.218695]\n",
      "epoch:3 step:2855[D loss: 0.450953, acc: 63.28%, op_acc: 27.34%] [G loss: 1.084770]\n",
      "epoch:3 step:2856[D loss: 0.468201, acc: 56.25%, op_acc: 32.03%] [G loss: 1.023948]\n",
      "epoch:3 step:2857[D loss: 0.498791, acc: 53.12%, op_acc: 32.81%] [G loss: 0.942202]\n",
      "epoch:3 step:2858[D loss: 0.452650, acc: 60.16%, op_acc: 26.56%] [G loss: 1.083718]\n",
      "epoch:3 step:2859[D loss: 0.430941, acc: 69.53%, op_acc: 32.81%] [G loss: 1.121704]\n",
      "epoch:3 step:2860[D loss: 0.463083, acc: 64.06%, op_acc: 30.47%] [G loss: 0.961839]\n",
      "epoch:3 step:2861[D loss: 0.440698, acc: 68.75%, op_acc: 26.56%] [G loss: 1.040915]\n",
      "epoch:3 step:2862[D loss: 0.423026, acc: 71.09%, op_acc: 34.38%] [G loss: 1.087501]\n",
      "epoch:3 step:2863[D loss: 0.434761, acc: 60.16%, op_acc: 34.38%] [G loss: 1.104883]\n",
      "epoch:3 step:2864[D loss: 0.488144, acc: 54.69%, op_acc: 28.12%] [G loss: 0.992406]\n",
      "epoch:3 step:2865[D loss: 0.460945, acc: 67.97%, op_acc: 29.69%] [G loss: 1.043401]\n",
      "epoch:3 step:2866[D loss: 0.469144, acc: 57.03%, op_acc: 31.25%] [G loss: 0.948948]\n",
      "epoch:3 step:2867[D loss: 0.454833, acc: 64.84%, op_acc: 27.34%] [G loss: 0.930379]\n",
      "epoch:3 step:2868[D loss: 0.438879, acc: 62.50%, op_acc: 30.47%] [G loss: 1.096821]\n",
      "epoch:3 step:2869[D loss: 0.432314, acc: 71.09%, op_acc: 28.91%] [G loss: 1.007383]\n",
      "epoch:3 step:2870[D loss: 0.465803, acc: 57.03%, op_acc: 32.81%] [G loss: 0.958888]\n",
      "epoch:3 step:2871[D loss: 0.442683, acc: 57.03%, op_acc: 37.50%] [G loss: 1.007462]\n",
      "epoch:3 step:2872[D loss: 0.438421, acc: 60.16%, op_acc: 30.47%] [G loss: 1.125931]\n",
      "epoch:3 step:2873[D loss: 0.423275, acc: 66.41%, op_acc: 25.00%] [G loss: 1.128277]\n",
      "epoch:3 step:2874[D loss: 0.473228, acc: 57.03%, op_acc: 29.69%] [G loss: 0.862152]\n",
      "epoch:3 step:2875[D loss: 0.413803, acc: 68.75%, op_acc: 33.59%] [G loss: 0.975084]\n",
      "epoch:3 step:2876[D loss: 0.431058, acc: 61.72%, op_acc: 31.25%] [G loss: 0.955250]\n",
      "epoch:3 step:2877[D loss: 0.457652, acc: 60.94%, op_acc: 30.47%] [G loss: 0.964545]\n",
      "epoch:3 step:2878[D loss: 0.447275, acc: 63.28%, op_acc: 27.34%] [G loss: 0.935413]\n",
      "epoch:3 step:2879[D loss: 0.411472, acc: 68.75%, op_acc: 35.16%] [G loss: 0.969222]\n",
      "epoch:3 step:2880[D loss: 0.432153, acc: 66.41%, op_acc: 29.69%] [G loss: 0.976488]\n",
      "epoch:3 step:2881[D loss: 0.416054, acc: 64.84%, op_acc: 35.94%] [G loss: 0.863181]\n",
      "epoch:3 step:2882[D loss: 0.417178, acc: 67.97%, op_acc: 35.16%] [G loss: 1.062999]\n",
      "epoch:3 step:2883[D loss: 0.435186, acc: 58.59%, op_acc: 35.16%] [G loss: 1.074600]\n",
      "epoch:3 step:2884[D loss: 0.422220, acc: 64.84%, op_acc: 38.28%] [G loss: 0.920476]\n",
      "epoch:3 step:2885[D loss: 0.445154, acc: 59.38%, op_acc: 26.56%] [G loss: 1.065348]\n",
      "epoch:3 step:2886[D loss: 0.456044, acc: 62.50%, op_acc: 32.03%] [G loss: 1.000533]\n",
      "epoch:3 step:2887[D loss: 0.437646, acc: 64.06%, op_acc: 39.84%] [G loss: 1.109904]\n",
      "epoch:3 step:2888[D loss: 0.406968, acc: 71.09%, op_acc: 35.16%] [G loss: 1.052204]\n",
      "epoch:3 step:2889[D loss: 0.484193, acc: 57.81%, op_acc: 27.34%] [G loss: 0.956073]\n",
      "epoch:3 step:2890[D loss: 0.477949, acc: 58.59%, op_acc: 32.81%] [G loss: 0.873281]\n",
      "epoch:3 step:2891[D loss: 0.438823, acc: 67.97%, op_acc: 31.25%] [G loss: 1.001644]\n",
      "epoch:3 step:2892[D loss: 0.446083, acc: 56.25%, op_acc: 34.38%] [G loss: 1.078122]\n",
      "epoch:3 step:2893[D loss: 0.437052, acc: 67.19%, op_acc: 34.38%] [G loss: 0.996895]\n",
      "epoch:3 step:2894[D loss: 0.462196, acc: 54.69%, op_acc: 31.25%] [G loss: 1.096123]\n",
      "epoch:3 step:2895[D loss: 0.451221, acc: 64.84%, op_acc: 28.12%] [G loss: 1.126191]\n",
      "epoch:3 step:2896[D loss: 0.428893, acc: 65.62%, op_acc: 35.94%] [G loss: 1.148103]\n",
      "epoch:3 step:2897[D loss: 0.428578, acc: 69.53%, op_acc: 31.25%] [G loss: 1.001351]\n",
      "epoch:3 step:2898[D loss: 0.436590, acc: 64.06%, op_acc: 33.59%] [G loss: 0.966315]\n",
      "epoch:3 step:2899[D loss: 0.444945, acc: 58.59%, op_acc: 36.72%] [G loss: 0.927156]\n",
      "epoch:3 step:2900[D loss: 0.447423, acc: 63.28%, op_acc: 29.69%] [G loss: 0.948539]\n",
      "epoch:3 step:2901[D loss: 0.460581, acc: 60.94%, op_acc: 30.47%] [G loss: 1.029288]\n",
      "epoch:3 step:2902[D loss: 0.434930, acc: 68.75%, op_acc: 33.59%] [G loss: 1.241728]\n",
      "epoch:3 step:2903[D loss: 0.460358, acc: 57.81%, op_acc: 25.00%] [G loss: 1.067447]\n",
      "epoch:3 step:2904[D loss: 0.416377, acc: 68.75%, op_acc: 30.47%] [G loss: 1.077383]\n",
      "epoch:3 step:2905[D loss: 0.430428, acc: 63.28%, op_acc: 35.94%] [G loss: 1.016946]\n",
      "epoch:3 step:2906[D loss: 0.461481, acc: 53.91%, op_acc: 29.69%] [G loss: 1.027871]\n",
      "epoch:3 step:2907[D loss: 0.488354, acc: 54.69%, op_acc: 28.91%] [G loss: 0.941483]\n",
      "epoch:3 step:2908[D loss: 0.445957, acc: 64.84%, op_acc: 42.97%] [G loss: 1.044952]\n",
      "epoch:3 step:2909[D loss: 0.463560, acc: 63.28%, op_acc: 31.25%] [G loss: 0.954016]\n",
      "epoch:3 step:2910[D loss: 0.434268, acc: 58.59%, op_acc: 33.59%] [G loss: 0.942462]\n",
      "epoch:3 step:2911[D loss: 0.440949, acc: 60.94%, op_acc: 32.03%] [G loss: 1.043245]\n",
      "epoch:3 step:2912[D loss: 0.466891, acc: 54.69%, op_acc: 30.47%] [G loss: 0.881854]\n",
      "epoch:3 step:2913[D loss: 0.440201, acc: 60.94%, op_acc: 35.16%] [G loss: 1.006765]\n",
      "epoch:3 step:2914[D loss: 0.462192, acc: 57.03%, op_acc: 28.91%] [G loss: 0.996703]\n",
      "epoch:3 step:2915[D loss: 0.454170, acc: 51.56%, op_acc: 34.38%] [G loss: 1.010901]\n",
      "epoch:3 step:2916[D loss: 0.437442, acc: 64.06%, op_acc: 39.06%] [G loss: 1.030435]\n",
      "epoch:3 step:2917[D loss: 0.446050, acc: 60.16%, op_acc: 28.12%] [G loss: 0.886993]\n",
      "epoch:3 step:2918[D loss: 0.473930, acc: 62.50%, op_acc: 33.59%] [G loss: 0.859363]\n",
      "epoch:3 step:2919[D loss: 0.408520, acc: 68.75%, op_acc: 39.06%] [G loss: 0.945056]\n",
      "epoch:3 step:2920[D loss: 0.429374, acc: 65.62%, op_acc: 33.59%] [G loss: 1.127980]\n",
      "epoch:3 step:2921[D loss: 0.479926, acc: 60.94%, op_acc: 28.91%] [G loss: 1.122000]\n",
      "epoch:3 step:2922[D loss: 0.381145, acc: 75.00%, op_acc: 36.72%] [G loss: 1.046266]\n",
      "epoch:3 step:2923[D loss: 0.444969, acc: 65.62%, op_acc: 35.94%] [G loss: 1.094696]\n",
      "epoch:3 step:2924[D loss: 0.475465, acc: 57.81%, op_acc: 28.91%] [G loss: 0.997062]\n",
      "epoch:3 step:2925[D loss: 0.457149, acc: 60.16%, op_acc: 26.56%] [G loss: 0.954260]\n",
      "epoch:3 step:2926[D loss: 0.443375, acc: 61.72%, op_acc: 31.25%] [G loss: 1.025525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2927[D loss: 0.426748, acc: 67.19%, op_acc: 31.25%] [G loss: 1.079917]\n",
      "epoch:3 step:2928[D loss: 0.446827, acc: 61.72%, op_acc: 32.03%] [G loss: 0.979652]\n",
      "epoch:3 step:2929[D loss: 0.483528, acc: 53.91%, op_acc: 32.03%] [G loss: 0.937319]\n",
      "epoch:3 step:2930[D loss: 0.459776, acc: 63.28%, op_acc: 30.47%] [G loss: 0.996559]\n",
      "epoch:3 step:2931[D loss: 0.440400, acc: 62.50%, op_acc: 32.81%] [G loss: 0.972721]\n",
      "epoch:3 step:2932[D loss: 0.453174, acc: 59.38%, op_acc: 28.12%] [G loss: 1.019368]\n",
      "epoch:3 step:2933[D loss: 0.483000, acc: 60.16%, op_acc: 32.03%] [G loss: 1.083310]\n",
      "epoch:3 step:2934[D loss: 0.464987, acc: 54.69%, op_acc: 34.38%] [G loss: 1.042744]\n",
      "epoch:3 step:2935[D loss: 0.467249, acc: 54.69%, op_acc: 39.84%] [G loss: 1.072160]\n",
      "epoch:3 step:2936[D loss: 0.451889, acc: 64.06%, op_acc: 27.34%] [G loss: 0.994309]\n",
      "epoch:3 step:2937[D loss: 0.458888, acc: 60.16%, op_acc: 32.81%] [G loss: 1.040023]\n",
      "epoch:3 step:2938[D loss: 0.420186, acc: 72.66%, op_acc: 29.69%] [G loss: 1.045081]\n",
      "epoch:3 step:2939[D loss: 0.467739, acc: 59.38%, op_acc: 30.47%] [G loss: 1.007324]\n",
      "epoch:3 step:2940[D loss: 0.416651, acc: 65.62%, op_acc: 35.16%] [G loss: 1.107231]\n",
      "epoch:3 step:2941[D loss: 0.424884, acc: 69.53%, op_acc: 35.94%] [G loss: 1.053833]\n",
      "epoch:3 step:2942[D loss: 0.411620, acc: 69.53%, op_acc: 36.72%] [G loss: 1.176333]\n",
      "epoch:3 step:2943[D loss: 0.443012, acc: 64.06%, op_acc: 25.78%] [G loss: 1.131208]\n",
      "epoch:3 step:2944[D loss: 0.446604, acc: 62.50%, op_acc: 32.81%] [G loss: 1.166554]\n",
      "epoch:3 step:2945[D loss: 0.448454, acc: 61.72%, op_acc: 44.53%] [G loss: 1.097648]\n",
      "epoch:3 step:2946[D loss: 0.428438, acc: 62.50%, op_acc: 38.28%] [G loss: 1.070859]\n",
      "epoch:3 step:2947[D loss: 0.464155, acc: 70.31%, op_acc: 28.12%] [G loss: 1.028653]\n",
      "epoch:3 step:2948[D loss: 0.431470, acc: 61.72%, op_acc: 32.03%] [G loss: 1.063102]\n",
      "epoch:3 step:2949[D loss: 0.461476, acc: 59.38%, op_acc: 32.03%] [G loss: 1.008685]\n",
      "epoch:3 step:2950[D loss: 0.439481, acc: 61.72%, op_acc: 38.28%] [G loss: 1.085165]\n",
      "epoch:3 step:2951[D loss: 0.451019, acc: 55.47%, op_acc: 35.94%] [G loss: 1.018198]\n",
      "epoch:3 step:2952[D loss: 0.463794, acc: 58.59%, op_acc: 33.59%] [G loss: 1.025906]\n",
      "epoch:3 step:2953[D loss: 0.446122, acc: 64.84%, op_acc: 33.59%] [G loss: 0.949980]\n",
      "epoch:3 step:2954[D loss: 0.455898, acc: 61.72%, op_acc: 31.25%] [G loss: 0.889160]\n",
      "epoch:3 step:2955[D loss: 0.444442, acc: 56.25%, op_acc: 31.25%] [G loss: 1.004011]\n",
      "epoch:3 step:2956[D loss: 0.456223, acc: 60.16%, op_acc: 34.38%] [G loss: 1.056372]\n",
      "epoch:3 step:2957[D loss: 0.396998, acc: 73.44%, op_acc: 35.94%] [G loss: 1.074634]\n",
      "epoch:3 step:2958[D loss: 0.459119, acc: 57.03%, op_acc: 34.38%] [G loss: 1.089436]\n",
      "epoch:3 step:2959[D loss: 0.451345, acc: 60.16%, op_acc: 35.16%] [G loss: 1.142841]\n",
      "epoch:3 step:2960[D loss: 0.513012, acc: 48.44%, op_acc: 28.12%] [G loss: 1.050996]\n",
      "epoch:3 step:2961[D loss: 0.443523, acc: 67.19%, op_acc: 26.56%] [G loss: 0.892980]\n",
      "epoch:3 step:2962[D loss: 0.459732, acc: 60.16%, op_acc: 28.91%] [G loss: 0.964564]\n",
      "epoch:3 step:2963[D loss: 0.441691, acc: 65.62%, op_acc: 35.16%] [G loss: 0.988038]\n",
      "epoch:3 step:2964[D loss: 0.438930, acc: 67.97%, op_acc: 35.94%] [G loss: 1.070372]\n",
      "epoch:3 step:2965[D loss: 0.488213, acc: 53.12%, op_acc: 26.56%] [G loss: 0.961196]\n",
      "epoch:3 step:2966[D loss: 0.413911, acc: 69.53%, op_acc: 38.28%] [G loss: 0.994364]\n",
      "epoch:3 step:2967[D loss: 0.453328, acc: 57.81%, op_acc: 31.25%] [G loss: 0.944794]\n",
      "epoch:3 step:2968[D loss: 0.430653, acc: 67.19%, op_acc: 29.69%] [G loss: 0.990783]\n",
      "epoch:3 step:2969[D loss: 0.430232, acc: 64.06%, op_acc: 35.94%] [G loss: 1.013215]\n",
      "epoch:3 step:2970[D loss: 0.443724, acc: 61.72%, op_acc: 35.94%] [G loss: 1.124908]\n",
      "epoch:3 step:2971[D loss: 0.452131, acc: 59.38%, op_acc: 33.59%] [G loss: 0.904161]\n",
      "epoch:3 step:2972[D loss: 0.506927, acc: 53.91%, op_acc: 23.44%] [G loss: 1.054849]\n",
      "epoch:3 step:2973[D loss: 0.436154, acc: 62.50%, op_acc: 34.38%] [G loss: 1.041025]\n",
      "epoch:3 step:2974[D loss: 0.440140, acc: 61.72%, op_acc: 33.59%] [G loss: 1.019484]\n",
      "epoch:3 step:2975[D loss: 0.445304, acc: 65.62%, op_acc: 30.47%] [G loss: 1.012190]\n",
      "epoch:3 step:2976[D loss: 0.470911, acc: 59.38%, op_acc: 35.94%] [G loss: 0.981803]\n",
      "epoch:3 step:2977[D loss: 0.414992, acc: 66.41%, op_acc: 37.50%] [G loss: 1.028255]\n",
      "epoch:3 step:2978[D loss: 0.444465, acc: 60.16%, op_acc: 42.19%] [G loss: 1.053494]\n",
      "epoch:3 step:2979[D loss: 0.447233, acc: 59.38%, op_acc: 34.38%] [G loss: 1.003956]\n",
      "epoch:3 step:2980[D loss: 0.441334, acc: 64.06%, op_acc: 25.78%] [G loss: 1.018370]\n",
      "epoch:3 step:2981[D loss: 0.439586, acc: 60.16%, op_acc: 36.72%] [G loss: 1.072403]\n",
      "epoch:3 step:2982[D loss: 0.464427, acc: 59.38%, op_acc: 28.12%] [G loss: 0.971397]\n",
      "epoch:3 step:2983[D loss: 0.449736, acc: 71.09%, op_acc: 28.12%] [G loss: 1.097736]\n",
      "epoch:3 step:2984[D loss: 0.477450, acc: 58.59%, op_acc: 27.34%] [G loss: 0.925305]\n",
      "epoch:3 step:2985[D loss: 0.473247, acc: 60.16%, op_acc: 28.12%] [G loss: 1.056858]\n",
      "epoch:3 step:2986[D loss: 0.416090, acc: 72.66%, op_acc: 32.03%] [G loss: 1.115572]\n",
      "epoch:3 step:2987[D loss: 0.443033, acc: 67.19%, op_acc: 35.94%] [G loss: 0.980884]\n",
      "epoch:3 step:2988[D loss: 0.443753, acc: 61.72%, op_acc: 28.91%] [G loss: 1.038261]\n",
      "epoch:3 step:2989[D loss: 0.437525, acc: 67.19%, op_acc: 28.91%] [G loss: 0.998310]\n",
      "epoch:3 step:2990[D loss: 0.444417, acc: 55.47%, op_acc: 31.25%] [G loss: 1.050492]\n",
      "epoch:3 step:2991[D loss: 0.462002, acc: 59.38%, op_acc: 27.34%] [G loss: 0.962602]\n",
      "epoch:3 step:2992[D loss: 0.508867, acc: 52.34%, op_acc: 28.91%] [G loss: 1.082199]\n",
      "epoch:3 step:2993[D loss: 0.470785, acc: 57.81%, op_acc: 31.25%] [G loss: 1.044850]\n",
      "epoch:3 step:2994[D loss: 0.492581, acc: 54.69%, op_acc: 31.25%] [G loss: 1.024376]\n",
      "epoch:3 step:2995[D loss: 0.447949, acc: 58.59%, op_acc: 28.12%] [G loss: 0.990470]\n",
      "epoch:3 step:2996[D loss: 0.447716, acc: 57.03%, op_acc: 35.16%] [G loss: 0.984471]\n",
      "epoch:3 step:2997[D loss: 0.446900, acc: 60.94%, op_acc: 31.25%] [G loss: 1.007470]\n",
      "epoch:3 step:2998[D loss: 0.427925, acc: 67.97%, op_acc: 35.16%] [G loss: 0.993681]\n",
      "epoch:3 step:2999[D loss: 0.447133, acc: 61.72%, op_acc: 27.34%] [G loss: 1.065324]\n",
      "epoch:3 step:3000[D loss: 0.436254, acc: 67.97%, op_acc: 34.38%] [G loss: 1.042506]\n",
      "epoch:3 step:3001[D loss: 0.419483, acc: 68.75%, op_acc: 33.59%] [G loss: 1.077573]\n",
      "epoch:3 step:3002[D loss: 0.466730, acc: 62.50%, op_acc: 28.12%] [G loss: 1.076635]\n",
      "epoch:3 step:3003[D loss: 0.447388, acc: 57.03%, op_acc: 34.38%] [G loss: 1.168619]\n",
      "epoch:3 step:3004[D loss: 0.431758, acc: 60.94%, op_acc: 33.59%] [G loss: 1.008232]\n",
      "epoch:3 step:3005[D loss: 0.433820, acc: 57.03%, op_acc: 39.84%] [G loss: 1.014040]\n",
      "epoch:3 step:3006[D loss: 0.418161, acc: 65.62%, op_acc: 35.16%] [G loss: 1.015018]\n",
      "epoch:3 step:3007[D loss: 0.424002, acc: 67.19%, op_acc: 32.03%] [G loss: 0.964002]\n",
      "epoch:3 step:3008[D loss: 0.450802, acc: 57.81%, op_acc: 26.56%] [G loss: 1.063000]\n",
      "epoch:3 step:3009[D loss: 0.479396, acc: 56.25%, op_acc: 32.03%] [G loss: 0.968312]\n",
      "epoch:3 step:3010[D loss: 0.430602, acc: 68.75%, op_acc: 32.03%] [G loss: 0.970605]\n",
      "epoch:3 step:3011[D loss: 0.454641, acc: 62.50%, op_acc: 29.69%] [G loss: 1.077105]\n",
      "epoch:3 step:3012[D loss: 0.412541, acc: 69.53%, op_acc: 35.94%] [G loss: 1.075593]\n",
      "epoch:3 step:3013[D loss: 0.437007, acc: 66.41%, op_acc: 32.81%] [G loss: 0.981631]\n",
      "epoch:3 step:3014[D loss: 0.452766, acc: 60.94%, op_acc: 32.03%] [G loss: 0.989573]\n",
      "epoch:3 step:3015[D loss: 0.439255, acc: 64.84%, op_acc: 34.38%] [G loss: 1.061280]\n",
      "epoch:3 step:3016[D loss: 0.441519, acc: 67.19%, op_acc: 33.59%] [G loss: 0.932727]\n",
      "epoch:3 step:3017[D loss: 0.435202, acc: 57.81%, op_acc: 30.47%] [G loss: 1.052871]\n",
      "epoch:3 step:3018[D loss: 0.468885, acc: 57.03%, op_acc: 34.38%] [G loss: 1.003471]\n",
      "epoch:3 step:3019[D loss: 0.499656, acc: 58.59%, op_acc: 28.91%] [G loss: 0.974504]\n",
      "epoch:3 step:3020[D loss: 0.460192, acc: 64.84%, op_acc: 27.34%] [G loss: 0.945238]\n",
      "epoch:3 step:3021[D loss: 0.419010, acc: 67.97%, op_acc: 38.28%] [G loss: 0.980113]\n",
      "epoch:3 step:3022[D loss: 0.483694, acc: 57.81%, op_acc: 31.25%] [G loss: 1.055159]\n",
      "epoch:3 step:3023[D loss: 0.459562, acc: 66.41%, op_acc: 32.03%] [G loss: 1.066308]\n",
      "epoch:3 step:3024[D loss: 0.493141, acc: 57.81%, op_acc: 29.69%] [G loss: 0.977877]\n",
      "epoch:3 step:3025[D loss: 0.450466, acc: 66.41%, op_acc: 31.25%] [G loss: 0.979959]\n",
      "epoch:3 step:3026[D loss: 0.455621, acc: 56.25%, op_acc: 32.03%] [G loss: 1.006601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3027[D loss: 0.439604, acc: 57.81%, op_acc: 31.25%] [G loss: 1.106536]\n",
      "epoch:3 step:3028[D loss: 0.483672, acc: 58.59%, op_acc: 27.34%] [G loss: 0.976253]\n",
      "epoch:3 step:3029[D loss: 0.460137, acc: 64.84%, op_acc: 28.12%] [G loss: 0.946835]\n",
      "epoch:3 step:3030[D loss: 0.412940, acc: 74.22%, op_acc: 28.91%] [G loss: 1.032920]\n",
      "epoch:3 step:3031[D loss: 0.434653, acc: 60.94%, op_acc: 35.16%] [G loss: 0.996831]\n",
      "epoch:3 step:3032[D loss: 0.465821, acc: 57.03%, op_acc: 29.69%] [G loss: 0.965016]\n",
      "epoch:3 step:3033[D loss: 0.450514, acc: 66.41%, op_acc: 29.69%] [G loss: 0.994518]\n",
      "epoch:3 step:3034[D loss: 0.453029, acc: 61.72%, op_acc: 30.47%] [G loss: 1.010719]\n",
      "epoch:3 step:3035[D loss: 0.457720, acc: 60.16%, op_acc: 33.59%] [G loss: 1.047035]\n",
      "epoch:3 step:3036[D loss: 0.456760, acc: 66.41%, op_acc: 22.66%] [G loss: 1.022342]\n",
      "epoch:3 step:3037[D loss: 0.448321, acc: 60.94%, op_acc: 33.59%] [G loss: 1.017840]\n",
      "epoch:3 step:3038[D loss: 0.434042, acc: 70.31%, op_acc: 31.25%] [G loss: 0.985934]\n",
      "epoch:3 step:3039[D loss: 0.506371, acc: 49.22%, op_acc: 26.56%] [G loss: 1.076618]\n",
      "epoch:3 step:3040[D loss: 0.485351, acc: 54.69%, op_acc: 35.16%] [G loss: 0.985431]\n",
      "epoch:3 step:3041[D loss: 0.464449, acc: 60.94%, op_acc: 28.12%] [G loss: 0.986379]\n",
      "epoch:3 step:3042[D loss: 0.431933, acc: 61.72%, op_acc: 28.12%] [G loss: 1.064032]\n",
      "epoch:3 step:3043[D loss: 0.447081, acc: 63.28%, op_acc: 32.81%] [G loss: 0.929270]\n",
      "epoch:3 step:3044[D loss: 0.405529, acc: 71.88%, op_acc: 28.91%] [G loss: 0.943561]\n",
      "epoch:3 step:3045[D loss: 0.423369, acc: 65.62%, op_acc: 33.59%] [G loss: 0.955007]\n",
      "epoch:3 step:3046[D loss: 0.453928, acc: 56.25%, op_acc: 28.12%] [G loss: 1.042452]\n",
      "epoch:3 step:3047[D loss: 0.435437, acc: 58.59%, op_acc: 36.72%] [G loss: 0.990846]\n",
      "epoch:3 step:3048[D loss: 0.450587, acc: 66.41%, op_acc: 28.91%] [G loss: 1.048735]\n",
      "epoch:3 step:3049[D loss: 0.442571, acc: 61.72%, op_acc: 28.12%] [G loss: 0.988020]\n",
      "epoch:3 step:3050[D loss: 0.432333, acc: 71.09%, op_acc: 28.91%] [G loss: 1.017407]\n",
      "epoch:3 step:3051[D loss: 0.465236, acc: 60.94%, op_acc: 29.69%] [G loss: 0.937285]\n",
      "epoch:3 step:3052[D loss: 0.437132, acc: 69.53%, op_acc: 32.81%] [G loss: 0.965916]\n",
      "epoch:3 step:3053[D loss: 0.413577, acc: 63.28%, op_acc: 37.50%] [G loss: 1.115739]\n",
      "epoch:3 step:3054[D loss: 0.446496, acc: 63.28%, op_acc: 28.91%] [G loss: 0.946353]\n",
      "epoch:3 step:3055[D loss: 0.403070, acc: 69.53%, op_acc: 38.28%] [G loss: 0.983874]\n",
      "epoch:3 step:3056[D loss: 0.447244, acc: 61.72%, op_acc: 36.72%] [G loss: 1.014205]\n",
      "epoch:3 step:3057[D loss: 0.487986, acc: 57.81%, op_acc: 22.66%] [G loss: 1.033317]\n",
      "epoch:3 step:3058[D loss: 0.465704, acc: 57.03%, op_acc: 29.69%] [G loss: 1.043480]\n",
      "epoch:3 step:3059[D loss: 0.470034, acc: 62.50%, op_acc: 32.03%] [G loss: 1.047312]\n",
      "epoch:3 step:3060[D loss: 0.428556, acc: 67.19%, op_acc: 33.59%] [G loss: 1.095048]\n",
      "epoch:3 step:3061[D loss: 0.472023, acc: 60.16%, op_acc: 28.12%] [G loss: 1.103657]\n",
      "epoch:3 step:3062[D loss: 0.454312, acc: 57.03%, op_acc: 32.81%] [G loss: 1.028394]\n",
      "epoch:3 step:3063[D loss: 0.488731, acc: 59.38%, op_acc: 29.69%] [G loss: 1.057155]\n",
      "epoch:3 step:3064[D loss: 0.445644, acc: 61.72%, op_acc: 38.28%] [G loss: 1.013575]\n",
      "epoch:3 step:3065[D loss: 0.458525, acc: 56.25%, op_acc: 29.69%] [G loss: 0.997171]\n",
      "epoch:3 step:3066[D loss: 0.452400, acc: 59.38%, op_acc: 28.91%] [G loss: 1.012547]\n",
      "epoch:3 step:3067[D loss: 0.497691, acc: 59.38%, op_acc: 16.41%] [G loss: 1.023889]\n",
      "epoch:3 step:3068[D loss: 0.472912, acc: 57.03%, op_acc: 31.25%] [G loss: 0.992317]\n",
      "epoch:3 step:3069[D loss: 0.449976, acc: 58.59%, op_acc: 38.28%] [G loss: 1.088499]\n",
      "epoch:3 step:3070[D loss: 0.475091, acc: 60.94%, op_acc: 21.88%] [G loss: 0.953239]\n",
      "epoch:3 step:3071[D loss: 0.444895, acc: 65.62%, op_acc: 27.34%] [G loss: 1.055043]\n",
      "epoch:3 step:3072[D loss: 0.442278, acc: 60.94%, op_acc: 30.47%] [G loss: 0.990781]\n",
      "epoch:3 step:3073[D loss: 0.455864, acc: 63.28%, op_acc: 27.34%] [G loss: 1.097420]\n",
      "epoch:3 step:3074[D loss: 0.442646, acc: 57.03%, op_acc: 31.25%] [G loss: 1.019958]\n",
      "epoch:3 step:3075[D loss: 0.521405, acc: 48.44%, op_acc: 28.12%] [G loss: 0.959720]\n",
      "epoch:3 step:3076[D loss: 0.436782, acc: 64.84%, op_acc: 37.50%] [G loss: 1.080286]\n",
      "epoch:3 step:3077[D loss: 0.462063, acc: 60.16%, op_acc: 31.25%] [G loss: 0.833059]\n",
      "epoch:3 step:3078[D loss: 0.447250, acc: 56.25%, op_acc: 32.03%] [G loss: 0.854866]\n",
      "epoch:3 step:3079[D loss: 0.444081, acc: 65.62%, op_acc: 35.94%] [G loss: 1.032961]\n",
      "epoch:3 step:3080[D loss: 0.453078, acc: 55.47%, op_acc: 38.28%] [G loss: 0.963944]\n",
      "epoch:3 step:3081[D loss: 0.450954, acc: 58.59%, op_acc: 39.06%] [G loss: 0.991081]\n",
      "epoch:3 step:3082[D loss: 0.428504, acc: 62.50%, op_acc: 33.59%] [G loss: 1.049516]\n",
      "epoch:3 step:3083[D loss: 0.439062, acc: 60.16%, op_acc: 34.38%] [G loss: 0.954741]\n",
      "epoch:3 step:3084[D loss: 0.443762, acc: 68.75%, op_acc: 25.00%] [G loss: 1.072303]\n",
      "epoch:3 step:3085[D loss: 0.452440, acc: 64.06%, op_acc: 36.72%] [G loss: 0.966323]\n",
      "epoch:3 step:3086[D loss: 0.474037, acc: 59.38%, op_acc: 27.34%] [G loss: 1.057486]\n",
      "epoch:3 step:3087[D loss: 0.386287, acc: 67.97%, op_acc: 44.53%] [G loss: 1.142467]\n",
      "epoch:3 step:3088[D loss: 0.465714, acc: 54.69%, op_acc: 32.81%] [G loss: 1.068518]\n",
      "epoch:3 step:3089[D loss: 0.451192, acc: 62.50%, op_acc: 28.12%] [G loss: 1.149614]\n",
      "epoch:3 step:3090[D loss: 0.452566, acc: 62.50%, op_acc: 31.25%] [G loss: 0.949193]\n",
      "epoch:3 step:3091[D loss: 0.511984, acc: 53.12%, op_acc: 25.78%] [G loss: 0.939748]\n",
      "epoch:3 step:3092[D loss: 0.460202, acc: 63.28%, op_acc: 29.69%] [G loss: 1.079220]\n",
      "epoch:3 step:3093[D loss: 0.436923, acc: 58.59%, op_acc: 36.72%] [G loss: 1.139361]\n",
      "epoch:3 step:3094[D loss: 0.480760, acc: 61.72%, op_acc: 29.69%] [G loss: 1.004432]\n",
      "epoch:3 step:3095[D loss: 0.449718, acc: 62.50%, op_acc: 27.34%] [G loss: 0.941105]\n",
      "epoch:3 step:3096[D loss: 0.458619, acc: 62.50%, op_acc: 29.69%] [G loss: 0.952778]\n",
      "epoch:3 step:3097[D loss: 0.445170, acc: 60.94%, op_acc: 36.72%] [G loss: 0.993325]\n",
      "epoch:3 step:3098[D loss: 0.427567, acc: 62.50%, op_acc: 34.38%] [G loss: 1.034904]\n",
      "epoch:3 step:3099[D loss: 0.424590, acc: 58.59%, op_acc: 40.62%] [G loss: 1.086499]\n",
      "epoch:3 step:3100[D loss: 0.430681, acc: 64.84%, op_acc: 34.38%] [G loss: 0.999348]\n",
      "epoch:3 step:3101[D loss: 0.461180, acc: 56.25%, op_acc: 32.03%] [G loss: 1.017099]\n",
      "epoch:3 step:3102[D loss: 0.444740, acc: 68.75%, op_acc: 32.81%] [G loss: 0.995934]\n",
      "epoch:3 step:3103[D loss: 0.437485, acc: 63.28%, op_acc: 39.06%] [G loss: 0.954309]\n",
      "epoch:3 step:3104[D loss: 0.445883, acc: 58.59%, op_acc: 36.72%] [G loss: 0.939339]\n",
      "epoch:3 step:3105[D loss: 0.491124, acc: 52.34%, op_acc: 32.03%] [G loss: 0.935119]\n",
      "epoch:3 step:3106[D loss: 0.472713, acc: 58.59%, op_acc: 32.81%] [G loss: 1.033962]\n",
      "epoch:3 step:3107[D loss: 0.443342, acc: 60.94%, op_acc: 31.25%] [G loss: 0.997278]\n",
      "epoch:3 step:3108[D loss: 0.415811, acc: 68.75%, op_acc: 34.38%] [G loss: 1.052991]\n",
      "epoch:3 step:3109[D loss: 0.512954, acc: 48.44%, op_acc: 30.47%] [G loss: 0.936095]\n",
      "epoch:3 step:3110[D loss: 0.439150, acc: 58.59%, op_acc: 35.94%] [G loss: 1.008554]\n",
      "epoch:3 step:3111[D loss: 0.485621, acc: 52.34%, op_acc: 24.22%] [G loss: 1.066303]\n",
      "epoch:3 step:3112[D loss: 0.448883, acc: 66.41%, op_acc: 38.28%] [G loss: 1.024958]\n",
      "epoch:3 step:3113[D loss: 0.456896, acc: 56.25%, op_acc: 32.81%] [G loss: 0.962345]\n",
      "epoch:3 step:3114[D loss: 0.457900, acc: 64.84%, op_acc: 28.91%] [G loss: 1.057451]\n",
      "epoch:3 step:3115[D loss: 0.476261, acc: 57.03%, op_acc: 29.69%] [G loss: 0.962085]\n",
      "epoch:3 step:3116[D loss: 0.443966, acc: 62.50%, op_acc: 30.47%] [G loss: 0.963753]\n",
      "epoch:3 step:3117[D loss: 0.441601, acc: 55.47%, op_acc: 30.47%] [G loss: 0.906044]\n",
      "epoch:3 step:3118[D loss: 0.451796, acc: 66.41%, op_acc: 25.78%] [G loss: 0.990223]\n",
      "epoch:3 step:3119[D loss: 0.424910, acc: 71.88%, op_acc: 32.03%] [G loss: 1.037699]\n",
      "epoch:3 step:3120[D loss: 0.458103, acc: 65.62%, op_acc: 27.34%] [G loss: 1.096341]\n",
      "epoch:3 step:3121[D loss: 0.420127, acc: 64.84%, op_acc: 36.72%] [G loss: 0.991484]\n",
      "epoch:3 step:3122[D loss: 0.468350, acc: 57.03%, op_acc: 30.47%] [G loss: 0.990420]\n",
      "epoch:3 step:3123[D loss: 0.417723, acc: 58.59%, op_acc: 35.94%] [G loss: 1.093107]\n",
      "epoch:3 step:3124[D loss: 0.449413, acc: 64.06%, op_acc: 36.72%] [G loss: 1.016542]\n",
      "epoch:4 step:3125[D loss: 0.442414, acc: 64.06%, op_acc: 25.78%] [G loss: 1.021390]\n",
      "epoch:4 step:3126[D loss: 0.408532, acc: 65.62%, op_acc: 32.81%] [G loss: 0.927744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3127[D loss: 0.430630, acc: 70.31%, op_acc: 30.47%] [G loss: 0.995427]\n",
      "epoch:4 step:3128[D loss: 0.416496, acc: 62.50%, op_acc: 35.94%] [G loss: 1.048292]\n",
      "epoch:4 step:3129[D loss: 0.421708, acc: 59.38%, op_acc: 37.50%] [G loss: 1.059666]\n",
      "epoch:4 step:3130[D loss: 0.444315, acc: 60.16%, op_acc: 32.81%] [G loss: 1.104951]\n",
      "epoch:4 step:3131[D loss: 0.434541, acc: 61.72%, op_acc: 32.81%] [G loss: 1.017523]\n",
      "epoch:4 step:3132[D loss: 0.495320, acc: 50.78%, op_acc: 30.47%] [G loss: 0.840763]\n",
      "epoch:4 step:3133[D loss: 0.434648, acc: 60.94%, op_acc: 31.25%] [G loss: 0.929386]\n",
      "epoch:4 step:3134[D loss: 0.497475, acc: 56.25%, op_acc: 28.12%] [G loss: 0.916708]\n",
      "epoch:4 step:3135[D loss: 0.461126, acc: 62.50%, op_acc: 29.69%] [G loss: 0.873482]\n",
      "epoch:4 step:3136[D loss: 0.454462, acc: 63.28%, op_acc: 30.47%] [G loss: 0.922421]\n",
      "epoch:4 step:3137[D loss: 0.455794, acc: 67.97%, op_acc: 25.00%] [G loss: 1.074378]\n",
      "epoch:4 step:3138[D loss: 0.455681, acc: 60.16%, op_acc: 22.66%] [G loss: 0.991129]\n",
      "epoch:4 step:3139[D loss: 0.440657, acc: 60.94%, op_acc: 33.59%] [G loss: 0.986214]\n",
      "epoch:4 step:3140[D loss: 0.450686, acc: 61.72%, op_acc: 33.59%] [G loss: 0.994236]\n",
      "epoch:4 step:3141[D loss: 0.487010, acc: 53.12%, op_acc: 32.03%] [G loss: 0.932596]\n",
      "epoch:4 step:3142[D loss: 0.459204, acc: 54.69%, op_acc: 33.59%] [G loss: 1.036947]\n",
      "epoch:4 step:3143[D loss: 0.437036, acc: 59.38%, op_acc: 32.81%] [G loss: 1.028504]\n",
      "epoch:4 step:3144[D loss: 0.432987, acc: 55.47%, op_acc: 33.59%] [G loss: 1.091453]\n",
      "epoch:4 step:3145[D loss: 0.491250, acc: 53.12%, op_acc: 30.47%] [G loss: 0.938319]\n",
      "epoch:4 step:3146[D loss: 0.425560, acc: 63.28%, op_acc: 33.59%] [G loss: 1.037703]\n",
      "epoch:4 step:3147[D loss: 0.427441, acc: 60.94%, op_acc: 35.16%] [G loss: 1.059642]\n",
      "epoch:4 step:3148[D loss: 0.466006, acc: 60.94%, op_acc: 31.25%] [G loss: 1.080661]\n",
      "epoch:4 step:3149[D loss: 0.470090, acc: 57.81%, op_acc: 30.47%] [G loss: 1.187480]\n",
      "epoch:4 step:3150[D loss: 0.457643, acc: 53.12%, op_acc: 33.59%] [G loss: 1.107198]\n",
      "epoch:4 step:3151[D loss: 0.425227, acc: 65.62%, op_acc: 34.38%] [G loss: 1.039075]\n",
      "epoch:4 step:3152[D loss: 0.419419, acc: 64.84%, op_acc: 36.72%] [G loss: 1.009056]\n",
      "epoch:4 step:3153[D loss: 0.418492, acc: 68.75%, op_acc: 33.59%] [G loss: 1.038149]\n",
      "epoch:4 step:3154[D loss: 0.444670, acc: 62.50%, op_acc: 38.28%] [G loss: 1.000234]\n",
      "epoch:4 step:3155[D loss: 0.438353, acc: 64.84%, op_acc: 29.69%] [G loss: 1.136637]\n",
      "epoch:4 step:3156[D loss: 0.472786, acc: 64.06%, op_acc: 25.00%] [G loss: 0.994939]\n",
      "epoch:4 step:3157[D loss: 0.442488, acc: 60.16%, op_acc: 35.94%] [G loss: 1.036465]\n",
      "epoch:4 step:3158[D loss: 0.424164, acc: 64.84%, op_acc: 37.50%] [G loss: 1.062879]\n",
      "epoch:4 step:3159[D loss: 0.452446, acc: 57.81%, op_acc: 32.03%] [G loss: 1.008012]\n",
      "epoch:4 step:3160[D loss: 0.427702, acc: 64.06%, op_acc: 30.47%] [G loss: 0.996755]\n",
      "epoch:4 step:3161[D loss: 0.448458, acc: 69.53%, op_acc: 27.34%] [G loss: 1.106085]\n",
      "epoch:4 step:3162[D loss: 0.451868, acc: 55.47%, op_acc: 33.59%] [G loss: 0.842089]\n",
      "epoch:4 step:3163[D loss: 0.451924, acc: 55.47%, op_acc: 34.38%] [G loss: 0.984468]\n",
      "epoch:4 step:3164[D loss: 0.475358, acc: 55.47%, op_acc: 26.56%] [G loss: 0.912871]\n",
      "epoch:4 step:3165[D loss: 0.438003, acc: 60.16%, op_acc: 35.16%] [G loss: 1.060794]\n",
      "epoch:4 step:3166[D loss: 0.470962, acc: 58.59%, op_acc: 29.69%] [G loss: 0.903068]\n",
      "epoch:4 step:3167[D loss: 0.453449, acc: 61.72%, op_acc: 27.34%] [G loss: 0.954715]\n",
      "epoch:4 step:3168[D loss: 0.460107, acc: 60.16%, op_acc: 30.47%] [G loss: 0.954469]\n",
      "epoch:4 step:3169[D loss: 0.426360, acc: 64.84%, op_acc: 35.94%] [G loss: 0.894434]\n",
      "epoch:4 step:3170[D loss: 0.447961, acc: 61.72%, op_acc: 31.25%] [G loss: 0.888532]\n",
      "epoch:4 step:3171[D loss: 0.434164, acc: 68.75%, op_acc: 26.56%] [G loss: 1.033402]\n",
      "epoch:4 step:3172[D loss: 0.445494, acc: 64.06%, op_acc: 30.47%] [G loss: 0.972674]\n",
      "epoch:4 step:3173[D loss: 0.449226, acc: 63.28%, op_acc: 41.41%] [G loss: 0.944662]\n",
      "epoch:4 step:3174[D loss: 0.465483, acc: 64.84%, op_acc: 27.34%] [G loss: 0.912948]\n",
      "epoch:4 step:3175[D loss: 0.466402, acc: 58.59%, op_acc: 33.59%] [G loss: 0.958801]\n",
      "epoch:4 step:3176[D loss: 0.439876, acc: 64.84%, op_acc: 29.69%] [G loss: 0.927345]\n",
      "epoch:4 step:3177[D loss: 0.477310, acc: 53.91%, op_acc: 38.28%] [G loss: 0.956074]\n",
      "epoch:4 step:3178[D loss: 0.485879, acc: 54.69%, op_acc: 32.03%] [G loss: 1.037669]\n",
      "epoch:4 step:3179[D loss: 0.416683, acc: 67.19%, op_acc: 32.81%] [G loss: 1.014901]\n",
      "epoch:4 step:3180[D loss: 0.445757, acc: 64.06%, op_acc: 35.16%] [G loss: 1.048187]\n",
      "epoch:4 step:3181[D loss: 0.442417, acc: 59.38%, op_acc: 34.38%] [G loss: 1.080494]\n",
      "epoch:4 step:3182[D loss: 0.475288, acc: 54.69%, op_acc: 35.94%] [G loss: 1.002428]\n",
      "epoch:4 step:3183[D loss: 0.406596, acc: 67.97%, op_acc: 32.03%] [G loss: 1.041107]\n",
      "epoch:4 step:3184[D loss: 0.426752, acc: 64.84%, op_acc: 25.00%] [G loss: 0.962434]\n",
      "epoch:4 step:3185[D loss: 0.424777, acc: 71.88%, op_acc: 32.81%] [G loss: 1.113758]\n",
      "epoch:4 step:3186[D loss: 0.471254, acc: 62.50%, op_acc: 26.56%] [G loss: 1.038550]\n",
      "epoch:4 step:3187[D loss: 0.505839, acc: 51.56%, op_acc: 28.91%] [G loss: 0.910812]\n",
      "epoch:4 step:3188[D loss: 0.449931, acc: 64.06%, op_acc: 31.25%] [G loss: 0.955614]\n",
      "epoch:4 step:3189[D loss: 0.439341, acc: 68.75%, op_acc: 29.69%] [G loss: 0.990363]\n",
      "epoch:4 step:3190[D loss: 0.434983, acc: 64.06%, op_acc: 30.47%] [G loss: 1.000133]\n",
      "epoch:4 step:3191[D loss: 0.461756, acc: 64.06%, op_acc: 34.38%] [G loss: 1.009641]\n",
      "epoch:4 step:3192[D loss: 0.440842, acc: 58.59%, op_acc: 33.59%] [G loss: 0.936250]\n",
      "epoch:4 step:3193[D loss: 0.448173, acc: 56.25%, op_acc: 35.94%] [G loss: 0.954799]\n",
      "epoch:4 step:3194[D loss: 0.461474, acc: 58.59%, op_acc: 33.59%] [G loss: 0.986218]\n",
      "epoch:4 step:3195[D loss: 0.482050, acc: 59.38%, op_acc: 30.47%] [G loss: 1.006214]\n",
      "epoch:4 step:3196[D loss: 0.471663, acc: 53.12%, op_acc: 30.47%] [G loss: 1.052129]\n",
      "epoch:4 step:3197[D loss: 0.445812, acc: 64.06%, op_acc: 26.56%] [G loss: 1.052333]\n",
      "epoch:4 step:3198[D loss: 0.419134, acc: 63.28%, op_acc: 33.59%] [G loss: 1.119053]\n",
      "epoch:4 step:3199[D loss: 0.419302, acc: 68.75%, op_acc: 35.94%] [G loss: 1.186451]\n",
      "epoch:4 step:3200[D loss: 0.444286, acc: 65.62%, op_acc: 35.16%] [G loss: 1.030552]\n",
      "epoch:4 step:3201[D loss: 0.453606, acc: 60.94%, op_acc: 29.69%] [G loss: 0.963472]\n",
      "epoch:4 step:3202[D loss: 0.428399, acc: 74.22%, op_acc: 26.56%] [G loss: 1.135664]\n",
      "epoch:4 step:3203[D loss: 0.399120, acc: 68.75%, op_acc: 38.28%] [G loss: 1.070593]\n",
      "epoch:4 step:3204[D loss: 0.469962, acc: 63.28%, op_acc: 25.78%] [G loss: 1.017217]\n",
      "epoch:4 step:3205[D loss: 0.476236, acc: 60.94%, op_acc: 31.25%] [G loss: 0.975709]\n",
      "epoch:4 step:3206[D loss: 0.431176, acc: 72.66%, op_acc: 28.91%] [G loss: 0.930706]\n",
      "epoch:4 step:3207[D loss: 0.464864, acc: 57.81%, op_acc: 31.25%] [G loss: 0.965674]\n",
      "epoch:4 step:3208[D loss: 0.426029, acc: 66.41%, op_acc: 41.41%] [G loss: 0.932042]\n",
      "epoch:4 step:3209[D loss: 0.460801, acc: 63.28%, op_acc: 30.47%] [G loss: 0.925590]\n",
      "epoch:4 step:3210[D loss: 0.463825, acc: 60.16%, op_acc: 27.34%] [G loss: 0.993060]\n",
      "epoch:4 step:3211[D loss: 0.398063, acc: 69.53%, op_acc: 35.16%] [G loss: 0.940735]\n",
      "epoch:4 step:3212[D loss: 0.422047, acc: 66.41%, op_acc: 31.25%] [G loss: 0.931275]\n",
      "epoch:4 step:3213[D loss: 0.481501, acc: 53.12%, op_acc: 28.91%] [G loss: 0.961761]\n",
      "epoch:4 step:3214[D loss: 0.474447, acc: 55.47%, op_acc: 34.38%] [G loss: 1.005963]\n",
      "epoch:4 step:3215[D loss: 0.425999, acc: 61.72%, op_acc: 29.69%] [G loss: 1.067760]\n",
      "epoch:4 step:3216[D loss: 0.501687, acc: 46.09%, op_acc: 32.03%] [G loss: 0.919732]\n",
      "epoch:4 step:3217[D loss: 0.463167, acc: 53.12%, op_acc: 35.16%] [G loss: 1.054259]\n",
      "epoch:4 step:3218[D loss: 0.433096, acc: 64.06%, op_acc: 40.62%] [G loss: 1.109583]\n",
      "epoch:4 step:3219[D loss: 0.462930, acc: 59.38%, op_acc: 32.03%] [G loss: 1.003958]\n",
      "epoch:4 step:3220[D loss: 0.467518, acc: 61.72%, op_acc: 31.25%] [G loss: 0.882268]\n",
      "epoch:4 step:3221[D loss: 0.429993, acc: 62.50%, op_acc: 32.81%] [G loss: 0.931816]\n",
      "epoch:4 step:3222[D loss: 0.453894, acc: 59.38%, op_acc: 26.56%] [G loss: 0.988927]\n",
      "epoch:4 step:3223[D loss: 0.412568, acc: 64.84%, op_acc: 35.16%] [G loss: 0.992890]\n",
      "epoch:4 step:3224[D loss: 0.459351, acc: 57.03%, op_acc: 34.38%] [G loss: 1.106925]\n",
      "epoch:4 step:3225[D loss: 0.420943, acc: 67.19%, op_acc: 33.59%] [G loss: 1.030149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3226[D loss: 0.411527, acc: 72.66%, op_acc: 37.50%] [G loss: 1.143931]\n",
      "epoch:4 step:3227[D loss: 0.500214, acc: 50.00%, op_acc: 28.91%] [G loss: 1.028364]\n",
      "epoch:4 step:3228[D loss: 0.453862, acc: 61.72%, op_acc: 30.47%] [G loss: 1.006745]\n",
      "epoch:4 step:3229[D loss: 0.435231, acc: 63.28%, op_acc: 35.16%] [G loss: 1.091475]\n",
      "epoch:4 step:3230[D loss: 0.375120, acc: 76.56%, op_acc: 35.94%] [G loss: 1.012000]\n",
      "epoch:4 step:3231[D loss: 0.428910, acc: 70.31%, op_acc: 34.38%] [G loss: 1.057033]\n",
      "epoch:4 step:3232[D loss: 0.523957, acc: 50.78%, op_acc: 28.12%] [G loss: 1.004636]\n",
      "epoch:4 step:3233[D loss: 0.450108, acc: 58.59%, op_acc: 32.81%] [G loss: 0.896735]\n",
      "epoch:4 step:3234[D loss: 0.443088, acc: 64.84%, op_acc: 32.81%] [G loss: 0.934108]\n",
      "epoch:4 step:3235[D loss: 0.496745, acc: 56.25%, op_acc: 26.56%] [G loss: 0.966630]\n",
      "epoch:4 step:3236[D loss: 0.440394, acc: 60.94%, op_acc: 37.50%] [G loss: 1.045212]\n",
      "epoch:4 step:3237[D loss: 0.461171, acc: 65.62%, op_acc: 26.56%] [G loss: 0.991464]\n",
      "epoch:4 step:3238[D loss: 0.441112, acc: 61.72%, op_acc: 39.06%] [G loss: 1.055975]\n",
      "epoch:4 step:3239[D loss: 0.427057, acc: 60.94%, op_acc: 40.62%] [G loss: 0.999336]\n",
      "epoch:4 step:3240[D loss: 0.477869, acc: 59.38%, op_acc: 32.03%] [G loss: 1.014635]\n",
      "epoch:4 step:3241[D loss: 0.463151, acc: 53.91%, op_acc: 31.25%] [G loss: 0.929707]\n",
      "epoch:4 step:3242[D loss: 0.414007, acc: 67.19%, op_acc: 34.38%] [G loss: 1.028023]\n",
      "epoch:4 step:3243[D loss: 0.452118, acc: 61.72%, op_acc: 31.25%] [G loss: 0.978854]\n",
      "epoch:4 step:3244[D loss: 0.445029, acc: 55.47%, op_acc: 34.38%] [G loss: 0.950022]\n",
      "epoch:4 step:3245[D loss: 0.476681, acc: 60.94%, op_acc: 32.03%] [G loss: 0.937580]\n",
      "epoch:4 step:3246[D loss: 0.479152, acc: 59.38%, op_acc: 25.00%] [G loss: 0.936707]\n",
      "epoch:4 step:3247[D loss: 0.458894, acc: 62.50%, op_acc: 29.69%] [G loss: 0.960237]\n",
      "epoch:4 step:3248[D loss: 0.474727, acc: 57.03%, op_acc: 28.91%] [G loss: 0.895645]\n",
      "epoch:4 step:3249[D loss: 0.458697, acc: 66.41%, op_acc: 28.12%] [G loss: 0.954139]\n",
      "epoch:4 step:3250[D loss: 0.391635, acc: 67.19%, op_acc: 35.94%] [G loss: 1.011015]\n",
      "epoch:4 step:3251[D loss: 0.427518, acc: 67.97%, op_acc: 32.81%] [G loss: 1.069832]\n",
      "epoch:4 step:3252[D loss: 0.408783, acc: 74.22%, op_acc: 30.47%] [G loss: 1.097594]\n",
      "epoch:4 step:3253[D loss: 0.453089, acc: 58.59%, op_acc: 28.12%] [G loss: 1.057346]\n",
      "epoch:4 step:3254[D loss: 0.463655, acc: 59.38%, op_acc: 32.81%] [G loss: 0.965751]\n",
      "epoch:4 step:3255[D loss: 0.446842, acc: 59.38%, op_acc: 30.47%] [G loss: 1.119710]\n",
      "epoch:4 step:3256[D loss: 0.418683, acc: 68.75%, op_acc: 32.81%] [G loss: 1.032157]\n",
      "epoch:4 step:3257[D loss: 0.481208, acc: 58.59%, op_acc: 28.12%] [G loss: 1.151964]\n",
      "epoch:4 step:3258[D loss: 0.454548, acc: 56.25%, op_acc: 31.25%] [G loss: 1.024766]\n",
      "epoch:4 step:3259[D loss: 0.487427, acc: 55.47%, op_acc: 35.94%] [G loss: 1.018307]\n",
      "epoch:4 step:3260[D loss: 0.430908, acc: 60.94%, op_acc: 35.94%] [G loss: 0.917123]\n",
      "epoch:4 step:3261[D loss: 0.481195, acc: 54.69%, op_acc: 38.28%] [G loss: 0.931665]\n",
      "epoch:4 step:3262[D loss: 0.473425, acc: 53.12%, op_acc: 26.56%] [G loss: 0.929586]\n",
      "epoch:4 step:3263[D loss: 0.436859, acc: 66.41%, op_acc: 38.28%] [G loss: 0.966552]\n",
      "epoch:4 step:3264[D loss: 0.478823, acc: 59.38%, op_acc: 31.25%] [G loss: 1.020688]\n",
      "epoch:4 step:3265[D loss: 0.476535, acc: 56.25%, op_acc: 29.69%] [G loss: 0.936498]\n",
      "epoch:4 step:3266[D loss: 0.418016, acc: 68.75%, op_acc: 32.03%] [G loss: 0.990911]\n",
      "epoch:4 step:3267[D loss: 0.445968, acc: 55.47%, op_acc: 30.47%] [G loss: 0.978324]\n",
      "epoch:4 step:3268[D loss: 0.458503, acc: 56.25%, op_acc: 26.56%] [G loss: 1.065452]\n",
      "epoch:4 step:3269[D loss: 0.461349, acc: 61.72%, op_acc: 32.03%] [G loss: 0.985474]\n",
      "epoch:4 step:3270[D loss: 0.425790, acc: 64.84%, op_acc: 32.81%] [G loss: 0.999150]\n",
      "epoch:4 step:3271[D loss: 0.426191, acc: 60.16%, op_acc: 34.38%] [G loss: 0.949309]\n",
      "epoch:4 step:3272[D loss: 0.467554, acc: 57.81%, op_acc: 32.81%] [G loss: 0.928677]\n",
      "epoch:4 step:3273[D loss: 0.449505, acc: 55.47%, op_acc: 32.03%] [G loss: 0.921873]\n",
      "epoch:4 step:3274[D loss: 0.434331, acc: 64.84%, op_acc: 30.47%] [G loss: 1.030545]\n",
      "epoch:4 step:3275[D loss: 0.420069, acc: 67.97%, op_acc: 35.16%] [G loss: 0.952001]\n",
      "epoch:4 step:3276[D loss: 0.459424, acc: 59.38%, op_acc: 32.03%] [G loss: 1.001507]\n",
      "epoch:4 step:3277[D loss: 0.434142, acc: 60.16%, op_acc: 28.91%] [G loss: 0.915979]\n",
      "epoch:4 step:3278[D loss: 0.458370, acc: 55.47%, op_acc: 29.69%] [G loss: 0.903959]\n",
      "epoch:4 step:3279[D loss: 0.435794, acc: 63.28%, op_acc: 35.94%] [G loss: 1.005458]\n",
      "epoch:4 step:3280[D loss: 0.460172, acc: 52.34%, op_acc: 37.50%] [G loss: 0.859314]\n",
      "epoch:4 step:3281[D loss: 0.444894, acc: 63.28%, op_acc: 31.25%] [G loss: 1.069199]\n",
      "epoch:4 step:3282[D loss: 0.487428, acc: 52.34%, op_acc: 28.12%] [G loss: 0.902381]\n",
      "epoch:4 step:3283[D loss: 0.459829, acc: 57.81%, op_acc: 37.50%] [G loss: 1.030752]\n",
      "epoch:4 step:3284[D loss: 0.480564, acc: 64.84%, op_acc: 25.78%] [G loss: 0.975393]\n",
      "epoch:4 step:3285[D loss: 0.456654, acc: 57.81%, op_acc: 35.94%] [G loss: 1.019090]\n",
      "epoch:4 step:3286[D loss: 0.463218, acc: 59.38%, op_acc: 32.03%] [G loss: 0.949147]\n",
      "epoch:4 step:3287[D loss: 0.486232, acc: 55.47%, op_acc: 31.25%] [G loss: 0.912292]\n",
      "epoch:4 step:3288[D loss: 0.433180, acc: 68.75%, op_acc: 28.12%] [G loss: 1.008601]\n",
      "epoch:4 step:3289[D loss: 0.430760, acc: 65.62%, op_acc: 35.16%] [G loss: 1.096068]\n",
      "epoch:4 step:3290[D loss: 0.459986, acc: 64.06%, op_acc: 32.81%] [G loss: 1.011245]\n",
      "epoch:4 step:3291[D loss: 0.436177, acc: 59.38%, op_acc: 31.25%] [G loss: 1.072243]\n",
      "epoch:4 step:3292[D loss: 0.442966, acc: 60.94%, op_acc: 37.50%] [G loss: 1.103221]\n",
      "epoch:4 step:3293[D loss: 0.396998, acc: 73.44%, op_acc: 36.72%] [G loss: 1.070667]\n",
      "epoch:4 step:3294[D loss: 0.474202, acc: 57.03%, op_acc: 30.47%] [G loss: 1.073232]\n",
      "epoch:4 step:3295[D loss: 0.431157, acc: 63.28%, op_acc: 33.59%] [G loss: 1.002765]\n",
      "epoch:4 step:3296[D loss: 0.410881, acc: 67.19%, op_acc: 37.50%] [G loss: 0.950076]\n",
      "epoch:4 step:3297[D loss: 0.423352, acc: 63.28%, op_acc: 31.25%] [G loss: 1.058159]\n",
      "epoch:4 step:3298[D loss: 0.461178, acc: 62.50%, op_acc: 33.59%] [G loss: 0.971335]\n",
      "epoch:4 step:3299[D loss: 0.475891, acc: 51.56%, op_acc: 32.03%] [G loss: 0.857358]\n",
      "epoch:4 step:3300[D loss: 0.458219, acc: 61.72%, op_acc: 33.59%] [G loss: 0.966012]\n",
      "epoch:4 step:3301[D loss: 0.430676, acc: 62.50%, op_acc: 32.03%] [G loss: 1.021396]\n",
      "epoch:4 step:3302[D loss: 0.445996, acc: 63.28%, op_acc: 32.81%] [G loss: 0.953465]\n",
      "epoch:4 step:3303[D loss: 0.416950, acc: 60.94%, op_acc: 35.16%] [G loss: 0.917200]\n",
      "epoch:4 step:3304[D loss: 0.463334, acc: 65.62%, op_acc: 26.56%] [G loss: 1.064444]\n",
      "epoch:4 step:3305[D loss: 0.430558, acc: 64.84%, op_acc: 33.59%] [G loss: 1.048564]\n",
      "epoch:4 step:3306[D loss: 0.437571, acc: 62.50%, op_acc: 32.03%] [G loss: 1.036842]\n",
      "epoch:4 step:3307[D loss: 0.438209, acc: 60.94%, op_acc: 33.59%] [G loss: 0.960874]\n",
      "epoch:4 step:3308[D loss: 0.422583, acc: 67.19%, op_acc: 32.81%] [G loss: 1.055053]\n",
      "epoch:4 step:3309[D loss: 0.439532, acc: 70.31%, op_acc: 32.81%] [G loss: 1.023843]\n",
      "epoch:4 step:3310[D loss: 0.442971, acc: 67.19%, op_acc: 40.62%] [G loss: 1.035023]\n",
      "epoch:4 step:3311[D loss: 0.442383, acc: 57.81%, op_acc: 31.25%] [G loss: 0.987744]\n",
      "epoch:4 step:3312[D loss: 0.428839, acc: 65.62%, op_acc: 37.50%] [G loss: 0.893788]\n",
      "epoch:4 step:3313[D loss: 0.430774, acc: 69.53%, op_acc: 32.81%] [G loss: 1.091204]\n",
      "epoch:4 step:3314[D loss: 0.455242, acc: 59.38%, op_acc: 36.72%] [G loss: 1.062130]\n",
      "epoch:4 step:3315[D loss: 0.407183, acc: 63.28%, op_acc: 36.72%] [G loss: 1.057178]\n",
      "epoch:4 step:3316[D loss: 0.408842, acc: 71.09%, op_acc: 32.03%] [G loss: 1.110749]\n",
      "epoch:4 step:3317[D loss: 0.470332, acc: 59.38%, op_acc: 25.78%] [G loss: 1.075846]\n",
      "epoch:4 step:3318[D loss: 0.451217, acc: 60.94%, op_acc: 33.59%] [G loss: 0.922953]\n",
      "epoch:4 step:3319[D loss: 0.438461, acc: 57.81%, op_acc: 32.03%] [G loss: 0.983166]\n",
      "epoch:4 step:3320[D loss: 0.427718, acc: 67.97%, op_acc: 39.84%] [G loss: 1.069751]\n",
      "epoch:4 step:3321[D loss: 0.476072, acc: 53.91%, op_acc: 28.91%] [G loss: 0.961795]\n",
      "epoch:4 step:3322[D loss: 0.488050, acc: 52.34%, op_acc: 32.03%] [G loss: 0.955767]\n",
      "epoch:4 step:3323[D loss: 0.421598, acc: 64.84%, op_acc: 37.50%] [G loss: 1.014903]\n",
      "epoch:4 step:3324[D loss: 0.449986, acc: 66.41%, op_acc: 32.03%] [G loss: 1.099831]\n",
      "epoch:4 step:3325[D loss: 0.425504, acc: 63.28%, op_acc: 32.81%] [G loss: 0.973273]\n",
      "epoch:4 step:3326[D loss: 0.494330, acc: 54.69%, op_acc: 31.25%] [G loss: 1.044393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3327[D loss: 0.474817, acc: 61.72%, op_acc: 27.34%] [G loss: 0.815406]\n",
      "epoch:4 step:3328[D loss: 0.436936, acc: 67.19%, op_acc: 35.16%] [G loss: 0.944225]\n",
      "epoch:4 step:3329[D loss: 0.465465, acc: 57.03%, op_acc: 33.59%] [G loss: 0.898921]\n",
      "epoch:4 step:3330[D loss: 0.457320, acc: 63.28%, op_acc: 28.91%] [G loss: 0.946564]\n",
      "epoch:4 step:3331[D loss: 0.419071, acc: 66.41%, op_acc: 29.69%] [G loss: 0.946820]\n",
      "epoch:4 step:3332[D loss: 0.457787, acc: 66.41%, op_acc: 31.25%] [G loss: 1.010618]\n",
      "epoch:4 step:3333[D loss: 0.436009, acc: 58.59%, op_acc: 33.59%] [G loss: 0.964743]\n",
      "epoch:4 step:3334[D loss: 0.440846, acc: 70.31%, op_acc: 28.91%] [G loss: 1.000970]\n",
      "epoch:4 step:3335[D loss: 0.436639, acc: 58.59%, op_acc: 32.81%] [G loss: 1.042460]\n",
      "epoch:4 step:3336[D loss: 0.428383, acc: 67.19%, op_acc: 28.91%] [G loss: 0.895117]\n",
      "epoch:4 step:3337[D loss: 0.449073, acc: 61.72%, op_acc: 31.25%] [G loss: 1.095126]\n",
      "epoch:4 step:3338[D loss: 0.455072, acc: 60.16%, op_acc: 28.91%] [G loss: 0.950183]\n",
      "epoch:4 step:3339[D loss: 0.490879, acc: 52.34%, op_acc: 26.56%] [G loss: 1.067060]\n",
      "epoch:4 step:3340[D loss: 0.466819, acc: 52.34%, op_acc: 31.25%] [G loss: 1.014427]\n",
      "epoch:4 step:3341[D loss: 0.424614, acc: 65.62%, op_acc: 37.50%] [G loss: 1.111379]\n",
      "epoch:4 step:3342[D loss: 0.453534, acc: 58.59%, op_acc: 32.03%] [G loss: 0.935244]\n",
      "epoch:4 step:3343[D loss: 0.440647, acc: 63.28%, op_acc: 28.91%] [G loss: 0.969484]\n",
      "epoch:4 step:3344[D loss: 0.438207, acc: 63.28%, op_acc: 33.59%] [G loss: 1.023221]\n",
      "epoch:4 step:3345[D loss: 0.465685, acc: 59.38%, op_acc: 38.28%] [G loss: 0.975598]\n",
      "epoch:4 step:3346[D loss: 0.434439, acc: 61.72%, op_acc: 32.03%] [G loss: 1.049137]\n",
      "epoch:4 step:3347[D loss: 0.466648, acc: 60.16%, op_acc: 33.59%] [G loss: 1.081288]\n",
      "epoch:4 step:3348[D loss: 0.422127, acc: 64.84%, op_acc: 35.16%] [G loss: 1.052433]\n",
      "epoch:4 step:3349[D loss: 0.459728, acc: 64.84%, op_acc: 33.59%] [G loss: 1.017270]\n",
      "epoch:4 step:3350[D loss: 0.417629, acc: 67.97%, op_acc: 29.69%] [G loss: 1.010276]\n",
      "epoch:4 step:3351[D loss: 0.459698, acc: 60.16%, op_acc: 28.91%] [G loss: 1.065435]\n",
      "epoch:4 step:3352[D loss: 0.455705, acc: 59.38%, op_acc: 33.59%] [G loss: 0.970763]\n",
      "epoch:4 step:3353[D loss: 0.439418, acc: 64.84%, op_acc: 32.81%] [G loss: 0.921148]\n",
      "epoch:4 step:3354[D loss: 0.493371, acc: 52.34%, op_acc: 28.91%] [G loss: 0.891411]\n",
      "epoch:4 step:3355[D loss: 0.424658, acc: 62.50%, op_acc: 35.16%] [G loss: 0.971302]\n",
      "epoch:4 step:3356[D loss: 0.464157, acc: 56.25%, op_acc: 28.12%] [G loss: 0.966356]\n",
      "epoch:4 step:3357[D loss: 0.462057, acc: 60.94%, op_acc: 28.91%] [G loss: 1.067951]\n",
      "epoch:4 step:3358[D loss: 0.475533, acc: 58.59%, op_acc: 33.59%] [G loss: 0.943352]\n",
      "epoch:4 step:3359[D loss: 0.462808, acc: 58.59%, op_acc: 35.16%] [G loss: 0.996864]\n",
      "epoch:4 step:3360[D loss: 0.479335, acc: 55.47%, op_acc: 28.91%] [G loss: 0.936143]\n",
      "epoch:4 step:3361[D loss: 0.452867, acc: 60.16%, op_acc: 34.38%] [G loss: 0.989287]\n",
      "epoch:4 step:3362[D loss: 0.456152, acc: 63.28%, op_acc: 29.69%] [G loss: 0.915048]\n",
      "epoch:4 step:3363[D loss: 0.452217, acc: 54.69%, op_acc: 32.81%] [G loss: 1.008868]\n",
      "epoch:4 step:3364[D loss: 0.434067, acc: 62.50%, op_acc: 33.59%] [G loss: 1.067612]\n",
      "epoch:4 step:3365[D loss: 0.470561, acc: 53.12%, op_acc: 34.38%] [G loss: 0.977528]\n",
      "epoch:4 step:3366[D loss: 0.453130, acc: 61.72%, op_acc: 35.16%] [G loss: 0.964122]\n",
      "epoch:4 step:3367[D loss: 0.479210, acc: 54.69%, op_acc: 25.78%] [G loss: 0.991169]\n",
      "epoch:4 step:3368[D loss: 0.495190, acc: 58.59%, op_acc: 25.78%] [G loss: 1.031382]\n",
      "epoch:4 step:3369[D loss: 0.446860, acc: 57.03%, op_acc: 34.38%] [G loss: 1.011567]\n",
      "epoch:4 step:3370[D loss: 0.428067, acc: 66.41%, op_acc: 36.72%] [G loss: 0.991050]\n",
      "epoch:4 step:3371[D loss: 0.449253, acc: 61.72%, op_acc: 31.25%] [G loss: 0.941340]\n",
      "epoch:4 step:3372[D loss: 0.458717, acc: 64.84%, op_acc: 29.69%] [G loss: 0.931577]\n",
      "epoch:4 step:3373[D loss: 0.496607, acc: 56.25%, op_acc: 27.34%] [G loss: 0.976591]\n",
      "epoch:4 step:3374[D loss: 0.472159, acc: 62.50%, op_acc: 28.12%] [G loss: 0.934749]\n",
      "epoch:4 step:3375[D loss: 0.462360, acc: 60.16%, op_acc: 34.38%] [G loss: 1.006226]\n",
      "epoch:4 step:3376[D loss: 0.445243, acc: 66.41%, op_acc: 27.34%] [G loss: 1.040353]\n",
      "epoch:4 step:3377[D loss: 0.432176, acc: 62.50%, op_acc: 34.38%] [G loss: 1.016741]\n",
      "epoch:4 step:3378[D loss: 0.425255, acc: 68.75%, op_acc: 33.59%] [G loss: 0.924060]\n",
      "epoch:4 step:3379[D loss: 0.467141, acc: 52.34%, op_acc: 33.59%] [G loss: 0.879716]\n",
      "epoch:4 step:3380[D loss: 0.464941, acc: 55.47%, op_acc: 37.50%] [G loss: 0.888848]\n",
      "epoch:4 step:3381[D loss: 0.443438, acc: 63.28%, op_acc: 30.47%] [G loss: 0.985950]\n",
      "epoch:4 step:3382[D loss: 0.451741, acc: 58.59%, op_acc: 33.59%] [G loss: 0.930177]\n",
      "epoch:4 step:3383[D loss: 0.443907, acc: 60.94%, op_acc: 35.94%] [G loss: 0.987334]\n",
      "epoch:4 step:3384[D loss: 0.455045, acc: 60.16%, op_acc: 29.69%] [G loss: 0.903712]\n",
      "epoch:4 step:3385[D loss: 0.399460, acc: 71.88%, op_acc: 36.72%] [G loss: 0.909948]\n",
      "epoch:4 step:3386[D loss: 0.431421, acc: 57.03%, op_acc: 38.28%] [G loss: 0.961678]\n",
      "epoch:4 step:3387[D loss: 0.469707, acc: 64.84%, op_acc: 24.22%] [G loss: 1.001136]\n",
      "epoch:4 step:3388[D loss: 0.441390, acc: 63.28%, op_acc: 28.12%] [G loss: 1.034272]\n",
      "epoch:4 step:3389[D loss: 0.410687, acc: 62.50%, op_acc: 39.84%] [G loss: 1.031808]\n",
      "epoch:4 step:3390[D loss: 0.450188, acc: 61.72%, op_acc: 29.69%] [G loss: 1.052704]\n",
      "epoch:4 step:3391[D loss: 0.478763, acc: 57.03%, op_acc: 27.34%] [G loss: 1.012903]\n",
      "epoch:4 step:3392[D loss: 0.411548, acc: 66.41%, op_acc: 33.59%] [G loss: 1.018726]\n",
      "epoch:4 step:3393[D loss: 0.418654, acc: 65.62%, op_acc: 38.28%] [G loss: 0.968124]\n",
      "epoch:4 step:3394[D loss: 0.438985, acc: 61.72%, op_acc: 30.47%] [G loss: 0.934558]\n",
      "epoch:4 step:3395[D loss: 0.454695, acc: 57.81%, op_acc: 34.38%] [G loss: 1.093990]\n",
      "epoch:4 step:3396[D loss: 0.458754, acc: 60.94%, op_acc: 26.56%] [G loss: 0.899720]\n",
      "epoch:4 step:3397[D loss: 0.440534, acc: 63.28%, op_acc: 32.81%] [G loss: 0.951201]\n",
      "epoch:4 step:3398[D loss: 0.483808, acc: 58.59%, op_acc: 32.03%] [G loss: 0.977474]\n",
      "epoch:4 step:3399[D loss: 0.435545, acc: 67.19%, op_acc: 26.56%] [G loss: 0.955749]\n",
      "epoch:4 step:3400[D loss: 0.479652, acc: 57.81%, op_acc: 29.69%] [G loss: 0.917947]\n",
      "epoch:4 step:3401[D loss: 0.462348, acc: 61.72%, op_acc: 30.47%] [G loss: 0.973696]\n",
      "epoch:4 step:3402[D loss: 0.477021, acc: 57.03%, op_acc: 32.03%] [G loss: 1.076125]\n",
      "epoch:4 step:3403[D loss: 0.448741, acc: 66.41%, op_acc: 37.50%] [G loss: 1.044911]\n",
      "epoch:4 step:3404[D loss: 0.443095, acc: 56.25%, op_acc: 39.84%] [G loss: 1.052377]\n",
      "epoch:4 step:3405[D loss: 0.469660, acc: 55.47%, op_acc: 29.69%] [G loss: 1.012187]\n",
      "epoch:4 step:3406[D loss: 0.464972, acc: 57.81%, op_acc: 32.03%] [G loss: 0.963405]\n",
      "epoch:4 step:3407[D loss: 0.418477, acc: 63.28%, op_acc: 34.38%] [G loss: 0.984537]\n",
      "epoch:4 step:3408[D loss: 0.482459, acc: 56.25%, op_acc: 32.03%] [G loss: 1.034209]\n",
      "epoch:4 step:3409[D loss: 0.426102, acc: 69.53%, op_acc: 27.34%] [G loss: 1.014002]\n",
      "epoch:4 step:3410[D loss: 0.405277, acc: 76.56%, op_acc: 28.91%] [G loss: 0.965638]\n",
      "epoch:4 step:3411[D loss: 0.459499, acc: 52.34%, op_acc: 36.72%] [G loss: 0.922551]\n",
      "epoch:4 step:3412[D loss: 0.446649, acc: 58.59%, op_acc: 34.38%] [G loss: 0.949275]\n",
      "epoch:4 step:3413[D loss: 0.476319, acc: 57.81%, op_acc: 27.34%] [G loss: 1.023552]\n",
      "epoch:4 step:3414[D loss: 0.456772, acc: 57.81%, op_acc: 28.12%] [G loss: 0.966868]\n",
      "epoch:4 step:3415[D loss: 0.451884, acc: 55.47%, op_acc: 34.38%] [G loss: 0.922107]\n",
      "epoch:4 step:3416[D loss: 0.447273, acc: 65.62%, op_acc: 28.91%] [G loss: 1.097401]\n",
      "epoch:4 step:3417[D loss: 0.431350, acc: 65.62%, op_acc: 32.03%] [G loss: 0.979181]\n",
      "epoch:4 step:3418[D loss: 0.453985, acc: 57.03%, op_acc: 35.16%] [G loss: 1.007481]\n",
      "epoch:4 step:3419[D loss: 0.440245, acc: 61.72%, op_acc: 28.91%] [G loss: 0.939986]\n",
      "epoch:4 step:3420[D loss: 0.453711, acc: 53.91%, op_acc: 32.03%] [G loss: 0.962984]\n",
      "epoch:4 step:3421[D loss: 0.445997, acc: 67.19%, op_acc: 29.69%] [G loss: 0.964453]\n",
      "epoch:4 step:3422[D loss: 0.418382, acc: 68.75%, op_acc: 32.81%] [G loss: 1.016305]\n",
      "epoch:4 step:3423[D loss: 0.445368, acc: 53.12%, op_acc: 34.38%] [G loss: 0.889593]\n",
      "epoch:4 step:3424[D loss: 0.493655, acc: 60.16%, op_acc: 25.00%] [G loss: 0.952691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3425[D loss: 0.421775, acc: 63.28%, op_acc: 35.94%] [G loss: 1.089618]\n",
      "epoch:4 step:3426[D loss: 0.437919, acc: 56.25%, op_acc: 38.28%] [G loss: 1.000931]\n",
      "epoch:4 step:3427[D loss: 0.458285, acc: 57.81%, op_acc: 26.56%] [G loss: 0.980432]\n",
      "epoch:4 step:3428[D loss: 0.446861, acc: 57.81%, op_acc: 39.06%] [G loss: 0.863258]\n",
      "epoch:4 step:3429[D loss: 0.485265, acc: 51.56%, op_acc: 32.81%] [G loss: 0.896865]\n",
      "epoch:4 step:3430[D loss: 0.441003, acc: 66.41%, op_acc: 33.59%] [G loss: 1.031298]\n",
      "epoch:4 step:3431[D loss: 0.424666, acc: 68.75%, op_acc: 39.06%] [G loss: 0.999314]\n",
      "epoch:4 step:3432[D loss: 0.451900, acc: 61.72%, op_acc: 28.12%] [G loss: 0.975969]\n",
      "epoch:4 step:3433[D loss: 0.468002, acc: 60.94%, op_acc: 29.69%] [G loss: 0.997052]\n",
      "epoch:4 step:3434[D loss: 0.450063, acc: 62.50%, op_acc: 35.16%] [G loss: 0.995700]\n",
      "epoch:4 step:3435[D loss: 0.461263, acc: 58.59%, op_acc: 29.69%] [G loss: 0.987790]\n",
      "epoch:4 step:3436[D loss: 0.457801, acc: 53.91%, op_acc: 29.69%] [G loss: 0.979900]\n",
      "epoch:4 step:3437[D loss: 0.441896, acc: 64.06%, op_acc: 28.91%] [G loss: 0.973395]\n",
      "epoch:4 step:3438[D loss: 0.443912, acc: 69.53%, op_acc: 31.25%] [G loss: 1.017760]\n",
      "epoch:4 step:3439[D loss: 0.474505, acc: 57.03%, op_acc: 27.34%] [G loss: 1.052723]\n",
      "epoch:4 step:3440[D loss: 0.467201, acc: 57.03%, op_acc: 28.91%] [G loss: 1.075503]\n",
      "epoch:4 step:3441[D loss: 0.469019, acc: 58.59%, op_acc: 26.56%] [G loss: 0.955869]\n",
      "epoch:4 step:3442[D loss: 0.477706, acc: 56.25%, op_acc: 27.34%] [G loss: 0.891042]\n",
      "epoch:4 step:3443[D loss: 0.478407, acc: 52.34%, op_acc: 27.34%] [G loss: 1.013429]\n",
      "epoch:4 step:3444[D loss: 0.483358, acc: 54.69%, op_acc: 30.47%] [G loss: 0.963944]\n",
      "epoch:4 step:3445[D loss: 0.491030, acc: 53.91%, op_acc: 32.03%] [G loss: 0.901485]\n",
      "epoch:4 step:3446[D loss: 0.471061, acc: 59.38%, op_acc: 31.25%] [G loss: 0.916150]\n",
      "epoch:4 step:3447[D loss: 0.448772, acc: 59.38%, op_acc: 32.81%] [G loss: 0.982021]\n",
      "epoch:4 step:3448[D loss: 0.454819, acc: 60.94%, op_acc: 34.38%] [G loss: 1.003608]\n",
      "epoch:4 step:3449[D loss: 0.470178, acc: 57.03%, op_acc: 35.16%] [G loss: 0.958853]\n",
      "epoch:4 step:3450[D loss: 0.448244, acc: 64.06%, op_acc: 30.47%] [G loss: 0.960158]\n",
      "epoch:4 step:3451[D loss: 0.439499, acc: 62.50%, op_acc: 36.72%] [G loss: 0.933806]\n",
      "epoch:4 step:3452[D loss: 0.434798, acc: 66.41%, op_acc: 35.16%] [G loss: 0.904576]\n",
      "epoch:4 step:3453[D loss: 0.451533, acc: 61.72%, op_acc: 28.91%] [G loss: 0.928942]\n",
      "epoch:4 step:3454[D loss: 0.430769, acc: 68.75%, op_acc: 31.25%] [G loss: 1.040601]\n",
      "epoch:4 step:3455[D loss: 0.437818, acc: 65.62%, op_acc: 37.50%] [G loss: 0.973650]\n",
      "epoch:4 step:3456[D loss: 0.440915, acc: 60.94%, op_acc: 34.38%] [G loss: 0.989740]\n",
      "epoch:4 step:3457[D loss: 0.430427, acc: 62.50%, op_acc: 35.16%] [G loss: 1.026376]\n",
      "epoch:4 step:3458[D loss: 0.468700, acc: 56.25%, op_acc: 36.72%] [G loss: 0.977503]\n",
      "epoch:4 step:3459[D loss: 0.472529, acc: 62.50%, op_acc: 23.44%] [G loss: 0.887037]\n",
      "epoch:4 step:3460[D loss: 0.447511, acc: 60.94%, op_acc: 30.47%] [G loss: 0.942485]\n",
      "epoch:4 step:3461[D loss: 0.420808, acc: 66.41%, op_acc: 35.94%] [G loss: 1.000727]\n",
      "epoch:4 step:3462[D loss: 0.421912, acc: 62.50%, op_acc: 41.41%] [G loss: 0.957984]\n",
      "epoch:4 step:3463[D loss: 0.450616, acc: 58.59%, op_acc: 39.06%] [G loss: 0.919237]\n",
      "epoch:4 step:3464[D loss: 0.442637, acc: 60.94%, op_acc: 33.59%] [G loss: 0.989230]\n",
      "epoch:4 step:3465[D loss: 0.441666, acc: 61.72%, op_acc: 33.59%] [G loss: 1.111325]\n",
      "epoch:4 step:3466[D loss: 0.451197, acc: 64.06%, op_acc: 28.91%] [G loss: 0.919904]\n",
      "epoch:4 step:3467[D loss: 0.438241, acc: 60.94%, op_acc: 33.59%] [G loss: 0.860338]\n",
      "epoch:4 step:3468[D loss: 0.458514, acc: 54.69%, op_acc: 36.72%] [G loss: 0.977120]\n",
      "epoch:4 step:3469[D loss: 0.440538, acc: 65.62%, op_acc: 28.91%] [G loss: 0.991926]\n",
      "epoch:4 step:3470[D loss: 0.436094, acc: 59.38%, op_acc: 35.16%] [G loss: 0.925204]\n",
      "epoch:4 step:3471[D loss: 0.457121, acc: 66.41%, op_acc: 34.38%] [G loss: 0.932580]\n",
      "epoch:4 step:3472[D loss: 0.440600, acc: 64.84%, op_acc: 35.16%] [G loss: 0.963271]\n",
      "epoch:4 step:3473[D loss: 0.451646, acc: 64.84%, op_acc: 35.16%] [G loss: 0.908060]\n",
      "epoch:4 step:3474[D loss: 0.468335, acc: 53.12%, op_acc: 35.16%] [G loss: 0.861723]\n",
      "epoch:4 step:3475[D loss: 0.430959, acc: 67.97%, op_acc: 31.25%] [G loss: 0.989789]\n",
      "epoch:4 step:3476[D loss: 0.439594, acc: 60.94%, op_acc: 29.69%] [G loss: 0.960872]\n",
      "epoch:4 step:3477[D loss: 0.454511, acc: 63.28%, op_acc: 32.81%] [G loss: 0.953384]\n",
      "epoch:4 step:3478[D loss: 0.439326, acc: 61.72%, op_acc: 34.38%] [G loss: 1.029827]\n",
      "epoch:4 step:3479[D loss: 0.456492, acc: 57.03%, op_acc: 30.47%] [G loss: 0.981712]\n",
      "epoch:4 step:3480[D loss: 0.460345, acc: 57.03%, op_acc: 31.25%] [G loss: 0.997577]\n",
      "epoch:4 step:3481[D loss: 0.443633, acc: 64.84%, op_acc: 32.81%] [G loss: 0.948446]\n",
      "epoch:4 step:3482[D loss: 0.445192, acc: 65.62%, op_acc: 30.47%] [G loss: 0.922192]\n",
      "epoch:4 step:3483[D loss: 0.459728, acc: 60.94%, op_acc: 29.69%] [G loss: 0.939631]\n",
      "epoch:4 step:3484[D loss: 0.478722, acc: 57.03%, op_acc: 32.81%] [G loss: 0.967413]\n",
      "epoch:4 step:3485[D loss: 0.447759, acc: 54.69%, op_acc: 41.41%] [G loss: 0.986536]\n",
      "epoch:4 step:3486[D loss: 0.400761, acc: 68.75%, op_acc: 40.62%] [G loss: 0.964765]\n",
      "epoch:4 step:3487[D loss: 0.460014, acc: 61.72%, op_acc: 28.91%] [G loss: 0.846236]\n",
      "epoch:4 step:3488[D loss: 0.459969, acc: 58.59%, op_acc: 35.94%] [G loss: 1.011067]\n",
      "epoch:4 step:3489[D loss: 0.424932, acc: 57.81%, op_acc: 35.94%] [G loss: 0.931262]\n",
      "epoch:4 step:3490[D loss: 0.410390, acc: 68.75%, op_acc: 36.72%] [G loss: 0.930733]\n",
      "epoch:4 step:3491[D loss: 0.458365, acc: 63.28%, op_acc: 28.91%] [G loss: 1.076479]\n",
      "epoch:4 step:3492[D loss: 0.456277, acc: 62.50%, op_acc: 34.38%] [G loss: 0.996427]\n",
      "epoch:4 step:3493[D loss: 0.436957, acc: 60.94%, op_acc: 34.38%] [G loss: 0.949494]\n",
      "epoch:4 step:3494[D loss: 0.459251, acc: 50.78%, op_acc: 33.59%] [G loss: 0.980508]\n",
      "epoch:4 step:3495[D loss: 0.426008, acc: 65.62%, op_acc: 39.06%] [G loss: 1.001524]\n",
      "epoch:4 step:3496[D loss: 0.437674, acc: 63.28%, op_acc: 35.94%] [G loss: 0.978315]\n",
      "epoch:4 step:3497[D loss: 0.443501, acc: 56.25%, op_acc: 34.38%] [G loss: 0.916665]\n",
      "epoch:4 step:3498[D loss: 0.466543, acc: 56.25%, op_acc: 36.72%] [G loss: 0.960043]\n",
      "epoch:4 step:3499[D loss: 0.456926, acc: 60.94%, op_acc: 28.91%] [G loss: 0.939370]\n",
      "epoch:4 step:3500[D loss: 0.428008, acc: 68.75%, op_acc: 31.25%] [G loss: 0.933647]\n",
      "epoch:4 step:3501[D loss: 0.420745, acc: 63.28%, op_acc: 33.59%] [G loss: 1.084173]\n",
      "epoch:4 step:3502[D loss: 0.451773, acc: 56.25%, op_acc: 33.59%] [G loss: 0.941210]\n",
      "epoch:4 step:3503[D loss: 0.430659, acc: 61.72%, op_acc: 34.38%] [G loss: 1.025888]\n",
      "epoch:4 step:3504[D loss: 0.470586, acc: 51.56%, op_acc: 44.53%] [G loss: 0.973924]\n",
      "epoch:4 step:3505[D loss: 0.442954, acc: 60.94%, op_acc: 29.69%] [G loss: 0.957385]\n",
      "epoch:4 step:3506[D loss: 0.433424, acc: 57.81%, op_acc: 35.16%] [G loss: 0.917901]\n",
      "epoch:4 step:3507[D loss: 0.433667, acc: 59.38%, op_acc: 34.38%] [G loss: 0.985316]\n",
      "epoch:4 step:3508[D loss: 0.446433, acc: 56.25%, op_acc: 38.28%] [G loss: 1.000515]\n",
      "epoch:4 step:3509[D loss: 0.429438, acc: 65.62%, op_acc: 34.38%] [G loss: 0.958826]\n",
      "epoch:4 step:3510[D loss: 0.476326, acc: 52.34%, op_acc: 26.56%] [G loss: 0.989132]\n",
      "epoch:4 step:3511[D loss: 0.474698, acc: 56.25%, op_acc: 32.03%] [G loss: 0.977596]\n",
      "epoch:4 step:3512[D loss: 0.441654, acc: 65.62%, op_acc: 28.12%] [G loss: 1.147116]\n",
      "epoch:4 step:3513[D loss: 0.447509, acc: 62.50%, op_acc: 32.81%] [G loss: 1.150197]\n",
      "epoch:4 step:3514[D loss: 0.417469, acc: 71.09%, op_acc: 35.16%] [G loss: 1.059294]\n",
      "epoch:4 step:3515[D loss: 0.431282, acc: 62.50%, op_acc: 35.94%] [G loss: 1.028237]\n",
      "epoch:4 step:3516[D loss: 0.421340, acc: 68.75%, op_acc: 32.03%] [G loss: 0.964024]\n",
      "epoch:4 step:3517[D loss: 0.451804, acc: 64.84%, op_acc: 33.59%] [G loss: 1.018346]\n",
      "epoch:4 step:3518[D loss: 0.422390, acc: 71.09%, op_acc: 34.38%] [G loss: 0.951554]\n",
      "epoch:4 step:3519[D loss: 0.472008, acc: 61.72%, op_acc: 27.34%] [G loss: 0.972576]\n",
      "epoch:4 step:3520[D loss: 0.428997, acc: 65.62%, op_acc: 42.97%] [G loss: 1.053708]\n",
      "epoch:4 step:3521[D loss: 0.421700, acc: 67.19%, op_acc: 37.50%] [G loss: 0.974153]\n",
      "epoch:4 step:3522[D loss: 0.460246, acc: 60.94%, op_acc: 28.91%] [G loss: 0.987237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3523[D loss: 0.428988, acc: 63.28%, op_acc: 36.72%] [G loss: 0.935022]\n",
      "epoch:4 step:3524[D loss: 0.449216, acc: 63.28%, op_acc: 33.59%] [G loss: 0.948863]\n",
      "epoch:4 step:3525[D loss: 0.454220, acc: 54.69%, op_acc: 32.03%] [G loss: 1.070137]\n",
      "epoch:4 step:3526[D loss: 0.437102, acc: 62.50%, op_acc: 35.16%] [G loss: 1.055595]\n",
      "epoch:4 step:3527[D loss: 0.434549, acc: 63.28%, op_acc: 30.47%] [G loss: 1.054925]\n",
      "epoch:4 step:3528[D loss: 0.419134, acc: 65.62%, op_acc: 33.59%] [G loss: 1.142521]\n",
      "epoch:4 step:3529[D loss: 0.428057, acc: 68.75%, op_acc: 30.47%] [G loss: 1.000943]\n",
      "epoch:4 step:3530[D loss: 0.445240, acc: 61.72%, op_acc: 34.38%] [G loss: 1.031125]\n",
      "epoch:4 step:3531[D loss: 0.444654, acc: 64.06%, op_acc: 30.47%] [G loss: 1.013818]\n",
      "epoch:4 step:3532[D loss: 0.405526, acc: 71.88%, op_acc: 32.03%] [G loss: 1.026562]\n",
      "epoch:4 step:3533[D loss: 0.440110, acc: 67.97%, op_acc: 35.16%] [G loss: 0.987847]\n",
      "epoch:4 step:3534[D loss: 0.422039, acc: 62.50%, op_acc: 35.94%] [G loss: 0.952283]\n",
      "epoch:4 step:3535[D loss: 0.444482, acc: 67.19%, op_acc: 31.25%] [G loss: 0.935955]\n",
      "epoch:4 step:3536[D loss: 0.440096, acc: 59.38%, op_acc: 33.59%] [G loss: 0.898915]\n",
      "epoch:4 step:3537[D loss: 0.439334, acc: 64.06%, op_acc: 33.59%] [G loss: 0.955995]\n",
      "epoch:4 step:3538[D loss: 0.451821, acc: 50.00%, op_acc: 35.94%] [G loss: 0.973563]\n",
      "epoch:4 step:3539[D loss: 0.437225, acc: 64.06%, op_acc: 34.38%] [G loss: 1.025269]\n",
      "epoch:4 step:3540[D loss: 0.411758, acc: 63.28%, op_acc: 34.38%] [G loss: 1.072524]\n",
      "epoch:4 step:3541[D loss: 0.458539, acc: 60.16%, op_acc: 32.03%] [G loss: 1.014691]\n",
      "epoch:4 step:3542[D loss: 0.459285, acc: 61.72%, op_acc: 35.94%] [G loss: 0.887544]\n",
      "epoch:4 step:3543[D loss: 0.445167, acc: 66.41%, op_acc: 29.69%] [G loss: 0.952774]\n",
      "epoch:4 step:3544[D loss: 0.467124, acc: 52.34%, op_acc: 30.47%] [G loss: 1.150227]\n",
      "epoch:4 step:3545[D loss: 0.450740, acc: 63.28%, op_acc: 31.25%] [G loss: 0.954113]\n",
      "epoch:4 step:3546[D loss: 0.438327, acc: 57.81%, op_acc: 35.94%] [G loss: 1.015148]\n",
      "epoch:4 step:3547[D loss: 0.463450, acc: 62.50%, op_acc: 28.12%] [G loss: 1.092295]\n",
      "epoch:4 step:3548[D loss: 0.454051, acc: 57.81%, op_acc: 36.72%] [G loss: 0.987023]\n",
      "epoch:4 step:3549[D loss: 0.412079, acc: 67.97%, op_acc: 35.16%] [G loss: 0.918815]\n",
      "epoch:4 step:3550[D loss: 0.473776, acc: 56.25%, op_acc: 32.81%] [G loss: 0.967000]\n",
      "epoch:4 step:3551[D loss: 0.411563, acc: 75.78%, op_acc: 36.72%] [G loss: 1.062331]\n",
      "epoch:4 step:3552[D loss: 0.487350, acc: 52.34%, op_acc: 39.06%] [G loss: 0.935238]\n",
      "epoch:4 step:3553[D loss: 0.431050, acc: 63.28%, op_acc: 35.16%] [G loss: 0.965053]\n",
      "epoch:4 step:3554[D loss: 0.450260, acc: 58.59%, op_acc: 33.59%] [G loss: 1.017727]\n",
      "epoch:4 step:3555[D loss: 0.454742, acc: 62.50%, op_acc: 35.16%] [G loss: 1.057595]\n",
      "epoch:4 step:3556[D loss: 0.432213, acc: 60.16%, op_acc: 40.62%] [G loss: 0.961087]\n",
      "epoch:4 step:3557[D loss: 0.447213, acc: 64.84%, op_acc: 29.69%] [G loss: 0.978548]\n",
      "epoch:4 step:3558[D loss: 0.453643, acc: 56.25%, op_acc: 36.72%] [G loss: 0.944425]\n",
      "epoch:4 step:3559[D loss: 0.447150, acc: 60.16%, op_acc: 33.59%] [G loss: 1.078770]\n",
      "epoch:4 step:3560[D loss: 0.444462, acc: 64.84%, op_acc: 30.47%] [G loss: 0.926930]\n",
      "epoch:4 step:3561[D loss: 0.481226, acc: 53.12%, op_acc: 31.25%] [G loss: 0.962519]\n",
      "epoch:4 step:3562[D loss: 0.470058, acc: 56.25%, op_acc: 29.69%] [G loss: 0.959464]\n",
      "epoch:4 step:3563[D loss: 0.469556, acc: 56.25%, op_acc: 33.59%] [G loss: 0.963402]\n",
      "epoch:4 step:3564[D loss: 0.436269, acc: 63.28%, op_acc: 36.72%] [G loss: 0.948176]\n",
      "epoch:4 step:3565[D loss: 0.433297, acc: 66.41%, op_acc: 32.03%] [G loss: 1.026902]\n",
      "epoch:4 step:3566[D loss: 0.404167, acc: 69.53%, op_acc: 34.38%] [G loss: 0.953771]\n",
      "epoch:4 step:3567[D loss: 0.437731, acc: 64.84%, op_acc: 27.34%] [G loss: 0.955563]\n",
      "epoch:4 step:3568[D loss: 0.423203, acc: 63.28%, op_acc: 39.06%] [G loss: 1.047103]\n",
      "epoch:4 step:3569[D loss: 0.425191, acc: 68.75%, op_acc: 35.94%] [G loss: 0.954693]\n",
      "epoch:4 step:3570[D loss: 0.423420, acc: 65.62%, op_acc: 37.50%] [G loss: 0.974312]\n",
      "epoch:4 step:3571[D loss: 0.470168, acc: 61.72%, op_acc: 33.59%] [G loss: 0.986923]\n",
      "epoch:4 step:3572[D loss: 0.393684, acc: 72.66%, op_acc: 37.50%] [G loss: 1.030851]\n",
      "epoch:4 step:3573[D loss: 0.467873, acc: 55.47%, op_acc: 31.25%] [G loss: 1.035093]\n",
      "epoch:4 step:3574[D loss: 0.480462, acc: 54.69%, op_acc: 25.78%] [G loss: 0.953300]\n",
      "epoch:4 step:3575[D loss: 0.422628, acc: 64.84%, op_acc: 35.94%] [G loss: 0.868207]\n",
      "epoch:4 step:3576[D loss: 0.435590, acc: 58.59%, op_acc: 34.38%] [G loss: 0.970364]\n",
      "epoch:4 step:3577[D loss: 0.436721, acc: 60.94%, op_acc: 37.50%] [G loss: 0.948211]\n",
      "epoch:4 step:3578[D loss: 0.415950, acc: 66.41%, op_acc: 32.03%] [G loss: 0.988854]\n",
      "epoch:4 step:3579[D loss: 0.497889, acc: 54.69%, op_acc: 25.00%] [G loss: 0.929180]\n",
      "epoch:4 step:3580[D loss: 0.520237, acc: 47.66%, op_acc: 28.91%] [G loss: 0.847667]\n",
      "epoch:4 step:3581[D loss: 0.461392, acc: 59.38%, op_acc: 26.56%] [G loss: 0.918073]\n",
      "epoch:4 step:3582[D loss: 0.434693, acc: 57.03%, op_acc: 38.28%] [G loss: 0.918097]\n",
      "epoch:4 step:3583[D loss: 0.408258, acc: 66.41%, op_acc: 39.06%] [G loss: 0.968145]\n",
      "epoch:4 step:3584[D loss: 0.441286, acc: 53.12%, op_acc: 35.16%] [G loss: 0.950873]\n",
      "epoch:4 step:3585[D loss: 0.450029, acc: 63.28%, op_acc: 26.56%] [G loss: 0.846791]\n",
      "epoch:4 step:3586[D loss: 0.431292, acc: 61.72%, op_acc: 30.47%] [G loss: 1.039680]\n",
      "epoch:4 step:3587[D loss: 0.479919, acc: 53.91%, op_acc: 28.12%] [G loss: 0.899760]\n",
      "epoch:4 step:3588[D loss: 0.434692, acc: 64.84%, op_acc: 27.34%] [G loss: 1.029049]\n",
      "epoch:4 step:3589[D loss: 0.437378, acc: 61.72%, op_acc: 28.12%] [G loss: 0.939729]\n",
      "epoch:4 step:3590[D loss: 0.436885, acc: 61.72%, op_acc: 33.59%] [G loss: 1.028861]\n",
      "epoch:4 step:3591[D loss: 0.440729, acc: 64.06%, op_acc: 33.59%] [G loss: 1.035444]\n",
      "epoch:4 step:3592[D loss: 0.431767, acc: 61.72%, op_acc: 36.72%] [G loss: 0.983782]\n",
      "epoch:4 step:3593[D loss: 0.424323, acc: 65.62%, op_acc: 35.16%] [G loss: 1.020953]\n",
      "epoch:4 step:3594[D loss: 0.430166, acc: 59.38%, op_acc: 29.69%] [G loss: 1.059148]\n",
      "epoch:4 step:3595[D loss: 0.446681, acc: 65.62%, op_acc: 31.25%] [G loss: 0.860246]\n",
      "epoch:4 step:3596[D loss: 0.458148, acc: 61.72%, op_acc: 26.56%] [G loss: 1.001336]\n",
      "epoch:4 step:3597[D loss: 0.446511, acc: 58.59%, op_acc: 35.94%] [G loss: 0.916410]\n",
      "epoch:4 step:3598[D loss: 0.442116, acc: 64.84%, op_acc: 32.03%] [G loss: 1.039332]\n",
      "epoch:4 step:3599[D loss: 0.447552, acc: 55.47%, op_acc: 33.59%] [G loss: 0.950357]\n",
      "epoch:4 step:3600[D loss: 0.451378, acc: 63.28%, op_acc: 30.47%] [G loss: 0.966208]\n",
      "epoch:4 step:3601[D loss: 0.421636, acc: 60.94%, op_acc: 35.94%] [G loss: 0.984358]\n",
      "epoch:4 step:3602[D loss: 0.459447, acc: 65.62%, op_acc: 33.59%] [G loss: 1.042460]\n",
      "epoch:4 step:3603[D loss: 0.457795, acc: 60.16%, op_acc: 35.94%] [G loss: 1.005184]\n",
      "epoch:4 step:3604[D loss: 0.496524, acc: 58.59%, op_acc: 32.81%] [G loss: 1.066564]\n",
      "epoch:4 step:3605[D loss: 0.462315, acc: 63.28%, op_acc: 29.69%] [G loss: 0.984513]\n",
      "epoch:4 step:3606[D loss: 0.475463, acc: 56.25%, op_acc: 30.47%] [G loss: 1.011210]\n",
      "epoch:4 step:3607[D loss: 0.441883, acc: 62.50%, op_acc: 35.16%] [G loss: 1.081215]\n",
      "epoch:4 step:3608[D loss: 0.445515, acc: 63.28%, op_acc: 34.38%] [G loss: 1.004188]\n",
      "epoch:4 step:3609[D loss: 0.427416, acc: 62.50%, op_acc: 32.03%] [G loss: 0.986356]\n",
      "epoch:4 step:3610[D loss: 0.418899, acc: 68.75%, op_acc: 38.28%] [G loss: 1.079249]\n",
      "epoch:4 step:3611[D loss: 0.454328, acc: 60.94%, op_acc: 32.03%] [G loss: 0.942872]\n",
      "epoch:4 step:3612[D loss: 0.451039, acc: 57.03%, op_acc: 32.03%] [G loss: 0.870503]\n",
      "epoch:4 step:3613[D loss: 0.487079, acc: 53.12%, op_acc: 32.81%] [G loss: 0.977799]\n",
      "epoch:4 step:3614[D loss: 0.477849, acc: 56.25%, op_acc: 33.59%] [G loss: 0.960649]\n",
      "epoch:4 step:3615[D loss: 0.448355, acc: 64.06%, op_acc: 38.28%] [G loss: 1.030346]\n",
      "epoch:4 step:3616[D loss: 0.431119, acc: 60.16%, op_acc: 35.16%] [G loss: 0.988026]\n",
      "epoch:4 step:3617[D loss: 0.445787, acc: 64.06%, op_acc: 39.84%] [G loss: 0.915718]\n",
      "epoch:4 step:3618[D loss: 0.431933, acc: 67.19%, op_acc: 33.59%] [G loss: 0.940568]\n",
      "epoch:4 step:3619[D loss: 0.434620, acc: 66.41%, op_acc: 29.69%] [G loss: 0.900949]\n",
      "epoch:4 step:3620[D loss: 0.439320, acc: 62.50%, op_acc: 29.69%] [G loss: 1.030406]\n",
      "epoch:4 step:3621[D loss: 0.430568, acc: 65.62%, op_acc: 36.72%] [G loss: 1.050167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3622[D loss: 0.479028, acc: 59.38%, op_acc: 28.12%] [G loss: 1.008844]\n",
      "epoch:4 step:3623[D loss: 0.473839, acc: 59.38%, op_acc: 39.06%] [G loss: 1.076172]\n",
      "epoch:4 step:3624[D loss: 0.442211, acc: 56.25%, op_acc: 38.28%] [G loss: 1.007666]\n",
      "epoch:4 step:3625[D loss: 0.451201, acc: 62.50%, op_acc: 33.59%] [G loss: 0.957054]\n",
      "epoch:4 step:3626[D loss: 0.471139, acc: 59.38%, op_acc: 35.16%] [G loss: 0.916331]\n",
      "epoch:4 step:3627[D loss: 0.427069, acc: 65.62%, op_acc: 30.47%] [G loss: 0.899885]\n",
      "epoch:4 step:3628[D loss: 0.480397, acc: 53.12%, op_acc: 33.59%] [G loss: 0.983287]\n",
      "epoch:4 step:3629[D loss: 0.456363, acc: 66.41%, op_acc: 26.56%] [G loss: 0.920435]\n",
      "epoch:4 step:3630[D loss: 0.443403, acc: 63.28%, op_acc: 33.59%] [G loss: 0.934533]\n",
      "epoch:4 step:3631[D loss: 0.399338, acc: 71.88%, op_acc: 35.16%] [G loss: 0.951874]\n",
      "epoch:4 step:3632[D loss: 0.438946, acc: 60.16%, op_acc: 33.59%] [G loss: 0.912845]\n",
      "epoch:4 step:3633[D loss: 0.481338, acc: 54.69%, op_acc: 36.72%] [G loss: 0.976165]\n",
      "epoch:4 step:3634[D loss: 0.426209, acc: 67.19%, op_acc: 35.94%] [G loss: 1.031023]\n",
      "epoch:4 step:3635[D loss: 0.464032, acc: 54.69%, op_acc: 36.72%] [G loss: 0.956927]\n",
      "epoch:4 step:3636[D loss: 0.461684, acc: 66.41%, op_acc: 28.12%] [G loss: 0.888926]\n",
      "epoch:4 step:3637[D loss: 0.485686, acc: 55.47%, op_acc: 25.00%] [G loss: 0.951788]\n",
      "epoch:4 step:3638[D loss: 0.497538, acc: 55.47%, op_acc: 28.12%] [G loss: 1.021507]\n",
      "epoch:4 step:3639[D loss: 0.481616, acc: 52.34%, op_acc: 35.16%] [G loss: 0.901659]\n",
      "epoch:4 step:3640[D loss: 0.462000, acc: 57.03%, op_acc: 28.12%] [G loss: 1.014379]\n",
      "epoch:4 step:3641[D loss: 0.484525, acc: 58.59%, op_acc: 25.78%] [G loss: 0.921167]\n",
      "epoch:4 step:3642[D loss: 0.423526, acc: 67.19%, op_acc: 28.91%] [G loss: 1.022213]\n",
      "epoch:4 step:3643[D loss: 0.441180, acc: 64.84%, op_acc: 31.25%] [G loss: 0.942408]\n",
      "epoch:4 step:3644[D loss: 0.461308, acc: 60.94%, op_acc: 32.03%] [G loss: 0.939768]\n",
      "epoch:4 step:3645[D loss: 0.451214, acc: 60.94%, op_acc: 33.59%] [G loss: 0.979610]\n",
      "epoch:4 step:3646[D loss: 0.456628, acc: 60.16%, op_acc: 28.91%] [G loss: 0.985729]\n",
      "epoch:4 step:3647[D loss: 0.437915, acc: 64.84%, op_acc: 34.38%] [G loss: 0.981681]\n",
      "epoch:4 step:3648[D loss: 0.420206, acc: 72.66%, op_acc: 30.47%] [G loss: 1.046697]\n",
      "epoch:4 step:3649[D loss: 0.430792, acc: 67.19%, op_acc: 29.69%] [G loss: 1.067326]\n",
      "epoch:4 step:3650[D loss: 0.505523, acc: 53.91%, op_acc: 32.03%] [G loss: 1.001057]\n",
      "epoch:4 step:3651[D loss: 0.435188, acc: 64.84%, op_acc: 37.50%] [G loss: 1.083422]\n",
      "epoch:4 step:3652[D loss: 0.453410, acc: 55.47%, op_acc: 37.50%] [G loss: 0.930918]\n",
      "epoch:4 step:3653[D loss: 0.437945, acc: 67.19%, op_acc: 35.16%] [G loss: 0.827943]\n",
      "epoch:4 step:3654[D loss: 0.420376, acc: 68.75%, op_acc: 35.16%] [G loss: 0.940405]\n",
      "epoch:4 step:3655[D loss: 0.452788, acc: 64.84%, op_acc: 29.69%] [G loss: 0.891408]\n",
      "epoch:4 step:3656[D loss: 0.463623, acc: 61.72%, op_acc: 32.03%] [G loss: 0.795858]\n",
      "epoch:4 step:3657[D loss: 0.438954, acc: 62.50%, op_acc: 31.25%] [G loss: 0.993078]\n",
      "epoch:4 step:3658[D loss: 0.445697, acc: 60.94%, op_acc: 35.94%] [G loss: 0.949531]\n",
      "epoch:4 step:3659[D loss: 0.445256, acc: 65.62%, op_acc: 31.25%] [G loss: 0.864779]\n",
      "epoch:4 step:3660[D loss: 0.455559, acc: 64.06%, op_acc: 35.16%] [G loss: 0.959453]\n",
      "epoch:4 step:3661[D loss: 0.457027, acc: 63.28%, op_acc: 28.91%] [G loss: 1.045985]\n",
      "epoch:4 step:3662[D loss: 0.453635, acc: 57.81%, op_acc: 32.03%] [G loss: 0.932310]\n",
      "epoch:4 step:3663[D loss: 0.449386, acc: 66.41%, op_acc: 30.47%] [G loss: 1.041752]\n",
      "epoch:4 step:3664[D loss: 0.410102, acc: 67.19%, op_acc: 35.94%] [G loss: 0.940466]\n",
      "epoch:4 step:3665[D loss: 0.415701, acc: 68.75%, op_acc: 33.59%] [G loss: 1.016746]\n",
      "epoch:4 step:3666[D loss: 0.452577, acc: 57.03%, op_acc: 29.69%] [G loss: 1.028420]\n",
      "epoch:4 step:3667[D loss: 0.453454, acc: 58.59%, op_acc: 35.16%] [G loss: 0.990678]\n",
      "epoch:4 step:3668[D loss: 0.446699, acc: 63.28%, op_acc: 32.81%] [G loss: 0.983045]\n",
      "epoch:4 step:3669[D loss: 0.415952, acc: 59.38%, op_acc: 34.38%] [G loss: 0.929864]\n",
      "epoch:4 step:3670[D loss: 0.450980, acc: 62.50%, op_acc: 34.38%] [G loss: 1.081930]\n",
      "epoch:4 step:3671[D loss: 0.496160, acc: 48.44%, op_acc: 29.69%] [G loss: 0.954098]\n",
      "epoch:4 step:3672[D loss: 0.442592, acc: 64.84%, op_acc: 35.16%] [G loss: 0.986274]\n",
      "epoch:4 step:3673[D loss: 0.456596, acc: 67.19%, op_acc: 31.25%] [G loss: 0.969489]\n",
      "epoch:4 step:3674[D loss: 0.468387, acc: 60.16%, op_acc: 32.81%] [G loss: 1.052143]\n",
      "epoch:4 step:3675[D loss: 0.429886, acc: 63.28%, op_acc: 32.81%] [G loss: 1.014219]\n",
      "epoch:4 step:3676[D loss: 0.466114, acc: 56.25%, op_acc: 25.78%] [G loss: 0.911957]\n",
      "epoch:4 step:3677[D loss: 0.400542, acc: 64.84%, op_acc: 33.59%] [G loss: 1.019065]\n",
      "epoch:4 step:3678[D loss: 0.449727, acc: 58.59%, op_acc: 36.72%] [G loss: 0.959327]\n",
      "epoch:4 step:3679[D loss: 0.424537, acc: 58.59%, op_acc: 33.59%] [G loss: 1.025613]\n",
      "epoch:4 step:3680[D loss: 0.445359, acc: 64.06%, op_acc: 31.25%] [G loss: 0.997970]\n",
      "epoch:4 step:3681[D loss: 0.442033, acc: 64.84%, op_acc: 32.03%] [G loss: 0.967525]\n",
      "epoch:4 step:3682[D loss: 0.430901, acc: 64.06%, op_acc: 36.72%] [G loss: 1.007797]\n",
      "epoch:4 step:3683[D loss: 0.452667, acc: 57.03%, op_acc: 27.34%] [G loss: 0.852098]\n",
      "epoch:4 step:3684[D loss: 0.479415, acc: 54.69%, op_acc: 32.03%] [G loss: 0.851619]\n",
      "epoch:4 step:3685[D loss: 0.438540, acc: 63.28%, op_acc: 33.59%] [G loss: 1.021474]\n",
      "epoch:4 step:3686[D loss: 0.414451, acc: 65.62%, op_acc: 32.03%] [G loss: 0.986493]\n",
      "epoch:4 step:3687[D loss: 0.469498, acc: 54.69%, op_acc: 34.38%] [G loss: 1.020130]\n",
      "epoch:4 step:3688[D loss: 0.447263, acc: 60.16%, op_acc: 39.06%] [G loss: 0.900588]\n",
      "epoch:4 step:3689[D loss: 0.481902, acc: 55.47%, op_acc: 32.03%] [G loss: 0.958273]\n",
      "epoch:4 step:3690[D loss: 0.466042, acc: 58.59%, op_acc: 32.03%] [G loss: 1.032549]\n",
      "epoch:4 step:3691[D loss: 0.414143, acc: 68.75%, op_acc: 37.50%] [G loss: 1.019473]\n",
      "epoch:4 step:3692[D loss: 0.439563, acc: 63.28%, op_acc: 34.38%] [G loss: 1.044643]\n",
      "epoch:4 step:3693[D loss: 0.441053, acc: 59.38%, op_acc: 30.47%] [G loss: 0.996292]\n",
      "epoch:4 step:3694[D loss: 0.394567, acc: 70.31%, op_acc: 39.06%] [G loss: 1.039683]\n",
      "epoch:4 step:3695[D loss: 0.406087, acc: 68.75%, op_acc: 39.06%] [G loss: 1.001178]\n",
      "epoch:4 step:3696[D loss: 0.450695, acc: 57.03%, op_acc: 28.91%] [G loss: 0.886994]\n",
      "epoch:4 step:3697[D loss: 0.443625, acc: 66.41%, op_acc: 32.81%] [G loss: 0.981373]\n",
      "epoch:4 step:3698[D loss: 0.471028, acc: 60.16%, op_acc: 27.34%] [G loss: 0.906364]\n",
      "epoch:4 step:3699[D loss: 0.466850, acc: 52.34%, op_acc: 31.25%] [G loss: 0.955062]\n",
      "epoch:4 step:3700[D loss: 0.437984, acc: 63.28%, op_acc: 35.94%] [G loss: 1.090542]\n",
      "epoch:4 step:3701[D loss: 0.465537, acc: 59.38%, op_acc: 32.81%] [G loss: 0.886991]\n",
      "epoch:4 step:3702[D loss: 0.461232, acc: 60.16%, op_acc: 30.47%] [G loss: 0.900308]\n",
      "epoch:4 step:3703[D loss: 0.394959, acc: 65.62%, op_acc: 37.50%] [G loss: 0.978366]\n",
      "epoch:4 step:3704[D loss: 0.459211, acc: 58.59%, op_acc: 29.69%] [G loss: 0.962778]\n",
      "epoch:4 step:3705[D loss: 0.456085, acc: 61.72%, op_acc: 31.25%] [G loss: 1.013893]\n",
      "epoch:4 step:3706[D loss: 0.455583, acc: 58.59%, op_acc: 28.12%] [G loss: 1.081377]\n",
      "epoch:4 step:3707[D loss: 0.449987, acc: 55.47%, op_acc: 37.50%] [G loss: 0.967173]\n",
      "epoch:4 step:3708[D loss: 0.452984, acc: 60.16%, op_acc: 35.16%] [G loss: 0.964113]\n",
      "epoch:4 step:3709[D loss: 0.481005, acc: 50.78%, op_acc: 29.69%] [G loss: 0.915338]\n",
      "epoch:4 step:3710[D loss: 0.443004, acc: 63.28%, op_acc: 33.59%] [G loss: 1.061698]\n",
      "epoch:4 step:3711[D loss: 0.420174, acc: 66.41%, op_acc: 37.50%] [G loss: 1.029235]\n",
      "epoch:4 step:3712[D loss: 0.417794, acc: 68.75%, op_acc: 36.72%] [G loss: 1.010031]\n",
      "epoch:4 step:3713[D loss: 0.439030, acc: 60.94%, op_acc: 33.59%] [G loss: 0.925141]\n",
      "epoch:4 step:3714[D loss: 0.486305, acc: 53.91%, op_acc: 30.47%] [G loss: 0.959785]\n",
      "epoch:4 step:3715[D loss: 0.435995, acc: 66.41%, op_acc: 38.28%] [G loss: 0.954076]\n",
      "epoch:4 step:3716[D loss: 0.468242, acc: 53.12%, op_acc: 32.03%] [G loss: 0.890131]\n",
      "epoch:4 step:3717[D loss: 0.441982, acc: 61.72%, op_acc: 35.16%] [G loss: 0.982150]\n",
      "epoch:4 step:3718[D loss: 0.458692, acc: 52.34%, op_acc: 32.03%] [G loss: 0.977632]\n",
      "epoch:4 step:3719[D loss: 0.448623, acc: 63.28%, op_acc: 28.91%] [G loss: 0.927767]\n",
      "epoch:4 step:3720[D loss: 0.454023, acc: 62.50%, op_acc: 39.84%] [G loss: 0.931251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3721[D loss: 0.473093, acc: 53.91%, op_acc: 29.69%] [G loss: 0.921376]\n",
      "epoch:4 step:3722[D loss: 0.420386, acc: 67.19%, op_acc: 33.59%] [G loss: 1.001881]\n",
      "epoch:4 step:3723[D loss: 0.445448, acc: 64.84%, op_acc: 32.81%] [G loss: 0.932631]\n",
      "epoch:4 step:3724[D loss: 0.462086, acc: 55.47%, op_acc: 31.25%] [G loss: 1.040349]\n",
      "epoch:4 step:3725[D loss: 0.424644, acc: 68.75%, op_acc: 35.16%] [G loss: 1.115987]\n",
      "epoch:4 step:3726[D loss: 0.385355, acc: 67.19%, op_acc: 39.84%] [G loss: 0.952138]\n",
      "epoch:4 step:3727[D loss: 0.417021, acc: 57.81%, op_acc: 37.50%] [G loss: 0.901179]\n",
      "epoch:4 step:3728[D loss: 0.497494, acc: 54.69%, op_acc: 28.12%] [G loss: 0.946604]\n",
      "epoch:4 step:3729[D loss: 0.440068, acc: 57.81%, op_acc: 28.91%] [G loss: 0.888479]\n",
      "epoch:4 step:3730[D loss: 0.431408, acc: 65.62%, op_acc: 37.50%] [G loss: 0.993708]\n",
      "epoch:4 step:3731[D loss: 0.464423, acc: 53.91%, op_acc: 39.06%] [G loss: 1.037840]\n",
      "epoch:4 step:3732[D loss: 0.433012, acc: 63.28%, op_acc: 34.38%] [G loss: 0.958070]\n",
      "epoch:4 step:3733[D loss: 0.478946, acc: 50.00%, op_acc: 39.06%] [G loss: 1.018724]\n",
      "epoch:4 step:3734[D loss: 0.459826, acc: 62.50%, op_acc: 30.47%] [G loss: 0.951724]\n",
      "epoch:4 step:3735[D loss: 0.445700, acc: 64.06%, op_acc: 35.16%] [G loss: 0.909162]\n",
      "epoch:4 step:3736[D loss: 0.451108, acc: 57.81%, op_acc: 27.34%] [G loss: 0.957915]\n",
      "epoch:4 step:3737[D loss: 0.434097, acc: 58.59%, op_acc: 36.72%] [G loss: 1.067390]\n",
      "epoch:4 step:3738[D loss: 0.408963, acc: 65.62%, op_acc: 37.50%] [G loss: 1.020471]\n",
      "epoch:4 step:3739[D loss: 0.429541, acc: 66.41%, op_acc: 42.19%] [G loss: 0.937478]\n",
      "epoch:4 step:3740[D loss: 0.485278, acc: 57.81%, op_acc: 33.59%] [G loss: 1.088403]\n",
      "epoch:4 step:3741[D loss: 0.477696, acc: 60.16%, op_acc: 25.00%] [G loss: 0.877866]\n",
      "epoch:4 step:3742[D loss: 0.463819, acc: 61.72%, op_acc: 32.03%] [G loss: 0.973472]\n",
      "epoch:4 step:3743[D loss: 0.483112, acc: 54.69%, op_acc: 35.16%] [G loss: 0.958343]\n",
      "epoch:4 step:3744[D loss: 0.482732, acc: 54.69%, op_acc: 25.00%] [G loss: 1.007639]\n",
      "epoch:4 step:3745[D loss: 0.435545, acc: 68.75%, op_acc: 35.94%] [G loss: 1.030758]\n",
      "epoch:4 step:3746[D loss: 0.474669, acc: 57.81%, op_acc: 28.91%] [G loss: 1.083767]\n",
      "epoch:4 step:3747[D loss: 0.462932, acc: 56.25%, op_acc: 35.16%] [G loss: 1.025448]\n",
      "epoch:4 step:3748[D loss: 0.472558, acc: 56.25%, op_acc: 31.25%] [G loss: 1.037829]\n",
      "epoch:4 step:3749[D loss: 0.487402, acc: 51.56%, op_acc: 31.25%] [G loss: 0.891984]\n",
      "epoch:4 step:3750[D loss: 0.450790, acc: 60.16%, op_acc: 35.16%] [G loss: 0.974573]\n",
      "epoch:4 step:3751[D loss: 0.448998, acc: 53.91%, op_acc: 38.28%] [G loss: 1.006214]\n",
      "epoch:4 step:3752[D loss: 0.435269, acc: 65.62%, op_acc: 38.28%] [G loss: 1.049832]\n",
      "epoch:4 step:3753[D loss: 0.503597, acc: 52.34%, op_acc: 28.12%] [G loss: 0.946792]\n",
      "epoch:4 step:3754[D loss: 0.430714, acc: 62.50%, op_acc: 37.50%] [G loss: 1.014885]\n",
      "epoch:4 step:3755[D loss: 0.443880, acc: 59.38%, op_acc: 32.03%] [G loss: 1.007217]\n",
      "epoch:4 step:3756[D loss: 0.445793, acc: 67.97%, op_acc: 31.25%] [G loss: 1.006412]\n",
      "epoch:4 step:3757[D loss: 0.415504, acc: 64.84%, op_acc: 28.91%] [G loss: 1.088739]\n",
      "epoch:4 step:3758[D loss: 0.437725, acc: 57.03%, op_acc: 38.28%] [G loss: 1.022603]\n",
      "epoch:4 step:3759[D loss: 0.456459, acc: 61.72%, op_acc: 37.50%] [G loss: 1.010609]\n",
      "epoch:4 step:3760[D loss: 0.435498, acc: 63.28%, op_acc: 35.94%] [G loss: 1.006478]\n",
      "epoch:4 step:3761[D loss: 0.479336, acc: 55.47%, op_acc: 22.66%] [G loss: 0.882075]\n",
      "epoch:4 step:3762[D loss: 0.440578, acc: 59.38%, op_acc: 25.78%] [G loss: 1.028472]\n",
      "epoch:4 step:3763[D loss: 0.471281, acc: 56.25%, op_acc: 32.81%] [G loss: 0.936651]\n",
      "epoch:4 step:3764[D loss: 0.511483, acc: 50.00%, op_acc: 28.91%] [G loss: 0.857153]\n",
      "epoch:4 step:3765[D loss: 0.438036, acc: 67.97%, op_acc: 27.34%] [G loss: 0.946736]\n",
      "epoch:4 step:3766[D loss: 0.461049, acc: 61.72%, op_acc: 35.16%] [G loss: 0.979954]\n",
      "epoch:4 step:3767[D loss: 0.487393, acc: 56.25%, op_acc: 28.91%] [G loss: 0.952916]\n",
      "epoch:4 step:3768[D loss: 0.449869, acc: 54.69%, op_acc: 36.72%] [G loss: 0.932158]\n",
      "epoch:4 step:3769[D loss: 0.445681, acc: 63.28%, op_acc: 33.59%] [G loss: 1.045498]\n",
      "epoch:4 step:3770[D loss: 0.488888, acc: 58.59%, op_acc: 28.12%] [G loss: 0.886889]\n",
      "epoch:4 step:3771[D loss: 0.458482, acc: 55.47%, op_acc: 32.81%] [G loss: 0.968568]\n",
      "epoch:4 step:3772[D loss: 0.464037, acc: 60.94%, op_acc: 32.81%] [G loss: 0.883557]\n",
      "epoch:4 step:3773[D loss: 0.467357, acc: 53.12%, op_acc: 29.69%] [G loss: 0.977804]\n",
      "epoch:4 step:3774[D loss: 0.495084, acc: 52.34%, op_acc: 29.69%] [G loss: 1.090351]\n",
      "epoch:4 step:3775[D loss: 0.444169, acc: 60.16%, op_acc: 30.47%] [G loss: 1.082225]\n",
      "epoch:4 step:3776[D loss: 0.417860, acc: 68.75%, op_acc: 36.72%] [G loss: 1.068795]\n",
      "epoch:4 step:3777[D loss: 0.396980, acc: 68.75%, op_acc: 42.97%] [G loss: 0.909205]\n",
      "epoch:4 step:3778[D loss: 0.444247, acc: 62.50%, op_acc: 35.16%] [G loss: 0.923424]\n",
      "epoch:4 step:3779[D loss: 0.431759, acc: 63.28%, op_acc: 30.47%] [G loss: 0.898099]\n",
      "epoch:4 step:3780[D loss: 0.472844, acc: 60.16%, op_acc: 28.12%] [G loss: 0.973041]\n",
      "epoch:4 step:3781[D loss: 0.454389, acc: 60.16%, op_acc: 28.91%] [G loss: 0.995800]\n",
      "epoch:4 step:3782[D loss: 0.418889, acc: 67.97%, op_acc: 38.28%] [G loss: 0.921886]\n",
      "epoch:4 step:3783[D loss: 0.411383, acc: 72.66%, op_acc: 35.94%] [G loss: 0.988588]\n",
      "epoch:4 step:3784[D loss: 0.447377, acc: 57.81%, op_acc: 37.50%] [G loss: 0.986547]\n",
      "epoch:4 step:3785[D loss: 0.483836, acc: 51.56%, op_acc: 29.69%] [G loss: 0.889124]\n",
      "epoch:4 step:3786[D loss: 0.426514, acc: 60.94%, op_acc: 42.97%] [G loss: 1.003587]\n",
      "epoch:4 step:3787[D loss: 0.411856, acc: 65.62%, op_acc: 33.59%] [G loss: 0.969699]\n",
      "epoch:4 step:3788[D loss: 0.422330, acc: 59.38%, op_acc: 37.50%] [G loss: 0.950927]\n",
      "epoch:4 step:3789[D loss: 0.456951, acc: 62.50%, op_acc: 25.78%] [G loss: 0.966233]\n",
      "epoch:4 step:3790[D loss: 0.468378, acc: 62.50%, op_acc: 32.03%] [G loss: 0.927414]\n",
      "epoch:4 step:3791[D loss: 0.445046, acc: 60.16%, op_acc: 36.72%] [G loss: 0.942356]\n",
      "epoch:4 step:3792[D loss: 0.471121, acc: 55.47%, op_acc: 32.03%] [G loss: 0.890515]\n",
      "epoch:4 step:3793[D loss: 0.469001, acc: 57.03%, op_acc: 33.59%] [G loss: 0.910973]\n",
      "epoch:4 step:3794[D loss: 0.455195, acc: 56.25%, op_acc: 29.69%] [G loss: 0.956192]\n",
      "epoch:4 step:3795[D loss: 0.453866, acc: 60.94%, op_acc: 32.03%] [G loss: 0.997940]\n",
      "epoch:4 step:3796[D loss: 0.452702, acc: 64.06%, op_acc: 32.81%] [G loss: 1.011714]\n",
      "epoch:4 step:3797[D loss: 0.437389, acc: 63.28%, op_acc: 33.59%] [G loss: 0.955637]\n",
      "epoch:4 step:3798[D loss: 0.446766, acc: 57.81%, op_acc: 35.16%] [G loss: 0.878994]\n",
      "epoch:4 step:3799[D loss: 0.454563, acc: 54.69%, op_acc: 31.25%] [G loss: 0.855027]\n",
      "epoch:4 step:3800[D loss: 0.433670, acc: 69.53%, op_acc: 31.25%] [G loss: 1.009216]\n",
      "epoch:4 step:3801[D loss: 0.493339, acc: 53.12%, op_acc: 33.59%] [G loss: 0.923854]\n",
      "epoch:4 step:3802[D loss: 0.455480, acc: 58.59%, op_acc: 30.47%] [G loss: 0.865244]\n",
      "epoch:4 step:3803[D loss: 0.445232, acc: 60.94%, op_acc: 34.38%] [G loss: 0.948682]\n",
      "epoch:4 step:3804[D loss: 0.448842, acc: 63.28%, op_acc: 32.81%] [G loss: 0.997351]\n",
      "epoch:4 step:3805[D loss: 0.497776, acc: 54.69%, op_acc: 28.91%] [G loss: 0.931316]\n",
      "epoch:4 step:3806[D loss: 0.438041, acc: 60.94%, op_acc: 39.84%] [G loss: 1.056633]\n",
      "epoch:4 step:3807[D loss: 0.451704, acc: 61.72%, op_acc: 36.72%] [G loss: 0.905216]\n",
      "epoch:4 step:3808[D loss: 0.474670, acc: 57.81%, op_acc: 26.56%] [G loss: 0.894331]\n",
      "epoch:4 step:3809[D loss: 0.485421, acc: 54.69%, op_acc: 33.59%] [G loss: 0.946504]\n",
      "epoch:4 step:3810[D loss: 0.480135, acc: 56.25%, op_acc: 30.47%] [G loss: 0.995956]\n",
      "epoch:4 step:3811[D loss: 0.429778, acc: 67.19%, op_acc: 34.38%] [G loss: 1.006505]\n",
      "epoch:4 step:3812[D loss: 0.440565, acc: 64.06%, op_acc: 27.34%] [G loss: 0.938288]\n",
      "epoch:4 step:3813[D loss: 0.490308, acc: 51.56%, op_acc: 32.81%] [G loss: 0.977039]\n",
      "epoch:4 step:3814[D loss: 0.443473, acc: 64.84%, op_acc: 32.81%] [G loss: 0.987896]\n",
      "epoch:4 step:3815[D loss: 0.419535, acc: 65.62%, op_acc: 35.94%] [G loss: 0.966165]\n",
      "epoch:4 step:3816[D loss: 0.473625, acc: 54.69%, op_acc: 30.47%] [G loss: 1.018661]\n",
      "epoch:4 step:3817[D loss: 0.468686, acc: 64.06%, op_acc: 27.34%] [G loss: 0.879025]\n",
      "epoch:4 step:3818[D loss: 0.468607, acc: 60.94%, op_acc: 30.47%] [G loss: 1.005614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3819[D loss: 0.443841, acc: 64.06%, op_acc: 32.03%] [G loss: 0.987120]\n",
      "epoch:4 step:3820[D loss: 0.445076, acc: 60.16%, op_acc: 35.16%] [G loss: 0.957576]\n",
      "epoch:4 step:3821[D loss: 0.492840, acc: 49.22%, op_acc: 31.25%] [G loss: 0.971679]\n",
      "epoch:4 step:3822[D loss: 0.424422, acc: 64.06%, op_acc: 37.50%] [G loss: 0.961266]\n",
      "epoch:4 step:3823[D loss: 0.419899, acc: 63.28%, op_acc: 39.06%] [G loss: 0.952276]\n",
      "epoch:4 step:3824[D loss: 0.472958, acc: 60.16%, op_acc: 27.34%] [G loss: 0.930208]\n",
      "epoch:4 step:3825[D loss: 0.444731, acc: 61.72%, op_acc: 27.34%] [G loss: 0.938945]\n",
      "epoch:4 step:3826[D loss: 0.461534, acc: 56.25%, op_acc: 29.69%] [G loss: 0.909442]\n",
      "epoch:4 step:3827[D loss: 0.422550, acc: 68.75%, op_acc: 32.81%] [G loss: 0.915683]\n",
      "epoch:4 step:3828[D loss: 0.438349, acc: 59.38%, op_acc: 35.16%] [G loss: 0.913054]\n",
      "epoch:4 step:3829[D loss: 0.449313, acc: 60.94%, op_acc: 29.69%] [G loss: 0.856014]\n",
      "epoch:4 step:3830[D loss: 0.438513, acc: 63.28%, op_acc: 32.03%] [G loss: 0.945435]\n",
      "epoch:4 step:3831[D loss: 0.425778, acc: 68.75%, op_acc: 28.91%] [G loss: 0.986796]\n",
      "epoch:4 step:3832[D loss: 0.473999, acc: 51.56%, op_acc: 26.56%] [G loss: 0.883457]\n",
      "epoch:4 step:3833[D loss: 0.431741, acc: 60.94%, op_acc: 35.16%] [G loss: 0.947610]\n",
      "epoch:4 step:3834[D loss: 0.408265, acc: 66.41%, op_acc: 39.06%] [G loss: 0.936136]\n",
      "epoch:4 step:3835[D loss: 0.457171, acc: 60.16%, op_acc: 32.03%] [G loss: 0.972102]\n",
      "epoch:4 step:3836[D loss: 0.419604, acc: 63.28%, op_acc: 39.06%] [G loss: 0.950406]\n",
      "epoch:4 step:3837[D loss: 0.426664, acc: 62.50%, op_acc: 38.28%] [G loss: 1.010355]\n",
      "epoch:4 step:3838[D loss: 0.432418, acc: 67.19%, op_acc: 35.94%] [G loss: 1.036832]\n",
      "epoch:4 step:3839[D loss: 0.451056, acc: 56.25%, op_acc: 34.38%] [G loss: 1.039931]\n",
      "epoch:4 step:3840[D loss: 0.451702, acc: 61.72%, op_acc: 30.47%] [G loss: 0.955525]\n",
      "epoch:4 step:3841[D loss: 0.446463, acc: 59.38%, op_acc: 34.38%] [G loss: 0.975279]\n",
      "epoch:4 step:3842[D loss: 0.448924, acc: 61.72%, op_acc: 28.91%] [G loss: 1.010634]\n",
      "epoch:4 step:3843[D loss: 0.460532, acc: 54.69%, op_acc: 31.25%] [G loss: 1.018556]\n",
      "epoch:4 step:3844[D loss: 0.455353, acc: 63.28%, op_acc: 34.38%] [G loss: 0.923222]\n",
      "epoch:4 step:3845[D loss: 0.450890, acc: 56.25%, op_acc: 34.38%] [G loss: 0.979774]\n",
      "epoch:4 step:3846[D loss: 0.448153, acc: 56.25%, op_acc: 34.38%] [G loss: 1.035872]\n",
      "epoch:4 step:3847[D loss: 0.443212, acc: 58.59%, op_acc: 31.25%] [G loss: 0.828994]\n",
      "epoch:4 step:3848[D loss: 0.496293, acc: 57.81%, op_acc: 25.78%] [G loss: 0.966138]\n",
      "epoch:4 step:3849[D loss: 0.421603, acc: 68.75%, op_acc: 34.38%] [G loss: 0.922076]\n",
      "epoch:4 step:3850[D loss: 0.423080, acc: 64.84%, op_acc: 32.81%] [G loss: 0.911155]\n",
      "epoch:4 step:3851[D loss: 0.463607, acc: 62.50%, op_acc: 25.78%] [G loss: 1.059540]\n",
      "epoch:4 step:3852[D loss: 0.448674, acc: 63.28%, op_acc: 29.69%] [G loss: 0.944460]\n",
      "epoch:4 step:3853[D loss: 0.446649, acc: 60.94%, op_acc: 28.12%] [G loss: 0.874325]\n",
      "epoch:4 step:3854[D loss: 0.404427, acc: 64.84%, op_acc: 34.38%] [G loss: 0.933417]\n",
      "epoch:4 step:3855[D loss: 0.421108, acc: 64.06%, op_acc: 39.06%] [G loss: 1.000566]\n",
      "epoch:4 step:3856[D loss: 0.449844, acc: 64.84%, op_acc: 32.81%] [G loss: 0.881768]\n",
      "epoch:4 step:3857[D loss: 0.440284, acc: 62.50%, op_acc: 30.47%] [G loss: 0.914330]\n",
      "epoch:4 step:3858[D loss: 0.422949, acc: 66.41%, op_acc: 38.28%] [G loss: 1.043199]\n",
      "epoch:4 step:3859[D loss: 0.449630, acc: 60.16%, op_acc: 30.47%] [G loss: 0.991746]\n",
      "epoch:4 step:3860[D loss: 0.419247, acc: 67.19%, op_acc: 33.59%] [G loss: 1.009004]\n",
      "epoch:4 step:3861[D loss: 0.421797, acc: 60.94%, op_acc: 32.81%] [G loss: 1.028201]\n",
      "epoch:4 step:3862[D loss: 0.432920, acc: 60.16%, op_acc: 38.28%] [G loss: 1.082101]\n",
      "epoch:4 step:3863[D loss: 0.422603, acc: 61.72%, op_acc: 34.38%] [G loss: 0.993482]\n",
      "epoch:4 step:3864[D loss: 0.465724, acc: 57.03%, op_acc: 36.72%] [G loss: 0.910345]\n",
      "epoch:4 step:3865[D loss: 0.428377, acc: 71.09%, op_acc: 27.34%] [G loss: 1.087028]\n",
      "epoch:4 step:3866[D loss: 0.449891, acc: 53.91%, op_acc: 38.28%] [G loss: 0.900515]\n",
      "epoch:4 step:3867[D loss: 0.464240, acc: 59.38%, op_acc: 30.47%] [G loss: 0.904335]\n",
      "epoch:4 step:3868[D loss: 0.443252, acc: 53.12%, op_acc: 36.72%] [G loss: 0.928073]\n",
      "epoch:4 step:3869[D loss: 0.454222, acc: 55.47%, op_acc: 35.94%] [G loss: 1.074559]\n",
      "epoch:4 step:3870[D loss: 0.482346, acc: 59.38%, op_acc: 29.69%] [G loss: 0.987151]\n",
      "epoch:4 step:3871[D loss: 0.437398, acc: 60.94%, op_acc: 36.72%] [G loss: 1.076799]\n",
      "epoch:4 step:3872[D loss: 0.445873, acc: 65.62%, op_acc: 32.81%] [G loss: 0.850469]\n",
      "epoch:4 step:3873[D loss: 0.456979, acc: 61.72%, op_acc: 32.81%] [G loss: 0.961979]\n",
      "epoch:4 step:3874[D loss: 0.444491, acc: 56.25%, op_acc: 35.16%] [G loss: 0.968723]\n",
      "epoch:4 step:3875[D loss: 0.494561, acc: 61.72%, op_acc: 27.34%] [G loss: 0.862549]\n",
      "epoch:4 step:3876[D loss: 0.467603, acc: 58.59%, op_acc: 28.91%] [G loss: 0.935713]\n",
      "epoch:4 step:3877[D loss: 0.471233, acc: 56.25%, op_acc: 30.47%] [G loss: 0.973310]\n",
      "epoch:4 step:3878[D loss: 0.463960, acc: 60.94%, op_acc: 29.69%] [G loss: 1.020742]\n",
      "epoch:4 step:3879[D loss: 0.425046, acc: 67.97%, op_acc: 28.91%] [G loss: 1.016229]\n",
      "epoch:4 step:3880[D loss: 0.400650, acc: 73.44%, op_acc: 40.62%] [G loss: 0.974090]\n",
      "epoch:4 step:3881[D loss: 0.436165, acc: 63.28%, op_acc: 29.69%] [G loss: 0.938092]\n",
      "epoch:4 step:3882[D loss: 0.438489, acc: 61.72%, op_acc: 36.72%] [G loss: 0.964925]\n",
      "epoch:4 step:3883[D loss: 0.456020, acc: 62.50%, op_acc: 32.81%] [G loss: 0.920769]\n",
      "epoch:4 step:3884[D loss: 0.412748, acc: 67.19%, op_acc: 35.94%] [G loss: 1.015829]\n",
      "epoch:4 step:3885[D loss: 0.447265, acc: 61.72%, op_acc: 31.25%] [G loss: 0.905721]\n",
      "epoch:4 step:3886[D loss: 0.498917, acc: 51.56%, op_acc: 38.28%] [G loss: 0.958551]\n",
      "epoch:4 step:3887[D loss: 0.448304, acc: 61.72%, op_acc: 35.16%] [G loss: 0.959883]\n",
      "epoch:4 step:3888[D loss: 0.457130, acc: 53.12%, op_acc: 35.94%] [G loss: 0.888377]\n",
      "epoch:4 step:3889[D loss: 0.422552, acc: 62.50%, op_acc: 39.84%] [G loss: 0.933394]\n",
      "epoch:4 step:3890[D loss: 0.481748, acc: 56.25%, op_acc: 33.59%] [G loss: 1.029430]\n",
      "epoch:4 step:3891[D loss: 0.429492, acc: 64.06%, op_acc: 33.59%] [G loss: 0.895237]\n",
      "epoch:4 step:3892[D loss: 0.493098, acc: 59.38%, op_acc: 28.12%] [G loss: 0.927358]\n",
      "epoch:4 step:3893[D loss: 0.433843, acc: 64.84%, op_acc: 37.50%] [G loss: 0.962170]\n",
      "epoch:4 step:3894[D loss: 0.442889, acc: 61.72%, op_acc: 30.47%] [G loss: 1.022083]\n",
      "epoch:4 step:3895[D loss: 0.472032, acc: 60.16%, op_acc: 30.47%] [G loss: 0.922789]\n",
      "epoch:4 step:3896[D loss: 0.442168, acc: 62.50%, op_acc: 30.47%] [G loss: 1.005839]\n",
      "epoch:4 step:3897[D loss: 0.420283, acc: 65.62%, op_acc: 30.47%] [G loss: 1.014456]\n",
      "epoch:4 step:3898[D loss: 0.399421, acc: 64.06%, op_acc: 39.06%] [G loss: 1.046576]\n",
      "epoch:4 step:3899[D loss: 0.457293, acc: 58.59%, op_acc: 29.69%] [G loss: 0.940799]\n",
      "epoch:4 step:3900[D loss: 0.411794, acc: 68.75%, op_acc: 35.94%] [G loss: 0.859898]\n",
      "epoch:4 step:3901[D loss: 0.491286, acc: 58.59%, op_acc: 30.47%] [G loss: 0.916306]\n",
      "epoch:4 step:3902[D loss: 0.427548, acc: 57.81%, op_acc: 39.84%] [G loss: 1.034081]\n",
      "epoch:4 step:3903[D loss: 0.437138, acc: 60.94%, op_acc: 35.94%] [G loss: 0.859481]\n",
      "epoch:4 step:3904[D loss: 0.460601, acc: 56.25%, op_acc: 35.94%] [G loss: 0.970217]\n",
      "epoch:4 step:3905[D loss: 0.424205, acc: 68.75%, op_acc: 36.72%] [G loss: 1.001463]\n",
      "epoch:5 step:3906[D loss: 0.480918, acc: 54.69%, op_acc: 32.81%] [G loss: 0.952640]\n",
      "epoch:5 step:3907[D loss: 0.426018, acc: 64.06%, op_acc: 38.28%] [G loss: 0.948175]\n",
      "epoch:5 step:3908[D loss: 0.466348, acc: 60.94%, op_acc: 30.47%] [G loss: 1.016374]\n",
      "epoch:5 step:3909[D loss: 0.476924, acc: 50.78%, op_acc: 31.25%] [G loss: 0.851614]\n",
      "epoch:5 step:3910[D loss: 0.445478, acc: 58.59%, op_acc: 35.16%] [G loss: 0.891983]\n",
      "epoch:5 step:3911[D loss: 0.455484, acc: 58.59%, op_acc: 34.38%] [G loss: 0.998162]\n",
      "epoch:5 step:3912[D loss: 0.444450, acc: 57.81%, op_acc: 36.72%] [G loss: 0.878267]\n",
      "epoch:5 step:3913[D loss: 0.463507, acc: 60.94%, op_acc: 32.81%] [G loss: 0.904881]\n",
      "epoch:5 step:3914[D loss: 0.448324, acc: 60.16%, op_acc: 32.81%] [G loss: 0.982566]\n",
      "epoch:5 step:3915[D loss: 0.463790, acc: 65.62%, op_acc: 25.78%] [G loss: 0.931453]\n",
      "epoch:5 step:3916[D loss: 0.458685, acc: 54.69%, op_acc: 32.81%] [G loss: 0.940968]\n",
      "epoch:5 step:3917[D loss: 0.453896, acc: 60.16%, op_acc: 29.69%] [G loss: 0.992334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:3918[D loss: 0.439839, acc: 60.16%, op_acc: 32.81%] [G loss: 1.047925]\n",
      "epoch:5 step:3919[D loss: 0.431422, acc: 62.50%, op_acc: 31.25%] [G loss: 0.938975]\n",
      "epoch:5 step:3920[D loss: 0.443612, acc: 60.16%, op_acc: 36.72%] [G loss: 0.944709]\n",
      "epoch:5 step:3921[D loss: 0.438110, acc: 60.16%, op_acc: 28.91%] [G loss: 0.948304]\n",
      "epoch:5 step:3922[D loss: 0.420203, acc: 65.62%, op_acc: 38.28%] [G loss: 0.943450]\n",
      "epoch:5 step:3923[D loss: 0.403026, acc: 71.09%, op_acc: 34.38%] [G loss: 0.999108]\n",
      "epoch:5 step:3924[D loss: 0.400111, acc: 69.53%, op_acc: 32.81%] [G loss: 0.978770]\n",
      "epoch:5 step:3925[D loss: 0.455753, acc: 56.25%, op_acc: 33.59%] [G loss: 0.919310]\n",
      "epoch:5 step:3926[D loss: 0.454014, acc: 58.59%, op_acc: 35.94%] [G loss: 0.954256]\n",
      "epoch:5 step:3927[D loss: 0.476982, acc: 58.59%, op_acc: 39.84%] [G loss: 0.957307]\n",
      "epoch:5 step:3928[D loss: 0.490032, acc: 50.78%, op_acc: 32.81%] [G loss: 0.853235]\n",
      "epoch:5 step:3929[D loss: 0.465966, acc: 55.47%, op_acc: 31.25%] [G loss: 0.972009]\n",
      "epoch:5 step:3930[D loss: 0.474179, acc: 56.25%, op_acc: 31.25%] [G loss: 0.875093]\n",
      "epoch:5 step:3931[D loss: 0.422421, acc: 60.94%, op_acc: 35.94%] [G loss: 0.926714]\n",
      "epoch:5 step:3932[D loss: 0.477563, acc: 53.12%, op_acc: 31.25%] [G loss: 0.885045]\n",
      "epoch:5 step:3933[D loss: 0.447132, acc: 57.03%, op_acc: 33.59%] [G loss: 0.994789]\n",
      "epoch:5 step:3934[D loss: 0.458724, acc: 54.69%, op_acc: 35.16%] [G loss: 0.976043]\n",
      "epoch:5 step:3935[D loss: 0.454715, acc: 56.25%, op_acc: 35.94%] [G loss: 1.015332]\n",
      "epoch:5 step:3936[D loss: 0.490295, acc: 58.59%, op_acc: 28.91%] [G loss: 1.004821]\n",
      "epoch:5 step:3937[D loss: 0.473155, acc: 57.03%, op_acc: 29.69%] [G loss: 0.947851]\n",
      "epoch:5 step:3938[D loss: 0.419213, acc: 65.62%, op_acc: 39.84%] [G loss: 0.890938]\n",
      "epoch:5 step:3939[D loss: 0.407028, acc: 71.09%, op_acc: 39.06%] [G loss: 0.964950]\n",
      "epoch:5 step:3940[D loss: 0.435083, acc: 63.28%, op_acc: 32.81%] [G loss: 0.947027]\n",
      "epoch:5 step:3941[D loss: 0.476314, acc: 50.00%, op_acc: 31.25%] [G loss: 0.917564]\n",
      "epoch:5 step:3942[D loss: 0.442902, acc: 64.06%, op_acc: 30.47%] [G loss: 1.006614]\n",
      "epoch:5 step:3943[D loss: 0.423350, acc: 67.19%, op_acc: 31.25%] [G loss: 1.027460]\n",
      "epoch:5 step:3944[D loss: 0.464325, acc: 60.16%, op_acc: 32.03%] [G loss: 0.974359]\n",
      "epoch:5 step:3945[D loss: 0.488110, acc: 54.69%, op_acc: 17.97%] [G loss: 0.970358]\n",
      "epoch:5 step:3946[D loss: 0.467786, acc: 54.69%, op_acc: 34.38%] [G loss: 0.930629]\n",
      "epoch:5 step:3947[D loss: 0.414418, acc: 60.94%, op_acc: 40.62%] [G loss: 1.029411]\n",
      "epoch:5 step:3948[D loss: 0.492500, acc: 50.00%, op_acc: 27.34%] [G loss: 0.998728]\n",
      "epoch:5 step:3949[D loss: 0.460017, acc: 53.91%, op_acc: 32.03%] [G loss: 1.072009]\n",
      "epoch:5 step:3950[D loss: 0.426878, acc: 63.28%, op_acc: 38.28%] [G loss: 0.899385]\n",
      "epoch:5 step:3951[D loss: 0.480827, acc: 54.69%, op_acc: 28.91%] [G loss: 0.933791]\n",
      "epoch:5 step:3952[D loss: 0.453905, acc: 65.62%, op_acc: 30.47%] [G loss: 0.996394]\n",
      "epoch:5 step:3953[D loss: 0.453860, acc: 64.84%, op_acc: 29.69%] [G loss: 0.889580]\n",
      "epoch:5 step:3954[D loss: 0.481099, acc: 53.91%, op_acc: 28.91%] [G loss: 0.930665]\n",
      "epoch:5 step:3955[D loss: 0.485449, acc: 53.91%, op_acc: 33.59%] [G loss: 0.937974]\n",
      "epoch:5 step:3956[D loss: 0.411103, acc: 67.19%, op_acc: 37.50%] [G loss: 0.913814]\n",
      "epoch:5 step:3957[D loss: 0.453790, acc: 57.81%, op_acc: 31.25%] [G loss: 0.922079]\n",
      "epoch:5 step:3958[D loss: 0.496071, acc: 51.56%, op_acc: 26.56%] [G loss: 0.962316]\n",
      "epoch:5 step:3959[D loss: 0.504949, acc: 50.00%, op_acc: 32.03%] [G loss: 0.881140]\n",
      "epoch:5 step:3960[D loss: 0.422670, acc: 67.19%, op_acc: 31.25%] [G loss: 0.938093]\n",
      "epoch:5 step:3961[D loss: 0.417173, acc: 60.16%, op_acc: 39.06%] [G loss: 0.922116]\n",
      "epoch:5 step:3962[D loss: 0.471234, acc: 54.69%, op_acc: 35.16%] [G loss: 0.926952]\n",
      "epoch:5 step:3963[D loss: 0.417112, acc: 68.75%, op_acc: 37.50%] [G loss: 0.994275]\n",
      "epoch:5 step:3964[D loss: 0.426670, acc: 57.81%, op_acc: 39.06%] [G loss: 0.938141]\n",
      "epoch:5 step:3965[D loss: 0.417988, acc: 62.50%, op_acc: 30.47%] [G loss: 0.932744]\n",
      "epoch:5 step:3966[D loss: 0.417743, acc: 71.88%, op_acc: 34.38%] [G loss: 0.879826]\n",
      "epoch:5 step:3967[D loss: 0.477043, acc: 60.16%, op_acc: 28.91%] [G loss: 0.979470]\n",
      "epoch:5 step:3968[D loss: 0.460477, acc: 53.91%, op_acc: 30.47%] [G loss: 0.891499]\n",
      "epoch:5 step:3969[D loss: 0.423504, acc: 65.62%, op_acc: 35.16%] [G loss: 0.908438]\n",
      "epoch:5 step:3970[D loss: 0.443591, acc: 57.03%, op_acc: 34.38%] [G loss: 0.975665]\n",
      "epoch:5 step:3971[D loss: 0.441241, acc: 67.19%, op_acc: 32.81%] [G loss: 0.944459]\n",
      "epoch:5 step:3972[D loss: 0.445801, acc: 61.72%, op_acc: 39.06%] [G loss: 0.973132]\n",
      "epoch:5 step:3973[D loss: 0.447708, acc: 58.59%, op_acc: 39.06%] [G loss: 0.981262]\n",
      "epoch:5 step:3974[D loss: 0.438931, acc: 54.69%, op_acc: 37.50%] [G loss: 0.910845]\n",
      "epoch:5 step:3975[D loss: 0.468503, acc: 59.38%, op_acc: 27.34%] [G loss: 0.919844]\n",
      "epoch:5 step:3976[D loss: 0.469347, acc: 65.62%, op_acc: 31.25%] [G loss: 0.943697]\n",
      "epoch:5 step:3977[D loss: 0.437143, acc: 64.84%, op_acc: 34.38%] [G loss: 0.824693]\n",
      "epoch:5 step:3978[D loss: 0.476235, acc: 53.91%, op_acc: 35.16%] [G loss: 0.825539]\n",
      "epoch:5 step:3979[D loss: 0.430496, acc: 63.28%, op_acc: 28.91%] [G loss: 0.940632]\n",
      "epoch:5 step:3980[D loss: 0.492565, acc: 47.66%, op_acc: 28.91%] [G loss: 0.855153]\n",
      "epoch:5 step:3981[D loss: 0.434283, acc: 69.53%, op_acc: 37.50%] [G loss: 0.940545]\n",
      "epoch:5 step:3982[D loss: 0.481540, acc: 53.91%, op_acc: 29.69%] [G loss: 0.907385]\n",
      "epoch:5 step:3983[D loss: 0.461341, acc: 65.62%, op_acc: 24.22%] [G loss: 0.980196]\n",
      "epoch:5 step:3984[D loss: 0.475620, acc: 53.91%, op_acc: 32.81%] [G loss: 0.957209]\n",
      "epoch:5 step:3985[D loss: 0.480982, acc: 53.12%, op_acc: 32.81%] [G loss: 0.879107]\n",
      "epoch:5 step:3986[D loss: 0.517309, acc: 44.53%, op_acc: 32.03%] [G loss: 0.925686]\n",
      "epoch:5 step:3987[D loss: 0.427773, acc: 66.41%, op_acc: 39.84%] [G loss: 1.072755]\n",
      "epoch:5 step:3988[D loss: 0.449082, acc: 58.59%, op_acc: 33.59%] [G loss: 1.043006]\n",
      "epoch:5 step:3989[D loss: 0.441398, acc: 60.94%, op_acc: 38.28%] [G loss: 0.929270]\n",
      "epoch:5 step:3990[D loss: 0.442442, acc: 61.72%, op_acc: 30.47%] [G loss: 1.034731]\n",
      "epoch:5 step:3991[D loss: 0.426574, acc: 62.50%, op_acc: 32.81%] [G loss: 0.996886]\n",
      "epoch:5 step:3992[D loss: 0.405563, acc: 67.19%, op_acc: 37.50%] [G loss: 0.975864]\n",
      "epoch:5 step:3993[D loss: 0.453099, acc: 57.03%, op_acc: 36.72%] [G loss: 0.911313]\n",
      "epoch:5 step:3994[D loss: 0.445662, acc: 59.38%, op_acc: 32.03%] [G loss: 0.991256]\n",
      "epoch:5 step:3995[D loss: 0.455799, acc: 53.91%, op_acc: 29.69%] [G loss: 0.922535]\n",
      "epoch:5 step:3996[D loss: 0.437866, acc: 64.06%, op_acc: 34.38%] [G loss: 0.899860]\n",
      "epoch:5 step:3997[D loss: 0.457383, acc: 57.03%, op_acc: 28.91%] [G loss: 1.029698]\n",
      "epoch:5 step:3998[D loss: 0.453269, acc: 60.16%, op_acc: 32.03%] [G loss: 0.971673]\n",
      "epoch:5 step:3999[D loss: 0.423527, acc: 63.28%, op_acc: 35.94%] [G loss: 0.948179]\n",
      "epoch:5 step:4000[D loss: 0.437864, acc: 65.62%, op_acc: 37.50%] [G loss: 0.967146]\n",
      "epoch:5 step:4001[D loss: 0.447371, acc: 60.94%, op_acc: 32.81%] [G loss: 1.020588]\n",
      "epoch:5 step:4002[D loss: 0.419564, acc: 67.19%, op_acc: 33.59%] [G loss: 0.999773]\n",
      "epoch:5 step:4003[D loss: 0.476564, acc: 57.03%, op_acc: 28.91%] [G loss: 0.974126]\n",
      "epoch:5 step:4004[D loss: 0.432109, acc: 64.06%, op_acc: 35.16%] [G loss: 0.988175]\n",
      "epoch:5 step:4005[D loss: 0.436722, acc: 60.94%, op_acc: 37.50%] [G loss: 0.967928]\n",
      "epoch:5 step:4006[D loss: 0.450008, acc: 60.16%, op_acc: 35.94%] [G loss: 1.020239]\n",
      "epoch:5 step:4007[D loss: 0.416651, acc: 67.97%, op_acc: 35.94%] [G loss: 1.105269]\n",
      "epoch:5 step:4008[D loss: 0.447047, acc: 59.38%, op_acc: 31.25%] [G loss: 1.013477]\n",
      "epoch:5 step:4009[D loss: 0.447649, acc: 64.84%, op_acc: 37.50%] [G loss: 0.967498]\n",
      "epoch:5 step:4010[D loss: 0.452835, acc: 63.28%, op_acc: 32.81%] [G loss: 0.916074]\n",
      "epoch:5 step:4011[D loss: 0.434988, acc: 59.38%, op_acc: 37.50%] [G loss: 0.936780]\n",
      "epoch:5 step:4012[D loss: 0.466385, acc: 59.38%, op_acc: 31.25%] [G loss: 0.922794]\n",
      "epoch:5 step:4013[D loss: 0.496304, acc: 46.88%, op_acc: 33.59%] [G loss: 0.988857]\n",
      "epoch:5 step:4014[D loss: 0.456286, acc: 58.59%, op_acc: 28.12%] [G loss: 0.938005]\n",
      "epoch:5 step:4015[D loss: 0.447987, acc: 55.47%, op_acc: 33.59%] [G loss: 0.887725]\n",
      "epoch:5 step:4016[D loss: 0.431954, acc: 62.50%, op_acc: 30.47%] [G loss: 1.017240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4017[D loss: 0.433922, acc: 58.59%, op_acc: 35.94%] [G loss: 0.958736]\n",
      "epoch:5 step:4018[D loss: 0.450468, acc: 60.94%, op_acc: 29.69%] [G loss: 0.951972]\n",
      "epoch:5 step:4019[D loss: 0.424652, acc: 66.41%, op_acc: 37.50%] [G loss: 0.897335]\n",
      "epoch:5 step:4020[D loss: 0.437531, acc: 60.94%, op_acc: 28.91%] [G loss: 0.891762]\n",
      "epoch:5 step:4021[D loss: 0.464642, acc: 69.53%, op_acc: 26.56%] [G loss: 0.944992]\n",
      "epoch:5 step:4022[D loss: 0.427058, acc: 65.62%, op_acc: 38.28%] [G loss: 1.008013]\n",
      "epoch:5 step:4023[D loss: 0.454500, acc: 59.38%, op_acc: 38.28%] [G loss: 0.965296]\n",
      "epoch:5 step:4024[D loss: 0.456555, acc: 66.41%, op_acc: 31.25%] [G loss: 0.924259]\n",
      "epoch:5 step:4025[D loss: 0.450312, acc: 61.72%, op_acc: 29.69%] [G loss: 0.918826]\n",
      "epoch:5 step:4026[D loss: 0.477672, acc: 53.91%, op_acc: 33.59%] [G loss: 0.956519]\n",
      "epoch:5 step:4027[D loss: 0.485958, acc: 52.34%, op_acc: 24.22%] [G loss: 0.950625]\n",
      "epoch:5 step:4028[D loss: 0.474067, acc: 54.69%, op_acc: 31.25%] [G loss: 0.932929]\n",
      "epoch:5 step:4029[D loss: 0.440751, acc: 63.28%, op_acc: 37.50%] [G loss: 0.929777]\n",
      "epoch:5 step:4030[D loss: 0.480139, acc: 56.25%, op_acc: 29.69%] [G loss: 0.893584]\n",
      "epoch:5 step:4031[D loss: 0.427923, acc: 66.41%, op_acc: 32.81%] [G loss: 1.053301]\n",
      "epoch:5 step:4032[D loss: 0.425673, acc: 64.84%, op_acc: 34.38%] [G loss: 1.006455]\n",
      "epoch:5 step:4033[D loss: 0.438030, acc: 57.03%, op_acc: 32.81%] [G loss: 0.859412]\n",
      "epoch:5 step:4034[D loss: 0.448874, acc: 62.50%, op_acc: 29.69%] [G loss: 0.944372]\n",
      "epoch:5 step:4035[D loss: 0.440010, acc: 58.59%, op_acc: 33.59%] [G loss: 0.892678]\n",
      "epoch:5 step:4036[D loss: 0.423735, acc: 68.75%, op_acc: 31.25%] [G loss: 1.064834]\n",
      "epoch:5 step:4037[D loss: 0.422757, acc: 67.19%, op_acc: 36.72%] [G loss: 1.070102]\n",
      "epoch:5 step:4038[D loss: 0.451768, acc: 68.75%, op_acc: 30.47%] [G loss: 0.936803]\n",
      "epoch:5 step:4039[D loss: 0.439732, acc: 65.62%, op_acc: 36.72%] [G loss: 0.981395]\n",
      "epoch:5 step:4040[D loss: 0.479716, acc: 58.59%, op_acc: 37.50%] [G loss: 0.901617]\n",
      "epoch:5 step:4041[D loss: 0.437737, acc: 62.50%, op_acc: 34.38%] [G loss: 0.941607]\n",
      "epoch:5 step:4042[D loss: 0.438898, acc: 65.62%, op_acc: 39.06%] [G loss: 0.960643]\n",
      "epoch:5 step:4043[D loss: 0.471440, acc: 53.12%, op_acc: 36.72%] [G loss: 0.851365]\n",
      "epoch:5 step:4044[D loss: 0.445081, acc: 63.28%, op_acc: 36.72%] [G loss: 0.938708]\n",
      "epoch:5 step:4045[D loss: 0.512103, acc: 51.56%, op_acc: 28.12%] [G loss: 0.937896]\n",
      "epoch:5 step:4046[D loss: 0.488231, acc: 58.59%, op_acc: 30.47%] [G loss: 1.005454]\n",
      "epoch:5 step:4047[D loss: 0.422277, acc: 65.62%, op_acc: 32.81%] [G loss: 0.846284]\n",
      "epoch:5 step:4048[D loss: 0.433693, acc: 64.06%, op_acc: 32.03%] [G loss: 0.992556]\n",
      "epoch:5 step:4049[D loss: 0.429879, acc: 60.94%, op_acc: 34.38%] [G loss: 0.941206]\n",
      "epoch:5 step:4050[D loss: 0.449551, acc: 59.38%, op_acc: 32.03%] [G loss: 0.901852]\n",
      "epoch:5 step:4051[D loss: 0.446650, acc: 57.81%, op_acc: 33.59%] [G loss: 0.882881]\n",
      "epoch:5 step:4052[D loss: 0.425834, acc: 64.84%, op_acc: 39.06%] [G loss: 0.964415]\n",
      "epoch:5 step:4053[D loss: 0.462292, acc: 64.06%, op_acc: 32.81%] [G loss: 0.912859]\n",
      "epoch:5 step:4054[D loss: 0.454967, acc: 57.81%, op_acc: 32.81%] [G loss: 0.938867]\n",
      "epoch:5 step:4055[D loss: 0.421259, acc: 62.50%, op_acc: 39.06%] [G loss: 0.962599]\n",
      "epoch:5 step:4056[D loss: 0.431204, acc: 61.72%, op_acc: 35.94%] [G loss: 0.953088]\n",
      "epoch:5 step:4057[D loss: 0.443970, acc: 61.72%, op_acc: 34.38%] [G loss: 0.853131]\n",
      "epoch:5 step:4058[D loss: 0.481114, acc: 56.25%, op_acc: 28.91%] [G loss: 0.977193]\n",
      "epoch:5 step:4059[D loss: 0.469297, acc: 53.12%, op_acc: 32.03%] [G loss: 0.977701]\n",
      "epoch:5 step:4060[D loss: 0.427325, acc: 62.50%, op_acc: 32.03%] [G loss: 1.072543]\n",
      "epoch:5 step:4061[D loss: 0.473892, acc: 53.91%, op_acc: 35.16%] [G loss: 0.875041]\n",
      "epoch:5 step:4062[D loss: 0.443335, acc: 62.50%, op_acc: 33.59%] [G loss: 0.836162]\n",
      "epoch:5 step:4063[D loss: 0.467008, acc: 52.34%, op_acc: 35.16%] [G loss: 0.990387]\n",
      "epoch:5 step:4064[D loss: 0.459757, acc: 55.47%, op_acc: 35.16%] [G loss: 0.837926]\n",
      "epoch:5 step:4065[D loss: 0.445073, acc: 69.53%, op_acc: 25.78%] [G loss: 0.921424]\n",
      "epoch:5 step:4066[D loss: 0.474336, acc: 61.72%, op_acc: 34.38%] [G loss: 0.920243]\n",
      "epoch:5 step:4067[D loss: 0.472455, acc: 53.12%, op_acc: 38.28%] [G loss: 0.896371]\n",
      "epoch:5 step:4068[D loss: 0.466679, acc: 60.94%, op_acc: 30.47%] [G loss: 0.966885]\n",
      "epoch:5 step:4069[D loss: 0.453649, acc: 63.28%, op_acc: 27.34%] [G loss: 0.993365]\n",
      "epoch:5 step:4070[D loss: 0.445942, acc: 60.16%, op_acc: 33.59%] [G loss: 0.985910]\n",
      "epoch:5 step:4071[D loss: 0.463673, acc: 57.03%, op_acc: 29.69%] [G loss: 0.986195]\n",
      "epoch:5 step:4072[D loss: 0.464942, acc: 60.16%, op_acc: 32.81%] [G loss: 0.870852]\n",
      "epoch:5 step:4073[D loss: 0.445816, acc: 61.72%, op_acc: 33.59%] [G loss: 0.927173]\n",
      "epoch:5 step:4074[D loss: 0.418374, acc: 69.53%, op_acc: 39.84%] [G loss: 0.970456]\n",
      "epoch:5 step:4075[D loss: 0.445759, acc: 52.34%, op_acc: 32.81%] [G loss: 0.964421]\n",
      "epoch:5 step:4076[D loss: 0.465252, acc: 59.38%, op_acc: 30.47%] [G loss: 0.872655]\n",
      "epoch:5 step:4077[D loss: 0.418951, acc: 61.72%, op_acc: 35.16%] [G loss: 0.896718]\n",
      "epoch:5 step:4078[D loss: 0.418388, acc: 66.41%, op_acc: 35.16%] [G loss: 0.985004]\n",
      "epoch:5 step:4079[D loss: 0.502658, acc: 52.34%, op_acc: 34.38%] [G loss: 0.986591]\n",
      "epoch:5 step:4080[D loss: 0.454773, acc: 56.25%, op_acc: 35.94%] [G loss: 0.855731]\n",
      "epoch:5 step:4081[D loss: 0.450116, acc: 59.38%, op_acc: 32.03%] [G loss: 0.929790]\n",
      "epoch:5 step:4082[D loss: 0.436213, acc: 59.38%, op_acc: 32.03%] [G loss: 0.929110]\n",
      "epoch:5 step:4083[D loss: 0.446552, acc: 63.28%, op_acc: 33.59%] [G loss: 0.926181]\n",
      "epoch:5 step:4084[D loss: 0.425716, acc: 57.81%, op_acc: 40.62%] [G loss: 0.897580]\n",
      "epoch:5 step:4085[D loss: 0.430059, acc: 61.72%, op_acc: 35.16%] [G loss: 1.086360]\n",
      "epoch:5 step:4086[D loss: 0.404562, acc: 63.28%, op_acc: 40.62%] [G loss: 1.010437]\n",
      "epoch:5 step:4087[D loss: 0.453100, acc: 62.50%, op_acc: 33.59%] [G loss: 0.993835]\n",
      "epoch:5 step:4088[D loss: 0.448381, acc: 60.94%, op_acc: 33.59%] [G loss: 0.951950]\n",
      "epoch:5 step:4089[D loss: 0.412800, acc: 72.66%, op_acc: 37.50%] [G loss: 0.951969]\n",
      "epoch:5 step:4090[D loss: 0.459355, acc: 60.94%, op_acc: 28.12%] [G loss: 1.072081]\n",
      "epoch:5 step:4091[D loss: 0.439136, acc: 64.06%, op_acc: 35.94%] [G loss: 1.040186]\n",
      "epoch:5 step:4092[D loss: 0.437712, acc: 59.38%, op_acc: 25.78%] [G loss: 0.915419]\n",
      "epoch:5 step:4093[D loss: 0.476448, acc: 51.56%, op_acc: 31.25%] [G loss: 0.920257]\n",
      "epoch:5 step:4094[D loss: 0.410322, acc: 74.22%, op_acc: 33.59%] [G loss: 1.022256]\n",
      "epoch:5 step:4095[D loss: 0.458182, acc: 59.38%, op_acc: 32.81%] [G loss: 1.082554]\n",
      "epoch:5 step:4096[D loss: 0.430736, acc: 60.94%, op_acc: 36.72%] [G loss: 0.989256]\n",
      "epoch:5 step:4097[D loss: 0.469267, acc: 54.69%, op_acc: 32.03%] [G loss: 0.809808]\n",
      "epoch:5 step:4098[D loss: 0.445199, acc: 65.62%, op_acc: 32.81%] [G loss: 1.000303]\n",
      "epoch:5 step:4099[D loss: 0.463844, acc: 60.94%, op_acc: 33.59%] [G loss: 0.982111]\n",
      "epoch:5 step:4100[D loss: 0.462305, acc: 53.12%, op_acc: 25.78%] [G loss: 0.856064]\n",
      "epoch:5 step:4101[D loss: 0.431222, acc: 66.41%, op_acc: 35.16%] [G loss: 0.870532]\n",
      "epoch:5 step:4102[D loss: 0.479077, acc: 50.00%, op_acc: 35.16%] [G loss: 0.827138]\n",
      "epoch:5 step:4103[D loss: 0.448863, acc: 64.06%, op_acc: 32.03%] [G loss: 0.952170]\n",
      "epoch:5 step:4104[D loss: 0.468046, acc: 53.91%, op_acc: 36.72%] [G loss: 0.930942]\n",
      "epoch:5 step:4105[D loss: 0.457885, acc: 54.69%, op_acc: 32.81%] [G loss: 0.961488]\n",
      "epoch:5 step:4106[D loss: 0.459250, acc: 54.69%, op_acc: 32.81%] [G loss: 0.879241]\n",
      "epoch:5 step:4107[D loss: 0.502025, acc: 54.69%, op_acc: 26.56%] [G loss: 0.892283]\n",
      "epoch:5 step:4108[D loss: 0.513268, acc: 47.66%, op_acc: 27.34%] [G loss: 0.851879]\n",
      "epoch:5 step:4109[D loss: 0.464733, acc: 61.72%, op_acc: 30.47%] [G loss: 0.996305]\n",
      "epoch:5 step:4110[D loss: 0.436689, acc: 64.84%, op_acc: 33.59%] [G loss: 0.923736]\n",
      "epoch:5 step:4111[D loss: 0.487107, acc: 60.16%, op_acc: 32.81%] [G loss: 0.958528]\n",
      "epoch:5 step:4112[D loss: 0.452745, acc: 58.59%, op_acc: 32.03%] [G loss: 1.028877]\n",
      "epoch:5 step:4113[D loss: 0.453388, acc: 61.72%, op_acc: 32.81%] [G loss: 0.964673]\n",
      "epoch:5 step:4114[D loss: 0.440468, acc: 60.16%, op_acc: 32.81%] [G loss: 0.978731]\n",
      "epoch:5 step:4115[D loss: 0.458064, acc: 60.16%, op_acc: 28.12%] [G loss: 0.911505]\n",
      "epoch:5 step:4116[D loss: 0.445915, acc: 57.03%, op_acc: 30.47%] [G loss: 0.916349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4117[D loss: 0.442752, acc: 66.41%, op_acc: 32.03%] [G loss: 0.994070]\n",
      "epoch:5 step:4118[D loss: 0.416410, acc: 66.41%, op_acc: 32.81%] [G loss: 0.996407]\n",
      "epoch:5 step:4119[D loss: 0.435882, acc: 70.31%, op_acc: 32.03%] [G loss: 0.970424]\n",
      "epoch:5 step:4120[D loss: 0.450193, acc: 68.75%, op_acc: 29.69%] [G loss: 0.984437]\n",
      "epoch:5 step:4121[D loss: 0.471461, acc: 49.22%, op_acc: 31.25%] [G loss: 0.930942]\n",
      "epoch:5 step:4122[D loss: 0.438111, acc: 56.25%, op_acc: 32.03%] [G loss: 0.955582]\n",
      "epoch:5 step:4123[D loss: 0.435772, acc: 67.19%, op_acc: 34.38%] [G loss: 0.867010]\n",
      "epoch:5 step:4124[D loss: 0.428071, acc: 63.28%, op_acc: 33.59%] [G loss: 0.988024]\n",
      "epoch:5 step:4125[D loss: 0.477970, acc: 56.25%, op_acc: 28.91%] [G loss: 0.849424]\n",
      "epoch:5 step:4126[D loss: 0.451193, acc: 58.59%, op_acc: 32.03%] [G loss: 0.930347]\n",
      "epoch:5 step:4127[D loss: 0.486635, acc: 64.06%, op_acc: 27.34%] [G loss: 0.876354]\n",
      "epoch:5 step:4128[D loss: 0.489912, acc: 52.34%, op_acc: 26.56%] [G loss: 0.948255]\n",
      "epoch:5 step:4129[D loss: 0.489880, acc: 53.91%, op_acc: 30.47%] [G loss: 0.822341]\n",
      "epoch:5 step:4130[D loss: 0.457990, acc: 61.72%, op_acc: 38.28%] [G loss: 0.898723]\n",
      "epoch:5 step:4131[D loss: 0.430506, acc: 63.28%, op_acc: 30.47%] [G loss: 0.970041]\n",
      "epoch:5 step:4132[D loss: 0.438634, acc: 56.25%, op_acc: 33.59%] [G loss: 0.955809]\n",
      "epoch:5 step:4133[D loss: 0.476318, acc: 55.47%, op_acc: 30.47%] [G loss: 0.936299]\n",
      "epoch:5 step:4134[D loss: 0.454699, acc: 62.50%, op_acc: 32.81%] [G loss: 0.853458]\n",
      "epoch:5 step:4135[D loss: 0.429794, acc: 64.06%, op_acc: 30.47%] [G loss: 1.037591]\n",
      "epoch:5 step:4136[D loss: 0.443076, acc: 57.81%, op_acc: 35.16%] [G loss: 0.859771]\n",
      "epoch:5 step:4137[D loss: 0.484216, acc: 50.00%, op_acc: 31.25%] [G loss: 0.920421]\n",
      "epoch:5 step:4138[D loss: 0.444585, acc: 64.84%, op_acc: 32.03%] [G loss: 0.952521]\n",
      "epoch:5 step:4139[D loss: 0.451157, acc: 64.06%, op_acc: 32.81%] [G loss: 0.917926]\n",
      "epoch:5 step:4140[D loss: 0.460616, acc: 64.84%, op_acc: 33.59%] [G loss: 0.881933]\n",
      "epoch:5 step:4141[D loss: 0.456431, acc: 66.41%, op_acc: 28.91%] [G loss: 1.027855]\n",
      "epoch:5 step:4142[D loss: 0.407644, acc: 69.53%, op_acc: 39.84%] [G loss: 1.070661]\n",
      "epoch:5 step:4143[D loss: 0.448613, acc: 59.38%, op_acc: 35.94%] [G loss: 0.864407]\n",
      "epoch:5 step:4144[D loss: 0.459323, acc: 59.38%, op_acc: 35.94%] [G loss: 0.914404]\n",
      "epoch:5 step:4145[D loss: 0.456328, acc: 58.59%, op_acc: 32.81%] [G loss: 0.960292]\n",
      "epoch:5 step:4146[D loss: 0.453795, acc: 57.81%, op_acc: 35.16%] [G loss: 0.929009]\n",
      "epoch:5 step:4147[D loss: 0.452012, acc: 54.69%, op_acc: 32.81%] [G loss: 0.954361]\n",
      "epoch:5 step:4148[D loss: 0.486930, acc: 45.31%, op_acc: 33.59%] [G loss: 0.860995]\n",
      "epoch:5 step:4149[D loss: 0.476929, acc: 53.91%, op_acc: 29.69%] [G loss: 0.944225]\n",
      "epoch:5 step:4150[D loss: 0.434893, acc: 64.84%, op_acc: 33.59%] [G loss: 0.924908]\n",
      "epoch:5 step:4151[D loss: 0.475821, acc: 57.03%, op_acc: 27.34%] [G loss: 0.961930]\n",
      "epoch:5 step:4152[D loss: 0.466733, acc: 57.81%, op_acc: 27.34%] [G loss: 0.817726]\n",
      "epoch:5 step:4153[D loss: 0.472141, acc: 65.62%, op_acc: 27.34%] [G loss: 0.981829]\n",
      "epoch:5 step:4154[D loss: 0.455550, acc: 64.84%, op_acc: 31.25%] [G loss: 0.858167]\n",
      "epoch:5 step:4155[D loss: 0.458960, acc: 57.03%, op_acc: 29.69%] [G loss: 0.904807]\n",
      "epoch:5 step:4156[D loss: 0.422742, acc: 67.19%, op_acc: 34.38%] [G loss: 0.945244]\n",
      "epoch:5 step:4157[D loss: 0.431442, acc: 64.06%, op_acc: 36.72%] [G loss: 0.979948]\n",
      "epoch:5 step:4158[D loss: 0.446684, acc: 58.59%, op_acc: 32.81%] [G loss: 0.950627]\n",
      "epoch:5 step:4159[D loss: 0.489442, acc: 56.25%, op_acc: 31.25%] [G loss: 0.894598]\n",
      "epoch:5 step:4160[D loss: 0.455823, acc: 63.28%, op_acc: 32.81%] [G loss: 0.866053]\n",
      "epoch:5 step:4161[D loss: 0.477949, acc: 56.25%, op_acc: 31.25%] [G loss: 0.875213]\n",
      "epoch:5 step:4162[D loss: 0.444774, acc: 64.06%, op_acc: 28.91%] [G loss: 0.916864]\n",
      "epoch:5 step:4163[D loss: 0.448444, acc: 59.38%, op_acc: 34.38%] [G loss: 0.887937]\n",
      "epoch:5 step:4164[D loss: 0.429335, acc: 67.19%, op_acc: 35.94%] [G loss: 0.962761]\n",
      "epoch:5 step:4165[D loss: 0.450390, acc: 66.41%, op_acc: 36.72%] [G loss: 0.910094]\n",
      "epoch:5 step:4166[D loss: 0.408392, acc: 63.28%, op_acc: 34.38%] [G loss: 0.904345]\n",
      "epoch:5 step:4167[D loss: 0.417927, acc: 67.97%, op_acc: 32.03%] [G loss: 0.888159]\n",
      "epoch:5 step:4168[D loss: 0.441282, acc: 61.72%, op_acc: 39.84%] [G loss: 0.858130]\n",
      "epoch:5 step:4169[D loss: 0.446373, acc: 58.59%, op_acc: 35.16%] [G loss: 0.951825]\n",
      "epoch:5 step:4170[D loss: 0.442071, acc: 57.81%, op_acc: 32.03%] [G loss: 0.961192]\n",
      "epoch:5 step:4171[D loss: 0.453894, acc: 56.25%, op_acc: 30.47%] [G loss: 0.994448]\n",
      "epoch:5 step:4172[D loss: 0.452730, acc: 61.72%, op_acc: 35.16%] [G loss: 0.900788]\n",
      "epoch:5 step:4173[D loss: 0.434255, acc: 62.50%, op_acc: 31.25%] [G loss: 0.886530]\n",
      "epoch:5 step:4174[D loss: 0.419796, acc: 67.19%, op_acc: 32.03%] [G loss: 0.862913]\n",
      "epoch:5 step:4175[D loss: 0.437079, acc: 64.06%, op_acc: 29.69%] [G loss: 0.939197]\n",
      "epoch:5 step:4176[D loss: 0.462815, acc: 58.59%, op_acc: 29.69%] [G loss: 0.910220]\n",
      "epoch:5 step:4177[D loss: 0.439968, acc: 60.16%, op_acc: 31.25%] [G loss: 0.920012]\n",
      "epoch:5 step:4178[D loss: 0.433502, acc: 64.84%, op_acc: 32.81%] [G loss: 1.018355]\n",
      "epoch:5 step:4179[D loss: 0.479308, acc: 46.09%, op_acc: 29.69%] [G loss: 0.872603]\n",
      "epoch:5 step:4180[D loss: 0.444640, acc: 61.72%, op_acc: 34.38%] [G loss: 0.897289]\n",
      "epoch:5 step:4181[D loss: 0.447699, acc: 64.06%, op_acc: 32.81%] [G loss: 0.831581]\n",
      "epoch:5 step:4182[D loss: 0.498720, acc: 53.91%, op_acc: 25.78%] [G loss: 0.898822]\n",
      "epoch:5 step:4183[D loss: 0.478054, acc: 56.25%, op_acc: 30.47%] [G loss: 0.932641]\n",
      "epoch:5 step:4184[D loss: 0.409431, acc: 67.97%, op_acc: 36.72%] [G loss: 0.988801]\n",
      "epoch:5 step:4185[D loss: 0.393920, acc: 67.97%, op_acc: 35.16%] [G loss: 1.021725]\n",
      "epoch:5 step:4186[D loss: 0.466452, acc: 65.62%, op_acc: 30.47%] [G loss: 0.979468]\n",
      "epoch:5 step:4187[D loss: 0.431466, acc: 58.59%, op_acc: 32.03%] [G loss: 1.008958]\n",
      "epoch:5 step:4188[D loss: 0.441370, acc: 59.38%, op_acc: 36.72%] [G loss: 0.972157]\n",
      "epoch:5 step:4189[D loss: 0.415954, acc: 65.62%, op_acc: 33.59%] [G loss: 0.806953]\n",
      "epoch:5 step:4190[D loss: 0.451669, acc: 57.81%, op_acc: 27.34%] [G loss: 0.919850]\n",
      "epoch:5 step:4191[D loss: 0.432698, acc: 64.06%, op_acc: 32.03%] [G loss: 0.870970]\n",
      "epoch:5 step:4192[D loss: 0.494469, acc: 49.22%, op_acc: 35.16%] [G loss: 0.888009]\n",
      "epoch:5 step:4193[D loss: 0.475527, acc: 51.56%, op_acc: 33.59%] [G loss: 0.792965]\n",
      "epoch:5 step:4194[D loss: 0.460705, acc: 57.81%, op_acc: 28.91%] [G loss: 0.896912]\n",
      "epoch:5 step:4195[D loss: 0.435594, acc: 60.16%, op_acc: 36.72%] [G loss: 0.987199]\n",
      "epoch:5 step:4196[D loss: 0.436207, acc: 60.16%, op_acc: 32.03%] [G loss: 1.032942]\n",
      "epoch:5 step:4197[D loss: 0.391442, acc: 76.56%, op_acc: 35.94%] [G loss: 0.926963]\n",
      "epoch:5 step:4198[D loss: 0.430001, acc: 67.19%, op_acc: 35.94%] [G loss: 1.018031]\n",
      "epoch:5 step:4199[D loss: 0.434310, acc: 59.38%, op_acc: 37.50%] [G loss: 0.939710]\n",
      "epoch:5 step:4200[D loss: 0.445896, acc: 58.59%, op_acc: 32.03%] [G loss: 0.842395]\n",
      "epoch:5 step:4201[D loss: 0.434857, acc: 59.38%, op_acc: 35.16%] [G loss: 1.022588]\n",
      "epoch:5 step:4202[D loss: 0.427888, acc: 68.75%, op_acc: 32.81%] [G loss: 0.875856]\n",
      "epoch:5 step:4203[D loss: 0.449992, acc: 67.19%, op_acc: 30.47%] [G loss: 1.036182]\n",
      "epoch:5 step:4204[D loss: 0.438224, acc: 63.28%, op_acc: 38.28%] [G loss: 0.914183]\n",
      "epoch:5 step:4205[D loss: 0.466155, acc: 56.25%, op_acc: 40.62%] [G loss: 1.031623]\n",
      "epoch:5 step:4206[D loss: 0.453750, acc: 53.91%, op_acc: 32.81%] [G loss: 0.889488]\n",
      "epoch:5 step:4207[D loss: 0.441907, acc: 60.94%, op_acc: 33.59%] [G loss: 0.890518]\n",
      "epoch:5 step:4208[D loss: 0.436188, acc: 62.50%, op_acc: 36.72%] [G loss: 0.980964]\n",
      "epoch:5 step:4209[D loss: 0.428992, acc: 64.06%, op_acc: 30.47%] [G loss: 0.942037]\n",
      "epoch:5 step:4210[D loss: 0.454091, acc: 57.81%, op_acc: 28.91%] [G loss: 0.916983]\n",
      "epoch:5 step:4211[D loss: 0.480722, acc: 52.34%, op_acc: 34.38%] [G loss: 0.839967]\n",
      "epoch:5 step:4212[D loss: 0.437199, acc: 63.28%, op_acc: 34.38%] [G loss: 0.931670]\n",
      "epoch:5 step:4213[D loss: 0.477628, acc: 56.25%, op_acc: 27.34%] [G loss: 0.926220]\n",
      "epoch:5 step:4214[D loss: 0.485015, acc: 53.12%, op_acc: 33.59%] [G loss: 0.900172]\n",
      "epoch:5 step:4215[D loss: 0.474367, acc: 54.69%, op_acc: 31.25%] [G loss: 0.943979]\n",
      "epoch:5 step:4216[D loss: 0.444235, acc: 60.16%, op_acc: 33.59%] [G loss: 0.926015]\n",
      "epoch:5 step:4217[D loss: 0.466646, acc: 59.38%, op_acc: 31.25%] [G loss: 0.764043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4218[D loss: 0.499588, acc: 46.88%, op_acc: 28.12%] [G loss: 0.901819]\n",
      "epoch:5 step:4219[D loss: 0.473822, acc: 53.12%, op_acc: 32.03%] [G loss: 0.993339]\n",
      "epoch:5 step:4220[D loss: 0.452830, acc: 54.69%, op_acc: 23.44%] [G loss: 0.904546]\n",
      "epoch:5 step:4221[D loss: 0.463665, acc: 46.88%, op_acc: 32.03%] [G loss: 0.907511]\n",
      "epoch:5 step:4222[D loss: 0.466696, acc: 52.34%, op_acc: 33.59%] [G loss: 0.790463]\n",
      "epoch:5 step:4223[D loss: 0.488391, acc: 56.25%, op_acc: 28.12%] [G loss: 0.827504]\n",
      "epoch:5 step:4224[D loss: 0.482064, acc: 54.69%, op_acc: 31.25%] [G loss: 0.906397]\n",
      "epoch:5 step:4225[D loss: 0.477742, acc: 51.56%, op_acc: 31.25%] [G loss: 0.946651]\n",
      "epoch:5 step:4226[D loss: 0.449596, acc: 62.50%, op_acc: 33.59%] [G loss: 1.002609]\n",
      "epoch:5 step:4227[D loss: 0.465062, acc: 54.69%, op_acc: 32.03%] [G loss: 0.983507]\n",
      "epoch:5 step:4228[D loss: 0.442599, acc: 57.81%, op_acc: 33.59%] [G loss: 0.971433]\n",
      "epoch:5 step:4229[D loss: 0.439471, acc: 64.06%, op_acc: 30.47%] [G loss: 0.897320]\n",
      "epoch:5 step:4230[D loss: 0.467011, acc: 58.59%, op_acc: 32.81%] [G loss: 0.985351]\n",
      "epoch:5 step:4231[D loss: 0.435984, acc: 58.59%, op_acc: 35.16%] [G loss: 0.989763]\n",
      "epoch:5 step:4232[D loss: 0.422189, acc: 69.53%, op_acc: 37.50%] [G loss: 0.973780]\n",
      "epoch:5 step:4233[D loss: 0.445332, acc: 63.28%, op_acc: 33.59%] [G loss: 0.949843]\n",
      "epoch:5 step:4234[D loss: 0.447170, acc: 59.38%, op_acc: 34.38%] [G loss: 0.893887]\n",
      "epoch:5 step:4235[D loss: 0.465893, acc: 55.47%, op_acc: 35.94%] [G loss: 1.037852]\n",
      "epoch:5 step:4236[D loss: 0.436158, acc: 65.62%, op_acc: 31.25%] [G loss: 0.943677]\n",
      "epoch:5 step:4237[D loss: 0.444206, acc: 59.38%, op_acc: 32.81%] [G loss: 0.932142]\n",
      "epoch:5 step:4238[D loss: 0.424867, acc: 74.22%, op_acc: 39.06%] [G loss: 0.924376]\n",
      "epoch:5 step:4239[D loss: 0.438778, acc: 62.50%, op_acc: 32.81%] [G loss: 0.921804]\n",
      "epoch:5 step:4240[D loss: 0.464592, acc: 56.25%, op_acc: 30.47%] [G loss: 0.870397]\n",
      "epoch:5 step:4241[D loss: 0.456193, acc: 58.59%, op_acc: 37.50%] [G loss: 0.920729]\n",
      "epoch:5 step:4242[D loss: 0.451996, acc: 61.72%, op_acc: 35.16%] [G loss: 0.869994]\n",
      "epoch:5 step:4243[D loss: 0.411078, acc: 64.84%, op_acc: 37.50%] [G loss: 0.920097]\n",
      "epoch:5 step:4244[D loss: 0.452449, acc: 57.81%, op_acc: 35.94%] [G loss: 0.860667]\n",
      "epoch:5 step:4245[D loss: 0.485303, acc: 50.78%, op_acc: 32.03%] [G loss: 0.847252]\n",
      "epoch:5 step:4246[D loss: 0.451865, acc: 63.28%, op_acc: 31.25%] [G loss: 0.940901]\n",
      "epoch:5 step:4247[D loss: 0.445177, acc: 61.72%, op_acc: 30.47%] [G loss: 0.916924]\n",
      "epoch:5 step:4248[D loss: 0.459031, acc: 60.94%, op_acc: 38.28%] [G loss: 0.891059]\n",
      "epoch:5 step:4249[D loss: 0.466197, acc: 54.69%, op_acc: 32.03%] [G loss: 0.915733]\n",
      "epoch:5 step:4250[D loss: 0.473038, acc: 54.69%, op_acc: 29.69%] [G loss: 0.864603]\n",
      "epoch:5 step:4251[D loss: 0.437559, acc: 65.62%, op_acc: 29.69%] [G loss: 0.853402]\n",
      "epoch:5 step:4252[D loss: 0.471783, acc: 53.12%, op_acc: 35.16%] [G loss: 0.927036]\n",
      "epoch:5 step:4253[D loss: 0.406936, acc: 65.62%, op_acc: 36.72%] [G loss: 0.983759]\n",
      "epoch:5 step:4254[D loss: 0.428421, acc: 64.06%, op_acc: 35.94%] [G loss: 0.936265]\n",
      "epoch:5 step:4255[D loss: 0.444577, acc: 57.03%, op_acc: 38.28%] [G loss: 0.867800]\n",
      "epoch:5 step:4256[D loss: 0.445023, acc: 59.38%, op_acc: 29.69%] [G loss: 0.962308]\n",
      "epoch:5 step:4257[D loss: 0.446294, acc: 60.16%, op_acc: 30.47%] [G loss: 0.939410]\n",
      "epoch:5 step:4258[D loss: 0.446483, acc: 60.16%, op_acc: 30.47%] [G loss: 0.951854]\n",
      "epoch:5 step:4259[D loss: 0.432340, acc: 64.06%, op_acc: 32.81%] [G loss: 1.047164]\n",
      "epoch:5 step:4260[D loss: 0.474490, acc: 53.91%, op_acc: 34.38%] [G loss: 0.857014]\n",
      "epoch:5 step:4261[D loss: 0.486006, acc: 51.56%, op_acc: 30.47%] [G loss: 0.881170]\n",
      "epoch:5 step:4262[D loss: 0.444974, acc: 64.06%, op_acc: 32.81%] [G loss: 0.929191]\n",
      "epoch:5 step:4263[D loss: 0.452943, acc: 56.25%, op_acc: 34.38%] [G loss: 0.945724]\n",
      "epoch:5 step:4264[D loss: 0.436371, acc: 60.94%, op_acc: 31.25%] [G loss: 0.962520]\n",
      "epoch:5 step:4265[D loss: 0.469390, acc: 60.16%, op_acc: 31.25%] [G loss: 0.937608]\n",
      "epoch:5 step:4266[D loss: 0.441381, acc: 57.81%, op_acc: 38.28%] [G loss: 0.858997]\n",
      "epoch:5 step:4267[D loss: 0.438877, acc: 54.69%, op_acc: 34.38%] [G loss: 0.940192]\n",
      "epoch:5 step:4268[D loss: 0.452790, acc: 60.94%, op_acc: 35.16%] [G loss: 0.911435]\n",
      "epoch:5 step:4269[D loss: 0.454464, acc: 55.47%, op_acc: 30.47%] [G loss: 1.084806]\n",
      "epoch:5 step:4270[D loss: 0.420581, acc: 61.72%, op_acc: 35.94%] [G loss: 0.858352]\n",
      "epoch:5 step:4271[D loss: 0.432638, acc: 60.94%, op_acc: 37.50%] [G loss: 0.874554]\n",
      "epoch:5 step:4272[D loss: 0.448026, acc: 60.94%, op_acc: 25.00%] [G loss: 0.973645]\n",
      "epoch:5 step:4273[D loss: 0.436596, acc: 66.41%, op_acc: 33.59%] [G loss: 1.047958]\n",
      "epoch:5 step:4274[D loss: 0.413139, acc: 68.75%, op_acc: 36.72%] [G loss: 0.956149]\n",
      "epoch:5 step:4275[D loss: 0.439767, acc: 59.38%, op_acc: 35.16%] [G loss: 0.985575]\n",
      "epoch:5 step:4276[D loss: 0.383558, acc: 68.75%, op_acc: 43.75%] [G loss: 1.040112]\n",
      "epoch:5 step:4277[D loss: 0.413331, acc: 66.41%, op_acc: 35.16%] [G loss: 0.999312]\n",
      "epoch:5 step:4278[D loss: 0.466612, acc: 59.38%, op_acc: 34.38%] [G loss: 0.955928]\n",
      "epoch:5 step:4279[D loss: 0.454320, acc: 58.59%, op_acc: 36.72%] [G loss: 0.871050]\n",
      "epoch:5 step:4280[D loss: 0.469603, acc: 52.34%, op_acc: 30.47%] [G loss: 0.916363]\n",
      "epoch:5 step:4281[D loss: 0.476830, acc: 57.03%, op_acc: 30.47%] [G loss: 0.894561]\n",
      "epoch:5 step:4282[D loss: 0.443327, acc: 60.16%, op_acc: 32.03%] [G loss: 1.022213]\n",
      "epoch:5 step:4283[D loss: 0.437786, acc: 62.50%, op_acc: 33.59%] [G loss: 0.970686]\n",
      "epoch:5 step:4284[D loss: 0.402241, acc: 70.31%, op_acc: 35.94%] [G loss: 0.995414]\n",
      "epoch:5 step:4285[D loss: 0.451293, acc: 60.16%, op_acc: 31.25%] [G loss: 1.027892]\n",
      "epoch:5 step:4286[D loss: 0.449607, acc: 57.03%, op_acc: 32.81%] [G loss: 0.936338]\n",
      "epoch:5 step:4287[D loss: 0.434647, acc: 62.50%, op_acc: 35.16%] [G loss: 0.971734]\n",
      "epoch:5 step:4288[D loss: 0.427755, acc: 63.28%, op_acc: 33.59%] [G loss: 0.973863]\n",
      "epoch:5 step:4289[D loss: 0.429513, acc: 62.50%, op_acc: 28.12%] [G loss: 0.970049]\n",
      "epoch:5 step:4290[D loss: 0.419272, acc: 63.28%, op_acc: 34.38%] [G loss: 0.963243]\n",
      "epoch:5 step:4291[D loss: 0.408512, acc: 64.84%, op_acc: 37.50%] [G loss: 0.912211]\n",
      "epoch:5 step:4292[D loss: 0.465785, acc: 57.03%, op_acc: 29.69%] [G loss: 0.907794]\n",
      "epoch:5 step:4293[D loss: 0.476234, acc: 54.69%, op_acc: 31.25%] [G loss: 1.016018]\n",
      "epoch:5 step:4294[D loss: 0.464691, acc: 54.69%, op_acc: 33.59%] [G loss: 0.933128]\n",
      "epoch:5 step:4295[D loss: 0.459644, acc: 53.91%, op_acc: 35.94%] [G loss: 0.860750]\n",
      "epoch:5 step:4296[D loss: 0.448528, acc: 60.94%, op_acc: 32.03%] [G loss: 0.962471]\n",
      "epoch:5 step:4297[D loss: 0.433670, acc: 70.31%, op_acc: 37.50%] [G loss: 0.935500]\n",
      "epoch:5 step:4298[D loss: 0.444764, acc: 66.41%, op_acc: 34.38%] [G loss: 0.948239]\n",
      "epoch:5 step:4299[D loss: 0.436134, acc: 60.94%, op_acc: 32.81%] [G loss: 0.894663]\n",
      "epoch:5 step:4300[D loss: 0.465517, acc: 57.03%, op_acc: 25.00%] [G loss: 0.960945]\n",
      "epoch:5 step:4301[D loss: 0.428564, acc: 65.62%, op_acc: 36.72%] [G loss: 0.993966]\n",
      "epoch:5 step:4302[D loss: 0.435194, acc: 58.59%, op_acc: 43.75%] [G loss: 0.988490]\n",
      "epoch:5 step:4303[D loss: 0.476004, acc: 63.28%, op_acc: 27.34%] [G loss: 0.799378]\n",
      "epoch:5 step:4304[D loss: 0.429085, acc: 60.94%, op_acc: 37.50%] [G loss: 0.939019]\n",
      "epoch:5 step:4305[D loss: 0.448052, acc: 53.12%, op_acc: 39.06%] [G loss: 0.888095]\n",
      "epoch:5 step:4306[D loss: 0.431670, acc: 59.38%, op_acc: 37.50%] [G loss: 0.935686]\n",
      "epoch:5 step:4307[D loss: 0.462464, acc: 54.69%, op_acc: 31.25%] [G loss: 0.940566]\n",
      "epoch:5 step:4308[D loss: 0.423104, acc: 65.62%, op_acc: 35.16%] [G loss: 0.962212]\n",
      "epoch:5 step:4309[D loss: 0.428568, acc: 63.28%, op_acc: 39.06%] [G loss: 0.967302]\n",
      "epoch:5 step:4310[D loss: 0.432254, acc: 67.97%, op_acc: 39.06%] [G loss: 0.907367]\n",
      "epoch:5 step:4311[D loss: 0.456011, acc: 52.34%, op_acc: 35.94%] [G loss: 0.977642]\n",
      "epoch:5 step:4312[D loss: 0.441141, acc: 63.28%, op_acc: 34.38%] [G loss: 0.883324]\n",
      "epoch:5 step:4313[D loss: 0.420503, acc: 67.19%, op_acc: 38.28%] [G loss: 0.934022]\n",
      "epoch:5 step:4314[D loss: 0.474499, acc: 49.22%, op_acc: 34.38%] [G loss: 0.873874]\n",
      "epoch:5 step:4315[D loss: 0.414714, acc: 59.38%, op_acc: 37.50%] [G loss: 0.937821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4316[D loss: 0.450198, acc: 64.84%, op_acc: 32.81%] [G loss: 0.911691]\n",
      "epoch:5 step:4317[D loss: 0.438149, acc: 59.38%, op_acc: 38.28%] [G loss: 0.968384]\n",
      "epoch:5 step:4318[D loss: 0.466803, acc: 52.34%, op_acc: 35.16%] [G loss: 0.899959]\n",
      "epoch:5 step:4319[D loss: 0.459736, acc: 57.81%, op_acc: 32.81%] [G loss: 1.024746]\n",
      "epoch:5 step:4320[D loss: 0.433026, acc: 68.75%, op_acc: 34.38%] [G loss: 0.939142]\n",
      "epoch:5 step:4321[D loss: 0.442110, acc: 67.97%, op_acc: 31.25%] [G loss: 0.965578]\n",
      "epoch:5 step:4322[D loss: 0.478793, acc: 51.56%, op_acc: 30.47%] [G loss: 0.970975]\n",
      "epoch:5 step:4323[D loss: 0.433951, acc: 63.28%, op_acc: 36.72%] [G loss: 0.924297]\n",
      "epoch:5 step:4324[D loss: 0.424095, acc: 66.41%, op_acc: 31.25%] [G loss: 0.999923]\n",
      "epoch:5 step:4325[D loss: 0.478834, acc: 56.25%, op_acc: 30.47%] [G loss: 0.930121]\n",
      "epoch:5 step:4326[D loss: 0.408380, acc: 70.31%, op_acc: 29.69%] [G loss: 0.979014]\n",
      "epoch:5 step:4327[D loss: 0.417208, acc: 65.62%, op_acc: 41.41%] [G loss: 1.004598]\n",
      "epoch:5 step:4328[D loss: 0.466580, acc: 56.25%, op_acc: 35.16%] [G loss: 0.962979]\n",
      "epoch:5 step:4329[D loss: 0.503035, acc: 49.22%, op_acc: 29.69%] [G loss: 0.935795]\n",
      "epoch:5 step:4330[D loss: 0.463558, acc: 56.25%, op_acc: 33.59%] [G loss: 0.962167]\n",
      "epoch:5 step:4331[D loss: 0.490708, acc: 46.88%, op_acc: 30.47%] [G loss: 0.880340]\n",
      "epoch:5 step:4332[D loss: 0.443284, acc: 65.62%, op_acc: 34.38%] [G loss: 0.939714]\n",
      "epoch:5 step:4333[D loss: 0.467479, acc: 56.25%, op_acc: 35.94%] [G loss: 0.909267]\n",
      "epoch:5 step:4334[D loss: 0.468231, acc: 54.69%, op_acc: 36.72%] [G loss: 0.919825]\n",
      "epoch:5 step:4335[D loss: 0.461426, acc: 57.81%, op_acc: 32.03%] [G loss: 0.897328]\n",
      "epoch:5 step:4336[D loss: 0.467710, acc: 57.03%, op_acc: 32.81%] [G loss: 0.949076]\n",
      "epoch:5 step:4337[D loss: 0.431599, acc: 60.94%, op_acc: 33.59%] [G loss: 0.896742]\n",
      "epoch:5 step:4338[D loss: 0.433702, acc: 67.19%, op_acc: 30.47%] [G loss: 1.006435]\n",
      "epoch:5 step:4339[D loss: 0.437970, acc: 62.50%, op_acc: 32.03%] [G loss: 0.925348]\n",
      "epoch:5 step:4340[D loss: 0.446163, acc: 56.25%, op_acc: 39.06%] [G loss: 0.892311]\n",
      "epoch:5 step:4341[D loss: 0.464658, acc: 59.38%, op_acc: 36.72%] [G loss: 0.875664]\n",
      "epoch:5 step:4342[D loss: 0.469024, acc: 57.81%, op_acc: 32.03%] [G loss: 0.922507]\n",
      "epoch:5 step:4343[D loss: 0.463494, acc: 53.91%, op_acc: 37.50%] [G loss: 0.868786]\n",
      "epoch:5 step:4344[D loss: 0.450121, acc: 56.25%, op_acc: 31.25%] [G loss: 0.940012]\n",
      "epoch:5 step:4345[D loss: 0.475096, acc: 59.38%, op_acc: 32.03%] [G loss: 0.879103]\n",
      "epoch:5 step:4346[D loss: 0.457188, acc: 54.69%, op_acc: 35.94%] [G loss: 0.934587]\n",
      "epoch:5 step:4347[D loss: 0.427665, acc: 59.38%, op_acc: 31.25%] [G loss: 0.888233]\n",
      "epoch:5 step:4348[D loss: 0.456502, acc: 60.94%, op_acc: 24.22%] [G loss: 0.877622]\n",
      "epoch:5 step:4349[D loss: 0.459535, acc: 55.47%, op_acc: 32.81%] [G loss: 0.889126]\n",
      "epoch:5 step:4350[D loss: 0.465531, acc: 61.72%, op_acc: 30.47%] [G loss: 0.926646]\n",
      "epoch:5 step:4351[D loss: 0.457258, acc: 54.69%, op_acc: 32.81%] [G loss: 0.949361]\n",
      "epoch:5 step:4352[D loss: 0.444254, acc: 64.06%, op_acc: 31.25%] [G loss: 1.005239]\n",
      "epoch:5 step:4353[D loss: 0.416062, acc: 62.50%, op_acc: 35.16%] [G loss: 0.957557]\n",
      "epoch:5 step:4354[D loss: 0.439607, acc: 59.38%, op_acc: 32.03%] [G loss: 0.856886]\n",
      "epoch:5 step:4355[D loss: 0.460142, acc: 61.72%, op_acc: 28.12%] [G loss: 0.946660]\n",
      "epoch:5 step:4356[D loss: 0.451722, acc: 56.25%, op_acc: 33.59%] [G loss: 0.943202]\n",
      "epoch:5 step:4357[D loss: 0.440223, acc: 61.72%, op_acc: 34.38%] [G loss: 0.958388]\n",
      "epoch:5 step:4358[D loss: 0.412834, acc: 62.50%, op_acc: 39.84%] [G loss: 1.012873]\n",
      "epoch:5 step:4359[D loss: 0.443800, acc: 57.03%, op_acc: 32.81%] [G loss: 0.982339]\n",
      "epoch:5 step:4360[D loss: 0.479242, acc: 57.03%, op_acc: 29.69%] [G loss: 0.993649]\n",
      "epoch:5 step:4361[D loss: 0.439770, acc: 59.38%, op_acc: 30.47%] [G loss: 1.019317]\n",
      "epoch:5 step:4362[D loss: 0.457980, acc: 59.38%, op_acc: 29.69%] [G loss: 0.931823]\n",
      "epoch:5 step:4363[D loss: 0.425760, acc: 61.72%, op_acc: 39.06%] [G loss: 0.836012]\n",
      "epoch:5 step:4364[D loss: 0.430810, acc: 58.59%, op_acc: 32.81%] [G loss: 0.918292]\n",
      "epoch:5 step:4365[D loss: 0.424239, acc: 60.94%, op_acc: 30.47%] [G loss: 0.935749]\n",
      "epoch:5 step:4366[D loss: 0.467382, acc: 58.59%, op_acc: 28.12%] [G loss: 0.908710]\n",
      "epoch:5 step:4367[D loss: 0.445202, acc: 58.59%, op_acc: 30.47%] [G loss: 0.945122]\n",
      "epoch:5 step:4368[D loss: 0.469823, acc: 53.12%, op_acc: 28.91%] [G loss: 0.984884]\n",
      "epoch:5 step:4369[D loss: 0.452233, acc: 66.41%, op_acc: 28.91%] [G loss: 0.947347]\n",
      "epoch:5 step:4370[D loss: 0.447564, acc: 64.06%, op_acc: 28.12%] [G loss: 1.025525]\n",
      "epoch:5 step:4371[D loss: 0.448480, acc: 64.06%, op_acc: 38.28%] [G loss: 0.950333]\n",
      "epoch:5 step:4372[D loss: 0.438607, acc: 59.38%, op_acc: 32.81%] [G loss: 0.891668]\n",
      "epoch:5 step:4373[D loss: 0.431160, acc: 64.84%, op_acc: 38.28%] [G loss: 1.012245]\n",
      "epoch:5 step:4374[D loss: 0.391972, acc: 74.22%, op_acc: 32.03%] [G loss: 0.910451]\n",
      "epoch:5 step:4375[D loss: 0.427309, acc: 60.94%, op_acc: 39.84%] [G loss: 0.914511]\n",
      "epoch:5 step:4376[D loss: 0.461806, acc: 62.50%, op_acc: 31.25%] [G loss: 0.931497]\n",
      "epoch:5 step:4377[D loss: 0.461589, acc: 58.59%, op_acc: 28.12%] [G loss: 0.888285]\n",
      "epoch:5 step:4378[D loss: 0.445083, acc: 59.38%, op_acc: 38.28%] [G loss: 0.943769]\n",
      "epoch:5 step:4379[D loss: 0.430217, acc: 68.75%, op_acc: 28.12%] [G loss: 1.103954]\n",
      "epoch:5 step:4380[D loss: 0.431699, acc: 60.16%, op_acc: 37.50%] [G loss: 0.937045]\n",
      "epoch:5 step:4381[D loss: 0.475055, acc: 55.47%, op_acc: 32.81%] [G loss: 0.917739]\n",
      "epoch:5 step:4382[D loss: 0.444890, acc: 64.06%, op_acc: 39.06%] [G loss: 0.914599]\n",
      "epoch:5 step:4383[D loss: 0.465837, acc: 54.69%, op_acc: 34.38%] [G loss: 0.905782]\n",
      "epoch:5 step:4384[D loss: 0.436812, acc: 61.72%, op_acc: 36.72%] [G loss: 0.886299]\n",
      "epoch:5 step:4385[D loss: 0.490845, acc: 53.91%, op_acc: 25.00%] [G loss: 0.961052]\n",
      "epoch:5 step:4386[D loss: 0.475080, acc: 60.94%, op_acc: 28.91%] [G loss: 0.978115]\n",
      "epoch:5 step:4387[D loss: 0.442632, acc: 61.72%, op_acc: 35.94%] [G loss: 0.936551]\n",
      "epoch:5 step:4388[D loss: 0.471166, acc: 55.47%, op_acc: 31.25%] [G loss: 0.902587]\n",
      "epoch:5 step:4389[D loss: 0.429182, acc: 57.03%, op_acc: 44.53%] [G loss: 0.948163]\n",
      "epoch:5 step:4390[D loss: 0.467777, acc: 55.47%, op_acc: 29.69%] [G loss: 0.870066]\n",
      "epoch:5 step:4391[D loss: 0.401521, acc: 67.19%, op_acc: 39.06%] [G loss: 0.931616]\n",
      "epoch:5 step:4392[D loss: 0.435990, acc: 63.28%, op_acc: 35.16%] [G loss: 0.995614]\n",
      "epoch:5 step:4393[D loss: 0.436390, acc: 61.72%, op_acc: 33.59%] [G loss: 0.971978]\n",
      "epoch:5 step:4394[D loss: 0.437337, acc: 62.50%, op_acc: 34.38%] [G loss: 1.031537]\n",
      "epoch:5 step:4395[D loss: 0.415018, acc: 66.41%, op_acc: 38.28%] [G loss: 0.948152]\n",
      "epoch:5 step:4396[D loss: 0.452146, acc: 67.19%, op_acc: 28.91%] [G loss: 0.923329]\n",
      "epoch:5 step:4397[D loss: 0.421315, acc: 63.28%, op_acc: 31.25%] [G loss: 1.054518]\n",
      "epoch:5 step:4398[D loss: 0.463681, acc: 58.59%, op_acc: 29.69%] [G loss: 0.896584]\n",
      "epoch:5 step:4399[D loss: 0.432079, acc: 56.25%, op_acc: 35.94%] [G loss: 1.013108]\n",
      "epoch:5 step:4400[D loss: 0.434169, acc: 71.88%, op_acc: 31.25%] [G loss: 0.969476]\n",
      "epoch:5 step:4401[D loss: 0.463816, acc: 59.38%, op_acc: 32.81%] [G loss: 0.915408]\n",
      "epoch:5 step:4402[D loss: 0.419824, acc: 60.16%, op_acc: 35.94%] [G loss: 0.903957]\n",
      "epoch:5 step:4403[D loss: 0.473108, acc: 52.34%, op_acc: 34.38%] [G loss: 1.046237]\n",
      "epoch:5 step:4404[D loss: 0.485364, acc: 49.22%, op_acc: 29.69%] [G loss: 0.937066]\n",
      "epoch:5 step:4405[D loss: 0.427137, acc: 65.62%, op_acc: 36.72%] [G loss: 0.991953]\n",
      "epoch:5 step:4406[D loss: 0.453235, acc: 60.16%, op_acc: 30.47%] [G loss: 0.992561]\n",
      "epoch:5 step:4407[D loss: 0.438000, acc: 63.28%, op_acc: 41.41%] [G loss: 1.007123]\n",
      "epoch:5 step:4408[D loss: 0.399703, acc: 77.34%, op_acc: 35.94%] [G loss: 0.949730]\n",
      "epoch:5 step:4409[D loss: 0.469262, acc: 53.12%, op_acc: 28.91%] [G loss: 0.950423]\n",
      "epoch:5 step:4410[D loss: 0.466955, acc: 61.72%, op_acc: 36.72%] [G loss: 0.919081]\n",
      "epoch:5 step:4411[D loss: 0.460170, acc: 57.81%, op_acc: 32.81%] [G loss: 1.055732]\n",
      "epoch:5 step:4412[D loss: 0.408843, acc: 72.66%, op_acc: 28.91%] [G loss: 0.892035]\n",
      "epoch:5 step:4413[D loss: 0.430996, acc: 64.84%, op_acc: 35.94%] [G loss: 1.024424]\n",
      "epoch:5 step:4414[D loss: 0.453011, acc: 62.50%, op_acc: 32.03%] [G loss: 0.942385]\n",
      "epoch:5 step:4415[D loss: 0.434589, acc: 65.62%, op_acc: 32.03%] [G loss: 1.040700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4416[D loss: 0.443351, acc: 59.38%, op_acc: 35.16%] [G loss: 0.974942]\n",
      "epoch:5 step:4417[D loss: 0.478712, acc: 53.91%, op_acc: 29.69%] [G loss: 0.932165]\n",
      "epoch:5 step:4418[D loss: 0.476948, acc: 51.56%, op_acc: 28.91%] [G loss: 0.881518]\n",
      "epoch:5 step:4419[D loss: 0.475941, acc: 56.25%, op_acc: 25.78%] [G loss: 0.841070]\n",
      "epoch:5 step:4420[D loss: 0.463760, acc: 63.28%, op_acc: 30.47%] [G loss: 0.923546]\n",
      "epoch:5 step:4421[D loss: 0.436938, acc: 67.19%, op_acc: 34.38%] [G loss: 0.959951]\n",
      "epoch:5 step:4422[D loss: 0.495710, acc: 54.69%, op_acc: 30.47%] [G loss: 0.860557]\n",
      "epoch:5 step:4423[D loss: 0.428876, acc: 67.19%, op_acc: 35.16%] [G loss: 0.888876]\n",
      "epoch:5 step:4424[D loss: 0.417669, acc: 71.88%, op_acc: 32.81%] [G loss: 0.881161]\n",
      "epoch:5 step:4425[D loss: 0.440116, acc: 60.16%, op_acc: 33.59%] [G loss: 0.887611]\n",
      "epoch:5 step:4426[D loss: 0.459850, acc: 58.59%, op_acc: 33.59%] [G loss: 0.973028]\n",
      "epoch:5 step:4427[D loss: 0.484498, acc: 54.69%, op_acc: 28.91%] [G loss: 0.887589]\n",
      "epoch:5 step:4428[D loss: 0.451431, acc: 61.72%, op_acc: 38.28%] [G loss: 0.877420]\n",
      "epoch:5 step:4429[D loss: 0.465058, acc: 59.38%, op_acc: 24.22%] [G loss: 0.883655]\n",
      "epoch:5 step:4430[D loss: 0.473716, acc: 60.94%, op_acc: 25.78%] [G loss: 1.009145]\n",
      "epoch:5 step:4431[D loss: 0.463220, acc: 58.59%, op_acc: 30.47%] [G loss: 0.967901]\n",
      "epoch:5 step:4432[D loss: 0.466977, acc: 57.81%, op_acc: 29.69%] [G loss: 1.040356]\n",
      "epoch:5 step:4433[D loss: 0.483229, acc: 54.69%, op_acc: 32.03%] [G loss: 0.882252]\n",
      "epoch:5 step:4434[D loss: 0.441551, acc: 64.06%, op_acc: 32.81%] [G loss: 1.021778]\n",
      "epoch:5 step:4435[D loss: 0.426440, acc: 66.41%, op_acc: 31.25%] [G loss: 1.021507]\n",
      "epoch:5 step:4436[D loss: 0.407385, acc: 66.41%, op_acc: 33.59%] [G loss: 1.102310]\n",
      "epoch:5 step:4437[D loss: 0.456257, acc: 59.38%, op_acc: 32.03%] [G loss: 0.914320]\n",
      "epoch:5 step:4438[D loss: 0.460590, acc: 57.03%, op_acc: 39.84%] [G loss: 0.954325]\n",
      "epoch:5 step:4439[D loss: 0.441373, acc: 51.56%, op_acc: 39.84%] [G loss: 0.937351]\n",
      "epoch:5 step:4440[D loss: 0.396143, acc: 71.88%, op_acc: 33.59%] [G loss: 0.909781]\n",
      "epoch:5 step:4441[D loss: 0.444104, acc: 60.94%, op_acc: 34.38%] [G loss: 0.980839]\n",
      "epoch:5 step:4442[D loss: 0.464536, acc: 56.25%, op_acc: 27.34%] [G loss: 0.949214]\n",
      "epoch:5 step:4443[D loss: 0.444658, acc: 55.47%, op_acc: 35.94%] [G loss: 0.963490]\n",
      "epoch:5 step:4444[D loss: 0.482363, acc: 49.22%, op_acc: 34.38%] [G loss: 0.882295]\n",
      "epoch:5 step:4445[D loss: 0.433119, acc: 57.03%, op_acc: 38.28%] [G loss: 0.903218]\n",
      "epoch:5 step:4446[D loss: 0.393424, acc: 71.88%, op_acc: 34.38%] [G loss: 0.946383]\n",
      "epoch:5 step:4447[D loss: 0.407830, acc: 70.31%, op_acc: 35.94%] [G loss: 0.933064]\n",
      "epoch:5 step:4448[D loss: 0.430808, acc: 57.81%, op_acc: 32.03%] [G loss: 0.858677]\n",
      "epoch:5 step:4449[D loss: 0.451106, acc: 58.59%, op_acc: 40.62%] [G loss: 0.902125]\n",
      "epoch:5 step:4450[D loss: 0.411158, acc: 72.66%, op_acc: 34.38%] [G loss: 0.916586]\n",
      "epoch:5 step:4451[D loss: 0.430091, acc: 62.50%, op_acc: 35.94%] [G loss: 0.949501]\n",
      "epoch:5 step:4452[D loss: 0.445756, acc: 60.16%, op_acc: 31.25%] [G loss: 0.964852]\n",
      "epoch:5 step:4453[D loss: 0.438832, acc: 66.41%, op_acc: 33.59%] [G loss: 0.934283]\n",
      "epoch:5 step:4454[D loss: 0.481782, acc: 53.91%, op_acc: 28.91%] [G loss: 1.072208]\n",
      "epoch:5 step:4455[D loss: 0.435566, acc: 64.06%, op_acc: 33.59%] [G loss: 0.867989]\n",
      "epoch:5 step:4456[D loss: 0.448860, acc: 56.25%, op_acc: 32.81%] [G loss: 0.841237]\n",
      "epoch:5 step:4457[D loss: 0.458660, acc: 63.28%, op_acc: 22.66%] [G loss: 0.886908]\n",
      "epoch:5 step:4458[D loss: 0.410575, acc: 68.75%, op_acc: 34.38%] [G loss: 1.038981]\n",
      "epoch:5 step:4459[D loss: 0.443996, acc: 63.28%, op_acc: 25.78%] [G loss: 1.015701]\n",
      "epoch:5 step:4460[D loss: 0.460620, acc: 57.81%, op_acc: 31.25%] [G loss: 0.989286]\n",
      "epoch:5 step:4461[D loss: 0.451415, acc: 54.69%, op_acc: 41.41%] [G loss: 1.046962]\n",
      "epoch:5 step:4462[D loss: 0.463196, acc: 60.94%, op_acc: 27.34%] [G loss: 0.926954]\n",
      "epoch:5 step:4463[D loss: 0.475556, acc: 53.91%, op_acc: 29.69%] [G loss: 0.943090]\n",
      "epoch:5 step:4464[D loss: 0.428616, acc: 61.72%, op_acc: 30.47%] [G loss: 1.009575]\n",
      "epoch:5 step:4465[D loss: 0.495733, acc: 49.22%, op_acc: 27.34%] [G loss: 0.935102]\n",
      "epoch:5 step:4466[D loss: 0.450577, acc: 61.72%, op_acc: 33.59%] [G loss: 0.960183]\n",
      "epoch:5 step:4467[D loss: 0.454287, acc: 57.81%, op_acc: 29.69%] [G loss: 0.860747]\n",
      "epoch:5 step:4468[D loss: 0.475470, acc: 57.81%, op_acc: 32.03%] [G loss: 0.957558]\n",
      "epoch:5 step:4469[D loss: 0.439525, acc: 66.41%, op_acc: 32.81%] [G loss: 1.001760]\n",
      "epoch:5 step:4470[D loss: 0.443681, acc: 57.03%, op_acc: 38.28%] [G loss: 0.967080]\n",
      "epoch:5 step:4471[D loss: 0.430021, acc: 66.41%, op_acc: 33.59%] [G loss: 1.077835]\n",
      "epoch:5 step:4472[D loss: 0.436294, acc: 63.28%, op_acc: 37.50%] [G loss: 0.947596]\n",
      "epoch:5 step:4473[D loss: 0.443176, acc: 61.72%, op_acc: 34.38%] [G loss: 0.863397]\n",
      "epoch:5 step:4474[D loss: 0.466426, acc: 52.34%, op_acc: 29.69%] [G loss: 0.991507]\n",
      "epoch:5 step:4475[D loss: 0.475705, acc: 49.22%, op_acc: 35.94%] [G loss: 0.970648]\n",
      "epoch:5 step:4476[D loss: 0.466087, acc: 60.16%, op_acc: 35.94%] [G loss: 0.995112]\n",
      "epoch:5 step:4477[D loss: 0.474757, acc: 50.78%, op_acc: 34.38%] [G loss: 0.921226]\n",
      "epoch:5 step:4478[D loss: 0.451552, acc: 55.47%, op_acc: 37.50%] [G loss: 0.903899]\n",
      "epoch:5 step:4479[D loss: 0.435998, acc: 64.06%, op_acc: 32.81%] [G loss: 0.952051]\n",
      "epoch:5 step:4480[D loss: 0.442125, acc: 63.28%, op_acc: 30.47%] [G loss: 0.941685]\n",
      "epoch:5 step:4481[D loss: 0.456824, acc: 56.25%, op_acc: 31.25%] [G loss: 0.909269]\n",
      "epoch:5 step:4482[D loss: 0.456285, acc: 54.69%, op_acc: 33.59%] [G loss: 0.934465]\n",
      "epoch:5 step:4483[D loss: 0.491705, acc: 57.81%, op_acc: 29.69%] [G loss: 0.834689]\n",
      "epoch:5 step:4484[D loss: 0.431554, acc: 57.03%, op_acc: 42.19%] [G loss: 1.003234]\n",
      "epoch:5 step:4485[D loss: 0.482513, acc: 54.69%, op_acc: 32.03%] [G loss: 1.010278]\n",
      "epoch:5 step:4486[D loss: 0.470029, acc: 57.03%, op_acc: 31.25%] [G loss: 0.884035]\n",
      "epoch:5 step:4487[D loss: 0.462010, acc: 61.72%, op_acc: 30.47%] [G loss: 0.894535]\n",
      "epoch:5 step:4488[D loss: 0.428211, acc: 60.16%, op_acc: 33.59%] [G loss: 0.947948]\n",
      "epoch:5 step:4489[D loss: 0.446066, acc: 64.06%, op_acc: 35.94%] [G loss: 0.925144]\n",
      "epoch:5 step:4490[D loss: 0.420236, acc: 64.06%, op_acc: 32.03%] [G loss: 0.985056]\n",
      "epoch:5 step:4491[D loss: 0.478639, acc: 56.25%, op_acc: 28.12%] [G loss: 0.934118]\n",
      "epoch:5 step:4492[D loss: 0.421575, acc: 64.84%, op_acc: 32.03%] [G loss: 0.934155]\n",
      "epoch:5 step:4493[D loss: 0.451471, acc: 63.28%, op_acc: 39.84%] [G loss: 0.939154]\n",
      "epoch:5 step:4494[D loss: 0.454082, acc: 59.38%, op_acc: 31.25%] [G loss: 0.921294]\n",
      "epoch:5 step:4495[D loss: 0.468427, acc: 60.94%, op_acc: 34.38%] [G loss: 0.902409]\n",
      "epoch:5 step:4496[D loss: 0.464158, acc: 60.16%, op_acc: 31.25%] [G loss: 0.910466]\n",
      "epoch:5 step:4497[D loss: 0.442766, acc: 59.38%, op_acc: 32.81%] [G loss: 0.850278]\n",
      "epoch:5 step:4498[D loss: 0.460479, acc: 53.12%, op_acc: 31.25%] [G loss: 0.967846]\n",
      "epoch:5 step:4499[D loss: 0.444345, acc: 59.38%, op_acc: 33.59%] [G loss: 0.950266]\n",
      "epoch:5 step:4500[D loss: 0.450994, acc: 67.19%, op_acc: 28.12%] [G loss: 0.957320]\n",
      "epoch:5 step:4501[D loss: 0.459870, acc: 57.81%, op_acc: 34.38%] [G loss: 0.976333]\n",
      "epoch:5 step:4502[D loss: 0.448340, acc: 57.03%, op_acc: 36.72%] [G loss: 1.015916]\n",
      "epoch:5 step:4503[D loss: 0.422026, acc: 63.28%, op_acc: 32.81%] [G loss: 0.892472]\n",
      "epoch:5 step:4504[D loss: 0.430777, acc: 67.19%, op_acc: 33.59%] [G loss: 0.894064]\n",
      "epoch:5 step:4505[D loss: 0.435579, acc: 67.19%, op_acc: 30.47%] [G loss: 0.967561]\n",
      "epoch:5 step:4506[D loss: 0.440176, acc: 60.16%, op_acc: 31.25%] [G loss: 0.971466]\n",
      "epoch:5 step:4507[D loss: 0.406708, acc: 60.16%, op_acc: 44.53%] [G loss: 0.911963]\n",
      "epoch:5 step:4508[D loss: 0.401742, acc: 60.94%, op_acc: 42.19%] [G loss: 0.882626]\n",
      "epoch:5 step:4509[D loss: 0.504481, acc: 54.69%, op_acc: 26.56%] [G loss: 0.940288]\n",
      "epoch:5 step:4510[D loss: 0.439280, acc: 63.28%, op_acc: 32.81%] [G loss: 0.993531]\n",
      "epoch:5 step:4511[D loss: 0.438797, acc: 64.06%, op_acc: 34.38%] [G loss: 0.982389]\n",
      "epoch:5 step:4512[D loss: 0.425913, acc: 61.72%, op_acc: 39.06%] [G loss: 1.000380]\n",
      "epoch:5 step:4513[D loss: 0.423298, acc: 61.72%, op_acc: 38.28%] [G loss: 0.957805]\n",
      "epoch:5 step:4514[D loss: 0.455286, acc: 53.91%, op_acc: 36.72%] [G loss: 0.887693]\n",
      "epoch:5 step:4515[D loss: 0.452993, acc: 65.62%, op_acc: 27.34%] [G loss: 0.840909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4516[D loss: 0.432828, acc: 63.28%, op_acc: 31.25%] [G loss: 0.987734]\n",
      "epoch:5 step:4517[D loss: 0.429652, acc: 66.41%, op_acc: 36.72%] [G loss: 0.991764]\n",
      "epoch:5 step:4518[D loss: 0.425621, acc: 64.06%, op_acc: 33.59%] [G loss: 0.968527]\n",
      "epoch:5 step:4519[D loss: 0.418055, acc: 66.41%, op_acc: 34.38%] [G loss: 0.968461]\n",
      "epoch:5 step:4520[D loss: 0.448382, acc: 60.16%, op_acc: 33.59%] [G loss: 0.930813]\n",
      "epoch:5 step:4521[D loss: 0.470940, acc: 54.69%, op_acc: 35.94%] [G loss: 0.895144]\n",
      "epoch:5 step:4522[D loss: 0.501574, acc: 51.56%, op_acc: 32.03%] [G loss: 0.800853]\n",
      "epoch:5 step:4523[D loss: 0.448139, acc: 62.50%, op_acc: 30.47%] [G loss: 0.970693]\n",
      "epoch:5 step:4524[D loss: 0.469968, acc: 65.62%, op_acc: 29.69%] [G loss: 0.959419]\n",
      "epoch:5 step:4525[D loss: 0.431759, acc: 67.19%, op_acc: 33.59%] [G loss: 0.994001]\n",
      "epoch:5 step:4526[D loss: 0.468117, acc: 60.16%, op_acc: 34.38%] [G loss: 0.930200]\n",
      "epoch:5 step:4527[D loss: 0.456980, acc: 67.97%, op_acc: 28.12%] [G loss: 0.953103]\n",
      "epoch:5 step:4528[D loss: 0.462366, acc: 53.91%, op_acc: 39.06%] [G loss: 0.961230]\n",
      "epoch:5 step:4529[D loss: 0.444535, acc: 61.72%, op_acc: 33.59%] [G loss: 0.823323]\n",
      "epoch:5 step:4530[D loss: 0.458396, acc: 51.56%, op_acc: 37.50%] [G loss: 0.974992]\n",
      "epoch:5 step:4531[D loss: 0.450433, acc: 57.81%, op_acc: 36.72%] [G loss: 0.958388]\n",
      "epoch:5 step:4532[D loss: 0.438391, acc: 60.94%, op_acc: 37.50%] [G loss: 0.875801]\n",
      "epoch:5 step:4533[D loss: 0.464789, acc: 58.59%, op_acc: 35.16%] [G loss: 0.951418]\n",
      "epoch:5 step:4534[D loss: 0.468930, acc: 57.81%, op_acc: 31.25%] [G loss: 0.962120]\n",
      "epoch:5 step:4535[D loss: 0.445052, acc: 62.50%, op_acc: 32.03%] [G loss: 0.984197]\n",
      "epoch:5 step:4536[D loss: 0.440781, acc: 57.81%, op_acc: 34.38%] [G loss: 0.931848]\n",
      "epoch:5 step:4537[D loss: 0.436873, acc: 67.19%, op_acc: 28.91%] [G loss: 0.988773]\n",
      "epoch:5 step:4538[D loss: 0.469789, acc: 49.22%, op_acc: 29.69%] [G loss: 0.929609]\n",
      "epoch:5 step:4539[D loss: 0.429387, acc: 59.38%, op_acc: 36.72%] [G loss: 0.943385]\n",
      "epoch:5 step:4540[D loss: 0.442671, acc: 60.94%, op_acc: 32.03%] [G loss: 0.928703]\n",
      "epoch:5 step:4541[D loss: 0.419126, acc: 63.28%, op_acc: 38.28%] [G loss: 0.923381]\n",
      "epoch:5 step:4542[D loss: 0.440295, acc: 64.06%, op_acc: 29.69%] [G loss: 0.971404]\n",
      "epoch:5 step:4543[D loss: 0.497384, acc: 53.91%, op_acc: 25.78%] [G loss: 0.930570]\n",
      "epoch:5 step:4544[D loss: 0.444820, acc: 60.94%, op_acc: 29.69%] [G loss: 0.837812]\n",
      "epoch:5 step:4545[D loss: 0.457283, acc: 68.75%, op_acc: 33.59%] [G loss: 0.927394]\n",
      "epoch:5 step:4546[D loss: 0.446325, acc: 60.16%, op_acc: 28.91%] [G loss: 1.003285]\n",
      "epoch:5 step:4547[D loss: 0.477948, acc: 56.25%, op_acc: 30.47%] [G loss: 0.964503]\n",
      "epoch:5 step:4548[D loss: 0.462153, acc: 58.59%, op_acc: 32.03%] [G loss: 0.964964]\n",
      "epoch:5 step:4549[D loss: 0.446026, acc: 60.94%, op_acc: 38.28%] [G loss: 0.888921]\n",
      "epoch:5 step:4550[D loss: 0.457994, acc: 57.03%, op_acc: 35.94%] [G loss: 0.898422]\n",
      "epoch:5 step:4551[D loss: 0.476227, acc: 56.25%, op_acc: 29.69%] [G loss: 0.990877]\n",
      "epoch:5 step:4552[D loss: 0.424817, acc: 58.59%, op_acc: 37.50%] [G loss: 0.948992]\n",
      "epoch:5 step:4553[D loss: 0.443196, acc: 64.06%, op_acc: 34.38%] [G loss: 0.951108]\n",
      "epoch:5 step:4554[D loss: 0.490311, acc: 56.25%, op_acc: 30.47%] [G loss: 0.948665]\n",
      "epoch:5 step:4555[D loss: 0.477120, acc: 63.28%, op_acc: 29.69%] [G loss: 0.918450]\n",
      "epoch:5 step:4556[D loss: 0.475649, acc: 54.69%, op_acc: 28.91%] [G loss: 0.923487]\n",
      "epoch:5 step:4557[D loss: 0.411282, acc: 69.53%, op_acc: 39.84%] [G loss: 1.086491]\n",
      "epoch:5 step:4558[D loss: 0.395640, acc: 61.72%, op_acc: 42.19%] [G loss: 0.959107]\n",
      "epoch:5 step:4559[D loss: 0.429275, acc: 65.62%, op_acc: 34.38%] [G loss: 0.992741]\n",
      "epoch:5 step:4560[D loss: 0.461347, acc: 57.03%, op_acc: 31.25%] [G loss: 0.914411]\n",
      "epoch:5 step:4561[D loss: 0.465011, acc: 57.81%, op_acc: 33.59%] [G loss: 0.873850]\n",
      "epoch:5 step:4562[D loss: 0.443139, acc: 64.84%, op_acc: 32.03%] [G loss: 0.955163]\n",
      "epoch:5 step:4563[D loss: 0.411681, acc: 61.72%, op_acc: 35.94%] [G loss: 0.913956]\n",
      "epoch:5 step:4564[D loss: 0.438561, acc: 72.66%, op_acc: 31.25%] [G loss: 0.954606]\n",
      "epoch:5 step:4565[D loss: 0.467888, acc: 55.47%, op_acc: 34.38%] [G loss: 0.916333]\n",
      "epoch:5 step:4566[D loss: 0.451696, acc: 61.72%, op_acc: 33.59%] [G loss: 0.958272]\n",
      "epoch:5 step:4567[D loss: 0.416285, acc: 61.72%, op_acc: 35.94%] [G loss: 0.909750]\n",
      "epoch:5 step:4568[D loss: 0.465196, acc: 51.56%, op_acc: 32.03%] [G loss: 0.899870]\n",
      "epoch:5 step:4569[D loss: 0.428194, acc: 59.38%, op_acc: 39.06%] [G loss: 0.916791]\n",
      "epoch:5 step:4570[D loss: 0.459460, acc: 60.16%, op_acc: 26.56%] [G loss: 0.979478]\n",
      "epoch:5 step:4571[D loss: 0.467594, acc: 57.03%, op_acc: 30.47%] [G loss: 0.893890]\n",
      "epoch:5 step:4572[D loss: 0.440613, acc: 60.94%, op_acc: 31.25%] [G loss: 0.971276]\n",
      "epoch:5 step:4573[D loss: 0.434624, acc: 63.28%, op_acc: 32.03%] [G loss: 0.962122]\n",
      "epoch:5 step:4574[D loss: 0.432889, acc: 65.62%, op_acc: 39.84%] [G loss: 0.934225]\n",
      "epoch:5 step:4575[D loss: 0.441140, acc: 65.62%, op_acc: 26.56%] [G loss: 1.005002]\n",
      "epoch:5 step:4576[D loss: 0.484083, acc: 58.59%, op_acc: 24.22%] [G loss: 0.927100]\n",
      "epoch:5 step:4577[D loss: 0.491941, acc: 52.34%, op_acc: 25.78%] [G loss: 0.972180]\n",
      "epoch:5 step:4578[D loss: 0.447200, acc: 61.72%, op_acc: 32.03%] [G loss: 0.871202]\n",
      "epoch:5 step:4579[D loss: 0.471742, acc: 53.12%, op_acc: 34.38%] [G loss: 0.917640]\n",
      "epoch:5 step:4580[D loss: 0.454097, acc: 62.50%, op_acc: 29.69%] [G loss: 0.930358]\n",
      "epoch:5 step:4581[D loss: 0.460705, acc: 64.06%, op_acc: 28.91%] [G loss: 0.983374]\n",
      "epoch:5 step:4582[D loss: 0.452142, acc: 67.19%, op_acc: 31.25%] [G loss: 0.970405]\n",
      "epoch:5 step:4583[D loss: 0.437776, acc: 62.50%, op_acc: 31.25%] [G loss: 0.999831]\n",
      "epoch:5 step:4584[D loss: 0.414696, acc: 64.84%, op_acc: 37.50%] [G loss: 0.897862]\n",
      "epoch:5 step:4585[D loss: 0.445413, acc: 60.16%, op_acc: 34.38%] [G loss: 1.026270]\n",
      "epoch:5 step:4586[D loss: 0.466700, acc: 57.81%, op_acc: 26.56%] [G loss: 1.018194]\n",
      "epoch:5 step:4587[D loss: 0.437086, acc: 61.72%, op_acc: 35.16%] [G loss: 0.906546]\n",
      "epoch:5 step:4588[D loss: 0.438972, acc: 60.16%, op_acc: 34.38%] [G loss: 1.000004]\n",
      "epoch:5 step:4589[D loss: 0.456056, acc: 62.50%, op_acc: 28.12%] [G loss: 0.909604]\n",
      "epoch:5 step:4590[D loss: 0.439286, acc: 64.06%, op_acc: 30.47%] [G loss: 0.940702]\n",
      "epoch:5 step:4591[D loss: 0.462636, acc: 64.06%, op_acc: 28.12%] [G loss: 0.866549]\n",
      "epoch:5 step:4592[D loss: 0.427731, acc: 64.84%, op_acc: 29.69%] [G loss: 0.982313]\n",
      "epoch:5 step:4593[D loss: 0.422062, acc: 59.38%, op_acc: 42.19%] [G loss: 0.925135]\n",
      "epoch:5 step:4594[D loss: 0.415114, acc: 63.28%, op_acc: 40.62%] [G loss: 0.939648]\n",
      "epoch:5 step:4595[D loss: 0.436135, acc: 66.41%, op_acc: 35.94%] [G loss: 0.913234]\n",
      "epoch:5 step:4596[D loss: 0.456037, acc: 57.03%, op_acc: 31.25%] [G loss: 0.828688]\n",
      "epoch:5 step:4597[D loss: 0.457473, acc: 58.59%, op_acc: 27.34%] [G loss: 0.901603]\n",
      "epoch:5 step:4598[D loss: 0.446323, acc: 65.62%, op_acc: 29.69%] [G loss: 0.945878]\n",
      "epoch:5 step:4599[D loss: 0.454591, acc: 60.94%, op_acc: 36.72%] [G loss: 0.957591]\n",
      "epoch:5 step:4600[D loss: 0.471044, acc: 57.81%, op_acc: 34.38%] [G loss: 0.821421]\n",
      "epoch:5 step:4601[D loss: 0.465634, acc: 56.25%, op_acc: 34.38%] [G loss: 0.940848]\n",
      "epoch:5 step:4602[D loss: 0.434500, acc: 61.72%, op_acc: 35.94%] [G loss: 1.034951]\n",
      "epoch:5 step:4603[D loss: 0.430329, acc: 68.75%, op_acc: 37.50%] [G loss: 0.844482]\n",
      "epoch:5 step:4604[D loss: 0.433703, acc: 61.72%, op_acc: 35.94%] [G loss: 0.926641]\n",
      "epoch:5 step:4605[D loss: 0.433962, acc: 65.62%, op_acc: 31.25%] [G loss: 0.823373]\n",
      "epoch:5 step:4606[D loss: 0.413786, acc: 71.09%, op_acc: 29.69%] [G loss: 0.893247]\n",
      "epoch:5 step:4607[D loss: 0.436432, acc: 65.62%, op_acc: 35.16%] [G loss: 0.914447]\n",
      "epoch:5 step:4608[D loss: 0.435047, acc: 64.06%, op_acc: 33.59%] [G loss: 0.995059]\n",
      "epoch:5 step:4609[D loss: 0.428222, acc: 56.25%, op_acc: 36.72%] [G loss: 0.862122]\n",
      "epoch:5 step:4610[D loss: 0.424827, acc: 61.72%, op_acc: 34.38%] [G loss: 0.886334]\n",
      "epoch:5 step:4611[D loss: 0.445754, acc: 61.72%, op_acc: 32.81%] [G loss: 0.938240]\n",
      "epoch:5 step:4612[D loss: 0.467117, acc: 55.47%, op_acc: 30.47%] [G loss: 0.901302]\n",
      "epoch:5 step:4613[D loss: 0.423623, acc: 67.19%, op_acc: 30.47%] [G loss: 0.945619]\n",
      "epoch:5 step:4614[D loss: 0.415223, acc: 66.41%, op_acc: 35.94%] [G loss: 0.921846]\n",
      "epoch:5 step:4615[D loss: 0.382334, acc: 70.31%, op_acc: 38.28%] [G loss: 0.981081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4616[D loss: 0.433931, acc: 71.09%, op_acc: 29.69%] [G loss: 0.950312]\n",
      "epoch:5 step:4617[D loss: 0.429976, acc: 61.72%, op_acc: 35.16%] [G loss: 0.885964]\n",
      "epoch:5 step:4618[D loss: 0.438965, acc: 59.38%, op_acc: 32.81%] [G loss: 0.945372]\n",
      "epoch:5 step:4619[D loss: 0.443991, acc: 67.97%, op_acc: 30.47%] [G loss: 0.870076]\n",
      "epoch:5 step:4620[D loss: 0.436593, acc: 61.72%, op_acc: 35.16%] [G loss: 1.027248]\n",
      "epoch:5 step:4621[D loss: 0.484392, acc: 52.34%, op_acc: 29.69%] [G loss: 0.918087]\n",
      "epoch:5 step:4622[D loss: 0.418367, acc: 64.84%, op_acc: 32.81%] [G loss: 1.009946]\n",
      "epoch:5 step:4623[D loss: 0.440763, acc: 52.34%, op_acc: 35.94%] [G loss: 0.941546]\n",
      "epoch:5 step:4624[D loss: 0.427171, acc: 63.28%, op_acc: 34.38%] [G loss: 0.939200]\n",
      "epoch:5 step:4625[D loss: 0.458083, acc: 61.72%, op_acc: 31.25%] [G loss: 0.985252]\n",
      "epoch:5 step:4626[D loss: 0.424027, acc: 60.16%, op_acc: 39.06%] [G loss: 0.922213]\n",
      "epoch:5 step:4627[D loss: 0.457018, acc: 57.03%, op_acc: 32.03%] [G loss: 0.893000]\n",
      "epoch:5 step:4628[D loss: 0.419711, acc: 66.41%, op_acc: 33.59%] [G loss: 1.092329]\n",
      "epoch:5 step:4629[D loss: 0.484176, acc: 53.91%, op_acc: 25.78%] [G loss: 0.961152]\n",
      "epoch:5 step:4630[D loss: 0.422682, acc: 71.09%, op_acc: 32.81%] [G loss: 1.049748]\n",
      "epoch:5 step:4631[D loss: 0.470355, acc: 55.47%, op_acc: 32.03%] [G loss: 0.946353]\n",
      "epoch:5 step:4632[D loss: 0.494766, acc: 56.25%, op_acc: 25.00%] [G loss: 0.944248]\n",
      "epoch:5 step:4633[D loss: 0.457780, acc: 57.03%, op_acc: 34.38%] [G loss: 0.957983]\n",
      "epoch:5 step:4634[D loss: 0.452036, acc: 59.38%, op_acc: 34.38%] [G loss: 0.827269]\n",
      "epoch:5 step:4635[D loss: 0.447083, acc: 58.59%, op_acc: 33.59%] [G loss: 0.945592]\n",
      "epoch:5 step:4636[D loss: 0.423302, acc: 64.06%, op_acc: 38.28%] [G loss: 0.930909]\n",
      "epoch:5 step:4637[D loss: 0.439381, acc: 60.94%, op_acc: 35.94%] [G loss: 0.966869]\n",
      "epoch:5 step:4638[D loss: 0.442541, acc: 52.34%, op_acc: 32.03%] [G loss: 0.982657]\n",
      "epoch:5 step:4639[D loss: 0.467176, acc: 59.38%, op_acc: 30.47%] [G loss: 0.898685]\n",
      "epoch:5 step:4640[D loss: 0.470896, acc: 59.38%, op_acc: 29.69%] [G loss: 0.921260]\n",
      "epoch:5 step:4641[D loss: 0.461273, acc: 54.69%, op_acc: 32.81%] [G loss: 0.931580]\n",
      "epoch:5 step:4642[D loss: 0.432845, acc: 53.12%, op_acc: 39.84%] [G loss: 0.980932]\n",
      "epoch:5 step:4643[D loss: 0.432290, acc: 65.62%, op_acc: 35.94%] [G loss: 0.894263]\n",
      "epoch:5 step:4644[D loss: 0.417516, acc: 68.75%, op_acc: 35.16%] [G loss: 0.941014]\n",
      "epoch:5 step:4645[D loss: 0.440714, acc: 56.25%, op_acc: 34.38%] [G loss: 0.950070]\n",
      "epoch:5 step:4646[D loss: 0.446177, acc: 62.50%, op_acc: 31.25%] [G loss: 1.020559]\n",
      "epoch:5 step:4647[D loss: 0.455440, acc: 60.94%, op_acc: 32.03%] [G loss: 0.941011]\n",
      "epoch:5 step:4648[D loss: 0.447820, acc: 67.97%, op_acc: 28.12%] [G loss: 0.960033]\n",
      "epoch:5 step:4649[D loss: 0.413442, acc: 61.72%, op_acc: 39.06%] [G loss: 0.919681]\n",
      "epoch:5 step:4650[D loss: 0.446433, acc: 60.16%, op_acc: 32.03%] [G loss: 0.989482]\n",
      "epoch:5 step:4651[D loss: 0.437424, acc: 67.19%, op_acc: 33.59%] [G loss: 0.990360]\n",
      "epoch:5 step:4652[D loss: 0.423010, acc: 63.28%, op_acc: 39.84%] [G loss: 0.933703]\n",
      "epoch:5 step:4653[D loss: 0.489274, acc: 54.69%, op_acc: 26.56%] [G loss: 0.874679]\n",
      "epoch:5 step:4654[D loss: 0.450178, acc: 61.72%, op_acc: 28.91%] [G loss: 0.989370]\n",
      "epoch:5 step:4655[D loss: 0.451199, acc: 57.03%, op_acc: 32.81%] [G loss: 0.903862]\n",
      "epoch:5 step:4656[D loss: 0.486733, acc: 57.03%, op_acc: 34.38%] [G loss: 0.903497]\n",
      "epoch:5 step:4657[D loss: 0.413037, acc: 74.22%, op_acc: 34.38%] [G loss: 0.899288]\n",
      "epoch:5 step:4658[D loss: 0.418745, acc: 71.09%, op_acc: 36.72%] [G loss: 0.866466]\n",
      "epoch:5 step:4659[D loss: 0.441921, acc: 57.81%, op_acc: 37.50%] [G loss: 0.901665]\n",
      "epoch:5 step:4660[D loss: 0.459722, acc: 56.25%, op_acc: 34.38%] [G loss: 0.886015]\n",
      "epoch:5 step:4661[D loss: 0.404794, acc: 64.06%, op_acc: 40.62%] [G loss: 0.998412]\n",
      "epoch:5 step:4662[D loss: 0.436291, acc: 60.94%, op_acc: 35.94%] [G loss: 0.993829]\n",
      "epoch:5 step:4663[D loss: 0.464976, acc: 53.12%, op_acc: 40.62%] [G loss: 1.046233]\n",
      "epoch:5 step:4664[D loss: 0.450900, acc: 55.47%, op_acc: 28.91%] [G loss: 0.924464]\n",
      "epoch:5 step:4665[D loss: 0.437839, acc: 57.81%, op_acc: 37.50%] [G loss: 0.946387]\n",
      "epoch:5 step:4666[D loss: 0.418361, acc: 66.41%, op_acc: 38.28%] [G loss: 0.821139]\n",
      "epoch:5 step:4667[D loss: 0.498723, acc: 55.47%, op_acc: 29.69%] [G loss: 0.954694]\n",
      "epoch:5 step:4668[D loss: 0.455078, acc: 59.38%, op_acc: 38.28%] [G loss: 0.953403]\n",
      "epoch:5 step:4669[D loss: 0.453279, acc: 53.91%, op_acc: 37.50%] [G loss: 0.964104]\n",
      "epoch:5 step:4670[D loss: 0.398495, acc: 71.88%, op_acc: 33.59%] [G loss: 0.922189]\n",
      "epoch:5 step:4671[D loss: 0.455130, acc: 64.06%, op_acc: 32.03%] [G loss: 0.980059]\n",
      "epoch:5 step:4672[D loss: 0.449311, acc: 57.03%, op_acc: 28.91%] [G loss: 0.931511]\n",
      "epoch:5 step:4673[D loss: 0.483851, acc: 53.12%, op_acc: 29.69%] [G loss: 0.965799]\n",
      "epoch:5 step:4674[D loss: 0.433317, acc: 63.28%, op_acc: 31.25%] [G loss: 0.953559]\n",
      "epoch:5 step:4675[D loss: 0.447583, acc: 60.94%, op_acc: 31.25%] [G loss: 0.988968]\n",
      "epoch:5 step:4676[D loss: 0.445010, acc: 62.50%, op_acc: 29.69%] [G loss: 1.017580]\n",
      "epoch:5 step:4677[D loss: 0.439865, acc: 66.41%, op_acc: 36.72%] [G loss: 1.007690]\n",
      "epoch:5 step:4678[D loss: 0.442859, acc: 66.41%, op_acc: 32.81%] [G loss: 0.897721]\n",
      "epoch:5 step:4679[D loss: 0.388240, acc: 68.75%, op_acc: 36.72%] [G loss: 0.958324]\n",
      "epoch:5 step:4680[D loss: 0.450446, acc: 66.41%, op_acc: 30.47%] [G loss: 0.970689]\n",
      "epoch:5 step:4681[D loss: 0.451886, acc: 56.25%, op_acc: 28.91%] [G loss: 0.941953]\n",
      "epoch:5 step:4682[D loss: 0.470527, acc: 57.81%, op_acc: 32.03%] [G loss: 1.066256]\n",
      "epoch:5 step:4683[D loss: 0.411895, acc: 63.28%, op_acc: 40.62%] [G loss: 0.985599]\n",
      "epoch:5 step:4684[D loss: 0.449408, acc: 56.25%, op_acc: 36.72%] [G loss: 0.943336]\n",
      "epoch:5 step:4685[D loss: 0.441856, acc: 57.03%, op_acc: 31.25%] [G loss: 0.977916]\n",
      "epoch:5 step:4686[D loss: 0.466936, acc: 57.03%, op_acc: 36.72%] [G loss: 0.800506]\n",
      "epoch:6 step:4687[D loss: 0.439642, acc: 59.38%, op_acc: 37.50%] [G loss: 0.903414]\n",
      "epoch:6 step:4688[D loss: 0.425902, acc: 64.84%, op_acc: 42.19%] [G loss: 0.958159]\n",
      "epoch:6 step:4689[D loss: 0.483379, acc: 57.81%, op_acc: 34.38%] [G loss: 0.944420]\n",
      "epoch:6 step:4690[D loss: 0.413281, acc: 65.62%, op_acc: 42.97%] [G loss: 0.976045]\n",
      "epoch:6 step:4691[D loss: 0.456509, acc: 53.91%, op_acc: 36.72%] [G loss: 0.955653]\n",
      "epoch:6 step:4692[D loss: 0.474014, acc: 58.59%, op_acc: 33.59%] [G loss: 0.896591]\n",
      "epoch:6 step:4693[D loss: 0.475382, acc: 51.56%, op_acc: 34.38%] [G loss: 0.931189]\n",
      "epoch:6 step:4694[D loss: 0.473830, acc: 51.56%, op_acc: 30.47%] [G loss: 0.923549]\n",
      "epoch:6 step:4695[D loss: 0.435444, acc: 60.16%, op_acc: 36.72%] [G loss: 0.938852]\n",
      "epoch:6 step:4696[D loss: 0.423858, acc: 67.97%, op_acc: 35.16%] [G loss: 0.970326]\n",
      "epoch:6 step:4697[D loss: 0.455829, acc: 60.16%, op_acc: 32.03%] [G loss: 0.871787]\n",
      "epoch:6 step:4698[D loss: 0.448039, acc: 58.59%, op_acc: 33.59%] [G loss: 0.972451]\n",
      "epoch:6 step:4699[D loss: 0.449711, acc: 62.50%, op_acc: 35.16%] [G loss: 0.931780]\n",
      "epoch:6 step:4700[D loss: 0.445081, acc: 60.16%, op_acc: 29.69%] [G loss: 0.905424]\n",
      "epoch:6 step:4701[D loss: 0.456047, acc: 58.59%, op_acc: 30.47%] [G loss: 0.925171]\n",
      "epoch:6 step:4702[D loss: 0.451445, acc: 53.91%, op_acc: 33.59%] [G loss: 1.010182]\n",
      "epoch:6 step:4703[D loss: 0.448053, acc: 59.38%, op_acc: 31.25%] [G loss: 0.885665]\n",
      "epoch:6 step:4704[D loss: 0.390133, acc: 71.09%, op_acc: 38.28%] [G loss: 0.914572]\n",
      "epoch:6 step:4705[D loss: 0.432328, acc: 59.38%, op_acc: 38.28%] [G loss: 0.895836]\n",
      "epoch:6 step:4706[D loss: 0.420913, acc: 59.38%, op_acc: 35.16%] [G loss: 1.071119]\n",
      "epoch:6 step:4707[D loss: 0.476903, acc: 57.03%, op_acc: 28.91%] [G loss: 0.922858]\n",
      "epoch:6 step:4708[D loss: 0.451128, acc: 60.16%, op_acc: 34.38%] [G loss: 1.014799]\n",
      "epoch:6 step:4709[D loss: 0.476558, acc: 47.66%, op_acc: 32.03%] [G loss: 0.914444]\n",
      "epoch:6 step:4710[D loss: 0.482026, acc: 58.59%, op_acc: 32.81%] [G loss: 0.979549]\n",
      "epoch:6 step:4711[D loss: 0.469326, acc: 51.56%, op_acc: 34.38%] [G loss: 1.015736]\n",
      "epoch:6 step:4712[D loss: 0.411534, acc: 68.75%, op_acc: 32.81%] [G loss: 1.097872]\n",
      "epoch:6 step:4713[D loss: 0.488069, acc: 53.12%, op_acc: 29.69%] [G loss: 0.885779]\n",
      "epoch:6 step:4714[D loss: 0.447071, acc: 55.47%, op_acc: 35.94%] [G loss: 0.875828]\n",
      "epoch:6 step:4715[D loss: 0.425067, acc: 62.50%, op_acc: 34.38%] [G loss: 0.949290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4716[D loss: 0.402920, acc: 64.84%, op_acc: 37.50%] [G loss: 0.974778]\n",
      "epoch:6 step:4717[D loss: 0.469705, acc: 56.25%, op_acc: 31.25%] [G loss: 0.903614]\n",
      "epoch:6 step:4718[D loss: 0.480862, acc: 53.91%, op_acc: 27.34%] [G loss: 0.922968]\n",
      "epoch:6 step:4719[D loss: 0.455437, acc: 57.03%, op_acc: 32.81%] [G loss: 0.946174]\n",
      "epoch:6 step:4720[D loss: 0.451759, acc: 55.47%, op_acc: 32.03%] [G loss: 0.877943]\n",
      "epoch:6 step:4721[D loss: 0.444528, acc: 62.50%, op_acc: 32.81%] [G loss: 0.912966]\n",
      "epoch:6 step:4722[D loss: 0.431229, acc: 67.19%, op_acc: 37.50%] [G loss: 1.004201]\n",
      "epoch:6 step:4723[D loss: 0.450672, acc: 58.59%, op_acc: 32.81%] [G loss: 0.880919]\n",
      "epoch:6 step:4724[D loss: 0.462020, acc: 57.81%, op_acc: 33.59%] [G loss: 0.930685]\n",
      "epoch:6 step:4725[D loss: 0.453068, acc: 53.91%, op_acc: 37.50%] [G loss: 0.967526]\n",
      "epoch:6 step:4726[D loss: 0.470061, acc: 55.47%, op_acc: 26.56%] [G loss: 0.909224]\n",
      "epoch:6 step:4727[D loss: 0.444198, acc: 56.25%, op_acc: 34.38%] [G loss: 0.851626]\n",
      "epoch:6 step:4728[D loss: 0.439701, acc: 62.50%, op_acc: 35.16%] [G loss: 0.961356]\n",
      "epoch:6 step:4729[D loss: 0.512884, acc: 51.56%, op_acc: 28.12%] [G loss: 0.803430]\n",
      "epoch:6 step:4730[D loss: 0.450871, acc: 62.50%, op_acc: 32.81%] [G loss: 0.951689]\n",
      "epoch:6 step:4731[D loss: 0.406988, acc: 70.31%, op_acc: 35.16%] [G loss: 1.020083]\n",
      "epoch:6 step:4732[D loss: 0.438201, acc: 69.53%, op_acc: 33.59%] [G loss: 0.962653]\n",
      "epoch:6 step:4733[D loss: 0.436126, acc: 65.62%, op_acc: 31.25%] [G loss: 0.878976]\n",
      "epoch:6 step:4734[D loss: 0.463533, acc: 59.38%, op_acc: 28.12%] [G loss: 0.996194]\n",
      "epoch:6 step:4735[D loss: 0.407886, acc: 68.75%, op_acc: 40.62%] [G loss: 1.013866]\n",
      "epoch:6 step:4736[D loss: 0.461192, acc: 60.16%, op_acc: 33.59%] [G loss: 1.000563]\n",
      "epoch:6 step:4737[D loss: 0.443166, acc: 61.72%, op_acc: 35.16%] [G loss: 0.985784]\n",
      "epoch:6 step:4738[D loss: 0.453078, acc: 57.03%, op_acc: 35.16%] [G loss: 0.934921]\n",
      "epoch:6 step:4739[D loss: 0.475247, acc: 54.69%, op_acc: 25.00%] [G loss: 0.904961]\n",
      "epoch:6 step:4740[D loss: 0.492958, acc: 53.12%, op_acc: 33.59%] [G loss: 0.952441]\n",
      "epoch:6 step:4741[D loss: 0.468304, acc: 52.34%, op_acc: 36.72%] [G loss: 0.961176]\n",
      "epoch:6 step:4742[D loss: 0.442465, acc: 60.16%, op_acc: 31.25%] [G loss: 0.878256]\n",
      "epoch:6 step:4743[D loss: 0.456366, acc: 59.38%, op_acc: 30.47%] [G loss: 0.978335]\n",
      "epoch:6 step:4744[D loss: 0.437031, acc: 58.59%, op_acc: 41.41%] [G loss: 0.927755]\n",
      "epoch:6 step:4745[D loss: 0.409353, acc: 67.19%, op_acc: 35.94%] [G loss: 0.967432]\n",
      "epoch:6 step:4746[D loss: 0.412741, acc: 70.31%, op_acc: 32.03%] [G loss: 0.949877]\n",
      "epoch:6 step:4747[D loss: 0.458650, acc: 53.12%, op_acc: 32.81%] [G loss: 0.886378]\n",
      "epoch:6 step:4748[D loss: 0.471029, acc: 57.81%, op_acc: 28.91%] [G loss: 0.917683]\n",
      "epoch:6 step:4749[D loss: 0.467816, acc: 58.59%, op_acc: 35.16%] [G loss: 0.953633]\n",
      "epoch:6 step:4750[D loss: 0.438467, acc: 65.62%, op_acc: 30.47%] [G loss: 1.002312]\n",
      "epoch:6 step:4751[D loss: 0.469601, acc: 55.47%, op_acc: 27.34%] [G loss: 0.935723]\n",
      "epoch:6 step:4752[D loss: 0.452705, acc: 59.38%, op_acc: 33.59%] [G loss: 0.968950]\n",
      "epoch:6 step:4753[D loss: 0.438029, acc: 67.19%, op_acc: 35.94%] [G loss: 0.945486]\n",
      "epoch:6 step:4754[D loss: 0.448698, acc: 52.34%, op_acc: 26.56%] [G loss: 0.976248]\n",
      "epoch:6 step:4755[D loss: 0.414305, acc: 65.62%, op_acc: 37.50%] [G loss: 0.949168]\n",
      "epoch:6 step:4756[D loss: 0.454354, acc: 54.69%, op_acc: 32.81%] [G loss: 0.856953]\n",
      "epoch:6 step:4757[D loss: 0.477376, acc: 61.72%, op_acc: 27.34%] [G loss: 0.885621]\n",
      "epoch:6 step:4758[D loss: 0.441789, acc: 60.16%, op_acc: 32.03%] [G loss: 0.922340]\n",
      "epoch:6 step:4759[D loss: 0.454648, acc: 54.69%, op_acc: 33.59%] [G loss: 0.884547]\n",
      "epoch:6 step:4760[D loss: 0.429517, acc: 58.59%, op_acc: 42.97%] [G loss: 0.893988]\n",
      "epoch:6 step:4761[D loss: 0.466922, acc: 58.59%, op_acc: 31.25%] [G loss: 0.849157]\n",
      "epoch:6 step:4762[D loss: 0.475693, acc: 55.47%, op_acc: 34.38%] [G loss: 1.008686]\n",
      "epoch:6 step:4763[D loss: 0.427141, acc: 62.50%, op_acc: 35.16%] [G loss: 0.877308]\n",
      "epoch:6 step:4764[D loss: 0.472720, acc: 57.81%, op_acc: 24.22%] [G loss: 0.949514]\n",
      "epoch:6 step:4765[D loss: 0.457763, acc: 60.16%, op_acc: 31.25%] [G loss: 0.982826]\n",
      "epoch:6 step:4766[D loss: 0.453152, acc: 66.41%, op_acc: 27.34%] [G loss: 0.861385]\n",
      "epoch:6 step:4767[D loss: 0.471595, acc: 60.16%, op_acc: 28.91%] [G loss: 0.881641]\n",
      "epoch:6 step:4768[D loss: 0.435153, acc: 67.19%, op_acc: 32.03%] [G loss: 0.895906]\n",
      "epoch:6 step:4769[D loss: 0.444587, acc: 60.16%, op_acc: 35.16%] [G loss: 0.923856]\n",
      "epoch:6 step:4770[D loss: 0.440993, acc: 62.50%, op_acc: 39.84%] [G loss: 0.980742]\n",
      "epoch:6 step:4771[D loss: 0.467040, acc: 57.81%, op_acc: 32.03%] [G loss: 0.965794]\n",
      "epoch:6 step:4772[D loss: 0.418297, acc: 64.84%, op_acc: 33.59%] [G loss: 0.875796]\n",
      "epoch:6 step:4773[D loss: 0.449159, acc: 59.38%, op_acc: 27.34%] [G loss: 0.890042]\n",
      "epoch:6 step:4774[D loss: 0.436402, acc: 60.16%, op_acc: 35.94%] [G loss: 0.891699]\n",
      "epoch:6 step:4775[D loss: 0.438838, acc: 64.06%, op_acc: 34.38%] [G loss: 0.898226]\n",
      "epoch:6 step:4776[D loss: 0.407423, acc: 66.41%, op_acc: 37.50%] [G loss: 0.954789]\n",
      "epoch:6 step:4777[D loss: 0.454234, acc: 57.81%, op_acc: 30.47%] [G loss: 0.910816]\n",
      "epoch:6 step:4778[D loss: 0.449018, acc: 54.69%, op_acc: 28.12%] [G loss: 0.877022]\n",
      "epoch:6 step:4779[D loss: 0.428392, acc: 60.16%, op_acc: 35.94%] [G loss: 1.038373]\n",
      "epoch:6 step:4780[D loss: 0.433267, acc: 63.28%, op_acc: 34.38%] [G loss: 0.958741]\n",
      "epoch:6 step:4781[D loss: 0.447697, acc: 60.94%, op_acc: 31.25%] [G loss: 0.889076]\n",
      "epoch:6 step:4782[D loss: 0.467394, acc: 54.69%, op_acc: 29.69%] [G loss: 1.083966]\n",
      "epoch:6 step:4783[D loss: 0.450494, acc: 50.00%, op_acc: 37.50%] [G loss: 0.848312]\n",
      "epoch:6 step:4784[D loss: 0.449175, acc: 65.62%, op_acc: 23.44%] [G loss: 0.920479]\n",
      "epoch:6 step:4785[D loss: 0.450155, acc: 57.03%, op_acc: 33.59%] [G loss: 0.969132]\n",
      "epoch:6 step:4786[D loss: 0.438439, acc: 60.94%, op_acc: 34.38%] [G loss: 0.972209]\n",
      "epoch:6 step:4787[D loss: 0.448676, acc: 60.94%, op_acc: 33.59%] [G loss: 0.958574]\n",
      "epoch:6 step:4788[D loss: 0.424706, acc: 66.41%, op_acc: 37.50%] [G loss: 1.018802]\n",
      "epoch:6 step:4789[D loss: 0.494545, acc: 52.34%, op_acc: 27.34%] [G loss: 0.873776]\n",
      "epoch:6 step:4790[D loss: 0.453385, acc: 65.62%, op_acc: 30.47%] [G loss: 0.886007]\n",
      "epoch:6 step:4791[D loss: 0.430479, acc: 66.41%, op_acc: 36.72%] [G loss: 0.945708]\n",
      "epoch:6 step:4792[D loss: 0.403785, acc: 71.09%, op_acc: 41.41%] [G loss: 0.818384]\n",
      "epoch:6 step:4793[D loss: 0.471613, acc: 53.91%, op_acc: 32.81%] [G loss: 0.979643]\n",
      "epoch:6 step:4794[D loss: 0.478785, acc: 60.94%, op_acc: 31.25%] [G loss: 0.988338]\n",
      "epoch:6 step:4795[D loss: 0.443045, acc: 62.50%, op_acc: 31.25%] [G loss: 0.867030]\n",
      "epoch:6 step:4796[D loss: 0.440554, acc: 51.56%, op_acc: 35.94%] [G loss: 0.834345]\n",
      "epoch:6 step:4797[D loss: 0.448180, acc: 57.03%, op_acc: 31.25%] [G loss: 0.858358]\n",
      "epoch:6 step:4798[D loss: 0.420197, acc: 64.84%, op_acc: 34.38%] [G loss: 0.986337]\n",
      "epoch:6 step:4799[D loss: 0.446441, acc: 57.03%, op_acc: 28.91%] [G loss: 0.863225]\n",
      "epoch:6 step:4800[D loss: 0.418993, acc: 64.06%, op_acc: 36.72%] [G loss: 0.945183]\n",
      "epoch:6 step:4801[D loss: 0.416302, acc: 64.06%, op_acc: 39.06%] [G loss: 0.943437]\n",
      "epoch:6 step:4802[D loss: 0.468803, acc: 55.47%, op_acc: 31.25%] [G loss: 0.988043]\n",
      "epoch:6 step:4803[D loss: 0.437215, acc: 60.94%, op_acc: 30.47%] [G loss: 0.925079]\n",
      "epoch:6 step:4804[D loss: 0.424778, acc: 63.28%, op_acc: 33.59%] [G loss: 0.905939]\n",
      "epoch:6 step:4805[D loss: 0.449918, acc: 63.28%, op_acc: 32.03%] [G loss: 0.865542]\n",
      "epoch:6 step:4806[D loss: 0.460966, acc: 57.03%, op_acc: 28.91%] [G loss: 0.871106]\n",
      "epoch:6 step:4807[D loss: 0.455548, acc: 62.50%, op_acc: 32.03%] [G loss: 0.934547]\n",
      "epoch:6 step:4808[D loss: 0.441660, acc: 60.94%, op_acc: 29.69%] [G loss: 0.993315]\n",
      "epoch:6 step:4809[D loss: 0.471528, acc: 53.12%, op_acc: 35.94%] [G loss: 0.938615]\n",
      "epoch:6 step:4810[D loss: 0.420549, acc: 66.41%, op_acc: 35.16%] [G loss: 0.925940]\n",
      "epoch:6 step:4811[D loss: 0.476989, acc: 62.50%, op_acc: 27.34%] [G loss: 0.898874]\n",
      "epoch:6 step:4812[D loss: 0.420330, acc: 62.50%, op_acc: 35.94%] [G loss: 0.970781]\n",
      "epoch:6 step:4813[D loss: 0.448495, acc: 59.38%, op_acc: 28.12%] [G loss: 0.829557]\n",
      "epoch:6 step:4814[D loss: 0.412779, acc: 66.41%, op_acc: 39.06%] [G loss: 0.948961]\n",
      "epoch:6 step:4815[D loss: 0.484206, acc: 53.12%, op_acc: 25.78%] [G loss: 0.930082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4816[D loss: 0.411689, acc: 62.50%, op_acc: 36.72%] [G loss: 0.909169]\n",
      "epoch:6 step:4817[D loss: 0.430070, acc: 59.38%, op_acc: 28.91%] [G loss: 0.969787]\n",
      "epoch:6 step:4818[D loss: 0.442170, acc: 60.16%, op_acc: 41.41%] [G loss: 0.924888]\n",
      "epoch:6 step:4819[D loss: 0.433450, acc: 67.97%, op_acc: 32.81%] [G loss: 0.942331]\n",
      "epoch:6 step:4820[D loss: 0.450753, acc: 57.81%, op_acc: 34.38%] [G loss: 0.968376]\n",
      "epoch:6 step:4821[D loss: 0.457898, acc: 61.72%, op_acc: 36.72%] [G loss: 1.024149]\n",
      "epoch:6 step:4822[D loss: 0.419518, acc: 67.97%, op_acc: 32.81%] [G loss: 0.964285]\n",
      "epoch:6 step:4823[D loss: 0.450140, acc: 64.06%, op_acc: 34.38%] [G loss: 0.907057]\n",
      "epoch:6 step:4824[D loss: 0.436547, acc: 62.50%, op_acc: 26.56%] [G loss: 1.000254]\n",
      "epoch:6 step:4825[D loss: 0.440518, acc: 61.72%, op_acc: 33.59%] [G loss: 0.968381]\n",
      "epoch:6 step:4826[D loss: 0.495225, acc: 52.34%, op_acc: 32.81%] [G loss: 0.905282]\n",
      "epoch:6 step:4827[D loss: 0.461375, acc: 60.16%, op_acc: 30.47%] [G loss: 0.867610]\n",
      "epoch:6 step:4828[D loss: 0.413937, acc: 68.75%, op_acc: 34.38%] [G loss: 0.901357]\n",
      "epoch:6 step:4829[D loss: 0.450946, acc: 59.38%, op_acc: 33.59%] [G loss: 0.906052]\n",
      "epoch:6 step:4830[D loss: 0.454307, acc: 63.28%, op_acc: 32.03%] [G loss: 0.932716]\n",
      "epoch:6 step:4831[D loss: 0.464919, acc: 57.03%, op_acc: 36.72%] [G loss: 0.914627]\n",
      "epoch:6 step:4832[D loss: 0.449340, acc: 53.91%, op_acc: 40.62%] [G loss: 0.844805]\n",
      "epoch:6 step:4833[D loss: 0.444219, acc: 64.06%, op_acc: 35.16%] [G loss: 0.888583]\n",
      "epoch:6 step:4834[D loss: 0.466895, acc: 60.94%, op_acc: 31.25%] [G loss: 0.975777]\n",
      "epoch:6 step:4835[D loss: 0.466235, acc: 52.34%, op_acc: 36.72%] [G loss: 0.934334]\n",
      "epoch:6 step:4836[D loss: 0.458616, acc: 56.25%, op_acc: 34.38%] [G loss: 0.971513]\n",
      "epoch:6 step:4837[D loss: 0.431254, acc: 64.06%, op_acc: 28.91%] [G loss: 0.996181]\n",
      "epoch:6 step:4838[D loss: 0.420787, acc: 66.41%, op_acc: 37.50%] [G loss: 0.997181]\n",
      "epoch:6 step:4839[D loss: 0.430166, acc: 62.50%, op_acc: 39.06%] [G loss: 1.008837]\n",
      "epoch:6 step:4840[D loss: 0.438153, acc: 58.59%, op_acc: 32.81%] [G loss: 0.892379]\n",
      "epoch:6 step:4841[D loss: 0.443164, acc: 60.16%, op_acc: 32.81%] [G loss: 0.900484]\n",
      "epoch:6 step:4842[D loss: 0.430646, acc: 64.06%, op_acc: 35.94%] [G loss: 0.905938]\n",
      "epoch:6 step:4843[D loss: 0.445147, acc: 53.12%, op_acc: 31.25%] [G loss: 0.908371]\n",
      "epoch:6 step:4844[D loss: 0.446732, acc: 58.59%, op_acc: 32.03%] [G loss: 0.879770]\n",
      "epoch:6 step:4845[D loss: 0.444073, acc: 60.94%, op_acc: 35.94%] [G loss: 0.904041]\n",
      "epoch:6 step:4846[D loss: 0.468344, acc: 59.38%, op_acc: 29.69%] [G loss: 0.992514]\n",
      "epoch:6 step:4847[D loss: 0.457185, acc: 58.59%, op_acc: 32.81%] [G loss: 0.933046]\n",
      "epoch:6 step:4848[D loss: 0.426629, acc: 64.84%, op_acc: 37.50%] [G loss: 0.952427]\n",
      "epoch:6 step:4849[D loss: 0.443677, acc: 64.84%, op_acc: 35.16%] [G loss: 0.998926]\n",
      "epoch:6 step:4850[D loss: 0.470403, acc: 60.94%, op_acc: 30.47%] [G loss: 0.954709]\n",
      "epoch:6 step:4851[D loss: 0.425010, acc: 64.84%, op_acc: 32.81%] [G loss: 0.995544]\n",
      "epoch:6 step:4852[D loss: 0.468141, acc: 58.59%, op_acc: 30.47%] [G loss: 0.885413]\n",
      "epoch:6 step:4853[D loss: 0.468993, acc: 55.47%, op_acc: 32.03%] [G loss: 0.954061]\n",
      "epoch:6 step:4854[D loss: 0.424350, acc: 66.41%, op_acc: 39.84%] [G loss: 0.873723]\n",
      "epoch:6 step:4855[D loss: 0.409953, acc: 67.19%, op_acc: 37.50%] [G loss: 0.919116]\n",
      "epoch:6 step:4856[D loss: 0.404592, acc: 66.41%, op_acc: 32.81%] [G loss: 0.933178]\n",
      "epoch:6 step:4857[D loss: 0.428893, acc: 62.50%, op_acc: 30.47%] [G loss: 0.910285]\n",
      "epoch:6 step:4858[D loss: 0.439949, acc: 57.81%, op_acc: 37.50%] [G loss: 0.915561]\n",
      "epoch:6 step:4859[D loss: 0.439705, acc: 62.50%, op_acc: 33.59%] [G loss: 0.911161]\n",
      "epoch:6 step:4860[D loss: 0.485587, acc: 52.34%, op_acc: 28.91%] [G loss: 0.905327]\n",
      "epoch:6 step:4861[D loss: 0.435783, acc: 58.59%, op_acc: 31.25%] [G loss: 0.934003]\n",
      "epoch:6 step:4862[D loss: 0.462138, acc: 57.03%, op_acc: 34.38%] [G loss: 0.886237]\n",
      "epoch:6 step:4863[D loss: 0.451609, acc: 53.91%, op_acc: 30.47%] [G loss: 0.913894]\n",
      "epoch:6 step:4864[D loss: 0.449787, acc: 61.72%, op_acc: 33.59%] [G loss: 0.947605]\n",
      "epoch:6 step:4865[D loss: 0.422824, acc: 58.59%, op_acc: 42.19%] [G loss: 0.953887]\n",
      "epoch:6 step:4866[D loss: 0.477515, acc: 57.03%, op_acc: 30.47%] [G loss: 0.859159]\n",
      "epoch:6 step:4867[D loss: 0.414366, acc: 63.28%, op_acc: 34.38%] [G loss: 0.926794]\n",
      "epoch:6 step:4868[D loss: 0.426142, acc: 62.50%, op_acc: 31.25%] [G loss: 0.936571]\n",
      "epoch:6 step:4869[D loss: 0.432888, acc: 66.41%, op_acc: 35.94%] [G loss: 0.960410]\n",
      "epoch:6 step:4870[D loss: 0.437282, acc: 60.16%, op_acc: 31.25%] [G loss: 1.012665]\n",
      "epoch:6 step:4871[D loss: 0.464010, acc: 54.69%, op_acc: 33.59%] [G loss: 0.971606]\n",
      "epoch:6 step:4872[D loss: 0.448300, acc: 58.59%, op_acc: 32.03%] [G loss: 0.887983]\n",
      "epoch:6 step:4873[D loss: 0.441389, acc: 62.50%, op_acc: 33.59%] [G loss: 0.978947]\n",
      "epoch:6 step:4874[D loss: 0.406826, acc: 71.88%, op_acc: 39.84%] [G loss: 1.112623]\n",
      "epoch:6 step:4875[D loss: 0.422268, acc: 64.06%, op_acc: 33.59%] [G loss: 0.922017]\n",
      "epoch:6 step:4876[D loss: 0.452246, acc: 57.81%, op_acc: 29.69%] [G loss: 1.001185]\n",
      "epoch:6 step:4877[D loss: 0.428437, acc: 57.81%, op_acc: 32.81%] [G loss: 0.929093]\n",
      "epoch:6 step:4878[D loss: 0.454896, acc: 59.38%, op_acc: 28.91%] [G loss: 0.881825]\n",
      "epoch:6 step:4879[D loss: 0.508245, acc: 50.00%, op_acc: 28.91%] [G loss: 0.911399]\n",
      "epoch:6 step:4880[D loss: 0.426080, acc: 67.19%, op_acc: 37.50%] [G loss: 0.924733]\n",
      "epoch:6 step:4881[D loss: 0.427633, acc: 66.41%, op_acc: 35.16%] [G loss: 0.895095]\n",
      "epoch:6 step:4882[D loss: 0.436537, acc: 67.97%, op_acc: 32.03%] [G loss: 0.965552]\n",
      "epoch:6 step:4883[D loss: 0.442640, acc: 61.72%, op_acc: 30.47%] [G loss: 0.930945]\n",
      "epoch:6 step:4884[D loss: 0.458739, acc: 57.81%, op_acc: 32.81%] [G loss: 0.919297]\n",
      "epoch:6 step:4885[D loss: 0.461892, acc: 57.03%, op_acc: 31.25%] [G loss: 0.876384]\n",
      "epoch:6 step:4886[D loss: 0.454483, acc: 64.06%, op_acc: 32.03%] [G loss: 0.878477]\n",
      "epoch:6 step:4887[D loss: 0.424577, acc: 62.50%, op_acc: 36.72%] [G loss: 0.902708]\n",
      "epoch:6 step:4888[D loss: 0.441752, acc: 64.06%, op_acc: 29.69%] [G loss: 0.875155]\n",
      "epoch:6 step:4889[D loss: 0.456989, acc: 66.41%, op_acc: 27.34%] [G loss: 0.923982]\n",
      "epoch:6 step:4890[D loss: 0.450611, acc: 61.72%, op_acc: 33.59%] [G loss: 0.852248]\n",
      "epoch:6 step:4891[D loss: 0.484171, acc: 53.12%, op_acc: 25.78%] [G loss: 0.758351]\n",
      "epoch:6 step:4892[D loss: 0.439255, acc: 67.97%, op_acc: 34.38%] [G loss: 0.904740]\n",
      "epoch:6 step:4893[D loss: 0.430786, acc: 54.69%, op_acc: 32.81%] [G loss: 0.916029]\n",
      "epoch:6 step:4894[D loss: 0.471597, acc: 59.38%, op_acc: 31.25%] [G loss: 1.005440]\n",
      "epoch:6 step:4895[D loss: 0.448450, acc: 57.03%, op_acc: 32.03%] [G loss: 0.998981]\n",
      "epoch:6 step:4896[D loss: 0.461952, acc: 61.72%, op_acc: 30.47%] [G loss: 1.009016]\n",
      "epoch:6 step:4897[D loss: 0.436764, acc: 64.84%, op_acc: 31.25%] [G loss: 0.966347]\n",
      "epoch:6 step:4898[D loss: 0.455729, acc: 57.81%, op_acc: 32.81%] [G loss: 1.051250]\n",
      "epoch:6 step:4899[D loss: 0.463675, acc: 53.91%, op_acc: 32.81%] [G loss: 0.922601]\n",
      "epoch:6 step:4900[D loss: 0.482603, acc: 53.91%, op_acc: 32.03%] [G loss: 0.956653]\n",
      "epoch:6 step:4901[D loss: 0.484251, acc: 53.12%, op_acc: 29.69%] [G loss: 0.920326]\n",
      "epoch:6 step:4902[D loss: 0.462639, acc: 60.94%, op_acc: 30.47%] [G loss: 0.949417]\n",
      "epoch:6 step:4903[D loss: 0.410198, acc: 64.06%, op_acc: 39.06%] [G loss: 0.948435]\n",
      "epoch:6 step:4904[D loss: 0.425326, acc: 60.16%, op_acc: 36.72%] [G loss: 0.911707]\n",
      "epoch:6 step:4905[D loss: 0.429935, acc: 64.06%, op_acc: 32.03%] [G loss: 0.967289]\n",
      "epoch:6 step:4906[D loss: 0.462158, acc: 55.47%, op_acc: 25.78%] [G loss: 0.960514]\n",
      "epoch:6 step:4907[D loss: 0.468882, acc: 58.59%, op_acc: 33.59%] [G loss: 0.895749]\n",
      "epoch:6 step:4908[D loss: 0.432405, acc: 65.62%, op_acc: 34.38%] [G loss: 0.905826]\n",
      "epoch:6 step:4909[D loss: 0.421349, acc: 64.06%, op_acc: 37.50%] [G loss: 0.884615]\n",
      "epoch:6 step:4910[D loss: 0.481895, acc: 59.38%, op_acc: 29.69%] [G loss: 1.025913]\n",
      "epoch:6 step:4911[D loss: 0.466410, acc: 57.03%, op_acc: 28.91%] [G loss: 0.894642]\n",
      "epoch:6 step:4912[D loss: 0.412513, acc: 67.97%, op_acc: 32.03%] [G loss: 0.949615]\n",
      "epoch:6 step:4913[D loss: 0.429137, acc: 64.84%, op_acc: 34.38%] [G loss: 0.977507]\n",
      "epoch:6 step:4914[D loss: 0.456220, acc: 54.69%, op_acc: 38.28%] [G loss: 0.977316]\n",
      "epoch:6 step:4915[D loss: 0.451455, acc: 57.81%, op_acc: 35.16%] [G loss: 0.937035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:4916[D loss: 0.437365, acc: 62.50%, op_acc: 36.72%] [G loss: 0.880939]\n",
      "epoch:6 step:4917[D loss: 0.409016, acc: 61.72%, op_acc: 37.50%] [G loss: 0.908347]\n",
      "epoch:6 step:4918[D loss: 0.462129, acc: 55.47%, op_acc: 29.69%] [G loss: 0.846846]\n",
      "epoch:6 step:4919[D loss: 0.439199, acc: 64.06%, op_acc: 28.91%] [G loss: 0.905290]\n",
      "epoch:6 step:4920[D loss: 0.459936, acc: 57.03%, op_acc: 32.03%] [G loss: 1.000393]\n",
      "epoch:6 step:4921[D loss: 0.450308, acc: 61.72%, op_acc: 35.94%] [G loss: 1.012062]\n",
      "epoch:6 step:4922[D loss: 0.461565, acc: 57.03%, op_acc: 34.38%] [G loss: 0.984759]\n",
      "epoch:6 step:4923[D loss: 0.432408, acc: 60.16%, op_acc: 33.59%] [G loss: 0.939151]\n",
      "epoch:6 step:4924[D loss: 0.471461, acc: 55.47%, op_acc: 30.47%] [G loss: 0.927344]\n",
      "epoch:6 step:4925[D loss: 0.447651, acc: 57.81%, op_acc: 36.72%] [G loss: 0.961548]\n",
      "epoch:6 step:4926[D loss: 0.414917, acc: 64.84%, op_acc: 33.59%] [G loss: 0.933875]\n",
      "epoch:6 step:4927[D loss: 0.435212, acc: 64.84%, op_acc: 32.03%] [G loss: 0.900490]\n",
      "epoch:6 step:4928[D loss: 0.432275, acc: 60.16%, op_acc: 40.62%] [G loss: 0.961476]\n",
      "epoch:6 step:4929[D loss: 0.436964, acc: 62.50%, op_acc: 37.50%] [G loss: 0.955649]\n",
      "epoch:6 step:4930[D loss: 0.471747, acc: 53.91%, op_acc: 29.69%] [G loss: 0.921786]\n",
      "epoch:6 step:4931[D loss: 0.462455, acc: 48.44%, op_acc: 34.38%] [G loss: 0.898064]\n",
      "epoch:6 step:4932[D loss: 0.448284, acc: 62.50%, op_acc: 34.38%] [G loss: 0.910679]\n",
      "epoch:6 step:4933[D loss: 0.439236, acc: 58.59%, op_acc: 30.47%] [G loss: 0.978738]\n",
      "epoch:6 step:4934[D loss: 0.445905, acc: 65.62%, op_acc: 31.25%] [G loss: 0.868907]\n",
      "epoch:6 step:4935[D loss: 0.459050, acc: 63.28%, op_acc: 28.12%] [G loss: 0.918229]\n",
      "epoch:6 step:4936[D loss: 0.469043, acc: 55.47%, op_acc: 31.25%] [G loss: 0.842042]\n",
      "epoch:6 step:4937[D loss: 0.465389, acc: 57.81%, op_acc: 32.03%] [G loss: 1.011546]\n",
      "epoch:6 step:4938[D loss: 0.431006, acc: 64.06%, op_acc: 35.94%] [G loss: 0.944860]\n",
      "epoch:6 step:4939[D loss: 0.463941, acc: 61.72%, op_acc: 32.03%] [G loss: 1.028806]\n",
      "epoch:6 step:4940[D loss: 0.422252, acc: 71.88%, op_acc: 26.56%] [G loss: 1.089179]\n",
      "epoch:6 step:4941[D loss: 0.463676, acc: 57.81%, op_acc: 32.81%] [G loss: 0.969194]\n",
      "epoch:6 step:4942[D loss: 0.427111, acc: 58.59%, op_acc: 32.81%] [G loss: 0.946399]\n",
      "epoch:6 step:4943[D loss: 0.487112, acc: 57.03%, op_acc: 25.78%] [G loss: 0.829623]\n",
      "epoch:6 step:4944[D loss: 0.437616, acc: 60.94%, op_acc: 35.16%] [G loss: 0.907117]\n",
      "epoch:6 step:4945[D loss: 0.432725, acc: 67.19%, op_acc: 33.59%] [G loss: 0.925777]\n",
      "epoch:6 step:4946[D loss: 0.455825, acc: 65.62%, op_acc: 35.16%] [G loss: 0.952903]\n",
      "epoch:6 step:4947[D loss: 0.404801, acc: 67.97%, op_acc: 35.16%] [G loss: 0.953866]\n",
      "epoch:6 step:4948[D loss: 0.403650, acc: 65.62%, op_acc: 34.38%] [G loss: 1.015555]\n",
      "epoch:6 step:4949[D loss: 0.394755, acc: 71.88%, op_acc: 42.19%] [G loss: 0.950433]\n",
      "epoch:6 step:4950[D loss: 0.428325, acc: 64.06%, op_acc: 28.91%] [G loss: 0.890660]\n",
      "epoch:6 step:4951[D loss: 0.407429, acc: 64.84%, op_acc: 36.72%] [G loss: 0.972983]\n",
      "epoch:6 step:4952[D loss: 0.432819, acc: 64.06%, op_acc: 35.16%] [G loss: 1.000195]\n",
      "epoch:6 step:4953[D loss: 0.463100, acc: 56.25%, op_acc: 31.25%] [G loss: 0.898394]\n",
      "epoch:6 step:4954[D loss: 0.433924, acc: 59.38%, op_acc: 32.81%] [G loss: 0.873412]\n",
      "epoch:6 step:4955[D loss: 0.435670, acc: 60.16%, op_acc: 33.59%] [G loss: 0.906346]\n",
      "epoch:6 step:4956[D loss: 0.419149, acc: 69.53%, op_acc: 32.81%] [G loss: 0.930249]\n",
      "epoch:6 step:4957[D loss: 0.457977, acc: 58.59%, op_acc: 38.28%] [G loss: 0.975796]\n",
      "epoch:6 step:4958[D loss: 0.432571, acc: 61.72%, op_acc: 39.06%] [G loss: 0.934637]\n",
      "epoch:6 step:4959[D loss: 0.431799, acc: 64.84%, op_acc: 36.72%] [G loss: 0.944527]\n",
      "epoch:6 step:4960[D loss: 0.467633, acc: 54.69%, op_acc: 35.94%] [G loss: 0.929762]\n",
      "epoch:6 step:4961[D loss: 0.435832, acc: 58.59%, op_acc: 31.25%] [G loss: 0.984769]\n",
      "epoch:6 step:4962[D loss: 0.434191, acc: 64.84%, op_acc: 38.28%] [G loss: 0.908417]\n",
      "epoch:6 step:4963[D loss: 0.445923, acc: 60.16%, op_acc: 28.91%] [G loss: 0.907314]\n",
      "epoch:6 step:4964[D loss: 0.521045, acc: 50.00%, op_acc: 26.56%] [G loss: 0.932467]\n",
      "epoch:6 step:4965[D loss: 0.438030, acc: 65.62%, op_acc: 33.59%] [G loss: 0.942086]\n",
      "epoch:6 step:4966[D loss: 0.446761, acc: 53.91%, op_acc: 36.72%] [G loss: 0.934887]\n",
      "epoch:6 step:4967[D loss: 0.473929, acc: 57.03%, op_acc: 30.47%] [G loss: 0.895651]\n",
      "epoch:6 step:4968[D loss: 0.442217, acc: 64.84%, op_acc: 33.59%] [G loss: 0.969949]\n",
      "epoch:6 step:4969[D loss: 0.421785, acc: 61.72%, op_acc: 38.28%] [G loss: 0.933018]\n",
      "epoch:6 step:4970[D loss: 0.452535, acc: 60.16%, op_acc: 28.12%] [G loss: 0.970789]\n",
      "epoch:6 step:4971[D loss: 0.424438, acc: 60.94%, op_acc: 32.81%] [G loss: 0.994994]\n",
      "epoch:6 step:4972[D loss: 0.419495, acc: 67.97%, op_acc: 32.81%] [G loss: 0.962211]\n",
      "epoch:6 step:4973[D loss: 0.472316, acc: 51.56%, op_acc: 35.94%] [G loss: 0.927440]\n",
      "epoch:6 step:4974[D loss: 0.431175, acc: 60.94%, op_acc: 32.03%] [G loss: 0.870641]\n",
      "epoch:6 step:4975[D loss: 0.449896, acc: 61.72%, op_acc: 30.47%] [G loss: 0.995660]\n",
      "epoch:6 step:4976[D loss: 0.446145, acc: 57.81%, op_acc: 36.72%] [G loss: 0.871724]\n",
      "epoch:6 step:4977[D loss: 0.459261, acc: 57.03%, op_acc: 37.50%] [G loss: 0.903366]\n",
      "epoch:6 step:4978[D loss: 0.451129, acc: 60.94%, op_acc: 29.69%] [G loss: 0.866288]\n",
      "epoch:6 step:4979[D loss: 0.468367, acc: 58.59%, op_acc: 30.47%] [G loss: 0.943855]\n",
      "epoch:6 step:4980[D loss: 0.437799, acc: 63.28%, op_acc: 28.12%] [G loss: 0.846414]\n",
      "epoch:6 step:4981[D loss: 0.416218, acc: 67.19%, op_acc: 36.72%] [G loss: 1.002677]\n",
      "epoch:6 step:4982[D loss: 0.445831, acc: 57.81%, op_acc: 33.59%] [G loss: 0.948447]\n",
      "epoch:6 step:4983[D loss: 0.440675, acc: 62.50%, op_acc: 33.59%] [G loss: 0.950235]\n",
      "epoch:6 step:4984[D loss: 0.432121, acc: 64.06%, op_acc: 28.12%] [G loss: 1.034824]\n",
      "epoch:6 step:4985[D loss: 0.436618, acc: 62.50%, op_acc: 36.72%] [G loss: 1.069988]\n",
      "epoch:6 step:4986[D loss: 0.465849, acc: 60.16%, op_acc: 32.81%] [G loss: 0.977875]\n",
      "epoch:6 step:4987[D loss: 0.445217, acc: 60.94%, op_acc: 31.25%] [G loss: 1.009313]\n",
      "epoch:6 step:4988[D loss: 0.408355, acc: 67.19%, op_acc: 33.59%] [G loss: 0.949577]\n",
      "epoch:6 step:4989[D loss: 0.449516, acc: 53.12%, op_acc: 33.59%] [G loss: 0.942415]\n",
      "epoch:6 step:4990[D loss: 0.429853, acc: 61.72%, op_acc: 34.38%] [G loss: 0.910327]\n",
      "epoch:6 step:4991[D loss: 0.454221, acc: 55.47%, op_acc: 35.94%] [G loss: 0.925046]\n",
      "epoch:6 step:4992[D loss: 0.443151, acc: 64.84%, op_acc: 32.81%] [G loss: 0.954246]\n",
      "epoch:6 step:4993[D loss: 0.464771, acc: 58.59%, op_acc: 32.03%] [G loss: 0.964895]\n",
      "epoch:6 step:4994[D loss: 0.432755, acc: 64.06%, op_acc: 30.47%] [G loss: 0.961207]\n",
      "epoch:6 step:4995[D loss: 0.498200, acc: 50.00%, op_acc: 32.03%] [G loss: 0.862088]\n",
      "epoch:6 step:4996[D loss: 0.426576, acc: 60.94%, op_acc: 34.38%] [G loss: 0.900452]\n",
      "epoch:6 step:4997[D loss: 0.434707, acc: 62.50%, op_acc: 37.50%] [G loss: 0.985349]\n",
      "epoch:6 step:4998[D loss: 0.464215, acc: 56.25%, op_acc: 35.94%] [G loss: 0.925553]\n",
      "epoch:6 step:4999[D loss: 0.440507, acc: 66.41%, op_acc: 33.59%] [G loss: 1.023962]\n",
      "epoch:6 step:5000[D loss: 0.432935, acc: 64.84%, op_acc: 35.16%] [G loss: 0.990124]\n",
      "epoch:6 step:5001[D loss: 0.482102, acc: 57.81%, op_acc: 31.25%] [G loss: 0.915136]\n",
      "epoch:6 step:5002[D loss: 0.446859, acc: 59.38%, op_acc: 33.59%] [G loss: 0.976686]\n",
      "epoch:6 step:5003[D loss: 0.433671, acc: 60.16%, op_acc: 34.38%] [G loss: 0.863577]\n",
      "epoch:6 step:5004[D loss: 0.449586, acc: 62.50%, op_acc: 25.00%] [G loss: 0.855691]\n",
      "epoch:6 step:5005[D loss: 0.459938, acc: 57.81%, op_acc: 34.38%] [G loss: 0.930345]\n",
      "epoch:6 step:5006[D loss: 0.454090, acc: 60.16%, op_acc: 33.59%] [G loss: 0.889955]\n",
      "epoch:6 step:5007[D loss: 0.488881, acc: 53.12%, op_acc: 35.16%] [G loss: 0.908427]\n",
      "epoch:6 step:5008[D loss: 0.454030, acc: 63.28%, op_acc: 31.25%] [G loss: 0.931689]\n",
      "epoch:6 step:5009[D loss: 0.435245, acc: 60.94%, op_acc: 35.16%] [G loss: 1.051758]\n",
      "epoch:6 step:5010[D loss: 0.439231, acc: 61.72%, op_acc: 32.03%] [G loss: 0.932006]\n",
      "epoch:6 step:5011[D loss: 0.426891, acc: 61.72%, op_acc: 39.84%] [G loss: 0.954549]\n",
      "epoch:6 step:5012[D loss: 0.413972, acc: 68.75%, op_acc: 36.72%] [G loss: 0.921934]\n",
      "epoch:6 step:5013[D loss: 0.419932, acc: 62.50%, op_acc: 32.81%] [G loss: 0.962981]\n",
      "epoch:6 step:5014[D loss: 0.460989, acc: 59.38%, op_acc: 35.16%] [G loss: 0.931906]\n",
      "epoch:6 step:5015[D loss: 0.478129, acc: 54.69%, op_acc: 32.81%] [G loss: 0.844331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5016[D loss: 0.447534, acc: 55.47%, op_acc: 33.59%] [G loss: 0.872706]\n",
      "epoch:6 step:5017[D loss: 0.441707, acc: 61.72%, op_acc: 37.50%] [G loss: 0.905450]\n",
      "epoch:6 step:5018[D loss: 0.449160, acc: 61.72%, op_acc: 32.81%] [G loss: 1.041309]\n",
      "epoch:6 step:5019[D loss: 0.430066, acc: 69.53%, op_acc: 35.16%] [G loss: 0.960274]\n",
      "epoch:6 step:5020[D loss: 0.447110, acc: 53.91%, op_acc: 34.38%] [G loss: 0.856411]\n",
      "epoch:6 step:5021[D loss: 0.494078, acc: 51.56%, op_acc: 28.12%] [G loss: 0.958721]\n",
      "epoch:6 step:5022[D loss: 0.448227, acc: 66.41%, op_acc: 29.69%] [G loss: 0.926866]\n",
      "epoch:6 step:5023[D loss: 0.429028, acc: 67.97%, op_acc: 36.72%] [G loss: 1.003857]\n",
      "epoch:6 step:5024[D loss: 0.439253, acc: 57.81%, op_acc: 37.50%] [G loss: 0.918899]\n",
      "epoch:6 step:5025[D loss: 0.414504, acc: 71.09%, op_acc: 36.72%] [G loss: 0.932014]\n",
      "epoch:6 step:5026[D loss: 0.446661, acc: 60.16%, op_acc: 35.16%] [G loss: 0.948155]\n",
      "epoch:6 step:5027[D loss: 0.459396, acc: 57.81%, op_acc: 32.81%] [G loss: 0.882077]\n",
      "epoch:6 step:5028[D loss: 0.445211, acc: 61.72%, op_acc: 28.12%] [G loss: 0.906706]\n",
      "epoch:6 step:5029[D loss: 0.432719, acc: 65.62%, op_acc: 36.72%] [G loss: 0.938703]\n",
      "epoch:6 step:5030[D loss: 0.467237, acc: 54.69%, op_acc: 32.81%] [G loss: 0.938258]\n",
      "epoch:6 step:5031[D loss: 0.456099, acc: 57.81%, op_acc: 28.91%] [G loss: 0.882249]\n",
      "epoch:6 step:5032[D loss: 0.430175, acc: 66.41%, op_acc: 34.38%] [G loss: 0.926153]\n",
      "epoch:6 step:5033[D loss: 0.457586, acc: 53.12%, op_acc: 31.25%] [G loss: 0.873609]\n",
      "epoch:6 step:5034[D loss: 0.446831, acc: 57.81%, op_acc: 31.25%] [G loss: 0.869635]\n",
      "epoch:6 step:5035[D loss: 0.433886, acc: 57.81%, op_acc: 34.38%] [G loss: 0.880109]\n",
      "epoch:6 step:5036[D loss: 0.479926, acc: 52.34%, op_acc: 29.69%] [G loss: 0.822061]\n",
      "epoch:6 step:5037[D loss: 0.425038, acc: 61.72%, op_acc: 36.72%] [G loss: 0.841973]\n",
      "epoch:6 step:5038[D loss: 0.443029, acc: 62.50%, op_acc: 35.94%] [G loss: 0.983331]\n",
      "epoch:6 step:5039[D loss: 0.433275, acc: 57.81%, op_acc: 35.16%] [G loss: 0.974707]\n",
      "epoch:6 step:5040[D loss: 0.433511, acc: 60.16%, op_acc: 32.03%] [G loss: 0.838507]\n",
      "epoch:6 step:5041[D loss: 0.429437, acc: 64.06%, op_acc: 32.81%] [G loss: 0.884459]\n",
      "epoch:6 step:5042[D loss: 0.464899, acc: 49.22%, op_acc: 29.69%] [G loss: 0.908210]\n",
      "epoch:6 step:5043[D loss: 0.454689, acc: 59.38%, op_acc: 32.03%] [G loss: 0.938859]\n",
      "epoch:6 step:5044[D loss: 0.450507, acc: 60.16%, op_acc: 34.38%] [G loss: 0.878758]\n",
      "epoch:6 step:5045[D loss: 0.441591, acc: 59.38%, op_acc: 33.59%] [G loss: 0.994372]\n",
      "epoch:6 step:5046[D loss: 0.483462, acc: 52.34%, op_acc: 31.25%] [G loss: 0.947085]\n",
      "epoch:6 step:5047[D loss: 0.465291, acc: 54.69%, op_acc: 29.69%] [G loss: 0.869356]\n",
      "epoch:6 step:5048[D loss: 0.431452, acc: 60.94%, op_acc: 34.38%] [G loss: 0.837358]\n",
      "epoch:6 step:5049[D loss: 0.448316, acc: 55.47%, op_acc: 32.03%] [G loss: 0.931236]\n",
      "epoch:6 step:5050[D loss: 0.436061, acc: 58.59%, op_acc: 30.47%] [G loss: 0.897967]\n",
      "epoch:6 step:5051[D loss: 0.402255, acc: 71.09%, op_acc: 37.50%] [G loss: 0.964023]\n",
      "epoch:6 step:5052[D loss: 0.409301, acc: 60.94%, op_acc: 37.50%] [G loss: 0.895439]\n",
      "epoch:6 step:5053[D loss: 0.477915, acc: 57.81%, op_acc: 25.78%] [G loss: 0.972414]\n",
      "epoch:6 step:5054[D loss: 0.443735, acc: 64.06%, op_acc: 29.69%] [G loss: 0.926864]\n",
      "epoch:6 step:5055[D loss: 0.444507, acc: 55.47%, op_acc: 38.28%] [G loss: 0.994908]\n",
      "epoch:6 step:5056[D loss: 0.451767, acc: 57.81%, op_acc: 33.59%] [G loss: 0.910508]\n",
      "epoch:6 step:5057[D loss: 0.423376, acc: 63.28%, op_acc: 35.16%] [G loss: 0.885214]\n",
      "epoch:6 step:5058[D loss: 0.435856, acc: 61.72%, op_acc: 38.28%] [G loss: 0.865252]\n",
      "epoch:6 step:5059[D loss: 0.463470, acc: 57.81%, op_acc: 35.94%] [G loss: 0.931794]\n",
      "epoch:6 step:5060[D loss: 0.455938, acc: 56.25%, op_acc: 35.94%] [G loss: 0.945801]\n",
      "epoch:6 step:5061[D loss: 0.453053, acc: 53.12%, op_acc: 32.03%] [G loss: 0.839201]\n",
      "epoch:6 step:5062[D loss: 0.413840, acc: 69.53%, op_acc: 34.38%] [G loss: 0.961062]\n",
      "epoch:6 step:5063[D loss: 0.434337, acc: 64.06%, op_acc: 32.81%] [G loss: 0.950804]\n",
      "epoch:6 step:5064[D loss: 0.434238, acc: 64.84%, op_acc: 32.03%] [G loss: 0.863044]\n",
      "epoch:6 step:5065[D loss: 0.419870, acc: 63.28%, op_acc: 41.41%] [G loss: 0.911386]\n",
      "epoch:6 step:5066[D loss: 0.458671, acc: 55.47%, op_acc: 29.69%] [G loss: 0.953557]\n",
      "epoch:6 step:5067[D loss: 0.459269, acc: 56.25%, op_acc: 31.25%] [G loss: 0.905091]\n",
      "epoch:6 step:5068[D loss: 0.439218, acc: 65.62%, op_acc: 29.69%] [G loss: 0.924360]\n",
      "epoch:6 step:5069[D loss: 0.429469, acc: 59.38%, op_acc: 35.16%] [G loss: 1.003828]\n",
      "epoch:6 step:5070[D loss: 0.432349, acc: 66.41%, op_acc: 29.69%] [G loss: 0.973490]\n",
      "epoch:6 step:5071[D loss: 0.437713, acc: 64.06%, op_acc: 35.94%] [G loss: 0.956567]\n",
      "epoch:6 step:5072[D loss: 0.425740, acc: 60.16%, op_acc: 35.16%] [G loss: 0.955265]\n",
      "epoch:6 step:5073[D loss: 0.429812, acc: 60.16%, op_acc: 38.28%] [G loss: 0.978636]\n",
      "epoch:6 step:5074[D loss: 0.452186, acc: 60.94%, op_acc: 30.47%] [G loss: 0.906602]\n",
      "epoch:6 step:5075[D loss: 0.441227, acc: 63.28%, op_acc: 30.47%] [G loss: 0.902564]\n",
      "epoch:6 step:5076[D loss: 0.447562, acc: 58.59%, op_acc: 30.47%] [G loss: 0.905736]\n",
      "epoch:6 step:5077[D loss: 0.419559, acc: 60.94%, op_acc: 40.62%] [G loss: 0.983056]\n",
      "epoch:6 step:5078[D loss: 0.442464, acc: 56.25%, op_acc: 38.28%] [G loss: 1.007914]\n",
      "epoch:6 step:5079[D loss: 0.414738, acc: 71.09%, op_acc: 37.50%] [G loss: 0.915273]\n",
      "epoch:6 step:5080[D loss: 0.452493, acc: 54.69%, op_acc: 34.38%] [G loss: 0.851575]\n",
      "epoch:6 step:5081[D loss: 0.465925, acc: 58.59%, op_acc: 29.69%] [G loss: 0.966556]\n",
      "epoch:6 step:5082[D loss: 0.497038, acc: 49.22%, op_acc: 32.03%] [G loss: 0.918103]\n",
      "epoch:6 step:5083[D loss: 0.412038, acc: 60.94%, op_acc: 36.72%] [G loss: 0.970772]\n",
      "epoch:6 step:5084[D loss: 0.471666, acc: 57.03%, op_acc: 29.69%] [G loss: 0.956747]\n",
      "epoch:6 step:5085[D loss: 0.431157, acc: 59.38%, op_acc: 38.28%] [G loss: 1.006587]\n",
      "epoch:6 step:5086[D loss: 0.434473, acc: 60.16%, op_acc: 36.72%] [G loss: 0.972847]\n",
      "epoch:6 step:5087[D loss: 0.422628, acc: 59.38%, op_acc: 37.50%] [G loss: 0.980007]\n",
      "epoch:6 step:5088[D loss: 0.453340, acc: 60.94%, op_acc: 31.25%] [G loss: 0.977951]\n",
      "epoch:6 step:5089[D loss: 0.437175, acc: 60.94%, op_acc: 35.94%] [G loss: 0.889933]\n",
      "epoch:6 step:5090[D loss: 0.401395, acc: 64.06%, op_acc: 42.19%] [G loss: 0.990853]\n",
      "epoch:6 step:5091[D loss: 0.469031, acc: 56.25%, op_acc: 33.59%] [G loss: 0.886849]\n",
      "epoch:6 step:5092[D loss: 0.451446, acc: 50.00%, op_acc: 35.16%] [G loss: 0.997723]\n",
      "epoch:6 step:5093[D loss: 0.446121, acc: 65.62%, op_acc: 27.34%] [G loss: 0.906921]\n",
      "epoch:6 step:5094[D loss: 0.443145, acc: 57.81%, op_acc: 35.94%] [G loss: 0.891147]\n",
      "epoch:6 step:5095[D loss: 0.446717, acc: 57.81%, op_acc: 36.72%] [G loss: 0.937777]\n",
      "epoch:6 step:5096[D loss: 0.420446, acc: 66.41%, op_acc: 36.72%] [G loss: 0.924226]\n",
      "epoch:6 step:5097[D loss: 0.470907, acc: 58.59%, op_acc: 30.47%] [G loss: 0.888430]\n",
      "epoch:6 step:5098[D loss: 0.455370, acc: 56.25%, op_acc: 29.69%] [G loss: 0.913510]\n",
      "epoch:6 step:5099[D loss: 0.441545, acc: 58.59%, op_acc: 34.38%] [G loss: 0.960874]\n",
      "epoch:6 step:5100[D loss: 0.451531, acc: 61.72%, op_acc: 30.47%] [G loss: 0.893872]\n",
      "epoch:6 step:5101[D loss: 0.426719, acc: 67.97%, op_acc: 33.59%] [G loss: 0.953980]\n",
      "epoch:6 step:5102[D loss: 0.414236, acc: 68.75%, op_acc: 38.28%] [G loss: 0.963154]\n",
      "epoch:6 step:5103[D loss: 0.468646, acc: 51.56%, op_acc: 36.72%] [G loss: 0.902849]\n",
      "epoch:6 step:5104[D loss: 0.413657, acc: 62.50%, op_acc: 33.59%] [G loss: 0.873544]\n",
      "epoch:6 step:5105[D loss: 0.427947, acc: 60.16%, op_acc: 29.69%] [G loss: 0.966124]\n",
      "epoch:6 step:5106[D loss: 0.463779, acc: 53.91%, op_acc: 31.25%] [G loss: 0.858128]\n",
      "epoch:6 step:5107[D loss: 0.429434, acc: 66.41%, op_acc: 32.81%] [G loss: 0.901402]\n",
      "epoch:6 step:5108[D loss: 0.427403, acc: 67.97%, op_acc: 37.50%] [G loss: 0.889127]\n",
      "epoch:6 step:5109[D loss: 0.433414, acc: 67.19%, op_acc: 32.81%] [G loss: 0.996001]\n",
      "epoch:6 step:5110[D loss: 0.476098, acc: 56.25%, op_acc: 30.47%] [G loss: 0.898620]\n",
      "epoch:6 step:5111[D loss: 0.449852, acc: 59.38%, op_acc: 37.50%] [G loss: 0.915857]\n",
      "epoch:6 step:5112[D loss: 0.461107, acc: 53.12%, op_acc: 32.03%] [G loss: 0.862981]\n",
      "epoch:6 step:5113[D loss: 0.420502, acc: 69.53%, op_acc: 32.81%] [G loss: 0.969388]\n",
      "epoch:6 step:5114[D loss: 0.450603, acc: 55.47%, op_acc: 35.16%] [G loss: 0.950408]\n",
      "epoch:6 step:5115[D loss: 0.463490, acc: 53.12%, op_acc: 32.03%] [G loss: 0.884576]\n",
      "epoch:6 step:5116[D loss: 0.426508, acc: 64.06%, op_acc: 37.50%] [G loss: 0.998960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5117[D loss: 0.435921, acc: 60.16%, op_acc: 32.81%] [G loss: 0.902385]\n",
      "epoch:6 step:5118[D loss: 0.417756, acc: 59.38%, op_acc: 36.72%] [G loss: 0.924825]\n",
      "epoch:6 step:5119[D loss: 0.471896, acc: 50.78%, op_acc: 31.25%] [G loss: 0.867317]\n",
      "epoch:6 step:5120[D loss: 0.412875, acc: 61.72%, op_acc: 36.72%] [G loss: 0.973963]\n",
      "epoch:6 step:5121[D loss: 0.458549, acc: 57.03%, op_acc: 39.06%] [G loss: 1.074292]\n",
      "epoch:6 step:5122[D loss: 0.479837, acc: 59.38%, op_acc: 28.91%] [G loss: 0.920006]\n",
      "epoch:6 step:5123[D loss: 0.437783, acc: 61.72%, op_acc: 32.03%] [G loss: 0.909368]\n",
      "epoch:6 step:5124[D loss: 0.483053, acc: 54.69%, op_acc: 28.12%] [G loss: 0.810198]\n",
      "epoch:6 step:5125[D loss: 0.433723, acc: 62.50%, op_acc: 33.59%] [G loss: 0.892978]\n",
      "epoch:6 step:5126[D loss: 0.449796, acc: 58.59%, op_acc: 32.81%] [G loss: 0.970276]\n",
      "epoch:6 step:5127[D loss: 0.428766, acc: 60.94%, op_acc: 37.50%] [G loss: 0.969905]\n",
      "epoch:6 step:5128[D loss: 0.399348, acc: 68.75%, op_acc: 44.53%] [G loss: 0.964885]\n",
      "epoch:6 step:5129[D loss: 0.450187, acc: 61.72%, op_acc: 32.81%] [G loss: 0.975145]\n",
      "epoch:6 step:5130[D loss: 0.438055, acc: 61.72%, op_acc: 31.25%] [G loss: 0.929598]\n",
      "epoch:6 step:5131[D loss: 0.452533, acc: 65.62%, op_acc: 28.12%] [G loss: 0.937651]\n",
      "epoch:6 step:5132[D loss: 0.464106, acc: 57.81%, op_acc: 29.69%] [G loss: 0.895949]\n",
      "epoch:6 step:5133[D loss: 0.439242, acc: 67.19%, op_acc: 28.91%] [G loss: 0.924861]\n",
      "epoch:6 step:5134[D loss: 0.425667, acc: 71.09%, op_acc: 33.59%] [G loss: 0.934592]\n",
      "epoch:6 step:5135[D loss: 0.432260, acc: 62.50%, op_acc: 34.38%] [G loss: 0.999438]\n",
      "epoch:6 step:5136[D loss: 0.436350, acc: 67.19%, op_acc: 34.38%] [G loss: 0.932199]\n",
      "epoch:6 step:5137[D loss: 0.454621, acc: 56.25%, op_acc: 34.38%] [G loss: 0.957681]\n",
      "epoch:6 step:5138[D loss: 0.415947, acc: 64.84%, op_acc: 38.28%] [G loss: 0.906701]\n",
      "epoch:6 step:5139[D loss: 0.472244, acc: 48.44%, op_acc: 34.38%] [G loss: 0.870126]\n",
      "epoch:6 step:5140[D loss: 0.430527, acc: 67.19%, op_acc: 32.03%] [G loss: 0.922240]\n",
      "epoch:6 step:5141[D loss: 0.478814, acc: 50.78%, op_acc: 32.81%] [G loss: 0.854867]\n",
      "epoch:6 step:5142[D loss: 0.426576, acc: 68.75%, op_acc: 35.94%] [G loss: 0.859421]\n",
      "epoch:6 step:5143[D loss: 0.437180, acc: 67.19%, op_acc: 28.12%] [G loss: 0.959560]\n",
      "epoch:6 step:5144[D loss: 0.404942, acc: 66.41%, op_acc: 41.41%] [G loss: 0.996426]\n",
      "epoch:6 step:5145[D loss: 0.439378, acc: 58.59%, op_acc: 40.62%] [G loss: 0.966799]\n",
      "epoch:6 step:5146[D loss: 0.423791, acc: 64.06%, op_acc: 35.94%] [G loss: 0.984254]\n",
      "epoch:6 step:5147[D loss: 0.426972, acc: 68.75%, op_acc: 32.03%] [G loss: 0.956679]\n",
      "epoch:6 step:5148[D loss: 0.437178, acc: 64.84%, op_acc: 35.16%] [G loss: 1.005399]\n",
      "epoch:6 step:5149[D loss: 0.467977, acc: 56.25%, op_acc: 35.16%] [G loss: 0.945509]\n",
      "epoch:6 step:5150[D loss: 0.460384, acc: 64.06%, op_acc: 28.12%] [G loss: 0.975509]\n",
      "epoch:6 step:5151[D loss: 0.419049, acc: 67.19%, op_acc: 37.50%] [G loss: 0.978625]\n",
      "epoch:6 step:5152[D loss: 0.451228, acc: 57.03%, op_acc: 32.81%] [G loss: 0.986963]\n",
      "epoch:6 step:5153[D loss: 0.454665, acc: 58.59%, op_acc: 30.47%] [G loss: 0.857875]\n",
      "epoch:6 step:5154[D loss: 0.412004, acc: 64.06%, op_acc: 34.38%] [G loss: 0.900285]\n",
      "epoch:6 step:5155[D loss: 0.406869, acc: 64.84%, op_acc: 33.59%] [G loss: 1.038241]\n",
      "epoch:6 step:5156[D loss: 0.405965, acc: 70.31%, op_acc: 29.69%] [G loss: 1.071355]\n",
      "epoch:6 step:5157[D loss: 0.428125, acc: 62.50%, op_acc: 37.50%] [G loss: 1.013824]\n",
      "epoch:6 step:5158[D loss: 0.440292, acc: 60.94%, op_acc: 35.94%] [G loss: 1.006388]\n",
      "epoch:6 step:5159[D loss: 0.443137, acc: 52.34%, op_acc: 34.38%] [G loss: 0.914049]\n",
      "epoch:6 step:5160[D loss: 0.432965, acc: 63.28%, op_acc: 31.25%] [G loss: 0.923297]\n",
      "epoch:6 step:5161[D loss: 0.432750, acc: 62.50%, op_acc: 40.62%] [G loss: 1.017679]\n",
      "epoch:6 step:5162[D loss: 0.439932, acc: 64.06%, op_acc: 29.69%] [G loss: 0.978706]\n",
      "epoch:6 step:5163[D loss: 0.433688, acc: 60.16%, op_acc: 37.50%] [G loss: 0.954937]\n",
      "epoch:6 step:5164[D loss: 0.429537, acc: 59.38%, op_acc: 38.28%] [G loss: 0.982971]\n",
      "epoch:6 step:5165[D loss: 0.418118, acc: 66.41%, op_acc: 39.06%] [G loss: 0.948125]\n",
      "epoch:6 step:5166[D loss: 0.476190, acc: 57.81%, op_acc: 26.56%] [G loss: 0.970714]\n",
      "epoch:6 step:5167[D loss: 0.481154, acc: 60.94%, op_acc: 28.91%] [G loss: 0.968571]\n",
      "epoch:6 step:5168[D loss: 0.460137, acc: 58.59%, op_acc: 31.25%] [G loss: 0.921684]\n",
      "epoch:6 step:5169[D loss: 0.460775, acc: 61.72%, op_acc: 25.00%] [G loss: 0.930784]\n",
      "epoch:6 step:5170[D loss: 0.427370, acc: 62.50%, op_acc: 42.19%] [G loss: 0.987175]\n",
      "epoch:6 step:5171[D loss: 0.438855, acc: 58.59%, op_acc: 34.38%] [G loss: 0.902776]\n",
      "epoch:6 step:5172[D loss: 0.401341, acc: 68.75%, op_acc: 38.28%] [G loss: 0.893932]\n",
      "epoch:6 step:5173[D loss: 0.443692, acc: 54.69%, op_acc: 29.69%] [G loss: 0.929535]\n",
      "epoch:6 step:5174[D loss: 0.462901, acc: 54.69%, op_acc: 25.78%] [G loss: 0.903956]\n",
      "epoch:6 step:5175[D loss: 0.475782, acc: 50.78%, op_acc: 33.59%] [G loss: 0.865193]\n",
      "epoch:6 step:5176[D loss: 0.436272, acc: 60.16%, op_acc: 30.47%] [G loss: 0.886520]\n",
      "epoch:6 step:5177[D loss: 0.477244, acc: 54.69%, op_acc: 32.81%] [G loss: 0.984891]\n",
      "epoch:6 step:5178[D loss: 0.440788, acc: 61.72%, op_acc: 36.72%] [G loss: 0.932406]\n",
      "epoch:6 step:5179[D loss: 0.453802, acc: 52.34%, op_acc: 31.25%] [G loss: 0.932326]\n",
      "epoch:6 step:5180[D loss: 0.437344, acc: 62.50%, op_acc: 32.03%] [G loss: 0.856067]\n",
      "epoch:6 step:5181[D loss: 0.425934, acc: 64.06%, op_acc: 35.16%] [G loss: 0.933842]\n",
      "epoch:6 step:5182[D loss: 0.456019, acc: 60.94%, op_acc: 30.47%] [G loss: 0.896675]\n",
      "epoch:6 step:5183[D loss: 0.467184, acc: 57.03%, op_acc: 31.25%] [G loss: 0.915918]\n",
      "epoch:6 step:5184[D loss: 0.450412, acc: 60.16%, op_acc: 29.69%] [G loss: 0.949234]\n",
      "epoch:6 step:5185[D loss: 0.504035, acc: 50.78%, op_acc: 28.91%] [G loss: 0.916004]\n",
      "epoch:6 step:5186[D loss: 0.433732, acc: 56.25%, op_acc: 35.94%] [G loss: 0.878769]\n",
      "epoch:6 step:5187[D loss: 0.468001, acc: 60.16%, op_acc: 28.91%] [G loss: 0.922247]\n",
      "epoch:6 step:5188[D loss: 0.439736, acc: 60.94%, op_acc: 34.38%] [G loss: 0.987696]\n",
      "epoch:6 step:5189[D loss: 0.461076, acc: 57.81%, op_acc: 33.59%] [G loss: 0.985920]\n",
      "epoch:6 step:5190[D loss: 0.488054, acc: 52.34%, op_acc: 26.56%] [G loss: 0.938920]\n",
      "epoch:6 step:5191[D loss: 0.452121, acc: 60.94%, op_acc: 35.94%] [G loss: 0.940691]\n",
      "epoch:6 step:5192[D loss: 0.454995, acc: 63.28%, op_acc: 36.72%] [G loss: 0.972553]\n",
      "epoch:6 step:5193[D loss: 0.416850, acc: 66.41%, op_acc: 33.59%] [G loss: 0.971682]\n",
      "epoch:6 step:5194[D loss: 0.492116, acc: 46.88%, op_acc: 28.12%] [G loss: 0.825890]\n",
      "epoch:6 step:5195[D loss: 0.474447, acc: 55.47%, op_acc: 31.25%] [G loss: 0.950319]\n",
      "epoch:6 step:5196[D loss: 0.438085, acc: 64.84%, op_acc: 34.38%] [G loss: 0.873112]\n",
      "epoch:6 step:5197[D loss: 0.416757, acc: 60.16%, op_acc: 38.28%] [G loss: 1.043375]\n",
      "epoch:6 step:5198[D loss: 0.483184, acc: 55.47%, op_acc: 29.69%] [G loss: 0.938039]\n",
      "epoch:6 step:5199[D loss: 0.462606, acc: 58.59%, op_acc: 36.72%] [G loss: 0.958367]\n",
      "epoch:6 step:5200[D loss: 0.484943, acc: 45.31%, op_acc: 30.47%] [G loss: 0.857296]\n",
      "epoch:6 step:5201[D loss: 0.433224, acc: 65.62%, op_acc: 30.47%] [G loss: 0.945970]\n",
      "epoch:6 step:5202[D loss: 0.446533, acc: 63.28%, op_acc: 33.59%] [G loss: 0.881195]\n",
      "epoch:6 step:5203[D loss: 0.457219, acc: 60.16%, op_acc: 31.25%] [G loss: 0.974250]\n",
      "epoch:6 step:5204[D loss: 0.413681, acc: 67.19%, op_acc: 32.03%] [G loss: 0.908763]\n",
      "epoch:6 step:5205[D loss: 0.411995, acc: 62.50%, op_acc: 38.28%] [G loss: 0.845128]\n",
      "epoch:6 step:5206[D loss: 0.455349, acc: 56.25%, op_acc: 32.03%] [G loss: 0.935946]\n",
      "epoch:6 step:5207[D loss: 0.428100, acc: 65.62%, op_acc: 31.25%] [G loss: 0.935338]\n",
      "epoch:6 step:5208[D loss: 0.461139, acc: 55.47%, op_acc: 31.25%] [G loss: 0.975733]\n",
      "epoch:6 step:5209[D loss: 0.417963, acc: 64.06%, op_acc: 32.81%] [G loss: 0.981620]\n",
      "epoch:6 step:5210[D loss: 0.447401, acc: 60.94%, op_acc: 31.25%] [G loss: 0.862441]\n",
      "epoch:6 step:5211[D loss: 0.431018, acc: 67.97%, op_acc: 32.03%] [G loss: 0.968942]\n",
      "epoch:6 step:5212[D loss: 0.451000, acc: 67.19%, op_acc: 31.25%] [G loss: 1.006325]\n",
      "epoch:6 step:5213[D loss: 0.446704, acc: 63.28%, op_acc: 37.50%] [G loss: 0.927866]\n",
      "epoch:6 step:5214[D loss: 0.431860, acc: 63.28%, op_acc: 31.25%] [G loss: 0.923097]\n",
      "epoch:6 step:5215[D loss: 0.406953, acc: 68.75%, op_acc: 32.81%] [G loss: 0.932819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5216[D loss: 0.443767, acc: 66.41%, op_acc: 30.47%] [G loss: 0.983743]\n",
      "epoch:6 step:5217[D loss: 0.414441, acc: 68.75%, op_acc: 32.81%] [G loss: 0.947728]\n",
      "epoch:6 step:5218[D loss: 0.452934, acc: 64.06%, op_acc: 28.91%] [G loss: 0.879151]\n",
      "epoch:6 step:5219[D loss: 0.440717, acc: 64.06%, op_acc: 34.38%] [G loss: 0.873182]\n",
      "epoch:6 step:5220[D loss: 0.435849, acc: 62.50%, op_acc: 35.16%] [G loss: 0.826450]\n",
      "epoch:6 step:5221[D loss: 0.415549, acc: 64.06%, op_acc: 33.59%] [G loss: 0.894611]\n",
      "epoch:6 step:5222[D loss: 0.446874, acc: 50.78%, op_acc: 35.16%] [G loss: 0.840992]\n",
      "epoch:6 step:5223[D loss: 0.500107, acc: 56.25%, op_acc: 24.22%] [G loss: 0.868484]\n",
      "epoch:6 step:5224[D loss: 0.472114, acc: 56.25%, op_acc: 28.91%] [G loss: 0.863274]\n",
      "epoch:6 step:5225[D loss: 0.456284, acc: 59.38%, op_acc: 35.94%] [G loss: 0.850595]\n",
      "epoch:6 step:5226[D loss: 0.421878, acc: 65.62%, op_acc: 35.94%] [G loss: 1.018971]\n",
      "epoch:6 step:5227[D loss: 0.443016, acc: 59.38%, op_acc: 33.59%] [G loss: 0.907534]\n",
      "epoch:6 step:5228[D loss: 0.423803, acc: 60.16%, op_acc: 28.91%] [G loss: 0.937421]\n",
      "epoch:6 step:5229[D loss: 0.434340, acc: 60.94%, op_acc: 30.47%] [G loss: 0.962201]\n",
      "epoch:6 step:5230[D loss: 0.428424, acc: 63.28%, op_acc: 37.50%] [G loss: 0.912282]\n",
      "epoch:6 step:5231[D loss: 0.415437, acc: 64.06%, op_acc: 35.16%] [G loss: 1.010363]\n",
      "epoch:6 step:5232[D loss: 0.462430, acc: 50.78%, op_acc: 37.50%] [G loss: 0.908759]\n",
      "epoch:6 step:5233[D loss: 0.472913, acc: 53.12%, op_acc: 32.03%] [G loss: 0.938585]\n",
      "epoch:6 step:5234[D loss: 0.434051, acc: 62.50%, op_acc: 35.16%] [G loss: 0.920201]\n",
      "epoch:6 step:5235[D loss: 0.457469, acc: 61.72%, op_acc: 31.25%] [G loss: 0.927321]\n",
      "epoch:6 step:5236[D loss: 0.445468, acc: 64.84%, op_acc: 29.69%] [G loss: 0.912006]\n",
      "epoch:6 step:5237[D loss: 0.459156, acc: 63.28%, op_acc: 31.25%] [G loss: 0.895632]\n",
      "epoch:6 step:5238[D loss: 0.484690, acc: 58.59%, op_acc: 26.56%] [G loss: 0.816630]\n",
      "epoch:6 step:5239[D loss: 0.420886, acc: 64.06%, op_acc: 33.59%] [G loss: 0.993148]\n",
      "epoch:6 step:5240[D loss: 0.441978, acc: 60.16%, op_acc: 33.59%] [G loss: 0.980299]\n",
      "epoch:6 step:5241[D loss: 0.410640, acc: 67.97%, op_acc: 38.28%] [G loss: 1.024587]\n",
      "epoch:6 step:5242[D loss: 0.436031, acc: 61.72%, op_acc: 32.81%] [G loss: 0.986031]\n",
      "epoch:6 step:5243[D loss: 0.442518, acc: 60.94%, op_acc: 32.81%] [G loss: 0.970945]\n",
      "epoch:6 step:5244[D loss: 0.469741, acc: 49.22%, op_acc: 31.25%] [G loss: 0.852728]\n",
      "epoch:6 step:5245[D loss: 0.393323, acc: 66.41%, op_acc: 35.94%] [G loss: 1.006119]\n",
      "epoch:6 step:5246[D loss: 0.458041, acc: 60.16%, op_acc: 38.28%] [G loss: 0.941263]\n",
      "epoch:6 step:5247[D loss: 0.415414, acc: 69.53%, op_acc: 35.94%] [G loss: 0.959211]\n",
      "epoch:6 step:5248[D loss: 0.447128, acc: 60.94%, op_acc: 28.12%] [G loss: 1.024994]\n",
      "epoch:6 step:5249[D loss: 0.450964, acc: 64.06%, op_acc: 32.03%] [G loss: 0.974436]\n",
      "epoch:6 step:5250[D loss: 0.413802, acc: 64.06%, op_acc: 39.06%] [G loss: 1.048600]\n",
      "epoch:6 step:5251[D loss: 0.447571, acc: 63.28%, op_acc: 34.38%] [G loss: 0.926774]\n",
      "epoch:6 step:5252[D loss: 0.436591, acc: 66.41%, op_acc: 38.28%] [G loss: 1.028588]\n",
      "epoch:6 step:5253[D loss: 0.443835, acc: 54.69%, op_acc: 37.50%] [G loss: 0.975300]\n",
      "epoch:6 step:5254[D loss: 0.439468, acc: 59.38%, op_acc: 39.84%] [G loss: 1.060295]\n",
      "epoch:6 step:5255[D loss: 0.442092, acc: 57.03%, op_acc: 34.38%] [G loss: 0.810670]\n",
      "epoch:6 step:5256[D loss: 0.449651, acc: 58.59%, op_acc: 35.94%] [G loss: 0.901549]\n",
      "epoch:6 step:5257[D loss: 0.483477, acc: 53.91%, op_acc: 39.84%] [G loss: 0.914868]\n",
      "epoch:6 step:5258[D loss: 0.454188, acc: 58.59%, op_acc: 27.34%] [G loss: 0.892988]\n",
      "epoch:6 step:5259[D loss: 0.436094, acc: 55.47%, op_acc: 35.94%] [G loss: 0.990243]\n",
      "epoch:6 step:5260[D loss: 0.476870, acc: 52.34%, op_acc: 30.47%] [G loss: 0.999454]\n",
      "epoch:6 step:5261[D loss: 0.429740, acc: 68.75%, op_acc: 35.94%] [G loss: 1.134516]\n",
      "epoch:6 step:5262[D loss: 0.426393, acc: 58.59%, op_acc: 35.16%] [G loss: 1.024333]\n",
      "epoch:6 step:5263[D loss: 0.472129, acc: 56.25%, op_acc: 34.38%] [G loss: 1.105392]\n",
      "epoch:6 step:5264[D loss: 0.456826, acc: 60.16%, op_acc: 28.12%] [G loss: 1.026227]\n",
      "epoch:6 step:5265[D loss: 0.397477, acc: 68.75%, op_acc: 35.94%] [G loss: 1.072883]\n",
      "epoch:6 step:5266[D loss: 0.460974, acc: 64.06%, op_acc: 35.16%] [G loss: 0.946716]\n",
      "epoch:6 step:5267[D loss: 0.463722, acc: 59.38%, op_acc: 28.91%] [G loss: 0.954536]\n",
      "epoch:6 step:5268[D loss: 0.474877, acc: 59.38%, op_acc: 30.47%] [G loss: 0.982813]\n",
      "epoch:6 step:5269[D loss: 0.434792, acc: 65.62%, op_acc: 33.59%] [G loss: 0.872565]\n",
      "epoch:6 step:5270[D loss: 0.442563, acc: 64.84%, op_acc: 28.12%] [G loss: 0.930583]\n",
      "epoch:6 step:5271[D loss: 0.418719, acc: 65.62%, op_acc: 39.84%] [G loss: 0.875226]\n",
      "epoch:6 step:5272[D loss: 0.449406, acc: 60.94%, op_acc: 28.91%] [G loss: 0.810856]\n",
      "epoch:6 step:5273[D loss: 0.413367, acc: 71.09%, op_acc: 34.38%] [G loss: 1.026635]\n",
      "epoch:6 step:5274[D loss: 0.457087, acc: 51.56%, op_acc: 32.81%] [G loss: 0.900998]\n",
      "epoch:6 step:5275[D loss: 0.410220, acc: 72.66%, op_acc: 29.69%] [G loss: 0.927896]\n",
      "epoch:6 step:5276[D loss: 0.469081, acc: 49.22%, op_acc: 36.72%] [G loss: 0.919897]\n",
      "epoch:6 step:5277[D loss: 0.446257, acc: 67.19%, op_acc: 25.78%] [G loss: 1.102901]\n",
      "epoch:6 step:5278[D loss: 0.438585, acc: 59.38%, op_acc: 37.50%] [G loss: 0.844252]\n",
      "epoch:6 step:5279[D loss: 0.457548, acc: 60.16%, op_acc: 34.38%] [G loss: 0.895546]\n",
      "epoch:6 step:5280[D loss: 0.464213, acc: 59.38%, op_acc: 29.69%] [G loss: 0.951588]\n",
      "epoch:6 step:5281[D loss: 0.449911, acc: 58.59%, op_acc: 30.47%] [G loss: 0.928851]\n",
      "epoch:6 step:5282[D loss: 0.437584, acc: 63.28%, op_acc: 36.72%] [G loss: 0.952487]\n",
      "epoch:6 step:5283[D loss: 0.440939, acc: 62.50%, op_acc: 35.94%] [G loss: 0.895398]\n",
      "epoch:6 step:5284[D loss: 0.443590, acc: 61.72%, op_acc: 34.38%] [G loss: 0.957405]\n",
      "epoch:6 step:5285[D loss: 0.449610, acc: 62.50%, op_acc: 32.03%] [G loss: 1.002310]\n",
      "epoch:6 step:5286[D loss: 0.448638, acc: 65.62%, op_acc: 33.59%] [G loss: 0.962377]\n",
      "epoch:6 step:5287[D loss: 0.448704, acc: 59.38%, op_acc: 33.59%] [G loss: 0.946596]\n",
      "epoch:6 step:5288[D loss: 0.385700, acc: 65.62%, op_acc: 38.28%] [G loss: 0.984298]\n",
      "epoch:6 step:5289[D loss: 0.389299, acc: 68.75%, op_acc: 38.28%] [G loss: 0.946098]\n",
      "epoch:6 step:5290[D loss: 0.432410, acc: 64.84%, op_acc: 32.03%] [G loss: 0.903026]\n",
      "epoch:6 step:5291[D loss: 0.469567, acc: 58.59%, op_acc: 29.69%] [G loss: 0.843958]\n",
      "epoch:6 step:5292[D loss: 0.443765, acc: 58.59%, op_acc: 35.16%] [G loss: 0.916232]\n",
      "epoch:6 step:5293[D loss: 0.443289, acc: 57.03%, op_acc: 35.94%] [G loss: 0.908777]\n",
      "epoch:6 step:5294[D loss: 0.430574, acc: 62.50%, op_acc: 34.38%] [G loss: 0.941308]\n",
      "epoch:6 step:5295[D loss: 0.472362, acc: 56.25%, op_acc: 28.12%] [G loss: 0.885585]\n",
      "epoch:6 step:5296[D loss: 0.432548, acc: 61.72%, op_acc: 36.72%] [G loss: 1.042081]\n",
      "epoch:6 step:5297[D loss: 0.437428, acc: 57.81%, op_acc: 31.25%] [G loss: 0.870527]\n",
      "epoch:6 step:5298[D loss: 0.449777, acc: 60.94%, op_acc: 31.25%] [G loss: 0.884008]\n",
      "epoch:6 step:5299[D loss: 0.425824, acc: 60.16%, op_acc: 35.16%] [G loss: 0.936018]\n",
      "epoch:6 step:5300[D loss: 0.425199, acc: 66.41%, op_acc: 29.69%] [G loss: 0.921437]\n",
      "epoch:6 step:5301[D loss: 0.430062, acc: 67.19%, op_acc: 34.38%] [G loss: 0.887038]\n",
      "epoch:6 step:5302[D loss: 0.455791, acc: 59.38%, op_acc: 35.94%] [G loss: 0.901186]\n",
      "epoch:6 step:5303[D loss: 0.472559, acc: 55.47%, op_acc: 32.03%] [G loss: 1.025312]\n",
      "epoch:6 step:5304[D loss: 0.430624, acc: 61.72%, op_acc: 33.59%] [G loss: 0.929488]\n",
      "epoch:6 step:5305[D loss: 0.494136, acc: 51.56%, op_acc: 28.91%] [G loss: 0.896760]\n",
      "epoch:6 step:5306[D loss: 0.469839, acc: 60.16%, op_acc: 25.00%] [G loss: 0.955569]\n",
      "epoch:6 step:5307[D loss: 0.485700, acc: 53.12%, op_acc: 30.47%] [G loss: 0.893991]\n",
      "epoch:6 step:5308[D loss: 0.464357, acc: 61.72%, op_acc: 34.38%] [G loss: 0.898975]\n",
      "epoch:6 step:5309[D loss: 0.462835, acc: 55.47%, op_acc: 32.81%] [G loss: 0.916931]\n",
      "epoch:6 step:5310[D loss: 0.461598, acc: 57.03%, op_acc: 36.72%] [G loss: 0.854362]\n",
      "epoch:6 step:5311[D loss: 0.435443, acc: 59.38%, op_acc: 41.41%] [G loss: 1.002767]\n",
      "epoch:6 step:5312[D loss: 0.435740, acc: 56.25%, op_acc: 36.72%] [G loss: 1.004970]\n",
      "epoch:6 step:5313[D loss: 0.451189, acc: 55.47%, op_acc: 33.59%] [G loss: 0.980140]\n",
      "epoch:6 step:5314[D loss: 0.424928, acc: 68.75%, op_acc: 37.50%] [G loss: 1.019195]\n",
      "epoch:6 step:5315[D loss: 0.468881, acc: 53.91%, op_acc: 31.25%] [G loss: 0.896071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5316[D loss: 0.430797, acc: 61.72%, op_acc: 33.59%] [G loss: 0.943089]\n",
      "epoch:6 step:5317[D loss: 0.431561, acc: 65.62%, op_acc: 33.59%] [G loss: 0.906404]\n",
      "epoch:6 step:5318[D loss: 0.461318, acc: 65.62%, op_acc: 30.47%] [G loss: 1.015639]\n",
      "epoch:6 step:5319[D loss: 0.451647, acc: 67.19%, op_acc: 32.81%] [G loss: 0.895655]\n",
      "epoch:6 step:5320[D loss: 0.447125, acc: 63.28%, op_acc: 35.94%] [G loss: 0.881070]\n",
      "epoch:6 step:5321[D loss: 0.477864, acc: 52.34%, op_acc: 32.81%] [G loss: 0.847903]\n",
      "epoch:6 step:5322[D loss: 0.422380, acc: 64.06%, op_acc: 36.72%] [G loss: 0.981470]\n",
      "epoch:6 step:5323[D loss: 0.462086, acc: 57.03%, op_acc: 30.47%] [G loss: 0.847000]\n",
      "epoch:6 step:5324[D loss: 0.451367, acc: 61.72%, op_acc: 37.50%] [G loss: 0.929471]\n",
      "epoch:6 step:5325[D loss: 0.450410, acc: 57.81%, op_acc: 35.94%] [G loss: 0.888344]\n",
      "epoch:6 step:5326[D loss: 0.439408, acc: 60.16%, op_acc: 34.38%] [G loss: 0.925647]\n",
      "epoch:6 step:5327[D loss: 0.439729, acc: 64.84%, op_acc: 28.91%] [G loss: 0.848357]\n",
      "epoch:6 step:5328[D loss: 0.453934, acc: 60.16%, op_acc: 33.59%] [G loss: 0.961517]\n",
      "epoch:6 step:5329[D loss: 0.474546, acc: 56.25%, op_acc: 28.12%] [G loss: 0.942757]\n",
      "epoch:6 step:5330[D loss: 0.410030, acc: 67.97%, op_acc: 39.06%] [G loss: 1.022099]\n",
      "epoch:6 step:5331[D loss: 0.454828, acc: 66.41%, op_acc: 35.94%] [G loss: 0.979082]\n",
      "epoch:6 step:5332[D loss: 0.455378, acc: 57.81%, op_acc: 30.47%] [G loss: 1.047541]\n",
      "epoch:6 step:5333[D loss: 0.436331, acc: 58.59%, op_acc: 29.69%] [G loss: 0.946359]\n",
      "epoch:6 step:5334[D loss: 0.415762, acc: 69.53%, op_acc: 34.38%] [G loss: 0.951111]\n",
      "epoch:6 step:5335[D loss: 0.418600, acc: 65.62%, op_acc: 37.50%] [G loss: 1.145735]\n",
      "epoch:6 step:5336[D loss: 0.448031, acc: 64.06%, op_acc: 32.81%] [G loss: 1.014865]\n",
      "epoch:6 step:5337[D loss: 0.438516, acc: 64.84%, op_acc: 32.81%] [G loss: 0.898932]\n",
      "epoch:6 step:5338[D loss: 0.427652, acc: 67.19%, op_acc: 35.16%] [G loss: 1.047178]\n",
      "epoch:6 step:5339[D loss: 0.446210, acc: 56.25%, op_acc: 39.84%] [G loss: 0.946194]\n",
      "epoch:6 step:5340[D loss: 0.460266, acc: 57.03%, op_acc: 33.59%] [G loss: 0.883232]\n",
      "epoch:6 step:5341[D loss: 0.442815, acc: 64.06%, op_acc: 33.59%] [G loss: 0.888668]\n",
      "epoch:6 step:5342[D loss: 0.442519, acc: 63.28%, op_acc: 29.69%] [G loss: 0.866255]\n",
      "epoch:6 step:5343[D loss: 0.467269, acc: 57.03%, op_acc: 37.50%] [G loss: 0.896606]\n",
      "epoch:6 step:5344[D loss: 0.420601, acc: 64.84%, op_acc: 36.72%] [G loss: 0.943457]\n",
      "epoch:6 step:5345[D loss: 0.466964, acc: 53.91%, op_acc: 28.12%] [G loss: 0.883517]\n",
      "epoch:6 step:5346[D loss: 0.423158, acc: 65.62%, op_acc: 35.16%] [G loss: 0.936786]\n",
      "epoch:6 step:5347[D loss: 0.441948, acc: 54.69%, op_acc: 38.28%] [G loss: 1.025596]\n",
      "epoch:6 step:5348[D loss: 0.436429, acc: 59.38%, op_acc: 41.41%] [G loss: 0.974417]\n",
      "epoch:6 step:5349[D loss: 0.447354, acc: 53.91%, op_acc: 37.50%] [G loss: 0.910848]\n",
      "epoch:6 step:5350[D loss: 0.434324, acc: 59.38%, op_acc: 39.84%] [G loss: 0.875882]\n",
      "epoch:6 step:5351[D loss: 0.489214, acc: 59.38%, op_acc: 22.66%] [G loss: 0.976612]\n",
      "epoch:6 step:5352[D loss: 0.436637, acc: 64.06%, op_acc: 35.16%] [G loss: 0.911243]\n",
      "epoch:6 step:5353[D loss: 0.404187, acc: 65.62%, op_acc: 33.59%] [G loss: 0.959899]\n",
      "epoch:6 step:5354[D loss: 0.449681, acc: 58.59%, op_acc: 37.50%] [G loss: 0.870732]\n",
      "epoch:6 step:5355[D loss: 0.455226, acc: 60.94%, op_acc: 28.12%] [G loss: 0.819986]\n",
      "epoch:6 step:5356[D loss: 0.443387, acc: 54.69%, op_acc: 30.47%] [G loss: 0.983195]\n",
      "epoch:6 step:5357[D loss: 0.443487, acc: 61.72%, op_acc: 29.69%] [G loss: 0.964884]\n",
      "epoch:6 step:5358[D loss: 0.433981, acc: 63.28%, op_acc: 32.03%] [G loss: 1.005271]\n",
      "epoch:6 step:5359[D loss: 0.453268, acc: 62.50%, op_acc: 32.03%] [G loss: 0.857806]\n",
      "epoch:6 step:5360[D loss: 0.441297, acc: 59.38%, op_acc: 38.28%] [G loss: 1.038525]\n",
      "epoch:6 step:5361[D loss: 0.422749, acc: 59.38%, op_acc: 33.59%] [G loss: 1.014997]\n",
      "epoch:6 step:5362[D loss: 0.455364, acc: 70.31%, op_acc: 32.03%] [G loss: 0.858888]\n",
      "epoch:6 step:5363[D loss: 0.478329, acc: 57.81%, op_acc: 27.34%] [G loss: 0.883124]\n",
      "epoch:6 step:5364[D loss: 0.451337, acc: 57.03%, op_acc: 34.38%] [G loss: 0.899969]\n",
      "epoch:6 step:5365[D loss: 0.445120, acc: 60.94%, op_acc: 37.50%] [G loss: 0.820896]\n",
      "epoch:6 step:5366[D loss: 0.414240, acc: 70.31%, op_acc: 32.81%] [G loss: 1.048965]\n",
      "epoch:6 step:5367[D loss: 0.457065, acc: 60.16%, op_acc: 32.03%] [G loss: 0.980477]\n",
      "epoch:6 step:5368[D loss: 0.462456, acc: 50.00%, op_acc: 39.06%] [G loss: 0.899981]\n",
      "epoch:6 step:5369[D loss: 0.450011, acc: 60.16%, op_acc: 35.16%] [G loss: 0.820732]\n",
      "epoch:6 step:5370[D loss: 0.454535, acc: 63.28%, op_acc: 36.72%] [G loss: 0.923785]\n",
      "epoch:6 step:5371[D loss: 0.493861, acc: 44.53%, op_acc: 28.91%] [G loss: 0.858456]\n",
      "epoch:6 step:5372[D loss: 0.424241, acc: 64.84%, op_acc: 32.03%] [G loss: 0.903338]\n",
      "epoch:6 step:5373[D loss: 0.453315, acc: 58.59%, op_acc: 31.25%] [G loss: 0.910459]\n",
      "epoch:6 step:5374[D loss: 0.404041, acc: 71.09%, op_acc: 39.06%] [G loss: 0.919368]\n",
      "epoch:6 step:5375[D loss: 0.437049, acc: 67.97%, op_acc: 32.03%] [G loss: 1.074306]\n",
      "epoch:6 step:5376[D loss: 0.437587, acc: 59.38%, op_acc: 32.81%] [G loss: 0.943145]\n",
      "epoch:6 step:5377[D loss: 0.431764, acc: 61.72%, op_acc: 32.03%] [G loss: 1.002396]\n",
      "epoch:6 step:5378[D loss: 0.433804, acc: 64.84%, op_acc: 35.16%] [G loss: 0.987718]\n",
      "epoch:6 step:5379[D loss: 0.467603, acc: 63.28%, op_acc: 28.91%] [G loss: 1.029127]\n",
      "epoch:6 step:5380[D loss: 0.419548, acc: 69.53%, op_acc: 35.16%] [G loss: 0.945082]\n",
      "epoch:6 step:5381[D loss: 0.481991, acc: 50.00%, op_acc: 32.03%] [G loss: 0.860885]\n",
      "epoch:6 step:5382[D loss: 0.446267, acc: 61.72%, op_acc: 33.59%] [G loss: 0.976536]\n",
      "epoch:6 step:5383[D loss: 0.464968, acc: 53.91%, op_acc: 29.69%] [G loss: 0.931114]\n",
      "epoch:6 step:5384[D loss: 0.411707, acc: 67.19%, op_acc: 39.84%] [G loss: 0.929128]\n",
      "epoch:6 step:5385[D loss: 0.434302, acc: 58.59%, op_acc: 39.84%] [G loss: 1.063514]\n",
      "epoch:6 step:5386[D loss: 0.482019, acc: 51.56%, op_acc: 31.25%] [G loss: 0.913319]\n",
      "epoch:6 step:5387[D loss: 0.439696, acc: 64.06%, op_acc: 28.91%] [G loss: 0.860906]\n",
      "epoch:6 step:5388[D loss: 0.452644, acc: 60.16%, op_acc: 32.81%] [G loss: 0.924515]\n",
      "epoch:6 step:5389[D loss: 0.432484, acc: 67.19%, op_acc: 35.16%] [G loss: 0.884459]\n",
      "epoch:6 step:5390[D loss: 0.416745, acc: 64.06%, op_acc: 39.06%] [G loss: 0.956942]\n",
      "epoch:6 step:5391[D loss: 0.415376, acc: 67.19%, op_acc: 39.84%] [G loss: 0.893543]\n",
      "epoch:6 step:5392[D loss: 0.429045, acc: 66.41%, op_acc: 31.25%] [G loss: 0.900325]\n",
      "epoch:6 step:5393[D loss: 0.522496, acc: 48.44%, op_acc: 30.47%] [G loss: 0.821876]\n",
      "epoch:6 step:5394[D loss: 0.452067, acc: 58.59%, op_acc: 34.38%] [G loss: 0.964370]\n",
      "epoch:6 step:5395[D loss: 0.442439, acc: 58.59%, op_acc: 38.28%] [G loss: 0.922522]\n",
      "epoch:6 step:5396[D loss: 0.393898, acc: 65.62%, op_acc: 43.75%] [G loss: 1.007020]\n",
      "epoch:6 step:5397[D loss: 0.417879, acc: 70.31%, op_acc: 34.38%] [G loss: 0.969176]\n",
      "epoch:6 step:5398[D loss: 0.385045, acc: 71.88%, op_acc: 38.28%] [G loss: 1.072477]\n",
      "epoch:6 step:5399[D loss: 0.448279, acc: 58.59%, op_acc: 33.59%] [G loss: 0.878185]\n",
      "epoch:6 step:5400[D loss: 0.460781, acc: 60.16%, op_acc: 32.03%] [G loss: 0.939134]\n",
      "epoch:6 step:5401[D loss: 0.446745, acc: 58.59%, op_acc: 33.59%] [G loss: 0.848913]\n",
      "epoch:6 step:5402[D loss: 0.473192, acc: 62.50%, op_acc: 29.69%] [G loss: 0.848784]\n",
      "epoch:6 step:5403[D loss: 0.418950, acc: 67.97%, op_acc: 37.50%] [G loss: 0.923924]\n",
      "epoch:6 step:5404[D loss: 0.446302, acc: 54.69%, op_acc: 33.59%] [G loss: 0.874589]\n",
      "epoch:6 step:5405[D loss: 0.446964, acc: 59.38%, op_acc: 35.16%] [G loss: 0.961858]\n",
      "epoch:6 step:5406[D loss: 0.450168, acc: 64.84%, op_acc: 28.91%] [G loss: 0.985604]\n",
      "epoch:6 step:5407[D loss: 0.430445, acc: 57.03%, op_acc: 39.84%] [G loss: 0.961071]\n",
      "epoch:6 step:5408[D loss: 0.443642, acc: 59.38%, op_acc: 32.81%] [G loss: 0.872677]\n",
      "epoch:6 step:5409[D loss: 0.425642, acc: 60.16%, op_acc: 34.38%] [G loss: 0.872892]\n",
      "epoch:6 step:5410[D loss: 0.497651, acc: 56.25%, op_acc: 25.78%] [G loss: 0.819784]\n",
      "epoch:6 step:5411[D loss: 0.431065, acc: 65.62%, op_acc: 35.16%] [G loss: 0.943916]\n",
      "epoch:6 step:5412[D loss: 0.447665, acc: 59.38%, op_acc: 40.62%] [G loss: 0.949304]\n",
      "epoch:6 step:5413[D loss: 0.477593, acc: 60.94%, op_acc: 32.03%] [G loss: 0.936022]\n",
      "epoch:6 step:5414[D loss: 0.451537, acc: 63.28%, op_acc: 32.03%] [G loss: 0.975552]\n",
      "epoch:6 step:5415[D loss: 0.435847, acc: 61.72%, op_acc: 32.81%] [G loss: 0.892340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5416[D loss: 0.451262, acc: 57.03%, op_acc: 32.81%] [G loss: 0.959283]\n",
      "epoch:6 step:5417[D loss: 0.442288, acc: 57.03%, op_acc: 38.28%] [G loss: 0.918763]\n",
      "epoch:6 step:5418[D loss: 0.427353, acc: 64.06%, op_acc: 33.59%] [G loss: 0.968144]\n",
      "epoch:6 step:5419[D loss: 0.481116, acc: 50.00%, op_acc: 33.59%] [G loss: 0.892366]\n",
      "epoch:6 step:5420[D loss: 0.453369, acc: 61.72%, op_acc: 29.69%] [G loss: 0.976040]\n",
      "epoch:6 step:5421[D loss: 0.463253, acc: 60.16%, op_acc: 25.00%] [G loss: 0.941777]\n",
      "epoch:6 step:5422[D loss: 0.447758, acc: 70.31%, op_acc: 28.91%] [G loss: 0.973300]\n",
      "epoch:6 step:5423[D loss: 0.419222, acc: 64.84%, op_acc: 39.06%] [G loss: 0.883903]\n",
      "epoch:6 step:5424[D loss: 0.462599, acc: 56.25%, op_acc: 32.81%] [G loss: 0.961002]\n",
      "epoch:6 step:5425[D loss: 0.448734, acc: 55.47%, op_acc: 33.59%] [G loss: 0.859037]\n",
      "epoch:6 step:5426[D loss: 0.434408, acc: 57.03%, op_acc: 37.50%] [G loss: 0.996978]\n",
      "epoch:6 step:5427[D loss: 0.423836, acc: 66.41%, op_acc: 29.69%] [G loss: 0.851335]\n",
      "epoch:6 step:5428[D loss: 0.430990, acc: 63.28%, op_acc: 35.94%] [G loss: 0.899015]\n",
      "epoch:6 step:5429[D loss: 0.432464, acc: 61.72%, op_acc: 34.38%] [G loss: 0.903325]\n",
      "epoch:6 step:5430[D loss: 0.392821, acc: 64.84%, op_acc: 43.75%] [G loss: 0.943726]\n",
      "epoch:6 step:5431[D loss: 0.423264, acc: 65.62%, op_acc: 33.59%] [G loss: 0.894663]\n",
      "epoch:6 step:5432[D loss: 0.432327, acc: 60.94%, op_acc: 34.38%] [G loss: 1.051260]\n",
      "epoch:6 step:5433[D loss: 0.430733, acc: 64.06%, op_acc: 37.50%] [G loss: 0.864701]\n",
      "epoch:6 step:5434[D loss: 0.418932, acc: 71.88%, op_acc: 27.34%] [G loss: 0.969191]\n",
      "epoch:6 step:5435[D loss: 0.474200, acc: 53.91%, op_acc: 30.47%] [G loss: 0.923702]\n",
      "epoch:6 step:5436[D loss: 0.426412, acc: 64.06%, op_acc: 36.72%] [G loss: 0.942428]\n",
      "epoch:6 step:5437[D loss: 0.451330, acc: 64.84%, op_acc: 32.03%] [G loss: 0.991468]\n",
      "epoch:6 step:5438[D loss: 0.455525, acc: 59.38%, op_acc: 32.03%] [G loss: 0.907571]\n",
      "epoch:6 step:5439[D loss: 0.427901, acc: 62.50%, op_acc: 35.16%] [G loss: 0.917717]\n",
      "epoch:6 step:5440[D loss: 0.449207, acc: 57.81%, op_acc: 37.50%] [G loss: 0.926490]\n",
      "epoch:6 step:5441[D loss: 0.454073, acc: 64.06%, op_acc: 30.47%] [G loss: 0.915730]\n",
      "epoch:6 step:5442[D loss: 0.430437, acc: 58.59%, op_acc: 39.84%] [G loss: 0.768969]\n",
      "epoch:6 step:5443[D loss: 0.427863, acc: 66.41%, op_acc: 31.25%] [G loss: 0.882395]\n",
      "epoch:6 step:5444[D loss: 0.431802, acc: 60.94%, op_acc: 35.94%] [G loss: 0.993992]\n",
      "epoch:6 step:5445[D loss: 0.444667, acc: 60.94%, op_acc: 34.38%] [G loss: 0.994164]\n",
      "epoch:6 step:5446[D loss: 0.433143, acc: 56.25%, op_acc: 39.06%] [G loss: 0.963458]\n",
      "epoch:6 step:5447[D loss: 0.437142, acc: 58.59%, op_acc: 34.38%] [G loss: 0.926720]\n",
      "epoch:6 step:5448[D loss: 0.447171, acc: 64.84%, op_acc: 29.69%] [G loss: 0.978336]\n",
      "epoch:6 step:5449[D loss: 0.469236, acc: 58.59%, op_acc: 29.69%] [G loss: 0.927813]\n",
      "epoch:6 step:5450[D loss: 0.455293, acc: 52.34%, op_acc: 35.94%] [G loss: 0.847783]\n",
      "epoch:6 step:5451[D loss: 0.399893, acc: 64.84%, op_acc: 37.50%] [G loss: 1.029478]\n",
      "epoch:6 step:5452[D loss: 0.439181, acc: 66.41%, op_acc: 28.91%] [G loss: 0.983115]\n",
      "epoch:6 step:5453[D loss: 0.429561, acc: 57.81%, op_acc: 35.94%] [G loss: 1.027288]\n",
      "epoch:6 step:5454[D loss: 0.430232, acc: 64.06%, op_acc: 33.59%] [G loss: 0.914059]\n",
      "epoch:6 step:5455[D loss: 0.409159, acc: 66.41%, op_acc: 37.50%] [G loss: 0.940244]\n",
      "epoch:6 step:5456[D loss: 0.434448, acc: 59.38%, op_acc: 37.50%] [G loss: 1.036395]\n",
      "epoch:6 step:5457[D loss: 0.496574, acc: 51.56%, op_acc: 31.25%] [G loss: 0.870788]\n",
      "epoch:6 step:5458[D loss: 0.454209, acc: 63.28%, op_acc: 34.38%] [G loss: 0.899990]\n",
      "epoch:6 step:5459[D loss: 0.435533, acc: 62.50%, op_acc: 32.81%] [G loss: 0.991182]\n",
      "epoch:6 step:5460[D loss: 0.409892, acc: 70.31%, op_acc: 35.94%] [G loss: 0.876653]\n",
      "epoch:6 step:5461[D loss: 0.425295, acc: 69.53%, op_acc: 32.03%] [G loss: 1.044292]\n",
      "epoch:6 step:5462[D loss: 0.444598, acc: 59.38%, op_acc: 29.69%] [G loss: 0.877415]\n",
      "epoch:6 step:5463[D loss: 0.463583, acc: 58.59%, op_acc: 28.91%] [G loss: 0.888422]\n",
      "epoch:6 step:5464[D loss: 0.416261, acc: 64.84%, op_acc: 39.84%] [G loss: 0.865116]\n",
      "epoch:6 step:5465[D loss: 0.444528, acc: 59.38%, op_acc: 32.81%] [G loss: 0.898773]\n",
      "epoch:6 step:5466[D loss: 0.449067, acc: 53.12%, op_acc: 32.81%] [G loss: 0.820497]\n",
      "epoch:6 step:5467[D loss: 0.443310, acc: 62.50%, op_acc: 35.16%] [G loss: 0.929164]\n",
      "epoch:7 step:5468[D loss: 0.419480, acc: 64.06%, op_acc: 36.72%] [G loss: 1.005992]\n",
      "epoch:7 step:5469[D loss: 0.459213, acc: 53.12%, op_acc: 37.50%] [G loss: 0.928223]\n",
      "epoch:7 step:5470[D loss: 0.455557, acc: 59.38%, op_acc: 35.94%] [G loss: 0.951225]\n",
      "epoch:7 step:5471[D loss: 0.417671, acc: 61.72%, op_acc: 35.94%] [G loss: 0.919839]\n",
      "epoch:7 step:5472[D loss: 0.470906, acc: 54.69%, op_acc: 35.16%] [G loss: 1.000249]\n",
      "epoch:7 step:5473[D loss: 0.425333, acc: 63.28%, op_acc: 31.25%] [G loss: 0.934040]\n",
      "epoch:7 step:5474[D loss: 0.463378, acc: 52.34%, op_acc: 33.59%] [G loss: 0.949851]\n",
      "epoch:7 step:5475[D loss: 0.465471, acc: 53.12%, op_acc: 30.47%] [G loss: 0.879671]\n",
      "epoch:7 step:5476[D loss: 0.432197, acc: 63.28%, op_acc: 36.72%] [G loss: 0.860998]\n",
      "epoch:7 step:5477[D loss: 0.487173, acc: 54.69%, op_acc: 28.91%] [G loss: 0.845996]\n",
      "epoch:7 step:5478[D loss: 0.443349, acc: 60.16%, op_acc: 42.19%] [G loss: 0.877087]\n",
      "epoch:7 step:5479[D loss: 0.438383, acc: 67.19%, op_acc: 32.03%] [G loss: 0.978961]\n",
      "epoch:7 step:5480[D loss: 0.423540, acc: 67.19%, op_acc: 32.03%] [G loss: 1.027075]\n",
      "epoch:7 step:5481[D loss: 0.462861, acc: 60.16%, op_acc: 27.34%] [G loss: 0.963043]\n",
      "epoch:7 step:5482[D loss: 0.450214, acc: 58.59%, op_acc: 33.59%] [G loss: 0.928352]\n",
      "epoch:7 step:5483[D loss: 0.441271, acc: 60.16%, op_acc: 33.59%] [G loss: 0.940441]\n",
      "epoch:7 step:5484[D loss: 0.482021, acc: 49.22%, op_acc: 37.50%] [G loss: 0.835967]\n",
      "epoch:7 step:5485[D loss: 0.393175, acc: 69.53%, op_acc: 34.38%] [G loss: 0.946893]\n",
      "epoch:7 step:5486[D loss: 0.413073, acc: 65.62%, op_acc: 39.84%] [G loss: 0.906225]\n",
      "epoch:7 step:5487[D loss: 0.408352, acc: 67.19%, op_acc: 33.59%] [G loss: 1.050127]\n",
      "epoch:7 step:5488[D loss: 0.448391, acc: 67.97%, op_acc: 34.38%] [G loss: 0.902561]\n",
      "epoch:7 step:5489[D loss: 0.416495, acc: 65.62%, op_acc: 39.06%] [G loss: 0.940557]\n",
      "epoch:7 step:5490[D loss: 0.424495, acc: 64.84%, op_acc: 32.81%] [G loss: 1.000530]\n",
      "epoch:7 step:5491[D loss: 0.452473, acc: 58.59%, op_acc: 34.38%] [G loss: 1.000338]\n",
      "epoch:7 step:5492[D loss: 0.477424, acc: 56.25%, op_acc: 33.59%] [G loss: 0.895736]\n",
      "epoch:7 step:5493[D loss: 0.441314, acc: 61.72%, op_acc: 35.94%] [G loss: 0.957836]\n",
      "epoch:7 step:5494[D loss: 0.454254, acc: 60.94%, op_acc: 34.38%] [G loss: 0.935011]\n",
      "epoch:7 step:5495[D loss: 0.436677, acc: 57.03%, op_acc: 33.59%] [G loss: 0.858512]\n",
      "epoch:7 step:5496[D loss: 0.437891, acc: 58.59%, op_acc: 35.94%] [G loss: 0.849299]\n",
      "epoch:7 step:5497[D loss: 0.443300, acc: 54.69%, op_acc: 33.59%] [G loss: 0.946328]\n",
      "epoch:7 step:5498[D loss: 0.459259, acc: 64.06%, op_acc: 30.47%] [G loss: 0.958044]\n",
      "epoch:7 step:5499[D loss: 0.494655, acc: 51.56%, op_acc: 28.91%] [G loss: 0.929666]\n",
      "epoch:7 step:5500[D loss: 0.461999, acc: 55.47%, op_acc: 35.16%] [G loss: 0.919946]\n",
      "epoch:7 step:5501[D loss: 0.423597, acc: 61.72%, op_acc: 38.28%] [G loss: 0.937947]\n",
      "epoch:7 step:5502[D loss: 0.416989, acc: 70.31%, op_acc: 30.47%] [G loss: 1.012041]\n",
      "epoch:7 step:5503[D loss: 0.466000, acc: 52.34%, op_acc: 31.25%] [G loss: 0.930818]\n",
      "epoch:7 step:5504[D loss: 0.411371, acc: 69.53%, op_acc: 39.84%] [G loss: 0.968915]\n",
      "epoch:7 step:5505[D loss: 0.427868, acc: 60.16%, op_acc: 38.28%] [G loss: 0.914431]\n",
      "epoch:7 step:5506[D loss: 0.452346, acc: 50.78%, op_acc: 29.69%] [G loss: 0.893522]\n",
      "epoch:7 step:5507[D loss: 0.454121, acc: 57.81%, op_acc: 36.72%] [G loss: 0.977825]\n",
      "epoch:7 step:5508[D loss: 0.445404, acc: 60.16%, op_acc: 34.38%] [G loss: 0.997274]\n",
      "epoch:7 step:5509[D loss: 0.444353, acc: 60.16%, op_acc: 34.38%] [G loss: 0.906541]\n",
      "epoch:7 step:5510[D loss: 0.453529, acc: 61.72%, op_acc: 27.34%] [G loss: 0.957986]\n",
      "epoch:7 step:5511[D loss: 0.456828, acc: 55.47%, op_acc: 36.72%] [G loss: 0.889790]\n",
      "epoch:7 step:5512[D loss: 0.441410, acc: 57.03%, op_acc: 32.81%] [G loss: 0.894048]\n",
      "epoch:7 step:5513[D loss: 0.420177, acc: 59.38%, op_acc: 35.16%] [G loss: 0.964817]\n",
      "epoch:7 step:5514[D loss: 0.415924, acc: 69.53%, op_acc: 32.81%] [G loss: 0.971818]\n",
      "epoch:7 step:5515[D loss: 0.469022, acc: 61.72%, op_acc: 26.56%] [G loss: 0.996713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5516[D loss: 0.419399, acc: 63.28%, op_acc: 34.38%] [G loss: 0.983026]\n",
      "epoch:7 step:5517[D loss: 0.453589, acc: 59.38%, op_acc: 32.81%] [G loss: 0.845024]\n",
      "epoch:7 step:5518[D loss: 0.394085, acc: 74.22%, op_acc: 39.06%] [G loss: 0.981156]\n",
      "epoch:7 step:5519[D loss: 0.459245, acc: 52.34%, op_acc: 32.81%] [G loss: 0.873246]\n",
      "epoch:7 step:5520[D loss: 0.440851, acc: 64.06%, op_acc: 32.03%] [G loss: 0.892935]\n",
      "epoch:7 step:5521[D loss: 0.491198, acc: 53.91%, op_acc: 34.38%] [G loss: 0.903345]\n",
      "epoch:7 step:5522[D loss: 0.442091, acc: 60.94%, op_acc: 35.16%] [G loss: 0.917125]\n",
      "epoch:7 step:5523[D loss: 0.423353, acc: 62.50%, op_acc: 34.38%] [G loss: 0.910883]\n",
      "epoch:7 step:5524[D loss: 0.475543, acc: 57.03%, op_acc: 32.81%] [G loss: 0.852250]\n",
      "epoch:7 step:5525[D loss: 0.428375, acc: 54.69%, op_acc: 42.19%] [G loss: 0.891517]\n",
      "epoch:7 step:5526[D loss: 0.426778, acc: 67.19%, op_acc: 35.16%] [G loss: 0.878917]\n",
      "epoch:7 step:5527[D loss: 0.417732, acc: 66.41%, op_acc: 36.72%] [G loss: 0.902299]\n",
      "epoch:7 step:5528[D loss: 0.425462, acc: 66.41%, op_acc: 32.03%] [G loss: 0.902394]\n",
      "epoch:7 step:5529[D loss: 0.478187, acc: 57.03%, op_acc: 31.25%] [G loss: 0.960631]\n",
      "epoch:7 step:5530[D loss: 0.436514, acc: 64.06%, op_acc: 28.12%] [G loss: 0.898513]\n",
      "epoch:7 step:5531[D loss: 0.445182, acc: 64.84%, op_acc: 32.81%] [G loss: 0.967472]\n",
      "epoch:7 step:5532[D loss: 0.462662, acc: 57.03%, op_acc: 28.91%] [G loss: 0.941649]\n",
      "epoch:7 step:5533[D loss: 0.441127, acc: 64.06%, op_acc: 37.50%] [G loss: 0.940015]\n",
      "epoch:7 step:5534[D loss: 0.452243, acc: 63.28%, op_acc: 37.50%] [G loss: 0.955796]\n",
      "epoch:7 step:5535[D loss: 0.462105, acc: 57.81%, op_acc: 32.81%] [G loss: 0.904132]\n",
      "epoch:7 step:5536[D loss: 0.446202, acc: 51.56%, op_acc: 32.03%] [G loss: 0.831318]\n",
      "epoch:7 step:5537[D loss: 0.470588, acc: 55.47%, op_acc: 31.25%] [G loss: 0.896550]\n",
      "epoch:7 step:5538[D loss: 0.465356, acc: 63.28%, op_acc: 28.12%] [G loss: 0.845593]\n",
      "epoch:7 step:5539[D loss: 0.440747, acc: 56.25%, op_acc: 37.50%] [G loss: 0.916473]\n",
      "epoch:7 step:5540[D loss: 0.468608, acc: 53.12%, op_acc: 33.59%] [G loss: 0.901366]\n",
      "epoch:7 step:5541[D loss: 0.434247, acc: 56.25%, op_acc: 35.94%] [G loss: 0.895273]\n",
      "epoch:7 step:5542[D loss: 0.443819, acc: 59.38%, op_acc: 34.38%] [G loss: 1.030792]\n",
      "epoch:7 step:5543[D loss: 0.442825, acc: 68.75%, op_acc: 34.38%] [G loss: 0.984386]\n",
      "epoch:7 step:5544[D loss: 0.435781, acc: 60.94%, op_acc: 41.41%] [G loss: 0.896360]\n",
      "epoch:7 step:5545[D loss: 0.479617, acc: 57.03%, op_acc: 35.94%] [G loss: 0.897390]\n",
      "epoch:7 step:5546[D loss: 0.425301, acc: 61.72%, op_acc: 36.72%] [G loss: 0.871100]\n",
      "epoch:7 step:5547[D loss: 0.464227, acc: 64.84%, op_acc: 31.25%] [G loss: 0.915023]\n",
      "epoch:7 step:5548[D loss: 0.469085, acc: 57.03%, op_acc: 32.81%] [G loss: 0.863972]\n",
      "epoch:7 step:5549[D loss: 0.426726, acc: 63.28%, op_acc: 35.16%] [G loss: 0.932327]\n",
      "epoch:7 step:5550[D loss: 0.436627, acc: 60.16%, op_acc: 32.81%] [G loss: 0.989211]\n",
      "epoch:7 step:5551[D loss: 0.422826, acc: 65.62%, op_acc: 38.28%] [G loss: 0.918975]\n",
      "epoch:7 step:5552[D loss: 0.446489, acc: 67.97%, op_acc: 29.69%] [G loss: 0.934140]\n",
      "epoch:7 step:5553[D loss: 0.434750, acc: 63.28%, op_acc: 31.25%] [G loss: 0.942574]\n",
      "epoch:7 step:5554[D loss: 0.427836, acc: 66.41%, op_acc: 39.06%] [G loss: 0.971757]\n",
      "epoch:7 step:5555[D loss: 0.456282, acc: 57.03%, op_acc: 32.03%] [G loss: 0.895543]\n",
      "epoch:7 step:5556[D loss: 0.439563, acc: 64.06%, op_acc: 37.50%] [G loss: 0.907267]\n",
      "epoch:7 step:5557[D loss: 0.454504, acc: 54.69%, op_acc: 35.94%] [G loss: 1.008806]\n",
      "epoch:7 step:5558[D loss: 0.410292, acc: 67.97%, op_acc: 35.94%] [G loss: 0.929642]\n",
      "epoch:7 step:5559[D loss: 0.440966, acc: 63.28%, op_acc: 34.38%] [G loss: 0.867984]\n",
      "epoch:7 step:5560[D loss: 0.414218, acc: 64.84%, op_acc: 36.72%] [G loss: 0.873815]\n",
      "epoch:7 step:5561[D loss: 0.432139, acc: 63.28%, op_acc: 34.38%] [G loss: 0.858087]\n",
      "epoch:7 step:5562[D loss: 0.428824, acc: 67.97%, op_acc: 34.38%] [G loss: 0.949132]\n",
      "epoch:7 step:5563[D loss: 0.437279, acc: 67.19%, op_acc: 33.59%] [G loss: 0.922452]\n",
      "epoch:7 step:5564[D loss: 0.437694, acc: 54.69%, op_acc: 38.28%] [G loss: 0.948416]\n",
      "epoch:7 step:5565[D loss: 0.429339, acc: 67.19%, op_acc: 26.56%] [G loss: 0.966746]\n",
      "epoch:7 step:5566[D loss: 0.458871, acc: 54.69%, op_acc: 35.16%] [G loss: 0.915433]\n",
      "epoch:7 step:5567[D loss: 0.427907, acc: 63.28%, op_acc: 32.81%] [G loss: 0.865852]\n",
      "epoch:7 step:5568[D loss: 0.456298, acc: 57.03%, op_acc: 33.59%] [G loss: 0.908130]\n",
      "epoch:7 step:5569[D loss: 0.410246, acc: 64.84%, op_acc: 35.94%] [G loss: 0.911817]\n",
      "epoch:7 step:5570[D loss: 0.441388, acc: 52.34%, op_acc: 35.94%] [G loss: 0.955233]\n",
      "epoch:7 step:5571[D loss: 0.442989, acc: 60.16%, op_acc: 27.34%] [G loss: 0.886935]\n",
      "epoch:7 step:5572[D loss: 0.457102, acc: 59.38%, op_acc: 33.59%] [G loss: 0.834250]\n",
      "epoch:7 step:5573[D loss: 0.435256, acc: 57.81%, op_acc: 40.62%] [G loss: 0.878182]\n",
      "epoch:7 step:5574[D loss: 0.456524, acc: 56.25%, op_acc: 38.28%] [G loss: 0.897902]\n",
      "epoch:7 step:5575[D loss: 0.476333, acc: 54.69%, op_acc: 28.91%] [G loss: 0.942030]\n",
      "epoch:7 step:5576[D loss: 0.447840, acc: 55.47%, op_acc: 32.03%] [G loss: 0.940461]\n",
      "epoch:7 step:5577[D loss: 0.429111, acc: 64.06%, op_acc: 35.16%] [G loss: 0.916677]\n",
      "epoch:7 step:5578[D loss: 0.457802, acc: 58.59%, op_acc: 29.69%] [G loss: 0.905110]\n",
      "epoch:7 step:5579[D loss: 0.407783, acc: 68.75%, op_acc: 39.06%] [G loss: 0.976019]\n",
      "epoch:7 step:5580[D loss: 0.441647, acc: 61.72%, op_acc: 29.69%] [G loss: 0.987077]\n",
      "epoch:7 step:5581[D loss: 0.419752, acc: 62.50%, op_acc: 39.84%] [G loss: 0.905407]\n",
      "epoch:7 step:5582[D loss: 0.422664, acc: 53.12%, op_acc: 36.72%] [G loss: 0.978396]\n",
      "epoch:7 step:5583[D loss: 0.431028, acc: 69.53%, op_acc: 34.38%] [G loss: 0.843023]\n",
      "epoch:7 step:5584[D loss: 0.432651, acc: 59.38%, op_acc: 40.62%] [G loss: 0.962136]\n",
      "epoch:7 step:5585[D loss: 0.452128, acc: 59.38%, op_acc: 32.81%] [G loss: 0.896641]\n",
      "epoch:7 step:5586[D loss: 0.449691, acc: 57.81%, op_acc: 30.47%] [G loss: 0.898647]\n",
      "epoch:7 step:5587[D loss: 0.415754, acc: 69.53%, op_acc: 32.03%] [G loss: 0.862237]\n",
      "epoch:7 step:5588[D loss: 0.430566, acc: 63.28%, op_acc: 37.50%] [G loss: 1.009778]\n",
      "epoch:7 step:5589[D loss: 0.442547, acc: 55.47%, op_acc: 31.25%] [G loss: 0.908096]\n",
      "epoch:7 step:5590[D loss: 0.452621, acc: 57.03%, op_acc: 33.59%] [G loss: 0.973710]\n",
      "epoch:7 step:5591[D loss: 0.447962, acc: 61.72%, op_acc: 31.25%] [G loss: 0.883416]\n",
      "epoch:7 step:5592[D loss: 0.463766, acc: 60.94%, op_acc: 26.56%] [G loss: 0.958325]\n",
      "epoch:7 step:5593[D loss: 0.407894, acc: 71.88%, op_acc: 38.28%] [G loss: 0.926078]\n",
      "epoch:7 step:5594[D loss: 0.398086, acc: 68.75%, op_acc: 37.50%] [G loss: 0.918570]\n",
      "epoch:7 step:5595[D loss: 0.439200, acc: 55.47%, op_acc: 35.94%] [G loss: 0.920581]\n",
      "epoch:7 step:5596[D loss: 0.451426, acc: 56.25%, op_acc: 28.91%] [G loss: 0.972194]\n",
      "epoch:7 step:5597[D loss: 0.418157, acc: 64.84%, op_acc: 36.72%] [G loss: 0.954738]\n",
      "epoch:7 step:5598[D loss: 0.446817, acc: 57.81%, op_acc: 30.47%] [G loss: 0.978415]\n",
      "epoch:7 step:5599[D loss: 0.407114, acc: 65.62%, op_acc: 35.94%] [G loss: 0.992408]\n",
      "epoch:7 step:5600[D loss: 0.456701, acc: 65.62%, op_acc: 23.44%] [G loss: 0.967183]\n",
      "epoch:7 step:5601[D loss: 0.488798, acc: 50.00%, op_acc: 32.81%] [G loss: 0.878826]\n",
      "epoch:7 step:5602[D loss: 0.471453, acc: 53.12%, op_acc: 36.72%] [G loss: 0.909502]\n",
      "epoch:7 step:5603[D loss: 0.416420, acc: 67.97%, op_acc: 31.25%] [G loss: 0.979638]\n",
      "epoch:7 step:5604[D loss: 0.456882, acc: 60.16%, op_acc: 32.81%] [G loss: 0.929126]\n",
      "epoch:7 step:5605[D loss: 0.451449, acc: 62.50%, op_acc: 28.91%] [G loss: 0.988219]\n",
      "epoch:7 step:5606[D loss: 0.418334, acc: 62.50%, op_acc: 34.38%] [G loss: 0.925886]\n",
      "epoch:7 step:5607[D loss: 0.472213, acc: 59.38%, op_acc: 32.03%] [G loss: 0.937531]\n",
      "epoch:7 step:5608[D loss: 0.476838, acc: 57.81%, op_acc: 31.25%] [G loss: 0.985283]\n",
      "epoch:7 step:5609[D loss: 0.432969, acc: 62.50%, op_acc: 31.25%] [G loss: 0.937584]\n",
      "epoch:7 step:5610[D loss: 0.425431, acc: 64.84%, op_acc: 30.47%] [G loss: 0.932045]\n",
      "epoch:7 step:5611[D loss: 0.463405, acc: 51.56%, op_acc: 34.38%] [G loss: 0.887102]\n",
      "epoch:7 step:5612[D loss: 0.410780, acc: 67.97%, op_acc: 40.62%] [G loss: 0.964614]\n",
      "epoch:7 step:5613[D loss: 0.422842, acc: 64.06%, op_acc: 32.03%] [G loss: 0.913260]\n",
      "epoch:7 step:5614[D loss: 0.420666, acc: 63.28%, op_acc: 36.72%] [G loss: 0.862600]\n",
      "epoch:7 step:5615[D loss: 0.448005, acc: 64.06%, op_acc: 27.34%] [G loss: 0.888188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5616[D loss: 0.445082, acc: 53.91%, op_acc: 37.50%] [G loss: 0.872901]\n",
      "epoch:7 step:5617[D loss: 0.454825, acc: 57.03%, op_acc: 36.72%] [G loss: 0.930474]\n",
      "epoch:7 step:5618[D loss: 0.433985, acc: 57.81%, op_acc: 34.38%] [G loss: 0.945046]\n",
      "epoch:7 step:5619[D loss: 0.440996, acc: 65.62%, op_acc: 33.59%] [G loss: 0.905234]\n",
      "epoch:7 step:5620[D loss: 0.457978, acc: 57.81%, op_acc: 36.72%] [G loss: 1.036724]\n",
      "epoch:7 step:5621[D loss: 0.438842, acc: 57.03%, op_acc: 37.50%] [G loss: 1.021155]\n",
      "epoch:7 step:5622[D loss: 0.446190, acc: 56.25%, op_acc: 32.81%] [G loss: 0.837146]\n",
      "epoch:7 step:5623[D loss: 0.472316, acc: 49.22%, op_acc: 32.81%] [G loss: 0.877941]\n",
      "epoch:7 step:5624[D loss: 0.422542, acc: 67.19%, op_acc: 31.25%] [G loss: 0.940816]\n",
      "epoch:7 step:5625[D loss: 0.454946, acc: 53.91%, op_acc: 34.38%] [G loss: 0.921131]\n",
      "epoch:7 step:5626[D loss: 0.433283, acc: 65.62%, op_acc: 35.16%] [G loss: 0.870922]\n",
      "epoch:7 step:5627[D loss: 0.452445, acc: 58.59%, op_acc: 32.03%] [G loss: 0.997806]\n",
      "epoch:7 step:5628[D loss: 0.437948, acc: 61.72%, op_acc: 36.72%] [G loss: 1.046873]\n",
      "epoch:7 step:5629[D loss: 0.442091, acc: 60.16%, op_acc: 36.72%] [G loss: 0.929546]\n",
      "epoch:7 step:5630[D loss: 0.456684, acc: 57.81%, op_acc: 34.38%] [G loss: 0.892395]\n",
      "epoch:7 step:5631[D loss: 0.453351, acc: 60.94%, op_acc: 30.47%] [G loss: 0.940506]\n",
      "epoch:7 step:5632[D loss: 0.453359, acc: 57.03%, op_acc: 32.03%] [G loss: 0.893348]\n",
      "epoch:7 step:5633[D loss: 0.457214, acc: 57.03%, op_acc: 35.16%] [G loss: 0.883864]\n",
      "epoch:7 step:5634[D loss: 0.441489, acc: 60.94%, op_acc: 41.41%] [G loss: 0.976465]\n",
      "epoch:7 step:5635[D loss: 0.423930, acc: 57.03%, op_acc: 37.50%] [G loss: 1.014868]\n",
      "epoch:7 step:5636[D loss: 0.419133, acc: 67.19%, op_acc: 39.06%] [G loss: 0.944674]\n",
      "epoch:7 step:5637[D loss: 0.433789, acc: 58.59%, op_acc: 32.81%] [G loss: 0.936679]\n",
      "epoch:7 step:5638[D loss: 0.458162, acc: 61.72%, op_acc: 27.34%] [G loss: 0.956522]\n",
      "epoch:7 step:5639[D loss: 0.466345, acc: 50.78%, op_acc: 33.59%] [G loss: 0.909621]\n",
      "epoch:7 step:5640[D loss: 0.438949, acc: 60.94%, op_acc: 31.25%] [G loss: 0.922772]\n",
      "epoch:7 step:5641[D loss: 0.473786, acc: 56.25%, op_acc: 36.72%] [G loss: 0.939082]\n",
      "epoch:7 step:5642[D loss: 0.408722, acc: 67.19%, op_acc: 39.84%] [G loss: 0.884630]\n",
      "epoch:7 step:5643[D loss: 0.418074, acc: 66.41%, op_acc: 37.50%] [G loss: 0.919985]\n",
      "epoch:7 step:5644[D loss: 0.441509, acc: 53.91%, op_acc: 34.38%] [G loss: 0.855732]\n",
      "epoch:7 step:5645[D loss: 0.432841, acc: 61.72%, op_acc: 34.38%] [G loss: 0.971601]\n",
      "epoch:7 step:5646[D loss: 0.427978, acc: 64.84%, op_acc: 35.94%] [G loss: 0.980995]\n",
      "epoch:7 step:5647[D loss: 0.461676, acc: 61.72%, op_acc: 35.16%] [G loss: 0.927731]\n",
      "epoch:7 step:5648[D loss: 0.407550, acc: 62.50%, op_acc: 34.38%] [G loss: 0.972247]\n",
      "epoch:7 step:5649[D loss: 0.427696, acc: 62.50%, op_acc: 35.16%] [G loss: 0.916645]\n",
      "epoch:7 step:5650[D loss: 0.396705, acc: 68.75%, op_acc: 34.38%] [G loss: 0.913869]\n",
      "epoch:7 step:5651[D loss: 0.438119, acc: 62.50%, op_acc: 36.72%] [G loss: 1.010677]\n",
      "epoch:7 step:5652[D loss: 0.423059, acc: 71.88%, op_acc: 39.84%] [G loss: 1.052883]\n",
      "epoch:7 step:5653[D loss: 0.436334, acc: 60.16%, op_acc: 35.94%] [G loss: 1.055000]\n",
      "epoch:7 step:5654[D loss: 0.467937, acc: 57.03%, op_acc: 31.25%] [G loss: 0.981599]\n",
      "epoch:7 step:5655[D loss: 0.398749, acc: 70.31%, op_acc: 36.72%] [G loss: 1.022441]\n",
      "epoch:7 step:5656[D loss: 0.440346, acc: 62.50%, op_acc: 35.16%] [G loss: 0.933017]\n",
      "epoch:7 step:5657[D loss: 0.451383, acc: 60.94%, op_acc: 31.25%] [G loss: 0.848581]\n",
      "epoch:7 step:5658[D loss: 0.407664, acc: 60.94%, op_acc: 39.84%] [G loss: 0.923361]\n",
      "epoch:7 step:5659[D loss: 0.414472, acc: 70.31%, op_acc: 39.06%] [G loss: 0.950323]\n",
      "epoch:7 step:5660[D loss: 0.464555, acc: 69.53%, op_acc: 29.69%] [G loss: 1.037130]\n",
      "epoch:7 step:5661[D loss: 0.432575, acc: 62.50%, op_acc: 32.03%] [G loss: 0.962305]\n",
      "epoch:7 step:5662[D loss: 0.440948, acc: 60.94%, op_acc: 32.81%] [G loss: 1.003105]\n",
      "epoch:7 step:5663[D loss: 0.426365, acc: 64.84%, op_acc: 36.72%] [G loss: 1.022395]\n",
      "epoch:7 step:5664[D loss: 0.443879, acc: 60.16%, op_acc: 34.38%] [G loss: 0.987616]\n",
      "epoch:7 step:5665[D loss: 0.428038, acc: 66.41%, op_acc: 37.50%] [G loss: 0.880376]\n",
      "epoch:7 step:5666[D loss: 0.456534, acc: 55.47%, op_acc: 35.16%] [G loss: 0.932359]\n",
      "epoch:7 step:5667[D loss: 0.436050, acc: 59.38%, op_acc: 33.59%] [G loss: 0.940989]\n",
      "epoch:7 step:5668[D loss: 0.418823, acc: 62.50%, op_acc: 35.94%] [G loss: 0.936862]\n",
      "epoch:7 step:5669[D loss: 0.433844, acc: 62.50%, op_acc: 33.59%] [G loss: 0.968993]\n",
      "epoch:7 step:5670[D loss: 0.449234, acc: 67.19%, op_acc: 34.38%] [G loss: 0.931528]\n",
      "epoch:7 step:5671[D loss: 0.406308, acc: 67.97%, op_acc: 36.72%] [G loss: 0.978282]\n",
      "epoch:7 step:5672[D loss: 0.457164, acc: 59.38%, op_acc: 31.25%] [G loss: 0.901951]\n",
      "epoch:7 step:5673[D loss: 0.428895, acc: 57.81%, op_acc: 35.94%] [G loss: 0.934835]\n",
      "epoch:7 step:5674[D loss: 0.480800, acc: 49.22%, op_acc: 36.72%] [G loss: 0.905840]\n",
      "epoch:7 step:5675[D loss: 0.464630, acc: 59.38%, op_acc: 31.25%] [G loss: 0.921074]\n",
      "epoch:7 step:5676[D loss: 0.452563, acc: 55.47%, op_acc: 39.06%] [G loss: 0.841846]\n",
      "epoch:7 step:5677[D loss: 0.473723, acc: 52.34%, op_acc: 32.03%] [G loss: 0.869205]\n",
      "epoch:7 step:5678[D loss: 0.393262, acc: 67.97%, op_acc: 39.84%] [G loss: 1.001462]\n",
      "epoch:7 step:5679[D loss: 0.445562, acc: 57.03%, op_acc: 32.03%] [G loss: 0.908660]\n",
      "epoch:7 step:5680[D loss: 0.429962, acc: 60.94%, op_acc: 35.94%] [G loss: 1.021228]\n",
      "epoch:7 step:5681[D loss: 0.442023, acc: 64.84%, op_acc: 35.16%] [G loss: 0.997277]\n",
      "epoch:7 step:5682[D loss: 0.451536, acc: 59.38%, op_acc: 25.00%] [G loss: 0.960474]\n",
      "epoch:7 step:5683[D loss: 0.451730, acc: 58.59%, op_acc: 31.25%] [G loss: 0.850133]\n",
      "epoch:7 step:5684[D loss: 0.390105, acc: 71.09%, op_acc: 37.50%] [G loss: 1.037782]\n",
      "epoch:7 step:5685[D loss: 0.465746, acc: 61.72%, op_acc: 33.59%] [G loss: 0.931737]\n",
      "epoch:7 step:5686[D loss: 0.408231, acc: 61.72%, op_acc: 32.03%] [G loss: 1.008561]\n",
      "epoch:7 step:5687[D loss: 0.477820, acc: 54.69%, op_acc: 36.72%] [G loss: 0.843820]\n",
      "epoch:7 step:5688[D loss: 0.451863, acc: 55.47%, op_acc: 31.25%] [G loss: 0.904419]\n",
      "epoch:7 step:5689[D loss: 0.457874, acc: 61.72%, op_acc: 29.69%] [G loss: 0.898234]\n",
      "epoch:7 step:5690[D loss: 0.434549, acc: 59.38%, op_acc: 35.94%] [G loss: 0.827021]\n",
      "epoch:7 step:5691[D loss: 0.439270, acc: 59.38%, op_acc: 33.59%] [G loss: 0.806290]\n",
      "epoch:7 step:5692[D loss: 0.443813, acc: 60.16%, op_acc: 31.25%] [G loss: 0.867922]\n",
      "epoch:7 step:5693[D loss: 0.440155, acc: 59.38%, op_acc: 32.81%] [G loss: 0.861584]\n",
      "epoch:7 step:5694[D loss: 0.436186, acc: 64.84%, op_acc: 32.03%] [G loss: 0.874719]\n",
      "epoch:7 step:5695[D loss: 0.443820, acc: 59.38%, op_acc: 35.16%] [G loss: 0.963121]\n",
      "epoch:7 step:5696[D loss: 0.448649, acc: 60.94%, op_acc: 31.25%] [G loss: 0.857336]\n",
      "epoch:7 step:5697[D loss: 0.448805, acc: 61.72%, op_acc: 29.69%] [G loss: 0.898269]\n",
      "epoch:7 step:5698[D loss: 0.395597, acc: 65.62%, op_acc: 35.94%] [G loss: 1.063339]\n",
      "epoch:7 step:5699[D loss: 0.458079, acc: 59.38%, op_acc: 33.59%] [G loss: 0.929744]\n",
      "epoch:7 step:5700[D loss: 0.387553, acc: 82.03%, op_acc: 34.38%] [G loss: 0.941323]\n",
      "epoch:7 step:5701[D loss: 0.483138, acc: 50.78%, op_acc: 29.69%] [G loss: 0.916006]\n",
      "epoch:7 step:5702[D loss: 0.445832, acc: 60.94%, op_acc: 39.06%] [G loss: 0.973707]\n",
      "epoch:7 step:5703[D loss: 0.456470, acc: 58.59%, op_acc: 33.59%] [G loss: 0.995886]\n",
      "epoch:7 step:5704[D loss: 0.440192, acc: 57.03%, op_acc: 39.84%] [G loss: 1.020695]\n",
      "epoch:7 step:5705[D loss: 0.430059, acc: 59.38%, op_acc: 35.94%] [G loss: 1.032267]\n",
      "epoch:7 step:5706[D loss: 0.394671, acc: 75.78%, op_acc: 37.50%] [G loss: 0.951291]\n",
      "epoch:7 step:5707[D loss: 0.447069, acc: 63.28%, op_acc: 32.81%] [G loss: 0.944786]\n",
      "epoch:7 step:5708[D loss: 0.447183, acc: 57.81%, op_acc: 35.16%] [G loss: 0.908928]\n",
      "epoch:7 step:5709[D loss: 0.439211, acc: 60.94%, op_acc: 35.94%] [G loss: 0.942065]\n",
      "epoch:7 step:5710[D loss: 0.428936, acc: 60.94%, op_acc: 32.03%] [G loss: 0.968942]\n",
      "epoch:7 step:5711[D loss: 0.467889, acc: 62.50%, op_acc: 27.34%] [G loss: 0.906879]\n",
      "epoch:7 step:5712[D loss: 0.414576, acc: 60.16%, op_acc: 36.72%] [G loss: 1.038867]\n",
      "epoch:7 step:5713[D loss: 0.467220, acc: 57.03%, op_acc: 32.03%] [G loss: 1.021302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5714[D loss: 0.459491, acc: 56.25%, op_acc: 35.94%] [G loss: 0.939622]\n",
      "epoch:7 step:5715[D loss: 0.469271, acc: 54.69%, op_acc: 28.91%] [G loss: 0.968651]\n",
      "epoch:7 step:5716[D loss: 0.462130, acc: 60.16%, op_acc: 30.47%] [G loss: 0.998242]\n",
      "epoch:7 step:5717[D loss: 0.468751, acc: 57.03%, op_acc: 27.34%] [G loss: 0.979188]\n",
      "epoch:7 step:5718[D loss: 0.481003, acc: 50.78%, op_acc: 36.72%] [G loss: 0.887560]\n",
      "epoch:7 step:5719[D loss: 0.432125, acc: 60.94%, op_acc: 38.28%] [G loss: 1.001169]\n",
      "epoch:7 step:5720[D loss: 0.441543, acc: 60.94%, op_acc: 33.59%] [G loss: 0.825265]\n",
      "epoch:7 step:5721[D loss: 0.426185, acc: 67.19%, op_acc: 30.47%] [G loss: 0.996190]\n",
      "epoch:7 step:5722[D loss: 0.468958, acc: 56.25%, op_acc: 32.81%] [G loss: 0.871631]\n",
      "epoch:7 step:5723[D loss: 0.455712, acc: 52.34%, op_acc: 35.94%] [G loss: 0.907681]\n",
      "epoch:7 step:5724[D loss: 0.433629, acc: 69.53%, op_acc: 27.34%] [G loss: 0.925908]\n",
      "epoch:7 step:5725[D loss: 0.462901, acc: 59.38%, op_acc: 35.94%] [G loss: 0.952200]\n",
      "epoch:7 step:5726[D loss: 0.430840, acc: 67.19%, op_acc: 29.69%] [G loss: 0.896816]\n",
      "epoch:7 step:5727[D loss: 0.449992, acc: 57.03%, op_acc: 34.38%] [G loss: 0.976857]\n",
      "epoch:7 step:5728[D loss: 0.418551, acc: 67.19%, op_acc: 35.94%] [G loss: 1.049908]\n",
      "epoch:7 step:5729[D loss: 0.414875, acc: 69.53%, op_acc: 35.94%] [G loss: 1.050191]\n",
      "epoch:7 step:5730[D loss: 0.448739, acc: 57.03%, op_acc: 32.03%] [G loss: 0.895631]\n",
      "epoch:7 step:5731[D loss: 0.429824, acc: 64.06%, op_acc: 35.94%] [G loss: 0.878749]\n",
      "epoch:7 step:5732[D loss: 0.440593, acc: 53.91%, op_acc: 36.72%] [G loss: 0.957138]\n",
      "epoch:7 step:5733[D loss: 0.423552, acc: 67.19%, op_acc: 35.16%] [G loss: 1.051683]\n",
      "epoch:7 step:5734[D loss: 0.471881, acc: 52.34%, op_acc: 30.47%] [G loss: 0.900866]\n",
      "epoch:7 step:5735[D loss: 0.413643, acc: 63.28%, op_acc: 37.50%] [G loss: 0.964393]\n",
      "epoch:7 step:5736[D loss: 0.417241, acc: 64.84%, op_acc: 39.84%] [G loss: 0.985216]\n",
      "epoch:7 step:5737[D loss: 0.435973, acc: 62.50%, op_acc: 35.94%] [G loss: 0.902733]\n",
      "epoch:7 step:5738[D loss: 0.448273, acc: 55.47%, op_acc: 39.06%] [G loss: 0.993924]\n",
      "epoch:7 step:5739[D loss: 0.443410, acc: 57.03%, op_acc: 39.06%] [G loss: 0.919537]\n",
      "epoch:7 step:5740[D loss: 0.451840, acc: 52.34%, op_acc: 34.38%] [G loss: 0.888899]\n",
      "epoch:7 step:5741[D loss: 0.443459, acc: 60.94%, op_acc: 33.59%] [G loss: 0.949307]\n",
      "epoch:7 step:5742[D loss: 0.443916, acc: 61.72%, op_acc: 29.69%] [G loss: 0.942364]\n",
      "epoch:7 step:5743[D loss: 0.462025, acc: 57.03%, op_acc: 32.81%] [G loss: 0.891237]\n",
      "epoch:7 step:5744[D loss: 0.459295, acc: 61.72%, op_acc: 33.59%] [G loss: 0.889884]\n",
      "epoch:7 step:5745[D loss: 0.462345, acc: 53.91%, op_acc: 35.16%] [G loss: 1.030046]\n",
      "epoch:7 step:5746[D loss: 0.446935, acc: 65.62%, op_acc: 36.72%] [G loss: 0.848013]\n",
      "epoch:7 step:5747[D loss: 0.424812, acc: 60.16%, op_acc: 36.72%] [G loss: 0.998744]\n",
      "epoch:7 step:5748[D loss: 0.448523, acc: 59.38%, op_acc: 29.69%] [G loss: 1.011950]\n",
      "epoch:7 step:5749[D loss: 0.451650, acc: 60.94%, op_acc: 35.94%] [G loss: 0.881984]\n",
      "epoch:7 step:5750[D loss: 0.427312, acc: 63.28%, op_acc: 43.75%] [G loss: 0.952058]\n",
      "epoch:7 step:5751[D loss: 0.439561, acc: 57.81%, op_acc: 34.38%] [G loss: 0.965027]\n",
      "epoch:7 step:5752[D loss: 0.429080, acc: 60.94%, op_acc: 29.69%] [G loss: 0.893773]\n",
      "epoch:7 step:5753[D loss: 0.447598, acc: 60.94%, op_acc: 32.81%] [G loss: 0.937341]\n",
      "epoch:7 step:5754[D loss: 0.465813, acc: 50.00%, op_acc: 33.59%] [G loss: 0.907336]\n",
      "epoch:7 step:5755[D loss: 0.443307, acc: 59.38%, op_acc: 32.03%] [G loss: 0.917692]\n",
      "epoch:7 step:5756[D loss: 0.436693, acc: 64.84%, op_acc: 28.12%] [G loss: 0.873302]\n",
      "epoch:7 step:5757[D loss: 0.444849, acc: 64.06%, op_acc: 36.72%] [G loss: 0.829986]\n",
      "epoch:7 step:5758[D loss: 0.442301, acc: 62.50%, op_acc: 39.84%] [G loss: 1.018773]\n",
      "epoch:7 step:5759[D loss: 0.440342, acc: 67.97%, op_acc: 35.94%] [G loss: 0.969900]\n",
      "epoch:7 step:5760[D loss: 0.427018, acc: 65.62%, op_acc: 33.59%] [G loss: 0.922745]\n",
      "epoch:7 step:5761[D loss: 0.436238, acc: 64.84%, op_acc: 35.94%] [G loss: 0.896541]\n",
      "epoch:7 step:5762[D loss: 0.447557, acc: 61.72%, op_acc: 28.12%] [G loss: 0.847709]\n",
      "epoch:7 step:5763[D loss: 0.461763, acc: 55.47%, op_acc: 32.81%] [G loss: 0.883401]\n",
      "epoch:7 step:5764[D loss: 0.476391, acc: 55.47%, op_acc: 33.59%] [G loss: 0.952506]\n",
      "epoch:7 step:5765[D loss: 0.429292, acc: 64.06%, op_acc: 37.50%] [G loss: 0.907420]\n",
      "epoch:7 step:5766[D loss: 0.461622, acc: 53.91%, op_acc: 39.06%] [G loss: 0.910531]\n",
      "epoch:7 step:5767[D loss: 0.472708, acc: 55.47%, op_acc: 32.03%] [G loss: 0.878005]\n",
      "epoch:7 step:5768[D loss: 0.444871, acc: 60.94%, op_acc: 34.38%] [G loss: 0.864626]\n",
      "epoch:7 step:5769[D loss: 0.408076, acc: 69.53%, op_acc: 32.03%] [G loss: 0.954300]\n",
      "epoch:7 step:5770[D loss: 0.428549, acc: 60.94%, op_acc: 35.94%] [G loss: 0.938041]\n",
      "epoch:7 step:5771[D loss: 0.431062, acc: 57.81%, op_acc: 40.62%] [G loss: 0.919781]\n",
      "epoch:7 step:5772[D loss: 0.429716, acc: 57.03%, op_acc: 35.94%] [G loss: 0.950286]\n",
      "epoch:7 step:5773[D loss: 0.453101, acc: 63.28%, op_acc: 35.94%] [G loss: 0.940065]\n",
      "epoch:7 step:5774[D loss: 0.421615, acc: 66.41%, op_acc: 37.50%] [G loss: 0.905162]\n",
      "epoch:7 step:5775[D loss: 0.461222, acc: 54.69%, op_acc: 30.47%] [G loss: 0.978569]\n",
      "epoch:7 step:5776[D loss: 0.464411, acc: 60.16%, op_acc: 29.69%] [G loss: 0.933455]\n",
      "epoch:7 step:5777[D loss: 0.444750, acc: 59.38%, op_acc: 34.38%] [G loss: 0.860781]\n",
      "epoch:7 step:5778[D loss: 0.458050, acc: 57.81%, op_acc: 36.72%] [G loss: 0.871212]\n",
      "epoch:7 step:5779[D loss: 0.466126, acc: 57.81%, op_acc: 35.16%] [G loss: 0.949204]\n",
      "epoch:7 step:5780[D loss: 0.469121, acc: 51.56%, op_acc: 32.81%] [G loss: 0.918916]\n",
      "epoch:7 step:5781[D loss: 0.473707, acc: 53.91%, op_acc: 33.59%] [G loss: 0.895692]\n",
      "epoch:7 step:5782[D loss: 0.481581, acc: 49.22%, op_acc: 35.16%] [G loss: 0.897287]\n",
      "epoch:7 step:5783[D loss: 0.471623, acc: 46.88%, op_acc: 29.69%] [G loss: 0.849270]\n",
      "epoch:7 step:5784[D loss: 0.473693, acc: 57.03%, op_acc: 30.47%] [G loss: 0.880640]\n",
      "epoch:7 step:5785[D loss: 0.436862, acc: 64.06%, op_acc: 27.34%] [G loss: 0.913557]\n",
      "epoch:7 step:5786[D loss: 0.456251, acc: 54.69%, op_acc: 30.47%] [G loss: 0.858237]\n",
      "epoch:7 step:5787[D loss: 0.449061, acc: 57.03%, op_acc: 28.91%] [G loss: 0.969258]\n",
      "epoch:7 step:5788[D loss: 0.463187, acc: 59.38%, op_acc: 35.16%] [G loss: 0.922159]\n",
      "epoch:7 step:5789[D loss: 0.449331, acc: 60.94%, op_acc: 32.81%] [G loss: 1.014562]\n",
      "epoch:7 step:5790[D loss: 0.430612, acc: 64.06%, op_acc: 37.50%] [G loss: 0.856309]\n",
      "epoch:7 step:5791[D loss: 0.424532, acc: 66.41%, op_acc: 30.47%] [G loss: 0.985275]\n",
      "epoch:7 step:5792[D loss: 0.439152, acc: 62.50%, op_acc: 34.38%] [G loss: 0.990989]\n",
      "epoch:7 step:5793[D loss: 0.421005, acc: 66.41%, op_acc: 32.03%] [G loss: 1.092532]\n",
      "epoch:7 step:5794[D loss: 0.386029, acc: 67.97%, op_acc: 44.53%] [G loss: 1.078944]\n",
      "epoch:7 step:5795[D loss: 0.441414, acc: 66.41%, op_acc: 29.69%] [G loss: 0.992456]\n",
      "epoch:7 step:5796[D loss: 0.431398, acc: 57.03%, op_acc: 35.16%] [G loss: 0.878739]\n",
      "epoch:7 step:5797[D loss: 0.422767, acc: 58.59%, op_acc: 33.59%] [G loss: 0.923700]\n",
      "epoch:7 step:5798[D loss: 0.438068, acc: 57.81%, op_acc: 32.03%] [G loss: 0.857798]\n",
      "epoch:7 step:5799[D loss: 0.430585, acc: 57.03%, op_acc: 35.16%] [G loss: 0.860477]\n",
      "epoch:7 step:5800[D loss: 0.451040, acc: 55.47%, op_acc: 32.03%] [G loss: 0.845251]\n",
      "epoch:7 step:5801[D loss: 0.439589, acc: 52.34%, op_acc: 35.16%] [G loss: 0.877078]\n",
      "epoch:7 step:5802[D loss: 0.432601, acc: 67.97%, op_acc: 32.03%] [G loss: 0.875264]\n",
      "epoch:7 step:5803[D loss: 0.479825, acc: 55.47%, op_acc: 34.38%] [G loss: 0.928777]\n",
      "epoch:7 step:5804[D loss: 0.435876, acc: 59.38%, op_acc: 32.81%] [G loss: 0.945440]\n",
      "epoch:7 step:5805[D loss: 0.413286, acc: 59.38%, op_acc: 39.06%] [G loss: 0.904318]\n",
      "epoch:7 step:5806[D loss: 0.429440, acc: 64.84%, op_acc: 35.16%] [G loss: 0.915399]\n",
      "epoch:7 step:5807[D loss: 0.431346, acc: 69.53%, op_acc: 33.59%] [G loss: 0.921195]\n",
      "epoch:7 step:5808[D loss: 0.460937, acc: 59.38%, op_acc: 31.25%] [G loss: 0.898603]\n",
      "epoch:7 step:5809[D loss: 0.436134, acc: 60.94%, op_acc: 31.25%] [G loss: 0.839597]\n",
      "epoch:7 step:5810[D loss: 0.434886, acc: 59.38%, op_acc: 32.81%] [G loss: 0.866125]\n",
      "epoch:7 step:5811[D loss: 0.454863, acc: 56.25%, op_acc: 28.91%] [G loss: 0.853737]\n",
      "epoch:7 step:5812[D loss: 0.456137, acc: 53.12%, op_acc: 29.69%] [G loss: 0.822073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5813[D loss: 0.460697, acc: 53.91%, op_acc: 30.47%] [G loss: 0.806874]\n",
      "epoch:7 step:5814[D loss: 0.444894, acc: 56.25%, op_acc: 32.81%] [G loss: 0.902727]\n",
      "epoch:7 step:5815[D loss: 0.461201, acc: 60.16%, op_acc: 32.03%] [G loss: 0.904798]\n",
      "epoch:7 step:5816[D loss: 0.429990, acc: 62.50%, op_acc: 34.38%] [G loss: 0.915521]\n",
      "epoch:7 step:5817[D loss: 0.420077, acc: 67.19%, op_acc: 36.72%] [G loss: 0.948977]\n",
      "epoch:7 step:5818[D loss: 0.450588, acc: 65.62%, op_acc: 34.38%] [G loss: 0.938607]\n",
      "epoch:7 step:5819[D loss: 0.424597, acc: 66.41%, op_acc: 37.50%] [G loss: 0.986272]\n",
      "epoch:7 step:5820[D loss: 0.422014, acc: 56.25%, op_acc: 36.72%] [G loss: 0.989561]\n",
      "epoch:7 step:5821[D loss: 0.431151, acc: 65.62%, op_acc: 33.59%] [G loss: 0.995590]\n",
      "epoch:7 step:5822[D loss: 0.459506, acc: 61.72%, op_acc: 32.03%] [G loss: 0.985729]\n",
      "epoch:7 step:5823[D loss: 0.451243, acc: 62.50%, op_acc: 32.81%] [G loss: 0.879722]\n",
      "epoch:7 step:5824[D loss: 0.420732, acc: 66.41%, op_acc: 33.59%] [G loss: 1.008173]\n",
      "epoch:7 step:5825[D loss: 0.471775, acc: 53.12%, op_acc: 33.59%] [G loss: 0.937886]\n",
      "epoch:7 step:5826[D loss: 0.433075, acc: 58.59%, op_acc: 35.16%] [G loss: 0.915206]\n",
      "epoch:7 step:5827[D loss: 0.433448, acc: 64.84%, op_acc: 28.91%] [G loss: 1.015553]\n",
      "epoch:7 step:5828[D loss: 0.415694, acc: 66.41%, op_acc: 36.72%] [G loss: 0.997294]\n",
      "epoch:7 step:5829[D loss: 0.406910, acc: 65.62%, op_acc: 41.41%] [G loss: 0.972523]\n",
      "epoch:7 step:5830[D loss: 0.471267, acc: 54.69%, op_acc: 35.16%] [G loss: 0.986811]\n",
      "epoch:7 step:5831[D loss: 0.447493, acc: 53.12%, op_acc: 36.72%] [G loss: 1.031246]\n",
      "epoch:7 step:5832[D loss: 0.405984, acc: 67.19%, op_acc: 44.53%] [G loss: 1.015476]\n",
      "epoch:7 step:5833[D loss: 0.434982, acc: 58.59%, op_acc: 39.06%] [G loss: 0.929958]\n",
      "epoch:7 step:5834[D loss: 0.476161, acc: 58.59%, op_acc: 27.34%] [G loss: 0.931531]\n",
      "epoch:7 step:5835[D loss: 0.426065, acc: 69.53%, op_acc: 32.03%] [G loss: 0.988968]\n",
      "epoch:7 step:5836[D loss: 0.447130, acc: 53.12%, op_acc: 39.06%] [G loss: 0.891768]\n",
      "epoch:7 step:5837[D loss: 0.447375, acc: 61.72%, op_acc: 28.91%] [G loss: 0.978056]\n",
      "epoch:7 step:5838[D loss: 0.380745, acc: 67.19%, op_acc: 42.97%] [G loss: 0.921322]\n",
      "epoch:7 step:5839[D loss: 0.461567, acc: 53.12%, op_acc: 32.03%] [G loss: 0.993861]\n",
      "epoch:7 step:5840[D loss: 0.423576, acc: 59.38%, op_acc: 39.84%] [G loss: 1.015087]\n",
      "epoch:7 step:5841[D loss: 0.439310, acc: 60.94%, op_acc: 32.03%] [G loss: 0.921147]\n",
      "epoch:7 step:5842[D loss: 0.430360, acc: 62.50%, op_acc: 37.50%] [G loss: 0.921755]\n",
      "epoch:7 step:5843[D loss: 0.427027, acc: 61.72%, op_acc: 31.25%] [G loss: 0.973720]\n",
      "epoch:7 step:5844[D loss: 0.437043, acc: 57.81%, op_acc: 33.59%] [G loss: 0.846221]\n",
      "epoch:7 step:5845[D loss: 0.450674, acc: 60.16%, op_acc: 34.38%] [G loss: 0.938584]\n",
      "epoch:7 step:5846[D loss: 0.420567, acc: 62.50%, op_acc: 36.72%] [G loss: 0.928959]\n",
      "epoch:7 step:5847[D loss: 0.430489, acc: 62.50%, op_acc: 35.16%] [G loss: 0.950831]\n",
      "epoch:7 step:5848[D loss: 0.434483, acc: 69.53%, op_acc: 31.25%] [G loss: 0.987801]\n",
      "epoch:7 step:5849[D loss: 0.402842, acc: 68.75%, op_acc: 32.81%] [G loss: 0.947076]\n",
      "epoch:7 step:5850[D loss: 0.443858, acc: 65.62%, op_acc: 35.94%] [G loss: 0.939058]\n",
      "epoch:7 step:5851[D loss: 0.423127, acc: 62.50%, op_acc: 35.16%] [G loss: 0.948000]\n",
      "epoch:7 step:5852[D loss: 0.418465, acc: 61.72%, op_acc: 35.16%] [G loss: 0.899238]\n",
      "epoch:7 step:5853[D loss: 0.423261, acc: 60.16%, op_acc: 44.53%] [G loss: 1.009253]\n",
      "epoch:7 step:5854[D loss: 0.445719, acc: 59.38%, op_acc: 39.06%] [G loss: 0.951931]\n",
      "epoch:7 step:5855[D loss: 0.447436, acc: 67.97%, op_acc: 29.69%] [G loss: 0.982224]\n",
      "epoch:7 step:5856[D loss: 0.453266, acc: 61.72%, op_acc: 35.16%] [G loss: 0.895740]\n",
      "epoch:7 step:5857[D loss: 0.456676, acc: 53.91%, op_acc: 32.03%] [G loss: 0.896803]\n",
      "epoch:7 step:5858[D loss: 0.411973, acc: 60.16%, op_acc: 41.41%] [G loss: 0.928668]\n",
      "epoch:7 step:5859[D loss: 0.405206, acc: 60.94%, op_acc: 43.75%] [G loss: 0.990692]\n",
      "epoch:7 step:5860[D loss: 0.444435, acc: 53.91%, op_acc: 42.97%] [G loss: 0.930128]\n",
      "epoch:7 step:5861[D loss: 0.422861, acc: 65.62%, op_acc: 34.38%] [G loss: 0.971154]\n",
      "epoch:7 step:5862[D loss: 0.440381, acc: 64.84%, op_acc: 27.34%] [G loss: 0.865522]\n",
      "epoch:7 step:5863[D loss: 0.412402, acc: 67.97%, op_acc: 39.06%] [G loss: 0.860176]\n",
      "epoch:7 step:5864[D loss: 0.428934, acc: 61.72%, op_acc: 36.72%] [G loss: 0.904642]\n",
      "epoch:7 step:5865[D loss: 0.455492, acc: 57.81%, op_acc: 28.91%] [G loss: 0.923455]\n",
      "epoch:7 step:5866[D loss: 0.412253, acc: 62.50%, op_acc: 41.41%] [G loss: 0.917906]\n",
      "epoch:7 step:5867[D loss: 0.429909, acc: 65.62%, op_acc: 39.06%] [G loss: 1.046161]\n",
      "epoch:7 step:5868[D loss: 0.415907, acc: 66.41%, op_acc: 35.94%] [G loss: 0.967133]\n",
      "epoch:7 step:5869[D loss: 0.432522, acc: 69.53%, op_acc: 35.94%] [G loss: 0.882210]\n",
      "epoch:7 step:5870[D loss: 0.416415, acc: 60.94%, op_acc: 35.94%] [G loss: 1.031909]\n",
      "epoch:7 step:5871[D loss: 0.399510, acc: 64.84%, op_acc: 37.50%] [G loss: 0.956974]\n",
      "epoch:7 step:5872[D loss: 0.437109, acc: 64.06%, op_acc: 34.38%] [G loss: 0.985207]\n",
      "epoch:7 step:5873[D loss: 0.460240, acc: 58.59%, op_acc: 32.03%] [G loss: 0.871046]\n",
      "epoch:7 step:5874[D loss: 0.430556, acc: 66.41%, op_acc: 28.91%] [G loss: 0.980691]\n",
      "epoch:7 step:5875[D loss: 0.421508, acc: 64.06%, op_acc: 40.62%] [G loss: 0.925767]\n",
      "epoch:7 step:5876[D loss: 0.442598, acc: 55.47%, op_acc: 39.84%] [G loss: 0.973543]\n",
      "epoch:7 step:5877[D loss: 0.409943, acc: 65.62%, op_acc: 39.06%] [G loss: 0.876870]\n",
      "epoch:7 step:5878[D loss: 0.448142, acc: 60.94%, op_acc: 28.91%] [G loss: 0.956573]\n",
      "epoch:7 step:5879[D loss: 0.442633, acc: 53.91%, op_acc: 28.91%] [G loss: 0.950444]\n",
      "epoch:7 step:5880[D loss: 0.451893, acc: 61.72%, op_acc: 33.59%] [G loss: 0.887674]\n",
      "epoch:7 step:5881[D loss: 0.437620, acc: 67.19%, op_acc: 34.38%] [G loss: 0.970579]\n",
      "epoch:7 step:5882[D loss: 0.428220, acc: 63.28%, op_acc: 32.81%] [G loss: 0.996846]\n",
      "epoch:7 step:5883[D loss: 0.440085, acc: 57.81%, op_acc: 35.94%] [G loss: 0.980702]\n",
      "epoch:7 step:5884[D loss: 0.442931, acc: 62.50%, op_acc: 35.16%] [G loss: 0.970077]\n",
      "epoch:7 step:5885[D loss: 0.405039, acc: 67.97%, op_acc: 39.06%] [G loss: 0.925419]\n",
      "epoch:7 step:5886[D loss: 0.469461, acc: 60.94%, op_acc: 28.12%] [G loss: 0.995367]\n",
      "epoch:7 step:5887[D loss: 0.440268, acc: 59.38%, op_acc: 31.25%] [G loss: 0.894669]\n",
      "epoch:7 step:5888[D loss: 0.463176, acc: 54.69%, op_acc: 39.06%] [G loss: 0.844615]\n",
      "epoch:7 step:5889[D loss: 0.431806, acc: 54.69%, op_acc: 35.94%] [G loss: 0.922436]\n",
      "epoch:7 step:5890[D loss: 0.449514, acc: 56.25%, op_acc: 34.38%] [G loss: 0.920965]\n",
      "epoch:7 step:5891[D loss: 0.443902, acc: 63.28%, op_acc: 34.38%] [G loss: 0.945542]\n",
      "epoch:7 step:5892[D loss: 0.444798, acc: 53.91%, op_acc: 39.84%] [G loss: 0.892587]\n",
      "epoch:7 step:5893[D loss: 0.476455, acc: 51.56%, op_acc: 30.47%] [G loss: 0.850764]\n",
      "epoch:7 step:5894[D loss: 0.422353, acc: 62.50%, op_acc: 32.81%] [G loss: 0.948294]\n",
      "epoch:7 step:5895[D loss: 0.486967, acc: 49.22%, op_acc: 30.47%] [G loss: 0.967861]\n",
      "epoch:7 step:5896[D loss: 0.447533, acc: 64.06%, op_acc: 28.91%] [G loss: 0.881260]\n",
      "epoch:7 step:5897[D loss: 0.417248, acc: 64.06%, op_acc: 35.94%] [G loss: 0.883004]\n",
      "epoch:7 step:5898[D loss: 0.473067, acc: 59.38%, op_acc: 35.94%] [G loss: 0.874943]\n",
      "epoch:7 step:5899[D loss: 0.442128, acc: 50.78%, op_acc: 39.84%] [G loss: 0.883710]\n",
      "epoch:7 step:5900[D loss: 0.418858, acc: 65.62%, op_acc: 33.59%] [G loss: 0.895460]\n",
      "epoch:7 step:5901[D loss: 0.450198, acc: 57.81%, op_acc: 36.72%] [G loss: 0.920384]\n",
      "epoch:7 step:5902[D loss: 0.453206, acc: 52.34%, op_acc: 34.38%] [G loss: 0.926996]\n",
      "epoch:7 step:5903[D loss: 0.462330, acc: 56.25%, op_acc: 33.59%] [G loss: 0.948790]\n",
      "epoch:7 step:5904[D loss: 0.464435, acc: 51.56%, op_acc: 35.16%] [G loss: 0.819032]\n",
      "epoch:7 step:5905[D loss: 0.441269, acc: 59.38%, op_acc: 28.12%] [G loss: 0.834300]\n",
      "epoch:7 step:5906[D loss: 0.404764, acc: 66.41%, op_acc: 38.28%] [G loss: 0.910874]\n",
      "epoch:7 step:5907[D loss: 0.457766, acc: 50.78%, op_acc: 37.50%] [G loss: 0.895114]\n",
      "epoch:7 step:5908[D loss: 0.410344, acc: 72.66%, op_acc: 34.38%] [G loss: 1.062622]\n",
      "epoch:7 step:5909[D loss: 0.428898, acc: 61.72%, op_acc: 29.69%] [G loss: 0.921116]\n",
      "epoch:7 step:5910[D loss: 0.426847, acc: 66.41%, op_acc: 33.59%] [G loss: 1.034996]\n",
      "epoch:7 step:5911[D loss: 0.449673, acc: 56.25%, op_acc: 36.72%] [G loss: 0.911265]\n",
      "epoch:7 step:5912[D loss: 0.475869, acc: 54.69%, op_acc: 30.47%] [G loss: 0.959387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:5913[D loss: 0.402694, acc: 73.44%, op_acc: 35.94%] [G loss: 0.956511]\n",
      "epoch:7 step:5914[D loss: 0.463330, acc: 60.16%, op_acc: 32.81%] [G loss: 1.021018]\n",
      "epoch:7 step:5915[D loss: 0.448974, acc: 57.03%, op_acc: 36.72%] [G loss: 1.059259]\n",
      "epoch:7 step:5916[D loss: 0.401794, acc: 72.66%, op_acc: 32.81%] [G loss: 0.895869]\n",
      "epoch:7 step:5917[D loss: 0.445011, acc: 58.59%, op_acc: 25.78%] [G loss: 0.981513]\n",
      "epoch:7 step:5918[D loss: 0.440471, acc: 60.94%, op_acc: 35.16%] [G loss: 1.000959]\n",
      "epoch:7 step:5919[D loss: 0.432748, acc: 62.50%, op_acc: 35.16%] [G loss: 1.040480]\n",
      "epoch:7 step:5920[D loss: 0.406169, acc: 64.84%, op_acc: 35.94%] [G loss: 0.920251]\n",
      "epoch:7 step:5921[D loss: 0.438669, acc: 60.94%, op_acc: 32.03%] [G loss: 0.975514]\n",
      "epoch:7 step:5922[D loss: 0.487084, acc: 48.44%, op_acc: 28.91%] [G loss: 0.873160]\n",
      "epoch:7 step:5923[D loss: 0.443012, acc: 64.06%, op_acc: 33.59%] [G loss: 0.977678]\n",
      "epoch:7 step:5924[D loss: 0.447968, acc: 60.94%, op_acc: 31.25%] [G loss: 1.014168]\n",
      "epoch:7 step:5925[D loss: 0.414046, acc: 62.50%, op_acc: 38.28%] [G loss: 0.928230]\n",
      "epoch:7 step:5926[D loss: 0.430732, acc: 55.47%, op_acc: 40.62%] [G loss: 0.984652]\n",
      "epoch:7 step:5927[D loss: 0.405678, acc: 68.75%, op_acc: 35.94%] [G loss: 1.026260]\n",
      "epoch:7 step:5928[D loss: 0.428395, acc: 64.06%, op_acc: 32.81%] [G loss: 0.973485]\n",
      "epoch:7 step:5929[D loss: 0.431972, acc: 64.84%, op_acc: 32.81%] [G loss: 1.050026]\n",
      "epoch:7 step:5930[D loss: 0.446694, acc: 59.38%, op_acc: 32.03%] [G loss: 0.937450]\n",
      "epoch:7 step:5931[D loss: 0.445404, acc: 60.94%, op_acc: 32.81%] [G loss: 0.978385]\n",
      "epoch:7 step:5932[D loss: 0.421835, acc: 66.41%, op_acc: 31.25%] [G loss: 0.935326]\n",
      "epoch:7 step:5933[D loss: 0.410729, acc: 65.62%, op_acc: 39.06%] [G loss: 0.960711]\n",
      "epoch:7 step:5934[D loss: 0.450771, acc: 57.03%, op_acc: 28.12%] [G loss: 0.953320]\n",
      "epoch:7 step:5935[D loss: 0.405131, acc: 64.84%, op_acc: 37.50%] [G loss: 0.937817]\n",
      "epoch:7 step:5936[D loss: 0.402733, acc: 68.75%, op_acc: 35.94%] [G loss: 0.974039]\n",
      "epoch:7 step:5937[D loss: 0.403875, acc: 70.31%, op_acc: 39.06%] [G loss: 0.867723]\n",
      "epoch:7 step:5938[D loss: 0.481724, acc: 53.91%, op_acc: 34.38%] [G loss: 0.893576]\n",
      "epoch:7 step:5939[D loss: 0.427332, acc: 57.03%, op_acc: 31.25%] [G loss: 0.896398]\n",
      "epoch:7 step:5940[D loss: 0.432332, acc: 60.16%, op_acc: 39.06%] [G loss: 0.947195]\n",
      "epoch:7 step:5941[D loss: 0.427980, acc: 68.75%, op_acc: 34.38%] [G loss: 0.957204]\n",
      "epoch:7 step:5942[D loss: 0.460605, acc: 48.44%, op_acc: 37.50%] [G loss: 0.897991]\n",
      "epoch:7 step:5943[D loss: 0.430725, acc: 68.75%, op_acc: 28.91%] [G loss: 0.972904]\n",
      "epoch:7 step:5944[D loss: 0.416080, acc: 62.50%, op_acc: 39.84%] [G loss: 0.951555]\n",
      "epoch:7 step:5945[D loss: 0.439892, acc: 58.59%, op_acc: 39.06%] [G loss: 0.971713]\n",
      "epoch:7 step:5946[D loss: 0.440788, acc: 59.38%, op_acc: 31.25%] [G loss: 0.959815]\n",
      "epoch:7 step:5947[D loss: 0.507834, acc: 48.44%, op_acc: 29.69%] [G loss: 0.865285]\n",
      "epoch:7 step:5948[D loss: 0.449554, acc: 61.72%, op_acc: 32.03%] [G loss: 0.920407]\n",
      "epoch:7 step:5949[D loss: 0.466364, acc: 60.16%, op_acc: 33.59%] [G loss: 0.913702]\n",
      "epoch:7 step:5950[D loss: 0.437361, acc: 67.19%, op_acc: 37.50%] [G loss: 0.973889]\n",
      "epoch:7 step:5951[D loss: 0.409707, acc: 67.97%, op_acc: 40.62%] [G loss: 0.934995]\n",
      "epoch:7 step:5952[D loss: 0.413068, acc: 62.50%, op_acc: 36.72%] [G loss: 0.911938]\n",
      "epoch:7 step:5953[D loss: 0.433606, acc: 60.16%, op_acc: 39.06%] [G loss: 0.868008]\n",
      "epoch:7 step:5954[D loss: 0.470499, acc: 53.12%, op_acc: 28.12%] [G loss: 0.897283]\n",
      "epoch:7 step:5955[D loss: 0.445830, acc: 67.19%, op_acc: 30.47%] [G loss: 0.953664]\n",
      "epoch:7 step:5956[D loss: 0.444171, acc: 58.59%, op_acc: 38.28%] [G loss: 0.934689]\n",
      "epoch:7 step:5957[D loss: 0.419410, acc: 61.72%, op_acc: 39.06%] [G loss: 0.974683]\n",
      "epoch:7 step:5958[D loss: 0.493673, acc: 54.69%, op_acc: 25.78%] [G loss: 0.961310]\n",
      "epoch:7 step:5959[D loss: 0.449523, acc: 57.03%, op_acc: 32.03%] [G loss: 0.922187]\n",
      "epoch:7 step:5960[D loss: 0.425896, acc: 64.06%, op_acc: 32.81%] [G loss: 0.992155]\n",
      "epoch:7 step:5961[D loss: 0.416955, acc: 63.28%, op_acc: 39.06%] [G loss: 0.964804]\n",
      "epoch:7 step:5962[D loss: 0.418412, acc: 67.19%, op_acc: 37.50%] [G loss: 0.992259]\n",
      "epoch:7 step:5963[D loss: 0.454714, acc: 57.81%, op_acc: 32.03%] [G loss: 0.932622]\n",
      "epoch:7 step:5964[D loss: 0.429033, acc: 61.72%, op_acc: 36.72%] [G loss: 0.925448]\n",
      "epoch:7 step:5965[D loss: 0.476911, acc: 56.25%, op_acc: 30.47%] [G loss: 0.859038]\n",
      "epoch:7 step:5966[D loss: 0.466959, acc: 58.59%, op_acc: 35.16%] [G loss: 0.921447]\n",
      "epoch:7 step:5967[D loss: 0.409642, acc: 71.09%, op_acc: 35.94%] [G loss: 0.941303]\n",
      "epoch:7 step:5968[D loss: 0.449864, acc: 59.38%, op_acc: 31.25%] [G loss: 0.994482]\n",
      "epoch:7 step:5969[D loss: 0.419780, acc: 65.62%, op_acc: 32.81%] [G loss: 0.872638]\n",
      "epoch:7 step:5970[D loss: 0.411791, acc: 69.53%, op_acc: 35.94%] [G loss: 0.944405]\n",
      "epoch:7 step:5971[D loss: 0.477703, acc: 52.34%, op_acc: 34.38%] [G loss: 0.928311]\n",
      "epoch:7 step:5972[D loss: 0.432372, acc: 68.75%, op_acc: 34.38%] [G loss: 0.948711]\n",
      "epoch:7 step:5973[D loss: 0.440326, acc: 64.06%, op_acc: 31.25%] [G loss: 0.909408]\n",
      "epoch:7 step:5974[D loss: 0.429705, acc: 60.94%, op_acc: 38.28%] [G loss: 0.907929]\n",
      "epoch:7 step:5975[D loss: 0.463484, acc: 54.69%, op_acc: 28.12%] [G loss: 0.853363]\n",
      "epoch:7 step:5976[D loss: 0.488631, acc: 50.78%, op_acc: 33.59%] [G loss: 0.799617]\n",
      "epoch:7 step:5977[D loss: 0.461221, acc: 53.91%, op_acc: 31.25%] [G loss: 0.887845]\n",
      "epoch:7 step:5978[D loss: 0.431448, acc: 60.16%, op_acc: 35.16%] [G loss: 0.876270]\n",
      "epoch:7 step:5979[D loss: 0.462630, acc: 60.94%, op_acc: 35.94%] [G loss: 0.958237]\n",
      "epoch:7 step:5980[D loss: 0.471521, acc: 56.25%, op_acc: 29.69%] [G loss: 0.879825]\n",
      "epoch:7 step:5981[D loss: 0.447691, acc: 61.72%, op_acc: 31.25%] [G loss: 0.909072]\n",
      "epoch:7 step:5982[D loss: 0.451028, acc: 60.94%, op_acc: 27.34%] [G loss: 0.948849]\n",
      "epoch:7 step:5983[D loss: 0.398448, acc: 74.22%, op_acc: 41.41%] [G loss: 1.066648]\n",
      "epoch:7 step:5984[D loss: 0.467881, acc: 59.38%, op_acc: 29.69%] [G loss: 1.019949]\n",
      "epoch:7 step:5985[D loss: 0.453264, acc: 59.38%, op_acc: 33.59%] [G loss: 0.913280]\n",
      "epoch:7 step:5986[D loss: 0.421380, acc: 64.06%, op_acc: 36.72%] [G loss: 0.904885]\n",
      "epoch:7 step:5987[D loss: 0.418105, acc: 64.84%, op_acc: 36.72%] [G loss: 0.959143]\n",
      "epoch:7 step:5988[D loss: 0.451297, acc: 59.38%, op_acc: 32.03%] [G loss: 0.915340]\n",
      "epoch:7 step:5989[D loss: 0.453014, acc: 54.69%, op_acc: 33.59%] [G loss: 1.009562]\n",
      "epoch:7 step:5990[D loss: 0.465143, acc: 55.47%, op_acc: 36.72%] [G loss: 0.972797]\n",
      "epoch:7 step:5991[D loss: 0.477842, acc: 51.56%, op_acc: 29.69%] [G loss: 0.985982]\n",
      "epoch:7 step:5992[D loss: 0.446404, acc: 63.28%, op_acc: 29.69%] [G loss: 1.021616]\n",
      "epoch:7 step:5993[D loss: 0.463780, acc: 59.38%, op_acc: 28.91%] [G loss: 0.942670]\n",
      "epoch:7 step:5994[D loss: 0.423608, acc: 67.97%, op_acc: 36.72%] [G loss: 1.121019]\n",
      "epoch:7 step:5995[D loss: 0.444720, acc: 57.03%, op_acc: 35.94%] [G loss: 0.953914]\n",
      "epoch:7 step:5996[D loss: 0.453471, acc: 56.25%, op_acc: 34.38%] [G loss: 0.977900]\n",
      "epoch:7 step:5997[D loss: 0.421390, acc: 66.41%, op_acc: 33.59%] [G loss: 0.983494]\n",
      "epoch:7 step:5998[D loss: 0.436124, acc: 64.06%, op_acc: 35.94%] [G loss: 0.970141]\n",
      "epoch:7 step:5999[D loss: 0.443648, acc: 64.06%, op_acc: 39.84%] [G loss: 0.963183]\n",
      "epoch:7 step:6000[D loss: 0.454503, acc: 53.91%, op_acc: 38.28%] [G loss: 0.907890]\n",
      "epoch:7 step:6001[D loss: 0.461636, acc: 58.59%, op_acc: 33.59%] [G loss: 0.812966]\n",
      "epoch:7 step:6002[D loss: 0.428811, acc: 63.28%, op_acc: 33.59%] [G loss: 0.917988]\n",
      "epoch:7 step:6003[D loss: 0.418721, acc: 60.94%, op_acc: 42.19%] [G loss: 0.973068]\n",
      "epoch:7 step:6004[D loss: 0.478913, acc: 57.81%, op_acc: 28.91%] [G loss: 0.924652]\n",
      "epoch:7 step:6005[D loss: 0.431000, acc: 64.84%, op_acc: 35.16%] [G loss: 1.014472]\n",
      "epoch:7 step:6006[D loss: 0.464221, acc: 54.69%, op_acc: 32.03%] [G loss: 0.939368]\n",
      "epoch:7 step:6007[D loss: 0.430564, acc: 61.72%, op_acc: 33.59%] [G loss: 0.930900]\n",
      "epoch:7 step:6008[D loss: 0.430619, acc: 57.81%, op_acc: 36.72%] [G loss: 0.908318]\n",
      "epoch:7 step:6009[D loss: 0.427459, acc: 65.62%, op_acc: 35.94%] [G loss: 0.986539]\n",
      "epoch:7 step:6010[D loss: 0.467078, acc: 60.94%, op_acc: 37.50%] [G loss: 0.935987]\n",
      "epoch:7 step:6011[D loss: 0.463563, acc: 52.34%, op_acc: 32.81%] [G loss: 0.784981]\n",
      "epoch:7 step:6012[D loss: 0.408417, acc: 69.53%, op_acc: 33.59%] [G loss: 0.966874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6013[D loss: 0.458958, acc: 54.69%, op_acc: 38.28%] [G loss: 0.907239]\n",
      "epoch:7 step:6014[D loss: 0.452012, acc: 60.94%, op_acc: 37.50%] [G loss: 1.034346]\n",
      "epoch:7 step:6015[D loss: 0.438938, acc: 66.41%, op_acc: 32.81%] [G loss: 0.943782]\n",
      "epoch:7 step:6016[D loss: 0.480113, acc: 46.09%, op_acc: 30.47%] [G loss: 0.848909]\n",
      "epoch:7 step:6017[D loss: 0.453365, acc: 53.91%, op_acc: 34.38%] [G loss: 0.905111]\n",
      "epoch:7 step:6018[D loss: 0.429490, acc: 60.94%, op_acc: 35.94%] [G loss: 1.027863]\n",
      "epoch:7 step:6019[D loss: 0.485737, acc: 56.25%, op_acc: 25.78%] [G loss: 0.965746]\n",
      "epoch:7 step:6020[D loss: 0.417351, acc: 67.19%, op_acc: 33.59%] [G loss: 0.966990]\n",
      "epoch:7 step:6021[D loss: 0.441112, acc: 64.84%, op_acc: 27.34%] [G loss: 0.917398]\n",
      "epoch:7 step:6022[D loss: 0.433396, acc: 57.03%, op_acc: 35.16%] [G loss: 0.925904]\n",
      "epoch:7 step:6023[D loss: 0.428112, acc: 60.94%, op_acc: 36.72%] [G loss: 0.961265]\n",
      "epoch:7 step:6024[D loss: 0.430614, acc: 63.28%, op_acc: 28.12%] [G loss: 1.025382]\n",
      "epoch:7 step:6025[D loss: 0.469304, acc: 58.59%, op_acc: 33.59%] [G loss: 0.954119]\n",
      "epoch:7 step:6026[D loss: 0.413112, acc: 63.28%, op_acc: 35.94%] [G loss: 1.009042]\n",
      "epoch:7 step:6027[D loss: 0.432638, acc: 59.38%, op_acc: 34.38%] [G loss: 1.011941]\n",
      "epoch:7 step:6028[D loss: 0.425119, acc: 63.28%, op_acc: 35.16%] [G loss: 0.862751]\n",
      "epoch:7 step:6029[D loss: 0.437418, acc: 60.16%, op_acc: 32.03%] [G loss: 0.945004]\n",
      "epoch:7 step:6030[D loss: 0.446801, acc: 60.16%, op_acc: 30.47%] [G loss: 0.952512]\n",
      "epoch:7 step:6031[D loss: 0.417865, acc: 62.50%, op_acc: 35.94%] [G loss: 0.899174]\n",
      "epoch:7 step:6032[D loss: 0.420470, acc: 62.50%, op_acc: 39.06%] [G loss: 0.982816]\n",
      "epoch:7 step:6033[D loss: 0.483290, acc: 49.22%, op_acc: 34.38%] [G loss: 0.999578]\n",
      "epoch:7 step:6034[D loss: 0.471170, acc: 59.38%, op_acc: 32.03%] [G loss: 0.936844]\n",
      "epoch:7 step:6035[D loss: 0.444547, acc: 56.25%, op_acc: 32.03%] [G loss: 0.939898]\n",
      "epoch:7 step:6036[D loss: 0.458058, acc: 58.59%, op_acc: 32.03%] [G loss: 0.844816]\n",
      "epoch:7 step:6037[D loss: 0.486643, acc: 42.97%, op_acc: 30.47%] [G loss: 0.869151]\n",
      "epoch:7 step:6038[D loss: 0.455010, acc: 50.78%, op_acc: 37.50%] [G loss: 0.913155]\n",
      "epoch:7 step:6039[D loss: 0.423318, acc: 59.38%, op_acc: 34.38%] [G loss: 0.884622]\n",
      "epoch:7 step:6040[D loss: 0.450899, acc: 55.47%, op_acc: 35.16%] [G loss: 0.868660]\n",
      "epoch:7 step:6041[D loss: 0.473760, acc: 51.56%, op_acc: 31.25%] [G loss: 0.923031]\n",
      "epoch:7 step:6042[D loss: 0.461289, acc: 53.12%, op_acc: 27.34%] [G loss: 0.929110]\n",
      "epoch:7 step:6043[D loss: 0.440937, acc: 61.72%, op_acc: 34.38%] [G loss: 0.966513]\n",
      "epoch:7 step:6044[D loss: 0.449803, acc: 58.59%, op_acc: 36.72%] [G loss: 0.935702]\n",
      "epoch:7 step:6045[D loss: 0.448043, acc: 60.94%, op_acc: 33.59%] [G loss: 0.953310]\n",
      "epoch:7 step:6046[D loss: 0.383501, acc: 70.31%, op_acc: 39.84%] [G loss: 1.001652]\n",
      "epoch:7 step:6047[D loss: 0.451962, acc: 55.47%, op_acc: 31.25%] [G loss: 0.976367]\n",
      "epoch:7 step:6048[D loss: 0.435680, acc: 60.16%, op_acc: 35.94%] [G loss: 0.875942]\n",
      "epoch:7 step:6049[D loss: 0.475610, acc: 58.59%, op_acc: 29.69%] [G loss: 0.905387]\n",
      "epoch:7 step:6050[D loss: 0.445755, acc: 53.91%, op_acc: 34.38%] [G loss: 0.944562]\n",
      "epoch:7 step:6051[D loss: 0.461019, acc: 60.16%, op_acc: 30.47%] [G loss: 0.959231]\n",
      "epoch:7 step:6052[D loss: 0.418983, acc: 62.50%, op_acc: 32.81%] [G loss: 0.917859]\n",
      "epoch:7 step:6053[D loss: 0.477875, acc: 58.59%, op_acc: 30.47%] [G loss: 0.930110]\n",
      "epoch:7 step:6054[D loss: 0.429523, acc: 65.62%, op_acc: 36.72%] [G loss: 0.951846]\n",
      "epoch:7 step:6055[D loss: 0.431406, acc: 60.94%, op_acc: 37.50%] [G loss: 0.891472]\n",
      "epoch:7 step:6056[D loss: 0.414094, acc: 69.53%, op_acc: 32.03%] [G loss: 0.972975]\n",
      "epoch:7 step:6057[D loss: 0.460748, acc: 53.12%, op_acc: 32.81%] [G loss: 0.905004]\n",
      "epoch:7 step:6058[D loss: 0.463033, acc: 55.47%, op_acc: 32.03%] [G loss: 0.903476]\n",
      "epoch:7 step:6059[D loss: 0.434122, acc: 59.38%, op_acc: 39.06%] [G loss: 0.927396]\n",
      "epoch:7 step:6060[D loss: 0.434755, acc: 65.62%, op_acc: 34.38%] [G loss: 0.959088]\n",
      "epoch:7 step:6061[D loss: 0.441554, acc: 60.94%, op_acc: 32.03%] [G loss: 0.928439]\n",
      "epoch:7 step:6062[D loss: 0.472774, acc: 57.03%, op_acc: 23.44%] [G loss: 0.915361]\n",
      "epoch:7 step:6063[D loss: 0.429608, acc: 66.41%, op_acc: 31.25%] [G loss: 0.869654]\n",
      "epoch:7 step:6064[D loss: 0.408306, acc: 62.50%, op_acc: 36.72%] [G loss: 0.886742]\n",
      "epoch:7 step:6065[D loss: 0.420555, acc: 66.41%, op_acc: 41.41%] [G loss: 0.975594]\n",
      "epoch:7 step:6066[D loss: 0.446382, acc: 62.50%, op_acc: 27.34%] [G loss: 0.940912]\n",
      "epoch:7 step:6067[D loss: 0.415362, acc: 65.62%, op_acc: 40.62%] [G loss: 0.963360]\n",
      "epoch:7 step:6068[D loss: 0.433929, acc: 64.84%, op_acc: 34.38%] [G loss: 0.945640]\n",
      "epoch:7 step:6069[D loss: 0.427172, acc: 55.47%, op_acc: 39.84%] [G loss: 0.932481]\n",
      "epoch:7 step:6070[D loss: 0.431116, acc: 57.81%, op_acc: 35.16%] [G loss: 0.829834]\n",
      "epoch:7 step:6071[D loss: 0.446485, acc: 60.16%, op_acc: 30.47%] [G loss: 1.058317]\n",
      "epoch:7 step:6072[D loss: 0.454768, acc: 62.50%, op_acc: 32.03%] [G loss: 0.920834]\n",
      "epoch:7 step:6073[D loss: 0.432234, acc: 60.94%, op_acc: 31.25%] [G loss: 0.920814]\n",
      "epoch:7 step:6074[D loss: 0.428175, acc: 55.47%, op_acc: 38.28%] [G loss: 0.914406]\n",
      "epoch:7 step:6075[D loss: 0.415116, acc: 61.72%, op_acc: 41.41%] [G loss: 0.908266]\n",
      "epoch:7 step:6076[D loss: 0.449571, acc: 59.38%, op_acc: 31.25%] [G loss: 0.912373]\n",
      "epoch:7 step:6077[D loss: 0.442365, acc: 57.03%, op_acc: 35.16%] [G loss: 0.878060]\n",
      "epoch:7 step:6078[D loss: 0.421680, acc: 68.75%, op_acc: 36.72%] [G loss: 0.903713]\n",
      "epoch:7 step:6079[D loss: 0.420381, acc: 67.97%, op_acc: 35.94%] [G loss: 0.999307]\n",
      "epoch:7 step:6080[D loss: 0.444339, acc: 57.81%, op_acc: 34.38%] [G loss: 0.885942]\n",
      "epoch:7 step:6081[D loss: 0.416464, acc: 67.97%, op_acc: 38.28%] [G loss: 0.968068]\n",
      "epoch:7 step:6082[D loss: 0.444817, acc: 62.50%, op_acc: 37.50%] [G loss: 0.958787]\n",
      "epoch:7 step:6083[D loss: 0.445720, acc: 61.72%, op_acc: 34.38%] [G loss: 0.978119]\n",
      "epoch:7 step:6084[D loss: 0.456659, acc: 62.50%, op_acc: 29.69%] [G loss: 0.956661]\n",
      "epoch:7 step:6085[D loss: 0.413375, acc: 68.75%, op_acc: 40.62%] [G loss: 0.926637]\n",
      "epoch:7 step:6086[D loss: 0.482059, acc: 55.47%, op_acc: 31.25%] [G loss: 0.923042]\n",
      "epoch:7 step:6087[D loss: 0.433012, acc: 64.84%, op_acc: 32.81%] [G loss: 1.003968]\n",
      "epoch:7 step:6088[D loss: 0.431278, acc: 64.06%, op_acc: 33.59%] [G loss: 0.939204]\n",
      "epoch:7 step:6089[D loss: 0.450606, acc: 61.72%, op_acc: 28.12%] [G loss: 0.885157]\n",
      "epoch:7 step:6090[D loss: 0.462861, acc: 53.91%, op_acc: 32.03%] [G loss: 0.902225]\n",
      "epoch:7 step:6091[D loss: 0.420403, acc: 62.50%, op_acc: 32.81%] [G loss: 0.896768]\n",
      "epoch:7 step:6092[D loss: 0.454338, acc: 57.03%, op_acc: 35.16%] [G loss: 0.776838]\n",
      "epoch:7 step:6093[D loss: 0.442553, acc: 53.91%, op_acc: 39.84%] [G loss: 0.964718]\n",
      "epoch:7 step:6094[D loss: 0.453080, acc: 50.00%, op_acc: 36.72%] [G loss: 0.895280]\n",
      "epoch:7 step:6095[D loss: 0.460755, acc: 55.47%, op_acc: 33.59%] [G loss: 1.017139]\n",
      "epoch:7 step:6096[D loss: 0.466765, acc: 57.81%, op_acc: 31.25%] [G loss: 0.889971]\n",
      "epoch:7 step:6097[D loss: 0.420543, acc: 64.06%, op_acc: 39.84%] [G loss: 0.937356]\n",
      "epoch:7 step:6098[D loss: 0.475150, acc: 52.34%, op_acc: 30.47%] [G loss: 0.814369]\n",
      "epoch:7 step:6099[D loss: 0.429775, acc: 67.19%, op_acc: 28.12%] [G loss: 1.006795]\n",
      "epoch:7 step:6100[D loss: 0.452539, acc: 61.72%, op_acc: 33.59%] [G loss: 0.930423]\n",
      "epoch:7 step:6101[D loss: 0.404205, acc: 64.06%, op_acc: 40.62%] [G loss: 0.928201]\n",
      "epoch:7 step:6102[D loss: 0.453101, acc: 58.59%, op_acc: 28.12%] [G loss: 0.919479]\n",
      "epoch:7 step:6103[D loss: 0.412568, acc: 67.19%, op_acc: 40.62%] [G loss: 0.985895]\n",
      "epoch:7 step:6104[D loss: 0.421825, acc: 65.62%, op_acc: 33.59%] [G loss: 0.917247]\n",
      "epoch:7 step:6105[D loss: 0.474908, acc: 53.91%, op_acc: 28.91%] [G loss: 0.922145]\n",
      "epoch:7 step:6106[D loss: 0.458986, acc: 60.16%, op_acc: 32.03%] [G loss: 0.939787]\n",
      "epoch:7 step:6107[D loss: 0.440936, acc: 63.28%, op_acc: 36.72%] [G loss: 0.924508]\n",
      "epoch:7 step:6108[D loss: 0.461594, acc: 64.06%, op_acc: 31.25%] [G loss: 0.976969]\n",
      "epoch:7 step:6109[D loss: 0.448552, acc: 60.94%, op_acc: 35.16%] [G loss: 1.006964]\n",
      "epoch:7 step:6110[D loss: 0.451879, acc: 57.81%, op_acc: 38.28%] [G loss: 0.962591]\n",
      "epoch:7 step:6111[D loss: 0.403265, acc: 64.84%, op_acc: 40.62%] [G loss: 0.897200]\n",
      "epoch:7 step:6112[D loss: 0.440112, acc: 58.59%, op_acc: 33.59%] [G loss: 1.076219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6113[D loss: 0.465455, acc: 62.50%, op_acc: 32.81%] [G loss: 1.016230]\n",
      "epoch:7 step:6114[D loss: 0.431516, acc: 56.25%, op_acc: 35.16%] [G loss: 0.961198]\n",
      "epoch:7 step:6115[D loss: 0.435787, acc: 61.72%, op_acc: 34.38%] [G loss: 0.935787]\n",
      "epoch:7 step:6116[D loss: 0.457109, acc: 59.38%, op_acc: 32.03%] [G loss: 0.936979]\n",
      "epoch:7 step:6117[D loss: 0.431939, acc: 68.75%, op_acc: 31.25%] [G loss: 0.994290]\n",
      "epoch:7 step:6118[D loss: 0.459263, acc: 59.38%, op_acc: 32.03%] [G loss: 0.839568]\n",
      "epoch:7 step:6119[D loss: 0.409352, acc: 64.84%, op_acc: 41.41%] [G loss: 0.879089]\n",
      "epoch:7 step:6120[D loss: 0.465903, acc: 52.34%, op_acc: 36.72%] [G loss: 0.824838]\n",
      "epoch:7 step:6121[D loss: 0.457602, acc: 56.25%, op_acc: 32.81%] [G loss: 0.885566]\n",
      "epoch:7 step:6122[D loss: 0.412659, acc: 68.75%, op_acc: 29.69%] [G loss: 0.951233]\n",
      "epoch:7 step:6123[D loss: 0.460262, acc: 55.47%, op_acc: 32.03%] [G loss: 0.961286]\n",
      "epoch:7 step:6124[D loss: 0.442745, acc: 58.59%, op_acc: 35.94%] [G loss: 0.881066]\n",
      "epoch:7 step:6125[D loss: 0.434531, acc: 57.81%, op_acc: 30.47%] [G loss: 0.869343]\n",
      "epoch:7 step:6126[D loss: 0.456680, acc: 60.16%, op_acc: 29.69%] [G loss: 0.894515]\n",
      "epoch:7 step:6127[D loss: 0.464311, acc: 57.81%, op_acc: 35.16%] [G loss: 0.827660]\n",
      "epoch:7 step:6128[D loss: 0.441775, acc: 57.03%, op_acc: 36.72%] [G loss: 0.951318]\n",
      "epoch:7 step:6129[D loss: 0.436546, acc: 57.81%, op_acc: 37.50%] [G loss: 0.950557]\n",
      "epoch:7 step:6130[D loss: 0.422854, acc: 62.50%, op_acc: 39.06%] [G loss: 1.028965]\n",
      "epoch:7 step:6131[D loss: 0.432726, acc: 60.94%, op_acc: 36.72%] [G loss: 0.908475]\n",
      "epoch:7 step:6132[D loss: 0.475857, acc: 59.38%, op_acc: 29.69%] [G loss: 1.007518]\n",
      "epoch:7 step:6133[D loss: 0.440211, acc: 63.28%, op_acc: 31.25%] [G loss: 0.994791]\n",
      "epoch:7 step:6134[D loss: 0.428660, acc: 66.41%, op_acc: 34.38%] [G loss: 1.066272]\n",
      "epoch:7 step:6135[D loss: 0.457814, acc: 56.25%, op_acc: 35.16%] [G loss: 0.917738]\n",
      "epoch:7 step:6136[D loss: 0.482885, acc: 51.56%, op_acc: 32.03%] [G loss: 0.901129]\n",
      "epoch:7 step:6137[D loss: 0.447070, acc: 60.94%, op_acc: 36.72%] [G loss: 0.968881]\n",
      "epoch:7 step:6138[D loss: 0.423248, acc: 67.97%, op_acc: 32.03%] [G loss: 1.017884]\n",
      "epoch:7 step:6139[D loss: 0.461288, acc: 60.16%, op_acc: 36.72%] [G loss: 0.994085]\n",
      "epoch:7 step:6140[D loss: 0.431540, acc: 63.28%, op_acc: 38.28%] [G loss: 0.912675]\n",
      "epoch:7 step:6141[D loss: 0.448031, acc: 54.69%, op_acc: 31.25%] [G loss: 0.963495]\n",
      "epoch:7 step:6142[D loss: 0.454971, acc: 60.94%, op_acc: 32.03%] [G loss: 0.956368]\n",
      "epoch:7 step:6143[D loss: 0.469830, acc: 59.38%, op_acc: 27.34%] [G loss: 0.924629]\n",
      "epoch:7 step:6144[D loss: 0.462024, acc: 56.25%, op_acc: 31.25%] [G loss: 0.938055]\n",
      "epoch:7 step:6145[D loss: 0.427234, acc: 60.94%, op_acc: 32.81%] [G loss: 0.959601]\n",
      "epoch:7 step:6146[D loss: 0.436925, acc: 57.81%, op_acc: 39.06%] [G loss: 0.991055]\n",
      "epoch:7 step:6147[D loss: 0.427240, acc: 60.94%, op_acc: 35.16%] [G loss: 0.865988]\n",
      "epoch:7 step:6148[D loss: 0.430378, acc: 65.62%, op_acc: 31.25%] [G loss: 1.006244]\n",
      "epoch:7 step:6149[D loss: 0.425490, acc: 65.62%, op_acc: 36.72%] [G loss: 0.991649]\n",
      "epoch:7 step:6150[D loss: 0.435807, acc: 60.16%, op_acc: 36.72%] [G loss: 0.923787]\n",
      "epoch:7 step:6151[D loss: 0.463614, acc: 52.34%, op_acc: 34.38%] [G loss: 0.897529]\n",
      "epoch:7 step:6152[D loss: 0.504613, acc: 49.22%, op_acc: 33.59%] [G loss: 0.905652]\n",
      "epoch:7 step:6153[D loss: 0.486831, acc: 50.78%, op_acc: 30.47%] [G loss: 0.923271]\n",
      "epoch:7 step:6154[D loss: 0.417544, acc: 67.19%, op_acc: 32.81%] [G loss: 0.873747]\n",
      "epoch:7 step:6155[D loss: 0.428108, acc: 63.28%, op_acc: 38.28%] [G loss: 0.994232]\n",
      "epoch:7 step:6156[D loss: 0.478327, acc: 48.44%, op_acc: 32.03%] [G loss: 0.848156]\n",
      "epoch:7 step:6157[D loss: 0.445850, acc: 64.06%, op_acc: 31.25%] [G loss: 0.935640]\n",
      "epoch:7 step:6158[D loss: 0.418925, acc: 67.19%, op_acc: 36.72%] [G loss: 1.077409]\n",
      "epoch:7 step:6159[D loss: 0.458095, acc: 60.16%, op_acc: 35.16%] [G loss: 0.931545]\n",
      "epoch:7 step:6160[D loss: 0.475548, acc: 59.38%, op_acc: 31.25%] [G loss: 0.881819]\n",
      "epoch:7 step:6161[D loss: 0.467024, acc: 58.59%, op_acc: 32.81%] [G loss: 0.866376]\n",
      "epoch:7 step:6162[D loss: 0.452436, acc: 55.47%, op_acc: 31.25%] [G loss: 0.884320]\n",
      "epoch:7 step:6163[D loss: 0.438732, acc: 67.97%, op_acc: 32.81%] [G loss: 0.872059]\n",
      "epoch:7 step:6164[D loss: 0.445514, acc: 53.12%, op_acc: 40.62%] [G loss: 0.920073]\n",
      "epoch:7 step:6165[D loss: 0.399687, acc: 71.88%, op_acc: 35.94%] [G loss: 0.966966]\n",
      "epoch:7 step:6166[D loss: 0.449523, acc: 56.25%, op_acc: 35.94%] [G loss: 0.907485]\n",
      "epoch:7 step:6167[D loss: 0.458762, acc: 60.16%, op_acc: 28.12%] [G loss: 0.937184]\n",
      "epoch:7 step:6168[D loss: 0.461038, acc: 54.69%, op_acc: 31.25%] [G loss: 0.914821]\n",
      "epoch:7 step:6169[D loss: 0.462364, acc: 59.38%, op_acc: 33.59%] [G loss: 0.960032]\n",
      "epoch:7 step:6170[D loss: 0.487095, acc: 50.00%, op_acc: 34.38%] [G loss: 0.989446]\n",
      "epoch:7 step:6171[D loss: 0.426618, acc: 57.03%, op_acc: 37.50%] [G loss: 1.053250]\n",
      "epoch:7 step:6172[D loss: 0.417463, acc: 65.62%, op_acc: 41.41%] [G loss: 0.996006]\n",
      "epoch:7 step:6173[D loss: 0.414395, acc: 67.19%, op_acc: 31.25%] [G loss: 0.963069]\n",
      "epoch:7 step:6174[D loss: 0.495640, acc: 53.91%, op_acc: 31.25%] [G loss: 0.885470]\n",
      "epoch:7 step:6175[D loss: 0.498708, acc: 55.47%, op_acc: 28.91%] [G loss: 0.960883]\n",
      "epoch:7 step:6176[D loss: 0.445194, acc: 54.69%, op_acc: 36.72%] [G loss: 0.956778]\n",
      "epoch:7 step:6177[D loss: 0.394493, acc: 70.31%, op_acc: 35.16%] [G loss: 0.882498]\n",
      "epoch:7 step:6178[D loss: 0.444430, acc: 59.38%, op_acc: 33.59%] [G loss: 0.953045]\n",
      "epoch:7 step:6179[D loss: 0.423531, acc: 57.81%, op_acc: 37.50%] [G loss: 0.950859]\n",
      "epoch:7 step:6180[D loss: 0.433958, acc: 60.16%, op_acc: 30.47%] [G loss: 0.899692]\n",
      "epoch:7 step:6181[D loss: 0.465574, acc: 57.03%, op_acc: 33.59%] [G loss: 0.823434]\n",
      "epoch:7 step:6182[D loss: 0.451471, acc: 57.81%, op_acc: 28.91%] [G loss: 0.898853]\n",
      "epoch:7 step:6183[D loss: 0.463310, acc: 58.59%, op_acc: 35.16%] [G loss: 0.875097]\n",
      "epoch:7 step:6184[D loss: 0.421583, acc: 65.62%, op_acc: 35.94%] [G loss: 0.892986]\n",
      "epoch:7 step:6185[D loss: 0.444294, acc: 59.38%, op_acc: 36.72%] [G loss: 0.893237]\n",
      "epoch:7 step:6186[D loss: 0.448385, acc: 60.94%, op_acc: 32.81%] [G loss: 0.910065]\n",
      "epoch:7 step:6187[D loss: 0.427791, acc: 62.50%, op_acc: 33.59%] [G loss: 1.018833]\n",
      "epoch:7 step:6188[D loss: 0.387724, acc: 66.41%, op_acc: 39.06%] [G loss: 0.981176]\n",
      "epoch:7 step:6189[D loss: 0.440152, acc: 58.59%, op_acc: 32.81%] [G loss: 1.001905]\n",
      "epoch:7 step:6190[D loss: 0.452866, acc: 53.12%, op_acc: 32.03%] [G loss: 0.950559]\n",
      "epoch:7 step:6191[D loss: 0.449124, acc: 61.72%, op_acc: 32.03%] [G loss: 0.886714]\n",
      "epoch:7 step:6192[D loss: 0.419442, acc: 67.97%, op_acc: 39.06%] [G loss: 0.836969]\n",
      "epoch:7 step:6193[D loss: 0.435090, acc: 57.81%, op_acc: 37.50%] [G loss: 0.904499]\n",
      "epoch:7 step:6194[D loss: 0.469257, acc: 57.03%, op_acc: 27.34%] [G loss: 0.852125]\n",
      "epoch:7 step:6195[D loss: 0.457385, acc: 64.06%, op_acc: 36.72%] [G loss: 0.936601]\n",
      "epoch:7 step:6196[D loss: 0.419546, acc: 71.88%, op_acc: 35.16%] [G loss: 0.923514]\n",
      "epoch:7 step:6197[D loss: 0.436971, acc: 63.28%, op_acc: 33.59%] [G loss: 0.865402]\n",
      "epoch:7 step:6198[D loss: 0.436788, acc: 57.81%, op_acc: 32.03%] [G loss: 0.991632]\n",
      "epoch:7 step:6199[D loss: 0.466538, acc: 57.03%, op_acc: 32.81%] [G loss: 0.923762]\n",
      "epoch:7 step:6200[D loss: 0.433494, acc: 61.72%, op_acc: 35.94%] [G loss: 0.899253]\n",
      "epoch:7 step:6201[D loss: 0.458833, acc: 59.38%, op_acc: 32.03%] [G loss: 0.906082]\n",
      "epoch:7 step:6202[D loss: 0.459997, acc: 55.47%, op_acc: 27.34%] [G loss: 0.836290]\n",
      "epoch:7 step:6203[D loss: 0.442134, acc: 64.84%, op_acc: 31.25%] [G loss: 0.944723]\n",
      "epoch:7 step:6204[D loss: 0.445830, acc: 56.25%, op_acc: 37.50%] [G loss: 0.904950]\n",
      "epoch:7 step:6205[D loss: 0.434216, acc: 57.03%, op_acc: 32.81%] [G loss: 1.021793]\n",
      "epoch:7 step:6206[D loss: 0.438601, acc: 59.38%, op_acc: 35.94%] [G loss: 0.847271]\n",
      "epoch:7 step:6207[D loss: 0.440674, acc: 57.81%, op_acc: 37.50%] [G loss: 0.915121]\n",
      "epoch:7 step:6208[D loss: 0.429285, acc: 65.62%, op_acc: 33.59%] [G loss: 1.044924]\n",
      "epoch:7 step:6209[D loss: 0.427922, acc: 60.16%, op_acc: 30.47%] [G loss: 0.943987]\n",
      "epoch:7 step:6210[D loss: 0.467759, acc: 56.25%, op_acc: 30.47%] [G loss: 0.903145]\n",
      "epoch:7 step:6211[D loss: 0.444738, acc: 52.34%, op_acc: 41.41%] [G loss: 0.914116]\n",
      "epoch:7 step:6212[D loss: 0.420527, acc: 64.84%, op_acc: 35.94%] [G loss: 0.957089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6213[D loss: 0.428232, acc: 64.84%, op_acc: 32.03%] [G loss: 0.989877]\n",
      "epoch:7 step:6214[D loss: 0.462360, acc: 53.91%, op_acc: 32.03%] [G loss: 0.784187]\n",
      "epoch:7 step:6215[D loss: 0.452374, acc: 59.38%, op_acc: 26.56%] [G loss: 0.844180]\n",
      "epoch:7 step:6216[D loss: 0.459765, acc: 55.47%, op_acc: 32.81%] [G loss: 0.830236]\n",
      "epoch:7 step:6217[D loss: 0.452804, acc: 54.69%, op_acc: 34.38%] [G loss: 0.852693]\n",
      "epoch:7 step:6218[D loss: 0.482318, acc: 49.22%, op_acc: 30.47%] [G loss: 0.963297]\n",
      "epoch:7 step:6219[D loss: 0.449136, acc: 58.59%, op_acc: 35.94%] [G loss: 0.878466]\n",
      "epoch:7 step:6220[D loss: 0.422415, acc: 64.06%, op_acc: 36.72%] [G loss: 1.021324]\n",
      "epoch:7 step:6221[D loss: 0.429311, acc: 57.03%, op_acc: 40.62%] [G loss: 0.887575]\n",
      "epoch:7 step:6222[D loss: 0.448043, acc: 59.38%, op_acc: 32.03%] [G loss: 0.917450]\n",
      "epoch:7 step:6223[D loss: 0.439371, acc: 57.03%, op_acc: 41.41%] [G loss: 0.968178]\n",
      "epoch:7 step:6224[D loss: 0.426235, acc: 62.50%, op_acc: 34.38%] [G loss: 0.929355]\n",
      "epoch:7 step:6225[D loss: 0.444063, acc: 60.94%, op_acc: 35.16%] [G loss: 0.922263]\n",
      "epoch:7 step:6226[D loss: 0.440043, acc: 60.94%, op_acc: 37.50%] [G loss: 0.965991]\n",
      "epoch:7 step:6227[D loss: 0.445647, acc: 63.28%, op_acc: 34.38%] [G loss: 0.920003]\n",
      "epoch:7 step:6228[D loss: 0.431794, acc: 53.91%, op_acc: 39.84%] [G loss: 0.967040]\n",
      "epoch:7 step:6229[D loss: 0.428039, acc: 64.06%, op_acc: 35.94%] [G loss: 1.015718]\n",
      "epoch:7 step:6230[D loss: 0.446457, acc: 60.94%, op_acc: 33.59%] [G loss: 0.962613]\n",
      "epoch:7 step:6231[D loss: 0.435464, acc: 52.34%, op_acc: 39.06%] [G loss: 0.898856]\n",
      "epoch:7 step:6232[D loss: 0.427682, acc: 54.69%, op_acc: 36.72%] [G loss: 0.881868]\n",
      "epoch:7 step:6233[D loss: 0.474487, acc: 59.38%, op_acc: 29.69%] [G loss: 0.916880]\n",
      "epoch:7 step:6234[D loss: 0.430786, acc: 60.16%, op_acc: 34.38%] [G loss: 0.924553]\n",
      "epoch:7 step:6235[D loss: 0.458452, acc: 51.56%, op_acc: 32.81%] [G loss: 0.911684]\n",
      "epoch:7 step:6236[D loss: 0.417798, acc: 64.84%, op_acc: 35.16%] [G loss: 0.983798]\n",
      "epoch:7 step:6237[D loss: 0.423290, acc: 70.31%, op_acc: 29.69%] [G loss: 0.967031]\n",
      "epoch:7 step:6238[D loss: 0.453626, acc: 60.94%, op_acc: 29.69%] [G loss: 1.029297]\n",
      "epoch:7 step:6239[D loss: 0.471836, acc: 60.94%, op_acc: 32.03%] [G loss: 0.967442]\n",
      "epoch:7 step:6240[D loss: 0.415272, acc: 65.62%, op_acc: 40.62%] [G loss: 0.963865]\n",
      "epoch:7 step:6241[D loss: 0.425109, acc: 57.81%, op_acc: 37.50%] [G loss: 0.917147]\n",
      "epoch:7 step:6242[D loss: 0.431038, acc: 64.06%, op_acc: 35.16%] [G loss: 0.901917]\n",
      "epoch:7 step:6243[D loss: 0.423216, acc: 62.50%, op_acc: 37.50%] [G loss: 0.882710]\n",
      "epoch:7 step:6244[D loss: 0.469898, acc: 57.81%, op_acc: 23.44%] [G loss: 0.945680]\n",
      "epoch:7 step:6245[D loss: 0.416511, acc: 57.03%, op_acc: 37.50%] [G loss: 0.886528]\n",
      "epoch:7 step:6246[D loss: 0.432433, acc: 60.94%, op_acc: 39.84%] [G loss: 0.914074]\n",
      "epoch:7 step:6247[D loss: 0.452108, acc: 56.25%, op_acc: 37.50%] [G loss: 0.946547]\n",
      "epoch:7 step:6248[D loss: 0.452715, acc: 57.03%, op_acc: 34.38%] [G loss: 0.909137]\n",
      "epoch:8 step:6249[D loss: 0.458218, acc: 59.38%, op_acc: 38.28%] [G loss: 0.952615]\n",
      "epoch:8 step:6250[D loss: 0.418676, acc: 62.50%, op_acc: 32.81%] [G loss: 0.858710]\n",
      "epoch:8 step:6251[D loss: 0.467971, acc: 54.69%, op_acc: 33.59%] [G loss: 0.870064]\n",
      "epoch:8 step:6252[D loss: 0.390299, acc: 64.06%, op_acc: 39.84%] [G loss: 0.999873]\n",
      "epoch:8 step:6253[D loss: 0.407522, acc: 65.62%, op_acc: 40.62%] [G loss: 1.004202]\n",
      "epoch:8 step:6254[D loss: 0.443098, acc: 56.25%, op_acc: 33.59%] [G loss: 0.925564]\n",
      "epoch:8 step:6255[D loss: 0.418886, acc: 67.97%, op_acc: 42.97%] [G loss: 1.013348]\n",
      "epoch:8 step:6256[D loss: 0.427792, acc: 63.28%, op_acc: 32.81%] [G loss: 1.002948]\n",
      "epoch:8 step:6257[D loss: 0.416234, acc: 63.28%, op_acc: 39.06%] [G loss: 0.956585]\n",
      "epoch:8 step:6258[D loss: 0.449391, acc: 64.06%, op_acc: 31.25%] [G loss: 0.831296]\n",
      "epoch:8 step:6259[D loss: 0.487181, acc: 51.56%, op_acc: 29.69%] [G loss: 0.909092]\n",
      "epoch:8 step:6260[D loss: 0.446110, acc: 61.72%, op_acc: 32.03%] [G loss: 0.886671]\n",
      "epoch:8 step:6261[D loss: 0.458806, acc: 60.94%, op_acc: 30.47%] [G loss: 0.879290]\n",
      "epoch:8 step:6262[D loss: 0.459235, acc: 53.12%, op_acc: 32.03%] [G loss: 0.914976]\n",
      "epoch:8 step:6263[D loss: 0.422609, acc: 60.94%, op_acc: 32.03%] [G loss: 0.829260]\n",
      "epoch:8 step:6264[D loss: 0.411935, acc: 58.59%, op_acc: 39.06%] [G loss: 1.024514]\n",
      "epoch:8 step:6265[D loss: 0.435823, acc: 57.81%, op_acc: 40.62%] [G loss: 0.929914]\n",
      "epoch:8 step:6266[D loss: 0.416298, acc: 61.72%, op_acc: 36.72%] [G loss: 0.922543]\n",
      "epoch:8 step:6267[D loss: 0.430211, acc: 60.94%, op_acc: 37.50%] [G loss: 0.887069]\n",
      "epoch:8 step:6268[D loss: 0.438542, acc: 57.03%, op_acc: 36.72%] [G loss: 0.818536]\n",
      "epoch:8 step:6269[D loss: 0.458419, acc: 55.47%, op_acc: 30.47%] [G loss: 0.886132]\n",
      "epoch:8 step:6270[D loss: 0.408827, acc: 67.97%, op_acc: 39.06%] [G loss: 1.023664]\n",
      "epoch:8 step:6271[D loss: 0.472484, acc: 48.44%, op_acc: 33.59%] [G loss: 1.012355]\n",
      "epoch:8 step:6272[D loss: 0.436348, acc: 61.72%, op_acc: 34.38%] [G loss: 0.886443]\n",
      "epoch:8 step:6273[D loss: 0.445932, acc: 60.16%, op_acc: 38.28%] [G loss: 0.944299]\n",
      "epoch:8 step:6274[D loss: 0.425634, acc: 61.72%, op_acc: 35.16%] [G loss: 1.099737]\n",
      "epoch:8 step:6275[D loss: 0.455094, acc: 59.38%, op_acc: 35.16%] [G loss: 0.932804]\n",
      "epoch:8 step:6276[D loss: 0.421208, acc: 64.06%, op_acc: 43.75%] [G loss: 0.993374]\n",
      "epoch:8 step:6277[D loss: 0.421944, acc: 60.94%, op_acc: 39.84%] [G loss: 0.927674]\n",
      "epoch:8 step:6278[D loss: 0.406126, acc: 64.84%, op_acc: 41.41%] [G loss: 0.991121]\n",
      "epoch:8 step:6279[D loss: 0.480228, acc: 59.38%, op_acc: 28.91%] [G loss: 0.902455]\n",
      "epoch:8 step:6280[D loss: 0.446532, acc: 67.19%, op_acc: 36.72%] [G loss: 0.921834]\n",
      "epoch:8 step:6281[D loss: 0.424480, acc: 64.06%, op_acc: 38.28%] [G loss: 1.009232]\n",
      "epoch:8 step:6282[D loss: 0.453129, acc: 57.03%, op_acc: 34.38%] [G loss: 0.959603]\n",
      "epoch:8 step:6283[D loss: 0.468976, acc: 52.34%, op_acc: 30.47%] [G loss: 0.844788]\n",
      "epoch:8 step:6284[D loss: 0.458786, acc: 54.69%, op_acc: 35.94%] [G loss: 0.876492]\n",
      "epoch:8 step:6285[D loss: 0.404303, acc: 66.41%, op_acc: 37.50%] [G loss: 0.935602]\n",
      "epoch:8 step:6286[D loss: 0.419632, acc: 63.28%, op_acc: 36.72%] [G loss: 1.031768]\n",
      "epoch:8 step:6287[D loss: 0.433256, acc: 62.50%, op_acc: 33.59%] [G loss: 0.954480]\n",
      "epoch:8 step:6288[D loss: 0.452861, acc: 63.28%, op_acc: 31.25%] [G loss: 0.968017]\n",
      "epoch:8 step:6289[D loss: 0.432618, acc: 63.28%, op_acc: 36.72%] [G loss: 0.873119]\n",
      "epoch:8 step:6290[D loss: 0.394904, acc: 64.84%, op_acc: 36.72%] [G loss: 0.874646]\n",
      "epoch:8 step:6291[D loss: 0.462150, acc: 52.34%, op_acc: 29.69%] [G loss: 0.880528]\n",
      "epoch:8 step:6292[D loss: 0.437869, acc: 57.03%, op_acc: 32.81%] [G loss: 0.916916]\n",
      "epoch:8 step:6293[D loss: 0.412216, acc: 64.06%, op_acc: 35.16%] [G loss: 0.945861]\n",
      "epoch:8 step:6294[D loss: 0.419804, acc: 62.50%, op_acc: 36.72%] [G loss: 1.050488]\n",
      "epoch:8 step:6295[D loss: 0.424460, acc: 70.31%, op_acc: 34.38%] [G loss: 0.948973]\n",
      "epoch:8 step:6296[D loss: 0.435536, acc: 60.16%, op_acc: 33.59%] [G loss: 0.887564]\n",
      "epoch:8 step:6297[D loss: 0.402992, acc: 71.88%, op_acc: 35.16%] [G loss: 1.016414]\n",
      "epoch:8 step:6298[D loss: 0.441525, acc: 59.38%, op_acc: 32.81%] [G loss: 0.995772]\n",
      "epoch:8 step:6299[D loss: 0.449354, acc: 59.38%, op_acc: 34.38%] [G loss: 1.006395]\n",
      "epoch:8 step:6300[D loss: 0.445692, acc: 63.28%, op_acc: 36.72%] [G loss: 1.009621]\n",
      "epoch:8 step:6301[D loss: 0.464997, acc: 57.81%, op_acc: 30.47%] [G loss: 0.940642]\n",
      "epoch:8 step:6302[D loss: 0.463576, acc: 58.59%, op_acc: 37.50%] [G loss: 0.855726]\n",
      "epoch:8 step:6303[D loss: 0.426235, acc: 61.72%, op_acc: 34.38%] [G loss: 0.949107]\n",
      "epoch:8 step:6304[D loss: 0.425670, acc: 64.06%, op_acc: 38.28%] [G loss: 0.886755]\n",
      "epoch:8 step:6305[D loss: 0.454626, acc: 56.25%, op_acc: 32.81%] [G loss: 0.853214]\n",
      "epoch:8 step:6306[D loss: 0.422295, acc: 58.59%, op_acc: 35.16%] [G loss: 0.931887]\n",
      "epoch:8 step:6307[D loss: 0.402418, acc: 64.84%, op_acc: 36.72%] [G loss: 0.979496]\n",
      "epoch:8 step:6308[D loss: 0.408476, acc: 67.19%, op_acc: 39.84%] [G loss: 0.918748]\n",
      "epoch:8 step:6309[D loss: 0.410101, acc: 75.78%, op_acc: 32.81%] [G loss: 0.843013]\n",
      "epoch:8 step:6310[D loss: 0.447345, acc: 61.72%, op_acc: 31.25%] [G loss: 0.952829]\n",
      "epoch:8 step:6311[D loss: 0.415711, acc: 70.31%, op_acc: 30.47%] [G loss: 0.908149]\n",
      "epoch:8 step:6312[D loss: 0.471518, acc: 54.69%, op_acc: 33.59%] [G loss: 0.881481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6313[D loss: 0.478976, acc: 51.56%, op_acc: 33.59%] [G loss: 0.889503]\n",
      "epoch:8 step:6314[D loss: 0.451618, acc: 57.03%, op_acc: 32.03%] [G loss: 0.954248]\n",
      "epoch:8 step:6315[D loss: 0.427379, acc: 61.72%, op_acc: 38.28%] [G loss: 0.962784]\n",
      "epoch:8 step:6316[D loss: 0.416196, acc: 64.84%, op_acc: 37.50%] [G loss: 0.995104]\n",
      "epoch:8 step:6317[D loss: 0.428502, acc: 58.59%, op_acc: 39.06%] [G loss: 0.968554]\n",
      "epoch:8 step:6318[D loss: 0.466579, acc: 51.56%, op_acc: 32.81%] [G loss: 0.962332]\n",
      "epoch:8 step:6319[D loss: 0.451687, acc: 62.50%, op_acc: 27.34%] [G loss: 0.886633]\n",
      "epoch:8 step:6320[D loss: 0.460637, acc: 56.25%, op_acc: 33.59%] [G loss: 0.897153]\n",
      "epoch:8 step:6321[D loss: 0.425830, acc: 63.28%, op_acc: 39.06%] [G loss: 0.917916]\n",
      "epoch:8 step:6322[D loss: 0.459564, acc: 51.56%, op_acc: 35.94%] [G loss: 0.975891]\n",
      "epoch:8 step:6323[D loss: 0.417933, acc: 64.06%, op_acc: 37.50%] [G loss: 0.946066]\n",
      "epoch:8 step:6324[D loss: 0.445395, acc: 63.28%, op_acc: 37.50%] [G loss: 1.013855]\n",
      "epoch:8 step:6325[D loss: 0.463493, acc: 51.56%, op_acc: 30.47%] [G loss: 0.876126]\n",
      "epoch:8 step:6326[D loss: 0.444314, acc: 66.41%, op_acc: 32.03%] [G loss: 0.917696]\n",
      "epoch:8 step:6327[D loss: 0.426034, acc: 70.31%, op_acc: 34.38%] [G loss: 0.995230]\n",
      "epoch:8 step:6328[D loss: 0.457409, acc: 64.06%, op_acc: 28.91%] [G loss: 0.950108]\n",
      "epoch:8 step:6329[D loss: 0.442233, acc: 70.31%, op_acc: 31.25%] [G loss: 1.041676]\n",
      "epoch:8 step:6330[D loss: 0.437255, acc: 60.16%, op_acc: 35.94%] [G loss: 0.892388]\n",
      "epoch:8 step:6331[D loss: 0.418537, acc: 67.19%, op_acc: 38.28%] [G loss: 0.949651]\n",
      "epoch:8 step:6332[D loss: 0.416786, acc: 64.84%, op_acc: 39.84%] [G loss: 0.977384]\n",
      "epoch:8 step:6333[D loss: 0.448509, acc: 62.50%, op_acc: 30.47%] [G loss: 0.935488]\n",
      "epoch:8 step:6334[D loss: 0.450524, acc: 60.94%, op_acc: 33.59%] [G loss: 0.922179]\n",
      "epoch:8 step:6335[D loss: 0.418707, acc: 60.94%, op_acc: 32.81%] [G loss: 0.943492]\n",
      "epoch:8 step:6336[D loss: 0.483710, acc: 47.66%, op_acc: 32.81%] [G loss: 0.901233]\n",
      "epoch:8 step:6337[D loss: 0.461718, acc: 55.47%, op_acc: 33.59%] [G loss: 0.881499]\n",
      "epoch:8 step:6338[D loss: 0.424133, acc: 63.28%, op_acc: 38.28%] [G loss: 1.029510]\n",
      "epoch:8 step:6339[D loss: 0.414710, acc: 69.53%, op_acc: 32.81%] [G loss: 0.943967]\n",
      "epoch:8 step:6340[D loss: 0.470570, acc: 53.12%, op_acc: 35.16%] [G loss: 0.883186]\n",
      "epoch:8 step:6341[D loss: 0.410329, acc: 67.19%, op_acc: 35.94%] [G loss: 0.883271]\n",
      "epoch:8 step:6342[D loss: 0.432782, acc: 59.38%, op_acc: 35.16%] [G loss: 0.963604]\n",
      "epoch:8 step:6343[D loss: 0.442852, acc: 67.19%, op_acc: 33.59%] [G loss: 0.915578]\n",
      "epoch:8 step:6344[D loss: 0.441872, acc: 61.72%, op_acc: 35.16%] [G loss: 0.869214]\n",
      "epoch:8 step:6345[D loss: 0.468193, acc: 51.56%, op_acc: 35.16%] [G loss: 0.871387]\n",
      "epoch:8 step:6346[D loss: 0.436807, acc: 65.62%, op_acc: 26.56%] [G loss: 0.951592]\n",
      "epoch:8 step:6347[D loss: 0.441595, acc: 60.16%, op_acc: 35.94%] [G loss: 1.002452]\n",
      "epoch:8 step:6348[D loss: 0.414053, acc: 62.50%, op_acc: 37.50%] [G loss: 0.945525]\n",
      "epoch:8 step:6349[D loss: 0.452802, acc: 57.03%, op_acc: 40.62%] [G loss: 0.918160]\n",
      "epoch:8 step:6350[D loss: 0.415768, acc: 66.41%, op_acc: 33.59%] [G loss: 0.945377]\n",
      "epoch:8 step:6351[D loss: 0.439345, acc: 59.38%, op_acc: 31.25%] [G loss: 0.793426]\n",
      "epoch:8 step:6352[D loss: 0.461976, acc: 57.81%, op_acc: 32.03%] [G loss: 0.817472]\n",
      "epoch:8 step:6353[D loss: 0.444629, acc: 55.47%, op_acc: 35.16%] [G loss: 0.946327]\n",
      "epoch:8 step:6354[D loss: 0.444987, acc: 53.12%, op_acc: 38.28%] [G loss: 0.964020]\n",
      "epoch:8 step:6355[D loss: 0.427237, acc: 63.28%, op_acc: 38.28%] [G loss: 0.981803]\n",
      "epoch:8 step:6356[D loss: 0.470345, acc: 64.06%, op_acc: 31.25%] [G loss: 0.958196]\n",
      "epoch:8 step:6357[D loss: 0.439148, acc: 56.25%, op_acc: 34.38%] [G loss: 0.964669]\n",
      "epoch:8 step:6358[D loss: 0.437493, acc: 56.25%, op_acc: 35.16%] [G loss: 0.862322]\n",
      "epoch:8 step:6359[D loss: 0.439243, acc: 64.06%, op_acc: 29.69%] [G loss: 1.035911]\n",
      "epoch:8 step:6360[D loss: 0.437039, acc: 56.25%, op_acc: 39.06%] [G loss: 0.923327]\n",
      "epoch:8 step:6361[D loss: 0.441033, acc: 63.28%, op_acc: 32.81%] [G loss: 0.874417]\n",
      "epoch:8 step:6362[D loss: 0.432069, acc: 64.84%, op_acc: 38.28%] [G loss: 0.900986]\n",
      "epoch:8 step:6363[D loss: 0.412615, acc: 64.84%, op_acc: 41.41%] [G loss: 0.967898]\n",
      "epoch:8 step:6364[D loss: 0.440731, acc: 69.53%, op_acc: 35.16%] [G loss: 0.969096]\n",
      "epoch:8 step:6365[D loss: 0.446919, acc: 60.16%, op_acc: 34.38%] [G loss: 0.896657]\n",
      "epoch:8 step:6366[D loss: 0.454454, acc: 50.00%, op_acc: 38.28%] [G loss: 0.891750]\n",
      "epoch:8 step:6367[D loss: 0.422300, acc: 67.19%, op_acc: 30.47%] [G loss: 0.903042]\n",
      "epoch:8 step:6368[D loss: 0.442749, acc: 61.72%, op_acc: 30.47%] [G loss: 0.908325]\n",
      "epoch:8 step:6369[D loss: 0.437483, acc: 70.31%, op_acc: 33.59%] [G loss: 0.937785]\n",
      "epoch:8 step:6370[D loss: 0.452667, acc: 59.38%, op_acc: 29.69%] [G loss: 0.933281]\n",
      "epoch:8 step:6371[D loss: 0.466819, acc: 53.91%, op_acc: 28.12%] [G loss: 0.888473]\n",
      "epoch:8 step:6372[D loss: 0.445439, acc: 56.25%, op_acc: 35.94%] [G loss: 0.861475]\n",
      "epoch:8 step:6373[D loss: 0.454405, acc: 59.38%, op_acc: 31.25%] [G loss: 0.841438]\n",
      "epoch:8 step:6374[D loss: 0.414005, acc: 63.28%, op_acc: 41.41%] [G loss: 0.838226]\n",
      "epoch:8 step:6375[D loss: 0.423312, acc: 60.94%, op_acc: 30.47%] [G loss: 0.899202]\n",
      "epoch:8 step:6376[D loss: 0.417528, acc: 70.31%, op_acc: 35.94%] [G loss: 0.914134]\n",
      "epoch:8 step:6377[D loss: 0.442035, acc: 53.91%, op_acc: 34.38%] [G loss: 0.882174]\n",
      "epoch:8 step:6378[D loss: 0.448212, acc: 50.78%, op_acc: 35.16%] [G loss: 0.908363]\n",
      "epoch:8 step:6379[D loss: 0.446712, acc: 63.28%, op_acc: 28.91%] [G loss: 0.955901]\n",
      "epoch:8 step:6380[D loss: 0.404490, acc: 60.16%, op_acc: 46.88%] [G loss: 0.992311]\n",
      "epoch:8 step:6381[D loss: 0.456636, acc: 61.72%, op_acc: 30.47%] [G loss: 0.913462]\n",
      "epoch:8 step:6382[D loss: 0.454717, acc: 61.72%, op_acc: 32.03%] [G loss: 1.007081]\n",
      "epoch:8 step:6383[D loss: 0.413666, acc: 67.19%, op_acc: 33.59%] [G loss: 0.919503]\n",
      "epoch:8 step:6384[D loss: 0.372244, acc: 71.88%, op_acc: 42.19%] [G loss: 0.906777]\n",
      "epoch:8 step:6385[D loss: 0.444843, acc: 62.50%, op_acc: 37.50%] [G loss: 0.917611]\n",
      "epoch:8 step:6386[D loss: 0.463353, acc: 54.69%, op_acc: 32.81%] [G loss: 0.977722]\n",
      "epoch:8 step:6387[D loss: 0.455942, acc: 54.69%, op_acc: 38.28%] [G loss: 0.870498]\n",
      "epoch:8 step:6388[D loss: 0.504474, acc: 58.59%, op_acc: 32.03%] [G loss: 0.913831]\n",
      "epoch:8 step:6389[D loss: 0.458377, acc: 64.06%, op_acc: 31.25%] [G loss: 0.909568]\n",
      "epoch:8 step:6390[D loss: 0.414912, acc: 62.50%, op_acc: 35.16%] [G loss: 0.899769]\n",
      "epoch:8 step:6391[D loss: 0.426066, acc: 66.41%, op_acc: 32.03%] [G loss: 0.945776]\n",
      "epoch:8 step:6392[D loss: 0.419294, acc: 64.84%, op_acc: 38.28%] [G loss: 0.930805]\n",
      "epoch:8 step:6393[D loss: 0.444495, acc: 53.91%, op_acc: 36.72%] [G loss: 0.862962]\n",
      "epoch:8 step:6394[D loss: 0.421873, acc: 62.50%, op_acc: 39.06%] [G loss: 0.975798]\n",
      "epoch:8 step:6395[D loss: 0.432578, acc: 59.38%, op_acc: 35.16%] [G loss: 0.907338]\n",
      "epoch:8 step:6396[D loss: 0.423323, acc: 64.06%, op_acc: 33.59%] [G loss: 0.965327]\n",
      "epoch:8 step:6397[D loss: 0.421217, acc: 62.50%, op_acc: 32.81%] [G loss: 0.989699]\n",
      "epoch:8 step:6398[D loss: 0.437898, acc: 58.59%, op_acc: 36.72%] [G loss: 0.934610]\n",
      "epoch:8 step:6399[D loss: 0.436576, acc: 53.91%, op_acc: 41.41%] [G loss: 0.886060]\n",
      "epoch:8 step:6400[D loss: 0.452613, acc: 57.81%, op_acc: 32.03%] [G loss: 0.967644]\n",
      "epoch:8 step:6401[D loss: 0.426204, acc: 62.50%, op_acc: 36.72%] [G loss: 0.992833]\n",
      "epoch:8 step:6402[D loss: 0.437916, acc: 54.69%, op_acc: 33.59%] [G loss: 0.923753]\n",
      "epoch:8 step:6403[D loss: 0.433784, acc: 60.16%, op_acc: 35.16%] [G loss: 0.940773]\n",
      "epoch:8 step:6404[D loss: 0.442931, acc: 60.16%, op_acc: 32.81%] [G loss: 0.826300]\n",
      "epoch:8 step:6405[D loss: 0.450917, acc: 57.03%, op_acc: 31.25%] [G loss: 0.915446]\n",
      "epoch:8 step:6406[D loss: 0.427148, acc: 60.16%, op_acc: 37.50%] [G loss: 0.878120]\n",
      "epoch:8 step:6407[D loss: 0.414827, acc: 68.75%, op_acc: 38.28%] [G loss: 0.925936]\n",
      "epoch:8 step:6408[D loss: 0.430903, acc: 63.28%, op_acc: 28.91%] [G loss: 0.980410]\n",
      "epoch:8 step:6409[D loss: 0.478375, acc: 52.34%, op_acc: 25.78%] [G loss: 0.905775]\n",
      "epoch:8 step:6410[D loss: 0.471599, acc: 49.22%, op_acc: 36.72%] [G loss: 0.918637]\n",
      "epoch:8 step:6411[D loss: 0.464918, acc: 56.25%, op_acc: 29.69%] [G loss: 0.916676]\n",
      "epoch:8 step:6412[D loss: 0.449907, acc: 58.59%, op_acc: 32.81%] [G loss: 0.938433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6413[D loss: 0.441534, acc: 60.16%, op_acc: 35.94%] [G loss: 0.897638]\n",
      "epoch:8 step:6414[D loss: 0.460605, acc: 55.47%, op_acc: 33.59%] [G loss: 0.927093]\n",
      "epoch:8 step:6415[D loss: 0.441349, acc: 58.59%, op_acc: 41.41%] [G loss: 0.932802]\n",
      "epoch:8 step:6416[D loss: 0.433225, acc: 53.91%, op_acc: 36.72%] [G loss: 1.017421]\n",
      "epoch:8 step:6417[D loss: 0.457493, acc: 58.59%, op_acc: 38.28%] [G loss: 0.894018]\n",
      "epoch:8 step:6418[D loss: 0.415414, acc: 59.38%, op_acc: 42.19%] [G loss: 0.958595]\n",
      "epoch:8 step:6419[D loss: 0.443216, acc: 59.38%, op_acc: 28.12%] [G loss: 0.929818]\n",
      "epoch:8 step:6420[D loss: 0.414352, acc: 63.28%, op_acc: 36.72%] [G loss: 0.938405]\n",
      "epoch:8 step:6421[D loss: 0.435850, acc: 61.72%, op_acc: 33.59%] [G loss: 0.911637]\n",
      "epoch:8 step:6422[D loss: 0.478779, acc: 56.25%, op_acc: 28.12%] [G loss: 0.958978]\n",
      "epoch:8 step:6423[D loss: 0.414438, acc: 58.59%, op_acc: 31.25%] [G loss: 1.007415]\n",
      "epoch:8 step:6424[D loss: 0.420907, acc: 66.41%, op_acc: 36.72%] [G loss: 1.010445]\n",
      "epoch:8 step:6425[D loss: 0.433021, acc: 62.50%, op_acc: 39.06%] [G loss: 0.918719]\n",
      "epoch:8 step:6426[D loss: 0.435832, acc: 66.41%, op_acc: 32.03%] [G loss: 0.992033]\n",
      "epoch:8 step:6427[D loss: 0.419217, acc: 64.06%, op_acc: 37.50%] [G loss: 0.950286]\n",
      "epoch:8 step:6428[D loss: 0.462266, acc: 63.28%, op_acc: 28.91%] [G loss: 0.910253]\n",
      "epoch:8 step:6429[D loss: 0.406782, acc: 67.19%, op_acc: 40.62%] [G loss: 0.950495]\n",
      "epoch:8 step:6430[D loss: 0.429008, acc: 65.62%, op_acc: 32.81%] [G loss: 0.879831]\n",
      "epoch:8 step:6431[D loss: 0.423250, acc: 62.50%, op_acc: 29.69%] [G loss: 0.982357]\n",
      "epoch:8 step:6432[D loss: 0.427214, acc: 61.72%, op_acc: 36.72%] [G loss: 0.965305]\n",
      "epoch:8 step:6433[D loss: 0.473107, acc: 55.47%, op_acc: 31.25%] [G loss: 0.921045]\n",
      "epoch:8 step:6434[D loss: 0.465441, acc: 55.47%, op_acc: 35.94%] [G loss: 0.953079]\n",
      "epoch:8 step:6435[D loss: 0.445594, acc: 58.59%, op_acc: 34.38%] [G loss: 0.953937]\n",
      "epoch:8 step:6436[D loss: 0.417459, acc: 67.97%, op_acc: 34.38%] [G loss: 0.900090]\n",
      "epoch:8 step:6437[D loss: 0.453107, acc: 62.50%, op_acc: 30.47%] [G loss: 0.948432]\n",
      "epoch:8 step:6438[D loss: 0.456367, acc: 54.69%, op_acc: 32.81%] [G loss: 0.856192]\n",
      "epoch:8 step:6439[D loss: 0.415161, acc: 59.38%, op_acc: 35.94%] [G loss: 0.906273]\n",
      "epoch:8 step:6440[D loss: 0.424149, acc: 64.84%, op_acc: 35.16%] [G loss: 0.956228]\n",
      "epoch:8 step:6441[D loss: 0.474205, acc: 58.59%, op_acc: 30.47%] [G loss: 0.854094]\n",
      "epoch:8 step:6442[D loss: 0.408744, acc: 68.75%, op_acc: 37.50%] [G loss: 0.919538]\n",
      "epoch:8 step:6443[D loss: 0.437664, acc: 59.38%, op_acc: 37.50%] [G loss: 0.926106]\n",
      "epoch:8 step:6444[D loss: 0.440793, acc: 65.62%, op_acc: 36.72%] [G loss: 0.888060]\n",
      "epoch:8 step:6445[D loss: 0.463475, acc: 59.38%, op_acc: 35.16%] [G loss: 0.924551]\n",
      "epoch:8 step:6446[D loss: 0.424366, acc: 66.41%, op_acc: 39.06%] [G loss: 0.891847]\n",
      "epoch:8 step:6447[D loss: 0.423570, acc: 64.84%, op_acc: 39.06%] [G loss: 0.949333]\n",
      "epoch:8 step:6448[D loss: 0.451534, acc: 55.47%, op_acc: 32.03%] [G loss: 0.846542]\n",
      "epoch:8 step:6449[D loss: 0.392547, acc: 71.09%, op_acc: 28.91%] [G loss: 0.897556]\n",
      "epoch:8 step:6450[D loss: 0.443450, acc: 68.75%, op_acc: 33.59%] [G loss: 0.945839]\n",
      "epoch:8 step:6451[D loss: 0.461345, acc: 61.72%, op_acc: 29.69%] [G loss: 0.831452]\n",
      "epoch:8 step:6452[D loss: 0.449365, acc: 53.91%, op_acc: 35.94%] [G loss: 0.892642]\n",
      "epoch:8 step:6453[D loss: 0.446932, acc: 60.16%, op_acc: 32.81%] [G loss: 0.845835]\n",
      "epoch:8 step:6454[D loss: 0.445697, acc: 61.72%, op_acc: 30.47%] [G loss: 0.787217]\n",
      "epoch:8 step:6455[D loss: 0.423053, acc: 59.38%, op_acc: 41.41%] [G loss: 0.904725]\n",
      "epoch:8 step:6456[D loss: 0.436442, acc: 69.53%, op_acc: 35.94%] [G loss: 0.884705]\n",
      "epoch:8 step:6457[D loss: 0.470485, acc: 51.56%, op_acc: 35.16%] [G loss: 0.934200]\n",
      "epoch:8 step:6458[D loss: 0.423039, acc: 65.62%, op_acc: 32.03%] [G loss: 0.936184]\n",
      "epoch:8 step:6459[D loss: 0.455399, acc: 55.47%, op_acc: 35.94%] [G loss: 0.942166]\n",
      "epoch:8 step:6460[D loss: 0.421608, acc: 66.41%, op_acc: 40.62%] [G loss: 0.994885]\n",
      "epoch:8 step:6461[D loss: 0.430373, acc: 62.50%, op_acc: 35.94%] [G loss: 0.977337]\n",
      "epoch:8 step:6462[D loss: 0.441833, acc: 60.16%, op_acc: 32.03%] [G loss: 0.983275]\n",
      "epoch:8 step:6463[D loss: 0.451739, acc: 57.03%, op_acc: 32.81%] [G loss: 0.907734]\n",
      "epoch:8 step:6464[D loss: 0.437869, acc: 60.94%, op_acc: 33.59%] [G loss: 0.979061]\n",
      "epoch:8 step:6465[D loss: 0.415101, acc: 68.75%, op_acc: 42.19%] [G loss: 0.919343]\n",
      "epoch:8 step:6466[D loss: 0.433982, acc: 58.59%, op_acc: 39.84%] [G loss: 0.989786]\n",
      "epoch:8 step:6467[D loss: 0.403637, acc: 70.31%, op_acc: 34.38%] [G loss: 0.922690]\n",
      "epoch:8 step:6468[D loss: 0.437315, acc: 57.81%, op_acc: 42.19%] [G loss: 0.957300]\n",
      "epoch:8 step:6469[D loss: 0.419923, acc: 60.16%, op_acc: 34.38%] [G loss: 0.907693]\n",
      "epoch:8 step:6470[D loss: 0.452152, acc: 60.94%, op_acc: 33.59%] [G loss: 0.872210]\n",
      "epoch:8 step:6471[D loss: 0.423448, acc: 67.19%, op_acc: 35.16%] [G loss: 0.945294]\n",
      "epoch:8 step:6472[D loss: 0.427325, acc: 61.72%, op_acc: 37.50%] [G loss: 0.924258]\n",
      "epoch:8 step:6473[D loss: 0.469908, acc: 54.69%, op_acc: 33.59%] [G loss: 0.960961]\n",
      "epoch:8 step:6474[D loss: 0.437263, acc: 60.94%, op_acc: 39.06%] [G loss: 0.928917]\n",
      "epoch:8 step:6475[D loss: 0.415582, acc: 69.53%, op_acc: 38.28%] [G loss: 0.905089]\n",
      "epoch:8 step:6476[D loss: 0.435716, acc: 60.94%, op_acc: 36.72%] [G loss: 0.883449]\n",
      "epoch:8 step:6477[D loss: 0.435858, acc: 60.94%, op_acc: 36.72%] [G loss: 0.968411]\n",
      "epoch:8 step:6478[D loss: 0.430395, acc: 63.28%, op_acc: 35.94%] [G loss: 0.952170]\n",
      "epoch:8 step:6479[D loss: 0.401307, acc: 71.09%, op_acc: 34.38%] [G loss: 1.017740]\n",
      "epoch:8 step:6480[D loss: 0.473091, acc: 56.25%, op_acc: 32.81%] [G loss: 0.900427]\n",
      "epoch:8 step:6481[D loss: 0.414843, acc: 68.75%, op_acc: 38.28%] [G loss: 0.984271]\n",
      "epoch:8 step:6482[D loss: 0.432196, acc: 62.50%, op_acc: 34.38%] [G loss: 0.902001]\n",
      "epoch:8 step:6483[D loss: 0.468631, acc: 56.25%, op_acc: 32.03%] [G loss: 0.961163]\n",
      "epoch:8 step:6484[D loss: 0.452827, acc: 58.59%, op_acc: 34.38%] [G loss: 0.973062]\n",
      "epoch:8 step:6485[D loss: 0.464260, acc: 53.91%, op_acc: 29.69%] [G loss: 0.949979]\n",
      "epoch:8 step:6486[D loss: 0.446029, acc: 60.94%, op_acc: 32.81%] [G loss: 0.982044]\n",
      "epoch:8 step:6487[D loss: 0.411710, acc: 67.19%, op_acc: 32.81%] [G loss: 1.160016]\n",
      "epoch:8 step:6488[D loss: 0.415563, acc: 67.19%, op_acc: 30.47%] [G loss: 0.982774]\n",
      "epoch:8 step:6489[D loss: 0.413806, acc: 66.41%, op_acc: 35.16%] [G loss: 1.000077]\n",
      "epoch:8 step:6490[D loss: 0.433123, acc: 62.50%, op_acc: 35.94%] [G loss: 0.981436]\n",
      "epoch:8 step:6491[D loss: 0.464742, acc: 62.50%, op_acc: 29.69%] [G loss: 0.882806]\n",
      "epoch:8 step:6492[D loss: 0.476669, acc: 57.81%, op_acc: 29.69%] [G loss: 0.857610]\n",
      "epoch:8 step:6493[D loss: 0.467328, acc: 53.91%, op_acc: 34.38%] [G loss: 0.883132]\n",
      "epoch:8 step:6494[D loss: 0.440709, acc: 56.25%, op_acc: 36.72%] [G loss: 0.885972]\n",
      "epoch:8 step:6495[D loss: 0.439569, acc: 51.56%, op_acc: 35.16%] [G loss: 0.993740]\n",
      "epoch:8 step:6496[D loss: 0.450460, acc: 59.38%, op_acc: 28.12%] [G loss: 0.993733]\n",
      "epoch:8 step:6497[D loss: 0.456080, acc: 60.16%, op_acc: 35.94%] [G loss: 0.983468]\n",
      "epoch:8 step:6498[D loss: 0.440067, acc: 62.50%, op_acc: 36.72%] [G loss: 0.941095]\n",
      "epoch:8 step:6499[D loss: 0.408939, acc: 69.53%, op_acc: 35.16%] [G loss: 1.078081]\n",
      "epoch:8 step:6500[D loss: 0.416955, acc: 64.06%, op_acc: 39.84%] [G loss: 0.878637]\n",
      "epoch:8 step:6501[D loss: 0.426334, acc: 64.06%, op_acc: 38.28%] [G loss: 0.952243]\n",
      "epoch:8 step:6502[D loss: 0.421141, acc: 67.19%, op_acc: 31.25%] [G loss: 0.978296]\n",
      "epoch:8 step:6503[D loss: 0.482130, acc: 52.34%, op_acc: 32.81%] [G loss: 0.914308]\n",
      "epoch:8 step:6504[D loss: 0.442047, acc: 58.59%, op_acc: 30.47%] [G loss: 0.881316]\n",
      "epoch:8 step:6505[D loss: 0.441855, acc: 63.28%, op_acc: 38.28%] [G loss: 0.968668]\n",
      "epoch:8 step:6506[D loss: 0.420819, acc: 64.06%, op_acc: 37.50%] [G loss: 0.985259]\n",
      "epoch:8 step:6507[D loss: 0.442599, acc: 58.59%, op_acc: 27.34%] [G loss: 0.960409]\n",
      "epoch:8 step:6508[D loss: 0.431142, acc: 64.84%, op_acc: 32.81%] [G loss: 1.019529]\n",
      "epoch:8 step:6509[D loss: 0.454183, acc: 53.91%, op_acc: 30.47%] [G loss: 1.000305]\n",
      "epoch:8 step:6510[D loss: 0.422976, acc: 63.28%, op_acc: 35.94%] [G loss: 0.980253]\n",
      "epoch:8 step:6511[D loss: 0.441560, acc: 60.94%, op_acc: 28.12%] [G loss: 0.937161]\n",
      "epoch:8 step:6512[D loss: 0.416076, acc: 64.06%, op_acc: 32.81%] [G loss: 0.875923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6513[D loss: 0.427692, acc: 60.16%, op_acc: 30.47%] [G loss: 0.966496]\n",
      "epoch:8 step:6514[D loss: 0.442084, acc: 64.06%, op_acc: 37.50%] [G loss: 0.976791]\n",
      "epoch:8 step:6515[D loss: 0.458764, acc: 49.22%, op_acc: 32.81%] [G loss: 0.976640]\n",
      "epoch:8 step:6516[D loss: 0.419548, acc: 67.97%, op_acc: 36.72%] [G loss: 1.035363]\n",
      "epoch:8 step:6517[D loss: 0.410128, acc: 65.62%, op_acc: 36.72%] [G loss: 0.909198]\n",
      "epoch:8 step:6518[D loss: 0.430709, acc: 61.72%, op_acc: 34.38%] [G loss: 0.867396]\n",
      "epoch:8 step:6519[D loss: 0.429439, acc: 63.28%, op_acc: 35.94%] [G loss: 0.932410]\n",
      "epoch:8 step:6520[D loss: 0.441792, acc: 61.72%, op_acc: 31.25%] [G loss: 1.060663]\n",
      "epoch:8 step:6521[D loss: 0.426628, acc: 62.50%, op_acc: 35.94%] [G loss: 0.922599]\n",
      "epoch:8 step:6522[D loss: 0.449723, acc: 57.81%, op_acc: 35.16%] [G loss: 0.925461]\n",
      "epoch:8 step:6523[D loss: 0.434232, acc: 61.72%, op_acc: 34.38%] [G loss: 0.947832]\n",
      "epoch:8 step:6524[D loss: 0.456242, acc: 53.91%, op_acc: 32.03%] [G loss: 0.914585]\n",
      "epoch:8 step:6525[D loss: 0.457434, acc: 63.28%, op_acc: 27.34%] [G loss: 0.853103]\n",
      "epoch:8 step:6526[D loss: 0.439694, acc: 67.19%, op_acc: 39.84%] [G loss: 0.956081]\n",
      "epoch:8 step:6527[D loss: 0.438235, acc: 57.03%, op_acc: 36.72%] [G loss: 0.920085]\n",
      "epoch:8 step:6528[D loss: 0.431214, acc: 58.59%, op_acc: 34.38%] [G loss: 0.900858]\n",
      "epoch:8 step:6529[D loss: 0.449890, acc: 56.25%, op_acc: 33.59%] [G loss: 0.920399]\n",
      "epoch:8 step:6530[D loss: 0.443973, acc: 65.62%, op_acc: 34.38%] [G loss: 0.911041]\n",
      "epoch:8 step:6531[D loss: 0.433566, acc: 60.16%, op_acc: 35.16%] [G loss: 0.894435]\n",
      "epoch:8 step:6532[D loss: 0.460552, acc: 55.47%, op_acc: 25.78%] [G loss: 0.905789]\n",
      "epoch:8 step:6533[D loss: 0.422208, acc: 62.50%, op_acc: 33.59%] [G loss: 0.883044]\n",
      "epoch:8 step:6534[D loss: 0.439309, acc: 57.03%, op_acc: 32.03%] [G loss: 0.958482]\n",
      "epoch:8 step:6535[D loss: 0.462176, acc: 54.69%, op_acc: 37.50%] [G loss: 0.947399]\n",
      "epoch:8 step:6536[D loss: 0.446278, acc: 58.59%, op_acc: 38.28%] [G loss: 0.934001]\n",
      "epoch:8 step:6537[D loss: 0.445667, acc: 60.16%, op_acc: 29.69%] [G loss: 0.996437]\n",
      "epoch:8 step:6538[D loss: 0.434632, acc: 64.06%, op_acc: 35.16%] [G loss: 0.968393]\n",
      "epoch:8 step:6539[D loss: 0.456705, acc: 53.12%, op_acc: 36.72%] [G loss: 0.932050]\n",
      "epoch:8 step:6540[D loss: 0.472513, acc: 59.38%, op_acc: 30.47%] [G loss: 0.949358]\n",
      "epoch:8 step:6541[D loss: 0.451594, acc: 59.38%, op_acc: 32.81%] [G loss: 0.934702]\n",
      "epoch:8 step:6542[D loss: 0.415600, acc: 69.53%, op_acc: 35.94%] [G loss: 0.921536]\n",
      "epoch:8 step:6543[D loss: 0.408457, acc: 67.97%, op_acc: 36.72%] [G loss: 1.001058]\n",
      "epoch:8 step:6544[D loss: 0.410515, acc: 61.72%, op_acc: 38.28%] [G loss: 0.987110]\n",
      "epoch:8 step:6545[D loss: 0.452922, acc: 55.47%, op_acc: 29.69%] [G loss: 0.932145]\n",
      "epoch:8 step:6546[D loss: 0.436310, acc: 60.94%, op_acc: 34.38%] [G loss: 0.841947]\n",
      "epoch:8 step:6547[D loss: 0.383889, acc: 74.22%, op_acc: 37.50%] [G loss: 1.009859]\n",
      "epoch:8 step:6548[D loss: 0.467819, acc: 56.25%, op_acc: 33.59%] [G loss: 0.847261]\n",
      "epoch:8 step:6549[D loss: 0.419884, acc: 64.84%, op_acc: 32.81%] [G loss: 0.890308]\n",
      "epoch:8 step:6550[D loss: 0.398570, acc: 70.31%, op_acc: 34.38%] [G loss: 0.954788]\n",
      "epoch:8 step:6551[D loss: 0.433176, acc: 60.94%, op_acc: 32.81%] [G loss: 0.872050]\n",
      "epoch:8 step:6552[D loss: 0.435074, acc: 59.38%, op_acc: 33.59%] [G loss: 0.869015]\n",
      "epoch:8 step:6553[D loss: 0.455256, acc: 56.25%, op_acc: 34.38%] [G loss: 0.901462]\n",
      "epoch:8 step:6554[D loss: 0.457474, acc: 62.50%, op_acc: 31.25%] [G loss: 0.839113]\n",
      "epoch:8 step:6555[D loss: 0.427714, acc: 60.16%, op_acc: 40.62%] [G loss: 0.916646]\n",
      "epoch:8 step:6556[D loss: 0.447114, acc: 60.94%, op_acc: 30.47%] [G loss: 0.936434]\n",
      "epoch:8 step:6557[D loss: 0.446933, acc: 62.50%, op_acc: 31.25%] [G loss: 0.933528]\n",
      "epoch:8 step:6558[D loss: 0.447467, acc: 61.72%, op_acc: 34.38%] [G loss: 0.891541]\n",
      "epoch:8 step:6559[D loss: 0.441887, acc: 57.03%, op_acc: 32.81%] [G loss: 0.960990]\n",
      "epoch:8 step:6560[D loss: 0.430372, acc: 64.84%, op_acc: 38.28%] [G loss: 0.871678]\n",
      "epoch:8 step:6561[D loss: 0.433309, acc: 64.06%, op_acc: 36.72%] [G loss: 0.880549]\n",
      "epoch:8 step:6562[D loss: 0.469078, acc: 59.38%, op_acc: 36.72%] [G loss: 0.929578]\n",
      "epoch:8 step:6563[D loss: 0.451833, acc: 62.50%, op_acc: 26.56%] [G loss: 0.867815]\n",
      "epoch:8 step:6564[D loss: 0.457559, acc: 59.38%, op_acc: 32.81%] [G loss: 0.966534]\n",
      "epoch:8 step:6565[D loss: 0.440814, acc: 62.50%, op_acc: 32.81%] [G loss: 0.864083]\n",
      "epoch:8 step:6566[D loss: 0.460646, acc: 63.28%, op_acc: 30.47%] [G loss: 0.884293]\n",
      "epoch:8 step:6567[D loss: 0.447880, acc: 57.03%, op_acc: 33.59%] [G loss: 0.880850]\n",
      "epoch:8 step:6568[D loss: 0.456810, acc: 57.81%, op_acc: 28.91%] [G loss: 0.984065]\n",
      "epoch:8 step:6569[D loss: 0.469838, acc: 60.16%, op_acc: 31.25%] [G loss: 0.928705]\n",
      "epoch:8 step:6570[D loss: 0.424424, acc: 64.06%, op_acc: 34.38%] [G loss: 1.012317]\n",
      "epoch:8 step:6571[D loss: 0.434130, acc: 64.06%, op_acc: 34.38%] [G loss: 1.010930]\n",
      "epoch:8 step:6572[D loss: 0.452623, acc: 65.62%, op_acc: 29.69%] [G loss: 0.898898]\n",
      "epoch:8 step:6573[D loss: 0.416490, acc: 65.62%, op_acc: 38.28%] [G loss: 0.943346]\n",
      "epoch:8 step:6574[D loss: 0.425939, acc: 63.28%, op_acc: 32.81%] [G loss: 1.042521]\n",
      "epoch:8 step:6575[D loss: 0.403975, acc: 71.88%, op_acc: 39.84%] [G loss: 1.034222]\n",
      "epoch:8 step:6576[D loss: 0.414647, acc: 69.53%, op_acc: 32.81%] [G loss: 0.978857]\n",
      "epoch:8 step:6577[D loss: 0.406131, acc: 63.28%, op_acc: 38.28%] [G loss: 0.914635]\n",
      "epoch:8 step:6578[D loss: 0.452741, acc: 53.12%, op_acc: 36.72%] [G loss: 0.847219]\n",
      "epoch:8 step:6579[D loss: 0.431622, acc: 62.50%, op_acc: 36.72%] [G loss: 0.875239]\n",
      "epoch:8 step:6580[D loss: 0.430346, acc: 61.72%, op_acc: 35.94%] [G loss: 1.011995]\n",
      "epoch:8 step:6581[D loss: 0.412428, acc: 68.75%, op_acc: 35.16%] [G loss: 0.951647]\n",
      "epoch:8 step:6582[D loss: 0.471150, acc: 53.12%, op_acc: 33.59%] [G loss: 0.939294]\n",
      "epoch:8 step:6583[D loss: 0.451923, acc: 64.84%, op_acc: 33.59%] [G loss: 0.982624]\n",
      "epoch:8 step:6584[D loss: 0.439517, acc: 60.16%, op_acc: 32.03%] [G loss: 0.919518]\n",
      "epoch:8 step:6585[D loss: 0.436171, acc: 61.72%, op_acc: 35.94%] [G loss: 0.999246]\n",
      "epoch:8 step:6586[D loss: 0.415255, acc: 64.06%, op_acc: 35.16%] [G loss: 0.931060]\n",
      "epoch:8 step:6587[D loss: 0.426380, acc: 65.62%, op_acc: 35.16%] [G loss: 0.911549]\n",
      "epoch:8 step:6588[D loss: 0.402135, acc: 64.84%, op_acc: 33.59%] [G loss: 1.052203]\n",
      "epoch:8 step:6589[D loss: 0.463701, acc: 55.47%, op_acc: 32.03%] [G loss: 0.984100]\n",
      "epoch:8 step:6590[D loss: 0.443881, acc: 57.81%, op_acc: 35.16%] [G loss: 0.889370]\n",
      "epoch:8 step:6591[D loss: 0.437291, acc: 67.19%, op_acc: 28.91%] [G loss: 1.044428]\n",
      "epoch:8 step:6592[D loss: 0.450778, acc: 58.59%, op_acc: 30.47%] [G loss: 0.890163]\n",
      "epoch:8 step:6593[D loss: 0.428772, acc: 62.50%, op_acc: 31.25%] [G loss: 0.819243]\n",
      "epoch:8 step:6594[D loss: 0.434459, acc: 60.94%, op_acc: 32.81%] [G loss: 0.978551]\n",
      "epoch:8 step:6595[D loss: 0.455396, acc: 54.69%, op_acc: 38.28%] [G loss: 0.932949]\n",
      "epoch:8 step:6596[D loss: 0.440581, acc: 60.16%, op_acc: 36.72%] [G loss: 0.922611]\n",
      "epoch:8 step:6597[D loss: 0.439020, acc: 56.25%, op_acc: 35.16%] [G loss: 0.965603]\n",
      "epoch:8 step:6598[D loss: 0.426206, acc: 62.50%, op_acc: 35.94%] [G loss: 0.996892]\n",
      "epoch:8 step:6599[D loss: 0.431994, acc: 67.19%, op_acc: 32.81%] [G loss: 0.975992]\n",
      "epoch:8 step:6600[D loss: 0.436503, acc: 60.16%, op_acc: 39.84%] [G loss: 0.915022]\n",
      "epoch:8 step:6601[D loss: 0.399324, acc: 68.75%, op_acc: 39.06%] [G loss: 0.973741]\n",
      "epoch:8 step:6602[D loss: 0.463463, acc: 54.69%, op_acc: 35.94%] [G loss: 0.880747]\n",
      "epoch:8 step:6603[D loss: 0.435415, acc: 60.16%, op_acc: 32.03%] [G loss: 0.949408]\n",
      "epoch:8 step:6604[D loss: 0.437801, acc: 61.72%, op_acc: 35.16%] [G loss: 0.970638]\n",
      "epoch:8 step:6605[D loss: 0.466973, acc: 53.12%, op_acc: 33.59%] [G loss: 0.891301]\n",
      "epoch:8 step:6606[D loss: 0.445072, acc: 62.50%, op_acc: 32.03%] [G loss: 0.878309]\n",
      "epoch:8 step:6607[D loss: 0.445812, acc: 57.03%, op_acc: 32.03%] [G loss: 1.017083]\n",
      "epoch:8 step:6608[D loss: 0.466507, acc: 55.47%, op_acc: 32.81%] [G loss: 0.981279]\n",
      "epoch:8 step:6609[D loss: 0.438525, acc: 59.38%, op_acc: 35.94%] [G loss: 0.928616]\n",
      "epoch:8 step:6610[D loss: 0.440305, acc: 53.91%, op_acc: 39.06%] [G loss: 0.855107]\n",
      "epoch:8 step:6611[D loss: 0.443899, acc: 64.06%, op_acc: 31.25%] [G loss: 0.964904]\n",
      "epoch:8 step:6612[D loss: 0.451183, acc: 54.69%, op_acc: 35.94%] [G loss: 0.913100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6613[D loss: 0.416900, acc: 64.06%, op_acc: 42.97%] [G loss: 0.951882]\n",
      "epoch:8 step:6614[D loss: 0.425073, acc: 63.28%, op_acc: 34.38%] [G loss: 0.955795]\n",
      "epoch:8 step:6615[D loss: 0.443378, acc: 63.28%, op_acc: 36.72%] [G loss: 0.943910]\n",
      "epoch:8 step:6616[D loss: 0.418841, acc: 70.31%, op_acc: 32.81%] [G loss: 0.969482]\n",
      "epoch:8 step:6617[D loss: 0.461000, acc: 60.16%, op_acc: 36.72%] [G loss: 0.880944]\n",
      "epoch:8 step:6618[D loss: 0.432166, acc: 59.38%, op_acc: 36.72%] [G loss: 0.905486]\n",
      "epoch:8 step:6619[D loss: 0.427961, acc: 59.38%, op_acc: 36.72%] [G loss: 0.930359]\n",
      "epoch:8 step:6620[D loss: 0.427928, acc: 64.06%, op_acc: 35.16%] [G loss: 0.911438]\n",
      "epoch:8 step:6621[D loss: 0.471116, acc: 53.91%, op_acc: 37.50%] [G loss: 0.979136]\n",
      "epoch:8 step:6622[D loss: 0.420518, acc: 63.28%, op_acc: 42.19%] [G loss: 0.953994]\n",
      "epoch:8 step:6623[D loss: 0.437721, acc: 55.47%, op_acc: 35.16%] [G loss: 0.935500]\n",
      "epoch:8 step:6624[D loss: 0.418647, acc: 67.97%, op_acc: 36.72%] [G loss: 0.926805]\n",
      "epoch:8 step:6625[D loss: 0.437178, acc: 62.50%, op_acc: 35.16%] [G loss: 0.904884]\n",
      "epoch:8 step:6626[D loss: 0.404331, acc: 66.41%, op_acc: 37.50%] [G loss: 0.931847]\n",
      "epoch:8 step:6627[D loss: 0.429966, acc: 63.28%, op_acc: 32.03%] [G loss: 0.959201]\n",
      "epoch:8 step:6628[D loss: 0.434190, acc: 64.84%, op_acc: 39.06%] [G loss: 0.995039]\n",
      "epoch:8 step:6629[D loss: 0.425675, acc: 68.75%, op_acc: 32.03%] [G loss: 0.950841]\n",
      "epoch:8 step:6630[D loss: 0.422404, acc: 67.19%, op_acc: 37.50%] [G loss: 0.925328]\n",
      "epoch:8 step:6631[D loss: 0.389864, acc: 69.53%, op_acc: 38.28%] [G loss: 0.984232]\n",
      "epoch:8 step:6632[D loss: 0.413544, acc: 72.66%, op_acc: 39.06%] [G loss: 1.055857]\n",
      "epoch:8 step:6633[D loss: 0.401824, acc: 62.50%, op_acc: 43.75%] [G loss: 0.912733]\n",
      "epoch:8 step:6634[D loss: 0.413835, acc: 67.97%, op_acc: 37.50%] [G loss: 1.053728]\n",
      "epoch:8 step:6635[D loss: 0.443142, acc: 64.06%, op_acc: 29.69%] [G loss: 0.993007]\n",
      "epoch:8 step:6636[D loss: 0.457344, acc: 63.28%, op_acc: 32.81%] [G loss: 0.994058]\n",
      "epoch:8 step:6637[D loss: 0.478863, acc: 55.47%, op_acc: 31.25%] [G loss: 0.957735]\n",
      "epoch:8 step:6638[D loss: 0.448651, acc: 57.03%, op_acc: 32.03%] [G loss: 1.027057]\n",
      "epoch:8 step:6639[D loss: 0.427105, acc: 59.38%, op_acc: 39.06%] [G loss: 0.955110]\n",
      "epoch:8 step:6640[D loss: 0.420435, acc: 61.72%, op_acc: 41.41%] [G loss: 0.928304]\n",
      "epoch:8 step:6641[D loss: 0.463806, acc: 52.34%, op_acc: 36.72%] [G loss: 0.821382]\n",
      "epoch:8 step:6642[D loss: 0.419263, acc: 67.97%, op_acc: 35.16%] [G loss: 0.928304]\n",
      "epoch:8 step:6643[D loss: 0.444827, acc: 62.50%, op_acc: 29.69%] [G loss: 0.923819]\n",
      "epoch:8 step:6644[D loss: 0.429231, acc: 59.38%, op_acc: 38.28%] [G loss: 0.971348]\n",
      "epoch:8 step:6645[D loss: 0.416302, acc: 57.81%, op_acc: 39.06%] [G loss: 0.937757]\n",
      "epoch:8 step:6646[D loss: 0.478709, acc: 51.56%, op_acc: 32.81%] [G loss: 0.952888]\n",
      "epoch:8 step:6647[D loss: 0.428669, acc: 61.72%, op_acc: 33.59%] [G loss: 0.843070]\n",
      "epoch:8 step:6648[D loss: 0.426422, acc: 64.06%, op_acc: 36.72%] [G loss: 0.956594]\n",
      "epoch:8 step:6649[D loss: 0.435921, acc: 61.72%, op_acc: 37.50%] [G loss: 0.838908]\n",
      "epoch:8 step:6650[D loss: 0.438426, acc: 60.16%, op_acc: 31.25%] [G loss: 0.998337]\n",
      "epoch:8 step:6651[D loss: 0.422937, acc: 66.41%, op_acc: 35.94%] [G loss: 0.975453]\n",
      "epoch:8 step:6652[D loss: 0.417552, acc: 62.50%, op_acc: 42.19%] [G loss: 1.039352]\n",
      "epoch:8 step:6653[D loss: 0.440800, acc: 62.50%, op_acc: 31.25%] [G loss: 1.006182]\n",
      "epoch:8 step:6654[D loss: 0.443630, acc: 58.59%, op_acc: 35.94%] [G loss: 0.954384]\n",
      "epoch:8 step:6655[D loss: 0.447837, acc: 57.81%, op_acc: 29.69%] [G loss: 0.950309]\n",
      "epoch:8 step:6656[D loss: 0.412257, acc: 60.94%, op_acc: 44.53%] [G loss: 1.080719]\n",
      "epoch:8 step:6657[D loss: 0.417383, acc: 60.94%, op_acc: 35.16%] [G loss: 0.983844]\n",
      "epoch:8 step:6658[D loss: 0.434960, acc: 59.38%, op_acc: 37.50%] [G loss: 0.857310]\n",
      "epoch:8 step:6659[D loss: 0.444520, acc: 58.59%, op_acc: 30.47%] [G loss: 0.862575]\n",
      "epoch:8 step:6660[D loss: 0.443874, acc: 53.91%, op_acc: 34.38%] [G loss: 0.850648]\n",
      "epoch:8 step:6661[D loss: 0.428600, acc: 62.50%, op_acc: 33.59%] [G loss: 0.908275]\n",
      "epoch:8 step:6662[D loss: 0.433264, acc: 59.38%, op_acc: 37.50%] [G loss: 0.901021]\n",
      "epoch:8 step:6663[D loss: 0.446031, acc: 57.81%, op_acc: 35.16%] [G loss: 0.949589]\n",
      "epoch:8 step:6664[D loss: 0.429034, acc: 66.41%, op_acc: 32.03%] [G loss: 0.958876]\n",
      "epoch:8 step:6665[D loss: 0.418173, acc: 65.62%, op_acc: 38.28%] [G loss: 0.981150]\n",
      "epoch:8 step:6666[D loss: 0.391076, acc: 71.88%, op_acc: 37.50%] [G loss: 1.001847]\n",
      "epoch:8 step:6667[D loss: 0.460998, acc: 57.03%, op_acc: 31.25%] [G loss: 0.869941]\n",
      "epoch:8 step:6668[D loss: 0.457420, acc: 54.69%, op_acc: 33.59%] [G loss: 0.977728]\n",
      "epoch:8 step:6669[D loss: 0.447417, acc: 60.94%, op_acc: 35.16%] [G loss: 1.029070]\n",
      "epoch:8 step:6670[D loss: 0.409465, acc: 64.06%, op_acc: 40.62%] [G loss: 0.997527]\n",
      "epoch:8 step:6671[D loss: 0.463160, acc: 59.38%, op_acc: 32.03%] [G loss: 0.978127]\n",
      "epoch:8 step:6672[D loss: 0.436582, acc: 67.19%, op_acc: 36.72%] [G loss: 0.928793]\n",
      "epoch:8 step:6673[D loss: 0.449344, acc: 61.72%, op_acc: 39.06%] [G loss: 0.924455]\n",
      "epoch:8 step:6674[D loss: 0.433159, acc: 64.06%, op_acc: 34.38%] [G loss: 0.981406]\n",
      "epoch:8 step:6675[D loss: 0.443592, acc: 62.50%, op_acc: 33.59%] [G loss: 0.903422]\n",
      "epoch:8 step:6676[D loss: 0.460128, acc: 53.91%, op_acc: 38.28%] [G loss: 0.988628]\n",
      "epoch:8 step:6677[D loss: 0.436947, acc: 63.28%, op_acc: 32.81%] [G loss: 0.905324]\n",
      "epoch:8 step:6678[D loss: 0.409762, acc: 67.97%, op_acc: 34.38%] [G loss: 0.964908]\n",
      "epoch:8 step:6679[D loss: 0.434881, acc: 67.19%, op_acc: 27.34%] [G loss: 1.043468]\n",
      "epoch:8 step:6680[D loss: 0.438059, acc: 57.03%, op_acc: 35.94%] [G loss: 0.957642]\n",
      "epoch:8 step:6681[D loss: 0.420752, acc: 68.75%, op_acc: 36.72%] [G loss: 0.893794]\n",
      "epoch:8 step:6682[D loss: 0.445933, acc: 53.12%, op_acc: 38.28%] [G loss: 0.899342]\n",
      "epoch:8 step:6683[D loss: 0.436390, acc: 59.38%, op_acc: 37.50%] [G loss: 0.889990]\n",
      "epoch:8 step:6684[D loss: 0.470636, acc: 53.91%, op_acc: 31.25%] [G loss: 0.913617]\n",
      "epoch:8 step:6685[D loss: 0.459251, acc: 56.25%, op_acc: 31.25%] [G loss: 0.872635]\n",
      "epoch:8 step:6686[D loss: 0.440556, acc: 60.94%, op_acc: 34.38%] [G loss: 0.975622]\n",
      "epoch:8 step:6687[D loss: 0.444713, acc: 60.16%, op_acc: 34.38%] [G loss: 0.899072]\n",
      "epoch:8 step:6688[D loss: 0.454425, acc: 61.72%, op_acc: 33.59%] [G loss: 0.852629]\n",
      "epoch:8 step:6689[D loss: 0.431771, acc: 65.62%, op_acc: 30.47%] [G loss: 0.916103]\n",
      "epoch:8 step:6690[D loss: 0.417767, acc: 60.16%, op_acc: 35.16%] [G loss: 0.934715]\n",
      "epoch:8 step:6691[D loss: 0.461719, acc: 62.50%, op_acc: 32.03%] [G loss: 0.916209]\n",
      "epoch:8 step:6692[D loss: 0.416558, acc: 67.19%, op_acc: 40.62%] [G loss: 1.035996]\n",
      "epoch:8 step:6693[D loss: 0.435880, acc: 61.72%, op_acc: 32.03%] [G loss: 0.929298]\n",
      "epoch:8 step:6694[D loss: 0.452125, acc: 57.03%, op_acc: 31.25%] [G loss: 0.839421]\n",
      "epoch:8 step:6695[D loss: 0.461301, acc: 66.41%, op_acc: 30.47%] [G loss: 0.843251]\n",
      "epoch:8 step:6696[D loss: 0.401584, acc: 68.75%, op_acc: 39.06%] [G loss: 0.875331]\n",
      "epoch:8 step:6697[D loss: 0.424258, acc: 66.41%, op_acc: 36.72%] [G loss: 0.962571]\n",
      "epoch:8 step:6698[D loss: 0.458429, acc: 58.59%, op_acc: 28.91%] [G loss: 0.932087]\n",
      "epoch:8 step:6699[D loss: 0.453236, acc: 53.12%, op_acc: 35.94%] [G loss: 0.958888]\n",
      "epoch:8 step:6700[D loss: 0.432246, acc: 62.50%, op_acc: 42.19%] [G loss: 0.965038]\n",
      "epoch:8 step:6701[D loss: 0.408599, acc: 62.50%, op_acc: 40.62%] [G loss: 1.009701]\n",
      "epoch:8 step:6702[D loss: 0.437527, acc: 61.72%, op_acc: 28.91%] [G loss: 0.950612]\n",
      "epoch:8 step:6703[D loss: 0.448108, acc: 55.47%, op_acc: 32.81%] [G loss: 0.926431]\n",
      "epoch:8 step:6704[D loss: 0.482953, acc: 53.12%, op_acc: 37.50%] [G loss: 0.952839]\n",
      "epoch:8 step:6705[D loss: 0.442042, acc: 55.47%, op_acc: 35.94%] [G loss: 0.858655]\n",
      "epoch:8 step:6706[D loss: 0.406151, acc: 60.94%, op_acc: 40.62%] [G loss: 0.934742]\n",
      "epoch:8 step:6707[D loss: 0.442000, acc: 57.03%, op_acc: 34.38%] [G loss: 0.866286]\n",
      "epoch:8 step:6708[D loss: 0.433455, acc: 60.16%, op_acc: 38.28%] [G loss: 0.952542]\n",
      "epoch:8 step:6709[D loss: 0.445856, acc: 58.59%, op_acc: 31.25%] [G loss: 0.915437]\n",
      "epoch:8 step:6710[D loss: 0.438778, acc: 67.19%, op_acc: 29.69%] [G loss: 0.959912]\n",
      "epoch:8 step:6711[D loss: 0.406718, acc: 67.97%, op_acc: 39.84%] [G loss: 1.015532]\n",
      "epoch:8 step:6712[D loss: 0.429159, acc: 65.62%, op_acc: 33.59%] [G loss: 0.974696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6713[D loss: 0.418910, acc: 65.62%, op_acc: 32.81%] [G loss: 0.977656]\n",
      "epoch:8 step:6714[D loss: 0.428229, acc: 60.94%, op_acc: 42.19%] [G loss: 0.949041]\n",
      "epoch:8 step:6715[D loss: 0.420960, acc: 63.28%, op_acc: 32.81%] [G loss: 0.953578]\n",
      "epoch:8 step:6716[D loss: 0.396563, acc: 64.84%, op_acc: 37.50%] [G loss: 0.894758]\n",
      "epoch:8 step:6717[D loss: 0.385173, acc: 66.41%, op_acc: 40.62%] [G loss: 0.940878]\n",
      "epoch:8 step:6718[D loss: 0.407714, acc: 71.09%, op_acc: 34.38%] [G loss: 1.051851]\n",
      "epoch:8 step:6719[D loss: 0.447300, acc: 61.72%, op_acc: 30.47%] [G loss: 0.900279]\n",
      "epoch:8 step:6720[D loss: 0.429153, acc: 63.28%, op_acc: 39.84%] [G loss: 0.885476]\n",
      "epoch:8 step:6721[D loss: 0.449592, acc: 53.91%, op_acc: 40.62%] [G loss: 0.857872]\n",
      "epoch:8 step:6722[D loss: 0.425713, acc: 61.72%, op_acc: 31.25%] [G loss: 0.865886]\n",
      "epoch:8 step:6723[D loss: 0.429917, acc: 60.94%, op_acc: 35.16%] [G loss: 0.894952]\n",
      "epoch:8 step:6724[D loss: 0.454300, acc: 57.81%, op_acc: 33.59%] [G loss: 0.923932]\n",
      "epoch:8 step:6725[D loss: 0.448813, acc: 57.03%, op_acc: 32.03%] [G loss: 1.003720]\n",
      "epoch:8 step:6726[D loss: 0.433203, acc: 59.38%, op_acc: 39.06%] [G loss: 0.997717]\n",
      "epoch:8 step:6727[D loss: 0.444143, acc: 58.59%, op_acc: 33.59%] [G loss: 0.952364]\n",
      "epoch:8 step:6728[D loss: 0.440601, acc: 64.06%, op_acc: 32.81%] [G loss: 0.942918]\n",
      "epoch:8 step:6729[D loss: 0.468542, acc: 61.72%, op_acc: 25.00%] [G loss: 0.936313]\n",
      "epoch:8 step:6730[D loss: 0.442156, acc: 60.16%, op_acc: 42.19%] [G loss: 0.928709]\n",
      "epoch:8 step:6731[D loss: 0.423307, acc: 64.84%, op_acc: 36.72%] [G loss: 0.975109]\n",
      "epoch:8 step:6732[D loss: 0.419342, acc: 65.62%, op_acc: 37.50%] [G loss: 0.953749]\n",
      "epoch:8 step:6733[D loss: 0.445632, acc: 57.81%, op_acc: 32.81%] [G loss: 0.888245]\n",
      "epoch:8 step:6734[D loss: 0.429023, acc: 67.19%, op_acc: 40.62%] [G loss: 0.843773]\n",
      "epoch:8 step:6735[D loss: 0.427132, acc: 69.53%, op_acc: 35.16%] [G loss: 0.932373]\n",
      "epoch:8 step:6736[D loss: 0.466365, acc: 56.25%, op_acc: 29.69%] [G loss: 0.916266]\n",
      "epoch:8 step:6737[D loss: 0.436737, acc: 61.72%, op_acc: 40.62%] [G loss: 0.931722]\n",
      "epoch:8 step:6738[D loss: 0.414997, acc: 64.84%, op_acc: 39.06%] [G loss: 0.926944]\n",
      "epoch:8 step:6739[D loss: 0.480124, acc: 57.03%, op_acc: 31.25%] [G loss: 0.892199]\n",
      "epoch:8 step:6740[D loss: 0.412632, acc: 67.97%, op_acc: 35.94%] [G loss: 1.003377]\n",
      "epoch:8 step:6741[D loss: 0.414494, acc: 71.09%, op_acc: 35.16%] [G loss: 0.961910]\n",
      "epoch:8 step:6742[D loss: 0.403709, acc: 64.84%, op_acc: 35.16%] [G loss: 0.869726]\n",
      "epoch:8 step:6743[D loss: 0.430901, acc: 60.16%, op_acc: 35.16%] [G loss: 0.898514]\n",
      "epoch:8 step:6744[D loss: 0.425843, acc: 61.72%, op_acc: 37.50%] [G loss: 0.900990]\n",
      "epoch:8 step:6745[D loss: 0.450386, acc: 50.00%, op_acc: 36.72%] [G loss: 0.910932]\n",
      "epoch:8 step:6746[D loss: 0.458434, acc: 62.50%, op_acc: 35.94%] [G loss: 0.948815]\n",
      "epoch:8 step:6747[D loss: 0.453875, acc: 57.81%, op_acc: 39.06%] [G loss: 0.945133]\n",
      "epoch:8 step:6748[D loss: 0.411267, acc: 66.41%, op_acc: 35.94%] [G loss: 1.021680]\n",
      "epoch:8 step:6749[D loss: 0.483499, acc: 54.69%, op_acc: 33.59%] [G loss: 0.923437]\n",
      "epoch:8 step:6750[D loss: 0.402883, acc: 67.19%, op_acc: 39.84%] [G loss: 1.018842]\n",
      "epoch:8 step:6751[D loss: 0.437525, acc: 61.72%, op_acc: 30.47%] [G loss: 0.887606]\n",
      "epoch:8 step:6752[D loss: 0.467546, acc: 52.34%, op_acc: 34.38%] [G loss: 1.003193]\n",
      "epoch:8 step:6753[D loss: 0.416730, acc: 69.53%, op_acc: 34.38%] [G loss: 1.024067]\n",
      "epoch:8 step:6754[D loss: 0.445870, acc: 60.16%, op_acc: 33.59%] [G loss: 0.891405]\n",
      "epoch:8 step:6755[D loss: 0.429024, acc: 58.59%, op_acc: 34.38%] [G loss: 0.976941]\n",
      "epoch:8 step:6756[D loss: 0.433675, acc: 66.41%, op_acc: 35.94%] [G loss: 0.958553]\n",
      "epoch:8 step:6757[D loss: 0.447145, acc: 63.28%, op_acc: 35.16%] [G loss: 0.972276]\n",
      "epoch:8 step:6758[D loss: 0.455251, acc: 58.59%, op_acc: 34.38%] [G loss: 1.021276]\n",
      "epoch:8 step:6759[D loss: 0.426387, acc: 59.38%, op_acc: 40.62%] [G loss: 0.972158]\n",
      "epoch:8 step:6760[D loss: 0.472790, acc: 56.25%, op_acc: 29.69%] [G loss: 0.913389]\n",
      "epoch:8 step:6761[D loss: 0.439743, acc: 59.38%, op_acc: 35.94%] [G loss: 0.894644]\n",
      "epoch:8 step:6762[D loss: 0.457559, acc: 53.12%, op_acc: 32.03%] [G loss: 0.836736]\n",
      "epoch:8 step:6763[D loss: 0.424664, acc: 65.62%, op_acc: 33.59%] [G loss: 0.897990]\n",
      "epoch:8 step:6764[D loss: 0.391294, acc: 70.31%, op_acc: 31.25%] [G loss: 0.901765]\n",
      "epoch:8 step:6765[D loss: 0.478940, acc: 52.34%, op_acc: 25.78%] [G loss: 0.964299]\n",
      "epoch:8 step:6766[D loss: 0.406513, acc: 71.09%, op_acc: 33.59%] [G loss: 0.943653]\n",
      "epoch:8 step:6767[D loss: 0.399726, acc: 64.06%, op_acc: 38.28%] [G loss: 0.957813]\n",
      "epoch:8 step:6768[D loss: 0.442028, acc: 55.47%, op_acc: 38.28%] [G loss: 0.934366]\n",
      "epoch:8 step:6769[D loss: 0.427361, acc: 68.75%, op_acc: 30.47%] [G loss: 0.886148]\n",
      "epoch:8 step:6770[D loss: 0.463426, acc: 53.91%, op_acc: 35.16%] [G loss: 0.895687]\n",
      "epoch:8 step:6771[D loss: 0.451158, acc: 57.81%, op_acc: 33.59%] [G loss: 0.928198]\n",
      "epoch:8 step:6772[D loss: 0.426776, acc: 69.53%, op_acc: 33.59%] [G loss: 0.941467]\n",
      "epoch:8 step:6773[D loss: 0.439922, acc: 58.59%, op_acc: 31.25%] [G loss: 0.982203]\n",
      "epoch:8 step:6774[D loss: 0.491222, acc: 55.47%, op_acc: 29.69%] [G loss: 0.982397]\n",
      "epoch:8 step:6775[D loss: 0.432258, acc: 57.03%, op_acc: 43.75%] [G loss: 1.103354]\n",
      "epoch:8 step:6776[D loss: 0.428401, acc: 63.28%, op_acc: 34.38%] [G loss: 0.910049]\n",
      "epoch:8 step:6777[D loss: 0.432786, acc: 64.84%, op_acc: 35.94%] [G loss: 0.943700]\n",
      "epoch:8 step:6778[D loss: 0.462848, acc: 53.91%, op_acc: 33.59%] [G loss: 0.900263]\n",
      "epoch:8 step:6779[D loss: 0.415189, acc: 67.19%, op_acc: 32.03%] [G loss: 0.924481]\n",
      "epoch:8 step:6780[D loss: 0.461835, acc: 53.12%, op_acc: 35.16%] [G loss: 0.987757]\n",
      "epoch:8 step:6781[D loss: 0.422740, acc: 60.16%, op_acc: 42.19%] [G loss: 0.895112]\n",
      "epoch:8 step:6782[D loss: 0.434301, acc: 58.59%, op_acc: 39.06%] [G loss: 1.000851]\n",
      "epoch:8 step:6783[D loss: 0.446392, acc: 60.16%, op_acc: 32.81%] [G loss: 0.914983]\n",
      "epoch:8 step:6784[D loss: 0.430066, acc: 59.38%, op_acc: 37.50%] [G loss: 0.990001]\n",
      "epoch:8 step:6785[D loss: 0.432373, acc: 63.28%, op_acc: 35.16%] [G loss: 0.933357]\n",
      "epoch:8 step:6786[D loss: 0.421399, acc: 63.28%, op_acc: 35.16%] [G loss: 0.883466]\n",
      "epoch:8 step:6787[D loss: 0.464078, acc: 57.81%, op_acc: 35.94%] [G loss: 0.978203]\n",
      "epoch:8 step:6788[D loss: 0.395832, acc: 69.53%, op_acc: 35.16%] [G loss: 0.867772]\n",
      "epoch:8 step:6789[D loss: 0.402255, acc: 69.53%, op_acc: 41.41%] [G loss: 0.932028]\n",
      "epoch:8 step:6790[D loss: 0.445365, acc: 59.38%, op_acc: 28.91%] [G loss: 0.902073]\n",
      "epoch:8 step:6791[D loss: 0.461236, acc: 57.03%, op_acc: 34.38%] [G loss: 0.867208]\n",
      "epoch:8 step:6792[D loss: 0.410521, acc: 64.06%, op_acc: 42.19%] [G loss: 0.893653]\n",
      "epoch:8 step:6793[D loss: 0.400771, acc: 68.75%, op_acc: 34.38%] [G loss: 0.960389]\n",
      "epoch:8 step:6794[D loss: 0.451411, acc: 50.78%, op_acc: 32.03%] [G loss: 0.938513]\n",
      "epoch:8 step:6795[D loss: 0.430903, acc: 64.84%, op_acc: 32.81%] [G loss: 0.918593]\n",
      "epoch:8 step:6796[D loss: 0.457615, acc: 60.16%, op_acc: 29.69%] [G loss: 0.977916]\n",
      "epoch:8 step:6797[D loss: 0.444319, acc: 62.50%, op_acc: 35.16%] [G loss: 1.028152]\n",
      "epoch:8 step:6798[D loss: 0.421664, acc: 63.28%, op_acc: 36.72%] [G loss: 1.069136]\n",
      "epoch:8 step:6799[D loss: 0.448983, acc: 57.81%, op_acc: 35.16%] [G loss: 0.971900]\n",
      "epoch:8 step:6800[D loss: 0.476724, acc: 52.34%, op_acc: 21.88%] [G loss: 0.942811]\n",
      "epoch:8 step:6801[D loss: 0.398726, acc: 67.97%, op_acc: 40.62%] [G loss: 0.951120]\n",
      "epoch:8 step:6802[D loss: 0.446594, acc: 58.59%, op_acc: 31.25%] [G loss: 0.893906]\n",
      "epoch:8 step:6803[D loss: 0.464303, acc: 50.78%, op_acc: 32.03%] [G loss: 0.885086]\n",
      "epoch:8 step:6804[D loss: 0.448818, acc: 53.12%, op_acc: 38.28%] [G loss: 0.973704]\n",
      "epoch:8 step:6805[D loss: 0.441168, acc: 57.81%, op_acc: 29.69%] [G loss: 0.949216]\n",
      "epoch:8 step:6806[D loss: 0.444066, acc: 57.81%, op_acc: 38.28%] [G loss: 0.912052]\n",
      "epoch:8 step:6807[D loss: 0.413749, acc: 64.06%, op_acc: 35.16%] [G loss: 0.985059]\n",
      "epoch:8 step:6808[D loss: 0.461536, acc: 52.34%, op_acc: 35.94%] [G loss: 0.915051]\n",
      "epoch:8 step:6809[D loss: 0.443650, acc: 57.03%, op_acc: 35.94%] [G loss: 0.898878]\n",
      "epoch:8 step:6810[D loss: 0.441073, acc: 61.72%, op_acc: 36.72%] [G loss: 0.870197]\n",
      "epoch:8 step:6811[D loss: 0.460157, acc: 56.25%, op_acc: 32.81%] [G loss: 0.987756]\n",
      "epoch:8 step:6812[D loss: 0.404067, acc: 67.19%, op_acc: 41.41%] [G loss: 1.031546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6813[D loss: 0.415954, acc: 66.41%, op_acc: 39.84%] [G loss: 0.919104]\n",
      "epoch:8 step:6814[D loss: 0.424539, acc: 65.62%, op_acc: 32.81%] [G loss: 0.908588]\n",
      "epoch:8 step:6815[D loss: 0.408286, acc: 69.53%, op_acc: 39.06%] [G loss: 0.976722]\n",
      "epoch:8 step:6816[D loss: 0.444443, acc: 59.38%, op_acc: 35.16%] [G loss: 0.963058]\n",
      "epoch:8 step:6817[D loss: 0.407551, acc: 64.06%, op_acc: 33.59%] [G loss: 0.980323]\n",
      "epoch:8 step:6818[D loss: 0.418824, acc: 66.41%, op_acc: 35.94%] [G loss: 0.875266]\n",
      "epoch:8 step:6819[D loss: 0.437852, acc: 62.50%, op_acc: 35.16%] [G loss: 0.943421]\n",
      "epoch:8 step:6820[D loss: 0.427215, acc: 61.72%, op_acc: 35.16%] [G loss: 1.001271]\n",
      "epoch:8 step:6821[D loss: 0.448702, acc: 50.78%, op_acc: 35.94%] [G loss: 0.956540]\n",
      "epoch:8 step:6822[D loss: 0.451137, acc: 57.81%, op_acc: 33.59%] [G loss: 0.952105]\n",
      "epoch:8 step:6823[D loss: 0.444370, acc: 60.94%, op_acc: 33.59%] [G loss: 0.866763]\n",
      "epoch:8 step:6824[D loss: 0.390784, acc: 67.19%, op_acc: 39.84%] [G loss: 0.893466]\n",
      "epoch:8 step:6825[D loss: 0.459418, acc: 56.25%, op_acc: 35.16%] [G loss: 0.932250]\n",
      "epoch:8 step:6826[D loss: 0.448825, acc: 57.03%, op_acc: 28.91%] [G loss: 0.915282]\n",
      "epoch:8 step:6827[D loss: 0.408596, acc: 60.94%, op_acc: 38.28%] [G loss: 1.005944]\n",
      "epoch:8 step:6828[D loss: 0.430836, acc: 62.50%, op_acc: 39.06%] [G loss: 0.973616]\n",
      "epoch:8 step:6829[D loss: 0.435811, acc: 60.16%, op_acc: 36.72%] [G loss: 0.941923]\n",
      "epoch:8 step:6830[D loss: 0.436501, acc: 57.03%, op_acc: 32.03%] [G loss: 0.920918]\n",
      "epoch:8 step:6831[D loss: 0.409445, acc: 67.19%, op_acc: 37.50%] [G loss: 0.942307]\n",
      "epoch:8 step:6832[D loss: 0.422839, acc: 67.97%, op_acc: 33.59%] [G loss: 0.970601]\n",
      "epoch:8 step:6833[D loss: 0.401653, acc: 68.75%, op_acc: 35.16%] [G loss: 0.950236]\n",
      "epoch:8 step:6834[D loss: 0.456962, acc: 60.16%, op_acc: 28.12%] [G loss: 0.930257]\n",
      "epoch:8 step:6835[D loss: 0.424671, acc: 62.50%, op_acc: 35.16%] [G loss: 0.958290]\n",
      "epoch:8 step:6836[D loss: 0.420698, acc: 61.72%, op_acc: 35.94%] [G loss: 0.902583]\n",
      "epoch:8 step:6837[D loss: 0.447730, acc: 61.72%, op_acc: 32.81%] [G loss: 0.850707]\n",
      "epoch:8 step:6838[D loss: 0.457868, acc: 57.81%, op_acc: 35.16%] [G loss: 0.867307]\n",
      "epoch:8 step:6839[D loss: 0.444048, acc: 62.50%, op_acc: 32.03%] [G loss: 1.004439]\n",
      "epoch:8 step:6840[D loss: 0.422100, acc: 61.72%, op_acc: 34.38%] [G loss: 0.898838]\n",
      "epoch:8 step:6841[D loss: 0.423373, acc: 70.31%, op_acc: 28.91%] [G loss: 0.933546]\n",
      "epoch:8 step:6842[D loss: 0.413290, acc: 67.19%, op_acc: 32.03%] [G loss: 0.968186]\n",
      "epoch:8 step:6843[D loss: 0.440469, acc: 62.50%, op_acc: 34.38%] [G loss: 0.927018]\n",
      "epoch:8 step:6844[D loss: 0.416233, acc: 70.31%, op_acc: 35.16%] [G loss: 1.099047]\n",
      "epoch:8 step:6845[D loss: 0.418697, acc: 60.94%, op_acc: 34.38%] [G loss: 0.927498]\n",
      "epoch:8 step:6846[D loss: 0.466183, acc: 55.47%, op_acc: 34.38%] [G loss: 0.899192]\n",
      "epoch:8 step:6847[D loss: 0.424468, acc: 63.28%, op_acc: 37.50%] [G loss: 0.903273]\n",
      "epoch:8 step:6848[D loss: 0.431267, acc: 57.81%, op_acc: 33.59%] [G loss: 1.056925]\n",
      "epoch:8 step:6849[D loss: 0.413051, acc: 63.28%, op_acc: 39.84%] [G loss: 0.998277]\n",
      "epoch:8 step:6850[D loss: 0.438961, acc: 54.69%, op_acc: 37.50%] [G loss: 0.964397]\n",
      "epoch:8 step:6851[D loss: 0.382389, acc: 66.41%, op_acc: 42.19%] [G loss: 0.928139]\n",
      "epoch:8 step:6852[D loss: 0.460957, acc: 61.72%, op_acc: 32.03%] [G loss: 0.901902]\n",
      "epoch:8 step:6853[D loss: 0.445011, acc: 54.69%, op_acc: 33.59%] [G loss: 0.894573]\n",
      "epoch:8 step:6854[D loss: 0.449291, acc: 59.38%, op_acc: 35.16%] [G loss: 0.918910]\n",
      "epoch:8 step:6855[D loss: 0.431236, acc: 64.84%, op_acc: 39.84%] [G loss: 0.936960]\n",
      "epoch:8 step:6856[D loss: 0.401260, acc: 67.19%, op_acc: 37.50%] [G loss: 0.895246]\n",
      "epoch:8 step:6857[D loss: 0.447728, acc: 60.16%, op_acc: 34.38%] [G loss: 1.016776]\n",
      "epoch:8 step:6858[D loss: 0.407402, acc: 68.75%, op_acc: 36.72%] [G loss: 0.917710]\n",
      "epoch:8 step:6859[D loss: 0.444279, acc: 57.03%, op_acc: 34.38%] [G loss: 0.973353]\n",
      "epoch:8 step:6860[D loss: 0.440013, acc: 62.50%, op_acc: 39.06%] [G loss: 0.932526]\n",
      "epoch:8 step:6861[D loss: 0.457681, acc: 57.81%, op_acc: 32.81%] [G loss: 0.951198]\n",
      "epoch:8 step:6862[D loss: 0.463782, acc: 51.56%, op_acc: 39.84%] [G loss: 0.802387]\n",
      "epoch:8 step:6863[D loss: 0.441125, acc: 60.16%, op_acc: 38.28%] [G loss: 0.894761]\n",
      "epoch:8 step:6864[D loss: 0.437971, acc: 62.50%, op_acc: 35.94%] [G loss: 0.905094]\n",
      "epoch:8 step:6865[D loss: 0.466102, acc: 58.59%, op_acc: 32.03%] [G loss: 0.913527]\n",
      "epoch:8 step:6866[D loss: 0.405688, acc: 71.09%, op_acc: 35.94%] [G loss: 0.925187]\n",
      "epoch:8 step:6867[D loss: 0.451807, acc: 60.16%, op_acc: 39.06%] [G loss: 0.908648]\n",
      "epoch:8 step:6868[D loss: 0.456784, acc: 59.38%, op_acc: 30.47%] [G loss: 0.986996]\n",
      "epoch:8 step:6869[D loss: 0.437900, acc: 62.50%, op_acc: 35.94%] [G loss: 0.871918]\n",
      "epoch:8 step:6870[D loss: 0.474984, acc: 54.69%, op_acc: 30.47%] [G loss: 0.920336]\n",
      "epoch:8 step:6871[D loss: 0.419102, acc: 60.94%, op_acc: 35.94%] [G loss: 0.947862]\n",
      "epoch:8 step:6872[D loss: 0.414133, acc: 63.28%, op_acc: 37.50%] [G loss: 0.941974]\n",
      "epoch:8 step:6873[D loss: 0.440974, acc: 58.59%, op_acc: 37.50%] [G loss: 1.038040]\n",
      "epoch:8 step:6874[D loss: 0.457235, acc: 49.22%, op_acc: 35.94%] [G loss: 0.846182]\n",
      "epoch:8 step:6875[D loss: 0.422788, acc: 65.62%, op_acc: 39.84%] [G loss: 1.005480]\n",
      "epoch:8 step:6876[D loss: 0.437163, acc: 57.03%, op_acc: 34.38%] [G loss: 0.950968]\n",
      "epoch:8 step:6877[D loss: 0.457028, acc: 61.72%, op_acc: 29.69%] [G loss: 0.912550]\n",
      "epoch:8 step:6878[D loss: 0.404349, acc: 64.06%, op_acc: 36.72%] [G loss: 0.844882]\n",
      "epoch:8 step:6879[D loss: 0.436167, acc: 64.84%, op_acc: 39.84%] [G loss: 0.888395]\n",
      "epoch:8 step:6880[D loss: 0.442091, acc: 66.41%, op_acc: 29.69%] [G loss: 0.908780]\n",
      "epoch:8 step:6881[D loss: 0.450965, acc: 62.50%, op_acc: 32.81%] [G loss: 0.901245]\n",
      "epoch:8 step:6882[D loss: 0.403322, acc: 63.28%, op_acc: 43.75%] [G loss: 1.001236]\n",
      "epoch:8 step:6883[D loss: 0.442443, acc: 67.19%, op_acc: 38.28%] [G loss: 1.028379]\n",
      "epoch:8 step:6884[D loss: 0.396810, acc: 67.97%, op_acc: 39.06%] [G loss: 1.059722]\n",
      "epoch:8 step:6885[D loss: 0.434385, acc: 60.16%, op_acc: 32.03%] [G loss: 0.974933]\n",
      "epoch:8 step:6886[D loss: 0.433488, acc: 66.41%, op_acc: 33.59%] [G loss: 0.968704]\n",
      "epoch:8 step:6887[D loss: 0.426911, acc: 66.41%, op_acc: 34.38%] [G loss: 0.982321]\n",
      "epoch:8 step:6888[D loss: 0.439381, acc: 57.81%, op_acc: 33.59%] [G loss: 1.039126]\n",
      "epoch:8 step:6889[D loss: 0.453296, acc: 58.59%, op_acc: 25.78%] [G loss: 0.926475]\n",
      "epoch:8 step:6890[D loss: 0.442035, acc: 60.94%, op_acc: 32.81%] [G loss: 0.955346]\n",
      "epoch:8 step:6891[D loss: 0.475333, acc: 59.38%, op_acc: 32.81%] [G loss: 0.952850]\n",
      "epoch:8 step:6892[D loss: 0.374881, acc: 69.53%, op_acc: 43.75%] [G loss: 1.016801]\n",
      "epoch:8 step:6893[D loss: 0.423420, acc: 62.50%, op_acc: 41.41%] [G loss: 0.978861]\n",
      "epoch:8 step:6894[D loss: 0.449486, acc: 61.72%, op_acc: 32.03%] [G loss: 1.014035]\n",
      "epoch:8 step:6895[D loss: 0.436198, acc: 56.25%, op_acc: 32.81%] [G loss: 0.920400]\n",
      "epoch:8 step:6896[D loss: 0.439126, acc: 60.94%, op_acc: 33.59%] [G loss: 0.828720]\n",
      "epoch:8 step:6897[D loss: 0.469505, acc: 58.59%, op_acc: 31.25%] [G loss: 0.929533]\n",
      "epoch:8 step:6898[D loss: 0.450938, acc: 59.38%, op_acc: 31.25%] [G loss: 0.979457]\n",
      "epoch:8 step:6899[D loss: 0.423792, acc: 64.06%, op_acc: 39.84%] [G loss: 1.008742]\n",
      "epoch:8 step:6900[D loss: 0.423453, acc: 60.16%, op_acc: 35.94%] [G loss: 0.910482]\n",
      "epoch:8 step:6901[D loss: 0.421240, acc: 60.94%, op_acc: 42.19%] [G loss: 0.942473]\n",
      "epoch:8 step:6902[D loss: 0.429496, acc: 64.84%, op_acc: 30.47%] [G loss: 0.889330]\n",
      "epoch:8 step:6903[D loss: 0.407317, acc: 64.06%, op_acc: 35.94%] [G loss: 0.933123]\n",
      "epoch:8 step:6904[D loss: 0.449752, acc: 60.94%, op_acc: 31.25%] [G loss: 0.840528]\n",
      "epoch:8 step:6905[D loss: 0.464593, acc: 54.69%, op_acc: 31.25%] [G loss: 0.902747]\n",
      "epoch:8 step:6906[D loss: 0.418824, acc: 64.84%, op_acc: 35.94%] [G loss: 0.853480]\n",
      "epoch:8 step:6907[D loss: 0.439925, acc: 63.28%, op_acc: 31.25%] [G loss: 0.894524]\n",
      "epoch:8 step:6908[D loss: 0.432060, acc: 64.06%, op_acc: 39.06%] [G loss: 0.958310]\n",
      "epoch:8 step:6909[D loss: 0.426169, acc: 64.84%, op_acc: 40.62%] [G loss: 0.916269]\n",
      "epoch:8 step:6910[D loss: 0.428481, acc: 59.38%, op_acc: 37.50%] [G loss: 0.851382]\n",
      "epoch:8 step:6911[D loss: 0.391861, acc: 70.31%, op_acc: 35.94%] [G loss: 0.930072]\n",
      "epoch:8 step:6912[D loss: 0.407629, acc: 64.06%, op_acc: 35.94%] [G loss: 0.935972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:6913[D loss: 0.469309, acc: 58.59%, op_acc: 24.22%] [G loss: 0.928785]\n",
      "epoch:8 step:6914[D loss: 0.460896, acc: 60.94%, op_acc: 30.47%] [G loss: 0.972696]\n",
      "epoch:8 step:6915[D loss: 0.414683, acc: 67.97%, op_acc: 33.59%] [G loss: 1.024415]\n",
      "epoch:8 step:6916[D loss: 0.455002, acc: 59.38%, op_acc: 31.25%] [G loss: 0.918845]\n",
      "epoch:8 step:6917[D loss: 0.430838, acc: 68.75%, op_acc: 35.16%] [G loss: 0.837514]\n",
      "epoch:8 step:6918[D loss: 0.444328, acc: 64.06%, op_acc: 33.59%] [G loss: 0.944115]\n",
      "epoch:8 step:6919[D loss: 0.456991, acc: 55.47%, op_acc: 38.28%] [G loss: 1.004810]\n",
      "epoch:8 step:6920[D loss: 0.447669, acc: 60.16%, op_acc: 35.94%] [G loss: 0.964733]\n",
      "epoch:8 step:6921[D loss: 0.421940, acc: 60.16%, op_acc: 39.84%] [G loss: 0.882402]\n",
      "epoch:8 step:6922[D loss: 0.410840, acc: 60.94%, op_acc: 39.06%] [G loss: 0.943315]\n",
      "epoch:8 step:6923[D loss: 0.412682, acc: 71.09%, op_acc: 35.94%] [G loss: 1.002788]\n",
      "epoch:8 step:6924[D loss: 0.428613, acc: 67.97%, op_acc: 33.59%] [G loss: 0.991639]\n",
      "epoch:8 step:6925[D loss: 0.459118, acc: 57.03%, op_acc: 31.25%] [G loss: 0.940932]\n",
      "epoch:8 step:6926[D loss: 0.419439, acc: 58.59%, op_acc: 37.50%] [G loss: 0.847808]\n",
      "epoch:8 step:6927[D loss: 0.401714, acc: 64.06%, op_acc: 42.19%] [G loss: 0.933692]\n",
      "epoch:8 step:6928[D loss: 0.429494, acc: 60.94%, op_acc: 37.50%] [G loss: 0.875818]\n",
      "epoch:8 step:6929[D loss: 0.446268, acc: 60.16%, op_acc: 34.38%] [G loss: 0.995895]\n",
      "epoch:8 step:6930[D loss: 0.417390, acc: 63.28%, op_acc: 35.94%] [G loss: 0.969304]\n",
      "epoch:8 step:6931[D loss: 0.456545, acc: 55.47%, op_acc: 38.28%] [G loss: 0.972869]\n",
      "epoch:8 step:6932[D loss: 0.424934, acc: 67.19%, op_acc: 33.59%] [G loss: 1.007750]\n",
      "epoch:8 step:6933[D loss: 0.434295, acc: 62.50%, op_acc: 33.59%] [G loss: 0.954764]\n",
      "epoch:8 step:6934[D loss: 0.450336, acc: 64.06%, op_acc: 31.25%] [G loss: 0.924497]\n",
      "epoch:8 step:6935[D loss: 0.418086, acc: 65.62%, op_acc: 31.25%] [G loss: 1.041431]\n",
      "epoch:8 step:6936[D loss: 0.421249, acc: 62.50%, op_acc: 36.72%] [G loss: 1.032149]\n",
      "epoch:8 step:6937[D loss: 0.442210, acc: 54.69%, op_acc: 37.50%] [G loss: 0.936635]\n",
      "epoch:8 step:6938[D loss: 0.432825, acc: 61.72%, op_acc: 34.38%] [G loss: 0.984972]\n",
      "epoch:8 step:6939[D loss: 0.418663, acc: 63.28%, op_acc: 40.62%] [G loss: 1.020300]\n",
      "epoch:8 step:6940[D loss: 0.486694, acc: 50.00%, op_acc: 31.25%] [G loss: 0.946180]\n",
      "epoch:8 step:6941[D loss: 0.453854, acc: 60.94%, op_acc: 31.25%] [G loss: 1.077406]\n",
      "epoch:8 step:6942[D loss: 0.430041, acc: 62.50%, op_acc: 35.16%] [G loss: 0.995963]\n",
      "epoch:8 step:6943[D loss: 0.440568, acc: 63.28%, op_acc: 28.91%] [G loss: 1.068945]\n",
      "epoch:8 step:6944[D loss: 0.420435, acc: 66.41%, op_acc: 35.94%] [G loss: 1.006187]\n",
      "epoch:8 step:6945[D loss: 0.449425, acc: 59.38%, op_acc: 37.50%] [G loss: 0.891703]\n",
      "epoch:8 step:6946[D loss: 0.416445, acc: 66.41%, op_acc: 36.72%] [G loss: 1.053372]\n",
      "epoch:8 step:6947[D loss: 0.473676, acc: 54.69%, op_acc: 37.50%] [G loss: 0.928910]\n",
      "epoch:8 step:6948[D loss: 0.430317, acc: 64.06%, op_acc: 35.16%] [G loss: 0.943275]\n",
      "epoch:8 step:6949[D loss: 0.429126, acc: 64.84%, op_acc: 31.25%] [G loss: 0.821821]\n",
      "epoch:8 step:6950[D loss: 0.455936, acc: 53.91%, op_acc: 36.72%] [G loss: 0.907794]\n",
      "epoch:8 step:6951[D loss: 0.430270, acc: 63.28%, op_acc: 31.25%] [G loss: 0.977184]\n",
      "epoch:8 step:6952[D loss: 0.405955, acc: 62.50%, op_acc: 45.31%] [G loss: 0.979521]\n",
      "epoch:8 step:6953[D loss: 0.441116, acc: 64.06%, op_acc: 36.72%] [G loss: 0.901198]\n",
      "epoch:8 step:6954[D loss: 0.441302, acc: 60.94%, op_acc: 33.59%] [G loss: 0.919871]\n",
      "epoch:8 step:6955[D loss: 0.470882, acc: 56.25%, op_acc: 31.25%] [G loss: 0.870621]\n",
      "epoch:8 step:6956[D loss: 0.441335, acc: 61.72%, op_acc: 36.72%] [G loss: 0.937546]\n",
      "epoch:8 step:6957[D loss: 0.401542, acc: 64.84%, op_acc: 40.62%] [G loss: 0.980903]\n",
      "epoch:8 step:6958[D loss: 0.399662, acc: 63.28%, op_acc: 42.97%] [G loss: 0.883073]\n",
      "epoch:8 step:6959[D loss: 0.419686, acc: 64.84%, op_acc: 29.69%] [G loss: 0.904051]\n",
      "epoch:8 step:6960[D loss: 0.406941, acc: 66.41%, op_acc: 41.41%] [G loss: 1.008572]\n",
      "epoch:8 step:6961[D loss: 0.412324, acc: 60.94%, op_acc: 35.94%] [G loss: 0.930780]\n",
      "epoch:8 step:6962[D loss: 0.419400, acc: 64.84%, op_acc: 35.94%] [G loss: 0.942008]\n",
      "epoch:8 step:6963[D loss: 0.441276, acc: 60.94%, op_acc: 37.50%] [G loss: 0.924407]\n",
      "epoch:8 step:6964[D loss: 0.494183, acc: 55.47%, op_acc: 33.59%] [G loss: 0.837329]\n",
      "epoch:8 step:6965[D loss: 0.449467, acc: 59.38%, op_acc: 33.59%] [G loss: 0.852310]\n",
      "epoch:8 step:6966[D loss: 0.462500, acc: 57.81%, op_acc: 28.91%] [G loss: 0.977002]\n",
      "epoch:8 step:6967[D loss: 0.436212, acc: 60.16%, op_acc: 42.97%] [G loss: 0.949833]\n",
      "epoch:8 step:6968[D loss: 0.462422, acc: 57.03%, op_acc: 32.81%] [G loss: 0.997883]\n",
      "epoch:8 step:6969[D loss: 0.422188, acc: 60.94%, op_acc: 37.50%] [G loss: 0.997158]\n",
      "epoch:8 step:6970[D loss: 0.465373, acc: 52.34%, op_acc: 33.59%] [G loss: 0.858688]\n",
      "epoch:8 step:6971[D loss: 0.420427, acc: 65.62%, op_acc: 33.59%] [G loss: 0.865129]\n",
      "epoch:8 step:6972[D loss: 0.456042, acc: 66.41%, op_acc: 31.25%] [G loss: 0.981054]\n",
      "epoch:8 step:6973[D loss: 0.429183, acc: 60.94%, op_acc: 32.03%] [G loss: 0.924862]\n",
      "epoch:8 step:6974[D loss: 0.423670, acc: 62.50%, op_acc: 42.19%] [G loss: 0.993134]\n",
      "epoch:8 step:6975[D loss: 0.433170, acc: 67.97%, op_acc: 32.03%] [G loss: 0.984166]\n",
      "epoch:8 step:6976[D loss: 0.475020, acc: 57.03%, op_acc: 31.25%] [G loss: 0.956530]\n",
      "epoch:8 step:6977[D loss: 0.427404, acc: 60.16%, op_acc: 39.06%] [G loss: 1.002838]\n",
      "epoch:8 step:6978[D loss: 0.403529, acc: 62.50%, op_acc: 39.84%] [G loss: 0.985315]\n",
      "epoch:8 step:6979[D loss: 0.435842, acc: 67.97%, op_acc: 37.50%] [G loss: 0.923333]\n",
      "epoch:8 step:6980[D loss: 0.463785, acc: 55.47%, op_acc: 32.03%] [G loss: 1.041466]\n",
      "epoch:8 step:6981[D loss: 0.444489, acc: 57.81%, op_acc: 29.69%] [G loss: 1.007020]\n",
      "epoch:8 step:6982[D loss: 0.453700, acc: 53.91%, op_acc: 34.38%] [G loss: 0.929245]\n",
      "epoch:8 step:6983[D loss: 0.449284, acc: 53.91%, op_acc: 35.94%] [G loss: 0.925265]\n",
      "epoch:8 step:6984[D loss: 0.457099, acc: 61.72%, op_acc: 26.56%] [G loss: 1.013417]\n",
      "epoch:8 step:6985[D loss: 0.400810, acc: 63.28%, op_acc: 40.62%] [G loss: 1.000034]\n",
      "epoch:8 step:6986[D loss: 0.437747, acc: 60.94%, op_acc: 38.28%] [G loss: 0.928694]\n",
      "epoch:8 step:6987[D loss: 0.392462, acc: 64.84%, op_acc: 43.75%] [G loss: 0.972340]\n",
      "epoch:8 step:6988[D loss: 0.470196, acc: 53.91%, op_acc: 36.72%] [G loss: 0.917672]\n",
      "epoch:8 step:6989[D loss: 0.431701, acc: 64.84%, op_acc: 32.03%] [G loss: 1.005098]\n",
      "epoch:8 step:6990[D loss: 0.442945, acc: 60.16%, op_acc: 35.16%] [G loss: 0.822724]\n",
      "epoch:8 step:6991[D loss: 0.449233, acc: 61.72%, op_acc: 33.59%] [G loss: 0.937596]\n",
      "epoch:8 step:6992[D loss: 0.384424, acc: 67.19%, op_acc: 41.41%] [G loss: 0.933473]\n",
      "epoch:8 step:6993[D loss: 0.408444, acc: 69.53%, op_acc: 35.16%] [G loss: 0.954447]\n",
      "epoch:8 step:6994[D loss: 0.455868, acc: 55.47%, op_acc: 32.03%] [G loss: 1.001914]\n",
      "epoch:8 step:6995[D loss: 0.436287, acc: 64.84%, op_acc: 39.06%] [G loss: 0.972160]\n",
      "epoch:8 step:6996[D loss: 0.417457, acc: 68.75%, op_acc: 32.81%] [G loss: 0.967236]\n",
      "epoch:8 step:6997[D loss: 0.440232, acc: 64.06%, op_acc: 35.16%] [G loss: 0.929887]\n",
      "epoch:8 step:6998[D loss: 0.438779, acc: 56.25%, op_acc: 40.62%] [G loss: 0.928552]\n",
      "epoch:8 step:6999[D loss: 0.468216, acc: 60.16%, op_acc: 29.69%] [G loss: 0.934967]\n",
      "epoch:8 step:7000[D loss: 0.444025, acc: 60.16%, op_acc: 32.81%] [G loss: 0.930532]\n",
      "epoch:8 step:7001[D loss: 0.426242, acc: 60.94%, op_acc: 35.94%] [G loss: 0.988895]\n",
      "epoch:8 step:7002[D loss: 0.420449, acc: 64.06%, op_acc: 32.03%] [G loss: 0.907945]\n",
      "epoch:8 step:7003[D loss: 0.424907, acc: 63.28%, op_acc: 38.28%] [G loss: 0.894288]\n",
      "epoch:8 step:7004[D loss: 0.440091, acc: 54.69%, op_acc: 41.41%] [G loss: 1.015709]\n",
      "epoch:8 step:7005[D loss: 0.420896, acc: 66.41%, op_acc: 34.38%] [G loss: 1.053802]\n",
      "epoch:8 step:7006[D loss: 0.408892, acc: 65.62%, op_acc: 35.16%] [G loss: 0.946759]\n",
      "epoch:8 step:7007[D loss: 0.461051, acc: 57.03%, op_acc: 31.25%] [G loss: 0.966062]\n",
      "epoch:8 step:7008[D loss: 0.414675, acc: 64.06%, op_acc: 40.62%] [G loss: 0.909664]\n",
      "epoch:8 step:7009[D loss: 0.420822, acc: 58.59%, op_acc: 40.62%] [G loss: 0.908743]\n",
      "epoch:8 step:7010[D loss: 0.466835, acc: 54.69%, op_acc: 31.25%] [G loss: 0.988478]\n",
      "epoch:8 step:7011[D loss: 0.435101, acc: 58.59%, op_acc: 40.62%] [G loss: 0.968940]\n",
      "epoch:8 step:7012[D loss: 0.409037, acc: 64.84%, op_acc: 33.59%] [G loss: 0.959943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7013[D loss: 0.415163, acc: 63.28%, op_acc: 40.62%] [G loss: 0.951987]\n",
      "epoch:8 step:7014[D loss: 0.475311, acc: 53.12%, op_acc: 30.47%] [G loss: 0.923278]\n",
      "epoch:8 step:7015[D loss: 0.410033, acc: 63.28%, op_acc: 37.50%] [G loss: 0.994017]\n",
      "epoch:8 step:7016[D loss: 0.459863, acc: 51.56%, op_acc: 31.25%] [G loss: 0.818792]\n",
      "epoch:8 step:7017[D loss: 0.422193, acc: 62.50%, op_acc: 41.41%] [G loss: 0.875225]\n",
      "epoch:8 step:7018[D loss: 0.432246, acc: 57.81%, op_acc: 36.72%] [G loss: 0.968364]\n",
      "epoch:8 step:7019[D loss: 0.434941, acc: 64.06%, op_acc: 32.03%] [G loss: 0.970772]\n",
      "epoch:8 step:7020[D loss: 0.458608, acc: 57.03%, op_acc: 34.38%] [G loss: 0.929232]\n",
      "epoch:8 step:7021[D loss: 0.454135, acc: 67.19%, op_acc: 29.69%] [G loss: 0.953966]\n",
      "epoch:8 step:7022[D loss: 0.405094, acc: 69.53%, op_acc: 36.72%] [G loss: 0.999251]\n",
      "epoch:8 step:7023[D loss: 0.459558, acc: 57.03%, op_acc: 29.69%] [G loss: 0.912464]\n",
      "epoch:8 step:7024[D loss: 0.412728, acc: 72.66%, op_acc: 35.94%] [G loss: 0.885442]\n",
      "epoch:8 step:7025[D loss: 0.461065, acc: 57.81%, op_acc: 33.59%] [G loss: 0.997100]\n",
      "epoch:8 step:7026[D loss: 0.420295, acc: 59.38%, op_acc: 40.62%] [G loss: 1.005788]\n",
      "epoch:8 step:7027[D loss: 0.434660, acc: 60.94%, op_acc: 38.28%] [G loss: 0.900943]\n",
      "epoch:8 step:7028[D loss: 0.446863, acc: 56.25%, op_acc: 35.94%] [G loss: 0.866712]\n",
      "epoch:8 step:7029[D loss: 0.448310, acc: 59.38%, op_acc: 32.81%] [G loss: 0.908366]\n",
      "epoch:9 step:7030[D loss: 0.428904, acc: 58.59%, op_acc: 37.50%] [G loss: 1.016755]\n",
      "epoch:9 step:7031[D loss: 0.424620, acc: 57.81%, op_acc: 40.62%] [G loss: 0.968813]\n",
      "epoch:9 step:7032[D loss: 0.431255, acc: 64.06%, op_acc: 35.16%] [G loss: 0.930733]\n",
      "epoch:9 step:7033[D loss: 0.399191, acc: 66.41%, op_acc: 32.03%] [G loss: 0.957513]\n",
      "epoch:9 step:7034[D loss: 0.432137, acc: 57.81%, op_acc: 36.72%] [G loss: 0.850053]\n",
      "epoch:9 step:7035[D loss: 0.409264, acc: 69.53%, op_acc: 31.25%] [G loss: 0.891486]\n",
      "epoch:9 step:7036[D loss: 0.425877, acc: 63.28%, op_acc: 28.12%] [G loss: 0.993090]\n",
      "epoch:9 step:7037[D loss: 0.414507, acc: 68.75%, op_acc: 32.81%] [G loss: 0.848844]\n",
      "epoch:9 step:7038[D loss: 0.414967, acc: 62.50%, op_acc: 37.50%] [G loss: 1.018179]\n",
      "epoch:9 step:7039[D loss: 0.467096, acc: 56.25%, op_acc: 35.94%] [G loss: 0.948518]\n",
      "epoch:9 step:7040[D loss: 0.461585, acc: 57.81%, op_acc: 36.72%] [G loss: 0.863677]\n",
      "epoch:9 step:7041[D loss: 0.437141, acc: 64.84%, op_acc: 32.81%] [G loss: 0.869255]\n",
      "epoch:9 step:7042[D loss: 0.414943, acc: 69.53%, op_acc: 29.69%] [G loss: 0.940791]\n",
      "epoch:9 step:7043[D loss: 0.440214, acc: 66.41%, op_acc: 29.69%] [G loss: 0.979123]\n",
      "epoch:9 step:7044[D loss: 0.447168, acc: 57.03%, op_acc: 37.50%] [G loss: 0.998803]\n",
      "epoch:9 step:7045[D loss: 0.437641, acc: 55.47%, op_acc: 33.59%] [G loss: 0.947210]\n",
      "epoch:9 step:7046[D loss: 0.460531, acc: 53.91%, op_acc: 36.72%] [G loss: 0.959192]\n",
      "epoch:9 step:7047[D loss: 0.405864, acc: 62.50%, op_acc: 36.72%] [G loss: 0.949420]\n",
      "epoch:9 step:7048[D loss: 0.408327, acc: 69.53%, op_acc: 42.97%] [G loss: 1.007946]\n",
      "epoch:9 step:7049[D loss: 0.415753, acc: 67.97%, op_acc: 42.97%] [G loss: 1.011206]\n",
      "epoch:9 step:7050[D loss: 0.442103, acc: 57.03%, op_acc: 38.28%] [G loss: 0.880815]\n",
      "epoch:9 step:7051[D loss: 0.432694, acc: 61.72%, op_acc: 40.62%] [G loss: 0.882959]\n",
      "epoch:9 step:7052[D loss: 0.414902, acc: 62.50%, op_acc: 38.28%] [G loss: 0.865949]\n",
      "epoch:9 step:7053[D loss: 0.483726, acc: 51.56%, op_acc: 31.25%] [G loss: 0.959436]\n",
      "epoch:9 step:7054[D loss: 0.424337, acc: 64.06%, op_acc: 42.19%] [G loss: 1.052413]\n",
      "epoch:9 step:7055[D loss: 0.430062, acc: 64.06%, op_acc: 37.50%] [G loss: 0.923454]\n",
      "epoch:9 step:7056[D loss: 0.419855, acc: 65.62%, op_acc: 38.28%] [G loss: 0.903434]\n",
      "epoch:9 step:7057[D loss: 0.392769, acc: 67.97%, op_acc: 45.31%] [G loss: 0.899342]\n",
      "epoch:9 step:7058[D loss: 0.397316, acc: 69.53%, op_acc: 37.50%] [G loss: 0.980834]\n",
      "epoch:9 step:7059[D loss: 0.396620, acc: 64.06%, op_acc: 39.06%] [G loss: 0.954651]\n",
      "epoch:9 step:7060[D loss: 0.472136, acc: 57.03%, op_acc: 34.38%] [G loss: 0.919456]\n",
      "epoch:9 step:7061[D loss: 0.450773, acc: 57.81%, op_acc: 30.47%] [G loss: 0.908650]\n",
      "epoch:9 step:7062[D loss: 0.427255, acc: 56.25%, op_acc: 40.62%] [G loss: 0.843792]\n",
      "epoch:9 step:7063[D loss: 0.424237, acc: 60.16%, op_acc: 39.06%] [G loss: 0.874085]\n",
      "epoch:9 step:7064[D loss: 0.443920, acc: 60.94%, op_acc: 36.72%] [G loss: 0.923016]\n",
      "epoch:9 step:7065[D loss: 0.454367, acc: 55.47%, op_acc: 35.94%] [G loss: 0.900028]\n",
      "epoch:9 step:7066[D loss: 0.423512, acc: 61.72%, op_acc: 37.50%] [G loss: 1.119530]\n",
      "epoch:9 step:7067[D loss: 0.422351, acc: 60.94%, op_acc: 35.94%] [G loss: 0.963332]\n",
      "epoch:9 step:7068[D loss: 0.397454, acc: 67.97%, op_acc: 41.41%] [G loss: 0.892497]\n",
      "epoch:9 step:7069[D loss: 0.447647, acc: 66.41%, op_acc: 33.59%] [G loss: 0.956001]\n",
      "epoch:9 step:7070[D loss: 0.405636, acc: 65.62%, op_acc: 35.16%] [G loss: 1.016962]\n",
      "epoch:9 step:7071[D loss: 0.412474, acc: 67.97%, op_acc: 39.84%] [G loss: 1.019073]\n",
      "epoch:9 step:7072[D loss: 0.457629, acc: 57.03%, op_acc: 33.59%] [G loss: 1.113268]\n",
      "epoch:9 step:7073[D loss: 0.426361, acc: 57.03%, op_acc: 35.16%] [G loss: 0.964383]\n",
      "epoch:9 step:7074[D loss: 0.406805, acc: 69.53%, op_acc: 39.06%] [G loss: 1.064683]\n",
      "epoch:9 step:7075[D loss: 0.420201, acc: 63.28%, op_acc: 39.84%] [G loss: 1.011116]\n",
      "epoch:9 step:7076[D loss: 0.460452, acc: 58.59%, op_acc: 31.25%] [G loss: 0.950405]\n",
      "epoch:9 step:7077[D loss: 0.441450, acc: 66.41%, op_acc: 33.59%] [G loss: 0.966322]\n",
      "epoch:9 step:7078[D loss: 0.438583, acc: 57.03%, op_acc: 39.06%] [G loss: 0.850970]\n",
      "epoch:9 step:7079[D loss: 0.479292, acc: 50.00%, op_acc: 34.38%] [G loss: 0.882687]\n",
      "epoch:9 step:7080[D loss: 0.386295, acc: 69.53%, op_acc: 41.41%] [G loss: 1.044915]\n",
      "epoch:9 step:7081[D loss: 0.456149, acc: 50.00%, op_acc: 35.94%] [G loss: 0.874202]\n",
      "epoch:9 step:7082[D loss: 0.443506, acc: 60.94%, op_acc: 34.38%] [G loss: 1.007897]\n",
      "epoch:9 step:7083[D loss: 0.484967, acc: 53.91%, op_acc: 34.38%] [G loss: 0.994614]\n",
      "epoch:9 step:7084[D loss: 0.412708, acc: 64.84%, op_acc: 37.50%] [G loss: 0.959974]\n",
      "epoch:9 step:7085[D loss: 0.412268, acc: 71.09%, op_acc: 36.72%] [G loss: 0.931699]\n",
      "epoch:9 step:7086[D loss: 0.420601, acc: 65.62%, op_acc: 34.38%] [G loss: 0.897937]\n",
      "epoch:9 step:7087[D loss: 0.411782, acc: 65.62%, op_acc: 36.72%] [G loss: 0.934303]\n",
      "epoch:9 step:7088[D loss: 0.435589, acc: 61.72%, op_acc: 35.94%] [G loss: 0.911678]\n",
      "epoch:9 step:7089[D loss: 0.418957, acc: 68.75%, op_acc: 35.16%] [G loss: 0.890877]\n",
      "epoch:9 step:7090[D loss: 0.437503, acc: 64.06%, op_acc: 31.25%] [G loss: 0.917072]\n",
      "epoch:9 step:7091[D loss: 0.432766, acc: 57.03%, op_acc: 39.84%] [G loss: 0.973040]\n",
      "epoch:9 step:7092[D loss: 0.433180, acc: 60.94%, op_acc: 32.81%] [G loss: 0.927401]\n",
      "epoch:9 step:7093[D loss: 0.471761, acc: 54.69%, op_acc: 35.16%] [G loss: 0.940923]\n",
      "epoch:9 step:7094[D loss: 0.454728, acc: 57.03%, op_acc: 31.25%] [G loss: 0.974127]\n",
      "epoch:9 step:7095[D loss: 0.453262, acc: 60.16%, op_acc: 32.81%] [G loss: 0.906245]\n",
      "epoch:9 step:7096[D loss: 0.446236, acc: 61.72%, op_acc: 38.28%] [G loss: 0.949521]\n",
      "epoch:9 step:7097[D loss: 0.453547, acc: 53.91%, op_acc: 31.25%] [G loss: 0.991672]\n",
      "epoch:9 step:7098[D loss: 0.415455, acc: 64.06%, op_acc: 35.94%] [G loss: 1.029012]\n",
      "epoch:9 step:7099[D loss: 0.445263, acc: 57.81%, op_acc: 29.69%] [G loss: 0.994049]\n",
      "epoch:9 step:7100[D loss: 0.481391, acc: 50.00%, op_acc: 30.47%] [G loss: 0.826859]\n",
      "epoch:9 step:7101[D loss: 0.402950, acc: 64.06%, op_acc: 41.41%] [G loss: 0.941147]\n",
      "epoch:9 step:7102[D loss: 0.420445, acc: 63.28%, op_acc: 34.38%] [G loss: 0.856896]\n",
      "epoch:9 step:7103[D loss: 0.392909, acc: 64.84%, op_acc: 42.19%] [G loss: 0.929329]\n",
      "epoch:9 step:7104[D loss: 0.428524, acc: 64.06%, op_acc: 36.72%] [G loss: 0.958000]\n",
      "epoch:9 step:7105[D loss: 0.466142, acc: 50.00%, op_acc: 33.59%] [G loss: 0.879615]\n",
      "epoch:9 step:7106[D loss: 0.440107, acc: 60.16%, op_acc: 35.16%] [G loss: 0.979831]\n",
      "epoch:9 step:7107[D loss: 0.440781, acc: 65.62%, op_acc: 32.03%] [G loss: 0.839322]\n",
      "epoch:9 step:7108[D loss: 0.435775, acc: 60.16%, op_acc: 37.50%] [G loss: 0.890893]\n",
      "epoch:9 step:7109[D loss: 0.450025, acc: 62.50%, op_acc: 29.69%] [G loss: 0.949129]\n",
      "epoch:9 step:7110[D loss: 0.469949, acc: 60.94%, op_acc: 28.12%] [G loss: 0.843527]\n",
      "epoch:9 step:7111[D loss: 0.391324, acc: 68.75%, op_acc: 39.84%] [G loss: 1.095420]\n",
      "epoch:9 step:7112[D loss: 0.461173, acc: 55.47%, op_acc: 36.72%] [G loss: 0.930026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7113[D loss: 0.462887, acc: 55.47%, op_acc: 35.16%] [G loss: 0.874968]\n",
      "epoch:9 step:7114[D loss: 0.461499, acc: 60.16%, op_acc: 29.69%] [G loss: 1.037803]\n",
      "epoch:9 step:7115[D loss: 0.428671, acc: 58.59%, op_acc: 35.94%] [G loss: 0.995925]\n",
      "epoch:9 step:7116[D loss: 0.475376, acc: 56.25%, op_acc: 31.25%] [G loss: 0.875034]\n",
      "epoch:9 step:7117[D loss: 0.469082, acc: 57.03%, op_acc: 31.25%] [G loss: 0.895566]\n",
      "epoch:9 step:7118[D loss: 0.436015, acc: 64.06%, op_acc: 38.28%] [G loss: 0.953262]\n",
      "epoch:9 step:7119[D loss: 0.486744, acc: 50.00%, op_acc: 37.50%] [G loss: 0.801957]\n",
      "epoch:9 step:7120[D loss: 0.389553, acc: 68.75%, op_acc: 37.50%] [G loss: 0.937748]\n",
      "epoch:9 step:7121[D loss: 0.442704, acc: 53.91%, op_acc: 32.81%] [G loss: 0.963337]\n",
      "epoch:9 step:7122[D loss: 0.430385, acc: 57.81%, op_acc: 37.50%] [G loss: 0.968524]\n",
      "epoch:9 step:7123[D loss: 0.452880, acc: 54.69%, op_acc: 35.16%] [G loss: 0.961314]\n",
      "epoch:9 step:7124[D loss: 0.416942, acc: 65.62%, op_acc: 34.38%] [G loss: 0.966681]\n",
      "epoch:9 step:7125[D loss: 0.439504, acc: 60.94%, op_acc: 32.81%] [G loss: 0.954735]\n",
      "epoch:9 step:7126[D loss: 0.448474, acc: 56.25%, op_acc: 37.50%] [G loss: 0.839854]\n",
      "epoch:9 step:7127[D loss: 0.463101, acc: 52.34%, op_acc: 28.91%] [G loss: 0.974183]\n",
      "epoch:9 step:7128[D loss: 0.426887, acc: 56.25%, op_acc: 36.72%] [G loss: 0.930946]\n",
      "epoch:9 step:7129[D loss: 0.429876, acc: 53.12%, op_acc: 36.72%] [G loss: 0.983422]\n",
      "epoch:9 step:7130[D loss: 0.449351, acc: 58.59%, op_acc: 35.16%] [G loss: 1.029010]\n",
      "epoch:9 step:7131[D loss: 0.450746, acc: 60.94%, op_acc: 35.94%] [G loss: 0.903588]\n",
      "epoch:9 step:7132[D loss: 0.443981, acc: 60.16%, op_acc: 31.25%] [G loss: 1.016585]\n",
      "epoch:9 step:7133[D loss: 0.461886, acc: 55.47%, op_acc: 34.38%] [G loss: 0.922375]\n",
      "epoch:9 step:7134[D loss: 0.413715, acc: 64.84%, op_acc: 39.84%] [G loss: 0.914425]\n",
      "epoch:9 step:7135[D loss: 0.401778, acc: 67.97%, op_acc: 39.06%] [G loss: 0.993542]\n",
      "epoch:9 step:7136[D loss: 0.416445, acc: 67.19%, op_acc: 32.81%] [G loss: 1.039010]\n",
      "epoch:9 step:7137[D loss: 0.482593, acc: 56.25%, op_acc: 28.91%] [G loss: 0.912951]\n",
      "epoch:9 step:7138[D loss: 0.406799, acc: 60.16%, op_acc: 35.16%] [G loss: 0.950497]\n",
      "epoch:9 step:7139[D loss: 0.428638, acc: 67.19%, op_acc: 38.28%] [G loss: 0.939170]\n",
      "epoch:9 step:7140[D loss: 0.471562, acc: 55.47%, op_acc: 30.47%] [G loss: 0.936747]\n",
      "epoch:9 step:7141[D loss: 0.426100, acc: 65.62%, op_acc: 35.94%] [G loss: 0.941998]\n",
      "epoch:9 step:7142[D loss: 0.433295, acc: 60.16%, op_acc: 22.66%] [G loss: 0.965981]\n",
      "epoch:9 step:7143[D loss: 0.413966, acc: 67.19%, op_acc: 39.84%] [G loss: 0.939552]\n",
      "epoch:9 step:7144[D loss: 0.409490, acc: 59.38%, op_acc: 40.62%] [G loss: 0.962376]\n",
      "epoch:9 step:7145[D loss: 0.440543, acc: 57.81%, op_acc: 37.50%] [G loss: 0.913661]\n",
      "epoch:9 step:7146[D loss: 0.415698, acc: 62.50%, op_acc: 34.38%] [G loss: 0.976415]\n",
      "epoch:9 step:7147[D loss: 0.433806, acc: 60.94%, op_acc: 28.91%] [G loss: 0.898757]\n",
      "epoch:9 step:7148[D loss: 0.442185, acc: 58.59%, op_acc: 32.81%] [G loss: 0.831106]\n",
      "epoch:9 step:7149[D loss: 0.454295, acc: 59.38%, op_acc: 29.69%] [G loss: 0.927059]\n",
      "epoch:9 step:7150[D loss: 0.436074, acc: 64.06%, op_acc: 35.94%] [G loss: 1.024253]\n",
      "epoch:9 step:7151[D loss: 0.456841, acc: 53.91%, op_acc: 32.81%] [G loss: 0.925818]\n",
      "epoch:9 step:7152[D loss: 0.450694, acc: 57.81%, op_acc: 31.25%] [G loss: 0.922545]\n",
      "epoch:9 step:7153[D loss: 0.431705, acc: 66.41%, op_acc: 39.06%] [G loss: 0.954570]\n",
      "epoch:9 step:7154[D loss: 0.433647, acc: 62.50%, op_acc: 37.50%] [G loss: 0.941871]\n",
      "epoch:9 step:7155[D loss: 0.410126, acc: 64.06%, op_acc: 35.16%] [G loss: 0.943670]\n",
      "epoch:9 step:7156[D loss: 0.414424, acc: 61.72%, op_acc: 35.94%] [G loss: 0.942598]\n",
      "epoch:9 step:7157[D loss: 0.433212, acc: 57.81%, op_acc: 37.50%] [G loss: 0.945310]\n",
      "epoch:9 step:7158[D loss: 0.440434, acc: 61.72%, op_acc: 32.03%] [G loss: 0.983711]\n",
      "epoch:9 step:7159[D loss: 0.386922, acc: 72.66%, op_acc: 38.28%] [G loss: 0.945666]\n",
      "epoch:9 step:7160[D loss: 0.398507, acc: 67.19%, op_acc: 39.06%] [G loss: 0.925104]\n",
      "epoch:9 step:7161[D loss: 0.435369, acc: 56.25%, op_acc: 38.28%] [G loss: 0.925880]\n",
      "epoch:9 step:7162[D loss: 0.482264, acc: 54.69%, op_acc: 25.00%] [G loss: 0.943637]\n",
      "epoch:9 step:7163[D loss: 0.468955, acc: 50.00%, op_acc: 31.25%] [G loss: 0.897138]\n",
      "epoch:9 step:7164[D loss: 0.429327, acc: 60.94%, op_acc: 38.28%] [G loss: 1.026337]\n",
      "epoch:9 step:7165[D loss: 0.388421, acc: 70.31%, op_acc: 36.72%] [G loss: 0.954766]\n",
      "epoch:9 step:7166[D loss: 0.421429, acc: 62.50%, op_acc: 36.72%] [G loss: 1.004778]\n",
      "epoch:9 step:7167[D loss: 0.451533, acc: 59.38%, op_acc: 34.38%] [G loss: 0.947991]\n",
      "epoch:9 step:7168[D loss: 0.412172, acc: 67.19%, op_acc: 34.38%] [G loss: 0.943035]\n",
      "epoch:9 step:7169[D loss: 0.479839, acc: 56.25%, op_acc: 34.38%] [G loss: 0.904342]\n",
      "epoch:9 step:7170[D loss: 0.475852, acc: 57.81%, op_acc: 28.91%] [G loss: 0.880974]\n",
      "epoch:9 step:7171[D loss: 0.405777, acc: 68.75%, op_acc: 32.81%] [G loss: 0.922118]\n",
      "epoch:9 step:7172[D loss: 0.427268, acc: 64.06%, op_acc: 36.72%] [G loss: 0.927949]\n",
      "epoch:9 step:7173[D loss: 0.447940, acc: 64.06%, op_acc: 38.28%] [G loss: 0.910103]\n",
      "epoch:9 step:7174[D loss: 0.428578, acc: 61.72%, op_acc: 42.19%] [G loss: 1.012830]\n",
      "epoch:9 step:7175[D loss: 0.421404, acc: 63.28%, op_acc: 35.94%] [G loss: 0.834965]\n",
      "epoch:9 step:7176[D loss: 0.426333, acc: 61.72%, op_acc: 38.28%] [G loss: 0.991974]\n",
      "epoch:9 step:7177[D loss: 0.490502, acc: 52.34%, op_acc: 33.59%] [G loss: 0.978289]\n",
      "epoch:9 step:7178[D loss: 0.415088, acc: 64.06%, op_acc: 43.75%] [G loss: 1.020278]\n",
      "epoch:9 step:7179[D loss: 0.429503, acc: 57.81%, op_acc: 35.16%] [G loss: 1.026606]\n",
      "epoch:9 step:7180[D loss: 0.444443, acc: 57.03%, op_acc: 38.28%] [G loss: 0.944020]\n",
      "epoch:9 step:7181[D loss: 0.426993, acc: 57.03%, op_acc: 38.28%] [G loss: 0.948475]\n",
      "epoch:9 step:7182[D loss: 0.474107, acc: 49.22%, op_acc: 30.47%] [G loss: 0.895072]\n",
      "epoch:9 step:7183[D loss: 0.418829, acc: 67.97%, op_acc: 33.59%] [G loss: 0.998452]\n",
      "epoch:9 step:7184[D loss: 0.452124, acc: 57.81%, op_acc: 33.59%] [G loss: 0.983732]\n",
      "epoch:9 step:7185[D loss: 0.418781, acc: 60.94%, op_acc: 38.28%] [G loss: 0.997115]\n",
      "epoch:9 step:7186[D loss: 0.428920, acc: 61.72%, op_acc: 36.72%] [G loss: 0.920532]\n",
      "epoch:9 step:7187[D loss: 0.412364, acc: 62.50%, op_acc: 39.84%] [G loss: 1.008047]\n",
      "epoch:9 step:7188[D loss: 0.432354, acc: 62.50%, op_acc: 38.28%] [G loss: 0.969756]\n",
      "epoch:9 step:7189[D loss: 0.420823, acc: 76.56%, op_acc: 32.03%] [G loss: 0.966529]\n",
      "epoch:9 step:7190[D loss: 0.463051, acc: 58.59%, op_acc: 37.50%] [G loss: 0.947467]\n",
      "epoch:9 step:7191[D loss: 0.416776, acc: 60.16%, op_acc: 39.06%] [G loss: 0.973580]\n",
      "epoch:9 step:7192[D loss: 0.461605, acc: 58.59%, op_acc: 28.12%] [G loss: 0.887496]\n",
      "epoch:9 step:7193[D loss: 0.447338, acc: 63.28%, op_acc: 31.25%] [G loss: 0.917143]\n",
      "epoch:9 step:7194[D loss: 0.398015, acc: 65.62%, op_acc: 43.75%] [G loss: 0.978629]\n",
      "epoch:9 step:7195[D loss: 0.459022, acc: 58.59%, op_acc: 32.81%] [G loss: 0.966960]\n",
      "epoch:9 step:7196[D loss: 0.414894, acc: 67.19%, op_acc: 37.50%] [G loss: 0.916271]\n",
      "epoch:9 step:7197[D loss: 0.432237, acc: 58.59%, op_acc: 39.84%] [G loss: 0.984677]\n",
      "epoch:9 step:7198[D loss: 0.444815, acc: 59.38%, op_acc: 44.53%] [G loss: 0.972399]\n",
      "epoch:9 step:7199[D loss: 0.466103, acc: 51.56%, op_acc: 36.72%] [G loss: 0.957620]\n",
      "epoch:9 step:7200[D loss: 0.467483, acc: 63.28%, op_acc: 30.47%] [G loss: 0.911964]\n",
      "epoch:9 step:7201[D loss: 0.420934, acc: 60.94%, op_acc: 34.38%] [G loss: 0.911287]\n",
      "epoch:9 step:7202[D loss: 0.415292, acc: 66.41%, op_acc: 39.06%] [G loss: 0.917936]\n",
      "epoch:9 step:7203[D loss: 0.457910, acc: 57.81%, op_acc: 29.69%] [G loss: 0.996631]\n",
      "epoch:9 step:7204[D loss: 0.398783, acc: 66.41%, op_acc: 35.94%] [G loss: 0.954401]\n",
      "epoch:9 step:7205[D loss: 0.427041, acc: 61.72%, op_acc: 35.94%] [G loss: 0.899942]\n",
      "epoch:9 step:7206[D loss: 0.434234, acc: 58.59%, op_acc: 39.84%] [G loss: 0.914360]\n",
      "epoch:9 step:7207[D loss: 0.459085, acc: 51.56%, op_acc: 32.03%] [G loss: 0.969860]\n",
      "epoch:9 step:7208[D loss: 0.416604, acc: 64.84%, op_acc: 37.50%] [G loss: 0.938568]\n",
      "epoch:9 step:7209[D loss: 0.442904, acc: 60.16%, op_acc: 34.38%] [G loss: 0.950304]\n",
      "epoch:9 step:7210[D loss: 0.409341, acc: 64.06%, op_acc: 37.50%] [G loss: 0.989155]\n",
      "epoch:9 step:7211[D loss: 0.449900, acc: 61.72%, op_acc: 34.38%] [G loss: 1.044904]\n",
      "epoch:9 step:7212[D loss: 0.410046, acc: 70.31%, op_acc: 30.47%] [G loss: 0.932281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7213[D loss: 0.468775, acc: 56.25%, op_acc: 32.81%] [G loss: 1.048397]\n",
      "epoch:9 step:7214[D loss: 0.409083, acc: 69.53%, op_acc: 31.25%] [G loss: 1.063825]\n",
      "epoch:9 step:7215[D loss: 0.445176, acc: 53.12%, op_acc: 38.28%] [G loss: 1.030735]\n",
      "epoch:9 step:7216[D loss: 0.473220, acc: 50.78%, op_acc: 35.16%] [G loss: 0.939885]\n",
      "epoch:9 step:7217[D loss: 0.475619, acc: 49.22%, op_acc: 32.03%] [G loss: 1.037184]\n",
      "epoch:9 step:7218[D loss: 0.424863, acc: 64.84%, op_acc: 32.81%] [G loss: 0.999415]\n",
      "epoch:9 step:7219[D loss: 0.440365, acc: 57.81%, op_acc: 32.03%] [G loss: 1.007407]\n",
      "epoch:9 step:7220[D loss: 0.404719, acc: 67.19%, op_acc: 37.50%] [G loss: 0.922328]\n",
      "epoch:9 step:7221[D loss: 0.425915, acc: 64.84%, op_acc: 30.47%] [G loss: 1.003154]\n",
      "epoch:9 step:7222[D loss: 0.439688, acc: 62.50%, op_acc: 36.72%] [G loss: 1.025995]\n",
      "epoch:9 step:7223[D loss: 0.422298, acc: 64.06%, op_acc: 32.81%] [G loss: 1.015383]\n",
      "epoch:9 step:7224[D loss: 0.462330, acc: 65.62%, op_acc: 36.72%] [G loss: 0.945398]\n",
      "epoch:9 step:7225[D loss: 0.468963, acc: 57.03%, op_acc: 32.81%] [G loss: 0.968389]\n",
      "epoch:9 step:7226[D loss: 0.451808, acc: 61.72%, op_acc: 34.38%] [G loss: 0.935826]\n",
      "epoch:9 step:7227[D loss: 0.438644, acc: 58.59%, op_acc: 35.16%] [G loss: 0.974014]\n",
      "epoch:9 step:7228[D loss: 0.438386, acc: 63.28%, op_acc: 35.94%] [G loss: 1.061245]\n",
      "epoch:9 step:7229[D loss: 0.431846, acc: 64.06%, op_acc: 31.25%] [G loss: 1.007885]\n",
      "epoch:9 step:7230[D loss: 0.420072, acc: 59.38%, op_acc: 36.72%] [G loss: 0.924623]\n",
      "epoch:9 step:7231[D loss: 0.439471, acc: 57.81%, op_acc: 34.38%] [G loss: 0.999321]\n",
      "epoch:9 step:7232[D loss: 0.448528, acc: 60.16%, op_acc: 32.81%] [G loss: 0.924603]\n",
      "epoch:9 step:7233[D loss: 0.420661, acc: 68.75%, op_acc: 32.03%] [G loss: 0.972799]\n",
      "epoch:9 step:7234[D loss: 0.409397, acc: 71.09%, op_acc: 33.59%] [G loss: 0.984748]\n",
      "epoch:9 step:7235[D loss: 0.420022, acc: 66.41%, op_acc: 35.94%] [G loss: 1.013224]\n",
      "epoch:9 step:7236[D loss: 0.420076, acc: 63.28%, op_acc: 39.84%] [G loss: 0.825901]\n",
      "epoch:9 step:7237[D loss: 0.435175, acc: 64.84%, op_acc: 35.16%] [G loss: 0.968059]\n",
      "epoch:9 step:7238[D loss: 0.401866, acc: 73.44%, op_acc: 42.19%] [G loss: 0.984135]\n",
      "epoch:9 step:7239[D loss: 0.436716, acc: 68.75%, op_acc: 29.69%] [G loss: 1.024208]\n",
      "epoch:9 step:7240[D loss: 0.424366, acc: 53.91%, op_acc: 39.06%] [G loss: 0.991639]\n",
      "epoch:9 step:7241[D loss: 0.428758, acc: 58.59%, op_acc: 39.06%] [G loss: 0.917654]\n",
      "epoch:9 step:7242[D loss: 0.423955, acc: 60.16%, op_acc: 37.50%] [G loss: 0.977932]\n",
      "epoch:9 step:7243[D loss: 0.468215, acc: 55.47%, op_acc: 34.38%] [G loss: 0.967514]\n",
      "epoch:9 step:7244[D loss: 0.478191, acc: 50.78%, op_acc: 31.25%] [G loss: 0.893007]\n",
      "epoch:9 step:7245[D loss: 0.452334, acc: 57.03%, op_acc: 35.16%] [G loss: 0.950927]\n",
      "epoch:9 step:7246[D loss: 0.424356, acc: 60.94%, op_acc: 34.38%] [G loss: 0.912783]\n",
      "epoch:9 step:7247[D loss: 0.434402, acc: 63.28%, op_acc: 35.16%] [G loss: 0.897589]\n",
      "epoch:9 step:7248[D loss: 0.422101, acc: 60.16%, op_acc: 35.94%] [G loss: 0.949795]\n",
      "epoch:9 step:7249[D loss: 0.495813, acc: 49.22%, op_acc: 33.59%] [G loss: 0.868446]\n",
      "epoch:9 step:7250[D loss: 0.422561, acc: 61.72%, op_acc: 34.38%] [G loss: 0.999456]\n",
      "epoch:9 step:7251[D loss: 0.424877, acc: 64.06%, op_acc: 37.50%] [G loss: 0.861026]\n",
      "epoch:9 step:7252[D loss: 0.419806, acc: 65.62%, op_acc: 36.72%] [G loss: 1.019296]\n",
      "epoch:9 step:7253[D loss: 0.458498, acc: 57.81%, op_acc: 35.16%] [G loss: 0.893386]\n",
      "epoch:9 step:7254[D loss: 0.464002, acc: 59.38%, op_acc: 35.16%] [G loss: 0.934703]\n",
      "epoch:9 step:7255[D loss: 0.412533, acc: 67.19%, op_acc: 33.59%] [G loss: 0.880829]\n",
      "epoch:9 step:7256[D loss: 0.400533, acc: 71.09%, op_acc: 34.38%] [G loss: 0.946299]\n",
      "epoch:9 step:7257[D loss: 0.434716, acc: 60.94%, op_acc: 35.94%] [G loss: 0.969691]\n",
      "epoch:9 step:7258[D loss: 0.469317, acc: 50.78%, op_acc: 35.16%] [G loss: 0.917315]\n",
      "epoch:9 step:7259[D loss: 0.431675, acc: 62.50%, op_acc: 38.28%] [G loss: 0.886768]\n",
      "epoch:9 step:7260[D loss: 0.426126, acc: 65.62%, op_acc: 35.94%] [G loss: 0.904992]\n",
      "epoch:9 step:7261[D loss: 0.467578, acc: 54.69%, op_acc: 35.94%] [G loss: 1.013285]\n",
      "epoch:9 step:7262[D loss: 0.417296, acc: 64.06%, op_acc: 34.38%] [G loss: 0.963599]\n",
      "epoch:9 step:7263[D loss: 0.471030, acc: 60.94%, op_acc: 33.59%] [G loss: 0.893772]\n",
      "epoch:9 step:7264[D loss: 0.416931, acc: 64.84%, op_acc: 45.31%] [G loss: 1.033655]\n",
      "epoch:9 step:7265[D loss: 0.443957, acc: 59.38%, op_acc: 36.72%] [G loss: 0.973186]\n",
      "epoch:9 step:7266[D loss: 0.410829, acc: 65.62%, op_acc: 32.81%] [G loss: 0.955861]\n",
      "epoch:9 step:7267[D loss: 0.401538, acc: 71.88%, op_acc: 36.72%] [G loss: 0.986275]\n",
      "epoch:9 step:7268[D loss: 0.436684, acc: 62.50%, op_acc: 35.94%] [G loss: 0.952242]\n",
      "epoch:9 step:7269[D loss: 0.418764, acc: 67.19%, op_acc: 40.62%] [G loss: 1.008834]\n",
      "epoch:9 step:7270[D loss: 0.446515, acc: 57.03%, op_acc: 39.84%] [G loss: 0.902922]\n",
      "epoch:9 step:7271[D loss: 0.438377, acc: 53.91%, op_acc: 33.59%] [G loss: 0.916919]\n",
      "epoch:9 step:7272[D loss: 0.481395, acc: 49.22%, op_acc: 32.81%] [G loss: 0.811110]\n",
      "epoch:9 step:7273[D loss: 0.429518, acc: 67.97%, op_acc: 32.81%] [G loss: 0.923479]\n",
      "epoch:9 step:7274[D loss: 0.441567, acc: 53.91%, op_acc: 40.62%] [G loss: 0.934411]\n",
      "epoch:9 step:7275[D loss: 0.452362, acc: 60.16%, op_acc: 34.38%] [G loss: 0.904244]\n",
      "epoch:9 step:7276[D loss: 0.430535, acc: 56.25%, op_acc: 39.84%] [G loss: 1.023619]\n",
      "epoch:9 step:7277[D loss: 0.450113, acc: 62.50%, op_acc: 30.47%] [G loss: 0.935762]\n",
      "epoch:9 step:7278[D loss: 0.424378, acc: 66.41%, op_acc: 35.16%] [G loss: 0.952967]\n",
      "epoch:9 step:7279[D loss: 0.442582, acc: 53.12%, op_acc: 33.59%] [G loss: 1.029847]\n",
      "epoch:9 step:7280[D loss: 0.387889, acc: 65.62%, op_acc: 39.84%] [G loss: 0.951999]\n",
      "epoch:9 step:7281[D loss: 0.448804, acc: 56.25%, op_acc: 32.03%] [G loss: 0.867268]\n",
      "epoch:9 step:7282[D loss: 0.434225, acc: 57.81%, op_acc: 32.03%] [G loss: 0.919174]\n",
      "epoch:9 step:7283[D loss: 0.416371, acc: 70.31%, op_acc: 34.38%] [G loss: 0.914837]\n",
      "epoch:9 step:7284[D loss: 0.458194, acc: 53.91%, op_acc: 35.94%] [G loss: 0.943231]\n",
      "epoch:9 step:7285[D loss: 0.432435, acc: 57.81%, op_acc: 37.50%] [G loss: 0.877633]\n",
      "epoch:9 step:7286[D loss: 0.430299, acc: 59.38%, op_acc: 34.38%] [G loss: 1.009674]\n",
      "epoch:9 step:7287[D loss: 0.432474, acc: 60.94%, op_acc: 34.38%] [G loss: 0.929595]\n",
      "epoch:9 step:7288[D loss: 0.425076, acc: 69.53%, op_acc: 28.91%] [G loss: 0.953269]\n",
      "epoch:9 step:7289[D loss: 0.445842, acc: 59.38%, op_acc: 32.81%] [G loss: 0.981067]\n",
      "epoch:9 step:7290[D loss: 0.426920, acc: 57.03%, op_acc: 38.28%] [G loss: 0.980867]\n",
      "epoch:9 step:7291[D loss: 0.440896, acc: 61.72%, op_acc: 32.81%] [G loss: 0.888037]\n",
      "epoch:9 step:7292[D loss: 0.482470, acc: 49.22%, op_acc: 36.72%] [G loss: 0.936602]\n",
      "epoch:9 step:7293[D loss: 0.401526, acc: 69.53%, op_acc: 35.16%] [G loss: 0.917015]\n",
      "epoch:9 step:7294[D loss: 0.422573, acc: 60.16%, op_acc: 36.72%] [G loss: 0.864977]\n",
      "epoch:9 step:7295[D loss: 0.450341, acc: 58.59%, op_acc: 32.81%] [G loss: 0.881923]\n",
      "epoch:9 step:7296[D loss: 0.449631, acc: 55.47%, op_acc: 32.03%] [G loss: 0.890003]\n",
      "epoch:9 step:7297[D loss: 0.414261, acc: 58.59%, op_acc: 41.41%] [G loss: 0.865987]\n",
      "epoch:9 step:7298[D loss: 0.411544, acc: 64.84%, op_acc: 36.72%] [G loss: 0.970133]\n",
      "epoch:9 step:7299[D loss: 0.424767, acc: 63.28%, op_acc: 35.16%] [G loss: 0.990704]\n",
      "epoch:9 step:7300[D loss: 0.454665, acc: 53.91%, op_acc: 42.19%] [G loss: 0.869268]\n",
      "epoch:9 step:7301[D loss: 0.420739, acc: 65.62%, op_acc: 35.94%] [G loss: 0.926270]\n",
      "epoch:9 step:7302[D loss: 0.475676, acc: 56.25%, op_acc: 33.59%] [G loss: 0.869205]\n",
      "epoch:9 step:7303[D loss: 0.483154, acc: 53.91%, op_acc: 32.81%] [G loss: 0.888785]\n",
      "epoch:9 step:7304[D loss: 0.439987, acc: 58.59%, op_acc: 35.16%] [G loss: 0.915670]\n",
      "epoch:9 step:7305[D loss: 0.422157, acc: 59.38%, op_acc: 38.28%] [G loss: 0.887327]\n",
      "epoch:9 step:7306[D loss: 0.469178, acc: 53.91%, op_acc: 35.94%] [G loss: 0.829609]\n",
      "epoch:9 step:7307[D loss: 0.451832, acc: 61.72%, op_acc: 35.16%] [G loss: 0.864016]\n",
      "epoch:9 step:7308[D loss: 0.435905, acc: 65.62%, op_acc: 34.38%] [G loss: 0.988538]\n",
      "epoch:9 step:7309[D loss: 0.407976, acc: 62.50%, op_acc: 35.94%] [G loss: 0.894746]\n",
      "epoch:9 step:7310[D loss: 0.443567, acc: 58.59%, op_acc: 32.03%] [G loss: 1.074031]\n",
      "epoch:9 step:7311[D loss: 0.439788, acc: 60.16%, op_acc: 34.38%] [G loss: 0.966971]\n",
      "epoch:9 step:7312[D loss: 0.408997, acc: 66.41%, op_acc: 36.72%] [G loss: 1.081350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7313[D loss: 0.456627, acc: 55.47%, op_acc: 32.03%] [G loss: 0.868840]\n",
      "epoch:9 step:7314[D loss: 0.437399, acc: 61.72%, op_acc: 32.81%] [G loss: 0.954919]\n",
      "epoch:9 step:7315[D loss: 0.420404, acc: 65.62%, op_acc: 33.59%] [G loss: 0.983235]\n",
      "epoch:9 step:7316[D loss: 0.465797, acc: 56.25%, op_acc: 35.94%] [G loss: 0.921724]\n",
      "epoch:9 step:7317[D loss: 0.415005, acc: 64.84%, op_acc: 39.84%] [G loss: 0.934572]\n",
      "epoch:9 step:7318[D loss: 0.423771, acc: 67.19%, op_acc: 30.47%] [G loss: 0.941141]\n",
      "epoch:9 step:7319[D loss: 0.444816, acc: 60.16%, op_acc: 31.25%] [G loss: 0.918578]\n",
      "epoch:9 step:7320[D loss: 0.449314, acc: 60.94%, op_acc: 37.50%] [G loss: 1.017679]\n",
      "epoch:9 step:7321[D loss: 0.452400, acc: 66.41%, op_acc: 30.47%] [G loss: 0.972180]\n",
      "epoch:9 step:7322[D loss: 0.457558, acc: 57.03%, op_acc: 39.06%] [G loss: 0.824830]\n",
      "epoch:9 step:7323[D loss: 0.439540, acc: 57.81%, op_acc: 37.50%] [G loss: 0.864972]\n",
      "epoch:9 step:7324[D loss: 0.427966, acc: 58.59%, op_acc: 37.50%] [G loss: 1.003428]\n",
      "epoch:9 step:7325[D loss: 0.480318, acc: 49.22%, op_acc: 35.16%] [G loss: 0.906453]\n",
      "epoch:9 step:7326[D loss: 0.407655, acc: 68.75%, op_acc: 39.84%] [G loss: 1.021526]\n",
      "epoch:9 step:7327[D loss: 0.422573, acc: 63.28%, op_acc: 38.28%] [G loss: 0.979465]\n",
      "epoch:9 step:7328[D loss: 0.414831, acc: 62.50%, op_acc: 37.50%] [G loss: 0.859312]\n",
      "epoch:9 step:7329[D loss: 0.458845, acc: 60.16%, op_acc: 32.81%] [G loss: 0.964891]\n",
      "epoch:9 step:7330[D loss: 0.467690, acc: 56.25%, op_acc: 37.50%] [G loss: 0.916380]\n",
      "epoch:9 step:7331[D loss: 0.421632, acc: 63.28%, op_acc: 34.38%] [G loss: 0.882085]\n",
      "epoch:9 step:7332[D loss: 0.480658, acc: 53.12%, op_acc: 28.91%] [G loss: 0.807023]\n",
      "epoch:9 step:7333[D loss: 0.436112, acc: 60.16%, op_acc: 32.81%] [G loss: 0.906588]\n",
      "epoch:9 step:7334[D loss: 0.420467, acc: 66.41%, op_acc: 34.38%] [G loss: 1.056937]\n",
      "epoch:9 step:7335[D loss: 0.486824, acc: 57.81%, op_acc: 30.47%] [G loss: 0.952772]\n",
      "epoch:9 step:7336[D loss: 0.414550, acc: 61.72%, op_acc: 39.84%] [G loss: 0.988380]\n",
      "epoch:9 step:7337[D loss: 0.438339, acc: 64.84%, op_acc: 32.81%] [G loss: 0.969576]\n",
      "epoch:9 step:7338[D loss: 0.468500, acc: 60.94%, op_acc: 30.47%] [G loss: 0.917271]\n",
      "epoch:9 step:7339[D loss: 0.431487, acc: 64.84%, op_acc: 31.25%] [G loss: 1.006543]\n",
      "epoch:9 step:7340[D loss: 0.473246, acc: 56.25%, op_acc: 31.25%] [G loss: 0.933945]\n",
      "epoch:9 step:7341[D loss: 0.448120, acc: 56.25%, op_acc: 35.16%] [G loss: 0.929791]\n",
      "epoch:9 step:7342[D loss: 0.438275, acc: 64.06%, op_acc: 32.81%] [G loss: 0.857040]\n",
      "epoch:9 step:7343[D loss: 0.419924, acc: 60.94%, op_acc: 35.16%] [G loss: 0.955655]\n",
      "epoch:9 step:7344[D loss: 0.448146, acc: 60.94%, op_acc: 37.50%] [G loss: 0.963018]\n",
      "epoch:9 step:7345[D loss: 0.425784, acc: 60.94%, op_acc: 37.50%] [G loss: 0.984589]\n",
      "epoch:9 step:7346[D loss: 0.447287, acc: 58.59%, op_acc: 33.59%] [G loss: 0.905578]\n",
      "epoch:9 step:7347[D loss: 0.448413, acc: 54.69%, op_acc: 28.91%] [G loss: 0.921759]\n",
      "epoch:9 step:7348[D loss: 0.421483, acc: 63.28%, op_acc: 38.28%] [G loss: 0.904894]\n",
      "epoch:9 step:7349[D loss: 0.446191, acc: 59.38%, op_acc: 36.72%] [G loss: 0.990794]\n",
      "epoch:9 step:7350[D loss: 0.482099, acc: 53.12%, op_acc: 33.59%] [G loss: 0.978963]\n",
      "epoch:9 step:7351[D loss: 0.439137, acc: 57.03%, op_acc: 32.81%] [G loss: 0.855390]\n",
      "epoch:9 step:7352[D loss: 0.437719, acc: 61.72%, op_acc: 38.28%] [G loss: 0.919257]\n",
      "epoch:9 step:7353[D loss: 0.441285, acc: 64.84%, op_acc: 28.12%] [G loss: 0.886905]\n",
      "epoch:9 step:7354[D loss: 0.434027, acc: 65.62%, op_acc: 35.16%] [G loss: 0.943719]\n",
      "epoch:9 step:7355[D loss: 0.431775, acc: 59.38%, op_acc: 38.28%] [G loss: 0.909744]\n",
      "epoch:9 step:7356[D loss: 0.382896, acc: 71.88%, op_acc: 37.50%] [G loss: 0.940911]\n",
      "epoch:9 step:7357[D loss: 0.423999, acc: 63.28%, op_acc: 35.94%] [G loss: 0.898378]\n",
      "epoch:9 step:7358[D loss: 0.437163, acc: 59.38%, op_acc: 32.81%] [G loss: 0.918904]\n",
      "epoch:9 step:7359[D loss: 0.436035, acc: 58.59%, op_acc: 36.72%] [G loss: 0.921553]\n",
      "epoch:9 step:7360[D loss: 0.444643, acc: 57.81%, op_acc: 34.38%] [G loss: 0.899913]\n",
      "epoch:9 step:7361[D loss: 0.408365, acc: 62.50%, op_acc: 39.84%] [G loss: 1.001327]\n",
      "epoch:9 step:7362[D loss: 0.450989, acc: 58.59%, op_acc: 35.16%] [G loss: 0.956053]\n",
      "epoch:9 step:7363[D loss: 0.441896, acc: 60.16%, op_acc: 33.59%] [G loss: 0.938317]\n",
      "epoch:9 step:7364[D loss: 0.439462, acc: 60.94%, op_acc: 35.16%] [G loss: 0.994515]\n",
      "epoch:9 step:7365[D loss: 0.487449, acc: 55.47%, op_acc: 30.47%] [G loss: 0.935319]\n",
      "epoch:9 step:7366[D loss: 0.445091, acc: 61.72%, op_acc: 35.94%] [G loss: 0.967821]\n",
      "epoch:9 step:7367[D loss: 0.434457, acc: 53.91%, op_acc: 36.72%] [G loss: 1.029658]\n",
      "epoch:9 step:7368[D loss: 0.456124, acc: 53.91%, op_acc: 37.50%] [G loss: 0.943158]\n",
      "epoch:9 step:7369[D loss: 0.409813, acc: 64.84%, op_acc: 35.16%] [G loss: 0.978428]\n",
      "epoch:9 step:7370[D loss: 0.428180, acc: 64.06%, op_acc: 34.38%] [G loss: 0.958682]\n",
      "epoch:9 step:7371[D loss: 0.448162, acc: 63.28%, op_acc: 38.28%] [G loss: 0.863287]\n",
      "epoch:9 step:7372[D loss: 0.438941, acc: 63.28%, op_acc: 36.72%] [G loss: 0.988215]\n",
      "epoch:9 step:7373[D loss: 0.450214, acc: 54.69%, op_acc: 33.59%] [G loss: 0.980651]\n",
      "epoch:9 step:7374[D loss: 0.435684, acc: 62.50%, op_acc: 26.56%] [G loss: 0.995317]\n",
      "epoch:9 step:7375[D loss: 0.463312, acc: 60.94%, op_acc: 35.94%] [G loss: 0.920602]\n",
      "epoch:9 step:7376[D loss: 0.455239, acc: 57.03%, op_acc: 38.28%] [G loss: 0.925937]\n",
      "epoch:9 step:7377[D loss: 0.426317, acc: 61.72%, op_acc: 32.03%] [G loss: 0.939598]\n",
      "epoch:9 step:7378[D loss: 0.429471, acc: 61.72%, op_acc: 38.28%] [G loss: 1.041174]\n",
      "epoch:9 step:7379[D loss: 0.411961, acc: 73.44%, op_acc: 32.81%] [G loss: 0.889501]\n",
      "epoch:9 step:7380[D loss: 0.428599, acc: 66.41%, op_acc: 33.59%] [G loss: 0.945397]\n",
      "epoch:9 step:7381[D loss: 0.435513, acc: 63.28%, op_acc: 30.47%] [G loss: 0.832160]\n",
      "epoch:9 step:7382[D loss: 0.388805, acc: 60.94%, op_acc: 39.84%] [G loss: 1.011430]\n",
      "epoch:9 step:7383[D loss: 0.445146, acc: 58.59%, op_acc: 37.50%] [G loss: 0.898894]\n",
      "epoch:9 step:7384[D loss: 0.455922, acc: 57.03%, op_acc: 39.06%] [G loss: 0.838060]\n",
      "epoch:9 step:7385[D loss: 0.444189, acc: 57.03%, op_acc: 37.50%] [G loss: 0.896159]\n",
      "epoch:9 step:7386[D loss: 0.425287, acc: 66.41%, op_acc: 37.50%] [G loss: 0.894994]\n",
      "epoch:9 step:7387[D loss: 0.430897, acc: 61.72%, op_acc: 32.81%] [G loss: 0.916004]\n",
      "epoch:9 step:7388[D loss: 0.440091, acc: 58.59%, op_acc: 35.94%] [G loss: 0.910864]\n",
      "epoch:9 step:7389[D loss: 0.455856, acc: 53.12%, op_acc: 34.38%] [G loss: 0.887673]\n",
      "epoch:9 step:7390[D loss: 0.414904, acc: 67.97%, op_acc: 35.16%] [G loss: 1.014817]\n",
      "epoch:9 step:7391[D loss: 0.388445, acc: 67.19%, op_acc: 40.62%] [G loss: 0.975201]\n",
      "epoch:9 step:7392[D loss: 0.458959, acc: 50.78%, op_acc: 37.50%] [G loss: 0.900987]\n",
      "epoch:9 step:7393[D loss: 0.444576, acc: 61.72%, op_acc: 32.03%] [G loss: 0.893640]\n",
      "epoch:9 step:7394[D loss: 0.403071, acc: 59.38%, op_acc: 39.06%] [G loss: 0.897739]\n",
      "epoch:9 step:7395[D loss: 0.410690, acc: 61.72%, op_acc: 39.84%] [G loss: 0.914077]\n",
      "epoch:9 step:7396[D loss: 0.454889, acc: 55.47%, op_acc: 29.69%] [G loss: 0.978233]\n",
      "epoch:9 step:7397[D loss: 0.431490, acc: 65.62%, op_acc: 29.69%] [G loss: 1.011841]\n",
      "epoch:9 step:7398[D loss: 0.433323, acc: 66.41%, op_acc: 34.38%] [G loss: 0.955599]\n",
      "epoch:9 step:7399[D loss: 0.433588, acc: 65.62%, op_acc: 30.47%] [G loss: 0.925011]\n",
      "epoch:9 step:7400[D loss: 0.420622, acc: 60.94%, op_acc: 35.94%] [G loss: 0.880722]\n",
      "epoch:9 step:7401[D loss: 0.441783, acc: 62.50%, op_acc: 30.47%] [G loss: 0.956293]\n",
      "epoch:9 step:7402[D loss: 0.406300, acc: 64.84%, op_acc: 41.41%] [G loss: 0.909061]\n",
      "epoch:9 step:7403[D loss: 0.407988, acc: 63.28%, op_acc: 42.19%] [G loss: 1.039326]\n",
      "epoch:9 step:7404[D loss: 0.415902, acc: 60.16%, op_acc: 36.72%] [G loss: 0.927418]\n",
      "epoch:9 step:7405[D loss: 0.412856, acc: 70.31%, op_acc: 36.72%] [G loss: 0.997924]\n",
      "epoch:9 step:7406[D loss: 0.433349, acc: 64.84%, op_acc: 28.91%] [G loss: 0.979118]\n",
      "epoch:9 step:7407[D loss: 0.395920, acc: 67.97%, op_acc: 40.62%] [G loss: 0.857892]\n",
      "epoch:9 step:7408[D loss: 0.429748, acc: 61.72%, op_acc: 34.38%] [G loss: 0.985247]\n",
      "epoch:9 step:7409[D loss: 0.445642, acc: 59.38%, op_acc: 35.94%] [G loss: 0.946621]\n",
      "epoch:9 step:7410[D loss: 0.455644, acc: 55.47%, op_acc: 37.50%] [G loss: 0.943079]\n",
      "epoch:9 step:7411[D loss: 0.431223, acc: 61.72%, op_acc: 36.72%] [G loss: 0.997446]\n",
      "epoch:9 step:7412[D loss: 0.420540, acc: 60.94%, op_acc: 38.28%] [G loss: 0.945415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7413[D loss: 0.436064, acc: 60.94%, op_acc: 35.94%] [G loss: 0.952470]\n",
      "epoch:9 step:7414[D loss: 0.401583, acc: 65.62%, op_acc: 43.75%] [G loss: 1.016847]\n",
      "epoch:9 step:7415[D loss: 0.424681, acc: 63.28%, op_acc: 45.31%] [G loss: 0.844321]\n",
      "epoch:9 step:7416[D loss: 0.440964, acc: 56.25%, op_acc: 34.38%] [G loss: 0.969903]\n",
      "epoch:9 step:7417[D loss: 0.419556, acc: 65.62%, op_acc: 36.72%] [G loss: 0.981202]\n",
      "epoch:9 step:7418[D loss: 0.425080, acc: 62.50%, op_acc: 38.28%] [G loss: 0.998703]\n",
      "epoch:9 step:7419[D loss: 0.432402, acc: 60.16%, op_acc: 35.16%] [G loss: 0.937174]\n",
      "epoch:9 step:7420[D loss: 0.412625, acc: 57.03%, op_acc: 39.06%] [G loss: 0.974160]\n",
      "epoch:9 step:7421[D loss: 0.408464, acc: 64.84%, op_acc: 35.16%] [G loss: 0.974697]\n",
      "epoch:9 step:7422[D loss: 0.441059, acc: 60.94%, op_acc: 35.16%] [G loss: 0.880144]\n",
      "epoch:9 step:7423[D loss: 0.430258, acc: 62.50%, op_acc: 34.38%] [G loss: 0.946363]\n",
      "epoch:9 step:7424[D loss: 0.439832, acc: 59.38%, op_acc: 32.81%] [G loss: 0.925609]\n",
      "epoch:9 step:7425[D loss: 0.418554, acc: 63.28%, op_acc: 38.28%] [G loss: 0.900865]\n",
      "epoch:9 step:7426[D loss: 0.443353, acc: 56.25%, op_acc: 39.06%] [G loss: 0.994333]\n",
      "epoch:9 step:7427[D loss: 0.450503, acc: 65.62%, op_acc: 33.59%] [G loss: 0.961920]\n",
      "epoch:9 step:7428[D loss: 0.424828, acc: 60.94%, op_acc: 36.72%] [G loss: 0.929895]\n",
      "epoch:9 step:7429[D loss: 0.423475, acc: 64.84%, op_acc: 37.50%] [G loss: 0.934614]\n",
      "epoch:9 step:7430[D loss: 0.426263, acc: 58.59%, op_acc: 38.28%] [G loss: 0.981683]\n",
      "epoch:9 step:7431[D loss: 0.440093, acc: 61.72%, op_acc: 35.94%] [G loss: 0.918720]\n",
      "epoch:9 step:7432[D loss: 0.430875, acc: 61.72%, op_acc: 39.84%] [G loss: 0.962020]\n",
      "epoch:9 step:7433[D loss: 0.416429, acc: 69.53%, op_acc: 35.94%] [G loss: 0.901187]\n",
      "epoch:9 step:7434[D loss: 0.452663, acc: 61.72%, op_acc: 35.94%] [G loss: 0.925220]\n",
      "epoch:9 step:7435[D loss: 0.400505, acc: 67.97%, op_acc: 35.16%] [G loss: 0.895358]\n",
      "epoch:9 step:7436[D loss: 0.397316, acc: 67.97%, op_acc: 36.72%] [G loss: 0.885416]\n",
      "epoch:9 step:7437[D loss: 0.413674, acc: 65.62%, op_acc: 39.84%] [G loss: 0.957510]\n",
      "epoch:9 step:7438[D loss: 0.433386, acc: 59.38%, op_acc: 39.84%] [G loss: 0.934858]\n",
      "epoch:9 step:7439[D loss: 0.408365, acc: 64.06%, op_acc: 39.06%] [G loss: 1.001827]\n",
      "epoch:9 step:7440[D loss: 0.456931, acc: 57.03%, op_acc: 33.59%] [G loss: 0.948012]\n",
      "epoch:9 step:7441[D loss: 0.454868, acc: 53.91%, op_acc: 37.50%] [G loss: 0.954923]\n",
      "epoch:9 step:7442[D loss: 0.426083, acc: 63.28%, op_acc: 37.50%] [G loss: 0.944263]\n",
      "epoch:9 step:7443[D loss: 0.456473, acc: 53.12%, op_acc: 36.72%] [G loss: 0.859068]\n",
      "epoch:9 step:7444[D loss: 0.408066, acc: 66.41%, op_acc: 35.94%] [G loss: 0.978756]\n",
      "epoch:9 step:7445[D loss: 0.415143, acc: 62.50%, op_acc: 39.84%] [G loss: 0.913327]\n",
      "epoch:9 step:7446[D loss: 0.454594, acc: 60.16%, op_acc: 29.69%] [G loss: 0.854931]\n",
      "epoch:9 step:7447[D loss: 0.449826, acc: 56.25%, op_acc: 32.03%] [G loss: 0.904114]\n",
      "epoch:9 step:7448[D loss: 0.420871, acc: 68.75%, op_acc: 37.50%] [G loss: 0.928969]\n",
      "epoch:9 step:7449[D loss: 0.438605, acc: 60.94%, op_acc: 37.50%] [G loss: 0.996117]\n",
      "epoch:9 step:7450[D loss: 0.475128, acc: 57.81%, op_acc: 33.59%] [G loss: 1.014103]\n",
      "epoch:9 step:7451[D loss: 0.449362, acc: 57.81%, op_acc: 37.50%] [G loss: 0.928101]\n",
      "epoch:9 step:7452[D loss: 0.456483, acc: 58.59%, op_acc: 32.03%] [G loss: 0.999513]\n",
      "epoch:9 step:7453[D loss: 0.455092, acc: 59.38%, op_acc: 38.28%] [G loss: 0.990318]\n",
      "epoch:9 step:7454[D loss: 0.453023, acc: 60.16%, op_acc: 32.03%] [G loss: 0.980487]\n",
      "epoch:9 step:7455[D loss: 0.465298, acc: 50.00%, op_acc: 32.03%] [G loss: 0.945358]\n",
      "epoch:9 step:7456[D loss: 0.448224, acc: 57.81%, op_acc: 35.94%] [G loss: 0.875299]\n",
      "epoch:9 step:7457[D loss: 0.435449, acc: 57.81%, op_acc: 33.59%] [G loss: 0.870537]\n",
      "epoch:9 step:7458[D loss: 0.437969, acc: 57.81%, op_acc: 33.59%] [G loss: 0.836579]\n",
      "epoch:9 step:7459[D loss: 0.435771, acc: 61.72%, op_acc: 37.50%] [G loss: 0.892824]\n",
      "epoch:9 step:7460[D loss: 0.472263, acc: 56.25%, op_acc: 35.16%] [G loss: 1.012486]\n",
      "epoch:9 step:7461[D loss: 0.411752, acc: 67.19%, op_acc: 41.41%] [G loss: 1.002882]\n",
      "epoch:9 step:7462[D loss: 0.428728, acc: 63.28%, op_acc: 35.16%] [G loss: 0.908361]\n",
      "epoch:9 step:7463[D loss: 0.454215, acc: 54.69%, op_acc: 38.28%] [G loss: 0.941956]\n",
      "epoch:9 step:7464[D loss: 0.441001, acc: 62.50%, op_acc: 39.84%] [G loss: 0.923310]\n",
      "epoch:9 step:7465[D loss: 0.490158, acc: 51.56%, op_acc: 30.47%] [G loss: 0.954956]\n",
      "epoch:9 step:7466[D loss: 0.443954, acc: 57.03%, op_acc: 35.16%] [G loss: 1.004014]\n",
      "epoch:9 step:7467[D loss: 0.429447, acc: 61.72%, op_acc: 31.25%] [G loss: 0.902501]\n",
      "epoch:9 step:7468[D loss: 0.418325, acc: 64.84%, op_acc: 35.94%] [G loss: 0.936509]\n",
      "epoch:9 step:7469[D loss: 0.411756, acc: 67.19%, op_acc: 39.06%] [G loss: 1.040280]\n",
      "epoch:9 step:7470[D loss: 0.423031, acc: 65.62%, op_acc: 31.25%] [G loss: 0.973246]\n",
      "epoch:9 step:7471[D loss: 0.437041, acc: 53.91%, op_acc: 36.72%] [G loss: 0.914557]\n",
      "epoch:9 step:7472[D loss: 0.485284, acc: 53.12%, op_acc: 30.47%] [G loss: 0.889835]\n",
      "epoch:9 step:7473[D loss: 0.403938, acc: 63.28%, op_acc: 40.62%] [G loss: 0.925728]\n",
      "epoch:9 step:7474[D loss: 0.456584, acc: 56.25%, op_acc: 31.25%] [G loss: 0.882483]\n",
      "epoch:9 step:7475[D loss: 0.447418, acc: 58.59%, op_acc: 36.72%] [G loss: 0.927385]\n",
      "epoch:9 step:7476[D loss: 0.461578, acc: 64.06%, op_acc: 35.16%] [G loss: 0.957152]\n",
      "epoch:9 step:7477[D loss: 0.432911, acc: 65.62%, op_acc: 35.16%] [G loss: 0.971148]\n",
      "epoch:9 step:7478[D loss: 0.425880, acc: 61.72%, op_acc: 36.72%] [G loss: 0.968466]\n",
      "epoch:9 step:7479[D loss: 0.425611, acc: 62.50%, op_acc: 35.16%] [G loss: 0.939990]\n",
      "epoch:9 step:7480[D loss: 0.438681, acc: 61.72%, op_acc: 38.28%] [G loss: 0.943796]\n",
      "epoch:9 step:7481[D loss: 0.401459, acc: 67.19%, op_acc: 35.94%] [G loss: 1.032371]\n",
      "epoch:9 step:7482[D loss: 0.422697, acc: 60.16%, op_acc: 41.41%] [G loss: 0.977862]\n",
      "epoch:9 step:7483[D loss: 0.403906, acc: 65.62%, op_acc: 36.72%] [G loss: 0.918600]\n",
      "epoch:9 step:7484[D loss: 0.453508, acc: 53.91%, op_acc: 40.62%] [G loss: 0.967229]\n",
      "epoch:9 step:7485[D loss: 0.432679, acc: 66.41%, op_acc: 35.16%] [G loss: 0.892157]\n",
      "epoch:9 step:7486[D loss: 0.444028, acc: 53.91%, op_acc: 33.59%] [G loss: 0.840095]\n",
      "epoch:9 step:7487[D loss: 0.431226, acc: 62.50%, op_acc: 38.28%] [G loss: 0.881404]\n",
      "epoch:9 step:7488[D loss: 0.457521, acc: 54.69%, op_acc: 40.62%] [G loss: 0.979822]\n",
      "epoch:9 step:7489[D loss: 0.438598, acc: 57.81%, op_acc: 36.72%] [G loss: 0.948530]\n",
      "epoch:9 step:7490[D loss: 0.455105, acc: 56.25%, op_acc: 31.25%] [G loss: 0.892379]\n",
      "epoch:9 step:7491[D loss: 0.441486, acc: 60.16%, op_acc: 35.16%] [G loss: 1.063260]\n",
      "epoch:9 step:7492[D loss: 0.410669, acc: 71.88%, op_acc: 42.97%] [G loss: 0.986959]\n",
      "epoch:9 step:7493[D loss: 0.429509, acc: 61.72%, op_acc: 32.81%] [G loss: 0.973834]\n",
      "epoch:9 step:7494[D loss: 0.414262, acc: 67.97%, op_acc: 35.16%] [G loss: 0.975443]\n",
      "epoch:9 step:7495[D loss: 0.415651, acc: 68.75%, op_acc: 36.72%] [G loss: 0.899565]\n",
      "epoch:9 step:7496[D loss: 0.444455, acc: 55.47%, op_acc: 32.03%] [G loss: 0.961324]\n",
      "epoch:9 step:7497[D loss: 0.412701, acc: 60.94%, op_acc: 42.19%] [G loss: 1.008612]\n",
      "epoch:9 step:7498[D loss: 0.404115, acc: 67.97%, op_acc: 35.94%] [G loss: 0.910071]\n",
      "epoch:9 step:7499[D loss: 0.411142, acc: 63.28%, op_acc: 35.16%] [G loss: 0.990440]\n",
      "epoch:9 step:7500[D loss: 0.447892, acc: 64.06%, op_acc: 31.25%] [G loss: 1.007861]\n",
      "epoch:9 step:7501[D loss: 0.495544, acc: 43.75%, op_acc: 29.69%] [G loss: 0.923379]\n",
      "epoch:9 step:7502[D loss: 0.439375, acc: 56.25%, op_acc: 37.50%] [G loss: 0.992977]\n",
      "epoch:9 step:7503[D loss: 0.434493, acc: 60.94%, op_acc: 31.25%] [G loss: 0.927386]\n",
      "epoch:9 step:7504[D loss: 0.425382, acc: 61.72%, op_acc: 40.62%] [G loss: 0.886402]\n",
      "epoch:9 step:7505[D loss: 0.464199, acc: 57.81%, op_acc: 28.91%] [G loss: 0.931862]\n",
      "epoch:9 step:7506[D loss: 0.440509, acc: 57.81%, op_acc: 39.84%] [G loss: 0.949810]\n",
      "epoch:9 step:7507[D loss: 0.430935, acc: 60.16%, op_acc: 39.06%] [G loss: 0.921297]\n",
      "epoch:9 step:7508[D loss: 0.444950, acc: 57.81%, op_acc: 39.06%] [G loss: 0.971395]\n",
      "epoch:9 step:7509[D loss: 0.457971, acc: 55.47%, op_acc: 31.25%] [G loss: 0.968369]\n",
      "epoch:9 step:7510[D loss: 0.455631, acc: 59.38%, op_acc: 32.03%] [G loss: 0.982070]\n",
      "epoch:9 step:7511[D loss: 0.448700, acc: 53.91%, op_acc: 35.16%] [G loss: 0.855214]\n",
      "epoch:9 step:7512[D loss: 0.433836, acc: 63.28%, op_acc: 37.50%] [G loss: 0.935459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7513[D loss: 0.433292, acc: 60.16%, op_acc: 35.16%] [G loss: 1.044930]\n",
      "epoch:9 step:7514[D loss: 0.406358, acc: 68.75%, op_acc: 32.81%] [G loss: 0.969897]\n",
      "epoch:9 step:7515[D loss: 0.433472, acc: 60.94%, op_acc: 35.94%] [G loss: 0.947632]\n",
      "epoch:9 step:7516[D loss: 0.463067, acc: 57.81%, op_acc: 29.69%] [G loss: 0.885879]\n",
      "epoch:9 step:7517[D loss: 0.436456, acc: 64.84%, op_acc: 35.94%] [G loss: 0.933911]\n",
      "epoch:9 step:7518[D loss: 0.439971, acc: 58.59%, op_acc: 42.97%] [G loss: 0.895592]\n",
      "epoch:9 step:7519[D loss: 0.388627, acc: 71.88%, op_acc: 43.75%] [G loss: 0.872094]\n",
      "epoch:9 step:7520[D loss: 0.467570, acc: 53.12%, op_acc: 31.25%] [G loss: 0.897193]\n",
      "epoch:9 step:7521[D loss: 0.434301, acc: 57.03%, op_acc: 39.06%] [G loss: 0.894097]\n",
      "epoch:9 step:7522[D loss: 0.419402, acc: 61.72%, op_acc: 35.16%] [G loss: 0.995283]\n",
      "epoch:9 step:7523[D loss: 0.388338, acc: 69.53%, op_acc: 39.06%] [G loss: 1.013135]\n",
      "epoch:9 step:7524[D loss: 0.424986, acc: 64.84%, op_acc: 35.16%] [G loss: 0.948442]\n",
      "epoch:9 step:7525[D loss: 0.424067, acc: 65.62%, op_acc: 33.59%] [G loss: 0.892296]\n",
      "epoch:9 step:7526[D loss: 0.389180, acc: 67.19%, op_acc: 47.66%] [G loss: 0.958749]\n",
      "epoch:9 step:7527[D loss: 0.479801, acc: 55.47%, op_acc: 33.59%] [G loss: 0.869445]\n",
      "epoch:9 step:7528[D loss: 0.429063, acc: 64.06%, op_acc: 33.59%] [G loss: 0.935117]\n",
      "epoch:9 step:7529[D loss: 0.422269, acc: 66.41%, op_acc: 37.50%] [G loss: 0.947790]\n",
      "epoch:9 step:7530[D loss: 0.447167, acc: 64.06%, op_acc: 37.50%] [G loss: 0.897373]\n",
      "epoch:9 step:7531[D loss: 0.424134, acc: 64.84%, op_acc: 36.72%] [G loss: 0.927073]\n",
      "epoch:9 step:7532[D loss: 0.421243, acc: 66.41%, op_acc: 35.16%] [G loss: 1.004111]\n",
      "epoch:9 step:7533[D loss: 0.466131, acc: 52.34%, op_acc: 30.47%] [G loss: 0.934908]\n",
      "epoch:9 step:7534[D loss: 0.429489, acc: 63.28%, op_acc: 32.03%] [G loss: 1.044487]\n",
      "epoch:9 step:7535[D loss: 0.454530, acc: 52.34%, op_acc: 35.94%] [G loss: 0.948979]\n",
      "epoch:9 step:7536[D loss: 0.413214, acc: 66.41%, op_acc: 35.16%] [G loss: 0.976243]\n",
      "epoch:9 step:7537[D loss: 0.443824, acc: 60.94%, op_acc: 35.94%] [G loss: 0.903348]\n",
      "epoch:9 step:7538[D loss: 0.471503, acc: 46.88%, op_acc: 33.59%] [G loss: 0.908635]\n",
      "epoch:9 step:7539[D loss: 0.446941, acc: 61.72%, op_acc: 28.12%] [G loss: 0.946761]\n",
      "epoch:9 step:7540[D loss: 0.457583, acc: 53.12%, op_acc: 37.50%] [G loss: 0.752473]\n",
      "epoch:9 step:7541[D loss: 0.454473, acc: 57.81%, op_acc: 32.03%] [G loss: 0.926705]\n",
      "epoch:9 step:7542[D loss: 0.471026, acc: 53.12%, op_acc: 29.69%] [G loss: 0.809423]\n",
      "epoch:9 step:7543[D loss: 0.468341, acc: 57.03%, op_acc: 32.81%] [G loss: 0.945754]\n",
      "epoch:9 step:7544[D loss: 0.439055, acc: 59.38%, op_acc: 32.03%] [G loss: 0.883532]\n",
      "epoch:9 step:7545[D loss: 0.423502, acc: 65.62%, op_acc: 34.38%] [G loss: 0.947195]\n",
      "epoch:9 step:7546[D loss: 0.465158, acc: 59.38%, op_acc: 32.81%] [G loss: 0.973735]\n",
      "epoch:9 step:7547[D loss: 0.429302, acc: 65.62%, op_acc: 29.69%] [G loss: 0.934583]\n",
      "epoch:9 step:7548[D loss: 0.401902, acc: 67.19%, op_acc: 40.62%] [G loss: 0.997119]\n",
      "epoch:9 step:7549[D loss: 0.457552, acc: 58.59%, op_acc: 28.12%] [G loss: 0.994128]\n",
      "epoch:9 step:7550[D loss: 0.471637, acc: 49.22%, op_acc: 28.12%] [G loss: 0.961632]\n",
      "epoch:9 step:7551[D loss: 0.442202, acc: 60.16%, op_acc: 36.72%] [G loss: 0.932852]\n",
      "epoch:9 step:7552[D loss: 0.458037, acc: 57.03%, op_acc: 35.94%] [G loss: 1.010940]\n",
      "epoch:9 step:7553[D loss: 0.440530, acc: 62.50%, op_acc: 32.81%] [G loss: 0.950953]\n",
      "epoch:9 step:7554[D loss: 0.463177, acc: 63.28%, op_acc: 29.69%] [G loss: 1.019754]\n",
      "epoch:9 step:7555[D loss: 0.445735, acc: 62.50%, op_acc: 32.03%] [G loss: 1.053822]\n",
      "epoch:9 step:7556[D loss: 0.464074, acc: 53.12%, op_acc: 32.81%] [G loss: 1.029782]\n",
      "epoch:9 step:7557[D loss: 0.425460, acc: 61.72%, op_acc: 39.84%] [G loss: 0.972371]\n",
      "epoch:9 step:7558[D loss: 0.378218, acc: 72.66%, op_acc: 36.72%] [G loss: 0.989939]\n",
      "epoch:9 step:7559[D loss: 0.418363, acc: 67.19%, op_acc: 32.03%] [G loss: 0.903143]\n",
      "epoch:9 step:7560[D loss: 0.429653, acc: 67.19%, op_acc: 39.06%] [G loss: 1.000800]\n",
      "epoch:9 step:7561[D loss: 0.445420, acc: 60.16%, op_acc: 39.06%] [G loss: 0.995795]\n",
      "epoch:9 step:7562[D loss: 0.432784, acc: 56.25%, op_acc: 36.72%] [G loss: 0.903211]\n",
      "epoch:9 step:7563[D loss: 0.464009, acc: 55.47%, op_acc: 33.59%] [G loss: 0.989157]\n",
      "epoch:9 step:7564[D loss: 0.401781, acc: 64.84%, op_acc: 39.06%] [G loss: 1.056092]\n",
      "epoch:9 step:7565[D loss: 0.423506, acc: 60.16%, op_acc: 43.75%] [G loss: 1.007702]\n",
      "epoch:9 step:7566[D loss: 0.494609, acc: 52.34%, op_acc: 35.16%] [G loss: 0.915585]\n",
      "epoch:9 step:7567[D loss: 0.416426, acc: 63.28%, op_acc: 38.28%] [G loss: 0.923207]\n",
      "epoch:9 step:7568[D loss: 0.439922, acc: 60.94%, op_acc: 34.38%] [G loss: 0.898753]\n",
      "epoch:9 step:7569[D loss: 0.427313, acc: 58.59%, op_acc: 35.94%] [G loss: 0.962128]\n",
      "epoch:9 step:7570[D loss: 0.407495, acc: 60.16%, op_acc: 43.75%] [G loss: 0.958357]\n",
      "epoch:9 step:7571[D loss: 0.423219, acc: 60.16%, op_acc: 35.16%] [G loss: 0.937360]\n",
      "epoch:9 step:7572[D loss: 0.447690, acc: 56.25%, op_acc: 29.69%] [G loss: 0.895046]\n",
      "epoch:9 step:7573[D loss: 0.418623, acc: 64.06%, op_acc: 33.59%] [G loss: 0.921384]\n",
      "epoch:9 step:7574[D loss: 0.401183, acc: 67.97%, op_acc: 41.41%] [G loss: 0.946210]\n",
      "epoch:9 step:7575[D loss: 0.442115, acc: 55.47%, op_acc: 40.62%] [G loss: 1.003213]\n",
      "epoch:9 step:7576[D loss: 0.456914, acc: 53.91%, op_acc: 39.06%] [G loss: 0.948029]\n",
      "epoch:9 step:7577[D loss: 0.453457, acc: 60.16%, op_acc: 36.72%] [G loss: 0.997780]\n",
      "epoch:9 step:7578[D loss: 0.435024, acc: 64.84%, op_acc: 40.62%] [G loss: 0.889914]\n",
      "epoch:9 step:7579[D loss: 0.426044, acc: 60.16%, op_acc: 36.72%] [G loss: 0.977884]\n",
      "epoch:9 step:7580[D loss: 0.402729, acc: 66.41%, op_acc: 38.28%] [G loss: 1.001707]\n",
      "epoch:9 step:7581[D loss: 0.465829, acc: 57.81%, op_acc: 29.69%] [G loss: 0.984015]\n",
      "epoch:9 step:7582[D loss: 0.439182, acc: 55.47%, op_acc: 36.72%] [G loss: 0.837109]\n",
      "epoch:9 step:7583[D loss: 0.468069, acc: 47.66%, op_acc: 35.16%] [G loss: 0.914072]\n",
      "epoch:9 step:7584[D loss: 0.425047, acc: 60.94%, op_acc: 39.06%] [G loss: 0.887032]\n",
      "epoch:9 step:7585[D loss: 0.425904, acc: 59.38%, op_acc: 37.50%] [G loss: 1.011711]\n",
      "epoch:9 step:7586[D loss: 0.455458, acc: 57.81%, op_acc: 32.03%] [G loss: 0.988253]\n",
      "epoch:9 step:7587[D loss: 0.428607, acc: 58.59%, op_acc: 34.38%] [G loss: 0.913880]\n",
      "epoch:9 step:7588[D loss: 0.407266, acc: 67.19%, op_acc: 34.38%] [G loss: 0.984316]\n",
      "epoch:9 step:7589[D loss: 0.475849, acc: 60.94%, op_acc: 28.91%] [G loss: 0.908528]\n",
      "epoch:9 step:7590[D loss: 0.413595, acc: 60.16%, op_acc: 41.41%] [G loss: 0.894304]\n",
      "epoch:9 step:7591[D loss: 0.450920, acc: 57.81%, op_acc: 34.38%] [G loss: 0.914678]\n",
      "epoch:9 step:7592[D loss: 0.402675, acc: 71.88%, op_acc: 34.38%] [G loss: 0.988726]\n",
      "epoch:9 step:7593[D loss: 0.409715, acc: 63.28%, op_acc: 39.84%] [G loss: 0.996948]\n",
      "epoch:9 step:7594[D loss: 0.418314, acc: 66.41%, op_acc: 35.94%] [G loss: 0.935035]\n",
      "epoch:9 step:7595[D loss: 0.451104, acc: 62.50%, op_acc: 35.94%] [G loss: 0.859209]\n",
      "epoch:9 step:7596[D loss: 0.434519, acc: 64.06%, op_acc: 38.28%] [G loss: 0.939661]\n",
      "epoch:9 step:7597[D loss: 0.419461, acc: 66.41%, op_acc: 34.38%] [G loss: 0.884679]\n",
      "epoch:9 step:7598[D loss: 0.420166, acc: 57.81%, op_acc: 35.16%] [G loss: 0.967894]\n",
      "epoch:9 step:7599[D loss: 0.446221, acc: 55.47%, op_acc: 38.28%] [G loss: 0.882937]\n",
      "epoch:9 step:7600[D loss: 0.433577, acc: 58.59%, op_acc: 43.75%] [G loss: 1.068724]\n",
      "epoch:9 step:7601[D loss: 0.434103, acc: 63.28%, op_acc: 36.72%] [G loss: 0.877821]\n",
      "epoch:9 step:7602[D loss: 0.446383, acc: 59.38%, op_acc: 38.28%] [G loss: 0.813022]\n",
      "epoch:9 step:7603[D loss: 0.452297, acc: 60.16%, op_acc: 32.81%] [G loss: 0.972495]\n",
      "epoch:9 step:7604[D loss: 0.450014, acc: 66.41%, op_acc: 36.72%] [G loss: 0.923609]\n",
      "epoch:9 step:7605[D loss: 0.422236, acc: 62.50%, op_acc: 35.16%] [G loss: 0.966044]\n",
      "epoch:9 step:7606[D loss: 0.467414, acc: 57.81%, op_acc: 30.47%] [G loss: 0.936465]\n",
      "epoch:9 step:7607[D loss: 0.401358, acc: 67.97%, op_acc: 35.94%] [G loss: 1.021891]\n",
      "epoch:9 step:7608[D loss: 0.432502, acc: 57.03%, op_acc: 36.72%] [G loss: 0.941995]\n",
      "epoch:9 step:7609[D loss: 0.489769, acc: 53.12%, op_acc: 33.59%] [G loss: 0.877362]\n",
      "epoch:9 step:7610[D loss: 0.450032, acc: 56.25%, op_acc: 35.16%] [G loss: 0.896083]\n",
      "epoch:9 step:7611[D loss: 0.449684, acc: 56.25%, op_acc: 38.28%] [G loss: 0.920579]\n",
      "epoch:9 step:7612[D loss: 0.429709, acc: 60.16%, op_acc: 37.50%] [G loss: 0.973448]\n",
      "epoch:9 step:7613[D loss: 0.449566, acc: 63.28%, op_acc: 33.59%] [G loss: 1.015906]\n",
      "epoch:9 step:7614[D loss: 0.424462, acc: 61.72%, op_acc: 42.97%] [G loss: 0.958570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7615[D loss: 0.480661, acc: 53.91%, op_acc: 32.03%] [G loss: 0.866205]\n",
      "epoch:9 step:7616[D loss: 0.419464, acc: 62.50%, op_acc: 32.81%] [G loss: 0.988942]\n",
      "epoch:9 step:7617[D loss: 0.415605, acc: 66.41%, op_acc: 38.28%] [G loss: 0.921577]\n",
      "epoch:9 step:7618[D loss: 0.423148, acc: 62.50%, op_acc: 38.28%] [G loss: 0.890941]\n",
      "epoch:9 step:7619[D loss: 0.443931, acc: 59.38%, op_acc: 31.25%] [G loss: 0.931896]\n",
      "epoch:9 step:7620[D loss: 0.439769, acc: 60.16%, op_acc: 32.03%] [G loss: 0.969789]\n",
      "epoch:9 step:7621[D loss: 0.461771, acc: 54.69%, op_acc: 34.38%] [G loss: 0.925499]\n",
      "epoch:9 step:7622[D loss: 0.480327, acc: 52.34%, op_acc: 28.12%] [G loss: 0.934380]\n",
      "epoch:9 step:7623[D loss: 0.463745, acc: 48.44%, op_acc: 36.72%] [G loss: 0.893603]\n",
      "epoch:9 step:7624[D loss: 0.445780, acc: 57.03%, op_acc: 32.03%] [G loss: 0.964388]\n",
      "epoch:9 step:7625[D loss: 0.446384, acc: 59.38%, op_acc: 34.38%] [G loss: 0.902115]\n",
      "epoch:9 step:7626[D loss: 0.433572, acc: 54.69%, op_acc: 40.62%] [G loss: 0.932742]\n",
      "epoch:9 step:7627[D loss: 0.404016, acc: 67.19%, op_acc: 37.50%] [G loss: 0.983816]\n",
      "epoch:9 step:7628[D loss: 0.436746, acc: 64.06%, op_acc: 32.03%] [G loss: 1.022874]\n",
      "epoch:9 step:7629[D loss: 0.412639, acc: 64.06%, op_acc: 37.50%] [G loss: 0.900418]\n",
      "epoch:9 step:7630[D loss: 0.430391, acc: 63.28%, op_acc: 35.16%] [G loss: 0.899955]\n",
      "epoch:9 step:7631[D loss: 0.421322, acc: 60.16%, op_acc: 37.50%] [G loss: 1.005558]\n",
      "epoch:9 step:7632[D loss: 0.401110, acc: 67.19%, op_acc: 41.41%] [G loss: 0.951858]\n",
      "epoch:9 step:7633[D loss: 0.466385, acc: 60.94%, op_acc: 29.69%] [G loss: 0.870788]\n",
      "epoch:9 step:7634[D loss: 0.470910, acc: 50.78%, op_acc: 32.03%] [G loss: 0.975956]\n",
      "epoch:9 step:7635[D loss: 0.438462, acc: 56.25%, op_acc: 40.62%] [G loss: 1.012498]\n",
      "epoch:9 step:7636[D loss: 0.434466, acc: 55.47%, op_acc: 38.28%] [G loss: 1.039235]\n",
      "epoch:9 step:7637[D loss: 0.378817, acc: 72.66%, op_acc: 35.94%] [G loss: 0.978132]\n",
      "epoch:9 step:7638[D loss: 0.488871, acc: 46.88%, op_acc: 35.94%] [G loss: 0.946236]\n",
      "epoch:9 step:7639[D loss: 0.456604, acc: 58.59%, op_acc: 34.38%] [G loss: 0.945308]\n",
      "epoch:9 step:7640[D loss: 0.436642, acc: 63.28%, op_acc: 33.59%] [G loss: 1.033575]\n",
      "epoch:9 step:7641[D loss: 0.419629, acc: 62.50%, op_acc: 39.06%] [G loss: 0.989291]\n",
      "epoch:9 step:7642[D loss: 0.450062, acc: 60.16%, op_acc: 36.72%] [G loss: 0.865943]\n",
      "epoch:9 step:7643[D loss: 0.434185, acc: 56.25%, op_acc: 37.50%] [G loss: 0.921513]\n",
      "epoch:9 step:7644[D loss: 0.435854, acc: 60.94%, op_acc: 36.72%] [G loss: 0.949418]\n",
      "epoch:9 step:7645[D loss: 0.479184, acc: 53.91%, op_acc: 32.03%] [G loss: 0.930135]\n",
      "epoch:9 step:7646[D loss: 0.460923, acc: 56.25%, op_acc: 27.34%] [G loss: 0.959413]\n",
      "epoch:9 step:7647[D loss: 0.408901, acc: 60.94%, op_acc: 35.94%] [G loss: 0.970294]\n",
      "epoch:9 step:7648[D loss: 0.447190, acc: 58.59%, op_acc: 33.59%] [G loss: 0.919098]\n",
      "epoch:9 step:7649[D loss: 0.443798, acc: 60.16%, op_acc: 28.91%] [G loss: 0.897075]\n",
      "epoch:9 step:7650[D loss: 0.435642, acc: 53.12%, op_acc: 35.94%] [G loss: 0.859007]\n",
      "epoch:9 step:7651[D loss: 0.436879, acc: 68.75%, op_acc: 33.59%] [G loss: 0.969317]\n",
      "epoch:9 step:7652[D loss: 0.429459, acc: 58.59%, op_acc: 39.06%] [G loss: 1.013655]\n",
      "epoch:9 step:7653[D loss: 0.447780, acc: 55.47%, op_acc: 32.03%] [G loss: 1.000556]\n",
      "epoch:9 step:7654[D loss: 0.474366, acc: 50.00%, op_acc: 36.72%] [G loss: 0.870430]\n",
      "epoch:9 step:7655[D loss: 0.443494, acc: 56.25%, op_acc: 39.06%] [G loss: 0.869755]\n",
      "epoch:9 step:7656[D loss: 0.421241, acc: 64.84%, op_acc: 32.81%] [G loss: 0.900417]\n",
      "epoch:9 step:7657[D loss: 0.446898, acc: 53.12%, op_acc: 35.94%] [G loss: 0.949129]\n",
      "epoch:9 step:7658[D loss: 0.448456, acc: 57.03%, op_acc: 32.81%] [G loss: 0.993901]\n",
      "epoch:9 step:7659[D loss: 0.419587, acc: 60.16%, op_acc: 36.72%] [G loss: 0.905735]\n",
      "epoch:9 step:7660[D loss: 0.444351, acc: 56.25%, op_acc: 32.81%] [G loss: 0.979137]\n",
      "epoch:9 step:7661[D loss: 0.428990, acc: 67.97%, op_acc: 32.03%] [G loss: 0.988267]\n",
      "epoch:9 step:7662[D loss: 0.428691, acc: 64.06%, op_acc: 35.94%] [G loss: 0.943736]\n",
      "epoch:9 step:7663[D loss: 0.442228, acc: 55.47%, op_acc: 37.50%] [G loss: 0.892963]\n",
      "epoch:9 step:7664[D loss: 0.453024, acc: 56.25%, op_acc: 39.06%] [G loss: 0.947050]\n",
      "epoch:9 step:7665[D loss: 0.424671, acc: 60.94%, op_acc: 37.50%] [G loss: 0.832536]\n",
      "epoch:9 step:7666[D loss: 0.430673, acc: 63.28%, op_acc: 30.47%] [G loss: 0.934120]\n",
      "epoch:9 step:7667[D loss: 0.452910, acc: 60.16%, op_acc: 32.81%] [G loss: 0.923407]\n",
      "epoch:9 step:7668[D loss: 0.469515, acc: 52.34%, op_acc: 33.59%] [G loss: 0.913441]\n",
      "epoch:9 step:7669[D loss: 0.450841, acc: 61.72%, op_acc: 32.81%] [G loss: 0.867465]\n",
      "epoch:9 step:7670[D loss: 0.438238, acc: 59.38%, op_acc: 37.50%] [G loss: 0.837500]\n",
      "epoch:9 step:7671[D loss: 0.477339, acc: 56.25%, op_acc: 28.12%] [G loss: 0.917761]\n",
      "epoch:9 step:7672[D loss: 0.466926, acc: 57.03%, op_acc: 32.81%] [G loss: 0.921765]\n",
      "epoch:9 step:7673[D loss: 0.420703, acc: 63.28%, op_acc: 37.50%] [G loss: 0.941115]\n",
      "epoch:9 step:7674[D loss: 0.409208, acc: 71.88%, op_acc: 38.28%] [G loss: 0.907593]\n",
      "epoch:9 step:7675[D loss: 0.437956, acc: 67.19%, op_acc: 34.38%] [G loss: 0.855935]\n",
      "epoch:9 step:7676[D loss: 0.434293, acc: 58.59%, op_acc: 37.50%] [G loss: 0.991153]\n",
      "epoch:9 step:7677[D loss: 0.450356, acc: 57.03%, op_acc: 34.38%] [G loss: 0.900063]\n",
      "epoch:9 step:7678[D loss: 0.439235, acc: 60.94%, op_acc: 32.81%] [G loss: 0.978317]\n",
      "epoch:9 step:7679[D loss: 0.446581, acc: 60.16%, op_acc: 35.16%] [G loss: 0.861935]\n",
      "epoch:9 step:7680[D loss: 0.446040, acc: 58.59%, op_acc: 35.16%] [G loss: 0.941989]\n",
      "epoch:9 step:7681[D loss: 0.421597, acc: 60.94%, op_acc: 35.16%] [G loss: 0.994703]\n",
      "epoch:9 step:7682[D loss: 0.415489, acc: 64.06%, op_acc: 35.16%] [G loss: 0.905130]\n",
      "epoch:9 step:7683[D loss: 0.434809, acc: 64.06%, op_acc: 34.38%] [G loss: 0.889470]\n",
      "epoch:9 step:7684[D loss: 0.397691, acc: 64.84%, op_acc: 39.06%] [G loss: 0.960802]\n",
      "epoch:9 step:7685[D loss: 0.432678, acc: 60.16%, op_acc: 37.50%] [G loss: 0.944930]\n",
      "epoch:9 step:7686[D loss: 0.438583, acc: 59.38%, op_acc: 39.84%] [G loss: 0.932942]\n",
      "epoch:9 step:7687[D loss: 0.403268, acc: 67.19%, op_acc: 34.38%] [G loss: 0.921255]\n",
      "epoch:9 step:7688[D loss: 0.416618, acc: 66.41%, op_acc: 39.06%] [G loss: 1.009042]\n",
      "epoch:9 step:7689[D loss: 0.436023, acc: 65.62%, op_acc: 37.50%] [G loss: 0.987099]\n",
      "epoch:9 step:7690[D loss: 0.428456, acc: 57.81%, op_acc: 37.50%] [G loss: 0.911357]\n",
      "epoch:9 step:7691[D loss: 0.416408, acc: 60.16%, op_acc: 39.06%] [G loss: 0.880844]\n",
      "epoch:9 step:7692[D loss: 0.402573, acc: 67.97%, op_acc: 39.84%] [G loss: 0.890089]\n",
      "epoch:9 step:7693[D loss: 0.433123, acc: 54.69%, op_acc: 39.84%] [G loss: 0.933199]\n",
      "epoch:9 step:7694[D loss: 0.443291, acc: 61.72%, op_acc: 35.94%] [G loss: 1.013988]\n",
      "epoch:9 step:7695[D loss: 0.433482, acc: 66.41%, op_acc: 34.38%] [G loss: 0.906349]\n",
      "epoch:9 step:7696[D loss: 0.433449, acc: 62.50%, op_acc: 32.03%] [G loss: 0.905974]\n",
      "epoch:9 step:7697[D loss: 0.433686, acc: 56.25%, op_acc: 40.62%] [G loss: 0.928617]\n",
      "epoch:9 step:7698[D loss: 0.447386, acc: 63.28%, op_acc: 29.69%] [G loss: 0.943182]\n",
      "epoch:9 step:7699[D loss: 0.422996, acc: 58.59%, op_acc: 42.19%] [G loss: 0.864898]\n",
      "epoch:9 step:7700[D loss: 0.451653, acc: 60.94%, op_acc: 25.78%] [G loss: 1.008558]\n",
      "epoch:9 step:7701[D loss: 0.447643, acc: 56.25%, op_acc: 35.16%] [G loss: 0.817678]\n",
      "epoch:9 step:7702[D loss: 0.422931, acc: 60.16%, op_acc: 37.50%] [G loss: 0.998981]\n",
      "epoch:9 step:7703[D loss: 0.443072, acc: 55.47%, op_acc: 35.16%] [G loss: 0.947323]\n",
      "epoch:9 step:7704[D loss: 0.407152, acc: 64.84%, op_acc: 39.06%] [G loss: 0.963755]\n",
      "epoch:9 step:7705[D loss: 0.487147, acc: 56.25%, op_acc: 28.12%] [G loss: 0.995711]\n",
      "epoch:9 step:7706[D loss: 0.431076, acc: 66.41%, op_acc: 34.38%] [G loss: 0.905272]\n",
      "epoch:9 step:7707[D loss: 0.434851, acc: 54.69%, op_acc: 34.38%] [G loss: 0.930545]\n",
      "epoch:9 step:7708[D loss: 0.394456, acc: 65.62%, op_acc: 40.62%] [G loss: 0.911819]\n",
      "epoch:9 step:7709[D loss: 0.470225, acc: 57.03%, op_acc: 32.03%] [G loss: 0.934156]\n",
      "epoch:9 step:7710[D loss: 0.436870, acc: 71.09%, op_acc: 29.69%] [G loss: 0.981156]\n",
      "epoch:9 step:7711[D loss: 0.443112, acc: 55.47%, op_acc: 42.19%] [G loss: 0.955235]\n",
      "epoch:9 step:7712[D loss: 0.411490, acc: 60.94%, op_acc: 42.19%] [G loss: 0.987721]\n",
      "epoch:9 step:7713[D loss: 0.450660, acc: 53.12%, op_acc: 41.41%] [G loss: 0.974924]\n",
      "epoch:9 step:7714[D loss: 0.440329, acc: 64.06%, op_acc: 38.28%] [G loss: 0.924705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:7715[D loss: 0.460402, acc: 62.50%, op_acc: 31.25%] [G loss: 0.924882]\n",
      "epoch:9 step:7716[D loss: 0.416911, acc: 59.38%, op_acc: 35.16%] [G loss: 0.934395]\n",
      "epoch:9 step:7717[D loss: 0.459573, acc: 53.12%, op_acc: 35.94%] [G loss: 0.893285]\n",
      "epoch:9 step:7718[D loss: 0.438953, acc: 60.16%, op_acc: 40.62%] [G loss: 0.962331]\n",
      "epoch:9 step:7719[D loss: 0.433014, acc: 64.06%, op_acc: 32.81%] [G loss: 0.897865]\n",
      "epoch:9 step:7720[D loss: 0.422018, acc: 64.06%, op_acc: 34.38%] [G loss: 0.917710]\n",
      "epoch:9 step:7721[D loss: 0.466165, acc: 57.03%, op_acc: 36.72%] [G loss: 0.922340]\n",
      "epoch:9 step:7722[D loss: 0.435070, acc: 62.50%, op_acc: 37.50%] [G loss: 0.890577]\n",
      "epoch:9 step:7723[D loss: 0.434750, acc: 56.25%, op_acc: 36.72%] [G loss: 0.994767]\n",
      "epoch:9 step:7724[D loss: 0.426673, acc: 60.94%, op_acc: 36.72%] [G loss: 0.953058]\n",
      "epoch:9 step:7725[D loss: 0.438232, acc: 63.28%, op_acc: 39.84%] [G loss: 1.040624]\n",
      "epoch:9 step:7726[D loss: 0.446262, acc: 61.72%, op_acc: 34.38%] [G loss: 0.985540]\n",
      "epoch:9 step:7727[D loss: 0.422912, acc: 64.84%, op_acc: 39.06%] [G loss: 0.929659]\n",
      "epoch:9 step:7728[D loss: 0.432311, acc: 60.16%, op_acc: 32.03%] [G loss: 0.918233]\n",
      "epoch:9 step:7729[D loss: 0.428271, acc: 61.72%, op_acc: 32.81%] [G loss: 0.891119]\n",
      "epoch:9 step:7730[D loss: 0.441249, acc: 63.28%, op_acc: 34.38%] [G loss: 0.944474]\n",
      "epoch:9 step:7731[D loss: 0.421961, acc: 62.50%, op_acc: 32.81%] [G loss: 0.902518]\n",
      "epoch:9 step:7732[D loss: 0.442268, acc: 57.03%, op_acc: 35.94%] [G loss: 0.958892]\n",
      "epoch:9 step:7733[D loss: 0.413706, acc: 64.06%, op_acc: 42.19%] [G loss: 1.003092]\n",
      "epoch:9 step:7734[D loss: 0.450586, acc: 64.06%, op_acc: 39.06%] [G loss: 0.924042]\n",
      "epoch:9 step:7735[D loss: 0.449883, acc: 57.03%, op_acc: 39.06%] [G loss: 1.078474]\n",
      "epoch:9 step:7736[D loss: 0.453740, acc: 57.03%, op_acc: 28.12%] [G loss: 0.952863]\n",
      "epoch:9 step:7737[D loss: 0.434705, acc: 62.50%, op_acc: 39.84%] [G loss: 0.847254]\n",
      "epoch:9 step:7738[D loss: 0.414204, acc: 63.28%, op_acc: 37.50%] [G loss: 0.973940]\n",
      "epoch:9 step:7739[D loss: 0.392245, acc: 64.84%, op_acc: 42.97%] [G loss: 0.992361]\n",
      "epoch:9 step:7740[D loss: 0.408312, acc: 61.72%, op_acc: 38.28%] [G loss: 0.897776]\n",
      "epoch:9 step:7741[D loss: 0.419497, acc: 64.06%, op_acc: 39.06%] [G loss: 0.934180]\n",
      "epoch:9 step:7742[D loss: 0.423461, acc: 57.81%, op_acc: 37.50%] [G loss: 0.895810]\n",
      "epoch:9 step:7743[D loss: 0.461114, acc: 56.25%, op_acc: 31.25%] [G loss: 0.988543]\n",
      "epoch:9 step:7744[D loss: 0.404797, acc: 64.84%, op_acc: 39.84%] [G loss: 0.907999]\n",
      "epoch:9 step:7745[D loss: 0.451789, acc: 55.47%, op_acc: 37.50%] [G loss: 0.992279]\n",
      "epoch:9 step:7746[D loss: 0.449898, acc: 52.34%, op_acc: 33.59%] [G loss: 0.936400]\n",
      "epoch:9 step:7747[D loss: 0.461556, acc: 52.34%, op_acc: 32.03%] [G loss: 0.942760]\n",
      "epoch:9 step:7748[D loss: 0.436469, acc: 62.50%, op_acc: 39.84%] [G loss: 0.985047]\n",
      "epoch:9 step:7749[D loss: 0.420259, acc: 60.16%, op_acc: 43.75%] [G loss: 1.021179]\n",
      "epoch:9 step:7750[D loss: 0.440008, acc: 60.16%, op_acc: 39.06%] [G loss: 0.915005]\n",
      "epoch:9 step:7751[D loss: 0.455482, acc: 55.47%, op_acc: 39.06%] [G loss: 0.904906]\n",
      "epoch:9 step:7752[D loss: 0.431153, acc: 58.59%, op_acc: 38.28%] [G loss: 0.954635]\n",
      "epoch:9 step:7753[D loss: 0.466403, acc: 58.59%, op_acc: 28.91%] [G loss: 0.887405]\n",
      "epoch:9 step:7754[D loss: 0.424921, acc: 67.19%, op_acc: 33.59%] [G loss: 1.020440]\n",
      "epoch:9 step:7755[D loss: 0.433675, acc: 60.16%, op_acc: 34.38%] [G loss: 0.898053]\n",
      "epoch:9 step:7756[D loss: 0.481812, acc: 51.56%, op_acc: 36.72%] [G loss: 0.887011]\n",
      "epoch:9 step:7757[D loss: 0.461948, acc: 58.59%, op_acc: 30.47%] [G loss: 0.869990]\n",
      "epoch:9 step:7758[D loss: 0.466644, acc: 52.34%, op_acc: 33.59%] [G loss: 0.793671]\n",
      "epoch:9 step:7759[D loss: 0.440832, acc: 55.47%, op_acc: 37.50%] [G loss: 1.021534]\n",
      "epoch:9 step:7760[D loss: 0.437158, acc: 57.03%, op_acc: 39.06%] [G loss: 0.932182]\n",
      "epoch:9 step:7761[D loss: 0.451659, acc: 64.06%, op_acc: 32.03%] [G loss: 1.022449]\n",
      "epoch:9 step:7762[D loss: 0.450664, acc: 57.03%, op_acc: 35.16%] [G loss: 0.976761]\n",
      "epoch:9 step:7763[D loss: 0.461339, acc: 53.91%, op_acc: 35.94%] [G loss: 0.933607]\n",
      "epoch:9 step:7764[D loss: 0.450745, acc: 57.03%, op_acc: 32.03%] [G loss: 0.868362]\n",
      "epoch:9 step:7765[D loss: 0.443668, acc: 58.59%, op_acc: 32.03%] [G loss: 0.860686]\n",
      "epoch:9 step:7766[D loss: 0.406852, acc: 67.19%, op_acc: 41.41%] [G loss: 0.946020]\n",
      "epoch:9 step:7767[D loss: 0.432583, acc: 60.94%, op_acc: 35.94%] [G loss: 0.958234]\n",
      "epoch:9 step:7768[D loss: 0.397406, acc: 67.19%, op_acc: 41.41%] [G loss: 0.890327]\n",
      "epoch:9 step:7769[D loss: 0.423959, acc: 58.59%, op_acc: 40.62%] [G loss: 0.916897]\n",
      "epoch:9 step:7770[D loss: 0.423497, acc: 64.84%, op_acc: 33.59%] [G loss: 0.950184]\n",
      "epoch:9 step:7771[D loss: 0.430874, acc: 59.38%, op_acc: 39.06%] [G loss: 0.909135]\n",
      "epoch:9 step:7772[D loss: 0.472663, acc: 58.59%, op_acc: 29.69%] [G loss: 1.013298]\n",
      "epoch:9 step:7773[D loss: 0.409708, acc: 60.94%, op_acc: 42.97%] [G loss: 0.889726]\n",
      "epoch:9 step:7774[D loss: 0.430887, acc: 63.28%, op_acc: 36.72%] [G loss: 0.916414]\n",
      "epoch:9 step:7775[D loss: 0.446291, acc: 59.38%, op_acc: 35.94%] [G loss: 0.959201]\n",
      "epoch:9 step:7776[D loss: 0.465654, acc: 54.69%, op_acc: 37.50%] [G loss: 0.922977]\n",
      "epoch:9 step:7777[D loss: 0.462106, acc: 55.47%, op_acc: 35.94%] [G loss: 0.921737]\n",
      "epoch:9 step:7778[D loss: 0.471770, acc: 56.25%, op_acc: 31.25%] [G loss: 0.820843]\n",
      "epoch:9 step:7779[D loss: 0.432572, acc: 65.62%, op_acc: 33.59%] [G loss: 0.909591]\n",
      "epoch:9 step:7780[D loss: 0.475114, acc: 56.25%, op_acc: 31.25%] [G loss: 0.870035]\n",
      "epoch:9 step:7781[D loss: 0.418365, acc: 62.50%, op_acc: 40.62%] [G loss: 0.945605]\n",
      "epoch:9 step:7782[D loss: 0.441946, acc: 60.16%, op_acc: 39.84%] [G loss: 0.854806]\n",
      "epoch:9 step:7783[D loss: 0.465833, acc: 53.12%, op_acc: 34.38%] [G loss: 0.967632]\n",
      "epoch:9 step:7784[D loss: 0.431905, acc: 63.28%, op_acc: 39.06%] [G loss: 0.920663]\n",
      "epoch:9 step:7785[D loss: 0.425390, acc: 56.25%, op_acc: 39.84%] [G loss: 0.943674]\n",
      "epoch:9 step:7786[D loss: 0.400905, acc: 64.06%, op_acc: 39.84%] [G loss: 0.904550]\n",
      "epoch:9 step:7787[D loss: 0.388954, acc: 72.66%, op_acc: 42.97%] [G loss: 0.981018]\n",
      "epoch:9 step:7788[D loss: 0.459737, acc: 60.16%, op_acc: 39.06%] [G loss: 0.895434]\n",
      "epoch:9 step:7789[D loss: 0.472597, acc: 54.69%, op_acc: 29.69%] [G loss: 0.891114]\n",
      "epoch:9 step:7790[D loss: 0.403444, acc: 65.62%, op_acc: 35.94%] [G loss: 0.850203]\n",
      "epoch:9 step:7791[D loss: 0.456872, acc: 57.03%, op_acc: 31.25%] [G loss: 0.807204]\n",
      "epoch:9 step:7792[D loss: 0.450363, acc: 51.56%, op_acc: 37.50%] [G loss: 0.883286]\n",
      "epoch:9 step:7793[D loss: 0.459421, acc: 53.91%, op_acc: 36.72%] [G loss: 0.896337]\n",
      "epoch:9 step:7794[D loss: 0.456563, acc: 55.47%, op_acc: 34.38%] [G loss: 0.921288]\n",
      "epoch:9 step:7795[D loss: 0.479371, acc: 49.22%, op_acc: 31.25%] [G loss: 0.923441]\n",
      "epoch:9 step:7796[D loss: 0.385662, acc: 68.75%, op_acc: 42.97%] [G loss: 0.948877]\n",
      "epoch:9 step:7797[D loss: 0.446821, acc: 61.72%, op_acc: 32.81%] [G loss: 0.921746]\n",
      "epoch:9 step:7798[D loss: 0.430379, acc: 64.06%, op_acc: 39.84%] [G loss: 0.913481]\n",
      "epoch:9 step:7799[D loss: 0.422475, acc: 56.25%, op_acc: 32.03%] [G loss: 0.876774]\n",
      "epoch:9 step:7800[D loss: 0.452046, acc: 59.38%, op_acc: 32.03%] [G loss: 0.960055]\n",
      "epoch:9 step:7801[D loss: 0.449844, acc: 56.25%, op_acc: 34.38%] [G loss: 0.926308]\n",
      "epoch:9 step:7802[D loss: 0.441445, acc: 60.94%, op_acc: 34.38%] [G loss: 0.956796]\n",
      "epoch:9 step:7803[D loss: 0.389156, acc: 62.50%, op_acc: 43.75%] [G loss: 0.873077]\n",
      "epoch:9 step:7804[D loss: 0.438636, acc: 64.06%, op_acc: 28.91%] [G loss: 0.942967]\n",
      "epoch:9 step:7805[D loss: 0.422139, acc: 58.59%, op_acc: 41.41%] [G loss: 0.917747]\n",
      "epoch:9 step:7806[D loss: 0.428034, acc: 62.50%, op_acc: 28.91%] [G loss: 1.019617]\n",
      "epoch:9 step:7807[D loss: 0.441584, acc: 54.69%, op_acc: 40.62%] [G loss: 0.889994]\n",
      "epoch:9 step:7808[D loss: 0.439253, acc: 62.50%, op_acc: 36.72%] [G loss: 0.895472]\n",
      "epoch:9 step:7809[D loss: 0.436390, acc: 53.12%, op_acc: 39.06%] [G loss: 1.001187]\n",
      "epoch:9 step:7810[D loss: 0.439332, acc: 62.50%, op_acc: 31.25%] [G loss: 0.929990]\n",
      "epoch:10 step:7811[D loss: 0.428707, acc: 59.38%, op_acc: 41.41%] [G loss: 0.953011]\n",
      "epoch:10 step:7812[D loss: 0.416310, acc: 64.06%, op_acc: 34.38%] [G loss: 0.973107]\n",
      "epoch:10 step:7813[D loss: 0.444704, acc: 57.03%, op_acc: 33.59%] [G loss: 0.932258]\n",
      "epoch:10 step:7814[D loss: 0.405188, acc: 63.28%, op_acc: 42.97%] [G loss: 0.936400]\n",
      "epoch:10 step:7815[D loss: 0.422877, acc: 67.97%, op_acc: 38.28%] [G loss: 0.897015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7816[D loss: 0.437678, acc: 56.25%, op_acc: 36.72%] [G loss: 0.931777]\n",
      "epoch:10 step:7817[D loss: 0.429430, acc: 62.50%, op_acc: 37.50%] [G loss: 0.946986]\n",
      "epoch:10 step:7818[D loss: 0.436112, acc: 61.72%, op_acc: 38.28%] [G loss: 0.865746]\n",
      "epoch:10 step:7819[D loss: 0.424134, acc: 60.94%, op_acc: 38.28%] [G loss: 0.895614]\n",
      "epoch:10 step:7820[D loss: 0.472979, acc: 53.91%, op_acc: 29.69%] [G loss: 0.828800]\n",
      "epoch:10 step:7821[D loss: 0.480135, acc: 56.25%, op_acc: 32.81%] [G loss: 0.867168]\n",
      "epoch:10 step:7822[D loss: 0.441286, acc: 63.28%, op_acc: 31.25%] [G loss: 0.962221]\n",
      "epoch:10 step:7823[D loss: 0.422623, acc: 60.16%, op_acc: 38.28%] [G loss: 0.936789]\n",
      "epoch:10 step:7824[D loss: 0.453087, acc: 53.91%, op_acc: 33.59%] [G loss: 0.955393]\n",
      "epoch:10 step:7825[D loss: 0.434371, acc: 57.03%, op_acc: 33.59%] [G loss: 0.987870]\n",
      "epoch:10 step:7826[D loss: 0.440442, acc: 55.47%, op_acc: 32.03%] [G loss: 0.831646]\n",
      "epoch:10 step:7827[D loss: 0.416073, acc: 67.19%, op_acc: 38.28%] [G loss: 0.833271]\n",
      "epoch:10 step:7828[D loss: 0.444282, acc: 52.34%, op_acc: 32.03%] [G loss: 0.865680]\n",
      "epoch:10 step:7829[D loss: 0.420548, acc: 62.50%, op_acc: 40.62%] [G loss: 0.921692]\n",
      "epoch:10 step:7830[D loss: 0.425002, acc: 60.94%, op_acc: 35.16%] [G loss: 0.935975]\n",
      "epoch:10 step:7831[D loss: 0.463481, acc: 57.03%, op_acc: 33.59%] [G loss: 1.019432]\n",
      "epoch:10 step:7832[D loss: 0.447420, acc: 60.94%, op_acc: 32.03%] [G loss: 0.952155]\n",
      "epoch:10 step:7833[D loss: 0.452172, acc: 54.69%, op_acc: 35.94%] [G loss: 0.958470]\n",
      "epoch:10 step:7834[D loss: 0.453312, acc: 63.28%, op_acc: 34.38%] [G loss: 0.975812]\n",
      "epoch:10 step:7835[D loss: 0.452505, acc: 54.69%, op_acc: 38.28%] [G loss: 0.980878]\n",
      "epoch:10 step:7836[D loss: 0.412413, acc: 66.41%, op_acc: 39.06%] [G loss: 0.958062]\n",
      "epoch:10 step:7837[D loss: 0.448099, acc: 55.47%, op_acc: 36.72%] [G loss: 0.869070]\n",
      "epoch:10 step:7838[D loss: 0.443273, acc: 53.12%, op_acc: 37.50%] [G loss: 0.961731]\n",
      "epoch:10 step:7839[D loss: 0.415969, acc: 63.28%, op_acc: 37.50%] [G loss: 0.938520]\n",
      "epoch:10 step:7840[D loss: 0.413920, acc: 62.50%, op_acc: 44.53%] [G loss: 0.861415]\n",
      "epoch:10 step:7841[D loss: 0.493678, acc: 54.69%, op_acc: 29.69%] [G loss: 0.981560]\n",
      "epoch:10 step:7842[D loss: 0.441900, acc: 63.28%, op_acc: 29.69%] [G loss: 0.934052]\n",
      "epoch:10 step:7843[D loss: 0.427997, acc: 61.72%, op_acc: 41.41%] [G loss: 0.908649]\n",
      "epoch:10 step:7844[D loss: 0.434257, acc: 60.16%, op_acc: 39.06%] [G loss: 0.947911]\n",
      "epoch:10 step:7845[D loss: 0.447923, acc: 64.84%, op_acc: 32.03%] [G loss: 0.924352]\n",
      "epoch:10 step:7846[D loss: 0.417980, acc: 59.38%, op_acc: 34.38%] [G loss: 0.907489]\n",
      "epoch:10 step:7847[D loss: 0.410492, acc: 59.38%, op_acc: 39.06%] [G loss: 0.960202]\n",
      "epoch:10 step:7848[D loss: 0.419194, acc: 66.41%, op_acc: 37.50%] [G loss: 1.047971]\n",
      "epoch:10 step:7849[D loss: 0.422690, acc: 60.94%, op_acc: 37.50%] [G loss: 0.890821]\n",
      "epoch:10 step:7850[D loss: 0.438402, acc: 60.94%, op_acc: 37.50%] [G loss: 0.920920]\n",
      "epoch:10 step:7851[D loss: 0.433405, acc: 60.16%, op_acc: 36.72%] [G loss: 0.944128]\n",
      "epoch:10 step:7852[D loss: 0.400001, acc: 63.28%, op_acc: 41.41%] [G loss: 0.909860]\n",
      "epoch:10 step:7853[D loss: 0.458698, acc: 55.47%, op_acc: 29.69%] [G loss: 0.925746]\n",
      "epoch:10 step:7854[D loss: 0.443476, acc: 55.47%, op_acc: 32.03%] [G loss: 0.898871]\n",
      "epoch:10 step:7855[D loss: 0.441303, acc: 65.62%, op_acc: 34.38%] [G loss: 0.860477]\n",
      "epoch:10 step:7856[D loss: 0.440344, acc: 57.81%, op_acc: 29.69%] [G loss: 0.937221]\n",
      "epoch:10 step:7857[D loss: 0.468959, acc: 57.81%, op_acc: 28.12%] [G loss: 0.985449]\n",
      "epoch:10 step:7858[D loss: 0.441514, acc: 64.84%, op_acc: 37.50%] [G loss: 0.993075]\n",
      "epoch:10 step:7859[D loss: 0.462119, acc: 53.91%, op_acc: 32.81%] [G loss: 0.841622]\n",
      "epoch:10 step:7860[D loss: 0.444367, acc: 58.59%, op_acc: 36.72%] [G loss: 0.879329]\n",
      "epoch:10 step:7861[D loss: 0.419496, acc: 61.72%, op_acc: 39.84%] [G loss: 0.962151]\n",
      "epoch:10 step:7862[D loss: 0.435972, acc: 59.38%, op_acc: 39.06%] [G loss: 0.947224]\n",
      "epoch:10 step:7863[D loss: 0.441424, acc: 62.50%, op_acc: 28.91%] [G loss: 0.934729]\n",
      "epoch:10 step:7864[D loss: 0.467382, acc: 55.47%, op_acc: 36.72%] [G loss: 0.929388]\n",
      "epoch:10 step:7865[D loss: 0.422730, acc: 63.28%, op_acc: 34.38%] [G loss: 0.934362]\n",
      "epoch:10 step:7866[D loss: 0.427476, acc: 57.81%, op_acc: 34.38%] [G loss: 0.900293]\n",
      "epoch:10 step:7867[D loss: 0.456397, acc: 57.81%, op_acc: 31.25%] [G loss: 0.951531]\n",
      "epoch:10 step:7868[D loss: 0.446734, acc: 54.69%, op_acc: 35.94%] [G loss: 0.925135]\n",
      "epoch:10 step:7869[D loss: 0.423771, acc: 56.25%, op_acc: 39.06%] [G loss: 0.928269]\n",
      "epoch:10 step:7870[D loss: 0.405861, acc: 66.41%, op_acc: 32.03%] [G loss: 0.949785]\n",
      "epoch:10 step:7871[D loss: 0.419297, acc: 69.53%, op_acc: 34.38%] [G loss: 0.926892]\n",
      "epoch:10 step:7872[D loss: 0.453317, acc: 63.28%, op_acc: 31.25%] [G loss: 0.922468]\n",
      "epoch:10 step:7873[D loss: 0.458546, acc: 54.69%, op_acc: 32.81%] [G loss: 0.891163]\n",
      "epoch:10 step:7874[D loss: 0.419781, acc: 65.62%, op_acc: 39.06%] [G loss: 0.982968]\n",
      "epoch:10 step:7875[D loss: 0.438617, acc: 60.16%, op_acc: 41.41%] [G loss: 0.914881]\n",
      "epoch:10 step:7876[D loss: 0.422952, acc: 60.94%, op_acc: 38.28%] [G loss: 0.904485]\n",
      "epoch:10 step:7877[D loss: 0.433806, acc: 65.62%, op_acc: 37.50%] [G loss: 0.968368]\n",
      "epoch:10 step:7878[D loss: 0.428374, acc: 60.16%, op_acc: 35.16%] [G loss: 0.960166]\n",
      "epoch:10 step:7879[D loss: 0.442278, acc: 55.47%, op_acc: 40.62%] [G loss: 0.924529]\n",
      "epoch:10 step:7880[D loss: 0.439617, acc: 57.03%, op_acc: 34.38%] [G loss: 0.907082]\n",
      "epoch:10 step:7881[D loss: 0.463987, acc: 56.25%, op_acc: 30.47%] [G loss: 0.925153]\n",
      "epoch:10 step:7882[D loss: 0.413594, acc: 63.28%, op_acc: 42.97%] [G loss: 0.891540]\n",
      "epoch:10 step:7883[D loss: 0.430569, acc: 64.84%, op_acc: 34.38%] [G loss: 0.924009]\n",
      "epoch:10 step:7884[D loss: 0.441829, acc: 57.03%, op_acc: 35.94%] [G loss: 0.873088]\n",
      "epoch:10 step:7885[D loss: 0.399696, acc: 64.06%, op_acc: 35.94%] [G loss: 0.911435]\n",
      "epoch:10 step:7886[D loss: 0.471695, acc: 57.03%, op_acc: 32.03%] [G loss: 0.890424]\n",
      "epoch:10 step:7887[D loss: 0.422396, acc: 60.94%, op_acc: 38.28%] [G loss: 1.026893]\n",
      "epoch:10 step:7888[D loss: 0.469559, acc: 56.25%, op_acc: 28.91%] [G loss: 0.866028]\n",
      "epoch:10 step:7889[D loss: 0.452578, acc: 60.94%, op_acc: 34.38%] [G loss: 0.909639]\n",
      "epoch:10 step:7890[D loss: 0.477400, acc: 57.03%, op_acc: 25.78%] [G loss: 0.891132]\n",
      "epoch:10 step:7891[D loss: 0.459124, acc: 61.72%, op_acc: 34.38%] [G loss: 0.956204]\n",
      "epoch:10 step:7892[D loss: 0.435775, acc: 59.38%, op_acc: 33.59%] [G loss: 0.932366]\n",
      "epoch:10 step:7893[D loss: 0.450401, acc: 60.16%, op_acc: 35.16%] [G loss: 0.882238]\n",
      "epoch:10 step:7894[D loss: 0.461594, acc: 54.69%, op_acc: 36.72%] [G loss: 0.866634]\n",
      "epoch:10 step:7895[D loss: 0.450549, acc: 64.06%, op_acc: 27.34%] [G loss: 0.935428]\n",
      "epoch:10 step:7896[D loss: 0.422327, acc: 59.38%, op_acc: 38.28%] [G loss: 0.989002]\n",
      "epoch:10 step:7897[D loss: 0.406611, acc: 68.75%, op_acc: 37.50%] [G loss: 0.895909]\n",
      "epoch:10 step:7898[D loss: 0.448707, acc: 50.78%, op_acc: 33.59%] [G loss: 0.899798]\n",
      "epoch:10 step:7899[D loss: 0.429653, acc: 67.19%, op_acc: 33.59%] [G loss: 0.814897]\n",
      "epoch:10 step:7900[D loss: 0.436085, acc: 63.28%, op_acc: 38.28%] [G loss: 0.910161]\n",
      "epoch:10 step:7901[D loss: 0.455175, acc: 55.47%, op_acc: 35.94%] [G loss: 0.834451]\n",
      "epoch:10 step:7902[D loss: 0.406547, acc: 67.19%, op_acc: 30.47%] [G loss: 0.945015]\n",
      "epoch:10 step:7903[D loss: 0.434326, acc: 53.91%, op_acc: 38.28%] [G loss: 0.904896]\n",
      "epoch:10 step:7904[D loss: 0.407746, acc: 68.75%, op_acc: 35.16%] [G loss: 0.910326]\n",
      "epoch:10 step:7905[D loss: 0.407940, acc: 65.62%, op_acc: 33.59%] [G loss: 1.002764]\n",
      "epoch:10 step:7906[D loss: 0.459744, acc: 50.78%, op_acc: 34.38%] [G loss: 0.951818]\n",
      "epoch:10 step:7907[D loss: 0.439908, acc: 57.81%, op_acc: 33.59%] [G loss: 0.931748]\n",
      "epoch:10 step:7908[D loss: 0.432351, acc: 64.84%, op_acc: 35.16%] [G loss: 0.989094]\n",
      "epoch:10 step:7909[D loss: 0.435755, acc: 57.81%, op_acc: 39.84%] [G loss: 0.867363]\n",
      "epoch:10 step:7910[D loss: 0.431126, acc: 60.16%, op_acc: 41.41%] [G loss: 0.966268]\n",
      "epoch:10 step:7911[D loss: 0.450866, acc: 52.34%, op_acc: 33.59%] [G loss: 0.896053]\n",
      "epoch:10 step:7912[D loss: 0.450005, acc: 53.91%, op_acc: 34.38%] [G loss: 0.894645]\n",
      "epoch:10 step:7913[D loss: 0.454374, acc: 53.91%, op_acc: 32.03%] [G loss: 0.927794]\n",
      "epoch:10 step:7914[D loss: 0.421749, acc: 60.94%, op_acc: 39.06%] [G loss: 0.983548]\n",
      "epoch:10 step:7915[D loss: 0.428662, acc: 60.16%, op_acc: 35.94%] [G loss: 0.918669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:7916[D loss: 0.412263, acc: 62.50%, op_acc: 33.59%] [G loss: 0.892450]\n",
      "epoch:10 step:7917[D loss: 0.436530, acc: 60.16%, op_acc: 33.59%] [G loss: 0.946589]\n",
      "epoch:10 step:7918[D loss: 0.490232, acc: 56.25%, op_acc: 33.59%] [G loss: 0.890610]\n",
      "epoch:10 step:7919[D loss: 0.384884, acc: 68.75%, op_acc: 40.62%] [G loss: 0.957761]\n",
      "epoch:10 step:7920[D loss: 0.435664, acc: 60.94%, op_acc: 36.72%] [G loss: 0.964549]\n",
      "epoch:10 step:7921[D loss: 0.434725, acc: 57.81%, op_acc: 37.50%] [G loss: 0.990888]\n",
      "epoch:10 step:7922[D loss: 0.438820, acc: 56.25%, op_acc: 30.47%] [G loss: 0.881016]\n",
      "epoch:10 step:7923[D loss: 0.437449, acc: 61.72%, op_acc: 34.38%] [G loss: 0.993750]\n",
      "epoch:10 step:7924[D loss: 0.412685, acc: 60.16%, op_acc: 43.75%] [G loss: 0.964031]\n",
      "epoch:10 step:7925[D loss: 0.407918, acc: 59.38%, op_acc: 37.50%] [G loss: 0.971682]\n",
      "epoch:10 step:7926[D loss: 0.456932, acc: 56.25%, op_acc: 29.69%] [G loss: 0.861155]\n",
      "epoch:10 step:7927[D loss: 0.444053, acc: 56.25%, op_acc: 38.28%] [G loss: 0.860770]\n",
      "epoch:10 step:7928[D loss: 0.436780, acc: 58.59%, op_acc: 32.81%] [G loss: 0.975879]\n",
      "epoch:10 step:7929[D loss: 0.437579, acc: 64.06%, op_acc: 30.47%] [G loss: 0.894013]\n",
      "epoch:10 step:7930[D loss: 0.493972, acc: 52.34%, op_acc: 28.91%] [G loss: 0.980135]\n",
      "epoch:10 step:7931[D loss: 0.461933, acc: 56.25%, op_acc: 34.38%] [G loss: 1.005686]\n",
      "epoch:10 step:7932[D loss: 0.460305, acc: 50.78%, op_acc: 32.03%] [G loss: 0.959724]\n",
      "epoch:10 step:7933[D loss: 0.453871, acc: 59.38%, op_acc: 36.72%] [G loss: 0.938250]\n",
      "epoch:10 step:7934[D loss: 0.447819, acc: 53.12%, op_acc: 34.38%] [G loss: 0.986854]\n",
      "epoch:10 step:7935[D loss: 0.483981, acc: 53.12%, op_acc: 29.69%] [G loss: 0.917246]\n",
      "epoch:10 step:7936[D loss: 0.427439, acc: 57.03%, op_acc: 37.50%] [G loss: 0.857437]\n",
      "epoch:10 step:7937[D loss: 0.450065, acc: 62.50%, op_acc: 27.34%] [G loss: 0.956975]\n",
      "epoch:10 step:7938[D loss: 0.413207, acc: 67.19%, op_acc: 37.50%] [G loss: 0.993919]\n",
      "epoch:10 step:7939[D loss: 0.448128, acc: 55.47%, op_acc: 32.81%] [G loss: 0.920767]\n",
      "epoch:10 step:7940[D loss: 0.394928, acc: 70.31%, op_acc: 37.50%] [G loss: 0.959732]\n",
      "epoch:10 step:7941[D loss: 0.403373, acc: 64.84%, op_acc: 36.72%] [G loss: 0.990389]\n",
      "epoch:10 step:7942[D loss: 0.393240, acc: 63.28%, op_acc: 41.41%] [G loss: 0.894027]\n",
      "epoch:10 step:7943[D loss: 0.450410, acc: 65.62%, op_acc: 31.25%] [G loss: 0.888355]\n",
      "epoch:10 step:7944[D loss: 0.416306, acc: 68.75%, op_acc: 42.97%] [G loss: 0.964920]\n",
      "epoch:10 step:7945[D loss: 0.457471, acc: 57.81%, op_acc: 39.06%] [G loss: 0.949343]\n",
      "epoch:10 step:7946[D loss: 0.381325, acc: 71.09%, op_acc: 38.28%] [G loss: 0.989066]\n",
      "epoch:10 step:7947[D loss: 0.429243, acc: 61.72%, op_acc: 37.50%] [G loss: 0.875797]\n",
      "epoch:10 step:7948[D loss: 0.460510, acc: 51.56%, op_acc: 32.03%] [G loss: 0.909469]\n",
      "epoch:10 step:7949[D loss: 0.424037, acc: 62.50%, op_acc: 35.16%] [G loss: 0.982570]\n",
      "epoch:10 step:7950[D loss: 0.431068, acc: 65.62%, op_acc: 41.41%] [G loss: 0.861150]\n",
      "epoch:10 step:7951[D loss: 0.454956, acc: 64.84%, op_acc: 29.69%] [G loss: 0.988562]\n",
      "epoch:10 step:7952[D loss: 0.423761, acc: 62.50%, op_acc: 31.25%] [G loss: 0.824382]\n",
      "epoch:10 step:7953[D loss: 0.441017, acc: 60.16%, op_acc: 37.50%] [G loss: 0.918875]\n",
      "epoch:10 step:7954[D loss: 0.441660, acc: 64.84%, op_acc: 34.38%] [G loss: 0.906107]\n",
      "epoch:10 step:7955[D loss: 0.438961, acc: 61.72%, op_acc: 35.16%] [G loss: 0.858741]\n",
      "epoch:10 step:7956[D loss: 0.436004, acc: 60.94%, op_acc: 39.06%] [G loss: 0.890648]\n",
      "epoch:10 step:7957[D loss: 0.439497, acc: 57.81%, op_acc: 33.59%] [G loss: 0.981556]\n",
      "epoch:10 step:7958[D loss: 0.439350, acc: 54.69%, op_acc: 39.06%] [G loss: 0.901114]\n",
      "epoch:10 step:7959[D loss: 0.417234, acc: 62.50%, op_acc: 40.62%] [G loss: 0.966975]\n",
      "epoch:10 step:7960[D loss: 0.421523, acc: 64.84%, op_acc: 39.06%] [G loss: 0.914634]\n",
      "epoch:10 step:7961[D loss: 0.436182, acc: 57.81%, op_acc: 32.81%] [G loss: 0.837892]\n",
      "epoch:10 step:7962[D loss: 0.430984, acc: 58.59%, op_acc: 36.72%] [G loss: 0.897274]\n",
      "epoch:10 step:7963[D loss: 0.460064, acc: 53.12%, op_acc: 36.72%] [G loss: 0.914617]\n",
      "epoch:10 step:7964[D loss: 0.437822, acc: 63.28%, op_acc: 32.03%] [G loss: 0.929879]\n",
      "epoch:10 step:7965[D loss: 0.439083, acc: 67.19%, op_acc: 38.28%] [G loss: 0.924931]\n",
      "epoch:10 step:7966[D loss: 0.440455, acc: 59.38%, op_acc: 35.94%] [G loss: 0.908257]\n",
      "epoch:10 step:7967[D loss: 0.415733, acc: 65.62%, op_acc: 39.84%] [G loss: 0.831957]\n",
      "epoch:10 step:7968[D loss: 0.422459, acc: 59.38%, op_acc: 35.16%] [G loss: 0.863018]\n",
      "epoch:10 step:7969[D loss: 0.424026, acc: 64.84%, op_acc: 39.84%] [G loss: 0.888775]\n",
      "epoch:10 step:7970[D loss: 0.434082, acc: 63.28%, op_acc: 31.25%] [G loss: 0.962760]\n",
      "epoch:10 step:7971[D loss: 0.432619, acc: 60.16%, op_acc: 41.41%] [G loss: 0.971751]\n",
      "epoch:10 step:7972[D loss: 0.442607, acc: 57.03%, op_acc: 41.41%] [G loss: 0.921281]\n",
      "epoch:10 step:7973[D loss: 0.426639, acc: 61.72%, op_acc: 39.06%] [G loss: 0.986295]\n",
      "epoch:10 step:7974[D loss: 0.438725, acc: 69.53%, op_acc: 35.94%] [G loss: 0.881809]\n",
      "epoch:10 step:7975[D loss: 0.428374, acc: 50.00%, op_acc: 40.62%] [G loss: 0.798771]\n",
      "epoch:10 step:7976[D loss: 0.433342, acc: 64.06%, op_acc: 37.50%] [G loss: 0.836650]\n",
      "epoch:10 step:7977[D loss: 0.441291, acc: 62.50%, op_acc: 35.94%] [G loss: 0.897178]\n",
      "epoch:10 step:7978[D loss: 0.431386, acc: 57.03%, op_acc: 33.59%] [G loss: 0.941968]\n",
      "epoch:10 step:7979[D loss: 0.407247, acc: 59.38%, op_acc: 39.84%] [G loss: 0.945619]\n",
      "epoch:10 step:7980[D loss: 0.430065, acc: 60.94%, op_acc: 35.94%] [G loss: 1.000963]\n",
      "epoch:10 step:7981[D loss: 0.452038, acc: 60.16%, op_acc: 30.47%] [G loss: 0.889914]\n",
      "epoch:10 step:7982[D loss: 0.403724, acc: 64.84%, op_acc: 35.16%] [G loss: 0.925224]\n",
      "epoch:10 step:7983[D loss: 0.469417, acc: 51.56%, op_acc: 34.38%] [G loss: 0.917401]\n",
      "epoch:10 step:7984[D loss: 0.467874, acc: 64.06%, op_acc: 31.25%] [G loss: 0.901976]\n",
      "epoch:10 step:7985[D loss: 0.414746, acc: 65.62%, op_acc: 34.38%] [G loss: 0.829302]\n",
      "epoch:10 step:7986[D loss: 0.458652, acc: 51.56%, op_acc: 36.72%] [G loss: 0.907258]\n",
      "epoch:10 step:7987[D loss: 0.432669, acc: 56.25%, op_acc: 38.28%] [G loss: 0.906746]\n",
      "epoch:10 step:7988[D loss: 0.468732, acc: 56.25%, op_acc: 34.38%] [G loss: 0.933642]\n",
      "epoch:10 step:7989[D loss: 0.410331, acc: 66.41%, op_acc: 35.94%] [G loss: 0.962528]\n",
      "epoch:10 step:7990[D loss: 0.482904, acc: 57.03%, op_acc: 32.03%] [G loss: 0.902601]\n",
      "epoch:10 step:7991[D loss: 0.407700, acc: 62.50%, op_acc: 34.38%] [G loss: 0.926453]\n",
      "epoch:10 step:7992[D loss: 0.406608, acc: 70.31%, op_acc: 32.81%] [G loss: 0.927120]\n",
      "epoch:10 step:7993[D loss: 0.439337, acc: 60.16%, op_acc: 28.91%] [G loss: 0.904083]\n",
      "epoch:10 step:7994[D loss: 0.456867, acc: 55.47%, op_acc: 29.69%] [G loss: 1.013521]\n",
      "epoch:10 step:7995[D loss: 0.419435, acc: 67.97%, op_acc: 28.91%] [G loss: 0.940441]\n",
      "epoch:10 step:7996[D loss: 0.432423, acc: 57.81%, op_acc: 39.06%] [G loss: 0.972113]\n",
      "epoch:10 step:7997[D loss: 0.461560, acc: 49.22%, op_acc: 39.06%] [G loss: 0.897875]\n",
      "epoch:10 step:7998[D loss: 0.452985, acc: 53.91%, op_acc: 33.59%] [G loss: 0.974407]\n",
      "epoch:10 step:7999[D loss: 0.424658, acc: 69.53%, op_acc: 32.03%] [G loss: 0.861509]\n",
      "epoch:10 step:8000[D loss: 0.470038, acc: 55.47%, op_acc: 32.81%] [G loss: 0.910406]\n",
      "epoch:10 step:8001[D loss: 0.407022, acc: 65.62%, op_acc: 36.72%] [G loss: 0.974008]\n",
      "epoch:10 step:8002[D loss: 0.445852, acc: 60.16%, op_acc: 35.16%] [G loss: 1.036804]\n",
      "epoch:10 step:8003[D loss: 0.476983, acc: 58.59%, op_acc: 29.69%] [G loss: 0.884562]\n",
      "epoch:10 step:8004[D loss: 0.454167, acc: 53.12%, op_acc: 34.38%] [G loss: 0.922198]\n",
      "epoch:10 step:8005[D loss: 0.461289, acc: 53.91%, op_acc: 32.03%] [G loss: 0.914678]\n",
      "epoch:10 step:8006[D loss: 0.451092, acc: 63.28%, op_acc: 32.81%] [G loss: 0.974065]\n",
      "epoch:10 step:8007[D loss: 0.456847, acc: 64.06%, op_acc: 34.38%] [G loss: 0.997334]\n",
      "epoch:10 step:8008[D loss: 0.462776, acc: 57.81%, op_acc: 35.94%] [G loss: 0.855515]\n",
      "epoch:10 step:8009[D loss: 0.415136, acc: 64.84%, op_acc: 30.47%] [G loss: 0.940020]\n",
      "epoch:10 step:8010[D loss: 0.428804, acc: 64.84%, op_acc: 35.16%] [G loss: 0.915538]\n",
      "epoch:10 step:8011[D loss: 0.429185, acc: 60.16%, op_acc: 39.84%] [G loss: 0.932510]\n",
      "epoch:10 step:8012[D loss: 0.459746, acc: 54.69%, op_acc: 33.59%] [G loss: 0.838614]\n",
      "epoch:10 step:8013[D loss: 0.474993, acc: 53.91%, op_acc: 33.59%] [G loss: 0.967806]\n",
      "epoch:10 step:8014[D loss: 0.463517, acc: 59.38%, op_acc: 29.69%] [G loss: 1.032781]\n",
      "epoch:10 step:8015[D loss: 0.473279, acc: 52.34%, op_acc: 28.91%] [G loss: 0.902439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8016[D loss: 0.464846, acc: 52.34%, op_acc: 31.25%] [G loss: 0.869530]\n",
      "epoch:10 step:8017[D loss: 0.394522, acc: 67.19%, op_acc: 37.50%] [G loss: 0.952936]\n",
      "epoch:10 step:8018[D loss: 0.430120, acc: 68.75%, op_acc: 35.94%] [G loss: 1.059245]\n",
      "epoch:10 step:8019[D loss: 0.450498, acc: 50.78%, op_acc: 36.72%] [G loss: 0.865199]\n",
      "epoch:10 step:8020[D loss: 0.451239, acc: 65.62%, op_acc: 32.81%] [G loss: 0.888327]\n",
      "epoch:10 step:8021[D loss: 0.411238, acc: 64.06%, op_acc: 45.31%] [G loss: 0.996483]\n",
      "epoch:10 step:8022[D loss: 0.420939, acc: 60.94%, op_acc: 36.72%] [G loss: 0.911692]\n",
      "epoch:10 step:8023[D loss: 0.437732, acc: 61.72%, op_acc: 34.38%] [G loss: 0.907667]\n",
      "epoch:10 step:8024[D loss: 0.484515, acc: 54.69%, op_acc: 32.81%] [G loss: 0.885307]\n",
      "epoch:10 step:8025[D loss: 0.476496, acc: 56.25%, op_acc: 32.81%] [G loss: 0.947711]\n",
      "epoch:10 step:8026[D loss: 0.427024, acc: 60.16%, op_acc: 39.06%] [G loss: 0.908653]\n",
      "epoch:10 step:8027[D loss: 0.407214, acc: 64.06%, op_acc: 35.94%] [G loss: 0.954186]\n",
      "epoch:10 step:8028[D loss: 0.424446, acc: 68.75%, op_acc: 35.16%] [G loss: 0.957639]\n",
      "epoch:10 step:8029[D loss: 0.426929, acc: 59.38%, op_acc: 32.81%] [G loss: 0.917804]\n",
      "epoch:10 step:8030[D loss: 0.457205, acc: 57.81%, op_acc: 32.81%] [G loss: 0.850801]\n",
      "epoch:10 step:8031[D loss: 0.425166, acc: 64.84%, op_acc: 32.81%] [G loss: 0.805081]\n",
      "epoch:10 step:8032[D loss: 0.446499, acc: 60.94%, op_acc: 26.56%] [G loss: 0.905266]\n",
      "epoch:10 step:8033[D loss: 0.442661, acc: 54.69%, op_acc: 41.41%] [G loss: 0.916114]\n",
      "epoch:10 step:8034[D loss: 0.446919, acc: 55.47%, op_acc: 32.81%] [G loss: 0.884077]\n",
      "epoch:10 step:8035[D loss: 0.463026, acc: 55.47%, op_acc: 36.72%] [G loss: 0.939747]\n",
      "epoch:10 step:8036[D loss: 0.431878, acc: 62.50%, op_acc: 36.72%] [G loss: 0.805617]\n",
      "epoch:10 step:8037[D loss: 0.422488, acc: 62.50%, op_acc: 34.38%] [G loss: 0.846273]\n",
      "epoch:10 step:8038[D loss: 0.450917, acc: 54.69%, op_acc: 35.16%] [G loss: 0.859265]\n",
      "epoch:10 step:8039[D loss: 0.452038, acc: 60.16%, op_acc: 32.81%] [G loss: 0.908398]\n",
      "epoch:10 step:8040[D loss: 0.440500, acc: 61.72%, op_acc: 36.72%] [G loss: 0.949278]\n",
      "epoch:10 step:8041[D loss: 0.407395, acc: 67.97%, op_acc: 35.94%] [G loss: 0.935888]\n",
      "epoch:10 step:8042[D loss: 0.434916, acc: 62.50%, op_acc: 35.16%] [G loss: 0.992198]\n",
      "epoch:10 step:8043[D loss: 0.441128, acc: 60.16%, op_acc: 35.94%] [G loss: 0.912927]\n",
      "epoch:10 step:8044[D loss: 0.468315, acc: 53.91%, op_acc: 36.72%] [G loss: 0.881003]\n",
      "epoch:10 step:8045[D loss: 0.421473, acc: 62.50%, op_acc: 39.84%] [G loss: 0.939467]\n",
      "epoch:10 step:8046[D loss: 0.466820, acc: 55.47%, op_acc: 31.25%] [G loss: 0.975250]\n",
      "epoch:10 step:8047[D loss: 0.416902, acc: 57.81%, op_acc: 32.03%] [G loss: 0.869458]\n",
      "epoch:10 step:8048[D loss: 0.428047, acc: 63.28%, op_acc: 39.06%] [G loss: 0.933355]\n",
      "epoch:10 step:8049[D loss: 0.425613, acc: 60.16%, op_acc: 35.94%] [G loss: 0.943518]\n",
      "epoch:10 step:8050[D loss: 0.443673, acc: 60.94%, op_acc: 36.72%] [G loss: 0.845022]\n",
      "epoch:10 step:8051[D loss: 0.428894, acc: 55.47%, op_acc: 38.28%] [G loss: 0.912782]\n",
      "epoch:10 step:8052[D loss: 0.451836, acc: 60.94%, op_acc: 32.81%] [G loss: 0.857090]\n",
      "epoch:10 step:8053[D loss: 0.440984, acc: 59.38%, op_acc: 30.47%] [G loss: 0.915302]\n",
      "epoch:10 step:8054[D loss: 0.445987, acc: 58.59%, op_acc: 33.59%] [G loss: 0.843135]\n",
      "epoch:10 step:8055[D loss: 0.456200, acc: 53.91%, op_acc: 36.72%] [G loss: 0.836918]\n",
      "epoch:10 step:8056[D loss: 0.435474, acc: 57.81%, op_acc: 35.94%] [G loss: 0.973852]\n",
      "epoch:10 step:8057[D loss: 0.440390, acc: 57.81%, op_acc: 34.38%] [G loss: 0.955221]\n",
      "epoch:10 step:8058[D loss: 0.478797, acc: 56.25%, op_acc: 32.81%] [G loss: 0.934638]\n",
      "epoch:10 step:8059[D loss: 0.426799, acc: 66.41%, op_acc: 33.59%] [G loss: 0.960469]\n",
      "epoch:10 step:8060[D loss: 0.459447, acc: 57.81%, op_acc: 32.81%] [G loss: 1.002327]\n",
      "epoch:10 step:8061[D loss: 0.430610, acc: 63.28%, op_acc: 39.06%] [G loss: 0.934214]\n",
      "epoch:10 step:8062[D loss: 0.411119, acc: 65.62%, op_acc: 41.41%] [G loss: 0.912043]\n",
      "epoch:10 step:8063[D loss: 0.426247, acc: 63.28%, op_acc: 31.25%] [G loss: 0.874649]\n",
      "epoch:10 step:8064[D loss: 0.470000, acc: 53.91%, op_acc: 32.81%] [G loss: 0.946420]\n",
      "epoch:10 step:8065[D loss: 0.440922, acc: 63.28%, op_acc: 34.38%] [G loss: 0.877891]\n",
      "epoch:10 step:8066[D loss: 0.422301, acc: 60.94%, op_acc: 35.94%] [G loss: 0.933948]\n",
      "epoch:10 step:8067[D loss: 0.421164, acc: 65.62%, op_acc: 35.94%] [G loss: 1.004661]\n",
      "epoch:10 step:8068[D loss: 0.430465, acc: 60.16%, op_acc: 38.28%] [G loss: 0.904456]\n",
      "epoch:10 step:8069[D loss: 0.429595, acc: 67.19%, op_acc: 29.69%] [G loss: 0.934815]\n",
      "epoch:10 step:8070[D loss: 0.448642, acc: 59.38%, op_acc: 35.94%] [G loss: 0.934192]\n",
      "epoch:10 step:8071[D loss: 0.427455, acc: 62.50%, op_acc: 37.50%] [G loss: 0.898879]\n",
      "epoch:10 step:8072[D loss: 0.428325, acc: 66.41%, op_acc: 32.81%] [G loss: 0.937716]\n",
      "epoch:10 step:8073[D loss: 0.460305, acc: 51.56%, op_acc: 33.59%] [G loss: 0.821612]\n",
      "epoch:10 step:8074[D loss: 0.443458, acc: 57.81%, op_acc: 30.47%] [G loss: 0.959553]\n",
      "epoch:10 step:8075[D loss: 0.404336, acc: 60.16%, op_acc: 39.06%] [G loss: 0.950219]\n",
      "epoch:10 step:8076[D loss: 0.450878, acc: 51.56%, op_acc: 35.94%] [G loss: 0.981473]\n",
      "epoch:10 step:8077[D loss: 0.464978, acc: 57.81%, op_acc: 33.59%] [G loss: 0.940989]\n",
      "epoch:10 step:8078[D loss: 0.434703, acc: 53.12%, op_acc: 32.03%] [G loss: 0.903043]\n",
      "epoch:10 step:8079[D loss: 0.419607, acc: 56.25%, op_acc: 39.84%] [G loss: 0.916669]\n",
      "epoch:10 step:8080[D loss: 0.413156, acc: 67.97%, op_acc: 35.94%] [G loss: 0.993884]\n",
      "epoch:10 step:8081[D loss: 0.451782, acc: 56.25%, op_acc: 32.81%] [G loss: 0.912517]\n",
      "epoch:10 step:8082[D loss: 0.405152, acc: 71.88%, op_acc: 35.94%] [G loss: 0.933608]\n",
      "epoch:10 step:8083[D loss: 0.458878, acc: 52.34%, op_acc: 40.62%] [G loss: 0.906140]\n",
      "epoch:10 step:8084[D loss: 0.425743, acc: 61.72%, op_acc: 35.94%] [G loss: 0.914754]\n",
      "epoch:10 step:8085[D loss: 0.413259, acc: 67.97%, op_acc: 34.38%] [G loss: 0.931885]\n",
      "epoch:10 step:8086[D loss: 0.482275, acc: 49.22%, op_acc: 31.25%] [G loss: 0.831897]\n",
      "epoch:10 step:8087[D loss: 0.434419, acc: 67.97%, op_acc: 33.59%] [G loss: 0.836837]\n",
      "epoch:10 step:8088[D loss: 0.435864, acc: 67.97%, op_acc: 32.81%] [G loss: 0.925781]\n",
      "epoch:10 step:8089[D loss: 0.409842, acc: 70.31%, op_acc: 33.59%] [G loss: 0.978235]\n",
      "epoch:10 step:8090[D loss: 0.441566, acc: 56.25%, op_acc: 35.16%] [G loss: 0.976627]\n",
      "epoch:10 step:8091[D loss: 0.450944, acc: 57.81%, op_acc: 33.59%] [G loss: 0.955188]\n",
      "epoch:10 step:8092[D loss: 0.462650, acc: 54.69%, op_acc: 33.59%] [G loss: 0.913161]\n",
      "epoch:10 step:8093[D loss: 0.429278, acc: 58.59%, op_acc: 37.50%] [G loss: 0.895412]\n",
      "epoch:10 step:8094[D loss: 0.446142, acc: 60.16%, op_acc: 37.50%] [G loss: 0.939009]\n",
      "epoch:10 step:8095[D loss: 0.399327, acc: 69.53%, op_acc: 35.94%] [G loss: 1.007179]\n",
      "epoch:10 step:8096[D loss: 0.416770, acc: 70.31%, op_acc: 31.25%] [G loss: 0.984613]\n",
      "epoch:10 step:8097[D loss: 0.454192, acc: 59.38%, op_acc: 35.94%] [G loss: 0.886984]\n",
      "epoch:10 step:8098[D loss: 0.433344, acc: 55.47%, op_acc: 39.06%] [G loss: 0.969759]\n",
      "epoch:10 step:8099[D loss: 0.444363, acc: 58.59%, op_acc: 32.81%] [G loss: 0.818070]\n",
      "epoch:10 step:8100[D loss: 0.411921, acc: 67.97%, op_acc: 35.16%] [G loss: 0.933325]\n",
      "epoch:10 step:8101[D loss: 0.420047, acc: 60.94%, op_acc: 41.41%] [G loss: 1.006380]\n",
      "epoch:10 step:8102[D loss: 0.429825, acc: 65.62%, op_acc: 36.72%] [G loss: 1.029671]\n",
      "epoch:10 step:8103[D loss: 0.439261, acc: 57.03%, op_acc: 36.72%] [G loss: 0.857239]\n",
      "epoch:10 step:8104[D loss: 0.436101, acc: 60.16%, op_acc: 36.72%] [G loss: 0.886019]\n",
      "epoch:10 step:8105[D loss: 0.446911, acc: 52.34%, op_acc: 37.50%] [G loss: 0.905941]\n",
      "epoch:10 step:8106[D loss: 0.444747, acc: 55.47%, op_acc: 37.50%] [G loss: 0.864041]\n",
      "epoch:10 step:8107[D loss: 0.437738, acc: 63.28%, op_acc: 35.16%] [G loss: 0.940680]\n",
      "epoch:10 step:8108[D loss: 0.462729, acc: 49.22%, op_acc: 34.38%] [G loss: 0.935778]\n",
      "epoch:10 step:8109[D loss: 0.457596, acc: 52.34%, op_acc: 41.41%] [G loss: 0.918762]\n",
      "epoch:10 step:8110[D loss: 0.446655, acc: 54.69%, op_acc: 32.03%] [G loss: 0.966405]\n",
      "epoch:10 step:8111[D loss: 0.465152, acc: 55.47%, op_acc: 32.81%] [G loss: 0.914227]\n",
      "epoch:10 step:8112[D loss: 0.444975, acc: 53.12%, op_acc: 36.72%] [G loss: 0.954831]\n",
      "epoch:10 step:8113[D loss: 0.446659, acc: 57.03%, op_acc: 33.59%] [G loss: 0.918249]\n",
      "epoch:10 step:8114[D loss: 0.431965, acc: 61.72%, op_acc: 34.38%] [G loss: 0.894420]\n",
      "epoch:10 step:8115[D loss: 0.464567, acc: 52.34%, op_acc: 34.38%] [G loss: 0.877887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8116[D loss: 0.440262, acc: 62.50%, op_acc: 34.38%] [G loss: 0.969481]\n",
      "epoch:10 step:8117[D loss: 0.436075, acc: 63.28%, op_acc: 32.81%] [G loss: 0.990347]\n",
      "epoch:10 step:8118[D loss: 0.466638, acc: 52.34%, op_acc: 35.94%] [G loss: 0.846365]\n",
      "epoch:10 step:8119[D loss: 0.471259, acc: 57.81%, op_acc: 30.47%] [G loss: 0.879710]\n",
      "epoch:10 step:8120[D loss: 0.454396, acc: 57.81%, op_acc: 28.91%] [G loss: 0.846746]\n",
      "epoch:10 step:8121[D loss: 0.422537, acc: 61.72%, op_acc: 32.81%] [G loss: 0.951678]\n",
      "epoch:10 step:8122[D loss: 0.460709, acc: 53.91%, op_acc: 35.16%] [G loss: 0.910824]\n",
      "epoch:10 step:8123[D loss: 0.451856, acc: 57.81%, op_acc: 36.72%] [G loss: 0.905070]\n",
      "epoch:10 step:8124[D loss: 0.441250, acc: 59.38%, op_acc: 33.59%] [G loss: 0.930960]\n",
      "epoch:10 step:8125[D loss: 0.471024, acc: 53.91%, op_acc: 32.81%] [G loss: 0.846290]\n",
      "epoch:10 step:8126[D loss: 0.464856, acc: 57.81%, op_acc: 32.03%] [G loss: 0.913278]\n",
      "epoch:10 step:8127[D loss: 0.450708, acc: 56.25%, op_acc: 29.69%] [G loss: 0.918653]\n",
      "epoch:10 step:8128[D loss: 0.468263, acc: 50.78%, op_acc: 31.25%] [G loss: 0.896451]\n",
      "epoch:10 step:8129[D loss: 0.430492, acc: 53.12%, op_acc: 35.16%] [G loss: 0.805387]\n",
      "epoch:10 step:8130[D loss: 0.472808, acc: 51.56%, op_acc: 29.69%] [G loss: 0.881255]\n",
      "epoch:10 step:8131[D loss: 0.469693, acc: 52.34%, op_acc: 35.94%] [G loss: 0.908523]\n",
      "epoch:10 step:8132[D loss: 0.465943, acc: 52.34%, op_acc: 29.69%] [G loss: 0.907555]\n",
      "epoch:10 step:8133[D loss: 0.431755, acc: 64.06%, op_acc: 32.03%] [G loss: 0.892685]\n",
      "epoch:10 step:8134[D loss: 0.439613, acc: 63.28%, op_acc: 33.59%] [G loss: 1.005422]\n",
      "epoch:10 step:8135[D loss: 0.445167, acc: 59.38%, op_acc: 37.50%] [G loss: 0.959150]\n",
      "epoch:10 step:8136[D loss: 0.422284, acc: 61.72%, op_acc: 35.94%] [G loss: 0.832725]\n",
      "epoch:10 step:8137[D loss: 0.431788, acc: 57.03%, op_acc: 34.38%] [G loss: 0.891406]\n",
      "epoch:10 step:8138[D loss: 0.434158, acc: 62.50%, op_acc: 39.06%] [G loss: 0.968511]\n",
      "epoch:10 step:8139[D loss: 0.430665, acc: 64.06%, op_acc: 35.94%] [G loss: 0.996347]\n",
      "epoch:10 step:8140[D loss: 0.421040, acc: 62.50%, op_acc: 37.50%] [G loss: 0.935286]\n",
      "epoch:10 step:8141[D loss: 0.413670, acc: 64.84%, op_acc: 40.62%] [G loss: 0.876497]\n",
      "epoch:10 step:8142[D loss: 0.432343, acc: 60.94%, op_acc: 36.72%] [G loss: 0.972175]\n",
      "epoch:10 step:8143[D loss: 0.442807, acc: 62.50%, op_acc: 35.94%] [G loss: 0.880809]\n",
      "epoch:10 step:8144[D loss: 0.479512, acc: 46.88%, op_acc: 35.94%] [G loss: 0.875128]\n",
      "epoch:10 step:8145[D loss: 0.458686, acc: 57.03%, op_acc: 28.91%] [G loss: 0.861090]\n",
      "epoch:10 step:8146[D loss: 0.443176, acc: 64.06%, op_acc: 32.03%] [G loss: 0.937718]\n",
      "epoch:10 step:8147[D loss: 0.420334, acc: 67.97%, op_acc: 36.72%] [G loss: 0.847749]\n",
      "epoch:10 step:8148[D loss: 0.442520, acc: 58.59%, op_acc: 38.28%] [G loss: 0.822101]\n",
      "epoch:10 step:8149[D loss: 0.436924, acc: 60.16%, op_acc: 34.38%] [G loss: 0.891419]\n",
      "epoch:10 step:8150[D loss: 0.439187, acc: 57.03%, op_acc: 33.59%] [G loss: 0.885777]\n",
      "epoch:10 step:8151[D loss: 0.437332, acc: 60.94%, op_acc: 36.72%] [G loss: 0.774970]\n",
      "epoch:10 step:8152[D loss: 0.468584, acc: 54.69%, op_acc: 30.47%] [G loss: 0.887590]\n",
      "epoch:10 step:8153[D loss: 0.431883, acc: 63.28%, op_acc: 35.94%] [G loss: 0.884483]\n",
      "epoch:10 step:8154[D loss: 0.439995, acc: 56.25%, op_acc: 39.06%] [G loss: 0.956545]\n",
      "epoch:10 step:8155[D loss: 0.437770, acc: 58.59%, op_acc: 32.81%] [G loss: 0.916975]\n",
      "epoch:10 step:8156[D loss: 0.422944, acc: 62.50%, op_acc: 35.16%] [G loss: 0.878405]\n",
      "epoch:10 step:8157[D loss: 0.408399, acc: 63.28%, op_acc: 39.84%] [G loss: 0.900077]\n",
      "epoch:10 step:8158[D loss: 0.396678, acc: 68.75%, op_acc: 41.41%] [G loss: 0.995082]\n",
      "epoch:10 step:8159[D loss: 0.430070, acc: 63.28%, op_acc: 34.38%] [G loss: 0.936668]\n",
      "epoch:10 step:8160[D loss: 0.449322, acc: 56.25%, op_acc: 36.72%] [G loss: 0.827044]\n",
      "epoch:10 step:8161[D loss: 0.456302, acc: 54.69%, op_acc: 35.94%] [G loss: 0.828613]\n",
      "epoch:10 step:8162[D loss: 0.431456, acc: 66.41%, op_acc: 35.16%] [G loss: 0.938145]\n",
      "epoch:10 step:8163[D loss: 0.408409, acc: 58.59%, op_acc: 41.41%] [G loss: 0.953953]\n",
      "epoch:10 step:8164[D loss: 0.400956, acc: 69.53%, op_acc: 42.19%] [G loss: 0.936018]\n",
      "epoch:10 step:8165[D loss: 0.431110, acc: 57.81%, op_acc: 41.41%] [G loss: 0.853426]\n",
      "epoch:10 step:8166[D loss: 0.417987, acc: 63.28%, op_acc: 35.16%] [G loss: 0.932796]\n",
      "epoch:10 step:8167[D loss: 0.452681, acc: 57.03%, op_acc: 30.47%] [G loss: 0.965914]\n",
      "epoch:10 step:8168[D loss: 0.438588, acc: 64.84%, op_acc: 35.94%] [G loss: 0.994137]\n",
      "epoch:10 step:8169[D loss: 0.405452, acc: 63.28%, op_acc: 39.06%] [G loss: 0.943055]\n",
      "epoch:10 step:8170[D loss: 0.471208, acc: 53.91%, op_acc: 35.94%] [G loss: 0.941968]\n",
      "epoch:10 step:8171[D loss: 0.424341, acc: 65.62%, op_acc: 38.28%] [G loss: 0.928644]\n",
      "epoch:10 step:8172[D loss: 0.409436, acc: 58.59%, op_acc: 35.94%] [G loss: 0.967479]\n",
      "epoch:10 step:8173[D loss: 0.421002, acc: 60.16%, op_acc: 37.50%] [G loss: 0.890663]\n",
      "epoch:10 step:8174[D loss: 0.449587, acc: 54.69%, op_acc: 35.94%] [G loss: 0.845980]\n",
      "epoch:10 step:8175[D loss: 0.395230, acc: 67.19%, op_acc: 39.84%] [G loss: 0.881075]\n",
      "epoch:10 step:8176[D loss: 0.434412, acc: 57.03%, op_acc: 37.50%] [G loss: 0.914027]\n",
      "epoch:10 step:8177[D loss: 0.449595, acc: 61.72%, op_acc: 34.38%] [G loss: 0.906875]\n",
      "epoch:10 step:8178[D loss: 0.415822, acc: 67.19%, op_acc: 30.47%] [G loss: 0.926157]\n",
      "epoch:10 step:8179[D loss: 0.419843, acc: 57.81%, op_acc: 39.06%] [G loss: 0.856673]\n",
      "epoch:10 step:8180[D loss: 0.431541, acc: 62.50%, op_acc: 37.50%] [G loss: 0.835526]\n",
      "epoch:10 step:8181[D loss: 0.395769, acc: 60.94%, op_acc: 49.22%] [G loss: 0.952605]\n",
      "epoch:10 step:8182[D loss: 0.448999, acc: 60.16%, op_acc: 40.62%] [G loss: 0.954222]\n",
      "epoch:10 step:8183[D loss: 0.403370, acc: 61.72%, op_acc: 39.84%] [G loss: 0.869235]\n",
      "epoch:10 step:8184[D loss: 0.438279, acc: 55.47%, op_acc: 34.38%] [G loss: 0.899773]\n",
      "epoch:10 step:8185[D loss: 0.439703, acc: 57.81%, op_acc: 35.94%] [G loss: 0.912025]\n",
      "epoch:10 step:8186[D loss: 0.432709, acc: 61.72%, op_acc: 35.16%] [G loss: 0.884821]\n",
      "epoch:10 step:8187[D loss: 0.433893, acc: 62.50%, op_acc: 35.94%] [G loss: 0.986578]\n",
      "epoch:10 step:8188[D loss: 0.438216, acc: 57.03%, op_acc: 38.28%] [G loss: 0.941672]\n",
      "epoch:10 step:8189[D loss: 0.416757, acc: 55.47%, op_acc: 39.06%] [G loss: 0.915063]\n",
      "epoch:10 step:8190[D loss: 0.422567, acc: 63.28%, op_acc: 38.28%] [G loss: 0.940304]\n",
      "epoch:10 step:8191[D loss: 0.423347, acc: 64.06%, op_acc: 38.28%] [G loss: 0.992211]\n",
      "epoch:10 step:8192[D loss: 0.449452, acc: 54.69%, op_acc: 33.59%] [G loss: 0.854411]\n",
      "epoch:10 step:8193[D loss: 0.438988, acc: 57.03%, op_acc: 35.94%] [G loss: 0.987941]\n",
      "epoch:10 step:8194[D loss: 0.430857, acc: 63.28%, op_acc: 34.38%] [G loss: 0.928330]\n",
      "epoch:10 step:8195[D loss: 0.409180, acc: 64.06%, op_acc: 40.62%] [G loss: 0.906574]\n",
      "epoch:10 step:8196[D loss: 0.427318, acc: 57.81%, op_acc: 39.06%] [G loss: 0.955285]\n",
      "epoch:10 step:8197[D loss: 0.436806, acc: 60.16%, op_acc: 35.16%] [G loss: 0.918969]\n",
      "epoch:10 step:8198[D loss: 0.447009, acc: 59.38%, op_acc: 31.25%] [G loss: 0.903186]\n",
      "epoch:10 step:8199[D loss: 0.461939, acc: 54.69%, op_acc: 28.12%] [G loss: 0.940361]\n",
      "epoch:10 step:8200[D loss: 0.424951, acc: 63.28%, op_acc: 39.06%] [G loss: 0.933300]\n",
      "epoch:10 step:8201[D loss: 0.420321, acc: 64.06%, op_acc: 38.28%] [G loss: 0.872364]\n",
      "epoch:10 step:8202[D loss: 0.403208, acc: 57.03%, op_acc: 38.28%] [G loss: 0.882700]\n",
      "epoch:10 step:8203[D loss: 0.431169, acc: 64.06%, op_acc: 35.16%] [G loss: 0.961179]\n",
      "epoch:10 step:8204[D loss: 0.437679, acc: 60.94%, op_acc: 33.59%] [G loss: 0.935455]\n",
      "epoch:10 step:8205[D loss: 0.475056, acc: 50.00%, op_acc: 32.03%] [G loss: 0.935166]\n",
      "epoch:10 step:8206[D loss: 0.419460, acc: 60.94%, op_acc: 34.38%] [G loss: 0.885821]\n",
      "epoch:10 step:8207[D loss: 0.460475, acc: 52.34%, op_acc: 38.28%] [G loss: 0.850067]\n",
      "epoch:10 step:8208[D loss: 0.462450, acc: 62.50%, op_acc: 33.59%] [G loss: 0.868903]\n",
      "epoch:10 step:8209[D loss: 0.422563, acc: 59.38%, op_acc: 36.72%] [G loss: 0.938364]\n",
      "epoch:10 step:8210[D loss: 0.437228, acc: 57.81%, op_acc: 36.72%] [G loss: 0.868489]\n",
      "epoch:10 step:8211[D loss: 0.443571, acc: 53.91%, op_acc: 39.84%] [G loss: 0.862698]\n",
      "epoch:10 step:8212[D loss: 0.438167, acc: 60.94%, op_acc: 28.91%] [G loss: 0.955086]\n",
      "epoch:10 step:8213[D loss: 0.430613, acc: 71.09%, op_acc: 30.47%] [G loss: 0.921745]\n",
      "epoch:10 step:8214[D loss: 0.380379, acc: 71.09%, op_acc: 45.31%] [G loss: 0.952819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8215[D loss: 0.442355, acc: 60.94%, op_acc: 36.72%] [G loss: 0.938796]\n",
      "epoch:10 step:8216[D loss: 0.424748, acc: 63.28%, op_acc: 33.59%] [G loss: 0.917259]\n",
      "epoch:10 step:8217[D loss: 0.451996, acc: 57.03%, op_acc: 30.47%] [G loss: 0.942871]\n",
      "epoch:10 step:8218[D loss: 0.417898, acc: 63.28%, op_acc: 38.28%] [G loss: 0.947566]\n",
      "epoch:10 step:8219[D loss: 0.433197, acc: 60.16%, op_acc: 40.62%] [G loss: 0.906958]\n",
      "epoch:10 step:8220[D loss: 0.423016, acc: 61.72%, op_acc: 37.50%] [G loss: 0.872964]\n",
      "epoch:10 step:8221[D loss: 0.447663, acc: 59.38%, op_acc: 37.50%] [G loss: 0.869576]\n",
      "epoch:10 step:8222[D loss: 0.433926, acc: 59.38%, op_acc: 35.16%] [G loss: 0.856804]\n",
      "epoch:10 step:8223[D loss: 0.426750, acc: 57.03%, op_acc: 33.59%] [G loss: 0.984772]\n",
      "epoch:10 step:8224[D loss: 0.433622, acc: 56.25%, op_acc: 37.50%] [G loss: 0.923214]\n",
      "epoch:10 step:8225[D loss: 0.424421, acc: 57.81%, op_acc: 38.28%] [G loss: 0.823346]\n",
      "epoch:10 step:8226[D loss: 0.421732, acc: 62.50%, op_acc: 36.72%] [G loss: 0.880242]\n",
      "epoch:10 step:8227[D loss: 0.454551, acc: 57.81%, op_acc: 36.72%] [G loss: 0.867869]\n",
      "epoch:10 step:8228[D loss: 0.446915, acc: 53.91%, op_acc: 35.16%] [G loss: 0.831729]\n",
      "epoch:10 step:8229[D loss: 0.456140, acc: 56.25%, op_acc: 28.91%] [G loss: 0.910693]\n",
      "epoch:10 step:8230[D loss: 0.439615, acc: 60.94%, op_acc: 39.06%] [G loss: 0.957727]\n",
      "epoch:10 step:8231[D loss: 0.465740, acc: 56.25%, op_acc: 34.38%] [G loss: 0.938508]\n",
      "epoch:10 step:8232[D loss: 0.411753, acc: 68.75%, op_acc: 37.50%] [G loss: 0.815634]\n",
      "epoch:10 step:8233[D loss: 0.453798, acc: 62.50%, op_acc: 32.03%] [G loss: 0.833834]\n",
      "epoch:10 step:8234[D loss: 0.475989, acc: 57.81%, op_acc: 37.50%] [G loss: 0.854540]\n",
      "epoch:10 step:8235[D loss: 0.445179, acc: 59.38%, op_acc: 34.38%] [G loss: 0.871582]\n",
      "epoch:10 step:8236[D loss: 0.441427, acc: 60.94%, op_acc: 35.94%] [G loss: 0.864469]\n",
      "epoch:10 step:8237[D loss: 0.431278, acc: 64.06%, op_acc: 37.50%] [G loss: 0.964267]\n",
      "epoch:10 step:8238[D loss: 0.461942, acc: 46.88%, op_acc: 33.59%] [G loss: 0.946769]\n",
      "epoch:10 step:8239[D loss: 0.437720, acc: 59.38%, op_acc: 37.50%] [G loss: 0.983184]\n",
      "epoch:10 step:8240[D loss: 0.463855, acc: 54.69%, op_acc: 40.62%] [G loss: 0.899390]\n",
      "epoch:10 step:8241[D loss: 0.468918, acc: 56.25%, op_acc: 36.72%] [G loss: 0.913186]\n",
      "epoch:10 step:8242[D loss: 0.411112, acc: 59.38%, op_acc: 42.19%] [G loss: 0.893027]\n",
      "epoch:10 step:8243[D loss: 0.440725, acc: 62.50%, op_acc: 30.47%] [G loss: 0.890451]\n",
      "epoch:10 step:8244[D loss: 0.460209, acc: 53.12%, op_acc: 37.50%] [G loss: 0.869882]\n",
      "epoch:10 step:8245[D loss: 0.456887, acc: 50.78%, op_acc: 42.19%] [G loss: 0.859879]\n",
      "epoch:10 step:8246[D loss: 0.456232, acc: 56.25%, op_acc: 29.69%] [G loss: 0.885677]\n",
      "epoch:10 step:8247[D loss: 0.450457, acc: 60.16%, op_acc: 40.62%] [G loss: 0.848938]\n",
      "epoch:10 step:8248[D loss: 0.447342, acc: 57.03%, op_acc: 33.59%] [G loss: 0.845683]\n",
      "epoch:10 step:8249[D loss: 0.428120, acc: 59.38%, op_acc: 35.16%] [G loss: 0.830776]\n",
      "epoch:10 step:8250[D loss: 0.443075, acc: 60.94%, op_acc: 38.28%] [G loss: 0.912579]\n",
      "epoch:10 step:8251[D loss: 0.424957, acc: 69.53%, op_acc: 39.06%] [G loss: 0.902365]\n",
      "epoch:10 step:8252[D loss: 0.414218, acc: 64.84%, op_acc: 44.53%] [G loss: 0.851073]\n",
      "epoch:10 step:8253[D loss: 0.439543, acc: 62.50%, op_acc: 36.72%] [G loss: 0.862649]\n",
      "epoch:10 step:8254[D loss: 0.422349, acc: 63.28%, op_acc: 39.84%] [G loss: 0.936613]\n",
      "epoch:10 step:8255[D loss: 0.454221, acc: 61.72%, op_acc: 32.03%] [G loss: 0.920959]\n",
      "epoch:10 step:8256[D loss: 0.444326, acc: 60.94%, op_acc: 32.81%] [G loss: 0.891928]\n",
      "epoch:10 step:8257[D loss: 0.437997, acc: 67.19%, op_acc: 29.69%] [G loss: 0.865380]\n",
      "epoch:10 step:8258[D loss: 0.444299, acc: 55.47%, op_acc: 33.59%] [G loss: 0.899756]\n",
      "epoch:10 step:8259[D loss: 0.386584, acc: 73.44%, op_acc: 40.62%] [G loss: 0.968142]\n",
      "epoch:10 step:8260[D loss: 0.486665, acc: 50.78%, op_acc: 24.22%] [G loss: 0.870263]\n",
      "epoch:10 step:8261[D loss: 0.474607, acc: 50.78%, op_acc: 34.38%] [G loss: 0.800330]\n",
      "epoch:10 step:8262[D loss: 0.441099, acc: 61.72%, op_acc: 35.16%] [G loss: 0.917427]\n",
      "epoch:10 step:8263[D loss: 0.428954, acc: 57.03%, op_acc: 39.06%] [G loss: 0.962115]\n",
      "epoch:10 step:8264[D loss: 0.444686, acc: 60.16%, op_acc: 31.25%] [G loss: 0.952431]\n",
      "epoch:10 step:8265[D loss: 0.493135, acc: 49.22%, op_acc: 35.16%] [G loss: 0.869206]\n",
      "epoch:10 step:8266[D loss: 0.456799, acc: 54.69%, op_acc: 33.59%] [G loss: 0.973075]\n",
      "epoch:10 step:8267[D loss: 0.443516, acc: 60.16%, op_acc: 32.03%] [G loss: 0.858324]\n",
      "epoch:10 step:8268[D loss: 0.419507, acc: 64.06%, op_acc: 35.94%] [G loss: 0.887200]\n",
      "epoch:10 step:8269[D loss: 0.427356, acc: 58.59%, op_acc: 40.62%] [G loss: 0.937909]\n",
      "epoch:10 step:8270[D loss: 0.414162, acc: 64.06%, op_acc: 36.72%] [G loss: 0.818965]\n",
      "epoch:10 step:8271[D loss: 0.444260, acc: 58.59%, op_acc: 31.25%] [G loss: 0.935664]\n",
      "epoch:10 step:8272[D loss: 0.433084, acc: 61.72%, op_acc: 36.72%] [G loss: 0.934170]\n",
      "epoch:10 step:8273[D loss: 0.432959, acc: 60.16%, op_acc: 35.16%] [G loss: 0.820197]\n",
      "epoch:10 step:8274[D loss: 0.412005, acc: 65.62%, op_acc: 41.41%] [G loss: 0.883007]\n",
      "epoch:10 step:8275[D loss: 0.406148, acc: 70.31%, op_acc: 35.16%] [G loss: 0.931179]\n",
      "epoch:10 step:8276[D loss: 0.426561, acc: 60.94%, op_acc: 38.28%] [G loss: 0.980712]\n",
      "epoch:10 step:8277[D loss: 0.415192, acc: 62.50%, op_acc: 38.28%] [G loss: 0.839908]\n",
      "epoch:10 step:8278[D loss: 0.431284, acc: 58.59%, op_acc: 36.72%] [G loss: 0.814056]\n",
      "epoch:10 step:8279[D loss: 0.422474, acc: 60.94%, op_acc: 36.72%] [G loss: 0.886221]\n",
      "epoch:10 step:8280[D loss: 0.420248, acc: 60.16%, op_acc: 38.28%] [G loss: 0.849772]\n",
      "epoch:10 step:8281[D loss: 0.426456, acc: 68.75%, op_acc: 33.59%] [G loss: 0.867951]\n",
      "epoch:10 step:8282[D loss: 0.477255, acc: 53.12%, op_acc: 28.91%] [G loss: 0.933320]\n",
      "epoch:10 step:8283[D loss: 0.417277, acc: 62.50%, op_acc: 42.19%] [G loss: 0.966342]\n",
      "epoch:10 step:8284[D loss: 0.446820, acc: 58.59%, op_acc: 33.59%] [G loss: 0.935402]\n",
      "epoch:10 step:8285[D loss: 0.427747, acc: 56.25%, op_acc: 39.84%] [G loss: 0.973337]\n",
      "epoch:10 step:8286[D loss: 0.501013, acc: 49.22%, op_acc: 28.12%] [G loss: 0.892596]\n",
      "epoch:10 step:8287[D loss: 0.413579, acc: 64.06%, op_acc: 38.28%] [G loss: 0.901226]\n",
      "epoch:10 step:8288[D loss: 0.428967, acc: 59.38%, op_acc: 39.84%] [G loss: 0.870800]\n",
      "epoch:10 step:8289[D loss: 0.436297, acc: 57.03%, op_acc: 36.72%] [G loss: 0.938017]\n",
      "epoch:10 step:8290[D loss: 0.467991, acc: 50.78%, op_acc: 32.81%] [G loss: 0.948491]\n",
      "epoch:10 step:8291[D loss: 0.450251, acc: 61.72%, op_acc: 32.03%] [G loss: 0.940625]\n",
      "epoch:10 step:8292[D loss: 0.441610, acc: 62.50%, op_acc: 33.59%] [G loss: 0.901081]\n",
      "epoch:10 step:8293[D loss: 0.440557, acc: 64.06%, op_acc: 35.16%] [G loss: 0.898530]\n",
      "epoch:10 step:8294[D loss: 0.422770, acc: 60.94%, op_acc: 39.06%] [G loss: 0.977317]\n",
      "epoch:10 step:8295[D loss: 0.431323, acc: 55.47%, op_acc: 38.28%] [G loss: 0.826494]\n",
      "epoch:10 step:8296[D loss: 0.432704, acc: 59.38%, op_acc: 36.72%] [G loss: 0.943660]\n",
      "epoch:10 step:8297[D loss: 0.460878, acc: 57.03%, op_acc: 32.81%] [G loss: 0.887111]\n",
      "epoch:10 step:8298[D loss: 0.408720, acc: 67.97%, op_acc: 35.94%] [G loss: 0.937533]\n",
      "epoch:10 step:8299[D loss: 0.450725, acc: 53.91%, op_acc: 40.62%] [G loss: 0.903382]\n",
      "epoch:10 step:8300[D loss: 0.414439, acc: 65.62%, op_acc: 39.06%] [G loss: 0.944276]\n",
      "epoch:10 step:8301[D loss: 0.477021, acc: 62.50%, op_acc: 30.47%] [G loss: 0.919473]\n",
      "epoch:10 step:8302[D loss: 0.420390, acc: 61.72%, op_acc: 39.06%] [G loss: 0.978175]\n",
      "epoch:10 step:8303[D loss: 0.453756, acc: 51.56%, op_acc: 32.81%] [G loss: 0.927771]\n",
      "epoch:10 step:8304[D loss: 0.411365, acc: 67.19%, op_acc: 39.84%] [G loss: 0.903320]\n",
      "epoch:10 step:8305[D loss: 0.455137, acc: 57.03%, op_acc: 32.81%] [G loss: 0.959665]\n",
      "epoch:10 step:8306[D loss: 0.413550, acc: 64.06%, op_acc: 40.62%] [G loss: 0.972802]\n",
      "epoch:10 step:8307[D loss: 0.413846, acc: 63.28%, op_acc: 38.28%] [G loss: 0.942140]\n",
      "epoch:10 step:8308[D loss: 0.471865, acc: 51.56%, op_acc: 30.47%] [G loss: 0.916371]\n",
      "epoch:10 step:8309[D loss: 0.431532, acc: 68.75%, op_acc: 33.59%] [G loss: 0.967730]\n",
      "epoch:10 step:8310[D loss: 0.453824, acc: 52.34%, op_acc: 35.16%] [G loss: 0.874083]\n",
      "epoch:10 step:8311[D loss: 0.450483, acc: 60.16%, op_acc: 32.81%] [G loss: 0.877689]\n",
      "epoch:10 step:8312[D loss: 0.415626, acc: 62.50%, op_acc: 35.16%] [G loss: 0.958995]\n",
      "epoch:10 step:8313[D loss: 0.405567, acc: 67.19%, op_acc: 35.16%] [G loss: 0.955110]\n",
      "epoch:10 step:8314[D loss: 0.444193, acc: 60.94%, op_acc: 35.94%] [G loss: 0.929130]\n",
      "epoch:10 step:8315[D loss: 0.447189, acc: 56.25%, op_acc: 34.38%] [G loss: 0.873972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8316[D loss: 0.454130, acc: 60.16%, op_acc: 35.16%] [G loss: 0.947179]\n",
      "epoch:10 step:8317[D loss: 0.459171, acc: 55.47%, op_acc: 35.16%] [G loss: 0.934546]\n",
      "epoch:10 step:8318[D loss: 0.420267, acc: 67.97%, op_acc: 34.38%] [G loss: 0.876821]\n",
      "epoch:10 step:8319[D loss: 0.454005, acc: 58.59%, op_acc: 33.59%] [G loss: 0.833516]\n",
      "epoch:10 step:8320[D loss: 0.433514, acc: 55.47%, op_acc: 37.50%] [G loss: 0.871066]\n",
      "epoch:10 step:8321[D loss: 0.418162, acc: 60.16%, op_acc: 35.94%] [G loss: 0.950182]\n",
      "epoch:10 step:8322[D loss: 0.473080, acc: 53.12%, op_acc: 32.81%] [G loss: 0.837270]\n",
      "epoch:10 step:8323[D loss: 0.467097, acc: 55.47%, op_acc: 29.69%] [G loss: 0.841912]\n",
      "epoch:10 step:8324[D loss: 0.431331, acc: 64.06%, op_acc: 31.25%] [G loss: 0.860655]\n",
      "epoch:10 step:8325[D loss: 0.445172, acc: 57.03%, op_acc: 32.03%] [G loss: 0.910814]\n",
      "epoch:10 step:8326[D loss: 0.433357, acc: 60.16%, op_acc: 30.47%] [G loss: 0.905482]\n",
      "epoch:10 step:8327[D loss: 0.446719, acc: 67.19%, op_acc: 30.47%] [G loss: 0.922093]\n",
      "epoch:10 step:8328[D loss: 0.430050, acc: 61.72%, op_acc: 31.25%] [G loss: 0.958559]\n",
      "epoch:10 step:8329[D loss: 0.417462, acc: 60.94%, op_acc: 39.06%] [G loss: 0.870010]\n",
      "epoch:10 step:8330[D loss: 0.428422, acc: 66.41%, op_acc: 28.12%] [G loss: 1.024647]\n",
      "epoch:10 step:8331[D loss: 0.450064, acc: 60.16%, op_acc: 35.16%] [G loss: 0.819461]\n",
      "epoch:10 step:8332[D loss: 0.456351, acc: 53.91%, op_acc: 33.59%] [G loss: 0.918087]\n",
      "epoch:10 step:8333[D loss: 0.439827, acc: 60.16%, op_acc: 35.94%] [G loss: 0.881919]\n",
      "epoch:10 step:8334[D loss: 0.438437, acc: 60.16%, op_acc: 42.19%] [G loss: 0.920830]\n",
      "epoch:10 step:8335[D loss: 0.398750, acc: 71.09%, op_acc: 32.81%] [G loss: 0.943235]\n",
      "epoch:10 step:8336[D loss: 0.459234, acc: 57.81%, op_acc: 33.59%] [G loss: 0.914890]\n",
      "epoch:10 step:8337[D loss: 0.436925, acc: 57.81%, op_acc: 37.50%] [G loss: 0.875474]\n",
      "epoch:10 step:8338[D loss: 0.461346, acc: 53.91%, op_acc: 34.38%] [G loss: 0.873416]\n",
      "epoch:10 step:8339[D loss: 0.431877, acc: 60.94%, op_acc: 33.59%] [G loss: 0.869841]\n",
      "epoch:10 step:8340[D loss: 0.444649, acc: 59.38%, op_acc: 34.38%] [G loss: 0.955247]\n",
      "epoch:10 step:8341[D loss: 0.445701, acc: 60.94%, op_acc: 35.94%] [G loss: 0.963227]\n",
      "epoch:10 step:8342[D loss: 0.443279, acc: 60.16%, op_acc: 34.38%] [G loss: 0.906861]\n",
      "epoch:10 step:8343[D loss: 0.456575, acc: 56.25%, op_acc: 37.50%] [G loss: 0.933250]\n",
      "epoch:10 step:8344[D loss: 0.424657, acc: 59.38%, op_acc: 39.06%] [G loss: 0.873709]\n",
      "epoch:10 step:8345[D loss: 0.416443, acc: 59.38%, op_acc: 32.81%] [G loss: 0.907490]\n",
      "epoch:10 step:8346[D loss: 0.406175, acc: 61.72%, op_acc: 42.19%] [G loss: 0.986354]\n",
      "epoch:10 step:8347[D loss: 0.463501, acc: 63.28%, op_acc: 31.25%] [G loss: 0.915705]\n",
      "epoch:10 step:8348[D loss: 0.422708, acc: 59.38%, op_acc: 39.84%] [G loss: 0.891367]\n",
      "epoch:10 step:8349[D loss: 0.457666, acc: 51.56%, op_acc: 33.59%] [G loss: 0.943950]\n",
      "epoch:10 step:8350[D loss: 0.424606, acc: 63.28%, op_acc: 39.84%] [G loss: 0.902297]\n",
      "epoch:10 step:8351[D loss: 0.371494, acc: 75.78%, op_acc: 39.06%] [G loss: 0.953353]\n",
      "epoch:10 step:8352[D loss: 0.434431, acc: 60.16%, op_acc: 36.72%] [G loss: 0.871498]\n",
      "epoch:10 step:8353[D loss: 0.442449, acc: 61.72%, op_acc: 32.81%] [G loss: 0.925586]\n",
      "epoch:10 step:8354[D loss: 0.440265, acc: 53.91%, op_acc: 39.06%] [G loss: 0.925217]\n",
      "epoch:10 step:8355[D loss: 0.392256, acc: 69.53%, op_acc: 35.94%] [G loss: 0.972906]\n",
      "epoch:10 step:8356[D loss: 0.491336, acc: 39.84%, op_acc: 36.72%] [G loss: 0.927469]\n",
      "epoch:10 step:8357[D loss: 0.431970, acc: 63.28%, op_acc: 32.81%] [G loss: 0.907047]\n",
      "epoch:10 step:8358[D loss: 0.451171, acc: 57.81%, op_acc: 32.81%] [G loss: 0.938639]\n",
      "epoch:10 step:8359[D loss: 0.422210, acc: 63.28%, op_acc: 40.62%] [G loss: 0.939136]\n",
      "epoch:10 step:8360[D loss: 0.440026, acc: 59.38%, op_acc: 32.81%] [G loss: 0.881168]\n",
      "epoch:10 step:8361[D loss: 0.408170, acc: 66.41%, op_acc: 39.84%] [G loss: 0.921808]\n",
      "epoch:10 step:8362[D loss: 0.443568, acc: 53.91%, op_acc: 30.47%] [G loss: 0.884577]\n",
      "epoch:10 step:8363[D loss: 0.409949, acc: 63.28%, op_acc: 40.62%] [G loss: 0.928872]\n",
      "epoch:10 step:8364[D loss: 0.422489, acc: 61.72%, op_acc: 36.72%] [G loss: 0.897093]\n",
      "epoch:10 step:8365[D loss: 0.408602, acc: 61.72%, op_acc: 40.62%] [G loss: 0.934346]\n",
      "epoch:10 step:8366[D loss: 0.430719, acc: 60.16%, op_acc: 32.03%] [G loss: 0.999940]\n",
      "epoch:10 step:8367[D loss: 0.425392, acc: 74.22%, op_acc: 26.56%] [G loss: 0.942854]\n",
      "epoch:10 step:8368[D loss: 0.415125, acc: 67.19%, op_acc: 39.06%] [G loss: 0.941941]\n",
      "epoch:10 step:8369[D loss: 0.421657, acc: 59.38%, op_acc: 35.94%] [G loss: 0.921936]\n",
      "epoch:10 step:8370[D loss: 0.421289, acc: 66.41%, op_acc: 33.59%] [G loss: 0.910715]\n",
      "epoch:10 step:8371[D loss: 0.432261, acc: 50.78%, op_acc: 40.62%] [G loss: 0.846500]\n",
      "epoch:10 step:8372[D loss: 0.448252, acc: 56.25%, op_acc: 34.38%] [G loss: 0.842005]\n",
      "epoch:10 step:8373[D loss: 0.451726, acc: 59.38%, op_acc: 33.59%] [G loss: 0.838116]\n",
      "epoch:10 step:8374[D loss: 0.452684, acc: 52.34%, op_acc: 33.59%] [G loss: 0.913507]\n",
      "epoch:10 step:8375[D loss: 0.431374, acc: 64.84%, op_acc: 37.50%] [G loss: 1.012336]\n",
      "epoch:10 step:8376[D loss: 0.468046, acc: 57.81%, op_acc: 34.38%] [G loss: 0.944048]\n",
      "epoch:10 step:8377[D loss: 0.421427, acc: 63.28%, op_acc: 38.28%] [G loss: 0.873078]\n",
      "epoch:10 step:8378[D loss: 0.447215, acc: 60.94%, op_acc: 30.47%] [G loss: 0.870460]\n",
      "epoch:10 step:8379[D loss: 0.424083, acc: 60.16%, op_acc: 38.28%] [G loss: 0.879180]\n",
      "epoch:10 step:8380[D loss: 0.438621, acc: 57.81%, op_acc: 35.94%] [G loss: 0.869929]\n",
      "epoch:10 step:8381[D loss: 0.454385, acc: 50.78%, op_acc: 43.75%] [G loss: 0.908310]\n",
      "epoch:10 step:8382[D loss: 0.442175, acc: 60.16%, op_acc: 34.38%] [G loss: 0.886662]\n",
      "epoch:10 step:8383[D loss: 0.435435, acc: 55.47%, op_acc: 37.50%] [G loss: 0.967538]\n",
      "epoch:10 step:8384[D loss: 0.457674, acc: 60.16%, op_acc: 33.59%] [G loss: 0.964292]\n",
      "epoch:10 step:8385[D loss: 0.449319, acc: 56.25%, op_acc: 35.16%] [G loss: 0.849124]\n",
      "epoch:10 step:8386[D loss: 0.456371, acc: 50.00%, op_acc: 37.50%] [G loss: 0.780668]\n",
      "epoch:10 step:8387[D loss: 0.437409, acc: 65.62%, op_acc: 35.94%] [G loss: 0.954189]\n",
      "epoch:10 step:8388[D loss: 0.463443, acc: 63.28%, op_acc: 31.25%] [G loss: 0.901589]\n",
      "epoch:10 step:8389[D loss: 0.403353, acc: 67.97%, op_acc: 42.19%] [G loss: 0.885226]\n",
      "epoch:10 step:8390[D loss: 0.439619, acc: 66.41%, op_acc: 31.25%] [G loss: 0.936572]\n",
      "epoch:10 step:8391[D loss: 0.431057, acc: 64.06%, op_acc: 35.16%] [G loss: 0.908844]\n",
      "epoch:10 step:8392[D loss: 0.447869, acc: 57.03%, op_acc: 35.16%] [G loss: 0.902605]\n",
      "epoch:10 step:8393[D loss: 0.444117, acc: 57.03%, op_acc: 35.16%] [G loss: 0.956270]\n",
      "epoch:10 step:8394[D loss: 0.451053, acc: 64.06%, op_acc: 30.47%] [G loss: 0.904806]\n",
      "epoch:10 step:8395[D loss: 0.431785, acc: 55.47%, op_acc: 36.72%] [G loss: 0.941935]\n",
      "epoch:10 step:8396[D loss: 0.447610, acc: 59.38%, op_acc: 32.03%] [G loss: 0.940776]\n",
      "epoch:10 step:8397[D loss: 0.447097, acc: 60.94%, op_acc: 29.69%] [G loss: 0.994626]\n",
      "epoch:10 step:8398[D loss: 0.447871, acc: 57.81%, op_acc: 37.50%] [G loss: 0.968712]\n",
      "epoch:10 step:8399[D loss: 0.452582, acc: 62.50%, op_acc: 32.81%] [G loss: 0.962436]\n",
      "epoch:10 step:8400[D loss: 0.432724, acc: 60.16%, op_acc: 39.06%] [G loss: 0.976714]\n",
      "epoch:10 step:8401[D loss: 0.446576, acc: 60.16%, op_acc: 35.16%] [G loss: 0.858190]\n",
      "epoch:10 step:8402[D loss: 0.458735, acc: 59.38%, op_acc: 32.81%] [G loss: 0.921326]\n",
      "epoch:10 step:8403[D loss: 0.429041, acc: 64.06%, op_acc: 32.03%] [G loss: 0.967971]\n",
      "epoch:10 step:8404[D loss: 0.448780, acc: 53.12%, op_acc: 39.06%] [G loss: 0.888720]\n",
      "epoch:10 step:8405[D loss: 0.458623, acc: 55.47%, op_acc: 31.25%] [G loss: 0.949965]\n",
      "epoch:10 step:8406[D loss: 0.440313, acc: 63.28%, op_acc: 33.59%] [G loss: 0.834686]\n",
      "epoch:10 step:8407[D loss: 0.427782, acc: 65.62%, op_acc: 35.94%] [G loss: 0.926777]\n",
      "epoch:10 step:8408[D loss: 0.451259, acc: 59.38%, op_acc: 32.03%] [G loss: 0.950831]\n",
      "epoch:10 step:8409[D loss: 0.443805, acc: 57.81%, op_acc: 35.16%] [G loss: 0.933330]\n",
      "epoch:10 step:8410[D loss: 0.429252, acc: 62.50%, op_acc: 30.47%] [G loss: 0.947705]\n",
      "epoch:10 step:8411[D loss: 0.466222, acc: 53.91%, op_acc: 38.28%] [G loss: 0.975666]\n",
      "epoch:10 step:8412[D loss: 0.410266, acc: 60.94%, op_acc: 42.97%] [G loss: 0.917086]\n",
      "epoch:10 step:8413[D loss: 0.379705, acc: 64.84%, op_acc: 45.31%] [G loss: 0.944906]\n",
      "epoch:10 step:8414[D loss: 0.479169, acc: 53.12%, op_acc: 29.69%] [G loss: 0.898962]\n",
      "epoch:10 step:8415[D loss: 0.442347, acc: 64.06%, op_acc: 31.25%] [G loss: 0.916536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8416[D loss: 0.429446, acc: 57.81%, op_acc: 36.72%] [G loss: 0.898102]\n",
      "epoch:10 step:8417[D loss: 0.448411, acc: 48.44%, op_acc: 35.94%] [G loss: 0.887979]\n",
      "epoch:10 step:8418[D loss: 0.398253, acc: 61.72%, op_acc: 41.41%] [G loss: 0.987983]\n",
      "epoch:10 step:8419[D loss: 0.448803, acc: 60.16%, op_acc: 33.59%] [G loss: 0.934458]\n",
      "epoch:10 step:8420[D loss: 0.452152, acc: 57.81%, op_acc: 31.25%] [G loss: 0.925215]\n",
      "epoch:10 step:8421[D loss: 0.440485, acc: 63.28%, op_acc: 38.28%] [G loss: 0.914502]\n",
      "epoch:10 step:8422[D loss: 0.432122, acc: 60.94%, op_acc: 37.50%] [G loss: 0.840496]\n",
      "epoch:10 step:8423[D loss: 0.466090, acc: 51.56%, op_acc: 32.81%] [G loss: 0.956746]\n",
      "epoch:10 step:8424[D loss: 0.454639, acc: 53.91%, op_acc: 33.59%] [G loss: 0.890122]\n",
      "epoch:10 step:8425[D loss: 0.452304, acc: 57.81%, op_acc: 33.59%] [G loss: 0.937877]\n",
      "epoch:10 step:8426[D loss: 0.434601, acc: 60.16%, op_acc: 34.38%] [G loss: 0.921686]\n",
      "epoch:10 step:8427[D loss: 0.468885, acc: 48.44%, op_acc: 36.72%] [G loss: 0.863267]\n",
      "epoch:10 step:8428[D loss: 0.408573, acc: 65.62%, op_acc: 39.06%] [G loss: 0.860065]\n",
      "epoch:10 step:8429[D loss: 0.464309, acc: 54.69%, op_acc: 30.47%] [G loss: 0.844853]\n",
      "epoch:10 step:8430[D loss: 0.454728, acc: 55.47%, op_acc: 28.91%] [G loss: 0.956661]\n",
      "epoch:10 step:8431[D loss: 0.442998, acc: 60.94%, op_acc: 31.25%] [G loss: 0.889041]\n",
      "epoch:10 step:8432[D loss: 0.494831, acc: 54.69%, op_acc: 31.25%] [G loss: 0.912099]\n",
      "epoch:10 step:8433[D loss: 0.429014, acc: 60.16%, op_acc: 38.28%] [G loss: 0.945345]\n",
      "epoch:10 step:8434[D loss: 0.467175, acc: 48.44%, op_acc: 32.81%] [G loss: 0.893787]\n",
      "epoch:10 step:8435[D loss: 0.468502, acc: 57.81%, op_acc: 33.59%] [G loss: 0.932369]\n",
      "epoch:10 step:8436[D loss: 0.442882, acc: 58.59%, op_acc: 34.38%] [G loss: 0.977742]\n",
      "epoch:10 step:8437[D loss: 0.446721, acc: 52.34%, op_acc: 36.72%] [G loss: 0.855081]\n",
      "epoch:10 step:8438[D loss: 0.442945, acc: 55.47%, op_acc: 33.59%] [G loss: 0.859247]\n",
      "epoch:10 step:8439[D loss: 0.463020, acc: 56.25%, op_acc: 30.47%] [G loss: 0.920232]\n",
      "epoch:10 step:8440[D loss: 0.414997, acc: 66.41%, op_acc: 36.72%] [G loss: 0.971851]\n",
      "epoch:10 step:8441[D loss: 0.455249, acc: 57.03%, op_acc: 31.25%] [G loss: 0.924180]\n",
      "epoch:10 step:8442[D loss: 0.426112, acc: 66.41%, op_acc: 32.81%] [G loss: 0.912044]\n",
      "epoch:10 step:8443[D loss: 0.438011, acc: 61.72%, op_acc: 35.16%] [G loss: 0.840701]\n",
      "epoch:10 step:8444[D loss: 0.401446, acc: 66.41%, op_acc: 37.50%] [G loss: 1.056175]\n",
      "epoch:10 step:8445[D loss: 0.439383, acc: 61.72%, op_acc: 32.03%] [G loss: 0.857895]\n",
      "epoch:10 step:8446[D loss: 0.401223, acc: 67.19%, op_acc: 39.84%] [G loss: 0.984200]\n",
      "epoch:10 step:8447[D loss: 0.428673, acc: 64.84%, op_acc: 32.03%] [G loss: 0.945262]\n",
      "epoch:10 step:8448[D loss: 0.435874, acc: 62.50%, op_acc: 28.12%] [G loss: 0.917812]\n",
      "epoch:10 step:8449[D loss: 0.473118, acc: 51.56%, op_acc: 32.81%] [G loss: 0.932271]\n",
      "epoch:10 step:8450[D loss: 0.429986, acc: 63.28%, op_acc: 41.41%] [G loss: 0.940294]\n",
      "epoch:10 step:8451[D loss: 0.424198, acc: 57.81%, op_acc: 33.59%] [G loss: 0.950533]\n",
      "epoch:10 step:8452[D loss: 0.446272, acc: 59.38%, op_acc: 32.81%] [G loss: 0.936875]\n",
      "epoch:10 step:8453[D loss: 0.488499, acc: 47.66%, op_acc: 32.03%] [G loss: 0.864999]\n",
      "epoch:10 step:8454[D loss: 0.455443, acc: 46.88%, op_acc: 36.72%] [G loss: 0.973011]\n",
      "epoch:10 step:8455[D loss: 0.438120, acc: 58.59%, op_acc: 32.81%] [G loss: 0.903266]\n",
      "epoch:10 step:8456[D loss: 0.474606, acc: 58.59%, op_acc: 31.25%] [G loss: 0.825598]\n",
      "epoch:10 step:8457[D loss: 0.421952, acc: 60.94%, op_acc: 38.28%] [G loss: 0.827530]\n",
      "epoch:10 step:8458[D loss: 0.431648, acc: 62.50%, op_acc: 31.25%] [G loss: 0.850608]\n",
      "epoch:10 step:8459[D loss: 0.441823, acc: 61.72%, op_acc: 32.81%] [G loss: 0.960730]\n",
      "epoch:10 step:8460[D loss: 0.431381, acc: 64.06%, op_acc: 30.47%] [G loss: 0.956789]\n",
      "epoch:10 step:8461[D loss: 0.431271, acc: 63.28%, op_acc: 38.28%] [G loss: 0.962467]\n",
      "epoch:10 step:8462[D loss: 0.415384, acc: 67.19%, op_acc: 39.84%] [G loss: 0.956073]\n",
      "epoch:10 step:8463[D loss: 0.440429, acc: 57.81%, op_acc: 37.50%] [G loss: 0.849363]\n",
      "epoch:10 step:8464[D loss: 0.398679, acc: 67.97%, op_acc: 35.94%] [G loss: 0.905926]\n",
      "epoch:10 step:8465[D loss: 0.436296, acc: 62.50%, op_acc: 35.94%] [G loss: 0.969558]\n",
      "epoch:10 step:8466[D loss: 0.426610, acc: 62.50%, op_acc: 33.59%] [G loss: 0.901416]\n",
      "epoch:10 step:8467[D loss: 0.449807, acc: 55.47%, op_acc: 39.06%] [G loss: 0.954363]\n",
      "epoch:10 step:8468[D loss: 0.445222, acc: 52.34%, op_acc: 35.16%] [G loss: 0.878786]\n",
      "epoch:10 step:8469[D loss: 0.424792, acc: 69.53%, op_acc: 38.28%] [G loss: 1.011414]\n",
      "epoch:10 step:8470[D loss: 0.413648, acc: 68.75%, op_acc: 37.50%] [G loss: 0.800267]\n",
      "epoch:10 step:8471[D loss: 0.454399, acc: 50.00%, op_acc: 39.06%] [G loss: 0.782780]\n",
      "epoch:10 step:8472[D loss: 0.438104, acc: 55.47%, op_acc: 31.25%] [G loss: 0.890797]\n",
      "epoch:10 step:8473[D loss: 0.431074, acc: 61.72%, op_acc: 32.03%] [G loss: 0.958388]\n",
      "epoch:10 step:8474[D loss: 0.420110, acc: 55.47%, op_acc: 35.16%] [G loss: 0.929490]\n",
      "epoch:10 step:8475[D loss: 0.453413, acc: 57.81%, op_acc: 30.47%] [G loss: 0.991056]\n",
      "epoch:10 step:8476[D loss: 0.436984, acc: 62.50%, op_acc: 35.16%] [G loss: 0.968958]\n",
      "epoch:10 step:8477[D loss: 0.416859, acc: 65.62%, op_acc: 34.38%] [G loss: 0.912000]\n",
      "epoch:10 step:8478[D loss: 0.406317, acc: 68.75%, op_acc: 35.94%] [G loss: 0.899630]\n",
      "epoch:10 step:8479[D loss: 0.447667, acc: 62.50%, op_acc: 32.81%] [G loss: 0.812643]\n",
      "epoch:10 step:8480[D loss: 0.435342, acc: 64.84%, op_acc: 32.81%] [G loss: 0.864936]\n",
      "epoch:10 step:8481[D loss: 0.456730, acc: 59.38%, op_acc: 38.28%] [G loss: 0.819183]\n",
      "epoch:10 step:8482[D loss: 0.459412, acc: 53.91%, op_acc: 35.94%] [G loss: 0.892979]\n",
      "epoch:10 step:8483[D loss: 0.457639, acc: 49.22%, op_acc: 37.50%] [G loss: 0.835953]\n",
      "epoch:10 step:8484[D loss: 0.461068, acc: 52.34%, op_acc: 39.06%] [G loss: 0.847264]\n",
      "epoch:10 step:8485[D loss: 0.427659, acc: 60.16%, op_acc: 33.59%] [G loss: 0.947674]\n",
      "epoch:10 step:8486[D loss: 0.471093, acc: 60.16%, op_acc: 34.38%] [G loss: 0.987943]\n",
      "epoch:10 step:8487[D loss: 0.474194, acc: 57.03%, op_acc: 33.59%] [G loss: 0.868728]\n",
      "epoch:10 step:8488[D loss: 0.428143, acc: 63.28%, op_acc: 39.84%] [G loss: 0.961435]\n",
      "epoch:10 step:8489[D loss: 0.405223, acc: 67.97%, op_acc: 38.28%] [G loss: 0.941551]\n",
      "epoch:10 step:8490[D loss: 0.440562, acc: 64.06%, op_acc: 38.28%] [G loss: 1.009226]\n",
      "epoch:10 step:8491[D loss: 0.432082, acc: 63.28%, op_acc: 30.47%] [G loss: 0.995608]\n",
      "epoch:10 step:8492[D loss: 0.457062, acc: 52.34%, op_acc: 37.50%] [G loss: 0.893478]\n",
      "epoch:10 step:8493[D loss: 0.438803, acc: 56.25%, op_acc: 40.62%] [G loss: 0.952683]\n",
      "epoch:10 step:8494[D loss: 0.421509, acc: 60.94%, op_acc: 34.38%] [G loss: 0.965013]\n",
      "epoch:10 step:8495[D loss: 0.464398, acc: 49.22%, op_acc: 32.03%] [G loss: 0.968031]\n",
      "epoch:10 step:8496[D loss: 0.422206, acc: 63.28%, op_acc: 37.50%] [G loss: 0.892205]\n",
      "epoch:10 step:8497[D loss: 0.417065, acc: 57.81%, op_acc: 38.28%] [G loss: 0.897979]\n",
      "epoch:10 step:8498[D loss: 0.457548, acc: 50.78%, op_acc: 37.50%] [G loss: 0.947170]\n",
      "epoch:10 step:8499[D loss: 0.440646, acc: 57.81%, op_acc: 35.16%] [G loss: 0.921651]\n",
      "epoch:10 step:8500[D loss: 0.424080, acc: 71.09%, op_acc: 33.59%] [G loss: 0.903431]\n",
      "epoch:10 step:8501[D loss: 0.426399, acc: 63.28%, op_acc: 35.16%] [G loss: 0.906442]\n",
      "epoch:10 step:8502[D loss: 0.476100, acc: 56.25%, op_acc: 33.59%] [G loss: 0.845847]\n",
      "epoch:10 step:8503[D loss: 0.447672, acc: 65.62%, op_acc: 33.59%] [G loss: 0.905278]\n",
      "epoch:10 step:8504[D loss: 0.452100, acc: 54.69%, op_acc: 32.03%] [G loss: 0.931273]\n",
      "epoch:10 step:8505[D loss: 0.445505, acc: 60.16%, op_acc: 33.59%] [G loss: 0.969661]\n",
      "epoch:10 step:8506[D loss: 0.458805, acc: 57.03%, op_acc: 35.16%] [G loss: 0.900316]\n",
      "epoch:10 step:8507[D loss: 0.411540, acc: 63.28%, op_acc: 41.41%] [G loss: 1.014473]\n",
      "epoch:10 step:8508[D loss: 0.455823, acc: 57.81%, op_acc: 32.81%] [G loss: 0.882093]\n",
      "epoch:10 step:8509[D loss: 0.431974, acc: 60.16%, op_acc: 32.03%] [G loss: 0.840477]\n",
      "epoch:10 step:8510[D loss: 0.446154, acc: 62.50%, op_acc: 37.50%] [G loss: 0.886977]\n",
      "epoch:10 step:8511[D loss: 0.464631, acc: 55.47%, op_acc: 31.25%] [G loss: 0.895129]\n",
      "epoch:10 step:8512[D loss: 0.438602, acc: 60.94%, op_acc: 38.28%] [G loss: 0.902631]\n",
      "epoch:10 step:8513[D loss: 0.435887, acc: 54.69%, op_acc: 39.06%] [G loss: 0.964062]\n",
      "epoch:10 step:8514[D loss: 0.412800, acc: 63.28%, op_acc: 39.06%] [G loss: 0.958993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:8515[D loss: 0.433555, acc: 69.53%, op_acc: 32.03%] [G loss: 0.886695]\n",
      "epoch:10 step:8516[D loss: 0.419460, acc: 66.41%, op_acc: 42.97%] [G loss: 0.900665]\n",
      "epoch:10 step:8517[D loss: 0.444629, acc: 60.16%, op_acc: 34.38%] [G loss: 0.817502]\n",
      "epoch:10 step:8518[D loss: 0.456986, acc: 60.16%, op_acc: 35.94%] [G loss: 0.912048]\n",
      "epoch:10 step:8519[D loss: 0.406456, acc: 67.19%, op_acc: 35.16%] [G loss: 0.920370]\n",
      "epoch:10 step:8520[D loss: 0.380961, acc: 67.97%, op_acc: 40.62%] [G loss: 0.933143]\n",
      "epoch:10 step:8521[D loss: 0.439759, acc: 55.47%, op_acc: 32.03%] [G loss: 0.912447]\n",
      "epoch:10 step:8522[D loss: 0.391332, acc: 69.53%, op_acc: 41.41%] [G loss: 0.890856]\n",
      "epoch:10 step:8523[D loss: 0.445548, acc: 54.69%, op_acc: 35.16%] [G loss: 0.908718]\n",
      "epoch:10 step:8524[D loss: 0.401563, acc: 70.31%, op_acc: 32.03%] [G loss: 0.939384]\n",
      "epoch:10 step:8525[D loss: 0.478811, acc: 44.53%, op_acc: 29.69%] [G loss: 0.849467]\n",
      "epoch:10 step:8526[D loss: 0.467360, acc: 53.12%, op_acc: 34.38%] [G loss: 0.936872]\n",
      "epoch:10 step:8527[D loss: 0.409033, acc: 68.75%, op_acc: 41.41%] [G loss: 0.922236]\n",
      "epoch:10 step:8528[D loss: 0.429692, acc: 65.62%, op_acc: 32.03%] [G loss: 0.921709]\n",
      "epoch:10 step:8529[D loss: 0.437704, acc: 57.03%, op_acc: 32.81%] [G loss: 0.866292]\n",
      "epoch:10 step:8530[D loss: 0.428374, acc: 60.94%, op_acc: 38.28%] [G loss: 0.984058]\n",
      "epoch:10 step:8531[D loss: 0.428232, acc: 52.34%, op_acc: 39.06%] [G loss: 0.899864]\n",
      "epoch:10 step:8532[D loss: 0.446782, acc: 56.25%, op_acc: 34.38%] [G loss: 0.820302]\n",
      "epoch:10 step:8533[D loss: 0.457269, acc: 53.12%, op_acc: 36.72%] [G loss: 0.878224]\n",
      "epoch:10 step:8534[D loss: 0.463352, acc: 55.47%, op_acc: 33.59%] [G loss: 0.881799]\n",
      "epoch:10 step:8535[D loss: 0.416341, acc: 64.84%, op_acc: 35.16%] [G loss: 0.916044]\n",
      "epoch:10 step:8536[D loss: 0.412631, acc: 60.16%, op_acc: 38.28%] [G loss: 0.913684]\n",
      "epoch:10 step:8537[D loss: 0.457020, acc: 59.38%, op_acc: 31.25%] [G loss: 0.916529]\n",
      "epoch:10 step:8538[D loss: 0.462110, acc: 60.94%, op_acc: 31.25%] [G loss: 0.881187]\n",
      "epoch:10 step:8539[D loss: 0.445578, acc: 57.81%, op_acc: 39.06%] [G loss: 0.901753]\n",
      "epoch:10 step:8540[D loss: 0.465466, acc: 50.78%, op_acc: 38.28%] [G loss: 0.864315]\n",
      "epoch:10 step:8541[D loss: 0.438057, acc: 58.59%, op_acc: 34.38%] [G loss: 0.900969]\n",
      "epoch:10 step:8542[D loss: 0.449045, acc: 58.59%, op_acc: 33.59%] [G loss: 0.929692]\n",
      "epoch:10 step:8543[D loss: 0.443590, acc: 55.47%, op_acc: 34.38%] [G loss: 1.014693]\n",
      "epoch:10 step:8544[D loss: 0.438856, acc: 60.94%, op_acc: 32.81%] [G loss: 0.950330]\n",
      "epoch:10 step:8545[D loss: 0.443022, acc: 60.16%, op_acc: 31.25%] [G loss: 0.892533]\n",
      "epoch:10 step:8546[D loss: 0.428542, acc: 64.84%, op_acc: 35.94%] [G loss: 0.998470]\n",
      "epoch:10 step:8547[D loss: 0.423158, acc: 62.50%, op_acc: 38.28%] [G loss: 0.922891]\n",
      "epoch:10 step:8548[D loss: 0.419693, acc: 60.94%, op_acc: 42.97%] [G loss: 0.934007]\n",
      "epoch:10 step:8549[D loss: 0.421109, acc: 60.16%, op_acc: 41.41%] [G loss: 0.880875]\n",
      "epoch:10 step:8550[D loss: 0.447936, acc: 48.44%, op_acc: 35.16%] [G loss: 0.853337]\n",
      "epoch:10 step:8551[D loss: 0.434067, acc: 57.81%, op_acc: 35.16%] [G loss: 0.856537]\n",
      "epoch:10 step:8552[D loss: 0.419173, acc: 60.16%, op_acc: 35.16%] [G loss: 0.960239]\n",
      "epoch:10 step:8553[D loss: 0.432451, acc: 63.28%, op_acc: 29.69%] [G loss: 0.900691]\n",
      "epoch:10 step:8554[D loss: 0.411959, acc: 57.81%, op_acc: 39.06%] [G loss: 0.941406]\n",
      "epoch:10 step:8555[D loss: 0.436645, acc: 63.28%, op_acc: 39.06%] [G loss: 0.908623]\n",
      "epoch:10 step:8556[D loss: 0.431854, acc: 60.94%, op_acc: 36.72%] [G loss: 1.006480]\n",
      "epoch:10 step:8557[D loss: 0.441893, acc: 53.12%, op_acc: 36.72%] [G loss: 0.907716]\n",
      "epoch:10 step:8558[D loss: 0.458038, acc: 60.16%, op_acc: 26.56%] [G loss: 0.882987]\n",
      "epoch:10 step:8559[D loss: 0.441811, acc: 57.81%, op_acc: 35.16%] [G loss: 0.834355]\n",
      "epoch:10 step:8560[D loss: 0.415105, acc: 67.19%, op_acc: 37.50%] [G loss: 0.955204]\n",
      "epoch:10 step:8561[D loss: 0.470492, acc: 54.69%, op_acc: 26.56%] [G loss: 0.879976]\n",
      "epoch:10 step:8562[D loss: 0.423887, acc: 64.84%, op_acc: 31.25%] [G loss: 0.862725]\n",
      "epoch:10 step:8563[D loss: 0.437184, acc: 60.94%, op_acc: 29.69%] [G loss: 0.867241]\n",
      "epoch:10 step:8564[D loss: 0.399672, acc: 71.09%, op_acc: 37.50%] [G loss: 0.949936]\n",
      "epoch:10 step:8565[D loss: 0.449010, acc: 59.38%, op_acc: 32.03%] [G loss: 0.937566]\n",
      "epoch:10 step:8566[D loss: 0.384646, acc: 70.31%, op_acc: 41.41%] [G loss: 0.933928]\n",
      "epoch:10 step:8567[D loss: 0.424179, acc: 64.06%, op_acc: 35.94%] [G loss: 0.926414]\n",
      "epoch:10 step:8568[D loss: 0.428937, acc: 59.38%, op_acc: 39.84%] [G loss: 0.908733]\n",
      "epoch:10 step:8569[D loss: 0.422576, acc: 63.28%, op_acc: 36.72%] [G loss: 0.858892]\n",
      "epoch:10 step:8570[D loss: 0.444271, acc: 57.81%, op_acc: 32.03%] [G loss: 0.847263]\n",
      "epoch:10 step:8571[D loss: 0.429438, acc: 58.59%, op_acc: 33.59%] [G loss: 0.909535]\n",
      "epoch:10 step:8572[D loss: 0.431281, acc: 60.16%, op_acc: 36.72%] [G loss: 0.873163]\n",
      "epoch:10 step:8573[D loss: 0.439120, acc: 60.16%, op_acc: 35.16%] [G loss: 0.916442]\n",
      "epoch:10 step:8574[D loss: 0.439636, acc: 54.69%, op_acc: 39.06%] [G loss: 0.897362]\n",
      "epoch:10 step:8575[D loss: 0.435494, acc: 55.47%, op_acc: 35.94%] [G loss: 0.929659]\n",
      "epoch:10 step:8576[D loss: 0.458103, acc: 56.25%, op_acc: 33.59%] [G loss: 1.038388]\n",
      "epoch:10 step:8577[D loss: 0.413156, acc: 65.62%, op_acc: 39.06%] [G loss: 0.918632]\n",
      "epoch:10 step:8578[D loss: 0.440228, acc: 64.84%, op_acc: 32.81%] [G loss: 0.881967]\n",
      "epoch:10 step:8579[D loss: 0.431864, acc: 60.94%, op_acc: 35.94%] [G loss: 0.914099]\n",
      "epoch:10 step:8580[D loss: 0.419020, acc: 63.28%, op_acc: 35.94%] [G loss: 0.911897]\n",
      "epoch:10 step:8581[D loss: 0.463665, acc: 57.03%, op_acc: 35.94%] [G loss: 0.904420]\n",
      "epoch:10 step:8582[D loss: 0.464453, acc: 58.59%, op_acc: 33.59%] [G loss: 0.882520]\n",
      "epoch:10 step:8583[D loss: 0.448181, acc: 60.16%, op_acc: 33.59%] [G loss: 0.909729]\n",
      "epoch:10 step:8584[D loss: 0.418913, acc: 59.38%, op_acc: 40.62%] [G loss: 0.814247]\n",
      "epoch:10 step:8585[D loss: 0.427665, acc: 63.28%, op_acc: 34.38%] [G loss: 0.956827]\n",
      "epoch:10 step:8586[D loss: 0.425771, acc: 64.84%, op_acc: 35.16%] [G loss: 0.965420]\n",
      "epoch:10 step:8587[D loss: 0.492656, acc: 48.44%, op_acc: 25.00%] [G loss: 0.902784]\n",
      "epoch:10 step:8588[D loss: 0.412713, acc: 65.62%, op_acc: 42.19%] [G loss: 0.938461]\n",
      "epoch:10 step:8589[D loss: 0.427800, acc: 60.94%, op_acc: 39.06%] [G loss: 0.908811]\n",
      "epoch:10 step:8590[D loss: 0.433515, acc: 67.19%, op_acc: 35.16%] [G loss: 0.956647]\n",
      "epoch:10 step:8591[D loss: 0.437319, acc: 65.62%, op_acc: 35.94%] [G loss: 0.907934]\n",
      "epoch:11 step:8592[D loss: 0.431691, acc: 62.50%, op_acc: 38.28%] [G loss: 0.953141]\n",
      "epoch:11 step:8593[D loss: 0.421179, acc: 60.94%, op_acc: 39.06%] [G loss: 0.909431]\n",
      "epoch:11 step:8594[D loss: 0.474902, acc: 50.78%, op_acc: 33.59%] [G loss: 0.917311]\n",
      "epoch:11 step:8595[D loss: 0.449055, acc: 48.44%, op_acc: 38.28%] [G loss: 0.946034]\n",
      "epoch:11 step:8596[D loss: 0.444747, acc: 62.50%, op_acc: 35.94%] [G loss: 0.974563]\n",
      "epoch:11 step:8597[D loss: 0.418279, acc: 58.59%, op_acc: 38.28%] [G loss: 0.855973]\n",
      "epoch:11 step:8598[D loss: 0.435549, acc: 58.59%, op_acc: 35.94%] [G loss: 0.898661]\n",
      "epoch:11 step:8599[D loss: 0.435454, acc: 59.38%, op_acc: 34.38%] [G loss: 0.908632]\n",
      "epoch:11 step:8600[D loss: 0.430079, acc: 64.84%, op_acc: 37.50%] [G loss: 0.903277]\n",
      "epoch:11 step:8601[D loss: 0.428163, acc: 63.28%, op_acc: 34.38%] [G loss: 0.971137]\n",
      "epoch:11 step:8602[D loss: 0.461103, acc: 63.28%, op_acc: 30.47%] [G loss: 0.968491]\n",
      "epoch:11 step:8603[D loss: 0.415461, acc: 71.09%, op_acc: 34.38%] [G loss: 0.969732]\n",
      "epoch:11 step:8604[D loss: 0.404473, acc: 64.84%, op_acc: 34.38%] [G loss: 0.982595]\n",
      "epoch:11 step:8605[D loss: 0.449614, acc: 60.94%, op_acc: 35.16%] [G loss: 0.976888]\n",
      "epoch:11 step:8606[D loss: 0.450041, acc: 53.12%, op_acc: 35.94%] [G loss: 0.901974]\n",
      "epoch:11 step:8607[D loss: 0.446156, acc: 49.22%, op_acc: 28.12%] [G loss: 0.903997]\n",
      "epoch:11 step:8608[D loss: 0.441954, acc: 53.91%, op_acc: 39.84%] [G loss: 0.882311]\n",
      "epoch:11 step:8609[D loss: 0.437953, acc: 56.25%, op_acc: 35.94%] [G loss: 0.867659]\n",
      "epoch:11 step:8610[D loss: 0.394650, acc: 70.31%, op_acc: 40.62%] [G loss: 0.886032]\n",
      "epoch:11 step:8611[D loss: 0.426401, acc: 58.59%, op_acc: 38.28%] [G loss: 0.842952]\n",
      "epoch:11 step:8612[D loss: 0.443613, acc: 62.50%, op_acc: 30.47%] [G loss: 0.909146]\n",
      "epoch:11 step:8613[D loss: 0.423880, acc: 59.38%, op_acc: 36.72%] [G loss: 0.910723]\n",
      "epoch:11 step:8614[D loss: 0.453999, acc: 55.47%, op_acc: 36.72%] [G loss: 0.886290]\n",
      "epoch:11 step:8615[D loss: 0.446548, acc: 60.16%, op_acc: 37.50%] [G loss: 0.909427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8616[D loss: 0.464251, acc: 54.69%, op_acc: 36.72%] [G loss: 0.915043]\n",
      "epoch:11 step:8617[D loss: 0.408879, acc: 67.97%, op_acc: 36.72%] [G loss: 0.887406]\n",
      "epoch:11 step:8618[D loss: 0.406308, acc: 72.66%, op_acc: 41.41%] [G loss: 0.883546]\n",
      "epoch:11 step:8619[D loss: 0.418292, acc: 61.72%, op_acc: 37.50%] [G loss: 0.939885]\n",
      "epoch:11 step:8620[D loss: 0.419605, acc: 63.28%, op_acc: 37.50%] [G loss: 0.933490]\n",
      "epoch:11 step:8621[D loss: 0.426371, acc: 58.59%, op_acc: 38.28%] [G loss: 0.958338]\n",
      "epoch:11 step:8622[D loss: 0.482174, acc: 62.50%, op_acc: 26.56%] [G loss: 0.922599]\n",
      "epoch:11 step:8623[D loss: 0.431384, acc: 64.06%, op_acc: 32.03%] [G loss: 0.963444]\n",
      "epoch:11 step:8624[D loss: 0.415691, acc: 66.41%, op_acc: 35.94%] [G loss: 1.042829]\n",
      "epoch:11 step:8625[D loss: 0.407163, acc: 63.28%, op_acc: 39.06%] [G loss: 0.882853]\n",
      "epoch:11 step:8626[D loss: 0.422893, acc: 63.28%, op_acc: 35.16%] [G loss: 0.911179]\n",
      "epoch:11 step:8627[D loss: 0.406835, acc: 64.06%, op_acc: 39.84%] [G loss: 0.918463]\n",
      "epoch:11 step:8628[D loss: 0.432155, acc: 53.91%, op_acc: 35.94%] [G loss: 0.895223]\n",
      "epoch:11 step:8629[D loss: 0.433024, acc: 59.38%, op_acc: 39.84%] [G loss: 0.932131]\n",
      "epoch:11 step:8630[D loss: 0.439235, acc: 57.81%, op_acc: 40.62%] [G loss: 0.886069]\n",
      "epoch:11 step:8631[D loss: 0.459233, acc: 63.28%, op_acc: 30.47%] [G loss: 0.944998]\n",
      "epoch:11 step:8632[D loss: 0.397285, acc: 70.31%, op_acc: 34.38%] [G loss: 0.992183]\n",
      "epoch:11 step:8633[D loss: 0.417585, acc: 59.38%, op_acc: 42.19%] [G loss: 0.906573]\n",
      "epoch:11 step:8634[D loss: 0.461850, acc: 55.47%, op_acc: 28.91%] [G loss: 0.851348]\n",
      "epoch:11 step:8635[D loss: 0.460923, acc: 55.47%, op_acc: 31.25%] [G loss: 0.852626]\n",
      "epoch:11 step:8636[D loss: 0.420962, acc: 67.97%, op_acc: 33.59%] [G loss: 0.907638]\n",
      "epoch:11 step:8637[D loss: 0.445671, acc: 64.84%, op_acc: 32.81%] [G loss: 0.862203]\n",
      "epoch:11 step:8638[D loss: 0.449427, acc: 58.59%, op_acc: 35.94%] [G loss: 0.807247]\n",
      "epoch:11 step:8639[D loss: 0.461261, acc: 61.72%, op_acc: 28.12%] [G loss: 0.908277]\n",
      "epoch:11 step:8640[D loss: 0.445131, acc: 60.16%, op_acc: 35.16%] [G loss: 0.820658]\n",
      "epoch:11 step:8641[D loss: 0.432162, acc: 63.28%, op_acc: 32.81%] [G loss: 0.883790]\n",
      "epoch:11 step:8642[D loss: 0.431264, acc: 62.50%, op_acc: 35.94%] [G loss: 0.847821]\n",
      "epoch:11 step:8643[D loss: 0.471170, acc: 50.00%, op_acc: 32.81%] [G loss: 0.830212]\n",
      "epoch:11 step:8644[D loss: 0.458788, acc: 57.81%, op_acc: 31.25%] [G loss: 0.871516]\n",
      "epoch:11 step:8645[D loss: 0.454911, acc: 57.03%, op_acc: 33.59%] [G loss: 0.861134]\n",
      "epoch:11 step:8646[D loss: 0.442487, acc: 58.59%, op_acc: 37.50%] [G loss: 0.910573]\n",
      "epoch:11 step:8647[D loss: 0.426432, acc: 64.84%, op_acc: 33.59%] [G loss: 0.856537]\n",
      "epoch:11 step:8648[D loss: 0.463699, acc: 52.34%, op_acc: 34.38%] [G loss: 0.842511]\n",
      "epoch:11 step:8649[D loss: 0.407807, acc: 64.84%, op_acc: 37.50%] [G loss: 0.927568]\n",
      "epoch:11 step:8650[D loss: 0.384729, acc: 65.62%, op_acc: 37.50%] [G loss: 0.910139]\n",
      "epoch:11 step:8651[D loss: 0.416897, acc: 66.41%, op_acc: 42.19%] [G loss: 0.956144]\n",
      "epoch:11 step:8652[D loss: 0.419303, acc: 65.62%, op_acc: 39.06%] [G loss: 0.929793]\n",
      "epoch:11 step:8653[D loss: 0.431944, acc: 52.34%, op_acc: 37.50%] [G loss: 0.819590]\n",
      "epoch:11 step:8654[D loss: 0.408942, acc: 64.84%, op_acc: 39.84%] [G loss: 0.929043]\n",
      "epoch:11 step:8655[D loss: 0.441434, acc: 57.81%, op_acc: 34.38%] [G loss: 0.903945]\n",
      "epoch:11 step:8656[D loss: 0.470493, acc: 53.12%, op_acc: 35.16%] [G loss: 0.904753]\n",
      "epoch:11 step:8657[D loss: 0.465115, acc: 54.69%, op_acc: 38.28%] [G loss: 0.932084]\n",
      "epoch:11 step:8658[D loss: 0.425082, acc: 64.06%, op_acc: 34.38%] [G loss: 0.930533]\n",
      "epoch:11 step:8659[D loss: 0.462211, acc: 55.47%, op_acc: 27.34%] [G loss: 0.876717]\n",
      "epoch:11 step:8660[D loss: 0.453981, acc: 50.78%, op_acc: 36.72%] [G loss: 0.974960]\n",
      "epoch:11 step:8661[D loss: 0.422237, acc: 67.97%, op_acc: 28.91%] [G loss: 0.916296]\n",
      "epoch:11 step:8662[D loss: 0.460046, acc: 54.69%, op_acc: 32.81%] [G loss: 0.947758]\n",
      "epoch:11 step:8663[D loss: 0.411092, acc: 60.94%, op_acc: 35.94%] [G loss: 0.910392]\n",
      "epoch:11 step:8664[D loss: 0.456423, acc: 51.56%, op_acc: 35.94%] [G loss: 0.888067]\n",
      "epoch:11 step:8665[D loss: 0.408536, acc: 61.72%, op_acc: 41.41%] [G loss: 0.916092]\n",
      "epoch:11 step:8666[D loss: 0.436902, acc: 57.81%, op_acc: 32.03%] [G loss: 0.926748]\n",
      "epoch:11 step:8667[D loss: 0.470331, acc: 59.38%, op_acc: 29.69%] [G loss: 0.965600]\n",
      "epoch:11 step:8668[D loss: 0.468712, acc: 50.78%, op_acc: 36.72%] [G loss: 0.801005]\n",
      "epoch:11 step:8669[D loss: 0.452563, acc: 58.59%, op_acc: 28.91%] [G loss: 0.866826]\n",
      "epoch:11 step:8670[D loss: 0.447329, acc: 60.16%, op_acc: 35.16%] [G loss: 0.881795]\n",
      "epoch:11 step:8671[D loss: 0.459749, acc: 57.03%, op_acc: 28.12%] [G loss: 0.901697]\n",
      "epoch:11 step:8672[D loss: 0.455821, acc: 59.38%, op_acc: 33.59%] [G loss: 0.880236]\n",
      "epoch:11 step:8673[D loss: 0.440819, acc: 62.50%, op_acc: 35.94%] [G loss: 0.878566]\n",
      "epoch:11 step:8674[D loss: 0.419944, acc: 63.28%, op_acc: 35.94%] [G loss: 0.862408]\n",
      "epoch:11 step:8675[D loss: 0.421801, acc: 60.16%, op_acc: 33.59%] [G loss: 0.971099]\n",
      "epoch:11 step:8676[D loss: 0.451444, acc: 57.03%, op_acc: 31.25%] [G loss: 0.912015]\n",
      "epoch:11 step:8677[D loss: 0.419753, acc: 67.19%, op_acc: 38.28%] [G loss: 0.958935]\n",
      "epoch:11 step:8678[D loss: 0.444602, acc: 64.84%, op_acc: 33.59%] [G loss: 0.895568]\n",
      "epoch:11 step:8679[D loss: 0.465771, acc: 57.81%, op_acc: 34.38%] [G loss: 0.808127]\n",
      "epoch:11 step:8680[D loss: 0.447505, acc: 59.38%, op_acc: 35.16%] [G loss: 0.898981]\n",
      "epoch:11 step:8681[D loss: 0.415767, acc: 61.72%, op_acc: 42.97%] [G loss: 0.938519]\n",
      "epoch:11 step:8682[D loss: 0.431056, acc: 61.72%, op_acc: 39.84%] [G loss: 0.863633]\n",
      "epoch:11 step:8683[D loss: 0.451110, acc: 57.81%, op_acc: 31.25%] [G loss: 0.849026]\n",
      "epoch:11 step:8684[D loss: 0.415036, acc: 60.94%, op_acc: 36.72%] [G loss: 0.833262]\n",
      "epoch:11 step:8685[D loss: 0.421955, acc: 61.72%, op_acc: 39.84%] [G loss: 0.841237]\n",
      "epoch:11 step:8686[D loss: 0.432130, acc: 64.84%, op_acc: 35.16%] [G loss: 0.963801]\n",
      "epoch:11 step:8687[D loss: 0.423584, acc: 62.50%, op_acc: 32.03%] [G loss: 0.971970]\n",
      "epoch:11 step:8688[D loss: 0.426552, acc: 61.72%, op_acc: 35.16%] [G loss: 0.890330]\n",
      "epoch:11 step:8689[D loss: 0.421396, acc: 67.97%, op_acc: 32.81%] [G loss: 0.938594]\n",
      "epoch:11 step:8690[D loss: 0.416632, acc: 58.59%, op_acc: 39.06%] [G loss: 0.903074]\n",
      "epoch:11 step:8691[D loss: 0.416203, acc: 56.25%, op_acc: 38.28%] [G loss: 0.881122]\n",
      "epoch:11 step:8692[D loss: 0.446229, acc: 60.16%, op_acc: 35.16%] [G loss: 0.922892]\n",
      "epoch:11 step:8693[D loss: 0.456936, acc: 57.03%, op_acc: 35.16%] [G loss: 0.870456]\n",
      "epoch:11 step:8694[D loss: 0.467977, acc: 64.84%, op_acc: 32.03%] [G loss: 0.917302]\n",
      "epoch:11 step:8695[D loss: 0.457677, acc: 54.69%, op_acc: 32.03%] [G loss: 0.880132]\n",
      "epoch:11 step:8696[D loss: 0.453824, acc: 51.56%, op_acc: 32.81%] [G loss: 0.831407]\n",
      "epoch:11 step:8697[D loss: 0.401603, acc: 64.06%, op_acc: 38.28%] [G loss: 0.934971]\n",
      "epoch:11 step:8698[D loss: 0.431777, acc: 57.81%, op_acc: 32.81%] [G loss: 0.932023]\n",
      "epoch:11 step:8699[D loss: 0.475284, acc: 53.12%, op_acc: 35.16%] [G loss: 0.895599]\n",
      "epoch:11 step:8700[D loss: 0.434791, acc: 53.91%, op_acc: 39.06%] [G loss: 0.918640]\n",
      "epoch:11 step:8701[D loss: 0.421305, acc: 60.16%, op_acc: 39.06%] [G loss: 0.882722]\n",
      "epoch:11 step:8702[D loss: 0.432096, acc: 58.59%, op_acc: 34.38%] [G loss: 0.882192]\n",
      "epoch:11 step:8703[D loss: 0.419814, acc: 60.16%, op_acc: 39.84%] [G loss: 0.990550]\n",
      "epoch:11 step:8704[D loss: 0.419822, acc: 63.28%, op_acc: 29.69%] [G loss: 0.896930]\n",
      "epoch:11 step:8705[D loss: 0.443568, acc: 53.12%, op_acc: 35.16%] [G loss: 0.933446]\n",
      "epoch:11 step:8706[D loss: 0.398406, acc: 60.94%, op_acc: 39.06%] [G loss: 0.947360]\n",
      "epoch:11 step:8707[D loss: 0.465462, acc: 55.47%, op_acc: 33.59%] [G loss: 0.932444]\n",
      "epoch:11 step:8708[D loss: 0.424719, acc: 62.50%, op_acc: 36.72%] [G loss: 0.871551]\n",
      "epoch:11 step:8709[D loss: 0.461461, acc: 50.00%, op_acc: 35.94%] [G loss: 0.828117]\n",
      "epoch:11 step:8710[D loss: 0.437689, acc: 64.84%, op_acc: 30.47%] [G loss: 0.877344]\n",
      "epoch:11 step:8711[D loss: 0.436123, acc: 62.50%, op_acc: 35.94%] [G loss: 0.962453]\n",
      "epoch:11 step:8712[D loss: 0.453254, acc: 61.72%, op_acc: 32.03%] [G loss: 0.988156]\n",
      "epoch:11 step:8713[D loss: 0.445640, acc: 57.03%, op_acc: 34.38%] [G loss: 0.934705]\n",
      "epoch:11 step:8714[D loss: 0.427032, acc: 59.38%, op_acc: 34.38%] [G loss: 0.923520]\n",
      "epoch:11 step:8715[D loss: 0.419319, acc: 59.38%, op_acc: 35.94%] [G loss: 0.955334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8716[D loss: 0.419010, acc: 65.62%, op_acc: 35.16%] [G loss: 0.969376]\n",
      "epoch:11 step:8717[D loss: 0.412756, acc: 65.62%, op_acc: 40.62%] [G loss: 0.938783]\n",
      "epoch:11 step:8718[D loss: 0.402537, acc: 70.31%, op_acc: 30.47%] [G loss: 0.901755]\n",
      "epoch:11 step:8719[D loss: 0.426500, acc: 57.81%, op_acc: 35.94%] [G loss: 0.936604]\n",
      "epoch:11 step:8720[D loss: 0.444628, acc: 61.72%, op_acc: 35.16%] [G loss: 0.927552]\n",
      "epoch:11 step:8721[D loss: 0.425968, acc: 61.72%, op_acc: 32.81%] [G loss: 0.899605]\n",
      "epoch:11 step:8722[D loss: 0.410610, acc: 65.62%, op_acc: 37.50%] [G loss: 0.851617]\n",
      "epoch:11 step:8723[D loss: 0.405993, acc: 61.72%, op_acc: 39.06%] [G loss: 0.871353]\n",
      "epoch:11 step:8724[D loss: 0.421663, acc: 67.19%, op_acc: 31.25%] [G loss: 0.954080]\n",
      "epoch:11 step:8725[D loss: 0.451189, acc: 60.94%, op_acc: 33.59%] [G loss: 0.825955]\n",
      "epoch:11 step:8726[D loss: 0.473081, acc: 47.66%, op_acc: 36.72%] [G loss: 0.855541]\n",
      "epoch:11 step:8727[D loss: 0.411901, acc: 62.50%, op_acc: 36.72%] [G loss: 0.874302]\n",
      "epoch:11 step:8728[D loss: 0.460657, acc: 57.03%, op_acc: 34.38%] [G loss: 0.903579]\n",
      "epoch:11 step:8729[D loss: 0.450250, acc: 59.38%, op_acc: 34.38%] [G loss: 0.947371]\n",
      "epoch:11 step:8730[D loss: 0.435747, acc: 57.81%, op_acc: 36.72%] [G loss: 0.929481]\n",
      "epoch:11 step:8731[D loss: 0.517957, acc: 53.91%, op_acc: 29.69%] [G loss: 0.901648]\n",
      "epoch:11 step:8732[D loss: 0.479380, acc: 57.03%, op_acc: 30.47%] [G loss: 0.950194]\n",
      "epoch:11 step:8733[D loss: 0.409173, acc: 65.62%, op_acc: 34.38%] [G loss: 0.954026]\n",
      "epoch:11 step:8734[D loss: 0.453677, acc: 53.12%, op_acc: 36.72%] [G loss: 0.840327]\n",
      "epoch:11 step:8735[D loss: 0.462915, acc: 55.47%, op_acc: 30.47%] [G loss: 0.879369]\n",
      "epoch:11 step:8736[D loss: 0.446774, acc: 57.81%, op_acc: 34.38%] [G loss: 0.789951]\n",
      "epoch:11 step:8737[D loss: 0.461174, acc: 54.69%, op_acc: 33.59%] [G loss: 0.938798]\n",
      "epoch:11 step:8738[D loss: 0.408599, acc: 61.72%, op_acc: 36.72%] [G loss: 0.995634]\n",
      "epoch:11 step:8739[D loss: 0.453041, acc: 56.25%, op_acc: 36.72%] [G loss: 0.897291]\n",
      "epoch:11 step:8740[D loss: 0.435530, acc: 56.25%, op_acc: 34.38%] [G loss: 0.904667]\n",
      "epoch:11 step:8741[D loss: 0.422703, acc: 59.38%, op_acc: 32.03%] [G loss: 0.860784]\n",
      "epoch:11 step:8742[D loss: 0.427374, acc: 64.06%, op_acc: 36.72%] [G loss: 0.874648]\n",
      "epoch:11 step:8743[D loss: 0.437735, acc: 56.25%, op_acc: 35.94%] [G loss: 0.930622]\n",
      "epoch:11 step:8744[D loss: 0.478814, acc: 59.38%, op_acc: 32.81%] [G loss: 0.828064]\n",
      "epoch:11 step:8745[D loss: 0.430856, acc: 63.28%, op_acc: 33.59%] [G loss: 0.955576]\n",
      "epoch:11 step:8746[D loss: 0.451464, acc: 58.59%, op_acc: 34.38%] [G loss: 0.838169]\n",
      "epoch:11 step:8747[D loss: 0.446441, acc: 56.25%, op_acc: 35.16%] [G loss: 0.920315]\n",
      "epoch:11 step:8748[D loss: 0.423891, acc: 62.50%, op_acc: 39.06%] [G loss: 0.842570]\n",
      "epoch:11 step:8749[D loss: 0.425705, acc: 56.25%, op_acc: 44.53%] [G loss: 0.905113]\n",
      "epoch:11 step:8750[D loss: 0.436365, acc: 61.72%, op_acc: 31.25%] [G loss: 0.929037]\n",
      "epoch:11 step:8751[D loss: 0.472969, acc: 56.25%, op_acc: 32.81%] [G loss: 0.906798]\n",
      "epoch:11 step:8752[D loss: 0.459439, acc: 62.50%, op_acc: 35.16%] [G loss: 0.945173]\n",
      "epoch:11 step:8753[D loss: 0.451811, acc: 57.81%, op_acc: 38.28%] [G loss: 0.953997]\n",
      "epoch:11 step:8754[D loss: 0.449655, acc: 60.94%, op_acc: 30.47%] [G loss: 0.996736]\n",
      "epoch:11 step:8755[D loss: 0.440446, acc: 65.62%, op_acc: 31.25%] [G loss: 0.957991]\n",
      "epoch:11 step:8756[D loss: 0.424140, acc: 57.03%, op_acc: 35.94%] [G loss: 0.887059]\n",
      "epoch:11 step:8757[D loss: 0.475633, acc: 60.16%, op_acc: 33.59%] [G loss: 0.821132]\n",
      "epoch:11 step:8758[D loss: 0.416689, acc: 71.88%, op_acc: 39.06%] [G loss: 0.968880]\n",
      "epoch:11 step:8759[D loss: 0.442301, acc: 58.59%, op_acc: 33.59%] [G loss: 0.968682]\n",
      "epoch:11 step:8760[D loss: 0.421510, acc: 58.59%, op_acc: 39.84%] [G loss: 0.954765]\n",
      "epoch:11 step:8761[D loss: 0.440544, acc: 53.12%, op_acc: 39.84%] [G loss: 0.944345]\n",
      "epoch:11 step:8762[D loss: 0.452747, acc: 61.72%, op_acc: 32.03%] [G loss: 0.933750]\n",
      "epoch:11 step:8763[D loss: 0.428438, acc: 62.50%, op_acc: 39.06%] [G loss: 0.907604]\n",
      "epoch:11 step:8764[D loss: 0.430582, acc: 58.59%, op_acc: 35.16%] [G loss: 0.903043]\n",
      "epoch:11 step:8765[D loss: 0.479418, acc: 52.34%, op_acc: 30.47%] [G loss: 0.824781]\n",
      "epoch:11 step:8766[D loss: 0.401299, acc: 66.41%, op_acc: 38.28%] [G loss: 0.852194]\n",
      "epoch:11 step:8767[D loss: 0.430160, acc: 64.06%, op_acc: 35.94%] [G loss: 0.855229]\n",
      "epoch:11 step:8768[D loss: 0.421250, acc: 59.38%, op_acc: 37.50%] [G loss: 0.878143]\n",
      "epoch:11 step:8769[D loss: 0.467346, acc: 59.38%, op_acc: 32.03%] [G loss: 0.873240]\n",
      "epoch:11 step:8770[D loss: 0.386786, acc: 72.66%, op_acc: 38.28%] [G loss: 0.881881]\n",
      "epoch:11 step:8771[D loss: 0.438951, acc: 63.28%, op_acc: 31.25%] [G loss: 0.874626]\n",
      "epoch:11 step:8772[D loss: 0.419875, acc: 61.72%, op_acc: 40.62%] [G loss: 0.875380]\n",
      "epoch:11 step:8773[D loss: 0.429759, acc: 63.28%, op_acc: 35.94%] [G loss: 0.851391]\n",
      "epoch:11 step:8774[D loss: 0.411807, acc: 64.84%, op_acc: 36.72%] [G loss: 0.909735]\n",
      "epoch:11 step:8775[D loss: 0.433504, acc: 57.81%, op_acc: 35.94%] [G loss: 0.986127]\n",
      "epoch:11 step:8776[D loss: 0.425883, acc: 67.19%, op_acc: 32.81%] [G loss: 1.001608]\n",
      "epoch:11 step:8777[D loss: 0.434255, acc: 62.50%, op_acc: 37.50%] [G loss: 0.894966]\n",
      "epoch:11 step:8778[D loss: 0.422751, acc: 64.06%, op_acc: 32.81%] [G loss: 0.953459]\n",
      "epoch:11 step:8779[D loss: 0.446973, acc: 57.81%, op_acc: 32.81%] [G loss: 0.874128]\n",
      "epoch:11 step:8780[D loss: 0.444840, acc: 62.50%, op_acc: 32.03%] [G loss: 0.904502]\n",
      "epoch:11 step:8781[D loss: 0.453882, acc: 58.59%, op_acc: 27.34%] [G loss: 0.923306]\n",
      "epoch:11 step:8782[D loss: 0.457304, acc: 50.78%, op_acc: 35.94%] [G loss: 0.902503]\n",
      "epoch:11 step:8783[D loss: 0.445957, acc: 57.03%, op_acc: 36.72%] [G loss: 0.840476]\n",
      "epoch:11 step:8784[D loss: 0.485519, acc: 48.44%, op_acc: 32.81%] [G loss: 0.901966]\n",
      "epoch:11 step:8785[D loss: 0.445718, acc: 59.38%, op_acc: 38.28%] [G loss: 1.055293]\n",
      "epoch:11 step:8786[D loss: 0.446554, acc: 61.72%, op_acc: 39.06%] [G loss: 0.962813]\n",
      "epoch:11 step:8787[D loss: 0.448714, acc: 60.94%, op_acc: 35.16%] [G loss: 0.969474]\n",
      "epoch:11 step:8788[D loss: 0.444484, acc: 60.16%, op_acc: 35.94%] [G loss: 1.003255]\n",
      "epoch:11 step:8789[D loss: 0.446371, acc: 53.91%, op_acc: 37.50%] [G loss: 0.910187]\n",
      "epoch:11 step:8790[D loss: 0.402712, acc: 67.97%, op_acc: 35.94%] [G loss: 0.943940]\n",
      "epoch:11 step:8791[D loss: 0.443315, acc: 62.50%, op_acc: 32.03%] [G loss: 0.853460]\n",
      "epoch:11 step:8792[D loss: 0.437482, acc: 56.25%, op_acc: 32.81%] [G loss: 0.820810]\n",
      "epoch:11 step:8793[D loss: 0.415541, acc: 67.97%, op_acc: 37.50%] [G loss: 0.967410]\n",
      "epoch:11 step:8794[D loss: 0.455167, acc: 61.72%, op_acc: 32.81%] [G loss: 0.941617]\n",
      "epoch:11 step:8795[D loss: 0.476376, acc: 48.44%, op_acc: 35.16%] [G loss: 0.891574]\n",
      "epoch:11 step:8796[D loss: 0.440246, acc: 60.16%, op_acc: 26.56%] [G loss: 0.867899]\n",
      "epoch:11 step:8797[D loss: 0.423893, acc: 63.28%, op_acc: 33.59%] [G loss: 0.823623]\n",
      "epoch:11 step:8798[D loss: 0.418846, acc: 64.06%, op_acc: 36.72%] [G loss: 0.945791]\n",
      "epoch:11 step:8799[D loss: 0.446647, acc: 60.16%, op_acc: 33.59%] [G loss: 0.986538]\n",
      "epoch:11 step:8800[D loss: 0.399259, acc: 67.97%, op_acc: 41.41%] [G loss: 0.926978]\n",
      "epoch:11 step:8801[D loss: 0.470060, acc: 50.00%, op_acc: 31.25%] [G loss: 0.848704]\n",
      "epoch:11 step:8802[D loss: 0.416290, acc: 63.28%, op_acc: 38.28%] [G loss: 0.913294]\n",
      "epoch:11 step:8803[D loss: 0.433107, acc: 59.38%, op_acc: 38.28%] [G loss: 0.856495]\n",
      "epoch:11 step:8804[D loss: 0.455945, acc: 50.78%, op_acc: 32.81%] [G loss: 0.853352]\n",
      "epoch:11 step:8805[D loss: 0.447047, acc: 62.50%, op_acc: 32.03%] [G loss: 0.890625]\n",
      "epoch:11 step:8806[D loss: 0.449382, acc: 65.62%, op_acc: 34.38%] [G loss: 0.957564]\n",
      "epoch:11 step:8807[D loss: 0.434853, acc: 64.06%, op_acc: 30.47%] [G loss: 0.984077]\n",
      "epoch:11 step:8808[D loss: 0.439696, acc: 55.47%, op_acc: 32.81%] [G loss: 0.876776]\n",
      "epoch:11 step:8809[D loss: 0.458876, acc: 54.69%, op_acc: 36.72%] [G loss: 0.923245]\n",
      "epoch:11 step:8810[D loss: 0.441008, acc: 63.28%, op_acc: 35.16%] [G loss: 0.910399]\n",
      "epoch:11 step:8811[D loss: 0.458310, acc: 50.00%, op_acc: 33.59%] [G loss: 0.849204]\n",
      "epoch:11 step:8812[D loss: 0.452620, acc: 61.72%, op_acc: 30.47%] [G loss: 0.889816]\n",
      "epoch:11 step:8813[D loss: 0.448293, acc: 59.38%, op_acc: 36.72%] [G loss: 0.917427]\n",
      "epoch:11 step:8814[D loss: 0.456021, acc: 53.12%, op_acc: 35.16%] [G loss: 0.957095]\n",
      "epoch:11 step:8815[D loss: 0.443311, acc: 60.16%, op_acc: 35.94%] [G loss: 0.835740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8816[D loss: 0.496228, acc: 46.88%, op_acc: 35.94%] [G loss: 0.824840]\n",
      "epoch:11 step:8817[D loss: 0.425610, acc: 65.62%, op_acc: 34.38%] [G loss: 0.951709]\n",
      "epoch:11 step:8818[D loss: 0.450778, acc: 55.47%, op_acc: 28.91%] [G loss: 1.016497]\n",
      "epoch:11 step:8819[D loss: 0.428642, acc: 64.06%, op_acc: 39.06%] [G loss: 0.933172]\n",
      "epoch:11 step:8820[D loss: 0.425638, acc: 63.28%, op_acc: 39.84%] [G loss: 0.959322]\n",
      "epoch:11 step:8821[D loss: 0.454078, acc: 53.12%, op_acc: 35.16%] [G loss: 0.872548]\n",
      "epoch:11 step:8822[D loss: 0.431948, acc: 57.81%, op_acc: 36.72%] [G loss: 0.917550]\n",
      "epoch:11 step:8823[D loss: 0.445110, acc: 58.59%, op_acc: 36.72%] [G loss: 0.885718]\n",
      "epoch:11 step:8824[D loss: 0.419830, acc: 66.41%, op_acc: 32.81%] [G loss: 0.958143]\n",
      "epoch:11 step:8825[D loss: 0.462781, acc: 60.94%, op_acc: 33.59%] [G loss: 0.879460]\n",
      "epoch:11 step:8826[D loss: 0.457695, acc: 50.78%, op_acc: 35.94%] [G loss: 0.883281]\n",
      "epoch:11 step:8827[D loss: 0.420681, acc: 53.91%, op_acc: 34.38%] [G loss: 0.936993]\n",
      "epoch:11 step:8828[D loss: 0.410753, acc: 67.97%, op_acc: 38.28%] [G loss: 0.924016]\n",
      "epoch:11 step:8829[D loss: 0.419013, acc: 61.72%, op_acc: 32.81%] [G loss: 0.944234]\n",
      "epoch:11 step:8830[D loss: 0.426268, acc: 62.50%, op_acc: 34.38%] [G loss: 0.923908]\n",
      "epoch:11 step:8831[D loss: 0.426204, acc: 57.81%, op_acc: 32.81%] [G loss: 0.911012]\n",
      "epoch:11 step:8832[D loss: 0.422156, acc: 66.41%, op_acc: 32.81%] [G loss: 0.876826]\n",
      "epoch:11 step:8833[D loss: 0.417626, acc: 61.72%, op_acc: 36.72%] [G loss: 0.858615]\n",
      "epoch:11 step:8834[D loss: 0.454404, acc: 58.59%, op_acc: 37.50%] [G loss: 0.971664]\n",
      "epoch:11 step:8835[D loss: 0.426892, acc: 62.50%, op_acc: 34.38%] [G loss: 0.961480]\n",
      "epoch:11 step:8836[D loss: 0.400610, acc: 63.28%, op_acc: 41.41%] [G loss: 0.903522]\n",
      "epoch:11 step:8837[D loss: 0.451947, acc: 60.16%, op_acc: 37.50%] [G loss: 0.935310]\n",
      "epoch:11 step:8838[D loss: 0.438683, acc: 59.38%, op_acc: 36.72%] [G loss: 0.946450]\n",
      "epoch:11 step:8839[D loss: 0.450160, acc: 57.81%, op_acc: 33.59%] [G loss: 0.844605]\n",
      "epoch:11 step:8840[D loss: 0.451448, acc: 57.81%, op_acc: 38.28%] [G loss: 0.921069]\n",
      "epoch:11 step:8841[D loss: 0.448056, acc: 59.38%, op_acc: 30.47%] [G loss: 0.936236]\n",
      "epoch:11 step:8842[D loss: 0.424095, acc: 67.19%, op_acc: 35.94%] [G loss: 0.917477]\n",
      "epoch:11 step:8843[D loss: 0.431011, acc: 56.25%, op_acc: 41.41%] [G loss: 0.895750]\n",
      "epoch:11 step:8844[D loss: 0.416893, acc: 71.09%, op_acc: 36.72%] [G loss: 0.950150]\n",
      "epoch:11 step:8845[D loss: 0.472751, acc: 53.12%, op_acc: 35.16%] [G loss: 0.829992]\n",
      "epoch:11 step:8846[D loss: 0.460795, acc: 55.47%, op_acc: 35.94%] [G loss: 0.817446]\n",
      "epoch:11 step:8847[D loss: 0.443377, acc: 55.47%, op_acc: 36.72%] [G loss: 0.887446]\n",
      "epoch:11 step:8848[D loss: 0.439255, acc: 57.81%, op_acc: 36.72%] [G loss: 0.956692]\n",
      "epoch:11 step:8849[D loss: 0.419525, acc: 60.94%, op_acc: 35.16%] [G loss: 0.972294]\n",
      "epoch:11 step:8850[D loss: 0.456118, acc: 56.25%, op_acc: 30.47%] [G loss: 0.949022]\n",
      "epoch:11 step:8851[D loss: 0.449636, acc: 58.59%, op_acc: 33.59%] [G loss: 1.019282]\n",
      "epoch:11 step:8852[D loss: 0.441777, acc: 62.50%, op_acc: 37.50%] [G loss: 0.843164]\n",
      "epoch:11 step:8853[D loss: 0.425676, acc: 64.84%, op_acc: 36.72%] [G loss: 0.857573]\n",
      "epoch:11 step:8854[D loss: 0.464621, acc: 60.16%, op_acc: 33.59%] [G loss: 0.917557]\n",
      "epoch:11 step:8855[D loss: 0.425863, acc: 67.19%, op_acc: 32.81%] [G loss: 0.918371]\n",
      "epoch:11 step:8856[D loss: 0.424188, acc: 63.28%, op_acc: 38.28%] [G loss: 0.839520]\n",
      "epoch:11 step:8857[D loss: 0.424443, acc: 70.31%, op_acc: 39.06%] [G loss: 0.972163]\n",
      "epoch:11 step:8858[D loss: 0.450704, acc: 58.59%, op_acc: 38.28%] [G loss: 0.991736]\n",
      "epoch:11 step:8859[D loss: 0.446149, acc: 53.91%, op_acc: 39.84%] [G loss: 0.871313]\n",
      "epoch:11 step:8860[D loss: 0.407635, acc: 62.50%, op_acc: 34.38%] [G loss: 0.936614]\n",
      "epoch:11 step:8861[D loss: 0.457292, acc: 60.94%, op_acc: 35.94%] [G loss: 0.940573]\n",
      "epoch:11 step:8862[D loss: 0.448285, acc: 57.81%, op_acc: 33.59%] [G loss: 0.850276]\n",
      "epoch:11 step:8863[D loss: 0.432922, acc: 57.03%, op_acc: 39.84%] [G loss: 0.932520]\n",
      "epoch:11 step:8864[D loss: 0.455565, acc: 51.56%, op_acc: 37.50%] [G loss: 0.877829]\n",
      "epoch:11 step:8865[D loss: 0.451085, acc: 60.16%, op_acc: 33.59%] [G loss: 0.954203]\n",
      "epoch:11 step:8866[D loss: 0.424772, acc: 64.06%, op_acc: 33.59%] [G loss: 0.855326]\n",
      "epoch:11 step:8867[D loss: 0.449448, acc: 53.91%, op_acc: 33.59%] [G loss: 0.871645]\n",
      "epoch:11 step:8868[D loss: 0.420788, acc: 68.75%, op_acc: 34.38%] [G loss: 0.846506]\n",
      "epoch:11 step:8869[D loss: 0.444696, acc: 56.25%, op_acc: 38.28%] [G loss: 0.954977]\n",
      "epoch:11 step:8870[D loss: 0.459928, acc: 50.78%, op_acc: 35.94%] [G loss: 0.862711]\n",
      "epoch:11 step:8871[D loss: 0.449183, acc: 50.78%, op_acc: 38.28%] [G loss: 0.945477]\n",
      "epoch:11 step:8872[D loss: 0.475554, acc: 51.56%, op_acc: 30.47%] [G loss: 0.923565]\n",
      "epoch:11 step:8873[D loss: 0.447556, acc: 57.81%, op_acc: 31.25%] [G loss: 0.906529]\n",
      "epoch:11 step:8874[D loss: 0.413042, acc: 65.62%, op_acc: 39.06%] [G loss: 0.963284]\n",
      "epoch:11 step:8875[D loss: 0.451791, acc: 58.59%, op_acc: 33.59%] [G loss: 0.860945]\n",
      "epoch:11 step:8876[D loss: 0.411891, acc: 64.84%, op_acc: 39.06%] [G loss: 0.906254]\n",
      "epoch:11 step:8877[D loss: 0.469290, acc: 60.16%, op_acc: 29.69%] [G loss: 0.907290]\n",
      "epoch:11 step:8878[D loss: 0.447194, acc: 54.69%, op_acc: 38.28%] [G loss: 0.981296]\n",
      "epoch:11 step:8879[D loss: 0.438438, acc: 57.81%, op_acc: 33.59%] [G loss: 0.982040]\n",
      "epoch:11 step:8880[D loss: 0.455908, acc: 58.59%, op_acc: 28.91%] [G loss: 0.963840]\n",
      "epoch:11 step:8881[D loss: 0.404602, acc: 70.31%, op_acc: 39.06%] [G loss: 0.925137]\n",
      "epoch:11 step:8882[D loss: 0.447822, acc: 53.12%, op_acc: 38.28%] [G loss: 0.888918]\n",
      "epoch:11 step:8883[D loss: 0.448412, acc: 61.72%, op_acc: 33.59%] [G loss: 0.969591]\n",
      "epoch:11 step:8884[D loss: 0.441545, acc: 57.81%, op_acc: 32.03%] [G loss: 0.878246]\n",
      "epoch:11 step:8885[D loss: 0.437422, acc: 62.50%, op_acc: 36.72%] [G loss: 0.928768]\n",
      "epoch:11 step:8886[D loss: 0.469240, acc: 47.66%, op_acc: 35.94%] [G loss: 0.828134]\n",
      "epoch:11 step:8887[D loss: 0.460134, acc: 54.69%, op_acc: 37.50%] [G loss: 0.903142]\n",
      "epoch:11 step:8888[D loss: 0.430433, acc: 63.28%, op_acc: 38.28%] [G loss: 0.902517]\n",
      "epoch:11 step:8889[D loss: 0.438087, acc: 65.62%, op_acc: 35.16%] [G loss: 0.830032]\n",
      "epoch:11 step:8890[D loss: 0.447797, acc: 57.03%, op_acc: 35.16%] [G loss: 0.845614]\n",
      "epoch:11 step:8891[D loss: 0.430681, acc: 64.06%, op_acc: 37.50%] [G loss: 0.959835]\n",
      "epoch:11 step:8892[D loss: 0.463164, acc: 52.34%, op_acc: 37.50%] [G loss: 0.901528]\n",
      "epoch:11 step:8893[D loss: 0.433226, acc: 59.38%, op_acc: 35.94%] [G loss: 0.865017]\n",
      "epoch:11 step:8894[D loss: 0.454781, acc: 55.47%, op_acc: 29.69%] [G loss: 0.849986]\n",
      "epoch:11 step:8895[D loss: 0.427394, acc: 64.84%, op_acc: 38.28%] [G loss: 0.937560]\n",
      "epoch:11 step:8896[D loss: 0.434196, acc: 59.38%, op_acc: 33.59%] [G loss: 0.873417]\n",
      "epoch:11 step:8897[D loss: 0.470389, acc: 53.12%, op_acc: 34.38%] [G loss: 0.885750]\n",
      "epoch:11 step:8898[D loss: 0.451346, acc: 61.72%, op_acc: 36.72%] [G loss: 0.853560]\n",
      "epoch:11 step:8899[D loss: 0.445640, acc: 62.50%, op_acc: 30.47%] [G loss: 0.912593]\n",
      "epoch:11 step:8900[D loss: 0.468962, acc: 55.47%, op_acc: 30.47%] [G loss: 0.914230]\n",
      "epoch:11 step:8901[D loss: 0.417935, acc: 65.62%, op_acc: 36.72%] [G loss: 0.877715]\n",
      "epoch:11 step:8902[D loss: 0.432303, acc: 61.72%, op_acc: 41.41%] [G loss: 0.880595]\n",
      "epoch:11 step:8903[D loss: 0.444340, acc: 62.50%, op_acc: 32.81%] [G loss: 0.869270]\n",
      "epoch:11 step:8904[D loss: 0.452700, acc: 60.16%, op_acc: 38.28%] [G loss: 0.834874]\n",
      "epoch:11 step:8905[D loss: 0.432333, acc: 58.59%, op_acc: 36.72%] [G loss: 0.867102]\n",
      "epoch:11 step:8906[D loss: 0.449627, acc: 58.59%, op_acc: 34.38%] [G loss: 0.796408]\n",
      "epoch:11 step:8907[D loss: 0.423340, acc: 62.50%, op_acc: 41.41%] [G loss: 0.816470]\n",
      "epoch:11 step:8908[D loss: 0.433939, acc: 57.03%, op_acc: 38.28%] [G loss: 0.895322]\n",
      "epoch:11 step:8909[D loss: 0.451762, acc: 54.69%, op_acc: 32.03%] [G loss: 0.904191]\n",
      "epoch:11 step:8910[D loss: 0.413069, acc: 65.62%, op_acc: 35.94%] [G loss: 0.959633]\n",
      "epoch:11 step:8911[D loss: 0.436087, acc: 57.81%, op_acc: 37.50%] [G loss: 0.928297]\n",
      "epoch:11 step:8912[D loss: 0.468486, acc: 54.69%, op_acc: 29.69%] [G loss: 0.961362]\n",
      "epoch:11 step:8913[D loss: 0.454398, acc: 56.25%, op_acc: 34.38%] [G loss: 0.855464]\n",
      "epoch:11 step:8914[D loss: 0.444860, acc: 57.03%, op_acc: 34.38%] [G loss: 0.899188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:8915[D loss: 0.466161, acc: 56.25%, op_acc: 33.59%] [G loss: 0.861977]\n",
      "epoch:11 step:8916[D loss: 0.453247, acc: 50.78%, op_acc: 38.28%] [G loss: 0.907529]\n",
      "epoch:11 step:8917[D loss: 0.416909, acc: 65.62%, op_acc: 39.06%] [G loss: 0.892604]\n",
      "epoch:11 step:8918[D loss: 0.423979, acc: 57.81%, op_acc: 35.94%] [G loss: 0.882720]\n",
      "epoch:11 step:8919[D loss: 0.455462, acc: 51.56%, op_acc: 31.25%] [G loss: 0.903081]\n",
      "epoch:11 step:8920[D loss: 0.446548, acc: 56.25%, op_acc: 36.72%] [G loss: 0.853134]\n",
      "epoch:11 step:8921[D loss: 0.430755, acc: 56.25%, op_acc: 29.69%] [G loss: 0.918734]\n",
      "epoch:11 step:8922[D loss: 0.457717, acc: 52.34%, op_acc: 35.94%] [G loss: 0.898722]\n",
      "epoch:11 step:8923[D loss: 0.456197, acc: 57.03%, op_acc: 31.25%] [G loss: 0.924166]\n",
      "epoch:11 step:8924[D loss: 0.423983, acc: 65.62%, op_acc: 32.81%] [G loss: 0.846883]\n",
      "epoch:11 step:8925[D loss: 0.449435, acc: 51.56%, op_acc: 40.62%] [G loss: 0.872328]\n",
      "epoch:11 step:8926[D loss: 0.447598, acc: 58.59%, op_acc: 31.25%] [G loss: 0.885356]\n",
      "epoch:11 step:8927[D loss: 0.466793, acc: 57.81%, op_acc: 27.34%] [G loss: 0.912525]\n",
      "epoch:11 step:8928[D loss: 0.445871, acc: 60.16%, op_acc: 32.81%] [G loss: 0.872529]\n",
      "epoch:11 step:8929[D loss: 0.435517, acc: 51.56%, op_acc: 39.06%] [G loss: 0.880343]\n",
      "epoch:11 step:8930[D loss: 0.456397, acc: 60.16%, op_acc: 32.03%] [G loss: 0.781396]\n",
      "epoch:11 step:8931[D loss: 0.455584, acc: 54.69%, op_acc: 36.72%] [G loss: 0.867896]\n",
      "epoch:11 step:8932[D loss: 0.471595, acc: 56.25%, op_acc: 34.38%] [G loss: 0.874139]\n",
      "epoch:11 step:8933[D loss: 0.453990, acc: 52.34%, op_acc: 34.38%] [G loss: 0.852029]\n",
      "epoch:11 step:8934[D loss: 0.444886, acc: 60.94%, op_acc: 29.69%] [G loss: 0.882781]\n",
      "epoch:11 step:8935[D loss: 0.430875, acc: 63.28%, op_acc: 35.94%] [G loss: 0.885911]\n",
      "epoch:11 step:8936[D loss: 0.413832, acc: 60.16%, op_acc: 34.38%] [G loss: 0.986709]\n",
      "epoch:11 step:8937[D loss: 0.412337, acc: 66.41%, op_acc: 42.97%] [G loss: 0.913497]\n",
      "epoch:11 step:8938[D loss: 0.436835, acc: 58.59%, op_acc: 36.72%] [G loss: 0.916386]\n",
      "epoch:11 step:8939[D loss: 0.426376, acc: 64.84%, op_acc: 35.94%] [G loss: 0.935523]\n",
      "epoch:11 step:8940[D loss: 0.423330, acc: 61.72%, op_acc: 39.84%] [G loss: 0.892942]\n",
      "epoch:11 step:8941[D loss: 0.455462, acc: 57.03%, op_acc: 36.72%] [G loss: 0.882968]\n",
      "epoch:11 step:8942[D loss: 0.461973, acc: 49.22%, op_acc: 35.16%] [G loss: 0.963595]\n",
      "epoch:11 step:8943[D loss: 0.422968, acc: 71.09%, op_acc: 32.81%] [G loss: 0.930202]\n",
      "epoch:11 step:8944[D loss: 0.426226, acc: 58.59%, op_acc: 38.28%] [G loss: 0.964777]\n",
      "epoch:11 step:8945[D loss: 0.456233, acc: 53.91%, op_acc: 37.50%] [G loss: 0.953555]\n",
      "epoch:11 step:8946[D loss: 0.450392, acc: 52.34%, op_acc: 40.62%] [G loss: 0.828562]\n",
      "epoch:11 step:8947[D loss: 0.421045, acc: 57.03%, op_acc: 29.69%] [G loss: 0.957184]\n",
      "epoch:11 step:8948[D loss: 0.436081, acc: 63.28%, op_acc: 34.38%] [G loss: 0.925536]\n",
      "epoch:11 step:8949[D loss: 0.477327, acc: 47.66%, op_acc: 34.38%] [G loss: 0.785073]\n",
      "epoch:11 step:8950[D loss: 0.450507, acc: 59.38%, op_acc: 36.72%] [G loss: 0.868174]\n",
      "epoch:11 step:8951[D loss: 0.433326, acc: 67.19%, op_acc: 35.94%] [G loss: 0.891109]\n",
      "epoch:11 step:8952[D loss: 0.446729, acc: 52.34%, op_acc: 37.50%] [G loss: 0.890570]\n",
      "epoch:11 step:8953[D loss: 0.396296, acc: 64.84%, op_acc: 33.59%] [G loss: 0.867983]\n",
      "epoch:11 step:8954[D loss: 0.456507, acc: 58.59%, op_acc: 32.81%] [G loss: 0.852357]\n",
      "epoch:11 step:8955[D loss: 0.444732, acc: 60.16%, op_acc: 39.06%] [G loss: 0.870374]\n",
      "epoch:11 step:8956[D loss: 0.425305, acc: 57.03%, op_acc: 38.28%] [G loss: 0.975610]\n",
      "epoch:11 step:8957[D loss: 0.422420, acc: 60.94%, op_acc: 34.38%] [G loss: 0.893174]\n",
      "epoch:11 step:8958[D loss: 0.479450, acc: 55.47%, op_acc: 29.69%] [G loss: 0.916007]\n",
      "epoch:11 step:8959[D loss: 0.417627, acc: 67.97%, op_acc: 34.38%] [G loss: 0.904008]\n",
      "epoch:11 step:8960[D loss: 0.427889, acc: 60.94%, op_acc: 32.81%] [G loss: 0.923671]\n",
      "epoch:11 step:8961[D loss: 0.444609, acc: 54.69%, op_acc: 35.16%] [G loss: 0.941616]\n",
      "epoch:11 step:8962[D loss: 0.404747, acc: 64.06%, op_acc: 42.19%] [G loss: 0.927811]\n",
      "epoch:11 step:8963[D loss: 0.445045, acc: 60.16%, op_acc: 32.03%] [G loss: 0.942311]\n",
      "epoch:11 step:8964[D loss: 0.422121, acc: 62.50%, op_acc: 39.06%] [G loss: 0.912875]\n",
      "epoch:11 step:8965[D loss: 0.437330, acc: 59.38%, op_acc: 33.59%] [G loss: 0.848496]\n",
      "epoch:11 step:8966[D loss: 0.433489, acc: 60.94%, op_acc: 35.16%] [G loss: 0.915109]\n",
      "epoch:11 step:8967[D loss: 0.434532, acc: 60.16%, op_acc: 35.16%] [G loss: 0.888915]\n",
      "epoch:11 step:8968[D loss: 0.420393, acc: 60.94%, op_acc: 38.28%] [G loss: 0.950629]\n",
      "epoch:11 step:8969[D loss: 0.426894, acc: 65.62%, op_acc: 36.72%] [G loss: 0.883592]\n",
      "epoch:11 step:8970[D loss: 0.402435, acc: 65.62%, op_acc: 35.16%] [G loss: 0.914860]\n",
      "epoch:11 step:8971[D loss: 0.437027, acc: 59.38%, op_acc: 32.81%] [G loss: 0.883555]\n",
      "epoch:11 step:8972[D loss: 0.406287, acc: 70.31%, op_acc: 35.94%] [G loss: 0.981743]\n",
      "epoch:11 step:8973[D loss: 0.428210, acc: 56.25%, op_acc: 37.50%] [G loss: 0.899589]\n",
      "epoch:11 step:8974[D loss: 0.423439, acc: 64.06%, op_acc: 42.97%] [G loss: 0.943569]\n",
      "epoch:11 step:8975[D loss: 0.435448, acc: 63.28%, op_acc: 35.16%] [G loss: 0.885998]\n",
      "epoch:11 step:8976[D loss: 0.410418, acc: 61.72%, op_acc: 42.97%] [G loss: 0.803680]\n",
      "epoch:11 step:8977[D loss: 0.416806, acc: 60.94%, op_acc: 36.72%] [G loss: 0.887426]\n",
      "epoch:11 step:8978[D loss: 0.441168, acc: 56.25%, op_acc: 33.59%] [G loss: 0.920254]\n",
      "epoch:11 step:8979[D loss: 0.438533, acc: 61.72%, op_acc: 39.84%] [G loss: 0.857693]\n",
      "epoch:11 step:8980[D loss: 0.427291, acc: 64.06%, op_acc: 39.84%] [G loss: 0.907474]\n",
      "epoch:11 step:8981[D loss: 0.431812, acc: 63.28%, op_acc: 38.28%] [G loss: 0.924377]\n",
      "epoch:11 step:8982[D loss: 0.412004, acc: 60.94%, op_acc: 44.53%] [G loss: 0.957075]\n",
      "epoch:11 step:8983[D loss: 0.406943, acc: 59.38%, op_acc: 42.19%] [G loss: 0.912824]\n",
      "epoch:11 step:8984[D loss: 0.436486, acc: 60.94%, op_acc: 35.94%] [G loss: 0.996841]\n",
      "epoch:11 step:8985[D loss: 0.430487, acc: 62.50%, op_acc: 35.94%] [G loss: 0.905823]\n",
      "epoch:11 step:8986[D loss: 0.456907, acc: 60.94%, op_acc: 32.81%] [G loss: 0.916349]\n",
      "epoch:11 step:8987[D loss: 0.441236, acc: 57.81%, op_acc: 39.06%] [G loss: 0.907947]\n",
      "epoch:11 step:8988[D loss: 0.444469, acc: 54.69%, op_acc: 36.72%] [G loss: 0.810749]\n",
      "epoch:11 step:8989[D loss: 0.453964, acc: 52.34%, op_acc: 32.03%] [G loss: 0.804959]\n",
      "epoch:11 step:8990[D loss: 0.416154, acc: 59.38%, op_acc: 41.41%] [G loss: 0.904399]\n",
      "epoch:11 step:8991[D loss: 0.422861, acc: 60.16%, op_acc: 37.50%] [G loss: 0.896527]\n",
      "epoch:11 step:8992[D loss: 0.424313, acc: 60.94%, op_acc: 38.28%] [G loss: 0.887174]\n",
      "epoch:11 step:8993[D loss: 0.417340, acc: 69.53%, op_acc: 34.38%] [G loss: 0.931139]\n",
      "epoch:11 step:8994[D loss: 0.429797, acc: 59.38%, op_acc: 41.41%] [G loss: 0.955302]\n",
      "epoch:11 step:8995[D loss: 0.394671, acc: 68.75%, op_acc: 46.09%] [G loss: 0.962105]\n",
      "epoch:11 step:8996[D loss: 0.445874, acc: 55.47%, op_acc: 39.06%] [G loss: 0.931854]\n",
      "epoch:11 step:8997[D loss: 0.434671, acc: 58.59%, op_acc: 34.38%] [G loss: 0.967323]\n",
      "epoch:11 step:8998[D loss: 0.414069, acc: 72.66%, op_acc: 32.03%] [G loss: 0.916494]\n",
      "epoch:11 step:8999[D loss: 0.426055, acc: 61.72%, op_acc: 37.50%] [G loss: 0.912339]\n",
      "epoch:11 step:9000[D loss: 0.452123, acc: 52.34%, op_acc: 34.38%] [G loss: 0.931816]\n",
      "epoch:11 step:9001[D loss: 0.402463, acc: 66.41%, op_acc: 39.84%] [G loss: 0.921397]\n",
      "epoch:11 step:9002[D loss: 0.448115, acc: 58.59%, op_acc: 35.94%] [G loss: 0.914997]\n",
      "epoch:11 step:9003[D loss: 0.444214, acc: 57.81%, op_acc: 34.38%] [G loss: 0.876367]\n",
      "epoch:11 step:9004[D loss: 0.433638, acc: 59.38%, op_acc: 39.84%] [G loss: 0.906819]\n",
      "epoch:11 step:9005[D loss: 0.433323, acc: 54.69%, op_acc: 33.59%] [G loss: 0.929103]\n",
      "epoch:11 step:9006[D loss: 0.442473, acc: 57.81%, op_acc: 39.06%] [G loss: 0.836433]\n",
      "epoch:11 step:9007[D loss: 0.442610, acc: 56.25%, op_acc: 35.16%] [G loss: 0.910727]\n",
      "epoch:11 step:9008[D loss: 0.438226, acc: 65.62%, op_acc: 38.28%] [G loss: 0.877883]\n",
      "epoch:11 step:9009[D loss: 0.411487, acc: 66.41%, op_acc: 36.72%] [G loss: 0.965855]\n",
      "epoch:11 step:9010[D loss: 0.429106, acc: 58.59%, op_acc: 34.38%] [G loss: 0.798873]\n",
      "epoch:11 step:9011[D loss: 0.459583, acc: 56.25%, op_acc: 32.03%] [G loss: 0.866527]\n",
      "epoch:11 step:9012[D loss: 0.453865, acc: 54.69%, op_acc: 36.72%] [G loss: 0.861787]\n",
      "epoch:11 step:9013[D loss: 0.463018, acc: 54.69%, op_acc: 35.16%] [G loss: 0.897123]\n",
      "epoch:11 step:9014[D loss: 0.426740, acc: 60.16%, op_acc: 35.94%] [G loss: 1.038012]\n",
      "epoch:11 step:9015[D loss: 0.470074, acc: 50.00%, op_acc: 28.12%] [G loss: 0.958292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9016[D loss: 0.441850, acc: 58.59%, op_acc: 32.81%] [G loss: 0.996824]\n",
      "epoch:11 step:9017[D loss: 0.458790, acc: 54.69%, op_acc: 34.38%] [G loss: 0.837399]\n",
      "epoch:11 step:9018[D loss: 0.432708, acc: 64.84%, op_acc: 33.59%] [G loss: 0.945392]\n",
      "epoch:11 step:9019[D loss: 0.472791, acc: 51.56%, op_acc: 36.72%] [G loss: 0.888969]\n",
      "epoch:11 step:9020[D loss: 0.460317, acc: 52.34%, op_acc: 32.81%] [G loss: 0.914889]\n",
      "epoch:11 step:9021[D loss: 0.439088, acc: 60.16%, op_acc: 37.50%] [G loss: 0.911270]\n",
      "epoch:11 step:9022[D loss: 0.478022, acc: 55.47%, op_acc: 32.03%] [G loss: 0.880345]\n",
      "epoch:11 step:9023[D loss: 0.421602, acc: 57.81%, op_acc: 40.62%] [G loss: 0.849481]\n",
      "epoch:11 step:9024[D loss: 0.419265, acc: 67.19%, op_acc: 33.59%] [G loss: 0.917396]\n",
      "epoch:11 step:9025[D loss: 0.418470, acc: 60.94%, op_acc: 40.62%] [G loss: 0.857050]\n",
      "epoch:11 step:9026[D loss: 0.413813, acc: 61.72%, op_acc: 42.97%] [G loss: 0.952900]\n",
      "epoch:11 step:9027[D loss: 0.444858, acc: 61.72%, op_acc: 29.69%] [G loss: 0.842919]\n",
      "epoch:11 step:9028[D loss: 0.450967, acc: 59.38%, op_acc: 32.81%] [G loss: 0.922574]\n",
      "epoch:11 step:9029[D loss: 0.437456, acc: 60.94%, op_acc: 35.16%] [G loss: 0.909998]\n",
      "epoch:11 step:9030[D loss: 0.417487, acc: 67.97%, op_acc: 35.94%] [G loss: 0.956048]\n",
      "epoch:11 step:9031[D loss: 0.452704, acc: 49.22%, op_acc: 37.50%] [G loss: 0.826828]\n",
      "epoch:11 step:9032[D loss: 0.404440, acc: 72.66%, op_acc: 38.28%] [G loss: 0.990322]\n",
      "epoch:11 step:9033[D loss: 0.409496, acc: 60.94%, op_acc: 40.62%] [G loss: 0.991473]\n",
      "epoch:11 step:9034[D loss: 0.443413, acc: 60.16%, op_acc: 35.94%] [G loss: 0.915696]\n",
      "epoch:11 step:9035[D loss: 0.409881, acc: 67.97%, op_acc: 42.19%] [G loss: 0.869563]\n",
      "epoch:11 step:9036[D loss: 0.457430, acc: 54.69%, op_acc: 35.16%] [G loss: 0.880979]\n",
      "epoch:11 step:9037[D loss: 0.438156, acc: 63.28%, op_acc: 32.81%] [G loss: 0.870729]\n",
      "epoch:11 step:9038[D loss: 0.490798, acc: 52.34%, op_acc: 26.56%] [G loss: 0.886891]\n",
      "epoch:11 step:9039[D loss: 0.420587, acc: 58.59%, op_acc: 39.06%] [G loss: 0.871551]\n",
      "epoch:11 step:9040[D loss: 0.402396, acc: 62.50%, op_acc: 39.06%] [G loss: 1.004404]\n",
      "epoch:11 step:9041[D loss: 0.428769, acc: 63.28%, op_acc: 30.47%] [G loss: 0.977032]\n",
      "epoch:11 step:9042[D loss: 0.445330, acc: 53.91%, op_acc: 39.84%] [G loss: 0.864468]\n",
      "epoch:11 step:9043[D loss: 0.423618, acc: 64.06%, op_acc: 35.94%] [G loss: 0.997902]\n",
      "epoch:11 step:9044[D loss: 0.447441, acc: 50.00%, op_acc: 37.50%] [G loss: 0.877487]\n",
      "epoch:11 step:9045[D loss: 0.422560, acc: 61.72%, op_acc: 32.81%] [G loss: 0.961910]\n",
      "epoch:11 step:9046[D loss: 0.448648, acc: 51.56%, op_acc: 33.59%] [G loss: 0.832984]\n",
      "epoch:11 step:9047[D loss: 0.459655, acc: 61.72%, op_acc: 31.25%] [G loss: 0.944520]\n",
      "epoch:11 step:9048[D loss: 0.456424, acc: 56.25%, op_acc: 35.94%] [G loss: 0.901325]\n",
      "epoch:11 step:9049[D loss: 0.433359, acc: 56.25%, op_acc: 34.38%] [G loss: 0.835928]\n",
      "epoch:11 step:9050[D loss: 0.424870, acc: 54.69%, op_acc: 38.28%] [G loss: 0.922247]\n",
      "epoch:11 step:9051[D loss: 0.401815, acc: 68.75%, op_acc: 36.72%] [G loss: 0.842164]\n",
      "epoch:11 step:9052[D loss: 0.409635, acc: 63.28%, op_acc: 42.97%] [G loss: 0.849659]\n",
      "epoch:11 step:9053[D loss: 0.413304, acc: 60.94%, op_acc: 35.16%] [G loss: 0.835331]\n",
      "epoch:11 step:9054[D loss: 0.448639, acc: 57.81%, op_acc: 35.94%] [G loss: 0.870114]\n",
      "epoch:11 step:9055[D loss: 0.452548, acc: 58.59%, op_acc: 36.72%] [G loss: 0.909457]\n",
      "epoch:11 step:9056[D loss: 0.431331, acc: 62.50%, op_acc: 37.50%] [G loss: 0.935240]\n",
      "epoch:11 step:9057[D loss: 0.448018, acc: 53.91%, op_acc: 38.28%] [G loss: 0.878554]\n",
      "epoch:11 step:9058[D loss: 0.437682, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889016]\n",
      "epoch:11 step:9059[D loss: 0.425671, acc: 63.28%, op_acc: 35.94%] [G loss: 0.810252]\n",
      "epoch:11 step:9060[D loss: 0.408414, acc: 67.97%, op_acc: 36.72%] [G loss: 0.922309]\n",
      "epoch:11 step:9061[D loss: 0.409600, acc: 65.62%, op_acc: 35.16%] [G loss: 0.973340]\n",
      "epoch:11 step:9062[D loss: 0.476745, acc: 56.25%, op_acc: 26.56%] [G loss: 0.953845]\n",
      "epoch:11 step:9063[D loss: 0.449968, acc: 56.25%, op_acc: 33.59%] [G loss: 0.921431]\n",
      "epoch:11 step:9064[D loss: 0.419845, acc: 59.38%, op_acc: 39.06%] [G loss: 0.970056]\n",
      "epoch:11 step:9065[D loss: 0.429987, acc: 61.72%, op_acc: 39.06%] [G loss: 0.857635]\n",
      "epoch:11 step:9066[D loss: 0.439475, acc: 49.22%, op_acc: 39.06%] [G loss: 0.870191]\n",
      "epoch:11 step:9067[D loss: 0.455494, acc: 61.72%, op_acc: 30.47%] [G loss: 0.797225]\n",
      "epoch:11 step:9068[D loss: 0.432069, acc: 63.28%, op_acc: 40.62%] [G loss: 0.867115]\n",
      "epoch:11 step:9069[D loss: 0.438361, acc: 51.56%, op_acc: 38.28%] [G loss: 0.919105]\n",
      "epoch:11 step:9070[D loss: 0.439373, acc: 53.12%, op_acc: 39.06%] [G loss: 0.844801]\n",
      "epoch:11 step:9071[D loss: 0.466614, acc: 57.03%, op_acc: 34.38%] [G loss: 0.867314]\n",
      "epoch:11 step:9072[D loss: 0.468427, acc: 64.84%, op_acc: 28.91%] [G loss: 0.878400]\n",
      "epoch:11 step:9073[D loss: 0.451769, acc: 57.81%, op_acc: 35.16%] [G loss: 0.966412]\n",
      "epoch:11 step:9074[D loss: 0.420450, acc: 63.28%, op_acc: 33.59%] [G loss: 0.870396]\n",
      "epoch:11 step:9075[D loss: 0.437926, acc: 62.50%, op_acc: 40.62%] [G loss: 0.872340]\n",
      "epoch:11 step:9076[D loss: 0.455088, acc: 58.59%, op_acc: 32.81%] [G loss: 0.844869]\n",
      "epoch:11 step:9077[D loss: 0.436452, acc: 59.38%, op_acc: 32.03%] [G loss: 0.859508]\n",
      "epoch:11 step:9078[D loss: 0.448212, acc: 54.69%, op_acc: 37.50%] [G loss: 0.863206]\n",
      "epoch:11 step:9079[D loss: 0.453694, acc: 55.47%, op_acc: 34.38%] [G loss: 0.888101]\n",
      "epoch:11 step:9080[D loss: 0.460339, acc: 53.91%, op_acc: 38.28%] [G loss: 0.877455]\n",
      "epoch:11 step:9081[D loss: 0.410159, acc: 64.06%, op_acc: 37.50%] [G loss: 0.931286]\n",
      "epoch:11 step:9082[D loss: 0.484873, acc: 54.69%, op_acc: 31.25%] [G loss: 0.866407]\n",
      "epoch:11 step:9083[D loss: 0.416595, acc: 61.72%, op_acc: 38.28%] [G loss: 0.945027]\n",
      "epoch:11 step:9084[D loss: 0.463804, acc: 55.47%, op_acc: 30.47%] [G loss: 0.873659]\n",
      "epoch:11 step:9085[D loss: 0.392385, acc: 71.09%, op_acc: 39.06%] [G loss: 0.924565]\n",
      "epoch:11 step:9086[D loss: 0.426569, acc: 65.62%, op_acc: 35.94%] [G loss: 0.850389]\n",
      "epoch:11 step:9087[D loss: 0.447342, acc: 59.38%, op_acc: 34.38%] [G loss: 0.962459]\n",
      "epoch:11 step:9088[D loss: 0.434276, acc: 60.16%, op_acc: 39.06%] [G loss: 0.884510]\n",
      "epoch:11 step:9089[D loss: 0.477104, acc: 49.22%, op_acc: 32.81%] [G loss: 0.837397]\n",
      "epoch:11 step:9090[D loss: 0.456460, acc: 54.69%, op_acc: 39.84%] [G loss: 0.899916]\n",
      "epoch:11 step:9091[D loss: 0.420273, acc: 62.50%, op_acc: 39.06%] [G loss: 0.841301]\n",
      "epoch:11 step:9092[D loss: 0.440270, acc: 64.06%, op_acc: 32.03%] [G loss: 0.871418]\n",
      "epoch:11 step:9093[D loss: 0.421486, acc: 64.06%, op_acc: 42.19%] [G loss: 0.844525]\n",
      "epoch:11 step:9094[D loss: 0.410119, acc: 69.53%, op_acc: 32.81%] [G loss: 0.926114]\n",
      "epoch:11 step:9095[D loss: 0.464289, acc: 55.47%, op_acc: 36.72%] [G loss: 0.886011]\n",
      "epoch:11 step:9096[D loss: 0.460195, acc: 52.34%, op_acc: 31.25%] [G loss: 0.863925]\n",
      "epoch:11 step:9097[D loss: 0.437333, acc: 58.59%, op_acc: 40.62%] [G loss: 0.883874]\n",
      "epoch:11 step:9098[D loss: 0.411335, acc: 63.28%, op_acc: 44.53%] [G loss: 0.902292]\n",
      "epoch:11 step:9099[D loss: 0.420080, acc: 62.50%, op_acc: 38.28%] [G loss: 1.013174]\n",
      "epoch:11 step:9100[D loss: 0.473527, acc: 51.56%, op_acc: 35.16%] [G loss: 0.798359]\n",
      "epoch:11 step:9101[D loss: 0.450810, acc: 54.69%, op_acc: 37.50%] [G loss: 0.862505]\n",
      "epoch:11 step:9102[D loss: 0.417577, acc: 67.97%, op_acc: 37.50%] [G loss: 0.881122]\n",
      "epoch:11 step:9103[D loss: 0.466955, acc: 57.03%, op_acc: 33.59%] [G loss: 0.830798]\n",
      "epoch:11 step:9104[D loss: 0.496371, acc: 50.00%, op_acc: 28.91%] [G loss: 0.855250]\n",
      "epoch:11 step:9105[D loss: 0.429524, acc: 64.84%, op_acc: 34.38%] [G loss: 0.871557]\n",
      "epoch:11 step:9106[D loss: 0.436004, acc: 64.84%, op_acc: 34.38%] [G loss: 0.931658]\n",
      "epoch:11 step:9107[D loss: 0.418583, acc: 64.06%, op_acc: 33.59%] [G loss: 1.004549]\n",
      "epoch:11 step:9108[D loss: 0.481632, acc: 52.34%, op_acc: 35.16%] [G loss: 0.887656]\n",
      "epoch:11 step:9109[D loss: 0.418910, acc: 70.31%, op_acc: 35.16%] [G loss: 0.935898]\n",
      "epoch:11 step:9110[D loss: 0.415325, acc: 65.62%, op_acc: 37.50%] [G loss: 0.865956]\n",
      "epoch:11 step:9111[D loss: 0.426384, acc: 57.81%, op_acc: 42.97%] [G loss: 0.957536]\n",
      "epoch:11 step:9112[D loss: 0.433342, acc: 64.84%, op_acc: 38.28%] [G loss: 0.862131]\n",
      "epoch:11 step:9113[D loss: 0.465246, acc: 51.56%, op_acc: 35.94%] [G loss: 0.873888]\n",
      "epoch:11 step:9114[D loss: 0.435442, acc: 55.47%, op_acc: 38.28%] [G loss: 0.882407]\n",
      "epoch:11 step:9115[D loss: 0.429878, acc: 60.16%, op_acc: 41.41%] [G loss: 0.873753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9116[D loss: 0.425890, acc: 63.28%, op_acc: 29.69%] [G loss: 0.929707]\n",
      "epoch:11 step:9117[D loss: 0.455503, acc: 64.06%, op_acc: 30.47%] [G loss: 0.903277]\n",
      "epoch:11 step:9118[D loss: 0.452356, acc: 55.47%, op_acc: 32.81%] [G loss: 0.934582]\n",
      "epoch:11 step:9119[D loss: 0.454118, acc: 53.12%, op_acc: 33.59%] [G loss: 0.848992]\n",
      "epoch:11 step:9120[D loss: 0.401715, acc: 64.06%, op_acc: 39.84%] [G loss: 0.943954]\n",
      "epoch:11 step:9121[D loss: 0.419402, acc: 68.75%, op_acc: 34.38%] [G loss: 0.826803]\n",
      "epoch:11 step:9122[D loss: 0.444245, acc: 54.69%, op_acc: 32.81%] [G loss: 0.923138]\n",
      "epoch:11 step:9123[D loss: 0.460827, acc: 56.25%, op_acc: 31.25%] [G loss: 0.866556]\n",
      "epoch:11 step:9124[D loss: 0.403724, acc: 64.84%, op_acc: 39.84%] [G loss: 0.888893]\n",
      "epoch:11 step:9125[D loss: 0.415742, acc: 54.69%, op_acc: 44.53%] [G loss: 0.982192]\n",
      "epoch:11 step:9126[D loss: 0.457812, acc: 57.03%, op_acc: 30.47%] [G loss: 0.878967]\n",
      "epoch:11 step:9127[D loss: 0.415405, acc: 60.94%, op_acc: 35.94%] [G loss: 0.944940]\n",
      "epoch:11 step:9128[D loss: 0.464530, acc: 57.03%, op_acc: 36.72%] [G loss: 0.883090]\n",
      "epoch:11 step:9129[D loss: 0.433164, acc: 56.25%, op_acc: 38.28%] [G loss: 0.917660]\n",
      "epoch:11 step:9130[D loss: 0.440195, acc: 60.16%, op_acc: 32.81%] [G loss: 0.935243]\n",
      "epoch:11 step:9131[D loss: 0.415637, acc: 64.84%, op_acc: 38.28%] [G loss: 0.905813]\n",
      "epoch:11 step:9132[D loss: 0.405362, acc: 64.06%, op_acc: 43.75%] [G loss: 1.020354]\n",
      "epoch:11 step:9133[D loss: 0.433482, acc: 57.03%, op_acc: 34.38%] [G loss: 0.931363]\n",
      "epoch:11 step:9134[D loss: 0.425533, acc: 53.12%, op_acc: 31.25%] [G loss: 0.952655]\n",
      "epoch:11 step:9135[D loss: 0.430147, acc: 57.03%, op_acc: 35.16%] [G loss: 0.915039]\n",
      "epoch:11 step:9136[D loss: 0.424953, acc: 60.16%, op_acc: 35.94%] [G loss: 0.960631]\n",
      "epoch:11 step:9137[D loss: 0.429559, acc: 60.94%, op_acc: 41.41%] [G loss: 0.956354]\n",
      "epoch:11 step:9138[D loss: 0.477803, acc: 53.91%, op_acc: 34.38%] [G loss: 0.849081]\n",
      "epoch:11 step:9139[D loss: 0.447216, acc: 54.69%, op_acc: 38.28%] [G loss: 1.016090]\n",
      "epoch:11 step:9140[D loss: 0.436832, acc: 62.50%, op_acc: 41.41%] [G loss: 0.857879]\n",
      "epoch:11 step:9141[D loss: 0.459802, acc: 58.59%, op_acc: 35.16%] [G loss: 0.919732]\n",
      "epoch:11 step:9142[D loss: 0.444901, acc: 50.78%, op_acc: 39.06%] [G loss: 0.863937]\n",
      "epoch:11 step:9143[D loss: 0.470160, acc: 60.16%, op_acc: 34.38%] [G loss: 0.902196]\n",
      "epoch:11 step:9144[D loss: 0.440522, acc: 53.12%, op_acc: 33.59%] [G loss: 0.914521]\n",
      "epoch:11 step:9145[D loss: 0.444166, acc: 57.81%, op_acc: 36.72%] [G loss: 0.893465]\n",
      "epoch:11 step:9146[D loss: 0.445083, acc: 56.25%, op_acc: 35.16%] [G loss: 0.920335]\n",
      "epoch:11 step:9147[D loss: 0.428912, acc: 57.81%, op_acc: 36.72%] [G loss: 0.918542]\n",
      "epoch:11 step:9148[D loss: 0.465992, acc: 57.03%, op_acc: 34.38%] [G loss: 0.948891]\n",
      "epoch:11 step:9149[D loss: 0.417993, acc: 57.81%, op_acc: 43.75%] [G loss: 0.875433]\n",
      "epoch:11 step:9150[D loss: 0.390870, acc: 66.41%, op_acc: 45.31%] [G loss: 0.934501]\n",
      "epoch:11 step:9151[D loss: 0.442548, acc: 62.50%, op_acc: 35.16%] [G loss: 0.841997]\n",
      "epoch:11 step:9152[D loss: 0.424399, acc: 60.16%, op_acc: 40.62%] [G loss: 0.953508]\n",
      "epoch:11 step:9153[D loss: 0.443802, acc: 57.03%, op_acc: 32.03%] [G loss: 0.920514]\n",
      "epoch:11 step:9154[D loss: 0.432124, acc: 58.59%, op_acc: 39.06%] [G loss: 0.805876]\n",
      "epoch:11 step:9155[D loss: 0.409568, acc: 62.50%, op_acc: 38.28%] [G loss: 0.958802]\n",
      "epoch:11 step:9156[D loss: 0.421389, acc: 67.19%, op_acc: 36.72%] [G loss: 0.989025]\n",
      "epoch:11 step:9157[D loss: 0.408514, acc: 66.41%, op_acc: 42.97%] [G loss: 0.882444]\n",
      "epoch:11 step:9158[D loss: 0.450096, acc: 50.00%, op_acc: 36.72%] [G loss: 0.955197]\n",
      "epoch:11 step:9159[D loss: 0.433357, acc: 62.50%, op_acc: 39.84%] [G loss: 0.871841]\n",
      "epoch:11 step:9160[D loss: 0.418086, acc: 59.38%, op_acc: 39.06%] [G loss: 0.904186]\n",
      "epoch:11 step:9161[D loss: 0.450332, acc: 53.91%, op_acc: 34.38%] [G loss: 0.836106]\n",
      "epoch:11 step:9162[D loss: 0.436243, acc: 53.91%, op_acc: 42.19%] [G loss: 0.923510]\n",
      "epoch:11 step:9163[D loss: 0.437166, acc: 60.16%, op_acc: 32.03%] [G loss: 0.913645]\n",
      "epoch:11 step:9164[D loss: 0.465304, acc: 48.44%, op_acc: 33.59%] [G loss: 0.844368]\n",
      "epoch:11 step:9165[D loss: 0.471906, acc: 59.38%, op_acc: 28.12%] [G loss: 0.952712]\n",
      "epoch:11 step:9166[D loss: 0.436159, acc: 58.59%, op_acc: 35.94%] [G loss: 0.934698]\n",
      "epoch:11 step:9167[D loss: 0.447311, acc: 57.03%, op_acc: 32.03%] [G loss: 0.954935]\n",
      "epoch:11 step:9168[D loss: 0.487249, acc: 47.66%, op_acc: 32.81%] [G loss: 0.777048]\n",
      "epoch:11 step:9169[D loss: 0.464991, acc: 56.25%, op_acc: 28.91%] [G loss: 0.941416]\n",
      "epoch:11 step:9170[D loss: 0.440469, acc: 58.59%, op_acc: 36.72%] [G loss: 0.858625]\n",
      "epoch:11 step:9171[D loss: 0.448430, acc: 59.38%, op_acc: 30.47%] [G loss: 0.887861]\n",
      "epoch:11 step:9172[D loss: 0.463457, acc: 59.38%, op_acc: 32.03%] [G loss: 0.897282]\n",
      "epoch:11 step:9173[D loss: 0.414509, acc: 65.62%, op_acc: 34.38%] [G loss: 0.932150]\n",
      "epoch:11 step:9174[D loss: 0.418974, acc: 62.50%, op_acc: 35.94%] [G loss: 0.870106]\n",
      "epoch:11 step:9175[D loss: 0.461528, acc: 58.59%, op_acc: 29.69%] [G loss: 0.847555]\n",
      "epoch:11 step:9176[D loss: 0.417667, acc: 58.59%, op_acc: 35.94%] [G loss: 0.877404]\n",
      "epoch:11 step:9177[D loss: 0.450102, acc: 61.72%, op_acc: 28.12%] [G loss: 0.912843]\n",
      "epoch:11 step:9178[D loss: 0.423882, acc: 64.06%, op_acc: 29.69%] [G loss: 0.929919]\n",
      "epoch:11 step:9179[D loss: 0.436604, acc: 58.59%, op_acc: 35.94%] [G loss: 0.891342]\n",
      "epoch:11 step:9180[D loss: 0.426854, acc: 67.19%, op_acc: 35.94%] [G loss: 0.882033]\n",
      "epoch:11 step:9181[D loss: 0.445521, acc: 52.34%, op_acc: 35.16%] [G loss: 0.886858]\n",
      "epoch:11 step:9182[D loss: 0.418702, acc: 66.41%, op_acc: 32.03%] [G loss: 0.924280]\n",
      "epoch:11 step:9183[D loss: 0.446328, acc: 60.16%, op_acc: 30.47%] [G loss: 0.859225]\n",
      "epoch:11 step:9184[D loss: 0.436980, acc: 63.28%, op_acc: 32.03%] [G loss: 0.820684]\n",
      "epoch:11 step:9185[D loss: 0.412958, acc: 65.62%, op_acc: 28.12%] [G loss: 0.932531]\n",
      "epoch:11 step:9186[D loss: 0.412949, acc: 72.66%, op_acc: 33.59%] [G loss: 0.934394]\n",
      "epoch:11 step:9187[D loss: 0.435407, acc: 53.91%, op_acc: 31.25%] [G loss: 0.930848]\n",
      "epoch:11 step:9188[D loss: 0.402547, acc: 71.09%, op_acc: 36.72%] [G loss: 0.908613]\n",
      "epoch:11 step:9189[D loss: 0.419617, acc: 67.19%, op_acc: 35.94%] [G loss: 0.948383]\n",
      "epoch:11 step:9190[D loss: 0.463514, acc: 58.59%, op_acc: 28.12%] [G loss: 0.886905]\n",
      "epoch:11 step:9191[D loss: 0.451877, acc: 57.81%, op_acc: 36.72%] [G loss: 0.740068]\n",
      "epoch:11 step:9192[D loss: 0.446864, acc: 60.16%, op_acc: 32.81%] [G loss: 0.954360]\n",
      "epoch:11 step:9193[D loss: 0.415440, acc: 57.81%, op_acc: 39.84%] [G loss: 0.951929]\n",
      "epoch:11 step:9194[D loss: 0.397322, acc: 62.50%, op_acc: 42.19%] [G loss: 0.860409]\n",
      "epoch:11 step:9195[D loss: 0.482203, acc: 54.69%, op_acc: 28.91%] [G loss: 0.786669]\n",
      "epoch:11 step:9196[D loss: 0.447885, acc: 54.69%, op_acc: 34.38%] [G loss: 0.926077]\n",
      "epoch:11 step:9197[D loss: 0.406792, acc: 70.31%, op_acc: 36.72%] [G loss: 0.920121]\n",
      "epoch:11 step:9198[D loss: 0.412816, acc: 62.50%, op_acc: 40.62%] [G loss: 0.913907]\n",
      "epoch:11 step:9199[D loss: 0.431931, acc: 57.81%, op_acc: 32.03%] [G loss: 0.842377]\n",
      "epoch:11 step:9200[D loss: 0.455082, acc: 54.69%, op_acc: 36.72%] [G loss: 0.899129]\n",
      "epoch:11 step:9201[D loss: 0.440591, acc: 59.38%, op_acc: 30.47%] [G loss: 0.884108]\n",
      "epoch:11 step:9202[D loss: 0.473866, acc: 53.91%, op_acc: 37.50%] [G loss: 0.808555]\n",
      "epoch:11 step:9203[D loss: 0.420295, acc: 65.62%, op_acc: 30.47%] [G loss: 0.946694]\n",
      "epoch:11 step:9204[D loss: 0.459900, acc: 52.34%, op_acc: 32.81%] [G loss: 0.887990]\n",
      "epoch:11 step:9205[D loss: 0.442409, acc: 53.12%, op_acc: 39.06%] [G loss: 0.855783]\n",
      "epoch:11 step:9206[D loss: 0.430840, acc: 57.81%, op_acc: 38.28%] [G loss: 0.880968]\n",
      "epoch:11 step:9207[D loss: 0.433892, acc: 56.25%, op_acc: 37.50%] [G loss: 0.874868]\n",
      "epoch:11 step:9208[D loss: 0.440791, acc: 60.16%, op_acc: 33.59%] [G loss: 0.908362]\n",
      "epoch:11 step:9209[D loss: 0.415211, acc: 64.06%, op_acc: 42.19%] [G loss: 0.806539]\n",
      "epoch:11 step:9210[D loss: 0.489319, acc: 53.91%, op_acc: 33.59%] [G loss: 0.891511]\n",
      "epoch:11 step:9211[D loss: 0.446700, acc: 60.94%, op_acc: 36.72%] [G loss: 0.880084]\n",
      "epoch:11 step:9212[D loss: 0.433446, acc: 60.16%, op_acc: 38.28%] [G loss: 0.892846]\n",
      "epoch:11 step:9213[D loss: 0.459946, acc: 61.72%, op_acc: 28.91%] [G loss: 0.949006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9214[D loss: 0.462018, acc: 57.03%, op_acc: 33.59%] [G loss: 0.822261]\n",
      "epoch:11 step:9215[D loss: 0.459755, acc: 50.78%, op_acc: 38.28%] [G loss: 0.875146]\n",
      "epoch:11 step:9216[D loss: 0.454395, acc: 51.56%, op_acc: 38.28%] [G loss: 0.868433]\n",
      "epoch:11 step:9217[D loss: 0.401039, acc: 64.06%, op_acc: 39.84%] [G loss: 0.921485]\n",
      "epoch:11 step:9218[D loss: 0.468593, acc: 50.78%, op_acc: 33.59%] [G loss: 0.871993]\n",
      "epoch:11 step:9219[D loss: 0.434849, acc: 59.38%, op_acc: 32.03%] [G loss: 0.956930]\n",
      "epoch:11 step:9220[D loss: 0.468035, acc: 53.91%, op_acc: 30.47%] [G loss: 0.842296]\n",
      "epoch:11 step:9221[D loss: 0.414796, acc: 58.59%, op_acc: 39.06%] [G loss: 0.883806]\n",
      "epoch:11 step:9222[D loss: 0.452447, acc: 61.72%, op_acc: 32.81%] [G loss: 0.860182]\n",
      "epoch:11 step:9223[D loss: 0.453437, acc: 57.81%, op_acc: 35.94%] [G loss: 0.785213]\n",
      "epoch:11 step:9224[D loss: 0.413584, acc: 59.38%, op_acc: 33.59%] [G loss: 0.883894]\n",
      "epoch:11 step:9225[D loss: 0.438605, acc: 57.03%, op_acc: 39.06%] [G loss: 0.877802]\n",
      "epoch:11 step:9226[D loss: 0.417911, acc: 64.84%, op_acc: 35.94%] [G loss: 0.870663]\n",
      "epoch:11 step:9227[D loss: 0.428130, acc: 55.47%, op_acc: 38.28%] [G loss: 0.841395]\n",
      "epoch:11 step:9228[D loss: 0.427567, acc: 59.38%, op_acc: 29.69%] [G loss: 0.863807]\n",
      "epoch:11 step:9229[D loss: 0.443946, acc: 59.38%, op_acc: 34.38%] [G loss: 0.860945]\n",
      "epoch:11 step:9230[D loss: 0.443501, acc: 59.38%, op_acc: 39.84%] [G loss: 0.968648]\n",
      "epoch:11 step:9231[D loss: 0.428078, acc: 66.41%, op_acc: 33.59%] [G loss: 0.936801]\n",
      "epoch:11 step:9232[D loss: 0.445944, acc: 57.03%, op_acc: 34.38%] [G loss: 0.956935]\n",
      "epoch:11 step:9233[D loss: 0.427710, acc: 66.41%, op_acc: 41.41%] [G loss: 0.898880]\n",
      "epoch:11 step:9234[D loss: 0.433497, acc: 57.03%, op_acc: 35.94%] [G loss: 0.926671]\n",
      "epoch:11 step:9235[D loss: 0.392536, acc: 65.62%, op_acc: 46.09%] [G loss: 0.938571]\n",
      "epoch:11 step:9236[D loss: 0.438199, acc: 56.25%, op_acc: 34.38%] [G loss: 0.880426]\n",
      "epoch:11 step:9237[D loss: 0.451495, acc: 57.81%, op_acc: 32.81%] [G loss: 0.916842]\n",
      "epoch:11 step:9238[D loss: 0.405168, acc: 62.50%, op_acc: 44.53%] [G loss: 1.016747]\n",
      "epoch:11 step:9239[D loss: 0.447600, acc: 54.69%, op_acc: 32.03%] [G loss: 0.918956]\n",
      "epoch:11 step:9240[D loss: 0.435721, acc: 62.50%, op_acc: 35.16%] [G loss: 0.844155]\n",
      "epoch:11 step:9241[D loss: 0.433253, acc: 61.72%, op_acc: 33.59%] [G loss: 0.825530]\n",
      "epoch:11 step:9242[D loss: 0.426085, acc: 65.62%, op_acc: 37.50%] [G loss: 0.909642]\n",
      "epoch:11 step:9243[D loss: 0.448660, acc: 57.81%, op_acc: 32.03%] [G loss: 0.834934]\n",
      "epoch:11 step:9244[D loss: 0.416138, acc: 60.16%, op_acc: 39.84%] [G loss: 0.932755]\n",
      "epoch:11 step:9245[D loss: 0.420680, acc: 61.72%, op_acc: 35.94%] [G loss: 0.908258]\n",
      "epoch:11 step:9246[D loss: 0.430237, acc: 56.25%, op_acc: 36.72%] [G loss: 0.820616]\n",
      "epoch:11 step:9247[D loss: 0.425685, acc: 55.47%, op_acc: 36.72%] [G loss: 0.925834]\n",
      "epoch:11 step:9248[D loss: 0.465737, acc: 52.34%, op_acc: 27.34%] [G loss: 0.898803]\n",
      "epoch:11 step:9249[D loss: 0.438824, acc: 59.38%, op_acc: 35.94%] [G loss: 0.917389]\n",
      "epoch:11 step:9250[D loss: 0.439175, acc: 67.97%, op_acc: 32.03%] [G loss: 0.935919]\n",
      "epoch:11 step:9251[D loss: 0.426461, acc: 62.50%, op_acc: 37.50%] [G loss: 0.969087]\n",
      "epoch:11 step:9252[D loss: 0.414220, acc: 62.50%, op_acc: 34.38%] [G loss: 0.955909]\n",
      "epoch:11 step:9253[D loss: 0.416495, acc: 59.38%, op_acc: 44.53%] [G loss: 0.967185]\n",
      "epoch:11 step:9254[D loss: 0.389463, acc: 64.84%, op_acc: 41.41%] [G loss: 0.922148]\n",
      "epoch:11 step:9255[D loss: 0.440356, acc: 55.47%, op_acc: 32.81%] [G loss: 0.914394]\n",
      "epoch:11 step:9256[D loss: 0.463091, acc: 54.69%, op_acc: 31.25%] [G loss: 0.871676]\n",
      "epoch:11 step:9257[D loss: 0.435542, acc: 64.06%, op_acc: 30.47%] [G loss: 0.919681]\n",
      "epoch:11 step:9258[D loss: 0.414817, acc: 67.19%, op_acc: 36.72%] [G loss: 0.929353]\n",
      "epoch:11 step:9259[D loss: 0.455364, acc: 56.25%, op_acc: 33.59%] [G loss: 0.842571]\n",
      "epoch:11 step:9260[D loss: 0.445439, acc: 59.38%, op_acc: 33.59%] [G loss: 0.861804]\n",
      "epoch:11 step:9261[D loss: 0.424406, acc: 60.94%, op_acc: 38.28%] [G loss: 0.935585]\n",
      "epoch:11 step:9262[D loss: 0.466813, acc: 50.78%, op_acc: 32.81%] [G loss: 0.942134]\n",
      "epoch:11 step:9263[D loss: 0.487434, acc: 52.34%, op_acc: 31.25%] [G loss: 0.840661]\n",
      "epoch:11 step:9264[D loss: 0.440734, acc: 55.47%, op_acc: 33.59%] [G loss: 0.981971]\n",
      "epoch:11 step:9265[D loss: 0.424559, acc: 60.16%, op_acc: 37.50%] [G loss: 0.906020]\n",
      "epoch:11 step:9266[D loss: 0.445565, acc: 58.59%, op_acc: 37.50%] [G loss: 0.918152]\n",
      "epoch:11 step:9267[D loss: 0.489116, acc: 55.47%, op_acc: 30.47%] [G loss: 0.917057]\n",
      "epoch:11 step:9268[D loss: 0.451143, acc: 58.59%, op_acc: 31.25%] [G loss: 0.957219]\n",
      "epoch:11 step:9269[D loss: 0.403508, acc: 66.41%, op_acc: 38.28%] [G loss: 1.033409]\n",
      "epoch:11 step:9270[D loss: 0.450960, acc: 53.12%, op_acc: 35.94%] [G loss: 0.898193]\n",
      "epoch:11 step:9271[D loss: 0.444632, acc: 60.94%, op_acc: 34.38%] [G loss: 0.924464]\n",
      "epoch:11 step:9272[D loss: 0.452375, acc: 62.50%, op_acc: 35.16%] [G loss: 1.046129]\n",
      "epoch:11 step:9273[D loss: 0.428378, acc: 60.16%, op_acc: 42.97%] [G loss: 0.947242]\n",
      "epoch:11 step:9274[D loss: 0.441391, acc: 54.69%, op_acc: 37.50%] [G loss: 0.863615]\n",
      "epoch:11 step:9275[D loss: 0.451351, acc: 60.16%, op_acc: 31.25%] [G loss: 0.768530]\n",
      "epoch:11 step:9276[D loss: 0.466282, acc: 50.00%, op_acc: 32.81%] [G loss: 0.854957]\n",
      "epoch:11 step:9277[D loss: 0.429424, acc: 67.97%, op_acc: 32.81%] [G loss: 0.831765]\n",
      "epoch:11 step:9278[D loss: 0.406181, acc: 68.75%, op_acc: 35.94%] [G loss: 0.913378]\n",
      "epoch:11 step:9279[D loss: 0.443324, acc: 52.34%, op_acc: 39.06%] [G loss: 0.969587]\n",
      "epoch:11 step:9280[D loss: 0.467276, acc: 53.12%, op_acc: 34.38%] [G loss: 0.974872]\n",
      "epoch:11 step:9281[D loss: 0.440717, acc: 61.72%, op_acc: 30.47%] [G loss: 0.891145]\n",
      "epoch:11 step:9282[D loss: 0.445218, acc: 63.28%, op_acc: 34.38%] [G loss: 0.939168]\n",
      "epoch:11 step:9283[D loss: 0.443597, acc: 61.72%, op_acc: 32.03%] [G loss: 0.894072]\n",
      "epoch:11 step:9284[D loss: 0.443253, acc: 60.16%, op_acc: 32.81%] [G loss: 0.926455]\n",
      "epoch:11 step:9285[D loss: 0.449828, acc: 58.59%, op_acc: 32.03%] [G loss: 0.984356]\n",
      "epoch:11 step:9286[D loss: 0.439724, acc: 53.91%, op_acc: 39.06%] [G loss: 0.907022]\n",
      "epoch:11 step:9287[D loss: 0.434307, acc: 58.59%, op_acc: 36.72%] [G loss: 0.938459]\n",
      "epoch:11 step:9288[D loss: 0.410488, acc: 64.06%, op_acc: 39.84%] [G loss: 0.881738]\n",
      "epoch:11 step:9289[D loss: 0.442659, acc: 60.94%, op_acc: 34.38%] [G loss: 0.940554]\n",
      "epoch:11 step:9290[D loss: 0.421822, acc: 60.94%, op_acc: 34.38%] [G loss: 0.882724]\n",
      "epoch:11 step:9291[D loss: 0.428435, acc: 63.28%, op_acc: 30.47%] [G loss: 0.924107]\n",
      "epoch:11 step:9292[D loss: 0.444345, acc: 58.59%, op_acc: 32.81%] [G loss: 0.968223]\n",
      "epoch:11 step:9293[D loss: 0.446072, acc: 55.47%, op_acc: 30.47%] [G loss: 0.818956]\n",
      "epoch:11 step:9294[D loss: 0.485023, acc: 42.97%, op_acc: 33.59%] [G loss: 0.833102]\n",
      "epoch:11 step:9295[D loss: 0.426293, acc: 59.38%, op_acc: 42.97%] [G loss: 0.861075]\n",
      "epoch:11 step:9296[D loss: 0.455509, acc: 57.81%, op_acc: 35.16%] [G loss: 0.952145]\n",
      "epoch:11 step:9297[D loss: 0.441651, acc: 59.38%, op_acc: 32.81%] [G loss: 0.922008]\n",
      "epoch:11 step:9298[D loss: 0.466534, acc: 50.78%, op_acc: 32.03%] [G loss: 0.866970]\n",
      "epoch:11 step:9299[D loss: 0.439639, acc: 58.59%, op_acc: 37.50%] [G loss: 0.845210]\n",
      "epoch:11 step:9300[D loss: 0.406409, acc: 67.19%, op_acc: 33.59%] [G loss: 0.904631]\n",
      "epoch:11 step:9301[D loss: 0.416004, acc: 58.59%, op_acc: 37.50%] [G loss: 0.943427]\n",
      "epoch:11 step:9302[D loss: 0.439520, acc: 63.28%, op_acc: 35.16%] [G loss: 0.852755]\n",
      "epoch:11 step:9303[D loss: 0.407656, acc: 65.62%, op_acc: 39.84%] [G loss: 0.970681]\n",
      "epoch:11 step:9304[D loss: 0.437068, acc: 55.47%, op_acc: 36.72%] [G loss: 0.951998]\n",
      "epoch:11 step:9305[D loss: 0.437112, acc: 62.50%, op_acc: 31.25%] [G loss: 0.905096]\n",
      "epoch:11 step:9306[D loss: 0.444559, acc: 66.41%, op_acc: 36.72%] [G loss: 0.911754]\n",
      "epoch:11 step:9307[D loss: 0.458186, acc: 49.22%, op_acc: 35.94%] [G loss: 0.961820]\n",
      "epoch:11 step:9308[D loss: 0.420917, acc: 63.28%, op_acc: 31.25%] [G loss: 0.911069]\n",
      "epoch:11 step:9309[D loss: 0.425413, acc: 66.41%, op_acc: 35.94%] [G loss: 0.933429]\n",
      "epoch:11 step:9310[D loss: 0.428097, acc: 61.72%, op_acc: 35.16%] [G loss: 0.884366]\n",
      "epoch:11 step:9311[D loss: 0.474479, acc: 57.03%, op_acc: 28.12%] [G loss: 0.948093]\n",
      "epoch:11 step:9312[D loss: 0.440563, acc: 47.66%, op_acc: 38.28%] [G loss: 0.810172]\n",
      "epoch:11 step:9313[D loss: 0.435393, acc: 60.16%, op_acc: 36.72%] [G loss: 0.912700]\n",
      "epoch:11 step:9314[D loss: 0.434806, acc: 59.38%, op_acc: 34.38%] [G loss: 0.870802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:9315[D loss: 0.471421, acc: 55.47%, op_acc: 25.78%] [G loss: 0.918870]\n",
      "epoch:11 step:9316[D loss: 0.422952, acc: 57.81%, op_acc: 32.03%] [G loss: 0.813135]\n",
      "epoch:11 step:9317[D loss: 0.406066, acc: 67.97%, op_acc: 42.19%] [G loss: 0.834337]\n",
      "epoch:11 step:9318[D loss: 0.465379, acc: 58.59%, op_acc: 28.12%] [G loss: 0.850605]\n",
      "epoch:11 step:9319[D loss: 0.469506, acc: 57.03%, op_acc: 33.59%] [G loss: 0.888333]\n",
      "epoch:11 step:9320[D loss: 0.418557, acc: 60.16%, op_acc: 34.38%] [G loss: 0.934182]\n",
      "epoch:11 step:9321[D loss: 0.427412, acc: 64.06%, op_acc: 35.94%] [G loss: 0.899181]\n",
      "epoch:11 step:9322[D loss: 0.415029, acc: 67.19%, op_acc: 32.03%] [G loss: 0.928349]\n",
      "epoch:11 step:9323[D loss: 0.466184, acc: 52.34%, op_acc: 32.81%] [G loss: 0.875725]\n",
      "epoch:11 step:9324[D loss: 0.386528, acc: 75.00%, op_acc: 36.72%] [G loss: 0.984626]\n",
      "epoch:11 step:9325[D loss: 0.449358, acc: 50.00%, op_acc: 35.94%] [G loss: 0.818477]\n",
      "epoch:11 step:9326[D loss: 0.438065, acc: 57.03%, op_acc: 31.25%] [G loss: 0.956444]\n",
      "epoch:11 step:9327[D loss: 0.438195, acc: 56.25%, op_acc: 34.38%] [G loss: 0.884367]\n",
      "epoch:11 step:9328[D loss: 0.414619, acc: 60.94%, op_acc: 41.41%] [G loss: 0.937553]\n",
      "epoch:11 step:9329[D loss: 0.440692, acc: 58.59%, op_acc: 37.50%] [G loss: 0.860387]\n",
      "epoch:11 step:9330[D loss: 0.408090, acc: 64.06%, op_acc: 37.50%] [G loss: 0.930961]\n",
      "epoch:11 step:9331[D loss: 0.434560, acc: 58.59%, op_acc: 42.97%] [G loss: 0.855233]\n",
      "epoch:11 step:9332[D loss: 0.428384, acc: 62.50%, op_acc: 36.72%] [G loss: 0.819169]\n",
      "epoch:11 step:9333[D loss: 0.431246, acc: 63.28%, op_acc: 39.06%] [G loss: 0.911542]\n",
      "epoch:11 step:9334[D loss: 0.450600, acc: 52.34%, op_acc: 33.59%] [G loss: 0.916044]\n",
      "epoch:11 step:9335[D loss: 0.429631, acc: 61.72%, op_acc: 36.72%] [G loss: 0.931434]\n",
      "epoch:11 step:9336[D loss: 0.441330, acc: 57.81%, op_acc: 33.59%] [G loss: 0.963266]\n",
      "epoch:11 step:9337[D loss: 0.434517, acc: 62.50%, op_acc: 34.38%] [G loss: 0.916475]\n",
      "epoch:11 step:9338[D loss: 0.446015, acc: 53.91%, op_acc: 30.47%] [G loss: 0.803111]\n",
      "epoch:11 step:9339[D loss: 0.444634, acc: 58.59%, op_acc: 28.91%] [G loss: 0.909694]\n",
      "epoch:11 step:9340[D loss: 0.426054, acc: 64.84%, op_acc: 35.16%] [G loss: 0.838875]\n",
      "epoch:11 step:9341[D loss: 0.438504, acc: 57.03%, op_acc: 37.50%] [G loss: 0.897138]\n",
      "epoch:11 step:9342[D loss: 0.460470, acc: 65.62%, op_acc: 30.47%] [G loss: 0.853390]\n",
      "epoch:11 step:9343[D loss: 0.458518, acc: 56.25%, op_acc: 30.47%] [G loss: 0.880234]\n",
      "epoch:11 step:9344[D loss: 0.450452, acc: 52.34%, op_acc: 37.50%] [G loss: 0.880983]\n",
      "epoch:11 step:9345[D loss: 0.409728, acc: 67.19%, op_acc: 39.06%] [G loss: 0.882247]\n",
      "epoch:11 step:9346[D loss: 0.417878, acc: 67.97%, op_acc: 33.59%] [G loss: 0.955311]\n",
      "epoch:11 step:9347[D loss: 0.438197, acc: 56.25%, op_acc: 40.62%] [G loss: 0.771780]\n",
      "epoch:11 step:9348[D loss: 0.453315, acc: 56.25%, op_acc: 35.94%] [G loss: 0.889218]\n",
      "epoch:11 step:9349[D loss: 0.421099, acc: 59.38%, op_acc: 37.50%] [G loss: 0.908606]\n",
      "epoch:11 step:9350[D loss: 0.450572, acc: 57.03%, op_acc: 33.59%] [G loss: 0.842732]\n",
      "epoch:11 step:9351[D loss: 0.413669, acc: 64.06%, op_acc: 40.62%] [G loss: 0.857228]\n",
      "epoch:11 step:9352[D loss: 0.420599, acc: 58.59%, op_acc: 35.94%] [G loss: 0.944523]\n",
      "epoch:11 step:9353[D loss: 0.431159, acc: 62.50%, op_acc: 34.38%] [G loss: 0.915104]\n",
      "epoch:11 step:9354[D loss: 0.462655, acc: 53.12%, op_acc: 35.16%] [G loss: 0.807183]\n",
      "epoch:11 step:9355[D loss: 0.425275, acc: 58.59%, op_acc: 42.97%] [G loss: 0.914277]\n",
      "epoch:11 step:9356[D loss: 0.434219, acc: 55.47%, op_acc: 40.62%] [G loss: 0.941937]\n",
      "epoch:11 step:9357[D loss: 0.457908, acc: 60.16%, op_acc: 32.81%] [G loss: 0.881386]\n",
      "epoch:11 step:9358[D loss: 0.411817, acc: 66.41%, op_acc: 32.81%] [G loss: 0.945910]\n",
      "epoch:11 step:9359[D loss: 0.417503, acc: 61.72%, op_acc: 35.16%] [G loss: 0.957068]\n",
      "epoch:11 step:9360[D loss: 0.400775, acc: 63.28%, op_acc: 41.41%] [G loss: 0.889017]\n",
      "epoch:11 step:9361[D loss: 0.440940, acc: 56.25%, op_acc: 33.59%] [G loss: 0.902179]\n",
      "epoch:11 step:9362[D loss: 0.448868, acc: 61.72%, op_acc: 35.94%] [G loss: 0.944860]\n",
      "epoch:11 step:9363[D loss: 0.435105, acc: 62.50%, op_acc: 33.59%] [G loss: 0.900371]\n",
      "epoch:11 step:9364[D loss: 0.431986, acc: 68.75%, op_acc: 36.72%] [G loss: 0.844898]\n",
      "epoch:11 step:9365[D loss: 0.420228, acc: 61.72%, op_acc: 37.50%] [G loss: 0.795978]\n",
      "epoch:11 step:9366[D loss: 0.474920, acc: 55.47%, op_acc: 29.69%] [G loss: 0.907252]\n",
      "epoch:11 step:9367[D loss: 0.413184, acc: 62.50%, op_acc: 37.50%] [G loss: 0.870956]\n",
      "epoch:11 step:9368[D loss: 0.449462, acc: 57.03%, op_acc: 33.59%] [G loss: 0.943186]\n",
      "epoch:11 step:9369[D loss: 0.438420, acc: 53.91%, op_acc: 42.19%] [G loss: 0.913153]\n",
      "epoch:11 step:9370[D loss: 0.459720, acc: 56.25%, op_acc: 35.94%] [G loss: 0.931580]\n",
      "epoch:11 step:9371[D loss: 0.453299, acc: 53.91%, op_acc: 40.62%] [G loss: 0.948371]\n",
      "epoch:11 step:9372[D loss: 0.445238, acc: 61.72%, op_acc: 32.81%] [G loss: 0.859593]\n",
      "epoch:12 step:9373[D loss: 0.410750, acc: 71.88%, op_acc: 37.50%] [G loss: 0.898267]\n",
      "epoch:12 step:9374[D loss: 0.413533, acc: 56.25%, op_acc: 43.75%] [G loss: 0.945780]\n",
      "epoch:12 step:9375[D loss: 0.427966, acc: 67.19%, op_acc: 33.59%] [G loss: 0.912546]\n",
      "epoch:12 step:9376[D loss: 0.413891, acc: 59.38%, op_acc: 41.41%] [G loss: 0.964320]\n",
      "epoch:12 step:9377[D loss: 0.455316, acc: 57.81%, op_acc: 35.16%] [G loss: 0.854759]\n",
      "epoch:12 step:9378[D loss: 0.442371, acc: 57.81%, op_acc: 39.06%] [G loss: 0.874643]\n",
      "epoch:12 step:9379[D loss: 0.424490, acc: 64.84%, op_acc: 42.97%] [G loss: 0.827790]\n",
      "epoch:12 step:9380[D loss: 0.453640, acc: 59.38%, op_acc: 30.47%] [G loss: 0.894829]\n",
      "epoch:12 step:9381[D loss: 0.411437, acc: 59.38%, op_acc: 45.31%] [G loss: 0.954775]\n",
      "epoch:12 step:9382[D loss: 0.463398, acc: 58.59%, op_acc: 34.38%] [G loss: 0.908735]\n",
      "epoch:12 step:9383[D loss: 0.443928, acc: 60.16%, op_acc: 39.06%] [G loss: 0.897446]\n",
      "epoch:12 step:9384[D loss: 0.450064, acc: 58.59%, op_acc: 33.59%] [G loss: 0.927493]\n",
      "epoch:12 step:9385[D loss: 0.439344, acc: 67.97%, op_acc: 32.81%] [G loss: 0.889577]\n",
      "epoch:12 step:9386[D loss: 0.459812, acc: 55.47%, op_acc: 29.69%] [G loss: 0.891577]\n",
      "epoch:12 step:9387[D loss: 0.396747, acc: 64.84%, op_acc: 40.62%] [G loss: 0.918736]\n",
      "epoch:12 step:9388[D loss: 0.416407, acc: 59.38%, op_acc: 38.28%] [G loss: 0.901758]\n",
      "epoch:12 step:9389[D loss: 0.434198, acc: 66.41%, op_acc: 35.16%] [G loss: 0.895777]\n",
      "epoch:12 step:9390[D loss: 0.426472, acc: 56.25%, op_acc: 37.50%] [G loss: 0.914690]\n",
      "epoch:12 step:9391[D loss: 0.434426, acc: 60.16%, op_acc: 36.72%] [G loss: 0.856666]\n",
      "epoch:12 step:9392[D loss: 0.408221, acc: 61.72%, op_acc: 39.84%] [G loss: 0.860124]\n",
      "epoch:12 step:9393[D loss: 0.469633, acc: 50.78%, op_acc: 35.94%] [G loss: 0.859968]\n",
      "epoch:12 step:9394[D loss: 0.461901, acc: 48.44%, op_acc: 32.81%] [G loss: 0.861057]\n",
      "epoch:12 step:9395[D loss: 0.427268, acc: 63.28%, op_acc: 34.38%] [G loss: 0.896795]\n",
      "epoch:12 step:9396[D loss: 0.439098, acc: 68.75%, op_acc: 34.38%] [G loss: 0.856948]\n",
      "epoch:12 step:9397[D loss: 0.459462, acc: 54.69%, op_acc: 32.81%] [G loss: 0.815916]\n",
      "epoch:12 step:9398[D loss: 0.439128, acc: 60.94%, op_acc: 40.62%] [G loss: 0.913492]\n",
      "epoch:12 step:9399[D loss: 0.481291, acc: 46.09%, op_acc: 34.38%] [G loss: 0.870072]\n",
      "epoch:12 step:9400[D loss: 0.417606, acc: 63.28%, op_acc: 41.41%] [G loss: 0.884359]\n",
      "epoch:12 step:9401[D loss: 0.409848, acc: 61.72%, op_acc: 43.75%] [G loss: 0.860672]\n",
      "epoch:12 step:9402[D loss: 0.393678, acc: 63.28%, op_acc: 39.06%] [G loss: 0.979791]\n",
      "epoch:12 step:9403[D loss: 0.456886, acc: 60.16%, op_acc: 32.03%] [G loss: 0.874717]\n",
      "epoch:12 step:9404[D loss: 0.450042, acc: 56.25%, op_acc: 37.50%] [G loss: 0.884915]\n",
      "epoch:12 step:9405[D loss: 0.417792, acc: 63.28%, op_acc: 37.50%] [G loss: 0.821325]\n",
      "epoch:12 step:9406[D loss: 0.415562, acc: 60.94%, op_acc: 42.97%] [G loss: 0.907032]\n",
      "epoch:12 step:9407[D loss: 0.475363, acc: 52.34%, op_acc: 34.38%] [G loss: 0.913158]\n",
      "epoch:12 step:9408[D loss: 0.400534, acc: 68.75%, op_acc: 39.06%] [G loss: 0.838385]\n",
      "epoch:12 step:9409[D loss: 0.428254, acc: 55.47%, op_acc: 33.59%] [G loss: 0.896137]\n",
      "epoch:12 step:9410[D loss: 0.456907, acc: 54.69%, op_acc: 35.16%] [G loss: 0.850493]\n",
      "epoch:12 step:9411[D loss: 0.411496, acc: 61.72%, op_acc: 44.53%] [G loss: 0.859086]\n",
      "epoch:12 step:9412[D loss: 0.453937, acc: 58.59%, op_acc: 32.03%] [G loss: 0.850921]\n",
      "epoch:12 step:9413[D loss: 0.406285, acc: 63.28%, op_acc: 43.75%] [G loss: 0.829468]\n",
      "epoch:12 step:9414[D loss: 0.389503, acc: 67.97%, op_acc: 39.84%] [G loss: 0.883341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9415[D loss: 0.435162, acc: 55.47%, op_acc: 36.72%] [G loss: 0.971562]\n",
      "epoch:12 step:9416[D loss: 0.442689, acc: 55.47%, op_acc: 33.59%] [G loss: 0.956348]\n",
      "epoch:12 step:9417[D loss: 0.420514, acc: 62.50%, op_acc: 35.94%] [G loss: 0.857853]\n",
      "epoch:12 step:9418[D loss: 0.452133, acc: 56.25%, op_acc: 39.06%] [G loss: 0.816779]\n",
      "epoch:12 step:9419[D loss: 0.436130, acc: 65.62%, op_acc: 35.16%] [G loss: 0.869758]\n",
      "epoch:12 step:9420[D loss: 0.464956, acc: 58.59%, op_acc: 28.12%] [G loss: 0.931409]\n",
      "epoch:12 step:9421[D loss: 0.407673, acc: 67.97%, op_acc: 34.38%] [G loss: 0.927298]\n",
      "epoch:12 step:9422[D loss: 0.424451, acc: 64.84%, op_acc: 38.28%] [G loss: 0.898605]\n",
      "epoch:12 step:9423[D loss: 0.403752, acc: 61.72%, op_acc: 40.62%] [G loss: 0.928996]\n",
      "epoch:12 step:9424[D loss: 0.457303, acc: 54.69%, op_acc: 34.38%] [G loss: 0.883385]\n",
      "epoch:12 step:9425[D loss: 0.463276, acc: 53.91%, op_acc: 32.81%] [G loss: 0.863191]\n",
      "epoch:12 step:9426[D loss: 0.435830, acc: 63.28%, op_acc: 35.94%] [G loss: 0.933991]\n",
      "epoch:12 step:9427[D loss: 0.403152, acc: 68.75%, op_acc: 33.59%] [G loss: 0.817308]\n",
      "epoch:12 step:9428[D loss: 0.439866, acc: 52.34%, op_acc: 32.03%] [G loss: 0.914560]\n",
      "epoch:12 step:9429[D loss: 0.475985, acc: 56.25%, op_acc: 32.03%] [G loss: 0.856895]\n",
      "epoch:12 step:9430[D loss: 0.430117, acc: 52.34%, op_acc: 36.72%] [G loss: 0.907322]\n",
      "epoch:12 step:9431[D loss: 0.412932, acc: 64.84%, op_acc: 40.62%] [G loss: 0.916545]\n",
      "epoch:12 step:9432[D loss: 0.406037, acc: 68.75%, op_acc: 36.72%] [G loss: 0.850963]\n",
      "epoch:12 step:9433[D loss: 0.440453, acc: 63.28%, op_acc: 33.59%] [G loss: 0.889792]\n",
      "epoch:12 step:9434[D loss: 0.437155, acc: 63.28%, op_acc: 35.94%] [G loss: 0.934118]\n",
      "epoch:12 step:9435[D loss: 0.435265, acc: 61.72%, op_acc: 34.38%] [G loss: 0.944714]\n",
      "epoch:12 step:9436[D loss: 0.452087, acc: 51.56%, op_acc: 36.72%] [G loss: 0.795860]\n",
      "epoch:12 step:9437[D loss: 0.424833, acc: 59.38%, op_acc: 39.06%] [G loss: 0.935672]\n",
      "epoch:12 step:9438[D loss: 0.451384, acc: 53.12%, op_acc: 36.72%] [G loss: 0.919791]\n",
      "epoch:12 step:9439[D loss: 0.437007, acc: 63.28%, op_acc: 35.16%] [G loss: 0.958074]\n",
      "epoch:12 step:9440[D loss: 0.450297, acc: 58.59%, op_acc: 32.81%] [G loss: 0.896218]\n",
      "epoch:12 step:9441[D loss: 0.412299, acc: 56.25%, op_acc: 43.75%] [G loss: 0.874144]\n",
      "epoch:12 step:9442[D loss: 0.453933, acc: 58.59%, op_acc: 28.12%] [G loss: 0.856348]\n",
      "epoch:12 step:9443[D loss: 0.453364, acc: 59.38%, op_acc: 31.25%] [G loss: 0.912940]\n",
      "epoch:12 step:9444[D loss: 0.429578, acc: 60.94%, op_acc: 38.28%] [G loss: 0.798683]\n",
      "epoch:12 step:9445[D loss: 0.424320, acc: 61.72%, op_acc: 34.38%] [G loss: 0.856804]\n",
      "epoch:12 step:9446[D loss: 0.443503, acc: 57.03%, op_acc: 35.94%] [G loss: 0.845756]\n",
      "epoch:12 step:9447[D loss: 0.438288, acc: 57.81%, op_acc: 38.28%] [G loss: 0.908867]\n",
      "epoch:12 step:9448[D loss: 0.479109, acc: 53.12%, op_acc: 34.38%] [G loss: 0.893220]\n",
      "epoch:12 step:9449[D loss: 0.464202, acc: 53.91%, op_acc: 33.59%] [G loss: 0.825946]\n",
      "epoch:12 step:9450[D loss: 0.475689, acc: 55.47%, op_acc: 29.69%] [G loss: 0.782371]\n",
      "epoch:12 step:9451[D loss: 0.440473, acc: 52.34%, op_acc: 39.84%] [G loss: 0.895281]\n",
      "epoch:12 step:9452[D loss: 0.480850, acc: 55.47%, op_acc: 28.91%] [G loss: 0.889329]\n",
      "epoch:12 step:9453[D loss: 0.428846, acc: 67.19%, op_acc: 35.16%] [G loss: 0.954270]\n",
      "epoch:12 step:9454[D loss: 0.418613, acc: 69.53%, op_acc: 37.50%] [G loss: 0.976666]\n",
      "epoch:12 step:9455[D loss: 0.452171, acc: 52.34%, op_acc: 33.59%] [G loss: 0.840017]\n",
      "epoch:12 step:9456[D loss: 0.439239, acc: 56.25%, op_acc: 39.06%] [G loss: 0.938121]\n",
      "epoch:12 step:9457[D loss: 0.415385, acc: 70.31%, op_acc: 34.38%] [G loss: 0.815960]\n",
      "epoch:12 step:9458[D loss: 0.440343, acc: 63.28%, op_acc: 35.16%] [G loss: 0.965496]\n",
      "epoch:12 step:9459[D loss: 0.424037, acc: 59.38%, op_acc: 32.81%] [G loss: 0.856335]\n",
      "epoch:12 step:9460[D loss: 0.429012, acc: 64.84%, op_acc: 35.16%] [G loss: 0.911714]\n",
      "epoch:12 step:9461[D loss: 0.446523, acc: 59.38%, op_acc: 39.84%] [G loss: 0.892745]\n",
      "epoch:12 step:9462[D loss: 0.431998, acc: 63.28%, op_acc: 32.81%] [G loss: 0.957295]\n",
      "epoch:12 step:9463[D loss: 0.445489, acc: 57.03%, op_acc: 32.81%] [G loss: 0.888343]\n",
      "epoch:12 step:9464[D loss: 0.455404, acc: 55.47%, op_acc: 31.25%] [G loss: 0.854628]\n",
      "epoch:12 step:9465[D loss: 0.418528, acc: 64.84%, op_acc: 39.84%] [G loss: 0.914385]\n",
      "epoch:12 step:9466[D loss: 0.394748, acc: 67.19%, op_acc: 37.50%] [G loss: 0.929095]\n",
      "epoch:12 step:9467[D loss: 0.455539, acc: 55.47%, op_acc: 39.84%] [G loss: 0.847153]\n",
      "epoch:12 step:9468[D loss: 0.443195, acc: 60.16%, op_acc: 31.25%] [G loss: 0.889273]\n",
      "epoch:12 step:9469[D loss: 0.440529, acc: 54.69%, op_acc: 38.28%] [G loss: 0.905392]\n",
      "epoch:12 step:9470[D loss: 0.446359, acc: 59.38%, op_acc: 31.25%] [G loss: 0.932845]\n",
      "epoch:12 step:9471[D loss: 0.432834, acc: 57.81%, op_acc: 38.28%] [G loss: 0.913267]\n",
      "epoch:12 step:9472[D loss: 0.468989, acc: 45.31%, op_acc: 32.81%] [G loss: 0.839264]\n",
      "epoch:12 step:9473[D loss: 0.425916, acc: 57.03%, op_acc: 33.59%] [G loss: 0.884375]\n",
      "epoch:12 step:9474[D loss: 0.416791, acc: 60.16%, op_acc: 37.50%] [G loss: 0.878451]\n",
      "epoch:12 step:9475[D loss: 0.439837, acc: 57.81%, op_acc: 40.62%] [G loss: 0.955765]\n",
      "epoch:12 step:9476[D loss: 0.430076, acc: 62.50%, op_acc: 37.50%] [G loss: 0.861099]\n",
      "epoch:12 step:9477[D loss: 0.424900, acc: 60.94%, op_acc: 39.84%] [G loss: 0.898103]\n",
      "epoch:12 step:9478[D loss: 0.415498, acc: 60.94%, op_acc: 37.50%] [G loss: 0.877903]\n",
      "epoch:12 step:9479[D loss: 0.440175, acc: 54.69%, op_acc: 33.59%] [G loss: 0.982806]\n",
      "epoch:12 step:9480[D loss: 0.450451, acc: 56.25%, op_acc: 33.59%] [G loss: 0.900667]\n",
      "epoch:12 step:9481[D loss: 0.431478, acc: 53.12%, op_acc: 38.28%] [G loss: 0.942673]\n",
      "epoch:12 step:9482[D loss: 0.420218, acc: 63.28%, op_acc: 34.38%] [G loss: 1.004517]\n",
      "epoch:12 step:9483[D loss: 0.457879, acc: 54.69%, op_acc: 35.16%] [G loss: 0.827287]\n",
      "epoch:12 step:9484[D loss: 0.428975, acc: 63.28%, op_acc: 38.28%] [G loss: 0.905430]\n",
      "epoch:12 step:9485[D loss: 0.451352, acc: 57.03%, op_acc: 26.56%] [G loss: 0.876936]\n",
      "epoch:12 step:9486[D loss: 0.405314, acc: 60.16%, op_acc: 44.53%] [G loss: 0.944793]\n",
      "epoch:12 step:9487[D loss: 0.421557, acc: 60.94%, op_acc: 39.06%] [G loss: 0.827116]\n",
      "epoch:12 step:9488[D loss: 0.455421, acc: 57.03%, op_acc: 32.81%] [G loss: 0.889672]\n",
      "epoch:12 step:9489[D loss: 0.420773, acc: 64.06%, op_acc: 36.72%] [G loss: 0.958110]\n",
      "epoch:12 step:9490[D loss: 0.434577, acc: 59.38%, op_acc: 35.16%] [G loss: 0.917403]\n",
      "epoch:12 step:9491[D loss: 0.433591, acc: 63.28%, op_acc: 29.69%] [G loss: 0.887345]\n",
      "epoch:12 step:9492[D loss: 0.463696, acc: 51.56%, op_acc: 32.03%] [G loss: 0.921203]\n",
      "epoch:12 step:9493[D loss: 0.430461, acc: 66.41%, op_acc: 32.81%] [G loss: 0.835984]\n",
      "epoch:12 step:9494[D loss: 0.463152, acc: 54.69%, op_acc: 32.81%] [G loss: 0.847773]\n",
      "epoch:12 step:9495[D loss: 0.437629, acc: 62.50%, op_acc: 37.50%] [G loss: 0.854765]\n",
      "epoch:12 step:9496[D loss: 0.456538, acc: 53.12%, op_acc: 37.50%] [G loss: 0.844808]\n",
      "epoch:12 step:9497[D loss: 0.479520, acc: 48.44%, op_acc: 29.69%] [G loss: 0.902627]\n",
      "epoch:12 step:9498[D loss: 0.410088, acc: 64.84%, op_acc: 35.16%] [G loss: 0.899296]\n",
      "epoch:12 step:9499[D loss: 0.430719, acc: 59.38%, op_acc: 38.28%] [G loss: 0.797780]\n",
      "epoch:12 step:9500[D loss: 0.405318, acc: 67.19%, op_acc: 34.38%] [G loss: 0.937501]\n",
      "epoch:12 step:9501[D loss: 0.456254, acc: 57.03%, op_acc: 30.47%] [G loss: 0.818405]\n",
      "epoch:12 step:9502[D loss: 0.435642, acc: 62.50%, op_acc: 35.94%] [G loss: 0.951021]\n",
      "epoch:12 step:9503[D loss: 0.441979, acc: 57.81%, op_acc: 35.94%] [G loss: 0.815391]\n",
      "epoch:12 step:9504[D loss: 0.393690, acc: 61.72%, op_acc: 45.31%] [G loss: 0.914896]\n",
      "epoch:12 step:9505[D loss: 0.448760, acc: 62.50%, op_acc: 35.16%] [G loss: 0.854881]\n",
      "epoch:12 step:9506[D loss: 0.424054, acc: 63.28%, op_acc: 33.59%] [G loss: 0.842525]\n",
      "epoch:12 step:9507[D loss: 0.461997, acc: 53.91%, op_acc: 33.59%] [G loss: 0.893366]\n",
      "epoch:12 step:9508[D loss: 0.403326, acc: 68.75%, op_acc: 37.50%] [G loss: 0.834386]\n",
      "epoch:12 step:9509[D loss: 0.439334, acc: 54.69%, op_acc: 38.28%] [G loss: 0.921635]\n",
      "epoch:12 step:9510[D loss: 0.467391, acc: 55.47%, op_acc: 32.81%] [G loss: 0.862445]\n",
      "epoch:12 step:9511[D loss: 0.410689, acc: 63.28%, op_acc: 37.50%] [G loss: 0.974575]\n",
      "epoch:12 step:9512[D loss: 0.473031, acc: 57.81%, op_acc: 38.28%] [G loss: 0.857842]\n",
      "epoch:12 step:9513[D loss: 0.435279, acc: 60.94%, op_acc: 35.94%] [G loss: 0.869154]\n",
      "epoch:12 step:9514[D loss: 0.411838, acc: 57.81%, op_acc: 38.28%] [G loss: 0.887894]\n",
      "epoch:12 step:9515[D loss: 0.431528, acc: 63.28%, op_acc: 32.03%] [G loss: 0.878466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9516[D loss: 0.434060, acc: 60.94%, op_acc: 38.28%] [G loss: 0.882219]\n",
      "epoch:12 step:9517[D loss: 0.430265, acc: 60.16%, op_acc: 39.84%] [G loss: 0.870068]\n",
      "epoch:12 step:9518[D loss: 0.427788, acc: 62.50%, op_acc: 35.16%] [G loss: 0.775563]\n",
      "epoch:12 step:9519[D loss: 0.452707, acc: 55.47%, op_acc: 38.28%] [G loss: 0.902928]\n",
      "epoch:12 step:9520[D loss: 0.472290, acc: 54.69%, op_acc: 30.47%] [G loss: 0.840526]\n",
      "epoch:12 step:9521[D loss: 0.418106, acc: 64.06%, op_acc: 38.28%] [G loss: 0.878179]\n",
      "epoch:12 step:9522[D loss: 0.440023, acc: 60.16%, op_acc: 36.72%] [G loss: 0.885379]\n",
      "epoch:12 step:9523[D loss: 0.439411, acc: 58.59%, op_acc: 39.84%] [G loss: 0.842697]\n",
      "epoch:12 step:9524[D loss: 0.432803, acc: 60.16%, op_acc: 32.03%] [G loss: 0.877777]\n",
      "epoch:12 step:9525[D loss: 0.427357, acc: 60.16%, op_acc: 37.50%] [G loss: 0.861941]\n",
      "epoch:12 step:9526[D loss: 0.451444, acc: 58.59%, op_acc: 33.59%] [G loss: 0.845988]\n",
      "epoch:12 step:9527[D loss: 0.438589, acc: 58.59%, op_acc: 32.81%] [G loss: 0.930796]\n",
      "epoch:12 step:9528[D loss: 0.452442, acc: 53.12%, op_acc: 32.03%] [G loss: 0.865526]\n",
      "epoch:12 step:9529[D loss: 0.415949, acc: 64.06%, op_acc: 40.62%] [G loss: 0.830271]\n",
      "epoch:12 step:9530[D loss: 0.415835, acc: 60.16%, op_acc: 35.94%] [G loss: 0.896841]\n",
      "epoch:12 step:9531[D loss: 0.444421, acc: 59.38%, op_acc: 33.59%] [G loss: 0.902226]\n",
      "epoch:12 step:9532[D loss: 0.444836, acc: 59.38%, op_acc: 30.47%] [G loss: 0.909535]\n",
      "epoch:12 step:9533[D loss: 0.477367, acc: 49.22%, op_acc: 33.59%] [G loss: 0.829478]\n",
      "epoch:12 step:9534[D loss: 0.428566, acc: 64.84%, op_acc: 34.38%] [G loss: 0.905934]\n",
      "epoch:12 step:9535[D loss: 0.450140, acc: 64.06%, op_acc: 35.94%] [G loss: 0.951112]\n",
      "epoch:12 step:9536[D loss: 0.461495, acc: 55.47%, op_acc: 32.81%] [G loss: 0.866695]\n",
      "epoch:12 step:9537[D loss: 0.402542, acc: 70.31%, op_acc: 36.72%] [G loss: 0.872476]\n",
      "epoch:12 step:9538[D loss: 0.452804, acc: 59.38%, op_acc: 35.16%] [G loss: 0.858543]\n",
      "epoch:12 step:9539[D loss: 0.406998, acc: 71.88%, op_acc: 38.28%] [G loss: 0.973321]\n",
      "epoch:12 step:9540[D loss: 0.426684, acc: 61.72%, op_acc: 37.50%] [G loss: 0.921555]\n",
      "epoch:12 step:9541[D loss: 0.452461, acc: 60.16%, op_acc: 34.38%] [G loss: 0.870013]\n",
      "epoch:12 step:9542[D loss: 0.416825, acc: 62.50%, op_acc: 42.19%] [G loss: 0.922450]\n",
      "epoch:12 step:9543[D loss: 0.429883, acc: 63.28%, op_acc: 32.81%] [G loss: 0.887089]\n",
      "epoch:12 step:9544[D loss: 0.433328, acc: 59.38%, op_acc: 37.50%] [G loss: 0.884332]\n",
      "epoch:12 step:9545[D loss: 0.472551, acc: 47.66%, op_acc: 35.16%] [G loss: 0.885948]\n",
      "epoch:12 step:9546[D loss: 0.483051, acc: 54.69%, op_acc: 32.03%] [G loss: 0.902303]\n",
      "epoch:12 step:9547[D loss: 0.405687, acc: 68.75%, op_acc: 39.06%] [G loss: 0.964577]\n",
      "epoch:12 step:9548[D loss: 0.416191, acc: 64.06%, op_acc: 40.62%] [G loss: 0.899738]\n",
      "epoch:12 step:9549[D loss: 0.403964, acc: 69.53%, op_acc: 38.28%] [G loss: 0.935898]\n",
      "epoch:12 step:9550[D loss: 0.458307, acc: 54.69%, op_acc: 36.72%] [G loss: 0.906296]\n",
      "epoch:12 step:9551[D loss: 0.403610, acc: 64.84%, op_acc: 39.06%] [G loss: 0.882081]\n",
      "epoch:12 step:9552[D loss: 0.465608, acc: 53.12%, op_acc: 33.59%] [G loss: 0.894770]\n",
      "epoch:12 step:9553[D loss: 0.449042, acc: 52.34%, op_acc: 37.50%] [G loss: 0.833744]\n",
      "epoch:12 step:9554[D loss: 0.402745, acc: 68.75%, op_acc: 34.38%] [G loss: 0.968895]\n",
      "epoch:12 step:9555[D loss: 0.406056, acc: 66.41%, op_acc: 35.16%] [G loss: 0.938118]\n",
      "epoch:12 step:9556[D loss: 0.434479, acc: 56.25%, op_acc: 34.38%] [G loss: 0.926434]\n",
      "epoch:12 step:9557[D loss: 0.407277, acc: 67.97%, op_acc: 35.94%] [G loss: 0.930798]\n",
      "epoch:12 step:9558[D loss: 0.452839, acc: 49.22%, op_acc: 40.62%] [G loss: 0.882786]\n",
      "epoch:12 step:9559[D loss: 0.417464, acc: 65.62%, op_acc: 36.72%] [G loss: 0.892466]\n",
      "epoch:12 step:9560[D loss: 0.407915, acc: 64.84%, op_acc: 39.84%] [G loss: 0.954306]\n",
      "epoch:12 step:9561[D loss: 0.449884, acc: 56.25%, op_acc: 35.16%] [G loss: 0.982936]\n",
      "epoch:12 step:9562[D loss: 0.432562, acc: 64.84%, op_acc: 35.16%] [G loss: 0.881894]\n",
      "epoch:12 step:9563[D loss: 0.412730, acc: 61.72%, op_acc: 40.62%] [G loss: 0.953081]\n",
      "epoch:12 step:9564[D loss: 0.429492, acc: 67.19%, op_acc: 32.03%] [G loss: 0.871141]\n",
      "epoch:12 step:9565[D loss: 0.422565, acc: 61.72%, op_acc: 35.94%] [G loss: 0.879579]\n",
      "epoch:12 step:9566[D loss: 0.454809, acc: 53.91%, op_acc: 34.38%] [G loss: 0.880138]\n",
      "epoch:12 step:9567[D loss: 0.444150, acc: 57.81%, op_acc: 34.38%] [G loss: 0.968312]\n",
      "epoch:12 step:9568[D loss: 0.434831, acc: 63.28%, op_acc: 30.47%] [G loss: 0.856162]\n",
      "epoch:12 step:9569[D loss: 0.451922, acc: 58.59%, op_acc: 35.94%] [G loss: 0.849991]\n",
      "epoch:12 step:9570[D loss: 0.439745, acc: 60.16%, op_acc: 34.38%] [G loss: 0.871397]\n",
      "epoch:12 step:9571[D loss: 0.443877, acc: 63.28%, op_acc: 33.59%] [G loss: 0.907549]\n",
      "epoch:12 step:9572[D loss: 0.429392, acc: 57.03%, op_acc: 33.59%] [G loss: 0.946247]\n",
      "epoch:12 step:9573[D loss: 0.435733, acc: 62.50%, op_acc: 34.38%] [G loss: 0.951118]\n",
      "epoch:12 step:9574[D loss: 0.432048, acc: 63.28%, op_acc: 35.16%] [G loss: 0.926149]\n",
      "epoch:12 step:9575[D loss: 0.434951, acc: 60.94%, op_acc: 39.06%] [G loss: 0.886486]\n",
      "epoch:12 step:9576[D loss: 0.470752, acc: 54.69%, op_acc: 32.03%] [G loss: 0.892228]\n",
      "epoch:12 step:9577[D loss: 0.446300, acc: 59.38%, op_acc: 36.72%] [G loss: 0.876964]\n",
      "epoch:12 step:9578[D loss: 0.472955, acc: 50.78%, op_acc: 33.59%] [G loss: 0.835254]\n",
      "epoch:12 step:9579[D loss: 0.446166, acc: 56.25%, op_acc: 35.94%] [G loss: 0.896461]\n",
      "epoch:12 step:9580[D loss: 0.433782, acc: 67.19%, op_acc: 32.03%] [G loss: 0.992552]\n",
      "epoch:12 step:9581[D loss: 0.440241, acc: 60.94%, op_acc: 32.81%] [G loss: 0.892138]\n",
      "epoch:12 step:9582[D loss: 0.455704, acc: 57.03%, op_acc: 28.91%] [G loss: 0.826167]\n",
      "epoch:12 step:9583[D loss: 0.419808, acc: 64.06%, op_acc: 45.31%] [G loss: 0.883370]\n",
      "epoch:12 step:9584[D loss: 0.401149, acc: 67.97%, op_acc: 39.84%] [G loss: 0.912062]\n",
      "epoch:12 step:9585[D loss: 0.411958, acc: 62.50%, op_acc: 38.28%] [G loss: 0.952160]\n",
      "epoch:12 step:9586[D loss: 0.439127, acc: 62.50%, op_acc: 32.81%] [G loss: 0.890927]\n",
      "epoch:12 step:9587[D loss: 0.444042, acc: 63.28%, op_acc: 32.81%] [G loss: 0.918337]\n",
      "epoch:12 step:9588[D loss: 0.424505, acc: 65.62%, op_acc: 35.94%] [G loss: 0.896915]\n",
      "epoch:12 step:9589[D loss: 0.439230, acc: 57.81%, op_acc: 35.16%] [G loss: 0.955185]\n",
      "epoch:12 step:9590[D loss: 0.468312, acc: 54.69%, op_acc: 36.72%] [G loss: 0.823391]\n",
      "epoch:12 step:9591[D loss: 0.406980, acc: 62.50%, op_acc: 38.28%] [G loss: 0.926962]\n",
      "epoch:12 step:9592[D loss: 0.437412, acc: 60.16%, op_acc: 40.62%] [G loss: 0.918446]\n",
      "epoch:12 step:9593[D loss: 0.417422, acc: 65.62%, op_acc: 32.81%] [G loss: 0.947894]\n",
      "epoch:12 step:9594[D loss: 0.437556, acc: 57.81%, op_acc: 39.06%] [G loss: 0.843068]\n",
      "epoch:12 step:9595[D loss: 0.452836, acc: 57.81%, op_acc: 34.38%] [G loss: 0.900560]\n",
      "epoch:12 step:9596[D loss: 0.445909, acc: 57.03%, op_acc: 34.38%] [G loss: 0.858350]\n",
      "epoch:12 step:9597[D loss: 0.469020, acc: 58.59%, op_acc: 35.16%] [G loss: 0.868745]\n",
      "epoch:12 step:9598[D loss: 0.458661, acc: 61.72%, op_acc: 31.25%] [G loss: 0.846614]\n",
      "epoch:12 step:9599[D loss: 0.403639, acc: 70.31%, op_acc: 42.97%] [G loss: 0.944535]\n",
      "epoch:12 step:9600[D loss: 0.447770, acc: 48.44%, op_acc: 35.94%] [G loss: 0.807696]\n",
      "epoch:12 step:9601[D loss: 0.434157, acc: 60.16%, op_acc: 39.84%] [G loss: 0.889319]\n",
      "epoch:12 step:9602[D loss: 0.451255, acc: 58.59%, op_acc: 38.28%] [G loss: 0.832949]\n",
      "epoch:12 step:9603[D loss: 0.422287, acc: 59.38%, op_acc: 39.84%] [G loss: 0.830594]\n",
      "epoch:12 step:9604[D loss: 0.456591, acc: 56.25%, op_acc: 35.16%] [G loss: 0.909343]\n",
      "epoch:12 step:9605[D loss: 0.404662, acc: 64.84%, op_acc: 39.84%] [G loss: 0.903152]\n",
      "epoch:12 step:9606[D loss: 0.438952, acc: 64.06%, op_acc: 31.25%] [G loss: 0.860645]\n",
      "epoch:12 step:9607[D loss: 0.446939, acc: 53.91%, op_acc: 38.28%] [G loss: 0.895168]\n",
      "epoch:12 step:9608[D loss: 0.436589, acc: 59.38%, op_acc: 36.72%] [G loss: 0.894955]\n",
      "epoch:12 step:9609[D loss: 0.420085, acc: 62.50%, op_acc: 32.03%] [G loss: 0.994794]\n",
      "epoch:12 step:9610[D loss: 0.412892, acc: 64.06%, op_acc: 36.72%] [G loss: 1.004944]\n",
      "epoch:12 step:9611[D loss: 0.429281, acc: 64.84%, op_acc: 36.72%] [G loss: 0.912980]\n",
      "epoch:12 step:9612[D loss: 0.436677, acc: 55.47%, op_acc: 39.06%] [G loss: 0.898481]\n",
      "epoch:12 step:9613[D loss: 0.453467, acc: 48.44%, op_acc: 35.16%] [G loss: 0.886926]\n",
      "epoch:12 step:9614[D loss: 0.438112, acc: 56.25%, op_acc: 37.50%] [G loss: 0.803478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9615[D loss: 0.459273, acc: 54.69%, op_acc: 36.72%] [G loss: 0.909047]\n",
      "epoch:12 step:9616[D loss: 0.448399, acc: 63.28%, op_acc: 28.91%] [G loss: 0.889230]\n",
      "epoch:12 step:9617[D loss: 0.425616, acc: 60.94%, op_acc: 39.06%] [G loss: 1.003409]\n",
      "epoch:12 step:9618[D loss: 0.452700, acc: 62.50%, op_acc: 33.59%] [G loss: 0.929793]\n",
      "epoch:12 step:9619[D loss: 0.422323, acc: 60.16%, op_acc: 37.50%] [G loss: 0.890038]\n",
      "epoch:12 step:9620[D loss: 0.458418, acc: 50.78%, op_acc: 35.94%] [G loss: 0.888548]\n",
      "epoch:12 step:9621[D loss: 0.424410, acc: 57.81%, op_acc: 35.94%] [G loss: 0.931019]\n",
      "epoch:12 step:9622[D loss: 0.455075, acc: 57.03%, op_acc: 32.81%] [G loss: 0.857640]\n",
      "epoch:12 step:9623[D loss: 0.402345, acc: 68.75%, op_acc: 42.19%] [G loss: 0.921965]\n",
      "epoch:12 step:9624[D loss: 0.431692, acc: 56.25%, op_acc: 35.94%] [G loss: 0.838332]\n",
      "epoch:12 step:9625[D loss: 0.437327, acc: 63.28%, op_acc: 34.38%] [G loss: 0.882344]\n",
      "epoch:12 step:9626[D loss: 0.459392, acc: 60.16%, op_acc: 32.81%] [G loss: 0.806848]\n",
      "epoch:12 step:9627[D loss: 0.433113, acc: 59.38%, op_acc: 37.50%] [G loss: 0.845084]\n",
      "epoch:12 step:9628[D loss: 0.402345, acc: 67.97%, op_acc: 42.19%] [G loss: 0.889262]\n",
      "epoch:12 step:9629[D loss: 0.467302, acc: 57.03%, op_acc: 30.47%] [G loss: 0.855181]\n",
      "epoch:12 step:9630[D loss: 0.428321, acc: 55.47%, op_acc: 34.38%] [G loss: 0.874357]\n",
      "epoch:12 step:9631[D loss: 0.439025, acc: 62.50%, op_acc: 31.25%] [G loss: 0.919790]\n",
      "epoch:12 step:9632[D loss: 0.433114, acc: 60.94%, op_acc: 35.16%] [G loss: 0.913616]\n",
      "epoch:12 step:9633[D loss: 0.434713, acc: 58.59%, op_acc: 32.81%] [G loss: 0.911878]\n",
      "epoch:12 step:9634[D loss: 0.431095, acc: 64.06%, op_acc: 34.38%] [G loss: 0.954286]\n",
      "epoch:12 step:9635[D loss: 0.455974, acc: 48.44%, op_acc: 33.59%] [G loss: 0.945681]\n",
      "epoch:12 step:9636[D loss: 0.427628, acc: 60.16%, op_acc: 33.59%] [G loss: 0.896214]\n",
      "epoch:12 step:9637[D loss: 0.429593, acc: 57.03%, op_acc: 35.94%] [G loss: 0.911688]\n",
      "epoch:12 step:9638[D loss: 0.451077, acc: 50.00%, op_acc: 35.94%] [G loss: 0.929245]\n",
      "epoch:12 step:9639[D loss: 0.456070, acc: 54.69%, op_acc: 36.72%] [G loss: 0.904926]\n",
      "epoch:12 step:9640[D loss: 0.420602, acc: 57.81%, op_acc: 35.16%] [G loss: 0.886548]\n",
      "epoch:12 step:9641[D loss: 0.429784, acc: 53.12%, op_acc: 37.50%] [G loss: 0.866498]\n",
      "epoch:12 step:9642[D loss: 0.427445, acc: 63.28%, op_acc: 35.94%] [G loss: 0.885492]\n",
      "epoch:12 step:9643[D loss: 0.431318, acc: 59.38%, op_acc: 39.84%] [G loss: 0.922967]\n",
      "epoch:12 step:9644[D loss: 0.416621, acc: 60.16%, op_acc: 39.84%] [G loss: 0.974312]\n",
      "epoch:12 step:9645[D loss: 0.431580, acc: 57.81%, op_acc: 35.94%] [G loss: 0.918480]\n",
      "epoch:12 step:9646[D loss: 0.435058, acc: 57.81%, op_acc: 34.38%] [G loss: 0.983006]\n",
      "epoch:12 step:9647[D loss: 0.438162, acc: 59.38%, op_acc: 35.94%] [G loss: 0.970592]\n",
      "epoch:12 step:9648[D loss: 0.472454, acc: 53.12%, op_acc: 32.03%] [G loss: 0.868520]\n",
      "epoch:12 step:9649[D loss: 0.454587, acc: 60.94%, op_acc: 37.50%] [G loss: 0.965166]\n",
      "epoch:12 step:9650[D loss: 0.435549, acc: 61.72%, op_acc: 33.59%] [G loss: 0.946409]\n",
      "epoch:12 step:9651[D loss: 0.420244, acc: 63.28%, op_acc: 39.84%] [G loss: 0.976694]\n",
      "epoch:12 step:9652[D loss: 0.456049, acc: 55.47%, op_acc: 31.25%] [G loss: 0.927718]\n",
      "epoch:12 step:9653[D loss: 0.469908, acc: 53.12%, op_acc: 32.03%] [G loss: 0.894352]\n",
      "epoch:12 step:9654[D loss: 0.430222, acc: 64.06%, op_acc: 32.81%] [G loss: 0.936565]\n",
      "epoch:12 step:9655[D loss: 0.434249, acc: 56.25%, op_acc: 36.72%] [G loss: 0.832691]\n",
      "epoch:12 step:9656[D loss: 0.445695, acc: 55.47%, op_acc: 35.94%] [G loss: 0.880116]\n",
      "epoch:12 step:9657[D loss: 0.455151, acc: 57.03%, op_acc: 33.59%] [G loss: 0.905071]\n",
      "epoch:12 step:9658[D loss: 0.431283, acc: 64.84%, op_acc: 34.38%] [G loss: 0.939306]\n",
      "epoch:12 step:9659[D loss: 0.466331, acc: 56.25%, op_acc: 34.38%] [G loss: 0.825576]\n",
      "epoch:12 step:9660[D loss: 0.434982, acc: 57.03%, op_acc: 41.41%] [G loss: 0.904847]\n",
      "epoch:12 step:9661[D loss: 0.449066, acc: 58.59%, op_acc: 33.59%] [G loss: 0.902735]\n",
      "epoch:12 step:9662[D loss: 0.419597, acc: 67.19%, op_acc: 39.06%] [G loss: 0.960756]\n",
      "epoch:12 step:9663[D loss: 0.442723, acc: 56.25%, op_acc: 44.53%] [G loss: 0.837736]\n",
      "epoch:12 step:9664[D loss: 0.454526, acc: 58.59%, op_acc: 33.59%] [G loss: 0.852316]\n",
      "epoch:12 step:9665[D loss: 0.453754, acc: 53.12%, op_acc: 35.94%] [G loss: 0.840825]\n",
      "epoch:12 step:9666[D loss: 0.437634, acc: 60.94%, op_acc: 35.94%] [G loss: 0.803575]\n",
      "epoch:12 step:9667[D loss: 0.434616, acc: 54.69%, op_acc: 41.41%] [G loss: 0.867921]\n",
      "epoch:12 step:9668[D loss: 0.435172, acc: 53.12%, op_acc: 35.94%] [G loss: 0.772893]\n",
      "epoch:12 step:9669[D loss: 0.440663, acc: 63.28%, op_acc: 28.12%] [G loss: 0.890000]\n",
      "epoch:12 step:9670[D loss: 0.440097, acc: 60.94%, op_acc: 32.03%] [G loss: 0.844553]\n",
      "epoch:12 step:9671[D loss: 0.435686, acc: 59.38%, op_acc: 37.50%] [G loss: 0.845141]\n",
      "epoch:12 step:9672[D loss: 0.468679, acc: 47.66%, op_acc: 33.59%] [G loss: 0.849033]\n",
      "epoch:12 step:9673[D loss: 0.437125, acc: 60.16%, op_acc: 34.38%] [G loss: 0.848288]\n",
      "epoch:12 step:9674[D loss: 0.429340, acc: 63.28%, op_acc: 35.94%] [G loss: 0.889474]\n",
      "epoch:12 step:9675[D loss: 0.455723, acc: 57.03%, op_acc: 32.03%] [G loss: 0.874892]\n",
      "epoch:12 step:9676[D loss: 0.430812, acc: 59.38%, op_acc: 37.50%] [G loss: 0.904198]\n",
      "epoch:12 step:9677[D loss: 0.430015, acc: 58.59%, op_acc: 37.50%] [G loss: 0.886979]\n",
      "epoch:12 step:9678[D loss: 0.451541, acc: 62.50%, op_acc: 34.38%] [G loss: 0.886985]\n",
      "epoch:12 step:9679[D loss: 0.428746, acc: 61.72%, op_acc: 36.72%] [G loss: 0.874829]\n",
      "epoch:12 step:9680[D loss: 0.411174, acc: 69.53%, op_acc: 35.94%] [G loss: 0.845774]\n",
      "epoch:12 step:9681[D loss: 0.489256, acc: 52.34%, op_acc: 28.91%] [G loss: 0.764919]\n",
      "epoch:12 step:9682[D loss: 0.405991, acc: 61.72%, op_acc: 33.59%] [G loss: 0.911992]\n",
      "epoch:12 step:9683[D loss: 0.455832, acc: 57.81%, op_acc: 32.81%] [G loss: 0.907627]\n",
      "epoch:12 step:9684[D loss: 0.468054, acc: 52.34%, op_acc: 28.12%] [G loss: 0.875178]\n",
      "epoch:12 step:9685[D loss: 0.453866, acc: 60.16%, op_acc: 36.72%] [G loss: 0.848446]\n",
      "epoch:12 step:9686[D loss: 0.439815, acc: 57.03%, op_acc: 38.28%] [G loss: 0.923526]\n",
      "epoch:12 step:9687[D loss: 0.495506, acc: 43.75%, op_acc: 30.47%] [G loss: 0.888342]\n",
      "epoch:12 step:9688[D loss: 0.440159, acc: 54.69%, op_acc: 39.06%] [G loss: 0.866142]\n",
      "epoch:12 step:9689[D loss: 0.468909, acc: 54.69%, op_acc: 32.03%] [G loss: 0.899940]\n",
      "epoch:12 step:9690[D loss: 0.472850, acc: 53.12%, op_acc: 31.25%] [G loss: 0.877144]\n",
      "epoch:12 step:9691[D loss: 0.440278, acc: 60.16%, op_acc: 34.38%] [G loss: 0.846526]\n",
      "epoch:12 step:9692[D loss: 0.423924, acc: 59.38%, op_acc: 33.59%] [G loss: 0.860289]\n",
      "epoch:12 step:9693[D loss: 0.490255, acc: 50.78%, op_acc: 35.94%] [G loss: 0.968374]\n",
      "epoch:12 step:9694[D loss: 0.435335, acc: 62.50%, op_acc: 35.16%] [G loss: 0.918959]\n",
      "epoch:12 step:9695[D loss: 0.431419, acc: 60.16%, op_acc: 42.97%] [G loss: 0.856743]\n",
      "epoch:12 step:9696[D loss: 0.448146, acc: 61.72%, op_acc: 34.38%] [G loss: 0.845399]\n",
      "epoch:12 step:9697[D loss: 0.425348, acc: 58.59%, op_acc: 35.16%] [G loss: 0.822210]\n",
      "epoch:12 step:9698[D loss: 0.429371, acc: 57.81%, op_acc: 37.50%] [G loss: 0.788427]\n",
      "epoch:12 step:9699[D loss: 0.444016, acc: 53.91%, op_acc: 37.50%] [G loss: 0.863794]\n",
      "epoch:12 step:9700[D loss: 0.435326, acc: 59.38%, op_acc: 35.16%] [G loss: 0.901797]\n",
      "epoch:12 step:9701[D loss: 0.400072, acc: 74.22%, op_acc: 39.84%] [G loss: 0.882308]\n",
      "epoch:12 step:9702[D loss: 0.424880, acc: 54.69%, op_acc: 40.62%] [G loss: 0.903182]\n",
      "epoch:12 step:9703[D loss: 0.462263, acc: 52.34%, op_acc: 34.38%] [G loss: 0.811662]\n",
      "epoch:12 step:9704[D loss: 0.444304, acc: 60.94%, op_acc: 39.06%] [G loss: 0.871565]\n",
      "epoch:12 step:9705[D loss: 0.430564, acc: 59.38%, op_acc: 34.38%] [G loss: 0.845495]\n",
      "epoch:12 step:9706[D loss: 0.434619, acc: 54.69%, op_acc: 41.41%] [G loss: 0.878888]\n",
      "epoch:12 step:9707[D loss: 0.442736, acc: 61.72%, op_acc: 34.38%] [G loss: 0.895575]\n",
      "epoch:12 step:9708[D loss: 0.480065, acc: 51.56%, op_acc: 25.00%] [G loss: 0.868245]\n",
      "epoch:12 step:9709[D loss: 0.440578, acc: 57.81%, op_acc: 33.59%] [G loss: 0.910329]\n",
      "epoch:12 step:9710[D loss: 0.414114, acc: 63.28%, op_acc: 41.41%] [G loss: 0.850479]\n",
      "epoch:12 step:9711[D loss: 0.429904, acc: 59.38%, op_acc: 34.38%] [G loss: 1.015742]\n",
      "epoch:12 step:9712[D loss: 0.433122, acc: 64.84%, op_acc: 29.69%] [G loss: 0.925091]\n",
      "epoch:12 step:9713[D loss: 0.436888, acc: 60.94%, op_acc: 28.12%] [G loss: 0.788838]\n",
      "epoch:12 step:9714[D loss: 0.435095, acc: 57.03%, op_acc: 39.84%] [G loss: 0.883583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9715[D loss: 0.448859, acc: 57.03%, op_acc: 32.03%] [G loss: 0.817392]\n",
      "epoch:12 step:9716[D loss: 0.451661, acc: 53.12%, op_acc: 35.94%] [G loss: 0.894413]\n",
      "epoch:12 step:9717[D loss: 0.467213, acc: 50.00%, op_acc: 25.78%] [G loss: 0.874911]\n",
      "epoch:12 step:9718[D loss: 0.390446, acc: 72.66%, op_acc: 43.75%] [G loss: 1.077595]\n",
      "epoch:12 step:9719[D loss: 0.411861, acc: 64.84%, op_acc: 35.16%] [G loss: 0.907153]\n",
      "epoch:12 step:9720[D loss: 0.418665, acc: 67.97%, op_acc: 31.25%] [G loss: 0.780681]\n",
      "epoch:12 step:9721[D loss: 0.415579, acc: 60.16%, op_acc: 35.16%] [G loss: 0.945938]\n",
      "epoch:12 step:9722[D loss: 0.450697, acc: 60.16%, op_acc: 34.38%] [G loss: 0.900241]\n",
      "epoch:12 step:9723[D loss: 0.417945, acc: 64.84%, op_acc: 40.62%] [G loss: 0.988576]\n",
      "epoch:12 step:9724[D loss: 0.435948, acc: 64.06%, op_acc: 34.38%] [G loss: 0.820362]\n",
      "epoch:12 step:9725[D loss: 0.410862, acc: 59.38%, op_acc: 44.53%] [G loss: 0.929038]\n",
      "epoch:12 step:9726[D loss: 0.426831, acc: 60.16%, op_acc: 35.94%] [G loss: 0.833726]\n",
      "epoch:12 step:9727[D loss: 0.430905, acc: 67.97%, op_acc: 35.94%] [G loss: 0.924431]\n",
      "epoch:12 step:9728[D loss: 0.431223, acc: 56.25%, op_acc: 31.25%] [G loss: 0.930064]\n",
      "epoch:12 step:9729[D loss: 0.436282, acc: 60.16%, op_acc: 32.03%] [G loss: 0.909251]\n",
      "epoch:12 step:9730[D loss: 0.434986, acc: 58.59%, op_acc: 34.38%] [G loss: 0.849932]\n",
      "epoch:12 step:9731[D loss: 0.439466, acc: 57.03%, op_acc: 35.94%] [G loss: 0.917977]\n",
      "epoch:12 step:9732[D loss: 0.453219, acc: 54.69%, op_acc: 38.28%] [G loss: 0.810646]\n",
      "epoch:12 step:9733[D loss: 0.425479, acc: 65.62%, op_acc: 35.16%] [G loss: 0.842818]\n",
      "epoch:12 step:9734[D loss: 0.391184, acc: 66.41%, op_acc: 40.62%] [G loss: 0.887075]\n",
      "epoch:12 step:9735[D loss: 0.454056, acc: 55.47%, op_acc: 35.16%] [G loss: 0.851809]\n",
      "epoch:12 step:9736[D loss: 0.453310, acc: 57.03%, op_acc: 35.16%] [G loss: 0.915372]\n",
      "epoch:12 step:9737[D loss: 0.408171, acc: 64.84%, op_acc: 37.50%] [G loss: 0.972680]\n",
      "epoch:12 step:9738[D loss: 0.428647, acc: 57.81%, op_acc: 39.84%] [G loss: 0.997479]\n",
      "epoch:12 step:9739[D loss: 0.466315, acc: 53.91%, op_acc: 35.94%] [G loss: 0.940385]\n",
      "epoch:12 step:9740[D loss: 0.429457, acc: 65.62%, op_acc: 32.81%] [G loss: 0.902707]\n",
      "epoch:12 step:9741[D loss: 0.441722, acc: 57.81%, op_acc: 28.91%] [G loss: 0.902546]\n",
      "epoch:12 step:9742[D loss: 0.447357, acc: 60.94%, op_acc: 35.16%] [G loss: 0.890243]\n",
      "epoch:12 step:9743[D loss: 0.425315, acc: 57.03%, op_acc: 37.50%] [G loss: 0.860063]\n",
      "epoch:12 step:9744[D loss: 0.427233, acc: 59.38%, op_acc: 36.72%] [G loss: 0.893421]\n",
      "epoch:12 step:9745[D loss: 0.415892, acc: 63.28%, op_acc: 36.72%] [G loss: 0.878817]\n",
      "epoch:12 step:9746[D loss: 0.429619, acc: 60.16%, op_acc: 40.62%] [G loss: 0.882542]\n",
      "epoch:12 step:9747[D loss: 0.430384, acc: 56.25%, op_acc: 37.50%] [G loss: 0.847625]\n",
      "epoch:12 step:9748[D loss: 0.434734, acc: 59.38%, op_acc: 37.50%] [G loss: 0.857797]\n",
      "epoch:12 step:9749[D loss: 0.434701, acc: 57.81%, op_acc: 35.94%] [G loss: 0.906521]\n",
      "epoch:12 step:9750[D loss: 0.439578, acc: 57.81%, op_acc: 36.72%] [G loss: 0.875189]\n",
      "epoch:12 step:9751[D loss: 0.412802, acc: 65.62%, op_acc: 40.62%] [G loss: 0.942961]\n",
      "epoch:12 step:9752[D loss: 0.432189, acc: 56.25%, op_acc: 39.84%] [G loss: 1.025294]\n",
      "epoch:12 step:9753[D loss: 0.427151, acc: 58.59%, op_acc: 40.62%] [G loss: 0.955793]\n",
      "epoch:12 step:9754[D loss: 0.402744, acc: 64.84%, op_acc: 35.16%] [G loss: 0.939182]\n",
      "epoch:12 step:9755[D loss: 0.418716, acc: 62.50%, op_acc: 35.94%] [G loss: 0.899743]\n",
      "epoch:12 step:9756[D loss: 0.408303, acc: 65.62%, op_acc: 36.72%] [G loss: 0.929574]\n",
      "epoch:12 step:9757[D loss: 0.439281, acc: 56.25%, op_acc: 39.06%] [G loss: 0.875906]\n",
      "epoch:12 step:9758[D loss: 0.428182, acc: 64.84%, op_acc: 38.28%] [G loss: 0.983301]\n",
      "epoch:12 step:9759[D loss: 0.435074, acc: 64.06%, op_acc: 35.94%] [G loss: 0.974036]\n",
      "epoch:12 step:9760[D loss: 0.445090, acc: 60.16%, op_acc: 33.59%] [G loss: 0.900432]\n",
      "epoch:12 step:9761[D loss: 0.444513, acc: 69.53%, op_acc: 28.91%] [G loss: 0.877402]\n",
      "epoch:12 step:9762[D loss: 0.422984, acc: 58.59%, op_acc: 35.94%] [G loss: 0.906958]\n",
      "epoch:12 step:9763[D loss: 0.437124, acc: 52.34%, op_acc: 39.84%] [G loss: 0.933298]\n",
      "epoch:12 step:9764[D loss: 0.412628, acc: 63.28%, op_acc: 36.72%] [G loss: 0.795483]\n",
      "epoch:12 step:9765[D loss: 0.429682, acc: 57.03%, op_acc: 38.28%] [G loss: 0.850347]\n",
      "epoch:12 step:9766[D loss: 0.445860, acc: 57.03%, op_acc: 34.38%] [G loss: 0.969459]\n",
      "epoch:12 step:9767[D loss: 0.453894, acc: 57.81%, op_acc: 36.72%] [G loss: 0.849211]\n",
      "epoch:12 step:9768[D loss: 0.426527, acc: 64.06%, op_acc: 39.06%] [G loss: 0.903538]\n",
      "epoch:12 step:9769[D loss: 0.452779, acc: 56.25%, op_acc: 35.16%] [G loss: 0.907490]\n",
      "epoch:12 step:9770[D loss: 0.490836, acc: 54.69%, op_acc: 27.34%] [G loss: 0.826171]\n",
      "epoch:12 step:9771[D loss: 0.447372, acc: 49.22%, op_acc: 35.94%] [G loss: 0.835498]\n",
      "epoch:12 step:9772[D loss: 0.435941, acc: 56.25%, op_acc: 43.75%] [G loss: 0.795939]\n",
      "epoch:12 step:9773[D loss: 0.435902, acc: 58.59%, op_acc: 39.84%] [G loss: 0.890915]\n",
      "epoch:12 step:9774[D loss: 0.421295, acc: 65.62%, op_acc: 32.81%] [G loss: 0.901585]\n",
      "epoch:12 step:9775[D loss: 0.418153, acc: 62.50%, op_acc: 37.50%] [G loss: 0.897417]\n",
      "epoch:12 step:9776[D loss: 0.422173, acc: 58.59%, op_acc: 39.06%] [G loss: 0.884902]\n",
      "epoch:12 step:9777[D loss: 0.466755, acc: 50.00%, op_acc: 38.28%] [G loss: 0.907841]\n",
      "epoch:12 step:9778[D loss: 0.430542, acc: 63.28%, op_acc: 38.28%] [G loss: 0.848720]\n",
      "epoch:12 step:9779[D loss: 0.453400, acc: 54.69%, op_acc: 36.72%] [G loss: 0.865493]\n",
      "epoch:12 step:9780[D loss: 0.422634, acc: 57.81%, op_acc: 38.28%] [G loss: 0.915979]\n",
      "epoch:12 step:9781[D loss: 0.410827, acc: 62.50%, op_acc: 36.72%] [G loss: 0.930399]\n",
      "epoch:12 step:9782[D loss: 0.430290, acc: 56.25%, op_acc: 39.06%] [G loss: 0.894214]\n",
      "epoch:12 step:9783[D loss: 0.455902, acc: 55.47%, op_acc: 32.81%] [G loss: 0.844074]\n",
      "epoch:12 step:9784[D loss: 0.451747, acc: 54.69%, op_acc: 36.72%] [G loss: 0.898004]\n",
      "epoch:12 step:9785[D loss: 0.440050, acc: 64.06%, op_acc: 35.94%] [G loss: 0.906400]\n",
      "epoch:12 step:9786[D loss: 0.428410, acc: 58.59%, op_acc: 42.97%] [G loss: 0.933158]\n",
      "epoch:12 step:9787[D loss: 0.440027, acc: 60.16%, op_acc: 38.28%] [G loss: 0.919511]\n",
      "epoch:12 step:9788[D loss: 0.409829, acc: 64.06%, op_acc: 41.41%] [G loss: 0.946623]\n",
      "epoch:12 step:9789[D loss: 0.465280, acc: 54.69%, op_acc: 36.72%] [G loss: 0.876735]\n",
      "epoch:12 step:9790[D loss: 0.427339, acc: 60.16%, op_acc: 36.72%] [G loss: 0.965815]\n",
      "epoch:12 step:9791[D loss: 0.439656, acc: 58.59%, op_acc: 40.62%] [G loss: 0.822406]\n",
      "epoch:12 step:9792[D loss: 0.466234, acc: 50.00%, op_acc: 34.38%] [G loss: 0.878814]\n",
      "epoch:12 step:9793[D loss: 0.461901, acc: 55.47%, op_acc: 39.06%] [G loss: 0.878777]\n",
      "epoch:12 step:9794[D loss: 0.428515, acc: 57.81%, op_acc: 38.28%] [G loss: 0.852509]\n",
      "epoch:12 step:9795[D loss: 0.450445, acc: 60.94%, op_acc: 31.25%] [G loss: 0.853597]\n",
      "epoch:12 step:9796[D loss: 0.460674, acc: 53.91%, op_acc: 36.72%] [G loss: 0.945899]\n",
      "epoch:12 step:9797[D loss: 0.479192, acc: 50.00%, op_acc: 28.12%] [G loss: 0.824752]\n",
      "epoch:12 step:9798[D loss: 0.483086, acc: 48.44%, op_acc: 29.69%] [G loss: 0.901470]\n",
      "epoch:12 step:9799[D loss: 0.422832, acc: 69.53%, op_acc: 35.16%] [G loss: 0.966318]\n",
      "epoch:12 step:9800[D loss: 0.436325, acc: 53.12%, op_acc: 38.28%] [G loss: 0.908169]\n",
      "epoch:12 step:9801[D loss: 0.450259, acc: 60.16%, op_acc: 35.16%] [G loss: 0.850196]\n",
      "epoch:12 step:9802[D loss: 0.429597, acc: 59.38%, op_acc: 39.06%] [G loss: 0.955259]\n",
      "epoch:12 step:9803[D loss: 0.455136, acc: 53.91%, op_acc: 41.41%] [G loss: 0.883951]\n",
      "epoch:12 step:9804[D loss: 0.423272, acc: 58.59%, op_acc: 42.19%] [G loss: 0.887307]\n",
      "epoch:12 step:9805[D loss: 0.405138, acc: 64.06%, op_acc: 36.72%] [G loss: 0.870189]\n",
      "epoch:12 step:9806[D loss: 0.414782, acc: 63.28%, op_acc: 41.41%] [G loss: 0.843416]\n",
      "epoch:12 step:9807[D loss: 0.438021, acc: 53.12%, op_acc: 36.72%] [G loss: 0.881667]\n",
      "epoch:12 step:9808[D loss: 0.474633, acc: 52.34%, op_acc: 35.94%] [G loss: 0.910557]\n",
      "epoch:12 step:9809[D loss: 0.435883, acc: 57.81%, op_acc: 38.28%] [G loss: 0.863718]\n",
      "epoch:12 step:9810[D loss: 0.421522, acc: 62.50%, op_acc: 39.84%] [G loss: 0.867835]\n",
      "epoch:12 step:9811[D loss: 0.386645, acc: 67.97%, op_acc: 36.72%] [G loss: 0.913357]\n",
      "epoch:12 step:9812[D loss: 0.438778, acc: 57.81%, op_acc: 38.28%] [G loss: 0.861704]\n",
      "epoch:12 step:9813[D loss: 0.421290, acc: 62.50%, op_acc: 32.03%] [G loss: 0.811872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9814[D loss: 0.428509, acc: 57.03%, op_acc: 39.84%] [G loss: 0.876179]\n",
      "epoch:12 step:9815[D loss: 0.449692, acc: 57.03%, op_acc: 32.81%] [G loss: 0.817542]\n",
      "epoch:12 step:9816[D loss: 0.420589, acc: 59.38%, op_acc: 35.94%] [G loss: 0.902641]\n",
      "epoch:12 step:9817[D loss: 0.461784, acc: 57.81%, op_acc: 34.38%] [G loss: 0.921668]\n",
      "epoch:12 step:9818[D loss: 0.424496, acc: 62.50%, op_acc: 35.16%] [G loss: 0.897279]\n",
      "epoch:12 step:9819[D loss: 0.467607, acc: 56.25%, op_acc: 28.91%] [G loss: 0.843557]\n",
      "epoch:12 step:9820[D loss: 0.408368, acc: 65.62%, op_acc: 39.06%] [G loss: 0.848199]\n",
      "epoch:12 step:9821[D loss: 0.416221, acc: 65.62%, op_acc: 36.72%] [G loss: 0.866941]\n",
      "epoch:12 step:9822[D loss: 0.435726, acc: 64.06%, op_acc: 32.81%] [G loss: 0.916439]\n",
      "epoch:12 step:9823[D loss: 0.441690, acc: 60.94%, op_acc: 36.72%] [G loss: 0.925191]\n",
      "epoch:12 step:9824[D loss: 0.400975, acc: 62.50%, op_acc: 39.06%] [G loss: 0.850930]\n",
      "epoch:12 step:9825[D loss: 0.428106, acc: 50.78%, op_acc: 40.62%] [G loss: 0.850181]\n",
      "epoch:12 step:9826[D loss: 0.409811, acc: 72.66%, op_acc: 32.81%] [G loss: 0.894383]\n",
      "epoch:12 step:9827[D loss: 0.465943, acc: 48.44%, op_acc: 28.91%] [G loss: 0.835599]\n",
      "epoch:12 step:9828[D loss: 0.475211, acc: 52.34%, op_acc: 32.81%] [G loss: 0.945926]\n",
      "epoch:12 step:9829[D loss: 0.437527, acc: 61.72%, op_acc: 35.16%] [G loss: 0.901760]\n",
      "epoch:12 step:9830[D loss: 0.402346, acc: 69.53%, op_acc: 42.19%] [G loss: 0.894779]\n",
      "epoch:12 step:9831[D loss: 0.408866, acc: 67.19%, op_acc: 35.94%] [G loss: 0.862142]\n",
      "epoch:12 step:9832[D loss: 0.433955, acc: 55.47%, op_acc: 35.94%] [G loss: 0.855142]\n",
      "epoch:12 step:9833[D loss: 0.454057, acc: 57.03%, op_acc: 30.47%] [G loss: 0.922703]\n",
      "epoch:12 step:9834[D loss: 0.469168, acc: 50.00%, op_acc: 35.94%] [G loss: 0.905814]\n",
      "epoch:12 step:9835[D loss: 0.420571, acc: 60.94%, op_acc: 37.50%] [G loss: 0.830807]\n",
      "epoch:12 step:9836[D loss: 0.423672, acc: 65.62%, op_acc: 36.72%] [G loss: 0.938067]\n",
      "epoch:12 step:9837[D loss: 0.429267, acc: 62.50%, op_acc: 34.38%] [G loss: 0.858250]\n",
      "epoch:12 step:9838[D loss: 0.420496, acc: 61.72%, op_acc: 33.59%] [G loss: 0.889089]\n",
      "epoch:12 step:9839[D loss: 0.410367, acc: 65.62%, op_acc: 38.28%] [G loss: 0.953817]\n",
      "epoch:12 step:9840[D loss: 0.425615, acc: 55.47%, op_acc: 37.50%] [G loss: 0.897073]\n",
      "epoch:12 step:9841[D loss: 0.401078, acc: 64.06%, op_acc: 39.84%] [G loss: 0.938351]\n",
      "epoch:12 step:9842[D loss: 0.425186, acc: 60.16%, op_acc: 41.41%] [G loss: 0.909441]\n",
      "epoch:12 step:9843[D loss: 0.443035, acc: 57.81%, op_acc: 35.16%] [G loss: 0.912785]\n",
      "epoch:12 step:9844[D loss: 0.475634, acc: 58.59%, op_acc: 34.38%] [G loss: 0.830284]\n",
      "epoch:12 step:9845[D loss: 0.426393, acc: 61.72%, op_acc: 41.41%] [G loss: 0.904601]\n",
      "epoch:12 step:9846[D loss: 0.460116, acc: 54.69%, op_acc: 36.72%] [G loss: 0.926474]\n",
      "epoch:12 step:9847[D loss: 0.418408, acc: 59.38%, op_acc: 39.84%] [G loss: 0.889807]\n",
      "epoch:12 step:9848[D loss: 0.477566, acc: 53.91%, op_acc: 29.69%] [G loss: 0.809078]\n",
      "epoch:12 step:9849[D loss: 0.453364, acc: 60.94%, op_acc: 37.50%] [G loss: 0.899721]\n",
      "epoch:12 step:9850[D loss: 0.419568, acc: 54.69%, op_acc: 39.06%] [G loss: 0.836522]\n",
      "epoch:12 step:9851[D loss: 0.439345, acc: 66.41%, op_acc: 34.38%] [G loss: 0.902829]\n",
      "epoch:12 step:9852[D loss: 0.499398, acc: 50.78%, op_acc: 28.12%] [G loss: 0.901913]\n",
      "epoch:12 step:9853[D loss: 0.456069, acc: 56.25%, op_acc: 28.91%] [G loss: 0.898917]\n",
      "epoch:12 step:9854[D loss: 0.464400, acc: 55.47%, op_acc: 34.38%] [G loss: 0.851819]\n",
      "epoch:12 step:9855[D loss: 0.448848, acc: 58.59%, op_acc: 32.81%] [G loss: 0.825527]\n",
      "epoch:12 step:9856[D loss: 0.420734, acc: 60.16%, op_acc: 39.84%] [G loss: 0.921732]\n",
      "epoch:12 step:9857[D loss: 0.436806, acc: 62.50%, op_acc: 39.06%] [G loss: 0.889057]\n",
      "epoch:12 step:9858[D loss: 0.406140, acc: 57.81%, op_acc: 41.41%] [G loss: 0.875229]\n",
      "epoch:12 step:9859[D loss: 0.453098, acc: 55.47%, op_acc: 30.47%] [G loss: 0.889263]\n",
      "epoch:12 step:9860[D loss: 0.420333, acc: 64.06%, op_acc: 39.84%] [G loss: 0.854654]\n",
      "epoch:12 step:9861[D loss: 0.437597, acc: 58.59%, op_acc: 35.94%] [G loss: 0.872825]\n",
      "epoch:12 step:9862[D loss: 0.427907, acc: 60.16%, op_acc: 35.16%] [G loss: 0.850766]\n",
      "epoch:12 step:9863[D loss: 0.447394, acc: 53.91%, op_acc: 34.38%] [G loss: 0.856290]\n",
      "epoch:12 step:9864[D loss: 0.435485, acc: 62.50%, op_acc: 37.50%] [G loss: 0.837093]\n",
      "epoch:12 step:9865[D loss: 0.438121, acc: 60.94%, op_acc: 33.59%] [G loss: 0.862186]\n",
      "epoch:12 step:9866[D loss: 0.395852, acc: 65.62%, op_acc: 37.50%] [G loss: 0.950209]\n",
      "epoch:12 step:9867[D loss: 0.432834, acc: 65.62%, op_acc: 35.16%] [G loss: 0.907015]\n",
      "epoch:12 step:9868[D loss: 0.425831, acc: 65.62%, op_acc: 35.94%] [G loss: 0.925210]\n",
      "epoch:12 step:9869[D loss: 0.413400, acc: 64.84%, op_acc: 35.16%] [G loss: 0.873299]\n",
      "epoch:12 step:9870[D loss: 0.462562, acc: 53.91%, op_acc: 33.59%] [G loss: 0.839226]\n",
      "epoch:12 step:9871[D loss: 0.433353, acc: 67.97%, op_acc: 35.94%] [G loss: 0.887141]\n",
      "epoch:12 step:9872[D loss: 0.440567, acc: 57.81%, op_acc: 35.16%] [G loss: 0.872536]\n",
      "epoch:12 step:9873[D loss: 0.445737, acc: 60.16%, op_acc: 39.06%] [G loss: 0.849055]\n",
      "epoch:12 step:9874[D loss: 0.443990, acc: 57.03%, op_acc: 37.50%] [G loss: 0.897648]\n",
      "epoch:12 step:9875[D loss: 0.420012, acc: 65.62%, op_acc: 35.94%] [G loss: 0.921579]\n",
      "epoch:12 step:9876[D loss: 0.464129, acc: 54.69%, op_acc: 34.38%] [G loss: 0.911074]\n",
      "epoch:12 step:9877[D loss: 0.428330, acc: 60.16%, op_acc: 37.50%] [G loss: 0.928537]\n",
      "epoch:12 step:9878[D loss: 0.451412, acc: 56.25%, op_acc: 33.59%] [G loss: 0.938762]\n",
      "epoch:12 step:9879[D loss: 0.429700, acc: 61.72%, op_acc: 37.50%] [G loss: 0.807566]\n",
      "epoch:12 step:9880[D loss: 0.452047, acc: 56.25%, op_acc: 32.81%] [G loss: 0.861049]\n",
      "epoch:12 step:9881[D loss: 0.457981, acc: 56.25%, op_acc: 35.16%] [G loss: 0.851839]\n",
      "epoch:12 step:9882[D loss: 0.455523, acc: 53.12%, op_acc: 37.50%] [G loss: 0.756573]\n",
      "epoch:12 step:9883[D loss: 0.417651, acc: 58.59%, op_acc: 41.41%] [G loss: 0.822708]\n",
      "epoch:12 step:9884[D loss: 0.471366, acc: 53.91%, op_acc: 28.12%] [G loss: 0.845635]\n",
      "epoch:12 step:9885[D loss: 0.464247, acc: 54.69%, op_acc: 30.47%] [G loss: 0.859895]\n",
      "epoch:12 step:9886[D loss: 0.436782, acc: 60.94%, op_acc: 32.03%] [G loss: 0.873204]\n",
      "epoch:12 step:9887[D loss: 0.447830, acc: 61.72%, op_acc: 31.25%] [G loss: 0.934202]\n",
      "epoch:12 step:9888[D loss: 0.429143, acc: 62.50%, op_acc: 41.41%] [G loss: 0.884079]\n",
      "epoch:12 step:9889[D loss: 0.451100, acc: 56.25%, op_acc: 29.69%] [G loss: 0.900235]\n",
      "epoch:12 step:9890[D loss: 0.428312, acc: 58.59%, op_acc: 35.16%] [G loss: 0.884525]\n",
      "epoch:12 step:9891[D loss: 0.417516, acc: 58.59%, op_acc: 34.38%] [G loss: 0.887047]\n",
      "epoch:12 step:9892[D loss: 0.417659, acc: 60.16%, op_acc: 39.84%] [G loss: 0.935770]\n",
      "epoch:12 step:9893[D loss: 0.449155, acc: 56.25%, op_acc: 33.59%] [G loss: 0.929566]\n",
      "epoch:12 step:9894[D loss: 0.440063, acc: 60.94%, op_acc: 35.16%] [G loss: 0.909861]\n",
      "epoch:12 step:9895[D loss: 0.440450, acc: 52.34%, op_acc: 35.94%] [G loss: 0.934287]\n",
      "epoch:12 step:9896[D loss: 0.456262, acc: 53.91%, op_acc: 32.03%] [G loss: 0.875137]\n",
      "epoch:12 step:9897[D loss: 0.430199, acc: 66.41%, op_acc: 26.56%] [G loss: 0.974155]\n",
      "epoch:12 step:9898[D loss: 0.461826, acc: 55.47%, op_acc: 29.69%] [G loss: 0.984207]\n",
      "epoch:12 step:9899[D loss: 0.413757, acc: 64.06%, op_acc: 32.81%] [G loss: 1.010983]\n",
      "epoch:12 step:9900[D loss: 0.426346, acc: 58.59%, op_acc: 42.19%] [G loss: 1.024729]\n",
      "epoch:12 step:9901[D loss: 0.401741, acc: 65.62%, op_acc: 34.38%] [G loss: 0.940955]\n",
      "epoch:12 step:9902[D loss: 0.410944, acc: 64.84%, op_acc: 36.72%] [G loss: 0.968521]\n",
      "epoch:12 step:9903[D loss: 0.445923, acc: 60.94%, op_acc: 37.50%] [G loss: 0.840157]\n",
      "epoch:12 step:9904[D loss: 0.425838, acc: 65.62%, op_acc: 39.06%] [G loss: 0.915560]\n",
      "epoch:12 step:9905[D loss: 0.446438, acc: 53.91%, op_acc: 37.50%] [G loss: 0.998100]\n",
      "epoch:12 step:9906[D loss: 0.419462, acc: 61.72%, op_acc: 41.41%] [G loss: 0.898481]\n",
      "epoch:12 step:9907[D loss: 0.448520, acc: 56.25%, op_acc: 35.94%] [G loss: 0.792860]\n",
      "epoch:12 step:9908[D loss: 0.398940, acc: 60.94%, op_acc: 42.19%] [G loss: 0.887312]\n",
      "epoch:12 step:9909[D loss: 0.444734, acc: 68.75%, op_acc: 32.81%] [G loss: 0.880208]\n",
      "epoch:12 step:9910[D loss: 0.445699, acc: 60.94%, op_acc: 34.38%] [G loss: 0.804532]\n",
      "epoch:12 step:9911[D loss: 0.425385, acc: 62.50%, op_acc: 35.94%] [G loss: 0.879666]\n",
      "epoch:12 step:9912[D loss: 0.405891, acc: 65.62%, op_acc: 42.19%] [G loss: 0.946894]\n",
      "epoch:12 step:9913[D loss: 0.412215, acc: 62.50%, op_acc: 44.53%] [G loss: 0.829161]\n",
      "epoch:12 step:9914[D loss: 0.430220, acc: 64.06%, op_acc: 38.28%] [G loss: 0.944256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:9915[D loss: 0.435071, acc: 61.72%, op_acc: 34.38%] [G loss: 0.889245]\n",
      "epoch:12 step:9916[D loss: 0.408043, acc: 65.62%, op_acc: 38.28%] [G loss: 0.896877]\n",
      "epoch:12 step:9917[D loss: 0.391007, acc: 71.88%, op_acc: 39.06%] [G loss: 0.933037]\n",
      "epoch:12 step:9918[D loss: 0.432929, acc: 58.59%, op_acc: 39.84%] [G loss: 0.911708]\n",
      "epoch:12 step:9919[D loss: 0.443114, acc: 58.59%, op_acc: 35.16%] [G loss: 0.856551]\n",
      "epoch:12 step:9920[D loss: 0.439437, acc: 62.50%, op_acc: 33.59%] [G loss: 0.876325]\n",
      "epoch:12 step:9921[D loss: 0.433856, acc: 58.59%, op_acc: 39.84%] [G loss: 0.850627]\n",
      "epoch:12 step:9922[D loss: 0.456313, acc: 50.78%, op_acc: 34.38%] [G loss: 0.843063]\n",
      "epoch:12 step:9923[D loss: 0.439746, acc: 56.25%, op_acc: 34.38%] [G loss: 0.821785]\n",
      "epoch:12 step:9924[D loss: 0.454643, acc: 57.81%, op_acc: 31.25%] [G loss: 0.825146]\n",
      "epoch:12 step:9925[D loss: 0.421115, acc: 60.16%, op_acc: 38.28%] [G loss: 0.864342]\n",
      "epoch:12 step:9926[D loss: 0.427961, acc: 63.28%, op_acc: 35.16%] [G loss: 0.877454]\n",
      "epoch:12 step:9927[D loss: 0.417664, acc: 56.25%, op_acc: 38.28%] [G loss: 0.879941]\n",
      "epoch:12 step:9928[D loss: 0.412323, acc: 60.94%, op_acc: 35.94%] [G loss: 0.939878]\n",
      "epoch:12 step:9929[D loss: 0.475583, acc: 50.00%, op_acc: 29.69%] [G loss: 0.793084]\n",
      "epoch:12 step:9930[D loss: 0.400410, acc: 71.09%, op_acc: 42.19%] [G loss: 0.854728]\n",
      "epoch:12 step:9931[D loss: 0.394610, acc: 68.75%, op_acc: 40.62%] [G loss: 1.001997]\n",
      "epoch:12 step:9932[D loss: 0.433560, acc: 59.38%, op_acc: 39.84%] [G loss: 0.904151]\n",
      "epoch:12 step:9933[D loss: 0.396090, acc: 71.88%, op_acc: 38.28%] [G loss: 0.849269]\n",
      "epoch:12 step:9934[D loss: 0.444364, acc: 58.59%, op_acc: 32.81%] [G loss: 0.883491]\n",
      "epoch:12 step:9935[D loss: 0.449586, acc: 58.59%, op_acc: 32.81%] [G loss: 0.939027]\n",
      "epoch:12 step:9936[D loss: 0.433597, acc: 60.16%, op_acc: 38.28%] [G loss: 0.891301]\n",
      "epoch:12 step:9937[D loss: 0.407241, acc: 60.16%, op_acc: 35.16%] [G loss: 0.959692]\n",
      "epoch:12 step:9938[D loss: 0.439439, acc: 61.72%, op_acc: 35.94%] [G loss: 0.925975]\n",
      "epoch:12 step:9939[D loss: 0.418371, acc: 65.62%, op_acc: 34.38%] [G loss: 0.970119]\n",
      "epoch:12 step:9940[D loss: 0.406179, acc: 65.62%, op_acc: 42.97%] [G loss: 0.930563]\n",
      "epoch:12 step:9941[D loss: 0.450110, acc: 51.56%, op_acc: 39.84%] [G loss: 0.855965]\n",
      "epoch:12 step:9942[D loss: 0.441034, acc: 55.47%, op_acc: 35.16%] [G loss: 0.996953]\n",
      "epoch:12 step:9943[D loss: 0.440144, acc: 53.91%, op_acc: 41.41%] [G loss: 0.948945]\n",
      "epoch:12 step:9944[D loss: 0.426191, acc: 56.25%, op_acc: 36.72%] [G loss: 0.896075]\n",
      "epoch:12 step:9945[D loss: 0.460226, acc: 50.78%, op_acc: 39.06%] [G loss: 0.847187]\n",
      "epoch:12 step:9946[D loss: 0.450535, acc: 65.62%, op_acc: 30.47%] [G loss: 0.936790]\n",
      "epoch:12 step:9947[D loss: 0.455330, acc: 55.47%, op_acc: 31.25%] [G loss: 0.878251]\n",
      "epoch:12 step:9948[D loss: 0.435615, acc: 58.59%, op_acc: 35.94%] [G loss: 0.825951]\n",
      "epoch:12 step:9949[D loss: 0.452734, acc: 58.59%, op_acc: 35.94%] [G loss: 0.883320]\n",
      "epoch:12 step:9950[D loss: 0.448716, acc: 59.38%, op_acc: 37.50%] [G loss: 0.928088]\n",
      "epoch:12 step:9951[D loss: 0.422193, acc: 61.72%, op_acc: 39.06%] [G loss: 0.840838]\n",
      "epoch:12 step:9952[D loss: 0.447609, acc: 60.16%, op_acc: 37.50%] [G loss: 0.945022]\n",
      "epoch:12 step:9953[D loss: 0.450267, acc: 60.16%, op_acc: 31.25%] [G loss: 0.896434]\n",
      "epoch:12 step:9954[D loss: 0.452977, acc: 54.69%, op_acc: 32.03%] [G loss: 0.900713]\n",
      "epoch:12 step:9955[D loss: 0.390258, acc: 63.28%, op_acc: 40.62%] [G loss: 0.934896]\n",
      "epoch:12 step:9956[D loss: 0.458369, acc: 57.03%, op_acc: 32.03%] [G loss: 0.902724]\n",
      "epoch:12 step:9957[D loss: 0.426113, acc: 60.94%, op_acc: 40.62%] [G loss: 0.880704]\n",
      "epoch:12 step:9958[D loss: 0.411787, acc: 68.75%, op_acc: 41.41%] [G loss: 1.019598]\n",
      "epoch:12 step:9959[D loss: 0.422940, acc: 63.28%, op_acc: 28.91%] [G loss: 0.884781]\n",
      "epoch:12 step:9960[D loss: 0.423610, acc: 60.16%, op_acc: 43.75%] [G loss: 0.889255]\n",
      "epoch:12 step:9961[D loss: 0.416840, acc: 64.84%, op_acc: 37.50%] [G loss: 0.982143]\n",
      "epoch:12 step:9962[D loss: 0.420048, acc: 64.84%, op_acc: 35.94%] [G loss: 0.920578]\n",
      "epoch:12 step:9963[D loss: 0.447399, acc: 57.03%, op_acc: 30.47%] [G loss: 0.881625]\n",
      "epoch:12 step:9964[D loss: 0.439188, acc: 59.38%, op_acc: 32.03%] [G loss: 0.880745]\n",
      "epoch:12 step:9965[D loss: 0.446861, acc: 55.47%, op_acc: 33.59%] [G loss: 0.868137]\n",
      "epoch:12 step:9966[D loss: 0.418726, acc: 60.16%, op_acc: 32.81%] [G loss: 0.835767]\n",
      "epoch:12 step:9967[D loss: 0.435897, acc: 64.06%, op_acc: 32.03%] [G loss: 0.829103]\n",
      "epoch:12 step:9968[D loss: 0.414579, acc: 57.81%, op_acc: 43.75%] [G loss: 0.884002]\n",
      "epoch:12 step:9969[D loss: 0.434571, acc: 57.81%, op_acc: 39.06%] [G loss: 0.930461]\n",
      "epoch:12 step:9970[D loss: 0.434851, acc: 63.28%, op_acc: 39.06%] [G loss: 0.927208]\n",
      "epoch:12 step:9971[D loss: 0.442281, acc: 58.59%, op_acc: 34.38%] [G loss: 0.927312]\n",
      "epoch:12 step:9972[D loss: 0.423642, acc: 64.84%, op_acc: 36.72%] [G loss: 0.918522]\n",
      "epoch:12 step:9973[D loss: 0.443347, acc: 53.91%, op_acc: 33.59%] [G loss: 0.886181]\n",
      "epoch:12 step:9974[D loss: 0.417533, acc: 57.03%, op_acc: 38.28%] [G loss: 0.811877]\n",
      "epoch:12 step:9975[D loss: 0.402966, acc: 55.47%, op_acc: 42.19%] [G loss: 0.879887]\n",
      "epoch:12 step:9976[D loss: 0.453695, acc: 59.38%, op_acc: 28.12%] [G loss: 0.903863]\n",
      "epoch:12 step:9977[D loss: 0.428580, acc: 65.62%, op_acc: 37.50%] [G loss: 0.861330]\n",
      "epoch:12 step:9978[D loss: 0.431573, acc: 56.25%, op_acc: 37.50%] [G loss: 0.930238]\n",
      "epoch:12 step:9979[D loss: 0.442891, acc: 53.12%, op_acc: 41.41%] [G loss: 0.944947]\n",
      "epoch:12 step:9980[D loss: 0.406036, acc: 60.16%, op_acc: 39.84%] [G loss: 0.907623]\n",
      "epoch:12 step:9981[D loss: 0.441043, acc: 55.47%, op_acc: 35.94%] [G loss: 0.880294]\n",
      "epoch:12 step:9982[D loss: 0.435055, acc: 60.16%, op_acc: 32.03%] [G loss: 0.850129]\n",
      "epoch:12 step:9983[D loss: 0.422276, acc: 63.28%, op_acc: 38.28%] [G loss: 0.923800]\n",
      "epoch:12 step:9984[D loss: 0.436101, acc: 60.94%, op_acc: 36.72%] [G loss: 0.946589]\n",
      "epoch:12 step:9985[D loss: 0.455732, acc: 56.25%, op_acc: 42.19%] [G loss: 0.923065]\n",
      "epoch:12 step:9986[D loss: 0.436837, acc: 58.59%, op_acc: 35.94%] [G loss: 0.904388]\n",
      "epoch:12 step:9987[D loss: 0.414983, acc: 64.84%, op_acc: 41.41%] [G loss: 0.837431]\n",
      "epoch:12 step:9988[D loss: 0.424613, acc: 62.50%, op_acc: 35.94%] [G loss: 0.920004]\n",
      "epoch:12 step:9989[D loss: 0.460489, acc: 52.34%, op_acc: 33.59%] [G loss: 0.970132]\n",
      "epoch:12 step:9990[D loss: 0.411658, acc: 65.62%, op_acc: 40.62%] [G loss: 0.861768]\n",
      "epoch:12 step:9991[D loss: 0.441283, acc: 61.72%, op_acc: 34.38%] [G loss: 0.956037]\n",
      "epoch:12 step:9992[D loss: 0.472915, acc: 53.91%, op_acc: 29.69%] [G loss: 0.911932]\n",
      "epoch:12 step:9993[D loss: 0.436562, acc: 60.16%, op_acc: 32.81%] [G loss: 0.946428]\n",
      "epoch:12 step:9994[D loss: 0.478711, acc: 60.16%, op_acc: 36.72%] [G loss: 0.925155]\n",
      "epoch:12 step:9995[D loss: 0.419710, acc: 63.28%, op_acc: 36.72%] [G loss: 0.879034]\n",
      "epoch:12 step:9996[D loss: 0.435926, acc: 60.16%, op_acc: 38.28%] [G loss: 0.866132]\n",
      "epoch:12 step:9997[D loss: 0.462914, acc: 57.81%, op_acc: 34.38%] [G loss: 0.849642]\n",
      "epoch:12 step:9998[D loss: 0.449846, acc: 50.00%, op_acc: 35.16%] [G loss: 0.873490]\n",
      "epoch:12 step:9999[D loss: 0.426555, acc: 60.94%, op_acc: 36.72%] [G loss: 0.935791]\n",
      "epoch:12 step:10000[D loss: 0.444817, acc: 57.03%, op_acc: 33.59%] [G loss: 0.842997]\n",
      "epoch:12 step:10001[D loss: 0.454100, acc: 56.25%, op_acc: 33.59%] [G loss: 0.924057]\n",
      "epoch:12 step:10002[D loss: 0.388435, acc: 65.62%, op_acc: 40.62%] [G loss: 0.865128]\n",
      "epoch:12 step:10003[D loss: 0.436988, acc: 64.06%, op_acc: 36.72%] [G loss: 0.852882]\n",
      "epoch:12 step:10004[D loss: 0.421552, acc: 66.41%, op_acc: 36.72%] [G loss: 0.869485]\n",
      "epoch:12 step:10005[D loss: 0.433791, acc: 56.25%, op_acc: 33.59%] [G loss: 0.827284]\n",
      "epoch:12 step:10006[D loss: 0.417071, acc: 57.81%, op_acc: 42.19%] [G loss: 0.868053]\n",
      "epoch:12 step:10007[D loss: 0.431171, acc: 61.72%, op_acc: 36.72%] [G loss: 0.798363]\n",
      "epoch:12 step:10008[D loss: 0.450065, acc: 54.69%, op_acc: 39.06%] [G loss: 0.863808]\n",
      "epoch:12 step:10009[D loss: 0.419888, acc: 63.28%, op_acc: 35.94%] [G loss: 0.922807]\n",
      "epoch:12 step:10010[D loss: 0.436415, acc: 58.59%, op_acc: 39.06%] [G loss: 0.903068]\n",
      "epoch:12 step:10011[D loss: 0.500192, acc: 47.66%, op_acc: 30.47%] [G loss: 0.864528]\n",
      "epoch:12 step:10012[D loss: 0.465455, acc: 53.91%, op_acc: 36.72%] [G loss: 0.869760]\n",
      "epoch:12 step:10013[D loss: 0.446429, acc: 64.06%, op_acc: 32.03%] [G loss: 0.774470]\n",
      "epoch:12 step:10014[D loss: 0.440691, acc: 62.50%, op_acc: 35.16%] [G loss: 0.905575]\n",
      "epoch:12 step:10015[D loss: 0.450898, acc: 58.59%, op_acc: 31.25%] [G loss: 0.788949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10016[D loss: 0.404918, acc: 66.41%, op_acc: 41.41%] [G loss: 0.938522]\n",
      "epoch:12 step:10017[D loss: 0.430310, acc: 60.94%, op_acc: 38.28%] [G loss: 0.860040]\n",
      "epoch:12 step:10018[D loss: 0.454626, acc: 60.94%, op_acc: 32.81%] [G loss: 0.828165]\n",
      "epoch:12 step:10019[D loss: 0.410662, acc: 61.72%, op_acc: 38.28%] [G loss: 0.889628]\n",
      "epoch:12 step:10020[D loss: 0.428412, acc: 64.84%, op_acc: 30.47%] [G loss: 0.970851]\n",
      "epoch:12 step:10021[D loss: 0.434381, acc: 63.28%, op_acc: 37.50%] [G loss: 0.905964]\n",
      "epoch:12 step:10022[D loss: 0.439233, acc: 66.41%, op_acc: 37.50%] [G loss: 0.931837]\n",
      "epoch:12 step:10023[D loss: 0.430185, acc: 55.47%, op_acc: 39.84%] [G loss: 0.806327]\n",
      "epoch:12 step:10024[D loss: 0.430029, acc: 63.28%, op_acc: 37.50%] [G loss: 0.909861]\n",
      "epoch:12 step:10025[D loss: 0.387486, acc: 68.75%, op_acc: 43.75%] [G loss: 0.899983]\n",
      "epoch:12 step:10026[D loss: 0.426764, acc: 59.38%, op_acc: 37.50%] [G loss: 0.889628]\n",
      "epoch:12 step:10027[D loss: 0.424008, acc: 63.28%, op_acc: 32.03%] [G loss: 0.925744]\n",
      "epoch:12 step:10028[D loss: 0.448439, acc: 57.03%, op_acc: 32.03%] [G loss: 0.915651]\n",
      "epoch:12 step:10029[D loss: 0.416335, acc: 66.41%, op_acc: 31.25%] [G loss: 0.982980]\n",
      "epoch:12 step:10030[D loss: 0.447181, acc: 53.91%, op_acc: 35.16%] [G loss: 0.822902]\n",
      "epoch:12 step:10031[D loss: 0.434897, acc: 64.84%, op_acc: 33.59%] [G loss: 0.948045]\n",
      "epoch:12 step:10032[D loss: 0.453622, acc: 51.56%, op_acc: 35.94%] [G loss: 0.863078]\n",
      "epoch:12 step:10033[D loss: 0.420371, acc: 59.38%, op_acc: 40.62%] [G loss: 0.844175]\n",
      "epoch:12 step:10034[D loss: 0.410536, acc: 59.38%, op_acc: 40.62%] [G loss: 0.862353]\n",
      "epoch:12 step:10035[D loss: 0.434834, acc: 51.56%, op_acc: 33.59%] [G loss: 0.819397]\n",
      "epoch:12 step:10036[D loss: 0.412812, acc: 64.84%, op_acc: 33.59%] [G loss: 0.922306]\n",
      "epoch:12 step:10037[D loss: 0.463593, acc: 56.25%, op_acc: 32.03%] [G loss: 0.826475]\n",
      "epoch:12 step:10038[D loss: 0.438413, acc: 64.06%, op_acc: 30.47%] [G loss: 0.894439]\n",
      "epoch:12 step:10039[D loss: 0.425997, acc: 58.59%, op_acc: 33.59%] [G loss: 0.927211]\n",
      "epoch:12 step:10040[D loss: 0.411639, acc: 67.19%, op_acc: 39.06%] [G loss: 0.886896]\n",
      "epoch:12 step:10041[D loss: 0.461489, acc: 48.44%, op_acc: 33.59%] [G loss: 0.867357]\n",
      "epoch:12 step:10042[D loss: 0.422110, acc: 61.72%, op_acc: 40.62%] [G loss: 0.912197]\n",
      "epoch:12 step:10043[D loss: 0.473531, acc: 48.44%, op_acc: 31.25%] [G loss: 0.842750]\n",
      "epoch:12 step:10044[D loss: 0.480350, acc: 50.00%, op_acc: 34.38%] [G loss: 0.956123]\n",
      "epoch:12 step:10045[D loss: 0.440366, acc: 62.50%, op_acc: 32.81%] [G loss: 0.974421]\n",
      "epoch:12 step:10046[D loss: 0.427482, acc: 57.03%, op_acc: 39.06%] [G loss: 0.974691]\n",
      "epoch:12 step:10047[D loss: 0.434617, acc: 55.47%, op_acc: 35.94%] [G loss: 0.903876]\n",
      "epoch:12 step:10048[D loss: 0.446652, acc: 57.81%, op_acc: 37.50%] [G loss: 0.877450]\n",
      "epoch:12 step:10049[D loss: 0.497137, acc: 49.22%, op_acc: 30.47%] [G loss: 0.936696]\n",
      "epoch:12 step:10050[D loss: 0.448007, acc: 53.91%, op_acc: 40.62%] [G loss: 0.834120]\n",
      "epoch:12 step:10051[D loss: 0.446117, acc: 57.81%, op_acc: 35.94%] [G loss: 0.868259]\n",
      "epoch:12 step:10052[D loss: 0.457664, acc: 54.69%, op_acc: 33.59%] [G loss: 0.854351]\n",
      "epoch:12 step:10053[D loss: 0.459022, acc: 56.25%, op_acc: 31.25%] [G loss: 0.991738]\n",
      "epoch:12 step:10054[D loss: 0.418772, acc: 52.34%, op_acc: 41.41%] [G loss: 0.886396]\n",
      "epoch:12 step:10055[D loss: 0.426173, acc: 59.38%, op_acc: 37.50%] [G loss: 0.845681]\n",
      "epoch:12 step:10056[D loss: 0.435827, acc: 64.06%, op_acc: 35.16%] [G loss: 0.882305]\n",
      "epoch:12 step:10057[D loss: 0.452469, acc: 53.91%, op_acc: 32.03%] [G loss: 0.841253]\n",
      "epoch:12 step:10058[D loss: 0.452931, acc: 62.50%, op_acc: 33.59%] [G loss: 0.918365]\n",
      "epoch:12 step:10059[D loss: 0.435392, acc: 59.38%, op_acc: 33.59%] [G loss: 0.902864]\n",
      "epoch:12 step:10060[D loss: 0.414448, acc: 61.72%, op_acc: 39.84%] [G loss: 0.879782]\n",
      "epoch:12 step:10061[D loss: 0.411733, acc: 68.75%, op_acc: 42.19%] [G loss: 0.982784]\n",
      "epoch:12 step:10062[D loss: 0.427884, acc: 59.38%, op_acc: 36.72%] [G loss: 0.908127]\n",
      "epoch:12 step:10063[D loss: 0.414382, acc: 67.97%, op_acc: 39.06%] [G loss: 0.893237]\n",
      "epoch:12 step:10064[D loss: 0.488577, acc: 48.44%, op_acc: 30.47%] [G loss: 0.872774]\n",
      "epoch:12 step:10065[D loss: 0.453474, acc: 56.25%, op_acc: 33.59%] [G loss: 0.886794]\n",
      "epoch:12 step:10066[D loss: 0.453777, acc: 52.34%, op_acc: 35.94%] [G loss: 0.873933]\n",
      "epoch:12 step:10067[D loss: 0.436407, acc: 57.81%, op_acc: 35.16%] [G loss: 0.949632]\n",
      "epoch:12 step:10068[D loss: 0.444108, acc: 60.16%, op_acc: 34.38%] [G loss: 0.965200]\n",
      "epoch:12 step:10069[D loss: 0.449009, acc: 60.94%, op_acc: 38.28%] [G loss: 0.867586]\n",
      "epoch:12 step:10070[D loss: 0.433876, acc: 58.59%, op_acc: 32.03%] [G loss: 0.924820]\n",
      "epoch:12 step:10071[D loss: 0.441721, acc: 59.38%, op_acc: 34.38%] [G loss: 0.870915]\n",
      "epoch:12 step:10072[D loss: 0.437455, acc: 62.50%, op_acc: 35.16%] [G loss: 0.874829]\n",
      "epoch:12 step:10073[D loss: 0.456449, acc: 54.69%, op_acc: 31.25%] [G loss: 0.930242]\n",
      "epoch:12 step:10074[D loss: 0.429803, acc: 60.16%, op_acc: 36.72%] [G loss: 0.921539]\n",
      "epoch:12 step:10075[D loss: 0.456971, acc: 57.03%, op_acc: 33.59%] [G loss: 0.894201]\n",
      "epoch:12 step:10076[D loss: 0.413251, acc: 57.81%, op_acc: 41.41%] [G loss: 0.900382]\n",
      "epoch:12 step:10077[D loss: 0.446097, acc: 56.25%, op_acc: 35.94%] [G loss: 0.879346]\n",
      "epoch:12 step:10078[D loss: 0.447816, acc: 51.56%, op_acc: 31.25%] [G loss: 0.829125]\n",
      "epoch:12 step:10079[D loss: 0.465734, acc: 53.12%, op_acc: 33.59%] [G loss: 0.899549]\n",
      "epoch:12 step:10080[D loss: 0.438656, acc: 57.03%, op_acc: 32.81%] [G loss: 0.931338]\n",
      "epoch:12 step:10081[D loss: 0.442600, acc: 57.03%, op_acc: 35.94%] [G loss: 0.932409]\n",
      "epoch:12 step:10082[D loss: 0.420446, acc: 59.38%, op_acc: 43.75%] [G loss: 0.898811]\n",
      "epoch:12 step:10083[D loss: 0.419675, acc: 63.28%, op_acc: 35.16%] [G loss: 0.938285]\n",
      "epoch:12 step:10084[D loss: 0.398396, acc: 61.72%, op_acc: 39.06%] [G loss: 0.878451]\n",
      "epoch:12 step:10085[D loss: 0.443542, acc: 50.00%, op_acc: 39.06%] [G loss: 0.902892]\n",
      "epoch:12 step:10086[D loss: 0.434214, acc: 60.16%, op_acc: 34.38%] [G loss: 0.929432]\n",
      "epoch:12 step:10087[D loss: 0.433417, acc: 54.69%, op_acc: 35.16%] [G loss: 0.896757]\n",
      "epoch:12 step:10088[D loss: 0.440325, acc: 63.28%, op_acc: 32.03%] [G loss: 0.909831]\n",
      "epoch:12 step:10089[D loss: 0.439123, acc: 57.03%, op_acc: 37.50%] [G loss: 0.733951]\n",
      "epoch:12 step:10090[D loss: 0.454472, acc: 60.16%, op_acc: 34.38%] [G loss: 0.862451]\n",
      "epoch:12 step:10091[D loss: 0.459929, acc: 58.59%, op_acc: 33.59%] [G loss: 0.844330]\n",
      "epoch:12 step:10092[D loss: 0.446660, acc: 59.38%, op_acc: 33.59%] [G loss: 0.896665]\n",
      "epoch:12 step:10093[D loss: 0.466692, acc: 46.09%, op_acc: 39.84%] [G loss: 0.834098]\n",
      "epoch:12 step:10094[D loss: 0.464346, acc: 52.34%, op_acc: 34.38%] [G loss: 0.894582]\n",
      "epoch:12 step:10095[D loss: 0.459021, acc: 52.34%, op_acc: 32.03%] [G loss: 0.807692]\n",
      "epoch:12 step:10096[D loss: 0.509552, acc: 50.78%, op_acc: 31.25%] [G loss: 0.882728]\n",
      "epoch:12 step:10097[D loss: 0.434459, acc: 64.84%, op_acc: 35.94%] [G loss: 0.992494]\n",
      "epoch:12 step:10098[D loss: 0.412100, acc: 64.84%, op_acc: 41.41%] [G loss: 1.001867]\n",
      "epoch:12 step:10099[D loss: 0.452106, acc: 61.72%, op_acc: 26.56%] [G loss: 0.919650]\n",
      "epoch:12 step:10100[D loss: 0.452850, acc: 58.59%, op_acc: 33.59%] [G loss: 0.895607]\n",
      "epoch:12 step:10101[D loss: 0.422654, acc: 62.50%, op_acc: 39.84%] [G loss: 0.832848]\n",
      "epoch:12 step:10102[D loss: 0.455125, acc: 54.69%, op_acc: 33.59%] [G loss: 0.853581]\n",
      "epoch:12 step:10103[D loss: 0.428243, acc: 57.81%, op_acc: 41.41%] [G loss: 0.865876]\n",
      "epoch:12 step:10104[D loss: 0.431111, acc: 60.94%, op_acc: 35.94%] [G loss: 0.904138]\n",
      "epoch:12 step:10105[D loss: 0.431358, acc: 60.94%, op_acc: 34.38%] [G loss: 0.977461]\n",
      "epoch:12 step:10106[D loss: 0.439476, acc: 53.91%, op_acc: 40.62%] [G loss: 0.870561]\n",
      "epoch:12 step:10107[D loss: 0.442209, acc: 59.38%, op_acc: 34.38%] [G loss: 0.916866]\n",
      "epoch:12 step:10108[D loss: 0.448793, acc: 59.38%, op_acc: 32.03%] [G loss: 0.823951]\n",
      "epoch:12 step:10109[D loss: 0.399313, acc: 64.06%, op_acc: 38.28%] [G loss: 0.899887]\n",
      "epoch:12 step:10110[D loss: 0.453649, acc: 56.25%, op_acc: 33.59%] [G loss: 0.892842]\n",
      "epoch:12 step:10111[D loss: 0.414451, acc: 58.59%, op_acc: 41.41%] [G loss: 0.814547]\n",
      "epoch:12 step:10112[D loss: 0.424762, acc: 57.81%, op_acc: 40.62%] [G loss: 0.842192]\n",
      "epoch:12 step:10113[D loss: 0.425544, acc: 60.16%, op_acc: 34.38%] [G loss: 0.961329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:10114[D loss: 0.419741, acc: 62.50%, op_acc: 35.94%] [G loss: 0.848444]\n",
      "epoch:12 step:10115[D loss: 0.433544, acc: 58.59%, op_acc: 37.50%] [G loss: 0.844519]\n",
      "epoch:12 step:10116[D loss: 0.425556, acc: 53.91%, op_acc: 41.41%] [G loss: 0.833495]\n",
      "epoch:12 step:10117[D loss: 0.448388, acc: 57.03%, op_acc: 35.94%] [G loss: 0.866052]\n",
      "epoch:12 step:10118[D loss: 0.417991, acc: 61.72%, op_acc: 37.50%] [G loss: 0.899195]\n",
      "epoch:12 step:10119[D loss: 0.433123, acc: 58.59%, op_acc: 35.16%] [G loss: 0.778027]\n",
      "epoch:12 step:10120[D loss: 0.461095, acc: 55.47%, op_acc: 32.03%] [G loss: 0.888223]\n",
      "epoch:12 step:10121[D loss: 0.453712, acc: 60.16%, op_acc: 31.25%] [G loss: 0.877588]\n",
      "epoch:12 step:10122[D loss: 0.402039, acc: 64.84%, op_acc: 37.50%] [G loss: 0.879446]\n",
      "epoch:12 step:10123[D loss: 0.457883, acc: 61.72%, op_acc: 36.72%] [G loss: 0.853002]\n",
      "epoch:12 step:10124[D loss: 0.418033, acc: 66.41%, op_acc: 39.84%] [G loss: 0.939227]\n",
      "epoch:12 step:10125[D loss: 0.441134, acc: 62.50%, op_acc: 35.94%] [G loss: 0.756193]\n",
      "epoch:12 step:10126[D loss: 0.425741, acc: 60.94%, op_acc: 37.50%] [G loss: 0.885093]\n",
      "epoch:12 step:10127[D loss: 0.466326, acc: 50.00%, op_acc: 32.81%] [G loss: 0.882496]\n",
      "epoch:12 step:10128[D loss: 0.421214, acc: 64.06%, op_acc: 35.94%] [G loss: 0.891061]\n",
      "epoch:12 step:10129[D loss: 0.447825, acc: 55.47%, op_acc: 39.06%] [G loss: 0.878731]\n",
      "epoch:12 step:10130[D loss: 0.404604, acc: 66.41%, op_acc: 36.72%] [G loss: 0.925230]\n",
      "epoch:12 step:10131[D loss: 0.455005, acc: 56.25%, op_acc: 33.59%] [G loss: 0.850067]\n",
      "epoch:12 step:10132[D loss: 0.419358, acc: 62.50%, op_acc: 35.94%] [G loss: 0.912588]\n",
      "epoch:12 step:10133[D loss: 0.416130, acc: 65.62%, op_acc: 35.16%] [G loss: 0.920296]\n",
      "epoch:12 step:10134[D loss: 0.452713, acc: 52.34%, op_acc: 41.41%] [G loss: 0.976079]\n",
      "epoch:12 step:10135[D loss: 0.452939, acc: 52.34%, op_acc: 35.94%] [G loss: 0.922577]\n",
      "epoch:12 step:10136[D loss: 0.433428, acc: 53.91%, op_acc: 36.72%] [G loss: 0.847872]\n",
      "epoch:12 step:10137[D loss: 0.421098, acc: 58.59%, op_acc: 40.62%] [G loss: 0.884608]\n",
      "epoch:12 step:10138[D loss: 0.452360, acc: 58.59%, op_acc: 30.47%] [G loss: 0.887677]\n",
      "epoch:12 step:10139[D loss: 0.430849, acc: 58.59%, op_acc: 33.59%] [G loss: 0.869272]\n",
      "epoch:12 step:10140[D loss: 0.433048, acc: 62.50%, op_acc: 35.16%] [G loss: 0.962093]\n",
      "epoch:12 step:10141[D loss: 0.416669, acc: 62.50%, op_acc: 37.50%] [G loss: 0.809926]\n",
      "epoch:12 step:10142[D loss: 0.445823, acc: 54.69%, op_acc: 36.72%] [G loss: 0.896753]\n",
      "epoch:12 step:10143[D loss: 0.447059, acc: 60.16%, op_acc: 28.12%] [G loss: 0.880753]\n",
      "epoch:12 step:10144[D loss: 0.455104, acc: 53.91%, op_acc: 36.72%] [G loss: 0.897517]\n",
      "epoch:12 step:10145[D loss: 0.441884, acc: 63.28%, op_acc: 32.03%] [G loss: 0.831688]\n",
      "epoch:12 step:10146[D loss: 0.396765, acc: 65.62%, op_acc: 39.84%] [G loss: 0.915145]\n",
      "epoch:12 step:10147[D loss: 0.429971, acc: 64.84%, op_acc: 38.28%] [G loss: 0.865675]\n",
      "epoch:12 step:10148[D loss: 0.435482, acc: 53.12%, op_acc: 36.72%] [G loss: 0.946657]\n",
      "epoch:12 step:10149[D loss: 0.460600, acc: 57.03%, op_acc: 35.16%] [G loss: 0.828414]\n",
      "epoch:12 step:10150[D loss: 0.428785, acc: 58.59%, op_acc: 44.53%] [G loss: 0.863228]\n",
      "epoch:12 step:10151[D loss: 0.442959, acc: 54.69%, op_acc: 35.94%] [G loss: 0.977385]\n",
      "epoch:12 step:10152[D loss: 0.440191, acc: 55.47%, op_acc: 42.97%] [G loss: 0.804042]\n",
      "epoch:12 step:10153[D loss: 0.436992, acc: 57.81%, op_acc: 35.94%] [G loss: 0.905391]\n",
      "epoch:13 step:10154[D loss: 0.416099, acc: 70.31%, op_acc: 35.16%] [G loss: 0.957910]\n",
      "epoch:13 step:10155[D loss: 0.421526, acc: 59.38%, op_acc: 36.72%] [G loss: 0.961949]\n",
      "epoch:13 step:10156[D loss: 0.456160, acc: 54.69%, op_acc: 32.81%] [G loss: 0.893909]\n",
      "epoch:13 step:10157[D loss: 0.419344, acc: 57.03%, op_acc: 37.50%] [G loss: 0.917882]\n",
      "epoch:13 step:10158[D loss: 0.417617, acc: 61.72%, op_acc: 40.62%] [G loss: 0.948604]\n",
      "epoch:13 step:10159[D loss: 0.408553, acc: 66.41%, op_acc: 35.16%] [G loss: 0.893864]\n",
      "epoch:13 step:10160[D loss: 0.416379, acc: 60.16%, op_acc: 41.41%] [G loss: 0.908719]\n",
      "epoch:13 step:10161[D loss: 0.435035, acc: 55.47%, op_acc: 33.59%] [G loss: 0.854768]\n",
      "epoch:13 step:10162[D loss: 0.406142, acc: 70.31%, op_acc: 36.72%] [G loss: 0.885743]\n",
      "epoch:13 step:10163[D loss: 0.454129, acc: 58.59%, op_acc: 31.25%] [G loss: 0.912689]\n",
      "epoch:13 step:10164[D loss: 0.455149, acc: 60.94%, op_acc: 32.81%] [G loss: 0.875805]\n",
      "epoch:13 step:10165[D loss: 0.414317, acc: 67.19%, op_acc: 31.25%] [G loss: 0.828808]\n",
      "epoch:13 step:10166[D loss: 0.400196, acc: 68.75%, op_acc: 39.84%] [G loss: 0.899608]\n",
      "epoch:13 step:10167[D loss: 0.442597, acc: 59.38%, op_acc: 38.28%] [G loss: 0.881060]\n",
      "epoch:13 step:10168[D loss: 0.442378, acc: 54.69%, op_acc: 34.38%] [G loss: 0.856780]\n",
      "epoch:13 step:10169[D loss: 0.404339, acc: 67.97%, op_acc: 37.50%] [G loss: 0.937047]\n",
      "epoch:13 step:10170[D loss: 0.416219, acc: 64.84%, op_acc: 37.50%] [G loss: 0.969869]\n",
      "epoch:13 step:10171[D loss: 0.466446, acc: 50.00%, op_acc: 39.06%] [G loss: 0.870745]\n",
      "epoch:13 step:10172[D loss: 0.451964, acc: 51.56%, op_acc: 41.41%] [G loss: 0.893976]\n",
      "epoch:13 step:10173[D loss: 0.420420, acc: 60.16%, op_acc: 39.06%] [G loss: 0.906443]\n",
      "epoch:13 step:10174[D loss: 0.458692, acc: 58.59%, op_acc: 35.16%] [G loss: 0.904333]\n",
      "epoch:13 step:10175[D loss: 0.436350, acc: 57.03%, op_acc: 35.16%] [G loss: 0.875265]\n",
      "epoch:13 step:10176[D loss: 0.455832, acc: 48.44%, op_acc: 36.72%] [G loss: 0.904741]\n",
      "epoch:13 step:10177[D loss: 0.455911, acc: 56.25%, op_acc: 36.72%] [G loss: 0.921893]\n",
      "epoch:13 step:10178[D loss: 0.460054, acc: 54.69%, op_acc: 35.94%] [G loss: 0.931702]\n",
      "epoch:13 step:10179[D loss: 0.411927, acc: 62.50%, op_acc: 37.50%] [G loss: 0.884192]\n",
      "epoch:13 step:10180[D loss: 0.420825, acc: 60.94%, op_acc: 42.19%] [G loss: 0.858362]\n",
      "epoch:13 step:10181[D loss: 0.444550, acc: 57.03%, op_acc: 35.94%] [G loss: 0.853728]\n",
      "epoch:13 step:10182[D loss: 0.440580, acc: 57.81%, op_acc: 40.62%] [G loss: 0.841937]\n",
      "epoch:13 step:10183[D loss: 0.426986, acc: 57.81%, op_acc: 36.72%] [G loss: 0.887961]\n",
      "epoch:13 step:10184[D loss: 0.471493, acc: 58.59%, op_acc: 30.47%] [G loss: 0.859452]\n",
      "epoch:13 step:10185[D loss: 0.459519, acc: 63.28%, op_acc: 28.12%] [G loss: 0.901223]\n",
      "epoch:13 step:10186[D loss: 0.411778, acc: 58.59%, op_acc: 43.75%] [G loss: 0.876158]\n",
      "epoch:13 step:10187[D loss: 0.416573, acc: 64.84%, op_acc: 39.06%] [G loss: 0.902435]\n",
      "epoch:13 step:10188[D loss: 0.468017, acc: 55.47%, op_acc: 30.47%] [G loss: 0.880921]\n",
      "epoch:13 step:10189[D loss: 0.407373, acc: 67.19%, op_acc: 38.28%] [G loss: 0.900768]\n",
      "epoch:13 step:10190[D loss: 0.435571, acc: 55.47%, op_acc: 35.16%] [G loss: 0.819214]\n",
      "epoch:13 step:10191[D loss: 0.425272, acc: 58.59%, op_acc: 35.16%] [G loss: 0.862338]\n",
      "epoch:13 step:10192[D loss: 0.394726, acc: 67.19%, op_acc: 40.62%] [G loss: 1.006711]\n",
      "epoch:13 step:10193[D loss: 0.459196, acc: 57.03%, op_acc: 33.59%] [G loss: 0.805008]\n",
      "epoch:13 step:10194[D loss: 0.395038, acc: 64.84%, op_acc: 42.97%] [G loss: 0.861270]\n",
      "epoch:13 step:10195[D loss: 0.395950, acc: 66.41%, op_acc: 46.88%] [G loss: 0.872565]\n",
      "epoch:13 step:10196[D loss: 0.433595, acc: 58.59%, op_acc: 35.16%] [G loss: 0.911597]\n",
      "epoch:13 step:10197[D loss: 0.442431, acc: 57.81%, op_acc: 34.38%] [G loss: 0.839646]\n",
      "epoch:13 step:10198[D loss: 0.423901, acc: 65.62%, op_acc: 33.59%] [G loss: 0.876040]\n",
      "epoch:13 step:10199[D loss: 0.440122, acc: 63.28%, op_acc: 36.72%] [G loss: 0.883059]\n",
      "epoch:13 step:10200[D loss: 0.455509, acc: 55.47%, op_acc: 34.38%] [G loss: 0.875827]\n",
      "epoch:13 step:10201[D loss: 0.448706, acc: 62.50%, op_acc: 32.03%] [G loss: 0.886277]\n",
      "epoch:13 step:10202[D loss: 0.430275, acc: 58.59%, op_acc: 35.94%] [G loss: 0.910658]\n",
      "epoch:13 step:10203[D loss: 0.453804, acc: 54.69%, op_acc: 32.81%] [G loss: 0.791840]\n",
      "epoch:13 step:10204[D loss: 0.419296, acc: 63.28%, op_acc: 33.59%] [G loss: 0.899535]\n",
      "epoch:13 step:10205[D loss: 0.433240, acc: 57.81%, op_acc: 34.38%] [G loss: 0.887225]\n",
      "epoch:13 step:10206[D loss: 0.455048, acc: 55.47%, op_acc: 30.47%] [G loss: 0.941287]\n",
      "epoch:13 step:10207[D loss: 0.474667, acc: 51.56%, op_acc: 35.16%] [G loss: 0.837318]\n",
      "epoch:13 step:10208[D loss: 0.393237, acc: 69.53%, op_acc: 41.41%] [G loss: 0.819232]\n",
      "epoch:13 step:10209[D loss: 0.412923, acc: 57.81%, op_acc: 35.94%] [G loss: 0.902515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10210[D loss: 0.440541, acc: 58.59%, op_acc: 34.38%] [G loss: 0.925050]\n",
      "epoch:13 step:10211[D loss: 0.410001, acc: 61.72%, op_acc: 50.00%] [G loss: 0.949488]\n",
      "epoch:13 step:10212[D loss: 0.419840, acc: 62.50%, op_acc: 35.16%] [G loss: 0.871352]\n",
      "epoch:13 step:10213[D loss: 0.418514, acc: 64.84%, op_acc: 34.38%] [G loss: 0.808634]\n",
      "epoch:13 step:10214[D loss: 0.430858, acc: 64.06%, op_acc: 35.16%] [G loss: 0.892062]\n",
      "epoch:13 step:10215[D loss: 0.447324, acc: 60.16%, op_acc: 34.38%] [G loss: 0.923331]\n",
      "epoch:13 step:10216[D loss: 0.455332, acc: 54.69%, op_acc: 31.25%] [G loss: 0.834219]\n",
      "epoch:13 step:10217[D loss: 0.447931, acc: 56.25%, op_acc: 38.28%] [G loss: 0.845578]\n",
      "epoch:13 step:10218[D loss: 0.443285, acc: 59.38%, op_acc: 33.59%] [G loss: 0.933177]\n",
      "epoch:13 step:10219[D loss: 0.472943, acc: 46.09%, op_acc: 33.59%] [G loss: 0.888951]\n",
      "epoch:13 step:10220[D loss: 0.452475, acc: 58.59%, op_acc: 32.03%] [G loss: 0.847006]\n",
      "epoch:13 step:10221[D loss: 0.445056, acc: 57.81%, op_acc: 29.69%] [G loss: 0.895204]\n",
      "epoch:13 step:10222[D loss: 0.405874, acc: 57.81%, op_acc: 39.84%] [G loss: 0.975881]\n",
      "epoch:13 step:10223[D loss: 0.432695, acc: 61.72%, op_acc: 36.72%] [G loss: 0.934602]\n",
      "epoch:13 step:10224[D loss: 0.478807, acc: 54.69%, op_acc: 26.56%] [G loss: 0.915650]\n",
      "epoch:13 step:10225[D loss: 0.421881, acc: 67.19%, op_acc: 37.50%] [G loss: 0.824241]\n",
      "epoch:13 step:10226[D loss: 0.453444, acc: 56.25%, op_acc: 34.38%] [G loss: 0.849809]\n",
      "epoch:13 step:10227[D loss: 0.433039, acc: 53.91%, op_acc: 37.50%] [G loss: 0.927752]\n",
      "epoch:13 step:10228[D loss: 0.416466, acc: 62.50%, op_acc: 35.94%] [G loss: 0.895418]\n",
      "epoch:13 step:10229[D loss: 0.411249, acc: 65.62%, op_acc: 44.53%] [G loss: 0.865221]\n",
      "epoch:13 step:10230[D loss: 0.413285, acc: 63.28%, op_acc: 35.94%] [G loss: 0.896253]\n",
      "epoch:13 step:10231[D loss: 0.453985, acc: 64.06%, op_acc: 31.25%] [G loss: 0.906069]\n",
      "epoch:13 step:10232[D loss: 0.438680, acc: 58.59%, op_acc: 32.03%] [G loss: 0.806442]\n",
      "epoch:13 step:10233[D loss: 0.423045, acc: 62.50%, op_acc: 29.69%] [G loss: 0.864855]\n",
      "epoch:13 step:10234[D loss: 0.445858, acc: 57.03%, op_acc: 32.81%] [G loss: 0.895238]\n",
      "epoch:13 step:10235[D loss: 0.462162, acc: 53.91%, op_acc: 32.81%] [G loss: 0.829189]\n",
      "epoch:13 step:10236[D loss: 0.432415, acc: 61.72%, op_acc: 36.72%] [G loss: 0.834512]\n",
      "epoch:13 step:10237[D loss: 0.424201, acc: 58.59%, op_acc: 43.75%] [G loss: 0.924282]\n",
      "epoch:13 step:10238[D loss: 0.476125, acc: 54.69%, op_acc: 31.25%] [G loss: 0.931530]\n",
      "epoch:13 step:10239[D loss: 0.433781, acc: 62.50%, op_acc: 36.72%] [G loss: 0.891031]\n",
      "epoch:13 step:10240[D loss: 0.418061, acc: 63.28%, op_acc: 37.50%] [G loss: 0.935486]\n",
      "epoch:13 step:10241[D loss: 0.410541, acc: 66.41%, op_acc: 34.38%] [G loss: 0.886636]\n",
      "epoch:13 step:10242[D loss: 0.460671, acc: 46.09%, op_acc: 35.16%] [G loss: 0.927270]\n",
      "epoch:13 step:10243[D loss: 0.425227, acc: 59.38%, op_acc: 39.84%] [G loss: 0.844691]\n",
      "epoch:13 step:10244[D loss: 0.418820, acc: 58.59%, op_acc: 36.72%] [G loss: 0.898433]\n",
      "epoch:13 step:10245[D loss: 0.443152, acc: 63.28%, op_acc: 37.50%] [G loss: 0.885261]\n",
      "epoch:13 step:10246[D loss: 0.450478, acc: 50.00%, op_acc: 39.06%] [G loss: 0.826725]\n",
      "epoch:13 step:10247[D loss: 0.406969, acc: 64.84%, op_acc: 35.94%] [G loss: 0.850329]\n",
      "epoch:13 step:10248[D loss: 0.430786, acc: 60.94%, op_acc: 35.94%] [G loss: 0.831637]\n",
      "epoch:13 step:10249[D loss: 0.449798, acc: 59.38%, op_acc: 32.03%] [G loss: 0.893784]\n",
      "epoch:13 step:10250[D loss: 0.424245, acc: 62.50%, op_acc: 35.16%] [G loss: 0.826267]\n",
      "epoch:13 step:10251[D loss: 0.430455, acc: 60.94%, op_acc: 33.59%] [G loss: 0.852097]\n",
      "epoch:13 step:10252[D loss: 0.460769, acc: 53.91%, op_acc: 35.94%] [G loss: 0.882576]\n",
      "epoch:13 step:10253[D loss: 0.419380, acc: 56.25%, op_acc: 39.84%] [G loss: 0.813380]\n",
      "epoch:13 step:10254[D loss: 0.437025, acc: 57.81%, op_acc: 33.59%] [G loss: 0.838310]\n",
      "epoch:13 step:10255[D loss: 0.429651, acc: 60.16%, op_acc: 36.72%] [G loss: 0.896711]\n",
      "epoch:13 step:10256[D loss: 0.432686, acc: 55.47%, op_acc: 38.28%] [G loss: 0.951002]\n",
      "epoch:13 step:10257[D loss: 0.439104, acc: 60.94%, op_acc: 37.50%] [G loss: 0.854465]\n",
      "epoch:13 step:10258[D loss: 0.444610, acc: 58.59%, op_acc: 38.28%] [G loss: 0.895381]\n",
      "epoch:13 step:10259[D loss: 0.407645, acc: 67.19%, op_acc: 38.28%] [G loss: 0.883747]\n",
      "epoch:13 step:10260[D loss: 0.449306, acc: 59.38%, op_acc: 35.16%] [G loss: 0.917229]\n",
      "epoch:13 step:10261[D loss: 0.456058, acc: 59.38%, op_acc: 33.59%] [G loss: 0.906582]\n",
      "epoch:13 step:10262[D loss: 0.457462, acc: 51.56%, op_acc: 35.16%] [G loss: 0.851177]\n",
      "epoch:13 step:10263[D loss: 0.445851, acc: 60.16%, op_acc: 39.84%] [G loss: 0.884020]\n",
      "epoch:13 step:10264[D loss: 0.442849, acc: 62.50%, op_acc: 32.03%] [G loss: 0.899120]\n",
      "epoch:13 step:10265[D loss: 0.423385, acc: 66.41%, op_acc: 32.81%] [G loss: 0.834076]\n",
      "epoch:13 step:10266[D loss: 0.437604, acc: 60.16%, op_acc: 29.69%] [G loss: 0.930767]\n",
      "epoch:13 step:10267[D loss: 0.414942, acc: 64.06%, op_acc: 41.41%] [G loss: 0.925912]\n",
      "epoch:13 step:10268[D loss: 0.427624, acc: 53.12%, op_acc: 37.50%] [G loss: 0.889787]\n",
      "epoch:13 step:10269[D loss: 0.449010, acc: 61.72%, op_acc: 35.16%] [G loss: 0.874431]\n",
      "epoch:13 step:10270[D loss: 0.442710, acc: 51.56%, op_acc: 36.72%] [G loss: 0.891333]\n",
      "epoch:13 step:10271[D loss: 0.408837, acc: 62.50%, op_acc: 39.84%] [G loss: 0.978765]\n",
      "epoch:13 step:10272[D loss: 0.439338, acc: 57.81%, op_acc: 35.16%] [G loss: 0.860742]\n",
      "epoch:13 step:10273[D loss: 0.453723, acc: 57.03%, op_acc: 35.94%] [G loss: 0.810137]\n",
      "epoch:13 step:10274[D loss: 0.432793, acc: 67.19%, op_acc: 39.06%] [G loss: 0.959310]\n",
      "epoch:13 step:10275[D loss: 0.427882, acc: 64.06%, op_acc: 38.28%] [G loss: 0.843727]\n",
      "epoch:13 step:10276[D loss: 0.452245, acc: 53.91%, op_acc: 37.50%] [G loss: 0.813887]\n",
      "epoch:13 step:10277[D loss: 0.483616, acc: 48.44%, op_acc: 36.72%] [G loss: 0.826866]\n",
      "epoch:13 step:10278[D loss: 0.454421, acc: 50.00%, op_acc: 32.03%] [G loss: 0.949975]\n",
      "epoch:13 step:10279[D loss: 0.419470, acc: 60.94%, op_acc: 38.28%] [G loss: 0.877150]\n",
      "epoch:13 step:10280[D loss: 0.429187, acc: 60.94%, op_acc: 33.59%] [G loss: 0.869175]\n",
      "epoch:13 step:10281[D loss: 0.407602, acc: 67.19%, op_acc: 36.72%] [G loss: 0.871367]\n",
      "epoch:13 step:10282[D loss: 0.431884, acc: 64.06%, op_acc: 39.06%] [G loss: 0.874211]\n",
      "epoch:13 step:10283[D loss: 0.423272, acc: 60.94%, op_acc: 36.72%] [G loss: 0.876962]\n",
      "epoch:13 step:10284[D loss: 0.416366, acc: 68.75%, op_acc: 36.72%] [G loss: 0.869156]\n",
      "epoch:13 step:10285[D loss: 0.403592, acc: 64.06%, op_acc: 40.62%] [G loss: 0.907170]\n",
      "epoch:13 step:10286[D loss: 0.445072, acc: 68.75%, op_acc: 35.94%] [G loss: 0.927104]\n",
      "epoch:13 step:10287[D loss: 0.435147, acc: 60.16%, op_acc: 33.59%] [G loss: 0.873151]\n",
      "epoch:13 step:10288[D loss: 0.430208, acc: 62.50%, op_acc: 37.50%] [G loss: 0.932523]\n",
      "epoch:13 step:10289[D loss: 0.390222, acc: 71.09%, op_acc: 39.84%] [G loss: 0.874308]\n",
      "epoch:13 step:10290[D loss: 0.424466, acc: 57.03%, op_acc: 41.41%] [G loss: 0.904903]\n",
      "epoch:13 step:10291[D loss: 0.444643, acc: 59.38%, op_acc: 32.81%] [G loss: 0.857150]\n",
      "epoch:13 step:10292[D loss: 0.403163, acc: 61.72%, op_acc: 42.97%] [G loss: 0.948282]\n",
      "epoch:13 step:10293[D loss: 0.480037, acc: 53.91%, op_acc: 32.81%] [G loss: 0.835385]\n",
      "epoch:13 step:10294[D loss: 0.461029, acc: 53.91%, op_acc: 34.38%] [G loss: 0.932421]\n",
      "epoch:13 step:10295[D loss: 0.438126, acc: 57.03%, op_acc: 38.28%] [G loss: 0.809195]\n",
      "epoch:13 step:10296[D loss: 0.423615, acc: 62.50%, op_acc: 38.28%] [G loss: 0.866830]\n",
      "epoch:13 step:10297[D loss: 0.439695, acc: 57.03%, op_acc: 37.50%] [G loss: 0.878124]\n",
      "epoch:13 step:10298[D loss: 0.449619, acc: 55.47%, op_acc: 36.72%] [G loss: 0.785195]\n",
      "epoch:13 step:10299[D loss: 0.414678, acc: 64.84%, op_acc: 35.94%] [G loss: 0.846834]\n",
      "epoch:13 step:10300[D loss: 0.439489, acc: 58.59%, op_acc: 39.06%] [G loss: 0.857645]\n",
      "epoch:13 step:10301[D loss: 0.446733, acc: 56.25%, op_acc: 37.50%] [G loss: 0.836189]\n",
      "epoch:13 step:10302[D loss: 0.431698, acc: 53.12%, op_acc: 36.72%] [G loss: 0.862338]\n",
      "epoch:13 step:10303[D loss: 0.424047, acc: 61.72%, op_acc: 39.06%] [G loss: 0.864274]\n",
      "epoch:13 step:10304[D loss: 0.461416, acc: 50.00%, op_acc: 38.28%] [G loss: 0.825591]\n",
      "epoch:13 step:10305[D loss: 0.465079, acc: 55.47%, op_acc: 33.59%] [G loss: 0.869668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10306[D loss: 0.442586, acc: 61.72%, op_acc: 32.03%] [G loss: 0.851424]\n",
      "epoch:13 step:10307[D loss: 0.402263, acc: 66.41%, op_acc: 35.94%] [G loss: 0.864530]\n",
      "epoch:13 step:10308[D loss: 0.425689, acc: 56.25%, op_acc: 32.03%] [G loss: 0.859447]\n",
      "epoch:13 step:10309[D loss: 0.461669, acc: 48.44%, op_acc: 39.06%] [G loss: 0.869585]\n",
      "epoch:13 step:10310[D loss: 0.428701, acc: 58.59%, op_acc: 34.38%] [G loss: 0.817915]\n",
      "epoch:13 step:10311[D loss: 0.442468, acc: 58.59%, op_acc: 35.16%] [G loss: 0.839085]\n",
      "epoch:13 step:10312[D loss: 0.446096, acc: 64.06%, op_acc: 35.16%] [G loss: 0.948117]\n",
      "epoch:13 step:10313[D loss: 0.462613, acc: 51.56%, op_acc: 32.81%] [G loss: 0.901527]\n",
      "epoch:13 step:10314[D loss: 0.468285, acc: 54.69%, op_acc: 34.38%] [G loss: 0.956399]\n",
      "epoch:13 step:10315[D loss: 0.428559, acc: 56.25%, op_acc: 42.97%] [G loss: 0.875658]\n",
      "epoch:13 step:10316[D loss: 0.435245, acc: 61.72%, op_acc: 35.16%] [G loss: 0.835488]\n",
      "epoch:13 step:10317[D loss: 0.448233, acc: 62.50%, op_acc: 32.81%] [G loss: 0.877526]\n",
      "epoch:13 step:10318[D loss: 0.398681, acc: 64.06%, op_acc: 40.62%] [G loss: 0.947983]\n",
      "epoch:13 step:10319[D loss: 0.454213, acc: 57.81%, op_acc: 33.59%] [G loss: 0.884154]\n",
      "epoch:13 step:10320[D loss: 0.422228, acc: 63.28%, op_acc: 35.16%] [G loss: 0.878880]\n",
      "epoch:13 step:10321[D loss: 0.425935, acc: 60.16%, op_acc: 35.94%] [G loss: 0.907163]\n",
      "epoch:13 step:10322[D loss: 0.422411, acc: 58.59%, op_acc: 37.50%] [G loss: 0.938123]\n",
      "epoch:13 step:10323[D loss: 0.465838, acc: 57.03%, op_acc: 35.16%] [G loss: 0.903375]\n",
      "epoch:13 step:10324[D loss: 0.445322, acc: 64.06%, op_acc: 31.25%] [G loss: 0.802455]\n",
      "epoch:13 step:10325[D loss: 0.423550, acc: 60.16%, op_acc: 39.84%] [G loss: 0.840077]\n",
      "epoch:13 step:10326[D loss: 0.411799, acc: 61.72%, op_acc: 36.72%] [G loss: 0.860781]\n",
      "epoch:13 step:10327[D loss: 0.473414, acc: 55.47%, op_acc: 33.59%] [G loss: 0.845395]\n",
      "epoch:13 step:10328[D loss: 0.399368, acc: 64.06%, op_acc: 35.94%] [G loss: 0.840976]\n",
      "epoch:13 step:10329[D loss: 0.456694, acc: 56.25%, op_acc: 35.16%] [G loss: 0.937611]\n",
      "epoch:13 step:10330[D loss: 0.407694, acc: 58.59%, op_acc: 35.16%] [G loss: 0.891869]\n",
      "epoch:13 step:10331[D loss: 0.464259, acc: 56.25%, op_acc: 28.91%] [G loss: 0.920705]\n",
      "epoch:13 step:10332[D loss: 0.403855, acc: 68.75%, op_acc: 43.75%] [G loss: 0.871081]\n",
      "epoch:13 step:10333[D loss: 0.424742, acc: 63.28%, op_acc: 32.81%] [G loss: 0.937932]\n",
      "epoch:13 step:10334[D loss: 0.428334, acc: 54.69%, op_acc: 38.28%] [G loss: 0.950155]\n",
      "epoch:13 step:10335[D loss: 0.453464, acc: 56.25%, op_acc: 35.16%] [G loss: 0.938257]\n",
      "epoch:13 step:10336[D loss: 0.450115, acc: 57.81%, op_acc: 42.19%] [G loss: 0.872730]\n",
      "epoch:13 step:10337[D loss: 0.455546, acc: 53.12%, op_acc: 36.72%] [G loss: 0.900195]\n",
      "epoch:13 step:10338[D loss: 0.436070, acc: 59.38%, op_acc: 35.16%] [G loss: 0.880349]\n",
      "epoch:13 step:10339[D loss: 0.438699, acc: 57.81%, op_acc: 32.03%] [G loss: 0.928426]\n",
      "epoch:13 step:10340[D loss: 0.452111, acc: 56.25%, op_acc: 33.59%] [G loss: 0.841124]\n",
      "epoch:13 step:10341[D loss: 0.459868, acc: 50.78%, op_acc: 40.62%] [G loss: 0.926026]\n",
      "epoch:13 step:10342[D loss: 0.429190, acc: 60.16%, op_acc: 38.28%] [G loss: 0.850597]\n",
      "epoch:13 step:10343[D loss: 0.435194, acc: 57.81%, op_acc: 39.84%] [G loss: 0.890741]\n",
      "epoch:13 step:10344[D loss: 0.410570, acc: 60.16%, op_acc: 41.41%] [G loss: 0.864854]\n",
      "epoch:13 step:10345[D loss: 0.390168, acc: 73.44%, op_acc: 36.72%] [G loss: 0.958675]\n",
      "epoch:13 step:10346[D loss: 0.451095, acc: 62.50%, op_acc: 32.81%] [G loss: 0.895513]\n",
      "epoch:13 step:10347[D loss: 0.413521, acc: 63.28%, op_acc: 35.94%] [G loss: 0.914083]\n",
      "epoch:13 step:10348[D loss: 0.440399, acc: 56.25%, op_acc: 38.28%] [G loss: 0.908035]\n",
      "epoch:13 step:10349[D loss: 0.431556, acc: 66.41%, op_acc: 32.81%] [G loss: 0.845013]\n",
      "epoch:13 step:10350[D loss: 0.451883, acc: 57.03%, op_acc: 37.50%] [G loss: 0.890354]\n",
      "epoch:13 step:10351[D loss: 0.465574, acc: 54.69%, op_acc: 32.81%] [G loss: 0.928482]\n",
      "epoch:13 step:10352[D loss: 0.432027, acc: 55.47%, op_acc: 35.16%] [G loss: 0.836995]\n",
      "epoch:13 step:10353[D loss: 0.433450, acc: 60.16%, op_acc: 34.38%] [G loss: 0.876743]\n",
      "epoch:13 step:10354[D loss: 0.417619, acc: 61.72%, op_acc: 35.94%] [G loss: 0.879631]\n",
      "epoch:13 step:10355[D loss: 0.460362, acc: 48.44%, op_acc: 34.38%] [G loss: 0.876522]\n",
      "epoch:13 step:10356[D loss: 0.456157, acc: 54.69%, op_acc: 31.25%] [G loss: 0.917871]\n",
      "epoch:13 step:10357[D loss: 0.441227, acc: 60.16%, op_acc: 37.50%] [G loss: 0.848094]\n",
      "epoch:13 step:10358[D loss: 0.447693, acc: 56.25%, op_acc: 35.16%] [G loss: 0.911857]\n",
      "epoch:13 step:10359[D loss: 0.424943, acc: 66.41%, op_acc: 29.69%] [G loss: 0.821399]\n",
      "epoch:13 step:10360[D loss: 0.407982, acc: 64.84%, op_acc: 42.19%] [G loss: 0.896215]\n",
      "epoch:13 step:10361[D loss: 0.452120, acc: 56.25%, op_acc: 38.28%] [G loss: 0.899330]\n",
      "epoch:13 step:10362[D loss: 0.396455, acc: 70.31%, op_acc: 35.94%] [G loss: 0.843375]\n",
      "epoch:13 step:10363[D loss: 0.472014, acc: 56.25%, op_acc: 28.12%] [G loss: 0.855464]\n",
      "epoch:13 step:10364[D loss: 0.416235, acc: 56.25%, op_acc: 39.84%] [G loss: 0.863296]\n",
      "epoch:13 step:10365[D loss: 0.402653, acc: 69.53%, op_acc: 39.06%] [G loss: 0.908944]\n",
      "epoch:13 step:10366[D loss: 0.440833, acc: 53.91%, op_acc: 34.38%] [G loss: 0.851875]\n",
      "epoch:13 step:10367[D loss: 0.432351, acc: 69.53%, op_acc: 28.91%] [G loss: 0.836174]\n",
      "epoch:13 step:10368[D loss: 0.442888, acc: 57.81%, op_acc: 35.94%] [G loss: 0.826142]\n",
      "epoch:13 step:10369[D loss: 0.432216, acc: 64.06%, op_acc: 36.72%] [G loss: 0.978400]\n",
      "epoch:13 step:10370[D loss: 0.415663, acc: 64.84%, op_acc: 34.38%] [G loss: 0.916512]\n",
      "epoch:13 step:10371[D loss: 0.438780, acc: 55.47%, op_acc: 39.84%] [G loss: 0.826510]\n",
      "epoch:13 step:10372[D loss: 0.443802, acc: 57.81%, op_acc: 33.59%] [G loss: 0.873774]\n",
      "epoch:13 step:10373[D loss: 0.450738, acc: 57.03%, op_acc: 35.94%] [G loss: 0.920404]\n",
      "epoch:13 step:10374[D loss: 0.425008, acc: 64.84%, op_acc: 35.16%] [G loss: 0.904918]\n",
      "epoch:13 step:10375[D loss: 0.469808, acc: 53.12%, op_acc: 36.72%] [G loss: 0.907301]\n",
      "epoch:13 step:10376[D loss: 0.439514, acc: 57.81%, op_acc: 35.94%] [G loss: 0.892945]\n",
      "epoch:13 step:10377[D loss: 0.439388, acc: 66.41%, op_acc: 33.59%] [G loss: 0.885845]\n",
      "epoch:13 step:10378[D loss: 0.448245, acc: 50.78%, op_acc: 37.50%] [G loss: 0.887350]\n",
      "epoch:13 step:10379[D loss: 0.406288, acc: 67.19%, op_acc: 36.72%] [G loss: 0.926087]\n",
      "epoch:13 step:10380[D loss: 0.419805, acc: 58.59%, op_acc: 35.94%] [G loss: 0.912282]\n",
      "epoch:13 step:10381[D loss: 0.409266, acc: 63.28%, op_acc: 38.28%] [G loss: 0.917736]\n",
      "epoch:13 step:10382[D loss: 0.421978, acc: 64.06%, op_acc: 35.16%] [G loss: 0.875046]\n",
      "epoch:13 step:10383[D loss: 0.424212, acc: 64.84%, op_acc: 34.38%] [G loss: 0.866691]\n",
      "epoch:13 step:10384[D loss: 0.412134, acc: 60.94%, op_acc: 41.41%] [G loss: 0.909723]\n",
      "epoch:13 step:10385[D loss: 0.478923, acc: 43.75%, op_acc: 32.81%] [G loss: 0.876615]\n",
      "epoch:13 step:10386[D loss: 0.399729, acc: 64.84%, op_acc: 39.06%] [G loss: 0.845626]\n",
      "epoch:13 step:10387[D loss: 0.468354, acc: 58.59%, op_acc: 32.81%] [G loss: 0.837524]\n",
      "epoch:13 step:10388[D loss: 0.421441, acc: 57.81%, op_acc: 39.06%] [G loss: 0.920094]\n",
      "epoch:13 step:10389[D loss: 0.428238, acc: 58.59%, op_acc: 36.72%] [G loss: 0.904191]\n",
      "epoch:13 step:10390[D loss: 0.424371, acc: 60.94%, op_acc: 39.06%] [G loss: 0.877776]\n",
      "epoch:13 step:10391[D loss: 0.446344, acc: 60.16%, op_acc: 40.62%] [G loss: 0.917087]\n",
      "epoch:13 step:10392[D loss: 0.406583, acc: 64.06%, op_acc: 42.19%] [G loss: 0.882988]\n",
      "epoch:13 step:10393[D loss: 0.429546, acc: 58.59%, op_acc: 35.94%] [G loss: 0.921107]\n",
      "epoch:13 step:10394[D loss: 0.430876, acc: 58.59%, op_acc: 37.50%] [G loss: 0.836476]\n",
      "epoch:13 step:10395[D loss: 0.438122, acc: 57.03%, op_acc: 36.72%] [G loss: 0.809018]\n",
      "epoch:13 step:10396[D loss: 0.446929, acc: 56.25%, op_acc: 36.72%] [G loss: 0.896683]\n",
      "epoch:13 step:10397[D loss: 0.428140, acc: 59.38%, op_acc: 37.50%] [G loss: 0.848222]\n",
      "epoch:13 step:10398[D loss: 0.451671, acc: 53.12%, op_acc: 35.94%] [G loss: 0.844449]\n",
      "epoch:13 step:10399[D loss: 0.496760, acc: 47.66%, op_acc: 27.34%] [G loss: 0.751894]\n",
      "epoch:13 step:10400[D loss: 0.430989, acc: 55.47%, op_acc: 39.06%] [G loss: 0.880592]\n",
      "epoch:13 step:10401[D loss: 0.463653, acc: 57.03%, op_acc: 29.69%] [G loss: 0.860349]\n",
      "epoch:13 step:10402[D loss: 0.440380, acc: 63.28%, op_acc: 38.28%] [G loss: 0.882306]\n",
      "epoch:13 step:10403[D loss: 0.466656, acc: 54.69%, op_acc: 37.50%] [G loss: 0.867805]\n",
      "epoch:13 step:10404[D loss: 0.385688, acc: 64.84%, op_acc: 42.97%] [G loss: 0.968374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10405[D loss: 0.446621, acc: 50.00%, op_acc: 41.41%] [G loss: 0.965838]\n",
      "epoch:13 step:10406[D loss: 0.428100, acc: 70.31%, op_acc: 26.56%] [G loss: 0.958223]\n",
      "epoch:13 step:10407[D loss: 0.420269, acc: 61.72%, op_acc: 32.81%] [G loss: 0.894738]\n",
      "epoch:13 step:10408[D loss: 0.480000, acc: 46.09%, op_acc: 33.59%] [G loss: 0.831043]\n",
      "epoch:13 step:10409[D loss: 0.429169, acc: 61.72%, op_acc: 38.28%] [G loss: 0.924899]\n",
      "epoch:13 step:10410[D loss: 0.450921, acc: 54.69%, op_acc: 32.03%] [G loss: 0.924300]\n",
      "epoch:13 step:10411[D loss: 0.423335, acc: 59.38%, op_acc: 39.84%] [G loss: 0.897386]\n",
      "epoch:13 step:10412[D loss: 0.426849, acc: 64.84%, op_acc: 32.81%] [G loss: 0.913973]\n",
      "epoch:13 step:10413[D loss: 0.439554, acc: 59.38%, op_acc: 35.16%] [G loss: 0.888495]\n",
      "epoch:13 step:10414[D loss: 0.414110, acc: 69.53%, op_acc: 39.84%] [G loss: 0.921973]\n",
      "epoch:13 step:10415[D loss: 0.442419, acc: 57.03%, op_acc: 35.16%] [G loss: 0.870484]\n",
      "epoch:13 step:10416[D loss: 0.453909, acc: 57.81%, op_acc: 34.38%] [G loss: 0.892576]\n",
      "epoch:13 step:10417[D loss: 0.420079, acc: 64.06%, op_acc: 37.50%] [G loss: 0.876344]\n",
      "epoch:13 step:10418[D loss: 0.418106, acc: 62.50%, op_acc: 39.06%] [G loss: 0.840170]\n",
      "epoch:13 step:10419[D loss: 0.444592, acc: 59.38%, op_acc: 33.59%] [G loss: 0.902226]\n",
      "epoch:13 step:10420[D loss: 0.465684, acc: 53.12%, op_acc: 40.62%] [G loss: 0.828121]\n",
      "epoch:13 step:10421[D loss: 0.426897, acc: 60.16%, op_acc: 42.97%] [G loss: 0.875644]\n",
      "epoch:13 step:10422[D loss: 0.436166, acc: 57.81%, op_acc: 37.50%] [G loss: 0.899782]\n",
      "epoch:13 step:10423[D loss: 0.425474, acc: 61.72%, op_acc: 38.28%] [G loss: 0.949094]\n",
      "epoch:13 step:10424[D loss: 0.416800, acc: 63.28%, op_acc: 42.97%] [G loss: 0.978085]\n",
      "epoch:13 step:10425[D loss: 0.438539, acc: 56.25%, op_acc: 35.94%] [G loss: 0.968896]\n",
      "epoch:13 step:10426[D loss: 0.435849, acc: 52.34%, op_acc: 42.97%] [G loss: 0.893430]\n",
      "epoch:13 step:10427[D loss: 0.458981, acc: 57.81%, op_acc: 39.06%] [G loss: 0.849545]\n",
      "epoch:13 step:10428[D loss: 0.427882, acc: 61.72%, op_acc: 33.59%] [G loss: 0.913343]\n",
      "epoch:13 step:10429[D loss: 0.435883, acc: 60.16%, op_acc: 32.81%] [G loss: 0.916620]\n",
      "epoch:13 step:10430[D loss: 0.430110, acc: 70.31%, op_acc: 32.81%] [G loss: 0.856229]\n",
      "epoch:13 step:10431[D loss: 0.432194, acc: 60.94%, op_acc: 36.72%] [G loss: 0.828422]\n",
      "epoch:13 step:10432[D loss: 0.448051, acc: 55.47%, op_acc: 39.06%] [G loss: 0.831822]\n",
      "epoch:13 step:10433[D loss: 0.420298, acc: 60.94%, op_acc: 39.06%] [G loss: 0.827355]\n",
      "epoch:13 step:10434[D loss: 0.467936, acc: 50.78%, op_acc: 30.47%] [G loss: 0.883967]\n",
      "epoch:13 step:10435[D loss: 0.458130, acc: 58.59%, op_acc: 36.72%] [G loss: 0.845843]\n",
      "epoch:13 step:10436[D loss: 0.430690, acc: 65.62%, op_acc: 37.50%] [G loss: 0.879089]\n",
      "epoch:13 step:10437[D loss: 0.455172, acc: 53.91%, op_acc: 35.16%] [G loss: 0.921591]\n",
      "epoch:13 step:10438[D loss: 0.438639, acc: 60.16%, op_acc: 37.50%] [G loss: 0.953218]\n",
      "epoch:13 step:10439[D loss: 0.428392, acc: 62.50%, op_acc: 32.81%] [G loss: 1.002031]\n",
      "epoch:13 step:10440[D loss: 0.456890, acc: 55.47%, op_acc: 35.16%] [G loss: 0.859716]\n",
      "epoch:13 step:10441[D loss: 0.433378, acc: 58.59%, op_acc: 39.06%] [G loss: 0.858724]\n",
      "epoch:13 step:10442[D loss: 0.456212, acc: 54.69%, op_acc: 28.12%] [G loss: 0.873151]\n",
      "epoch:13 step:10443[D loss: 0.432061, acc: 56.25%, op_acc: 39.84%] [G loss: 0.859524]\n",
      "epoch:13 step:10444[D loss: 0.417223, acc: 60.94%, op_acc: 41.41%] [G loss: 0.916074]\n",
      "epoch:13 step:10445[D loss: 0.457724, acc: 54.69%, op_acc: 36.72%] [G loss: 0.889140]\n",
      "epoch:13 step:10446[D loss: 0.436872, acc: 56.25%, op_acc: 32.81%] [G loss: 0.888317]\n",
      "epoch:13 step:10447[D loss: 0.426892, acc: 63.28%, op_acc: 34.38%] [G loss: 0.878319]\n",
      "epoch:13 step:10448[D loss: 0.418713, acc: 66.41%, op_acc: 36.72%] [G loss: 0.825927]\n",
      "epoch:13 step:10449[D loss: 0.429300, acc: 57.81%, op_acc: 40.62%] [G loss: 0.972258]\n",
      "epoch:13 step:10450[D loss: 0.457450, acc: 56.25%, op_acc: 31.25%] [G loss: 0.857047]\n",
      "epoch:13 step:10451[D loss: 0.444412, acc: 57.81%, op_acc: 31.25%] [G loss: 0.891758]\n",
      "epoch:13 step:10452[D loss: 0.457926, acc: 56.25%, op_acc: 31.25%] [G loss: 0.928694]\n",
      "epoch:13 step:10453[D loss: 0.434020, acc: 61.72%, op_acc: 34.38%] [G loss: 0.858881]\n",
      "epoch:13 step:10454[D loss: 0.408331, acc: 64.06%, op_acc: 35.94%] [G loss: 0.878332]\n",
      "epoch:13 step:10455[D loss: 0.421044, acc: 60.94%, op_acc: 41.41%] [G loss: 0.874314]\n",
      "epoch:13 step:10456[D loss: 0.437517, acc: 58.59%, op_acc: 37.50%] [G loss: 0.779065]\n",
      "epoch:13 step:10457[D loss: 0.423080, acc: 58.59%, op_acc: 39.84%] [G loss: 0.823909]\n",
      "epoch:13 step:10458[D loss: 0.459529, acc: 56.25%, op_acc: 32.81%] [G loss: 0.854633]\n",
      "epoch:13 step:10459[D loss: 0.456142, acc: 62.50%, op_acc: 32.03%] [G loss: 0.913671]\n",
      "epoch:13 step:10460[D loss: 0.441390, acc: 60.94%, op_acc: 35.16%] [G loss: 0.736648]\n",
      "epoch:13 step:10461[D loss: 0.431312, acc: 60.16%, op_acc: 35.16%] [G loss: 0.945468]\n",
      "epoch:13 step:10462[D loss: 0.439871, acc: 61.72%, op_acc: 30.47%] [G loss: 0.886480]\n",
      "epoch:13 step:10463[D loss: 0.434024, acc: 56.25%, op_acc: 35.16%] [G loss: 0.890352]\n",
      "epoch:13 step:10464[D loss: 0.443160, acc: 55.47%, op_acc: 33.59%] [G loss: 0.924060]\n",
      "epoch:13 step:10465[D loss: 0.441828, acc: 60.16%, op_acc: 40.62%] [G loss: 0.829346]\n",
      "epoch:13 step:10466[D loss: 0.443774, acc: 58.59%, op_acc: 39.84%] [G loss: 0.861013]\n",
      "epoch:13 step:10467[D loss: 0.453486, acc: 55.47%, op_acc: 31.25%] [G loss: 0.889475]\n",
      "epoch:13 step:10468[D loss: 0.437620, acc: 65.62%, op_acc: 32.81%] [G loss: 0.884199]\n",
      "epoch:13 step:10469[D loss: 0.449837, acc: 60.16%, op_acc: 30.47%] [G loss: 0.893746]\n",
      "epoch:13 step:10470[D loss: 0.432185, acc: 57.81%, op_acc: 34.38%] [G loss: 0.914212]\n",
      "epoch:13 step:10471[D loss: 0.455224, acc: 59.38%, op_acc: 30.47%] [G loss: 0.853312]\n",
      "epoch:13 step:10472[D loss: 0.411591, acc: 61.72%, op_acc: 42.97%] [G loss: 0.861042]\n",
      "epoch:13 step:10473[D loss: 0.435312, acc: 61.72%, op_acc: 38.28%] [G loss: 0.879309]\n",
      "epoch:13 step:10474[D loss: 0.467108, acc: 58.59%, op_acc: 34.38%] [G loss: 0.847470]\n",
      "epoch:13 step:10475[D loss: 0.417709, acc: 59.38%, op_acc: 38.28%] [G loss: 0.868096]\n",
      "epoch:13 step:10476[D loss: 0.428807, acc: 57.03%, op_acc: 41.41%] [G loss: 0.809381]\n",
      "epoch:13 step:10477[D loss: 0.453297, acc: 61.72%, op_acc: 31.25%] [G loss: 0.823989]\n",
      "epoch:13 step:10478[D loss: 0.429092, acc: 62.50%, op_acc: 39.84%] [G loss: 0.850213]\n",
      "epoch:13 step:10479[D loss: 0.402897, acc: 66.41%, op_acc: 36.72%] [G loss: 0.867613]\n",
      "epoch:13 step:10480[D loss: 0.431801, acc: 59.38%, op_acc: 36.72%] [G loss: 0.871176]\n",
      "epoch:13 step:10481[D loss: 0.440107, acc: 60.16%, op_acc: 35.16%] [G loss: 0.873719]\n",
      "epoch:13 step:10482[D loss: 0.435419, acc: 50.00%, op_acc: 36.72%] [G loss: 0.818287]\n",
      "epoch:13 step:10483[D loss: 0.399828, acc: 61.72%, op_acc: 39.84%] [G loss: 0.951773]\n",
      "epoch:13 step:10484[D loss: 0.445642, acc: 57.81%, op_acc: 39.06%] [G loss: 0.822780]\n",
      "epoch:13 step:10485[D loss: 0.426800, acc: 61.72%, op_acc: 36.72%] [G loss: 0.877136]\n",
      "epoch:13 step:10486[D loss: 0.423220, acc: 64.06%, op_acc: 33.59%] [G loss: 0.939454]\n",
      "epoch:13 step:10487[D loss: 0.432083, acc: 57.81%, op_acc: 42.19%] [G loss: 0.914585]\n",
      "epoch:13 step:10488[D loss: 0.466144, acc: 63.28%, op_acc: 32.03%] [G loss: 0.865113]\n",
      "epoch:13 step:10489[D loss: 0.452204, acc: 60.94%, op_acc: 32.81%] [G loss: 0.902997]\n",
      "epoch:13 step:10490[D loss: 0.443616, acc: 53.91%, op_acc: 33.59%] [G loss: 0.898085]\n",
      "epoch:13 step:10491[D loss: 0.428488, acc: 53.12%, op_acc: 39.84%] [G loss: 0.947852]\n",
      "epoch:13 step:10492[D loss: 0.432251, acc: 64.06%, op_acc: 35.94%] [G loss: 0.883590]\n",
      "epoch:13 step:10493[D loss: 0.439989, acc: 57.81%, op_acc: 32.81%] [G loss: 0.895582]\n",
      "epoch:13 step:10494[D loss: 0.421582, acc: 65.62%, op_acc: 36.72%] [G loss: 0.900495]\n",
      "epoch:13 step:10495[D loss: 0.437474, acc: 60.16%, op_acc: 37.50%] [G loss: 0.905825]\n",
      "epoch:13 step:10496[D loss: 0.447583, acc: 53.91%, op_acc: 38.28%] [G loss: 0.876399]\n",
      "epoch:13 step:10497[D loss: 0.454291, acc: 50.00%, op_acc: 39.84%] [G loss: 0.824758]\n",
      "epoch:13 step:10498[D loss: 0.443603, acc: 56.25%, op_acc: 36.72%] [G loss: 0.820297]\n",
      "epoch:13 step:10499[D loss: 0.434088, acc: 60.94%, op_acc: 32.81%] [G loss: 0.871581]\n",
      "epoch:13 step:10500[D loss: 0.431289, acc: 58.59%, op_acc: 39.06%] [G loss: 0.908141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10501[D loss: 0.440824, acc: 64.06%, op_acc: 29.69%] [G loss: 0.911848]\n",
      "epoch:13 step:10502[D loss: 0.429269, acc: 62.50%, op_acc: 37.50%] [G loss: 0.889489]\n",
      "epoch:13 step:10503[D loss: 0.455573, acc: 57.03%, op_acc: 35.16%] [G loss: 0.835538]\n",
      "epoch:13 step:10504[D loss: 0.429682, acc: 61.72%, op_acc: 33.59%] [G loss: 0.892429]\n",
      "epoch:13 step:10505[D loss: 0.439686, acc: 58.59%, op_acc: 33.59%] [G loss: 0.924624]\n",
      "epoch:13 step:10506[D loss: 0.408340, acc: 64.84%, op_acc: 42.19%] [G loss: 0.857466]\n",
      "epoch:13 step:10507[D loss: 0.442831, acc: 57.03%, op_acc: 35.16%] [G loss: 0.811168]\n",
      "epoch:13 step:10508[D loss: 0.472020, acc: 52.34%, op_acc: 32.03%] [G loss: 0.840868]\n",
      "epoch:13 step:10509[D loss: 0.433281, acc: 56.25%, op_acc: 35.16%] [G loss: 0.881806]\n",
      "epoch:13 step:10510[D loss: 0.444019, acc: 64.06%, op_acc: 32.03%] [G loss: 0.866613]\n",
      "epoch:13 step:10511[D loss: 0.483089, acc: 49.22%, op_acc: 34.38%] [G loss: 0.799608]\n",
      "epoch:13 step:10512[D loss: 0.428881, acc: 60.94%, op_acc: 37.50%] [G loss: 0.894557]\n",
      "epoch:13 step:10513[D loss: 0.445420, acc: 55.47%, op_acc: 41.41%] [G loss: 0.959453]\n",
      "epoch:13 step:10514[D loss: 0.437721, acc: 54.69%, op_acc: 37.50%] [G loss: 0.960900]\n",
      "epoch:13 step:10515[D loss: 0.398902, acc: 64.06%, op_acc: 39.06%] [G loss: 0.905549]\n",
      "epoch:13 step:10516[D loss: 0.416988, acc: 65.62%, op_acc: 37.50%] [G loss: 0.946834]\n",
      "epoch:13 step:10517[D loss: 0.430832, acc: 53.12%, op_acc: 38.28%] [G loss: 0.928659]\n",
      "epoch:13 step:10518[D loss: 0.399456, acc: 62.50%, op_acc: 42.19%] [G loss: 0.850176]\n",
      "epoch:13 step:10519[D loss: 0.449430, acc: 51.56%, op_acc: 38.28%] [G loss: 0.871755]\n",
      "epoch:13 step:10520[D loss: 0.477828, acc: 57.03%, op_acc: 28.91%] [G loss: 0.950054]\n",
      "epoch:13 step:10521[D loss: 0.432637, acc: 61.72%, op_acc: 34.38%] [G loss: 0.975080]\n",
      "epoch:13 step:10522[D loss: 0.426070, acc: 61.72%, op_acc: 35.16%] [G loss: 0.963647]\n",
      "epoch:13 step:10523[D loss: 0.421785, acc: 58.59%, op_acc: 40.62%] [G loss: 0.846579]\n",
      "epoch:13 step:10524[D loss: 0.428150, acc: 58.59%, op_acc: 38.28%] [G loss: 0.928140]\n",
      "epoch:13 step:10525[D loss: 0.450073, acc: 57.81%, op_acc: 34.38%] [G loss: 0.924626]\n",
      "epoch:13 step:10526[D loss: 0.439751, acc: 56.25%, op_acc: 38.28%] [G loss: 0.879307]\n",
      "epoch:13 step:10527[D loss: 0.404337, acc: 65.62%, op_acc: 40.62%] [G loss: 0.926678]\n",
      "epoch:13 step:10528[D loss: 0.397184, acc: 60.16%, op_acc: 42.19%] [G loss: 0.917236]\n",
      "epoch:13 step:10529[D loss: 0.423630, acc: 62.50%, op_acc: 35.94%] [G loss: 0.832913]\n",
      "epoch:13 step:10530[D loss: 0.417234, acc: 61.72%, op_acc: 38.28%] [G loss: 0.888760]\n",
      "epoch:13 step:10531[D loss: 0.424290, acc: 64.06%, op_acc: 35.16%] [G loss: 0.905464]\n",
      "epoch:13 step:10532[D loss: 0.412126, acc: 64.84%, op_acc: 37.50%] [G loss: 0.941232]\n",
      "epoch:13 step:10533[D loss: 0.440419, acc: 58.59%, op_acc: 32.81%] [G loss: 0.857039]\n",
      "epoch:13 step:10534[D loss: 0.396886, acc: 69.53%, op_acc: 39.06%] [G loss: 0.932624]\n",
      "epoch:13 step:10535[D loss: 0.435507, acc: 57.81%, op_acc: 38.28%] [G loss: 0.940388]\n",
      "epoch:13 step:10536[D loss: 0.418441, acc: 60.16%, op_acc: 40.62%] [G loss: 0.912518]\n",
      "epoch:13 step:10537[D loss: 0.421050, acc: 57.03%, op_acc: 37.50%] [G loss: 0.944889]\n",
      "epoch:13 step:10538[D loss: 0.453273, acc: 52.34%, op_acc: 40.62%] [G loss: 0.822241]\n",
      "epoch:13 step:10539[D loss: 0.436299, acc: 58.59%, op_acc: 37.50%] [G loss: 0.922923]\n",
      "epoch:13 step:10540[D loss: 0.438645, acc: 60.94%, op_acc: 33.59%] [G loss: 0.977713]\n",
      "epoch:13 step:10541[D loss: 0.408415, acc: 67.19%, op_acc: 35.94%] [G loss: 0.940257]\n",
      "epoch:13 step:10542[D loss: 0.421452, acc: 57.81%, op_acc: 33.59%] [G loss: 0.992584]\n",
      "epoch:13 step:10543[D loss: 0.458741, acc: 57.03%, op_acc: 32.81%] [G loss: 0.930838]\n",
      "epoch:13 step:10544[D loss: 0.435311, acc: 54.69%, op_acc: 41.41%] [G loss: 0.923953]\n",
      "epoch:13 step:10545[D loss: 0.445895, acc: 50.78%, op_acc: 39.06%] [G loss: 0.909167]\n",
      "epoch:13 step:10546[D loss: 0.438444, acc: 57.03%, op_acc: 37.50%] [G loss: 0.875923]\n",
      "epoch:13 step:10547[D loss: 0.464577, acc: 47.66%, op_acc: 40.62%] [G loss: 0.906740]\n",
      "epoch:13 step:10548[D loss: 0.465419, acc: 59.38%, op_acc: 33.59%] [G loss: 0.908643]\n",
      "epoch:13 step:10549[D loss: 0.458808, acc: 54.69%, op_acc: 39.84%] [G loss: 0.924154]\n",
      "epoch:13 step:10550[D loss: 0.424621, acc: 57.03%, op_acc: 39.06%] [G loss: 0.914748]\n",
      "epoch:13 step:10551[D loss: 0.445306, acc: 63.28%, op_acc: 39.84%] [G loss: 0.821219]\n",
      "epoch:13 step:10552[D loss: 0.433566, acc: 56.25%, op_acc: 39.06%] [G loss: 0.950532]\n",
      "epoch:13 step:10553[D loss: 0.429821, acc: 59.38%, op_acc: 35.16%] [G loss: 0.874194]\n",
      "epoch:13 step:10554[D loss: 0.445916, acc: 52.34%, op_acc: 38.28%] [G loss: 0.787543]\n",
      "epoch:13 step:10555[D loss: 0.438769, acc: 64.84%, op_acc: 33.59%] [G loss: 0.911412]\n",
      "epoch:13 step:10556[D loss: 0.396374, acc: 67.97%, op_acc: 35.94%] [G loss: 0.958576]\n",
      "epoch:13 step:10557[D loss: 0.405473, acc: 57.03%, op_acc: 39.06%] [G loss: 0.908406]\n",
      "epoch:13 step:10558[D loss: 0.451236, acc: 60.16%, op_acc: 36.72%] [G loss: 1.007195]\n",
      "epoch:13 step:10559[D loss: 0.425003, acc: 64.84%, op_acc: 38.28%] [G loss: 0.902599]\n",
      "epoch:13 step:10560[D loss: 0.426620, acc: 56.25%, op_acc: 39.06%] [G loss: 0.973886]\n",
      "epoch:13 step:10561[D loss: 0.443045, acc: 53.12%, op_acc: 36.72%] [G loss: 0.855195]\n",
      "epoch:13 step:10562[D loss: 0.445512, acc: 55.47%, op_acc: 39.06%] [G loss: 0.911238]\n",
      "epoch:13 step:10563[D loss: 0.412665, acc: 60.94%, op_acc: 45.31%] [G loss: 0.868459]\n",
      "epoch:13 step:10564[D loss: 0.431822, acc: 61.72%, op_acc: 35.16%] [G loss: 0.915957]\n",
      "epoch:13 step:10565[D loss: 0.410837, acc: 54.69%, op_acc: 39.84%] [G loss: 0.774936]\n",
      "epoch:13 step:10566[D loss: 0.421018, acc: 60.94%, op_acc: 38.28%] [G loss: 0.872506]\n",
      "epoch:13 step:10567[D loss: 0.399351, acc: 66.41%, op_acc: 41.41%] [G loss: 0.928498]\n",
      "epoch:13 step:10568[D loss: 0.427264, acc: 60.94%, op_acc: 36.72%] [G loss: 0.815527]\n",
      "epoch:13 step:10569[D loss: 0.458837, acc: 58.59%, op_acc: 38.28%] [G loss: 0.858010]\n",
      "epoch:13 step:10570[D loss: 0.457985, acc: 57.81%, op_acc: 39.06%] [G loss: 0.870168]\n",
      "epoch:13 step:10571[D loss: 0.456544, acc: 54.69%, op_acc: 34.38%] [G loss: 0.885073]\n",
      "epoch:13 step:10572[D loss: 0.426438, acc: 58.59%, op_acc: 30.47%] [G loss: 0.934472]\n",
      "epoch:13 step:10573[D loss: 0.455253, acc: 50.78%, op_acc: 37.50%] [G loss: 0.947084]\n",
      "epoch:13 step:10574[D loss: 0.458609, acc: 56.25%, op_acc: 34.38%] [G loss: 0.837312]\n",
      "epoch:13 step:10575[D loss: 0.418407, acc: 62.50%, op_acc: 35.94%] [G loss: 0.945203]\n",
      "epoch:13 step:10576[D loss: 0.460479, acc: 58.59%, op_acc: 35.94%] [G loss: 0.841887]\n",
      "epoch:13 step:10577[D loss: 0.428356, acc: 65.62%, op_acc: 29.69%] [G loss: 0.852983]\n",
      "epoch:13 step:10578[D loss: 0.434892, acc: 60.16%, op_acc: 37.50%] [G loss: 0.764182]\n",
      "epoch:13 step:10579[D loss: 0.448607, acc: 61.72%, op_acc: 35.16%] [G loss: 0.848062]\n",
      "epoch:13 step:10580[D loss: 0.417570, acc: 68.75%, op_acc: 33.59%] [G loss: 0.891371]\n",
      "epoch:13 step:10581[D loss: 0.438834, acc: 57.03%, op_acc: 43.75%] [G loss: 0.902695]\n",
      "epoch:13 step:10582[D loss: 0.434747, acc: 60.94%, op_acc: 39.84%] [G loss: 0.867864]\n",
      "epoch:13 step:10583[D loss: 0.434873, acc: 59.38%, op_acc: 37.50%] [G loss: 0.828810]\n",
      "epoch:13 step:10584[D loss: 0.439722, acc: 57.03%, op_acc: 37.50%] [G loss: 0.874445]\n",
      "epoch:13 step:10585[D loss: 0.401885, acc: 62.50%, op_acc: 40.62%] [G loss: 0.899281]\n",
      "epoch:13 step:10586[D loss: 0.410306, acc: 64.84%, op_acc: 34.38%] [G loss: 0.867889]\n",
      "epoch:13 step:10587[D loss: 0.431762, acc: 53.91%, op_acc: 41.41%] [G loss: 0.846927]\n",
      "epoch:13 step:10588[D loss: 0.439994, acc: 51.56%, op_acc: 39.06%] [G loss: 0.870869]\n",
      "epoch:13 step:10589[D loss: 0.479629, acc: 48.44%, op_acc: 31.25%] [G loss: 0.858986]\n",
      "epoch:13 step:10590[D loss: 0.435057, acc: 60.94%, op_acc: 40.62%] [G loss: 0.881469]\n",
      "epoch:13 step:10591[D loss: 0.426307, acc: 64.84%, op_acc: 35.16%] [G loss: 0.883872]\n",
      "epoch:13 step:10592[D loss: 0.433408, acc: 60.16%, op_acc: 36.72%] [G loss: 0.897959]\n",
      "epoch:13 step:10593[D loss: 0.425392, acc: 64.84%, op_acc: 38.28%] [G loss: 0.917024]\n",
      "epoch:13 step:10594[D loss: 0.436074, acc: 57.03%, op_acc: 35.16%] [G loss: 0.878388]\n",
      "epoch:13 step:10595[D loss: 0.418950, acc: 60.94%, op_acc: 40.62%] [G loss: 0.814838]\n",
      "epoch:13 step:10596[D loss: 0.430752, acc: 59.38%, op_acc: 34.38%] [G loss: 0.912693]\n",
      "epoch:13 step:10597[D loss: 0.418175, acc: 60.94%, op_acc: 35.16%] [G loss: 0.913635]\n",
      "epoch:13 step:10598[D loss: 0.427229, acc: 61.72%, op_acc: 35.16%] [G loss: 0.934041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10599[D loss: 0.436741, acc: 56.25%, op_acc: 33.59%] [G loss: 0.924301]\n",
      "epoch:13 step:10600[D loss: 0.469188, acc: 56.25%, op_acc: 31.25%] [G loss: 0.928821]\n",
      "epoch:13 step:10601[D loss: 0.402347, acc: 71.88%, op_acc: 34.38%] [G loss: 0.855394]\n",
      "epoch:13 step:10602[D loss: 0.405226, acc: 67.19%, op_acc: 37.50%] [G loss: 0.876665]\n",
      "epoch:13 step:10603[D loss: 0.432402, acc: 56.25%, op_acc: 35.16%] [G loss: 0.921661]\n",
      "epoch:13 step:10604[D loss: 0.452601, acc: 52.34%, op_acc: 41.41%] [G loss: 0.884615]\n",
      "epoch:13 step:10605[D loss: 0.417576, acc: 57.81%, op_acc: 39.84%] [G loss: 0.861236]\n",
      "epoch:13 step:10606[D loss: 0.400781, acc: 58.59%, op_acc: 39.84%] [G loss: 0.907164]\n",
      "epoch:13 step:10607[D loss: 0.420506, acc: 57.81%, op_acc: 38.28%] [G loss: 0.947925]\n",
      "epoch:13 step:10608[D loss: 0.466914, acc: 57.03%, op_acc: 36.72%] [G loss: 0.922799]\n",
      "epoch:13 step:10609[D loss: 0.447921, acc: 58.59%, op_acc: 37.50%] [G loss: 0.943869]\n",
      "epoch:13 step:10610[D loss: 0.431483, acc: 67.19%, op_acc: 36.72%] [G loss: 0.890740]\n",
      "epoch:13 step:10611[D loss: 0.418006, acc: 62.50%, op_acc: 41.41%] [G loss: 0.969900]\n",
      "epoch:13 step:10612[D loss: 0.419194, acc: 62.50%, op_acc: 36.72%] [G loss: 0.885142]\n",
      "epoch:13 step:10613[D loss: 0.451930, acc: 52.34%, op_acc: 35.94%] [G loss: 0.870577]\n",
      "epoch:13 step:10614[D loss: 0.458898, acc: 56.25%, op_acc: 34.38%] [G loss: 0.893829]\n",
      "epoch:13 step:10615[D loss: 0.444266, acc: 60.16%, op_acc: 32.03%] [G loss: 0.875659]\n",
      "epoch:13 step:10616[D loss: 0.444247, acc: 58.59%, op_acc: 39.84%] [G loss: 0.796374]\n",
      "epoch:13 step:10617[D loss: 0.457979, acc: 60.16%, op_acc: 32.03%] [G loss: 0.827586]\n",
      "epoch:13 step:10618[D loss: 0.464275, acc: 51.56%, op_acc: 30.47%] [G loss: 0.828255]\n",
      "epoch:13 step:10619[D loss: 0.411900, acc: 61.72%, op_acc: 36.72%] [G loss: 0.926084]\n",
      "epoch:13 step:10620[D loss: 0.416131, acc: 63.28%, op_acc: 30.47%] [G loss: 0.909325]\n",
      "epoch:13 step:10621[D loss: 0.437958, acc: 53.12%, op_acc: 37.50%] [G loss: 0.916945]\n",
      "epoch:13 step:10622[D loss: 0.400051, acc: 64.06%, op_acc: 36.72%] [G loss: 0.953361]\n",
      "epoch:13 step:10623[D loss: 0.431392, acc: 56.25%, op_acc: 37.50%] [G loss: 0.816981]\n",
      "epoch:13 step:10624[D loss: 0.438832, acc: 57.81%, op_acc: 33.59%] [G loss: 0.891360]\n",
      "epoch:13 step:10625[D loss: 0.454198, acc: 60.16%, op_acc: 31.25%] [G loss: 0.900210]\n",
      "epoch:13 step:10626[D loss: 0.396929, acc: 65.62%, op_acc: 41.41%] [G loss: 0.921067]\n",
      "epoch:13 step:10627[D loss: 0.418680, acc: 64.06%, op_acc: 36.72%] [G loss: 0.861266]\n",
      "epoch:13 step:10628[D loss: 0.448053, acc: 46.88%, op_acc: 37.50%] [G loss: 0.839204]\n",
      "epoch:13 step:10629[D loss: 0.421583, acc: 64.84%, op_acc: 35.16%] [G loss: 0.914127]\n",
      "epoch:13 step:10630[D loss: 0.437515, acc: 56.25%, op_acc: 39.84%] [G loss: 0.966727]\n",
      "epoch:13 step:10631[D loss: 0.433024, acc: 57.03%, op_acc: 32.03%] [G loss: 0.896517]\n",
      "epoch:13 step:10632[D loss: 0.446252, acc: 57.81%, op_acc: 34.38%] [G loss: 0.911342]\n",
      "epoch:13 step:10633[D loss: 0.443965, acc: 64.84%, op_acc: 35.16%] [G loss: 0.926194]\n",
      "epoch:13 step:10634[D loss: 0.457664, acc: 59.38%, op_acc: 32.03%] [G loss: 0.926701]\n",
      "epoch:13 step:10635[D loss: 0.421736, acc: 67.97%, op_acc: 38.28%] [G loss: 0.961287]\n",
      "epoch:13 step:10636[D loss: 0.445443, acc: 56.25%, op_acc: 40.62%] [G loss: 0.933257]\n",
      "epoch:13 step:10637[D loss: 0.422727, acc: 58.59%, op_acc: 42.19%] [G loss: 0.937379]\n",
      "epoch:13 step:10638[D loss: 0.414652, acc: 72.66%, op_acc: 32.03%] [G loss: 0.832645]\n",
      "epoch:13 step:10639[D loss: 0.420697, acc: 61.72%, op_acc: 39.84%] [G loss: 0.863461]\n",
      "epoch:13 step:10640[D loss: 0.451317, acc: 57.81%, op_acc: 35.16%] [G loss: 0.981767]\n",
      "epoch:13 step:10641[D loss: 0.431411, acc: 64.06%, op_acc: 44.53%] [G loss: 0.944080]\n",
      "epoch:13 step:10642[D loss: 0.441247, acc: 62.50%, op_acc: 39.84%] [G loss: 0.954519]\n",
      "epoch:13 step:10643[D loss: 0.420725, acc: 62.50%, op_acc: 39.84%] [G loss: 0.854131]\n",
      "epoch:13 step:10644[D loss: 0.444098, acc: 63.28%, op_acc: 36.72%] [G loss: 0.962335]\n",
      "epoch:13 step:10645[D loss: 0.437417, acc: 60.94%, op_acc: 39.84%] [G loss: 0.921532]\n",
      "epoch:13 step:10646[D loss: 0.427327, acc: 64.84%, op_acc: 32.81%] [G loss: 0.843523]\n",
      "epoch:13 step:10647[D loss: 0.398238, acc: 63.28%, op_acc: 39.06%] [G loss: 0.846565]\n",
      "epoch:13 step:10648[D loss: 0.438428, acc: 64.84%, op_acc: 33.59%] [G loss: 0.949026]\n",
      "epoch:13 step:10649[D loss: 0.424316, acc: 64.84%, op_acc: 32.81%] [G loss: 0.735139]\n",
      "epoch:13 step:10650[D loss: 0.409114, acc: 60.94%, op_acc: 40.62%] [G loss: 0.903494]\n",
      "epoch:13 step:10651[D loss: 0.470008, acc: 52.34%, op_acc: 29.69%] [G loss: 0.881754]\n",
      "epoch:13 step:10652[D loss: 0.434441, acc: 59.38%, op_acc: 36.72%] [G loss: 0.898418]\n",
      "epoch:13 step:10653[D loss: 0.390931, acc: 66.41%, op_acc: 37.50%] [G loss: 0.940054]\n",
      "epoch:13 step:10654[D loss: 0.454820, acc: 62.50%, op_acc: 31.25%] [G loss: 0.913136]\n",
      "epoch:13 step:10655[D loss: 0.457786, acc: 51.56%, op_acc: 33.59%] [G loss: 0.839474]\n",
      "epoch:13 step:10656[D loss: 0.424525, acc: 66.41%, op_acc: 35.16%] [G loss: 0.981019]\n",
      "epoch:13 step:10657[D loss: 0.435002, acc: 55.47%, op_acc: 37.50%] [G loss: 0.888460]\n",
      "epoch:13 step:10658[D loss: 0.458930, acc: 53.91%, op_acc: 36.72%] [G loss: 1.028193]\n",
      "epoch:13 step:10659[D loss: 0.464991, acc: 56.25%, op_acc: 32.03%] [G loss: 0.937330]\n",
      "epoch:13 step:10660[D loss: 0.417850, acc: 64.84%, op_acc: 37.50%] [G loss: 0.964418]\n",
      "epoch:13 step:10661[D loss: 0.424629, acc: 61.72%, op_acc: 37.50%] [G loss: 0.861567]\n",
      "epoch:13 step:10662[D loss: 0.454616, acc: 50.00%, op_acc: 39.84%] [G loss: 0.883959]\n",
      "epoch:13 step:10663[D loss: 0.423625, acc: 64.84%, op_acc: 34.38%] [G loss: 0.832934]\n",
      "epoch:13 step:10664[D loss: 0.452461, acc: 53.91%, op_acc: 35.16%] [G loss: 0.885201]\n",
      "epoch:13 step:10665[D loss: 0.495284, acc: 46.88%, op_acc: 28.91%] [G loss: 0.858877]\n",
      "epoch:13 step:10666[D loss: 0.428896, acc: 61.72%, op_acc: 35.94%] [G loss: 0.936514]\n",
      "epoch:13 step:10667[D loss: 0.451363, acc: 53.12%, op_acc: 38.28%] [G loss: 0.814696]\n",
      "epoch:13 step:10668[D loss: 0.444303, acc: 60.16%, op_acc: 34.38%] [G loss: 0.884049]\n",
      "epoch:13 step:10669[D loss: 0.428438, acc: 62.50%, op_acc: 37.50%] [G loss: 0.924784]\n",
      "epoch:13 step:10670[D loss: 0.476690, acc: 53.91%, op_acc: 32.03%] [G loss: 0.912133]\n",
      "epoch:13 step:10671[D loss: 0.436961, acc: 56.25%, op_acc: 37.50%] [G loss: 0.862510]\n",
      "epoch:13 step:10672[D loss: 0.406791, acc: 58.59%, op_acc: 40.62%] [G loss: 0.850237]\n",
      "epoch:13 step:10673[D loss: 0.425615, acc: 63.28%, op_acc: 34.38%] [G loss: 0.892763]\n",
      "epoch:13 step:10674[D loss: 0.432056, acc: 60.94%, op_acc: 36.72%] [G loss: 0.895336]\n",
      "epoch:13 step:10675[D loss: 0.477605, acc: 49.22%, op_acc: 32.03%] [G loss: 0.906355]\n",
      "epoch:13 step:10676[D loss: 0.438808, acc: 55.47%, op_acc: 37.50%] [G loss: 0.870742]\n",
      "epoch:13 step:10677[D loss: 0.440285, acc: 53.91%, op_acc: 38.28%] [G loss: 0.849454]\n",
      "epoch:13 step:10678[D loss: 0.427921, acc: 67.97%, op_acc: 35.16%] [G loss: 0.956540]\n",
      "epoch:13 step:10679[D loss: 0.454095, acc: 60.94%, op_acc: 30.47%] [G loss: 0.915494]\n",
      "epoch:13 step:10680[D loss: 0.425241, acc: 56.25%, op_acc: 37.50%] [G loss: 0.918732]\n",
      "epoch:13 step:10681[D loss: 0.413340, acc: 60.16%, op_acc: 42.97%] [G loss: 0.922641]\n",
      "epoch:13 step:10682[D loss: 0.433340, acc: 60.94%, op_acc: 39.06%] [G loss: 1.007732]\n",
      "epoch:13 step:10683[D loss: 0.429397, acc: 58.59%, op_acc: 35.16%] [G loss: 0.890587]\n",
      "epoch:13 step:10684[D loss: 0.446215, acc: 54.69%, op_acc: 35.16%] [G loss: 0.842272]\n",
      "epoch:13 step:10685[D loss: 0.436031, acc: 57.81%, op_acc: 34.38%] [G loss: 0.877110]\n",
      "epoch:13 step:10686[D loss: 0.426924, acc: 62.50%, op_acc: 39.06%] [G loss: 0.961113]\n",
      "epoch:13 step:10687[D loss: 0.441309, acc: 52.34%, op_acc: 39.06%] [G loss: 0.870291]\n",
      "epoch:13 step:10688[D loss: 0.429452, acc: 59.38%, op_acc: 33.59%] [G loss: 0.818869]\n",
      "epoch:13 step:10689[D loss: 0.415130, acc: 60.94%, op_acc: 46.88%] [G loss: 0.943706]\n",
      "epoch:13 step:10690[D loss: 0.455270, acc: 56.25%, op_acc: 35.94%] [G loss: 0.805787]\n",
      "epoch:13 step:10691[D loss: 0.422811, acc: 61.72%, op_acc: 40.62%] [G loss: 0.877724]\n",
      "epoch:13 step:10692[D loss: 0.452968, acc: 60.94%, op_acc: 36.72%] [G loss: 0.943868]\n",
      "epoch:13 step:10693[D loss: 0.408506, acc: 64.06%, op_acc: 38.28%] [G loss: 0.868250]\n",
      "epoch:13 step:10694[D loss: 0.412392, acc: 61.72%, op_acc: 39.06%] [G loss: 0.893667]\n",
      "epoch:13 step:10695[D loss: 0.444543, acc: 60.94%, op_acc: 37.50%] [G loss: 0.881378]\n",
      "epoch:13 step:10696[D loss: 0.425944, acc: 64.06%, op_acc: 39.84%] [G loss: 0.959063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10697[D loss: 0.432994, acc: 58.59%, op_acc: 36.72%] [G loss: 0.947980]\n",
      "epoch:13 step:10698[D loss: 0.405805, acc: 65.62%, op_acc: 43.75%] [G loss: 0.895413]\n",
      "epoch:13 step:10699[D loss: 0.419378, acc: 60.16%, op_acc: 35.94%] [G loss: 0.981375]\n",
      "epoch:13 step:10700[D loss: 0.462854, acc: 53.12%, op_acc: 36.72%] [G loss: 0.914608]\n",
      "epoch:13 step:10701[D loss: 0.459593, acc: 62.50%, op_acc: 30.47%] [G loss: 0.876788]\n",
      "epoch:13 step:10702[D loss: 0.445713, acc: 56.25%, op_acc: 36.72%] [G loss: 0.850571]\n",
      "epoch:13 step:10703[D loss: 0.417470, acc: 57.81%, op_acc: 34.38%] [G loss: 0.894276]\n",
      "epoch:13 step:10704[D loss: 0.433160, acc: 56.25%, op_acc: 37.50%] [G loss: 0.919705]\n",
      "epoch:13 step:10705[D loss: 0.490623, acc: 49.22%, op_acc: 33.59%] [G loss: 0.886507]\n",
      "epoch:13 step:10706[D loss: 0.406109, acc: 62.50%, op_acc: 39.06%] [G loss: 0.855521]\n",
      "epoch:13 step:10707[D loss: 0.445786, acc: 59.38%, op_acc: 33.59%] [G loss: 0.890226]\n",
      "epoch:13 step:10708[D loss: 0.432989, acc: 62.50%, op_acc: 37.50%] [G loss: 0.818448]\n",
      "epoch:13 step:10709[D loss: 0.417905, acc: 59.38%, op_acc: 38.28%] [G loss: 0.919197]\n",
      "epoch:13 step:10710[D loss: 0.448967, acc: 57.03%, op_acc: 34.38%] [G loss: 0.836774]\n",
      "epoch:13 step:10711[D loss: 0.452035, acc: 53.91%, op_acc: 39.84%] [G loss: 0.948992]\n",
      "epoch:13 step:10712[D loss: 0.414084, acc: 58.59%, op_acc: 37.50%] [G loss: 0.902225]\n",
      "epoch:13 step:10713[D loss: 0.444284, acc: 60.94%, op_acc: 30.47%] [G loss: 0.951568]\n",
      "epoch:13 step:10714[D loss: 0.413363, acc: 63.28%, op_acc: 38.28%] [G loss: 0.934132]\n",
      "epoch:13 step:10715[D loss: 0.415162, acc: 64.84%, op_acc: 38.28%] [G loss: 0.972709]\n",
      "epoch:13 step:10716[D loss: 0.429605, acc: 60.94%, op_acc: 39.84%] [G loss: 0.921463]\n",
      "epoch:13 step:10717[D loss: 0.433000, acc: 53.12%, op_acc: 40.62%] [G loss: 0.935333]\n",
      "epoch:13 step:10718[D loss: 0.419316, acc: 62.50%, op_acc: 37.50%] [G loss: 0.967734]\n",
      "epoch:13 step:10719[D loss: 0.436651, acc: 59.38%, op_acc: 35.94%] [G loss: 0.910698]\n",
      "epoch:13 step:10720[D loss: 0.433161, acc: 57.03%, op_acc: 39.84%] [G loss: 0.856987]\n",
      "epoch:13 step:10721[D loss: 0.437195, acc: 58.59%, op_acc: 37.50%] [G loss: 0.852732]\n",
      "epoch:13 step:10722[D loss: 0.436684, acc: 59.38%, op_acc: 35.94%] [G loss: 0.792319]\n",
      "epoch:13 step:10723[D loss: 0.440998, acc: 60.16%, op_acc: 35.94%] [G loss: 0.879877]\n",
      "epoch:13 step:10724[D loss: 0.425245, acc: 61.72%, op_acc: 44.53%] [G loss: 0.869006]\n",
      "epoch:13 step:10725[D loss: 0.417759, acc: 61.72%, op_acc: 39.84%] [G loss: 0.928294]\n",
      "epoch:13 step:10726[D loss: 0.428697, acc: 60.16%, op_acc: 42.19%] [G loss: 0.956507]\n",
      "epoch:13 step:10727[D loss: 0.440734, acc: 62.50%, op_acc: 31.25%] [G loss: 0.951944]\n",
      "epoch:13 step:10728[D loss: 0.458102, acc: 51.56%, op_acc: 36.72%] [G loss: 0.789937]\n",
      "epoch:13 step:10729[D loss: 0.425412, acc: 61.72%, op_acc: 38.28%] [G loss: 0.812340]\n",
      "epoch:13 step:10730[D loss: 0.447230, acc: 60.94%, op_acc: 35.16%] [G loss: 0.883172]\n",
      "epoch:13 step:10731[D loss: 0.477753, acc: 55.47%, op_acc: 29.69%] [G loss: 0.870359]\n",
      "epoch:13 step:10732[D loss: 0.408615, acc: 62.50%, op_acc: 39.84%] [G loss: 0.826420]\n",
      "epoch:13 step:10733[D loss: 0.443498, acc: 56.25%, op_acc: 34.38%] [G loss: 0.902969]\n",
      "epoch:13 step:10734[D loss: 0.477029, acc: 51.56%, op_acc: 35.94%] [G loss: 0.924928]\n",
      "epoch:13 step:10735[D loss: 0.413828, acc: 70.31%, op_acc: 32.81%] [G loss: 0.918793]\n",
      "epoch:13 step:10736[D loss: 0.419122, acc: 63.28%, op_acc: 36.72%] [G loss: 0.946095]\n",
      "epoch:13 step:10737[D loss: 0.471564, acc: 52.34%, op_acc: 31.25%] [G loss: 0.938629]\n",
      "epoch:13 step:10738[D loss: 0.442511, acc: 57.03%, op_acc: 34.38%] [G loss: 0.792398]\n",
      "epoch:13 step:10739[D loss: 0.442171, acc: 57.03%, op_acc: 35.94%] [G loss: 0.884818]\n",
      "epoch:13 step:10740[D loss: 0.436730, acc: 64.84%, op_acc: 26.56%] [G loss: 0.882998]\n",
      "epoch:13 step:10741[D loss: 0.406177, acc: 60.16%, op_acc: 41.41%] [G loss: 0.880654]\n",
      "epoch:13 step:10742[D loss: 0.440521, acc: 63.28%, op_acc: 30.47%] [G loss: 0.801560]\n",
      "epoch:13 step:10743[D loss: 0.423517, acc: 58.59%, op_acc: 35.16%] [G loss: 0.912914]\n",
      "epoch:13 step:10744[D loss: 0.428066, acc: 60.94%, op_acc: 32.81%] [G loss: 0.934183]\n",
      "epoch:13 step:10745[D loss: 0.449631, acc: 52.34%, op_acc: 34.38%] [G loss: 0.961811]\n",
      "epoch:13 step:10746[D loss: 0.434123, acc: 60.94%, op_acc: 32.03%] [G loss: 0.900573]\n",
      "epoch:13 step:10747[D loss: 0.409823, acc: 67.19%, op_acc: 30.47%] [G loss: 0.859505]\n",
      "epoch:13 step:10748[D loss: 0.416905, acc: 60.94%, op_acc: 40.62%] [G loss: 0.854087]\n",
      "epoch:13 step:10749[D loss: 0.438328, acc: 58.59%, op_acc: 36.72%] [G loss: 0.812707]\n",
      "epoch:13 step:10750[D loss: 0.446095, acc: 53.12%, op_acc: 40.62%] [G loss: 0.915520]\n",
      "epoch:13 step:10751[D loss: 0.437267, acc: 63.28%, op_acc: 36.72%] [G loss: 0.889139]\n",
      "epoch:13 step:10752[D loss: 0.418579, acc: 66.41%, op_acc: 39.06%] [G loss: 1.027615]\n",
      "epoch:13 step:10753[D loss: 0.456307, acc: 66.41%, op_acc: 39.84%] [G loss: 0.931966]\n",
      "epoch:13 step:10754[D loss: 0.427858, acc: 57.81%, op_acc: 32.03%] [G loss: 0.973551]\n",
      "epoch:13 step:10755[D loss: 0.419053, acc: 56.25%, op_acc: 40.62%] [G loss: 0.940827]\n",
      "epoch:13 step:10756[D loss: 0.410408, acc: 65.62%, op_acc: 40.62%] [G loss: 0.962564]\n",
      "epoch:13 step:10757[D loss: 0.426610, acc: 70.31%, op_acc: 28.12%] [G loss: 1.053192]\n",
      "epoch:13 step:10758[D loss: 0.437369, acc: 62.50%, op_acc: 37.50%] [G loss: 0.953309]\n",
      "epoch:13 step:10759[D loss: 0.425998, acc: 63.28%, op_acc: 40.62%] [G loss: 0.893892]\n",
      "epoch:13 step:10760[D loss: 0.419568, acc: 60.16%, op_acc: 41.41%] [G loss: 0.833357]\n",
      "epoch:13 step:10761[D loss: 0.409242, acc: 71.88%, op_acc: 41.41%] [G loss: 0.889022]\n",
      "epoch:13 step:10762[D loss: 0.427539, acc: 56.25%, op_acc: 36.72%] [G loss: 0.898244]\n",
      "epoch:13 step:10763[D loss: 0.410359, acc: 74.22%, op_acc: 34.38%] [G loss: 0.881250]\n",
      "epoch:13 step:10764[D loss: 0.420888, acc: 61.72%, op_acc: 37.50%] [G loss: 0.892381]\n",
      "epoch:13 step:10765[D loss: 0.381258, acc: 70.31%, op_acc: 33.59%] [G loss: 0.920389]\n",
      "epoch:13 step:10766[D loss: 0.444217, acc: 56.25%, op_acc: 32.81%] [G loss: 1.012008]\n",
      "epoch:13 step:10767[D loss: 0.404962, acc: 64.06%, op_acc: 43.75%] [G loss: 0.985142]\n",
      "epoch:13 step:10768[D loss: 0.425707, acc: 60.16%, op_acc: 39.84%] [G loss: 0.906356]\n",
      "epoch:13 step:10769[D loss: 0.459722, acc: 55.47%, op_acc: 32.81%] [G loss: 0.872958]\n",
      "epoch:13 step:10770[D loss: 0.443973, acc: 55.47%, op_acc: 32.81%] [G loss: 0.906925]\n",
      "epoch:13 step:10771[D loss: 0.407841, acc: 63.28%, op_acc: 38.28%] [G loss: 0.997332]\n",
      "epoch:13 step:10772[D loss: 0.464150, acc: 61.72%, op_acc: 35.94%] [G loss: 0.907688]\n",
      "epoch:13 step:10773[D loss: 0.439999, acc: 60.16%, op_acc: 32.03%] [G loss: 0.973191]\n",
      "epoch:13 step:10774[D loss: 0.419505, acc: 61.72%, op_acc: 39.84%] [G loss: 0.892662]\n",
      "epoch:13 step:10775[D loss: 0.471432, acc: 60.16%, op_acc: 28.12%] [G loss: 0.870563]\n",
      "epoch:13 step:10776[D loss: 0.463842, acc: 55.47%, op_acc: 35.94%] [G loss: 0.897138]\n",
      "epoch:13 step:10777[D loss: 0.431497, acc: 61.72%, op_acc: 34.38%] [G loss: 0.839656]\n",
      "epoch:13 step:10778[D loss: 0.468324, acc: 53.91%, op_acc: 39.84%] [G loss: 0.798677]\n",
      "epoch:13 step:10779[D loss: 0.444186, acc: 50.00%, op_acc: 39.84%] [G loss: 0.890330]\n",
      "epoch:13 step:10780[D loss: 0.449768, acc: 60.16%, op_acc: 33.59%] [G loss: 0.822655]\n",
      "epoch:13 step:10781[D loss: 0.444359, acc: 58.59%, op_acc: 34.38%] [G loss: 0.832388]\n",
      "epoch:13 step:10782[D loss: 0.472149, acc: 53.12%, op_acc: 29.69%] [G loss: 0.879084]\n",
      "epoch:13 step:10783[D loss: 0.426373, acc: 54.69%, op_acc: 39.84%] [G loss: 0.846754]\n",
      "epoch:13 step:10784[D loss: 0.462808, acc: 50.00%, op_acc: 37.50%] [G loss: 0.857233]\n",
      "epoch:13 step:10785[D loss: 0.427816, acc: 63.28%, op_acc: 32.03%] [G loss: 0.997319]\n",
      "epoch:13 step:10786[D loss: 0.424070, acc: 63.28%, op_acc: 39.06%] [G loss: 0.851789]\n",
      "epoch:13 step:10787[D loss: 0.428834, acc: 55.47%, op_acc: 42.97%] [G loss: 0.860590]\n",
      "epoch:13 step:10788[D loss: 0.451066, acc: 53.12%, op_acc: 36.72%] [G loss: 0.871298]\n",
      "epoch:13 step:10789[D loss: 0.405417, acc: 67.19%, op_acc: 35.16%] [G loss: 0.920515]\n",
      "epoch:13 step:10790[D loss: 0.421005, acc: 61.72%, op_acc: 35.16%] [G loss: 0.944598]\n",
      "epoch:13 step:10791[D loss: 0.443086, acc: 60.16%, op_acc: 39.84%] [G loss: 0.870482]\n",
      "epoch:13 step:10792[D loss: 0.450375, acc: 57.81%, op_acc: 38.28%] [G loss: 0.865902]\n",
      "epoch:13 step:10793[D loss: 0.427696, acc: 67.19%, op_acc: 35.16%] [G loss: 0.946971]\n",
      "epoch:13 step:10794[D loss: 0.429599, acc: 64.06%, op_acc: 34.38%] [G loss: 0.826300]\n",
      "epoch:13 step:10795[D loss: 0.440061, acc: 60.16%, op_acc: 32.81%] [G loss: 0.933696]\n",
      "epoch:13 step:10796[D loss: 0.463491, acc: 57.03%, op_acc: 32.81%] [G loss: 0.901001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10797[D loss: 0.412266, acc: 67.97%, op_acc: 39.84%] [G loss: 0.970876]\n",
      "epoch:13 step:10798[D loss: 0.417571, acc: 58.59%, op_acc: 40.62%] [G loss: 0.910225]\n",
      "epoch:13 step:10799[D loss: 0.449566, acc: 61.72%, op_acc: 37.50%] [G loss: 0.906876]\n",
      "epoch:13 step:10800[D loss: 0.432765, acc: 48.44%, op_acc: 39.84%] [G loss: 0.962067]\n",
      "epoch:13 step:10801[D loss: 0.408671, acc: 67.97%, op_acc: 36.72%] [G loss: 0.853054]\n",
      "epoch:13 step:10802[D loss: 0.425994, acc: 55.47%, op_acc: 40.62%] [G loss: 0.929800]\n",
      "epoch:13 step:10803[D loss: 0.431674, acc: 63.28%, op_acc: 32.03%] [G loss: 0.904070]\n",
      "epoch:13 step:10804[D loss: 0.454913, acc: 55.47%, op_acc: 34.38%] [G loss: 0.903461]\n",
      "epoch:13 step:10805[D loss: 0.410284, acc: 66.41%, op_acc: 39.06%] [G loss: 0.885696]\n",
      "epoch:13 step:10806[D loss: 0.398960, acc: 72.66%, op_acc: 39.84%] [G loss: 0.879694]\n",
      "epoch:13 step:10807[D loss: 0.431308, acc: 57.81%, op_acc: 38.28%] [G loss: 0.911045]\n",
      "epoch:13 step:10808[D loss: 0.433743, acc: 58.59%, op_acc: 38.28%] [G loss: 0.853106]\n",
      "epoch:13 step:10809[D loss: 0.440720, acc: 56.25%, op_acc: 40.62%] [G loss: 0.829725]\n",
      "epoch:13 step:10810[D loss: 0.464980, acc: 54.69%, op_acc: 37.50%] [G loss: 0.865071]\n",
      "epoch:13 step:10811[D loss: 0.425428, acc: 57.03%, op_acc: 37.50%] [G loss: 0.919071]\n",
      "epoch:13 step:10812[D loss: 0.414540, acc: 63.28%, op_acc: 39.06%] [G loss: 0.946679]\n",
      "epoch:13 step:10813[D loss: 0.411504, acc: 66.41%, op_acc: 33.59%] [G loss: 0.845486]\n",
      "epoch:13 step:10814[D loss: 0.399788, acc: 64.06%, op_acc: 41.41%] [G loss: 0.871355]\n",
      "epoch:13 step:10815[D loss: 0.417214, acc: 61.72%, op_acc: 40.62%] [G loss: 0.935665]\n",
      "epoch:13 step:10816[D loss: 0.422195, acc: 61.72%, op_acc: 35.16%] [G loss: 0.857362]\n",
      "epoch:13 step:10817[D loss: 0.459079, acc: 57.81%, op_acc: 32.03%] [G loss: 0.897231]\n",
      "epoch:13 step:10818[D loss: 0.449186, acc: 63.28%, op_acc: 31.25%] [G loss: 0.874432]\n",
      "epoch:13 step:10819[D loss: 0.451671, acc: 62.50%, op_acc: 32.81%] [G loss: 0.906862]\n",
      "epoch:13 step:10820[D loss: 0.424853, acc: 54.69%, op_acc: 37.50%] [G loss: 0.863640]\n",
      "epoch:13 step:10821[D loss: 0.426108, acc: 65.62%, op_acc: 38.28%] [G loss: 0.860369]\n",
      "epoch:13 step:10822[D loss: 0.460373, acc: 50.00%, op_acc: 34.38%] [G loss: 0.848060]\n",
      "epoch:13 step:10823[D loss: 0.437826, acc: 55.47%, op_acc: 39.06%] [G loss: 0.881399]\n",
      "epoch:13 step:10824[D loss: 0.427204, acc: 62.50%, op_acc: 32.03%] [G loss: 0.862518]\n",
      "epoch:13 step:10825[D loss: 0.447697, acc: 56.25%, op_acc: 39.06%] [G loss: 0.919771]\n",
      "epoch:13 step:10826[D loss: 0.455618, acc: 57.81%, op_acc: 36.72%] [G loss: 0.844340]\n",
      "epoch:13 step:10827[D loss: 0.409868, acc: 63.28%, op_acc: 43.75%] [G loss: 0.828636]\n",
      "epoch:13 step:10828[D loss: 0.421846, acc: 64.84%, op_acc: 37.50%] [G loss: 0.881911]\n",
      "epoch:13 step:10829[D loss: 0.457294, acc: 53.91%, op_acc: 29.69%] [G loss: 0.778063]\n",
      "epoch:13 step:10830[D loss: 0.491399, acc: 56.25%, op_acc: 28.91%] [G loss: 0.869660]\n",
      "epoch:13 step:10831[D loss: 0.430723, acc: 61.72%, op_acc: 36.72%] [G loss: 0.849405]\n",
      "epoch:13 step:10832[D loss: 0.420668, acc: 56.25%, op_acc: 36.72%] [G loss: 0.885966]\n",
      "epoch:13 step:10833[D loss: 0.426485, acc: 70.31%, op_acc: 37.50%] [G loss: 0.888280]\n",
      "epoch:13 step:10834[D loss: 0.429005, acc: 59.38%, op_acc: 34.38%] [G loss: 0.867582]\n",
      "epoch:13 step:10835[D loss: 0.420754, acc: 57.03%, op_acc: 43.75%] [G loss: 0.812369]\n",
      "epoch:13 step:10836[D loss: 0.428099, acc: 58.59%, op_acc: 37.50%] [G loss: 0.818368]\n",
      "epoch:13 step:10837[D loss: 0.450259, acc: 54.69%, op_acc: 31.25%] [G loss: 0.881505]\n",
      "epoch:13 step:10838[D loss: 0.440149, acc: 64.06%, op_acc: 35.16%] [G loss: 0.916991]\n",
      "epoch:13 step:10839[D loss: 0.438760, acc: 64.84%, op_acc: 32.81%] [G loss: 0.959746]\n",
      "epoch:13 step:10840[D loss: 0.417284, acc: 67.19%, op_acc: 40.62%] [G loss: 0.848420]\n",
      "epoch:13 step:10841[D loss: 0.442174, acc: 54.69%, op_acc: 35.16%] [G loss: 0.852425]\n",
      "epoch:13 step:10842[D loss: 0.406043, acc: 62.50%, op_acc: 35.94%] [G loss: 0.917611]\n",
      "epoch:13 step:10843[D loss: 0.420951, acc: 70.31%, op_acc: 36.72%] [G loss: 0.855322]\n",
      "epoch:13 step:10844[D loss: 0.428680, acc: 62.50%, op_acc: 35.16%] [G loss: 0.901007]\n",
      "epoch:13 step:10845[D loss: 0.444793, acc: 60.16%, op_acc: 34.38%] [G loss: 0.880386]\n",
      "epoch:13 step:10846[D loss: 0.428905, acc: 66.41%, op_acc: 37.50%] [G loss: 0.872127]\n",
      "epoch:13 step:10847[D loss: 0.417837, acc: 63.28%, op_acc: 38.28%] [G loss: 0.886147]\n",
      "epoch:13 step:10848[D loss: 0.437452, acc: 57.81%, op_acc: 30.47%] [G loss: 0.894125]\n",
      "epoch:13 step:10849[D loss: 0.471353, acc: 53.12%, op_acc: 34.38%] [G loss: 0.926499]\n",
      "epoch:13 step:10850[D loss: 0.468749, acc: 52.34%, op_acc: 34.38%] [G loss: 0.850155]\n",
      "epoch:13 step:10851[D loss: 0.429923, acc: 63.28%, op_acc: 35.16%] [G loss: 0.968435]\n",
      "epoch:13 step:10852[D loss: 0.405716, acc: 61.72%, op_acc: 41.41%] [G loss: 0.845199]\n",
      "epoch:13 step:10853[D loss: 0.453615, acc: 60.16%, op_acc: 28.91%] [G loss: 0.886096]\n",
      "epoch:13 step:10854[D loss: 0.446751, acc: 57.03%, op_acc: 29.69%] [G loss: 0.967072]\n",
      "epoch:13 step:10855[D loss: 0.442599, acc: 66.41%, op_acc: 35.16%] [G loss: 0.913693]\n",
      "epoch:13 step:10856[D loss: 0.443771, acc: 52.34%, op_acc: 35.94%] [G loss: 0.897462]\n",
      "epoch:13 step:10857[D loss: 0.413237, acc: 57.03%, op_acc: 42.19%] [G loss: 0.885207]\n",
      "epoch:13 step:10858[D loss: 0.462380, acc: 57.03%, op_acc: 32.03%] [G loss: 0.853368]\n",
      "epoch:13 step:10859[D loss: 0.463304, acc: 50.78%, op_acc: 37.50%] [G loss: 0.850863]\n",
      "epoch:13 step:10860[D loss: 0.453223, acc: 57.81%, op_acc: 37.50%] [G loss: 0.913964]\n",
      "epoch:13 step:10861[D loss: 0.431472, acc: 58.59%, op_acc: 34.38%] [G loss: 0.908917]\n",
      "epoch:13 step:10862[D loss: 0.448552, acc: 52.34%, op_acc: 34.38%] [G loss: 0.855559]\n",
      "epoch:13 step:10863[D loss: 0.398440, acc: 62.50%, op_acc: 48.44%] [G loss: 0.877227]\n",
      "epoch:13 step:10864[D loss: 0.410368, acc: 55.47%, op_acc: 36.72%] [G loss: 0.859550]\n",
      "epoch:13 step:10865[D loss: 0.375614, acc: 69.53%, op_acc: 40.62%] [G loss: 0.929034]\n",
      "epoch:13 step:10866[D loss: 0.419052, acc: 57.81%, op_acc: 39.84%] [G loss: 0.879472]\n",
      "epoch:13 step:10867[D loss: 0.429053, acc: 65.62%, op_acc: 36.72%] [G loss: 0.884230]\n",
      "epoch:13 step:10868[D loss: 0.448136, acc: 57.03%, op_acc: 35.16%] [G loss: 0.840699]\n",
      "epoch:13 step:10869[D loss: 0.496964, acc: 50.00%, op_acc: 30.47%] [G loss: 0.860992]\n",
      "epoch:13 step:10870[D loss: 0.398574, acc: 67.97%, op_acc: 39.84%] [G loss: 0.994061]\n",
      "epoch:13 step:10871[D loss: 0.432211, acc: 63.28%, op_acc: 36.72%] [G loss: 0.926703]\n",
      "epoch:13 step:10872[D loss: 0.423491, acc: 61.72%, op_acc: 40.62%] [G loss: 0.953996]\n",
      "epoch:13 step:10873[D loss: 0.471321, acc: 51.56%, op_acc: 35.16%] [G loss: 0.865244]\n",
      "epoch:13 step:10874[D loss: 0.409876, acc: 59.38%, op_acc: 42.97%] [G loss: 0.979999]\n",
      "epoch:13 step:10875[D loss: 0.447166, acc: 54.69%, op_acc: 39.84%] [G loss: 0.935768]\n",
      "epoch:13 step:10876[D loss: 0.444744, acc: 60.16%, op_acc: 39.84%] [G loss: 0.861566]\n",
      "epoch:13 step:10877[D loss: 0.477039, acc: 50.78%, op_acc: 33.59%] [G loss: 0.850418]\n",
      "epoch:13 step:10878[D loss: 0.432864, acc: 62.50%, op_acc: 38.28%] [G loss: 0.934025]\n",
      "epoch:13 step:10879[D loss: 0.426263, acc: 55.47%, op_acc: 38.28%] [G loss: 0.792109]\n",
      "epoch:13 step:10880[D loss: 0.448351, acc: 57.03%, op_acc: 33.59%] [G loss: 0.927294]\n",
      "epoch:13 step:10881[D loss: 0.447144, acc: 50.78%, op_acc: 37.50%] [G loss: 0.907295]\n",
      "epoch:13 step:10882[D loss: 0.446015, acc: 53.12%, op_acc: 36.72%] [G loss: 0.863495]\n",
      "epoch:13 step:10883[D loss: 0.446836, acc: 60.16%, op_acc: 33.59%] [G loss: 0.835005]\n",
      "epoch:13 step:10884[D loss: 0.413609, acc: 61.72%, op_acc: 35.16%] [G loss: 0.872306]\n",
      "epoch:13 step:10885[D loss: 0.440880, acc: 51.56%, op_acc: 37.50%] [G loss: 0.880407]\n",
      "epoch:13 step:10886[D loss: 0.430620, acc: 58.59%, op_acc: 35.94%] [G loss: 0.914738]\n",
      "epoch:13 step:10887[D loss: 0.456551, acc: 55.47%, op_acc: 32.03%] [G loss: 0.848473]\n",
      "epoch:13 step:10888[D loss: 0.464077, acc: 49.22%, op_acc: 32.81%] [G loss: 0.892372]\n",
      "epoch:13 step:10889[D loss: 0.466854, acc: 50.00%, op_acc: 32.03%] [G loss: 0.921812]\n",
      "epoch:13 step:10890[D loss: 0.416235, acc: 57.81%, op_acc: 40.62%] [G loss: 0.980584]\n",
      "epoch:13 step:10891[D loss: 0.413049, acc: 66.41%, op_acc: 40.62%] [G loss: 0.876656]\n",
      "epoch:13 step:10892[D loss: 0.424696, acc: 57.81%, op_acc: 38.28%] [G loss: 0.839460]\n",
      "epoch:13 step:10893[D loss: 0.438528, acc: 53.91%, op_acc: 41.41%] [G loss: 0.971364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:10894[D loss: 0.437277, acc: 57.81%, op_acc: 37.50%] [G loss: 0.827086]\n",
      "epoch:13 step:10895[D loss: 0.433220, acc: 70.31%, op_acc: 32.03%] [G loss: 0.866572]\n",
      "epoch:13 step:10896[D loss: 0.428929, acc: 60.94%, op_acc: 39.06%] [G loss: 0.847021]\n",
      "epoch:13 step:10897[D loss: 0.420978, acc: 53.12%, op_acc: 43.75%] [G loss: 0.985813]\n",
      "epoch:13 step:10898[D loss: 0.417071, acc: 64.84%, op_acc: 32.81%] [G loss: 0.889353]\n",
      "epoch:13 step:10899[D loss: 0.457849, acc: 57.81%, op_acc: 34.38%] [G loss: 0.838261]\n",
      "epoch:13 step:10900[D loss: 0.463757, acc: 52.34%, op_acc: 33.59%] [G loss: 0.842399]\n",
      "epoch:13 step:10901[D loss: 0.417186, acc: 63.28%, op_acc: 37.50%] [G loss: 0.897901]\n",
      "epoch:13 step:10902[D loss: 0.437317, acc: 66.41%, op_acc: 36.72%] [G loss: 0.823877]\n",
      "epoch:13 step:10903[D loss: 0.409381, acc: 67.97%, op_acc: 39.84%] [G loss: 0.856479]\n",
      "epoch:13 step:10904[D loss: 0.474482, acc: 57.81%, op_acc: 28.12%] [G loss: 0.882175]\n",
      "epoch:13 step:10905[D loss: 0.449662, acc: 53.91%, op_acc: 38.28%] [G loss: 0.888740]\n",
      "epoch:13 step:10906[D loss: 0.442218, acc: 60.94%, op_acc: 35.94%] [G loss: 0.926232]\n",
      "epoch:13 step:10907[D loss: 0.412691, acc: 63.28%, op_acc: 37.50%] [G loss: 0.902412]\n",
      "epoch:13 step:10908[D loss: 0.413323, acc: 65.62%, op_acc: 39.84%] [G loss: 0.970029]\n",
      "epoch:13 step:10909[D loss: 0.454272, acc: 56.25%, op_acc: 37.50%] [G loss: 0.902656]\n",
      "epoch:13 step:10910[D loss: 0.418179, acc: 58.59%, op_acc: 38.28%] [G loss: 0.874009]\n",
      "epoch:13 step:10911[D loss: 0.428693, acc: 53.91%, op_acc: 39.06%] [G loss: 0.833724]\n",
      "epoch:13 step:10912[D loss: 0.454215, acc: 57.81%, op_acc: 35.16%] [G loss: 0.944383]\n",
      "epoch:13 step:10913[D loss: 0.425002, acc: 57.81%, op_acc: 35.94%] [G loss: 0.838884]\n",
      "epoch:13 step:10914[D loss: 0.449026, acc: 57.81%, op_acc: 38.28%] [G loss: 0.855598]\n",
      "epoch:13 step:10915[D loss: 0.435756, acc: 53.91%, op_acc: 32.81%] [G loss: 0.892722]\n",
      "epoch:13 step:10916[D loss: 0.453712, acc: 59.38%, op_acc: 32.81%] [G loss: 0.894803]\n",
      "epoch:13 step:10917[D loss: 0.405633, acc: 66.41%, op_acc: 35.16%] [G loss: 0.868738]\n",
      "epoch:13 step:10918[D loss: 0.404272, acc: 70.31%, op_acc: 39.84%] [G loss: 0.900711]\n",
      "epoch:13 step:10919[D loss: 0.466176, acc: 50.78%, op_acc: 32.81%] [G loss: 0.886280]\n",
      "epoch:13 step:10920[D loss: 0.403795, acc: 64.06%, op_acc: 46.09%] [G loss: 0.886776]\n",
      "epoch:13 step:10921[D loss: 0.442362, acc: 57.81%, op_acc: 35.94%] [G loss: 0.934978]\n",
      "epoch:13 step:10922[D loss: 0.438010, acc: 55.47%, op_acc: 41.41%] [G loss: 0.885463]\n",
      "epoch:13 step:10923[D loss: 0.426947, acc: 61.72%, op_acc: 37.50%] [G loss: 0.904485]\n",
      "epoch:13 step:10924[D loss: 0.416897, acc: 64.84%, op_acc: 35.16%] [G loss: 0.882877]\n",
      "epoch:13 step:10925[D loss: 0.444730, acc: 60.16%, op_acc: 35.94%] [G loss: 0.934262]\n",
      "epoch:13 step:10926[D loss: 0.462748, acc: 57.03%, op_acc: 29.69%] [G loss: 0.888310]\n",
      "epoch:13 step:10927[D loss: 0.409894, acc: 62.50%, op_acc: 40.62%] [G loss: 0.943986]\n",
      "epoch:13 step:10928[D loss: 0.437221, acc: 64.84%, op_acc: 32.03%] [G loss: 0.857928]\n",
      "epoch:13 step:10929[D loss: 0.430373, acc: 58.59%, op_acc: 36.72%] [G loss: 0.891657]\n",
      "epoch:13 step:10930[D loss: 0.441368, acc: 57.81%, op_acc: 34.38%] [G loss: 0.907999]\n",
      "epoch:13 step:10931[D loss: 0.438011, acc: 58.59%, op_acc: 40.62%] [G loss: 0.931298]\n",
      "epoch:13 step:10932[D loss: 0.423019, acc: 63.28%, op_acc: 40.62%] [G loss: 0.873412]\n",
      "epoch:13 step:10933[D loss: 0.413471, acc: 56.25%, op_acc: 39.06%] [G loss: 0.887882]\n",
      "epoch:13 step:10934[D loss: 0.454714, acc: 57.03%, op_acc: 35.94%] [G loss: 0.880766]\n",
      "epoch:14 step:10935[D loss: 0.402019, acc: 65.62%, op_acc: 38.28%] [G loss: 0.909439]\n",
      "epoch:14 step:10936[D loss: 0.405955, acc: 64.84%, op_acc: 40.62%] [G loss: 0.984451]\n",
      "epoch:14 step:10937[D loss: 0.408861, acc: 69.53%, op_acc: 38.28%] [G loss: 0.927374]\n",
      "epoch:14 step:10938[D loss: 0.434268, acc: 51.56%, op_acc: 45.31%] [G loss: 0.864157]\n",
      "epoch:14 step:10939[D loss: 0.435509, acc: 60.16%, op_acc: 35.94%] [G loss: 0.903121]\n",
      "epoch:14 step:10940[D loss: 0.455814, acc: 56.25%, op_acc: 35.16%] [G loss: 0.900131]\n",
      "epoch:14 step:10941[D loss: 0.431928, acc: 60.16%, op_acc: 39.06%] [G loss: 0.812391]\n",
      "epoch:14 step:10942[D loss: 0.438181, acc: 53.91%, op_acc: 39.06%] [G loss: 0.874589]\n",
      "epoch:14 step:10943[D loss: 0.393545, acc: 64.06%, op_acc: 42.97%] [G loss: 0.911963]\n",
      "epoch:14 step:10944[D loss: 0.438950, acc: 56.25%, op_acc: 32.81%] [G loss: 0.884357]\n",
      "epoch:14 step:10945[D loss: 0.415048, acc: 69.53%, op_acc: 38.28%] [G loss: 0.906250]\n",
      "epoch:14 step:10946[D loss: 0.447632, acc: 53.91%, op_acc: 33.59%] [G loss: 0.828439]\n",
      "epoch:14 step:10947[D loss: 0.400198, acc: 66.41%, op_acc: 32.03%] [G loss: 0.908531]\n",
      "epoch:14 step:10948[D loss: 0.464379, acc: 57.03%, op_acc: 31.25%] [G loss: 0.875140]\n",
      "epoch:14 step:10949[D loss: 0.384480, acc: 70.31%, op_acc: 36.72%] [G loss: 0.966074]\n",
      "epoch:14 step:10950[D loss: 0.399061, acc: 61.72%, op_acc: 40.62%] [G loss: 0.857884]\n",
      "epoch:14 step:10951[D loss: 0.446861, acc: 56.25%, op_acc: 36.72%] [G loss: 0.874282]\n",
      "epoch:14 step:10952[D loss: 0.456024, acc: 52.34%, op_acc: 32.81%] [G loss: 0.910779]\n",
      "epoch:14 step:10953[D loss: 0.391184, acc: 69.53%, op_acc: 43.75%] [G loss: 0.933380]\n",
      "epoch:14 step:10954[D loss: 0.408855, acc: 63.28%, op_acc: 40.62%] [G loss: 0.873292]\n",
      "epoch:14 step:10955[D loss: 0.464397, acc: 58.59%, op_acc: 28.12%] [G loss: 0.778904]\n",
      "epoch:14 step:10956[D loss: 0.448605, acc: 56.25%, op_acc: 38.28%] [G loss: 0.781372]\n",
      "epoch:14 step:10957[D loss: 0.427495, acc: 60.94%, op_acc: 36.72%] [G loss: 0.950715]\n",
      "epoch:14 step:10958[D loss: 0.471774, acc: 63.28%, op_acc: 31.25%] [G loss: 0.829540]\n",
      "epoch:14 step:10959[D loss: 0.476142, acc: 53.91%, op_acc: 39.84%] [G loss: 0.835712]\n",
      "epoch:14 step:10960[D loss: 0.424144, acc: 60.94%, op_acc: 39.06%] [G loss: 0.925258]\n",
      "epoch:14 step:10961[D loss: 0.454971, acc: 53.91%, op_acc: 35.94%] [G loss: 0.901463]\n",
      "epoch:14 step:10962[D loss: 0.434494, acc: 57.81%, op_acc: 35.16%] [G loss: 0.915377]\n",
      "epoch:14 step:10963[D loss: 0.431215, acc: 63.28%, op_acc: 34.38%] [G loss: 0.900761]\n",
      "epoch:14 step:10964[D loss: 0.401335, acc: 60.94%, op_acc: 42.97%] [G loss: 0.956727]\n",
      "epoch:14 step:10965[D loss: 0.489192, acc: 54.69%, op_acc: 28.12%] [G loss: 0.888638]\n",
      "epoch:14 step:10966[D loss: 0.427477, acc: 60.94%, op_acc: 35.94%] [G loss: 0.946979]\n",
      "epoch:14 step:10967[D loss: 0.437213, acc: 52.34%, op_acc: 38.28%] [G loss: 0.971889]\n",
      "epoch:14 step:10968[D loss: 0.416819, acc: 62.50%, op_acc: 42.97%] [G loss: 0.879020]\n",
      "epoch:14 step:10969[D loss: 0.422801, acc: 71.09%, op_acc: 34.38%] [G loss: 0.903974]\n",
      "epoch:14 step:10970[D loss: 0.423552, acc: 57.03%, op_acc: 36.72%] [G loss: 0.901919]\n",
      "epoch:14 step:10971[D loss: 0.431857, acc: 57.03%, op_acc: 37.50%] [G loss: 0.916916]\n",
      "epoch:14 step:10972[D loss: 0.452932, acc: 53.91%, op_acc: 36.72%] [G loss: 0.882973]\n",
      "epoch:14 step:10973[D loss: 0.403171, acc: 62.50%, op_acc: 39.06%] [G loss: 0.912681]\n",
      "epoch:14 step:10974[D loss: 0.417493, acc: 61.72%, op_acc: 38.28%] [G loss: 0.957278]\n",
      "epoch:14 step:10975[D loss: 0.408955, acc: 64.84%, op_acc: 39.84%] [G loss: 0.825682]\n",
      "epoch:14 step:10976[D loss: 0.418733, acc: 54.69%, op_acc: 39.06%] [G loss: 0.806690]\n",
      "epoch:14 step:10977[D loss: 0.432500, acc: 60.16%, op_acc: 32.81%] [G loss: 0.869255]\n",
      "epoch:14 step:10978[D loss: 0.437944, acc: 60.16%, op_acc: 33.59%] [G loss: 0.914994]\n",
      "epoch:14 step:10979[D loss: 0.394343, acc: 62.50%, op_acc: 42.19%] [G loss: 0.953562]\n",
      "epoch:14 step:10980[D loss: 0.441988, acc: 56.25%, op_acc: 35.16%] [G loss: 0.927146]\n",
      "epoch:14 step:10981[D loss: 0.429514, acc: 63.28%, op_acc: 35.16%] [G loss: 0.943197]\n",
      "epoch:14 step:10982[D loss: 0.447294, acc: 63.28%, op_acc: 30.47%] [G loss: 0.890383]\n",
      "epoch:14 step:10983[D loss: 0.439608, acc: 62.50%, op_acc: 34.38%] [G loss: 0.781640]\n",
      "epoch:14 step:10984[D loss: 0.447343, acc: 56.25%, op_acc: 34.38%] [G loss: 0.879225]\n",
      "epoch:14 step:10985[D loss: 0.437750, acc: 60.94%, op_acc: 32.81%] [G loss: 0.904579]\n",
      "epoch:14 step:10986[D loss: 0.433792, acc: 55.47%, op_acc: 39.84%] [G loss: 0.925770]\n",
      "epoch:14 step:10987[D loss: 0.472303, acc: 63.28%, op_acc: 29.69%] [G loss: 0.962852]\n",
      "epoch:14 step:10988[D loss: 0.465387, acc: 54.69%, op_acc: 35.16%] [G loss: 0.947237]\n",
      "epoch:14 step:10989[D loss: 0.449346, acc: 55.47%, op_acc: 39.84%] [G loss: 0.864747]\n",
      "epoch:14 step:10990[D loss: 0.445742, acc: 51.56%, op_acc: 37.50%] [G loss: 0.854919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:10991[D loss: 0.448737, acc: 54.69%, op_acc: 33.59%] [G loss: 0.933699]\n",
      "epoch:14 step:10992[D loss: 0.443438, acc: 50.00%, op_acc: 37.50%] [G loss: 0.864489]\n",
      "epoch:14 step:10993[D loss: 0.415026, acc: 68.75%, op_acc: 37.50%] [G loss: 0.935954]\n",
      "epoch:14 step:10994[D loss: 0.396654, acc: 68.75%, op_acc: 35.94%] [G loss: 0.883769]\n",
      "epoch:14 step:10995[D loss: 0.439611, acc: 64.06%, op_acc: 37.50%] [G loss: 0.911539]\n",
      "epoch:14 step:10996[D loss: 0.435659, acc: 61.72%, op_acc: 35.94%] [G loss: 0.826644]\n",
      "epoch:14 step:10997[D loss: 0.453470, acc: 55.47%, op_acc: 35.16%] [G loss: 0.890626]\n",
      "epoch:14 step:10998[D loss: 0.427445, acc: 62.50%, op_acc: 36.72%] [G loss: 0.935664]\n",
      "epoch:14 step:10999[D loss: 0.465168, acc: 57.81%, op_acc: 35.16%] [G loss: 0.829375]\n",
      "epoch:14 step:11000[D loss: 0.456665, acc: 55.47%, op_acc: 36.72%] [G loss: 0.874970]\n",
      "epoch:14 step:11001[D loss: 0.383355, acc: 71.09%, op_acc: 39.84%] [G loss: 0.875219]\n",
      "epoch:14 step:11002[D loss: 0.444717, acc: 61.72%, op_acc: 32.03%] [G loss: 0.821967]\n",
      "epoch:14 step:11003[D loss: 0.400268, acc: 61.72%, op_acc: 41.41%] [G loss: 0.903738]\n",
      "epoch:14 step:11004[D loss: 0.436739, acc: 61.72%, op_acc: 37.50%] [G loss: 0.899214]\n",
      "epoch:14 step:11005[D loss: 0.454297, acc: 57.03%, op_acc: 31.25%] [G loss: 0.902823]\n",
      "epoch:14 step:11006[D loss: 0.413034, acc: 60.94%, op_acc: 36.72%] [G loss: 0.869410]\n",
      "epoch:14 step:11007[D loss: 0.426854, acc: 63.28%, op_acc: 36.72%] [G loss: 0.999658]\n",
      "epoch:14 step:11008[D loss: 0.433172, acc: 57.81%, op_acc: 35.94%] [G loss: 0.875926]\n",
      "epoch:14 step:11009[D loss: 0.442671, acc: 57.81%, op_acc: 35.16%] [G loss: 0.937171]\n",
      "epoch:14 step:11010[D loss: 0.448107, acc: 54.69%, op_acc: 38.28%] [G loss: 0.913898]\n",
      "epoch:14 step:11011[D loss: 0.419803, acc: 62.50%, op_acc: 35.94%] [G loss: 0.992642]\n",
      "epoch:14 step:11012[D loss: 0.467973, acc: 61.72%, op_acc: 30.47%] [G loss: 0.877914]\n",
      "epoch:14 step:11013[D loss: 0.442037, acc: 57.81%, op_acc: 37.50%] [G loss: 0.917986]\n",
      "epoch:14 step:11014[D loss: 0.450785, acc: 56.25%, op_acc: 34.38%] [G loss: 0.910725]\n",
      "epoch:14 step:11015[D loss: 0.468602, acc: 60.94%, op_acc: 32.03%] [G loss: 0.938463]\n",
      "epoch:14 step:11016[D loss: 0.425078, acc: 56.25%, op_acc: 35.94%] [G loss: 0.877978]\n",
      "epoch:14 step:11017[D loss: 0.442255, acc: 60.16%, op_acc: 33.59%] [G loss: 0.878173]\n",
      "epoch:14 step:11018[D loss: 0.457330, acc: 46.09%, op_acc: 35.94%] [G loss: 0.907867]\n",
      "epoch:14 step:11019[D loss: 0.454427, acc: 60.16%, op_acc: 31.25%] [G loss: 0.801679]\n",
      "epoch:14 step:11020[D loss: 0.450186, acc: 59.38%, op_acc: 33.59%] [G loss: 0.938504]\n",
      "epoch:14 step:11021[D loss: 0.464868, acc: 57.81%, op_acc: 32.81%] [G loss: 0.882569]\n",
      "epoch:14 step:11022[D loss: 0.454252, acc: 60.94%, op_acc: 32.81%] [G loss: 0.881252]\n",
      "epoch:14 step:11023[D loss: 0.452529, acc: 55.47%, op_acc: 36.72%] [G loss: 0.983061]\n",
      "epoch:14 step:11024[D loss: 0.417553, acc: 55.47%, op_acc: 39.06%] [G loss: 0.919072]\n",
      "epoch:14 step:11025[D loss: 0.430207, acc: 60.94%, op_acc: 38.28%] [G loss: 0.881439]\n",
      "epoch:14 step:11026[D loss: 0.417009, acc: 64.84%, op_acc: 35.94%] [G loss: 0.933314]\n",
      "epoch:14 step:11027[D loss: 0.429011, acc: 55.47%, op_acc: 35.16%] [G loss: 0.860400]\n",
      "epoch:14 step:11028[D loss: 0.409635, acc: 59.38%, op_acc: 40.62%] [G loss: 0.892868]\n",
      "epoch:14 step:11029[D loss: 0.438718, acc: 55.47%, op_acc: 33.59%] [G loss: 0.844617]\n",
      "epoch:14 step:11030[D loss: 0.437919, acc: 60.16%, op_acc: 39.06%] [G loss: 0.866339]\n",
      "epoch:14 step:11031[D loss: 0.409667, acc: 59.38%, op_acc: 39.06%] [G loss: 0.910164]\n",
      "epoch:14 step:11032[D loss: 0.433735, acc: 61.72%, op_acc: 38.28%] [G loss: 0.824115]\n",
      "epoch:14 step:11033[D loss: 0.436063, acc: 59.38%, op_acc: 35.94%] [G loss: 0.883154]\n",
      "epoch:14 step:11034[D loss: 0.400490, acc: 69.53%, op_acc: 39.06%] [G loss: 0.876681]\n",
      "epoch:14 step:11035[D loss: 0.435608, acc: 60.94%, op_acc: 37.50%] [G loss: 0.880798]\n",
      "epoch:14 step:11036[D loss: 0.406246, acc: 61.72%, op_acc: 40.62%] [G loss: 0.894498]\n",
      "epoch:14 step:11037[D loss: 0.450180, acc: 50.00%, op_acc: 35.16%] [G loss: 0.796785]\n",
      "epoch:14 step:11038[D loss: 0.423505, acc: 63.28%, op_acc: 35.94%] [G loss: 0.790700]\n",
      "epoch:14 step:11039[D loss: 0.410819, acc: 60.16%, op_acc: 42.97%] [G loss: 0.829298]\n",
      "epoch:14 step:11040[D loss: 0.423001, acc: 62.50%, op_acc: 39.06%] [G loss: 0.896021]\n",
      "epoch:14 step:11041[D loss: 0.436507, acc: 56.25%, op_acc: 32.03%] [G loss: 0.937198]\n",
      "epoch:14 step:11042[D loss: 0.455207, acc: 56.25%, op_acc: 35.94%] [G loss: 0.969531]\n",
      "epoch:14 step:11043[D loss: 0.416770, acc: 60.94%, op_acc: 39.84%] [G loss: 0.892440]\n",
      "epoch:14 step:11044[D loss: 0.410500, acc: 59.38%, op_acc: 43.75%] [G loss: 0.953070]\n",
      "epoch:14 step:11045[D loss: 0.465866, acc: 56.25%, op_acc: 33.59%] [G loss: 0.876857]\n",
      "epoch:14 step:11046[D loss: 0.434348, acc: 64.84%, op_acc: 38.28%] [G loss: 0.887267]\n",
      "epoch:14 step:11047[D loss: 0.447539, acc: 59.38%, op_acc: 32.81%] [G loss: 0.937551]\n",
      "epoch:14 step:11048[D loss: 0.429317, acc: 61.72%, op_acc: 40.62%] [G loss: 0.881859]\n",
      "epoch:14 step:11049[D loss: 0.443431, acc: 52.34%, op_acc: 38.28%] [G loss: 0.876799]\n",
      "epoch:14 step:11050[D loss: 0.453335, acc: 57.81%, op_acc: 31.25%] [G loss: 0.958258]\n",
      "epoch:14 step:11051[D loss: 0.429454, acc: 55.47%, op_acc: 39.84%] [G loss: 0.912387]\n",
      "epoch:14 step:11052[D loss: 0.419240, acc: 62.50%, op_acc: 37.50%] [G loss: 0.909231]\n",
      "epoch:14 step:11053[D loss: 0.457102, acc: 58.59%, op_acc: 34.38%] [G loss: 0.851923]\n",
      "epoch:14 step:11054[D loss: 0.440034, acc: 54.69%, op_acc: 33.59%] [G loss: 0.806497]\n",
      "epoch:14 step:11055[D loss: 0.424275, acc: 65.62%, op_acc: 38.28%] [G loss: 0.927770]\n",
      "epoch:14 step:11056[D loss: 0.464351, acc: 51.56%, op_acc: 28.91%] [G loss: 0.839949]\n",
      "epoch:14 step:11057[D loss: 0.464472, acc: 53.12%, op_acc: 29.69%] [G loss: 0.924342]\n",
      "epoch:14 step:11058[D loss: 0.423306, acc: 55.47%, op_acc: 39.84%] [G loss: 0.857433]\n",
      "epoch:14 step:11059[D loss: 0.431780, acc: 66.41%, op_acc: 34.38%] [G loss: 0.939607]\n",
      "epoch:14 step:11060[D loss: 0.430469, acc: 54.69%, op_acc: 41.41%] [G loss: 0.912803]\n",
      "epoch:14 step:11061[D loss: 0.427763, acc: 61.72%, op_acc: 37.50%] [G loss: 0.921542]\n",
      "epoch:14 step:11062[D loss: 0.431244, acc: 59.38%, op_acc: 32.81%] [G loss: 0.926113]\n",
      "epoch:14 step:11063[D loss: 0.440840, acc: 57.03%, op_acc: 39.06%] [G loss: 0.971678]\n",
      "epoch:14 step:11064[D loss: 0.423214, acc: 61.72%, op_acc: 39.06%] [G loss: 0.851325]\n",
      "epoch:14 step:11065[D loss: 0.419100, acc: 58.59%, op_acc: 32.81%] [G loss: 0.957338]\n",
      "epoch:14 step:11066[D loss: 0.397630, acc: 61.72%, op_acc: 43.75%] [G loss: 0.944179]\n",
      "epoch:14 step:11067[D loss: 0.471854, acc: 64.06%, op_acc: 30.47%] [G loss: 0.844963]\n",
      "epoch:14 step:11068[D loss: 0.450164, acc: 62.50%, op_acc: 35.94%] [G loss: 0.826341]\n",
      "epoch:14 step:11069[D loss: 0.442319, acc: 59.38%, op_acc: 31.25%] [G loss: 0.889333]\n",
      "epoch:14 step:11070[D loss: 0.419596, acc: 57.03%, op_acc: 32.81%] [G loss: 0.846302]\n",
      "epoch:14 step:11071[D loss: 0.464614, acc: 53.91%, op_acc: 35.16%] [G loss: 0.879449]\n",
      "epoch:14 step:11072[D loss: 0.427791, acc: 65.62%, op_acc: 35.16%] [G loss: 0.934370]\n",
      "epoch:14 step:11073[D loss: 0.441337, acc: 59.38%, op_acc: 39.84%] [G loss: 0.884484]\n",
      "epoch:14 step:11074[D loss: 0.454337, acc: 58.59%, op_acc: 34.38%] [G loss: 0.816824]\n",
      "epoch:14 step:11075[D loss: 0.472252, acc: 51.56%, op_acc: 32.03%] [G loss: 0.898304]\n",
      "epoch:14 step:11076[D loss: 0.433041, acc: 57.81%, op_acc: 32.03%] [G loss: 0.928997]\n",
      "epoch:14 step:11077[D loss: 0.441716, acc: 60.94%, op_acc: 39.84%] [G loss: 0.888665]\n",
      "epoch:14 step:11078[D loss: 0.459628, acc: 53.12%, op_acc: 33.59%] [G loss: 0.843091]\n",
      "epoch:14 step:11079[D loss: 0.412195, acc: 66.41%, op_acc: 38.28%] [G loss: 0.877424]\n",
      "epoch:14 step:11080[D loss: 0.403470, acc: 67.97%, op_acc: 39.06%] [G loss: 0.874602]\n",
      "epoch:14 step:11081[D loss: 0.445947, acc: 55.47%, op_acc: 32.81%] [G loss: 0.816391]\n",
      "epoch:14 step:11082[D loss: 0.443514, acc: 57.03%, op_acc: 32.81%] [G loss: 0.902016]\n",
      "epoch:14 step:11083[D loss: 0.433269, acc: 60.94%, op_acc: 41.41%] [G loss: 0.811552]\n",
      "epoch:14 step:11084[D loss: 0.428968, acc: 58.59%, op_acc: 36.72%] [G loss: 0.874783]\n",
      "epoch:14 step:11085[D loss: 0.415620, acc: 62.50%, op_acc: 42.97%] [G loss: 0.890885]\n",
      "epoch:14 step:11086[D loss: 0.434572, acc: 54.69%, op_acc: 40.62%] [G loss: 0.837128]\n",
      "epoch:14 step:11087[D loss: 0.430417, acc: 59.38%, op_acc: 33.59%] [G loss: 0.913155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11088[D loss: 0.435619, acc: 57.81%, op_acc: 35.94%] [G loss: 0.850012]\n",
      "epoch:14 step:11089[D loss: 0.435350, acc: 62.50%, op_acc: 32.03%] [G loss: 0.943403]\n",
      "epoch:14 step:11090[D loss: 0.474847, acc: 43.75%, op_acc: 33.59%] [G loss: 0.877530]\n",
      "epoch:14 step:11091[D loss: 0.426872, acc: 62.50%, op_acc: 42.97%] [G loss: 0.864047]\n",
      "epoch:14 step:11092[D loss: 0.406741, acc: 66.41%, op_acc: 44.53%] [G loss: 0.891136]\n",
      "epoch:14 step:11093[D loss: 0.413899, acc: 64.84%, op_acc: 37.50%] [G loss: 0.889467]\n",
      "epoch:14 step:11094[D loss: 0.421747, acc: 67.97%, op_acc: 32.81%] [G loss: 0.890592]\n",
      "epoch:14 step:11095[D loss: 0.442487, acc: 61.72%, op_acc: 37.50%] [G loss: 0.886919]\n",
      "epoch:14 step:11096[D loss: 0.438661, acc: 53.12%, op_acc: 35.94%] [G loss: 0.809801]\n",
      "epoch:14 step:11097[D loss: 0.448017, acc: 61.72%, op_acc: 34.38%] [G loss: 0.891669]\n",
      "epoch:14 step:11098[D loss: 0.461286, acc: 59.38%, op_acc: 32.03%] [G loss: 0.905336]\n",
      "epoch:14 step:11099[D loss: 0.384003, acc: 71.88%, op_acc: 41.41%] [G loss: 0.949100]\n",
      "epoch:14 step:11100[D loss: 0.457025, acc: 52.34%, op_acc: 40.62%] [G loss: 0.866047]\n",
      "epoch:14 step:11101[D loss: 0.429449, acc: 69.53%, op_acc: 39.06%] [G loss: 0.939562]\n",
      "epoch:14 step:11102[D loss: 0.413801, acc: 61.72%, op_acc: 42.97%] [G loss: 0.920127]\n",
      "epoch:14 step:11103[D loss: 0.437473, acc: 51.56%, op_acc: 35.16%] [G loss: 0.885389]\n",
      "epoch:14 step:11104[D loss: 0.449273, acc: 48.44%, op_acc: 36.72%] [G loss: 0.839233]\n",
      "epoch:14 step:11105[D loss: 0.471780, acc: 47.66%, op_acc: 33.59%] [G loss: 0.918170]\n",
      "epoch:14 step:11106[D loss: 0.398110, acc: 64.84%, op_acc: 41.41%] [G loss: 0.944369]\n",
      "epoch:14 step:11107[D loss: 0.431974, acc: 59.38%, op_acc: 35.16%] [G loss: 0.938625]\n",
      "epoch:14 step:11108[D loss: 0.476992, acc: 47.66%, op_acc: 32.03%] [G loss: 0.854016]\n",
      "epoch:14 step:11109[D loss: 0.400233, acc: 64.06%, op_acc: 40.62%] [G loss: 0.883607]\n",
      "epoch:14 step:11110[D loss: 0.453940, acc: 57.81%, op_acc: 39.84%] [G loss: 0.829996]\n",
      "epoch:14 step:11111[D loss: 0.420120, acc: 71.09%, op_acc: 35.94%] [G loss: 0.891348]\n",
      "epoch:14 step:11112[D loss: 0.445681, acc: 55.47%, op_acc: 35.16%] [G loss: 0.953691]\n",
      "epoch:14 step:11113[D loss: 0.397809, acc: 63.28%, op_acc: 42.19%] [G loss: 0.928066]\n",
      "epoch:14 step:11114[D loss: 0.426909, acc: 67.97%, op_acc: 36.72%] [G loss: 0.874518]\n",
      "epoch:14 step:11115[D loss: 0.397150, acc: 67.19%, op_acc: 38.28%] [G loss: 0.915211]\n",
      "epoch:14 step:11116[D loss: 0.419706, acc: 66.41%, op_acc: 36.72%] [G loss: 0.929394]\n",
      "epoch:14 step:11117[D loss: 0.412943, acc: 67.97%, op_acc: 40.62%] [G loss: 0.975017]\n",
      "epoch:14 step:11118[D loss: 0.416424, acc: 69.53%, op_acc: 39.84%] [G loss: 0.889599]\n",
      "epoch:14 step:11119[D loss: 0.445994, acc: 66.41%, op_acc: 32.81%] [G loss: 0.907533]\n",
      "epoch:14 step:11120[D loss: 0.418921, acc: 63.28%, op_acc: 42.97%] [G loss: 0.965996]\n",
      "epoch:14 step:11121[D loss: 0.422038, acc: 63.28%, op_acc: 35.94%] [G loss: 0.926518]\n",
      "epoch:14 step:11122[D loss: 0.451561, acc: 55.47%, op_acc: 34.38%] [G loss: 0.845382]\n",
      "epoch:14 step:11123[D loss: 0.442575, acc: 62.50%, op_acc: 35.94%] [G loss: 0.979503]\n",
      "epoch:14 step:11124[D loss: 0.474323, acc: 50.78%, op_acc: 39.06%] [G loss: 0.922966]\n",
      "epoch:14 step:11125[D loss: 0.410023, acc: 60.16%, op_acc: 42.19%] [G loss: 0.893348]\n",
      "epoch:14 step:11126[D loss: 0.432585, acc: 63.28%, op_acc: 39.06%] [G loss: 0.841951]\n",
      "epoch:14 step:11127[D loss: 0.475822, acc: 51.56%, op_acc: 36.72%] [G loss: 0.908925]\n",
      "epoch:14 step:11128[D loss: 0.434300, acc: 55.47%, op_acc: 36.72%] [G loss: 0.806528]\n",
      "epoch:14 step:11129[D loss: 0.426601, acc: 58.59%, op_acc: 40.62%] [G loss: 0.881952]\n",
      "epoch:14 step:11130[D loss: 0.433767, acc: 60.16%, op_acc: 39.06%] [G loss: 0.833859]\n",
      "epoch:14 step:11131[D loss: 0.430512, acc: 61.72%, op_acc: 39.06%] [G loss: 0.895740]\n",
      "epoch:14 step:11132[D loss: 0.469811, acc: 57.03%, op_acc: 34.38%] [G loss: 0.886912]\n",
      "epoch:14 step:11133[D loss: 0.445149, acc: 60.94%, op_acc: 36.72%] [G loss: 0.806691]\n",
      "epoch:14 step:11134[D loss: 0.414194, acc: 57.03%, op_acc: 38.28%] [G loss: 0.895302]\n",
      "epoch:14 step:11135[D loss: 0.420030, acc: 56.25%, op_acc: 36.72%] [G loss: 0.821416]\n",
      "epoch:14 step:11136[D loss: 0.433223, acc: 56.25%, op_acc: 39.06%] [G loss: 0.978155]\n",
      "epoch:14 step:11137[D loss: 0.455305, acc: 53.12%, op_acc: 35.94%] [G loss: 0.928027]\n",
      "epoch:14 step:11138[D loss: 0.468321, acc: 54.69%, op_acc: 34.38%] [G loss: 0.838247]\n",
      "epoch:14 step:11139[D loss: 0.447251, acc: 61.72%, op_acc: 35.16%] [G loss: 0.821635]\n",
      "epoch:14 step:11140[D loss: 0.454628, acc: 50.78%, op_acc: 33.59%] [G loss: 0.840809]\n",
      "epoch:14 step:11141[D loss: 0.424281, acc: 59.38%, op_acc: 39.06%] [G loss: 0.761509]\n",
      "epoch:14 step:11142[D loss: 0.453831, acc: 60.16%, op_acc: 35.94%] [G loss: 0.769397]\n",
      "epoch:14 step:11143[D loss: 0.421663, acc: 60.94%, op_acc: 35.16%] [G loss: 0.922133]\n",
      "epoch:14 step:11144[D loss: 0.453679, acc: 53.91%, op_acc: 34.38%] [G loss: 0.937533]\n",
      "epoch:14 step:11145[D loss: 0.416397, acc: 57.03%, op_acc: 42.97%] [G loss: 0.954166]\n",
      "epoch:14 step:11146[D loss: 0.414407, acc: 60.16%, op_acc: 42.97%] [G loss: 0.915949]\n",
      "epoch:14 step:11147[D loss: 0.460774, acc: 57.03%, op_acc: 33.59%] [G loss: 0.911412]\n",
      "epoch:14 step:11148[D loss: 0.441632, acc: 57.03%, op_acc: 36.72%] [G loss: 0.930951]\n",
      "epoch:14 step:11149[D loss: 0.461849, acc: 58.59%, op_acc: 35.94%] [G loss: 0.861358]\n",
      "epoch:14 step:11150[D loss: 0.428573, acc: 64.06%, op_acc: 35.94%] [G loss: 0.975057]\n",
      "epoch:14 step:11151[D loss: 0.415200, acc: 65.62%, op_acc: 37.50%] [G loss: 0.829695]\n",
      "epoch:14 step:11152[D loss: 0.430305, acc: 60.16%, op_acc: 33.59%] [G loss: 0.895038]\n",
      "epoch:14 step:11153[D loss: 0.441271, acc: 56.25%, op_acc: 37.50%] [G loss: 0.986694]\n",
      "epoch:14 step:11154[D loss: 0.423931, acc: 59.38%, op_acc: 38.28%] [G loss: 0.928278]\n",
      "epoch:14 step:11155[D loss: 0.444814, acc: 52.34%, op_acc: 41.41%] [G loss: 0.909625]\n",
      "epoch:14 step:11156[D loss: 0.451668, acc: 49.22%, op_acc: 39.06%] [G loss: 0.883364]\n",
      "epoch:14 step:11157[D loss: 0.438328, acc: 57.03%, op_acc: 35.16%] [G loss: 0.965390]\n",
      "epoch:14 step:11158[D loss: 0.456491, acc: 55.47%, op_acc: 34.38%] [G loss: 0.923363]\n",
      "epoch:14 step:11159[D loss: 0.449206, acc: 57.03%, op_acc: 34.38%] [G loss: 0.912401]\n",
      "epoch:14 step:11160[D loss: 0.432691, acc: 62.50%, op_acc: 38.28%] [G loss: 0.848503]\n",
      "epoch:14 step:11161[D loss: 0.455518, acc: 55.47%, op_acc: 30.47%] [G loss: 0.871842]\n",
      "epoch:14 step:11162[D loss: 0.438771, acc: 55.47%, op_acc: 37.50%] [G loss: 0.897639]\n",
      "epoch:14 step:11163[D loss: 0.442797, acc: 54.69%, op_acc: 39.06%] [G loss: 0.852164]\n",
      "epoch:14 step:11164[D loss: 0.440986, acc: 59.38%, op_acc: 34.38%] [G loss: 0.897794]\n",
      "epoch:14 step:11165[D loss: 0.424273, acc: 55.47%, op_acc: 39.84%] [G loss: 0.806143]\n",
      "epoch:14 step:11166[D loss: 0.425886, acc: 60.16%, op_acc: 33.59%] [G loss: 0.850621]\n",
      "epoch:14 step:11167[D loss: 0.447494, acc: 60.94%, op_acc: 31.25%] [G loss: 0.830865]\n",
      "epoch:14 step:11168[D loss: 0.473693, acc: 55.47%, op_acc: 36.72%] [G loss: 0.918515]\n",
      "epoch:14 step:11169[D loss: 0.428386, acc: 56.25%, op_acc: 39.84%] [G loss: 0.931020]\n",
      "epoch:14 step:11170[D loss: 0.423841, acc: 64.06%, op_acc: 35.94%] [G loss: 0.920344]\n",
      "epoch:14 step:11171[D loss: 0.413232, acc: 64.06%, op_acc: 39.06%] [G loss: 0.942805]\n",
      "epoch:14 step:11172[D loss: 0.450969, acc: 47.66%, op_acc: 37.50%] [G loss: 0.832828]\n",
      "epoch:14 step:11173[D loss: 0.422593, acc: 56.25%, op_acc: 39.84%] [G loss: 1.049635]\n",
      "epoch:14 step:11174[D loss: 0.429801, acc: 58.59%, op_acc: 33.59%] [G loss: 0.865610]\n",
      "epoch:14 step:11175[D loss: 0.415869, acc: 67.19%, op_acc: 43.75%] [G loss: 0.875864]\n",
      "epoch:14 step:11176[D loss: 0.419650, acc: 60.94%, op_acc: 40.62%] [G loss: 0.888458]\n",
      "epoch:14 step:11177[D loss: 0.428471, acc: 53.91%, op_acc: 39.84%] [G loss: 0.899318]\n",
      "epoch:14 step:11178[D loss: 0.439095, acc: 56.25%, op_acc: 39.84%] [G loss: 0.895697]\n",
      "epoch:14 step:11179[D loss: 0.426587, acc: 62.50%, op_acc: 39.84%] [G loss: 0.883261]\n",
      "epoch:14 step:11180[D loss: 0.450342, acc: 57.81%, op_acc: 32.03%] [G loss: 0.846092]\n",
      "epoch:14 step:11181[D loss: 0.462761, acc: 53.12%, op_acc: 33.59%] [G loss: 0.849356]\n",
      "epoch:14 step:11182[D loss: 0.457082, acc: 58.59%, op_acc: 32.03%] [G loss: 0.853449]\n",
      "epoch:14 step:11183[D loss: 0.415359, acc: 67.19%, op_acc: 38.28%] [G loss: 0.917225]\n",
      "epoch:14 step:11184[D loss: 0.433313, acc: 64.06%, op_acc: 37.50%] [G loss: 0.879037]\n",
      "epoch:14 step:11185[D loss: 0.425489, acc: 59.38%, op_acc: 39.06%] [G loss: 0.844036]\n",
      "epoch:14 step:11186[D loss: 0.429277, acc: 59.38%, op_acc: 35.94%] [G loss: 0.923327]\n",
      "epoch:14 step:11187[D loss: 0.398626, acc: 68.75%, op_acc: 40.62%] [G loss: 0.902621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11188[D loss: 0.442498, acc: 56.25%, op_acc: 39.06%] [G loss: 0.883031]\n",
      "epoch:14 step:11189[D loss: 0.432206, acc: 57.03%, op_acc: 35.16%] [G loss: 0.858302]\n",
      "epoch:14 step:11190[D loss: 0.425006, acc: 54.69%, op_acc: 35.16%] [G loss: 0.915331]\n",
      "epoch:14 step:11191[D loss: 0.451176, acc: 50.78%, op_acc: 33.59%] [G loss: 0.873141]\n",
      "epoch:14 step:11192[D loss: 0.426637, acc: 60.94%, op_acc: 39.06%] [G loss: 0.877735]\n",
      "epoch:14 step:11193[D loss: 0.425573, acc: 63.28%, op_acc: 35.16%] [G loss: 0.867491]\n",
      "epoch:14 step:11194[D loss: 0.410278, acc: 67.19%, op_acc: 42.19%] [G loss: 0.957596]\n",
      "epoch:14 step:11195[D loss: 0.387537, acc: 71.09%, op_acc: 39.06%] [G loss: 0.954001]\n",
      "epoch:14 step:11196[D loss: 0.431387, acc: 54.69%, op_acc: 32.03%] [G loss: 0.835767]\n",
      "epoch:14 step:11197[D loss: 0.426790, acc: 60.16%, op_acc: 38.28%] [G loss: 0.914641]\n",
      "epoch:14 step:11198[D loss: 0.445721, acc: 53.12%, op_acc: 32.81%] [G loss: 0.914802]\n",
      "epoch:14 step:11199[D loss: 0.410047, acc: 64.06%, op_acc: 39.06%] [G loss: 0.978009]\n",
      "epoch:14 step:11200[D loss: 0.403596, acc: 67.19%, op_acc: 41.41%] [G loss: 0.876205]\n",
      "epoch:14 step:11201[D loss: 0.451776, acc: 57.03%, op_acc: 33.59%] [G loss: 0.936857]\n",
      "epoch:14 step:11202[D loss: 0.415202, acc: 56.25%, op_acc: 40.62%] [G loss: 0.885061]\n",
      "epoch:14 step:11203[D loss: 0.415002, acc: 61.72%, op_acc: 43.75%] [G loss: 0.988775]\n",
      "epoch:14 step:11204[D loss: 0.412073, acc: 66.41%, op_acc: 39.84%] [G loss: 0.942183]\n",
      "epoch:14 step:11205[D loss: 0.415036, acc: 70.31%, op_acc: 34.38%] [G loss: 0.928264]\n",
      "epoch:14 step:11206[D loss: 0.406363, acc: 68.75%, op_acc: 32.81%] [G loss: 0.899855]\n",
      "epoch:14 step:11207[D loss: 0.420375, acc: 60.94%, op_acc: 41.41%] [G loss: 0.881688]\n",
      "epoch:14 step:11208[D loss: 0.464336, acc: 55.47%, op_acc: 32.81%] [G loss: 0.906485]\n",
      "epoch:14 step:11209[D loss: 0.427395, acc: 58.59%, op_acc: 39.84%] [G loss: 0.876721]\n",
      "epoch:14 step:11210[D loss: 0.454457, acc: 51.56%, op_acc: 39.06%] [G loss: 0.796852]\n",
      "epoch:14 step:11211[D loss: 0.421882, acc: 67.97%, op_acc: 32.81%] [G loss: 0.928983]\n",
      "epoch:14 step:11212[D loss: 0.445156, acc: 57.81%, op_acc: 38.28%] [G loss: 0.921154]\n",
      "epoch:14 step:11213[D loss: 0.426997, acc: 60.16%, op_acc: 35.94%] [G loss: 0.879718]\n",
      "epoch:14 step:11214[D loss: 0.430425, acc: 64.06%, op_acc: 39.84%] [G loss: 0.859215]\n",
      "epoch:14 step:11215[D loss: 0.463273, acc: 55.47%, op_acc: 30.47%] [G loss: 0.863975]\n",
      "epoch:14 step:11216[D loss: 0.474200, acc: 57.03%, op_acc: 32.03%] [G loss: 0.883623]\n",
      "epoch:14 step:11217[D loss: 0.426939, acc: 56.25%, op_acc: 38.28%] [G loss: 0.893686]\n",
      "epoch:14 step:11218[D loss: 0.425635, acc: 58.59%, op_acc: 35.94%] [G loss: 0.894433]\n",
      "epoch:14 step:11219[D loss: 0.433108, acc: 58.59%, op_acc: 31.25%] [G loss: 0.816914]\n",
      "epoch:14 step:11220[D loss: 0.435834, acc: 60.94%, op_acc: 35.16%] [G loss: 0.871036]\n",
      "epoch:14 step:11221[D loss: 0.418560, acc: 64.84%, op_acc: 38.28%] [G loss: 0.862330]\n",
      "epoch:14 step:11222[D loss: 0.432716, acc: 54.69%, op_acc: 42.19%] [G loss: 0.899529]\n",
      "epoch:14 step:11223[D loss: 0.444877, acc: 58.59%, op_acc: 32.81%] [G loss: 0.875133]\n",
      "epoch:14 step:11224[D loss: 0.426547, acc: 62.50%, op_acc: 36.72%] [G loss: 0.929886]\n",
      "epoch:14 step:11225[D loss: 0.417859, acc: 63.28%, op_acc: 38.28%] [G loss: 0.943682]\n",
      "epoch:14 step:11226[D loss: 0.436606, acc: 56.25%, op_acc: 33.59%] [G loss: 0.954264]\n",
      "epoch:14 step:11227[D loss: 0.452465, acc: 53.91%, op_acc: 40.62%] [G loss: 0.936685]\n",
      "epoch:14 step:11228[D loss: 0.428298, acc: 64.06%, op_acc: 35.94%] [G loss: 0.862278]\n",
      "epoch:14 step:11229[D loss: 0.381940, acc: 70.31%, op_acc: 41.41%] [G loss: 0.915425]\n",
      "epoch:14 step:11230[D loss: 0.443523, acc: 57.03%, op_acc: 38.28%] [G loss: 0.839947]\n",
      "epoch:14 step:11231[D loss: 0.479307, acc: 51.56%, op_acc: 29.69%] [G loss: 0.873050]\n",
      "epoch:14 step:11232[D loss: 0.421648, acc: 61.72%, op_acc: 36.72%] [G loss: 0.911303]\n",
      "epoch:14 step:11233[D loss: 0.446188, acc: 56.25%, op_acc: 38.28%] [G loss: 0.934633]\n",
      "epoch:14 step:11234[D loss: 0.482171, acc: 46.88%, op_acc: 34.38%] [G loss: 0.870696]\n",
      "epoch:14 step:11235[D loss: 0.457420, acc: 47.66%, op_acc: 39.84%] [G loss: 0.882227]\n",
      "epoch:14 step:11236[D loss: 0.399424, acc: 62.50%, op_acc: 39.84%] [G loss: 0.935428]\n",
      "epoch:14 step:11237[D loss: 0.458718, acc: 54.69%, op_acc: 34.38%] [G loss: 0.962201]\n",
      "epoch:14 step:11238[D loss: 0.426739, acc: 64.06%, op_acc: 37.50%] [G loss: 0.926010]\n",
      "epoch:14 step:11239[D loss: 0.442198, acc: 56.25%, op_acc: 38.28%] [G loss: 0.836243]\n",
      "epoch:14 step:11240[D loss: 0.455033, acc: 58.59%, op_acc: 35.94%] [G loss: 0.960799]\n",
      "epoch:14 step:11241[D loss: 0.453638, acc: 58.59%, op_acc: 33.59%] [G loss: 0.906732]\n",
      "epoch:14 step:11242[D loss: 0.435610, acc: 64.84%, op_acc: 36.72%] [G loss: 0.862120]\n",
      "epoch:14 step:11243[D loss: 0.472723, acc: 55.47%, op_acc: 31.25%] [G loss: 0.864390]\n",
      "epoch:14 step:11244[D loss: 0.424405, acc: 60.16%, op_acc: 32.81%] [G loss: 0.979156]\n",
      "epoch:14 step:11245[D loss: 0.457594, acc: 55.47%, op_acc: 37.50%] [G loss: 0.893488]\n",
      "epoch:14 step:11246[D loss: 0.446453, acc: 65.62%, op_acc: 29.69%] [G loss: 0.817313]\n",
      "epoch:14 step:11247[D loss: 0.458455, acc: 58.59%, op_acc: 37.50%] [G loss: 0.834015]\n",
      "epoch:14 step:11248[D loss: 0.452866, acc: 52.34%, op_acc: 36.72%] [G loss: 0.878098]\n",
      "epoch:14 step:11249[D loss: 0.447233, acc: 55.47%, op_acc: 35.94%] [G loss: 0.917480]\n",
      "epoch:14 step:11250[D loss: 0.461241, acc: 55.47%, op_acc: 32.81%] [G loss: 0.824131]\n",
      "epoch:14 step:11251[D loss: 0.442098, acc: 60.94%, op_acc: 32.03%] [G loss: 0.862056]\n",
      "epoch:14 step:11252[D loss: 0.450761, acc: 59.38%, op_acc: 35.16%] [G loss: 0.913467]\n",
      "epoch:14 step:11253[D loss: 0.414067, acc: 59.38%, op_acc: 35.94%] [G loss: 0.891677]\n",
      "epoch:14 step:11254[D loss: 0.455061, acc: 56.25%, op_acc: 35.16%] [G loss: 0.862190]\n",
      "epoch:14 step:11255[D loss: 0.427824, acc: 61.72%, op_acc: 34.38%] [G loss: 0.839696]\n",
      "epoch:14 step:11256[D loss: 0.413235, acc: 64.84%, op_acc: 38.28%] [G loss: 0.915385]\n",
      "epoch:14 step:11257[D loss: 0.430500, acc: 56.25%, op_acc: 39.84%] [G loss: 0.884693]\n",
      "epoch:14 step:11258[D loss: 0.431521, acc: 58.59%, op_acc: 32.81%] [G loss: 0.872020]\n",
      "epoch:14 step:11259[D loss: 0.399002, acc: 67.19%, op_acc: 36.72%] [G loss: 0.880477]\n",
      "epoch:14 step:11260[D loss: 0.412219, acc: 63.28%, op_acc: 41.41%] [G loss: 0.878382]\n",
      "epoch:14 step:11261[D loss: 0.430051, acc: 64.06%, op_acc: 32.81%] [G loss: 0.925542]\n",
      "epoch:14 step:11262[D loss: 0.435537, acc: 63.28%, op_acc: 34.38%] [G loss: 0.900490]\n",
      "epoch:14 step:11263[D loss: 0.413555, acc: 62.50%, op_acc: 33.59%] [G loss: 0.860944]\n",
      "epoch:14 step:11264[D loss: 0.416866, acc: 60.16%, op_acc: 39.84%] [G loss: 0.810640]\n",
      "epoch:14 step:11265[D loss: 0.430439, acc: 56.25%, op_acc: 38.28%] [G loss: 0.840724]\n",
      "epoch:14 step:11266[D loss: 0.426548, acc: 64.84%, op_acc: 35.16%] [G loss: 0.875236]\n",
      "epoch:14 step:11267[D loss: 0.438759, acc: 64.84%, op_acc: 33.59%] [G loss: 0.928245]\n",
      "epoch:14 step:11268[D loss: 0.446888, acc: 57.03%, op_acc: 32.03%] [G loss: 0.886924]\n",
      "epoch:14 step:11269[D loss: 0.423280, acc: 64.84%, op_acc: 35.16%] [G loss: 0.813587]\n",
      "epoch:14 step:11270[D loss: 0.458444, acc: 56.25%, op_acc: 32.03%] [G loss: 0.911881]\n",
      "epoch:14 step:11271[D loss: 0.469033, acc: 48.44%, op_acc: 32.81%] [G loss: 0.852916]\n",
      "epoch:14 step:11272[D loss: 0.407844, acc: 61.72%, op_acc: 39.84%] [G loss: 0.978456]\n",
      "epoch:14 step:11273[D loss: 0.426153, acc: 58.59%, op_acc: 33.59%] [G loss: 0.895631]\n",
      "epoch:14 step:11274[D loss: 0.436569, acc: 55.47%, op_acc: 36.72%] [G loss: 0.849770]\n",
      "epoch:14 step:11275[D loss: 0.446362, acc: 57.81%, op_acc: 32.81%] [G loss: 0.846067]\n",
      "epoch:14 step:11276[D loss: 0.445763, acc: 57.03%, op_acc: 37.50%] [G loss: 0.838599]\n",
      "epoch:14 step:11277[D loss: 0.440736, acc: 60.16%, op_acc: 34.38%] [G loss: 0.861558]\n",
      "epoch:14 step:11278[D loss: 0.451465, acc: 50.78%, op_acc: 39.06%] [G loss: 0.902919]\n",
      "epoch:14 step:11279[D loss: 0.432602, acc: 57.03%, op_acc: 35.16%] [G loss: 0.933149]\n",
      "epoch:14 step:11280[D loss: 0.410467, acc: 59.38%, op_acc: 41.41%] [G loss: 0.869888]\n",
      "epoch:14 step:11281[D loss: 0.414765, acc: 56.25%, op_acc: 41.41%] [G loss: 0.911185]\n",
      "epoch:14 step:11282[D loss: 0.433280, acc: 62.50%, op_acc: 38.28%] [G loss: 0.841686]\n",
      "epoch:14 step:11283[D loss: 0.413366, acc: 68.75%, op_acc: 39.84%] [G loss: 0.837299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11284[D loss: 0.428699, acc: 64.84%, op_acc: 40.62%] [G loss: 0.882500]\n",
      "epoch:14 step:11285[D loss: 0.442044, acc: 55.47%, op_acc: 36.72%] [G loss: 0.923816]\n",
      "epoch:14 step:11286[D loss: 0.452732, acc: 59.38%, op_acc: 33.59%] [G loss: 0.873649]\n",
      "epoch:14 step:11287[D loss: 0.421340, acc: 57.03%, op_acc: 42.97%] [G loss: 0.860485]\n",
      "epoch:14 step:11288[D loss: 0.435253, acc: 56.25%, op_acc: 35.16%] [G loss: 0.882811]\n",
      "epoch:14 step:11289[D loss: 0.439518, acc: 58.59%, op_acc: 33.59%] [G loss: 0.902754]\n",
      "epoch:14 step:11290[D loss: 0.428704, acc: 62.50%, op_acc: 37.50%] [G loss: 0.796952]\n",
      "epoch:14 step:11291[D loss: 0.426024, acc: 67.97%, op_acc: 35.94%] [G loss: 0.922452]\n",
      "epoch:14 step:11292[D loss: 0.421706, acc: 54.69%, op_acc: 39.84%] [G loss: 0.914498]\n",
      "epoch:14 step:11293[D loss: 0.406656, acc: 67.97%, op_acc: 38.28%] [G loss: 0.937783]\n",
      "epoch:14 step:11294[D loss: 0.459238, acc: 55.47%, op_acc: 35.16%] [G loss: 0.855289]\n",
      "epoch:14 step:11295[D loss: 0.403265, acc: 60.94%, op_acc: 40.62%] [G loss: 0.800531]\n",
      "epoch:14 step:11296[D loss: 0.422385, acc: 57.03%, op_acc: 38.28%] [G loss: 0.838534]\n",
      "epoch:14 step:11297[D loss: 0.417884, acc: 62.50%, op_acc: 39.06%] [G loss: 0.946161]\n",
      "epoch:14 step:11298[D loss: 0.465437, acc: 50.78%, op_acc: 38.28%] [G loss: 0.869138]\n",
      "epoch:14 step:11299[D loss: 0.423143, acc: 60.16%, op_acc: 41.41%] [G loss: 0.887331]\n",
      "epoch:14 step:11300[D loss: 0.445623, acc: 51.56%, op_acc: 35.16%] [G loss: 0.917304]\n",
      "epoch:14 step:11301[D loss: 0.448451, acc: 60.94%, op_acc: 32.81%] [G loss: 0.950723]\n",
      "epoch:14 step:11302[D loss: 0.429672, acc: 68.75%, op_acc: 36.72%] [G loss: 0.957778]\n",
      "epoch:14 step:11303[D loss: 0.433182, acc: 54.69%, op_acc: 42.97%] [G loss: 0.812137]\n",
      "epoch:14 step:11304[D loss: 0.427000, acc: 64.84%, op_acc: 37.50%] [G loss: 0.960349]\n",
      "epoch:14 step:11305[D loss: 0.415331, acc: 60.94%, op_acc: 38.28%] [G loss: 0.901187]\n",
      "epoch:14 step:11306[D loss: 0.424399, acc: 54.69%, op_acc: 35.16%] [G loss: 0.954478]\n",
      "epoch:14 step:11307[D loss: 0.445184, acc: 53.12%, op_acc: 37.50%] [G loss: 0.852795]\n",
      "epoch:14 step:11308[D loss: 0.427546, acc: 57.81%, op_acc: 39.84%] [G loss: 0.900967]\n",
      "epoch:14 step:11309[D loss: 0.433989, acc: 57.03%, op_acc: 37.50%] [G loss: 0.867177]\n",
      "epoch:14 step:11310[D loss: 0.419304, acc: 65.62%, op_acc: 36.72%] [G loss: 0.938201]\n",
      "epoch:14 step:11311[D loss: 0.432241, acc: 62.50%, op_acc: 37.50%] [G loss: 0.964104]\n",
      "epoch:14 step:11312[D loss: 0.416257, acc: 64.06%, op_acc: 35.94%] [G loss: 0.901069]\n",
      "epoch:14 step:11313[D loss: 0.400125, acc: 68.75%, op_acc: 46.09%] [G loss: 0.973994]\n",
      "epoch:14 step:11314[D loss: 0.446220, acc: 57.81%, op_acc: 34.38%] [G loss: 0.902470]\n",
      "epoch:14 step:11315[D loss: 0.423068, acc: 63.28%, op_acc: 40.62%] [G loss: 0.911018]\n",
      "epoch:14 step:11316[D loss: 0.444348, acc: 54.69%, op_acc: 39.06%] [G loss: 0.867641]\n",
      "epoch:14 step:11317[D loss: 0.424525, acc: 60.16%, op_acc: 35.94%] [G loss: 0.834304]\n",
      "epoch:14 step:11318[D loss: 0.417434, acc: 62.50%, op_acc: 38.28%] [G loss: 0.869883]\n",
      "epoch:14 step:11319[D loss: 0.426730, acc: 59.38%, op_acc: 37.50%] [G loss: 0.824837]\n",
      "epoch:14 step:11320[D loss: 0.435461, acc: 53.91%, op_acc: 36.72%] [G loss: 0.856388]\n",
      "epoch:14 step:11321[D loss: 0.420045, acc: 66.41%, op_acc: 34.38%] [G loss: 0.889691]\n",
      "epoch:14 step:11322[D loss: 0.466028, acc: 58.59%, op_acc: 33.59%] [G loss: 0.916658]\n",
      "epoch:14 step:11323[D loss: 0.445001, acc: 53.12%, op_acc: 35.94%] [G loss: 0.919811]\n",
      "epoch:14 step:11324[D loss: 0.382752, acc: 75.78%, op_acc: 41.41%] [G loss: 0.875081]\n",
      "epoch:14 step:11325[D loss: 0.411650, acc: 65.62%, op_acc: 45.31%] [G loss: 0.888282]\n",
      "epoch:14 step:11326[D loss: 0.422154, acc: 54.69%, op_acc: 40.62%] [G loss: 0.865615]\n",
      "epoch:14 step:11327[D loss: 0.437287, acc: 60.94%, op_acc: 37.50%] [G loss: 0.773272]\n",
      "epoch:14 step:11328[D loss: 0.445592, acc: 62.50%, op_acc: 36.72%] [G loss: 0.908380]\n",
      "epoch:14 step:11329[D loss: 0.449627, acc: 60.16%, op_acc: 33.59%] [G loss: 0.889170]\n",
      "epoch:14 step:11330[D loss: 0.415522, acc: 57.03%, op_acc: 44.53%] [G loss: 0.910080]\n",
      "epoch:14 step:11331[D loss: 0.452922, acc: 44.53%, op_acc: 35.16%] [G loss: 0.878528]\n",
      "epoch:14 step:11332[D loss: 0.453606, acc: 59.38%, op_acc: 33.59%] [G loss: 0.886639]\n",
      "epoch:14 step:11333[D loss: 0.423855, acc: 60.94%, op_acc: 36.72%] [G loss: 0.865636]\n",
      "epoch:14 step:11334[D loss: 0.440190, acc: 56.25%, op_acc: 39.06%] [G loss: 0.897205]\n",
      "epoch:14 step:11335[D loss: 0.434248, acc: 57.81%, op_acc: 37.50%] [G loss: 0.880353]\n",
      "epoch:14 step:11336[D loss: 0.443925, acc: 60.94%, op_acc: 29.69%] [G loss: 0.905939]\n",
      "epoch:14 step:11337[D loss: 0.400326, acc: 70.31%, op_acc: 39.06%] [G loss: 0.877179]\n",
      "epoch:14 step:11338[D loss: 0.384635, acc: 67.19%, op_acc: 46.09%] [G loss: 0.967138]\n",
      "epoch:14 step:11339[D loss: 0.449460, acc: 59.38%, op_acc: 33.59%] [G loss: 0.950435]\n",
      "epoch:14 step:11340[D loss: 0.430111, acc: 51.56%, op_acc: 39.84%] [G loss: 0.877062]\n",
      "epoch:14 step:11341[D loss: 0.420470, acc: 59.38%, op_acc: 37.50%] [G loss: 0.888566]\n",
      "epoch:14 step:11342[D loss: 0.420896, acc: 58.59%, op_acc: 41.41%] [G loss: 0.909535]\n",
      "epoch:14 step:11343[D loss: 0.418758, acc: 61.72%, op_acc: 39.84%] [G loss: 0.852175]\n",
      "epoch:14 step:11344[D loss: 0.386028, acc: 67.19%, op_acc: 36.72%] [G loss: 0.871149]\n",
      "epoch:14 step:11345[D loss: 0.446756, acc: 57.81%, op_acc: 36.72%] [G loss: 0.806747]\n",
      "epoch:14 step:11346[D loss: 0.450069, acc: 50.78%, op_acc: 40.62%] [G loss: 0.872873]\n",
      "epoch:14 step:11347[D loss: 0.429863, acc: 66.41%, op_acc: 34.38%] [G loss: 0.925708]\n",
      "epoch:14 step:11348[D loss: 0.426054, acc: 59.38%, op_acc: 35.16%] [G loss: 0.849005]\n",
      "epoch:14 step:11349[D loss: 0.412322, acc: 71.09%, op_acc: 36.72%] [G loss: 0.940023]\n",
      "epoch:14 step:11350[D loss: 0.421126, acc: 63.28%, op_acc: 35.16%] [G loss: 0.941181]\n",
      "epoch:14 step:11351[D loss: 0.435390, acc: 64.06%, op_acc: 36.72%] [G loss: 0.895266]\n",
      "epoch:14 step:11352[D loss: 0.467213, acc: 51.56%, op_acc: 36.72%] [G loss: 0.786296]\n",
      "epoch:14 step:11353[D loss: 0.413537, acc: 61.72%, op_acc: 33.59%] [G loss: 0.874275]\n",
      "epoch:14 step:11354[D loss: 0.449278, acc: 50.78%, op_acc: 34.38%] [G loss: 0.908166]\n",
      "epoch:14 step:11355[D loss: 0.423059, acc: 57.03%, op_acc: 41.41%] [G loss: 0.938383]\n",
      "epoch:14 step:11356[D loss: 0.427412, acc: 55.47%, op_acc: 37.50%] [G loss: 0.911204]\n",
      "epoch:14 step:11357[D loss: 0.441663, acc: 59.38%, op_acc: 33.59%] [G loss: 0.970197]\n",
      "epoch:14 step:11358[D loss: 0.449321, acc: 54.69%, op_acc: 35.16%] [G loss: 0.870896]\n",
      "epoch:14 step:11359[D loss: 0.437878, acc: 54.69%, op_acc: 32.81%] [G loss: 0.822185]\n",
      "epoch:14 step:11360[D loss: 0.452931, acc: 58.59%, op_acc: 36.72%] [G loss: 0.951519]\n",
      "epoch:14 step:11361[D loss: 0.436916, acc: 64.06%, op_acc: 36.72%] [G loss: 0.956054]\n",
      "epoch:14 step:11362[D loss: 0.420889, acc: 57.03%, op_acc: 39.06%] [G loss: 0.866259]\n",
      "epoch:14 step:11363[D loss: 0.431526, acc: 63.28%, op_acc: 34.38%] [G loss: 0.950667]\n",
      "epoch:14 step:11364[D loss: 0.408191, acc: 63.28%, op_acc: 40.62%] [G loss: 0.810598]\n",
      "epoch:14 step:11365[D loss: 0.461920, acc: 54.69%, op_acc: 35.94%] [G loss: 0.906449]\n",
      "epoch:14 step:11366[D loss: 0.420883, acc: 58.59%, op_acc: 36.72%] [G loss: 0.882055]\n",
      "epoch:14 step:11367[D loss: 0.403233, acc: 63.28%, op_acc: 40.62%] [G loss: 0.935554]\n",
      "epoch:14 step:11368[D loss: 0.428533, acc: 59.38%, op_acc: 42.97%] [G loss: 0.865916]\n",
      "epoch:14 step:11369[D loss: 0.452676, acc: 61.72%, op_acc: 35.16%] [G loss: 0.837945]\n",
      "epoch:14 step:11370[D loss: 0.431373, acc: 58.59%, op_acc: 35.94%] [G loss: 0.909542]\n",
      "epoch:14 step:11371[D loss: 0.453391, acc: 53.91%, op_acc: 36.72%] [G loss: 0.891427]\n",
      "epoch:14 step:11372[D loss: 0.433721, acc: 53.91%, op_acc: 39.84%] [G loss: 0.906795]\n",
      "epoch:14 step:11373[D loss: 0.401734, acc: 67.19%, op_acc: 40.62%] [G loss: 0.814540]\n",
      "epoch:14 step:11374[D loss: 0.437936, acc: 58.59%, op_acc: 34.38%] [G loss: 0.874921]\n",
      "epoch:14 step:11375[D loss: 0.424118, acc: 61.72%, op_acc: 33.59%] [G loss: 0.880073]\n",
      "epoch:14 step:11376[D loss: 0.425118, acc: 61.72%, op_acc: 34.38%] [G loss: 0.885278]\n",
      "epoch:14 step:11377[D loss: 0.427310, acc: 62.50%, op_acc: 38.28%] [G loss: 0.844135]\n",
      "epoch:14 step:11378[D loss: 0.403715, acc: 64.06%, op_acc: 36.72%] [G loss: 0.957602]\n",
      "epoch:14 step:11379[D loss: 0.443148, acc: 64.84%, op_acc: 35.16%] [G loss: 0.959827]\n",
      "epoch:14 step:11380[D loss: 0.426245, acc: 61.72%, op_acc: 36.72%] [G loss: 0.918192]\n",
      "epoch:14 step:11381[D loss: 0.443687, acc: 60.16%, op_acc: 35.16%] [G loss: 0.777710]\n",
      "epoch:14 step:11382[D loss: 0.374991, acc: 74.22%, op_acc: 35.94%] [G loss: 0.884935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11383[D loss: 0.426080, acc: 62.50%, op_acc: 35.16%] [G loss: 0.929932]\n",
      "epoch:14 step:11384[D loss: 0.412710, acc: 62.50%, op_acc: 29.69%] [G loss: 0.945543]\n",
      "epoch:14 step:11385[D loss: 0.444405, acc: 52.34%, op_acc: 43.75%] [G loss: 0.914617]\n",
      "epoch:14 step:11386[D loss: 0.423496, acc: 56.25%, op_acc: 37.50%] [G loss: 0.844169]\n",
      "epoch:14 step:11387[D loss: 0.399434, acc: 64.06%, op_acc: 39.84%] [G loss: 0.923001]\n",
      "epoch:14 step:11388[D loss: 0.443006, acc: 58.59%, op_acc: 30.47%] [G loss: 0.806656]\n",
      "epoch:14 step:11389[D loss: 0.464408, acc: 56.25%, op_acc: 33.59%] [G loss: 0.902641]\n",
      "epoch:14 step:11390[D loss: 0.441377, acc: 56.25%, op_acc: 34.38%] [G loss: 0.879667]\n",
      "epoch:14 step:11391[D loss: 0.432521, acc: 59.38%, op_acc: 36.72%] [G loss: 0.839879]\n",
      "epoch:14 step:11392[D loss: 0.393194, acc: 70.31%, op_acc: 44.53%] [G loss: 0.904883]\n",
      "epoch:14 step:11393[D loss: 0.429975, acc: 55.47%, op_acc: 34.38%] [G loss: 0.897012]\n",
      "epoch:14 step:11394[D loss: 0.406081, acc: 67.97%, op_acc: 37.50%] [G loss: 0.821531]\n",
      "epoch:14 step:11395[D loss: 0.483164, acc: 50.00%, op_acc: 30.47%] [G loss: 0.848123]\n",
      "epoch:14 step:11396[D loss: 0.423297, acc: 64.06%, op_acc: 33.59%] [G loss: 0.904699]\n",
      "epoch:14 step:11397[D loss: 0.444483, acc: 55.47%, op_acc: 37.50%] [G loss: 0.875775]\n",
      "epoch:14 step:11398[D loss: 0.436236, acc: 61.72%, op_acc: 34.38%] [G loss: 0.839841]\n",
      "epoch:14 step:11399[D loss: 0.428279, acc: 60.94%, op_acc: 38.28%] [G loss: 0.900318]\n",
      "epoch:14 step:11400[D loss: 0.405639, acc: 67.97%, op_acc: 39.06%] [G loss: 0.944185]\n",
      "epoch:14 step:11401[D loss: 0.412855, acc: 67.97%, op_acc: 37.50%] [G loss: 0.878703]\n",
      "epoch:14 step:11402[D loss: 0.416745, acc: 59.38%, op_acc: 39.06%] [G loss: 0.830802]\n",
      "epoch:14 step:11403[D loss: 0.391831, acc: 64.84%, op_acc: 43.75%] [G loss: 0.893083]\n",
      "epoch:14 step:11404[D loss: 0.409382, acc: 67.19%, op_acc: 37.50%] [G loss: 0.957819]\n",
      "epoch:14 step:11405[D loss: 0.402184, acc: 70.31%, op_acc: 31.25%] [G loss: 0.952244]\n",
      "epoch:14 step:11406[D loss: 0.453749, acc: 57.03%, op_acc: 37.50%] [G loss: 0.853246]\n",
      "epoch:14 step:11407[D loss: 0.420439, acc: 53.91%, op_acc: 42.97%] [G loss: 0.831196]\n",
      "epoch:14 step:11408[D loss: 0.431679, acc: 59.38%, op_acc: 35.16%] [G loss: 0.856550]\n",
      "epoch:14 step:11409[D loss: 0.443644, acc: 52.34%, op_acc: 39.84%] [G loss: 0.869537]\n",
      "epoch:14 step:11410[D loss: 0.473984, acc: 46.09%, op_acc: 34.38%] [G loss: 0.798335]\n",
      "epoch:14 step:11411[D loss: 0.444427, acc: 57.81%, op_acc: 37.50%] [G loss: 0.804258]\n",
      "epoch:14 step:11412[D loss: 0.442310, acc: 53.12%, op_acc: 39.84%] [G loss: 0.829341]\n",
      "epoch:14 step:11413[D loss: 0.436123, acc: 57.03%, op_acc: 38.28%] [G loss: 0.851911]\n",
      "epoch:14 step:11414[D loss: 0.454793, acc: 60.16%, op_acc: 32.03%] [G loss: 0.763017]\n",
      "epoch:14 step:11415[D loss: 0.469516, acc: 58.59%, op_acc: 30.47%] [G loss: 0.806676]\n",
      "epoch:14 step:11416[D loss: 0.449567, acc: 53.91%, op_acc: 35.94%] [G loss: 0.842396]\n",
      "epoch:14 step:11417[D loss: 0.429607, acc: 57.81%, op_acc: 35.16%] [G loss: 0.909149]\n",
      "epoch:14 step:11418[D loss: 0.417318, acc: 60.94%, op_acc: 42.19%] [G loss: 0.870319]\n",
      "epoch:14 step:11419[D loss: 0.412582, acc: 65.62%, op_acc: 38.28%] [G loss: 0.850654]\n",
      "epoch:14 step:11420[D loss: 0.428097, acc: 57.03%, op_acc: 35.16%] [G loss: 1.001332]\n",
      "epoch:14 step:11421[D loss: 0.444052, acc: 60.94%, op_acc: 32.81%] [G loss: 0.886679]\n",
      "epoch:14 step:11422[D loss: 0.428550, acc: 58.59%, op_acc: 38.28%] [G loss: 0.955725]\n",
      "epoch:14 step:11423[D loss: 0.442202, acc: 52.34%, op_acc: 44.53%] [G loss: 0.897123]\n",
      "epoch:14 step:11424[D loss: 0.413788, acc: 58.59%, op_acc: 41.41%] [G loss: 0.949454]\n",
      "epoch:14 step:11425[D loss: 0.448598, acc: 57.03%, op_acc: 34.38%] [G loss: 0.891600]\n",
      "epoch:14 step:11426[D loss: 0.433549, acc: 60.16%, op_acc: 40.62%] [G loss: 0.861026]\n",
      "epoch:14 step:11427[D loss: 0.413064, acc: 68.75%, op_acc: 36.72%] [G loss: 0.908368]\n",
      "epoch:14 step:11428[D loss: 0.377214, acc: 76.56%, op_acc: 38.28%] [G loss: 0.907024]\n",
      "epoch:14 step:11429[D loss: 0.430317, acc: 59.38%, op_acc: 39.06%] [G loss: 0.840830]\n",
      "epoch:14 step:11430[D loss: 0.445804, acc: 58.59%, op_acc: 36.72%] [G loss: 0.848862]\n",
      "epoch:14 step:11431[D loss: 0.405338, acc: 59.38%, op_acc: 40.62%] [G loss: 0.956564]\n",
      "epoch:14 step:11432[D loss: 0.451410, acc: 57.03%, op_acc: 35.16%] [G loss: 0.981408]\n",
      "epoch:14 step:11433[D loss: 0.448102, acc: 56.25%, op_acc: 34.38%] [G loss: 0.923001]\n",
      "epoch:14 step:11434[D loss: 0.409615, acc: 61.72%, op_acc: 40.62%] [G loss: 0.943912]\n",
      "epoch:14 step:11435[D loss: 0.449708, acc: 58.59%, op_acc: 37.50%] [G loss: 0.924214]\n",
      "epoch:14 step:11436[D loss: 0.425760, acc: 60.94%, op_acc: 39.84%] [G loss: 0.975881]\n",
      "epoch:14 step:11437[D loss: 0.406605, acc: 67.97%, op_acc: 29.69%] [G loss: 0.912267]\n",
      "epoch:14 step:11438[D loss: 0.421561, acc: 67.19%, op_acc: 39.06%] [G loss: 0.968333]\n",
      "epoch:14 step:11439[D loss: 0.442906, acc: 63.28%, op_acc: 38.28%] [G loss: 0.897797]\n",
      "epoch:14 step:11440[D loss: 0.453218, acc: 54.69%, op_acc: 38.28%] [G loss: 0.891880]\n",
      "epoch:14 step:11441[D loss: 0.441811, acc: 53.12%, op_acc: 41.41%] [G loss: 0.887522]\n",
      "epoch:14 step:11442[D loss: 0.412354, acc: 68.75%, op_acc: 35.16%] [G loss: 0.893142]\n",
      "epoch:14 step:11443[D loss: 0.456470, acc: 57.81%, op_acc: 30.47%] [G loss: 0.836037]\n",
      "epoch:14 step:11444[D loss: 0.433421, acc: 63.28%, op_acc: 35.94%] [G loss: 0.941492]\n",
      "epoch:14 step:11445[D loss: 0.428741, acc: 61.72%, op_acc: 36.72%] [G loss: 0.830840]\n",
      "epoch:14 step:11446[D loss: 0.464092, acc: 51.56%, op_acc: 34.38%] [G loss: 0.826495]\n",
      "epoch:14 step:11447[D loss: 0.478807, acc: 55.47%, op_acc: 25.78%] [G loss: 0.915516]\n",
      "epoch:14 step:11448[D loss: 0.474362, acc: 55.47%, op_acc: 27.34%] [G loss: 0.852205]\n",
      "epoch:14 step:11449[D loss: 0.443127, acc: 61.72%, op_acc: 35.16%] [G loss: 0.884088]\n",
      "epoch:14 step:11450[D loss: 0.450399, acc: 53.12%, op_acc: 37.50%] [G loss: 0.854805]\n",
      "epoch:14 step:11451[D loss: 0.492981, acc: 46.09%, op_acc: 25.78%] [G loss: 0.938989]\n",
      "epoch:14 step:11452[D loss: 0.398182, acc: 64.84%, op_acc: 39.06%] [G loss: 0.949205]\n",
      "epoch:14 step:11453[D loss: 0.416838, acc: 65.62%, op_acc: 39.06%] [G loss: 0.888069]\n",
      "epoch:14 step:11454[D loss: 0.469800, acc: 49.22%, op_acc: 35.16%] [G loss: 0.853888]\n",
      "epoch:14 step:11455[D loss: 0.481780, acc: 52.34%, op_acc: 30.47%] [G loss: 0.848830]\n",
      "epoch:14 step:11456[D loss: 0.472629, acc: 49.22%, op_acc: 33.59%] [G loss: 0.875531]\n",
      "epoch:14 step:11457[D loss: 0.442844, acc: 58.59%, op_acc: 32.81%] [G loss: 0.885100]\n",
      "epoch:14 step:11458[D loss: 0.452068, acc: 58.59%, op_acc: 33.59%] [G loss: 0.880047]\n",
      "epoch:14 step:11459[D loss: 0.402905, acc: 69.53%, op_acc: 38.28%] [G loss: 0.973584]\n",
      "epoch:14 step:11460[D loss: 0.465612, acc: 53.91%, op_acc: 34.38%] [G loss: 0.987403]\n",
      "epoch:14 step:11461[D loss: 0.442413, acc: 53.12%, op_acc: 35.94%] [G loss: 0.958823]\n",
      "epoch:14 step:11462[D loss: 0.442008, acc: 58.59%, op_acc: 36.72%] [G loss: 0.883470]\n",
      "epoch:14 step:11463[D loss: 0.429511, acc: 60.94%, op_acc: 38.28%] [G loss: 0.947877]\n",
      "epoch:14 step:11464[D loss: 0.449062, acc: 55.47%, op_acc: 30.47%] [G loss: 0.867849]\n",
      "epoch:14 step:11465[D loss: 0.424440, acc: 64.06%, op_acc: 31.25%] [G loss: 0.881201]\n",
      "epoch:14 step:11466[D loss: 0.465326, acc: 53.91%, op_acc: 34.38%] [G loss: 0.957135]\n",
      "epoch:14 step:11467[D loss: 0.411572, acc: 63.28%, op_acc: 36.72%] [G loss: 0.913800]\n",
      "epoch:14 step:11468[D loss: 0.445631, acc: 53.91%, op_acc: 35.16%] [G loss: 0.848976]\n",
      "epoch:14 step:11469[D loss: 0.415032, acc: 64.06%, op_acc: 42.19%] [G loss: 0.844225]\n",
      "epoch:14 step:11470[D loss: 0.394967, acc: 60.16%, op_acc: 40.62%] [G loss: 0.923898]\n",
      "epoch:14 step:11471[D loss: 0.460596, acc: 53.12%, op_acc: 31.25%] [G loss: 0.947306]\n",
      "epoch:14 step:11472[D loss: 0.408946, acc: 63.28%, op_acc: 39.06%] [G loss: 0.973913]\n",
      "epoch:14 step:11473[D loss: 0.446062, acc: 62.50%, op_acc: 39.84%] [G loss: 0.928121]\n",
      "epoch:14 step:11474[D loss: 0.394812, acc: 71.88%, op_acc: 42.97%] [G loss: 0.874413]\n",
      "epoch:14 step:11475[D loss: 0.390265, acc: 69.53%, op_acc: 39.06%] [G loss: 0.913728]\n",
      "epoch:14 step:11476[D loss: 0.459039, acc: 57.03%, op_acc: 32.03%] [G loss: 0.825670]\n",
      "epoch:14 step:11477[D loss: 0.432220, acc: 60.94%, op_acc: 33.59%] [G loss: 0.905131]\n",
      "epoch:14 step:11478[D loss: 0.424398, acc: 62.50%, op_acc: 33.59%] [G loss: 0.894772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11479[D loss: 0.410487, acc: 63.28%, op_acc: 32.81%] [G loss: 0.923175]\n",
      "epoch:14 step:11480[D loss: 0.442561, acc: 53.91%, op_acc: 33.59%] [G loss: 0.970620]\n",
      "epoch:14 step:11481[D loss: 0.421149, acc: 68.75%, op_acc: 33.59%] [G loss: 0.877232]\n",
      "epoch:14 step:11482[D loss: 0.455526, acc: 58.59%, op_acc: 28.91%] [G loss: 0.978746]\n",
      "epoch:14 step:11483[D loss: 0.451390, acc: 50.00%, op_acc: 40.62%] [G loss: 0.806595]\n",
      "epoch:14 step:11484[D loss: 0.466827, acc: 53.12%, op_acc: 32.03%] [G loss: 0.841152]\n",
      "epoch:14 step:11485[D loss: 0.419876, acc: 60.94%, op_acc: 39.06%] [G loss: 0.853855]\n",
      "epoch:14 step:11486[D loss: 0.483012, acc: 51.56%, op_acc: 35.16%] [G loss: 0.853569]\n",
      "epoch:14 step:11487[D loss: 0.444136, acc: 58.59%, op_acc: 33.59%] [G loss: 0.845928]\n",
      "epoch:14 step:11488[D loss: 0.474102, acc: 50.78%, op_acc: 34.38%] [G loss: 0.955477]\n",
      "epoch:14 step:11489[D loss: 0.414686, acc: 62.50%, op_acc: 40.62%] [G loss: 0.845255]\n",
      "epoch:14 step:11490[D loss: 0.426790, acc: 60.94%, op_acc: 36.72%] [G loss: 0.898469]\n",
      "epoch:14 step:11491[D loss: 0.442120, acc: 60.94%, op_acc: 34.38%] [G loss: 0.891096]\n",
      "epoch:14 step:11492[D loss: 0.436531, acc: 53.91%, op_acc: 41.41%] [G loss: 0.965765]\n",
      "epoch:14 step:11493[D loss: 0.407586, acc: 65.62%, op_acc: 39.84%] [G loss: 0.895294]\n",
      "epoch:14 step:11494[D loss: 0.418708, acc: 66.41%, op_acc: 37.50%] [G loss: 0.921707]\n",
      "epoch:14 step:11495[D loss: 0.438919, acc: 55.47%, op_acc: 39.84%] [G loss: 0.856018]\n",
      "epoch:14 step:11496[D loss: 0.451145, acc: 61.72%, op_acc: 28.91%] [G loss: 0.981234]\n",
      "epoch:14 step:11497[D loss: 0.445400, acc: 63.28%, op_acc: 32.03%] [G loss: 0.944461]\n",
      "epoch:14 step:11498[D loss: 0.433652, acc: 55.47%, op_acc: 40.62%] [G loss: 0.891039]\n",
      "epoch:14 step:11499[D loss: 0.443270, acc: 54.69%, op_acc: 38.28%] [G loss: 0.901535]\n",
      "epoch:14 step:11500[D loss: 0.399930, acc: 63.28%, op_acc: 39.06%] [G loss: 0.877334]\n",
      "epoch:14 step:11501[D loss: 0.404928, acc: 64.06%, op_acc: 42.97%] [G loss: 0.934147]\n",
      "epoch:14 step:11502[D loss: 0.415631, acc: 62.50%, op_acc: 41.41%] [G loss: 0.907401]\n",
      "epoch:14 step:11503[D loss: 0.428499, acc: 59.38%, op_acc: 44.53%] [G loss: 0.815266]\n",
      "epoch:14 step:11504[D loss: 0.444322, acc: 55.47%, op_acc: 37.50%] [G loss: 0.859870]\n",
      "epoch:14 step:11505[D loss: 0.475463, acc: 41.41%, op_acc: 36.72%] [G loss: 0.859169]\n",
      "epoch:14 step:11506[D loss: 0.443722, acc: 55.47%, op_acc: 37.50%] [G loss: 0.844822]\n",
      "epoch:14 step:11507[D loss: 0.442221, acc: 59.38%, op_acc: 35.94%] [G loss: 0.882252]\n",
      "epoch:14 step:11508[D loss: 0.462940, acc: 55.47%, op_acc: 38.28%] [G loss: 0.874757]\n",
      "epoch:14 step:11509[D loss: 0.454323, acc: 49.22%, op_acc: 38.28%] [G loss: 0.837297]\n",
      "epoch:14 step:11510[D loss: 0.435038, acc: 60.94%, op_acc: 37.50%] [G loss: 0.890395]\n",
      "epoch:14 step:11511[D loss: 0.424403, acc: 68.75%, op_acc: 35.16%] [G loss: 0.942304]\n",
      "epoch:14 step:11512[D loss: 0.465481, acc: 55.47%, op_acc: 32.81%] [G loss: 0.928802]\n",
      "epoch:14 step:11513[D loss: 0.429784, acc: 56.25%, op_acc: 38.28%] [G loss: 0.895795]\n",
      "epoch:14 step:11514[D loss: 0.434958, acc: 54.69%, op_acc: 41.41%] [G loss: 0.938684]\n",
      "epoch:14 step:11515[D loss: 0.415464, acc: 63.28%, op_acc: 35.16%] [G loss: 0.927588]\n",
      "epoch:14 step:11516[D loss: 0.431191, acc: 60.94%, op_acc: 38.28%] [G loss: 0.906565]\n",
      "epoch:14 step:11517[D loss: 0.409038, acc: 69.53%, op_acc: 38.28%] [G loss: 0.959002]\n",
      "epoch:14 step:11518[D loss: 0.448451, acc: 55.47%, op_acc: 35.94%] [G loss: 0.902911]\n",
      "epoch:14 step:11519[D loss: 0.431505, acc: 56.25%, op_acc: 33.59%] [G loss: 0.902466]\n",
      "epoch:14 step:11520[D loss: 0.413629, acc: 69.53%, op_acc: 37.50%] [G loss: 0.852960]\n",
      "epoch:14 step:11521[D loss: 0.418435, acc: 64.06%, op_acc: 31.25%] [G loss: 0.938096]\n",
      "epoch:14 step:11522[D loss: 0.416566, acc: 57.81%, op_acc: 40.62%] [G loss: 0.872055]\n",
      "epoch:14 step:11523[D loss: 0.437604, acc: 56.25%, op_acc: 34.38%] [G loss: 0.900823]\n",
      "epoch:14 step:11524[D loss: 0.423096, acc: 60.94%, op_acc: 36.72%] [G loss: 0.943847]\n",
      "epoch:14 step:11525[D loss: 0.435395, acc: 63.28%, op_acc: 38.28%] [G loss: 0.884080]\n",
      "epoch:14 step:11526[D loss: 0.460437, acc: 53.12%, op_acc: 35.94%] [G loss: 0.855234]\n",
      "epoch:14 step:11527[D loss: 0.425945, acc: 60.94%, op_acc: 39.06%] [G loss: 0.877799]\n",
      "epoch:14 step:11528[D loss: 0.433738, acc: 55.47%, op_acc: 37.50%] [G loss: 0.878803]\n",
      "epoch:14 step:11529[D loss: 0.457830, acc: 56.25%, op_acc: 30.47%] [G loss: 0.924458]\n",
      "epoch:14 step:11530[D loss: 0.432262, acc: 60.94%, op_acc: 38.28%] [G loss: 0.850270]\n",
      "epoch:14 step:11531[D loss: 0.428682, acc: 57.03%, op_acc: 38.28%] [G loss: 0.879585]\n",
      "epoch:14 step:11532[D loss: 0.419847, acc: 61.72%, op_acc: 37.50%] [G loss: 0.908844]\n",
      "epoch:14 step:11533[D loss: 0.442214, acc: 56.25%, op_acc: 43.75%] [G loss: 0.905568]\n",
      "epoch:14 step:11534[D loss: 0.439494, acc: 64.06%, op_acc: 38.28%] [G loss: 0.926505]\n",
      "epoch:14 step:11535[D loss: 0.456521, acc: 58.59%, op_acc: 35.94%] [G loss: 0.904187]\n",
      "epoch:14 step:11536[D loss: 0.449701, acc: 53.12%, op_acc: 38.28%] [G loss: 0.875547]\n",
      "epoch:14 step:11537[D loss: 0.434417, acc: 55.47%, op_acc: 37.50%] [G loss: 0.910304]\n",
      "epoch:14 step:11538[D loss: 0.495169, acc: 57.81%, op_acc: 25.78%] [G loss: 0.841129]\n",
      "epoch:14 step:11539[D loss: 0.416465, acc: 64.06%, op_acc: 37.50%] [G loss: 0.899344]\n",
      "epoch:14 step:11540[D loss: 0.448433, acc: 53.91%, op_acc: 37.50%] [G loss: 0.829705]\n",
      "epoch:14 step:11541[D loss: 0.436071, acc: 57.81%, op_acc: 42.19%] [G loss: 0.888354]\n",
      "epoch:14 step:11542[D loss: 0.391591, acc: 67.19%, op_acc: 43.75%] [G loss: 0.984271]\n",
      "epoch:14 step:11543[D loss: 0.436254, acc: 58.59%, op_acc: 36.72%] [G loss: 0.865005]\n",
      "epoch:14 step:11544[D loss: 0.445749, acc: 54.69%, op_acc: 36.72%] [G loss: 0.877982]\n",
      "epoch:14 step:11545[D loss: 0.441719, acc: 60.16%, op_acc: 35.94%] [G loss: 0.869367]\n",
      "epoch:14 step:11546[D loss: 0.415486, acc: 64.84%, op_acc: 37.50%] [G loss: 0.947796]\n",
      "epoch:14 step:11547[D loss: 0.464964, acc: 52.34%, op_acc: 32.81%] [G loss: 0.916318]\n",
      "epoch:14 step:11548[D loss: 0.424467, acc: 60.16%, op_acc: 40.62%] [G loss: 0.871919]\n",
      "epoch:14 step:11549[D loss: 0.419194, acc: 60.16%, op_acc: 39.06%] [G loss: 0.899910]\n",
      "epoch:14 step:11550[D loss: 0.478633, acc: 53.91%, op_acc: 30.47%] [G loss: 0.813568]\n",
      "epoch:14 step:11551[D loss: 0.421886, acc: 56.25%, op_acc: 36.72%] [G loss: 0.903640]\n",
      "epoch:14 step:11552[D loss: 0.396360, acc: 63.28%, op_acc: 42.19%] [G loss: 0.940852]\n",
      "epoch:14 step:11553[D loss: 0.463273, acc: 53.12%, op_acc: 34.38%] [G loss: 0.926468]\n",
      "epoch:14 step:11554[D loss: 0.455251, acc: 57.03%, op_acc: 33.59%] [G loss: 0.797982]\n",
      "epoch:14 step:11555[D loss: 0.434788, acc: 58.59%, op_acc: 37.50%] [G loss: 0.912091]\n",
      "epoch:14 step:11556[D loss: 0.488859, acc: 49.22%, op_acc: 28.91%] [G loss: 0.815514]\n",
      "epoch:14 step:11557[D loss: 0.401379, acc: 62.50%, op_acc: 44.53%] [G loss: 0.940242]\n",
      "epoch:14 step:11558[D loss: 0.436656, acc: 58.59%, op_acc: 38.28%] [G loss: 0.827713]\n",
      "epoch:14 step:11559[D loss: 0.424257, acc: 63.28%, op_acc: 46.09%] [G loss: 0.904809]\n",
      "epoch:14 step:11560[D loss: 0.438532, acc: 57.03%, op_acc: 39.06%] [G loss: 0.892564]\n",
      "epoch:14 step:11561[D loss: 0.449748, acc: 46.09%, op_acc: 39.84%] [G loss: 0.887445]\n",
      "epoch:14 step:11562[D loss: 0.459835, acc: 53.91%, op_acc: 33.59%] [G loss: 0.862787]\n",
      "epoch:14 step:11563[D loss: 0.462370, acc: 54.69%, op_acc: 30.47%] [G loss: 0.878209]\n",
      "epoch:14 step:11564[D loss: 0.418879, acc: 60.16%, op_acc: 40.62%] [G loss: 0.932875]\n",
      "epoch:14 step:11565[D loss: 0.476478, acc: 45.31%, op_acc: 33.59%] [G loss: 0.832776]\n",
      "epoch:14 step:11566[D loss: 0.420364, acc: 65.62%, op_acc: 31.25%] [G loss: 0.845756]\n",
      "epoch:14 step:11567[D loss: 0.437884, acc: 52.34%, op_acc: 32.03%] [G loss: 0.897464]\n",
      "epoch:14 step:11568[D loss: 0.414043, acc: 60.16%, op_acc: 44.53%] [G loss: 0.874959]\n",
      "epoch:14 step:11569[D loss: 0.437164, acc: 62.50%, op_acc: 37.50%] [G loss: 0.851907]\n",
      "epoch:14 step:11570[D loss: 0.411364, acc: 65.62%, op_acc: 39.06%] [G loss: 0.871834]\n",
      "epoch:14 step:11571[D loss: 0.436226, acc: 59.38%, op_acc: 28.91%] [G loss: 0.888328]\n",
      "epoch:14 step:11572[D loss: 0.449692, acc: 60.94%, op_acc: 32.81%] [G loss: 0.874898]\n",
      "epoch:14 step:11573[D loss: 0.456556, acc: 53.12%, op_acc: 36.72%] [G loss: 0.861169]\n",
      "epoch:14 step:11574[D loss: 0.432619, acc: 60.16%, op_acc: 42.19%] [G loss: 0.904068]\n",
      "epoch:14 step:11575[D loss: 0.414590, acc: 61.72%, op_acc: 32.03%] [G loss: 0.924425]\n",
      "epoch:14 step:11576[D loss: 0.417704, acc: 54.69%, op_acc: 36.72%] [G loss: 0.862946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11577[D loss: 0.490939, acc: 50.78%, op_acc: 32.81%] [G loss: 0.867633]\n",
      "epoch:14 step:11578[D loss: 0.380285, acc: 68.75%, op_acc: 42.97%] [G loss: 0.881183]\n",
      "epoch:14 step:11579[D loss: 0.418006, acc: 57.03%, op_acc: 37.50%] [G loss: 0.905126]\n",
      "epoch:14 step:11580[D loss: 0.448941, acc: 61.72%, op_acc: 33.59%] [G loss: 0.790133]\n",
      "epoch:14 step:11581[D loss: 0.401065, acc: 65.62%, op_acc: 39.06%] [G loss: 0.882547]\n",
      "epoch:14 step:11582[D loss: 0.438122, acc: 60.94%, op_acc: 29.69%] [G loss: 0.857720]\n",
      "epoch:14 step:11583[D loss: 0.419450, acc: 64.06%, op_acc: 32.03%] [G loss: 0.892239]\n",
      "epoch:14 step:11584[D loss: 0.430831, acc: 64.84%, op_acc: 34.38%] [G loss: 0.936056]\n",
      "epoch:14 step:11585[D loss: 0.428880, acc: 57.03%, op_acc: 36.72%] [G loss: 0.900382]\n",
      "epoch:14 step:11586[D loss: 0.416266, acc: 60.94%, op_acc: 39.06%] [G loss: 0.850552]\n",
      "epoch:14 step:11587[D loss: 0.412457, acc: 60.16%, op_acc: 37.50%] [G loss: 0.905387]\n",
      "epoch:14 step:11588[D loss: 0.415517, acc: 64.84%, op_acc: 39.84%] [G loss: 0.830694]\n",
      "epoch:14 step:11589[D loss: 0.414819, acc: 64.84%, op_acc: 39.84%] [G loss: 0.881341]\n",
      "epoch:14 step:11590[D loss: 0.441928, acc: 57.81%, op_acc: 36.72%] [G loss: 0.856558]\n",
      "epoch:14 step:11591[D loss: 0.437407, acc: 53.12%, op_acc: 33.59%] [G loss: 0.898032]\n",
      "epoch:14 step:11592[D loss: 0.437784, acc: 58.59%, op_acc: 38.28%] [G loss: 0.859979]\n",
      "epoch:14 step:11593[D loss: 0.438922, acc: 58.59%, op_acc: 35.94%] [G loss: 0.824326]\n",
      "epoch:14 step:11594[D loss: 0.442643, acc: 56.25%, op_acc: 40.62%] [G loss: 0.890230]\n",
      "epoch:14 step:11595[D loss: 0.406163, acc: 60.94%, op_acc: 38.28%] [G loss: 0.921776]\n",
      "epoch:14 step:11596[D loss: 0.423088, acc: 58.59%, op_acc: 38.28%] [G loss: 0.881527]\n",
      "epoch:14 step:11597[D loss: 0.397692, acc: 63.28%, op_acc: 42.97%] [G loss: 0.903880]\n",
      "epoch:14 step:11598[D loss: 0.431216, acc: 60.94%, op_acc: 43.75%] [G loss: 0.860444]\n",
      "epoch:14 step:11599[D loss: 0.427843, acc: 64.06%, op_acc: 35.94%] [G loss: 0.843078]\n",
      "epoch:14 step:11600[D loss: 0.412458, acc: 70.31%, op_acc: 33.59%] [G loss: 0.909668]\n",
      "epoch:14 step:11601[D loss: 0.429695, acc: 60.16%, op_acc: 39.84%] [G loss: 0.920853]\n",
      "epoch:14 step:11602[D loss: 0.436520, acc: 57.81%, op_acc: 33.59%] [G loss: 0.933264]\n",
      "epoch:14 step:11603[D loss: 0.446551, acc: 57.81%, op_acc: 33.59%] [G loss: 0.935046]\n",
      "epoch:14 step:11604[D loss: 0.441551, acc: 54.69%, op_acc: 35.16%] [G loss: 0.998553]\n",
      "epoch:14 step:11605[D loss: 0.433976, acc: 62.50%, op_acc: 34.38%] [G loss: 0.854370]\n",
      "epoch:14 step:11606[D loss: 0.450742, acc: 56.25%, op_acc: 33.59%] [G loss: 0.869602]\n",
      "epoch:14 step:11607[D loss: 0.428375, acc: 57.03%, op_acc: 41.41%] [G loss: 0.909433]\n",
      "epoch:14 step:11608[D loss: 0.436059, acc: 51.56%, op_acc: 40.62%] [G loss: 0.836663]\n",
      "epoch:14 step:11609[D loss: 0.427061, acc: 63.28%, op_acc: 36.72%] [G loss: 0.899311]\n",
      "epoch:14 step:11610[D loss: 0.463090, acc: 50.78%, op_acc: 32.81%] [G loss: 0.928734]\n",
      "epoch:14 step:11611[D loss: 0.463634, acc: 57.81%, op_acc: 32.03%] [G loss: 0.830169]\n",
      "epoch:14 step:11612[D loss: 0.457091, acc: 50.78%, op_acc: 38.28%] [G loss: 0.889141]\n",
      "epoch:14 step:11613[D loss: 0.376661, acc: 71.88%, op_acc: 46.88%] [G loss: 0.926400]\n",
      "epoch:14 step:11614[D loss: 0.429472, acc: 63.28%, op_acc: 34.38%] [G loss: 0.809951]\n",
      "epoch:14 step:11615[D loss: 0.432821, acc: 63.28%, op_acc: 32.03%] [G loss: 0.893436]\n",
      "epoch:14 step:11616[D loss: 0.421813, acc: 60.16%, op_acc: 38.28%] [G loss: 0.935461]\n",
      "epoch:14 step:11617[D loss: 0.465588, acc: 50.78%, op_acc: 32.81%] [G loss: 0.813221]\n",
      "epoch:14 step:11618[D loss: 0.461853, acc: 57.81%, op_acc: 36.72%] [G loss: 0.880072]\n",
      "epoch:14 step:11619[D loss: 0.461660, acc: 57.03%, op_acc: 31.25%] [G loss: 0.934288]\n",
      "epoch:14 step:11620[D loss: 0.436654, acc: 60.94%, op_acc: 33.59%] [G loss: 0.892921]\n",
      "epoch:14 step:11621[D loss: 0.434567, acc: 57.03%, op_acc: 36.72%] [G loss: 0.858563]\n",
      "epoch:14 step:11622[D loss: 0.415605, acc: 61.72%, op_acc: 37.50%] [G loss: 0.925857]\n",
      "epoch:14 step:11623[D loss: 0.449048, acc: 50.78%, op_acc: 32.81%] [G loss: 0.904354]\n",
      "epoch:14 step:11624[D loss: 0.439124, acc: 60.94%, op_acc: 29.69%] [G loss: 0.931095]\n",
      "epoch:14 step:11625[D loss: 0.460986, acc: 51.56%, op_acc: 38.28%] [G loss: 0.884559]\n",
      "epoch:14 step:11626[D loss: 0.475484, acc: 43.75%, op_acc: 33.59%] [G loss: 0.871853]\n",
      "epoch:14 step:11627[D loss: 0.438833, acc: 59.38%, op_acc: 32.81%] [G loss: 0.938507]\n",
      "epoch:14 step:11628[D loss: 0.435521, acc: 64.06%, op_acc: 34.38%] [G loss: 0.925884]\n",
      "epoch:14 step:11629[D loss: 0.455839, acc: 57.81%, op_acc: 34.38%] [G loss: 0.854617]\n",
      "epoch:14 step:11630[D loss: 0.459315, acc: 55.47%, op_acc: 36.72%] [G loss: 0.904930]\n",
      "epoch:14 step:11631[D loss: 0.420280, acc: 64.84%, op_acc: 35.94%] [G loss: 0.930709]\n",
      "epoch:14 step:11632[D loss: 0.453365, acc: 59.38%, op_acc: 30.47%] [G loss: 0.928366]\n",
      "epoch:14 step:11633[D loss: 0.413737, acc: 60.94%, op_acc: 39.06%] [G loss: 0.885182]\n",
      "epoch:14 step:11634[D loss: 0.449779, acc: 53.91%, op_acc: 37.50%] [G loss: 0.878844]\n",
      "epoch:14 step:11635[D loss: 0.462167, acc: 53.91%, op_acc: 34.38%] [G loss: 0.867299]\n",
      "epoch:14 step:11636[D loss: 0.438746, acc: 56.25%, op_acc: 40.62%] [G loss: 0.807452]\n",
      "epoch:14 step:11637[D loss: 0.441935, acc: 54.69%, op_acc: 33.59%] [G loss: 0.894831]\n",
      "epoch:14 step:11638[D loss: 0.410367, acc: 57.03%, op_acc: 44.53%] [G loss: 0.853040]\n",
      "epoch:14 step:11639[D loss: 0.425177, acc: 59.38%, op_acc: 36.72%] [G loss: 0.843035]\n",
      "epoch:14 step:11640[D loss: 0.411517, acc: 67.97%, op_acc: 41.41%] [G loss: 0.822340]\n",
      "epoch:14 step:11641[D loss: 0.453651, acc: 57.03%, op_acc: 32.03%] [G loss: 0.890921]\n",
      "epoch:14 step:11642[D loss: 0.439185, acc: 55.47%, op_acc: 38.28%] [G loss: 0.807451]\n",
      "epoch:14 step:11643[D loss: 0.431985, acc: 59.38%, op_acc: 35.16%] [G loss: 0.912044]\n",
      "epoch:14 step:11644[D loss: 0.423849, acc: 64.06%, op_acc: 41.41%] [G loss: 0.922652]\n",
      "epoch:14 step:11645[D loss: 0.403788, acc: 66.41%, op_acc: 35.94%] [G loss: 0.806818]\n",
      "epoch:14 step:11646[D loss: 0.406575, acc: 64.06%, op_acc: 39.84%] [G loss: 0.916336]\n",
      "epoch:14 step:11647[D loss: 0.412859, acc: 62.50%, op_acc: 44.53%] [G loss: 0.918036]\n",
      "epoch:14 step:11648[D loss: 0.441507, acc: 58.59%, op_acc: 33.59%] [G loss: 0.967939]\n",
      "epoch:14 step:11649[D loss: 0.432168, acc: 54.69%, op_acc: 39.06%] [G loss: 0.898193]\n",
      "epoch:14 step:11650[D loss: 0.451669, acc: 53.12%, op_acc: 31.25%] [G loss: 0.881234]\n",
      "epoch:14 step:11651[D loss: 0.392053, acc: 69.53%, op_acc: 40.62%] [G loss: 0.906414]\n",
      "epoch:14 step:11652[D loss: 0.423775, acc: 61.72%, op_acc: 35.94%] [G loss: 0.976406]\n",
      "epoch:14 step:11653[D loss: 0.404187, acc: 64.06%, op_acc: 43.75%] [G loss: 0.956966]\n",
      "epoch:14 step:11654[D loss: 0.436454, acc: 60.16%, op_acc: 33.59%] [G loss: 0.832543]\n",
      "epoch:14 step:11655[D loss: 0.432183, acc: 57.81%, op_acc: 41.41%] [G loss: 0.867859]\n",
      "epoch:14 step:11656[D loss: 0.417424, acc: 61.72%, op_acc: 34.38%] [G loss: 0.860296]\n",
      "epoch:14 step:11657[D loss: 0.460275, acc: 48.44%, op_acc: 32.81%] [G loss: 0.760113]\n",
      "epoch:14 step:11658[D loss: 0.458512, acc: 58.59%, op_acc: 34.38%] [G loss: 0.902216]\n",
      "epoch:14 step:11659[D loss: 0.426356, acc: 63.28%, op_acc: 35.16%] [G loss: 0.934354]\n",
      "epoch:14 step:11660[D loss: 0.426343, acc: 60.94%, op_acc: 39.06%] [G loss: 0.862653]\n",
      "epoch:14 step:11661[D loss: 0.457970, acc: 53.12%, op_acc: 33.59%] [G loss: 0.967305]\n",
      "epoch:14 step:11662[D loss: 0.466504, acc: 57.03%, op_acc: 31.25%] [G loss: 0.908143]\n",
      "epoch:14 step:11663[D loss: 0.449325, acc: 52.34%, op_acc: 36.72%] [G loss: 0.897577]\n",
      "epoch:14 step:11664[D loss: 0.421221, acc: 66.41%, op_acc: 35.16%] [G loss: 0.830146]\n",
      "epoch:14 step:11665[D loss: 0.414802, acc: 64.06%, op_acc: 39.84%] [G loss: 0.899696]\n",
      "epoch:14 step:11666[D loss: 0.428850, acc: 60.16%, op_acc: 36.72%] [G loss: 0.847527]\n",
      "epoch:14 step:11667[D loss: 0.442705, acc: 54.69%, op_acc: 35.16%] [G loss: 0.891923]\n",
      "epoch:14 step:11668[D loss: 0.456000, acc: 52.34%, op_acc: 35.16%] [G loss: 0.850970]\n",
      "epoch:14 step:11669[D loss: 0.427194, acc: 61.72%, op_acc: 39.06%] [G loss: 0.926194]\n",
      "epoch:14 step:11670[D loss: 0.414839, acc: 66.41%, op_acc: 34.38%] [G loss: 0.959141]\n",
      "epoch:14 step:11671[D loss: 0.416612, acc: 60.16%, op_acc: 45.31%] [G loss: 0.953853]\n",
      "epoch:14 step:11672[D loss: 0.430985, acc: 60.94%, op_acc: 37.50%] [G loss: 0.881305]\n",
      "epoch:14 step:11673[D loss: 0.430362, acc: 57.81%, op_acc: 36.72%] [G loss: 0.789608]\n",
      "epoch:14 step:11674[D loss: 0.422101, acc: 64.84%, op_acc: 32.03%] [G loss: 0.815499]\n",
      "epoch:14 step:11675[D loss: 0.438100, acc: 58.59%, op_acc: 38.28%] [G loss: 0.912243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:11676[D loss: 0.455268, acc: 57.03%, op_acc: 37.50%] [G loss: 0.851969]\n",
      "epoch:14 step:11677[D loss: 0.436081, acc: 57.03%, op_acc: 32.81%] [G loss: 0.864959]\n",
      "epoch:14 step:11678[D loss: 0.398300, acc: 59.38%, op_acc: 42.19%] [G loss: 0.906988]\n",
      "epoch:14 step:11679[D loss: 0.442714, acc: 57.81%, op_acc: 36.72%] [G loss: 0.886044]\n",
      "epoch:14 step:11680[D loss: 0.442530, acc: 55.47%, op_acc: 32.81%] [G loss: 0.844016]\n",
      "epoch:14 step:11681[D loss: 0.413422, acc: 55.47%, op_acc: 42.97%] [G loss: 0.914510]\n",
      "epoch:14 step:11682[D loss: 0.401887, acc: 67.97%, op_acc: 36.72%] [G loss: 0.924424]\n",
      "epoch:14 step:11683[D loss: 0.476048, acc: 54.69%, op_acc: 33.59%] [G loss: 0.825484]\n",
      "epoch:14 step:11684[D loss: 0.421837, acc: 61.72%, op_acc: 33.59%] [G loss: 0.897924]\n",
      "epoch:14 step:11685[D loss: 0.449422, acc: 57.81%, op_acc: 34.38%] [G loss: 0.852292]\n",
      "epoch:14 step:11686[D loss: 0.422580, acc: 59.38%, op_acc: 37.50%] [G loss: 0.924100]\n",
      "epoch:14 step:11687[D loss: 0.409771, acc: 66.41%, op_acc: 36.72%] [G loss: 0.868837]\n",
      "epoch:14 step:11688[D loss: 0.460806, acc: 48.44%, op_acc: 36.72%] [G loss: 0.891461]\n",
      "epoch:14 step:11689[D loss: 0.449009, acc: 56.25%, op_acc: 39.06%] [G loss: 0.920910]\n",
      "epoch:14 step:11690[D loss: 0.416587, acc: 56.25%, op_acc: 41.41%] [G loss: 0.975580]\n",
      "epoch:14 step:11691[D loss: 0.412472, acc: 66.41%, op_acc: 37.50%] [G loss: 0.897685]\n",
      "epoch:14 step:11692[D loss: 0.424558, acc: 60.16%, op_acc: 35.94%] [G loss: 0.865041]\n",
      "epoch:14 step:11693[D loss: 0.452236, acc: 57.81%, op_acc: 35.94%] [G loss: 0.889547]\n",
      "epoch:14 step:11694[D loss: 0.428419, acc: 55.47%, op_acc: 41.41%] [G loss: 0.842984]\n",
      "epoch:14 step:11695[D loss: 0.392042, acc: 70.31%, op_acc: 39.84%] [G loss: 0.880458]\n",
      "epoch:14 step:11696[D loss: 0.429276, acc: 61.72%, op_acc: 35.94%] [G loss: 0.773778]\n",
      "epoch:14 step:11697[D loss: 0.422944, acc: 61.72%, op_acc: 34.38%] [G loss: 0.922662]\n",
      "epoch:14 step:11698[D loss: 0.426624, acc: 54.69%, op_acc: 41.41%] [G loss: 0.928953]\n",
      "epoch:14 step:11699[D loss: 0.413513, acc: 64.84%, op_acc: 37.50%] [G loss: 0.923649]\n",
      "epoch:14 step:11700[D loss: 0.466688, acc: 50.78%, op_acc: 34.38%] [G loss: 0.918670]\n",
      "epoch:14 step:11701[D loss: 0.409206, acc: 67.97%, op_acc: 39.06%] [G loss: 0.882152]\n",
      "epoch:14 step:11702[D loss: 0.477427, acc: 56.25%, op_acc: 29.69%] [G loss: 0.881890]\n",
      "epoch:14 step:11703[D loss: 0.402968, acc: 68.75%, op_acc: 36.72%] [G loss: 0.912347]\n",
      "epoch:14 step:11704[D loss: 0.409633, acc: 60.94%, op_acc: 39.84%] [G loss: 0.901482]\n",
      "epoch:14 step:11705[D loss: 0.457373, acc: 57.81%, op_acc: 32.03%] [G loss: 0.915066]\n",
      "epoch:14 step:11706[D loss: 0.460364, acc: 57.03%, op_acc: 34.38%] [G loss: 0.919696]\n",
      "epoch:14 step:11707[D loss: 0.429323, acc: 61.72%, op_acc: 36.72%] [G loss: 0.875232]\n",
      "epoch:14 step:11708[D loss: 0.388556, acc: 67.19%, op_acc: 38.28%] [G loss: 0.912417]\n",
      "epoch:14 step:11709[D loss: 0.453545, acc: 60.16%, op_acc: 36.72%] [G loss: 0.937306]\n",
      "epoch:14 step:11710[D loss: 0.414944, acc: 61.72%, op_acc: 38.28%] [G loss: 0.929966]\n",
      "epoch:14 step:11711[D loss: 0.433266, acc: 63.28%, op_acc: 33.59%] [G loss: 0.931761]\n",
      "epoch:14 step:11712[D loss: 0.393910, acc: 65.62%, op_acc: 46.09%] [G loss: 0.908040]\n",
      "epoch:14 step:11713[D loss: 0.458679, acc: 53.91%, op_acc: 33.59%] [G loss: 0.919019]\n",
      "epoch:14 step:11714[D loss: 0.442746, acc: 56.25%, op_acc: 38.28%] [G loss: 0.859332]\n",
      "epoch:14 step:11715[D loss: 0.430390, acc: 63.28%, op_acc: 38.28%] [G loss: 0.926376]\n",
      "epoch:15 step:11716[D loss: 0.425327, acc: 62.50%, op_acc: 42.97%] [G loss: 0.924115]\n",
      "epoch:15 step:11717[D loss: 0.409844, acc: 57.81%, op_acc: 42.19%] [G loss: 0.834528]\n",
      "epoch:15 step:11718[D loss: 0.450653, acc: 52.34%, op_acc: 36.72%] [G loss: 0.876621]\n",
      "epoch:15 step:11719[D loss: 0.449230, acc: 49.22%, op_acc: 38.28%] [G loss: 0.888065]\n",
      "epoch:15 step:11720[D loss: 0.416358, acc: 64.06%, op_acc: 35.94%] [G loss: 0.885893]\n",
      "epoch:15 step:11721[D loss: 0.446023, acc: 55.47%, op_acc: 35.16%] [G loss: 0.879645]\n",
      "epoch:15 step:11722[D loss: 0.427775, acc: 61.72%, op_acc: 41.41%] [G loss: 0.864217]\n",
      "epoch:15 step:11723[D loss: 0.425026, acc: 65.62%, op_acc: 37.50%] [G loss: 0.883355]\n",
      "epoch:15 step:11724[D loss: 0.426399, acc: 59.38%, op_acc: 39.06%] [G loss: 0.923980]\n",
      "epoch:15 step:11725[D loss: 0.469571, acc: 56.25%, op_acc: 32.03%] [G loss: 0.869745]\n",
      "epoch:15 step:11726[D loss: 0.430715, acc: 64.84%, op_acc: 38.28%] [G loss: 0.911420]\n",
      "epoch:15 step:11727[D loss: 0.432287, acc: 63.28%, op_acc: 33.59%] [G loss: 0.871699]\n",
      "epoch:15 step:11728[D loss: 0.397270, acc: 73.44%, op_acc: 35.94%] [G loss: 0.873780]\n",
      "epoch:15 step:11729[D loss: 0.452511, acc: 54.69%, op_acc: 35.16%] [G loss: 0.885418]\n",
      "epoch:15 step:11730[D loss: 0.420540, acc: 62.50%, op_acc: 39.06%] [G loss: 0.855470]\n",
      "epoch:15 step:11731[D loss: 0.412885, acc: 60.94%, op_acc: 39.84%] [G loss: 0.907101]\n",
      "epoch:15 step:11732[D loss: 0.454021, acc: 50.00%, op_acc: 38.28%] [G loss: 0.837891]\n",
      "epoch:15 step:11733[D loss: 0.411595, acc: 62.50%, op_acc: 40.62%] [G loss: 0.884307]\n",
      "epoch:15 step:11734[D loss: 0.409282, acc: 67.97%, op_acc: 35.94%] [G loss: 0.912785]\n",
      "epoch:15 step:11735[D loss: 0.398585, acc: 67.97%, op_acc: 45.31%] [G loss: 0.886351]\n",
      "epoch:15 step:11736[D loss: 0.475646, acc: 52.34%, op_acc: 28.91%] [G loss: 0.846236]\n",
      "epoch:15 step:11737[D loss: 0.431015, acc: 60.94%, op_acc: 38.28%] [G loss: 0.884097]\n",
      "epoch:15 step:11738[D loss: 0.416671, acc: 63.28%, op_acc: 36.72%] [G loss: 0.893096]\n",
      "epoch:15 step:11739[D loss: 0.430904, acc: 60.94%, op_acc: 35.94%] [G loss: 0.836278]\n",
      "epoch:15 step:11740[D loss: 0.455459, acc: 57.03%, op_acc: 35.16%] [G loss: 0.893624]\n",
      "epoch:15 step:11741[D loss: 0.423978, acc: 58.59%, op_acc: 39.06%] [G loss: 0.813760]\n",
      "epoch:15 step:11742[D loss: 0.432333, acc: 57.03%, op_acc: 42.19%] [G loss: 0.869620]\n",
      "epoch:15 step:11743[D loss: 0.418653, acc: 59.38%, op_acc: 39.84%] [G loss: 0.846469]\n",
      "epoch:15 step:11744[D loss: 0.417589, acc: 62.50%, op_acc: 38.28%] [G loss: 0.945376]\n",
      "epoch:15 step:11745[D loss: 0.407854, acc: 66.41%, op_acc: 41.41%] [G loss: 0.911234]\n",
      "epoch:15 step:11746[D loss: 0.466661, acc: 60.16%, op_acc: 32.81%] [G loss: 0.907500]\n",
      "epoch:15 step:11747[D loss: 0.443301, acc: 57.03%, op_acc: 29.69%] [G loss: 0.892747]\n",
      "epoch:15 step:11748[D loss: 0.438812, acc: 54.69%, op_acc: 39.06%] [G loss: 0.830399]\n",
      "epoch:15 step:11749[D loss: 0.399885, acc: 66.41%, op_acc: 39.06%] [G loss: 0.856707]\n",
      "epoch:15 step:11750[D loss: 0.433128, acc: 62.50%, op_acc: 35.94%] [G loss: 0.928424]\n",
      "epoch:15 step:11751[D loss: 0.404796, acc: 54.69%, op_acc: 43.75%] [G loss: 1.050706]\n",
      "epoch:15 step:11752[D loss: 0.416077, acc: 65.62%, op_acc: 41.41%] [G loss: 0.865204]\n",
      "epoch:15 step:11753[D loss: 0.438072, acc: 54.69%, op_acc: 40.62%] [G loss: 0.904242]\n",
      "epoch:15 step:11754[D loss: 0.402723, acc: 66.41%, op_acc: 38.28%] [G loss: 0.939553]\n",
      "epoch:15 step:11755[D loss: 0.451992, acc: 57.03%, op_acc: 37.50%] [G loss: 0.862072]\n",
      "epoch:15 step:11756[D loss: 0.416210, acc: 58.59%, op_acc: 41.41%] [G loss: 0.889970]\n",
      "epoch:15 step:11757[D loss: 0.375652, acc: 71.09%, op_acc: 38.28%] [G loss: 0.882200]\n",
      "epoch:15 step:11758[D loss: 0.449990, acc: 60.16%, op_acc: 32.81%] [G loss: 0.862952]\n",
      "epoch:15 step:11759[D loss: 0.450593, acc: 55.47%, op_acc: 38.28%] [G loss: 0.874146]\n",
      "epoch:15 step:11760[D loss: 0.434517, acc: 58.59%, op_acc: 33.59%] [G loss: 0.809564]\n",
      "epoch:15 step:11761[D loss: 0.451441, acc: 60.94%, op_acc: 32.03%] [G loss: 0.893300]\n",
      "epoch:15 step:11762[D loss: 0.457154, acc: 56.25%, op_acc: 39.84%] [G loss: 0.914153]\n",
      "epoch:15 step:11763[D loss: 0.448100, acc: 60.16%, op_acc: 35.94%] [G loss: 0.951916]\n",
      "epoch:15 step:11764[D loss: 0.440330, acc: 56.25%, op_acc: 35.94%] [G loss: 0.944036]\n",
      "epoch:15 step:11765[D loss: 0.444555, acc: 58.59%, op_acc: 39.06%] [G loss: 0.935680]\n",
      "epoch:15 step:11766[D loss: 0.420459, acc: 61.72%, op_acc: 34.38%] [G loss: 0.988392]\n",
      "epoch:15 step:11767[D loss: 0.445260, acc: 53.12%, op_acc: 37.50%] [G loss: 0.922257]\n",
      "epoch:15 step:11768[D loss: 0.458507, acc: 58.59%, op_acc: 29.69%] [G loss: 0.881212]\n",
      "epoch:15 step:11769[D loss: 0.476893, acc: 48.44%, op_acc: 38.28%] [G loss: 0.925204]\n",
      "epoch:15 step:11770[D loss: 0.434834, acc: 54.69%, op_acc: 35.94%] [G loss: 0.916209]\n",
      "epoch:15 step:11771[D loss: 0.462627, acc: 49.22%, op_acc: 39.06%] [G loss: 0.893878]\n",
      "epoch:15 step:11772[D loss: 0.443688, acc: 54.69%, op_acc: 34.38%] [G loss: 0.851667]\n",
      "epoch:15 step:11773[D loss: 0.426971, acc: 60.16%, op_acc: 42.19%] [G loss: 0.914588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11774[D loss: 0.405935, acc: 63.28%, op_acc: 39.84%] [G loss: 0.888891]\n",
      "epoch:15 step:11775[D loss: 0.423581, acc: 65.62%, op_acc: 36.72%] [G loss: 0.908242]\n",
      "epoch:15 step:11776[D loss: 0.425984, acc: 60.16%, op_acc: 37.50%] [G loss: 0.937619]\n",
      "epoch:15 step:11777[D loss: 0.430795, acc: 55.47%, op_acc: 36.72%] [G loss: 0.933797]\n",
      "epoch:15 step:11778[D loss: 0.443135, acc: 61.72%, op_acc: 34.38%] [G loss: 0.979535]\n",
      "epoch:15 step:11779[D loss: 0.410899, acc: 59.38%, op_acc: 42.19%] [G loss: 0.889080]\n",
      "epoch:15 step:11780[D loss: 0.438059, acc: 60.16%, op_acc: 36.72%] [G loss: 0.930913]\n",
      "epoch:15 step:11781[D loss: 0.431337, acc: 62.50%, op_acc: 42.19%] [G loss: 0.939636]\n",
      "epoch:15 step:11782[D loss: 0.405175, acc: 62.50%, op_acc: 44.53%] [G loss: 0.808893]\n",
      "epoch:15 step:11783[D loss: 0.446102, acc: 56.25%, op_acc: 32.81%] [G loss: 0.864367]\n",
      "epoch:15 step:11784[D loss: 0.407565, acc: 61.72%, op_acc: 37.50%] [G loss: 0.927602]\n",
      "epoch:15 step:11785[D loss: 0.451459, acc: 52.34%, op_acc: 39.06%] [G loss: 0.914056]\n",
      "epoch:15 step:11786[D loss: 0.473182, acc: 53.12%, op_acc: 30.47%] [G loss: 0.920344]\n",
      "epoch:15 step:11787[D loss: 0.399172, acc: 70.31%, op_acc: 43.75%] [G loss: 0.937175]\n",
      "epoch:15 step:11788[D loss: 0.431013, acc: 53.91%, op_acc: 39.84%] [G loss: 0.916564]\n",
      "epoch:15 step:11789[D loss: 0.415797, acc: 59.38%, op_acc: 38.28%] [G loss: 0.848195]\n",
      "epoch:15 step:11790[D loss: 0.439356, acc: 55.47%, op_acc: 35.94%] [G loss: 0.862360]\n",
      "epoch:15 step:11791[D loss: 0.439094, acc: 60.94%, op_acc: 35.16%] [G loss: 0.803611]\n",
      "epoch:15 step:11792[D loss: 0.448968, acc: 58.59%, op_acc: 41.41%] [G loss: 0.901248]\n",
      "epoch:15 step:11793[D loss: 0.456895, acc: 52.34%, op_acc: 30.47%] [G loss: 0.983144]\n",
      "epoch:15 step:11794[D loss: 0.445830, acc: 59.38%, op_acc: 42.19%] [G loss: 0.915153]\n",
      "epoch:15 step:11795[D loss: 0.463529, acc: 52.34%, op_acc: 32.03%] [G loss: 0.871200]\n",
      "epoch:15 step:11796[D loss: 0.443903, acc: 58.59%, op_acc: 36.72%] [G loss: 0.917278]\n",
      "epoch:15 step:11797[D loss: 0.421026, acc: 58.59%, op_acc: 36.72%] [G loss: 0.923322]\n",
      "epoch:15 step:11798[D loss: 0.410077, acc: 67.97%, op_acc: 34.38%] [G loss: 0.918324]\n",
      "epoch:15 step:11799[D loss: 0.429384, acc: 59.38%, op_acc: 42.19%] [G loss: 0.934443]\n",
      "epoch:15 step:11800[D loss: 0.433124, acc: 62.50%, op_acc: 33.59%] [G loss: 0.852261]\n",
      "epoch:15 step:11801[D loss: 0.440128, acc: 57.03%, op_acc: 35.16%] [G loss: 0.935557]\n",
      "epoch:15 step:11802[D loss: 0.427423, acc: 60.16%, op_acc: 33.59%] [G loss: 0.829798]\n",
      "epoch:15 step:11803[D loss: 0.430450, acc: 57.81%, op_acc: 34.38%] [G loss: 0.928425]\n",
      "epoch:15 step:11804[D loss: 0.446922, acc: 60.94%, op_acc: 36.72%] [G loss: 0.875200]\n",
      "epoch:15 step:11805[D loss: 0.432545, acc: 62.50%, op_acc: 33.59%] [G loss: 0.819667]\n",
      "epoch:15 step:11806[D loss: 0.444971, acc: 54.69%, op_acc: 32.81%] [G loss: 0.889893]\n",
      "epoch:15 step:11807[D loss: 0.438061, acc: 60.94%, op_acc: 36.72%] [G loss: 0.850410]\n",
      "epoch:15 step:11808[D loss: 0.423621, acc: 54.69%, op_acc: 40.62%] [G loss: 0.877002]\n",
      "epoch:15 step:11809[D loss: 0.408569, acc: 64.84%, op_acc: 35.94%] [G loss: 0.825351]\n",
      "epoch:15 step:11810[D loss: 0.433852, acc: 52.34%, op_acc: 38.28%] [G loss: 0.805738]\n",
      "epoch:15 step:11811[D loss: 0.411999, acc: 60.94%, op_acc: 39.06%] [G loss: 0.952352]\n",
      "epoch:15 step:11812[D loss: 0.408717, acc: 60.16%, op_acc: 35.94%] [G loss: 0.839368]\n",
      "epoch:15 step:11813[D loss: 0.431857, acc: 60.16%, op_acc: 32.03%] [G loss: 0.870281]\n",
      "epoch:15 step:11814[D loss: 0.437772, acc: 57.03%, op_acc: 41.41%] [G loss: 0.927486]\n",
      "epoch:15 step:11815[D loss: 0.422003, acc: 52.34%, op_acc: 36.72%] [G loss: 0.862122]\n",
      "epoch:15 step:11816[D loss: 0.415041, acc: 60.94%, op_acc: 44.53%] [G loss: 0.983337]\n",
      "epoch:15 step:11817[D loss: 0.464592, acc: 56.25%, op_acc: 32.81%] [G loss: 0.831710]\n",
      "epoch:15 step:11818[D loss: 0.450684, acc: 57.81%, op_acc: 38.28%] [G loss: 0.854536]\n",
      "epoch:15 step:11819[D loss: 0.408050, acc: 60.16%, op_acc: 39.06%] [G loss: 0.884499]\n",
      "epoch:15 step:11820[D loss: 0.461693, acc: 46.09%, op_acc: 34.38%] [G loss: 0.860734]\n",
      "epoch:15 step:11821[D loss: 0.433399, acc: 55.47%, op_acc: 40.62%] [G loss: 0.846855]\n",
      "epoch:15 step:11822[D loss: 0.427213, acc: 59.38%, op_acc: 42.97%] [G loss: 0.925184]\n",
      "epoch:15 step:11823[D loss: 0.462013, acc: 57.03%, op_acc: 33.59%] [G loss: 0.911743]\n",
      "epoch:15 step:11824[D loss: 0.428316, acc: 56.25%, op_acc: 40.62%] [G loss: 0.966263]\n",
      "epoch:15 step:11825[D loss: 0.426442, acc: 60.94%, op_acc: 42.19%] [G loss: 0.977653]\n",
      "epoch:15 step:11826[D loss: 0.433412, acc: 65.62%, op_acc: 36.72%] [G loss: 0.796585]\n",
      "epoch:15 step:11827[D loss: 0.405944, acc: 66.41%, op_acc: 36.72%] [G loss: 0.883825]\n",
      "epoch:15 step:11828[D loss: 0.417987, acc: 68.75%, op_acc: 32.03%] [G loss: 0.845145]\n",
      "epoch:15 step:11829[D loss: 0.430884, acc: 51.56%, op_acc: 43.75%] [G loss: 0.918969]\n",
      "epoch:15 step:11830[D loss: 0.400591, acc: 58.59%, op_acc: 46.09%] [G loss: 0.876230]\n",
      "epoch:15 step:11831[D loss: 0.456116, acc: 53.91%, op_acc: 38.28%] [G loss: 0.866603]\n",
      "epoch:15 step:11832[D loss: 0.432622, acc: 57.03%, op_acc: 37.50%] [G loss: 0.810538]\n",
      "epoch:15 step:11833[D loss: 0.441901, acc: 52.34%, op_acc: 38.28%] [G loss: 0.865226]\n",
      "epoch:15 step:11834[D loss: 0.461832, acc: 60.94%, op_acc: 28.12%] [G loss: 0.875510]\n",
      "epoch:15 step:11835[D loss: 0.434696, acc: 57.03%, op_acc: 35.16%] [G loss: 0.892394]\n",
      "epoch:15 step:11836[D loss: 0.446260, acc: 57.03%, op_acc: 35.16%] [G loss: 0.937189]\n",
      "epoch:15 step:11837[D loss: 0.432997, acc: 58.59%, op_acc: 34.38%] [G loss: 0.870935]\n",
      "epoch:15 step:11838[D loss: 0.454237, acc: 61.72%, op_acc: 30.47%] [G loss: 0.875268]\n",
      "epoch:15 step:11839[D loss: 0.437031, acc: 57.81%, op_acc: 37.50%] [G loss: 0.833172]\n",
      "epoch:15 step:11840[D loss: 0.457428, acc: 55.47%, op_acc: 29.69%] [G loss: 0.816676]\n",
      "epoch:15 step:11841[D loss: 0.409486, acc: 63.28%, op_acc: 37.50%] [G loss: 0.957772]\n",
      "epoch:15 step:11842[D loss: 0.448382, acc: 59.38%, op_acc: 31.25%] [G loss: 0.860200]\n",
      "epoch:15 step:11843[D loss: 0.410985, acc: 63.28%, op_acc: 39.06%] [G loss: 0.873016]\n",
      "epoch:15 step:11844[D loss: 0.435457, acc: 61.72%, op_acc: 35.16%] [G loss: 0.922516]\n",
      "epoch:15 step:11845[D loss: 0.413265, acc: 62.50%, op_acc: 40.62%] [G loss: 0.938353]\n",
      "epoch:15 step:11846[D loss: 0.410219, acc: 64.06%, op_acc: 33.59%] [G loss: 0.915399]\n",
      "epoch:15 step:11847[D loss: 0.408322, acc: 59.38%, op_acc: 42.19%] [G loss: 0.968107]\n",
      "epoch:15 step:11848[D loss: 0.435956, acc: 63.28%, op_acc: 29.69%] [G loss: 0.836970]\n",
      "epoch:15 step:11849[D loss: 0.456877, acc: 60.94%, op_acc: 35.16%] [G loss: 0.925332]\n",
      "epoch:15 step:11850[D loss: 0.460489, acc: 54.69%, op_acc: 35.16%] [G loss: 0.926203]\n",
      "epoch:15 step:11851[D loss: 0.396888, acc: 62.50%, op_acc: 42.19%] [G loss: 0.967040]\n",
      "epoch:15 step:11852[D loss: 0.444970, acc: 56.25%, op_acc: 37.50%] [G loss: 0.920476]\n",
      "epoch:15 step:11853[D loss: 0.465512, acc: 53.12%, op_acc: 29.69%] [G loss: 0.825799]\n",
      "epoch:15 step:11854[D loss: 0.423552, acc: 64.06%, op_acc: 37.50%] [G loss: 0.848622]\n",
      "epoch:15 step:11855[D loss: 0.475817, acc: 52.34%, op_acc: 35.16%] [G loss: 0.892909]\n",
      "epoch:15 step:11856[D loss: 0.453371, acc: 61.72%, op_acc: 33.59%] [G loss: 0.878234]\n",
      "epoch:15 step:11857[D loss: 0.433480, acc: 64.84%, op_acc: 32.03%] [G loss: 0.898412]\n",
      "epoch:15 step:11858[D loss: 0.454648, acc: 53.91%, op_acc: 35.16%] [G loss: 0.847724]\n",
      "epoch:15 step:11859[D loss: 0.434290, acc: 61.72%, op_acc: 39.06%] [G loss: 0.811684]\n",
      "epoch:15 step:11860[D loss: 0.440875, acc: 57.03%, op_acc: 35.94%] [G loss: 0.812963]\n",
      "epoch:15 step:11861[D loss: 0.416833, acc: 62.50%, op_acc: 36.72%] [G loss: 0.932132]\n",
      "epoch:15 step:11862[D loss: 0.439819, acc: 53.12%, op_acc: 42.19%] [G loss: 0.870013]\n",
      "epoch:15 step:11863[D loss: 0.427440, acc: 66.41%, op_acc: 34.38%] [G loss: 0.885801]\n",
      "epoch:15 step:11864[D loss: 0.441916, acc: 51.56%, op_acc: 36.72%] [G loss: 0.883936]\n",
      "epoch:15 step:11865[D loss: 0.451096, acc: 50.78%, op_acc: 39.06%] [G loss: 0.951871]\n",
      "epoch:15 step:11866[D loss: 0.418715, acc: 61.72%, op_acc: 39.84%] [G loss: 0.905119]\n",
      "epoch:15 step:11867[D loss: 0.411549, acc: 59.38%, op_acc: 41.41%] [G loss: 0.850788]\n",
      "epoch:15 step:11868[D loss: 0.475306, acc: 51.56%, op_acc: 34.38%] [G loss: 0.929348]\n",
      "epoch:15 step:11869[D loss: 0.438249, acc: 53.91%, op_acc: 35.16%] [G loss: 0.856783]\n",
      "epoch:15 step:11870[D loss: 0.392840, acc: 71.09%, op_acc: 39.06%] [G loss: 0.935805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11871[D loss: 0.448021, acc: 47.66%, op_acc: 38.28%] [G loss: 0.935442]\n",
      "epoch:15 step:11872[D loss: 0.425799, acc: 65.62%, op_acc: 36.72%] [G loss: 1.033968]\n",
      "epoch:15 step:11873[D loss: 0.384521, acc: 68.75%, op_acc: 46.09%] [G loss: 0.951871]\n",
      "epoch:15 step:11874[D loss: 0.448263, acc: 57.81%, op_acc: 35.94%] [G loss: 0.929773]\n",
      "epoch:15 step:11875[D loss: 0.420116, acc: 64.06%, op_acc: 35.94%] [G loss: 0.895337]\n",
      "epoch:15 step:11876[D loss: 0.435443, acc: 60.94%, op_acc: 38.28%] [G loss: 0.886366]\n",
      "epoch:15 step:11877[D loss: 0.411442, acc: 53.91%, op_acc: 42.97%] [G loss: 0.846459]\n",
      "epoch:15 step:11878[D loss: 0.438985, acc: 59.38%, op_acc: 39.06%] [G loss: 0.838127]\n",
      "epoch:15 step:11879[D loss: 0.454715, acc: 58.59%, op_acc: 27.34%] [G loss: 0.911575]\n",
      "epoch:15 step:11880[D loss: 0.412501, acc: 60.16%, op_acc: 41.41%] [G loss: 0.891756]\n",
      "epoch:15 step:11881[D loss: 0.424746, acc: 65.62%, op_acc: 36.72%] [G loss: 0.922461]\n",
      "epoch:15 step:11882[D loss: 0.423394, acc: 67.19%, op_acc: 40.62%] [G loss: 0.885333]\n",
      "epoch:15 step:11883[D loss: 0.411669, acc: 64.06%, op_acc: 41.41%] [G loss: 0.878138]\n",
      "epoch:15 step:11884[D loss: 0.433753, acc: 61.72%, op_acc: 37.50%] [G loss: 0.836874]\n",
      "epoch:15 step:11885[D loss: 0.432418, acc: 63.28%, op_acc: 34.38%] [G loss: 0.876140]\n",
      "epoch:15 step:11886[D loss: 0.437265, acc: 56.25%, op_acc: 39.84%] [G loss: 0.865133]\n",
      "epoch:15 step:11887[D loss: 0.419117, acc: 68.75%, op_acc: 38.28%] [G loss: 0.880947]\n",
      "epoch:15 step:11888[D loss: 0.470346, acc: 55.47%, op_acc: 26.56%] [G loss: 0.854252]\n",
      "epoch:15 step:11889[D loss: 0.488160, acc: 50.00%, op_acc: 33.59%] [G loss: 0.861005]\n",
      "epoch:15 step:11890[D loss: 0.401267, acc: 67.19%, op_acc: 35.16%] [G loss: 0.827011]\n",
      "epoch:15 step:11891[D loss: 0.477143, acc: 45.31%, op_acc: 39.06%] [G loss: 0.850304]\n",
      "epoch:15 step:11892[D loss: 0.435406, acc: 54.69%, op_acc: 34.38%] [G loss: 0.814825]\n",
      "epoch:15 step:11893[D loss: 0.444023, acc: 57.03%, op_acc: 35.94%] [G loss: 0.844830]\n",
      "epoch:15 step:11894[D loss: 0.409677, acc: 62.50%, op_acc: 35.94%] [G loss: 0.866566]\n",
      "epoch:15 step:11895[D loss: 0.428928, acc: 55.47%, op_acc: 32.81%] [G loss: 0.874124]\n",
      "epoch:15 step:11896[D loss: 0.420180, acc: 57.81%, op_acc: 39.84%] [G loss: 0.886003]\n",
      "epoch:15 step:11897[D loss: 0.467378, acc: 50.78%, op_acc: 34.38%] [G loss: 0.826193]\n",
      "epoch:15 step:11898[D loss: 0.445570, acc: 60.94%, op_acc: 34.38%] [G loss: 0.923792]\n",
      "epoch:15 step:11899[D loss: 0.438310, acc: 60.16%, op_acc: 39.84%] [G loss: 0.926728]\n",
      "epoch:15 step:11900[D loss: 0.435043, acc: 61.72%, op_acc: 31.25%] [G loss: 0.895027]\n",
      "epoch:15 step:11901[D loss: 0.458831, acc: 51.56%, op_acc: 39.06%] [G loss: 0.860088]\n",
      "epoch:15 step:11902[D loss: 0.423667, acc: 63.28%, op_acc: 39.06%] [G loss: 0.967684]\n",
      "epoch:15 step:11903[D loss: 0.444772, acc: 53.12%, op_acc: 37.50%] [G loss: 0.936556]\n",
      "epoch:15 step:11904[D loss: 0.421921, acc: 59.38%, op_acc: 37.50%] [G loss: 0.904102]\n",
      "epoch:15 step:11905[D loss: 0.448603, acc: 54.69%, op_acc: 35.16%] [G loss: 0.934340]\n",
      "epoch:15 step:11906[D loss: 0.401102, acc: 58.59%, op_acc: 42.19%] [G loss: 0.885585]\n",
      "epoch:15 step:11907[D loss: 0.446054, acc: 55.47%, op_acc: 35.94%] [G loss: 0.825460]\n",
      "epoch:15 step:11908[D loss: 0.465787, acc: 56.25%, op_acc: 35.94%] [G loss: 0.844505]\n",
      "epoch:15 step:11909[D loss: 0.425544, acc: 62.50%, op_acc: 38.28%] [G loss: 0.893743]\n",
      "epoch:15 step:11910[D loss: 0.429758, acc: 60.94%, op_acc: 34.38%] [G loss: 0.913107]\n",
      "epoch:15 step:11911[D loss: 0.406490, acc: 69.53%, op_acc: 34.38%] [G loss: 0.895126]\n",
      "epoch:15 step:11912[D loss: 0.447807, acc: 60.94%, op_acc: 32.03%] [G loss: 0.907083]\n",
      "epoch:15 step:11913[D loss: 0.453061, acc: 54.69%, op_acc: 36.72%] [G loss: 0.821440]\n",
      "epoch:15 step:11914[D loss: 0.456820, acc: 54.69%, op_acc: 30.47%] [G loss: 0.742975]\n",
      "epoch:15 step:11915[D loss: 0.443394, acc: 52.34%, op_acc: 31.25%] [G loss: 0.845536]\n",
      "epoch:15 step:11916[D loss: 0.427685, acc: 60.94%, op_acc: 35.16%] [G loss: 0.877157]\n",
      "epoch:15 step:11917[D loss: 0.465660, acc: 53.12%, op_acc: 33.59%] [G loss: 0.917480]\n",
      "epoch:15 step:11918[D loss: 0.468063, acc: 49.22%, op_acc: 35.94%] [G loss: 0.852138]\n",
      "epoch:15 step:11919[D loss: 0.431111, acc: 59.38%, op_acc: 37.50%] [G loss: 0.872006]\n",
      "epoch:15 step:11920[D loss: 0.421670, acc: 66.41%, op_acc: 30.47%] [G loss: 0.895118]\n",
      "epoch:15 step:11921[D loss: 0.469134, acc: 53.91%, op_acc: 33.59%] [G loss: 0.864369]\n",
      "epoch:15 step:11922[D loss: 0.418935, acc: 64.06%, op_acc: 35.94%] [G loss: 0.854795]\n",
      "epoch:15 step:11923[D loss: 0.473991, acc: 56.25%, op_acc: 31.25%] [G loss: 0.846624]\n",
      "epoch:15 step:11924[D loss: 0.414043, acc: 70.31%, op_acc: 35.94%] [G loss: 0.894627]\n",
      "epoch:15 step:11925[D loss: 0.459698, acc: 58.59%, op_acc: 32.03%] [G loss: 0.891436]\n",
      "epoch:15 step:11926[D loss: 0.396878, acc: 63.28%, op_acc: 42.19%] [G loss: 0.911336]\n",
      "epoch:15 step:11927[D loss: 0.443255, acc: 55.47%, op_acc: 34.38%] [G loss: 0.965936]\n",
      "epoch:15 step:11928[D loss: 0.439407, acc: 58.59%, op_acc: 36.72%] [G loss: 0.837916]\n",
      "epoch:15 step:11929[D loss: 0.426859, acc: 62.50%, op_acc: 35.94%] [G loss: 0.883950]\n",
      "epoch:15 step:11930[D loss: 0.456145, acc: 56.25%, op_acc: 35.94%] [G loss: 0.879859]\n",
      "epoch:15 step:11931[D loss: 0.450588, acc: 55.47%, op_acc: 33.59%] [G loss: 0.879796]\n",
      "epoch:15 step:11932[D loss: 0.441855, acc: 56.25%, op_acc: 36.72%] [G loss: 0.840292]\n",
      "epoch:15 step:11933[D loss: 0.405234, acc: 65.62%, op_acc: 39.84%] [G loss: 0.927268]\n",
      "epoch:15 step:11934[D loss: 0.427055, acc: 54.69%, op_acc: 37.50%] [G loss: 0.847978]\n",
      "epoch:15 step:11935[D loss: 0.406463, acc: 65.62%, op_acc: 44.53%] [G loss: 0.948917]\n",
      "epoch:15 step:11936[D loss: 0.433103, acc: 62.50%, op_acc: 32.81%] [G loss: 0.851080]\n",
      "epoch:15 step:11937[D loss: 0.419832, acc: 64.06%, op_acc: 32.03%] [G loss: 0.900834]\n",
      "epoch:15 step:11938[D loss: 0.436084, acc: 56.25%, op_acc: 39.06%] [G loss: 0.837662]\n",
      "epoch:15 step:11939[D loss: 0.454670, acc: 59.38%, op_acc: 39.06%] [G loss: 0.903106]\n",
      "epoch:15 step:11940[D loss: 0.444433, acc: 57.81%, op_acc: 34.38%] [G loss: 0.848706]\n",
      "epoch:15 step:11941[D loss: 0.452803, acc: 53.91%, op_acc: 39.84%] [G loss: 0.811208]\n",
      "epoch:15 step:11942[D loss: 0.427224, acc: 62.50%, op_acc: 39.84%] [G loss: 0.874605]\n",
      "epoch:15 step:11943[D loss: 0.429313, acc: 56.25%, op_acc: 38.28%] [G loss: 0.839185]\n",
      "epoch:15 step:11944[D loss: 0.432471, acc: 52.34%, op_acc: 37.50%] [G loss: 0.851743]\n",
      "epoch:15 step:11945[D loss: 0.464199, acc: 56.25%, op_acc: 35.16%] [G loss: 0.813666]\n",
      "epoch:15 step:11946[D loss: 0.406040, acc: 58.59%, op_acc: 44.53%] [G loss: 0.873567]\n",
      "epoch:15 step:11947[D loss: 0.409110, acc: 67.19%, op_acc: 42.97%] [G loss: 0.866061]\n",
      "epoch:15 step:11948[D loss: 0.409980, acc: 67.19%, op_acc: 42.19%] [G loss: 0.888839]\n",
      "epoch:15 step:11949[D loss: 0.427912, acc: 65.62%, op_acc: 32.81%] [G loss: 0.927967]\n",
      "epoch:15 step:11950[D loss: 0.414965, acc: 58.59%, op_acc: 39.06%] [G loss: 0.887322]\n",
      "epoch:15 step:11951[D loss: 0.462717, acc: 49.22%, op_acc: 39.06%] [G loss: 0.859325]\n",
      "epoch:15 step:11952[D loss: 0.428383, acc: 58.59%, op_acc: 38.28%] [G loss: 0.927261]\n",
      "epoch:15 step:11953[D loss: 0.423883, acc: 67.19%, op_acc: 37.50%] [G loss: 0.939157]\n",
      "epoch:15 step:11954[D loss: 0.443516, acc: 57.81%, op_acc: 35.16%] [G loss: 0.914879]\n",
      "epoch:15 step:11955[D loss: 0.420708, acc: 60.94%, op_acc: 39.84%] [G loss: 0.937527]\n",
      "epoch:15 step:11956[D loss: 0.444610, acc: 53.91%, op_acc: 35.16%] [G loss: 0.822505]\n",
      "epoch:15 step:11957[D loss: 0.441319, acc: 53.91%, op_acc: 36.72%] [G loss: 0.924178]\n",
      "epoch:15 step:11958[D loss: 0.470220, acc: 45.31%, op_acc: 39.06%] [G loss: 0.853511]\n",
      "epoch:15 step:11959[D loss: 0.429322, acc: 65.62%, op_acc: 38.28%] [G loss: 0.841445]\n",
      "epoch:15 step:11960[D loss: 0.413923, acc: 64.84%, op_acc: 48.44%] [G loss: 0.980379]\n",
      "epoch:15 step:11961[D loss: 0.459152, acc: 52.34%, op_acc: 33.59%] [G loss: 0.875416]\n",
      "epoch:15 step:11962[D loss: 0.392847, acc: 64.84%, op_acc: 39.06%] [G loss: 0.878423]\n",
      "epoch:15 step:11963[D loss: 0.460537, acc: 60.94%, op_acc: 35.94%] [G loss: 0.948503]\n",
      "epoch:15 step:11964[D loss: 0.411603, acc: 66.41%, op_acc: 39.06%] [G loss: 0.904376]\n",
      "epoch:15 step:11965[D loss: 0.438966, acc: 61.72%, op_acc: 38.28%] [G loss: 0.932393]\n",
      "epoch:15 step:11966[D loss: 0.417970, acc: 64.84%, op_acc: 35.94%] [G loss: 0.880679]\n",
      "epoch:15 step:11967[D loss: 0.439986, acc: 58.59%, op_acc: 37.50%] [G loss: 0.912710]\n",
      "epoch:15 step:11968[D loss: 0.441526, acc: 57.81%, op_acc: 34.38%] [G loss: 0.840405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:11969[D loss: 0.399335, acc: 67.19%, op_acc: 34.38%] [G loss: 0.930125]\n",
      "epoch:15 step:11970[D loss: 0.481842, acc: 46.09%, op_acc: 34.38%] [G loss: 0.824671]\n",
      "epoch:15 step:11971[D loss: 0.444188, acc: 51.56%, op_acc: 36.72%] [G loss: 0.847091]\n",
      "epoch:15 step:11972[D loss: 0.415450, acc: 64.06%, op_acc: 39.06%] [G loss: 0.838883]\n",
      "epoch:15 step:11973[D loss: 0.430869, acc: 59.38%, op_acc: 39.84%] [G loss: 0.846774]\n",
      "epoch:15 step:11974[D loss: 0.430199, acc: 58.59%, op_acc: 39.06%] [G loss: 0.935892]\n",
      "epoch:15 step:11975[D loss: 0.455118, acc: 55.47%, op_acc: 38.28%] [G loss: 0.797952]\n",
      "epoch:15 step:11976[D loss: 0.414337, acc: 60.94%, op_acc: 35.94%] [G loss: 0.877058]\n",
      "epoch:15 step:11977[D loss: 0.407857, acc: 64.06%, op_acc: 39.06%] [G loss: 0.851132]\n",
      "epoch:15 step:11978[D loss: 0.413316, acc: 67.97%, op_acc: 35.94%] [G loss: 0.963942]\n",
      "epoch:15 step:11979[D loss: 0.432993, acc: 66.41%, op_acc: 31.25%] [G loss: 0.852626]\n",
      "epoch:15 step:11980[D loss: 0.412225, acc: 64.84%, op_acc: 38.28%] [G loss: 0.900995]\n",
      "epoch:15 step:11981[D loss: 0.410861, acc: 64.06%, op_acc: 41.41%] [G loss: 0.986354]\n",
      "epoch:15 step:11982[D loss: 0.421735, acc: 60.94%, op_acc: 33.59%] [G loss: 0.847537]\n",
      "epoch:15 step:11983[D loss: 0.412406, acc: 53.12%, op_acc: 39.84%] [G loss: 0.921458]\n",
      "epoch:15 step:11984[D loss: 0.426259, acc: 57.81%, op_acc: 40.62%] [G loss: 0.891902]\n",
      "epoch:15 step:11985[D loss: 0.407859, acc: 64.84%, op_acc: 36.72%] [G loss: 0.860810]\n",
      "epoch:15 step:11986[D loss: 0.469864, acc: 49.22%, op_acc: 37.50%] [G loss: 0.872119]\n",
      "epoch:15 step:11987[D loss: 0.421364, acc: 61.72%, op_acc: 34.38%] [G loss: 0.946435]\n",
      "epoch:15 step:11988[D loss: 0.422681, acc: 59.38%, op_acc: 41.41%] [G loss: 0.894687]\n",
      "epoch:15 step:11989[D loss: 0.441338, acc: 59.38%, op_acc: 40.62%] [G loss: 0.896756]\n",
      "epoch:15 step:11990[D loss: 0.427817, acc: 57.03%, op_acc: 41.41%] [G loss: 0.863984]\n",
      "epoch:15 step:11991[D loss: 0.423443, acc: 54.69%, op_acc: 39.06%] [G loss: 0.908222]\n",
      "epoch:15 step:11992[D loss: 0.447618, acc: 61.72%, op_acc: 31.25%] [G loss: 0.912278]\n",
      "epoch:15 step:11993[D loss: 0.414769, acc: 63.28%, op_acc: 35.16%] [G loss: 0.886825]\n",
      "epoch:15 step:11994[D loss: 0.431493, acc: 60.94%, op_acc: 38.28%] [G loss: 0.856853]\n",
      "epoch:15 step:11995[D loss: 0.434820, acc: 56.25%, op_acc: 37.50%] [G loss: 0.806575]\n",
      "epoch:15 step:11996[D loss: 0.454156, acc: 59.38%, op_acc: 32.03%] [G loss: 0.895239]\n",
      "epoch:15 step:11997[D loss: 0.454313, acc: 54.69%, op_acc: 36.72%] [G loss: 0.853623]\n",
      "epoch:15 step:11998[D loss: 0.383553, acc: 69.53%, op_acc: 40.62%] [G loss: 0.950375]\n",
      "epoch:15 step:11999[D loss: 0.463217, acc: 55.47%, op_acc: 32.81%] [G loss: 0.854170]\n",
      "epoch:15 step:12000[D loss: 0.419718, acc: 63.28%, op_acc: 34.38%] [G loss: 0.875886]\n",
      "epoch:15 step:12001[D loss: 0.447132, acc: 54.69%, op_acc: 34.38%] [G loss: 0.926305]\n",
      "epoch:15 step:12002[D loss: 0.459184, acc: 53.12%, op_acc: 32.81%] [G loss: 0.902365]\n",
      "epoch:15 step:12003[D loss: 0.428778, acc: 61.72%, op_acc: 38.28%] [G loss: 0.831727]\n",
      "epoch:15 step:12004[D loss: 0.459877, acc: 46.09%, op_acc: 33.59%] [G loss: 0.819571]\n",
      "epoch:15 step:12005[D loss: 0.429064, acc: 59.38%, op_acc: 37.50%] [G loss: 0.884798]\n",
      "epoch:15 step:12006[D loss: 0.428315, acc: 58.59%, op_acc: 42.97%] [G loss: 0.888292]\n",
      "epoch:15 step:12007[D loss: 0.425078, acc: 63.28%, op_acc: 34.38%] [G loss: 0.913115]\n",
      "epoch:15 step:12008[D loss: 0.433793, acc: 59.38%, op_acc: 35.16%] [G loss: 0.816821]\n",
      "epoch:15 step:12009[D loss: 0.449550, acc: 50.78%, op_acc: 35.16%] [G loss: 0.897367]\n",
      "epoch:15 step:12010[D loss: 0.401828, acc: 65.62%, op_acc: 42.97%] [G loss: 0.928983]\n",
      "epoch:15 step:12011[D loss: 0.441407, acc: 49.22%, op_acc: 39.84%] [G loss: 0.884351]\n",
      "epoch:15 step:12012[D loss: 0.444718, acc: 56.25%, op_acc: 28.12%] [G loss: 0.853044]\n",
      "epoch:15 step:12013[D loss: 0.407920, acc: 67.19%, op_acc: 39.84%] [G loss: 0.909860]\n",
      "epoch:15 step:12014[D loss: 0.439468, acc: 57.81%, op_acc: 38.28%] [G loss: 0.890242]\n",
      "epoch:15 step:12015[D loss: 0.429531, acc: 56.25%, op_acc: 38.28%] [G loss: 0.880428]\n",
      "epoch:15 step:12016[D loss: 0.440004, acc: 60.16%, op_acc: 33.59%] [G loss: 0.895624]\n",
      "epoch:15 step:12017[D loss: 0.418895, acc: 59.38%, op_acc: 37.50%] [G loss: 0.925748]\n",
      "epoch:15 step:12018[D loss: 0.440079, acc: 53.91%, op_acc: 37.50%] [G loss: 0.870086]\n",
      "epoch:15 step:12019[D loss: 0.444537, acc: 49.22%, op_acc: 39.84%] [G loss: 0.834374]\n",
      "epoch:15 step:12020[D loss: 0.406734, acc: 64.06%, op_acc: 39.84%] [G loss: 0.907374]\n",
      "epoch:15 step:12021[D loss: 0.431028, acc: 63.28%, op_acc: 32.81%] [G loss: 0.888393]\n",
      "epoch:15 step:12022[D loss: 0.420521, acc: 56.25%, op_acc: 41.41%] [G loss: 0.935733]\n",
      "epoch:15 step:12023[D loss: 0.453770, acc: 54.69%, op_acc: 35.16%] [G loss: 0.855149]\n",
      "epoch:15 step:12024[D loss: 0.472467, acc: 56.25%, op_acc: 33.59%] [G loss: 0.857036]\n",
      "epoch:15 step:12025[D loss: 0.435929, acc: 60.94%, op_acc: 35.16%] [G loss: 0.867647]\n",
      "epoch:15 step:12026[D loss: 0.433971, acc: 60.16%, op_acc: 38.28%] [G loss: 0.950918]\n",
      "epoch:15 step:12027[D loss: 0.428141, acc: 59.38%, op_acc: 38.28%] [G loss: 0.945381]\n",
      "epoch:15 step:12028[D loss: 0.470014, acc: 54.69%, op_acc: 34.38%] [G loss: 0.834780]\n",
      "epoch:15 step:12029[D loss: 0.427405, acc: 60.16%, op_acc: 36.72%] [G loss: 0.880418]\n",
      "epoch:15 step:12030[D loss: 0.458989, acc: 55.47%, op_acc: 32.81%] [G loss: 0.821598]\n",
      "epoch:15 step:12031[D loss: 0.455983, acc: 51.56%, op_acc: 35.16%] [G loss: 0.857374]\n",
      "epoch:15 step:12032[D loss: 0.454873, acc: 52.34%, op_acc: 34.38%] [G loss: 0.864444]\n",
      "epoch:15 step:12033[D loss: 0.443039, acc: 56.25%, op_acc: 35.94%] [G loss: 0.899098]\n",
      "epoch:15 step:12034[D loss: 0.437085, acc: 58.59%, op_acc: 37.50%] [G loss: 0.849312]\n",
      "epoch:15 step:12035[D loss: 0.447255, acc: 50.00%, op_acc: 38.28%] [G loss: 0.909345]\n",
      "epoch:15 step:12036[D loss: 0.432852, acc: 61.72%, op_acc: 35.94%] [G loss: 0.911643]\n",
      "epoch:15 step:12037[D loss: 0.404105, acc: 64.84%, op_acc: 39.06%] [G loss: 0.982415]\n",
      "epoch:15 step:12038[D loss: 0.444504, acc: 56.25%, op_acc: 36.72%] [G loss: 0.950956]\n",
      "epoch:15 step:12039[D loss: 0.456862, acc: 52.34%, op_acc: 36.72%] [G loss: 0.811908]\n",
      "epoch:15 step:12040[D loss: 0.458874, acc: 52.34%, op_acc: 38.28%] [G loss: 0.847256]\n",
      "epoch:15 step:12041[D loss: 0.416700, acc: 67.19%, op_acc: 38.28%] [G loss: 0.922076]\n",
      "epoch:15 step:12042[D loss: 0.429063, acc: 60.16%, op_acc: 41.41%] [G loss: 0.976944]\n",
      "epoch:15 step:12043[D loss: 0.439465, acc: 59.38%, op_acc: 39.84%] [G loss: 0.859069]\n",
      "epoch:15 step:12044[D loss: 0.429961, acc: 57.03%, op_acc: 35.16%] [G loss: 0.891009]\n",
      "epoch:15 step:12045[D loss: 0.431804, acc: 52.34%, op_acc: 42.19%] [G loss: 0.838910]\n",
      "epoch:15 step:12046[D loss: 0.422393, acc: 59.38%, op_acc: 37.50%] [G loss: 0.941434]\n",
      "epoch:15 step:12047[D loss: 0.430399, acc: 62.50%, op_acc: 39.06%] [G loss: 0.864909]\n",
      "epoch:15 step:12048[D loss: 0.416970, acc: 62.50%, op_acc: 36.72%] [G loss: 0.917852]\n",
      "epoch:15 step:12049[D loss: 0.435812, acc: 53.12%, op_acc: 38.28%] [G loss: 0.847006]\n",
      "epoch:15 step:12050[D loss: 0.454412, acc: 56.25%, op_acc: 33.59%] [G loss: 0.837032]\n",
      "epoch:15 step:12051[D loss: 0.461223, acc: 54.69%, op_acc: 33.59%] [G loss: 0.861481]\n",
      "epoch:15 step:12052[D loss: 0.451459, acc: 53.91%, op_acc: 31.25%] [G loss: 0.852023]\n",
      "epoch:15 step:12053[D loss: 0.413955, acc: 57.81%, op_acc: 39.06%] [G loss: 0.906160]\n",
      "epoch:15 step:12054[D loss: 0.426702, acc: 62.50%, op_acc: 32.81%] [G loss: 0.866301]\n",
      "epoch:15 step:12055[D loss: 0.431111, acc: 57.81%, op_acc: 36.72%] [G loss: 0.930722]\n",
      "epoch:15 step:12056[D loss: 0.446041, acc: 59.38%, op_acc: 32.03%] [G loss: 0.882059]\n",
      "epoch:15 step:12057[D loss: 0.448703, acc: 54.69%, op_acc: 35.94%] [G loss: 0.789947]\n",
      "epoch:15 step:12058[D loss: 0.453611, acc: 56.25%, op_acc: 35.94%] [G loss: 0.863367]\n",
      "epoch:15 step:12059[D loss: 0.425759, acc: 63.28%, op_acc: 38.28%] [G loss: 0.956389]\n",
      "epoch:15 step:12060[D loss: 0.440438, acc: 54.69%, op_acc: 33.59%] [G loss: 0.822662]\n",
      "epoch:15 step:12061[D loss: 0.421176, acc: 60.94%, op_acc: 39.84%] [G loss: 0.914430]\n",
      "epoch:15 step:12062[D loss: 0.416753, acc: 57.81%, op_acc: 40.62%] [G loss: 0.878122]\n",
      "epoch:15 step:12063[D loss: 0.432417, acc: 60.94%, op_acc: 38.28%] [G loss: 0.862524]\n",
      "epoch:15 step:12064[D loss: 0.409533, acc: 71.88%, op_acc: 35.94%] [G loss: 0.904784]\n",
      "epoch:15 step:12065[D loss: 0.430409, acc: 59.38%, op_acc: 40.62%] [G loss: 0.803274]\n",
      "epoch:15 step:12066[D loss: 0.430676, acc: 60.94%, op_acc: 39.06%] [G loss: 0.894826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12067[D loss: 0.435736, acc: 64.84%, op_acc: 34.38%] [G loss: 0.863603]\n",
      "epoch:15 step:12068[D loss: 0.413618, acc: 56.25%, op_acc: 41.41%] [G loss: 0.897971]\n",
      "epoch:15 step:12069[D loss: 0.444488, acc: 53.91%, op_acc: 33.59%] [G loss: 0.917258]\n",
      "epoch:15 step:12070[D loss: 0.453512, acc: 56.25%, op_acc: 42.19%] [G loss: 0.826105]\n",
      "epoch:15 step:12071[D loss: 0.430533, acc: 56.25%, op_acc: 41.41%] [G loss: 0.932514]\n",
      "epoch:15 step:12072[D loss: 0.429686, acc: 54.69%, op_acc: 38.28%] [G loss: 0.941938]\n",
      "epoch:15 step:12073[D loss: 0.438990, acc: 57.03%, op_acc: 39.06%] [G loss: 0.898692]\n",
      "epoch:15 step:12074[D loss: 0.440413, acc: 58.59%, op_acc: 32.81%] [G loss: 0.899112]\n",
      "epoch:15 step:12075[D loss: 0.447607, acc: 53.91%, op_acc: 38.28%] [G loss: 0.891411]\n",
      "epoch:15 step:12076[D loss: 0.444588, acc: 53.91%, op_acc: 39.06%] [G loss: 0.892199]\n",
      "epoch:15 step:12077[D loss: 0.418523, acc: 60.94%, op_acc: 39.06%] [G loss: 0.926442]\n",
      "epoch:15 step:12078[D loss: 0.446705, acc: 57.03%, op_acc: 40.62%] [G loss: 0.931487]\n",
      "epoch:15 step:12079[D loss: 0.444770, acc: 56.25%, op_acc: 35.94%] [G loss: 0.894339]\n",
      "epoch:15 step:12080[D loss: 0.423035, acc: 58.59%, op_acc: 42.19%] [G loss: 0.878340]\n",
      "epoch:15 step:12081[D loss: 0.402465, acc: 61.72%, op_acc: 45.31%] [G loss: 0.818125]\n",
      "epoch:15 step:12082[D loss: 0.453300, acc: 57.03%, op_acc: 34.38%] [G loss: 0.910499]\n",
      "epoch:15 step:12083[D loss: 0.419051, acc: 64.06%, op_acc: 36.72%] [G loss: 0.878176]\n",
      "epoch:15 step:12084[D loss: 0.444622, acc: 56.25%, op_acc: 34.38%] [G loss: 0.886186]\n",
      "epoch:15 step:12085[D loss: 0.435625, acc: 60.16%, op_acc: 35.16%] [G loss: 0.895399]\n",
      "epoch:15 step:12086[D loss: 0.398102, acc: 57.81%, op_acc: 42.19%] [G loss: 0.916834]\n",
      "epoch:15 step:12087[D loss: 0.415303, acc: 66.41%, op_acc: 39.06%] [G loss: 0.850947]\n",
      "epoch:15 step:12088[D loss: 0.426663, acc: 58.59%, op_acc: 38.28%] [G loss: 0.972536]\n",
      "epoch:15 step:12089[D loss: 0.430246, acc: 57.81%, op_acc: 40.62%] [G loss: 0.917409]\n",
      "epoch:15 step:12090[D loss: 0.403528, acc: 64.84%, op_acc: 44.53%] [G loss: 0.915625]\n",
      "epoch:15 step:12091[D loss: 0.422715, acc: 57.03%, op_acc: 40.62%] [G loss: 0.875343]\n",
      "epoch:15 step:12092[D loss: 0.419763, acc: 60.94%, op_acc: 36.72%] [G loss: 0.884688]\n",
      "epoch:15 step:12093[D loss: 0.431721, acc: 60.94%, op_acc: 37.50%] [G loss: 0.809300]\n",
      "epoch:15 step:12094[D loss: 0.391173, acc: 65.62%, op_acc: 38.28%] [G loss: 0.837550]\n",
      "epoch:15 step:12095[D loss: 0.413298, acc: 59.38%, op_acc: 42.97%] [G loss: 0.948850]\n",
      "epoch:15 step:12096[D loss: 0.417136, acc: 67.97%, op_acc: 39.06%] [G loss: 0.889435]\n",
      "epoch:15 step:12097[D loss: 0.422491, acc: 64.06%, op_acc: 37.50%] [G loss: 0.941651]\n",
      "epoch:15 step:12098[D loss: 0.445309, acc: 55.47%, op_acc: 39.84%] [G loss: 0.882494]\n",
      "epoch:15 step:12099[D loss: 0.415697, acc: 60.94%, op_acc: 34.38%] [G loss: 0.880283]\n",
      "epoch:15 step:12100[D loss: 0.434434, acc: 53.91%, op_acc: 39.06%] [G loss: 0.867203]\n",
      "epoch:15 step:12101[D loss: 0.422704, acc: 57.81%, op_acc: 39.84%] [G loss: 0.895944]\n",
      "epoch:15 step:12102[D loss: 0.434461, acc: 56.25%, op_acc: 36.72%] [G loss: 0.937158]\n",
      "epoch:15 step:12103[D loss: 0.431860, acc: 57.81%, op_acc: 34.38%] [G loss: 0.919610]\n",
      "epoch:15 step:12104[D loss: 0.429524, acc: 60.16%, op_acc: 35.94%] [G loss: 0.860464]\n",
      "epoch:15 step:12105[D loss: 0.423142, acc: 64.06%, op_acc: 37.50%] [G loss: 0.874199]\n",
      "epoch:15 step:12106[D loss: 0.397983, acc: 64.06%, op_acc: 42.19%] [G loss: 0.920222]\n",
      "epoch:15 step:12107[D loss: 0.436158, acc: 53.12%, op_acc: 39.84%] [G loss: 0.881702]\n",
      "epoch:15 step:12108[D loss: 0.450629, acc: 51.56%, op_acc: 40.62%] [G loss: 0.815067]\n",
      "epoch:15 step:12109[D loss: 0.443188, acc: 57.03%, op_acc: 31.25%] [G loss: 0.918400]\n",
      "epoch:15 step:12110[D loss: 0.436986, acc: 60.94%, op_acc: 30.47%] [G loss: 0.917307]\n",
      "epoch:15 step:12111[D loss: 0.423954, acc: 59.38%, op_acc: 39.06%] [G loss: 0.814617]\n",
      "epoch:15 step:12112[D loss: 0.423667, acc: 57.03%, op_acc: 36.72%] [G loss: 0.869261]\n",
      "epoch:15 step:12113[D loss: 0.463461, acc: 53.12%, op_acc: 37.50%] [G loss: 0.917661]\n",
      "epoch:15 step:12114[D loss: 0.410441, acc: 64.84%, op_acc: 43.75%] [G loss: 0.889642]\n",
      "epoch:15 step:12115[D loss: 0.411554, acc: 61.72%, op_acc: 41.41%] [G loss: 0.868587]\n",
      "epoch:15 step:12116[D loss: 0.420631, acc: 63.28%, op_acc: 34.38%] [G loss: 0.784335]\n",
      "epoch:15 step:12117[D loss: 0.425789, acc: 63.28%, op_acc: 33.59%] [G loss: 0.958897]\n",
      "epoch:15 step:12118[D loss: 0.426865, acc: 64.84%, op_acc: 35.16%] [G loss: 0.890839]\n",
      "epoch:15 step:12119[D loss: 0.375529, acc: 67.19%, op_acc: 42.19%] [G loss: 0.909622]\n",
      "epoch:15 step:12120[D loss: 0.446653, acc: 60.16%, op_acc: 39.84%] [G loss: 0.907232]\n",
      "epoch:15 step:12121[D loss: 0.431401, acc: 57.03%, op_acc: 44.53%] [G loss: 0.833257]\n",
      "epoch:15 step:12122[D loss: 0.412121, acc: 67.97%, op_acc: 32.81%] [G loss: 0.899410]\n",
      "epoch:15 step:12123[D loss: 0.399371, acc: 67.19%, op_acc: 37.50%] [G loss: 0.921083]\n",
      "epoch:15 step:12124[D loss: 0.427083, acc: 57.03%, op_acc: 42.97%] [G loss: 0.976127]\n",
      "epoch:15 step:12125[D loss: 0.402090, acc: 67.97%, op_acc: 39.06%] [G loss: 0.940166]\n",
      "epoch:15 step:12126[D loss: 0.459930, acc: 55.47%, op_acc: 35.94%] [G loss: 0.845960]\n",
      "epoch:15 step:12127[D loss: 0.437821, acc: 55.47%, op_acc: 42.19%] [G loss: 0.819373]\n",
      "epoch:15 step:12128[D loss: 0.429930, acc: 58.59%, op_acc: 34.38%] [G loss: 0.841822]\n",
      "epoch:15 step:12129[D loss: 0.413316, acc: 60.94%, op_acc: 42.19%] [G loss: 0.934973]\n",
      "epoch:15 step:12130[D loss: 0.434329, acc: 61.72%, op_acc: 36.72%] [G loss: 0.964833]\n",
      "epoch:15 step:12131[D loss: 0.424778, acc: 61.72%, op_acc: 36.72%] [G loss: 0.972147]\n",
      "epoch:15 step:12132[D loss: 0.427902, acc: 61.72%, op_acc: 38.28%] [G loss: 0.963614]\n",
      "epoch:15 step:12133[D loss: 0.452195, acc: 53.12%, op_acc: 36.72%] [G loss: 0.851821]\n",
      "epoch:15 step:12134[D loss: 0.450607, acc: 50.78%, op_acc: 32.81%] [G loss: 0.821618]\n",
      "epoch:15 step:12135[D loss: 0.470626, acc: 50.00%, op_acc: 38.28%] [G loss: 0.864110]\n",
      "epoch:15 step:12136[D loss: 0.447550, acc: 53.91%, op_acc: 35.16%] [G loss: 0.871048]\n",
      "epoch:15 step:12137[D loss: 0.438567, acc: 51.56%, op_acc: 39.84%] [G loss: 0.837279]\n",
      "epoch:15 step:12138[D loss: 0.445883, acc: 64.06%, op_acc: 33.59%] [G loss: 0.900837]\n",
      "epoch:15 step:12139[D loss: 0.450222, acc: 54.69%, op_acc: 37.50%] [G loss: 0.858123]\n",
      "epoch:15 step:12140[D loss: 0.427154, acc: 55.47%, op_acc: 39.06%] [G loss: 0.806874]\n",
      "epoch:15 step:12141[D loss: 0.445184, acc: 60.94%, op_acc: 32.03%] [G loss: 0.852965]\n",
      "epoch:15 step:12142[D loss: 0.434657, acc: 57.03%, op_acc: 32.03%] [G loss: 0.889445]\n",
      "epoch:15 step:12143[D loss: 0.459076, acc: 56.25%, op_acc: 34.38%] [G loss: 0.831089]\n",
      "epoch:15 step:12144[D loss: 0.430643, acc: 60.94%, op_acc: 37.50%] [G loss: 0.946151]\n",
      "epoch:15 step:12145[D loss: 0.410351, acc: 64.06%, op_acc: 36.72%] [G loss: 0.811414]\n",
      "epoch:15 step:12146[D loss: 0.471545, acc: 47.66%, op_acc: 30.47%] [G loss: 0.837358]\n",
      "epoch:15 step:12147[D loss: 0.422561, acc: 53.91%, op_acc: 40.62%] [G loss: 0.886778]\n",
      "epoch:15 step:12148[D loss: 0.442072, acc: 56.25%, op_acc: 35.16%] [G loss: 0.843136]\n",
      "epoch:15 step:12149[D loss: 0.398725, acc: 66.41%, op_acc: 39.84%] [G loss: 0.924318]\n",
      "epoch:15 step:12150[D loss: 0.444525, acc: 54.69%, op_acc: 37.50%] [G loss: 0.971776]\n",
      "epoch:15 step:12151[D loss: 0.461960, acc: 53.91%, op_acc: 37.50%] [G loss: 0.856119]\n",
      "epoch:15 step:12152[D loss: 0.447410, acc: 59.38%, op_acc: 39.84%] [G loss: 0.829682]\n",
      "epoch:15 step:12153[D loss: 0.414208, acc: 62.50%, op_acc: 41.41%] [G loss: 0.898039]\n",
      "epoch:15 step:12154[D loss: 0.408417, acc: 60.94%, op_acc: 43.75%] [G loss: 0.821095]\n",
      "epoch:15 step:12155[D loss: 0.439912, acc: 56.25%, op_acc: 32.81%] [G loss: 0.864206]\n",
      "epoch:15 step:12156[D loss: 0.438315, acc: 58.59%, op_acc: 32.03%] [G loss: 0.884258]\n",
      "epoch:15 step:12157[D loss: 0.450362, acc: 50.00%, op_acc: 36.72%] [G loss: 0.847045]\n",
      "epoch:15 step:12158[D loss: 0.452395, acc: 57.81%, op_acc: 34.38%] [G loss: 0.878231]\n",
      "epoch:15 step:12159[D loss: 0.424770, acc: 60.16%, op_acc: 38.28%] [G loss: 0.858089]\n",
      "epoch:15 step:12160[D loss: 0.459816, acc: 59.38%, op_acc: 31.25%] [G loss: 0.848070]\n",
      "epoch:15 step:12161[D loss: 0.465536, acc: 53.91%, op_acc: 31.25%] [G loss: 0.910031]\n",
      "epoch:15 step:12162[D loss: 0.447352, acc: 63.28%, op_acc: 32.03%] [G loss: 0.889781]\n",
      "epoch:15 step:12163[D loss: 0.419457, acc: 59.38%, op_acc: 35.16%] [G loss: 0.838868]\n",
      "epoch:15 step:12164[D loss: 0.401044, acc: 66.41%, op_acc: 34.38%] [G loss: 0.840321]\n",
      "epoch:15 step:12165[D loss: 0.421043, acc: 64.06%, op_acc: 32.81%] [G loss: 0.933547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12166[D loss: 0.429928, acc: 57.03%, op_acc: 41.41%] [G loss: 0.954252]\n",
      "epoch:15 step:12167[D loss: 0.449205, acc: 50.00%, op_acc: 36.72%] [G loss: 0.882885]\n",
      "epoch:15 step:12168[D loss: 0.425052, acc: 60.94%, op_acc: 35.94%] [G loss: 0.939087]\n",
      "epoch:15 step:12169[D loss: 0.407324, acc: 64.84%, op_acc: 37.50%] [G loss: 0.888898]\n",
      "epoch:15 step:12170[D loss: 0.452830, acc: 57.03%, op_acc: 39.06%] [G loss: 0.914919]\n",
      "epoch:15 step:12171[D loss: 0.434372, acc: 63.28%, op_acc: 39.06%] [G loss: 0.888304]\n",
      "epoch:15 step:12172[D loss: 0.433100, acc: 60.94%, op_acc: 38.28%] [G loss: 0.794947]\n",
      "epoch:15 step:12173[D loss: 0.410392, acc: 61.72%, op_acc: 36.72%] [G loss: 0.832476]\n",
      "epoch:15 step:12174[D loss: 0.401888, acc: 58.59%, op_acc: 41.41%] [G loss: 0.892869]\n",
      "epoch:15 step:12175[D loss: 0.421074, acc: 62.50%, op_acc: 39.06%] [G loss: 0.849324]\n",
      "epoch:15 step:12176[D loss: 0.427130, acc: 59.38%, op_acc: 39.06%] [G loss: 0.939044]\n",
      "epoch:15 step:12177[D loss: 0.428904, acc: 54.69%, op_acc: 36.72%] [G loss: 0.887372]\n",
      "epoch:15 step:12178[D loss: 0.426510, acc: 59.38%, op_acc: 41.41%] [G loss: 0.841752]\n",
      "epoch:15 step:12179[D loss: 0.432110, acc: 67.19%, op_acc: 35.94%] [G loss: 1.005698]\n",
      "epoch:15 step:12180[D loss: 0.409434, acc: 62.50%, op_acc: 35.94%] [G loss: 0.828703]\n",
      "epoch:15 step:12181[D loss: 0.439736, acc: 60.16%, op_acc: 34.38%] [G loss: 0.871682]\n",
      "epoch:15 step:12182[D loss: 0.418526, acc: 60.94%, op_acc: 42.19%] [G loss: 0.869603]\n",
      "epoch:15 step:12183[D loss: 0.421133, acc: 64.84%, op_acc: 39.84%] [G loss: 0.972825]\n",
      "epoch:15 step:12184[D loss: 0.394767, acc: 67.19%, op_acc: 35.16%] [G loss: 0.955852]\n",
      "epoch:15 step:12185[D loss: 0.410466, acc: 61.72%, op_acc: 40.62%] [G loss: 0.904356]\n",
      "epoch:15 step:12186[D loss: 0.465966, acc: 51.56%, op_acc: 29.69%] [G loss: 0.880840]\n",
      "epoch:15 step:12187[D loss: 0.430572, acc: 63.28%, op_acc: 29.69%] [G loss: 0.874157]\n",
      "epoch:15 step:12188[D loss: 0.417347, acc: 60.16%, op_acc: 42.97%] [G loss: 0.830360]\n",
      "epoch:15 step:12189[D loss: 0.449333, acc: 59.38%, op_acc: 42.19%] [G loss: 0.794016]\n",
      "epoch:15 step:12190[D loss: 0.426203, acc: 53.91%, op_acc: 41.41%] [G loss: 0.807752]\n",
      "epoch:15 step:12191[D loss: 0.443482, acc: 54.69%, op_acc: 32.81%] [G loss: 0.806711]\n",
      "epoch:15 step:12192[D loss: 0.417102, acc: 67.97%, op_acc: 35.16%] [G loss: 0.888553]\n",
      "epoch:15 step:12193[D loss: 0.426647, acc: 57.03%, op_acc: 35.16%] [G loss: 0.916285]\n",
      "epoch:15 step:12194[D loss: 0.431735, acc: 59.38%, op_acc: 35.16%] [G loss: 0.897853]\n",
      "epoch:15 step:12195[D loss: 0.457292, acc: 59.38%, op_acc: 30.47%] [G loss: 0.904168]\n",
      "epoch:15 step:12196[D loss: 0.435131, acc: 63.28%, op_acc: 32.81%] [G loss: 0.814242]\n",
      "epoch:15 step:12197[D loss: 0.398484, acc: 64.06%, op_acc: 35.94%] [G loss: 0.938825]\n",
      "epoch:15 step:12198[D loss: 0.440969, acc: 57.81%, op_acc: 36.72%] [G loss: 0.878597]\n",
      "epoch:15 step:12199[D loss: 0.432436, acc: 53.12%, op_acc: 42.19%] [G loss: 0.841528]\n",
      "epoch:15 step:12200[D loss: 0.416471, acc: 62.50%, op_acc: 36.72%] [G loss: 0.917940]\n",
      "epoch:15 step:12201[D loss: 0.384548, acc: 70.31%, op_acc: 42.97%] [G loss: 1.035169]\n",
      "epoch:15 step:12202[D loss: 0.443982, acc: 57.03%, op_acc: 35.94%] [G loss: 0.973180]\n",
      "epoch:15 step:12203[D loss: 0.442478, acc: 60.94%, op_acc: 32.81%] [G loss: 0.901747]\n",
      "epoch:15 step:12204[D loss: 0.451493, acc: 53.91%, op_acc: 34.38%] [G loss: 0.860579]\n",
      "epoch:15 step:12205[D loss: 0.410935, acc: 60.94%, op_acc: 38.28%] [G loss: 0.945716]\n",
      "epoch:15 step:12206[D loss: 0.441123, acc: 59.38%, op_acc: 38.28%] [G loss: 0.928245]\n",
      "epoch:15 step:12207[D loss: 0.394563, acc: 65.62%, op_acc: 38.28%] [G loss: 0.874326]\n",
      "epoch:15 step:12208[D loss: 0.430388, acc: 64.06%, op_acc: 34.38%] [G loss: 0.887869]\n",
      "epoch:15 step:12209[D loss: 0.407079, acc: 60.94%, op_acc: 42.19%] [G loss: 0.877077]\n",
      "epoch:15 step:12210[D loss: 0.427269, acc: 66.41%, op_acc: 32.81%] [G loss: 0.888448]\n",
      "epoch:15 step:12211[D loss: 0.429506, acc: 62.50%, op_acc: 32.81%] [G loss: 0.937711]\n",
      "epoch:15 step:12212[D loss: 0.394379, acc: 64.06%, op_acc: 36.72%] [G loss: 0.915745]\n",
      "epoch:15 step:12213[D loss: 0.456102, acc: 62.50%, op_acc: 30.47%] [G loss: 0.814455]\n",
      "epoch:15 step:12214[D loss: 0.444150, acc: 61.72%, op_acc: 34.38%] [G loss: 0.865506]\n",
      "epoch:15 step:12215[D loss: 0.426923, acc: 54.69%, op_acc: 43.75%] [G loss: 0.915270]\n",
      "epoch:15 step:12216[D loss: 0.443211, acc: 58.59%, op_acc: 36.72%] [G loss: 0.934113]\n",
      "epoch:15 step:12217[D loss: 0.410632, acc: 60.94%, op_acc: 40.62%] [G loss: 0.907779]\n",
      "epoch:15 step:12218[D loss: 0.414033, acc: 60.16%, op_acc: 36.72%] [G loss: 0.859818]\n",
      "epoch:15 step:12219[D loss: 0.442262, acc: 61.72%, op_acc: 40.62%] [G loss: 0.852877]\n",
      "epoch:15 step:12220[D loss: 0.429608, acc: 62.50%, op_acc: 40.62%] [G loss: 0.950644]\n",
      "epoch:15 step:12221[D loss: 0.441924, acc: 60.94%, op_acc: 33.59%] [G loss: 0.911580]\n",
      "epoch:15 step:12222[D loss: 0.401918, acc: 60.94%, op_acc: 35.16%] [G loss: 0.887053]\n",
      "epoch:15 step:12223[D loss: 0.428400, acc: 60.16%, op_acc: 41.41%] [G loss: 0.912482]\n",
      "epoch:15 step:12224[D loss: 0.444051, acc: 55.47%, op_acc: 36.72%] [G loss: 0.870781]\n",
      "epoch:15 step:12225[D loss: 0.452637, acc: 55.47%, op_acc: 35.16%] [G loss: 0.892856]\n",
      "epoch:15 step:12226[D loss: 0.442991, acc: 58.59%, op_acc: 39.06%] [G loss: 0.940865]\n",
      "epoch:15 step:12227[D loss: 0.499680, acc: 49.22%, op_acc: 32.81%] [G loss: 0.848428]\n",
      "epoch:15 step:12228[D loss: 0.476375, acc: 50.78%, op_acc: 32.81%] [G loss: 0.883830]\n",
      "epoch:15 step:12229[D loss: 0.437340, acc: 61.72%, op_acc: 29.69%] [G loss: 0.838184]\n",
      "epoch:15 step:12230[D loss: 0.446854, acc: 57.81%, op_acc: 31.25%] [G loss: 0.881801]\n",
      "epoch:15 step:12231[D loss: 0.437835, acc: 60.94%, op_acc: 36.72%] [G loss: 0.952019]\n",
      "epoch:15 step:12232[D loss: 0.461581, acc: 52.34%, op_acc: 27.34%] [G loss: 0.879559]\n",
      "epoch:15 step:12233[D loss: 0.429193, acc: 57.81%, op_acc: 37.50%] [G loss: 0.850458]\n",
      "epoch:15 step:12234[D loss: 0.408520, acc: 65.62%, op_acc: 45.31%] [G loss: 0.876361]\n",
      "epoch:15 step:12235[D loss: 0.412598, acc: 63.28%, op_acc: 42.19%] [G loss: 0.875743]\n",
      "epoch:15 step:12236[D loss: 0.450522, acc: 59.38%, op_acc: 32.03%] [G loss: 0.893961]\n",
      "epoch:15 step:12237[D loss: 0.464971, acc: 53.91%, op_acc: 40.62%] [G loss: 0.887683]\n",
      "epoch:15 step:12238[D loss: 0.410511, acc: 61.72%, op_acc: 36.72%] [G loss: 0.936418]\n",
      "epoch:15 step:12239[D loss: 0.462719, acc: 57.03%, op_acc: 35.94%] [G loss: 0.955333]\n",
      "epoch:15 step:12240[D loss: 0.433540, acc: 62.50%, op_acc: 35.16%] [G loss: 0.958572]\n",
      "epoch:15 step:12241[D loss: 0.443987, acc: 63.28%, op_acc: 28.91%] [G loss: 0.946634]\n",
      "epoch:15 step:12242[D loss: 0.454557, acc: 54.69%, op_acc: 35.94%] [G loss: 0.834089]\n",
      "epoch:15 step:12243[D loss: 0.420254, acc: 57.81%, op_acc: 39.06%] [G loss: 0.856900]\n",
      "epoch:15 step:12244[D loss: 0.436129, acc: 58.59%, op_acc: 39.84%] [G loss: 0.891122]\n",
      "epoch:15 step:12245[D loss: 0.436507, acc: 57.03%, op_acc: 34.38%] [G loss: 0.840446]\n",
      "epoch:15 step:12246[D loss: 0.437895, acc: 62.50%, op_acc: 31.25%] [G loss: 0.825537]\n",
      "epoch:15 step:12247[D loss: 0.465925, acc: 54.69%, op_acc: 35.16%] [G loss: 0.868788]\n",
      "epoch:15 step:12248[D loss: 0.458591, acc: 50.78%, op_acc: 33.59%] [G loss: 0.843078]\n",
      "epoch:15 step:12249[D loss: 0.401128, acc: 62.50%, op_acc: 45.31%] [G loss: 0.935778]\n",
      "epoch:15 step:12250[D loss: 0.436983, acc: 60.16%, op_acc: 32.03%] [G loss: 0.860134]\n",
      "epoch:15 step:12251[D loss: 0.394909, acc: 60.16%, op_acc: 41.41%] [G loss: 0.889412]\n",
      "epoch:15 step:12252[D loss: 0.459854, acc: 50.78%, op_acc: 36.72%] [G loss: 0.858921]\n",
      "epoch:15 step:12253[D loss: 0.424483, acc: 59.38%, op_acc: 36.72%] [G loss: 0.886201]\n",
      "epoch:15 step:12254[D loss: 0.425308, acc: 63.28%, op_acc: 31.25%] [G loss: 0.955610]\n",
      "epoch:15 step:12255[D loss: 0.427573, acc: 58.59%, op_acc: 35.16%] [G loss: 0.832361]\n",
      "epoch:15 step:12256[D loss: 0.394692, acc: 70.31%, op_acc: 41.41%] [G loss: 0.876631]\n",
      "epoch:15 step:12257[D loss: 0.438343, acc: 53.91%, op_acc: 35.16%] [G loss: 0.820758]\n",
      "epoch:15 step:12258[D loss: 0.468453, acc: 55.47%, op_acc: 29.69%] [G loss: 0.833574]\n",
      "epoch:15 step:12259[D loss: 0.419579, acc: 62.50%, op_acc: 40.62%] [G loss: 0.908935]\n",
      "epoch:15 step:12260[D loss: 0.416365, acc: 64.06%, op_acc: 39.84%] [G loss: 0.891592]\n",
      "epoch:15 step:12261[D loss: 0.428288, acc: 61.72%, op_acc: 38.28%] [G loss: 0.893183]\n",
      "epoch:15 step:12262[D loss: 0.455890, acc: 48.44%, op_acc: 36.72%] [G loss: 0.905372]\n",
      "epoch:15 step:12263[D loss: 0.421698, acc: 60.94%, op_acc: 38.28%] [G loss: 0.897490]\n",
      "epoch:15 step:12264[D loss: 0.437782, acc: 60.16%, op_acc: 34.38%] [G loss: 0.891280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12265[D loss: 0.447069, acc: 51.56%, op_acc: 35.16%] [G loss: 0.860521]\n",
      "epoch:15 step:12266[D loss: 0.452905, acc: 53.91%, op_acc: 37.50%] [G loss: 0.931578]\n",
      "epoch:15 step:12267[D loss: 0.484409, acc: 51.56%, op_acc: 28.12%] [G loss: 0.872805]\n",
      "epoch:15 step:12268[D loss: 0.419757, acc: 62.50%, op_acc: 36.72%] [G loss: 0.873291]\n",
      "epoch:15 step:12269[D loss: 0.419389, acc: 62.50%, op_acc: 36.72%] [G loss: 0.899705]\n",
      "epoch:15 step:12270[D loss: 0.423691, acc: 60.16%, op_acc: 40.62%] [G loss: 0.854558]\n",
      "epoch:15 step:12271[D loss: 0.418820, acc: 59.38%, op_acc: 42.19%] [G loss: 0.798230]\n",
      "epoch:15 step:12272[D loss: 0.422931, acc: 67.19%, op_acc: 34.38%] [G loss: 0.902580]\n",
      "epoch:15 step:12273[D loss: 0.416034, acc: 66.41%, op_acc: 35.94%] [G loss: 0.822368]\n",
      "epoch:15 step:12274[D loss: 0.399383, acc: 62.50%, op_acc: 38.28%] [G loss: 0.928277]\n",
      "epoch:15 step:12275[D loss: 0.482228, acc: 50.78%, op_acc: 32.03%] [G loss: 0.763742]\n",
      "epoch:15 step:12276[D loss: 0.422338, acc: 58.59%, op_acc: 41.41%] [G loss: 0.815979]\n",
      "epoch:15 step:12277[D loss: 0.418658, acc: 67.97%, op_acc: 32.03%] [G loss: 0.860665]\n",
      "epoch:15 step:12278[D loss: 0.447293, acc: 57.03%, op_acc: 32.81%] [G loss: 0.936713]\n",
      "epoch:15 step:12279[D loss: 0.416506, acc: 60.16%, op_acc: 41.41%] [G loss: 0.868406]\n",
      "epoch:15 step:12280[D loss: 0.418903, acc: 64.06%, op_acc: 36.72%] [G loss: 0.867130]\n",
      "epoch:15 step:12281[D loss: 0.434871, acc: 57.81%, op_acc: 37.50%] [G loss: 0.888280]\n",
      "epoch:15 step:12282[D loss: 0.439181, acc: 54.69%, op_acc: 38.28%] [G loss: 0.918611]\n",
      "epoch:15 step:12283[D loss: 0.417656, acc: 61.72%, op_acc: 36.72%] [G loss: 0.842773]\n",
      "epoch:15 step:12284[D loss: 0.445365, acc: 58.59%, op_acc: 35.94%] [G loss: 0.867217]\n",
      "epoch:15 step:12285[D loss: 0.427544, acc: 61.72%, op_acc: 37.50%] [G loss: 0.917676]\n",
      "epoch:15 step:12286[D loss: 0.426750, acc: 57.81%, op_acc: 39.84%] [G loss: 0.943211]\n",
      "epoch:15 step:12287[D loss: 0.452074, acc: 52.34%, op_acc: 38.28%] [G loss: 0.891030]\n",
      "epoch:15 step:12288[D loss: 0.426862, acc: 60.16%, op_acc: 41.41%] [G loss: 0.872296]\n",
      "epoch:15 step:12289[D loss: 0.444264, acc: 58.59%, op_acc: 33.59%] [G loss: 0.879559]\n",
      "epoch:15 step:12290[D loss: 0.465357, acc: 50.78%, op_acc: 39.84%] [G loss: 0.911141]\n",
      "epoch:15 step:12291[D loss: 0.430731, acc: 58.59%, op_acc: 42.97%] [G loss: 0.849697]\n",
      "epoch:15 step:12292[D loss: 0.464540, acc: 57.03%, op_acc: 36.72%] [G loss: 0.830553]\n",
      "epoch:15 step:12293[D loss: 0.485081, acc: 55.47%, op_acc: 30.47%] [G loss: 0.854999]\n",
      "epoch:15 step:12294[D loss: 0.435236, acc: 55.47%, op_acc: 41.41%] [G loss: 0.878592]\n",
      "epoch:15 step:12295[D loss: 0.435931, acc: 57.81%, op_acc: 38.28%] [G loss: 0.837650]\n",
      "epoch:15 step:12296[D loss: 0.439099, acc: 57.03%, op_acc: 35.94%] [G loss: 0.940156]\n",
      "epoch:15 step:12297[D loss: 0.444310, acc: 57.81%, op_acc: 35.16%] [G loss: 0.838015]\n",
      "epoch:15 step:12298[D loss: 0.405449, acc: 64.84%, op_acc: 32.03%] [G loss: 0.874524]\n",
      "epoch:15 step:12299[D loss: 0.456691, acc: 56.25%, op_acc: 33.59%] [G loss: 0.925214]\n",
      "epoch:15 step:12300[D loss: 0.413968, acc: 59.38%, op_acc: 42.97%] [G loss: 0.916461]\n",
      "epoch:15 step:12301[D loss: 0.447407, acc: 53.91%, op_acc: 34.38%] [G loss: 0.871840]\n",
      "epoch:15 step:12302[D loss: 0.434713, acc: 57.81%, op_acc: 32.81%] [G loss: 0.882506]\n",
      "epoch:15 step:12303[D loss: 0.404601, acc: 61.72%, op_acc: 42.19%] [G loss: 0.963294]\n",
      "epoch:15 step:12304[D loss: 0.412400, acc: 63.28%, op_acc: 39.06%] [G loss: 0.895805]\n",
      "epoch:15 step:12305[D loss: 0.406040, acc: 67.97%, op_acc: 38.28%] [G loss: 0.906070]\n",
      "epoch:15 step:12306[D loss: 0.430026, acc: 56.25%, op_acc: 39.84%] [G loss: 0.888624]\n",
      "epoch:15 step:12307[D loss: 0.442555, acc: 53.91%, op_acc: 32.03%] [G loss: 0.872074]\n",
      "epoch:15 step:12308[D loss: 0.453732, acc: 55.47%, op_acc: 31.25%] [G loss: 0.861551]\n",
      "epoch:15 step:12309[D loss: 0.401118, acc: 67.19%, op_acc: 42.97%] [G loss: 0.970867]\n",
      "epoch:15 step:12310[D loss: 0.426120, acc: 66.41%, op_acc: 34.38%] [G loss: 0.880217]\n",
      "epoch:15 step:12311[D loss: 0.451165, acc: 53.91%, op_acc: 30.47%] [G loss: 0.956417]\n",
      "epoch:15 step:12312[D loss: 0.433653, acc: 56.25%, op_acc: 38.28%] [G loss: 0.899958]\n",
      "epoch:15 step:12313[D loss: 0.427401, acc: 55.47%, op_acc: 34.38%] [G loss: 0.823709]\n",
      "epoch:15 step:12314[D loss: 0.418285, acc: 64.84%, op_acc: 36.72%] [G loss: 0.975692]\n",
      "epoch:15 step:12315[D loss: 0.453265, acc: 58.59%, op_acc: 30.47%] [G loss: 0.982797]\n",
      "epoch:15 step:12316[D loss: 0.438965, acc: 57.03%, op_acc: 35.94%] [G loss: 0.970057]\n",
      "epoch:15 step:12317[D loss: 0.408918, acc: 62.50%, op_acc: 36.72%] [G loss: 0.884975]\n",
      "epoch:15 step:12318[D loss: 0.395454, acc: 68.75%, op_acc: 42.97%] [G loss: 0.933679]\n",
      "epoch:15 step:12319[D loss: 0.439994, acc: 61.72%, op_acc: 35.16%] [G loss: 0.910675]\n",
      "epoch:15 step:12320[D loss: 0.435352, acc: 56.25%, op_acc: 35.16%] [G loss: 0.826371]\n",
      "epoch:15 step:12321[D loss: 0.438239, acc: 53.91%, op_acc: 39.06%] [G loss: 0.828729]\n",
      "epoch:15 step:12322[D loss: 0.411508, acc: 62.50%, op_acc: 43.75%] [G loss: 0.830173]\n",
      "epoch:15 step:12323[D loss: 0.424958, acc: 60.94%, op_acc: 39.06%] [G loss: 0.880584]\n",
      "epoch:15 step:12324[D loss: 0.444265, acc: 53.91%, op_acc: 35.94%] [G loss: 0.877367]\n",
      "epoch:15 step:12325[D loss: 0.415491, acc: 56.25%, op_acc: 44.53%] [G loss: 0.835067]\n",
      "epoch:15 step:12326[D loss: 0.430701, acc: 57.03%, op_acc: 40.62%] [G loss: 0.859762]\n",
      "epoch:15 step:12327[D loss: 0.437825, acc: 50.00%, op_acc: 36.72%] [G loss: 0.812059]\n",
      "epoch:15 step:12328[D loss: 0.446560, acc: 56.25%, op_acc: 38.28%] [G loss: 0.940048]\n",
      "epoch:15 step:12329[D loss: 0.438081, acc: 59.38%, op_acc: 37.50%] [G loss: 0.902978]\n",
      "epoch:15 step:12330[D loss: 0.454669, acc: 55.47%, op_acc: 34.38%] [G loss: 0.911987]\n",
      "epoch:15 step:12331[D loss: 0.440356, acc: 59.38%, op_acc: 32.03%] [G loss: 0.880143]\n",
      "epoch:15 step:12332[D loss: 0.460513, acc: 53.91%, op_acc: 35.16%] [G loss: 0.844303]\n",
      "epoch:15 step:12333[D loss: 0.419802, acc: 56.25%, op_acc: 39.84%] [G loss: 0.867160]\n",
      "epoch:15 step:12334[D loss: 0.459975, acc: 54.69%, op_acc: 36.72%] [G loss: 0.910185]\n",
      "epoch:15 step:12335[D loss: 0.397771, acc: 70.31%, op_acc: 32.81%] [G loss: 0.871344]\n",
      "epoch:15 step:12336[D loss: 0.451470, acc: 54.69%, op_acc: 37.50%] [G loss: 0.830008]\n",
      "epoch:15 step:12337[D loss: 0.495803, acc: 54.69%, op_acc: 25.00%] [G loss: 0.884330]\n",
      "epoch:15 step:12338[D loss: 0.422290, acc: 57.81%, op_acc: 38.28%] [G loss: 0.788505]\n",
      "epoch:15 step:12339[D loss: 0.436022, acc: 54.69%, op_acc: 37.50%] [G loss: 0.860110]\n",
      "epoch:15 step:12340[D loss: 0.429518, acc: 61.72%, op_acc: 38.28%] [G loss: 0.794669]\n",
      "epoch:15 step:12341[D loss: 0.425387, acc: 51.56%, op_acc: 41.41%] [G loss: 0.884284]\n",
      "epoch:15 step:12342[D loss: 0.436790, acc: 57.81%, op_acc: 38.28%] [G loss: 0.898312]\n",
      "epoch:15 step:12343[D loss: 0.475767, acc: 46.88%, op_acc: 37.50%] [G loss: 0.899919]\n",
      "epoch:15 step:12344[D loss: 0.463208, acc: 50.78%, op_acc: 35.16%] [G loss: 0.901061]\n",
      "epoch:15 step:12345[D loss: 0.410680, acc: 60.16%, op_acc: 38.28%] [G loss: 0.942400]\n",
      "epoch:15 step:12346[D loss: 0.444794, acc: 52.34%, op_acc: 32.81%] [G loss: 0.822548]\n",
      "epoch:15 step:12347[D loss: 0.406952, acc: 60.94%, op_acc: 32.03%] [G loss: 0.935123]\n",
      "epoch:15 step:12348[D loss: 0.426488, acc: 62.50%, op_acc: 35.94%] [G loss: 0.881459]\n",
      "epoch:15 step:12349[D loss: 0.431659, acc: 57.03%, op_acc: 41.41%] [G loss: 0.825298]\n",
      "epoch:15 step:12350[D loss: 0.427457, acc: 60.94%, op_acc: 36.72%] [G loss: 0.872675]\n",
      "epoch:15 step:12351[D loss: 0.412641, acc: 60.16%, op_acc: 39.84%] [G loss: 0.861516]\n",
      "epoch:15 step:12352[D loss: 0.434531, acc: 56.25%, op_acc: 39.06%] [G loss: 0.784006]\n",
      "epoch:15 step:12353[D loss: 0.429547, acc: 60.16%, op_acc: 41.41%] [G loss: 0.883505]\n",
      "epoch:15 step:12354[D loss: 0.439514, acc: 53.12%, op_acc: 38.28%] [G loss: 0.936757]\n",
      "epoch:15 step:12355[D loss: 0.434851, acc: 60.16%, op_acc: 32.81%] [G loss: 0.877672]\n",
      "epoch:15 step:12356[D loss: 0.416084, acc: 61.72%, op_acc: 37.50%] [G loss: 0.850451]\n",
      "epoch:15 step:12357[D loss: 0.426118, acc: 63.28%, op_acc: 35.16%] [G loss: 0.920588]\n",
      "epoch:15 step:12358[D loss: 0.446966, acc: 62.50%, op_acc: 33.59%] [G loss: 0.904235]\n",
      "epoch:15 step:12359[D loss: 0.427739, acc: 57.81%, op_acc: 38.28%] [G loss: 0.951471]\n",
      "epoch:15 step:12360[D loss: 0.387263, acc: 67.97%, op_acc: 42.19%] [G loss: 0.909575]\n",
      "epoch:15 step:12361[D loss: 0.446968, acc: 60.94%, op_acc: 33.59%] [G loss: 0.900238]\n",
      "epoch:15 step:12362[D loss: 0.408353, acc: 60.16%, op_acc: 41.41%] [G loss: 0.942383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12363[D loss: 0.426421, acc: 54.69%, op_acc: 36.72%] [G loss: 0.903789]\n",
      "epoch:15 step:12364[D loss: 0.429904, acc: 60.16%, op_acc: 42.19%] [G loss: 0.810738]\n",
      "epoch:15 step:12365[D loss: 0.423960, acc: 61.72%, op_acc: 36.72%] [G loss: 0.887304]\n",
      "epoch:15 step:12366[D loss: 0.455452, acc: 52.34%, op_acc: 37.50%] [G loss: 0.857136]\n",
      "epoch:15 step:12367[D loss: 0.421128, acc: 58.59%, op_acc: 35.16%] [G loss: 0.858750]\n",
      "epoch:15 step:12368[D loss: 0.429920, acc: 57.81%, op_acc: 38.28%] [G loss: 0.893838]\n",
      "epoch:15 step:12369[D loss: 0.439379, acc: 55.47%, op_acc: 37.50%] [G loss: 0.863221]\n",
      "epoch:15 step:12370[D loss: 0.439470, acc: 60.94%, op_acc: 38.28%] [G loss: 0.901876]\n",
      "epoch:15 step:12371[D loss: 0.449556, acc: 55.47%, op_acc: 38.28%] [G loss: 0.849184]\n",
      "epoch:15 step:12372[D loss: 0.437386, acc: 58.59%, op_acc: 38.28%] [G loss: 0.875808]\n",
      "epoch:15 step:12373[D loss: 0.435637, acc: 57.03%, op_acc: 34.38%] [G loss: 0.893097]\n",
      "epoch:15 step:12374[D loss: 0.429242, acc: 64.06%, op_acc: 39.06%] [G loss: 0.951703]\n",
      "epoch:15 step:12375[D loss: 0.423506, acc: 57.81%, op_acc: 36.72%] [G loss: 0.849983]\n",
      "epoch:15 step:12376[D loss: 0.416284, acc: 58.59%, op_acc: 46.09%] [G loss: 0.874588]\n",
      "epoch:15 step:12377[D loss: 0.439298, acc: 48.44%, op_acc: 39.84%] [G loss: 0.859690]\n",
      "epoch:15 step:12378[D loss: 0.413261, acc: 66.41%, op_acc: 37.50%] [G loss: 0.857095]\n",
      "epoch:15 step:12379[D loss: 0.399321, acc: 67.97%, op_acc: 41.41%] [G loss: 0.829325]\n",
      "epoch:15 step:12380[D loss: 0.454909, acc: 57.81%, op_acc: 27.34%] [G loss: 0.881040]\n",
      "epoch:15 step:12381[D loss: 0.447009, acc: 59.38%, op_acc: 33.59%] [G loss: 0.885782]\n",
      "epoch:15 step:12382[D loss: 0.426152, acc: 61.72%, op_acc: 33.59%] [G loss: 0.826473]\n",
      "epoch:15 step:12383[D loss: 0.427861, acc: 57.81%, op_acc: 36.72%] [G loss: 0.975680]\n",
      "epoch:15 step:12384[D loss: 0.421305, acc: 58.59%, op_acc: 36.72%] [G loss: 0.914325]\n",
      "epoch:15 step:12385[D loss: 0.401437, acc: 64.06%, op_acc: 42.19%] [G loss: 0.888685]\n",
      "epoch:15 step:12386[D loss: 0.441685, acc: 49.22%, op_acc: 36.72%] [G loss: 0.876381]\n",
      "epoch:15 step:12387[D loss: 0.447929, acc: 59.38%, op_acc: 37.50%] [G loss: 0.834156]\n",
      "epoch:15 step:12388[D loss: 0.414040, acc: 66.41%, op_acc: 30.47%] [G loss: 0.937650]\n",
      "epoch:15 step:12389[D loss: 0.434150, acc: 57.03%, op_acc: 42.19%] [G loss: 0.901938]\n",
      "epoch:15 step:12390[D loss: 0.460300, acc: 55.47%, op_acc: 35.16%] [G loss: 0.932369]\n",
      "epoch:15 step:12391[D loss: 0.462965, acc: 58.59%, op_acc: 34.38%] [G loss: 0.859475]\n",
      "epoch:15 step:12392[D loss: 0.501754, acc: 43.75%, op_acc: 32.03%] [G loss: 0.844407]\n",
      "epoch:15 step:12393[D loss: 0.413813, acc: 61.72%, op_acc: 37.50%] [G loss: 0.916336]\n",
      "epoch:15 step:12394[D loss: 0.397630, acc: 62.50%, op_acc: 34.38%] [G loss: 0.892220]\n",
      "epoch:15 step:12395[D loss: 0.441574, acc: 58.59%, op_acc: 33.59%] [G loss: 0.909375]\n",
      "epoch:15 step:12396[D loss: 0.438940, acc: 58.59%, op_acc: 35.16%] [G loss: 0.770925]\n",
      "epoch:15 step:12397[D loss: 0.417810, acc: 60.16%, op_acc: 38.28%] [G loss: 0.883819]\n",
      "epoch:15 step:12398[D loss: 0.423254, acc: 57.81%, op_acc: 39.84%] [G loss: 0.815855]\n",
      "epoch:15 step:12399[D loss: 0.447114, acc: 60.94%, op_acc: 30.47%] [G loss: 0.779272]\n",
      "epoch:15 step:12400[D loss: 0.471354, acc: 50.78%, op_acc: 38.28%] [G loss: 0.864290]\n",
      "epoch:15 step:12401[D loss: 0.418368, acc: 63.28%, op_acc: 35.94%] [G loss: 0.904594]\n",
      "epoch:15 step:12402[D loss: 0.410890, acc: 62.50%, op_acc: 37.50%] [G loss: 0.855707]\n",
      "epoch:15 step:12403[D loss: 0.423135, acc: 58.59%, op_acc: 35.94%] [G loss: 0.968148]\n",
      "epoch:15 step:12404[D loss: 0.429184, acc: 50.00%, op_acc: 41.41%] [G loss: 0.925723]\n",
      "epoch:15 step:12405[D loss: 0.406846, acc: 61.72%, op_acc: 41.41%] [G loss: 0.918715]\n",
      "epoch:15 step:12406[D loss: 0.415686, acc: 61.72%, op_acc: 36.72%] [G loss: 0.896501]\n",
      "epoch:15 step:12407[D loss: 0.454514, acc: 56.25%, op_acc: 35.16%] [G loss: 0.946986]\n",
      "epoch:15 step:12408[D loss: 0.417535, acc: 64.06%, op_acc: 35.94%] [G loss: 0.966580]\n",
      "epoch:15 step:12409[D loss: 0.429652, acc: 54.69%, op_acc: 37.50%] [G loss: 0.965673]\n",
      "epoch:15 step:12410[D loss: 0.445372, acc: 53.91%, op_acc: 32.03%] [G loss: 0.839919]\n",
      "epoch:15 step:12411[D loss: 0.410370, acc: 66.41%, op_acc: 45.31%] [G loss: 0.948314]\n",
      "epoch:15 step:12412[D loss: 0.408914, acc: 58.59%, op_acc: 40.62%] [G loss: 0.846230]\n",
      "epoch:15 step:12413[D loss: 0.444494, acc: 57.03%, op_acc: 37.50%] [G loss: 0.898241]\n",
      "epoch:15 step:12414[D loss: 0.385224, acc: 68.75%, op_acc: 41.41%] [G loss: 0.909638]\n",
      "epoch:15 step:12415[D loss: 0.437590, acc: 60.16%, op_acc: 37.50%] [G loss: 1.019608]\n",
      "epoch:15 step:12416[D loss: 0.457392, acc: 54.69%, op_acc: 34.38%] [G loss: 0.942002]\n",
      "epoch:15 step:12417[D loss: 0.414739, acc: 61.72%, op_acc: 38.28%] [G loss: 0.920084]\n",
      "epoch:15 step:12418[D loss: 0.424291, acc: 61.72%, op_acc: 39.06%] [G loss: 0.873039]\n",
      "epoch:15 step:12419[D loss: 0.413100, acc: 53.91%, op_acc: 45.31%] [G loss: 0.894691]\n",
      "epoch:15 step:12420[D loss: 0.440582, acc: 58.59%, op_acc: 39.84%] [G loss: 0.913080]\n",
      "epoch:15 step:12421[D loss: 0.446508, acc: 55.47%, op_acc: 36.72%] [G loss: 0.787183]\n",
      "epoch:15 step:12422[D loss: 0.447066, acc: 60.94%, op_acc: 32.03%] [G loss: 0.861258]\n",
      "epoch:15 step:12423[D loss: 0.433425, acc: 61.72%, op_acc: 36.72%] [G loss: 0.887646]\n",
      "epoch:15 step:12424[D loss: 0.420203, acc: 60.16%, op_acc: 39.84%] [G loss: 0.840140]\n",
      "epoch:15 step:12425[D loss: 0.387907, acc: 67.97%, op_acc: 48.44%] [G loss: 0.931170]\n",
      "epoch:15 step:12426[D loss: 0.427928, acc: 61.72%, op_acc: 35.94%] [G loss: 0.938336]\n",
      "epoch:15 step:12427[D loss: 0.432030, acc: 54.69%, op_acc: 39.06%] [G loss: 0.843014]\n",
      "epoch:15 step:12428[D loss: 0.416454, acc: 61.72%, op_acc: 37.50%] [G loss: 0.961006]\n",
      "epoch:15 step:12429[D loss: 0.443403, acc: 59.38%, op_acc: 34.38%] [G loss: 0.875631]\n",
      "epoch:15 step:12430[D loss: 0.439874, acc: 53.91%, op_acc: 35.16%] [G loss: 0.909572]\n",
      "epoch:15 step:12431[D loss: 0.458903, acc: 54.69%, op_acc: 36.72%] [G loss: 0.901386]\n",
      "epoch:15 step:12432[D loss: 0.423687, acc: 60.16%, op_acc: 42.19%] [G loss: 0.874047]\n",
      "epoch:15 step:12433[D loss: 0.424100, acc: 53.12%, op_acc: 37.50%] [G loss: 0.865026]\n",
      "epoch:15 step:12434[D loss: 0.425975, acc: 60.94%, op_acc: 41.41%] [G loss: 0.863774]\n",
      "epoch:15 step:12435[D loss: 0.445200, acc: 53.12%, op_acc: 39.84%] [G loss: 0.870918]\n",
      "epoch:15 step:12436[D loss: 0.465465, acc: 48.44%, op_acc: 39.06%] [G loss: 0.801230]\n",
      "epoch:15 step:12437[D loss: 0.431032, acc: 60.16%, op_acc: 37.50%] [G loss: 0.870569]\n",
      "epoch:15 step:12438[D loss: 0.435691, acc: 56.25%, op_acc: 38.28%] [G loss: 0.930626]\n",
      "epoch:15 step:12439[D loss: 0.482626, acc: 55.47%, op_acc: 34.38%] [G loss: 0.903759]\n",
      "epoch:15 step:12440[D loss: 0.407544, acc: 64.06%, op_acc: 35.16%] [G loss: 0.890190]\n",
      "epoch:15 step:12441[D loss: 0.419813, acc: 62.50%, op_acc: 35.16%] [G loss: 0.895368]\n",
      "epoch:15 step:12442[D loss: 0.450719, acc: 60.16%, op_acc: 29.69%] [G loss: 0.929455]\n",
      "epoch:15 step:12443[D loss: 0.439413, acc: 56.25%, op_acc: 37.50%] [G loss: 0.941012]\n",
      "epoch:15 step:12444[D loss: 0.419947, acc: 61.72%, op_acc: 38.28%] [G loss: 0.888556]\n",
      "epoch:15 step:12445[D loss: 0.459314, acc: 51.56%, op_acc: 31.25%] [G loss: 0.816104]\n",
      "epoch:15 step:12446[D loss: 0.418832, acc: 60.94%, op_acc: 41.41%] [G loss: 0.939832]\n",
      "epoch:15 step:12447[D loss: 0.443941, acc: 58.59%, op_acc: 35.16%] [G loss: 0.889347]\n",
      "epoch:15 step:12448[D loss: 0.453036, acc: 54.69%, op_acc: 33.59%] [G loss: 0.845156]\n",
      "epoch:15 step:12449[D loss: 0.446068, acc: 54.69%, op_acc: 35.94%] [G loss: 0.830422]\n",
      "epoch:15 step:12450[D loss: 0.437921, acc: 57.03%, op_acc: 37.50%] [G loss: 0.880152]\n",
      "epoch:15 step:12451[D loss: 0.422138, acc: 62.50%, op_acc: 36.72%] [G loss: 0.878269]\n",
      "epoch:15 step:12452[D loss: 0.434255, acc: 50.78%, op_acc: 45.31%] [G loss: 0.883083]\n",
      "epoch:15 step:12453[D loss: 0.456281, acc: 53.12%, op_acc: 37.50%] [G loss: 0.908567]\n",
      "epoch:15 step:12454[D loss: 0.395217, acc: 66.41%, op_acc: 41.41%] [G loss: 0.990268]\n",
      "epoch:15 step:12455[D loss: 0.452737, acc: 56.25%, op_acc: 36.72%] [G loss: 0.902730]\n",
      "epoch:15 step:12456[D loss: 0.450887, acc: 57.03%, op_acc: 39.06%] [G loss: 0.886662]\n",
      "epoch:15 step:12457[D loss: 0.405134, acc: 65.62%, op_acc: 36.72%] [G loss: 0.932549]\n",
      "epoch:15 step:12458[D loss: 0.438831, acc: 53.91%, op_acc: 35.16%] [G loss: 0.895293]\n",
      "epoch:15 step:12459[D loss: 0.388937, acc: 68.75%, op_acc: 44.53%] [G loss: 0.884465]\n",
      "epoch:15 step:12460[D loss: 0.415094, acc: 60.94%, op_acc: 42.97%] [G loss: 0.959161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:12461[D loss: 0.451802, acc: 56.25%, op_acc: 39.06%] [G loss: 0.878844]\n",
      "epoch:15 step:12462[D loss: 0.433963, acc: 55.47%, op_acc: 40.62%] [G loss: 0.853831]\n",
      "epoch:15 step:12463[D loss: 0.425419, acc: 60.16%, op_acc: 41.41%] [G loss: 0.962405]\n",
      "epoch:15 step:12464[D loss: 0.468040, acc: 57.03%, op_acc: 27.34%] [G loss: 0.897940]\n",
      "epoch:15 step:12465[D loss: 0.433806, acc: 54.69%, op_acc: 42.19%] [G loss: 0.828383]\n",
      "epoch:15 step:12466[D loss: 0.443455, acc: 61.72%, op_acc: 31.25%] [G loss: 0.867600]\n",
      "epoch:15 step:12467[D loss: 0.429719, acc: 67.97%, op_acc: 39.06%] [G loss: 0.854187]\n",
      "epoch:15 step:12468[D loss: 0.427936, acc: 55.47%, op_acc: 35.94%] [G loss: 0.845384]\n",
      "epoch:15 step:12469[D loss: 0.423602, acc: 57.81%, op_acc: 38.28%] [G loss: 0.876401]\n",
      "epoch:15 step:12470[D loss: 0.431527, acc: 64.84%, op_acc: 35.16%] [G loss: 0.808646]\n",
      "epoch:15 step:12471[D loss: 0.417566, acc: 56.25%, op_acc: 40.62%] [G loss: 0.913794]\n",
      "epoch:15 step:12472[D loss: 0.426646, acc: 57.03%, op_acc: 39.84%] [G loss: 0.887517]\n",
      "epoch:15 step:12473[D loss: 0.446398, acc: 57.81%, op_acc: 35.94%] [G loss: 0.874178]\n",
      "epoch:15 step:12474[D loss: 0.444717, acc: 57.03%, op_acc: 34.38%] [G loss: 0.857699]\n",
      "epoch:15 step:12475[D loss: 0.441309, acc: 57.81%, op_acc: 39.06%] [G loss: 0.928632]\n",
      "epoch:15 step:12476[D loss: 0.415609, acc: 57.03%, op_acc: 43.75%] [G loss: 0.915150]\n",
      "epoch:15 step:12477[D loss: 0.466788, acc: 53.91%, op_acc: 35.16%] [G loss: 0.919974]\n",
      "epoch:15 step:12478[D loss: 0.430635, acc: 60.16%, op_acc: 39.06%] [G loss: 0.876853]\n",
      "epoch:15 step:12479[D loss: 0.417125, acc: 63.28%, op_acc: 40.62%] [G loss: 0.842852]\n",
      "epoch:15 step:12480[D loss: 0.421692, acc: 60.94%, op_acc: 35.94%] [G loss: 0.842709]\n",
      "epoch:15 step:12481[D loss: 0.483262, acc: 54.69%, op_acc: 34.38%] [G loss: 0.878483]\n",
      "epoch:15 step:12482[D loss: 0.435956, acc: 57.03%, op_acc: 37.50%] [G loss: 0.887104]\n",
      "epoch:15 step:12483[D loss: 0.424642, acc: 58.59%, op_acc: 32.81%] [G loss: 0.950862]\n",
      "epoch:15 step:12484[D loss: 0.397505, acc: 61.72%, op_acc: 45.31%] [G loss: 0.981377]\n",
      "epoch:15 step:12485[D loss: 0.415218, acc: 64.84%, op_acc: 39.06%] [G loss: 0.939727]\n",
      "epoch:15 step:12486[D loss: 0.430667, acc: 61.72%, op_acc: 33.59%] [G loss: 0.882248]\n",
      "epoch:15 step:12487[D loss: 0.464927, acc: 50.00%, op_acc: 29.69%] [G loss: 0.847446]\n",
      "epoch:15 step:12488[D loss: 0.424449, acc: 66.41%, op_acc: 36.72%] [G loss: 0.890618]\n",
      "epoch:15 step:12489[D loss: 0.423569, acc: 60.94%, op_acc: 42.97%] [G loss: 0.871419]\n",
      "epoch:15 step:12490[D loss: 0.452529, acc: 50.78%, op_acc: 33.59%] [G loss: 0.818080]\n",
      "epoch:15 step:12491[D loss: 0.432753, acc: 53.12%, op_acc: 35.94%] [G loss: 0.876797]\n",
      "epoch:15 step:12492[D loss: 0.451978, acc: 59.38%, op_acc: 28.12%] [G loss: 0.863838]\n",
      "epoch:15 step:12493[D loss: 0.435817, acc: 54.69%, op_acc: 42.97%] [G loss: 0.799471]\n",
      "epoch:15 step:12494[D loss: 0.432909, acc: 57.03%, op_acc: 39.06%] [G loss: 0.862571]\n",
      "epoch:15 step:12495[D loss: 0.447788, acc: 51.56%, op_acc: 42.97%] [G loss: 0.842293]\n",
      "epoch:15 step:12496[D loss: 0.441124, acc: 53.12%, op_acc: 35.94%] [G loss: 0.874613]\n",
      "epoch:16 step:12497[D loss: 0.441482, acc: 58.59%, op_acc: 32.81%] [G loss: 0.940133]\n",
      "epoch:16 step:12498[D loss: 0.426605, acc: 57.81%, op_acc: 41.41%] [G loss: 0.831719]\n",
      "epoch:16 step:12499[D loss: 0.426078, acc: 63.28%, op_acc: 38.28%] [G loss: 0.834061]\n",
      "epoch:16 step:12500[D loss: 0.407770, acc: 61.72%, op_acc: 39.84%] [G loss: 0.881165]\n",
      "epoch:16 step:12501[D loss: 0.419983, acc: 64.06%, op_acc: 35.94%] [G loss: 0.901058]\n",
      "epoch:16 step:12502[D loss: 0.424992, acc: 60.94%, op_acc: 39.84%] [G loss: 0.896943]\n",
      "epoch:16 step:12503[D loss: 0.408996, acc: 66.41%, op_acc: 39.84%] [G loss: 0.805878]\n",
      "epoch:16 step:12504[D loss: 0.420040, acc: 60.94%, op_acc: 35.16%] [G loss: 0.865784]\n",
      "epoch:16 step:12505[D loss: 0.414071, acc: 57.03%, op_acc: 41.41%] [G loss: 0.882272]\n",
      "epoch:16 step:12506[D loss: 0.440484, acc: 63.28%, op_acc: 30.47%] [G loss: 0.810871]\n",
      "epoch:16 step:12507[D loss: 0.474680, acc: 55.47%, op_acc: 36.72%] [G loss: 0.789746]\n",
      "epoch:16 step:12508[D loss: 0.419657, acc: 57.81%, op_acc: 39.06%] [G loss: 0.884092]\n",
      "epoch:16 step:12509[D loss: 0.435870, acc: 60.94%, op_acc: 34.38%] [G loss: 0.869744]\n",
      "epoch:16 step:12510[D loss: 0.435041, acc: 60.94%, op_acc: 42.97%] [G loss: 0.875415]\n",
      "epoch:16 step:12511[D loss: 0.419839, acc: 57.81%, op_acc: 39.84%] [G loss: 0.843894]\n",
      "epoch:16 step:12512[D loss: 0.401481, acc: 63.28%, op_acc: 42.97%] [G loss: 0.949654]\n",
      "epoch:16 step:12513[D loss: 0.440133, acc: 58.59%, op_acc: 36.72%] [G loss: 0.904352]\n",
      "epoch:16 step:12514[D loss: 0.424180, acc: 60.16%, op_acc: 38.28%] [G loss: 0.894050]\n",
      "epoch:16 step:12515[D loss: 0.426922, acc: 56.25%, op_acc: 46.09%] [G loss: 0.813286]\n",
      "epoch:16 step:12516[D loss: 0.405190, acc: 66.41%, op_acc: 44.53%] [G loss: 0.935161]\n",
      "epoch:16 step:12517[D loss: 0.454526, acc: 55.47%, op_acc: 37.50%] [G loss: 0.856764]\n",
      "epoch:16 step:12518[D loss: 0.435484, acc: 56.25%, op_acc: 41.41%] [G loss: 0.829625]\n",
      "epoch:16 step:12519[D loss: 0.393660, acc: 65.62%, op_acc: 40.62%] [G loss: 0.860660]\n",
      "epoch:16 step:12520[D loss: 0.440438, acc: 54.69%, op_acc: 35.94%] [G loss: 0.865983]\n",
      "epoch:16 step:12521[D loss: 0.463058, acc: 50.00%, op_acc: 38.28%] [G loss: 0.865742]\n",
      "epoch:16 step:12522[D loss: 0.429966, acc: 57.81%, op_acc: 37.50%] [G loss: 0.872408]\n",
      "epoch:16 step:12523[D loss: 0.438444, acc: 57.03%, op_acc: 39.06%] [G loss: 0.886972]\n",
      "epoch:16 step:12524[D loss: 0.438708, acc: 60.16%, op_acc: 41.41%] [G loss: 0.925930]\n",
      "epoch:16 step:12525[D loss: 0.388507, acc: 67.97%, op_acc: 43.75%] [G loss: 0.907293]\n",
      "epoch:16 step:12526[D loss: 0.416695, acc: 63.28%, op_acc: 38.28%] [G loss: 0.931374]\n",
      "epoch:16 step:12527[D loss: 0.445634, acc: 57.03%, op_acc: 32.81%] [G loss: 0.850759]\n",
      "epoch:16 step:12528[D loss: 0.445063, acc: 53.12%, op_acc: 30.47%] [G loss: 0.921659]\n",
      "epoch:16 step:12529[D loss: 0.396804, acc: 64.06%, op_acc: 47.66%] [G loss: 0.888288]\n",
      "epoch:16 step:12530[D loss: 0.411594, acc: 61.72%, op_acc: 46.88%] [G loss: 0.984039]\n",
      "epoch:16 step:12531[D loss: 0.430179, acc: 60.16%, op_acc: 40.62%] [G loss: 0.879591]\n",
      "epoch:16 step:12532[D loss: 0.439324, acc: 54.69%, op_acc: 37.50%] [G loss: 0.878809]\n",
      "epoch:16 step:12533[D loss: 0.380951, acc: 71.88%, op_acc: 41.41%] [G loss: 0.868508]\n",
      "epoch:16 step:12534[D loss: 0.416876, acc: 57.81%, op_acc: 38.28%] [G loss: 0.843741]\n",
      "epoch:16 step:12535[D loss: 0.447991, acc: 55.47%, op_acc: 39.84%] [G loss: 0.879182]\n",
      "epoch:16 step:12536[D loss: 0.460314, acc: 50.78%, op_acc: 36.72%] [G loss: 0.872795]\n",
      "epoch:16 step:12537[D loss: 0.408739, acc: 61.72%, op_acc: 37.50%] [G loss: 0.907115]\n",
      "epoch:16 step:12538[D loss: 0.418683, acc: 52.34%, op_acc: 39.84%] [G loss: 0.913267]\n",
      "epoch:16 step:12539[D loss: 0.441562, acc: 54.69%, op_acc: 37.50%] [G loss: 0.863535]\n",
      "epoch:16 step:12540[D loss: 0.461614, acc: 48.44%, op_acc: 35.94%] [G loss: 0.833360]\n",
      "epoch:16 step:12541[D loss: 0.422189, acc: 63.28%, op_acc: 32.81%] [G loss: 0.904329]\n",
      "epoch:16 step:12542[D loss: 0.441036, acc: 53.91%, op_acc: 36.72%] [G loss: 0.924360]\n",
      "epoch:16 step:12543[D loss: 0.419248, acc: 60.94%, op_acc: 35.94%] [G loss: 0.912232]\n",
      "epoch:16 step:12544[D loss: 0.457761, acc: 64.84%, op_acc: 31.25%] [G loss: 0.927521]\n",
      "epoch:16 step:12545[D loss: 0.427195, acc: 66.41%, op_acc: 35.94%] [G loss: 0.917138]\n",
      "epoch:16 step:12546[D loss: 0.473229, acc: 48.44%, op_acc: 35.94%] [G loss: 0.813237]\n",
      "epoch:16 step:12547[D loss: 0.429018, acc: 60.16%, op_acc: 37.50%] [G loss: 0.909657]\n",
      "epoch:16 step:12548[D loss: 0.418989, acc: 62.50%, op_acc: 35.16%] [G loss: 0.864467]\n",
      "epoch:16 step:12549[D loss: 0.460895, acc: 57.03%, op_acc: 31.25%] [G loss: 0.901571]\n",
      "epoch:16 step:12550[D loss: 0.459838, acc: 57.81%, op_acc: 37.50%] [G loss: 0.887667]\n",
      "epoch:16 step:12551[D loss: 0.418161, acc: 59.38%, op_acc: 37.50%] [G loss: 0.872075]\n",
      "epoch:16 step:12552[D loss: 0.451883, acc: 53.91%, op_acc: 37.50%] [G loss: 0.824039]\n",
      "epoch:16 step:12553[D loss: 0.428654, acc: 59.38%, op_acc: 34.38%] [G loss: 0.849663]\n",
      "epoch:16 step:12554[D loss: 0.403393, acc: 65.62%, op_acc: 42.19%] [G loss: 0.829721]\n",
      "epoch:16 step:12555[D loss: 0.406706, acc: 60.94%, op_acc: 35.94%] [G loss: 0.938215]\n",
      "epoch:16 step:12556[D loss: 0.399096, acc: 65.62%, op_acc: 41.41%] [G loss: 0.976384]\n",
      "epoch:16 step:12557[D loss: 0.436345, acc: 55.47%, op_acc: 34.38%] [G loss: 0.792334]\n",
      "epoch:16 step:12558[D loss: 0.427587, acc: 61.72%, op_acc: 32.03%] [G loss: 0.804316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12559[D loss: 0.471952, acc: 50.00%, op_acc: 31.25%] [G loss: 0.808286]\n",
      "epoch:16 step:12560[D loss: 0.423828, acc: 61.72%, op_acc: 36.72%] [G loss: 0.845225]\n",
      "epoch:16 step:12561[D loss: 0.437113, acc: 62.50%, op_acc: 33.59%] [G loss: 0.840279]\n",
      "epoch:16 step:12562[D loss: 0.447794, acc: 58.59%, op_acc: 36.72%] [G loss: 0.822437]\n",
      "epoch:16 step:12563[D loss: 0.394249, acc: 66.41%, op_acc: 42.97%] [G loss: 0.985271]\n",
      "epoch:16 step:12564[D loss: 0.452950, acc: 55.47%, op_acc: 35.16%] [G loss: 0.862018]\n",
      "epoch:16 step:12565[D loss: 0.413491, acc: 61.72%, op_acc: 42.19%] [G loss: 0.937135]\n",
      "epoch:16 step:12566[D loss: 0.427422, acc: 54.69%, op_acc: 39.84%] [G loss: 0.878405]\n",
      "epoch:16 step:12567[D loss: 0.477480, acc: 57.81%, op_acc: 29.69%] [G loss: 0.877573]\n",
      "epoch:16 step:12568[D loss: 0.392075, acc: 70.31%, op_acc: 37.50%] [G loss: 0.883274]\n",
      "epoch:16 step:12569[D loss: 0.436248, acc: 60.94%, op_acc: 39.06%] [G loss: 0.978600]\n",
      "epoch:16 step:12570[D loss: 0.395312, acc: 63.28%, op_acc: 46.09%] [G loss: 0.985555]\n",
      "epoch:16 step:12571[D loss: 0.414008, acc: 64.06%, op_acc: 35.94%] [G loss: 0.867720]\n",
      "epoch:16 step:12572[D loss: 0.456023, acc: 51.56%, op_acc: 37.50%] [G loss: 0.827015]\n",
      "epoch:16 step:12573[D loss: 0.448903, acc: 53.91%, op_acc: 37.50%] [G loss: 0.850047]\n",
      "epoch:16 step:12574[D loss: 0.466267, acc: 60.16%, op_acc: 33.59%] [G loss: 0.909419]\n",
      "epoch:16 step:12575[D loss: 0.435389, acc: 57.81%, op_acc: 42.19%] [G loss: 0.922582]\n",
      "epoch:16 step:12576[D loss: 0.438625, acc: 60.94%, op_acc: 32.03%] [G loss: 0.871692]\n",
      "epoch:16 step:12577[D loss: 0.448727, acc: 57.81%, op_acc: 33.59%] [G loss: 0.888637]\n",
      "epoch:16 step:12578[D loss: 0.423963, acc: 59.38%, op_acc: 41.41%] [G loss: 0.900995]\n",
      "epoch:16 step:12579[D loss: 0.432695, acc: 64.06%, op_acc: 37.50%] [G loss: 0.930023]\n",
      "epoch:16 step:12580[D loss: 0.421465, acc: 64.06%, op_acc: 39.84%] [G loss: 0.844310]\n",
      "epoch:16 step:12581[D loss: 0.453670, acc: 61.72%, op_acc: 32.81%] [G loss: 0.836253]\n",
      "epoch:16 step:12582[D loss: 0.420192, acc: 60.16%, op_acc: 33.59%] [G loss: 0.869747]\n",
      "epoch:16 step:12583[D loss: 0.414756, acc: 66.41%, op_acc: 35.94%] [G loss: 0.849613]\n",
      "epoch:16 step:12584[D loss: 0.441997, acc: 57.81%, op_acc: 35.94%] [G loss: 0.931240]\n",
      "epoch:16 step:12585[D loss: 0.437340, acc: 55.47%, op_acc: 36.72%] [G loss: 0.835072]\n",
      "epoch:16 step:12586[D loss: 0.439517, acc: 58.59%, op_acc: 42.97%] [G loss: 0.834970]\n",
      "epoch:16 step:12587[D loss: 0.420168, acc: 58.59%, op_acc: 36.72%] [G loss: 0.900219]\n",
      "epoch:16 step:12588[D loss: 0.469773, acc: 55.47%, op_acc: 33.59%] [G loss: 0.841308]\n",
      "epoch:16 step:12589[D loss: 0.403922, acc: 60.16%, op_acc: 38.28%] [G loss: 0.872801]\n",
      "epoch:16 step:12590[D loss: 0.426864, acc: 56.25%, op_acc: 36.72%] [G loss: 0.825001]\n",
      "epoch:16 step:12591[D loss: 0.440029, acc: 58.59%, op_acc: 40.62%] [G loss: 0.854059]\n",
      "epoch:16 step:12592[D loss: 0.441841, acc: 58.59%, op_acc: 35.16%] [G loss: 0.843053]\n",
      "epoch:16 step:12593[D loss: 0.425087, acc: 55.47%, op_acc: 39.84%] [G loss: 0.768705]\n",
      "epoch:16 step:12594[D loss: 0.451030, acc: 56.25%, op_acc: 27.34%] [G loss: 0.885942]\n",
      "epoch:16 step:12595[D loss: 0.448721, acc: 60.16%, op_acc: 31.25%] [G loss: 0.900753]\n",
      "epoch:16 step:12596[D loss: 0.420404, acc: 63.28%, op_acc: 38.28%] [G loss: 0.947593]\n",
      "epoch:16 step:12597[D loss: 0.417544, acc: 57.03%, op_acc: 34.38%] [G loss: 0.944914]\n",
      "epoch:16 step:12598[D loss: 0.421780, acc: 60.16%, op_acc: 36.72%] [G loss: 0.919253]\n",
      "epoch:16 step:12599[D loss: 0.432992, acc: 62.50%, op_acc: 35.94%] [G loss: 0.812074]\n",
      "epoch:16 step:12600[D loss: 0.423209, acc: 59.38%, op_acc: 39.84%] [G loss: 0.819838]\n",
      "epoch:16 step:12601[D loss: 0.396489, acc: 65.62%, op_acc: 45.31%] [G loss: 0.929109]\n",
      "epoch:16 step:12602[D loss: 0.410994, acc: 50.78%, op_acc: 39.84%] [G loss: 0.954068]\n",
      "epoch:16 step:12603[D loss: 0.421501, acc: 62.50%, op_acc: 37.50%] [G loss: 0.863029]\n",
      "epoch:16 step:12604[D loss: 0.446916, acc: 55.47%, op_acc: 36.72%] [G loss: 0.838746]\n",
      "epoch:16 step:12605[D loss: 0.414287, acc: 63.28%, op_acc: 44.53%] [G loss: 0.835745]\n",
      "epoch:16 step:12606[D loss: 0.420764, acc: 63.28%, op_acc: 42.97%] [G loss: 0.869418]\n",
      "epoch:16 step:12607[D loss: 0.427889, acc: 64.06%, op_acc: 36.72%] [G loss: 0.844554]\n",
      "epoch:16 step:12608[D loss: 0.424885, acc: 60.16%, op_acc: 37.50%] [G loss: 0.965859]\n",
      "epoch:16 step:12609[D loss: 0.440536, acc: 58.59%, op_acc: 33.59%] [G loss: 0.927699]\n",
      "epoch:16 step:12610[D loss: 0.441747, acc: 59.38%, op_acc: 35.16%] [G loss: 0.899065]\n",
      "epoch:16 step:12611[D loss: 0.405500, acc: 60.94%, op_acc: 46.09%] [G loss: 0.907985]\n",
      "epoch:16 step:12612[D loss: 0.445825, acc: 55.47%, op_acc: 37.50%] [G loss: 0.859975]\n",
      "epoch:16 step:12613[D loss: 0.444921, acc: 52.34%, op_acc: 40.62%] [G loss: 0.849408]\n",
      "epoch:16 step:12614[D loss: 0.430335, acc: 51.56%, op_acc: 40.62%] [G loss: 0.821304]\n",
      "epoch:16 step:12615[D loss: 0.431865, acc: 64.06%, op_acc: 35.16%] [G loss: 0.917842]\n",
      "epoch:16 step:12616[D loss: 0.431654, acc: 60.16%, op_acc: 32.81%] [G loss: 0.902457]\n",
      "epoch:16 step:12617[D loss: 0.436635, acc: 61.72%, op_acc: 37.50%] [G loss: 0.841635]\n",
      "epoch:16 step:12618[D loss: 0.424152, acc: 57.81%, op_acc: 35.94%] [G loss: 0.859650]\n",
      "epoch:16 step:12619[D loss: 0.434371, acc: 60.94%, op_acc: 37.50%] [G loss: 0.853679]\n",
      "epoch:16 step:12620[D loss: 0.416330, acc: 60.16%, op_acc: 37.50%] [G loss: 0.903037]\n",
      "epoch:16 step:12621[D loss: 0.445072, acc: 59.38%, op_acc: 31.25%] [G loss: 0.871395]\n",
      "epoch:16 step:12622[D loss: 0.398511, acc: 64.84%, op_acc: 40.62%] [G loss: 0.880521]\n",
      "epoch:16 step:12623[D loss: 0.408659, acc: 62.50%, op_acc: 36.72%] [G loss: 0.855183]\n",
      "epoch:16 step:12624[D loss: 0.405788, acc: 64.84%, op_acc: 39.84%] [G loss: 0.931881]\n",
      "epoch:16 step:12625[D loss: 0.458927, acc: 57.81%, op_acc: 32.81%] [G loss: 0.875032]\n",
      "epoch:16 step:12626[D loss: 0.398208, acc: 64.06%, op_acc: 38.28%] [G loss: 0.923327]\n",
      "epoch:16 step:12627[D loss: 0.420384, acc: 57.81%, op_acc: 39.06%] [G loss: 0.887623]\n",
      "epoch:16 step:12628[D loss: 0.406277, acc: 62.50%, op_acc: 43.75%] [G loss: 0.848621]\n",
      "epoch:16 step:12629[D loss: 0.438470, acc: 61.72%, op_acc: 33.59%] [G loss: 0.971701]\n",
      "epoch:16 step:12630[D loss: 0.413459, acc: 64.84%, op_acc: 35.94%] [G loss: 0.896716]\n",
      "epoch:16 step:12631[D loss: 0.456952, acc: 53.12%, op_acc: 39.84%] [G loss: 0.911627]\n",
      "epoch:16 step:12632[D loss: 0.415463, acc: 63.28%, op_acc: 41.41%] [G loss: 0.885089]\n",
      "epoch:16 step:12633[D loss: 0.425121, acc: 63.28%, op_acc: 39.84%] [G loss: 0.913217]\n",
      "epoch:16 step:12634[D loss: 0.461457, acc: 47.66%, op_acc: 34.38%] [G loss: 0.925084]\n",
      "epoch:16 step:12635[D loss: 0.413653, acc: 65.62%, op_acc: 35.94%] [G loss: 0.915297]\n",
      "epoch:16 step:12636[D loss: 0.476736, acc: 53.91%, op_acc: 33.59%] [G loss: 0.900068]\n",
      "epoch:16 step:12637[D loss: 0.447391, acc: 64.06%, op_acc: 32.03%] [G loss: 0.934914]\n",
      "epoch:16 step:12638[D loss: 0.434696, acc: 56.25%, op_acc: 35.94%] [G loss: 0.846164]\n",
      "epoch:16 step:12639[D loss: 0.415492, acc: 64.06%, op_acc: 41.41%] [G loss: 0.877978]\n",
      "epoch:16 step:12640[D loss: 0.433711, acc: 55.47%, op_acc: 41.41%] [G loss: 0.868174]\n",
      "epoch:16 step:12641[D loss: 0.432863, acc: 52.34%, op_acc: 35.94%] [G loss: 0.828553]\n",
      "epoch:16 step:12642[D loss: 0.425623, acc: 58.59%, op_acc: 38.28%] [G loss: 0.844365]\n",
      "epoch:16 step:12643[D loss: 0.448567, acc: 50.00%, op_acc: 38.28%] [G loss: 0.885653]\n",
      "epoch:16 step:12644[D loss: 0.428917, acc: 67.19%, op_acc: 35.94%] [G loss: 0.845708]\n",
      "epoch:16 step:12645[D loss: 0.399394, acc: 65.62%, op_acc: 40.62%] [G loss: 0.842181]\n",
      "epoch:16 step:12646[D loss: 0.420046, acc: 60.94%, op_acc: 38.28%] [G loss: 0.825347]\n",
      "epoch:16 step:12647[D loss: 0.420528, acc: 55.47%, op_acc: 39.06%] [G loss: 0.903768]\n",
      "epoch:16 step:12648[D loss: 0.398729, acc: 62.50%, op_acc: 39.06%] [G loss: 0.875219]\n",
      "epoch:16 step:12649[D loss: 0.430293, acc: 62.50%, op_acc: 32.81%] [G loss: 0.855122]\n",
      "epoch:16 step:12650[D loss: 0.438215, acc: 59.38%, op_acc: 35.94%] [G loss: 0.901387]\n",
      "epoch:16 step:12651[D loss: 0.433090, acc: 58.59%, op_acc: 36.72%] [G loss: 0.858631]\n",
      "epoch:16 step:12652[D loss: 0.462300, acc: 50.78%, op_acc: 35.94%] [G loss: 0.855977]\n",
      "epoch:16 step:12653[D loss: 0.417804, acc: 66.41%, op_acc: 39.06%] [G loss: 0.913139]\n",
      "epoch:16 step:12654[D loss: 0.410546, acc: 64.84%, op_acc: 39.06%] [G loss: 0.866780]\n",
      "epoch:16 step:12655[D loss: 0.453646, acc: 51.56%, op_acc: 40.62%] [G loss: 0.878314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12656[D loss: 0.406531, acc: 66.41%, op_acc: 38.28%] [G loss: 0.812162]\n",
      "epoch:16 step:12657[D loss: 0.443810, acc: 54.69%, op_acc: 37.50%] [G loss: 0.815914]\n",
      "epoch:16 step:12658[D loss: 0.420462, acc: 58.59%, op_acc: 43.75%] [G loss: 0.881716]\n",
      "epoch:16 step:12659[D loss: 0.431112, acc: 64.06%, op_acc: 37.50%] [G loss: 0.866688]\n",
      "epoch:16 step:12660[D loss: 0.457904, acc: 57.81%, op_acc: 29.69%] [G loss: 0.902448]\n",
      "epoch:16 step:12661[D loss: 0.416531, acc: 57.03%, op_acc: 35.94%] [G loss: 0.976845]\n",
      "epoch:16 step:12662[D loss: 0.434242, acc: 58.59%, op_acc: 35.16%] [G loss: 0.866114]\n",
      "epoch:16 step:12663[D loss: 0.438727, acc: 64.06%, op_acc: 35.94%] [G loss: 0.906904]\n",
      "epoch:16 step:12664[D loss: 0.438329, acc: 51.56%, op_acc: 41.41%] [G loss: 0.920633]\n",
      "epoch:16 step:12665[D loss: 0.437828, acc: 57.03%, op_acc: 36.72%] [G loss: 0.913510]\n",
      "epoch:16 step:12666[D loss: 0.412857, acc: 60.94%, op_acc: 42.97%] [G loss: 0.885435]\n",
      "epoch:16 step:12667[D loss: 0.454006, acc: 56.25%, op_acc: 32.03%] [G loss: 0.908606]\n",
      "epoch:16 step:12668[D loss: 0.433396, acc: 57.03%, op_acc: 39.06%] [G loss: 0.897247]\n",
      "epoch:16 step:12669[D loss: 0.423555, acc: 64.06%, op_acc: 31.25%] [G loss: 0.830251]\n",
      "epoch:16 step:12670[D loss: 0.489862, acc: 49.22%, op_acc: 32.81%] [G loss: 0.895033]\n",
      "epoch:16 step:12671[D loss: 0.427699, acc: 60.94%, op_acc: 39.06%] [G loss: 0.863217]\n",
      "epoch:16 step:12672[D loss: 0.406135, acc: 61.72%, op_acc: 42.97%] [G loss: 0.879403]\n",
      "epoch:16 step:12673[D loss: 0.425864, acc: 64.06%, op_acc: 39.06%] [G loss: 0.892016]\n",
      "epoch:16 step:12674[D loss: 0.494249, acc: 42.19%, op_acc: 30.47%] [G loss: 0.810229]\n",
      "epoch:16 step:12675[D loss: 0.426922, acc: 59.38%, op_acc: 37.50%] [G loss: 0.887148]\n",
      "epoch:16 step:12676[D loss: 0.410066, acc: 67.97%, op_acc: 34.38%] [G loss: 0.891474]\n",
      "epoch:16 step:12677[D loss: 0.422459, acc: 57.81%, op_acc: 40.62%] [G loss: 0.867340]\n",
      "epoch:16 step:12678[D loss: 0.437469, acc: 57.03%, op_acc: 33.59%] [G loss: 0.888531]\n",
      "epoch:16 step:12679[D loss: 0.413879, acc: 63.28%, op_acc: 40.62%] [G loss: 0.952569]\n",
      "epoch:16 step:12680[D loss: 0.418931, acc: 61.72%, op_acc: 38.28%] [G loss: 0.890295]\n",
      "epoch:16 step:12681[D loss: 0.427803, acc: 62.50%, op_acc: 39.06%] [G loss: 0.874116]\n",
      "epoch:16 step:12682[D loss: 0.418897, acc: 64.84%, op_acc: 37.50%] [G loss: 0.926965]\n",
      "epoch:16 step:12683[D loss: 0.438925, acc: 57.03%, op_acc: 35.94%] [G loss: 0.885855]\n",
      "epoch:16 step:12684[D loss: 0.413304, acc: 62.50%, op_acc: 39.06%] [G loss: 0.917213]\n",
      "epoch:16 step:12685[D loss: 0.423429, acc: 62.50%, op_acc: 38.28%] [G loss: 0.946762]\n",
      "epoch:16 step:12686[D loss: 0.420817, acc: 61.72%, op_acc: 35.94%] [G loss: 0.983301]\n",
      "epoch:16 step:12687[D loss: 0.412548, acc: 59.38%, op_acc: 36.72%] [G loss: 0.841251]\n",
      "epoch:16 step:12688[D loss: 0.428165, acc: 64.84%, op_acc: 35.94%] [G loss: 0.911380]\n",
      "epoch:16 step:12689[D loss: 0.459707, acc: 53.91%, op_acc: 41.41%] [G loss: 0.893121]\n",
      "epoch:16 step:12690[D loss: 0.440003, acc: 59.38%, op_acc: 35.16%] [G loss: 0.903563]\n",
      "epoch:16 step:12691[D loss: 0.441198, acc: 57.03%, op_acc: 35.94%] [G loss: 0.923436]\n",
      "epoch:16 step:12692[D loss: 0.425310, acc: 66.41%, op_acc: 39.06%] [G loss: 0.890616]\n",
      "epoch:16 step:12693[D loss: 0.453687, acc: 57.81%, op_acc: 36.72%] [G loss: 0.809911]\n",
      "epoch:16 step:12694[D loss: 0.459241, acc: 54.69%, op_acc: 40.62%] [G loss: 0.845548]\n",
      "epoch:16 step:12695[D loss: 0.425759, acc: 58.59%, op_acc: 39.84%] [G loss: 0.900554]\n",
      "epoch:16 step:12696[D loss: 0.438566, acc: 55.47%, op_acc: 39.84%] [G loss: 0.933642]\n",
      "epoch:16 step:12697[D loss: 0.397040, acc: 63.28%, op_acc: 36.72%] [G loss: 0.900395]\n",
      "epoch:16 step:12698[D loss: 0.441018, acc: 58.59%, op_acc: 35.94%] [G loss: 0.900747]\n",
      "epoch:16 step:12699[D loss: 0.440610, acc: 62.50%, op_acc: 33.59%] [G loss: 0.812656]\n",
      "epoch:16 step:12700[D loss: 0.435499, acc: 59.38%, op_acc: 40.62%] [G loss: 0.842884]\n",
      "epoch:16 step:12701[D loss: 0.449813, acc: 54.69%, op_acc: 34.38%] [G loss: 0.783740]\n",
      "epoch:16 step:12702[D loss: 0.454464, acc: 53.91%, op_acc: 34.38%] [G loss: 0.848924]\n",
      "epoch:16 step:12703[D loss: 0.410254, acc: 62.50%, op_acc: 48.44%] [G loss: 0.904935]\n",
      "epoch:16 step:12704[D loss: 0.472904, acc: 54.69%, op_acc: 35.16%] [G loss: 0.939157]\n",
      "epoch:16 step:12705[D loss: 0.451009, acc: 48.44%, op_acc: 36.72%] [G loss: 0.890183]\n",
      "epoch:16 step:12706[D loss: 0.416818, acc: 61.72%, op_acc: 39.84%] [G loss: 0.917764]\n",
      "epoch:16 step:12707[D loss: 0.401691, acc: 67.19%, op_acc: 38.28%] [G loss: 0.883983]\n",
      "epoch:16 step:12708[D loss: 0.435058, acc: 59.38%, op_acc: 43.75%] [G loss: 0.993094]\n",
      "epoch:16 step:12709[D loss: 0.434505, acc: 58.59%, op_acc: 42.19%] [G loss: 0.958414]\n",
      "epoch:16 step:12710[D loss: 0.420389, acc: 62.50%, op_acc: 33.59%] [G loss: 0.794928]\n",
      "epoch:16 step:12711[D loss: 0.423548, acc: 67.19%, op_acc: 38.28%] [G loss: 0.900942]\n",
      "epoch:16 step:12712[D loss: 0.420377, acc: 66.41%, op_acc: 35.94%] [G loss: 0.921678]\n",
      "epoch:16 step:12713[D loss: 0.405692, acc: 62.50%, op_acc: 39.06%] [G loss: 0.926444]\n",
      "epoch:16 step:12714[D loss: 0.450143, acc: 56.25%, op_acc: 37.50%] [G loss: 0.910209]\n",
      "epoch:16 step:12715[D loss: 0.412645, acc: 60.94%, op_acc: 37.50%] [G loss: 0.923379]\n",
      "epoch:16 step:12716[D loss: 0.425915, acc: 63.28%, op_acc: 36.72%] [G loss: 0.988667]\n",
      "epoch:16 step:12717[D loss: 0.439192, acc: 56.25%, op_acc: 38.28%] [G loss: 0.840905]\n",
      "epoch:16 step:12718[D loss: 0.461003, acc: 53.91%, op_acc: 39.06%] [G loss: 0.894337]\n",
      "epoch:16 step:12719[D loss: 0.439919, acc: 61.72%, op_acc: 39.06%] [G loss: 0.825879]\n",
      "epoch:16 step:12720[D loss: 0.461176, acc: 50.00%, op_acc: 36.72%] [G loss: 0.816982]\n",
      "epoch:16 step:12721[D loss: 0.426962, acc: 63.28%, op_acc: 41.41%] [G loss: 0.963987]\n",
      "epoch:16 step:12722[D loss: 0.420298, acc: 62.50%, op_acc: 44.53%] [G loss: 0.923074]\n",
      "epoch:16 step:12723[D loss: 0.429203, acc: 61.72%, op_acc: 38.28%] [G loss: 0.853966]\n",
      "epoch:16 step:12724[D loss: 0.423402, acc: 60.94%, op_acc: 35.16%] [G loss: 0.943927]\n",
      "epoch:16 step:12725[D loss: 0.428041, acc: 58.59%, op_acc: 42.97%] [G loss: 0.932547]\n",
      "epoch:16 step:12726[D loss: 0.453805, acc: 55.47%, op_acc: 36.72%] [G loss: 0.954157]\n",
      "epoch:16 step:12727[D loss: 0.420268, acc: 56.25%, op_acc: 46.09%] [G loss: 0.871210]\n",
      "epoch:16 step:12728[D loss: 0.439791, acc: 57.03%, op_acc: 35.94%] [G loss: 0.878668]\n",
      "epoch:16 step:12729[D loss: 0.419335, acc: 64.06%, op_acc: 37.50%] [G loss: 0.890398]\n",
      "epoch:16 step:12730[D loss: 0.430636, acc: 63.28%, op_acc: 39.06%] [G loss: 0.993484]\n",
      "epoch:16 step:12731[D loss: 0.416913, acc: 61.72%, op_acc: 39.06%] [G loss: 0.899529]\n",
      "epoch:16 step:12732[D loss: 0.431006, acc: 57.81%, op_acc: 36.72%] [G loss: 0.910032]\n",
      "epoch:16 step:12733[D loss: 0.402326, acc: 64.84%, op_acc: 43.75%] [G loss: 0.907977]\n",
      "epoch:16 step:12734[D loss: 0.410798, acc: 65.62%, op_acc: 39.06%] [G loss: 0.905955]\n",
      "epoch:16 step:12735[D loss: 0.412508, acc: 63.28%, op_acc: 38.28%] [G loss: 0.909163]\n",
      "epoch:16 step:12736[D loss: 0.440404, acc: 50.00%, op_acc: 36.72%] [G loss: 0.827600]\n",
      "epoch:16 step:12737[D loss: 0.435226, acc: 62.50%, op_acc: 32.03%] [G loss: 0.852260]\n",
      "epoch:16 step:12738[D loss: 0.410427, acc: 60.94%, op_acc: 39.84%] [G loss: 0.874434]\n",
      "epoch:16 step:12739[D loss: 0.449350, acc: 52.34%, op_acc: 40.62%] [G loss: 0.914281]\n",
      "epoch:16 step:12740[D loss: 0.434105, acc: 63.28%, op_acc: 39.84%] [G loss: 0.844080]\n",
      "epoch:16 step:12741[D loss: 0.461733, acc: 51.56%, op_acc: 42.19%] [G loss: 0.880798]\n",
      "epoch:16 step:12742[D loss: 0.431842, acc: 61.72%, op_acc: 35.16%] [G loss: 0.891279]\n",
      "epoch:16 step:12743[D loss: 0.445309, acc: 52.34%, op_acc: 35.94%] [G loss: 0.888283]\n",
      "epoch:16 step:12744[D loss: 0.478879, acc: 48.44%, op_acc: 28.91%] [G loss: 0.816068]\n",
      "epoch:16 step:12745[D loss: 0.446635, acc: 57.81%, op_acc: 35.16%] [G loss: 0.838629]\n",
      "epoch:16 step:12746[D loss: 0.455965, acc: 57.03%, op_acc: 32.81%] [G loss: 0.800262]\n",
      "epoch:16 step:12747[D loss: 0.394484, acc: 69.53%, op_acc: 38.28%] [G loss: 0.828491]\n",
      "epoch:16 step:12748[D loss: 0.412931, acc: 63.28%, op_acc: 36.72%] [G loss: 0.911518]\n",
      "epoch:16 step:12749[D loss: 0.428770, acc: 63.28%, op_acc: 33.59%] [G loss: 0.869283]\n",
      "epoch:16 step:12750[D loss: 0.444887, acc: 59.38%, op_acc: 35.94%] [G loss: 0.905488]\n",
      "epoch:16 step:12751[D loss: 0.459518, acc: 47.66%, op_acc: 34.38%] [G loss: 0.931530]\n",
      "epoch:16 step:12752[D loss: 0.431360, acc: 58.59%, op_acc: 39.06%] [G loss: 0.864098]\n",
      "epoch:16 step:12753[D loss: 0.445480, acc: 54.69%, op_acc: 40.62%] [G loss: 0.852399]\n",
      "epoch:16 step:12754[D loss: 0.432772, acc: 60.16%, op_acc: 39.06%] [G loss: 1.006603]\n",
      "epoch:16 step:12755[D loss: 0.412564, acc: 65.62%, op_acc: 35.16%] [G loss: 0.885338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12756[D loss: 0.448318, acc: 55.47%, op_acc: 38.28%] [G loss: 0.904623]\n",
      "epoch:16 step:12757[D loss: 0.445422, acc: 60.16%, op_acc: 35.94%] [G loss: 0.963649]\n",
      "epoch:16 step:12758[D loss: 0.417584, acc: 61.72%, op_acc: 38.28%] [G loss: 0.972713]\n",
      "epoch:16 step:12759[D loss: 0.434472, acc: 63.28%, op_acc: 32.81%] [G loss: 0.901136]\n",
      "epoch:16 step:12760[D loss: 0.390581, acc: 73.44%, op_acc: 37.50%] [G loss: 0.932919]\n",
      "epoch:16 step:12761[D loss: 0.407106, acc: 65.62%, op_acc: 42.97%] [G loss: 0.996852]\n",
      "epoch:16 step:12762[D loss: 0.435835, acc: 56.25%, op_acc: 32.81%] [G loss: 0.951903]\n",
      "epoch:16 step:12763[D loss: 0.433276, acc: 55.47%, op_acc: 38.28%] [G loss: 1.009080]\n",
      "epoch:16 step:12764[D loss: 0.386797, acc: 68.75%, op_acc: 40.62%] [G loss: 0.859488]\n",
      "epoch:16 step:12765[D loss: 0.432393, acc: 53.12%, op_acc: 36.72%] [G loss: 0.920107]\n",
      "epoch:16 step:12766[D loss: 0.405179, acc: 64.06%, op_acc: 42.19%] [G loss: 0.984911]\n",
      "epoch:16 step:12767[D loss: 0.441209, acc: 59.38%, op_acc: 36.72%] [G loss: 0.937094]\n",
      "epoch:16 step:12768[D loss: 0.429227, acc: 61.72%, op_acc: 34.38%] [G loss: 0.910015]\n",
      "epoch:16 step:12769[D loss: 0.441818, acc: 49.22%, op_acc: 42.97%] [G loss: 0.866593]\n",
      "epoch:16 step:12770[D loss: 0.465940, acc: 50.00%, op_acc: 43.75%] [G loss: 0.833595]\n",
      "epoch:16 step:12771[D loss: 0.456005, acc: 51.56%, op_acc: 35.94%] [G loss: 0.901497]\n",
      "epoch:16 step:12772[D loss: 0.445984, acc: 54.69%, op_acc: 34.38%] [G loss: 0.882969]\n",
      "epoch:16 step:12773[D loss: 0.436601, acc: 64.84%, op_acc: 37.50%] [G loss: 0.807212]\n",
      "epoch:16 step:12774[D loss: 0.449816, acc: 60.16%, op_acc: 35.94%] [G loss: 0.909756]\n",
      "epoch:16 step:12775[D loss: 0.429378, acc: 63.28%, op_acc: 39.06%] [G loss: 0.888043]\n",
      "epoch:16 step:12776[D loss: 0.458433, acc: 47.66%, op_acc: 43.75%] [G loss: 0.810675]\n",
      "epoch:16 step:12777[D loss: 0.441398, acc: 52.34%, op_acc: 31.25%] [G loss: 0.880494]\n",
      "epoch:16 step:12778[D loss: 0.438625, acc: 62.50%, op_acc: 38.28%] [G loss: 0.915394]\n",
      "epoch:16 step:12779[D loss: 0.402562, acc: 67.19%, op_acc: 39.84%] [G loss: 0.860433]\n",
      "epoch:16 step:12780[D loss: 0.433714, acc: 59.38%, op_acc: 35.94%] [G loss: 0.892266]\n",
      "epoch:16 step:12781[D loss: 0.427692, acc: 64.06%, op_acc: 35.94%] [G loss: 0.953023]\n",
      "epoch:16 step:12782[D loss: 0.438832, acc: 64.84%, op_acc: 34.38%] [G loss: 0.900911]\n",
      "epoch:16 step:12783[D loss: 0.441428, acc: 57.81%, op_acc: 39.84%] [G loss: 0.829105]\n",
      "epoch:16 step:12784[D loss: 0.449989, acc: 53.12%, op_acc: 35.94%] [G loss: 0.913624]\n",
      "epoch:16 step:12785[D loss: 0.441863, acc: 58.59%, op_acc: 32.03%] [G loss: 0.816459]\n",
      "epoch:16 step:12786[D loss: 0.408949, acc: 71.88%, op_acc: 43.75%] [G loss: 0.853691]\n",
      "epoch:16 step:12787[D loss: 0.454271, acc: 56.25%, op_acc: 33.59%] [G loss: 0.868272]\n",
      "epoch:16 step:12788[D loss: 0.403412, acc: 64.84%, op_acc: 39.06%] [G loss: 0.917743]\n",
      "epoch:16 step:12789[D loss: 0.449931, acc: 52.34%, op_acc: 35.16%] [G loss: 0.855748]\n",
      "epoch:16 step:12790[D loss: 0.404719, acc: 70.31%, op_acc: 35.94%] [G loss: 0.917345]\n",
      "epoch:16 step:12791[D loss: 0.430201, acc: 63.28%, op_acc: 35.94%] [G loss: 0.897695]\n",
      "epoch:16 step:12792[D loss: 0.446368, acc: 53.12%, op_acc: 36.72%] [G loss: 0.901231]\n",
      "epoch:16 step:12793[D loss: 0.469822, acc: 57.03%, op_acc: 35.16%] [G loss: 0.876262]\n",
      "epoch:16 step:12794[D loss: 0.411119, acc: 67.19%, op_acc: 39.06%] [G loss: 0.839057]\n",
      "epoch:16 step:12795[D loss: 0.452116, acc: 55.47%, op_acc: 35.94%] [G loss: 0.859693]\n",
      "epoch:16 step:12796[D loss: 0.455407, acc: 55.47%, op_acc: 32.03%] [G loss: 0.817238]\n",
      "epoch:16 step:12797[D loss: 0.422420, acc: 62.50%, op_acc: 39.06%] [G loss: 0.866514]\n",
      "epoch:16 step:12798[D loss: 0.439928, acc: 60.16%, op_acc: 36.72%] [G loss: 0.825840]\n",
      "epoch:16 step:12799[D loss: 0.442928, acc: 57.03%, op_acc: 36.72%] [G loss: 0.876483]\n",
      "epoch:16 step:12800[D loss: 0.411139, acc: 57.81%, op_acc: 39.06%] [G loss: 0.924698]\n",
      "epoch:16 step:12801[D loss: 0.402612, acc: 61.72%, op_acc: 39.84%] [G loss: 0.880503]\n",
      "epoch:16 step:12802[D loss: 0.449268, acc: 60.16%, op_acc: 27.34%] [G loss: 0.886656]\n",
      "epoch:16 step:12803[D loss: 0.408610, acc: 65.62%, op_acc: 39.84%] [G loss: 0.852393]\n",
      "epoch:16 step:12804[D loss: 0.454841, acc: 61.72%, op_acc: 36.72%] [G loss: 0.842984]\n",
      "epoch:16 step:12805[D loss: 0.491343, acc: 52.34%, op_acc: 29.69%] [G loss: 0.791165]\n",
      "epoch:16 step:12806[D loss: 0.441882, acc: 57.81%, op_acc: 31.25%] [G loss: 0.890461]\n",
      "epoch:16 step:12807[D loss: 0.446957, acc: 60.16%, op_acc: 35.16%] [G loss: 0.842953]\n",
      "epoch:16 step:12808[D loss: 0.433564, acc: 58.59%, op_acc: 35.16%] [G loss: 0.969410]\n",
      "epoch:16 step:12809[D loss: 0.439543, acc: 59.38%, op_acc: 37.50%] [G loss: 0.852434]\n",
      "epoch:16 step:12810[D loss: 0.428349, acc: 64.06%, op_acc: 32.03%] [G loss: 0.899532]\n",
      "epoch:16 step:12811[D loss: 0.420948, acc: 60.16%, op_acc: 36.72%] [G loss: 0.926057]\n",
      "epoch:16 step:12812[D loss: 0.412407, acc: 67.97%, op_acc: 34.38%] [G loss: 0.944816]\n",
      "epoch:16 step:12813[D loss: 0.429510, acc: 56.25%, op_acc: 36.72%] [G loss: 0.882581]\n",
      "epoch:16 step:12814[D loss: 0.463064, acc: 54.69%, op_acc: 33.59%] [G loss: 0.883310]\n",
      "epoch:16 step:12815[D loss: 0.430371, acc: 57.81%, op_acc: 33.59%] [G loss: 0.871118]\n",
      "epoch:16 step:12816[D loss: 0.467066, acc: 50.00%, op_acc: 29.69%] [G loss: 0.887045]\n",
      "epoch:16 step:12817[D loss: 0.479605, acc: 47.66%, op_acc: 35.94%] [G loss: 0.890508]\n",
      "epoch:16 step:12818[D loss: 0.433858, acc: 56.25%, op_acc: 38.28%] [G loss: 0.818223]\n",
      "epoch:16 step:12819[D loss: 0.430799, acc: 57.81%, op_acc: 37.50%] [G loss: 0.990238]\n",
      "epoch:16 step:12820[D loss: 0.425941, acc: 66.41%, op_acc: 32.03%] [G loss: 0.904311]\n",
      "epoch:16 step:12821[D loss: 0.441949, acc: 60.16%, op_acc: 38.28%] [G loss: 0.882706]\n",
      "epoch:16 step:12822[D loss: 0.408876, acc: 63.28%, op_acc: 40.62%] [G loss: 0.977003]\n",
      "epoch:16 step:12823[D loss: 0.389501, acc: 67.97%, op_acc: 35.94%] [G loss: 0.886153]\n",
      "epoch:16 step:12824[D loss: 0.444690, acc: 56.25%, op_acc: 39.06%] [G loss: 0.945609]\n",
      "epoch:16 step:12825[D loss: 0.409457, acc: 65.62%, op_acc: 33.59%] [G loss: 0.865571]\n",
      "epoch:16 step:12826[D loss: 0.425340, acc: 60.94%, op_acc: 32.81%] [G loss: 0.828164]\n",
      "epoch:16 step:12827[D loss: 0.439505, acc: 58.59%, op_acc: 38.28%] [G loss: 0.975702]\n",
      "epoch:16 step:12828[D loss: 0.391872, acc: 70.31%, op_acc: 38.28%] [G loss: 0.850711]\n",
      "epoch:16 step:12829[D loss: 0.463393, acc: 56.25%, op_acc: 37.50%] [G loss: 0.881576]\n",
      "epoch:16 step:12830[D loss: 0.425099, acc: 55.47%, op_acc: 37.50%] [G loss: 0.934993]\n",
      "epoch:16 step:12831[D loss: 0.423371, acc: 57.81%, op_acc: 35.16%] [G loss: 0.939971]\n",
      "epoch:16 step:12832[D loss: 0.434919, acc: 63.28%, op_acc: 33.59%] [G loss: 0.904924]\n",
      "epoch:16 step:12833[D loss: 0.458083, acc: 53.91%, op_acc: 37.50%] [G loss: 0.943410]\n",
      "epoch:16 step:12834[D loss: 0.402970, acc: 61.72%, op_acc: 40.62%] [G loss: 0.930188]\n",
      "epoch:16 step:12835[D loss: 0.410295, acc: 68.75%, op_acc: 33.59%] [G loss: 0.925224]\n",
      "epoch:16 step:12836[D loss: 0.461582, acc: 57.03%, op_acc: 33.59%] [G loss: 0.791015]\n",
      "epoch:16 step:12837[D loss: 0.453573, acc: 52.34%, op_acc: 37.50%] [G loss: 0.899983]\n",
      "epoch:16 step:12838[D loss: 0.452279, acc: 58.59%, op_acc: 35.16%] [G loss: 0.910132]\n",
      "epoch:16 step:12839[D loss: 0.425407, acc: 63.28%, op_acc: 32.81%] [G loss: 0.920321]\n",
      "epoch:16 step:12840[D loss: 0.446031, acc: 60.94%, op_acc: 37.50%] [G loss: 0.883208]\n",
      "epoch:16 step:12841[D loss: 0.406348, acc: 63.28%, op_acc: 40.62%] [G loss: 0.923291]\n",
      "epoch:16 step:12842[D loss: 0.418005, acc: 54.69%, op_acc: 42.97%] [G loss: 0.893107]\n",
      "epoch:16 step:12843[D loss: 0.427610, acc: 58.59%, op_acc: 38.28%] [G loss: 0.948184]\n",
      "epoch:16 step:12844[D loss: 0.436260, acc: 63.28%, op_acc: 35.16%] [G loss: 0.927296]\n",
      "epoch:16 step:12845[D loss: 0.418721, acc: 68.75%, op_acc: 38.28%] [G loss: 0.879640]\n",
      "epoch:16 step:12846[D loss: 0.405473, acc: 66.41%, op_acc: 39.84%] [G loss: 0.927318]\n",
      "epoch:16 step:12847[D loss: 0.450192, acc: 52.34%, op_acc: 39.06%] [G loss: 0.859187]\n",
      "epoch:16 step:12848[D loss: 0.425395, acc: 65.62%, op_acc: 41.41%] [G loss: 0.880533]\n",
      "epoch:16 step:12849[D loss: 0.406881, acc: 57.81%, op_acc: 47.66%] [G loss: 0.919238]\n",
      "epoch:16 step:12850[D loss: 0.428757, acc: 59.38%, op_acc: 39.06%] [G loss: 0.917505]\n",
      "epoch:16 step:12851[D loss: 0.428971, acc: 65.62%, op_acc: 39.06%] [G loss: 0.882946]\n",
      "epoch:16 step:12852[D loss: 0.423126, acc: 58.59%, op_acc: 36.72%] [G loss: 0.854724]\n",
      "epoch:16 step:12853[D loss: 0.407916, acc: 69.53%, op_acc: 35.94%] [G loss: 0.968136]\n",
      "epoch:16 step:12854[D loss: 0.481375, acc: 52.34%, op_acc: 36.72%] [G loss: 0.896330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12855[D loss: 0.430362, acc: 64.06%, op_acc: 32.03%] [G loss: 0.833319]\n",
      "epoch:16 step:12856[D loss: 0.456941, acc: 48.44%, op_acc: 39.06%] [G loss: 0.867476]\n",
      "epoch:16 step:12857[D loss: 0.433264, acc: 60.94%, op_acc: 36.72%] [G loss: 0.882706]\n",
      "epoch:16 step:12858[D loss: 0.396364, acc: 67.19%, op_acc: 42.19%] [G loss: 0.876754]\n",
      "epoch:16 step:12859[D loss: 0.419760, acc: 63.28%, op_acc: 34.38%] [G loss: 0.960861]\n",
      "epoch:16 step:12860[D loss: 0.421375, acc: 62.50%, op_acc: 39.84%] [G loss: 0.881182]\n",
      "epoch:16 step:12861[D loss: 0.409915, acc: 60.16%, op_acc: 35.16%] [G loss: 0.925661]\n",
      "epoch:16 step:12862[D loss: 0.416802, acc: 57.81%, op_acc: 39.84%] [G loss: 0.965907]\n",
      "epoch:16 step:12863[D loss: 0.443428, acc: 60.94%, op_acc: 33.59%] [G loss: 0.948151]\n",
      "epoch:16 step:12864[D loss: 0.430496, acc: 67.19%, op_acc: 38.28%] [G loss: 0.891045]\n",
      "epoch:16 step:12865[D loss: 0.437883, acc: 57.81%, op_acc: 35.16%] [G loss: 0.927929]\n",
      "epoch:16 step:12866[D loss: 0.440943, acc: 60.94%, op_acc: 39.06%] [G loss: 0.927450]\n",
      "epoch:16 step:12867[D loss: 0.416974, acc: 57.03%, op_acc: 37.50%] [G loss: 0.889967]\n",
      "epoch:16 step:12868[D loss: 0.435847, acc: 55.47%, op_acc: 35.16%] [G loss: 0.843768]\n",
      "epoch:16 step:12869[D loss: 0.458204, acc: 53.91%, op_acc: 34.38%] [G loss: 0.891478]\n",
      "epoch:16 step:12870[D loss: 0.434241, acc: 54.69%, op_acc: 39.06%] [G loss: 0.885184]\n",
      "epoch:16 step:12871[D loss: 0.407999, acc: 69.53%, op_acc: 39.06%] [G loss: 0.959827]\n",
      "epoch:16 step:12872[D loss: 0.421216, acc: 66.41%, op_acc: 37.50%] [G loss: 0.806408]\n",
      "epoch:16 step:12873[D loss: 0.420536, acc: 64.06%, op_acc: 39.84%] [G loss: 0.858022]\n",
      "epoch:16 step:12874[D loss: 0.434911, acc: 64.06%, op_acc: 35.94%] [G loss: 0.884786]\n",
      "epoch:16 step:12875[D loss: 0.389078, acc: 74.22%, op_acc: 37.50%] [G loss: 0.862506]\n",
      "epoch:16 step:12876[D loss: 0.404832, acc: 67.97%, op_acc: 33.59%] [G loss: 0.916514]\n",
      "epoch:16 step:12877[D loss: 0.425796, acc: 64.84%, op_acc: 38.28%] [G loss: 0.933671]\n",
      "epoch:16 step:12878[D loss: 0.417119, acc: 59.38%, op_acc: 39.84%] [G loss: 0.880569]\n",
      "epoch:16 step:12879[D loss: 0.424681, acc: 57.81%, op_acc: 39.84%] [G loss: 0.882249]\n",
      "epoch:16 step:12880[D loss: 0.415082, acc: 65.62%, op_acc: 37.50%] [G loss: 0.958861]\n",
      "epoch:16 step:12881[D loss: 0.407901, acc: 59.38%, op_acc: 46.09%] [G loss: 0.805484]\n",
      "epoch:16 step:12882[D loss: 0.419766, acc: 60.16%, op_acc: 38.28%] [G loss: 0.922294]\n",
      "epoch:16 step:12883[D loss: 0.454613, acc: 53.12%, op_acc: 35.94%] [G loss: 0.802178]\n",
      "epoch:16 step:12884[D loss: 0.418383, acc: 67.97%, op_acc: 33.59%] [G loss: 0.863825]\n",
      "epoch:16 step:12885[D loss: 0.429630, acc: 59.38%, op_acc: 38.28%] [G loss: 0.877567]\n",
      "epoch:16 step:12886[D loss: 0.413992, acc: 64.06%, op_acc: 39.84%] [G loss: 0.995185]\n",
      "epoch:16 step:12887[D loss: 0.410639, acc: 62.50%, op_acc: 42.19%] [G loss: 0.893274]\n",
      "epoch:16 step:12888[D loss: 0.418151, acc: 58.59%, op_acc: 41.41%] [G loss: 0.841006]\n",
      "epoch:16 step:12889[D loss: 0.432443, acc: 64.06%, op_acc: 41.41%] [G loss: 0.941560]\n",
      "epoch:16 step:12890[D loss: 0.469612, acc: 52.34%, op_acc: 32.81%] [G loss: 0.885709]\n",
      "epoch:16 step:12891[D loss: 0.450005, acc: 58.59%, op_acc: 33.59%] [G loss: 0.962817]\n",
      "epoch:16 step:12892[D loss: 0.456124, acc: 53.12%, op_acc: 41.41%] [G loss: 0.923638]\n",
      "epoch:16 step:12893[D loss: 0.439915, acc: 53.12%, op_acc: 41.41%] [G loss: 0.859873]\n",
      "epoch:16 step:12894[D loss: 0.467488, acc: 51.56%, op_acc: 33.59%] [G loss: 0.992596]\n",
      "epoch:16 step:12895[D loss: 0.430170, acc: 61.72%, op_acc: 39.84%] [G loss: 0.774762]\n",
      "epoch:16 step:12896[D loss: 0.426726, acc: 53.12%, op_acc: 44.53%] [G loss: 0.975912]\n",
      "epoch:16 step:12897[D loss: 0.426037, acc: 61.72%, op_acc: 40.62%] [G loss: 0.902405]\n",
      "epoch:16 step:12898[D loss: 0.429628, acc: 60.94%, op_acc: 37.50%] [G loss: 0.902049]\n",
      "epoch:16 step:12899[D loss: 0.423406, acc: 64.06%, op_acc: 35.16%] [G loss: 0.916206]\n",
      "epoch:16 step:12900[D loss: 0.424136, acc: 61.72%, op_acc: 40.62%] [G loss: 0.943185]\n",
      "epoch:16 step:12901[D loss: 0.436822, acc: 63.28%, op_acc: 39.06%] [G loss: 0.930241]\n",
      "epoch:16 step:12902[D loss: 0.457779, acc: 50.00%, op_acc: 37.50%] [G loss: 0.906396]\n",
      "epoch:16 step:12903[D loss: 0.438370, acc: 55.47%, op_acc: 32.81%] [G loss: 0.847254]\n",
      "epoch:16 step:12904[D loss: 0.436511, acc: 51.56%, op_acc: 39.06%] [G loss: 0.861503]\n",
      "epoch:16 step:12905[D loss: 0.435354, acc: 59.38%, op_acc: 38.28%] [G loss: 0.900205]\n",
      "epoch:16 step:12906[D loss: 0.395091, acc: 66.41%, op_acc: 39.84%] [G loss: 0.907044]\n",
      "epoch:16 step:12907[D loss: 0.440497, acc: 57.03%, op_acc: 34.38%] [G loss: 0.928974]\n",
      "epoch:16 step:12908[D loss: 0.422139, acc: 60.94%, op_acc: 38.28%] [G loss: 0.842690]\n",
      "epoch:16 step:12909[D loss: 0.443946, acc: 55.47%, op_acc: 35.94%] [G loss: 0.866488]\n",
      "epoch:16 step:12910[D loss: 0.411177, acc: 66.41%, op_acc: 35.94%] [G loss: 0.905949]\n",
      "epoch:16 step:12911[D loss: 0.425462, acc: 59.38%, op_acc: 36.72%] [G loss: 0.869835]\n",
      "epoch:16 step:12912[D loss: 0.423876, acc: 54.69%, op_acc: 39.84%] [G loss: 0.909428]\n",
      "epoch:16 step:12913[D loss: 0.446339, acc: 57.81%, op_acc: 36.72%] [G loss: 0.905212]\n",
      "epoch:16 step:12914[D loss: 0.449025, acc: 54.69%, op_acc: 41.41%] [G loss: 0.934115]\n",
      "epoch:16 step:12915[D loss: 0.437574, acc: 60.16%, op_acc: 32.03%] [G loss: 0.848767]\n",
      "epoch:16 step:12916[D loss: 0.471135, acc: 46.09%, op_acc: 37.50%] [G loss: 1.007638]\n",
      "epoch:16 step:12917[D loss: 0.427874, acc: 63.28%, op_acc: 36.72%] [G loss: 0.981410]\n",
      "epoch:16 step:12918[D loss: 0.437754, acc: 53.91%, op_acc: 35.94%] [G loss: 0.849667]\n",
      "epoch:16 step:12919[D loss: 0.434302, acc: 61.72%, op_acc: 36.72%] [G loss: 0.922139]\n",
      "epoch:16 step:12920[D loss: 0.452885, acc: 49.22%, op_acc: 41.41%] [G loss: 0.842160]\n",
      "epoch:16 step:12921[D loss: 0.399139, acc: 64.84%, op_acc: 42.19%] [G loss: 0.918781]\n",
      "epoch:16 step:12922[D loss: 0.500145, acc: 49.22%, op_acc: 32.81%] [G loss: 0.913193]\n",
      "epoch:16 step:12923[D loss: 0.432210, acc: 60.94%, op_acc: 42.97%] [G loss: 0.931856]\n",
      "epoch:16 step:12924[D loss: 0.448157, acc: 53.91%, op_acc: 39.06%] [G loss: 0.894792]\n",
      "epoch:16 step:12925[D loss: 0.425296, acc: 58.59%, op_acc: 39.84%] [G loss: 0.863378]\n",
      "epoch:16 step:12926[D loss: 0.435756, acc: 60.16%, op_acc: 35.94%] [G loss: 0.886931]\n",
      "epoch:16 step:12927[D loss: 0.463856, acc: 55.47%, op_acc: 33.59%] [G loss: 0.859282]\n",
      "epoch:16 step:12928[D loss: 0.411283, acc: 60.94%, op_acc: 39.84%] [G loss: 0.833825]\n",
      "epoch:16 step:12929[D loss: 0.422110, acc: 64.84%, op_acc: 39.84%] [G loss: 0.828980]\n",
      "epoch:16 step:12930[D loss: 0.420210, acc: 59.38%, op_acc: 38.28%] [G loss: 0.815606]\n",
      "epoch:16 step:12931[D loss: 0.435768, acc: 53.12%, op_acc: 38.28%] [G loss: 0.904667]\n",
      "epoch:16 step:12932[D loss: 0.464341, acc: 54.69%, op_acc: 38.28%] [G loss: 0.846574]\n",
      "epoch:16 step:12933[D loss: 0.420415, acc: 67.97%, op_acc: 33.59%] [G loss: 0.891741]\n",
      "epoch:16 step:12934[D loss: 0.413850, acc: 61.72%, op_acc: 45.31%] [G loss: 0.868787]\n",
      "epoch:16 step:12935[D loss: 0.417502, acc: 64.06%, op_acc: 38.28%] [G loss: 0.874855]\n",
      "epoch:16 step:12936[D loss: 0.428305, acc: 60.16%, op_acc: 32.03%] [G loss: 0.912567]\n",
      "epoch:16 step:12937[D loss: 0.427385, acc: 61.72%, op_acc: 35.16%] [G loss: 0.889799]\n",
      "epoch:16 step:12938[D loss: 0.421124, acc: 60.16%, op_acc: 36.72%] [G loss: 0.891476]\n",
      "epoch:16 step:12939[D loss: 0.449888, acc: 54.69%, op_acc: 37.50%] [G loss: 0.863852]\n",
      "epoch:16 step:12940[D loss: 0.441368, acc: 54.69%, op_acc: 36.72%] [G loss: 0.869264]\n",
      "epoch:16 step:12941[D loss: 0.437789, acc: 61.72%, op_acc: 38.28%] [G loss: 0.824008]\n",
      "epoch:16 step:12942[D loss: 0.423737, acc: 59.38%, op_acc: 39.06%] [G loss: 0.933653]\n",
      "epoch:16 step:12943[D loss: 0.455283, acc: 60.16%, op_acc: 32.03%] [G loss: 0.812227]\n",
      "epoch:16 step:12944[D loss: 0.389643, acc: 67.97%, op_acc: 37.50%] [G loss: 0.915069]\n",
      "epoch:16 step:12945[D loss: 0.393168, acc: 71.88%, op_acc: 39.84%] [G loss: 0.962521]\n",
      "epoch:16 step:12946[D loss: 0.427573, acc: 59.38%, op_acc: 37.50%] [G loss: 0.875789]\n",
      "epoch:16 step:12947[D loss: 0.407941, acc: 59.38%, op_acc: 39.84%] [G loss: 0.919711]\n",
      "epoch:16 step:12948[D loss: 0.425812, acc: 57.03%, op_acc: 35.94%] [G loss: 0.845919]\n",
      "epoch:16 step:12949[D loss: 0.436334, acc: 47.66%, op_acc: 39.84%] [G loss: 0.924570]\n",
      "epoch:16 step:12950[D loss: 0.443061, acc: 56.25%, op_acc: 33.59%] [G loss: 0.971772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:12951[D loss: 0.424226, acc: 59.38%, op_acc: 39.84%] [G loss: 0.815799]\n",
      "epoch:16 step:12952[D loss: 0.420127, acc: 64.06%, op_acc: 38.28%] [G loss: 0.878049]\n",
      "epoch:16 step:12953[D loss: 0.420320, acc: 60.94%, op_acc: 38.28%] [G loss: 0.860783]\n",
      "epoch:16 step:12954[D loss: 0.417757, acc: 56.25%, op_acc: 41.41%] [G loss: 0.882099]\n",
      "epoch:16 step:12955[D loss: 0.430046, acc: 51.56%, op_acc: 39.84%] [G loss: 0.963089]\n",
      "epoch:16 step:12956[D loss: 0.449309, acc: 53.12%, op_acc: 38.28%] [G loss: 0.908293]\n",
      "epoch:16 step:12957[D loss: 0.446427, acc: 59.38%, op_acc: 28.91%] [G loss: 0.819252]\n",
      "epoch:16 step:12958[D loss: 0.443655, acc: 61.72%, op_acc: 35.16%] [G loss: 0.837525]\n",
      "epoch:16 step:12959[D loss: 0.432804, acc: 56.25%, op_acc: 41.41%] [G loss: 0.907042]\n",
      "epoch:16 step:12960[D loss: 0.441805, acc: 57.81%, op_acc: 36.72%] [G loss: 0.876208]\n",
      "epoch:16 step:12961[D loss: 0.443409, acc: 54.69%, op_acc: 35.16%] [G loss: 0.886609]\n",
      "epoch:16 step:12962[D loss: 0.399232, acc: 62.50%, op_acc: 40.62%] [G loss: 0.927755]\n",
      "epoch:16 step:12963[D loss: 0.432018, acc: 61.72%, op_acc: 35.16%] [G loss: 0.948262]\n",
      "epoch:16 step:12964[D loss: 0.418061, acc: 55.47%, op_acc: 39.84%] [G loss: 0.856556]\n",
      "epoch:16 step:12965[D loss: 0.401614, acc: 64.84%, op_acc: 35.16%] [G loss: 0.886574]\n",
      "epoch:16 step:12966[D loss: 0.414516, acc: 63.28%, op_acc: 37.50%] [G loss: 0.928028]\n",
      "epoch:16 step:12967[D loss: 0.444037, acc: 56.25%, op_acc: 36.72%] [G loss: 0.827978]\n",
      "epoch:16 step:12968[D loss: 0.432054, acc: 61.72%, op_acc: 35.94%] [G loss: 0.843778]\n",
      "epoch:16 step:12969[D loss: 0.412836, acc: 62.50%, op_acc: 42.97%] [G loss: 0.838342]\n",
      "epoch:16 step:12970[D loss: 0.425951, acc: 55.47%, op_acc: 39.06%] [G loss: 0.852635]\n",
      "epoch:16 step:12971[D loss: 0.425089, acc: 56.25%, op_acc: 40.62%] [G loss: 0.837001]\n",
      "epoch:16 step:12972[D loss: 0.449616, acc: 50.00%, op_acc: 37.50%] [G loss: 0.866925]\n",
      "epoch:16 step:12973[D loss: 0.428357, acc: 62.50%, op_acc: 39.84%] [G loss: 0.901477]\n",
      "epoch:16 step:12974[D loss: 0.420691, acc: 55.47%, op_acc: 37.50%] [G loss: 0.869723]\n",
      "epoch:16 step:12975[D loss: 0.432587, acc: 59.38%, op_acc: 34.38%] [G loss: 0.849975]\n",
      "epoch:16 step:12976[D loss: 0.454015, acc: 57.03%, op_acc: 32.03%] [G loss: 0.883086]\n",
      "epoch:16 step:12977[D loss: 0.460300, acc: 55.47%, op_acc: 35.16%] [G loss: 0.848794]\n",
      "epoch:16 step:12978[D loss: 0.419845, acc: 60.94%, op_acc: 35.94%] [G loss: 0.929602]\n",
      "epoch:16 step:12979[D loss: 0.435941, acc: 57.81%, op_acc: 39.06%] [G loss: 0.954835]\n",
      "epoch:16 step:12980[D loss: 0.385148, acc: 71.88%, op_acc: 40.62%] [G loss: 0.920899]\n",
      "epoch:16 step:12981[D loss: 0.430062, acc: 59.38%, op_acc: 36.72%] [G loss: 0.861064]\n",
      "epoch:16 step:12982[D loss: 0.410863, acc: 62.50%, op_acc: 40.62%] [G loss: 0.901839]\n",
      "epoch:16 step:12983[D loss: 0.397130, acc: 71.09%, op_acc: 39.06%] [G loss: 0.896222]\n",
      "epoch:16 step:12984[D loss: 0.451688, acc: 60.94%, op_acc: 34.38%] [G loss: 1.019604]\n",
      "epoch:16 step:12985[D loss: 0.447416, acc: 54.69%, op_acc: 38.28%] [G loss: 0.885386]\n",
      "epoch:16 step:12986[D loss: 0.412796, acc: 60.94%, op_acc: 37.50%] [G loss: 0.880690]\n",
      "epoch:16 step:12987[D loss: 0.468880, acc: 50.00%, op_acc: 35.16%] [G loss: 0.885416]\n",
      "epoch:16 step:12988[D loss: 0.424734, acc: 59.38%, op_acc: 39.06%] [G loss: 0.862928]\n",
      "epoch:16 step:12989[D loss: 0.431505, acc: 60.16%, op_acc: 32.03%] [G loss: 0.925947]\n",
      "epoch:16 step:12990[D loss: 0.407144, acc: 67.19%, op_acc: 34.38%] [G loss: 0.948884]\n",
      "epoch:16 step:12991[D loss: 0.402259, acc: 67.19%, op_acc: 41.41%] [G loss: 0.944937]\n",
      "epoch:16 step:12992[D loss: 0.438598, acc: 58.59%, op_acc: 36.72%] [G loss: 0.884047]\n",
      "epoch:16 step:12993[D loss: 0.431302, acc: 56.25%, op_acc: 36.72%] [G loss: 0.950422]\n",
      "epoch:16 step:12994[D loss: 0.449551, acc: 59.38%, op_acc: 35.94%] [G loss: 0.927487]\n",
      "epoch:16 step:12995[D loss: 0.419547, acc: 64.06%, op_acc: 35.16%] [G loss: 0.976063]\n",
      "epoch:16 step:12996[D loss: 0.419026, acc: 59.38%, op_acc: 39.84%] [G loss: 0.881461]\n",
      "epoch:16 step:12997[D loss: 0.458435, acc: 57.81%, op_acc: 31.25%] [G loss: 0.918730]\n",
      "epoch:16 step:12998[D loss: 0.434028, acc: 54.69%, op_acc: 39.84%] [G loss: 0.895433]\n",
      "epoch:16 step:12999[D loss: 0.437982, acc: 53.91%, op_acc: 35.94%] [G loss: 0.893492]\n",
      "epoch:16 step:13000[D loss: 0.455786, acc: 51.56%, op_acc: 39.84%] [G loss: 0.831037]\n",
      "epoch:16 step:13001[D loss: 0.425291, acc: 64.06%, op_acc: 34.38%] [G loss: 0.926284]\n",
      "epoch:16 step:13002[D loss: 0.452654, acc: 53.12%, op_acc: 41.41%] [G loss: 0.869996]\n",
      "epoch:16 step:13003[D loss: 0.440051, acc: 56.25%, op_acc: 39.84%] [G loss: 0.918435]\n",
      "epoch:16 step:13004[D loss: 0.435383, acc: 59.38%, op_acc: 37.50%] [G loss: 0.954746]\n",
      "epoch:16 step:13005[D loss: 0.486176, acc: 46.88%, op_acc: 33.59%] [G loss: 0.888998]\n",
      "epoch:16 step:13006[D loss: 0.423270, acc: 63.28%, op_acc: 42.19%] [G loss: 0.933537]\n",
      "epoch:16 step:13007[D loss: 0.433997, acc: 55.47%, op_acc: 41.41%] [G loss: 0.886869]\n",
      "epoch:16 step:13008[D loss: 0.440146, acc: 61.72%, op_acc: 33.59%] [G loss: 0.830364]\n",
      "epoch:16 step:13009[D loss: 0.438066, acc: 62.50%, op_acc: 41.41%] [G loss: 0.850612]\n",
      "epoch:16 step:13010[D loss: 0.426629, acc: 60.94%, op_acc: 37.50%] [G loss: 0.854593]\n",
      "epoch:16 step:13011[D loss: 0.457710, acc: 56.25%, op_acc: 34.38%] [G loss: 0.814226]\n",
      "epoch:16 step:13012[D loss: 0.443556, acc: 56.25%, op_acc: 35.94%] [G loss: 0.911607]\n",
      "epoch:16 step:13013[D loss: 0.448962, acc: 63.28%, op_acc: 32.03%] [G loss: 0.829803]\n",
      "epoch:16 step:13014[D loss: 0.386089, acc: 65.62%, op_acc: 40.62%] [G loss: 0.892694]\n",
      "epoch:16 step:13015[D loss: 0.407669, acc: 63.28%, op_acc: 38.28%] [G loss: 0.901460]\n",
      "epoch:16 step:13016[D loss: 0.461331, acc: 49.22%, op_acc: 39.84%] [G loss: 0.897546]\n",
      "epoch:16 step:13017[D loss: 0.419529, acc: 66.41%, op_acc: 39.06%] [G loss: 0.972785]\n",
      "epoch:16 step:13018[D loss: 0.446105, acc: 53.12%, op_acc: 33.59%] [G loss: 0.798622]\n",
      "epoch:16 step:13019[D loss: 0.446452, acc: 56.25%, op_acc: 31.25%] [G loss: 0.918227]\n",
      "epoch:16 step:13020[D loss: 0.407139, acc: 70.31%, op_acc: 39.84%] [G loss: 0.899877]\n",
      "epoch:16 step:13021[D loss: 0.409100, acc: 71.09%, op_acc: 31.25%] [G loss: 0.993489]\n",
      "epoch:16 step:13022[D loss: 0.450298, acc: 60.16%, op_acc: 29.69%] [G loss: 0.911864]\n",
      "epoch:16 step:13023[D loss: 0.439196, acc: 60.16%, op_acc: 39.06%] [G loss: 0.851977]\n",
      "epoch:16 step:13024[D loss: 0.431991, acc: 57.03%, op_acc: 43.75%] [G loss: 0.906921]\n",
      "epoch:16 step:13025[D loss: 0.409125, acc: 63.28%, op_acc: 45.31%] [G loss: 0.961333]\n",
      "epoch:16 step:13026[D loss: 0.433516, acc: 59.38%, op_acc: 36.72%] [G loss: 0.884935]\n",
      "epoch:16 step:13027[D loss: 0.433313, acc: 62.50%, op_acc: 35.16%] [G loss: 0.911231]\n",
      "epoch:16 step:13028[D loss: 0.447041, acc: 54.69%, op_acc: 40.62%] [G loss: 0.897093]\n",
      "epoch:16 step:13029[D loss: 0.414895, acc: 63.28%, op_acc: 35.16%] [G loss: 0.895331]\n",
      "epoch:16 step:13030[D loss: 0.404129, acc: 67.19%, op_acc: 45.31%] [G loss: 0.889798]\n",
      "epoch:16 step:13031[D loss: 0.454075, acc: 58.59%, op_acc: 31.25%] [G loss: 0.874545]\n",
      "epoch:16 step:13032[D loss: 0.388744, acc: 68.75%, op_acc: 44.53%] [G loss: 0.858368]\n",
      "epoch:16 step:13033[D loss: 0.451521, acc: 57.81%, op_acc: 36.72%] [G loss: 0.912170]\n",
      "epoch:16 step:13034[D loss: 0.408429, acc: 63.28%, op_acc: 38.28%] [G loss: 0.958404]\n",
      "epoch:16 step:13035[D loss: 0.436844, acc: 60.94%, op_acc: 34.38%] [G loss: 0.921331]\n",
      "epoch:16 step:13036[D loss: 0.436164, acc: 51.56%, op_acc: 39.06%] [G loss: 0.793299]\n",
      "epoch:16 step:13037[D loss: 0.404159, acc: 65.62%, op_acc: 39.06%] [G loss: 0.952336]\n",
      "epoch:16 step:13038[D loss: 0.431116, acc: 63.28%, op_acc: 34.38%] [G loss: 0.933820]\n",
      "epoch:16 step:13039[D loss: 0.420455, acc: 60.94%, op_acc: 38.28%] [G loss: 0.898591]\n",
      "epoch:16 step:13040[D loss: 0.461482, acc: 53.12%, op_acc: 37.50%] [G loss: 0.798887]\n",
      "epoch:16 step:13041[D loss: 0.398827, acc: 65.62%, op_acc: 42.19%] [G loss: 0.961406]\n",
      "epoch:16 step:13042[D loss: 0.440833, acc: 62.50%, op_acc: 35.16%] [G loss: 0.867316]\n",
      "epoch:16 step:13043[D loss: 0.436158, acc: 58.59%, op_acc: 37.50%] [G loss: 0.887775]\n",
      "epoch:16 step:13044[D loss: 0.467616, acc: 51.56%, op_acc: 32.03%] [G loss: 0.837634]\n",
      "epoch:16 step:13045[D loss: 0.432212, acc: 62.50%, op_acc: 35.94%] [G loss: 0.862901]\n",
      "epoch:16 step:13046[D loss: 0.417747, acc: 61.72%, op_acc: 37.50%] [G loss: 0.910589]\n",
      "epoch:16 step:13047[D loss: 0.405362, acc: 57.03%, op_acc: 39.84%] [G loss: 0.903980]\n",
      "epoch:16 step:13048[D loss: 0.462900, acc: 52.34%, op_acc: 32.03%] [G loss: 0.835765]\n",
      "epoch:16 step:13049[D loss: 0.442291, acc: 55.47%, op_acc: 38.28%] [G loss: 0.857744]\n",
      "epoch:16 step:13050[D loss: 0.462150, acc: 56.25%, op_acc: 36.72%] [G loss: 0.867801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13051[D loss: 0.415851, acc: 61.72%, op_acc: 39.06%] [G loss: 0.943761]\n",
      "epoch:16 step:13052[D loss: 0.463957, acc: 47.66%, op_acc: 35.94%] [G loss: 0.835729]\n",
      "epoch:16 step:13053[D loss: 0.456131, acc: 55.47%, op_acc: 37.50%] [G loss: 0.841949]\n",
      "epoch:16 step:13054[D loss: 0.419180, acc: 63.28%, op_acc: 41.41%] [G loss: 0.865654]\n",
      "epoch:16 step:13055[D loss: 0.390854, acc: 71.09%, op_acc: 35.16%] [G loss: 0.928175]\n",
      "epoch:16 step:13056[D loss: 0.469422, acc: 54.69%, op_acc: 32.81%] [G loss: 0.842282]\n",
      "epoch:16 step:13057[D loss: 0.408475, acc: 63.28%, op_acc: 42.97%] [G loss: 0.947764]\n",
      "epoch:16 step:13058[D loss: 0.453609, acc: 53.91%, op_acc: 35.94%] [G loss: 0.879328]\n",
      "epoch:16 step:13059[D loss: 0.445926, acc: 61.72%, op_acc: 32.81%] [G loss: 0.905212]\n",
      "epoch:16 step:13060[D loss: 0.435224, acc: 57.03%, op_acc: 42.19%] [G loss: 0.904199]\n",
      "epoch:16 step:13061[D loss: 0.408526, acc: 63.28%, op_acc: 37.50%] [G loss: 0.924773]\n",
      "epoch:16 step:13062[D loss: 0.420246, acc: 62.50%, op_acc: 37.50%] [G loss: 0.927270]\n",
      "epoch:16 step:13063[D loss: 0.440189, acc: 57.03%, op_acc: 41.41%] [G loss: 0.897061]\n",
      "epoch:16 step:13064[D loss: 0.408126, acc: 66.41%, op_acc: 41.41%] [G loss: 0.943266]\n",
      "epoch:16 step:13065[D loss: 0.415767, acc: 64.84%, op_acc: 36.72%] [G loss: 0.948301]\n",
      "epoch:16 step:13066[D loss: 0.439185, acc: 59.38%, op_acc: 35.16%] [G loss: 0.875564]\n",
      "epoch:16 step:13067[D loss: 0.441811, acc: 56.25%, op_acc: 42.19%] [G loss: 0.872625]\n",
      "epoch:16 step:13068[D loss: 0.410615, acc: 57.81%, op_acc: 41.41%] [G loss: 0.946618]\n",
      "epoch:16 step:13069[D loss: 0.451171, acc: 55.47%, op_acc: 39.06%] [G loss: 0.966945]\n",
      "epoch:16 step:13070[D loss: 0.462768, acc: 63.28%, op_acc: 38.28%] [G loss: 0.905993]\n",
      "epoch:16 step:13071[D loss: 0.444236, acc: 57.81%, op_acc: 34.38%] [G loss: 0.838404]\n",
      "epoch:16 step:13072[D loss: 0.444840, acc: 55.47%, op_acc: 39.06%] [G loss: 0.909882]\n",
      "epoch:16 step:13073[D loss: 0.447652, acc: 61.72%, op_acc: 39.06%] [G loss: 0.854522]\n",
      "epoch:16 step:13074[D loss: 0.434426, acc: 64.84%, op_acc: 36.72%] [G loss: 0.867751]\n",
      "epoch:16 step:13075[D loss: 0.426373, acc: 55.47%, op_acc: 41.41%] [G loss: 0.867934]\n",
      "epoch:16 step:13076[D loss: 0.465723, acc: 51.56%, op_acc: 33.59%] [G loss: 0.848956]\n",
      "epoch:16 step:13077[D loss: 0.429182, acc: 64.06%, op_acc: 34.38%] [G loss: 0.832637]\n",
      "epoch:16 step:13078[D loss: 0.431993, acc: 57.81%, op_acc: 37.50%] [G loss: 0.888611]\n",
      "epoch:16 step:13079[D loss: 0.407735, acc: 60.94%, op_acc: 38.28%] [G loss: 0.892444]\n",
      "epoch:16 step:13080[D loss: 0.438397, acc: 61.72%, op_acc: 35.94%] [G loss: 0.899474]\n",
      "epoch:16 step:13081[D loss: 0.409604, acc: 67.19%, op_acc: 39.84%] [G loss: 0.901697]\n",
      "epoch:16 step:13082[D loss: 0.453490, acc: 60.94%, op_acc: 33.59%] [G loss: 0.867975]\n",
      "epoch:16 step:13083[D loss: 0.419066, acc: 65.62%, op_acc: 36.72%] [G loss: 0.879182]\n",
      "epoch:16 step:13084[D loss: 0.436499, acc: 56.25%, op_acc: 39.06%] [G loss: 0.864708]\n",
      "epoch:16 step:13085[D loss: 0.430875, acc: 64.84%, op_acc: 36.72%] [G loss: 0.891843]\n",
      "epoch:16 step:13086[D loss: 0.435263, acc: 59.38%, op_acc: 34.38%] [G loss: 0.877880]\n",
      "epoch:16 step:13087[D loss: 0.435533, acc: 57.03%, op_acc: 35.94%] [G loss: 0.806180]\n",
      "epoch:16 step:13088[D loss: 0.420433, acc: 60.16%, op_acc: 39.84%] [G loss: 0.857897]\n",
      "epoch:16 step:13089[D loss: 0.464750, acc: 57.81%, op_acc: 30.47%] [G loss: 0.927388]\n",
      "epoch:16 step:13090[D loss: 0.443908, acc: 51.56%, op_acc: 35.94%] [G loss: 0.893636]\n",
      "epoch:16 step:13091[D loss: 0.432295, acc: 60.94%, op_acc: 38.28%] [G loss: 0.840646]\n",
      "epoch:16 step:13092[D loss: 0.435006, acc: 60.16%, op_acc: 33.59%] [G loss: 0.909927]\n",
      "epoch:16 step:13093[D loss: 0.418669, acc: 62.50%, op_acc: 36.72%] [G loss: 0.841735]\n",
      "epoch:16 step:13094[D loss: 0.400926, acc: 67.97%, op_acc: 35.16%] [G loss: 0.918544]\n",
      "epoch:16 step:13095[D loss: 0.414366, acc: 63.28%, op_acc: 37.50%] [G loss: 0.917815]\n",
      "epoch:16 step:13096[D loss: 0.435819, acc: 64.06%, op_acc: 33.59%] [G loss: 1.006729]\n",
      "epoch:16 step:13097[D loss: 0.427471, acc: 60.94%, op_acc: 41.41%] [G loss: 0.898773]\n",
      "epoch:16 step:13098[D loss: 0.393070, acc: 65.62%, op_acc: 42.97%] [G loss: 0.915972]\n",
      "epoch:16 step:13099[D loss: 0.377110, acc: 71.88%, op_acc: 42.97%] [G loss: 0.935960]\n",
      "epoch:16 step:13100[D loss: 0.473661, acc: 51.56%, op_acc: 33.59%] [G loss: 0.925315]\n",
      "epoch:16 step:13101[D loss: 0.411457, acc: 66.41%, op_acc: 39.06%] [G loss: 0.852238]\n",
      "epoch:16 step:13102[D loss: 0.423326, acc: 65.62%, op_acc: 38.28%] [G loss: 0.899667]\n",
      "epoch:16 step:13103[D loss: 0.410344, acc: 60.94%, op_acc: 40.62%] [G loss: 0.950642]\n",
      "epoch:16 step:13104[D loss: 0.382435, acc: 68.75%, op_acc: 44.53%] [G loss: 0.896798]\n",
      "epoch:16 step:13105[D loss: 0.430140, acc: 59.38%, op_acc: 42.97%] [G loss: 0.869208]\n",
      "epoch:16 step:13106[D loss: 0.442838, acc: 53.12%, op_acc: 36.72%] [G loss: 0.920959]\n",
      "epoch:16 step:13107[D loss: 0.427186, acc: 64.06%, op_acc: 37.50%] [G loss: 0.831982]\n",
      "epoch:16 step:13108[D loss: 0.411121, acc: 64.06%, op_acc: 39.06%] [G loss: 0.917927]\n",
      "epoch:16 step:13109[D loss: 0.416720, acc: 64.06%, op_acc: 40.62%] [G loss: 0.913323]\n",
      "epoch:16 step:13110[D loss: 0.440349, acc: 53.12%, op_acc: 38.28%] [G loss: 0.752040]\n",
      "epoch:16 step:13111[D loss: 0.419911, acc: 67.97%, op_acc: 35.16%] [G loss: 0.865547]\n",
      "epoch:16 step:13112[D loss: 0.451401, acc: 53.12%, op_acc: 39.06%] [G loss: 0.834433]\n",
      "epoch:16 step:13113[D loss: 0.452400, acc: 55.47%, op_acc: 34.38%] [G loss: 0.860092]\n",
      "epoch:16 step:13114[D loss: 0.398654, acc: 60.94%, op_acc: 43.75%] [G loss: 0.903797]\n",
      "epoch:16 step:13115[D loss: 0.452946, acc: 57.03%, op_acc: 35.94%] [G loss: 0.884961]\n",
      "epoch:16 step:13116[D loss: 0.419771, acc: 64.84%, op_acc: 35.94%] [G loss: 0.837608]\n",
      "epoch:16 step:13117[D loss: 0.426296, acc: 64.06%, op_acc: 39.06%] [G loss: 0.941600]\n",
      "epoch:16 step:13118[D loss: 0.468672, acc: 57.81%, op_acc: 33.59%] [G loss: 0.823357]\n",
      "epoch:16 step:13119[D loss: 0.432602, acc: 63.28%, op_acc: 37.50%] [G loss: 0.844046]\n",
      "epoch:16 step:13120[D loss: 0.443217, acc: 55.47%, op_acc: 36.72%] [G loss: 0.838760]\n",
      "epoch:16 step:13121[D loss: 0.457318, acc: 51.56%, op_acc: 38.28%] [G loss: 0.833586]\n",
      "epoch:16 step:13122[D loss: 0.425085, acc: 53.91%, op_acc: 40.62%] [G loss: 0.891864]\n",
      "epoch:16 step:13123[D loss: 0.444340, acc: 53.12%, op_acc: 39.06%] [G loss: 0.828806]\n",
      "epoch:16 step:13124[D loss: 0.453078, acc: 60.16%, op_acc: 37.50%] [G loss: 0.860351]\n",
      "epoch:16 step:13125[D loss: 0.428505, acc: 69.53%, op_acc: 36.72%] [G loss: 0.824612]\n",
      "epoch:16 step:13126[D loss: 0.419558, acc: 59.38%, op_acc: 35.16%] [G loss: 0.854652]\n",
      "epoch:16 step:13127[D loss: 0.435216, acc: 59.38%, op_acc: 35.94%] [G loss: 0.939640]\n",
      "epoch:16 step:13128[D loss: 0.416910, acc: 68.75%, op_acc: 33.59%] [G loss: 1.002470]\n",
      "epoch:16 step:13129[D loss: 0.448110, acc: 52.34%, op_acc: 39.06%] [G loss: 0.824168]\n",
      "epoch:16 step:13130[D loss: 0.427495, acc: 55.47%, op_acc: 39.06%] [G loss: 0.862441]\n",
      "epoch:16 step:13131[D loss: 0.461301, acc: 52.34%, op_acc: 33.59%] [G loss: 0.827011]\n",
      "epoch:16 step:13132[D loss: 0.434685, acc: 51.56%, op_acc: 43.75%] [G loss: 0.794866]\n",
      "epoch:16 step:13133[D loss: 0.402794, acc: 71.09%, op_acc: 39.84%] [G loss: 0.865792]\n",
      "epoch:16 step:13134[D loss: 0.419166, acc: 64.06%, op_acc: 40.62%] [G loss: 0.857833]\n",
      "epoch:16 step:13135[D loss: 0.452124, acc: 51.56%, op_acc: 35.16%] [G loss: 0.833674]\n",
      "epoch:16 step:13136[D loss: 0.447715, acc: 58.59%, op_acc: 36.72%] [G loss: 0.852332]\n",
      "epoch:16 step:13137[D loss: 0.429033, acc: 60.16%, op_acc: 35.94%] [G loss: 0.842834]\n",
      "epoch:16 step:13138[D loss: 0.430210, acc: 60.94%, op_acc: 36.72%] [G loss: 0.927516]\n",
      "epoch:16 step:13139[D loss: 0.439930, acc: 56.25%, op_acc: 35.16%] [G loss: 0.906708]\n",
      "epoch:16 step:13140[D loss: 0.394050, acc: 59.38%, op_acc: 39.06%] [G loss: 0.841923]\n",
      "epoch:16 step:13141[D loss: 0.407352, acc: 60.94%, op_acc: 41.41%] [G loss: 0.866629]\n",
      "epoch:16 step:13142[D loss: 0.431597, acc: 66.41%, op_acc: 33.59%] [G loss: 0.914869]\n",
      "epoch:16 step:13143[D loss: 0.419943, acc: 58.59%, op_acc: 42.97%] [G loss: 0.929610]\n",
      "epoch:16 step:13144[D loss: 0.416730, acc: 66.41%, op_acc: 37.50%] [G loss: 0.874009]\n",
      "epoch:16 step:13145[D loss: 0.457410, acc: 51.56%, op_acc: 35.94%] [G loss: 0.879214]\n",
      "epoch:16 step:13146[D loss: 0.427185, acc: 64.84%, op_acc: 35.94%] [G loss: 0.897292]\n",
      "epoch:16 step:13147[D loss: 0.423157, acc: 56.25%, op_acc: 38.28%] [G loss: 0.906124]\n",
      "epoch:16 step:13148[D loss: 0.437539, acc: 56.25%, op_acc: 35.16%] [G loss: 0.805071]\n",
      "epoch:16 step:13149[D loss: 0.395775, acc: 64.84%, op_acc: 40.62%] [G loss: 0.940996]\n",
      "epoch:16 step:13150[D loss: 0.432874, acc: 63.28%, op_acc: 39.84%] [G loss: 0.883004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13151[D loss: 0.423804, acc: 60.94%, op_acc: 37.50%] [G loss: 0.878773]\n",
      "epoch:16 step:13152[D loss: 0.428895, acc: 58.59%, op_acc: 38.28%] [G loss: 0.836524]\n",
      "epoch:16 step:13153[D loss: 0.445419, acc: 53.91%, op_acc: 36.72%] [G loss: 0.892023]\n",
      "epoch:16 step:13154[D loss: 0.415730, acc: 57.81%, op_acc: 38.28%] [G loss: 0.830525]\n",
      "epoch:16 step:13155[D loss: 0.432212, acc: 59.38%, op_acc: 36.72%] [G loss: 0.879148]\n",
      "epoch:16 step:13156[D loss: 0.427894, acc: 61.72%, op_acc: 35.94%] [G loss: 0.892552]\n",
      "epoch:16 step:13157[D loss: 0.414983, acc: 62.50%, op_acc: 48.44%] [G loss: 0.916282]\n",
      "epoch:16 step:13158[D loss: 0.425098, acc: 55.47%, op_acc: 42.97%] [G loss: 0.858894]\n",
      "epoch:16 step:13159[D loss: 0.423581, acc: 62.50%, op_acc: 32.03%] [G loss: 0.930236]\n",
      "epoch:16 step:13160[D loss: 0.411353, acc: 66.41%, op_acc: 36.72%] [G loss: 0.939932]\n",
      "epoch:16 step:13161[D loss: 0.450295, acc: 64.84%, op_acc: 32.03%] [G loss: 0.938269]\n",
      "epoch:16 step:13162[D loss: 0.401897, acc: 68.75%, op_acc: 39.84%] [G loss: 0.898176]\n",
      "epoch:16 step:13163[D loss: 0.410958, acc: 65.62%, op_acc: 39.06%] [G loss: 0.865341]\n",
      "epoch:16 step:13164[D loss: 0.437916, acc: 55.47%, op_acc: 34.38%] [G loss: 0.799596]\n",
      "epoch:16 step:13165[D loss: 0.397991, acc: 65.62%, op_acc: 39.84%] [G loss: 0.864700]\n",
      "epoch:16 step:13166[D loss: 0.439011, acc: 55.47%, op_acc: 37.50%] [G loss: 0.922066]\n",
      "epoch:16 step:13167[D loss: 0.443835, acc: 60.94%, op_acc: 33.59%] [G loss: 0.888687]\n",
      "epoch:16 step:13168[D loss: 0.411323, acc: 69.53%, op_acc: 35.16%] [G loss: 0.865025]\n",
      "epoch:16 step:13169[D loss: 0.440226, acc: 57.81%, op_acc: 36.72%] [G loss: 0.873445]\n",
      "epoch:16 step:13170[D loss: 0.440530, acc: 52.34%, op_acc: 39.06%] [G loss: 0.932485]\n",
      "epoch:16 step:13171[D loss: 0.425716, acc: 58.59%, op_acc: 40.62%] [G loss: 0.954409]\n",
      "epoch:16 step:13172[D loss: 0.470232, acc: 47.66%, op_acc: 34.38%] [G loss: 0.849089]\n",
      "epoch:16 step:13173[D loss: 0.468543, acc: 51.56%, op_acc: 34.38%] [G loss: 0.843741]\n",
      "epoch:16 step:13174[D loss: 0.441433, acc: 57.81%, op_acc: 35.16%] [G loss: 0.915465]\n",
      "epoch:16 step:13175[D loss: 0.413794, acc: 60.94%, op_acc: 36.72%] [G loss: 0.912675]\n",
      "epoch:16 step:13176[D loss: 0.442685, acc: 62.50%, op_acc: 36.72%] [G loss: 0.918721]\n",
      "epoch:16 step:13177[D loss: 0.449946, acc: 60.94%, op_acc: 33.59%] [G loss: 0.964630]\n",
      "epoch:16 step:13178[D loss: 0.403869, acc: 66.41%, op_acc: 40.62%] [G loss: 0.941286]\n",
      "epoch:16 step:13179[D loss: 0.454059, acc: 57.03%, op_acc: 35.16%] [G loss: 0.913233]\n",
      "epoch:16 step:13180[D loss: 0.430871, acc: 64.06%, op_acc: 36.72%] [G loss: 0.875440]\n",
      "epoch:16 step:13181[D loss: 0.447678, acc: 58.59%, op_acc: 35.94%] [G loss: 0.934288]\n",
      "epoch:16 step:13182[D loss: 0.418053, acc: 57.03%, op_acc: 41.41%] [G loss: 0.896013]\n",
      "epoch:16 step:13183[D loss: 0.414449, acc: 57.03%, op_acc: 40.62%] [G loss: 0.894851]\n",
      "epoch:16 step:13184[D loss: 0.424332, acc: 57.03%, op_acc: 41.41%] [G loss: 0.890176]\n",
      "epoch:16 step:13185[D loss: 0.440289, acc: 51.56%, op_acc: 38.28%] [G loss: 0.856912]\n",
      "epoch:16 step:13186[D loss: 0.402844, acc: 67.19%, op_acc: 33.59%] [G loss: 0.910064]\n",
      "epoch:16 step:13187[D loss: 0.439235, acc: 57.81%, op_acc: 39.84%] [G loss: 0.892844]\n",
      "epoch:16 step:13188[D loss: 0.445243, acc: 57.03%, op_acc: 39.84%] [G loss: 0.927999]\n",
      "epoch:16 step:13189[D loss: 0.425481, acc: 63.28%, op_acc: 40.62%] [G loss: 0.955604]\n",
      "epoch:16 step:13190[D loss: 0.445428, acc: 60.16%, op_acc: 29.69%] [G loss: 0.936123]\n",
      "epoch:16 step:13191[D loss: 0.424193, acc: 68.75%, op_acc: 33.59%] [G loss: 0.877591]\n",
      "epoch:16 step:13192[D loss: 0.425568, acc: 57.03%, op_acc: 38.28%] [G loss: 0.980807]\n",
      "epoch:16 step:13193[D loss: 0.451865, acc: 52.34%, op_acc: 39.06%] [G loss: 0.916690]\n",
      "epoch:16 step:13194[D loss: 0.442984, acc: 60.16%, op_acc: 35.94%] [G loss: 0.895537]\n",
      "epoch:16 step:13195[D loss: 0.420235, acc: 64.06%, op_acc: 38.28%] [G loss: 0.865330]\n",
      "epoch:16 step:13196[D loss: 0.445661, acc: 57.81%, op_acc: 36.72%] [G loss: 0.864708]\n",
      "epoch:16 step:13197[D loss: 0.468673, acc: 53.91%, op_acc: 39.84%] [G loss: 0.881403]\n",
      "epoch:16 step:13198[D loss: 0.460700, acc: 58.59%, op_acc: 35.94%] [G loss: 0.824681]\n",
      "epoch:16 step:13199[D loss: 0.442916, acc: 49.22%, op_acc: 35.94%] [G loss: 0.865322]\n",
      "epoch:16 step:13200[D loss: 0.430710, acc: 57.81%, op_acc: 35.94%] [G loss: 0.884619]\n",
      "epoch:16 step:13201[D loss: 0.430040, acc: 61.72%, op_acc: 36.72%] [G loss: 0.850035]\n",
      "epoch:16 step:13202[D loss: 0.423413, acc: 64.84%, op_acc: 38.28%] [G loss: 0.888685]\n",
      "epoch:16 step:13203[D loss: 0.433778, acc: 59.38%, op_acc: 29.69%] [G loss: 0.868289]\n",
      "epoch:16 step:13204[D loss: 0.430833, acc: 57.81%, op_acc: 38.28%] [G loss: 0.813283]\n",
      "epoch:16 step:13205[D loss: 0.412946, acc: 64.84%, op_acc: 37.50%] [G loss: 0.830029]\n",
      "epoch:16 step:13206[D loss: 0.398259, acc: 60.94%, op_acc: 38.28%] [G loss: 0.851715]\n",
      "epoch:16 step:13207[D loss: 0.433751, acc: 57.81%, op_acc: 35.16%] [G loss: 0.919020]\n",
      "epoch:16 step:13208[D loss: 0.420052, acc: 58.59%, op_acc: 37.50%] [G loss: 0.969783]\n",
      "epoch:16 step:13209[D loss: 0.424493, acc: 61.72%, op_acc: 39.84%] [G loss: 0.857576]\n",
      "epoch:16 step:13210[D loss: 0.438015, acc: 62.50%, op_acc: 34.38%] [G loss: 0.944755]\n",
      "epoch:16 step:13211[D loss: 0.418889, acc: 63.28%, op_acc: 37.50%] [G loss: 0.898643]\n",
      "epoch:16 step:13212[D loss: 0.438802, acc: 59.38%, op_acc: 39.84%] [G loss: 0.839756]\n",
      "epoch:16 step:13213[D loss: 0.373684, acc: 68.75%, op_acc: 39.84%] [G loss: 0.907943]\n",
      "epoch:16 step:13214[D loss: 0.428380, acc: 60.16%, op_acc: 35.94%] [G loss: 0.874775]\n",
      "epoch:16 step:13215[D loss: 0.409880, acc: 64.84%, op_acc: 44.53%] [G loss: 0.974191]\n",
      "epoch:16 step:13216[D loss: 0.433141, acc: 55.47%, op_acc: 41.41%] [G loss: 0.917408]\n",
      "epoch:16 step:13217[D loss: 0.399816, acc: 66.41%, op_acc: 39.84%] [G loss: 0.931385]\n",
      "epoch:16 step:13218[D loss: 0.422955, acc: 58.59%, op_acc: 36.72%] [G loss: 0.926772]\n",
      "epoch:16 step:13219[D loss: 0.403394, acc: 59.38%, op_acc: 45.31%] [G loss: 0.982217]\n",
      "epoch:16 step:13220[D loss: 0.476387, acc: 57.03%, op_acc: 31.25%] [G loss: 0.873189]\n",
      "epoch:16 step:13221[D loss: 0.443794, acc: 58.59%, op_acc: 35.94%] [G loss: 0.887633]\n",
      "epoch:16 step:13222[D loss: 0.428385, acc: 53.91%, op_acc: 41.41%] [G loss: 0.837556]\n",
      "epoch:16 step:13223[D loss: 0.419590, acc: 66.41%, op_acc: 33.59%] [G loss: 0.905545]\n",
      "epoch:16 step:13224[D loss: 0.448448, acc: 57.81%, op_acc: 33.59%] [G loss: 0.882229]\n",
      "epoch:16 step:13225[D loss: 0.438674, acc: 56.25%, op_acc: 35.16%] [G loss: 0.831077]\n",
      "epoch:16 step:13226[D loss: 0.424267, acc: 57.03%, op_acc: 40.62%] [G loss: 0.851640]\n",
      "epoch:16 step:13227[D loss: 0.414982, acc: 62.50%, op_acc: 39.84%] [G loss: 0.933373]\n",
      "epoch:16 step:13228[D loss: 0.425196, acc: 61.72%, op_acc: 41.41%] [G loss: 0.906414]\n",
      "epoch:16 step:13229[D loss: 0.403985, acc: 64.06%, op_acc: 42.97%] [G loss: 0.898294]\n",
      "epoch:16 step:13230[D loss: 0.446845, acc: 54.69%, op_acc: 35.94%] [G loss: 0.923898]\n",
      "epoch:16 step:13231[D loss: 0.419322, acc: 60.16%, op_acc: 40.62%] [G loss: 0.843110]\n",
      "epoch:16 step:13232[D loss: 0.437903, acc: 58.59%, op_acc: 36.72%] [G loss: 0.912966]\n",
      "epoch:16 step:13233[D loss: 0.412711, acc: 66.41%, op_acc: 39.84%] [G loss: 0.820269]\n",
      "epoch:16 step:13234[D loss: 0.419528, acc: 60.94%, op_acc: 37.50%] [G loss: 0.868319]\n",
      "epoch:16 step:13235[D loss: 0.431867, acc: 57.81%, op_acc: 37.50%] [G loss: 0.915997]\n",
      "epoch:16 step:13236[D loss: 0.430530, acc: 57.81%, op_acc: 42.97%] [G loss: 0.897880]\n",
      "epoch:16 step:13237[D loss: 0.416940, acc: 61.72%, op_acc: 39.06%] [G loss: 0.873912]\n",
      "epoch:16 step:13238[D loss: 0.468388, acc: 50.00%, op_acc: 38.28%] [G loss: 0.800345]\n",
      "epoch:16 step:13239[D loss: 0.429422, acc: 63.28%, op_acc: 36.72%] [G loss: 0.876710]\n",
      "epoch:16 step:13240[D loss: 0.422252, acc: 57.03%, op_acc: 42.97%] [G loss: 0.962881]\n",
      "epoch:16 step:13241[D loss: 0.421906, acc: 63.28%, op_acc: 39.06%] [G loss: 0.781416]\n",
      "epoch:16 step:13242[D loss: 0.468986, acc: 49.22%, op_acc: 35.94%] [G loss: 0.817107]\n",
      "epoch:16 step:13243[D loss: 0.451739, acc: 57.81%, op_acc: 32.03%] [G loss: 0.856549]\n",
      "epoch:16 step:13244[D loss: 0.440656, acc: 57.81%, op_acc: 37.50%] [G loss: 0.825883]\n",
      "epoch:16 step:13245[D loss: 0.416826, acc: 63.28%, op_acc: 40.62%] [G loss: 0.877351]\n",
      "epoch:16 step:13246[D loss: 0.450607, acc: 52.34%, op_acc: 35.94%] [G loss: 0.855193]\n",
      "epoch:16 step:13247[D loss: 0.487091, acc: 50.78%, op_acc: 32.03%] [G loss: 0.939102]\n",
      "epoch:16 step:13248[D loss: 0.410280, acc: 67.97%, op_acc: 36.72%] [G loss: 0.861140]\n",
      "epoch:16 step:13249[D loss: 0.426952, acc: 57.81%, op_acc: 39.84%] [G loss: 0.882936]\n",
      "epoch:16 step:13250[D loss: 0.427014, acc: 56.25%, op_acc: 42.19%] [G loss: 0.888473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:13251[D loss: 0.412929, acc: 60.94%, op_acc: 35.16%] [G loss: 0.916530]\n",
      "epoch:16 step:13252[D loss: 0.424411, acc: 57.03%, op_acc: 39.84%] [G loss: 0.846952]\n",
      "epoch:16 step:13253[D loss: 0.444706, acc: 57.81%, op_acc: 33.59%] [G loss: 0.916991]\n",
      "epoch:16 step:13254[D loss: 0.412009, acc: 62.50%, op_acc: 39.84%] [G loss: 0.997415]\n",
      "epoch:16 step:13255[D loss: 0.431461, acc: 64.84%, op_acc: 37.50%] [G loss: 0.872967]\n",
      "epoch:16 step:13256[D loss: 0.421056, acc: 55.47%, op_acc: 40.62%] [G loss: 0.857340]\n",
      "epoch:16 step:13257[D loss: 0.402900, acc: 64.84%, op_acc: 39.06%] [G loss: 0.930403]\n",
      "epoch:16 step:13258[D loss: 0.450240, acc: 58.59%, op_acc: 34.38%] [G loss: 0.844285]\n",
      "epoch:16 step:13259[D loss: 0.438378, acc: 59.38%, op_acc: 39.06%] [G loss: 0.880685]\n",
      "epoch:16 step:13260[D loss: 0.401715, acc: 67.19%, op_acc: 41.41%] [G loss: 0.937326]\n",
      "epoch:16 step:13261[D loss: 0.428983, acc: 58.59%, op_acc: 34.38%] [G loss: 0.856766]\n",
      "epoch:16 step:13262[D loss: 0.452018, acc: 55.47%, op_acc: 32.03%] [G loss: 0.854516]\n",
      "epoch:16 step:13263[D loss: 0.433378, acc: 55.47%, op_acc: 36.72%] [G loss: 0.837581]\n",
      "epoch:16 step:13264[D loss: 0.440807, acc: 52.34%, op_acc: 32.81%] [G loss: 0.871302]\n",
      "epoch:16 step:13265[D loss: 0.461317, acc: 55.47%, op_acc: 33.59%] [G loss: 0.801056]\n",
      "epoch:16 step:13266[D loss: 0.425067, acc: 57.81%, op_acc: 42.97%] [G loss: 0.854479]\n",
      "epoch:16 step:13267[D loss: 0.468849, acc: 57.81%, op_acc: 35.16%] [G loss: 0.917692]\n",
      "epoch:16 step:13268[D loss: 0.454210, acc: 60.16%, op_acc: 32.03%] [G loss: 0.844535]\n",
      "epoch:16 step:13269[D loss: 0.438751, acc: 60.16%, op_acc: 38.28%] [G loss: 0.942892]\n",
      "epoch:16 step:13270[D loss: 0.405906, acc: 57.03%, op_acc: 46.88%] [G loss: 0.918122]\n",
      "epoch:16 step:13271[D loss: 0.441902, acc: 59.38%, op_acc: 28.91%] [G loss: 0.901441]\n",
      "epoch:16 step:13272[D loss: 0.439809, acc: 51.56%, op_acc: 38.28%] [G loss: 0.825175]\n",
      "epoch:16 step:13273[D loss: 0.472399, acc: 52.34%, op_acc: 35.94%] [G loss: 0.866171]\n",
      "epoch:16 step:13274[D loss: 0.439543, acc: 56.25%, op_acc: 40.62%] [G loss: 0.902486]\n",
      "epoch:16 step:13275[D loss: 0.411776, acc: 66.41%, op_acc: 41.41%] [G loss: 0.882675]\n",
      "epoch:16 step:13276[D loss: 0.409155, acc: 60.94%, op_acc: 38.28%] [G loss: 0.953105]\n",
      "epoch:16 step:13277[D loss: 0.447325, acc: 56.25%, op_acc: 32.81%] [G loss: 0.858114]\n",
      "epoch:17 step:13278[D loss: 0.431160, acc: 58.59%, op_acc: 42.19%] [G loss: 0.838804]\n",
      "epoch:17 step:13279[D loss: 0.411314, acc: 63.28%, op_acc: 39.84%] [G loss: 0.974054]\n",
      "epoch:17 step:13280[D loss: 0.441812, acc: 53.91%, op_acc: 39.06%] [G loss: 0.928133]\n",
      "epoch:17 step:13281[D loss: 0.404860, acc: 63.28%, op_acc: 40.62%] [G loss: 0.975587]\n",
      "epoch:17 step:13282[D loss: 0.445468, acc: 54.69%, op_acc: 39.06%] [G loss: 0.927088]\n",
      "epoch:17 step:13283[D loss: 0.413569, acc: 64.06%, op_acc: 40.62%] [G loss: 0.901477]\n",
      "epoch:17 step:13284[D loss: 0.420249, acc: 65.62%, op_acc: 43.75%] [G loss: 0.919019]\n",
      "epoch:17 step:13285[D loss: 0.437241, acc: 50.78%, op_acc: 37.50%] [G loss: 0.859319]\n",
      "epoch:17 step:13286[D loss: 0.428008, acc: 53.91%, op_acc: 42.19%] [G loss: 0.948407]\n",
      "epoch:17 step:13287[D loss: 0.433910, acc: 62.50%, op_acc: 35.16%] [G loss: 0.899646]\n",
      "epoch:17 step:13288[D loss: 0.448860, acc: 64.06%, op_acc: 33.59%] [G loss: 0.841013]\n",
      "epoch:17 step:13289[D loss: 0.448104, acc: 60.16%, op_acc: 34.38%] [G loss: 0.824349]\n",
      "epoch:17 step:13290[D loss: 0.434609, acc: 53.91%, op_acc: 32.81%] [G loss: 0.889227]\n",
      "epoch:17 step:13291[D loss: 0.430675, acc: 64.06%, op_acc: 36.72%] [G loss: 0.928870]\n",
      "epoch:17 step:13292[D loss: 0.418135, acc: 62.50%, op_acc: 36.72%] [G loss: 0.887358]\n",
      "epoch:17 step:13293[D loss: 0.420783, acc: 64.06%, op_acc: 43.75%] [G loss: 0.921246]\n",
      "epoch:17 step:13294[D loss: 0.432176, acc: 60.94%, op_acc: 42.19%] [G loss: 0.880391]\n",
      "epoch:17 step:13295[D loss: 0.445987, acc: 57.03%, op_acc: 37.50%] [G loss: 0.892471]\n",
      "epoch:17 step:13296[D loss: 0.416240, acc: 63.28%, op_acc: 44.53%] [G loss: 0.842409]\n",
      "epoch:17 step:13297[D loss: 0.420802, acc: 58.59%, op_acc: 32.03%] [G loss: 0.741788]\n",
      "epoch:17 step:13298[D loss: 0.464969, acc: 53.91%, op_acc: 31.25%] [G loss: 0.845056]\n",
      "epoch:17 step:13299[D loss: 0.437826, acc: 60.94%, op_acc: 36.72%] [G loss: 0.844096]\n",
      "epoch:17 step:13300[D loss: 0.430342, acc: 63.28%, op_acc: 33.59%] [G loss: 0.909968]\n",
      "epoch:17 step:13301[D loss: 0.416355, acc: 68.75%, op_acc: 37.50%] [G loss: 0.881390]\n",
      "epoch:17 step:13302[D loss: 0.456157, acc: 56.25%, op_acc: 38.28%] [G loss: 0.881839]\n",
      "epoch:17 step:13303[D loss: 0.454989, acc: 56.25%, op_acc: 36.72%] [G loss: 0.885162]\n",
      "epoch:17 step:13304[D loss: 0.436686, acc: 53.91%, op_acc: 36.72%] [G loss: 0.904659]\n",
      "epoch:17 step:13305[D loss: 0.447526, acc: 51.56%, op_acc: 35.94%] [G loss: 0.923613]\n",
      "epoch:17 step:13306[D loss: 0.413876, acc: 60.94%, op_acc: 37.50%] [G loss: 0.930247]\n",
      "epoch:17 step:13307[D loss: 0.420414, acc: 62.50%, op_acc: 38.28%] [G loss: 0.897540]\n",
      "epoch:17 step:13308[D loss: 0.472231, acc: 52.34%, op_acc: 39.84%] [G loss: 0.961346]\n",
      "epoch:17 step:13309[D loss: 0.410143, acc: 68.75%, op_acc: 39.84%] [G loss: 0.903831]\n",
      "epoch:17 step:13310[D loss: 0.423928, acc: 61.72%, op_acc: 40.62%] [G loss: 0.878335]\n",
      "epoch:17 step:13311[D loss: 0.419115, acc: 58.59%, op_acc: 42.97%] [G loss: 0.894864]\n",
      "epoch:17 step:13312[D loss: 0.420146, acc: 68.75%, op_acc: 39.06%] [G loss: 0.957847]\n",
      "epoch:17 step:13313[D loss: 0.414619, acc: 59.38%, op_acc: 40.62%] [G loss: 0.838850]\n",
      "epoch:17 step:13314[D loss: 0.415431, acc: 67.97%, op_acc: 41.41%] [G loss: 0.835598]\n",
      "epoch:17 step:13315[D loss: 0.420271, acc: 56.25%, op_acc: 38.28%] [G loss: 0.958607]\n",
      "epoch:17 step:13316[D loss: 0.429088, acc: 62.50%, op_acc: 36.72%] [G loss: 0.916152]\n",
      "epoch:17 step:13317[D loss: 0.418503, acc: 60.16%, op_acc: 35.94%] [G loss: 0.882959]\n",
      "epoch:17 step:13318[D loss: 0.406970, acc: 60.94%, op_acc: 45.31%] [G loss: 0.833346]\n",
      "epoch:17 step:13319[D loss: 0.391621, acc: 65.62%, op_acc: 44.53%] [G loss: 0.950354]\n",
      "epoch:17 step:13320[D loss: 0.433375, acc: 61.72%, op_acc: 36.72%] [G loss: 0.912862]\n",
      "epoch:17 step:13321[D loss: 0.460044, acc: 46.88%, op_acc: 39.84%] [G loss: 0.768829]\n",
      "epoch:17 step:13322[D loss: 0.431842, acc: 53.12%, op_acc: 36.72%] [G loss: 0.887813]\n",
      "epoch:17 step:13323[D loss: 0.430741, acc: 60.16%, op_acc: 39.06%] [G loss: 0.895314]\n",
      "epoch:17 step:13324[D loss: 0.464178, acc: 55.47%, op_acc: 32.03%] [G loss: 0.955728]\n",
      "epoch:17 step:13325[D loss: 0.428467, acc: 62.50%, op_acc: 35.94%] [G loss: 0.828204]\n",
      "epoch:17 step:13326[D loss: 0.388280, acc: 69.53%, op_acc: 35.94%] [G loss: 0.922099]\n",
      "epoch:17 step:13327[D loss: 0.443015, acc: 60.94%, op_acc: 39.06%] [G loss: 0.877738]\n",
      "epoch:17 step:13328[D loss: 0.400528, acc: 64.84%, op_acc: 41.41%] [G loss: 0.867021]\n",
      "epoch:17 step:13329[D loss: 0.424082, acc: 61.72%, op_acc: 38.28%] [G loss: 0.813272]\n",
      "epoch:17 step:13330[D loss: 0.449742, acc: 57.03%, op_acc: 34.38%] [G loss: 0.857281]\n",
      "epoch:17 step:13331[D loss: 0.442947, acc: 56.25%, op_acc: 35.94%] [G loss: 0.936444]\n",
      "epoch:17 step:13332[D loss: 0.407891, acc: 65.62%, op_acc: 38.28%] [G loss: 0.847901]\n",
      "epoch:17 step:13333[D loss: 0.430875, acc: 57.81%, op_acc: 34.38%] [G loss: 0.827596]\n",
      "epoch:17 step:13334[D loss: 0.446990, acc: 62.50%, op_acc: 36.72%] [G loss: 0.851528]\n",
      "epoch:17 step:13335[D loss: 0.388290, acc: 61.72%, op_acc: 43.75%] [G loss: 0.901740]\n",
      "epoch:17 step:13336[D loss: 0.427635, acc: 51.56%, op_acc: 39.06%] [G loss: 0.811816]\n",
      "epoch:17 step:13337[D loss: 0.454156, acc: 51.56%, op_acc: 33.59%] [G loss: 0.879092]\n",
      "epoch:17 step:13338[D loss: 0.415922, acc: 66.41%, op_acc: 35.16%] [G loss: 0.895825]\n",
      "epoch:17 step:13339[D loss: 0.434625, acc: 56.25%, op_acc: 39.06%] [G loss: 0.865469]\n",
      "epoch:17 step:13340[D loss: 0.450915, acc: 54.69%, op_acc: 33.59%] [G loss: 0.907322]\n",
      "epoch:17 step:13341[D loss: 0.398060, acc: 66.41%, op_acc: 37.50%] [G loss: 0.936406]\n",
      "epoch:17 step:13342[D loss: 0.429885, acc: 62.50%, op_acc: 43.75%] [G loss: 0.893417]\n",
      "epoch:17 step:13343[D loss: 0.461378, acc: 50.00%, op_acc: 35.94%] [G loss: 0.771309]\n",
      "epoch:17 step:13344[D loss: 0.460381, acc: 48.44%, op_acc: 36.72%] [G loss: 0.798417]\n",
      "epoch:17 step:13345[D loss: 0.435758, acc: 58.59%, op_acc: 30.47%] [G loss: 0.855522]\n",
      "epoch:17 step:13346[D loss: 0.406321, acc: 63.28%, op_acc: 41.41%] [G loss: 0.915516]\n",
      "epoch:17 step:13347[D loss: 0.467746, acc: 50.00%, op_acc: 32.81%] [G loss: 0.847799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13348[D loss: 0.475171, acc: 50.00%, op_acc: 31.25%] [G loss: 0.884072]\n",
      "epoch:17 step:13349[D loss: 0.407668, acc: 65.62%, op_acc: 38.28%] [G loss: 0.898573]\n",
      "epoch:17 step:13350[D loss: 0.450511, acc: 56.25%, op_acc: 35.94%] [G loss: 0.904110]\n",
      "epoch:17 step:13351[D loss: 0.410646, acc: 62.50%, op_acc: 40.62%] [G loss: 0.858906]\n",
      "epoch:17 step:13352[D loss: 0.420780, acc: 61.72%, op_acc: 39.84%] [G loss: 0.871838]\n",
      "epoch:17 step:13353[D loss: 0.458201, acc: 55.47%, op_acc: 35.16%] [G loss: 0.895121]\n",
      "epoch:17 step:13354[D loss: 0.460703, acc: 50.00%, op_acc: 35.94%] [G loss: 0.882174]\n",
      "epoch:17 step:13355[D loss: 0.440689, acc: 59.38%, op_acc: 35.94%] [G loss: 0.910470]\n",
      "epoch:17 step:13356[D loss: 0.418568, acc: 60.94%, op_acc: 28.91%] [G loss: 0.850735]\n",
      "epoch:17 step:13357[D loss: 0.457558, acc: 59.38%, op_acc: 33.59%] [G loss: 0.928308]\n",
      "epoch:17 step:13358[D loss: 0.437603, acc: 55.47%, op_acc: 41.41%] [G loss: 0.860685]\n",
      "epoch:17 step:13359[D loss: 0.423121, acc: 60.94%, op_acc: 39.84%] [G loss: 0.865292]\n",
      "epoch:17 step:13360[D loss: 0.427186, acc: 63.28%, op_acc: 34.38%] [G loss: 0.871599]\n",
      "epoch:17 step:13361[D loss: 0.453878, acc: 57.81%, op_acc: 37.50%] [G loss: 0.946750]\n",
      "epoch:17 step:13362[D loss: 0.431285, acc: 61.72%, op_acc: 34.38%] [G loss: 0.848381]\n",
      "epoch:17 step:13363[D loss: 0.401813, acc: 65.62%, op_acc: 43.75%] [G loss: 0.895889]\n",
      "epoch:17 step:13364[D loss: 0.395530, acc: 69.53%, op_acc: 38.28%] [G loss: 0.961909]\n",
      "epoch:17 step:13365[D loss: 0.417312, acc: 60.94%, op_acc: 40.62%] [G loss: 0.945639]\n",
      "epoch:17 step:13366[D loss: 0.447986, acc: 57.81%, op_acc: 34.38%] [G loss: 0.877213]\n",
      "epoch:17 step:13367[D loss: 0.426479, acc: 57.81%, op_acc: 41.41%] [G loss: 0.859536]\n",
      "epoch:17 step:13368[D loss: 0.443010, acc: 48.44%, op_acc: 40.62%] [G loss: 0.739941]\n",
      "epoch:17 step:13369[D loss: 0.469703, acc: 51.56%, op_acc: 38.28%] [G loss: 0.858674]\n",
      "epoch:17 step:13370[D loss: 0.432270, acc: 52.34%, op_acc: 39.06%] [G loss: 0.889366]\n",
      "epoch:17 step:13371[D loss: 0.409222, acc: 60.94%, op_acc: 38.28%] [G loss: 0.797511]\n",
      "epoch:17 step:13372[D loss: 0.424126, acc: 60.16%, op_acc: 35.16%] [G loss: 0.875440]\n",
      "epoch:17 step:13373[D loss: 0.435372, acc: 57.03%, op_acc: 34.38%] [G loss: 0.812644]\n",
      "epoch:17 step:13374[D loss: 0.435595, acc: 50.78%, op_acc: 34.38%] [G loss: 0.852890]\n",
      "epoch:17 step:13375[D loss: 0.409742, acc: 61.72%, op_acc: 39.84%] [G loss: 0.882385]\n",
      "epoch:17 step:13376[D loss: 0.415779, acc: 59.38%, op_acc: 38.28%] [G loss: 0.889695]\n",
      "epoch:17 step:13377[D loss: 0.414477, acc: 54.69%, op_acc: 41.41%] [G loss: 0.894462]\n",
      "epoch:17 step:13378[D loss: 0.425008, acc: 60.16%, op_acc: 34.38%] [G loss: 1.014606]\n",
      "epoch:17 step:13379[D loss: 0.439527, acc: 54.69%, op_acc: 42.19%] [G loss: 0.910968]\n",
      "epoch:17 step:13380[D loss: 0.445130, acc: 49.22%, op_acc: 36.72%] [G loss: 0.830628]\n",
      "epoch:17 step:13381[D loss: 0.449654, acc: 57.03%, op_acc: 40.62%] [G loss: 0.880484]\n",
      "epoch:17 step:13382[D loss: 0.429241, acc: 60.16%, op_acc: 35.94%] [G loss: 0.937894]\n",
      "epoch:17 step:13383[D loss: 0.450302, acc: 52.34%, op_acc: 35.94%] [G loss: 0.952968]\n",
      "epoch:17 step:13384[D loss: 0.442609, acc: 53.12%, op_acc: 36.72%] [G loss: 0.866612]\n",
      "epoch:17 step:13385[D loss: 0.478338, acc: 60.16%, op_acc: 33.59%] [G loss: 0.935391]\n",
      "epoch:17 step:13386[D loss: 0.407256, acc: 64.84%, op_acc: 41.41%] [G loss: 0.854331]\n",
      "epoch:17 step:13387[D loss: 0.419626, acc: 60.94%, op_acc: 39.84%] [G loss: 0.969936]\n",
      "epoch:17 step:13388[D loss: 0.449208, acc: 55.47%, op_acc: 36.72%] [G loss: 0.812105]\n",
      "epoch:17 step:13389[D loss: 0.417119, acc: 57.81%, op_acc: 39.84%] [G loss: 1.005930]\n",
      "epoch:17 step:13390[D loss: 0.438671, acc: 55.47%, op_acc: 32.81%] [G loss: 0.821490]\n",
      "epoch:17 step:13391[D loss: 0.442348, acc: 55.47%, op_acc: 36.72%] [G loss: 0.829566]\n",
      "epoch:17 step:13392[D loss: 0.414942, acc: 58.59%, op_acc: 39.84%] [G loss: 0.890873]\n",
      "epoch:17 step:13393[D loss: 0.432254, acc: 62.50%, op_acc: 35.16%] [G loss: 0.956078]\n",
      "epoch:17 step:13394[D loss: 0.453631, acc: 50.78%, op_acc: 40.62%] [G loss: 0.872480]\n",
      "epoch:17 step:13395[D loss: 0.439687, acc: 58.59%, op_acc: 32.81%] [G loss: 0.905375]\n",
      "epoch:17 step:13396[D loss: 0.441061, acc: 58.59%, op_acc: 33.59%] [G loss: 0.885535]\n",
      "epoch:17 step:13397[D loss: 0.418525, acc: 60.16%, op_acc: 36.72%] [G loss: 0.904357]\n",
      "epoch:17 step:13398[D loss: 0.437067, acc: 64.06%, op_acc: 37.50%] [G loss: 0.922749]\n",
      "epoch:17 step:13399[D loss: 0.455460, acc: 54.69%, op_acc: 32.81%] [G loss: 0.871544]\n",
      "epoch:17 step:13400[D loss: 0.454316, acc: 50.00%, op_acc: 38.28%] [G loss: 0.827911]\n",
      "epoch:17 step:13401[D loss: 0.397861, acc: 64.84%, op_acc: 40.62%] [G loss: 0.854429]\n",
      "epoch:17 step:13402[D loss: 0.482454, acc: 53.91%, op_acc: 27.34%] [G loss: 0.809468]\n",
      "epoch:17 step:13403[D loss: 0.442863, acc: 55.47%, op_acc: 39.06%] [G loss: 0.832706]\n",
      "epoch:17 step:13404[D loss: 0.405213, acc: 64.84%, op_acc: 32.03%] [G loss: 1.024725]\n",
      "epoch:17 step:13405[D loss: 0.390353, acc: 77.34%, op_acc: 39.84%] [G loss: 0.858626]\n",
      "epoch:17 step:13406[D loss: 0.436371, acc: 59.38%, op_acc: 35.16%] [G loss: 0.941687]\n",
      "epoch:17 step:13407[D loss: 0.446435, acc: 57.03%, op_acc: 35.94%] [G loss: 0.927092]\n",
      "epoch:17 step:13408[D loss: 0.430389, acc: 56.25%, op_acc: 34.38%] [G loss: 0.925257]\n",
      "epoch:17 step:13409[D loss: 0.393421, acc: 63.28%, op_acc: 44.53%] [G loss: 0.931148]\n",
      "epoch:17 step:13410[D loss: 0.469800, acc: 60.94%, op_acc: 32.03%] [G loss: 0.993889]\n",
      "epoch:17 step:13411[D loss: 0.469650, acc: 55.47%, op_acc: 35.16%] [G loss: 0.872752]\n",
      "epoch:17 step:13412[D loss: 0.445841, acc: 51.56%, op_acc: 37.50%] [G loss: 0.814658]\n",
      "epoch:17 step:13413[D loss: 0.374060, acc: 74.22%, op_acc: 38.28%] [G loss: 0.902550]\n",
      "epoch:17 step:13414[D loss: 0.454455, acc: 51.56%, op_acc: 31.25%] [G loss: 0.833637]\n",
      "epoch:17 step:13415[D loss: 0.437834, acc: 59.38%, op_acc: 32.03%] [G loss: 0.948416]\n",
      "epoch:17 step:13416[D loss: 0.410542, acc: 61.72%, op_acc: 44.53%] [G loss: 0.995507]\n",
      "epoch:17 step:13417[D loss: 0.501422, acc: 42.19%, op_acc: 35.16%] [G loss: 0.815013]\n",
      "epoch:17 step:13418[D loss: 0.433370, acc: 56.25%, op_acc: 35.94%] [G loss: 1.007876]\n",
      "epoch:17 step:13419[D loss: 0.421816, acc: 57.03%, op_acc: 40.62%] [G loss: 0.916957]\n",
      "epoch:17 step:13420[D loss: 0.420676, acc: 57.03%, op_acc: 39.84%] [G loss: 0.870617]\n",
      "epoch:17 step:13421[D loss: 0.455881, acc: 51.56%, op_acc: 39.06%] [G loss: 0.881972]\n",
      "epoch:17 step:13422[D loss: 0.413557, acc: 66.41%, op_acc: 35.16%] [G loss: 0.918473]\n",
      "epoch:17 step:13423[D loss: 0.420672, acc: 63.28%, op_acc: 39.84%] [G loss: 0.870985]\n",
      "epoch:17 step:13424[D loss: 0.429804, acc: 55.47%, op_acc: 38.28%] [G loss: 0.863951]\n",
      "epoch:17 step:13425[D loss: 0.430431, acc: 61.72%, op_acc: 34.38%] [G loss: 0.959215]\n",
      "epoch:17 step:13426[D loss: 0.425849, acc: 55.47%, op_acc: 36.72%] [G loss: 0.846053]\n",
      "epoch:17 step:13427[D loss: 0.397623, acc: 67.97%, op_acc: 40.62%] [G loss: 0.866142]\n",
      "epoch:17 step:13428[D loss: 0.426040, acc: 59.38%, op_acc: 46.88%] [G loss: 0.877069]\n",
      "epoch:17 step:13429[D loss: 0.390446, acc: 66.41%, op_acc: 43.75%] [G loss: 0.997374]\n",
      "epoch:17 step:13430[D loss: 0.422217, acc: 60.94%, op_acc: 38.28%] [G loss: 0.888027]\n",
      "epoch:17 step:13431[D loss: 0.438975, acc: 59.38%, op_acc: 35.16%] [G loss: 0.893186]\n",
      "epoch:17 step:13432[D loss: 0.430575, acc: 53.91%, op_acc: 39.84%] [G loss: 0.929377]\n",
      "epoch:17 step:13433[D loss: 0.433141, acc: 60.94%, op_acc: 39.06%] [G loss: 0.907224]\n",
      "epoch:17 step:13434[D loss: 0.404791, acc: 67.19%, op_acc: 35.94%] [G loss: 0.846875]\n",
      "epoch:17 step:13435[D loss: 0.421181, acc: 61.72%, op_acc: 39.06%] [G loss: 0.879727]\n",
      "epoch:17 step:13436[D loss: 0.444658, acc: 55.47%, op_acc: 38.28%] [G loss: 0.918327]\n",
      "epoch:17 step:13437[D loss: 0.450461, acc: 65.62%, op_acc: 34.38%] [G loss: 0.829725]\n",
      "epoch:17 step:13438[D loss: 0.475974, acc: 46.88%, op_acc: 40.62%] [G loss: 0.902991]\n",
      "epoch:17 step:13439[D loss: 0.396162, acc: 65.62%, op_acc: 49.22%] [G loss: 0.944417]\n",
      "epoch:17 step:13440[D loss: 0.413602, acc: 64.84%, op_acc: 40.62%] [G loss: 0.905341]\n",
      "epoch:17 step:13441[D loss: 0.425553, acc: 67.19%, op_acc: 29.69%] [G loss: 0.911529]\n",
      "epoch:17 step:13442[D loss: 0.436932, acc: 50.00%, op_acc: 39.84%] [G loss: 0.916511]\n",
      "epoch:17 step:13443[D loss: 0.450794, acc: 59.38%, op_acc: 39.06%] [G loss: 0.971316]\n",
      "epoch:17 step:13444[D loss: 0.437040, acc: 60.94%, op_acc: 39.84%] [G loss: 0.856218]\n",
      "epoch:17 step:13445[D loss: 0.391226, acc: 64.84%, op_acc: 39.84%] [G loss: 0.899223]\n",
      "epoch:17 step:13446[D loss: 0.414321, acc: 60.94%, op_acc: 37.50%] [G loss: 0.858115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13447[D loss: 0.428437, acc: 56.25%, op_acc: 41.41%] [G loss: 0.937151]\n",
      "epoch:17 step:13448[D loss: 0.421814, acc: 67.19%, op_acc: 36.72%] [G loss: 0.859218]\n",
      "epoch:17 step:13449[D loss: 0.420445, acc: 63.28%, op_acc: 36.72%] [G loss: 0.881231]\n",
      "epoch:17 step:13450[D loss: 0.439418, acc: 60.16%, op_acc: 39.06%] [G loss: 0.880457]\n",
      "epoch:17 step:13451[D loss: 0.497833, acc: 40.62%, op_acc: 31.25%] [G loss: 0.853684]\n",
      "epoch:17 step:13452[D loss: 0.391145, acc: 69.53%, op_acc: 41.41%] [G loss: 0.911942]\n",
      "epoch:17 step:13453[D loss: 0.417654, acc: 65.62%, op_acc: 36.72%] [G loss: 0.857013]\n",
      "epoch:17 step:13454[D loss: 0.409084, acc: 61.72%, op_acc: 41.41%] [G loss: 0.909237]\n",
      "epoch:17 step:13455[D loss: 0.451372, acc: 57.03%, op_acc: 34.38%] [G loss: 0.883058]\n",
      "epoch:17 step:13456[D loss: 0.414774, acc: 64.06%, op_acc: 38.28%] [G loss: 0.979088]\n",
      "epoch:17 step:13457[D loss: 0.441850, acc: 53.91%, op_acc: 34.38%] [G loss: 0.882712]\n",
      "epoch:17 step:13458[D loss: 0.401894, acc: 67.97%, op_acc: 41.41%] [G loss: 0.928614]\n",
      "epoch:17 step:13459[D loss: 0.427339, acc: 66.41%, op_acc: 35.16%] [G loss: 0.881237]\n",
      "epoch:17 step:13460[D loss: 0.439343, acc: 55.47%, op_acc: 42.19%] [G loss: 0.901438]\n",
      "epoch:17 step:13461[D loss: 0.434948, acc: 60.16%, op_acc: 32.03%] [G loss: 0.938067]\n",
      "epoch:17 step:13462[D loss: 0.465222, acc: 50.78%, op_acc: 30.47%] [G loss: 0.912335]\n",
      "epoch:17 step:13463[D loss: 0.428947, acc: 61.72%, op_acc: 33.59%] [G loss: 0.889686]\n",
      "epoch:17 step:13464[D loss: 0.449076, acc: 55.47%, op_acc: 37.50%] [G loss: 0.908247]\n",
      "epoch:17 step:13465[D loss: 0.420664, acc: 60.94%, op_acc: 41.41%] [G loss: 0.829922]\n",
      "epoch:17 step:13466[D loss: 0.427556, acc: 62.50%, op_acc: 35.16%] [G loss: 0.948710]\n",
      "epoch:17 step:13467[D loss: 0.445522, acc: 58.59%, op_acc: 35.16%] [G loss: 0.853841]\n",
      "epoch:17 step:13468[D loss: 0.433085, acc: 53.91%, op_acc: 43.75%] [G loss: 0.907409]\n",
      "epoch:17 step:13469[D loss: 0.406250, acc: 64.06%, op_acc: 39.06%] [G loss: 0.888480]\n",
      "epoch:17 step:13470[D loss: 0.464243, acc: 60.94%, op_acc: 30.47%] [G loss: 0.802620]\n",
      "epoch:17 step:13471[D loss: 0.453910, acc: 53.12%, op_acc: 36.72%] [G loss: 0.902788]\n",
      "epoch:17 step:13472[D loss: 0.438279, acc: 57.03%, op_acc: 37.50%] [G loss: 0.896989]\n",
      "epoch:17 step:13473[D loss: 0.421842, acc: 64.06%, op_acc: 36.72%] [G loss: 0.914322]\n",
      "epoch:17 step:13474[D loss: 0.432795, acc: 59.38%, op_acc: 42.19%] [G loss: 0.898011]\n",
      "epoch:17 step:13475[D loss: 0.478334, acc: 46.09%, op_acc: 33.59%] [G loss: 0.863697]\n",
      "epoch:17 step:13476[D loss: 0.464678, acc: 53.91%, op_acc: 35.94%] [G loss: 0.841799]\n",
      "epoch:17 step:13477[D loss: 0.410451, acc: 67.97%, op_acc: 37.50%] [G loss: 0.955970]\n",
      "epoch:17 step:13478[D loss: 0.403223, acc: 63.28%, op_acc: 40.62%] [G loss: 0.889003]\n",
      "epoch:17 step:13479[D loss: 0.424980, acc: 60.94%, op_acc: 35.16%] [G loss: 0.903789]\n",
      "epoch:17 step:13480[D loss: 0.415992, acc: 60.94%, op_acc: 39.84%] [G loss: 0.890860]\n",
      "epoch:17 step:13481[D loss: 0.436161, acc: 57.03%, op_acc: 40.62%] [G loss: 0.897864]\n",
      "epoch:17 step:13482[D loss: 0.440370, acc: 54.69%, op_acc: 37.50%] [G loss: 0.799443]\n",
      "epoch:17 step:13483[D loss: 0.450778, acc: 51.56%, op_acc: 31.25%] [G loss: 0.787497]\n",
      "epoch:17 step:13484[D loss: 0.435380, acc: 57.03%, op_acc: 37.50%] [G loss: 0.894427]\n",
      "epoch:17 step:13485[D loss: 0.437550, acc: 62.50%, op_acc: 32.81%] [G loss: 0.983208]\n",
      "epoch:17 step:13486[D loss: 0.426313, acc: 54.69%, op_acc: 42.97%] [G loss: 0.892147]\n",
      "epoch:17 step:13487[D loss: 0.434443, acc: 57.81%, op_acc: 42.19%] [G loss: 0.846635]\n",
      "epoch:17 step:13488[D loss: 0.387792, acc: 74.22%, op_acc: 42.97%] [G loss: 0.923301]\n",
      "epoch:17 step:13489[D loss: 0.445248, acc: 53.91%, op_acc: 36.72%] [G loss: 0.895321]\n",
      "epoch:17 step:13490[D loss: 0.421879, acc: 62.50%, op_acc: 39.84%] [G loss: 0.814962]\n",
      "epoch:17 step:13491[D loss: 0.447465, acc: 57.03%, op_acc: 34.38%] [G loss: 0.803823]\n",
      "epoch:17 step:13492[D loss: 0.451071, acc: 57.03%, op_acc: 39.06%] [G loss: 0.891488]\n",
      "epoch:17 step:13493[D loss: 0.441160, acc: 60.94%, op_acc: 34.38%] [G loss: 0.870763]\n",
      "epoch:17 step:13494[D loss: 0.410893, acc: 65.62%, op_acc: 44.53%] [G loss: 0.902987]\n",
      "epoch:17 step:13495[D loss: 0.422890, acc: 60.16%, op_acc: 40.62%] [G loss: 0.904800]\n",
      "epoch:17 step:13496[D loss: 0.395957, acc: 67.19%, op_acc: 42.97%] [G loss: 0.967451]\n",
      "epoch:17 step:13497[D loss: 0.471470, acc: 52.34%, op_acc: 37.50%] [G loss: 0.765526]\n",
      "epoch:17 step:13498[D loss: 0.435637, acc: 53.12%, op_acc: 35.94%] [G loss: 0.835520]\n",
      "epoch:17 step:13499[D loss: 0.454528, acc: 53.12%, op_acc: 35.94%] [G loss: 0.863784]\n",
      "epoch:17 step:13500[D loss: 0.433461, acc: 55.47%, op_acc: 35.16%] [G loss: 0.880126]\n",
      "epoch:17 step:13501[D loss: 0.406953, acc: 64.06%, op_acc: 36.72%] [G loss: 0.928552]\n",
      "epoch:17 step:13502[D loss: 0.436300, acc: 52.34%, op_acc: 42.97%] [G loss: 0.980567]\n",
      "epoch:17 step:13503[D loss: 0.438653, acc: 57.03%, op_acc: 32.81%] [G loss: 0.883809]\n",
      "epoch:17 step:13504[D loss: 0.417865, acc: 55.47%, op_acc: 37.50%] [G loss: 0.854410]\n",
      "epoch:17 step:13505[D loss: 0.432240, acc: 57.03%, op_acc: 43.75%] [G loss: 0.800235]\n",
      "epoch:17 step:13506[D loss: 0.439719, acc: 57.81%, op_acc: 39.84%] [G loss: 0.922230]\n",
      "epoch:17 step:13507[D loss: 0.424340, acc: 63.28%, op_acc: 36.72%] [G loss: 0.903722]\n",
      "epoch:17 step:13508[D loss: 0.398287, acc: 61.72%, op_acc: 44.53%] [G loss: 0.953433]\n",
      "epoch:17 step:13509[D loss: 0.422373, acc: 63.28%, op_acc: 34.38%] [G loss: 0.953957]\n",
      "epoch:17 step:13510[D loss: 0.425049, acc: 68.75%, op_acc: 43.75%] [G loss: 0.861068]\n",
      "epoch:17 step:13511[D loss: 0.423071, acc: 68.75%, op_acc: 36.72%] [G loss: 0.884255]\n",
      "epoch:17 step:13512[D loss: 0.427298, acc: 57.81%, op_acc: 39.84%] [G loss: 0.923304]\n",
      "epoch:17 step:13513[D loss: 0.427325, acc: 59.38%, op_acc: 39.84%] [G loss: 0.914992]\n",
      "epoch:17 step:13514[D loss: 0.409275, acc: 66.41%, op_acc: 39.06%] [G loss: 0.884563]\n",
      "epoch:17 step:13515[D loss: 0.418082, acc: 63.28%, op_acc: 36.72%] [G loss: 0.824215]\n",
      "epoch:17 step:13516[D loss: 0.413249, acc: 60.94%, op_acc: 38.28%] [G loss: 0.820013]\n",
      "epoch:17 step:13517[D loss: 0.447339, acc: 53.12%, op_acc: 41.41%] [G loss: 0.852079]\n",
      "epoch:17 step:13518[D loss: 0.429680, acc: 54.69%, op_acc: 37.50%] [G loss: 0.840585]\n",
      "epoch:17 step:13519[D loss: 0.424694, acc: 61.72%, op_acc: 42.19%] [G loss: 0.897437]\n",
      "epoch:17 step:13520[D loss: 0.424888, acc: 56.25%, op_acc: 45.31%] [G loss: 0.809973]\n",
      "epoch:17 step:13521[D loss: 0.441358, acc: 62.50%, op_acc: 35.94%] [G loss: 0.935916]\n",
      "epoch:17 step:13522[D loss: 0.416250, acc: 60.94%, op_acc: 41.41%] [G loss: 0.871278]\n",
      "epoch:17 step:13523[D loss: 0.447622, acc: 53.91%, op_acc: 36.72%] [G loss: 0.854412]\n",
      "epoch:17 step:13524[D loss: 0.412012, acc: 60.94%, op_acc: 43.75%] [G loss: 0.912824]\n",
      "epoch:17 step:13525[D loss: 0.447185, acc: 60.16%, op_acc: 32.81%] [G loss: 0.861410]\n",
      "epoch:17 step:13526[D loss: 0.420591, acc: 67.19%, op_acc: 40.62%] [G loss: 0.822963]\n",
      "epoch:17 step:13527[D loss: 0.423836, acc: 62.50%, op_acc: 39.84%] [G loss: 0.855109]\n",
      "epoch:17 step:13528[D loss: 0.407637, acc: 66.41%, op_acc: 42.19%] [G loss: 0.810675]\n",
      "epoch:17 step:13529[D loss: 0.441273, acc: 58.59%, op_acc: 36.72%] [G loss: 0.838526]\n",
      "epoch:17 step:13530[D loss: 0.429788, acc: 60.94%, op_acc: 36.72%] [G loss: 0.870657]\n",
      "epoch:17 step:13531[D loss: 0.455992, acc: 53.91%, op_acc: 35.16%] [G loss: 0.830223]\n",
      "epoch:17 step:13532[D loss: 0.454756, acc: 55.47%, op_acc: 33.59%] [G loss: 0.863184]\n",
      "epoch:17 step:13533[D loss: 0.408376, acc: 57.03%, op_acc: 38.28%] [G loss: 0.910874]\n",
      "epoch:17 step:13534[D loss: 0.438324, acc: 58.59%, op_acc: 36.72%] [G loss: 0.881296]\n",
      "epoch:17 step:13535[D loss: 0.407783, acc: 67.97%, op_acc: 42.19%] [G loss: 0.878304]\n",
      "epoch:17 step:13536[D loss: 0.406752, acc: 64.06%, op_acc: 43.75%] [G loss: 0.896796]\n",
      "epoch:17 step:13537[D loss: 0.454482, acc: 60.94%, op_acc: 39.06%] [G loss: 0.919237]\n",
      "epoch:17 step:13538[D loss: 0.435641, acc: 57.03%, op_acc: 41.41%] [G loss: 0.911107]\n",
      "epoch:17 step:13539[D loss: 0.424156, acc: 60.16%, op_acc: 37.50%] [G loss: 0.874647]\n",
      "epoch:17 step:13540[D loss: 0.427007, acc: 62.50%, op_acc: 35.16%] [G loss: 0.842610]\n",
      "epoch:17 step:13541[D loss: 0.406054, acc: 61.72%, op_acc: 39.06%] [G loss: 0.940750]\n",
      "epoch:17 step:13542[D loss: 0.382783, acc: 69.53%, op_acc: 42.19%] [G loss: 0.926077]\n",
      "epoch:17 step:13543[D loss: 0.423587, acc: 55.47%, op_acc: 42.97%] [G loss: 0.936244]\n",
      "epoch:17 step:13544[D loss: 0.438829, acc: 57.03%, op_acc: 35.16%] [G loss: 0.964373]\n",
      "epoch:17 step:13545[D loss: 0.425421, acc: 57.81%, op_acc: 42.19%] [G loss: 0.869701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13546[D loss: 0.411217, acc: 57.81%, op_acc: 39.84%] [G loss: 0.959068]\n",
      "epoch:17 step:13547[D loss: 0.433087, acc: 57.81%, op_acc: 37.50%] [G loss: 0.894855]\n",
      "epoch:17 step:13548[D loss: 0.417932, acc: 56.25%, op_acc: 42.19%] [G loss: 0.914789]\n",
      "epoch:17 step:13549[D loss: 0.426398, acc: 62.50%, op_acc: 35.94%] [G loss: 0.822040]\n",
      "epoch:17 step:13550[D loss: 0.438626, acc: 51.56%, op_acc: 38.28%] [G loss: 0.869233]\n",
      "epoch:17 step:13551[D loss: 0.449927, acc: 59.38%, op_acc: 36.72%] [G loss: 1.008828]\n",
      "epoch:17 step:13552[D loss: 0.419057, acc: 61.72%, op_acc: 39.06%] [G loss: 0.896085]\n",
      "epoch:17 step:13553[D loss: 0.478863, acc: 44.53%, op_acc: 39.06%] [G loss: 0.855171]\n",
      "epoch:17 step:13554[D loss: 0.436217, acc: 62.50%, op_acc: 35.16%] [G loss: 0.905473]\n",
      "epoch:17 step:13555[D loss: 0.441315, acc: 60.16%, op_acc: 43.75%] [G loss: 0.890618]\n",
      "epoch:17 step:13556[D loss: 0.427263, acc: 65.62%, op_acc: 38.28%] [G loss: 0.900138]\n",
      "epoch:17 step:13557[D loss: 0.452076, acc: 50.78%, op_acc: 36.72%] [G loss: 0.901656]\n",
      "epoch:17 step:13558[D loss: 0.460615, acc: 52.34%, op_acc: 32.03%] [G loss: 0.875762]\n",
      "epoch:17 step:13559[D loss: 0.457711, acc: 53.12%, op_acc: 34.38%] [G loss: 0.854375]\n",
      "epoch:17 step:13560[D loss: 0.419780, acc: 62.50%, op_acc: 39.84%] [G loss: 0.918402]\n",
      "epoch:17 step:13561[D loss: 0.423087, acc: 61.72%, op_acc: 35.16%] [G loss: 0.948310]\n",
      "epoch:17 step:13562[D loss: 0.421402, acc: 59.38%, op_acc: 39.84%] [G loss: 0.901712]\n",
      "epoch:17 step:13563[D loss: 0.449592, acc: 58.59%, op_acc: 35.94%] [G loss: 0.840189]\n",
      "epoch:17 step:13564[D loss: 0.452771, acc: 56.25%, op_acc: 38.28%] [G loss: 0.900314]\n",
      "epoch:17 step:13565[D loss: 0.420920, acc: 56.25%, op_acc: 42.97%] [G loss: 0.934518]\n",
      "epoch:17 step:13566[D loss: 0.444619, acc: 55.47%, op_acc: 40.62%] [G loss: 0.939688]\n",
      "epoch:17 step:13567[D loss: 0.433779, acc: 65.62%, op_acc: 38.28%] [G loss: 0.808110]\n",
      "epoch:17 step:13568[D loss: 0.413394, acc: 66.41%, op_acc: 42.19%] [G loss: 0.973655]\n",
      "epoch:17 step:13569[D loss: 0.456491, acc: 55.47%, op_acc: 32.03%] [G loss: 0.973476]\n",
      "epoch:17 step:13570[D loss: 0.417988, acc: 62.50%, op_acc: 39.06%] [G loss: 0.888164]\n",
      "epoch:17 step:13571[D loss: 0.420015, acc: 64.84%, op_acc: 36.72%] [G loss: 0.845708]\n",
      "epoch:17 step:13572[D loss: 0.403083, acc: 63.28%, op_acc: 40.62%] [G loss: 0.988385]\n",
      "epoch:17 step:13573[D loss: 0.429153, acc: 58.59%, op_acc: 36.72%] [G loss: 0.870755]\n",
      "epoch:17 step:13574[D loss: 0.450531, acc: 62.50%, op_acc: 32.03%] [G loss: 0.916324]\n",
      "epoch:17 step:13575[D loss: 0.427183, acc: 60.94%, op_acc: 35.94%] [G loss: 0.886840]\n",
      "epoch:17 step:13576[D loss: 0.428098, acc: 59.38%, op_acc: 38.28%] [G loss: 0.871572]\n",
      "epoch:17 step:13577[D loss: 0.431745, acc: 60.94%, op_acc: 39.84%] [G loss: 0.893876]\n",
      "epoch:17 step:13578[D loss: 0.400606, acc: 65.62%, op_acc: 36.72%] [G loss: 0.881240]\n",
      "epoch:17 step:13579[D loss: 0.417824, acc: 56.25%, op_acc: 40.62%] [G loss: 0.839095]\n",
      "epoch:17 step:13580[D loss: 0.416411, acc: 62.50%, op_acc: 35.16%] [G loss: 0.848027]\n",
      "epoch:17 step:13581[D loss: 0.435823, acc: 57.03%, op_acc: 35.94%] [G loss: 0.858937]\n",
      "epoch:17 step:13582[D loss: 0.421372, acc: 64.06%, op_acc: 37.50%] [G loss: 0.851557]\n",
      "epoch:17 step:13583[D loss: 0.446916, acc: 59.38%, op_acc: 35.94%] [G loss: 0.888041]\n",
      "epoch:17 step:13584[D loss: 0.438434, acc: 56.25%, op_acc: 37.50%] [G loss: 0.806947]\n",
      "epoch:17 step:13585[D loss: 0.444079, acc: 57.03%, op_acc: 34.38%] [G loss: 0.909869]\n",
      "epoch:17 step:13586[D loss: 0.473205, acc: 56.25%, op_acc: 28.12%] [G loss: 0.840836]\n",
      "epoch:17 step:13587[D loss: 0.425025, acc: 60.16%, op_acc: 39.84%] [G loss: 0.876861]\n",
      "epoch:17 step:13588[D loss: 0.455594, acc: 54.69%, op_acc: 32.03%] [G loss: 0.843985]\n",
      "epoch:17 step:13589[D loss: 0.435207, acc: 58.59%, op_acc: 38.28%] [G loss: 0.915647]\n",
      "epoch:17 step:13590[D loss: 0.418040, acc: 62.50%, op_acc: 41.41%] [G loss: 0.913870]\n",
      "epoch:17 step:13591[D loss: 0.410259, acc: 60.16%, op_acc: 40.62%] [G loss: 0.893547]\n",
      "epoch:17 step:13592[D loss: 0.453578, acc: 53.12%, op_acc: 39.06%] [G loss: 0.883634]\n",
      "epoch:17 step:13593[D loss: 0.431069, acc: 60.16%, op_acc: 35.94%] [G loss: 0.849306]\n",
      "epoch:17 step:13594[D loss: 0.463760, acc: 54.69%, op_acc: 34.38%] [G loss: 0.938238]\n",
      "epoch:17 step:13595[D loss: 0.445177, acc: 55.47%, op_acc: 36.72%] [G loss: 0.873898]\n",
      "epoch:17 step:13596[D loss: 0.434848, acc: 57.81%, op_acc: 32.81%] [G loss: 0.851092]\n",
      "epoch:17 step:13597[D loss: 0.425321, acc: 64.06%, op_acc: 32.81%] [G loss: 0.857328]\n",
      "epoch:17 step:13598[D loss: 0.425978, acc: 64.84%, op_acc: 40.62%] [G loss: 0.919235]\n",
      "epoch:17 step:13599[D loss: 0.437668, acc: 54.69%, op_acc: 34.38%] [G loss: 0.865401]\n",
      "epoch:17 step:13600[D loss: 0.451516, acc: 52.34%, op_acc: 36.72%] [G loss: 0.834947]\n",
      "epoch:17 step:13601[D loss: 0.469716, acc: 50.78%, op_acc: 29.69%] [G loss: 0.795195]\n",
      "epoch:17 step:13602[D loss: 0.423474, acc: 57.81%, op_acc: 39.84%] [G loss: 0.926208]\n",
      "epoch:17 step:13603[D loss: 0.420238, acc: 65.62%, op_acc: 39.84%] [G loss: 0.835830]\n",
      "epoch:17 step:13604[D loss: 0.447218, acc: 54.69%, op_acc: 32.81%] [G loss: 0.871081]\n",
      "epoch:17 step:13605[D loss: 0.433114, acc: 57.81%, op_acc: 36.72%] [G loss: 0.857856]\n",
      "epoch:17 step:13606[D loss: 0.405325, acc: 68.75%, op_acc: 41.41%] [G loss: 0.887717]\n",
      "epoch:17 step:13607[D loss: 0.402786, acc: 62.50%, op_acc: 46.88%] [G loss: 0.897803]\n",
      "epoch:17 step:13608[D loss: 0.418259, acc: 58.59%, op_acc: 39.06%] [G loss: 0.963576]\n",
      "epoch:17 step:13609[D loss: 0.411592, acc: 64.84%, op_acc: 42.19%] [G loss: 0.909690]\n",
      "epoch:17 step:13610[D loss: 0.432773, acc: 60.94%, op_acc: 39.84%] [G loss: 0.852553]\n",
      "epoch:17 step:13611[D loss: 0.421650, acc: 58.59%, op_acc: 46.09%] [G loss: 0.922330]\n",
      "epoch:17 step:13612[D loss: 0.454724, acc: 52.34%, op_acc: 35.94%] [G loss: 0.843371]\n",
      "epoch:17 step:13613[D loss: 0.442865, acc: 59.38%, op_acc: 37.50%] [G loss: 0.823842]\n",
      "epoch:17 step:13614[D loss: 0.436716, acc: 59.38%, op_acc: 34.38%] [G loss: 0.914249]\n",
      "epoch:17 step:13615[D loss: 0.415450, acc: 61.72%, op_acc: 41.41%] [G loss: 0.831238]\n",
      "epoch:17 step:13616[D loss: 0.406367, acc: 66.41%, op_acc: 39.84%] [G loss: 1.029085]\n",
      "epoch:17 step:13617[D loss: 0.437851, acc: 55.47%, op_acc: 34.38%] [G loss: 0.872195]\n",
      "epoch:17 step:13618[D loss: 0.433842, acc: 58.59%, op_acc: 37.50%] [G loss: 0.866706]\n",
      "epoch:17 step:13619[D loss: 0.448780, acc: 53.12%, op_acc: 31.25%] [G loss: 0.921825]\n",
      "epoch:17 step:13620[D loss: 0.428300, acc: 63.28%, op_acc: 33.59%] [G loss: 0.872072]\n",
      "epoch:17 step:13621[D loss: 0.454187, acc: 47.66%, op_acc: 38.28%] [G loss: 0.881886]\n",
      "epoch:17 step:13622[D loss: 0.421725, acc: 60.94%, op_acc: 40.62%] [G loss: 0.816767]\n",
      "epoch:17 step:13623[D loss: 0.408561, acc: 64.06%, op_acc: 37.50%] [G loss: 0.923779]\n",
      "epoch:17 step:13624[D loss: 0.434840, acc: 59.38%, op_acc: 37.50%] [G loss: 0.878672]\n",
      "epoch:17 step:13625[D loss: 0.442660, acc: 60.94%, op_acc: 33.59%] [G loss: 0.851919]\n",
      "epoch:17 step:13626[D loss: 0.464805, acc: 50.00%, op_acc: 37.50%] [G loss: 0.884631]\n",
      "epoch:17 step:13627[D loss: 0.427786, acc: 61.72%, op_acc: 35.94%] [G loss: 0.969214]\n",
      "epoch:17 step:13628[D loss: 0.438002, acc: 56.25%, op_acc: 36.72%] [G loss: 0.886965]\n",
      "epoch:17 step:13629[D loss: 0.455748, acc: 57.03%, op_acc: 33.59%] [G loss: 0.783431]\n",
      "epoch:17 step:13630[D loss: 0.415298, acc: 58.59%, op_acc: 38.28%] [G loss: 0.919713]\n",
      "epoch:17 step:13631[D loss: 0.416003, acc: 58.59%, op_acc: 37.50%] [G loss: 0.891552]\n",
      "epoch:17 step:13632[D loss: 0.433642, acc: 61.72%, op_acc: 38.28%] [G loss: 0.836308]\n",
      "epoch:17 step:13633[D loss: 0.415383, acc: 60.16%, op_acc: 36.72%] [G loss: 0.851949]\n",
      "epoch:17 step:13634[D loss: 0.438283, acc: 60.94%, op_acc: 38.28%] [G loss: 0.886189]\n",
      "epoch:17 step:13635[D loss: 0.435104, acc: 64.06%, op_acc: 39.06%] [G loss: 0.981007]\n",
      "epoch:17 step:13636[D loss: 0.422464, acc: 64.84%, op_acc: 40.62%] [G loss: 0.864827]\n",
      "epoch:17 step:13637[D loss: 0.440086, acc: 56.25%, op_acc: 39.06%] [G loss: 0.909094]\n",
      "epoch:17 step:13638[D loss: 0.423241, acc: 57.03%, op_acc: 41.41%] [G loss: 0.948546]\n",
      "epoch:17 step:13639[D loss: 0.408381, acc: 60.94%, op_acc: 40.62%] [G loss: 0.895326]\n",
      "epoch:17 step:13640[D loss: 0.411688, acc: 67.97%, op_acc: 37.50%] [G loss: 0.933397]\n",
      "epoch:17 step:13641[D loss: 0.417750, acc: 60.16%, op_acc: 39.84%] [G loss: 0.945043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13642[D loss: 0.413324, acc: 62.50%, op_acc: 38.28%] [G loss: 0.858704]\n",
      "epoch:17 step:13643[D loss: 0.437745, acc: 54.69%, op_acc: 37.50%] [G loss: 0.936177]\n",
      "epoch:17 step:13644[D loss: 0.461515, acc: 56.25%, op_acc: 32.81%] [G loss: 0.903551]\n",
      "epoch:17 step:13645[D loss: 0.450347, acc: 63.28%, op_acc: 32.81%] [G loss: 0.842722]\n",
      "epoch:17 step:13646[D loss: 0.418633, acc: 62.50%, op_acc: 35.16%] [G loss: 0.852449]\n",
      "epoch:17 step:13647[D loss: 0.441875, acc: 54.69%, op_acc: 37.50%] [G loss: 0.850934]\n",
      "epoch:17 step:13648[D loss: 0.403682, acc: 56.25%, op_acc: 44.53%] [G loss: 1.004696]\n",
      "epoch:17 step:13649[D loss: 0.422639, acc: 58.59%, op_acc: 38.28%] [G loss: 0.919233]\n",
      "epoch:17 step:13650[D loss: 0.446807, acc: 55.47%, op_acc: 45.31%] [G loss: 0.865260]\n",
      "epoch:17 step:13651[D loss: 0.436870, acc: 54.69%, op_acc: 35.94%] [G loss: 0.870159]\n",
      "epoch:17 step:13652[D loss: 0.419177, acc: 63.28%, op_acc: 40.62%] [G loss: 0.893996]\n",
      "epoch:17 step:13653[D loss: 0.434994, acc: 56.25%, op_acc: 35.16%] [G loss: 0.807764]\n",
      "epoch:17 step:13654[D loss: 0.429965, acc: 57.81%, op_acc: 36.72%] [G loss: 0.798046]\n",
      "epoch:17 step:13655[D loss: 0.415035, acc: 64.06%, op_acc: 39.84%] [G loss: 0.923686]\n",
      "epoch:17 step:13656[D loss: 0.416124, acc: 62.50%, op_acc: 34.38%] [G loss: 0.870848]\n",
      "epoch:17 step:13657[D loss: 0.397689, acc: 67.19%, op_acc: 34.38%] [G loss: 0.938216]\n",
      "epoch:17 step:13658[D loss: 0.443858, acc: 59.38%, op_acc: 38.28%] [G loss: 0.950032]\n",
      "epoch:17 step:13659[D loss: 0.423139, acc: 64.06%, op_acc: 36.72%] [G loss: 0.889352]\n",
      "epoch:17 step:13660[D loss: 0.426241, acc: 57.81%, op_acc: 50.00%] [G loss: 0.938846]\n",
      "epoch:17 step:13661[D loss: 0.386043, acc: 67.97%, op_acc: 40.62%] [G loss: 0.918586]\n",
      "epoch:17 step:13662[D loss: 0.439748, acc: 54.69%, op_acc: 39.06%] [G loss: 0.929736]\n",
      "epoch:17 step:13663[D loss: 0.429978, acc: 55.47%, op_acc: 39.06%] [G loss: 0.808412]\n",
      "epoch:17 step:13664[D loss: 0.429535, acc: 63.28%, op_acc: 36.72%] [G loss: 0.853581]\n",
      "epoch:17 step:13665[D loss: 0.435053, acc: 64.06%, op_acc: 37.50%] [G loss: 0.856318]\n",
      "epoch:17 step:13666[D loss: 0.459951, acc: 47.66%, op_acc: 38.28%] [G loss: 0.839719]\n",
      "epoch:17 step:13667[D loss: 0.403110, acc: 64.84%, op_acc: 42.97%] [G loss: 0.907480]\n",
      "epoch:17 step:13668[D loss: 0.431189, acc: 59.38%, op_acc: 41.41%] [G loss: 0.860610]\n",
      "epoch:17 step:13669[D loss: 0.413340, acc: 56.25%, op_acc: 41.41%] [G loss: 0.832314]\n",
      "epoch:17 step:13670[D loss: 0.416244, acc: 58.59%, op_acc: 36.72%] [G loss: 0.870925]\n",
      "epoch:17 step:13671[D loss: 0.441419, acc: 60.16%, op_acc: 35.94%] [G loss: 0.870671]\n",
      "epoch:17 step:13672[D loss: 0.442287, acc: 58.59%, op_acc: 32.03%] [G loss: 0.869863]\n",
      "epoch:17 step:13673[D loss: 0.433715, acc: 60.16%, op_acc: 36.72%] [G loss: 0.864514]\n",
      "epoch:17 step:13674[D loss: 0.433178, acc: 53.12%, op_acc: 39.06%] [G loss: 0.831221]\n",
      "epoch:17 step:13675[D loss: 0.468297, acc: 50.00%, op_acc: 37.50%] [G loss: 0.927138]\n",
      "epoch:17 step:13676[D loss: 0.450774, acc: 53.91%, op_acc: 36.72%] [G loss: 0.860770]\n",
      "epoch:17 step:13677[D loss: 0.404273, acc: 68.75%, op_acc: 35.94%] [G loss: 0.925878]\n",
      "epoch:17 step:13678[D loss: 0.411394, acc: 65.62%, op_acc: 37.50%] [G loss: 0.954308]\n",
      "epoch:17 step:13679[D loss: 0.432281, acc: 64.84%, op_acc: 33.59%] [G loss: 0.975743]\n",
      "epoch:17 step:13680[D loss: 0.429523, acc: 61.72%, op_acc: 35.94%] [G loss: 0.869098]\n",
      "epoch:17 step:13681[D loss: 0.397637, acc: 64.84%, op_acc: 39.84%] [G loss: 0.904666]\n",
      "epoch:17 step:13682[D loss: 0.446423, acc: 52.34%, op_acc: 40.62%] [G loss: 0.942445]\n",
      "epoch:17 step:13683[D loss: 0.426306, acc: 58.59%, op_acc: 35.16%] [G loss: 0.906066]\n",
      "epoch:17 step:13684[D loss: 0.441509, acc: 58.59%, op_acc: 32.81%] [G loss: 0.905486]\n",
      "epoch:17 step:13685[D loss: 0.434235, acc: 53.12%, op_acc: 42.97%] [G loss: 0.947626]\n",
      "epoch:17 step:13686[D loss: 0.437558, acc: 57.03%, op_acc: 41.41%] [G loss: 0.898627]\n",
      "epoch:17 step:13687[D loss: 0.406792, acc: 57.81%, op_acc: 41.41%] [G loss: 0.913948]\n",
      "epoch:17 step:13688[D loss: 0.447428, acc: 49.22%, op_acc: 42.97%] [G loss: 0.945921]\n",
      "epoch:17 step:13689[D loss: 0.423998, acc: 60.94%, op_acc: 39.84%] [G loss: 0.864144]\n",
      "epoch:17 step:13690[D loss: 0.434649, acc: 58.59%, op_acc: 38.28%] [G loss: 0.835456]\n",
      "epoch:17 step:13691[D loss: 0.439145, acc: 53.91%, op_acc: 35.16%] [G loss: 0.855653]\n",
      "epoch:17 step:13692[D loss: 0.396308, acc: 65.62%, op_acc: 37.50%] [G loss: 0.888489]\n",
      "epoch:17 step:13693[D loss: 0.414864, acc: 63.28%, op_acc: 36.72%] [G loss: 0.909551]\n",
      "epoch:17 step:13694[D loss: 0.430618, acc: 59.38%, op_acc: 38.28%] [G loss: 0.942847]\n",
      "epoch:17 step:13695[D loss: 0.414354, acc: 64.06%, op_acc: 36.72%] [G loss: 0.796602]\n",
      "epoch:17 step:13696[D loss: 0.427952, acc: 57.81%, op_acc: 37.50%] [G loss: 0.833369]\n",
      "epoch:17 step:13697[D loss: 0.455997, acc: 49.22%, op_acc: 36.72%] [G loss: 0.864782]\n",
      "epoch:17 step:13698[D loss: 0.451821, acc: 57.03%, op_acc: 33.59%] [G loss: 0.843236]\n",
      "epoch:17 step:13699[D loss: 0.409678, acc: 62.50%, op_acc: 42.97%] [G loss: 0.963951]\n",
      "epoch:17 step:13700[D loss: 0.438040, acc: 56.25%, op_acc: 32.81%] [G loss: 0.978138]\n",
      "epoch:17 step:13701[D loss: 0.468856, acc: 50.00%, op_acc: 32.81%] [G loss: 0.851137]\n",
      "epoch:17 step:13702[D loss: 0.430021, acc: 61.72%, op_acc: 36.72%] [G loss: 0.788475]\n",
      "epoch:17 step:13703[D loss: 0.451785, acc: 60.16%, op_acc: 32.03%] [G loss: 0.830583]\n",
      "epoch:17 step:13704[D loss: 0.419720, acc: 58.59%, op_acc: 37.50%] [G loss: 0.835341]\n",
      "epoch:17 step:13705[D loss: 0.474196, acc: 47.66%, op_acc: 34.38%] [G loss: 0.820497]\n",
      "epoch:17 step:13706[D loss: 0.427673, acc: 59.38%, op_acc: 38.28%] [G loss: 0.843582]\n",
      "epoch:17 step:13707[D loss: 0.436666, acc: 64.06%, op_acc: 36.72%] [G loss: 0.861826]\n",
      "epoch:17 step:13708[D loss: 0.417355, acc: 58.59%, op_acc: 41.41%] [G loss: 0.858254]\n",
      "epoch:17 step:13709[D loss: 0.435453, acc: 57.81%, op_acc: 35.16%] [G loss: 0.853895]\n",
      "epoch:17 step:13710[D loss: 0.439151, acc: 55.47%, op_acc: 35.16%] [G loss: 0.851829]\n",
      "epoch:17 step:13711[D loss: 0.411887, acc: 60.94%, op_acc: 42.97%] [G loss: 0.881339]\n",
      "epoch:17 step:13712[D loss: 0.428429, acc: 53.91%, op_acc: 39.06%] [G loss: 0.829898]\n",
      "epoch:17 step:13713[D loss: 0.446179, acc: 57.03%, op_acc: 40.62%] [G loss: 0.894187]\n",
      "epoch:17 step:13714[D loss: 0.454705, acc: 53.12%, op_acc: 36.72%] [G loss: 0.877113]\n",
      "epoch:17 step:13715[D loss: 0.428132, acc: 57.03%, op_acc: 40.62%] [G loss: 0.875660]\n",
      "epoch:17 step:13716[D loss: 0.416136, acc: 58.59%, op_acc: 42.19%] [G loss: 0.935594]\n",
      "epoch:17 step:13717[D loss: 0.414854, acc: 68.75%, op_acc: 34.38%] [G loss: 0.888060]\n",
      "epoch:17 step:13718[D loss: 0.428300, acc: 63.28%, op_acc: 35.94%] [G loss: 0.938162]\n",
      "epoch:17 step:13719[D loss: 0.401306, acc: 62.50%, op_acc: 41.41%] [G loss: 0.840491]\n",
      "epoch:17 step:13720[D loss: 0.447570, acc: 56.25%, op_acc: 35.94%] [G loss: 0.858675]\n",
      "epoch:17 step:13721[D loss: 0.395434, acc: 63.28%, op_acc: 43.75%] [G loss: 0.936039]\n",
      "epoch:17 step:13722[D loss: 0.431284, acc: 56.25%, op_acc: 35.94%] [G loss: 0.954970]\n",
      "epoch:17 step:13723[D loss: 0.399567, acc: 59.38%, op_acc: 39.06%] [G loss: 0.988503]\n",
      "epoch:17 step:13724[D loss: 0.432775, acc: 57.03%, op_acc: 34.38%] [G loss: 0.923635]\n",
      "epoch:17 step:13725[D loss: 0.417755, acc: 61.72%, op_acc: 35.94%] [G loss: 0.867994]\n",
      "epoch:17 step:13726[D loss: 0.392742, acc: 67.19%, op_acc: 39.06%] [G loss: 0.899455]\n",
      "epoch:17 step:13727[D loss: 0.446646, acc: 63.28%, op_acc: 28.91%] [G loss: 0.948201]\n",
      "epoch:17 step:13728[D loss: 0.434968, acc: 50.78%, op_acc: 37.50%] [G loss: 0.891326]\n",
      "epoch:17 step:13729[D loss: 0.436063, acc: 51.56%, op_acc: 40.62%] [G loss: 0.935241]\n",
      "epoch:17 step:13730[D loss: 0.412868, acc: 57.03%, op_acc: 39.84%] [G loss: 0.863598]\n",
      "epoch:17 step:13731[D loss: 0.420412, acc: 56.25%, op_acc: 39.06%] [G loss: 0.910615]\n",
      "epoch:17 step:13732[D loss: 0.439229, acc: 63.28%, op_acc: 39.84%] [G loss: 0.989560]\n",
      "epoch:17 step:13733[D loss: 0.460381, acc: 50.00%, op_acc: 42.97%] [G loss: 0.865058]\n",
      "epoch:17 step:13734[D loss: 0.404127, acc: 71.09%, op_acc: 39.84%] [G loss: 0.940037]\n",
      "epoch:17 step:13735[D loss: 0.395628, acc: 68.75%, op_acc: 40.62%] [G loss: 0.962842]\n",
      "epoch:17 step:13736[D loss: 0.419738, acc: 53.12%, op_acc: 42.19%] [G loss: 0.819404]\n",
      "epoch:17 step:13737[D loss: 0.428752, acc: 53.91%, op_acc: 39.06%] [G loss: 0.843331]\n",
      "epoch:17 step:13738[D loss: 0.457351, acc: 48.44%, op_acc: 42.97%] [G loss: 0.917200]\n",
      "epoch:17 step:13739[D loss: 0.435937, acc: 54.69%, op_acc: 45.31%] [G loss: 0.873996]\n",
      "epoch:17 step:13740[D loss: 0.408358, acc: 65.62%, op_acc: 46.09%] [G loss: 0.923569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13741[D loss: 0.447213, acc: 60.94%, op_acc: 35.94%] [G loss: 0.835541]\n",
      "epoch:17 step:13742[D loss: 0.437143, acc: 60.16%, op_acc: 35.94%] [G loss: 0.881789]\n",
      "epoch:17 step:13743[D loss: 0.401411, acc: 66.41%, op_acc: 36.72%] [G loss: 0.853719]\n",
      "epoch:17 step:13744[D loss: 0.428076, acc: 57.03%, op_acc: 39.84%] [G loss: 0.849702]\n",
      "epoch:17 step:13745[D loss: 0.427196, acc: 58.59%, op_acc: 39.84%] [G loss: 0.836243]\n",
      "epoch:17 step:13746[D loss: 0.389057, acc: 67.19%, op_acc: 39.84%] [G loss: 0.911093]\n",
      "epoch:17 step:13747[D loss: 0.413636, acc: 60.16%, op_acc: 36.72%] [G loss: 0.832814]\n",
      "epoch:17 step:13748[D loss: 0.453894, acc: 53.12%, op_acc: 32.03%] [G loss: 0.881382]\n",
      "epoch:17 step:13749[D loss: 0.430650, acc: 60.94%, op_acc: 32.03%] [G loss: 0.850509]\n",
      "epoch:17 step:13750[D loss: 0.405268, acc: 61.72%, op_acc: 42.97%] [G loss: 0.843249]\n",
      "epoch:17 step:13751[D loss: 0.443106, acc: 50.78%, op_acc: 37.50%] [G loss: 0.819265]\n",
      "epoch:17 step:13752[D loss: 0.409792, acc: 60.94%, op_acc: 42.97%] [G loss: 0.864706]\n",
      "epoch:17 step:13753[D loss: 0.450168, acc: 58.59%, op_acc: 35.94%] [G loss: 0.920351]\n",
      "epoch:17 step:13754[D loss: 0.436928, acc: 58.59%, op_acc: 39.06%] [G loss: 0.868467]\n",
      "epoch:17 step:13755[D loss: 0.418590, acc: 61.72%, op_acc: 40.62%] [G loss: 0.843973]\n",
      "epoch:17 step:13756[D loss: 0.430414, acc: 59.38%, op_acc: 38.28%] [G loss: 0.887568]\n",
      "epoch:17 step:13757[D loss: 0.455016, acc: 57.03%, op_acc: 35.16%] [G loss: 0.848537]\n",
      "epoch:17 step:13758[D loss: 0.447446, acc: 66.41%, op_acc: 25.78%] [G loss: 0.844738]\n",
      "epoch:17 step:13759[D loss: 0.432064, acc: 61.72%, op_acc: 42.97%] [G loss: 0.913594]\n",
      "epoch:17 step:13760[D loss: 0.417473, acc: 59.38%, op_acc: 39.84%] [G loss: 0.880743]\n",
      "epoch:17 step:13761[D loss: 0.431956, acc: 57.81%, op_acc: 40.62%] [G loss: 0.848218]\n",
      "epoch:17 step:13762[D loss: 0.417668, acc: 64.84%, op_acc: 38.28%] [G loss: 0.925253]\n",
      "epoch:17 step:13763[D loss: 0.444012, acc: 54.69%, op_acc: 32.81%] [G loss: 0.804173]\n",
      "epoch:17 step:13764[D loss: 0.414040, acc: 63.28%, op_acc: 38.28%] [G loss: 0.962304]\n",
      "epoch:17 step:13765[D loss: 0.418313, acc: 67.97%, op_acc: 29.69%] [G loss: 0.917735]\n",
      "epoch:17 step:13766[D loss: 0.438924, acc: 54.69%, op_acc: 38.28%] [G loss: 0.850054]\n",
      "epoch:17 step:13767[D loss: 0.417713, acc: 60.16%, op_acc: 39.84%] [G loss: 0.838060]\n",
      "epoch:17 step:13768[D loss: 0.465691, acc: 57.81%, op_acc: 35.94%] [G loss: 0.822835]\n",
      "epoch:17 step:13769[D loss: 0.397457, acc: 69.53%, op_acc: 35.16%] [G loss: 0.874392]\n",
      "epoch:17 step:13770[D loss: 0.443969, acc: 53.12%, op_acc: 35.94%] [G loss: 0.881139]\n",
      "epoch:17 step:13771[D loss: 0.405761, acc: 63.28%, op_acc: 35.94%] [G loss: 0.910741]\n",
      "epoch:17 step:13772[D loss: 0.442057, acc: 59.38%, op_acc: 37.50%] [G loss: 0.897948]\n",
      "epoch:17 step:13773[D loss: 0.417781, acc: 64.06%, op_acc: 37.50%] [G loss: 0.838461]\n",
      "epoch:17 step:13774[D loss: 0.415823, acc: 65.62%, op_acc: 42.97%] [G loss: 0.899846]\n",
      "epoch:17 step:13775[D loss: 0.443026, acc: 55.47%, op_acc: 35.16%] [G loss: 0.910845]\n",
      "epoch:17 step:13776[D loss: 0.439812, acc: 59.38%, op_acc: 37.50%] [G loss: 0.880398]\n",
      "epoch:17 step:13777[D loss: 0.387404, acc: 67.97%, op_acc: 37.50%] [G loss: 0.889771]\n",
      "epoch:17 step:13778[D loss: 0.428063, acc: 59.38%, op_acc: 39.06%] [G loss: 0.960285]\n",
      "epoch:17 step:13779[D loss: 0.426548, acc: 57.81%, op_acc: 39.06%] [G loss: 0.888286]\n",
      "epoch:17 step:13780[D loss: 0.423776, acc: 65.62%, op_acc: 35.16%] [G loss: 0.841437]\n",
      "epoch:17 step:13781[D loss: 0.440788, acc: 60.16%, op_acc: 34.38%] [G loss: 0.890564]\n",
      "epoch:17 step:13782[D loss: 0.403209, acc: 66.41%, op_acc: 40.62%] [G loss: 0.960934]\n",
      "epoch:17 step:13783[D loss: 0.430091, acc: 57.81%, op_acc: 41.41%] [G loss: 0.909045]\n",
      "epoch:17 step:13784[D loss: 0.412481, acc: 62.50%, op_acc: 38.28%] [G loss: 0.917920]\n",
      "epoch:17 step:13785[D loss: 0.413750, acc: 59.38%, op_acc: 32.81%] [G loss: 0.853758]\n",
      "epoch:17 step:13786[D loss: 0.453938, acc: 51.56%, op_acc: 45.31%] [G loss: 0.899833]\n",
      "epoch:17 step:13787[D loss: 0.434577, acc: 63.28%, op_acc: 36.72%] [G loss: 0.937179]\n",
      "epoch:17 step:13788[D loss: 0.438805, acc: 55.47%, op_acc: 38.28%] [G loss: 0.873839]\n",
      "epoch:17 step:13789[D loss: 0.456304, acc: 49.22%, op_acc: 35.16%] [G loss: 0.888804]\n",
      "epoch:17 step:13790[D loss: 0.472782, acc: 55.47%, op_acc: 34.38%] [G loss: 0.900460]\n",
      "epoch:17 step:13791[D loss: 0.440085, acc: 57.81%, op_acc: 34.38%] [G loss: 0.916448]\n",
      "epoch:17 step:13792[D loss: 0.437051, acc: 60.16%, op_acc: 39.06%] [G loss: 0.937972]\n",
      "epoch:17 step:13793[D loss: 0.435133, acc: 58.59%, op_acc: 33.59%] [G loss: 0.819073]\n",
      "epoch:17 step:13794[D loss: 0.477112, acc: 53.91%, op_acc: 33.59%] [G loss: 0.836086]\n",
      "epoch:17 step:13795[D loss: 0.431131, acc: 64.84%, op_acc: 29.69%] [G loss: 1.014950]\n",
      "epoch:17 step:13796[D loss: 0.416087, acc: 62.50%, op_acc: 39.84%] [G loss: 0.799573]\n",
      "epoch:17 step:13797[D loss: 0.430771, acc: 58.59%, op_acc: 39.84%] [G loss: 0.856390]\n",
      "epoch:17 step:13798[D loss: 0.422605, acc: 64.06%, op_acc: 32.81%] [G loss: 0.869682]\n",
      "epoch:17 step:13799[D loss: 0.453175, acc: 58.59%, op_acc: 32.03%] [G loss: 0.817015]\n",
      "epoch:17 step:13800[D loss: 0.457580, acc: 53.12%, op_acc: 38.28%] [G loss: 0.822086]\n",
      "epoch:17 step:13801[D loss: 0.438707, acc: 53.12%, op_acc: 39.84%] [G loss: 0.884908]\n",
      "epoch:17 step:13802[D loss: 0.435330, acc: 57.81%, op_acc: 37.50%] [G loss: 0.861463]\n",
      "epoch:17 step:13803[D loss: 0.440392, acc: 65.62%, op_acc: 32.81%] [G loss: 0.930820]\n",
      "epoch:17 step:13804[D loss: 0.415021, acc: 61.72%, op_acc: 37.50%] [G loss: 0.867661]\n",
      "epoch:17 step:13805[D loss: 0.411100, acc: 70.31%, op_acc: 40.62%] [G loss: 0.887741]\n",
      "epoch:17 step:13806[D loss: 0.431851, acc: 53.12%, op_acc: 41.41%] [G loss: 0.820229]\n",
      "epoch:17 step:13807[D loss: 0.437324, acc: 57.81%, op_acc: 35.94%] [G loss: 0.838086]\n",
      "epoch:17 step:13808[D loss: 0.444814, acc: 59.38%, op_acc: 39.06%] [G loss: 0.985937]\n",
      "epoch:17 step:13809[D loss: 0.441799, acc: 59.38%, op_acc: 39.06%] [G loss: 0.911259]\n",
      "epoch:17 step:13810[D loss: 0.448775, acc: 52.34%, op_acc: 38.28%] [G loss: 0.882596]\n",
      "epoch:17 step:13811[D loss: 0.411513, acc: 62.50%, op_acc: 39.84%] [G loss: 0.933308]\n",
      "epoch:17 step:13812[D loss: 0.461236, acc: 52.34%, op_acc: 34.38%] [G loss: 0.859362]\n",
      "epoch:17 step:13813[D loss: 0.412678, acc: 55.47%, op_acc: 42.19%] [G loss: 0.846224]\n",
      "epoch:17 step:13814[D loss: 0.437019, acc: 58.59%, op_acc: 36.72%] [G loss: 0.979682]\n",
      "epoch:17 step:13815[D loss: 0.424646, acc: 57.81%, op_acc: 40.62%] [G loss: 0.804058]\n",
      "epoch:17 step:13816[D loss: 0.456873, acc: 52.34%, op_acc: 37.50%] [G loss: 0.908283]\n",
      "epoch:17 step:13817[D loss: 0.407090, acc: 55.47%, op_acc: 43.75%] [G loss: 0.828276]\n",
      "epoch:17 step:13818[D loss: 0.397200, acc: 64.06%, op_acc: 41.41%] [G loss: 0.828535]\n",
      "epoch:17 step:13819[D loss: 0.437245, acc: 55.47%, op_acc: 35.94%] [G loss: 0.855541]\n",
      "epoch:17 step:13820[D loss: 0.438655, acc: 55.47%, op_acc: 37.50%] [G loss: 0.860643]\n",
      "epoch:17 step:13821[D loss: 0.435630, acc: 60.16%, op_acc: 40.62%] [G loss: 0.841956]\n",
      "epoch:17 step:13822[D loss: 0.397562, acc: 64.84%, op_acc: 43.75%] [G loss: 0.893067]\n",
      "epoch:17 step:13823[D loss: 0.391193, acc: 65.62%, op_acc: 42.19%] [G loss: 0.952911]\n",
      "epoch:17 step:13824[D loss: 0.424283, acc: 63.28%, op_acc: 39.84%] [G loss: 0.922459]\n",
      "epoch:17 step:13825[D loss: 0.424904, acc: 64.84%, op_acc: 39.84%] [G loss: 0.983107]\n",
      "epoch:17 step:13826[D loss: 0.404717, acc: 66.41%, op_acc: 40.62%] [G loss: 0.954048]\n",
      "epoch:17 step:13827[D loss: 0.443967, acc: 53.12%, op_acc: 36.72%] [G loss: 0.968339]\n",
      "epoch:17 step:13828[D loss: 0.424300, acc: 56.25%, op_acc: 39.06%] [G loss: 0.859790]\n",
      "epoch:17 step:13829[D loss: 0.454608, acc: 56.25%, op_acc: 35.94%] [G loss: 0.875065]\n",
      "epoch:17 step:13830[D loss: 0.409918, acc: 55.47%, op_acc: 34.38%] [G loss: 0.889496]\n",
      "epoch:17 step:13831[D loss: 0.467322, acc: 58.59%, op_acc: 35.16%] [G loss: 0.861976]\n",
      "epoch:17 step:13832[D loss: 0.440975, acc: 51.56%, op_acc: 44.53%] [G loss: 0.835309]\n",
      "epoch:17 step:13833[D loss: 0.409862, acc: 64.84%, op_acc: 40.62%] [G loss: 0.870200]\n",
      "epoch:17 step:13834[D loss: 0.439648, acc: 62.50%, op_acc: 35.16%] [G loss: 0.897657]\n",
      "epoch:17 step:13835[D loss: 0.423919, acc: 57.03%, op_acc: 42.97%] [G loss: 0.865986]\n",
      "epoch:17 step:13836[D loss: 0.421215, acc: 60.94%, op_acc: 39.84%] [G loss: 0.768069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13837[D loss: 0.412199, acc: 71.88%, op_acc: 35.94%] [G loss: 0.910942]\n",
      "epoch:17 step:13838[D loss: 0.409457, acc: 59.38%, op_acc: 39.84%] [G loss: 0.833188]\n",
      "epoch:17 step:13839[D loss: 0.436424, acc: 57.81%, op_acc: 35.16%] [G loss: 0.937273]\n",
      "epoch:17 step:13840[D loss: 0.426788, acc: 58.59%, op_acc: 37.50%] [G loss: 0.922982]\n",
      "epoch:17 step:13841[D loss: 0.425145, acc: 61.72%, op_acc: 38.28%] [G loss: 0.910883]\n",
      "epoch:17 step:13842[D loss: 0.419390, acc: 63.28%, op_acc: 38.28%] [G loss: 0.933298]\n",
      "epoch:17 step:13843[D loss: 0.434424, acc: 57.81%, op_acc: 40.62%] [G loss: 0.902288]\n",
      "epoch:17 step:13844[D loss: 0.423100, acc: 63.28%, op_acc: 40.62%] [G loss: 0.979716]\n",
      "epoch:17 step:13845[D loss: 0.426002, acc: 53.91%, op_acc: 42.97%] [G loss: 0.850291]\n",
      "epoch:17 step:13846[D loss: 0.405803, acc: 62.50%, op_acc: 38.28%] [G loss: 0.922117]\n",
      "epoch:17 step:13847[D loss: 0.406994, acc: 66.41%, op_acc: 39.06%] [G loss: 0.891034]\n",
      "epoch:17 step:13848[D loss: 0.447246, acc: 58.59%, op_acc: 46.09%] [G loss: 0.952161]\n",
      "epoch:17 step:13849[D loss: 0.400557, acc: 65.62%, op_acc: 38.28%] [G loss: 0.911048]\n",
      "epoch:17 step:13850[D loss: 0.425466, acc: 56.25%, op_acc: 41.41%] [G loss: 0.813993]\n",
      "epoch:17 step:13851[D loss: 0.471493, acc: 53.91%, op_acc: 35.94%] [G loss: 0.964027]\n",
      "epoch:17 step:13852[D loss: 0.433630, acc: 57.03%, op_acc: 37.50%] [G loss: 0.883349]\n",
      "epoch:17 step:13853[D loss: 0.428600, acc: 62.50%, op_acc: 41.41%] [G loss: 0.974447]\n",
      "epoch:17 step:13854[D loss: 0.425342, acc: 63.28%, op_acc: 37.50%] [G loss: 0.936691]\n",
      "epoch:17 step:13855[D loss: 0.456701, acc: 63.28%, op_acc: 35.94%] [G loss: 0.885741]\n",
      "epoch:17 step:13856[D loss: 0.428805, acc: 58.59%, op_acc: 37.50%] [G loss: 0.879394]\n",
      "epoch:17 step:13857[D loss: 0.455451, acc: 54.69%, op_acc: 32.03%] [G loss: 0.943818]\n",
      "epoch:17 step:13858[D loss: 0.457044, acc: 59.38%, op_acc: 32.81%] [G loss: 0.887483]\n",
      "epoch:17 step:13859[D loss: 0.438132, acc: 57.03%, op_acc: 35.94%] [G loss: 0.885240]\n",
      "epoch:17 step:13860[D loss: 0.402957, acc: 63.28%, op_acc: 42.97%] [G loss: 0.917168]\n",
      "epoch:17 step:13861[D loss: 0.462286, acc: 60.16%, op_acc: 33.59%] [G loss: 0.947853]\n",
      "epoch:17 step:13862[D loss: 0.421815, acc: 60.16%, op_acc: 40.62%] [G loss: 0.892216]\n",
      "epoch:17 step:13863[D loss: 0.420100, acc: 65.62%, op_acc: 33.59%] [G loss: 0.954023]\n",
      "epoch:17 step:13864[D loss: 0.419212, acc: 65.62%, op_acc: 33.59%] [G loss: 0.917903]\n",
      "epoch:17 step:13865[D loss: 0.386760, acc: 70.31%, op_acc: 41.41%] [G loss: 1.004289]\n",
      "epoch:17 step:13866[D loss: 0.431364, acc: 60.16%, op_acc: 32.81%] [G loss: 0.930071]\n",
      "epoch:17 step:13867[D loss: 0.445490, acc: 55.47%, op_acc: 33.59%] [G loss: 0.846817]\n",
      "epoch:17 step:13868[D loss: 0.461042, acc: 48.44%, op_acc: 38.28%] [G loss: 0.871305]\n",
      "epoch:17 step:13869[D loss: 0.466096, acc: 54.69%, op_acc: 35.16%] [G loss: 0.877195]\n",
      "epoch:17 step:13870[D loss: 0.465032, acc: 50.78%, op_acc: 35.16%] [G loss: 0.875306]\n",
      "epoch:17 step:13871[D loss: 0.426989, acc: 56.25%, op_acc: 32.03%] [G loss: 0.993682]\n",
      "epoch:17 step:13872[D loss: 0.417574, acc: 62.50%, op_acc: 36.72%] [G loss: 0.906153]\n",
      "epoch:17 step:13873[D loss: 0.420887, acc: 61.72%, op_acc: 42.19%] [G loss: 0.917408]\n",
      "epoch:17 step:13874[D loss: 0.455264, acc: 59.38%, op_acc: 36.72%] [G loss: 0.852822]\n",
      "epoch:17 step:13875[D loss: 0.419134, acc: 67.19%, op_acc: 35.94%] [G loss: 0.850808]\n",
      "epoch:17 step:13876[D loss: 0.420376, acc: 63.28%, op_acc: 39.06%] [G loss: 0.878667]\n",
      "epoch:17 step:13877[D loss: 0.423053, acc: 59.38%, op_acc: 41.41%] [G loss: 0.919981]\n",
      "epoch:17 step:13878[D loss: 0.430819, acc: 59.38%, op_acc: 38.28%] [G loss: 0.880376]\n",
      "epoch:17 step:13879[D loss: 0.428088, acc: 56.25%, op_acc: 40.62%] [G loss: 0.858817]\n",
      "epoch:17 step:13880[D loss: 0.417319, acc: 57.03%, op_acc: 39.84%] [G loss: 0.863750]\n",
      "epoch:17 step:13881[D loss: 0.441040, acc: 58.59%, op_acc: 33.59%] [G loss: 0.883681]\n",
      "epoch:17 step:13882[D loss: 0.433347, acc: 62.50%, op_acc: 34.38%] [G loss: 0.856707]\n",
      "epoch:17 step:13883[D loss: 0.437390, acc: 56.25%, op_acc: 36.72%] [G loss: 0.901658]\n",
      "epoch:17 step:13884[D loss: 0.397823, acc: 64.84%, op_acc: 45.31%] [G loss: 0.939000]\n",
      "epoch:17 step:13885[D loss: 0.419327, acc: 65.62%, op_acc: 38.28%] [G loss: 0.931488]\n",
      "epoch:17 step:13886[D loss: 0.458646, acc: 53.12%, op_acc: 39.06%] [G loss: 0.885692]\n",
      "epoch:17 step:13887[D loss: 0.423906, acc: 60.16%, op_acc: 42.97%] [G loss: 0.875403]\n",
      "epoch:17 step:13888[D loss: 0.426017, acc: 60.94%, op_acc: 39.06%] [G loss: 0.866472]\n",
      "epoch:17 step:13889[D loss: 0.440097, acc: 59.38%, op_acc: 35.16%] [G loss: 0.854587]\n",
      "epoch:17 step:13890[D loss: 0.435208, acc: 58.59%, op_acc: 37.50%] [G loss: 0.851316]\n",
      "epoch:17 step:13891[D loss: 0.417253, acc: 60.16%, op_acc: 40.62%] [G loss: 0.846425]\n",
      "epoch:17 step:13892[D loss: 0.447280, acc: 57.81%, op_acc: 35.16%] [G loss: 0.969879]\n",
      "epoch:17 step:13893[D loss: 0.436424, acc: 60.94%, op_acc: 38.28%] [G loss: 0.972774]\n",
      "epoch:17 step:13894[D loss: 0.462370, acc: 53.12%, op_acc: 32.03%] [G loss: 0.801519]\n",
      "epoch:17 step:13895[D loss: 0.404835, acc: 62.50%, op_acc: 45.31%] [G loss: 0.772915]\n",
      "epoch:17 step:13896[D loss: 0.430355, acc: 57.81%, op_acc: 36.72%] [G loss: 0.869987]\n",
      "epoch:17 step:13897[D loss: 0.418361, acc: 64.06%, op_acc: 34.38%] [G loss: 0.923488]\n",
      "epoch:17 step:13898[D loss: 0.417901, acc: 65.62%, op_acc: 35.16%] [G loss: 0.918775]\n",
      "epoch:17 step:13899[D loss: 0.525232, acc: 46.88%, op_acc: 31.25%] [G loss: 0.804019]\n",
      "epoch:17 step:13900[D loss: 0.422756, acc: 64.84%, op_acc: 37.50%] [G loss: 0.839934]\n",
      "epoch:17 step:13901[D loss: 0.454010, acc: 54.69%, op_acc: 31.25%] [G loss: 0.835717]\n",
      "epoch:17 step:13902[D loss: 0.443062, acc: 54.69%, op_acc: 39.06%] [G loss: 0.880937]\n",
      "epoch:17 step:13903[D loss: 0.398052, acc: 61.72%, op_acc: 42.97%] [G loss: 0.900633]\n",
      "epoch:17 step:13904[D loss: 0.416425, acc: 57.03%, op_acc: 35.16%] [G loss: 0.913237]\n",
      "epoch:17 step:13905[D loss: 0.442186, acc: 56.25%, op_acc: 35.16%] [G loss: 0.971320]\n",
      "epoch:17 step:13906[D loss: 0.426980, acc: 56.25%, op_acc: 39.84%] [G loss: 0.972722]\n",
      "epoch:17 step:13907[D loss: 0.418252, acc: 58.59%, op_acc: 40.62%] [G loss: 0.866615]\n",
      "epoch:17 step:13908[D loss: 0.440692, acc: 54.69%, op_acc: 31.25%] [G loss: 0.821608]\n",
      "epoch:17 step:13909[D loss: 0.453561, acc: 60.16%, op_acc: 32.03%] [G loss: 0.835200]\n",
      "epoch:17 step:13910[D loss: 0.451900, acc: 58.59%, op_acc: 37.50%] [G loss: 0.865417]\n",
      "epoch:17 step:13911[D loss: 0.420588, acc: 54.69%, op_acc: 41.41%] [G loss: 0.830735]\n",
      "epoch:17 step:13912[D loss: 0.458779, acc: 52.34%, op_acc: 37.50%] [G loss: 0.854118]\n",
      "epoch:17 step:13913[D loss: 0.413761, acc: 64.84%, op_acc: 42.19%] [G loss: 0.893036]\n",
      "epoch:17 step:13914[D loss: 0.417780, acc: 64.84%, op_acc: 39.06%] [G loss: 1.000611]\n",
      "epoch:17 step:13915[D loss: 0.432069, acc: 57.03%, op_acc: 39.06%] [G loss: 0.931118]\n",
      "epoch:17 step:13916[D loss: 0.426314, acc: 56.25%, op_acc: 39.06%] [G loss: 0.794642]\n",
      "epoch:17 step:13917[D loss: 0.443890, acc: 60.94%, op_acc: 39.84%] [G loss: 0.936901]\n",
      "epoch:17 step:13918[D loss: 0.405466, acc: 68.75%, op_acc: 37.50%] [G loss: 0.869074]\n",
      "epoch:17 step:13919[D loss: 0.447514, acc: 57.81%, op_acc: 38.28%] [G loss: 0.904139]\n",
      "epoch:17 step:13920[D loss: 0.435301, acc: 60.16%, op_acc: 39.84%] [G loss: 0.826747]\n",
      "epoch:17 step:13921[D loss: 0.389096, acc: 65.62%, op_acc: 44.53%] [G loss: 0.918853]\n",
      "epoch:17 step:13922[D loss: 0.405472, acc: 64.06%, op_acc: 37.50%] [G loss: 0.985770]\n",
      "epoch:17 step:13923[D loss: 0.427016, acc: 60.94%, op_acc: 35.94%] [G loss: 0.940566]\n",
      "epoch:17 step:13924[D loss: 0.389263, acc: 65.62%, op_acc: 42.97%] [G loss: 0.911943]\n",
      "epoch:17 step:13925[D loss: 0.421069, acc: 60.16%, op_acc: 33.59%] [G loss: 0.849787]\n",
      "epoch:17 step:13926[D loss: 0.416468, acc: 64.06%, op_acc: 39.06%] [G loss: 0.856681]\n",
      "epoch:17 step:13927[D loss: 0.438324, acc: 64.84%, op_acc: 35.16%] [G loss: 0.943042]\n",
      "epoch:17 step:13928[D loss: 0.454591, acc: 51.56%, op_acc: 36.72%] [G loss: 0.937524]\n",
      "epoch:17 step:13929[D loss: 0.411495, acc: 60.94%, op_acc: 39.06%] [G loss: 0.866785]\n",
      "epoch:17 step:13930[D loss: 0.409124, acc: 67.19%, op_acc: 43.75%] [G loss: 0.884454]\n",
      "epoch:17 step:13931[D loss: 0.414832, acc: 67.19%, op_acc: 35.94%] [G loss: 0.884327]\n",
      "epoch:17 step:13932[D loss: 0.448762, acc: 55.47%, op_acc: 35.94%] [G loss: 0.878683]\n",
      "epoch:17 step:13933[D loss: 0.429404, acc: 57.03%, op_acc: 40.62%] [G loss: 0.999722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:13934[D loss: 0.414818, acc: 64.84%, op_acc: 35.94%] [G loss: 0.862910]\n",
      "epoch:17 step:13935[D loss: 0.436841, acc: 57.03%, op_acc: 40.62%] [G loss: 0.836466]\n",
      "epoch:17 step:13936[D loss: 0.416751, acc: 71.09%, op_acc: 37.50%] [G loss: 0.907284]\n",
      "epoch:17 step:13937[D loss: 0.419389, acc: 60.94%, op_acc: 42.97%] [G loss: 0.834140]\n",
      "epoch:17 step:13938[D loss: 0.414639, acc: 59.38%, op_acc: 46.09%] [G loss: 0.826024]\n",
      "epoch:17 step:13939[D loss: 0.441563, acc: 53.91%, op_acc: 37.50%] [G loss: 0.858726]\n",
      "epoch:17 step:13940[D loss: 0.420196, acc: 59.38%, op_acc: 43.75%] [G loss: 0.899916]\n",
      "epoch:17 step:13941[D loss: 0.426809, acc: 62.50%, op_acc: 39.06%] [G loss: 0.832266]\n",
      "epoch:17 step:13942[D loss: 0.462443, acc: 59.38%, op_acc: 32.81%] [G loss: 0.876965]\n",
      "epoch:17 step:13943[D loss: 0.406818, acc: 66.41%, op_acc: 31.25%] [G loss: 0.901302]\n",
      "epoch:17 step:13944[D loss: 0.417974, acc: 61.72%, op_acc: 35.16%] [G loss: 0.816681]\n",
      "epoch:17 step:13945[D loss: 0.444898, acc: 61.72%, op_acc: 34.38%] [G loss: 0.884996]\n",
      "epoch:17 step:13946[D loss: 0.423652, acc: 57.81%, op_acc: 40.62%] [G loss: 0.861587]\n",
      "epoch:17 step:13947[D loss: 0.444039, acc: 51.56%, op_acc: 38.28%] [G loss: 0.848626]\n",
      "epoch:17 step:13948[D loss: 0.435829, acc: 58.59%, op_acc: 33.59%] [G loss: 0.903016]\n",
      "epoch:17 step:13949[D loss: 0.439371, acc: 60.16%, op_acc: 35.16%] [G loss: 0.854433]\n",
      "epoch:17 step:13950[D loss: 0.424053, acc: 56.25%, op_acc: 39.84%] [G loss: 0.882803]\n",
      "epoch:17 step:13951[D loss: 0.410778, acc: 58.59%, op_acc: 44.53%] [G loss: 0.953028]\n",
      "epoch:17 step:13952[D loss: 0.413951, acc: 62.50%, op_acc: 37.50%] [G loss: 0.910997]\n",
      "epoch:17 step:13953[D loss: 0.483580, acc: 57.03%, op_acc: 30.47%] [G loss: 0.868546]\n",
      "epoch:17 step:13954[D loss: 0.464365, acc: 57.81%, op_acc: 28.91%] [G loss: 0.826200]\n",
      "epoch:17 step:13955[D loss: 0.402400, acc: 62.50%, op_acc: 38.28%] [G loss: 0.959993]\n",
      "epoch:17 step:13956[D loss: 0.395633, acc: 68.75%, op_acc: 41.41%] [G loss: 0.905694]\n",
      "epoch:17 step:13957[D loss: 0.435888, acc: 58.59%, op_acc: 36.72%] [G loss: 0.835534]\n",
      "epoch:17 step:13958[D loss: 0.475319, acc: 53.91%, op_acc: 32.03%] [G loss: 0.818477]\n",
      "epoch:17 step:13959[D loss: 0.407974, acc: 60.94%, op_acc: 40.62%] [G loss: 0.905101]\n",
      "epoch:17 step:13960[D loss: 0.448787, acc: 63.28%, op_acc: 42.97%] [G loss: 0.860696]\n",
      "epoch:17 step:13961[D loss: 0.438384, acc: 57.81%, op_acc: 34.38%] [G loss: 0.935148]\n",
      "epoch:17 step:13962[D loss: 0.461080, acc: 53.91%, op_acc: 35.16%] [G loss: 0.883536]\n",
      "epoch:17 step:13963[D loss: 0.421355, acc: 66.41%, op_acc: 35.94%] [G loss: 0.882380]\n",
      "epoch:17 step:13964[D loss: 0.429274, acc: 55.47%, op_acc: 38.28%] [G loss: 0.864229]\n",
      "epoch:17 step:13965[D loss: 0.426481, acc: 62.50%, op_acc: 36.72%] [G loss: 0.944382]\n",
      "epoch:17 step:13966[D loss: 0.468940, acc: 44.53%, op_acc: 39.06%] [G loss: 0.865904]\n",
      "epoch:17 step:13967[D loss: 0.434314, acc: 63.28%, op_acc: 32.81%] [G loss: 0.913659]\n",
      "epoch:17 step:13968[D loss: 0.449481, acc: 48.44%, op_acc: 38.28%] [G loss: 0.864933]\n",
      "epoch:17 step:13969[D loss: 0.466530, acc: 53.91%, op_acc: 34.38%] [G loss: 0.856788]\n",
      "epoch:17 step:13970[D loss: 0.438218, acc: 56.25%, op_acc: 38.28%] [G loss: 0.818158]\n",
      "epoch:17 step:13971[D loss: 0.454284, acc: 57.03%, op_acc: 39.84%] [G loss: 0.906735]\n",
      "epoch:17 step:13972[D loss: 0.438087, acc: 61.72%, op_acc: 39.06%] [G loss: 0.914675]\n",
      "epoch:17 step:13973[D loss: 0.433860, acc: 60.94%, op_acc: 34.38%] [G loss: 1.013440]\n",
      "epoch:17 step:13974[D loss: 0.404958, acc: 72.66%, op_acc: 39.84%] [G loss: 0.910608]\n",
      "epoch:17 step:13975[D loss: 0.416317, acc: 67.97%, op_acc: 39.06%] [G loss: 0.911402]\n",
      "epoch:17 step:13976[D loss: 0.451342, acc: 50.00%, op_acc: 42.19%] [G loss: 0.861856]\n",
      "epoch:17 step:13977[D loss: 0.427070, acc: 62.50%, op_acc: 32.03%] [G loss: 0.898856]\n",
      "epoch:17 step:13978[D loss: 0.443921, acc: 57.03%, op_acc: 33.59%] [G loss: 0.889702]\n",
      "epoch:17 step:13979[D loss: 0.433104, acc: 57.81%, op_acc: 38.28%] [G loss: 0.868712]\n",
      "epoch:17 step:13980[D loss: 0.438477, acc: 62.50%, op_acc: 40.62%] [G loss: 0.897394]\n",
      "epoch:17 step:13981[D loss: 0.419654, acc: 56.25%, op_acc: 41.41%] [G loss: 0.813644]\n",
      "epoch:17 step:13982[D loss: 0.440569, acc: 53.91%, op_acc: 36.72%] [G loss: 0.855321]\n",
      "epoch:17 step:13983[D loss: 0.458086, acc: 52.34%, op_acc: 34.38%] [G loss: 0.881224]\n",
      "epoch:17 step:13984[D loss: 0.471176, acc: 49.22%, op_acc: 32.03%] [G loss: 0.868835]\n",
      "epoch:17 step:13985[D loss: 0.413306, acc: 60.94%, op_acc: 44.53%] [G loss: 0.931748]\n",
      "epoch:17 step:13986[D loss: 0.411496, acc: 64.84%, op_acc: 33.59%] [G loss: 0.892425]\n",
      "epoch:17 step:13987[D loss: 0.377109, acc: 68.75%, op_acc: 40.62%] [G loss: 0.868095]\n",
      "epoch:17 step:13988[D loss: 0.422645, acc: 60.94%, op_acc: 32.03%] [G loss: 0.814320]\n",
      "epoch:17 step:13989[D loss: 0.411304, acc: 60.94%, op_acc: 42.97%] [G loss: 0.877982]\n",
      "epoch:17 step:13990[D loss: 0.430994, acc: 57.03%, op_acc: 36.72%] [G loss: 0.919190]\n",
      "epoch:17 step:13991[D loss: 0.426012, acc: 63.28%, op_acc: 39.84%] [G loss: 1.021634]\n",
      "epoch:17 step:13992[D loss: 0.383065, acc: 67.97%, op_acc: 39.84%] [G loss: 0.799971]\n",
      "epoch:17 step:13993[D loss: 0.430901, acc: 54.69%, op_acc: 36.72%] [G loss: 0.865887]\n",
      "epoch:17 step:13994[D loss: 0.406655, acc: 63.28%, op_acc: 36.72%] [G loss: 0.868008]\n",
      "epoch:17 step:13995[D loss: 0.412314, acc: 62.50%, op_acc: 37.50%] [G loss: 0.897011]\n",
      "epoch:17 step:13996[D loss: 0.420500, acc: 56.25%, op_acc: 35.16%] [G loss: 0.866231]\n",
      "epoch:17 step:13997[D loss: 0.416936, acc: 64.06%, op_acc: 40.62%] [G loss: 0.942377]\n",
      "epoch:17 step:13998[D loss: 0.425374, acc: 52.34%, op_acc: 37.50%] [G loss: 0.926536]\n",
      "epoch:17 step:13999[D loss: 0.434475, acc: 57.81%, op_acc: 35.16%] [G loss: 0.885221]\n",
      "epoch:17 step:14000[D loss: 0.437856, acc: 56.25%, op_acc: 40.62%] [G loss: 0.975136]\n",
      "epoch:17 step:14001[D loss: 0.477527, acc: 49.22%, op_acc: 32.03%] [G loss: 0.895658]\n",
      "epoch:17 step:14002[D loss: 0.437232, acc: 60.94%, op_acc: 38.28%] [G loss: 0.947044]\n",
      "epoch:17 step:14003[D loss: 0.398405, acc: 65.62%, op_acc: 42.97%] [G loss: 0.920344]\n",
      "epoch:17 step:14004[D loss: 0.450575, acc: 57.03%, op_acc: 35.16%] [G loss: 0.927566]\n",
      "epoch:17 step:14005[D loss: 0.482469, acc: 49.22%, op_acc: 34.38%] [G loss: 0.842668]\n",
      "epoch:17 step:14006[D loss: 0.437828, acc: 59.38%, op_acc: 36.72%] [G loss: 0.821092]\n",
      "epoch:17 step:14007[D loss: 0.401635, acc: 62.50%, op_acc: 36.72%] [G loss: 0.892697]\n",
      "epoch:17 step:14008[D loss: 0.404641, acc: 66.41%, op_acc: 40.62%] [G loss: 0.891517]\n",
      "epoch:17 step:14009[D loss: 0.428100, acc: 57.81%, op_acc: 35.94%] [G loss: 0.821525]\n",
      "epoch:17 step:14010[D loss: 0.413624, acc: 63.28%, op_acc: 38.28%] [G loss: 0.790416]\n",
      "epoch:17 step:14011[D loss: 0.453159, acc: 51.56%, op_acc: 40.62%] [G loss: 0.880248]\n",
      "epoch:17 step:14012[D loss: 0.437517, acc: 56.25%, op_acc: 35.16%] [G loss: 0.883411]\n",
      "epoch:17 step:14013[D loss: 0.437019, acc: 60.16%, op_acc: 37.50%] [G loss: 0.946565]\n",
      "epoch:17 step:14014[D loss: 0.401483, acc: 62.50%, op_acc: 42.19%] [G loss: 1.021681]\n",
      "epoch:17 step:14015[D loss: 0.425999, acc: 54.69%, op_acc: 41.41%] [G loss: 0.912121]\n",
      "epoch:17 step:14016[D loss: 0.450952, acc: 52.34%, op_acc: 41.41%] [G loss: 0.900365]\n",
      "epoch:17 step:14017[D loss: 0.430389, acc: 54.69%, op_acc: 39.84%] [G loss: 0.913823]\n",
      "epoch:17 step:14018[D loss: 0.434485, acc: 56.25%, op_acc: 39.84%] [G loss: 0.915604]\n",
      "epoch:17 step:14019[D loss: 0.416378, acc: 64.06%, op_acc: 36.72%] [G loss: 0.835472]\n",
      "epoch:17 step:14020[D loss: 0.456572, acc: 61.72%, op_acc: 30.47%] [G loss: 0.898044]\n",
      "epoch:17 step:14021[D loss: 0.423910, acc: 53.12%, op_acc: 44.53%] [G loss: 0.809043]\n",
      "epoch:17 step:14022[D loss: 0.439379, acc: 56.25%, op_acc: 39.06%] [G loss: 0.841688]\n",
      "epoch:17 step:14023[D loss: 0.435626, acc: 57.81%, op_acc: 38.28%] [G loss: 0.924157]\n",
      "epoch:17 step:14024[D loss: 0.445930, acc: 54.69%, op_acc: 34.38%] [G loss: 0.893929]\n",
      "epoch:17 step:14025[D loss: 0.467394, acc: 57.03%, op_acc: 32.03%] [G loss: 0.804102]\n",
      "epoch:17 step:14026[D loss: 0.420436, acc: 60.94%, op_acc: 35.16%] [G loss: 0.912346]\n",
      "epoch:17 step:14027[D loss: 0.421560, acc: 61.72%, op_acc: 38.28%] [G loss: 0.860505]\n",
      "epoch:17 step:14028[D loss: 0.467397, acc: 62.50%, op_acc: 28.91%] [G loss: 0.861064]\n",
      "epoch:17 step:14029[D loss: 0.435214, acc: 57.03%, op_acc: 44.53%] [G loss: 0.855183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:14030[D loss: 0.404073, acc: 60.94%, op_acc: 43.75%] [G loss: 0.957281]\n",
      "epoch:17 step:14031[D loss: 0.435520, acc: 57.03%, op_acc: 37.50%] [G loss: 0.886131]\n",
      "epoch:17 step:14032[D loss: 0.394410, acc: 70.31%, op_acc: 40.62%] [G loss: 0.935321]\n",
      "epoch:17 step:14033[D loss: 0.411345, acc: 60.94%, op_acc: 39.06%] [G loss: 0.858142]\n",
      "epoch:17 step:14034[D loss: 0.433718, acc: 57.81%, op_acc: 39.06%] [G loss: 0.841017]\n",
      "epoch:17 step:14035[D loss: 0.407864, acc: 61.72%, op_acc: 42.19%] [G loss: 0.956699]\n",
      "epoch:17 step:14036[D loss: 0.430922, acc: 57.81%, op_acc: 37.50%] [G loss: 0.880269]\n",
      "epoch:17 step:14037[D loss: 0.401776, acc: 65.62%, op_acc: 46.88%] [G loss: 0.895004]\n",
      "epoch:17 step:14038[D loss: 0.384758, acc: 68.75%, op_acc: 48.44%] [G loss: 0.865382]\n",
      "epoch:17 step:14039[D loss: 0.451860, acc: 57.03%, op_acc: 34.38%] [G loss: 0.938814]\n",
      "epoch:17 step:14040[D loss: 0.464523, acc: 44.53%, op_acc: 35.94%] [G loss: 0.865727]\n",
      "epoch:17 step:14041[D loss: 0.401643, acc: 67.19%, op_acc: 38.28%] [G loss: 0.936047]\n",
      "epoch:17 step:14042[D loss: 0.433493, acc: 63.28%, op_acc: 42.19%] [G loss: 0.820319]\n",
      "epoch:17 step:14043[D loss: 0.488743, acc: 46.09%, op_acc: 31.25%] [G loss: 0.874984]\n",
      "epoch:17 step:14044[D loss: 0.408756, acc: 67.19%, op_acc: 37.50%] [G loss: 1.004307]\n",
      "epoch:17 step:14045[D loss: 0.436026, acc: 59.38%, op_acc: 38.28%] [G loss: 0.852595]\n",
      "epoch:17 step:14046[D loss: 0.412115, acc: 53.91%, op_acc: 39.06%] [G loss: 0.859642]\n",
      "epoch:17 step:14047[D loss: 0.443937, acc: 50.78%, op_acc: 36.72%] [G loss: 0.871024]\n",
      "epoch:17 step:14048[D loss: 0.479458, acc: 52.34%, op_acc: 31.25%] [G loss: 0.843072]\n",
      "epoch:17 step:14049[D loss: 0.470849, acc: 56.25%, op_acc: 36.72%] [G loss: 0.889054]\n",
      "epoch:17 step:14050[D loss: 0.438767, acc: 60.16%, op_acc: 33.59%] [G loss: 0.897561]\n",
      "epoch:17 step:14051[D loss: 0.409581, acc: 61.72%, op_acc: 37.50%] [G loss: 0.910636]\n",
      "epoch:17 step:14052[D loss: 0.441445, acc: 58.59%, op_acc: 35.16%] [G loss: 0.877458]\n",
      "epoch:17 step:14053[D loss: 0.413537, acc: 58.59%, op_acc: 40.62%] [G loss: 0.856491]\n",
      "epoch:17 step:14054[D loss: 0.470586, acc: 54.69%, op_acc: 39.06%] [G loss: 0.852019]\n",
      "epoch:17 step:14055[D loss: 0.430103, acc: 60.16%, op_acc: 39.84%] [G loss: 0.846025]\n",
      "epoch:17 step:14056[D loss: 0.440807, acc: 53.12%, op_acc: 38.28%] [G loss: 0.815048]\n",
      "epoch:17 step:14057[D loss: 0.430936, acc: 56.25%, op_acc: 43.75%] [G loss: 0.814359]\n",
      "epoch:17 step:14058[D loss: 0.404378, acc: 73.44%, op_acc: 39.06%] [G loss: 0.932789]\n",
      "epoch:18 step:14059[D loss: 0.403975, acc: 66.41%, op_acc: 38.28%] [G loss: 0.984900]\n",
      "epoch:18 step:14060[D loss: 0.378032, acc: 64.84%, op_acc: 42.19%] [G loss: 0.895754]\n",
      "epoch:18 step:14061[D loss: 0.424552, acc: 60.94%, op_acc: 39.06%] [G loss: 0.972143]\n",
      "epoch:18 step:14062[D loss: 0.405439, acc: 60.16%, op_acc: 39.06%] [G loss: 0.902469]\n",
      "epoch:18 step:14063[D loss: 0.423084, acc: 64.06%, op_acc: 36.72%] [G loss: 0.924298]\n",
      "epoch:18 step:14064[D loss: 0.451283, acc: 50.78%, op_acc: 39.84%] [G loss: 0.865408]\n",
      "epoch:18 step:14065[D loss: 0.430981, acc: 52.34%, op_acc: 35.94%] [G loss: 0.852025]\n",
      "epoch:18 step:14066[D loss: 0.454165, acc: 53.91%, op_acc: 39.84%] [G loss: 0.909965]\n",
      "epoch:18 step:14067[D loss: 0.407425, acc: 59.38%, op_acc: 42.19%] [G loss: 0.900129]\n",
      "epoch:18 step:14068[D loss: 0.465035, acc: 50.00%, op_acc: 35.16%] [G loss: 0.856070]\n",
      "epoch:18 step:14069[D loss: 0.440341, acc: 55.47%, op_acc: 41.41%] [G loss: 0.866451]\n",
      "epoch:18 step:14070[D loss: 0.424415, acc: 64.06%, op_acc: 32.81%] [G loss: 0.858823]\n",
      "epoch:18 step:14071[D loss: 0.435804, acc: 61.72%, op_acc: 33.59%] [G loss: 0.885719]\n",
      "epoch:18 step:14072[D loss: 0.459022, acc: 56.25%, op_acc: 32.81%] [G loss: 0.808154]\n",
      "epoch:18 step:14073[D loss: 0.400730, acc: 62.50%, op_acc: 43.75%] [G loss: 0.790403]\n",
      "epoch:18 step:14074[D loss: 0.393618, acc: 64.84%, op_acc: 39.06%] [G loss: 0.913658]\n",
      "epoch:18 step:14075[D loss: 0.461670, acc: 54.69%, op_acc: 35.16%] [G loss: 0.822737]\n",
      "epoch:18 step:14076[D loss: 0.434014, acc: 51.56%, op_acc: 35.16%] [G loss: 0.849993]\n",
      "epoch:18 step:14077[D loss: 0.441783, acc: 58.59%, op_acc: 41.41%] [G loss: 0.864264]\n",
      "epoch:18 step:14078[D loss: 0.419674, acc: 60.16%, op_acc: 35.16%] [G loss: 0.855927]\n",
      "epoch:18 step:14079[D loss: 0.440394, acc: 53.91%, op_acc: 39.06%] [G loss: 0.845285]\n",
      "epoch:18 step:14080[D loss: 0.432858, acc: 57.81%, op_acc: 42.97%] [G loss: 0.867525]\n",
      "epoch:18 step:14081[D loss: 0.417452, acc: 64.84%, op_acc: 42.97%] [G loss: 0.889251]\n",
      "epoch:18 step:14082[D loss: 0.435546, acc: 65.62%, op_acc: 36.72%] [G loss: 0.866487]\n",
      "epoch:18 step:14083[D loss: 0.473032, acc: 55.47%, op_acc: 32.81%] [G loss: 0.909765]\n",
      "epoch:18 step:14084[D loss: 0.437729, acc: 59.38%, op_acc: 32.81%] [G loss: 0.970659]\n",
      "epoch:18 step:14085[D loss: 0.430617, acc: 58.59%, op_acc: 41.41%] [G loss: 0.831882]\n",
      "epoch:18 step:14086[D loss: 0.431657, acc: 57.03%, op_acc: 41.41%] [G loss: 0.888145]\n",
      "epoch:18 step:14087[D loss: 0.397428, acc: 67.97%, op_acc: 41.41%] [G loss: 0.918378]\n",
      "epoch:18 step:14088[D loss: 0.412158, acc: 60.94%, op_acc: 39.06%] [G loss: 0.803262]\n",
      "epoch:18 step:14089[D loss: 0.452281, acc: 55.47%, op_acc: 39.06%] [G loss: 0.909078]\n",
      "epoch:18 step:14090[D loss: 0.427212, acc: 59.38%, op_acc: 40.62%] [G loss: 0.878896]\n",
      "epoch:18 step:14091[D loss: 0.407166, acc: 63.28%, op_acc: 44.53%] [G loss: 0.878034]\n",
      "epoch:18 step:14092[D loss: 0.421657, acc: 61.72%, op_acc: 35.94%] [G loss: 0.837707]\n",
      "epoch:18 step:14093[D loss: 0.465082, acc: 60.94%, op_acc: 30.47%] [G loss: 0.829810]\n",
      "epoch:18 step:14094[D loss: 0.374498, acc: 70.31%, op_acc: 39.84%] [G loss: 0.886922]\n",
      "epoch:18 step:14095[D loss: 0.403412, acc: 67.97%, op_acc: 38.28%] [G loss: 0.944455]\n",
      "epoch:18 step:14096[D loss: 0.454063, acc: 50.00%, op_acc: 38.28%] [G loss: 0.855364]\n",
      "epoch:18 step:14097[D loss: 0.411086, acc: 57.81%, op_acc: 41.41%] [G loss: 0.821375]\n",
      "epoch:18 step:14098[D loss: 0.470974, acc: 53.12%, op_acc: 27.34%] [G loss: 0.887603]\n",
      "epoch:18 step:14099[D loss: 0.427297, acc: 64.06%, op_acc: 42.97%] [G loss: 0.830801]\n",
      "epoch:18 step:14100[D loss: 0.404763, acc: 56.25%, op_acc: 44.53%] [G loss: 0.892022]\n",
      "epoch:18 step:14101[D loss: 0.451575, acc: 53.12%, op_acc: 35.94%] [G loss: 0.859864]\n",
      "epoch:18 step:14102[D loss: 0.422538, acc: 61.72%, op_acc: 38.28%] [G loss: 0.841611]\n",
      "epoch:18 step:14103[D loss: 0.434886, acc: 60.94%, op_acc: 34.38%] [G loss: 0.827191]\n",
      "epoch:18 step:14104[D loss: 0.425358, acc: 53.91%, op_acc: 35.16%] [G loss: 0.825482]\n",
      "epoch:18 step:14105[D loss: 0.438584, acc: 55.47%, op_acc: 32.81%] [G loss: 0.869370]\n",
      "epoch:18 step:14106[D loss: 0.458840, acc: 51.56%, op_acc: 35.16%] [G loss: 0.847803]\n",
      "epoch:18 step:14107[D loss: 0.396906, acc: 73.44%, op_acc: 40.62%] [G loss: 0.927855]\n",
      "epoch:18 step:14108[D loss: 0.428805, acc: 68.75%, op_acc: 38.28%] [G loss: 0.914850]\n",
      "epoch:18 step:14109[D loss: 0.402641, acc: 67.19%, op_acc: 48.44%] [G loss: 0.912787]\n",
      "epoch:18 step:14110[D loss: 0.420268, acc: 63.28%, op_acc: 38.28%] [G loss: 0.846694]\n",
      "epoch:18 step:14111[D loss: 0.452700, acc: 55.47%, op_acc: 34.38%] [G loss: 0.977717]\n",
      "epoch:18 step:14112[D loss: 0.472354, acc: 48.44%, op_acc: 37.50%] [G loss: 0.823230]\n",
      "epoch:18 step:14113[D loss: 0.428025, acc: 57.03%, op_acc: 35.94%] [G loss: 0.845695]\n",
      "epoch:18 step:14114[D loss: 0.410465, acc: 61.72%, op_acc: 35.16%] [G loss: 0.885612]\n",
      "epoch:18 step:14115[D loss: 0.416662, acc: 68.75%, op_acc: 35.94%] [G loss: 0.865141]\n",
      "epoch:18 step:14116[D loss: 0.435360, acc: 57.81%, op_acc: 36.72%] [G loss: 0.857332]\n",
      "epoch:18 step:14117[D loss: 0.403709, acc: 63.28%, op_acc: 43.75%] [G loss: 0.845575]\n",
      "epoch:18 step:14118[D loss: 0.425028, acc: 61.72%, op_acc: 37.50%] [G loss: 0.852805]\n",
      "epoch:18 step:14119[D loss: 0.450682, acc: 62.50%, op_acc: 34.38%] [G loss: 0.805208]\n",
      "epoch:18 step:14120[D loss: 0.395540, acc: 70.31%, op_acc: 35.94%] [G loss: 0.878874]\n",
      "epoch:18 step:14121[D loss: 0.453423, acc: 52.34%, op_acc: 35.16%] [G loss: 0.880140]\n",
      "epoch:18 step:14122[D loss: 0.411044, acc: 63.28%, op_acc: 42.97%] [G loss: 0.890352]\n",
      "epoch:18 step:14123[D loss: 0.450034, acc: 51.56%, op_acc: 38.28%] [G loss: 0.822666]\n",
      "epoch:18 step:14124[D loss: 0.470555, acc: 46.09%, op_acc: 33.59%] [G loss: 0.831536]\n",
      "epoch:18 step:14125[D loss: 0.439907, acc: 58.59%, op_acc: 36.72%] [G loss: 0.924034]\n",
      "epoch:18 step:14126[D loss: 0.432835, acc: 54.69%, op_acc: 35.94%] [G loss: 0.857952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14127[D loss: 0.428554, acc: 52.34%, op_acc: 44.53%] [G loss: 0.933316]\n",
      "epoch:18 step:14128[D loss: 0.445564, acc: 56.25%, op_acc: 38.28%] [G loss: 0.864420]\n",
      "epoch:18 step:14129[D loss: 0.471302, acc: 58.59%, op_acc: 29.69%] [G loss: 0.871774]\n",
      "epoch:18 step:14130[D loss: 0.403056, acc: 63.28%, op_acc: 35.94%] [G loss: 0.899406]\n",
      "epoch:18 step:14131[D loss: 0.439970, acc: 54.69%, op_acc: 39.84%] [G loss: 0.782171]\n",
      "epoch:18 step:14132[D loss: 0.406673, acc: 62.50%, op_acc: 41.41%] [G loss: 0.926262]\n",
      "epoch:18 step:14133[D loss: 0.423540, acc: 64.06%, op_acc: 36.72%] [G loss: 0.865963]\n",
      "epoch:18 step:14134[D loss: 0.459967, acc: 54.69%, op_acc: 42.19%] [G loss: 0.863576]\n",
      "epoch:18 step:14135[D loss: 0.435729, acc: 60.16%, op_acc: 35.94%] [G loss: 0.883584]\n",
      "epoch:18 step:14136[D loss: 0.457375, acc: 59.38%, op_acc: 40.62%] [G loss: 0.866793]\n",
      "epoch:18 step:14137[D loss: 0.437482, acc: 60.16%, op_acc: 40.62%] [G loss: 0.825945]\n",
      "epoch:18 step:14138[D loss: 0.444774, acc: 61.72%, op_acc: 35.16%] [G loss: 0.811576]\n",
      "epoch:18 step:14139[D loss: 0.440318, acc: 57.03%, op_acc: 40.62%] [G loss: 0.897071]\n",
      "epoch:18 step:14140[D loss: 0.410779, acc: 61.72%, op_acc: 41.41%] [G loss: 0.870804]\n",
      "epoch:18 step:14141[D loss: 0.438520, acc: 60.16%, op_acc: 38.28%] [G loss: 0.912795]\n",
      "epoch:18 step:14142[D loss: 0.403573, acc: 67.97%, op_acc: 39.06%] [G loss: 0.850317]\n",
      "epoch:18 step:14143[D loss: 0.436716, acc: 62.50%, op_acc: 30.47%] [G loss: 0.821882]\n",
      "epoch:18 step:14144[D loss: 0.437541, acc: 54.69%, op_acc: 34.38%] [G loss: 0.823248]\n",
      "epoch:18 step:14145[D loss: 0.399113, acc: 73.44%, op_acc: 35.94%] [G loss: 0.964072]\n",
      "epoch:18 step:14146[D loss: 0.463948, acc: 50.00%, op_acc: 36.72%] [G loss: 0.891347]\n",
      "epoch:18 step:14147[D loss: 0.449732, acc: 57.03%, op_acc: 35.94%] [G loss: 0.848176]\n",
      "epoch:18 step:14148[D loss: 0.402935, acc: 65.62%, op_acc: 39.84%] [G loss: 0.872040]\n",
      "epoch:18 step:14149[D loss: 0.400766, acc: 60.94%, op_acc: 41.41%] [G loss: 0.931528]\n",
      "epoch:18 step:14150[D loss: 0.424470, acc: 64.06%, op_acc: 35.94%] [G loss: 0.896599]\n",
      "epoch:18 step:14151[D loss: 0.426408, acc: 62.50%, op_acc: 36.72%] [G loss: 0.928095]\n",
      "epoch:18 step:14152[D loss: 0.393752, acc: 69.53%, op_acc: 41.41%] [G loss: 0.892879]\n",
      "epoch:18 step:14153[D loss: 0.441739, acc: 57.81%, op_acc: 36.72%] [G loss: 0.757144]\n",
      "epoch:18 step:14154[D loss: 0.438503, acc: 60.16%, op_acc: 36.72%] [G loss: 0.852591]\n",
      "epoch:18 step:14155[D loss: 0.432733, acc: 53.91%, op_acc: 35.16%] [G loss: 0.860537]\n",
      "epoch:18 step:14156[D loss: 0.405054, acc: 64.84%, op_acc: 37.50%] [G loss: 0.878420]\n",
      "epoch:18 step:14157[D loss: 0.446701, acc: 50.00%, op_acc: 38.28%] [G loss: 0.823700]\n",
      "epoch:18 step:14158[D loss: 0.421115, acc: 64.06%, op_acc: 38.28%] [G loss: 0.792309]\n",
      "epoch:18 step:14159[D loss: 0.439265, acc: 60.16%, op_acc: 38.28%] [G loss: 0.954662]\n",
      "epoch:18 step:14160[D loss: 0.417473, acc: 57.81%, op_acc: 39.84%] [G loss: 0.861230]\n",
      "epoch:18 step:14161[D loss: 0.426577, acc: 55.47%, op_acc: 35.94%] [G loss: 0.892170]\n",
      "epoch:18 step:14162[D loss: 0.433291, acc: 60.16%, op_acc: 35.94%] [G loss: 0.843331]\n",
      "epoch:18 step:14163[D loss: 0.393880, acc: 67.97%, op_acc: 41.41%] [G loss: 0.882821]\n",
      "epoch:18 step:14164[D loss: 0.433724, acc: 59.38%, op_acc: 33.59%] [G loss: 0.946801]\n",
      "epoch:18 step:14165[D loss: 0.409579, acc: 61.72%, op_acc: 35.94%] [G loss: 0.956150]\n",
      "epoch:18 step:14166[D loss: 0.450345, acc: 61.72%, op_acc: 34.38%] [G loss: 0.876077]\n",
      "epoch:18 step:14167[D loss: 0.433934, acc: 53.91%, op_acc: 36.72%] [G loss: 0.811177]\n",
      "epoch:18 step:14168[D loss: 0.444501, acc: 54.69%, op_acc: 40.62%] [G loss: 0.876192]\n",
      "epoch:18 step:14169[D loss: 0.440917, acc: 60.16%, op_acc: 34.38%] [G loss: 0.902360]\n",
      "epoch:18 step:14170[D loss: 0.428899, acc: 55.47%, op_acc: 39.06%] [G loss: 0.874928]\n",
      "epoch:18 step:14171[D loss: 0.398409, acc: 63.28%, op_acc: 39.84%] [G loss: 0.890776]\n",
      "epoch:18 step:14172[D loss: 0.409390, acc: 65.62%, op_acc: 42.97%] [G loss: 0.900680]\n",
      "epoch:18 step:14173[D loss: 0.418977, acc: 57.81%, op_acc: 41.41%] [G loss: 0.875509]\n",
      "epoch:18 step:14174[D loss: 0.447548, acc: 58.59%, op_acc: 36.72%] [G loss: 0.873271]\n",
      "epoch:18 step:14175[D loss: 0.418221, acc: 60.16%, op_acc: 39.06%] [G loss: 0.835341]\n",
      "epoch:18 step:14176[D loss: 0.419366, acc: 64.84%, op_acc: 39.84%] [G loss: 0.916810]\n",
      "epoch:18 step:14177[D loss: 0.418098, acc: 60.94%, op_acc: 36.72%] [G loss: 0.857065]\n",
      "epoch:18 step:14178[D loss: 0.445367, acc: 56.25%, op_acc: 32.03%] [G loss: 0.761138]\n",
      "epoch:18 step:14179[D loss: 0.423110, acc: 64.06%, op_acc: 37.50%] [G loss: 0.817969]\n",
      "epoch:18 step:14180[D loss: 0.404078, acc: 67.19%, op_acc: 43.75%] [G loss: 0.906443]\n",
      "epoch:18 step:14181[D loss: 0.474201, acc: 55.47%, op_acc: 32.03%] [G loss: 0.850602]\n",
      "epoch:18 step:14182[D loss: 0.438758, acc: 53.91%, op_acc: 36.72%] [G loss: 0.867640]\n",
      "epoch:18 step:14183[D loss: 0.446586, acc: 60.16%, op_acc: 29.69%] [G loss: 0.836490]\n",
      "epoch:18 step:14184[D loss: 0.393533, acc: 64.84%, op_acc: 38.28%] [G loss: 0.864085]\n",
      "epoch:18 step:14185[D loss: 0.412740, acc: 60.16%, op_acc: 40.62%] [G loss: 0.830055]\n",
      "epoch:18 step:14186[D loss: 0.419022, acc: 62.50%, op_acc: 37.50%] [G loss: 0.866042]\n",
      "epoch:18 step:14187[D loss: 0.449559, acc: 55.47%, op_acc: 36.72%] [G loss: 0.875348]\n",
      "epoch:18 step:14188[D loss: 0.406588, acc: 68.75%, op_acc: 35.16%] [G loss: 0.930418]\n",
      "epoch:18 step:14189[D loss: 0.405649, acc: 70.31%, op_acc: 39.06%] [G loss: 0.951893]\n",
      "epoch:18 step:14190[D loss: 0.402063, acc: 65.62%, op_acc: 43.75%] [G loss: 0.951011]\n",
      "epoch:18 step:14191[D loss: 0.457402, acc: 57.03%, op_acc: 32.03%] [G loss: 0.927202]\n",
      "epoch:18 step:14192[D loss: 0.453261, acc: 52.34%, op_acc: 38.28%] [G loss: 0.881887]\n",
      "epoch:18 step:14193[D loss: 0.423967, acc: 60.94%, op_acc: 36.72%] [G loss: 0.966667]\n",
      "epoch:18 step:14194[D loss: 0.416559, acc: 58.59%, op_acc: 40.62%] [G loss: 0.862943]\n",
      "epoch:18 step:14195[D loss: 0.432262, acc: 52.34%, op_acc: 37.50%] [G loss: 0.871893]\n",
      "epoch:18 step:14196[D loss: 0.460395, acc: 54.69%, op_acc: 38.28%] [G loss: 0.833396]\n",
      "epoch:18 step:14197[D loss: 0.448822, acc: 46.88%, op_acc: 41.41%] [G loss: 0.776565]\n",
      "epoch:18 step:14198[D loss: 0.490042, acc: 45.31%, op_acc: 35.94%] [G loss: 0.876564]\n",
      "epoch:18 step:14199[D loss: 0.442924, acc: 63.28%, op_acc: 33.59%] [G loss: 0.815303]\n",
      "epoch:18 step:14200[D loss: 0.407872, acc: 60.94%, op_acc: 39.06%] [G loss: 0.874919]\n",
      "epoch:18 step:14201[D loss: 0.438102, acc: 56.25%, op_acc: 41.41%] [G loss: 0.814733]\n",
      "epoch:18 step:14202[D loss: 0.428652, acc: 54.69%, op_acc: 40.62%] [G loss: 0.815667]\n",
      "epoch:18 step:14203[D loss: 0.434191, acc: 58.59%, op_acc: 40.62%] [G loss: 0.880342]\n",
      "epoch:18 step:14204[D loss: 0.413615, acc: 61.72%, op_acc: 36.72%] [G loss: 0.890819]\n",
      "epoch:18 step:14205[D loss: 0.416434, acc: 59.38%, op_acc: 42.19%] [G loss: 0.864444]\n",
      "epoch:18 step:14206[D loss: 0.423827, acc: 62.50%, op_acc: 36.72%] [G loss: 0.902963]\n",
      "epoch:18 step:14207[D loss: 0.448166, acc: 56.25%, op_acc: 35.94%] [G loss: 0.827864]\n",
      "epoch:18 step:14208[D loss: 0.426678, acc: 58.59%, op_acc: 32.03%] [G loss: 0.934527]\n",
      "epoch:18 step:14209[D loss: 0.421302, acc: 56.25%, op_acc: 37.50%] [G loss: 0.800258]\n",
      "epoch:18 step:14210[D loss: 0.406407, acc: 64.06%, op_acc: 42.19%] [G loss: 0.901860]\n",
      "epoch:18 step:14211[D loss: 0.442684, acc: 49.22%, op_acc: 35.94%] [G loss: 0.829943]\n",
      "epoch:18 step:14212[D loss: 0.421926, acc: 60.16%, op_acc: 38.28%] [G loss: 0.914682]\n",
      "epoch:18 step:14213[D loss: 0.429760, acc: 60.16%, op_acc: 32.81%] [G loss: 0.899864]\n",
      "epoch:18 step:14214[D loss: 0.432439, acc: 57.81%, op_acc: 39.84%] [G loss: 0.852853]\n",
      "epoch:18 step:14215[D loss: 0.395252, acc: 69.53%, op_acc: 41.41%] [G loss: 0.844462]\n",
      "epoch:18 step:14216[D loss: 0.440804, acc: 47.66%, op_acc: 39.06%] [G loss: 0.858621]\n",
      "epoch:18 step:14217[D loss: 0.417146, acc: 66.41%, op_acc: 36.72%] [G loss: 0.816513]\n",
      "epoch:18 step:14218[D loss: 0.405357, acc: 71.09%, op_acc: 39.06%] [G loss: 0.890478]\n",
      "epoch:18 step:14219[D loss: 0.447152, acc: 57.81%, op_acc: 37.50%] [G loss: 0.849769]\n",
      "epoch:18 step:14220[D loss: 0.420497, acc: 57.81%, op_acc: 40.62%] [G loss: 0.837177]\n",
      "epoch:18 step:14221[D loss: 0.444913, acc: 57.81%, op_acc: 35.16%] [G loss: 0.838020]\n",
      "epoch:18 step:14222[D loss: 0.462126, acc: 55.47%, op_acc: 31.25%] [G loss: 0.898954]\n",
      "epoch:18 step:14223[D loss: 0.419951, acc: 58.59%, op_acc: 42.97%] [G loss: 0.932924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14224[D loss: 0.447677, acc: 57.03%, op_acc: 38.28%] [G loss: 0.865645]\n",
      "epoch:18 step:14225[D loss: 0.415793, acc: 62.50%, op_acc: 48.44%] [G loss: 0.945751]\n",
      "epoch:18 step:14226[D loss: 0.431766, acc: 55.47%, op_acc: 36.72%] [G loss: 0.818955]\n",
      "epoch:18 step:14227[D loss: 0.432050, acc: 60.16%, op_acc: 40.62%] [G loss: 0.940603]\n",
      "epoch:18 step:14228[D loss: 0.425978, acc: 58.59%, op_acc: 40.62%] [G loss: 0.828495]\n",
      "epoch:18 step:14229[D loss: 0.416202, acc: 67.19%, op_acc: 37.50%] [G loss: 0.886141]\n",
      "epoch:18 step:14230[D loss: 0.426446, acc: 57.03%, op_acc: 39.06%] [G loss: 0.960376]\n",
      "epoch:18 step:14231[D loss: 0.428991, acc: 60.16%, op_acc: 35.94%] [G loss: 0.889540]\n",
      "epoch:18 step:14232[D loss: 0.450493, acc: 57.81%, op_acc: 33.59%] [G loss: 0.892189]\n",
      "epoch:18 step:14233[D loss: 0.414216, acc: 59.38%, op_acc: 42.19%] [G loss: 0.803679]\n",
      "epoch:18 step:14234[D loss: 0.420138, acc: 59.38%, op_acc: 39.84%] [G loss: 0.854290]\n",
      "epoch:18 step:14235[D loss: 0.395906, acc: 64.84%, op_acc: 39.84%] [G loss: 0.878928]\n",
      "epoch:18 step:14236[D loss: 0.448236, acc: 55.47%, op_acc: 37.50%] [G loss: 0.829248]\n",
      "epoch:18 step:14237[D loss: 0.411650, acc: 60.94%, op_acc: 39.06%] [G loss: 0.860906]\n",
      "epoch:18 step:14238[D loss: 0.421392, acc: 67.19%, op_acc: 42.19%] [G loss: 0.859048]\n",
      "epoch:18 step:14239[D loss: 0.424691, acc: 57.81%, op_acc: 39.84%] [G loss: 0.901253]\n",
      "epoch:18 step:14240[D loss: 0.432760, acc: 64.84%, op_acc: 38.28%] [G loss: 0.865167]\n",
      "epoch:18 step:14241[D loss: 0.410181, acc: 66.41%, op_acc: 40.62%] [G loss: 0.879208]\n",
      "epoch:18 step:14242[D loss: 0.418357, acc: 58.59%, op_acc: 39.84%] [G loss: 0.823793]\n",
      "epoch:18 step:14243[D loss: 0.447452, acc: 60.94%, op_acc: 30.47%] [G loss: 0.824881]\n",
      "epoch:18 step:14244[D loss: 0.442932, acc: 57.03%, op_acc: 33.59%] [G loss: 0.841934]\n",
      "epoch:18 step:14245[D loss: 0.431916, acc: 59.38%, op_acc: 35.16%] [G loss: 0.896447]\n",
      "epoch:18 step:14246[D loss: 0.434485, acc: 50.78%, op_acc: 39.84%] [G loss: 0.884405]\n",
      "epoch:18 step:14247[D loss: 0.443037, acc: 58.59%, op_acc: 38.28%] [G loss: 0.990994]\n",
      "epoch:18 step:14248[D loss: 0.438829, acc: 60.94%, op_acc: 33.59%] [G loss: 0.879868]\n",
      "epoch:18 step:14249[D loss: 0.431845, acc: 53.91%, op_acc: 40.62%] [G loss: 0.844487]\n",
      "epoch:18 step:14250[D loss: 0.433432, acc: 63.28%, op_acc: 35.94%] [G loss: 0.880372]\n",
      "epoch:18 step:14251[D loss: 0.432568, acc: 61.72%, op_acc: 40.62%] [G loss: 0.933266]\n",
      "epoch:18 step:14252[D loss: 0.391582, acc: 65.62%, op_acc: 41.41%] [G loss: 0.875500]\n",
      "epoch:18 step:14253[D loss: 0.461929, acc: 53.12%, op_acc: 37.50%] [G loss: 0.861081]\n",
      "epoch:18 step:14254[D loss: 0.416364, acc: 63.28%, op_acc: 33.59%] [G loss: 0.919809]\n",
      "epoch:18 step:14255[D loss: 0.434935, acc: 57.03%, op_acc: 41.41%] [G loss: 0.891027]\n",
      "epoch:18 step:14256[D loss: 0.457756, acc: 58.59%, op_acc: 32.81%] [G loss: 0.881641]\n",
      "epoch:18 step:14257[D loss: 0.470319, acc: 50.78%, op_acc: 36.72%] [G loss: 0.909871]\n",
      "epoch:18 step:14258[D loss: 0.408892, acc: 71.09%, op_acc: 40.62%] [G loss: 0.914143]\n",
      "epoch:18 step:14259[D loss: 0.415620, acc: 63.28%, op_acc: 39.06%] [G loss: 0.888798]\n",
      "epoch:18 step:14260[D loss: 0.419266, acc: 60.16%, op_acc: 37.50%] [G loss: 0.808297]\n",
      "epoch:18 step:14261[D loss: 0.447731, acc: 56.25%, op_acc: 31.25%] [G loss: 0.897313]\n",
      "epoch:18 step:14262[D loss: 0.448736, acc: 50.00%, op_acc: 42.97%] [G loss: 0.964799]\n",
      "epoch:18 step:14263[D loss: 0.440375, acc: 62.50%, op_acc: 32.03%] [G loss: 0.843511]\n",
      "epoch:18 step:14264[D loss: 0.446519, acc: 57.03%, op_acc: 35.94%] [G loss: 0.877825]\n",
      "epoch:18 step:14265[D loss: 0.403176, acc: 70.31%, op_acc: 41.41%] [G loss: 0.866589]\n",
      "epoch:18 step:14266[D loss: 0.456662, acc: 55.47%, op_acc: 32.03%] [G loss: 0.834564]\n",
      "epoch:18 step:14267[D loss: 0.401405, acc: 60.94%, op_acc: 40.62%] [G loss: 0.901402]\n",
      "epoch:18 step:14268[D loss: 0.433966, acc: 62.50%, op_acc: 35.16%] [G loss: 0.876935]\n",
      "epoch:18 step:14269[D loss: 0.416198, acc: 64.06%, op_acc: 39.06%] [G loss: 0.832716]\n",
      "epoch:18 step:14270[D loss: 0.399899, acc: 65.62%, op_acc: 42.97%] [G loss: 0.918271]\n",
      "epoch:18 step:14271[D loss: 0.431037, acc: 54.69%, op_acc: 39.84%] [G loss: 0.849969]\n",
      "epoch:18 step:14272[D loss: 0.446901, acc: 60.16%, op_acc: 36.72%] [G loss: 0.820054]\n",
      "epoch:18 step:14273[D loss: 0.485423, acc: 46.09%, op_acc: 34.38%] [G loss: 0.875908]\n",
      "epoch:18 step:14274[D loss: 0.431002, acc: 58.59%, op_acc: 35.16%] [G loss: 0.894028]\n",
      "epoch:18 step:14275[D loss: 0.395188, acc: 64.84%, op_acc: 39.84%] [G loss: 0.906888]\n",
      "epoch:18 step:14276[D loss: 0.424760, acc: 53.91%, op_acc: 42.19%] [G loss: 0.917538]\n",
      "epoch:18 step:14277[D loss: 0.404072, acc: 67.97%, op_acc: 39.06%] [G loss: 0.867618]\n",
      "epoch:18 step:14278[D loss: 0.451634, acc: 51.56%, op_acc: 36.72%] [G loss: 0.836978]\n",
      "epoch:18 step:14279[D loss: 0.416256, acc: 58.59%, op_acc: 35.94%] [G loss: 0.894515]\n",
      "epoch:18 step:14280[D loss: 0.439943, acc: 55.47%, op_acc: 36.72%] [G loss: 0.784152]\n",
      "epoch:18 step:14281[D loss: 0.439163, acc: 59.38%, op_acc: 39.06%] [G loss: 0.879883]\n",
      "epoch:18 step:14282[D loss: 0.425533, acc: 59.38%, op_acc: 39.06%] [G loss: 0.899671]\n",
      "epoch:18 step:14283[D loss: 0.462817, acc: 52.34%, op_acc: 30.47%] [G loss: 0.892976]\n",
      "epoch:18 step:14284[D loss: 0.431354, acc: 57.81%, op_acc: 37.50%] [G loss: 0.891604]\n",
      "epoch:18 step:14285[D loss: 0.423495, acc: 58.59%, op_acc: 38.28%] [G loss: 0.955818]\n",
      "epoch:18 step:14286[D loss: 0.424590, acc: 63.28%, op_acc: 35.16%] [G loss: 0.881767]\n",
      "epoch:18 step:14287[D loss: 0.419053, acc: 57.81%, op_acc: 42.19%] [G loss: 0.842789]\n",
      "epoch:18 step:14288[D loss: 0.448818, acc: 55.47%, op_acc: 38.28%] [G loss: 0.870857]\n",
      "epoch:18 step:14289[D loss: 0.439750, acc: 50.78%, op_acc: 35.94%] [G loss: 0.842681]\n",
      "epoch:18 step:14290[D loss: 0.484811, acc: 45.31%, op_acc: 34.38%] [G loss: 0.868380]\n",
      "epoch:18 step:14291[D loss: 0.431672, acc: 58.59%, op_acc: 34.38%] [G loss: 0.809107]\n",
      "epoch:18 step:14292[D loss: 0.445980, acc: 60.16%, op_acc: 35.16%] [G loss: 0.901123]\n",
      "epoch:18 step:14293[D loss: 0.395436, acc: 67.19%, op_acc: 40.62%] [G loss: 0.850673]\n",
      "epoch:18 step:14294[D loss: 0.421566, acc: 56.25%, op_acc: 39.06%] [G loss: 0.886192]\n",
      "epoch:18 step:14295[D loss: 0.445973, acc: 57.81%, op_acc: 38.28%] [G loss: 0.954258]\n",
      "epoch:18 step:14296[D loss: 0.426693, acc: 59.38%, op_acc: 40.62%] [G loss: 0.922305]\n",
      "epoch:18 step:14297[D loss: 0.424394, acc: 58.59%, op_acc: 39.06%] [G loss: 0.975037]\n",
      "epoch:18 step:14298[D loss: 0.423597, acc: 59.38%, op_acc: 36.72%] [G loss: 0.895766]\n",
      "epoch:18 step:14299[D loss: 0.409289, acc: 59.38%, op_acc: 38.28%] [G loss: 0.825284]\n",
      "epoch:18 step:14300[D loss: 0.419852, acc: 60.94%, op_acc: 37.50%] [G loss: 0.848893]\n",
      "epoch:18 step:14301[D loss: 0.445783, acc: 53.91%, op_acc: 39.84%] [G loss: 0.847909]\n",
      "epoch:18 step:14302[D loss: 0.436896, acc: 57.81%, op_acc: 35.94%] [G loss: 0.850860]\n",
      "epoch:18 step:14303[D loss: 0.434225, acc: 56.25%, op_acc: 43.75%] [G loss: 0.899571]\n",
      "epoch:18 step:14304[D loss: 0.454862, acc: 57.81%, op_acc: 33.59%] [G loss: 0.947057]\n",
      "epoch:18 step:14305[D loss: 0.422253, acc: 57.81%, op_acc: 44.53%] [G loss: 0.901654]\n",
      "epoch:18 step:14306[D loss: 0.438560, acc: 59.38%, op_acc: 36.72%] [G loss: 0.925001]\n",
      "epoch:18 step:14307[D loss: 0.441096, acc: 56.25%, op_acc: 41.41%] [G loss: 0.915309]\n",
      "epoch:18 step:14308[D loss: 0.476552, acc: 46.88%, op_acc: 31.25%] [G loss: 0.870306]\n",
      "epoch:18 step:14309[D loss: 0.416952, acc: 60.16%, op_acc: 43.75%] [G loss: 0.961545]\n",
      "epoch:18 step:14310[D loss: 0.458574, acc: 55.47%, op_acc: 38.28%] [G loss: 0.867752]\n",
      "epoch:18 step:14311[D loss: 0.444935, acc: 57.81%, op_acc: 35.94%] [G loss: 0.905243]\n",
      "epoch:18 step:14312[D loss: 0.456788, acc: 53.12%, op_acc: 32.81%] [G loss: 0.814504]\n",
      "epoch:18 step:14313[D loss: 0.439639, acc: 60.94%, op_acc: 39.84%] [G loss: 0.956763]\n",
      "epoch:18 step:14314[D loss: 0.436267, acc: 55.47%, op_acc: 38.28%] [G loss: 0.820467]\n",
      "epoch:18 step:14315[D loss: 0.436577, acc: 57.03%, op_acc: 35.16%] [G loss: 0.818281]\n",
      "epoch:18 step:14316[D loss: 0.431343, acc: 60.94%, op_acc: 40.62%] [G loss: 0.964384]\n",
      "epoch:18 step:14317[D loss: 0.436022, acc: 59.38%, op_acc: 33.59%] [G loss: 0.843993]\n",
      "epoch:18 step:14318[D loss: 0.470271, acc: 52.34%, op_acc: 35.94%] [G loss: 0.886946]\n",
      "epoch:18 step:14319[D loss: 0.444508, acc: 57.03%, op_acc: 34.38%] [G loss: 1.021044]\n",
      "epoch:18 step:14320[D loss: 0.429292, acc: 60.94%, op_acc: 39.06%] [G loss: 0.941512]\n",
      "epoch:18 step:14321[D loss: 0.461832, acc: 48.44%, op_acc: 35.16%] [G loss: 0.966851]\n",
      "epoch:18 step:14322[D loss: 0.411484, acc: 57.03%, op_acc: 35.16%] [G loss: 0.903486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14323[D loss: 0.412027, acc: 57.81%, op_acc: 35.94%] [G loss: 0.882528]\n",
      "epoch:18 step:14324[D loss: 0.417394, acc: 64.84%, op_acc: 38.28%] [G loss: 0.937729]\n",
      "epoch:18 step:14325[D loss: 0.440128, acc: 56.25%, op_acc: 41.41%] [G loss: 0.896373]\n",
      "epoch:18 step:14326[D loss: 0.394850, acc: 68.75%, op_acc: 42.97%] [G loss: 0.860751]\n",
      "epoch:18 step:14327[D loss: 0.406769, acc: 63.28%, op_acc: 40.62%] [G loss: 0.935008]\n",
      "epoch:18 step:14328[D loss: 0.429714, acc: 64.84%, op_acc: 36.72%] [G loss: 0.975114]\n",
      "epoch:18 step:14329[D loss: 0.428284, acc: 60.16%, op_acc: 38.28%] [G loss: 0.999794]\n",
      "epoch:18 step:14330[D loss: 0.416495, acc: 64.06%, op_acc: 37.50%] [G loss: 0.983760]\n",
      "epoch:18 step:14331[D loss: 0.421265, acc: 60.94%, op_acc: 44.53%] [G loss: 0.871097]\n",
      "epoch:18 step:14332[D loss: 0.417341, acc: 67.19%, op_acc: 39.84%] [G loss: 0.855591]\n",
      "epoch:18 step:14333[D loss: 0.426108, acc: 62.50%, op_acc: 39.84%] [G loss: 0.870996]\n",
      "epoch:18 step:14334[D loss: 0.427604, acc: 54.69%, op_acc: 38.28%] [G loss: 0.839885]\n",
      "epoch:18 step:14335[D loss: 0.445492, acc: 61.72%, op_acc: 33.59%] [G loss: 0.809326]\n",
      "epoch:18 step:14336[D loss: 0.444580, acc: 61.72%, op_acc: 38.28%] [G loss: 0.839926]\n",
      "epoch:18 step:14337[D loss: 0.416771, acc: 61.72%, op_acc: 39.06%] [G loss: 0.799843]\n",
      "epoch:18 step:14338[D loss: 0.425650, acc: 62.50%, op_acc: 39.06%] [G loss: 0.871482]\n",
      "epoch:18 step:14339[D loss: 0.463604, acc: 48.44%, op_acc: 35.94%] [G loss: 0.780746]\n",
      "epoch:18 step:14340[D loss: 0.435760, acc: 57.81%, op_acc: 35.94%] [G loss: 0.845885]\n",
      "epoch:18 step:14341[D loss: 0.411823, acc: 60.94%, op_acc: 45.31%] [G loss: 0.932146]\n",
      "epoch:18 step:14342[D loss: 0.434115, acc: 63.28%, op_acc: 32.81%] [G loss: 0.852842]\n",
      "epoch:18 step:14343[D loss: 0.445219, acc: 54.69%, op_acc: 35.16%] [G loss: 0.846767]\n",
      "epoch:18 step:14344[D loss: 0.428065, acc: 64.06%, op_acc: 36.72%] [G loss: 0.853734]\n",
      "epoch:18 step:14345[D loss: 0.469708, acc: 48.44%, op_acc: 44.53%] [G loss: 0.864051]\n",
      "epoch:18 step:14346[D loss: 0.427157, acc: 57.03%, op_acc: 42.97%] [G loss: 0.808979]\n",
      "epoch:18 step:14347[D loss: 0.430876, acc: 64.06%, op_acc: 39.06%] [G loss: 0.904090]\n",
      "epoch:18 step:14348[D loss: 0.431597, acc: 56.25%, op_acc: 37.50%] [G loss: 0.887614]\n",
      "epoch:18 step:14349[D loss: 0.433161, acc: 54.69%, op_acc: 40.62%] [G loss: 0.905519]\n",
      "epoch:18 step:14350[D loss: 0.429978, acc: 61.72%, op_acc: 32.81%] [G loss: 0.910568]\n",
      "epoch:18 step:14351[D loss: 0.454399, acc: 50.00%, op_acc: 42.19%] [G loss: 0.835518]\n",
      "epoch:18 step:14352[D loss: 0.453930, acc: 54.69%, op_acc: 35.94%] [G loss: 0.777969]\n",
      "epoch:18 step:14353[D loss: 0.406419, acc: 64.06%, op_acc: 43.75%] [G loss: 0.857628]\n",
      "epoch:18 step:14354[D loss: 0.447925, acc: 50.00%, op_acc: 37.50%] [G loss: 0.887508]\n",
      "epoch:18 step:14355[D loss: 0.448634, acc: 58.59%, op_acc: 28.12%] [G loss: 0.878055]\n",
      "epoch:18 step:14356[D loss: 0.447343, acc: 56.25%, op_acc: 39.84%] [G loss: 0.812784]\n",
      "epoch:18 step:14357[D loss: 0.452530, acc: 48.44%, op_acc: 39.06%] [G loss: 0.941645]\n",
      "epoch:18 step:14358[D loss: 0.440614, acc: 59.38%, op_acc: 39.84%] [G loss: 0.839056]\n",
      "epoch:18 step:14359[D loss: 0.411369, acc: 62.50%, op_acc: 39.06%] [G loss: 0.958471]\n",
      "epoch:18 step:14360[D loss: 0.384685, acc: 64.84%, op_acc: 39.84%] [G loss: 0.871658]\n",
      "epoch:18 step:14361[D loss: 0.440269, acc: 57.03%, op_acc: 37.50%] [G loss: 0.891178]\n",
      "epoch:18 step:14362[D loss: 0.413145, acc: 64.84%, op_acc: 35.94%] [G loss: 0.895050]\n",
      "epoch:18 step:14363[D loss: 0.431453, acc: 59.38%, op_acc: 39.06%] [G loss: 0.935551]\n",
      "epoch:18 step:14364[D loss: 0.447419, acc: 60.16%, op_acc: 35.94%] [G loss: 0.977386]\n",
      "epoch:18 step:14365[D loss: 0.448009, acc: 50.78%, op_acc: 38.28%] [G loss: 0.915312]\n",
      "epoch:18 step:14366[D loss: 0.467136, acc: 54.69%, op_acc: 32.03%] [G loss: 0.910116]\n",
      "epoch:18 step:14367[D loss: 0.480455, acc: 55.47%, op_acc: 32.03%] [G loss: 0.813741]\n",
      "epoch:18 step:14368[D loss: 0.418292, acc: 63.28%, op_acc: 37.50%] [G loss: 0.910073]\n",
      "epoch:18 step:14369[D loss: 0.410132, acc: 61.72%, op_acc: 45.31%] [G loss: 1.001313]\n",
      "epoch:18 step:14370[D loss: 0.421478, acc: 59.38%, op_acc: 40.62%] [G loss: 0.946201]\n",
      "epoch:18 step:14371[D loss: 0.442385, acc: 60.94%, op_acc: 38.28%] [G loss: 0.933168]\n",
      "epoch:18 step:14372[D loss: 0.434431, acc: 52.34%, op_acc: 39.84%] [G loss: 0.887199]\n",
      "epoch:18 step:14373[D loss: 0.458046, acc: 55.47%, op_acc: 32.81%] [G loss: 0.883904]\n",
      "epoch:18 step:14374[D loss: 0.429263, acc: 60.16%, op_acc: 38.28%] [G loss: 0.898094]\n",
      "epoch:18 step:14375[D loss: 0.435006, acc: 58.59%, op_acc: 38.28%] [G loss: 0.881117]\n",
      "epoch:18 step:14376[D loss: 0.436385, acc: 60.16%, op_acc: 32.81%] [G loss: 0.913294]\n",
      "epoch:18 step:14377[D loss: 0.391509, acc: 66.41%, op_acc: 42.19%] [G loss: 0.885140]\n",
      "epoch:18 step:14378[D loss: 0.480376, acc: 46.09%, op_acc: 31.25%] [G loss: 0.758776]\n",
      "epoch:18 step:14379[D loss: 0.460721, acc: 54.69%, op_acc: 32.81%] [G loss: 0.905963]\n",
      "epoch:18 step:14380[D loss: 0.423147, acc: 60.94%, op_acc: 37.50%] [G loss: 0.889715]\n",
      "epoch:18 step:14381[D loss: 0.447937, acc: 50.78%, op_acc: 38.28%] [G loss: 0.831555]\n",
      "epoch:18 step:14382[D loss: 0.445084, acc: 59.38%, op_acc: 40.62%] [G loss: 0.928820]\n",
      "epoch:18 step:14383[D loss: 0.441667, acc: 58.59%, op_acc: 38.28%] [G loss: 0.832986]\n",
      "epoch:18 step:14384[D loss: 0.462161, acc: 49.22%, op_acc: 36.72%] [G loss: 0.853502]\n",
      "epoch:18 step:14385[D loss: 0.413604, acc: 64.06%, op_acc: 36.72%] [G loss: 0.960221]\n",
      "epoch:18 step:14386[D loss: 0.431510, acc: 59.38%, op_acc: 37.50%] [G loss: 0.840532]\n",
      "epoch:18 step:14387[D loss: 0.398587, acc: 68.75%, op_acc: 40.62%] [G loss: 0.855085]\n",
      "epoch:18 step:14388[D loss: 0.429118, acc: 56.25%, op_acc: 43.75%] [G loss: 0.897487]\n",
      "epoch:18 step:14389[D loss: 0.446773, acc: 53.12%, op_acc: 36.72%] [G loss: 0.934451]\n",
      "epoch:18 step:14390[D loss: 0.445654, acc: 53.91%, op_acc: 38.28%] [G loss: 0.856044]\n",
      "epoch:18 step:14391[D loss: 0.419559, acc: 67.19%, op_acc: 39.06%] [G loss: 0.974209]\n",
      "epoch:18 step:14392[D loss: 0.402718, acc: 64.06%, op_acc: 39.06%] [G loss: 0.922027]\n",
      "epoch:18 step:14393[D loss: 0.464254, acc: 54.69%, op_acc: 33.59%] [G loss: 0.787340]\n",
      "epoch:18 step:14394[D loss: 0.442923, acc: 63.28%, op_acc: 39.06%] [G loss: 0.836805]\n",
      "epoch:18 step:14395[D loss: 0.440924, acc: 57.81%, op_acc: 39.06%] [G loss: 0.922990]\n",
      "epoch:18 step:14396[D loss: 0.409978, acc: 62.50%, op_acc: 42.19%] [G loss: 0.872361]\n",
      "epoch:18 step:14397[D loss: 0.394379, acc: 68.75%, op_acc: 35.16%] [G loss: 0.894084]\n",
      "epoch:18 step:14398[D loss: 0.436438, acc: 59.38%, op_acc: 39.06%] [G loss: 0.905314]\n",
      "epoch:18 step:14399[D loss: 0.446949, acc: 53.91%, op_acc: 33.59%] [G loss: 0.833961]\n",
      "epoch:18 step:14400[D loss: 0.441247, acc: 54.69%, op_acc: 35.16%] [G loss: 0.910249]\n",
      "epoch:18 step:14401[D loss: 0.449998, acc: 53.12%, op_acc: 33.59%] [G loss: 0.823564]\n",
      "epoch:18 step:14402[D loss: 0.424637, acc: 57.03%, op_acc: 36.72%] [G loss: 0.865796]\n",
      "epoch:18 step:14403[D loss: 0.436614, acc: 57.81%, op_acc: 33.59%] [G loss: 0.870158]\n",
      "epoch:18 step:14404[D loss: 0.425594, acc: 57.81%, op_acc: 39.84%] [G loss: 0.882920]\n",
      "epoch:18 step:14405[D loss: 0.412022, acc: 60.94%, op_acc: 37.50%] [G loss: 0.848751]\n",
      "epoch:18 step:14406[D loss: 0.439321, acc: 60.94%, op_acc: 36.72%] [G loss: 0.850719]\n",
      "epoch:18 step:14407[D loss: 0.419128, acc: 62.50%, op_acc: 37.50%] [G loss: 0.883047]\n",
      "epoch:18 step:14408[D loss: 0.440727, acc: 53.91%, op_acc: 36.72%] [G loss: 0.918229]\n",
      "epoch:18 step:14409[D loss: 0.443250, acc: 57.03%, op_acc: 39.06%] [G loss: 0.929717]\n",
      "epoch:18 step:14410[D loss: 0.431858, acc: 59.38%, op_acc: 41.41%] [G loss: 0.874696]\n",
      "epoch:18 step:14411[D loss: 0.401209, acc: 60.16%, op_acc: 43.75%] [G loss: 1.003344]\n",
      "epoch:18 step:14412[D loss: 0.432265, acc: 57.81%, op_acc: 33.59%] [G loss: 0.922264]\n",
      "epoch:18 step:14413[D loss: 0.442826, acc: 52.34%, op_acc: 35.16%] [G loss: 0.841281]\n",
      "epoch:18 step:14414[D loss: 0.421594, acc: 57.81%, op_acc: 38.28%] [G loss: 0.857174]\n",
      "epoch:18 step:14415[D loss: 0.407691, acc: 63.28%, op_acc: 40.62%] [G loss: 0.845026]\n",
      "epoch:18 step:14416[D loss: 0.427216, acc: 64.06%, op_acc: 39.84%] [G loss: 0.873118]\n",
      "epoch:18 step:14417[D loss: 0.425316, acc: 60.16%, op_acc: 36.72%] [G loss: 0.872327]\n",
      "epoch:18 step:14418[D loss: 0.421712, acc: 64.84%, op_acc: 36.72%] [G loss: 0.927972]\n",
      "epoch:18 step:14419[D loss: 0.413141, acc: 55.47%, op_acc: 43.75%] [G loss: 0.892947]\n",
      "epoch:18 step:14420[D loss: 0.395571, acc: 65.62%, op_acc: 37.50%] [G loss: 0.911984]\n",
      "epoch:18 step:14421[D loss: 0.440870, acc: 60.94%, op_acc: 37.50%] [G loss: 0.838500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14422[D loss: 0.446869, acc: 57.03%, op_acc: 35.16%] [G loss: 0.883315]\n",
      "epoch:18 step:14423[D loss: 0.398582, acc: 63.28%, op_acc: 42.19%] [G loss: 0.922266]\n",
      "epoch:18 step:14424[D loss: 0.423820, acc: 57.03%, op_acc: 35.94%] [G loss: 0.954851]\n",
      "epoch:18 step:14425[D loss: 0.456203, acc: 54.69%, op_acc: 35.16%] [G loss: 0.841827]\n",
      "epoch:18 step:14426[D loss: 0.406894, acc: 65.62%, op_acc: 39.06%] [G loss: 0.862782]\n",
      "epoch:18 step:14427[D loss: 0.429720, acc: 59.38%, op_acc: 35.16%] [G loss: 0.891263]\n",
      "epoch:18 step:14428[D loss: 0.435290, acc: 57.81%, op_acc: 39.84%] [G loss: 0.862130]\n",
      "epoch:18 step:14429[D loss: 0.403743, acc: 65.62%, op_acc: 44.53%] [G loss: 0.953943]\n",
      "epoch:18 step:14430[D loss: 0.422704, acc: 63.28%, op_acc: 36.72%] [G loss: 0.894587]\n",
      "epoch:18 step:14431[D loss: 0.421241, acc: 67.19%, op_acc: 39.84%] [G loss: 0.888022]\n",
      "epoch:18 step:14432[D loss: 0.411289, acc: 60.16%, op_acc: 42.19%] [G loss: 0.881578]\n",
      "epoch:18 step:14433[D loss: 0.426749, acc: 56.25%, op_acc: 40.62%] [G loss: 0.878097]\n",
      "epoch:18 step:14434[D loss: 0.423943, acc: 60.16%, op_acc: 39.84%] [G loss: 0.805446]\n",
      "epoch:18 step:14435[D loss: 0.409659, acc: 60.94%, op_acc: 39.06%] [G loss: 0.976919]\n",
      "epoch:18 step:14436[D loss: 0.406382, acc: 62.50%, op_acc: 40.62%] [G loss: 0.885580]\n",
      "epoch:18 step:14437[D loss: 0.407341, acc: 58.59%, op_acc: 42.97%] [G loss: 0.825211]\n",
      "epoch:18 step:14438[D loss: 0.398550, acc: 67.19%, op_acc: 39.84%] [G loss: 0.953251]\n",
      "epoch:18 step:14439[D loss: 0.411348, acc: 64.06%, op_acc: 37.50%] [G loss: 0.924679]\n",
      "epoch:18 step:14440[D loss: 0.441189, acc: 50.78%, op_acc: 37.50%] [G loss: 0.830373]\n",
      "epoch:18 step:14441[D loss: 0.454096, acc: 55.47%, op_acc: 38.28%] [G loss: 0.834084]\n",
      "epoch:18 step:14442[D loss: 0.410952, acc: 68.75%, op_acc: 34.38%] [G loss: 0.911150]\n",
      "epoch:18 step:14443[D loss: 0.401734, acc: 63.28%, op_acc: 41.41%] [G loss: 0.924270]\n",
      "epoch:18 step:14444[D loss: 0.417778, acc: 59.38%, op_acc: 44.53%] [G loss: 0.940954]\n",
      "epoch:18 step:14445[D loss: 0.415511, acc: 63.28%, op_acc: 40.62%] [G loss: 0.961471]\n",
      "epoch:18 step:14446[D loss: 0.439249, acc: 64.84%, op_acc: 32.03%] [G loss: 0.966922]\n",
      "epoch:18 step:14447[D loss: 0.440798, acc: 52.34%, op_acc: 39.06%] [G loss: 0.922685]\n",
      "epoch:18 step:14448[D loss: 0.410151, acc: 60.94%, op_acc: 44.53%] [G loss: 0.899886]\n",
      "epoch:18 step:14449[D loss: 0.441734, acc: 54.69%, op_acc: 37.50%] [G loss: 0.857150]\n",
      "epoch:18 step:14450[D loss: 0.416506, acc: 60.94%, op_acc: 40.62%] [G loss: 1.001467]\n",
      "epoch:18 step:14451[D loss: 0.420442, acc: 61.72%, op_acc: 39.06%] [G loss: 0.911184]\n",
      "epoch:18 step:14452[D loss: 0.443381, acc: 58.59%, op_acc: 34.38%] [G loss: 0.910989]\n",
      "epoch:18 step:14453[D loss: 0.470661, acc: 53.91%, op_acc: 34.38%] [G loss: 0.841380]\n",
      "epoch:18 step:14454[D loss: 0.411147, acc: 61.72%, op_acc: 42.19%] [G loss: 0.898980]\n",
      "epoch:18 step:14455[D loss: 0.449897, acc: 46.88%, op_acc: 35.94%] [G loss: 0.866884]\n",
      "epoch:18 step:14456[D loss: 0.423237, acc: 63.28%, op_acc: 37.50%] [G loss: 0.862186]\n",
      "epoch:18 step:14457[D loss: 0.445252, acc: 56.25%, op_acc: 39.84%] [G loss: 0.867879]\n",
      "epoch:18 step:14458[D loss: 0.417127, acc: 60.16%, op_acc: 35.16%] [G loss: 0.888305]\n",
      "epoch:18 step:14459[D loss: 0.446245, acc: 50.78%, op_acc: 42.19%] [G loss: 0.911943]\n",
      "epoch:18 step:14460[D loss: 0.427960, acc: 61.72%, op_acc: 33.59%] [G loss: 0.854799]\n",
      "epoch:18 step:14461[D loss: 0.447797, acc: 57.81%, op_acc: 34.38%] [G loss: 0.853611]\n",
      "epoch:18 step:14462[D loss: 0.396845, acc: 62.50%, op_acc: 43.75%] [G loss: 0.855044]\n",
      "epoch:18 step:14463[D loss: 0.436926, acc: 63.28%, op_acc: 35.16%] [G loss: 0.883389]\n",
      "epoch:18 step:14464[D loss: 0.433517, acc: 58.59%, op_acc: 35.94%] [G loss: 0.839090]\n",
      "epoch:18 step:14465[D loss: 0.410563, acc: 66.41%, op_acc: 38.28%] [G loss: 0.860619]\n",
      "epoch:18 step:14466[D loss: 0.428496, acc: 55.47%, op_acc: 35.94%] [G loss: 0.966764]\n",
      "epoch:18 step:14467[D loss: 0.439416, acc: 57.81%, op_acc: 38.28%] [G loss: 0.962248]\n",
      "epoch:18 step:14468[D loss: 0.410627, acc: 57.03%, op_acc: 41.41%] [G loss: 0.849034]\n",
      "epoch:18 step:14469[D loss: 0.420914, acc: 61.72%, op_acc: 35.16%] [G loss: 0.859851]\n",
      "epoch:18 step:14470[D loss: 0.421585, acc: 54.69%, op_acc: 39.06%] [G loss: 0.815581]\n",
      "epoch:18 step:14471[D loss: 0.422947, acc: 57.03%, op_acc: 45.31%] [G loss: 0.875811]\n",
      "epoch:18 step:14472[D loss: 0.391088, acc: 66.41%, op_acc: 39.84%] [G loss: 1.009327]\n",
      "epoch:18 step:14473[D loss: 0.423900, acc: 60.16%, op_acc: 33.59%] [G loss: 0.889722]\n",
      "epoch:18 step:14474[D loss: 0.416418, acc: 58.59%, op_acc: 39.84%] [G loss: 0.833129]\n",
      "epoch:18 step:14475[D loss: 0.450430, acc: 58.59%, op_acc: 31.25%] [G loss: 0.881747]\n",
      "epoch:18 step:14476[D loss: 0.415309, acc: 63.28%, op_acc: 39.84%] [G loss: 0.866927]\n",
      "epoch:18 step:14477[D loss: 0.441576, acc: 60.94%, op_acc: 30.47%] [G loss: 0.900733]\n",
      "epoch:18 step:14478[D loss: 0.409494, acc: 67.97%, op_acc: 38.28%] [G loss: 0.944143]\n",
      "epoch:18 step:14479[D loss: 0.461814, acc: 52.34%, op_acc: 37.50%] [G loss: 0.941171]\n",
      "epoch:18 step:14480[D loss: 0.456235, acc: 50.00%, op_acc: 41.41%] [G loss: 0.954384]\n",
      "epoch:18 step:14481[D loss: 0.450567, acc: 56.25%, op_acc: 37.50%] [G loss: 0.853872]\n",
      "epoch:18 step:14482[D loss: 0.423727, acc: 56.25%, op_acc: 39.84%] [G loss: 0.858283]\n",
      "epoch:18 step:14483[D loss: 0.427805, acc: 58.59%, op_acc: 36.72%] [G loss: 0.818575]\n",
      "epoch:18 step:14484[D loss: 0.481899, acc: 43.75%, op_acc: 28.12%] [G loss: 0.854278]\n",
      "epoch:18 step:14485[D loss: 0.431580, acc: 56.25%, op_acc: 35.94%] [G loss: 0.832592]\n",
      "epoch:18 step:14486[D loss: 0.424242, acc: 53.12%, op_acc: 41.41%] [G loss: 0.828351]\n",
      "epoch:18 step:14487[D loss: 0.462828, acc: 50.78%, op_acc: 32.81%] [G loss: 0.833959]\n",
      "epoch:18 step:14488[D loss: 0.396903, acc: 67.97%, op_acc: 42.19%] [G loss: 0.829395]\n",
      "epoch:18 step:14489[D loss: 0.438466, acc: 50.78%, op_acc: 39.84%] [G loss: 0.827228]\n",
      "epoch:18 step:14490[D loss: 0.442018, acc: 50.00%, op_acc: 44.53%] [G loss: 0.889724]\n",
      "epoch:18 step:14491[D loss: 0.426868, acc: 54.69%, op_acc: 37.50%] [G loss: 0.926061]\n",
      "epoch:18 step:14492[D loss: 0.433734, acc: 53.91%, op_acc: 38.28%] [G loss: 0.859548]\n",
      "epoch:18 step:14493[D loss: 0.418040, acc: 57.03%, op_acc: 42.19%] [G loss: 0.933273]\n",
      "epoch:18 step:14494[D loss: 0.467573, acc: 50.78%, op_acc: 35.16%] [G loss: 0.856442]\n",
      "epoch:18 step:14495[D loss: 0.425650, acc: 63.28%, op_acc: 40.62%] [G loss: 0.886262]\n",
      "epoch:18 step:14496[D loss: 0.409226, acc: 62.50%, op_acc: 36.72%] [G loss: 0.788354]\n",
      "epoch:18 step:14497[D loss: 0.428108, acc: 60.16%, op_acc: 35.16%] [G loss: 0.877119]\n",
      "epoch:18 step:14498[D loss: 0.425871, acc: 57.03%, op_acc: 37.50%] [G loss: 0.886865]\n",
      "epoch:18 step:14499[D loss: 0.461086, acc: 47.66%, op_acc: 34.38%] [G loss: 0.814973]\n",
      "epoch:18 step:14500[D loss: 0.433312, acc: 56.25%, op_acc: 39.06%] [G loss: 0.908125]\n",
      "epoch:18 step:14501[D loss: 0.469881, acc: 49.22%, op_acc: 35.94%] [G loss: 0.872899]\n",
      "epoch:18 step:14502[D loss: 0.412828, acc: 59.38%, op_acc: 37.50%] [G loss: 0.888385]\n",
      "epoch:18 step:14503[D loss: 0.434701, acc: 59.38%, op_acc: 33.59%] [G loss: 0.829482]\n",
      "epoch:18 step:14504[D loss: 0.433681, acc: 50.78%, op_acc: 39.06%] [G loss: 0.891067]\n",
      "epoch:18 step:14505[D loss: 0.476515, acc: 54.69%, op_acc: 32.81%] [G loss: 0.890019]\n",
      "epoch:18 step:14506[D loss: 0.431755, acc: 62.50%, op_acc: 40.62%] [G loss: 0.926967]\n",
      "epoch:18 step:14507[D loss: 0.409204, acc: 60.94%, op_acc: 41.41%] [G loss: 0.890085]\n",
      "epoch:18 step:14508[D loss: 0.467803, acc: 58.59%, op_acc: 32.81%] [G loss: 0.981059]\n",
      "epoch:18 step:14509[D loss: 0.419896, acc: 64.06%, op_acc: 43.75%] [G loss: 0.862335]\n",
      "epoch:18 step:14510[D loss: 0.399210, acc: 64.06%, op_acc: 39.84%] [G loss: 0.907246]\n",
      "epoch:18 step:14511[D loss: 0.414114, acc: 59.38%, op_acc: 42.19%] [G loss: 0.804159]\n",
      "epoch:18 step:14512[D loss: 0.437529, acc: 58.59%, op_acc: 37.50%] [G loss: 0.906268]\n",
      "epoch:18 step:14513[D loss: 0.435804, acc: 58.59%, op_acc: 39.84%] [G loss: 0.799053]\n",
      "epoch:18 step:14514[D loss: 0.444391, acc: 57.81%, op_acc: 28.91%] [G loss: 0.867008]\n",
      "epoch:18 step:14515[D loss: 0.441175, acc: 59.38%, op_acc: 35.16%] [G loss: 0.831107]\n",
      "epoch:18 step:14516[D loss: 0.394257, acc: 64.06%, op_acc: 44.53%] [G loss: 0.858137]\n",
      "epoch:18 step:14517[D loss: 0.421409, acc: 57.03%, op_acc: 41.41%] [G loss: 0.817802]\n",
      "epoch:18 step:14518[D loss: 0.396277, acc: 65.62%, op_acc: 41.41%] [G loss: 0.848338]\n",
      "epoch:18 step:14519[D loss: 0.442460, acc: 51.56%, op_acc: 35.16%] [G loss: 0.812566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14520[D loss: 0.409501, acc: 67.97%, op_acc: 37.50%] [G loss: 0.853183]\n",
      "epoch:18 step:14521[D loss: 0.438888, acc: 57.81%, op_acc: 37.50%] [G loss: 0.855161]\n",
      "epoch:18 step:14522[D loss: 0.424952, acc: 64.06%, op_acc: 37.50%] [G loss: 0.854429]\n",
      "epoch:18 step:14523[D loss: 0.396896, acc: 67.19%, op_acc: 43.75%] [G loss: 0.878523]\n",
      "epoch:18 step:14524[D loss: 0.435420, acc: 59.38%, op_acc: 40.62%] [G loss: 0.872659]\n",
      "epoch:18 step:14525[D loss: 0.436833, acc: 55.47%, op_acc: 39.06%] [G loss: 0.824455]\n",
      "epoch:18 step:14526[D loss: 0.398430, acc: 59.38%, op_acc: 46.09%] [G loss: 0.842478]\n",
      "epoch:18 step:14527[D loss: 0.409583, acc: 63.28%, op_acc: 43.75%] [G loss: 0.887825]\n",
      "epoch:18 step:14528[D loss: 0.395946, acc: 65.62%, op_acc: 42.97%] [G loss: 0.934181]\n",
      "epoch:18 step:14529[D loss: 0.427724, acc: 62.50%, op_acc: 36.72%] [G loss: 0.883318]\n",
      "epoch:18 step:14530[D loss: 0.423644, acc: 55.47%, op_acc: 35.16%] [G loss: 0.848135]\n",
      "epoch:18 step:14531[D loss: 0.420973, acc: 57.03%, op_acc: 40.62%] [G loss: 0.787710]\n",
      "epoch:18 step:14532[D loss: 0.429954, acc: 60.16%, op_acc: 37.50%] [G loss: 0.901258]\n",
      "epoch:18 step:14533[D loss: 0.462091, acc: 50.78%, op_acc: 38.28%] [G loss: 0.855081]\n",
      "epoch:18 step:14534[D loss: 0.449087, acc: 60.16%, op_acc: 36.72%] [G loss: 0.879972]\n",
      "epoch:18 step:14535[D loss: 0.421641, acc: 63.28%, op_acc: 39.84%] [G loss: 0.918015]\n",
      "epoch:18 step:14536[D loss: 0.415610, acc: 56.25%, op_acc: 39.84%] [G loss: 0.909298]\n",
      "epoch:18 step:14537[D loss: 0.440879, acc: 52.34%, op_acc: 37.50%] [G loss: 0.904705]\n",
      "epoch:18 step:14538[D loss: 0.441338, acc: 60.16%, op_acc: 34.38%] [G loss: 0.906675]\n",
      "epoch:18 step:14539[D loss: 0.427813, acc: 68.75%, op_acc: 32.81%] [G loss: 0.870526]\n",
      "epoch:18 step:14540[D loss: 0.422010, acc: 62.50%, op_acc: 39.84%] [G loss: 0.886307]\n",
      "epoch:18 step:14541[D loss: 0.433267, acc: 53.12%, op_acc: 38.28%] [G loss: 0.796419]\n",
      "epoch:18 step:14542[D loss: 0.416231, acc: 60.16%, op_acc: 42.97%] [G loss: 0.888854]\n",
      "epoch:18 step:14543[D loss: 0.408943, acc: 67.97%, op_acc: 39.06%] [G loss: 0.871249]\n",
      "epoch:18 step:14544[D loss: 0.413494, acc: 60.94%, op_acc: 41.41%] [G loss: 0.907992]\n",
      "epoch:18 step:14545[D loss: 0.447700, acc: 53.91%, op_acc: 41.41%] [G loss: 0.851051]\n",
      "epoch:18 step:14546[D loss: 0.448624, acc: 57.03%, op_acc: 37.50%] [G loss: 0.892992]\n",
      "epoch:18 step:14547[D loss: 0.422755, acc: 62.50%, op_acc: 37.50%] [G loss: 0.874471]\n",
      "epoch:18 step:14548[D loss: 0.414230, acc: 56.25%, op_acc: 39.84%] [G loss: 0.867284]\n",
      "epoch:18 step:14549[D loss: 0.440235, acc: 53.12%, op_acc: 44.53%] [G loss: 0.890267]\n",
      "epoch:18 step:14550[D loss: 0.430488, acc: 56.25%, op_acc: 35.94%] [G loss: 0.888964]\n",
      "epoch:18 step:14551[D loss: 0.424513, acc: 65.62%, op_acc: 35.94%] [G loss: 0.881973]\n",
      "epoch:18 step:14552[D loss: 0.389420, acc: 65.62%, op_acc: 46.88%] [G loss: 0.874804]\n",
      "epoch:18 step:14553[D loss: 0.435218, acc: 67.97%, op_acc: 34.38%] [G loss: 0.837360]\n",
      "epoch:18 step:14554[D loss: 0.423549, acc: 57.03%, op_acc: 37.50%] [G loss: 0.894142]\n",
      "epoch:18 step:14555[D loss: 0.411543, acc: 60.94%, op_acc: 39.84%] [G loss: 0.941854]\n",
      "epoch:18 step:14556[D loss: 0.455003, acc: 58.59%, op_acc: 39.84%] [G loss: 0.865531]\n",
      "epoch:18 step:14557[D loss: 0.443814, acc: 58.59%, op_acc: 33.59%] [G loss: 0.916303]\n",
      "epoch:18 step:14558[D loss: 0.433489, acc: 61.72%, op_acc: 41.41%] [G loss: 0.854616]\n",
      "epoch:18 step:14559[D loss: 0.458026, acc: 49.22%, op_acc: 35.94%] [G loss: 0.895513]\n",
      "epoch:18 step:14560[D loss: 0.423488, acc: 58.59%, op_acc: 38.28%] [G loss: 0.862311]\n",
      "epoch:18 step:14561[D loss: 0.431402, acc: 60.94%, op_acc: 36.72%] [G loss: 0.862336]\n",
      "epoch:18 step:14562[D loss: 0.436618, acc: 55.47%, op_acc: 35.16%] [G loss: 0.930528]\n",
      "epoch:18 step:14563[D loss: 0.421683, acc: 60.94%, op_acc: 32.81%] [G loss: 0.920731]\n",
      "epoch:18 step:14564[D loss: 0.423447, acc: 62.50%, op_acc: 41.41%] [G loss: 0.865985]\n",
      "epoch:18 step:14565[D loss: 0.399322, acc: 67.97%, op_acc: 38.28%] [G loss: 0.921726]\n",
      "epoch:18 step:14566[D loss: 0.426324, acc: 62.50%, op_acc: 37.50%] [G loss: 0.850767]\n",
      "epoch:18 step:14567[D loss: 0.443337, acc: 55.47%, op_acc: 36.72%] [G loss: 0.918630]\n",
      "epoch:18 step:14568[D loss: 0.437510, acc: 57.81%, op_acc: 39.06%] [G loss: 0.851385]\n",
      "epoch:18 step:14569[D loss: 0.419385, acc: 57.81%, op_acc: 39.06%] [G loss: 0.915703]\n",
      "epoch:18 step:14570[D loss: 0.450789, acc: 57.81%, op_acc: 37.50%] [G loss: 0.911979]\n",
      "epoch:18 step:14571[D loss: 0.472980, acc: 60.16%, op_acc: 32.81%] [G loss: 0.851016]\n",
      "epoch:18 step:14572[D loss: 0.442211, acc: 50.78%, op_acc: 33.59%] [G loss: 0.784167]\n",
      "epoch:18 step:14573[D loss: 0.408696, acc: 69.53%, op_acc: 39.84%] [G loss: 0.893152]\n",
      "epoch:18 step:14574[D loss: 0.429827, acc: 60.94%, op_acc: 41.41%] [G loss: 0.903889]\n",
      "epoch:18 step:14575[D loss: 0.445323, acc: 58.59%, op_acc: 40.62%] [G loss: 0.878851]\n",
      "epoch:18 step:14576[D loss: 0.417515, acc: 69.53%, op_acc: 36.72%] [G loss: 0.935074]\n",
      "epoch:18 step:14577[D loss: 0.433203, acc: 52.34%, op_acc: 35.94%] [G loss: 0.898888]\n",
      "epoch:18 step:14578[D loss: 0.434024, acc: 51.56%, op_acc: 38.28%] [G loss: 0.859675]\n",
      "epoch:18 step:14579[D loss: 0.437819, acc: 64.06%, op_acc: 30.47%] [G loss: 0.853225]\n",
      "epoch:18 step:14580[D loss: 0.463422, acc: 57.03%, op_acc: 28.91%] [G loss: 0.871418]\n",
      "epoch:18 step:14581[D loss: 0.416238, acc: 60.94%, op_acc: 39.06%] [G loss: 0.937373]\n",
      "epoch:18 step:14582[D loss: 0.414254, acc: 69.53%, op_acc: 33.59%] [G loss: 0.930821]\n",
      "epoch:18 step:14583[D loss: 0.450362, acc: 58.59%, op_acc: 29.69%] [G loss: 0.798373]\n",
      "epoch:18 step:14584[D loss: 0.440671, acc: 60.94%, op_acc: 35.94%] [G loss: 0.899045]\n",
      "epoch:18 step:14585[D loss: 0.447596, acc: 51.56%, op_acc: 39.06%] [G loss: 0.862317]\n",
      "epoch:18 step:14586[D loss: 0.428948, acc: 58.59%, op_acc: 43.75%] [G loss: 0.911315]\n",
      "epoch:18 step:14587[D loss: 0.402849, acc: 66.41%, op_acc: 41.41%] [G loss: 0.893732]\n",
      "epoch:18 step:14588[D loss: 0.433265, acc: 56.25%, op_acc: 37.50%] [G loss: 0.890185]\n",
      "epoch:18 step:14589[D loss: 0.471649, acc: 52.34%, op_acc: 30.47%] [G loss: 0.921637]\n",
      "epoch:18 step:14590[D loss: 0.425708, acc: 63.28%, op_acc: 34.38%] [G loss: 0.876886]\n",
      "epoch:18 step:14591[D loss: 0.453412, acc: 53.12%, op_acc: 39.84%] [G loss: 0.897954]\n",
      "epoch:18 step:14592[D loss: 0.425296, acc: 51.56%, op_acc: 41.41%] [G loss: 0.845089]\n",
      "epoch:18 step:14593[D loss: 0.442101, acc: 52.34%, op_acc: 40.62%] [G loss: 0.894050]\n",
      "epoch:18 step:14594[D loss: 0.407717, acc: 60.16%, op_acc: 41.41%] [G loss: 0.925275]\n",
      "epoch:18 step:14595[D loss: 0.482432, acc: 47.66%, op_acc: 32.03%] [G loss: 0.903225]\n",
      "epoch:18 step:14596[D loss: 0.398087, acc: 65.62%, op_acc: 38.28%] [G loss: 0.909145]\n",
      "epoch:18 step:14597[D loss: 0.423656, acc: 65.62%, op_acc: 35.94%] [G loss: 0.966975]\n",
      "epoch:18 step:14598[D loss: 0.407278, acc: 63.28%, op_acc: 35.16%] [G loss: 0.855849]\n",
      "epoch:18 step:14599[D loss: 0.390471, acc: 70.31%, op_acc: 42.19%] [G loss: 0.986803]\n",
      "epoch:18 step:14600[D loss: 0.432911, acc: 54.69%, op_acc: 38.28%] [G loss: 0.863679]\n",
      "epoch:18 step:14601[D loss: 0.431176, acc: 64.84%, op_acc: 36.72%] [G loss: 0.902263]\n",
      "epoch:18 step:14602[D loss: 0.413269, acc: 64.06%, op_acc: 39.84%] [G loss: 0.930463]\n",
      "epoch:18 step:14603[D loss: 0.403994, acc: 60.16%, op_acc: 37.50%] [G loss: 0.885255]\n",
      "epoch:18 step:14604[D loss: 0.389133, acc: 62.50%, op_acc: 43.75%] [G loss: 0.863917]\n",
      "epoch:18 step:14605[D loss: 0.427546, acc: 64.06%, op_acc: 38.28%] [G loss: 0.885202]\n",
      "epoch:18 step:14606[D loss: 0.425303, acc: 64.84%, op_acc: 38.28%] [G loss: 0.957841]\n",
      "epoch:18 step:14607[D loss: 0.429180, acc: 59.38%, op_acc: 40.62%] [G loss: 0.904290]\n",
      "epoch:18 step:14608[D loss: 0.439178, acc: 57.81%, op_acc: 40.62%] [G loss: 0.867012]\n",
      "epoch:18 step:14609[D loss: 0.412495, acc: 63.28%, op_acc: 39.84%] [G loss: 0.800974]\n",
      "epoch:18 step:14610[D loss: 0.502253, acc: 49.22%, op_acc: 25.00%] [G loss: 0.851619]\n",
      "epoch:18 step:14611[D loss: 0.418233, acc: 64.06%, op_acc: 37.50%] [G loss: 0.856359]\n",
      "epoch:18 step:14612[D loss: 0.427845, acc: 60.94%, op_acc: 39.06%] [G loss: 0.837737]\n",
      "epoch:18 step:14613[D loss: 0.433325, acc: 56.25%, op_acc: 39.84%] [G loss: 0.894189]\n",
      "epoch:18 step:14614[D loss: 0.418777, acc: 56.25%, op_acc: 37.50%] [G loss: 0.846679]\n",
      "epoch:18 step:14615[D loss: 0.434402, acc: 60.94%, op_acc: 30.47%] [G loss: 0.819111]\n",
      "epoch:18 step:14616[D loss: 0.393620, acc: 71.88%, op_acc: 42.19%] [G loss: 0.852065]\n",
      "epoch:18 step:14617[D loss: 0.401495, acc: 62.50%, op_acc: 42.97%] [G loss: 0.863368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14618[D loss: 0.450327, acc: 57.81%, op_acc: 39.06%] [G loss: 0.872440]\n",
      "epoch:18 step:14619[D loss: 0.443056, acc: 56.25%, op_acc: 35.16%] [G loss: 0.942437]\n",
      "epoch:18 step:14620[D loss: 0.460982, acc: 51.56%, op_acc: 35.16%] [G loss: 0.882749]\n",
      "epoch:18 step:14621[D loss: 0.424865, acc: 60.94%, op_acc: 39.84%] [G loss: 0.957982]\n",
      "epoch:18 step:14622[D loss: 0.440131, acc: 53.12%, op_acc: 45.31%] [G loss: 0.861668]\n",
      "epoch:18 step:14623[D loss: 0.403960, acc: 69.53%, op_acc: 34.38%] [G loss: 0.866805]\n",
      "epoch:18 step:14624[D loss: 0.430230, acc: 60.16%, op_acc: 34.38%] [G loss: 0.920018]\n",
      "epoch:18 step:14625[D loss: 0.404074, acc: 62.50%, op_acc: 39.06%] [G loss: 0.973749]\n",
      "epoch:18 step:14626[D loss: 0.409134, acc: 64.84%, op_acc: 40.62%] [G loss: 0.917917]\n",
      "epoch:18 step:14627[D loss: 0.445593, acc: 51.56%, op_acc: 41.41%] [G loss: 0.907038]\n",
      "epoch:18 step:14628[D loss: 0.434783, acc: 59.38%, op_acc: 37.50%] [G loss: 0.876811]\n",
      "epoch:18 step:14629[D loss: 0.421046, acc: 57.03%, op_acc: 39.84%] [G loss: 0.819363]\n",
      "epoch:18 step:14630[D loss: 0.449155, acc: 46.09%, op_acc: 37.50%] [G loss: 0.824550]\n",
      "epoch:18 step:14631[D loss: 0.448422, acc: 57.81%, op_acc: 38.28%] [G loss: 0.898749]\n",
      "epoch:18 step:14632[D loss: 0.449946, acc: 51.56%, op_acc: 33.59%] [G loss: 0.875221]\n",
      "epoch:18 step:14633[D loss: 0.406657, acc: 65.62%, op_acc: 40.62%] [G loss: 0.905409]\n",
      "epoch:18 step:14634[D loss: 0.425360, acc: 58.59%, op_acc: 36.72%] [G loss: 0.821157]\n",
      "epoch:18 step:14635[D loss: 0.447455, acc: 57.03%, op_acc: 33.59%] [G loss: 0.841272]\n",
      "epoch:18 step:14636[D loss: 0.471918, acc: 61.72%, op_acc: 31.25%] [G loss: 0.912418]\n",
      "epoch:18 step:14637[D loss: 0.387859, acc: 67.19%, op_acc: 42.97%] [G loss: 0.912102]\n",
      "epoch:18 step:14638[D loss: 0.423910, acc: 60.16%, op_acc: 38.28%] [G loss: 0.882403]\n",
      "epoch:18 step:14639[D loss: 0.447413, acc: 60.16%, op_acc: 35.16%] [G loss: 0.857894]\n",
      "epoch:18 step:14640[D loss: 0.429373, acc: 58.59%, op_acc: 32.03%] [G loss: 0.858588]\n",
      "epoch:18 step:14641[D loss: 0.433378, acc: 57.03%, op_acc: 39.84%] [G loss: 0.886432]\n",
      "epoch:18 step:14642[D loss: 0.427001, acc: 65.62%, op_acc: 33.59%] [G loss: 0.949611]\n",
      "epoch:18 step:14643[D loss: 0.448575, acc: 57.81%, op_acc: 32.03%] [G loss: 0.928332]\n",
      "epoch:18 step:14644[D loss: 0.416421, acc: 68.75%, op_acc: 37.50%] [G loss: 0.952477]\n",
      "epoch:18 step:14645[D loss: 0.398302, acc: 64.84%, op_acc: 36.72%] [G loss: 0.934731]\n",
      "epoch:18 step:14646[D loss: 0.399181, acc: 66.41%, op_acc: 40.62%] [G loss: 0.889916]\n",
      "epoch:18 step:14647[D loss: 0.444953, acc: 53.91%, op_acc: 35.94%] [G loss: 0.846006]\n",
      "epoch:18 step:14648[D loss: 0.439876, acc: 54.69%, op_acc: 38.28%] [G loss: 0.905609]\n",
      "epoch:18 step:14649[D loss: 0.454991, acc: 47.66%, op_acc: 34.38%] [G loss: 0.892488]\n",
      "epoch:18 step:14650[D loss: 0.458286, acc: 49.22%, op_acc: 40.62%] [G loss: 0.892518]\n",
      "epoch:18 step:14651[D loss: 0.465883, acc: 53.91%, op_acc: 29.69%] [G loss: 0.932677]\n",
      "epoch:18 step:14652[D loss: 0.448538, acc: 55.47%, op_acc: 41.41%] [G loss: 0.879502]\n",
      "epoch:18 step:14653[D loss: 0.407890, acc: 60.16%, op_acc: 39.06%] [G loss: 0.963681]\n",
      "epoch:18 step:14654[D loss: 0.438731, acc: 54.69%, op_acc: 35.94%] [G loss: 0.921509]\n",
      "epoch:18 step:14655[D loss: 0.418736, acc: 63.28%, op_acc: 36.72%] [G loss: 0.926753]\n",
      "epoch:18 step:14656[D loss: 0.401219, acc: 67.19%, op_acc: 38.28%] [G loss: 0.881567]\n",
      "epoch:18 step:14657[D loss: 0.417948, acc: 68.75%, op_acc: 35.94%] [G loss: 0.964015]\n",
      "epoch:18 step:14658[D loss: 0.418956, acc: 57.81%, op_acc: 35.16%] [G loss: 0.958417]\n",
      "epoch:18 step:14659[D loss: 0.449140, acc: 54.69%, op_acc: 34.38%] [G loss: 0.856215]\n",
      "epoch:18 step:14660[D loss: 0.392013, acc: 61.72%, op_acc: 42.97%] [G loss: 1.002362]\n",
      "epoch:18 step:14661[D loss: 0.400598, acc: 58.59%, op_acc: 41.41%] [G loss: 0.942306]\n",
      "epoch:18 step:14662[D loss: 0.456036, acc: 65.62%, op_acc: 34.38%] [G loss: 0.921328]\n",
      "epoch:18 step:14663[D loss: 0.430053, acc: 57.03%, op_acc: 37.50%] [G loss: 0.786327]\n",
      "epoch:18 step:14664[D loss: 0.447625, acc: 48.44%, op_acc: 39.06%] [G loss: 0.769654]\n",
      "epoch:18 step:14665[D loss: 0.463784, acc: 47.66%, op_acc: 35.94%] [G loss: 0.801637]\n",
      "epoch:18 step:14666[D loss: 0.396091, acc: 60.16%, op_acc: 42.19%] [G loss: 0.876692]\n",
      "epoch:18 step:14667[D loss: 0.447685, acc: 56.25%, op_acc: 37.50%] [G loss: 0.906367]\n",
      "epoch:18 step:14668[D loss: 0.411242, acc: 68.75%, op_acc: 37.50%] [G loss: 0.924389]\n",
      "epoch:18 step:14669[D loss: 0.446378, acc: 51.56%, op_acc: 38.28%] [G loss: 0.940973]\n",
      "epoch:18 step:14670[D loss: 0.416923, acc: 64.06%, op_acc: 36.72%] [G loss: 0.903244]\n",
      "epoch:18 step:14671[D loss: 0.463672, acc: 46.88%, op_acc: 37.50%] [G loss: 0.778291]\n",
      "epoch:18 step:14672[D loss: 0.412804, acc: 53.12%, op_acc: 42.97%] [G loss: 0.863359]\n",
      "epoch:18 step:14673[D loss: 0.432061, acc: 65.62%, op_acc: 39.84%] [G loss: 0.926591]\n",
      "epoch:18 step:14674[D loss: 0.476168, acc: 48.44%, op_acc: 39.84%] [G loss: 0.853305]\n",
      "epoch:18 step:14675[D loss: 0.452444, acc: 56.25%, op_acc: 32.81%] [G loss: 0.773419]\n",
      "epoch:18 step:14676[D loss: 0.424813, acc: 59.38%, op_acc: 38.28%] [G loss: 0.855164]\n",
      "epoch:18 step:14677[D loss: 0.446165, acc: 60.94%, op_acc: 37.50%] [G loss: 0.836656]\n",
      "epoch:18 step:14678[D loss: 0.423723, acc: 60.94%, op_acc: 40.62%] [G loss: 0.846825]\n",
      "epoch:18 step:14679[D loss: 0.411913, acc: 57.81%, op_acc: 35.16%] [G loss: 0.911986]\n",
      "epoch:18 step:14680[D loss: 0.452581, acc: 57.81%, op_acc: 39.06%] [G loss: 0.885100]\n",
      "epoch:18 step:14681[D loss: 0.427778, acc: 56.25%, op_acc: 40.62%] [G loss: 0.943809]\n",
      "epoch:18 step:14682[D loss: 0.434796, acc: 50.78%, op_acc: 48.44%] [G loss: 0.882846]\n",
      "epoch:18 step:14683[D loss: 0.441126, acc: 55.47%, op_acc: 39.06%] [G loss: 0.913449]\n",
      "epoch:18 step:14684[D loss: 0.407403, acc: 66.41%, op_acc: 40.62%] [G loss: 0.870840]\n",
      "epoch:18 step:14685[D loss: 0.415769, acc: 65.62%, op_acc: 40.62%] [G loss: 0.832125]\n",
      "epoch:18 step:14686[D loss: 0.442936, acc: 55.47%, op_acc: 37.50%] [G loss: 0.879115]\n",
      "epoch:18 step:14687[D loss: 0.439894, acc: 55.47%, op_acc: 31.25%] [G loss: 0.938437]\n",
      "epoch:18 step:14688[D loss: 0.395402, acc: 64.84%, op_acc: 42.97%] [G loss: 0.906258]\n",
      "epoch:18 step:14689[D loss: 0.441910, acc: 55.47%, op_acc: 37.50%] [G loss: 0.906666]\n",
      "epoch:18 step:14690[D loss: 0.463679, acc: 57.03%, op_acc: 32.03%] [G loss: 0.823659]\n",
      "epoch:18 step:14691[D loss: 0.424419, acc: 60.16%, op_acc: 38.28%] [G loss: 0.928393]\n",
      "epoch:18 step:14692[D loss: 0.426505, acc: 61.72%, op_acc: 40.62%] [G loss: 0.945563]\n",
      "epoch:18 step:14693[D loss: 0.445539, acc: 53.91%, op_acc: 39.84%] [G loss: 0.941962]\n",
      "epoch:18 step:14694[D loss: 0.419011, acc: 60.94%, op_acc: 37.50%] [G loss: 0.893284]\n",
      "epoch:18 step:14695[D loss: 0.407223, acc: 65.62%, op_acc: 40.62%] [G loss: 0.963291]\n",
      "epoch:18 step:14696[D loss: 0.461373, acc: 54.69%, op_acc: 32.03%] [G loss: 0.907576]\n",
      "epoch:18 step:14697[D loss: 0.483394, acc: 46.88%, op_acc: 34.38%] [G loss: 0.873508]\n",
      "epoch:18 step:14698[D loss: 0.455202, acc: 55.47%, op_acc: 31.25%] [G loss: 0.831848]\n",
      "epoch:18 step:14699[D loss: 0.407854, acc: 67.19%, op_acc: 40.62%] [G loss: 0.870544]\n",
      "epoch:18 step:14700[D loss: 0.430919, acc: 58.59%, op_acc: 40.62%] [G loss: 0.890168]\n",
      "epoch:18 step:14701[D loss: 0.472735, acc: 53.12%, op_acc: 29.69%] [G loss: 0.856911]\n",
      "epoch:18 step:14702[D loss: 0.415787, acc: 55.47%, op_acc: 47.66%] [G loss: 0.781825]\n",
      "epoch:18 step:14703[D loss: 0.403173, acc: 65.62%, op_acc: 44.53%] [G loss: 0.900545]\n",
      "epoch:18 step:14704[D loss: 0.439881, acc: 56.25%, op_acc: 39.06%] [G loss: 0.906452]\n",
      "epoch:18 step:14705[D loss: 0.427302, acc: 64.06%, op_acc: 34.38%] [G loss: 0.913540]\n",
      "epoch:18 step:14706[D loss: 0.414962, acc: 67.97%, op_acc: 35.94%] [G loss: 0.917031]\n",
      "epoch:18 step:14707[D loss: 0.458571, acc: 46.09%, op_acc: 36.72%] [G loss: 0.840921]\n",
      "epoch:18 step:14708[D loss: 0.431094, acc: 67.19%, op_acc: 36.72%] [G loss: 0.860175]\n",
      "epoch:18 step:14709[D loss: 0.434445, acc: 55.47%, op_acc: 41.41%] [G loss: 0.837523]\n",
      "epoch:18 step:14710[D loss: 0.442776, acc: 50.78%, op_acc: 39.84%] [G loss: 0.817873]\n",
      "epoch:18 step:14711[D loss: 0.416872, acc: 61.72%, op_acc: 40.62%] [G loss: 0.861064]\n",
      "epoch:18 step:14712[D loss: 0.435929, acc: 60.94%, op_acc: 38.28%] [G loss: 0.887486]\n",
      "epoch:18 step:14713[D loss: 0.403846, acc: 68.75%, op_acc: 40.62%] [G loss: 0.879417]\n",
      "epoch:18 step:14714[D loss: 0.457232, acc: 52.34%, op_acc: 35.94%] [G loss: 0.798683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14715[D loss: 0.453536, acc: 49.22%, op_acc: 39.06%] [G loss: 0.806047]\n",
      "epoch:18 step:14716[D loss: 0.391582, acc: 69.53%, op_acc: 45.31%] [G loss: 0.944685]\n",
      "epoch:18 step:14717[D loss: 0.457440, acc: 57.81%, op_acc: 33.59%] [G loss: 0.887928]\n",
      "epoch:18 step:14718[D loss: 0.410031, acc: 61.72%, op_acc: 42.97%] [G loss: 0.885665]\n",
      "epoch:18 step:14719[D loss: 0.426487, acc: 58.59%, op_acc: 40.62%] [G loss: 0.932705]\n",
      "epoch:18 step:14720[D loss: 0.399307, acc: 66.41%, op_acc: 40.62%] [G loss: 0.896973]\n",
      "epoch:18 step:14721[D loss: 0.424915, acc: 60.16%, op_acc: 39.84%] [G loss: 0.903831]\n",
      "epoch:18 step:14722[D loss: 0.436314, acc: 53.91%, op_acc: 38.28%] [G loss: 0.888130]\n",
      "epoch:18 step:14723[D loss: 0.465241, acc: 55.47%, op_acc: 35.94%] [G loss: 0.889237]\n",
      "epoch:18 step:14724[D loss: 0.426427, acc: 60.94%, op_acc: 36.72%] [G loss: 0.868705]\n",
      "epoch:18 step:14725[D loss: 0.421473, acc: 57.03%, op_acc: 35.94%] [G loss: 0.921848]\n",
      "epoch:18 step:14726[D loss: 0.419642, acc: 57.03%, op_acc: 43.75%] [G loss: 0.947460]\n",
      "epoch:18 step:14727[D loss: 0.431538, acc: 58.59%, op_acc: 36.72%] [G loss: 0.883077]\n",
      "epoch:18 step:14728[D loss: 0.439569, acc: 50.78%, op_acc: 40.62%] [G loss: 0.874767]\n",
      "epoch:18 step:14729[D loss: 0.417013, acc: 61.72%, op_acc: 39.84%] [G loss: 0.902066]\n",
      "epoch:18 step:14730[D loss: 0.435224, acc: 57.81%, op_acc: 38.28%] [G loss: 0.847558]\n",
      "epoch:18 step:14731[D loss: 0.439910, acc: 58.59%, op_acc: 33.59%] [G loss: 0.842685]\n",
      "epoch:18 step:14732[D loss: 0.408001, acc: 61.72%, op_acc: 46.88%] [G loss: 0.846736]\n",
      "epoch:18 step:14733[D loss: 0.431592, acc: 61.72%, op_acc: 37.50%] [G loss: 0.810681]\n",
      "epoch:18 step:14734[D loss: 0.456784, acc: 53.91%, op_acc: 36.72%] [G loss: 0.958574]\n",
      "epoch:18 step:14735[D loss: 0.457746, acc: 52.34%, op_acc: 35.16%] [G loss: 0.818951]\n",
      "epoch:18 step:14736[D loss: 0.402715, acc: 67.19%, op_acc: 42.19%] [G loss: 0.903478]\n",
      "epoch:18 step:14737[D loss: 0.413500, acc: 57.81%, op_acc: 45.31%] [G loss: 0.892093]\n",
      "epoch:18 step:14738[D loss: 0.451132, acc: 57.03%, op_acc: 36.72%] [G loss: 0.896013]\n",
      "epoch:18 step:14739[D loss: 0.460315, acc: 50.78%, op_acc: 32.81%] [G loss: 0.877978]\n",
      "epoch:18 step:14740[D loss: 0.433511, acc: 57.03%, op_acc: 36.72%] [G loss: 0.939932]\n",
      "epoch:18 step:14741[D loss: 0.424916, acc: 57.03%, op_acc: 40.62%] [G loss: 0.881843]\n",
      "epoch:18 step:14742[D loss: 0.429630, acc: 66.41%, op_acc: 32.03%] [G loss: 0.922688]\n",
      "epoch:18 step:14743[D loss: 0.441858, acc: 59.38%, op_acc: 38.28%] [G loss: 0.891315]\n",
      "epoch:18 step:14744[D loss: 0.429607, acc: 62.50%, op_acc: 31.25%] [G loss: 0.858764]\n",
      "epoch:18 step:14745[D loss: 0.426293, acc: 60.16%, op_acc: 33.59%] [G loss: 0.857922]\n",
      "epoch:18 step:14746[D loss: 0.383041, acc: 68.75%, op_acc: 45.31%] [G loss: 0.865475]\n",
      "epoch:18 step:14747[D loss: 0.438432, acc: 52.34%, op_acc: 44.53%] [G loss: 0.854085]\n",
      "epoch:18 step:14748[D loss: 0.432831, acc: 57.81%, op_acc: 37.50%] [G loss: 0.882715]\n",
      "epoch:18 step:14749[D loss: 0.433276, acc: 62.50%, op_acc: 35.16%] [G loss: 0.986864]\n",
      "epoch:18 step:14750[D loss: 0.440768, acc: 63.28%, op_acc: 29.69%] [G loss: 0.880160]\n",
      "epoch:18 step:14751[D loss: 0.417888, acc: 61.72%, op_acc: 39.06%] [G loss: 0.875097]\n",
      "epoch:18 step:14752[D loss: 0.444504, acc: 57.03%, op_acc: 39.06%] [G loss: 0.894711]\n",
      "epoch:18 step:14753[D loss: 0.434251, acc: 54.69%, op_acc: 39.84%] [G loss: 0.894202]\n",
      "epoch:18 step:14754[D loss: 0.422404, acc: 62.50%, op_acc: 36.72%] [G loss: 0.880125]\n",
      "epoch:18 step:14755[D loss: 0.432477, acc: 59.38%, op_acc: 41.41%] [G loss: 0.838111]\n",
      "epoch:18 step:14756[D loss: 0.453764, acc: 53.12%, op_acc: 39.06%] [G loss: 0.837710]\n",
      "epoch:18 step:14757[D loss: 0.409323, acc: 60.16%, op_acc: 39.84%] [G loss: 0.873734]\n",
      "epoch:18 step:14758[D loss: 0.412901, acc: 67.19%, op_acc: 40.62%] [G loss: 0.923170]\n",
      "epoch:18 step:14759[D loss: 0.441078, acc: 62.50%, op_acc: 35.16%] [G loss: 0.887125]\n",
      "epoch:18 step:14760[D loss: 0.420597, acc: 64.06%, op_acc: 38.28%] [G loss: 0.829757]\n",
      "epoch:18 step:14761[D loss: 0.424145, acc: 62.50%, op_acc: 34.38%] [G loss: 0.841976]\n",
      "epoch:18 step:14762[D loss: 0.398063, acc: 53.91%, op_acc: 44.53%] [G loss: 0.860687]\n",
      "epoch:18 step:14763[D loss: 0.417148, acc: 64.84%, op_acc: 35.16%] [G loss: 0.931100]\n",
      "epoch:18 step:14764[D loss: 0.426219, acc: 60.16%, op_acc: 43.75%] [G loss: 0.859204]\n",
      "epoch:18 step:14765[D loss: 0.467539, acc: 55.47%, op_acc: 35.16%] [G loss: 0.859752]\n",
      "epoch:18 step:14766[D loss: 0.447189, acc: 53.12%, op_acc: 37.50%] [G loss: 0.851705]\n",
      "epoch:18 step:14767[D loss: 0.430754, acc: 61.72%, op_acc: 35.16%] [G loss: 0.877767]\n",
      "epoch:18 step:14768[D loss: 0.417205, acc: 60.94%, op_acc: 37.50%] [G loss: 0.891025]\n",
      "epoch:18 step:14769[D loss: 0.415177, acc: 62.50%, op_acc: 34.38%] [G loss: 0.826263]\n",
      "epoch:18 step:14770[D loss: 0.411427, acc: 60.94%, op_acc: 46.09%] [G loss: 0.887721]\n",
      "epoch:18 step:14771[D loss: 0.386238, acc: 66.41%, op_acc: 46.09%] [G loss: 0.874029]\n",
      "epoch:18 step:14772[D loss: 0.413004, acc: 67.97%, op_acc: 38.28%] [G loss: 0.872135]\n",
      "epoch:18 step:14773[D loss: 0.408577, acc: 62.50%, op_acc: 39.84%] [G loss: 0.907147]\n",
      "epoch:18 step:14774[D loss: 0.418795, acc: 55.47%, op_acc: 37.50%] [G loss: 0.867822]\n",
      "epoch:18 step:14775[D loss: 0.421873, acc: 59.38%, op_acc: 41.41%] [G loss: 0.866545]\n",
      "epoch:18 step:14776[D loss: 0.431299, acc: 61.72%, op_acc: 38.28%] [G loss: 0.889484]\n",
      "epoch:18 step:14777[D loss: 0.409978, acc: 61.72%, op_acc: 42.19%] [G loss: 0.870431]\n",
      "epoch:18 step:14778[D loss: 0.425247, acc: 66.41%, op_acc: 39.06%] [G loss: 0.786802]\n",
      "epoch:18 step:14779[D loss: 0.432941, acc: 49.22%, op_acc: 37.50%] [G loss: 0.926704]\n",
      "epoch:18 step:14780[D loss: 0.419617, acc: 60.16%, op_acc: 42.97%] [G loss: 0.915429]\n",
      "epoch:18 step:14781[D loss: 0.419080, acc: 53.91%, op_acc: 43.75%] [G loss: 0.861590]\n",
      "epoch:18 step:14782[D loss: 0.457033, acc: 56.25%, op_acc: 32.81%] [G loss: 0.869452]\n",
      "epoch:18 step:14783[D loss: 0.407783, acc: 60.94%, op_acc: 44.53%] [G loss: 0.958092]\n",
      "epoch:18 step:14784[D loss: 0.414387, acc: 60.16%, op_acc: 42.19%] [G loss: 0.886940]\n",
      "epoch:18 step:14785[D loss: 0.471656, acc: 48.44%, op_acc: 32.03%] [G loss: 0.751327]\n",
      "epoch:18 step:14786[D loss: 0.470338, acc: 51.56%, op_acc: 35.94%] [G loss: 0.874497]\n",
      "epoch:18 step:14787[D loss: 0.411072, acc: 63.28%, op_acc: 39.06%] [G loss: 0.806568]\n",
      "epoch:18 step:14788[D loss: 0.440376, acc: 57.03%, op_acc: 36.72%] [G loss: 0.815403]\n",
      "epoch:18 step:14789[D loss: 0.404645, acc: 61.72%, op_acc: 45.31%] [G loss: 0.851773]\n",
      "epoch:18 step:14790[D loss: 0.430481, acc: 55.47%, op_acc: 41.41%] [G loss: 0.854836]\n",
      "epoch:18 step:14791[D loss: 0.444668, acc: 53.12%, op_acc: 37.50%] [G loss: 0.816816]\n",
      "epoch:18 step:14792[D loss: 0.443843, acc: 54.69%, op_acc: 34.38%] [G loss: 0.854937]\n",
      "epoch:18 step:14793[D loss: 0.448353, acc: 56.25%, op_acc: 39.06%] [G loss: 0.905454]\n",
      "epoch:18 step:14794[D loss: 0.431353, acc: 57.81%, op_acc: 36.72%] [G loss: 0.897866]\n",
      "epoch:18 step:14795[D loss: 0.422593, acc: 57.81%, op_acc: 36.72%] [G loss: 0.891639]\n",
      "epoch:18 step:14796[D loss: 0.423776, acc: 60.94%, op_acc: 35.94%] [G loss: 0.902330]\n",
      "epoch:18 step:14797[D loss: 0.422903, acc: 55.47%, op_acc: 39.84%] [G loss: 0.896915]\n",
      "epoch:18 step:14798[D loss: 0.472353, acc: 45.31%, op_acc: 38.28%] [G loss: 0.824111]\n",
      "epoch:18 step:14799[D loss: 0.445130, acc: 57.03%, op_acc: 37.50%] [G loss: 0.858752]\n",
      "epoch:18 step:14800[D loss: 0.428324, acc: 56.25%, op_acc: 39.84%] [G loss: 0.842007]\n",
      "epoch:18 step:14801[D loss: 0.440966, acc: 54.69%, op_acc: 32.81%] [G loss: 0.848018]\n",
      "epoch:18 step:14802[D loss: 0.428359, acc: 53.91%, op_acc: 35.94%] [G loss: 0.928241]\n",
      "epoch:18 step:14803[D loss: 0.442148, acc: 61.72%, op_acc: 34.38%] [G loss: 0.850250]\n",
      "epoch:18 step:14804[D loss: 0.434264, acc: 54.69%, op_acc: 36.72%] [G loss: 0.830560]\n",
      "epoch:18 step:14805[D loss: 0.449369, acc: 51.56%, op_acc: 39.06%] [G loss: 0.861590]\n",
      "epoch:18 step:14806[D loss: 0.428851, acc: 55.47%, op_acc: 36.72%] [G loss: 0.823874]\n",
      "epoch:18 step:14807[D loss: 0.435740, acc: 50.00%, op_acc: 42.97%] [G loss: 0.763359]\n",
      "epoch:18 step:14808[D loss: 0.420698, acc: 53.12%, op_acc: 47.66%] [G loss: 0.829829]\n",
      "epoch:18 step:14809[D loss: 0.459070, acc: 61.72%, op_acc: 31.25%] [G loss: 0.831658]\n",
      "epoch:18 step:14810[D loss: 0.442054, acc: 54.69%, op_acc: 35.94%] [G loss: 0.868169]\n",
      "epoch:18 step:14811[D loss: 0.425205, acc: 62.50%, op_acc: 39.06%] [G loss: 0.871561]\n",
      "epoch:18 step:14812[D loss: 0.421891, acc: 57.81%, op_acc: 39.06%] [G loss: 0.881775]\n",
      "epoch:18 step:14813[D loss: 0.418594, acc: 64.06%, op_acc: 40.62%] [G loss: 0.864359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:14814[D loss: 0.451802, acc: 49.22%, op_acc: 41.41%] [G loss: 0.810884]\n",
      "epoch:18 step:14815[D loss: 0.412694, acc: 64.84%, op_acc: 40.62%] [G loss: 0.863213]\n",
      "epoch:18 step:14816[D loss: 0.390536, acc: 67.97%, op_acc: 51.56%] [G loss: 0.920640]\n",
      "epoch:18 step:14817[D loss: 0.421524, acc: 67.97%, op_acc: 37.50%] [G loss: 0.875107]\n",
      "epoch:18 step:14818[D loss: 0.417818, acc: 61.72%, op_acc: 35.94%] [G loss: 0.816632]\n",
      "epoch:18 step:14819[D loss: 0.433027, acc: 54.69%, op_acc: 40.62%] [G loss: 0.855084]\n",
      "epoch:18 step:14820[D loss: 0.412551, acc: 61.72%, op_acc: 39.06%] [G loss: 0.784335]\n",
      "epoch:18 step:14821[D loss: 0.449509, acc: 52.34%, op_acc: 34.38%] [G loss: 0.750593]\n",
      "epoch:18 step:14822[D loss: 0.408575, acc: 62.50%, op_acc: 39.06%] [G loss: 0.866907]\n",
      "epoch:18 step:14823[D loss: 0.399292, acc: 69.53%, op_acc: 42.19%] [G loss: 0.873574]\n",
      "epoch:18 step:14824[D loss: 0.463393, acc: 52.34%, op_acc: 38.28%] [G loss: 0.879948]\n",
      "epoch:18 step:14825[D loss: 0.425296, acc: 54.69%, op_acc: 40.62%] [G loss: 0.845234]\n",
      "epoch:18 step:14826[D loss: 0.426795, acc: 64.84%, op_acc: 39.06%] [G loss: 0.899361]\n",
      "epoch:18 step:14827[D loss: 0.428057, acc: 55.47%, op_acc: 41.41%] [G loss: 0.850391]\n",
      "epoch:18 step:14828[D loss: 0.434266, acc: 61.72%, op_acc: 38.28%] [G loss: 0.875346]\n",
      "epoch:18 step:14829[D loss: 0.467825, acc: 59.38%, op_acc: 36.72%] [G loss: 0.845858]\n",
      "epoch:18 step:14830[D loss: 0.438880, acc: 66.41%, op_acc: 35.94%] [G loss: 0.848024]\n",
      "epoch:18 step:14831[D loss: 0.435172, acc: 60.16%, op_acc: 38.28%] [G loss: 0.884034]\n",
      "epoch:18 step:14832[D loss: 0.402204, acc: 60.16%, op_acc: 40.62%] [G loss: 0.911531]\n",
      "epoch:18 step:14833[D loss: 0.432470, acc: 63.28%, op_acc: 33.59%] [G loss: 0.934512]\n",
      "epoch:18 step:14834[D loss: 0.406581, acc: 61.72%, op_acc: 37.50%] [G loss: 0.923704]\n",
      "epoch:18 step:14835[D loss: 0.454159, acc: 60.94%, op_acc: 35.16%] [G loss: 0.944446]\n",
      "epoch:18 step:14836[D loss: 0.409485, acc: 60.16%, op_acc: 44.53%] [G loss: 0.938607]\n",
      "epoch:18 step:14837[D loss: 0.423660, acc: 62.50%, op_acc: 35.16%] [G loss: 0.928486]\n",
      "epoch:18 step:14838[D loss: 0.446008, acc: 57.03%, op_acc: 37.50%] [G loss: 0.849623]\n",
      "epoch:18 step:14839[D loss: 0.455395, acc: 52.34%, op_acc: 37.50%] [G loss: 0.973242]\n",
      "epoch:19 step:14840[D loss: 0.397544, acc: 66.41%, op_acc: 38.28%] [G loss: 0.930897]\n",
      "epoch:19 step:14841[D loss: 0.391049, acc: 61.72%, op_acc: 41.41%] [G loss: 0.926081]\n",
      "epoch:19 step:14842[D loss: 0.445342, acc: 50.00%, op_acc: 36.72%] [G loss: 0.906469]\n",
      "epoch:19 step:14843[D loss: 0.410577, acc: 53.12%, op_acc: 42.19%] [G loss: 0.896721]\n",
      "epoch:19 step:14844[D loss: 0.434338, acc: 59.38%, op_acc: 38.28%] [G loss: 0.951036]\n",
      "epoch:19 step:14845[D loss: 0.462132, acc: 59.38%, op_acc: 37.50%] [G loss: 0.903195]\n",
      "epoch:19 step:14846[D loss: 0.420200, acc: 55.47%, op_acc: 37.50%] [G loss: 0.850973]\n",
      "epoch:19 step:14847[D loss: 0.428644, acc: 57.03%, op_acc: 36.72%] [G loss: 0.855449]\n",
      "epoch:19 step:14848[D loss: 0.392623, acc: 67.19%, op_acc: 42.97%] [G loss: 0.856350]\n",
      "epoch:19 step:14849[D loss: 0.432916, acc: 55.47%, op_acc: 33.59%] [G loss: 0.904021]\n",
      "epoch:19 step:14850[D loss: 0.442012, acc: 60.16%, op_acc: 34.38%] [G loss: 0.924882]\n",
      "epoch:19 step:14851[D loss: 0.446814, acc: 55.47%, op_acc: 35.16%] [G loss: 0.884483]\n",
      "epoch:19 step:14852[D loss: 0.429398, acc: 64.06%, op_acc: 36.72%] [G loss: 0.878830]\n",
      "epoch:19 step:14853[D loss: 0.430064, acc: 63.28%, op_acc: 30.47%] [G loss: 0.865074]\n",
      "epoch:19 step:14854[D loss: 0.407470, acc: 62.50%, op_acc: 39.84%] [G loss: 0.922591]\n",
      "epoch:19 step:14855[D loss: 0.459495, acc: 49.22%, op_acc: 36.72%] [G loss: 0.900766]\n",
      "epoch:19 step:14856[D loss: 0.409660, acc: 64.06%, op_acc: 44.53%] [G loss: 0.871936]\n",
      "epoch:19 step:14857[D loss: 0.428621, acc: 59.38%, op_acc: 39.06%] [G loss: 0.957335]\n",
      "epoch:19 step:14858[D loss: 0.438648, acc: 56.25%, op_acc: 39.06%] [G loss: 0.860773]\n",
      "epoch:19 step:14859[D loss: 0.405497, acc: 59.38%, op_acc: 42.19%] [G loss: 0.890241]\n",
      "epoch:19 step:14860[D loss: 0.455272, acc: 60.16%, op_acc: 33.59%] [G loss: 0.863845]\n",
      "epoch:19 step:14861[D loss: 0.447388, acc: 54.69%, op_acc: 41.41%] [G loss: 0.901074]\n",
      "epoch:19 step:14862[D loss: 0.422831, acc: 67.19%, op_acc: 39.84%] [G loss: 0.893728]\n",
      "epoch:19 step:14863[D loss: 0.430630, acc: 59.38%, op_acc: 38.28%] [G loss: 0.978048]\n",
      "epoch:19 step:14864[D loss: 0.457724, acc: 49.22%, op_acc: 38.28%] [G loss: 0.816336]\n",
      "epoch:19 step:14865[D loss: 0.414162, acc: 61.72%, op_acc: 39.06%] [G loss: 0.889313]\n",
      "epoch:19 step:14866[D loss: 0.458925, acc: 51.56%, op_acc: 39.84%] [G loss: 0.846898]\n",
      "epoch:19 step:14867[D loss: 0.446391, acc: 54.69%, op_acc: 43.75%] [G loss: 0.882236]\n",
      "epoch:19 step:14868[D loss: 0.418855, acc: 60.94%, op_acc: 38.28%] [G loss: 1.019534]\n",
      "epoch:19 step:14869[D loss: 0.401035, acc: 61.72%, op_acc: 42.19%] [G loss: 0.919042]\n",
      "epoch:19 step:14870[D loss: 0.455485, acc: 54.69%, op_acc: 36.72%] [G loss: 0.891102]\n",
      "epoch:19 step:14871[D loss: 0.452189, acc: 50.78%, op_acc: 35.94%] [G loss: 0.838841]\n",
      "epoch:19 step:14872[D loss: 0.435713, acc: 56.25%, op_acc: 39.06%] [G loss: 0.862780]\n",
      "epoch:19 step:14873[D loss: 0.416008, acc: 58.59%, op_acc: 41.41%] [G loss: 0.831052]\n",
      "epoch:19 step:14874[D loss: 0.423950, acc: 67.19%, op_acc: 38.28%] [G loss: 0.909358]\n",
      "epoch:19 step:14875[D loss: 0.443459, acc: 53.12%, op_acc: 44.53%] [G loss: 0.876487]\n",
      "epoch:19 step:14876[D loss: 0.418273, acc: 63.28%, op_acc: 42.19%] [G loss: 0.841504]\n",
      "epoch:19 step:14877[D loss: 0.445228, acc: 50.00%, op_acc: 39.84%] [G loss: 0.852541]\n",
      "epoch:19 step:14878[D loss: 0.414647, acc: 61.72%, op_acc: 36.72%] [G loss: 0.824652]\n",
      "epoch:19 step:14879[D loss: 0.439618, acc: 55.47%, op_acc: 32.03%] [G loss: 0.925704]\n",
      "epoch:19 step:14880[D loss: 0.402534, acc: 67.19%, op_acc: 41.41%] [G loss: 0.864548]\n",
      "epoch:19 step:14881[D loss: 0.399946, acc: 61.72%, op_acc: 43.75%] [G loss: 0.956533]\n",
      "epoch:19 step:14882[D loss: 0.469485, acc: 53.12%, op_acc: 33.59%] [G loss: 0.849759]\n",
      "epoch:19 step:14883[D loss: 0.405686, acc: 64.06%, op_acc: 40.62%] [G loss: 0.821702]\n",
      "epoch:19 step:14884[D loss: 0.393503, acc: 69.53%, op_acc: 38.28%] [G loss: 0.886629]\n",
      "epoch:19 step:14885[D loss: 0.409512, acc: 58.59%, op_acc: 35.16%] [G loss: 0.843718]\n",
      "epoch:19 step:14886[D loss: 0.438794, acc: 60.16%, op_acc: 32.81%] [G loss: 0.855094]\n",
      "epoch:19 step:14887[D loss: 0.445775, acc: 61.72%, op_acc: 32.03%] [G loss: 0.877106]\n",
      "epoch:19 step:14888[D loss: 0.402865, acc: 62.50%, op_acc: 39.06%] [G loss: 0.939883]\n",
      "epoch:19 step:14889[D loss: 0.446602, acc: 53.12%, op_acc: 42.97%] [G loss: 0.836345]\n",
      "epoch:19 step:14890[D loss: 0.396923, acc: 62.50%, op_acc: 45.31%] [G loss: 0.921507]\n",
      "epoch:19 step:14891[D loss: 0.415353, acc: 61.72%, op_acc: 38.28%] [G loss: 0.845833]\n",
      "epoch:19 step:14892[D loss: 0.469480, acc: 53.12%, op_acc: 28.91%] [G loss: 0.922777]\n",
      "epoch:19 step:14893[D loss: 0.464215, acc: 54.69%, op_acc: 35.94%] [G loss: 0.844574]\n",
      "epoch:19 step:14894[D loss: 0.422494, acc: 57.03%, op_acc: 40.62%] [G loss: 0.871517]\n",
      "epoch:19 step:14895[D loss: 0.440978, acc: 48.44%, op_acc: 39.06%] [G loss: 0.880098]\n",
      "epoch:19 step:14896[D loss: 0.432116, acc: 61.72%, op_acc: 39.06%] [G loss: 0.894850]\n",
      "epoch:19 step:14897[D loss: 0.417805, acc: 64.84%, op_acc: 41.41%] [G loss: 0.886774]\n",
      "epoch:19 step:14898[D loss: 0.422519, acc: 60.94%, op_acc: 36.72%] [G loss: 0.869820]\n",
      "epoch:19 step:14899[D loss: 0.423285, acc: 65.62%, op_acc: 36.72%] [G loss: 0.834892]\n",
      "epoch:19 step:14900[D loss: 0.415575, acc: 61.72%, op_acc: 38.28%] [G loss: 0.853446]\n",
      "epoch:19 step:14901[D loss: 0.426699, acc: 59.38%, op_acc: 39.06%] [G loss: 0.894415]\n",
      "epoch:19 step:14902[D loss: 0.453678, acc: 57.81%, op_acc: 34.38%] [G loss: 0.890989]\n",
      "epoch:19 step:14903[D loss: 0.431965, acc: 53.12%, op_acc: 38.28%] [G loss: 0.853350]\n",
      "epoch:19 step:14904[D loss: 0.445517, acc: 53.91%, op_acc: 41.41%] [G loss: 0.847299]\n",
      "epoch:19 step:14905[D loss: 0.427735, acc: 62.50%, op_acc: 35.94%] [G loss: 0.843960]\n",
      "epoch:19 step:14906[D loss: 0.418759, acc: 67.97%, op_acc: 39.84%] [G loss: 0.954748]\n",
      "epoch:19 step:14907[D loss: 0.440251, acc: 54.69%, op_acc: 39.06%] [G loss: 0.868752]\n",
      "epoch:19 step:14908[D loss: 0.398988, acc: 64.84%, op_acc: 42.97%] [G loss: 0.983796]\n",
      "epoch:19 step:14909[D loss: 0.429180, acc: 59.38%, op_acc: 39.06%] [G loss: 0.943767]\n",
      "epoch:19 step:14910[D loss: 0.462516, acc: 53.12%, op_acc: 32.03%] [G loss: 0.871503]\n",
      "epoch:19 step:14911[D loss: 0.410567, acc: 65.62%, op_acc: 37.50%] [G loss: 0.868124]\n",
      "epoch:19 step:14912[D loss: 0.436780, acc: 58.59%, op_acc: 37.50%] [G loss: 0.886960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:14913[D loss: 0.415435, acc: 64.06%, op_acc: 40.62%] [G loss: 0.819486]\n",
      "epoch:19 step:14914[D loss: 0.402326, acc: 66.41%, op_acc: 42.19%] [G loss: 0.949093]\n",
      "epoch:19 step:14915[D loss: 0.437299, acc: 61.72%, op_acc: 39.06%] [G loss: 0.940656]\n",
      "epoch:19 step:14916[D loss: 0.416788, acc: 57.81%, op_acc: 39.84%] [G loss: 0.893861]\n",
      "epoch:19 step:14917[D loss: 0.429176, acc: 59.38%, op_acc: 32.81%] [G loss: 0.911515]\n",
      "epoch:19 step:14918[D loss: 0.408694, acc: 62.50%, op_acc: 40.62%] [G loss: 0.858012]\n",
      "epoch:19 step:14919[D loss: 0.455680, acc: 53.91%, op_acc: 33.59%] [G loss: 0.876633]\n",
      "epoch:19 step:14920[D loss: 0.439979, acc: 59.38%, op_acc: 34.38%] [G loss: 0.849918]\n",
      "epoch:19 step:14921[D loss: 0.429953, acc: 53.91%, op_acc: 39.06%] [G loss: 0.815458]\n",
      "epoch:19 step:14922[D loss: 0.458716, acc: 53.91%, op_acc: 35.16%] [G loss: 0.836047]\n",
      "epoch:19 step:14923[D loss: 0.436222, acc: 58.59%, op_acc: 38.28%] [G loss: 0.900625]\n",
      "epoch:19 step:14924[D loss: 0.430094, acc: 68.75%, op_acc: 35.94%] [G loss: 0.877715]\n",
      "epoch:19 step:14925[D loss: 0.416274, acc: 55.47%, op_acc: 38.28%] [G loss: 0.783202]\n",
      "epoch:19 step:14926[D loss: 0.436120, acc: 57.81%, op_acc: 38.28%] [G loss: 0.916431]\n",
      "epoch:19 step:14927[D loss: 0.442139, acc: 55.47%, op_acc: 36.72%] [G loss: 0.866632]\n",
      "epoch:19 step:14928[D loss: 0.461672, acc: 47.66%, op_acc: 35.16%] [G loss: 0.862562]\n",
      "epoch:19 step:14929[D loss: 0.410612, acc: 63.28%, op_acc: 42.97%] [G loss: 0.920937]\n",
      "epoch:19 step:14930[D loss: 0.410215, acc: 61.72%, op_acc: 42.97%] [G loss: 0.858559]\n",
      "epoch:19 step:14931[D loss: 0.445047, acc: 57.81%, op_acc: 39.06%] [G loss: 0.858360]\n",
      "epoch:19 step:14932[D loss: 0.413850, acc: 60.16%, op_acc: 38.28%] [G loss: 0.893078]\n",
      "epoch:19 step:14933[D loss: 0.403259, acc: 67.19%, op_acc: 38.28%] [G loss: 0.900908]\n",
      "epoch:19 step:14934[D loss: 0.423762, acc: 57.03%, op_acc: 39.06%] [G loss: 0.920654]\n",
      "epoch:19 step:14935[D loss: 0.436368, acc: 61.72%, op_acc: 37.50%] [G loss: 0.865122]\n",
      "epoch:19 step:14936[D loss: 0.423254, acc: 57.81%, op_acc: 39.06%] [G loss: 0.927611]\n",
      "epoch:19 step:14937[D loss: 0.400940, acc: 63.28%, op_acc: 41.41%] [G loss: 0.821665]\n",
      "epoch:19 step:14938[D loss: 0.402983, acc: 68.75%, op_acc: 39.06%] [G loss: 0.921560]\n",
      "epoch:19 step:14939[D loss: 0.428033, acc: 50.00%, op_acc: 40.62%] [G loss: 0.896531]\n",
      "epoch:19 step:14940[D loss: 0.413350, acc: 57.81%, op_acc: 36.72%] [G loss: 0.890763]\n",
      "epoch:19 step:14941[D loss: 0.438880, acc: 55.47%, op_acc: 41.41%] [G loss: 0.848705]\n",
      "epoch:19 step:14942[D loss: 0.427766, acc: 60.94%, op_acc: 45.31%] [G loss: 0.915902]\n",
      "epoch:19 step:14943[D loss: 0.432999, acc: 56.25%, op_acc: 35.94%] [G loss: 0.880029]\n",
      "epoch:19 step:14944[D loss: 0.411219, acc: 59.38%, op_acc: 45.31%] [G loss: 0.963237]\n",
      "epoch:19 step:14945[D loss: 0.395245, acc: 65.62%, op_acc: 41.41%] [G loss: 0.898150]\n",
      "epoch:19 step:14946[D loss: 0.408566, acc: 65.62%, op_acc: 42.97%] [G loss: 0.910284]\n",
      "epoch:19 step:14947[D loss: 0.465869, acc: 56.25%, op_acc: 33.59%] [G loss: 0.890941]\n",
      "epoch:19 step:14948[D loss: 0.414817, acc: 58.59%, op_acc: 41.41%] [G loss: 0.942753]\n",
      "epoch:19 step:14949[D loss: 0.447420, acc: 53.12%, op_acc: 38.28%] [G loss: 0.897657]\n",
      "epoch:19 step:14950[D loss: 0.415205, acc: 69.53%, op_acc: 36.72%] [G loss: 0.893475]\n",
      "epoch:19 step:14951[D loss: 0.404572, acc: 60.94%, op_acc: 46.09%] [G loss: 0.854279]\n",
      "epoch:19 step:14952[D loss: 0.416727, acc: 62.50%, op_acc: 40.62%] [G loss: 0.898043]\n",
      "epoch:19 step:14953[D loss: 0.435753, acc: 50.00%, op_acc: 39.84%] [G loss: 0.849337]\n",
      "epoch:19 step:14954[D loss: 0.428290, acc: 56.25%, op_acc: 42.19%] [G loss: 0.892403]\n",
      "epoch:19 step:14955[D loss: 0.442369, acc: 60.94%, op_acc: 37.50%] [G loss: 0.875108]\n",
      "epoch:19 step:14956[D loss: 0.466884, acc: 46.88%, op_acc: 37.50%] [G loss: 0.844771]\n",
      "epoch:19 step:14957[D loss: 0.425880, acc: 60.94%, op_acc: 36.72%] [G loss: 0.835849]\n",
      "epoch:19 step:14958[D loss: 0.438839, acc: 59.38%, op_acc: 35.94%] [G loss: 0.931483]\n",
      "epoch:19 step:14959[D loss: 0.455211, acc: 54.69%, op_acc: 38.28%] [G loss: 0.801622]\n",
      "epoch:19 step:14960[D loss: 0.407443, acc: 66.41%, op_acc: 39.06%] [G loss: 0.829249]\n",
      "epoch:19 step:14961[D loss: 0.408803, acc: 59.38%, op_acc: 39.84%] [G loss: 0.884459]\n",
      "epoch:19 step:14962[D loss: 0.438245, acc: 62.50%, op_acc: 39.06%] [G loss: 0.968362]\n",
      "epoch:19 step:14963[D loss: 0.445656, acc: 53.91%, op_acc: 38.28%] [G loss: 0.832148]\n",
      "epoch:19 step:14964[D loss: 0.458217, acc: 53.91%, op_acc: 34.38%] [G loss: 0.853087]\n",
      "epoch:19 step:14965[D loss: 0.417705, acc: 62.50%, op_acc: 40.62%] [G loss: 0.904772]\n",
      "epoch:19 step:14966[D loss: 0.424195, acc: 64.06%, op_acc: 37.50%] [G loss: 0.914159]\n",
      "epoch:19 step:14967[D loss: 0.416679, acc: 64.06%, op_acc: 42.19%] [G loss: 0.906495]\n",
      "epoch:19 step:14968[D loss: 0.422354, acc: 64.06%, op_acc: 33.59%] [G loss: 0.891756]\n",
      "epoch:19 step:14969[D loss: 0.420255, acc: 58.59%, op_acc: 39.84%] [G loss: 0.851786]\n",
      "epoch:19 step:14970[D loss: 0.418827, acc: 59.38%, op_acc: 39.06%] [G loss: 0.879189]\n",
      "epoch:19 step:14971[D loss: 0.402754, acc: 60.16%, op_acc: 40.62%] [G loss: 0.950679]\n",
      "epoch:19 step:14972[D loss: 0.456813, acc: 57.81%, op_acc: 35.16%] [G loss: 0.916961]\n",
      "epoch:19 step:14973[D loss: 0.424620, acc: 60.94%, op_acc: 32.81%] [G loss: 0.858725]\n",
      "epoch:19 step:14974[D loss: 0.418635, acc: 60.16%, op_acc: 43.75%] [G loss: 0.939673]\n",
      "epoch:19 step:14975[D loss: 0.399201, acc: 60.16%, op_acc: 40.62%] [G loss: 0.865854]\n",
      "epoch:19 step:14976[D loss: 0.439133, acc: 56.25%, op_acc: 39.06%] [G loss: 0.897653]\n",
      "epoch:19 step:14977[D loss: 0.448710, acc: 54.69%, op_acc: 33.59%] [G loss: 0.946063]\n",
      "epoch:19 step:14978[D loss: 0.415012, acc: 58.59%, op_acc: 40.62%] [G loss: 0.899456]\n",
      "epoch:19 step:14979[D loss: 0.452282, acc: 60.94%, op_acc: 32.81%] [G loss: 0.841420]\n",
      "epoch:19 step:14980[D loss: 0.451605, acc: 57.03%, op_acc: 33.59%] [G loss: 0.849927]\n",
      "epoch:19 step:14981[D loss: 0.426280, acc: 66.41%, op_acc: 33.59%] [G loss: 0.888488]\n",
      "epoch:19 step:14982[D loss: 0.454203, acc: 60.16%, op_acc: 39.06%] [G loss: 0.823974]\n",
      "epoch:19 step:14983[D loss: 0.440894, acc: 58.59%, op_acc: 35.94%] [G loss: 0.826271]\n",
      "epoch:19 step:14984[D loss: 0.428108, acc: 57.81%, op_acc: 36.72%] [G loss: 0.836223]\n",
      "epoch:19 step:14985[D loss: 0.399001, acc: 72.66%, op_acc: 32.81%] [G loss: 0.883504]\n",
      "epoch:19 step:14986[D loss: 0.444628, acc: 51.56%, op_acc: 35.94%] [G loss: 0.908397]\n",
      "epoch:19 step:14987[D loss: 0.428195, acc: 60.16%, op_acc: 36.72%] [G loss: 0.841783]\n",
      "epoch:19 step:14988[D loss: 0.430967, acc: 57.03%, op_acc: 41.41%] [G loss: 0.812134]\n",
      "epoch:19 step:14989[D loss: 0.419947, acc: 61.72%, op_acc: 40.62%] [G loss: 0.902348]\n",
      "epoch:19 step:14990[D loss: 0.432823, acc: 55.47%, op_acc: 42.19%] [G loss: 0.777259]\n",
      "epoch:19 step:14991[D loss: 0.422381, acc: 60.16%, op_acc: 43.75%] [G loss: 0.897445]\n",
      "epoch:19 step:14992[D loss: 0.421925, acc: 57.81%, op_acc: 41.41%] [G loss: 0.904422]\n",
      "epoch:19 step:14993[D loss: 0.450318, acc: 57.03%, op_acc: 36.72%] [G loss: 0.839039]\n",
      "epoch:19 step:14994[D loss: 0.392781, acc: 68.75%, op_acc: 35.16%] [G loss: 0.896183]\n",
      "epoch:19 step:14995[D loss: 0.439954, acc: 54.69%, op_acc: 39.06%] [G loss: 0.904245]\n",
      "epoch:19 step:14996[D loss: 0.414561, acc: 65.62%, op_acc: 39.84%] [G loss: 0.908947]\n",
      "epoch:19 step:14997[D loss: 0.404730, acc: 63.28%, op_acc: 41.41%] [G loss: 0.876413]\n",
      "epoch:19 step:14998[D loss: 0.422763, acc: 64.84%, op_acc: 36.72%] [G loss: 0.956168]\n",
      "epoch:19 step:14999[D loss: 0.445110, acc: 53.91%, op_acc: 39.06%] [G loss: 0.970177]\n",
      "epoch:19 step:15000[D loss: 0.424678, acc: 62.50%, op_acc: 35.94%] [G loss: 1.015099]\n",
      "epoch:19 step:15001[D loss: 0.416060, acc: 58.59%, op_acc: 45.31%] [G loss: 0.882515]\n",
      "epoch:19 step:15002[D loss: 0.440417, acc: 60.94%, op_acc: 33.59%] [G loss: 0.837124]\n",
      "epoch:19 step:15003[D loss: 0.460121, acc: 52.34%, op_acc: 30.47%] [G loss: 0.920761]\n",
      "epoch:19 step:15004[D loss: 0.397151, acc: 70.31%, op_acc: 39.06%] [G loss: 0.873816]\n",
      "epoch:19 step:15005[D loss: 0.434345, acc: 61.72%, op_acc: 34.38%] [G loss: 0.879051]\n",
      "epoch:19 step:15006[D loss: 0.465611, acc: 50.78%, op_acc: 37.50%] [G loss: 0.772572]\n",
      "epoch:19 step:15007[D loss: 0.392176, acc: 66.41%, op_acc: 43.75%] [G loss: 0.908546]\n",
      "epoch:19 step:15008[D loss: 0.428200, acc: 57.03%, op_acc: 37.50%] [G loss: 0.941229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15009[D loss: 0.438051, acc: 46.88%, op_acc: 47.66%] [G loss: 0.888916]\n",
      "epoch:19 step:15010[D loss: 0.444120, acc: 57.81%, op_acc: 39.84%] [G loss: 0.795557]\n",
      "epoch:19 step:15011[D loss: 0.412202, acc: 60.94%, op_acc: 42.19%] [G loss: 0.945685]\n",
      "epoch:19 step:15012[D loss: 0.436701, acc: 56.25%, op_acc: 35.94%] [G loss: 0.840377]\n",
      "epoch:19 step:15013[D loss: 0.468454, acc: 56.25%, op_acc: 32.81%] [G loss: 0.827431]\n",
      "epoch:19 step:15014[D loss: 0.397992, acc: 61.72%, op_acc: 46.09%] [G loss: 0.847042]\n",
      "epoch:19 step:15015[D loss: 0.433007, acc: 53.91%, op_acc: 39.84%] [G loss: 0.914535]\n",
      "epoch:19 step:15016[D loss: 0.449425, acc: 53.91%, op_acc: 34.38%] [G loss: 0.806326]\n",
      "epoch:19 step:15017[D loss: 0.474654, acc: 50.00%, op_acc: 36.72%] [G loss: 0.823374]\n",
      "epoch:19 step:15018[D loss: 0.396503, acc: 65.62%, op_acc: 39.06%] [G loss: 0.883897]\n",
      "epoch:19 step:15019[D loss: 0.424804, acc: 61.72%, op_acc: 38.28%] [G loss: 0.894621]\n",
      "epoch:19 step:15020[D loss: 0.427145, acc: 59.38%, op_acc: 42.19%] [G loss: 0.957011]\n",
      "epoch:19 step:15021[D loss: 0.427024, acc: 64.06%, op_acc: 32.81%] [G loss: 0.899797]\n",
      "epoch:19 step:15022[D loss: 0.429709, acc: 57.03%, op_acc: 38.28%] [G loss: 0.870696]\n",
      "epoch:19 step:15023[D loss: 0.434704, acc: 51.56%, op_acc: 35.94%] [G loss: 0.922159]\n",
      "epoch:19 step:15024[D loss: 0.443517, acc: 51.56%, op_acc: 36.72%] [G loss: 0.859193]\n",
      "epoch:19 step:15025[D loss: 0.429252, acc: 54.69%, op_acc: 39.84%] [G loss: 0.935040]\n",
      "epoch:19 step:15026[D loss: 0.418203, acc: 61.72%, op_acc: 32.03%] [G loss: 0.969596]\n",
      "epoch:19 step:15027[D loss: 0.423866, acc: 54.69%, op_acc: 39.06%] [G loss: 0.923239]\n",
      "epoch:19 step:15028[D loss: 0.392455, acc: 65.62%, op_acc: 36.72%] [G loss: 0.901390]\n",
      "epoch:19 step:15029[D loss: 0.436298, acc: 62.50%, op_acc: 39.06%] [G loss: 0.923888]\n",
      "epoch:19 step:15030[D loss: 0.431481, acc: 60.94%, op_acc: 40.62%] [G loss: 0.897988]\n",
      "epoch:19 step:15031[D loss: 0.423977, acc: 61.72%, op_acc: 39.84%] [G loss: 0.852749]\n",
      "epoch:19 step:15032[D loss: 0.438406, acc: 60.16%, op_acc: 40.62%] [G loss: 0.891675]\n",
      "epoch:19 step:15033[D loss: 0.422227, acc: 59.38%, op_acc: 42.19%] [G loss: 0.808408]\n",
      "epoch:19 step:15034[D loss: 0.413417, acc: 66.41%, op_acc: 40.62%] [G loss: 0.881151]\n",
      "epoch:19 step:15035[D loss: 0.422015, acc: 67.19%, op_acc: 34.38%] [G loss: 0.892396]\n",
      "epoch:19 step:15036[D loss: 0.469522, acc: 51.56%, op_acc: 39.84%] [G loss: 0.845514]\n",
      "epoch:19 step:15037[D loss: 0.430856, acc: 61.72%, op_acc: 35.94%] [G loss: 0.871241]\n",
      "epoch:19 step:15038[D loss: 0.440390, acc: 49.22%, op_acc: 40.62%] [G loss: 0.967209]\n",
      "epoch:19 step:15039[D loss: 0.451729, acc: 55.47%, op_acc: 34.38%] [G loss: 0.942125]\n",
      "epoch:19 step:15040[D loss: 0.403516, acc: 64.84%, op_acc: 38.28%] [G loss: 0.932855]\n",
      "epoch:19 step:15041[D loss: 0.449859, acc: 52.34%, op_acc: 38.28%] [G loss: 0.874092]\n",
      "epoch:19 step:15042[D loss: 0.428304, acc: 59.38%, op_acc: 32.03%] [G loss: 0.867396]\n",
      "epoch:19 step:15043[D loss: 0.459018, acc: 53.91%, op_acc: 36.72%] [G loss: 0.822754]\n",
      "epoch:19 step:15044[D loss: 0.446916, acc: 53.91%, op_acc: 35.94%] [G loss: 0.916694]\n",
      "epoch:19 step:15045[D loss: 0.420276, acc: 60.94%, op_acc: 38.28%] [G loss: 0.856872]\n",
      "epoch:19 step:15046[D loss: 0.432545, acc: 58.59%, op_acc: 33.59%] [G loss: 0.876560]\n",
      "epoch:19 step:15047[D loss: 0.441290, acc: 58.59%, op_acc: 34.38%] [G loss: 0.910934]\n",
      "epoch:19 step:15048[D loss: 0.426132, acc: 56.25%, op_acc: 37.50%] [G loss: 0.825260]\n",
      "epoch:19 step:15049[D loss: 0.467040, acc: 57.81%, op_acc: 31.25%] [G loss: 0.854903]\n",
      "epoch:19 step:15050[D loss: 0.409761, acc: 60.94%, op_acc: 42.19%] [G loss: 0.872102]\n",
      "epoch:19 step:15051[D loss: 0.423082, acc: 59.38%, op_acc: 40.62%] [G loss: 0.924649]\n",
      "epoch:19 step:15052[D loss: 0.447642, acc: 56.25%, op_acc: 33.59%] [G loss: 0.858401]\n",
      "epoch:19 step:15053[D loss: 0.402606, acc: 68.75%, op_acc: 41.41%] [G loss: 0.977112]\n",
      "epoch:19 step:15054[D loss: 0.427744, acc: 61.72%, op_acc: 34.38%] [G loss: 0.942880]\n",
      "epoch:19 step:15055[D loss: 0.439625, acc: 56.25%, op_acc: 34.38%] [G loss: 0.984258]\n",
      "epoch:19 step:15056[D loss: 0.430206, acc: 60.94%, op_acc: 39.06%] [G loss: 0.851117]\n",
      "epoch:19 step:15057[D loss: 0.423893, acc: 58.59%, op_acc: 39.84%] [G loss: 0.889099]\n",
      "epoch:19 step:15058[D loss: 0.424790, acc: 60.94%, op_acc: 39.84%] [G loss: 0.816432]\n",
      "epoch:19 step:15059[D loss: 0.475735, acc: 49.22%, op_acc: 35.16%] [G loss: 0.906724]\n",
      "epoch:19 step:15060[D loss: 0.434728, acc: 53.91%, op_acc: 37.50%] [G loss: 0.857111]\n",
      "epoch:19 step:15061[D loss: 0.444996, acc: 53.12%, op_acc: 40.62%] [G loss: 0.874478]\n",
      "epoch:19 step:15062[D loss: 0.412363, acc: 53.91%, op_acc: 40.62%] [G loss: 0.909265]\n",
      "epoch:19 step:15063[D loss: 0.426102, acc: 54.69%, op_acc: 38.28%] [G loss: 0.903522]\n",
      "epoch:19 step:15064[D loss: 0.448303, acc: 65.62%, op_acc: 39.06%] [G loss: 0.880295]\n",
      "epoch:19 step:15065[D loss: 0.429473, acc: 64.06%, op_acc: 34.38%] [G loss: 0.899762]\n",
      "epoch:19 step:15066[D loss: 0.444042, acc: 57.81%, op_acc: 38.28%] [G loss: 0.818081]\n",
      "epoch:19 step:15067[D loss: 0.400991, acc: 64.84%, op_acc: 42.19%] [G loss: 0.858301]\n",
      "epoch:19 step:15068[D loss: 0.401188, acc: 67.97%, op_acc: 36.72%] [G loss: 0.854243]\n",
      "epoch:19 step:15069[D loss: 0.432243, acc: 56.25%, op_acc: 35.94%] [G loss: 0.898002]\n",
      "epoch:19 step:15070[D loss: 0.401519, acc: 65.62%, op_acc: 39.84%] [G loss: 0.931049]\n",
      "epoch:19 step:15071[D loss: 0.419060, acc: 64.84%, op_acc: 42.19%] [G loss: 0.932200]\n",
      "epoch:19 step:15072[D loss: 0.407753, acc: 66.41%, op_acc: 33.59%] [G loss: 0.963892]\n",
      "epoch:19 step:15073[D loss: 0.442994, acc: 64.84%, op_acc: 36.72%] [G loss: 0.921068]\n",
      "epoch:19 step:15074[D loss: 0.403796, acc: 59.38%, op_acc: 43.75%] [G loss: 0.859189]\n",
      "epoch:19 step:15075[D loss: 0.441060, acc: 52.34%, op_acc: 38.28%] [G loss: 0.952332]\n",
      "epoch:19 step:15076[D loss: 0.403536, acc: 60.16%, op_acc: 38.28%] [G loss: 0.913098]\n",
      "epoch:19 step:15077[D loss: 0.432968, acc: 57.81%, op_acc: 37.50%] [G loss: 0.867297]\n",
      "epoch:19 step:15078[D loss: 0.431192, acc: 58.59%, op_acc: 35.94%] [G loss: 0.897342]\n",
      "epoch:19 step:15079[D loss: 0.426102, acc: 62.50%, op_acc: 39.84%] [G loss: 0.890369]\n",
      "epoch:19 step:15080[D loss: 0.431967, acc: 55.47%, op_acc: 39.06%] [G loss: 0.863561]\n",
      "epoch:19 step:15081[D loss: 0.421417, acc: 56.25%, op_acc: 42.19%] [G loss: 0.877832]\n",
      "epoch:19 step:15082[D loss: 0.433545, acc: 53.12%, op_acc: 38.28%] [G loss: 0.855619]\n",
      "epoch:19 step:15083[D loss: 0.433357, acc: 57.03%, op_acc: 35.94%] [G loss: 0.824882]\n",
      "epoch:19 step:15084[D loss: 0.435629, acc: 57.03%, op_acc: 39.06%] [G loss: 0.831397]\n",
      "epoch:19 step:15085[D loss: 0.448956, acc: 57.03%, op_acc: 39.84%] [G loss: 0.805119]\n",
      "epoch:19 step:15086[D loss: 0.418172, acc: 55.47%, op_acc: 43.75%] [G loss: 0.819838]\n",
      "epoch:19 step:15087[D loss: 0.454810, acc: 58.59%, op_acc: 30.47%] [G loss: 0.909297]\n",
      "epoch:19 step:15088[D loss: 0.420187, acc: 63.28%, op_acc: 39.84%] [G loss: 0.850981]\n",
      "epoch:19 step:15089[D loss: 0.468351, acc: 54.69%, op_acc: 31.25%] [G loss: 0.865198]\n",
      "epoch:19 step:15090[D loss: 0.415943, acc: 61.72%, op_acc: 42.97%] [G loss: 0.954529]\n",
      "epoch:19 step:15091[D loss: 0.454101, acc: 50.78%, op_acc: 35.94%] [G loss: 0.880199]\n",
      "epoch:19 step:15092[D loss: 0.447909, acc: 52.34%, op_acc: 42.19%] [G loss: 0.975357]\n",
      "epoch:19 step:15093[D loss: 0.450622, acc: 53.91%, op_acc: 34.38%] [G loss: 0.847669]\n",
      "epoch:19 step:15094[D loss: 0.451340, acc: 57.81%, op_acc: 38.28%] [G loss: 0.883597]\n",
      "epoch:19 step:15095[D loss: 0.412716, acc: 65.62%, op_acc: 40.62%] [G loss: 0.934939]\n",
      "epoch:19 step:15096[D loss: 0.416056, acc: 60.94%, op_acc: 39.06%] [G loss: 0.943115]\n",
      "epoch:19 step:15097[D loss: 0.447119, acc: 53.12%, op_acc: 42.97%] [G loss: 0.922339]\n",
      "epoch:19 step:15098[D loss: 0.425600, acc: 57.03%, op_acc: 30.47%] [G loss: 0.856364]\n",
      "epoch:19 step:15099[D loss: 0.433831, acc: 56.25%, op_acc: 35.94%] [G loss: 0.867425]\n",
      "epoch:19 step:15100[D loss: 0.411934, acc: 62.50%, op_acc: 36.72%] [G loss: 0.949936]\n",
      "epoch:19 step:15101[D loss: 0.434328, acc: 60.94%, op_acc: 33.59%] [G loss: 0.915652]\n",
      "epoch:19 step:15102[D loss: 0.438055, acc: 58.59%, op_acc: 34.38%] [G loss: 0.850643]\n",
      "epoch:19 step:15103[D loss: 0.422133, acc: 60.94%, op_acc: 36.72%] [G loss: 0.967003]\n",
      "epoch:19 step:15104[D loss: 0.430461, acc: 57.03%, op_acc: 34.38%] [G loss: 0.907392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15105[D loss: 0.444750, acc: 62.50%, op_acc: 36.72%] [G loss: 0.887914]\n",
      "epoch:19 step:15106[D loss: 0.460724, acc: 53.12%, op_acc: 39.84%] [G loss: 0.913643]\n",
      "epoch:19 step:15107[D loss: 0.385711, acc: 64.06%, op_acc: 46.09%] [G loss: 0.893452]\n",
      "epoch:19 step:15108[D loss: 0.416269, acc: 57.81%, op_acc: 40.62%] [G loss: 0.893367]\n",
      "epoch:19 step:15109[D loss: 0.439624, acc: 53.91%, op_acc: 39.06%] [G loss: 0.924157]\n",
      "epoch:19 step:15110[D loss: 0.414631, acc: 64.06%, op_acc: 37.50%] [G loss: 0.887342]\n",
      "epoch:19 step:15111[D loss: 0.420867, acc: 55.47%, op_acc: 37.50%] [G loss: 0.924406]\n",
      "epoch:19 step:15112[D loss: 0.416860, acc: 60.94%, op_acc: 42.97%] [G loss: 0.810760]\n",
      "epoch:19 step:15113[D loss: 0.441751, acc: 57.03%, op_acc: 37.50%] [G loss: 0.872784]\n",
      "epoch:19 step:15114[D loss: 0.434162, acc: 54.69%, op_acc: 39.06%] [G loss: 0.894659]\n",
      "epoch:19 step:15115[D loss: 0.427151, acc: 58.59%, op_acc: 42.19%] [G loss: 0.894869]\n",
      "epoch:19 step:15116[D loss: 0.420788, acc: 57.81%, op_acc: 36.72%] [G loss: 0.927216]\n",
      "epoch:19 step:15117[D loss: 0.444271, acc: 51.56%, op_acc: 39.06%] [G loss: 0.949331]\n",
      "epoch:19 step:15118[D loss: 0.413739, acc: 66.41%, op_acc: 32.81%] [G loss: 0.911561]\n",
      "epoch:19 step:15119[D loss: 0.394654, acc: 64.06%, op_acc: 43.75%] [G loss: 0.853050]\n",
      "epoch:19 step:15120[D loss: 0.492883, acc: 45.31%, op_acc: 31.25%] [G loss: 0.865063]\n",
      "epoch:19 step:15121[D loss: 0.483667, acc: 50.78%, op_acc: 35.16%] [G loss: 0.857727]\n",
      "epoch:19 step:15122[D loss: 0.408537, acc: 60.16%, op_acc: 43.75%] [G loss: 0.914775]\n",
      "epoch:19 step:15123[D loss: 0.444024, acc: 50.78%, op_acc: 39.84%] [G loss: 0.807030]\n",
      "epoch:19 step:15124[D loss: 0.422379, acc: 57.03%, op_acc: 37.50%] [G loss: 0.812450]\n",
      "epoch:19 step:15125[D loss: 0.462407, acc: 53.12%, op_acc: 31.25%] [G loss: 0.902662]\n",
      "epoch:19 step:15126[D loss: 0.443167, acc: 56.25%, op_acc: 39.06%] [G loss: 0.829730]\n",
      "epoch:19 step:15127[D loss: 0.403381, acc: 63.28%, op_acc: 41.41%] [G loss: 0.831869]\n",
      "epoch:19 step:15128[D loss: 0.433196, acc: 59.38%, op_acc: 35.94%] [G loss: 0.869944]\n",
      "epoch:19 step:15129[D loss: 0.402765, acc: 64.84%, op_acc: 38.28%] [G loss: 0.924558]\n",
      "epoch:19 step:15130[D loss: 0.413060, acc: 60.16%, op_acc: 38.28%] [G loss: 0.852941]\n",
      "epoch:19 step:15131[D loss: 0.437432, acc: 60.94%, op_acc: 34.38%] [G loss: 0.962477]\n",
      "epoch:19 step:15132[D loss: 0.431446, acc: 57.81%, op_acc: 35.94%] [G loss: 0.867279]\n",
      "epoch:19 step:15133[D loss: 0.437127, acc: 59.38%, op_acc: 38.28%] [G loss: 0.861130]\n",
      "epoch:19 step:15134[D loss: 0.420365, acc: 58.59%, op_acc: 39.84%] [G loss: 0.847178]\n",
      "epoch:19 step:15135[D loss: 0.444996, acc: 52.34%, op_acc: 42.19%] [G loss: 0.920187]\n",
      "epoch:19 step:15136[D loss: 0.433325, acc: 64.84%, op_acc: 37.50%] [G loss: 0.900549]\n",
      "epoch:19 step:15137[D loss: 0.445143, acc: 60.94%, op_acc: 35.16%] [G loss: 0.777647]\n",
      "epoch:19 step:15138[D loss: 0.453699, acc: 57.81%, op_acc: 35.16%] [G loss: 0.838579]\n",
      "epoch:19 step:15139[D loss: 0.459220, acc: 57.03%, op_acc: 31.25%] [G loss: 0.897289]\n",
      "epoch:19 step:15140[D loss: 0.444657, acc: 50.78%, op_acc: 39.06%] [G loss: 0.819799]\n",
      "epoch:19 step:15141[D loss: 0.390940, acc: 67.19%, op_acc: 35.16%] [G loss: 0.940132]\n",
      "epoch:19 step:15142[D loss: 0.407641, acc: 61.72%, op_acc: 40.62%] [G loss: 0.854073]\n",
      "epoch:19 step:15143[D loss: 0.407894, acc: 59.38%, op_acc: 39.84%] [G loss: 0.868161]\n",
      "epoch:19 step:15144[D loss: 0.426607, acc: 53.12%, op_acc: 35.94%] [G loss: 0.936296]\n",
      "epoch:19 step:15145[D loss: 0.437927, acc: 59.38%, op_acc: 35.94%] [G loss: 0.918555]\n",
      "epoch:19 step:15146[D loss: 0.424861, acc: 58.59%, op_acc: 37.50%] [G loss: 0.788047]\n",
      "epoch:19 step:15147[D loss: 0.445477, acc: 56.25%, op_acc: 34.38%] [G loss: 0.810139]\n",
      "epoch:19 step:15148[D loss: 0.417374, acc: 67.19%, op_acc: 32.81%] [G loss: 0.872338]\n",
      "epoch:19 step:15149[D loss: 0.441155, acc: 54.69%, op_acc: 37.50%] [G loss: 0.822505]\n",
      "epoch:19 step:15150[D loss: 0.439253, acc: 53.91%, op_acc: 39.84%] [G loss: 0.872254]\n",
      "epoch:19 step:15151[D loss: 0.446184, acc: 55.47%, op_acc: 40.62%] [G loss: 0.846503]\n",
      "epoch:19 step:15152[D loss: 0.445470, acc: 53.12%, op_acc: 39.06%] [G loss: 0.915721]\n",
      "epoch:19 step:15153[D loss: 0.422235, acc: 60.94%, op_acc: 34.38%] [G loss: 0.957823]\n",
      "epoch:19 step:15154[D loss: 0.439815, acc: 53.91%, op_acc: 38.28%] [G loss: 0.890889]\n",
      "epoch:19 step:15155[D loss: 0.423506, acc: 60.16%, op_acc: 32.81%] [G loss: 0.880189]\n",
      "epoch:19 step:15156[D loss: 0.482721, acc: 46.09%, op_acc: 35.94%] [G loss: 0.769765]\n",
      "epoch:19 step:15157[D loss: 0.427559, acc: 63.28%, op_acc: 30.47%] [G loss: 0.867051]\n",
      "epoch:19 step:15158[D loss: 0.429945, acc: 60.16%, op_acc: 39.06%] [G loss: 0.894148]\n",
      "epoch:19 step:15159[D loss: 0.439639, acc: 57.81%, op_acc: 37.50%] [G loss: 0.877992]\n",
      "epoch:19 step:15160[D loss: 0.443519, acc: 60.16%, op_acc: 39.84%] [G loss: 0.863907]\n",
      "epoch:19 step:15161[D loss: 0.418474, acc: 57.81%, op_acc: 41.41%] [G loss: 0.971692]\n",
      "epoch:19 step:15162[D loss: 0.418759, acc: 57.03%, op_acc: 42.19%] [G loss: 0.829365]\n",
      "epoch:19 step:15163[D loss: 0.459333, acc: 53.12%, op_acc: 32.03%] [G loss: 0.916130]\n",
      "epoch:19 step:15164[D loss: 0.441507, acc: 55.47%, op_acc: 40.62%] [G loss: 0.843725]\n",
      "epoch:19 step:15165[D loss: 0.438394, acc: 50.00%, op_acc: 41.41%] [G loss: 0.839370]\n",
      "epoch:19 step:15166[D loss: 0.418711, acc: 57.03%, op_acc: 41.41%] [G loss: 0.854540]\n",
      "epoch:19 step:15167[D loss: 0.453187, acc: 51.56%, op_acc: 38.28%] [G loss: 0.857645]\n",
      "epoch:19 step:15168[D loss: 0.424238, acc: 57.03%, op_acc: 39.06%] [G loss: 0.945514]\n",
      "epoch:19 step:15169[D loss: 0.389718, acc: 67.97%, op_acc: 40.62%] [G loss: 0.882823]\n",
      "epoch:19 step:15170[D loss: 0.455220, acc: 50.00%, op_acc: 37.50%] [G loss: 0.888161]\n",
      "epoch:19 step:15171[D loss: 0.394868, acc: 66.41%, op_acc: 42.19%] [G loss: 0.838797]\n",
      "epoch:19 step:15172[D loss: 0.427964, acc: 58.59%, op_acc: 39.06%] [G loss: 0.911379]\n",
      "epoch:19 step:15173[D loss: 0.437109, acc: 57.81%, op_acc: 39.06%] [G loss: 0.888403]\n",
      "epoch:19 step:15174[D loss: 0.445805, acc: 51.56%, op_acc: 36.72%] [G loss: 0.836633]\n",
      "epoch:19 step:15175[D loss: 0.448500, acc: 60.94%, op_acc: 40.62%] [G loss: 0.865015]\n",
      "epoch:19 step:15176[D loss: 0.459917, acc: 55.47%, op_acc: 35.94%] [G loss: 0.963841]\n",
      "epoch:19 step:15177[D loss: 0.421731, acc: 53.12%, op_acc: 38.28%] [G loss: 0.955495]\n",
      "epoch:19 step:15178[D loss: 0.425669, acc: 56.25%, op_acc: 38.28%] [G loss: 0.832550]\n",
      "epoch:19 step:15179[D loss: 0.436104, acc: 54.69%, op_acc: 38.28%] [G loss: 0.893408]\n",
      "epoch:19 step:15180[D loss: 0.422221, acc: 62.50%, op_acc: 44.53%] [G loss: 0.932652]\n",
      "epoch:19 step:15181[D loss: 0.457860, acc: 52.34%, op_acc: 30.47%] [G loss: 0.916423]\n",
      "epoch:19 step:15182[D loss: 0.431028, acc: 55.47%, op_acc: 34.38%] [G loss: 0.838433]\n",
      "epoch:19 step:15183[D loss: 0.453047, acc: 52.34%, op_acc: 39.84%] [G loss: 0.782627]\n",
      "epoch:19 step:15184[D loss: 0.404372, acc: 63.28%, op_acc: 38.28%] [G loss: 0.897719]\n",
      "epoch:19 step:15185[D loss: 0.424524, acc: 60.16%, op_acc: 34.38%] [G loss: 0.867106]\n",
      "epoch:19 step:15186[D loss: 0.428591, acc: 54.69%, op_acc: 35.94%] [G loss: 0.992467]\n",
      "epoch:19 step:15187[D loss: 0.429170, acc: 64.84%, op_acc: 34.38%] [G loss: 0.824682]\n",
      "epoch:19 step:15188[D loss: 0.424752, acc: 56.25%, op_acc: 39.84%] [G loss: 0.934663]\n",
      "epoch:19 step:15189[D loss: 0.409592, acc: 64.84%, op_acc: 38.28%] [G loss: 0.892339]\n",
      "epoch:19 step:15190[D loss: 0.455892, acc: 51.56%, op_acc: 32.03%] [G loss: 0.803499]\n",
      "epoch:19 step:15191[D loss: 0.429375, acc: 63.28%, op_acc: 39.84%] [G loss: 0.923063]\n",
      "epoch:19 step:15192[D loss: 0.394709, acc: 65.62%, op_acc: 39.84%] [G loss: 0.914118]\n",
      "epoch:19 step:15193[D loss: 0.457212, acc: 50.78%, op_acc: 35.94%] [G loss: 0.903895]\n",
      "epoch:19 step:15194[D loss: 0.426971, acc: 55.47%, op_acc: 38.28%] [G loss: 0.903904]\n",
      "epoch:19 step:15195[D loss: 0.435919, acc: 51.56%, op_acc: 35.94%] [G loss: 0.927726]\n",
      "epoch:19 step:15196[D loss: 0.433324, acc: 55.47%, op_acc: 32.81%] [G loss: 0.947428]\n",
      "epoch:19 step:15197[D loss: 0.438384, acc: 59.38%, op_acc: 38.28%] [G loss: 0.894026]\n",
      "epoch:19 step:15198[D loss: 0.440343, acc: 64.06%, op_acc: 35.94%] [G loss: 0.906511]\n",
      "epoch:19 step:15199[D loss: 0.419311, acc: 62.50%, op_acc: 34.38%] [G loss: 0.884887]\n",
      "epoch:19 step:15200[D loss: 0.434837, acc: 46.88%, op_acc: 41.41%] [G loss: 0.890124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15201[D loss: 0.406291, acc: 61.72%, op_acc: 36.72%] [G loss: 0.843151]\n",
      "epoch:19 step:15202[D loss: 0.453244, acc: 53.12%, op_acc: 31.25%] [G loss: 0.827672]\n",
      "epoch:19 step:15203[D loss: 0.442385, acc: 53.91%, op_acc: 35.16%] [G loss: 0.921563]\n",
      "epoch:19 step:15204[D loss: 0.408683, acc: 60.16%, op_acc: 42.97%] [G loss: 0.937324]\n",
      "epoch:19 step:15205[D loss: 0.415191, acc: 60.16%, op_acc: 42.97%] [G loss: 0.925124]\n",
      "epoch:19 step:15206[D loss: 0.453877, acc: 63.28%, op_acc: 32.03%] [G loss: 0.845011]\n",
      "epoch:19 step:15207[D loss: 0.463144, acc: 50.78%, op_acc: 32.81%] [G loss: 0.812715]\n",
      "epoch:19 step:15208[D loss: 0.394756, acc: 69.53%, op_acc: 39.06%] [G loss: 0.896749]\n",
      "epoch:19 step:15209[D loss: 0.428666, acc: 59.38%, op_acc: 33.59%] [G loss: 0.865325]\n",
      "epoch:19 step:15210[D loss: 0.385488, acc: 63.28%, op_acc: 39.06%] [G loss: 0.827960]\n",
      "epoch:19 step:15211[D loss: 0.432853, acc: 51.56%, op_acc: 39.06%] [G loss: 0.944563]\n",
      "epoch:19 step:15212[D loss: 0.411515, acc: 65.62%, op_acc: 38.28%] [G loss: 0.882549]\n",
      "epoch:19 step:15213[D loss: 0.443890, acc: 59.38%, op_acc: 41.41%] [G loss: 0.847301]\n",
      "epoch:19 step:15214[D loss: 0.409508, acc: 60.16%, op_acc: 40.62%] [G loss: 0.863946]\n",
      "epoch:19 step:15215[D loss: 0.431804, acc: 64.06%, op_acc: 34.38%] [G loss: 0.831195]\n",
      "epoch:19 step:15216[D loss: 0.440287, acc: 58.59%, op_acc: 32.81%] [G loss: 0.831131]\n",
      "epoch:19 step:15217[D loss: 0.437412, acc: 60.94%, op_acc: 35.94%] [G loss: 0.892591]\n",
      "epoch:19 step:15218[D loss: 0.391672, acc: 64.84%, op_acc: 42.97%] [G loss: 0.842784]\n",
      "epoch:19 step:15219[D loss: 0.423362, acc: 59.38%, op_acc: 36.72%] [G loss: 0.892991]\n",
      "epoch:19 step:15220[D loss: 0.408502, acc: 67.19%, op_acc: 37.50%] [G loss: 0.878193]\n",
      "epoch:19 step:15221[D loss: 0.401740, acc: 65.62%, op_acc: 36.72%] [G loss: 0.873628]\n",
      "epoch:19 step:15222[D loss: 0.445388, acc: 57.81%, op_acc: 42.19%] [G loss: 0.839750]\n",
      "epoch:19 step:15223[D loss: 0.416128, acc: 60.94%, op_acc: 35.16%] [G loss: 0.878351]\n",
      "epoch:19 step:15224[D loss: 0.430711, acc: 55.47%, op_acc: 41.41%] [G loss: 0.853214]\n",
      "epoch:19 step:15225[D loss: 0.413347, acc: 57.81%, op_acc: 43.75%] [G loss: 0.913359]\n",
      "epoch:19 step:15226[D loss: 0.419826, acc: 64.84%, op_acc: 36.72%] [G loss: 0.895327]\n",
      "epoch:19 step:15227[D loss: 0.438696, acc: 60.94%, op_acc: 34.38%] [G loss: 0.980986]\n",
      "epoch:19 step:15228[D loss: 0.444217, acc: 53.12%, op_acc: 39.06%] [G loss: 0.908936]\n",
      "epoch:19 step:15229[D loss: 0.408290, acc: 64.06%, op_acc: 41.41%] [G loss: 0.936601]\n",
      "epoch:19 step:15230[D loss: 0.392380, acc: 62.50%, op_acc: 43.75%] [G loss: 0.937066]\n",
      "epoch:19 step:15231[D loss: 0.406866, acc: 54.69%, op_acc: 42.19%] [G loss: 0.978390]\n",
      "epoch:19 step:15232[D loss: 0.417966, acc: 66.41%, op_acc: 40.62%] [G loss: 0.819744]\n",
      "epoch:19 step:15233[D loss: 0.430740, acc: 58.59%, op_acc: 36.72%] [G loss: 0.852497]\n",
      "epoch:19 step:15234[D loss: 0.468663, acc: 56.25%, op_acc: 28.91%] [G loss: 0.865829]\n",
      "epoch:19 step:15235[D loss: 0.416699, acc: 57.81%, op_acc: 43.75%] [G loss: 0.918028]\n",
      "epoch:19 step:15236[D loss: 0.432089, acc: 62.50%, op_acc: 36.72%] [G loss: 0.836092]\n",
      "epoch:19 step:15237[D loss: 0.441463, acc: 54.69%, op_acc: 34.38%] [G loss: 0.850609]\n",
      "epoch:19 step:15238[D loss: 0.442024, acc: 53.91%, op_acc: 41.41%] [G loss: 0.901415]\n",
      "epoch:19 step:15239[D loss: 0.417645, acc: 58.59%, op_acc: 42.97%] [G loss: 0.882266]\n",
      "epoch:19 step:15240[D loss: 0.460213, acc: 54.69%, op_acc: 36.72%] [G loss: 0.832144]\n",
      "epoch:19 step:15241[D loss: 0.419036, acc: 61.72%, op_acc: 35.16%] [G loss: 0.907214]\n",
      "epoch:19 step:15242[D loss: 0.438701, acc: 62.50%, op_acc: 32.81%] [G loss: 0.910311]\n",
      "epoch:19 step:15243[D loss: 0.415172, acc: 55.47%, op_acc: 40.62%] [G loss: 0.863202]\n",
      "epoch:19 step:15244[D loss: 0.441983, acc: 58.59%, op_acc: 35.16%] [G loss: 0.945548]\n",
      "epoch:19 step:15245[D loss: 0.430855, acc: 60.94%, op_acc: 37.50%] [G loss: 0.880897]\n",
      "epoch:19 step:15246[D loss: 0.452580, acc: 53.91%, op_acc: 38.28%] [G loss: 0.884169]\n",
      "epoch:19 step:15247[D loss: 0.418744, acc: 63.28%, op_acc: 39.06%] [G loss: 0.891685]\n",
      "epoch:19 step:15248[D loss: 0.422022, acc: 59.38%, op_acc: 43.75%] [G loss: 0.927163]\n",
      "epoch:19 step:15249[D loss: 0.435924, acc: 49.22%, op_acc: 39.06%] [G loss: 0.837494]\n",
      "epoch:19 step:15250[D loss: 0.440851, acc: 50.78%, op_acc: 34.38%] [G loss: 0.867010]\n",
      "epoch:19 step:15251[D loss: 0.438422, acc: 53.91%, op_acc: 39.06%] [G loss: 0.861144]\n",
      "epoch:19 step:15252[D loss: 0.410452, acc: 60.94%, op_acc: 45.31%] [G loss: 0.942985]\n",
      "epoch:19 step:15253[D loss: 0.428523, acc: 65.62%, op_acc: 36.72%] [G loss: 0.880602]\n",
      "epoch:19 step:15254[D loss: 0.401588, acc: 67.97%, op_acc: 40.62%] [G loss: 0.864904]\n",
      "epoch:19 step:15255[D loss: 0.422291, acc: 57.03%, op_acc: 41.41%] [G loss: 0.898988]\n",
      "epoch:19 step:15256[D loss: 0.421246, acc: 60.16%, op_acc: 35.16%] [G loss: 0.865563]\n",
      "epoch:19 step:15257[D loss: 0.448032, acc: 54.69%, op_acc: 41.41%] [G loss: 0.877479]\n",
      "epoch:19 step:15258[D loss: 0.429070, acc: 59.38%, op_acc: 35.94%] [G loss: 0.881998]\n",
      "epoch:19 step:15259[D loss: 0.404285, acc: 66.41%, op_acc: 45.31%] [G loss: 0.975892]\n",
      "epoch:19 step:15260[D loss: 0.426853, acc: 60.16%, op_acc: 37.50%] [G loss: 0.956971]\n",
      "epoch:19 step:15261[D loss: 0.401894, acc: 67.19%, op_acc: 44.53%] [G loss: 0.832518]\n",
      "epoch:19 step:15262[D loss: 0.437504, acc: 61.72%, op_acc: 32.03%] [G loss: 0.893744]\n",
      "epoch:19 step:15263[D loss: 0.412047, acc: 69.53%, op_acc: 34.38%] [G loss: 0.944707]\n",
      "epoch:19 step:15264[D loss: 0.455301, acc: 60.16%, op_acc: 37.50%] [G loss: 0.921291]\n",
      "epoch:19 step:15265[D loss: 0.435835, acc: 53.91%, op_acc: 37.50%] [G loss: 0.853566]\n",
      "epoch:19 step:15266[D loss: 0.426957, acc: 59.38%, op_acc: 41.41%] [G loss: 0.887112]\n",
      "epoch:19 step:15267[D loss: 0.450882, acc: 53.91%, op_acc: 38.28%] [G loss: 0.888145]\n",
      "epoch:19 step:15268[D loss: 0.424780, acc: 65.62%, op_acc: 35.16%] [G loss: 0.831898]\n",
      "epoch:19 step:15269[D loss: 0.426632, acc: 61.72%, op_acc: 38.28%] [G loss: 0.936876]\n",
      "epoch:19 step:15270[D loss: 0.448047, acc: 59.38%, op_acc: 42.97%] [G loss: 0.823812]\n",
      "epoch:19 step:15271[D loss: 0.388278, acc: 61.72%, op_acc: 39.84%] [G loss: 0.869901]\n",
      "epoch:19 step:15272[D loss: 0.419281, acc: 57.81%, op_acc: 42.97%] [G loss: 0.939343]\n",
      "epoch:19 step:15273[D loss: 0.409937, acc: 60.16%, op_acc: 42.19%] [G loss: 0.898684]\n",
      "epoch:19 step:15274[D loss: 0.405569, acc: 64.06%, op_acc: 34.38%] [G loss: 0.867102]\n",
      "epoch:19 step:15275[D loss: 0.479367, acc: 51.56%, op_acc: 33.59%] [G loss: 0.823944]\n",
      "epoch:19 step:15276[D loss: 0.430566, acc: 54.69%, op_acc: 38.28%] [G loss: 0.866291]\n",
      "epoch:19 step:15277[D loss: 0.416614, acc: 59.38%, op_acc: 45.31%] [G loss: 0.820142]\n",
      "epoch:19 step:15278[D loss: 0.426501, acc: 58.59%, op_acc: 39.84%] [G loss: 0.866063]\n",
      "epoch:19 step:15279[D loss: 0.416320, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880224]\n",
      "epoch:19 step:15280[D loss: 0.429654, acc: 57.03%, op_acc: 35.16%] [G loss: 0.915818]\n",
      "epoch:19 step:15281[D loss: 0.418325, acc: 60.94%, op_acc: 39.84%] [G loss: 0.831786]\n",
      "epoch:19 step:15282[D loss: 0.404631, acc: 69.53%, op_acc: 37.50%] [G loss: 0.944498]\n",
      "epoch:19 step:15283[D loss: 0.402629, acc: 60.94%, op_acc: 39.06%] [G loss: 0.907667]\n",
      "epoch:19 step:15284[D loss: 0.417369, acc: 65.62%, op_acc: 33.59%] [G loss: 0.911817]\n",
      "epoch:19 step:15285[D loss: 0.421527, acc: 61.72%, op_acc: 42.19%] [G loss: 0.807963]\n",
      "epoch:19 step:15286[D loss: 0.439205, acc: 60.94%, op_acc: 35.94%] [G loss: 0.830321]\n",
      "epoch:19 step:15287[D loss: 0.403653, acc: 60.94%, op_acc: 42.19%] [G loss: 0.891141]\n",
      "epoch:19 step:15288[D loss: 0.400044, acc: 60.94%, op_acc: 42.97%] [G loss: 0.876393]\n",
      "epoch:19 step:15289[D loss: 0.424792, acc: 67.19%, op_acc: 32.03%] [G loss: 0.865967]\n",
      "epoch:19 step:15290[D loss: 0.429554, acc: 57.81%, op_acc: 46.09%] [G loss: 0.878771]\n",
      "epoch:19 step:15291[D loss: 0.445839, acc: 53.91%, op_acc: 33.59%] [G loss: 0.863888]\n",
      "epoch:19 step:15292[D loss: 0.422919, acc: 56.25%, op_acc: 39.84%] [G loss: 0.873415]\n",
      "epoch:19 step:15293[D loss: 0.418142, acc: 68.75%, op_acc: 32.03%] [G loss: 0.920231]\n",
      "epoch:19 step:15294[D loss: 0.436018, acc: 57.81%, op_acc: 34.38%] [G loss: 0.899224]\n",
      "epoch:19 step:15295[D loss: 0.425745, acc: 60.94%, op_acc: 39.84%] [G loss: 0.834543]\n",
      "epoch:19 step:15296[D loss: 0.428302, acc: 52.34%, op_acc: 38.28%] [G loss: 0.938633]\n",
      "epoch:19 step:15297[D loss: 0.386187, acc: 64.84%, op_acc: 42.97%] [G loss: 0.851811]\n",
      "epoch:19 step:15298[D loss: 0.435767, acc: 57.03%, op_acc: 42.97%] [G loss: 0.917648]\n",
      "epoch:19 step:15299[D loss: 0.414008, acc: 61.72%, op_acc: 40.62%] [G loss: 0.869727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15300[D loss: 0.448688, acc: 53.12%, op_acc: 35.16%] [G loss: 0.835312]\n",
      "epoch:19 step:15301[D loss: 0.414270, acc: 59.38%, op_acc: 40.62%] [G loss: 0.868616]\n",
      "epoch:19 step:15302[D loss: 0.426527, acc: 53.91%, op_acc: 37.50%] [G loss: 0.945236]\n",
      "epoch:19 step:15303[D loss: 0.476219, acc: 53.91%, op_acc: 39.06%] [G loss: 0.802932]\n",
      "epoch:19 step:15304[D loss: 0.410589, acc: 62.50%, op_acc: 38.28%] [G loss: 0.959052]\n",
      "epoch:19 step:15305[D loss: 0.413878, acc: 64.84%, op_acc: 39.84%] [G loss: 0.941639]\n",
      "epoch:19 step:15306[D loss: 0.429034, acc: 57.81%, op_acc: 32.81%] [G loss: 0.956653]\n",
      "epoch:19 step:15307[D loss: 0.409897, acc: 55.47%, op_acc: 42.19%] [G loss: 0.904306]\n",
      "epoch:19 step:15308[D loss: 0.410869, acc: 63.28%, op_acc: 41.41%] [G loss: 0.897208]\n",
      "epoch:19 step:15309[D loss: 0.385662, acc: 67.19%, op_acc: 44.53%] [G loss: 0.929813]\n",
      "epoch:19 step:15310[D loss: 0.439624, acc: 58.59%, op_acc: 32.81%] [G loss: 0.966750]\n",
      "epoch:19 step:15311[D loss: 0.449031, acc: 59.38%, op_acc: 32.81%] [G loss: 0.819582]\n",
      "epoch:19 step:15312[D loss: 0.402332, acc: 65.62%, op_acc: 39.84%] [G loss: 0.826738]\n",
      "epoch:19 step:15313[D loss: 0.428320, acc: 62.50%, op_acc: 35.94%] [G loss: 0.882031]\n",
      "epoch:19 step:15314[D loss: 0.450755, acc: 54.69%, op_acc: 37.50%] [G loss: 0.831866]\n",
      "epoch:19 step:15315[D loss: 0.400442, acc: 67.97%, op_acc: 35.16%] [G loss: 0.861725]\n",
      "epoch:19 step:15316[D loss: 0.411163, acc: 65.62%, op_acc: 41.41%] [G loss: 0.866093]\n",
      "epoch:19 step:15317[D loss: 0.407800, acc: 64.06%, op_acc: 38.28%] [G loss: 0.918736]\n",
      "epoch:19 step:15318[D loss: 0.422790, acc: 62.50%, op_acc: 42.97%] [G loss: 0.884471]\n",
      "epoch:19 step:15319[D loss: 0.489819, acc: 46.88%, op_acc: 33.59%] [G loss: 0.827558]\n",
      "epoch:19 step:15320[D loss: 0.439731, acc: 57.03%, op_acc: 29.69%] [G loss: 0.822036]\n",
      "epoch:19 step:15321[D loss: 0.440511, acc: 54.69%, op_acc: 38.28%] [G loss: 0.853425]\n",
      "epoch:19 step:15322[D loss: 0.427631, acc: 61.72%, op_acc: 39.06%] [G loss: 0.895979]\n",
      "epoch:19 step:15323[D loss: 0.410285, acc: 64.06%, op_acc: 43.75%] [G loss: 0.907562]\n",
      "epoch:19 step:15324[D loss: 0.427691, acc: 60.16%, op_acc: 38.28%] [G loss: 0.808841]\n",
      "epoch:19 step:15325[D loss: 0.424247, acc: 60.94%, op_acc: 44.53%] [G loss: 0.921705]\n",
      "epoch:19 step:15326[D loss: 0.413373, acc: 64.84%, op_acc: 42.19%] [G loss: 0.914432]\n",
      "epoch:19 step:15327[D loss: 0.427948, acc: 60.94%, op_acc: 36.72%] [G loss: 0.848794]\n",
      "epoch:19 step:15328[D loss: 0.454090, acc: 48.44%, op_acc: 39.84%] [G loss: 0.835818]\n",
      "epoch:19 step:15329[D loss: 0.437543, acc: 50.00%, op_acc: 37.50%] [G loss: 0.897857]\n",
      "epoch:19 step:15330[D loss: 0.470178, acc: 57.81%, op_acc: 33.59%] [G loss: 0.850518]\n",
      "epoch:19 step:15331[D loss: 0.429362, acc: 58.59%, op_acc: 40.62%] [G loss: 0.922461]\n",
      "epoch:19 step:15332[D loss: 0.446895, acc: 49.22%, op_acc: 35.16%] [G loss: 0.873745]\n",
      "epoch:19 step:15333[D loss: 0.413953, acc: 59.38%, op_acc: 38.28%] [G loss: 0.884954]\n",
      "epoch:19 step:15334[D loss: 0.406990, acc: 70.31%, op_acc: 32.81%] [G loss: 0.893750]\n",
      "epoch:19 step:15335[D loss: 0.426412, acc: 62.50%, op_acc: 30.47%] [G loss: 0.868535]\n",
      "epoch:19 step:15336[D loss: 0.412116, acc: 56.25%, op_acc: 40.62%] [G loss: 0.868390]\n",
      "epoch:19 step:15337[D loss: 0.472921, acc: 57.81%, op_acc: 34.38%] [G loss: 0.834805]\n",
      "epoch:19 step:15338[D loss: 0.448454, acc: 47.66%, op_acc: 41.41%] [G loss: 0.850392]\n",
      "epoch:19 step:15339[D loss: 0.407225, acc: 63.28%, op_acc: 42.19%] [G loss: 0.961416]\n",
      "epoch:19 step:15340[D loss: 0.433082, acc: 60.16%, op_acc: 43.75%] [G loss: 0.843748]\n",
      "epoch:19 step:15341[D loss: 0.422534, acc: 53.12%, op_acc: 39.84%] [G loss: 0.816145]\n",
      "epoch:19 step:15342[D loss: 0.439802, acc: 59.38%, op_acc: 36.72%] [G loss: 0.823223]\n",
      "epoch:19 step:15343[D loss: 0.410842, acc: 62.50%, op_acc: 39.84%] [G loss: 0.904019]\n",
      "epoch:19 step:15344[D loss: 0.449698, acc: 57.03%, op_acc: 30.47%] [G loss: 0.867836]\n",
      "epoch:19 step:15345[D loss: 0.446230, acc: 56.25%, op_acc: 39.06%] [G loss: 0.925678]\n",
      "epoch:19 step:15346[D loss: 0.401420, acc: 62.50%, op_acc: 41.41%] [G loss: 0.862183]\n",
      "epoch:19 step:15347[D loss: 0.427789, acc: 62.50%, op_acc: 37.50%] [G loss: 0.927310]\n",
      "epoch:19 step:15348[D loss: 0.418430, acc: 57.81%, op_acc: 35.94%] [G loss: 0.924060]\n",
      "epoch:19 step:15349[D loss: 0.431536, acc: 64.06%, op_acc: 35.16%] [G loss: 0.814369]\n",
      "epoch:19 step:15350[D loss: 0.436066, acc: 52.34%, op_acc: 40.62%] [G loss: 0.871057]\n",
      "epoch:19 step:15351[D loss: 0.458961, acc: 53.12%, op_acc: 40.62%] [G loss: 0.935127]\n",
      "epoch:19 step:15352[D loss: 0.437752, acc: 58.59%, op_acc: 37.50%] [G loss: 0.890703]\n",
      "epoch:19 step:15353[D loss: 0.434210, acc: 60.94%, op_acc: 35.16%] [G loss: 0.882288]\n",
      "epoch:19 step:15354[D loss: 0.448282, acc: 60.94%, op_acc: 35.94%] [G loss: 0.864451]\n",
      "epoch:19 step:15355[D loss: 0.414520, acc: 64.06%, op_acc: 39.84%] [G loss: 0.909966]\n",
      "epoch:19 step:15356[D loss: 0.436265, acc: 57.81%, op_acc: 39.84%] [G loss: 0.874491]\n",
      "epoch:19 step:15357[D loss: 0.419668, acc: 60.16%, op_acc: 36.72%] [G loss: 0.921865]\n",
      "epoch:19 step:15358[D loss: 0.405127, acc: 61.72%, op_acc: 37.50%] [G loss: 0.885668]\n",
      "epoch:19 step:15359[D loss: 0.417409, acc: 62.50%, op_acc: 40.62%] [G loss: 0.974552]\n",
      "epoch:19 step:15360[D loss: 0.459591, acc: 52.34%, op_acc: 32.03%] [G loss: 0.799129]\n",
      "epoch:19 step:15361[D loss: 0.427852, acc: 66.41%, op_acc: 35.16%] [G loss: 0.871039]\n",
      "epoch:19 step:15362[D loss: 0.422047, acc: 64.84%, op_acc: 35.94%] [G loss: 0.868631]\n",
      "epoch:19 step:15363[D loss: 0.421949, acc: 59.38%, op_acc: 39.06%] [G loss: 0.840485]\n",
      "epoch:19 step:15364[D loss: 0.421050, acc: 61.72%, op_acc: 33.59%] [G loss: 0.901190]\n",
      "epoch:19 step:15365[D loss: 0.395106, acc: 70.31%, op_acc: 40.62%] [G loss: 0.858339]\n",
      "epoch:19 step:15366[D loss: 0.442431, acc: 53.91%, op_acc: 34.38%] [G loss: 0.907388]\n",
      "epoch:19 step:15367[D loss: 0.443713, acc: 57.03%, op_acc: 39.84%] [G loss: 0.829716]\n",
      "epoch:19 step:15368[D loss: 0.400356, acc: 66.41%, op_acc: 39.06%] [G loss: 0.949707]\n",
      "epoch:19 step:15369[D loss: 0.414701, acc: 61.72%, op_acc: 40.62%] [G loss: 0.987885]\n",
      "epoch:19 step:15370[D loss: 0.421586, acc: 64.84%, op_acc: 40.62%] [G loss: 0.985205]\n",
      "epoch:19 step:15371[D loss: 0.429401, acc: 60.16%, op_acc: 40.62%] [G loss: 0.911626]\n",
      "epoch:19 step:15372[D loss: 0.447998, acc: 54.69%, op_acc: 38.28%] [G loss: 0.871934]\n",
      "epoch:19 step:15373[D loss: 0.435139, acc: 54.69%, op_acc: 41.41%] [G loss: 0.830716]\n",
      "epoch:19 step:15374[D loss: 0.428742, acc: 58.59%, op_acc: 39.06%] [G loss: 0.848940]\n",
      "epoch:19 step:15375[D loss: 0.412413, acc: 53.12%, op_acc: 44.53%] [G loss: 0.969111]\n",
      "epoch:19 step:15376[D loss: 0.434442, acc: 63.28%, op_acc: 28.91%] [G loss: 0.882981]\n",
      "epoch:19 step:15377[D loss: 0.418433, acc: 60.94%, op_acc: 39.84%] [G loss: 0.851187]\n",
      "epoch:19 step:15378[D loss: 0.470562, acc: 48.44%, op_acc: 37.50%] [G loss: 0.898665]\n",
      "epoch:19 step:15379[D loss: 0.415475, acc: 57.81%, op_acc: 40.62%] [G loss: 0.830066]\n",
      "epoch:19 step:15380[D loss: 0.410364, acc: 60.16%, op_acc: 40.62%] [G loss: 0.832099]\n",
      "epoch:19 step:15381[D loss: 0.427758, acc: 64.06%, op_acc: 35.94%] [G loss: 0.854938]\n",
      "epoch:19 step:15382[D loss: 0.408565, acc: 62.50%, op_acc: 39.84%] [G loss: 0.830183]\n",
      "epoch:19 step:15383[D loss: 0.443434, acc: 53.91%, op_acc: 39.06%] [G loss: 0.834229]\n",
      "epoch:19 step:15384[D loss: 0.384966, acc: 68.75%, op_acc: 42.19%] [G loss: 0.987368]\n",
      "epoch:19 step:15385[D loss: 0.427326, acc: 56.25%, op_acc: 38.28%] [G loss: 0.825546]\n",
      "epoch:19 step:15386[D loss: 0.435078, acc: 60.16%, op_acc: 38.28%] [G loss: 0.863546]\n",
      "epoch:19 step:15387[D loss: 0.447031, acc: 61.72%, op_acc: 32.81%] [G loss: 0.840253]\n",
      "epoch:19 step:15388[D loss: 0.417369, acc: 62.50%, op_acc: 44.53%] [G loss: 0.915866]\n",
      "epoch:19 step:15389[D loss: 0.435028, acc: 60.16%, op_acc: 32.81%] [G loss: 0.904187]\n",
      "epoch:19 step:15390[D loss: 0.421216, acc: 60.16%, op_acc: 42.19%] [G loss: 0.861061]\n",
      "epoch:19 step:15391[D loss: 0.465154, acc: 51.56%, op_acc: 32.03%] [G loss: 0.892044]\n",
      "epoch:19 step:15392[D loss: 0.422992, acc: 57.03%, op_acc: 37.50%] [G loss: 0.817128]\n",
      "epoch:19 step:15393[D loss: 0.436468, acc: 53.12%, op_acc: 42.19%] [G loss: 0.841045]\n",
      "epoch:19 step:15394[D loss: 0.422468, acc: 60.94%, op_acc: 42.19%] [G loss: 0.773987]\n",
      "epoch:19 step:15395[D loss: 0.416564, acc: 57.81%, op_acc: 41.41%] [G loss: 0.916641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15396[D loss: 0.454244, acc: 56.25%, op_acc: 37.50%] [G loss: 0.914585]\n",
      "epoch:19 step:15397[D loss: 0.433373, acc: 64.06%, op_acc: 32.81%] [G loss: 0.880630]\n",
      "epoch:19 step:15398[D loss: 0.408405, acc: 60.94%, op_acc: 39.06%] [G loss: 0.889771]\n",
      "epoch:19 step:15399[D loss: 0.422123, acc: 66.41%, op_acc: 32.03%] [G loss: 0.901590]\n",
      "epoch:19 step:15400[D loss: 0.432594, acc: 56.25%, op_acc: 39.84%] [G loss: 0.929243]\n",
      "epoch:19 step:15401[D loss: 0.430327, acc: 56.25%, op_acc: 35.94%] [G loss: 1.002787]\n",
      "epoch:19 step:15402[D loss: 0.420749, acc: 60.16%, op_acc: 35.94%] [G loss: 0.911397]\n",
      "epoch:19 step:15403[D loss: 0.424597, acc: 62.50%, op_acc: 39.84%] [G loss: 0.868394]\n",
      "epoch:19 step:15404[D loss: 0.432612, acc: 60.16%, op_acc: 41.41%] [G loss: 0.929673]\n",
      "epoch:19 step:15405[D loss: 0.422367, acc: 55.47%, op_acc: 39.84%] [G loss: 0.902041]\n",
      "epoch:19 step:15406[D loss: 0.404418, acc: 60.16%, op_acc: 39.84%] [G loss: 0.929745]\n",
      "epoch:19 step:15407[D loss: 0.420941, acc: 64.06%, op_acc: 39.84%] [G loss: 0.798198]\n",
      "epoch:19 step:15408[D loss: 0.399276, acc: 64.84%, op_acc: 40.62%] [G loss: 0.999490]\n",
      "epoch:19 step:15409[D loss: 0.448367, acc: 57.03%, op_acc: 39.84%] [G loss: 0.790547]\n",
      "epoch:19 step:15410[D loss: 0.451358, acc: 51.56%, op_acc: 40.62%] [G loss: 0.806691]\n",
      "epoch:19 step:15411[D loss: 0.378048, acc: 71.09%, op_acc: 43.75%] [G loss: 0.921660]\n",
      "epoch:19 step:15412[D loss: 0.441069, acc: 47.66%, op_acc: 37.50%] [G loss: 0.884624]\n",
      "epoch:19 step:15413[D loss: 0.443766, acc: 57.81%, op_acc: 38.28%] [G loss: 0.861837]\n",
      "epoch:19 step:15414[D loss: 0.457376, acc: 53.12%, op_acc: 38.28%] [G loss: 0.874692]\n",
      "epoch:19 step:15415[D loss: 0.413607, acc: 64.06%, op_acc: 40.62%] [G loss: 0.838704]\n",
      "epoch:19 step:15416[D loss: 0.468986, acc: 53.12%, op_acc: 32.81%] [G loss: 0.839877]\n",
      "epoch:19 step:15417[D loss: 0.452661, acc: 60.94%, op_acc: 32.81%] [G loss: 0.859817]\n",
      "epoch:19 step:15418[D loss: 0.401678, acc: 65.62%, op_acc: 37.50%] [G loss: 0.895550]\n",
      "epoch:19 step:15419[D loss: 0.411297, acc: 64.84%, op_acc: 40.62%] [G loss: 0.817835]\n",
      "epoch:19 step:15420[D loss: 0.411775, acc: 64.06%, op_acc: 31.25%] [G loss: 0.831278]\n",
      "epoch:19 step:15421[D loss: 0.425043, acc: 60.16%, op_acc: 38.28%] [G loss: 0.865513]\n",
      "epoch:19 step:15422[D loss: 0.412703, acc: 65.62%, op_acc: 33.59%] [G loss: 0.805341]\n",
      "epoch:19 step:15423[D loss: 0.458568, acc: 56.25%, op_acc: 32.03%] [G loss: 0.835308]\n",
      "epoch:19 step:15424[D loss: 0.421239, acc: 60.94%, op_acc: 40.62%] [G loss: 0.940844]\n",
      "epoch:19 step:15425[D loss: 0.397794, acc: 71.09%, op_acc: 39.06%] [G loss: 0.928516]\n",
      "epoch:19 step:15426[D loss: 0.386503, acc: 71.09%, op_acc: 37.50%] [G loss: 0.909079]\n",
      "epoch:19 step:15427[D loss: 0.436448, acc: 48.44%, op_acc: 39.84%] [G loss: 0.801897]\n",
      "epoch:19 step:15428[D loss: 0.414524, acc: 66.41%, op_acc: 42.19%] [G loss: 0.937379]\n",
      "epoch:19 step:15429[D loss: 0.436692, acc: 61.72%, op_acc: 35.16%] [G loss: 0.892185]\n",
      "epoch:19 step:15430[D loss: 0.420568, acc: 60.94%, op_acc: 39.06%] [G loss: 0.962554]\n",
      "epoch:19 step:15431[D loss: 0.446212, acc: 56.25%, op_acc: 39.84%] [G loss: 0.969650]\n",
      "epoch:19 step:15432[D loss: 0.449180, acc: 57.03%, op_acc: 38.28%] [G loss: 1.028670]\n",
      "epoch:19 step:15433[D loss: 0.424181, acc: 62.50%, op_acc: 38.28%] [G loss: 0.890545]\n",
      "epoch:19 step:15434[D loss: 0.398506, acc: 60.94%, op_acc: 35.94%] [G loss: 0.893324]\n",
      "epoch:19 step:15435[D loss: 0.424433, acc: 60.94%, op_acc: 38.28%] [G loss: 0.945846]\n",
      "epoch:19 step:15436[D loss: 0.412112, acc: 64.06%, op_acc: 37.50%] [G loss: 0.898716]\n",
      "epoch:19 step:15437[D loss: 0.404799, acc: 60.16%, op_acc: 40.62%] [G loss: 0.933269]\n",
      "epoch:19 step:15438[D loss: 0.445654, acc: 59.38%, op_acc: 32.81%] [G loss: 0.968237]\n",
      "epoch:19 step:15439[D loss: 0.413196, acc: 64.06%, op_acc: 37.50%] [G loss: 0.928688]\n",
      "epoch:19 step:15440[D loss: 0.427577, acc: 57.03%, op_acc: 36.72%] [G loss: 0.901627]\n",
      "epoch:19 step:15441[D loss: 0.401940, acc: 66.41%, op_acc: 39.84%] [G loss: 1.012745]\n",
      "epoch:19 step:15442[D loss: 0.381244, acc: 62.50%, op_acc: 42.19%] [G loss: 0.972032]\n",
      "epoch:19 step:15443[D loss: 0.447681, acc: 61.72%, op_acc: 32.03%] [G loss: 0.950872]\n",
      "epoch:19 step:15444[D loss: 0.418309, acc: 68.75%, op_acc: 41.41%] [G loss: 0.872219]\n",
      "epoch:19 step:15445[D loss: 0.464795, acc: 47.66%, op_acc: 35.94%] [G loss: 0.834550]\n",
      "epoch:19 step:15446[D loss: 0.405895, acc: 57.03%, op_acc: 42.97%] [G loss: 0.883526]\n",
      "epoch:19 step:15447[D loss: 0.435008, acc: 57.03%, op_acc: 39.84%] [G loss: 0.888899]\n",
      "epoch:19 step:15448[D loss: 0.457921, acc: 52.34%, op_acc: 32.03%] [G loss: 0.882526]\n",
      "epoch:19 step:15449[D loss: 0.407250, acc: 65.62%, op_acc: 36.72%] [G loss: 0.948302]\n",
      "epoch:19 step:15450[D loss: 0.435434, acc: 55.47%, op_acc: 40.62%] [G loss: 0.903385]\n",
      "epoch:19 step:15451[D loss: 0.443869, acc: 55.47%, op_acc: 38.28%] [G loss: 0.972675]\n",
      "epoch:19 step:15452[D loss: 0.434804, acc: 55.47%, op_acc: 39.84%] [G loss: 0.886581]\n",
      "epoch:19 step:15453[D loss: 0.443618, acc: 54.69%, op_acc: 36.72%] [G loss: 0.802594]\n",
      "epoch:19 step:15454[D loss: 0.414195, acc: 62.50%, op_acc: 42.19%] [G loss: 0.976440]\n",
      "epoch:19 step:15455[D loss: 0.441284, acc: 56.25%, op_acc: 42.19%] [G loss: 0.903023]\n",
      "epoch:19 step:15456[D loss: 0.457016, acc: 55.47%, op_acc: 34.38%] [G loss: 0.912074]\n",
      "epoch:19 step:15457[D loss: 0.383426, acc: 68.75%, op_acc: 46.09%] [G loss: 0.922993]\n",
      "epoch:19 step:15458[D loss: 0.455730, acc: 56.25%, op_acc: 36.72%] [G loss: 0.869877]\n",
      "epoch:19 step:15459[D loss: 0.429174, acc: 63.28%, op_acc: 37.50%] [G loss: 0.920783]\n",
      "epoch:19 step:15460[D loss: 0.456422, acc: 49.22%, op_acc: 32.03%] [G loss: 0.891314]\n",
      "epoch:19 step:15461[D loss: 0.457191, acc: 54.69%, op_acc: 34.38%] [G loss: 0.885527]\n",
      "epoch:19 step:15462[D loss: 0.425116, acc: 57.81%, op_acc: 40.62%] [G loss: 0.868569]\n",
      "epoch:19 step:15463[D loss: 0.464406, acc: 49.22%, op_acc: 33.59%] [G loss: 0.874393]\n",
      "epoch:19 step:15464[D loss: 0.435219, acc: 53.91%, op_acc: 40.62%] [G loss: 0.900807]\n",
      "epoch:19 step:15465[D loss: 0.412377, acc: 60.16%, op_acc: 42.97%] [G loss: 0.918990]\n",
      "epoch:19 step:15466[D loss: 0.406678, acc: 58.59%, op_acc: 39.84%] [G loss: 0.915417]\n",
      "epoch:19 step:15467[D loss: 0.395956, acc: 73.44%, op_acc: 41.41%] [G loss: 0.974586]\n",
      "epoch:19 step:15468[D loss: 0.454199, acc: 52.34%, op_acc: 39.06%] [G loss: 0.926401]\n",
      "epoch:19 step:15469[D loss: 0.381811, acc: 66.41%, op_acc: 43.75%] [G loss: 0.863745]\n",
      "epoch:19 step:15470[D loss: 0.451744, acc: 51.56%, op_acc: 35.94%] [G loss: 0.904287]\n",
      "epoch:19 step:15471[D loss: 0.432082, acc: 61.72%, op_acc: 34.38%] [G loss: 0.894392]\n",
      "epoch:19 step:15472[D loss: 0.424790, acc: 64.84%, op_acc: 37.50%] [G loss: 0.850788]\n",
      "epoch:19 step:15473[D loss: 0.414911, acc: 61.72%, op_acc: 39.06%] [G loss: 0.925856]\n",
      "epoch:19 step:15474[D loss: 0.461769, acc: 57.03%, op_acc: 38.28%] [G loss: 0.791524]\n",
      "epoch:19 step:15475[D loss: 0.410578, acc: 62.50%, op_acc: 41.41%] [G loss: 0.886108]\n",
      "epoch:19 step:15476[D loss: 0.422114, acc: 60.16%, op_acc: 36.72%] [G loss: 0.883528]\n",
      "epoch:19 step:15477[D loss: 0.466362, acc: 49.22%, op_acc: 33.59%] [G loss: 0.959308]\n",
      "epoch:19 step:15478[D loss: 0.452946, acc: 58.59%, op_acc: 33.59%] [G loss: 0.890599]\n",
      "epoch:19 step:15479[D loss: 0.460514, acc: 57.81%, op_acc: 35.16%] [G loss: 0.975885]\n",
      "epoch:19 step:15480[D loss: 0.424909, acc: 56.25%, op_acc: 42.19%] [G loss: 0.859047]\n",
      "epoch:19 step:15481[D loss: 0.432119, acc: 60.16%, op_acc: 43.75%] [G loss: 0.949754]\n",
      "epoch:19 step:15482[D loss: 0.413541, acc: 67.19%, op_acc: 36.72%] [G loss: 0.929844]\n",
      "epoch:19 step:15483[D loss: 0.397318, acc: 67.19%, op_acc: 44.53%] [G loss: 0.960869]\n",
      "epoch:19 step:15484[D loss: 0.419915, acc: 57.03%, op_acc: 38.28%] [G loss: 0.882241]\n",
      "epoch:19 step:15485[D loss: 0.413715, acc: 65.62%, op_acc: 38.28%] [G loss: 0.889983]\n",
      "epoch:19 step:15486[D loss: 0.416990, acc: 64.84%, op_acc: 42.19%] [G loss: 0.927380]\n",
      "epoch:19 step:15487[D loss: 0.407388, acc: 65.62%, op_acc: 41.41%] [G loss: 0.918145]\n",
      "epoch:19 step:15488[D loss: 0.436593, acc: 55.47%, op_acc: 37.50%] [G loss: 0.880366]\n",
      "epoch:19 step:15489[D loss: 0.430735, acc: 59.38%, op_acc: 39.84%] [G loss: 0.903525]\n",
      "epoch:19 step:15490[D loss: 0.427745, acc: 62.50%, op_acc: 37.50%] [G loss: 0.883913]\n",
      "epoch:19 step:15491[D loss: 0.442160, acc: 49.22%, op_acc: 38.28%] [G loss: 0.820487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15492[D loss: 0.394481, acc: 63.28%, op_acc: 39.84%] [G loss: 0.837151]\n",
      "epoch:19 step:15493[D loss: 0.435890, acc: 57.03%, op_acc: 39.84%] [G loss: 0.796367]\n",
      "epoch:19 step:15494[D loss: 0.442312, acc: 57.03%, op_acc: 38.28%] [G loss: 0.866833]\n",
      "epoch:19 step:15495[D loss: 0.416388, acc: 67.97%, op_acc: 35.16%] [G loss: 0.828169]\n",
      "epoch:19 step:15496[D loss: 0.446456, acc: 50.00%, op_acc: 39.06%] [G loss: 0.825035]\n",
      "epoch:19 step:15497[D loss: 0.414300, acc: 69.53%, op_acc: 34.38%] [G loss: 0.912044]\n",
      "epoch:19 step:15498[D loss: 0.434938, acc: 57.81%, op_acc: 38.28%] [G loss: 0.877859]\n",
      "epoch:19 step:15499[D loss: 0.421519, acc: 56.25%, op_acc: 42.19%] [G loss: 0.856784]\n",
      "epoch:19 step:15500[D loss: 0.430229, acc: 57.03%, op_acc: 38.28%] [G loss: 0.884334]\n",
      "epoch:19 step:15501[D loss: 0.413539, acc: 59.38%, op_acc: 42.97%] [G loss: 0.866415]\n",
      "epoch:19 step:15502[D loss: 0.405190, acc: 63.28%, op_acc: 45.31%] [G loss: 0.853509]\n",
      "epoch:19 step:15503[D loss: 0.406226, acc: 59.38%, op_acc: 42.97%] [G loss: 0.886637]\n",
      "epoch:19 step:15504[D loss: 0.461775, acc: 56.25%, op_acc: 31.25%] [G loss: 0.931838]\n",
      "epoch:19 step:15505[D loss: 0.431405, acc: 67.97%, op_acc: 34.38%] [G loss: 0.836146]\n",
      "epoch:19 step:15506[D loss: 0.439490, acc: 57.03%, op_acc: 38.28%] [G loss: 0.844541]\n",
      "epoch:19 step:15507[D loss: 0.399712, acc: 66.41%, op_acc: 42.19%] [G loss: 0.939846]\n",
      "epoch:19 step:15508[D loss: 0.464088, acc: 51.56%, op_acc: 33.59%] [G loss: 0.896438]\n",
      "epoch:19 step:15509[D loss: 0.422446, acc: 55.47%, op_acc: 39.06%] [G loss: 0.882911]\n",
      "epoch:19 step:15510[D loss: 0.430388, acc: 61.72%, op_acc: 39.84%] [G loss: 0.871632]\n",
      "epoch:19 step:15511[D loss: 0.440183, acc: 60.16%, op_acc: 38.28%] [G loss: 0.923317]\n",
      "epoch:19 step:15512[D loss: 0.446005, acc: 48.44%, op_acc: 33.59%] [G loss: 0.885734]\n",
      "epoch:19 step:15513[D loss: 0.428317, acc: 55.47%, op_acc: 39.06%] [G loss: 0.885216]\n",
      "epoch:19 step:15514[D loss: 0.420695, acc: 58.59%, op_acc: 39.84%] [G loss: 0.869136]\n",
      "epoch:19 step:15515[D loss: 0.449927, acc: 55.47%, op_acc: 39.06%] [G loss: 0.907244]\n",
      "epoch:19 step:15516[D loss: 0.477333, acc: 48.44%, op_acc: 34.38%] [G loss: 0.866520]\n",
      "epoch:19 step:15517[D loss: 0.430750, acc: 58.59%, op_acc: 38.28%] [G loss: 0.889756]\n",
      "epoch:19 step:15518[D loss: 0.407701, acc: 58.59%, op_acc: 43.75%] [G loss: 0.963224]\n",
      "epoch:19 step:15519[D loss: 0.438976, acc: 50.00%, op_acc: 35.94%] [G loss: 0.831974]\n",
      "epoch:19 step:15520[D loss: 0.436916, acc: 59.38%, op_acc: 37.50%] [G loss: 0.911297]\n",
      "epoch:19 step:15521[D loss: 0.410262, acc: 60.16%, op_acc: 41.41%] [G loss: 0.837183]\n",
      "epoch:19 step:15522[D loss: 0.432507, acc: 57.03%, op_acc: 39.84%] [G loss: 0.836999]\n",
      "epoch:19 step:15523[D loss: 0.446558, acc: 59.38%, op_acc: 39.06%] [G loss: 0.943275]\n",
      "epoch:19 step:15524[D loss: 0.438193, acc: 54.69%, op_acc: 39.06%] [G loss: 0.868792]\n",
      "epoch:19 step:15525[D loss: 0.438206, acc: 62.50%, op_acc: 33.59%] [G loss: 0.864529]\n",
      "epoch:19 step:15526[D loss: 0.389446, acc: 66.41%, op_acc: 43.75%] [G loss: 0.887955]\n",
      "epoch:19 step:15527[D loss: 0.430040, acc: 57.03%, op_acc: 42.19%] [G loss: 0.931190]\n",
      "epoch:19 step:15528[D loss: 0.425374, acc: 53.91%, op_acc: 42.97%] [G loss: 0.805577]\n",
      "epoch:19 step:15529[D loss: 0.404862, acc: 72.66%, op_acc: 32.81%] [G loss: 0.909549]\n",
      "epoch:19 step:15530[D loss: 0.428840, acc: 64.06%, op_acc: 39.84%] [G loss: 0.900234]\n",
      "epoch:19 step:15531[D loss: 0.452994, acc: 54.69%, op_acc: 38.28%] [G loss: 0.896885]\n",
      "epoch:19 step:15532[D loss: 0.425033, acc: 62.50%, op_acc: 38.28%] [G loss: 0.896496]\n",
      "epoch:19 step:15533[D loss: 0.412078, acc: 62.50%, op_acc: 35.94%] [G loss: 0.849444]\n",
      "epoch:19 step:15534[D loss: 0.437668, acc: 54.69%, op_acc: 36.72%] [G loss: 0.900200]\n",
      "epoch:19 step:15535[D loss: 0.411364, acc: 60.94%, op_acc: 40.62%] [G loss: 0.930859]\n",
      "epoch:19 step:15536[D loss: 0.426736, acc: 55.47%, op_acc: 41.41%] [G loss: 0.910273]\n",
      "epoch:19 step:15537[D loss: 0.423242, acc: 61.72%, op_acc: 40.62%] [G loss: 0.917591]\n",
      "epoch:19 step:15538[D loss: 0.407477, acc: 66.41%, op_acc: 43.75%] [G loss: 0.858332]\n",
      "epoch:19 step:15539[D loss: 0.414454, acc: 62.50%, op_acc: 35.94%] [G loss: 0.881148]\n",
      "epoch:19 step:15540[D loss: 0.435991, acc: 64.84%, op_acc: 39.06%] [G loss: 0.893139]\n",
      "epoch:19 step:15541[D loss: 0.429509, acc: 55.47%, op_acc: 34.38%] [G loss: 0.834947]\n",
      "epoch:19 step:15542[D loss: 0.420125, acc: 66.41%, op_acc: 39.06%] [G loss: 0.801510]\n",
      "epoch:19 step:15543[D loss: 0.435039, acc: 50.78%, op_acc: 38.28%] [G loss: 0.862734]\n",
      "epoch:19 step:15544[D loss: 0.475352, acc: 51.56%, op_acc: 30.47%] [G loss: 0.853711]\n",
      "epoch:19 step:15545[D loss: 0.445982, acc: 56.25%, op_acc: 37.50%] [G loss: 0.915024]\n",
      "epoch:19 step:15546[D loss: 0.447088, acc: 56.25%, op_acc: 35.94%] [G loss: 0.807416]\n",
      "epoch:19 step:15547[D loss: 0.431342, acc: 62.50%, op_acc: 36.72%] [G loss: 0.967781]\n",
      "epoch:19 step:15548[D loss: 0.445103, acc: 57.03%, op_acc: 37.50%] [G loss: 0.787692]\n",
      "epoch:19 step:15549[D loss: 0.390523, acc: 62.50%, op_acc: 45.31%] [G loss: 0.934141]\n",
      "epoch:19 step:15550[D loss: 0.424468, acc: 60.94%, op_acc: 38.28%] [G loss: 0.876945]\n",
      "epoch:19 step:15551[D loss: 0.408078, acc: 61.72%, op_acc: 41.41%] [G loss: 0.880669]\n",
      "epoch:19 step:15552[D loss: 0.436843, acc: 50.78%, op_acc: 39.84%] [G loss: 0.847863]\n",
      "epoch:19 step:15553[D loss: 0.459879, acc: 51.56%, op_acc: 35.16%] [G loss: 0.913761]\n",
      "epoch:19 step:15554[D loss: 0.441813, acc: 49.22%, op_acc: 42.97%] [G loss: 0.821481]\n",
      "epoch:19 step:15555[D loss: 0.433296, acc: 57.03%, op_acc: 37.50%] [G loss: 0.956013]\n",
      "epoch:19 step:15556[D loss: 0.426623, acc: 53.91%, op_acc: 38.28%] [G loss: 0.843325]\n",
      "epoch:19 step:15557[D loss: 0.441837, acc: 57.03%, op_acc: 38.28%] [G loss: 0.814480]\n",
      "epoch:19 step:15558[D loss: 0.398456, acc: 66.41%, op_acc: 43.75%] [G loss: 0.983382]\n",
      "epoch:19 step:15559[D loss: 0.427512, acc: 57.81%, op_acc: 39.84%] [G loss: 0.917764]\n",
      "epoch:19 step:15560[D loss: 0.419011, acc: 56.25%, op_acc: 35.94%] [G loss: 0.889310]\n",
      "epoch:19 step:15561[D loss: 0.417560, acc: 64.84%, op_acc: 36.72%] [G loss: 0.900843]\n",
      "epoch:19 step:15562[D loss: 0.422422, acc: 64.84%, op_acc: 35.94%] [G loss: 0.834121]\n",
      "epoch:19 step:15563[D loss: 0.475843, acc: 54.69%, op_acc: 29.69%] [G loss: 0.866587]\n",
      "epoch:19 step:15564[D loss: 0.407060, acc: 67.19%, op_acc: 40.62%] [G loss: 0.933616]\n",
      "epoch:19 step:15565[D loss: 0.436229, acc: 60.16%, op_acc: 34.38%] [G loss: 0.847306]\n",
      "epoch:19 step:15566[D loss: 0.463873, acc: 57.03%, op_acc: 32.81%] [G loss: 0.916416]\n",
      "epoch:19 step:15567[D loss: 0.451163, acc: 60.94%, op_acc: 35.94%] [G loss: 0.824418]\n",
      "epoch:19 step:15568[D loss: 0.417380, acc: 64.84%, op_acc: 42.97%] [G loss: 0.889506]\n",
      "epoch:19 step:15569[D loss: 0.415593, acc: 66.41%, op_acc: 38.28%] [G loss: 0.824575]\n",
      "epoch:19 step:15570[D loss: 0.412855, acc: 60.16%, op_acc: 46.88%] [G loss: 0.916286]\n",
      "epoch:19 step:15571[D loss: 0.434541, acc: 59.38%, op_acc: 35.94%] [G loss: 0.857227]\n",
      "epoch:19 step:15572[D loss: 0.423095, acc: 60.94%, op_acc: 39.84%] [G loss: 0.794099]\n",
      "epoch:19 step:15573[D loss: 0.424352, acc: 60.94%, op_acc: 39.06%] [G loss: 0.876311]\n",
      "epoch:19 step:15574[D loss: 0.447207, acc: 54.69%, op_acc: 35.94%] [G loss: 0.918596]\n",
      "epoch:19 step:15575[D loss: 0.405000, acc: 66.41%, op_acc: 35.16%] [G loss: 0.863167]\n",
      "epoch:19 step:15576[D loss: 0.431097, acc: 55.47%, op_acc: 40.62%] [G loss: 0.891326]\n",
      "epoch:19 step:15577[D loss: 0.405026, acc: 65.62%, op_acc: 36.72%] [G loss: 0.898009]\n",
      "epoch:19 step:15578[D loss: 0.442377, acc: 50.00%, op_acc: 38.28%] [G loss: 0.872286]\n",
      "epoch:19 step:15579[D loss: 0.433644, acc: 58.59%, op_acc: 39.06%] [G loss: 0.839068]\n",
      "epoch:19 step:15580[D loss: 0.432218, acc: 60.94%, op_acc: 37.50%] [G loss: 0.866964]\n",
      "epoch:19 step:15581[D loss: 0.416420, acc: 62.50%, op_acc: 38.28%] [G loss: 0.834136]\n",
      "epoch:19 step:15582[D loss: 0.443260, acc: 60.16%, op_acc: 34.38%] [G loss: 0.863127]\n",
      "epoch:19 step:15583[D loss: 0.397267, acc: 58.59%, op_acc: 45.31%] [G loss: 0.861940]\n",
      "epoch:19 step:15584[D loss: 0.452389, acc: 53.91%, op_acc: 35.16%] [G loss: 0.940086]\n",
      "epoch:19 step:15585[D loss: 0.447440, acc: 57.81%, op_acc: 37.50%] [G loss: 0.860470]\n",
      "epoch:19 step:15586[D loss: 0.473170, acc: 49.22%, op_acc: 28.91%] [G loss: 0.820333]\n",
      "epoch:19 step:15587[D loss: 0.438514, acc: 60.94%, op_acc: 35.16%] [G loss: 0.917925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:15588[D loss: 0.441390, acc: 56.25%, op_acc: 40.62%] [G loss: 0.942574]\n",
      "epoch:19 step:15589[D loss: 0.430729, acc: 57.03%, op_acc: 39.06%] [G loss: 0.877467]\n",
      "epoch:19 step:15590[D loss: 0.453338, acc: 57.81%, op_acc: 31.25%] [G loss: 0.864908]\n",
      "epoch:19 step:15591[D loss: 0.429229, acc: 62.50%, op_acc: 39.84%] [G loss: 0.937118]\n",
      "epoch:19 step:15592[D loss: 0.404355, acc: 66.41%, op_acc: 41.41%] [G loss: 0.876002]\n",
      "epoch:19 step:15593[D loss: 0.411608, acc: 64.06%, op_acc: 41.41%] [G loss: 0.884465]\n",
      "epoch:19 step:15594[D loss: 0.416024, acc: 65.62%, op_acc: 40.62%] [G loss: 0.810031]\n",
      "epoch:19 step:15595[D loss: 0.405917, acc: 61.72%, op_acc: 47.66%] [G loss: 0.812992]\n",
      "epoch:19 step:15596[D loss: 0.427171, acc: 59.38%, op_acc: 42.19%] [G loss: 0.919787]\n",
      "epoch:19 step:15597[D loss: 0.398135, acc: 65.62%, op_acc: 39.06%] [G loss: 0.882402]\n",
      "epoch:19 step:15598[D loss: 0.423071, acc: 63.28%, op_acc: 44.53%] [G loss: 0.891712]\n",
      "epoch:19 step:15599[D loss: 0.384326, acc: 68.75%, op_acc: 40.62%] [G loss: 0.931019]\n",
      "epoch:19 step:15600[D loss: 0.395262, acc: 64.06%, op_acc: 42.19%] [G loss: 0.857456]\n",
      "epoch:19 step:15601[D loss: 0.477126, acc: 50.78%, op_acc: 35.16%] [G loss: 0.810296]\n",
      "epoch:19 step:15602[D loss: 0.426744, acc: 57.81%, op_acc: 39.84%] [G loss: 0.849654]\n",
      "epoch:19 step:15603[D loss: 0.445706, acc: 47.66%, op_acc: 35.94%] [G loss: 0.925849]\n",
      "epoch:19 step:15604[D loss: 0.419657, acc: 54.69%, op_acc: 39.06%] [G loss: 0.834092]\n",
      "epoch:19 step:15605[D loss: 0.467392, acc: 57.03%, op_acc: 37.50%] [G loss: 0.905421]\n",
      "epoch:19 step:15606[D loss: 0.416134, acc: 66.41%, op_acc: 40.62%] [G loss: 0.739463]\n",
      "epoch:19 step:15607[D loss: 0.435193, acc: 50.00%, op_acc: 38.28%] [G loss: 0.886530]\n",
      "epoch:19 step:15608[D loss: 0.397695, acc: 67.19%, op_acc: 40.62%] [G loss: 0.832943]\n",
      "epoch:19 step:15609[D loss: 0.395045, acc: 66.41%, op_acc: 39.84%] [G loss: 0.924924]\n",
      "epoch:19 step:15610[D loss: 0.463302, acc: 58.59%, op_acc: 36.72%] [G loss: 0.938506]\n",
      "epoch:19 step:15611[D loss: 0.468080, acc: 51.56%, op_acc: 34.38%] [G loss: 0.893985]\n",
      "epoch:19 step:15612[D loss: 0.451644, acc: 56.25%, op_acc: 40.62%] [G loss: 0.892931]\n",
      "epoch:19 step:15613[D loss: 0.407678, acc: 61.72%, op_acc: 42.19%] [G loss: 0.825318]\n",
      "epoch:19 step:15614[D loss: 0.442243, acc: 60.16%, op_acc: 34.38%] [G loss: 0.863276]\n",
      "epoch:19 step:15615[D loss: 0.402093, acc: 64.06%, op_acc: 41.41%] [G loss: 0.882730]\n",
      "epoch:19 step:15616[D loss: 0.431307, acc: 60.16%, op_acc: 35.16%] [G loss: 0.924560]\n",
      "epoch:19 step:15617[D loss: 0.428256, acc: 62.50%, op_acc: 42.19%] [G loss: 0.848845]\n",
      "epoch:19 step:15618[D loss: 0.453344, acc: 57.03%, op_acc: 39.84%] [G loss: 0.823140]\n",
      "epoch:19 step:15619[D loss: 0.422894, acc: 62.50%, op_acc: 38.28%] [G loss: 0.811461]\n",
      "epoch:19 step:15620[D loss: 0.428275, acc: 57.81%, op_acc: 37.50%] [G loss: 0.863103]\n",
      "epoch:20 step:15621[D loss: 0.434513, acc: 62.50%, op_acc: 37.50%] [G loss: 0.817381]\n",
      "epoch:20 step:15622[D loss: 0.421314, acc: 62.50%, op_acc: 38.28%] [G loss: 0.851675]\n",
      "epoch:20 step:15623[D loss: 0.458134, acc: 53.91%, op_acc: 39.06%] [G loss: 0.880769]\n",
      "epoch:20 step:15624[D loss: 0.407748, acc: 60.16%, op_acc: 39.84%] [G loss: 0.867395]\n",
      "epoch:20 step:15625[D loss: 0.462705, acc: 50.78%, op_acc: 37.50%] [G loss: 0.914149]\n",
      "epoch:20 step:15626[D loss: 0.446162, acc: 57.03%, op_acc: 35.16%] [G loss: 0.871188]\n",
      "epoch:20 step:15627[D loss: 0.404542, acc: 62.50%, op_acc: 41.41%] [G loss: 0.912638]\n",
      "epoch:20 step:15628[D loss: 0.421845, acc: 59.38%, op_acc: 38.28%] [G loss: 0.912224]\n",
      "epoch:20 step:15629[D loss: 0.410161, acc: 61.72%, op_acc: 40.62%] [G loss: 0.842950]\n",
      "epoch:20 step:15630[D loss: 0.444061, acc: 67.19%, op_acc: 31.25%] [G loss: 0.901638]\n",
      "epoch:20 step:15631[D loss: 0.452266, acc: 57.03%, op_acc: 36.72%] [G loss: 0.894167]\n",
      "epoch:20 step:15632[D loss: 0.409834, acc: 64.84%, op_acc: 34.38%] [G loss: 0.843159]\n",
      "epoch:20 step:15633[D loss: 0.421183, acc: 60.16%, op_acc: 35.94%] [G loss: 0.871518]\n",
      "epoch:20 step:15634[D loss: 0.438038, acc: 57.81%, op_acc: 36.72%] [G loss: 0.835394]\n",
      "epoch:20 step:15635[D loss: 0.408780, acc: 62.50%, op_acc: 44.53%] [G loss: 0.924896]\n",
      "epoch:20 step:15636[D loss: 0.431176, acc: 57.81%, op_acc: 42.19%] [G loss: 1.010637]\n",
      "epoch:20 step:15637[D loss: 0.444876, acc: 57.03%, op_acc: 37.50%] [G loss: 0.932496]\n",
      "epoch:20 step:15638[D loss: 0.426426, acc: 51.56%, op_acc: 39.84%] [G loss: 0.864272]\n",
      "epoch:20 step:15639[D loss: 0.429006, acc: 60.94%, op_acc: 43.75%] [G loss: 0.833879]\n",
      "epoch:20 step:15640[D loss: 0.386208, acc: 66.41%, op_acc: 41.41%] [G loss: 0.864816]\n",
      "epoch:20 step:15641[D loss: 0.418806, acc: 60.94%, op_acc: 36.72%] [G loss: 0.904371]\n",
      "epoch:20 step:15642[D loss: 0.432427, acc: 58.59%, op_acc: 39.84%] [G loss: 0.863697]\n",
      "epoch:20 step:15643[D loss: 0.406464, acc: 65.62%, op_acc: 35.16%] [G loss: 0.903167]\n",
      "epoch:20 step:15644[D loss: 0.480467, acc: 51.56%, op_acc: 32.81%] [G loss: 0.899677]\n",
      "epoch:20 step:15645[D loss: 0.429021, acc: 55.47%, op_acc: 42.97%] [G loss: 0.866541]\n",
      "epoch:20 step:15646[D loss: 0.393711, acc: 69.53%, op_acc: 39.06%] [G loss: 0.868117]\n",
      "epoch:20 step:15647[D loss: 0.429645, acc: 49.22%, op_acc: 37.50%] [G loss: 0.953661]\n",
      "epoch:20 step:15648[D loss: 0.453600, acc: 57.03%, op_acc: 39.84%] [G loss: 0.862141]\n",
      "epoch:20 step:15649[D loss: 0.423830, acc: 58.59%, op_acc: 42.97%] [G loss: 0.881020]\n",
      "epoch:20 step:15650[D loss: 0.396101, acc: 64.84%, op_acc: 43.75%] [G loss: 0.895911]\n",
      "epoch:20 step:15651[D loss: 0.445946, acc: 63.28%, op_acc: 42.19%] [G loss: 0.855227]\n",
      "epoch:20 step:15652[D loss: 0.441108, acc: 57.81%, op_acc: 35.94%] [G loss: 0.878705]\n",
      "epoch:20 step:15653[D loss: 0.408899, acc: 58.59%, op_acc: 41.41%] [G loss: 0.934469]\n",
      "epoch:20 step:15654[D loss: 0.398043, acc: 65.62%, op_acc: 39.84%] [G loss: 0.907542]\n",
      "epoch:20 step:15655[D loss: 0.466330, acc: 59.38%, op_acc: 32.03%] [G loss: 0.860568]\n",
      "epoch:20 step:15656[D loss: 0.409403, acc: 57.03%, op_acc: 42.19%] [G loss: 0.858260]\n",
      "epoch:20 step:15657[D loss: 0.447251, acc: 54.69%, op_acc: 33.59%] [G loss: 0.952003]\n",
      "epoch:20 step:15658[D loss: 0.434414, acc: 54.69%, op_acc: 35.16%] [G loss: 0.831673]\n",
      "epoch:20 step:15659[D loss: 0.419357, acc: 57.81%, op_acc: 41.41%] [G loss: 0.902746]\n",
      "epoch:20 step:15660[D loss: 0.472283, acc: 55.47%, op_acc: 32.03%] [G loss: 0.841972]\n",
      "epoch:20 step:15661[D loss: 0.405358, acc: 60.16%, op_acc: 43.75%] [G loss: 0.831704]\n",
      "epoch:20 step:15662[D loss: 0.405865, acc: 61.72%, op_acc: 42.97%] [G loss: 0.845076]\n",
      "epoch:20 step:15663[D loss: 0.428825, acc: 57.03%, op_acc: 34.38%] [G loss: 0.944916]\n",
      "epoch:20 step:15664[D loss: 0.446253, acc: 55.47%, op_acc: 33.59%] [G loss: 0.887535]\n",
      "epoch:20 step:15665[D loss: 0.412008, acc: 64.06%, op_acc: 39.06%] [G loss: 0.908693]\n",
      "epoch:20 step:15666[D loss: 0.411735, acc: 61.72%, op_acc: 41.41%] [G loss: 0.898806]\n",
      "epoch:20 step:15667[D loss: 0.466555, acc: 47.66%, op_acc: 35.16%] [G loss: 0.858696]\n",
      "epoch:20 step:15668[D loss: 0.431971, acc: 58.59%, op_acc: 35.94%] [G loss: 0.842423]\n",
      "epoch:20 step:15669[D loss: 0.438733, acc: 55.47%, op_acc: 32.03%] [G loss: 0.875652]\n",
      "epoch:20 step:15670[D loss: 0.446427, acc: 53.12%, op_acc: 35.94%] [G loss: 0.905531]\n",
      "epoch:20 step:15671[D loss: 0.415407, acc: 64.84%, op_acc: 35.94%] [G loss: 0.894784]\n",
      "epoch:20 step:15672[D loss: 0.420779, acc: 62.50%, op_acc: 41.41%] [G loss: 0.880809]\n",
      "epoch:20 step:15673[D loss: 0.457110, acc: 53.91%, op_acc: 35.16%] [G loss: 0.882739]\n",
      "epoch:20 step:15674[D loss: 0.432649, acc: 57.03%, op_acc: 39.06%] [G loss: 0.867677]\n",
      "epoch:20 step:15675[D loss: 0.411826, acc: 64.06%, op_acc: 39.06%] [G loss: 0.870798]\n",
      "epoch:20 step:15676[D loss: 0.438478, acc: 57.03%, op_acc: 36.72%] [G loss: 0.917688]\n",
      "epoch:20 step:15677[D loss: 0.420178, acc: 66.41%, op_acc: 37.50%] [G loss: 0.858067]\n",
      "epoch:20 step:15678[D loss: 0.417926, acc: 52.34%, op_acc: 39.84%] [G loss: 0.842990]\n",
      "epoch:20 step:15679[D loss: 0.395107, acc: 57.03%, op_acc: 42.97%] [G loss: 0.878849]\n",
      "epoch:20 step:15680[D loss: 0.409243, acc: 59.38%, op_acc: 37.50%] [G loss: 0.840364]\n",
      "epoch:20 step:15681[D loss: 0.421922, acc: 61.72%, op_acc: 35.94%] [G loss: 0.943498]\n",
      "epoch:20 step:15682[D loss: 0.406883, acc: 64.84%, op_acc: 42.19%] [G loss: 0.947374]\n",
      "epoch:20 step:15683[D loss: 0.407023, acc: 62.50%, op_acc: 39.06%] [G loss: 0.806023]\n",
      "epoch:20 step:15684[D loss: 0.424201, acc: 60.16%, op_acc: 36.72%] [G loss: 0.929745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15685[D loss: 0.458046, acc: 53.12%, op_acc: 37.50%] [G loss: 0.832366]\n",
      "epoch:20 step:15686[D loss: 0.427245, acc: 64.84%, op_acc: 40.62%] [G loss: 0.867444]\n",
      "epoch:20 step:15687[D loss: 0.396579, acc: 65.62%, op_acc: 45.31%] [G loss: 0.873718]\n",
      "epoch:20 step:15688[D loss: 0.424999, acc: 62.50%, op_acc: 32.81%] [G loss: 0.887457]\n",
      "epoch:20 step:15689[D loss: 0.420846, acc: 53.91%, op_acc: 42.19%] [G loss: 0.810376]\n",
      "epoch:20 step:15690[D loss: 0.420383, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880160]\n",
      "epoch:20 step:15691[D loss: 0.483975, acc: 46.09%, op_acc: 33.59%] [G loss: 0.850284]\n",
      "epoch:20 step:15692[D loss: 0.388882, acc: 67.97%, op_acc: 40.62%] [G loss: 0.865881]\n",
      "epoch:20 step:15693[D loss: 0.450586, acc: 57.03%, op_acc: 36.72%] [G loss: 0.905414]\n",
      "epoch:20 step:15694[D loss: 0.408433, acc: 63.28%, op_acc: 42.19%] [G loss: 0.869291]\n",
      "epoch:20 step:15695[D loss: 0.388229, acc: 64.84%, op_acc: 42.97%] [G loss: 0.855794]\n",
      "epoch:20 step:15696[D loss: 0.459485, acc: 56.25%, op_acc: 33.59%] [G loss: 0.883458]\n",
      "epoch:20 step:15697[D loss: 0.425959, acc: 58.59%, op_acc: 39.84%] [G loss: 0.981045]\n",
      "epoch:20 step:15698[D loss: 0.459883, acc: 55.47%, op_acc: 36.72%] [G loss: 0.860395]\n",
      "epoch:20 step:15699[D loss: 0.439304, acc: 50.78%, op_acc: 36.72%] [G loss: 0.848816]\n",
      "epoch:20 step:15700[D loss: 0.467211, acc: 53.12%, op_acc: 30.47%] [G loss: 0.894000]\n",
      "epoch:20 step:15701[D loss: 0.423434, acc: 62.50%, op_acc: 35.16%] [G loss: 0.895848]\n",
      "epoch:20 step:15702[D loss: 0.428693, acc: 56.25%, op_acc: 37.50%] [G loss: 0.918810]\n",
      "epoch:20 step:15703[D loss: 0.422350, acc: 58.59%, op_acc: 36.72%] [G loss: 0.829064]\n",
      "epoch:20 step:15704[D loss: 0.444481, acc: 57.81%, op_acc: 37.50%] [G loss: 0.873393]\n",
      "epoch:20 step:15705[D loss: 0.429097, acc: 71.09%, op_acc: 29.69%] [G loss: 0.841362]\n",
      "epoch:20 step:15706[D loss: 0.429618, acc: 61.72%, op_acc: 35.94%] [G loss: 0.904015]\n",
      "epoch:20 step:15707[D loss: 0.401024, acc: 64.84%, op_acc: 39.06%] [G loss: 0.976301]\n",
      "epoch:20 step:15708[D loss: 0.420069, acc: 60.94%, op_acc: 40.62%] [G loss: 0.854442]\n",
      "epoch:20 step:15709[D loss: 0.443142, acc: 46.09%, op_acc: 36.72%] [G loss: 0.884436]\n",
      "epoch:20 step:15710[D loss: 0.428377, acc: 54.69%, op_acc: 41.41%] [G loss: 0.908491]\n",
      "epoch:20 step:15711[D loss: 0.412531, acc: 60.16%, op_acc: 44.53%] [G loss: 0.852364]\n",
      "epoch:20 step:15712[D loss: 0.452541, acc: 61.72%, op_acc: 37.50%] [G loss: 0.914690]\n",
      "epoch:20 step:15713[D loss: 0.408245, acc: 66.41%, op_acc: 40.62%] [G loss: 0.984503]\n",
      "epoch:20 step:15714[D loss: 0.399057, acc: 68.75%, op_acc: 38.28%] [G loss: 0.852122]\n",
      "epoch:20 step:15715[D loss: 0.405657, acc: 65.62%, op_acc: 36.72%] [G loss: 0.886835]\n",
      "epoch:20 step:15716[D loss: 0.443059, acc: 52.34%, op_acc: 35.16%] [G loss: 0.822710]\n",
      "epoch:20 step:15717[D loss: 0.429662, acc: 54.69%, op_acc: 35.94%] [G loss: 0.908488]\n",
      "epoch:20 step:15718[D loss: 0.439756, acc: 59.38%, op_acc: 34.38%] [G loss: 0.822765]\n",
      "epoch:20 step:15719[D loss: 0.431250, acc: 60.16%, op_acc: 39.84%] [G loss: 0.912897]\n",
      "epoch:20 step:15720[D loss: 0.403950, acc: 57.03%, op_acc: 46.88%] [G loss: 0.816082]\n",
      "epoch:20 step:15721[D loss: 0.406722, acc: 64.84%, op_acc: 39.06%] [G loss: 0.903499]\n",
      "epoch:20 step:15722[D loss: 0.417709, acc: 60.94%, op_acc: 41.41%] [G loss: 0.875939]\n",
      "epoch:20 step:15723[D loss: 0.437641, acc: 56.25%, op_acc: 42.19%] [G loss: 0.910163]\n",
      "epoch:20 step:15724[D loss: 0.401247, acc: 64.84%, op_acc: 38.28%] [G loss: 0.914979]\n",
      "epoch:20 step:15725[D loss: 0.442937, acc: 56.25%, op_acc: 31.25%] [G loss: 0.850801]\n",
      "epoch:20 step:15726[D loss: 0.430375, acc: 60.94%, op_acc: 39.06%] [G loss: 0.874152]\n",
      "epoch:20 step:15727[D loss: 0.418659, acc: 61.72%, op_acc: 40.62%] [G loss: 0.834803]\n",
      "epoch:20 step:15728[D loss: 0.466307, acc: 50.78%, op_acc: 36.72%] [G loss: 0.942393]\n",
      "epoch:20 step:15729[D loss: 0.436110, acc: 46.88%, op_acc: 41.41%] [G loss: 0.843649]\n",
      "epoch:20 step:15730[D loss: 0.430206, acc: 51.56%, op_acc: 39.84%] [G loss: 0.893689]\n",
      "epoch:20 step:15731[D loss: 0.428084, acc: 66.41%, op_acc: 36.72%] [G loss: 0.813005]\n",
      "epoch:20 step:15732[D loss: 0.433994, acc: 53.12%, op_acc: 44.53%] [G loss: 0.888455]\n",
      "epoch:20 step:15733[D loss: 0.447986, acc: 52.34%, op_acc: 34.38%] [G loss: 0.863834]\n",
      "epoch:20 step:15734[D loss: 0.419160, acc: 64.06%, op_acc: 43.75%] [G loss: 0.828514]\n",
      "epoch:20 step:15735[D loss: 0.408394, acc: 63.28%, op_acc: 40.62%] [G loss: 0.915632]\n",
      "epoch:20 step:15736[D loss: 0.448772, acc: 57.03%, op_acc: 33.59%] [G loss: 0.849662]\n",
      "epoch:20 step:15737[D loss: 0.411371, acc: 61.72%, op_acc: 39.84%] [G loss: 0.844299]\n",
      "epoch:20 step:15738[D loss: 0.427112, acc: 61.72%, op_acc: 37.50%] [G loss: 0.885303]\n",
      "epoch:20 step:15739[D loss: 0.442728, acc: 59.38%, op_acc: 42.19%] [G loss: 0.896242]\n",
      "epoch:20 step:15740[D loss: 0.416189, acc: 63.28%, op_acc: 34.38%] [G loss: 0.854501]\n",
      "epoch:20 step:15741[D loss: 0.446915, acc: 60.94%, op_acc: 33.59%] [G loss: 0.841861]\n",
      "epoch:20 step:15742[D loss: 0.404862, acc: 63.28%, op_acc: 39.06%] [G loss: 0.886363]\n",
      "epoch:20 step:15743[D loss: 0.427317, acc: 59.38%, op_acc: 35.16%] [G loss: 0.893285]\n",
      "epoch:20 step:15744[D loss: 0.425533, acc: 60.16%, op_acc: 39.06%] [G loss: 0.870396]\n",
      "epoch:20 step:15745[D loss: 0.445384, acc: 58.59%, op_acc: 39.84%] [G loss: 0.871647]\n",
      "epoch:20 step:15746[D loss: 0.418764, acc: 60.16%, op_acc: 38.28%] [G loss: 0.875938]\n",
      "epoch:20 step:15747[D loss: 0.432045, acc: 57.81%, op_acc: 35.16%] [G loss: 0.872507]\n",
      "epoch:20 step:15748[D loss: 0.415048, acc: 59.38%, op_acc: 38.28%] [G loss: 0.920306]\n",
      "epoch:20 step:15749[D loss: 0.441927, acc: 54.69%, op_acc: 34.38%] [G loss: 0.887488]\n",
      "epoch:20 step:15750[D loss: 0.421085, acc: 57.03%, op_acc: 42.97%] [G loss: 0.915927]\n",
      "epoch:20 step:15751[D loss: 0.404311, acc: 62.50%, op_acc: 38.28%] [G loss: 0.887934]\n",
      "epoch:20 step:15752[D loss: 0.407691, acc: 64.84%, op_acc: 39.84%] [G loss: 0.930403]\n",
      "epoch:20 step:15753[D loss: 0.442313, acc: 65.62%, op_acc: 31.25%] [G loss: 0.935472]\n",
      "epoch:20 step:15754[D loss: 0.409992, acc: 63.28%, op_acc: 39.84%] [G loss: 0.888866]\n",
      "epoch:20 step:15755[D loss: 0.437007, acc: 65.62%, op_acc: 36.72%] [G loss: 0.881462]\n",
      "epoch:20 step:15756[D loss: 0.385204, acc: 70.31%, op_acc: 42.19%] [G loss: 0.899471]\n",
      "epoch:20 step:15757[D loss: 0.448542, acc: 53.91%, op_acc: 39.84%] [G loss: 0.847298]\n",
      "epoch:20 step:15758[D loss: 0.434926, acc: 58.59%, op_acc: 39.84%] [G loss: 0.888138]\n",
      "epoch:20 step:15759[D loss: 0.410990, acc: 63.28%, op_acc: 35.94%] [G loss: 0.899244]\n",
      "epoch:20 step:15760[D loss: 0.478189, acc: 50.00%, op_acc: 31.25%] [G loss: 0.885563]\n",
      "epoch:20 step:15761[D loss: 0.477203, acc: 47.66%, op_acc: 32.03%] [G loss: 0.796469]\n",
      "epoch:20 step:15762[D loss: 0.420638, acc: 60.94%, op_acc: 37.50%] [G loss: 0.879178]\n",
      "epoch:20 step:15763[D loss: 0.418301, acc: 62.50%, op_acc: 36.72%] [G loss: 0.887885]\n",
      "epoch:20 step:15764[D loss: 0.425702, acc: 57.81%, op_acc: 43.75%] [G loss: 0.842492]\n",
      "epoch:20 step:15765[D loss: 0.415476, acc: 60.16%, op_acc: 39.84%] [G loss: 0.894608]\n",
      "epoch:20 step:15766[D loss: 0.416498, acc: 60.94%, op_acc: 41.41%] [G loss: 0.926088]\n",
      "epoch:20 step:15767[D loss: 0.404816, acc: 63.28%, op_acc: 40.62%] [G loss: 0.857055]\n",
      "epoch:20 step:15768[D loss: 0.420902, acc: 59.38%, op_acc: 43.75%] [G loss: 0.870294]\n",
      "epoch:20 step:15769[D loss: 0.398487, acc: 60.16%, op_acc: 44.53%] [G loss: 0.841102]\n",
      "epoch:20 step:15770[D loss: 0.418254, acc: 60.16%, op_acc: 35.94%] [G loss: 0.850863]\n",
      "epoch:20 step:15771[D loss: 0.410233, acc: 60.16%, op_acc: 41.41%] [G loss: 0.878687]\n",
      "epoch:20 step:15772[D loss: 0.436196, acc: 53.91%, op_acc: 38.28%] [G loss: 0.887056]\n",
      "epoch:20 step:15773[D loss: 0.455488, acc: 53.91%, op_acc: 37.50%] [G loss: 0.833862]\n",
      "epoch:20 step:15774[D loss: 0.455439, acc: 54.69%, op_acc: 38.28%] [G loss: 0.837814]\n",
      "epoch:20 step:15775[D loss: 0.422482, acc: 63.28%, op_acc: 39.06%] [G loss: 0.904056]\n",
      "epoch:20 step:15776[D loss: 0.436432, acc: 58.59%, op_acc: 35.94%] [G loss: 0.873220]\n",
      "epoch:20 step:15777[D loss: 0.434698, acc: 61.72%, op_acc: 39.84%] [G loss: 0.863712]\n",
      "epoch:20 step:15778[D loss: 0.388664, acc: 64.06%, op_acc: 41.41%] [G loss: 0.857105]\n",
      "epoch:20 step:15779[D loss: 0.430392, acc: 57.81%, op_acc: 39.06%] [G loss: 0.864978]\n",
      "epoch:20 step:15780[D loss: 0.448036, acc: 59.38%, op_acc: 33.59%] [G loss: 0.846979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15781[D loss: 0.444432, acc: 53.91%, op_acc: 32.81%] [G loss: 0.927805]\n",
      "epoch:20 step:15782[D loss: 0.418479, acc: 50.00%, op_acc: 46.09%] [G loss: 0.885338]\n",
      "epoch:20 step:15783[D loss: 0.438633, acc: 58.59%, op_acc: 43.75%] [G loss: 0.936893]\n",
      "epoch:20 step:15784[D loss: 0.479149, acc: 54.69%, op_acc: 29.69%] [G loss: 0.889000]\n",
      "epoch:20 step:15785[D loss: 0.400448, acc: 64.06%, op_acc: 42.97%] [G loss: 0.913768]\n",
      "epoch:20 step:15786[D loss: 0.451960, acc: 52.34%, op_acc: 36.72%] [G loss: 0.892629]\n",
      "epoch:20 step:15787[D loss: 0.437790, acc: 63.28%, op_acc: 37.50%] [G loss: 0.896843]\n",
      "epoch:20 step:15788[D loss: 0.393791, acc: 63.28%, op_acc: 39.84%] [G loss: 0.996080]\n",
      "epoch:20 step:15789[D loss: 0.427564, acc: 60.16%, op_acc: 39.84%] [G loss: 0.895255]\n",
      "epoch:20 step:15790[D loss: 0.439275, acc: 52.34%, op_acc: 38.28%] [G loss: 0.925534]\n",
      "epoch:20 step:15791[D loss: 0.424518, acc: 64.06%, op_acc: 38.28%] [G loss: 0.996954]\n",
      "epoch:20 step:15792[D loss: 0.423100, acc: 64.84%, op_acc: 36.72%] [G loss: 0.868330]\n",
      "epoch:20 step:15793[D loss: 0.445068, acc: 56.25%, op_acc: 39.06%] [G loss: 0.861264]\n",
      "epoch:20 step:15794[D loss: 0.476476, acc: 54.69%, op_acc: 32.81%] [G loss: 0.893020]\n",
      "epoch:20 step:15795[D loss: 0.415879, acc: 57.81%, op_acc: 39.84%] [G loss: 0.825703]\n",
      "epoch:20 step:15796[D loss: 0.440926, acc: 56.25%, op_acc: 39.84%] [G loss: 0.916392]\n",
      "epoch:20 step:15797[D loss: 0.418743, acc: 60.16%, op_acc: 40.62%] [G loss: 0.879369]\n",
      "epoch:20 step:15798[D loss: 0.470290, acc: 51.56%, op_acc: 31.25%] [G loss: 0.878731]\n",
      "epoch:20 step:15799[D loss: 0.432947, acc: 54.69%, op_acc: 35.94%] [G loss: 0.929077]\n",
      "epoch:20 step:15800[D loss: 0.435841, acc: 60.94%, op_acc: 31.25%] [G loss: 0.939791]\n",
      "epoch:20 step:15801[D loss: 0.434399, acc: 54.69%, op_acc: 39.06%] [G loss: 0.857026]\n",
      "epoch:20 step:15802[D loss: 0.413291, acc: 59.38%, op_acc: 40.62%] [G loss: 0.948142]\n",
      "epoch:20 step:15803[D loss: 0.415977, acc: 58.59%, op_acc: 41.41%] [G loss: 0.869302]\n",
      "epoch:20 step:15804[D loss: 0.410236, acc: 55.47%, op_acc: 40.62%] [G loss: 0.963750]\n",
      "epoch:20 step:15805[D loss: 0.427935, acc: 62.50%, op_acc: 35.16%] [G loss: 0.885756]\n",
      "epoch:20 step:15806[D loss: 0.408142, acc: 53.91%, op_acc: 44.53%] [G loss: 0.852434]\n",
      "epoch:20 step:15807[D loss: 0.405241, acc: 66.41%, op_acc: 38.28%] [G loss: 0.863948]\n",
      "epoch:20 step:15808[D loss: 0.430504, acc: 59.38%, op_acc: 37.50%] [G loss: 0.864474]\n",
      "epoch:20 step:15809[D loss: 0.430822, acc: 60.94%, op_acc: 39.06%] [G loss: 0.879514]\n",
      "epoch:20 step:15810[D loss: 0.442737, acc: 56.25%, op_acc: 32.81%] [G loss: 0.954950]\n",
      "epoch:20 step:15811[D loss: 0.404649, acc: 62.50%, op_acc: 42.97%] [G loss: 0.908208]\n",
      "epoch:20 step:15812[D loss: 0.420370, acc: 67.19%, op_acc: 42.97%] [G loss: 0.835363]\n",
      "epoch:20 step:15813[D loss: 0.449057, acc: 53.91%, op_acc: 32.03%] [G loss: 0.829799]\n",
      "epoch:20 step:15814[D loss: 0.428974, acc: 60.16%, op_acc: 35.16%] [G loss: 0.866280]\n",
      "epoch:20 step:15815[D loss: 0.455480, acc: 57.81%, op_acc: 32.03%] [G loss: 0.811974]\n",
      "epoch:20 step:15816[D loss: 0.411402, acc: 59.38%, op_acc: 37.50%] [G loss: 0.876985]\n",
      "epoch:20 step:15817[D loss: 0.452159, acc: 52.34%, op_acc: 39.84%] [G loss: 0.828722]\n",
      "epoch:20 step:15818[D loss: 0.428489, acc: 59.38%, op_acc: 33.59%] [G loss: 0.963760]\n",
      "epoch:20 step:15819[D loss: 0.434880, acc: 53.91%, op_acc: 40.62%] [G loss: 0.813872]\n",
      "epoch:20 step:15820[D loss: 0.417593, acc: 66.41%, op_acc: 34.38%] [G loss: 0.908620]\n",
      "epoch:20 step:15821[D loss: 0.389208, acc: 66.41%, op_acc: 41.41%] [G loss: 0.932674]\n",
      "epoch:20 step:15822[D loss: 0.435393, acc: 61.72%, op_acc: 35.16%] [G loss: 0.852272]\n",
      "epoch:20 step:15823[D loss: 0.424223, acc: 64.06%, op_acc: 35.94%] [G loss: 0.841865]\n",
      "epoch:20 step:15824[D loss: 0.455264, acc: 49.22%, op_acc: 37.50%] [G loss: 0.872347]\n",
      "epoch:20 step:15825[D loss: 0.436094, acc: 57.81%, op_acc: 35.94%] [G loss: 0.803276]\n",
      "epoch:20 step:15826[D loss: 0.440985, acc: 57.03%, op_acc: 35.94%] [G loss: 0.919861]\n",
      "epoch:20 step:15827[D loss: 0.413358, acc: 62.50%, op_acc: 39.06%] [G loss: 0.885014]\n",
      "epoch:20 step:15828[D loss: 0.434939, acc: 54.69%, op_acc: 32.03%] [G loss: 0.896298]\n",
      "epoch:20 step:15829[D loss: 0.404761, acc: 62.50%, op_acc: 42.97%] [G loss: 0.855014]\n",
      "epoch:20 step:15830[D loss: 0.444623, acc: 57.81%, op_acc: 36.72%] [G loss: 0.845937]\n",
      "epoch:20 step:15831[D loss: 0.389454, acc: 66.41%, op_acc: 47.66%] [G loss: 0.891364]\n",
      "epoch:20 step:15832[D loss: 0.399406, acc: 64.06%, op_acc: 44.53%] [G loss: 0.936431]\n",
      "epoch:20 step:15833[D loss: 0.427297, acc: 60.16%, op_acc: 37.50%] [G loss: 0.874248]\n",
      "epoch:20 step:15834[D loss: 0.431853, acc: 64.84%, op_acc: 31.25%] [G loss: 0.878719]\n",
      "epoch:20 step:15835[D loss: 0.466242, acc: 57.81%, op_acc: 29.69%] [G loss: 0.898788]\n",
      "epoch:20 step:15836[D loss: 0.430653, acc: 60.16%, op_acc: 37.50%] [G loss: 0.881484]\n",
      "epoch:20 step:15837[D loss: 0.415231, acc: 61.72%, op_acc: 36.72%] [G loss: 0.863761]\n",
      "epoch:20 step:15838[D loss: 0.432961, acc: 51.56%, op_acc: 42.97%] [G loss: 0.938460]\n",
      "epoch:20 step:15839[D loss: 0.435697, acc: 55.47%, op_acc: 36.72%] [G loss: 0.896386]\n",
      "epoch:20 step:15840[D loss: 0.427933, acc: 54.69%, op_acc: 43.75%] [G loss: 0.920506]\n",
      "epoch:20 step:15841[D loss: 0.429305, acc: 57.03%, op_acc: 32.81%] [G loss: 0.845837]\n",
      "epoch:20 step:15842[D loss: 0.432560, acc: 57.81%, op_acc: 39.06%] [G loss: 0.813515]\n",
      "epoch:20 step:15843[D loss: 0.436369, acc: 57.03%, op_acc: 37.50%] [G loss: 0.878400]\n",
      "epoch:20 step:15844[D loss: 0.459904, acc: 46.09%, op_acc: 33.59%] [G loss: 0.905159]\n",
      "epoch:20 step:15845[D loss: 0.423796, acc: 63.28%, op_acc: 38.28%] [G loss: 0.871556]\n",
      "epoch:20 step:15846[D loss: 0.434786, acc: 57.81%, op_acc: 35.94%] [G loss: 0.825515]\n",
      "epoch:20 step:15847[D loss: 0.415718, acc: 64.06%, op_acc: 36.72%] [G loss: 0.902376]\n",
      "epoch:20 step:15848[D loss: 0.424749, acc: 55.47%, op_acc: 35.94%] [G loss: 0.917454]\n",
      "epoch:20 step:15849[D loss: 0.441193, acc: 55.47%, op_acc: 40.62%] [G loss: 0.882653]\n",
      "epoch:20 step:15850[D loss: 0.446418, acc: 59.38%, op_acc: 33.59%] [G loss: 0.870180]\n",
      "epoch:20 step:15851[D loss: 0.390931, acc: 67.97%, op_acc: 45.31%] [G loss: 0.859951]\n",
      "epoch:20 step:15852[D loss: 0.433818, acc: 56.25%, op_acc: 36.72%] [G loss: 0.899714]\n",
      "epoch:20 step:15853[D loss: 0.428755, acc: 57.03%, op_acc: 38.28%] [G loss: 0.893396]\n",
      "epoch:20 step:15854[D loss: 0.425142, acc: 64.84%, op_acc: 37.50%] [G loss: 0.843522]\n",
      "epoch:20 step:15855[D loss: 0.422107, acc: 60.94%, op_acc: 44.53%] [G loss: 0.884952]\n",
      "epoch:20 step:15856[D loss: 0.440360, acc: 55.47%, op_acc: 36.72%] [G loss: 0.907076]\n",
      "epoch:20 step:15857[D loss: 0.394986, acc: 63.28%, op_acc: 39.06%] [G loss: 0.827849]\n",
      "epoch:20 step:15858[D loss: 0.425084, acc: 61.72%, op_acc: 35.16%] [G loss: 0.813101]\n",
      "epoch:20 step:15859[D loss: 0.448895, acc: 61.72%, op_acc: 34.38%] [G loss: 0.896668]\n",
      "epoch:20 step:15860[D loss: 0.431941, acc: 56.25%, op_acc: 40.62%] [G loss: 0.879044]\n",
      "epoch:20 step:15861[D loss: 0.447897, acc: 54.69%, op_acc: 40.62%] [G loss: 0.929707]\n",
      "epoch:20 step:15862[D loss: 0.433499, acc: 49.22%, op_acc: 37.50%] [G loss: 0.857008]\n",
      "epoch:20 step:15863[D loss: 0.448057, acc: 53.91%, op_acc: 40.62%] [G loss: 0.870564]\n",
      "epoch:20 step:15864[D loss: 0.467449, acc: 47.66%, op_acc: 35.94%] [G loss: 0.881917]\n",
      "epoch:20 step:15865[D loss: 0.440435, acc: 47.66%, op_acc: 41.41%] [G loss: 0.856253]\n",
      "epoch:20 step:15866[D loss: 0.431603, acc: 61.72%, op_acc: 38.28%] [G loss: 0.877783]\n",
      "epoch:20 step:15867[D loss: 0.414644, acc: 64.84%, op_acc: 37.50%] [G loss: 0.901174]\n",
      "epoch:20 step:15868[D loss: 0.449125, acc: 56.25%, op_acc: 37.50%] [G loss: 0.838332]\n",
      "epoch:20 step:15869[D loss: 0.410657, acc: 65.62%, op_acc: 42.97%] [G loss: 0.886428]\n",
      "epoch:20 step:15870[D loss: 0.439732, acc: 58.59%, op_acc: 35.16%] [G loss: 0.861758]\n",
      "epoch:20 step:15871[D loss: 0.406565, acc: 63.28%, op_acc: 42.97%] [G loss: 0.831481]\n",
      "epoch:20 step:15872[D loss: 0.427633, acc: 61.72%, op_acc: 39.06%] [G loss: 0.875513]\n",
      "epoch:20 step:15873[D loss: 0.449565, acc: 61.72%, op_acc: 34.38%] [G loss: 0.908899]\n",
      "epoch:20 step:15874[D loss: 0.420433, acc: 63.28%, op_acc: 39.84%] [G loss: 0.886841]\n",
      "epoch:20 step:15875[D loss: 0.444519, acc: 50.78%, op_acc: 37.50%] [G loss: 0.836594]\n",
      "epoch:20 step:15876[D loss: 0.422757, acc: 57.03%, op_acc: 40.62%] [G loss: 0.849298]\n",
      "epoch:20 step:15877[D loss: 0.478855, acc: 50.00%, op_acc: 35.94%] [G loss: 0.834496]\n",
      "epoch:20 step:15878[D loss: 0.390036, acc: 65.62%, op_acc: 40.62%] [G loss: 0.897310]\n",
      "epoch:20 step:15879[D loss: 0.448459, acc: 60.16%, op_acc: 35.16%] [G loss: 0.952605]\n",
      "epoch:20 step:15880[D loss: 0.437584, acc: 58.59%, op_acc: 36.72%] [G loss: 0.842775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15881[D loss: 0.409998, acc: 59.38%, op_acc: 43.75%] [G loss: 0.957334]\n",
      "epoch:20 step:15882[D loss: 0.417097, acc: 64.06%, op_acc: 37.50%] [G loss: 0.902396]\n",
      "epoch:20 step:15883[D loss: 0.419889, acc: 60.16%, op_acc: 40.62%] [G loss: 0.894804]\n",
      "epoch:20 step:15884[D loss: 0.422873, acc: 62.50%, op_acc: 33.59%] [G loss: 0.862787]\n",
      "epoch:20 step:15885[D loss: 0.436530, acc: 57.03%, op_acc: 39.06%] [G loss: 0.885068]\n",
      "epoch:20 step:15886[D loss: 0.397002, acc: 66.41%, op_acc: 39.06%] [G loss: 0.931351]\n",
      "epoch:20 step:15887[D loss: 0.449158, acc: 50.78%, op_acc: 43.75%] [G loss: 0.919013]\n",
      "epoch:20 step:15888[D loss: 0.420932, acc: 59.38%, op_acc: 41.41%] [G loss: 0.844229]\n",
      "epoch:20 step:15889[D loss: 0.410660, acc: 67.97%, op_acc: 39.84%] [G loss: 0.882435]\n",
      "epoch:20 step:15890[D loss: 0.418334, acc: 63.28%, op_acc: 39.84%] [G loss: 0.887210]\n",
      "epoch:20 step:15891[D loss: 0.457890, acc: 51.56%, op_acc: 35.16%] [G loss: 0.817868]\n",
      "epoch:20 step:15892[D loss: 0.393095, acc: 66.41%, op_acc: 42.19%] [G loss: 0.881328]\n",
      "epoch:20 step:15893[D loss: 0.417599, acc: 54.69%, op_acc: 45.31%] [G loss: 0.824206]\n",
      "epoch:20 step:15894[D loss: 0.442195, acc: 54.69%, op_acc: 38.28%] [G loss: 0.863493]\n",
      "epoch:20 step:15895[D loss: 0.445569, acc: 50.00%, op_acc: 36.72%] [G loss: 0.869553]\n",
      "epoch:20 step:15896[D loss: 0.425988, acc: 60.16%, op_acc: 39.06%] [G loss: 0.903370]\n",
      "epoch:20 step:15897[D loss: 0.439170, acc: 50.78%, op_acc: 38.28%] [G loss: 0.890171]\n",
      "epoch:20 step:15898[D loss: 0.437454, acc: 59.38%, op_acc: 36.72%] [G loss: 0.850299]\n",
      "epoch:20 step:15899[D loss: 0.415098, acc: 58.59%, op_acc: 39.84%] [G loss: 0.877890]\n",
      "epoch:20 step:15900[D loss: 0.421926, acc: 61.72%, op_acc: 38.28%] [G loss: 0.856382]\n",
      "epoch:20 step:15901[D loss: 0.466921, acc: 51.56%, op_acc: 38.28%] [G loss: 0.904664]\n",
      "epoch:20 step:15902[D loss: 0.456110, acc: 53.91%, op_acc: 36.72%] [G loss: 0.923859]\n",
      "epoch:20 step:15903[D loss: 0.395611, acc: 61.72%, op_acc: 41.41%] [G loss: 0.936423]\n",
      "epoch:20 step:15904[D loss: 0.439271, acc: 53.12%, op_acc: 34.38%] [G loss: 0.860027]\n",
      "epoch:20 step:15905[D loss: 0.441013, acc: 53.91%, op_acc: 37.50%] [G loss: 0.745395]\n",
      "epoch:20 step:15906[D loss: 0.449618, acc: 57.03%, op_acc: 34.38%] [G loss: 0.900805]\n",
      "epoch:20 step:15907[D loss: 0.439112, acc: 56.25%, op_acc: 42.97%] [G loss: 0.814111]\n",
      "epoch:20 step:15908[D loss: 0.411038, acc: 65.62%, op_acc: 40.62%] [G loss: 0.869501]\n",
      "epoch:20 step:15909[D loss: 0.423102, acc: 63.28%, op_acc: 39.06%] [G loss: 0.892808]\n",
      "epoch:20 step:15910[D loss: 0.402040, acc: 67.19%, op_acc: 39.84%] [G loss: 0.857029]\n",
      "epoch:20 step:15911[D loss: 0.450080, acc: 51.56%, op_acc: 39.06%] [G loss: 0.861933]\n",
      "epoch:20 step:15912[D loss: 0.442713, acc: 54.69%, op_acc: 35.16%] [G loss: 0.887887]\n",
      "epoch:20 step:15913[D loss: 0.438168, acc: 58.59%, op_acc: 35.94%] [G loss: 0.878075]\n",
      "epoch:20 step:15914[D loss: 0.428654, acc: 62.50%, op_acc: 37.50%] [G loss: 0.898340]\n",
      "epoch:20 step:15915[D loss: 0.413085, acc: 63.28%, op_acc: 42.19%] [G loss: 0.912955]\n",
      "epoch:20 step:15916[D loss: 0.443368, acc: 56.25%, op_acc: 42.19%] [G loss: 0.824151]\n",
      "epoch:20 step:15917[D loss: 0.422474, acc: 67.19%, op_acc: 35.94%] [G loss: 0.924573]\n",
      "epoch:20 step:15918[D loss: 0.418657, acc: 64.84%, op_acc: 40.62%] [G loss: 0.876562]\n",
      "epoch:20 step:15919[D loss: 0.434630, acc: 58.59%, op_acc: 39.06%] [G loss: 0.834744]\n",
      "epoch:20 step:15920[D loss: 0.440300, acc: 57.03%, op_acc: 36.72%] [G loss: 0.880555]\n",
      "epoch:20 step:15921[D loss: 0.423008, acc: 53.91%, op_acc: 39.84%] [G loss: 0.855379]\n",
      "epoch:20 step:15922[D loss: 0.411191, acc: 59.38%, op_acc: 40.62%] [G loss: 0.872776]\n",
      "epoch:20 step:15923[D loss: 0.421688, acc: 59.38%, op_acc: 35.16%] [G loss: 0.887677]\n",
      "epoch:20 step:15924[D loss: 0.402843, acc: 64.84%, op_acc: 41.41%] [G loss: 0.894631]\n",
      "epoch:20 step:15925[D loss: 0.429637, acc: 58.59%, op_acc: 37.50%] [G loss: 0.917997]\n",
      "epoch:20 step:15926[D loss: 0.436032, acc: 60.94%, op_acc: 34.38%] [G loss: 0.872872]\n",
      "epoch:20 step:15927[D loss: 0.419277, acc: 62.50%, op_acc: 38.28%] [G loss: 0.926150]\n",
      "epoch:20 step:15928[D loss: 0.446358, acc: 59.38%, op_acc: 33.59%] [G loss: 0.970036]\n",
      "epoch:20 step:15929[D loss: 0.457508, acc: 64.84%, op_acc: 35.16%] [G loss: 0.911084]\n",
      "epoch:20 step:15930[D loss: 0.415642, acc: 65.62%, op_acc: 37.50%] [G loss: 0.870267]\n",
      "epoch:20 step:15931[D loss: 0.445253, acc: 53.91%, op_acc: 36.72%] [G loss: 0.879544]\n",
      "epoch:20 step:15932[D loss: 0.434069, acc: 60.16%, op_acc: 37.50%] [G loss: 0.848916]\n",
      "epoch:20 step:15933[D loss: 0.432207, acc: 59.38%, op_acc: 41.41%] [G loss: 0.855026]\n",
      "epoch:20 step:15934[D loss: 0.434775, acc: 58.59%, op_acc: 39.06%] [G loss: 0.905825]\n",
      "epoch:20 step:15935[D loss: 0.451444, acc: 57.03%, op_acc: 31.25%] [G loss: 0.948238]\n",
      "epoch:20 step:15936[D loss: 0.424225, acc: 60.94%, op_acc: 36.72%] [G loss: 0.856745]\n",
      "epoch:20 step:15937[D loss: 0.449520, acc: 56.25%, op_acc: 35.16%] [G loss: 0.868594]\n",
      "epoch:20 step:15938[D loss: 0.422460, acc: 60.16%, op_acc: 33.59%] [G loss: 0.852275]\n",
      "epoch:20 step:15939[D loss: 0.458219, acc: 53.12%, op_acc: 31.25%] [G loss: 0.853248]\n",
      "epoch:20 step:15940[D loss: 0.453602, acc: 53.12%, op_acc: 30.47%] [G loss: 0.848821]\n",
      "epoch:20 step:15941[D loss: 0.441025, acc: 57.81%, op_acc: 36.72%] [G loss: 0.875502]\n",
      "epoch:20 step:15942[D loss: 0.421733, acc: 60.16%, op_acc: 40.62%] [G loss: 0.831057]\n",
      "epoch:20 step:15943[D loss: 0.430711, acc: 55.47%, op_acc: 41.41%] [G loss: 0.828203]\n",
      "epoch:20 step:15944[D loss: 0.421868, acc: 61.72%, op_acc: 39.84%] [G loss: 0.780525]\n",
      "epoch:20 step:15945[D loss: 0.461643, acc: 45.31%, op_acc: 38.28%] [G loss: 0.897573]\n",
      "epoch:20 step:15946[D loss: 0.420682, acc: 63.28%, op_acc: 40.62%] [G loss: 0.856208]\n",
      "epoch:20 step:15947[D loss: 0.426265, acc: 60.16%, op_acc: 37.50%] [G loss: 0.870595]\n",
      "epoch:20 step:15948[D loss: 0.437188, acc: 50.00%, op_acc: 38.28%] [G loss: 0.834044]\n",
      "epoch:20 step:15949[D loss: 0.407510, acc: 60.94%, op_acc: 42.97%] [G loss: 0.866463]\n",
      "epoch:20 step:15950[D loss: 0.419091, acc: 58.59%, op_acc: 38.28%] [G loss: 0.841304]\n",
      "epoch:20 step:15951[D loss: 0.438131, acc: 54.69%, op_acc: 35.16%] [G loss: 0.852491]\n",
      "epoch:20 step:15952[D loss: 0.435317, acc: 57.03%, op_acc: 36.72%] [G loss: 0.808412]\n",
      "epoch:20 step:15953[D loss: 0.402240, acc: 64.06%, op_acc: 41.41%] [G loss: 0.889888]\n",
      "epoch:20 step:15954[D loss: 0.405224, acc: 64.06%, op_acc: 39.06%] [G loss: 0.967618]\n",
      "epoch:20 step:15955[D loss: 0.421991, acc: 66.41%, op_acc: 35.94%] [G loss: 0.986303]\n",
      "epoch:20 step:15956[D loss: 0.430246, acc: 61.72%, op_acc: 32.03%] [G loss: 0.944562]\n",
      "epoch:20 step:15957[D loss: 0.474418, acc: 50.00%, op_acc: 35.94%] [G loss: 0.825199]\n",
      "epoch:20 step:15958[D loss: 0.413104, acc: 59.38%, op_acc: 42.19%] [G loss: 0.935393]\n",
      "epoch:20 step:15959[D loss: 0.422804, acc: 59.38%, op_acc: 40.62%] [G loss: 0.932972]\n",
      "epoch:20 step:15960[D loss: 0.418356, acc: 56.25%, op_acc: 37.50%] [G loss: 0.926617]\n",
      "epoch:20 step:15961[D loss: 0.419879, acc: 63.28%, op_acc: 39.84%] [G loss: 0.858790]\n",
      "epoch:20 step:15962[D loss: 0.440406, acc: 54.69%, op_acc: 40.62%] [G loss: 0.832345]\n",
      "epoch:20 step:15963[D loss: 0.432914, acc: 58.59%, op_acc: 35.16%] [G loss: 0.940705]\n",
      "epoch:20 step:15964[D loss: 0.436918, acc: 55.47%, op_acc: 39.06%] [G loss: 0.925883]\n",
      "epoch:20 step:15965[D loss: 0.375547, acc: 77.34%, op_acc: 42.19%] [G loss: 0.808496]\n",
      "epoch:20 step:15966[D loss: 0.410554, acc: 59.38%, op_acc: 40.62%] [G loss: 0.865451]\n",
      "epoch:20 step:15967[D loss: 0.418820, acc: 58.59%, op_acc: 40.62%] [G loss: 0.906381]\n",
      "epoch:20 step:15968[D loss: 0.401652, acc: 70.31%, op_acc: 38.28%] [G loss: 0.931125]\n",
      "epoch:20 step:15969[D loss: 0.437084, acc: 55.47%, op_acc: 35.16%] [G loss: 0.813266]\n",
      "epoch:20 step:15970[D loss: 0.417608, acc: 67.19%, op_acc: 36.72%] [G loss: 0.874123]\n",
      "epoch:20 step:15971[D loss: 0.427030, acc: 61.72%, op_acc: 37.50%] [G loss: 0.882342]\n",
      "epoch:20 step:15972[D loss: 0.429474, acc: 56.25%, op_acc: 35.16%] [G loss: 0.967903]\n",
      "epoch:20 step:15973[D loss: 0.374435, acc: 71.88%, op_acc: 46.09%] [G loss: 0.993935]\n",
      "epoch:20 step:15974[D loss: 0.451494, acc: 50.78%, op_acc: 35.94%] [G loss: 0.895946]\n",
      "epoch:20 step:15975[D loss: 0.439247, acc: 53.12%, op_acc: 35.16%] [G loss: 0.906762]\n",
      "epoch:20 step:15976[D loss: 0.425987, acc: 57.81%, op_acc: 40.62%] [G loss: 0.890524]\n",
      "epoch:20 step:15977[D loss: 0.419550, acc: 66.41%, op_acc: 38.28%] [G loss: 0.960131]\n",
      "epoch:20 step:15978[D loss: 0.446994, acc: 56.25%, op_acc: 34.38%] [G loss: 0.906838]\n",
      "epoch:20 step:15979[D loss: 0.413275, acc: 61.72%, op_acc: 41.41%] [G loss: 0.884035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:15980[D loss: 0.428112, acc: 64.06%, op_acc: 36.72%] [G loss: 0.859790]\n",
      "epoch:20 step:15981[D loss: 0.421863, acc: 57.81%, op_acc: 40.62%] [G loss: 0.880698]\n",
      "epoch:20 step:15982[D loss: 0.394277, acc: 61.72%, op_acc: 42.97%] [G loss: 0.884418]\n",
      "epoch:20 step:15983[D loss: 0.445730, acc: 60.94%, op_acc: 31.25%] [G loss: 0.895379]\n",
      "epoch:20 step:15984[D loss: 0.459264, acc: 53.91%, op_acc: 38.28%] [G loss: 0.863210]\n",
      "epoch:20 step:15985[D loss: 0.408144, acc: 60.16%, op_acc: 41.41%] [G loss: 0.875718]\n",
      "epoch:20 step:15986[D loss: 0.443213, acc: 46.09%, op_acc: 35.94%] [G loss: 0.889670]\n",
      "epoch:20 step:15987[D loss: 0.431565, acc: 64.84%, op_acc: 39.06%] [G loss: 0.879590]\n",
      "epoch:20 step:15988[D loss: 0.431957, acc: 53.91%, op_acc: 39.84%] [G loss: 0.885312]\n",
      "epoch:20 step:15989[D loss: 0.454748, acc: 54.69%, op_acc: 33.59%] [G loss: 0.813311]\n",
      "epoch:20 step:15990[D loss: 0.443751, acc: 53.91%, op_acc: 35.94%] [G loss: 0.838077]\n",
      "epoch:20 step:15991[D loss: 0.429318, acc: 47.66%, op_acc: 39.06%] [G loss: 0.834819]\n",
      "epoch:20 step:15992[D loss: 0.445459, acc: 59.38%, op_acc: 33.59%] [G loss: 0.909279]\n",
      "epoch:20 step:15993[D loss: 0.441426, acc: 57.81%, op_acc: 41.41%] [G loss: 0.952382]\n",
      "epoch:20 step:15994[D loss: 0.452554, acc: 50.00%, op_acc: 41.41%] [G loss: 0.853400]\n",
      "epoch:20 step:15995[D loss: 0.405326, acc: 63.28%, op_acc: 41.41%] [G loss: 0.853996]\n",
      "epoch:20 step:15996[D loss: 0.412653, acc: 59.38%, op_acc: 39.84%] [G loss: 0.869412]\n",
      "epoch:20 step:15997[D loss: 0.407855, acc: 57.03%, op_acc: 42.97%] [G loss: 0.865660]\n",
      "epoch:20 step:15998[D loss: 0.451356, acc: 57.03%, op_acc: 32.03%] [G loss: 0.873481]\n",
      "epoch:20 step:15999[D loss: 0.392445, acc: 66.41%, op_acc: 37.50%] [G loss: 0.837229]\n",
      "epoch:20 step:16000[D loss: 0.434569, acc: 60.94%, op_acc: 38.28%] [G loss: 0.856424]\n",
      "epoch:20 step:16001[D loss: 0.424358, acc: 65.62%, op_acc: 33.59%] [G loss: 0.847001]\n",
      "epoch:20 step:16002[D loss: 0.436267, acc: 60.94%, op_acc: 34.38%] [G loss: 0.843782]\n",
      "epoch:20 step:16003[D loss: 0.429785, acc: 59.38%, op_acc: 36.72%] [G loss: 0.888268]\n",
      "epoch:20 step:16004[D loss: 0.417708, acc: 58.59%, op_acc: 35.94%] [G loss: 0.844643]\n",
      "epoch:20 step:16005[D loss: 0.404437, acc: 68.75%, op_acc: 39.84%] [G loss: 0.886573]\n",
      "epoch:20 step:16006[D loss: 0.427881, acc: 62.50%, op_acc: 39.84%] [G loss: 0.886286]\n",
      "epoch:20 step:16007[D loss: 0.437881, acc: 63.28%, op_acc: 36.72%] [G loss: 0.917524]\n",
      "epoch:20 step:16008[D loss: 0.456862, acc: 53.91%, op_acc: 36.72%] [G loss: 0.910990]\n",
      "epoch:20 step:16009[D loss: 0.427971, acc: 58.59%, op_acc: 38.28%] [G loss: 0.936519]\n",
      "epoch:20 step:16010[D loss: 0.417078, acc: 59.38%, op_acc: 39.84%] [G loss: 0.894878]\n",
      "epoch:20 step:16011[D loss: 0.391887, acc: 62.50%, op_acc: 45.31%] [G loss: 0.870034]\n",
      "epoch:20 step:16012[D loss: 0.438495, acc: 49.22%, op_acc: 39.06%] [G loss: 0.895896]\n",
      "epoch:20 step:16013[D loss: 0.405562, acc: 59.38%, op_acc: 42.97%] [G loss: 0.853112]\n",
      "epoch:20 step:16014[D loss: 0.449810, acc: 57.03%, op_acc: 34.38%] [G loss: 0.813296]\n",
      "epoch:20 step:16015[D loss: 0.474636, acc: 55.47%, op_acc: 32.03%] [G loss: 0.833590]\n",
      "epoch:20 step:16016[D loss: 0.421376, acc: 57.03%, op_acc: 42.97%] [G loss: 0.869926]\n",
      "epoch:20 step:16017[D loss: 0.435941, acc: 60.94%, op_acc: 37.50%] [G loss: 0.812363]\n",
      "epoch:20 step:16018[D loss: 0.441124, acc: 64.84%, op_acc: 33.59%] [G loss: 0.880099]\n",
      "epoch:20 step:16019[D loss: 0.426861, acc: 58.59%, op_acc: 39.06%] [G loss: 0.911778]\n",
      "epoch:20 step:16020[D loss: 0.414477, acc: 60.16%, op_acc: 42.97%] [G loss: 0.864223]\n",
      "epoch:20 step:16021[D loss: 0.441284, acc: 57.03%, op_acc: 38.28%] [G loss: 0.814369]\n",
      "epoch:20 step:16022[D loss: 0.433628, acc: 67.19%, op_acc: 36.72%] [G loss: 0.927513]\n",
      "epoch:20 step:16023[D loss: 0.418607, acc: 64.84%, op_acc: 35.16%] [G loss: 0.925200]\n",
      "epoch:20 step:16024[D loss: 0.405716, acc: 63.28%, op_acc: 43.75%] [G loss: 0.862635]\n",
      "epoch:20 step:16025[D loss: 0.430435, acc: 63.28%, op_acc: 35.94%] [G loss: 0.847061]\n",
      "epoch:20 step:16026[D loss: 0.426888, acc: 57.03%, op_acc: 35.94%] [G loss: 0.890588]\n",
      "epoch:20 step:16027[D loss: 0.436843, acc: 57.03%, op_acc: 36.72%] [G loss: 0.840552]\n",
      "epoch:20 step:16028[D loss: 0.415772, acc: 59.38%, op_acc: 42.19%] [G loss: 0.995826]\n",
      "epoch:20 step:16029[D loss: 0.426683, acc: 56.25%, op_acc: 43.75%] [G loss: 0.871145]\n",
      "epoch:20 step:16030[D loss: 0.405855, acc: 57.03%, op_acc: 41.41%] [G loss: 0.879948]\n",
      "epoch:20 step:16031[D loss: 0.424813, acc: 59.38%, op_acc: 36.72%] [G loss: 0.808939]\n",
      "epoch:20 step:16032[D loss: 0.437045, acc: 53.91%, op_acc: 39.84%] [G loss: 0.853856]\n",
      "epoch:20 step:16033[D loss: 0.433008, acc: 61.72%, op_acc: 39.06%] [G loss: 0.870832]\n",
      "epoch:20 step:16034[D loss: 0.405004, acc: 62.50%, op_acc: 36.72%] [G loss: 0.920342]\n",
      "epoch:20 step:16035[D loss: 0.396462, acc: 67.97%, op_acc: 39.84%] [G loss: 0.819850]\n",
      "epoch:20 step:16036[D loss: 0.400058, acc: 64.84%, op_acc: 43.75%] [G loss: 0.895400]\n",
      "epoch:20 step:16037[D loss: 0.432083, acc: 59.38%, op_acc: 35.94%] [G loss: 0.859561]\n",
      "epoch:20 step:16038[D loss: 0.421431, acc: 58.59%, op_acc: 35.94%] [G loss: 0.862187]\n",
      "epoch:20 step:16039[D loss: 0.436479, acc: 57.03%, op_acc: 35.16%] [G loss: 0.864949]\n",
      "epoch:20 step:16040[D loss: 0.454589, acc: 49.22%, op_acc: 32.81%] [G loss: 0.881152]\n",
      "epoch:20 step:16041[D loss: 0.466239, acc: 50.00%, op_acc: 37.50%] [G loss: 0.902438]\n",
      "epoch:20 step:16042[D loss: 0.425134, acc: 55.47%, op_acc: 40.62%] [G loss: 0.856016]\n",
      "epoch:20 step:16043[D loss: 0.442031, acc: 57.03%, op_acc: 34.38%] [G loss: 0.906569]\n",
      "epoch:20 step:16044[D loss: 0.457765, acc: 53.91%, op_acc: 30.47%] [G loss: 0.903302]\n",
      "epoch:20 step:16045[D loss: 0.407495, acc: 60.16%, op_acc: 37.50%] [G loss: 0.960377]\n",
      "epoch:20 step:16046[D loss: 0.458179, acc: 54.69%, op_acc: 40.62%] [G loss: 0.926683]\n",
      "epoch:20 step:16047[D loss: 0.448479, acc: 57.81%, op_acc: 36.72%] [G loss: 0.856343]\n",
      "epoch:20 step:16048[D loss: 0.422690, acc: 57.81%, op_acc: 40.62%] [G loss: 0.854465]\n",
      "epoch:20 step:16049[D loss: 0.416890, acc: 63.28%, op_acc: 43.75%] [G loss: 0.838980]\n",
      "epoch:20 step:16050[D loss: 0.411307, acc: 64.06%, op_acc: 39.06%] [G loss: 0.877364]\n",
      "epoch:20 step:16051[D loss: 0.413567, acc: 61.72%, op_acc: 41.41%] [G loss: 0.875668]\n",
      "epoch:20 step:16052[D loss: 0.410422, acc: 57.81%, op_acc: 43.75%] [G loss: 0.881357]\n",
      "epoch:20 step:16053[D loss: 0.410291, acc: 63.28%, op_acc: 37.50%] [G loss: 0.896266]\n",
      "epoch:20 step:16054[D loss: 0.432331, acc: 57.03%, op_acc: 43.75%] [G loss: 0.919014]\n",
      "epoch:20 step:16055[D loss: 0.398203, acc: 63.28%, op_acc: 43.75%] [G loss: 0.845521]\n",
      "epoch:20 step:16056[D loss: 0.448214, acc: 53.91%, op_acc: 35.16%] [G loss: 0.875684]\n",
      "epoch:20 step:16057[D loss: 0.428920, acc: 57.81%, op_acc: 36.72%] [G loss: 0.818740]\n",
      "epoch:20 step:16058[D loss: 0.400453, acc: 67.19%, op_acc: 39.06%] [G loss: 0.883173]\n",
      "epoch:20 step:16059[D loss: 0.388606, acc: 61.72%, op_acc: 38.28%] [G loss: 0.877764]\n",
      "epoch:20 step:16060[D loss: 0.446450, acc: 60.16%, op_acc: 41.41%] [G loss: 0.913089]\n",
      "epoch:20 step:16061[D loss: 0.432699, acc: 57.03%, op_acc: 39.84%] [G loss: 0.925080]\n",
      "epoch:20 step:16062[D loss: 0.412921, acc: 59.38%, op_acc: 44.53%] [G loss: 0.863579]\n",
      "epoch:20 step:16063[D loss: 0.433813, acc: 60.16%, op_acc: 38.28%] [G loss: 0.825855]\n",
      "epoch:20 step:16064[D loss: 0.387679, acc: 68.75%, op_acc: 44.53%] [G loss: 0.945578]\n",
      "epoch:20 step:16065[D loss: 0.452891, acc: 58.59%, op_acc: 41.41%] [G loss: 0.929917]\n",
      "epoch:20 step:16066[D loss: 0.428292, acc: 62.50%, op_acc: 39.84%] [G loss: 0.851241]\n",
      "epoch:20 step:16067[D loss: 0.462199, acc: 59.38%, op_acc: 37.50%] [G loss: 0.909372]\n",
      "epoch:20 step:16068[D loss: 0.408867, acc: 63.28%, op_acc: 42.19%] [G loss: 0.779230]\n",
      "epoch:20 step:16069[D loss: 0.406623, acc: 66.41%, op_acc: 43.75%] [G loss: 0.854496]\n",
      "epoch:20 step:16070[D loss: 0.440753, acc: 57.03%, op_acc: 34.38%] [G loss: 0.887508]\n",
      "epoch:20 step:16071[D loss: 0.415716, acc: 56.25%, op_acc: 42.19%] [G loss: 0.884090]\n",
      "epoch:20 step:16072[D loss: 0.434281, acc: 50.78%, op_acc: 36.72%] [G loss: 0.771881]\n",
      "epoch:20 step:16073[D loss: 0.415055, acc: 60.16%, op_acc: 35.94%] [G loss: 0.918657]\n",
      "epoch:20 step:16074[D loss: 0.425321, acc: 62.50%, op_acc: 35.94%] [G loss: 0.860682]\n",
      "epoch:20 step:16075[D loss: 0.452436, acc: 54.69%, op_acc: 32.03%] [G loss: 0.953415]\n",
      "epoch:20 step:16076[D loss: 0.421039, acc: 67.19%, op_acc: 39.84%] [G loss: 0.917433]\n",
      "epoch:20 step:16077[D loss: 0.429142, acc: 56.25%, op_acc: 30.47%] [G loss: 0.842064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16078[D loss: 0.422798, acc: 60.16%, op_acc: 41.41%] [G loss: 0.865642]\n",
      "epoch:20 step:16079[D loss: 0.419878, acc: 57.81%, op_acc: 39.84%] [G loss: 0.925406]\n",
      "epoch:20 step:16080[D loss: 0.422562, acc: 61.72%, op_acc: 39.84%] [G loss: 0.985469]\n",
      "epoch:20 step:16081[D loss: 0.455894, acc: 49.22%, op_acc: 42.97%] [G loss: 0.900076]\n",
      "epoch:20 step:16082[D loss: 0.449192, acc: 51.56%, op_acc: 36.72%] [G loss: 0.824147]\n",
      "epoch:20 step:16083[D loss: 0.438286, acc: 56.25%, op_acc: 37.50%] [G loss: 0.873038]\n",
      "epoch:20 step:16084[D loss: 0.449358, acc: 58.59%, op_acc: 36.72%] [G loss: 0.856700]\n",
      "epoch:20 step:16085[D loss: 0.417710, acc: 60.16%, op_acc: 40.62%] [G loss: 0.871501]\n",
      "epoch:20 step:16086[D loss: 0.415634, acc: 53.12%, op_acc: 40.62%] [G loss: 0.856767]\n",
      "epoch:20 step:16087[D loss: 0.447949, acc: 54.69%, op_acc: 33.59%] [G loss: 0.850605]\n",
      "epoch:20 step:16088[D loss: 0.418279, acc: 53.91%, op_acc: 40.62%] [G loss: 0.933407]\n",
      "epoch:20 step:16089[D loss: 0.375646, acc: 64.84%, op_acc: 40.62%] [G loss: 0.930276]\n",
      "epoch:20 step:16090[D loss: 0.410637, acc: 57.03%, op_acc: 42.19%] [G loss: 0.888593]\n",
      "epoch:20 step:16091[D loss: 0.456795, acc: 57.03%, op_acc: 39.84%] [G loss: 0.864712]\n",
      "epoch:20 step:16092[D loss: 0.442346, acc: 50.78%, op_acc: 35.94%] [G loss: 0.885954]\n",
      "epoch:20 step:16093[D loss: 0.378629, acc: 67.97%, op_acc: 45.31%] [G loss: 0.858122]\n",
      "epoch:20 step:16094[D loss: 0.451438, acc: 57.03%, op_acc: 31.25%] [G loss: 0.965971]\n",
      "epoch:20 step:16095[D loss: 0.419637, acc: 60.94%, op_acc: 35.16%] [G loss: 0.880167]\n",
      "epoch:20 step:16096[D loss: 0.457858, acc: 54.69%, op_acc: 32.81%] [G loss: 0.879933]\n",
      "epoch:20 step:16097[D loss: 0.443671, acc: 56.25%, op_acc: 40.62%] [G loss: 0.883378]\n",
      "epoch:20 step:16098[D loss: 0.416716, acc: 61.72%, op_acc: 39.84%] [G loss: 0.918150]\n",
      "epoch:20 step:16099[D loss: 0.424056, acc: 56.25%, op_acc: 41.41%] [G loss: 0.915457]\n",
      "epoch:20 step:16100[D loss: 0.432983, acc: 58.59%, op_acc: 39.06%] [G loss: 0.922038]\n",
      "epoch:20 step:16101[D loss: 0.451709, acc: 57.03%, op_acc: 32.03%] [G loss: 0.866649]\n",
      "epoch:20 step:16102[D loss: 0.440415, acc: 60.16%, op_acc: 33.59%] [G loss: 0.821423]\n",
      "epoch:20 step:16103[D loss: 0.401706, acc: 65.62%, op_acc: 39.06%] [G loss: 0.967422]\n",
      "epoch:20 step:16104[D loss: 0.422897, acc: 57.03%, op_acc: 40.62%] [G loss: 0.878757]\n",
      "epoch:20 step:16105[D loss: 0.439863, acc: 54.69%, op_acc: 32.81%] [G loss: 0.871086]\n",
      "epoch:20 step:16106[D loss: 0.404911, acc: 59.38%, op_acc: 46.09%] [G loss: 0.888936]\n",
      "epoch:20 step:16107[D loss: 0.435772, acc: 56.25%, op_acc: 37.50%] [G loss: 0.836890]\n",
      "epoch:20 step:16108[D loss: 0.445057, acc: 53.91%, op_acc: 36.72%] [G loss: 0.783240]\n",
      "epoch:20 step:16109[D loss: 0.451160, acc: 53.91%, op_acc: 39.06%] [G loss: 0.873961]\n",
      "epoch:20 step:16110[D loss: 0.408481, acc: 60.94%, op_acc: 42.97%] [G loss: 0.856122]\n",
      "epoch:20 step:16111[D loss: 0.451466, acc: 63.28%, op_acc: 35.16%] [G loss: 0.855505]\n",
      "epoch:20 step:16112[D loss: 0.411746, acc: 64.06%, op_acc: 39.06%] [G loss: 0.855857]\n",
      "epoch:20 step:16113[D loss: 0.403584, acc: 64.06%, op_acc: 40.62%] [G loss: 0.900747]\n",
      "epoch:20 step:16114[D loss: 0.431637, acc: 60.16%, op_acc: 40.62%] [G loss: 0.902886]\n",
      "epoch:20 step:16115[D loss: 0.419701, acc: 72.66%, op_acc: 31.25%] [G loss: 0.913604]\n",
      "epoch:20 step:16116[D loss: 0.410244, acc: 60.16%, op_acc: 45.31%] [G loss: 0.870863]\n",
      "epoch:20 step:16117[D loss: 0.409659, acc: 60.94%, op_acc: 37.50%] [G loss: 0.869890]\n",
      "epoch:20 step:16118[D loss: 0.419605, acc: 64.06%, op_acc: 41.41%] [G loss: 0.908616]\n",
      "epoch:20 step:16119[D loss: 0.427169, acc: 64.06%, op_acc: 37.50%] [G loss: 0.840501]\n",
      "epoch:20 step:16120[D loss: 0.402767, acc: 63.28%, op_acc: 42.19%] [G loss: 0.883765]\n",
      "epoch:20 step:16121[D loss: 0.432080, acc: 60.94%, op_acc: 39.84%] [G loss: 0.893655]\n",
      "epoch:20 step:16122[D loss: 0.429095, acc: 62.50%, op_acc: 36.72%] [G loss: 0.864064]\n",
      "epoch:20 step:16123[D loss: 0.408099, acc: 64.84%, op_acc: 41.41%] [G loss: 0.912199]\n",
      "epoch:20 step:16124[D loss: 0.423198, acc: 55.47%, op_acc: 38.28%] [G loss: 0.812018]\n",
      "epoch:20 step:16125[D loss: 0.412276, acc: 67.19%, op_acc: 41.41%] [G loss: 0.883478]\n",
      "epoch:20 step:16126[D loss: 0.441182, acc: 59.38%, op_acc: 35.94%] [G loss: 0.826817]\n",
      "epoch:20 step:16127[D loss: 0.434593, acc: 55.47%, op_acc: 35.94%] [G loss: 0.826852]\n",
      "epoch:20 step:16128[D loss: 0.444790, acc: 57.03%, op_acc: 36.72%] [G loss: 0.845078]\n",
      "epoch:20 step:16129[D loss: 0.453463, acc: 55.47%, op_acc: 42.97%] [G loss: 0.883040]\n",
      "epoch:20 step:16130[D loss: 0.408260, acc: 57.03%, op_acc: 44.53%] [G loss: 0.854510]\n",
      "epoch:20 step:16131[D loss: 0.429902, acc: 59.38%, op_acc: 40.62%] [G loss: 0.855934]\n",
      "epoch:20 step:16132[D loss: 0.445353, acc: 58.59%, op_acc: 35.94%] [G loss: 0.895063]\n",
      "epoch:20 step:16133[D loss: 0.463545, acc: 52.34%, op_acc: 31.25%] [G loss: 0.834064]\n",
      "epoch:20 step:16134[D loss: 0.460924, acc: 53.91%, op_acc: 34.38%] [G loss: 0.804373]\n",
      "epoch:20 step:16135[D loss: 0.432026, acc: 60.16%, op_acc: 34.38%] [G loss: 0.839701]\n",
      "epoch:20 step:16136[D loss: 0.425459, acc: 58.59%, op_acc: 38.28%] [G loss: 0.879383]\n",
      "epoch:20 step:16137[D loss: 0.465577, acc: 50.78%, op_acc: 39.06%] [G loss: 0.827117]\n",
      "epoch:20 step:16138[D loss: 0.451281, acc: 47.66%, op_acc: 39.84%] [G loss: 0.830730]\n",
      "epoch:20 step:16139[D loss: 0.413095, acc: 59.38%, op_acc: 35.94%] [G loss: 0.899742]\n",
      "epoch:20 step:16140[D loss: 0.410275, acc: 63.28%, op_acc: 42.19%] [G loss: 0.922853]\n",
      "epoch:20 step:16141[D loss: 0.428458, acc: 59.38%, op_acc: 35.16%] [G loss: 0.890144]\n",
      "epoch:20 step:16142[D loss: 0.435974, acc: 61.72%, op_acc: 35.94%] [G loss: 0.890332]\n",
      "epoch:20 step:16143[D loss: 0.439611, acc: 54.69%, op_acc: 36.72%] [G loss: 0.894776]\n",
      "epoch:20 step:16144[D loss: 0.416209, acc: 63.28%, op_acc: 36.72%] [G loss: 0.776429]\n",
      "epoch:20 step:16145[D loss: 0.422844, acc: 64.06%, op_acc: 31.25%] [G loss: 0.861088]\n",
      "epoch:20 step:16146[D loss: 0.460947, acc: 54.69%, op_acc: 30.47%] [G loss: 0.908018]\n",
      "epoch:20 step:16147[D loss: 0.423609, acc: 58.59%, op_acc: 38.28%] [G loss: 0.887476]\n",
      "epoch:20 step:16148[D loss: 0.421356, acc: 61.72%, op_acc: 38.28%] [G loss: 0.868818]\n",
      "epoch:20 step:16149[D loss: 0.435831, acc: 54.69%, op_acc: 40.62%] [G loss: 0.896209]\n",
      "epoch:20 step:16150[D loss: 0.418539, acc: 65.62%, op_acc: 35.16%] [G loss: 0.858733]\n",
      "epoch:20 step:16151[D loss: 0.430814, acc: 57.03%, op_acc: 36.72%] [G loss: 0.905485]\n",
      "epoch:20 step:16152[D loss: 0.439328, acc: 56.25%, op_acc: 38.28%] [G loss: 0.872225]\n",
      "epoch:20 step:16153[D loss: 0.428259, acc: 56.25%, op_acc: 37.50%] [G loss: 0.880439]\n",
      "epoch:20 step:16154[D loss: 0.419457, acc: 60.16%, op_acc: 39.06%] [G loss: 0.869425]\n",
      "epoch:20 step:16155[D loss: 0.425022, acc: 63.28%, op_acc: 39.06%] [G loss: 0.938222]\n",
      "epoch:20 step:16156[D loss: 0.413524, acc: 60.16%, op_acc: 42.19%] [G loss: 0.894073]\n",
      "epoch:20 step:16157[D loss: 0.461053, acc: 51.56%, op_acc: 27.34%] [G loss: 0.829716]\n",
      "epoch:20 step:16158[D loss: 0.410096, acc: 57.03%, op_acc: 42.97%] [G loss: 0.901887]\n",
      "epoch:20 step:16159[D loss: 0.459629, acc: 52.34%, op_acc: 35.16%] [G loss: 0.885672]\n",
      "epoch:20 step:16160[D loss: 0.446841, acc: 52.34%, op_acc: 41.41%] [G loss: 0.873596]\n",
      "epoch:20 step:16161[D loss: 0.407082, acc: 61.72%, op_acc: 39.06%] [G loss: 0.901179]\n",
      "epoch:20 step:16162[D loss: 0.423537, acc: 61.72%, op_acc: 37.50%] [G loss: 0.905485]\n",
      "epoch:20 step:16163[D loss: 0.445795, acc: 53.91%, op_acc: 36.72%] [G loss: 0.905046]\n",
      "epoch:20 step:16164[D loss: 0.407802, acc: 60.16%, op_acc: 39.06%] [G loss: 0.911458]\n",
      "epoch:20 step:16165[D loss: 0.399426, acc: 60.94%, op_acc: 41.41%] [G loss: 0.861237]\n",
      "epoch:20 step:16166[D loss: 0.409253, acc: 60.94%, op_acc: 44.53%] [G loss: 0.867190]\n",
      "epoch:20 step:16167[D loss: 0.408447, acc: 66.41%, op_acc: 38.28%] [G loss: 0.918357]\n",
      "epoch:20 step:16168[D loss: 0.439610, acc: 53.12%, op_acc: 35.94%] [G loss: 0.917313]\n",
      "epoch:20 step:16169[D loss: 0.401980, acc: 62.50%, op_acc: 42.97%] [G loss: 0.896649]\n",
      "epoch:20 step:16170[D loss: 0.433295, acc: 57.81%, op_acc: 40.62%] [G loss: 0.885708]\n",
      "epoch:20 step:16171[D loss: 0.433228, acc: 55.47%, op_acc: 36.72%] [G loss: 0.861164]\n",
      "epoch:20 step:16172[D loss: 0.472391, acc: 51.56%, op_acc: 32.81%] [G loss: 0.835005]\n",
      "epoch:20 step:16173[D loss: 0.400892, acc: 62.50%, op_acc: 42.97%] [G loss: 0.852887]\n",
      "epoch:20 step:16174[D loss: 0.430895, acc: 58.59%, op_acc: 34.38%] [G loss: 0.857750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16175[D loss: 0.422742, acc: 57.03%, op_acc: 41.41%] [G loss: 0.841357]\n",
      "epoch:20 step:16176[D loss: 0.438539, acc: 60.16%, op_acc: 38.28%] [G loss: 0.953650]\n",
      "epoch:20 step:16177[D loss: 0.445139, acc: 58.59%, op_acc: 33.59%] [G loss: 0.842058]\n",
      "epoch:20 step:16178[D loss: 0.448816, acc: 57.81%, op_acc: 42.19%] [G loss: 0.861562]\n",
      "epoch:20 step:16179[D loss: 0.415091, acc: 63.28%, op_acc: 36.72%] [G loss: 0.780448]\n",
      "epoch:20 step:16180[D loss: 0.451691, acc: 56.25%, op_acc: 35.94%] [G loss: 0.892391]\n",
      "epoch:20 step:16181[D loss: 0.417634, acc: 60.94%, op_acc: 42.97%] [G loss: 0.878748]\n",
      "epoch:20 step:16182[D loss: 0.414372, acc: 64.06%, op_acc: 35.16%] [G loss: 0.919366]\n",
      "epoch:20 step:16183[D loss: 0.437601, acc: 55.47%, op_acc: 36.72%] [G loss: 0.912934]\n",
      "epoch:20 step:16184[D loss: 0.406418, acc: 58.59%, op_acc: 42.19%] [G loss: 0.847012]\n",
      "epoch:20 step:16185[D loss: 0.409222, acc: 63.28%, op_acc: 41.41%] [G loss: 0.864898]\n",
      "epoch:20 step:16186[D loss: 0.410685, acc: 60.94%, op_acc: 44.53%] [G loss: 0.918687]\n",
      "epoch:20 step:16187[D loss: 0.429753, acc: 57.81%, op_acc: 41.41%] [G loss: 0.829030]\n",
      "epoch:20 step:16188[D loss: 0.422246, acc: 56.25%, op_acc: 41.41%] [G loss: 0.910283]\n",
      "epoch:20 step:16189[D loss: 0.399039, acc: 63.28%, op_acc: 39.06%] [G loss: 0.856575]\n",
      "epoch:20 step:16190[D loss: 0.427171, acc: 57.03%, op_acc: 38.28%] [G loss: 0.902128]\n",
      "epoch:20 step:16191[D loss: 0.401074, acc: 61.72%, op_acc: 45.31%] [G loss: 0.925556]\n",
      "epoch:20 step:16192[D loss: 0.414845, acc: 60.94%, op_acc: 36.72%] [G loss: 0.887940]\n",
      "epoch:20 step:16193[D loss: 0.453017, acc: 54.69%, op_acc: 39.84%] [G loss: 0.912440]\n",
      "epoch:20 step:16194[D loss: 0.412540, acc: 60.94%, op_acc: 34.38%] [G loss: 0.872539]\n",
      "epoch:20 step:16195[D loss: 0.430738, acc: 60.94%, op_acc: 40.62%] [G loss: 0.836098]\n",
      "epoch:20 step:16196[D loss: 0.436851, acc: 55.47%, op_acc: 37.50%] [G loss: 0.929106]\n",
      "epoch:20 step:16197[D loss: 0.441253, acc: 55.47%, op_acc: 32.81%] [G loss: 0.966024]\n",
      "epoch:20 step:16198[D loss: 0.450043, acc: 57.03%, op_acc: 32.81%] [G loss: 0.981960]\n",
      "epoch:20 step:16199[D loss: 0.400816, acc: 66.41%, op_acc: 43.75%] [G loss: 0.851357]\n",
      "epoch:20 step:16200[D loss: 0.426387, acc: 57.03%, op_acc: 39.06%] [G loss: 0.853316]\n",
      "epoch:20 step:16201[D loss: 0.441703, acc: 57.03%, op_acc: 31.25%] [G loss: 0.865302]\n",
      "epoch:20 step:16202[D loss: 0.436115, acc: 58.59%, op_acc: 38.28%] [G loss: 0.880015]\n",
      "epoch:20 step:16203[D loss: 0.402007, acc: 64.06%, op_acc: 38.28%] [G loss: 0.923194]\n",
      "epoch:20 step:16204[D loss: 0.464869, acc: 57.03%, op_acc: 32.03%] [G loss: 0.856570]\n",
      "epoch:20 step:16205[D loss: 0.433594, acc: 53.12%, op_acc: 38.28%] [G loss: 0.893359]\n",
      "epoch:20 step:16206[D loss: 0.401583, acc: 60.94%, op_acc: 44.53%] [G loss: 0.930469]\n",
      "epoch:20 step:16207[D loss: 0.412567, acc: 64.84%, op_acc: 39.84%] [G loss: 0.877710]\n",
      "epoch:20 step:16208[D loss: 0.398936, acc: 67.19%, op_acc: 42.97%] [G loss: 0.844449]\n",
      "epoch:20 step:16209[D loss: 0.420336, acc: 64.84%, op_acc: 34.38%] [G loss: 0.884872]\n",
      "epoch:20 step:16210[D loss: 0.417967, acc: 55.47%, op_acc: 42.19%] [G loss: 0.930175]\n",
      "epoch:20 step:16211[D loss: 0.458195, acc: 52.34%, op_acc: 36.72%] [G loss: 0.937817]\n",
      "epoch:20 step:16212[D loss: 0.443583, acc: 58.59%, op_acc: 41.41%] [G loss: 0.838457]\n",
      "epoch:20 step:16213[D loss: 0.448659, acc: 55.47%, op_acc: 35.94%] [G loss: 0.854800]\n",
      "epoch:20 step:16214[D loss: 0.434814, acc: 58.59%, op_acc: 40.62%] [G loss: 0.779336]\n",
      "epoch:20 step:16215[D loss: 0.423275, acc: 60.16%, op_acc: 41.41%] [G loss: 0.877530]\n",
      "epoch:20 step:16216[D loss: 0.435236, acc: 54.69%, op_acc: 35.16%] [G loss: 0.913086]\n",
      "epoch:20 step:16217[D loss: 0.420235, acc: 60.16%, op_acc: 40.62%] [G loss: 0.877960]\n",
      "epoch:20 step:16218[D loss: 0.413176, acc: 64.06%, op_acc: 40.62%] [G loss: 0.914843]\n",
      "epoch:20 step:16219[D loss: 0.447340, acc: 55.47%, op_acc: 33.59%] [G loss: 0.867835]\n",
      "epoch:20 step:16220[D loss: 0.434628, acc: 53.12%, op_acc: 39.84%] [G loss: 0.827569]\n",
      "epoch:20 step:16221[D loss: 0.425231, acc: 60.16%, op_acc: 37.50%] [G loss: 0.939272]\n",
      "epoch:20 step:16222[D loss: 0.408291, acc: 59.38%, op_acc: 44.53%] [G loss: 0.909399]\n",
      "epoch:20 step:16223[D loss: 0.378597, acc: 68.75%, op_acc: 42.19%] [G loss: 0.934103]\n",
      "epoch:20 step:16224[D loss: 0.442463, acc: 57.03%, op_acc: 36.72%] [G loss: 0.904824]\n",
      "epoch:20 step:16225[D loss: 0.406692, acc: 66.41%, op_acc: 42.19%] [G loss: 0.935642]\n",
      "epoch:20 step:16226[D loss: 0.448480, acc: 52.34%, op_acc: 38.28%] [G loss: 0.828686]\n",
      "epoch:20 step:16227[D loss: 0.430284, acc: 53.91%, op_acc: 40.62%] [G loss: 0.896052]\n",
      "epoch:20 step:16228[D loss: 0.396738, acc: 63.28%, op_acc: 40.62%] [G loss: 0.967307]\n",
      "epoch:20 step:16229[D loss: 0.434915, acc: 53.12%, op_acc: 42.97%] [G loss: 0.918170]\n",
      "epoch:20 step:16230[D loss: 0.441947, acc: 62.50%, op_acc: 36.72%] [G loss: 0.883520]\n",
      "epoch:20 step:16231[D loss: 0.446175, acc: 51.56%, op_acc: 35.16%] [G loss: 0.824555]\n",
      "epoch:20 step:16232[D loss: 0.433616, acc: 60.16%, op_acc: 36.72%] [G loss: 0.888529]\n",
      "epoch:20 step:16233[D loss: 0.439445, acc: 53.12%, op_acc: 42.19%] [G loss: 0.880328]\n",
      "epoch:20 step:16234[D loss: 0.409191, acc: 66.41%, op_acc: 39.06%] [G loss: 0.891676]\n",
      "epoch:20 step:16235[D loss: 0.430590, acc: 60.16%, op_acc: 36.72%] [G loss: 0.841773]\n",
      "epoch:20 step:16236[D loss: 0.427801, acc: 63.28%, op_acc: 39.06%] [G loss: 0.880915]\n",
      "epoch:20 step:16237[D loss: 0.439861, acc: 48.44%, op_acc: 38.28%] [G loss: 0.972152]\n",
      "epoch:20 step:16238[D loss: 0.401771, acc: 60.16%, op_acc: 47.66%] [G loss: 0.869346]\n",
      "epoch:20 step:16239[D loss: 0.422234, acc: 61.72%, op_acc: 44.53%] [G loss: 0.890281]\n",
      "epoch:20 step:16240[D loss: 0.441337, acc: 53.12%, op_acc: 34.38%] [G loss: 0.857314]\n",
      "epoch:20 step:16241[D loss: 0.409661, acc: 64.84%, op_acc: 39.06%] [G loss: 0.860401]\n",
      "epoch:20 step:16242[D loss: 0.458287, acc: 57.81%, op_acc: 39.84%] [G loss: 0.868004]\n",
      "epoch:20 step:16243[D loss: 0.404664, acc: 59.38%, op_acc: 41.41%] [G loss: 0.891050]\n",
      "epoch:20 step:16244[D loss: 0.472556, acc: 49.22%, op_acc: 34.38%] [G loss: 0.799005]\n",
      "epoch:20 step:16245[D loss: 0.444255, acc: 57.03%, op_acc: 37.50%] [G loss: 0.848979]\n",
      "epoch:20 step:16246[D loss: 0.457173, acc: 41.41%, op_acc: 38.28%] [G loss: 0.860265]\n",
      "epoch:20 step:16247[D loss: 0.437357, acc: 60.16%, op_acc: 42.97%] [G loss: 0.935195]\n",
      "epoch:20 step:16248[D loss: 0.430976, acc: 62.50%, op_acc: 42.97%] [G loss: 0.952673]\n",
      "epoch:20 step:16249[D loss: 0.449235, acc: 58.59%, op_acc: 37.50%] [G loss: 0.994163]\n",
      "epoch:20 step:16250[D loss: 0.401433, acc: 60.16%, op_acc: 40.62%] [G loss: 0.856852]\n",
      "epoch:20 step:16251[D loss: 0.440909, acc: 57.03%, op_acc: 40.62%] [G loss: 0.888156]\n",
      "epoch:20 step:16252[D loss: 0.458028, acc: 53.91%, op_acc: 35.16%] [G loss: 0.841027]\n",
      "epoch:20 step:16253[D loss: 0.448842, acc: 58.59%, op_acc: 35.16%] [G loss: 0.959775]\n",
      "epoch:20 step:16254[D loss: 0.431080, acc: 58.59%, op_acc: 38.28%] [G loss: 0.882762]\n",
      "epoch:20 step:16255[D loss: 0.451094, acc: 55.47%, op_acc: 40.62%] [G loss: 0.862861]\n",
      "epoch:20 step:16256[D loss: 0.410549, acc: 58.59%, op_acc: 43.75%] [G loss: 0.885853]\n",
      "epoch:20 step:16257[D loss: 0.433501, acc: 53.12%, op_acc: 38.28%] [G loss: 0.929771]\n",
      "epoch:20 step:16258[D loss: 0.420563, acc: 60.94%, op_acc: 38.28%] [G loss: 0.913181]\n",
      "epoch:20 step:16259[D loss: 0.444133, acc: 57.03%, op_acc: 36.72%] [G loss: 0.881680]\n",
      "epoch:20 step:16260[D loss: 0.458016, acc: 53.91%, op_acc: 37.50%] [G loss: 0.917542]\n",
      "epoch:20 step:16261[D loss: 0.440626, acc: 57.81%, op_acc: 35.94%] [G loss: 0.873055]\n",
      "epoch:20 step:16262[D loss: 0.454173, acc: 53.91%, op_acc: 35.94%] [G loss: 0.908668]\n",
      "epoch:20 step:16263[D loss: 0.468193, acc: 52.34%, op_acc: 35.16%] [G loss: 0.954003]\n",
      "epoch:20 step:16264[D loss: 0.416726, acc: 59.38%, op_acc: 37.50%] [G loss: 0.892898]\n",
      "epoch:20 step:16265[D loss: 0.415341, acc: 60.16%, op_acc: 41.41%] [G loss: 0.917116]\n",
      "epoch:20 step:16266[D loss: 0.468651, acc: 60.94%, op_acc: 34.38%] [G loss: 0.918680]\n",
      "epoch:20 step:16267[D loss: 0.407661, acc: 57.81%, op_acc: 41.41%] [G loss: 0.875748]\n",
      "epoch:20 step:16268[D loss: 0.414270, acc: 63.28%, op_acc: 38.28%] [G loss: 0.862779]\n",
      "epoch:20 step:16269[D loss: 0.411954, acc: 67.19%, op_acc: 34.38%] [G loss: 0.968134]\n",
      "epoch:20 step:16270[D loss: 0.450758, acc: 60.94%, op_acc: 36.72%] [G loss: 0.881989]\n",
      "epoch:20 step:16271[D loss: 0.434291, acc: 54.69%, op_acc: 38.28%] [G loss: 0.919775]\n",
      "epoch:20 step:16272[D loss: 0.438504, acc: 55.47%, op_acc: 37.50%] [G loss: 0.893158]\n",
      "epoch:20 step:16273[D loss: 0.449651, acc: 50.00%, op_acc: 40.62%] [G loss: 0.826905]\n",
      "epoch:20 step:16274[D loss: 0.411059, acc: 58.59%, op_acc: 38.28%] [G loss: 0.854066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16275[D loss: 0.425437, acc: 60.94%, op_acc: 38.28%] [G loss: 0.833703]\n",
      "epoch:20 step:16276[D loss: 0.425861, acc: 57.81%, op_acc: 39.84%] [G loss: 0.850436]\n",
      "epoch:20 step:16277[D loss: 0.407756, acc: 61.72%, op_acc: 45.31%] [G loss: 0.957769]\n",
      "epoch:20 step:16278[D loss: 0.421305, acc: 61.72%, op_acc: 39.06%] [G loss: 0.914218]\n",
      "epoch:20 step:16279[D loss: 0.408843, acc: 65.62%, op_acc: 35.16%] [G loss: 0.975176]\n",
      "epoch:20 step:16280[D loss: 0.419259, acc: 60.16%, op_acc: 38.28%] [G loss: 0.860821]\n",
      "epoch:20 step:16281[D loss: 0.404071, acc: 58.59%, op_acc: 45.31%] [G loss: 0.804329]\n",
      "epoch:20 step:16282[D loss: 0.421198, acc: 60.16%, op_acc: 39.06%] [G loss: 0.895655]\n",
      "epoch:20 step:16283[D loss: 0.437007, acc: 57.03%, op_acc: 38.28%] [G loss: 0.855001]\n",
      "epoch:20 step:16284[D loss: 0.423294, acc: 58.59%, op_acc: 43.75%] [G loss: 0.883543]\n",
      "epoch:20 step:16285[D loss: 0.455356, acc: 53.91%, op_acc: 32.81%] [G loss: 0.779325]\n",
      "epoch:20 step:16286[D loss: 0.459767, acc: 53.91%, op_acc: 34.38%] [G loss: 0.774314]\n",
      "epoch:20 step:16287[D loss: 0.395874, acc: 65.62%, op_acc: 36.72%] [G loss: 0.861478]\n",
      "epoch:20 step:16288[D loss: 0.434633, acc: 59.38%, op_acc: 33.59%] [G loss: 0.866648]\n",
      "epoch:20 step:16289[D loss: 0.449960, acc: 55.47%, op_acc: 37.50%] [G loss: 0.846744]\n",
      "epoch:20 step:16290[D loss: 0.405462, acc: 60.16%, op_acc: 42.19%] [G loss: 0.857720]\n",
      "epoch:20 step:16291[D loss: 0.432841, acc: 54.69%, op_acc: 35.94%] [G loss: 0.898194]\n",
      "epoch:20 step:16292[D loss: 0.462900, acc: 53.12%, op_acc: 39.84%] [G loss: 0.854113]\n",
      "epoch:20 step:16293[D loss: 0.472573, acc: 52.34%, op_acc: 35.94%] [G loss: 0.850386]\n",
      "epoch:20 step:16294[D loss: 0.404460, acc: 55.47%, op_acc: 43.75%] [G loss: 0.998691]\n",
      "epoch:20 step:16295[D loss: 0.422777, acc: 62.50%, op_acc: 34.38%] [G loss: 0.947429]\n",
      "epoch:20 step:16296[D loss: 0.442713, acc: 53.91%, op_acc: 39.84%] [G loss: 0.970335]\n",
      "epoch:20 step:16297[D loss: 0.452141, acc: 61.72%, op_acc: 35.16%] [G loss: 0.832377]\n",
      "epoch:20 step:16298[D loss: 0.426745, acc: 61.72%, op_acc: 38.28%] [G loss: 0.869843]\n",
      "epoch:20 step:16299[D loss: 0.417066, acc: 57.81%, op_acc: 37.50%] [G loss: 0.852919]\n",
      "epoch:20 step:16300[D loss: 0.427315, acc: 57.03%, op_acc: 41.41%] [G loss: 0.815329]\n",
      "epoch:20 step:16301[D loss: 0.462996, acc: 54.69%, op_acc: 34.38%] [G loss: 0.907480]\n",
      "epoch:20 step:16302[D loss: 0.388121, acc: 64.06%, op_acc: 43.75%] [G loss: 0.947142]\n",
      "epoch:20 step:16303[D loss: 0.437902, acc: 54.69%, op_acc: 37.50%] [G loss: 0.881770]\n",
      "epoch:20 step:16304[D loss: 0.438460, acc: 56.25%, op_acc: 33.59%] [G loss: 0.941345]\n",
      "epoch:20 step:16305[D loss: 0.443142, acc: 54.69%, op_acc: 37.50%] [G loss: 0.919133]\n",
      "epoch:20 step:16306[D loss: 0.437191, acc: 55.47%, op_acc: 35.94%] [G loss: 0.786632]\n",
      "epoch:20 step:16307[D loss: 0.397693, acc: 66.41%, op_acc: 42.97%] [G loss: 0.878751]\n",
      "epoch:20 step:16308[D loss: 0.444454, acc: 52.34%, op_acc: 37.50%] [G loss: 0.874781]\n",
      "epoch:20 step:16309[D loss: 0.439257, acc: 51.56%, op_acc: 39.84%] [G loss: 0.803864]\n",
      "epoch:20 step:16310[D loss: 0.414363, acc: 67.97%, op_acc: 36.72%] [G loss: 0.835523]\n",
      "epoch:20 step:16311[D loss: 0.392615, acc: 70.31%, op_acc: 39.84%] [G loss: 0.894339]\n",
      "epoch:20 step:16312[D loss: 0.437517, acc: 56.25%, op_acc: 35.16%] [G loss: 0.936593]\n",
      "epoch:20 step:16313[D loss: 0.429647, acc: 53.91%, op_acc: 36.72%] [G loss: 0.907156]\n",
      "epoch:20 step:16314[D loss: 0.426106, acc: 57.81%, op_acc: 39.84%] [G loss: 0.952075]\n",
      "epoch:20 step:16315[D loss: 0.425653, acc: 64.06%, op_acc: 36.72%] [G loss: 0.911647]\n",
      "epoch:20 step:16316[D loss: 0.442543, acc: 59.38%, op_acc: 37.50%] [G loss: 0.828331]\n",
      "epoch:20 step:16317[D loss: 0.423578, acc: 60.16%, op_acc: 41.41%] [G loss: 0.865142]\n",
      "epoch:20 step:16318[D loss: 0.419395, acc: 60.94%, op_acc: 39.06%] [G loss: 0.903831]\n",
      "epoch:20 step:16319[D loss: 0.399721, acc: 60.94%, op_acc: 42.97%] [G loss: 0.869446]\n",
      "epoch:20 step:16320[D loss: 0.448820, acc: 55.47%, op_acc: 35.16%] [G loss: 0.874511]\n",
      "epoch:20 step:16321[D loss: 0.439691, acc: 57.03%, op_acc: 37.50%] [G loss: 0.858365]\n",
      "epoch:20 step:16322[D loss: 0.428670, acc: 62.50%, op_acc: 37.50%] [G loss: 0.829650]\n",
      "epoch:20 step:16323[D loss: 0.439242, acc: 54.69%, op_acc: 37.50%] [G loss: 0.861159]\n",
      "epoch:20 step:16324[D loss: 0.406574, acc: 60.16%, op_acc: 40.62%] [G loss: 0.874662]\n",
      "epoch:20 step:16325[D loss: 0.443913, acc: 51.56%, op_acc: 37.50%] [G loss: 0.785944]\n",
      "epoch:20 step:16326[D loss: 0.437530, acc: 56.25%, op_acc: 42.19%] [G loss: 0.845244]\n",
      "epoch:20 step:16327[D loss: 0.459396, acc: 52.34%, op_acc: 32.81%] [G loss: 0.776603]\n",
      "epoch:20 step:16328[D loss: 0.441609, acc: 54.69%, op_acc: 38.28%] [G loss: 0.924820]\n",
      "epoch:20 step:16329[D loss: 0.429243, acc: 61.72%, op_acc: 40.62%] [G loss: 0.840658]\n",
      "epoch:20 step:16330[D loss: 0.412423, acc: 60.94%, op_acc: 46.88%] [G loss: 0.859320]\n",
      "epoch:20 step:16331[D loss: 0.430172, acc: 60.94%, op_acc: 37.50%] [G loss: 0.910733]\n",
      "epoch:20 step:16332[D loss: 0.413301, acc: 64.06%, op_acc: 40.62%] [G loss: 0.898979]\n",
      "epoch:20 step:16333[D loss: 0.422233, acc: 56.25%, op_acc: 35.16%] [G loss: 0.809479]\n",
      "epoch:20 step:16334[D loss: 0.412354, acc: 71.09%, op_acc: 32.81%] [G loss: 0.910922]\n",
      "epoch:20 step:16335[D loss: 0.411613, acc: 62.50%, op_acc: 40.62%] [G loss: 0.861137]\n",
      "epoch:20 step:16336[D loss: 0.410030, acc: 70.31%, op_acc: 42.97%] [G loss: 0.820702]\n",
      "epoch:20 step:16337[D loss: 0.439979, acc: 55.47%, op_acc: 37.50%] [G loss: 0.775118]\n",
      "epoch:20 step:16338[D loss: 0.436118, acc: 57.81%, op_acc: 33.59%] [G loss: 0.846842]\n",
      "epoch:20 step:16339[D loss: 0.410411, acc: 61.72%, op_acc: 39.06%] [G loss: 0.829598]\n",
      "epoch:20 step:16340[D loss: 0.435470, acc: 64.84%, op_acc: 34.38%] [G loss: 0.943882]\n",
      "epoch:20 step:16341[D loss: 0.446783, acc: 52.34%, op_acc: 37.50%] [G loss: 0.916059]\n",
      "epoch:20 step:16342[D loss: 0.446239, acc: 47.66%, op_acc: 40.62%] [G loss: 0.932641]\n",
      "epoch:20 step:16343[D loss: 0.414687, acc: 60.16%, op_acc: 47.66%] [G loss: 0.835331]\n",
      "epoch:20 step:16344[D loss: 0.455157, acc: 58.59%, op_acc: 34.38%] [G loss: 0.840151]\n",
      "epoch:20 step:16345[D loss: 0.409368, acc: 56.25%, op_acc: 40.62%] [G loss: 0.859966]\n",
      "epoch:20 step:16346[D loss: 0.434399, acc: 53.91%, op_acc: 39.06%] [G loss: 0.866767]\n",
      "epoch:20 step:16347[D loss: 0.442853, acc: 57.81%, op_acc: 36.72%] [G loss: 0.900839]\n",
      "epoch:20 step:16348[D loss: 0.420349, acc: 60.16%, op_acc: 38.28%] [G loss: 0.940029]\n",
      "epoch:20 step:16349[D loss: 0.428591, acc: 60.16%, op_acc: 38.28%] [G loss: 0.880108]\n",
      "epoch:20 step:16350[D loss: 0.433192, acc: 58.59%, op_acc: 45.31%] [G loss: 0.892445]\n",
      "epoch:20 step:16351[D loss: 0.408891, acc: 59.38%, op_acc: 40.62%] [G loss: 0.917469]\n",
      "epoch:20 step:16352[D loss: 0.485874, acc: 48.44%, op_acc: 36.72%] [G loss: 0.954253]\n",
      "epoch:20 step:16353[D loss: 0.413750, acc: 58.59%, op_acc: 41.41%] [G loss: 0.885383]\n",
      "epoch:20 step:16354[D loss: 0.428942, acc: 57.03%, op_acc: 46.09%] [G loss: 0.788713]\n",
      "epoch:20 step:16355[D loss: 0.412811, acc: 61.72%, op_acc: 46.09%] [G loss: 0.885644]\n",
      "epoch:20 step:16356[D loss: 0.443741, acc: 54.69%, op_acc: 37.50%] [G loss: 0.860471]\n",
      "epoch:20 step:16357[D loss: 0.438848, acc: 47.66%, op_acc: 42.19%] [G loss: 0.815200]\n",
      "epoch:20 step:16358[D loss: 0.411269, acc: 63.28%, op_acc: 35.94%] [G loss: 0.923365]\n",
      "epoch:20 step:16359[D loss: 0.450826, acc: 55.47%, op_acc: 32.81%] [G loss: 0.867597]\n",
      "epoch:20 step:16360[D loss: 0.439850, acc: 53.12%, op_acc: 39.06%] [G loss: 0.866206]\n",
      "epoch:20 step:16361[D loss: 0.421631, acc: 60.16%, op_acc: 34.38%] [G loss: 0.842332]\n",
      "epoch:20 step:16362[D loss: 0.435508, acc: 56.25%, op_acc: 35.94%] [G loss: 0.834189]\n",
      "epoch:20 step:16363[D loss: 0.442632, acc: 65.62%, op_acc: 32.03%] [G loss: 0.807311]\n",
      "epoch:20 step:16364[D loss: 0.391222, acc: 60.94%, op_acc: 40.62%] [G loss: 0.926525]\n",
      "epoch:20 step:16365[D loss: 0.453046, acc: 48.44%, op_acc: 39.84%] [G loss: 0.834899]\n",
      "epoch:20 step:16366[D loss: 0.449808, acc: 53.91%, op_acc: 35.94%] [G loss: 0.901970]\n",
      "epoch:20 step:16367[D loss: 0.459939, acc: 50.78%, op_acc: 35.94%] [G loss: 0.827247]\n",
      "epoch:20 step:16368[D loss: 0.456120, acc: 53.91%, op_acc: 35.94%] [G loss: 0.866875]\n",
      "epoch:20 step:16369[D loss: 0.406346, acc: 65.62%, op_acc: 35.94%] [G loss: 0.931961]\n",
      "epoch:20 step:16370[D loss: 0.444945, acc: 53.12%, op_acc: 35.16%] [G loss: 0.966125]\n",
      "epoch:20 step:16371[D loss: 0.469953, acc: 52.34%, op_acc: 34.38%] [G loss: 0.944491]\n",
      "epoch:20 step:16372[D loss: 0.411878, acc: 60.94%, op_acc: 46.09%] [G loss: 0.890060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:16373[D loss: 0.420364, acc: 59.38%, op_acc: 34.38%] [G loss: 0.838314]\n",
      "epoch:20 step:16374[D loss: 0.441004, acc: 59.38%, op_acc: 38.28%] [G loss: 0.862177]\n",
      "epoch:20 step:16375[D loss: 0.410216, acc: 65.62%, op_acc: 42.19%] [G loss: 0.953953]\n",
      "epoch:20 step:16376[D loss: 0.443835, acc: 53.12%, op_acc: 40.62%] [G loss: 0.852219]\n",
      "epoch:20 step:16377[D loss: 0.401543, acc: 65.62%, op_acc: 44.53%] [G loss: 0.893174]\n",
      "epoch:20 step:16378[D loss: 0.429824, acc: 57.03%, op_acc: 36.72%] [G loss: 0.837726]\n",
      "epoch:20 step:16379[D loss: 0.444585, acc: 59.38%, op_acc: 39.06%] [G loss: 0.901357]\n",
      "epoch:20 step:16380[D loss: 0.433417, acc: 54.69%, op_acc: 41.41%] [G loss: 0.941541]\n",
      "epoch:20 step:16381[D loss: 0.416087, acc: 64.06%, op_acc: 38.28%] [G loss: 0.843688]\n",
      "epoch:20 step:16382[D loss: 0.431326, acc: 57.81%, op_acc: 39.06%] [G loss: 0.809795]\n",
      "epoch:20 step:16383[D loss: 0.443013, acc: 57.81%, op_acc: 35.94%] [G loss: 0.829403]\n",
      "epoch:20 step:16384[D loss: 0.436288, acc: 58.59%, op_acc: 35.16%] [G loss: 0.884584]\n",
      "epoch:20 step:16385[D loss: 0.404868, acc: 56.25%, op_acc: 46.09%] [G loss: 0.768059]\n",
      "epoch:20 step:16386[D loss: 0.459729, acc: 53.91%, op_acc: 30.47%] [G loss: 0.836953]\n",
      "epoch:20 step:16387[D loss: 0.421397, acc: 60.16%, op_acc: 39.84%] [G loss: 0.835344]\n",
      "epoch:20 step:16388[D loss: 0.442134, acc: 53.12%, op_acc: 40.62%] [G loss: 0.872557]\n",
      "epoch:20 step:16389[D loss: 0.411224, acc: 63.28%, op_acc: 45.31%] [G loss: 0.888948]\n",
      "epoch:20 step:16390[D loss: 0.427819, acc: 56.25%, op_acc: 37.50%] [G loss: 0.907018]\n",
      "epoch:20 step:16391[D loss: 0.450187, acc: 55.47%, op_acc: 37.50%] [G loss: 0.872275]\n",
      "epoch:20 step:16392[D loss: 0.474463, acc: 53.91%, op_acc: 33.59%] [G loss: 0.850069]\n",
      "epoch:20 step:16393[D loss: 0.430419, acc: 57.03%, op_acc: 39.06%] [G loss: 0.870075]\n",
      "epoch:20 step:16394[D loss: 0.451557, acc: 49.22%, op_acc: 35.94%] [G loss: 0.861754]\n",
      "epoch:20 step:16395[D loss: 0.440371, acc: 59.38%, op_acc: 34.38%] [G loss: 0.920435]\n",
      "epoch:20 step:16396[D loss: 0.413425, acc: 60.16%, op_acc: 39.84%] [G loss: 0.844205]\n",
      "epoch:20 step:16397[D loss: 0.458684, acc: 51.56%, op_acc: 35.16%] [G loss: 0.877769]\n",
      "epoch:20 step:16398[D loss: 0.420422, acc: 57.81%, op_acc: 42.97%] [G loss: 0.896611]\n",
      "epoch:20 step:16399[D loss: 0.421558, acc: 56.25%, op_acc: 38.28%] [G loss: 0.873950]\n",
      "epoch:20 step:16400[D loss: 0.431671, acc: 52.34%, op_acc: 39.84%] [G loss: 0.830907]\n",
      "epoch:20 step:16401[D loss: 0.428269, acc: 63.28%, op_acc: 35.94%] [G loss: 0.854445]\n",
      "epoch:21 step:16402[D loss: 0.392002, acc: 64.84%, op_acc: 39.06%] [G loss: 0.959360]\n",
      "epoch:21 step:16403[D loss: 0.420099, acc: 53.12%, op_acc: 41.41%] [G loss: 0.814216]\n",
      "epoch:21 step:16404[D loss: 0.436125, acc: 56.25%, op_acc: 40.62%] [G loss: 0.860984]\n",
      "epoch:21 step:16405[D loss: 0.381233, acc: 64.06%, op_acc: 42.97%] [G loss: 0.860633]\n",
      "epoch:21 step:16406[D loss: 0.439220, acc: 58.59%, op_acc: 32.81%] [G loss: 0.823331]\n",
      "epoch:21 step:16407[D loss: 0.448002, acc: 62.50%, op_acc: 35.16%] [G loss: 0.786660]\n",
      "epoch:21 step:16408[D loss: 0.423108, acc: 57.81%, op_acc: 40.62%] [G loss: 0.861847]\n",
      "epoch:21 step:16409[D loss: 0.437744, acc: 57.03%, op_acc: 39.84%] [G loss: 0.860412]\n",
      "epoch:21 step:16410[D loss: 0.418787, acc: 62.50%, op_acc: 39.06%] [G loss: 0.870504]\n",
      "epoch:21 step:16411[D loss: 0.435333, acc: 64.06%, op_acc: 34.38%] [G loss: 0.830418]\n",
      "epoch:21 step:16412[D loss: 0.427371, acc: 60.16%, op_acc: 41.41%] [G loss: 0.908124]\n",
      "epoch:21 step:16413[D loss: 0.387147, acc: 69.53%, op_acc: 36.72%] [G loss: 0.953075]\n",
      "epoch:21 step:16414[D loss: 0.409967, acc: 67.19%, op_acc: 38.28%] [G loss: 0.906666]\n",
      "epoch:21 step:16415[D loss: 0.434696, acc: 60.16%, op_acc: 38.28%] [G loss: 0.841575]\n",
      "epoch:21 step:16416[D loss: 0.422461, acc: 60.16%, op_acc: 39.84%] [G loss: 0.829783]\n",
      "epoch:21 step:16417[D loss: 0.428279, acc: 60.16%, op_acc: 38.28%] [G loss: 0.901701]\n",
      "epoch:21 step:16418[D loss: 0.444298, acc: 49.22%, op_acc: 42.97%] [G loss: 0.885928]\n",
      "epoch:21 step:16419[D loss: 0.417752, acc: 54.69%, op_acc: 39.06%] [G loss: 0.800488]\n",
      "epoch:21 step:16420[D loss: 0.420570, acc: 57.81%, op_acc: 41.41%] [G loss: 0.849721]\n",
      "epoch:21 step:16421[D loss: 0.445997, acc: 48.44%, op_acc: 36.72%] [G loss: 0.820664]\n",
      "epoch:21 step:16422[D loss: 0.440590, acc: 53.12%, op_acc: 37.50%] [G loss: 0.869335]\n",
      "epoch:21 step:16423[D loss: 0.410426, acc: 65.62%, op_acc: 38.28%] [G loss: 0.935059]\n",
      "epoch:21 step:16424[D loss: 0.381034, acc: 67.97%, op_acc: 40.62%] [G loss: 0.952078]\n",
      "epoch:21 step:16425[D loss: 0.449034, acc: 56.25%, op_acc: 36.72%] [G loss: 0.919189]\n",
      "epoch:21 step:16426[D loss: 0.473607, acc: 52.34%, op_acc: 39.84%] [G loss: 0.929521]\n",
      "epoch:21 step:16427[D loss: 0.411357, acc: 60.16%, op_acc: 44.53%] [G loss: 0.870881]\n",
      "epoch:21 step:16428[D loss: 0.434830, acc: 57.03%, op_acc: 39.06%] [G loss: 0.961609]\n",
      "epoch:21 step:16429[D loss: 0.411479, acc: 60.16%, op_acc: 41.41%] [G loss: 0.892805]\n",
      "epoch:21 step:16430[D loss: 0.411788, acc: 64.84%, op_acc: 45.31%] [G loss: 0.869682]\n",
      "epoch:21 step:16431[D loss: 0.398180, acc: 62.50%, op_acc: 44.53%] [G loss: 0.917851]\n",
      "epoch:21 step:16432[D loss: 0.470601, acc: 61.72%, op_acc: 39.06%] [G loss: 0.891015]\n",
      "epoch:21 step:16433[D loss: 0.448163, acc: 60.16%, op_acc: 36.72%] [G loss: 0.824295]\n",
      "epoch:21 step:16434[D loss: 0.401936, acc: 64.84%, op_acc: 38.28%] [G loss: 0.941696]\n",
      "epoch:21 step:16435[D loss: 0.405552, acc: 64.84%, op_acc: 41.41%] [G loss: 0.797976]\n",
      "epoch:21 step:16436[D loss: 0.433815, acc: 64.84%, op_acc: 42.19%] [G loss: 0.926465]\n",
      "epoch:21 step:16437[D loss: 0.419143, acc: 58.59%, op_acc: 40.62%] [G loss: 0.868923]\n",
      "epoch:21 step:16438[D loss: 0.439988, acc: 52.34%, op_acc: 36.72%] [G loss: 0.876965]\n",
      "epoch:21 step:16439[D loss: 0.428491, acc: 56.25%, op_acc: 39.06%] [G loss: 0.909181]\n",
      "epoch:21 step:16440[D loss: 0.445922, acc: 50.78%, op_acc: 38.28%] [G loss: 0.876699]\n",
      "epoch:21 step:16441[D loss: 0.439557, acc: 58.59%, op_acc: 39.06%] [G loss: 0.890239]\n",
      "epoch:21 step:16442[D loss: 0.428135, acc: 57.03%, op_acc: 40.62%] [G loss: 0.895141]\n",
      "epoch:21 step:16443[D loss: 0.382233, acc: 67.97%, op_acc: 43.75%] [G loss: 0.905643]\n",
      "epoch:21 step:16444[D loss: 0.439091, acc: 57.81%, op_acc: 34.38%] [G loss: 0.919363]\n",
      "epoch:21 step:16445[D loss: 0.425705, acc: 53.91%, op_acc: 41.41%] [G loss: 0.825984]\n",
      "epoch:21 step:16446[D loss: 0.415971, acc: 59.38%, op_acc: 39.84%] [G loss: 0.960238]\n",
      "epoch:21 step:16447[D loss: 0.438704, acc: 59.38%, op_acc: 39.06%] [G loss: 0.868192]\n",
      "epoch:21 step:16448[D loss: 0.447741, acc: 61.72%, op_acc: 35.94%] [G loss: 0.890598]\n",
      "epoch:21 step:16449[D loss: 0.459706, acc: 56.25%, op_acc: 35.94%] [G loss: 0.902120]\n",
      "epoch:21 step:16450[D loss: 0.425282, acc: 57.03%, op_acc: 37.50%] [G loss: 0.947161]\n",
      "epoch:21 step:16451[D loss: 0.429771, acc: 60.16%, op_acc: 37.50%] [G loss: 0.904680]\n",
      "epoch:21 step:16452[D loss: 0.400218, acc: 67.97%, op_acc: 41.41%] [G loss: 0.907623]\n",
      "epoch:21 step:16453[D loss: 0.426926, acc: 60.94%, op_acc: 39.06%] [G loss: 0.914040]\n",
      "epoch:21 step:16454[D loss: 0.429909, acc: 63.28%, op_acc: 35.16%] [G loss: 0.883378]\n",
      "epoch:21 step:16455[D loss: 0.428520, acc: 58.59%, op_acc: 37.50%] [G loss: 0.847432]\n",
      "epoch:21 step:16456[D loss: 0.417591, acc: 59.38%, op_acc: 37.50%] [G loss: 0.877151]\n",
      "epoch:21 step:16457[D loss: 0.453247, acc: 50.00%, op_acc: 35.94%] [G loss: 0.941332]\n",
      "epoch:21 step:16458[D loss: 0.450498, acc: 54.69%, op_acc: 36.72%] [G loss: 0.938679]\n",
      "epoch:21 step:16459[D loss: 0.401867, acc: 60.16%, op_acc: 41.41%] [G loss: 0.897372]\n",
      "epoch:21 step:16460[D loss: 0.396015, acc: 59.38%, op_acc: 41.41%] [G loss: 0.856071]\n",
      "epoch:21 step:16461[D loss: 0.410410, acc: 60.16%, op_acc: 35.94%] [G loss: 0.844487]\n",
      "epoch:21 step:16462[D loss: 0.440977, acc: 57.03%, op_acc: 37.50%] [G loss: 0.884343]\n",
      "epoch:21 step:16463[D loss: 0.420795, acc: 57.03%, op_acc: 41.41%] [G loss: 0.868830]\n",
      "epoch:21 step:16464[D loss: 0.440251, acc: 61.72%, op_acc: 39.06%] [G loss: 0.810106]\n",
      "epoch:21 step:16465[D loss: 0.411118, acc: 64.84%, op_acc: 39.84%] [G loss: 0.867586]\n",
      "epoch:21 step:16466[D loss: 0.439954, acc: 56.25%, op_acc: 36.72%] [G loss: 0.823005]\n",
      "epoch:21 step:16467[D loss: 0.425049, acc: 55.47%, op_acc: 38.28%] [G loss: 0.901428]\n",
      "epoch:21 step:16468[D loss: 0.428899, acc: 58.59%, op_acc: 38.28%] [G loss: 0.896413]\n",
      "epoch:21 step:16469[D loss: 0.422866, acc: 67.19%, op_acc: 39.06%] [G loss: 0.874566]\n",
      "epoch:21 step:16470[D loss: 0.416106, acc: 53.91%, op_acc: 44.53%] [G loss: 0.871981]\n",
      "epoch:21 step:16471[D loss: 0.413041, acc: 61.72%, op_acc: 36.72%] [G loss: 0.904978]\n",
      "epoch:21 step:16472[D loss: 0.435646, acc: 60.16%, op_acc: 37.50%] [G loss: 0.828041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16473[D loss: 0.419360, acc: 57.81%, op_acc: 41.41%] [G loss: 0.797063]\n",
      "epoch:21 step:16474[D loss: 0.440965, acc: 56.25%, op_acc: 37.50%] [G loss: 0.816370]\n",
      "epoch:21 step:16475[D loss: 0.417520, acc: 62.50%, op_acc: 39.06%] [G loss: 0.883600]\n",
      "epoch:21 step:16476[D loss: 0.399770, acc: 64.06%, op_acc: 40.62%] [G loss: 0.865248]\n",
      "epoch:21 step:16477[D loss: 0.436961, acc: 60.16%, op_acc: 43.75%] [G loss: 0.829470]\n",
      "epoch:21 step:16478[D loss: 0.415051, acc: 60.94%, op_acc: 35.16%] [G loss: 0.886506]\n",
      "epoch:21 step:16479[D loss: 0.451277, acc: 59.38%, op_acc: 32.81%] [G loss: 0.805507]\n",
      "epoch:21 step:16480[D loss: 0.409581, acc: 59.38%, op_acc: 40.62%] [G loss: 0.843355]\n",
      "epoch:21 step:16481[D loss: 0.455145, acc: 60.16%, op_acc: 27.34%] [G loss: 0.868478]\n",
      "epoch:21 step:16482[D loss: 0.444719, acc: 53.12%, op_acc: 36.72%] [G loss: 0.910231]\n",
      "epoch:21 step:16483[D loss: 0.443864, acc: 51.56%, op_acc: 39.06%] [G loss: 0.817688]\n",
      "epoch:21 step:16484[D loss: 0.435737, acc: 57.81%, op_acc: 37.50%] [G loss: 0.875907]\n",
      "epoch:21 step:16485[D loss: 0.422164, acc: 54.69%, op_acc: 38.28%] [G loss: 0.884352]\n",
      "epoch:21 step:16486[D loss: 0.467006, acc: 58.59%, op_acc: 32.03%] [G loss: 0.883235]\n",
      "epoch:21 step:16487[D loss: 0.410637, acc: 64.06%, op_acc: 36.72%] [G loss: 0.926542]\n",
      "epoch:21 step:16488[D loss: 0.431859, acc: 53.91%, op_acc: 34.38%] [G loss: 0.830926]\n",
      "epoch:21 step:16489[D loss: 0.443170, acc: 57.81%, op_acc: 37.50%] [G loss: 0.863629]\n",
      "epoch:21 step:16490[D loss: 0.450661, acc: 56.25%, op_acc: 37.50%] [G loss: 0.896032]\n",
      "epoch:21 step:16491[D loss: 0.437649, acc: 57.03%, op_acc: 38.28%] [G loss: 0.888059]\n",
      "epoch:21 step:16492[D loss: 0.418362, acc: 57.81%, op_acc: 42.97%] [G loss: 0.928995]\n",
      "epoch:21 step:16493[D loss: 0.427458, acc: 60.16%, op_acc: 39.06%] [G loss: 0.821409]\n",
      "epoch:21 step:16494[D loss: 0.437490, acc: 50.00%, op_acc: 37.50%] [G loss: 0.857743]\n",
      "epoch:21 step:16495[D loss: 0.439754, acc: 58.59%, op_acc: 39.06%] [G loss: 0.864042]\n",
      "epoch:21 step:16496[D loss: 0.427586, acc: 57.03%, op_acc: 42.19%] [G loss: 0.891699]\n",
      "epoch:21 step:16497[D loss: 0.468386, acc: 50.78%, op_acc: 38.28%] [G loss: 0.830048]\n",
      "epoch:21 step:16498[D loss: 0.415635, acc: 56.25%, op_acc: 43.75%] [G loss: 0.853204]\n",
      "epoch:21 step:16499[D loss: 0.448886, acc: 51.56%, op_acc: 36.72%] [G loss: 0.897328]\n",
      "epoch:21 step:16500[D loss: 0.428440, acc: 60.16%, op_acc: 42.19%] [G loss: 0.806687]\n",
      "epoch:21 step:16501[D loss: 0.431412, acc: 54.69%, op_acc: 36.72%] [G loss: 0.861533]\n",
      "epoch:21 step:16502[D loss: 0.428509, acc: 56.25%, op_acc: 40.62%] [G loss: 0.856257]\n",
      "epoch:21 step:16503[D loss: 0.412649, acc: 62.50%, op_acc: 39.06%] [G loss: 0.944995]\n",
      "epoch:21 step:16504[D loss: 0.442044, acc: 55.47%, op_acc: 36.72%] [G loss: 0.961269]\n",
      "epoch:21 step:16505[D loss: 0.439624, acc: 53.12%, op_acc: 41.41%] [G loss: 0.882474]\n",
      "epoch:21 step:16506[D loss: 0.395721, acc: 65.62%, op_acc: 46.88%] [G loss: 0.887522]\n",
      "epoch:21 step:16507[D loss: 0.422036, acc: 54.69%, op_acc: 39.84%] [G loss: 0.904177]\n",
      "epoch:21 step:16508[D loss: 0.444822, acc: 58.59%, op_acc: 36.72%] [G loss: 0.917504]\n",
      "epoch:21 step:16509[D loss: 0.444305, acc: 58.59%, op_acc: 39.84%] [G loss: 0.846950]\n",
      "epoch:21 step:16510[D loss: 0.421510, acc: 57.81%, op_acc: 39.06%] [G loss: 0.927658]\n",
      "epoch:21 step:16511[D loss: 0.401221, acc: 64.06%, op_acc: 40.62%] [G loss: 0.873442]\n",
      "epoch:21 step:16512[D loss: 0.433982, acc: 71.88%, op_acc: 31.25%] [G loss: 0.886300]\n",
      "epoch:21 step:16513[D loss: 0.409810, acc: 62.50%, op_acc: 41.41%] [G loss: 0.931552]\n",
      "epoch:21 step:16514[D loss: 0.452843, acc: 58.59%, op_acc: 32.03%] [G loss: 0.938737]\n",
      "epoch:21 step:16515[D loss: 0.405453, acc: 66.41%, op_acc: 43.75%] [G loss: 0.841086]\n",
      "epoch:21 step:16516[D loss: 0.415236, acc: 56.25%, op_acc: 42.19%] [G loss: 0.837161]\n",
      "epoch:21 step:16517[D loss: 0.436638, acc: 65.62%, op_acc: 35.16%] [G loss: 0.931627]\n",
      "epoch:21 step:16518[D loss: 0.447200, acc: 53.91%, op_acc: 34.38%] [G loss: 0.946333]\n",
      "epoch:21 step:16519[D loss: 0.432049, acc: 59.38%, op_acc: 32.03%] [G loss: 0.960848]\n",
      "epoch:21 step:16520[D loss: 0.446246, acc: 55.47%, op_acc: 35.16%] [G loss: 0.860862]\n",
      "epoch:21 step:16521[D loss: 0.439036, acc: 60.16%, op_acc: 35.94%] [G loss: 0.880790]\n",
      "epoch:21 step:16522[D loss: 0.426391, acc: 65.62%, op_acc: 36.72%] [G loss: 0.908791]\n",
      "epoch:21 step:16523[D loss: 0.391613, acc: 67.97%, op_acc: 44.53%] [G loss: 0.857819]\n",
      "epoch:21 step:16524[D loss: 0.424072, acc: 63.28%, op_acc: 34.38%] [G loss: 0.884014]\n",
      "epoch:21 step:16525[D loss: 0.406973, acc: 64.84%, op_acc: 34.38%] [G loss: 0.918109]\n",
      "epoch:21 step:16526[D loss: 0.446492, acc: 57.81%, op_acc: 32.81%] [G loss: 0.936916]\n",
      "epoch:21 step:16527[D loss: 0.423026, acc: 57.03%, op_acc: 34.38%] [G loss: 0.926439]\n",
      "epoch:21 step:16528[D loss: 0.405249, acc: 58.59%, op_acc: 37.50%] [G loss: 0.910519]\n",
      "epoch:21 step:16529[D loss: 0.414871, acc: 64.84%, op_acc: 44.53%] [G loss: 0.950744]\n",
      "epoch:21 step:16530[D loss: 0.442286, acc: 60.16%, op_acc: 38.28%] [G loss: 0.905510]\n",
      "epoch:21 step:16531[D loss: 0.414773, acc: 57.03%, op_acc: 39.84%] [G loss: 0.916074]\n",
      "epoch:21 step:16532[D loss: 0.423468, acc: 60.16%, op_acc: 37.50%] [G loss: 0.874416]\n",
      "epoch:21 step:16533[D loss: 0.383433, acc: 68.75%, op_acc: 43.75%] [G loss: 0.933043]\n",
      "epoch:21 step:16534[D loss: 0.439245, acc: 62.50%, op_acc: 31.25%] [G loss: 0.911245]\n",
      "epoch:21 step:16535[D loss: 0.406448, acc: 67.97%, op_acc: 40.62%] [G loss: 0.861234]\n",
      "epoch:21 step:16536[D loss: 0.438737, acc: 54.69%, op_acc: 39.84%] [G loss: 0.860920]\n",
      "epoch:21 step:16537[D loss: 0.417926, acc: 58.59%, op_acc: 38.28%] [G loss: 0.858447]\n",
      "epoch:21 step:16538[D loss: 0.426550, acc: 57.81%, op_acc: 42.97%] [G loss: 0.877976]\n",
      "epoch:21 step:16539[D loss: 0.431674, acc: 57.81%, op_acc: 36.72%] [G loss: 0.860438]\n",
      "epoch:21 step:16540[D loss: 0.421978, acc: 52.34%, op_acc: 35.94%] [G loss: 0.868478]\n",
      "epoch:21 step:16541[D loss: 0.472389, acc: 44.53%, op_acc: 39.06%] [G loss: 0.930674]\n",
      "epoch:21 step:16542[D loss: 0.446558, acc: 54.69%, op_acc: 33.59%] [G loss: 0.786353]\n",
      "epoch:21 step:16543[D loss: 0.434946, acc: 57.03%, op_acc: 34.38%] [G loss: 0.806735]\n",
      "epoch:21 step:16544[D loss: 0.413243, acc: 65.62%, op_acc: 39.06%] [G loss: 0.920249]\n",
      "epoch:21 step:16545[D loss: 0.455417, acc: 51.56%, op_acc: 39.06%] [G loss: 0.820245]\n",
      "epoch:21 step:16546[D loss: 0.410416, acc: 68.75%, op_acc: 41.41%] [G loss: 0.809698]\n",
      "epoch:21 step:16547[D loss: 0.413529, acc: 53.91%, op_acc: 36.72%] [G loss: 0.818502]\n",
      "epoch:21 step:16548[D loss: 0.425530, acc: 55.47%, op_acc: 42.19%] [G loss: 0.870332]\n",
      "epoch:21 step:16549[D loss: 0.441994, acc: 58.59%, op_acc: 35.16%] [G loss: 0.873295]\n",
      "epoch:21 step:16550[D loss: 0.408935, acc: 60.94%, op_acc: 38.28%] [G loss: 0.840708]\n",
      "epoch:21 step:16551[D loss: 0.409557, acc: 62.50%, op_acc: 43.75%] [G loss: 0.887156]\n",
      "epoch:21 step:16552[D loss: 0.423681, acc: 54.69%, op_acc: 39.84%] [G loss: 0.834862]\n",
      "epoch:21 step:16553[D loss: 0.422738, acc: 54.69%, op_acc: 40.62%] [G loss: 0.911584]\n",
      "epoch:21 step:16554[D loss: 0.419200, acc: 57.81%, op_acc: 44.53%] [G loss: 0.810063]\n",
      "epoch:21 step:16555[D loss: 0.397195, acc: 65.62%, op_acc: 39.06%] [G loss: 0.854151]\n",
      "epoch:21 step:16556[D loss: 0.424160, acc: 66.41%, op_acc: 35.16%] [G loss: 0.846014]\n",
      "epoch:21 step:16557[D loss: 0.417026, acc: 58.59%, op_acc: 38.28%] [G loss: 0.916168]\n",
      "epoch:21 step:16558[D loss: 0.413309, acc: 58.59%, op_acc: 42.97%] [G loss: 0.815307]\n",
      "epoch:21 step:16559[D loss: 0.398302, acc: 62.50%, op_acc: 39.06%] [G loss: 0.870344]\n",
      "epoch:21 step:16560[D loss: 0.419458, acc: 66.41%, op_acc: 39.06%] [G loss: 0.935292]\n",
      "epoch:21 step:16561[D loss: 0.470329, acc: 51.56%, op_acc: 31.25%] [G loss: 0.890547]\n",
      "epoch:21 step:16562[D loss: 0.461406, acc: 48.44%, op_acc: 38.28%] [G loss: 0.920068]\n",
      "epoch:21 step:16563[D loss: 0.400708, acc: 61.72%, op_acc: 43.75%] [G loss: 0.863498]\n",
      "epoch:21 step:16564[D loss: 0.434992, acc: 60.16%, op_acc: 38.28%] [G loss: 0.952098]\n",
      "epoch:21 step:16565[D loss: 0.424437, acc: 66.41%, op_acc: 35.16%] [G loss: 0.892113]\n",
      "epoch:21 step:16566[D loss: 0.406385, acc: 61.72%, op_acc: 42.19%] [G loss: 0.893530]\n",
      "epoch:21 step:16567[D loss: 0.394230, acc: 67.97%, op_acc: 42.19%] [G loss: 0.889356]\n",
      "epoch:21 step:16568[D loss: 0.446727, acc: 58.59%, op_acc: 34.38%] [G loss: 0.866950]\n",
      "epoch:21 step:16569[D loss: 0.410302, acc: 54.69%, op_acc: 45.31%] [G loss: 0.838638]\n",
      "epoch:21 step:16570[D loss: 0.425401, acc: 59.38%, op_acc: 36.72%] [G loss: 0.910310]\n",
      "epoch:21 step:16571[D loss: 0.424539, acc: 60.94%, op_acc: 36.72%] [G loss: 0.861435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16572[D loss: 0.458255, acc: 47.66%, op_acc: 29.69%] [G loss: 0.864232]\n",
      "epoch:21 step:16573[D loss: 0.444582, acc: 49.22%, op_acc: 41.41%] [G loss: 0.890868]\n",
      "epoch:21 step:16574[D loss: 0.450799, acc: 54.69%, op_acc: 35.16%] [G loss: 0.893161]\n",
      "epoch:21 step:16575[D loss: 0.459828, acc: 51.56%, op_acc: 35.94%] [G loss: 0.902496]\n",
      "epoch:21 step:16576[D loss: 0.412043, acc: 58.59%, op_acc: 39.06%] [G loss: 0.873803]\n",
      "epoch:21 step:16577[D loss: 0.427996, acc: 60.16%, op_acc: 41.41%] [G loss: 0.834183]\n",
      "epoch:21 step:16578[D loss: 0.432211, acc: 55.47%, op_acc: 39.06%] [G loss: 0.804026]\n",
      "epoch:21 step:16579[D loss: 0.439124, acc: 62.50%, op_acc: 39.84%] [G loss: 0.880645]\n",
      "epoch:21 step:16580[D loss: 0.404916, acc: 59.38%, op_acc: 43.75%] [G loss: 0.884045]\n",
      "epoch:21 step:16581[D loss: 0.419232, acc: 58.59%, op_acc: 41.41%] [G loss: 0.916200]\n",
      "epoch:21 step:16582[D loss: 0.442622, acc: 57.81%, op_acc: 36.72%] [G loss: 0.881787]\n",
      "epoch:21 step:16583[D loss: 0.439885, acc: 57.81%, op_acc: 38.28%] [G loss: 0.838018]\n",
      "epoch:21 step:16584[D loss: 0.418243, acc: 60.16%, op_acc: 42.19%] [G loss: 0.902747]\n",
      "epoch:21 step:16585[D loss: 0.415865, acc: 64.84%, op_acc: 37.50%] [G loss: 0.859066]\n",
      "epoch:21 step:16586[D loss: 0.442315, acc: 57.81%, op_acc: 32.81%] [G loss: 0.867518]\n",
      "epoch:21 step:16587[D loss: 0.412284, acc: 60.94%, op_acc: 39.06%] [G loss: 0.840412]\n",
      "epoch:21 step:16588[D loss: 0.407322, acc: 64.06%, op_acc: 42.19%] [G loss: 0.901063]\n",
      "epoch:21 step:16589[D loss: 0.442358, acc: 56.25%, op_acc: 35.94%] [G loss: 0.869231]\n",
      "epoch:21 step:16590[D loss: 0.440677, acc: 60.16%, op_acc: 35.16%] [G loss: 0.875066]\n",
      "epoch:21 step:16591[D loss: 0.436214, acc: 56.25%, op_acc: 39.06%] [G loss: 0.776589]\n",
      "epoch:21 step:16592[D loss: 0.396765, acc: 64.84%, op_acc: 38.28%] [G loss: 0.845715]\n",
      "epoch:21 step:16593[D loss: 0.439111, acc: 60.16%, op_acc: 35.94%] [G loss: 0.904510]\n",
      "epoch:21 step:16594[D loss: 0.456590, acc: 56.25%, op_acc: 32.81%] [G loss: 0.890547]\n",
      "epoch:21 step:16595[D loss: 0.428887, acc: 50.78%, op_acc: 46.88%] [G loss: 0.839660]\n",
      "epoch:21 step:16596[D loss: 0.425023, acc: 58.59%, op_acc: 38.28%] [G loss: 0.857735]\n",
      "epoch:21 step:16597[D loss: 0.396784, acc: 67.97%, op_acc: 41.41%] [G loss: 0.940114]\n",
      "epoch:21 step:16598[D loss: 0.475636, acc: 49.22%, op_acc: 35.94%] [G loss: 0.878642]\n",
      "epoch:21 step:16599[D loss: 0.418841, acc: 56.25%, op_acc: 37.50%] [G loss: 0.879299]\n",
      "epoch:21 step:16600[D loss: 0.424995, acc: 60.94%, op_acc: 36.72%] [G loss: 0.870584]\n",
      "epoch:21 step:16601[D loss: 0.425327, acc: 54.69%, op_acc: 42.97%] [G loss: 0.918628]\n",
      "epoch:21 step:16602[D loss: 0.418899, acc: 58.59%, op_acc: 37.50%] [G loss: 0.897667]\n",
      "epoch:21 step:16603[D loss: 0.439581, acc: 55.47%, op_acc: 39.06%] [G loss: 0.915079]\n",
      "epoch:21 step:16604[D loss: 0.445798, acc: 53.91%, op_acc: 36.72%] [G loss: 0.910490]\n",
      "epoch:21 step:16605[D loss: 0.430981, acc: 54.69%, op_acc: 39.84%] [G loss: 0.888457]\n",
      "epoch:21 step:16606[D loss: 0.432807, acc: 58.59%, op_acc: 37.50%] [G loss: 0.902622]\n",
      "epoch:21 step:16607[D loss: 0.438410, acc: 54.69%, op_acc: 39.06%] [G loss: 0.915777]\n",
      "epoch:21 step:16608[D loss: 0.390749, acc: 62.50%, op_acc: 36.72%] [G loss: 0.849273]\n",
      "epoch:21 step:16609[D loss: 0.441782, acc: 59.38%, op_acc: 32.03%] [G loss: 0.938746]\n",
      "epoch:21 step:16610[D loss: 0.410998, acc: 66.41%, op_acc: 43.75%] [G loss: 0.907084]\n",
      "epoch:21 step:16611[D loss: 0.486616, acc: 50.78%, op_acc: 35.16%] [G loss: 0.869387]\n",
      "epoch:21 step:16612[D loss: 0.442155, acc: 53.12%, op_acc: 36.72%] [G loss: 0.881357]\n",
      "epoch:21 step:16613[D loss: 0.445034, acc: 55.47%, op_acc: 36.72%] [G loss: 0.854642]\n",
      "epoch:21 step:16614[D loss: 0.432931, acc: 61.72%, op_acc: 35.16%] [G loss: 0.863902]\n",
      "epoch:21 step:16615[D loss: 0.430650, acc: 63.28%, op_acc: 39.06%] [G loss: 0.887027]\n",
      "epoch:21 step:16616[D loss: 0.421728, acc: 63.28%, op_acc: 38.28%] [G loss: 0.846783]\n",
      "epoch:21 step:16617[D loss: 0.423401, acc: 60.16%, op_acc: 38.28%] [G loss: 0.843389]\n",
      "epoch:21 step:16618[D loss: 0.417899, acc: 60.94%, op_acc: 41.41%] [G loss: 0.826675]\n",
      "epoch:21 step:16619[D loss: 0.435222, acc: 60.16%, op_acc: 36.72%] [G loss: 0.918552]\n",
      "epoch:21 step:16620[D loss: 0.393015, acc: 68.75%, op_acc: 41.41%] [G loss: 0.894638]\n",
      "epoch:21 step:16621[D loss: 0.432967, acc: 58.59%, op_acc: 37.50%] [G loss: 0.898956]\n",
      "epoch:21 step:16622[D loss: 0.430476, acc: 60.94%, op_acc: 38.28%] [G loss: 0.889036]\n",
      "epoch:21 step:16623[D loss: 0.422512, acc: 57.03%, op_acc: 39.84%] [G loss: 0.821762]\n",
      "epoch:21 step:16624[D loss: 0.423247, acc: 52.34%, op_acc: 39.84%] [G loss: 0.933297]\n",
      "epoch:21 step:16625[D loss: 0.433528, acc: 53.91%, op_acc: 38.28%] [G loss: 0.895650]\n",
      "epoch:21 step:16626[D loss: 0.448769, acc: 54.69%, op_acc: 39.06%] [G loss: 0.916837]\n",
      "epoch:21 step:16627[D loss: 0.420617, acc: 57.81%, op_acc: 37.50%] [G loss: 0.891388]\n",
      "epoch:21 step:16628[D loss: 0.408067, acc: 64.06%, op_acc: 37.50%] [G loss: 0.877097]\n",
      "epoch:21 step:16629[D loss: 0.438388, acc: 57.03%, op_acc: 35.16%] [G loss: 0.779910]\n",
      "epoch:21 step:16630[D loss: 0.423331, acc: 62.50%, op_acc: 43.75%] [G loss: 0.859265]\n",
      "epoch:21 step:16631[D loss: 0.422242, acc: 58.59%, op_acc: 36.72%] [G loss: 0.966950]\n",
      "epoch:21 step:16632[D loss: 0.390710, acc: 68.75%, op_acc: 41.41%] [G loss: 0.887845]\n",
      "epoch:21 step:16633[D loss: 0.418968, acc: 60.16%, op_acc: 39.06%] [G loss: 0.887164]\n",
      "epoch:21 step:16634[D loss: 0.419502, acc: 64.06%, op_acc: 38.28%] [G loss: 0.864210]\n",
      "epoch:21 step:16635[D loss: 0.424810, acc: 57.03%, op_acc: 36.72%] [G loss: 0.935496]\n",
      "epoch:21 step:16636[D loss: 0.403072, acc: 64.06%, op_acc: 39.06%] [G loss: 0.871827]\n",
      "epoch:21 step:16637[D loss: 0.442498, acc: 58.59%, op_acc: 37.50%] [G loss: 0.862367]\n",
      "epoch:21 step:16638[D loss: 0.422975, acc: 60.16%, op_acc: 40.62%] [G loss: 0.909371]\n",
      "epoch:21 step:16639[D loss: 0.436863, acc: 54.69%, op_acc: 35.94%] [G loss: 0.844574]\n",
      "epoch:21 step:16640[D loss: 0.413278, acc: 64.84%, op_acc: 39.06%] [G loss: 0.842056]\n",
      "epoch:21 step:16641[D loss: 0.433914, acc: 56.25%, op_acc: 33.59%] [G loss: 0.818939]\n",
      "epoch:21 step:16642[D loss: 0.421195, acc: 55.47%, op_acc: 41.41%] [G loss: 0.917392]\n",
      "epoch:21 step:16643[D loss: 0.436875, acc: 56.25%, op_acc: 40.62%] [G loss: 0.905683]\n",
      "epoch:21 step:16644[D loss: 0.425598, acc: 59.38%, op_acc: 38.28%] [G loss: 0.846558]\n",
      "epoch:21 step:16645[D loss: 0.445359, acc: 56.25%, op_acc: 33.59%] [G loss: 0.857405]\n",
      "epoch:21 step:16646[D loss: 0.414360, acc: 60.94%, op_acc: 45.31%] [G loss: 0.831846]\n",
      "epoch:21 step:16647[D loss: 0.459171, acc: 57.03%, op_acc: 34.38%] [G loss: 0.923881]\n",
      "epoch:21 step:16648[D loss: 0.420872, acc: 60.16%, op_acc: 38.28%] [G loss: 0.862941]\n",
      "epoch:21 step:16649[D loss: 0.429123, acc: 58.59%, op_acc: 32.03%] [G loss: 0.852784]\n",
      "epoch:21 step:16650[D loss: 0.440904, acc: 60.16%, op_acc: 39.06%] [G loss: 0.930888]\n",
      "epoch:21 step:16651[D loss: 0.443558, acc: 51.56%, op_acc: 36.72%] [G loss: 0.840210]\n",
      "epoch:21 step:16652[D loss: 0.403331, acc: 60.16%, op_acc: 39.06%] [G loss: 0.792531]\n",
      "epoch:21 step:16653[D loss: 0.420580, acc: 64.06%, op_acc: 40.62%] [G loss: 0.881784]\n",
      "epoch:21 step:16654[D loss: 0.436426, acc: 62.50%, op_acc: 35.94%] [G loss: 0.922694]\n",
      "epoch:21 step:16655[D loss: 0.453630, acc: 57.81%, op_acc: 35.16%] [G loss: 0.893941]\n",
      "epoch:21 step:16656[D loss: 0.425341, acc: 57.03%, op_acc: 36.72%] [G loss: 0.884409]\n",
      "epoch:21 step:16657[D loss: 0.452098, acc: 50.78%, op_acc: 35.16%] [G loss: 0.801781]\n",
      "epoch:21 step:16658[D loss: 0.440758, acc: 57.81%, op_acc: 35.16%] [G loss: 0.903406]\n",
      "epoch:21 step:16659[D loss: 0.410540, acc: 59.38%, op_acc: 39.06%] [G loss: 0.989485]\n",
      "epoch:21 step:16660[D loss: 0.446670, acc: 60.94%, op_acc: 35.16%] [G loss: 0.843066]\n",
      "epoch:21 step:16661[D loss: 0.425719, acc: 60.16%, op_acc: 38.28%] [G loss: 0.770441]\n",
      "epoch:21 step:16662[D loss: 0.432002, acc: 65.62%, op_acc: 37.50%] [G loss: 0.918460]\n",
      "epoch:21 step:16663[D loss: 0.434246, acc: 57.81%, op_acc: 34.38%] [G loss: 0.830887]\n",
      "epoch:21 step:16664[D loss: 0.436753, acc: 60.94%, op_acc: 36.72%] [G loss: 0.860719]\n",
      "epoch:21 step:16665[D loss: 0.415516, acc: 60.16%, op_acc: 39.84%] [G loss: 0.895798]\n",
      "epoch:21 step:16666[D loss: 0.429068, acc: 58.59%, op_acc: 36.72%] [G loss: 0.912950]\n",
      "epoch:21 step:16667[D loss: 0.436153, acc: 58.59%, op_acc: 35.16%] [G loss: 0.857754]\n",
      "epoch:21 step:16668[D loss: 0.428848, acc: 59.38%, op_acc: 39.84%] [G loss: 0.962351]\n",
      "epoch:21 step:16669[D loss: 0.390649, acc: 64.84%, op_acc: 40.62%] [G loss: 0.887195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16670[D loss: 0.424684, acc: 57.03%, op_acc: 37.50%] [G loss: 0.860404]\n",
      "epoch:21 step:16671[D loss: 0.439216, acc: 49.22%, op_acc: 35.94%] [G loss: 0.862015]\n",
      "epoch:21 step:16672[D loss: 0.427045, acc: 62.50%, op_acc: 36.72%] [G loss: 0.922376]\n",
      "epoch:21 step:16673[D loss: 0.408440, acc: 66.41%, op_acc: 36.72%] [G loss: 0.852264]\n",
      "epoch:21 step:16674[D loss: 0.391710, acc: 67.97%, op_acc: 44.53%] [G loss: 0.887655]\n",
      "epoch:21 step:16675[D loss: 0.443809, acc: 59.38%, op_acc: 42.19%] [G loss: 0.897829]\n",
      "epoch:21 step:16676[D loss: 0.446672, acc: 53.12%, op_acc: 35.94%] [G loss: 0.896983]\n",
      "epoch:21 step:16677[D loss: 0.411025, acc: 62.50%, op_acc: 40.62%] [G loss: 0.875411]\n",
      "epoch:21 step:16678[D loss: 0.424402, acc: 57.81%, op_acc: 32.81%] [G loss: 0.880164]\n",
      "epoch:21 step:16679[D loss: 0.440333, acc: 64.84%, op_acc: 36.72%] [G loss: 0.908284]\n",
      "epoch:21 step:16680[D loss: 0.444369, acc: 56.25%, op_acc: 39.06%] [G loss: 0.881998]\n",
      "epoch:21 step:16681[D loss: 0.425924, acc: 57.03%, op_acc: 40.62%] [G loss: 0.817440]\n",
      "epoch:21 step:16682[D loss: 0.446034, acc: 57.03%, op_acc: 40.62%] [G loss: 0.822865]\n",
      "epoch:21 step:16683[D loss: 0.444570, acc: 62.50%, op_acc: 32.81%] [G loss: 0.859071]\n",
      "epoch:21 step:16684[D loss: 0.390415, acc: 65.62%, op_acc: 44.53%] [G loss: 0.883054]\n",
      "epoch:21 step:16685[D loss: 0.425808, acc: 57.03%, op_acc: 41.41%] [G loss: 0.811119]\n",
      "epoch:21 step:16686[D loss: 0.429157, acc: 57.81%, op_acc: 40.62%] [G loss: 0.846864]\n",
      "epoch:21 step:16687[D loss: 0.428525, acc: 60.94%, op_acc: 35.94%] [G loss: 0.856636]\n",
      "epoch:21 step:16688[D loss: 0.439050, acc: 60.16%, op_acc: 32.81%] [G loss: 0.874617]\n",
      "epoch:21 step:16689[D loss: 0.420452, acc: 60.94%, op_acc: 39.06%] [G loss: 0.873183]\n",
      "epoch:21 step:16690[D loss: 0.441189, acc: 57.81%, op_acc: 39.84%] [G loss: 0.844653]\n",
      "epoch:21 step:16691[D loss: 0.456582, acc: 52.34%, op_acc: 39.06%] [G loss: 0.807703]\n",
      "epoch:21 step:16692[D loss: 0.419329, acc: 60.94%, op_acc: 40.62%] [G loss: 0.918968]\n",
      "epoch:21 step:16693[D loss: 0.413868, acc: 58.59%, op_acc: 37.50%] [G loss: 0.871662]\n",
      "epoch:21 step:16694[D loss: 0.423740, acc: 53.91%, op_acc: 39.84%] [G loss: 0.811543]\n",
      "epoch:21 step:16695[D loss: 0.424606, acc: 64.84%, op_acc: 35.94%] [G loss: 0.920572]\n",
      "epoch:21 step:16696[D loss: 0.403647, acc: 60.94%, op_acc: 40.62%] [G loss: 0.920487]\n",
      "epoch:21 step:16697[D loss: 0.423076, acc: 57.03%, op_acc: 39.84%] [G loss: 0.834134]\n",
      "epoch:21 step:16698[D loss: 0.411735, acc: 60.94%, op_acc: 35.16%] [G loss: 0.834314]\n",
      "epoch:21 step:16699[D loss: 0.418010, acc: 64.84%, op_acc: 39.84%] [G loss: 0.820004]\n",
      "epoch:21 step:16700[D loss: 0.428560, acc: 59.38%, op_acc: 39.84%] [G loss: 0.842226]\n",
      "epoch:21 step:16701[D loss: 0.456274, acc: 52.34%, op_acc: 36.72%] [G loss: 0.801754]\n",
      "epoch:21 step:16702[D loss: 0.426300, acc: 63.28%, op_acc: 38.28%] [G loss: 0.902465]\n",
      "epoch:21 step:16703[D loss: 0.395971, acc: 64.84%, op_acc: 41.41%] [G loss: 0.859942]\n",
      "epoch:21 step:16704[D loss: 0.421655, acc: 59.38%, op_acc: 39.06%] [G loss: 0.842647]\n",
      "epoch:21 step:16705[D loss: 0.414732, acc: 59.38%, op_acc: 36.72%] [G loss: 0.833568]\n",
      "epoch:21 step:16706[D loss: 0.430114, acc: 56.25%, op_acc: 39.06%] [G loss: 0.867710]\n",
      "epoch:21 step:16707[D loss: 0.465394, acc: 50.78%, op_acc: 33.59%] [G loss: 0.903751]\n",
      "epoch:21 step:16708[D loss: 0.439319, acc: 54.69%, op_acc: 35.94%] [G loss: 0.854152]\n",
      "epoch:21 step:16709[D loss: 0.449886, acc: 55.47%, op_acc: 33.59%] [G loss: 0.917955]\n",
      "epoch:21 step:16710[D loss: 0.461806, acc: 57.81%, op_acc: 34.38%] [G loss: 0.843244]\n",
      "epoch:21 step:16711[D loss: 0.427162, acc: 64.84%, op_acc: 35.16%] [G loss: 0.833262]\n",
      "epoch:21 step:16712[D loss: 0.445422, acc: 57.03%, op_acc: 37.50%] [G loss: 0.823033]\n",
      "epoch:21 step:16713[D loss: 0.444657, acc: 57.81%, op_acc: 36.72%] [G loss: 0.803334]\n",
      "epoch:21 step:16714[D loss: 0.427502, acc: 61.72%, op_acc: 39.06%] [G loss: 0.821687]\n",
      "epoch:21 step:16715[D loss: 0.447266, acc: 56.25%, op_acc: 34.38%] [G loss: 0.849409]\n",
      "epoch:21 step:16716[D loss: 0.423038, acc: 54.69%, op_acc: 38.28%] [G loss: 0.850474]\n",
      "epoch:21 step:16717[D loss: 0.440660, acc: 51.56%, op_acc: 37.50%] [G loss: 0.828995]\n",
      "epoch:21 step:16718[D loss: 0.473723, acc: 53.12%, op_acc: 35.94%] [G loss: 0.857277]\n",
      "epoch:21 step:16719[D loss: 0.461909, acc: 52.34%, op_acc: 28.91%] [G loss: 0.844710]\n",
      "epoch:21 step:16720[D loss: 0.403246, acc: 62.50%, op_acc: 37.50%] [G loss: 0.931460]\n",
      "epoch:21 step:16721[D loss: 0.427017, acc: 56.25%, op_acc: 37.50%] [G loss: 0.856037]\n",
      "epoch:21 step:16722[D loss: 0.429351, acc: 60.94%, op_acc: 35.16%] [G loss: 0.916661]\n",
      "epoch:21 step:16723[D loss: 0.423777, acc: 58.59%, op_acc: 38.28%] [G loss: 0.880520]\n",
      "epoch:21 step:16724[D loss: 0.428947, acc: 53.91%, op_acc: 40.62%] [G loss: 0.851708]\n",
      "epoch:21 step:16725[D loss: 0.434130, acc: 54.69%, op_acc: 39.06%] [G loss: 0.846367]\n",
      "epoch:21 step:16726[D loss: 0.427889, acc: 55.47%, op_acc: 39.06%] [G loss: 0.888039]\n",
      "epoch:21 step:16727[D loss: 0.423662, acc: 55.47%, op_acc: 42.19%] [G loss: 0.848154]\n",
      "epoch:21 step:16728[D loss: 0.411986, acc: 59.38%, op_acc: 38.28%] [G loss: 0.893823]\n",
      "epoch:21 step:16729[D loss: 0.441858, acc: 61.72%, op_acc: 32.81%] [G loss: 0.789503]\n",
      "epoch:21 step:16730[D loss: 0.435767, acc: 57.81%, op_acc: 36.72%] [G loss: 0.922819]\n",
      "epoch:21 step:16731[D loss: 0.425610, acc: 54.69%, op_acc: 39.84%] [G loss: 0.818001]\n",
      "epoch:21 step:16732[D loss: 0.466781, acc: 51.56%, op_acc: 37.50%] [G loss: 0.814958]\n",
      "epoch:21 step:16733[D loss: 0.406903, acc: 61.72%, op_acc: 39.84%] [G loss: 0.852571]\n",
      "epoch:21 step:16734[D loss: 0.409468, acc: 67.19%, op_acc: 42.19%] [G loss: 0.901586]\n",
      "epoch:21 step:16735[D loss: 0.422257, acc: 60.16%, op_acc: 38.28%] [G loss: 0.826541]\n",
      "epoch:21 step:16736[D loss: 0.443746, acc: 57.03%, op_acc: 32.81%] [G loss: 0.875216]\n",
      "epoch:21 step:16737[D loss: 0.439126, acc: 56.25%, op_acc: 39.06%] [G loss: 0.893550]\n",
      "epoch:21 step:16738[D loss: 0.432007, acc: 58.59%, op_acc: 35.94%] [G loss: 0.849749]\n",
      "epoch:21 step:16739[D loss: 0.411182, acc: 55.47%, op_acc: 40.62%] [G loss: 0.883350]\n",
      "epoch:21 step:16740[D loss: 0.427149, acc: 60.16%, op_acc: 39.84%] [G loss: 0.847704]\n",
      "epoch:21 step:16741[D loss: 0.430750, acc: 62.50%, op_acc: 38.28%] [G loss: 0.934174]\n",
      "epoch:21 step:16742[D loss: 0.411332, acc: 64.84%, op_acc: 39.06%] [G loss: 0.848319]\n",
      "epoch:21 step:16743[D loss: 0.425808, acc: 60.94%, op_acc: 38.28%] [G loss: 0.912472]\n",
      "epoch:21 step:16744[D loss: 0.427155, acc: 59.38%, op_acc: 34.38%] [G loss: 0.871062]\n",
      "epoch:21 step:16745[D loss: 0.428847, acc: 57.03%, op_acc: 42.97%] [G loss: 0.875104]\n",
      "epoch:21 step:16746[D loss: 0.409625, acc: 63.28%, op_acc: 36.72%] [G loss: 0.866875]\n",
      "epoch:21 step:16747[D loss: 0.450284, acc: 56.25%, op_acc: 40.62%] [G loss: 0.951654]\n",
      "epoch:21 step:16748[D loss: 0.438725, acc: 48.44%, op_acc: 41.41%] [G loss: 0.867893]\n",
      "epoch:21 step:16749[D loss: 0.419444, acc: 60.94%, op_acc: 35.94%] [G loss: 0.855939]\n",
      "epoch:21 step:16750[D loss: 0.421998, acc: 54.69%, op_acc: 40.62%] [G loss: 0.847252]\n",
      "epoch:21 step:16751[D loss: 0.436233, acc: 57.81%, op_acc: 39.84%] [G loss: 0.921806]\n",
      "epoch:21 step:16752[D loss: 0.451765, acc: 52.34%, op_acc: 34.38%] [G loss: 0.871022]\n",
      "epoch:21 step:16753[D loss: 0.407557, acc: 67.97%, op_acc: 36.72%] [G loss: 0.903567]\n",
      "epoch:21 step:16754[D loss: 0.414286, acc: 60.16%, op_acc: 41.41%] [G loss: 0.954334]\n",
      "epoch:21 step:16755[D loss: 0.424819, acc: 62.50%, op_acc: 37.50%] [G loss: 0.975794]\n",
      "epoch:21 step:16756[D loss: 0.438443, acc: 49.22%, op_acc: 36.72%] [G loss: 0.811721]\n",
      "epoch:21 step:16757[D loss: 0.448369, acc: 50.78%, op_acc: 41.41%] [G loss: 0.907400]\n",
      "epoch:21 step:16758[D loss: 0.434506, acc: 57.03%, op_acc: 34.38%] [G loss: 0.861388]\n",
      "epoch:21 step:16759[D loss: 0.449668, acc: 58.59%, op_acc: 36.72%] [G loss: 0.866994]\n",
      "epoch:21 step:16760[D loss: 0.446033, acc: 53.91%, op_acc: 37.50%] [G loss: 0.831446]\n",
      "epoch:21 step:16761[D loss: 0.425770, acc: 60.94%, op_acc: 39.06%] [G loss: 0.852056]\n",
      "epoch:21 step:16762[D loss: 0.431575, acc: 54.69%, op_acc: 36.72%] [G loss: 0.841513]\n",
      "epoch:21 step:16763[D loss: 0.406043, acc: 64.84%, op_acc: 39.06%] [G loss: 0.841012]\n",
      "epoch:21 step:16764[D loss: 0.443360, acc: 61.72%, op_acc: 38.28%] [G loss: 0.849206]\n",
      "epoch:21 step:16765[D loss: 0.430586, acc: 57.81%, op_acc: 36.72%] [G loss: 0.877145]\n",
      "epoch:21 step:16766[D loss: 0.394300, acc: 68.75%, op_acc: 40.62%] [G loss: 0.927003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16767[D loss: 0.433639, acc: 57.81%, op_acc: 40.62%] [G loss: 0.919713]\n",
      "epoch:21 step:16768[D loss: 0.446403, acc: 64.06%, op_acc: 35.94%] [G loss: 0.882814]\n",
      "epoch:21 step:16769[D loss: 0.420848, acc: 61.72%, op_acc: 36.72%] [G loss: 0.832699]\n",
      "epoch:21 step:16770[D loss: 0.412364, acc: 60.94%, op_acc: 39.84%] [G loss: 0.867386]\n",
      "epoch:21 step:16771[D loss: 0.411384, acc: 61.72%, op_acc: 42.19%] [G loss: 0.849798]\n",
      "epoch:21 step:16772[D loss: 0.403835, acc: 58.59%, op_acc: 46.88%] [G loss: 0.895510]\n",
      "epoch:21 step:16773[D loss: 0.415038, acc: 59.38%, op_acc: 39.06%] [G loss: 0.902860]\n",
      "epoch:21 step:16774[D loss: 0.424451, acc: 57.81%, op_acc: 40.62%] [G loss: 0.876085]\n",
      "epoch:21 step:16775[D loss: 0.456705, acc: 51.56%, op_acc: 40.62%] [G loss: 0.862703]\n",
      "epoch:21 step:16776[D loss: 0.409693, acc: 63.28%, op_acc: 38.28%] [G loss: 0.855893]\n",
      "epoch:21 step:16777[D loss: 0.412112, acc: 62.50%, op_acc: 39.06%] [G loss: 0.908539]\n",
      "epoch:21 step:16778[D loss: 0.400103, acc: 63.28%, op_acc: 36.72%] [G loss: 0.862354]\n",
      "epoch:21 step:16779[D loss: 0.409508, acc: 61.72%, op_acc: 37.50%] [G loss: 0.923365]\n",
      "epoch:21 step:16780[D loss: 0.405575, acc: 67.19%, op_acc: 38.28%] [G loss: 0.915054]\n",
      "epoch:21 step:16781[D loss: 0.417119, acc: 60.16%, op_acc: 39.06%] [G loss: 0.916561]\n",
      "epoch:21 step:16782[D loss: 0.392832, acc: 73.44%, op_acc: 33.59%] [G loss: 0.830545]\n",
      "epoch:21 step:16783[D loss: 0.423046, acc: 58.59%, op_acc: 35.94%] [G loss: 0.832637]\n",
      "epoch:21 step:16784[D loss: 0.405457, acc: 58.59%, op_acc: 42.97%] [G loss: 0.864713]\n",
      "epoch:21 step:16785[D loss: 0.445982, acc: 57.03%, op_acc: 35.94%] [G loss: 0.847625]\n",
      "epoch:21 step:16786[D loss: 0.428534, acc: 56.25%, op_acc: 39.06%] [G loss: 0.868154]\n",
      "epoch:21 step:16787[D loss: 0.410227, acc: 60.16%, op_acc: 38.28%] [G loss: 0.961714]\n",
      "epoch:21 step:16788[D loss: 0.469533, acc: 53.91%, op_acc: 37.50%] [G loss: 0.797426]\n",
      "epoch:21 step:16789[D loss: 0.449951, acc: 54.69%, op_acc: 36.72%] [G loss: 0.938866]\n",
      "epoch:21 step:16790[D loss: 0.449874, acc: 56.25%, op_acc: 34.38%] [G loss: 0.848242]\n",
      "epoch:21 step:16791[D loss: 0.395523, acc: 63.28%, op_acc: 45.31%] [G loss: 0.909330]\n",
      "epoch:21 step:16792[D loss: 0.423849, acc: 55.47%, op_acc: 43.75%] [G loss: 0.875967]\n",
      "epoch:21 step:16793[D loss: 0.415247, acc: 63.28%, op_acc: 43.75%] [G loss: 0.915079]\n",
      "epoch:21 step:16794[D loss: 0.428967, acc: 59.38%, op_acc: 39.06%] [G loss: 0.840518]\n",
      "epoch:21 step:16795[D loss: 0.434577, acc: 59.38%, op_acc: 39.06%] [G loss: 0.871683]\n",
      "epoch:21 step:16796[D loss: 0.436454, acc: 63.28%, op_acc: 35.94%] [G loss: 0.874501]\n",
      "epoch:21 step:16797[D loss: 0.420936, acc: 55.47%, op_acc: 40.62%] [G loss: 0.856265]\n",
      "epoch:21 step:16798[D loss: 0.409111, acc: 58.59%, op_acc: 41.41%] [G loss: 0.901478]\n",
      "epoch:21 step:16799[D loss: 0.432869, acc: 62.50%, op_acc: 35.94%] [G loss: 0.929876]\n",
      "epoch:21 step:16800[D loss: 0.449835, acc: 44.53%, op_acc: 40.62%] [G loss: 0.845209]\n",
      "epoch:21 step:16801[D loss: 0.397105, acc: 64.06%, op_acc: 43.75%] [G loss: 0.884736]\n",
      "epoch:21 step:16802[D loss: 0.388735, acc: 67.97%, op_acc: 42.19%] [G loss: 0.924954]\n",
      "epoch:21 step:16803[D loss: 0.427062, acc: 67.19%, op_acc: 38.28%] [G loss: 0.920860]\n",
      "epoch:21 step:16804[D loss: 0.444593, acc: 57.81%, op_acc: 37.50%] [G loss: 0.831184]\n",
      "epoch:21 step:16805[D loss: 0.418154, acc: 54.69%, op_acc: 46.88%] [G loss: 0.856726]\n",
      "epoch:21 step:16806[D loss: 0.407070, acc: 68.75%, op_acc: 38.28%] [G loss: 0.916230]\n",
      "epoch:21 step:16807[D loss: 0.451629, acc: 50.78%, op_acc: 33.59%] [G loss: 0.823015]\n",
      "epoch:21 step:16808[D loss: 0.412765, acc: 59.38%, op_acc: 39.84%] [G loss: 0.893675]\n",
      "epoch:21 step:16809[D loss: 0.390026, acc: 60.16%, op_acc: 43.75%] [G loss: 0.992085]\n",
      "epoch:21 step:16810[D loss: 0.432469, acc: 57.03%, op_acc: 43.75%] [G loss: 0.856480]\n",
      "epoch:21 step:16811[D loss: 0.400410, acc: 60.94%, op_acc: 41.41%] [G loss: 0.902264]\n",
      "epoch:21 step:16812[D loss: 0.413351, acc: 64.06%, op_acc: 32.81%] [G loss: 0.902338]\n",
      "epoch:21 step:16813[D loss: 0.429983, acc: 53.91%, op_acc: 38.28%] [G loss: 0.859915]\n",
      "epoch:21 step:16814[D loss: 0.399395, acc: 66.41%, op_acc: 37.50%] [G loss: 0.835300]\n",
      "epoch:21 step:16815[D loss: 0.415316, acc: 55.47%, op_acc: 35.94%] [G loss: 0.844123]\n",
      "epoch:21 step:16816[D loss: 0.406393, acc: 63.28%, op_acc: 41.41%] [G loss: 0.903430]\n",
      "epoch:21 step:16817[D loss: 0.435198, acc: 60.16%, op_acc: 40.62%] [G loss: 0.854800]\n",
      "epoch:21 step:16818[D loss: 0.411532, acc: 61.72%, op_acc: 39.84%] [G loss: 0.859777]\n",
      "epoch:21 step:16819[D loss: 0.419331, acc: 65.62%, op_acc: 38.28%] [G loss: 0.879129]\n",
      "epoch:21 step:16820[D loss: 0.401495, acc: 69.53%, op_acc: 39.84%] [G loss: 0.902536]\n",
      "epoch:21 step:16821[D loss: 0.446150, acc: 54.69%, op_acc: 38.28%] [G loss: 0.885556]\n",
      "epoch:21 step:16822[D loss: 0.424499, acc: 67.19%, op_acc: 38.28%] [G loss: 0.875842]\n",
      "epoch:21 step:16823[D loss: 0.426910, acc: 54.69%, op_acc: 36.72%] [G loss: 0.934922]\n",
      "epoch:21 step:16824[D loss: 0.450947, acc: 46.88%, op_acc: 35.16%] [G loss: 0.891079]\n",
      "epoch:21 step:16825[D loss: 0.454622, acc: 53.91%, op_acc: 36.72%] [G loss: 0.899366]\n",
      "epoch:21 step:16826[D loss: 0.432597, acc: 57.03%, op_acc: 37.50%] [G loss: 0.929402]\n",
      "epoch:21 step:16827[D loss: 0.464216, acc: 53.12%, op_acc: 38.28%] [G loss: 0.938321]\n",
      "epoch:21 step:16828[D loss: 0.439356, acc: 52.34%, op_acc: 36.72%] [G loss: 0.769184]\n",
      "epoch:21 step:16829[D loss: 0.433243, acc: 57.03%, op_acc: 44.53%] [G loss: 0.807018]\n",
      "epoch:21 step:16830[D loss: 0.411548, acc: 60.94%, op_acc: 37.50%] [G loss: 0.866796]\n",
      "epoch:21 step:16831[D loss: 0.427865, acc: 59.38%, op_acc: 35.16%] [G loss: 0.827756]\n",
      "epoch:21 step:16832[D loss: 0.421991, acc: 64.06%, op_acc: 38.28%] [G loss: 0.885129]\n",
      "epoch:21 step:16833[D loss: 0.396643, acc: 57.81%, op_acc: 43.75%] [G loss: 0.944977]\n",
      "epoch:21 step:16834[D loss: 0.433083, acc: 53.12%, op_acc: 40.62%] [G loss: 0.849464]\n",
      "epoch:21 step:16835[D loss: 0.432142, acc: 55.47%, op_acc: 38.28%] [G loss: 0.948987]\n",
      "epoch:21 step:16836[D loss: 0.418260, acc: 60.16%, op_acc: 39.84%] [G loss: 0.921065]\n",
      "epoch:21 step:16837[D loss: 0.458960, acc: 59.38%, op_acc: 36.72%] [G loss: 0.905736]\n",
      "epoch:21 step:16838[D loss: 0.458315, acc: 56.25%, op_acc: 35.94%] [G loss: 0.883579]\n",
      "epoch:21 step:16839[D loss: 0.420564, acc: 60.16%, op_acc: 41.41%] [G loss: 0.865717]\n",
      "epoch:21 step:16840[D loss: 0.432135, acc: 59.38%, op_acc: 36.72%] [G loss: 0.925059]\n",
      "epoch:21 step:16841[D loss: 0.416671, acc: 64.06%, op_acc: 34.38%] [G loss: 0.911565]\n",
      "epoch:21 step:16842[D loss: 0.431047, acc: 55.47%, op_acc: 38.28%] [G loss: 0.830369]\n",
      "epoch:21 step:16843[D loss: 0.425000, acc: 52.34%, op_acc: 42.19%] [G loss: 0.858376]\n",
      "epoch:21 step:16844[D loss: 0.440367, acc: 55.47%, op_acc: 36.72%] [G loss: 0.860214]\n",
      "epoch:21 step:16845[D loss: 0.422788, acc: 50.00%, op_acc: 39.84%] [G loss: 0.895054]\n",
      "epoch:21 step:16846[D loss: 0.429297, acc: 60.94%, op_acc: 39.06%] [G loss: 0.859237]\n",
      "epoch:21 step:16847[D loss: 0.421301, acc: 61.72%, op_acc: 40.62%] [G loss: 0.794960]\n",
      "epoch:21 step:16848[D loss: 0.451969, acc: 58.59%, op_acc: 35.94%] [G loss: 0.920829]\n",
      "epoch:21 step:16849[D loss: 0.404842, acc: 67.19%, op_acc: 36.72%] [G loss: 0.920398]\n",
      "epoch:21 step:16850[D loss: 0.420333, acc: 57.03%, op_acc: 39.06%] [G loss: 0.907621]\n",
      "epoch:21 step:16851[D loss: 0.428828, acc: 61.72%, op_acc: 33.59%] [G loss: 0.950653]\n",
      "epoch:21 step:16852[D loss: 0.415386, acc: 62.50%, op_acc: 42.19%] [G loss: 0.899810]\n",
      "epoch:21 step:16853[D loss: 0.399363, acc: 62.50%, op_acc: 39.84%] [G loss: 0.839923]\n",
      "epoch:21 step:16854[D loss: 0.411412, acc: 67.97%, op_acc: 41.41%] [G loss: 0.890721]\n",
      "epoch:21 step:16855[D loss: 0.447536, acc: 48.44%, op_acc: 39.06%] [G loss: 0.886740]\n",
      "epoch:21 step:16856[D loss: 0.448398, acc: 55.47%, op_acc: 40.62%] [G loss: 0.907991]\n",
      "epoch:21 step:16857[D loss: 0.433942, acc: 58.59%, op_acc: 35.94%] [G loss: 0.895746]\n",
      "epoch:21 step:16858[D loss: 0.432977, acc: 57.81%, op_acc: 35.94%] [G loss: 0.841380]\n",
      "epoch:21 step:16859[D loss: 0.418579, acc: 54.69%, op_acc: 39.06%] [G loss: 0.854102]\n",
      "epoch:21 step:16860[D loss: 0.408499, acc: 53.91%, op_acc: 44.53%] [G loss: 0.786704]\n",
      "epoch:21 step:16861[D loss: 0.421591, acc: 57.81%, op_acc: 39.06%] [G loss: 0.824053]\n",
      "epoch:21 step:16862[D loss: 0.391257, acc: 63.28%, op_acc: 42.19%] [G loss: 0.971056]\n",
      "epoch:21 step:16863[D loss: 0.417679, acc: 64.06%, op_acc: 35.94%] [G loss: 0.900962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16864[D loss: 0.434791, acc: 54.69%, op_acc: 40.62%] [G loss: 0.880433]\n",
      "epoch:21 step:16865[D loss: 0.449664, acc: 60.94%, op_acc: 29.69%] [G loss: 0.906284]\n",
      "epoch:21 step:16866[D loss: 0.446068, acc: 51.56%, op_acc: 38.28%] [G loss: 0.889345]\n",
      "epoch:21 step:16867[D loss: 0.426184, acc: 62.50%, op_acc: 36.72%] [G loss: 0.911412]\n",
      "epoch:21 step:16868[D loss: 0.430024, acc: 54.69%, op_acc: 37.50%] [G loss: 0.816981]\n",
      "epoch:21 step:16869[D loss: 0.373206, acc: 64.84%, op_acc: 46.88%] [G loss: 0.931000]\n",
      "epoch:21 step:16870[D loss: 0.389129, acc: 66.41%, op_acc: 38.28%] [G loss: 0.891988]\n",
      "epoch:21 step:16871[D loss: 0.412504, acc: 64.84%, op_acc: 38.28%] [G loss: 0.873927]\n",
      "epoch:21 step:16872[D loss: 0.426214, acc: 59.38%, op_acc: 36.72%] [G loss: 0.933420]\n",
      "epoch:21 step:16873[D loss: 0.409825, acc: 60.16%, op_acc: 37.50%] [G loss: 0.867544]\n",
      "epoch:21 step:16874[D loss: 0.383339, acc: 60.16%, op_acc: 46.09%] [G loss: 0.977330]\n",
      "epoch:21 step:16875[D loss: 0.419927, acc: 64.84%, op_acc: 39.06%] [G loss: 0.902091]\n",
      "epoch:21 step:16876[D loss: 0.425437, acc: 53.91%, op_acc: 46.09%] [G loss: 0.900797]\n",
      "epoch:21 step:16877[D loss: 0.429124, acc: 57.81%, op_acc: 33.59%] [G loss: 0.811097]\n",
      "epoch:21 step:16878[D loss: 0.443311, acc: 57.03%, op_acc: 42.19%] [G loss: 0.867810]\n",
      "epoch:21 step:16879[D loss: 0.421567, acc: 60.94%, op_acc: 41.41%] [G loss: 0.909752]\n",
      "epoch:21 step:16880[D loss: 0.432510, acc: 61.72%, op_acc: 40.62%] [G loss: 0.939943]\n",
      "epoch:21 step:16881[D loss: 0.448774, acc: 58.59%, op_acc: 33.59%] [G loss: 0.839722]\n",
      "epoch:21 step:16882[D loss: 0.420979, acc: 68.75%, op_acc: 40.62%] [G loss: 0.875880]\n",
      "epoch:21 step:16883[D loss: 0.412467, acc: 57.81%, op_acc: 42.19%] [G loss: 1.005060]\n",
      "epoch:21 step:16884[D loss: 0.443215, acc: 59.38%, op_acc: 38.28%] [G loss: 0.866483]\n",
      "epoch:21 step:16885[D loss: 0.428820, acc: 57.03%, op_acc: 38.28%] [G loss: 0.856466]\n",
      "epoch:21 step:16886[D loss: 0.443946, acc: 52.34%, op_acc: 38.28%] [G loss: 0.808094]\n",
      "epoch:21 step:16887[D loss: 0.429101, acc: 50.78%, op_acc: 39.84%] [G loss: 0.838507]\n",
      "epoch:21 step:16888[D loss: 0.418859, acc: 62.50%, op_acc: 36.72%] [G loss: 0.899515]\n",
      "epoch:21 step:16889[D loss: 0.447323, acc: 54.69%, op_acc: 35.16%] [G loss: 0.857077]\n",
      "epoch:21 step:16890[D loss: 0.441534, acc: 56.25%, op_acc: 43.75%] [G loss: 0.881815]\n",
      "epoch:21 step:16891[D loss: 0.415504, acc: 63.28%, op_acc: 39.06%] [G loss: 0.911354]\n",
      "epoch:21 step:16892[D loss: 0.451947, acc: 51.56%, op_acc: 36.72%] [G loss: 0.883459]\n",
      "epoch:21 step:16893[D loss: 0.442834, acc: 54.69%, op_acc: 35.16%] [G loss: 0.918536]\n",
      "epoch:21 step:16894[D loss: 0.433769, acc: 55.47%, op_acc: 34.38%] [G loss: 0.849365]\n",
      "epoch:21 step:16895[D loss: 0.367402, acc: 78.12%, op_acc: 41.41%] [G loss: 0.896330]\n",
      "epoch:21 step:16896[D loss: 0.445702, acc: 56.25%, op_acc: 36.72%] [G loss: 0.874222]\n",
      "epoch:21 step:16897[D loss: 0.394600, acc: 70.31%, op_acc: 42.19%] [G loss: 0.872719]\n",
      "epoch:21 step:16898[D loss: 0.407348, acc: 60.16%, op_acc: 39.06%] [G loss: 0.816301]\n",
      "epoch:21 step:16899[D loss: 0.459959, acc: 56.25%, op_acc: 33.59%] [G loss: 0.919914]\n",
      "epoch:21 step:16900[D loss: 0.457972, acc: 57.03%, op_acc: 35.94%] [G loss: 0.850466]\n",
      "epoch:21 step:16901[D loss: 0.401720, acc: 67.19%, op_acc: 45.31%] [G loss: 0.929340]\n",
      "epoch:21 step:16902[D loss: 0.481324, acc: 53.91%, op_acc: 28.12%] [G loss: 0.888122]\n",
      "epoch:21 step:16903[D loss: 0.450581, acc: 50.00%, op_acc: 39.84%] [G loss: 0.923575]\n",
      "epoch:21 step:16904[D loss: 0.413188, acc: 64.84%, op_acc: 34.38%] [G loss: 0.968354]\n",
      "epoch:21 step:16905[D loss: 0.438608, acc: 55.47%, op_acc: 31.25%] [G loss: 0.925439]\n",
      "epoch:21 step:16906[D loss: 0.423581, acc: 62.50%, op_acc: 40.62%] [G loss: 0.985361]\n",
      "epoch:21 step:16907[D loss: 0.458500, acc: 47.66%, op_acc: 40.62%] [G loss: 0.870195]\n",
      "epoch:21 step:16908[D loss: 0.397028, acc: 64.06%, op_acc: 37.50%] [G loss: 0.886128]\n",
      "epoch:21 step:16909[D loss: 0.445316, acc: 54.69%, op_acc: 39.06%] [G loss: 0.950614]\n",
      "epoch:21 step:16910[D loss: 0.473794, acc: 55.47%, op_acc: 35.16%] [G loss: 0.939114]\n",
      "epoch:21 step:16911[D loss: 0.439507, acc: 56.25%, op_acc: 38.28%] [G loss: 0.813741]\n",
      "epoch:21 step:16912[D loss: 0.429990, acc: 56.25%, op_acc: 39.84%] [G loss: 0.902101]\n",
      "epoch:21 step:16913[D loss: 0.451133, acc: 58.59%, op_acc: 34.38%] [G loss: 0.873979]\n",
      "epoch:21 step:16914[D loss: 0.437429, acc: 63.28%, op_acc: 35.16%] [G loss: 0.894349]\n",
      "epoch:21 step:16915[D loss: 0.431879, acc: 57.81%, op_acc: 38.28%] [G loss: 0.919436]\n",
      "epoch:21 step:16916[D loss: 0.425952, acc: 63.28%, op_acc: 39.84%] [G loss: 0.871502]\n",
      "epoch:21 step:16917[D loss: 0.413774, acc: 65.62%, op_acc: 41.41%] [G loss: 0.846070]\n",
      "epoch:21 step:16918[D loss: 0.469069, acc: 55.47%, op_acc: 37.50%] [G loss: 0.927953]\n",
      "epoch:21 step:16919[D loss: 0.429188, acc: 57.81%, op_acc: 42.19%] [G loss: 0.759034]\n",
      "epoch:21 step:16920[D loss: 0.401024, acc: 62.50%, op_acc: 42.19%] [G loss: 0.848698]\n",
      "epoch:21 step:16921[D loss: 0.432602, acc: 60.16%, op_acc: 41.41%] [G loss: 0.790081]\n",
      "epoch:21 step:16922[D loss: 0.428287, acc: 59.38%, op_acc: 38.28%] [G loss: 0.931455]\n",
      "epoch:21 step:16923[D loss: 0.434535, acc: 55.47%, op_acc: 35.16%] [G loss: 0.831067]\n",
      "epoch:21 step:16924[D loss: 0.425955, acc: 60.94%, op_acc: 42.19%] [G loss: 0.897081]\n",
      "epoch:21 step:16925[D loss: 0.423266, acc: 61.72%, op_acc: 42.97%] [G loss: 0.848888]\n",
      "epoch:21 step:16926[D loss: 0.444088, acc: 57.03%, op_acc: 32.81%] [G loss: 0.863111]\n",
      "epoch:21 step:16927[D loss: 0.444896, acc: 60.16%, op_acc: 37.50%] [G loss: 1.032946]\n",
      "epoch:21 step:16928[D loss: 0.454572, acc: 53.91%, op_acc: 37.50%] [G loss: 0.886336]\n",
      "epoch:21 step:16929[D loss: 0.413501, acc: 59.38%, op_acc: 44.53%] [G loss: 0.852595]\n",
      "epoch:21 step:16930[D loss: 0.411246, acc: 61.72%, op_acc: 41.41%] [G loss: 0.908244]\n",
      "epoch:21 step:16931[D loss: 0.426316, acc: 61.72%, op_acc: 34.38%] [G loss: 0.901684]\n",
      "epoch:21 step:16932[D loss: 0.428398, acc: 60.16%, op_acc: 36.72%] [G loss: 0.877609]\n",
      "epoch:21 step:16933[D loss: 0.428615, acc: 58.59%, op_acc: 38.28%] [G loss: 0.823382]\n",
      "epoch:21 step:16934[D loss: 0.439333, acc: 51.56%, op_acc: 38.28%] [G loss: 0.904598]\n",
      "epoch:21 step:16935[D loss: 0.436016, acc: 59.38%, op_acc: 43.75%] [G loss: 0.922356]\n",
      "epoch:21 step:16936[D loss: 0.428447, acc: 61.72%, op_acc: 35.16%] [G loss: 0.930535]\n",
      "epoch:21 step:16937[D loss: 0.417555, acc: 57.81%, op_acc: 38.28%] [G loss: 0.946013]\n",
      "epoch:21 step:16938[D loss: 0.455941, acc: 48.44%, op_acc: 36.72%] [G loss: 0.885027]\n",
      "epoch:21 step:16939[D loss: 0.413382, acc: 67.97%, op_acc: 40.62%] [G loss: 0.904647]\n",
      "epoch:21 step:16940[D loss: 0.432609, acc: 60.94%, op_acc: 40.62%] [G loss: 0.905198]\n",
      "epoch:21 step:16941[D loss: 0.426708, acc: 63.28%, op_acc: 38.28%] [G loss: 0.866827]\n",
      "epoch:21 step:16942[D loss: 0.393460, acc: 67.19%, op_acc: 45.31%] [G loss: 0.873122]\n",
      "epoch:21 step:16943[D loss: 0.466586, acc: 49.22%, op_acc: 31.25%] [G loss: 0.957997]\n",
      "epoch:21 step:16944[D loss: 0.424560, acc: 64.84%, op_acc: 38.28%] [G loss: 0.803662]\n",
      "epoch:21 step:16945[D loss: 0.403400, acc: 63.28%, op_acc: 39.06%] [G loss: 0.907899]\n",
      "epoch:21 step:16946[D loss: 0.380573, acc: 68.75%, op_acc: 39.06%] [G loss: 1.018092]\n",
      "epoch:21 step:16947[D loss: 0.419991, acc: 64.06%, op_acc: 41.41%] [G loss: 0.891348]\n",
      "epoch:21 step:16948[D loss: 0.436674, acc: 55.47%, op_acc: 35.94%] [G loss: 0.890205]\n",
      "epoch:21 step:16949[D loss: 0.442642, acc: 57.03%, op_acc: 35.94%] [G loss: 0.905547]\n",
      "epoch:21 step:16950[D loss: 0.454914, acc: 52.34%, op_acc: 39.06%] [G loss: 0.821272]\n",
      "epoch:21 step:16951[D loss: 0.452022, acc: 53.12%, op_acc: 31.25%] [G loss: 0.936312]\n",
      "epoch:21 step:16952[D loss: 0.396844, acc: 64.84%, op_acc: 42.19%] [G loss: 0.917819]\n",
      "epoch:21 step:16953[D loss: 0.460702, acc: 49.22%, op_acc: 34.38%] [G loss: 0.868732]\n",
      "epoch:21 step:16954[D loss: 0.413232, acc: 53.91%, op_acc: 42.97%] [G loss: 0.819396]\n",
      "epoch:21 step:16955[D loss: 0.445859, acc: 53.12%, op_acc: 36.72%] [G loss: 0.969225]\n",
      "epoch:21 step:16956[D loss: 0.409111, acc: 60.16%, op_acc: 42.97%] [G loss: 0.860631]\n",
      "epoch:21 step:16957[D loss: 0.428363, acc: 58.59%, op_acc: 32.81%] [G loss: 0.889709]\n",
      "epoch:21 step:16958[D loss: 0.432115, acc: 61.72%, op_acc: 34.38%] [G loss: 0.780816]\n",
      "epoch:21 step:16959[D loss: 0.426046, acc: 58.59%, op_acc: 43.75%] [G loss: 0.866577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:16960[D loss: 0.404115, acc: 64.84%, op_acc: 35.94%] [G loss: 0.851308]\n",
      "epoch:21 step:16961[D loss: 0.451808, acc: 53.91%, op_acc: 36.72%] [G loss: 0.917158]\n",
      "epoch:21 step:16962[D loss: 0.412189, acc: 60.16%, op_acc: 42.19%] [G loss: 0.886948]\n",
      "epoch:21 step:16963[D loss: 0.435400, acc: 55.47%, op_acc: 38.28%] [G loss: 0.986700]\n",
      "epoch:21 step:16964[D loss: 0.425323, acc: 60.16%, op_acc: 34.38%] [G loss: 0.991688]\n",
      "epoch:21 step:16965[D loss: 0.403338, acc: 62.50%, op_acc: 48.44%] [G loss: 0.974811]\n",
      "epoch:21 step:16966[D loss: 0.412646, acc: 67.97%, op_acc: 36.72%] [G loss: 0.824351]\n",
      "epoch:21 step:16967[D loss: 0.410839, acc: 62.50%, op_acc: 39.06%] [G loss: 0.884033]\n",
      "epoch:21 step:16968[D loss: 0.418582, acc: 60.16%, op_acc: 42.19%] [G loss: 0.862769]\n",
      "epoch:21 step:16969[D loss: 0.435426, acc: 56.25%, op_acc: 38.28%] [G loss: 0.929641]\n",
      "epoch:21 step:16970[D loss: 0.416793, acc: 59.38%, op_acc: 39.84%] [G loss: 0.795795]\n",
      "epoch:21 step:16971[D loss: 0.399112, acc: 68.75%, op_acc: 43.75%] [G loss: 0.886392]\n",
      "epoch:21 step:16972[D loss: 0.402421, acc: 63.28%, op_acc: 40.62%] [G loss: 0.936970]\n",
      "epoch:21 step:16973[D loss: 0.436815, acc: 58.59%, op_acc: 38.28%] [G loss: 0.913889]\n",
      "epoch:21 step:16974[D loss: 0.412089, acc: 62.50%, op_acc: 42.19%] [G loss: 0.852361]\n",
      "epoch:21 step:16975[D loss: 0.437705, acc: 58.59%, op_acc: 39.84%] [G loss: 0.831404]\n",
      "epoch:21 step:16976[D loss: 0.426356, acc: 51.56%, op_acc: 42.19%] [G loss: 0.831295]\n",
      "epoch:21 step:16977[D loss: 0.438594, acc: 50.78%, op_acc: 36.72%] [G loss: 0.871391]\n",
      "epoch:21 step:16978[D loss: 0.439556, acc: 60.16%, op_acc: 38.28%] [G loss: 0.819176]\n",
      "epoch:21 step:16979[D loss: 0.468100, acc: 52.34%, op_acc: 32.81%] [G loss: 0.899658]\n",
      "epoch:21 step:16980[D loss: 0.393027, acc: 71.09%, op_acc: 41.41%] [G loss: 0.812926]\n",
      "epoch:21 step:16981[D loss: 0.419015, acc: 64.84%, op_acc: 38.28%] [G loss: 0.886591]\n",
      "epoch:21 step:16982[D loss: 0.439703, acc: 60.16%, op_acc: 30.47%] [G loss: 0.912635]\n",
      "epoch:21 step:16983[D loss: 0.404884, acc: 64.84%, op_acc: 35.94%] [G loss: 0.812823]\n",
      "epoch:21 step:16984[D loss: 0.394362, acc: 61.72%, op_acc: 40.62%] [G loss: 0.932923]\n",
      "epoch:21 step:16985[D loss: 0.466373, acc: 57.81%, op_acc: 28.91%] [G loss: 0.931079]\n",
      "epoch:21 step:16986[D loss: 0.424114, acc: 58.59%, op_acc: 40.62%] [G loss: 0.859764]\n",
      "epoch:21 step:16987[D loss: 0.415721, acc: 66.41%, op_acc: 37.50%] [G loss: 0.913062]\n",
      "epoch:21 step:16988[D loss: 0.422523, acc: 68.75%, op_acc: 35.16%] [G loss: 0.899541]\n",
      "epoch:21 step:16989[D loss: 0.416383, acc: 56.25%, op_acc: 42.97%] [G loss: 0.932788]\n",
      "epoch:21 step:16990[D loss: 0.434274, acc: 61.72%, op_acc: 39.84%] [G loss: 0.897587]\n",
      "epoch:21 step:16991[D loss: 0.394447, acc: 66.41%, op_acc: 41.41%] [G loss: 0.849367]\n",
      "epoch:21 step:16992[D loss: 0.403241, acc: 64.84%, op_acc: 39.84%] [G loss: 0.952664]\n",
      "epoch:21 step:16993[D loss: 0.462210, acc: 50.78%, op_acc: 34.38%] [G loss: 0.893831]\n",
      "epoch:21 step:16994[D loss: 0.428133, acc: 59.38%, op_acc: 40.62%] [G loss: 0.956218]\n",
      "epoch:21 step:16995[D loss: 0.419629, acc: 64.84%, op_acc: 40.62%] [G loss: 0.938170]\n",
      "epoch:21 step:16996[D loss: 0.430719, acc: 61.72%, op_acc: 32.81%] [G loss: 0.864557]\n",
      "epoch:21 step:16997[D loss: 0.402849, acc: 64.06%, op_acc: 39.84%] [G loss: 0.865931]\n",
      "epoch:21 step:16998[D loss: 0.411057, acc: 59.38%, op_acc: 44.53%] [G loss: 0.791443]\n",
      "epoch:21 step:16999[D loss: 0.405005, acc: 64.06%, op_acc: 42.97%] [G loss: 0.831588]\n",
      "epoch:21 step:17000[D loss: 0.439982, acc: 60.94%, op_acc: 35.16%] [G loss: 0.926284]\n",
      "epoch:21 step:17001[D loss: 0.398830, acc: 67.97%, op_acc: 39.84%] [G loss: 0.925067]\n",
      "epoch:21 step:17002[D loss: 0.420017, acc: 64.84%, op_acc: 35.94%] [G loss: 0.898403]\n",
      "epoch:21 step:17003[D loss: 0.442617, acc: 55.47%, op_acc: 39.84%] [G loss: 0.814929]\n",
      "epoch:21 step:17004[D loss: 0.420699, acc: 60.16%, op_acc: 44.53%] [G loss: 0.840656]\n",
      "epoch:21 step:17005[D loss: 0.453785, acc: 60.94%, op_acc: 28.91%] [G loss: 0.901985]\n",
      "epoch:21 step:17006[D loss: 0.430577, acc: 60.94%, op_acc: 35.16%] [G loss: 0.912842]\n",
      "epoch:21 step:17007[D loss: 0.414604, acc: 62.50%, op_acc: 34.38%] [G loss: 0.826871]\n",
      "epoch:21 step:17008[D loss: 0.398172, acc: 67.97%, op_acc: 44.53%] [G loss: 0.904521]\n",
      "epoch:21 step:17009[D loss: 0.387345, acc: 64.84%, op_acc: 39.84%] [G loss: 0.902574]\n",
      "epoch:21 step:17010[D loss: 0.458359, acc: 47.66%, op_acc: 42.19%] [G loss: 0.857382]\n",
      "epoch:21 step:17011[D loss: 0.435571, acc: 51.56%, op_acc: 38.28%] [G loss: 0.882360]\n",
      "epoch:21 step:17012[D loss: 0.437542, acc: 54.69%, op_acc: 38.28%] [G loss: 0.870465]\n",
      "epoch:21 step:17013[D loss: 0.419904, acc: 57.81%, op_acc: 42.19%] [G loss: 0.781275]\n",
      "epoch:21 step:17014[D loss: 0.470537, acc: 48.44%, op_acc: 39.84%] [G loss: 0.813097]\n",
      "epoch:21 step:17015[D loss: 0.429797, acc: 61.72%, op_acc: 36.72%] [G loss: 0.822340]\n",
      "epoch:21 step:17016[D loss: 0.439075, acc: 57.03%, op_acc: 39.84%] [G loss: 0.931898]\n",
      "epoch:21 step:17017[D loss: 0.434929, acc: 54.69%, op_acc: 37.50%] [G loss: 0.884861]\n",
      "epoch:21 step:17018[D loss: 0.450793, acc: 53.12%, op_acc: 36.72%] [G loss: 0.894818]\n",
      "epoch:21 step:17019[D loss: 0.424158, acc: 57.81%, op_acc: 42.97%] [G loss: 0.858322]\n",
      "epoch:21 step:17020[D loss: 0.453817, acc: 56.25%, op_acc: 32.81%] [G loss: 0.886529]\n",
      "epoch:21 step:17021[D loss: 0.404011, acc: 63.28%, op_acc: 35.94%] [G loss: 0.916960]\n",
      "epoch:21 step:17022[D loss: 0.446212, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880350]\n",
      "epoch:21 step:17023[D loss: 0.464078, acc: 53.12%, op_acc: 30.47%] [G loss: 0.885352]\n",
      "epoch:21 step:17024[D loss: 0.418698, acc: 55.47%, op_acc: 39.06%] [G loss: 0.873006]\n",
      "epoch:21 step:17025[D loss: 0.417135, acc: 60.94%, op_acc: 40.62%] [G loss: 0.903626]\n",
      "epoch:21 step:17026[D loss: 0.447671, acc: 53.12%, op_acc: 42.19%] [G loss: 0.890676]\n",
      "epoch:21 step:17027[D loss: 0.438215, acc: 49.22%, op_acc: 42.19%] [G loss: 0.845381]\n",
      "epoch:21 step:17028[D loss: 0.441473, acc: 48.44%, op_acc: 41.41%] [G loss: 0.842080]\n",
      "epoch:21 step:17029[D loss: 0.423625, acc: 58.59%, op_acc: 40.62%] [G loss: 0.828327]\n",
      "epoch:21 step:17030[D loss: 0.413610, acc: 58.59%, op_acc: 39.06%] [G loss: 0.856739]\n",
      "epoch:21 step:17031[D loss: 0.425076, acc: 56.25%, op_acc: 42.19%] [G loss: 0.900170]\n",
      "epoch:21 step:17032[D loss: 0.454926, acc: 45.31%, op_acc: 39.84%] [G loss: 0.834697]\n",
      "epoch:21 step:17033[D loss: 0.417461, acc: 62.50%, op_acc: 36.72%] [G loss: 0.974165]\n",
      "epoch:21 step:17034[D loss: 0.438955, acc: 59.38%, op_acc: 37.50%] [G loss: 0.792214]\n",
      "epoch:21 step:17035[D loss: 0.406078, acc: 60.16%, op_acc: 39.84%] [G loss: 0.979788]\n",
      "epoch:21 step:17036[D loss: 0.448046, acc: 51.56%, op_acc: 35.94%] [G loss: 0.838461]\n",
      "epoch:21 step:17037[D loss: 0.422010, acc: 57.81%, op_acc: 39.84%] [G loss: 0.853326]\n",
      "epoch:21 step:17038[D loss: 0.404579, acc: 58.59%, op_acc: 38.28%] [G loss: 0.819099]\n",
      "epoch:21 step:17039[D loss: 0.461653, acc: 59.38%, op_acc: 31.25%] [G loss: 0.848184]\n",
      "epoch:21 step:17040[D loss: 0.439965, acc: 58.59%, op_acc: 37.50%] [G loss: 0.828404]\n",
      "epoch:21 step:17041[D loss: 0.451000, acc: 54.69%, op_acc: 41.41%] [G loss: 0.882049]\n",
      "epoch:21 step:17042[D loss: 0.403673, acc: 65.62%, op_acc: 35.94%] [G loss: 0.936129]\n",
      "epoch:21 step:17043[D loss: 0.421361, acc: 61.72%, op_acc: 31.25%] [G loss: 0.894552]\n",
      "epoch:21 step:17044[D loss: 0.449625, acc: 53.91%, op_acc: 36.72%] [G loss: 0.881582]\n",
      "epoch:21 step:17045[D loss: 0.407980, acc: 64.84%, op_acc: 46.88%] [G loss: 0.937041]\n",
      "epoch:21 step:17046[D loss: 0.422536, acc: 60.16%, op_acc: 43.75%] [G loss: 0.886254]\n",
      "epoch:21 step:17047[D loss: 0.466287, acc: 53.12%, op_acc: 34.38%] [G loss: 0.881343]\n",
      "epoch:21 step:17048[D loss: 0.413701, acc: 65.62%, op_acc: 40.62%] [G loss: 0.905200]\n",
      "epoch:21 step:17049[D loss: 0.419646, acc: 64.06%, op_acc: 38.28%] [G loss: 0.922796]\n",
      "epoch:21 step:17050[D loss: 0.422606, acc: 61.72%, op_acc: 36.72%] [G loss: 0.850099]\n",
      "epoch:21 step:17051[D loss: 0.434683, acc: 61.72%, op_acc: 45.31%] [G loss: 0.914839]\n",
      "epoch:21 step:17052[D loss: 0.445257, acc: 58.59%, op_acc: 35.94%] [G loss: 0.856881]\n",
      "epoch:21 step:17053[D loss: 0.438830, acc: 53.91%, op_acc: 38.28%] [G loss: 0.906497]\n",
      "epoch:21 step:17054[D loss: 0.429243, acc: 54.69%, op_acc: 40.62%] [G loss: 0.859746]\n",
      "epoch:21 step:17055[D loss: 0.430184, acc: 57.03%, op_acc: 39.06%] [G loss: 0.859334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17056[D loss: 0.428842, acc: 60.94%, op_acc: 41.41%] [G loss: 0.804083]\n",
      "epoch:21 step:17057[D loss: 0.429487, acc: 61.72%, op_acc: 33.59%] [G loss: 0.937680]\n",
      "epoch:21 step:17058[D loss: 0.457742, acc: 54.69%, op_acc: 37.50%] [G loss: 0.904577]\n",
      "epoch:21 step:17059[D loss: 0.421844, acc: 55.47%, op_acc: 44.53%] [G loss: 0.858893]\n",
      "epoch:21 step:17060[D loss: 0.429977, acc: 53.12%, op_acc: 39.06%] [G loss: 0.867995]\n",
      "epoch:21 step:17061[D loss: 0.430092, acc: 59.38%, op_acc: 42.97%] [G loss: 0.838310]\n",
      "epoch:21 step:17062[D loss: 0.417909, acc: 57.03%, op_acc: 42.19%] [G loss: 0.865535]\n",
      "epoch:21 step:17063[D loss: 0.394668, acc: 64.06%, op_acc: 41.41%] [G loss: 0.930933]\n",
      "epoch:21 step:17064[D loss: 0.384075, acc: 70.31%, op_acc: 39.84%] [G loss: 0.931007]\n",
      "epoch:21 step:17065[D loss: 0.440430, acc: 51.56%, op_acc: 39.84%] [G loss: 0.812009]\n",
      "epoch:21 step:17066[D loss: 0.417941, acc: 71.09%, op_acc: 32.81%] [G loss: 0.943151]\n",
      "epoch:21 step:17067[D loss: 0.435021, acc: 58.59%, op_acc: 37.50%] [G loss: 0.974951]\n",
      "epoch:21 step:17068[D loss: 0.421677, acc: 58.59%, op_acc: 34.38%] [G loss: 0.869424]\n",
      "epoch:21 step:17069[D loss: 0.440639, acc: 51.56%, op_acc: 35.16%] [G loss: 0.889939]\n",
      "epoch:21 step:17070[D loss: 0.451044, acc: 54.69%, op_acc: 32.81%] [G loss: 1.007233]\n",
      "epoch:21 step:17071[D loss: 0.442119, acc: 57.03%, op_acc: 40.62%] [G loss: 0.885509]\n",
      "epoch:21 step:17072[D loss: 0.419788, acc: 60.16%, op_acc: 38.28%] [G loss: 0.875805]\n",
      "epoch:21 step:17073[D loss: 0.440700, acc: 61.72%, op_acc: 39.84%] [G loss: 0.855189]\n",
      "epoch:21 step:17074[D loss: 0.438541, acc: 57.81%, op_acc: 39.06%] [G loss: 0.919704]\n",
      "epoch:21 step:17075[D loss: 0.411825, acc: 59.38%, op_acc: 47.66%] [G loss: 0.851672]\n",
      "epoch:21 step:17076[D loss: 0.414650, acc: 63.28%, op_acc: 37.50%] [G loss: 0.881312]\n",
      "epoch:21 step:17077[D loss: 0.449099, acc: 57.03%, op_acc: 33.59%] [G loss: 0.868458]\n",
      "epoch:21 step:17078[D loss: 0.462054, acc: 53.91%, op_acc: 32.81%] [G loss: 0.866578]\n",
      "epoch:21 step:17079[D loss: 0.425072, acc: 57.03%, op_acc: 43.75%] [G loss: 0.905447]\n",
      "epoch:21 step:17080[D loss: 0.400463, acc: 64.84%, op_acc: 44.53%] [G loss: 0.892565]\n",
      "epoch:21 step:17081[D loss: 0.461745, acc: 56.25%, op_acc: 36.72%] [G loss: 0.768713]\n",
      "epoch:21 step:17082[D loss: 0.437959, acc: 54.69%, op_acc: 39.06%] [G loss: 0.829650]\n",
      "epoch:21 step:17083[D loss: 0.438053, acc: 49.22%, op_acc: 41.41%] [G loss: 0.844644]\n",
      "epoch:21 step:17084[D loss: 0.436900, acc: 57.03%, op_acc: 43.75%] [G loss: 0.893417]\n",
      "epoch:21 step:17085[D loss: 0.439717, acc: 57.81%, op_acc: 36.72%] [G loss: 0.870784]\n",
      "epoch:21 step:17086[D loss: 0.421007, acc: 60.94%, op_acc: 39.06%] [G loss: 0.886172]\n",
      "epoch:21 step:17087[D loss: 0.431786, acc: 56.25%, op_acc: 37.50%] [G loss: 0.868748]\n",
      "epoch:21 step:17088[D loss: 0.430110, acc: 58.59%, op_acc: 35.16%] [G loss: 0.916497]\n",
      "epoch:21 step:17089[D loss: 0.396531, acc: 60.94%, op_acc: 46.09%] [G loss: 1.006205]\n",
      "epoch:21 step:17090[D loss: 0.443224, acc: 53.12%, op_acc: 35.94%] [G loss: 0.939279]\n",
      "epoch:21 step:17091[D loss: 0.432381, acc: 62.50%, op_acc: 33.59%] [G loss: 0.849317]\n",
      "epoch:21 step:17092[D loss: 0.451553, acc: 59.38%, op_acc: 39.84%] [G loss: 0.828027]\n",
      "epoch:21 step:17093[D loss: 0.458037, acc: 57.81%, op_acc: 35.16%] [G loss: 0.912825]\n",
      "epoch:21 step:17094[D loss: 0.452968, acc: 54.69%, op_acc: 36.72%] [G loss: 0.848704]\n",
      "epoch:21 step:17095[D loss: 0.429217, acc: 57.81%, op_acc: 34.38%] [G loss: 0.828237]\n",
      "epoch:21 step:17096[D loss: 0.420262, acc: 60.94%, op_acc: 39.06%] [G loss: 0.863823]\n",
      "epoch:21 step:17097[D loss: 0.450053, acc: 46.88%, op_acc: 37.50%] [G loss: 0.853617]\n",
      "epoch:21 step:17098[D loss: 0.430359, acc: 51.56%, op_acc: 44.53%] [G loss: 0.834648]\n",
      "epoch:21 step:17099[D loss: 0.415663, acc: 59.38%, op_acc: 35.16%] [G loss: 0.926453]\n",
      "epoch:21 step:17100[D loss: 0.389317, acc: 60.16%, op_acc: 42.97%] [G loss: 0.944750]\n",
      "epoch:21 step:17101[D loss: 0.429456, acc: 56.25%, op_acc: 42.19%] [G loss: 0.808543]\n",
      "epoch:21 step:17102[D loss: 0.409865, acc: 56.25%, op_acc: 36.72%] [G loss: 0.816035]\n",
      "epoch:21 step:17103[D loss: 0.443834, acc: 59.38%, op_acc: 37.50%] [G loss: 0.837155]\n",
      "epoch:21 step:17104[D loss: 0.449455, acc: 54.69%, op_acc: 39.84%] [G loss: 0.828299]\n",
      "epoch:21 step:17105[D loss: 0.393514, acc: 65.62%, op_acc: 41.41%] [G loss: 0.948637]\n",
      "epoch:21 step:17106[D loss: 0.423707, acc: 58.59%, op_acc: 39.84%] [G loss: 0.831041]\n",
      "epoch:21 step:17107[D loss: 0.468404, acc: 52.34%, op_acc: 32.03%] [G loss: 0.796614]\n",
      "epoch:21 step:17108[D loss: 0.447848, acc: 57.81%, op_acc: 32.81%] [G loss: 0.938072]\n",
      "epoch:21 step:17109[D loss: 0.444632, acc: 53.12%, op_acc: 35.16%] [G loss: 0.889109]\n",
      "epoch:21 step:17110[D loss: 0.423538, acc: 60.16%, op_acc: 37.50%] [G loss: 0.946541]\n",
      "epoch:21 step:17111[D loss: 0.358934, acc: 73.44%, op_acc: 46.88%] [G loss: 0.808541]\n",
      "epoch:21 step:17112[D loss: 0.427649, acc: 60.94%, op_acc: 41.41%] [G loss: 0.853078]\n",
      "epoch:21 step:17113[D loss: 0.415488, acc: 58.59%, op_acc: 40.62%] [G loss: 0.908451]\n",
      "epoch:21 step:17114[D loss: 0.411372, acc: 59.38%, op_acc: 43.75%] [G loss: 0.865326]\n",
      "epoch:21 step:17115[D loss: 0.425141, acc: 60.94%, op_acc: 32.81%] [G loss: 0.784474]\n",
      "epoch:21 step:17116[D loss: 0.429155, acc: 56.25%, op_acc: 38.28%] [G loss: 0.812842]\n",
      "epoch:21 step:17117[D loss: 0.458472, acc: 51.56%, op_acc: 36.72%] [G loss: 0.802934]\n",
      "epoch:21 step:17118[D loss: 0.379887, acc: 64.06%, op_acc: 40.62%] [G loss: 0.870568]\n",
      "epoch:21 step:17119[D loss: 0.428480, acc: 61.72%, op_acc: 35.16%] [G loss: 0.858765]\n",
      "epoch:21 step:17120[D loss: 0.404133, acc: 62.50%, op_acc: 44.53%] [G loss: 0.825380]\n",
      "epoch:21 step:17121[D loss: 0.401783, acc: 60.94%, op_acc: 38.28%] [G loss: 0.898821]\n",
      "epoch:21 step:17122[D loss: 0.455136, acc: 42.97%, op_acc: 35.94%] [G loss: 0.818811]\n",
      "epoch:21 step:17123[D loss: 0.440404, acc: 53.91%, op_acc: 35.94%] [G loss: 0.888790]\n",
      "epoch:21 step:17124[D loss: 0.426411, acc: 57.81%, op_acc: 42.19%] [G loss: 0.945188]\n",
      "epoch:21 step:17125[D loss: 0.483452, acc: 49.22%, op_acc: 36.72%] [G loss: 0.930766]\n",
      "epoch:21 step:17126[D loss: 0.412517, acc: 60.16%, op_acc: 37.50%] [G loss: 0.923407]\n",
      "epoch:21 step:17127[D loss: 0.432212, acc: 54.69%, op_acc: 40.62%] [G loss: 0.870795]\n",
      "epoch:21 step:17128[D loss: 0.452284, acc: 55.47%, op_acc: 34.38%] [G loss: 0.789206]\n",
      "epoch:21 step:17129[D loss: 0.426233, acc: 63.28%, op_acc: 35.16%] [G loss: 0.879647]\n",
      "epoch:21 step:17130[D loss: 0.427420, acc: 61.72%, op_acc: 40.62%] [G loss: 0.917964]\n",
      "epoch:21 step:17131[D loss: 0.450141, acc: 55.47%, op_acc: 37.50%] [G loss: 0.879592]\n",
      "epoch:21 step:17132[D loss: 0.413908, acc: 57.03%, op_acc: 37.50%] [G loss: 0.900110]\n",
      "epoch:21 step:17133[D loss: 0.415715, acc: 61.72%, op_acc: 39.06%] [G loss: 0.912530]\n",
      "epoch:21 step:17134[D loss: 0.420458, acc: 53.12%, op_acc: 37.50%] [G loss: 0.899045]\n",
      "epoch:21 step:17135[D loss: 0.440643, acc: 56.25%, op_acc: 33.59%] [G loss: 0.871938]\n",
      "epoch:21 step:17136[D loss: 0.436639, acc: 53.91%, op_acc: 42.19%] [G loss: 0.837189]\n",
      "epoch:21 step:17137[D loss: 0.452000, acc: 58.59%, op_acc: 36.72%] [G loss: 0.800848]\n",
      "epoch:21 step:17138[D loss: 0.408798, acc: 60.94%, op_acc: 42.97%] [G loss: 1.002037]\n",
      "epoch:21 step:17139[D loss: 0.425341, acc: 50.78%, op_acc: 38.28%] [G loss: 0.851860]\n",
      "epoch:21 step:17140[D loss: 0.434843, acc: 58.59%, op_acc: 45.31%] [G loss: 0.906715]\n",
      "epoch:21 step:17141[D loss: 0.442185, acc: 56.25%, op_acc: 37.50%] [G loss: 0.769273]\n",
      "epoch:21 step:17142[D loss: 0.439310, acc: 54.69%, op_acc: 39.06%] [G loss: 0.878280]\n",
      "epoch:21 step:17143[D loss: 0.424027, acc: 59.38%, op_acc: 39.06%] [G loss: 0.835536]\n",
      "epoch:21 step:17144[D loss: 0.414459, acc: 58.59%, op_acc: 36.72%] [G loss: 0.859904]\n",
      "epoch:21 step:17145[D loss: 0.420418, acc: 50.78%, op_acc: 43.75%] [G loss: 0.861113]\n",
      "epoch:21 step:17146[D loss: 0.414463, acc: 60.16%, op_acc: 42.97%] [G loss: 0.903802]\n",
      "epoch:21 step:17147[D loss: 0.463036, acc: 49.22%, op_acc: 31.25%] [G loss: 0.762004]\n",
      "epoch:21 step:17148[D loss: 0.418652, acc: 64.84%, op_acc: 36.72%] [G loss: 0.852610]\n",
      "epoch:21 step:17149[D loss: 0.457905, acc: 57.03%, op_acc: 35.16%] [G loss: 0.767509]\n",
      "epoch:21 step:17150[D loss: 0.459212, acc: 54.69%, op_acc: 36.72%] [G loss: 0.869692]\n",
      "epoch:21 step:17151[D loss: 0.423384, acc: 55.47%, op_acc: 39.06%] [G loss: 0.895140]\n",
      "epoch:21 step:17152[D loss: 0.461799, acc: 60.94%, op_acc: 32.03%] [G loss: 0.882416]\n",
      "epoch:21 step:17153[D loss: 0.397291, acc: 64.84%, op_acc: 41.41%] [G loss: 0.849568]\n",
      "epoch:21 step:17154[D loss: 0.414545, acc: 58.59%, op_acc: 43.75%] [G loss: 0.856097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:17155[D loss: 0.421935, acc: 55.47%, op_acc: 40.62%] [G loss: 0.895075]\n",
      "epoch:21 step:17156[D loss: 0.443675, acc: 55.47%, op_acc: 32.81%] [G loss: 0.892832]\n",
      "epoch:21 step:17157[D loss: 0.421283, acc: 64.06%, op_acc: 39.84%] [G loss: 0.940131]\n",
      "epoch:21 step:17158[D loss: 0.414962, acc: 58.59%, op_acc: 37.50%] [G loss: 0.849044]\n",
      "epoch:21 step:17159[D loss: 0.420834, acc: 56.25%, op_acc: 39.84%] [G loss: 0.883021]\n",
      "epoch:21 step:17160[D loss: 0.433307, acc: 62.50%, op_acc: 36.72%] [G loss: 0.922038]\n",
      "epoch:21 step:17161[D loss: 0.410003, acc: 60.16%, op_acc: 43.75%] [G loss: 0.897717]\n",
      "epoch:21 step:17162[D loss: 0.404765, acc: 55.47%, op_acc: 46.88%] [G loss: 0.883267]\n",
      "epoch:21 step:17163[D loss: 0.454282, acc: 56.25%, op_acc: 34.38%] [G loss: 0.924473]\n",
      "epoch:21 step:17164[D loss: 0.433763, acc: 57.81%, op_acc: 39.06%] [G loss: 0.935946]\n",
      "epoch:21 step:17165[D loss: 0.429616, acc: 50.78%, op_acc: 38.28%] [G loss: 0.918560]\n",
      "epoch:21 step:17166[D loss: 0.416531, acc: 56.25%, op_acc: 39.06%] [G loss: 0.900588]\n",
      "epoch:21 step:17167[D loss: 0.441613, acc: 65.62%, op_acc: 31.25%] [G loss: 0.857811]\n",
      "epoch:21 step:17168[D loss: 0.419558, acc: 58.59%, op_acc: 35.94%] [G loss: 0.913998]\n",
      "epoch:21 step:17169[D loss: 0.432283, acc: 56.25%, op_acc: 35.16%] [G loss: 0.917548]\n",
      "epoch:21 step:17170[D loss: 0.395141, acc: 60.16%, op_acc: 47.66%] [G loss: 0.860079]\n",
      "epoch:21 step:17171[D loss: 0.420428, acc: 58.59%, op_acc: 42.97%] [G loss: 0.901456]\n",
      "epoch:21 step:17172[D loss: 0.450485, acc: 50.78%, op_acc: 33.59%] [G loss: 0.891571]\n",
      "epoch:21 step:17173[D loss: 0.468639, acc: 53.12%, op_acc: 32.03%] [G loss: 0.814515]\n",
      "epoch:21 step:17174[D loss: 0.407589, acc: 64.06%, op_acc: 43.75%] [G loss: 0.828350]\n",
      "epoch:21 step:17175[D loss: 0.393202, acc: 62.50%, op_acc: 43.75%] [G loss: 0.864843]\n",
      "epoch:21 step:17176[D loss: 0.422211, acc: 70.31%, op_acc: 34.38%] [G loss: 0.900279]\n",
      "epoch:21 step:17177[D loss: 0.393742, acc: 62.50%, op_acc: 40.62%] [G loss: 0.944296]\n",
      "epoch:21 step:17178[D loss: 0.464352, acc: 49.22%, op_acc: 38.28%] [G loss: 0.868484]\n",
      "epoch:21 step:17179[D loss: 0.440928, acc: 53.91%, op_acc: 40.62%] [G loss: 0.849462]\n",
      "epoch:21 step:17180[D loss: 0.430223, acc: 56.25%, op_acc: 41.41%] [G loss: 0.951885]\n",
      "epoch:21 step:17181[D loss: 0.419946, acc: 57.81%, op_acc: 39.06%] [G loss: 0.858140]\n",
      "epoch:21 step:17182[D loss: 0.430029, acc: 53.91%, op_acc: 42.19%] [G loss: 0.956767]\n",
      "epoch:22 step:17183[D loss: 0.417206, acc: 65.62%, op_acc: 37.50%] [G loss: 0.899881]\n",
      "epoch:22 step:17184[D loss: 0.420120, acc: 63.28%, op_acc: 44.53%] [G loss: 0.876996]\n",
      "epoch:22 step:17185[D loss: 0.431029, acc: 53.91%, op_acc: 39.84%] [G loss: 0.894020]\n",
      "epoch:22 step:17186[D loss: 0.394185, acc: 60.16%, op_acc: 43.75%] [G loss: 0.920430]\n",
      "epoch:22 step:17187[D loss: 0.423029, acc: 60.16%, op_acc: 43.75%] [G loss: 0.868181]\n",
      "epoch:22 step:17188[D loss: 0.451595, acc: 56.25%, op_acc: 38.28%] [G loss: 0.860069]\n",
      "epoch:22 step:17189[D loss: 0.410714, acc: 64.06%, op_acc: 40.62%] [G loss: 0.852314]\n",
      "epoch:22 step:17190[D loss: 0.411545, acc: 55.47%, op_acc: 42.97%] [G loss: 0.863531]\n",
      "epoch:22 step:17191[D loss: 0.403209, acc: 65.62%, op_acc: 45.31%] [G loss: 0.819741]\n",
      "epoch:22 step:17192[D loss: 0.433657, acc: 58.59%, op_acc: 35.94%] [G loss: 0.910838]\n",
      "epoch:22 step:17193[D loss: 0.449649, acc: 53.12%, op_acc: 40.62%] [G loss: 0.827107]\n",
      "epoch:22 step:17194[D loss: 0.419976, acc: 64.06%, op_acc: 35.16%] [G loss: 0.875457]\n",
      "epoch:22 step:17195[D loss: 0.422012, acc: 60.16%, op_acc: 39.06%] [G loss: 0.919603]\n",
      "epoch:22 step:17196[D loss: 0.410767, acc: 66.41%, op_acc: 35.94%] [G loss: 0.951706]\n",
      "epoch:22 step:17197[D loss: 0.406412, acc: 62.50%, op_acc: 42.97%] [G loss: 0.901400]\n",
      "epoch:22 step:17198[D loss: 0.416338, acc: 61.72%, op_acc: 40.62%] [G loss: 0.833280]\n",
      "epoch:22 step:17199[D loss: 0.410822, acc: 66.41%, op_acc: 42.97%] [G loss: 0.853527]\n",
      "epoch:22 step:17200[D loss: 0.411052, acc: 64.06%, op_acc: 40.62%] [G loss: 0.826640]\n",
      "epoch:22 step:17201[D loss: 0.431651, acc: 55.47%, op_acc: 41.41%] [G loss: 0.846007]\n",
      "epoch:22 step:17202[D loss: 0.408510, acc: 58.59%, op_acc: 44.53%] [G loss: 0.914527]\n",
      "epoch:22 step:17203[D loss: 0.449089, acc: 53.91%, op_acc: 40.62%] [G loss: 0.853032]\n",
      "epoch:22 step:17204[D loss: 0.391574, acc: 65.62%, op_acc: 42.97%] [G loss: 0.858190]\n",
      "epoch:22 step:17205[D loss: 0.426689, acc: 62.50%, op_acc: 39.06%] [G loss: 0.797364]\n",
      "epoch:22 step:17206[D loss: 0.436683, acc: 61.72%, op_acc: 39.84%] [G loss: 0.899964]\n",
      "epoch:22 step:17207[D loss: 0.465670, acc: 53.91%, op_acc: 38.28%] [G loss: 0.805665]\n",
      "epoch:22 step:17208[D loss: 0.413374, acc: 61.72%, op_acc: 41.41%] [G loss: 0.844739]\n",
      "epoch:22 step:17209[D loss: 0.433294, acc: 60.16%, op_acc: 38.28%] [G loss: 0.903540]\n",
      "epoch:22 step:17210[D loss: 0.413787, acc: 59.38%, op_acc: 41.41%] [G loss: 0.909816]\n",
      "epoch:22 step:17211[D loss: 0.399726, acc: 67.19%, op_acc: 42.97%] [G loss: 0.954824]\n",
      "epoch:22 step:17212[D loss: 0.426059, acc: 53.12%, op_acc: 43.75%] [G loss: 0.861024]\n",
      "epoch:22 step:17213[D loss: 0.418720, acc: 67.19%, op_acc: 33.59%] [G loss: 0.824170]\n",
      "epoch:22 step:17214[D loss: 0.466112, acc: 46.88%, op_acc: 41.41%] [G loss: 0.900022]\n",
      "epoch:22 step:17215[D loss: 0.429416, acc: 57.03%, op_acc: 45.31%] [G loss: 0.871573]\n",
      "epoch:22 step:17216[D loss: 0.396636, acc: 66.41%, op_acc: 42.19%] [G loss: 0.930510]\n",
      "epoch:22 step:17217[D loss: 0.456171, acc: 50.78%, op_acc: 37.50%] [G loss: 0.867684]\n",
      "epoch:22 step:17218[D loss: 0.389531, acc: 68.75%, op_acc: 42.19%] [G loss: 0.970467]\n",
      "epoch:22 step:17219[D loss: 0.384207, acc: 73.44%, op_acc: 40.62%] [G loss: 0.937981]\n",
      "epoch:22 step:17220[D loss: 0.434608, acc: 62.50%, op_acc: 38.28%] [G loss: 1.030444]\n",
      "epoch:22 step:17221[D loss: 0.394157, acc: 67.19%, op_acc: 42.97%] [G loss: 0.870196]\n",
      "epoch:22 step:17222[D loss: 0.451293, acc: 58.59%, op_acc: 36.72%] [G loss: 0.898424]\n",
      "epoch:22 step:17223[D loss: 0.412634, acc: 68.75%, op_acc: 41.41%] [G loss: 0.939248]\n",
      "epoch:22 step:17224[D loss: 0.415122, acc: 55.47%, op_acc: 42.97%] [G loss: 0.822577]\n",
      "epoch:22 step:17225[D loss: 0.416102, acc: 58.59%, op_acc: 36.72%] [G loss: 0.816408]\n",
      "epoch:22 step:17226[D loss: 0.415778, acc: 60.94%, op_acc: 38.28%] [G loss: 0.801679]\n",
      "epoch:22 step:17227[D loss: 0.412024, acc: 68.75%, op_acc: 42.97%] [G loss: 0.928388]\n",
      "epoch:22 step:17228[D loss: 0.391064, acc: 67.19%, op_acc: 42.19%] [G loss: 0.928106]\n",
      "epoch:22 step:17229[D loss: 0.427641, acc: 60.16%, op_acc: 37.50%] [G loss: 0.906871]\n",
      "epoch:22 step:17230[D loss: 0.444990, acc: 47.66%, op_acc: 42.19%] [G loss: 0.793417]\n",
      "epoch:22 step:17231[D loss: 0.433972, acc: 56.25%, op_acc: 39.84%] [G loss: 0.872698]\n",
      "epoch:22 step:17232[D loss: 0.459242, acc: 46.88%, op_acc: 42.97%] [G loss: 0.800458]\n",
      "epoch:22 step:17233[D loss: 0.413552, acc: 65.62%, op_acc: 37.50%] [G loss: 0.855670]\n",
      "epoch:22 step:17234[D loss: 0.468657, acc: 51.56%, op_acc: 38.28%] [G loss: 0.867414]\n",
      "epoch:22 step:17235[D loss: 0.461233, acc: 49.22%, op_acc: 38.28%] [G loss: 0.793726]\n",
      "epoch:22 step:17236[D loss: 0.417914, acc: 64.06%, op_acc: 43.75%] [G loss: 0.912299]\n",
      "epoch:22 step:17237[D loss: 0.440192, acc: 57.03%, op_acc: 40.62%] [G loss: 0.924123]\n",
      "epoch:22 step:17238[D loss: 0.442652, acc: 54.69%, op_acc: 33.59%] [G loss: 0.840953]\n",
      "epoch:22 step:17239[D loss: 0.452041, acc: 57.03%, op_acc: 30.47%] [G loss: 0.876064]\n",
      "epoch:22 step:17240[D loss: 0.413713, acc: 57.03%, op_acc: 42.19%] [G loss: 0.917855]\n",
      "epoch:22 step:17241[D loss: 0.418250, acc: 55.47%, op_acc: 44.53%] [G loss: 0.891707]\n",
      "epoch:22 step:17242[D loss: 0.405666, acc: 66.41%, op_acc: 40.62%] [G loss: 0.866369]\n",
      "epoch:22 step:17243[D loss: 0.414727, acc: 64.06%, op_acc: 35.94%] [G loss: 0.932391]\n",
      "epoch:22 step:17244[D loss: 0.425481, acc: 64.06%, op_acc: 40.62%] [G loss: 0.881899]\n",
      "epoch:22 step:17245[D loss: 0.421221, acc: 62.50%, op_acc: 39.84%] [G loss: 0.874765]\n",
      "epoch:22 step:17246[D loss: 0.405615, acc: 60.94%, op_acc: 41.41%] [G loss: 0.869934]\n",
      "epoch:22 step:17247[D loss: 0.418485, acc: 57.81%, op_acc: 39.84%] [G loss: 0.889077]\n",
      "epoch:22 step:17248[D loss: 0.450611, acc: 56.25%, op_acc: 37.50%] [G loss: 0.780621]\n",
      "epoch:22 step:17249[D loss: 0.393751, acc: 71.88%, op_acc: 43.75%] [G loss: 0.868383]\n",
      "epoch:22 step:17250[D loss: 0.428441, acc: 62.50%, op_acc: 38.28%] [G loss: 0.868091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17251[D loss: 0.383602, acc: 69.53%, op_acc: 46.88%] [G loss: 0.931148]\n",
      "epoch:22 step:17252[D loss: 0.456024, acc: 50.00%, op_acc: 36.72%] [G loss: 0.785466]\n",
      "epoch:22 step:17253[D loss: 0.491250, acc: 47.66%, op_acc: 34.38%] [G loss: 0.868645]\n",
      "epoch:22 step:17254[D loss: 0.410289, acc: 61.72%, op_acc: 40.62%] [G loss: 0.865764]\n",
      "epoch:22 step:17255[D loss: 0.449499, acc: 54.69%, op_acc: 42.19%] [G loss: 0.842233]\n",
      "epoch:22 step:17256[D loss: 0.406921, acc: 65.62%, op_acc: 46.09%] [G loss: 0.932929]\n",
      "epoch:22 step:17257[D loss: 0.435780, acc: 52.34%, op_acc: 36.72%] [G loss: 0.828398]\n",
      "epoch:22 step:17258[D loss: 0.430621, acc: 63.28%, op_acc: 39.06%] [G loss: 0.801016]\n",
      "epoch:22 step:17259[D loss: 0.444081, acc: 60.94%, op_acc: 39.06%] [G loss: 0.862087]\n",
      "epoch:22 step:17260[D loss: 0.435048, acc: 65.62%, op_acc: 32.81%] [G loss: 0.904832]\n",
      "epoch:22 step:17261[D loss: 0.445302, acc: 59.38%, op_acc: 36.72%] [G loss: 0.827845]\n",
      "epoch:22 step:17262[D loss: 0.432363, acc: 61.72%, op_acc: 33.59%] [G loss: 0.888928]\n",
      "epoch:22 step:17263[D loss: 0.426737, acc: 61.72%, op_acc: 36.72%] [G loss: 0.915464]\n",
      "epoch:22 step:17264[D loss: 0.417424, acc: 60.16%, op_acc: 42.19%] [G loss: 0.937476]\n",
      "epoch:22 step:17265[D loss: 0.434368, acc: 64.06%, op_acc: 29.69%] [G loss: 0.905597]\n",
      "epoch:22 step:17266[D loss: 0.425977, acc: 62.50%, op_acc: 35.94%] [G loss: 0.888731]\n",
      "epoch:22 step:17267[D loss: 0.417468, acc: 70.31%, op_acc: 37.50%] [G loss: 0.837508]\n",
      "epoch:22 step:17268[D loss: 0.431530, acc: 57.81%, op_acc: 37.50%] [G loss: 0.920714]\n",
      "epoch:22 step:17269[D loss: 0.447176, acc: 50.00%, op_acc: 34.38%] [G loss: 0.875724]\n",
      "epoch:22 step:17270[D loss: 0.435465, acc: 57.81%, op_acc: 36.72%] [G loss: 0.790605]\n",
      "epoch:22 step:17271[D loss: 0.433731, acc: 52.34%, op_acc: 38.28%] [G loss: 0.863273]\n",
      "epoch:22 step:17272[D loss: 0.447259, acc: 49.22%, op_acc: 39.84%] [G loss: 0.859711]\n",
      "epoch:22 step:17273[D loss: 0.465130, acc: 51.56%, op_acc: 35.16%] [G loss: 0.896138]\n",
      "epoch:22 step:17274[D loss: 0.469367, acc: 53.12%, op_acc: 32.81%] [G loss: 0.956964]\n",
      "epoch:22 step:17275[D loss: 0.444874, acc: 47.66%, op_acc: 40.62%] [G loss: 0.906900]\n",
      "epoch:22 step:17276[D loss: 0.420181, acc: 56.25%, op_acc: 42.19%] [G loss: 0.869621]\n",
      "epoch:22 step:17277[D loss: 0.425034, acc: 57.81%, op_acc: 40.62%] [G loss: 0.904657]\n",
      "epoch:22 step:17278[D loss: 0.441307, acc: 57.03%, op_acc: 32.81%] [G loss: 0.852222]\n",
      "epoch:22 step:17279[D loss: 0.414658, acc: 60.16%, op_acc: 37.50%] [G loss: 0.871433]\n",
      "epoch:22 step:17280[D loss: 0.421193, acc: 59.38%, op_acc: 35.16%] [G loss: 0.903867]\n",
      "epoch:22 step:17281[D loss: 0.448971, acc: 53.12%, op_acc: 42.97%] [G loss: 0.935147]\n",
      "epoch:22 step:17282[D loss: 0.385614, acc: 68.75%, op_acc: 46.09%] [G loss: 0.876418]\n",
      "epoch:22 step:17283[D loss: 0.441846, acc: 48.44%, op_acc: 39.06%] [G loss: 0.874824]\n",
      "epoch:22 step:17284[D loss: 0.414631, acc: 70.31%, op_acc: 38.28%] [G loss: 0.930284]\n",
      "epoch:22 step:17285[D loss: 0.441846, acc: 46.09%, op_acc: 44.53%] [G loss: 0.945209]\n",
      "epoch:22 step:17286[D loss: 0.419717, acc: 60.94%, op_acc: 40.62%] [G loss: 0.868280]\n",
      "epoch:22 step:17287[D loss: 0.441462, acc: 52.34%, op_acc: 40.62%] [G loss: 0.832094]\n",
      "epoch:22 step:17288[D loss: 0.425794, acc: 54.69%, op_acc: 38.28%] [G loss: 0.920469]\n",
      "epoch:22 step:17289[D loss: 0.393602, acc: 64.06%, op_acc: 43.75%] [G loss: 0.926063]\n",
      "epoch:22 step:17290[D loss: 0.455604, acc: 59.38%, op_acc: 35.94%] [G loss: 0.943285]\n",
      "epoch:22 step:17291[D loss: 0.419177, acc: 53.91%, op_acc: 44.53%] [G loss: 0.886747]\n",
      "epoch:22 step:17292[D loss: 0.422924, acc: 57.03%, op_acc: 42.97%] [G loss: 0.875489]\n",
      "epoch:22 step:17293[D loss: 0.452394, acc: 51.56%, op_acc: 32.81%] [G loss: 0.809069]\n",
      "epoch:22 step:17294[D loss: 0.430031, acc: 59.38%, op_acc: 39.06%] [G loss: 0.808826]\n",
      "epoch:22 step:17295[D loss: 0.442674, acc: 54.69%, op_acc: 35.16%] [G loss: 0.911265]\n",
      "epoch:22 step:17296[D loss: 0.434577, acc: 50.78%, op_acc: 44.53%] [G loss: 0.863310]\n",
      "epoch:22 step:17297[D loss: 0.419383, acc: 54.69%, op_acc: 43.75%] [G loss: 0.879531]\n",
      "epoch:22 step:17298[D loss: 0.426108, acc: 60.94%, op_acc: 42.19%] [G loss: 0.978911]\n",
      "epoch:22 step:17299[D loss: 0.416024, acc: 63.28%, op_acc: 41.41%] [G loss: 0.914745]\n",
      "epoch:22 step:17300[D loss: 0.429334, acc: 59.38%, op_acc: 39.06%] [G loss: 0.901005]\n",
      "epoch:22 step:17301[D loss: 0.433624, acc: 57.81%, op_acc: 33.59%] [G loss: 0.916271]\n",
      "epoch:22 step:17302[D loss: 0.411413, acc: 65.62%, op_acc: 35.16%] [G loss: 0.831897]\n",
      "epoch:22 step:17303[D loss: 0.423893, acc: 59.38%, op_acc: 40.62%] [G loss: 0.861598]\n",
      "epoch:22 step:17304[D loss: 0.434755, acc: 56.25%, op_acc: 39.84%] [G loss: 0.822737]\n",
      "epoch:22 step:17305[D loss: 0.431028, acc: 60.16%, op_acc: 40.62%] [G loss: 0.880108]\n",
      "epoch:22 step:17306[D loss: 0.423128, acc: 55.47%, op_acc: 46.88%] [G loss: 0.949018]\n",
      "epoch:22 step:17307[D loss: 0.464027, acc: 59.38%, op_acc: 31.25%] [G loss: 0.859396]\n",
      "epoch:22 step:17308[D loss: 0.402721, acc: 64.84%, op_acc: 40.62%] [G loss: 0.796676]\n",
      "epoch:22 step:17309[D loss: 0.432529, acc: 57.03%, op_acc: 40.62%] [G loss: 0.928575]\n",
      "epoch:22 step:17310[D loss: 0.421076, acc: 60.16%, op_acc: 34.38%] [G loss: 0.905578]\n",
      "epoch:22 step:17311[D loss: 0.431965, acc: 59.38%, op_acc: 39.06%] [G loss: 0.857608]\n",
      "epoch:22 step:17312[D loss: 0.407559, acc: 60.94%, op_acc: 42.97%] [G loss: 0.844874]\n",
      "epoch:22 step:17313[D loss: 0.399611, acc: 67.19%, op_acc: 36.72%] [G loss: 0.868529]\n",
      "epoch:22 step:17314[D loss: 0.387997, acc: 64.06%, op_acc: 43.75%] [G loss: 0.924414]\n",
      "epoch:22 step:17315[D loss: 0.462092, acc: 53.12%, op_acc: 35.94%] [G loss: 0.827061]\n",
      "epoch:22 step:17316[D loss: 0.427679, acc: 58.59%, op_acc: 42.97%] [G loss: 0.829884]\n",
      "epoch:22 step:17317[D loss: 0.428234, acc: 57.03%, op_acc: 39.84%] [G loss: 0.878090]\n",
      "epoch:22 step:17318[D loss: 0.396978, acc: 64.84%, op_acc: 43.75%] [G loss: 0.835622]\n",
      "epoch:22 step:17319[D loss: 0.445290, acc: 55.47%, op_acc: 35.94%] [G loss: 0.803493]\n",
      "epoch:22 step:17320[D loss: 0.420652, acc: 54.69%, op_acc: 37.50%] [G loss: 0.807768]\n",
      "epoch:22 step:17321[D loss: 0.432059, acc: 49.22%, op_acc: 39.84%] [G loss: 0.876335]\n",
      "epoch:22 step:17322[D loss: 0.462239, acc: 48.44%, op_acc: 38.28%] [G loss: 0.785040]\n",
      "epoch:22 step:17323[D loss: 0.444628, acc: 57.81%, op_acc: 32.03%] [G loss: 0.803492]\n",
      "epoch:22 step:17324[D loss: 0.437223, acc: 61.72%, op_acc: 32.81%] [G loss: 0.847729]\n",
      "epoch:22 step:17325[D loss: 0.422938, acc: 60.94%, op_acc: 38.28%] [G loss: 0.943052]\n",
      "epoch:22 step:17326[D loss: 0.438463, acc: 59.38%, op_acc: 37.50%] [G loss: 0.841305]\n",
      "epoch:22 step:17327[D loss: 0.439233, acc: 58.59%, op_acc: 35.16%] [G loss: 0.814381]\n",
      "epoch:22 step:17328[D loss: 0.414716, acc: 60.94%, op_acc: 35.16%] [G loss: 0.823136]\n",
      "epoch:22 step:17329[D loss: 0.415879, acc: 59.38%, op_acc: 41.41%] [G loss: 0.894442]\n",
      "epoch:22 step:17330[D loss: 0.435231, acc: 57.03%, op_acc: 37.50%] [G loss: 0.853958]\n",
      "epoch:22 step:17331[D loss: 0.425079, acc: 53.12%, op_acc: 40.62%] [G loss: 0.948432]\n",
      "epoch:22 step:17332[D loss: 0.418710, acc: 59.38%, op_acc: 39.84%] [G loss: 0.944955]\n",
      "epoch:22 step:17333[D loss: 0.407753, acc: 60.16%, op_acc: 39.84%] [G loss: 0.869953]\n",
      "epoch:22 step:17334[D loss: 0.415105, acc: 60.16%, op_acc: 39.06%] [G loss: 0.943162]\n",
      "epoch:22 step:17335[D loss: 0.422778, acc: 57.81%, op_acc: 37.50%] [G loss: 0.939721]\n",
      "epoch:22 step:17336[D loss: 0.392764, acc: 72.66%, op_acc: 39.84%] [G loss: 0.929296]\n",
      "epoch:22 step:17337[D loss: 0.432986, acc: 55.47%, op_acc: 35.94%] [G loss: 0.855195]\n",
      "epoch:22 step:17338[D loss: 0.406422, acc: 65.62%, op_acc: 42.19%] [G loss: 0.886657]\n",
      "epoch:22 step:17339[D loss: 0.421914, acc: 57.81%, op_acc: 39.84%] [G loss: 0.867951]\n",
      "epoch:22 step:17340[D loss: 0.425486, acc: 53.91%, op_acc: 36.72%] [G loss: 0.869465]\n",
      "epoch:22 step:17341[D loss: 0.427692, acc: 57.03%, op_acc: 36.72%] [G loss: 0.819825]\n",
      "epoch:22 step:17342[D loss: 0.426209, acc: 60.94%, op_acc: 32.03%] [G loss: 0.883370]\n",
      "epoch:22 step:17343[D loss: 0.455343, acc: 57.03%, op_acc: 37.50%] [G loss: 0.920240]\n",
      "epoch:22 step:17344[D loss: 0.402198, acc: 60.16%, op_acc: 42.97%] [G loss: 0.838757]\n",
      "epoch:22 step:17345[D loss: 0.435126, acc: 54.69%, op_acc: 35.94%] [G loss: 0.889841]\n",
      "epoch:22 step:17346[D loss: 0.444273, acc: 67.19%, op_acc: 31.25%] [G loss: 0.810436]\n",
      "epoch:22 step:17347[D loss: 0.435504, acc: 54.69%, op_acc: 39.84%] [G loss: 0.880896]\n",
      "epoch:22 step:17348[D loss: 0.424180, acc: 57.81%, op_acc: 42.97%] [G loss: 0.907752]\n",
      "epoch:22 step:17349[D loss: 0.400373, acc: 64.84%, op_acc: 38.28%] [G loss: 0.949755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17350[D loss: 0.408417, acc: 65.62%, op_acc: 43.75%] [G loss: 0.914217]\n",
      "epoch:22 step:17351[D loss: 0.442248, acc: 57.03%, op_acc: 35.94%] [G loss: 0.882030]\n",
      "epoch:22 step:17352[D loss: 0.415044, acc: 71.88%, op_acc: 38.28%] [G loss: 0.885132]\n",
      "epoch:22 step:17353[D loss: 0.429328, acc: 57.03%, op_acc: 33.59%] [G loss: 0.885329]\n",
      "epoch:22 step:17354[D loss: 0.410731, acc: 53.12%, op_acc: 42.97%] [G loss: 0.855343]\n",
      "epoch:22 step:17355[D loss: 0.423985, acc: 57.03%, op_acc: 34.38%] [G loss: 0.847634]\n",
      "epoch:22 step:17356[D loss: 0.458921, acc: 51.56%, op_acc: 35.16%] [G loss: 0.886956]\n",
      "epoch:22 step:17357[D loss: 0.438279, acc: 52.34%, op_acc: 35.16%] [G loss: 0.803150]\n",
      "epoch:22 step:17358[D loss: 0.420835, acc: 64.06%, op_acc: 39.06%] [G loss: 0.919467]\n",
      "epoch:22 step:17359[D loss: 0.417128, acc: 57.81%, op_acc: 43.75%] [G loss: 0.873285]\n",
      "epoch:22 step:17360[D loss: 0.438725, acc: 56.25%, op_acc: 35.94%] [G loss: 0.869810]\n",
      "epoch:22 step:17361[D loss: 0.412375, acc: 64.84%, op_acc: 40.62%] [G loss: 0.915975]\n",
      "epoch:22 step:17362[D loss: 0.408980, acc: 60.94%, op_acc: 39.84%] [G loss: 0.911718]\n",
      "epoch:22 step:17363[D loss: 0.401892, acc: 61.72%, op_acc: 40.62%] [G loss: 0.861588]\n",
      "epoch:22 step:17364[D loss: 0.429514, acc: 60.94%, op_acc: 36.72%] [G loss: 0.853794]\n",
      "epoch:22 step:17365[D loss: 0.432498, acc: 60.16%, op_acc: 38.28%] [G loss: 0.907996]\n",
      "epoch:22 step:17366[D loss: 0.411256, acc: 59.38%, op_acc: 40.62%] [G loss: 0.920240]\n",
      "epoch:22 step:17367[D loss: 0.432039, acc: 57.81%, op_acc: 39.06%] [G loss: 0.880345]\n",
      "epoch:22 step:17368[D loss: 0.446673, acc: 53.12%, op_acc: 37.50%] [G loss: 0.863128]\n",
      "epoch:22 step:17369[D loss: 0.425925, acc: 57.81%, op_acc: 35.16%] [G loss: 0.865849]\n",
      "epoch:22 step:17370[D loss: 0.447088, acc: 52.34%, op_acc: 35.16%] [G loss: 0.825832]\n",
      "epoch:22 step:17371[D loss: 0.433645, acc: 52.34%, op_acc: 39.84%] [G loss: 0.924466]\n",
      "epoch:22 step:17372[D loss: 0.442121, acc: 56.25%, op_acc: 33.59%] [G loss: 0.874704]\n",
      "epoch:22 step:17373[D loss: 0.408593, acc: 60.16%, op_acc: 39.06%] [G loss: 0.832360]\n",
      "epoch:22 step:17374[D loss: 0.411355, acc: 64.06%, op_acc: 37.50%] [G loss: 0.771997]\n",
      "epoch:22 step:17375[D loss: 0.428622, acc: 56.25%, op_acc: 35.16%] [G loss: 0.919846]\n",
      "epoch:22 step:17376[D loss: 0.426253, acc: 56.25%, op_acc: 39.84%] [G loss: 0.941008]\n",
      "epoch:22 step:17377[D loss: 0.460472, acc: 50.78%, op_acc: 37.50%] [G loss: 0.816798]\n",
      "epoch:22 step:17378[D loss: 0.437095, acc: 53.91%, op_acc: 35.94%] [G loss: 0.780809]\n",
      "epoch:22 step:17379[D loss: 0.495380, acc: 45.31%, op_acc: 33.59%] [G loss: 0.832905]\n",
      "epoch:22 step:17380[D loss: 0.433773, acc: 61.72%, op_acc: 40.62%] [G loss: 0.922251]\n",
      "epoch:22 step:17381[D loss: 0.423431, acc: 64.84%, op_acc: 39.06%] [G loss: 0.886090]\n",
      "epoch:22 step:17382[D loss: 0.445139, acc: 59.38%, op_acc: 35.94%] [G loss: 0.922338]\n",
      "epoch:22 step:17383[D loss: 0.410558, acc: 59.38%, op_acc: 40.62%] [G loss: 0.920942]\n",
      "epoch:22 step:17384[D loss: 0.407670, acc: 64.84%, op_acc: 35.16%] [G loss: 0.861902]\n",
      "epoch:22 step:17385[D loss: 0.446841, acc: 57.81%, op_acc: 39.06%] [G loss: 0.929377]\n",
      "epoch:22 step:17386[D loss: 0.414083, acc: 60.94%, op_acc: 41.41%] [G loss: 0.862122]\n",
      "epoch:22 step:17387[D loss: 0.417397, acc: 62.50%, op_acc: 42.19%] [G loss: 0.802631]\n",
      "epoch:22 step:17388[D loss: 0.440225, acc: 53.12%, op_acc: 38.28%] [G loss: 0.845591]\n",
      "epoch:22 step:17389[D loss: 0.408836, acc: 59.38%, op_acc: 46.09%] [G loss: 0.851613]\n",
      "epoch:22 step:17390[D loss: 0.423861, acc: 64.06%, op_acc: 36.72%] [G loss: 0.803428]\n",
      "epoch:22 step:17391[D loss: 0.415055, acc: 61.72%, op_acc: 37.50%] [G loss: 0.846959]\n",
      "epoch:22 step:17392[D loss: 0.424298, acc: 63.28%, op_acc: 36.72%] [G loss: 0.890519]\n",
      "epoch:22 step:17393[D loss: 0.396766, acc: 64.06%, op_acc: 43.75%] [G loss: 0.938272]\n",
      "epoch:22 step:17394[D loss: 0.408433, acc: 60.94%, op_acc: 47.66%] [G loss: 0.869683]\n",
      "epoch:22 step:17395[D loss: 0.415269, acc: 60.94%, op_acc: 42.19%] [G loss: 0.888159]\n",
      "epoch:22 step:17396[D loss: 0.427861, acc: 58.59%, op_acc: 39.06%] [G loss: 0.903793]\n",
      "epoch:22 step:17397[D loss: 0.438236, acc: 56.25%, op_acc: 37.50%] [G loss: 0.813905]\n",
      "epoch:22 step:17398[D loss: 0.455104, acc: 50.00%, op_acc: 28.91%] [G loss: 0.808811]\n",
      "epoch:22 step:17399[D loss: 0.402124, acc: 70.31%, op_acc: 39.84%] [G loss: 0.884274]\n",
      "epoch:22 step:17400[D loss: 0.427357, acc: 60.94%, op_acc: 39.06%] [G loss: 0.884544]\n",
      "epoch:22 step:17401[D loss: 0.432158, acc: 62.50%, op_acc: 31.25%] [G loss: 0.811962]\n",
      "epoch:22 step:17402[D loss: 0.448906, acc: 53.12%, op_acc: 35.16%] [G loss: 0.833636]\n",
      "epoch:22 step:17403[D loss: 0.428706, acc: 63.28%, op_acc: 38.28%] [G loss: 0.841705]\n",
      "epoch:22 step:17404[D loss: 0.426172, acc: 59.38%, op_acc: 35.94%] [G loss: 0.928056]\n",
      "epoch:22 step:17405[D loss: 0.432987, acc: 60.94%, op_acc: 41.41%] [G loss: 0.967144]\n",
      "epoch:22 step:17406[D loss: 0.426606, acc: 56.25%, op_acc: 42.19%] [G loss: 0.797909]\n",
      "epoch:22 step:17407[D loss: 0.415421, acc: 64.84%, op_acc: 40.62%] [G loss: 0.843980]\n",
      "epoch:22 step:17408[D loss: 0.429900, acc: 61.72%, op_acc: 40.62%] [G loss: 0.845549]\n",
      "epoch:22 step:17409[D loss: 0.436660, acc: 57.03%, op_acc: 39.84%] [G loss: 0.826879]\n",
      "epoch:22 step:17410[D loss: 0.414315, acc: 64.84%, op_acc: 39.06%] [G loss: 0.882473]\n",
      "epoch:22 step:17411[D loss: 0.421020, acc: 62.50%, op_acc: 40.62%] [G loss: 0.871301]\n",
      "epoch:22 step:17412[D loss: 0.419693, acc: 63.28%, op_acc: 39.06%] [G loss: 0.848471]\n",
      "epoch:22 step:17413[D loss: 0.422567, acc: 53.12%, op_acc: 41.41%] [G loss: 0.925095]\n",
      "epoch:22 step:17414[D loss: 0.425918, acc: 56.25%, op_acc: 36.72%] [G loss: 0.923026]\n",
      "epoch:22 step:17415[D loss: 0.391039, acc: 67.97%, op_acc: 38.28%] [G loss: 0.960571]\n",
      "epoch:22 step:17416[D loss: 0.436793, acc: 60.94%, op_acc: 34.38%] [G loss: 0.940072]\n",
      "epoch:22 step:17417[D loss: 0.399800, acc: 65.62%, op_acc: 38.28%] [G loss: 0.917862]\n",
      "epoch:22 step:17418[D loss: 0.420859, acc: 60.16%, op_acc: 39.06%] [G loss: 0.930336]\n",
      "epoch:22 step:17419[D loss: 0.409472, acc: 60.94%, op_acc: 42.19%] [G loss: 0.910996]\n",
      "epoch:22 step:17420[D loss: 0.419559, acc: 64.84%, op_acc: 39.06%] [G loss: 0.821079]\n",
      "epoch:22 step:17421[D loss: 0.425449, acc: 61.72%, op_acc: 34.38%] [G loss: 0.878978]\n",
      "epoch:22 step:17422[D loss: 0.425254, acc: 50.00%, op_acc: 38.28%] [G loss: 0.846219]\n",
      "epoch:22 step:17423[D loss: 0.414138, acc: 61.72%, op_acc: 40.62%] [G loss: 0.881210]\n",
      "epoch:22 step:17424[D loss: 0.386286, acc: 66.41%, op_acc: 45.31%] [G loss: 0.883358]\n",
      "epoch:22 step:17425[D loss: 0.412808, acc: 58.59%, op_acc: 46.09%] [G loss: 0.891472]\n",
      "epoch:22 step:17426[D loss: 0.454337, acc: 53.91%, op_acc: 31.25%] [G loss: 0.884142]\n",
      "epoch:22 step:17427[D loss: 0.461616, acc: 51.56%, op_acc: 43.75%] [G loss: 0.868626]\n",
      "epoch:22 step:17428[D loss: 0.452573, acc: 59.38%, op_acc: 32.03%] [G loss: 0.921528]\n",
      "epoch:22 step:17429[D loss: 0.399394, acc: 64.06%, op_acc: 45.31%] [G loss: 0.825532]\n",
      "epoch:22 step:17430[D loss: 0.435335, acc: 55.47%, op_acc: 34.38%] [G loss: 0.967213]\n",
      "epoch:22 step:17431[D loss: 0.458127, acc: 52.34%, op_acc: 36.72%] [G loss: 0.856337]\n",
      "epoch:22 step:17432[D loss: 0.462122, acc: 56.25%, op_acc: 36.72%] [G loss: 0.891154]\n",
      "epoch:22 step:17433[D loss: 0.396210, acc: 69.53%, op_acc: 48.44%] [G loss: 0.908168]\n",
      "epoch:22 step:17434[D loss: 0.416520, acc: 58.59%, op_acc: 42.97%] [G loss: 0.826810]\n",
      "epoch:22 step:17435[D loss: 0.455756, acc: 56.25%, op_acc: 38.28%] [G loss: 0.871904]\n",
      "epoch:22 step:17436[D loss: 0.416912, acc: 59.38%, op_acc: 38.28%] [G loss: 0.953604]\n",
      "epoch:22 step:17437[D loss: 0.419615, acc: 54.69%, op_acc: 41.41%] [G loss: 0.840001]\n",
      "epoch:22 step:17438[D loss: 0.431873, acc: 56.25%, op_acc: 42.97%] [G loss: 0.873188]\n",
      "epoch:22 step:17439[D loss: 0.416964, acc: 67.19%, op_acc: 41.41%] [G loss: 0.810796]\n",
      "epoch:22 step:17440[D loss: 0.421531, acc: 60.16%, op_acc: 42.97%] [G loss: 0.894996]\n",
      "epoch:22 step:17441[D loss: 0.418433, acc: 63.28%, op_acc: 35.94%] [G loss: 0.891124]\n",
      "epoch:22 step:17442[D loss: 0.457166, acc: 59.38%, op_acc: 32.81%] [G loss: 0.954897]\n",
      "epoch:22 step:17443[D loss: 0.394330, acc: 63.28%, op_acc: 39.84%] [G loss: 0.832581]\n",
      "epoch:22 step:17444[D loss: 0.406183, acc: 69.53%, op_acc: 35.16%] [G loss: 0.940952]\n",
      "epoch:22 step:17445[D loss: 0.426844, acc: 57.03%, op_acc: 36.72%] [G loss: 0.854632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17446[D loss: 0.381829, acc: 69.53%, op_acc: 44.53%] [G loss: 0.896140]\n",
      "epoch:22 step:17447[D loss: 0.419751, acc: 57.03%, op_acc: 40.62%] [G loss: 0.846347]\n",
      "epoch:22 step:17448[D loss: 0.391134, acc: 71.09%, op_acc: 40.62%] [G loss: 0.939018]\n",
      "epoch:22 step:17449[D loss: 0.439645, acc: 50.78%, op_acc: 39.84%] [G loss: 0.814420]\n",
      "epoch:22 step:17450[D loss: 0.395618, acc: 70.31%, op_acc: 44.53%] [G loss: 0.907236]\n",
      "epoch:22 step:17451[D loss: 0.398437, acc: 65.62%, op_acc: 41.41%] [G loss: 0.879263]\n",
      "epoch:22 step:17452[D loss: 0.454608, acc: 53.91%, op_acc: 34.38%] [G loss: 0.858007]\n",
      "epoch:22 step:17453[D loss: 0.443323, acc: 50.78%, op_acc: 41.41%] [G loss: 0.935794]\n",
      "epoch:22 step:17454[D loss: 0.419085, acc: 56.25%, op_acc: 38.28%] [G loss: 0.950432]\n",
      "epoch:22 step:17455[D loss: 0.410882, acc: 59.38%, op_acc: 43.75%] [G loss: 0.997634]\n",
      "epoch:22 step:17456[D loss: 0.443035, acc: 54.69%, op_acc: 37.50%] [G loss: 0.935331]\n",
      "epoch:22 step:17457[D loss: 0.389107, acc: 64.06%, op_acc: 38.28%] [G loss: 0.952157]\n",
      "epoch:22 step:17458[D loss: 0.444453, acc: 61.72%, op_acc: 38.28%] [G loss: 0.862128]\n",
      "epoch:22 step:17459[D loss: 0.423387, acc: 64.84%, op_acc: 35.16%] [G loss: 0.853085]\n",
      "epoch:22 step:17460[D loss: 0.433503, acc: 58.59%, op_acc: 36.72%] [G loss: 0.786216]\n",
      "epoch:22 step:17461[D loss: 0.434233, acc: 54.69%, op_acc: 35.94%] [G loss: 0.831454]\n",
      "epoch:22 step:17462[D loss: 0.423204, acc: 54.69%, op_acc: 41.41%] [G loss: 0.809644]\n",
      "epoch:22 step:17463[D loss: 0.431646, acc: 57.81%, op_acc: 36.72%] [G loss: 0.899200]\n",
      "epoch:22 step:17464[D loss: 0.406344, acc: 62.50%, op_acc: 45.31%] [G loss: 0.907136]\n",
      "epoch:22 step:17465[D loss: 0.415616, acc: 60.16%, op_acc: 41.41%] [G loss: 0.884230]\n",
      "epoch:22 step:17466[D loss: 0.438477, acc: 57.03%, op_acc: 39.84%] [G loss: 0.979818]\n",
      "epoch:22 step:17467[D loss: 0.445018, acc: 59.38%, op_acc: 35.94%] [G loss: 0.864380]\n",
      "epoch:22 step:17468[D loss: 0.432589, acc: 58.59%, op_acc: 39.06%] [G loss: 0.916003]\n",
      "epoch:22 step:17469[D loss: 0.442577, acc: 57.03%, op_acc: 41.41%] [G loss: 0.819474]\n",
      "epoch:22 step:17470[D loss: 0.447005, acc: 51.56%, op_acc: 39.06%] [G loss: 0.894283]\n",
      "epoch:22 step:17471[D loss: 0.438408, acc: 57.03%, op_acc: 39.84%] [G loss: 0.850535]\n",
      "epoch:22 step:17472[D loss: 0.420205, acc: 60.94%, op_acc: 42.97%] [G loss: 0.900642]\n",
      "epoch:22 step:17473[D loss: 0.444955, acc: 53.12%, op_acc: 40.62%] [G loss: 0.934096]\n",
      "epoch:22 step:17474[D loss: 0.462750, acc: 53.91%, op_acc: 31.25%] [G loss: 0.904112]\n",
      "epoch:22 step:17475[D loss: 0.424902, acc: 55.47%, op_acc: 43.75%] [G loss: 0.926053]\n",
      "epoch:22 step:17476[D loss: 0.412282, acc: 64.06%, op_acc: 39.84%] [G loss: 0.941898]\n",
      "epoch:22 step:17477[D loss: 0.411061, acc: 59.38%, op_acc: 41.41%] [G loss: 0.849831]\n",
      "epoch:22 step:17478[D loss: 0.449051, acc: 49.22%, op_acc: 39.84%] [G loss: 0.888839]\n",
      "epoch:22 step:17479[D loss: 0.412072, acc: 62.50%, op_acc: 41.41%] [G loss: 0.956083]\n",
      "epoch:22 step:17480[D loss: 0.404682, acc: 64.06%, op_acc: 39.06%] [G loss: 0.901110]\n",
      "epoch:22 step:17481[D loss: 0.411420, acc: 64.84%, op_acc: 41.41%] [G loss: 0.883609]\n",
      "epoch:22 step:17482[D loss: 0.416599, acc: 58.59%, op_acc: 39.84%] [G loss: 0.858504]\n",
      "epoch:22 step:17483[D loss: 0.429856, acc: 57.03%, op_acc: 39.06%] [G loss: 0.883618]\n",
      "epoch:22 step:17484[D loss: 0.410109, acc: 64.06%, op_acc: 39.06%] [G loss: 0.851218]\n",
      "epoch:22 step:17485[D loss: 0.440717, acc: 49.22%, op_acc: 37.50%] [G loss: 0.886989]\n",
      "epoch:22 step:17486[D loss: 0.403400, acc: 60.94%, op_acc: 40.62%] [G loss: 0.908988]\n",
      "epoch:22 step:17487[D loss: 0.424142, acc: 56.25%, op_acc: 39.06%] [G loss: 0.894265]\n",
      "epoch:22 step:17488[D loss: 0.407229, acc: 67.97%, op_acc: 35.94%] [G loss: 0.827566]\n",
      "epoch:22 step:17489[D loss: 0.396805, acc: 67.97%, op_acc: 40.62%] [G loss: 1.005020]\n",
      "epoch:22 step:17490[D loss: 0.421261, acc: 61.72%, op_acc: 39.06%] [G loss: 0.914295]\n",
      "epoch:22 step:17491[D loss: 0.446854, acc: 64.06%, op_acc: 37.50%] [G loss: 0.918695]\n",
      "epoch:22 step:17492[D loss: 0.422350, acc: 60.94%, op_acc: 35.16%] [G loss: 0.839739]\n",
      "epoch:22 step:17493[D loss: 0.430480, acc: 55.47%, op_acc: 43.75%] [G loss: 0.840288]\n",
      "epoch:22 step:17494[D loss: 0.444115, acc: 56.25%, op_acc: 35.94%] [G loss: 0.837803]\n",
      "epoch:22 step:17495[D loss: 0.437034, acc: 58.59%, op_acc: 37.50%] [G loss: 0.853273]\n",
      "epoch:22 step:17496[D loss: 0.430159, acc: 60.94%, op_acc: 40.62%] [G loss: 0.837017]\n",
      "epoch:22 step:17497[D loss: 0.451162, acc: 52.34%, op_acc: 35.94%] [G loss: 0.788830]\n",
      "epoch:22 step:17498[D loss: 0.428036, acc: 57.03%, op_acc: 37.50%] [G loss: 0.882840]\n",
      "epoch:22 step:17499[D loss: 0.431470, acc: 60.94%, op_acc: 35.16%] [G loss: 0.846397]\n",
      "epoch:22 step:17500[D loss: 0.444446, acc: 54.69%, op_acc: 34.38%] [G loss: 0.777775]\n",
      "epoch:22 step:17501[D loss: 0.404550, acc: 60.16%, op_acc: 39.06%] [G loss: 0.875558]\n",
      "epoch:22 step:17502[D loss: 0.419746, acc: 57.81%, op_acc: 38.28%] [G loss: 0.881789]\n",
      "epoch:22 step:17503[D loss: 0.470420, acc: 49.22%, op_acc: 39.84%] [G loss: 0.836129]\n",
      "epoch:22 step:17504[D loss: 0.408304, acc: 60.94%, op_acc: 39.06%] [G loss: 0.834730]\n",
      "epoch:22 step:17505[D loss: 0.437008, acc: 56.25%, op_acc: 36.72%] [G loss: 0.825417]\n",
      "epoch:22 step:17506[D loss: 0.428587, acc: 61.72%, op_acc: 33.59%] [G loss: 0.933230]\n",
      "epoch:22 step:17507[D loss: 0.440638, acc: 56.25%, op_acc: 38.28%] [G loss: 0.819657]\n",
      "epoch:22 step:17508[D loss: 0.429984, acc: 61.72%, op_acc: 39.06%] [G loss: 0.907681]\n",
      "epoch:22 step:17509[D loss: 0.414351, acc: 65.62%, op_acc: 39.84%] [G loss: 0.837745]\n",
      "epoch:22 step:17510[D loss: 0.422688, acc: 60.16%, op_acc: 38.28%] [G loss: 0.870662]\n",
      "epoch:22 step:17511[D loss: 0.426177, acc: 55.47%, op_acc: 40.62%] [G loss: 0.938118]\n",
      "epoch:22 step:17512[D loss: 0.421381, acc: 60.94%, op_acc: 38.28%] [G loss: 0.909176]\n",
      "epoch:22 step:17513[D loss: 0.409103, acc: 63.28%, op_acc: 45.31%] [G loss: 0.903522]\n",
      "epoch:22 step:17514[D loss: 0.440686, acc: 51.56%, op_acc: 35.94%] [G loss: 0.818207]\n",
      "epoch:22 step:17515[D loss: 0.427893, acc: 60.16%, op_acc: 39.06%] [G loss: 0.913895]\n",
      "epoch:22 step:17516[D loss: 0.409570, acc: 64.84%, op_acc: 37.50%] [G loss: 0.885159]\n",
      "epoch:22 step:17517[D loss: 0.415732, acc: 66.41%, op_acc: 37.50%] [G loss: 0.925121]\n",
      "epoch:22 step:17518[D loss: 0.432312, acc: 55.47%, op_acc: 37.50%] [G loss: 0.916635]\n",
      "epoch:22 step:17519[D loss: 0.440929, acc: 54.69%, op_acc: 36.72%] [G loss: 0.818755]\n",
      "epoch:22 step:17520[D loss: 0.416648, acc: 60.94%, op_acc: 39.06%] [G loss: 0.875850]\n",
      "epoch:22 step:17521[D loss: 0.401563, acc: 59.38%, op_acc: 42.19%] [G loss: 0.862589]\n",
      "epoch:22 step:17522[D loss: 0.423807, acc: 58.59%, op_acc: 43.75%] [G loss: 0.896638]\n",
      "epoch:22 step:17523[D loss: 0.421110, acc: 61.72%, op_acc: 37.50%] [G loss: 0.889369]\n",
      "epoch:22 step:17524[D loss: 0.431035, acc: 60.94%, op_acc: 34.38%] [G loss: 0.883397]\n",
      "epoch:22 step:17525[D loss: 0.416409, acc: 62.50%, op_acc: 38.28%] [G loss: 0.836302]\n",
      "epoch:22 step:17526[D loss: 0.395661, acc: 69.53%, op_acc: 40.62%] [G loss: 0.865903]\n",
      "epoch:22 step:17527[D loss: 0.397258, acc: 63.28%, op_acc: 39.06%] [G loss: 0.871635]\n",
      "epoch:22 step:17528[D loss: 0.433094, acc: 61.72%, op_acc: 35.16%] [G loss: 0.850184]\n",
      "epoch:22 step:17529[D loss: 0.427183, acc: 57.03%, op_acc: 39.84%] [G loss: 0.842203]\n",
      "epoch:22 step:17530[D loss: 0.408641, acc: 60.94%, op_acc: 42.97%] [G loss: 0.885005]\n",
      "epoch:22 step:17531[D loss: 0.404195, acc: 64.06%, op_acc: 42.97%] [G loss: 0.936041]\n",
      "epoch:22 step:17532[D loss: 0.438913, acc: 57.81%, op_acc: 40.62%] [G loss: 0.894784]\n",
      "epoch:22 step:17533[D loss: 0.437638, acc: 54.69%, op_acc: 37.50%] [G loss: 0.928124]\n",
      "epoch:22 step:17534[D loss: 0.396611, acc: 66.41%, op_acc: 32.81%] [G loss: 0.947156]\n",
      "epoch:22 step:17535[D loss: 0.411901, acc: 61.72%, op_acc: 40.62%] [G loss: 0.979019]\n",
      "epoch:22 step:17536[D loss: 0.440545, acc: 59.38%, op_acc: 35.94%] [G loss: 0.912626]\n",
      "epoch:22 step:17537[D loss: 0.426209, acc: 58.59%, op_acc: 43.75%] [G loss: 0.942386]\n",
      "epoch:22 step:17538[D loss: 0.448521, acc: 54.69%, op_acc: 38.28%] [G loss: 0.806544]\n",
      "epoch:22 step:17539[D loss: 0.422327, acc: 64.06%, op_acc: 36.72%] [G loss: 0.833816]\n",
      "epoch:22 step:17540[D loss: 0.435287, acc: 60.94%, op_acc: 39.84%] [G loss: 0.889383]\n",
      "epoch:22 step:17541[D loss: 0.422082, acc: 64.06%, op_acc: 39.06%] [G loss: 0.886600]\n",
      "epoch:22 step:17542[D loss: 0.416312, acc: 61.72%, op_acc: 41.41%] [G loss: 0.910548]\n",
      "epoch:22 step:17543[D loss: 0.438594, acc: 55.47%, op_acc: 42.97%] [G loss: 0.896713]\n",
      "epoch:22 step:17544[D loss: 0.405340, acc: 62.50%, op_acc: 41.41%] [G loss: 0.900081]\n",
      "epoch:22 step:17545[D loss: 0.416514, acc: 64.06%, op_acc: 36.72%] [G loss: 0.962787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17546[D loss: 0.430202, acc: 59.38%, op_acc: 40.62%] [G loss: 0.906859]\n",
      "epoch:22 step:17547[D loss: 0.399976, acc: 65.62%, op_acc: 42.19%] [G loss: 0.915411]\n",
      "epoch:22 step:17548[D loss: 0.413750, acc: 57.81%, op_acc: 42.19%] [G loss: 0.881260]\n",
      "epoch:22 step:17549[D loss: 0.463992, acc: 55.47%, op_acc: 34.38%] [G loss: 0.825612]\n",
      "epoch:22 step:17550[D loss: 0.417998, acc: 56.25%, op_acc: 36.72%] [G loss: 0.866431]\n",
      "epoch:22 step:17551[D loss: 0.425462, acc: 64.84%, op_acc: 39.06%] [G loss: 0.918299]\n",
      "epoch:22 step:17552[D loss: 0.417597, acc: 58.59%, op_acc: 36.72%] [G loss: 0.887065]\n",
      "epoch:22 step:17553[D loss: 0.419937, acc: 57.03%, op_acc: 47.66%] [G loss: 0.807426]\n",
      "epoch:22 step:17554[D loss: 0.432230, acc: 56.25%, op_acc: 36.72%] [G loss: 0.929354]\n",
      "epoch:22 step:17555[D loss: 0.442580, acc: 53.91%, op_acc: 40.62%] [G loss: 0.785798]\n",
      "epoch:22 step:17556[D loss: 0.433468, acc: 55.47%, op_acc: 45.31%] [G loss: 0.920410]\n",
      "epoch:22 step:17557[D loss: 0.423079, acc: 59.38%, op_acc: 39.06%] [G loss: 0.903882]\n",
      "epoch:22 step:17558[D loss: 0.427625, acc: 56.25%, op_acc: 35.94%] [G loss: 0.820443]\n",
      "epoch:22 step:17559[D loss: 0.424476, acc: 58.59%, op_acc: 37.50%] [G loss: 0.888405]\n",
      "epoch:22 step:17560[D loss: 0.408006, acc: 64.06%, op_acc: 43.75%] [G loss: 0.873673]\n",
      "epoch:22 step:17561[D loss: 0.404632, acc: 64.06%, op_acc: 39.84%] [G loss: 0.936452]\n",
      "epoch:22 step:17562[D loss: 0.437053, acc: 55.47%, op_acc: 42.97%] [G loss: 0.888395]\n",
      "epoch:22 step:17563[D loss: 0.429741, acc: 62.50%, op_acc: 36.72%] [G loss: 0.927642]\n",
      "epoch:22 step:17564[D loss: 0.453210, acc: 55.47%, op_acc: 35.16%] [G loss: 0.891100]\n",
      "epoch:22 step:17565[D loss: 0.424273, acc: 55.47%, op_acc: 40.62%] [G loss: 0.871598]\n",
      "epoch:22 step:17566[D loss: 0.431567, acc: 60.94%, op_acc: 38.28%] [G loss: 0.879456]\n",
      "epoch:22 step:17567[D loss: 0.419980, acc: 58.59%, op_acc: 40.62%] [G loss: 0.899820]\n",
      "epoch:22 step:17568[D loss: 0.436355, acc: 51.56%, op_acc: 37.50%] [G loss: 0.872572]\n",
      "epoch:22 step:17569[D loss: 0.431165, acc: 53.12%, op_acc: 41.41%] [G loss: 0.898999]\n",
      "epoch:22 step:17570[D loss: 0.440615, acc: 60.94%, op_acc: 39.84%] [G loss: 0.936788]\n",
      "epoch:22 step:17571[D loss: 0.432574, acc: 57.03%, op_acc: 40.62%] [G loss: 0.841829]\n",
      "epoch:22 step:17572[D loss: 0.417496, acc: 57.81%, op_acc: 39.84%] [G loss: 0.857262]\n",
      "epoch:22 step:17573[D loss: 0.387639, acc: 60.94%, op_acc: 44.53%] [G loss: 0.829919]\n",
      "epoch:22 step:17574[D loss: 0.408935, acc: 60.94%, op_acc: 42.97%] [G loss: 0.830966]\n",
      "epoch:22 step:17575[D loss: 0.415483, acc: 58.59%, op_acc: 42.19%] [G loss: 0.895142]\n",
      "epoch:22 step:17576[D loss: 0.441381, acc: 60.94%, op_acc: 35.16%] [G loss: 0.828227]\n",
      "epoch:22 step:17577[D loss: 0.439572, acc: 54.69%, op_acc: 34.38%] [G loss: 0.843489]\n",
      "epoch:22 step:17578[D loss: 0.401985, acc: 66.41%, op_acc: 43.75%] [G loss: 0.890082]\n",
      "epoch:22 step:17579[D loss: 0.404507, acc: 61.72%, op_acc: 37.50%] [G loss: 0.833834]\n",
      "epoch:22 step:17580[D loss: 0.453581, acc: 57.03%, op_acc: 34.38%] [G loss: 0.896938]\n",
      "epoch:22 step:17581[D loss: 0.433178, acc: 55.47%, op_acc: 39.06%] [G loss: 0.829096]\n",
      "epoch:22 step:17582[D loss: 0.429753, acc: 58.59%, op_acc: 37.50%] [G loss: 0.889931]\n",
      "epoch:22 step:17583[D loss: 0.408743, acc: 60.94%, op_acc: 43.75%] [G loss: 0.892870]\n",
      "epoch:22 step:17584[D loss: 0.439302, acc: 66.41%, op_acc: 35.94%] [G loss: 1.028417]\n",
      "epoch:22 step:17585[D loss: 0.398216, acc: 67.97%, op_acc: 45.31%] [G loss: 0.933187]\n",
      "epoch:22 step:17586[D loss: 0.409223, acc: 67.97%, op_acc: 42.97%] [G loss: 0.901543]\n",
      "epoch:22 step:17587[D loss: 0.425146, acc: 58.59%, op_acc: 41.41%] [G loss: 0.901017]\n",
      "epoch:22 step:17588[D loss: 0.427120, acc: 56.25%, op_acc: 39.06%] [G loss: 0.911587]\n",
      "epoch:22 step:17589[D loss: 0.443631, acc: 57.03%, op_acc: 33.59%] [G loss: 0.981314]\n",
      "epoch:22 step:17590[D loss: 0.435135, acc: 50.00%, op_acc: 41.41%] [G loss: 0.908730]\n",
      "epoch:22 step:17591[D loss: 0.422701, acc: 59.38%, op_acc: 42.97%] [G loss: 0.975842]\n",
      "epoch:22 step:17592[D loss: 0.439291, acc: 50.00%, op_acc: 39.84%] [G loss: 0.847458]\n",
      "epoch:22 step:17593[D loss: 0.441407, acc: 60.16%, op_acc: 35.94%] [G loss: 0.886380]\n",
      "epoch:22 step:17594[D loss: 0.442731, acc: 48.44%, op_acc: 39.06%] [G loss: 0.829740]\n",
      "epoch:22 step:17595[D loss: 0.409670, acc: 64.84%, op_acc: 43.75%] [G loss: 0.881155]\n",
      "epoch:22 step:17596[D loss: 0.397731, acc: 64.06%, op_acc: 43.75%] [G loss: 0.829029]\n",
      "epoch:22 step:17597[D loss: 0.408122, acc: 63.28%, op_acc: 36.72%] [G loss: 0.936278]\n",
      "epoch:22 step:17598[D loss: 0.438946, acc: 61.72%, op_acc: 37.50%] [G loss: 0.930858]\n",
      "epoch:22 step:17599[D loss: 0.426932, acc: 58.59%, op_acc: 35.16%] [G loss: 0.857273]\n",
      "epoch:22 step:17600[D loss: 0.455567, acc: 53.12%, op_acc: 35.16%] [G loss: 0.846385]\n",
      "epoch:22 step:17601[D loss: 0.392759, acc: 67.19%, op_acc: 35.94%] [G loss: 0.826589]\n",
      "epoch:22 step:17602[D loss: 0.434247, acc: 54.69%, op_acc: 38.28%] [G loss: 0.862595]\n",
      "epoch:22 step:17603[D loss: 0.454597, acc: 56.25%, op_acc: 39.84%] [G loss: 0.888692]\n",
      "epoch:22 step:17604[D loss: 0.409072, acc: 60.16%, op_acc: 43.75%] [G loss: 0.966857]\n",
      "epoch:22 step:17605[D loss: 0.449201, acc: 56.25%, op_acc: 35.94%] [G loss: 0.892802]\n",
      "epoch:22 step:17606[D loss: 0.459304, acc: 54.69%, op_acc: 39.06%] [G loss: 0.888701]\n",
      "epoch:22 step:17607[D loss: 0.406518, acc: 61.72%, op_acc: 41.41%] [G loss: 0.828792]\n",
      "epoch:22 step:17608[D loss: 0.450760, acc: 46.09%, op_acc: 41.41%] [G loss: 0.851870]\n",
      "epoch:22 step:17609[D loss: 0.421129, acc: 62.50%, op_acc: 35.16%] [G loss: 0.882963]\n",
      "epoch:22 step:17610[D loss: 0.436409, acc: 54.69%, op_acc: 38.28%] [G loss: 0.888931]\n",
      "epoch:22 step:17611[D loss: 0.425852, acc: 50.78%, op_acc: 39.06%] [G loss: 0.869229]\n",
      "epoch:22 step:17612[D loss: 0.393369, acc: 70.31%, op_acc: 44.53%] [G loss: 0.806353]\n",
      "epoch:22 step:17613[D loss: 0.436691, acc: 59.38%, op_acc: 37.50%] [G loss: 0.865368]\n",
      "epoch:22 step:17614[D loss: 0.397405, acc: 58.59%, op_acc: 46.09%] [G loss: 0.802323]\n",
      "epoch:22 step:17615[D loss: 0.420709, acc: 53.91%, op_acc: 37.50%] [G loss: 0.833829]\n",
      "epoch:22 step:17616[D loss: 0.413626, acc: 63.28%, op_acc: 39.84%] [G loss: 0.954592]\n",
      "epoch:22 step:17617[D loss: 0.429175, acc: 59.38%, op_acc: 39.84%] [G loss: 0.866821]\n",
      "epoch:22 step:17618[D loss: 0.496775, acc: 50.00%, op_acc: 36.72%] [G loss: 0.836562]\n",
      "epoch:22 step:17619[D loss: 0.463504, acc: 46.09%, op_acc: 37.50%] [G loss: 0.856729]\n",
      "epoch:22 step:17620[D loss: 0.420516, acc: 65.62%, op_acc: 42.19%] [G loss: 0.831549]\n",
      "epoch:22 step:17621[D loss: 0.424302, acc: 55.47%, op_acc: 42.19%] [G loss: 0.902592]\n",
      "epoch:22 step:17622[D loss: 0.407693, acc: 64.06%, op_acc: 42.19%] [G loss: 0.927729]\n",
      "epoch:22 step:17623[D loss: 0.413777, acc: 59.38%, op_acc: 35.94%] [G loss: 0.840529]\n",
      "epoch:22 step:17624[D loss: 0.413848, acc: 57.81%, op_acc: 42.19%] [G loss: 0.837300]\n",
      "epoch:22 step:17625[D loss: 0.422025, acc: 56.25%, op_acc: 39.06%] [G loss: 0.882619]\n",
      "epoch:22 step:17626[D loss: 0.411461, acc: 63.28%, op_acc: 41.41%] [G loss: 0.899402]\n",
      "epoch:22 step:17627[D loss: 0.469862, acc: 52.34%, op_acc: 34.38%] [G loss: 0.786426]\n",
      "epoch:22 step:17628[D loss: 0.448734, acc: 57.03%, op_acc: 32.81%] [G loss: 0.857242]\n",
      "epoch:22 step:17629[D loss: 0.438570, acc: 67.97%, op_acc: 35.16%] [G loss: 0.909281]\n",
      "epoch:22 step:17630[D loss: 0.397452, acc: 63.28%, op_acc: 44.53%] [G loss: 0.854126]\n",
      "epoch:22 step:17631[D loss: 0.401437, acc: 63.28%, op_acc: 37.50%] [G loss: 0.930526]\n",
      "epoch:22 step:17632[D loss: 0.413558, acc: 57.03%, op_acc: 40.62%] [G loss: 0.968329]\n",
      "epoch:22 step:17633[D loss: 0.414298, acc: 57.81%, op_acc: 41.41%] [G loss: 0.916908]\n",
      "epoch:22 step:17634[D loss: 0.402043, acc: 59.38%, op_acc: 44.53%] [G loss: 0.911153]\n",
      "epoch:22 step:17635[D loss: 0.407339, acc: 59.38%, op_acc: 39.06%] [G loss: 0.913405]\n",
      "epoch:22 step:17636[D loss: 0.409069, acc: 62.50%, op_acc: 39.06%] [G loss: 0.932071]\n",
      "epoch:22 step:17637[D loss: 0.414206, acc: 59.38%, op_acc: 42.97%] [G loss: 0.876196]\n",
      "epoch:22 step:17638[D loss: 0.426727, acc: 57.81%, op_acc: 42.19%] [G loss: 0.961697]\n",
      "epoch:22 step:17639[D loss: 0.419159, acc: 62.50%, op_acc: 35.94%] [G loss: 0.895666]\n",
      "epoch:22 step:17640[D loss: 0.394500, acc: 65.62%, op_acc: 37.50%] [G loss: 0.937058]\n",
      "epoch:22 step:17641[D loss: 0.419973, acc: 53.91%, op_acc: 41.41%] [G loss: 0.955369]\n",
      "epoch:22 step:17642[D loss: 0.434777, acc: 57.81%, op_acc: 41.41%] [G loss: 0.939645]\n",
      "epoch:22 step:17643[D loss: 0.415659, acc: 59.38%, op_acc: 38.28%] [G loss: 0.901786]\n",
      "epoch:22 step:17644[D loss: 0.442112, acc: 56.25%, op_acc: 37.50%] [G loss: 0.831386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17645[D loss: 0.424967, acc: 64.06%, op_acc: 39.06%] [G loss: 0.899157]\n",
      "epoch:22 step:17646[D loss: 0.434371, acc: 65.62%, op_acc: 39.84%] [G loss: 0.876227]\n",
      "epoch:22 step:17647[D loss: 0.407411, acc: 59.38%, op_acc: 39.06%] [G loss: 0.931024]\n",
      "epoch:22 step:17648[D loss: 0.424979, acc: 51.56%, op_acc: 43.75%] [G loss: 0.961854]\n",
      "epoch:22 step:17649[D loss: 0.431507, acc: 63.28%, op_acc: 37.50%] [G loss: 0.855328]\n",
      "epoch:22 step:17650[D loss: 0.418354, acc: 60.94%, op_acc: 41.41%] [G loss: 0.834362]\n",
      "epoch:22 step:17651[D loss: 0.379306, acc: 74.22%, op_acc: 43.75%] [G loss: 0.946225]\n",
      "epoch:22 step:17652[D loss: 0.407069, acc: 63.28%, op_acc: 42.97%] [G loss: 0.951202]\n",
      "epoch:22 step:17653[D loss: 0.400253, acc: 66.41%, op_acc: 41.41%] [G loss: 0.926935]\n",
      "epoch:22 step:17654[D loss: 0.436344, acc: 58.59%, op_acc: 34.38%] [G loss: 0.886614]\n",
      "epoch:22 step:17655[D loss: 0.391415, acc: 60.94%, op_acc: 50.78%] [G loss: 0.797196]\n",
      "epoch:22 step:17656[D loss: 0.400338, acc: 70.31%, op_acc: 39.84%] [G loss: 0.921466]\n",
      "epoch:22 step:17657[D loss: 0.410530, acc: 55.47%, op_acc: 38.28%] [G loss: 0.854673]\n",
      "epoch:22 step:17658[D loss: 0.423564, acc: 56.25%, op_acc: 36.72%] [G loss: 0.946172]\n",
      "epoch:22 step:17659[D loss: 0.426693, acc: 61.72%, op_acc: 42.97%] [G loss: 0.863608]\n",
      "epoch:22 step:17660[D loss: 0.420484, acc: 64.84%, op_acc: 37.50%] [G loss: 0.897972]\n",
      "epoch:22 step:17661[D loss: 0.440292, acc: 53.91%, op_acc: 38.28%] [G loss: 0.774409]\n",
      "epoch:22 step:17662[D loss: 0.442719, acc: 65.62%, op_acc: 32.81%] [G loss: 0.948977]\n",
      "epoch:22 step:17663[D loss: 0.454637, acc: 59.38%, op_acc: 31.25%] [G loss: 0.820290]\n",
      "epoch:22 step:17664[D loss: 0.424791, acc: 56.25%, op_acc: 40.62%] [G loss: 0.872702]\n",
      "epoch:22 step:17665[D loss: 0.415256, acc: 71.88%, op_acc: 34.38%] [G loss: 0.892991]\n",
      "epoch:22 step:17666[D loss: 0.434046, acc: 55.47%, op_acc: 39.84%] [G loss: 0.846523]\n",
      "epoch:22 step:17667[D loss: 0.396177, acc: 73.44%, op_acc: 35.94%] [G loss: 0.901484]\n",
      "epoch:22 step:17668[D loss: 0.420710, acc: 53.12%, op_acc: 46.88%] [G loss: 0.925523]\n",
      "epoch:22 step:17669[D loss: 0.422116, acc: 60.16%, op_acc: 42.97%] [G loss: 0.846084]\n",
      "epoch:22 step:17670[D loss: 0.450795, acc: 55.47%, op_acc: 38.28%] [G loss: 0.865273]\n",
      "epoch:22 step:17671[D loss: 0.462018, acc: 50.00%, op_acc: 35.16%] [G loss: 0.789478]\n",
      "epoch:22 step:17672[D loss: 0.391515, acc: 67.19%, op_acc: 38.28%] [G loss: 0.829888]\n",
      "epoch:22 step:17673[D loss: 0.471713, acc: 58.59%, op_acc: 26.56%] [G loss: 0.901842]\n",
      "epoch:22 step:17674[D loss: 0.409233, acc: 61.72%, op_acc: 39.84%] [G loss: 0.951699]\n",
      "epoch:22 step:17675[D loss: 0.415679, acc: 60.94%, op_acc: 43.75%] [G loss: 0.897115]\n",
      "epoch:22 step:17676[D loss: 0.434855, acc: 61.72%, op_acc: 33.59%] [G loss: 0.916922]\n",
      "epoch:22 step:17677[D loss: 0.414113, acc: 61.72%, op_acc: 41.41%] [G loss: 0.990095]\n",
      "epoch:22 step:17678[D loss: 0.430170, acc: 63.28%, op_acc: 32.81%] [G loss: 0.866768]\n",
      "epoch:22 step:17679[D loss: 0.400295, acc: 62.50%, op_acc: 40.62%] [G loss: 0.870025]\n",
      "epoch:22 step:17680[D loss: 0.426605, acc: 64.84%, op_acc: 33.59%] [G loss: 0.915777]\n",
      "epoch:22 step:17681[D loss: 0.457714, acc: 59.38%, op_acc: 34.38%] [G loss: 0.826277]\n",
      "epoch:22 step:17682[D loss: 0.402028, acc: 65.62%, op_acc: 46.88%] [G loss: 0.905228]\n",
      "epoch:22 step:17683[D loss: 0.453554, acc: 55.47%, op_acc: 39.06%] [G loss: 0.858279]\n",
      "epoch:22 step:17684[D loss: 0.434772, acc: 61.72%, op_acc: 41.41%] [G loss: 0.903393]\n",
      "epoch:22 step:17685[D loss: 0.416405, acc: 61.72%, op_acc: 43.75%] [G loss: 0.903185]\n",
      "epoch:22 step:17686[D loss: 0.435569, acc: 54.69%, op_acc: 35.94%] [G loss: 0.864114]\n",
      "epoch:22 step:17687[D loss: 0.419741, acc: 62.50%, op_acc: 33.59%] [G loss: 0.926953]\n",
      "epoch:22 step:17688[D loss: 0.463014, acc: 46.88%, op_acc: 35.94%] [G loss: 0.879387]\n",
      "epoch:22 step:17689[D loss: 0.415224, acc: 60.16%, op_acc: 42.97%] [G loss: 0.970725]\n",
      "epoch:22 step:17690[D loss: 0.420394, acc: 66.41%, op_acc: 39.84%] [G loss: 0.893374]\n",
      "epoch:22 step:17691[D loss: 0.450171, acc: 53.12%, op_acc: 39.84%] [G loss: 0.918906]\n",
      "epoch:22 step:17692[D loss: 0.434267, acc: 50.78%, op_acc: 36.72%] [G loss: 0.803317]\n",
      "epoch:22 step:17693[D loss: 0.398520, acc: 65.62%, op_acc: 40.62%] [G loss: 0.933861]\n",
      "epoch:22 step:17694[D loss: 0.450494, acc: 53.91%, op_acc: 40.62%] [G loss: 0.834769]\n",
      "epoch:22 step:17695[D loss: 0.474891, acc: 53.91%, op_acc: 33.59%] [G loss: 0.789244]\n",
      "epoch:22 step:17696[D loss: 0.463806, acc: 40.62%, op_acc: 35.94%] [G loss: 0.756653]\n",
      "epoch:22 step:17697[D loss: 0.423412, acc: 65.62%, op_acc: 34.38%] [G loss: 0.811345]\n",
      "epoch:22 step:17698[D loss: 0.416526, acc: 60.94%, op_acc: 40.62%] [G loss: 0.899967]\n",
      "epoch:22 step:17699[D loss: 0.463573, acc: 52.34%, op_acc: 37.50%] [G loss: 0.929104]\n",
      "epoch:22 step:17700[D loss: 0.425473, acc: 58.59%, op_acc: 34.38%] [G loss: 0.872974]\n",
      "epoch:22 step:17701[D loss: 0.403900, acc: 66.41%, op_acc: 39.06%] [G loss: 0.931213]\n",
      "epoch:22 step:17702[D loss: 0.409449, acc: 60.16%, op_acc: 46.09%] [G loss: 0.933474]\n",
      "epoch:22 step:17703[D loss: 0.420733, acc: 68.75%, op_acc: 35.94%] [G loss: 0.932507]\n",
      "epoch:22 step:17704[D loss: 0.438688, acc: 60.16%, op_acc: 37.50%] [G loss: 0.887576]\n",
      "epoch:22 step:17705[D loss: 0.435155, acc: 60.94%, op_acc: 39.06%] [G loss: 0.895741]\n",
      "epoch:22 step:17706[D loss: 0.408024, acc: 60.16%, op_acc: 42.19%] [G loss: 0.872347]\n",
      "epoch:22 step:17707[D loss: 0.398419, acc: 71.88%, op_acc: 35.16%] [G loss: 0.975960]\n",
      "epoch:22 step:17708[D loss: 0.455524, acc: 54.69%, op_acc: 35.16%] [G loss: 0.935357]\n",
      "epoch:22 step:17709[D loss: 0.454546, acc: 46.09%, op_acc: 35.16%] [G loss: 0.837037]\n",
      "epoch:22 step:17710[D loss: 0.465449, acc: 52.34%, op_acc: 32.03%] [G loss: 0.795628]\n",
      "epoch:22 step:17711[D loss: 0.414676, acc: 59.38%, op_acc: 43.75%] [G loss: 0.911462]\n",
      "epoch:22 step:17712[D loss: 0.444354, acc: 58.59%, op_acc: 35.16%] [G loss: 0.863811]\n",
      "epoch:22 step:17713[D loss: 0.459284, acc: 56.25%, op_acc: 35.94%] [G loss: 0.920114]\n",
      "epoch:22 step:17714[D loss: 0.448969, acc: 55.47%, op_acc: 34.38%] [G loss: 0.864624]\n",
      "epoch:22 step:17715[D loss: 0.427723, acc: 60.94%, op_acc: 38.28%] [G loss: 0.885126]\n",
      "epoch:22 step:17716[D loss: 0.407561, acc: 63.28%, op_acc: 47.66%] [G loss: 0.850077]\n",
      "epoch:22 step:17717[D loss: 0.434779, acc: 61.72%, op_acc: 30.47%] [G loss: 0.957627]\n",
      "epoch:22 step:17718[D loss: 0.411007, acc: 56.25%, op_acc: 36.72%] [G loss: 0.876557]\n",
      "epoch:22 step:17719[D loss: 0.461829, acc: 54.69%, op_acc: 32.03%] [G loss: 0.935341]\n",
      "epoch:22 step:17720[D loss: 0.437269, acc: 50.78%, op_acc: 38.28%] [G loss: 0.864301]\n",
      "epoch:22 step:17721[D loss: 0.430563, acc: 57.03%, op_acc: 38.28%] [G loss: 0.893142]\n",
      "epoch:22 step:17722[D loss: 0.416860, acc: 64.06%, op_acc: 44.53%] [G loss: 0.945916]\n",
      "epoch:22 step:17723[D loss: 0.398870, acc: 61.72%, op_acc: 41.41%] [G loss: 0.882585]\n",
      "epoch:22 step:17724[D loss: 0.450206, acc: 51.56%, op_acc: 41.41%] [G loss: 0.823032]\n",
      "epoch:22 step:17725[D loss: 0.434331, acc: 58.59%, op_acc: 34.38%] [G loss: 0.829852]\n",
      "epoch:22 step:17726[D loss: 0.441307, acc: 50.00%, op_acc: 41.41%] [G loss: 0.849562]\n",
      "epoch:22 step:17727[D loss: 0.403115, acc: 58.59%, op_acc: 40.62%] [G loss: 0.909379]\n",
      "epoch:22 step:17728[D loss: 0.403668, acc: 61.72%, op_acc: 47.66%] [G loss: 0.896397]\n",
      "epoch:22 step:17729[D loss: 0.402603, acc: 67.19%, op_acc: 37.50%] [G loss: 0.904459]\n",
      "epoch:22 step:17730[D loss: 0.419853, acc: 60.94%, op_acc: 41.41%] [G loss: 0.899942]\n",
      "epoch:22 step:17731[D loss: 0.426040, acc: 58.59%, op_acc: 39.84%] [G loss: 0.930724]\n",
      "epoch:22 step:17732[D loss: 0.440446, acc: 56.25%, op_acc: 35.94%] [G loss: 0.926003]\n",
      "epoch:22 step:17733[D loss: 0.445462, acc: 50.00%, op_acc: 38.28%] [G loss: 0.759330]\n",
      "epoch:22 step:17734[D loss: 0.447922, acc: 54.69%, op_acc: 27.34%] [G loss: 0.855673]\n",
      "epoch:22 step:17735[D loss: 0.419514, acc: 65.62%, op_acc: 43.75%] [G loss: 0.881998]\n",
      "epoch:22 step:17736[D loss: 0.416367, acc: 64.06%, op_acc: 39.06%] [G loss: 0.899279]\n",
      "epoch:22 step:17737[D loss: 0.402656, acc: 60.94%, op_acc: 36.72%] [G loss: 0.873080]\n",
      "epoch:22 step:17738[D loss: 0.434384, acc: 54.69%, op_acc: 39.06%] [G loss: 0.835881]\n",
      "epoch:22 step:17739[D loss: 0.447408, acc: 57.81%, op_acc: 32.81%] [G loss: 0.877435]\n",
      "epoch:22 step:17740[D loss: 0.390832, acc: 71.09%, op_acc: 39.06%] [G loss: 0.864068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17741[D loss: 0.403059, acc: 65.62%, op_acc: 38.28%] [G loss: 0.925140]\n",
      "epoch:22 step:17742[D loss: 0.432149, acc: 67.19%, op_acc: 35.16%] [G loss: 0.902005]\n",
      "epoch:22 step:17743[D loss: 0.448656, acc: 53.12%, op_acc: 39.84%] [G loss: 0.877847]\n",
      "epoch:22 step:17744[D loss: 0.423228, acc: 57.03%, op_acc: 36.72%] [G loss: 0.906928]\n",
      "epoch:22 step:17745[D loss: 0.410705, acc: 64.84%, op_acc: 42.19%] [G loss: 0.884365]\n",
      "epoch:22 step:17746[D loss: 0.419310, acc: 57.81%, op_acc: 45.31%] [G loss: 0.863653]\n",
      "epoch:22 step:17747[D loss: 0.411174, acc: 57.03%, op_acc: 42.97%] [G loss: 0.801831]\n",
      "epoch:22 step:17748[D loss: 0.440717, acc: 58.59%, op_acc: 34.38%] [G loss: 0.849605]\n",
      "epoch:22 step:17749[D loss: 0.417926, acc: 58.59%, op_acc: 41.41%] [G loss: 0.881107]\n",
      "epoch:22 step:17750[D loss: 0.431148, acc: 57.03%, op_acc: 37.50%] [G loss: 0.856861]\n",
      "epoch:22 step:17751[D loss: 0.403726, acc: 65.62%, op_acc: 42.97%] [G loss: 0.883731]\n",
      "epoch:22 step:17752[D loss: 0.432943, acc: 60.16%, op_acc: 39.84%] [G loss: 0.851028]\n",
      "epoch:22 step:17753[D loss: 0.435060, acc: 50.00%, op_acc: 42.19%] [G loss: 0.920369]\n",
      "epoch:22 step:17754[D loss: 0.428697, acc: 57.81%, op_acc: 38.28%] [G loss: 0.877501]\n",
      "epoch:22 step:17755[D loss: 0.420300, acc: 64.06%, op_acc: 39.84%] [G loss: 0.948144]\n",
      "epoch:22 step:17756[D loss: 0.444988, acc: 57.81%, op_acc: 35.94%] [G loss: 0.981675]\n",
      "epoch:22 step:17757[D loss: 0.396652, acc: 67.19%, op_acc: 42.19%] [G loss: 0.888271]\n",
      "epoch:22 step:17758[D loss: 0.401016, acc: 70.31%, op_acc: 39.84%] [G loss: 0.859529]\n",
      "epoch:22 step:17759[D loss: 0.438651, acc: 57.03%, op_acc: 37.50%] [G loss: 0.831250]\n",
      "epoch:22 step:17760[D loss: 0.489928, acc: 49.22%, op_acc: 31.25%] [G loss: 0.891571]\n",
      "epoch:22 step:17761[D loss: 0.424296, acc: 59.38%, op_acc: 42.97%] [G loss: 0.935184]\n",
      "epoch:22 step:17762[D loss: 0.421182, acc: 60.94%, op_acc: 40.62%] [G loss: 0.974819]\n",
      "epoch:22 step:17763[D loss: 0.460549, acc: 53.12%, op_acc: 39.06%] [G loss: 0.989947]\n",
      "epoch:22 step:17764[D loss: 0.428926, acc: 57.81%, op_acc: 38.28%] [G loss: 0.952553]\n",
      "epoch:22 step:17765[D loss: 0.412579, acc: 61.72%, op_acc: 41.41%] [G loss: 0.932524]\n",
      "epoch:22 step:17766[D loss: 0.430267, acc: 60.94%, op_acc: 32.03%] [G loss: 0.842456]\n",
      "epoch:22 step:17767[D loss: 0.391448, acc: 68.75%, op_acc: 40.62%] [G loss: 0.896103]\n",
      "epoch:22 step:17768[D loss: 0.411197, acc: 66.41%, op_acc: 39.06%] [G loss: 0.911745]\n",
      "epoch:22 step:17769[D loss: 0.418848, acc: 57.81%, op_acc: 34.38%] [G loss: 0.959370]\n",
      "epoch:22 step:17770[D loss: 0.411091, acc: 57.03%, op_acc: 38.28%] [G loss: 0.904108]\n",
      "epoch:22 step:17771[D loss: 0.378752, acc: 71.09%, op_acc: 42.97%] [G loss: 0.985925]\n",
      "epoch:22 step:17772[D loss: 0.397837, acc: 69.53%, op_acc: 42.97%] [G loss: 0.868195]\n",
      "epoch:22 step:17773[D loss: 0.452306, acc: 52.34%, op_acc: 36.72%] [G loss: 0.808024]\n",
      "epoch:22 step:17774[D loss: 0.458721, acc: 54.69%, op_acc: 35.16%] [G loss: 0.914682]\n",
      "epoch:22 step:17775[D loss: 0.467689, acc: 49.22%, op_acc: 34.38%] [G loss: 0.856911]\n",
      "epoch:22 step:17776[D loss: 0.402520, acc: 62.50%, op_acc: 42.19%] [G loss: 0.853385]\n",
      "epoch:22 step:17777[D loss: 0.380760, acc: 69.53%, op_acc: 36.72%] [G loss: 0.921159]\n",
      "epoch:22 step:17778[D loss: 0.473783, acc: 50.78%, op_acc: 32.81%] [G loss: 0.935239]\n",
      "epoch:22 step:17779[D loss: 0.423608, acc: 62.50%, op_acc: 38.28%] [G loss: 0.914814]\n",
      "epoch:22 step:17780[D loss: 0.423437, acc: 60.16%, op_acc: 35.16%] [G loss: 0.834727]\n",
      "epoch:22 step:17781[D loss: 0.428302, acc: 62.50%, op_acc: 35.16%] [G loss: 0.847983]\n",
      "epoch:22 step:17782[D loss: 0.406995, acc: 63.28%, op_acc: 38.28%] [G loss: 0.930877]\n",
      "epoch:22 step:17783[D loss: 0.404497, acc: 64.84%, op_acc: 38.28%] [G loss: 0.903120]\n",
      "epoch:22 step:17784[D loss: 0.460191, acc: 50.78%, op_acc: 40.62%] [G loss: 0.779268]\n",
      "epoch:22 step:17785[D loss: 0.428307, acc: 53.12%, op_acc: 39.84%] [G loss: 0.824943]\n",
      "epoch:22 step:17786[D loss: 0.463541, acc: 55.47%, op_acc: 32.03%] [G loss: 0.891005]\n",
      "epoch:22 step:17787[D loss: 0.427649, acc: 59.38%, op_acc: 35.16%] [G loss: 1.036019]\n",
      "epoch:22 step:17788[D loss: 0.414797, acc: 59.38%, op_acc: 41.41%] [G loss: 0.820222]\n",
      "epoch:22 step:17789[D loss: 0.401684, acc: 59.38%, op_acc: 42.97%] [G loss: 0.844517]\n",
      "epoch:22 step:17790[D loss: 0.396929, acc: 60.94%, op_acc: 42.19%] [G loss: 0.829593]\n",
      "epoch:22 step:17791[D loss: 0.419674, acc: 58.59%, op_acc: 35.16%] [G loss: 0.859436]\n",
      "epoch:22 step:17792[D loss: 0.417552, acc: 59.38%, op_acc: 35.16%] [G loss: 0.868028]\n",
      "epoch:22 step:17793[D loss: 0.462896, acc: 49.22%, op_acc: 35.94%] [G loss: 0.876467]\n",
      "epoch:22 step:17794[D loss: 0.441703, acc: 56.25%, op_acc: 39.06%] [G loss: 0.920442]\n",
      "epoch:22 step:17795[D loss: 0.454326, acc: 51.56%, op_acc: 36.72%] [G loss: 0.920266]\n",
      "epoch:22 step:17796[D loss: 0.417880, acc: 61.72%, op_acc: 37.50%] [G loss: 0.915509]\n",
      "epoch:22 step:17797[D loss: 0.421482, acc: 60.94%, op_acc: 39.06%] [G loss: 0.934840]\n",
      "epoch:22 step:17798[D loss: 0.437255, acc: 58.59%, op_acc: 35.94%] [G loss: 0.961651]\n",
      "epoch:22 step:17799[D loss: 0.425562, acc: 57.03%, op_acc: 38.28%] [G loss: 0.953663]\n",
      "epoch:22 step:17800[D loss: 0.406689, acc: 61.72%, op_acc: 42.97%] [G loss: 0.933581]\n",
      "epoch:22 step:17801[D loss: 0.441541, acc: 61.72%, op_acc: 36.72%] [G loss: 0.784543]\n",
      "epoch:22 step:17802[D loss: 0.443644, acc: 53.91%, op_acc: 29.69%] [G loss: 0.919382]\n",
      "epoch:22 step:17803[D loss: 0.412467, acc: 66.41%, op_acc: 42.97%] [G loss: 0.922294]\n",
      "epoch:22 step:17804[D loss: 0.457628, acc: 57.81%, op_acc: 31.25%] [G loss: 0.916591]\n",
      "epoch:22 step:17805[D loss: 0.414884, acc: 64.06%, op_acc: 42.19%] [G loss: 0.997732]\n",
      "epoch:22 step:17806[D loss: 0.400614, acc: 63.28%, op_acc: 46.09%] [G loss: 0.839488]\n",
      "epoch:22 step:17807[D loss: 0.416820, acc: 56.25%, op_acc: 42.19%] [G loss: 0.840916]\n",
      "epoch:22 step:17808[D loss: 0.404510, acc: 67.19%, op_acc: 42.97%] [G loss: 0.859094]\n",
      "epoch:22 step:17809[D loss: 0.432144, acc: 60.94%, op_acc: 39.84%] [G loss: 0.898624]\n",
      "epoch:22 step:17810[D loss: 0.403264, acc: 62.50%, op_acc: 42.19%] [G loss: 0.951508]\n",
      "epoch:22 step:17811[D loss: 0.425626, acc: 53.12%, op_acc: 35.16%] [G loss: 0.793799]\n",
      "epoch:22 step:17812[D loss: 0.418688, acc: 59.38%, op_acc: 37.50%] [G loss: 0.921738]\n",
      "epoch:22 step:17813[D loss: 0.431303, acc: 57.03%, op_acc: 35.94%] [G loss: 0.826979]\n",
      "epoch:22 step:17814[D loss: 0.418747, acc: 59.38%, op_acc: 35.94%] [G loss: 0.896340]\n",
      "epoch:22 step:17815[D loss: 0.452557, acc: 53.12%, op_acc: 38.28%] [G loss: 0.775052]\n",
      "epoch:22 step:17816[D loss: 0.415670, acc: 60.16%, op_acc: 42.97%] [G loss: 0.850842]\n",
      "epoch:22 step:17817[D loss: 0.438106, acc: 53.12%, op_acc: 40.62%] [G loss: 0.849353]\n",
      "epoch:22 step:17818[D loss: 0.407168, acc: 63.28%, op_acc: 42.97%] [G loss: 0.970904]\n",
      "epoch:22 step:17819[D loss: 0.409477, acc: 65.62%, op_acc: 38.28%] [G loss: 0.939385]\n",
      "epoch:22 step:17820[D loss: 0.448145, acc: 50.00%, op_acc: 39.84%] [G loss: 0.898661]\n",
      "epoch:22 step:17821[D loss: 0.433555, acc: 60.16%, op_acc: 35.94%] [G loss: 0.855435]\n",
      "epoch:22 step:17822[D loss: 0.430471, acc: 56.25%, op_acc: 39.06%] [G loss: 0.849797]\n",
      "epoch:22 step:17823[D loss: 0.414041, acc: 63.28%, op_acc: 41.41%] [G loss: 0.844855]\n",
      "epoch:22 step:17824[D loss: 0.443664, acc: 57.03%, op_acc: 35.94%] [G loss: 0.808909]\n",
      "epoch:22 step:17825[D loss: 0.443520, acc: 58.59%, op_acc: 34.38%] [G loss: 0.853799]\n",
      "epoch:22 step:17826[D loss: 0.396692, acc: 54.69%, op_acc: 47.66%] [G loss: 0.877632]\n",
      "epoch:22 step:17827[D loss: 0.420648, acc: 60.16%, op_acc: 38.28%] [G loss: 0.957775]\n",
      "epoch:22 step:17828[D loss: 0.457607, acc: 60.94%, op_acc: 33.59%] [G loss: 0.852226]\n",
      "epoch:22 step:17829[D loss: 0.433850, acc: 57.03%, op_acc: 40.62%] [G loss: 0.859044]\n",
      "epoch:22 step:17830[D loss: 0.409443, acc: 58.59%, op_acc: 39.06%] [G loss: 0.873047]\n",
      "epoch:22 step:17831[D loss: 0.401819, acc: 63.28%, op_acc: 38.28%] [G loss: 0.992988]\n",
      "epoch:22 step:17832[D loss: 0.440452, acc: 64.06%, op_acc: 35.16%] [G loss: 0.894980]\n",
      "epoch:22 step:17833[D loss: 0.414865, acc: 60.94%, op_acc: 43.75%] [G loss: 0.875724]\n",
      "epoch:22 step:17834[D loss: 0.423404, acc: 59.38%, op_acc: 35.16%] [G loss: 0.794043]\n",
      "epoch:22 step:17835[D loss: 0.412346, acc: 60.16%, op_acc: 46.88%] [G loss: 0.861296]\n",
      "epoch:22 step:17836[D loss: 0.406283, acc: 71.09%, op_acc: 37.50%] [G loss: 0.886537]\n",
      "epoch:22 step:17837[D loss: 0.416634, acc: 59.38%, op_acc: 39.06%] [G loss: 0.866964]\n",
      "epoch:22 step:17838[D loss: 0.444343, acc: 50.78%, op_acc: 35.94%] [G loss: 0.877928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17839[D loss: 0.454346, acc: 53.12%, op_acc: 41.41%] [G loss: 0.904335]\n",
      "epoch:22 step:17840[D loss: 0.435638, acc: 58.59%, op_acc: 39.84%] [G loss: 0.878442]\n",
      "epoch:22 step:17841[D loss: 0.393422, acc: 67.97%, op_acc: 40.62%] [G loss: 0.886188]\n",
      "epoch:22 step:17842[D loss: 0.420572, acc: 55.47%, op_acc: 42.97%] [G loss: 0.929653]\n",
      "epoch:22 step:17843[D loss: 0.420799, acc: 57.81%, op_acc: 42.97%] [G loss: 0.859526]\n",
      "epoch:22 step:17844[D loss: 0.403516, acc: 54.69%, op_acc: 42.19%] [G loss: 0.874874]\n",
      "epoch:22 step:17845[D loss: 0.417869, acc: 60.94%, op_acc: 40.62%] [G loss: 0.865942]\n",
      "epoch:22 step:17846[D loss: 0.416436, acc: 58.59%, op_acc: 42.19%] [G loss: 0.925584]\n",
      "epoch:22 step:17847[D loss: 0.442312, acc: 69.53%, op_acc: 34.38%] [G loss: 0.963566]\n",
      "epoch:22 step:17848[D loss: 0.431914, acc: 61.72%, op_acc: 36.72%] [G loss: 0.816304]\n",
      "epoch:22 step:17849[D loss: 0.407872, acc: 67.19%, op_acc: 37.50%] [G loss: 0.881912]\n",
      "epoch:22 step:17850[D loss: 0.423336, acc: 56.25%, op_acc: 44.53%] [G loss: 0.837808]\n",
      "epoch:22 step:17851[D loss: 0.452844, acc: 53.12%, op_acc: 39.06%] [G loss: 0.819530]\n",
      "epoch:22 step:17852[D loss: 0.402046, acc: 61.72%, op_acc: 44.53%] [G loss: 0.911475]\n",
      "epoch:22 step:17853[D loss: 0.437236, acc: 57.81%, op_acc: 39.06%] [G loss: 0.922017]\n",
      "epoch:22 step:17854[D loss: 0.437718, acc: 60.94%, op_acc: 35.94%] [G loss: 0.865280]\n",
      "epoch:22 step:17855[D loss: 0.430585, acc: 58.59%, op_acc: 37.50%] [G loss: 0.890944]\n",
      "epoch:22 step:17856[D loss: 0.442648, acc: 53.12%, op_acc: 39.06%] [G loss: 0.847836]\n",
      "epoch:22 step:17857[D loss: 0.420666, acc: 69.53%, op_acc: 39.84%] [G loss: 0.843516]\n",
      "epoch:22 step:17858[D loss: 0.444202, acc: 59.38%, op_acc: 30.47%] [G loss: 0.868523]\n",
      "epoch:22 step:17859[D loss: 0.439881, acc: 60.94%, op_acc: 28.91%] [G loss: 0.986909]\n",
      "epoch:22 step:17860[D loss: 0.434660, acc: 57.81%, op_acc: 45.31%] [G loss: 0.840632]\n",
      "epoch:22 step:17861[D loss: 0.408061, acc: 58.59%, op_acc: 48.44%] [G loss: 0.824298]\n",
      "epoch:22 step:17862[D loss: 0.423485, acc: 66.41%, op_acc: 35.16%] [G loss: 0.929076]\n",
      "epoch:22 step:17863[D loss: 0.459798, acc: 55.47%, op_acc: 33.59%] [G loss: 0.879600]\n",
      "epoch:22 step:17864[D loss: 0.396447, acc: 61.72%, op_acc: 42.97%] [G loss: 0.887776]\n",
      "epoch:22 step:17865[D loss: 0.391454, acc: 64.84%, op_acc: 40.62%] [G loss: 0.893839]\n",
      "epoch:22 step:17866[D loss: 0.428204, acc: 64.84%, op_acc: 39.84%] [G loss: 0.897004]\n",
      "epoch:22 step:17867[D loss: 0.417642, acc: 62.50%, op_acc: 31.25%] [G loss: 0.877589]\n",
      "epoch:22 step:17868[D loss: 0.434235, acc: 64.84%, op_acc: 35.94%] [G loss: 0.842809]\n",
      "epoch:22 step:17869[D loss: 0.439567, acc: 60.16%, op_acc: 32.81%] [G loss: 0.791534]\n",
      "epoch:22 step:17870[D loss: 0.383167, acc: 64.84%, op_acc: 49.22%] [G loss: 0.928957]\n",
      "epoch:22 step:17871[D loss: 0.437680, acc: 51.56%, op_acc: 38.28%] [G loss: 0.809900]\n",
      "epoch:22 step:17872[D loss: 0.413052, acc: 63.28%, op_acc: 38.28%] [G loss: 0.913051]\n",
      "epoch:22 step:17873[D loss: 0.401298, acc: 67.97%, op_acc: 44.53%] [G loss: 0.874385]\n",
      "epoch:22 step:17874[D loss: 0.492700, acc: 50.00%, op_acc: 32.81%] [G loss: 0.848577]\n",
      "epoch:22 step:17875[D loss: 0.451787, acc: 56.25%, op_acc: 33.59%] [G loss: 0.886270]\n",
      "epoch:22 step:17876[D loss: 0.433762, acc: 59.38%, op_acc: 39.06%] [G loss: 0.888593]\n",
      "epoch:22 step:17877[D loss: 0.429183, acc: 66.41%, op_acc: 33.59%] [G loss: 0.848021]\n",
      "epoch:22 step:17878[D loss: 0.439817, acc: 53.91%, op_acc: 42.97%] [G loss: 0.875276]\n",
      "epoch:22 step:17879[D loss: 0.438549, acc: 50.78%, op_acc: 38.28%] [G loss: 0.871383]\n",
      "epoch:22 step:17880[D loss: 0.427258, acc: 63.28%, op_acc: 35.16%] [G loss: 0.915244]\n",
      "epoch:22 step:17881[D loss: 0.391231, acc: 67.19%, op_acc: 46.09%] [G loss: 0.937018]\n",
      "epoch:22 step:17882[D loss: 0.426324, acc: 59.38%, op_acc: 40.62%] [G loss: 0.907319]\n",
      "epoch:22 step:17883[D loss: 0.444188, acc: 56.25%, op_acc: 35.16%] [G loss: 0.918055]\n",
      "epoch:22 step:17884[D loss: 0.431827, acc: 62.50%, op_acc: 37.50%] [G loss: 0.851357]\n",
      "epoch:22 step:17885[D loss: 0.460584, acc: 46.88%, op_acc: 39.06%] [G loss: 0.748904]\n",
      "epoch:22 step:17886[D loss: 0.402424, acc: 62.50%, op_acc: 42.19%] [G loss: 0.760081]\n",
      "epoch:22 step:17887[D loss: 0.416122, acc: 61.72%, op_acc: 39.84%] [G loss: 0.861253]\n",
      "epoch:22 step:17888[D loss: 0.419282, acc: 58.59%, op_acc: 40.62%] [G loss: 0.915788]\n",
      "epoch:22 step:17889[D loss: 0.466325, acc: 54.69%, op_acc: 34.38%] [G loss: 0.853811]\n",
      "epoch:22 step:17890[D loss: 0.423717, acc: 60.16%, op_acc: 38.28%] [G loss: 0.929876]\n",
      "epoch:22 step:17891[D loss: 0.411427, acc: 59.38%, op_acc: 38.28%] [G loss: 0.943442]\n",
      "epoch:22 step:17892[D loss: 0.392368, acc: 67.19%, op_acc: 42.97%] [G loss: 0.846322]\n",
      "epoch:22 step:17893[D loss: 0.427284, acc: 62.50%, op_acc: 35.16%] [G loss: 0.980857]\n",
      "epoch:22 step:17894[D loss: 0.415513, acc: 57.03%, op_acc: 37.50%] [G loss: 0.890208]\n",
      "epoch:22 step:17895[D loss: 0.413031, acc: 54.69%, op_acc: 39.84%] [G loss: 0.981233]\n",
      "epoch:22 step:17896[D loss: 0.442447, acc: 57.81%, op_acc: 34.38%] [G loss: 0.926192]\n",
      "epoch:22 step:17897[D loss: 0.421552, acc: 62.50%, op_acc: 37.50%] [G loss: 0.927568]\n",
      "epoch:22 step:17898[D loss: 0.405603, acc: 64.06%, op_acc: 38.28%] [G loss: 0.888781]\n",
      "epoch:22 step:17899[D loss: 0.416320, acc: 59.38%, op_acc: 43.75%] [G loss: 0.838895]\n",
      "epoch:22 step:17900[D loss: 0.437676, acc: 64.06%, op_acc: 34.38%] [G loss: 0.931317]\n",
      "epoch:22 step:17901[D loss: 0.398376, acc: 64.84%, op_acc: 41.41%] [G loss: 0.876766]\n",
      "epoch:22 step:17902[D loss: 0.447221, acc: 56.25%, op_acc: 39.06%] [G loss: 0.783308]\n",
      "epoch:22 step:17903[D loss: 0.407108, acc: 58.59%, op_acc: 40.62%] [G loss: 0.862577]\n",
      "epoch:22 step:17904[D loss: 0.439335, acc: 55.47%, op_acc: 38.28%] [G loss: 0.882436]\n",
      "epoch:22 step:17905[D loss: 0.417899, acc: 63.28%, op_acc: 38.28%] [G loss: 0.952662]\n",
      "epoch:22 step:17906[D loss: 0.447347, acc: 61.72%, op_acc: 36.72%] [G loss: 0.934407]\n",
      "epoch:22 step:17907[D loss: 0.431155, acc: 60.16%, op_acc: 43.75%] [G loss: 0.909421]\n",
      "epoch:22 step:17908[D loss: 0.404625, acc: 60.16%, op_acc: 44.53%] [G loss: 0.982163]\n",
      "epoch:22 step:17909[D loss: 0.461188, acc: 56.25%, op_acc: 30.47%] [G loss: 0.823522]\n",
      "epoch:22 step:17910[D loss: 0.421007, acc: 63.28%, op_acc: 47.66%] [G loss: 0.949154]\n",
      "epoch:22 step:17911[D loss: 0.421125, acc: 60.94%, op_acc: 41.41%] [G loss: 0.878686]\n",
      "epoch:22 step:17912[D loss: 0.421781, acc: 59.38%, op_acc: 40.62%] [G loss: 0.936151]\n",
      "epoch:22 step:17913[D loss: 0.400095, acc: 63.28%, op_acc: 42.19%] [G loss: 0.794930]\n",
      "epoch:22 step:17914[D loss: 0.430815, acc: 57.03%, op_acc: 39.84%] [G loss: 0.875793]\n",
      "epoch:22 step:17915[D loss: 0.463953, acc: 50.00%, op_acc: 34.38%] [G loss: 0.812866]\n",
      "epoch:22 step:17916[D loss: 0.445697, acc: 51.56%, op_acc: 37.50%] [G loss: 0.911506]\n",
      "epoch:22 step:17917[D loss: 0.411380, acc: 63.28%, op_acc: 33.59%] [G loss: 0.862882]\n",
      "epoch:22 step:17918[D loss: 0.424470, acc: 63.28%, op_acc: 36.72%] [G loss: 0.920519]\n",
      "epoch:22 step:17919[D loss: 0.410575, acc: 53.91%, op_acc: 48.44%] [G loss: 0.875673]\n",
      "epoch:22 step:17920[D loss: 0.428077, acc: 59.38%, op_acc: 35.16%] [G loss: 0.871667]\n",
      "epoch:22 step:17921[D loss: 0.422622, acc: 58.59%, op_acc: 35.94%] [G loss: 0.927943]\n",
      "epoch:22 step:17922[D loss: 0.406466, acc: 61.72%, op_acc: 45.31%] [G loss: 0.834433]\n",
      "epoch:22 step:17923[D loss: 0.367269, acc: 70.31%, op_acc: 43.75%] [G loss: 0.862736]\n",
      "epoch:22 step:17924[D loss: 0.472777, acc: 51.56%, op_acc: 34.38%] [G loss: 0.913637]\n",
      "epoch:22 step:17925[D loss: 0.424130, acc: 64.84%, op_acc: 37.50%] [G loss: 0.841588]\n",
      "epoch:22 step:17926[D loss: 0.414333, acc: 59.38%, op_acc: 44.53%] [G loss: 0.891790]\n",
      "epoch:22 step:17927[D loss: 0.424678, acc: 60.94%, op_acc: 37.50%] [G loss: 0.901851]\n",
      "epoch:22 step:17928[D loss: 0.433275, acc: 55.47%, op_acc: 40.62%] [G loss: 0.870656]\n",
      "epoch:22 step:17929[D loss: 0.418679, acc: 60.94%, op_acc: 40.62%] [G loss: 0.870466]\n",
      "epoch:22 step:17930[D loss: 0.466029, acc: 52.34%, op_acc: 33.59%] [G loss: 0.861423]\n",
      "epoch:22 step:17931[D loss: 0.417110, acc: 63.28%, op_acc: 39.06%] [G loss: 0.875974]\n",
      "epoch:22 step:17932[D loss: 0.436802, acc: 53.12%, op_acc: 36.72%] [G loss: 0.787919]\n",
      "epoch:22 step:17933[D loss: 0.419986, acc: 67.19%, op_acc: 35.94%] [G loss: 0.869864]\n",
      "epoch:22 step:17934[D loss: 0.395044, acc: 70.31%, op_acc: 39.84%] [G loss: 0.949025]\n",
      "epoch:22 step:17935[D loss: 0.410991, acc: 66.41%, op_acc: 39.06%] [G loss: 0.943749]\n",
      "epoch:22 step:17936[D loss: 0.412296, acc: 57.81%, op_acc: 38.28%] [G loss: 0.867987]\n",
      "epoch:22 step:17937[D loss: 0.390123, acc: 68.75%, op_acc: 42.19%] [G loss: 0.868437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:17938[D loss: 0.408675, acc: 61.72%, op_acc: 39.84%] [G loss: 0.879550]\n",
      "epoch:22 step:17939[D loss: 0.403057, acc: 67.97%, op_acc: 40.62%] [G loss: 0.894995]\n",
      "epoch:22 step:17940[D loss: 0.389446, acc: 67.19%, op_acc: 41.41%] [G loss: 0.923686]\n",
      "epoch:22 step:17941[D loss: 0.432228, acc: 57.81%, op_acc: 41.41%] [G loss: 0.934685]\n",
      "epoch:22 step:17942[D loss: 0.419827, acc: 60.94%, op_acc: 41.41%] [G loss: 0.876406]\n",
      "epoch:22 step:17943[D loss: 0.397514, acc: 64.06%, op_acc: 45.31%] [G loss: 0.902240]\n",
      "epoch:22 step:17944[D loss: 0.461625, acc: 54.69%, op_acc: 34.38%] [G loss: 0.802989]\n",
      "epoch:22 step:17945[D loss: 0.429731, acc: 58.59%, op_acc: 35.94%] [G loss: 0.820287]\n",
      "epoch:22 step:17946[D loss: 0.440263, acc: 53.91%, op_acc: 40.62%] [G loss: 0.892014]\n",
      "epoch:22 step:17947[D loss: 0.405401, acc: 59.38%, op_acc: 40.62%] [G loss: 0.869446]\n",
      "epoch:22 step:17948[D loss: 0.453185, acc: 55.47%, op_acc: 35.16%] [G loss: 0.794899]\n",
      "epoch:22 step:17949[D loss: 0.405133, acc: 60.16%, op_acc: 44.53%] [G loss: 0.878533]\n",
      "epoch:22 step:17950[D loss: 0.422917, acc: 59.38%, op_acc: 38.28%] [G loss: 0.898842]\n",
      "epoch:22 step:17951[D loss: 0.407045, acc: 60.16%, op_acc: 46.09%] [G loss: 0.833533]\n",
      "epoch:22 step:17952[D loss: 0.452275, acc: 46.88%, op_acc: 37.50%] [G loss: 0.829549]\n",
      "epoch:22 step:17953[D loss: 0.466556, acc: 49.22%, op_acc: 29.69%] [G loss: 0.921272]\n",
      "epoch:22 step:17954[D loss: 0.468816, acc: 51.56%, op_acc: 36.72%] [G loss: 0.856322]\n",
      "epoch:22 step:17955[D loss: 0.423225, acc: 65.62%, op_acc: 35.94%] [G loss: 0.849811]\n",
      "epoch:22 step:17956[D loss: 0.416605, acc: 59.38%, op_acc: 35.94%] [G loss: 0.935793]\n",
      "epoch:22 step:17957[D loss: 0.426553, acc: 62.50%, op_acc: 35.94%] [G loss: 0.967059]\n",
      "epoch:22 step:17958[D loss: 0.414249, acc: 56.25%, op_acc: 40.62%] [G loss: 0.932993]\n",
      "epoch:22 step:17959[D loss: 0.437357, acc: 59.38%, op_acc: 35.16%] [G loss: 0.859325]\n",
      "epoch:22 step:17960[D loss: 0.421983, acc: 60.16%, op_acc: 41.41%] [G loss: 0.777298]\n",
      "epoch:22 step:17961[D loss: 0.422957, acc: 55.47%, op_acc: 39.84%] [G loss: 0.944729]\n",
      "epoch:22 step:17962[D loss: 0.437920, acc: 54.69%, op_acc: 40.62%] [G loss: 0.791582]\n",
      "epoch:22 step:17963[D loss: 0.439897, acc: 50.78%, op_acc: 43.75%] [G loss: 0.864256]\n",
      "epoch:23 step:17964[D loss: 0.408585, acc: 63.28%, op_acc: 40.62%] [G loss: 0.861396]\n",
      "epoch:23 step:17965[D loss: 0.401721, acc: 61.72%, op_acc: 40.62%] [G loss: 0.878861]\n",
      "epoch:23 step:17966[D loss: 0.423803, acc: 58.59%, op_acc: 38.28%] [G loss: 0.848819]\n",
      "epoch:23 step:17967[D loss: 0.402363, acc: 60.16%, op_acc: 46.88%] [G loss: 0.813751]\n",
      "epoch:23 step:17968[D loss: 0.443495, acc: 60.16%, op_acc: 41.41%] [G loss: 0.846615]\n",
      "epoch:23 step:17969[D loss: 0.442860, acc: 56.25%, op_acc: 44.53%] [G loss: 0.843148]\n",
      "epoch:23 step:17970[D loss: 0.411061, acc: 62.50%, op_acc: 40.62%] [G loss: 0.910179]\n",
      "epoch:23 step:17971[D loss: 0.449190, acc: 57.03%, op_acc: 34.38%] [G loss: 0.866189]\n",
      "epoch:23 step:17972[D loss: 0.405883, acc: 66.41%, op_acc: 36.72%] [G loss: 0.874089]\n",
      "epoch:23 step:17973[D loss: 0.436893, acc: 53.91%, op_acc: 37.50%] [G loss: 0.863165]\n",
      "epoch:23 step:17974[D loss: 0.446274, acc: 60.94%, op_acc: 40.62%] [G loss: 0.841256]\n",
      "epoch:23 step:17975[D loss: 0.407233, acc: 62.50%, op_acc: 35.16%] [G loss: 0.883776]\n",
      "epoch:23 step:17976[D loss: 0.390759, acc: 65.62%, op_acc: 44.53%] [G loss: 0.846447]\n",
      "epoch:23 step:17977[D loss: 0.435606, acc: 61.72%, op_acc: 32.81%] [G loss: 0.940464]\n",
      "epoch:23 step:17978[D loss: 0.422395, acc: 51.56%, op_acc: 43.75%] [G loss: 0.854755]\n",
      "epoch:23 step:17979[D loss: 0.412955, acc: 66.41%, op_acc: 37.50%] [G loss: 0.868569]\n",
      "epoch:23 step:17980[D loss: 0.443935, acc: 57.03%, op_acc: 39.84%] [G loss: 0.860457]\n",
      "epoch:23 step:17981[D loss: 0.412053, acc: 57.03%, op_acc: 39.06%] [G loss: 0.883586]\n",
      "epoch:23 step:17982[D loss: 0.404954, acc: 60.94%, op_acc: 41.41%] [G loss: 0.844378]\n",
      "epoch:23 step:17983[D loss: 0.429204, acc: 58.59%, op_acc: 36.72%] [G loss: 0.858167]\n",
      "epoch:23 step:17984[D loss: 0.453679, acc: 60.16%, op_acc: 33.59%] [G loss: 0.798351]\n",
      "epoch:23 step:17985[D loss: 0.412422, acc: 64.84%, op_acc: 41.41%] [G loss: 0.844345]\n",
      "epoch:23 step:17986[D loss: 0.430607, acc: 52.34%, op_acc: 41.41%] [G loss: 0.906541]\n",
      "epoch:23 step:17987[D loss: 0.426602, acc: 64.84%, op_acc: 40.62%] [G loss: 0.848969]\n",
      "epoch:23 step:17988[D loss: 0.465813, acc: 53.91%, op_acc: 38.28%] [G loss: 0.782335]\n",
      "epoch:23 step:17989[D loss: 0.426149, acc: 57.81%, op_acc: 42.19%] [G loss: 0.899907]\n",
      "epoch:23 step:17990[D loss: 0.414019, acc: 65.62%, op_acc: 42.19%] [G loss: 0.873782]\n",
      "epoch:23 step:17991[D loss: 0.422070, acc: 59.38%, op_acc: 39.06%] [G loss: 0.894029]\n",
      "epoch:23 step:17992[D loss: 0.429264, acc: 53.91%, op_acc: 43.75%] [G loss: 0.906507]\n",
      "epoch:23 step:17993[D loss: 0.407363, acc: 64.06%, op_acc: 43.75%] [G loss: 0.866670]\n",
      "epoch:23 step:17994[D loss: 0.450934, acc: 60.94%, op_acc: 33.59%] [G loss: 0.941761]\n",
      "epoch:23 step:17995[D loss: 0.400905, acc: 66.41%, op_acc: 39.84%] [G loss: 0.964500]\n",
      "epoch:23 step:17996[D loss: 0.396973, acc: 67.97%, op_acc: 47.66%] [G loss: 0.867486]\n",
      "epoch:23 step:17997[D loss: 0.380688, acc: 67.19%, op_acc: 44.53%] [G loss: 0.933642]\n",
      "epoch:23 step:17998[D loss: 0.436781, acc: 57.81%, op_acc: 35.94%] [G loss: 0.833414]\n",
      "epoch:23 step:17999[D loss: 0.425588, acc: 60.94%, op_acc: 40.62%] [G loss: 0.883109]\n",
      "epoch:23 step:18000[D loss: 0.415743, acc: 57.81%, op_acc: 35.94%] [G loss: 0.934020]\n",
      "epoch:23 step:18001[D loss: 0.407441, acc: 57.81%, op_acc: 42.19%] [G loss: 0.836686]\n",
      "epoch:23 step:18002[D loss: 0.416041, acc: 57.81%, op_acc: 42.19%] [G loss: 0.811283]\n",
      "epoch:23 step:18003[D loss: 0.450360, acc: 57.81%, op_acc: 33.59%] [G loss: 0.865721]\n",
      "epoch:23 step:18004[D loss: 0.396556, acc: 64.84%, op_acc: 47.66%] [G loss: 0.902430]\n",
      "epoch:23 step:18005[D loss: 0.390625, acc: 61.72%, op_acc: 43.75%] [G loss: 0.900711]\n",
      "epoch:23 step:18006[D loss: 0.436894, acc: 57.81%, op_acc: 32.81%] [G loss: 0.902666]\n",
      "epoch:23 step:18007[D loss: 0.421788, acc: 56.25%, op_acc: 41.41%] [G loss: 0.894077]\n",
      "epoch:23 step:18008[D loss: 0.402645, acc: 67.19%, op_acc: 41.41%] [G loss: 0.868408]\n",
      "epoch:23 step:18009[D loss: 0.421029, acc: 64.84%, op_acc: 41.41%] [G loss: 0.887005]\n",
      "epoch:23 step:18010[D loss: 0.466639, acc: 53.91%, op_acc: 34.38%] [G loss: 0.925658]\n",
      "epoch:23 step:18011[D loss: 0.453302, acc: 57.03%, op_acc: 35.16%] [G loss: 0.839244]\n",
      "epoch:23 step:18012[D loss: 0.409826, acc: 61.72%, op_acc: 39.84%] [G loss: 0.805531]\n",
      "epoch:23 step:18013[D loss: 0.393607, acc: 69.53%, op_acc: 38.28%] [G loss: 0.910578]\n",
      "epoch:23 step:18014[D loss: 0.382053, acc: 68.75%, op_acc: 42.19%] [G loss: 0.915270]\n",
      "epoch:23 step:18015[D loss: 0.427776, acc: 60.94%, op_acc: 32.81%] [G loss: 0.920627]\n",
      "epoch:23 step:18016[D loss: 0.439341, acc: 56.25%, op_acc: 36.72%] [G loss: 0.823407]\n",
      "epoch:23 step:18017[D loss: 0.432639, acc: 61.72%, op_acc: 45.31%] [G loss: 0.824289]\n",
      "epoch:23 step:18018[D loss: 0.432928, acc: 53.91%, op_acc: 42.19%] [G loss: 0.868437]\n",
      "epoch:23 step:18019[D loss: 0.435173, acc: 61.72%, op_acc: 36.72%] [G loss: 0.976007]\n",
      "epoch:23 step:18020[D loss: 0.444717, acc: 55.47%, op_acc: 36.72%] [G loss: 0.827000]\n",
      "epoch:23 step:18021[D loss: 0.440501, acc: 57.81%, op_acc: 42.97%] [G loss: 0.885097]\n",
      "epoch:23 step:18022[D loss: 0.412797, acc: 60.16%, op_acc: 39.06%] [G loss: 0.809659]\n",
      "epoch:23 step:18023[D loss: 0.422864, acc: 57.03%, op_acc: 39.06%] [G loss: 0.995880]\n",
      "epoch:23 step:18024[D loss: 0.438278, acc: 58.59%, op_acc: 33.59%] [G loss: 0.849940]\n",
      "epoch:23 step:18025[D loss: 0.423483, acc: 56.25%, op_acc: 39.84%] [G loss: 0.966861]\n",
      "epoch:23 step:18026[D loss: 0.458866, acc: 59.38%, op_acc: 37.50%] [G loss: 0.821334]\n",
      "epoch:23 step:18027[D loss: 0.422271, acc: 55.47%, op_acc: 36.72%] [G loss: 0.865314]\n",
      "epoch:23 step:18028[D loss: 0.399873, acc: 67.97%, op_acc: 44.53%] [G loss: 0.907130]\n",
      "epoch:23 step:18029[D loss: 0.437130, acc: 53.91%, op_acc: 39.84%] [G loss: 0.924507]\n",
      "epoch:23 step:18030[D loss: 0.415555, acc: 61.72%, op_acc: 41.41%] [G loss: 0.957749]\n",
      "epoch:23 step:18031[D loss: 0.409665, acc: 60.16%, op_acc: 37.50%] [G loss: 0.909681]\n",
      "epoch:23 step:18032[D loss: 0.396153, acc: 60.16%, op_acc: 43.75%] [G loss: 0.840384]\n",
      "epoch:23 step:18033[D loss: 0.459113, acc: 55.47%, op_acc: 39.06%] [G loss: 0.840300]\n",
      "epoch:23 step:18034[D loss: 0.473802, acc: 57.03%, op_acc: 33.59%] [G loss: 0.783403]\n",
      "epoch:23 step:18035[D loss: 0.392661, acc: 61.72%, op_acc: 40.62%] [G loss: 0.917691]\n",
      "epoch:23 step:18036[D loss: 0.459449, acc: 57.03%, op_acc: 33.59%] [G loss: 0.860311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18037[D loss: 0.396694, acc: 61.72%, op_acc: 41.41%] [G loss: 0.932442]\n",
      "epoch:23 step:18038[D loss: 0.426136, acc: 60.16%, op_acc: 36.72%] [G loss: 0.958677]\n",
      "epoch:23 step:18039[D loss: 0.437302, acc: 55.47%, op_acc: 39.06%] [G loss: 0.823017]\n",
      "epoch:23 step:18040[D loss: 0.449594, acc: 48.44%, op_acc: 39.06%] [G loss: 0.816861]\n",
      "epoch:23 step:18041[D loss: 0.458807, acc: 57.03%, op_acc: 38.28%] [G loss: 0.838872]\n",
      "epoch:23 step:18042[D loss: 0.444843, acc: 53.91%, op_acc: 36.72%] [G loss: 0.842937]\n",
      "epoch:23 step:18043[D loss: 0.428464, acc: 60.94%, op_acc: 35.16%] [G loss: 0.906447]\n",
      "epoch:23 step:18044[D loss: 0.437650, acc: 62.50%, op_acc: 35.16%] [G loss: 0.869259]\n",
      "epoch:23 step:18045[D loss: 0.388439, acc: 69.53%, op_acc: 42.97%] [G loss: 0.903351]\n",
      "epoch:23 step:18046[D loss: 0.441999, acc: 59.38%, op_acc: 35.16%] [G loss: 0.886914]\n",
      "epoch:23 step:18047[D loss: 0.435255, acc: 59.38%, op_acc: 38.28%] [G loss: 0.900643]\n",
      "epoch:23 step:18048[D loss: 0.450267, acc: 60.94%, op_acc: 31.25%] [G loss: 0.898482]\n",
      "epoch:23 step:18049[D loss: 0.416078, acc: 61.72%, op_acc: 41.41%] [G loss: 0.903312]\n",
      "epoch:23 step:18050[D loss: 0.409240, acc: 62.50%, op_acc: 39.84%] [G loss: 0.867340]\n",
      "epoch:23 step:18051[D loss: 0.451661, acc: 54.69%, op_acc: 34.38%] [G loss: 0.848567]\n",
      "epoch:23 step:18052[D loss: 0.422279, acc: 63.28%, op_acc: 38.28%] [G loss: 0.911808]\n",
      "epoch:23 step:18053[D loss: 0.449584, acc: 51.56%, op_acc: 38.28%] [G loss: 0.831696]\n",
      "epoch:23 step:18054[D loss: 0.406250, acc: 63.28%, op_acc: 41.41%] [G loss: 0.892293]\n",
      "epoch:23 step:18055[D loss: 0.408249, acc: 64.06%, op_acc: 37.50%] [G loss: 0.908680]\n",
      "epoch:23 step:18056[D loss: 0.396002, acc: 65.62%, op_acc: 42.19%] [G loss: 0.939566]\n",
      "epoch:23 step:18057[D loss: 0.410342, acc: 64.84%, op_acc: 42.97%] [G loss: 0.824195]\n",
      "epoch:23 step:18058[D loss: 0.447635, acc: 56.25%, op_acc: 41.41%] [G loss: 0.864297]\n",
      "epoch:23 step:18059[D loss: 0.452138, acc: 59.38%, op_acc: 33.59%] [G loss: 0.864153]\n",
      "epoch:23 step:18060[D loss: 0.404680, acc: 59.38%, op_acc: 42.19%] [G loss: 0.900459]\n",
      "epoch:23 step:18061[D loss: 0.425621, acc: 54.69%, op_acc: 40.62%] [G loss: 0.942300]\n",
      "epoch:23 step:18062[D loss: 0.400164, acc: 66.41%, op_acc: 45.31%] [G loss: 0.865636]\n",
      "epoch:23 step:18063[D loss: 0.415086, acc: 60.16%, op_acc: 39.84%] [G loss: 0.805904]\n",
      "epoch:23 step:18064[D loss: 0.423596, acc: 57.81%, op_acc: 35.94%] [G loss: 0.813803]\n",
      "epoch:23 step:18065[D loss: 0.424154, acc: 60.16%, op_acc: 38.28%] [G loss: 1.007228]\n",
      "epoch:23 step:18066[D loss: 0.430341, acc: 51.56%, op_acc: 35.94%] [G loss: 0.833244]\n",
      "epoch:23 step:18067[D loss: 0.423172, acc: 64.06%, op_acc: 34.38%] [G loss: 0.850119]\n",
      "epoch:23 step:18068[D loss: 0.424729, acc: 48.44%, op_acc: 39.84%] [G loss: 0.879092]\n",
      "epoch:23 step:18069[D loss: 0.407867, acc: 67.19%, op_acc: 37.50%] [G loss: 0.846418]\n",
      "epoch:23 step:18070[D loss: 0.415733, acc: 62.50%, op_acc: 40.62%] [G loss: 0.882899]\n",
      "epoch:23 step:18071[D loss: 0.462248, acc: 55.47%, op_acc: 39.84%] [G loss: 0.844769]\n",
      "epoch:23 step:18072[D loss: 0.421126, acc: 59.38%, op_acc: 39.06%] [G loss: 0.852594]\n",
      "epoch:23 step:18073[D loss: 0.425559, acc: 60.16%, op_acc: 40.62%] [G loss: 0.818208]\n",
      "epoch:23 step:18074[D loss: 0.442649, acc: 66.41%, op_acc: 35.16%] [G loss: 0.832888]\n",
      "epoch:23 step:18075[D loss: 0.426799, acc: 54.69%, op_acc: 41.41%] [G loss: 0.843745]\n",
      "epoch:23 step:18076[D loss: 0.457096, acc: 55.47%, op_acc: 34.38%] [G loss: 0.819930]\n",
      "epoch:23 step:18077[D loss: 0.420162, acc: 60.16%, op_acc: 43.75%] [G loss: 0.833423]\n",
      "epoch:23 step:18078[D loss: 0.407187, acc: 60.94%, op_acc: 39.06%] [G loss: 0.946226]\n",
      "epoch:23 step:18079[D loss: 0.455502, acc: 60.94%, op_acc: 33.59%] [G loss: 0.856817]\n",
      "epoch:23 step:18080[D loss: 0.437942, acc: 54.69%, op_acc: 32.81%] [G loss: 0.903651]\n",
      "epoch:23 step:18081[D loss: 0.413188, acc: 55.47%, op_acc: 39.84%] [G loss: 0.817294]\n",
      "epoch:23 step:18082[D loss: 0.439511, acc: 60.16%, op_acc: 34.38%] [G loss: 0.865010]\n",
      "epoch:23 step:18083[D loss: 0.413458, acc: 63.28%, op_acc: 37.50%] [G loss: 0.952576]\n",
      "epoch:23 step:18084[D loss: 0.392019, acc: 68.75%, op_acc: 38.28%] [G loss: 0.920231]\n",
      "epoch:23 step:18085[D loss: 0.425922, acc: 56.25%, op_acc: 35.94%] [G loss: 0.843250]\n",
      "epoch:23 step:18086[D loss: 0.444851, acc: 55.47%, op_acc: 42.19%] [G loss: 0.928644]\n",
      "epoch:23 step:18087[D loss: 0.440963, acc: 53.12%, op_acc: 39.06%] [G loss: 0.892916]\n",
      "epoch:23 step:18088[D loss: 0.431025, acc: 62.50%, op_acc: 40.62%] [G loss: 0.927059]\n",
      "epoch:23 step:18089[D loss: 0.436064, acc: 51.56%, op_acc: 42.97%] [G loss: 0.834704]\n",
      "epoch:23 step:18090[D loss: 0.429689, acc: 57.81%, op_acc: 36.72%] [G loss: 0.858882]\n",
      "epoch:23 step:18091[D loss: 0.414615, acc: 65.62%, op_acc: 43.75%] [G loss: 0.936918]\n",
      "epoch:23 step:18092[D loss: 0.436238, acc: 57.03%, op_acc: 34.38%] [G loss: 0.826628]\n",
      "epoch:23 step:18093[D loss: 0.401662, acc: 67.97%, op_acc: 36.72%] [G loss: 1.006536]\n",
      "epoch:23 step:18094[D loss: 0.405200, acc: 66.41%, op_acc: 37.50%] [G loss: 0.869034]\n",
      "epoch:23 step:18095[D loss: 0.392356, acc: 70.31%, op_acc: 38.28%] [G loss: 0.941913]\n",
      "epoch:23 step:18096[D loss: 0.449194, acc: 58.59%, op_acc: 31.25%] [G loss: 0.894202]\n",
      "epoch:23 step:18097[D loss: 0.429309, acc: 60.94%, op_acc: 36.72%] [G loss: 0.867358]\n",
      "epoch:23 step:18098[D loss: 0.436846, acc: 54.69%, op_acc: 34.38%] [G loss: 0.906255]\n",
      "epoch:23 step:18099[D loss: 0.401461, acc: 62.50%, op_acc: 41.41%] [G loss: 0.979454]\n",
      "epoch:23 step:18100[D loss: 0.418436, acc: 63.28%, op_acc: 37.50%] [G loss: 0.963162]\n",
      "epoch:23 step:18101[D loss: 0.469118, acc: 53.12%, op_acc: 37.50%] [G loss: 0.876928]\n",
      "epoch:23 step:18102[D loss: 0.413938, acc: 61.72%, op_acc: 40.62%] [G loss: 0.906459]\n",
      "epoch:23 step:18103[D loss: 0.479209, acc: 52.34%, op_acc: 36.72%] [G loss: 0.862707]\n",
      "epoch:23 step:18104[D loss: 0.435793, acc: 53.91%, op_acc: 36.72%] [G loss: 0.870571]\n",
      "epoch:23 step:18105[D loss: 0.455523, acc: 51.56%, op_acc: 38.28%] [G loss: 0.835137]\n",
      "epoch:23 step:18106[D loss: 0.437565, acc: 55.47%, op_acc: 36.72%] [G loss: 0.913017]\n",
      "epoch:23 step:18107[D loss: 0.417384, acc: 61.72%, op_acc: 39.84%] [G loss: 0.913480]\n",
      "epoch:23 step:18108[D loss: 0.434887, acc: 60.16%, op_acc: 37.50%] [G loss: 0.858954]\n",
      "epoch:23 step:18109[D loss: 0.440078, acc: 57.03%, op_acc: 31.25%] [G loss: 0.944693]\n",
      "epoch:23 step:18110[D loss: 0.385583, acc: 69.53%, op_acc: 42.97%] [G loss: 0.891399]\n",
      "epoch:23 step:18111[D loss: 0.432567, acc: 59.38%, op_acc: 36.72%] [G loss: 0.944558]\n",
      "epoch:23 step:18112[D loss: 0.383248, acc: 64.84%, op_acc: 46.09%] [G loss: 0.884988]\n",
      "epoch:23 step:18113[D loss: 0.415636, acc: 57.03%, op_acc: 41.41%] [G loss: 0.918516]\n",
      "epoch:23 step:18114[D loss: 0.385235, acc: 67.19%, op_acc: 42.19%] [G loss: 0.905150]\n",
      "epoch:23 step:18115[D loss: 0.397827, acc: 65.62%, op_acc: 41.41%] [G loss: 0.817089]\n",
      "epoch:23 step:18116[D loss: 0.428492, acc: 60.16%, op_acc: 36.72%] [G loss: 0.892095]\n",
      "epoch:23 step:18117[D loss: 0.417672, acc: 63.28%, op_acc: 30.47%] [G loss: 0.869762]\n",
      "epoch:23 step:18118[D loss: 0.428642, acc: 64.84%, op_acc: 35.94%] [G loss: 0.916206]\n",
      "epoch:23 step:18119[D loss: 0.464834, acc: 50.78%, op_acc: 39.84%] [G loss: 0.815859]\n",
      "epoch:23 step:18120[D loss: 0.444728, acc: 56.25%, op_acc: 37.50%] [G loss: 0.812989]\n",
      "epoch:23 step:18121[D loss: 0.411937, acc: 60.16%, op_acc: 42.19%] [G loss: 0.866888]\n",
      "epoch:23 step:18122[D loss: 0.454156, acc: 54.69%, op_acc: 32.81%] [G loss: 0.928773]\n",
      "epoch:23 step:18123[D loss: 0.412545, acc: 64.84%, op_acc: 37.50%] [G loss: 0.903341]\n",
      "epoch:23 step:18124[D loss: 0.427665, acc: 55.47%, op_acc: 40.62%] [G loss: 0.922060]\n",
      "epoch:23 step:18125[D loss: 0.419350, acc: 54.69%, op_acc: 41.41%] [G loss: 0.862980]\n",
      "epoch:23 step:18126[D loss: 0.449318, acc: 59.38%, op_acc: 39.84%] [G loss: 0.850443]\n",
      "epoch:23 step:18127[D loss: 0.421801, acc: 67.19%, op_acc: 35.16%] [G loss: 0.894520]\n",
      "epoch:23 step:18128[D loss: 0.396163, acc: 63.28%, op_acc: 41.41%] [G loss: 0.884720]\n",
      "epoch:23 step:18129[D loss: 0.456129, acc: 54.69%, op_acc: 32.03%] [G loss: 0.859575]\n",
      "epoch:23 step:18130[D loss: 0.435238, acc: 56.25%, op_acc: 39.84%] [G loss: 0.831535]\n",
      "epoch:23 step:18131[D loss: 0.442833, acc: 51.56%, op_acc: 42.19%] [G loss: 0.890523]\n",
      "epoch:23 step:18132[D loss: 0.414913, acc: 60.16%, op_acc: 41.41%] [G loss: 0.844424]\n",
      "epoch:23 step:18133[D loss: 0.463551, acc: 51.56%, op_acc: 38.28%] [G loss: 0.871833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18134[D loss: 0.438768, acc: 60.94%, op_acc: 38.28%] [G loss: 0.815546]\n",
      "epoch:23 step:18135[D loss: 0.411227, acc: 64.84%, op_acc: 38.28%] [G loss: 0.966153]\n",
      "epoch:23 step:18136[D loss: 0.430729, acc: 63.28%, op_acc: 35.16%] [G loss: 0.886275]\n",
      "epoch:23 step:18137[D loss: 0.475860, acc: 46.88%, op_acc: 33.59%] [G loss: 0.903084]\n",
      "epoch:23 step:18138[D loss: 0.410378, acc: 64.84%, op_acc: 38.28%] [G loss: 0.850604]\n",
      "epoch:23 step:18139[D loss: 0.432213, acc: 59.38%, op_acc: 42.97%] [G loss: 0.931919]\n",
      "epoch:23 step:18140[D loss: 0.397938, acc: 68.75%, op_acc: 36.72%] [G loss: 0.909509]\n",
      "epoch:23 step:18141[D loss: 0.459283, acc: 60.94%, op_acc: 31.25%] [G loss: 0.941278]\n",
      "epoch:23 step:18142[D loss: 0.407751, acc: 63.28%, op_acc: 43.75%] [G loss: 0.865213]\n",
      "epoch:23 step:18143[D loss: 0.394753, acc: 64.06%, op_acc: 39.06%] [G loss: 0.894327]\n",
      "epoch:23 step:18144[D loss: 0.423895, acc: 60.16%, op_acc: 39.84%] [G loss: 0.920966]\n",
      "epoch:23 step:18145[D loss: 0.409098, acc: 57.81%, op_acc: 41.41%] [G loss: 0.828277]\n",
      "epoch:23 step:18146[D loss: 0.431727, acc: 62.50%, op_acc: 32.81%] [G loss: 0.874042]\n",
      "epoch:23 step:18147[D loss: 0.390762, acc: 65.62%, op_acc: 38.28%] [G loss: 0.879201]\n",
      "epoch:23 step:18148[D loss: 0.417883, acc: 61.72%, op_acc: 39.06%] [G loss: 0.841565]\n",
      "epoch:23 step:18149[D loss: 0.431358, acc: 57.03%, op_acc: 41.41%] [G loss: 0.897152]\n",
      "epoch:23 step:18150[D loss: 0.437685, acc: 58.59%, op_acc: 37.50%] [G loss: 0.812151]\n",
      "epoch:23 step:18151[D loss: 0.425141, acc: 56.25%, op_acc: 46.88%] [G loss: 0.914626]\n",
      "epoch:23 step:18152[D loss: 0.437882, acc: 61.72%, op_acc: 36.72%] [G loss: 0.906905]\n",
      "epoch:23 step:18153[D loss: 0.433684, acc: 57.03%, op_acc: 37.50%] [G loss: 0.859162]\n",
      "epoch:23 step:18154[D loss: 0.425014, acc: 53.91%, op_acc: 39.06%] [G loss: 0.870160]\n",
      "epoch:23 step:18155[D loss: 0.421451, acc: 60.16%, op_acc: 36.72%] [G loss: 0.898996]\n",
      "epoch:23 step:18156[D loss: 0.445551, acc: 54.69%, op_acc: 38.28%] [G loss: 0.996197]\n",
      "epoch:23 step:18157[D loss: 0.434026, acc: 55.47%, op_acc: 38.28%] [G loss: 0.848981]\n",
      "epoch:23 step:18158[D loss: 0.433538, acc: 57.03%, op_acc: 35.16%] [G loss: 0.872173]\n",
      "epoch:23 step:18159[D loss: 0.416767, acc: 61.72%, op_acc: 33.59%] [G loss: 0.961272]\n",
      "epoch:23 step:18160[D loss: 0.432544, acc: 60.16%, op_acc: 40.62%] [G loss: 0.842722]\n",
      "epoch:23 step:18161[D loss: 0.437089, acc: 57.03%, op_acc: 35.94%] [G loss: 0.841460]\n",
      "epoch:23 step:18162[D loss: 0.412872, acc: 64.06%, op_acc: 35.94%] [G loss: 0.904238]\n",
      "epoch:23 step:18163[D loss: 0.403310, acc: 68.75%, op_acc: 37.50%] [G loss: 0.913462]\n",
      "epoch:23 step:18164[D loss: 0.425361, acc: 55.47%, op_acc: 39.84%] [G loss: 0.918319]\n",
      "epoch:23 step:18165[D loss: 0.438546, acc: 61.72%, op_acc: 40.62%] [G loss: 0.824939]\n",
      "epoch:23 step:18166[D loss: 0.466686, acc: 53.91%, op_acc: 35.16%] [G loss: 0.797362]\n",
      "epoch:23 step:18167[D loss: 0.436731, acc: 58.59%, op_acc: 41.41%] [G loss: 0.829124]\n",
      "epoch:23 step:18168[D loss: 0.418829, acc: 59.38%, op_acc: 36.72%] [G loss: 0.793724]\n",
      "epoch:23 step:18169[D loss: 0.426216, acc: 57.03%, op_acc: 39.84%] [G loss: 0.802118]\n",
      "epoch:23 step:18170[D loss: 0.412378, acc: 61.72%, op_acc: 41.41%] [G loss: 0.869774]\n",
      "epoch:23 step:18171[D loss: 0.405465, acc: 63.28%, op_acc: 37.50%] [G loss: 0.895743]\n",
      "epoch:23 step:18172[D loss: 0.422081, acc: 62.50%, op_acc: 36.72%] [G loss: 0.935820]\n",
      "epoch:23 step:18173[D loss: 0.439814, acc: 57.03%, op_acc: 38.28%] [G loss: 0.859003]\n",
      "epoch:23 step:18174[D loss: 0.410924, acc: 64.06%, op_acc: 45.31%] [G loss: 0.893473]\n",
      "epoch:23 step:18175[D loss: 0.436656, acc: 50.78%, op_acc: 37.50%] [G loss: 0.825624]\n",
      "epoch:23 step:18176[D loss: 0.424251, acc: 60.16%, op_acc: 42.19%] [G loss: 0.889172]\n",
      "epoch:23 step:18177[D loss: 0.425703, acc: 62.50%, op_acc: 37.50%] [G loss: 0.857616]\n",
      "epoch:23 step:18178[D loss: 0.434467, acc: 53.12%, op_acc: 39.84%] [G loss: 0.856214]\n",
      "epoch:23 step:18179[D loss: 0.417916, acc: 63.28%, op_acc: 40.62%] [G loss: 0.898139]\n",
      "epoch:23 step:18180[D loss: 0.409756, acc: 58.59%, op_acc: 40.62%] [G loss: 0.846671]\n",
      "epoch:23 step:18181[D loss: 0.416780, acc: 61.72%, op_acc: 39.84%] [G loss: 0.857702]\n",
      "epoch:23 step:18182[D loss: 0.399835, acc: 61.72%, op_acc: 42.97%] [G loss: 0.949489]\n",
      "epoch:23 step:18183[D loss: 0.440404, acc: 53.91%, op_acc: 38.28%] [G loss: 0.852309]\n",
      "epoch:23 step:18184[D loss: 0.408718, acc: 60.16%, op_acc: 39.84%] [G loss: 0.773402]\n",
      "epoch:23 step:18185[D loss: 0.421799, acc: 58.59%, op_acc: 38.28%] [G loss: 0.853515]\n",
      "epoch:23 step:18186[D loss: 0.432337, acc: 53.12%, op_acc: 39.84%] [G loss: 0.865832]\n",
      "epoch:23 step:18187[D loss: 0.405197, acc: 60.16%, op_acc: 41.41%] [G loss: 0.822703]\n",
      "epoch:23 step:18188[D loss: 0.405242, acc: 64.84%, op_acc: 41.41%] [G loss: 0.928259]\n",
      "epoch:23 step:18189[D loss: 0.444776, acc: 53.12%, op_acc: 40.62%] [G loss: 0.842611]\n",
      "epoch:23 step:18190[D loss: 0.403872, acc: 60.94%, op_acc: 42.19%] [G loss: 0.928693]\n",
      "epoch:23 step:18191[D loss: 0.420438, acc: 51.56%, op_acc: 39.06%] [G loss: 0.834252]\n",
      "epoch:23 step:18192[D loss: 0.446784, acc: 52.34%, op_acc: 35.16%] [G loss: 0.915357]\n",
      "epoch:23 step:18193[D loss: 0.483350, acc: 48.44%, op_acc: 38.28%] [G loss: 0.868752]\n",
      "epoch:23 step:18194[D loss: 0.390857, acc: 64.06%, op_acc: 44.53%] [G loss: 0.886802]\n",
      "epoch:23 step:18195[D loss: 0.432200, acc: 58.59%, op_acc: 41.41%] [G loss: 0.842243]\n",
      "epoch:23 step:18196[D loss: 0.395723, acc: 69.53%, op_acc: 40.62%] [G loss: 0.943405]\n",
      "epoch:23 step:18197[D loss: 0.418738, acc: 65.62%, op_acc: 30.47%] [G loss: 0.927232]\n",
      "epoch:23 step:18198[D loss: 0.429430, acc: 55.47%, op_acc: 38.28%] [G loss: 0.788363]\n",
      "epoch:23 step:18199[D loss: 0.447099, acc: 52.34%, op_acc: 39.06%] [G loss: 0.933809]\n",
      "epoch:23 step:18200[D loss: 0.410322, acc: 59.38%, op_acc: 39.06%] [G loss: 0.863592]\n",
      "epoch:23 step:18201[D loss: 0.450558, acc: 51.56%, op_acc: 37.50%] [G loss: 0.851755]\n",
      "epoch:23 step:18202[D loss: 0.438044, acc: 55.47%, op_acc: 38.28%] [G loss: 0.912657]\n",
      "epoch:23 step:18203[D loss: 0.422885, acc: 57.03%, op_acc: 39.84%] [G loss: 0.941884]\n",
      "epoch:23 step:18204[D loss: 0.429057, acc: 60.94%, op_acc: 37.50%] [G loss: 0.943986]\n",
      "epoch:23 step:18205[D loss: 0.373488, acc: 71.88%, op_acc: 40.62%] [G loss: 0.930650]\n",
      "epoch:23 step:18206[D loss: 0.423777, acc: 51.56%, op_acc: 44.53%] [G loss: 0.922024]\n",
      "epoch:23 step:18207[D loss: 0.430208, acc: 60.94%, op_acc: 38.28%] [G loss: 0.879361]\n",
      "epoch:23 step:18208[D loss: 0.432021, acc: 57.81%, op_acc: 38.28%] [G loss: 0.810528]\n",
      "epoch:23 step:18209[D loss: 0.447950, acc: 60.16%, op_acc: 39.84%] [G loss: 0.828775]\n",
      "epoch:23 step:18210[D loss: 0.439612, acc: 50.78%, op_acc: 40.62%] [G loss: 0.804280]\n",
      "epoch:23 step:18211[D loss: 0.419088, acc: 60.94%, op_acc: 35.16%] [G loss: 0.879970]\n",
      "epoch:23 step:18212[D loss: 0.442777, acc: 58.59%, op_acc: 39.06%] [G loss: 0.763192]\n",
      "epoch:23 step:18213[D loss: 0.443011, acc: 50.78%, op_acc: 38.28%] [G loss: 0.850108]\n",
      "epoch:23 step:18214[D loss: 0.423084, acc: 57.81%, op_acc: 41.41%] [G loss: 0.852054]\n",
      "epoch:23 step:18215[D loss: 0.438118, acc: 57.03%, op_acc: 39.84%] [G loss: 0.856515]\n",
      "epoch:23 step:18216[D loss: 0.425628, acc: 57.81%, op_acc: 35.16%] [G loss: 0.822888]\n",
      "epoch:23 step:18217[D loss: 0.441195, acc: 59.38%, op_acc: 35.16%] [G loss: 0.894115]\n",
      "epoch:23 step:18218[D loss: 0.422039, acc: 62.50%, op_acc: 37.50%] [G loss: 0.886015]\n",
      "epoch:23 step:18219[D loss: 0.402545, acc: 67.19%, op_acc: 38.28%] [G loss: 0.865707]\n",
      "epoch:23 step:18220[D loss: 0.431610, acc: 62.50%, op_acc: 35.16%] [G loss: 0.893212]\n",
      "epoch:23 step:18221[D loss: 0.420487, acc: 58.59%, op_acc: 41.41%] [G loss: 0.838248]\n",
      "epoch:23 step:18222[D loss: 0.441537, acc: 61.72%, op_acc: 34.38%] [G loss: 0.918027]\n",
      "epoch:23 step:18223[D loss: 0.425126, acc: 67.97%, op_acc: 35.94%] [G loss: 0.935907]\n",
      "epoch:23 step:18224[D loss: 0.430673, acc: 52.34%, op_acc: 35.16%] [G loss: 0.999037]\n",
      "epoch:23 step:18225[D loss: 0.423979, acc: 56.25%, op_acc: 39.84%] [G loss: 0.891137]\n",
      "epoch:23 step:18226[D loss: 0.416431, acc: 66.41%, op_acc: 39.84%] [G loss: 0.864336]\n",
      "epoch:23 step:18227[D loss: 0.433059, acc: 57.03%, op_acc: 38.28%] [G loss: 0.903413]\n",
      "epoch:23 step:18228[D loss: 0.414014, acc: 60.94%, op_acc: 38.28%] [G loss: 0.887175]\n",
      "epoch:23 step:18229[D loss: 0.426557, acc: 59.38%, op_acc: 39.06%] [G loss: 0.828751]\n",
      "epoch:23 step:18230[D loss: 0.407515, acc: 60.16%, op_acc: 45.31%] [G loss: 0.986800]\n",
      "epoch:23 step:18231[D loss: 0.413856, acc: 56.25%, op_acc: 36.72%] [G loss: 0.895424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18232[D loss: 0.436025, acc: 57.81%, op_acc: 39.84%] [G loss: 0.833547]\n",
      "epoch:23 step:18233[D loss: 0.425647, acc: 62.50%, op_acc: 35.94%] [G loss: 0.807959]\n",
      "epoch:23 step:18234[D loss: 0.447462, acc: 58.59%, op_acc: 35.16%] [G loss: 0.890469]\n",
      "epoch:23 step:18235[D loss: 0.412249, acc: 64.84%, op_acc: 36.72%] [G loss: 0.858630]\n",
      "epoch:23 step:18236[D loss: 0.409824, acc: 61.72%, op_acc: 40.62%] [G loss: 0.903688]\n",
      "epoch:23 step:18237[D loss: 0.432023, acc: 50.78%, op_acc: 42.97%] [G loss: 0.869447]\n",
      "epoch:23 step:18238[D loss: 0.442877, acc: 51.56%, op_acc: 35.94%] [G loss: 0.916750]\n",
      "epoch:23 step:18239[D loss: 0.413425, acc: 56.25%, op_acc: 45.31%] [G loss: 0.911641]\n",
      "epoch:23 step:18240[D loss: 0.444359, acc: 54.69%, op_acc: 30.47%] [G loss: 0.951999]\n",
      "epoch:23 step:18241[D loss: 0.428276, acc: 58.59%, op_acc: 35.94%] [G loss: 0.897643]\n",
      "epoch:23 step:18242[D loss: 0.414104, acc: 63.28%, op_acc: 41.41%] [G loss: 0.896928]\n",
      "epoch:23 step:18243[D loss: 0.426161, acc: 59.38%, op_acc: 36.72%] [G loss: 0.786140]\n",
      "epoch:23 step:18244[D loss: 0.433541, acc: 59.38%, op_acc: 39.06%] [G loss: 0.861119]\n",
      "epoch:23 step:18245[D loss: 0.423502, acc: 64.84%, op_acc: 38.28%] [G loss: 0.872248]\n",
      "epoch:23 step:18246[D loss: 0.397043, acc: 62.50%, op_acc: 45.31%] [G loss: 0.878588]\n",
      "epoch:23 step:18247[D loss: 0.432117, acc: 57.81%, op_acc: 39.84%] [G loss: 0.818205]\n",
      "epoch:23 step:18248[D loss: 0.452372, acc: 57.81%, op_acc: 33.59%] [G loss: 0.796614]\n",
      "epoch:23 step:18249[D loss: 0.447135, acc: 54.69%, op_acc: 32.81%] [G loss: 0.853827]\n",
      "epoch:23 step:18250[D loss: 0.429524, acc: 60.16%, op_acc: 42.19%] [G loss: 0.919869]\n",
      "epoch:23 step:18251[D loss: 0.402971, acc: 59.38%, op_acc: 37.50%] [G loss: 0.847404]\n",
      "epoch:23 step:18252[D loss: 0.432655, acc: 60.16%, op_acc: 37.50%] [G loss: 0.868199]\n",
      "epoch:23 step:18253[D loss: 0.409564, acc: 62.50%, op_acc: 35.94%] [G loss: 0.876429]\n",
      "epoch:23 step:18254[D loss: 0.421743, acc: 61.72%, op_acc: 43.75%] [G loss: 0.868049]\n",
      "epoch:23 step:18255[D loss: 0.446443, acc: 57.03%, op_acc: 39.84%] [G loss: 0.800804]\n",
      "epoch:23 step:18256[D loss: 0.414733, acc: 65.62%, op_acc: 38.28%] [G loss: 0.882811]\n",
      "epoch:23 step:18257[D loss: 0.424192, acc: 67.19%, op_acc: 39.84%] [G loss: 0.942683]\n",
      "epoch:23 step:18258[D loss: 0.397133, acc: 64.84%, op_acc: 39.06%] [G loss: 0.917624]\n",
      "epoch:23 step:18259[D loss: 0.420766, acc: 60.16%, op_acc: 40.62%] [G loss: 0.868893]\n",
      "epoch:23 step:18260[D loss: 0.429900, acc: 64.06%, op_acc: 36.72%] [G loss: 0.870672]\n",
      "epoch:23 step:18261[D loss: 0.388885, acc: 66.41%, op_acc: 41.41%] [G loss: 0.882475]\n",
      "epoch:23 step:18262[D loss: 0.412901, acc: 58.59%, op_acc: 40.62%] [G loss: 0.892928]\n",
      "epoch:23 step:18263[D loss: 0.435676, acc: 63.28%, op_acc: 29.69%] [G loss: 0.910389]\n",
      "epoch:23 step:18264[D loss: 0.422040, acc: 60.16%, op_acc: 39.06%] [G loss: 0.979265]\n",
      "epoch:23 step:18265[D loss: 0.397745, acc: 64.84%, op_acc: 44.53%] [G loss: 0.926548]\n",
      "epoch:23 step:18266[D loss: 0.428404, acc: 58.59%, op_acc: 35.94%] [G loss: 0.844630]\n",
      "epoch:23 step:18267[D loss: 0.398844, acc: 62.50%, op_acc: 42.97%] [G loss: 0.911970]\n",
      "epoch:23 step:18268[D loss: 0.413548, acc: 55.47%, op_acc: 40.62%] [G loss: 0.888394]\n",
      "epoch:23 step:18269[D loss: 0.425871, acc: 56.25%, op_acc: 39.84%] [G loss: 0.908465]\n",
      "epoch:23 step:18270[D loss: 0.396929, acc: 66.41%, op_acc: 36.72%] [G loss: 0.881520]\n",
      "epoch:23 step:18271[D loss: 0.410139, acc: 67.97%, op_acc: 39.06%] [G loss: 0.956144]\n",
      "epoch:23 step:18272[D loss: 0.438207, acc: 64.06%, op_acc: 37.50%] [G loss: 0.848488]\n",
      "epoch:23 step:18273[D loss: 0.425884, acc: 64.84%, op_acc: 37.50%] [G loss: 0.728383]\n",
      "epoch:23 step:18274[D loss: 0.448505, acc: 54.69%, op_acc: 38.28%] [G loss: 0.846695]\n",
      "epoch:23 step:18275[D loss: 0.458458, acc: 55.47%, op_acc: 39.84%] [G loss: 0.917475]\n",
      "epoch:23 step:18276[D loss: 0.428874, acc: 62.50%, op_acc: 36.72%] [G loss: 0.893349]\n",
      "epoch:23 step:18277[D loss: 0.434844, acc: 53.91%, op_acc: 40.62%] [G loss: 0.824388]\n",
      "epoch:23 step:18278[D loss: 0.445005, acc: 56.25%, op_acc: 36.72%] [G loss: 0.848013]\n",
      "epoch:23 step:18279[D loss: 0.439788, acc: 58.59%, op_acc: 37.50%] [G loss: 0.836695]\n",
      "epoch:23 step:18280[D loss: 0.421722, acc: 61.72%, op_acc: 38.28%] [G loss: 0.891261]\n",
      "epoch:23 step:18281[D loss: 0.465840, acc: 55.47%, op_acc: 33.59%] [G loss: 0.859960]\n",
      "epoch:23 step:18282[D loss: 0.403392, acc: 54.69%, op_acc: 36.72%] [G loss: 0.869026]\n",
      "epoch:23 step:18283[D loss: 0.456470, acc: 52.34%, op_acc: 37.50%] [G loss: 0.804749]\n",
      "epoch:23 step:18284[D loss: 0.426656, acc: 56.25%, op_acc: 39.84%] [G loss: 0.864501]\n",
      "epoch:23 step:18285[D loss: 0.414743, acc: 60.16%, op_acc: 40.62%] [G loss: 0.876066]\n",
      "epoch:23 step:18286[D loss: 0.414750, acc: 58.59%, op_acc: 43.75%] [G loss: 0.839389]\n",
      "epoch:23 step:18287[D loss: 0.430961, acc: 61.72%, op_acc: 39.06%] [G loss: 0.919843]\n",
      "epoch:23 step:18288[D loss: 0.400675, acc: 65.62%, op_acc: 45.31%] [G loss: 0.879687]\n",
      "epoch:23 step:18289[D loss: 0.413409, acc: 63.28%, op_acc: 44.53%] [G loss: 0.963458]\n",
      "epoch:23 step:18290[D loss: 0.411673, acc: 64.06%, op_acc: 33.59%] [G loss: 0.868123]\n",
      "epoch:23 step:18291[D loss: 0.414272, acc: 60.94%, op_acc: 39.84%] [G loss: 0.913108]\n",
      "epoch:23 step:18292[D loss: 0.431749, acc: 60.94%, op_acc: 40.62%] [G loss: 0.843519]\n",
      "epoch:23 step:18293[D loss: 0.409578, acc: 60.94%, op_acc: 40.62%] [G loss: 0.877276]\n",
      "epoch:23 step:18294[D loss: 0.415388, acc: 64.84%, op_acc: 42.19%] [G loss: 0.946213]\n",
      "epoch:23 step:18295[D loss: 0.405859, acc: 64.84%, op_acc: 38.28%] [G loss: 0.891075]\n",
      "epoch:23 step:18296[D loss: 0.412411, acc: 62.50%, op_acc: 39.06%] [G loss: 0.800888]\n",
      "epoch:23 step:18297[D loss: 0.376679, acc: 66.41%, op_acc: 39.06%] [G loss: 0.940694]\n",
      "epoch:23 step:18298[D loss: 0.407248, acc: 67.19%, op_acc: 42.97%] [G loss: 0.940970]\n",
      "epoch:23 step:18299[D loss: 0.458402, acc: 54.69%, op_acc: 35.94%] [G loss: 0.915002]\n",
      "epoch:23 step:18300[D loss: 0.440953, acc: 57.81%, op_acc: 33.59%] [G loss: 0.943823]\n",
      "epoch:23 step:18301[D loss: 0.388187, acc: 63.28%, op_acc: 45.31%] [G loss: 0.848485]\n",
      "epoch:23 step:18302[D loss: 0.427445, acc: 60.94%, op_acc: 39.06%] [G loss: 0.913034]\n",
      "epoch:23 step:18303[D loss: 0.452624, acc: 51.56%, op_acc: 38.28%] [G loss: 0.844964]\n",
      "epoch:23 step:18304[D loss: 0.427578, acc: 67.19%, op_acc: 35.94%] [G loss: 0.929364]\n",
      "epoch:23 step:18305[D loss: 0.474302, acc: 48.44%, op_acc: 30.47%] [G loss: 0.854786]\n",
      "epoch:23 step:18306[D loss: 0.453258, acc: 53.91%, op_acc: 37.50%] [G loss: 0.794333]\n",
      "epoch:23 step:18307[D loss: 0.439941, acc: 48.44%, op_acc: 45.31%] [G loss: 0.779188]\n",
      "epoch:23 step:18308[D loss: 0.407795, acc: 62.50%, op_acc: 43.75%] [G loss: 0.851844]\n",
      "epoch:23 step:18309[D loss: 0.463654, acc: 47.66%, op_acc: 38.28%] [G loss: 0.856434]\n",
      "epoch:23 step:18310[D loss: 0.453041, acc: 53.12%, op_acc: 37.50%] [G loss: 0.838001]\n",
      "epoch:23 step:18311[D loss: 0.405130, acc: 60.16%, op_acc: 41.41%] [G loss: 0.917224]\n",
      "epoch:23 step:18312[D loss: 0.458045, acc: 51.56%, op_acc: 40.62%] [G loss: 0.858363]\n",
      "epoch:23 step:18313[D loss: 0.425490, acc: 59.38%, op_acc: 35.94%] [G loss: 0.793100]\n",
      "epoch:23 step:18314[D loss: 0.457050, acc: 53.91%, op_acc: 38.28%] [G loss: 0.818180]\n",
      "epoch:23 step:18315[D loss: 0.432896, acc: 57.03%, op_acc: 38.28%] [G loss: 0.845684]\n",
      "epoch:23 step:18316[D loss: 0.424881, acc: 59.38%, op_acc: 39.84%] [G loss: 0.913067]\n",
      "epoch:23 step:18317[D loss: 0.436265, acc: 52.34%, op_acc: 38.28%] [G loss: 0.927713]\n",
      "epoch:23 step:18318[D loss: 0.460352, acc: 50.78%, op_acc: 42.97%] [G loss: 0.924196]\n",
      "epoch:23 step:18319[D loss: 0.410358, acc: 64.84%, op_acc: 37.50%] [G loss: 0.938935]\n",
      "epoch:23 step:18320[D loss: 0.445545, acc: 57.03%, op_acc: 40.62%] [G loss: 0.823734]\n",
      "epoch:23 step:18321[D loss: 0.427537, acc: 67.19%, op_acc: 35.16%] [G loss: 0.864441]\n",
      "epoch:23 step:18322[D loss: 0.409030, acc: 63.28%, op_acc: 36.72%] [G loss: 0.855668]\n",
      "epoch:23 step:18323[D loss: 0.417664, acc: 63.28%, op_acc: 39.06%] [G loss: 0.894615]\n",
      "epoch:23 step:18324[D loss: 0.393314, acc: 67.19%, op_acc: 40.62%] [G loss: 0.901729]\n",
      "epoch:23 step:18325[D loss: 0.390364, acc: 66.41%, op_acc: 39.84%] [G loss: 0.835288]\n",
      "epoch:23 step:18326[D loss: 0.430546, acc: 61.72%, op_acc: 38.28%] [G loss: 0.831040]\n",
      "epoch:23 step:18327[D loss: 0.427385, acc: 53.91%, op_acc: 39.06%] [G loss: 0.855263]\n",
      "epoch:23 step:18328[D loss: 0.385163, acc: 68.75%, op_acc: 40.62%] [G loss: 0.881737]\n",
      "epoch:23 step:18329[D loss: 0.422555, acc: 65.62%, op_acc: 37.50%] [G loss: 0.925462]\n",
      "epoch:23 step:18330[D loss: 0.433019, acc: 63.28%, op_acc: 41.41%] [G loss: 0.860273]\n",
      "epoch:23 step:18331[D loss: 0.444802, acc: 60.16%, op_acc: 37.50%] [G loss: 0.918210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18332[D loss: 0.409699, acc: 63.28%, op_acc: 36.72%] [G loss: 0.871530]\n",
      "epoch:23 step:18333[D loss: 0.408617, acc: 61.72%, op_acc: 39.06%] [G loss: 0.969026]\n",
      "epoch:23 step:18334[D loss: 0.411330, acc: 54.69%, op_acc: 38.28%] [G loss: 0.806646]\n",
      "epoch:23 step:18335[D loss: 0.436627, acc: 57.03%, op_acc: 39.06%] [G loss: 0.870435]\n",
      "epoch:23 step:18336[D loss: 0.412292, acc: 59.38%, op_acc: 44.53%] [G loss: 0.802062]\n",
      "epoch:23 step:18337[D loss: 0.411746, acc: 57.03%, op_acc: 41.41%] [G loss: 0.936229]\n",
      "epoch:23 step:18338[D loss: 0.390238, acc: 64.06%, op_acc: 41.41%] [G loss: 0.871704]\n",
      "epoch:23 step:18339[D loss: 0.435273, acc: 52.34%, op_acc: 36.72%] [G loss: 0.870915]\n",
      "epoch:23 step:18340[D loss: 0.408944, acc: 60.94%, op_acc: 39.84%] [G loss: 0.867567]\n",
      "epoch:23 step:18341[D loss: 0.396765, acc: 62.50%, op_acc: 42.97%] [G loss: 0.921267]\n",
      "epoch:23 step:18342[D loss: 0.415068, acc: 66.41%, op_acc: 36.72%] [G loss: 0.850501]\n",
      "epoch:23 step:18343[D loss: 0.430347, acc: 56.25%, op_acc: 36.72%] [G loss: 0.877606]\n",
      "epoch:23 step:18344[D loss: 0.430397, acc: 63.28%, op_acc: 35.94%] [G loss: 0.887544]\n",
      "epoch:23 step:18345[D loss: 0.438931, acc: 53.91%, op_acc: 37.50%] [G loss: 0.847753]\n",
      "epoch:23 step:18346[D loss: 0.438320, acc: 57.81%, op_acc: 39.84%] [G loss: 0.943631]\n",
      "epoch:23 step:18347[D loss: 0.428636, acc: 57.03%, op_acc: 40.62%] [G loss: 0.952964]\n",
      "epoch:23 step:18348[D loss: 0.390133, acc: 62.50%, op_acc: 46.09%] [G loss: 0.967488]\n",
      "epoch:23 step:18349[D loss: 0.429751, acc: 60.94%, op_acc: 34.38%] [G loss: 0.911675]\n",
      "epoch:23 step:18350[D loss: 0.452279, acc: 53.12%, op_acc: 38.28%] [G loss: 0.888536]\n",
      "epoch:23 step:18351[D loss: 0.470523, acc: 49.22%, op_acc: 37.50%] [G loss: 0.925250]\n",
      "epoch:23 step:18352[D loss: 0.438741, acc: 55.47%, op_acc: 39.06%] [G loss: 0.920856]\n",
      "epoch:23 step:18353[D loss: 0.417533, acc: 62.50%, op_acc: 38.28%] [G loss: 0.941699]\n",
      "epoch:23 step:18354[D loss: 0.412822, acc: 60.94%, op_acc: 42.19%] [G loss: 0.895410]\n",
      "epoch:23 step:18355[D loss: 0.412414, acc: 58.59%, op_acc: 46.09%] [G loss: 0.871833]\n",
      "epoch:23 step:18356[D loss: 0.426155, acc: 57.03%, op_acc: 41.41%] [G loss: 0.929298]\n",
      "epoch:23 step:18357[D loss: 0.438536, acc: 55.47%, op_acc: 35.16%] [G loss: 0.901147]\n",
      "epoch:23 step:18358[D loss: 0.437935, acc: 60.94%, op_acc: 34.38%] [G loss: 0.838717]\n",
      "epoch:23 step:18359[D loss: 0.410020, acc: 60.94%, op_acc: 42.19%] [G loss: 0.856037]\n",
      "epoch:23 step:18360[D loss: 0.392461, acc: 64.84%, op_acc: 44.53%] [G loss: 0.922790]\n",
      "epoch:23 step:18361[D loss: 0.439091, acc: 55.47%, op_acc: 37.50%] [G loss: 0.889650]\n",
      "epoch:23 step:18362[D loss: 0.423452, acc: 56.25%, op_acc: 40.62%] [G loss: 0.869917]\n",
      "epoch:23 step:18363[D loss: 0.394113, acc: 60.94%, op_acc: 49.22%] [G loss: 0.865894]\n",
      "epoch:23 step:18364[D loss: 0.410425, acc: 63.28%, op_acc: 40.62%] [G loss: 0.830590]\n",
      "epoch:23 step:18365[D loss: 0.442880, acc: 63.28%, op_acc: 34.38%] [G loss: 0.958109]\n",
      "epoch:23 step:18366[D loss: 0.401431, acc: 61.72%, op_acc: 42.19%] [G loss: 1.022239]\n",
      "epoch:23 step:18367[D loss: 0.397014, acc: 59.38%, op_acc: 46.88%] [G loss: 0.810348]\n",
      "epoch:23 step:18368[D loss: 0.424265, acc: 64.84%, op_acc: 42.19%] [G loss: 0.939904]\n",
      "epoch:23 step:18369[D loss: 0.430486, acc: 58.59%, op_acc: 35.16%] [G loss: 0.934934]\n",
      "epoch:23 step:18370[D loss: 0.372588, acc: 67.19%, op_acc: 46.88%] [G loss: 0.914445]\n",
      "epoch:23 step:18371[D loss: 0.413664, acc: 55.47%, op_acc: 39.84%] [G loss: 0.968465]\n",
      "epoch:23 step:18372[D loss: 0.418215, acc: 56.25%, op_acc: 42.19%] [G loss: 0.896044]\n",
      "epoch:23 step:18373[D loss: 0.410436, acc: 59.38%, op_acc: 41.41%] [G loss: 0.886423]\n",
      "epoch:23 step:18374[D loss: 0.458821, acc: 53.12%, op_acc: 34.38%] [G loss: 0.855378]\n",
      "epoch:23 step:18375[D loss: 0.421488, acc: 61.72%, op_acc: 45.31%] [G loss: 0.876802]\n",
      "epoch:23 step:18376[D loss: 0.459379, acc: 53.91%, op_acc: 38.28%] [G loss: 0.774882]\n",
      "epoch:23 step:18377[D loss: 0.392541, acc: 63.28%, op_acc: 39.06%] [G loss: 0.840013]\n",
      "epoch:23 step:18378[D loss: 0.421104, acc: 60.16%, op_acc: 39.84%] [G loss: 0.889079]\n",
      "epoch:23 step:18379[D loss: 0.435935, acc: 57.03%, op_acc: 41.41%] [G loss: 0.892959]\n",
      "epoch:23 step:18380[D loss: 0.424258, acc: 60.94%, op_acc: 39.84%] [G loss: 0.967374]\n",
      "epoch:23 step:18381[D loss: 0.422164, acc: 60.94%, op_acc: 39.84%] [G loss: 0.791416]\n",
      "epoch:23 step:18382[D loss: 0.410603, acc: 64.06%, op_acc: 41.41%] [G loss: 0.884496]\n",
      "epoch:23 step:18383[D loss: 0.432600, acc: 57.81%, op_acc: 38.28%] [G loss: 0.900987]\n",
      "epoch:23 step:18384[D loss: 0.475343, acc: 55.47%, op_acc: 37.50%] [G loss: 0.833813]\n",
      "epoch:23 step:18385[D loss: 0.436873, acc: 57.03%, op_acc: 37.50%] [G loss: 0.908779]\n",
      "epoch:23 step:18386[D loss: 0.427093, acc: 62.50%, op_acc: 37.50%] [G loss: 0.882249]\n",
      "epoch:23 step:18387[D loss: 0.433991, acc: 64.84%, op_acc: 33.59%] [G loss: 0.896370]\n",
      "epoch:23 step:18388[D loss: 0.426260, acc: 54.69%, op_acc: 36.72%] [G loss: 0.910636]\n",
      "epoch:23 step:18389[D loss: 0.441757, acc: 56.25%, op_acc: 39.06%] [G loss: 0.902053]\n",
      "epoch:23 step:18390[D loss: 0.428960, acc: 67.19%, op_acc: 35.94%] [G loss: 0.827486]\n",
      "epoch:23 step:18391[D loss: 0.433695, acc: 58.59%, op_acc: 38.28%] [G loss: 0.918388]\n",
      "epoch:23 step:18392[D loss: 0.413918, acc: 60.16%, op_acc: 39.06%] [G loss: 0.839272]\n",
      "epoch:23 step:18393[D loss: 0.411424, acc: 60.94%, op_acc: 35.94%] [G loss: 0.838931]\n",
      "epoch:23 step:18394[D loss: 0.437775, acc: 56.25%, op_acc: 37.50%] [G loss: 0.862981]\n",
      "epoch:23 step:18395[D loss: 0.399324, acc: 56.25%, op_acc: 43.75%] [G loss: 0.832538]\n",
      "epoch:23 step:18396[D loss: 0.436243, acc: 54.69%, op_acc: 39.84%] [G loss: 0.892689]\n",
      "epoch:23 step:18397[D loss: 0.431121, acc: 51.56%, op_acc: 47.66%] [G loss: 0.794406]\n",
      "epoch:23 step:18398[D loss: 0.421899, acc: 58.59%, op_acc: 44.53%] [G loss: 0.867491]\n",
      "epoch:23 step:18399[D loss: 0.454039, acc: 52.34%, op_acc: 32.03%] [G loss: 0.873607]\n",
      "epoch:23 step:18400[D loss: 0.444536, acc: 54.69%, op_acc: 35.94%] [G loss: 0.798715]\n",
      "epoch:23 step:18401[D loss: 0.437795, acc: 60.94%, op_acc: 40.62%] [G loss: 0.896851]\n",
      "epoch:23 step:18402[D loss: 0.406829, acc: 64.84%, op_acc: 37.50%] [G loss: 0.904425]\n",
      "epoch:23 step:18403[D loss: 0.414721, acc: 57.03%, op_acc: 42.97%] [G loss: 0.994350]\n",
      "epoch:23 step:18404[D loss: 0.430429, acc: 63.28%, op_acc: 39.06%] [G loss: 0.980378]\n",
      "epoch:23 step:18405[D loss: 0.416961, acc: 58.59%, op_acc: 42.97%] [G loss: 0.888453]\n",
      "epoch:23 step:18406[D loss: 0.436300, acc: 57.03%, op_acc: 36.72%] [G loss: 0.902491]\n",
      "epoch:23 step:18407[D loss: 0.417199, acc: 57.03%, op_acc: 39.84%] [G loss: 0.848286]\n",
      "epoch:23 step:18408[D loss: 0.466861, acc: 50.78%, op_acc: 39.84%] [G loss: 0.800129]\n",
      "epoch:23 step:18409[D loss: 0.416152, acc: 64.06%, op_acc: 37.50%] [G loss: 0.873308]\n",
      "epoch:23 step:18410[D loss: 0.464640, acc: 60.94%, op_acc: 32.03%] [G loss: 0.900654]\n",
      "epoch:23 step:18411[D loss: 0.418572, acc: 57.81%, op_acc: 40.62%] [G loss: 0.903924]\n",
      "epoch:23 step:18412[D loss: 0.408386, acc: 66.41%, op_acc: 39.06%] [G loss: 0.916522]\n",
      "epoch:23 step:18413[D loss: 0.425568, acc: 63.28%, op_acc: 40.62%] [G loss: 0.905657]\n",
      "epoch:23 step:18414[D loss: 0.441603, acc: 52.34%, op_acc: 40.62%] [G loss: 0.853756]\n",
      "epoch:23 step:18415[D loss: 0.414749, acc: 54.69%, op_acc: 45.31%] [G loss: 0.881511]\n",
      "epoch:23 step:18416[D loss: 0.402946, acc: 61.72%, op_acc: 42.19%] [G loss: 0.919565]\n",
      "epoch:23 step:18417[D loss: 0.439013, acc: 56.25%, op_acc: 35.94%] [G loss: 0.878366]\n",
      "epoch:23 step:18418[D loss: 0.432528, acc: 57.81%, op_acc: 42.97%] [G loss: 0.836209]\n",
      "epoch:23 step:18419[D loss: 0.438480, acc: 62.50%, op_acc: 35.94%] [G loss: 0.858704]\n",
      "epoch:23 step:18420[D loss: 0.426853, acc: 58.59%, op_acc: 41.41%] [G loss: 0.851116]\n",
      "epoch:23 step:18421[D loss: 0.404781, acc: 64.06%, op_acc: 38.28%] [G loss: 0.916711]\n",
      "epoch:23 step:18422[D loss: 0.412018, acc: 60.94%, op_acc: 40.62%] [G loss: 0.912200]\n",
      "epoch:23 step:18423[D loss: 0.403845, acc: 61.72%, op_acc: 39.06%] [G loss: 0.941559]\n",
      "epoch:23 step:18424[D loss: 0.441873, acc: 52.34%, op_acc: 34.38%] [G loss: 0.828294]\n",
      "epoch:23 step:18425[D loss: 0.418842, acc: 59.38%, op_acc: 34.38%] [G loss: 0.848845]\n",
      "epoch:23 step:18426[D loss: 0.410522, acc: 64.06%, op_acc: 40.62%] [G loss: 0.909001]\n",
      "epoch:23 step:18427[D loss: 0.451342, acc: 56.25%, op_acc: 38.28%] [G loss: 0.802752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18428[D loss: 0.412367, acc: 64.84%, op_acc: 39.84%] [G loss: 0.824504]\n",
      "epoch:23 step:18429[D loss: 0.386829, acc: 67.19%, op_acc: 40.62%] [G loss: 0.938442]\n",
      "epoch:23 step:18430[D loss: 0.443460, acc: 58.59%, op_acc: 37.50%] [G loss: 0.784846]\n",
      "epoch:23 step:18431[D loss: 0.405344, acc: 65.62%, op_acc: 41.41%] [G loss: 0.835772]\n",
      "epoch:23 step:18432[D loss: 0.401496, acc: 68.75%, op_acc: 41.41%] [G loss: 0.903220]\n",
      "epoch:23 step:18433[D loss: 0.413836, acc: 57.81%, op_acc: 41.41%] [G loss: 0.870874]\n",
      "epoch:23 step:18434[D loss: 0.419730, acc: 66.41%, op_acc: 35.94%] [G loss: 0.810367]\n",
      "epoch:23 step:18435[D loss: 0.452019, acc: 54.69%, op_acc: 29.69%] [G loss: 0.861063]\n",
      "epoch:23 step:18436[D loss: 0.390075, acc: 64.84%, op_acc: 49.22%] [G loss: 0.900496]\n",
      "epoch:23 step:18437[D loss: 0.445097, acc: 53.12%, op_acc: 39.06%] [G loss: 0.884593]\n",
      "epoch:23 step:18438[D loss: 0.433299, acc: 55.47%, op_acc: 39.06%] [G loss: 0.877606]\n",
      "epoch:23 step:18439[D loss: 0.459198, acc: 50.00%, op_acc: 28.91%] [G loss: 0.880744]\n",
      "epoch:23 step:18440[D loss: 0.434857, acc: 49.22%, op_acc: 37.50%] [G loss: 0.837016]\n",
      "epoch:23 step:18441[D loss: 0.417738, acc: 61.72%, op_acc: 36.72%] [G loss: 0.821478]\n",
      "epoch:23 step:18442[D loss: 0.410339, acc: 63.28%, op_acc: 36.72%] [G loss: 0.879229]\n",
      "epoch:23 step:18443[D loss: 0.440352, acc: 58.59%, op_acc: 36.72%] [G loss: 0.869778]\n",
      "epoch:23 step:18444[D loss: 0.456547, acc: 60.16%, op_acc: 35.16%] [G loss: 0.864401]\n",
      "epoch:23 step:18445[D loss: 0.437352, acc: 54.69%, op_acc: 41.41%] [G loss: 0.886479]\n",
      "epoch:23 step:18446[D loss: 0.405420, acc: 64.06%, op_acc: 44.53%] [G loss: 0.917201]\n",
      "epoch:23 step:18447[D loss: 0.421131, acc: 58.59%, op_acc: 42.97%] [G loss: 0.868740]\n",
      "epoch:23 step:18448[D loss: 0.427059, acc: 59.38%, op_acc: 41.41%] [G loss: 0.859235]\n",
      "epoch:23 step:18449[D loss: 0.414438, acc: 59.38%, op_acc: 39.06%] [G loss: 0.890819]\n",
      "epoch:23 step:18450[D loss: 0.422279, acc: 62.50%, op_acc: 33.59%] [G loss: 0.905677]\n",
      "epoch:23 step:18451[D loss: 0.443400, acc: 50.78%, op_acc: 42.19%] [G loss: 0.824712]\n",
      "epoch:23 step:18452[D loss: 0.415882, acc: 58.59%, op_acc: 37.50%] [G loss: 0.858620]\n",
      "epoch:23 step:18453[D loss: 0.406669, acc: 61.72%, op_acc: 38.28%] [G loss: 0.874562]\n",
      "epoch:23 step:18454[D loss: 0.429233, acc: 64.84%, op_acc: 42.19%] [G loss: 0.918375]\n",
      "epoch:23 step:18455[D loss: 0.420901, acc: 63.28%, op_acc: 40.62%] [G loss: 0.887799]\n",
      "epoch:23 step:18456[D loss: 0.416535, acc: 60.16%, op_acc: 42.19%] [G loss: 0.914814]\n",
      "epoch:23 step:18457[D loss: 0.397173, acc: 64.06%, op_acc: 45.31%] [G loss: 0.885102]\n",
      "epoch:23 step:18458[D loss: 0.442941, acc: 55.47%, op_acc: 41.41%] [G loss: 0.874524]\n",
      "epoch:23 step:18459[D loss: 0.395937, acc: 64.84%, op_acc: 39.84%] [G loss: 0.916721]\n",
      "epoch:23 step:18460[D loss: 0.405121, acc: 61.72%, op_acc: 41.41%] [G loss: 0.914652]\n",
      "epoch:23 step:18461[D loss: 0.417764, acc: 62.50%, op_acc: 40.62%] [G loss: 0.852055]\n",
      "epoch:23 step:18462[D loss: 0.448230, acc: 58.59%, op_acc: 40.62%] [G loss: 0.852535]\n",
      "epoch:23 step:18463[D loss: 0.405011, acc: 63.28%, op_acc: 39.06%] [G loss: 0.903530]\n",
      "epoch:23 step:18464[D loss: 0.429771, acc: 57.81%, op_acc: 34.38%] [G loss: 0.943358]\n",
      "epoch:23 step:18465[D loss: 0.437849, acc: 55.47%, op_acc: 42.19%] [G loss: 0.925971]\n",
      "epoch:23 step:18466[D loss: 0.433549, acc: 53.12%, op_acc: 42.19%] [G loss: 0.825800]\n",
      "epoch:23 step:18467[D loss: 0.441919, acc: 59.38%, op_acc: 35.16%] [G loss: 0.895518]\n",
      "epoch:23 step:18468[D loss: 0.412568, acc: 58.59%, op_acc: 41.41%] [G loss: 0.897649]\n",
      "epoch:23 step:18469[D loss: 0.438183, acc: 59.38%, op_acc: 42.19%] [G loss: 0.857665]\n",
      "epoch:23 step:18470[D loss: 0.407474, acc: 63.28%, op_acc: 39.84%] [G loss: 0.856056]\n",
      "epoch:23 step:18471[D loss: 0.422627, acc: 53.91%, op_acc: 41.41%] [G loss: 0.819251]\n",
      "epoch:23 step:18472[D loss: 0.430162, acc: 58.59%, op_acc: 42.97%] [G loss: 0.875975]\n",
      "epoch:23 step:18473[D loss: 0.441881, acc: 52.34%, op_acc: 39.06%] [G loss: 0.876897]\n",
      "epoch:23 step:18474[D loss: 0.439661, acc: 51.56%, op_acc: 42.19%] [G loss: 0.856234]\n",
      "epoch:23 step:18475[D loss: 0.457162, acc: 53.91%, op_acc: 35.94%] [G loss: 0.870081]\n",
      "epoch:23 step:18476[D loss: 0.448759, acc: 57.81%, op_acc: 38.28%] [G loss: 0.842910]\n",
      "epoch:23 step:18477[D loss: 0.432653, acc: 57.81%, op_acc: 40.62%] [G loss: 0.826562]\n",
      "epoch:23 step:18478[D loss: 0.440966, acc: 59.38%, op_acc: 29.69%] [G loss: 0.868298]\n",
      "epoch:23 step:18479[D loss: 0.411392, acc: 62.50%, op_acc: 42.19%] [G loss: 0.880485]\n",
      "epoch:23 step:18480[D loss: 0.431540, acc: 60.94%, op_acc: 38.28%] [G loss: 0.912197]\n",
      "epoch:23 step:18481[D loss: 0.400514, acc: 68.75%, op_acc: 38.28%] [G loss: 0.819728]\n",
      "epoch:23 step:18482[D loss: 0.417812, acc: 64.84%, op_acc: 39.84%] [G loss: 0.884653]\n",
      "epoch:23 step:18483[D loss: 0.428323, acc: 53.91%, op_acc: 37.50%] [G loss: 0.868428]\n",
      "epoch:23 step:18484[D loss: 0.411641, acc: 69.53%, op_acc: 38.28%] [G loss: 0.895171]\n",
      "epoch:23 step:18485[D loss: 0.447260, acc: 52.34%, op_acc: 39.06%] [G loss: 0.873626]\n",
      "epoch:23 step:18486[D loss: 0.422228, acc: 60.94%, op_acc: 36.72%] [G loss: 0.869383]\n",
      "epoch:23 step:18487[D loss: 0.449048, acc: 54.69%, op_acc: 38.28%] [G loss: 0.854954]\n",
      "epoch:23 step:18488[D loss: 0.457108, acc: 60.16%, op_acc: 30.47%] [G loss: 0.872920]\n",
      "epoch:23 step:18489[D loss: 0.450027, acc: 55.47%, op_acc: 35.16%] [G loss: 0.912669]\n",
      "epoch:23 step:18490[D loss: 0.450353, acc: 52.34%, op_acc: 36.72%] [G loss: 0.894166]\n",
      "epoch:23 step:18491[D loss: 0.432561, acc: 56.25%, op_acc: 42.97%] [G loss: 0.805289]\n",
      "epoch:23 step:18492[D loss: 0.393293, acc: 65.62%, op_acc: 42.19%] [G loss: 0.906084]\n",
      "epoch:23 step:18493[D loss: 0.457103, acc: 57.03%, op_acc: 39.84%] [G loss: 0.858742]\n",
      "epoch:23 step:18494[D loss: 0.415978, acc: 64.84%, op_acc: 38.28%] [G loss: 0.877473]\n",
      "epoch:23 step:18495[D loss: 0.444708, acc: 54.69%, op_acc: 35.16%] [G loss: 0.882743]\n",
      "epoch:23 step:18496[D loss: 0.418444, acc: 54.69%, op_acc: 43.75%] [G loss: 0.901599]\n",
      "epoch:23 step:18497[D loss: 0.411550, acc: 60.16%, op_acc: 44.53%] [G loss: 0.851678]\n",
      "epoch:23 step:18498[D loss: 0.429021, acc: 58.59%, op_acc: 35.16%] [G loss: 0.929029]\n",
      "epoch:23 step:18499[D loss: 0.426249, acc: 46.88%, op_acc: 42.97%] [G loss: 0.876930]\n",
      "epoch:23 step:18500[D loss: 0.442849, acc: 54.69%, op_acc: 35.94%] [G loss: 0.880515]\n",
      "epoch:23 step:18501[D loss: 0.417388, acc: 61.72%, op_acc: 41.41%] [G loss: 0.879457]\n",
      "epoch:23 step:18502[D loss: 0.458490, acc: 54.69%, op_acc: 35.16%] [G loss: 0.921948]\n",
      "epoch:23 step:18503[D loss: 0.419695, acc: 56.25%, op_acc: 39.84%] [G loss: 0.885183]\n",
      "epoch:23 step:18504[D loss: 0.434364, acc: 59.38%, op_acc: 41.41%] [G loss: 0.845344]\n",
      "epoch:23 step:18505[D loss: 0.426340, acc: 62.50%, op_acc: 38.28%] [G loss: 0.823413]\n",
      "epoch:23 step:18506[D loss: 0.438981, acc: 58.59%, op_acc: 40.62%] [G loss: 0.759619]\n",
      "epoch:23 step:18507[D loss: 0.444567, acc: 50.00%, op_acc: 38.28%] [G loss: 0.861395]\n",
      "epoch:23 step:18508[D loss: 0.396596, acc: 61.72%, op_acc: 34.38%] [G loss: 0.799458]\n",
      "epoch:23 step:18509[D loss: 0.417830, acc: 57.03%, op_acc: 39.84%] [G loss: 0.843804]\n",
      "epoch:23 step:18510[D loss: 0.419696, acc: 66.41%, op_acc: 37.50%] [G loss: 0.925803]\n",
      "epoch:23 step:18511[D loss: 0.441531, acc: 59.38%, op_acc: 39.06%] [G loss: 0.862971]\n",
      "epoch:23 step:18512[D loss: 0.419469, acc: 65.62%, op_acc: 35.94%] [G loss: 0.901558]\n",
      "epoch:23 step:18513[D loss: 0.437361, acc: 53.12%, op_acc: 41.41%] [G loss: 0.921517]\n",
      "epoch:23 step:18514[D loss: 0.419569, acc: 63.28%, op_acc: 39.84%] [G loss: 0.921264]\n",
      "epoch:23 step:18515[D loss: 0.472639, acc: 57.81%, op_acc: 33.59%] [G loss: 0.892077]\n",
      "epoch:23 step:18516[D loss: 0.438668, acc: 53.12%, op_acc: 39.06%] [G loss: 0.865299]\n",
      "epoch:23 step:18517[D loss: 0.462825, acc: 56.25%, op_acc: 40.62%] [G loss: 0.847530]\n",
      "epoch:23 step:18518[D loss: 0.420203, acc: 59.38%, op_acc: 38.28%] [G loss: 0.826820]\n",
      "epoch:23 step:18519[D loss: 0.416971, acc: 61.72%, op_acc: 39.84%] [G loss: 0.855773]\n",
      "epoch:23 step:18520[D loss: 0.463125, acc: 46.09%, op_acc: 32.81%] [G loss: 0.851105]\n",
      "epoch:23 step:18521[D loss: 0.419778, acc: 60.16%, op_acc: 40.62%] [G loss: 0.979884]\n",
      "epoch:23 step:18522[D loss: 0.410889, acc: 63.28%, op_acc: 32.03%] [G loss: 0.875168]\n",
      "epoch:23 step:18523[D loss: 0.418207, acc: 61.72%, op_acc: 41.41%] [G loss: 0.897767]\n",
      "epoch:23 step:18524[D loss: 0.418885, acc: 56.25%, op_acc: 42.97%] [G loss: 0.853558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18525[D loss: 0.422700, acc: 57.81%, op_acc: 35.94%] [G loss: 0.829814]\n",
      "epoch:23 step:18526[D loss: 0.406495, acc: 61.72%, op_acc: 39.84%] [G loss: 0.876575]\n",
      "epoch:23 step:18527[D loss: 0.408952, acc: 60.94%, op_acc: 45.31%] [G loss: 0.890805]\n",
      "epoch:23 step:18528[D loss: 0.396979, acc: 67.19%, op_acc: 38.28%] [G loss: 0.871833]\n",
      "epoch:23 step:18529[D loss: 0.453166, acc: 51.56%, op_acc: 34.38%] [G loss: 0.963382]\n",
      "epoch:23 step:18530[D loss: 0.414386, acc: 58.59%, op_acc: 45.31%] [G loss: 0.961670]\n",
      "epoch:23 step:18531[D loss: 0.400676, acc: 60.16%, op_acc: 43.75%] [G loss: 0.867591]\n",
      "epoch:23 step:18532[D loss: 0.407326, acc: 61.72%, op_acc: 42.19%] [G loss: 0.904302]\n",
      "epoch:23 step:18533[D loss: 0.445153, acc: 58.59%, op_acc: 39.84%] [G loss: 0.879152]\n",
      "epoch:23 step:18534[D loss: 0.420999, acc: 62.50%, op_acc: 42.19%] [G loss: 0.899794]\n",
      "epoch:23 step:18535[D loss: 0.425398, acc: 58.59%, op_acc: 37.50%] [G loss: 0.937271]\n",
      "epoch:23 step:18536[D loss: 0.424227, acc: 57.03%, op_acc: 39.84%] [G loss: 0.916073]\n",
      "epoch:23 step:18537[D loss: 0.452402, acc: 48.44%, op_acc: 37.50%] [G loss: 0.878712]\n",
      "epoch:23 step:18538[D loss: 0.424430, acc: 57.81%, op_acc: 37.50%] [G loss: 0.910949]\n",
      "epoch:23 step:18539[D loss: 0.402014, acc: 65.62%, op_acc: 46.88%] [G loss: 0.849548]\n",
      "epoch:23 step:18540[D loss: 0.447258, acc: 52.34%, op_acc: 39.06%] [G loss: 0.883458]\n",
      "epoch:23 step:18541[D loss: 0.453086, acc: 59.38%, op_acc: 33.59%] [G loss: 0.840732]\n",
      "epoch:23 step:18542[D loss: 0.430612, acc: 58.59%, op_acc: 43.75%] [G loss: 0.955578]\n",
      "epoch:23 step:18543[D loss: 0.425485, acc: 58.59%, op_acc: 37.50%] [G loss: 0.879001]\n",
      "epoch:23 step:18544[D loss: 0.446636, acc: 54.69%, op_acc: 39.06%] [G loss: 0.858286]\n",
      "epoch:23 step:18545[D loss: 0.434004, acc: 58.59%, op_acc: 35.16%] [G loss: 0.867601]\n",
      "epoch:23 step:18546[D loss: 0.406171, acc: 64.84%, op_acc: 35.16%] [G loss: 0.865914]\n",
      "epoch:23 step:18547[D loss: 0.457395, acc: 50.78%, op_acc: 33.59%] [G loss: 0.920614]\n",
      "epoch:23 step:18548[D loss: 0.430127, acc: 52.34%, op_acc: 39.06%] [G loss: 0.860187]\n",
      "epoch:23 step:18549[D loss: 0.436870, acc: 57.03%, op_acc: 41.41%] [G loss: 0.842938]\n",
      "epoch:23 step:18550[D loss: 0.403515, acc: 70.31%, op_acc: 35.16%] [G loss: 0.934844]\n",
      "epoch:23 step:18551[D loss: 0.414844, acc: 62.50%, op_acc: 41.41%] [G loss: 0.930541]\n",
      "epoch:23 step:18552[D loss: 0.406677, acc: 55.47%, op_acc: 38.28%] [G loss: 0.881711]\n",
      "epoch:23 step:18553[D loss: 0.426948, acc: 59.38%, op_acc: 38.28%] [G loss: 0.848403]\n",
      "epoch:23 step:18554[D loss: 0.447630, acc: 54.69%, op_acc: 35.94%] [G loss: 0.847238]\n",
      "epoch:23 step:18555[D loss: 0.430518, acc: 53.12%, op_acc: 36.72%] [G loss: 0.866603]\n",
      "epoch:23 step:18556[D loss: 0.445205, acc: 57.03%, op_acc: 37.50%] [G loss: 0.953646]\n",
      "epoch:23 step:18557[D loss: 0.437529, acc: 62.50%, op_acc: 32.81%] [G loss: 0.914143]\n",
      "epoch:23 step:18558[D loss: 0.406314, acc: 60.94%, op_acc: 43.75%] [G loss: 0.898015]\n",
      "epoch:23 step:18559[D loss: 0.421966, acc: 60.94%, op_acc: 42.97%] [G loss: 0.862504]\n",
      "epoch:23 step:18560[D loss: 0.432909, acc: 56.25%, op_acc: 42.19%] [G loss: 0.929478]\n",
      "epoch:23 step:18561[D loss: 0.426677, acc: 63.28%, op_acc: 41.41%] [G loss: 0.865263]\n",
      "epoch:23 step:18562[D loss: 0.437748, acc: 61.72%, op_acc: 31.25%] [G loss: 0.923314]\n",
      "epoch:23 step:18563[D loss: 0.426517, acc: 62.50%, op_acc: 32.81%] [G loss: 0.840593]\n",
      "epoch:23 step:18564[D loss: 0.423122, acc: 60.16%, op_acc: 39.06%] [G loss: 0.934409]\n",
      "epoch:23 step:18565[D loss: 0.420885, acc: 58.59%, op_acc: 38.28%] [G loss: 0.893310]\n",
      "epoch:23 step:18566[D loss: 0.399492, acc: 60.94%, op_acc: 45.31%] [G loss: 0.911056]\n",
      "epoch:23 step:18567[D loss: 0.433753, acc: 62.50%, op_acc: 32.81%] [G loss: 0.898402]\n",
      "epoch:23 step:18568[D loss: 0.438910, acc: 58.59%, op_acc: 39.84%] [G loss: 0.815796]\n",
      "epoch:23 step:18569[D loss: 0.411646, acc: 69.53%, op_acc: 42.97%] [G loss: 0.855724]\n",
      "epoch:23 step:18570[D loss: 0.397198, acc: 61.72%, op_acc: 42.97%] [G loss: 0.886628]\n",
      "epoch:23 step:18571[D loss: 0.386111, acc: 66.41%, op_acc: 45.31%] [G loss: 0.902635]\n",
      "epoch:23 step:18572[D loss: 0.438630, acc: 57.81%, op_acc: 36.72%] [G loss: 0.907268]\n",
      "epoch:23 step:18573[D loss: 0.401902, acc: 69.53%, op_acc: 42.19%] [G loss: 0.938579]\n",
      "epoch:23 step:18574[D loss: 0.429675, acc: 58.59%, op_acc: 44.53%] [G loss: 0.886477]\n",
      "epoch:23 step:18575[D loss: 0.422616, acc: 56.25%, op_acc: 39.84%] [G loss: 0.912590]\n",
      "epoch:23 step:18576[D loss: 0.441899, acc: 51.56%, op_acc: 48.44%] [G loss: 0.789345]\n",
      "epoch:23 step:18577[D loss: 0.419798, acc: 58.59%, op_acc: 39.06%] [G loss: 0.864611]\n",
      "epoch:23 step:18578[D loss: 0.446921, acc: 59.38%, op_acc: 35.16%] [G loss: 0.826127]\n",
      "epoch:23 step:18579[D loss: 0.455865, acc: 50.00%, op_acc: 32.03%] [G loss: 0.856934]\n",
      "epoch:23 step:18580[D loss: 0.431507, acc: 64.06%, op_acc: 37.50%] [G loss: 0.835087]\n",
      "epoch:23 step:18581[D loss: 0.402987, acc: 64.84%, op_acc: 43.75%] [G loss: 0.882229]\n",
      "epoch:23 step:18582[D loss: 0.434319, acc: 56.25%, op_acc: 35.16%] [G loss: 0.888072]\n",
      "epoch:23 step:18583[D loss: 0.414000, acc: 64.84%, op_acc: 36.72%] [G loss: 0.937169]\n",
      "epoch:23 step:18584[D loss: 0.419892, acc: 61.72%, op_acc: 38.28%] [G loss: 0.864032]\n",
      "epoch:23 step:18585[D loss: 0.447087, acc: 55.47%, op_acc: 35.16%] [G loss: 0.868603]\n",
      "epoch:23 step:18586[D loss: 0.390626, acc: 71.09%, op_acc: 42.19%] [G loss: 0.857416]\n",
      "epoch:23 step:18587[D loss: 0.435308, acc: 53.91%, op_acc: 42.97%] [G loss: 0.825228]\n",
      "epoch:23 step:18588[D loss: 0.439857, acc: 55.47%, op_acc: 39.84%] [G loss: 0.848393]\n",
      "epoch:23 step:18589[D loss: 0.415406, acc: 59.38%, op_acc: 39.06%] [G loss: 0.862523]\n",
      "epoch:23 step:18590[D loss: 0.414115, acc: 60.94%, op_acc: 39.84%] [G loss: 0.922033]\n",
      "epoch:23 step:18591[D loss: 0.424107, acc: 63.28%, op_acc: 39.84%] [G loss: 0.899680]\n",
      "epoch:23 step:18592[D loss: 0.444191, acc: 58.59%, op_acc: 39.06%] [G loss: 0.854842]\n",
      "epoch:23 step:18593[D loss: 0.398017, acc: 66.41%, op_acc: 37.50%] [G loss: 0.928754]\n",
      "epoch:23 step:18594[D loss: 0.452109, acc: 57.03%, op_acc: 34.38%] [G loss: 0.911085]\n",
      "epoch:23 step:18595[D loss: 0.404893, acc: 64.84%, op_acc: 39.06%] [G loss: 0.861438]\n",
      "epoch:23 step:18596[D loss: 0.428334, acc: 66.41%, op_acc: 39.84%] [G loss: 0.941339]\n",
      "epoch:23 step:18597[D loss: 0.436913, acc: 60.16%, op_acc: 39.06%] [G loss: 0.871935]\n",
      "epoch:23 step:18598[D loss: 0.420560, acc: 59.38%, op_acc: 40.62%] [G loss: 0.903625]\n",
      "epoch:23 step:18599[D loss: 0.429555, acc: 55.47%, op_acc: 32.81%] [G loss: 0.808531]\n",
      "epoch:23 step:18600[D loss: 0.391841, acc: 63.28%, op_acc: 44.53%] [G loss: 0.911592]\n",
      "epoch:23 step:18601[D loss: 0.459599, acc: 50.00%, op_acc: 35.94%] [G loss: 0.890714]\n",
      "epoch:23 step:18602[D loss: 0.430654, acc: 61.72%, op_acc: 40.62%] [G loss: 0.957300]\n",
      "epoch:23 step:18603[D loss: 0.429529, acc: 58.59%, op_acc: 37.50%] [G loss: 0.905296]\n",
      "epoch:23 step:18604[D loss: 0.436591, acc: 56.25%, op_acc: 32.81%] [G loss: 0.952387]\n",
      "epoch:23 step:18605[D loss: 0.419207, acc: 60.16%, op_acc: 40.62%] [G loss: 0.895920]\n",
      "epoch:23 step:18606[D loss: 0.450754, acc: 53.91%, op_acc: 34.38%] [G loss: 0.924390]\n",
      "epoch:23 step:18607[D loss: 0.397173, acc: 58.59%, op_acc: 42.97%] [G loss: 0.875350]\n",
      "epoch:23 step:18608[D loss: 0.424069, acc: 55.47%, op_acc: 45.31%] [G loss: 0.929655]\n",
      "epoch:23 step:18609[D loss: 0.468059, acc: 53.12%, op_acc: 34.38%] [G loss: 0.890828]\n",
      "epoch:23 step:18610[D loss: 0.427110, acc: 54.69%, op_acc: 39.06%] [G loss: 0.802666]\n",
      "epoch:23 step:18611[D loss: 0.396848, acc: 65.62%, op_acc: 40.62%] [G loss: 0.890398]\n",
      "epoch:23 step:18612[D loss: 0.404005, acc: 63.28%, op_acc: 41.41%] [G loss: 0.890360]\n",
      "epoch:23 step:18613[D loss: 0.439086, acc: 60.16%, op_acc: 37.50%] [G loss: 0.908280]\n",
      "epoch:23 step:18614[D loss: 0.432379, acc: 56.25%, op_acc: 39.06%] [G loss: 0.822897]\n",
      "epoch:23 step:18615[D loss: 0.433858, acc: 55.47%, op_acc: 40.62%] [G loss: 0.767229]\n",
      "epoch:23 step:18616[D loss: 0.409344, acc: 53.91%, op_acc: 40.62%] [G loss: 0.841914]\n",
      "epoch:23 step:18617[D loss: 0.436791, acc: 48.44%, op_acc: 39.06%] [G loss: 0.791749]\n",
      "epoch:23 step:18618[D loss: 0.427969, acc: 57.81%, op_acc: 38.28%] [G loss: 0.930271]\n",
      "epoch:23 step:18619[D loss: 0.436579, acc: 56.25%, op_acc: 37.50%] [G loss: 0.869866]\n",
      "epoch:23 step:18620[D loss: 0.454283, acc: 49.22%, op_acc: 39.06%] [G loss: 0.875957]\n",
      "epoch:23 step:18621[D loss: 0.407438, acc: 60.94%, op_acc: 41.41%] [G loss: 0.931575]\n",
      "epoch:23 step:18622[D loss: 0.422662, acc: 62.50%, op_acc: 38.28%] [G loss: 0.876635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18623[D loss: 0.399991, acc: 67.97%, op_acc: 42.19%] [G loss: 0.856115]\n",
      "epoch:23 step:18624[D loss: 0.400646, acc: 60.16%, op_acc: 45.31%] [G loss: 0.890954]\n",
      "epoch:23 step:18625[D loss: 0.427806, acc: 51.56%, op_acc: 42.19%] [G loss: 0.816066]\n",
      "epoch:23 step:18626[D loss: 0.414740, acc: 63.28%, op_acc: 42.97%] [G loss: 0.828180]\n",
      "epoch:23 step:18627[D loss: 0.419436, acc: 58.59%, op_acc: 39.84%] [G loss: 0.873079]\n",
      "epoch:23 step:18628[D loss: 0.449230, acc: 61.72%, op_acc: 35.94%] [G loss: 0.855673]\n",
      "epoch:23 step:18629[D loss: 0.416625, acc: 62.50%, op_acc: 39.06%] [G loss: 0.883066]\n",
      "epoch:23 step:18630[D loss: 0.412170, acc: 62.50%, op_acc: 39.06%] [G loss: 0.824790]\n",
      "epoch:23 step:18631[D loss: 0.425978, acc: 57.81%, op_acc: 42.19%] [G loss: 0.838888]\n",
      "epoch:23 step:18632[D loss: 0.410220, acc: 66.41%, op_acc: 35.94%] [G loss: 0.880780]\n",
      "epoch:23 step:18633[D loss: 0.430271, acc: 56.25%, op_acc: 41.41%] [G loss: 0.819390]\n",
      "epoch:23 step:18634[D loss: 0.473106, acc: 48.44%, op_acc: 35.16%] [G loss: 0.818486]\n",
      "epoch:23 step:18635[D loss: 0.447614, acc: 53.91%, op_acc: 39.06%] [G loss: 0.877964]\n",
      "epoch:23 step:18636[D loss: 0.438072, acc: 59.38%, op_acc: 34.38%] [G loss: 0.903506]\n",
      "epoch:23 step:18637[D loss: 0.438928, acc: 55.47%, op_acc: 42.97%] [G loss: 0.857793]\n",
      "epoch:23 step:18638[D loss: 0.428931, acc: 60.16%, op_acc: 39.84%] [G loss: 0.849045]\n",
      "epoch:23 step:18639[D loss: 0.472311, acc: 53.91%, op_acc: 36.72%] [G loss: 0.846646]\n",
      "epoch:23 step:18640[D loss: 0.447528, acc: 54.69%, op_acc: 39.84%] [G loss: 0.892895]\n",
      "epoch:23 step:18641[D loss: 0.417333, acc: 60.16%, op_acc: 42.19%] [G loss: 0.873103]\n",
      "epoch:23 step:18642[D loss: 0.392081, acc: 64.84%, op_acc: 45.31%] [G loss: 0.872905]\n",
      "epoch:23 step:18643[D loss: 0.421996, acc: 63.28%, op_acc: 39.06%] [G loss: 0.926271]\n",
      "epoch:23 step:18644[D loss: 0.432113, acc: 66.41%, op_acc: 32.03%] [G loss: 0.896254]\n",
      "epoch:23 step:18645[D loss: 0.420966, acc: 57.81%, op_acc: 40.62%] [G loss: 0.882996]\n",
      "epoch:23 step:18646[D loss: 0.417247, acc: 60.16%, op_acc: 43.75%] [G loss: 0.867946]\n",
      "epoch:23 step:18647[D loss: 0.427623, acc: 60.16%, op_acc: 32.81%] [G loss: 0.912396]\n",
      "epoch:23 step:18648[D loss: 0.434313, acc: 60.94%, op_acc: 35.94%] [G loss: 0.899052]\n",
      "epoch:23 step:18649[D loss: 0.410988, acc: 64.06%, op_acc: 42.19%] [G loss: 0.866533]\n",
      "epoch:23 step:18650[D loss: 0.397414, acc: 63.28%, op_acc: 38.28%] [G loss: 0.912884]\n",
      "epoch:23 step:18651[D loss: 0.439316, acc: 48.44%, op_acc: 42.97%] [G loss: 0.901955]\n",
      "epoch:23 step:18652[D loss: 0.416347, acc: 54.69%, op_acc: 41.41%] [G loss: 0.861652]\n",
      "epoch:23 step:18653[D loss: 0.448884, acc: 57.03%, op_acc: 39.06%] [G loss: 0.908712]\n",
      "epoch:23 step:18654[D loss: 0.416570, acc: 62.50%, op_acc: 37.50%] [G loss: 0.873601]\n",
      "epoch:23 step:18655[D loss: 0.457150, acc: 53.91%, op_acc: 37.50%] [G loss: 0.905046]\n",
      "epoch:23 step:18656[D loss: 0.422512, acc: 58.59%, op_acc: 37.50%] [G loss: 0.881762]\n",
      "epoch:23 step:18657[D loss: 0.404584, acc: 64.06%, op_acc: 42.97%] [G loss: 0.929619]\n",
      "epoch:23 step:18658[D loss: 0.431998, acc: 59.38%, op_acc: 36.72%] [G loss: 0.832730]\n",
      "epoch:23 step:18659[D loss: 0.428576, acc: 54.69%, op_acc: 38.28%] [G loss: 0.859236]\n",
      "epoch:23 step:18660[D loss: 0.399686, acc: 64.06%, op_acc: 39.84%] [G loss: 0.908176]\n",
      "epoch:23 step:18661[D loss: 0.410446, acc: 63.28%, op_acc: 37.50%] [G loss: 0.915876]\n",
      "epoch:23 step:18662[D loss: 0.415260, acc: 58.59%, op_acc: 42.97%] [G loss: 0.855477]\n",
      "epoch:23 step:18663[D loss: 0.429662, acc: 56.25%, op_acc: 33.59%] [G loss: 0.836698]\n",
      "epoch:23 step:18664[D loss: 0.420310, acc: 63.28%, op_acc: 32.03%] [G loss: 0.879766]\n",
      "epoch:23 step:18665[D loss: 0.415007, acc: 60.94%, op_acc: 38.28%] [G loss: 0.827709]\n",
      "epoch:23 step:18666[D loss: 0.436786, acc: 57.81%, op_acc: 37.50%] [G loss: 0.888246]\n",
      "epoch:23 step:18667[D loss: 0.424249, acc: 57.03%, op_acc: 41.41%] [G loss: 0.846209]\n",
      "epoch:23 step:18668[D loss: 0.445971, acc: 51.56%, op_acc: 38.28%] [G loss: 0.788716]\n",
      "epoch:23 step:18669[D loss: 0.422163, acc: 55.47%, op_acc: 40.62%] [G loss: 0.909663]\n",
      "epoch:23 step:18670[D loss: 0.429493, acc: 61.72%, op_acc: 36.72%] [G loss: 0.836044]\n",
      "epoch:23 step:18671[D loss: 0.441945, acc: 56.25%, op_acc: 38.28%] [G loss: 0.836312]\n",
      "epoch:23 step:18672[D loss: 0.419698, acc: 57.81%, op_acc: 39.84%] [G loss: 0.889740]\n",
      "epoch:23 step:18673[D loss: 0.369463, acc: 73.44%, op_acc: 49.22%] [G loss: 0.847413]\n",
      "epoch:23 step:18674[D loss: 0.417012, acc: 61.72%, op_acc: 40.62%] [G loss: 0.854569]\n",
      "epoch:23 step:18675[D loss: 0.388691, acc: 64.06%, op_acc: 38.28%] [G loss: 0.870383]\n",
      "epoch:23 step:18676[D loss: 0.417700, acc: 60.16%, op_acc: 46.09%] [G loss: 0.867279]\n",
      "epoch:23 step:18677[D loss: 0.440233, acc: 53.91%, op_acc: 37.50%] [G loss: 0.791713]\n",
      "epoch:23 step:18678[D loss: 0.436853, acc: 51.56%, op_acc: 35.94%] [G loss: 0.903788]\n",
      "epoch:23 step:18679[D loss: 0.421220, acc: 63.28%, op_acc: 39.06%] [G loss: 0.877617]\n",
      "epoch:23 step:18680[D loss: 0.406422, acc: 61.72%, op_acc: 42.19%] [G loss: 0.949314]\n",
      "epoch:23 step:18681[D loss: 0.415604, acc: 66.41%, op_acc: 35.16%] [G loss: 0.949264]\n",
      "epoch:23 step:18682[D loss: 0.419084, acc: 64.06%, op_acc: 41.41%] [G loss: 0.942204]\n",
      "epoch:23 step:18683[D loss: 0.415701, acc: 59.38%, op_acc: 41.41%] [G loss: 0.892621]\n",
      "epoch:23 step:18684[D loss: 0.425669, acc: 58.59%, op_acc: 43.75%] [G loss: 0.983925]\n",
      "epoch:23 step:18685[D loss: 0.428228, acc: 60.16%, op_acc: 42.19%] [G loss: 0.848948]\n",
      "epoch:23 step:18686[D loss: 0.416784, acc: 60.16%, op_acc: 39.06%] [G loss: 0.868051]\n",
      "epoch:23 step:18687[D loss: 0.434180, acc: 62.50%, op_acc: 36.72%] [G loss: 0.852759]\n",
      "epoch:23 step:18688[D loss: 0.395876, acc: 64.06%, op_acc: 39.06%] [G loss: 0.899947]\n",
      "epoch:23 step:18689[D loss: 0.413010, acc: 68.75%, op_acc: 41.41%] [G loss: 0.945642]\n",
      "epoch:23 step:18690[D loss: 0.450216, acc: 54.69%, op_acc: 37.50%] [G loss: 0.891839]\n",
      "epoch:23 step:18691[D loss: 0.416335, acc: 62.50%, op_acc: 37.50%] [G loss: 0.936639]\n",
      "epoch:23 step:18692[D loss: 0.399973, acc: 65.62%, op_acc: 40.62%] [G loss: 0.824430]\n",
      "epoch:23 step:18693[D loss: 0.431103, acc: 63.28%, op_acc: 37.50%] [G loss: 0.777678]\n",
      "epoch:23 step:18694[D loss: 0.414933, acc: 60.16%, op_acc: 39.84%] [G loss: 0.767637]\n",
      "epoch:23 step:18695[D loss: 0.407390, acc: 64.06%, op_acc: 35.16%] [G loss: 0.871298]\n",
      "epoch:23 step:18696[D loss: 0.407655, acc: 63.28%, op_acc: 44.53%] [G loss: 0.815556]\n",
      "epoch:23 step:18697[D loss: 0.443629, acc: 54.69%, op_acc: 36.72%] [G loss: 0.788961]\n",
      "epoch:23 step:18698[D loss: 0.427975, acc: 55.47%, op_acc: 36.72%] [G loss: 0.804395]\n",
      "epoch:23 step:18699[D loss: 0.420408, acc: 57.81%, op_acc: 42.19%] [G loss: 0.829607]\n",
      "epoch:23 step:18700[D loss: 0.412853, acc: 59.38%, op_acc: 46.09%] [G loss: 0.834940]\n",
      "epoch:23 step:18701[D loss: 0.427871, acc: 53.12%, op_acc: 39.06%] [G loss: 0.829693]\n",
      "epoch:23 step:18702[D loss: 0.416071, acc: 57.03%, op_acc: 37.50%] [G loss: 0.902523]\n",
      "epoch:23 step:18703[D loss: 0.426256, acc: 64.06%, op_acc: 40.62%] [G loss: 0.896098]\n",
      "epoch:23 step:18704[D loss: 0.412202, acc: 60.16%, op_acc: 39.06%] [G loss: 0.803315]\n",
      "epoch:23 step:18705[D loss: 0.400938, acc: 63.28%, op_acc: 41.41%] [G loss: 0.914609]\n",
      "epoch:23 step:18706[D loss: 0.456928, acc: 57.81%, op_acc: 34.38%] [G loss: 0.856575]\n",
      "epoch:23 step:18707[D loss: 0.406559, acc: 54.69%, op_acc: 44.53%] [G loss: 0.911424]\n",
      "epoch:23 step:18708[D loss: 0.417849, acc: 60.16%, op_acc: 38.28%] [G loss: 0.850768]\n",
      "epoch:23 step:18709[D loss: 0.440149, acc: 56.25%, op_acc: 39.06%] [G loss: 0.826985]\n",
      "epoch:23 step:18710[D loss: 0.442088, acc: 47.66%, op_acc: 39.84%] [G loss: 0.892845]\n",
      "epoch:23 step:18711[D loss: 0.433856, acc: 52.34%, op_acc: 38.28%] [G loss: 0.948007]\n",
      "epoch:23 step:18712[D loss: 0.444794, acc: 59.38%, op_acc: 39.06%] [G loss: 0.907462]\n",
      "epoch:23 step:18713[D loss: 0.419779, acc: 56.25%, op_acc: 39.84%] [G loss: 0.842738]\n",
      "epoch:23 step:18714[D loss: 0.425173, acc: 64.84%, op_acc: 35.16%] [G loss: 0.878237]\n",
      "epoch:23 step:18715[D loss: 0.412478, acc: 64.84%, op_acc: 37.50%] [G loss: 0.868774]\n",
      "epoch:23 step:18716[D loss: 0.395155, acc: 67.19%, op_acc: 39.84%] [G loss: 0.880964]\n",
      "epoch:23 step:18717[D loss: 0.398224, acc: 67.19%, op_acc: 47.66%] [G loss: 0.954136]\n",
      "epoch:23 step:18718[D loss: 0.397786, acc: 70.31%, op_acc: 40.62%] [G loss: 0.849046]\n",
      "epoch:23 step:18719[D loss: 0.401963, acc: 63.28%, op_acc: 42.19%] [G loss: 0.867625]\n",
      "epoch:23 step:18720[D loss: 0.406556, acc: 61.72%, op_acc: 39.84%] [G loss: 0.777818]\n",
      "epoch:23 step:18721[D loss: 0.409167, acc: 61.72%, op_acc: 38.28%] [G loss: 0.741100]\n",
      "epoch:23 step:18722[D loss: 0.424534, acc: 57.81%, op_acc: 36.72%] [G loss: 0.830672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:18723[D loss: 0.411022, acc: 61.72%, op_acc: 45.31%] [G loss: 0.872040]\n",
      "epoch:23 step:18724[D loss: 0.400379, acc: 62.50%, op_acc: 44.53%] [G loss: 0.876382]\n",
      "epoch:23 step:18725[D loss: 0.474817, acc: 48.44%, op_acc: 34.38%] [G loss: 0.900923]\n",
      "epoch:23 step:18726[D loss: 0.427821, acc: 60.94%, op_acc: 38.28%] [G loss: 0.837471]\n",
      "epoch:23 step:18727[D loss: 0.411385, acc: 61.72%, op_acc: 46.09%] [G loss: 0.891082]\n",
      "epoch:23 step:18728[D loss: 0.373568, acc: 68.75%, op_acc: 45.31%] [G loss: 0.940299]\n",
      "epoch:23 step:18729[D loss: 0.424980, acc: 60.94%, op_acc: 39.06%] [G loss: 0.887882]\n",
      "epoch:23 step:18730[D loss: 0.387015, acc: 64.06%, op_acc: 49.22%] [G loss: 0.901089]\n",
      "epoch:23 step:18731[D loss: 0.460312, acc: 55.47%, op_acc: 36.72%] [G loss: 0.761291]\n",
      "epoch:23 step:18732[D loss: 0.410816, acc: 62.50%, op_acc: 39.06%] [G loss: 0.894061]\n",
      "epoch:23 step:18733[D loss: 0.456129, acc: 55.47%, op_acc: 35.94%] [G loss: 0.858810]\n",
      "epoch:23 step:18734[D loss: 0.481306, acc: 52.34%, op_acc: 34.38%] [G loss: 0.828195]\n",
      "epoch:23 step:18735[D loss: 0.420321, acc: 67.97%, op_acc: 31.25%] [G loss: 0.883407]\n",
      "epoch:23 step:18736[D loss: 0.450980, acc: 58.59%, op_acc: 32.81%] [G loss: 0.866384]\n",
      "epoch:23 step:18737[D loss: 0.406748, acc: 63.28%, op_acc: 40.62%] [G loss: 0.875615]\n",
      "epoch:23 step:18738[D loss: 0.440188, acc: 54.69%, op_acc: 33.59%] [G loss: 0.932925]\n",
      "epoch:23 step:18739[D loss: 0.398316, acc: 62.50%, op_acc: 41.41%] [G loss: 0.871527]\n",
      "epoch:23 step:18740[D loss: 0.446467, acc: 51.56%, op_acc: 35.16%] [G loss: 0.931810]\n",
      "epoch:23 step:18741[D loss: 0.426721, acc: 59.38%, op_acc: 39.84%] [G loss: 0.937602]\n",
      "epoch:23 step:18742[D loss: 0.427028, acc: 51.56%, op_acc: 42.19%] [G loss: 0.917697]\n",
      "epoch:23 step:18743[D loss: 0.436513, acc: 48.44%, op_acc: 42.97%] [G loss: 0.944614]\n",
      "epoch:23 step:18744[D loss: 0.415771, acc: 60.16%, op_acc: 41.41%] [G loss: 0.891309]\n",
      "epoch:24 step:18745[D loss: 0.396001, acc: 64.06%, op_acc: 42.97%] [G loss: 0.901227]\n",
      "epoch:24 step:18746[D loss: 0.430345, acc: 53.12%, op_acc: 35.94%] [G loss: 0.978500]\n",
      "epoch:24 step:18747[D loss: 0.412920, acc: 64.84%, op_acc: 38.28%] [G loss: 0.965208]\n",
      "epoch:24 step:18748[D loss: 0.424976, acc: 60.94%, op_acc: 42.19%] [G loss: 0.816068]\n",
      "epoch:24 step:18749[D loss: 0.428988, acc: 60.16%, op_acc: 39.84%] [G loss: 0.936791]\n",
      "epoch:24 step:18750[D loss: 0.457927, acc: 52.34%, op_acc: 42.19%] [G loss: 0.913422]\n",
      "epoch:24 step:18751[D loss: 0.400835, acc: 60.16%, op_acc: 45.31%] [G loss: 0.902251]\n",
      "epoch:24 step:18752[D loss: 0.405019, acc: 62.50%, op_acc: 40.62%] [G loss: 0.846574]\n",
      "epoch:24 step:18753[D loss: 0.380494, acc: 65.62%, op_acc: 42.97%] [G loss: 0.839936]\n",
      "epoch:24 step:18754[D loss: 0.417669, acc: 60.94%, op_acc: 37.50%] [G loss: 0.874529]\n",
      "epoch:24 step:18755[D loss: 0.433220, acc: 60.16%, op_acc: 39.06%] [G loss: 0.880134]\n",
      "epoch:24 step:18756[D loss: 0.422807, acc: 57.81%, op_acc: 36.72%] [G loss: 0.862071]\n",
      "epoch:24 step:18757[D loss: 0.394597, acc: 67.19%, op_acc: 39.84%] [G loss: 0.970287]\n",
      "epoch:24 step:18758[D loss: 0.433585, acc: 63.28%, op_acc: 35.94%] [G loss: 0.912624]\n",
      "epoch:24 step:18759[D loss: 0.395404, acc: 64.06%, op_acc: 42.19%] [G loss: 0.913105]\n",
      "epoch:24 step:18760[D loss: 0.422280, acc: 53.12%, op_acc: 42.19%] [G loss: 0.901542]\n",
      "epoch:24 step:18761[D loss: 0.414711, acc: 60.16%, op_acc: 39.84%] [G loss: 0.861662]\n",
      "epoch:24 step:18762[D loss: 0.407440, acc: 59.38%, op_acc: 43.75%] [G loss: 0.885959]\n",
      "epoch:24 step:18763[D loss: 0.405715, acc: 64.06%, op_acc: 46.88%] [G loss: 0.788389]\n",
      "epoch:24 step:18764[D loss: 0.410652, acc: 58.59%, op_acc: 40.62%] [G loss: 0.801615]\n",
      "epoch:24 step:18765[D loss: 0.443482, acc: 62.50%, op_acc: 32.81%] [G loss: 0.954639]\n",
      "epoch:24 step:18766[D loss: 0.435414, acc: 59.38%, op_acc: 36.72%] [G loss: 0.937386]\n",
      "epoch:24 step:18767[D loss: 0.433951, acc: 53.91%, op_acc: 38.28%] [G loss: 0.800461]\n",
      "epoch:24 step:18768[D loss: 0.430928, acc: 59.38%, op_acc: 37.50%] [G loss: 0.854430]\n",
      "epoch:24 step:18769[D loss: 0.449808, acc: 53.91%, op_acc: 36.72%] [G loss: 0.845791]\n",
      "epoch:24 step:18770[D loss: 0.410850, acc: 60.94%, op_acc: 42.19%] [G loss: 0.851396]\n",
      "epoch:24 step:18771[D loss: 0.418689, acc: 64.06%, op_acc: 39.84%] [G loss: 0.946153]\n",
      "epoch:24 step:18772[D loss: 0.422402, acc: 58.59%, op_acc: 40.62%] [G loss: 0.925454]\n",
      "epoch:24 step:18773[D loss: 0.389346, acc: 70.31%, op_acc: 42.97%] [G loss: 0.940989]\n",
      "epoch:24 step:18774[D loss: 0.379093, acc: 62.50%, op_acc: 45.31%] [G loss: 0.905474]\n",
      "epoch:24 step:18775[D loss: 0.462007, acc: 50.78%, op_acc: 33.59%] [G loss: 0.902442]\n",
      "epoch:24 step:18776[D loss: 0.431690, acc: 61.72%, op_acc: 35.94%] [G loss: 0.925079]\n",
      "epoch:24 step:18777[D loss: 0.413490, acc: 59.38%, op_acc: 46.88%] [G loss: 0.815294]\n",
      "epoch:24 step:18778[D loss: 0.395951, acc: 67.97%, op_acc: 43.75%] [G loss: 0.953001]\n",
      "epoch:24 step:18779[D loss: 0.433235, acc: 60.94%, op_acc: 34.38%] [G loss: 0.919033]\n",
      "epoch:24 step:18780[D loss: 0.396900, acc: 61.72%, op_acc: 44.53%] [G loss: 0.836662]\n",
      "epoch:24 step:18781[D loss: 0.394110, acc: 61.72%, op_acc: 36.72%] [G loss: 0.877415]\n",
      "epoch:24 step:18782[D loss: 0.393866, acc: 65.62%, op_acc: 42.19%] [G loss: 0.848125]\n",
      "epoch:24 step:18783[D loss: 0.396739, acc: 61.72%, op_acc: 44.53%] [G loss: 0.906561]\n",
      "epoch:24 step:18784[D loss: 0.437396, acc: 57.03%, op_acc: 37.50%] [G loss: 0.877169]\n",
      "epoch:24 step:18785[D loss: 0.399536, acc: 64.06%, op_acc: 44.53%] [G loss: 0.867912]\n",
      "epoch:24 step:18786[D loss: 0.406121, acc: 57.81%, op_acc: 46.88%] [G loss: 0.964799]\n",
      "epoch:24 step:18787[D loss: 0.460270, acc: 58.59%, op_acc: 37.50%] [G loss: 0.849996]\n",
      "epoch:24 step:18788[D loss: 0.439414, acc: 51.56%, op_acc: 42.97%] [G loss: 0.848050]\n",
      "epoch:24 step:18789[D loss: 0.437724, acc: 60.94%, op_acc: 37.50%] [G loss: 0.862656]\n",
      "epoch:24 step:18790[D loss: 0.439878, acc: 57.81%, op_acc: 38.28%] [G loss: 0.939038]\n",
      "epoch:24 step:18791[D loss: 0.448114, acc: 54.69%, op_acc: 35.16%] [G loss: 0.865774]\n",
      "epoch:24 step:18792[D loss: 0.438849, acc: 60.16%, op_acc: 33.59%] [G loss: 0.815392]\n",
      "epoch:24 step:18793[D loss: 0.416303, acc: 60.16%, op_acc: 41.41%] [G loss: 0.886199]\n",
      "epoch:24 step:18794[D loss: 0.419330, acc: 60.16%, op_acc: 37.50%] [G loss: 0.970050]\n",
      "epoch:24 step:18795[D loss: 0.395636, acc: 69.53%, op_acc: 39.06%] [G loss: 0.875773]\n",
      "epoch:24 step:18796[D loss: 0.434982, acc: 61.72%, op_acc: 37.50%] [G loss: 0.893380]\n",
      "epoch:24 step:18797[D loss: 0.442596, acc: 57.81%, op_acc: 35.16%] [G loss: 0.878843]\n",
      "epoch:24 step:18798[D loss: 0.477812, acc: 46.09%, op_acc: 31.25%] [G loss: 0.781859]\n",
      "epoch:24 step:18799[D loss: 0.403024, acc: 62.50%, op_acc: 37.50%] [G loss: 0.862081]\n",
      "epoch:24 step:18800[D loss: 0.451897, acc: 55.47%, op_acc: 40.62%] [G loss: 0.862575]\n",
      "epoch:24 step:18801[D loss: 0.427464, acc: 53.91%, op_acc: 39.06%] [G loss: 0.807670]\n",
      "epoch:24 step:18802[D loss: 0.430307, acc: 54.69%, op_acc: 42.97%] [G loss: 0.816589]\n",
      "epoch:24 step:18803[D loss: 0.415957, acc: 56.25%, op_acc: 39.84%] [G loss: 0.934963]\n",
      "epoch:24 step:18804[D loss: 0.403231, acc: 61.72%, op_acc: 39.06%] [G loss: 0.881351]\n",
      "epoch:24 step:18805[D loss: 0.421574, acc: 63.28%, op_acc: 40.62%] [G loss: 0.908981]\n",
      "epoch:24 step:18806[D loss: 0.436702, acc: 54.69%, op_acc: 37.50%] [G loss: 0.965357]\n",
      "epoch:24 step:18807[D loss: 0.433579, acc: 61.72%, op_acc: 37.50%] [G loss: 0.913721]\n",
      "epoch:24 step:18808[D loss: 0.420546, acc: 55.47%, op_acc: 41.41%] [G loss: 0.945933]\n",
      "epoch:24 step:18809[D loss: 0.454420, acc: 55.47%, op_acc: 39.84%] [G loss: 0.843860]\n",
      "epoch:24 step:18810[D loss: 0.433189, acc: 57.81%, op_acc: 36.72%] [G loss: 0.946837]\n",
      "epoch:24 step:18811[D loss: 0.416638, acc: 59.38%, op_acc: 39.84%] [G loss: 0.909932]\n",
      "epoch:24 step:18812[D loss: 0.433087, acc: 54.69%, op_acc: 39.84%] [G loss: 0.801931]\n",
      "epoch:24 step:18813[D loss: 0.404061, acc: 64.06%, op_acc: 40.62%] [G loss: 0.892976]\n",
      "epoch:24 step:18814[D loss: 0.446275, acc: 52.34%, op_acc: 35.16%] [G loss: 0.861245]\n",
      "epoch:24 step:18815[D loss: 0.453687, acc: 52.34%, op_acc: 34.38%] [G loss: 0.905970]\n",
      "epoch:24 step:18816[D loss: 0.404787, acc: 60.94%, op_acc: 38.28%] [G loss: 0.860326]\n",
      "epoch:24 step:18817[D loss: 0.419376, acc: 60.16%, op_acc: 38.28%] [G loss: 0.990187]\n",
      "epoch:24 step:18818[D loss: 0.403990, acc: 64.06%, op_acc: 39.06%] [G loss: 0.929656]\n",
      "epoch:24 step:18819[D loss: 0.401271, acc: 61.72%, op_acc: 41.41%] [G loss: 0.844591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18820[D loss: 0.434533, acc: 59.38%, op_acc: 36.72%] [G loss: 0.902595]\n",
      "epoch:24 step:18821[D loss: 0.427294, acc: 57.81%, op_acc: 40.62%] [G loss: 0.807196]\n",
      "epoch:24 step:18822[D loss: 0.470918, acc: 47.66%, op_acc: 32.81%] [G loss: 0.782345]\n",
      "epoch:24 step:18823[D loss: 0.419202, acc: 53.12%, op_acc: 39.84%] [G loss: 0.929049]\n",
      "epoch:24 step:18824[D loss: 0.449340, acc: 57.81%, op_acc: 38.28%] [G loss: 0.813099]\n",
      "epoch:24 step:18825[D loss: 0.444222, acc: 60.16%, op_acc: 33.59%] [G loss: 0.823888]\n",
      "epoch:24 step:18826[D loss: 0.403068, acc: 67.19%, op_acc: 41.41%] [G loss: 0.898722]\n",
      "epoch:24 step:18827[D loss: 0.428838, acc: 55.47%, op_acc: 40.62%] [G loss: 0.879621]\n",
      "epoch:24 step:18828[D loss: 0.390175, acc: 66.41%, op_acc: 43.75%] [G loss: 0.828606]\n",
      "epoch:24 step:18829[D loss: 0.466827, acc: 58.59%, op_acc: 34.38%] [G loss: 0.872183]\n",
      "epoch:24 step:18830[D loss: 0.399445, acc: 69.53%, op_acc: 39.84%] [G loss: 0.903064]\n",
      "epoch:24 step:18831[D loss: 0.424821, acc: 60.16%, op_acc: 38.28%] [G loss: 0.838791]\n",
      "epoch:24 step:18832[D loss: 0.427748, acc: 60.94%, op_acc: 42.97%] [G loss: 0.875982]\n",
      "epoch:24 step:18833[D loss: 0.442931, acc: 53.12%, op_acc: 33.59%] [G loss: 0.869814]\n",
      "epoch:24 step:18834[D loss: 0.399749, acc: 67.97%, op_acc: 42.19%] [G loss: 0.912573]\n",
      "epoch:24 step:18835[D loss: 0.406069, acc: 64.06%, op_acc: 43.75%] [G loss: 0.992925]\n",
      "epoch:24 step:18836[D loss: 0.440076, acc: 57.81%, op_acc: 35.16%] [G loss: 0.843571]\n",
      "epoch:24 step:18837[D loss: 0.412075, acc: 57.81%, op_acc: 43.75%] [G loss: 0.906342]\n",
      "epoch:24 step:18838[D loss: 0.415984, acc: 60.94%, op_acc: 39.06%] [G loss: 0.860964]\n",
      "epoch:24 step:18839[D loss: 0.420750, acc: 57.81%, op_acc: 38.28%] [G loss: 0.806265]\n",
      "epoch:24 step:18840[D loss: 0.461011, acc: 46.09%, op_acc: 42.19%] [G loss: 0.889733]\n",
      "epoch:24 step:18841[D loss: 0.398136, acc: 59.38%, op_acc: 42.19%] [G loss: 0.908496]\n",
      "epoch:24 step:18842[D loss: 0.399476, acc: 62.50%, op_acc: 40.62%] [G loss: 0.938329]\n",
      "epoch:24 step:18843[D loss: 0.407107, acc: 61.72%, op_acc: 40.62%] [G loss: 0.891482]\n",
      "epoch:24 step:18844[D loss: 0.409937, acc: 64.84%, op_acc: 38.28%] [G loss: 0.922331]\n",
      "epoch:24 step:18845[D loss: 0.409744, acc: 62.50%, op_acc: 41.41%] [G loss: 0.906924]\n",
      "epoch:24 step:18846[D loss: 0.423501, acc: 59.38%, op_acc: 37.50%] [G loss: 0.910429]\n",
      "epoch:24 step:18847[D loss: 0.415335, acc: 57.03%, op_acc: 42.19%] [G loss: 0.805555]\n",
      "epoch:24 step:18848[D loss: 0.428192, acc: 58.59%, op_acc: 40.62%] [G loss: 0.798742]\n",
      "epoch:24 step:18849[D loss: 0.409967, acc: 57.03%, op_acc: 47.66%] [G loss: 0.859548]\n",
      "epoch:24 step:18850[D loss: 0.390797, acc: 61.72%, op_acc: 43.75%] [G loss: 0.907474]\n",
      "epoch:24 step:18851[D loss: 0.418025, acc: 62.50%, op_acc: 40.62%] [G loss: 0.889942]\n",
      "epoch:24 step:18852[D loss: 0.433507, acc: 60.16%, op_acc: 39.84%] [G loss: 0.831339]\n",
      "epoch:24 step:18853[D loss: 0.409635, acc: 60.94%, op_acc: 42.19%] [G loss: 0.918905]\n",
      "epoch:24 step:18854[D loss: 0.407503, acc: 60.94%, op_acc: 39.06%] [G loss: 0.829222]\n",
      "epoch:24 step:18855[D loss: 0.435430, acc: 66.41%, op_acc: 36.72%] [G loss: 0.878838]\n",
      "epoch:24 step:18856[D loss: 0.413737, acc: 59.38%, op_acc: 46.88%] [G loss: 0.941882]\n",
      "epoch:24 step:18857[D loss: 0.447524, acc: 51.56%, op_acc: 36.72%] [G loss: 0.920971]\n",
      "epoch:24 step:18858[D loss: 0.424210, acc: 54.69%, op_acc: 39.84%] [G loss: 0.925745]\n",
      "epoch:24 step:18859[D loss: 0.384351, acc: 70.31%, op_acc: 36.72%] [G loss: 0.940616]\n",
      "epoch:24 step:18860[D loss: 0.435918, acc: 57.03%, op_acc: 41.41%] [G loss: 0.891847]\n",
      "epoch:24 step:18861[D loss: 0.403333, acc: 60.94%, op_acc: 41.41%] [G loss: 0.901883]\n",
      "epoch:24 step:18862[D loss: 0.440942, acc: 51.56%, op_acc: 35.94%] [G loss: 0.897591]\n",
      "epoch:24 step:18863[D loss: 0.405922, acc: 66.41%, op_acc: 35.94%] [G loss: 0.944013]\n",
      "epoch:24 step:18864[D loss: 0.450967, acc: 53.91%, op_acc: 35.16%] [G loss: 0.919398]\n",
      "epoch:24 step:18865[D loss: 0.422641, acc: 61.72%, op_acc: 35.16%] [G loss: 0.886889]\n",
      "epoch:24 step:18866[D loss: 0.440840, acc: 58.59%, op_acc: 34.38%] [G loss: 0.940854]\n",
      "epoch:24 step:18867[D loss: 0.425813, acc: 58.59%, op_acc: 37.50%] [G loss: 0.909998]\n",
      "epoch:24 step:18868[D loss: 0.421041, acc: 60.94%, op_acc: 35.16%] [G loss: 0.876154]\n",
      "epoch:24 step:18869[D loss: 0.442788, acc: 59.38%, op_acc: 37.50%] [G loss: 0.891328]\n",
      "epoch:24 step:18870[D loss: 0.410688, acc: 57.81%, op_acc: 43.75%] [G loss: 0.848167]\n",
      "epoch:24 step:18871[D loss: 0.395697, acc: 67.97%, op_acc: 40.62%] [G loss: 0.883233]\n",
      "epoch:24 step:18872[D loss: 0.403866, acc: 65.62%, op_acc: 38.28%] [G loss: 0.906693]\n",
      "epoch:24 step:18873[D loss: 0.423821, acc: 56.25%, op_acc: 37.50%] [G loss: 0.833960]\n",
      "epoch:24 step:18874[D loss: 0.408749, acc: 67.19%, op_acc: 41.41%] [G loss: 0.907121]\n",
      "epoch:24 step:18875[D loss: 0.400574, acc: 63.28%, op_acc: 38.28%] [G loss: 0.839271]\n",
      "epoch:24 step:18876[D loss: 0.398515, acc: 63.28%, op_acc: 42.97%] [G loss: 0.901662]\n",
      "epoch:24 step:18877[D loss: 0.436090, acc: 60.16%, op_acc: 36.72%] [G loss: 0.906985]\n",
      "epoch:24 step:18878[D loss: 0.429353, acc: 64.06%, op_acc: 39.84%] [G loss: 0.853801]\n",
      "epoch:24 step:18879[D loss: 0.406128, acc: 57.81%, op_acc: 40.62%] [G loss: 0.852877]\n",
      "epoch:24 step:18880[D loss: 0.390529, acc: 62.50%, op_acc: 42.97%] [G loss: 0.837957]\n",
      "epoch:24 step:18881[D loss: 0.427143, acc: 57.81%, op_acc: 40.62%] [G loss: 0.837942]\n",
      "epoch:24 step:18882[D loss: 0.429957, acc: 57.03%, op_acc: 38.28%] [G loss: 0.926993]\n",
      "epoch:24 step:18883[D loss: 0.434377, acc: 56.25%, op_acc: 39.06%] [G loss: 0.890889]\n",
      "epoch:24 step:18884[D loss: 0.452063, acc: 57.03%, op_acc: 36.72%] [G loss: 0.843358]\n",
      "epoch:24 step:18885[D loss: 0.445791, acc: 55.47%, op_acc: 36.72%] [G loss: 0.895466]\n",
      "epoch:24 step:18886[D loss: 0.431123, acc: 60.94%, op_acc: 39.06%] [G loss: 0.854161]\n",
      "epoch:24 step:18887[D loss: 0.438212, acc: 54.69%, op_acc: 35.16%] [G loss: 0.877518]\n",
      "epoch:24 step:18888[D loss: 0.461889, acc: 54.69%, op_acc: 35.94%] [G loss: 0.863914]\n",
      "epoch:24 step:18889[D loss: 0.416416, acc: 67.19%, op_acc: 41.41%] [G loss: 0.790161]\n",
      "epoch:24 step:18890[D loss: 0.413897, acc: 59.38%, op_acc: 39.84%] [G loss: 0.932564]\n",
      "epoch:24 step:18891[D loss: 0.419131, acc: 60.16%, op_acc: 40.62%] [G loss: 0.925622]\n",
      "epoch:24 step:18892[D loss: 0.448052, acc: 56.25%, op_acc: 39.06%] [G loss: 0.938196]\n",
      "epoch:24 step:18893[D loss: 0.428036, acc: 57.81%, op_acc: 39.84%] [G loss: 0.895647]\n",
      "epoch:24 step:18894[D loss: 0.418577, acc: 63.28%, op_acc: 41.41%] [G loss: 0.894366]\n",
      "epoch:24 step:18895[D loss: 0.414004, acc: 64.06%, op_acc: 43.75%] [G loss: 0.915617]\n",
      "epoch:24 step:18896[D loss: 0.396441, acc: 57.03%, op_acc: 42.97%] [G loss: 0.876254]\n",
      "epoch:24 step:18897[D loss: 0.420509, acc: 57.81%, op_acc: 36.72%] [G loss: 0.785940]\n",
      "epoch:24 step:18898[D loss: 0.394984, acc: 67.97%, op_acc: 42.97%] [G loss: 0.901047]\n",
      "epoch:24 step:18899[D loss: 0.449687, acc: 51.56%, op_acc: 32.81%] [G loss: 0.941044]\n",
      "epoch:24 step:18900[D loss: 0.421169, acc: 62.50%, op_acc: 35.94%] [G loss: 1.013293]\n",
      "epoch:24 step:18901[D loss: 0.427869, acc: 59.38%, op_acc: 42.19%] [G loss: 0.775900]\n",
      "epoch:24 step:18902[D loss: 0.401186, acc: 62.50%, op_acc: 43.75%] [G loss: 0.887933]\n",
      "epoch:24 step:18903[D loss: 0.410303, acc: 64.06%, op_acc: 33.59%] [G loss: 0.927639]\n",
      "epoch:24 step:18904[D loss: 0.444213, acc: 66.41%, op_acc: 39.06%] [G loss: 0.956820]\n",
      "epoch:24 step:18905[D loss: 0.433126, acc: 55.47%, op_acc: 42.19%] [G loss: 0.899720]\n",
      "epoch:24 step:18906[D loss: 0.439802, acc: 58.59%, op_acc: 40.62%] [G loss: 0.921733]\n",
      "epoch:24 step:18907[D loss: 0.471488, acc: 50.78%, op_acc: 30.47%] [G loss: 0.829610]\n",
      "epoch:24 step:18908[D loss: 0.451220, acc: 55.47%, op_acc: 35.16%] [G loss: 0.892553]\n",
      "epoch:24 step:18909[D loss: 0.409913, acc: 60.94%, op_acc: 45.31%] [G loss: 0.892341]\n",
      "epoch:24 step:18910[D loss: 0.419283, acc: 67.19%, op_acc: 33.59%] [G loss: 0.880342]\n",
      "epoch:24 step:18911[D loss: 0.451823, acc: 53.12%, op_acc: 41.41%] [G loss: 1.004953]\n",
      "epoch:24 step:18912[D loss: 0.414243, acc: 56.25%, op_acc: 44.53%] [G loss: 0.895739]\n",
      "epoch:24 step:18913[D loss: 0.415910, acc: 59.38%, op_acc: 39.06%] [G loss: 0.870623]\n",
      "epoch:24 step:18914[D loss: 0.426259, acc: 62.50%, op_acc: 37.50%] [G loss: 0.884789]\n",
      "epoch:24 step:18915[D loss: 0.430415, acc: 56.25%, op_acc: 42.19%] [G loss: 0.886152]\n",
      "epoch:24 step:18916[D loss: 0.431747, acc: 60.16%, op_acc: 45.31%] [G loss: 0.884424]\n",
      "epoch:24 step:18917[D loss: 0.456178, acc: 50.78%, op_acc: 39.84%] [G loss: 0.829858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:18918[D loss: 0.465297, acc: 57.03%, op_acc: 38.28%] [G loss: 0.812655]\n",
      "epoch:24 step:18919[D loss: 0.411379, acc: 65.62%, op_acc: 39.84%] [G loss: 0.833982]\n",
      "epoch:24 step:18920[D loss: 0.442696, acc: 59.38%, op_acc: 35.94%] [G loss: 0.832244]\n",
      "epoch:24 step:18921[D loss: 0.428812, acc: 56.25%, op_acc: 40.62%] [G loss: 0.856065]\n",
      "epoch:24 step:18922[D loss: 0.437111, acc: 59.38%, op_acc: 34.38%] [G loss: 0.876901]\n",
      "epoch:24 step:18923[D loss: 0.416312, acc: 58.59%, op_acc: 44.53%] [G loss: 0.866344]\n",
      "epoch:24 step:18924[D loss: 0.427891, acc: 64.84%, op_acc: 33.59%] [G loss: 0.971607]\n",
      "epoch:24 step:18925[D loss: 0.387386, acc: 71.09%, op_acc: 39.84%] [G loss: 0.921104]\n",
      "epoch:24 step:18926[D loss: 0.424662, acc: 54.69%, op_acc: 41.41%] [G loss: 0.906650]\n",
      "epoch:24 step:18927[D loss: 0.394222, acc: 66.41%, op_acc: 39.84%] [G loss: 0.941510]\n",
      "epoch:24 step:18928[D loss: 0.414460, acc: 60.94%, op_acc: 39.84%] [G loss: 0.885526]\n",
      "epoch:24 step:18929[D loss: 0.422447, acc: 69.53%, op_acc: 31.25%] [G loss: 0.986573]\n",
      "epoch:24 step:18930[D loss: 0.431673, acc: 57.03%, op_acc: 39.84%] [G loss: 0.891413]\n",
      "epoch:24 step:18931[D loss: 0.414912, acc: 64.84%, op_acc: 38.28%] [G loss: 0.927475]\n",
      "epoch:24 step:18932[D loss: 0.438265, acc: 56.25%, op_acc: 37.50%] [G loss: 0.904454]\n",
      "epoch:24 step:18933[D loss: 0.409001, acc: 67.97%, op_acc: 40.62%] [G loss: 1.028570]\n",
      "epoch:24 step:18934[D loss: 0.471868, acc: 51.56%, op_acc: 36.72%] [G loss: 0.902734]\n",
      "epoch:24 step:18935[D loss: 0.432815, acc: 54.69%, op_acc: 42.97%] [G loss: 0.851722]\n",
      "epoch:24 step:18936[D loss: 0.421703, acc: 62.50%, op_acc: 39.84%] [G loss: 0.857979]\n",
      "epoch:24 step:18937[D loss: 0.440820, acc: 54.69%, op_acc: 39.84%] [G loss: 0.913389]\n",
      "epoch:24 step:18938[D loss: 0.415282, acc: 64.84%, op_acc: 40.62%] [G loss: 0.820782]\n",
      "epoch:24 step:18939[D loss: 0.406195, acc: 62.50%, op_acc: 39.84%] [G loss: 0.914799]\n",
      "epoch:24 step:18940[D loss: 0.375732, acc: 72.66%, op_acc: 42.97%] [G loss: 0.936682]\n",
      "epoch:24 step:18941[D loss: 0.456605, acc: 52.34%, op_acc: 35.16%] [G loss: 0.870012]\n",
      "epoch:24 step:18942[D loss: 0.396426, acc: 67.19%, op_acc: 44.53%] [G loss: 0.967096]\n",
      "epoch:24 step:18943[D loss: 0.436944, acc: 50.78%, op_acc: 36.72%] [G loss: 0.887578]\n",
      "epoch:24 step:18944[D loss: 0.432859, acc: 64.06%, op_acc: 36.72%] [G loss: 0.815343]\n",
      "epoch:24 step:18945[D loss: 0.393188, acc: 67.19%, op_acc: 46.88%] [G loss: 0.916676]\n",
      "epoch:24 step:18946[D loss: 0.424924, acc: 59.38%, op_acc: 39.06%] [G loss: 0.855623]\n",
      "epoch:24 step:18947[D loss: 0.425026, acc: 65.62%, op_acc: 39.84%] [G loss: 0.911606]\n",
      "epoch:24 step:18948[D loss: 0.441711, acc: 58.59%, op_acc: 36.72%] [G loss: 0.873515]\n",
      "epoch:24 step:18949[D loss: 0.412306, acc: 59.38%, op_acc: 42.97%] [G loss: 0.811935]\n",
      "epoch:24 step:18950[D loss: 0.424394, acc: 55.47%, op_acc: 42.97%] [G loss: 0.862560]\n",
      "epoch:24 step:18951[D loss: 0.387205, acc: 64.06%, op_acc: 47.66%] [G loss: 0.820159]\n",
      "epoch:24 step:18952[D loss: 0.436461, acc: 57.81%, op_acc: 30.47%] [G loss: 0.891487]\n",
      "epoch:24 step:18953[D loss: 0.419823, acc: 61.72%, op_acc: 40.62%] [G loss: 0.917185]\n",
      "epoch:24 step:18954[D loss: 0.448992, acc: 55.47%, op_acc: 38.28%] [G loss: 0.903452]\n",
      "epoch:24 step:18955[D loss: 0.409687, acc: 64.06%, op_acc: 39.06%] [G loss: 0.868547]\n",
      "epoch:24 step:18956[D loss: 0.425664, acc: 55.47%, op_acc: 39.06%] [G loss: 0.878969]\n",
      "epoch:24 step:18957[D loss: 0.443740, acc: 60.94%, op_acc: 37.50%] [G loss: 0.862144]\n",
      "epoch:24 step:18958[D loss: 0.445267, acc: 58.59%, op_acc: 34.38%] [G loss: 0.862026]\n",
      "epoch:24 step:18959[D loss: 0.457987, acc: 50.78%, op_acc: 35.94%] [G loss: 0.875272]\n",
      "epoch:24 step:18960[D loss: 0.445516, acc: 55.47%, op_acc: 34.38%] [G loss: 0.826855]\n",
      "epoch:24 step:18961[D loss: 0.408640, acc: 66.41%, op_acc: 40.62%] [G loss: 0.875253]\n",
      "epoch:24 step:18962[D loss: 0.403866, acc: 66.41%, op_acc: 46.88%] [G loss: 0.906356]\n",
      "epoch:24 step:18963[D loss: 0.422841, acc: 63.28%, op_acc: 37.50%] [G loss: 0.904218]\n",
      "epoch:24 step:18964[D loss: 0.423645, acc: 62.50%, op_acc: 39.06%] [G loss: 0.943077]\n",
      "epoch:24 step:18965[D loss: 0.426121, acc: 57.03%, op_acc: 39.06%] [G loss: 0.810037]\n",
      "epoch:24 step:18966[D loss: 0.411044, acc: 60.16%, op_acc: 40.62%] [G loss: 0.881849]\n",
      "epoch:24 step:18967[D loss: 0.428574, acc: 61.72%, op_acc: 39.06%] [G loss: 0.891273]\n",
      "epoch:24 step:18968[D loss: 0.440252, acc: 53.12%, op_acc: 39.06%] [G loss: 0.839200]\n",
      "epoch:24 step:18969[D loss: 0.407763, acc: 61.72%, op_acc: 40.62%] [G loss: 1.002244]\n",
      "epoch:24 step:18970[D loss: 0.420399, acc: 58.59%, op_acc: 41.41%] [G loss: 0.823079]\n",
      "epoch:24 step:18971[D loss: 0.410023, acc: 64.84%, op_acc: 37.50%] [G loss: 0.879063]\n",
      "epoch:24 step:18972[D loss: 0.406149, acc: 57.03%, op_acc: 44.53%] [G loss: 0.947248]\n",
      "epoch:24 step:18973[D loss: 0.415264, acc: 63.28%, op_acc: 39.84%] [G loss: 0.909428]\n",
      "epoch:24 step:18974[D loss: 0.411811, acc: 60.94%, op_acc: 35.94%] [G loss: 0.910403]\n",
      "epoch:24 step:18975[D loss: 0.427776, acc: 53.12%, op_acc: 39.06%] [G loss: 0.836308]\n",
      "epoch:24 step:18976[D loss: 0.410902, acc: 57.03%, op_acc: 42.97%] [G loss: 0.901195]\n",
      "epoch:24 step:18977[D loss: 0.436894, acc: 53.91%, op_acc: 42.19%] [G loss: 0.848121]\n",
      "epoch:24 step:18978[D loss: 0.464705, acc: 54.69%, op_acc: 34.38%] [G loss: 0.769452]\n",
      "epoch:24 step:18979[D loss: 0.417612, acc: 57.03%, op_acc: 39.06%] [G loss: 0.903555]\n",
      "epoch:24 step:18980[D loss: 0.427997, acc: 58.59%, op_acc: 41.41%] [G loss: 0.910719]\n",
      "epoch:24 step:18981[D loss: 0.410307, acc: 60.94%, op_acc: 40.62%] [G loss: 0.902304]\n",
      "epoch:24 step:18982[D loss: 0.413753, acc: 65.62%, op_acc: 39.06%] [G loss: 0.897164]\n",
      "epoch:24 step:18983[D loss: 0.435489, acc: 53.12%, op_acc: 36.72%] [G loss: 0.879132]\n",
      "epoch:24 step:18984[D loss: 0.426216, acc: 53.91%, op_acc: 39.06%] [G loss: 0.908033]\n",
      "epoch:24 step:18985[D loss: 0.409156, acc: 54.69%, op_acc: 46.09%] [G loss: 0.828764]\n",
      "epoch:24 step:18986[D loss: 0.379419, acc: 73.44%, op_acc: 43.75%] [G loss: 0.941499]\n",
      "epoch:24 step:18987[D loss: 0.456335, acc: 46.88%, op_acc: 39.06%] [G loss: 0.904580]\n",
      "epoch:24 step:18988[D loss: 0.433273, acc: 57.81%, op_acc: 36.72%] [G loss: 0.907122]\n",
      "epoch:24 step:18989[D loss: 0.418841, acc: 60.94%, op_acc: 46.88%] [G loss: 0.834132]\n",
      "epoch:24 step:18990[D loss: 0.438715, acc: 61.72%, op_acc: 35.16%] [G loss: 0.889012]\n",
      "epoch:24 step:18991[D loss: 0.411952, acc: 61.72%, op_acc: 40.62%] [G loss: 0.899887]\n",
      "epoch:24 step:18992[D loss: 0.457927, acc: 57.81%, op_acc: 33.59%] [G loss: 0.878570]\n",
      "epoch:24 step:18993[D loss: 0.433134, acc: 60.16%, op_acc: 43.75%] [G loss: 0.981102]\n",
      "epoch:24 step:18994[D loss: 0.447882, acc: 53.91%, op_acc: 35.94%] [G loss: 0.956180]\n",
      "epoch:24 step:18995[D loss: 0.410140, acc: 58.59%, op_acc: 45.31%] [G loss: 0.919964]\n",
      "epoch:24 step:18996[D loss: 0.408076, acc: 57.81%, op_acc: 46.09%] [G loss: 0.898140]\n",
      "epoch:24 step:18997[D loss: 0.447026, acc: 50.78%, op_acc: 36.72%] [G loss: 0.875440]\n",
      "epoch:24 step:18998[D loss: 0.428845, acc: 58.59%, op_acc: 37.50%] [G loss: 0.850620]\n",
      "epoch:24 step:18999[D loss: 0.431430, acc: 56.25%, op_acc: 41.41%] [G loss: 0.805067]\n",
      "epoch:24 step:19000[D loss: 0.422822, acc: 60.94%, op_acc: 38.28%] [G loss: 0.836055]\n",
      "epoch:24 step:19001[D loss: 0.446864, acc: 55.47%, op_acc: 35.94%] [G loss: 0.888932]\n",
      "epoch:24 step:19002[D loss: 0.432945, acc: 62.50%, op_acc: 44.53%] [G loss: 0.946491]\n",
      "epoch:24 step:19003[D loss: 0.446465, acc: 58.59%, op_acc: 29.69%] [G loss: 0.861159]\n",
      "epoch:24 step:19004[D loss: 0.431995, acc: 59.38%, op_acc: 43.75%] [G loss: 0.892713]\n",
      "epoch:24 step:19005[D loss: 0.445066, acc: 53.91%, op_acc: 41.41%] [G loss: 0.849378]\n",
      "epoch:24 step:19006[D loss: 0.411299, acc: 66.41%, op_acc: 33.59%] [G loss: 0.903337]\n",
      "epoch:24 step:19007[D loss: 0.413335, acc: 63.28%, op_acc: 39.06%] [G loss: 0.876706]\n",
      "epoch:24 step:19008[D loss: 0.420758, acc: 64.06%, op_acc: 42.97%] [G loss: 0.850390]\n",
      "epoch:24 step:19009[D loss: 0.414492, acc: 61.72%, op_acc: 33.59%] [G loss: 0.995158]\n",
      "epoch:24 step:19010[D loss: 0.421858, acc: 60.16%, op_acc: 40.62%] [G loss: 0.884274]\n",
      "epoch:24 step:19011[D loss: 0.435449, acc: 54.69%, op_acc: 43.75%] [G loss: 0.824898]\n",
      "epoch:24 step:19012[D loss: 0.412205, acc: 56.25%, op_acc: 45.31%] [G loss: 0.888356]\n",
      "epoch:24 step:19013[D loss: 0.427088, acc: 53.91%, op_acc: 42.19%] [G loss: 0.952716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19014[D loss: 0.424034, acc: 59.38%, op_acc: 39.06%] [G loss: 0.849885]\n",
      "epoch:24 step:19015[D loss: 0.431846, acc: 50.78%, op_acc: 39.06%] [G loss: 0.877150]\n",
      "epoch:24 step:19016[D loss: 0.418848, acc: 59.38%, op_acc: 41.41%] [G loss: 0.851528]\n",
      "epoch:24 step:19017[D loss: 0.405420, acc: 64.84%, op_acc: 42.97%] [G loss: 0.891091]\n",
      "epoch:24 step:19018[D loss: 0.453086, acc: 54.69%, op_acc: 39.06%] [G loss: 0.946686]\n",
      "epoch:24 step:19019[D loss: 0.424733, acc: 55.47%, op_acc: 46.09%] [G loss: 0.874925]\n",
      "epoch:24 step:19020[D loss: 0.420056, acc: 57.03%, op_acc: 42.19%] [G loss: 0.958403]\n",
      "epoch:24 step:19021[D loss: 0.432382, acc: 61.72%, op_acc: 33.59%] [G loss: 0.868355]\n",
      "epoch:24 step:19022[D loss: 0.418104, acc: 60.94%, op_acc: 39.06%] [G loss: 0.914761]\n",
      "epoch:24 step:19023[D loss: 0.436020, acc: 53.91%, op_acc: 35.16%] [G loss: 0.961182]\n",
      "epoch:24 step:19024[D loss: 0.439604, acc: 58.59%, op_acc: 33.59%] [G loss: 0.855143]\n",
      "epoch:24 step:19025[D loss: 0.404883, acc: 60.94%, op_acc: 39.06%] [G loss: 0.861794]\n",
      "epoch:24 step:19026[D loss: 0.455956, acc: 53.91%, op_acc: 34.38%] [G loss: 0.869421]\n",
      "epoch:24 step:19027[D loss: 0.412856, acc: 60.94%, op_acc: 42.97%] [G loss: 0.880936]\n",
      "epoch:24 step:19028[D loss: 0.411484, acc: 62.50%, op_acc: 36.72%] [G loss: 0.810353]\n",
      "epoch:24 step:19029[D loss: 0.409334, acc: 61.72%, op_acc: 35.16%] [G loss: 0.910710]\n",
      "epoch:24 step:19030[D loss: 0.435111, acc: 60.16%, op_acc: 37.50%] [G loss: 0.836904]\n",
      "epoch:24 step:19031[D loss: 0.437510, acc: 59.38%, op_acc: 39.84%] [G loss: 0.900662]\n",
      "epoch:24 step:19032[D loss: 0.412697, acc: 60.16%, op_acc: 45.31%] [G loss: 0.832840]\n",
      "epoch:24 step:19033[D loss: 0.434061, acc: 57.81%, op_acc: 33.59%] [G loss: 0.908733]\n",
      "epoch:24 step:19034[D loss: 0.432364, acc: 57.03%, op_acc: 39.84%] [G loss: 0.919872]\n",
      "epoch:24 step:19035[D loss: 0.408994, acc: 64.84%, op_acc: 45.31%] [G loss: 0.935603]\n",
      "epoch:24 step:19036[D loss: 0.435436, acc: 61.72%, op_acc: 38.28%] [G loss: 0.909374]\n",
      "epoch:24 step:19037[D loss: 0.428251, acc: 48.44%, op_acc: 40.62%] [G loss: 0.834772]\n",
      "epoch:24 step:19038[D loss: 0.431885, acc: 63.28%, op_acc: 34.38%] [G loss: 0.826575]\n",
      "epoch:24 step:19039[D loss: 0.394701, acc: 66.41%, op_acc: 39.84%] [G loss: 0.822305]\n",
      "epoch:24 step:19040[D loss: 0.404368, acc: 60.94%, op_acc: 42.19%] [G loss: 0.856752]\n",
      "epoch:24 step:19041[D loss: 0.425904, acc: 63.28%, op_acc: 35.16%] [G loss: 0.798529]\n",
      "epoch:24 step:19042[D loss: 0.434970, acc: 63.28%, op_acc: 34.38%] [G loss: 0.826506]\n",
      "epoch:24 step:19043[D loss: 0.417364, acc: 57.03%, op_acc: 35.94%] [G loss: 0.893395]\n",
      "epoch:24 step:19044[D loss: 0.460428, acc: 47.66%, op_acc: 32.03%] [G loss: 0.835415]\n",
      "epoch:24 step:19045[D loss: 0.433377, acc: 54.69%, op_acc: 39.06%] [G loss: 0.833258]\n",
      "epoch:24 step:19046[D loss: 0.397420, acc: 67.97%, op_acc: 42.19%] [G loss: 0.867833]\n",
      "epoch:24 step:19047[D loss: 0.423173, acc: 60.16%, op_acc: 41.41%] [G loss: 0.884390]\n",
      "epoch:24 step:19048[D loss: 0.425088, acc: 57.03%, op_acc: 39.84%] [G loss: 0.862038]\n",
      "epoch:24 step:19049[D loss: 0.410963, acc: 60.16%, op_acc: 44.53%] [G loss: 0.892814]\n",
      "epoch:24 step:19050[D loss: 0.461733, acc: 56.25%, op_acc: 35.16%] [G loss: 0.900811]\n",
      "epoch:24 step:19051[D loss: 0.425468, acc: 63.28%, op_acc: 39.84%] [G loss: 0.854095]\n",
      "epoch:24 step:19052[D loss: 0.406252, acc: 70.31%, op_acc: 33.59%] [G loss: 0.921023]\n",
      "epoch:24 step:19053[D loss: 0.455965, acc: 54.69%, op_acc: 34.38%] [G loss: 0.886100]\n",
      "epoch:24 step:19054[D loss: 0.415823, acc: 67.19%, op_acc: 32.81%] [G loss: 0.855146]\n",
      "epoch:24 step:19055[D loss: 0.422087, acc: 58.59%, op_acc: 39.06%] [G loss: 0.924985]\n",
      "epoch:24 step:19056[D loss: 0.419408, acc: 60.94%, op_acc: 36.72%] [G loss: 0.904775]\n",
      "epoch:24 step:19057[D loss: 0.412176, acc: 61.72%, op_acc: 37.50%] [G loss: 0.865258]\n",
      "epoch:24 step:19058[D loss: 0.429141, acc: 60.94%, op_acc: 36.72%] [G loss: 0.876652]\n",
      "epoch:24 step:19059[D loss: 0.441655, acc: 57.81%, op_acc: 33.59%] [G loss: 0.815048]\n",
      "epoch:24 step:19060[D loss: 0.429533, acc: 61.72%, op_acc: 43.75%] [G loss: 0.864133]\n",
      "epoch:24 step:19061[D loss: 0.440019, acc: 62.50%, op_acc: 32.81%] [G loss: 0.832653]\n",
      "epoch:24 step:19062[D loss: 0.439743, acc: 58.59%, op_acc: 34.38%] [G loss: 0.885189]\n",
      "epoch:24 step:19063[D loss: 0.417319, acc: 65.62%, op_acc: 32.03%] [G loss: 0.989764]\n",
      "epoch:24 step:19064[D loss: 0.401239, acc: 57.81%, op_acc: 40.62%] [G loss: 0.845543]\n",
      "epoch:24 step:19065[D loss: 0.444704, acc: 55.47%, op_acc: 40.62%] [G loss: 0.890212]\n",
      "epoch:24 step:19066[D loss: 0.415011, acc: 60.16%, op_acc: 41.41%] [G loss: 0.882085]\n",
      "epoch:24 step:19067[D loss: 0.415234, acc: 58.59%, op_acc: 44.53%] [G loss: 0.868322]\n",
      "epoch:24 step:19068[D loss: 0.476933, acc: 50.78%, op_acc: 34.38%] [G loss: 0.860909]\n",
      "epoch:24 step:19069[D loss: 0.411526, acc: 57.03%, op_acc: 41.41%] [G loss: 0.876211]\n",
      "epoch:24 step:19070[D loss: 0.442069, acc: 58.59%, op_acc: 37.50%] [G loss: 0.880860]\n",
      "epoch:24 step:19071[D loss: 0.400748, acc: 64.84%, op_acc: 33.59%] [G loss: 0.905094]\n",
      "epoch:24 step:19072[D loss: 0.422200, acc: 54.69%, op_acc: 38.28%] [G loss: 0.830838]\n",
      "epoch:24 step:19073[D loss: 0.439841, acc: 58.59%, op_acc: 43.75%] [G loss: 0.905973]\n",
      "epoch:24 step:19074[D loss: 0.430006, acc: 54.69%, op_acc: 40.62%] [G loss: 0.832198]\n",
      "epoch:24 step:19075[D loss: 0.443684, acc: 51.56%, op_acc: 42.19%] [G loss: 0.959533]\n",
      "epoch:24 step:19076[D loss: 0.416472, acc: 59.38%, op_acc: 40.62%] [G loss: 0.815122]\n",
      "epoch:24 step:19077[D loss: 0.427038, acc: 64.06%, op_acc: 40.62%] [G loss: 0.805817]\n",
      "epoch:24 step:19078[D loss: 0.420907, acc: 56.25%, op_acc: 42.97%] [G loss: 0.779211]\n",
      "epoch:24 step:19079[D loss: 0.427451, acc: 59.38%, op_acc: 38.28%] [G loss: 0.847119]\n",
      "epoch:24 step:19080[D loss: 0.427110, acc: 64.06%, op_acc: 42.19%] [G loss: 0.849879]\n",
      "epoch:24 step:19081[D loss: 0.436711, acc: 64.06%, op_acc: 33.59%] [G loss: 0.852505]\n",
      "epoch:24 step:19082[D loss: 0.415552, acc: 63.28%, op_acc: 42.19%] [G loss: 0.873835]\n",
      "epoch:24 step:19083[D loss: 0.424214, acc: 60.94%, op_acc: 42.19%] [G loss: 0.889133]\n",
      "epoch:24 step:19084[D loss: 0.429102, acc: 53.12%, op_acc: 41.41%] [G loss: 0.922990]\n",
      "epoch:24 step:19085[D loss: 0.437594, acc: 61.72%, op_acc: 38.28%] [G loss: 0.884460]\n",
      "epoch:24 step:19086[D loss: 0.424039, acc: 56.25%, op_acc: 41.41%] [G loss: 0.910528]\n",
      "epoch:24 step:19087[D loss: 0.425611, acc: 61.72%, op_acc: 36.72%] [G loss: 0.885179]\n",
      "epoch:24 step:19088[D loss: 0.426539, acc: 51.56%, op_acc: 46.09%] [G loss: 0.861715]\n",
      "epoch:24 step:19089[D loss: 0.426468, acc: 57.81%, op_acc: 36.72%] [G loss: 0.856895]\n",
      "epoch:24 step:19090[D loss: 0.446310, acc: 53.12%, op_acc: 40.62%] [G loss: 0.872457]\n",
      "epoch:24 step:19091[D loss: 0.432679, acc: 54.69%, op_acc: 39.06%] [G loss: 0.859796]\n",
      "epoch:24 step:19092[D loss: 0.406315, acc: 67.19%, op_acc: 39.84%] [G loss: 0.844121]\n",
      "epoch:24 step:19093[D loss: 0.388550, acc: 70.31%, op_acc: 44.53%] [G loss: 0.913924]\n",
      "epoch:24 step:19094[D loss: 0.427392, acc: 66.41%, op_acc: 32.81%] [G loss: 0.874557]\n",
      "epoch:24 step:19095[D loss: 0.433062, acc: 57.03%, op_acc: 33.59%] [G loss: 0.828894]\n",
      "epoch:24 step:19096[D loss: 0.424741, acc: 64.06%, op_acc: 37.50%] [G loss: 0.896928]\n",
      "epoch:24 step:19097[D loss: 0.407441, acc: 59.38%, op_acc: 40.62%] [G loss: 0.831906]\n",
      "epoch:24 step:19098[D loss: 0.457244, acc: 51.56%, op_acc: 33.59%] [G loss: 0.898091]\n",
      "epoch:24 step:19099[D loss: 0.448240, acc: 53.91%, op_acc: 41.41%] [G loss: 0.793202]\n",
      "epoch:24 step:19100[D loss: 0.419080, acc: 63.28%, op_acc: 35.94%] [G loss: 0.909012]\n",
      "epoch:24 step:19101[D loss: 0.411668, acc: 64.06%, op_acc: 41.41%] [G loss: 0.858360]\n",
      "epoch:24 step:19102[D loss: 0.437573, acc: 54.69%, op_acc: 38.28%] [G loss: 0.866995]\n",
      "epoch:24 step:19103[D loss: 0.413244, acc: 60.16%, op_acc: 35.16%] [G loss: 0.929389]\n",
      "epoch:24 step:19104[D loss: 0.425959, acc: 59.38%, op_acc: 39.06%] [G loss: 0.897721]\n",
      "epoch:24 step:19105[D loss: 0.400624, acc: 54.69%, op_acc: 43.75%] [G loss: 0.914888]\n",
      "epoch:24 step:19106[D loss: 0.406189, acc: 64.06%, op_acc: 42.19%] [G loss: 0.941055]\n",
      "epoch:24 step:19107[D loss: 0.477701, acc: 49.22%, op_acc: 31.25%] [G loss: 0.853428]\n",
      "epoch:24 step:19108[D loss: 0.453145, acc: 52.34%, op_acc: 42.19%] [G loss: 0.861929]\n",
      "epoch:24 step:19109[D loss: 0.394089, acc: 59.38%, op_acc: 43.75%] [G loss: 0.912076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19110[D loss: 0.400290, acc: 58.59%, op_acc: 42.19%] [G loss: 0.880113]\n",
      "epoch:24 step:19111[D loss: 0.463394, acc: 56.25%, op_acc: 36.72%] [G loss: 0.839251]\n",
      "epoch:24 step:19112[D loss: 0.429958, acc: 54.69%, op_acc: 39.06%] [G loss: 0.845865]\n",
      "epoch:24 step:19113[D loss: 0.413340, acc: 62.50%, op_acc: 42.19%] [G loss: 0.820318]\n",
      "epoch:24 step:19114[D loss: 0.430746, acc: 60.16%, op_acc: 39.84%] [G loss: 0.854129]\n",
      "epoch:24 step:19115[D loss: 0.422547, acc: 60.94%, op_acc: 39.84%] [G loss: 0.891044]\n",
      "epoch:24 step:19116[D loss: 0.404602, acc: 61.72%, op_acc: 45.31%] [G loss: 0.919860]\n",
      "epoch:24 step:19117[D loss: 0.400865, acc: 60.16%, op_acc: 38.28%] [G loss: 0.913653]\n",
      "epoch:24 step:19118[D loss: 0.399877, acc: 66.41%, op_acc: 45.31%] [G loss: 0.869745]\n",
      "epoch:24 step:19119[D loss: 0.416014, acc: 64.06%, op_acc: 43.75%] [G loss: 0.846673]\n",
      "epoch:24 step:19120[D loss: 0.376462, acc: 71.09%, op_acc: 39.84%] [G loss: 0.897733]\n",
      "epoch:24 step:19121[D loss: 0.399043, acc: 71.88%, op_acc: 42.19%] [G loss: 0.840514]\n",
      "epoch:24 step:19122[D loss: 0.431843, acc: 57.03%, op_acc: 39.06%] [G loss: 0.922317]\n",
      "epoch:24 step:19123[D loss: 0.404676, acc: 63.28%, op_acc: 45.31%] [G loss: 0.842006]\n",
      "epoch:24 step:19124[D loss: 0.382564, acc: 69.53%, op_acc: 41.41%] [G loss: 0.927000]\n",
      "epoch:24 step:19125[D loss: 0.399511, acc: 68.75%, op_acc: 39.84%] [G loss: 0.940449]\n",
      "epoch:24 step:19126[D loss: 0.421108, acc: 58.59%, op_acc: 39.84%] [G loss: 0.816846]\n",
      "epoch:24 step:19127[D loss: 0.418315, acc: 62.50%, op_acc: 42.19%] [G loss: 0.859391]\n",
      "epoch:24 step:19128[D loss: 0.428592, acc: 60.16%, op_acc: 33.59%] [G loss: 0.952707]\n",
      "epoch:24 step:19129[D loss: 0.432747, acc: 57.03%, op_acc: 39.06%] [G loss: 0.929300]\n",
      "epoch:24 step:19130[D loss: 0.406770, acc: 61.72%, op_acc: 43.75%] [G loss: 0.916657]\n",
      "epoch:24 step:19131[D loss: 0.439905, acc: 59.38%, op_acc: 34.38%] [G loss: 0.900102]\n",
      "epoch:24 step:19132[D loss: 0.441802, acc: 57.03%, op_acc: 37.50%] [G loss: 0.900455]\n",
      "epoch:24 step:19133[D loss: 0.452576, acc: 51.56%, op_acc: 40.62%] [G loss: 0.898730]\n",
      "epoch:24 step:19134[D loss: 0.402821, acc: 66.41%, op_acc: 39.84%] [G loss: 0.933386]\n",
      "epoch:24 step:19135[D loss: 0.420462, acc: 55.47%, op_acc: 45.31%] [G loss: 0.885799]\n",
      "epoch:24 step:19136[D loss: 0.414570, acc: 57.03%, op_acc: 40.62%] [G loss: 0.868115]\n",
      "epoch:24 step:19137[D loss: 0.430267, acc: 54.69%, op_acc: 42.97%] [G loss: 0.845762]\n",
      "epoch:24 step:19138[D loss: 0.448482, acc: 55.47%, op_acc: 33.59%] [G loss: 0.826625]\n",
      "epoch:24 step:19139[D loss: 0.431675, acc: 63.28%, op_acc: 36.72%] [G loss: 0.892051]\n",
      "epoch:24 step:19140[D loss: 0.408124, acc: 63.28%, op_acc: 39.06%] [G loss: 0.869747]\n",
      "epoch:24 step:19141[D loss: 0.408543, acc: 64.06%, op_acc: 42.97%] [G loss: 0.818093]\n",
      "epoch:24 step:19142[D loss: 0.434745, acc: 59.38%, op_acc: 39.06%] [G loss: 0.803253]\n",
      "epoch:24 step:19143[D loss: 0.395987, acc: 64.84%, op_acc: 48.44%] [G loss: 0.913983]\n",
      "epoch:24 step:19144[D loss: 0.416993, acc: 53.91%, op_acc: 40.62%] [G loss: 0.871889]\n",
      "epoch:24 step:19145[D loss: 0.421353, acc: 57.03%, op_acc: 39.84%] [G loss: 0.855594]\n",
      "epoch:24 step:19146[D loss: 0.426504, acc: 60.94%, op_acc: 38.28%] [G loss: 0.855622]\n",
      "epoch:24 step:19147[D loss: 0.392508, acc: 63.28%, op_acc: 45.31%] [G loss: 0.962857]\n",
      "epoch:24 step:19148[D loss: 0.410942, acc: 58.59%, op_acc: 41.41%] [G loss: 0.940213]\n",
      "epoch:24 step:19149[D loss: 0.432637, acc: 63.28%, op_acc: 42.19%] [G loss: 0.903548]\n",
      "epoch:24 step:19150[D loss: 0.416749, acc: 60.94%, op_acc: 41.41%] [G loss: 0.907747]\n",
      "epoch:24 step:19151[D loss: 0.388336, acc: 71.09%, op_acc: 42.97%] [G loss: 0.833800]\n",
      "epoch:24 step:19152[D loss: 0.417612, acc: 57.81%, op_acc: 39.84%] [G loss: 0.894590]\n",
      "epoch:24 step:19153[D loss: 0.418496, acc: 58.59%, op_acc: 42.19%] [G loss: 0.856027]\n",
      "epoch:24 step:19154[D loss: 0.382495, acc: 61.72%, op_acc: 42.19%] [G loss: 0.834334]\n",
      "epoch:24 step:19155[D loss: 0.422073, acc: 61.72%, op_acc: 35.16%] [G loss: 0.948403]\n",
      "epoch:24 step:19156[D loss: 0.423975, acc: 57.03%, op_acc: 42.19%] [G loss: 0.782070]\n",
      "epoch:24 step:19157[D loss: 0.422016, acc: 64.06%, op_acc: 45.31%] [G loss: 0.882281]\n",
      "epoch:24 step:19158[D loss: 0.428218, acc: 57.81%, op_acc: 37.50%] [G loss: 0.922911]\n",
      "epoch:24 step:19159[D loss: 0.394231, acc: 71.09%, op_acc: 39.84%] [G loss: 0.942853]\n",
      "epoch:24 step:19160[D loss: 0.391661, acc: 63.28%, op_acc: 39.84%] [G loss: 0.887762]\n",
      "epoch:24 step:19161[D loss: 0.416800, acc: 61.72%, op_acc: 40.62%] [G loss: 0.894739]\n",
      "epoch:24 step:19162[D loss: 0.426219, acc: 58.59%, op_acc: 41.41%] [G loss: 0.901691]\n",
      "epoch:24 step:19163[D loss: 0.410390, acc: 67.97%, op_acc: 35.94%] [G loss: 0.881837]\n",
      "epoch:24 step:19164[D loss: 0.454457, acc: 52.34%, op_acc: 41.41%] [G loss: 0.893379]\n",
      "epoch:24 step:19165[D loss: 0.465489, acc: 55.47%, op_acc: 36.72%] [G loss: 0.852802]\n",
      "epoch:24 step:19166[D loss: 0.418735, acc: 58.59%, op_acc: 42.19%] [G loss: 0.919933]\n",
      "epoch:24 step:19167[D loss: 0.453425, acc: 55.47%, op_acc: 39.84%] [G loss: 0.873932]\n",
      "epoch:24 step:19168[D loss: 0.436738, acc: 63.28%, op_acc: 29.69%] [G loss: 0.855690]\n",
      "epoch:24 step:19169[D loss: 0.405106, acc: 67.19%, op_acc: 42.97%] [G loss: 0.950679]\n",
      "epoch:24 step:19170[D loss: 0.437779, acc: 58.59%, op_acc: 41.41%] [G loss: 0.873521]\n",
      "epoch:24 step:19171[D loss: 0.414451, acc: 64.06%, op_acc: 35.94%] [G loss: 0.965370]\n",
      "epoch:24 step:19172[D loss: 0.421812, acc: 60.16%, op_acc: 42.19%] [G loss: 0.881934]\n",
      "epoch:24 step:19173[D loss: 0.408895, acc: 58.59%, op_acc: 43.75%] [G loss: 0.953655]\n",
      "epoch:24 step:19174[D loss: 0.421676, acc: 56.25%, op_acc: 42.19%] [G loss: 0.842702]\n",
      "epoch:24 step:19175[D loss: 0.444004, acc: 53.91%, op_acc: 41.41%] [G loss: 0.931099]\n",
      "epoch:24 step:19176[D loss: 0.421198, acc: 56.25%, op_acc: 42.19%] [G loss: 0.873251]\n",
      "epoch:24 step:19177[D loss: 0.430847, acc: 60.16%, op_acc: 39.84%] [G loss: 0.959798]\n",
      "epoch:24 step:19178[D loss: 0.393220, acc: 62.50%, op_acc: 39.84%] [G loss: 0.859377]\n",
      "epoch:24 step:19179[D loss: 0.403066, acc: 62.50%, op_acc: 42.97%] [G loss: 0.828839]\n",
      "epoch:24 step:19180[D loss: 0.439680, acc: 57.81%, op_acc: 35.16%] [G loss: 0.867863]\n",
      "epoch:24 step:19181[D loss: 0.451357, acc: 47.66%, op_acc: 39.06%] [G loss: 0.857184]\n",
      "epoch:24 step:19182[D loss: 0.417379, acc: 58.59%, op_acc: 41.41%] [G loss: 0.849285]\n",
      "epoch:24 step:19183[D loss: 0.423445, acc: 59.38%, op_acc: 39.84%] [G loss: 0.876019]\n",
      "epoch:24 step:19184[D loss: 0.442063, acc: 54.69%, op_acc: 39.84%] [G loss: 0.800212]\n",
      "epoch:24 step:19185[D loss: 0.412070, acc: 60.94%, op_acc: 44.53%] [G loss: 0.928304]\n",
      "epoch:24 step:19186[D loss: 0.408902, acc: 61.72%, op_acc: 42.19%] [G loss: 0.863007]\n",
      "epoch:24 step:19187[D loss: 0.445954, acc: 55.47%, op_acc: 39.84%] [G loss: 0.863606]\n",
      "epoch:24 step:19188[D loss: 0.405351, acc: 60.94%, op_acc: 43.75%] [G loss: 0.861496]\n",
      "epoch:24 step:19189[D loss: 0.421656, acc: 57.03%, op_acc: 40.62%] [G loss: 0.894560]\n",
      "epoch:24 step:19190[D loss: 0.416303, acc: 60.94%, op_acc: 41.41%] [G loss: 0.932454]\n",
      "epoch:24 step:19191[D loss: 0.417507, acc: 65.62%, op_acc: 35.16%] [G loss: 0.810815]\n",
      "epoch:24 step:19192[D loss: 0.423915, acc: 61.72%, op_acc: 36.72%] [G loss: 0.906919]\n",
      "epoch:24 step:19193[D loss: 0.399429, acc: 60.94%, op_acc: 38.28%] [G loss: 0.843791]\n",
      "epoch:24 step:19194[D loss: 0.457606, acc: 56.25%, op_acc: 35.94%] [G loss: 0.769461]\n",
      "epoch:24 step:19195[D loss: 0.426419, acc: 57.03%, op_acc: 42.19%] [G loss: 0.892429]\n",
      "epoch:24 step:19196[D loss: 0.396615, acc: 64.06%, op_acc: 42.97%] [G loss: 0.821832]\n",
      "epoch:24 step:19197[D loss: 0.417094, acc: 56.25%, op_acc: 47.66%] [G loss: 0.908448]\n",
      "epoch:24 step:19198[D loss: 0.408124, acc: 65.62%, op_acc: 41.41%] [G loss: 0.967883]\n",
      "epoch:24 step:19199[D loss: 0.463912, acc: 54.69%, op_acc: 37.50%] [G loss: 0.930700]\n",
      "epoch:24 step:19200[D loss: 0.439469, acc: 58.59%, op_acc: 35.94%] [G loss: 0.871932]\n",
      "epoch:24 step:19201[D loss: 0.442423, acc: 55.47%, op_acc: 39.84%] [G loss: 0.895258]\n",
      "epoch:24 step:19202[D loss: 0.417656, acc: 59.38%, op_acc: 40.62%] [G loss: 0.841634]\n",
      "epoch:24 step:19203[D loss: 0.411830, acc: 54.69%, op_acc: 42.19%] [G loss: 0.885479]\n",
      "epoch:24 step:19204[D loss: 0.413213, acc: 59.38%, op_acc: 43.75%] [G loss: 0.860022]\n",
      "epoch:24 step:19205[D loss: 0.433447, acc: 57.81%, op_acc: 39.84%] [G loss: 0.829574]\n",
      "epoch:24 step:19206[D loss: 0.426308, acc: 57.03%, op_acc: 40.62%] [G loss: 0.868202]\n",
      "epoch:24 step:19207[D loss: 0.398017, acc: 64.84%, op_acc: 35.16%] [G loss: 0.894232]\n",
      "epoch:24 step:19208[D loss: 0.448163, acc: 59.38%, op_acc: 36.72%] [G loss: 0.908498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19209[D loss: 0.425665, acc: 59.38%, op_acc: 36.72%] [G loss: 0.875812]\n",
      "epoch:24 step:19210[D loss: 0.413257, acc: 57.81%, op_acc: 40.62%] [G loss: 0.892863]\n",
      "epoch:24 step:19211[D loss: 0.408807, acc: 57.03%, op_acc: 45.31%] [G loss: 0.875890]\n",
      "epoch:24 step:19212[D loss: 0.437365, acc: 53.12%, op_acc: 42.19%] [G loss: 0.821384]\n",
      "epoch:24 step:19213[D loss: 0.387546, acc: 64.84%, op_acc: 43.75%] [G loss: 0.932298]\n",
      "epoch:24 step:19214[D loss: 0.393195, acc: 66.41%, op_acc: 46.88%] [G loss: 0.959008]\n",
      "epoch:24 step:19215[D loss: 0.444361, acc: 60.16%, op_acc: 38.28%] [G loss: 0.909499]\n",
      "epoch:24 step:19216[D loss: 0.441962, acc: 58.59%, op_acc: 37.50%] [G loss: 0.818840]\n",
      "epoch:24 step:19217[D loss: 0.381501, acc: 60.94%, op_acc: 53.12%] [G loss: 0.937524]\n",
      "epoch:24 step:19218[D loss: 0.446812, acc: 54.69%, op_acc: 34.38%] [G loss: 0.837344]\n",
      "epoch:24 step:19219[D loss: 0.433949, acc: 53.91%, op_acc: 41.41%] [G loss: 0.850996]\n",
      "epoch:24 step:19220[D loss: 0.432794, acc: 60.16%, op_acc: 40.62%] [G loss: 0.887396]\n",
      "epoch:24 step:19221[D loss: 0.411543, acc: 62.50%, op_acc: 39.84%] [G loss: 0.970232]\n",
      "epoch:24 step:19222[D loss: 0.397119, acc: 60.94%, op_acc: 39.06%] [G loss: 0.896905]\n",
      "epoch:24 step:19223[D loss: 0.439565, acc: 60.16%, op_acc: 34.38%] [G loss: 0.922217]\n",
      "epoch:24 step:19224[D loss: 0.442706, acc: 53.91%, op_acc: 32.81%] [G loss: 0.762024]\n",
      "epoch:24 step:19225[D loss: 0.423100, acc: 58.59%, op_acc: 33.59%] [G loss: 0.836857]\n",
      "epoch:24 step:19226[D loss: 0.429497, acc: 63.28%, op_acc: 37.50%] [G loss: 0.858147]\n",
      "epoch:24 step:19227[D loss: 0.448497, acc: 51.56%, op_acc: 41.41%] [G loss: 0.850366]\n",
      "epoch:24 step:19228[D loss: 0.420485, acc: 60.94%, op_acc: 42.97%] [G loss: 0.868310]\n",
      "epoch:24 step:19229[D loss: 0.404442, acc: 62.50%, op_acc: 43.75%] [G loss: 0.940204]\n",
      "epoch:24 step:19230[D loss: 0.379368, acc: 75.00%, op_acc: 41.41%] [G loss: 0.875250]\n",
      "epoch:24 step:19231[D loss: 0.419836, acc: 64.84%, op_acc: 39.84%] [G loss: 0.872038]\n",
      "epoch:24 step:19232[D loss: 0.453136, acc: 50.78%, op_acc: 39.84%] [G loss: 0.864326]\n",
      "epoch:24 step:19233[D loss: 0.415799, acc: 57.03%, op_acc: 46.09%] [G loss: 0.795519]\n",
      "epoch:24 step:19234[D loss: 0.427635, acc: 55.47%, op_acc: 41.41%] [G loss: 0.813954]\n",
      "epoch:24 step:19235[D loss: 0.439353, acc: 60.94%, op_acc: 39.84%] [G loss: 0.892819]\n",
      "epoch:24 step:19236[D loss: 0.414829, acc: 59.38%, op_acc: 35.94%] [G loss: 0.804750]\n",
      "epoch:24 step:19237[D loss: 0.427849, acc: 60.16%, op_acc: 40.62%] [G loss: 0.826262]\n",
      "epoch:24 step:19238[D loss: 0.371315, acc: 71.09%, op_acc: 41.41%] [G loss: 0.930582]\n",
      "epoch:24 step:19239[D loss: 0.420791, acc: 67.97%, op_acc: 36.72%] [G loss: 0.887766]\n",
      "epoch:24 step:19240[D loss: 0.399203, acc: 64.06%, op_acc: 43.75%] [G loss: 0.903051]\n",
      "epoch:24 step:19241[D loss: 0.403229, acc: 57.81%, op_acc: 37.50%] [G loss: 0.888363]\n",
      "epoch:24 step:19242[D loss: 0.428329, acc: 60.94%, op_acc: 39.06%] [G loss: 0.946507]\n",
      "epoch:24 step:19243[D loss: 0.423269, acc: 60.94%, op_acc: 35.16%] [G loss: 0.838351]\n",
      "epoch:24 step:19244[D loss: 0.406036, acc: 61.72%, op_acc: 42.19%] [G loss: 0.878738]\n",
      "epoch:24 step:19245[D loss: 0.438892, acc: 58.59%, op_acc: 28.12%] [G loss: 0.878443]\n",
      "epoch:24 step:19246[D loss: 0.429058, acc: 59.38%, op_acc: 39.84%] [G loss: 0.950686]\n",
      "epoch:24 step:19247[D loss: 0.439969, acc: 55.47%, op_acc: 32.03%] [G loss: 0.943054]\n",
      "epoch:24 step:19248[D loss: 0.449774, acc: 54.69%, op_acc: 39.84%] [G loss: 0.803799]\n",
      "epoch:24 step:19249[D loss: 0.428775, acc: 61.72%, op_acc: 33.59%] [G loss: 0.893749]\n",
      "epoch:24 step:19250[D loss: 0.428669, acc: 61.72%, op_acc: 33.59%] [G loss: 0.822519]\n",
      "epoch:24 step:19251[D loss: 0.403041, acc: 63.28%, op_acc: 40.62%] [G loss: 0.849055]\n",
      "epoch:24 step:19252[D loss: 0.422066, acc: 58.59%, op_acc: 35.16%] [G loss: 0.803577]\n",
      "epoch:24 step:19253[D loss: 0.426527, acc: 62.50%, op_acc: 36.72%] [G loss: 0.848832]\n",
      "epoch:24 step:19254[D loss: 0.426693, acc: 60.94%, op_acc: 36.72%] [G loss: 0.888646]\n",
      "epoch:24 step:19255[D loss: 0.411467, acc: 60.94%, op_acc: 39.84%] [G loss: 0.896171]\n",
      "epoch:24 step:19256[D loss: 0.475750, acc: 48.44%, op_acc: 32.81%] [G loss: 0.830436]\n",
      "epoch:24 step:19257[D loss: 0.480247, acc: 47.66%, op_acc: 35.16%] [G loss: 0.897575]\n",
      "epoch:24 step:19258[D loss: 0.449215, acc: 53.12%, op_acc: 39.84%] [G loss: 0.828777]\n",
      "epoch:24 step:19259[D loss: 0.411420, acc: 63.28%, op_acc: 37.50%] [G loss: 0.904270]\n",
      "epoch:24 step:19260[D loss: 0.405574, acc: 61.72%, op_acc: 43.75%] [G loss: 0.886999]\n",
      "epoch:24 step:19261[D loss: 0.457955, acc: 57.03%, op_acc: 37.50%] [G loss: 0.890584]\n",
      "epoch:24 step:19262[D loss: 0.389325, acc: 63.28%, op_acc: 43.75%] [G loss: 0.855713]\n",
      "epoch:24 step:19263[D loss: 0.372447, acc: 69.53%, op_acc: 36.72%] [G loss: 0.772039]\n",
      "epoch:24 step:19264[D loss: 0.422787, acc: 53.12%, op_acc: 36.72%] [G loss: 0.861250]\n",
      "epoch:24 step:19265[D loss: 0.412176, acc: 64.84%, op_acc: 40.62%] [G loss: 0.886870]\n",
      "epoch:24 step:19266[D loss: 0.406091, acc: 67.19%, op_acc: 41.41%] [G loss: 0.908520]\n",
      "epoch:24 step:19267[D loss: 0.439586, acc: 53.12%, op_acc: 38.28%] [G loss: 0.846426]\n",
      "epoch:24 step:19268[D loss: 0.417319, acc: 64.06%, op_acc: 34.38%] [G loss: 0.937196]\n",
      "epoch:24 step:19269[D loss: 0.445264, acc: 65.62%, op_acc: 34.38%] [G loss: 0.843415]\n",
      "epoch:24 step:19270[D loss: 0.488369, acc: 49.22%, op_acc: 28.91%] [G loss: 0.875512]\n",
      "epoch:24 step:19271[D loss: 0.443575, acc: 43.75%, op_acc: 41.41%] [G loss: 0.894851]\n",
      "epoch:24 step:19272[D loss: 0.438573, acc: 53.12%, op_acc: 39.06%] [G loss: 0.917368]\n",
      "epoch:24 step:19273[D loss: 0.427313, acc: 55.47%, op_acc: 41.41%] [G loss: 0.833709]\n",
      "epoch:24 step:19274[D loss: 0.412552, acc: 67.19%, op_acc: 35.16%] [G loss: 0.947394]\n",
      "epoch:24 step:19275[D loss: 0.424654, acc: 64.06%, op_acc: 36.72%] [G loss: 0.893737]\n",
      "epoch:24 step:19276[D loss: 0.452936, acc: 55.47%, op_acc: 32.81%] [G loss: 0.930475]\n",
      "epoch:24 step:19277[D loss: 0.425271, acc: 63.28%, op_acc: 42.19%] [G loss: 0.870347]\n",
      "epoch:24 step:19278[D loss: 0.409144, acc: 57.81%, op_acc: 43.75%] [G loss: 0.858897]\n",
      "epoch:24 step:19279[D loss: 0.431616, acc: 57.81%, op_acc: 39.06%] [G loss: 0.904919]\n",
      "epoch:24 step:19280[D loss: 0.427686, acc: 51.56%, op_acc: 37.50%] [G loss: 0.883189]\n",
      "epoch:24 step:19281[D loss: 0.459830, acc: 59.38%, op_acc: 32.81%] [G loss: 0.866058]\n",
      "epoch:24 step:19282[D loss: 0.400603, acc: 59.38%, op_acc: 42.97%] [G loss: 0.884677]\n",
      "epoch:24 step:19283[D loss: 0.435754, acc: 60.94%, op_acc: 35.94%] [G loss: 0.935003]\n",
      "epoch:24 step:19284[D loss: 0.425798, acc: 52.34%, op_acc: 39.06%] [G loss: 0.870648]\n",
      "epoch:24 step:19285[D loss: 0.438388, acc: 46.88%, op_acc: 39.84%] [G loss: 0.858693]\n",
      "epoch:24 step:19286[D loss: 0.446954, acc: 51.56%, op_acc: 39.06%] [G loss: 0.834855]\n",
      "epoch:24 step:19287[D loss: 0.430154, acc: 58.59%, op_acc: 39.84%] [G loss: 0.846825]\n",
      "epoch:24 step:19288[D loss: 0.425362, acc: 59.38%, op_acc: 35.94%] [G loss: 0.819872]\n",
      "epoch:24 step:19289[D loss: 0.383387, acc: 62.50%, op_acc: 42.97%] [G loss: 0.954415]\n",
      "epoch:24 step:19290[D loss: 0.413075, acc: 60.94%, op_acc: 42.19%] [G loss: 0.847065]\n",
      "epoch:24 step:19291[D loss: 0.389961, acc: 69.53%, op_acc: 42.97%] [G loss: 1.008165]\n",
      "epoch:24 step:19292[D loss: 0.415830, acc: 57.81%, op_acc: 30.47%] [G loss: 0.925704]\n",
      "epoch:24 step:19293[D loss: 0.464346, acc: 57.03%, op_acc: 40.62%] [G loss: 0.933241]\n",
      "epoch:24 step:19294[D loss: 0.419295, acc: 60.94%, op_acc: 39.06%] [G loss: 0.946628]\n",
      "epoch:24 step:19295[D loss: 0.388831, acc: 67.97%, op_acc: 42.97%] [G loss: 0.973222]\n",
      "epoch:24 step:19296[D loss: 0.463126, acc: 51.56%, op_acc: 35.94%] [G loss: 0.891192]\n",
      "epoch:24 step:19297[D loss: 0.420585, acc: 55.47%, op_acc: 40.62%] [G loss: 0.954558]\n",
      "epoch:24 step:19298[D loss: 0.441213, acc: 60.16%, op_acc: 35.94%] [G loss: 0.909492]\n",
      "epoch:24 step:19299[D loss: 0.384121, acc: 62.50%, op_acc: 39.06%] [G loss: 0.953848]\n",
      "epoch:24 step:19300[D loss: 0.409445, acc: 60.94%, op_acc: 39.06%] [G loss: 0.903826]\n",
      "epoch:24 step:19301[D loss: 0.434469, acc: 57.81%, op_acc: 32.03%] [G loss: 0.912589]\n",
      "epoch:24 step:19302[D loss: 0.394454, acc: 63.28%, op_acc: 46.09%] [G loss: 0.969434]\n",
      "epoch:24 step:19303[D loss: 0.407450, acc: 67.97%, op_acc: 36.72%] [G loss: 0.981050]\n",
      "epoch:24 step:19304[D loss: 0.433996, acc: 61.72%, op_acc: 37.50%] [G loss: 0.821817]\n",
      "epoch:24 step:19305[D loss: 0.366652, acc: 69.53%, op_acc: 45.31%] [G loss: 0.939779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19306[D loss: 0.397781, acc: 64.06%, op_acc: 39.06%] [G loss: 0.964159]\n",
      "epoch:24 step:19307[D loss: 0.414125, acc: 65.62%, op_acc: 39.06%] [G loss: 0.931786]\n",
      "epoch:24 step:19308[D loss: 0.376685, acc: 68.75%, op_acc: 47.66%] [G loss: 0.966766]\n",
      "epoch:24 step:19309[D loss: 0.400510, acc: 64.06%, op_acc: 43.75%] [G loss: 0.939581]\n",
      "epoch:24 step:19310[D loss: 0.406801, acc: 61.72%, op_acc: 43.75%] [G loss: 1.013758]\n",
      "epoch:24 step:19311[D loss: 0.386901, acc: 66.41%, op_acc: 45.31%] [G loss: 0.914146]\n",
      "epoch:24 step:19312[D loss: 0.413795, acc: 60.16%, op_acc: 44.53%] [G loss: 0.919055]\n",
      "epoch:24 step:19313[D loss: 0.435890, acc: 54.69%, op_acc: 39.06%] [G loss: 0.915919]\n",
      "epoch:24 step:19314[D loss: 0.411259, acc: 62.50%, op_acc: 42.19%] [G loss: 0.848897]\n",
      "epoch:24 step:19315[D loss: 0.409072, acc: 60.94%, op_acc: 51.56%] [G loss: 0.918230]\n",
      "epoch:24 step:19316[D loss: 0.429663, acc: 58.59%, op_acc: 42.19%] [G loss: 0.812525]\n",
      "epoch:24 step:19317[D loss: 0.432906, acc: 57.03%, op_acc: 42.97%] [G loss: 0.858703]\n",
      "epoch:24 step:19318[D loss: 0.425993, acc: 62.50%, op_acc: 39.84%] [G loss: 0.958388]\n",
      "epoch:24 step:19319[D loss: 0.413024, acc: 60.16%, op_acc: 41.41%] [G loss: 0.834071]\n",
      "epoch:24 step:19320[D loss: 0.445313, acc: 54.69%, op_acc: 36.72%] [G loss: 0.841408]\n",
      "epoch:24 step:19321[D loss: 0.461452, acc: 56.25%, op_acc: 36.72%] [G loss: 0.866775]\n",
      "epoch:24 step:19322[D loss: 0.448196, acc: 59.38%, op_acc: 35.16%] [G loss: 0.782849]\n",
      "epoch:24 step:19323[D loss: 0.385725, acc: 67.97%, op_acc: 45.31%] [G loss: 0.862652]\n",
      "epoch:24 step:19324[D loss: 0.407528, acc: 64.84%, op_acc: 41.41%] [G loss: 0.940437]\n",
      "epoch:24 step:19325[D loss: 0.451713, acc: 60.94%, op_acc: 32.81%] [G loss: 0.902398]\n",
      "epoch:24 step:19326[D loss: 0.416574, acc: 61.72%, op_acc: 37.50%] [G loss: 0.868528]\n",
      "epoch:24 step:19327[D loss: 0.419976, acc: 58.59%, op_acc: 37.50%] [G loss: 0.854205]\n",
      "epoch:24 step:19328[D loss: 0.448458, acc: 57.81%, op_acc: 31.25%] [G loss: 0.891887]\n",
      "epoch:24 step:19329[D loss: 0.441734, acc: 50.00%, op_acc: 35.94%] [G loss: 0.856977]\n",
      "epoch:24 step:19330[D loss: 0.425242, acc: 61.72%, op_acc: 43.75%] [G loss: 0.893021]\n",
      "epoch:24 step:19331[D loss: 0.452244, acc: 57.03%, op_acc: 34.38%] [G loss: 0.870227]\n",
      "epoch:24 step:19332[D loss: 0.398750, acc: 59.38%, op_acc: 44.53%] [G loss: 0.951962]\n",
      "epoch:24 step:19333[D loss: 0.420164, acc: 57.03%, op_acc: 37.50%] [G loss: 0.820498]\n",
      "epoch:24 step:19334[D loss: 0.415785, acc: 57.03%, op_acc: 41.41%] [G loss: 1.001100]\n",
      "epoch:24 step:19335[D loss: 0.427566, acc: 64.06%, op_acc: 36.72%] [G loss: 0.992216]\n",
      "epoch:24 step:19336[D loss: 0.398437, acc: 65.62%, op_acc: 38.28%] [G loss: 0.919642]\n",
      "epoch:24 step:19337[D loss: 0.430900, acc: 60.94%, op_acc: 32.03%] [G loss: 0.850030]\n",
      "epoch:24 step:19338[D loss: 0.411895, acc: 64.06%, op_acc: 38.28%] [G loss: 0.834076]\n",
      "epoch:24 step:19339[D loss: 0.406919, acc: 64.06%, op_acc: 38.28%] [G loss: 0.882978]\n",
      "epoch:24 step:19340[D loss: 0.436868, acc: 54.69%, op_acc: 35.94%] [G loss: 0.868998]\n",
      "epoch:24 step:19341[D loss: 0.388170, acc: 66.41%, op_acc: 42.19%] [G loss: 0.819034]\n",
      "epoch:24 step:19342[D loss: 0.401237, acc: 66.41%, op_acc: 37.50%] [G loss: 1.000982]\n",
      "epoch:24 step:19343[D loss: 0.416082, acc: 56.25%, op_acc: 35.16%] [G loss: 0.877290]\n",
      "epoch:24 step:19344[D loss: 0.397923, acc: 64.84%, op_acc: 42.19%] [G loss: 0.888058]\n",
      "epoch:24 step:19345[D loss: 0.403498, acc: 59.38%, op_acc: 42.19%] [G loss: 0.906357]\n",
      "epoch:24 step:19346[D loss: 0.366047, acc: 65.62%, op_acc: 47.66%] [G loss: 0.930361]\n",
      "epoch:24 step:19347[D loss: 0.402076, acc: 63.28%, op_acc: 39.84%] [G loss: 0.902117]\n",
      "epoch:24 step:19348[D loss: 0.433336, acc: 67.97%, op_acc: 40.62%] [G loss: 1.022094]\n",
      "epoch:24 step:19349[D loss: 0.381871, acc: 73.44%, op_acc: 40.62%] [G loss: 0.871403]\n",
      "epoch:24 step:19350[D loss: 0.425375, acc: 57.03%, op_acc: 38.28%] [G loss: 0.846850]\n",
      "epoch:24 step:19351[D loss: 0.443680, acc: 53.12%, op_acc: 41.41%] [G loss: 0.886623]\n",
      "epoch:24 step:19352[D loss: 0.379413, acc: 68.75%, op_acc: 46.09%] [G loss: 1.003037]\n",
      "epoch:24 step:19353[D loss: 0.448976, acc: 55.47%, op_acc: 37.50%] [G loss: 0.846300]\n",
      "epoch:24 step:19354[D loss: 0.408565, acc: 62.50%, op_acc: 37.50%] [G loss: 0.823577]\n",
      "epoch:24 step:19355[D loss: 0.417342, acc: 57.03%, op_acc: 42.19%] [G loss: 0.878382]\n",
      "epoch:24 step:19356[D loss: 0.441305, acc: 55.47%, op_acc: 35.16%] [G loss: 0.848227]\n",
      "epoch:24 step:19357[D loss: 0.402882, acc: 62.50%, op_acc: 39.84%] [G loss: 0.934728]\n",
      "epoch:24 step:19358[D loss: 0.419309, acc: 63.28%, op_acc: 39.84%] [G loss: 0.926282]\n",
      "epoch:24 step:19359[D loss: 0.419034, acc: 61.72%, op_acc: 37.50%] [G loss: 0.896594]\n",
      "epoch:24 step:19360[D loss: 0.485251, acc: 52.34%, op_acc: 33.59%] [G loss: 0.842873]\n",
      "epoch:24 step:19361[D loss: 0.438136, acc: 60.16%, op_acc: 40.62%] [G loss: 0.846967]\n",
      "epoch:24 step:19362[D loss: 0.395494, acc: 64.84%, op_acc: 41.41%] [G loss: 0.873332]\n",
      "epoch:24 step:19363[D loss: 0.456734, acc: 56.25%, op_acc: 38.28%] [G loss: 0.894870]\n",
      "epoch:24 step:19364[D loss: 0.392674, acc: 73.44%, op_acc: 32.81%] [G loss: 0.865238]\n",
      "epoch:24 step:19365[D loss: 0.439586, acc: 54.69%, op_acc: 41.41%] [G loss: 0.915393]\n",
      "epoch:24 step:19366[D loss: 0.449078, acc: 57.03%, op_acc: 35.16%] [G loss: 0.861296]\n",
      "epoch:24 step:19367[D loss: 0.394423, acc: 68.75%, op_acc: 39.06%] [G loss: 0.809399]\n",
      "epoch:24 step:19368[D loss: 0.426782, acc: 55.47%, op_acc: 44.53%] [G loss: 0.819025]\n",
      "epoch:24 step:19369[D loss: 0.445493, acc: 53.91%, op_acc: 35.94%] [G loss: 0.824383]\n",
      "epoch:24 step:19370[D loss: 0.421542, acc: 49.22%, op_acc: 41.41%] [G loss: 0.891610]\n",
      "epoch:24 step:19371[D loss: 0.423912, acc: 54.69%, op_acc: 39.84%] [G loss: 0.894797]\n",
      "epoch:24 step:19372[D loss: 0.442027, acc: 58.59%, op_acc: 39.84%] [G loss: 0.891352]\n",
      "epoch:24 step:19373[D loss: 0.440906, acc: 58.59%, op_acc: 36.72%] [G loss: 0.795811]\n",
      "epoch:24 step:19374[D loss: 0.421779, acc: 55.47%, op_acc: 39.84%] [G loss: 0.843113]\n",
      "epoch:24 step:19375[D loss: 0.428967, acc: 58.59%, op_acc: 43.75%] [G loss: 0.929201]\n",
      "epoch:24 step:19376[D loss: 0.419952, acc: 66.41%, op_acc: 37.50%] [G loss: 0.921609]\n",
      "epoch:24 step:19377[D loss: 0.422225, acc: 60.16%, op_acc: 38.28%] [G loss: 0.993978]\n",
      "epoch:24 step:19378[D loss: 0.406651, acc: 62.50%, op_acc: 40.62%] [G loss: 0.907736]\n",
      "epoch:24 step:19379[D loss: 0.464751, acc: 51.56%, op_acc: 37.50%] [G loss: 0.828609]\n",
      "epoch:24 step:19380[D loss: 0.413531, acc: 61.72%, op_acc: 42.19%] [G loss: 0.928126]\n",
      "epoch:24 step:19381[D loss: 0.416797, acc: 60.16%, op_acc: 34.38%] [G loss: 0.872448]\n",
      "epoch:24 step:19382[D loss: 0.419423, acc: 60.94%, op_acc: 40.62%] [G loss: 0.845292]\n",
      "epoch:24 step:19383[D loss: 0.444517, acc: 58.59%, op_acc: 37.50%] [G loss: 0.838052]\n",
      "epoch:24 step:19384[D loss: 0.455954, acc: 57.03%, op_acc: 42.97%] [G loss: 0.822413]\n",
      "epoch:24 step:19385[D loss: 0.405799, acc: 64.84%, op_acc: 36.72%] [G loss: 0.860125]\n",
      "epoch:24 step:19386[D loss: 0.439447, acc: 53.12%, op_acc: 42.19%] [G loss: 0.808783]\n",
      "epoch:24 step:19387[D loss: 0.405465, acc: 71.88%, op_acc: 41.41%] [G loss: 0.806057]\n",
      "epoch:24 step:19388[D loss: 0.403801, acc: 57.81%, op_acc: 42.19%] [G loss: 0.844769]\n",
      "epoch:24 step:19389[D loss: 0.444315, acc: 55.47%, op_acc: 39.84%] [G loss: 0.935680]\n",
      "epoch:24 step:19390[D loss: 0.415609, acc: 65.62%, op_acc: 35.16%] [G loss: 0.783147]\n",
      "epoch:24 step:19391[D loss: 0.400721, acc: 55.47%, op_acc: 47.66%] [G loss: 0.930284]\n",
      "epoch:24 step:19392[D loss: 0.400934, acc: 64.06%, op_acc: 37.50%] [G loss: 0.913764]\n",
      "epoch:24 step:19393[D loss: 0.435392, acc: 64.06%, op_acc: 39.84%] [G loss: 0.842670]\n",
      "epoch:24 step:19394[D loss: 0.431038, acc: 63.28%, op_acc: 35.16%] [G loss: 0.842920]\n",
      "epoch:24 step:19395[D loss: 0.394829, acc: 65.62%, op_acc: 44.53%] [G loss: 0.922749]\n",
      "epoch:24 step:19396[D loss: 0.386955, acc: 67.19%, op_acc: 41.41%] [G loss: 0.881199]\n",
      "epoch:24 step:19397[D loss: 0.401305, acc: 61.72%, op_acc: 39.84%] [G loss: 0.940602]\n",
      "epoch:24 step:19398[D loss: 0.394801, acc: 64.84%, op_acc: 43.75%] [G loss: 1.015441]\n",
      "epoch:24 step:19399[D loss: 0.438547, acc: 59.38%, op_acc: 39.06%] [G loss: 0.922488]\n",
      "epoch:24 step:19400[D loss: 0.430149, acc: 60.16%, op_acc: 40.62%] [G loss: 0.925231]\n",
      "epoch:24 step:19401[D loss: 0.444480, acc: 56.25%, op_acc: 35.16%] [G loss: 0.898344]\n",
      "epoch:24 step:19402[D loss: 0.393574, acc: 71.09%, op_acc: 42.97%] [G loss: 0.926204]\n",
      "epoch:24 step:19403[D loss: 0.379768, acc: 68.75%, op_acc: 39.84%] [G loss: 0.912287]\n",
      "epoch:24 step:19404[D loss: 0.425481, acc: 56.25%, op_acc: 42.97%] [G loss: 0.830178]\n",
      "epoch:24 step:19405[D loss: 0.423149, acc: 53.91%, op_acc: 41.41%] [G loss: 0.826643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19406[D loss: 0.434105, acc: 49.22%, op_acc: 43.75%] [G loss: 0.882237]\n",
      "epoch:24 step:19407[D loss: 0.402834, acc: 60.94%, op_acc: 38.28%] [G loss: 0.856630]\n",
      "epoch:24 step:19408[D loss: 0.402212, acc: 60.94%, op_acc: 36.72%] [G loss: 0.917152]\n",
      "epoch:24 step:19409[D loss: 0.424918, acc: 64.06%, op_acc: 36.72%] [G loss: 0.913431]\n",
      "epoch:24 step:19410[D loss: 0.428604, acc: 61.72%, op_acc: 38.28%] [G loss: 1.020761]\n",
      "epoch:24 step:19411[D loss: 0.410002, acc: 56.25%, op_acc: 46.09%] [G loss: 0.881418]\n",
      "epoch:24 step:19412[D loss: 0.416429, acc: 67.19%, op_acc: 40.62%] [G loss: 0.924115]\n",
      "epoch:24 step:19413[D loss: 0.415085, acc: 63.28%, op_acc: 39.84%] [G loss: 0.888910]\n",
      "epoch:24 step:19414[D loss: 0.433113, acc: 54.69%, op_acc: 38.28%] [G loss: 0.910347]\n",
      "epoch:24 step:19415[D loss: 0.422314, acc: 60.94%, op_acc: 39.06%] [G loss: 0.875166]\n",
      "epoch:24 step:19416[D loss: 0.427096, acc: 65.62%, op_acc: 35.16%] [G loss: 1.008537]\n",
      "epoch:24 step:19417[D loss: 0.419289, acc: 59.38%, op_acc: 35.94%] [G loss: 0.960281]\n",
      "epoch:24 step:19418[D loss: 0.424805, acc: 55.47%, op_acc: 39.84%] [G loss: 0.906843]\n",
      "epoch:24 step:19419[D loss: 0.427386, acc: 55.47%, op_acc: 38.28%] [G loss: 0.925854]\n",
      "epoch:24 step:19420[D loss: 0.465488, acc: 51.56%, op_acc: 31.25%] [G loss: 0.832925]\n",
      "epoch:24 step:19421[D loss: 0.448639, acc: 51.56%, op_acc: 38.28%] [G loss: 0.936455]\n",
      "epoch:24 step:19422[D loss: 0.447927, acc: 51.56%, op_acc: 38.28%] [G loss: 0.901247]\n",
      "epoch:24 step:19423[D loss: 0.388991, acc: 67.19%, op_acc: 45.31%] [G loss: 0.865567]\n",
      "epoch:24 step:19424[D loss: 0.400332, acc: 64.84%, op_acc: 42.97%] [G loss: 0.916368]\n",
      "epoch:24 step:19425[D loss: 0.448652, acc: 57.03%, op_acc: 39.06%] [G loss: 0.997496]\n",
      "epoch:24 step:19426[D loss: 0.416717, acc: 58.59%, op_acc: 42.97%] [G loss: 1.002518]\n",
      "epoch:24 step:19427[D loss: 0.405129, acc: 61.72%, op_acc: 43.75%] [G loss: 0.924965]\n",
      "epoch:24 step:19428[D loss: 0.426708, acc: 59.38%, op_acc: 38.28%] [G loss: 0.960605]\n",
      "epoch:24 step:19429[D loss: 0.445911, acc: 53.12%, op_acc: 32.81%] [G loss: 0.999379]\n",
      "epoch:24 step:19430[D loss: 0.412484, acc: 59.38%, op_acc: 43.75%] [G loss: 0.956757]\n",
      "epoch:24 step:19431[D loss: 0.432998, acc: 50.78%, op_acc: 36.72%] [G loss: 0.880293]\n",
      "epoch:24 step:19432[D loss: 0.390691, acc: 66.41%, op_acc: 40.62%] [G loss: 0.882788]\n",
      "epoch:24 step:19433[D loss: 0.446481, acc: 53.12%, op_acc: 39.06%] [G loss: 0.868048]\n",
      "epoch:24 step:19434[D loss: 0.413877, acc: 63.28%, op_acc: 31.25%] [G loss: 0.952201]\n",
      "epoch:24 step:19435[D loss: 0.412393, acc: 68.75%, op_acc: 42.19%] [G loss: 0.818920]\n",
      "epoch:24 step:19436[D loss: 0.453676, acc: 57.03%, op_acc: 34.38%] [G loss: 0.897469]\n",
      "epoch:24 step:19437[D loss: 0.400736, acc: 64.84%, op_acc: 45.31%] [G loss: 0.885049]\n",
      "epoch:24 step:19438[D loss: 0.449963, acc: 54.69%, op_acc: 34.38%] [G loss: 0.855626]\n",
      "epoch:24 step:19439[D loss: 0.395191, acc: 64.84%, op_acc: 42.19%] [G loss: 0.855074]\n",
      "epoch:24 step:19440[D loss: 0.422552, acc: 61.72%, op_acc: 37.50%] [G loss: 0.925097]\n",
      "epoch:24 step:19441[D loss: 0.401215, acc: 57.81%, op_acc: 42.19%] [G loss: 0.848102]\n",
      "epoch:24 step:19442[D loss: 0.423460, acc: 64.06%, op_acc: 39.06%] [G loss: 0.919974]\n",
      "epoch:24 step:19443[D loss: 0.411835, acc: 58.59%, op_acc: 41.41%] [G loss: 0.923388]\n",
      "epoch:24 step:19444[D loss: 0.401568, acc: 69.53%, op_acc: 35.16%] [G loss: 0.870197]\n",
      "epoch:24 step:19445[D loss: 0.436298, acc: 58.59%, op_acc: 40.62%] [G loss: 0.859461]\n",
      "epoch:24 step:19446[D loss: 0.435492, acc: 64.84%, op_acc: 38.28%] [G loss: 0.948741]\n",
      "epoch:24 step:19447[D loss: 0.440330, acc: 57.81%, op_acc: 41.41%] [G loss: 0.935981]\n",
      "epoch:24 step:19448[D loss: 0.407493, acc: 57.03%, op_acc: 43.75%] [G loss: 0.884232]\n",
      "epoch:24 step:19449[D loss: 0.433483, acc: 64.06%, op_acc: 36.72%] [G loss: 0.868780]\n",
      "epoch:24 step:19450[D loss: 0.416870, acc: 59.38%, op_acc: 39.06%] [G loss: 0.842190]\n",
      "epoch:24 step:19451[D loss: 0.439498, acc: 55.47%, op_acc: 40.62%] [G loss: 0.862902]\n",
      "epoch:24 step:19452[D loss: 0.455610, acc: 47.66%, op_acc: 37.50%] [G loss: 1.000914]\n",
      "epoch:24 step:19453[D loss: 0.398937, acc: 67.19%, op_acc: 38.28%] [G loss: 0.840994]\n",
      "epoch:24 step:19454[D loss: 0.377329, acc: 68.75%, op_acc: 40.62%] [G loss: 0.885467]\n",
      "epoch:24 step:19455[D loss: 0.430642, acc: 67.97%, op_acc: 32.03%] [G loss: 0.918171]\n",
      "epoch:24 step:19456[D loss: 0.412415, acc: 53.91%, op_acc: 42.19%] [G loss: 0.871869]\n",
      "epoch:24 step:19457[D loss: 0.414526, acc: 62.50%, op_acc: 46.88%] [G loss: 0.914859]\n",
      "epoch:24 step:19458[D loss: 0.471615, acc: 54.69%, op_acc: 32.03%] [G loss: 0.850966]\n",
      "epoch:24 step:19459[D loss: 0.433620, acc: 52.34%, op_acc: 37.50%] [G loss: 0.892704]\n",
      "epoch:24 step:19460[D loss: 0.416374, acc: 58.59%, op_acc: 44.53%] [G loss: 0.877926]\n",
      "epoch:24 step:19461[D loss: 0.402544, acc: 58.59%, op_acc: 47.66%] [G loss: 0.875709]\n",
      "epoch:24 step:19462[D loss: 0.429478, acc: 64.06%, op_acc: 37.50%] [G loss: 0.968897]\n",
      "epoch:24 step:19463[D loss: 0.405550, acc: 55.47%, op_acc: 42.19%] [G loss: 0.865405]\n",
      "epoch:24 step:19464[D loss: 0.422347, acc: 60.94%, op_acc: 40.62%] [G loss: 0.893386]\n",
      "epoch:24 step:19465[D loss: 0.411646, acc: 58.59%, op_acc: 43.75%] [G loss: 0.926258]\n",
      "epoch:24 step:19466[D loss: 0.430236, acc: 58.59%, op_acc: 37.50%] [G loss: 0.876785]\n",
      "epoch:24 step:19467[D loss: 0.453741, acc: 47.66%, op_acc: 39.84%] [G loss: 0.880431]\n",
      "epoch:24 step:19468[D loss: 0.442631, acc: 58.59%, op_acc: 35.94%] [G loss: 0.885337]\n",
      "epoch:24 step:19469[D loss: 0.413159, acc: 64.06%, op_acc: 39.84%] [G loss: 0.914401]\n",
      "epoch:24 step:19470[D loss: 0.414572, acc: 56.25%, op_acc: 39.84%] [G loss: 0.932700]\n",
      "epoch:24 step:19471[D loss: 0.467993, acc: 53.12%, op_acc: 35.94%] [G loss: 0.802211]\n",
      "epoch:24 step:19472[D loss: 0.467162, acc: 51.56%, op_acc: 33.59%] [G loss: 0.977274]\n",
      "epoch:24 step:19473[D loss: 0.366392, acc: 69.53%, op_acc: 44.53%] [G loss: 0.927291]\n",
      "epoch:24 step:19474[D loss: 0.453578, acc: 56.25%, op_acc: 33.59%] [G loss: 1.014969]\n",
      "epoch:24 step:19475[D loss: 0.388974, acc: 60.94%, op_acc: 46.09%] [G loss: 1.002839]\n",
      "epoch:24 step:19476[D loss: 0.445648, acc: 52.34%, op_acc: 40.62%] [G loss: 0.883169]\n",
      "epoch:24 step:19477[D loss: 0.395778, acc: 73.44%, op_acc: 43.75%] [G loss: 0.935104]\n",
      "epoch:24 step:19478[D loss: 0.438914, acc: 57.03%, op_acc: 39.84%] [G loss: 0.835120]\n",
      "epoch:24 step:19479[D loss: 0.435386, acc: 50.00%, op_acc: 38.28%] [G loss: 0.931825]\n",
      "epoch:24 step:19480[D loss: 0.439041, acc: 56.25%, op_acc: 35.16%] [G loss: 0.895439]\n",
      "epoch:24 step:19481[D loss: 0.397250, acc: 60.16%, op_acc: 50.78%] [G loss: 0.909899]\n",
      "epoch:24 step:19482[D loss: 0.425503, acc: 61.72%, op_acc: 37.50%] [G loss: 0.940717]\n",
      "epoch:24 step:19483[D loss: 0.431512, acc: 63.28%, op_acc: 40.62%] [G loss: 0.847042]\n",
      "epoch:24 step:19484[D loss: 0.421237, acc: 54.69%, op_acc: 42.97%] [G loss: 0.941893]\n",
      "epoch:24 step:19485[D loss: 0.420383, acc: 62.50%, op_acc: 38.28%] [G loss: 0.827962]\n",
      "epoch:24 step:19486[D loss: 0.438989, acc: 55.47%, op_acc: 39.84%] [G loss: 0.920062]\n",
      "epoch:24 step:19487[D loss: 0.432343, acc: 61.72%, op_acc: 35.16%] [G loss: 0.828455]\n",
      "epoch:24 step:19488[D loss: 0.433920, acc: 55.47%, op_acc: 39.06%] [G loss: 0.954396]\n",
      "epoch:24 step:19489[D loss: 0.432369, acc: 53.91%, op_acc: 39.06%] [G loss: 0.905532]\n",
      "epoch:24 step:19490[D loss: 0.420977, acc: 60.94%, op_acc: 44.53%] [G loss: 0.910935]\n",
      "epoch:24 step:19491[D loss: 0.462258, acc: 52.34%, op_acc: 37.50%] [G loss: 0.881617]\n",
      "epoch:24 step:19492[D loss: 0.443597, acc: 57.81%, op_acc: 36.72%] [G loss: 0.960799]\n",
      "epoch:24 step:19493[D loss: 0.415380, acc: 63.28%, op_acc: 38.28%] [G loss: 0.837502]\n",
      "epoch:24 step:19494[D loss: 0.415578, acc: 60.94%, op_acc: 44.53%] [G loss: 0.930819]\n",
      "epoch:24 step:19495[D loss: 0.492243, acc: 50.78%, op_acc: 32.81%] [G loss: 0.862774]\n",
      "epoch:24 step:19496[D loss: 0.395118, acc: 64.06%, op_acc: 41.41%] [G loss: 0.912779]\n",
      "epoch:24 step:19497[D loss: 0.420789, acc: 53.91%, op_acc: 45.31%] [G loss: 0.824077]\n",
      "epoch:24 step:19498[D loss: 0.401356, acc: 67.19%, op_acc: 42.97%] [G loss: 0.887698]\n",
      "epoch:24 step:19499[D loss: 0.396427, acc: 67.97%, op_acc: 43.75%] [G loss: 0.922621]\n",
      "epoch:24 step:19500[D loss: 0.412283, acc: 57.81%, op_acc: 40.62%] [G loss: 0.869801]\n",
      "epoch:24 step:19501[D loss: 0.394372, acc: 64.84%, op_acc: 40.62%] [G loss: 0.948105]\n",
      "epoch:24 step:19502[D loss: 0.406365, acc: 62.50%, op_acc: 42.97%] [G loss: 0.948430]\n",
      "epoch:24 step:19503[D loss: 0.446771, acc: 57.03%, op_acc: 37.50%] [G loss: 0.851363]\n",
      "epoch:24 step:19504[D loss: 0.409755, acc: 60.94%, op_acc: 44.53%] [G loss: 0.953363]\n",
      "epoch:24 step:19505[D loss: 0.405028, acc: 66.41%, op_acc: 42.97%] [G loss: 0.884768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:19506[D loss: 0.430142, acc: 64.84%, op_acc: 36.72%] [G loss: 0.924690]\n",
      "epoch:24 step:19507[D loss: 0.440400, acc: 56.25%, op_acc: 36.72%] [G loss: 0.910570]\n",
      "epoch:24 step:19508[D loss: 0.399963, acc: 62.50%, op_acc: 43.75%] [G loss: 0.902912]\n",
      "epoch:24 step:19509[D loss: 0.401849, acc: 65.62%, op_acc: 44.53%] [G loss: 0.801536]\n",
      "epoch:24 step:19510[D loss: 0.450179, acc: 53.91%, op_acc: 34.38%] [G loss: 0.785830]\n",
      "epoch:24 step:19511[D loss: 0.430707, acc: 59.38%, op_acc: 36.72%] [G loss: 0.908856]\n",
      "epoch:24 step:19512[D loss: 0.434908, acc: 60.16%, op_acc: 34.38%] [G loss: 0.893312]\n",
      "epoch:24 step:19513[D loss: 0.403659, acc: 60.94%, op_acc: 48.44%] [G loss: 0.892991]\n",
      "epoch:24 step:19514[D loss: 0.448244, acc: 50.00%, op_acc: 40.62%] [G loss: 0.877030]\n",
      "epoch:24 step:19515[D loss: 0.468169, acc: 55.47%, op_acc: 28.91%] [G loss: 0.870071]\n",
      "epoch:24 step:19516[D loss: 0.447444, acc: 57.81%, op_acc: 34.38%] [G loss: 0.811323]\n",
      "epoch:24 step:19517[D loss: 0.421515, acc: 60.94%, op_acc: 42.19%] [G loss: 0.836945]\n",
      "epoch:24 step:19518[D loss: 0.401775, acc: 62.50%, op_acc: 38.28%] [G loss: 0.905959]\n",
      "epoch:24 step:19519[D loss: 0.413724, acc: 64.84%, op_acc: 38.28%] [G loss: 0.881477]\n",
      "epoch:24 step:19520[D loss: 0.411376, acc: 61.72%, op_acc: 42.19%] [G loss: 0.946328]\n",
      "epoch:24 step:19521[D loss: 0.417206, acc: 60.94%, op_acc: 34.38%] [G loss: 0.895469]\n",
      "epoch:24 step:19522[D loss: 0.417839, acc: 57.03%, op_acc: 42.97%] [G loss: 0.879779]\n",
      "epoch:24 step:19523[D loss: 0.426765, acc: 54.69%, op_acc: 37.50%] [G loss: 0.834759]\n",
      "epoch:24 step:19524[D loss: 0.427770, acc: 53.12%, op_acc: 37.50%] [G loss: 0.927791]\n",
      "epoch:24 step:19525[D loss: 0.436453, acc: 57.03%, op_acc: 39.06%] [G loss: 0.857321]\n",
      "epoch:25 step:19526[D loss: 0.394659, acc: 67.97%, op_acc: 45.31%] [G loss: 0.990025]\n",
      "epoch:25 step:19527[D loss: 0.376164, acc: 64.06%, op_acc: 50.00%] [G loss: 0.950459]\n",
      "epoch:25 step:19528[D loss: 0.436108, acc: 55.47%, op_acc: 37.50%] [G loss: 0.842275]\n",
      "epoch:25 step:19529[D loss: 0.380048, acc: 64.84%, op_acc: 47.66%] [G loss: 0.997906]\n",
      "epoch:25 step:19530[D loss: 0.414200, acc: 64.06%, op_acc: 37.50%] [G loss: 0.898528]\n",
      "epoch:25 step:19531[D loss: 0.445802, acc: 57.03%, op_acc: 36.72%] [G loss: 0.865336]\n",
      "epoch:25 step:19532[D loss: 0.400485, acc: 66.41%, op_acc: 42.97%] [G loss: 0.909352]\n",
      "epoch:25 step:19533[D loss: 0.425674, acc: 53.12%, op_acc: 38.28%] [G loss: 0.799167]\n",
      "epoch:25 step:19534[D loss: 0.375297, acc: 65.62%, op_acc: 47.66%] [G loss: 0.922984]\n",
      "epoch:25 step:19535[D loss: 0.432258, acc: 62.50%, op_acc: 33.59%] [G loss: 1.035353]\n",
      "epoch:25 step:19536[D loss: 0.438034, acc: 54.69%, op_acc: 39.84%] [G loss: 0.869474]\n",
      "epoch:25 step:19537[D loss: 0.410200, acc: 69.53%, op_acc: 39.06%] [G loss: 0.829459]\n",
      "epoch:25 step:19538[D loss: 0.407165, acc: 69.53%, op_acc: 35.94%] [G loss: 0.916903]\n",
      "epoch:25 step:19539[D loss: 0.419907, acc: 58.59%, op_acc: 41.41%] [G loss: 0.919401]\n",
      "epoch:25 step:19540[D loss: 0.399982, acc: 64.06%, op_acc: 40.62%] [G loss: 0.900885]\n",
      "epoch:25 step:19541[D loss: 0.375273, acc: 65.62%, op_acc: 48.44%] [G loss: 0.953272]\n",
      "epoch:25 step:19542[D loss: 0.436611, acc: 52.34%, op_acc: 42.97%] [G loss: 0.933684]\n",
      "epoch:25 step:19543[D loss: 0.446560, acc: 53.91%, op_acc: 46.09%] [G loss: 0.829012]\n",
      "epoch:25 step:19544[D loss: 0.436200, acc: 56.25%, op_acc: 42.19%] [G loss: 0.930908]\n",
      "epoch:25 step:19545[D loss: 0.401956, acc: 59.38%, op_acc: 35.16%] [G loss: 0.764564]\n",
      "epoch:25 step:19546[D loss: 0.448633, acc: 56.25%, op_acc: 34.38%] [G loss: 0.862561]\n",
      "epoch:25 step:19547[D loss: 0.444489, acc: 53.91%, op_acc: 40.62%] [G loss: 0.890604]\n",
      "epoch:25 step:19548[D loss: 0.424216, acc: 56.25%, op_acc: 40.62%] [G loss: 0.846619]\n",
      "epoch:25 step:19549[D loss: 0.433117, acc: 57.03%, op_acc: 39.84%] [G loss: 0.965862]\n",
      "epoch:25 step:19550[D loss: 0.436509, acc: 61.72%, op_acc: 39.84%] [G loss: 0.929433]\n",
      "epoch:25 step:19551[D loss: 0.436223, acc: 60.94%, op_acc: 43.75%] [G loss: 0.904606]\n",
      "epoch:25 step:19552[D loss: 0.443734, acc: 56.25%, op_acc: 37.50%] [G loss: 0.898849]\n",
      "epoch:25 step:19553[D loss: 0.418181, acc: 57.81%, op_acc: 45.31%] [G loss: 0.867717]\n",
      "epoch:25 step:19554[D loss: 0.408851, acc: 62.50%, op_acc: 37.50%] [G loss: 0.870952]\n",
      "epoch:25 step:19555[D loss: 0.422547, acc: 57.03%, op_acc: 39.84%] [G loss: 0.897188]\n",
      "epoch:25 step:19556[D loss: 0.452527, acc: 54.69%, op_acc: 39.84%] [G loss: 0.935408]\n",
      "epoch:25 step:19557[D loss: 0.423510, acc: 56.25%, op_acc: 37.50%] [G loss: 0.893433]\n",
      "epoch:25 step:19558[D loss: 0.419140, acc: 56.25%, op_acc: 47.66%] [G loss: 0.839875]\n",
      "epoch:25 step:19559[D loss: 0.388255, acc: 70.31%, op_acc: 41.41%] [G loss: 0.947539]\n",
      "epoch:25 step:19560[D loss: 0.426601, acc: 61.72%, op_acc: 37.50%] [G loss: 0.870973]\n",
      "epoch:25 step:19561[D loss: 0.425863, acc: 53.12%, op_acc: 42.97%] [G loss: 0.828683]\n",
      "epoch:25 step:19562[D loss: 0.374541, acc: 70.31%, op_acc: 39.84%] [G loss: 0.962083]\n",
      "epoch:25 step:19563[D loss: 0.405256, acc: 64.84%, op_acc: 35.16%] [G loss: 0.802237]\n",
      "epoch:25 step:19564[D loss: 0.415926, acc: 57.03%, op_acc: 39.06%] [G loss: 0.824079]\n",
      "epoch:25 step:19565[D loss: 0.429621, acc: 57.81%, op_acc: 40.62%] [G loss: 0.884115]\n",
      "epoch:25 step:19566[D loss: 0.418660, acc: 57.03%, op_acc: 42.97%] [G loss: 0.911352]\n",
      "epoch:25 step:19567[D loss: 0.412872, acc: 61.72%, op_acc: 40.62%] [G loss: 0.958556]\n",
      "epoch:25 step:19568[D loss: 0.427665, acc: 56.25%, op_acc: 39.06%] [G loss: 0.905477]\n",
      "epoch:25 step:19569[D loss: 0.438953, acc: 55.47%, op_acc: 40.62%] [G loss: 0.839051]\n",
      "epoch:25 step:19570[D loss: 0.424727, acc: 62.50%, op_acc: 35.94%] [G loss: 0.911960]\n",
      "epoch:25 step:19571[D loss: 0.416552, acc: 60.16%, op_acc: 38.28%] [G loss: 0.893152]\n",
      "epoch:25 step:19572[D loss: 0.428673, acc: 64.06%, op_acc: 42.97%] [G loss: 0.944515]\n",
      "epoch:25 step:19573[D loss: 0.422942, acc: 60.94%, op_acc: 37.50%] [G loss: 0.872046]\n",
      "epoch:25 step:19574[D loss: 0.425232, acc: 62.50%, op_acc: 40.62%] [G loss: 0.817811]\n",
      "epoch:25 step:19575[D loss: 0.453974, acc: 57.03%, op_acc: 32.03%] [G loss: 0.814060]\n",
      "epoch:25 step:19576[D loss: 0.394606, acc: 64.06%, op_acc: 42.19%] [G loss: 0.753310]\n",
      "epoch:25 step:19577[D loss: 0.415799, acc: 58.59%, op_acc: 34.38%] [G loss: 0.903283]\n",
      "epoch:25 step:19578[D loss: 0.441861, acc: 58.59%, op_acc: 35.94%] [G loss: 0.914250]\n",
      "epoch:25 step:19579[D loss: 0.428198, acc: 62.50%, op_acc: 42.97%] [G loss: 0.877247]\n",
      "epoch:25 step:19580[D loss: 0.415107, acc: 57.81%, op_acc: 44.53%] [G loss: 0.873888]\n",
      "epoch:25 step:19581[D loss: 0.449112, acc: 50.78%, op_acc: 35.16%] [G loss: 0.876058]\n",
      "epoch:25 step:19582[D loss: 0.433477, acc: 56.25%, op_acc: 42.97%] [G loss: 0.808720]\n",
      "epoch:25 step:19583[D loss: 0.393803, acc: 66.41%, op_acc: 46.88%] [G loss: 0.956949]\n",
      "epoch:25 step:19584[D loss: 0.433152, acc: 53.91%, op_acc: 41.41%] [G loss: 0.789918]\n",
      "epoch:25 step:19585[D loss: 0.423761, acc: 58.59%, op_acc: 35.94%] [G loss: 0.851700]\n",
      "epoch:25 step:19586[D loss: 0.424816, acc: 58.59%, op_acc: 35.94%] [G loss: 0.828215]\n",
      "epoch:25 step:19587[D loss: 0.418573, acc: 62.50%, op_acc: 39.06%] [G loss: 0.924740]\n",
      "epoch:25 step:19588[D loss: 0.446475, acc: 55.47%, op_acc: 35.94%] [G loss: 0.932294]\n",
      "epoch:25 step:19589[D loss: 0.428790, acc: 56.25%, op_acc: 35.16%] [G loss: 0.861015]\n",
      "epoch:25 step:19590[D loss: 0.394541, acc: 69.53%, op_acc: 39.06%] [G loss: 0.863320]\n",
      "epoch:25 step:19591[D loss: 0.464068, acc: 53.91%, op_acc: 41.41%] [G loss: 0.828497]\n",
      "epoch:25 step:19592[D loss: 0.433604, acc: 56.25%, op_acc: 39.84%] [G loss: 0.839018]\n",
      "epoch:25 step:19593[D loss: 0.422225, acc: 60.16%, op_acc: 39.84%] [G loss: 0.890082]\n",
      "epoch:25 step:19594[D loss: 0.410240, acc: 56.25%, op_acc: 42.97%] [G loss: 0.791075]\n",
      "epoch:25 step:19595[D loss: 0.421975, acc: 60.16%, op_acc: 35.94%] [G loss: 0.881296]\n",
      "epoch:25 step:19596[D loss: 0.450064, acc: 55.47%, op_acc: 34.38%] [G loss: 0.850627]\n",
      "epoch:25 step:19597[D loss: 0.423811, acc: 62.50%, op_acc: 35.16%] [G loss: 0.883698]\n",
      "epoch:25 step:19598[D loss: 0.430754, acc: 61.72%, op_acc: 38.28%] [G loss: 0.886528]\n",
      "epoch:25 step:19599[D loss: 0.424150, acc: 50.78%, op_acc: 42.97%] [G loss: 0.905720]\n",
      "epoch:25 step:19600[D loss: 0.398655, acc: 65.62%, op_acc: 38.28%] [G loss: 0.879666]\n",
      "epoch:25 step:19601[D loss: 0.431757, acc: 63.28%, op_acc: 36.72%] [G loss: 0.869141]\n",
      "epoch:25 step:19602[D loss: 0.442216, acc: 54.69%, op_acc: 36.72%] [G loss: 0.968683]\n",
      "epoch:25 step:19603[D loss: 0.408042, acc: 77.34%, op_acc: 31.25%] [G loss: 0.933148]\n",
      "epoch:25 step:19604[D loss: 0.420442, acc: 53.91%, op_acc: 43.75%] [G loss: 0.846650]\n",
      "epoch:25 step:19605[D loss: 0.429600, acc: 63.28%, op_acc: 30.47%] [G loss: 0.931703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19606[D loss: 0.414301, acc: 67.97%, op_acc: 34.38%] [G loss: 0.918150]\n",
      "epoch:25 step:19607[D loss: 0.414108, acc: 56.25%, op_acc: 43.75%] [G loss: 0.887561]\n",
      "epoch:25 step:19608[D loss: 0.420283, acc: 52.34%, op_acc: 42.97%] [G loss: 0.870429]\n",
      "epoch:25 step:19609[D loss: 0.391967, acc: 64.84%, op_acc: 35.16%] [G loss: 0.839432]\n",
      "epoch:25 step:19610[D loss: 0.483917, acc: 54.69%, op_acc: 30.47%] [G loss: 0.832446]\n",
      "epoch:25 step:19611[D loss: 0.404803, acc: 70.31%, op_acc: 39.84%] [G loss: 0.933456]\n",
      "epoch:25 step:19612[D loss: 0.413607, acc: 62.50%, op_acc: 37.50%] [G loss: 0.872497]\n",
      "epoch:25 step:19613[D loss: 0.438846, acc: 53.12%, op_acc: 36.72%] [G loss: 0.811527]\n",
      "epoch:25 step:19614[D loss: 0.424703, acc: 58.59%, op_acc: 41.41%] [G loss: 0.904993]\n",
      "epoch:25 step:19615[D loss: 0.414929, acc: 56.25%, op_acc: 40.62%] [G loss: 1.000878]\n",
      "epoch:25 step:19616[D loss: 0.424061, acc: 58.59%, op_acc: 45.31%] [G loss: 0.892497]\n",
      "epoch:25 step:19617[D loss: 0.428101, acc: 57.03%, op_acc: 36.72%] [G loss: 0.935146]\n",
      "epoch:25 step:19618[D loss: 0.418144, acc: 55.47%, op_acc: 42.19%] [G loss: 0.870971]\n",
      "epoch:25 step:19619[D loss: 0.402811, acc: 67.97%, op_acc: 38.28%] [G loss: 0.900389]\n",
      "epoch:25 step:19620[D loss: 0.433352, acc: 55.47%, op_acc: 40.62%] [G loss: 0.843899]\n",
      "epoch:25 step:19621[D loss: 0.435980, acc: 60.16%, op_acc: 42.97%] [G loss: 0.919159]\n",
      "epoch:25 step:19622[D loss: 0.414141, acc: 54.69%, op_acc: 42.97%] [G loss: 0.843104]\n",
      "epoch:25 step:19623[D loss: 0.443934, acc: 54.69%, op_acc: 40.62%] [G loss: 0.850009]\n",
      "epoch:25 step:19624[D loss: 0.424698, acc: 57.03%, op_acc: 39.06%] [G loss: 0.829165]\n",
      "epoch:25 step:19625[D loss: 0.398489, acc: 62.50%, op_acc: 42.19%] [G loss: 0.898550]\n",
      "epoch:25 step:19626[D loss: 0.417420, acc: 60.94%, op_acc: 35.94%] [G loss: 0.965060]\n",
      "epoch:25 step:19627[D loss: 0.427752, acc: 60.16%, op_acc: 41.41%] [G loss: 0.806970]\n",
      "epoch:25 step:19628[D loss: 0.432166, acc: 54.69%, op_acc: 39.06%] [G loss: 0.946228]\n",
      "epoch:25 step:19629[D loss: 0.427194, acc: 56.25%, op_acc: 35.94%] [G loss: 0.937681]\n",
      "epoch:25 step:19630[D loss: 0.446017, acc: 53.12%, op_acc: 42.97%] [G loss: 0.875500]\n",
      "epoch:25 step:19631[D loss: 0.424473, acc: 60.16%, op_acc: 39.84%] [G loss: 0.890378]\n",
      "epoch:25 step:19632[D loss: 0.402040, acc: 60.94%, op_acc: 43.75%] [G loss: 0.883934]\n",
      "epoch:25 step:19633[D loss: 0.462281, acc: 57.03%, op_acc: 32.81%] [G loss: 0.953193]\n",
      "epoch:25 step:19634[D loss: 0.404032, acc: 63.28%, op_acc: 45.31%] [G loss: 0.898634]\n",
      "epoch:25 step:19635[D loss: 0.396097, acc: 64.06%, op_acc: 44.53%] [G loss: 0.919421]\n",
      "epoch:25 step:19636[D loss: 0.448269, acc: 55.47%, op_acc: 35.16%] [G loss: 0.873806]\n",
      "epoch:25 step:19637[D loss: 0.429328, acc: 60.16%, op_acc: 43.75%] [G loss: 0.831608]\n",
      "epoch:25 step:19638[D loss: 0.425824, acc: 60.16%, op_acc: 32.81%] [G loss: 0.896911]\n",
      "epoch:25 step:19639[D loss: 0.414646, acc: 60.16%, op_acc: 38.28%] [G loss: 0.955993]\n",
      "epoch:25 step:19640[D loss: 0.422190, acc: 64.84%, op_acc: 40.62%] [G loss: 0.898340]\n",
      "epoch:25 step:19641[D loss: 0.465602, acc: 53.91%, op_acc: 35.94%] [G loss: 0.860424]\n",
      "epoch:25 step:19642[D loss: 0.449567, acc: 49.22%, op_acc: 36.72%] [G loss: 0.894244]\n",
      "epoch:25 step:19643[D loss: 0.404743, acc: 63.28%, op_acc: 38.28%] [G loss: 0.892031]\n",
      "epoch:25 step:19644[D loss: 0.406265, acc: 64.84%, op_acc: 40.62%] [G loss: 0.851074]\n",
      "epoch:25 step:19645[D loss: 0.427037, acc: 64.06%, op_acc: 36.72%] [G loss: 0.901881]\n",
      "epoch:25 step:19646[D loss: 0.411888, acc: 67.97%, op_acc: 38.28%] [G loss: 0.915000]\n",
      "epoch:25 step:19647[D loss: 0.456305, acc: 53.91%, op_acc: 34.38%] [G loss: 0.804444]\n",
      "epoch:25 step:19648[D loss: 0.467956, acc: 48.44%, op_acc: 36.72%] [G loss: 0.898567]\n",
      "epoch:25 step:19649[D loss: 0.428860, acc: 56.25%, op_acc: 40.62%] [G loss: 0.869360]\n",
      "epoch:25 step:19650[D loss: 0.450777, acc: 60.16%, op_acc: 36.72%] [G loss: 0.871423]\n",
      "epoch:25 step:19651[D loss: 0.412750, acc: 60.16%, op_acc: 42.19%] [G loss: 0.888339]\n",
      "epoch:25 step:19652[D loss: 0.409822, acc: 66.41%, op_acc: 34.38%] [G loss: 0.890100]\n",
      "epoch:25 step:19653[D loss: 0.373349, acc: 66.41%, op_acc: 42.97%] [G loss: 0.902219]\n",
      "epoch:25 step:19654[D loss: 0.426577, acc: 66.41%, op_acc: 35.94%] [G loss: 0.824493]\n",
      "epoch:25 step:19655[D loss: 0.413379, acc: 57.81%, op_acc: 42.19%] [G loss: 0.855376]\n",
      "epoch:25 step:19656[D loss: 0.411500, acc: 59.38%, op_acc: 34.38%] [G loss: 0.847240]\n",
      "epoch:25 step:19657[D loss: 0.398600, acc: 60.94%, op_acc: 48.44%] [G loss: 0.889678]\n",
      "epoch:25 step:19658[D loss: 0.460683, acc: 60.16%, op_acc: 39.06%] [G loss: 0.889251]\n",
      "epoch:25 step:19659[D loss: 0.435830, acc: 63.28%, op_acc: 36.72%] [G loss: 0.942013]\n",
      "epoch:25 step:19660[D loss: 0.412770, acc: 62.50%, op_acc: 36.72%] [G loss: 0.919669]\n",
      "epoch:25 step:19661[D loss: 0.400883, acc: 66.41%, op_acc: 42.19%] [G loss: 0.786895]\n",
      "epoch:25 step:19662[D loss: 0.432295, acc: 59.38%, op_acc: 35.94%] [G loss: 0.900981]\n",
      "epoch:25 step:19663[D loss: 0.431187, acc: 55.47%, op_acc: 39.06%] [G loss: 0.954239]\n",
      "epoch:25 step:19664[D loss: 0.386021, acc: 67.97%, op_acc: 47.66%] [G loss: 0.881487]\n",
      "epoch:25 step:19665[D loss: 0.439645, acc: 57.03%, op_acc: 35.94%] [G loss: 0.782072]\n",
      "epoch:25 step:19666[D loss: 0.447322, acc: 60.16%, op_acc: 33.59%] [G loss: 0.868655]\n",
      "epoch:25 step:19667[D loss: 0.447586, acc: 52.34%, op_acc: 39.06%] [G loss: 0.854363]\n",
      "epoch:25 step:19668[D loss: 0.388853, acc: 68.75%, op_acc: 45.31%] [G loss: 0.892430]\n",
      "epoch:25 step:19669[D loss: 0.420083, acc: 64.06%, op_acc: 34.38%] [G loss: 0.882374]\n",
      "epoch:25 step:19670[D loss: 0.410451, acc: 66.41%, op_acc: 43.75%] [G loss: 0.868389]\n",
      "epoch:25 step:19671[D loss: 0.431151, acc: 58.59%, op_acc: 36.72%] [G loss: 0.818736]\n",
      "epoch:25 step:19672[D loss: 0.408837, acc: 57.03%, op_acc: 44.53%] [G loss: 0.936014]\n",
      "epoch:25 step:19673[D loss: 0.439416, acc: 52.34%, op_acc: 34.38%] [G loss: 0.873273]\n",
      "epoch:25 step:19674[D loss: 0.397854, acc: 67.19%, op_acc: 44.53%] [G loss: 0.894745]\n",
      "epoch:25 step:19675[D loss: 0.431904, acc: 57.81%, op_acc: 40.62%] [G loss: 0.942988]\n",
      "epoch:25 step:19676[D loss: 0.408635, acc: 57.03%, op_acc: 41.41%] [G loss: 0.949457]\n",
      "epoch:25 step:19677[D loss: 0.408292, acc: 60.94%, op_acc: 42.19%] [G loss: 0.913463]\n",
      "epoch:25 step:19678[D loss: 0.433540, acc: 56.25%, op_acc: 32.03%] [G loss: 0.862655]\n",
      "epoch:25 step:19679[D loss: 0.431281, acc: 56.25%, op_acc: 39.84%] [G loss: 0.963387]\n",
      "epoch:25 step:19680[D loss: 0.393186, acc: 67.19%, op_acc: 44.53%] [G loss: 0.896536]\n",
      "epoch:25 step:19681[D loss: 0.423344, acc: 58.59%, op_acc: 36.72%] [G loss: 0.895067]\n",
      "epoch:25 step:19682[D loss: 0.410664, acc: 59.38%, op_acc: 44.53%] [G loss: 0.832946]\n",
      "epoch:25 step:19683[D loss: 0.403330, acc: 60.16%, op_acc: 44.53%] [G loss: 0.903859]\n",
      "epoch:25 step:19684[D loss: 0.444531, acc: 51.56%, op_acc: 34.38%] [G loss: 0.828922]\n",
      "epoch:25 step:19685[D loss: 0.458696, acc: 55.47%, op_acc: 34.38%] [G loss: 0.901954]\n",
      "epoch:25 step:19686[D loss: 0.449104, acc: 58.59%, op_acc: 36.72%] [G loss: 0.993087]\n",
      "epoch:25 step:19687[D loss: 0.424074, acc: 57.03%, op_acc: 44.53%] [G loss: 0.909097]\n",
      "epoch:25 step:19688[D loss: 0.437080, acc: 59.38%, op_acc: 42.97%] [G loss: 0.885866]\n",
      "epoch:25 step:19689[D loss: 0.443779, acc: 58.59%, op_acc: 39.06%] [G loss: 0.924512]\n",
      "epoch:25 step:19690[D loss: 0.391465, acc: 73.44%, op_acc: 43.75%] [G loss: 0.938810]\n",
      "epoch:25 step:19691[D loss: 0.421729, acc: 60.94%, op_acc: 39.84%] [G loss: 0.906944]\n",
      "epoch:25 step:19692[D loss: 0.413116, acc: 63.28%, op_acc: 39.84%] [G loss: 0.949351]\n",
      "epoch:25 step:19693[D loss: 0.400799, acc: 65.62%, op_acc: 47.66%] [G loss: 0.950934]\n",
      "epoch:25 step:19694[D loss: 0.440950, acc: 51.56%, op_acc: 44.53%] [G loss: 0.906935]\n",
      "epoch:25 step:19695[D loss: 0.417967, acc: 55.47%, op_acc: 44.53%] [G loss: 0.954916]\n",
      "epoch:25 step:19696[D loss: 0.429686, acc: 58.59%, op_acc: 35.94%] [G loss: 0.888187]\n",
      "epoch:25 step:19697[D loss: 0.434082, acc: 59.38%, op_acc: 40.62%] [G loss: 0.977219]\n",
      "epoch:25 step:19698[D loss: 0.420773, acc: 61.72%, op_acc: 41.41%] [G loss: 0.969504]\n",
      "epoch:25 step:19699[D loss: 0.448418, acc: 53.12%, op_acc: 35.16%] [G loss: 0.853498]\n",
      "epoch:25 step:19700[D loss: 0.411994, acc: 63.28%, op_acc: 42.19%] [G loss: 0.918426]\n",
      "epoch:25 step:19701[D loss: 0.413299, acc: 58.59%, op_acc: 39.06%] [G loss: 0.888016]\n",
      "epoch:25 step:19702[D loss: 0.397864, acc: 58.59%, op_acc: 40.62%] [G loss: 0.971940]\n",
      "epoch:25 step:19703[D loss: 0.424505, acc: 57.81%, op_acc: 32.03%] [G loss: 0.856322]\n",
      "epoch:25 step:19704[D loss: 0.429689, acc: 56.25%, op_acc: 39.06%] [G loss: 0.899188]\n",
      "epoch:25 step:19705[D loss: 0.441010, acc: 56.25%, op_acc: 42.19%] [G loss: 0.846135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19706[D loss: 0.421033, acc: 62.50%, op_acc: 42.97%] [G loss: 0.870392]\n",
      "epoch:25 step:19707[D loss: 0.421396, acc: 56.25%, op_acc: 40.62%] [G loss: 0.883534]\n",
      "epoch:25 step:19708[D loss: 0.393776, acc: 64.06%, op_acc: 42.97%] [G loss: 0.827022]\n",
      "epoch:25 step:19709[D loss: 0.407715, acc: 61.72%, op_acc: 37.50%] [G loss: 0.829499]\n",
      "epoch:25 step:19710[D loss: 0.394072, acc: 70.31%, op_acc: 35.94%] [G loss: 0.861589]\n",
      "epoch:25 step:19711[D loss: 0.422474, acc: 56.25%, op_acc: 42.97%] [G loss: 0.910286]\n",
      "epoch:25 step:19712[D loss: 0.437607, acc: 55.47%, op_acc: 39.06%] [G loss: 0.990329]\n",
      "epoch:25 step:19713[D loss: 0.443884, acc: 51.56%, op_acc: 44.53%] [G loss: 0.874091]\n",
      "epoch:25 step:19714[D loss: 0.405274, acc: 65.62%, op_acc: 41.41%] [G loss: 0.911922]\n",
      "epoch:25 step:19715[D loss: 0.442728, acc: 54.69%, op_acc: 37.50%] [G loss: 0.937624]\n",
      "epoch:25 step:19716[D loss: 0.410913, acc: 57.03%, op_acc: 42.97%] [G loss: 0.836447]\n",
      "epoch:25 step:19717[D loss: 0.420631, acc: 62.50%, op_acc: 38.28%] [G loss: 0.829705]\n",
      "epoch:25 step:19718[D loss: 0.451930, acc: 53.12%, op_acc: 36.72%] [G loss: 0.768604]\n",
      "epoch:25 step:19719[D loss: 0.416457, acc: 57.81%, op_acc: 43.75%] [G loss: 0.927116]\n",
      "epoch:25 step:19720[D loss: 0.427394, acc: 60.94%, op_acc: 36.72%] [G loss: 0.922102]\n",
      "epoch:25 step:19721[D loss: 0.409485, acc: 63.28%, op_acc: 44.53%] [G loss: 0.840066]\n",
      "epoch:25 step:19722[D loss: 0.454638, acc: 55.47%, op_acc: 35.94%] [G loss: 0.894056]\n",
      "epoch:25 step:19723[D loss: 0.412730, acc: 64.06%, op_acc: 35.16%] [G loss: 0.840342]\n",
      "epoch:25 step:19724[D loss: 0.424424, acc: 55.47%, op_acc: 40.62%] [G loss: 0.925192]\n",
      "epoch:25 step:19725[D loss: 0.398168, acc: 71.09%, op_acc: 46.88%] [G loss: 0.962975]\n",
      "epoch:25 step:19726[D loss: 0.415734, acc: 60.94%, op_acc: 39.06%] [G loss: 0.911685]\n",
      "epoch:25 step:19727[D loss: 0.412072, acc: 62.50%, op_acc: 39.84%] [G loss: 0.851285]\n",
      "epoch:25 step:19728[D loss: 0.448969, acc: 47.66%, op_acc: 37.50%] [G loss: 0.873424]\n",
      "epoch:25 step:19729[D loss: 0.417345, acc: 60.94%, op_acc: 42.97%] [G loss: 0.858212]\n",
      "epoch:25 step:19730[D loss: 0.422366, acc: 60.94%, op_acc: 40.62%] [G loss: 0.830790]\n",
      "epoch:25 step:19731[D loss: 0.447579, acc: 47.66%, op_acc: 40.62%] [G loss: 0.895993]\n",
      "epoch:25 step:19732[D loss: 0.455856, acc: 54.69%, op_acc: 39.06%] [G loss: 0.830157]\n",
      "epoch:25 step:19733[D loss: 0.406892, acc: 65.62%, op_acc: 38.28%] [G loss: 0.937716]\n",
      "epoch:25 step:19734[D loss: 0.411889, acc: 58.59%, op_acc: 41.41%] [G loss: 0.991605]\n",
      "epoch:25 step:19735[D loss: 0.412735, acc: 60.94%, op_acc: 36.72%] [G loss: 0.896183]\n",
      "epoch:25 step:19736[D loss: 0.383482, acc: 66.41%, op_acc: 46.88%] [G loss: 0.909115]\n",
      "epoch:25 step:19737[D loss: 0.398105, acc: 64.84%, op_acc: 47.66%] [G loss: 0.953349]\n",
      "epoch:25 step:19738[D loss: 0.425030, acc: 53.91%, op_acc: 38.28%] [G loss: 0.919212]\n",
      "epoch:25 step:19739[D loss: 0.423981, acc: 56.25%, op_acc: 42.19%] [G loss: 0.903237]\n",
      "epoch:25 step:19740[D loss: 0.447907, acc: 52.34%, op_acc: 37.50%] [G loss: 0.903293]\n",
      "epoch:25 step:19741[D loss: 0.419687, acc: 62.50%, op_acc: 39.06%] [G loss: 0.977320]\n",
      "epoch:25 step:19742[D loss: 0.395867, acc: 60.16%, op_acc: 44.53%] [G loss: 0.848518]\n",
      "epoch:25 step:19743[D loss: 0.439372, acc: 58.59%, op_acc: 37.50%] [G loss: 0.899814]\n",
      "epoch:25 step:19744[D loss: 0.421615, acc: 67.19%, op_acc: 41.41%] [G loss: 0.920517]\n",
      "epoch:25 step:19745[D loss: 0.429579, acc: 58.59%, op_acc: 39.06%] [G loss: 0.903909]\n",
      "epoch:25 step:19746[D loss: 0.448543, acc: 54.69%, op_acc: 37.50%] [G loss: 0.863640]\n",
      "epoch:25 step:19747[D loss: 0.386053, acc: 66.41%, op_acc: 40.62%] [G loss: 0.881447]\n",
      "epoch:25 step:19748[D loss: 0.415181, acc: 60.16%, op_acc: 42.19%] [G loss: 0.789901]\n",
      "epoch:25 step:19749[D loss: 0.414475, acc: 58.59%, op_acc: 41.41%] [G loss: 0.948595]\n",
      "epoch:25 step:19750[D loss: 0.453163, acc: 53.91%, op_acc: 42.97%] [G loss: 0.859148]\n",
      "epoch:25 step:19751[D loss: 0.445779, acc: 60.16%, op_acc: 42.97%] [G loss: 0.836895]\n",
      "epoch:25 step:19752[D loss: 0.411140, acc: 67.19%, op_acc: 45.31%] [G loss: 0.885472]\n",
      "epoch:25 step:19753[D loss: 0.390295, acc: 64.84%, op_acc: 44.53%] [G loss: 0.892476]\n",
      "epoch:25 step:19754[D loss: 0.421792, acc: 57.03%, op_acc: 39.84%] [G loss: 0.769989]\n",
      "epoch:25 step:19755[D loss: 0.465559, acc: 47.66%, op_acc: 34.38%] [G loss: 0.833769]\n",
      "epoch:25 step:19756[D loss: 0.387977, acc: 64.84%, op_acc: 46.09%] [G loss: 0.874281]\n",
      "epoch:25 step:19757[D loss: 0.427044, acc: 61.72%, op_acc: 40.62%] [G loss: 0.903978]\n",
      "epoch:25 step:19758[D loss: 0.408753, acc: 71.09%, op_acc: 40.62%] [G loss: 0.918674]\n",
      "epoch:25 step:19759[D loss: 0.396628, acc: 71.88%, op_acc: 44.53%] [G loss: 0.969565]\n",
      "epoch:25 step:19760[D loss: 0.407305, acc: 64.84%, op_acc: 38.28%] [G loss: 0.912045]\n",
      "epoch:25 step:19761[D loss: 0.430019, acc: 56.25%, op_acc: 42.97%] [G loss: 0.855531]\n",
      "epoch:25 step:19762[D loss: 0.402162, acc: 59.38%, op_acc: 42.97%] [G loss: 0.921386]\n",
      "epoch:25 step:19763[D loss: 0.440099, acc: 57.03%, op_acc: 43.75%] [G loss: 0.933358]\n",
      "epoch:25 step:19764[D loss: 0.420456, acc: 63.28%, op_acc: 36.72%] [G loss: 0.896362]\n",
      "epoch:25 step:19765[D loss: 0.448357, acc: 52.34%, op_acc: 37.50%] [G loss: 0.962214]\n",
      "epoch:25 step:19766[D loss: 0.441435, acc: 50.00%, op_acc: 42.97%] [G loss: 0.836880]\n",
      "epoch:25 step:19767[D loss: 0.376186, acc: 68.75%, op_acc: 46.09%] [G loss: 0.909923]\n",
      "epoch:25 step:19768[D loss: 0.416348, acc: 59.38%, op_acc: 42.97%] [G loss: 1.017999]\n",
      "epoch:25 step:19769[D loss: 0.413779, acc: 62.50%, op_acc: 38.28%] [G loss: 0.861745]\n",
      "epoch:25 step:19770[D loss: 0.448897, acc: 50.00%, op_acc: 42.19%] [G loss: 0.904410]\n",
      "epoch:25 step:19771[D loss: 0.441108, acc: 56.25%, op_acc: 38.28%] [G loss: 0.801561]\n",
      "epoch:25 step:19772[D loss: 0.410555, acc: 58.59%, op_acc: 39.06%] [G loss: 0.879440]\n",
      "epoch:25 step:19773[D loss: 0.428091, acc: 62.50%, op_acc: 35.94%] [G loss: 0.863583]\n",
      "epoch:25 step:19774[D loss: 0.423015, acc: 57.81%, op_acc: 42.19%] [G loss: 0.912860]\n",
      "epoch:25 step:19775[D loss: 0.388011, acc: 69.53%, op_acc: 42.19%] [G loss: 0.907567]\n",
      "epoch:25 step:19776[D loss: 0.401586, acc: 60.94%, op_acc: 42.19%] [G loss: 0.794677]\n",
      "epoch:25 step:19777[D loss: 0.441866, acc: 55.47%, op_acc: 39.06%] [G loss: 0.919741]\n",
      "epoch:25 step:19778[D loss: 0.434016, acc: 60.94%, op_acc: 38.28%] [G loss: 0.922582]\n",
      "epoch:25 step:19779[D loss: 0.449894, acc: 60.94%, op_acc: 37.50%] [G loss: 0.918758]\n",
      "epoch:25 step:19780[D loss: 0.429758, acc: 57.03%, op_acc: 39.06%] [G loss: 0.836238]\n",
      "epoch:25 step:19781[D loss: 0.434106, acc: 55.47%, op_acc: 39.84%] [G loss: 0.898027]\n",
      "epoch:25 step:19782[D loss: 0.395641, acc: 63.28%, op_acc: 40.62%] [G loss: 0.916538]\n",
      "epoch:25 step:19783[D loss: 0.426603, acc: 58.59%, op_acc: 42.19%] [G loss: 0.953903]\n",
      "epoch:25 step:19784[D loss: 0.430861, acc: 58.59%, op_acc: 35.16%] [G loss: 0.859011]\n",
      "epoch:25 step:19785[D loss: 0.429203, acc: 55.47%, op_acc: 37.50%] [G loss: 0.923921]\n",
      "epoch:25 step:19786[D loss: 0.439229, acc: 52.34%, op_acc: 40.62%] [G loss: 0.981244]\n",
      "epoch:25 step:19787[D loss: 0.413529, acc: 61.72%, op_acc: 41.41%] [G loss: 0.862756]\n",
      "epoch:25 step:19788[D loss: 0.414038, acc: 55.47%, op_acc: 40.62%] [G loss: 0.927288]\n",
      "epoch:25 step:19789[D loss: 0.418226, acc: 59.38%, op_acc: 39.06%] [G loss: 0.839558]\n",
      "epoch:25 step:19790[D loss: 0.401508, acc: 62.50%, op_acc: 46.09%] [G loss: 0.886237]\n",
      "epoch:25 step:19791[D loss: 0.415535, acc: 62.50%, op_acc: 43.75%] [G loss: 0.884353]\n",
      "epoch:25 step:19792[D loss: 0.481982, acc: 45.31%, op_acc: 40.62%] [G loss: 0.880207]\n",
      "epoch:25 step:19793[D loss: 0.423950, acc: 60.94%, op_acc: 45.31%] [G loss: 0.883057]\n",
      "epoch:25 step:19794[D loss: 0.431095, acc: 57.81%, op_acc: 39.06%] [G loss: 0.904572]\n",
      "epoch:25 step:19795[D loss: 0.409545, acc: 66.41%, op_acc: 37.50%] [G loss: 0.952013]\n",
      "epoch:25 step:19796[D loss: 0.435047, acc: 56.25%, op_acc: 35.94%] [G loss: 0.905989]\n",
      "epoch:25 step:19797[D loss: 0.393606, acc: 74.22%, op_acc: 39.84%] [G loss: 0.840395]\n",
      "epoch:25 step:19798[D loss: 0.420580, acc: 54.69%, op_acc: 42.19%] [G loss: 0.857920]\n",
      "epoch:25 step:19799[D loss: 0.459664, acc: 46.09%, op_acc: 35.94%] [G loss: 0.891086]\n",
      "epoch:25 step:19800[D loss: 0.416126, acc: 61.72%, op_acc: 43.75%] [G loss: 0.865192]\n",
      "epoch:25 step:19801[D loss: 0.453902, acc: 48.44%, op_acc: 33.59%] [G loss: 0.792549]\n",
      "epoch:25 step:19802[D loss: 0.442495, acc: 60.16%, op_acc: 35.94%] [G loss: 0.847621]\n",
      "epoch:25 step:19803[D loss: 0.412375, acc: 61.72%, op_acc: 36.72%] [G loss: 0.895416]\n",
      "epoch:25 step:19804[D loss: 0.426854, acc: 63.28%, op_acc: 37.50%] [G loss: 0.812446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19805[D loss: 0.439005, acc: 54.69%, op_acc: 31.25%] [G loss: 0.875951]\n",
      "epoch:25 step:19806[D loss: 0.441011, acc: 53.12%, op_acc: 33.59%] [G loss: 0.921624]\n",
      "epoch:25 step:19807[D loss: 0.438159, acc: 64.84%, op_acc: 33.59%] [G loss: 0.916464]\n",
      "epoch:25 step:19808[D loss: 0.405803, acc: 65.62%, op_acc: 42.19%] [G loss: 0.947754]\n",
      "epoch:25 step:19809[D loss: 0.419727, acc: 60.94%, op_acc: 41.41%] [G loss: 0.831479]\n",
      "epoch:25 step:19810[D loss: 0.435494, acc: 60.16%, op_acc: 36.72%] [G loss: 0.814142]\n",
      "epoch:25 step:19811[D loss: 0.443864, acc: 59.38%, op_acc: 38.28%] [G loss: 0.916098]\n",
      "epoch:25 step:19812[D loss: 0.443186, acc: 51.56%, op_acc: 40.62%] [G loss: 0.853064]\n",
      "epoch:25 step:19813[D loss: 0.414717, acc: 57.03%, op_acc: 45.31%] [G loss: 0.821090]\n",
      "epoch:25 step:19814[D loss: 0.444572, acc: 57.03%, op_acc: 35.16%] [G loss: 0.887516]\n",
      "epoch:25 step:19815[D loss: 0.419901, acc: 61.72%, op_acc: 34.38%] [G loss: 0.894473]\n",
      "epoch:25 step:19816[D loss: 0.427741, acc: 61.72%, op_acc: 42.97%] [G loss: 0.864434]\n",
      "epoch:25 step:19817[D loss: 0.442691, acc: 58.59%, op_acc: 34.38%] [G loss: 0.870892]\n",
      "epoch:25 step:19818[D loss: 0.425038, acc: 56.25%, op_acc: 39.06%] [G loss: 0.815404]\n",
      "epoch:25 step:19819[D loss: 0.425135, acc: 60.16%, op_acc: 40.62%] [G loss: 0.905966]\n",
      "epoch:25 step:19820[D loss: 0.419087, acc: 63.28%, op_acc: 40.62%] [G loss: 0.855537]\n",
      "epoch:25 step:19821[D loss: 0.446890, acc: 52.34%, op_acc: 43.75%] [G loss: 0.835285]\n",
      "epoch:25 step:19822[D loss: 0.430030, acc: 67.97%, op_acc: 33.59%] [G loss: 0.889645]\n",
      "epoch:25 step:19823[D loss: 0.408393, acc: 64.84%, op_acc: 40.62%] [G loss: 0.944750]\n",
      "epoch:25 step:19824[D loss: 0.426095, acc: 58.59%, op_acc: 37.50%] [G loss: 0.842262]\n",
      "epoch:25 step:19825[D loss: 0.455519, acc: 53.12%, op_acc: 34.38%] [G loss: 0.770335]\n",
      "epoch:25 step:19826[D loss: 0.418912, acc: 60.94%, op_acc: 37.50%] [G loss: 0.812011]\n",
      "epoch:25 step:19827[D loss: 0.429592, acc: 51.56%, op_acc: 42.19%] [G loss: 0.887316]\n",
      "epoch:25 step:19828[D loss: 0.431346, acc: 56.25%, op_acc: 42.97%] [G loss: 0.866488]\n",
      "epoch:25 step:19829[D loss: 0.400192, acc: 60.16%, op_acc: 45.31%] [G loss: 0.887952]\n",
      "epoch:25 step:19830[D loss: 0.412133, acc: 58.59%, op_acc: 38.28%] [G loss: 0.909899]\n",
      "epoch:25 step:19831[D loss: 0.464019, acc: 53.91%, op_acc: 32.81%] [G loss: 0.797945]\n",
      "epoch:25 step:19832[D loss: 0.399319, acc: 61.72%, op_acc: 44.53%] [G loss: 0.844405]\n",
      "epoch:25 step:19833[D loss: 0.410434, acc: 60.16%, op_acc: 43.75%] [G loss: 0.822753]\n",
      "epoch:25 step:19834[D loss: 0.432335, acc: 62.50%, op_acc: 38.28%] [G loss: 0.924408]\n",
      "epoch:25 step:19835[D loss: 0.414302, acc: 68.75%, op_acc: 36.72%] [G loss: 0.904315]\n",
      "epoch:25 step:19836[D loss: 0.429204, acc: 58.59%, op_acc: 39.06%] [G loss: 0.794491]\n",
      "epoch:25 step:19837[D loss: 0.432766, acc: 55.47%, op_acc: 38.28%] [G loss: 0.898244]\n",
      "epoch:25 step:19838[D loss: 0.414065, acc: 65.62%, op_acc: 39.06%] [G loss: 0.946717]\n",
      "epoch:25 step:19839[D loss: 0.416991, acc: 65.62%, op_acc: 40.62%] [G loss: 0.787347]\n",
      "epoch:25 step:19840[D loss: 0.454431, acc: 53.91%, op_acc: 39.06%] [G loss: 0.837589]\n",
      "epoch:25 step:19841[D loss: 0.411670, acc: 54.69%, op_acc: 46.88%] [G loss: 0.909118]\n",
      "epoch:25 step:19842[D loss: 0.446455, acc: 60.94%, op_acc: 34.38%] [G loss: 0.829698]\n",
      "epoch:25 step:19843[D loss: 0.439713, acc: 64.84%, op_acc: 28.91%] [G loss: 0.836562]\n",
      "epoch:25 step:19844[D loss: 0.381696, acc: 68.75%, op_acc: 42.19%] [G loss: 0.951967]\n",
      "epoch:25 step:19845[D loss: 0.434819, acc: 57.03%, op_acc: 38.28%] [G loss: 0.865511]\n",
      "epoch:25 step:19846[D loss: 0.435260, acc: 59.38%, op_acc: 42.97%] [G loss: 0.877887]\n",
      "epoch:25 step:19847[D loss: 0.415552, acc: 60.16%, op_acc: 46.88%] [G loss: 0.951291]\n",
      "epoch:25 step:19848[D loss: 0.431997, acc: 60.94%, op_acc: 41.41%] [G loss: 0.891742]\n",
      "epoch:25 step:19849[D loss: 0.430021, acc: 53.12%, op_acc: 36.72%] [G loss: 0.870227]\n",
      "epoch:25 step:19850[D loss: 0.435955, acc: 48.44%, op_acc: 39.84%] [G loss: 0.849052]\n",
      "epoch:25 step:19851[D loss: 0.448943, acc: 50.78%, op_acc: 42.19%] [G loss: 0.883299]\n",
      "epoch:25 step:19852[D loss: 0.400994, acc: 63.28%, op_acc: 43.75%] [G loss: 0.887664]\n",
      "epoch:25 step:19853[D loss: 0.455389, acc: 48.44%, op_acc: 35.94%] [G loss: 0.830352]\n",
      "epoch:25 step:19854[D loss: 0.420132, acc: 57.81%, op_acc: 38.28%] [G loss: 0.893219]\n",
      "epoch:25 step:19855[D loss: 0.410596, acc: 56.25%, op_acc: 42.97%] [G loss: 0.899553]\n",
      "epoch:25 step:19856[D loss: 0.424272, acc: 56.25%, op_acc: 40.62%] [G loss: 0.842352]\n",
      "epoch:25 step:19857[D loss: 0.426021, acc: 60.16%, op_acc: 43.75%] [G loss: 0.929516]\n",
      "epoch:25 step:19858[D loss: 0.410900, acc: 60.94%, op_acc: 44.53%] [G loss: 0.915547]\n",
      "epoch:25 step:19859[D loss: 0.413726, acc: 59.38%, op_acc: 35.94%] [G loss: 0.934769]\n",
      "epoch:25 step:19860[D loss: 0.418625, acc: 62.50%, op_acc: 36.72%] [G loss: 0.920246]\n",
      "epoch:25 step:19861[D loss: 0.448029, acc: 62.50%, op_acc: 35.16%] [G loss: 0.904208]\n",
      "epoch:25 step:19862[D loss: 0.424585, acc: 59.38%, op_acc: 34.38%] [G loss: 0.896838]\n",
      "epoch:25 step:19863[D loss: 0.404168, acc: 57.81%, op_acc: 43.75%] [G loss: 0.952840]\n",
      "epoch:25 step:19864[D loss: 0.409875, acc: 65.62%, op_acc: 42.19%] [G loss: 0.908123]\n",
      "epoch:25 step:19865[D loss: 0.411535, acc: 67.97%, op_acc: 37.50%] [G loss: 0.817623]\n",
      "epoch:25 step:19866[D loss: 0.390582, acc: 64.06%, op_acc: 42.97%] [G loss: 0.880552]\n",
      "epoch:25 step:19867[D loss: 0.446557, acc: 53.12%, op_acc: 35.16%] [G loss: 0.860865]\n",
      "epoch:25 step:19868[D loss: 0.460524, acc: 56.25%, op_acc: 35.16%] [G loss: 0.863410]\n",
      "epoch:25 step:19869[D loss: 0.434131, acc: 57.03%, op_acc: 37.50%] [G loss: 0.840993]\n",
      "epoch:25 step:19870[D loss: 0.411588, acc: 61.72%, op_acc: 41.41%] [G loss: 0.936011]\n",
      "epoch:25 step:19871[D loss: 0.413315, acc: 60.94%, op_acc: 41.41%] [G loss: 0.971785]\n",
      "epoch:25 step:19872[D loss: 0.407236, acc: 59.38%, op_acc: 42.19%] [G loss: 0.897536]\n",
      "epoch:25 step:19873[D loss: 0.410960, acc: 66.41%, op_acc: 40.62%] [G loss: 0.887161]\n",
      "epoch:25 step:19874[D loss: 0.449206, acc: 53.91%, op_acc: 44.53%] [G loss: 0.908559]\n",
      "epoch:25 step:19875[D loss: 0.422284, acc: 64.84%, op_acc: 41.41%] [G loss: 0.907963]\n",
      "epoch:25 step:19876[D loss: 0.457403, acc: 57.03%, op_acc: 33.59%] [G loss: 0.865321]\n",
      "epoch:25 step:19877[D loss: 0.449745, acc: 54.69%, op_acc: 38.28%] [G loss: 0.838015]\n",
      "epoch:25 step:19878[D loss: 0.412802, acc: 57.81%, op_acc: 41.41%] [G loss: 0.830585]\n",
      "epoch:25 step:19879[D loss: 0.456383, acc: 47.66%, op_acc: 39.84%] [G loss: 0.903461]\n",
      "epoch:25 step:19880[D loss: 0.410096, acc: 67.19%, op_acc: 44.53%] [G loss: 0.795563]\n",
      "epoch:25 step:19881[D loss: 0.426028, acc: 53.12%, op_acc: 37.50%] [G loss: 0.861734]\n",
      "epoch:25 step:19882[D loss: 0.429897, acc: 60.94%, op_acc: 39.06%] [G loss: 0.915876]\n",
      "epoch:25 step:19883[D loss: 0.445076, acc: 50.00%, op_acc: 41.41%] [G loss: 0.883952]\n",
      "epoch:25 step:19884[D loss: 0.425844, acc: 57.81%, op_acc: 35.94%] [G loss: 0.992626]\n",
      "epoch:25 step:19885[D loss: 0.442149, acc: 58.59%, op_acc: 38.28%] [G loss: 0.926182]\n",
      "epoch:25 step:19886[D loss: 0.413209, acc: 56.25%, op_acc: 38.28%] [G loss: 0.940543]\n",
      "epoch:25 step:19887[D loss: 0.394103, acc: 64.84%, op_acc: 44.53%] [G loss: 0.833184]\n",
      "epoch:25 step:19888[D loss: 0.409315, acc: 57.81%, op_acc: 46.09%] [G loss: 0.905190]\n",
      "epoch:25 step:19889[D loss: 0.440935, acc: 56.25%, op_acc: 39.06%] [G loss: 0.838893]\n",
      "epoch:25 step:19890[D loss: 0.385608, acc: 68.75%, op_acc: 46.09%] [G loss: 0.828646]\n",
      "epoch:25 step:19891[D loss: 0.435950, acc: 56.25%, op_acc: 39.06%] [G loss: 0.933893]\n",
      "epoch:25 step:19892[D loss: 0.438029, acc: 62.50%, op_acc: 33.59%] [G loss: 0.842704]\n",
      "epoch:25 step:19893[D loss: 0.437458, acc: 53.91%, op_acc: 39.06%] [G loss: 0.863385]\n",
      "epoch:25 step:19894[D loss: 0.438421, acc: 55.47%, op_acc: 36.72%] [G loss: 0.866820]\n",
      "epoch:25 step:19895[D loss: 0.436973, acc: 62.50%, op_acc: 34.38%] [G loss: 0.896057]\n",
      "epoch:25 step:19896[D loss: 0.384193, acc: 64.06%, op_acc: 50.00%] [G loss: 0.969140]\n",
      "epoch:25 step:19897[D loss: 0.435910, acc: 52.34%, op_acc: 40.62%] [G loss: 0.874916]\n",
      "epoch:25 step:19898[D loss: 0.429609, acc: 57.03%, op_acc: 42.97%] [G loss: 0.858470]\n",
      "epoch:25 step:19899[D loss: 0.443638, acc: 50.78%, op_acc: 39.06%] [G loss: 0.900843]\n",
      "epoch:25 step:19900[D loss: 0.425997, acc: 60.94%, op_acc: 40.62%] [G loss: 0.918602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19901[D loss: 0.407272, acc: 65.62%, op_acc: 37.50%] [G loss: 0.944762]\n",
      "epoch:25 step:19902[D loss: 0.409565, acc: 57.81%, op_acc: 41.41%] [G loss: 0.875328]\n",
      "epoch:25 step:19903[D loss: 0.422129, acc: 57.81%, op_acc: 40.62%] [G loss: 0.909090]\n",
      "epoch:25 step:19904[D loss: 0.408665, acc: 61.72%, op_acc: 40.62%] [G loss: 1.025092]\n",
      "epoch:25 step:19905[D loss: 0.421905, acc: 62.50%, op_acc: 35.16%] [G loss: 0.840253]\n",
      "epoch:25 step:19906[D loss: 0.424117, acc: 64.06%, op_acc: 44.53%] [G loss: 0.915362]\n",
      "epoch:25 step:19907[D loss: 0.427879, acc: 62.50%, op_acc: 39.84%] [G loss: 0.934822]\n",
      "epoch:25 step:19908[D loss: 0.397618, acc: 65.62%, op_acc: 42.19%] [G loss: 0.986147]\n",
      "epoch:25 step:19909[D loss: 0.408046, acc: 64.06%, op_acc: 42.19%] [G loss: 0.887017]\n",
      "epoch:25 step:19910[D loss: 0.408797, acc: 64.84%, op_acc: 41.41%] [G loss: 0.967472]\n",
      "epoch:25 step:19911[D loss: 0.404956, acc: 59.38%, op_acc: 39.06%] [G loss: 0.878026]\n",
      "epoch:25 step:19912[D loss: 0.443413, acc: 55.47%, op_acc: 38.28%] [G loss: 0.929481]\n",
      "epoch:25 step:19913[D loss: 0.432857, acc: 63.28%, op_acc: 39.06%] [G loss: 0.969617]\n",
      "epoch:25 step:19914[D loss: 0.458333, acc: 50.00%, op_acc: 37.50%] [G loss: 0.929373]\n",
      "epoch:25 step:19915[D loss: 0.379576, acc: 64.84%, op_acc: 46.09%] [G loss: 0.876080]\n",
      "epoch:25 step:19916[D loss: 0.401329, acc: 57.03%, op_acc: 47.66%] [G loss: 0.873734]\n",
      "epoch:25 step:19917[D loss: 0.431609, acc: 56.25%, op_acc: 42.19%] [G loss: 0.950625]\n",
      "epoch:25 step:19918[D loss: 0.435678, acc: 55.47%, op_acc: 42.97%] [G loss: 0.867134]\n",
      "epoch:25 step:19919[D loss: 0.425887, acc: 64.84%, op_acc: 31.25%] [G loss: 0.872709]\n",
      "epoch:25 step:19920[D loss: 0.455655, acc: 57.81%, op_acc: 32.81%] [G loss: 0.940237]\n",
      "epoch:25 step:19921[D loss: 0.424062, acc: 57.03%, op_acc: 41.41%] [G loss: 0.901400]\n",
      "epoch:25 step:19922[D loss: 0.393933, acc: 62.50%, op_acc: 42.97%] [G loss: 0.941641]\n",
      "epoch:25 step:19923[D loss: 0.437203, acc: 60.94%, op_acc: 39.84%] [G loss: 1.019627]\n",
      "epoch:25 step:19924[D loss: 0.404497, acc: 62.50%, op_acc: 40.62%] [G loss: 0.948175]\n",
      "epoch:25 step:19925[D loss: 0.413472, acc: 60.94%, op_acc: 43.75%] [G loss: 0.915400]\n",
      "epoch:25 step:19926[D loss: 0.419408, acc: 56.25%, op_acc: 39.06%] [G loss: 0.901662]\n",
      "epoch:25 step:19927[D loss: 0.387720, acc: 75.78%, op_acc: 41.41%] [G loss: 0.925668]\n",
      "epoch:25 step:19928[D loss: 0.421039, acc: 57.81%, op_acc: 41.41%] [G loss: 0.891517]\n",
      "epoch:25 step:19929[D loss: 0.418077, acc: 56.25%, op_acc: 42.19%] [G loss: 0.846067]\n",
      "epoch:25 step:19930[D loss: 0.437674, acc: 61.72%, op_acc: 39.06%] [G loss: 0.903137]\n",
      "epoch:25 step:19931[D loss: 0.422608, acc: 53.12%, op_acc: 39.06%] [G loss: 0.919132]\n",
      "epoch:25 step:19932[D loss: 0.426299, acc: 60.16%, op_acc: 38.28%] [G loss: 0.915611]\n",
      "epoch:25 step:19933[D loss: 0.391469, acc: 64.84%, op_acc: 46.88%] [G loss: 0.986045]\n",
      "epoch:25 step:19934[D loss: 0.452558, acc: 53.91%, op_acc: 42.19%] [G loss: 0.903540]\n",
      "epoch:25 step:19935[D loss: 0.405127, acc: 60.16%, op_acc: 46.09%] [G loss: 0.900808]\n",
      "epoch:25 step:19936[D loss: 0.397462, acc: 67.19%, op_acc: 44.53%] [G loss: 0.905793]\n",
      "epoch:25 step:19937[D loss: 0.422924, acc: 57.81%, op_acc: 42.19%] [G loss: 0.845140]\n",
      "epoch:25 step:19938[D loss: 0.436728, acc: 49.22%, op_acc: 42.19%] [G loss: 0.899801]\n",
      "epoch:25 step:19939[D loss: 0.419692, acc: 58.59%, op_acc: 42.19%] [G loss: 0.916675]\n",
      "epoch:25 step:19940[D loss: 0.400628, acc: 65.62%, op_acc: 37.50%] [G loss: 0.921350]\n",
      "epoch:25 step:19941[D loss: 0.403661, acc: 58.59%, op_acc: 44.53%] [G loss: 0.871579]\n",
      "epoch:25 step:19942[D loss: 0.415549, acc: 60.94%, op_acc: 42.97%] [G loss: 0.841767]\n",
      "epoch:25 step:19943[D loss: 0.424978, acc: 57.03%, op_acc: 39.84%] [G loss: 0.885836]\n",
      "epoch:25 step:19944[D loss: 0.404691, acc: 60.94%, op_acc: 40.62%] [G loss: 0.935512]\n",
      "epoch:25 step:19945[D loss: 0.413154, acc: 57.81%, op_acc: 47.66%] [G loss: 0.933396]\n",
      "epoch:25 step:19946[D loss: 0.448388, acc: 61.72%, op_acc: 32.81%] [G loss: 0.977496]\n",
      "epoch:25 step:19947[D loss: 0.420540, acc: 59.38%, op_acc: 41.41%] [G loss: 0.892024]\n",
      "epoch:25 step:19948[D loss: 0.435481, acc: 59.38%, op_acc: 32.81%] [G loss: 0.931287]\n",
      "epoch:25 step:19949[D loss: 0.458956, acc: 54.69%, op_acc: 37.50%] [G loss: 0.937817]\n",
      "epoch:25 step:19950[D loss: 0.444605, acc: 53.12%, op_acc: 35.94%] [G loss: 0.881124]\n",
      "epoch:25 step:19951[D loss: 0.444545, acc: 56.25%, op_acc: 41.41%] [G loss: 0.822419]\n",
      "epoch:25 step:19952[D loss: 0.419013, acc: 62.50%, op_acc: 38.28%] [G loss: 0.856044]\n",
      "epoch:25 step:19953[D loss: 0.428113, acc: 56.25%, op_acc: 42.19%] [G loss: 0.968567]\n",
      "epoch:25 step:19954[D loss: 0.436719, acc: 56.25%, op_acc: 39.84%] [G loss: 0.853227]\n",
      "epoch:25 step:19955[D loss: 0.394941, acc: 70.31%, op_acc: 42.19%] [G loss: 0.817298]\n",
      "epoch:25 step:19956[D loss: 0.456090, acc: 50.00%, op_acc: 38.28%] [G loss: 0.834781]\n",
      "epoch:25 step:19957[D loss: 0.401179, acc: 58.59%, op_acc: 42.97%] [G loss: 1.027295]\n",
      "epoch:25 step:19958[D loss: 0.423502, acc: 57.03%, op_acc: 41.41%] [G loss: 0.810773]\n",
      "epoch:25 step:19959[D loss: 0.421086, acc: 57.03%, op_acc: 45.31%] [G loss: 0.884759]\n",
      "epoch:25 step:19960[D loss: 0.409087, acc: 60.94%, op_acc: 45.31%] [G loss: 0.847877]\n",
      "epoch:25 step:19961[D loss: 0.468106, acc: 50.00%, op_acc: 37.50%] [G loss: 0.811897]\n",
      "epoch:25 step:19962[D loss: 0.433205, acc: 62.50%, op_acc: 42.19%] [G loss: 0.854029]\n",
      "epoch:25 step:19963[D loss: 0.417093, acc: 59.38%, op_acc: 39.06%] [G loss: 0.784311]\n",
      "epoch:25 step:19964[D loss: 0.427735, acc: 54.69%, op_acc: 43.75%] [G loss: 0.833122]\n",
      "epoch:25 step:19965[D loss: 0.382068, acc: 69.53%, op_acc: 42.19%] [G loss: 0.900512]\n",
      "epoch:25 step:19966[D loss: 0.425181, acc: 59.38%, op_acc: 38.28%] [G loss: 0.900898]\n",
      "epoch:25 step:19967[D loss: 0.424864, acc: 56.25%, op_acc: 45.31%] [G loss: 0.833259]\n",
      "epoch:25 step:19968[D loss: 0.422586, acc: 62.50%, op_acc: 40.62%] [G loss: 0.878657]\n",
      "epoch:25 step:19969[D loss: 0.428355, acc: 60.16%, op_acc: 38.28%] [G loss: 0.870951]\n",
      "epoch:25 step:19970[D loss: 0.449142, acc: 57.03%, op_acc: 39.84%] [G loss: 0.854101]\n",
      "epoch:25 step:19971[D loss: 0.431476, acc: 58.59%, op_acc: 42.97%] [G loss: 0.860095]\n",
      "epoch:25 step:19972[D loss: 0.449225, acc: 59.38%, op_acc: 35.16%] [G loss: 0.884461]\n",
      "epoch:25 step:19973[D loss: 0.380962, acc: 67.19%, op_acc: 42.97%] [G loss: 0.934577]\n",
      "epoch:25 step:19974[D loss: 0.415645, acc: 61.72%, op_acc: 40.62%] [G loss: 0.955920]\n",
      "epoch:25 step:19975[D loss: 0.453142, acc: 53.91%, op_acc: 37.50%] [G loss: 0.887174]\n",
      "epoch:25 step:19976[D loss: 0.436872, acc: 53.12%, op_acc: 37.50%] [G loss: 0.853904]\n",
      "epoch:25 step:19977[D loss: 0.386596, acc: 67.19%, op_acc: 40.62%] [G loss: 0.857536]\n",
      "epoch:25 step:19978[D loss: 0.406421, acc: 59.38%, op_acc: 42.19%] [G loss: 0.864542]\n",
      "epoch:25 step:19979[D loss: 0.407148, acc: 63.28%, op_acc: 41.41%] [G loss: 0.886947]\n",
      "epoch:25 step:19980[D loss: 0.457296, acc: 46.88%, op_acc: 40.62%] [G loss: 0.913679]\n",
      "epoch:25 step:19981[D loss: 0.427762, acc: 58.59%, op_acc: 37.50%] [G loss: 0.922993]\n",
      "epoch:25 step:19982[D loss: 0.409038, acc: 64.06%, op_acc: 39.84%] [G loss: 0.915853]\n",
      "epoch:25 step:19983[D loss: 0.407699, acc: 61.72%, op_acc: 41.41%] [G loss: 0.817439]\n",
      "epoch:25 step:19984[D loss: 0.419680, acc: 60.94%, op_acc: 42.19%] [G loss: 0.942632]\n",
      "epoch:25 step:19985[D loss: 0.415069, acc: 57.81%, op_acc: 42.19%] [G loss: 0.881381]\n",
      "epoch:25 step:19986[D loss: 0.420428, acc: 60.16%, op_acc: 35.94%] [G loss: 0.935185]\n",
      "epoch:25 step:19987[D loss: 0.417525, acc: 59.38%, op_acc: 42.19%] [G loss: 0.905850]\n",
      "epoch:25 step:19988[D loss: 0.417508, acc: 62.50%, op_acc: 41.41%] [G loss: 0.914791]\n",
      "epoch:25 step:19989[D loss: 0.436710, acc: 62.50%, op_acc: 35.16%] [G loss: 0.814485]\n",
      "epoch:25 step:19990[D loss: 0.435745, acc: 54.69%, op_acc: 39.06%] [G loss: 0.850878]\n",
      "epoch:25 step:19991[D loss: 0.398247, acc: 64.84%, op_acc: 39.84%] [G loss: 0.912283]\n",
      "epoch:25 step:19992[D loss: 0.433824, acc: 55.47%, op_acc: 39.06%] [G loss: 0.861185]\n",
      "epoch:25 step:19993[D loss: 0.444047, acc: 51.56%, op_acc: 38.28%] [G loss: 0.918092]\n",
      "epoch:25 step:19994[D loss: 0.391221, acc: 71.09%, op_acc: 45.31%] [G loss: 0.811901]\n",
      "epoch:25 step:19995[D loss: 0.417663, acc: 60.16%, op_acc: 41.41%] [G loss: 0.923135]\n",
      "epoch:25 step:19996[D loss: 0.408927, acc: 59.38%, op_acc: 37.50%] [G loss: 0.905035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:19997[D loss: 0.427430, acc: 57.03%, op_acc: 35.94%] [G loss: 0.913112]\n",
      "epoch:25 step:19998[D loss: 0.408476, acc: 60.16%, op_acc: 39.84%] [G loss: 0.870814]\n",
      "epoch:25 step:19999[D loss: 0.425470, acc: 56.25%, op_acc: 42.19%] [G loss: 0.884753]\n",
      "epoch:25 step:20000[D loss: 0.413751, acc: 60.16%, op_acc: 39.84%] [G loss: 0.909334]\n",
      "epoch:25 step:20001[D loss: 0.458593, acc: 50.78%, op_acc: 39.84%] [G loss: 0.855675]\n",
      "epoch:25 step:20002[D loss: 0.434309, acc: 60.16%, op_acc: 39.06%] [G loss: 0.911430]\n",
      "epoch:25 step:20003[D loss: 0.431331, acc: 50.78%, op_acc: 39.84%] [G loss: 0.836415]\n",
      "epoch:25 step:20004[D loss: 0.431425, acc: 56.25%, op_acc: 33.59%] [G loss: 0.853086]\n",
      "epoch:25 step:20005[D loss: 0.441926, acc: 53.91%, op_acc: 33.59%] [G loss: 0.936281]\n",
      "epoch:25 step:20006[D loss: 0.422237, acc: 63.28%, op_acc: 35.16%] [G loss: 0.892349]\n",
      "epoch:25 step:20007[D loss: 0.421063, acc: 63.28%, op_acc: 39.84%] [G loss: 0.971698]\n",
      "epoch:25 step:20008[D loss: 0.436617, acc: 61.72%, op_acc: 41.41%] [G loss: 0.884603]\n",
      "epoch:25 step:20009[D loss: 0.418234, acc: 60.94%, op_acc: 41.41%] [G loss: 0.956873]\n",
      "epoch:25 step:20010[D loss: 0.403905, acc: 65.62%, op_acc: 35.94%] [G loss: 0.928319]\n",
      "epoch:25 step:20011[D loss: 0.407254, acc: 60.16%, op_acc: 42.97%] [G loss: 0.869207]\n",
      "epoch:25 step:20012[D loss: 0.410797, acc: 62.50%, op_acc: 39.06%] [G loss: 0.992672]\n",
      "epoch:25 step:20013[D loss: 0.430645, acc: 56.25%, op_acc: 38.28%] [G loss: 0.880062]\n",
      "epoch:25 step:20014[D loss: 0.436792, acc: 56.25%, op_acc: 42.97%] [G loss: 0.850876]\n",
      "epoch:25 step:20015[D loss: 0.386533, acc: 61.72%, op_acc: 49.22%] [G loss: 0.932966]\n",
      "epoch:25 step:20016[D loss: 0.459561, acc: 53.12%, op_acc: 36.72%] [G loss: 0.899663]\n",
      "epoch:25 step:20017[D loss: 0.413956, acc: 64.84%, op_acc: 33.59%] [G loss: 0.857035]\n",
      "epoch:25 step:20018[D loss: 0.437822, acc: 58.59%, op_acc: 40.62%] [G loss: 0.885605]\n",
      "epoch:25 step:20019[D loss: 0.388905, acc: 60.94%, op_acc: 39.06%] [G loss: 0.898272]\n",
      "epoch:25 step:20020[D loss: 0.422454, acc: 62.50%, op_acc: 36.72%] [G loss: 0.953951]\n",
      "epoch:25 step:20021[D loss: 0.380870, acc: 74.22%, op_acc: 39.06%] [G loss: 0.896065]\n",
      "epoch:25 step:20022[D loss: 0.427414, acc: 51.56%, op_acc: 42.97%] [G loss: 0.852786]\n",
      "epoch:25 step:20023[D loss: 0.430187, acc: 60.16%, op_acc: 37.50%] [G loss: 0.917346]\n",
      "epoch:25 step:20024[D loss: 0.445801, acc: 59.38%, op_acc: 38.28%] [G loss: 0.863045]\n",
      "epoch:25 step:20025[D loss: 0.414519, acc: 63.28%, op_acc: 39.84%] [G loss: 0.925334]\n",
      "epoch:25 step:20026[D loss: 0.458441, acc: 55.47%, op_acc: 36.72%] [G loss: 0.840204]\n",
      "epoch:25 step:20027[D loss: 0.431947, acc: 54.69%, op_acc: 36.72%] [G loss: 0.884329]\n",
      "epoch:25 step:20028[D loss: 0.413128, acc: 64.84%, op_acc: 35.94%] [G loss: 0.884187]\n",
      "epoch:25 step:20029[D loss: 0.469028, acc: 50.78%, op_acc: 35.94%] [G loss: 0.861253]\n",
      "epoch:25 step:20030[D loss: 0.452650, acc: 50.00%, op_acc: 35.94%] [G loss: 0.858036]\n",
      "epoch:25 step:20031[D loss: 0.447736, acc: 53.12%, op_acc: 36.72%] [G loss: 0.806845]\n",
      "epoch:25 step:20032[D loss: 0.399698, acc: 63.28%, op_acc: 38.28%] [G loss: 0.916891]\n",
      "epoch:25 step:20033[D loss: 0.446471, acc: 54.69%, op_acc: 41.41%] [G loss: 0.833278]\n",
      "epoch:25 step:20034[D loss: 0.462059, acc: 55.47%, op_acc: 35.16%] [G loss: 0.870578]\n",
      "epoch:25 step:20035[D loss: 0.449374, acc: 53.91%, op_acc: 34.38%] [G loss: 0.914916]\n",
      "epoch:25 step:20036[D loss: 0.427620, acc: 56.25%, op_acc: 41.41%] [G loss: 0.903800]\n",
      "epoch:25 step:20037[D loss: 0.437111, acc: 52.34%, op_acc: 39.06%] [G loss: 1.002200]\n",
      "epoch:25 step:20038[D loss: 0.472835, acc: 57.81%, op_acc: 36.72%] [G loss: 0.894078]\n",
      "epoch:25 step:20039[D loss: 0.430764, acc: 59.38%, op_acc: 36.72%] [G loss: 0.897484]\n",
      "epoch:25 step:20040[D loss: 0.426395, acc: 63.28%, op_acc: 35.16%] [G loss: 0.835984]\n",
      "epoch:25 step:20041[D loss: 0.419343, acc: 53.91%, op_acc: 42.19%] [G loss: 0.889243]\n",
      "epoch:25 step:20042[D loss: 0.438482, acc: 59.38%, op_acc: 40.62%] [G loss: 0.883329]\n",
      "epoch:25 step:20043[D loss: 0.398215, acc: 61.72%, op_acc: 40.62%] [G loss: 0.889409]\n",
      "epoch:25 step:20044[D loss: 0.438418, acc: 53.91%, op_acc: 40.62%] [G loss: 0.915081]\n",
      "epoch:25 step:20045[D loss: 0.430492, acc: 61.72%, op_acc: 42.97%] [G loss: 0.854825]\n",
      "epoch:25 step:20046[D loss: 0.426859, acc: 56.25%, op_acc: 36.72%] [G loss: 0.947527]\n",
      "epoch:25 step:20047[D loss: 0.445543, acc: 55.47%, op_acc: 39.06%] [G loss: 0.856486]\n",
      "epoch:25 step:20048[D loss: 0.438727, acc: 57.03%, op_acc: 35.94%] [G loss: 0.857920]\n",
      "epoch:25 step:20049[D loss: 0.416812, acc: 65.62%, op_acc: 35.16%] [G loss: 0.898605]\n",
      "epoch:25 step:20050[D loss: 0.429942, acc: 65.62%, op_acc: 36.72%] [G loss: 0.911649]\n",
      "epoch:25 step:20051[D loss: 0.433988, acc: 66.41%, op_acc: 32.03%] [G loss: 0.851157]\n",
      "epoch:25 step:20052[D loss: 0.423053, acc: 51.56%, op_acc: 40.62%] [G loss: 0.886945]\n",
      "epoch:25 step:20053[D loss: 0.415375, acc: 62.50%, op_acc: 44.53%] [G loss: 0.880932]\n",
      "epoch:25 step:20054[D loss: 0.385560, acc: 70.31%, op_acc: 41.41%] [G loss: 0.852336]\n",
      "epoch:25 step:20055[D loss: 0.424796, acc: 56.25%, op_acc: 39.06%] [G loss: 0.945546]\n",
      "epoch:25 step:20056[D loss: 0.400582, acc: 70.31%, op_acc: 38.28%] [G loss: 0.904685]\n",
      "epoch:25 step:20057[D loss: 0.460066, acc: 57.03%, op_acc: 37.50%] [G loss: 0.950441]\n",
      "epoch:25 step:20058[D loss: 0.419534, acc: 60.94%, op_acc: 43.75%] [G loss: 0.909253]\n",
      "epoch:25 step:20059[D loss: 0.431079, acc: 59.38%, op_acc: 43.75%] [G loss: 0.863706]\n",
      "epoch:25 step:20060[D loss: 0.445500, acc: 56.25%, op_acc: 39.06%] [G loss: 0.841157]\n",
      "epoch:25 step:20061[D loss: 0.417987, acc: 60.16%, op_acc: 36.72%] [G loss: 0.960251]\n",
      "epoch:25 step:20062[D loss: 0.450377, acc: 56.25%, op_acc: 37.50%] [G loss: 0.928470]\n",
      "epoch:25 step:20063[D loss: 0.420688, acc: 57.03%, op_acc: 40.62%] [G loss: 0.828027]\n",
      "epoch:25 step:20064[D loss: 0.432151, acc: 54.69%, op_acc: 40.62%] [G loss: 0.960064]\n",
      "epoch:25 step:20065[D loss: 0.426373, acc: 60.94%, op_acc: 37.50%] [G loss: 0.823503]\n",
      "epoch:25 step:20066[D loss: 0.386665, acc: 64.84%, op_acc: 42.19%] [G loss: 0.921750]\n",
      "epoch:25 step:20067[D loss: 0.443507, acc: 60.94%, op_acc: 36.72%] [G loss: 0.908423]\n",
      "epoch:25 step:20068[D loss: 0.424705, acc: 60.16%, op_acc: 39.06%] [G loss: 0.864565]\n",
      "epoch:25 step:20069[D loss: 0.441626, acc: 56.25%, op_acc: 39.06%] [G loss: 0.892498]\n",
      "epoch:25 step:20070[D loss: 0.401282, acc: 67.19%, op_acc: 40.62%] [G loss: 0.913099]\n",
      "epoch:25 step:20071[D loss: 0.420006, acc: 61.72%, op_acc: 38.28%] [G loss: 0.926548]\n",
      "epoch:25 step:20072[D loss: 0.427685, acc: 64.06%, op_acc: 36.72%] [G loss: 0.900490]\n",
      "epoch:25 step:20073[D loss: 0.448690, acc: 57.81%, op_acc: 39.84%] [G loss: 0.868010]\n",
      "epoch:25 step:20074[D loss: 0.430953, acc: 60.94%, op_acc: 41.41%] [G loss: 0.894483]\n",
      "epoch:25 step:20075[D loss: 0.403319, acc: 66.41%, op_acc: 39.84%] [G loss: 0.905660]\n",
      "epoch:25 step:20076[D loss: 0.416425, acc: 61.72%, op_acc: 37.50%] [G loss: 0.913851]\n",
      "epoch:25 step:20077[D loss: 0.470367, acc: 50.78%, op_acc: 39.84%] [G loss: 0.898122]\n",
      "epoch:25 step:20078[D loss: 0.407733, acc: 61.72%, op_acc: 45.31%] [G loss: 0.853392]\n",
      "epoch:25 step:20079[D loss: 0.432007, acc: 57.03%, op_acc: 38.28%] [G loss: 0.881446]\n",
      "epoch:25 step:20080[D loss: 0.415084, acc: 55.47%, op_acc: 39.84%] [G loss: 0.883334]\n",
      "epoch:25 step:20081[D loss: 0.423360, acc: 58.59%, op_acc: 40.62%] [G loss: 0.895849]\n",
      "epoch:25 step:20082[D loss: 0.438268, acc: 53.12%, op_acc: 41.41%] [G loss: 0.806918]\n",
      "epoch:25 step:20083[D loss: 0.397608, acc: 64.84%, op_acc: 46.88%] [G loss: 0.866741]\n",
      "epoch:25 step:20084[D loss: 0.390582, acc: 65.62%, op_acc: 41.41%] [G loss: 0.904395]\n",
      "epoch:25 step:20085[D loss: 0.436773, acc: 60.16%, op_acc: 34.38%] [G loss: 0.859152]\n",
      "epoch:25 step:20086[D loss: 0.402490, acc: 59.38%, op_acc: 43.75%] [G loss: 0.862966]\n",
      "epoch:25 step:20087[D loss: 0.429553, acc: 58.59%, op_acc: 35.16%] [G loss: 0.887984]\n",
      "epoch:25 step:20088[D loss: 0.428702, acc: 63.28%, op_acc: 34.38%] [G loss: 0.904529]\n",
      "epoch:25 step:20089[D loss: 0.426718, acc: 59.38%, op_acc: 36.72%] [G loss: 0.871577]\n",
      "epoch:25 step:20090[D loss: 0.423708, acc: 60.94%, op_acc: 39.84%] [G loss: 0.939377]\n",
      "epoch:25 step:20091[D loss: 0.428450, acc: 55.47%, op_acc: 42.19%] [G loss: 0.906234]\n",
      "epoch:25 step:20092[D loss: 0.422174, acc: 59.38%, op_acc: 39.84%] [G loss: 0.907817]\n",
      "epoch:25 step:20093[D loss: 0.425514, acc: 57.81%, op_acc: 40.62%] [G loss: 0.893324]\n",
      "epoch:25 step:20094[D loss: 0.395301, acc: 61.72%, op_acc: 49.22%] [G loss: 0.954457]\n",
      "epoch:25 step:20095[D loss: 0.418078, acc: 62.50%, op_acc: 35.16%] [G loss: 0.945438]\n",
      "epoch:25 step:20096[D loss: 0.444491, acc: 60.94%, op_acc: 40.62%] [G loss: 0.964521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20097[D loss: 0.425765, acc: 55.47%, op_acc: 39.84%] [G loss: 0.879827]\n",
      "epoch:25 step:20098[D loss: 0.426199, acc: 59.38%, op_acc: 40.62%] [G loss: 0.892316]\n",
      "epoch:25 step:20099[D loss: 0.426228, acc: 59.38%, op_acc: 36.72%] [G loss: 0.786563]\n",
      "epoch:25 step:20100[D loss: 0.420342, acc: 60.16%, op_acc: 39.84%] [G loss: 0.876955]\n",
      "epoch:25 step:20101[D loss: 0.397904, acc: 64.06%, op_acc: 41.41%] [G loss: 0.784321]\n",
      "epoch:25 step:20102[D loss: 0.404444, acc: 64.06%, op_acc: 45.31%] [G loss: 0.892388]\n",
      "epoch:25 step:20103[D loss: 0.450705, acc: 59.38%, op_acc: 37.50%] [G loss: 0.875018]\n",
      "epoch:25 step:20104[D loss: 0.392045, acc: 66.41%, op_acc: 42.19%] [G loss: 0.923560]\n",
      "epoch:25 step:20105[D loss: 0.428010, acc: 56.25%, op_acc: 39.06%] [G loss: 0.846977]\n",
      "epoch:25 step:20106[D loss: 0.433589, acc: 61.72%, op_acc: 28.91%] [G loss: 0.835858]\n",
      "epoch:25 step:20107[D loss: 0.420116, acc: 60.94%, op_acc: 41.41%] [G loss: 0.860503]\n",
      "epoch:25 step:20108[D loss: 0.405439, acc: 64.06%, op_acc: 40.62%] [G loss: 0.921607]\n",
      "epoch:25 step:20109[D loss: 0.463084, acc: 50.78%, op_acc: 31.25%] [G loss: 0.836750]\n",
      "epoch:25 step:20110[D loss: 0.410735, acc: 56.25%, op_acc: 39.84%] [G loss: 0.871935]\n",
      "epoch:25 step:20111[D loss: 0.421022, acc: 61.72%, op_acc: 42.97%] [G loss: 0.802613]\n",
      "epoch:25 step:20112[D loss: 0.408727, acc: 67.19%, op_acc: 35.94%] [G loss: 0.855966]\n",
      "epoch:25 step:20113[D loss: 0.407644, acc: 61.72%, op_acc: 42.19%] [G loss: 0.928938]\n",
      "epoch:25 step:20114[D loss: 0.396404, acc: 68.75%, op_acc: 42.97%] [G loss: 0.906013]\n",
      "epoch:25 step:20115[D loss: 0.430194, acc: 56.25%, op_acc: 39.06%] [G loss: 0.932242]\n",
      "epoch:25 step:20116[D loss: 0.441408, acc: 63.28%, op_acc: 36.72%] [G loss: 0.853255]\n",
      "epoch:25 step:20117[D loss: 0.407081, acc: 64.84%, op_acc: 42.97%] [G loss: 0.959340]\n",
      "epoch:25 step:20118[D loss: 0.447496, acc: 67.97%, op_acc: 35.94%] [G loss: 1.038870]\n",
      "epoch:25 step:20119[D loss: 0.441141, acc: 60.16%, op_acc: 33.59%] [G loss: 0.904551]\n",
      "epoch:25 step:20120[D loss: 0.419698, acc: 64.06%, op_acc: 39.84%] [G loss: 0.898096]\n",
      "epoch:25 step:20121[D loss: 0.414199, acc: 59.38%, op_acc: 42.19%] [G loss: 0.802768]\n",
      "epoch:25 step:20122[D loss: 0.406883, acc: 67.19%, op_acc: 41.41%] [G loss: 0.836398]\n",
      "epoch:25 step:20123[D loss: 0.419894, acc: 59.38%, op_acc: 39.06%] [G loss: 0.799851]\n",
      "epoch:25 step:20124[D loss: 0.425840, acc: 61.72%, op_acc: 39.84%] [G loss: 0.858104]\n",
      "epoch:25 step:20125[D loss: 0.432274, acc: 62.50%, op_acc: 39.06%] [G loss: 0.858402]\n",
      "epoch:25 step:20126[D loss: 0.427639, acc: 53.91%, op_acc: 39.06%] [G loss: 0.892229]\n",
      "epoch:25 step:20127[D loss: 0.379632, acc: 66.41%, op_acc: 44.53%] [G loss: 0.866241]\n",
      "epoch:25 step:20128[D loss: 0.395430, acc: 58.59%, op_acc: 48.44%] [G loss: 0.945475]\n",
      "epoch:25 step:20129[D loss: 0.416313, acc: 66.41%, op_acc: 39.84%] [G loss: 0.859322]\n",
      "epoch:25 step:20130[D loss: 0.436037, acc: 56.25%, op_acc: 37.50%] [G loss: 0.843833]\n",
      "epoch:25 step:20131[D loss: 0.395981, acc: 69.53%, op_acc: 49.22%] [G loss: 0.895383]\n",
      "epoch:25 step:20132[D loss: 0.421966, acc: 57.03%, op_acc: 45.31%] [G loss: 0.900349]\n",
      "epoch:25 step:20133[D loss: 0.396818, acc: 62.50%, op_acc: 42.19%] [G loss: 0.925472]\n",
      "epoch:25 step:20134[D loss: 0.414351, acc: 58.59%, op_acc: 38.28%] [G loss: 0.922209]\n",
      "epoch:25 step:20135[D loss: 0.418481, acc: 61.72%, op_acc: 35.94%] [G loss: 0.863664]\n",
      "epoch:25 step:20136[D loss: 0.430941, acc: 57.81%, op_acc: 41.41%] [G loss: 0.907732]\n",
      "epoch:25 step:20137[D loss: 0.431196, acc: 54.69%, op_acc: 35.94%] [G loss: 0.772617]\n",
      "epoch:25 step:20138[D loss: 0.428719, acc: 58.59%, op_acc: 38.28%] [G loss: 0.857725]\n",
      "epoch:25 step:20139[D loss: 0.412276, acc: 62.50%, op_acc: 40.62%] [G loss: 0.887006]\n",
      "epoch:25 step:20140[D loss: 0.452995, acc: 50.00%, op_acc: 35.94%] [G loss: 0.831939]\n",
      "epoch:25 step:20141[D loss: 0.424941, acc: 64.84%, op_acc: 39.06%] [G loss: 0.801251]\n",
      "epoch:25 step:20142[D loss: 0.455735, acc: 56.25%, op_acc: 32.81%] [G loss: 0.842558]\n",
      "epoch:25 step:20143[D loss: 0.398104, acc: 63.28%, op_acc: 46.09%] [G loss: 0.845819]\n",
      "epoch:25 step:20144[D loss: 0.432708, acc: 61.72%, op_acc: 36.72%] [G loss: 0.948310]\n",
      "epoch:25 step:20145[D loss: 0.404463, acc: 60.94%, op_acc: 39.84%] [G loss: 0.906570]\n",
      "epoch:25 step:20146[D loss: 0.405063, acc: 68.75%, op_acc: 38.28%] [G loss: 0.875658]\n",
      "epoch:25 step:20147[D loss: 0.461745, acc: 57.03%, op_acc: 34.38%] [G loss: 0.927916]\n",
      "epoch:25 step:20148[D loss: 0.400098, acc: 63.28%, op_acc: 40.62%] [G loss: 0.920875]\n",
      "epoch:25 step:20149[D loss: 0.445552, acc: 48.44%, op_acc: 39.84%] [G loss: 0.916821]\n",
      "epoch:25 step:20150[D loss: 0.436905, acc: 60.94%, op_acc: 41.41%] [G loss: 0.877393]\n",
      "epoch:25 step:20151[D loss: 0.425516, acc: 47.66%, op_acc: 41.41%] [G loss: 0.849090]\n",
      "epoch:25 step:20152[D loss: 0.407951, acc: 59.38%, op_acc: 40.62%] [G loss: 0.966416]\n",
      "epoch:25 step:20153[D loss: 0.414371, acc: 62.50%, op_acc: 39.84%] [G loss: 0.909022]\n",
      "epoch:25 step:20154[D loss: 0.437836, acc: 53.12%, op_acc: 36.72%] [G loss: 0.973984]\n",
      "epoch:25 step:20155[D loss: 0.426039, acc: 55.47%, op_acc: 41.41%] [G loss: 0.921588]\n",
      "epoch:25 step:20156[D loss: 0.428468, acc: 60.94%, op_acc: 35.16%] [G loss: 0.899199]\n",
      "epoch:25 step:20157[D loss: 0.429478, acc: 59.38%, op_acc: 39.06%] [G loss: 0.891068]\n",
      "epoch:25 step:20158[D loss: 0.425402, acc: 62.50%, op_acc: 39.06%] [G loss: 0.937539]\n",
      "epoch:25 step:20159[D loss: 0.429707, acc: 57.03%, op_acc: 36.72%] [G loss: 0.845382]\n",
      "epoch:25 step:20160[D loss: 0.418348, acc: 63.28%, op_acc: 38.28%] [G loss: 0.911969]\n",
      "epoch:25 step:20161[D loss: 0.416909, acc: 54.69%, op_acc: 43.75%] [G loss: 0.946478]\n",
      "epoch:25 step:20162[D loss: 0.420930, acc: 64.06%, op_acc: 40.62%] [G loss: 0.926246]\n",
      "epoch:25 step:20163[D loss: 0.440510, acc: 56.25%, op_acc: 42.19%] [G loss: 0.811761]\n",
      "epoch:25 step:20164[D loss: 0.441089, acc: 53.12%, op_acc: 35.94%] [G loss: 0.931718]\n",
      "epoch:25 step:20165[D loss: 0.444015, acc: 67.19%, op_acc: 37.50%] [G loss: 0.867771]\n",
      "epoch:25 step:20166[D loss: 0.443739, acc: 54.69%, op_acc: 41.41%] [G loss: 0.887790]\n",
      "epoch:25 step:20167[D loss: 0.469839, acc: 54.69%, op_acc: 35.94%] [G loss: 0.876637]\n",
      "epoch:25 step:20168[D loss: 0.461045, acc: 52.34%, op_acc: 33.59%] [G loss: 0.801134]\n",
      "epoch:25 step:20169[D loss: 0.402396, acc: 56.25%, op_acc: 44.53%] [G loss: 0.870445]\n",
      "epoch:25 step:20170[D loss: 0.406217, acc: 64.84%, op_acc: 40.62%] [G loss: 0.863827]\n",
      "epoch:25 step:20171[D loss: 0.458609, acc: 54.69%, op_acc: 35.94%] [G loss: 0.917318]\n",
      "epoch:25 step:20172[D loss: 0.439643, acc: 57.03%, op_acc: 35.94%] [G loss: 0.789401]\n",
      "epoch:25 step:20173[D loss: 0.437736, acc: 56.25%, op_acc: 39.84%] [G loss: 0.911804]\n",
      "epoch:25 step:20174[D loss: 0.430096, acc: 58.59%, op_acc: 36.72%] [G loss: 0.864230]\n",
      "epoch:25 step:20175[D loss: 0.422270, acc: 67.97%, op_acc: 38.28%] [G loss: 0.963988]\n",
      "epoch:25 step:20176[D loss: 0.411451, acc: 59.38%, op_acc: 42.97%] [G loss: 0.896020]\n",
      "epoch:25 step:20177[D loss: 0.448356, acc: 55.47%, op_acc: 35.94%] [G loss: 0.886565]\n",
      "epoch:25 step:20178[D loss: 0.393955, acc: 64.06%, op_acc: 39.06%] [G loss: 0.940504]\n",
      "epoch:25 step:20179[D loss: 0.429584, acc: 53.12%, op_acc: 43.75%] [G loss: 0.839386]\n",
      "epoch:25 step:20180[D loss: 0.415827, acc: 67.19%, op_acc: 49.22%] [G loss: 0.854515]\n",
      "epoch:25 step:20181[D loss: 0.419434, acc: 60.94%, op_acc: 40.62%] [G loss: 0.852643]\n",
      "epoch:25 step:20182[D loss: 0.406889, acc: 64.84%, op_acc: 41.41%] [G loss: 0.894613]\n",
      "epoch:25 step:20183[D loss: 0.422994, acc: 60.94%, op_acc: 39.84%] [G loss: 0.882697]\n",
      "epoch:25 step:20184[D loss: 0.433808, acc: 57.81%, op_acc: 36.72%] [G loss: 0.897201]\n",
      "epoch:25 step:20185[D loss: 0.420295, acc: 59.38%, op_acc: 42.97%] [G loss: 0.844873]\n",
      "epoch:25 step:20186[D loss: 0.434512, acc: 53.12%, op_acc: 46.88%] [G loss: 0.828218]\n",
      "epoch:25 step:20187[D loss: 0.437784, acc: 51.56%, op_acc: 41.41%] [G loss: 0.860334]\n",
      "epoch:25 step:20188[D loss: 0.410144, acc: 61.72%, op_acc: 39.06%] [G loss: 0.850890]\n",
      "epoch:25 step:20189[D loss: 0.430291, acc: 58.59%, op_acc: 36.72%] [G loss: 0.935204]\n",
      "epoch:25 step:20190[D loss: 0.430605, acc: 65.62%, op_acc: 32.81%] [G loss: 0.902168]\n",
      "epoch:25 step:20191[D loss: 0.409961, acc: 59.38%, op_acc: 35.94%] [G loss: 0.933959]\n",
      "epoch:25 step:20192[D loss: 0.420149, acc: 59.38%, op_acc: 38.28%] [G loss: 0.887090]\n",
      "epoch:25 step:20193[D loss: 0.417312, acc: 59.38%, op_acc: 42.19%] [G loss: 0.946081]\n",
      "epoch:25 step:20194[D loss: 0.414019, acc: 62.50%, op_acc: 34.38%] [G loss: 0.906789]\n",
      "epoch:25 step:20195[D loss: 0.412412, acc: 59.38%, op_acc: 37.50%] [G loss: 0.885335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20196[D loss: 0.428496, acc: 60.16%, op_acc: 39.84%] [G loss: 0.829019]\n",
      "epoch:25 step:20197[D loss: 0.457490, acc: 59.38%, op_acc: 39.06%] [G loss: 0.821354]\n",
      "epoch:25 step:20198[D loss: 0.436519, acc: 57.03%, op_acc: 35.94%] [G loss: 0.868029]\n",
      "epoch:25 step:20199[D loss: 0.423411, acc: 59.38%, op_acc: 40.62%] [G loss: 0.889057]\n",
      "epoch:25 step:20200[D loss: 0.422320, acc: 60.16%, op_acc: 37.50%] [G loss: 0.861657]\n",
      "epoch:25 step:20201[D loss: 0.467647, acc: 49.22%, op_acc: 35.16%] [G loss: 0.822471]\n",
      "epoch:25 step:20202[D loss: 0.449618, acc: 57.03%, op_acc: 33.59%] [G loss: 0.890499]\n",
      "epoch:25 step:20203[D loss: 0.405545, acc: 60.94%, op_acc: 42.19%] [G loss: 0.819736]\n",
      "epoch:25 step:20204[D loss: 0.408304, acc: 60.94%, op_acc: 43.75%] [G loss: 0.896547]\n",
      "epoch:25 step:20205[D loss: 0.401901, acc: 67.19%, op_acc: 38.28%] [G loss: 0.957466]\n",
      "epoch:25 step:20206[D loss: 0.456270, acc: 57.03%, op_acc: 37.50%] [G loss: 0.870416]\n",
      "epoch:25 step:20207[D loss: 0.420110, acc: 63.28%, op_acc: 39.84%] [G loss: 0.853835]\n",
      "epoch:25 step:20208[D loss: 0.429166, acc: 60.16%, op_acc: 37.50%] [G loss: 0.887331]\n",
      "epoch:25 step:20209[D loss: 0.413023, acc: 58.59%, op_acc: 42.97%] [G loss: 0.916020]\n",
      "epoch:25 step:20210[D loss: 0.432346, acc: 57.81%, op_acc: 38.28%] [G loss: 0.891716]\n",
      "epoch:25 step:20211[D loss: 0.430784, acc: 58.59%, op_acc: 37.50%] [G loss: 0.917485]\n",
      "epoch:25 step:20212[D loss: 0.406113, acc: 68.75%, op_acc: 39.06%] [G loss: 0.838915]\n",
      "epoch:25 step:20213[D loss: 0.427271, acc: 57.03%, op_acc: 39.84%] [G loss: 0.886126]\n",
      "epoch:25 step:20214[D loss: 0.417868, acc: 57.03%, op_acc: 37.50%] [G loss: 0.831683]\n",
      "epoch:25 step:20215[D loss: 0.421940, acc: 64.06%, op_acc: 37.50%] [G loss: 0.896441]\n",
      "epoch:25 step:20216[D loss: 0.405298, acc: 60.94%, op_acc: 42.19%] [G loss: 0.824834]\n",
      "epoch:25 step:20217[D loss: 0.424570, acc: 63.28%, op_acc: 35.94%] [G loss: 0.815308]\n",
      "epoch:25 step:20218[D loss: 0.432451, acc: 58.59%, op_acc: 40.62%] [G loss: 0.937508]\n",
      "epoch:25 step:20219[D loss: 0.412207, acc: 62.50%, op_acc: 41.41%] [G loss: 0.885098]\n",
      "epoch:25 step:20220[D loss: 0.406957, acc: 64.84%, op_acc: 33.59%] [G loss: 0.927564]\n",
      "epoch:25 step:20221[D loss: 0.449494, acc: 54.69%, op_acc: 41.41%] [G loss: 0.809192]\n",
      "epoch:25 step:20222[D loss: 0.396058, acc: 66.41%, op_acc: 43.75%] [G loss: 0.978496]\n",
      "epoch:25 step:20223[D loss: 0.410426, acc: 60.94%, op_acc: 39.84%] [G loss: 0.939605]\n",
      "epoch:25 step:20224[D loss: 0.381278, acc: 65.62%, op_acc: 40.62%] [G loss: 0.856117]\n",
      "epoch:25 step:20225[D loss: 0.438948, acc: 60.16%, op_acc: 37.50%] [G loss: 0.758441]\n",
      "epoch:25 step:20226[D loss: 0.426519, acc: 62.50%, op_acc: 42.97%] [G loss: 0.878504]\n",
      "epoch:25 step:20227[D loss: 0.461525, acc: 47.66%, op_acc: 37.50%] [G loss: 0.838718]\n",
      "epoch:25 step:20228[D loss: 0.422026, acc: 57.03%, op_acc: 39.06%] [G loss: 0.860540]\n",
      "epoch:25 step:20229[D loss: 0.393494, acc: 61.72%, op_acc: 44.53%] [G loss: 0.818661]\n",
      "epoch:25 step:20230[D loss: 0.443336, acc: 61.72%, op_acc: 32.81%] [G loss: 0.914011]\n",
      "epoch:25 step:20231[D loss: 0.429478, acc: 53.91%, op_acc: 42.19%] [G loss: 0.893378]\n",
      "epoch:25 step:20232[D loss: 0.427719, acc: 60.94%, op_acc: 42.19%] [G loss: 0.999429]\n",
      "epoch:25 step:20233[D loss: 0.434336, acc: 59.38%, op_acc: 42.97%] [G loss: 0.863858]\n",
      "epoch:25 step:20234[D loss: 0.409033, acc: 63.28%, op_acc: 43.75%] [G loss: 0.824285]\n",
      "epoch:25 step:20235[D loss: 0.369034, acc: 69.53%, op_acc: 43.75%] [G loss: 0.878900]\n",
      "epoch:25 step:20236[D loss: 0.407544, acc: 64.06%, op_acc: 35.16%] [G loss: 0.904682]\n",
      "epoch:25 step:20237[D loss: 0.390479, acc: 65.62%, op_acc: 45.31%] [G loss: 0.938062]\n",
      "epoch:25 step:20238[D loss: 0.425136, acc: 60.94%, op_acc: 42.97%] [G loss: 0.869954]\n",
      "epoch:25 step:20239[D loss: 0.448744, acc: 54.69%, op_acc: 35.94%] [G loss: 0.909750]\n",
      "epoch:25 step:20240[D loss: 0.382311, acc: 71.09%, op_acc: 40.62%] [G loss: 0.945177]\n",
      "epoch:25 step:20241[D loss: 0.432306, acc: 53.91%, op_acc: 39.84%] [G loss: 0.897296]\n",
      "epoch:25 step:20242[D loss: 0.415946, acc: 55.47%, op_acc: 43.75%] [G loss: 0.891817]\n",
      "epoch:25 step:20243[D loss: 0.420126, acc: 57.81%, op_acc: 38.28%] [G loss: 0.838424]\n",
      "epoch:25 step:20244[D loss: 0.422468, acc: 61.72%, op_acc: 42.97%] [G loss: 0.872934]\n",
      "epoch:25 step:20245[D loss: 0.432374, acc: 60.16%, op_acc: 38.28%] [G loss: 0.897867]\n",
      "epoch:25 step:20246[D loss: 0.418737, acc: 54.69%, op_acc: 39.06%] [G loss: 0.883208]\n",
      "epoch:25 step:20247[D loss: 0.407935, acc: 64.84%, op_acc: 38.28%] [G loss: 0.810820]\n",
      "epoch:25 step:20248[D loss: 0.411119, acc: 60.16%, op_acc: 41.41%] [G loss: 0.929772]\n",
      "epoch:25 step:20249[D loss: 0.429217, acc: 62.50%, op_acc: 37.50%] [G loss: 0.904141]\n",
      "epoch:25 step:20250[D loss: 0.442165, acc: 58.59%, op_acc: 39.84%] [G loss: 0.838531]\n",
      "epoch:25 step:20251[D loss: 0.427865, acc: 60.16%, op_acc: 42.97%] [G loss: 0.817373]\n",
      "epoch:25 step:20252[D loss: 0.425101, acc: 64.84%, op_acc: 35.16%] [G loss: 0.860388]\n",
      "epoch:25 step:20253[D loss: 0.421088, acc: 64.06%, op_acc: 40.62%] [G loss: 0.926200]\n",
      "epoch:25 step:20254[D loss: 0.388819, acc: 68.75%, op_acc: 38.28%] [G loss: 0.866286]\n",
      "epoch:25 step:20255[D loss: 0.412816, acc: 59.38%, op_acc: 42.19%] [G loss: 0.854616]\n",
      "epoch:25 step:20256[D loss: 0.393895, acc: 65.62%, op_acc: 42.97%] [G loss: 0.884409]\n",
      "epoch:25 step:20257[D loss: 0.436783, acc: 57.81%, op_acc: 35.94%] [G loss: 1.002854]\n",
      "epoch:25 step:20258[D loss: 0.427525, acc: 60.94%, op_acc: 36.72%] [G loss: 0.857434]\n",
      "epoch:25 step:20259[D loss: 0.430356, acc: 54.69%, op_acc: 36.72%] [G loss: 0.866381]\n",
      "epoch:25 step:20260[D loss: 0.412951, acc: 60.94%, op_acc: 39.84%] [G loss: 0.897251]\n",
      "epoch:25 step:20261[D loss: 0.426640, acc: 60.94%, op_acc: 37.50%] [G loss: 0.944100]\n",
      "epoch:25 step:20262[D loss: 0.392823, acc: 66.41%, op_acc: 45.31%] [G loss: 0.845175]\n",
      "epoch:25 step:20263[D loss: 0.398234, acc: 62.50%, op_acc: 38.28%] [G loss: 0.937706]\n",
      "epoch:25 step:20264[D loss: 0.415892, acc: 57.81%, op_acc: 43.75%] [G loss: 0.905576]\n",
      "epoch:25 step:20265[D loss: 0.415790, acc: 60.94%, op_acc: 42.97%] [G loss: 0.934742]\n",
      "epoch:25 step:20266[D loss: 0.415571, acc: 63.28%, op_acc: 39.84%] [G loss: 0.924530]\n",
      "epoch:25 step:20267[D loss: 0.426114, acc: 52.34%, op_acc: 42.19%] [G loss: 0.824401]\n",
      "epoch:25 step:20268[D loss: 0.425763, acc: 61.72%, op_acc: 39.84%] [G loss: 0.832213]\n",
      "epoch:25 step:20269[D loss: 0.404993, acc: 57.03%, op_acc: 45.31%] [G loss: 0.795194]\n",
      "epoch:25 step:20270[D loss: 0.427303, acc: 53.12%, op_acc: 39.06%] [G loss: 0.836874]\n",
      "epoch:25 step:20271[D loss: 0.443410, acc: 59.38%, op_acc: 39.84%] [G loss: 0.924279]\n",
      "epoch:25 step:20272[D loss: 0.434698, acc: 51.56%, op_acc: 42.19%] [G loss: 0.828536]\n",
      "epoch:25 step:20273[D loss: 0.416154, acc: 64.84%, op_acc: 38.28%] [G loss: 0.932727]\n",
      "epoch:25 step:20274[D loss: 0.444650, acc: 56.25%, op_acc: 40.62%] [G loss: 0.839501]\n",
      "epoch:25 step:20275[D loss: 0.439237, acc: 53.91%, op_acc: 35.94%] [G loss: 1.007304]\n",
      "epoch:25 step:20276[D loss: 0.450224, acc: 62.50%, op_acc: 31.25%] [G loss: 0.843840]\n",
      "epoch:25 step:20277[D loss: 0.446425, acc: 52.34%, op_acc: 37.50%] [G loss: 0.918098]\n",
      "epoch:25 step:20278[D loss: 0.424081, acc: 53.91%, op_acc: 40.62%] [G loss: 0.984652]\n",
      "epoch:25 step:20279[D loss: 0.427179, acc: 57.03%, op_acc: 39.84%] [G loss: 0.860529]\n",
      "epoch:25 step:20280[D loss: 0.397848, acc: 64.84%, op_acc: 42.97%] [G loss: 0.905115]\n",
      "epoch:25 step:20281[D loss: 0.403360, acc: 57.81%, op_acc: 45.31%] [G loss: 0.942409]\n",
      "epoch:25 step:20282[D loss: 0.436214, acc: 53.12%, op_acc: 42.97%] [G loss: 0.815072]\n",
      "epoch:25 step:20283[D loss: 0.380357, acc: 64.84%, op_acc: 42.97%] [G loss: 0.847022]\n",
      "epoch:25 step:20284[D loss: 0.409210, acc: 62.50%, op_acc: 42.97%] [G loss: 0.987704]\n",
      "epoch:25 step:20285[D loss: 0.397393, acc: 60.16%, op_acc: 46.09%] [G loss: 0.908583]\n",
      "epoch:25 step:20286[D loss: 0.378838, acc: 66.41%, op_acc: 46.09%] [G loss: 0.934247]\n",
      "epoch:25 step:20287[D loss: 0.458813, acc: 45.31%, op_acc: 38.28%] [G loss: 0.853429]\n",
      "epoch:25 step:20288[D loss: 0.443237, acc: 53.91%, op_acc: 35.94%] [G loss: 0.826750]\n",
      "epoch:25 step:20289[D loss: 0.407361, acc: 59.38%, op_acc: 35.94%] [G loss: 0.936171]\n",
      "epoch:25 step:20290[D loss: 0.391097, acc: 68.75%, op_acc: 46.09%] [G loss: 0.882528]\n",
      "epoch:25 step:20291[D loss: 0.445117, acc: 57.03%, op_acc: 36.72%] [G loss: 0.844584]\n",
      "epoch:25 step:20292[D loss: 0.421582, acc: 63.28%, op_acc: 39.84%] [G loss: 0.930205]\n",
      "epoch:25 step:20293[D loss: 0.415713, acc: 62.50%, op_acc: 39.06%] [G loss: 0.814876]\n",
      "epoch:25 step:20294[D loss: 0.420218, acc: 56.25%, op_acc: 43.75%] [G loss: 0.774953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:20295[D loss: 0.429516, acc: 53.12%, op_acc: 40.62%] [G loss: 0.870692]\n",
      "epoch:25 step:20296[D loss: 0.479171, acc: 49.22%, op_acc: 35.94%] [G loss: 0.850997]\n",
      "epoch:25 step:20297[D loss: 0.446861, acc: 54.69%, op_acc: 39.84%] [G loss: 0.859456]\n",
      "epoch:25 step:20298[D loss: 0.410795, acc: 67.97%, op_acc: 37.50%] [G loss: 0.873250]\n",
      "epoch:25 step:20299[D loss: 0.398566, acc: 60.94%, op_acc: 41.41%] [G loss: 0.966411]\n",
      "epoch:25 step:20300[D loss: 0.431446, acc: 59.38%, op_acc: 43.75%] [G loss: 0.881409]\n",
      "epoch:25 step:20301[D loss: 0.442463, acc: 53.12%, op_acc: 38.28%] [G loss: 0.823676]\n",
      "epoch:25 step:20302[D loss: 0.427600, acc: 64.06%, op_acc: 37.50%] [G loss: 0.857162]\n",
      "epoch:25 step:20303[D loss: 0.454976, acc: 51.56%, op_acc: 41.41%] [G loss: 0.823112]\n",
      "epoch:25 step:20304[D loss: 0.427305, acc: 56.25%, op_acc: 42.97%] [G loss: 0.886957]\n",
      "epoch:25 step:20305[D loss: 0.396134, acc: 64.06%, op_acc: 42.19%] [G loss: 0.921413]\n",
      "epoch:25 step:20306[D loss: 0.451369, acc: 53.91%, op_acc: 38.28%] [G loss: 0.841618]\n",
      "epoch:26 step:20307[D loss: 0.419869, acc: 60.16%, op_acc: 41.41%] [G loss: 0.821911]\n",
      "epoch:26 step:20308[D loss: 0.404272, acc: 60.94%, op_acc: 38.28%] [G loss: 0.921770]\n",
      "epoch:26 step:20309[D loss: 0.423274, acc: 57.03%, op_acc: 42.19%] [G loss: 0.835814]\n",
      "epoch:26 step:20310[D loss: 0.415515, acc: 60.16%, op_acc: 45.31%] [G loss: 0.882228]\n",
      "epoch:26 step:20311[D loss: 0.383695, acc: 70.31%, op_acc: 44.53%] [G loss: 0.957332]\n",
      "epoch:26 step:20312[D loss: 0.428589, acc: 60.94%, op_acc: 39.06%] [G loss: 0.911168]\n",
      "epoch:26 step:20313[D loss: 0.428471, acc: 57.81%, op_acc: 41.41%] [G loss: 0.887648]\n",
      "epoch:26 step:20314[D loss: 0.444488, acc: 53.12%, op_acc: 31.25%] [G loss: 0.823851]\n",
      "epoch:26 step:20315[D loss: 0.384447, acc: 64.84%, op_acc: 43.75%] [G loss: 0.858956]\n",
      "epoch:26 step:20316[D loss: 0.443403, acc: 49.22%, op_acc: 39.06%] [G loss: 0.836487]\n",
      "epoch:26 step:20317[D loss: 0.435988, acc: 55.47%, op_acc: 40.62%] [G loss: 0.873876]\n",
      "epoch:26 step:20318[D loss: 0.391832, acc: 65.62%, op_acc: 35.94%] [G loss: 0.876945]\n",
      "epoch:26 step:20319[D loss: 0.385597, acc: 64.84%, op_acc: 38.28%] [G loss: 0.951432]\n",
      "epoch:26 step:20320[D loss: 0.424038, acc: 60.94%, op_acc: 35.16%] [G loss: 0.902676]\n",
      "epoch:26 step:20321[D loss: 0.387334, acc: 66.41%, op_acc: 42.19%] [G loss: 0.865384]\n",
      "epoch:26 step:20322[D loss: 0.420270, acc: 53.91%, op_acc: 39.84%] [G loss: 0.885296]\n",
      "epoch:26 step:20323[D loss: 0.410170, acc: 64.84%, op_acc: 39.84%] [G loss: 0.875662]\n",
      "epoch:26 step:20324[D loss: 0.402236, acc: 60.94%, op_acc: 39.84%] [G loss: 0.920957]\n",
      "epoch:26 step:20325[D loss: 0.408503, acc: 58.59%, op_acc: 39.06%] [G loss: 0.894860]\n",
      "epoch:26 step:20326[D loss: 0.427144, acc: 50.00%, op_acc: 42.19%] [G loss: 0.855963]\n",
      "epoch:26 step:20327[D loss: 0.425838, acc: 57.81%, op_acc: 38.28%] [G loss: 0.913013]\n",
      "epoch:26 step:20328[D loss: 0.427207, acc: 56.25%, op_acc: 38.28%] [G loss: 0.877184]\n",
      "epoch:26 step:20329[D loss: 0.391697, acc: 64.06%, op_acc: 42.97%] [G loss: 0.792557]\n",
      "epoch:26 step:20330[D loss: 0.438205, acc: 55.47%, op_acc: 31.25%] [G loss: 0.867584]\n",
      "epoch:26 step:20331[D loss: 0.482277, acc: 46.88%, op_acc: 31.25%] [G loss: 0.920712]\n",
      "epoch:26 step:20332[D loss: 0.422526, acc: 59.38%, op_acc: 42.19%] [G loss: 0.821236]\n",
      "epoch:26 step:20333[D loss: 0.415703, acc: 57.03%, op_acc: 37.50%] [G loss: 0.857854]\n",
      "epoch:26 step:20334[D loss: 0.431564, acc: 58.59%, op_acc: 43.75%] [G loss: 0.907599]\n",
      "epoch:26 step:20335[D loss: 0.403495, acc: 65.62%, op_acc: 42.97%] [G loss: 0.970384]\n",
      "epoch:26 step:20336[D loss: 0.410493, acc: 55.47%, op_acc: 41.41%] [G loss: 0.915845]\n",
      "epoch:26 step:20337[D loss: 0.447402, acc: 55.47%, op_acc: 37.50%] [G loss: 0.877476]\n",
      "epoch:26 step:20338[D loss: 0.445401, acc: 57.81%, op_acc: 38.28%] [G loss: 0.893367]\n",
      "epoch:26 step:20339[D loss: 0.409287, acc: 63.28%, op_acc: 47.66%] [G loss: 0.881101]\n",
      "epoch:26 step:20340[D loss: 0.398608, acc: 63.28%, op_acc: 46.09%] [G loss: 0.854041]\n",
      "epoch:26 step:20341[D loss: 0.435963, acc: 60.16%, op_acc: 32.03%] [G loss: 0.915484]\n",
      "epoch:26 step:20342[D loss: 0.383261, acc: 66.41%, op_acc: 42.19%] [G loss: 0.859591]\n",
      "epoch:26 step:20343[D loss: 0.436958, acc: 58.59%, op_acc: 33.59%] [G loss: 0.843750]\n",
      "epoch:26 step:20344[D loss: 0.441521, acc: 48.44%, op_acc: 37.50%] [G loss: 0.911870]\n",
      "epoch:26 step:20345[D loss: 0.385472, acc: 64.84%, op_acc: 44.53%] [G loss: 0.907230]\n",
      "epoch:26 step:20346[D loss: 0.455083, acc: 57.81%, op_acc: 33.59%] [G loss: 0.868668]\n",
      "epoch:26 step:20347[D loss: 0.405361, acc: 64.06%, op_acc: 42.97%] [G loss: 0.857019]\n",
      "epoch:26 step:20348[D loss: 0.410753, acc: 57.81%, op_acc: 47.66%] [G loss: 0.870097]\n",
      "epoch:26 step:20349[D loss: 0.410385, acc: 64.06%, op_acc: 39.06%] [G loss: 0.953315]\n",
      "epoch:26 step:20350[D loss: 0.438376, acc: 49.22%, op_acc: 41.41%] [G loss: 0.886216]\n",
      "epoch:26 step:20351[D loss: 0.393795, acc: 65.62%, op_acc: 39.06%] [G loss: 0.867565]\n",
      "epoch:26 step:20352[D loss: 0.421853, acc: 59.38%, op_acc: 35.94%] [G loss: 0.825636]\n",
      "epoch:26 step:20353[D loss: 0.443973, acc: 54.69%, op_acc: 41.41%] [G loss: 0.865839]\n",
      "epoch:26 step:20354[D loss: 0.466682, acc: 53.91%, op_acc: 39.84%] [G loss: 0.875321]\n",
      "epoch:26 step:20355[D loss: 0.429318, acc: 57.81%, op_acc: 35.16%] [G loss: 0.827423]\n",
      "epoch:26 step:20356[D loss: 0.420815, acc: 58.59%, op_acc: 38.28%] [G loss: 0.888128]\n",
      "epoch:26 step:20357[D loss: 0.397299, acc: 65.62%, op_acc: 42.19%] [G loss: 0.918406]\n",
      "epoch:26 step:20358[D loss: 0.412946, acc: 67.97%, op_acc: 39.84%] [G loss: 0.844373]\n",
      "epoch:26 step:20359[D loss: 0.457869, acc: 56.25%, op_acc: 35.16%] [G loss: 0.865941]\n",
      "epoch:26 step:20360[D loss: 0.449067, acc: 57.03%, op_acc: 37.50%] [G loss: 0.868535]\n",
      "epoch:26 step:20361[D loss: 0.408719, acc: 66.41%, op_acc: 35.94%] [G loss: 0.962728]\n",
      "epoch:26 step:20362[D loss: 0.435957, acc: 60.94%, op_acc: 38.28%] [G loss: 0.915674]\n",
      "epoch:26 step:20363[D loss: 0.409898, acc: 64.84%, op_acc: 39.84%] [G loss: 0.905900]\n",
      "epoch:26 step:20364[D loss: 0.443166, acc: 51.56%, op_acc: 37.50%] [G loss: 0.925586]\n",
      "epoch:26 step:20365[D loss: 0.412093, acc: 59.38%, op_acc: 42.97%] [G loss: 0.947799]\n",
      "epoch:26 step:20366[D loss: 0.435085, acc: 57.03%, op_acc: 35.94%] [G loss: 0.887102]\n",
      "epoch:26 step:20367[D loss: 0.410944, acc: 64.84%, op_acc: 42.19%] [G loss: 0.884571]\n",
      "epoch:26 step:20368[D loss: 0.433770, acc: 60.16%, op_acc: 35.16%] [G loss: 0.870260]\n",
      "epoch:26 step:20369[D loss: 0.465200, acc: 49.22%, op_acc: 35.94%] [G loss: 0.835931]\n",
      "epoch:26 step:20370[D loss: 0.402395, acc: 60.16%, op_acc: 45.31%] [G loss: 0.870797]\n",
      "epoch:26 step:20371[D loss: 0.443682, acc: 55.47%, op_acc: 37.50%] [G loss: 0.874045]\n",
      "epoch:26 step:20372[D loss: 0.425800, acc: 56.25%, op_acc: 39.84%] [G loss: 0.847471]\n",
      "epoch:26 step:20373[D loss: 0.387659, acc: 63.28%, op_acc: 42.19%] [G loss: 0.893372]\n",
      "epoch:26 step:20374[D loss: 0.412771, acc: 60.94%, op_acc: 46.09%] [G loss: 0.898992]\n",
      "epoch:26 step:20375[D loss: 0.379616, acc: 68.75%, op_acc: 45.31%] [G loss: 0.843145]\n",
      "epoch:26 step:20376[D loss: 0.456350, acc: 50.00%, op_acc: 39.84%] [G loss: 0.827529]\n",
      "epoch:26 step:20377[D loss: 0.463472, acc: 51.56%, op_acc: 32.81%] [G loss: 0.787927]\n",
      "epoch:26 step:20378[D loss: 0.412010, acc: 60.16%, op_acc: 39.06%] [G loss: 0.856767]\n",
      "epoch:26 step:20379[D loss: 0.451060, acc: 53.91%, op_acc: 35.94%] [G loss: 0.823147]\n",
      "epoch:26 step:20380[D loss: 0.429542, acc: 51.56%, op_acc: 39.06%] [G loss: 0.817071]\n",
      "epoch:26 step:20381[D loss: 0.401994, acc: 64.84%, op_acc: 43.75%] [G loss: 0.937043]\n",
      "epoch:26 step:20382[D loss: 0.411231, acc: 66.41%, op_acc: 40.62%] [G loss: 0.894250]\n",
      "epoch:26 step:20383[D loss: 0.444899, acc: 60.16%, op_acc: 39.84%] [G loss: 0.808879]\n",
      "epoch:26 step:20384[D loss: 0.465681, acc: 50.78%, op_acc: 28.12%] [G loss: 0.876150]\n",
      "epoch:26 step:20385[D loss: 0.420929, acc: 57.81%, op_acc: 38.28%] [G loss: 0.920201]\n",
      "epoch:26 step:20386[D loss: 0.440063, acc: 61.72%, op_acc: 34.38%] [G loss: 0.851774]\n",
      "epoch:26 step:20387[D loss: 0.432800, acc: 60.94%, op_acc: 37.50%] [G loss: 0.876213]\n",
      "epoch:26 step:20388[D loss: 0.419226, acc: 57.81%, op_acc: 39.84%] [G loss: 0.852476]\n",
      "epoch:26 step:20389[D loss: 0.387915, acc: 62.50%, op_acc: 41.41%] [G loss: 0.887295]\n",
      "epoch:26 step:20390[D loss: 0.417351, acc: 66.41%, op_acc: 40.62%] [G loss: 0.968047]\n",
      "epoch:26 step:20391[D loss: 0.434107, acc: 64.06%, op_acc: 35.94%] [G loss: 0.934750]\n",
      "epoch:26 step:20392[D loss: 0.405046, acc: 64.84%, op_acc: 45.31%] [G loss: 0.926333]\n",
      "epoch:26 step:20393[D loss: 0.404364, acc: 62.50%, op_acc: 43.75%] [G loss: 0.984212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20394[D loss: 0.418876, acc: 61.72%, op_acc: 39.84%] [G loss: 0.889508]\n",
      "epoch:26 step:20395[D loss: 0.412272, acc: 63.28%, op_acc: 36.72%] [G loss: 0.870370]\n",
      "epoch:26 step:20396[D loss: 0.409079, acc: 58.59%, op_acc: 44.53%] [G loss: 0.830913]\n",
      "epoch:26 step:20397[D loss: 0.427296, acc: 57.81%, op_acc: 41.41%] [G loss: 0.901776]\n",
      "epoch:26 step:20398[D loss: 0.415113, acc: 64.84%, op_acc: 40.62%] [G loss: 0.884041]\n",
      "epoch:26 step:20399[D loss: 0.418410, acc: 57.81%, op_acc: 39.06%] [G loss: 0.984051]\n",
      "epoch:26 step:20400[D loss: 0.403738, acc: 60.94%, op_acc: 41.41%] [G loss: 0.911579]\n",
      "epoch:26 step:20401[D loss: 0.400836, acc: 62.50%, op_acc: 43.75%] [G loss: 0.984788]\n",
      "epoch:26 step:20402[D loss: 0.419401, acc: 60.94%, op_acc: 39.84%] [G loss: 0.990710]\n",
      "epoch:26 step:20403[D loss: 0.413842, acc: 57.81%, op_acc: 46.09%] [G loss: 0.845556]\n",
      "epoch:26 step:20404[D loss: 0.413979, acc: 64.06%, op_acc: 37.50%] [G loss: 0.989041]\n",
      "epoch:26 step:20405[D loss: 0.404460, acc: 62.50%, op_acc: 39.06%] [G loss: 0.886464]\n",
      "epoch:26 step:20406[D loss: 0.407404, acc: 61.72%, op_acc: 39.84%] [G loss: 0.838489]\n",
      "epoch:26 step:20407[D loss: 0.415416, acc: 67.97%, op_acc: 35.94%] [G loss: 0.883426]\n",
      "epoch:26 step:20408[D loss: 0.449912, acc: 51.56%, op_acc: 38.28%] [G loss: 0.901090]\n",
      "epoch:26 step:20409[D loss: 0.429949, acc: 57.03%, op_acc: 40.62%] [G loss: 0.894804]\n",
      "epoch:26 step:20410[D loss: 0.423274, acc: 57.81%, op_acc: 40.62%] [G loss: 0.836474]\n",
      "epoch:26 step:20411[D loss: 0.447963, acc: 53.91%, op_acc: 39.06%] [G loss: 0.920336]\n",
      "epoch:26 step:20412[D loss: 0.378813, acc: 65.62%, op_acc: 45.31%] [G loss: 0.932755]\n",
      "epoch:26 step:20413[D loss: 0.425096, acc: 64.06%, op_acc: 42.19%] [G loss: 0.842846]\n",
      "epoch:26 step:20414[D loss: 0.417181, acc: 66.41%, op_acc: 41.41%] [G loss: 0.944513]\n",
      "epoch:26 step:20415[D loss: 0.400808, acc: 66.41%, op_acc: 36.72%] [G loss: 0.934494]\n",
      "epoch:26 step:20416[D loss: 0.429403, acc: 55.47%, op_acc: 40.62%] [G loss: 0.792396]\n",
      "epoch:26 step:20417[D loss: 0.425679, acc: 60.94%, op_acc: 39.84%] [G loss: 0.969592]\n",
      "epoch:26 step:20418[D loss: 0.398045, acc: 63.28%, op_acc: 39.84%] [G loss: 0.848580]\n",
      "epoch:26 step:20419[D loss: 0.411766, acc: 65.62%, op_acc: 37.50%] [G loss: 0.894052]\n",
      "epoch:26 step:20420[D loss: 0.420585, acc: 56.25%, op_acc: 44.53%] [G loss: 0.946170]\n",
      "epoch:26 step:20421[D loss: 0.409660, acc: 57.81%, op_acc: 42.97%] [G loss: 0.944802]\n",
      "epoch:26 step:20422[D loss: 0.445773, acc: 59.38%, op_acc: 40.62%] [G loss: 0.940768]\n",
      "epoch:26 step:20423[D loss: 0.440519, acc: 53.91%, op_acc: 39.06%] [G loss: 0.895999]\n",
      "epoch:26 step:20424[D loss: 0.423605, acc: 56.25%, op_acc: 43.75%] [G loss: 0.827070]\n",
      "epoch:26 step:20425[D loss: 0.442034, acc: 60.16%, op_acc: 39.84%] [G loss: 0.865444]\n",
      "epoch:26 step:20426[D loss: 0.430436, acc: 63.28%, op_acc: 35.94%] [G loss: 0.765071]\n",
      "epoch:26 step:20427[D loss: 0.442889, acc: 58.59%, op_acc: 40.62%] [G loss: 0.870431]\n",
      "epoch:26 step:20428[D loss: 0.413090, acc: 58.59%, op_acc: 38.28%] [G loss: 0.888892]\n",
      "epoch:26 step:20429[D loss: 0.462159, acc: 50.78%, op_acc: 32.81%] [G loss: 0.867913]\n",
      "epoch:26 step:20430[D loss: 0.430030, acc: 57.03%, op_acc: 38.28%] [G loss: 0.869778]\n",
      "epoch:26 step:20431[D loss: 0.439024, acc: 58.59%, op_acc: 34.38%] [G loss: 0.837894]\n",
      "epoch:26 step:20432[D loss: 0.401838, acc: 69.53%, op_acc: 38.28%] [G loss: 0.781845]\n",
      "epoch:26 step:20433[D loss: 0.431183, acc: 63.28%, op_acc: 35.16%] [G loss: 0.894357]\n",
      "epoch:26 step:20434[D loss: 0.409686, acc: 57.81%, op_acc: 40.62%] [G loss: 0.931384]\n",
      "epoch:26 step:20435[D loss: 0.441094, acc: 58.59%, op_acc: 34.38%] [G loss: 0.866491]\n",
      "epoch:26 step:20436[D loss: 0.409712, acc: 61.72%, op_acc: 39.06%] [G loss: 0.831447]\n",
      "epoch:26 step:20437[D loss: 0.424593, acc: 61.72%, op_acc: 37.50%] [G loss: 0.933108]\n",
      "epoch:26 step:20438[D loss: 0.394003, acc: 65.62%, op_acc: 45.31%] [G loss: 0.892722]\n",
      "epoch:26 step:20439[D loss: 0.437270, acc: 65.62%, op_acc: 34.38%] [G loss: 0.777017]\n",
      "epoch:26 step:20440[D loss: 0.414628, acc: 66.41%, op_acc: 39.84%] [G loss: 0.819818]\n",
      "epoch:26 step:20441[D loss: 0.419427, acc: 62.50%, op_acc: 39.84%] [G loss: 0.889456]\n",
      "epoch:26 step:20442[D loss: 0.395669, acc: 67.97%, op_acc: 42.97%] [G loss: 0.908556]\n",
      "epoch:26 step:20443[D loss: 0.450074, acc: 52.34%, op_acc: 36.72%] [G loss: 0.854335]\n",
      "epoch:26 step:20444[D loss: 0.458925, acc: 53.91%, op_acc: 35.16%] [G loss: 0.783684]\n",
      "epoch:26 step:20445[D loss: 0.402839, acc: 61.72%, op_acc: 39.06%] [G loss: 0.877072]\n",
      "epoch:26 step:20446[D loss: 0.463822, acc: 52.34%, op_acc: 35.94%] [G loss: 0.898654]\n",
      "epoch:26 step:20447[D loss: 0.432590, acc: 57.03%, op_acc: 34.38%] [G loss: 0.854804]\n",
      "epoch:26 step:20448[D loss: 0.418765, acc: 59.38%, op_acc: 36.72%] [G loss: 0.916651]\n",
      "epoch:26 step:20449[D loss: 0.399887, acc: 59.38%, op_acc: 39.84%] [G loss: 0.858509]\n",
      "epoch:26 step:20450[D loss: 0.411561, acc: 60.16%, op_acc: 42.19%] [G loss: 0.991874]\n",
      "epoch:26 step:20451[D loss: 0.428011, acc: 57.81%, op_acc: 44.53%] [G loss: 0.856986]\n",
      "epoch:26 step:20452[D loss: 0.401581, acc: 64.84%, op_acc: 42.97%] [G loss: 0.834808]\n",
      "epoch:26 step:20453[D loss: 0.405213, acc: 60.16%, op_acc: 41.41%] [G loss: 0.837810]\n",
      "epoch:26 step:20454[D loss: 0.439239, acc: 56.25%, op_acc: 38.28%] [G loss: 0.823848]\n",
      "epoch:26 step:20455[D loss: 0.403656, acc: 62.50%, op_acc: 45.31%] [G loss: 0.886502]\n",
      "epoch:26 step:20456[D loss: 0.401575, acc: 64.06%, op_acc: 43.75%] [G loss: 0.896318]\n",
      "epoch:26 step:20457[D loss: 0.408860, acc: 57.03%, op_acc: 40.62%] [G loss: 0.879369]\n",
      "epoch:26 step:20458[D loss: 0.389060, acc: 63.28%, op_acc: 43.75%] [G loss: 0.921750]\n",
      "epoch:26 step:20459[D loss: 0.410838, acc: 65.62%, op_acc: 39.06%] [G loss: 0.861261]\n",
      "epoch:26 step:20460[D loss: 0.404645, acc: 68.75%, op_acc: 39.06%] [G loss: 0.940985]\n",
      "epoch:26 step:20461[D loss: 0.424346, acc: 60.16%, op_acc: 35.94%] [G loss: 0.747538]\n",
      "epoch:26 step:20462[D loss: 0.405749, acc: 61.72%, op_acc: 39.06%] [G loss: 0.875328]\n",
      "epoch:26 step:20463[D loss: 0.416944, acc: 60.94%, op_acc: 42.97%] [G loss: 0.942341]\n",
      "epoch:26 step:20464[D loss: 0.392963, acc: 59.38%, op_acc: 44.53%] [G loss: 0.754904]\n",
      "epoch:26 step:20465[D loss: 0.429560, acc: 57.81%, op_acc: 39.84%] [G loss: 0.879216]\n",
      "epoch:26 step:20466[D loss: 0.439022, acc: 52.34%, op_acc: 35.16%] [G loss: 0.986303]\n",
      "epoch:26 step:20467[D loss: 0.434866, acc: 59.38%, op_acc: 38.28%] [G loss: 0.853246]\n",
      "epoch:26 step:20468[D loss: 0.411963, acc: 53.91%, op_acc: 44.53%] [G loss: 0.938325]\n",
      "epoch:26 step:20469[D loss: 0.429242, acc: 60.94%, op_acc: 36.72%] [G loss: 0.893516]\n",
      "epoch:26 step:20470[D loss: 0.437249, acc: 65.62%, op_acc: 30.47%] [G loss: 0.862874]\n",
      "epoch:26 step:20471[D loss: 0.446934, acc: 52.34%, op_acc: 38.28%] [G loss: 0.947859]\n",
      "epoch:26 step:20472[D loss: 0.423654, acc: 55.47%, op_acc: 39.84%] [G loss: 0.823454]\n",
      "epoch:26 step:20473[D loss: 0.385512, acc: 69.53%, op_acc: 44.53%] [G loss: 0.877384]\n",
      "epoch:26 step:20474[D loss: 0.417651, acc: 53.12%, op_acc: 40.62%] [G loss: 0.913985]\n",
      "epoch:26 step:20475[D loss: 0.456730, acc: 58.59%, op_acc: 41.41%] [G loss: 0.910453]\n",
      "epoch:26 step:20476[D loss: 0.441941, acc: 53.91%, op_acc: 42.97%] [G loss: 0.894955]\n",
      "epoch:26 step:20477[D loss: 0.406455, acc: 66.41%, op_acc: 39.84%] [G loss: 0.949281]\n",
      "epoch:26 step:20478[D loss: 0.424219, acc: 62.50%, op_acc: 39.06%] [G loss: 0.937800]\n",
      "epoch:26 step:20479[D loss: 0.425436, acc: 64.84%, op_acc: 39.06%] [G loss: 0.878765]\n",
      "epoch:26 step:20480[D loss: 0.476536, acc: 49.22%, op_acc: 37.50%] [G loss: 0.802302]\n",
      "epoch:26 step:20481[D loss: 0.414013, acc: 62.50%, op_acc: 42.19%] [G loss: 0.881398]\n",
      "epoch:26 step:20482[D loss: 0.454932, acc: 55.47%, op_acc: 38.28%] [G loss: 0.876042]\n",
      "epoch:26 step:20483[D loss: 0.413500, acc: 58.59%, op_acc: 46.88%] [G loss: 0.897706]\n",
      "epoch:26 step:20484[D loss: 0.439010, acc: 55.47%, op_acc: 32.81%] [G loss: 0.976268]\n",
      "epoch:26 step:20485[D loss: 0.410449, acc: 61.72%, op_acc: 36.72%] [G loss: 0.860766]\n",
      "epoch:26 step:20486[D loss: 0.406835, acc: 65.62%, op_acc: 42.97%] [G loss: 0.961724]\n",
      "epoch:26 step:20487[D loss: 0.420668, acc: 53.91%, op_acc: 43.75%] [G loss: 0.875728]\n",
      "epoch:26 step:20488[D loss: 0.420578, acc: 62.50%, op_acc: 42.97%] [G loss: 1.025115]\n",
      "epoch:26 step:20489[D loss: 0.404934, acc: 60.16%, op_acc: 45.31%] [G loss: 0.948882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20490[D loss: 0.382294, acc: 67.19%, op_acc: 44.53%] [G loss: 0.967354]\n",
      "epoch:26 step:20491[D loss: 0.430308, acc: 64.06%, op_acc: 35.94%] [G loss: 0.936805]\n",
      "epoch:26 step:20492[D loss: 0.427120, acc: 54.69%, op_acc: 36.72%] [G loss: 0.936636]\n",
      "epoch:26 step:20493[D loss: 0.424838, acc: 57.81%, op_acc: 39.84%] [G loss: 0.898669]\n",
      "epoch:26 step:20494[D loss: 0.407509, acc: 63.28%, op_acc: 45.31%] [G loss: 0.830087]\n",
      "epoch:26 step:20495[D loss: 0.420377, acc: 63.28%, op_acc: 38.28%] [G loss: 0.907893]\n",
      "epoch:26 step:20496[D loss: 0.448411, acc: 55.47%, op_acc: 39.84%] [G loss: 0.912755]\n",
      "epoch:26 step:20497[D loss: 0.413240, acc: 56.25%, op_acc: 39.84%] [G loss: 0.894565]\n",
      "epoch:26 step:20498[D loss: 0.405278, acc: 61.72%, op_acc: 42.97%] [G loss: 0.865598]\n",
      "epoch:26 step:20499[D loss: 0.452981, acc: 53.12%, op_acc: 34.38%] [G loss: 0.967262]\n",
      "epoch:26 step:20500[D loss: 0.404255, acc: 63.28%, op_acc: 42.19%] [G loss: 0.836861]\n",
      "epoch:26 step:20501[D loss: 0.419684, acc: 67.97%, op_acc: 42.19%] [G loss: 0.902338]\n",
      "epoch:26 step:20502[D loss: 0.443707, acc: 57.81%, op_acc: 33.59%] [G loss: 0.932631]\n",
      "epoch:26 step:20503[D loss: 0.417486, acc: 62.50%, op_acc: 37.50%] [G loss: 0.892206]\n",
      "epoch:26 step:20504[D loss: 0.425286, acc: 61.72%, op_acc: 39.06%] [G loss: 0.919407]\n",
      "epoch:26 step:20505[D loss: 0.444498, acc: 52.34%, op_acc: 36.72%] [G loss: 0.812072]\n",
      "epoch:26 step:20506[D loss: 0.399817, acc: 63.28%, op_acc: 44.53%] [G loss: 0.904628]\n",
      "epoch:26 step:20507[D loss: 0.421647, acc: 55.47%, op_acc: 40.62%] [G loss: 0.846017]\n",
      "epoch:26 step:20508[D loss: 0.449797, acc: 59.38%, op_acc: 39.84%] [G loss: 0.956090]\n",
      "epoch:26 step:20509[D loss: 0.446206, acc: 59.38%, op_acc: 35.94%] [G loss: 0.888008]\n",
      "epoch:26 step:20510[D loss: 0.404094, acc: 63.28%, op_acc: 38.28%] [G loss: 0.873396]\n",
      "epoch:26 step:20511[D loss: 0.396535, acc: 62.50%, op_acc: 42.97%] [G loss: 0.937249]\n",
      "epoch:26 step:20512[D loss: 0.388140, acc: 64.06%, op_acc: 41.41%] [G loss: 0.946780]\n",
      "epoch:26 step:20513[D loss: 0.381234, acc: 71.88%, op_acc: 43.75%] [G loss: 0.942693]\n",
      "epoch:26 step:20514[D loss: 0.428292, acc: 55.47%, op_acc: 39.06%] [G loss: 0.962384]\n",
      "epoch:26 step:20515[D loss: 0.415384, acc: 56.25%, op_acc: 45.31%] [G loss: 0.910162]\n",
      "epoch:26 step:20516[D loss: 0.420866, acc: 63.28%, op_acc: 42.97%] [G loss: 0.976977]\n",
      "epoch:26 step:20517[D loss: 0.427335, acc: 58.59%, op_acc: 39.06%] [G loss: 0.894207]\n",
      "epoch:26 step:20518[D loss: 0.399925, acc: 64.06%, op_acc: 42.19%] [G loss: 0.874803]\n",
      "epoch:26 step:20519[D loss: 0.410968, acc: 59.38%, op_acc: 39.84%] [G loss: 0.793656]\n",
      "epoch:26 step:20520[D loss: 0.396661, acc: 70.31%, op_acc: 42.97%] [G loss: 0.803084]\n",
      "epoch:26 step:20521[D loss: 0.441253, acc: 64.06%, op_acc: 33.59%] [G loss: 0.901638]\n",
      "epoch:26 step:20522[D loss: 0.410405, acc: 66.41%, op_acc: 39.06%] [G loss: 0.859452]\n",
      "epoch:26 step:20523[D loss: 0.410160, acc: 57.03%, op_acc: 39.06%] [G loss: 0.866597]\n",
      "epoch:26 step:20524[D loss: 0.421049, acc: 63.28%, op_acc: 40.62%] [G loss: 0.948516]\n",
      "epoch:26 step:20525[D loss: 0.431037, acc: 54.69%, op_acc: 42.19%] [G loss: 0.810773]\n",
      "epoch:26 step:20526[D loss: 0.400287, acc: 63.28%, op_acc: 45.31%] [G loss: 0.897507]\n",
      "epoch:26 step:20527[D loss: 0.415249, acc: 59.38%, op_acc: 46.09%] [G loss: 0.801658]\n",
      "epoch:26 step:20528[D loss: 0.432257, acc: 53.12%, op_acc: 39.84%] [G loss: 0.848476]\n",
      "epoch:26 step:20529[D loss: 0.420867, acc: 67.19%, op_acc: 39.84%] [G loss: 0.936679]\n",
      "epoch:26 step:20530[D loss: 0.424694, acc: 54.69%, op_acc: 42.19%] [G loss: 0.879570]\n",
      "epoch:26 step:20531[D loss: 0.426105, acc: 55.47%, op_acc: 43.75%] [G loss: 0.855947]\n",
      "epoch:26 step:20532[D loss: 0.418151, acc: 62.50%, op_acc: 39.06%] [G loss: 0.912852]\n",
      "epoch:26 step:20533[D loss: 0.403297, acc: 61.72%, op_acc: 42.19%] [G loss: 0.924681]\n",
      "epoch:26 step:20534[D loss: 0.390826, acc: 67.97%, op_acc: 43.75%] [G loss: 0.928539]\n",
      "epoch:26 step:20535[D loss: 0.435021, acc: 58.59%, op_acc: 38.28%] [G loss: 0.924049]\n",
      "epoch:26 step:20536[D loss: 0.429018, acc: 61.72%, op_acc: 36.72%] [G loss: 0.998217]\n",
      "epoch:26 step:20537[D loss: 0.365562, acc: 70.31%, op_acc: 44.53%] [G loss: 0.978749]\n",
      "epoch:26 step:20538[D loss: 0.453436, acc: 50.00%, op_acc: 41.41%] [G loss: 0.933945]\n",
      "epoch:26 step:20539[D loss: 0.428924, acc: 63.28%, op_acc: 38.28%] [G loss: 0.931811]\n",
      "epoch:26 step:20540[D loss: 0.433490, acc: 60.94%, op_acc: 39.06%] [G loss: 0.870102]\n",
      "epoch:26 step:20541[D loss: 0.418986, acc: 62.50%, op_acc: 36.72%] [G loss: 0.853227]\n",
      "epoch:26 step:20542[D loss: 0.425433, acc: 60.16%, op_acc: 39.84%] [G loss: 0.846607]\n",
      "epoch:26 step:20543[D loss: 0.385629, acc: 67.19%, op_acc: 43.75%] [G loss: 0.816545]\n",
      "epoch:26 step:20544[D loss: 0.419172, acc: 65.62%, op_acc: 40.62%] [G loss: 0.875138]\n",
      "epoch:26 step:20545[D loss: 0.418245, acc: 60.94%, op_acc: 36.72%] [G loss: 0.858367]\n",
      "epoch:26 step:20546[D loss: 0.427220, acc: 54.69%, op_acc: 42.97%] [G loss: 0.911895]\n",
      "epoch:26 step:20547[D loss: 0.441674, acc: 52.34%, op_acc: 35.16%] [G loss: 0.835475]\n",
      "epoch:26 step:20548[D loss: 0.429431, acc: 54.69%, op_acc: 38.28%] [G loss: 0.961008]\n",
      "epoch:26 step:20549[D loss: 0.432709, acc: 52.34%, op_acc: 43.75%] [G loss: 0.895694]\n",
      "epoch:26 step:20550[D loss: 0.417456, acc: 57.81%, op_acc: 42.97%] [G loss: 0.854085]\n",
      "epoch:26 step:20551[D loss: 0.421687, acc: 47.66%, op_acc: 45.31%] [G loss: 0.897009]\n",
      "epoch:26 step:20552[D loss: 0.430029, acc: 62.50%, op_acc: 39.06%] [G loss: 0.974235]\n",
      "epoch:26 step:20553[D loss: 0.421364, acc: 56.25%, op_acc: 42.19%] [G loss: 0.938383]\n",
      "epoch:26 step:20554[D loss: 0.401513, acc: 69.53%, op_acc: 34.38%] [G loss: 0.945881]\n",
      "epoch:26 step:20555[D loss: 0.406844, acc: 66.41%, op_acc: 42.97%] [G loss: 0.937304]\n",
      "epoch:26 step:20556[D loss: 0.459933, acc: 53.12%, op_acc: 38.28%] [G loss: 0.888110]\n",
      "epoch:26 step:20557[D loss: 0.404498, acc: 60.16%, op_acc: 42.97%] [G loss: 0.890084]\n",
      "epoch:26 step:20558[D loss: 0.452520, acc: 55.47%, op_acc: 39.84%] [G loss: 0.992109]\n",
      "epoch:26 step:20559[D loss: 0.439017, acc: 57.81%, op_acc: 34.38%] [G loss: 0.846212]\n",
      "epoch:26 step:20560[D loss: 0.450033, acc: 53.12%, op_acc: 38.28%] [G loss: 0.920797]\n",
      "epoch:26 step:20561[D loss: 0.427924, acc: 57.81%, op_acc: 41.41%] [G loss: 0.907710]\n",
      "epoch:26 step:20562[D loss: 0.425472, acc: 60.16%, op_acc: 39.84%] [G loss: 0.891255]\n",
      "epoch:26 step:20563[D loss: 0.415339, acc: 62.50%, op_acc: 43.75%] [G loss: 0.880620]\n",
      "epoch:26 step:20564[D loss: 0.418143, acc: 60.16%, op_acc: 37.50%] [G loss: 0.817857]\n",
      "epoch:26 step:20565[D loss: 0.412109, acc: 63.28%, op_acc: 37.50%] [G loss: 0.946158]\n",
      "epoch:26 step:20566[D loss: 0.441591, acc: 57.03%, op_acc: 42.97%] [G loss: 0.990134]\n",
      "epoch:26 step:20567[D loss: 0.434488, acc: 54.69%, op_acc: 38.28%] [G loss: 0.981037]\n",
      "epoch:26 step:20568[D loss: 0.404582, acc: 64.84%, op_acc: 39.06%] [G loss: 0.984512]\n",
      "epoch:26 step:20569[D loss: 0.404963, acc: 65.62%, op_acc: 39.84%] [G loss: 0.961143]\n",
      "epoch:26 step:20570[D loss: 0.425469, acc: 61.72%, op_acc: 39.84%] [G loss: 0.891107]\n",
      "epoch:26 step:20571[D loss: 0.407858, acc: 60.16%, op_acc: 39.06%] [G loss: 0.946303]\n",
      "epoch:26 step:20572[D loss: 0.413541, acc: 66.41%, op_acc: 44.53%] [G loss: 0.960944]\n",
      "epoch:26 step:20573[D loss: 0.455702, acc: 52.34%, op_acc: 32.81%] [G loss: 0.926569]\n",
      "epoch:26 step:20574[D loss: 0.420619, acc: 56.25%, op_acc: 43.75%] [G loss: 0.923304]\n",
      "epoch:26 step:20575[D loss: 0.405835, acc: 63.28%, op_acc: 41.41%] [G loss: 0.842218]\n",
      "epoch:26 step:20576[D loss: 0.412758, acc: 62.50%, op_acc: 39.84%] [G loss: 0.933733]\n",
      "epoch:26 step:20577[D loss: 0.455665, acc: 54.69%, op_acc: 35.94%] [G loss: 0.878598]\n",
      "epoch:26 step:20578[D loss: 0.432420, acc: 57.81%, op_acc: 37.50%] [G loss: 0.933533]\n",
      "epoch:26 step:20579[D loss: 0.446112, acc: 57.81%, op_acc: 39.84%] [G loss: 0.810983]\n",
      "epoch:26 step:20580[D loss: 0.429822, acc: 58.59%, op_acc: 42.97%] [G loss: 0.756366]\n",
      "epoch:26 step:20581[D loss: 0.425865, acc: 57.81%, op_acc: 39.84%] [G loss: 0.955302]\n",
      "epoch:26 step:20582[D loss: 0.452531, acc: 49.22%, op_acc: 43.75%] [G loss: 0.973331]\n",
      "epoch:26 step:20583[D loss: 0.428532, acc: 56.25%, op_acc: 31.25%] [G loss: 0.722733]\n",
      "epoch:26 step:20584[D loss: 0.431667, acc: 59.38%, op_acc: 37.50%] [G loss: 0.862227]\n",
      "epoch:26 step:20585[D loss: 0.447099, acc: 56.25%, op_acc: 41.41%] [G loss: 0.893872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20586[D loss: 0.415404, acc: 61.72%, op_acc: 41.41%] [G loss: 0.918997]\n",
      "epoch:26 step:20587[D loss: 0.431613, acc: 58.59%, op_acc: 38.28%] [G loss: 0.815138]\n",
      "epoch:26 step:20588[D loss: 0.429830, acc: 62.50%, op_acc: 39.84%] [G loss: 0.905434]\n",
      "epoch:26 step:20589[D loss: 0.415530, acc: 66.41%, op_acc: 44.53%] [G loss: 0.962066]\n",
      "epoch:26 step:20590[D loss: 0.415066, acc: 57.81%, op_acc: 35.94%] [G loss: 0.876973]\n",
      "epoch:26 step:20591[D loss: 0.430562, acc: 58.59%, op_acc: 32.81%] [G loss: 0.834210]\n",
      "epoch:26 step:20592[D loss: 0.409416, acc: 71.09%, op_acc: 40.62%] [G loss: 0.965625]\n",
      "epoch:26 step:20593[D loss: 0.433519, acc: 55.47%, op_acc: 47.66%] [G loss: 0.914683]\n",
      "epoch:26 step:20594[D loss: 0.435526, acc: 61.72%, op_acc: 35.94%] [G loss: 0.934820]\n",
      "epoch:26 step:20595[D loss: 0.422643, acc: 61.72%, op_acc: 35.16%] [G loss: 1.000391]\n",
      "epoch:26 step:20596[D loss: 0.411444, acc: 63.28%, op_acc: 44.53%] [G loss: 0.876437]\n",
      "epoch:26 step:20597[D loss: 0.441084, acc: 53.12%, op_acc: 42.97%] [G loss: 0.836197]\n",
      "epoch:26 step:20598[D loss: 0.439700, acc: 54.69%, op_acc: 39.84%] [G loss: 0.915524]\n",
      "epoch:26 step:20599[D loss: 0.409720, acc: 69.53%, op_acc: 45.31%] [G loss: 0.873190]\n",
      "epoch:26 step:20600[D loss: 0.381733, acc: 70.31%, op_acc: 43.75%] [G loss: 0.878327]\n",
      "epoch:26 step:20601[D loss: 0.393323, acc: 65.62%, op_acc: 39.06%] [G loss: 0.819988]\n",
      "epoch:26 step:20602[D loss: 0.419390, acc: 57.03%, op_acc: 42.97%] [G loss: 0.847490]\n",
      "epoch:26 step:20603[D loss: 0.435752, acc: 63.28%, op_acc: 36.72%] [G loss: 0.904889]\n",
      "epoch:26 step:20604[D loss: 0.411827, acc: 62.50%, op_acc: 39.84%] [G loss: 0.874826]\n",
      "epoch:26 step:20605[D loss: 0.397477, acc: 67.97%, op_acc: 41.41%] [G loss: 0.867502]\n",
      "epoch:26 step:20606[D loss: 0.437988, acc: 60.16%, op_acc: 37.50%] [G loss: 0.822735]\n",
      "epoch:26 step:20607[D loss: 0.438736, acc: 59.38%, op_acc: 38.28%] [G loss: 0.871329]\n",
      "epoch:26 step:20608[D loss: 0.392441, acc: 68.75%, op_acc: 40.62%] [G loss: 0.887463]\n",
      "epoch:26 step:20609[D loss: 0.410563, acc: 67.19%, op_acc: 40.62%] [G loss: 0.897787]\n",
      "epoch:26 step:20610[D loss: 0.367419, acc: 70.31%, op_acc: 49.22%] [G loss: 0.881400]\n",
      "epoch:26 step:20611[D loss: 0.408326, acc: 62.50%, op_acc: 39.06%] [G loss: 0.859433]\n",
      "epoch:26 step:20612[D loss: 0.423763, acc: 62.50%, op_acc: 42.19%] [G loss: 0.951294]\n",
      "epoch:26 step:20613[D loss: 0.417538, acc: 56.25%, op_acc: 41.41%] [G loss: 0.942606]\n",
      "epoch:26 step:20614[D loss: 0.405269, acc: 67.19%, op_acc: 39.84%] [G loss: 0.889255]\n",
      "epoch:26 step:20615[D loss: 0.443351, acc: 57.81%, op_acc: 35.16%] [G loss: 0.965736]\n",
      "epoch:26 step:20616[D loss: 0.448314, acc: 59.38%, op_acc: 38.28%] [G loss: 0.841603]\n",
      "epoch:26 step:20617[D loss: 0.409559, acc: 63.28%, op_acc: 39.84%] [G loss: 0.826442]\n",
      "epoch:26 step:20618[D loss: 0.442205, acc: 50.00%, op_acc: 39.84%] [G loss: 0.833538]\n",
      "epoch:26 step:20619[D loss: 0.438314, acc: 56.25%, op_acc: 39.84%] [G loss: 0.914418]\n",
      "epoch:26 step:20620[D loss: 0.424354, acc: 61.72%, op_acc: 38.28%] [G loss: 0.827942]\n",
      "epoch:26 step:20621[D loss: 0.410890, acc: 60.16%, op_acc: 42.19%] [G loss: 0.889362]\n",
      "epoch:26 step:20622[D loss: 0.443046, acc: 56.25%, op_acc: 38.28%] [G loss: 0.875855]\n",
      "epoch:26 step:20623[D loss: 0.404012, acc: 68.75%, op_acc: 36.72%] [G loss: 0.967699]\n",
      "epoch:26 step:20624[D loss: 0.450785, acc: 58.59%, op_acc: 38.28%] [G loss: 0.847596]\n",
      "epoch:26 step:20625[D loss: 0.406887, acc: 59.38%, op_acc: 40.62%] [G loss: 0.847142]\n",
      "epoch:26 step:20626[D loss: 0.428055, acc: 58.59%, op_acc: 38.28%] [G loss: 0.850502]\n",
      "epoch:26 step:20627[D loss: 0.447351, acc: 53.12%, op_acc: 35.94%] [G loss: 0.853954]\n",
      "epoch:26 step:20628[D loss: 0.402492, acc: 64.06%, op_acc: 44.53%] [G loss: 0.813115]\n",
      "epoch:26 step:20629[D loss: 0.430720, acc: 55.47%, op_acc: 36.72%] [G loss: 0.829640]\n",
      "epoch:26 step:20630[D loss: 0.381877, acc: 73.44%, op_acc: 40.62%] [G loss: 0.842054]\n",
      "epoch:26 step:20631[D loss: 0.430095, acc: 53.91%, op_acc: 42.97%] [G loss: 0.848539]\n",
      "epoch:26 step:20632[D loss: 0.434885, acc: 55.47%, op_acc: 40.62%] [G loss: 0.844884]\n",
      "epoch:26 step:20633[D loss: 0.371238, acc: 72.66%, op_acc: 42.97%] [G loss: 0.892206]\n",
      "epoch:26 step:20634[D loss: 0.448121, acc: 53.12%, op_acc: 36.72%] [G loss: 0.897632]\n",
      "epoch:26 step:20635[D loss: 0.407059, acc: 67.97%, op_acc: 35.94%] [G loss: 0.872530]\n",
      "epoch:26 step:20636[D loss: 0.381614, acc: 64.84%, op_acc: 42.19%] [G loss: 0.863419]\n",
      "epoch:26 step:20637[D loss: 0.399346, acc: 61.72%, op_acc: 39.84%] [G loss: 0.894464]\n",
      "epoch:26 step:20638[D loss: 0.414804, acc: 64.06%, op_acc: 42.19%] [G loss: 0.927540]\n",
      "epoch:26 step:20639[D loss: 0.409178, acc: 68.75%, op_acc: 40.62%] [G loss: 0.929541]\n",
      "epoch:26 step:20640[D loss: 0.406796, acc: 57.81%, op_acc: 42.97%] [G loss: 0.892397]\n",
      "epoch:26 step:20641[D loss: 0.431108, acc: 64.06%, op_acc: 39.84%] [G loss: 0.841334]\n",
      "epoch:26 step:20642[D loss: 0.437710, acc: 53.12%, op_acc: 42.19%] [G loss: 0.859736]\n",
      "epoch:26 step:20643[D loss: 0.422093, acc: 64.84%, op_acc: 39.06%] [G loss: 0.947024]\n",
      "epoch:26 step:20644[D loss: 0.385145, acc: 66.41%, op_acc: 43.75%] [G loss: 0.937126]\n",
      "epoch:26 step:20645[D loss: 0.440114, acc: 55.47%, op_acc: 39.06%] [G loss: 0.892136]\n",
      "epoch:26 step:20646[D loss: 0.412663, acc: 60.16%, op_acc: 40.62%] [G loss: 0.860330]\n",
      "epoch:26 step:20647[D loss: 0.430416, acc: 58.59%, op_acc: 41.41%] [G loss: 0.915429]\n",
      "epoch:26 step:20648[D loss: 0.440946, acc: 51.56%, op_acc: 42.19%] [G loss: 0.850749]\n",
      "epoch:26 step:20649[D loss: 0.436969, acc: 60.94%, op_acc: 39.84%] [G loss: 0.878709]\n",
      "epoch:26 step:20650[D loss: 0.386686, acc: 63.28%, op_acc: 42.97%] [G loss: 0.840018]\n",
      "epoch:26 step:20651[D loss: 0.409138, acc: 66.41%, op_acc: 42.97%] [G loss: 0.929665]\n",
      "epoch:26 step:20652[D loss: 0.407733, acc: 66.41%, op_acc: 40.62%] [G loss: 0.840039]\n",
      "epoch:26 step:20653[D loss: 0.436370, acc: 56.25%, op_acc: 40.62%] [G loss: 0.910502]\n",
      "epoch:26 step:20654[D loss: 0.386229, acc: 63.28%, op_acc: 42.19%] [G loss: 0.920458]\n",
      "epoch:26 step:20655[D loss: 0.415758, acc: 59.38%, op_acc: 41.41%] [G loss: 0.889758]\n",
      "epoch:26 step:20656[D loss: 0.423684, acc: 60.16%, op_acc: 36.72%] [G loss: 0.925503]\n",
      "epoch:26 step:20657[D loss: 0.459605, acc: 51.56%, op_acc: 35.16%] [G loss: 0.833279]\n",
      "epoch:26 step:20658[D loss: 0.446083, acc: 55.47%, op_acc: 38.28%] [G loss: 0.891689]\n",
      "epoch:26 step:20659[D loss: 0.375895, acc: 67.97%, op_acc: 47.66%] [G loss: 0.941612]\n",
      "epoch:26 step:20660[D loss: 0.438148, acc: 53.12%, op_acc: 38.28%] [G loss: 0.908833]\n",
      "epoch:26 step:20661[D loss: 0.428258, acc: 60.16%, op_acc: 46.88%] [G loss: 0.870406]\n",
      "epoch:26 step:20662[D loss: 0.426230, acc: 54.69%, op_acc: 39.06%] [G loss: 0.848561]\n",
      "epoch:26 step:20663[D loss: 0.426281, acc: 61.72%, op_acc: 36.72%] [G loss: 0.843412]\n",
      "epoch:26 step:20664[D loss: 0.428683, acc: 59.38%, op_acc: 39.06%] [G loss: 0.929734]\n",
      "epoch:26 step:20665[D loss: 0.420907, acc: 59.38%, op_acc: 36.72%] [G loss: 0.853444]\n",
      "epoch:26 step:20666[D loss: 0.438373, acc: 55.47%, op_acc: 36.72%] [G loss: 0.975061]\n",
      "epoch:26 step:20667[D loss: 0.415999, acc: 57.81%, op_acc: 45.31%] [G loss: 0.913495]\n",
      "epoch:26 step:20668[D loss: 0.423118, acc: 55.47%, op_acc: 43.75%] [G loss: 0.996968]\n",
      "epoch:26 step:20669[D loss: 0.441303, acc: 60.94%, op_acc: 35.94%] [G loss: 0.915946]\n",
      "epoch:26 step:20670[D loss: 0.456088, acc: 58.59%, op_acc: 42.19%] [G loss: 0.890439]\n",
      "epoch:26 step:20671[D loss: 0.365732, acc: 67.97%, op_acc: 47.66%] [G loss: 0.951385]\n",
      "epoch:26 step:20672[D loss: 0.408629, acc: 60.94%, op_acc: 39.06%] [G loss: 0.913344]\n",
      "epoch:26 step:20673[D loss: 0.438233, acc: 60.94%, op_acc: 33.59%] [G loss: 0.933068]\n",
      "epoch:26 step:20674[D loss: 0.408627, acc: 61.72%, op_acc: 38.28%] [G loss: 0.960371]\n",
      "epoch:26 step:20675[D loss: 0.425069, acc: 60.94%, op_acc: 35.94%] [G loss: 0.913358]\n",
      "epoch:26 step:20676[D loss: 0.431004, acc: 57.03%, op_acc: 39.06%] [G loss: 0.981455]\n",
      "epoch:26 step:20677[D loss: 0.366051, acc: 67.97%, op_acc: 48.44%] [G loss: 0.936569]\n",
      "epoch:26 step:20678[D loss: 0.433235, acc: 60.94%, op_acc: 39.84%] [G loss: 0.885561]\n",
      "epoch:26 step:20679[D loss: 0.439679, acc: 49.22%, op_acc: 41.41%] [G loss: 0.836393]\n",
      "epoch:26 step:20680[D loss: 0.424274, acc: 56.25%, op_acc: 42.19%] [G loss: 0.848344]\n",
      "epoch:26 step:20681[D loss: 0.421789, acc: 54.69%, op_acc: 43.75%] [G loss: 0.897159]\n",
      "epoch:26 step:20682[D loss: 0.420475, acc: 61.72%, op_acc: 45.31%] [G loss: 0.929881]\n",
      "epoch:26 step:20683[D loss: 0.429407, acc: 56.25%, op_acc: 34.38%] [G loss: 0.950329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20684[D loss: 0.438570, acc: 59.38%, op_acc: 38.28%] [G loss: 0.924235]\n",
      "epoch:26 step:20685[D loss: 0.403079, acc: 61.72%, op_acc: 36.72%] [G loss: 0.877703]\n",
      "epoch:26 step:20686[D loss: 0.398300, acc: 64.06%, op_acc: 42.97%] [G loss: 0.889901]\n",
      "epoch:26 step:20687[D loss: 0.424584, acc: 60.16%, op_acc: 35.94%] [G loss: 0.848538]\n",
      "epoch:26 step:20688[D loss: 0.405746, acc: 64.06%, op_acc: 38.28%] [G loss: 0.955325]\n",
      "epoch:26 step:20689[D loss: 0.384921, acc: 65.62%, op_acc: 47.66%] [G loss: 0.913009]\n",
      "epoch:26 step:20690[D loss: 0.395748, acc: 68.75%, op_acc: 39.06%] [G loss: 0.864405]\n",
      "epoch:26 step:20691[D loss: 0.431071, acc: 57.03%, op_acc: 42.19%] [G loss: 0.857379]\n",
      "epoch:26 step:20692[D loss: 0.400485, acc: 60.94%, op_acc: 39.84%] [G loss: 0.944345]\n",
      "epoch:26 step:20693[D loss: 0.397419, acc: 64.84%, op_acc: 38.28%] [G loss: 0.960269]\n",
      "epoch:26 step:20694[D loss: 0.419325, acc: 63.28%, op_acc: 37.50%] [G loss: 0.914428]\n",
      "epoch:26 step:20695[D loss: 0.437905, acc: 58.59%, op_acc: 39.06%] [G loss: 0.847472]\n",
      "epoch:26 step:20696[D loss: 0.443745, acc: 56.25%, op_acc: 37.50%] [G loss: 0.821290]\n",
      "epoch:26 step:20697[D loss: 0.427756, acc: 53.91%, op_acc: 44.53%] [G loss: 0.912500]\n",
      "epoch:26 step:20698[D loss: 0.413334, acc: 60.16%, op_acc: 42.19%] [G loss: 0.936561]\n",
      "epoch:26 step:20699[D loss: 0.405855, acc: 63.28%, op_acc: 46.88%] [G loss: 0.923420]\n",
      "epoch:26 step:20700[D loss: 0.416371, acc: 61.72%, op_acc: 35.94%] [G loss: 0.844171]\n",
      "epoch:26 step:20701[D loss: 0.477016, acc: 51.56%, op_acc: 35.94%] [G loss: 0.898299]\n",
      "epoch:26 step:20702[D loss: 0.394021, acc: 69.53%, op_acc: 43.75%] [G loss: 0.906810]\n",
      "epoch:26 step:20703[D loss: 0.425929, acc: 53.91%, op_acc: 39.06%] [G loss: 0.850807]\n",
      "epoch:26 step:20704[D loss: 0.432773, acc: 63.28%, op_acc: 32.03%] [G loss: 0.864180]\n",
      "epoch:26 step:20705[D loss: 0.407386, acc: 61.72%, op_acc: 37.50%] [G loss: 0.852922]\n",
      "epoch:26 step:20706[D loss: 0.391684, acc: 63.28%, op_acc: 48.44%] [G loss: 0.926230]\n",
      "epoch:26 step:20707[D loss: 0.415810, acc: 57.03%, op_acc: 42.97%] [G loss: 0.872827]\n",
      "epoch:26 step:20708[D loss: 0.436159, acc: 60.16%, op_acc: 33.59%] [G loss: 0.880739]\n",
      "epoch:26 step:20709[D loss: 0.377953, acc: 71.09%, op_acc: 42.19%] [G loss: 0.864801]\n",
      "epoch:26 step:20710[D loss: 0.392505, acc: 65.62%, op_acc: 44.53%] [G loss: 0.930931]\n",
      "epoch:26 step:20711[D loss: 0.449905, acc: 57.81%, op_acc: 38.28%] [G loss: 0.840918]\n",
      "epoch:26 step:20712[D loss: 0.406918, acc: 57.81%, op_acc: 42.97%] [G loss: 0.877461]\n",
      "epoch:26 step:20713[D loss: 0.427417, acc: 59.38%, op_acc: 35.16%] [G loss: 0.923101]\n",
      "epoch:26 step:20714[D loss: 0.412445, acc: 57.81%, op_acc: 39.84%] [G loss: 0.875082]\n",
      "epoch:26 step:20715[D loss: 0.434169, acc: 53.91%, op_acc: 39.84%] [G loss: 0.783094]\n",
      "epoch:26 step:20716[D loss: 0.401700, acc: 60.16%, op_acc: 39.84%] [G loss: 0.815954]\n",
      "epoch:26 step:20717[D loss: 0.443637, acc: 49.22%, op_acc: 35.16%] [G loss: 0.754678]\n",
      "epoch:26 step:20718[D loss: 0.422946, acc: 58.59%, op_acc: 40.62%] [G loss: 0.944582]\n",
      "epoch:26 step:20719[D loss: 0.445549, acc: 57.81%, op_acc: 36.72%] [G loss: 0.870493]\n",
      "epoch:26 step:20720[D loss: 0.408674, acc: 62.50%, op_acc: 32.81%] [G loss: 0.939237]\n",
      "epoch:26 step:20721[D loss: 0.404703, acc: 64.84%, op_acc: 37.50%] [G loss: 0.937101]\n",
      "epoch:26 step:20722[D loss: 0.440833, acc: 55.47%, op_acc: 39.84%] [G loss: 0.942795]\n",
      "epoch:26 step:20723[D loss: 0.438412, acc: 59.38%, op_acc: 41.41%] [G loss: 0.938608]\n",
      "epoch:26 step:20724[D loss: 0.422177, acc: 60.94%, op_acc: 38.28%] [G loss: 0.862652]\n",
      "epoch:26 step:20725[D loss: 0.395309, acc: 67.97%, op_acc: 44.53%] [G loss: 0.904475]\n",
      "epoch:26 step:20726[D loss: 0.446867, acc: 58.59%, op_acc: 42.19%] [G loss: 0.961440]\n",
      "epoch:26 step:20727[D loss: 0.420383, acc: 64.06%, op_acc: 39.06%] [G loss: 0.846013]\n",
      "epoch:26 step:20728[D loss: 0.407790, acc: 60.94%, op_acc: 42.97%] [G loss: 1.007722]\n",
      "epoch:26 step:20729[D loss: 0.441271, acc: 64.06%, op_acc: 38.28%] [G loss: 0.887243]\n",
      "epoch:26 step:20730[D loss: 0.436925, acc: 57.03%, op_acc: 42.97%] [G loss: 0.881097]\n",
      "epoch:26 step:20731[D loss: 0.438911, acc: 55.47%, op_acc: 35.16%] [G loss: 0.899485]\n",
      "epoch:26 step:20732[D loss: 0.430222, acc: 56.25%, op_acc: 37.50%] [G loss: 0.850569]\n",
      "epoch:26 step:20733[D loss: 0.409436, acc: 67.97%, op_acc: 38.28%] [G loss: 0.905171]\n",
      "epoch:26 step:20734[D loss: 0.431216, acc: 50.78%, op_acc: 40.62%] [G loss: 0.923779]\n",
      "epoch:26 step:20735[D loss: 0.421325, acc: 59.38%, op_acc: 41.41%] [G loss: 0.820976]\n",
      "epoch:26 step:20736[D loss: 0.424709, acc: 60.16%, op_acc: 39.84%] [G loss: 0.908097]\n",
      "epoch:26 step:20737[D loss: 0.404660, acc: 64.06%, op_acc: 41.41%] [G loss: 0.927696]\n",
      "epoch:26 step:20738[D loss: 0.396297, acc: 60.16%, op_acc: 42.97%] [G loss: 0.798499]\n",
      "epoch:26 step:20739[D loss: 0.399903, acc: 61.72%, op_acc: 43.75%] [G loss: 0.869766]\n",
      "epoch:26 step:20740[D loss: 0.402341, acc: 62.50%, op_acc: 40.62%] [G loss: 0.976238]\n",
      "epoch:26 step:20741[D loss: 0.394569, acc: 62.50%, op_acc: 42.19%] [G loss: 0.965146]\n",
      "epoch:26 step:20742[D loss: 0.435604, acc: 60.94%, op_acc: 35.94%] [G loss: 0.971615]\n",
      "epoch:26 step:20743[D loss: 0.418604, acc: 67.19%, op_acc: 46.09%] [G loss: 0.863077]\n",
      "epoch:26 step:20744[D loss: 0.394251, acc: 61.72%, op_acc: 42.97%] [G loss: 0.912816]\n",
      "epoch:26 step:20745[D loss: 0.417964, acc: 60.16%, op_acc: 38.28%] [G loss: 0.921101]\n",
      "epoch:26 step:20746[D loss: 0.400640, acc: 63.28%, op_acc: 44.53%] [G loss: 0.913976]\n",
      "epoch:26 step:20747[D loss: 0.393265, acc: 67.19%, op_acc: 42.19%] [G loss: 0.841954]\n",
      "epoch:26 step:20748[D loss: 0.384763, acc: 71.09%, op_acc: 39.06%] [G loss: 0.896379]\n",
      "epoch:26 step:20749[D loss: 0.417073, acc: 64.84%, op_acc: 37.50%] [G loss: 0.933963]\n",
      "epoch:26 step:20750[D loss: 0.410003, acc: 69.53%, op_acc: 39.06%] [G loss: 0.878615]\n",
      "epoch:26 step:20751[D loss: 0.423092, acc: 62.50%, op_acc: 40.62%] [G loss: 1.064863]\n",
      "epoch:26 step:20752[D loss: 0.409028, acc: 60.94%, op_acc: 42.19%] [G loss: 0.926244]\n",
      "epoch:26 step:20753[D loss: 0.441757, acc: 57.03%, op_acc: 39.06%] [G loss: 0.860606]\n",
      "epoch:26 step:20754[D loss: 0.418005, acc: 57.81%, op_acc: 41.41%] [G loss: 0.929692]\n",
      "epoch:26 step:20755[D loss: 0.372386, acc: 68.75%, op_acc: 41.41%] [G loss: 0.819253]\n",
      "epoch:26 step:20756[D loss: 0.450533, acc: 57.03%, op_acc: 39.06%] [G loss: 1.044971]\n",
      "epoch:26 step:20757[D loss: 0.428554, acc: 51.56%, op_acc: 47.66%] [G loss: 1.033622]\n",
      "epoch:26 step:20758[D loss: 0.380334, acc: 69.53%, op_acc: 39.84%] [G loss: 0.951702]\n",
      "epoch:26 step:20759[D loss: 0.402342, acc: 59.38%, op_acc: 39.06%] [G loss: 0.958817]\n",
      "epoch:26 step:20760[D loss: 0.438034, acc: 58.59%, op_acc: 36.72%] [G loss: 0.861205]\n",
      "epoch:26 step:20761[D loss: 0.443072, acc: 58.59%, op_acc: 42.97%] [G loss: 0.979703]\n",
      "epoch:26 step:20762[D loss: 0.436574, acc: 59.38%, op_acc: 38.28%] [G loss: 0.896210]\n",
      "epoch:26 step:20763[D loss: 0.426909, acc: 58.59%, op_acc: 41.41%] [G loss: 0.903448]\n",
      "epoch:26 step:20764[D loss: 0.382917, acc: 67.97%, op_acc: 39.84%] [G loss: 0.982470]\n",
      "epoch:26 step:20765[D loss: 0.442376, acc: 49.22%, op_acc: 41.41%] [G loss: 0.892208]\n",
      "epoch:26 step:20766[D loss: 0.397627, acc: 61.72%, op_acc: 39.84%] [G loss: 0.922074]\n",
      "epoch:26 step:20767[D loss: 0.434688, acc: 57.03%, op_acc: 40.62%] [G loss: 0.825755]\n",
      "epoch:26 step:20768[D loss: 0.400419, acc: 65.62%, op_acc: 42.19%] [G loss: 0.928793]\n",
      "epoch:26 step:20769[D loss: 0.400308, acc: 60.94%, op_acc: 45.31%] [G loss: 0.918611]\n",
      "epoch:26 step:20770[D loss: 0.413766, acc: 61.72%, op_acc: 46.09%] [G loss: 0.927142]\n",
      "epoch:26 step:20771[D loss: 0.410346, acc: 61.72%, op_acc: 39.06%] [G loss: 0.901834]\n",
      "epoch:26 step:20772[D loss: 0.394709, acc: 64.06%, op_acc: 43.75%] [G loss: 0.927819]\n",
      "epoch:26 step:20773[D loss: 0.412750, acc: 66.41%, op_acc: 38.28%] [G loss: 0.897922]\n",
      "epoch:26 step:20774[D loss: 0.407885, acc: 54.69%, op_acc: 41.41%] [G loss: 0.794280]\n",
      "epoch:26 step:20775[D loss: 0.400722, acc: 61.72%, op_acc: 44.53%] [G loss: 0.868793]\n",
      "epoch:26 step:20776[D loss: 0.398498, acc: 71.09%, op_acc: 44.53%] [G loss: 0.752505]\n",
      "epoch:26 step:20777[D loss: 0.419663, acc: 60.94%, op_acc: 39.06%] [G loss: 0.922810]\n",
      "epoch:26 step:20778[D loss: 0.450801, acc: 57.81%, op_acc: 28.91%] [G loss: 0.768287]\n",
      "epoch:26 step:20779[D loss: 0.405684, acc: 56.25%, op_acc: 42.97%] [G loss: 0.886181]\n",
      "epoch:26 step:20780[D loss: 0.406239, acc: 64.84%, op_acc: 37.50%] [G loss: 0.893717]\n",
      "epoch:26 step:20781[D loss: 0.448194, acc: 49.22%, op_acc: 39.06%] [G loss: 0.936997]\n",
      "epoch:26 step:20782[D loss: 0.448177, acc: 59.38%, op_acc: 37.50%] [G loss: 0.840472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20783[D loss: 0.406167, acc: 69.53%, op_acc: 39.84%] [G loss: 0.927373]\n",
      "epoch:26 step:20784[D loss: 0.370325, acc: 73.44%, op_acc: 41.41%] [G loss: 0.834725]\n",
      "epoch:26 step:20785[D loss: 0.386389, acc: 66.41%, op_acc: 46.88%] [G loss: 0.980454]\n",
      "epoch:26 step:20786[D loss: 0.431515, acc: 61.72%, op_acc: 41.41%] [G loss: 0.943086]\n",
      "epoch:26 step:20787[D loss: 0.406961, acc: 67.19%, op_acc: 37.50%] [G loss: 0.898315]\n",
      "epoch:26 step:20788[D loss: 0.430049, acc: 63.28%, op_acc: 41.41%] [G loss: 0.830457]\n",
      "epoch:26 step:20789[D loss: 0.441357, acc: 59.38%, op_acc: 38.28%] [G loss: 0.868196]\n",
      "epoch:26 step:20790[D loss: 0.420853, acc: 55.47%, op_acc: 39.06%] [G loss: 0.879747]\n",
      "epoch:26 step:20791[D loss: 0.403923, acc: 63.28%, op_acc: 42.97%] [G loss: 0.937586]\n",
      "epoch:26 step:20792[D loss: 0.408819, acc: 60.94%, op_acc: 40.62%] [G loss: 0.888026]\n",
      "epoch:26 step:20793[D loss: 0.429893, acc: 62.50%, op_acc: 40.62%] [G loss: 0.926833]\n",
      "epoch:26 step:20794[D loss: 0.419931, acc: 64.06%, op_acc: 39.84%] [G loss: 0.921739]\n",
      "epoch:26 step:20795[D loss: 0.442595, acc: 50.78%, op_acc: 42.97%] [G loss: 0.796390]\n",
      "epoch:26 step:20796[D loss: 0.406829, acc: 63.28%, op_acc: 39.06%] [G loss: 0.938995]\n",
      "epoch:26 step:20797[D loss: 0.434525, acc: 61.72%, op_acc: 35.94%] [G loss: 1.020650]\n",
      "epoch:26 step:20798[D loss: 0.431540, acc: 57.81%, op_acc: 35.94%] [G loss: 0.863707]\n",
      "epoch:26 step:20799[D loss: 0.416625, acc: 61.72%, op_acc: 45.31%] [G loss: 0.935995]\n",
      "epoch:26 step:20800[D loss: 0.375975, acc: 70.31%, op_acc: 41.41%] [G loss: 0.891673]\n",
      "epoch:26 step:20801[D loss: 0.436632, acc: 60.16%, op_acc: 34.38%] [G loss: 0.887721]\n",
      "epoch:26 step:20802[D loss: 0.389809, acc: 72.66%, op_acc: 37.50%] [G loss: 0.928235]\n",
      "epoch:26 step:20803[D loss: 0.432879, acc: 56.25%, op_acc: 38.28%] [G loss: 0.852046]\n",
      "epoch:26 step:20804[D loss: 0.431370, acc: 64.84%, op_acc: 36.72%] [G loss: 0.840568]\n",
      "epoch:26 step:20805[D loss: 0.446744, acc: 57.03%, op_acc: 35.94%] [G loss: 0.888191]\n",
      "epoch:26 step:20806[D loss: 0.414235, acc: 59.38%, op_acc: 41.41%] [G loss: 0.973665]\n",
      "epoch:26 step:20807[D loss: 0.415592, acc: 67.19%, op_acc: 35.16%] [G loss: 0.969508]\n",
      "epoch:26 step:20808[D loss: 0.417917, acc: 57.81%, op_acc: 41.41%] [G loss: 1.046162]\n",
      "epoch:26 step:20809[D loss: 0.413502, acc: 69.53%, op_acc: 40.62%] [G loss: 0.851414]\n",
      "epoch:26 step:20810[D loss: 0.441976, acc: 55.47%, op_acc: 42.19%] [G loss: 0.893266]\n",
      "epoch:26 step:20811[D loss: 0.410780, acc: 64.06%, op_acc: 42.19%] [G loss: 0.895121]\n",
      "epoch:26 step:20812[D loss: 0.411582, acc: 66.41%, op_acc: 43.75%] [G loss: 0.874480]\n",
      "epoch:26 step:20813[D loss: 0.398397, acc: 62.50%, op_acc: 42.97%] [G loss: 0.930153]\n",
      "epoch:26 step:20814[D loss: 0.421640, acc: 62.50%, op_acc: 48.44%] [G loss: 0.870041]\n",
      "epoch:26 step:20815[D loss: 0.451788, acc: 50.00%, op_acc: 41.41%] [G loss: 0.911316]\n",
      "epoch:26 step:20816[D loss: 0.410993, acc: 64.84%, op_acc: 40.62%] [G loss: 0.971696]\n",
      "epoch:26 step:20817[D loss: 0.419425, acc: 57.81%, op_acc: 39.84%] [G loss: 0.926486]\n",
      "epoch:26 step:20818[D loss: 0.429006, acc: 65.62%, op_acc: 37.50%] [G loss: 0.847927]\n",
      "epoch:26 step:20819[D loss: 0.451944, acc: 64.06%, op_acc: 33.59%] [G loss: 0.873798]\n",
      "epoch:26 step:20820[D loss: 0.441861, acc: 53.12%, op_acc: 34.38%] [G loss: 0.878354]\n",
      "epoch:26 step:20821[D loss: 0.389531, acc: 69.53%, op_acc: 39.84%] [G loss: 0.907318]\n",
      "epoch:26 step:20822[D loss: 0.424410, acc: 55.47%, op_acc: 39.84%] [G loss: 1.034932]\n",
      "epoch:26 step:20823[D loss: 0.444756, acc: 55.47%, op_acc: 36.72%] [G loss: 0.815141]\n",
      "epoch:26 step:20824[D loss: 0.410464, acc: 63.28%, op_acc: 37.50%] [G loss: 0.896505]\n",
      "epoch:26 step:20825[D loss: 0.439002, acc: 57.81%, op_acc: 36.72%] [G loss: 0.887134]\n",
      "epoch:26 step:20826[D loss: 0.415183, acc: 62.50%, op_acc: 39.06%] [G loss: 0.866911]\n",
      "epoch:26 step:20827[D loss: 0.424928, acc: 63.28%, op_acc: 34.38%] [G loss: 0.851021]\n",
      "epoch:26 step:20828[D loss: 0.445794, acc: 53.91%, op_acc: 37.50%] [G loss: 0.946315]\n",
      "epoch:26 step:20829[D loss: 0.423795, acc: 52.34%, op_acc: 42.97%] [G loss: 0.886500]\n",
      "epoch:26 step:20830[D loss: 0.398820, acc: 69.53%, op_acc: 39.84%] [G loss: 0.857063]\n",
      "epoch:26 step:20831[D loss: 0.440434, acc: 63.28%, op_acc: 41.41%] [G loss: 0.854695]\n",
      "epoch:26 step:20832[D loss: 0.454343, acc: 53.91%, op_acc: 34.38%] [G loss: 0.933450]\n",
      "epoch:26 step:20833[D loss: 0.427686, acc: 54.69%, op_acc: 44.53%] [G loss: 0.963127]\n",
      "epoch:26 step:20834[D loss: 0.448046, acc: 55.47%, op_acc: 37.50%] [G loss: 0.882202]\n",
      "epoch:26 step:20835[D loss: 0.418832, acc: 60.94%, op_acc: 42.19%] [G loss: 0.926283]\n",
      "epoch:26 step:20836[D loss: 0.399821, acc: 65.62%, op_acc: 37.50%] [G loss: 0.893980]\n",
      "epoch:26 step:20837[D loss: 0.437028, acc: 62.50%, op_acc: 40.62%] [G loss: 0.941567]\n",
      "epoch:26 step:20838[D loss: 0.452898, acc: 57.03%, op_acc: 38.28%] [G loss: 0.979253]\n",
      "epoch:26 step:20839[D loss: 0.378921, acc: 68.75%, op_acc: 46.09%] [G loss: 0.896096]\n",
      "epoch:26 step:20840[D loss: 0.409496, acc: 61.72%, op_acc: 42.19%] [G loss: 0.905227]\n",
      "epoch:26 step:20841[D loss: 0.409149, acc: 64.84%, op_acc: 38.28%] [G loss: 0.878917]\n",
      "epoch:26 step:20842[D loss: 0.410229, acc: 65.62%, op_acc: 45.31%] [G loss: 0.872554]\n",
      "epoch:26 step:20843[D loss: 0.451899, acc: 60.94%, op_acc: 32.03%] [G loss: 1.008503]\n",
      "epoch:26 step:20844[D loss: 0.388228, acc: 67.19%, op_acc: 42.97%] [G loss: 0.945026]\n",
      "epoch:26 step:20845[D loss: 0.417338, acc: 62.50%, op_acc: 38.28%] [G loss: 0.804061]\n",
      "epoch:26 step:20846[D loss: 0.417807, acc: 60.94%, op_acc: 42.97%] [G loss: 0.975440]\n",
      "epoch:26 step:20847[D loss: 0.413123, acc: 57.03%, op_acc: 42.19%] [G loss: 0.969195]\n",
      "epoch:26 step:20848[D loss: 0.446885, acc: 56.25%, op_acc: 37.50%] [G loss: 0.813624]\n",
      "epoch:26 step:20849[D loss: 0.442628, acc: 60.16%, op_acc: 36.72%] [G loss: 0.794369]\n",
      "epoch:26 step:20850[D loss: 0.418448, acc: 57.03%, op_acc: 40.62%] [G loss: 0.874462]\n",
      "epoch:26 step:20851[D loss: 0.392683, acc: 64.84%, op_acc: 38.28%] [G loss: 1.008581]\n",
      "epoch:26 step:20852[D loss: 0.443562, acc: 52.34%, op_acc: 43.75%] [G loss: 0.902296]\n",
      "epoch:26 step:20853[D loss: 0.412729, acc: 67.97%, op_acc: 39.84%] [G loss: 0.988162]\n",
      "epoch:26 step:20854[D loss: 0.413081, acc: 67.19%, op_acc: 38.28%] [G loss: 0.869550]\n",
      "epoch:26 step:20855[D loss: 0.441243, acc: 51.56%, op_acc: 42.97%] [G loss: 0.907066]\n",
      "epoch:26 step:20856[D loss: 0.473687, acc: 43.75%, op_acc: 32.81%] [G loss: 0.909817]\n",
      "epoch:26 step:20857[D loss: 0.427093, acc: 59.38%, op_acc: 38.28%] [G loss: 0.844965]\n",
      "epoch:26 step:20858[D loss: 0.443027, acc: 60.16%, op_acc: 31.25%] [G loss: 0.980958]\n",
      "epoch:26 step:20859[D loss: 0.425412, acc: 63.28%, op_acc: 42.19%] [G loss: 0.922272]\n",
      "epoch:26 step:20860[D loss: 0.425202, acc: 61.72%, op_acc: 39.06%] [G loss: 0.989976]\n",
      "epoch:26 step:20861[D loss: 0.395447, acc: 64.84%, op_acc: 42.19%] [G loss: 0.817106]\n",
      "epoch:26 step:20862[D loss: 0.432570, acc: 57.03%, op_acc: 39.06%] [G loss: 0.910127]\n",
      "epoch:26 step:20863[D loss: 0.436093, acc: 58.59%, op_acc: 32.81%] [G loss: 0.864447]\n",
      "epoch:26 step:20864[D loss: 0.420238, acc: 54.69%, op_acc: 41.41%] [G loss: 0.927819]\n",
      "epoch:26 step:20865[D loss: 0.413144, acc: 62.50%, op_acc: 43.75%] [G loss: 0.895187]\n",
      "epoch:26 step:20866[D loss: 0.431154, acc: 59.38%, op_acc: 39.06%] [G loss: 0.788737]\n",
      "epoch:26 step:20867[D loss: 0.391936, acc: 61.72%, op_acc: 39.06%] [G loss: 0.945082]\n",
      "epoch:26 step:20868[D loss: 0.458554, acc: 52.34%, op_acc: 35.16%] [G loss: 0.924285]\n",
      "epoch:26 step:20869[D loss: 0.380927, acc: 68.75%, op_acc: 41.41%] [G loss: 1.008642]\n",
      "epoch:26 step:20870[D loss: 0.392922, acc: 63.28%, op_acc: 41.41%] [G loss: 0.853871]\n",
      "epoch:26 step:20871[D loss: 0.382114, acc: 65.62%, op_acc: 48.44%] [G loss: 0.898352]\n",
      "epoch:26 step:20872[D loss: 0.397989, acc: 67.97%, op_acc: 32.81%] [G loss: 0.891603]\n",
      "epoch:26 step:20873[D loss: 0.451579, acc: 50.00%, op_acc: 38.28%] [G loss: 0.876403]\n",
      "epoch:26 step:20874[D loss: 0.420113, acc: 62.50%, op_acc: 43.75%] [G loss: 0.864959]\n",
      "epoch:26 step:20875[D loss: 0.414109, acc: 57.81%, op_acc: 42.97%] [G loss: 0.946324]\n",
      "epoch:26 step:20876[D loss: 0.426786, acc: 57.81%, op_acc: 42.19%] [G loss: 0.896388]\n",
      "epoch:26 step:20877[D loss: 0.411662, acc: 57.03%, op_acc: 47.66%] [G loss: 0.908655]\n",
      "epoch:26 step:20878[D loss: 0.421682, acc: 57.03%, op_acc: 37.50%] [G loss: 0.885077]\n",
      "epoch:26 step:20879[D loss: 0.451081, acc: 53.91%, op_acc: 38.28%] [G loss: 0.810475]\n",
      "epoch:26 step:20880[D loss: 0.427593, acc: 58.59%, op_acc: 45.31%] [G loss: 0.927939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20881[D loss: 0.430951, acc: 53.91%, op_acc: 42.19%] [G loss: 0.861807]\n",
      "epoch:26 step:20882[D loss: 0.397491, acc: 68.75%, op_acc: 46.09%] [G loss: 0.838543]\n",
      "epoch:26 step:20883[D loss: 0.453264, acc: 57.03%, op_acc: 36.72%] [G loss: 0.933842]\n",
      "epoch:26 step:20884[D loss: 0.422959, acc: 60.94%, op_acc: 35.16%] [G loss: 0.866972]\n",
      "epoch:26 step:20885[D loss: 0.408504, acc: 58.59%, op_acc: 41.41%] [G loss: 0.899260]\n",
      "epoch:26 step:20886[D loss: 0.405896, acc: 60.94%, op_acc: 45.31%] [G loss: 0.883302]\n",
      "epoch:26 step:20887[D loss: 0.442577, acc: 57.03%, op_acc: 35.94%] [G loss: 0.864436]\n",
      "epoch:26 step:20888[D loss: 0.410466, acc: 64.06%, op_acc: 38.28%] [G loss: 0.913917]\n",
      "epoch:26 step:20889[D loss: 0.408207, acc: 60.16%, op_acc: 36.72%] [G loss: 0.810138]\n",
      "epoch:26 step:20890[D loss: 0.441331, acc: 62.50%, op_acc: 37.50%] [G loss: 0.881040]\n",
      "epoch:26 step:20891[D loss: 0.415785, acc: 62.50%, op_acc: 41.41%] [G loss: 0.810414]\n",
      "epoch:26 step:20892[D loss: 0.435238, acc: 61.72%, op_acc: 38.28%] [G loss: 0.929127]\n",
      "epoch:26 step:20893[D loss: 0.388504, acc: 67.97%, op_acc: 40.62%] [G loss: 0.961824]\n",
      "epoch:26 step:20894[D loss: 0.423571, acc: 59.38%, op_acc: 41.41%] [G loss: 0.926521]\n",
      "epoch:26 step:20895[D loss: 0.435709, acc: 59.38%, op_acc: 34.38%] [G loss: 0.961798]\n",
      "epoch:26 step:20896[D loss: 0.425833, acc: 60.16%, op_acc: 40.62%] [G loss: 0.884135]\n",
      "epoch:26 step:20897[D loss: 0.455449, acc: 60.16%, op_acc: 39.84%] [G loss: 0.934614]\n",
      "epoch:26 step:20898[D loss: 0.449425, acc: 50.78%, op_acc: 32.81%] [G loss: 0.915127]\n",
      "epoch:26 step:20899[D loss: 0.460447, acc: 53.91%, op_acc: 38.28%] [G loss: 0.855590]\n",
      "epoch:26 step:20900[D loss: 0.418009, acc: 61.72%, op_acc: 39.84%] [G loss: 0.861220]\n",
      "epoch:26 step:20901[D loss: 0.418600, acc: 64.84%, op_acc: 38.28%] [G loss: 0.840069]\n",
      "epoch:26 step:20902[D loss: 0.417585, acc: 62.50%, op_acc: 38.28%] [G loss: 0.906019]\n",
      "epoch:26 step:20903[D loss: 0.395648, acc: 66.41%, op_acc: 39.06%] [G loss: 0.885897]\n",
      "epoch:26 step:20904[D loss: 0.404520, acc: 64.06%, op_acc: 46.09%] [G loss: 0.916405]\n",
      "epoch:26 step:20905[D loss: 0.427695, acc: 58.59%, op_acc: 37.50%] [G loss: 0.956425]\n",
      "epoch:26 step:20906[D loss: 0.432770, acc: 55.47%, op_acc: 39.06%] [G loss: 0.926847]\n",
      "epoch:26 step:20907[D loss: 0.418295, acc: 62.50%, op_acc: 39.84%] [G loss: 0.958341]\n",
      "epoch:26 step:20908[D loss: 0.377059, acc: 67.97%, op_acc: 46.09%] [G loss: 0.885959]\n",
      "epoch:26 step:20909[D loss: 0.379368, acc: 68.75%, op_acc: 42.97%] [G loss: 0.829459]\n",
      "epoch:26 step:20910[D loss: 0.436732, acc: 57.03%, op_acc: 37.50%] [G loss: 0.934404]\n",
      "epoch:26 step:20911[D loss: 0.416581, acc: 59.38%, op_acc: 41.41%] [G loss: 0.843965]\n",
      "epoch:26 step:20912[D loss: 0.417836, acc: 57.03%, op_acc: 41.41%] [G loss: 0.807512]\n",
      "epoch:26 step:20913[D loss: 0.414309, acc: 54.69%, op_acc: 45.31%] [G loss: 0.878990]\n",
      "epoch:26 step:20914[D loss: 0.407058, acc: 63.28%, op_acc: 41.41%] [G loss: 0.845759]\n",
      "epoch:26 step:20915[D loss: 0.421643, acc: 54.69%, op_acc: 41.41%] [G loss: 0.933955]\n",
      "epoch:26 step:20916[D loss: 0.405468, acc: 67.19%, op_acc: 33.59%] [G loss: 0.980265]\n",
      "epoch:26 step:20917[D loss: 0.417039, acc: 61.72%, op_acc: 44.53%] [G loss: 0.868476]\n",
      "epoch:26 step:20918[D loss: 0.398817, acc: 64.84%, op_acc: 45.31%] [G loss: 0.876662]\n",
      "epoch:26 step:20919[D loss: 0.406682, acc: 57.03%, op_acc: 42.19%] [G loss: 0.816820]\n",
      "epoch:26 step:20920[D loss: 0.431150, acc: 57.81%, op_acc: 35.16%] [G loss: 0.828608]\n",
      "epoch:26 step:20921[D loss: 0.434122, acc: 66.41%, op_acc: 39.84%] [G loss: 0.837284]\n",
      "epoch:26 step:20922[D loss: 0.460343, acc: 52.34%, op_acc: 40.62%] [G loss: 0.858356]\n",
      "epoch:26 step:20923[D loss: 0.484767, acc: 45.31%, op_acc: 35.16%] [G loss: 0.928080]\n",
      "epoch:26 step:20924[D loss: 0.416009, acc: 55.47%, op_acc: 41.41%] [G loss: 0.866641]\n",
      "epoch:26 step:20925[D loss: 0.424941, acc: 60.16%, op_acc: 36.72%] [G loss: 0.875883]\n",
      "epoch:26 step:20926[D loss: 0.414394, acc: 60.16%, op_acc: 38.28%] [G loss: 1.010189]\n",
      "epoch:26 step:20927[D loss: 0.399689, acc: 66.41%, op_acc: 44.53%] [G loss: 0.901942]\n",
      "epoch:26 step:20928[D loss: 0.424268, acc: 64.06%, op_acc: 37.50%] [G loss: 0.962579]\n",
      "epoch:26 step:20929[D loss: 0.422205, acc: 55.47%, op_acc: 45.31%] [G loss: 0.941416]\n",
      "epoch:26 step:20930[D loss: 0.426960, acc: 51.56%, op_acc: 43.75%] [G loss: 0.949497]\n",
      "epoch:26 step:20931[D loss: 0.443532, acc: 58.59%, op_acc: 40.62%] [G loss: 0.902801]\n",
      "epoch:26 step:20932[D loss: 0.424550, acc: 60.16%, op_acc: 39.84%] [G loss: 0.901520]\n",
      "epoch:26 step:20933[D loss: 0.426036, acc: 55.47%, op_acc: 40.62%] [G loss: 0.791525]\n",
      "epoch:26 step:20934[D loss: 0.422241, acc: 57.81%, op_acc: 35.16%] [G loss: 0.891727]\n",
      "epoch:26 step:20935[D loss: 0.434630, acc: 53.91%, op_acc: 45.31%] [G loss: 0.724794]\n",
      "epoch:26 step:20936[D loss: 0.400768, acc: 58.59%, op_acc: 39.84%] [G loss: 0.849949]\n",
      "epoch:26 step:20937[D loss: 0.424384, acc: 60.94%, op_acc: 35.94%] [G loss: 0.926858]\n",
      "epoch:26 step:20938[D loss: 0.421724, acc: 61.72%, op_acc: 43.75%] [G loss: 0.860930]\n",
      "epoch:26 step:20939[D loss: 0.429189, acc: 55.47%, op_acc: 36.72%] [G loss: 0.746327]\n",
      "epoch:26 step:20940[D loss: 0.436029, acc: 52.34%, op_acc: 42.97%] [G loss: 0.799772]\n",
      "epoch:26 step:20941[D loss: 0.415060, acc: 64.06%, op_acc: 42.19%] [G loss: 0.879119]\n",
      "epoch:26 step:20942[D loss: 0.401927, acc: 61.72%, op_acc: 42.97%] [G loss: 0.893003]\n",
      "epoch:26 step:20943[D loss: 0.410992, acc: 70.31%, op_acc: 39.84%] [G loss: 0.878139]\n",
      "epoch:26 step:20944[D loss: 0.414253, acc: 60.94%, op_acc: 41.41%] [G loss: 0.917701]\n",
      "epoch:26 step:20945[D loss: 0.404241, acc: 63.28%, op_acc: 46.09%] [G loss: 0.897114]\n",
      "epoch:26 step:20946[D loss: 0.435789, acc: 60.16%, op_acc: 38.28%] [G loss: 0.829321]\n",
      "epoch:26 step:20947[D loss: 0.444946, acc: 55.47%, op_acc: 33.59%] [G loss: 0.788732]\n",
      "epoch:26 step:20948[D loss: 0.420582, acc: 60.16%, op_acc: 39.84%] [G loss: 0.887407]\n",
      "epoch:26 step:20949[D loss: 0.470171, acc: 53.91%, op_acc: 34.38%] [G loss: 0.744361]\n",
      "epoch:26 step:20950[D loss: 0.392366, acc: 57.81%, op_acc: 46.09%] [G loss: 0.900226]\n",
      "epoch:26 step:20951[D loss: 0.386066, acc: 71.09%, op_acc: 46.09%] [G loss: 0.848600]\n",
      "epoch:26 step:20952[D loss: 0.411300, acc: 62.50%, op_acc: 38.28%] [G loss: 1.022624]\n",
      "epoch:26 step:20953[D loss: 0.418874, acc: 57.81%, op_acc: 46.88%] [G loss: 0.911950]\n",
      "epoch:26 step:20954[D loss: 0.420758, acc: 58.59%, op_acc: 39.84%] [G loss: 0.855649]\n",
      "epoch:26 step:20955[D loss: 0.431071, acc: 54.69%, op_acc: 34.38%] [G loss: 0.915445]\n",
      "epoch:26 step:20956[D loss: 0.434093, acc: 57.81%, op_acc: 35.16%] [G loss: 0.867830]\n",
      "epoch:26 step:20957[D loss: 0.412891, acc: 65.62%, op_acc: 37.50%] [G loss: 0.924873]\n",
      "epoch:26 step:20958[D loss: 0.368351, acc: 71.09%, op_acc: 47.66%] [G loss: 0.910055]\n",
      "epoch:26 step:20959[D loss: 0.399443, acc: 62.50%, op_acc: 44.53%] [G loss: 0.964295]\n",
      "epoch:26 step:20960[D loss: 0.418606, acc: 56.25%, op_acc: 40.62%] [G loss: 0.905130]\n",
      "epoch:26 step:20961[D loss: 0.435175, acc: 51.56%, op_acc: 40.62%] [G loss: 0.881270]\n",
      "epoch:26 step:20962[D loss: 0.434237, acc: 57.03%, op_acc: 34.38%] [G loss: 0.866783]\n",
      "epoch:26 step:20963[D loss: 0.428023, acc: 57.81%, op_acc: 36.72%] [G loss: 0.847072]\n",
      "epoch:26 step:20964[D loss: 0.431686, acc: 60.94%, op_acc: 32.81%] [G loss: 0.920498]\n",
      "epoch:26 step:20965[D loss: 0.409122, acc: 65.62%, op_acc: 42.19%] [G loss: 0.896218]\n",
      "epoch:26 step:20966[D loss: 0.437257, acc: 56.25%, op_acc: 37.50%] [G loss: 0.963632]\n",
      "epoch:26 step:20967[D loss: 0.414036, acc: 57.03%, op_acc: 37.50%] [G loss: 0.850421]\n",
      "epoch:26 step:20968[D loss: 0.411466, acc: 52.34%, op_acc: 42.97%] [G loss: 0.855813]\n",
      "epoch:26 step:20969[D loss: 0.418807, acc: 53.12%, op_acc: 39.84%] [G loss: 0.943540]\n",
      "epoch:26 step:20970[D loss: 0.415695, acc: 57.81%, op_acc: 39.06%] [G loss: 0.889589]\n",
      "epoch:26 step:20971[D loss: 0.426619, acc: 61.72%, op_acc: 35.16%] [G loss: 0.896815]\n",
      "epoch:26 step:20972[D loss: 0.394858, acc: 68.75%, op_acc: 36.72%] [G loss: 0.948043]\n",
      "epoch:26 step:20973[D loss: 0.414779, acc: 62.50%, op_acc: 39.06%] [G loss: 0.914245]\n",
      "epoch:26 step:20974[D loss: 0.439567, acc: 48.44%, op_acc: 42.97%] [G loss: 0.949968]\n",
      "epoch:26 step:20975[D loss: 0.409026, acc: 59.38%, op_acc: 45.31%] [G loss: 0.909896]\n",
      "epoch:26 step:20976[D loss: 0.415126, acc: 58.59%, op_acc: 41.41%] [G loss: 0.833583]\n",
      "epoch:26 step:20977[D loss: 0.419051, acc: 59.38%, op_acc: 39.84%] [G loss: 0.949985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:20978[D loss: 0.423619, acc: 60.94%, op_acc: 37.50%] [G loss: 0.897697]\n",
      "epoch:26 step:20979[D loss: 0.447454, acc: 57.03%, op_acc: 33.59%] [G loss: 0.852914]\n",
      "epoch:26 step:20980[D loss: 0.423889, acc: 57.03%, op_acc: 44.53%] [G loss: 0.933155]\n",
      "epoch:26 step:20981[D loss: 0.419173, acc: 61.72%, op_acc: 37.50%] [G loss: 0.802659]\n",
      "epoch:26 step:20982[D loss: 0.431812, acc: 57.03%, op_acc: 36.72%] [G loss: 0.909767]\n",
      "epoch:26 step:20983[D loss: 0.441744, acc: 61.72%, op_acc: 32.81%] [G loss: 0.904265]\n",
      "epoch:26 step:20984[D loss: 0.416866, acc: 57.81%, op_acc: 41.41%] [G loss: 0.861073]\n",
      "epoch:26 step:20985[D loss: 0.361405, acc: 66.41%, op_acc: 43.75%] [G loss: 0.887949]\n",
      "epoch:26 step:20986[D loss: 0.402331, acc: 74.22%, op_acc: 35.94%] [G loss: 0.832733]\n",
      "epoch:26 step:20987[D loss: 0.445373, acc: 62.50%, op_acc: 34.38%] [G loss: 0.927984]\n",
      "epoch:26 step:20988[D loss: 0.414938, acc: 57.03%, op_acc: 40.62%] [G loss: 0.936624]\n",
      "epoch:26 step:20989[D loss: 0.427840, acc: 54.69%, op_acc: 41.41%] [G loss: 0.936895]\n",
      "epoch:26 step:20990[D loss: 0.444804, acc: 56.25%, op_acc: 36.72%] [G loss: 0.876668]\n",
      "epoch:26 step:20991[D loss: 0.428852, acc: 56.25%, op_acc: 40.62%] [G loss: 0.939935]\n",
      "epoch:26 step:20992[D loss: 0.433271, acc: 57.81%, op_acc: 36.72%] [G loss: 0.902055]\n",
      "epoch:26 step:20993[D loss: 0.399699, acc: 62.50%, op_acc: 40.62%] [G loss: 0.880715]\n",
      "epoch:26 step:20994[D loss: 0.394379, acc: 65.62%, op_acc: 44.53%] [G loss: 0.903103]\n",
      "epoch:26 step:20995[D loss: 0.381784, acc: 64.84%, op_acc: 43.75%] [G loss: 0.984306]\n",
      "epoch:26 step:20996[D loss: 0.421015, acc: 67.19%, op_acc: 41.41%] [G loss: 0.974513]\n",
      "epoch:26 step:20997[D loss: 0.395788, acc: 67.19%, op_acc: 38.28%] [G loss: 0.905782]\n",
      "epoch:26 step:20998[D loss: 0.450839, acc: 55.47%, op_acc: 37.50%] [G loss: 0.913903]\n",
      "epoch:26 step:20999[D loss: 0.447381, acc: 51.56%, op_acc: 37.50%] [G loss: 0.889195]\n",
      "epoch:26 step:21000[D loss: 0.423313, acc: 60.94%, op_acc: 41.41%] [G loss: 0.902845]\n",
      "epoch:26 step:21001[D loss: 0.391859, acc: 67.19%, op_acc: 35.94%] [G loss: 0.867553]\n",
      "epoch:26 step:21002[D loss: 0.420067, acc: 59.38%, op_acc: 39.06%] [G loss: 0.868605]\n",
      "epoch:26 step:21003[D loss: 0.414892, acc: 56.25%, op_acc: 43.75%] [G loss: 0.924061]\n",
      "epoch:26 step:21004[D loss: 0.455202, acc: 49.22%, op_acc: 42.97%] [G loss: 0.826950]\n",
      "epoch:26 step:21005[D loss: 0.408753, acc: 57.81%, op_acc: 39.06%] [G loss: 0.821443]\n",
      "epoch:26 step:21006[D loss: 0.430022, acc: 55.47%, op_acc: 37.50%] [G loss: 0.856858]\n",
      "epoch:26 step:21007[D loss: 0.436164, acc: 53.91%, op_acc: 36.72%] [G loss: 0.905290]\n",
      "epoch:26 step:21008[D loss: 0.440560, acc: 53.91%, op_acc: 39.06%] [G loss: 0.778615]\n",
      "epoch:26 step:21009[D loss: 0.437203, acc: 61.72%, op_acc: 39.84%] [G loss: 0.780923]\n",
      "epoch:26 step:21010[D loss: 0.407980, acc: 60.94%, op_acc: 42.19%] [G loss: 0.815045]\n",
      "epoch:26 step:21011[D loss: 0.410390, acc: 64.84%, op_acc: 44.53%] [G loss: 0.904581]\n",
      "epoch:26 step:21012[D loss: 0.432541, acc: 53.91%, op_acc: 42.97%] [G loss: 0.960945]\n",
      "epoch:26 step:21013[D loss: 0.464427, acc: 47.66%, op_acc: 37.50%] [G loss: 0.841333]\n",
      "epoch:26 step:21014[D loss: 0.412021, acc: 56.25%, op_acc: 39.06%] [G loss: 0.935483]\n",
      "epoch:26 step:21015[D loss: 0.405334, acc: 70.31%, op_acc: 34.38%] [G loss: 0.920410]\n",
      "epoch:26 step:21016[D loss: 0.401061, acc: 64.06%, op_acc: 44.53%] [G loss: 0.963980]\n",
      "epoch:26 step:21017[D loss: 0.395497, acc: 70.31%, op_acc: 38.28%] [G loss: 0.907061]\n",
      "epoch:26 step:21018[D loss: 0.421925, acc: 56.25%, op_acc: 42.97%] [G loss: 1.006300]\n",
      "epoch:26 step:21019[D loss: 0.414678, acc: 57.03%, op_acc: 43.75%] [G loss: 1.005042]\n",
      "epoch:26 step:21020[D loss: 0.412974, acc: 64.06%, op_acc: 38.28%] [G loss: 0.995711]\n",
      "epoch:26 step:21021[D loss: 0.398694, acc: 65.62%, op_acc: 42.97%] [G loss: 0.894242]\n",
      "epoch:26 step:21022[D loss: 0.436254, acc: 57.81%, op_acc: 39.84%] [G loss: 1.007531]\n",
      "epoch:26 step:21023[D loss: 0.396187, acc: 57.81%, op_acc: 44.53%] [G loss: 0.913863]\n",
      "epoch:26 step:21024[D loss: 0.423893, acc: 60.94%, op_acc: 39.06%] [G loss: 0.956103]\n",
      "epoch:26 step:21025[D loss: 0.427039, acc: 60.16%, op_acc: 39.84%] [G loss: 0.920402]\n",
      "epoch:26 step:21026[D loss: 0.414986, acc: 63.28%, op_acc: 33.59%] [G loss: 0.880770]\n",
      "epoch:26 step:21027[D loss: 0.450358, acc: 54.69%, op_acc: 38.28%] [G loss: 0.765420]\n",
      "epoch:26 step:21028[D loss: 0.440146, acc: 53.12%, op_acc: 41.41%] [G loss: 0.892303]\n",
      "epoch:26 step:21029[D loss: 0.421053, acc: 58.59%, op_acc: 39.84%] [G loss: 0.864477]\n",
      "epoch:26 step:21030[D loss: 0.428742, acc: 58.59%, op_acc: 35.94%] [G loss: 0.901349]\n",
      "epoch:26 step:21031[D loss: 0.426170, acc: 60.94%, op_acc: 35.16%] [G loss: 0.944106]\n",
      "epoch:26 step:21032[D loss: 0.427802, acc: 56.25%, op_acc: 43.75%] [G loss: 0.874944]\n",
      "epoch:26 step:21033[D loss: 0.444328, acc: 58.59%, op_acc: 38.28%] [G loss: 0.970572]\n",
      "epoch:26 step:21034[D loss: 0.443313, acc: 54.69%, op_acc: 39.84%] [G loss: 0.876306]\n",
      "epoch:26 step:21035[D loss: 0.404098, acc: 66.41%, op_acc: 38.28%] [G loss: 0.912290]\n",
      "epoch:26 step:21036[D loss: 0.415178, acc: 60.94%, op_acc: 38.28%] [G loss: 0.903552]\n",
      "epoch:26 step:21037[D loss: 0.417684, acc: 58.59%, op_acc: 42.97%] [G loss: 0.882256]\n",
      "epoch:26 step:21038[D loss: 0.435334, acc: 57.03%, op_acc: 36.72%] [G loss: 1.004257]\n",
      "epoch:26 step:21039[D loss: 0.401313, acc: 61.72%, op_acc: 43.75%] [G loss: 0.951065]\n",
      "epoch:26 step:21040[D loss: 0.421099, acc: 63.28%, op_acc: 42.97%] [G loss: 0.929601]\n",
      "epoch:26 step:21041[D loss: 0.424818, acc: 56.25%, op_acc: 42.97%] [G loss: 0.787116]\n",
      "epoch:26 step:21042[D loss: 0.400856, acc: 67.97%, op_acc: 42.97%] [G loss: 0.905199]\n",
      "epoch:26 step:21043[D loss: 0.415274, acc: 60.16%, op_acc: 39.06%] [G loss: 0.904766]\n",
      "epoch:26 step:21044[D loss: 0.425592, acc: 59.38%, op_acc: 45.31%] [G loss: 0.809892]\n",
      "epoch:26 step:21045[D loss: 0.419517, acc: 64.06%, op_acc: 42.19%] [G loss: 0.791349]\n",
      "epoch:26 step:21046[D loss: 0.409478, acc: 60.16%, op_acc: 44.53%] [G loss: 0.847501]\n",
      "epoch:26 step:21047[D loss: 0.412705, acc: 67.19%, op_acc: 37.50%] [G loss: 0.911270]\n",
      "epoch:26 step:21048[D loss: 0.444129, acc: 58.59%, op_acc: 42.19%] [G loss: 0.820990]\n",
      "epoch:26 step:21049[D loss: 0.452764, acc: 52.34%, op_acc: 36.72%] [G loss: 0.820793]\n",
      "epoch:26 step:21050[D loss: 0.435996, acc: 50.78%, op_acc: 46.09%] [G loss: 0.801031]\n",
      "epoch:26 step:21051[D loss: 0.403061, acc: 63.28%, op_acc: 38.28%] [G loss: 0.910652]\n",
      "epoch:26 step:21052[D loss: 0.421081, acc: 57.81%, op_acc: 37.50%] [G loss: 0.929755]\n",
      "epoch:26 step:21053[D loss: 0.398924, acc: 67.97%, op_acc: 39.06%] [G loss: 0.871277]\n",
      "epoch:26 step:21054[D loss: 0.446202, acc: 53.91%, op_acc: 39.84%] [G loss: 0.790227]\n",
      "epoch:26 step:21055[D loss: 0.436323, acc: 59.38%, op_acc: 42.97%] [G loss: 0.936016]\n",
      "epoch:26 step:21056[D loss: 0.433934, acc: 50.00%, op_acc: 37.50%] [G loss: 0.946142]\n",
      "epoch:26 step:21057[D loss: 0.412912, acc: 70.31%, op_acc: 35.16%] [G loss: 0.955590]\n",
      "epoch:26 step:21058[D loss: 0.398432, acc: 64.84%, op_acc: 43.75%] [G loss: 0.910675]\n",
      "epoch:26 step:21059[D loss: 0.413679, acc: 61.72%, op_acc: 39.06%] [G loss: 0.949471]\n",
      "epoch:26 step:21060[D loss: 0.417196, acc: 60.16%, op_acc: 41.41%] [G loss: 0.857292]\n",
      "epoch:26 step:21061[D loss: 0.399287, acc: 68.75%, op_acc: 42.19%] [G loss: 0.981442]\n",
      "epoch:26 step:21062[D loss: 0.417763, acc: 57.81%, op_acc: 39.84%] [G loss: 0.880448]\n",
      "epoch:26 step:21063[D loss: 0.398418, acc: 68.75%, op_acc: 41.41%] [G loss: 0.893884]\n",
      "epoch:26 step:21064[D loss: 0.408883, acc: 60.16%, op_acc: 43.75%] [G loss: 0.940251]\n",
      "epoch:26 step:21065[D loss: 0.415427, acc: 61.72%, op_acc: 39.06%] [G loss: 0.942726]\n",
      "epoch:26 step:21066[D loss: 0.447164, acc: 50.78%, op_acc: 37.50%] [G loss: 0.862539]\n",
      "epoch:26 step:21067[D loss: 0.417429, acc: 55.47%, op_acc: 40.62%] [G loss: 0.882130]\n",
      "epoch:26 step:21068[D loss: 0.439463, acc: 55.47%, op_acc: 37.50%] [G loss: 0.987100]\n",
      "epoch:26 step:21069[D loss: 0.412969, acc: 56.25%, op_acc: 42.97%] [G loss: 0.952662]\n",
      "epoch:26 step:21070[D loss: 0.414758, acc: 60.16%, op_acc: 40.62%] [G loss: 0.788256]\n",
      "epoch:26 step:21071[D loss: 0.381122, acc: 64.84%, op_acc: 44.53%] [G loss: 0.923553]\n",
      "epoch:26 step:21072[D loss: 0.455843, acc: 48.44%, op_acc: 37.50%] [G loss: 0.955120]\n",
      "epoch:26 step:21073[D loss: 0.391136, acc: 64.84%, op_acc: 39.06%] [G loss: 0.952633]\n",
      "epoch:26 step:21074[D loss: 0.445097, acc: 52.34%, op_acc: 39.84%] [G loss: 0.797076]\n",
      "epoch:26 step:21075[D loss: 0.395811, acc: 70.31%, op_acc: 43.75%] [G loss: 0.929360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:21076[D loss: 0.419329, acc: 57.03%, op_acc: 49.22%] [G loss: 0.800958]\n",
      "epoch:26 step:21077[D loss: 0.435273, acc: 58.59%, op_acc: 35.16%] [G loss: 0.914393]\n",
      "epoch:26 step:21078[D loss: 0.438179, acc: 57.81%, op_acc: 38.28%] [G loss: 0.905513]\n",
      "epoch:26 step:21079[D loss: 0.419667, acc: 65.62%, op_acc: 37.50%] [G loss: 0.917055]\n",
      "epoch:26 step:21080[D loss: 0.428123, acc: 61.72%, op_acc: 43.75%] [G loss: 0.888326]\n",
      "epoch:26 step:21081[D loss: 0.432769, acc: 60.16%, op_acc: 35.94%] [G loss: 0.810151]\n",
      "epoch:26 step:21082[D loss: 0.429522, acc: 55.47%, op_acc: 39.06%] [G loss: 0.797964]\n",
      "epoch:26 step:21083[D loss: 0.423813, acc: 56.25%, op_acc: 38.28%] [G loss: 0.879395]\n",
      "epoch:26 step:21084[D loss: 0.416505, acc: 62.50%, op_acc: 39.84%] [G loss: 0.927179]\n",
      "epoch:26 step:21085[D loss: 0.410911, acc: 60.16%, op_acc: 36.72%] [G loss: 0.897856]\n",
      "epoch:26 step:21086[D loss: 0.385716, acc: 58.59%, op_acc: 48.44%] [G loss: 0.903416]\n",
      "epoch:26 step:21087[D loss: 0.413832, acc: 61.72%, op_acc: 42.97%] [G loss: 0.805462]\n",
      "epoch:27 step:21088[D loss: 0.387210, acc: 69.53%, op_acc: 44.53%] [G loss: 0.811422]\n",
      "epoch:27 step:21089[D loss: 0.417084, acc: 57.03%, op_acc: 42.97%] [G loss: 0.901492]\n",
      "epoch:27 step:21090[D loss: 0.417271, acc: 59.38%, op_acc: 42.19%] [G loss: 0.855913]\n",
      "epoch:27 step:21091[D loss: 0.389424, acc: 54.69%, op_acc: 45.31%] [G loss: 0.926608]\n",
      "epoch:27 step:21092[D loss: 0.421220, acc: 58.59%, op_acc: 36.72%] [G loss: 0.873390]\n",
      "epoch:27 step:21093[D loss: 0.417593, acc: 64.06%, op_acc: 42.19%] [G loss: 0.965716]\n",
      "epoch:27 step:21094[D loss: 0.420417, acc: 60.16%, op_acc: 46.09%] [G loss: 0.963822]\n",
      "epoch:27 step:21095[D loss: 0.390719, acc: 68.75%, op_acc: 40.62%] [G loss: 0.934347]\n",
      "epoch:27 step:21096[D loss: 0.404277, acc: 53.91%, op_acc: 45.31%] [G loss: 0.927677]\n",
      "epoch:27 step:21097[D loss: 0.418435, acc: 60.94%, op_acc: 41.41%] [G loss: 0.932925]\n",
      "epoch:27 step:21098[D loss: 0.434541, acc: 64.06%, op_acc: 39.06%] [G loss: 0.786925]\n",
      "epoch:27 step:21099[D loss: 0.404814, acc: 64.06%, op_acc: 36.72%] [G loss: 0.980084]\n",
      "epoch:27 step:21100[D loss: 0.403576, acc: 68.75%, op_acc: 44.53%] [G loss: 0.922099]\n",
      "epoch:27 step:21101[D loss: 0.416779, acc: 63.28%, op_acc: 36.72%] [G loss: 0.895687]\n",
      "epoch:27 step:21102[D loss: 0.413662, acc: 56.25%, op_acc: 42.19%] [G loss: 0.949459]\n",
      "epoch:27 step:21103[D loss: 0.381604, acc: 68.75%, op_acc: 39.06%] [G loss: 0.915490]\n",
      "epoch:27 step:21104[D loss: 0.430899, acc: 57.81%, op_acc: 38.28%] [G loss: 0.878255]\n",
      "epoch:27 step:21105[D loss: 0.402828, acc: 61.72%, op_acc: 40.62%] [G loss: 0.855399]\n",
      "epoch:27 step:21106[D loss: 0.413621, acc: 60.94%, op_acc: 43.75%] [G loss: 0.966883]\n",
      "epoch:27 step:21107[D loss: 0.422518, acc: 62.50%, op_acc: 39.06%] [G loss: 0.933969]\n",
      "epoch:27 step:21108[D loss: 0.424680, acc: 59.38%, op_acc: 39.06%] [G loss: 0.907932]\n",
      "epoch:27 step:21109[D loss: 0.451779, acc: 52.34%, op_acc: 37.50%] [G loss: 0.827049]\n",
      "epoch:27 step:21110[D loss: 0.375673, acc: 66.41%, op_acc: 44.53%] [G loss: 0.817454]\n",
      "epoch:27 step:21111[D loss: 0.432177, acc: 67.19%, op_acc: 35.16%] [G loss: 0.891008]\n",
      "epoch:27 step:21112[D loss: 0.468672, acc: 53.91%, op_acc: 35.16%] [G loss: 0.951391]\n",
      "epoch:27 step:21113[D loss: 0.403109, acc: 63.28%, op_acc: 42.97%] [G loss: 0.989259]\n",
      "epoch:27 step:21114[D loss: 0.422228, acc: 60.16%, op_acc: 40.62%] [G loss: 0.944550]\n",
      "epoch:27 step:21115[D loss: 0.441680, acc: 53.12%, op_acc: 46.09%] [G loss: 0.885241]\n",
      "epoch:27 step:21116[D loss: 0.416053, acc: 59.38%, op_acc: 42.19%] [G loss: 0.910072]\n",
      "epoch:27 step:21117[D loss: 0.431635, acc: 49.22%, op_acc: 42.19%] [G loss: 0.906954]\n",
      "epoch:27 step:21118[D loss: 0.451382, acc: 58.59%, op_acc: 38.28%] [G loss: 0.936633]\n",
      "epoch:27 step:21119[D loss: 0.444250, acc: 57.81%, op_acc: 42.19%] [G loss: 0.991180]\n",
      "epoch:27 step:21120[D loss: 0.413162, acc: 57.81%, op_acc: 42.19%] [G loss: 0.931024]\n",
      "epoch:27 step:21121[D loss: 0.387808, acc: 67.19%, op_acc: 46.88%] [G loss: 0.850222]\n",
      "epoch:27 step:21122[D loss: 0.433820, acc: 57.81%, op_acc: 39.84%] [G loss: 0.905419]\n",
      "epoch:27 step:21123[D loss: 0.411973, acc: 61.72%, op_acc: 39.06%] [G loss: 0.907634]\n",
      "epoch:27 step:21124[D loss: 0.394256, acc: 62.50%, op_acc: 48.44%] [G loss: 0.917208]\n",
      "epoch:27 step:21125[D loss: 0.420699, acc: 62.50%, op_acc: 39.84%] [G loss: 0.928666]\n",
      "epoch:27 step:21126[D loss: 0.393320, acc: 62.50%, op_acc: 42.97%] [G loss: 1.005031]\n",
      "epoch:27 step:21127[D loss: 0.428662, acc: 63.28%, op_acc: 37.50%] [G loss: 0.916277]\n",
      "epoch:27 step:21128[D loss: 0.391214, acc: 64.06%, op_acc: 46.88%] [G loss: 0.927428]\n",
      "epoch:27 step:21129[D loss: 0.375453, acc: 67.97%, op_acc: 46.88%] [G loss: 0.876768]\n",
      "epoch:27 step:21130[D loss: 0.412586, acc: 68.75%, op_acc: 38.28%] [G loss: 0.724297]\n",
      "epoch:27 step:21131[D loss: 0.408592, acc: 60.16%, op_acc: 48.44%] [G loss: 0.856060]\n",
      "epoch:27 step:21132[D loss: 0.414280, acc: 61.72%, op_acc: 38.28%] [G loss: 0.857719]\n",
      "epoch:27 step:21133[D loss: 0.413795, acc: 67.19%, op_acc: 40.62%] [G loss: 0.888522]\n",
      "epoch:27 step:21134[D loss: 0.441207, acc: 53.91%, op_acc: 38.28%] [G loss: 0.924369]\n",
      "epoch:27 step:21135[D loss: 0.428926, acc: 67.97%, op_acc: 36.72%] [G loss: 0.922127]\n",
      "epoch:27 step:21136[D loss: 0.405589, acc: 63.28%, op_acc: 39.84%] [G loss: 0.838035]\n",
      "epoch:27 step:21137[D loss: 0.433891, acc: 61.72%, op_acc: 34.38%] [G loss: 0.860659]\n",
      "epoch:27 step:21138[D loss: 0.383142, acc: 64.84%, op_acc: 41.41%] [G loss: 0.808334]\n",
      "epoch:27 step:21139[D loss: 0.390623, acc: 67.19%, op_acc: 39.84%] [G loss: 0.877745]\n",
      "epoch:27 step:21140[D loss: 0.465151, acc: 54.69%, op_acc: 35.16%] [G loss: 0.839131]\n",
      "epoch:27 step:21141[D loss: 0.412545, acc: 62.50%, op_acc: 41.41%] [G loss: 0.983011]\n",
      "epoch:27 step:21142[D loss: 0.418105, acc: 61.72%, op_acc: 35.16%] [G loss: 0.817988]\n",
      "epoch:27 step:21143[D loss: 0.420936, acc: 64.84%, op_acc: 42.19%] [G loss: 0.910842]\n",
      "epoch:27 step:21144[D loss: 0.411133, acc: 64.06%, op_acc: 35.94%] [G loss: 0.851271]\n",
      "epoch:27 step:21145[D loss: 0.368243, acc: 70.31%, op_acc: 47.66%] [G loss: 0.880805]\n",
      "epoch:27 step:21146[D loss: 0.417202, acc: 58.59%, op_acc: 41.41%] [G loss: 0.799690]\n",
      "epoch:27 step:21147[D loss: 0.417325, acc: 62.50%, op_acc: 37.50%] [G loss: 0.928958]\n",
      "epoch:27 step:21148[D loss: 0.437016, acc: 62.50%, op_acc: 38.28%] [G loss: 0.861232]\n",
      "epoch:27 step:21149[D loss: 0.409255, acc: 64.84%, op_acc: 44.53%] [G loss: 0.963988]\n",
      "epoch:27 step:21150[D loss: 0.424590, acc: 53.12%, op_acc: 42.19%] [G loss: 0.934126]\n",
      "epoch:27 step:21151[D loss: 0.420548, acc: 59.38%, op_acc: 41.41%] [G loss: 0.901352]\n",
      "epoch:27 step:21152[D loss: 0.438143, acc: 60.94%, op_acc: 39.06%] [G loss: 0.936473]\n",
      "epoch:27 step:21153[D loss: 0.434477, acc: 51.56%, op_acc: 39.06%] [G loss: 0.929761]\n",
      "epoch:27 step:21154[D loss: 0.405214, acc: 65.62%, op_acc: 44.53%] [G loss: 0.949713]\n",
      "epoch:27 step:21155[D loss: 0.452706, acc: 53.91%, op_acc: 39.84%] [G loss: 0.960606]\n",
      "epoch:27 step:21156[D loss: 0.398402, acc: 64.84%, op_acc: 46.09%] [G loss: 0.978447]\n",
      "epoch:27 step:21157[D loss: 0.420976, acc: 59.38%, op_acc: 40.62%] [G loss: 0.882839]\n",
      "epoch:27 step:21158[D loss: 0.416662, acc: 64.84%, op_acc: 36.72%] [G loss: 0.792614]\n",
      "epoch:27 step:21159[D loss: 0.425023, acc: 57.81%, op_acc: 40.62%] [G loss: 0.947454]\n",
      "epoch:27 step:21160[D loss: 0.399940, acc: 66.41%, op_acc: 44.53%] [G loss: 1.042576]\n",
      "epoch:27 step:21161[D loss: 0.400990, acc: 66.41%, op_acc: 42.19%] [G loss: 0.840808]\n",
      "epoch:27 step:21162[D loss: 0.407140, acc: 62.50%, op_acc: 37.50%] [G loss: 0.914572]\n",
      "epoch:27 step:21163[D loss: 0.443063, acc: 53.12%, op_acc: 39.84%] [G loss: 0.841021]\n",
      "epoch:27 step:21164[D loss: 0.421344, acc: 59.38%, op_acc: 37.50%] [G loss: 0.932474]\n",
      "epoch:27 step:21165[D loss: 0.424118, acc: 64.84%, op_acc: 36.72%] [G loss: 0.801708]\n",
      "epoch:27 step:21166[D loss: 0.417843, acc: 58.59%, op_acc: 42.97%] [G loss: 0.927806]\n",
      "epoch:27 step:21167[D loss: 0.452956, acc: 53.12%, op_acc: 29.69%] [G loss: 0.980997]\n",
      "epoch:27 step:21168[D loss: 0.417260, acc: 61.72%, op_acc: 41.41%] [G loss: 0.915152]\n",
      "epoch:27 step:21169[D loss: 0.389223, acc: 70.31%, op_acc: 42.19%] [G loss: 0.910401]\n",
      "epoch:27 step:21170[D loss: 0.395999, acc: 67.97%, op_acc: 40.62%] [G loss: 0.812756]\n",
      "epoch:27 step:21171[D loss: 0.399625, acc: 65.62%, op_acc: 45.31%] [G loss: 0.902188]\n",
      "epoch:27 step:21172[D loss: 0.417988, acc: 66.41%, op_acc: 33.59%] [G loss: 0.986621]\n",
      "epoch:27 step:21173[D loss: 0.440166, acc: 57.81%, op_acc: 43.75%] [G loss: 0.910950]\n",
      "epoch:27 step:21174[D loss: 0.413308, acc: 57.81%, op_acc: 37.50%] [G loss: 0.920356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21175[D loss: 0.434755, acc: 55.47%, op_acc: 37.50%] [G loss: 0.865378]\n",
      "epoch:27 step:21176[D loss: 0.419184, acc: 59.38%, op_acc: 46.88%] [G loss: 0.925539]\n",
      "epoch:27 step:21177[D loss: 0.438505, acc: 54.69%, op_acc: 37.50%] [G loss: 0.939687]\n",
      "epoch:27 step:21178[D loss: 0.438182, acc: 51.56%, op_acc: 35.94%] [G loss: 0.811456]\n",
      "epoch:27 step:21179[D loss: 0.435020, acc: 61.72%, op_acc: 38.28%] [G loss: 0.832736]\n",
      "epoch:27 step:21180[D loss: 0.421064, acc: 61.72%, op_acc: 37.50%] [G loss: 0.926611]\n",
      "epoch:27 step:21181[D loss: 0.411204, acc: 58.59%, op_acc: 42.19%] [G loss: 0.878724]\n",
      "epoch:27 step:21182[D loss: 0.388073, acc: 68.75%, op_acc: 39.06%] [G loss: 0.856812]\n",
      "epoch:27 step:21183[D loss: 0.423996, acc: 56.25%, op_acc: 39.06%] [G loss: 0.940114]\n",
      "epoch:27 step:21184[D loss: 0.420837, acc: 56.25%, op_acc: 38.28%] [G loss: 0.932724]\n",
      "epoch:27 step:21185[D loss: 0.439508, acc: 59.38%, op_acc: 35.16%] [G loss: 0.835124]\n",
      "epoch:27 step:21186[D loss: 0.452281, acc: 53.91%, op_acc: 41.41%] [G loss: 0.878859]\n",
      "epoch:27 step:21187[D loss: 0.402076, acc: 63.28%, op_acc: 44.53%] [G loss: 0.879614]\n",
      "epoch:27 step:21188[D loss: 0.447455, acc: 51.56%, op_acc: 32.03%] [G loss: 0.898437]\n",
      "epoch:27 step:21189[D loss: 0.431146, acc: 53.91%, op_acc: 41.41%] [G loss: 0.986910]\n",
      "epoch:27 step:21190[D loss: 0.418585, acc: 60.94%, op_acc: 38.28%] [G loss: 0.875448]\n",
      "epoch:27 step:21191[D loss: 0.408353, acc: 64.84%, op_acc: 37.50%] [G loss: 0.933208]\n",
      "epoch:27 step:21192[D loss: 0.432130, acc: 63.28%, op_acc: 38.28%] [G loss: 0.908998]\n",
      "epoch:27 step:21193[D loss: 0.408622, acc: 60.16%, op_acc: 48.44%] [G loss: 0.896245]\n",
      "epoch:27 step:21194[D loss: 0.380709, acc: 69.53%, op_acc: 43.75%] [G loss: 0.967757]\n",
      "epoch:27 step:21195[D loss: 0.455665, acc: 60.16%, op_acc: 35.16%] [G loss: 0.977507]\n",
      "epoch:27 step:21196[D loss: 0.405898, acc: 60.16%, op_acc: 42.19%] [G loss: 0.977543]\n",
      "epoch:27 step:21197[D loss: 0.409085, acc: 60.94%, op_acc: 44.53%] [G loss: 0.830239]\n",
      "epoch:27 step:21198[D loss: 0.418551, acc: 64.84%, op_acc: 35.16%] [G loss: 0.996923]\n",
      "epoch:27 step:21199[D loss: 0.427800, acc: 63.28%, op_acc: 41.41%] [G loss: 0.909738]\n",
      "epoch:27 step:21200[D loss: 0.427446, acc: 58.59%, op_acc: 38.28%] [G loss: 0.920164]\n",
      "epoch:27 step:21201[D loss: 0.403942, acc: 61.72%, op_acc: 47.66%] [G loss: 0.839866]\n",
      "epoch:27 step:21202[D loss: 0.380069, acc: 67.97%, op_acc: 43.75%] [G loss: 0.791403]\n",
      "epoch:27 step:21203[D loss: 0.447289, acc: 64.06%, op_acc: 32.03%] [G loss: 0.752519]\n",
      "epoch:27 step:21204[D loss: 0.417949, acc: 62.50%, op_acc: 35.94%] [G loss: 1.037407]\n",
      "epoch:27 step:21205[D loss: 0.447537, acc: 53.12%, op_acc: 42.97%] [G loss: 0.783940]\n",
      "epoch:27 step:21206[D loss: 0.414257, acc: 67.19%, op_acc: 36.72%] [G loss: 0.932275]\n",
      "epoch:27 step:21207[D loss: 0.437371, acc: 53.12%, op_acc: 42.97%] [G loss: 0.968603]\n",
      "epoch:27 step:21208[D loss: 0.407182, acc: 70.31%, op_acc: 38.28%] [G loss: 0.821275]\n",
      "epoch:27 step:21209[D loss: 0.414087, acc: 61.72%, op_acc: 38.28%] [G loss: 0.932547]\n",
      "epoch:27 step:21210[D loss: 0.416746, acc: 61.72%, op_acc: 39.84%] [G loss: 1.017092]\n",
      "epoch:27 step:21211[D loss: 0.424578, acc: 58.59%, op_acc: 38.28%] [G loss: 0.934929]\n",
      "epoch:27 step:21212[D loss: 0.413796, acc: 64.06%, op_acc: 38.28%] [G loss: 0.859300]\n",
      "epoch:27 step:21213[D loss: 0.403655, acc: 61.72%, op_acc: 39.06%] [G loss: 0.827876]\n",
      "epoch:27 step:21214[D loss: 0.401583, acc: 67.19%, op_acc: 39.06%] [G loss: 0.945040]\n",
      "epoch:27 step:21215[D loss: 0.392827, acc: 67.19%, op_acc: 37.50%] [G loss: 0.774094]\n",
      "epoch:27 step:21216[D loss: 0.394097, acc: 67.19%, op_acc: 41.41%] [G loss: 0.895806]\n",
      "epoch:27 step:21217[D loss: 0.412632, acc: 61.72%, op_acc: 42.19%] [G loss: 0.909384]\n",
      "epoch:27 step:21218[D loss: 0.399115, acc: 66.41%, op_acc: 37.50%] [G loss: 0.756878]\n",
      "epoch:27 step:21219[D loss: 0.356108, acc: 67.97%, op_acc: 46.09%] [G loss: 0.776801]\n",
      "epoch:27 step:21220[D loss: 0.451031, acc: 62.50%, op_acc: 30.47%] [G loss: 0.972631]\n",
      "epoch:27 step:21221[D loss: 0.431086, acc: 64.06%, op_acc: 42.19%] [G loss: 0.872503]\n",
      "epoch:27 step:21222[D loss: 0.420754, acc: 53.91%, op_acc: 40.62%] [G loss: 0.898631]\n",
      "epoch:27 step:21223[D loss: 0.384143, acc: 65.62%, op_acc: 43.75%] [G loss: 1.100269]\n",
      "epoch:27 step:21224[D loss: 0.412872, acc: 66.41%, op_acc: 41.41%] [G loss: 0.856389]\n",
      "epoch:27 step:21225[D loss: 0.438004, acc: 53.12%, op_acc: 38.28%] [G loss: 0.919008]\n",
      "epoch:27 step:21226[D loss: 0.420626, acc: 59.38%, op_acc: 45.31%] [G loss: 0.849082]\n",
      "epoch:27 step:21227[D loss: 0.428270, acc: 60.16%, op_acc: 39.06%] [G loss: 0.875340]\n",
      "epoch:27 step:21228[D loss: 0.429087, acc: 60.16%, op_acc: 42.19%] [G loss: 0.901928]\n",
      "epoch:27 step:21229[D loss: 0.436291, acc: 59.38%, op_acc: 34.38%] [G loss: 0.861868]\n",
      "epoch:27 step:21230[D loss: 0.401725, acc: 65.62%, op_acc: 40.62%] [G loss: 0.934717]\n",
      "epoch:27 step:21231[D loss: 0.425880, acc: 60.94%, op_acc: 38.28%] [G loss: 0.904734]\n",
      "epoch:27 step:21232[D loss: 0.400766, acc: 62.50%, op_acc: 44.53%] [G loss: 0.970106]\n",
      "epoch:27 step:21233[D loss: 0.413833, acc: 60.94%, op_acc: 38.28%] [G loss: 0.891709]\n",
      "epoch:27 step:21234[D loss: 0.414389, acc: 51.56%, op_acc: 39.06%] [G loss: 0.834439]\n",
      "epoch:27 step:21235[D loss: 0.424092, acc: 60.16%, op_acc: 37.50%] [G loss: 0.923861]\n",
      "epoch:27 step:21236[D loss: 0.372154, acc: 65.62%, op_acc: 45.31%] [G loss: 0.930634]\n",
      "epoch:27 step:21237[D loss: 0.406708, acc: 62.50%, op_acc: 39.06%] [G loss: 0.896823]\n",
      "epoch:27 step:21238[D loss: 0.401141, acc: 61.72%, op_acc: 43.75%] [G loss: 0.852318]\n",
      "epoch:27 step:21239[D loss: 0.409382, acc: 58.59%, op_acc: 44.53%] [G loss: 0.943813]\n",
      "epoch:27 step:21240[D loss: 0.395047, acc: 61.72%, op_acc: 45.31%] [G loss: 0.892133]\n",
      "epoch:27 step:21241[D loss: 0.420361, acc: 58.59%, op_acc: 39.06%] [G loss: 0.911943]\n",
      "epoch:27 step:21242[D loss: 0.392229, acc: 69.53%, op_acc: 39.84%] [G loss: 0.881805]\n",
      "epoch:27 step:21243[D loss: 0.417141, acc: 60.16%, op_acc: 40.62%] [G loss: 0.853242]\n",
      "epoch:27 step:21244[D loss: 0.399993, acc: 67.97%, op_acc: 39.06%] [G loss: 0.749788]\n",
      "epoch:27 step:21245[D loss: 0.400786, acc: 61.72%, op_acc: 42.19%] [G loss: 0.829780]\n",
      "epoch:27 step:21246[D loss: 0.405887, acc: 64.06%, op_acc: 42.97%] [G loss: 0.842624]\n",
      "epoch:27 step:21247[D loss: 0.431399, acc: 58.59%, op_acc: 40.62%] [G loss: 0.885579]\n",
      "epoch:27 step:21248[D loss: 0.444273, acc: 59.38%, op_acc: 40.62%] [G loss: 0.788925]\n",
      "epoch:27 step:21249[D loss: 0.414368, acc: 58.59%, op_acc: 44.53%] [G loss: 0.923977]\n",
      "epoch:27 step:21250[D loss: 0.471473, acc: 49.22%, op_acc: 32.03%] [G loss: 1.003797]\n",
      "epoch:27 step:21251[D loss: 0.435933, acc: 58.59%, op_acc: 37.50%] [G loss: 0.983070]\n",
      "epoch:27 step:21252[D loss: 0.389628, acc: 64.84%, op_acc: 40.62%] [G loss: 1.025789]\n",
      "epoch:27 step:21253[D loss: 0.420581, acc: 64.06%, op_acc: 39.84%] [G loss: 0.951699]\n",
      "epoch:27 step:21254[D loss: 0.429165, acc: 55.47%, op_acc: 44.53%] [G loss: 0.924614]\n",
      "epoch:27 step:21255[D loss: 0.403140, acc: 59.38%, op_acc: 46.09%] [G loss: 1.035608]\n",
      "epoch:27 step:21256[D loss: 0.410800, acc: 66.41%, op_acc: 35.16%] [G loss: 0.939542]\n",
      "epoch:27 step:21257[D loss: 0.461819, acc: 56.25%, op_acc: 35.16%] [G loss: 0.824804]\n",
      "epoch:27 step:21258[D loss: 0.438689, acc: 60.16%, op_acc: 35.94%] [G loss: 1.013290]\n",
      "epoch:27 step:21259[D loss: 0.417961, acc: 56.25%, op_acc: 44.53%] [G loss: 0.967818]\n",
      "epoch:27 step:21260[D loss: 0.403595, acc: 64.06%, op_acc: 39.06%] [G loss: 1.046791]\n",
      "epoch:27 step:21261[D loss: 0.432638, acc: 63.28%, op_acc: 37.50%] [G loss: 0.803495]\n",
      "epoch:27 step:21262[D loss: 0.424520, acc: 52.34%, op_acc: 41.41%] [G loss: 0.848847]\n",
      "epoch:27 step:21263[D loss: 0.450301, acc: 54.69%, op_acc: 37.50%] [G loss: 0.955364]\n",
      "epoch:27 step:21264[D loss: 0.406024, acc: 57.03%, op_acc: 42.19%] [G loss: 0.933425]\n",
      "epoch:27 step:21265[D loss: 0.434171, acc: 64.06%, op_acc: 31.25%] [G loss: 0.922644]\n",
      "epoch:27 step:21266[D loss: 0.428972, acc: 53.91%, op_acc: 39.84%] [G loss: 0.914552]\n",
      "epoch:27 step:21267[D loss: 0.408875, acc: 67.19%, op_acc: 39.06%] [G loss: 0.937708]\n",
      "epoch:27 step:21268[D loss: 0.399678, acc: 57.03%, op_acc: 42.19%] [G loss: 0.824871]\n",
      "epoch:27 step:21269[D loss: 0.434458, acc: 64.06%, op_acc: 42.19%] [G loss: 0.826946]\n",
      "epoch:27 step:21270[D loss: 0.420764, acc: 67.19%, op_acc: 40.62%] [G loss: 0.985589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21271[D loss: 0.410278, acc: 64.06%, op_acc: 38.28%] [G loss: 0.892208]\n",
      "epoch:27 step:21272[D loss: 0.412378, acc: 69.53%, op_acc: 34.38%] [G loss: 0.930480]\n",
      "epoch:27 step:21273[D loss: 0.415004, acc: 58.59%, op_acc: 43.75%] [G loss: 0.925028]\n",
      "epoch:27 step:21274[D loss: 0.453425, acc: 54.69%, op_acc: 38.28%] [G loss: 0.886968]\n",
      "epoch:27 step:21275[D loss: 0.427086, acc: 57.03%, op_acc: 38.28%] [G loss: 0.894063]\n",
      "epoch:27 step:21276[D loss: 0.425112, acc: 59.38%, op_acc: 33.59%] [G loss: 0.879546]\n",
      "epoch:27 step:21277[D loss: 0.440794, acc: 57.81%, op_acc: 42.19%] [G loss: 0.894111]\n",
      "epoch:27 step:21278[D loss: 0.418386, acc: 57.81%, op_acc: 39.84%] [G loss: 0.872092]\n",
      "epoch:27 step:21279[D loss: 0.408856, acc: 60.94%, op_acc: 42.97%] [G loss: 0.918749]\n",
      "epoch:27 step:21280[D loss: 0.431300, acc: 55.47%, op_acc: 39.84%] [G loss: 0.829961]\n",
      "epoch:27 step:21281[D loss: 0.395958, acc: 66.41%, op_acc: 42.97%] [G loss: 0.951962]\n",
      "epoch:27 step:21282[D loss: 0.417610, acc: 57.03%, op_acc: 39.84%] [G loss: 0.945691]\n",
      "epoch:27 step:21283[D loss: 0.427048, acc: 56.25%, op_acc: 42.19%] [G loss: 0.918560]\n",
      "epoch:27 step:21284[D loss: 0.425008, acc: 59.38%, op_acc: 44.53%] [G loss: 0.924838]\n",
      "epoch:27 step:21285[D loss: 0.457404, acc: 56.25%, op_acc: 37.50%] [G loss: 0.871332]\n",
      "epoch:27 step:21286[D loss: 0.401084, acc: 61.72%, op_acc: 41.41%] [G loss: 0.811860]\n",
      "epoch:27 step:21287[D loss: 0.418607, acc: 62.50%, op_acc: 38.28%] [G loss: 0.999222]\n",
      "epoch:27 step:21288[D loss: 0.417877, acc: 57.03%, op_acc: 39.06%] [G loss: 0.927207]\n",
      "epoch:27 step:21289[D loss: 0.409134, acc: 66.41%, op_acc: 42.97%] [G loss: 0.949175]\n",
      "epoch:27 step:21290[D loss: 0.450743, acc: 59.38%, op_acc: 28.91%] [G loss: 0.939374]\n",
      "epoch:27 step:21291[D loss: 0.399692, acc: 59.38%, op_acc: 40.62%] [G loss: 0.931882]\n",
      "epoch:27 step:21292[D loss: 0.437836, acc: 55.47%, op_acc: 39.84%] [G loss: 0.883641]\n",
      "epoch:27 step:21293[D loss: 0.404880, acc: 66.41%, op_acc: 35.16%] [G loss: 0.948513]\n",
      "epoch:27 step:21294[D loss: 0.402575, acc: 68.75%, op_acc: 42.19%] [G loss: 0.988844]\n",
      "epoch:27 step:21295[D loss: 0.435899, acc: 59.38%, op_acc: 38.28%] [G loss: 0.902207]\n",
      "epoch:27 step:21296[D loss: 0.418210, acc: 54.69%, op_acc: 42.97%] [G loss: 0.855347]\n",
      "epoch:27 step:21297[D loss: 0.437553, acc: 57.81%, op_acc: 38.28%] [G loss: 0.866607]\n",
      "epoch:27 step:21298[D loss: 0.410315, acc: 64.84%, op_acc: 44.53%] [G loss: 0.894232]\n",
      "epoch:27 step:21299[D loss: 0.411213, acc: 62.50%, op_acc: 42.19%] [G loss: 0.893539]\n",
      "epoch:27 step:21300[D loss: 0.399712, acc: 64.06%, op_acc: 44.53%] [G loss: 0.869369]\n",
      "epoch:27 step:21301[D loss: 0.433153, acc: 60.16%, op_acc: 36.72%] [G loss: 1.009827]\n",
      "epoch:27 step:21302[D loss: 0.402801, acc: 67.19%, op_acc: 40.62%] [G loss: 0.861568]\n",
      "epoch:27 step:21303[D loss: 0.408811, acc: 64.06%, op_acc: 42.97%] [G loss: 0.945229]\n",
      "epoch:27 step:21304[D loss: 0.413437, acc: 59.38%, op_acc: 42.97%] [G loss: 0.885301]\n",
      "epoch:27 step:21305[D loss: 0.396518, acc: 64.06%, op_acc: 44.53%] [G loss: 0.772612]\n",
      "epoch:27 step:21306[D loss: 0.419575, acc: 64.84%, op_acc: 40.62%] [G loss: 0.756181]\n",
      "epoch:27 step:21307[D loss: 0.423247, acc: 64.06%, op_acc: 42.19%] [G loss: 0.897525]\n",
      "epoch:27 step:21308[D loss: 0.414832, acc: 62.50%, op_acc: 39.84%] [G loss: 0.900023]\n",
      "epoch:27 step:21309[D loss: 0.409617, acc: 62.50%, op_acc: 40.62%] [G loss: 0.928423]\n",
      "epoch:27 step:21310[D loss: 0.428666, acc: 57.03%, op_acc: 36.72%] [G loss: 0.979240]\n",
      "epoch:27 step:21311[D loss: 0.435505, acc: 57.03%, op_acc: 40.62%] [G loss: 0.916193]\n",
      "epoch:27 step:21312[D loss: 0.437305, acc: 56.25%, op_acc: 35.94%] [G loss: 0.930628]\n",
      "epoch:27 step:21313[D loss: 0.427149, acc: 57.81%, op_acc: 42.19%] [G loss: 0.872857]\n",
      "epoch:27 step:21314[D loss: 0.398556, acc: 67.19%, op_acc: 44.53%] [G loss: 0.872694]\n",
      "epoch:27 step:21315[D loss: 0.404627, acc: 63.28%, op_acc: 36.72%] [G loss: 0.944175]\n",
      "epoch:27 step:21316[D loss: 0.407067, acc: 59.38%, op_acc: 41.41%] [G loss: 0.915859]\n",
      "epoch:27 step:21317[D loss: 0.431574, acc: 61.72%, op_acc: 35.94%] [G loss: 0.870273]\n",
      "epoch:27 step:21318[D loss: 0.397548, acc: 64.84%, op_acc: 45.31%] [G loss: 0.781060]\n",
      "epoch:27 step:21319[D loss: 0.397587, acc: 65.62%, op_acc: 44.53%] [G loss: 0.896236]\n",
      "epoch:27 step:21320[D loss: 0.439004, acc: 53.12%, op_acc: 34.38%] [G loss: 0.820066]\n",
      "epoch:27 step:21321[D loss: 0.416504, acc: 67.97%, op_acc: 37.50%] [G loss: 0.873973]\n",
      "epoch:27 step:21322[D loss: 0.420094, acc: 58.59%, op_acc: 38.28%] [G loss: 0.982178]\n",
      "epoch:27 step:21323[D loss: 0.412944, acc: 62.50%, op_acc: 41.41%] [G loss: 0.909790]\n",
      "epoch:27 step:21324[D loss: 0.412916, acc: 60.94%, op_acc: 40.62%] [G loss: 0.925803]\n",
      "epoch:27 step:21325[D loss: 0.416638, acc: 60.16%, op_acc: 42.97%] [G loss: 0.915956]\n",
      "epoch:27 step:21326[D loss: 0.431587, acc: 58.59%, op_acc: 35.16%] [G loss: 0.958859]\n",
      "epoch:27 step:21327[D loss: 0.412695, acc: 64.84%, op_acc: 35.16%] [G loss: 0.969943]\n",
      "epoch:27 step:21328[D loss: 0.399537, acc: 67.97%, op_acc: 43.75%] [G loss: 0.843306]\n",
      "epoch:27 step:21329[D loss: 0.397210, acc: 66.41%, op_acc: 44.53%] [G loss: 0.843975]\n",
      "epoch:27 step:21330[D loss: 0.442769, acc: 60.16%, op_acc: 36.72%] [G loss: 0.799868]\n",
      "epoch:27 step:21331[D loss: 0.431539, acc: 57.03%, op_acc: 38.28%] [G loss: 0.916901]\n",
      "epoch:27 step:21332[D loss: 0.436186, acc: 57.81%, op_acc: 42.97%] [G loss: 0.865689]\n",
      "epoch:27 step:21333[D loss: 0.463721, acc: 56.25%, op_acc: 39.06%] [G loss: 0.895321]\n",
      "epoch:27 step:21334[D loss: 0.411080, acc: 62.50%, op_acc: 40.62%] [G loss: 0.920023]\n",
      "epoch:27 step:21335[D loss: 0.433738, acc: 60.94%, op_acc: 35.16%] [G loss: 0.775474]\n",
      "epoch:27 step:21336[D loss: 0.442550, acc: 56.25%, op_acc: 38.28%] [G loss: 0.952971]\n",
      "epoch:27 step:21337[D loss: 0.438436, acc: 62.50%, op_acc: 45.31%] [G loss: 0.915265]\n",
      "epoch:27 step:21338[D loss: 0.401122, acc: 64.06%, op_acc: 44.53%] [G loss: 0.827294]\n",
      "epoch:27 step:21339[D loss: 0.398138, acc: 64.06%, op_acc: 44.53%] [G loss: 0.861968]\n",
      "epoch:27 step:21340[D loss: 0.422279, acc: 59.38%, op_acc: 39.84%] [G loss: 0.934605]\n",
      "epoch:27 step:21341[D loss: 0.434783, acc: 58.59%, op_acc: 35.16%] [G loss: 0.942160]\n",
      "epoch:27 step:21342[D loss: 0.429986, acc: 61.72%, op_acc: 40.62%] [G loss: 0.835698]\n",
      "epoch:27 step:21343[D loss: 0.433416, acc: 48.44%, op_acc: 39.84%] [G loss: 0.835995]\n",
      "epoch:27 step:21344[D loss: 0.451088, acc: 57.03%, op_acc: 36.72%] [G loss: 0.943687]\n",
      "epoch:27 step:21345[D loss: 0.414265, acc: 62.50%, op_acc: 46.09%] [G loss: 0.955970]\n",
      "epoch:27 step:21346[D loss: 0.410370, acc: 66.41%, op_acc: 35.94%] [G loss: 0.873162]\n",
      "epoch:27 step:21347[D loss: 0.446524, acc: 57.03%, op_acc: 32.03%] [G loss: 0.825221]\n",
      "epoch:27 step:21348[D loss: 0.392671, acc: 70.31%, op_acc: 43.75%] [G loss: 0.823245]\n",
      "epoch:27 step:21349[D loss: 0.414463, acc: 60.94%, op_acc: 35.94%] [G loss: 0.811218]\n",
      "epoch:27 step:21350[D loss: 0.436179, acc: 52.34%, op_acc: 41.41%] [G loss: 0.797243]\n",
      "epoch:27 step:21351[D loss: 0.386178, acc: 74.22%, op_acc: 41.41%] [G loss: 0.837976]\n",
      "epoch:27 step:21352[D loss: 0.404847, acc: 59.38%, op_acc: 47.66%] [G loss: 0.862759]\n",
      "epoch:27 step:21353[D loss: 0.434846, acc: 53.91%, op_acc: 32.03%] [G loss: 0.899326]\n",
      "epoch:27 step:21354[D loss: 0.426546, acc: 56.25%, op_acc: 45.31%] [G loss: 0.931753]\n",
      "epoch:27 step:21355[D loss: 0.440822, acc: 53.12%, op_acc: 40.62%] [G loss: 0.841532]\n",
      "epoch:27 step:21356[D loss: 0.410797, acc: 60.16%, op_acc: 42.19%] [G loss: 0.854240]\n",
      "epoch:27 step:21357[D loss: 0.384878, acc: 63.28%, op_acc: 39.84%] [G loss: 0.910228]\n",
      "epoch:27 step:21358[D loss: 0.434418, acc: 62.50%, op_acc: 36.72%] [G loss: 0.998045]\n",
      "epoch:27 step:21359[D loss: 0.388403, acc: 71.88%, op_acc: 40.62%] [G loss: 0.943216]\n",
      "epoch:27 step:21360[D loss: 0.418208, acc: 59.38%, op_acc: 40.62%] [G loss: 0.862632]\n",
      "epoch:27 step:21361[D loss: 0.454852, acc: 51.56%, op_acc: 36.72%] [G loss: 0.905452]\n",
      "epoch:27 step:21362[D loss: 0.441209, acc: 57.81%, op_acc: 37.50%] [G loss: 0.855915]\n",
      "epoch:27 step:21363[D loss: 0.424682, acc: 59.38%, op_acc: 41.41%] [G loss: 0.887667]\n",
      "epoch:27 step:21364[D loss: 0.412138, acc: 64.06%, op_acc: 38.28%] [G loss: 0.928412]\n",
      "epoch:27 step:21365[D loss: 0.418954, acc: 60.94%, op_acc: 40.62%] [G loss: 0.846685]\n",
      "epoch:27 step:21366[D loss: 0.446728, acc: 52.34%, op_acc: 38.28%] [G loss: 0.840294]\n",
      "epoch:27 step:21367[D loss: 0.396748, acc: 64.06%, op_acc: 39.84%] [G loss: 0.875321]\n",
      "epoch:27 step:21368[D loss: 0.443970, acc: 58.59%, op_acc: 35.16%] [G loss: 0.832395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21369[D loss: 0.442730, acc: 57.81%, op_acc: 36.72%] [G loss: 0.866541]\n",
      "epoch:27 step:21370[D loss: 0.414774, acc: 60.94%, op_acc: 39.84%] [G loss: 0.929293]\n",
      "epoch:27 step:21371[D loss: 0.428035, acc: 53.91%, op_acc: 38.28%] [G loss: 1.077530]\n",
      "epoch:27 step:21372[D loss: 0.420323, acc: 61.72%, op_acc: 37.50%] [G loss: 0.919787]\n",
      "epoch:27 step:21373[D loss: 0.445862, acc: 58.59%, op_acc: 34.38%] [G loss: 1.047297]\n",
      "epoch:27 step:21374[D loss: 0.443897, acc: 50.78%, op_acc: 42.97%] [G loss: 1.063951]\n",
      "epoch:27 step:21375[D loss: 0.385415, acc: 67.97%, op_acc: 46.09%] [G loss: 0.862925]\n",
      "epoch:27 step:21376[D loss: 0.411976, acc: 64.84%, op_acc: 41.41%] [G loss: 0.971901]\n",
      "epoch:27 step:21377[D loss: 0.382692, acc: 71.09%, op_acc: 43.75%] [G loss: 0.893064]\n",
      "epoch:27 step:21378[D loss: 0.410914, acc: 67.97%, op_acc: 42.19%] [G loss: 1.041790]\n",
      "epoch:27 step:21379[D loss: 0.437251, acc: 50.78%, op_acc: 40.62%] [G loss: 0.928081]\n",
      "epoch:27 step:21380[D loss: 0.428458, acc: 58.59%, op_acc: 42.19%] [G loss: 0.858798]\n",
      "epoch:27 step:21381[D loss: 0.399419, acc: 69.53%, op_acc: 39.06%] [G loss: 0.926291]\n",
      "epoch:27 step:21382[D loss: 0.424313, acc: 59.38%, op_acc: 47.66%] [G loss: 0.974274]\n",
      "epoch:27 step:21383[D loss: 0.429239, acc: 59.38%, op_acc: 42.19%] [G loss: 0.853029]\n",
      "epoch:27 step:21384[D loss: 0.375662, acc: 74.22%, op_acc: 41.41%] [G loss: 0.968051]\n",
      "epoch:27 step:21385[D loss: 0.396942, acc: 67.97%, op_acc: 38.28%] [G loss: 0.932479]\n",
      "epoch:27 step:21386[D loss: 0.417578, acc: 59.38%, op_acc: 39.84%] [G loss: 0.858736]\n",
      "epoch:27 step:21387[D loss: 0.417167, acc: 64.06%, op_acc: 42.97%] [G loss: 0.876861]\n",
      "epoch:27 step:21388[D loss: 0.423879, acc: 57.81%, op_acc: 39.06%] [G loss: 0.936487]\n",
      "epoch:27 step:21389[D loss: 0.394680, acc: 65.62%, op_acc: 42.19%] [G loss: 0.984829]\n",
      "epoch:27 step:21390[D loss: 0.390353, acc: 66.41%, op_acc: 48.44%] [G loss: 0.978212]\n",
      "epoch:27 step:21391[D loss: 0.401086, acc: 61.72%, op_acc: 42.97%] [G loss: 0.787048]\n",
      "epoch:27 step:21392[D loss: 0.406364, acc: 58.59%, op_acc: 42.97%] [G loss: 0.959147]\n",
      "epoch:27 step:21393[D loss: 0.440444, acc: 60.94%, op_acc: 36.72%] [G loss: 0.898896]\n",
      "epoch:27 step:21394[D loss: 0.396095, acc: 64.06%, op_acc: 42.19%] [G loss: 0.836163]\n",
      "epoch:27 step:21395[D loss: 0.427523, acc: 63.28%, op_acc: 36.72%] [G loss: 0.903650]\n",
      "epoch:27 step:21396[D loss: 0.459427, acc: 57.81%, op_acc: 32.81%] [G loss: 0.796998]\n",
      "epoch:27 step:21397[D loss: 0.411412, acc: 60.16%, op_acc: 35.94%] [G loss: 0.834002]\n",
      "epoch:27 step:21398[D loss: 0.423121, acc: 65.62%, op_acc: 38.28%] [G loss: 0.969098]\n",
      "epoch:27 step:21399[D loss: 0.425932, acc: 57.81%, op_acc: 42.97%] [G loss: 0.929427]\n",
      "epoch:27 step:21400[D loss: 0.418538, acc: 65.62%, op_acc: 42.97%] [G loss: 0.999818]\n",
      "epoch:27 step:21401[D loss: 0.437388, acc: 57.81%, op_acc: 40.62%] [G loss: 0.964713]\n",
      "epoch:27 step:21402[D loss: 0.440691, acc: 57.81%, op_acc: 36.72%] [G loss: 0.949893]\n",
      "epoch:27 step:21403[D loss: 0.443847, acc: 57.81%, op_acc: 34.38%] [G loss: 0.825889]\n",
      "epoch:27 step:21404[D loss: 0.440584, acc: 58.59%, op_acc: 35.94%] [G loss: 0.867502]\n",
      "epoch:27 step:21405[D loss: 0.422537, acc: 61.72%, op_acc: 35.94%] [G loss: 0.898390]\n",
      "epoch:27 step:21406[D loss: 0.402136, acc: 65.62%, op_acc: 39.84%] [G loss: 0.902815]\n",
      "epoch:27 step:21407[D loss: 0.427212, acc: 63.28%, op_acc: 34.38%] [G loss: 0.858352]\n",
      "epoch:27 step:21408[D loss: 0.410006, acc: 66.41%, op_acc: 39.84%] [G loss: 0.875476]\n",
      "epoch:27 step:21409[D loss: 0.442229, acc: 58.59%, op_acc: 39.84%] [G loss: 0.910557]\n",
      "epoch:27 step:21410[D loss: 0.404221, acc: 66.41%, op_acc: 42.19%] [G loss: 0.990137]\n",
      "epoch:27 step:21411[D loss: 0.416227, acc: 64.06%, op_acc: 34.38%] [G loss: 0.925229]\n",
      "epoch:27 step:21412[D loss: 0.414600, acc: 59.38%, op_acc: 46.88%] [G loss: 0.789302]\n",
      "epoch:27 step:21413[D loss: 0.421986, acc: 60.16%, op_acc: 38.28%] [G loss: 0.883879]\n",
      "epoch:27 step:21414[D loss: 0.404944, acc: 64.84%, op_acc: 42.97%] [G loss: 0.877781]\n",
      "epoch:27 step:21415[D loss: 0.461557, acc: 48.44%, op_acc: 43.75%] [G loss: 0.956301]\n",
      "epoch:27 step:21416[D loss: 0.427418, acc: 50.00%, op_acc: 39.06%] [G loss: 0.929284]\n",
      "epoch:27 step:21417[D loss: 0.428167, acc: 53.91%, op_acc: 42.97%] [G loss: 0.869185]\n",
      "epoch:27 step:21418[D loss: 0.433020, acc: 60.94%, op_acc: 38.28%] [G loss: 0.966939]\n",
      "epoch:27 step:21419[D loss: 0.409512, acc: 57.81%, op_acc: 41.41%] [G loss: 0.868994]\n",
      "epoch:27 step:21420[D loss: 0.441226, acc: 61.72%, op_acc: 42.19%] [G loss: 0.923971]\n",
      "epoch:27 step:21421[D loss: 0.409702, acc: 64.84%, op_acc: 39.84%] [G loss: 1.003535]\n",
      "epoch:27 step:21422[D loss: 0.418664, acc: 59.38%, op_acc: 42.97%] [G loss: 0.966912]\n",
      "epoch:27 step:21423[D loss: 0.417245, acc: 65.62%, op_acc: 38.28%] [G loss: 1.020480]\n",
      "epoch:27 step:21424[D loss: 0.424474, acc: 59.38%, op_acc: 38.28%] [G loss: 0.906765]\n",
      "epoch:27 step:21425[D loss: 0.392544, acc: 60.94%, op_acc: 43.75%] [G loss: 0.862210]\n",
      "epoch:27 step:21426[D loss: 0.402062, acc: 66.41%, op_acc: 43.75%] [G loss: 0.782166]\n",
      "epoch:27 step:21427[D loss: 0.428680, acc: 64.84%, op_acc: 37.50%] [G loss: 0.791074]\n",
      "epoch:27 step:21428[D loss: 0.449199, acc: 54.69%, op_acc: 36.72%] [G loss: 0.988627]\n",
      "epoch:27 step:21429[D loss: 0.409408, acc: 62.50%, op_acc: 39.06%] [G loss: 0.952744]\n",
      "epoch:27 step:21430[D loss: 0.386550, acc: 71.88%, op_acc: 43.75%] [G loss: 0.835400]\n",
      "epoch:27 step:21431[D loss: 0.404274, acc: 66.41%, op_acc: 39.06%] [G loss: 0.836439]\n",
      "epoch:27 step:21432[D loss: 0.404772, acc: 60.16%, op_acc: 42.97%] [G loss: 0.844243]\n",
      "epoch:27 step:21433[D loss: 0.424367, acc: 61.72%, op_acc: 43.75%] [G loss: 0.804478]\n",
      "epoch:27 step:21434[D loss: 0.377068, acc: 69.53%, op_acc: 43.75%] [G loss: 0.874050]\n",
      "epoch:27 step:21435[D loss: 0.390750, acc: 64.84%, op_acc: 39.06%] [G loss: 0.775247]\n",
      "epoch:27 step:21436[D loss: 0.405442, acc: 57.03%, op_acc: 42.97%] [G loss: 0.890425]\n",
      "epoch:27 step:21437[D loss: 0.388265, acc: 74.22%, op_acc: 35.94%] [G loss: 0.968999]\n",
      "epoch:27 step:21438[D loss: 0.408123, acc: 68.75%, op_acc: 43.75%] [G loss: 0.899391]\n",
      "epoch:27 step:21439[D loss: 0.430687, acc: 62.50%, op_acc: 38.28%] [G loss: 0.955339]\n",
      "epoch:27 step:21440[D loss: 0.388537, acc: 61.72%, op_acc: 42.97%] [G loss: 0.908208]\n",
      "epoch:27 step:21441[D loss: 0.408661, acc: 64.06%, op_acc: 42.97%] [G loss: 0.971503]\n",
      "epoch:27 step:21442[D loss: 0.429024, acc: 64.06%, op_acc: 39.06%] [G loss: 0.898117]\n",
      "epoch:27 step:21443[D loss: 0.412513, acc: 63.28%, op_acc: 39.84%] [G loss: 0.934975]\n",
      "epoch:27 step:21444[D loss: 0.426030, acc: 57.81%, op_acc: 39.84%] [G loss: 0.893113]\n",
      "epoch:27 step:21445[D loss: 0.453049, acc: 57.03%, op_acc: 36.72%] [G loss: 0.939393]\n",
      "epoch:27 step:21446[D loss: 0.413732, acc: 60.94%, op_acc: 41.41%] [G loss: 0.775211]\n",
      "epoch:27 step:21447[D loss: 0.390641, acc: 68.75%, op_acc: 42.19%] [G loss: 0.990195]\n",
      "epoch:27 step:21448[D loss: 0.387862, acc: 64.84%, op_acc: 42.19%] [G loss: 0.911168]\n",
      "epoch:27 step:21449[D loss: 0.400605, acc: 57.81%, op_acc: 42.19%] [G loss: 0.976220]\n",
      "epoch:27 step:21450[D loss: 0.399718, acc: 67.97%, op_acc: 42.97%] [G loss: 0.935803]\n",
      "epoch:27 step:21451[D loss: 0.428706, acc: 57.81%, op_acc: 36.72%] [G loss: 1.029475]\n",
      "epoch:27 step:21452[D loss: 0.396250, acc: 60.94%, op_acc: 45.31%] [G loss: 0.961932]\n",
      "epoch:27 step:21453[D loss: 0.409721, acc: 62.50%, op_acc: 44.53%] [G loss: 0.884763]\n",
      "epoch:27 step:21454[D loss: 0.419083, acc: 61.72%, op_acc: 37.50%] [G loss: 0.839773]\n",
      "epoch:27 step:21455[D loss: 0.387664, acc: 70.31%, op_acc: 43.75%] [G loss: 0.805849]\n",
      "epoch:27 step:21456[D loss: 0.399551, acc: 61.72%, op_acc: 41.41%] [G loss: 0.818646]\n",
      "epoch:27 step:21457[D loss: 0.422809, acc: 56.25%, op_acc: 38.28%] [G loss: 0.887549]\n",
      "epoch:27 step:21458[D loss: 0.395417, acc: 61.72%, op_acc: 48.44%] [G loss: 0.882137]\n",
      "epoch:27 step:21459[D loss: 0.413112, acc: 60.94%, op_acc: 37.50%] [G loss: 0.860452]\n",
      "epoch:27 step:21460[D loss: 0.412338, acc: 60.94%, op_acc: 42.97%] [G loss: 0.826085]\n",
      "epoch:27 step:21461[D loss: 0.428138, acc: 60.16%, op_acc: 38.28%] [G loss: 0.824603]\n",
      "epoch:27 step:21462[D loss: 0.431860, acc: 63.28%, op_acc: 38.28%] [G loss: 0.982034]\n",
      "epoch:27 step:21463[D loss: 0.403551, acc: 60.16%, op_acc: 35.94%] [G loss: 0.934478]\n",
      "epoch:27 step:21464[D loss: 0.423545, acc: 64.84%, op_acc: 41.41%] [G loss: 0.838290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21465[D loss: 0.400648, acc: 62.50%, op_acc: 42.97%] [G loss: 0.958065]\n",
      "epoch:27 step:21466[D loss: 0.404839, acc: 60.16%, op_acc: 38.28%] [G loss: 0.929954]\n",
      "epoch:27 step:21467[D loss: 0.402232, acc: 64.84%, op_acc: 42.97%] [G loss: 0.904756]\n",
      "epoch:27 step:21468[D loss: 0.393674, acc: 69.53%, op_acc: 39.06%] [G loss: 0.996487]\n",
      "epoch:27 step:21469[D loss: 0.426321, acc: 58.59%, op_acc: 40.62%] [G loss: 0.811990]\n",
      "epoch:27 step:21470[D loss: 0.420457, acc: 60.94%, op_acc: 44.53%] [G loss: 0.870342]\n",
      "epoch:27 step:21471[D loss: 0.411739, acc: 63.28%, op_acc: 43.75%] [G loss: 0.892246]\n",
      "epoch:27 step:21472[D loss: 0.418552, acc: 57.81%, op_acc: 43.75%] [G loss: 0.926746]\n",
      "epoch:27 step:21473[D loss: 0.397114, acc: 67.19%, op_acc: 42.97%] [G loss: 0.914705]\n",
      "epoch:27 step:21474[D loss: 0.434696, acc: 53.12%, op_acc: 39.06%] [G loss: 0.813548]\n",
      "epoch:27 step:21475[D loss: 0.465022, acc: 57.03%, op_acc: 36.72%] [G loss: 0.942443]\n",
      "epoch:27 step:21476[D loss: 0.438031, acc: 59.38%, op_acc: 39.84%] [G loss: 0.868421]\n",
      "epoch:27 step:21477[D loss: 0.436006, acc: 59.38%, op_acc: 39.06%] [G loss: 0.832796]\n",
      "epoch:27 step:21478[D loss: 0.403609, acc: 60.94%, op_acc: 46.09%] [G loss: 0.796997]\n",
      "epoch:27 step:21479[D loss: 0.419861, acc: 55.47%, op_acc: 43.75%] [G loss: 0.919318]\n",
      "epoch:27 step:21480[D loss: 0.406907, acc: 66.41%, op_acc: 43.75%] [G loss: 0.995098]\n",
      "epoch:27 step:21481[D loss: 0.400984, acc: 64.84%, op_acc: 39.06%] [G loss: 0.901659]\n",
      "epoch:27 step:21482[D loss: 0.436670, acc: 61.72%, op_acc: 30.47%] [G loss: 0.917509]\n",
      "epoch:27 step:21483[D loss: 0.402750, acc: 65.62%, op_acc: 40.62%] [G loss: 1.010316]\n",
      "epoch:27 step:21484[D loss: 0.412828, acc: 60.16%, op_acc: 38.28%] [G loss: 0.946009]\n",
      "epoch:27 step:21485[D loss: 0.441293, acc: 60.94%, op_acc: 30.47%] [G loss: 0.892931]\n",
      "epoch:27 step:21486[D loss: 0.440737, acc: 52.34%, op_acc: 46.09%] [G loss: 0.885221]\n",
      "epoch:27 step:21487[D loss: 0.422398, acc: 62.50%, op_acc: 37.50%] [G loss: 0.963677]\n",
      "epoch:27 step:21488[D loss: 0.388088, acc: 65.62%, op_acc: 47.66%] [G loss: 0.952973]\n",
      "epoch:27 step:21489[D loss: 0.422270, acc: 61.72%, op_acc: 33.59%] [G loss: 0.896162]\n",
      "epoch:27 step:21490[D loss: 0.386302, acc: 67.19%, op_acc: 40.62%] [G loss: 0.969359]\n",
      "epoch:27 step:21491[D loss: 0.350496, acc: 77.34%, op_acc: 44.53%] [G loss: 0.864685]\n",
      "epoch:27 step:21492[D loss: 0.425092, acc: 62.50%, op_acc: 39.84%] [G loss: 0.938410]\n",
      "epoch:27 step:21493[D loss: 0.408744, acc: 57.03%, op_acc: 36.72%] [G loss: 0.974328]\n",
      "epoch:27 step:21494[D loss: 0.382803, acc: 68.75%, op_acc: 46.88%] [G loss: 0.886873]\n",
      "epoch:27 step:21495[D loss: 0.386425, acc: 62.50%, op_acc: 46.09%] [G loss: 1.019991]\n",
      "epoch:27 step:21496[D loss: 0.395138, acc: 71.09%, op_acc: 45.31%] [G loss: 0.774929]\n",
      "epoch:27 step:21497[D loss: 0.385865, acc: 63.28%, op_acc: 39.06%] [G loss: 0.852585]\n",
      "epoch:27 step:21498[D loss: 0.422705, acc: 57.81%, op_acc: 36.72%] [G loss: 0.821327]\n",
      "epoch:27 step:21499[D loss: 0.442379, acc: 55.47%, op_acc: 46.88%] [G loss: 0.964372]\n",
      "epoch:27 step:21500[D loss: 0.391683, acc: 70.31%, op_acc: 40.62%] [G loss: 0.855862]\n",
      "epoch:27 step:21501[D loss: 0.369365, acc: 71.88%, op_acc: 42.97%] [G loss: 0.915700]\n",
      "epoch:27 step:21502[D loss: 0.402371, acc: 59.38%, op_acc: 42.19%] [G loss: 0.955582]\n",
      "epoch:27 step:21503[D loss: 0.398133, acc: 60.16%, op_acc: 42.19%] [G loss: 0.877473]\n",
      "epoch:27 step:21504[D loss: 0.419440, acc: 61.72%, op_acc: 46.09%] [G loss: 1.066277]\n",
      "epoch:27 step:21505[D loss: 0.407764, acc: 57.81%, op_acc: 38.28%] [G loss: 0.885327]\n",
      "epoch:27 step:21506[D loss: 0.419651, acc: 57.81%, op_acc: 42.19%] [G loss: 0.850521]\n",
      "epoch:27 step:21507[D loss: 0.426771, acc: 55.47%, op_acc: 42.19%] [G loss: 0.994420]\n",
      "epoch:27 step:21508[D loss: 0.477489, acc: 50.00%, op_acc: 34.38%] [G loss: 0.825291]\n",
      "epoch:27 step:21509[D loss: 0.395584, acc: 66.41%, op_acc: 42.97%] [G loss: 0.969833]\n",
      "epoch:27 step:21510[D loss: 0.425581, acc: 60.94%, op_acc: 40.62%] [G loss: 0.921942]\n",
      "epoch:27 step:21511[D loss: 0.439423, acc: 52.34%, op_acc: 39.84%] [G loss: 1.046407]\n",
      "epoch:27 step:21512[D loss: 0.403737, acc: 66.41%, op_acc: 41.41%] [G loss: 0.954298]\n",
      "epoch:27 step:21513[D loss: 0.440036, acc: 58.59%, op_acc: 39.84%] [G loss: 0.798153]\n",
      "epoch:27 step:21514[D loss: 0.421385, acc: 57.81%, op_acc: 39.06%] [G loss: 0.913152]\n",
      "epoch:27 step:21515[D loss: 0.414051, acc: 58.59%, op_acc: 40.62%] [G loss: 0.909139]\n",
      "epoch:27 step:21516[D loss: 0.389768, acc: 64.06%, op_acc: 41.41%] [G loss: 0.990924]\n",
      "epoch:27 step:21517[D loss: 0.443941, acc: 58.59%, op_acc: 36.72%] [G loss: 0.908197]\n",
      "epoch:27 step:21518[D loss: 0.431789, acc: 58.59%, op_acc: 39.06%] [G loss: 0.853755]\n",
      "epoch:27 step:21519[D loss: 0.392595, acc: 64.06%, op_acc: 44.53%] [G loss: 0.916998]\n",
      "epoch:27 step:21520[D loss: 0.421809, acc: 56.25%, op_acc: 46.88%] [G loss: 0.912933]\n",
      "epoch:27 step:21521[D loss: 0.381972, acc: 64.06%, op_acc: 47.66%] [G loss: 0.846978]\n",
      "epoch:27 step:21522[D loss: 0.416010, acc: 58.59%, op_acc: 41.41%] [G loss: 0.832852]\n",
      "epoch:27 step:21523[D loss: 0.464295, acc: 53.12%, op_acc: 30.47%] [G loss: 0.831076]\n",
      "epoch:27 step:21524[D loss: 0.438584, acc: 53.12%, op_acc: 41.41%] [G loss: 0.871287]\n",
      "epoch:27 step:21525[D loss: 0.402750, acc: 62.50%, op_acc: 45.31%] [G loss: 0.778016]\n",
      "epoch:27 step:21526[D loss: 0.419411, acc: 59.38%, op_acc: 39.06%] [G loss: 0.857677]\n",
      "epoch:27 step:21527[D loss: 0.420315, acc: 59.38%, op_acc: 32.81%] [G loss: 0.992052]\n",
      "epoch:27 step:21528[D loss: 0.435629, acc: 54.69%, op_acc: 36.72%] [G loss: 0.978636]\n",
      "epoch:27 step:21529[D loss: 0.391134, acc: 64.06%, op_acc: 45.31%] [G loss: 0.962402]\n",
      "epoch:27 step:21530[D loss: 0.427828, acc: 64.06%, op_acc: 42.19%] [G loss: 0.985078]\n",
      "epoch:27 step:21531[D loss: 0.432540, acc: 54.69%, op_acc: 40.62%] [G loss: 0.857689]\n",
      "epoch:27 step:21532[D loss: 0.440303, acc: 53.91%, op_acc: 38.28%] [G loss: 1.017964]\n",
      "epoch:27 step:21533[D loss: 0.408367, acc: 71.09%, op_acc: 39.84%] [G loss: 0.980965]\n",
      "epoch:27 step:21534[D loss: 0.427000, acc: 60.16%, op_acc: 38.28%] [G loss: 0.873111]\n",
      "epoch:27 step:21535[D loss: 0.389649, acc: 68.75%, op_acc: 47.66%] [G loss: 0.942833]\n",
      "epoch:27 step:21536[D loss: 0.417668, acc: 60.94%, op_acc: 36.72%] [G loss: 0.849564]\n",
      "epoch:27 step:21537[D loss: 0.440610, acc: 59.38%, op_acc: 38.28%] [G loss: 0.922308]\n",
      "epoch:27 step:21538[D loss: 0.451637, acc: 51.56%, op_acc: 41.41%] [G loss: 0.812112]\n",
      "epoch:27 step:21539[D loss: 0.418878, acc: 60.94%, op_acc: 40.62%] [G loss: 0.934196]\n",
      "epoch:27 step:21540[D loss: 0.410286, acc: 59.38%, op_acc: 42.19%] [G loss: 0.872726]\n",
      "epoch:27 step:21541[D loss: 0.425135, acc: 63.28%, op_acc: 35.94%] [G loss: 0.905223]\n",
      "epoch:27 step:21542[D loss: 0.431472, acc: 54.69%, op_acc: 34.38%] [G loss: 0.861426]\n",
      "epoch:27 step:21543[D loss: 0.434649, acc: 60.94%, op_acc: 34.38%] [G loss: 0.834511]\n",
      "epoch:27 step:21544[D loss: 0.447302, acc: 53.12%, op_acc: 35.94%] [G loss: 0.836791]\n",
      "epoch:27 step:21545[D loss: 0.381619, acc: 72.66%, op_acc: 47.66%] [G loss: 0.887298]\n",
      "epoch:27 step:21546[D loss: 0.379780, acc: 64.84%, op_acc: 43.75%] [G loss: 0.921408]\n",
      "epoch:27 step:21547[D loss: 0.432376, acc: 56.25%, op_acc: 42.97%] [G loss: 0.932489]\n",
      "epoch:27 step:21548[D loss: 0.415567, acc: 57.03%, op_acc: 41.41%] [G loss: 0.856462]\n",
      "epoch:27 step:21549[D loss: 0.404972, acc: 71.09%, op_acc: 35.94%] [G loss: 0.846161]\n",
      "epoch:27 step:21550[D loss: 0.413563, acc: 59.38%, op_acc: 45.31%] [G loss: 0.894347]\n",
      "epoch:27 step:21551[D loss: 0.450921, acc: 56.25%, op_acc: 39.06%] [G loss: 0.946435]\n",
      "epoch:27 step:21552[D loss: 0.419011, acc: 57.03%, op_acc: 39.84%] [G loss: 0.825993]\n",
      "epoch:27 step:21553[D loss: 0.422211, acc: 59.38%, op_acc: 39.84%] [G loss: 0.926371]\n",
      "epoch:27 step:21554[D loss: 0.409015, acc: 63.28%, op_acc: 40.62%] [G loss: 0.900302]\n",
      "epoch:27 step:21555[D loss: 0.395484, acc: 62.50%, op_acc: 42.97%] [G loss: 0.946640]\n",
      "epoch:27 step:21556[D loss: 0.387672, acc: 64.84%, op_acc: 39.06%] [G loss: 0.930985]\n",
      "epoch:27 step:21557[D loss: 0.389662, acc: 69.53%, op_acc: 43.75%] [G loss: 0.878677]\n",
      "epoch:27 step:21558[D loss: 0.427682, acc: 65.62%, op_acc: 36.72%] [G loss: 0.883600]\n",
      "epoch:27 step:21559[D loss: 0.427789, acc: 58.59%, op_acc: 42.19%] [G loss: 0.827660]\n",
      "epoch:27 step:21560[D loss: 0.401386, acc: 64.84%, op_acc: 42.97%] [G loss: 0.924794]\n",
      "epoch:27 step:21561[D loss: 0.431647, acc: 59.38%, op_acc: 40.62%] [G loss: 0.862484]\n",
      "epoch:27 step:21562[D loss: 0.436873, acc: 45.31%, op_acc: 42.97%] [G loss: 0.784189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21563[D loss: 0.424498, acc: 63.28%, op_acc: 40.62%] [G loss: 0.943554]\n",
      "epoch:27 step:21564[D loss: 0.425309, acc: 60.94%, op_acc: 39.06%] [G loss: 0.950117]\n",
      "epoch:27 step:21565[D loss: 0.407557, acc: 64.06%, op_acc: 44.53%] [G loss: 0.933025]\n",
      "epoch:27 step:21566[D loss: 0.408651, acc: 63.28%, op_acc: 45.31%] [G loss: 0.839385]\n",
      "epoch:27 step:21567[D loss: 0.425286, acc: 65.62%, op_acc: 38.28%] [G loss: 0.845313]\n",
      "epoch:27 step:21568[D loss: 0.427650, acc: 60.16%, op_acc: 39.84%] [G loss: 0.821503]\n",
      "epoch:27 step:21569[D loss: 0.396998, acc: 64.06%, op_acc: 42.19%] [G loss: 0.978368]\n",
      "epoch:27 step:21570[D loss: 0.410354, acc: 65.62%, op_acc: 40.62%] [G loss: 0.898034]\n",
      "epoch:27 step:21571[D loss: 0.427028, acc: 57.81%, op_acc: 42.19%] [G loss: 0.911462]\n",
      "epoch:27 step:21572[D loss: 0.446874, acc: 55.47%, op_acc: 38.28%] [G loss: 0.888234]\n",
      "epoch:27 step:21573[D loss: 0.372778, acc: 71.88%, op_acc: 43.75%] [G loss: 0.809480]\n",
      "epoch:27 step:21574[D loss: 0.411967, acc: 66.41%, op_acc: 38.28%] [G loss: 0.903294]\n",
      "epoch:27 step:21575[D loss: 0.426812, acc: 56.25%, op_acc: 39.06%] [G loss: 0.800033]\n",
      "epoch:27 step:21576[D loss: 0.412758, acc: 61.72%, op_acc: 43.75%] [G loss: 0.937708]\n",
      "epoch:27 step:21577[D loss: 0.377938, acc: 71.88%, op_acc: 40.62%] [G loss: 0.842704]\n",
      "epoch:27 step:21578[D loss: 0.472393, acc: 57.81%, op_acc: 35.16%] [G loss: 0.897546]\n",
      "epoch:27 step:21579[D loss: 0.387931, acc: 70.31%, op_acc: 45.31%] [G loss: 0.953637]\n",
      "epoch:27 step:21580[D loss: 0.414989, acc: 60.94%, op_acc: 41.41%] [G loss: 0.899493]\n",
      "epoch:27 step:21581[D loss: 0.416428, acc: 63.28%, op_acc: 39.84%] [G loss: 0.946784]\n",
      "epoch:27 step:21582[D loss: 0.429773, acc: 62.50%, op_acc: 37.50%] [G loss: 0.827302]\n",
      "epoch:27 step:21583[D loss: 0.427718, acc: 60.94%, op_acc: 39.84%] [G loss: 0.929366]\n",
      "epoch:27 step:21584[D loss: 0.410629, acc: 56.25%, op_acc: 43.75%] [G loss: 0.875592]\n",
      "epoch:27 step:21585[D loss: 0.444960, acc: 56.25%, op_acc: 35.94%] [G loss: 0.784072]\n",
      "epoch:27 step:21586[D loss: 0.433452, acc: 65.62%, op_acc: 35.94%] [G loss: 0.912957]\n",
      "epoch:27 step:21587[D loss: 0.366973, acc: 66.41%, op_acc: 46.88%] [G loss: 0.893704]\n",
      "epoch:27 step:21588[D loss: 0.415750, acc: 61.72%, op_acc: 40.62%] [G loss: 0.945642]\n",
      "epoch:27 step:21589[D loss: 0.374763, acc: 67.19%, op_acc: 41.41%] [G loss: 0.986681]\n",
      "epoch:27 step:21590[D loss: 0.416818, acc: 66.41%, op_acc: 39.06%] [G loss: 0.879538]\n",
      "epoch:27 step:21591[D loss: 0.438818, acc: 59.38%, op_acc: 37.50%] [G loss: 0.849788]\n",
      "epoch:27 step:21592[D loss: 0.430599, acc: 54.69%, op_acc: 43.75%] [G loss: 0.943180]\n",
      "epoch:27 step:21593[D loss: 0.404235, acc: 67.19%, op_acc: 42.19%] [G loss: 0.924592]\n",
      "epoch:27 step:21594[D loss: 0.386391, acc: 70.31%, op_acc: 42.19%] [G loss: 0.927589]\n",
      "epoch:27 step:21595[D loss: 0.397152, acc: 67.97%, op_acc: 39.84%] [G loss: 0.893329]\n",
      "epoch:27 step:21596[D loss: 0.458883, acc: 54.69%, op_acc: 34.38%] [G loss: 0.817897]\n",
      "epoch:27 step:21597[D loss: 0.418098, acc: 62.50%, op_acc: 38.28%] [G loss: 0.988793]\n",
      "epoch:27 step:21598[D loss: 0.397061, acc: 58.59%, op_acc: 42.19%] [G loss: 0.926773]\n",
      "epoch:27 step:21599[D loss: 0.413129, acc: 60.94%, op_acc: 39.84%] [G loss: 0.833036]\n",
      "epoch:27 step:21600[D loss: 0.442770, acc: 58.59%, op_acc: 39.06%] [G loss: 0.934238]\n",
      "epoch:27 step:21601[D loss: 0.402699, acc: 65.62%, op_acc: 40.62%] [G loss: 0.968342]\n",
      "epoch:27 step:21602[D loss: 0.377872, acc: 71.88%, op_acc: 37.50%] [G loss: 0.807532]\n",
      "epoch:27 step:21603[D loss: 0.416641, acc: 62.50%, op_acc: 39.84%] [G loss: 0.941203]\n",
      "epoch:27 step:21604[D loss: 0.462412, acc: 52.34%, op_acc: 38.28%] [G loss: 0.930459]\n",
      "epoch:27 step:21605[D loss: 0.405777, acc: 62.50%, op_acc: 42.97%] [G loss: 0.902797]\n",
      "epoch:27 step:21606[D loss: 0.373327, acc: 70.31%, op_acc: 45.31%] [G loss: 0.864577]\n",
      "epoch:27 step:21607[D loss: 0.435241, acc: 55.47%, op_acc: 36.72%] [G loss: 0.919435]\n",
      "epoch:27 step:21608[D loss: 0.409175, acc: 60.16%, op_acc: 35.94%] [G loss: 0.884764]\n",
      "epoch:27 step:21609[D loss: 0.464601, acc: 53.91%, op_acc: 32.81%] [G loss: 0.912990]\n",
      "epoch:27 step:21610[D loss: 0.392453, acc: 67.19%, op_acc: 40.62%] [G loss: 0.910997]\n",
      "epoch:27 step:21611[D loss: 0.390474, acc: 64.06%, op_acc: 50.00%] [G loss: 1.008981]\n",
      "epoch:27 step:21612[D loss: 0.435224, acc: 58.59%, op_acc: 35.16%] [G loss: 0.866285]\n",
      "epoch:27 step:21613[D loss: 0.476133, acc: 49.22%, op_acc: 39.06%] [G loss: 0.937902]\n",
      "epoch:27 step:21614[D loss: 0.422055, acc: 59.38%, op_acc: 40.62%] [G loss: 0.958055]\n",
      "epoch:27 step:21615[D loss: 0.437127, acc: 50.78%, op_acc: 40.62%] [G loss: 0.840691]\n",
      "epoch:27 step:21616[D loss: 0.429019, acc: 59.38%, op_acc: 41.41%] [G loss: 0.884140]\n",
      "epoch:27 step:21617[D loss: 0.424161, acc: 61.72%, op_acc: 37.50%] [G loss: 0.905737]\n",
      "epoch:27 step:21618[D loss: 0.400125, acc: 68.75%, op_acc: 39.84%] [G loss: 0.977038]\n",
      "epoch:27 step:21619[D loss: 0.405998, acc: 66.41%, op_acc: 37.50%] [G loss: 0.959894]\n",
      "epoch:27 step:21620[D loss: 0.405504, acc: 65.62%, op_acc: 39.84%] [G loss: 0.875461]\n",
      "epoch:27 step:21621[D loss: 0.414692, acc: 57.03%, op_acc: 45.31%] [G loss: 0.852758]\n",
      "epoch:27 step:21622[D loss: 0.417656, acc: 61.72%, op_acc: 37.50%] [G loss: 0.939930]\n",
      "epoch:27 step:21623[D loss: 0.361486, acc: 63.28%, op_acc: 46.09%] [G loss: 0.922529]\n",
      "epoch:27 step:21624[D loss: 0.458853, acc: 51.56%, op_acc: 32.81%] [G loss: 0.856153]\n",
      "epoch:27 step:21625[D loss: 0.385923, acc: 69.53%, op_acc: 49.22%] [G loss: 0.998489]\n",
      "epoch:27 step:21626[D loss: 0.442784, acc: 53.12%, op_acc: 39.06%] [G loss: 0.923321]\n",
      "epoch:27 step:21627[D loss: 0.388419, acc: 60.94%, op_acc: 43.75%] [G loss: 0.829953]\n",
      "epoch:27 step:21628[D loss: 0.400905, acc: 64.06%, op_acc: 45.31%] [G loss: 0.945829]\n",
      "epoch:27 step:21629[D loss: 0.444658, acc: 57.81%, op_acc: 36.72%] [G loss: 0.854844]\n",
      "epoch:27 step:21630[D loss: 0.439620, acc: 61.72%, op_acc: 41.41%] [G loss: 0.944339]\n",
      "epoch:27 step:21631[D loss: 0.444681, acc: 57.81%, op_acc: 34.38%] [G loss: 0.713573]\n",
      "epoch:27 step:21632[D loss: 0.377642, acc: 67.19%, op_acc: 40.62%] [G loss: 0.789382]\n",
      "epoch:27 step:21633[D loss: 0.377605, acc: 68.75%, op_acc: 44.53%] [G loss: 0.921064]\n",
      "epoch:27 step:21634[D loss: 0.391824, acc: 71.88%, op_acc: 38.28%] [G loss: 0.914130]\n",
      "epoch:27 step:21635[D loss: 0.450275, acc: 52.34%, op_acc: 42.19%] [G loss: 0.992879]\n",
      "epoch:27 step:21636[D loss: 0.425266, acc: 57.81%, op_acc: 40.62%] [G loss: 0.911801]\n",
      "epoch:27 step:21637[D loss: 0.414913, acc: 53.12%, op_acc: 40.62%] [G loss: 0.893249]\n",
      "epoch:27 step:21638[D loss: 0.436389, acc: 53.12%, op_acc: 40.62%] [G loss: 0.923011]\n",
      "epoch:27 step:21639[D loss: 0.430636, acc: 66.41%, op_acc: 35.94%] [G loss: 0.886396]\n",
      "epoch:27 step:21640[D loss: 0.382268, acc: 68.75%, op_acc: 44.53%] [G loss: 0.795947]\n",
      "epoch:27 step:21641[D loss: 0.434502, acc: 59.38%, op_acc: 40.62%] [G loss: 0.930703]\n",
      "epoch:27 step:21642[D loss: 0.410020, acc: 57.81%, op_acc: 42.19%] [G loss: 0.986489]\n",
      "epoch:27 step:21643[D loss: 0.417116, acc: 64.84%, op_acc: 38.28%] [G loss: 0.935199]\n",
      "epoch:27 step:21644[D loss: 0.424867, acc: 60.16%, op_acc: 35.16%] [G loss: 1.016746]\n",
      "epoch:27 step:21645[D loss: 0.386307, acc: 62.50%, op_acc: 46.09%] [G loss: 0.853784]\n",
      "epoch:27 step:21646[D loss: 0.410794, acc: 70.31%, op_acc: 34.38%] [G loss: 0.795542]\n",
      "epoch:27 step:21647[D loss: 0.446677, acc: 60.16%, op_acc: 32.81%] [G loss: 0.881147]\n",
      "epoch:27 step:21648[D loss: 0.384183, acc: 65.62%, op_acc: 46.88%] [G loss: 0.860159]\n",
      "epoch:27 step:21649[D loss: 0.419798, acc: 57.03%, op_acc: 40.62%] [G loss: 0.797574]\n",
      "epoch:27 step:21650[D loss: 0.442068, acc: 60.94%, op_acc: 35.16%] [G loss: 0.801202]\n",
      "epoch:27 step:21651[D loss: 0.376012, acc: 70.31%, op_acc: 43.75%] [G loss: 0.823328]\n",
      "epoch:27 step:21652[D loss: 0.396927, acc: 66.41%, op_acc: 46.09%] [G loss: 0.910645]\n",
      "epoch:27 step:21653[D loss: 0.435232, acc: 56.25%, op_acc: 36.72%] [G loss: 0.980470]\n",
      "epoch:27 step:21654[D loss: 0.421185, acc: 59.38%, op_acc: 45.31%] [G loss: 0.975289]\n",
      "epoch:27 step:21655[D loss: 0.394526, acc: 60.94%, op_acc: 38.28%] [G loss: 0.833855]\n",
      "epoch:27 step:21656[D loss: 0.414311, acc: 60.16%, op_acc: 36.72%] [G loss: 0.829726]\n",
      "epoch:27 step:21657[D loss: 0.399475, acc: 65.62%, op_acc: 41.41%] [G loss: 0.906333]\n",
      "epoch:27 step:21658[D loss: 0.439389, acc: 56.25%, op_acc: 39.06%] [G loss: 0.960085]\n",
      "epoch:27 step:21659[D loss: 0.402291, acc: 64.84%, op_acc: 42.97%] [G loss: 0.935826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21660[D loss: 0.407112, acc: 65.62%, op_acc: 40.62%] [G loss: 0.866655]\n",
      "epoch:27 step:21661[D loss: 0.428105, acc: 58.59%, op_acc: 38.28%] [G loss: 0.932261]\n",
      "epoch:27 step:21662[D loss: 0.419767, acc: 60.16%, op_acc: 34.38%] [G loss: 0.890273]\n",
      "epoch:27 step:21663[D loss: 0.424097, acc: 58.59%, op_acc: 45.31%] [G loss: 0.897453]\n",
      "epoch:27 step:21664[D loss: 0.414689, acc: 67.19%, op_acc: 41.41%] [G loss: 1.022369]\n",
      "epoch:27 step:21665[D loss: 0.437106, acc: 67.19%, op_acc: 39.84%] [G loss: 0.909919]\n",
      "epoch:27 step:21666[D loss: 0.388983, acc: 67.97%, op_acc: 42.97%] [G loss: 0.941044]\n",
      "epoch:27 step:21667[D loss: 0.421495, acc: 61.72%, op_acc: 35.94%] [G loss: 0.776271]\n",
      "epoch:27 step:21668[D loss: 0.436129, acc: 56.25%, op_acc: 35.94%] [G loss: 0.884403]\n",
      "epoch:27 step:21669[D loss: 0.398239, acc: 64.06%, op_acc: 42.19%] [G loss: 0.969870]\n",
      "epoch:27 step:21670[D loss: 0.396524, acc: 57.81%, op_acc: 44.53%] [G loss: 0.857532]\n",
      "epoch:27 step:21671[D loss: 0.446083, acc: 63.28%, op_acc: 31.25%] [G loss: 0.987591]\n",
      "epoch:27 step:21672[D loss: 0.391125, acc: 67.19%, op_acc: 46.88%] [G loss: 0.946701]\n",
      "epoch:27 step:21673[D loss: 0.403532, acc: 64.84%, op_acc: 45.31%] [G loss: 0.911341]\n",
      "epoch:27 step:21674[D loss: 0.408990, acc: 67.97%, op_acc: 40.62%] [G loss: 0.825249]\n",
      "epoch:27 step:21675[D loss: 0.398951, acc: 64.06%, op_acc: 45.31%] [G loss: 1.010077]\n",
      "epoch:27 step:21676[D loss: 0.409334, acc: 66.41%, op_acc: 35.94%] [G loss: 0.938164]\n",
      "epoch:27 step:21677[D loss: 0.402138, acc: 63.28%, op_acc: 36.72%] [G loss: 0.837046]\n",
      "epoch:27 step:21678[D loss: 0.429134, acc: 59.38%, op_acc: 40.62%] [G loss: 0.853663]\n",
      "epoch:27 step:21679[D loss: 0.422143, acc: 60.16%, op_acc: 42.19%] [G loss: 0.975225]\n",
      "epoch:27 step:21680[D loss: 0.418489, acc: 60.94%, op_acc: 39.84%] [G loss: 0.948595]\n",
      "epoch:27 step:21681[D loss: 0.432049, acc: 56.25%, op_acc: 45.31%] [G loss: 0.942897]\n",
      "epoch:27 step:21682[D loss: 0.382569, acc: 70.31%, op_acc: 45.31%] [G loss: 0.891090]\n",
      "epoch:27 step:21683[D loss: 0.438307, acc: 53.91%, op_acc: 39.06%] [G loss: 0.928174]\n",
      "epoch:27 step:21684[D loss: 0.350080, acc: 76.56%, op_acc: 41.41%] [G loss: 0.945897]\n",
      "epoch:27 step:21685[D loss: 0.409532, acc: 62.50%, op_acc: 39.06%] [G loss: 0.934474]\n",
      "epoch:27 step:21686[D loss: 0.403793, acc: 67.97%, op_acc: 38.28%] [G loss: 0.910643]\n",
      "epoch:27 step:21687[D loss: 0.415474, acc: 60.94%, op_acc: 35.94%] [G loss: 0.862556]\n",
      "epoch:27 step:21688[D loss: 0.398063, acc: 66.41%, op_acc: 41.41%] [G loss: 0.921147]\n",
      "epoch:27 step:21689[D loss: 0.394452, acc: 64.06%, op_acc: 43.75%] [G loss: 0.858102]\n",
      "epoch:27 step:21690[D loss: 0.381231, acc: 64.06%, op_acc: 47.66%] [G loss: 0.989599]\n",
      "epoch:27 step:21691[D loss: 0.406195, acc: 64.84%, op_acc: 44.53%] [G loss: 0.886927]\n",
      "epoch:27 step:21692[D loss: 0.379714, acc: 71.09%, op_acc: 46.09%] [G loss: 1.072565]\n",
      "epoch:27 step:21693[D loss: 0.432633, acc: 59.38%, op_acc: 36.72%] [G loss: 0.860827]\n",
      "epoch:27 step:21694[D loss: 0.401396, acc: 60.16%, op_acc: 44.53%] [G loss: 0.851353]\n",
      "epoch:27 step:21695[D loss: 0.384398, acc: 70.31%, op_acc: 43.75%] [G loss: 0.903615]\n",
      "epoch:27 step:21696[D loss: 0.417101, acc: 58.59%, op_acc: 40.62%] [G loss: 0.927775]\n",
      "epoch:27 step:21697[D loss: 0.409937, acc: 60.16%, op_acc: 39.84%] [G loss: 0.896503]\n",
      "epoch:27 step:21698[D loss: 0.407234, acc: 61.72%, op_acc: 42.19%] [G loss: 0.976893]\n",
      "epoch:27 step:21699[D loss: 0.384776, acc: 69.53%, op_acc: 43.75%] [G loss: 0.985949]\n",
      "epoch:27 step:21700[D loss: 0.417904, acc: 61.72%, op_acc: 39.84%] [G loss: 0.872548]\n",
      "epoch:27 step:21701[D loss: 0.393883, acc: 67.97%, op_acc: 37.50%] [G loss: 0.903546]\n",
      "epoch:27 step:21702[D loss: 0.424285, acc: 60.94%, op_acc: 36.72%] [G loss: 0.807501]\n",
      "epoch:27 step:21703[D loss: 0.460629, acc: 54.69%, op_acc: 37.50%] [G loss: 0.920479]\n",
      "epoch:27 step:21704[D loss: 0.448699, acc: 53.91%, op_acc: 34.38%] [G loss: 0.904484]\n",
      "epoch:27 step:21705[D loss: 0.383947, acc: 68.75%, op_acc: 44.53%] [G loss: 0.941643]\n",
      "epoch:27 step:21706[D loss: 0.458018, acc: 55.47%, op_acc: 39.06%] [G loss: 0.920604]\n",
      "epoch:27 step:21707[D loss: 0.456324, acc: 52.34%, op_acc: 35.94%] [G loss: 0.862979]\n",
      "epoch:27 step:21708[D loss: 0.406021, acc: 62.50%, op_acc: 46.09%] [G loss: 0.859522]\n",
      "epoch:27 step:21709[D loss: 0.459384, acc: 56.25%, op_acc: 35.16%] [G loss: 0.764362]\n",
      "epoch:27 step:21710[D loss: 0.411183, acc: 60.94%, op_acc: 43.75%] [G loss: 0.910543]\n",
      "epoch:27 step:21711[D loss: 0.429885, acc: 59.38%, op_acc: 39.06%] [G loss: 1.022304]\n",
      "epoch:27 step:21712[D loss: 0.463145, acc: 44.53%, op_acc: 42.19%] [G loss: 0.929814]\n",
      "epoch:27 step:21713[D loss: 0.421323, acc: 53.91%, op_acc: 42.19%] [G loss: 0.887714]\n",
      "epoch:27 step:21714[D loss: 0.419241, acc: 58.59%, op_acc: 37.50%] [G loss: 0.893523]\n",
      "epoch:27 step:21715[D loss: 0.417152, acc: 61.72%, op_acc: 43.75%] [G loss: 0.865686]\n",
      "epoch:27 step:21716[D loss: 0.410514, acc: 60.94%, op_acc: 38.28%] [G loss: 0.868640]\n",
      "epoch:27 step:21717[D loss: 0.360648, acc: 78.12%, op_acc: 42.97%] [G loss: 0.940415]\n",
      "epoch:27 step:21718[D loss: 0.424946, acc: 61.72%, op_acc: 39.84%] [G loss: 0.783866]\n",
      "epoch:27 step:21719[D loss: 0.425288, acc: 68.75%, op_acc: 35.16%] [G loss: 0.789061]\n",
      "epoch:27 step:21720[D loss: 0.393478, acc: 67.19%, op_acc: 39.84%] [G loss: 0.818674]\n",
      "epoch:27 step:21721[D loss: 0.430783, acc: 57.03%, op_acc: 37.50%] [G loss: 0.944020]\n",
      "epoch:27 step:21722[D loss: 0.399880, acc: 60.94%, op_acc: 45.31%] [G loss: 0.916778]\n",
      "epoch:27 step:21723[D loss: 0.386442, acc: 64.06%, op_acc: 47.66%] [G loss: 0.891620]\n",
      "epoch:27 step:21724[D loss: 0.408171, acc: 62.50%, op_acc: 39.84%] [G loss: 0.854236]\n",
      "epoch:27 step:21725[D loss: 0.416012, acc: 60.16%, op_acc: 36.72%] [G loss: 0.857647]\n",
      "epoch:27 step:21726[D loss: 0.419638, acc: 66.41%, op_acc: 43.75%] [G loss: 0.947924]\n",
      "epoch:27 step:21727[D loss: 0.432823, acc: 57.81%, op_acc: 35.16%] [G loss: 0.953310]\n",
      "epoch:27 step:21728[D loss: 0.398397, acc: 62.50%, op_acc: 42.19%] [G loss: 1.021379]\n",
      "epoch:27 step:21729[D loss: 0.381472, acc: 70.31%, op_acc: 41.41%] [G loss: 0.881079]\n",
      "epoch:27 step:21730[D loss: 0.438393, acc: 57.03%, op_acc: 39.06%] [G loss: 0.982347]\n",
      "epoch:27 step:21731[D loss: 0.360364, acc: 65.62%, op_acc: 46.09%] [G loss: 0.981005]\n",
      "epoch:27 step:21732[D loss: 0.403119, acc: 62.50%, op_acc: 42.97%] [G loss: 0.912293]\n",
      "epoch:27 step:21733[D loss: 0.414901, acc: 64.84%, op_acc: 37.50%] [G loss: 1.106585]\n",
      "epoch:27 step:21734[D loss: 0.371098, acc: 77.34%, op_acc: 44.53%] [G loss: 1.006903]\n",
      "epoch:27 step:21735[D loss: 0.394869, acc: 67.19%, op_acc: 42.19%] [G loss: 1.084736]\n",
      "epoch:27 step:21736[D loss: 0.402936, acc: 63.28%, op_acc: 37.50%] [G loss: 1.004682]\n",
      "epoch:27 step:21737[D loss: 0.404761, acc: 63.28%, op_acc: 39.84%] [G loss: 1.054181]\n",
      "epoch:27 step:21738[D loss: 0.371199, acc: 75.78%, op_acc: 45.31%] [G loss: 0.931039]\n",
      "epoch:27 step:21739[D loss: 0.365119, acc: 73.44%, op_acc: 53.12%] [G loss: 1.125934]\n",
      "epoch:27 step:21740[D loss: 0.361665, acc: 72.66%, op_acc: 42.97%] [G loss: 1.076519]\n",
      "epoch:27 step:21741[D loss: 0.395507, acc: 64.06%, op_acc: 46.88%] [G loss: 1.093840]\n",
      "epoch:27 step:21742[D loss: 0.372783, acc: 73.44%, op_acc: 42.19%] [G loss: 1.000858]\n",
      "epoch:27 step:21743[D loss: 0.402969, acc: 67.19%, op_acc: 42.19%] [G loss: 1.046509]\n",
      "epoch:27 step:21744[D loss: 0.414072, acc: 60.16%, op_acc: 42.97%] [G loss: 0.771147]\n",
      "epoch:27 step:21745[D loss: 0.352439, acc: 71.09%, op_acc: 44.53%] [G loss: 0.749425]\n",
      "epoch:27 step:21746[D loss: 0.439963, acc: 60.16%, op_acc: 34.38%] [G loss: 0.946231]\n",
      "epoch:27 step:21747[D loss: 0.415338, acc: 63.28%, op_acc: 34.38%] [G loss: 1.012000]\n",
      "epoch:27 step:21748[D loss: 0.382621, acc: 69.53%, op_acc: 40.62%] [G loss: 0.737243]\n",
      "epoch:27 step:21749[D loss: 0.442733, acc: 50.00%, op_acc: 43.75%] [G loss: 0.683182]\n",
      "epoch:27 step:21750[D loss: 0.422678, acc: 56.25%, op_acc: 39.06%] [G loss: 0.741593]\n",
      "epoch:27 step:21751[D loss: 0.489588, acc: 41.41%, op_acc: 40.62%] [G loss: 0.952963]\n",
      "epoch:27 step:21752[D loss: 0.454663, acc: 59.38%, op_acc: 34.38%] [G loss: 0.923753]\n",
      "epoch:27 step:21753[D loss: 0.422304, acc: 63.28%, op_acc: 37.50%] [G loss: 0.971134]\n",
      "epoch:27 step:21754[D loss: 0.434544, acc: 54.69%, op_acc: 39.06%] [G loss: 0.906965]\n",
      "epoch:27 step:21755[D loss: 0.472592, acc: 44.53%, op_acc: 39.06%] [G loss: 0.978747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21756[D loss: 0.429552, acc: 57.81%, op_acc: 39.06%] [G loss: 0.968967]\n",
      "epoch:27 step:21757[D loss: 0.410346, acc: 53.12%, op_acc: 43.75%] [G loss: 0.932469]\n",
      "epoch:27 step:21758[D loss: 0.392285, acc: 71.09%, op_acc: 37.50%] [G loss: 0.941840]\n",
      "epoch:27 step:21759[D loss: 0.475847, acc: 54.69%, op_acc: 33.59%] [G loss: 0.879549]\n",
      "epoch:27 step:21760[D loss: 0.427500, acc: 59.38%, op_acc: 37.50%] [G loss: 0.989436]\n",
      "epoch:27 step:21761[D loss: 0.405905, acc: 59.38%, op_acc: 40.62%] [G loss: 1.017129]\n",
      "epoch:27 step:21762[D loss: 0.415133, acc: 61.72%, op_acc: 35.16%] [G loss: 1.033780]\n",
      "epoch:27 step:21763[D loss: 0.448268, acc: 60.94%, op_acc: 35.16%] [G loss: 0.834438]\n",
      "epoch:27 step:21764[D loss: 0.404243, acc: 72.66%, op_acc: 36.72%] [G loss: 0.981344]\n",
      "epoch:27 step:21765[D loss: 0.424965, acc: 54.69%, op_acc: 42.97%] [G loss: 0.987307]\n",
      "epoch:27 step:21766[D loss: 0.383077, acc: 68.75%, op_acc: 43.75%] [G loss: 0.940802]\n",
      "epoch:27 step:21767[D loss: 0.416877, acc: 60.16%, op_acc: 39.84%] [G loss: 0.765518]\n",
      "epoch:27 step:21768[D loss: 0.441364, acc: 60.16%, op_acc: 37.50%] [G loss: 1.027591]\n",
      "epoch:27 step:21769[D loss: 0.431371, acc: 54.69%, op_acc: 42.97%] [G loss: 1.042808]\n",
      "epoch:27 step:21770[D loss: 0.416161, acc: 60.94%, op_acc: 42.19%] [G loss: 0.933939]\n",
      "epoch:27 step:21771[D loss: 0.453204, acc: 53.91%, op_acc: 35.94%] [G loss: 0.864899]\n",
      "epoch:27 step:21772[D loss: 0.417469, acc: 57.81%, op_acc: 40.62%] [G loss: 0.824964]\n",
      "epoch:27 step:21773[D loss: 0.452009, acc: 57.81%, op_acc: 39.84%] [G loss: 0.813050]\n",
      "epoch:27 step:21774[D loss: 0.405096, acc: 62.50%, op_acc: 39.84%] [G loss: 0.838587]\n",
      "epoch:27 step:21775[D loss: 0.421463, acc: 55.47%, op_acc: 41.41%] [G loss: 0.890725]\n",
      "epoch:27 step:21776[D loss: 0.457790, acc: 46.09%, op_acc: 42.19%] [G loss: 0.925070]\n",
      "epoch:27 step:21777[D loss: 0.413724, acc: 67.19%, op_acc: 35.94%] [G loss: 0.973734]\n",
      "epoch:27 step:21778[D loss: 0.418621, acc: 57.81%, op_acc: 36.72%] [G loss: 0.926122]\n",
      "epoch:27 step:21779[D loss: 0.459895, acc: 59.38%, op_acc: 39.06%] [G loss: 0.979610]\n",
      "epoch:27 step:21780[D loss: 0.416168, acc: 60.16%, op_acc: 41.41%] [G loss: 0.941362]\n",
      "epoch:27 step:21781[D loss: 0.422680, acc: 57.03%, op_acc: 41.41%] [G loss: 0.769969]\n",
      "epoch:27 step:21782[D loss: 0.410992, acc: 58.59%, op_acc: 40.62%] [G loss: 0.940052]\n",
      "epoch:27 step:21783[D loss: 0.397675, acc: 64.84%, op_acc: 45.31%] [G loss: 1.011044]\n",
      "epoch:27 step:21784[D loss: 0.430342, acc: 57.03%, op_acc: 39.06%] [G loss: 0.907503]\n",
      "epoch:27 step:21785[D loss: 0.405599, acc: 64.06%, op_acc: 39.84%] [G loss: 1.036893]\n",
      "epoch:27 step:21786[D loss: 0.410834, acc: 60.94%, op_acc: 43.75%] [G loss: 0.955103]\n",
      "epoch:27 step:21787[D loss: 0.395428, acc: 67.97%, op_acc: 41.41%] [G loss: 0.808063]\n",
      "epoch:27 step:21788[D loss: 0.440651, acc: 54.69%, op_acc: 42.97%] [G loss: 0.910266]\n",
      "epoch:27 step:21789[D loss: 0.404589, acc: 64.84%, op_acc: 37.50%] [G loss: 0.911126]\n",
      "epoch:27 step:21790[D loss: 0.444983, acc: 58.59%, op_acc: 42.19%] [G loss: 0.861622]\n",
      "epoch:27 step:21791[D loss: 0.390078, acc: 62.50%, op_acc: 48.44%] [G loss: 0.860997]\n",
      "epoch:27 step:21792[D loss: 0.400052, acc: 70.31%, op_acc: 34.38%] [G loss: 0.866781]\n",
      "epoch:27 step:21793[D loss: 0.424714, acc: 61.72%, op_acc: 39.84%] [G loss: 0.861602]\n",
      "epoch:27 step:21794[D loss: 0.466776, acc: 53.91%, op_acc: 43.75%] [G loss: 0.844683]\n",
      "epoch:27 step:21795[D loss: 0.451738, acc: 57.03%, op_acc: 39.84%] [G loss: 0.865357]\n",
      "epoch:27 step:21796[D loss: 0.390036, acc: 67.97%, op_acc: 42.97%] [G loss: 0.891700]\n",
      "epoch:27 step:21797[D loss: 0.383842, acc: 62.50%, op_acc: 45.31%] [G loss: 0.985034]\n",
      "epoch:27 step:21798[D loss: 0.414994, acc: 60.16%, op_acc: 37.50%] [G loss: 0.995554]\n",
      "epoch:27 step:21799[D loss: 0.407836, acc: 62.50%, op_acc: 40.62%] [G loss: 0.881093]\n",
      "epoch:27 step:21800[D loss: 0.378747, acc: 66.41%, op_acc: 46.09%] [G loss: 0.941051]\n",
      "epoch:27 step:21801[D loss: 0.401072, acc: 63.28%, op_acc: 38.28%] [G loss: 0.982964]\n",
      "epoch:27 step:21802[D loss: 0.408183, acc: 60.16%, op_acc: 39.84%] [G loss: 0.985393]\n",
      "epoch:27 step:21803[D loss: 0.403707, acc: 65.62%, op_acc: 34.38%] [G loss: 0.882680]\n",
      "epoch:27 step:21804[D loss: 0.413831, acc: 53.12%, op_acc: 46.09%] [G loss: 0.911727]\n",
      "epoch:27 step:21805[D loss: 0.448717, acc: 57.81%, op_acc: 41.41%] [G loss: 0.878959]\n",
      "epoch:27 step:21806[D loss: 0.391457, acc: 61.72%, op_acc: 42.19%] [G loss: 0.840347]\n",
      "epoch:27 step:21807[D loss: 0.395263, acc: 65.62%, op_acc: 49.22%] [G loss: 0.973170]\n",
      "epoch:27 step:21808[D loss: 0.405788, acc: 63.28%, op_acc: 42.19%] [G loss: 0.841553]\n",
      "epoch:27 step:21809[D loss: 0.398906, acc: 60.16%, op_acc: 43.75%] [G loss: 0.966939]\n",
      "epoch:27 step:21810[D loss: 0.413418, acc: 64.06%, op_acc: 41.41%] [G loss: 0.972572]\n",
      "epoch:27 step:21811[D loss: 0.442378, acc: 58.59%, op_acc: 35.16%] [G loss: 0.868652]\n",
      "epoch:27 step:21812[D loss: 0.420668, acc: 66.41%, op_acc: 36.72%] [G loss: 0.852627]\n",
      "epoch:27 step:21813[D loss: 0.388137, acc: 63.28%, op_acc: 41.41%] [G loss: 0.906415]\n",
      "epoch:27 step:21814[D loss: 0.419021, acc: 65.62%, op_acc: 35.16%] [G loss: 0.786264]\n",
      "epoch:27 step:21815[D loss: 0.416806, acc: 58.59%, op_acc: 42.19%] [G loss: 0.901681]\n",
      "epoch:27 step:21816[D loss: 0.426702, acc: 55.47%, op_acc: 43.75%] [G loss: 0.826848]\n",
      "epoch:27 step:21817[D loss: 0.415678, acc: 59.38%, op_acc: 35.16%] [G loss: 0.826379]\n",
      "epoch:27 step:21818[D loss: 0.381427, acc: 67.97%, op_acc: 43.75%] [G loss: 0.979726]\n",
      "epoch:27 step:21819[D loss: 0.412236, acc: 61.72%, op_acc: 42.19%] [G loss: 0.920652]\n",
      "epoch:27 step:21820[D loss: 0.393930, acc: 65.62%, op_acc: 44.53%] [G loss: 0.900517]\n",
      "epoch:27 step:21821[D loss: 0.397782, acc: 71.88%, op_acc: 40.62%] [G loss: 1.027323]\n",
      "epoch:27 step:21822[D loss: 0.411104, acc: 62.50%, op_acc: 37.50%] [G loss: 0.744817]\n",
      "epoch:27 step:21823[D loss: 0.396788, acc: 65.62%, op_acc: 43.75%] [G loss: 0.990341]\n",
      "epoch:27 step:21824[D loss: 0.410083, acc: 64.06%, op_acc: 40.62%] [G loss: 1.045633]\n",
      "epoch:27 step:21825[D loss: 0.417324, acc: 58.59%, op_acc: 41.41%] [G loss: 0.918609]\n",
      "epoch:27 step:21826[D loss: 0.411430, acc: 58.59%, op_acc: 46.09%] [G loss: 0.762462]\n",
      "epoch:27 step:21827[D loss: 0.409847, acc: 63.28%, op_acc: 39.84%] [G loss: 1.058059]\n",
      "epoch:27 step:21828[D loss: 0.419322, acc: 64.06%, op_acc: 38.28%] [G loss: 0.959084]\n",
      "epoch:27 step:21829[D loss: 0.397561, acc: 74.22%, op_acc: 36.72%] [G loss: 0.840646]\n",
      "epoch:27 step:21830[D loss: 0.407526, acc: 64.84%, op_acc: 41.41%] [G loss: 0.839788]\n",
      "epoch:27 step:21831[D loss: 0.427882, acc: 50.00%, op_acc: 40.62%] [G loss: 0.962796]\n",
      "epoch:27 step:21832[D loss: 0.407091, acc: 60.94%, op_acc: 43.75%] [G loss: 0.916623]\n",
      "epoch:27 step:21833[D loss: 0.441099, acc: 54.69%, op_acc: 42.19%] [G loss: 1.001272]\n",
      "epoch:27 step:21834[D loss: 0.454477, acc: 49.22%, op_acc: 35.16%] [G loss: 0.819813]\n",
      "epoch:27 step:21835[D loss: 0.478379, acc: 48.44%, op_acc: 35.16%] [G loss: 0.912153]\n",
      "epoch:27 step:21836[D loss: 0.407631, acc: 64.84%, op_acc: 40.62%] [G loss: 0.910769]\n",
      "epoch:27 step:21837[D loss: 0.386623, acc: 65.62%, op_acc: 46.88%] [G loss: 0.921048]\n",
      "epoch:27 step:21838[D loss: 0.447078, acc: 60.16%, op_acc: 39.84%] [G loss: 0.661988]\n",
      "epoch:27 step:21839[D loss: 0.401787, acc: 61.72%, op_acc: 47.66%] [G loss: 0.919493]\n",
      "epoch:27 step:21840[D loss: 0.401475, acc: 64.84%, op_acc: 41.41%] [G loss: 0.846423]\n",
      "epoch:27 step:21841[D loss: 0.402864, acc: 65.62%, op_acc: 41.41%] [G loss: 0.894674]\n",
      "epoch:27 step:21842[D loss: 0.410165, acc: 61.72%, op_acc: 42.19%] [G loss: 0.866472]\n",
      "epoch:27 step:21843[D loss: 0.416327, acc: 56.25%, op_acc: 43.75%] [G loss: 0.850672]\n",
      "epoch:27 step:21844[D loss: 0.421475, acc: 57.81%, op_acc: 39.06%] [G loss: 0.937992]\n",
      "epoch:27 step:21845[D loss: 0.394742, acc: 65.62%, op_acc: 47.66%] [G loss: 0.870154]\n",
      "epoch:27 step:21846[D loss: 0.440930, acc: 52.34%, op_acc: 36.72%] [G loss: 0.897148]\n",
      "epoch:27 step:21847[D loss: 0.403839, acc: 67.97%, op_acc: 42.19%] [G loss: 0.929920]\n",
      "epoch:27 step:21848[D loss: 0.400910, acc: 56.25%, op_acc: 42.19%] [G loss: 0.882247]\n",
      "epoch:27 step:21849[D loss: 0.424648, acc: 59.38%, op_acc: 42.19%] [G loss: 0.918853]\n",
      "epoch:27 step:21850[D loss: 0.406701, acc: 57.81%, op_acc: 42.19%] [G loss: 0.967914]\n",
      "epoch:27 step:21851[D loss: 0.388901, acc: 65.62%, op_acc: 39.84%] [G loss: 0.977272]\n",
      "epoch:27 step:21852[D loss: 0.381102, acc: 70.31%, op_acc: 46.09%] [G loss: 0.937991]\n",
      "epoch:27 step:21853[D loss: 0.426139, acc: 67.19%, op_acc: 33.59%] [G loss: 0.977327]\n",
      "epoch:27 step:21854[D loss: 0.380778, acc: 71.09%, op_acc: 42.97%] [G loss: 1.064387]\n",
      "epoch:27 step:21855[D loss: 0.402072, acc: 59.38%, op_acc: 42.19%] [G loss: 0.906513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:21856[D loss: 0.373083, acc: 72.66%, op_acc: 44.53%] [G loss: 0.874074]\n",
      "epoch:27 step:21857[D loss: 0.401247, acc: 64.84%, op_acc: 39.06%] [G loss: 0.963949]\n",
      "epoch:27 step:21858[D loss: 0.415302, acc: 62.50%, op_acc: 42.97%] [G loss: 1.011165]\n",
      "epoch:27 step:21859[D loss: 0.465856, acc: 55.47%, op_acc: 39.06%] [G loss: 0.987484]\n",
      "epoch:27 step:21860[D loss: 0.409412, acc: 65.62%, op_acc: 38.28%] [G loss: 1.038502]\n",
      "epoch:27 step:21861[D loss: 0.405064, acc: 60.16%, op_acc: 42.19%] [G loss: 1.000971]\n",
      "epoch:27 step:21862[D loss: 0.426031, acc: 58.59%, op_acc: 32.03%] [G loss: 1.048632]\n",
      "epoch:27 step:21863[D loss: 0.426755, acc: 54.69%, op_acc: 40.62%] [G loss: 0.853045]\n",
      "epoch:27 step:21864[D loss: 0.424859, acc: 64.06%, op_acc: 39.06%] [G loss: 1.023520]\n",
      "epoch:27 step:21865[D loss: 0.402376, acc: 67.19%, op_acc: 42.19%] [G loss: 0.838730]\n",
      "epoch:27 step:21866[D loss: 0.417263, acc: 58.59%, op_acc: 38.28%] [G loss: 1.043638]\n",
      "epoch:27 step:21867[D loss: 0.430039, acc: 53.91%, op_acc: 46.09%] [G loss: 1.113322]\n",
      "epoch:27 step:21868[D loss: 0.396936, acc: 69.53%, op_acc: 41.41%] [G loss: 1.167393]\n",
      "epoch:28 step:21869[D loss: 0.398313, acc: 60.16%, op_acc: 45.31%] [G loss: 1.152936]\n",
      "epoch:28 step:21870[D loss: 0.399706, acc: 60.16%, op_acc: 42.97%] [G loss: 0.832100]\n",
      "epoch:28 step:21871[D loss: 0.369220, acc: 73.44%, op_acc: 47.66%] [G loss: 0.945013]\n",
      "epoch:28 step:21872[D loss: 0.378418, acc: 59.38%, op_acc: 47.66%] [G loss: 0.950000]\n",
      "epoch:28 step:21873[D loss: 0.386758, acc: 67.19%, op_acc: 43.75%] [G loss: 1.104229]\n",
      "epoch:28 step:21874[D loss: 0.398322, acc: 64.06%, op_acc: 46.88%] [G loss: 1.043223]\n",
      "epoch:28 step:21875[D loss: 0.413403, acc: 64.84%, op_acc: 40.62%] [G loss: 1.017458]\n",
      "epoch:28 step:21876[D loss: 0.376218, acc: 70.31%, op_acc: 49.22%] [G loss: 1.146496]\n",
      "epoch:28 step:21877[D loss: 0.372090, acc: 64.06%, op_acc: 46.09%] [G loss: 0.647176]\n",
      "epoch:28 step:21878[D loss: 0.449913, acc: 57.03%, op_acc: 35.94%] [G loss: 1.073417]\n",
      "epoch:28 step:21879[D loss: 0.414132, acc: 60.94%, op_acc: 42.19%] [G loss: 0.871920]\n",
      "epoch:28 step:21880[D loss: 0.416425, acc: 61.72%, op_acc: 39.84%] [G loss: 0.889564]\n",
      "epoch:28 step:21881[D loss: 0.409134, acc: 64.84%, op_acc: 39.84%] [G loss: 0.988647]\n",
      "epoch:28 step:21882[D loss: 0.418066, acc: 61.72%, op_acc: 45.31%] [G loss: 0.938013]\n",
      "epoch:28 step:21883[D loss: 0.382890, acc: 66.41%, op_acc: 44.53%] [G loss: 1.034494]\n",
      "epoch:28 step:21884[D loss: 0.406328, acc: 62.50%, op_acc: 42.97%] [G loss: 0.829535]\n",
      "epoch:28 step:21885[D loss: 0.428428, acc: 57.03%, op_acc: 45.31%] [G loss: 1.047511]\n",
      "epoch:28 step:21886[D loss: 0.446163, acc: 48.44%, op_acc: 36.72%] [G loss: 1.033699]\n",
      "epoch:28 step:21887[D loss: 0.387695, acc: 61.72%, op_acc: 50.00%] [G loss: 0.798166]\n",
      "epoch:28 step:21888[D loss: 0.435140, acc: 57.81%, op_acc: 41.41%] [G loss: 0.914993]\n",
      "epoch:28 step:21889[D loss: 0.468664, acc: 46.09%, op_acc: 35.94%] [G loss: 0.924608]\n",
      "epoch:28 step:21890[D loss: 0.416233, acc: 61.72%, op_acc: 47.66%] [G loss: 0.861742]\n",
      "epoch:28 step:21891[D loss: 0.430137, acc: 57.81%, op_acc: 41.41%] [G loss: 0.836082]\n",
      "epoch:28 step:21892[D loss: 0.430469, acc: 57.81%, op_acc: 39.06%] [G loss: 0.971153]\n",
      "epoch:28 step:21893[D loss: 0.435100, acc: 60.16%, op_acc: 36.72%] [G loss: 0.956403]\n",
      "epoch:28 step:21894[D loss: 0.425114, acc: 59.38%, op_acc: 42.19%] [G loss: 0.982432]\n",
      "epoch:28 step:21895[D loss: 0.401682, acc: 59.38%, op_acc: 40.62%] [G loss: 0.951430]\n",
      "epoch:28 step:21896[D loss: 0.425629, acc: 58.59%, op_acc: 39.06%] [G loss: 0.949094]\n",
      "epoch:28 step:21897[D loss: 0.427088, acc: 58.59%, op_acc: 39.84%] [G loss: 0.988010]\n",
      "epoch:28 step:21898[D loss: 0.415633, acc: 53.12%, op_acc: 44.53%] [G loss: 0.951518]\n",
      "epoch:28 step:21899[D loss: 0.449959, acc: 57.81%, op_acc: 39.06%] [G loss: 0.967425]\n",
      "epoch:28 step:21900[D loss: 0.454517, acc: 53.91%, op_acc: 33.59%] [G loss: 0.834528]\n",
      "epoch:28 step:21901[D loss: 0.398554, acc: 64.84%, op_acc: 40.62%] [G loss: 0.896264]\n",
      "epoch:28 step:21902[D loss: 0.415113, acc: 60.16%, op_acc: 42.19%] [G loss: 0.943772]\n",
      "epoch:28 step:21903[D loss: 0.457720, acc: 55.47%, op_acc: 37.50%] [G loss: 0.885657]\n",
      "epoch:28 step:21904[D loss: 0.416186, acc: 60.94%, op_acc: 46.09%] [G loss: 0.960512]\n",
      "epoch:28 step:21905[D loss: 0.397802, acc: 62.50%, op_acc: 39.06%] [G loss: 0.889444]\n",
      "epoch:28 step:21906[D loss: 0.458919, acc: 53.12%, op_acc: 36.72%] [G loss: 0.770660]\n",
      "epoch:28 step:21907[D loss: 0.431815, acc: 54.69%, op_acc: 39.84%] [G loss: 0.862560]\n",
      "epoch:28 step:21908[D loss: 0.451398, acc: 59.38%, op_acc: 34.38%] [G loss: 0.912839]\n",
      "epoch:28 step:21909[D loss: 0.416101, acc: 56.25%, op_acc: 46.09%] [G loss: 0.817110]\n",
      "epoch:28 step:21910[D loss: 0.388698, acc: 64.06%, op_acc: 43.75%] [G loss: 0.993747]\n",
      "epoch:28 step:21911[D loss: 0.441606, acc: 58.59%, op_acc: 41.41%] [G loss: 0.999832]\n",
      "epoch:28 step:21912[D loss: 0.390516, acc: 69.53%, op_acc: 44.53%] [G loss: 0.889999]\n",
      "epoch:28 step:21913[D loss: 0.409337, acc: 57.81%, op_acc: 48.44%] [G loss: 0.922651]\n",
      "epoch:28 step:21914[D loss: 0.393619, acc: 62.50%, op_acc: 44.53%] [G loss: 0.963635]\n",
      "epoch:28 step:21915[D loss: 0.427027, acc: 60.94%, op_acc: 33.59%] [G loss: 0.831329]\n",
      "epoch:28 step:21916[D loss: 0.444956, acc: 56.25%, op_acc: 38.28%] [G loss: 0.941036]\n",
      "epoch:28 step:21917[D loss: 0.413464, acc: 63.28%, op_acc: 42.19%] [G loss: 0.970801]\n",
      "epoch:28 step:21918[D loss: 0.407306, acc: 67.97%, op_acc: 44.53%] [G loss: 0.876906]\n",
      "epoch:28 step:21919[D loss: 0.371420, acc: 68.75%, op_acc: 46.88%] [G loss: 0.990201]\n",
      "epoch:28 step:21920[D loss: 0.403423, acc: 64.06%, op_acc: 42.19%] [G loss: 0.983926]\n",
      "epoch:28 step:21921[D loss: 0.429644, acc: 58.59%, op_acc: 39.06%] [G loss: 0.914141]\n",
      "epoch:28 step:21922[D loss: 0.433260, acc: 62.50%, op_acc: 39.06%] [G loss: 1.000865]\n",
      "epoch:28 step:21923[D loss: 0.400418, acc: 64.06%, op_acc: 41.41%] [G loss: 0.972579]\n",
      "epoch:28 step:21924[D loss: 0.450660, acc: 57.81%, op_acc: 34.38%] [G loss: 0.863091]\n",
      "epoch:28 step:21925[D loss: 0.424279, acc: 55.47%, op_acc: 45.31%] [G loss: 0.907378]\n",
      "epoch:28 step:21926[D loss: 0.363683, acc: 67.19%, op_acc: 51.56%] [G loss: 0.897446]\n",
      "epoch:28 step:21927[D loss: 0.390026, acc: 64.06%, op_acc: 46.09%] [G loss: 0.965579]\n",
      "epoch:28 step:21928[D loss: 0.368377, acc: 72.66%, op_acc: 44.53%] [G loss: 1.113305]\n",
      "epoch:28 step:21929[D loss: 0.394105, acc: 61.72%, op_acc: 39.84%] [G loss: 0.986706]\n",
      "epoch:28 step:21930[D loss: 0.397202, acc: 59.38%, op_acc: 45.31%] [G loss: 0.827487]\n",
      "epoch:28 step:21931[D loss: 0.458672, acc: 53.12%, op_acc: 42.19%] [G loss: 0.835430]\n",
      "epoch:28 step:21932[D loss: 0.406791, acc: 61.72%, op_acc: 43.75%] [G loss: 0.926996]\n",
      "epoch:28 step:21933[D loss: 0.437303, acc: 60.94%, op_acc: 39.84%] [G loss: 0.821784]\n",
      "epoch:28 step:21934[D loss: 0.424650, acc: 57.81%, op_acc: 40.62%] [G loss: 0.838109]\n",
      "epoch:28 step:21935[D loss: 0.372831, acc: 71.09%, op_acc: 42.97%] [G loss: 0.960274]\n",
      "epoch:28 step:21936[D loss: 0.421924, acc: 60.16%, op_acc: 36.72%] [G loss: 0.943169]\n",
      "epoch:28 step:21937[D loss: 0.401551, acc: 57.81%, op_acc: 43.75%] [G loss: 0.949961]\n",
      "epoch:28 step:21938[D loss: 0.406237, acc: 62.50%, op_acc: 40.62%] [G loss: 0.992833]\n",
      "epoch:28 step:21939[D loss: 0.454056, acc: 48.44%, op_acc: 34.38%] [G loss: 0.855511]\n",
      "epoch:28 step:21940[D loss: 0.365630, acc: 70.31%, op_acc: 42.19%] [G loss: 0.934572]\n",
      "epoch:28 step:21941[D loss: 0.415962, acc: 61.72%, op_acc: 38.28%] [G loss: 1.009359]\n",
      "epoch:28 step:21942[D loss: 0.391829, acc: 64.06%, op_acc: 42.19%] [G loss: 0.954958]\n",
      "epoch:28 step:21943[D loss: 0.399125, acc: 62.50%, op_acc: 38.28%] [G loss: 0.903697]\n",
      "epoch:28 step:21944[D loss: 0.427226, acc: 60.16%, op_acc: 39.84%] [G loss: 0.890960]\n",
      "epoch:28 step:21945[D loss: 0.426939, acc: 59.38%, op_acc: 41.41%] [G loss: 0.917973]\n",
      "epoch:28 step:21946[D loss: 0.421109, acc: 67.97%, op_acc: 38.28%] [G loss: 0.944751]\n",
      "epoch:28 step:21947[D loss: 0.421878, acc: 57.81%, op_acc: 38.28%] [G loss: 0.945534]\n",
      "epoch:28 step:21948[D loss: 0.456056, acc: 53.91%, op_acc: 35.94%] [G loss: 0.771153]\n",
      "epoch:28 step:21949[D loss: 0.418713, acc: 64.84%, op_acc: 42.97%] [G loss: 0.950325]\n",
      "epoch:28 step:21950[D loss: 0.394703, acc: 67.97%, op_acc: 49.22%] [G loss: 0.863705]\n",
      "epoch:28 step:21951[D loss: 0.438115, acc: 55.47%, op_acc: 38.28%] [G loss: 0.891768]\n",
      "epoch:28 step:21952[D loss: 0.415198, acc: 68.75%, op_acc: 42.97%] [G loss: 0.995468]\n",
      "epoch:28 step:21953[D loss: 0.439561, acc: 64.84%, op_acc: 35.16%] [G loss: 1.004623]\n",
      "epoch:28 step:21954[D loss: 0.391938, acc: 69.53%, op_acc: 48.44%] [G loss: 0.938186]\n",
      "epoch:28 step:21955[D loss: 0.406587, acc: 60.16%, op_acc: 41.41%] [G loss: 0.939033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:21956[D loss: 0.434907, acc: 60.16%, op_acc: 39.06%] [G loss: 1.108682]\n",
      "epoch:28 step:21957[D loss: 0.397655, acc: 62.50%, op_acc: 49.22%] [G loss: 0.900219]\n",
      "epoch:28 step:21958[D loss: 0.396741, acc: 64.06%, op_acc: 42.19%] [G loss: 0.937041]\n",
      "epoch:28 step:21959[D loss: 0.391110, acc: 65.62%, op_acc: 39.84%] [G loss: 1.030118]\n",
      "epoch:28 step:21960[D loss: 0.427241, acc: 61.72%, op_acc: 40.62%] [G loss: 0.932095]\n",
      "epoch:28 step:21961[D loss: 0.399029, acc: 60.94%, op_acc: 48.44%] [G loss: 0.913106]\n",
      "epoch:28 step:21962[D loss: 0.410680, acc: 67.19%, op_acc: 37.50%] [G loss: 0.868620]\n",
      "epoch:28 step:21963[D loss: 0.381208, acc: 69.53%, op_acc: 44.53%] [G loss: 0.965521]\n",
      "epoch:28 step:21964[D loss: 0.402531, acc: 64.06%, op_acc: 43.75%] [G loss: 0.724557]\n",
      "epoch:28 step:21965[D loss: 0.400114, acc: 64.84%, op_acc: 42.97%] [G loss: 0.861294]\n",
      "epoch:28 step:21966[D loss: 0.414277, acc: 66.41%, op_acc: 35.94%] [G loss: 0.766419]\n",
      "epoch:28 step:21967[D loss: 0.405049, acc: 67.19%, op_acc: 42.97%] [G loss: 0.827812]\n",
      "epoch:28 step:21968[D loss: 0.381700, acc: 72.66%, op_acc: 42.19%] [G loss: 0.941415]\n",
      "epoch:28 step:21969[D loss: 0.415517, acc: 60.16%, op_acc: 42.19%] [G loss: 0.965733]\n",
      "epoch:28 step:21970[D loss: 0.437830, acc: 59.38%, op_acc: 42.97%] [G loss: 0.883812]\n",
      "epoch:28 step:21971[D loss: 0.429489, acc: 53.91%, op_acc: 40.62%] [G loss: 0.776763]\n",
      "epoch:28 step:21972[D loss: 0.408817, acc: 64.06%, op_acc: 42.19%] [G loss: 0.881818]\n",
      "epoch:28 step:21973[D loss: 0.434817, acc: 53.12%, op_acc: 40.62%] [G loss: 0.851441]\n",
      "epoch:28 step:21974[D loss: 0.399807, acc: 57.81%, op_acc: 44.53%] [G loss: 0.914329]\n",
      "epoch:28 step:21975[D loss: 0.366503, acc: 74.22%, op_acc: 46.09%] [G loss: 0.981876]\n",
      "epoch:28 step:21976[D loss: 0.465040, acc: 55.47%, op_acc: 38.28%] [G loss: 1.012090]\n",
      "epoch:28 step:21977[D loss: 0.418800, acc: 59.38%, op_acc: 42.97%] [G loss: 0.994815]\n",
      "epoch:28 step:21978[D loss: 0.441819, acc: 55.47%, op_acc: 46.88%] [G loss: 0.885998]\n",
      "epoch:28 step:21979[D loss: 0.449199, acc: 57.03%, op_acc: 31.25%] [G loss: 0.937533]\n",
      "epoch:28 step:21980[D loss: 0.404442, acc: 64.84%, op_acc: 39.84%] [G loss: 0.849422]\n",
      "epoch:28 step:21981[D loss: 0.404967, acc: 64.84%, op_acc: 39.84%] [G loss: 0.928687]\n",
      "epoch:28 step:21982[D loss: 0.412677, acc: 59.38%, op_acc: 39.84%] [G loss: 0.875662]\n",
      "epoch:28 step:21983[D loss: 0.380791, acc: 64.06%, op_acc: 53.12%] [G loss: 1.021684]\n",
      "epoch:28 step:21984[D loss: 0.430804, acc: 55.47%, op_acc: 42.19%] [G loss: 0.845471]\n",
      "epoch:28 step:21985[D loss: 0.397117, acc: 67.19%, op_acc: 38.28%] [G loss: 0.913906]\n",
      "epoch:28 step:21986[D loss: 0.395128, acc: 61.72%, op_acc: 43.75%] [G loss: 0.932468]\n",
      "epoch:28 step:21987[D loss: 0.424162, acc: 57.03%, op_acc: 40.62%] [G loss: 0.878606]\n",
      "epoch:28 step:21988[D loss: 0.397953, acc: 69.53%, op_acc: 39.84%] [G loss: 0.993904]\n",
      "epoch:28 step:21989[D loss: 0.420114, acc: 60.16%, op_acc: 43.75%] [G loss: 0.924621]\n",
      "epoch:28 step:21990[D loss: 0.401047, acc: 63.28%, op_acc: 41.41%] [G loss: 0.987215]\n",
      "epoch:28 step:21991[D loss: 0.447095, acc: 53.91%, op_acc: 42.19%] [G loss: 1.003979]\n",
      "epoch:28 step:21992[D loss: 0.391488, acc: 61.72%, op_acc: 40.62%] [G loss: 0.931945]\n",
      "epoch:28 step:21993[D loss: 0.441140, acc: 60.16%, op_acc: 33.59%] [G loss: 0.833763]\n",
      "epoch:28 step:21994[D loss: 0.429643, acc: 55.47%, op_acc: 42.97%] [G loss: 0.996937]\n",
      "epoch:28 step:21995[D loss: 0.380509, acc: 64.06%, op_acc: 42.97%] [G loss: 1.031129]\n",
      "epoch:28 step:21996[D loss: 0.392521, acc: 60.94%, op_acc: 38.28%] [G loss: 0.965221]\n",
      "epoch:28 step:21997[D loss: 0.414333, acc: 62.50%, op_acc: 34.38%] [G loss: 1.003603]\n",
      "epoch:28 step:21998[D loss: 0.352666, acc: 75.00%, op_acc: 45.31%] [G loss: 0.879019]\n",
      "epoch:28 step:21999[D loss: 0.401417, acc: 64.84%, op_acc: 42.97%] [G loss: 0.951481]\n",
      "epoch:28 step:22000[D loss: 0.355002, acc: 71.88%, op_acc: 42.97%] [G loss: 0.855466]\n",
      "epoch:28 step:22001[D loss: 0.432073, acc: 59.38%, op_acc: 35.16%] [G loss: 1.059154]\n",
      "epoch:28 step:22002[D loss: 0.381981, acc: 72.66%, op_acc: 42.97%] [G loss: 1.034258]\n",
      "epoch:28 step:22003[D loss: 0.430714, acc: 53.12%, op_acc: 46.09%] [G loss: 0.931328]\n",
      "epoch:28 step:22004[D loss: 0.369020, acc: 70.31%, op_acc: 42.19%] [G loss: 0.896317]\n",
      "epoch:28 step:22005[D loss: 0.404619, acc: 65.62%, op_acc: 42.19%] [G loss: 0.946633]\n",
      "epoch:28 step:22006[D loss: 0.440439, acc: 57.81%, op_acc: 35.94%] [G loss: 1.010876]\n",
      "epoch:28 step:22007[D loss: 0.405414, acc: 64.84%, op_acc: 42.19%] [G loss: 0.925515]\n",
      "epoch:28 step:22008[D loss: 0.447510, acc: 55.47%, op_acc: 36.72%] [G loss: 0.954129]\n",
      "epoch:28 step:22009[D loss: 0.414534, acc: 65.62%, op_acc: 38.28%] [G loss: 0.749653]\n",
      "epoch:28 step:22010[D loss: 0.411813, acc: 62.50%, op_acc: 35.94%] [G loss: 1.018100]\n",
      "epoch:28 step:22011[D loss: 0.413022, acc: 55.47%, op_acc: 41.41%] [G loss: 1.036927]\n",
      "epoch:28 step:22012[D loss: 0.422598, acc: 56.25%, op_acc: 39.84%] [G loss: 0.759694]\n",
      "epoch:28 step:22013[D loss: 0.419308, acc: 60.94%, op_acc: 41.41%] [G loss: 0.843898]\n",
      "epoch:28 step:22014[D loss: 0.394859, acc: 60.94%, op_acc: 37.50%] [G loss: 1.002766]\n",
      "epoch:28 step:22015[D loss: 0.400020, acc: 65.62%, op_acc: 39.06%] [G loss: 0.770779]\n",
      "epoch:28 step:22016[D loss: 0.418854, acc: 64.06%, op_acc: 40.62%] [G loss: 0.894042]\n",
      "epoch:28 step:22017[D loss: 0.444274, acc: 54.69%, op_acc: 41.41%] [G loss: 0.872431]\n",
      "epoch:28 step:22018[D loss: 0.434787, acc: 56.25%, op_acc: 34.38%] [G loss: 0.875632]\n",
      "epoch:28 step:22019[D loss: 0.438959, acc: 55.47%, op_acc: 39.84%] [G loss: 0.895920]\n",
      "epoch:28 step:22020[D loss: 0.410394, acc: 59.38%, op_acc: 42.97%] [G loss: 0.886904]\n",
      "epoch:28 step:22021[D loss: 0.445028, acc: 50.00%, op_acc: 38.28%] [G loss: 0.967851]\n",
      "epoch:28 step:22022[D loss: 0.452612, acc: 53.12%, op_acc: 38.28%] [G loss: 0.919960]\n",
      "epoch:28 step:22023[D loss: 0.391464, acc: 63.28%, op_acc: 43.75%] [G loss: 0.956960]\n",
      "epoch:28 step:22024[D loss: 0.432441, acc: 55.47%, op_acc: 36.72%] [G loss: 0.884141]\n",
      "epoch:28 step:22025[D loss: 0.398480, acc: 67.19%, op_acc: 41.41%] [G loss: 0.966713]\n",
      "epoch:28 step:22026[D loss: 0.396558, acc: 59.38%, op_acc: 45.31%] [G loss: 0.957807]\n",
      "epoch:28 step:22027[D loss: 0.405553, acc: 64.84%, op_acc: 39.84%] [G loss: 0.988331]\n",
      "epoch:28 step:22028[D loss: 0.417637, acc: 62.50%, op_acc: 34.38%] [G loss: 0.909154]\n",
      "epoch:28 step:22029[D loss: 0.439475, acc: 53.12%, op_acc: 40.62%] [G loss: 1.005427]\n",
      "epoch:28 step:22030[D loss: 0.390533, acc: 64.84%, op_acc: 47.66%] [G loss: 0.951221]\n",
      "epoch:28 step:22031[D loss: 0.443009, acc: 52.34%, op_acc: 41.41%] [G loss: 1.025505]\n",
      "epoch:28 step:22032[D loss: 0.434340, acc: 59.38%, op_acc: 39.06%] [G loss: 0.891867]\n",
      "epoch:28 step:22033[D loss: 0.376887, acc: 66.41%, op_acc: 46.09%] [G loss: 1.002678]\n",
      "epoch:28 step:22034[D loss: 0.429129, acc: 63.28%, op_acc: 35.16%] [G loss: 0.984476]\n",
      "epoch:28 step:22035[D loss: 0.376014, acc: 71.88%, op_acc: 42.19%] [G loss: 1.085991]\n",
      "epoch:28 step:22036[D loss: 0.408041, acc: 61.72%, op_acc: 42.97%] [G loss: 0.706849]\n",
      "epoch:28 step:22037[D loss: 0.417543, acc: 60.16%, op_acc: 41.41%] [G loss: 0.870970]\n",
      "epoch:28 step:22038[D loss: 0.412573, acc: 60.16%, op_acc: 41.41%] [G loss: 0.907975]\n",
      "epoch:28 step:22039[D loss: 0.467398, acc: 53.12%, op_acc: 33.59%] [G loss: 0.961476]\n",
      "epoch:28 step:22040[D loss: 0.378717, acc: 67.19%, op_acc: 42.97%] [G loss: 0.752934]\n",
      "epoch:28 step:22041[D loss: 0.415116, acc: 61.72%, op_acc: 38.28%] [G loss: 0.945821]\n",
      "epoch:28 step:22042[D loss: 0.455782, acc: 50.00%, op_acc: 39.06%] [G loss: 0.972375]\n",
      "epoch:28 step:22043[D loss: 0.387541, acc: 65.62%, op_acc: 42.97%] [G loss: 1.085765]\n",
      "epoch:28 step:22044[D loss: 0.443010, acc: 54.69%, op_acc: 42.97%] [G loss: 0.898096]\n",
      "epoch:28 step:22045[D loss: 0.404565, acc: 62.50%, op_acc: 43.75%] [G loss: 0.962493]\n",
      "epoch:28 step:22046[D loss: 0.436671, acc: 57.03%, op_acc: 35.16%] [G loss: 0.912830]\n",
      "epoch:28 step:22047[D loss: 0.386263, acc: 70.31%, op_acc: 46.09%] [G loss: 0.982763]\n",
      "epoch:28 step:22048[D loss: 0.453507, acc: 54.69%, op_acc: 35.16%] [G loss: 1.012557]\n",
      "epoch:28 step:22049[D loss: 0.417848, acc: 58.59%, op_acc: 42.97%] [G loss: 0.762211]\n",
      "epoch:28 step:22050[D loss: 0.400756, acc: 65.62%, op_acc: 43.75%] [G loss: 0.729813]\n",
      "epoch:28 step:22051[D loss: 0.399860, acc: 66.41%, op_acc: 40.62%] [G loss: 0.848269]\n",
      "epoch:28 step:22052[D loss: 0.407699, acc: 62.50%, op_acc: 42.97%] [G loss: 0.802166]\n",
      "epoch:28 step:22053[D loss: 0.390881, acc: 71.88%, op_acc: 39.06%] [G loss: 0.753316]\n",
      "epoch:28 step:22054[D loss: 0.433796, acc: 57.81%, op_acc: 39.06%] [G loss: 0.895032]\n",
      "epoch:28 step:22055[D loss: 0.437999, acc: 57.03%, op_acc: 37.50%] [G loss: 1.012623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22056[D loss: 0.432837, acc: 56.25%, op_acc: 39.84%] [G loss: 1.066028]\n",
      "epoch:28 step:22057[D loss: 0.414832, acc: 63.28%, op_acc: 37.50%] [G loss: 0.794621]\n",
      "epoch:28 step:22058[D loss: 0.418556, acc: 64.84%, op_acc: 45.31%] [G loss: 0.902259]\n",
      "epoch:28 step:22059[D loss: 0.450169, acc: 46.88%, op_acc: 39.84%] [G loss: 0.833661]\n",
      "epoch:28 step:22060[D loss: 0.399787, acc: 64.06%, op_acc: 39.06%] [G loss: 0.954707]\n",
      "epoch:28 step:22061[D loss: 0.426406, acc: 64.84%, op_acc: 43.75%] [G loss: 0.940647]\n",
      "epoch:28 step:22062[D loss: 0.377352, acc: 69.53%, op_acc: 46.09%] [G loss: 1.040433]\n",
      "epoch:28 step:22063[D loss: 0.434827, acc: 55.47%, op_acc: 46.88%] [G loss: 0.914666]\n",
      "epoch:28 step:22064[D loss: 0.376347, acc: 68.75%, op_acc: 44.53%] [G loss: 1.005944]\n",
      "epoch:28 step:22065[D loss: 0.449746, acc: 53.12%, op_acc: 40.62%] [G loss: 0.956032]\n",
      "epoch:28 step:22066[D loss: 0.426264, acc: 64.06%, op_acc: 35.94%] [G loss: 1.007176]\n",
      "epoch:28 step:22067[D loss: 0.427080, acc: 54.69%, op_acc: 35.16%] [G loss: 0.970694]\n",
      "epoch:28 step:22068[D loss: 0.414961, acc: 64.84%, op_acc: 37.50%] [G loss: 0.970087]\n",
      "epoch:28 step:22069[D loss: 0.365376, acc: 73.44%, op_acc: 42.97%] [G loss: 0.980185]\n",
      "epoch:28 step:22070[D loss: 0.432228, acc: 57.03%, op_acc: 42.97%] [G loss: 0.951062]\n",
      "epoch:28 step:22071[D loss: 0.433733, acc: 57.03%, op_acc: 39.84%] [G loss: 0.923298]\n",
      "epoch:28 step:22072[D loss: 0.449604, acc: 50.78%, op_acc: 40.62%] [G loss: 0.706750]\n",
      "epoch:28 step:22073[D loss: 0.403345, acc: 62.50%, op_acc: 38.28%] [G loss: 0.970985]\n",
      "epoch:28 step:22074[D loss: 0.405451, acc: 59.38%, op_acc: 42.19%] [G loss: 0.913067]\n",
      "epoch:28 step:22075[D loss: 0.392059, acc: 66.41%, op_acc: 39.06%] [G loss: 0.851829]\n",
      "epoch:28 step:22076[D loss: 0.419587, acc: 61.72%, op_acc: 42.19%] [G loss: 0.808681]\n",
      "epoch:28 step:22077[D loss: 0.362683, acc: 68.75%, op_acc: 49.22%] [G loss: 0.896581]\n",
      "epoch:28 step:22078[D loss: 0.465636, acc: 53.12%, op_acc: 39.84%] [G loss: 1.019704]\n",
      "epoch:28 step:22079[D loss: 0.411934, acc: 55.47%, op_acc: 40.62%] [G loss: 0.940001]\n",
      "epoch:28 step:22080[D loss: 0.408278, acc: 64.06%, op_acc: 41.41%] [G loss: 0.879885]\n",
      "epoch:28 step:22081[D loss: 0.418526, acc: 57.81%, op_acc: 40.62%] [G loss: 0.921631]\n",
      "epoch:28 step:22082[D loss: 0.413111, acc: 66.41%, op_acc: 33.59%] [G loss: 0.937588]\n",
      "epoch:28 step:22083[D loss: 0.475134, acc: 54.69%, op_acc: 38.28%] [G loss: 0.950339]\n",
      "epoch:28 step:22084[D loss: 0.459895, acc: 57.81%, op_acc: 32.81%] [G loss: 0.908944]\n",
      "epoch:28 step:22085[D loss: 0.372353, acc: 64.06%, op_acc: 48.44%] [G loss: 0.941155]\n",
      "epoch:28 step:22086[D loss: 0.416859, acc: 61.72%, op_acc: 42.97%] [G loss: 1.025216]\n",
      "epoch:28 step:22087[D loss: 0.383923, acc: 63.28%, op_acc: 43.75%] [G loss: 1.094171]\n",
      "epoch:28 step:22088[D loss: 0.419511, acc: 62.50%, op_acc: 39.84%] [G loss: 0.927022]\n",
      "epoch:28 step:22089[D loss: 0.411121, acc: 60.94%, op_acc: 39.84%] [G loss: 0.988411]\n",
      "epoch:28 step:22090[D loss: 0.414608, acc: 62.50%, op_acc: 38.28%] [G loss: 0.932739]\n",
      "epoch:28 step:22091[D loss: 0.451473, acc: 48.44%, op_acc: 39.06%] [G loss: 0.861476]\n",
      "epoch:28 step:22092[D loss: 0.415627, acc: 60.94%, op_acc: 41.41%] [G loss: 0.949288]\n",
      "epoch:28 step:22093[D loss: 0.449911, acc: 54.69%, op_acc: 35.94%] [G loss: 0.983929]\n",
      "epoch:28 step:22094[D loss: 0.397544, acc: 69.53%, op_acc: 43.75%] [G loss: 1.004702]\n",
      "epoch:28 step:22095[D loss: 0.421703, acc: 61.72%, op_acc: 41.41%] [G loss: 0.886558]\n",
      "epoch:28 step:22096[D loss: 0.406089, acc: 62.50%, op_acc: 46.09%] [G loss: 0.933473]\n",
      "epoch:28 step:22097[D loss: 0.382337, acc: 72.66%, op_acc: 42.97%] [G loss: 0.959969]\n",
      "epoch:28 step:22098[D loss: 0.416103, acc: 60.94%, op_acc: 42.19%] [G loss: 0.910405]\n",
      "epoch:28 step:22099[D loss: 0.385088, acc: 65.62%, op_acc: 44.53%] [G loss: 0.878038]\n",
      "epoch:28 step:22100[D loss: 0.408541, acc: 62.50%, op_acc: 41.41%] [G loss: 0.945972]\n",
      "epoch:28 step:22101[D loss: 0.399074, acc: 66.41%, op_acc: 45.31%] [G loss: 0.910837]\n",
      "epoch:28 step:22102[D loss: 0.453132, acc: 61.72%, op_acc: 34.38%] [G loss: 0.828753]\n",
      "epoch:28 step:22103[D loss: 0.407756, acc: 60.16%, op_acc: 40.62%] [G loss: 0.949276]\n",
      "epoch:28 step:22104[D loss: 0.410828, acc: 64.06%, op_acc: 48.44%] [G loss: 0.966320]\n",
      "epoch:28 step:22105[D loss: 0.408652, acc: 66.41%, op_acc: 40.62%] [G loss: 0.938108]\n",
      "epoch:28 step:22106[D loss: 0.382499, acc: 69.53%, op_acc: 48.44%] [G loss: 0.922867]\n",
      "epoch:28 step:22107[D loss: 0.432435, acc: 56.25%, op_acc: 36.72%] [G loss: 0.853215]\n",
      "epoch:28 step:22108[D loss: 0.394334, acc: 63.28%, op_acc: 43.75%] [G loss: 0.941981]\n",
      "epoch:28 step:22109[D loss: 0.415807, acc: 60.16%, op_acc: 41.41%] [G loss: 0.811939]\n",
      "epoch:28 step:22110[D loss: 0.420605, acc: 54.69%, op_acc: 42.97%] [G loss: 0.896286]\n",
      "epoch:28 step:22111[D loss: 0.420630, acc: 64.06%, op_acc: 43.75%] [G loss: 0.883873]\n",
      "epoch:28 step:22112[D loss: 0.415961, acc: 64.06%, op_acc: 42.97%] [G loss: 0.848961]\n",
      "epoch:28 step:22113[D loss: 0.418444, acc: 61.72%, op_acc: 49.22%] [G loss: 0.957618]\n",
      "epoch:28 step:22114[D loss: 0.411520, acc: 68.75%, op_acc: 46.09%] [G loss: 0.934645]\n",
      "epoch:28 step:22115[D loss: 0.404502, acc: 67.19%, op_acc: 43.75%] [G loss: 0.837008]\n",
      "epoch:28 step:22116[D loss: 0.431661, acc: 58.59%, op_acc: 37.50%] [G loss: 1.038700]\n",
      "epoch:28 step:22117[D loss: 0.409099, acc: 61.72%, op_acc: 41.41%] [G loss: 0.949117]\n",
      "epoch:28 step:22118[D loss: 0.426339, acc: 58.59%, op_acc: 41.41%] [G loss: 0.902683]\n",
      "epoch:28 step:22119[D loss: 0.385155, acc: 64.84%, op_acc: 47.66%] [G loss: 0.957430]\n",
      "epoch:28 step:22120[D loss: 0.430648, acc: 57.81%, op_acc: 42.19%] [G loss: 0.873282]\n",
      "epoch:28 step:22121[D loss: 0.418630, acc: 62.50%, op_acc: 38.28%] [G loss: 0.912812]\n",
      "epoch:28 step:22122[D loss: 0.424112, acc: 57.03%, op_acc: 37.50%] [G loss: 0.857425]\n",
      "epoch:28 step:22123[D loss: 0.425729, acc: 55.47%, op_acc: 42.97%] [G loss: 0.825959]\n",
      "epoch:28 step:22124[D loss: 0.450570, acc: 56.25%, op_acc: 37.50%] [G loss: 0.891014]\n",
      "epoch:28 step:22125[D loss: 0.407778, acc: 63.28%, op_acc: 47.66%] [G loss: 0.932481]\n",
      "epoch:28 step:22126[D loss: 0.405694, acc: 58.59%, op_acc: 46.09%] [G loss: 0.869297]\n",
      "epoch:28 step:22127[D loss: 0.410281, acc: 68.75%, op_acc: 35.16%] [G loss: 0.879521]\n",
      "epoch:28 step:22128[D loss: 0.428204, acc: 60.94%, op_acc: 36.72%] [G loss: 0.906096]\n",
      "epoch:28 step:22129[D loss: 0.427241, acc: 59.38%, op_acc: 39.84%] [G loss: 0.875337]\n",
      "epoch:28 step:22130[D loss: 0.393284, acc: 63.28%, op_acc: 45.31%] [G loss: 0.938668]\n",
      "epoch:28 step:22131[D loss: 0.431651, acc: 55.47%, op_acc: 37.50%] [G loss: 0.939955]\n",
      "epoch:28 step:22132[D loss: 0.401836, acc: 62.50%, op_acc: 38.28%] [G loss: 1.032663]\n",
      "epoch:28 step:22133[D loss: 0.373353, acc: 72.66%, op_acc: 39.06%] [G loss: 1.020830]\n",
      "epoch:28 step:22134[D loss: 0.418005, acc: 60.94%, op_acc: 39.06%] [G loss: 0.982551]\n",
      "epoch:28 step:22135[D loss: 0.444135, acc: 50.78%, op_acc: 42.97%] [G loss: 0.940994]\n",
      "epoch:28 step:22136[D loss: 0.399448, acc: 61.72%, op_acc: 43.75%] [G loss: 0.987585]\n",
      "epoch:28 step:22137[D loss: 0.400516, acc: 59.38%, op_acc: 39.06%] [G loss: 0.932472]\n",
      "epoch:28 step:22138[D loss: 0.399128, acc: 67.97%, op_acc: 37.50%] [G loss: 0.989938]\n",
      "epoch:28 step:22139[D loss: 0.464054, acc: 50.78%, op_acc: 37.50%] [G loss: 0.863557]\n",
      "epoch:28 step:22140[D loss: 0.419023, acc: 63.28%, op_acc: 35.16%] [G loss: 0.957734]\n",
      "epoch:28 step:22141[D loss: 0.421414, acc: 55.47%, op_acc: 44.53%] [G loss: 0.918338]\n",
      "epoch:28 step:22142[D loss: 0.431407, acc: 58.59%, op_acc: 42.19%] [G loss: 0.841625]\n",
      "epoch:28 step:22143[D loss: 0.394712, acc: 64.84%, op_acc: 44.53%] [G loss: 0.933851]\n",
      "epoch:28 step:22144[D loss: 0.397964, acc: 69.53%, op_acc: 39.06%] [G loss: 0.822754]\n",
      "epoch:28 step:22145[D loss: 0.420330, acc: 63.28%, op_acc: 39.84%] [G loss: 0.883193]\n",
      "epoch:28 step:22146[D loss: 0.455139, acc: 52.34%, op_acc: 36.72%] [G loss: 1.004295]\n",
      "epoch:28 step:22147[D loss: 0.404138, acc: 65.62%, op_acc: 43.75%] [G loss: 0.835506]\n",
      "epoch:28 step:22148[D loss: 0.405659, acc: 69.53%, op_acc: 35.16%] [G loss: 0.846849]\n",
      "epoch:28 step:22149[D loss: 0.425206, acc: 57.81%, op_acc: 39.06%] [G loss: 0.976118]\n",
      "epoch:28 step:22150[D loss: 0.438385, acc: 59.38%, op_acc: 40.62%] [G loss: 0.858841]\n",
      "epoch:28 step:22151[D loss: 0.394208, acc: 64.06%, op_acc: 42.19%] [G loss: 0.864059]\n",
      "epoch:28 step:22152[D loss: 0.407606, acc: 63.28%, op_acc: 41.41%] [G loss: 0.908059]\n",
      "epoch:28 step:22153[D loss: 0.364464, acc: 67.19%, op_acc: 39.06%] [G loss: 0.905260]\n",
      "epoch:28 step:22154[D loss: 0.394581, acc: 71.09%, op_acc: 41.41%] [G loss: 0.983618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22155[D loss: 0.408613, acc: 62.50%, op_acc: 43.75%] [G loss: 0.909553]\n",
      "epoch:28 step:22156[D loss: 0.401149, acc: 64.06%, op_acc: 40.62%] [G loss: 0.958407]\n",
      "epoch:28 step:22157[D loss: 0.413599, acc: 63.28%, op_acc: 42.19%] [G loss: 0.946353]\n",
      "epoch:28 step:22158[D loss: 0.403514, acc: 67.19%, op_acc: 39.06%] [G loss: 0.883038]\n",
      "epoch:28 step:22159[D loss: 0.394468, acc: 65.62%, op_acc: 47.66%] [G loss: 0.868256]\n",
      "epoch:28 step:22160[D loss: 0.412644, acc: 64.84%, op_acc: 35.16%] [G loss: 0.967376]\n",
      "epoch:28 step:22161[D loss: 0.433746, acc: 57.81%, op_acc: 40.62%] [G loss: 0.916197]\n",
      "epoch:28 step:22162[D loss: 0.436803, acc: 60.94%, op_acc: 41.41%] [G loss: 0.866128]\n",
      "epoch:28 step:22163[D loss: 0.394259, acc: 59.38%, op_acc: 44.53%] [G loss: 0.913778]\n",
      "epoch:28 step:22164[D loss: 0.424739, acc: 61.72%, op_acc: 41.41%] [G loss: 0.916918]\n",
      "epoch:28 step:22165[D loss: 0.426273, acc: 55.47%, op_acc: 35.16%] [G loss: 0.942091]\n",
      "epoch:28 step:22166[D loss: 0.430670, acc: 57.03%, op_acc: 42.19%] [G loss: 0.852828]\n",
      "epoch:28 step:22167[D loss: 0.373911, acc: 70.31%, op_acc: 44.53%] [G loss: 0.911510]\n",
      "epoch:28 step:22168[D loss: 0.467128, acc: 47.66%, op_acc: 38.28%] [G loss: 0.900710]\n",
      "epoch:28 step:22169[D loss: 0.408185, acc: 67.19%, op_acc: 41.41%] [G loss: 0.877283]\n",
      "epoch:28 step:22170[D loss: 0.389369, acc: 63.28%, op_acc: 41.41%] [G loss: 1.004971]\n",
      "epoch:28 step:22171[D loss: 0.409731, acc: 60.16%, op_acc: 40.62%] [G loss: 1.027827]\n",
      "epoch:28 step:22172[D loss: 0.398642, acc: 61.72%, op_acc: 45.31%] [G loss: 0.922730]\n",
      "epoch:28 step:22173[D loss: 0.406572, acc: 64.84%, op_acc: 47.66%] [G loss: 0.855668]\n",
      "epoch:28 step:22174[D loss: 0.446007, acc: 59.38%, op_acc: 40.62%] [G loss: 0.869088]\n",
      "epoch:28 step:22175[D loss: 0.402535, acc: 60.16%, op_acc: 42.97%] [G loss: 0.812427]\n",
      "epoch:28 step:22176[D loss: 0.409223, acc: 67.97%, op_acc: 40.62%] [G loss: 0.936978]\n",
      "epoch:28 step:22177[D loss: 0.430584, acc: 64.84%, op_acc: 43.75%] [G loss: 0.833257]\n",
      "epoch:28 step:22178[D loss: 0.418688, acc: 64.06%, op_acc: 41.41%] [G loss: 0.766426]\n",
      "epoch:28 step:22179[D loss: 0.405315, acc: 63.28%, op_acc: 41.41%] [G loss: 0.939327]\n",
      "epoch:28 step:22180[D loss: 0.424959, acc: 59.38%, op_acc: 39.84%] [G loss: 0.975068]\n",
      "epoch:28 step:22181[D loss: 0.418490, acc: 68.75%, op_acc: 35.16%] [G loss: 0.792979]\n",
      "epoch:28 step:22182[D loss: 0.426378, acc: 58.59%, op_acc: 42.19%] [G loss: 0.800620]\n",
      "epoch:28 step:22183[D loss: 0.463223, acc: 50.78%, op_acc: 40.62%] [G loss: 0.857565]\n",
      "epoch:28 step:22184[D loss: 0.404543, acc: 64.06%, op_acc: 39.06%] [G loss: 1.034648]\n",
      "epoch:28 step:22185[D loss: 0.415549, acc: 65.62%, op_acc: 40.62%] [G loss: 0.955362]\n",
      "epoch:28 step:22186[D loss: 0.418961, acc: 64.06%, op_acc: 34.38%] [G loss: 0.920883]\n",
      "epoch:28 step:22187[D loss: 0.431369, acc: 59.38%, op_acc: 37.50%] [G loss: 0.858539]\n",
      "epoch:28 step:22188[D loss: 0.418460, acc: 57.81%, op_acc: 37.50%] [G loss: 0.844462]\n",
      "epoch:28 step:22189[D loss: 0.427073, acc: 59.38%, op_acc: 39.84%] [G loss: 0.796268]\n",
      "epoch:28 step:22190[D loss: 0.429713, acc: 60.16%, op_acc: 42.97%] [G loss: 0.881976]\n",
      "epoch:28 step:22191[D loss: 0.376424, acc: 66.41%, op_acc: 46.09%] [G loss: 0.968874]\n",
      "epoch:28 step:22192[D loss: 0.387725, acc: 71.09%, op_acc: 36.72%] [G loss: 0.889760]\n",
      "epoch:28 step:22193[D loss: 0.452194, acc: 48.44%, op_acc: 40.62%] [G loss: 0.859453]\n",
      "epoch:28 step:22194[D loss: 0.404552, acc: 65.62%, op_acc: 39.84%] [G loss: 0.835146]\n",
      "epoch:28 step:22195[D loss: 0.417624, acc: 60.16%, op_acc: 41.41%] [G loss: 0.978116]\n",
      "epoch:28 step:22196[D loss: 0.423197, acc: 53.12%, op_acc: 41.41%] [G loss: 0.812135]\n",
      "epoch:28 step:22197[D loss: 0.415382, acc: 58.59%, op_acc: 36.72%] [G loss: 0.932726]\n",
      "epoch:28 step:22198[D loss: 0.385025, acc: 62.50%, op_acc: 43.75%] [G loss: 0.939893]\n",
      "epoch:28 step:22199[D loss: 0.434817, acc: 57.81%, op_acc: 39.84%] [G loss: 0.934305]\n",
      "epoch:28 step:22200[D loss: 0.397835, acc: 61.72%, op_acc: 41.41%] [G loss: 1.005428]\n",
      "epoch:28 step:22201[D loss: 0.411587, acc: 60.94%, op_acc: 39.84%] [G loss: 0.960235]\n",
      "epoch:28 step:22202[D loss: 0.374767, acc: 66.41%, op_acc: 40.62%] [G loss: 0.928366]\n",
      "epoch:28 step:22203[D loss: 0.400433, acc: 64.84%, op_acc: 42.19%] [G loss: 0.956872]\n",
      "epoch:28 step:22204[D loss: 0.402431, acc: 67.19%, op_acc: 39.06%] [G loss: 0.884449]\n",
      "epoch:28 step:22205[D loss: 0.409788, acc: 66.41%, op_acc: 36.72%] [G loss: 0.801205]\n",
      "epoch:28 step:22206[D loss: 0.429018, acc: 57.81%, op_acc: 41.41%] [G loss: 1.026898]\n",
      "epoch:28 step:22207[D loss: 0.406407, acc: 58.59%, op_acc: 40.62%] [G loss: 0.948888]\n",
      "epoch:28 step:22208[D loss: 0.408066, acc: 64.06%, op_acc: 39.84%] [G loss: 0.968378]\n",
      "epoch:28 step:22209[D loss: 0.389408, acc: 68.75%, op_acc: 39.06%] [G loss: 1.130781]\n",
      "epoch:28 step:22210[D loss: 0.410280, acc: 66.41%, op_acc: 35.94%] [G loss: 1.047542]\n",
      "epoch:28 step:22211[D loss: 0.393417, acc: 70.31%, op_acc: 42.19%] [G loss: 1.044334]\n",
      "epoch:28 step:22212[D loss: 0.457778, acc: 53.12%, op_acc: 40.62%] [G loss: 1.031329]\n",
      "epoch:28 step:22213[D loss: 0.398112, acc: 64.84%, op_acc: 43.75%] [G loss: 0.868880]\n",
      "epoch:28 step:22214[D loss: 0.403312, acc: 62.50%, op_acc: 36.72%] [G loss: 0.890478]\n",
      "epoch:28 step:22215[D loss: 0.408562, acc: 58.59%, op_acc: 39.06%] [G loss: 0.895101]\n",
      "epoch:28 step:22216[D loss: 0.378038, acc: 71.88%, op_acc: 45.31%] [G loss: 0.873472]\n",
      "epoch:28 step:22217[D loss: 0.434629, acc: 54.69%, op_acc: 42.97%] [G loss: 0.873780]\n",
      "epoch:28 step:22218[D loss: 0.417544, acc: 65.62%, op_acc: 42.19%] [G loss: 1.071855]\n",
      "epoch:28 step:22219[D loss: 0.412533, acc: 64.84%, op_acc: 36.72%] [G loss: 0.731540]\n",
      "epoch:28 step:22220[D loss: 0.434153, acc: 60.94%, op_acc: 40.62%] [G loss: 0.830078]\n",
      "epoch:28 step:22221[D loss: 0.435277, acc: 55.47%, op_acc: 39.84%] [G loss: 1.011003]\n",
      "epoch:28 step:22222[D loss: 0.435771, acc: 58.59%, op_acc: 37.50%] [G loss: 0.977244]\n",
      "epoch:28 step:22223[D loss: 0.409906, acc: 63.28%, op_acc: 39.84%] [G loss: 0.890317]\n",
      "epoch:28 step:22224[D loss: 0.438188, acc: 61.72%, op_acc: 39.84%] [G loss: 0.934868]\n",
      "epoch:28 step:22225[D loss: 0.424699, acc: 64.06%, op_acc: 37.50%] [G loss: 0.862340]\n",
      "epoch:28 step:22226[D loss: 0.438818, acc: 55.47%, op_acc: 39.84%] [G loss: 0.931598]\n",
      "epoch:28 step:22227[D loss: 0.415468, acc: 57.81%, op_acc: 40.62%] [G loss: 0.940773]\n",
      "epoch:28 step:22228[D loss: 0.424772, acc: 62.50%, op_acc: 40.62%] [G loss: 0.837951]\n",
      "epoch:28 step:22229[D loss: 0.404079, acc: 64.84%, op_acc: 42.19%] [G loss: 0.933759]\n",
      "epoch:28 step:22230[D loss: 0.408776, acc: 60.94%, op_acc: 42.19%] [G loss: 0.932620]\n",
      "epoch:28 step:22231[D loss: 0.406506, acc: 63.28%, op_acc: 42.97%] [G loss: 1.003443]\n",
      "epoch:28 step:22232[D loss: 0.373974, acc: 71.09%, op_acc: 47.66%] [G loss: 0.952335]\n",
      "epoch:28 step:22233[D loss: 0.383514, acc: 65.62%, op_acc: 41.41%] [G loss: 1.013287]\n",
      "epoch:28 step:22234[D loss: 0.402941, acc: 64.06%, op_acc: 46.09%] [G loss: 0.907219]\n",
      "epoch:28 step:22235[D loss: 0.466724, acc: 52.34%, op_acc: 33.59%] [G loss: 0.913088]\n",
      "epoch:28 step:22236[D loss: 0.428508, acc: 64.06%, op_acc: 39.06%] [G loss: 0.844104]\n",
      "epoch:28 step:22237[D loss: 0.379489, acc: 67.19%, op_acc: 42.97%] [G loss: 0.946510]\n",
      "epoch:28 step:22238[D loss: 0.409846, acc: 56.25%, op_acc: 45.31%] [G loss: 0.984529]\n",
      "epoch:28 step:22239[D loss: 0.396456, acc: 59.38%, op_acc: 46.09%] [G loss: 0.797262]\n",
      "epoch:28 step:22240[D loss: 0.422503, acc: 64.06%, op_acc: 39.84%] [G loss: 0.962967]\n",
      "epoch:28 step:22241[D loss: 0.378998, acc: 68.75%, op_acc: 46.09%] [G loss: 0.868490]\n",
      "epoch:28 step:22242[D loss: 0.428195, acc: 56.25%, op_acc: 41.41%] [G loss: 0.889668]\n",
      "epoch:28 step:22243[D loss: 0.390535, acc: 64.84%, op_acc: 41.41%] [G loss: 0.960632]\n",
      "epoch:28 step:22244[D loss: 0.414805, acc: 61.72%, op_acc: 37.50%] [G loss: 0.892848]\n",
      "epoch:28 step:22245[D loss: 0.411671, acc: 60.94%, op_acc: 35.94%] [G loss: 1.025020]\n",
      "epoch:28 step:22246[D loss: 0.419415, acc: 66.41%, op_acc: 32.81%] [G loss: 0.987274]\n",
      "epoch:28 step:22247[D loss: 0.376248, acc: 71.09%, op_acc: 44.53%] [G loss: 1.090856]\n",
      "epoch:28 step:22248[D loss: 0.411474, acc: 66.41%, op_acc: 38.28%] [G loss: 1.103163]\n",
      "epoch:28 step:22249[D loss: 0.384325, acc: 77.34%, op_acc: 42.19%] [G loss: 1.036054]\n",
      "epoch:28 step:22250[D loss: 0.392801, acc: 67.97%, op_acc: 42.19%] [G loss: 0.848558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22251[D loss: 0.428896, acc: 56.25%, op_acc: 42.97%] [G loss: 0.988062]\n",
      "epoch:28 step:22252[D loss: 0.390805, acc: 67.97%, op_acc: 42.97%] [G loss: 0.940128]\n",
      "epoch:28 step:22253[D loss: 0.389920, acc: 64.06%, op_acc: 36.72%] [G loss: 1.040977]\n",
      "epoch:28 step:22254[D loss: 0.395571, acc: 63.28%, op_acc: 42.97%] [G loss: 0.807825]\n",
      "epoch:28 step:22255[D loss: 0.413749, acc: 65.62%, op_acc: 39.06%] [G loss: 0.685417]\n",
      "epoch:28 step:22256[D loss: 0.454038, acc: 59.38%, op_acc: 36.72%] [G loss: 0.938281]\n",
      "epoch:28 step:22257[D loss: 0.411467, acc: 64.84%, op_acc: 42.97%] [G loss: 0.892426]\n",
      "epoch:28 step:22258[D loss: 0.406726, acc: 60.94%, op_acc: 47.66%] [G loss: 0.955669]\n",
      "epoch:28 step:22259[D loss: 0.397337, acc: 66.41%, op_acc: 42.19%] [G loss: 0.730142]\n",
      "epoch:28 step:22260[D loss: 0.414135, acc: 59.38%, op_acc: 45.31%] [G loss: 0.940704]\n",
      "epoch:28 step:22261[D loss: 0.431922, acc: 60.16%, op_acc: 39.06%] [G loss: 0.802970]\n",
      "epoch:28 step:22262[D loss: 0.436052, acc: 60.16%, op_acc: 35.16%] [G loss: 0.960223]\n",
      "epoch:28 step:22263[D loss: 0.433164, acc: 57.03%, op_acc: 39.84%] [G loss: 0.893625]\n",
      "epoch:28 step:22264[D loss: 0.413029, acc: 59.38%, op_acc: 42.97%] [G loss: 0.900182]\n",
      "epoch:28 step:22265[D loss: 0.457658, acc: 48.44%, op_acc: 41.41%] [G loss: 0.848563]\n",
      "epoch:28 step:22266[D loss: 0.389990, acc: 72.66%, op_acc: 39.84%] [G loss: 0.852457]\n",
      "epoch:28 step:22267[D loss: 0.400526, acc: 61.72%, op_acc: 43.75%] [G loss: 1.007502]\n",
      "epoch:28 step:22268[D loss: 0.417497, acc: 58.59%, op_acc: 40.62%] [G loss: 0.803269]\n",
      "epoch:28 step:22269[D loss: 0.427955, acc: 57.81%, op_acc: 42.19%] [G loss: 0.844489]\n",
      "epoch:28 step:22270[D loss: 0.413759, acc: 64.84%, op_acc: 33.59%] [G loss: 0.821826]\n",
      "epoch:28 step:22271[D loss: 0.412288, acc: 64.84%, op_acc: 38.28%] [G loss: 0.969102]\n",
      "epoch:28 step:22272[D loss: 0.392384, acc: 64.84%, op_acc: 46.88%] [G loss: 0.808624]\n",
      "epoch:28 step:22273[D loss: 0.420895, acc: 65.62%, op_acc: 42.19%] [G loss: 0.987366]\n",
      "epoch:28 step:22274[D loss: 0.390248, acc: 66.41%, op_acc: 42.97%] [G loss: 0.754361]\n",
      "epoch:28 step:22275[D loss: 0.391795, acc: 71.09%, op_acc: 38.28%] [G loss: 0.807950]\n",
      "epoch:28 step:22276[D loss: 0.395177, acc: 64.06%, op_acc: 42.19%] [G loss: 0.801983]\n",
      "epoch:28 step:22277[D loss: 0.423830, acc: 58.59%, op_acc: 39.06%] [G loss: 0.945547]\n",
      "epoch:28 step:22278[D loss: 0.410635, acc: 61.72%, op_acc: 38.28%] [G loss: 0.962935]\n",
      "epoch:28 step:22279[D loss: 0.436048, acc: 57.81%, op_acc: 45.31%] [G loss: 0.868160]\n",
      "epoch:28 step:22280[D loss: 0.410314, acc: 58.59%, op_acc: 44.53%] [G loss: 0.928487]\n",
      "epoch:28 step:22281[D loss: 0.397755, acc: 67.19%, op_acc: 43.75%] [G loss: 0.828559]\n",
      "epoch:28 step:22282[D loss: 0.386139, acc: 74.22%, op_acc: 42.19%] [G loss: 0.858288]\n",
      "epoch:28 step:22283[D loss: 0.389541, acc: 67.19%, op_acc: 40.62%] [G loss: 0.870141]\n",
      "epoch:28 step:22284[D loss: 0.426443, acc: 54.69%, op_acc: 42.19%] [G loss: 0.836945]\n",
      "epoch:28 step:22285[D loss: 0.402129, acc: 61.72%, op_acc: 42.97%] [G loss: 0.789305]\n",
      "epoch:28 step:22286[D loss: 0.424136, acc: 62.50%, op_acc: 38.28%] [G loss: 0.854088]\n",
      "epoch:28 step:22287[D loss: 0.427366, acc: 56.25%, op_acc: 40.62%] [G loss: 0.794846]\n",
      "epoch:28 step:22288[D loss: 0.469245, acc: 50.00%, op_acc: 40.62%] [G loss: 0.787435]\n",
      "epoch:28 step:22289[D loss: 0.466209, acc: 60.16%, op_acc: 36.72%] [G loss: 0.838729]\n",
      "epoch:28 step:22290[D loss: 0.396558, acc: 58.59%, op_acc: 46.09%] [G loss: 0.963258]\n",
      "epoch:28 step:22291[D loss: 0.469385, acc: 55.47%, op_acc: 34.38%] [G loss: 0.935700]\n",
      "epoch:28 step:22292[D loss: 0.448028, acc: 53.91%, op_acc: 33.59%] [G loss: 0.856941]\n",
      "epoch:28 step:22293[D loss: 0.442964, acc: 53.91%, op_acc: 40.62%] [G loss: 0.911445]\n",
      "epoch:28 step:22294[D loss: 0.412997, acc: 65.62%, op_acc: 46.09%] [G loss: 0.861122]\n",
      "epoch:28 step:22295[D loss: 0.408197, acc: 67.19%, op_acc: 37.50%] [G loss: 0.891528]\n",
      "epoch:28 step:22296[D loss: 0.379358, acc: 64.06%, op_acc: 45.31%] [G loss: 1.049559]\n",
      "epoch:28 step:22297[D loss: 0.401914, acc: 59.38%, op_acc: 45.31%] [G loss: 0.969749]\n",
      "epoch:28 step:22298[D loss: 0.355842, acc: 75.00%, op_acc: 50.78%] [G loss: 0.982743]\n",
      "epoch:28 step:22299[D loss: 0.402905, acc: 64.06%, op_acc: 41.41%] [G loss: 1.045579]\n",
      "epoch:28 step:22300[D loss: 0.351167, acc: 67.97%, op_acc: 48.44%] [G loss: 1.030311]\n",
      "epoch:28 step:22301[D loss: 0.396051, acc: 71.88%, op_acc: 44.53%] [G loss: 1.100038]\n",
      "epoch:28 step:22302[D loss: 0.385745, acc: 63.28%, op_acc: 44.53%] [G loss: 1.082472]\n",
      "epoch:28 step:22303[D loss: 0.367907, acc: 69.53%, op_acc: 49.22%] [G loss: 0.848070]\n",
      "epoch:28 step:22304[D loss: 0.428970, acc: 60.94%, op_acc: 39.06%] [G loss: 1.056722]\n",
      "epoch:28 step:22305[D loss: 0.382762, acc: 66.41%, op_acc: 48.44%] [G loss: 1.193459]\n",
      "epoch:28 step:22306[D loss: 0.373272, acc: 73.44%, op_acc: 39.84%] [G loss: 1.116948]\n",
      "epoch:28 step:22307[D loss: 0.386596, acc: 61.72%, op_acc: 43.75%] [G loss: 1.186781]\n",
      "epoch:28 step:22308[D loss: 0.400532, acc: 62.50%, op_acc: 39.06%] [G loss: 0.852720]\n",
      "epoch:28 step:22309[D loss: 0.379324, acc: 67.19%, op_acc: 42.97%] [G loss: 1.268266]\n",
      "epoch:28 step:22310[D loss: 0.379183, acc: 66.41%, op_acc: 45.31%] [G loss: 1.183213]\n",
      "epoch:28 step:22311[D loss: 0.390273, acc: 68.75%, op_acc: 40.62%] [G loss: 1.182496]\n",
      "epoch:28 step:22312[D loss: 0.344814, acc: 75.00%, op_acc: 46.88%] [G loss: 1.001383]\n",
      "epoch:28 step:22313[D loss: 0.414735, acc: 60.16%, op_acc: 42.19%] [G loss: 0.832349]\n",
      "epoch:28 step:22314[D loss: 0.408239, acc: 64.84%, op_acc: 39.84%] [G loss: 1.143264]\n",
      "epoch:28 step:22315[D loss: 0.427604, acc: 67.19%, op_acc: 31.25%] [G loss: 0.855648]\n",
      "epoch:28 step:22316[D loss: 0.425935, acc: 58.59%, op_acc: 40.62%] [G loss: 0.789019]\n",
      "epoch:28 step:22317[D loss: 0.376168, acc: 70.31%, op_acc: 46.09%] [G loss: 0.914039]\n",
      "epoch:28 step:22318[D loss: 0.452147, acc: 53.12%, op_acc: 39.84%] [G loss: 1.205314]\n",
      "epoch:28 step:22319[D loss: 0.388782, acc: 60.16%, op_acc: 46.88%] [G loss: 0.922993]\n",
      "epoch:28 step:22320[D loss: 0.400834, acc: 58.59%, op_acc: 42.97%] [G loss: 1.152474]\n",
      "epoch:28 step:22321[D loss: 0.452328, acc: 55.47%, op_acc: 39.06%] [G loss: 1.136428]\n",
      "epoch:28 step:22322[D loss: 0.409974, acc: 64.06%, op_acc: 41.41%] [G loss: 0.857869]\n",
      "epoch:28 step:22323[D loss: 0.463068, acc: 52.34%, op_acc: 37.50%] [G loss: 0.947707]\n",
      "epoch:28 step:22324[D loss: 0.426971, acc: 60.94%, op_acc: 39.84%] [G loss: 0.902312]\n",
      "epoch:28 step:22325[D loss: 0.443019, acc: 60.16%, op_acc: 42.19%] [G loss: 1.027429]\n",
      "epoch:28 step:22326[D loss: 0.386980, acc: 65.62%, op_acc: 43.75%] [G loss: 1.029242]\n",
      "epoch:28 step:22327[D loss: 0.414518, acc: 53.12%, op_acc: 46.09%] [G loss: 0.953786]\n",
      "epoch:28 step:22328[D loss: 0.417930, acc: 60.16%, op_acc: 44.53%] [G loss: 0.965225]\n",
      "epoch:28 step:22329[D loss: 0.405712, acc: 60.94%, op_acc: 42.19%] [G loss: 0.894816]\n",
      "epoch:28 step:22330[D loss: 0.371491, acc: 70.31%, op_acc: 44.53%] [G loss: 0.974843]\n",
      "epoch:28 step:22331[D loss: 0.409870, acc: 61.72%, op_acc: 46.09%] [G loss: 0.974962]\n",
      "epoch:28 step:22332[D loss: 0.431043, acc: 60.94%, op_acc: 42.97%] [G loss: 0.916799]\n",
      "epoch:28 step:22333[D loss: 0.431265, acc: 57.03%, op_acc: 42.97%] [G loss: 0.970811]\n",
      "epoch:28 step:22334[D loss: 0.417098, acc: 59.38%, op_acc: 34.38%] [G loss: 0.873995]\n",
      "epoch:28 step:22335[D loss: 0.430313, acc: 56.25%, op_acc: 35.94%] [G loss: 0.847696]\n",
      "epoch:28 step:22336[D loss: 0.431216, acc: 50.00%, op_acc: 43.75%] [G loss: 0.951081]\n",
      "epoch:28 step:22337[D loss: 0.409154, acc: 61.72%, op_acc: 41.41%] [G loss: 0.799665]\n",
      "epoch:28 step:22338[D loss: 0.382637, acc: 70.31%, op_acc: 47.66%] [G loss: 1.043849]\n",
      "epoch:28 step:22339[D loss: 0.439347, acc: 59.38%, op_acc: 32.81%] [G loss: 0.897406]\n",
      "epoch:28 step:22340[D loss: 0.435954, acc: 60.16%, op_acc: 39.84%] [G loss: 0.997648]\n",
      "epoch:28 step:22341[D loss: 0.411058, acc: 58.59%, op_acc: 47.66%] [G loss: 1.009541]\n",
      "epoch:28 step:22342[D loss: 0.406995, acc: 67.19%, op_acc: 40.62%] [G loss: 1.008055]\n",
      "epoch:28 step:22343[D loss: 0.430889, acc: 53.12%, op_acc: 42.97%] [G loss: 0.980599]\n",
      "epoch:28 step:22344[D loss: 0.413908, acc: 57.81%, op_acc: 35.94%] [G loss: 0.977003]\n",
      "epoch:28 step:22345[D loss: 0.420776, acc: 58.59%, op_acc: 43.75%] [G loss: 0.889610]\n",
      "epoch:28 step:22346[D loss: 0.389206, acc: 64.84%, op_acc: 43.75%] [G loss: 1.006310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22347[D loss: 0.378024, acc: 67.19%, op_acc: 40.62%] [G loss: 1.065618]\n",
      "epoch:28 step:22348[D loss: 0.421276, acc: 61.72%, op_acc: 38.28%] [G loss: 0.838236]\n",
      "epoch:28 step:22349[D loss: 0.451848, acc: 62.50%, op_acc: 32.03%] [G loss: 1.078515]\n",
      "epoch:28 step:22350[D loss: 0.407602, acc: 65.62%, op_acc: 46.88%] [G loss: 0.852086]\n",
      "epoch:28 step:22351[D loss: 0.409450, acc: 62.50%, op_acc: 42.19%] [G loss: 0.991973]\n",
      "epoch:28 step:22352[D loss: 0.405068, acc: 63.28%, op_acc: 48.44%] [G loss: 0.982744]\n",
      "epoch:28 step:22353[D loss: 0.443163, acc: 58.59%, op_acc: 35.16%] [G loss: 0.986800]\n",
      "epoch:28 step:22354[D loss: 0.365954, acc: 67.19%, op_acc: 42.97%] [G loss: 0.880879]\n",
      "epoch:28 step:22355[D loss: 0.403932, acc: 66.41%, op_acc: 38.28%] [G loss: 0.943706]\n",
      "epoch:28 step:22356[D loss: 0.441163, acc: 57.03%, op_acc: 32.03%] [G loss: 0.845771]\n",
      "epoch:28 step:22357[D loss: 0.362060, acc: 73.44%, op_acc: 53.12%] [G loss: 0.939085]\n",
      "epoch:28 step:22358[D loss: 0.401912, acc: 60.16%, op_acc: 39.84%] [G loss: 0.788134]\n",
      "epoch:28 step:22359[D loss: 0.443318, acc: 61.72%, op_acc: 35.16%] [G loss: 0.873302]\n",
      "epoch:28 step:22360[D loss: 0.408481, acc: 58.59%, op_acc: 39.84%] [G loss: 0.879776]\n",
      "epoch:28 step:22361[D loss: 0.403529, acc: 62.50%, op_acc: 42.19%] [G loss: 0.875640]\n",
      "epoch:28 step:22362[D loss: 0.373819, acc: 67.97%, op_acc: 46.88%] [G loss: 0.961931]\n",
      "epoch:28 step:22363[D loss: 0.417081, acc: 58.59%, op_acc: 40.62%] [G loss: 0.957210]\n",
      "epoch:28 step:22364[D loss: 0.375940, acc: 72.66%, op_acc: 39.06%] [G loss: 0.815567]\n",
      "epoch:28 step:22365[D loss: 0.389190, acc: 62.50%, op_acc: 46.09%] [G loss: 0.887952]\n",
      "epoch:28 step:22366[D loss: 0.426901, acc: 56.25%, op_acc: 39.06%] [G loss: 0.800458]\n",
      "epoch:28 step:22367[D loss: 0.390817, acc: 64.06%, op_acc: 45.31%] [G loss: 0.838741]\n",
      "epoch:28 step:22368[D loss: 0.387116, acc: 67.19%, op_acc: 47.66%] [G loss: 0.902280]\n",
      "epoch:28 step:22369[D loss: 0.424730, acc: 57.03%, op_acc: 36.72%] [G loss: 0.965439]\n",
      "epoch:28 step:22370[D loss: 0.406351, acc: 60.94%, op_acc: 40.62%] [G loss: 0.873458]\n",
      "epoch:28 step:22371[D loss: 0.409918, acc: 61.72%, op_acc: 37.50%] [G loss: 0.852668]\n",
      "epoch:28 step:22372[D loss: 0.452182, acc: 59.38%, op_acc: 38.28%] [G loss: 0.864419]\n",
      "epoch:28 step:22373[D loss: 0.415839, acc: 61.72%, op_acc: 42.19%] [G loss: 0.883182]\n",
      "epoch:28 step:22374[D loss: 0.410682, acc: 67.97%, op_acc: 39.84%] [G loss: 0.998060]\n",
      "epoch:28 step:22375[D loss: 0.381421, acc: 66.41%, op_acc: 46.09%] [G loss: 0.989490]\n",
      "epoch:28 step:22376[D loss: 0.415671, acc: 56.25%, op_acc: 45.31%] [G loss: 0.958959]\n",
      "epoch:28 step:22377[D loss: 0.440441, acc: 63.28%, op_acc: 43.75%] [G loss: 0.841764]\n",
      "epoch:28 step:22378[D loss: 0.417023, acc: 63.28%, op_acc: 43.75%] [G loss: 0.859966]\n",
      "epoch:28 step:22379[D loss: 0.409133, acc: 60.16%, op_acc: 40.62%] [G loss: 0.857336]\n",
      "epoch:28 step:22380[D loss: 0.453526, acc: 55.47%, op_acc: 35.94%] [G loss: 0.936448]\n",
      "epoch:28 step:22381[D loss: 0.459918, acc: 53.91%, op_acc: 39.06%] [G loss: 0.888081]\n",
      "epoch:28 step:22382[D loss: 0.424364, acc: 61.72%, op_acc: 39.06%] [G loss: 0.897497]\n",
      "epoch:28 step:22383[D loss: 0.405070, acc: 67.19%, op_acc: 41.41%] [G loss: 0.905828]\n",
      "epoch:28 step:22384[D loss: 0.373798, acc: 71.88%, op_acc: 42.19%] [G loss: 0.896482]\n",
      "epoch:28 step:22385[D loss: 0.435117, acc: 58.59%, op_acc: 42.19%] [G loss: 0.921438]\n",
      "epoch:28 step:22386[D loss: 0.362563, acc: 67.97%, op_acc: 40.62%] [G loss: 0.952301]\n",
      "epoch:28 step:22387[D loss: 0.392232, acc: 64.84%, op_acc: 39.06%] [G loss: 0.920630]\n",
      "epoch:28 step:22388[D loss: 0.428763, acc: 63.28%, op_acc: 37.50%] [G loss: 0.892625]\n",
      "epoch:28 step:22389[D loss: 0.417193, acc: 60.94%, op_acc: 41.41%] [G loss: 0.939023]\n",
      "epoch:28 step:22390[D loss: 0.420154, acc: 63.28%, op_acc: 46.88%] [G loss: 0.933602]\n",
      "epoch:28 step:22391[D loss: 0.421540, acc: 60.94%, op_acc: 39.06%] [G loss: 0.889292]\n",
      "epoch:28 step:22392[D loss: 0.400852, acc: 64.84%, op_acc: 40.62%] [G loss: 0.906517]\n",
      "epoch:28 step:22393[D loss: 0.436593, acc: 62.50%, op_acc: 32.81%] [G loss: 0.882865]\n",
      "epoch:28 step:22394[D loss: 0.429724, acc: 62.50%, op_acc: 36.72%] [G loss: 0.926625]\n",
      "epoch:28 step:22395[D loss: 0.418820, acc: 63.28%, op_acc: 42.19%] [G loss: 0.843289]\n",
      "epoch:28 step:22396[D loss: 0.404245, acc: 60.94%, op_acc: 43.75%] [G loss: 0.901539]\n",
      "epoch:28 step:22397[D loss: 0.389562, acc: 67.19%, op_acc: 39.84%] [G loss: 0.907708]\n",
      "epoch:28 step:22398[D loss: 0.366854, acc: 68.75%, op_acc: 44.53%] [G loss: 0.870899]\n",
      "epoch:28 step:22399[D loss: 0.410186, acc: 64.06%, op_acc: 39.06%] [G loss: 0.949356]\n",
      "epoch:28 step:22400[D loss: 0.419712, acc: 59.38%, op_acc: 36.72%] [G loss: 0.970015]\n",
      "epoch:28 step:22401[D loss: 0.431966, acc: 56.25%, op_acc: 41.41%] [G loss: 0.962585]\n",
      "epoch:28 step:22402[D loss: 0.400303, acc: 65.62%, op_acc: 39.84%] [G loss: 0.834921]\n",
      "epoch:28 step:22403[D loss: 0.376109, acc: 75.78%, op_acc: 35.94%] [G loss: 0.966731]\n",
      "epoch:28 step:22404[D loss: 0.385656, acc: 60.16%, op_acc: 50.00%] [G loss: 0.932994]\n",
      "epoch:28 step:22405[D loss: 0.440046, acc: 56.25%, op_acc: 39.06%] [G loss: 0.914439]\n",
      "epoch:28 step:22406[D loss: 0.408157, acc: 61.72%, op_acc: 39.84%] [G loss: 0.920633]\n",
      "epoch:28 step:22407[D loss: 0.420531, acc: 59.38%, op_acc: 36.72%] [G loss: 0.957268]\n",
      "epoch:28 step:22408[D loss: 0.435229, acc: 56.25%, op_acc: 37.50%] [G loss: 0.924457]\n",
      "epoch:28 step:22409[D loss: 0.357511, acc: 69.53%, op_acc: 46.09%] [G loss: 1.074082]\n",
      "epoch:28 step:22410[D loss: 0.472392, acc: 54.69%, op_acc: 39.06%] [G loss: 0.804325]\n",
      "epoch:28 step:22411[D loss: 0.415012, acc: 66.41%, op_acc: 38.28%] [G loss: 0.907641]\n",
      "epoch:28 step:22412[D loss: 0.435817, acc: 54.69%, op_acc: 42.19%] [G loss: 0.942681]\n",
      "epoch:28 step:22413[D loss: 0.374397, acc: 71.88%, op_acc: 41.41%] [G loss: 0.956408]\n",
      "epoch:28 step:22414[D loss: 0.438714, acc: 52.34%, op_acc: 43.75%] [G loss: 1.016588]\n",
      "epoch:28 step:22415[D loss: 0.429319, acc: 58.59%, op_acc: 33.59%] [G loss: 0.910672]\n",
      "epoch:28 step:22416[D loss: 0.437637, acc: 57.81%, op_acc: 43.75%] [G loss: 0.973490]\n",
      "epoch:28 step:22417[D loss: 0.400342, acc: 61.72%, op_acc: 48.44%] [G loss: 0.974482]\n",
      "epoch:28 step:22418[D loss: 0.421790, acc: 59.38%, op_acc: 44.53%] [G loss: 0.915943]\n",
      "epoch:28 step:22419[D loss: 0.384694, acc: 67.19%, op_acc: 43.75%] [G loss: 0.968139]\n",
      "epoch:28 step:22420[D loss: 0.447007, acc: 50.00%, op_acc: 36.72%] [G loss: 0.902668]\n",
      "epoch:28 step:22421[D loss: 0.375258, acc: 71.09%, op_acc: 46.09%] [G loss: 0.840210]\n",
      "epoch:28 step:22422[D loss: 0.422392, acc: 63.28%, op_acc: 40.62%] [G loss: 0.945684]\n",
      "epoch:28 step:22423[D loss: 0.376424, acc: 63.28%, op_acc: 45.31%] [G loss: 0.896513]\n",
      "epoch:28 step:22424[D loss: 0.400684, acc: 60.16%, op_acc: 46.09%] [G loss: 1.050354]\n",
      "epoch:28 step:22425[D loss: 0.407879, acc: 60.94%, op_acc: 41.41%] [G loss: 0.849325]\n",
      "epoch:28 step:22426[D loss: 0.404368, acc: 61.72%, op_acc: 40.62%] [G loss: 0.867227]\n",
      "epoch:28 step:22427[D loss: 0.415639, acc: 60.16%, op_acc: 39.84%] [G loss: 0.845632]\n",
      "epoch:28 step:22428[D loss: 0.429317, acc: 62.50%, op_acc: 42.97%] [G loss: 0.934025]\n",
      "epoch:28 step:22429[D loss: 0.367774, acc: 67.97%, op_acc: 47.66%] [G loss: 0.974882]\n",
      "epoch:28 step:22430[D loss: 0.423347, acc: 60.16%, op_acc: 37.50%] [G loss: 1.021252]\n",
      "epoch:28 step:22431[D loss: 0.419513, acc: 66.41%, op_acc: 39.06%] [G loss: 0.925371]\n",
      "epoch:28 step:22432[D loss: 0.381777, acc: 70.31%, op_acc: 50.00%] [G loss: 0.998836]\n",
      "epoch:28 step:22433[D loss: 0.432503, acc: 58.59%, op_acc: 39.84%] [G loss: 0.866230]\n",
      "epoch:28 step:22434[D loss: 0.384038, acc: 65.62%, op_acc: 45.31%] [G loss: 0.878795]\n",
      "epoch:28 step:22435[D loss: 0.415546, acc: 57.81%, op_acc: 44.53%] [G loss: 1.025102]\n",
      "epoch:28 step:22436[D loss: 0.375944, acc: 71.88%, op_acc: 48.44%] [G loss: 0.907227]\n",
      "epoch:28 step:22437[D loss: 0.388503, acc: 62.50%, op_acc: 50.00%] [G loss: 0.937104]\n",
      "epoch:28 step:22438[D loss: 0.399123, acc: 67.97%, op_acc: 41.41%] [G loss: 0.898633]\n",
      "epoch:28 step:22439[D loss: 0.384919, acc: 65.62%, op_acc: 52.34%] [G loss: 0.788268]\n",
      "epoch:28 step:22440[D loss: 0.441803, acc: 60.94%, op_acc: 42.19%] [G loss: 0.882585]\n",
      "epoch:28 step:22441[D loss: 0.412075, acc: 67.97%, op_acc: 39.06%] [G loss: 0.825352]\n",
      "epoch:28 step:22442[D loss: 0.459571, acc: 54.69%, op_acc: 32.81%] [G loss: 1.057945]\n",
      "epoch:28 step:22443[D loss: 0.444702, acc: 57.03%, op_acc: 32.81%] [G loss: 1.055627]\n",
      "epoch:28 step:22444[D loss: 0.422006, acc: 57.81%, op_acc: 43.75%] [G loss: 0.965161]\n",
      "epoch:28 step:22445[D loss: 0.403469, acc: 60.94%, op_acc: 42.19%] [G loss: 0.936219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22446[D loss: 0.459822, acc: 53.12%, op_acc: 36.72%] [G loss: 0.895053]\n",
      "epoch:28 step:22447[D loss: 0.368986, acc: 69.53%, op_acc: 42.97%] [G loss: 0.936237]\n",
      "epoch:28 step:22448[D loss: 0.411610, acc: 66.41%, op_acc: 35.94%] [G loss: 1.013981]\n",
      "epoch:28 step:22449[D loss: 0.409158, acc: 71.88%, op_acc: 38.28%] [G loss: 1.048488]\n",
      "epoch:28 step:22450[D loss: 0.397030, acc: 65.62%, op_acc: 39.84%] [G loss: 0.944823]\n",
      "epoch:28 step:22451[D loss: 0.402063, acc: 57.03%, op_acc: 45.31%] [G loss: 0.972478]\n",
      "epoch:28 step:22452[D loss: 0.466579, acc: 56.25%, op_acc: 32.81%] [G loss: 1.006696]\n",
      "epoch:28 step:22453[D loss: 0.430085, acc: 50.00%, op_acc: 42.97%] [G loss: 0.912945]\n",
      "epoch:28 step:22454[D loss: 0.412751, acc: 64.84%, op_acc: 37.50%] [G loss: 0.874975]\n",
      "epoch:28 step:22455[D loss: 0.426716, acc: 63.28%, op_acc: 39.06%] [G loss: 0.990636]\n",
      "epoch:28 step:22456[D loss: 0.385307, acc: 65.62%, op_acc: 42.97%] [G loss: 0.972028]\n",
      "epoch:28 step:22457[D loss: 0.385139, acc: 66.41%, op_acc: 42.19%] [G loss: 0.947249]\n",
      "epoch:28 step:22458[D loss: 0.400995, acc: 66.41%, op_acc: 41.41%] [G loss: 0.905346]\n",
      "epoch:28 step:22459[D loss: 0.445410, acc: 57.81%, op_acc: 33.59%] [G loss: 0.909722]\n",
      "epoch:28 step:22460[D loss: 0.415153, acc: 59.38%, op_acc: 42.19%] [G loss: 1.033966]\n",
      "epoch:28 step:22461[D loss: 0.422993, acc: 63.28%, op_acc: 39.06%] [G loss: 0.956083]\n",
      "epoch:28 step:22462[D loss: 0.418209, acc: 60.16%, op_acc: 40.62%] [G loss: 0.880149]\n",
      "epoch:28 step:22463[D loss: 0.411466, acc: 64.06%, op_acc: 39.06%] [G loss: 0.889722]\n",
      "epoch:28 step:22464[D loss: 0.416375, acc: 60.94%, op_acc: 42.97%] [G loss: 0.950545]\n",
      "epoch:28 step:22465[D loss: 0.374956, acc: 69.53%, op_acc: 49.22%] [G loss: 0.887941]\n",
      "epoch:28 step:22466[D loss: 0.372840, acc: 71.09%, op_acc: 48.44%] [G loss: 0.899993]\n",
      "epoch:28 step:22467[D loss: 0.411220, acc: 67.19%, op_acc: 40.62%] [G loss: 1.011722]\n",
      "epoch:28 step:22468[D loss: 0.404127, acc: 59.38%, op_acc: 39.06%] [G loss: 0.966210]\n",
      "epoch:28 step:22469[D loss: 0.449726, acc: 50.78%, op_acc: 35.94%] [G loss: 0.964693]\n",
      "epoch:28 step:22470[D loss: 0.427141, acc: 61.72%, op_acc: 42.97%] [G loss: 0.821837]\n",
      "epoch:28 step:22471[D loss: 0.410861, acc: 61.72%, op_acc: 42.19%] [G loss: 0.912756]\n",
      "epoch:28 step:22472[D loss: 0.427533, acc: 64.06%, op_acc: 40.62%] [G loss: 0.936427]\n",
      "epoch:28 step:22473[D loss: 0.421180, acc: 60.16%, op_acc: 37.50%] [G loss: 1.042524]\n",
      "epoch:28 step:22474[D loss: 0.459181, acc: 53.12%, op_acc: 36.72%] [G loss: 0.730982]\n",
      "epoch:28 step:22475[D loss: 0.444034, acc: 52.34%, op_acc: 37.50%] [G loss: 0.925918]\n",
      "epoch:28 step:22476[D loss: 0.376446, acc: 65.62%, op_acc: 48.44%] [G loss: 0.900952]\n",
      "epoch:28 step:22477[D loss: 0.413792, acc: 59.38%, op_acc: 44.53%] [G loss: 0.977692]\n",
      "epoch:28 step:22478[D loss: 0.424054, acc: 62.50%, op_acc: 42.97%] [G loss: 0.938241]\n",
      "epoch:28 step:22479[D loss: 0.393904, acc: 68.75%, op_acc: 45.31%] [G loss: 0.861135]\n",
      "epoch:28 step:22480[D loss: 0.396535, acc: 65.62%, op_acc: 41.41%] [G loss: 0.831623]\n",
      "epoch:28 step:22481[D loss: 0.463491, acc: 53.12%, op_acc: 38.28%] [G loss: 0.891089]\n",
      "epoch:28 step:22482[D loss: 0.390398, acc: 67.97%, op_acc: 35.94%] [G loss: 1.028050]\n",
      "epoch:28 step:22483[D loss: 0.374783, acc: 75.00%, op_acc: 39.06%] [G loss: 1.000194]\n",
      "epoch:28 step:22484[D loss: 0.454061, acc: 55.47%, op_acc: 35.94%] [G loss: 1.024563]\n",
      "epoch:28 step:22485[D loss: 0.432001, acc: 60.16%, op_acc: 33.59%] [G loss: 0.865898]\n",
      "epoch:28 step:22486[D loss: 0.423091, acc: 61.72%, op_acc: 41.41%] [G loss: 0.993354]\n",
      "epoch:28 step:22487[D loss: 0.426650, acc: 63.28%, op_acc: 38.28%] [G loss: 0.893826]\n",
      "epoch:28 step:22488[D loss: 0.421936, acc: 62.50%, op_acc: 36.72%] [G loss: 0.997225]\n",
      "epoch:28 step:22489[D loss: 0.415644, acc: 64.06%, op_acc: 35.94%] [G loss: 0.936631]\n",
      "epoch:28 step:22490[D loss: 0.400851, acc: 71.88%, op_acc: 38.28%] [G loss: 0.901569]\n",
      "epoch:28 step:22491[D loss: 0.395448, acc: 61.72%, op_acc: 46.09%] [G loss: 0.834045]\n",
      "epoch:28 step:22492[D loss: 0.409875, acc: 60.16%, op_acc: 39.06%] [G loss: 0.944056]\n",
      "epoch:28 step:22493[D loss: 0.431632, acc: 55.47%, op_acc: 42.19%] [G loss: 0.777535]\n",
      "epoch:28 step:22494[D loss: 0.412706, acc: 57.81%, op_acc: 39.84%] [G loss: 0.740446]\n",
      "epoch:28 step:22495[D loss: 0.423186, acc: 55.47%, op_acc: 41.41%] [G loss: 0.731178]\n",
      "epoch:28 step:22496[D loss: 0.420559, acc: 62.50%, op_acc: 39.84%] [G loss: 1.014807]\n",
      "epoch:28 step:22497[D loss: 0.393982, acc: 60.94%, op_acc: 45.31%] [G loss: 0.783016]\n",
      "epoch:28 step:22498[D loss: 0.384374, acc: 65.62%, op_acc: 42.19%] [G loss: 1.004428]\n",
      "epoch:28 step:22499[D loss: 0.396540, acc: 69.53%, op_acc: 39.06%] [G loss: 0.957573]\n",
      "epoch:28 step:22500[D loss: 0.419038, acc: 60.16%, op_acc: 39.06%] [G loss: 0.926670]\n",
      "epoch:28 step:22501[D loss: 0.396376, acc: 67.19%, op_acc: 40.62%] [G loss: 0.739870]\n",
      "epoch:28 step:22502[D loss: 0.400878, acc: 66.41%, op_acc: 40.62%] [G loss: 1.036128]\n",
      "epoch:28 step:22503[D loss: 0.399160, acc: 64.06%, op_acc: 37.50%] [G loss: 0.867016]\n",
      "epoch:28 step:22504[D loss: 0.405939, acc: 60.94%, op_acc: 40.62%] [G loss: 0.872584]\n",
      "epoch:28 step:22505[D loss: 0.414338, acc: 59.38%, op_acc: 39.84%] [G loss: 0.965954]\n",
      "epoch:28 step:22506[D loss: 0.431251, acc: 59.38%, op_acc: 39.84%] [G loss: 0.907400]\n",
      "epoch:28 step:22507[D loss: 0.407431, acc: 63.28%, op_acc: 39.06%] [G loss: 0.889996]\n",
      "epoch:28 step:22508[D loss: 0.444737, acc: 57.81%, op_acc: 39.84%] [G loss: 0.876029]\n",
      "epoch:28 step:22509[D loss: 0.413376, acc: 67.19%, op_acc: 38.28%] [G loss: 0.923049]\n",
      "epoch:28 step:22510[D loss: 0.431533, acc: 59.38%, op_acc: 43.75%] [G loss: 0.944996]\n",
      "epoch:28 step:22511[D loss: 0.403484, acc: 67.97%, op_acc: 38.28%] [G loss: 0.850427]\n",
      "epoch:28 step:22512[D loss: 0.346242, acc: 74.22%, op_acc: 50.78%] [G loss: 0.905791]\n",
      "epoch:28 step:22513[D loss: 0.364200, acc: 72.66%, op_acc: 42.97%] [G loss: 0.925070]\n",
      "epoch:28 step:22514[D loss: 0.429128, acc: 59.38%, op_acc: 39.06%] [G loss: 1.025552]\n",
      "epoch:28 step:22515[D loss: 0.367425, acc: 68.75%, op_acc: 46.88%] [G loss: 0.914222]\n",
      "epoch:28 step:22516[D loss: 0.357121, acc: 71.88%, op_acc: 44.53%] [G loss: 0.947865]\n",
      "epoch:28 step:22517[D loss: 0.360896, acc: 68.75%, op_acc: 41.41%] [G loss: 1.060704]\n",
      "epoch:28 step:22518[D loss: 0.434042, acc: 65.62%, op_acc: 39.84%] [G loss: 1.021061]\n",
      "epoch:28 step:22519[D loss: 0.438753, acc: 57.03%, op_acc: 43.75%] [G loss: 1.017312]\n",
      "epoch:28 step:22520[D loss: 0.368365, acc: 69.53%, op_acc: 43.75%] [G loss: 1.041148]\n",
      "epoch:28 step:22521[D loss: 0.360547, acc: 72.66%, op_acc: 46.09%] [G loss: 1.068839]\n",
      "epoch:28 step:22522[D loss: 0.399996, acc: 66.41%, op_acc: 43.75%] [G loss: 0.863732]\n",
      "epoch:28 step:22523[D loss: 0.393612, acc: 71.88%, op_acc: 33.59%] [G loss: 0.955440]\n",
      "epoch:28 step:22524[D loss: 0.377460, acc: 71.88%, op_acc: 42.19%] [G loss: 1.160539]\n",
      "epoch:28 step:22525[D loss: 0.360776, acc: 72.66%, op_acc: 48.44%] [G loss: 1.239782]\n",
      "epoch:28 step:22526[D loss: 0.353535, acc: 75.00%, op_acc: 41.41%] [G loss: 1.187158]\n",
      "epoch:28 step:22527[D loss: 0.381856, acc: 67.97%, op_acc: 42.19%] [G loss: 1.102633]\n",
      "epoch:28 step:22528[D loss: 0.357827, acc: 75.00%, op_acc: 46.09%] [G loss: 1.043933]\n",
      "epoch:28 step:22529[D loss: 0.342268, acc: 73.44%, op_acc: 47.66%] [G loss: 0.895052]\n",
      "epoch:28 step:22530[D loss: 0.413257, acc: 60.16%, op_acc: 42.97%] [G loss: 1.163696]\n",
      "epoch:28 step:22531[D loss: 0.390898, acc: 65.62%, op_acc: 35.94%] [G loss: 0.735162]\n",
      "epoch:28 step:22532[D loss: 0.400401, acc: 65.62%, op_acc: 37.50%] [G loss: 0.863496]\n",
      "epoch:28 step:22533[D loss: 0.435514, acc: 60.94%, op_acc: 37.50%] [G loss: 1.046557]\n",
      "epoch:28 step:22534[D loss: 0.417547, acc: 64.06%, op_acc: 36.72%] [G loss: 0.790772]\n",
      "epoch:28 step:22535[D loss: 0.425857, acc: 54.69%, op_acc: 39.84%] [G loss: 0.884833]\n",
      "epoch:28 step:22536[D loss: 0.410897, acc: 64.84%, op_acc: 42.97%] [G loss: 1.143143]\n",
      "epoch:28 step:22537[D loss: 0.441698, acc: 60.16%, op_acc: 42.97%] [G loss: 0.708200]\n",
      "epoch:28 step:22538[D loss: 0.431453, acc: 56.25%, op_acc: 39.06%] [G loss: 1.126064]\n",
      "epoch:28 step:22539[D loss: 0.410009, acc: 64.84%, op_acc: 37.50%] [G loss: 0.988717]\n",
      "epoch:28 step:22540[D loss: 0.431518, acc: 60.16%, op_acc: 40.62%] [G loss: 0.878598]\n",
      "epoch:28 step:22541[D loss: 0.422099, acc: 60.94%, op_acc: 42.19%] [G loss: 1.079985]\n",
      "epoch:28 step:22542[D loss: 0.449773, acc: 53.12%, op_acc: 40.62%] [G loss: 1.074317]\n",
      "epoch:28 step:22543[D loss: 0.449210, acc: 57.03%, op_acc: 37.50%] [G loss: 1.056741]\n",
      "epoch:28 step:22544[D loss: 0.446961, acc: 55.47%, op_acc: 40.62%] [G loss: 1.059092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22545[D loss: 0.448909, acc: 53.91%, op_acc: 33.59%] [G loss: 1.025572]\n",
      "epoch:28 step:22546[D loss: 0.409785, acc: 60.16%, op_acc: 41.41%] [G loss: 0.893340]\n",
      "epoch:28 step:22547[D loss: 0.384657, acc: 70.31%, op_acc: 38.28%] [G loss: 1.104476]\n",
      "epoch:28 step:22548[D loss: 0.395277, acc: 67.97%, op_acc: 35.94%] [G loss: 1.135188]\n",
      "epoch:28 step:22549[D loss: 0.427264, acc: 57.81%, op_acc: 43.75%] [G loss: 0.996985]\n",
      "epoch:28 step:22550[D loss: 0.378343, acc: 67.19%, op_acc: 46.88%] [G loss: 0.992713]\n",
      "epoch:28 step:22551[D loss: 0.407766, acc: 60.94%, op_acc: 39.84%] [G loss: 0.787728]\n",
      "epoch:28 step:22552[D loss: 0.446521, acc: 57.81%, op_acc: 36.72%] [G loss: 0.736735]\n",
      "epoch:28 step:22553[D loss: 0.435399, acc: 67.97%, op_acc: 38.28%] [G loss: 0.807331]\n",
      "epoch:28 step:22554[D loss: 0.445027, acc: 54.69%, op_acc: 42.97%] [G loss: 0.788257]\n",
      "epoch:28 step:22555[D loss: 0.388572, acc: 61.72%, op_acc: 42.19%] [G loss: 0.849956]\n",
      "epoch:28 step:22556[D loss: 0.453211, acc: 47.66%, op_acc: 39.84%] [G loss: 0.978362]\n",
      "epoch:28 step:22557[D loss: 0.434841, acc: 52.34%, op_acc: 42.19%] [G loss: 1.004155]\n",
      "epoch:28 step:22558[D loss: 0.444923, acc: 57.81%, op_acc: 32.81%] [G loss: 0.966139]\n",
      "epoch:28 step:22559[D loss: 0.405757, acc: 63.28%, op_acc: 39.84%] [G loss: 0.941521]\n",
      "epoch:28 step:22560[D loss: 0.479301, acc: 50.00%, op_acc: 39.84%] [G loss: 0.936613]\n",
      "epoch:28 step:22561[D loss: 0.423806, acc: 59.38%, op_acc: 40.62%] [G loss: 1.010183]\n",
      "epoch:28 step:22562[D loss: 0.457596, acc: 50.00%, op_acc: 41.41%] [G loss: 0.991197]\n",
      "epoch:28 step:22563[D loss: 0.441162, acc: 57.03%, op_acc: 32.81%] [G loss: 0.969928]\n",
      "epoch:28 step:22564[D loss: 0.416078, acc: 56.25%, op_acc: 42.97%] [G loss: 1.057502]\n",
      "epoch:28 step:22565[D loss: 0.376291, acc: 64.06%, op_acc: 40.62%] [G loss: 1.027599]\n",
      "epoch:28 step:22566[D loss: 0.485741, acc: 48.44%, op_acc: 37.50%] [G loss: 0.986890]\n",
      "epoch:28 step:22567[D loss: 0.420006, acc: 60.16%, op_acc: 39.84%] [G loss: 0.988564]\n",
      "epoch:28 step:22568[D loss: 0.428341, acc: 58.59%, op_acc: 38.28%] [G loss: 1.024052]\n",
      "epoch:28 step:22569[D loss: 0.417704, acc: 62.50%, op_acc: 37.50%] [G loss: 0.804941]\n",
      "epoch:28 step:22570[D loss: 0.398043, acc: 70.31%, op_acc: 38.28%] [G loss: 0.855284]\n",
      "epoch:28 step:22571[D loss: 0.422565, acc: 59.38%, op_acc: 41.41%] [G loss: 0.985112]\n",
      "epoch:28 step:22572[D loss: 0.399856, acc: 63.28%, op_acc: 41.41%] [G loss: 0.995729]\n",
      "epoch:28 step:22573[D loss: 0.435926, acc: 57.81%, op_acc: 36.72%] [G loss: 0.859089]\n",
      "epoch:28 step:22574[D loss: 0.435235, acc: 57.81%, op_acc: 43.75%] [G loss: 0.963622]\n",
      "epoch:28 step:22575[D loss: 0.429485, acc: 57.03%, op_acc: 35.16%] [G loss: 0.970434]\n",
      "epoch:28 step:22576[D loss: 0.402426, acc: 60.16%, op_acc: 44.53%] [G loss: 0.889625]\n",
      "epoch:28 step:22577[D loss: 0.391515, acc: 61.72%, op_acc: 42.97%] [G loss: 0.930526]\n",
      "epoch:28 step:22578[D loss: 0.368735, acc: 73.44%, op_acc: 43.75%] [G loss: 1.025558]\n",
      "epoch:28 step:22579[D loss: 0.387804, acc: 67.97%, op_acc: 39.84%] [G loss: 0.982324]\n",
      "epoch:28 step:22580[D loss: 0.399756, acc: 60.94%, op_acc: 40.62%] [G loss: 0.877729]\n",
      "epoch:28 step:22581[D loss: 0.402701, acc: 64.84%, op_acc: 39.06%] [G loss: 1.022495]\n",
      "epoch:28 step:22582[D loss: 0.408049, acc: 66.41%, op_acc: 40.62%] [G loss: 0.933809]\n",
      "epoch:28 step:22583[D loss: 0.399375, acc: 64.06%, op_acc: 39.84%] [G loss: 0.974339]\n",
      "epoch:28 step:22584[D loss: 0.437967, acc: 54.69%, op_acc: 42.19%] [G loss: 0.944398]\n",
      "epoch:28 step:22585[D loss: 0.398281, acc: 54.69%, op_acc: 41.41%] [G loss: 0.864675]\n",
      "epoch:28 step:22586[D loss: 0.432872, acc: 62.50%, op_acc: 42.97%] [G loss: 0.833514]\n",
      "epoch:28 step:22587[D loss: 0.378956, acc: 71.09%, op_acc: 44.53%] [G loss: 0.946578]\n",
      "epoch:28 step:22588[D loss: 0.401649, acc: 71.88%, op_acc: 39.06%] [G loss: 1.035591]\n",
      "epoch:28 step:22589[D loss: 0.453380, acc: 53.91%, op_acc: 39.84%] [G loss: 0.927689]\n",
      "epoch:28 step:22590[D loss: 0.404246, acc: 58.59%, op_acc: 39.06%] [G loss: 0.821223]\n",
      "epoch:28 step:22591[D loss: 0.412149, acc: 62.50%, op_acc: 40.62%] [G loss: 1.034347]\n",
      "epoch:28 step:22592[D loss: 0.444386, acc: 62.50%, op_acc: 32.81%] [G loss: 0.862653]\n",
      "epoch:28 step:22593[D loss: 0.401513, acc: 61.72%, op_acc: 45.31%] [G loss: 0.916678]\n",
      "epoch:28 step:22594[D loss: 0.387033, acc: 64.06%, op_acc: 46.88%] [G loss: 0.892098]\n",
      "epoch:28 step:22595[D loss: 0.442389, acc: 62.50%, op_acc: 36.72%] [G loss: 0.901091]\n",
      "epoch:28 step:22596[D loss: 0.411509, acc: 61.72%, op_acc: 39.84%] [G loss: 0.878555]\n",
      "epoch:28 step:22597[D loss: 0.361822, acc: 70.31%, op_acc: 43.75%] [G loss: 0.850959]\n",
      "epoch:28 step:22598[D loss: 0.419971, acc: 58.59%, op_acc: 41.41%] [G loss: 1.096419]\n",
      "epoch:28 step:22599[D loss: 0.386366, acc: 67.97%, op_acc: 45.31%] [G loss: 0.929785]\n",
      "epoch:28 step:22600[D loss: 0.431684, acc: 66.41%, op_acc: 39.06%] [G loss: 1.028122]\n",
      "epoch:28 step:22601[D loss: 0.412252, acc: 60.94%, op_acc: 41.41%] [G loss: 0.960572]\n",
      "epoch:28 step:22602[D loss: 0.387671, acc: 61.72%, op_acc: 49.22%] [G loss: 1.049229]\n",
      "epoch:28 step:22603[D loss: 0.409586, acc: 64.84%, op_acc: 35.94%] [G loss: 0.915319]\n",
      "epoch:28 step:22604[D loss: 0.408532, acc: 63.28%, op_acc: 42.19%] [G loss: 0.878851]\n",
      "epoch:28 step:22605[D loss: 0.410859, acc: 61.72%, op_acc: 41.41%] [G loss: 0.767615]\n",
      "epoch:28 step:22606[D loss: 0.408871, acc: 67.19%, op_acc: 42.19%] [G loss: 0.818022]\n",
      "epoch:28 step:22607[D loss: 0.437135, acc: 51.56%, op_acc: 46.09%] [G loss: 0.758655]\n",
      "epoch:28 step:22608[D loss: 0.423879, acc: 60.94%, op_acc: 44.53%] [G loss: 0.798264]\n",
      "epoch:28 step:22609[D loss: 0.405356, acc: 62.50%, op_acc: 42.19%] [G loss: 0.924295]\n",
      "epoch:28 step:22610[D loss: 0.422459, acc: 64.84%, op_acc: 42.97%] [G loss: 0.990650]\n",
      "epoch:28 step:22611[D loss: 0.418680, acc: 56.25%, op_acc: 40.62%] [G loss: 0.807426]\n",
      "epoch:28 step:22612[D loss: 0.384617, acc: 63.28%, op_acc: 49.22%] [G loss: 0.973388]\n",
      "epoch:28 step:22613[D loss: 0.403441, acc: 60.94%, op_acc: 43.75%] [G loss: 1.075069]\n",
      "epoch:28 step:22614[D loss: 0.424560, acc: 64.06%, op_acc: 41.41%] [G loss: 0.932029]\n",
      "epoch:28 step:22615[D loss: 0.406147, acc: 63.28%, op_acc: 43.75%] [G loss: 1.021114]\n",
      "epoch:28 step:22616[D loss: 0.444873, acc: 53.12%, op_acc: 39.06%] [G loss: 0.845857]\n",
      "epoch:28 step:22617[D loss: 0.423182, acc: 53.91%, op_acc: 43.75%] [G loss: 0.918290]\n",
      "epoch:28 step:22618[D loss: 0.405675, acc: 60.94%, op_acc: 40.62%] [G loss: 0.971346]\n",
      "epoch:28 step:22619[D loss: 0.449094, acc: 60.16%, op_acc: 34.38%] [G loss: 1.182905]\n",
      "epoch:28 step:22620[D loss: 0.380338, acc: 71.09%, op_acc: 45.31%] [G loss: 0.752977]\n",
      "epoch:28 step:22621[D loss: 0.372866, acc: 67.19%, op_acc: 46.09%] [G loss: 0.889737]\n",
      "epoch:28 step:22622[D loss: 0.379555, acc: 67.97%, op_acc: 43.75%] [G loss: 0.917477]\n",
      "epoch:28 step:22623[D loss: 0.394581, acc: 72.66%, op_acc: 42.19%] [G loss: 0.785712]\n",
      "epoch:28 step:22624[D loss: 0.393848, acc: 63.28%, op_acc: 42.19%] [G loss: 0.911948]\n",
      "epoch:28 step:22625[D loss: 0.389253, acc: 66.41%, op_acc: 44.53%] [G loss: 0.991016]\n",
      "epoch:28 step:22626[D loss: 0.410807, acc: 55.47%, op_acc: 44.53%] [G loss: 0.847916]\n",
      "epoch:28 step:22627[D loss: 0.412995, acc: 64.06%, op_acc: 42.97%] [G loss: 1.038821]\n",
      "epoch:28 step:22628[D loss: 0.411150, acc: 57.81%, op_acc: 39.84%] [G loss: 1.061666]\n",
      "epoch:28 step:22629[D loss: 0.415926, acc: 47.66%, op_acc: 46.09%] [G loss: 0.994093]\n",
      "epoch:28 step:22630[D loss: 0.396561, acc: 62.50%, op_acc: 42.19%] [G loss: 1.064579]\n",
      "epoch:28 step:22631[D loss: 0.432191, acc: 56.25%, op_acc: 42.97%] [G loss: 0.760893]\n",
      "epoch:28 step:22632[D loss: 0.389021, acc: 64.06%, op_acc: 39.06%] [G loss: 0.813663]\n",
      "epoch:28 step:22633[D loss: 0.371692, acc: 68.75%, op_acc: 47.66%] [G loss: 1.069499]\n",
      "epoch:28 step:22634[D loss: 0.432054, acc: 61.72%, op_acc: 34.38%] [G loss: 0.794966]\n",
      "epoch:28 step:22635[D loss: 0.418051, acc: 58.59%, op_acc: 42.97%] [G loss: 1.031726]\n",
      "epoch:28 step:22636[D loss: 0.429861, acc: 57.81%, op_acc: 34.38%] [G loss: 0.914285]\n",
      "epoch:28 step:22637[D loss: 0.384829, acc: 65.62%, op_acc: 44.53%] [G loss: 0.778986]\n",
      "epoch:28 step:22638[D loss: 0.435403, acc: 57.03%, op_acc: 39.84%] [G loss: 0.792131]\n",
      "epoch:28 step:22639[D loss: 0.468558, acc: 52.34%, op_acc: 34.38%] [G loss: 0.894234]\n",
      "epoch:28 step:22640[D loss: 0.434343, acc: 61.72%, op_acc: 38.28%] [G loss: 0.775869]\n",
      "epoch:28 step:22641[D loss: 0.393908, acc: 71.09%, op_acc: 39.06%] [G loss: 1.107525]\n",
      "epoch:28 step:22642[D loss: 0.386047, acc: 68.75%, op_acc: 42.97%] [G loss: 1.016589]\n",
      "epoch:28 step:22643[D loss: 0.388630, acc: 69.53%, op_acc: 37.50%] [G loss: 0.958739]\n",
      "epoch:28 step:22644[D loss: 0.418096, acc: 66.41%, op_acc: 40.62%] [G loss: 0.927095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:22645[D loss: 0.410330, acc: 67.97%, op_acc: 38.28%] [G loss: 0.882975]\n",
      "epoch:28 step:22646[D loss: 0.384430, acc: 68.75%, op_acc: 46.88%] [G loss: 0.940437]\n",
      "epoch:28 step:22647[D loss: 0.412826, acc: 61.72%, op_acc: 35.94%] [G loss: 0.767532]\n",
      "epoch:28 step:22648[D loss: 0.389746, acc: 68.75%, op_acc: 42.19%] [G loss: 0.952901]\n",
      "epoch:28 step:22649[D loss: 0.421660, acc: 58.59%, op_acc: 42.97%] [G loss: 0.871321]\n",
      "epoch:29 step:22650[D loss: 0.380955, acc: 69.53%, op_acc: 41.41%] [G loss: 0.810125]\n",
      "epoch:29 step:22651[D loss: 0.409152, acc: 61.72%, op_acc: 42.97%] [G loss: 0.826434]\n",
      "epoch:29 step:22652[D loss: 0.438442, acc: 57.03%, op_acc: 42.97%] [G loss: 0.878829]\n",
      "epoch:29 step:22653[D loss: 0.373032, acc: 65.62%, op_acc: 44.53%] [G loss: 0.905322]\n",
      "epoch:29 step:22654[D loss: 0.405202, acc: 57.81%, op_acc: 42.97%] [G loss: 0.846599]\n",
      "epoch:29 step:22655[D loss: 0.423834, acc: 57.03%, op_acc: 43.75%] [G loss: 0.851668]\n",
      "epoch:29 step:22656[D loss: 0.388744, acc: 66.41%, op_acc: 42.19%] [G loss: 0.859468]\n",
      "epoch:29 step:22657[D loss: 0.405481, acc: 60.16%, op_acc: 39.06%] [G loss: 0.947062]\n",
      "epoch:29 step:22658[D loss: 0.380504, acc: 68.75%, op_acc: 39.84%] [G loss: 0.911471]\n",
      "epoch:29 step:22659[D loss: 0.429664, acc: 60.16%, op_acc: 38.28%] [G loss: 0.993648]\n",
      "epoch:29 step:22660[D loss: 0.415791, acc: 64.84%, op_acc: 43.75%] [G loss: 0.930990]\n",
      "epoch:29 step:22661[D loss: 0.418353, acc: 62.50%, op_acc: 36.72%] [G loss: 0.837708]\n",
      "epoch:29 step:22662[D loss: 0.384798, acc: 65.62%, op_acc: 40.62%] [G loss: 0.973029]\n",
      "epoch:29 step:22663[D loss: 0.428292, acc: 57.03%, op_acc: 46.09%] [G loss: 1.097971]\n",
      "epoch:29 step:22664[D loss: 0.375179, acc: 67.97%, op_acc: 46.09%] [G loss: 0.908124]\n",
      "epoch:29 step:22665[D loss: 0.374153, acc: 68.75%, op_acc: 46.88%] [G loss: 0.966442]\n",
      "epoch:29 step:22666[D loss: 0.449641, acc: 50.78%, op_acc: 46.09%] [G loss: 0.979440]\n",
      "epoch:29 step:22667[D loss: 0.433244, acc: 54.69%, op_acc: 46.09%] [G loss: 0.853034]\n",
      "epoch:29 step:22668[D loss: 0.379018, acc: 75.78%, op_acc: 40.62%] [G loss: 0.928848]\n",
      "epoch:29 step:22669[D loss: 0.384630, acc: 64.84%, op_acc: 39.84%] [G loss: 0.919816]\n",
      "epoch:29 step:22670[D loss: 0.448579, acc: 54.69%, op_acc: 37.50%] [G loss: 0.998866]\n",
      "epoch:29 step:22671[D loss: 0.439696, acc: 58.59%, op_acc: 40.62%] [G loss: 0.980770]\n",
      "epoch:29 step:22672[D loss: 0.386136, acc: 66.41%, op_acc: 44.53%] [G loss: 1.012661]\n",
      "epoch:29 step:22673[D loss: 0.369304, acc: 68.75%, op_acc: 42.19%] [G loss: 1.007558]\n",
      "epoch:29 step:22674[D loss: 0.392884, acc: 71.88%, op_acc: 43.75%] [G loss: 1.019210]\n",
      "epoch:29 step:22675[D loss: 0.321837, acc: 78.91%, op_acc: 50.78%] [G loss: 1.043372]\n",
      "epoch:29 step:22676[D loss: 0.406569, acc: 67.19%, op_acc: 42.97%] [G loss: 1.085792]\n",
      "epoch:29 step:22677[D loss: 0.385075, acc: 71.09%, op_acc: 42.19%] [G loss: 1.116901]\n",
      "epoch:29 step:22678[D loss: 0.365753, acc: 71.88%, op_acc: 42.19%] [G loss: 1.080824]\n",
      "epoch:29 step:22679[D loss: 0.380814, acc: 62.50%, op_acc: 46.88%] [G loss: 1.030570]\n",
      "epoch:29 step:22680[D loss: 0.393889, acc: 69.53%, op_acc: 39.84%] [G loss: 1.152853]\n",
      "epoch:29 step:22681[D loss: 0.369438, acc: 72.66%, op_acc: 44.53%] [G loss: 1.087059]\n",
      "epoch:29 step:22682[D loss: 0.356079, acc: 75.00%, op_acc: 44.53%] [G loss: 1.064192]\n",
      "epoch:29 step:22683[D loss: 0.383979, acc: 66.41%, op_acc: 46.88%] [G loss: 0.833058]\n",
      "epoch:29 step:22684[D loss: 0.397395, acc: 69.53%, op_acc: 44.53%] [G loss: 0.813728]\n",
      "epoch:29 step:22685[D loss: 0.382387, acc: 61.72%, op_acc: 39.84%] [G loss: 1.140941]\n",
      "epoch:29 step:22686[D loss: 0.375048, acc: 73.44%, op_acc: 39.84%] [G loss: 0.931960]\n",
      "epoch:29 step:22687[D loss: 0.451764, acc: 53.91%, op_acc: 43.75%] [G loss: 1.204079]\n",
      "epoch:29 step:22688[D loss: 0.360412, acc: 67.19%, op_acc: 41.41%] [G loss: 1.057042]\n",
      "epoch:29 step:22689[D loss: 0.459803, acc: 60.16%, op_acc: 32.81%] [G loss: 0.751185]\n",
      "epoch:29 step:22690[D loss: 0.407254, acc: 61.72%, op_acc: 42.19%] [G loss: 1.134032]\n",
      "epoch:29 step:22691[D loss: 0.401435, acc: 54.69%, op_acc: 46.09%] [G loss: 1.161767]\n",
      "epoch:29 step:22692[D loss: 0.416809, acc: 57.03%, op_acc: 44.53%] [G loss: 0.742777]\n",
      "epoch:29 step:22693[D loss: 0.405073, acc: 60.16%, op_acc: 45.31%] [G loss: 0.897352]\n",
      "epoch:29 step:22694[D loss: 0.432261, acc: 60.16%, op_acc: 34.38%] [G loss: 0.803862]\n",
      "epoch:29 step:22695[D loss: 0.434849, acc: 55.47%, op_acc: 42.19%] [G loss: 0.884757]\n",
      "epoch:29 step:22696[D loss: 0.432384, acc: 54.69%, op_acc: 41.41%] [G loss: 0.950170]\n",
      "epoch:29 step:22697[D loss: 0.462378, acc: 60.94%, op_acc: 39.84%] [G loss: 0.931085]\n",
      "epoch:29 step:22698[D loss: 0.406033, acc: 64.84%, op_acc: 35.94%] [G loss: 1.028308]\n",
      "epoch:29 step:22699[D loss: 0.455628, acc: 57.03%, op_acc: 43.75%] [G loss: 0.934923]\n",
      "epoch:29 step:22700[D loss: 0.399492, acc: 71.88%, op_acc: 43.75%] [G loss: 0.733841]\n",
      "epoch:29 step:22701[D loss: 0.435616, acc: 57.81%, op_acc: 38.28%] [G loss: 1.052425]\n",
      "epoch:29 step:22702[D loss: 0.472251, acc: 53.12%, op_acc: 38.28%] [G loss: 0.919249]\n",
      "epoch:29 step:22703[D loss: 0.468544, acc: 54.69%, op_acc: 36.72%] [G loss: 0.901450]\n",
      "epoch:29 step:22704[D loss: 0.413499, acc: 55.47%, op_acc: 35.94%] [G loss: 0.862310]\n",
      "epoch:29 step:22705[D loss: 0.419348, acc: 66.41%, op_acc: 44.53%] [G loss: 1.064754]\n",
      "epoch:29 step:22706[D loss: 0.435635, acc: 58.59%, op_acc: 41.41%] [G loss: 0.980672]\n",
      "epoch:29 step:22707[D loss: 0.413341, acc: 64.06%, op_acc: 48.44%] [G loss: 1.071530]\n",
      "epoch:29 step:22708[D loss: 0.418366, acc: 55.47%, op_acc: 45.31%] [G loss: 0.969478]\n",
      "epoch:29 step:22709[D loss: 0.405471, acc: 60.94%, op_acc: 39.84%] [G loss: 1.017716]\n",
      "epoch:29 step:22710[D loss: 0.430497, acc: 57.81%, op_acc: 41.41%] [G loss: 0.950277]\n",
      "epoch:29 step:22711[D loss: 0.405278, acc: 60.94%, op_acc: 37.50%] [G loss: 0.847665]\n",
      "epoch:29 step:22712[D loss: 0.458363, acc: 53.91%, op_acc: 38.28%] [G loss: 1.039313]\n",
      "epoch:29 step:22713[D loss: 0.404380, acc: 57.81%, op_acc: 42.19%] [G loss: 0.954301]\n",
      "epoch:29 step:22714[D loss: 0.399702, acc: 65.62%, op_acc: 42.19%] [G loss: 0.942573]\n",
      "epoch:29 step:22715[D loss: 0.432076, acc: 60.94%, op_acc: 38.28%] [G loss: 0.904521]\n",
      "epoch:29 step:22716[D loss: 0.384193, acc: 67.19%, op_acc: 45.31%] [G loss: 0.884759]\n",
      "epoch:29 step:22717[D loss: 0.405718, acc: 57.81%, op_acc: 46.09%] [G loss: 1.038787]\n",
      "epoch:29 step:22718[D loss: 0.377961, acc: 71.09%, op_acc: 53.12%] [G loss: 0.997047]\n",
      "epoch:29 step:22719[D loss: 0.424529, acc: 60.16%, op_acc: 36.72%] [G loss: 0.828111]\n",
      "epoch:29 step:22720[D loss: 0.406641, acc: 65.62%, op_acc: 37.50%] [G loss: 0.813657]\n",
      "epoch:29 step:22721[D loss: 0.402630, acc: 63.28%, op_acc: 40.62%] [G loss: 0.937028]\n",
      "epoch:29 step:22722[D loss: 0.410686, acc: 65.62%, op_acc: 35.94%] [G loss: 0.996610]\n",
      "epoch:29 step:22723[D loss: 0.377020, acc: 69.53%, op_acc: 44.53%] [G loss: 0.810816]\n",
      "epoch:29 step:22724[D loss: 0.414927, acc: 57.81%, op_acc: 39.84%] [G loss: 0.966698]\n",
      "epoch:29 step:22725[D loss: 0.449377, acc: 56.25%, op_acc: 41.41%] [G loss: 0.912340]\n",
      "epoch:29 step:22726[D loss: 0.410839, acc: 60.16%, op_acc: 42.97%] [G loss: 0.936954]\n",
      "epoch:29 step:22727[D loss: 0.433239, acc: 64.06%, op_acc: 32.03%] [G loss: 0.936284]\n",
      "epoch:29 step:22728[D loss: 0.422981, acc: 64.06%, op_acc: 39.06%] [G loss: 1.021432]\n",
      "epoch:29 step:22729[D loss: 0.425618, acc: 60.94%, op_acc: 35.16%] [G loss: 1.027243]\n",
      "epoch:29 step:22730[D loss: 0.423133, acc: 60.94%, op_acc: 32.81%] [G loss: 0.903060]\n",
      "epoch:29 step:22731[D loss: 0.421032, acc: 61.72%, op_acc: 39.84%] [G loss: 0.810370]\n",
      "epoch:29 step:22732[D loss: 0.429452, acc: 60.94%, op_acc: 33.59%] [G loss: 0.789741]\n",
      "epoch:29 step:22733[D loss: 0.392833, acc: 64.06%, op_acc: 40.62%] [G loss: 0.927816]\n",
      "epoch:29 step:22734[D loss: 0.397669, acc: 67.97%, op_acc: 33.59%] [G loss: 0.966617]\n",
      "epoch:29 step:22735[D loss: 0.409752, acc: 60.16%, op_acc: 40.62%] [G loss: 1.007180]\n",
      "epoch:29 step:22736[D loss: 0.397407, acc: 66.41%, op_acc: 41.41%] [G loss: 0.806040]\n",
      "epoch:29 step:22737[D loss: 0.432543, acc: 59.38%, op_acc: 46.09%] [G loss: 0.790047]\n",
      "epoch:29 step:22738[D loss: 0.419476, acc: 66.41%, op_acc: 37.50%] [G loss: 0.815411]\n",
      "epoch:29 step:22739[D loss: 0.421229, acc: 55.47%, op_acc: 50.00%] [G loss: 0.776463]\n",
      "epoch:29 step:22740[D loss: 0.407772, acc: 63.28%, op_acc: 43.75%] [G loss: 0.984532]\n",
      "epoch:29 step:22741[D loss: 0.416869, acc: 57.81%, op_acc: 42.19%] [G loss: 0.959589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22742[D loss: 0.389207, acc: 67.19%, op_acc: 38.28%] [G loss: 0.975514]\n",
      "epoch:29 step:22743[D loss: 0.421014, acc: 57.03%, op_acc: 40.62%] [G loss: 1.041898]\n",
      "epoch:29 step:22744[D loss: 0.409175, acc: 66.41%, op_acc: 39.06%] [G loss: 0.897049]\n",
      "epoch:29 step:22745[D loss: 0.418618, acc: 61.72%, op_acc: 33.59%] [G loss: 0.951678]\n",
      "epoch:29 step:22746[D loss: 0.384304, acc: 63.28%, op_acc: 46.09%] [G loss: 0.969813]\n",
      "epoch:29 step:22747[D loss: 0.401679, acc: 65.62%, op_acc: 39.84%] [G loss: 0.910319]\n",
      "epoch:29 step:22748[D loss: 0.420087, acc: 53.91%, op_acc: 40.62%] [G loss: 0.846760]\n",
      "epoch:29 step:22749[D loss: 0.396070, acc: 57.81%, op_acc: 46.09%] [G loss: 0.922135]\n",
      "epoch:29 step:22750[D loss: 0.413581, acc: 65.62%, op_acc: 36.72%] [G loss: 0.769872]\n",
      "epoch:29 step:22751[D loss: 0.426175, acc: 53.91%, op_acc: 39.84%] [G loss: 0.845754]\n",
      "epoch:29 step:22752[D loss: 0.463937, acc: 50.00%, op_acc: 37.50%] [G loss: 0.991311]\n",
      "epoch:29 step:22753[D loss: 0.423412, acc: 63.28%, op_acc: 40.62%] [G loss: 0.923480]\n",
      "epoch:29 step:22754[D loss: 0.414713, acc: 59.38%, op_acc: 45.31%] [G loss: 0.772017]\n",
      "epoch:29 step:22755[D loss: 0.390032, acc: 64.06%, op_acc: 39.84%] [G loss: 0.920309]\n",
      "epoch:29 step:22756[D loss: 0.400445, acc: 65.62%, op_acc: 46.88%] [G loss: 0.956733]\n",
      "epoch:29 step:22757[D loss: 0.423397, acc: 56.25%, op_acc: 40.62%] [G loss: 0.938248]\n",
      "epoch:29 step:22758[D loss: 0.389958, acc: 61.72%, op_acc: 46.88%] [G loss: 0.938446]\n",
      "epoch:29 step:22759[D loss: 0.397189, acc: 64.06%, op_acc: 39.06%] [G loss: 0.908247]\n",
      "epoch:29 step:22760[D loss: 0.424038, acc: 65.62%, op_acc: 35.16%] [G loss: 1.018018]\n",
      "epoch:29 step:22761[D loss: 0.384193, acc: 66.41%, op_acc: 44.53%] [G loss: 1.038511]\n",
      "epoch:29 step:22762[D loss: 0.426919, acc: 59.38%, op_acc: 36.72%] [G loss: 1.107671]\n",
      "epoch:29 step:22763[D loss: 0.439469, acc: 58.59%, op_acc: 41.41%] [G loss: 0.938640]\n",
      "epoch:29 step:22764[D loss: 0.403788, acc: 60.94%, op_acc: 46.09%] [G loss: 0.913150]\n",
      "epoch:29 step:22765[D loss: 0.434642, acc: 58.59%, op_acc: 37.50%] [G loss: 0.939342]\n",
      "epoch:29 step:22766[D loss: 0.384654, acc: 62.50%, op_acc: 46.88%] [G loss: 0.903303]\n",
      "epoch:29 step:22767[D loss: 0.450909, acc: 51.56%, op_acc: 39.84%] [G loss: 0.916670]\n",
      "epoch:29 step:22768[D loss: 0.380983, acc: 71.09%, op_acc: 40.62%] [G loss: 1.037813]\n",
      "epoch:29 step:22769[D loss: 0.376552, acc: 69.53%, op_acc: 42.97%] [G loss: 1.043106]\n",
      "epoch:29 step:22770[D loss: 0.399110, acc: 69.53%, op_acc: 35.94%] [G loss: 1.078701]\n",
      "epoch:29 step:22771[D loss: 0.384501, acc: 73.44%, op_acc: 39.84%] [G loss: 0.969462]\n",
      "epoch:29 step:22772[D loss: 0.431959, acc: 56.25%, op_acc: 36.72%] [G loss: 0.862635]\n",
      "epoch:29 step:22773[D loss: 0.414666, acc: 57.81%, op_acc: 42.97%] [G loss: 1.112053]\n",
      "epoch:29 step:22774[D loss: 0.426702, acc: 64.84%, op_acc: 36.72%] [G loss: 0.891597]\n",
      "epoch:29 step:22775[D loss: 0.410950, acc: 66.41%, op_acc: 39.84%] [G loss: 0.773223]\n",
      "epoch:29 step:22776[D loss: 0.390493, acc: 65.62%, op_acc: 41.41%] [G loss: 0.863988]\n",
      "epoch:29 step:22777[D loss: 0.406180, acc: 67.19%, op_acc: 37.50%] [G loss: 0.842294]\n",
      "epoch:29 step:22778[D loss: 0.436671, acc: 54.69%, op_acc: 39.84%] [G loss: 0.965940]\n",
      "epoch:29 step:22779[D loss: 0.407921, acc: 60.16%, op_acc: 40.62%] [G loss: 0.865860]\n",
      "epoch:29 step:22780[D loss: 0.398259, acc: 60.94%, op_acc: 44.53%] [G loss: 1.023773]\n",
      "epoch:29 step:22781[D loss: 0.379506, acc: 67.97%, op_acc: 48.44%] [G loss: 1.032813]\n",
      "epoch:29 step:22782[D loss: 0.446612, acc: 55.47%, op_acc: 37.50%] [G loss: 0.985164]\n",
      "epoch:29 step:22783[D loss: 0.410861, acc: 64.06%, op_acc: 35.94%] [G loss: 0.840049]\n",
      "epoch:29 step:22784[D loss: 0.429631, acc: 60.16%, op_acc: 40.62%] [G loss: 0.925632]\n",
      "epoch:29 step:22785[D loss: 0.363948, acc: 71.09%, op_acc: 44.53%] [G loss: 1.003125]\n",
      "epoch:29 step:22786[D loss: 0.436918, acc: 53.91%, op_acc: 39.06%] [G loss: 0.888543]\n",
      "epoch:29 step:22787[D loss: 0.436800, acc: 59.38%, op_acc: 35.16%] [G loss: 1.044439]\n",
      "epoch:29 step:22788[D loss: 0.384326, acc: 64.06%, op_acc: 44.53%] [G loss: 0.921380]\n",
      "epoch:29 step:22789[D loss: 0.439232, acc: 59.38%, op_acc: 39.84%] [G loss: 0.969968]\n",
      "epoch:29 step:22790[D loss: 0.429615, acc: 56.25%, op_acc: 36.72%] [G loss: 0.914300]\n",
      "epoch:29 step:22791[D loss: 0.377944, acc: 67.97%, op_acc: 45.31%] [G loss: 0.916258]\n",
      "epoch:29 step:22792[D loss: 0.459096, acc: 51.56%, op_acc: 39.06%] [G loss: 1.002609]\n",
      "epoch:29 step:22793[D loss: 0.450783, acc: 57.03%, op_acc: 39.06%] [G loss: 0.922686]\n",
      "epoch:29 step:22794[D loss: 0.410232, acc: 57.81%, op_acc: 46.09%] [G loss: 0.957513]\n",
      "epoch:29 step:22795[D loss: 0.416638, acc: 64.84%, op_acc: 41.41%] [G loss: 0.868343]\n",
      "epoch:29 step:22796[D loss: 0.392249, acc: 64.06%, op_acc: 40.62%] [G loss: 0.938704]\n",
      "epoch:29 step:22797[D loss: 0.465564, acc: 51.56%, op_acc: 34.38%] [G loss: 0.971693]\n",
      "epoch:29 step:22798[D loss: 0.372597, acc: 69.53%, op_acc: 45.31%] [G loss: 0.896627]\n",
      "epoch:29 step:22799[D loss: 0.396653, acc: 65.62%, op_acc: 43.75%] [G loss: 0.998095]\n",
      "epoch:29 step:22800[D loss: 0.382337, acc: 62.50%, op_acc: 46.09%] [G loss: 0.830745]\n",
      "epoch:29 step:22801[D loss: 0.400304, acc: 60.16%, op_acc: 43.75%] [G loss: 0.819776]\n",
      "epoch:29 step:22802[D loss: 0.427882, acc: 60.16%, op_acc: 33.59%] [G loss: 0.880414]\n",
      "epoch:29 step:22803[D loss: 0.392146, acc: 67.97%, op_acc: 43.75%] [G loss: 1.030357]\n",
      "epoch:29 step:22804[D loss: 0.424598, acc: 59.38%, op_acc: 35.94%] [G loss: 0.916213]\n",
      "epoch:29 step:22805[D loss: 0.413992, acc: 58.59%, op_acc: 43.75%] [G loss: 0.772363]\n",
      "epoch:29 step:22806[D loss: 0.397596, acc: 59.38%, op_acc: 45.31%] [G loss: 1.090290]\n",
      "epoch:29 step:22807[D loss: 0.362740, acc: 70.31%, op_acc: 46.88%] [G loss: 0.902859]\n",
      "epoch:29 step:22808[D loss: 0.455902, acc: 58.59%, op_acc: 35.16%] [G loss: 0.736320]\n",
      "epoch:29 step:22809[D loss: 0.423779, acc: 59.38%, op_acc: 35.94%] [G loss: 0.955875]\n",
      "epoch:29 step:22810[D loss: 0.419490, acc: 65.62%, op_acc: 39.84%] [G loss: 1.038528]\n",
      "epoch:29 step:22811[D loss: 0.398570, acc: 63.28%, op_acc: 48.44%] [G loss: 0.890131]\n",
      "epoch:29 step:22812[D loss: 0.430993, acc: 64.06%, op_acc: 43.75%] [G loss: 1.129319]\n",
      "epoch:29 step:22813[D loss: 0.425034, acc: 64.84%, op_acc: 37.50%] [G loss: 1.013297]\n",
      "epoch:29 step:22814[D loss: 0.376563, acc: 67.97%, op_acc: 47.66%] [G loss: 0.792569]\n",
      "epoch:29 step:22815[D loss: 0.436024, acc: 64.06%, op_acc: 42.19%] [G loss: 0.803901]\n",
      "epoch:29 step:22816[D loss: 0.434491, acc: 64.06%, op_acc: 39.06%] [G loss: 1.033462]\n",
      "epoch:29 step:22817[D loss: 0.410714, acc: 59.38%, op_acc: 40.62%] [G loss: 0.785742]\n",
      "epoch:29 step:22818[D loss: 0.415391, acc: 66.41%, op_acc: 44.53%] [G loss: 0.919428]\n",
      "epoch:29 step:22819[D loss: 0.425723, acc: 56.25%, op_acc: 39.84%] [G loss: 0.945475]\n",
      "epoch:29 step:22820[D loss: 0.435536, acc: 57.03%, op_acc: 35.16%] [G loss: 0.826331]\n",
      "epoch:29 step:22821[D loss: 0.387718, acc: 67.97%, op_acc: 42.19%] [G loss: 0.972608]\n",
      "epoch:29 step:22822[D loss: 0.386354, acc: 68.75%, op_acc: 45.31%] [G loss: 0.985977]\n",
      "epoch:29 step:22823[D loss: 0.448228, acc: 57.03%, op_acc: 39.06%] [G loss: 0.803295]\n",
      "epoch:29 step:22824[D loss: 0.411357, acc: 61.72%, op_acc: 43.75%] [G loss: 0.881294]\n",
      "epoch:29 step:22825[D loss: 0.382829, acc: 70.31%, op_acc: 45.31%] [G loss: 0.887876]\n",
      "epoch:29 step:22826[D loss: 0.352091, acc: 75.00%, op_acc: 43.75%] [G loss: 0.969862]\n",
      "epoch:29 step:22827[D loss: 0.464720, acc: 59.38%, op_acc: 33.59%] [G loss: 0.912598]\n",
      "epoch:29 step:22828[D loss: 0.400178, acc: 62.50%, op_acc: 42.19%] [G loss: 0.895510]\n",
      "epoch:29 step:22829[D loss: 0.424434, acc: 61.72%, op_acc: 35.94%] [G loss: 1.007244]\n",
      "epoch:29 step:22830[D loss: 0.403769, acc: 60.94%, op_acc: 40.62%] [G loss: 0.903418]\n",
      "epoch:29 step:22831[D loss: 0.382473, acc: 64.06%, op_acc: 43.75%] [G loss: 1.018358]\n",
      "epoch:29 step:22832[D loss: 0.366971, acc: 71.09%, op_acc: 45.31%] [G loss: 0.919716]\n",
      "epoch:29 step:22833[D loss: 0.379110, acc: 68.75%, op_acc: 39.84%] [G loss: 0.988954]\n",
      "epoch:29 step:22834[D loss: 0.399887, acc: 64.84%, op_acc: 37.50%] [G loss: 1.043005]\n",
      "epoch:29 step:22835[D loss: 0.393371, acc: 62.50%, op_acc: 46.09%] [G loss: 0.997675]\n",
      "epoch:29 step:22836[D loss: 0.413533, acc: 60.16%, op_acc: 42.19%] [G loss: 0.988785]\n",
      "epoch:29 step:22837[D loss: 0.424652, acc: 60.94%, op_acc: 37.50%] [G loss: 0.913429]\n",
      "epoch:29 step:22838[D loss: 0.399470, acc: 64.06%, op_acc: 41.41%] [G loss: 0.961819]\n",
      "epoch:29 step:22839[D loss: 0.451479, acc: 55.47%, op_acc: 39.84%] [G loss: 0.889497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22840[D loss: 0.405597, acc: 64.06%, op_acc: 37.50%] [G loss: 0.813912]\n",
      "epoch:29 step:22841[D loss: 0.388844, acc: 60.94%, op_acc: 42.97%] [G loss: 0.962053]\n",
      "epoch:29 step:22842[D loss: 0.438207, acc: 63.28%, op_acc: 39.84%] [G loss: 0.762273]\n",
      "epoch:29 step:22843[D loss: 0.464949, acc: 49.22%, op_acc: 38.28%] [G loss: 0.878309]\n",
      "epoch:29 step:22844[D loss: 0.446595, acc: 56.25%, op_acc: 38.28%] [G loss: 0.837605]\n",
      "epoch:29 step:22845[D loss: 0.421187, acc: 56.25%, op_acc: 41.41%] [G loss: 0.906286]\n",
      "epoch:29 step:22846[D loss: 0.399802, acc: 66.41%, op_acc: 41.41%] [G loss: 0.918874]\n",
      "epoch:29 step:22847[D loss: 0.415909, acc: 62.50%, op_acc: 40.62%] [G loss: 0.858738]\n",
      "epoch:29 step:22848[D loss: 0.435810, acc: 60.16%, op_acc: 35.94%] [G loss: 1.101745]\n",
      "epoch:29 step:22849[D loss: 0.420621, acc: 60.16%, op_acc: 41.41%] [G loss: 0.916199]\n",
      "epoch:29 step:22850[D loss: 0.398434, acc: 66.41%, op_acc: 45.31%] [G loss: 0.862539]\n",
      "epoch:29 step:22851[D loss: 0.402689, acc: 60.94%, op_acc: 42.97%] [G loss: 0.829222]\n",
      "epoch:29 step:22852[D loss: 0.431146, acc: 60.16%, op_acc: 40.62%] [G loss: 0.725072]\n",
      "epoch:29 step:22853[D loss: 0.438446, acc: 56.25%, op_acc: 39.06%] [G loss: 0.939339]\n",
      "epoch:29 step:22854[D loss: 0.405396, acc: 65.62%, op_acc: 35.94%] [G loss: 0.913483]\n",
      "epoch:29 step:22855[D loss: 0.409727, acc: 63.28%, op_acc: 36.72%] [G loss: 0.942961]\n",
      "epoch:29 step:22856[D loss: 0.425920, acc: 60.16%, op_acc: 45.31%] [G loss: 0.962858]\n",
      "epoch:29 step:22857[D loss: 0.391904, acc: 71.88%, op_acc: 39.84%] [G loss: 0.989984]\n",
      "epoch:29 step:22858[D loss: 0.393238, acc: 59.38%, op_acc: 40.62%] [G loss: 1.056459]\n",
      "epoch:29 step:22859[D loss: 0.456276, acc: 57.81%, op_acc: 39.84%] [G loss: 0.931447]\n",
      "epoch:29 step:22860[D loss: 0.354915, acc: 74.22%, op_acc: 46.09%] [G loss: 1.020957]\n",
      "epoch:29 step:22861[D loss: 0.397945, acc: 66.41%, op_acc: 40.62%] [G loss: 0.815935]\n",
      "epoch:29 step:22862[D loss: 0.420851, acc: 57.03%, op_acc: 42.97%] [G loss: 1.023096]\n",
      "epoch:29 step:22863[D loss: 0.414781, acc: 62.50%, op_acc: 39.06%] [G loss: 1.090469]\n",
      "epoch:29 step:22864[D loss: 0.445167, acc: 55.47%, op_acc: 35.16%] [G loss: 0.902314]\n",
      "epoch:29 step:22865[D loss: 0.414948, acc: 62.50%, op_acc: 40.62%] [G loss: 0.966374]\n",
      "epoch:29 step:22866[D loss: 0.371744, acc: 67.97%, op_acc: 45.31%] [G loss: 1.094582]\n",
      "epoch:29 step:22867[D loss: 0.403583, acc: 69.53%, op_acc: 48.44%] [G loss: 0.779848]\n",
      "epoch:29 step:22868[D loss: 0.443200, acc: 60.16%, op_acc: 34.38%] [G loss: 1.009244]\n",
      "epoch:29 step:22869[D loss: 0.403448, acc: 65.62%, op_acc: 42.97%] [G loss: 0.949746]\n",
      "epoch:29 step:22870[D loss: 0.378823, acc: 67.97%, op_acc: 42.19%] [G loss: 1.034709]\n",
      "epoch:29 step:22871[D loss: 0.408227, acc: 59.38%, op_acc: 41.41%] [G loss: 1.034976]\n",
      "epoch:29 step:22872[D loss: 0.385791, acc: 68.75%, op_acc: 44.53%] [G loss: 1.149991]\n",
      "epoch:29 step:22873[D loss: 0.410096, acc: 65.62%, op_acc: 38.28%] [G loss: 0.899588]\n",
      "epoch:29 step:22874[D loss: 0.398585, acc: 66.41%, op_acc: 37.50%] [G loss: 1.068275]\n",
      "epoch:29 step:22875[D loss: 0.418965, acc: 62.50%, op_acc: 39.84%] [G loss: 1.064909]\n",
      "epoch:29 step:22876[D loss: 0.393571, acc: 71.09%, op_acc: 38.28%] [G loss: 0.942533]\n",
      "epoch:29 step:22877[D loss: 0.405785, acc: 62.50%, op_acc: 40.62%] [G loss: 0.761096]\n",
      "epoch:29 step:22878[D loss: 0.415161, acc: 63.28%, op_acc: 39.06%] [G loss: 1.068266]\n",
      "epoch:29 step:22879[D loss: 0.425530, acc: 60.16%, op_acc: 37.50%] [G loss: 1.161359]\n",
      "epoch:29 step:22880[D loss: 0.393966, acc: 67.97%, op_acc: 41.41%] [G loss: 0.778085]\n",
      "epoch:29 step:22881[D loss: 0.405575, acc: 66.41%, op_acc: 38.28%] [G loss: 1.169193]\n",
      "epoch:29 step:22882[D loss: 0.367744, acc: 71.88%, op_acc: 45.31%] [G loss: 1.146296]\n",
      "epoch:29 step:22883[D loss: 0.410057, acc: 65.62%, op_acc: 41.41%] [G loss: 1.075633]\n",
      "epoch:29 step:22884[D loss: 0.361965, acc: 72.66%, op_acc: 46.09%] [G loss: 0.773038]\n",
      "epoch:29 step:22885[D loss: 0.414456, acc: 59.38%, op_acc: 44.53%] [G loss: 0.801399]\n",
      "epoch:29 step:22886[D loss: 0.409888, acc: 53.91%, op_acc: 42.97%] [G loss: 0.748958]\n",
      "epoch:29 step:22887[D loss: 0.450530, acc: 49.22%, op_acc: 40.62%] [G loss: 1.211357]\n",
      "epoch:29 step:22888[D loss: 0.411056, acc: 69.53%, op_acc: 41.41%] [G loss: 0.942894]\n",
      "epoch:29 step:22889[D loss: 0.426749, acc: 60.94%, op_acc: 41.41%] [G loss: 0.969020]\n",
      "epoch:29 step:22890[D loss: 0.390264, acc: 67.19%, op_acc: 46.09%] [G loss: 0.941324]\n",
      "epoch:29 step:22891[D loss: 0.409534, acc: 55.47%, op_acc: 46.88%] [G loss: 0.902587]\n",
      "epoch:29 step:22892[D loss: 0.441487, acc: 51.56%, op_acc: 39.84%] [G loss: 0.981003]\n",
      "epoch:29 step:22893[D loss: 0.419994, acc: 57.81%, op_acc: 46.09%] [G loss: 1.088624]\n",
      "epoch:29 step:22894[D loss: 0.411034, acc: 65.62%, op_acc: 51.56%] [G loss: 0.919599]\n",
      "epoch:29 step:22895[D loss: 0.446808, acc: 60.94%, op_acc: 36.72%] [G loss: 0.774825]\n",
      "epoch:29 step:22896[D loss: 0.411195, acc: 62.50%, op_acc: 42.19%] [G loss: 0.956215]\n",
      "epoch:29 step:22897[D loss: 0.409712, acc: 59.38%, op_acc: 37.50%] [G loss: 0.949654]\n",
      "epoch:29 step:22898[D loss: 0.434457, acc: 64.84%, op_acc: 38.28%] [G loss: 0.785571]\n",
      "epoch:29 step:22899[D loss: 0.395800, acc: 68.75%, op_acc: 41.41%] [G loss: 0.742196]\n",
      "epoch:29 step:22900[D loss: 0.399424, acc: 62.50%, op_acc: 42.97%] [G loss: 0.874270]\n",
      "epoch:29 step:22901[D loss: 0.423577, acc: 55.47%, op_acc: 46.09%] [G loss: 0.906225]\n",
      "epoch:29 step:22902[D loss: 0.418869, acc: 57.81%, op_acc: 42.97%] [G loss: 0.901084]\n",
      "epoch:29 step:22903[D loss: 0.385797, acc: 71.88%, op_acc: 42.19%] [G loss: 0.877807]\n",
      "epoch:29 step:22904[D loss: 0.388266, acc: 67.19%, op_acc: 46.88%] [G loss: 0.826249]\n",
      "epoch:29 step:22905[D loss: 0.395622, acc: 65.62%, op_acc: 42.19%] [G loss: 0.861256]\n",
      "epoch:29 step:22906[D loss: 0.413917, acc: 62.50%, op_acc: 43.75%] [G loss: 0.785406]\n",
      "epoch:29 step:22907[D loss: 0.421323, acc: 59.38%, op_acc: 42.19%] [G loss: 0.843433]\n",
      "epoch:29 step:22908[D loss: 0.389259, acc: 71.09%, op_acc: 39.06%] [G loss: 1.033936]\n",
      "epoch:29 step:22909[D loss: 0.413764, acc: 61.72%, op_acc: 35.16%] [G loss: 0.884403]\n",
      "epoch:29 step:22910[D loss: 0.407201, acc: 64.84%, op_acc: 43.75%] [G loss: 0.903985]\n",
      "epoch:29 step:22911[D loss: 0.397472, acc: 67.19%, op_acc: 39.84%] [G loss: 0.960925]\n",
      "epoch:29 step:22912[D loss: 0.397201, acc: 64.06%, op_acc: 40.62%] [G loss: 0.862449]\n",
      "epoch:29 step:22913[D loss: 0.393410, acc: 62.50%, op_acc: 43.75%] [G loss: 0.958879]\n",
      "epoch:29 step:22914[D loss: 0.413113, acc: 61.72%, op_acc: 35.16%] [G loss: 0.861623]\n",
      "epoch:29 step:22915[D loss: 0.422482, acc: 60.94%, op_acc: 39.84%] [G loss: 0.941677]\n",
      "epoch:29 step:22916[D loss: 0.433496, acc: 53.91%, op_acc: 39.06%] [G loss: 0.964482]\n",
      "epoch:29 step:22917[D loss: 0.430657, acc: 58.59%, op_acc: 39.84%] [G loss: 0.927737]\n",
      "epoch:29 step:22918[D loss: 0.412633, acc: 62.50%, op_acc: 47.66%] [G loss: 0.942026]\n",
      "epoch:29 step:22919[D loss: 0.413771, acc: 65.62%, op_acc: 39.84%] [G loss: 1.045333]\n",
      "epoch:29 step:22920[D loss: 0.408126, acc: 64.84%, op_acc: 40.62%] [G loss: 0.903915]\n",
      "epoch:29 step:22921[D loss: 0.430395, acc: 60.94%, op_acc: 42.19%] [G loss: 1.002097]\n",
      "epoch:29 step:22922[D loss: 0.397056, acc: 67.97%, op_acc: 42.97%] [G loss: 1.009013]\n",
      "epoch:29 step:22923[D loss: 0.431450, acc: 60.16%, op_acc: 48.44%] [G loss: 0.819770]\n",
      "epoch:29 step:22924[D loss: 0.379535, acc: 66.41%, op_acc: 46.88%] [G loss: 1.119178]\n",
      "epoch:29 step:22925[D loss: 0.430936, acc: 57.03%, op_acc: 43.75%] [G loss: 0.911558]\n",
      "epoch:29 step:22926[D loss: 0.397975, acc: 65.62%, op_acc: 35.94%] [G loss: 0.979260]\n",
      "epoch:29 step:22927[D loss: 0.416021, acc: 61.72%, op_acc: 40.62%] [G loss: 0.957610]\n",
      "epoch:29 step:22928[D loss: 0.417125, acc: 63.28%, op_acc: 41.41%] [G loss: 0.923653]\n",
      "epoch:29 step:22929[D loss: 0.389676, acc: 67.19%, op_acc: 39.84%] [G loss: 0.955375]\n",
      "epoch:29 step:22930[D loss: 0.413809, acc: 61.72%, op_acc: 40.62%] [G loss: 1.022471]\n",
      "epoch:29 step:22931[D loss: 0.402759, acc: 68.75%, op_acc: 44.53%] [G loss: 0.992529]\n",
      "epoch:29 step:22932[D loss: 0.370523, acc: 70.31%, op_acc: 50.00%] [G loss: 0.913202]\n",
      "epoch:29 step:22933[D loss: 0.418762, acc: 57.81%, op_acc: 37.50%] [G loss: 0.902633]\n",
      "epoch:29 step:22934[D loss: 0.378010, acc: 67.19%, op_acc: 44.53%] [G loss: 1.002007]\n",
      "epoch:29 step:22935[D loss: 0.438914, acc: 59.38%, op_acc: 35.94%] [G loss: 1.008046]\n",
      "epoch:29 step:22936[D loss: 0.366588, acc: 74.22%, op_acc: 44.53%] [G loss: 1.042065]\n",
      "epoch:29 step:22937[D loss: 0.349777, acc: 71.09%, op_acc: 44.53%] [G loss: 0.871669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:22938[D loss: 0.408591, acc: 65.62%, op_acc: 41.41%] [G loss: 1.009084]\n",
      "epoch:29 step:22939[D loss: 0.415909, acc: 59.38%, op_acc: 42.97%] [G loss: 1.008979]\n",
      "epoch:29 step:22940[D loss: 0.388472, acc: 67.97%, op_acc: 44.53%] [G loss: 0.894731]\n",
      "epoch:29 step:22941[D loss: 0.432526, acc: 60.94%, op_acc: 37.50%] [G loss: 1.094115]\n",
      "epoch:29 step:22942[D loss: 0.397453, acc: 60.94%, op_acc: 42.97%] [G loss: 1.035766]\n",
      "epoch:29 step:22943[D loss: 0.380148, acc: 66.41%, op_acc: 42.19%] [G loss: 1.161651]\n",
      "epoch:29 step:22944[D loss: 0.432337, acc: 57.03%, op_acc: 47.66%] [G loss: 1.002050]\n",
      "epoch:29 step:22945[D loss: 0.374100, acc: 65.62%, op_acc: 45.31%] [G loss: 0.943691]\n",
      "epoch:29 step:22946[D loss: 0.436503, acc: 57.81%, op_acc: 37.50%] [G loss: 1.051405]\n",
      "epoch:29 step:22947[D loss: 0.408240, acc: 60.16%, op_acc: 43.75%] [G loss: 0.901657]\n",
      "epoch:29 step:22948[D loss: 0.448869, acc: 47.66%, op_acc: 40.62%] [G loss: 0.817828]\n",
      "epoch:29 step:22949[D loss: 0.420390, acc: 61.72%, op_acc: 43.75%] [G loss: 0.985088]\n",
      "epoch:29 step:22950[D loss: 0.389482, acc: 65.62%, op_acc: 42.19%] [G loss: 0.987220]\n",
      "epoch:29 step:22951[D loss: 0.396391, acc: 67.97%, op_acc: 40.62%] [G loss: 1.004180]\n",
      "epoch:29 step:22952[D loss: 0.411700, acc: 57.03%, op_acc: 46.09%] [G loss: 0.921135]\n",
      "epoch:29 step:22953[D loss: 0.390797, acc: 61.72%, op_acc: 43.75%] [G loss: 0.943875]\n",
      "epoch:29 step:22954[D loss: 0.408611, acc: 57.81%, op_acc: 41.41%] [G loss: 0.934589]\n",
      "epoch:29 step:22955[D loss: 0.427807, acc: 60.94%, op_acc: 38.28%] [G loss: 0.907185]\n",
      "epoch:29 step:22956[D loss: 0.391733, acc: 64.06%, op_acc: 42.19%] [G loss: 1.024348]\n",
      "epoch:29 step:22957[D loss: 0.430523, acc: 56.25%, op_acc: 38.28%] [G loss: 0.833834]\n",
      "epoch:29 step:22958[D loss: 0.459039, acc: 54.69%, op_acc: 36.72%] [G loss: 0.860468]\n",
      "epoch:29 step:22959[D loss: 0.413865, acc: 63.28%, op_acc: 36.72%] [G loss: 0.940917]\n",
      "epoch:29 step:22960[D loss: 0.427925, acc: 57.81%, op_acc: 38.28%] [G loss: 0.902090]\n",
      "epoch:29 step:22961[D loss: 0.406097, acc: 63.28%, op_acc: 43.75%] [G loss: 1.024798]\n",
      "epoch:29 step:22962[D loss: 0.424552, acc: 64.06%, op_acc: 37.50%] [G loss: 0.992940]\n",
      "epoch:29 step:22963[D loss: 0.417117, acc: 59.38%, op_acc: 42.19%] [G loss: 0.844582]\n",
      "epoch:29 step:22964[D loss: 0.436168, acc: 60.16%, op_acc: 34.38%] [G loss: 0.998470]\n",
      "epoch:29 step:22965[D loss: 0.417061, acc: 62.50%, op_acc: 42.19%] [G loss: 0.808863]\n",
      "epoch:29 step:22966[D loss: 0.405614, acc: 57.03%, op_acc: 41.41%] [G loss: 0.875219]\n",
      "epoch:29 step:22967[D loss: 0.435918, acc: 54.69%, op_acc: 38.28%] [G loss: 0.807214]\n",
      "epoch:29 step:22968[D loss: 0.409900, acc: 64.84%, op_acc: 36.72%] [G loss: 0.807615]\n",
      "epoch:29 step:22969[D loss: 0.394630, acc: 68.75%, op_acc: 36.72%] [G loss: 0.914820]\n",
      "epoch:29 step:22970[D loss: 0.405751, acc: 66.41%, op_acc: 37.50%] [G loss: 0.986205]\n",
      "epoch:29 step:22971[D loss: 0.415738, acc: 56.25%, op_acc: 46.09%] [G loss: 1.103523]\n",
      "epoch:29 step:22972[D loss: 0.433192, acc: 52.34%, op_acc: 42.97%] [G loss: 0.788205]\n",
      "epoch:29 step:22973[D loss: 0.448049, acc: 57.03%, op_acc: 32.03%] [G loss: 0.810583]\n",
      "epoch:29 step:22974[D loss: 0.417435, acc: 64.06%, op_acc: 36.72%] [G loss: 1.004527]\n",
      "epoch:29 step:22975[D loss: 0.379693, acc: 68.75%, op_acc: 36.72%] [G loss: 0.887236]\n",
      "epoch:29 step:22976[D loss: 0.415622, acc: 61.72%, op_acc: 33.59%] [G loss: 0.878719]\n",
      "epoch:29 step:22977[D loss: 0.414227, acc: 66.41%, op_acc: 39.06%] [G loss: 0.792248]\n",
      "epoch:29 step:22978[D loss: 0.398139, acc: 63.28%, op_acc: 41.41%] [G loss: 0.899172]\n",
      "epoch:29 step:22979[D loss: 0.385774, acc: 67.97%, op_acc: 43.75%] [G loss: 0.898654]\n",
      "epoch:29 step:22980[D loss: 0.436373, acc: 59.38%, op_acc: 35.16%] [G loss: 0.981212]\n",
      "epoch:29 step:22981[D loss: 0.416310, acc: 57.81%, op_acc: 41.41%] [G loss: 0.894956]\n",
      "epoch:29 step:22982[D loss: 0.409425, acc: 57.81%, op_acc: 46.88%] [G loss: 0.939660]\n",
      "epoch:29 step:22983[D loss: 0.421129, acc: 58.59%, op_acc: 42.19%] [G loss: 0.991007]\n",
      "epoch:29 step:22984[D loss: 0.419654, acc: 60.16%, op_acc: 39.06%] [G loss: 0.953551]\n",
      "epoch:29 step:22985[D loss: 0.457918, acc: 50.00%, op_acc: 39.84%] [G loss: 1.006697]\n",
      "epoch:29 step:22986[D loss: 0.404681, acc: 70.31%, op_acc: 36.72%] [G loss: 0.947854]\n",
      "epoch:29 step:22987[D loss: 0.377373, acc: 67.19%, op_acc: 41.41%] [G loss: 0.983938]\n",
      "epoch:29 step:22988[D loss: 0.431243, acc: 60.16%, op_acc: 35.16%] [G loss: 0.946201]\n",
      "epoch:29 step:22989[D loss: 0.437270, acc: 63.28%, op_acc: 40.62%] [G loss: 0.941671]\n",
      "epoch:29 step:22990[D loss: 0.438744, acc: 53.91%, op_acc: 39.84%] [G loss: 0.883818]\n",
      "epoch:29 step:22991[D loss: 0.412533, acc: 62.50%, op_acc: 39.06%] [G loss: 0.801410]\n",
      "epoch:29 step:22992[D loss: 0.418550, acc: 64.84%, op_acc: 34.38%] [G loss: 1.074389]\n",
      "epoch:29 step:22993[D loss: 0.405180, acc: 60.16%, op_acc: 42.97%] [G loss: 0.954007]\n",
      "epoch:29 step:22994[D loss: 0.423801, acc: 58.59%, op_acc: 37.50%] [G loss: 0.800010]\n",
      "epoch:29 step:22995[D loss: 0.372211, acc: 70.31%, op_acc: 47.66%] [G loss: 0.757769]\n",
      "epoch:29 step:22996[D loss: 0.412315, acc: 62.50%, op_acc: 45.31%] [G loss: 1.031988]\n",
      "epoch:29 step:22997[D loss: 0.399632, acc: 62.50%, op_acc: 35.16%] [G loss: 0.727226]\n",
      "epoch:29 step:22998[D loss: 0.393187, acc: 65.62%, op_acc: 50.00%] [G loss: 1.000166]\n",
      "epoch:29 step:22999[D loss: 0.459087, acc: 57.81%, op_acc: 35.94%] [G loss: 1.042861]\n",
      "epoch:29 step:23000[D loss: 0.401753, acc: 65.62%, op_acc: 46.88%] [G loss: 0.752760]\n",
      "epoch:29 step:23001[D loss: 0.430683, acc: 60.94%, op_acc: 35.16%] [G loss: 0.883786]\n",
      "epoch:29 step:23002[D loss: 0.366080, acc: 73.44%, op_acc: 44.53%] [G loss: 0.824515]\n",
      "epoch:29 step:23003[D loss: 0.417637, acc: 62.50%, op_acc: 42.97%] [G loss: 0.912205]\n",
      "epoch:29 step:23004[D loss: 0.423524, acc: 53.91%, op_acc: 35.94%] [G loss: 0.806567]\n",
      "epoch:29 step:23005[D loss: 0.407682, acc: 67.19%, op_acc: 38.28%] [G loss: 0.953745]\n",
      "epoch:29 step:23006[D loss: 0.403846, acc: 66.41%, op_acc: 42.97%] [G loss: 0.904389]\n",
      "epoch:29 step:23007[D loss: 0.392110, acc: 69.53%, op_acc: 42.97%] [G loss: 1.005920]\n",
      "epoch:29 step:23008[D loss: 0.423081, acc: 60.94%, op_acc: 39.06%] [G loss: 0.899371]\n",
      "epoch:29 step:23009[D loss: 0.384672, acc: 70.31%, op_acc: 42.97%] [G loss: 1.055646]\n",
      "epoch:29 step:23010[D loss: 0.387725, acc: 67.97%, op_acc: 44.53%] [G loss: 0.955560]\n",
      "epoch:29 step:23011[D loss: 0.368186, acc: 67.19%, op_acc: 46.09%] [G loss: 0.959924]\n",
      "epoch:29 step:23012[D loss: 0.404967, acc: 67.19%, op_acc: 42.19%] [G loss: 0.959327]\n",
      "epoch:29 step:23013[D loss: 0.385080, acc: 69.53%, op_acc: 42.97%] [G loss: 0.969688]\n",
      "epoch:29 step:23014[D loss: 0.348772, acc: 71.09%, op_acc: 50.00%] [G loss: 1.032815]\n",
      "epoch:29 step:23015[D loss: 0.356534, acc: 71.88%, op_acc: 44.53%] [G loss: 1.001772]\n",
      "epoch:29 step:23016[D loss: 0.429289, acc: 60.94%, op_acc: 36.72%] [G loss: 0.979206]\n",
      "epoch:29 step:23017[D loss: 0.385152, acc: 68.75%, op_acc: 43.75%] [G loss: 0.986800]\n",
      "epoch:29 step:23018[D loss: 0.352372, acc: 71.88%, op_acc: 47.66%] [G loss: 0.967461]\n",
      "epoch:29 step:23019[D loss: 0.411004, acc: 65.62%, op_acc: 46.09%] [G loss: 0.853702]\n",
      "epoch:29 step:23020[D loss: 0.376456, acc: 64.06%, op_acc: 48.44%] [G loss: 0.998513]\n",
      "epoch:29 step:23021[D loss: 0.388415, acc: 67.97%, op_acc: 45.31%] [G loss: 1.134173]\n",
      "epoch:29 step:23022[D loss: 0.337252, acc: 77.34%, op_acc: 49.22%] [G loss: 1.017235]\n",
      "epoch:29 step:23023[D loss: 0.347712, acc: 72.66%, op_acc: 51.56%] [G loss: 1.182545]\n",
      "epoch:29 step:23024[D loss: 0.356368, acc: 75.00%, op_acc: 49.22%] [G loss: 1.142412]\n",
      "epoch:29 step:23025[D loss: 0.345950, acc: 77.34%, op_acc: 44.53%] [G loss: 1.139349]\n",
      "epoch:29 step:23026[D loss: 0.354480, acc: 75.78%, op_acc: 45.31%] [G loss: 0.814215]\n",
      "epoch:29 step:23027[D loss: 0.353269, acc: 72.66%, op_acc: 46.88%] [G loss: 1.243186]\n",
      "epoch:29 step:23028[D loss: 0.343887, acc: 76.56%, op_acc: 44.53%] [G loss: 0.795576]\n",
      "epoch:29 step:23029[D loss: 0.396559, acc: 60.94%, op_acc: 42.97%] [G loss: 1.269080]\n",
      "epoch:29 step:23030[D loss: 0.393213, acc: 67.19%, op_acc: 45.31%] [G loss: 1.288515]\n",
      "epoch:29 step:23031[D loss: 0.374035, acc: 69.53%, op_acc: 43.75%] [G loss: 0.891892]\n",
      "epoch:29 step:23032[D loss: 0.400029, acc: 59.38%, op_acc: 52.34%] [G loss: 1.265594]\n",
      "epoch:29 step:23033[D loss: 0.412521, acc: 61.72%, op_acc: 39.84%] [G loss: 1.245339]\n",
      "epoch:29 step:23034[D loss: 0.387957, acc: 64.84%, op_acc: 44.53%] [G loss: 0.753193]\n",
      "epoch:29 step:23035[D loss: 0.423402, acc: 58.59%, op_acc: 38.28%] [G loss: 1.085577]\n",
      "epoch:29 step:23036[D loss: 0.468364, acc: 50.00%, op_acc: 37.50%] [G loss: 1.292012]\n",
      "epoch:29 step:23037[D loss: 0.454646, acc: 58.59%, op_acc: 36.72%] [G loss: 1.117215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23038[D loss: 0.419202, acc: 67.19%, op_acc: 38.28%] [G loss: 0.842021]\n",
      "epoch:29 step:23039[D loss: 0.380077, acc: 66.41%, op_acc: 42.97%] [G loss: 0.954168]\n",
      "epoch:29 step:23040[D loss: 0.388191, acc: 61.72%, op_acc: 48.44%] [G loss: 1.011648]\n",
      "epoch:29 step:23041[D loss: 0.420697, acc: 56.25%, op_acc: 40.62%] [G loss: 1.078921]\n",
      "epoch:29 step:23042[D loss: 0.414271, acc: 61.72%, op_acc: 40.62%] [G loss: 0.905113]\n",
      "epoch:29 step:23043[D loss: 0.398012, acc: 67.97%, op_acc: 38.28%] [G loss: 0.985248]\n",
      "epoch:29 step:23044[D loss: 0.414435, acc: 64.06%, op_acc: 40.62%] [G loss: 0.818714]\n",
      "epoch:29 step:23045[D loss: 0.414414, acc: 58.59%, op_acc: 46.09%] [G loss: 0.830275]\n",
      "epoch:29 step:23046[D loss: 0.390652, acc: 64.06%, op_acc: 45.31%] [G loss: 1.019647]\n",
      "epoch:29 step:23047[D loss: 0.439203, acc: 67.19%, op_acc: 36.72%] [G loss: 0.972118]\n",
      "epoch:29 step:23048[D loss: 0.437894, acc: 57.03%, op_acc: 39.06%] [G loss: 0.871461]\n",
      "epoch:29 step:23049[D loss: 0.379470, acc: 67.97%, op_acc: 39.84%] [G loss: 0.989864]\n",
      "epoch:29 step:23050[D loss: 0.403885, acc: 66.41%, op_acc: 40.62%] [G loss: 1.012717]\n",
      "epoch:29 step:23051[D loss: 0.422956, acc: 64.06%, op_acc: 33.59%] [G loss: 0.939553]\n",
      "epoch:29 step:23052[D loss: 0.426576, acc: 56.25%, op_acc: 39.84%] [G loss: 0.965152]\n",
      "epoch:29 step:23053[D loss: 0.376269, acc: 71.88%, op_acc: 42.97%] [G loss: 1.046305]\n",
      "epoch:29 step:23054[D loss: 0.437910, acc: 59.38%, op_acc: 39.06%] [G loss: 1.037598]\n",
      "epoch:29 step:23055[D loss: 0.408170, acc: 58.59%, op_acc: 46.88%] [G loss: 1.003356]\n",
      "epoch:29 step:23056[D loss: 0.369492, acc: 63.28%, op_acc: 50.00%] [G loss: 1.013551]\n",
      "epoch:29 step:23057[D loss: 0.366309, acc: 65.62%, op_acc: 44.53%] [G loss: 1.017855]\n",
      "epoch:29 step:23058[D loss: 0.411738, acc: 66.41%, op_acc: 41.41%] [G loss: 0.836482]\n",
      "epoch:29 step:23059[D loss: 0.377392, acc: 67.19%, op_acc: 45.31%] [G loss: 0.950614]\n",
      "epoch:29 step:23060[D loss: 0.409202, acc: 64.84%, op_acc: 39.84%] [G loss: 0.964730]\n",
      "epoch:29 step:23061[D loss: 0.418086, acc: 55.47%, op_acc: 42.19%] [G loss: 0.892348]\n",
      "epoch:29 step:23062[D loss: 0.383746, acc: 67.19%, op_acc: 44.53%] [G loss: 0.922737]\n",
      "epoch:29 step:23063[D loss: 0.403870, acc: 61.72%, op_acc: 42.19%] [G loss: 0.945478]\n",
      "epoch:29 step:23064[D loss: 0.425606, acc: 59.38%, op_acc: 45.31%] [G loss: 0.932381]\n",
      "epoch:29 step:23065[D loss: 0.425563, acc: 57.03%, op_acc: 39.06%] [G loss: 0.809764]\n",
      "epoch:29 step:23066[D loss: 0.437301, acc: 54.69%, op_acc: 37.50%] [G loss: 0.890848]\n",
      "epoch:29 step:23067[D loss: 0.434665, acc: 57.03%, op_acc: 42.97%] [G loss: 1.005051]\n",
      "epoch:29 step:23068[D loss: 0.396035, acc: 57.81%, op_acc: 42.97%] [G loss: 0.912810]\n",
      "epoch:29 step:23069[D loss: 0.448162, acc: 49.22%, op_acc: 38.28%] [G loss: 1.015188]\n",
      "epoch:29 step:23070[D loss: 0.453320, acc: 57.03%, op_acc: 34.38%] [G loss: 0.856146]\n",
      "epoch:29 step:23071[D loss: 0.356784, acc: 75.78%, op_acc: 43.75%] [G loss: 1.119765]\n",
      "epoch:29 step:23072[D loss: 0.409468, acc: 70.31%, op_acc: 43.75%] [G loss: 1.007880]\n",
      "epoch:29 step:23073[D loss: 0.419256, acc: 64.84%, op_acc: 37.50%] [G loss: 1.139437]\n",
      "epoch:29 step:23074[D loss: 0.404245, acc: 68.75%, op_acc: 47.66%] [G loss: 0.986925]\n",
      "epoch:29 step:23075[D loss: 0.427159, acc: 60.94%, op_acc: 35.94%] [G loss: 0.964383]\n",
      "epoch:29 step:23076[D loss: 0.418938, acc: 60.94%, op_acc: 37.50%] [G loss: 0.666984]\n",
      "epoch:29 step:23077[D loss: 0.405954, acc: 64.84%, op_acc: 44.53%] [G loss: 0.904481]\n",
      "epoch:29 step:23078[D loss: 0.385798, acc: 64.06%, op_acc: 43.75%] [G loss: 0.951417]\n",
      "epoch:29 step:23079[D loss: 0.435504, acc: 61.72%, op_acc: 41.41%] [G loss: 0.731968]\n",
      "epoch:29 step:23080[D loss: 0.442177, acc: 60.94%, op_acc: 37.50%] [G loss: 0.911519]\n",
      "epoch:29 step:23081[D loss: 0.362573, acc: 72.66%, op_acc: 50.78%] [G loss: 1.031710]\n",
      "epoch:29 step:23082[D loss: 0.391541, acc: 58.59%, op_acc: 46.09%] [G loss: 0.819191]\n",
      "epoch:29 step:23083[D loss: 0.400477, acc: 63.28%, op_acc: 46.09%] [G loss: 0.893326]\n",
      "epoch:29 step:23084[D loss: 0.380980, acc: 70.31%, op_acc: 42.19%] [G loss: 0.774886]\n",
      "epoch:29 step:23085[D loss: 0.421920, acc: 64.06%, op_acc: 45.31%] [G loss: 0.872965]\n",
      "epoch:29 step:23086[D loss: 0.384706, acc: 66.41%, op_acc: 44.53%] [G loss: 0.888907]\n",
      "epoch:29 step:23087[D loss: 0.398717, acc: 64.06%, op_acc: 46.09%] [G loss: 0.962606]\n",
      "epoch:29 step:23088[D loss: 0.411987, acc: 60.16%, op_acc: 42.97%] [G loss: 0.993858]\n",
      "epoch:29 step:23089[D loss: 0.387722, acc: 64.84%, op_acc: 39.84%] [G loss: 0.958043]\n",
      "epoch:29 step:23090[D loss: 0.397841, acc: 67.19%, op_acc: 39.06%] [G loss: 0.921996]\n",
      "epoch:29 step:23091[D loss: 0.397614, acc: 59.38%, op_acc: 45.31%] [G loss: 0.935081]\n",
      "epoch:29 step:23092[D loss: 0.393698, acc: 68.75%, op_acc: 35.16%] [G loss: 1.019711]\n",
      "epoch:29 step:23093[D loss: 0.388278, acc: 68.75%, op_acc: 45.31%] [G loss: 0.970536]\n",
      "epoch:29 step:23094[D loss: 0.399908, acc: 71.09%, op_acc: 46.09%] [G loss: 0.877548]\n",
      "epoch:29 step:23095[D loss: 0.412870, acc: 62.50%, op_acc: 39.84%] [G loss: 1.086071]\n",
      "epoch:29 step:23096[D loss: 0.482110, acc: 53.91%, op_acc: 35.94%] [G loss: 0.928638]\n",
      "epoch:29 step:23097[D loss: 0.393961, acc: 60.16%, op_acc: 47.66%] [G loss: 1.078448]\n",
      "epoch:29 step:23098[D loss: 0.353605, acc: 73.44%, op_acc: 46.09%] [G loss: 0.985722]\n",
      "epoch:29 step:23099[D loss: 0.419282, acc: 60.94%, op_acc: 41.41%] [G loss: 0.881011]\n",
      "epoch:29 step:23100[D loss: 0.400867, acc: 67.19%, op_acc: 46.88%] [G loss: 0.890092]\n",
      "epoch:29 step:23101[D loss: 0.404891, acc: 59.38%, op_acc: 47.66%] [G loss: 0.817185]\n",
      "epoch:29 step:23102[D loss: 0.414777, acc: 55.47%, op_acc: 41.41%] [G loss: 0.961044]\n",
      "epoch:29 step:23103[D loss: 0.385682, acc: 68.75%, op_acc: 45.31%] [G loss: 0.859546]\n",
      "epoch:29 step:23104[D loss: 0.449951, acc: 50.00%, op_acc: 42.97%] [G loss: 1.016798]\n",
      "epoch:29 step:23105[D loss: 0.430176, acc: 66.41%, op_acc: 39.06%] [G loss: 0.921644]\n",
      "epoch:29 step:23106[D loss: 0.393635, acc: 65.62%, op_acc: 39.06%] [G loss: 0.907583]\n",
      "epoch:29 step:23107[D loss: 0.421679, acc: 57.81%, op_acc: 38.28%] [G loss: 0.881365]\n",
      "epoch:29 step:23108[D loss: 0.407277, acc: 59.38%, op_acc: 40.62%] [G loss: 1.014313]\n",
      "epoch:29 step:23109[D loss: 0.411990, acc: 62.50%, op_acc: 39.84%] [G loss: 1.032756]\n",
      "epoch:29 step:23110[D loss: 0.381201, acc: 71.09%, op_acc: 39.06%] [G loss: 0.846343]\n",
      "epoch:29 step:23111[D loss: 0.391947, acc: 70.31%, op_acc: 37.50%] [G loss: 0.816023]\n",
      "epoch:29 step:23112[D loss: 0.405885, acc: 64.06%, op_acc: 43.75%] [G loss: 0.958690]\n",
      "epoch:29 step:23113[D loss: 0.432710, acc: 53.12%, op_acc: 43.75%] [G loss: 0.963822]\n",
      "epoch:29 step:23114[D loss: 0.389027, acc: 67.97%, op_acc: 43.75%] [G loss: 0.833523]\n",
      "epoch:29 step:23115[D loss: 0.410378, acc: 54.69%, op_acc: 43.75%] [G loss: 1.100579]\n",
      "epoch:29 step:23116[D loss: 0.425381, acc: 63.28%, op_acc: 39.84%] [G loss: 0.934082]\n",
      "epoch:29 step:23117[D loss: 0.366323, acc: 71.88%, op_acc: 47.66%] [G loss: 0.956217]\n",
      "epoch:29 step:23118[D loss: 0.369604, acc: 68.75%, op_acc: 46.09%] [G loss: 1.018224]\n",
      "epoch:29 step:23119[D loss: 0.381034, acc: 67.97%, op_acc: 42.19%] [G loss: 0.880398]\n",
      "epoch:29 step:23120[D loss: 0.432930, acc: 57.03%, op_acc: 44.53%] [G loss: 0.949075]\n",
      "epoch:29 step:23121[D loss: 0.438464, acc: 59.38%, op_acc: 40.62%] [G loss: 0.856931]\n",
      "epoch:29 step:23122[D loss: 0.370967, acc: 67.19%, op_acc: 48.44%] [G loss: 0.955539]\n",
      "epoch:29 step:23123[D loss: 0.429132, acc: 59.38%, op_acc: 40.62%] [G loss: 0.915503]\n",
      "epoch:29 step:23124[D loss: 0.374956, acc: 66.41%, op_acc: 51.56%] [G loss: 0.901694]\n",
      "epoch:29 step:23125[D loss: 0.394954, acc: 64.84%, op_acc: 39.06%] [G loss: 0.965412]\n",
      "epoch:29 step:23126[D loss: 0.412675, acc: 64.84%, op_acc: 41.41%] [G loss: 1.007436]\n",
      "epoch:29 step:23127[D loss: 0.377830, acc: 62.50%, op_acc: 46.88%] [G loss: 0.912439]\n",
      "epoch:29 step:23128[D loss: 0.383652, acc: 69.53%, op_acc: 43.75%] [G loss: 0.919956]\n",
      "epoch:29 step:23129[D loss: 0.417876, acc: 59.38%, op_acc: 36.72%] [G loss: 0.856904]\n",
      "epoch:29 step:23130[D loss: 0.402423, acc: 67.97%, op_acc: 38.28%] [G loss: 0.850719]\n",
      "epoch:29 step:23131[D loss: 0.409828, acc: 64.84%, op_acc: 35.16%] [G loss: 0.960609]\n",
      "epoch:29 step:23132[D loss: 0.403332, acc: 68.75%, op_acc: 39.84%] [G loss: 0.827342]\n",
      "epoch:29 step:23133[D loss: 0.387553, acc: 71.09%, op_acc: 49.22%] [G loss: 1.019694]\n",
      "epoch:29 step:23134[D loss: 0.428015, acc: 60.16%, op_acc: 39.84%] [G loss: 0.731004]\n",
      "epoch:29 step:23135[D loss: 0.361648, acc: 71.09%, op_acc: 46.88%] [G loss: 0.849257]\n",
      "epoch:29 step:23136[D loss: 0.388205, acc: 68.75%, op_acc: 40.62%] [G loss: 0.981501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23137[D loss: 0.389788, acc: 70.31%, op_acc: 42.19%] [G loss: 0.972655]\n",
      "epoch:29 step:23138[D loss: 0.431222, acc: 60.16%, op_acc: 45.31%] [G loss: 0.955604]\n",
      "epoch:29 step:23139[D loss: 0.402669, acc: 62.50%, op_acc: 37.50%] [G loss: 0.937745]\n",
      "epoch:29 step:23140[D loss: 0.421074, acc: 67.19%, op_acc: 36.72%] [G loss: 1.010479]\n",
      "epoch:29 step:23141[D loss: 0.407567, acc: 64.84%, op_acc: 38.28%] [G loss: 0.892415]\n",
      "epoch:29 step:23142[D loss: 0.407028, acc: 62.50%, op_acc: 39.84%] [G loss: 0.893982]\n",
      "epoch:29 step:23143[D loss: 0.391576, acc: 65.62%, op_acc: 46.88%] [G loss: 1.017720]\n",
      "epoch:29 step:23144[D loss: 0.387585, acc: 69.53%, op_acc: 41.41%] [G loss: 0.863030]\n",
      "epoch:29 step:23145[D loss: 0.394212, acc: 58.59%, op_acc: 44.53%] [G loss: 0.938596]\n",
      "epoch:29 step:23146[D loss: 0.380529, acc: 67.97%, op_acc: 47.66%] [G loss: 1.026687]\n",
      "epoch:29 step:23147[D loss: 0.399984, acc: 68.75%, op_acc: 33.59%] [G loss: 0.911496]\n",
      "epoch:29 step:23148[D loss: 0.430449, acc: 67.97%, op_acc: 40.62%] [G loss: 1.065287]\n",
      "epoch:29 step:23149[D loss: 0.433146, acc: 55.47%, op_acc: 49.22%] [G loss: 0.975735]\n",
      "epoch:29 step:23150[D loss: 0.430613, acc: 58.59%, op_acc: 41.41%] [G loss: 1.076299]\n",
      "epoch:29 step:23151[D loss: 0.414392, acc: 61.72%, op_acc: 39.84%] [G loss: 1.098591]\n",
      "epoch:29 step:23152[D loss: 0.381066, acc: 69.53%, op_acc: 39.84%] [G loss: 0.790665]\n",
      "epoch:29 step:23153[D loss: 0.421473, acc: 57.03%, op_acc: 39.84%] [G loss: 1.051590]\n",
      "epoch:29 step:23154[D loss: 0.441129, acc: 57.03%, op_acc: 40.62%] [G loss: 1.085630]\n",
      "epoch:29 step:23155[D loss: 0.412550, acc: 64.06%, op_acc: 38.28%] [G loss: 0.903917]\n",
      "epoch:29 step:23156[D loss: 0.380940, acc: 63.28%, op_acc: 50.00%] [G loss: 0.898485]\n",
      "epoch:29 step:23157[D loss: 0.423232, acc: 60.16%, op_acc: 43.75%] [G loss: 1.038985]\n",
      "epoch:29 step:23158[D loss: 0.422173, acc: 64.84%, op_acc: 35.16%] [G loss: 0.907382]\n",
      "epoch:29 step:23159[D loss: 0.427348, acc: 60.16%, op_acc: 42.19%] [G loss: 0.955592]\n",
      "epoch:29 step:23160[D loss: 0.371704, acc: 67.97%, op_acc: 40.62%] [G loss: 0.962785]\n",
      "epoch:29 step:23161[D loss: 0.390989, acc: 71.09%, op_acc: 44.53%] [G loss: 0.954345]\n",
      "epoch:29 step:23162[D loss: 0.395078, acc: 67.97%, op_acc: 38.28%] [G loss: 1.032049]\n",
      "epoch:29 step:23163[D loss: 0.379078, acc: 71.88%, op_acc: 38.28%] [G loss: 0.674814]\n",
      "epoch:29 step:23164[D loss: 0.443903, acc: 60.94%, op_acc: 37.50%] [G loss: 0.993560]\n",
      "epoch:29 step:23165[D loss: 0.361895, acc: 69.53%, op_acc: 46.88%] [G loss: 0.980715]\n",
      "epoch:29 step:23166[D loss: 0.398828, acc: 65.62%, op_acc: 39.84%] [G loss: 1.060828]\n",
      "epoch:29 step:23167[D loss: 0.403125, acc: 62.50%, op_acc: 36.72%] [G loss: 0.954622]\n",
      "epoch:29 step:23168[D loss: 0.359727, acc: 73.44%, op_acc: 37.50%] [G loss: 0.918031]\n",
      "epoch:29 step:23169[D loss: 0.394980, acc: 64.06%, op_acc: 41.41%] [G loss: 1.019575]\n",
      "epoch:29 step:23170[D loss: 0.378891, acc: 68.75%, op_acc: 40.62%] [G loss: 1.115170]\n",
      "epoch:29 step:23171[D loss: 0.410105, acc: 60.16%, op_acc: 42.97%] [G loss: 1.200073]\n",
      "epoch:29 step:23172[D loss: 0.392867, acc: 64.84%, op_acc: 40.62%] [G loss: 1.185648]\n",
      "epoch:29 step:23173[D loss: 0.383142, acc: 70.31%, op_acc: 40.62%] [G loss: 1.076267]\n",
      "epoch:29 step:23174[D loss: 0.357963, acc: 79.69%, op_acc: 38.28%] [G loss: 1.080179]\n",
      "epoch:29 step:23175[D loss: 0.420373, acc: 63.28%, op_acc: 35.94%] [G loss: 1.142089]\n",
      "epoch:29 step:23176[D loss: 0.391026, acc: 65.62%, op_acc: 43.75%] [G loss: 1.171521]\n",
      "epoch:29 step:23177[D loss: 0.401064, acc: 64.84%, op_acc: 38.28%] [G loss: 1.046350]\n",
      "epoch:29 step:23178[D loss: 0.378775, acc: 64.06%, op_acc: 45.31%] [G loss: 0.788045]\n",
      "epoch:29 step:23179[D loss: 0.440505, acc: 58.59%, op_acc: 40.62%] [G loss: 1.100958]\n",
      "epoch:29 step:23180[D loss: 0.400177, acc: 67.19%, op_acc: 38.28%] [G loss: 1.038279]\n",
      "epoch:29 step:23181[D loss: 0.385122, acc: 70.31%, op_acc: 42.97%] [G loss: 1.041349]\n",
      "epoch:29 step:23182[D loss: 0.404989, acc: 64.06%, op_acc: 42.97%] [G loss: 1.132612]\n",
      "epoch:29 step:23183[D loss: 0.351057, acc: 74.22%, op_acc: 50.78%] [G loss: 1.103636]\n",
      "epoch:29 step:23184[D loss: 0.418119, acc: 63.28%, op_acc: 40.62%] [G loss: 1.120436]\n",
      "epoch:29 step:23185[D loss: 0.354828, acc: 67.19%, op_acc: 46.88%] [G loss: 1.136059]\n",
      "epoch:29 step:23186[D loss: 0.384016, acc: 69.53%, op_acc: 43.75%] [G loss: 1.179912]\n",
      "epoch:29 step:23187[D loss: 0.376191, acc: 69.53%, op_acc: 49.22%] [G loss: 1.076102]\n",
      "epoch:29 step:23188[D loss: 0.373502, acc: 75.00%, op_acc: 44.53%] [G loss: 1.140969]\n",
      "epoch:29 step:23189[D loss: 0.392987, acc: 68.75%, op_acc: 46.88%] [G loss: 1.269526]\n",
      "epoch:29 step:23190[D loss: 0.334928, acc: 82.81%, op_acc: 43.75%] [G loss: 1.171363]\n",
      "epoch:29 step:23191[D loss: 0.347289, acc: 76.56%, op_acc: 44.53%] [G loss: 1.160756]\n",
      "epoch:29 step:23192[D loss: 0.359740, acc: 73.44%, op_acc: 37.50%] [G loss: 0.618537]\n",
      "epoch:29 step:23193[D loss: 0.405178, acc: 64.06%, op_acc: 42.97%] [G loss: 1.367672]\n",
      "epoch:29 step:23194[D loss: 0.344595, acc: 75.00%, op_acc: 41.41%] [G loss: 1.119924]\n",
      "epoch:29 step:23195[D loss: 0.391044, acc: 64.84%, op_acc: 47.66%] [G loss: 1.196308]\n",
      "epoch:29 step:23196[D loss: 0.425720, acc: 64.84%, op_acc: 39.06%] [G loss: 0.772348]\n",
      "epoch:29 step:23197[D loss: 0.489955, acc: 50.00%, op_acc: 41.41%] [G loss: 0.819600]\n",
      "epoch:29 step:23198[D loss: 0.438030, acc: 55.47%, op_acc: 39.06%] [G loss: 1.172993]\n",
      "epoch:29 step:23199[D loss: 0.409001, acc: 67.19%, op_acc: 40.62%] [G loss: 0.697400]\n",
      "epoch:29 step:23200[D loss: 0.396384, acc: 69.53%, op_acc: 41.41%] [G loss: 0.914881]\n",
      "epoch:29 step:23201[D loss: 0.471112, acc: 47.66%, op_acc: 37.50%] [G loss: 1.047241]\n",
      "epoch:29 step:23202[D loss: 0.416596, acc: 56.25%, op_acc: 41.41%] [G loss: 1.195601]\n",
      "epoch:29 step:23203[D loss: 0.457786, acc: 54.69%, op_acc: 39.06%] [G loss: 0.970173]\n",
      "epoch:29 step:23204[D loss: 0.400944, acc: 62.50%, op_acc: 42.97%] [G loss: 0.806496]\n",
      "epoch:29 step:23205[D loss: 0.449387, acc: 54.69%, op_acc: 38.28%] [G loss: 0.809775]\n",
      "epoch:29 step:23206[D loss: 0.471758, acc: 55.47%, op_acc: 37.50%] [G loss: 0.938088]\n",
      "epoch:29 step:23207[D loss: 0.430557, acc: 53.91%, op_acc: 38.28%] [G loss: 0.929790]\n",
      "epoch:29 step:23208[D loss: 0.435248, acc: 62.50%, op_acc: 41.41%] [G loss: 1.136466]\n",
      "epoch:29 step:23209[D loss: 0.507601, acc: 44.53%, op_acc: 37.50%] [G loss: 1.133949]\n",
      "epoch:29 step:23210[D loss: 0.418971, acc: 57.81%, op_acc: 46.09%] [G loss: 1.138389]\n",
      "epoch:29 step:23211[D loss: 0.438942, acc: 58.59%, op_acc: 39.84%] [G loss: 0.999782]\n",
      "epoch:29 step:23212[D loss: 0.399974, acc: 70.31%, op_acc: 44.53%] [G loss: 1.080692]\n",
      "epoch:29 step:23213[D loss: 0.425830, acc: 57.03%, op_acc: 43.75%] [G loss: 1.024262]\n",
      "epoch:29 step:23214[D loss: 0.428757, acc: 60.16%, op_acc: 40.62%] [G loss: 0.963249]\n",
      "epoch:29 step:23215[D loss: 0.431444, acc: 65.62%, op_acc: 38.28%] [G loss: 0.916585]\n",
      "epoch:29 step:23216[D loss: 0.393183, acc: 62.50%, op_acc: 47.66%] [G loss: 0.863369]\n",
      "epoch:29 step:23217[D loss: 0.401583, acc: 60.94%, op_acc: 45.31%] [G loss: 0.820106]\n",
      "epoch:29 step:23218[D loss: 0.403543, acc: 66.41%, op_acc: 38.28%] [G loss: 1.070000]\n",
      "epoch:29 step:23219[D loss: 0.378667, acc: 68.75%, op_acc: 44.53%] [G loss: 1.013318]\n",
      "epoch:29 step:23220[D loss: 0.439754, acc: 56.25%, op_acc: 42.97%] [G loss: 0.992853]\n",
      "epoch:29 step:23221[D loss: 0.388688, acc: 60.16%, op_acc: 42.97%] [G loss: 0.909620]\n",
      "epoch:29 step:23222[D loss: 0.411896, acc: 62.50%, op_acc: 39.84%] [G loss: 0.915899]\n",
      "epoch:29 step:23223[D loss: 0.447722, acc: 58.59%, op_acc: 34.38%] [G loss: 0.950338]\n",
      "epoch:29 step:23224[D loss: 0.454352, acc: 50.00%, op_acc: 43.75%] [G loss: 0.985032]\n",
      "epoch:29 step:23225[D loss: 0.398559, acc: 66.41%, op_acc: 48.44%] [G loss: 1.115301]\n",
      "epoch:29 step:23226[D loss: 0.457982, acc: 54.69%, op_acc: 38.28%] [G loss: 1.094752]\n",
      "epoch:29 step:23227[D loss: 0.406825, acc: 67.19%, op_acc: 36.72%] [G loss: 0.877524]\n",
      "epoch:29 step:23228[D loss: 0.416489, acc: 60.94%, op_acc: 40.62%] [G loss: 0.914248]\n",
      "epoch:29 step:23229[D loss: 0.433327, acc: 50.78%, op_acc: 42.19%] [G loss: 0.799649]\n",
      "epoch:29 step:23230[D loss: 0.445181, acc: 62.50%, op_acc: 41.41%] [G loss: 1.121596]\n",
      "epoch:29 step:23231[D loss: 0.392217, acc: 70.31%, op_acc: 41.41%] [G loss: 0.858662]\n",
      "epoch:29 step:23232[D loss: 0.404296, acc: 65.62%, op_acc: 42.19%] [G loss: 1.038452]\n",
      "epoch:29 step:23233[D loss: 0.437168, acc: 62.50%, op_acc: 36.72%] [G loss: 1.056605]\n",
      "epoch:29 step:23234[D loss: 0.417531, acc: 60.16%, op_acc: 36.72%] [G loss: 1.117143]\n",
      "epoch:29 step:23235[D loss: 0.422380, acc: 66.41%, op_acc: 40.62%] [G loss: 0.759207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23236[D loss: 0.401008, acc: 67.97%, op_acc: 37.50%] [G loss: 0.688984]\n",
      "epoch:29 step:23237[D loss: 0.391732, acc: 62.50%, op_acc: 44.53%] [G loss: 0.884152]\n",
      "epoch:29 step:23238[D loss: 0.400263, acc: 61.72%, op_acc: 41.41%] [G loss: 0.899720]\n",
      "epoch:29 step:23239[D loss: 0.372422, acc: 67.19%, op_acc: 42.97%] [G loss: 1.001052]\n",
      "epoch:29 step:23240[D loss: 0.407960, acc: 67.19%, op_acc: 38.28%] [G loss: 0.658334]\n",
      "epoch:29 step:23241[D loss: 0.370804, acc: 67.19%, op_acc: 41.41%] [G loss: 0.743196]\n",
      "epoch:29 step:23242[D loss: 0.432435, acc: 61.72%, op_acc: 35.94%] [G loss: 0.918431]\n",
      "epoch:29 step:23243[D loss: 0.393268, acc: 68.75%, op_acc: 38.28%] [G loss: 0.826367]\n",
      "epoch:29 step:23244[D loss: 0.386519, acc: 66.41%, op_acc: 42.97%] [G loss: 1.070825]\n",
      "epoch:29 step:23245[D loss: 0.376226, acc: 70.31%, op_acc: 40.62%] [G loss: 0.973579]\n",
      "epoch:29 step:23246[D loss: 0.382429, acc: 71.09%, op_acc: 39.84%] [G loss: 0.784947]\n",
      "epoch:29 step:23247[D loss: 0.398572, acc: 65.62%, op_acc: 43.75%] [G loss: 0.975620]\n",
      "epoch:29 step:23248[D loss: 0.383975, acc: 64.84%, op_acc: 45.31%] [G loss: 0.932734]\n",
      "epoch:29 step:23249[D loss: 0.379603, acc: 71.09%, op_acc: 39.06%] [G loss: 0.769603]\n",
      "epoch:29 step:23250[D loss: 0.403059, acc: 74.22%, op_acc: 35.94%] [G loss: 0.911050]\n",
      "epoch:29 step:23251[D loss: 0.387872, acc: 66.41%, op_acc: 44.53%] [G loss: 0.754041]\n",
      "epoch:29 step:23252[D loss: 0.391648, acc: 64.84%, op_acc: 49.22%] [G loss: 1.104920]\n",
      "epoch:29 step:23253[D loss: 0.431151, acc: 64.84%, op_acc: 35.94%] [G loss: 0.988323]\n",
      "epoch:29 step:23254[D loss: 0.387218, acc: 68.75%, op_acc: 39.84%] [G loss: 0.823729]\n",
      "epoch:29 step:23255[D loss: 0.382486, acc: 66.41%, op_acc: 46.88%] [G loss: 0.708302]\n",
      "epoch:29 step:23256[D loss: 0.411301, acc: 60.94%, op_acc: 40.62%] [G loss: 0.675044]\n",
      "epoch:29 step:23257[D loss: 0.395519, acc: 65.62%, op_acc: 39.84%] [G loss: 0.991064]\n",
      "epoch:29 step:23258[D loss: 0.418243, acc: 58.59%, op_acc: 42.19%] [G loss: 1.064899]\n",
      "epoch:29 step:23259[D loss: 0.398976, acc: 68.75%, op_acc: 43.75%] [G loss: 0.737624]\n",
      "epoch:29 step:23260[D loss: 0.406248, acc: 60.94%, op_acc: 44.53%] [G loss: 0.622281]\n",
      "epoch:29 step:23261[D loss: 0.376746, acc: 72.66%, op_acc: 39.84%] [G loss: 1.103746]\n",
      "epoch:29 step:23262[D loss: 0.399337, acc: 61.72%, op_acc: 45.31%] [G loss: 1.160028]\n",
      "epoch:29 step:23263[D loss: 0.380504, acc: 70.31%, op_acc: 43.75%] [G loss: 0.626237]\n",
      "epoch:29 step:23264[D loss: 0.406055, acc: 71.88%, op_acc: 41.41%] [G loss: 0.708004]\n",
      "epoch:29 step:23265[D loss: 0.428055, acc: 60.16%, op_acc: 42.19%] [G loss: 0.653316]\n",
      "epoch:29 step:23266[D loss: 0.432324, acc: 64.84%, op_acc: 38.28%] [G loss: 0.575023]\n",
      "epoch:29 step:23267[D loss: 0.363908, acc: 71.88%, op_acc: 44.53%] [G loss: 0.909752]\n",
      "epoch:29 step:23268[D loss: 0.439611, acc: 60.94%, op_acc: 37.50%] [G loss: 0.817111]\n",
      "epoch:29 step:23269[D loss: 0.418105, acc: 65.62%, op_acc: 39.06%] [G loss: 0.732652]\n",
      "epoch:29 step:23270[D loss: 0.403457, acc: 65.62%, op_acc: 39.06%] [G loss: 1.087367]\n",
      "epoch:29 step:23271[D loss: 0.440673, acc: 56.25%, op_acc: 39.06%] [G loss: 0.857164]\n",
      "epoch:29 step:23272[D loss: 0.400192, acc: 60.94%, op_acc: 47.66%] [G loss: 0.842680]\n",
      "epoch:29 step:23273[D loss: 0.395293, acc: 63.28%, op_acc: 42.19%] [G loss: 0.873386]\n",
      "epoch:29 step:23274[D loss: 0.408229, acc: 59.38%, op_acc: 49.22%] [G loss: 0.936028]\n",
      "epoch:29 step:23275[D loss: 0.409161, acc: 64.06%, op_acc: 49.22%] [G loss: 0.965068]\n",
      "epoch:29 step:23276[D loss: 0.416946, acc: 62.50%, op_acc: 45.31%] [G loss: 0.910820]\n",
      "epoch:29 step:23277[D loss: 0.491226, acc: 48.44%, op_acc: 35.94%] [G loss: 0.946445]\n",
      "epoch:29 step:23278[D loss: 0.417059, acc: 57.03%, op_acc: 41.41%] [G loss: 1.057402]\n",
      "epoch:29 step:23279[D loss: 0.395966, acc: 67.97%, op_acc: 44.53%] [G loss: 1.043928]\n",
      "epoch:29 step:23280[D loss: 0.410674, acc: 66.41%, op_acc: 35.16%] [G loss: 0.918045]\n",
      "epoch:29 step:23281[D loss: 0.408394, acc: 63.28%, op_acc: 40.62%] [G loss: 0.924275]\n",
      "epoch:29 step:23282[D loss: 0.427980, acc: 65.62%, op_acc: 44.53%] [G loss: 1.027198]\n",
      "epoch:29 step:23283[D loss: 0.372644, acc: 76.56%, op_acc: 46.88%] [G loss: 1.139912]\n",
      "epoch:29 step:23284[D loss: 0.371358, acc: 69.53%, op_acc: 42.97%] [G loss: 1.016706]\n",
      "epoch:29 step:23285[D loss: 0.370510, acc: 71.88%, op_acc: 47.66%] [G loss: 0.974334]\n",
      "epoch:29 step:23286[D loss: 0.426108, acc: 64.06%, op_acc: 35.94%] [G loss: 1.125283]\n",
      "epoch:29 step:23287[D loss: 0.417958, acc: 64.06%, op_acc: 40.62%] [G loss: 0.777395]\n",
      "epoch:29 step:23288[D loss: 0.435670, acc: 63.28%, op_acc: 37.50%] [G loss: 1.012628]\n",
      "epoch:29 step:23289[D loss: 0.441135, acc: 58.59%, op_acc: 39.84%] [G loss: 1.082539]\n",
      "epoch:29 step:23290[D loss: 0.439828, acc: 66.41%, op_acc: 39.84%] [G loss: 0.853877]\n",
      "epoch:29 step:23291[D loss: 0.423434, acc: 60.94%, op_acc: 39.84%] [G loss: 0.785025]\n",
      "epoch:29 step:23292[D loss: 0.452224, acc: 57.81%, op_acc: 33.59%] [G loss: 1.029091]\n",
      "epoch:29 step:23293[D loss: 0.356607, acc: 66.41%, op_acc: 44.53%] [G loss: 0.991292]\n",
      "epoch:29 step:23294[D loss: 0.457859, acc: 47.66%, op_acc: 43.75%] [G loss: 0.972466]\n",
      "epoch:29 step:23295[D loss: 0.443938, acc: 54.69%, op_acc: 39.06%] [G loss: 0.798258]\n",
      "epoch:29 step:23296[D loss: 0.423854, acc: 60.16%, op_acc: 36.72%] [G loss: 0.970781]\n",
      "epoch:29 step:23297[D loss: 0.389961, acc: 62.50%, op_acc: 40.62%] [G loss: 0.784065]\n",
      "epoch:29 step:23298[D loss: 0.386776, acc: 71.09%, op_acc: 42.19%] [G loss: 0.833670]\n",
      "epoch:29 step:23299[D loss: 0.467197, acc: 54.69%, op_acc: 36.72%] [G loss: 1.094614]\n",
      "epoch:29 step:23300[D loss: 0.423889, acc: 57.81%, op_acc: 43.75%] [G loss: 1.148776]\n",
      "epoch:29 step:23301[D loss: 0.386540, acc: 65.62%, op_acc: 45.31%] [G loss: 0.842881]\n",
      "epoch:29 step:23302[D loss: 0.392398, acc: 61.72%, op_acc: 45.31%] [G loss: 0.718870]\n",
      "epoch:29 step:23303[D loss: 0.425221, acc: 61.72%, op_acc: 48.44%] [G loss: 1.077548]\n",
      "epoch:29 step:23304[D loss: 0.423585, acc: 59.38%, op_acc: 42.97%] [G loss: 0.948706]\n",
      "epoch:29 step:23305[D loss: 0.439976, acc: 60.16%, op_acc: 39.84%] [G loss: 1.009474]\n",
      "epoch:29 step:23306[D loss: 0.398596, acc: 70.31%, op_acc: 39.84%] [G loss: 0.931268]\n",
      "epoch:29 step:23307[D loss: 0.432318, acc: 59.38%, op_acc: 41.41%] [G loss: 0.948211]\n",
      "epoch:29 step:23308[D loss: 0.424461, acc: 60.94%, op_acc: 38.28%] [G loss: 0.860965]\n",
      "epoch:29 step:23309[D loss: 0.406246, acc: 71.09%, op_acc: 35.94%] [G loss: 0.965922]\n",
      "epoch:29 step:23310[D loss: 0.367458, acc: 68.75%, op_acc: 47.66%] [G loss: 0.977610]\n",
      "epoch:29 step:23311[D loss: 0.388853, acc: 70.31%, op_acc: 46.09%] [G loss: 0.867163]\n",
      "epoch:29 step:23312[D loss: 0.400734, acc: 63.28%, op_acc: 39.84%] [G loss: 1.032657]\n",
      "epoch:29 step:23313[D loss: 0.399654, acc: 67.19%, op_acc: 45.31%] [G loss: 1.020546]\n",
      "epoch:29 step:23314[D loss: 0.433724, acc: 63.28%, op_acc: 35.94%] [G loss: 0.930723]\n",
      "epoch:29 step:23315[D loss: 0.381398, acc: 72.66%, op_acc: 42.19%] [G loss: 0.914843]\n",
      "epoch:29 step:23316[D loss: 0.396852, acc: 71.09%, op_acc: 40.62%] [G loss: 0.826803]\n",
      "epoch:29 step:23317[D loss: 0.373481, acc: 67.97%, op_acc: 50.00%] [G loss: 0.859439]\n",
      "epoch:29 step:23318[D loss: 0.417233, acc: 58.59%, op_acc: 40.62%] [G loss: 0.897128]\n",
      "epoch:29 step:23319[D loss: 0.388799, acc: 65.62%, op_acc: 40.62%] [G loss: 0.908174]\n",
      "epoch:29 step:23320[D loss: 0.413228, acc: 64.84%, op_acc: 34.38%] [G loss: 0.945856]\n",
      "epoch:29 step:23321[D loss: 0.401333, acc: 70.31%, op_acc: 36.72%] [G loss: 0.998664]\n",
      "epoch:29 step:23322[D loss: 0.423706, acc: 64.84%, op_acc: 39.84%] [G loss: 1.010098]\n",
      "epoch:29 step:23323[D loss: 0.411735, acc: 64.84%, op_acc: 46.09%] [G loss: 0.927527]\n",
      "epoch:29 step:23324[D loss: 0.382384, acc: 71.09%, op_acc: 46.09%] [G loss: 0.840669]\n",
      "epoch:29 step:23325[D loss: 0.448301, acc: 54.69%, op_acc: 38.28%] [G loss: 0.836814]\n",
      "epoch:29 step:23326[D loss: 0.467617, acc: 50.00%, op_acc: 31.25%] [G loss: 0.931635]\n",
      "epoch:29 step:23327[D loss: 0.369683, acc: 68.75%, op_acc: 44.53%] [G loss: 0.908071]\n",
      "epoch:29 step:23328[D loss: 0.368794, acc: 67.97%, op_acc: 47.66%] [G loss: 1.016566]\n",
      "epoch:29 step:23329[D loss: 0.429154, acc: 63.28%, op_acc: 38.28%] [G loss: 0.887808]\n",
      "epoch:29 step:23330[D loss: 0.399725, acc: 67.19%, op_acc: 39.84%] [G loss: 0.747036]\n",
      "epoch:29 step:23331[D loss: 0.369874, acc: 65.62%, op_acc: 43.75%] [G loss: 0.874038]\n",
      "epoch:29 step:23332[D loss: 0.398079, acc: 68.75%, op_acc: 45.31%] [G loss: 1.012059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23333[D loss: 0.389097, acc: 69.53%, op_acc: 38.28%] [G loss: 0.960261]\n",
      "epoch:29 step:23334[D loss: 0.371639, acc: 71.09%, op_acc: 42.97%] [G loss: 1.066403]\n",
      "epoch:29 step:23335[D loss: 0.380951, acc: 64.84%, op_acc: 48.44%] [G loss: 1.072867]\n",
      "epoch:29 step:23336[D loss: 0.360823, acc: 70.31%, op_acc: 42.97%] [G loss: 1.154682]\n",
      "epoch:29 step:23337[D loss: 0.367615, acc: 69.53%, op_acc: 50.00%] [G loss: 0.846328]\n",
      "epoch:29 step:23338[D loss: 0.377907, acc: 71.09%, op_acc: 43.75%] [G loss: 1.119705]\n",
      "epoch:29 step:23339[D loss: 0.341626, acc: 79.69%, op_acc: 44.53%] [G loss: 1.178316]\n",
      "epoch:29 step:23340[D loss: 0.360507, acc: 74.22%, op_acc: 44.53%] [G loss: 1.151090]\n",
      "epoch:29 step:23341[D loss: 0.377956, acc: 71.09%, op_acc: 46.09%] [G loss: 1.047564]\n",
      "epoch:29 step:23342[D loss: 0.351822, acc: 75.00%, op_acc: 53.91%] [G loss: 0.805009]\n",
      "epoch:29 step:23343[D loss: 0.400073, acc: 68.75%, op_acc: 40.62%] [G loss: 1.114140]\n",
      "epoch:29 step:23344[D loss: 0.369243, acc: 70.31%, op_acc: 43.75%] [G loss: 1.181039]\n",
      "epoch:29 step:23345[D loss: 0.395649, acc: 69.53%, op_acc: 39.84%] [G loss: 1.085806]\n",
      "epoch:29 step:23346[D loss: 0.338845, acc: 79.69%, op_acc: 46.09%] [G loss: 1.057693]\n",
      "epoch:29 step:23347[D loss: 0.361078, acc: 80.47%, op_acc: 42.19%] [G loss: 0.801027]\n",
      "epoch:29 step:23348[D loss: 0.380944, acc: 67.97%, op_acc: 49.22%] [G loss: 1.050153]\n",
      "epoch:29 step:23349[D loss: 0.408265, acc: 66.41%, op_acc: 38.28%] [G loss: 1.229753]\n",
      "epoch:29 step:23350[D loss: 0.440269, acc: 55.47%, op_acc: 35.16%] [G loss: 1.045191]\n",
      "epoch:29 step:23351[D loss: 0.366769, acc: 72.66%, op_acc: 44.53%] [G loss: 0.832017]\n",
      "epoch:29 step:23352[D loss: 0.424487, acc: 58.59%, op_acc: 42.97%] [G loss: 0.743460]\n",
      "epoch:29 step:23353[D loss: 0.414913, acc: 56.25%, op_acc: 42.19%] [G loss: 0.964704]\n",
      "epoch:29 step:23354[D loss: 0.431406, acc: 59.38%, op_acc: 39.06%] [G loss: 1.071510]\n",
      "epoch:29 step:23355[D loss: 0.374572, acc: 75.78%, op_acc: 44.53%] [G loss: 1.300760]\n",
      "epoch:29 step:23356[D loss: 0.445098, acc: 56.25%, op_acc: 42.97%] [G loss: 1.109320]\n",
      "epoch:29 step:23357[D loss: 0.398612, acc: 64.06%, op_acc: 45.31%] [G loss: 0.865467]\n",
      "epoch:29 step:23358[D loss: 0.419511, acc: 64.06%, op_acc: 37.50%] [G loss: 1.044127]\n",
      "epoch:29 step:23359[D loss: 0.384296, acc: 68.75%, op_acc: 45.31%] [G loss: 0.893814]\n",
      "epoch:29 step:23360[D loss: 0.413245, acc: 64.84%, op_acc: 40.62%] [G loss: 1.037968]\n",
      "epoch:29 step:23361[D loss: 0.361618, acc: 71.88%, op_acc: 42.19%] [G loss: 1.141143]\n",
      "epoch:29 step:23362[D loss: 0.374961, acc: 70.31%, op_acc: 50.78%] [G loss: 0.998165]\n",
      "epoch:29 step:23363[D loss: 0.395315, acc: 72.66%, op_acc: 42.19%] [G loss: 1.003445]\n",
      "epoch:29 step:23364[D loss: 0.442766, acc: 56.25%, op_acc: 44.53%] [G loss: 0.993522]\n",
      "epoch:29 step:23365[D loss: 0.407862, acc: 62.50%, op_acc: 46.09%] [G loss: 0.930765]\n",
      "epoch:29 step:23366[D loss: 0.413029, acc: 56.25%, op_acc: 44.53%] [G loss: 0.988518]\n",
      "epoch:29 step:23367[D loss: 0.412370, acc: 65.62%, op_acc: 35.94%] [G loss: 1.150018]\n",
      "epoch:29 step:23368[D loss: 0.374601, acc: 67.19%, op_acc: 41.41%] [G loss: 1.043108]\n",
      "epoch:29 step:23369[D loss: 0.387735, acc: 71.09%, op_acc: 38.28%] [G loss: 1.127464]\n",
      "epoch:29 step:23370[D loss: 0.398417, acc: 61.72%, op_acc: 44.53%] [G loss: 0.995465]\n",
      "epoch:29 step:23371[D loss: 0.424111, acc: 57.03%, op_acc: 42.97%] [G loss: 1.108119]\n",
      "epoch:29 step:23372[D loss: 0.414920, acc: 61.72%, op_acc: 44.53%] [G loss: 1.118345]\n",
      "epoch:29 step:23373[D loss: 0.415360, acc: 64.06%, op_acc: 39.06%] [G loss: 1.134167]\n",
      "epoch:29 step:23374[D loss: 0.356810, acc: 78.91%, op_acc: 45.31%] [G loss: 0.873853]\n",
      "epoch:29 step:23375[D loss: 0.355428, acc: 75.00%, op_acc: 47.66%] [G loss: 0.907495]\n",
      "epoch:29 step:23376[D loss: 0.394842, acc: 65.62%, op_acc: 42.19%] [G loss: 1.258044]\n",
      "epoch:29 step:23377[D loss: 0.421840, acc: 61.72%, op_acc: 44.53%] [G loss: 1.048058]\n",
      "epoch:29 step:23378[D loss: 0.351443, acc: 73.44%, op_acc: 40.62%] [G loss: 1.222197]\n",
      "epoch:29 step:23379[D loss: 0.386930, acc: 73.44%, op_acc: 42.97%] [G loss: 1.179497]\n",
      "epoch:29 step:23380[D loss: 0.361941, acc: 70.31%, op_acc: 46.09%] [G loss: 1.126358]\n",
      "epoch:29 step:23381[D loss: 0.362182, acc: 78.91%, op_acc: 44.53%] [G loss: 1.125403]\n",
      "epoch:29 step:23382[D loss: 0.369137, acc: 71.09%, op_acc: 42.19%] [G loss: 0.594307]\n",
      "epoch:29 step:23383[D loss: 0.406437, acc: 62.50%, op_acc: 35.94%] [G loss: 0.796572]\n",
      "epoch:29 step:23384[D loss: 0.463298, acc: 57.03%, op_acc: 35.16%] [G loss: 1.250952]\n",
      "epoch:29 step:23385[D loss: 0.446071, acc: 52.34%, op_acc: 33.59%] [G loss: 1.229365]\n",
      "epoch:29 step:23386[D loss: 0.408027, acc: 60.16%, op_acc: 42.97%] [G loss: 1.349881]\n",
      "epoch:29 step:23387[D loss: 0.406909, acc: 61.72%, op_acc: 39.84%] [G loss: 0.801706]\n",
      "epoch:29 step:23388[D loss: 0.402391, acc: 60.16%, op_acc: 43.75%] [G loss: 0.778072]\n",
      "epoch:29 step:23389[D loss: 0.424632, acc: 57.03%, op_acc: 42.97%] [G loss: 1.238923]\n",
      "epoch:29 step:23390[D loss: 0.382526, acc: 69.53%, op_acc: 39.84%] [G loss: 1.002779]\n",
      "epoch:29 step:23391[D loss: 0.417615, acc: 65.62%, op_acc: 42.19%] [G loss: 0.870440]\n",
      "epoch:29 step:23392[D loss: 0.446678, acc: 58.59%, op_acc: 35.16%] [G loss: 0.856073]\n",
      "epoch:29 step:23393[D loss: 0.416069, acc: 60.94%, op_acc: 46.88%] [G loss: 1.038550]\n",
      "epoch:29 step:23394[D loss: 0.506948, acc: 40.62%, op_acc: 39.06%] [G loss: 0.950356]\n",
      "epoch:29 step:23395[D loss: 0.436210, acc: 61.72%, op_acc: 39.84%] [G loss: 1.062422]\n",
      "epoch:29 step:23396[D loss: 0.417147, acc: 57.81%, op_acc: 45.31%] [G loss: 1.006471]\n",
      "epoch:29 step:23397[D loss: 0.441372, acc: 60.16%, op_acc: 34.38%] [G loss: 1.028548]\n",
      "epoch:29 step:23398[D loss: 0.404604, acc: 62.50%, op_acc: 44.53%] [G loss: 1.117933]\n",
      "epoch:29 step:23399[D loss: 0.400466, acc: 60.16%, op_acc: 42.97%] [G loss: 1.066247]\n",
      "epoch:29 step:23400[D loss: 0.409968, acc: 66.41%, op_acc: 42.97%] [G loss: 1.125947]\n",
      "epoch:29 step:23401[D loss: 0.419233, acc: 62.50%, op_acc: 42.19%] [G loss: 1.055095]\n",
      "epoch:29 step:23402[D loss: 0.369357, acc: 75.00%, op_acc: 45.31%] [G loss: 1.169788]\n",
      "epoch:29 step:23403[D loss: 0.401132, acc: 60.94%, op_acc: 44.53%] [G loss: 0.796451]\n",
      "epoch:29 step:23404[D loss: 0.381463, acc: 67.97%, op_acc: 46.09%] [G loss: 0.921413]\n",
      "epoch:29 step:23405[D loss: 0.448838, acc: 50.78%, op_acc: 45.31%] [G loss: 0.892270]\n",
      "epoch:29 step:23406[D loss: 0.444225, acc: 51.56%, op_acc: 38.28%] [G loss: 0.946438]\n",
      "epoch:29 step:23407[D loss: 0.359161, acc: 72.66%, op_acc: 46.09%] [G loss: 0.839699]\n",
      "epoch:29 step:23408[D loss: 0.444688, acc: 57.03%, op_acc: 40.62%] [G loss: 0.999952]\n",
      "epoch:29 step:23409[D loss: 0.414248, acc: 57.03%, op_acc: 42.97%] [G loss: 1.066808]\n",
      "epoch:29 step:23410[D loss: 0.429963, acc: 52.34%, op_acc: 46.09%] [G loss: 0.947837]\n",
      "epoch:29 step:23411[D loss: 0.448213, acc: 51.56%, op_acc: 41.41%] [G loss: 1.059539]\n",
      "epoch:29 step:23412[D loss: 0.428078, acc: 53.12%, op_acc: 44.53%] [G loss: 0.791043]\n",
      "epoch:29 step:23413[D loss: 0.460163, acc: 50.78%, op_acc: 42.19%] [G loss: 0.831559]\n",
      "epoch:29 step:23414[D loss: 0.356657, acc: 72.66%, op_acc: 47.66%] [G loss: 0.989611]\n",
      "epoch:29 step:23415[D loss: 0.425493, acc: 60.94%, op_acc: 42.19%] [G loss: 0.953465]\n",
      "epoch:29 step:23416[D loss: 0.434754, acc: 53.91%, op_acc: 39.06%] [G loss: 0.817104]\n",
      "epoch:29 step:23417[D loss: 0.422714, acc: 60.16%, op_acc: 40.62%] [G loss: 1.091508]\n",
      "epoch:29 step:23418[D loss: 0.380331, acc: 64.84%, op_acc: 45.31%] [G loss: 0.946436]\n",
      "epoch:29 step:23419[D loss: 0.428396, acc: 55.47%, op_acc: 42.97%] [G loss: 0.908512]\n",
      "epoch:29 step:23420[D loss: 0.446143, acc: 60.94%, op_acc: 38.28%] [G loss: 1.048480]\n",
      "epoch:29 step:23421[D loss: 0.462605, acc: 54.69%, op_acc: 37.50%] [G loss: 0.972049]\n",
      "epoch:29 step:23422[D loss: 0.419777, acc: 64.06%, op_acc: 45.31%] [G loss: 0.946686]\n",
      "epoch:29 step:23423[D loss: 0.378486, acc: 62.50%, op_acc: 41.41%] [G loss: 0.777369]\n",
      "epoch:29 step:23424[D loss: 0.394388, acc: 74.22%, op_acc: 40.62%] [G loss: 1.020889]\n",
      "epoch:29 step:23425[D loss: 0.370694, acc: 71.88%, op_acc: 43.75%] [G loss: 1.090076]\n",
      "epoch:29 step:23426[D loss: 0.463653, acc: 58.59%, op_acc: 31.25%] [G loss: 1.047068]\n",
      "epoch:29 step:23427[D loss: 0.367139, acc: 71.88%, op_acc: 49.22%] [G loss: 1.143844]\n",
      "epoch:29 step:23428[D loss: 0.416441, acc: 62.50%, op_acc: 43.75%] [G loss: 1.113935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:23429[D loss: 0.390360, acc: 66.41%, op_acc: 43.75%] [G loss: 1.157204]\n",
      "epoch:29 step:23430[D loss: 0.420096, acc: 61.72%, op_acc: 39.06%] [G loss: 0.818857]\n",
      "epoch:30 step:23431[D loss: 0.364200, acc: 68.75%, op_acc: 46.88%] [G loss: 0.858724]\n",
      "epoch:30 step:23432[D loss: 0.429143, acc: 53.91%, op_acc: 42.97%] [G loss: 0.835325]\n",
      "epoch:30 step:23433[D loss: 0.410090, acc: 64.06%, op_acc: 42.97%] [G loss: 0.746087]\n",
      "epoch:30 step:23434[D loss: 0.401889, acc: 64.06%, op_acc: 43.75%] [G loss: 0.975311]\n",
      "epoch:30 step:23435[D loss: 0.376786, acc: 73.44%, op_acc: 39.84%] [G loss: 1.168801]\n",
      "epoch:30 step:23436[D loss: 0.403382, acc: 69.53%, op_acc: 42.97%] [G loss: 0.915195]\n",
      "epoch:30 step:23437[D loss: 0.388731, acc: 68.75%, op_acc: 42.97%] [G loss: 0.787475]\n",
      "epoch:30 step:23438[D loss: 0.454496, acc: 56.25%, op_acc: 36.72%] [G loss: 0.634397]\n",
      "epoch:30 step:23439[D loss: 0.404862, acc: 64.84%, op_acc: 42.19%] [G loss: 0.763747]\n",
      "epoch:30 step:23440[D loss: 0.428553, acc: 57.81%, op_acc: 38.28%] [G loss: 1.164391]\n",
      "epoch:30 step:23441[D loss: 0.427290, acc: 61.72%, op_acc: 43.75%] [G loss: 0.982440]\n",
      "epoch:30 step:23442[D loss: 0.401179, acc: 70.31%, op_acc: 39.06%] [G loss: 0.651569]\n",
      "epoch:30 step:23443[D loss: 0.378558, acc: 75.00%, op_acc: 37.50%] [G loss: 0.865264]\n",
      "epoch:30 step:23444[D loss: 0.427140, acc: 62.50%, op_acc: 38.28%] [G loss: 0.946322]\n",
      "epoch:30 step:23445[D loss: 0.401957, acc: 59.38%, op_acc: 42.97%] [G loss: 0.795060]\n",
      "epoch:30 step:23446[D loss: 0.427125, acc: 50.78%, op_acc: 41.41%] [G loss: 0.826440]\n",
      "epoch:30 step:23447[D loss: 0.385053, acc: 61.72%, op_acc: 47.66%] [G loss: 1.066783]\n",
      "epoch:30 step:23448[D loss: 0.399479, acc: 66.41%, op_acc: 42.19%] [G loss: 1.103571]\n",
      "epoch:30 step:23449[D loss: 0.365066, acc: 69.53%, op_acc: 43.75%] [G loss: 0.892519]\n",
      "epoch:30 step:23450[D loss: 0.363905, acc: 66.41%, op_acc: 46.09%] [G loss: 0.809172]\n",
      "epoch:30 step:23451[D loss: 0.411843, acc: 58.59%, op_acc: 39.84%] [G loss: 0.877244]\n",
      "epoch:30 step:23452[D loss: 0.412520, acc: 54.69%, op_acc: 41.41%] [G loss: 0.854728]\n",
      "epoch:30 step:23453[D loss: 0.407001, acc: 62.50%, op_acc: 45.31%] [G loss: 0.945011]\n",
      "epoch:30 step:23454[D loss: 0.379511, acc: 75.78%, op_acc: 42.97%] [G loss: 0.962684]\n",
      "epoch:30 step:23455[D loss: 0.426627, acc: 59.38%, op_acc: 44.53%] [G loss: 0.919927]\n",
      "epoch:30 step:23456[D loss: 0.361362, acc: 71.88%, op_acc: 44.53%] [G loss: 0.934058]\n",
      "epoch:30 step:23457[D loss: 0.393263, acc: 71.88%, op_acc: 43.75%] [G loss: 1.080533]\n",
      "epoch:30 step:23458[D loss: 0.395900, acc: 64.84%, op_acc: 38.28%] [G loss: 1.114184]\n",
      "epoch:30 step:23459[D loss: 0.379953, acc: 73.44%, op_acc: 45.31%] [G loss: 1.034060]\n",
      "epoch:30 step:23460[D loss: 0.382145, acc: 67.19%, op_acc: 41.41%] [G loss: 1.135332]\n",
      "epoch:30 step:23461[D loss: 0.414045, acc: 68.75%, op_acc: 40.62%] [G loss: 0.909872]\n",
      "epoch:30 step:23462[D loss: 0.401138, acc: 63.28%, op_acc: 39.84%] [G loss: 1.129973]\n",
      "epoch:30 step:23463[D loss: 0.390641, acc: 63.28%, op_acc: 43.75%] [G loss: 1.046120]\n",
      "epoch:30 step:23464[D loss: 0.356476, acc: 72.66%, op_acc: 48.44%] [G loss: 0.917051]\n",
      "epoch:30 step:23465[D loss: 0.376379, acc: 75.00%, op_acc: 39.84%] [G loss: 1.007059]\n",
      "epoch:30 step:23466[D loss: 0.401270, acc: 60.16%, op_acc: 42.97%] [G loss: 1.029640]\n",
      "epoch:30 step:23467[D loss: 0.364089, acc: 71.88%, op_acc: 46.09%] [G loss: 1.066864]\n",
      "epoch:30 step:23468[D loss: 0.438358, acc: 61.72%, op_acc: 42.97%] [G loss: 0.968035]\n",
      "epoch:30 step:23469[D loss: 0.376269, acc: 64.06%, op_acc: 40.62%] [G loss: 1.020264]\n",
      "epoch:30 step:23470[D loss: 0.417250, acc: 60.16%, op_acc: 42.19%] [G loss: 0.963508]\n",
      "epoch:30 step:23471[D loss: 0.391838, acc: 66.41%, op_acc: 50.00%] [G loss: 0.977772]\n",
      "epoch:30 step:23472[D loss: 0.336143, acc: 75.78%, op_acc: 48.44%] [G loss: 0.964524]\n",
      "epoch:30 step:23473[D loss: 0.405947, acc: 65.62%, op_acc: 39.84%] [G loss: 0.867709]\n",
      "epoch:30 step:23474[D loss: 0.413407, acc: 62.50%, op_acc: 40.62%] [G loss: 1.062845]\n",
      "epoch:30 step:23475[D loss: 0.429088, acc: 58.59%, op_acc: 39.06%] [G loss: 1.031415]\n",
      "epoch:30 step:23476[D loss: 0.336283, acc: 75.78%, op_acc: 43.75%] [G loss: 0.888417]\n",
      "epoch:30 step:23477[D loss: 0.424657, acc: 60.16%, op_acc: 39.84%] [G loss: 1.035037]\n",
      "epoch:30 step:23478[D loss: 0.414170, acc: 67.19%, op_acc: 35.94%] [G loss: 0.968446]\n",
      "epoch:30 step:23479[D loss: 0.389140, acc: 68.75%, op_acc: 39.06%] [G loss: 0.991692]\n",
      "epoch:30 step:23480[D loss: 0.388171, acc: 70.31%, op_acc: 36.72%] [G loss: 0.940001]\n",
      "epoch:30 step:23481[D loss: 0.377191, acc: 70.31%, op_acc: 39.06%] [G loss: 0.943630]\n",
      "epoch:30 step:23482[D loss: 0.427836, acc: 60.16%, op_acc: 38.28%] [G loss: 0.910083]\n",
      "epoch:30 step:23483[D loss: 0.431101, acc: 62.50%, op_acc: 42.19%] [G loss: 1.077770]\n",
      "epoch:30 step:23484[D loss: 0.408485, acc: 64.06%, op_acc: 40.62%] [G loss: 0.990379]\n",
      "epoch:30 step:23485[D loss: 0.393610, acc: 65.62%, op_acc: 41.41%] [G loss: 0.981084]\n",
      "epoch:30 step:23486[D loss: 0.378744, acc: 71.09%, op_acc: 40.62%] [G loss: 0.926900]\n",
      "epoch:30 step:23487[D loss: 0.379218, acc: 69.53%, op_acc: 43.75%] [G loss: 0.927984]\n",
      "epoch:30 step:23488[D loss: 0.360892, acc: 75.00%, op_acc: 44.53%] [G loss: 1.032684]\n",
      "epoch:30 step:23489[D loss: 0.353422, acc: 74.22%, op_acc: 46.09%] [G loss: 0.605915]\n",
      "epoch:30 step:23490[D loss: 0.369942, acc: 73.44%, op_acc: 42.19%] [G loss: 1.077640]\n",
      "epoch:30 step:23491[D loss: 0.388833, acc: 67.97%, op_acc: 35.16%] [G loss: 1.123953]\n",
      "epoch:30 step:23492[D loss: 0.381678, acc: 71.09%, op_acc: 43.75%] [G loss: 1.166135]\n",
      "epoch:30 step:23493[D loss: 0.425125, acc: 63.28%, op_acc: 38.28%] [G loss: 1.167599]\n",
      "epoch:30 step:23494[D loss: 0.372415, acc: 71.09%, op_acc: 42.97%] [G loss: 1.221346]\n",
      "epoch:30 step:23495[D loss: 0.370630, acc: 70.31%, op_acc: 44.53%] [G loss: 1.116005]\n",
      "epoch:30 step:23496[D loss: 0.378622, acc: 67.97%, op_acc: 46.09%] [G loss: 0.848720]\n",
      "epoch:30 step:23497[D loss: 0.411024, acc: 63.28%, op_acc: 43.75%] [G loss: 1.143572]\n",
      "epoch:30 step:23498[D loss: 0.439429, acc: 55.47%, op_acc: 39.84%] [G loss: 1.323011]\n",
      "epoch:30 step:23499[D loss: 0.378935, acc: 66.41%, op_acc: 48.44%] [G loss: 0.996483]\n",
      "epoch:30 step:23500[D loss: 0.417116, acc: 57.81%, op_acc: 39.06%] [G loss: 1.127297]\n",
      "epoch:30 step:23501[D loss: 0.419870, acc: 66.41%, op_acc: 36.72%] [G loss: 1.176764]\n",
      "epoch:30 step:23502[D loss: 0.414526, acc: 60.94%, op_acc: 38.28%] [G loss: 1.127786]\n",
      "epoch:30 step:23503[D loss: 0.401582, acc: 60.94%, op_acc: 44.53%] [G loss: 0.786449]\n",
      "epoch:30 step:23504[D loss: 0.380701, acc: 66.41%, op_acc: 47.66%] [G loss: 1.036778]\n",
      "epoch:30 step:23505[D loss: 0.376332, acc: 67.19%, op_acc: 44.53%] [G loss: 0.930914]\n",
      "epoch:30 step:23506[D loss: 0.408621, acc: 61.72%, op_acc: 42.97%] [G loss: 0.872024]\n",
      "epoch:30 step:23507[D loss: 0.468695, acc: 50.00%, op_acc: 35.94%] [G loss: 0.989394]\n",
      "epoch:30 step:23508[D loss: 0.447358, acc: 63.28%, op_acc: 33.59%] [G loss: 1.036397]\n",
      "epoch:30 step:23509[D loss: 0.366458, acc: 78.91%, op_acc: 40.62%] [G loss: 0.961674]\n",
      "epoch:30 step:23510[D loss: 0.426609, acc: 67.19%, op_acc: 34.38%] [G loss: 0.968833]\n",
      "epoch:30 step:23511[D loss: 0.415125, acc: 66.41%, op_acc: 38.28%] [G loss: 0.946577]\n",
      "epoch:30 step:23512[D loss: 0.394159, acc: 64.06%, op_acc: 40.62%] [G loss: 0.930699]\n",
      "epoch:30 step:23513[D loss: 0.352924, acc: 78.91%, op_acc: 44.53%] [G loss: 1.033911]\n",
      "epoch:30 step:23514[D loss: 0.397200, acc: 64.06%, op_acc: 47.66%] [G loss: 1.023046]\n",
      "epoch:30 step:23515[D loss: 0.414015, acc: 67.19%, op_acc: 38.28%] [G loss: 0.965273]\n",
      "epoch:30 step:23516[D loss: 0.436269, acc: 56.25%, op_acc: 39.84%] [G loss: 1.079543]\n",
      "epoch:30 step:23517[D loss: 0.375058, acc: 74.22%, op_acc: 41.41%] [G loss: 1.041882]\n",
      "epoch:30 step:23518[D loss: 0.409131, acc: 64.06%, op_acc: 38.28%] [G loss: 0.850500]\n",
      "epoch:30 step:23519[D loss: 0.382866, acc: 63.28%, op_acc: 40.62%] [G loss: 0.983783]\n",
      "epoch:30 step:23520[D loss: 0.461730, acc: 57.03%, op_acc: 39.06%] [G loss: 0.863423]\n",
      "epoch:30 step:23521[D loss: 0.419332, acc: 62.50%, op_acc: 46.09%] [G loss: 0.831925]\n",
      "epoch:30 step:23522[D loss: 0.413702, acc: 57.03%, op_acc: 39.84%] [G loss: 0.848539]\n",
      "epoch:30 step:23523[D loss: 0.413387, acc: 58.59%, op_acc: 43.75%] [G loss: 0.872981]\n",
      "epoch:30 step:23524[D loss: 0.382118, acc: 69.53%, op_acc: 43.75%] [G loss: 1.021820]\n",
      "epoch:30 step:23525[D loss: 0.424414, acc: 57.81%, op_acc: 44.53%] [G loss: 1.094164]\n",
      "epoch:30 step:23526[D loss: 0.386795, acc: 72.66%, op_acc: 42.19%] [G loss: 0.971775]\n",
      "epoch:30 step:23527[D loss: 0.372615, acc: 67.97%, op_acc: 39.06%] [G loss: 0.963011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23528[D loss: 0.387480, acc: 67.97%, op_acc: 41.41%] [G loss: 1.190984]\n",
      "epoch:30 step:23529[D loss: 0.378789, acc: 64.06%, op_acc: 47.66%] [G loss: 1.019507]\n",
      "epoch:30 step:23530[D loss: 0.375406, acc: 71.09%, op_acc: 39.84%] [G loss: 0.932744]\n",
      "epoch:30 step:23531[D loss: 0.430307, acc: 58.59%, op_acc: 44.53%] [G loss: 0.736248]\n",
      "epoch:30 step:23532[D loss: 0.401673, acc: 68.75%, op_acc: 39.84%] [G loss: 0.901412]\n",
      "epoch:30 step:23533[D loss: 0.409695, acc: 67.97%, op_acc: 39.06%] [G loss: 0.923124]\n",
      "epoch:30 step:23534[D loss: 0.367024, acc: 67.97%, op_acc: 45.31%] [G loss: 0.818441]\n",
      "epoch:30 step:23535[D loss: 0.387631, acc: 68.75%, op_acc: 42.19%] [G loss: 0.913144]\n",
      "epoch:30 step:23536[D loss: 0.357970, acc: 69.53%, op_acc: 46.09%] [G loss: 0.909336]\n",
      "epoch:30 step:23537[D loss: 0.374889, acc: 69.53%, op_acc: 49.22%] [G loss: 0.928093]\n",
      "epoch:30 step:23538[D loss: 0.448373, acc: 61.72%, op_acc: 39.06%] [G loss: 1.011417]\n",
      "epoch:30 step:23539[D loss: 0.406189, acc: 64.84%, op_acc: 45.31%] [G loss: 1.019426]\n",
      "epoch:30 step:23540[D loss: 0.370448, acc: 68.75%, op_acc: 49.22%] [G loss: 1.046220]\n",
      "epoch:30 step:23541[D loss: 0.397960, acc: 67.19%, op_acc: 41.41%] [G loss: 1.047748]\n",
      "epoch:30 step:23542[D loss: 0.389238, acc: 60.94%, op_acc: 47.66%] [G loss: 1.000817]\n",
      "epoch:30 step:23543[D loss: 0.438115, acc: 59.38%, op_acc: 41.41%] [G loss: 1.044688]\n",
      "epoch:30 step:23544[D loss: 0.419307, acc: 54.69%, op_acc: 42.97%] [G loss: 0.898811]\n",
      "epoch:30 step:23545[D loss: 0.420898, acc: 59.38%, op_acc: 43.75%] [G loss: 0.863659]\n",
      "epoch:30 step:23546[D loss: 0.405332, acc: 64.84%, op_acc: 41.41%] [G loss: 0.828523]\n",
      "epoch:30 step:23547[D loss: 0.425527, acc: 57.81%, op_acc: 46.09%] [G loss: 1.012418]\n",
      "epoch:30 step:23548[D loss: 0.360281, acc: 73.44%, op_acc: 43.75%] [G loss: 1.009007]\n",
      "epoch:30 step:23549[D loss: 0.382997, acc: 73.44%, op_acc: 35.94%] [G loss: 0.973294]\n",
      "epoch:30 step:23550[D loss: 0.408200, acc: 61.72%, op_acc: 37.50%] [G loss: 1.087275]\n",
      "epoch:30 step:23551[D loss: 0.386382, acc: 65.62%, op_acc: 45.31%] [G loss: 1.108981]\n",
      "epoch:30 step:23552[D loss: 0.387913, acc: 64.06%, op_acc: 42.97%] [G loss: 0.906411]\n",
      "epoch:30 step:23553[D loss: 0.426291, acc: 60.94%, op_acc: 38.28%] [G loss: 1.005165]\n",
      "epoch:30 step:23554[D loss: 0.436874, acc: 56.25%, op_acc: 39.06%] [G loss: 0.870466]\n",
      "epoch:30 step:23555[D loss: 0.411219, acc: 64.84%, op_acc: 36.72%] [G loss: 0.985655]\n",
      "epoch:30 step:23556[D loss: 0.370315, acc: 67.97%, op_acc: 45.31%] [G loss: 0.838770]\n",
      "epoch:30 step:23557[D loss: 0.396663, acc: 64.84%, op_acc: 45.31%] [G loss: 1.000779]\n",
      "epoch:30 step:23558[D loss: 0.369111, acc: 76.56%, op_acc: 39.06%] [G loss: 0.989159]\n",
      "epoch:30 step:23559[D loss: 0.388111, acc: 64.84%, op_acc: 43.75%] [G loss: 0.969925]\n",
      "epoch:30 step:23560[D loss: 0.347651, acc: 74.22%, op_acc: 46.09%] [G loss: 1.079450]\n",
      "epoch:30 step:23561[D loss: 0.350824, acc: 71.09%, op_acc: 42.97%] [G loss: 0.960624]\n",
      "epoch:30 step:23562[D loss: 0.323572, acc: 75.00%, op_acc: 46.09%] [G loss: 1.106441]\n",
      "epoch:30 step:23563[D loss: 0.376810, acc: 67.97%, op_acc: 38.28%] [G loss: 0.894878]\n",
      "epoch:30 step:23564[D loss: 0.401344, acc: 69.53%, op_acc: 42.97%] [G loss: 0.990615]\n",
      "epoch:30 step:23565[D loss: 0.419326, acc: 55.47%, op_acc: 42.97%] [G loss: 0.946472]\n",
      "epoch:30 step:23566[D loss: 0.365340, acc: 71.09%, op_acc: 43.75%] [G loss: 1.097582]\n",
      "epoch:30 step:23567[D loss: 0.401147, acc: 65.62%, op_acc: 34.38%] [G loss: 0.978479]\n",
      "epoch:30 step:23568[D loss: 0.413985, acc: 59.38%, op_acc: 42.97%] [G loss: 1.025362]\n",
      "epoch:30 step:23569[D loss: 0.362438, acc: 69.53%, op_acc: 44.53%] [G loss: 1.052351]\n",
      "epoch:30 step:23570[D loss: 0.481801, acc: 45.31%, op_acc: 42.19%] [G loss: 0.985752]\n",
      "epoch:30 step:23571[D loss: 0.427617, acc: 59.38%, op_acc: 39.84%] [G loss: 1.007499]\n",
      "epoch:30 step:23572[D loss: 0.375185, acc: 68.75%, op_acc: 39.06%] [G loss: 1.173525]\n",
      "epoch:30 step:23573[D loss: 0.422105, acc: 57.81%, op_acc: 43.75%] [G loss: 0.858273]\n",
      "epoch:30 step:23574[D loss: 0.411742, acc: 65.62%, op_acc: 39.06%] [G loss: 1.019257]\n",
      "epoch:30 step:23575[D loss: 0.423594, acc: 60.94%, op_acc: 41.41%] [G loss: 1.174212]\n",
      "epoch:30 step:23576[D loss: 0.369074, acc: 71.09%, op_acc: 44.53%] [G loss: 1.018885]\n",
      "epoch:30 step:23577[D loss: 0.395184, acc: 66.41%, op_acc: 42.97%] [G loss: 1.089514]\n",
      "epoch:30 step:23578[D loss: 0.396325, acc: 68.75%, op_acc: 42.97%] [G loss: 1.015247]\n",
      "epoch:30 step:23579[D loss: 0.402884, acc: 58.59%, op_acc: 40.62%] [G loss: 1.096426]\n",
      "epoch:30 step:23580[D loss: 0.429438, acc: 54.69%, op_acc: 40.62%] [G loss: 1.028836]\n",
      "epoch:30 step:23581[D loss: 0.392364, acc: 62.50%, op_acc: 45.31%] [G loss: 0.899776]\n",
      "epoch:30 step:23582[D loss: 0.371171, acc: 67.97%, op_acc: 39.84%] [G loss: 0.907537]\n",
      "epoch:30 step:23583[D loss: 0.426428, acc: 57.03%, op_acc: 39.84%] [G loss: 0.900501]\n",
      "epoch:30 step:23584[D loss: 0.448758, acc: 54.69%, op_acc: 32.81%] [G loss: 1.078069]\n",
      "epoch:30 step:23585[D loss: 0.379507, acc: 71.09%, op_acc: 42.19%] [G loss: 1.020420]\n",
      "epoch:30 step:23586[D loss: 0.417752, acc: 57.81%, op_acc: 42.19%] [G loss: 0.857910]\n",
      "epoch:30 step:23587[D loss: 0.386958, acc: 66.41%, op_acc: 43.75%] [G loss: 0.887910]\n",
      "epoch:30 step:23588[D loss: 0.393756, acc: 67.19%, op_acc: 43.75%] [G loss: 1.060846]\n",
      "epoch:30 step:23589[D loss: 0.444773, acc: 53.91%, op_acc: 36.72%] [G loss: 0.927971]\n",
      "epoch:30 step:23590[D loss: 0.407258, acc: 60.16%, op_acc: 39.84%] [G loss: 0.917679]\n",
      "epoch:30 step:23591[D loss: 0.393666, acc: 59.38%, op_acc: 43.75%] [G loss: 0.840582]\n",
      "epoch:30 step:23592[D loss: 0.372982, acc: 70.31%, op_acc: 49.22%] [G loss: 1.053801]\n",
      "epoch:30 step:23593[D loss: 0.397768, acc: 64.84%, op_acc: 44.53%] [G loss: 1.026668]\n",
      "epoch:30 step:23594[D loss: 0.438238, acc: 57.03%, op_acc: 35.16%] [G loss: 0.889595]\n",
      "epoch:30 step:23595[D loss: 0.375857, acc: 64.84%, op_acc: 50.78%] [G loss: 0.829056]\n",
      "epoch:30 step:23596[D loss: 0.401163, acc: 64.06%, op_acc: 42.19%] [G loss: 0.832124]\n",
      "epoch:30 step:23597[D loss: 0.407851, acc: 66.41%, op_acc: 44.53%] [G loss: 0.932631]\n",
      "epoch:30 step:23598[D loss: 0.382402, acc: 67.97%, op_acc: 46.88%] [G loss: 0.844560]\n",
      "epoch:30 step:23599[D loss: 0.396523, acc: 61.72%, op_acc: 46.09%] [G loss: 1.262096]\n",
      "epoch:30 step:23600[D loss: 0.460659, acc: 50.00%, op_acc: 39.06%] [G loss: 0.971308]\n",
      "epoch:30 step:23601[D loss: 0.368658, acc: 71.88%, op_acc: 41.41%] [G loss: 0.900581]\n",
      "epoch:30 step:23602[D loss: 0.408600, acc: 60.16%, op_acc: 42.97%] [G loss: 0.966222]\n",
      "epoch:30 step:23603[D loss: 0.369712, acc: 69.53%, op_acc: 45.31%] [G loss: 1.085602]\n",
      "epoch:30 step:23604[D loss: 0.460503, acc: 53.91%, op_acc: 35.16%] [G loss: 1.064794]\n",
      "epoch:30 step:23605[D loss: 0.405977, acc: 57.81%, op_acc: 42.19%] [G loss: 1.051724]\n",
      "epoch:30 step:23606[D loss: 0.428477, acc: 55.47%, op_acc: 39.06%] [G loss: 0.958127]\n",
      "epoch:30 step:23607[D loss: 0.370244, acc: 69.53%, op_acc: 42.19%] [G loss: 1.129866]\n",
      "epoch:30 step:23608[D loss: 0.384913, acc: 71.09%, op_acc: 46.88%] [G loss: 0.981261]\n",
      "epoch:30 step:23609[D loss: 0.361787, acc: 71.88%, op_acc: 42.97%] [G loss: 1.125079]\n",
      "epoch:30 step:23610[D loss: 0.398849, acc: 61.72%, op_acc: 42.19%] [G loss: 0.895877]\n",
      "epoch:30 step:23611[D loss: 0.347584, acc: 71.88%, op_acc: 43.75%] [G loss: 0.907554]\n",
      "epoch:30 step:23612[D loss: 0.354089, acc: 71.88%, op_acc: 44.53%] [G loss: 1.160508]\n",
      "epoch:30 step:23613[D loss: 0.376592, acc: 65.62%, op_acc: 42.97%] [G loss: 0.938287]\n",
      "epoch:30 step:23614[D loss: 0.356680, acc: 71.88%, op_acc: 50.00%] [G loss: 0.884659]\n",
      "epoch:30 step:23615[D loss: 0.385244, acc: 65.62%, op_acc: 39.06%] [G loss: 1.184470]\n",
      "epoch:30 step:23616[D loss: 0.399660, acc: 60.16%, op_acc: 44.53%] [G loss: 1.270566]\n",
      "epoch:30 step:23617[D loss: 0.393688, acc: 67.19%, op_acc: 44.53%] [G loss: 1.055818]\n",
      "epoch:30 step:23618[D loss: 0.380149, acc: 68.75%, op_acc: 47.66%] [G loss: 1.212849]\n",
      "epoch:30 step:23619[D loss: 0.381868, acc: 75.78%, op_acc: 39.84%] [G loss: 1.034682]\n",
      "epoch:30 step:23620[D loss: 0.378233, acc: 69.53%, op_acc: 46.09%] [G loss: 1.142733]\n",
      "epoch:30 step:23621[D loss: 0.320352, acc: 80.47%, op_acc: 44.53%] [G loss: 1.047169]\n",
      "epoch:30 step:23622[D loss: 0.361385, acc: 72.66%, op_acc: 38.28%] [G loss: 1.138407]\n",
      "epoch:30 step:23623[D loss: 0.388172, acc: 68.75%, op_acc: 45.31%] [G loss: 0.895144]\n",
      "epoch:30 step:23624[D loss: 0.357565, acc: 68.75%, op_acc: 50.78%] [G loss: 0.994022]\n",
      "epoch:30 step:23625[D loss: 0.365642, acc: 72.66%, op_acc: 39.84%] [G loss: 0.691749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23626[D loss: 0.352053, acc: 76.56%, op_acc: 42.19%] [G loss: 1.169520]\n",
      "epoch:30 step:23627[D loss: 0.438428, acc: 62.50%, op_acc: 38.28%] [G loss: 1.268000]\n",
      "epoch:30 step:23628[D loss: 0.371294, acc: 69.53%, op_acc: 40.62%] [G loss: 1.143568]\n",
      "epoch:30 step:23629[D loss: 0.419904, acc: 57.03%, op_acc: 45.31%] [G loss: 1.035623]\n",
      "epoch:30 step:23630[D loss: 0.385178, acc: 61.72%, op_acc: 47.66%] [G loss: 1.069960]\n",
      "epoch:30 step:23631[D loss: 0.347434, acc: 74.22%, op_acc: 55.47%] [G loss: 1.032163]\n",
      "epoch:30 step:23632[D loss: 0.379652, acc: 71.88%, op_acc: 39.84%] [G loss: 1.144940]\n",
      "epoch:30 step:23633[D loss: 0.438536, acc: 57.03%, op_acc: 37.50%] [G loss: 1.055896]\n",
      "epoch:30 step:23634[D loss: 0.365884, acc: 73.44%, op_acc: 44.53%] [G loss: 1.095859]\n",
      "epoch:30 step:23635[D loss: 0.346541, acc: 76.56%, op_acc: 53.12%] [G loss: 0.636687]\n",
      "epoch:30 step:23636[D loss: 0.468640, acc: 49.22%, op_acc: 39.06%] [G loss: 1.171893]\n",
      "epoch:30 step:23637[D loss: 0.449916, acc: 58.59%, op_acc: 37.50%] [G loss: 1.209405]\n",
      "epoch:30 step:23638[D loss: 0.404541, acc: 65.62%, op_acc: 42.19%] [G loss: 1.137048]\n",
      "epoch:30 step:23639[D loss: 0.366319, acc: 67.97%, op_acc: 42.97%] [G loss: 0.936118]\n",
      "epoch:30 step:23640[D loss: 0.410999, acc: 64.84%, op_acc: 35.16%] [G loss: 1.233119]\n",
      "epoch:30 step:23641[D loss: 0.372548, acc: 68.75%, op_acc: 52.34%] [G loss: 1.136696]\n",
      "epoch:30 step:23642[D loss: 0.353210, acc: 76.56%, op_acc: 47.66%] [G loss: 1.246503]\n",
      "epoch:30 step:23643[D loss: 0.338693, acc: 78.91%, op_acc: 50.00%] [G loss: 1.305174]\n",
      "epoch:30 step:23644[D loss: 0.347592, acc: 74.22%, op_acc: 46.09%] [G loss: 1.192177]\n",
      "epoch:30 step:23645[D loss: 0.396161, acc: 70.31%, op_acc: 48.44%] [G loss: 1.096048]\n",
      "epoch:30 step:23646[D loss: 0.354186, acc: 72.66%, op_acc: 41.41%] [G loss: 0.798465]\n",
      "epoch:30 step:23647[D loss: 0.344851, acc: 73.44%, op_acc: 47.66%] [G loss: 1.133419]\n",
      "epoch:30 step:23648[D loss: 0.370035, acc: 72.66%, op_acc: 47.66%] [G loss: 1.099081]\n",
      "epoch:30 step:23649[D loss: 0.375593, acc: 68.75%, op_acc: 38.28%] [G loss: 1.121558]\n",
      "epoch:30 step:23650[D loss: 0.375876, acc: 71.09%, op_acc: 43.75%] [G loss: 1.324198]\n",
      "epoch:30 step:23651[D loss: 0.345667, acc: 77.34%, op_acc: 43.75%] [G loss: 0.705374]\n",
      "epoch:30 step:23652[D loss: 0.385758, acc: 67.97%, op_acc: 39.06%] [G loss: 0.653601]\n",
      "epoch:30 step:23653[D loss: 0.469258, acc: 48.44%, op_acc: 34.38%] [G loss: 1.253785]\n",
      "epoch:30 step:23654[D loss: 0.409419, acc: 61.72%, op_acc: 41.41%] [G loss: 1.387603]\n",
      "epoch:30 step:23655[D loss: 0.412835, acc: 63.28%, op_acc: 40.62%] [G loss: 1.287855]\n",
      "epoch:30 step:23656[D loss: 0.393822, acc: 64.84%, op_acc: 48.44%] [G loss: 1.395341]\n",
      "epoch:30 step:23657[D loss: 0.361146, acc: 75.00%, op_acc: 49.22%] [G loss: 1.361400]\n",
      "epoch:30 step:23658[D loss: 0.383557, acc: 63.28%, op_acc: 45.31%] [G loss: 1.311682]\n",
      "epoch:30 step:23659[D loss: 0.366335, acc: 76.56%, op_acc: 42.19%] [G loss: 1.174021]\n",
      "epoch:30 step:23660[D loss: 0.413321, acc: 64.06%, op_acc: 44.53%] [G loss: 1.147060]\n",
      "epoch:30 step:23661[D loss: 0.322099, acc: 82.03%, op_acc: 56.25%] [G loss: 1.212777]\n",
      "epoch:30 step:23662[D loss: 0.390058, acc: 67.97%, op_acc: 41.41%] [G loss: 1.096521]\n",
      "epoch:30 step:23663[D loss: 0.311432, acc: 81.25%, op_acc: 50.78%] [G loss: 1.288022]\n",
      "epoch:30 step:23664[D loss: 0.416441, acc: 62.50%, op_acc: 44.53%] [G loss: 1.135619]\n",
      "epoch:30 step:23665[D loss: 0.365380, acc: 67.97%, op_acc: 46.09%] [G loss: 1.159563]\n",
      "epoch:30 step:23666[D loss: 0.375290, acc: 71.09%, op_acc: 50.78%] [G loss: 1.267393]\n",
      "epoch:30 step:23667[D loss: 0.344891, acc: 75.00%, op_acc: 44.53%] [G loss: 1.188985]\n",
      "epoch:30 step:23668[D loss: 0.348237, acc: 78.91%, op_acc: 49.22%] [G loss: 1.201961]\n",
      "epoch:30 step:23669[D loss: 0.344361, acc: 73.44%, op_acc: 48.44%] [G loss: 1.357608]\n",
      "epoch:30 step:23670[D loss: 0.343480, acc: 77.34%, op_acc: 45.31%] [G loss: 1.387651]\n",
      "epoch:30 step:23671[D loss: 0.288819, acc: 85.16%, op_acc: 57.03%] [G loss: 1.351093]\n",
      "epoch:30 step:23672[D loss: 0.307727, acc: 83.59%, op_acc: 59.38%] [G loss: 1.277231]\n",
      "epoch:30 step:23673[D loss: 0.302730, acc: 83.59%, op_acc: 50.78%] [G loss: 0.929038]\n",
      "epoch:30 step:23674[D loss: 0.344371, acc: 83.59%, op_acc: 42.19%] [G loss: 1.383071]\n",
      "epoch:30 step:23675[D loss: 0.325283, acc: 79.69%, op_acc: 50.00%] [G loss: 1.479348]\n",
      "epoch:30 step:23676[D loss: 0.311454, acc: 82.81%, op_acc: 45.31%] [G loss: 1.578044]\n",
      "epoch:30 step:23677[D loss: 0.310182, acc: 81.25%, op_acc: 42.19%] [G loss: 0.461866]\n",
      "epoch:30 step:23678[D loss: 0.475731, acc: 57.03%, op_acc: 35.16%] [G loss: 0.565795]\n",
      "epoch:30 step:23679[D loss: 0.504603, acc: 51.56%, op_acc: 33.59%] [G loss: 1.754409]\n",
      "epoch:30 step:23680[D loss: 0.445602, acc: 56.25%, op_acc: 35.94%] [G loss: 0.909972]\n",
      "epoch:30 step:23681[D loss: 0.390707, acc: 62.50%, op_acc: 45.31%] [G loss: 1.566687]\n",
      "epoch:30 step:23682[D loss: 0.447521, acc: 57.81%, op_acc: 40.62%] [G loss: 0.742830]\n",
      "epoch:30 step:23683[D loss: 0.469487, acc: 56.25%, op_acc: 35.16%] [G loss: 1.358421]\n",
      "epoch:30 step:23684[D loss: 0.458334, acc: 55.47%, op_acc: 39.06%] [G loss: 1.565043]\n",
      "epoch:30 step:23685[D loss: 0.418749, acc: 57.81%, op_acc: 45.31%] [G loss: 1.381074]\n",
      "epoch:30 step:23686[D loss: 0.443131, acc: 57.81%, op_acc: 42.19%] [G loss: 0.999753]\n",
      "epoch:30 step:23687[D loss: 0.466813, acc: 55.47%, op_acc: 38.28%] [G loss: 0.723221]\n",
      "epoch:30 step:23688[D loss: 0.423182, acc: 58.59%, op_acc: 39.84%] [G loss: 0.833230]\n",
      "epoch:30 step:23689[D loss: 0.391769, acc: 69.53%, op_acc: 41.41%] [G loss: 1.384629]\n",
      "epoch:30 step:23690[D loss: 0.411001, acc: 64.06%, op_acc: 46.09%] [G loss: 1.215893]\n",
      "epoch:30 step:23691[D loss: 0.435959, acc: 57.81%, op_acc: 41.41%] [G loss: 1.157285]\n",
      "epoch:30 step:23692[D loss: 0.404237, acc: 65.62%, op_acc: 43.75%] [G loss: 1.039640]\n",
      "epoch:30 step:23693[D loss: 0.413882, acc: 68.75%, op_acc: 39.06%] [G loss: 0.960922]\n",
      "epoch:30 step:23694[D loss: 0.379772, acc: 71.09%, op_acc: 39.84%] [G loss: 1.206024]\n",
      "epoch:30 step:23695[D loss: 0.406096, acc: 63.28%, op_acc: 42.19%] [G loss: 1.183633]\n",
      "epoch:30 step:23696[D loss: 0.426635, acc: 58.59%, op_acc: 41.41%] [G loss: 1.263961]\n",
      "epoch:30 step:23697[D loss: 0.512878, acc: 51.56%, op_acc: 38.28%] [G loss: 1.061556]\n",
      "epoch:30 step:23698[D loss: 0.416650, acc: 64.06%, op_acc: 38.28%] [G loss: 1.052851]\n",
      "epoch:30 step:23699[D loss: 0.429060, acc: 58.59%, op_acc: 42.97%] [G loss: 1.039969]\n",
      "epoch:30 step:23700[D loss: 0.426003, acc: 60.16%, op_acc: 37.50%] [G loss: 0.986279]\n",
      "epoch:30 step:23701[D loss: 0.384925, acc: 60.94%, op_acc: 46.09%] [G loss: 0.916821]\n",
      "epoch:30 step:23702[D loss: 0.390194, acc: 63.28%, op_acc: 43.75%] [G loss: 0.842561]\n",
      "epoch:30 step:23703[D loss: 0.445518, acc: 53.91%, op_acc: 44.53%] [G loss: 1.131050]\n",
      "epoch:30 step:23704[D loss: 0.416232, acc: 62.50%, op_acc: 42.19%] [G loss: 0.871209]\n",
      "epoch:30 step:23705[D loss: 0.436074, acc: 62.50%, op_acc: 41.41%] [G loss: 0.855803]\n",
      "epoch:30 step:23706[D loss: 0.439195, acc: 59.38%, op_acc: 42.19%] [G loss: 0.861206]\n",
      "epoch:30 step:23707[D loss: 0.384516, acc: 69.53%, op_acc: 44.53%] [G loss: 1.037192]\n",
      "epoch:30 step:23708[D loss: 0.405393, acc: 67.19%, op_acc: 44.53%] [G loss: 0.938664]\n",
      "epoch:30 step:23709[D loss: 0.405121, acc: 63.28%, op_acc: 48.44%] [G loss: 1.021721]\n",
      "epoch:30 step:23710[D loss: 0.422800, acc: 66.41%, op_acc: 39.06%] [G loss: 1.018347]\n",
      "epoch:30 step:23711[D loss: 0.458334, acc: 50.78%, op_acc: 40.62%] [G loss: 0.944679]\n",
      "epoch:30 step:23712[D loss: 0.440805, acc: 60.94%, op_acc: 42.19%] [G loss: 0.940059]\n",
      "epoch:30 step:23713[D loss: 0.353939, acc: 71.09%, op_acc: 45.31%] [G loss: 0.939887]\n",
      "epoch:30 step:23714[D loss: 0.434378, acc: 57.81%, op_acc: 39.84%] [G loss: 0.893293]\n",
      "epoch:30 step:23715[D loss: 0.385816, acc: 75.78%, op_acc: 41.41%] [G loss: 0.950303]\n",
      "epoch:30 step:23716[D loss: 0.444500, acc: 55.47%, op_acc: 38.28%] [G loss: 1.064711]\n",
      "epoch:30 step:23717[D loss: 0.428539, acc: 54.69%, op_acc: 39.84%] [G loss: 1.162383]\n",
      "epoch:30 step:23718[D loss: 0.398001, acc: 64.84%, op_acc: 42.19%] [G loss: 1.133210]\n",
      "epoch:30 step:23719[D loss: 0.437420, acc: 61.72%, op_acc: 33.59%] [G loss: 1.019054]\n",
      "epoch:30 step:23720[D loss: 0.398328, acc: 67.97%, op_acc: 43.75%] [G loss: 0.911189]\n",
      "epoch:30 step:23721[D loss: 0.382509, acc: 73.44%, op_acc: 46.09%] [G loss: 0.981440]\n",
      "epoch:30 step:23722[D loss: 0.407676, acc: 68.75%, op_acc: 37.50%] [G loss: 0.862197]\n",
      "epoch:30 step:23723[D loss: 0.396368, acc: 66.41%, op_acc: 48.44%] [G loss: 0.782309]\n",
      "epoch:30 step:23724[D loss: 0.449518, acc: 60.94%, op_acc: 37.50%] [G loss: 0.874728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23725[D loss: 0.384466, acc: 66.41%, op_acc: 45.31%] [G loss: 1.108575]\n",
      "epoch:30 step:23726[D loss: 0.424374, acc: 59.38%, op_acc: 43.75%] [G loss: 1.058006]\n",
      "epoch:30 step:23727[D loss: 0.420658, acc: 59.38%, op_acc: 42.97%] [G loss: 0.931829]\n",
      "epoch:30 step:23728[D loss: 0.364059, acc: 72.66%, op_acc: 51.56%] [G loss: 1.059548]\n",
      "epoch:30 step:23729[D loss: 0.380597, acc: 68.75%, op_acc: 48.44%] [G loss: 1.024312]\n",
      "epoch:30 step:23730[D loss: 0.390229, acc: 68.75%, op_acc: 44.53%] [G loss: 1.227452]\n",
      "epoch:30 step:23731[D loss: 0.381512, acc: 68.75%, op_acc: 51.56%] [G loss: 1.193332]\n",
      "epoch:30 step:23732[D loss: 0.375506, acc: 67.97%, op_acc: 44.53%] [G loss: 0.924976]\n",
      "epoch:30 step:23733[D loss: 0.448225, acc: 55.47%, op_acc: 37.50%] [G loss: 1.083539]\n",
      "epoch:30 step:23734[D loss: 0.331160, acc: 75.78%, op_acc: 42.19%] [G loss: 1.086425]\n",
      "epoch:30 step:23735[D loss: 0.483844, acc: 43.75%, op_acc: 42.19%] [G loss: 1.141504]\n",
      "epoch:30 step:23736[D loss: 0.435177, acc: 65.62%, op_acc: 40.62%] [G loss: 1.102308]\n",
      "epoch:30 step:23737[D loss: 0.403505, acc: 71.09%, op_acc: 40.62%] [G loss: 1.116876]\n",
      "epoch:30 step:23738[D loss: 0.449657, acc: 58.59%, op_acc: 43.75%] [G loss: 0.983825]\n",
      "epoch:30 step:23739[D loss: 0.475112, acc: 52.34%, op_acc: 34.38%] [G loss: 1.056805]\n",
      "epoch:30 step:23740[D loss: 0.363622, acc: 72.66%, op_acc: 39.06%] [G loss: 1.087033]\n",
      "epoch:30 step:23741[D loss: 0.378252, acc: 66.41%, op_acc: 44.53%] [G loss: 1.225662]\n",
      "epoch:30 step:23742[D loss: 0.395915, acc: 64.84%, op_acc: 42.97%] [G loss: 1.057024]\n",
      "epoch:30 step:23743[D loss: 0.375158, acc: 75.78%, op_acc: 46.09%] [G loss: 1.139709]\n",
      "epoch:30 step:23744[D loss: 0.397933, acc: 67.19%, op_acc: 44.53%] [G loss: 1.271459]\n",
      "epoch:30 step:23745[D loss: 0.394667, acc: 63.28%, op_acc: 41.41%] [G loss: 1.004371]\n",
      "epoch:30 step:23746[D loss: 0.397389, acc: 61.72%, op_acc: 46.09%] [G loss: 1.176311]\n",
      "epoch:30 step:23747[D loss: 0.401588, acc: 64.84%, op_acc: 42.19%] [G loss: 1.191704]\n",
      "epoch:30 step:23748[D loss: 0.444386, acc: 58.59%, op_acc: 38.28%] [G loss: 1.122048]\n",
      "epoch:30 step:23749[D loss: 0.410679, acc: 61.72%, op_acc: 40.62%] [G loss: 1.083038]\n",
      "epoch:30 step:23750[D loss: 0.399703, acc: 64.84%, op_acc: 46.09%] [G loss: 0.728670]\n",
      "epoch:30 step:23751[D loss: 0.426586, acc: 61.72%, op_acc: 35.94%] [G loss: 1.105916]\n",
      "epoch:30 step:23752[D loss: 0.394576, acc: 64.84%, op_acc: 41.41%] [G loss: 1.006209]\n",
      "epoch:30 step:23753[D loss: 0.418589, acc: 61.72%, op_acc: 41.41%] [G loss: 1.084728]\n",
      "epoch:30 step:23754[D loss: 0.408839, acc: 70.31%, op_acc: 35.94%] [G loss: 1.070459]\n",
      "epoch:30 step:23755[D loss: 0.406763, acc: 66.41%, op_acc: 39.06%] [G loss: 1.155748]\n",
      "epoch:30 step:23756[D loss: 0.393158, acc: 67.19%, op_acc: 42.19%] [G loss: 0.954634]\n",
      "epoch:30 step:23757[D loss: 0.396968, acc: 63.28%, op_acc: 35.16%] [G loss: 1.014115]\n",
      "epoch:30 step:23758[D loss: 0.438113, acc: 59.38%, op_acc: 44.53%] [G loss: 1.068857]\n",
      "epoch:30 step:23759[D loss: 0.368630, acc: 67.19%, op_acc: 46.88%] [G loss: 1.048133]\n",
      "epoch:30 step:23760[D loss: 0.407199, acc: 60.16%, op_acc: 40.62%] [G loss: 0.862306]\n",
      "epoch:30 step:23761[D loss: 0.409603, acc: 60.16%, op_acc: 40.62%] [G loss: 0.972551]\n",
      "epoch:30 step:23762[D loss: 0.380550, acc: 69.53%, op_acc: 46.09%] [G loss: 1.009633]\n",
      "epoch:30 step:23763[D loss: 0.375528, acc: 69.53%, op_acc: 40.62%] [G loss: 1.084986]\n",
      "epoch:30 step:23764[D loss: 0.412666, acc: 56.25%, op_acc: 41.41%] [G loss: 1.078656]\n",
      "epoch:30 step:23765[D loss: 0.390841, acc: 73.44%, op_acc: 34.38%] [G loss: 0.985654]\n",
      "epoch:30 step:23766[D loss: 0.431375, acc: 60.16%, op_acc: 35.16%] [G loss: 1.006946]\n",
      "epoch:30 step:23767[D loss: 0.406784, acc: 67.19%, op_acc: 33.59%] [G loss: 1.035441]\n",
      "epoch:30 step:23768[D loss: 0.402853, acc: 62.50%, op_acc: 42.97%] [G loss: 1.011506]\n",
      "epoch:30 step:23769[D loss: 0.450092, acc: 56.25%, op_acc: 42.19%] [G loss: 0.954232]\n",
      "epoch:30 step:23770[D loss: 0.430111, acc: 64.06%, op_acc: 41.41%] [G loss: 0.980327]\n",
      "epoch:30 step:23771[D loss: 0.408522, acc: 62.50%, op_acc: 39.84%] [G loss: 1.104132]\n",
      "epoch:30 step:23772[D loss: 0.408192, acc: 64.84%, op_acc: 41.41%] [G loss: 1.085615]\n",
      "epoch:30 step:23773[D loss: 0.404948, acc: 71.09%, op_acc: 37.50%] [G loss: 0.860615]\n",
      "epoch:30 step:23774[D loss: 0.404608, acc: 64.84%, op_acc: 44.53%] [G loss: 0.693052]\n",
      "epoch:30 step:23775[D loss: 0.404379, acc: 64.84%, op_acc: 38.28%] [G loss: 0.897412]\n",
      "epoch:30 step:23776[D loss: 0.394126, acc: 64.06%, op_acc: 39.84%] [G loss: 0.726921]\n",
      "epoch:30 step:23777[D loss: 0.407554, acc: 58.59%, op_acc: 45.31%] [G loss: 0.960574]\n",
      "epoch:30 step:23778[D loss: 0.376795, acc: 67.97%, op_acc: 40.62%] [G loss: 0.799570]\n",
      "epoch:30 step:23779[D loss: 0.386347, acc: 65.62%, op_acc: 42.19%] [G loss: 0.965425]\n",
      "epoch:30 step:23780[D loss: 0.434924, acc: 60.16%, op_acc: 37.50%] [G loss: 0.881140]\n",
      "epoch:30 step:23781[D loss: 0.445396, acc: 51.56%, op_acc: 38.28%] [G loss: 0.881030]\n",
      "epoch:30 step:23782[D loss: 0.417461, acc: 61.72%, op_acc: 41.41%] [G loss: 0.944569]\n",
      "epoch:30 step:23783[D loss: 0.332204, acc: 77.34%, op_acc: 48.44%] [G loss: 1.121760]\n",
      "epoch:30 step:23784[D loss: 0.390000, acc: 68.75%, op_acc: 50.78%] [G loss: 1.079490]\n",
      "epoch:30 step:23785[D loss: 0.334688, acc: 78.91%, op_acc: 50.78%] [G loss: 1.010158]\n",
      "epoch:30 step:23786[D loss: 0.414602, acc: 59.38%, op_acc: 41.41%] [G loss: 1.180964]\n",
      "epoch:30 step:23787[D loss: 0.381095, acc: 67.97%, op_acc: 39.84%] [G loss: 1.148022]\n",
      "epoch:30 step:23788[D loss: 0.406491, acc: 69.53%, op_acc: 42.97%] [G loss: 1.329574]\n",
      "epoch:30 step:23789[D loss: 0.353604, acc: 72.66%, op_acc: 51.56%] [G loss: 0.833480]\n",
      "epoch:30 step:23790[D loss: 0.452243, acc: 53.12%, op_acc: 36.72%] [G loss: 0.804686]\n",
      "epoch:30 step:23791[D loss: 0.369651, acc: 71.09%, op_acc: 46.88%] [G loss: 1.245582]\n",
      "epoch:30 step:23792[D loss: 0.402464, acc: 61.72%, op_acc: 43.75%] [G loss: 1.187472]\n",
      "epoch:30 step:23793[D loss: 0.465190, acc: 54.69%, op_acc: 42.19%] [G loss: 1.079903]\n",
      "epoch:30 step:23794[D loss: 0.397326, acc: 64.84%, op_acc: 42.19%] [G loss: 1.123261]\n",
      "epoch:30 step:23795[D loss: 0.406410, acc: 62.50%, op_acc: 45.31%] [G loss: 1.018082]\n",
      "epoch:30 step:23796[D loss: 0.401246, acc: 61.72%, op_acc: 40.62%] [G loss: 1.120746]\n",
      "epoch:30 step:23797[D loss: 0.435682, acc: 65.62%, op_acc: 35.94%] [G loss: 1.150486]\n",
      "epoch:30 step:23798[D loss: 0.383334, acc: 74.22%, op_acc: 42.97%] [G loss: 1.037727]\n",
      "epoch:30 step:23799[D loss: 0.421781, acc: 54.69%, op_acc: 38.28%] [G loss: 1.101847]\n",
      "epoch:30 step:23800[D loss: 0.376625, acc: 70.31%, op_acc: 46.88%] [G loss: 0.998301]\n",
      "epoch:30 step:23801[D loss: 0.369816, acc: 71.09%, op_acc: 42.97%] [G loss: 1.014763]\n",
      "epoch:30 step:23802[D loss: 0.362973, acc: 71.88%, op_acc: 46.09%] [G loss: 1.098623]\n",
      "epoch:30 step:23803[D loss: 0.373031, acc: 70.31%, op_acc: 46.09%] [G loss: 1.097494]\n",
      "epoch:30 step:23804[D loss: 0.404507, acc: 68.75%, op_acc: 46.88%] [G loss: 1.079351]\n",
      "epoch:30 step:23805[D loss: 0.371741, acc: 74.22%, op_acc: 41.41%] [G loss: 0.896143]\n",
      "epoch:30 step:23806[D loss: 0.372855, acc: 69.53%, op_acc: 39.06%] [G loss: 1.067655]\n",
      "epoch:30 step:23807[D loss: 0.399801, acc: 58.59%, op_acc: 46.09%] [G loss: 1.019352]\n",
      "epoch:30 step:23808[D loss: 0.410209, acc: 62.50%, op_acc: 42.19%] [G loss: 1.181712]\n",
      "epoch:30 step:23809[D loss: 0.400578, acc: 64.84%, op_acc: 46.88%] [G loss: 1.163096]\n",
      "epoch:30 step:23810[D loss: 0.418848, acc: 63.28%, op_acc: 41.41%] [G loss: 0.918878]\n",
      "epoch:30 step:23811[D loss: 0.411852, acc: 64.06%, op_acc: 39.84%] [G loss: 0.990440]\n",
      "epoch:30 step:23812[D loss: 0.377128, acc: 65.62%, op_acc: 46.09%] [G loss: 1.151223]\n",
      "epoch:30 step:23813[D loss: 0.365269, acc: 67.19%, op_acc: 46.09%] [G loss: 0.932379]\n",
      "epoch:30 step:23814[D loss: 0.380477, acc: 66.41%, op_acc: 37.50%] [G loss: 1.240695]\n",
      "epoch:30 step:23815[D loss: 0.350598, acc: 71.09%, op_acc: 49.22%] [G loss: 1.162786]\n",
      "epoch:30 step:23816[D loss: 0.362137, acc: 68.75%, op_acc: 43.75%] [G loss: 0.953678]\n",
      "epoch:30 step:23817[D loss: 0.423407, acc: 56.25%, op_acc: 38.28%] [G loss: 1.065996]\n",
      "epoch:30 step:23818[D loss: 0.471391, acc: 60.94%, op_acc: 36.72%] [G loss: 1.200243]\n",
      "epoch:30 step:23819[D loss: 0.430978, acc: 62.50%, op_acc: 35.94%] [G loss: 0.889372]\n",
      "epoch:30 step:23820[D loss: 0.393967, acc: 66.41%, op_acc: 45.31%] [G loss: 1.196549]\n",
      "epoch:30 step:23821[D loss: 0.403822, acc: 63.28%, op_acc: 47.66%] [G loss: 0.898311]\n",
      "epoch:30 step:23822[D loss: 0.397540, acc: 60.94%, op_acc: 39.06%] [G loss: 1.118227]\n",
      "epoch:30 step:23823[D loss: 0.408170, acc: 64.06%, op_acc: 44.53%] [G loss: 1.077814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23824[D loss: 0.349999, acc: 78.91%, op_acc: 46.09%] [G loss: 1.156933]\n",
      "epoch:30 step:23825[D loss: 0.408912, acc: 70.31%, op_acc: 32.81%] [G loss: 1.047305]\n",
      "epoch:30 step:23826[D loss: 0.435760, acc: 53.91%, op_acc: 47.66%] [G loss: 1.030198]\n",
      "epoch:30 step:23827[D loss: 0.427469, acc: 58.59%, op_acc: 42.19%] [G loss: 0.937921]\n",
      "epoch:30 step:23828[D loss: 0.438217, acc: 58.59%, op_acc: 41.41%] [G loss: 0.981507]\n",
      "epoch:30 step:23829[D loss: 0.432080, acc: 60.94%, op_acc: 42.97%] [G loss: 1.097212]\n",
      "epoch:30 step:23830[D loss: 0.377300, acc: 74.22%, op_acc: 40.62%] [G loss: 1.023415]\n",
      "epoch:30 step:23831[D loss: 0.404234, acc: 64.84%, op_acc: 40.62%] [G loss: 1.004169]\n",
      "epoch:30 step:23832[D loss: 0.403728, acc: 64.84%, op_acc: 38.28%] [G loss: 0.987197]\n",
      "epoch:30 step:23833[D loss: 0.399675, acc: 70.31%, op_acc: 42.19%] [G loss: 1.099226]\n",
      "epoch:30 step:23834[D loss: 0.415484, acc: 62.50%, op_acc: 41.41%] [G loss: 0.862200]\n",
      "epoch:30 step:23835[D loss: 0.453162, acc: 53.91%, op_acc: 37.50%] [G loss: 0.934364]\n",
      "epoch:30 step:23836[D loss: 0.412882, acc: 57.81%, op_acc: 40.62%] [G loss: 0.929152]\n",
      "epoch:30 step:23837[D loss: 0.396141, acc: 67.97%, op_acc: 39.06%] [G loss: 0.987882]\n",
      "epoch:30 step:23838[D loss: 0.380746, acc: 69.53%, op_acc: 40.62%] [G loss: 1.074260]\n",
      "epoch:30 step:23839[D loss: 0.400976, acc: 60.94%, op_acc: 48.44%] [G loss: 0.927016]\n",
      "epoch:30 step:23840[D loss: 0.364731, acc: 69.53%, op_acc: 42.19%] [G loss: 1.139038]\n",
      "epoch:30 step:23841[D loss: 0.414603, acc: 63.28%, op_acc: 42.19%] [G loss: 0.849612]\n",
      "epoch:30 step:23842[D loss: 0.370827, acc: 70.31%, op_acc: 47.66%] [G loss: 0.724725]\n",
      "epoch:30 step:23843[D loss: 0.372757, acc: 72.66%, op_acc: 42.19%] [G loss: 1.069346]\n",
      "epoch:30 step:23844[D loss: 0.417881, acc: 53.12%, op_acc: 42.19%] [G loss: 0.917323]\n",
      "epoch:30 step:23845[D loss: 0.390010, acc: 64.06%, op_acc: 50.78%] [G loss: 0.944885]\n",
      "epoch:30 step:23846[D loss: 0.377046, acc: 66.41%, op_acc: 44.53%] [G loss: 1.063966]\n",
      "epoch:30 step:23847[D loss: 0.415222, acc: 62.50%, op_acc: 39.84%] [G loss: 0.954587]\n",
      "epoch:30 step:23848[D loss: 0.393398, acc: 65.62%, op_acc: 43.75%] [G loss: 0.900271]\n",
      "epoch:30 step:23849[D loss: 0.376118, acc: 71.88%, op_acc: 39.06%] [G loss: 0.986154]\n",
      "epoch:30 step:23850[D loss: 0.435139, acc: 62.50%, op_acc: 42.97%] [G loss: 0.771529]\n",
      "epoch:30 step:23851[D loss: 0.467675, acc: 53.91%, op_acc: 34.38%] [G loss: 0.857801]\n",
      "epoch:30 step:23852[D loss: 0.398133, acc: 65.62%, op_acc: 42.97%] [G loss: 0.846761]\n",
      "epoch:30 step:23853[D loss: 0.392159, acc: 70.31%, op_acc: 44.53%] [G loss: 1.058139]\n",
      "epoch:30 step:23854[D loss: 0.397300, acc: 69.53%, op_acc: 46.88%] [G loss: 0.921530]\n",
      "epoch:30 step:23855[D loss: 0.432259, acc: 60.16%, op_acc: 40.62%] [G loss: 0.954038]\n",
      "epoch:30 step:23856[D loss: 0.435132, acc: 57.81%, op_acc: 44.53%] [G loss: 0.960737]\n",
      "epoch:30 step:23857[D loss: 0.403916, acc: 66.41%, op_acc: 36.72%] [G loss: 0.939857]\n",
      "epoch:30 step:23858[D loss: 0.391826, acc: 66.41%, op_acc: 44.53%] [G loss: 0.888299]\n",
      "epoch:30 step:23859[D loss: 0.375685, acc: 67.97%, op_acc: 46.88%] [G loss: 0.986326]\n",
      "epoch:30 step:23860[D loss: 0.378937, acc: 67.97%, op_acc: 43.75%] [G loss: 0.812345]\n",
      "epoch:30 step:23861[D loss: 0.409901, acc: 64.84%, op_acc: 40.62%] [G loss: 0.840161]\n",
      "epoch:30 step:23862[D loss: 0.381259, acc: 71.09%, op_acc: 44.53%] [G loss: 0.849212]\n",
      "epoch:30 step:23863[D loss: 0.449797, acc: 57.03%, op_acc: 35.94%] [G loss: 1.025908]\n",
      "epoch:30 step:23864[D loss: 0.425875, acc: 56.25%, op_acc: 44.53%] [G loss: 0.929487]\n",
      "epoch:30 step:23865[D loss: 0.375387, acc: 71.88%, op_acc: 42.19%] [G loss: 0.905735]\n",
      "epoch:30 step:23866[D loss: 0.395378, acc: 66.41%, op_acc: 39.84%] [G loss: 0.743749]\n",
      "epoch:30 step:23867[D loss: 0.409923, acc: 65.62%, op_acc: 36.72%] [G loss: 1.009164]\n",
      "epoch:30 step:23868[D loss: 0.397932, acc: 64.06%, op_acc: 40.62%] [G loss: 0.807907]\n",
      "epoch:30 step:23869[D loss: 0.334260, acc: 73.44%, op_acc: 49.22%] [G loss: 0.795249]\n",
      "epoch:30 step:23870[D loss: 0.390139, acc: 67.97%, op_acc: 40.62%] [G loss: 0.881312]\n",
      "epoch:30 step:23871[D loss: 0.442012, acc: 58.59%, op_acc: 33.59%] [G loss: 0.831277]\n",
      "epoch:30 step:23872[D loss: 0.383852, acc: 67.19%, op_acc: 44.53%] [G loss: 0.869945]\n",
      "epoch:30 step:23873[D loss: 0.417754, acc: 61.72%, op_acc: 40.62%] [G loss: 1.108805]\n",
      "epoch:30 step:23874[D loss: 0.401048, acc: 67.19%, op_acc: 44.53%] [G loss: 1.028215]\n",
      "epoch:30 step:23875[D loss: 0.405432, acc: 65.62%, op_acc: 44.53%] [G loss: 1.020352]\n",
      "epoch:30 step:23876[D loss: 0.376543, acc: 71.88%, op_acc: 42.19%] [G loss: 0.953914]\n",
      "epoch:30 step:23877[D loss: 0.430136, acc: 60.94%, op_acc: 43.75%] [G loss: 1.013569]\n",
      "epoch:30 step:23878[D loss: 0.344623, acc: 80.47%, op_acc: 42.97%] [G loss: 0.834411]\n",
      "epoch:30 step:23879[D loss: 0.345526, acc: 77.34%, op_acc: 42.97%] [G loss: 1.103683]\n",
      "epoch:30 step:23880[D loss: 0.372901, acc: 70.31%, op_acc: 45.31%] [G loss: 1.202647]\n",
      "epoch:30 step:23881[D loss: 0.418265, acc: 59.38%, op_acc: 46.88%] [G loss: 0.842446]\n",
      "epoch:30 step:23882[D loss: 0.351348, acc: 74.22%, op_acc: 44.53%] [G loss: 0.922983]\n",
      "epoch:30 step:23883[D loss: 0.357713, acc: 68.75%, op_acc: 43.75%] [G loss: 0.967737]\n",
      "epoch:30 step:23884[D loss: 0.422776, acc: 57.03%, op_acc: 37.50%] [G loss: 1.178956]\n",
      "epoch:30 step:23885[D loss: 0.427058, acc: 58.59%, op_acc: 42.97%] [G loss: 0.897690]\n",
      "epoch:30 step:23886[D loss: 0.407640, acc: 69.53%, op_acc: 38.28%] [G loss: 0.990875]\n",
      "epoch:30 step:23887[D loss: 0.394909, acc: 65.62%, op_acc: 46.09%] [G loss: 0.977552]\n",
      "epoch:30 step:23888[D loss: 0.370068, acc: 66.41%, op_acc: 41.41%] [G loss: 0.984041]\n",
      "epoch:30 step:23889[D loss: 0.370953, acc: 64.84%, op_acc: 45.31%] [G loss: 0.910544]\n",
      "epoch:30 step:23890[D loss: 0.338032, acc: 75.78%, op_acc: 43.75%] [G loss: 0.983050]\n",
      "epoch:30 step:23891[D loss: 0.427903, acc: 62.50%, op_acc: 37.50%] [G loss: 0.900794]\n",
      "epoch:30 step:23892[D loss: 0.426140, acc: 57.03%, op_acc: 39.06%] [G loss: 1.113446]\n",
      "epoch:30 step:23893[D loss: 0.391803, acc: 64.06%, op_acc: 46.88%] [G loss: 1.166429]\n",
      "epoch:30 step:23894[D loss: 0.398929, acc: 67.19%, op_acc: 39.06%] [G loss: 1.192480]\n",
      "epoch:30 step:23895[D loss: 0.379167, acc: 67.97%, op_acc: 42.97%] [G loss: 0.990988]\n",
      "epoch:30 step:23896[D loss: 0.394113, acc: 64.06%, op_acc: 45.31%] [G loss: 0.914783]\n",
      "epoch:30 step:23897[D loss: 0.414867, acc: 60.94%, op_acc: 39.06%] [G loss: 0.853355]\n",
      "epoch:30 step:23898[D loss: 0.371296, acc: 70.31%, op_acc: 52.34%] [G loss: 1.067180]\n",
      "epoch:30 step:23899[D loss: 0.393381, acc: 72.66%, op_acc: 41.41%] [G loss: 0.926668]\n",
      "epoch:30 step:23900[D loss: 0.375322, acc: 71.88%, op_acc: 43.75%] [G loss: 0.909434]\n",
      "epoch:30 step:23901[D loss: 0.395010, acc: 69.53%, op_acc: 45.31%] [G loss: 1.067122]\n",
      "epoch:30 step:23902[D loss: 0.416765, acc: 66.41%, op_acc: 38.28%] [G loss: 1.003393]\n",
      "epoch:30 step:23903[D loss: 0.388900, acc: 61.72%, op_acc: 46.88%] [G loss: 1.014610]\n",
      "epoch:30 step:23904[D loss: 0.361217, acc: 75.00%, op_acc: 44.53%] [G loss: 1.042894]\n",
      "epoch:30 step:23905[D loss: 0.375578, acc: 59.38%, op_acc: 49.22%] [G loss: 0.924299]\n",
      "epoch:30 step:23906[D loss: 0.386429, acc: 65.62%, op_acc: 35.94%] [G loss: 1.090876]\n",
      "epoch:30 step:23907[D loss: 0.362109, acc: 67.97%, op_acc: 42.19%] [G loss: 1.083098]\n",
      "epoch:30 step:23908[D loss: 0.402563, acc: 63.28%, op_acc: 46.09%] [G loss: 1.027551]\n",
      "epoch:30 step:23909[D loss: 0.407894, acc: 57.03%, op_acc: 42.97%] [G loss: 1.157223]\n",
      "epoch:30 step:23910[D loss: 0.416162, acc: 71.09%, op_acc: 34.38%] [G loss: 0.970954]\n",
      "epoch:30 step:23911[D loss: 0.404110, acc: 66.41%, op_acc: 34.38%] [G loss: 0.906748]\n",
      "epoch:30 step:23912[D loss: 0.388433, acc: 70.31%, op_acc: 46.09%] [G loss: 1.227065]\n",
      "epoch:30 step:23913[D loss: 0.346211, acc: 75.78%, op_acc: 46.88%] [G loss: 1.120944]\n",
      "epoch:30 step:23914[D loss: 0.363304, acc: 71.09%, op_acc: 45.31%] [G loss: 1.014371]\n",
      "epoch:30 step:23915[D loss: 0.359101, acc: 81.25%, op_acc: 46.09%] [G loss: 1.125358]\n",
      "epoch:30 step:23916[D loss: 0.407504, acc: 59.38%, op_acc: 42.97%] [G loss: 0.932924]\n",
      "epoch:30 step:23917[D loss: 0.389395, acc: 71.88%, op_acc: 48.44%] [G loss: 0.957305]\n",
      "epoch:30 step:23918[D loss: 0.330181, acc: 80.47%, op_acc: 50.78%] [G loss: 0.993202]\n",
      "epoch:30 step:23919[D loss: 0.385524, acc: 67.97%, op_acc: 46.09%] [G loss: 0.973476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:23920[D loss: 0.385581, acc: 65.62%, op_acc: 39.84%] [G loss: 1.121995]\n",
      "epoch:30 step:23921[D loss: 0.409592, acc: 67.97%, op_acc: 38.28%] [G loss: 0.901056]\n",
      "epoch:30 step:23922[D loss: 0.389350, acc: 70.31%, op_acc: 44.53%] [G loss: 0.915017]\n",
      "epoch:30 step:23923[D loss: 0.403688, acc: 61.72%, op_acc: 39.84%] [G loss: 0.903903]\n",
      "epoch:30 step:23924[D loss: 0.321219, acc: 80.47%, op_acc: 50.00%] [G loss: 1.081117]\n",
      "epoch:30 step:23925[D loss: 0.359433, acc: 75.00%, op_acc: 42.97%] [G loss: 0.937932]\n",
      "epoch:30 step:23926[D loss: 0.292907, acc: 88.28%, op_acc: 50.00%] [G loss: 1.140045]\n",
      "epoch:30 step:23927[D loss: 0.387834, acc: 64.84%, op_acc: 44.53%] [G loss: 1.135669]\n",
      "epoch:30 step:23928[D loss: 0.406675, acc: 73.44%, op_acc: 35.94%] [G loss: 1.151066]\n",
      "epoch:30 step:23929[D loss: 0.389480, acc: 71.09%, op_acc: 42.19%] [G loss: 0.998057]\n",
      "epoch:30 step:23930[D loss: 0.374525, acc: 72.66%, op_acc: 49.22%] [G loss: 1.294652]\n",
      "epoch:30 step:23931[D loss: 0.341327, acc: 80.47%, op_acc: 47.66%] [G loss: 1.142628]\n",
      "epoch:30 step:23932[D loss: 0.350116, acc: 72.66%, op_acc: 50.78%] [G loss: 1.161110]\n",
      "epoch:30 step:23933[D loss: 0.307954, acc: 86.72%, op_acc: 51.56%] [G loss: 1.288640]\n",
      "epoch:30 step:23934[D loss: 0.421656, acc: 59.38%, op_acc: 42.19%] [G loss: 1.148680]\n",
      "epoch:30 step:23935[D loss: 0.345726, acc: 81.25%, op_acc: 47.66%] [G loss: 1.032244]\n",
      "epoch:30 step:23936[D loss: 0.369572, acc: 72.66%, op_acc: 48.44%] [G loss: 1.227883]\n",
      "epoch:30 step:23937[D loss: 0.340347, acc: 74.22%, op_acc: 46.88%] [G loss: 0.881806]\n",
      "epoch:30 step:23938[D loss: 0.418407, acc: 60.16%, op_acc: 41.41%] [G loss: 0.571626]\n",
      "epoch:30 step:23939[D loss: 0.440866, acc: 52.34%, op_acc: 36.72%] [G loss: 1.210037]\n",
      "epoch:30 step:23940[D loss: 0.383644, acc: 65.62%, op_acc: 46.09%] [G loss: 1.315514]\n",
      "epoch:30 step:23941[D loss: 0.392974, acc: 62.50%, op_acc: 45.31%] [G loss: 1.392217]\n",
      "epoch:30 step:23942[D loss: 0.452262, acc: 54.69%, op_acc: 39.06%] [G loss: 0.811519]\n",
      "epoch:30 step:23943[D loss: 0.514355, acc: 42.97%, op_acc: 34.38%] [G loss: 1.336307]\n",
      "epoch:30 step:23944[D loss: 0.423524, acc: 64.06%, op_acc: 40.62%] [G loss: 1.146971]\n",
      "epoch:30 step:23945[D loss: 0.407409, acc: 64.84%, op_acc: 39.84%] [G loss: 1.022731]\n",
      "epoch:30 step:23946[D loss: 0.410603, acc: 64.06%, op_acc: 39.84%] [G loss: 0.923860]\n",
      "epoch:30 step:23947[D loss: 0.427133, acc: 61.72%, op_acc: 40.62%] [G loss: 1.140529]\n",
      "epoch:30 step:23948[D loss: 0.428111, acc: 60.16%, op_acc: 38.28%] [G loss: 1.127224]\n",
      "epoch:30 step:23949[D loss: 0.393517, acc: 64.06%, op_acc: 46.88%] [G loss: 1.019305]\n",
      "epoch:30 step:23950[D loss: 0.436671, acc: 60.16%, op_acc: 45.31%] [G loss: 1.148600]\n",
      "epoch:30 step:23951[D loss: 0.386338, acc: 67.19%, op_acc: 40.62%] [G loss: 1.188012]\n",
      "epoch:30 step:23952[D loss: 0.444258, acc: 60.16%, op_acc: 38.28%] [G loss: 1.022570]\n",
      "epoch:30 step:23953[D loss: 0.402994, acc: 61.72%, op_acc: 43.75%] [G loss: 1.002051]\n",
      "epoch:30 step:23954[D loss: 0.384271, acc: 71.88%, op_acc: 39.84%] [G loss: 1.237542]\n",
      "epoch:30 step:23955[D loss: 0.385107, acc: 73.44%, op_acc: 46.88%] [G loss: 1.028029]\n",
      "epoch:30 step:23956[D loss: 0.408262, acc: 69.53%, op_acc: 38.28%] [G loss: 1.185378]\n",
      "epoch:30 step:23957[D loss: 0.423469, acc: 57.81%, op_acc: 42.19%] [G loss: 1.043884]\n",
      "epoch:30 step:23958[D loss: 0.345727, acc: 73.44%, op_acc: 48.44%] [G loss: 0.903145]\n",
      "epoch:30 step:23959[D loss: 0.429544, acc: 57.03%, op_acc: 39.06%] [G loss: 1.142571]\n",
      "epoch:30 step:23960[D loss: 0.403272, acc: 65.62%, op_acc: 39.84%] [G loss: 0.836855]\n",
      "epoch:30 step:23961[D loss: 0.361272, acc: 74.22%, op_acc: 42.19%] [G loss: 1.082198]\n",
      "epoch:30 step:23962[D loss: 0.418260, acc: 63.28%, op_acc: 42.97%] [G loss: 1.016356]\n",
      "epoch:30 step:23963[D loss: 0.412801, acc: 59.38%, op_acc: 43.75%] [G loss: 0.970420]\n",
      "epoch:30 step:23964[D loss: 0.394134, acc: 64.06%, op_acc: 45.31%] [G loss: 0.687523]\n",
      "epoch:30 step:23965[D loss: 0.423434, acc: 63.28%, op_acc: 39.84%] [G loss: 1.079642]\n",
      "epoch:30 step:23966[D loss: 0.424877, acc: 56.25%, op_acc: 45.31%] [G loss: 0.785588]\n",
      "epoch:30 step:23967[D loss: 0.439686, acc: 58.59%, op_acc: 32.81%] [G loss: 1.049909]\n",
      "epoch:30 step:23968[D loss: 0.393155, acc: 65.62%, op_acc: 44.53%] [G loss: 1.021428]\n",
      "epoch:30 step:23969[D loss: 0.427093, acc: 63.28%, op_acc: 36.72%] [G loss: 1.090822]\n",
      "epoch:30 step:23970[D loss: 0.383213, acc: 67.97%, op_acc: 48.44%] [G loss: 1.069503]\n",
      "epoch:30 step:23971[D loss: 0.413501, acc: 61.72%, op_acc: 42.19%] [G loss: 1.067314]\n",
      "epoch:30 step:23972[D loss: 0.436755, acc: 59.38%, op_acc: 38.28%] [G loss: 1.039341]\n",
      "epoch:30 step:23973[D loss: 0.384869, acc: 64.84%, op_acc: 46.09%] [G loss: 1.155958]\n",
      "epoch:30 step:23974[D loss: 0.392198, acc: 66.41%, op_acc: 45.31%] [G loss: 0.871166]\n",
      "epoch:30 step:23975[D loss: 0.346404, acc: 71.88%, op_acc: 49.22%] [G loss: 1.050654]\n",
      "epoch:30 step:23976[D loss: 0.383787, acc: 64.06%, op_acc: 47.66%] [G loss: 0.972262]\n",
      "epoch:30 step:23977[D loss: 0.418826, acc: 70.31%, op_acc: 35.94%] [G loss: 1.225250]\n",
      "epoch:30 step:23978[D loss: 0.375168, acc: 74.22%, op_acc: 45.31%] [G loss: 1.023982]\n",
      "epoch:30 step:23979[D loss: 0.426750, acc: 59.38%, op_acc: 41.41%] [G loss: 1.090341]\n",
      "epoch:30 step:23980[D loss: 0.433044, acc: 58.59%, op_acc: 38.28%] [G loss: 0.717085]\n",
      "epoch:30 step:23981[D loss: 0.417989, acc: 57.81%, op_acc: 42.19%] [G loss: 0.886434]\n",
      "epoch:30 step:23982[D loss: 0.485885, acc: 49.22%, op_acc: 32.03%] [G loss: 0.851783]\n",
      "epoch:30 step:23983[D loss: 0.446050, acc: 55.47%, op_acc: 42.97%] [G loss: 0.719005]\n",
      "epoch:30 step:23984[D loss: 0.441438, acc: 58.59%, op_acc: 38.28%] [G loss: 1.045421]\n",
      "epoch:30 step:23985[D loss: 0.333570, acc: 72.66%, op_acc: 49.22%] [G loss: 0.972344]\n",
      "epoch:30 step:23986[D loss: 0.382702, acc: 60.94%, op_acc: 47.66%] [G loss: 1.110920]\n",
      "epoch:30 step:23987[D loss: 0.418165, acc: 64.06%, op_acc: 38.28%] [G loss: 0.985230]\n",
      "epoch:30 step:23988[D loss: 0.418783, acc: 56.25%, op_acc: 44.53%] [G loss: 0.788230]\n",
      "epoch:30 step:23989[D loss: 0.386906, acc: 69.53%, op_acc: 37.50%] [G loss: 1.077373]\n",
      "epoch:30 step:23990[D loss: 0.463747, acc: 57.03%, op_acc: 38.28%] [G loss: 1.082490]\n",
      "epoch:30 step:23991[D loss: 0.416317, acc: 59.38%, op_acc: 42.97%] [G loss: 0.906668]\n",
      "epoch:30 step:23992[D loss: 0.411888, acc: 65.62%, op_acc: 38.28%] [G loss: 0.974620]\n",
      "epoch:30 step:23993[D loss: 0.386262, acc: 67.97%, op_acc: 39.06%] [G loss: 0.984060]\n",
      "epoch:30 step:23994[D loss: 0.354944, acc: 68.75%, op_acc: 52.34%] [G loss: 0.829727]\n",
      "epoch:30 step:23995[D loss: 0.386262, acc: 68.75%, op_acc: 49.22%] [G loss: 1.249637]\n",
      "epoch:30 step:23996[D loss: 0.412967, acc: 64.84%, op_acc: 40.62%] [G loss: 1.131133]\n",
      "epoch:30 step:23997[D loss: 0.389408, acc: 64.06%, op_acc: 49.22%] [G loss: 1.235152]\n",
      "epoch:30 step:23998[D loss: 0.390978, acc: 67.97%, op_acc: 46.09%] [G loss: 1.178997]\n",
      "epoch:30 step:23999[D loss: 0.401739, acc: 65.62%, op_acc: 43.75%] [G loss: 1.037854]\n",
      "epoch:30 step:24000[D loss: 0.400014, acc: 64.06%, op_acc: 43.75%] [G loss: 1.091058]\n",
      "epoch:30 step:24001[D loss: 0.425806, acc: 61.72%, op_acc: 46.88%] [G loss: 1.207458]\n",
      "epoch:30 step:24002[D loss: 0.438153, acc: 55.47%, op_acc: 39.84%] [G loss: 0.759125]\n",
      "epoch:30 step:24003[D loss: 0.428290, acc: 60.16%, op_acc: 42.19%] [G loss: 1.198119]\n",
      "epoch:30 step:24004[D loss: 0.376342, acc: 68.75%, op_acc: 43.75%] [G loss: 1.094252]\n",
      "epoch:30 step:24005[D loss: 0.458132, acc: 58.59%, op_acc: 41.41%] [G loss: 0.615644]\n",
      "epoch:30 step:24006[D loss: 0.351164, acc: 71.09%, op_acc: 48.44%] [G loss: 0.949113]\n",
      "epoch:30 step:24007[D loss: 0.401114, acc: 67.19%, op_acc: 43.75%] [G loss: 0.662789]\n",
      "epoch:30 step:24008[D loss: 0.401508, acc: 71.09%, op_acc: 36.72%] [G loss: 0.703080]\n",
      "epoch:30 step:24009[D loss: 0.356646, acc: 73.44%, op_acc: 46.09%] [G loss: 0.828821]\n",
      "epoch:30 step:24010[D loss: 0.373556, acc: 65.62%, op_acc: 45.31%] [G loss: 1.172517]\n",
      "epoch:30 step:24011[D loss: 0.384964, acc: 67.19%, op_acc: 42.19%] [G loss: 0.642573]\n",
      "epoch:30 step:24012[D loss: 0.389004, acc: 67.19%, op_acc: 41.41%] [G loss: 0.760313]\n",
      "epoch:30 step:24013[D loss: 0.385800, acc: 69.53%, op_acc: 44.53%] [G loss: 0.719919]\n",
      "epoch:30 step:24014[D loss: 0.455245, acc: 57.81%, op_acc: 32.03%] [G loss: 0.731439]\n",
      "epoch:30 step:24015[D loss: 0.401952, acc: 61.72%, op_acc: 43.75%] [G loss: 0.835887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24016[D loss: 0.417749, acc: 60.16%, op_acc: 42.97%] [G loss: 1.018615]\n",
      "epoch:30 step:24017[D loss: 0.366533, acc: 71.09%, op_acc: 42.19%] [G loss: 1.114481]\n",
      "epoch:30 step:24018[D loss: 0.357896, acc: 69.53%, op_acc: 53.12%] [G loss: 1.047325]\n",
      "epoch:30 step:24019[D loss: 0.386316, acc: 67.97%, op_acc: 43.75%] [G loss: 0.950742]\n",
      "epoch:30 step:24020[D loss: 0.353762, acc: 72.66%, op_acc: 50.78%] [G loss: 1.093174]\n",
      "epoch:30 step:24021[D loss: 0.377490, acc: 69.53%, op_acc: 41.41%] [G loss: 1.022412]\n",
      "epoch:30 step:24022[D loss: 0.349752, acc: 74.22%, op_acc: 42.97%] [G loss: 1.012296]\n",
      "epoch:30 step:24023[D loss: 0.367296, acc: 72.66%, op_acc: 46.09%] [G loss: 1.014167]\n",
      "epoch:30 step:24024[D loss: 0.384426, acc: 66.41%, op_acc: 40.62%] [G loss: 1.283873]\n",
      "epoch:30 step:24025[D loss: 0.412202, acc: 63.28%, op_acc: 46.88%] [G loss: 1.142174]\n",
      "epoch:30 step:24026[D loss: 0.388779, acc: 68.75%, op_acc: 39.84%] [G loss: 1.012399]\n",
      "epoch:30 step:24027[D loss: 0.360868, acc: 67.19%, op_acc: 50.00%] [G loss: 1.136323]\n",
      "epoch:30 step:24028[D loss: 0.346486, acc: 78.12%, op_acc: 50.00%] [G loss: 1.167694]\n",
      "epoch:30 step:24029[D loss: 0.319081, acc: 86.72%, op_acc: 47.66%] [G loss: 0.807661]\n",
      "epoch:30 step:24030[D loss: 0.408519, acc: 67.19%, op_acc: 42.19%] [G loss: 1.255034]\n",
      "epoch:30 step:24031[D loss: 0.430073, acc: 58.59%, op_acc: 39.06%] [G loss: 1.285070]\n",
      "epoch:30 step:24032[D loss: 0.364451, acc: 67.97%, op_acc: 47.66%] [G loss: 1.313115]\n",
      "epoch:30 step:24033[D loss: 0.317802, acc: 78.12%, op_acc: 53.91%] [G loss: 1.451862]\n",
      "epoch:30 step:24034[D loss: 0.405635, acc: 67.97%, op_acc: 41.41%] [G loss: 1.378480]\n",
      "epoch:30 step:24035[D loss: 0.344157, acc: 72.66%, op_acc: 46.88%] [G loss: 1.137130]\n",
      "epoch:30 step:24036[D loss: 0.363865, acc: 70.31%, op_acc: 50.00%] [G loss: 1.169348]\n",
      "epoch:30 step:24037[D loss: 0.361805, acc: 71.88%, op_acc: 46.09%] [G loss: 1.156565]\n",
      "epoch:30 step:24038[D loss: 0.347882, acc: 74.22%, op_acc: 50.00%] [G loss: 1.058055]\n",
      "epoch:30 step:24039[D loss: 0.386697, acc: 66.41%, op_acc: 50.00%] [G loss: 1.119376]\n",
      "epoch:30 step:24040[D loss: 0.342023, acc: 79.69%, op_acc: 43.75%] [G loss: 1.175825]\n",
      "epoch:30 step:24041[D loss: 0.359095, acc: 70.31%, op_acc: 47.66%] [G loss: 1.197268]\n",
      "epoch:30 step:24042[D loss: 0.345735, acc: 77.34%, op_acc: 47.66%] [G loss: 1.150090]\n",
      "epoch:30 step:24043[D loss: 0.321169, acc: 78.12%, op_acc: 51.56%] [G loss: 1.261915]\n",
      "epoch:30 step:24044[D loss: 0.352098, acc: 75.78%, op_acc: 43.75%] [G loss: 1.250075]\n",
      "epoch:30 step:24045[D loss: 0.328632, acc: 78.91%, op_acc: 50.00%] [G loss: 0.717497]\n",
      "epoch:30 step:24046[D loss: 0.432508, acc: 61.72%, op_acc: 39.06%] [G loss: 1.259058]\n",
      "epoch:30 step:24047[D loss: 0.409332, acc: 68.75%, op_acc: 41.41%] [G loss: 1.440730]\n",
      "epoch:30 step:24048[D loss: 0.354163, acc: 72.66%, op_acc: 47.66%] [G loss: 1.563044]\n",
      "epoch:30 step:24049[D loss: 0.357141, acc: 75.00%, op_acc: 44.53%] [G loss: 1.453984]\n",
      "epoch:30 step:24050[D loss: 0.357082, acc: 67.97%, op_acc: 44.53%] [G loss: 1.370119]\n",
      "epoch:30 step:24051[D loss: 0.395944, acc: 67.19%, op_acc: 48.44%] [G loss: 1.509709]\n",
      "epoch:30 step:24052[D loss: 0.386417, acc: 79.69%, op_acc: 42.97%] [G loss: 1.354419]\n",
      "epoch:30 step:24053[D loss: 0.317227, acc: 82.81%, op_acc: 47.66%] [G loss: 1.499137]\n",
      "epoch:30 step:24054[D loss: 0.364239, acc: 75.78%, op_acc: 43.75%] [G loss: 1.393370]\n",
      "epoch:30 step:24055[D loss: 0.330079, acc: 75.78%, op_acc: 51.56%] [G loss: 1.384101]\n",
      "epoch:30 step:24056[D loss: 0.361426, acc: 67.97%, op_acc: 46.88%] [G loss: 1.365389]\n",
      "epoch:30 step:24057[D loss: 0.364564, acc: 69.53%, op_acc: 46.88%] [G loss: 1.482068]\n",
      "epoch:30 step:24058[D loss: 0.330902, acc: 85.16%, op_acc: 42.19%] [G loss: 1.271822]\n",
      "epoch:30 step:24059[D loss: 0.343847, acc: 74.22%, op_acc: 46.88%] [G loss: 1.339962]\n",
      "epoch:30 step:24060[D loss: 0.313228, acc: 79.69%, op_acc: 46.88%] [G loss: 1.143143]\n",
      "epoch:30 step:24061[D loss: 0.366284, acc: 71.88%, op_acc: 40.62%] [G loss: 1.340273]\n",
      "epoch:30 step:24062[D loss: 0.363175, acc: 74.22%, op_acc: 41.41%] [G loss: 0.438830]\n",
      "epoch:30 step:24063[D loss: 0.424397, acc: 58.59%, op_acc: 40.62%] [G loss: 1.429184]\n",
      "epoch:30 step:24064[D loss: 0.484584, acc: 50.78%, op_acc: 38.28%] [G loss: 1.249381]\n",
      "epoch:30 step:24065[D loss: 0.469250, acc: 53.91%, op_acc: 41.41%] [G loss: 1.247657]\n",
      "epoch:30 step:24066[D loss: 0.395140, acc: 67.97%, op_acc: 42.19%] [G loss: 1.314359]\n",
      "epoch:30 step:24067[D loss: 0.399727, acc: 65.62%, op_acc: 44.53%] [G loss: 1.109938]\n",
      "epoch:30 step:24068[D loss: 0.450714, acc: 63.28%, op_acc: 42.97%] [G loss: 0.797757]\n",
      "epoch:30 step:24069[D loss: 0.491262, acc: 52.34%, op_acc: 40.62%] [G loss: 0.848214]\n",
      "epoch:30 step:24070[D loss: 0.484579, acc: 54.69%, op_acc: 39.06%] [G loss: 1.277761]\n",
      "epoch:30 step:24071[D loss: 0.482809, acc: 50.78%, op_acc: 35.16%] [G loss: 1.240795]\n",
      "epoch:30 step:24072[D loss: 0.448845, acc: 60.94%, op_acc: 36.72%] [G loss: 1.070964]\n",
      "epoch:30 step:24073[D loss: 0.442547, acc: 56.25%, op_acc: 36.72%] [G loss: 0.815676]\n",
      "epoch:30 step:24074[D loss: 0.452622, acc: 52.34%, op_acc: 42.97%] [G loss: 0.999431]\n",
      "epoch:30 step:24075[D loss: 0.416623, acc: 56.25%, op_acc: 43.75%] [G loss: 1.039030]\n",
      "epoch:30 step:24076[D loss: 0.423596, acc: 60.94%, op_acc: 49.22%] [G loss: 1.114407]\n",
      "epoch:30 step:24077[D loss: 0.412822, acc: 60.94%, op_acc: 44.53%] [G loss: 1.135714]\n",
      "epoch:30 step:24078[D loss: 0.411033, acc: 59.38%, op_acc: 46.09%] [G loss: 1.040775]\n",
      "epoch:30 step:24079[D loss: 0.389086, acc: 67.97%, op_acc: 43.75%] [G loss: 0.895058]\n",
      "epoch:30 step:24080[D loss: 0.395881, acc: 68.75%, op_acc: 40.62%] [G loss: 0.949467]\n",
      "epoch:30 step:24081[D loss: 0.400584, acc: 66.41%, op_acc: 40.62%] [G loss: 0.942632]\n",
      "epoch:30 step:24082[D loss: 0.352412, acc: 75.78%, op_acc: 39.84%] [G loss: 0.981721]\n",
      "epoch:30 step:24083[D loss: 0.403878, acc: 55.47%, op_acc: 44.53%] [G loss: 0.925314]\n",
      "epoch:30 step:24084[D loss: 0.429949, acc: 56.25%, op_acc: 41.41%] [G loss: 1.025860]\n",
      "epoch:30 step:24085[D loss: 0.414166, acc: 62.50%, op_acc: 44.53%] [G loss: 1.184231]\n",
      "epoch:30 step:24086[D loss: 0.421304, acc: 61.72%, op_acc: 39.06%] [G loss: 1.193740]\n",
      "epoch:30 step:24087[D loss: 0.432701, acc: 60.94%, op_acc: 42.97%] [G loss: 1.080394]\n",
      "epoch:30 step:24088[D loss: 0.354200, acc: 76.56%, op_acc: 46.88%] [G loss: 0.929262]\n",
      "epoch:30 step:24089[D loss: 0.331876, acc: 78.12%, op_acc: 41.41%] [G loss: 0.982872]\n",
      "epoch:30 step:24090[D loss: 0.375251, acc: 69.53%, op_acc: 47.66%] [G loss: 1.005883]\n",
      "epoch:30 step:24091[D loss: 0.351550, acc: 71.09%, op_acc: 46.09%] [G loss: 1.169269]\n",
      "epoch:30 step:24092[D loss: 0.410547, acc: 57.81%, op_acc: 46.09%] [G loss: 1.089922]\n",
      "epoch:30 step:24093[D loss: 0.432438, acc: 52.34%, op_acc: 35.94%] [G loss: 0.934356]\n",
      "epoch:30 step:24094[D loss: 0.414349, acc: 61.72%, op_acc: 46.09%] [G loss: 1.000898]\n",
      "epoch:30 step:24095[D loss: 0.406585, acc: 69.53%, op_acc: 39.06%] [G loss: 1.008872]\n",
      "epoch:30 step:24096[D loss: 0.426492, acc: 64.84%, op_acc: 37.50%] [G loss: 1.085927]\n",
      "epoch:30 step:24097[D loss: 0.367737, acc: 71.88%, op_acc: 42.19%] [G loss: 1.079306]\n",
      "epoch:30 step:24098[D loss: 0.405084, acc: 67.19%, op_acc: 42.97%] [G loss: 0.797941]\n",
      "epoch:30 step:24099[D loss: 0.424853, acc: 64.06%, op_acc: 39.06%] [G loss: 0.574384]\n",
      "epoch:30 step:24100[D loss: 0.406876, acc: 61.72%, op_acc: 47.66%] [G loss: 0.708473]\n",
      "epoch:30 step:24101[D loss: 0.373579, acc: 71.88%, op_acc: 42.97%] [G loss: 1.272253]\n",
      "epoch:30 step:24102[D loss: 0.444062, acc: 56.25%, op_acc: 43.75%] [G loss: 0.812763]\n",
      "epoch:30 step:24103[D loss: 0.430392, acc: 62.50%, op_acc: 37.50%] [G loss: 1.344409]\n",
      "epoch:30 step:24104[D loss: 0.389672, acc: 65.62%, op_acc: 46.09%] [G loss: 0.643603]\n",
      "epoch:30 step:24105[D loss: 0.373958, acc: 70.31%, op_acc: 46.09%] [G loss: 1.225500]\n",
      "epoch:30 step:24106[D loss: 0.413739, acc: 64.84%, op_acc: 35.94%] [G loss: 0.620182]\n",
      "epoch:30 step:24107[D loss: 0.387219, acc: 75.00%, op_acc: 39.06%] [G loss: 0.775634]\n",
      "epoch:30 step:24108[D loss: 0.383929, acc: 67.19%, op_acc: 42.19%] [G loss: 0.783239]\n",
      "epoch:30 step:24109[D loss: 0.377304, acc: 68.75%, op_acc: 46.88%] [G loss: 0.637687]\n",
      "epoch:30 step:24110[D loss: 0.423960, acc: 63.28%, op_acc: 41.41%] [G loss: 0.842708]\n",
      "epoch:30 step:24111[D loss: 0.415563, acc: 70.31%, op_acc: 39.06%] [G loss: 1.186124]\n",
      "epoch:30 step:24112[D loss: 0.372242, acc: 67.19%, op_acc: 51.56%] [G loss: 1.280053]\n",
      "epoch:30 step:24113[D loss: 0.427465, acc: 60.94%, op_acc: 44.53%] [G loss: 0.870889]\n",
      "epoch:30 step:24114[D loss: 0.380556, acc: 70.31%, op_acc: 40.62%] [G loss: 1.111112]\n",
      "epoch:30 step:24115[D loss: 0.394315, acc: 70.31%, op_acc: 40.62%] [G loss: 0.967190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:24116[D loss: 0.404405, acc: 67.19%, op_acc: 41.41%] [G loss: 0.831093]\n",
      "epoch:30 step:24117[D loss: 0.388429, acc: 63.28%, op_acc: 43.75%] [G loss: 0.843847]\n",
      "epoch:30 step:24118[D loss: 0.396168, acc: 62.50%, op_acc: 42.19%] [G loss: 0.817500]\n",
      "epoch:30 step:24119[D loss: 0.407128, acc: 62.50%, op_acc: 44.53%] [G loss: 1.129466]\n",
      "epoch:30 step:24120[D loss: 0.379383, acc: 67.19%, op_acc: 40.62%] [G loss: 1.053646]\n",
      "epoch:30 step:24121[D loss: 0.345824, acc: 71.88%, op_acc: 49.22%] [G loss: 0.982728]\n",
      "epoch:30 step:24122[D loss: 0.456795, acc: 56.25%, op_acc: 38.28%] [G loss: 1.132402]\n",
      "epoch:30 step:24123[D loss: 0.371243, acc: 72.66%, op_acc: 46.88%] [G loss: 0.883053]\n",
      "epoch:30 step:24124[D loss: 0.460784, acc: 60.94%, op_acc: 35.94%] [G loss: 0.761109]\n",
      "epoch:30 step:24125[D loss: 0.375513, acc: 73.44%, op_acc: 45.31%] [G loss: 0.877210]\n",
      "epoch:30 step:24126[D loss: 0.446796, acc: 54.69%, op_acc: 42.19%] [G loss: 0.984942]\n",
      "epoch:30 step:24127[D loss: 0.378390, acc: 67.97%, op_acc: 49.22%] [G loss: 1.147728]\n",
      "epoch:30 step:24128[D loss: 0.360302, acc: 72.66%, op_acc: 50.00%] [G loss: 0.920593]\n",
      "epoch:30 step:24129[D loss: 0.416296, acc: 59.38%, op_acc: 46.09%] [G loss: 0.872420]\n",
      "epoch:30 step:24130[D loss: 0.417441, acc: 65.62%, op_acc: 35.94%] [G loss: 0.888551]\n",
      "epoch:30 step:24131[D loss: 0.438612, acc: 62.50%, op_acc: 43.75%] [G loss: 1.013628]\n",
      "epoch:30 step:24132[D loss: 0.391276, acc: 65.62%, op_acc: 42.19%] [G loss: 1.103335]\n",
      "epoch:30 step:24133[D loss: 0.446992, acc: 61.72%, op_acc: 43.75%] [G loss: 1.194885]\n",
      "epoch:30 step:24134[D loss: 0.341309, acc: 75.78%, op_acc: 52.34%] [G loss: 1.117580]\n",
      "epoch:30 step:24135[D loss: 0.393121, acc: 69.53%, op_acc: 43.75%] [G loss: 1.027299]\n",
      "epoch:30 step:24136[D loss: 0.441628, acc: 57.81%, op_acc: 40.62%] [G loss: 1.053336]\n",
      "epoch:30 step:24137[D loss: 0.449122, acc: 55.47%, op_acc: 42.97%] [G loss: 0.940303]\n",
      "epoch:30 step:24138[D loss: 0.412392, acc: 59.38%, op_acc: 48.44%] [G loss: 1.065791]\n",
      "epoch:30 step:24139[D loss: 0.389024, acc: 60.16%, op_acc: 39.84%] [G loss: 1.128329]\n",
      "epoch:30 step:24140[D loss: 0.386899, acc: 64.06%, op_acc: 49.22%] [G loss: 1.122036]\n",
      "epoch:30 step:24141[D loss: 0.364458, acc: 69.53%, op_acc: 50.78%] [G loss: 1.147415]\n",
      "epoch:30 step:24142[D loss: 0.354726, acc: 73.44%, op_acc: 45.31%] [G loss: 1.271644]\n",
      "epoch:30 step:24143[D loss: 0.446549, acc: 56.25%, op_acc: 46.09%] [G loss: 1.080344]\n",
      "epoch:30 step:24144[D loss: 0.392937, acc: 66.41%, op_acc: 43.75%] [G loss: 1.229118]\n",
      "epoch:30 step:24145[D loss: 0.419558, acc: 63.28%, op_acc: 38.28%] [G loss: 1.097144]\n",
      "epoch:30 step:24146[D loss: 0.420013, acc: 60.16%, op_acc: 43.75%] [G loss: 1.158210]\n",
      "epoch:30 step:24147[D loss: 0.415672, acc: 61.72%, op_acc: 39.84%] [G loss: 1.136189]\n",
      "epoch:30 step:24148[D loss: 0.405446, acc: 65.62%, op_acc: 42.97%] [G loss: 1.312288]\n",
      "epoch:30 step:24149[D loss: 0.402055, acc: 62.50%, op_acc: 40.62%] [G loss: 1.138500]\n",
      "epoch:30 step:24150[D loss: 0.356193, acc: 73.44%, op_acc: 44.53%] [G loss: 1.260113]\n",
      "epoch:30 step:24151[D loss: 0.359863, acc: 73.44%, op_acc: 47.66%] [G loss: 1.169755]\n",
      "epoch:30 step:24152[D loss: 0.381850, acc: 67.19%, op_acc: 46.09%] [G loss: 1.050478]\n",
      "epoch:30 step:24153[D loss: 0.359391, acc: 71.09%, op_acc: 48.44%] [G loss: 1.195251]\n",
      "epoch:30 step:24154[D loss: 0.449800, acc: 59.38%, op_acc: 37.50%] [G loss: 1.146971]\n",
      "epoch:30 step:24155[D loss: 0.365934, acc: 71.88%, op_acc: 46.88%] [G loss: 1.263589]\n",
      "epoch:30 step:24156[D loss: 0.290893, acc: 83.59%, op_acc: 46.88%] [G loss: 0.802966]\n",
      "epoch:30 step:24157[D loss: 0.445154, acc: 57.03%, op_acc: 39.84%] [G loss: 1.391341]\n",
      "epoch:30 step:24158[D loss: 0.415553, acc: 63.28%, op_acc: 37.50%] [G loss: 1.418453]\n",
      "epoch:30 step:24159[D loss: 0.343130, acc: 72.66%, op_acc: 47.66%] [G loss: 0.989892]\n",
      "epoch:30 step:24160[D loss: 0.413687, acc: 64.06%, op_acc: 41.41%] [G loss: 1.094578]\n",
      "epoch:30 step:24161[D loss: 0.396264, acc: 63.28%, op_acc: 46.09%] [G loss: 1.479689]\n",
      "epoch:30 step:24162[D loss: 0.407106, acc: 65.62%, op_acc: 43.75%] [G loss: 1.279114]\n",
      "epoch:30 step:24163[D loss: 0.438621, acc: 55.47%, op_acc: 38.28%] [G loss: 1.336874]\n",
      "epoch:30 step:24164[D loss: 0.447740, acc: 58.59%, op_acc: 33.59%] [G loss: 1.285201]\n",
      "epoch:30 step:24165[D loss: 0.394781, acc: 67.97%, op_acc: 41.41%] [G loss: 1.259341]\n",
      "epoch:30 step:24166[D loss: 0.386998, acc: 68.75%, op_acc: 39.84%] [G loss: 1.132452]\n",
      "epoch:30 step:24167[D loss: 0.371017, acc: 66.41%, op_acc: 46.09%] [G loss: 1.271120]\n",
      "epoch:30 step:24168[D loss: 0.421213, acc: 64.06%, op_acc: 44.53%] [G loss: 1.342358]\n",
      "epoch:30 step:24169[D loss: 0.380084, acc: 64.06%, op_acc: 43.75%] [G loss: 1.253650]\n",
      "epoch:30 step:24170[D loss: 0.340355, acc: 72.66%, op_acc: 50.00%] [G loss: 1.284786]\n",
      "epoch:30 step:24171[D loss: 0.372795, acc: 75.78%, op_acc: 42.97%] [G loss: 1.308128]\n",
      "epoch:30 step:24172[D loss: 0.388407, acc: 72.66%, op_acc: 48.44%] [G loss: 1.172730]\n",
      "epoch:30 step:24173[D loss: 0.386613, acc: 75.00%, op_acc: 46.09%] [G loss: 1.302659]\n",
      "epoch:30 step:24174[D loss: 0.340429, acc: 75.00%, op_acc: 51.56%] [G loss: 1.294731]\n",
      "epoch:30 step:24175[D loss: 0.357526, acc: 71.88%, op_acc: 50.00%] [G loss: 1.215575]\n",
      "epoch:30 step:24176[D loss: 0.373425, acc: 71.88%, op_acc: 46.09%] [G loss: 1.444357]\n",
      "epoch:30 step:24177[D loss: 0.357078, acc: 78.91%, op_acc: 47.66%] [G loss: 1.267609]\n",
      "epoch:30 step:24178[D loss: 0.339734, acc: 78.12%, op_acc: 50.00%] [G loss: 1.332283]\n",
      "epoch:30 step:24179[D loss: 0.410463, acc: 63.28%, op_acc: 52.34%] [G loss: 1.290812]\n",
      "epoch:30 step:24180[D loss: 0.385617, acc: 68.75%, op_acc: 50.78%] [G loss: 1.346442]\n",
      "epoch:30 step:24181[D loss: 0.388847, acc: 72.66%, op_acc: 39.06%] [G loss: 1.292482]\n",
      "epoch:30 step:24182[D loss: 0.374100, acc: 71.88%, op_acc: 41.41%] [G loss: 0.833866]\n",
      "epoch:30 step:24183[D loss: 0.375594, acc: 69.53%, op_acc: 42.19%] [G loss: 1.102349]\n",
      "epoch:30 step:24184[D loss: 0.353013, acc: 75.78%, op_acc: 44.53%] [G loss: 1.414973]\n",
      "epoch:30 step:24185[D loss: 0.407832, acc: 64.84%, op_acc: 46.88%] [G loss: 1.300972]\n",
      "epoch:30 step:24186[D loss: 0.343066, acc: 71.88%, op_acc: 53.91%] [G loss: 0.639414]\n",
      "epoch:30 step:24187[D loss: 0.478068, acc: 51.56%, op_acc: 39.84%] [G loss: 1.274848]\n",
      "epoch:30 step:24188[D loss: 0.389618, acc: 60.16%, op_acc: 46.09%] [G loss: 1.087738]\n",
      "epoch:30 step:24189[D loss: 0.381553, acc: 67.19%, op_acc: 42.19%] [G loss: 0.956921]\n",
      "epoch:30 step:24190[D loss: 0.399062, acc: 63.28%, op_acc: 41.41%] [G loss: 0.831130]\n",
      "epoch:30 step:24191[D loss: 0.434806, acc: 58.59%, op_acc: 42.97%] [G loss: 1.479791]\n",
      "epoch:30 step:24192[D loss: 0.473147, acc: 53.12%, op_acc: 45.31%] [G loss: 1.291583]\n",
      "epoch:30 step:24193[D loss: 0.486913, acc: 53.12%, op_acc: 36.72%] [G loss: 1.193551]\n",
      "epoch:30 step:24194[D loss: 0.399517, acc: 62.50%, op_acc: 42.97%] [G loss: 1.071243]\n",
      "epoch:30 step:24195[D loss: 0.380348, acc: 73.44%, op_acc: 42.19%] [G loss: 1.073739]\n",
      "epoch:30 step:24196[D loss: 0.412225, acc: 66.41%, op_acc: 37.50%] [G loss: 1.039266]\n",
      "epoch:30 step:24197[D loss: 0.409813, acc: 63.28%, op_acc: 39.84%] [G loss: 0.955797]\n",
      "epoch:30 step:24198[D loss: 0.456097, acc: 59.38%, op_acc: 36.72%] [G loss: 0.934316]\n",
      "epoch:30 step:24199[D loss: 0.391505, acc: 66.41%, op_acc: 42.19%] [G loss: 1.155422]\n",
      "epoch:30 step:24200[D loss: 0.443522, acc: 53.91%, op_acc: 48.44%] [G loss: 1.141748]\n",
      "epoch:30 step:24201[D loss: 0.420106, acc: 60.16%, op_acc: 45.31%] [G loss: 0.951005]\n",
      "epoch:30 step:24202[D loss: 0.452200, acc: 59.38%, op_acc: 36.72%] [G loss: 1.085082]\n",
      "epoch:30 step:24203[D loss: 0.437846, acc: 57.03%, op_acc: 35.94%] [G loss: 1.056011]\n",
      "epoch:30 step:24204[D loss: 0.380956, acc: 62.50%, op_acc: 44.53%] [G loss: 1.017628]\n",
      "epoch:30 step:24205[D loss: 0.407199, acc: 68.75%, op_acc: 40.62%] [G loss: 1.067495]\n",
      "epoch:30 step:24206[D loss: 0.415401, acc: 64.06%, op_acc: 39.06%] [G loss: 1.034813]\n",
      "epoch:30 step:24207[D loss: 0.403433, acc: 70.31%, op_acc: 43.75%] [G loss: 0.915004]\n",
      "epoch:30 step:24208[D loss: 0.355649, acc: 73.44%, op_acc: 50.78%] [G loss: 0.998090]\n",
      "epoch:30 step:24209[D loss: 0.393710, acc: 64.84%, op_acc: 43.75%] [G loss: 1.124583]\n",
      "epoch:30 step:24210[D loss: 0.428036, acc: 60.94%, op_acc: 36.72%] [G loss: 0.978914]\n",
      "epoch:30 step:24211[D loss: 0.412342, acc: 69.53%, op_acc: 35.94%] [G loss: 0.833896]\n",
      "epoch:31 step:24212[D loss: 0.353302, acc: 74.22%, op_acc: 47.66%] [G loss: 1.131743]\n",
      "epoch:31 step:24213[D loss: 0.407766, acc: 62.50%, op_acc: 46.09%] [G loss: 1.077238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24214[D loss: 0.418456, acc: 58.59%, op_acc: 46.09%] [G loss: 0.938584]\n",
      "epoch:31 step:24215[D loss: 0.425304, acc: 61.72%, op_acc: 43.75%] [G loss: 1.072690]\n",
      "epoch:31 step:24216[D loss: 0.437668, acc: 56.25%, op_acc: 40.62%] [G loss: 1.161427]\n",
      "epoch:31 step:24217[D loss: 0.420580, acc: 65.62%, op_acc: 40.62%] [G loss: 1.088361]\n",
      "epoch:31 step:24218[D loss: 0.361531, acc: 69.53%, op_acc: 46.88%] [G loss: 0.966116]\n",
      "epoch:31 step:24219[D loss: 0.426293, acc: 59.38%, op_acc: 46.88%] [G loss: 0.866029]\n",
      "epoch:31 step:24220[D loss: 0.407894, acc: 64.06%, op_acc: 44.53%] [G loss: 0.861264]\n",
      "epoch:31 step:24221[D loss: 0.412777, acc: 64.06%, op_acc: 41.41%] [G loss: 0.830271]\n",
      "epoch:31 step:24222[D loss: 0.446550, acc: 55.47%, op_acc: 44.53%] [G loss: 0.988882]\n",
      "epoch:31 step:24223[D loss: 0.377314, acc: 70.31%, op_acc: 44.53%] [G loss: 1.157741]\n",
      "epoch:31 step:24224[D loss: 0.390186, acc: 72.66%, op_acc: 40.62%] [G loss: 0.813052]\n",
      "epoch:31 step:24225[D loss: 0.382149, acc: 72.66%, op_acc: 40.62%] [G loss: 0.996646]\n",
      "epoch:31 step:24226[D loss: 0.401396, acc: 64.06%, op_acc: 42.97%] [G loss: 0.862709]\n",
      "epoch:31 step:24227[D loss: 0.368655, acc: 70.31%, op_acc: 48.44%] [G loss: 0.969920]\n",
      "epoch:31 step:24228[D loss: 0.416049, acc: 59.38%, op_acc: 45.31%] [G loss: 0.706917]\n",
      "epoch:31 step:24229[D loss: 0.377356, acc: 67.97%, op_acc: 44.53%] [G loss: 1.091220]\n",
      "epoch:31 step:24230[D loss: 0.341085, acc: 77.34%, op_acc: 48.44%] [G loss: 0.910515]\n",
      "epoch:31 step:24231[D loss: 0.471696, acc: 53.12%, op_acc: 40.62%] [G loss: 0.714509]\n",
      "epoch:31 step:24232[D loss: 0.437375, acc: 60.94%, op_acc: 39.84%] [G loss: 1.040416]\n",
      "epoch:31 step:24233[D loss: 0.391089, acc: 64.84%, op_acc: 48.44%] [G loss: 1.030628]\n",
      "epoch:31 step:24234[D loss: 0.369771, acc: 65.62%, op_acc: 51.56%] [G loss: 0.944054]\n",
      "epoch:31 step:24235[D loss: 0.397382, acc: 69.53%, op_acc: 42.97%] [G loss: 0.851438]\n",
      "epoch:31 step:24236[D loss: 0.418977, acc: 64.06%, op_acc: 40.62%] [G loss: 0.812912]\n",
      "epoch:31 step:24237[D loss: 0.377255, acc: 70.31%, op_acc: 46.88%] [G loss: 0.843160]\n",
      "epoch:31 step:24238[D loss: 0.409421, acc: 62.50%, op_acc: 41.41%] [G loss: 0.955378]\n",
      "epoch:31 step:24239[D loss: 0.337246, acc: 76.56%, op_acc: 48.44%] [G loss: 1.087227]\n",
      "epoch:31 step:24240[D loss: 0.358539, acc: 69.53%, op_acc: 44.53%] [G loss: 1.120209]\n",
      "epoch:31 step:24241[D loss: 0.355808, acc: 71.88%, op_acc: 46.88%] [G loss: 1.177613]\n",
      "epoch:31 step:24242[D loss: 0.347001, acc: 76.56%, op_acc: 43.75%] [G loss: 1.244554]\n",
      "epoch:31 step:24243[D loss: 0.436575, acc: 58.59%, op_acc: 44.53%] [G loss: 1.190068]\n",
      "epoch:31 step:24244[D loss: 0.364583, acc: 67.19%, op_acc: 45.31%] [G loss: 1.058235]\n",
      "epoch:31 step:24245[D loss: 0.383246, acc: 61.72%, op_acc: 44.53%] [G loss: 0.840778]\n",
      "epoch:31 step:24246[D loss: 0.373209, acc: 75.00%, op_acc: 46.09%] [G loss: 0.929780]\n",
      "epoch:31 step:24247[D loss: 0.408290, acc: 62.50%, op_acc: 41.41%] [G loss: 1.044490]\n",
      "epoch:31 step:24248[D loss: 0.381364, acc: 70.31%, op_acc: 46.88%] [G loss: 1.054890]\n",
      "epoch:31 step:24249[D loss: 0.385235, acc: 67.97%, op_acc: 46.88%] [G loss: 1.218265]\n",
      "epoch:31 step:24250[D loss: 0.334020, acc: 76.56%, op_acc: 48.44%] [G loss: 1.038913]\n",
      "epoch:31 step:24251[D loss: 0.385721, acc: 71.88%, op_acc: 42.19%] [G loss: 1.183114]\n",
      "epoch:31 step:24252[D loss: 0.344096, acc: 67.19%, op_acc: 48.44%] [G loss: 1.022241]\n",
      "epoch:31 step:24253[D loss: 0.293837, acc: 83.59%, op_acc: 53.91%] [G loss: 1.199501]\n",
      "epoch:31 step:24254[D loss: 0.414345, acc: 60.94%, op_acc: 39.06%] [G loss: 0.935503]\n",
      "epoch:31 step:24255[D loss: 0.335432, acc: 75.00%, op_acc: 44.53%] [G loss: 1.052773]\n",
      "epoch:31 step:24256[D loss: 0.308483, acc: 80.47%, op_acc: 54.69%] [G loss: 1.150606]\n",
      "epoch:31 step:24257[D loss: 0.377416, acc: 69.53%, op_acc: 41.41%] [G loss: 1.138774]\n",
      "epoch:31 step:24258[D loss: 0.383566, acc: 68.75%, op_acc: 42.19%] [G loss: 1.180749]\n",
      "epoch:31 step:24259[D loss: 0.383941, acc: 75.78%, op_acc: 46.09%] [G loss: 1.083840]\n",
      "epoch:31 step:24260[D loss: 0.370806, acc: 70.31%, op_acc: 42.19%] [G loss: 0.903588]\n",
      "epoch:31 step:24261[D loss: 0.432057, acc: 62.50%, op_acc: 37.50%] [G loss: 0.941247]\n",
      "epoch:31 step:24262[D loss: 0.358845, acc: 72.66%, op_acc: 51.56%] [G loss: 0.986800]\n",
      "epoch:31 step:24263[D loss: 0.403242, acc: 60.94%, op_acc: 41.41%] [G loss: 1.191419]\n",
      "epoch:31 step:24264[D loss: 0.446084, acc: 61.72%, op_acc: 41.41%] [G loss: 1.079328]\n",
      "epoch:31 step:24265[D loss: 0.406135, acc: 67.19%, op_acc: 41.41%] [G loss: 0.997260]\n",
      "epoch:31 step:24266[D loss: 0.360842, acc: 69.53%, op_acc: 46.88%] [G loss: 1.038676]\n",
      "epoch:31 step:24267[D loss: 0.389780, acc: 69.53%, op_acc: 43.75%] [G loss: 1.076545]\n",
      "epoch:31 step:24268[D loss: 0.376074, acc: 70.31%, op_acc: 47.66%] [G loss: 0.968428]\n",
      "epoch:31 step:24269[D loss: 0.394140, acc: 61.72%, op_acc: 46.09%] [G loss: 1.276868]\n",
      "epoch:31 step:24270[D loss: 0.332505, acc: 75.00%, op_acc: 50.78%] [G loss: 1.032448]\n",
      "epoch:31 step:24271[D loss: 0.332600, acc: 78.91%, op_acc: 42.97%] [G loss: 1.323754]\n",
      "epoch:31 step:24272[D loss: 0.389523, acc: 69.53%, op_acc: 46.88%] [G loss: 1.047511]\n",
      "epoch:31 step:24273[D loss: 0.363856, acc: 68.75%, op_acc: 43.75%] [G loss: 1.414119]\n",
      "epoch:31 step:24274[D loss: 0.388721, acc: 65.62%, op_acc: 41.41%] [G loss: 1.283613]\n",
      "epoch:31 step:24275[D loss: 0.365702, acc: 70.31%, op_acc: 50.00%] [G loss: 1.126289]\n",
      "epoch:31 step:24276[D loss: 0.388551, acc: 68.75%, op_acc: 44.53%] [G loss: 1.128687]\n",
      "epoch:31 step:24277[D loss: 0.360720, acc: 75.78%, op_acc: 52.34%] [G loss: 1.455679]\n",
      "epoch:31 step:24278[D loss: 0.379674, acc: 70.31%, op_acc: 44.53%] [G loss: 1.268277]\n",
      "epoch:31 step:24279[D loss: 0.388851, acc: 67.97%, op_acc: 40.62%] [G loss: 0.908537]\n",
      "epoch:31 step:24280[D loss: 0.393692, acc: 63.28%, op_acc: 40.62%] [G loss: 1.305685]\n",
      "epoch:31 step:24281[D loss: 0.413697, acc: 64.06%, op_acc: 44.53%] [G loss: 1.439379]\n",
      "epoch:31 step:24282[D loss: 0.415171, acc: 66.41%, op_acc: 38.28%] [G loss: 1.286421]\n",
      "epoch:31 step:24283[D loss: 0.364086, acc: 72.66%, op_acc: 43.75%] [G loss: 1.242410]\n",
      "epoch:31 step:24284[D loss: 0.397649, acc: 66.41%, op_acc: 42.19%] [G loss: 1.410545]\n",
      "epoch:31 step:24285[D loss: 0.322292, acc: 76.56%, op_acc: 48.44%] [G loss: 1.284182]\n",
      "epoch:31 step:24286[D loss: 0.319590, acc: 78.12%, op_acc: 46.88%] [G loss: 0.865713]\n",
      "epoch:31 step:24287[D loss: 0.331411, acc: 78.91%, op_acc: 43.75%] [G loss: 1.274099]\n",
      "epoch:31 step:24288[D loss: 0.439328, acc: 58.59%, op_acc: 40.62%] [G loss: 0.642686]\n",
      "epoch:31 step:24289[D loss: 0.498703, acc: 53.12%, op_acc: 35.94%] [G loss: 0.821171]\n",
      "epoch:31 step:24290[D loss: 0.451140, acc: 56.25%, op_acc: 40.62%] [G loss: 0.997059]\n",
      "epoch:31 step:24291[D loss: 0.471832, acc: 55.47%, op_acc: 37.50%] [G loss: 0.859683]\n",
      "epoch:31 step:24292[D loss: 0.428050, acc: 60.94%, op_acc: 36.72%] [G loss: 1.060495]\n",
      "epoch:31 step:24293[D loss: 0.431941, acc: 50.78%, op_acc: 45.31%] [G loss: 0.950379]\n",
      "epoch:31 step:24294[D loss: 0.381379, acc: 70.31%, op_acc: 42.19%] [G loss: 1.109998]\n",
      "epoch:31 step:24295[D loss: 0.417093, acc: 65.62%, op_acc: 39.06%] [G loss: 1.096729]\n",
      "epoch:31 step:24296[D loss: 0.422092, acc: 63.28%, op_acc: 33.59%] [G loss: 0.979205]\n",
      "epoch:31 step:24297[D loss: 0.410437, acc: 64.06%, op_acc: 41.41%] [G loss: 1.098887]\n",
      "epoch:31 step:24298[D loss: 0.436323, acc: 56.25%, op_acc: 40.62%] [G loss: 1.062059]\n",
      "epoch:31 step:24299[D loss: 0.411063, acc: 60.94%, op_acc: 37.50%] [G loss: 1.153154]\n",
      "epoch:31 step:24300[D loss: 0.445796, acc: 57.81%, op_acc: 40.62%] [G loss: 1.056147]\n",
      "epoch:31 step:24301[D loss: 0.371560, acc: 71.88%, op_acc: 43.75%] [G loss: 0.936598]\n",
      "epoch:31 step:24302[D loss: 0.425717, acc: 57.81%, op_acc: 45.31%] [G loss: 1.086243]\n",
      "epoch:31 step:24303[D loss: 0.417291, acc: 57.81%, op_acc: 45.31%] [G loss: 1.017279]\n",
      "epoch:31 step:24304[D loss: 0.411580, acc: 63.28%, op_acc: 38.28%] [G loss: 1.197125]\n",
      "epoch:31 step:24305[D loss: 0.354283, acc: 75.00%, op_acc: 41.41%] [G loss: 1.186900]\n",
      "epoch:31 step:24306[D loss: 0.403573, acc: 65.62%, op_acc: 43.75%] [G loss: 0.994832]\n",
      "epoch:31 step:24307[D loss: 0.436458, acc: 56.25%, op_acc: 38.28%] [G loss: 1.019432]\n",
      "epoch:31 step:24308[D loss: 0.434884, acc: 56.25%, op_acc: 42.97%] [G loss: 1.060492]\n",
      "epoch:31 step:24309[D loss: 0.395349, acc: 69.53%, op_acc: 39.06%] [G loss: 1.210253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24310[D loss: 0.409838, acc: 65.62%, op_acc: 41.41%] [G loss: 1.239927]\n",
      "epoch:31 step:24311[D loss: 0.370903, acc: 71.09%, op_acc: 43.75%] [G loss: 1.124799]\n",
      "epoch:31 step:24312[D loss: 0.405669, acc: 65.62%, op_acc: 42.97%] [G loss: 0.882794]\n",
      "epoch:31 step:24313[D loss: 0.439106, acc: 60.94%, op_acc: 41.41%] [G loss: 1.022121]\n",
      "epoch:31 step:24314[D loss: 0.438878, acc: 53.91%, op_acc: 41.41%] [G loss: 0.932511]\n",
      "epoch:31 step:24315[D loss: 0.427604, acc: 60.16%, op_acc: 39.84%] [G loss: 0.843970]\n",
      "epoch:31 step:24316[D loss: 0.405725, acc: 67.19%, op_acc: 43.75%] [G loss: 1.058318]\n",
      "epoch:31 step:24317[D loss: 0.379164, acc: 68.75%, op_acc: 46.09%] [G loss: 1.330670]\n",
      "epoch:31 step:24318[D loss: 0.384515, acc: 67.19%, op_acc: 43.75%] [G loss: 1.191176]\n",
      "epoch:31 step:24319[D loss: 0.424498, acc: 66.41%, op_acc: 42.97%] [G loss: 1.198084]\n",
      "epoch:31 step:24320[D loss: 0.379628, acc: 70.31%, op_acc: 45.31%] [G loss: 1.059435]\n",
      "epoch:31 step:24321[D loss: 0.350401, acc: 75.00%, op_acc: 44.53%] [G loss: 0.954424]\n",
      "epoch:31 step:24322[D loss: 0.414251, acc: 67.97%, op_acc: 39.06%] [G loss: 0.749059]\n",
      "epoch:31 step:24323[D loss: 0.354399, acc: 74.22%, op_acc: 45.31%] [G loss: 0.876771]\n",
      "epoch:31 step:24324[D loss: 0.391585, acc: 67.19%, op_acc: 42.19%] [G loss: 1.138821]\n",
      "epoch:31 step:24325[D loss: 0.396107, acc: 62.50%, op_acc: 43.75%] [G loss: 1.109657]\n",
      "epoch:31 step:24326[D loss: 0.429851, acc: 56.25%, op_acc: 42.19%] [G loss: 0.972689]\n",
      "epoch:31 step:24327[D loss: 0.399492, acc: 65.62%, op_acc: 37.50%] [G loss: 1.282784]\n",
      "epoch:31 step:24328[D loss: 0.390967, acc: 63.28%, op_acc: 43.75%] [G loss: 0.923997]\n",
      "epoch:31 step:24329[D loss: 0.380410, acc: 71.09%, op_acc: 50.00%] [G loss: 0.911293]\n",
      "epoch:31 step:24330[D loss: 0.369762, acc: 71.09%, op_acc: 44.53%] [G loss: 1.177966]\n",
      "epoch:31 step:24331[D loss: 0.437612, acc: 57.81%, op_acc: 35.16%] [G loss: 1.092873]\n",
      "epoch:31 step:24332[D loss: 0.400227, acc: 67.97%, op_acc: 33.59%] [G loss: 1.178779]\n",
      "epoch:31 step:24333[D loss: 0.412834, acc: 63.28%, op_acc: 41.41%] [G loss: 0.852782]\n",
      "epoch:31 step:24334[D loss: 0.432784, acc: 57.81%, op_acc: 35.94%] [G loss: 0.968175]\n",
      "epoch:31 step:24335[D loss: 0.383994, acc: 67.19%, op_acc: 43.75%] [G loss: 1.030476]\n",
      "epoch:31 step:24336[D loss: 0.480079, acc: 52.34%, op_acc: 40.62%] [G loss: 1.069717]\n",
      "epoch:31 step:24337[D loss: 0.408857, acc: 62.50%, op_acc: 43.75%] [G loss: 1.195363]\n",
      "epoch:31 step:24338[D loss: 0.382978, acc: 66.41%, op_acc: 39.84%] [G loss: 0.816957]\n",
      "epoch:31 step:24339[D loss: 0.358562, acc: 70.31%, op_acc: 42.97%] [G loss: 1.320408]\n",
      "epoch:31 step:24340[D loss: 0.418892, acc: 62.50%, op_acc: 39.84%] [G loss: 0.834056]\n",
      "epoch:31 step:24341[D loss: 0.389456, acc: 60.94%, op_acc: 46.09%] [G loss: 1.269785]\n",
      "epoch:31 step:24342[D loss: 0.351872, acc: 71.88%, op_acc: 46.88%] [G loss: 1.139213]\n",
      "epoch:31 step:24343[D loss: 0.407101, acc: 63.28%, op_acc: 45.31%] [G loss: 1.199838]\n",
      "epoch:31 step:24344[D loss: 0.409062, acc: 70.31%, op_acc: 39.84%] [G loss: 0.855199]\n",
      "epoch:31 step:24345[D loss: 0.367479, acc: 78.91%, op_acc: 41.41%] [G loss: 0.750389]\n",
      "epoch:31 step:24346[D loss: 0.412829, acc: 64.84%, op_acc: 43.75%] [G loss: 0.730141]\n",
      "epoch:31 step:24347[D loss: 0.403208, acc: 66.41%, op_acc: 39.06%] [G loss: 1.136177]\n",
      "epoch:31 step:24348[D loss: 0.375661, acc: 64.84%, op_acc: 50.00%] [G loss: 1.043624]\n",
      "epoch:31 step:24349[D loss: 0.444868, acc: 57.81%, op_acc: 37.50%] [G loss: 0.945215]\n",
      "epoch:31 step:24350[D loss: 0.379749, acc: 67.97%, op_acc: 48.44%] [G loss: 0.770422]\n",
      "epoch:31 step:24351[D loss: 0.428778, acc: 60.16%, op_acc: 38.28%] [G loss: 1.158143]\n",
      "epoch:31 step:24352[D loss: 0.423482, acc: 61.72%, op_acc: 42.97%] [G loss: 0.941570]\n",
      "epoch:31 step:24353[D loss: 0.394427, acc: 63.28%, op_acc: 37.50%] [G loss: 1.161661]\n",
      "epoch:31 step:24354[D loss: 0.369130, acc: 69.53%, op_acc: 53.12%] [G loss: 0.796166]\n",
      "epoch:31 step:24355[D loss: 0.398020, acc: 66.41%, op_acc: 43.75%] [G loss: 1.057241]\n",
      "epoch:31 step:24356[D loss: 0.355860, acc: 72.66%, op_acc: 46.09%] [G loss: 0.923016]\n",
      "epoch:31 step:24357[D loss: 0.386048, acc: 64.84%, op_acc: 42.19%] [G loss: 0.938334]\n",
      "epoch:31 step:24358[D loss: 0.381545, acc: 67.19%, op_acc: 52.34%] [G loss: 0.958185]\n",
      "epoch:31 step:24359[D loss: 0.442973, acc: 58.59%, op_acc: 41.41%] [G loss: 0.925030]\n",
      "epoch:31 step:24360[D loss: 0.380268, acc: 67.97%, op_acc: 47.66%] [G loss: 0.983656]\n",
      "epoch:31 step:24361[D loss: 0.361275, acc: 69.53%, op_acc: 46.88%] [G loss: 1.019942]\n",
      "epoch:31 step:24362[D loss: 0.373444, acc: 67.97%, op_acc: 53.12%] [G loss: 1.089254]\n",
      "epoch:31 step:24363[D loss: 0.387610, acc: 64.06%, op_acc: 43.75%] [G loss: 0.929396]\n",
      "epoch:31 step:24364[D loss: 0.414750, acc: 64.06%, op_acc: 48.44%] [G loss: 0.933648]\n",
      "epoch:31 step:24365[D loss: 0.389566, acc: 62.50%, op_acc: 39.84%] [G loss: 0.999642]\n",
      "epoch:31 step:24366[D loss: 0.403246, acc: 68.75%, op_acc: 41.41%] [G loss: 1.053237]\n",
      "epoch:31 step:24367[D loss: 0.386365, acc: 71.88%, op_acc: 46.09%] [G loss: 0.902234]\n",
      "epoch:31 step:24368[D loss: 0.416623, acc: 61.72%, op_acc: 41.41%] [G loss: 0.892137]\n",
      "epoch:31 step:24369[D loss: 0.393780, acc: 64.84%, op_acc: 44.53%] [G loss: 1.038204]\n",
      "epoch:31 step:24370[D loss: 0.392272, acc: 69.53%, op_acc: 42.97%] [G loss: 1.044787]\n",
      "epoch:31 step:24371[D loss: 0.419326, acc: 60.94%, op_acc: 42.97%] [G loss: 0.965821]\n",
      "epoch:31 step:24372[D loss: 0.461654, acc: 50.78%, op_acc: 39.06%] [G loss: 1.027655]\n",
      "epoch:31 step:24373[D loss: 0.427183, acc: 57.81%, op_acc: 47.66%] [G loss: 1.045505]\n",
      "epoch:31 step:24374[D loss: 0.427790, acc: 60.16%, op_acc: 41.41%] [G loss: 1.055815]\n",
      "epoch:31 step:24375[D loss: 0.407415, acc: 66.41%, op_acc: 39.06%] [G loss: 0.985268]\n",
      "epoch:31 step:24376[D loss: 0.328528, acc: 75.78%, op_acc: 50.00%] [G loss: 1.091947]\n",
      "epoch:31 step:24377[D loss: 0.432091, acc: 65.62%, op_acc: 41.41%] [G loss: 0.935059]\n",
      "epoch:31 step:24378[D loss: 0.412008, acc: 58.59%, op_acc: 41.41%] [G loss: 1.019242]\n",
      "epoch:31 step:24379[D loss: 0.377270, acc: 67.19%, op_acc: 47.66%] [G loss: 0.934973]\n",
      "epoch:31 step:24380[D loss: 0.409331, acc: 61.72%, op_acc: 42.19%] [G loss: 1.139158]\n",
      "epoch:31 step:24381[D loss: 0.420277, acc: 53.91%, op_acc: 41.41%] [G loss: 1.147499]\n",
      "epoch:31 step:24382[D loss: 0.378229, acc: 71.88%, op_acc: 39.84%] [G loss: 0.940993]\n",
      "epoch:31 step:24383[D loss: 0.386331, acc: 64.06%, op_acc: 45.31%] [G loss: 1.034215]\n",
      "epoch:31 step:24384[D loss: 0.366092, acc: 76.56%, op_acc: 40.62%] [G loss: 1.029419]\n",
      "epoch:31 step:24385[D loss: 0.426704, acc: 65.62%, op_acc: 39.84%] [G loss: 1.187853]\n",
      "epoch:31 step:24386[D loss: 0.391985, acc: 64.84%, op_acc: 42.19%] [G loss: 0.979060]\n",
      "epoch:31 step:24387[D loss: 0.449803, acc: 54.69%, op_acc: 36.72%] [G loss: 1.065008]\n",
      "epoch:31 step:24388[D loss: 0.370256, acc: 67.19%, op_acc: 40.62%] [G loss: 1.127504]\n",
      "epoch:31 step:24389[D loss: 0.463024, acc: 53.12%, op_acc: 39.84%] [G loss: 1.088306]\n",
      "epoch:31 step:24390[D loss: 0.338897, acc: 74.22%, op_acc: 43.75%] [G loss: 1.114648]\n",
      "epoch:31 step:24391[D loss: 0.385906, acc: 63.28%, op_acc: 46.09%] [G loss: 1.080768]\n",
      "epoch:31 step:24392[D loss: 0.371283, acc: 68.75%, op_acc: 46.09%] [G loss: 0.879540]\n",
      "epoch:31 step:24393[D loss: 0.385217, acc: 63.28%, op_acc: 48.44%] [G loss: 0.806726]\n",
      "epoch:31 step:24394[D loss: 0.353492, acc: 71.09%, op_acc: 50.78%] [G loss: 0.946301]\n",
      "epoch:31 step:24395[D loss: 0.371245, acc: 70.31%, op_acc: 42.97%] [G loss: 1.047046]\n",
      "epoch:31 step:24396[D loss: 0.389330, acc: 73.44%, op_acc: 41.41%] [G loss: 1.094510]\n",
      "epoch:31 step:24397[D loss: 0.393138, acc: 65.62%, op_acc: 42.97%] [G loss: 1.071041]\n",
      "epoch:31 step:24398[D loss: 0.366061, acc: 67.97%, op_acc: 39.06%] [G loss: 1.056210]\n",
      "epoch:31 step:24399[D loss: 0.358759, acc: 76.56%, op_acc: 47.66%] [G loss: 1.016205]\n",
      "epoch:31 step:24400[D loss: 0.406252, acc: 64.06%, op_acc: 39.06%] [G loss: 0.948992]\n",
      "epoch:31 step:24401[D loss: 0.352386, acc: 78.12%, op_acc: 46.88%] [G loss: 1.022361]\n",
      "epoch:31 step:24402[D loss: 0.367283, acc: 71.09%, op_acc: 43.75%] [G loss: 0.975489]\n",
      "epoch:31 step:24403[D loss: 0.394304, acc: 67.19%, op_acc: 43.75%] [G loss: 1.058814]\n",
      "epoch:31 step:24404[D loss: 0.436707, acc: 57.81%, op_acc: 38.28%] [G loss: 1.048099]\n",
      "epoch:31 step:24405[D loss: 0.399261, acc: 70.31%, op_acc: 40.62%] [G loss: 1.192955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24406[D loss: 0.369971, acc: 73.44%, op_acc: 44.53%] [G loss: 0.830327]\n",
      "epoch:31 step:24407[D loss: 0.420416, acc: 58.59%, op_acc: 39.84%] [G loss: 0.863206]\n",
      "epoch:31 step:24408[D loss: 0.421076, acc: 62.50%, op_acc: 39.84%] [G loss: 1.111512]\n",
      "epoch:31 step:24409[D loss: 0.429087, acc: 62.50%, op_acc: 38.28%] [G loss: 1.135856]\n",
      "epoch:31 step:24410[D loss: 0.402350, acc: 62.50%, op_acc: 42.97%] [G loss: 1.144708]\n",
      "epoch:31 step:24411[D loss: 0.403042, acc: 65.62%, op_acc: 43.75%] [G loss: 1.017146]\n",
      "epoch:31 step:24412[D loss: 0.369749, acc: 67.19%, op_acc: 42.19%] [G loss: 1.062687]\n",
      "epoch:31 step:24413[D loss: 0.404160, acc: 61.72%, op_acc: 42.19%] [G loss: 0.968249]\n",
      "epoch:31 step:24414[D loss: 0.418495, acc: 65.62%, op_acc: 41.41%] [G loss: 0.952910]\n",
      "epoch:31 step:24415[D loss: 0.413541, acc: 57.03%, op_acc: 43.75%] [G loss: 0.850888]\n",
      "epoch:31 step:24416[D loss: 0.458572, acc: 58.59%, op_acc: 38.28%] [G loss: 1.130295]\n",
      "epoch:31 step:24417[D loss: 0.379138, acc: 70.31%, op_acc: 46.09%] [G loss: 1.009526]\n",
      "epoch:31 step:24418[D loss: 0.363370, acc: 70.31%, op_acc: 50.00%] [G loss: 0.978418]\n",
      "epoch:31 step:24419[D loss: 0.395415, acc: 70.31%, op_acc: 40.62%] [G loss: 1.067909]\n",
      "epoch:31 step:24420[D loss: 0.353266, acc: 69.53%, op_acc: 48.44%] [G loss: 1.212777]\n",
      "epoch:31 step:24421[D loss: 0.381224, acc: 69.53%, op_acc: 40.62%] [G loss: 1.233196]\n",
      "epoch:31 step:24422[D loss: 0.334152, acc: 75.78%, op_acc: 47.66%] [G loss: 1.126398]\n",
      "epoch:31 step:24423[D loss: 0.367075, acc: 65.62%, op_acc: 48.44%] [G loss: 1.175092]\n",
      "epoch:31 step:24424[D loss: 0.349919, acc: 70.31%, op_acc: 47.66%] [G loss: 1.088023]\n",
      "epoch:31 step:24425[D loss: 0.359802, acc: 75.00%, op_acc: 43.75%] [G loss: 0.967206]\n",
      "epoch:31 step:24426[D loss: 0.372404, acc: 73.44%, op_acc: 38.28%] [G loss: 1.338512]\n",
      "epoch:31 step:24427[D loss: 0.388694, acc: 68.75%, op_acc: 42.97%] [G loss: 1.077469]\n",
      "epoch:31 step:24428[D loss: 0.363628, acc: 74.22%, op_acc: 46.09%] [G loss: 0.937113]\n",
      "epoch:31 step:24429[D loss: 0.407964, acc: 64.06%, op_acc: 45.31%] [G loss: 1.519892]\n",
      "epoch:31 step:24430[D loss: 0.397342, acc: 60.94%, op_acc: 39.06%] [G loss: 1.188048]\n",
      "epoch:31 step:24431[D loss: 0.400809, acc: 67.19%, op_acc: 42.19%] [G loss: 0.883860]\n",
      "epoch:31 step:24432[D loss: 0.377265, acc: 63.28%, op_acc: 44.53%] [G loss: 0.857177]\n",
      "epoch:31 step:24433[D loss: 0.403244, acc: 65.62%, op_acc: 46.88%] [G loss: 1.170346]\n",
      "epoch:31 step:24434[D loss: 0.433208, acc: 65.62%, op_acc: 35.94%] [G loss: 0.971106]\n",
      "epoch:31 step:24435[D loss: 0.407831, acc: 60.94%, op_acc: 39.84%] [G loss: 1.189476]\n",
      "epoch:31 step:24436[D loss: 0.397427, acc: 60.94%, op_acc: 43.75%] [G loss: 1.242898]\n",
      "epoch:31 step:24437[D loss: 0.477751, acc: 50.78%, op_acc: 37.50%] [G loss: 1.000545]\n",
      "epoch:31 step:24438[D loss: 0.413505, acc: 61.72%, op_acc: 43.75%] [G loss: 1.211586]\n",
      "epoch:31 step:24439[D loss: 0.424437, acc: 52.34%, op_acc: 40.62%] [G loss: 1.027074]\n",
      "epoch:31 step:24440[D loss: 0.375941, acc: 64.84%, op_acc: 49.22%] [G loss: 0.999405]\n",
      "epoch:31 step:24441[D loss: 0.408686, acc: 65.62%, op_acc: 42.97%] [G loss: 0.889844]\n",
      "epoch:31 step:24442[D loss: 0.404873, acc: 61.72%, op_acc: 39.84%] [G loss: 1.123172]\n",
      "epoch:31 step:24443[D loss: 0.415727, acc: 60.94%, op_acc: 43.75%] [G loss: 0.980664]\n",
      "epoch:31 step:24444[D loss: 0.378601, acc: 65.62%, op_acc: 42.19%] [G loss: 1.184538]\n",
      "epoch:31 step:24445[D loss: 0.414498, acc: 67.19%, op_acc: 42.19%] [G loss: 0.873383]\n",
      "epoch:31 step:24446[D loss: 0.371531, acc: 66.41%, op_acc: 45.31%] [G loss: 1.260080]\n",
      "epoch:31 step:24447[D loss: 0.421194, acc: 53.12%, op_acc: 45.31%] [G loss: 1.031740]\n",
      "epoch:31 step:24448[D loss: 0.339794, acc: 70.31%, op_acc: 42.97%] [G loss: 0.949332]\n",
      "epoch:31 step:24449[D loss: 0.427407, acc: 63.28%, op_acc: 39.06%] [G loss: 0.975740]\n",
      "epoch:31 step:24450[D loss: 0.387090, acc: 62.50%, op_acc: 45.31%] [G loss: 1.119167]\n",
      "epoch:31 step:24451[D loss: 0.415883, acc: 58.59%, op_acc: 42.19%] [G loss: 0.939464]\n",
      "epoch:31 step:24452[D loss: 0.441589, acc: 57.81%, op_acc: 43.75%] [G loss: 0.849546]\n",
      "epoch:31 step:24453[D loss: 0.398818, acc: 66.41%, op_acc: 39.84%] [G loss: 0.896322]\n",
      "epoch:31 step:24454[D loss: 0.410804, acc: 67.97%, op_acc: 46.09%] [G loss: 0.982974]\n",
      "epoch:31 step:24455[D loss: 0.383863, acc: 67.97%, op_acc: 48.44%] [G loss: 0.753170]\n",
      "epoch:31 step:24456[D loss: 0.453999, acc: 59.38%, op_acc: 39.84%] [G loss: 0.960022]\n",
      "epoch:31 step:24457[D loss: 0.406508, acc: 65.62%, op_acc: 42.97%] [G loss: 1.012160]\n",
      "epoch:31 step:24458[D loss: 0.392885, acc: 66.41%, op_acc: 46.88%] [G loss: 1.008567]\n",
      "epoch:31 step:24459[D loss: 0.408806, acc: 58.59%, op_acc: 40.62%] [G loss: 1.119452]\n",
      "epoch:31 step:24460[D loss: 0.414290, acc: 67.97%, op_acc: 36.72%] [G loss: 0.750462]\n",
      "epoch:31 step:24461[D loss: 0.407994, acc: 62.50%, op_acc: 42.97%] [G loss: 1.060579]\n",
      "epoch:31 step:24462[D loss: 0.396759, acc: 64.06%, op_acc: 46.88%] [G loss: 0.691674]\n",
      "epoch:31 step:24463[D loss: 0.341219, acc: 77.34%, op_acc: 41.41%] [G loss: 0.826873]\n",
      "epoch:31 step:24464[D loss: 0.375358, acc: 70.31%, op_acc: 39.84%] [G loss: 0.889050]\n",
      "epoch:31 step:24465[D loss: 0.388161, acc: 75.00%, op_acc: 41.41%] [G loss: 0.739789]\n",
      "epoch:31 step:24466[D loss: 0.465074, acc: 57.81%, op_acc: 39.06%] [G loss: 0.965108]\n",
      "epoch:31 step:24467[D loss: 0.370439, acc: 67.97%, op_acc: 46.88%] [G loss: 0.933123]\n",
      "epoch:31 step:24468[D loss: 0.399011, acc: 67.97%, op_acc: 39.84%] [G loss: 0.847665]\n",
      "epoch:31 step:24469[D loss: 0.380548, acc: 69.53%, op_acc: 49.22%] [G loss: 0.814159]\n",
      "epoch:31 step:24470[D loss: 0.365809, acc: 71.09%, op_acc: 42.97%] [G loss: 0.936070]\n",
      "epoch:31 step:24471[D loss: 0.356981, acc: 75.78%, op_acc: 47.66%] [G loss: 1.077239]\n",
      "epoch:31 step:24472[D loss: 0.349340, acc: 78.91%, op_acc: 44.53%] [G loss: 0.985046]\n",
      "epoch:31 step:24473[D loss: 0.375101, acc: 70.31%, op_acc: 46.09%] [G loss: 1.265182]\n",
      "epoch:31 step:24474[D loss: 0.335360, acc: 78.91%, op_acc: 45.31%] [G loss: 1.067258]\n",
      "epoch:31 step:24475[D loss: 0.356592, acc: 72.66%, op_acc: 46.88%] [G loss: 1.070833]\n",
      "epoch:31 step:24476[D loss: 0.392603, acc: 65.62%, op_acc: 40.62%] [G loss: 1.117591]\n",
      "epoch:31 step:24477[D loss: 0.325899, acc: 78.12%, op_acc: 48.44%] [G loss: 1.059142]\n",
      "epoch:31 step:24478[D loss: 0.428733, acc: 57.03%, op_acc: 50.78%] [G loss: 1.181541]\n",
      "epoch:31 step:24479[D loss: 0.401795, acc: 67.97%, op_acc: 42.19%] [G loss: 0.997396]\n",
      "epoch:31 step:24480[D loss: 0.414715, acc: 59.38%, op_acc: 44.53%] [G loss: 1.230016]\n",
      "epoch:31 step:24481[D loss: 0.336695, acc: 78.91%, op_acc: 42.19%] [G loss: 1.265976]\n",
      "epoch:31 step:24482[D loss: 0.380576, acc: 72.66%, op_acc: 45.31%] [G loss: 0.806890]\n",
      "epoch:31 step:24483[D loss: 0.371592, acc: 68.75%, op_acc: 46.88%] [G loss: 1.148394]\n",
      "epoch:31 step:24484[D loss: 0.444204, acc: 57.03%, op_acc: 41.41%] [G loss: 1.054716]\n",
      "epoch:31 step:24485[D loss: 0.393019, acc: 66.41%, op_acc: 47.66%] [G loss: 1.066161]\n",
      "epoch:31 step:24486[D loss: 0.364387, acc: 71.09%, op_acc: 47.66%] [G loss: 1.157003]\n",
      "epoch:31 step:24487[D loss: 0.374413, acc: 67.19%, op_acc: 44.53%] [G loss: 1.328206]\n",
      "epoch:31 step:24488[D loss: 0.414905, acc: 63.28%, op_acc: 40.62%] [G loss: 1.207980]\n",
      "epoch:31 step:24489[D loss: 0.380429, acc: 71.88%, op_acc: 46.09%] [G loss: 1.130765]\n",
      "epoch:31 step:24490[D loss: 0.366436, acc: 67.19%, op_acc: 46.09%] [G loss: 1.332232]\n",
      "epoch:31 step:24491[D loss: 0.384760, acc: 62.50%, op_acc: 45.31%] [G loss: 1.303475]\n",
      "epoch:31 step:24492[D loss: 0.393878, acc: 63.28%, op_acc: 44.53%] [G loss: 1.228166]\n",
      "epoch:31 step:24493[D loss: 0.394949, acc: 74.22%, op_acc: 39.84%] [G loss: 1.375578]\n",
      "epoch:31 step:24494[D loss: 0.349984, acc: 72.66%, op_acc: 44.53%] [G loss: 1.145744]\n",
      "epoch:31 step:24495[D loss: 0.371320, acc: 71.88%, op_acc: 50.78%] [G loss: 0.943806]\n",
      "epoch:31 step:24496[D loss: 0.385922, acc: 67.19%, op_acc: 36.72%] [G loss: 1.401372]\n",
      "epoch:31 step:24497[D loss: 0.346648, acc: 78.12%, op_acc: 45.31%] [G loss: 0.877015]\n",
      "epoch:31 step:24498[D loss: 0.430681, acc: 62.50%, op_acc: 39.06%] [G loss: 0.875184]\n",
      "epoch:31 step:24499[D loss: 0.411254, acc: 58.59%, op_acc: 44.53%] [G loss: 1.184030]\n",
      "epoch:31 step:24500[D loss: 0.430208, acc: 64.84%, op_acc: 32.81%] [G loss: 1.066074]\n",
      "epoch:31 step:24501[D loss: 0.390435, acc: 67.97%, op_acc: 40.62%] [G loss: 1.133197]\n",
      "epoch:31 step:24502[D loss: 0.382981, acc: 65.62%, op_acc: 45.31%] [G loss: 1.220665]\n",
      "epoch:31 step:24503[D loss: 0.440528, acc: 59.38%, op_acc: 40.62%] [G loss: 1.138290]\n",
      "epoch:31 step:24504[D loss: 0.407076, acc: 60.16%, op_acc: 44.53%] [G loss: 0.998107]\n",
      "epoch:31 step:24505[D loss: 0.370383, acc: 75.78%, op_acc: 36.72%] [G loss: 1.147129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24506[D loss: 0.413527, acc: 55.47%, op_acc: 46.88%] [G loss: 1.177002]\n",
      "epoch:31 step:24507[D loss: 0.395956, acc: 67.97%, op_acc: 42.97%] [G loss: 1.015655]\n",
      "epoch:31 step:24508[D loss: 0.436859, acc: 61.72%, op_acc: 35.94%] [G loss: 1.067046]\n",
      "epoch:31 step:24509[D loss: 0.402684, acc: 67.19%, op_acc: 40.62%] [G loss: 1.120131]\n",
      "epoch:31 step:24510[D loss: 0.389509, acc: 64.06%, op_acc: 46.09%] [G loss: 1.170077]\n",
      "epoch:31 step:24511[D loss: 0.435009, acc: 57.81%, op_acc: 39.06%] [G loss: 0.921456]\n",
      "epoch:31 step:24512[D loss: 0.367077, acc: 74.22%, op_acc: 44.53%] [G loss: 0.905017]\n",
      "epoch:31 step:24513[D loss: 0.359654, acc: 71.88%, op_acc: 50.00%] [G loss: 0.923621]\n",
      "epoch:31 step:24514[D loss: 0.405864, acc: 63.28%, op_acc: 41.41%] [G loss: 0.947209]\n",
      "epoch:31 step:24515[D loss: 0.355607, acc: 70.31%, op_acc: 47.66%] [G loss: 1.060483]\n",
      "epoch:31 step:24516[D loss: 0.350073, acc: 73.44%, op_acc: 46.88%] [G loss: 1.017996]\n",
      "epoch:31 step:24517[D loss: 0.390568, acc: 70.31%, op_acc: 42.97%] [G loss: 1.245008]\n",
      "epoch:31 step:24518[D loss: 0.391670, acc: 61.72%, op_acc: 41.41%] [G loss: 1.121892]\n",
      "epoch:31 step:24519[D loss: 0.382621, acc: 69.53%, op_acc: 42.19%] [G loss: 1.012538]\n",
      "epoch:31 step:24520[D loss: 0.439737, acc: 67.97%, op_acc: 33.59%] [G loss: 1.153591]\n",
      "epoch:31 step:24521[D loss: 0.361492, acc: 78.91%, op_acc: 41.41%] [G loss: 1.083555]\n",
      "epoch:31 step:24522[D loss: 0.387752, acc: 61.72%, op_acc: 46.09%] [G loss: 1.147734]\n",
      "epoch:31 step:24523[D loss: 0.406177, acc: 62.50%, op_acc: 42.97%] [G loss: 1.099249]\n",
      "epoch:31 step:24524[D loss: 0.436473, acc: 64.84%, op_acc: 43.75%] [G loss: 1.020144]\n",
      "epoch:31 step:24525[D loss: 0.431773, acc: 62.50%, op_acc: 42.19%] [G loss: 0.994813]\n",
      "epoch:31 step:24526[D loss: 0.411662, acc: 71.09%, op_acc: 42.19%] [G loss: 1.109296]\n",
      "epoch:31 step:24527[D loss: 0.394826, acc: 66.41%, op_acc: 37.50%] [G loss: 0.906870]\n",
      "epoch:31 step:24528[D loss: 0.425418, acc: 60.16%, op_acc: 36.72%] [G loss: 0.954726]\n",
      "epoch:31 step:24529[D loss: 0.397421, acc: 64.84%, op_acc: 39.84%] [G loss: 0.818769]\n",
      "epoch:31 step:24530[D loss: 0.403690, acc: 62.50%, op_acc: 41.41%] [G loss: 0.884059]\n",
      "epoch:31 step:24531[D loss: 0.383681, acc: 72.66%, op_acc: 39.84%] [G loss: 0.868273]\n",
      "epoch:31 step:24532[D loss: 0.362021, acc: 71.09%, op_acc: 49.22%] [G loss: 1.103249]\n",
      "epoch:31 step:24533[D loss: 0.416238, acc: 57.81%, op_acc: 43.75%] [G loss: 1.076831]\n",
      "epoch:31 step:24534[D loss: 0.369192, acc: 64.84%, op_acc: 48.44%] [G loss: 1.070887]\n",
      "epoch:31 step:24535[D loss: 0.383351, acc: 72.66%, op_acc: 42.19%] [G loss: 1.088600]\n",
      "epoch:31 step:24536[D loss: 0.388398, acc: 67.19%, op_acc: 46.88%] [G loss: 1.140336]\n",
      "epoch:31 step:24537[D loss: 0.390721, acc: 67.19%, op_acc: 42.97%] [G loss: 0.935814]\n",
      "epoch:31 step:24538[D loss: 0.413129, acc: 65.62%, op_acc: 42.97%] [G loss: 1.036539]\n",
      "epoch:31 step:24539[D loss: 0.398936, acc: 64.84%, op_acc: 45.31%] [G loss: 0.980318]\n",
      "epoch:31 step:24540[D loss: 0.331630, acc: 78.12%, op_acc: 44.53%] [G loss: 1.001083]\n",
      "epoch:31 step:24541[D loss: 0.375973, acc: 65.62%, op_acc: 42.97%] [G loss: 0.941177]\n",
      "epoch:31 step:24542[D loss: 0.359886, acc: 74.22%, op_acc: 46.88%] [G loss: 1.040405]\n",
      "epoch:31 step:24543[D loss: 0.412539, acc: 61.72%, op_acc: 38.28%] [G loss: 1.299786]\n",
      "epoch:31 step:24544[D loss: 0.400477, acc: 67.97%, op_acc: 50.78%] [G loss: 1.240196]\n",
      "epoch:31 step:24545[D loss: 0.370273, acc: 71.09%, op_acc: 44.53%] [G loss: 0.801053]\n",
      "epoch:31 step:24546[D loss: 0.377644, acc: 72.66%, op_acc: 37.50%] [G loss: 1.083331]\n",
      "epoch:31 step:24547[D loss: 0.480354, acc: 48.44%, op_acc: 35.94%] [G loss: 0.855041]\n",
      "epoch:31 step:24548[D loss: 0.468520, acc: 57.03%, op_acc: 32.81%] [G loss: 1.298660]\n",
      "epoch:31 step:24549[D loss: 0.441729, acc: 56.25%, op_acc: 43.75%] [G loss: 1.086798]\n",
      "epoch:31 step:24550[D loss: 0.460878, acc: 49.22%, op_acc: 42.19%] [G loss: 1.356363]\n",
      "epoch:31 step:24551[D loss: 0.435329, acc: 56.25%, op_acc: 35.16%] [G loss: 0.966182]\n",
      "epoch:31 step:24552[D loss: 0.456691, acc: 56.25%, op_acc: 40.62%] [G loss: 0.947554]\n",
      "epoch:31 step:24553[D loss: 0.416798, acc: 61.72%, op_acc: 41.41%] [G loss: 1.020751]\n",
      "epoch:31 step:24554[D loss: 0.440932, acc: 66.41%, op_acc: 38.28%] [G loss: 0.958943]\n",
      "epoch:31 step:24555[D loss: 0.431941, acc: 66.41%, op_acc: 35.16%] [G loss: 1.142926]\n",
      "epoch:31 step:24556[D loss: 0.400203, acc: 62.50%, op_acc: 39.06%] [G loss: 1.242570]\n",
      "epoch:31 step:24557[D loss: 0.438443, acc: 59.38%, op_acc: 39.06%] [G loss: 1.098057]\n",
      "epoch:31 step:24558[D loss: 0.396507, acc: 68.75%, op_acc: 43.75%] [G loss: 0.875454]\n",
      "epoch:31 step:24559[D loss: 0.402787, acc: 65.62%, op_acc: 40.62%] [G loss: 1.138072]\n",
      "epoch:31 step:24560[D loss: 0.428610, acc: 62.50%, op_acc: 39.84%] [G loss: 1.235309]\n",
      "epoch:31 step:24561[D loss: 0.400694, acc: 70.31%, op_acc: 42.19%] [G loss: 1.040897]\n",
      "epoch:31 step:24562[D loss: 0.435770, acc: 59.38%, op_acc: 42.19%] [G loss: 0.796989]\n",
      "epoch:31 step:24563[D loss: 0.396722, acc: 69.53%, op_acc: 34.38%] [G loss: 0.965263]\n",
      "epoch:31 step:24564[D loss: 0.389677, acc: 66.41%, op_acc: 46.09%] [G loss: 1.021940]\n",
      "epoch:31 step:24565[D loss: 0.412235, acc: 62.50%, op_acc: 45.31%] [G loss: 0.883902]\n",
      "epoch:31 step:24566[D loss: 0.371290, acc: 68.75%, op_acc: 46.09%] [G loss: 1.032650]\n",
      "epoch:31 step:24567[D loss: 0.365206, acc: 71.09%, op_acc: 47.66%] [G loss: 0.740608]\n",
      "epoch:31 step:24568[D loss: 0.392913, acc: 68.75%, op_acc: 39.84%] [G loss: 0.968682]\n",
      "epoch:31 step:24569[D loss: 0.386736, acc: 66.41%, op_acc: 42.19%] [G loss: 1.008454]\n",
      "epoch:31 step:24570[D loss: 0.402594, acc: 68.75%, op_acc: 42.19%] [G loss: 0.846798]\n",
      "epoch:31 step:24571[D loss: 0.421582, acc: 64.06%, op_acc: 39.06%] [G loss: 0.906680]\n",
      "epoch:31 step:24572[D loss: 0.352778, acc: 71.09%, op_acc: 50.78%] [G loss: 1.041821]\n",
      "epoch:31 step:24573[D loss: 0.384121, acc: 65.62%, op_acc: 43.75%] [G loss: 0.906291]\n",
      "epoch:31 step:24574[D loss: 0.391299, acc: 63.28%, op_acc: 42.19%] [G loss: 0.989099]\n",
      "epoch:31 step:24575[D loss: 0.376351, acc: 69.53%, op_acc: 42.19%] [G loss: 1.024412]\n",
      "epoch:31 step:24576[D loss: 0.356482, acc: 71.09%, op_acc: 46.09%] [G loss: 1.138475]\n",
      "epoch:31 step:24577[D loss: 0.338368, acc: 74.22%, op_acc: 46.09%] [G loss: 1.129107]\n",
      "epoch:31 step:24578[D loss: 0.371393, acc: 75.78%, op_acc: 45.31%] [G loss: 1.174120]\n",
      "epoch:31 step:24579[D loss: 0.384527, acc: 66.41%, op_acc: 39.06%] [G loss: 1.047365]\n",
      "epoch:31 step:24580[D loss: 0.375238, acc: 68.75%, op_acc: 48.44%] [G loss: 1.073385]\n",
      "epoch:31 step:24581[D loss: 0.431383, acc: 58.59%, op_acc: 39.84%] [G loss: 0.877985]\n",
      "epoch:31 step:24582[D loss: 0.395017, acc: 60.16%, op_acc: 46.88%] [G loss: 0.827387]\n",
      "epoch:31 step:24583[D loss: 0.391567, acc: 64.06%, op_acc: 37.50%] [G loss: 0.800075]\n",
      "epoch:31 step:24584[D loss: 0.410223, acc: 64.84%, op_acc: 45.31%] [G loss: 1.166077]\n",
      "epoch:31 step:24585[D loss: 0.356189, acc: 68.75%, op_acc: 53.12%] [G loss: 0.659771]\n",
      "epoch:31 step:24586[D loss: 0.370774, acc: 71.88%, op_acc: 44.53%] [G loss: 0.850614]\n",
      "epoch:31 step:24587[D loss: 0.383669, acc: 64.84%, op_acc: 42.97%] [G loss: 0.892643]\n",
      "epoch:31 step:24588[D loss: 0.369132, acc: 66.41%, op_acc: 42.19%] [G loss: 0.901179]\n",
      "epoch:31 step:24589[D loss: 0.347835, acc: 77.34%, op_acc: 42.97%] [G loss: 0.883655]\n",
      "epoch:31 step:24590[D loss: 0.391657, acc: 67.97%, op_acc: 42.19%] [G loss: 0.824938]\n",
      "epoch:31 step:24591[D loss: 0.389793, acc: 60.94%, op_acc: 42.19%] [G loss: 0.987266]\n",
      "epoch:31 step:24592[D loss: 0.389480, acc: 70.31%, op_acc: 46.09%] [G loss: 1.029854]\n",
      "epoch:31 step:24593[D loss: 0.377222, acc: 71.88%, op_acc: 43.75%] [G loss: 1.105347]\n",
      "epoch:31 step:24594[D loss: 0.362884, acc: 71.88%, op_acc: 54.69%] [G loss: 1.045817]\n",
      "epoch:31 step:24595[D loss: 0.409926, acc: 64.84%, op_acc: 41.41%] [G loss: 1.082616]\n",
      "epoch:31 step:24596[D loss: 0.412160, acc: 59.38%, op_acc: 40.62%] [G loss: 1.025858]\n",
      "epoch:31 step:24597[D loss: 0.333246, acc: 76.56%, op_acc: 49.22%] [G loss: 1.086648]\n",
      "epoch:31 step:24598[D loss: 0.447426, acc: 53.12%, op_acc: 39.84%] [G loss: 1.094540]\n",
      "epoch:31 step:24599[D loss: 0.447936, acc: 57.03%, op_acc: 42.19%] [G loss: 0.968952]\n",
      "epoch:31 step:24600[D loss: 0.436002, acc: 57.81%, op_acc: 42.97%] [G loss: 1.051892]\n",
      "epoch:31 step:24601[D loss: 0.397803, acc: 64.84%, op_acc: 39.84%] [G loss: 1.136354]\n",
      "epoch:31 step:24602[D loss: 0.392529, acc: 65.62%, op_acc: 50.78%] [G loss: 1.219944]\n",
      "epoch:31 step:24603[D loss: 0.366643, acc: 64.84%, op_acc: 46.88%] [G loss: 1.114363]\n",
      "epoch:31 step:24604[D loss: 0.427697, acc: 65.62%, op_acc: 46.88%] [G loss: 0.839190]\n",
      "epoch:31 step:24605[D loss: 0.394237, acc: 71.09%, op_acc: 42.97%] [G loss: 1.155635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24606[D loss: 0.370239, acc: 70.31%, op_acc: 40.62%] [G loss: 0.800274]\n",
      "epoch:31 step:24607[D loss: 0.407685, acc: 65.62%, op_acc: 44.53%] [G loss: 1.113652]\n",
      "epoch:31 step:24608[D loss: 0.396383, acc: 64.06%, op_acc: 42.19%] [G loss: 0.923298]\n",
      "epoch:31 step:24609[D loss: 0.425900, acc: 59.38%, op_acc: 41.41%] [G loss: 0.735489]\n",
      "epoch:31 step:24610[D loss: 0.429331, acc: 63.28%, op_acc: 38.28%] [G loss: 0.711086]\n",
      "epoch:31 step:24611[D loss: 0.398497, acc: 69.53%, op_acc: 39.84%] [G loss: 0.987046]\n",
      "epoch:31 step:24612[D loss: 0.389007, acc: 65.62%, op_acc: 43.75%] [G loss: 0.945174]\n",
      "epoch:31 step:24613[D loss: 0.395331, acc: 67.97%, op_acc: 43.75%] [G loss: 0.909309]\n",
      "epoch:31 step:24614[D loss: 0.359051, acc: 74.22%, op_acc: 42.97%] [G loss: 1.118141]\n",
      "epoch:31 step:24615[D loss: 0.358963, acc: 70.31%, op_acc: 50.78%] [G loss: 1.254955]\n",
      "epoch:31 step:24616[D loss: 0.431133, acc: 66.41%, op_acc: 45.31%] [G loss: 0.793297]\n",
      "epoch:31 step:24617[D loss: 0.384929, acc: 64.84%, op_acc: 40.62%] [G loss: 0.893130]\n",
      "epoch:31 step:24618[D loss: 0.360284, acc: 71.88%, op_acc: 44.53%] [G loss: 1.072534]\n",
      "epoch:31 step:24619[D loss: 0.356461, acc: 72.66%, op_acc: 44.53%] [G loss: 0.871442]\n",
      "epoch:31 step:24620[D loss: 0.387947, acc: 64.84%, op_acc: 47.66%] [G loss: 0.887785]\n",
      "epoch:31 step:24621[D loss: 0.330029, acc: 74.22%, op_acc: 48.44%] [G loss: 0.820440]\n",
      "epoch:31 step:24622[D loss: 0.416612, acc: 59.38%, op_acc: 48.44%] [G loss: 1.022364]\n",
      "epoch:31 step:24623[D loss: 0.399188, acc: 64.06%, op_acc: 41.41%] [G loss: 0.753355]\n",
      "epoch:31 step:24624[D loss: 0.395403, acc: 60.16%, op_acc: 48.44%] [G loss: 0.925407]\n",
      "epoch:31 step:24625[D loss: 0.395857, acc: 68.75%, op_acc: 40.62%] [G loss: 0.933479]\n",
      "epoch:31 step:24626[D loss: 0.401726, acc: 65.62%, op_acc: 43.75%] [G loss: 0.929119]\n",
      "epoch:31 step:24627[D loss: 0.393044, acc: 67.19%, op_acc: 39.06%] [G loss: 1.043781]\n",
      "epoch:31 step:24628[D loss: 0.396704, acc: 69.53%, op_acc: 45.31%] [G loss: 1.087239]\n",
      "epoch:31 step:24629[D loss: 0.355716, acc: 75.00%, op_acc: 49.22%] [G loss: 1.010329]\n",
      "epoch:31 step:24630[D loss: 0.365102, acc: 70.31%, op_acc: 45.31%] [G loss: 0.949246]\n",
      "epoch:31 step:24631[D loss: 0.405640, acc: 64.84%, op_acc: 45.31%] [G loss: 1.088602]\n",
      "epoch:31 step:24632[D loss: 0.416903, acc: 62.50%, op_acc: 33.59%] [G loss: 0.854646]\n",
      "epoch:31 step:24633[D loss: 0.388363, acc: 62.50%, op_acc: 41.41%] [G loss: 1.223156]\n",
      "epoch:31 step:24634[D loss: 0.377038, acc: 71.88%, op_acc: 42.19%] [G loss: 1.001291]\n",
      "epoch:31 step:24635[D loss: 0.447388, acc: 57.03%, op_acc: 36.72%] [G loss: 1.035561]\n",
      "epoch:31 step:24636[D loss: 0.383238, acc: 62.50%, op_acc: 43.75%] [G loss: 1.176392]\n",
      "epoch:31 step:24637[D loss: 0.394431, acc: 67.19%, op_acc: 44.53%] [G loss: 0.855711]\n",
      "epoch:31 step:24638[D loss: 0.392993, acc: 72.66%, op_acc: 35.16%] [G loss: 0.916641]\n",
      "epoch:31 step:24639[D loss: 0.414537, acc: 58.59%, op_acc: 47.66%] [G loss: 0.959337]\n",
      "epoch:31 step:24640[D loss: 0.406601, acc: 60.94%, op_acc: 50.00%] [G loss: 0.894293]\n",
      "epoch:31 step:24641[D loss: 0.379176, acc: 68.75%, op_acc: 46.09%] [G loss: 1.023704]\n",
      "epoch:31 step:24642[D loss: 0.395910, acc: 66.41%, op_acc: 38.28%] [G loss: 0.739519]\n",
      "epoch:31 step:24643[D loss: 0.336724, acc: 75.78%, op_acc: 44.53%] [G loss: 0.753753]\n",
      "epoch:31 step:24644[D loss: 0.407765, acc: 60.16%, op_acc: 42.97%] [G loss: 0.859138]\n",
      "epoch:31 step:24645[D loss: 0.388458, acc: 64.84%, op_acc: 46.09%] [G loss: 1.075068]\n",
      "epoch:31 step:24646[D loss: 0.365267, acc: 69.53%, op_acc: 49.22%] [G loss: 0.845301]\n",
      "epoch:31 step:24647[D loss: 0.465004, acc: 54.69%, op_acc: 39.84%] [G loss: 0.813584]\n",
      "epoch:31 step:24648[D loss: 0.395855, acc: 69.53%, op_acc: 41.41%] [G loss: 0.920237]\n",
      "epoch:31 step:24649[D loss: 0.376544, acc: 70.31%, op_acc: 46.88%] [G loss: 0.923129]\n",
      "epoch:31 step:24650[D loss: 0.382304, acc: 67.19%, op_acc: 50.00%] [G loss: 1.022320]\n",
      "epoch:31 step:24651[D loss: 0.363494, acc: 72.66%, op_acc: 44.53%] [G loss: 1.108512]\n",
      "epoch:31 step:24652[D loss: 0.395051, acc: 66.41%, op_acc: 41.41%] [G loss: 1.074546]\n",
      "epoch:31 step:24653[D loss: 0.331888, acc: 77.34%, op_acc: 47.66%] [G loss: 0.880603]\n",
      "epoch:31 step:24654[D loss: 0.363114, acc: 78.91%, op_acc: 42.19%] [G loss: 1.225653]\n",
      "epoch:31 step:24655[D loss: 0.347214, acc: 78.91%, op_acc: 44.53%] [G loss: 1.018603]\n",
      "epoch:31 step:24656[D loss: 0.349192, acc: 76.56%, op_acc: 50.78%] [G loss: 1.112090]\n",
      "epoch:31 step:24657[D loss: 0.376094, acc: 67.97%, op_acc: 49.22%] [G loss: 0.897488]\n",
      "epoch:31 step:24658[D loss: 0.421911, acc: 63.28%, op_acc: 39.06%] [G loss: 0.969130]\n",
      "epoch:31 step:24659[D loss: 0.371281, acc: 71.88%, op_acc: 35.94%] [G loss: 0.942447]\n",
      "epoch:31 step:24660[D loss: 0.394371, acc: 59.38%, op_acc: 41.41%] [G loss: 1.039842]\n",
      "epoch:31 step:24661[D loss: 0.403786, acc: 62.50%, op_acc: 42.19%] [G loss: 0.881043]\n",
      "epoch:31 step:24662[D loss: 0.375131, acc: 67.19%, op_acc: 48.44%] [G loss: 0.935293]\n",
      "epoch:31 step:24663[D loss: 0.384694, acc: 67.19%, op_acc: 42.19%] [G loss: 1.028322]\n",
      "epoch:31 step:24664[D loss: 0.412081, acc: 59.38%, op_acc: 43.75%] [G loss: 1.144896]\n",
      "epoch:31 step:24665[D loss: 0.370905, acc: 71.09%, op_acc: 43.75%] [G loss: 0.909077]\n",
      "epoch:31 step:24666[D loss: 0.403745, acc: 65.62%, op_acc: 46.09%] [G loss: 0.755456]\n",
      "epoch:31 step:24667[D loss: 0.407899, acc: 65.62%, op_acc: 39.84%] [G loss: 0.749956]\n",
      "epoch:31 step:24668[D loss: 0.363183, acc: 71.88%, op_acc: 45.31%] [G loss: 0.886309]\n",
      "epoch:31 step:24669[D loss: 0.366341, acc: 67.19%, op_acc: 50.78%] [G loss: 1.002584]\n",
      "epoch:31 step:24670[D loss: 0.414230, acc: 55.47%, op_acc: 46.88%] [G loss: 0.742999]\n",
      "epoch:31 step:24671[D loss: 0.346067, acc: 72.66%, op_acc: 48.44%] [G loss: 0.967179]\n",
      "epoch:31 step:24672[D loss: 0.373800, acc: 71.88%, op_acc: 43.75%] [G loss: 1.040350]\n",
      "epoch:31 step:24673[D loss: 0.351121, acc: 75.78%, op_acc: 40.62%] [G loss: 0.979984]\n",
      "epoch:31 step:24674[D loss: 0.393350, acc: 58.59%, op_acc: 45.31%] [G loss: 0.859518]\n",
      "epoch:31 step:24675[D loss: 0.407822, acc: 64.84%, op_acc: 39.84%] [G loss: 0.996171]\n",
      "epoch:31 step:24676[D loss: 0.365021, acc: 74.22%, op_acc: 45.31%] [G loss: 1.135680]\n",
      "epoch:31 step:24677[D loss: 0.387570, acc: 67.19%, op_acc: 39.06%] [G loss: 1.022234]\n",
      "epoch:31 step:24678[D loss: 0.375882, acc: 65.62%, op_acc: 40.62%] [G loss: 1.149337]\n",
      "epoch:31 step:24679[D loss: 0.320934, acc: 75.78%, op_acc: 52.34%] [G loss: 1.127833]\n",
      "epoch:31 step:24680[D loss: 0.326535, acc: 71.88%, op_acc: 51.56%] [G loss: 1.418921]\n",
      "epoch:31 step:24681[D loss: 0.286876, acc: 83.59%, op_acc: 52.34%] [G loss: 0.941900]\n",
      "epoch:31 step:24682[D loss: 0.342204, acc: 80.47%, op_acc: 47.66%] [G loss: 1.164248]\n",
      "epoch:31 step:24683[D loss: 0.358585, acc: 77.34%, op_acc: 42.97%] [G loss: 1.277602]\n",
      "epoch:31 step:24684[D loss: 0.323191, acc: 75.78%, op_acc: 49.22%] [G loss: 1.236706]\n",
      "epoch:31 step:24685[D loss: 0.400031, acc: 64.06%, op_acc: 41.41%] [G loss: 1.126491]\n",
      "epoch:31 step:24686[D loss: 0.332127, acc: 78.12%, op_acc: 50.78%] [G loss: 1.507288]\n",
      "epoch:31 step:24687[D loss: 0.338714, acc: 76.56%, op_acc: 46.09%] [G loss: 1.493482]\n",
      "epoch:31 step:24688[D loss: 0.334082, acc: 78.91%, op_acc: 48.44%] [G loss: 1.332441]\n",
      "epoch:31 step:24689[D loss: 0.333722, acc: 75.00%, op_acc: 47.66%] [G loss: 0.605467]\n",
      "epoch:31 step:24690[D loss: 0.410513, acc: 60.16%, op_acc: 35.94%] [G loss: 0.851492]\n",
      "epoch:31 step:24691[D loss: 0.433671, acc: 62.50%, op_acc: 39.06%] [G loss: 0.830973]\n",
      "epoch:31 step:24692[D loss: 0.492435, acc: 54.69%, op_acc: 32.03%] [G loss: 1.498879]\n",
      "epoch:31 step:24693[D loss: 0.427604, acc: 64.84%, op_acc: 41.41%] [G loss: 1.426958]\n",
      "epoch:31 step:24694[D loss: 0.399071, acc: 63.28%, op_acc: 46.09%] [G loss: 0.834276]\n",
      "epoch:31 step:24695[D loss: 0.388412, acc: 63.28%, op_acc: 51.56%] [G loss: 0.984658]\n",
      "epoch:31 step:24696[D loss: 0.446056, acc: 58.59%, op_acc: 37.50%] [G loss: 0.906472]\n",
      "epoch:31 step:24697[D loss: 0.360618, acc: 71.88%, op_acc: 45.31%] [G loss: 1.470274]\n",
      "epoch:31 step:24698[D loss: 0.431424, acc: 53.91%, op_acc: 42.19%] [G loss: 1.015291]\n",
      "epoch:31 step:24699[D loss: 0.390141, acc: 71.88%, op_acc: 44.53%] [G loss: 1.367836]\n",
      "epoch:31 step:24700[D loss: 0.404661, acc: 64.06%, op_acc: 47.66%] [G loss: 1.011277]\n",
      "epoch:31 step:24701[D loss: 0.421983, acc: 62.50%, op_acc: 41.41%] [G loss: 1.183304]\n",
      "epoch:31 step:24702[D loss: 0.427724, acc: 64.06%, op_acc: 40.62%] [G loss: 1.099703]\n",
      "epoch:31 step:24703[D loss: 0.432342, acc: 60.94%, op_acc: 42.97%] [G loss: 1.008769]\n",
      "epoch:31 step:24704[D loss: 0.357702, acc: 77.34%, op_acc: 46.09%] [G loss: 1.138054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24705[D loss: 0.357695, acc: 77.34%, op_acc: 45.31%] [G loss: 0.777622]\n",
      "epoch:31 step:24706[D loss: 0.408272, acc: 67.19%, op_acc: 39.84%] [G loss: 0.894384]\n",
      "epoch:31 step:24707[D loss: 0.368737, acc: 71.88%, op_acc: 41.41%] [G loss: 1.097388]\n",
      "epoch:31 step:24708[D loss: 0.420409, acc: 53.12%, op_acc: 36.72%] [G loss: 1.143030]\n",
      "epoch:31 step:24709[D loss: 0.469528, acc: 51.56%, op_acc: 35.16%] [G loss: 0.878264]\n",
      "epoch:31 step:24710[D loss: 0.392856, acc: 69.53%, op_acc: 42.19%] [G loss: 0.917748]\n",
      "epoch:31 step:24711[D loss: 0.385624, acc: 60.94%, op_acc: 47.66%] [G loss: 0.863873]\n",
      "epoch:31 step:24712[D loss: 0.417392, acc: 66.41%, op_acc: 39.06%] [G loss: 1.286615]\n",
      "epoch:31 step:24713[D loss: 0.407983, acc: 65.62%, op_acc: 40.62%] [G loss: 0.826900]\n",
      "epoch:31 step:24714[D loss: 0.381573, acc: 67.97%, op_acc: 44.53%] [G loss: 0.730107]\n",
      "epoch:31 step:24715[D loss: 0.430908, acc: 63.28%, op_acc: 42.97%] [G loss: 0.614568]\n",
      "epoch:31 step:24716[D loss: 0.364738, acc: 75.78%, op_acc: 47.66%] [G loss: 0.986139]\n",
      "epoch:31 step:24717[D loss: 0.389750, acc: 67.19%, op_acc: 42.97%] [G loss: 0.765526]\n",
      "epoch:31 step:24718[D loss: 0.439252, acc: 57.81%, op_acc: 46.09%] [G loss: 0.741499]\n",
      "epoch:31 step:24719[D loss: 0.405784, acc: 61.72%, op_acc: 46.88%] [G loss: 0.835474]\n",
      "epoch:31 step:24720[D loss: 0.406714, acc: 65.62%, op_acc: 48.44%] [G loss: 1.176045]\n",
      "epoch:31 step:24721[D loss: 0.387127, acc: 65.62%, op_acc: 46.88%] [G loss: 1.049817]\n",
      "epoch:31 step:24722[D loss: 0.416767, acc: 60.94%, op_acc: 44.53%] [G loss: 0.870960]\n",
      "epoch:31 step:24723[D loss: 0.428779, acc: 62.50%, op_acc: 39.06%] [G loss: 0.859163]\n",
      "epoch:31 step:24724[D loss: 0.415508, acc: 64.84%, op_acc: 40.62%] [G loss: 0.997403]\n",
      "epoch:31 step:24725[D loss: 0.396609, acc: 64.84%, op_acc: 42.19%] [G loss: 0.773614]\n",
      "epoch:31 step:24726[D loss: 0.374297, acc: 72.66%, op_acc: 45.31%] [G loss: 0.999489]\n",
      "epoch:31 step:24727[D loss: 0.339671, acc: 77.34%, op_acc: 42.97%] [G loss: 1.043758]\n",
      "epoch:31 step:24728[D loss: 0.424320, acc: 63.28%, op_acc: 46.09%] [G loss: 1.058693]\n",
      "epoch:31 step:24729[D loss: 0.340480, acc: 73.44%, op_acc: 50.78%] [G loss: 1.026023]\n",
      "epoch:31 step:24730[D loss: 0.376210, acc: 66.41%, op_acc: 44.53%] [G loss: 1.302425]\n",
      "epoch:31 step:24731[D loss: 0.350188, acc: 75.78%, op_acc: 43.75%] [G loss: 1.287715]\n",
      "epoch:31 step:24732[D loss: 0.402450, acc: 73.44%, op_acc: 41.41%] [G loss: 1.172060]\n",
      "epoch:31 step:24733[D loss: 0.397549, acc: 66.41%, op_acc: 42.19%] [G loss: 0.966530]\n",
      "epoch:31 step:24734[D loss: 0.361380, acc: 72.66%, op_acc: 45.31%] [G loss: 1.339928]\n",
      "epoch:31 step:24735[D loss: 0.323902, acc: 77.34%, op_acc: 53.91%] [G loss: 1.275934]\n",
      "epoch:31 step:24736[D loss: 0.303741, acc: 83.59%, op_acc: 45.31%] [G loss: 0.868837]\n",
      "epoch:31 step:24737[D loss: 0.521974, acc: 50.00%, op_acc: 37.50%] [G loss: 0.712734]\n",
      "epoch:31 step:24738[D loss: 0.399451, acc: 63.28%, op_acc: 38.28%] [G loss: 1.223269]\n",
      "epoch:31 step:24739[D loss: 0.391405, acc: 65.62%, op_acc: 47.66%] [G loss: 0.907146]\n",
      "epoch:31 step:24740[D loss: 0.410779, acc: 55.47%, op_acc: 46.09%] [G loss: 1.047167]\n",
      "epoch:31 step:24741[D loss: 0.393570, acc: 70.31%, op_acc: 44.53%] [G loss: 1.050537]\n",
      "epoch:31 step:24742[D loss: 0.454112, acc: 54.69%, op_acc: 39.06%] [G loss: 1.147222]\n",
      "epoch:31 step:24743[D loss: 0.381043, acc: 68.75%, op_acc: 39.84%] [G loss: 1.230016]\n",
      "epoch:31 step:24744[D loss: 0.401730, acc: 65.62%, op_acc: 40.62%] [G loss: 1.198698]\n",
      "epoch:31 step:24745[D loss: 0.368926, acc: 66.41%, op_acc: 47.66%] [G loss: 1.082236]\n",
      "epoch:31 step:24746[D loss: 0.410725, acc: 64.84%, op_acc: 39.06%] [G loss: 1.161779]\n",
      "epoch:31 step:24747[D loss: 0.376401, acc: 67.19%, op_acc: 46.88%] [G loss: 1.095057]\n",
      "epoch:31 step:24748[D loss: 0.447240, acc: 56.25%, op_acc: 35.16%] [G loss: 1.204234]\n",
      "epoch:31 step:24749[D loss: 0.409487, acc: 64.06%, op_acc: 43.75%] [G loss: 1.139045]\n",
      "epoch:31 step:24750[D loss: 0.421643, acc: 65.62%, op_acc: 43.75%] [G loss: 0.991906]\n",
      "epoch:31 step:24751[D loss: 0.400660, acc: 64.84%, op_acc: 42.19%] [G loss: 0.809908]\n",
      "epoch:31 step:24752[D loss: 0.355936, acc: 69.53%, op_acc: 46.88%] [G loss: 1.158399]\n",
      "epoch:31 step:24753[D loss: 0.426817, acc: 59.38%, op_acc: 39.06%] [G loss: 0.898865]\n",
      "epoch:31 step:24754[D loss: 0.420198, acc: 63.28%, op_acc: 38.28%] [G loss: 0.974533]\n",
      "epoch:31 step:24755[D loss: 0.408349, acc: 61.72%, op_acc: 37.50%] [G loss: 0.960762]\n",
      "epoch:31 step:24756[D loss: 0.378021, acc: 73.44%, op_acc: 42.97%] [G loss: 0.973017]\n",
      "epoch:31 step:24757[D loss: 0.385746, acc: 66.41%, op_acc: 48.44%] [G loss: 1.283229]\n",
      "epoch:31 step:24758[D loss: 0.464652, acc: 55.47%, op_acc: 41.41%] [G loss: 0.900869]\n",
      "epoch:31 step:24759[D loss: 0.425196, acc: 64.06%, op_acc: 41.41%] [G loss: 0.861917]\n",
      "epoch:31 step:24760[D loss: 0.412615, acc: 66.41%, op_acc: 38.28%] [G loss: 0.732951]\n",
      "epoch:31 step:24761[D loss: 0.431581, acc: 57.03%, op_acc: 46.09%] [G loss: 0.916388]\n",
      "epoch:31 step:24762[D loss: 0.402373, acc: 60.94%, op_acc: 44.53%] [G loss: 1.073546]\n",
      "epoch:31 step:24763[D loss: 0.425859, acc: 64.06%, op_acc: 39.84%] [G loss: 1.082078]\n",
      "epoch:31 step:24764[D loss: 0.380413, acc: 62.50%, op_acc: 42.97%] [G loss: 0.796481]\n",
      "epoch:31 step:24765[D loss: 0.414453, acc: 63.28%, op_acc: 39.84%] [G loss: 1.101843]\n",
      "epoch:31 step:24766[D loss: 0.369019, acc: 67.97%, op_acc: 45.31%] [G loss: 0.988337]\n",
      "epoch:31 step:24767[D loss: 0.416895, acc: 64.84%, op_acc: 41.41%] [G loss: 0.695373]\n",
      "epoch:31 step:24768[D loss: 0.386432, acc: 69.53%, op_acc: 42.19%] [G loss: 1.016298]\n",
      "epoch:31 step:24769[D loss: 0.412968, acc: 61.72%, op_acc: 39.84%] [G loss: 0.729295]\n",
      "epoch:31 step:24770[D loss: 0.325521, acc: 76.56%, op_acc: 39.84%] [G loss: 1.228793]\n",
      "epoch:31 step:24771[D loss: 0.391874, acc: 69.53%, op_acc: 45.31%] [G loss: 0.837303]\n",
      "epoch:31 step:24772[D loss: 0.362953, acc: 67.19%, op_acc: 47.66%] [G loss: 0.823631]\n",
      "epoch:31 step:24773[D loss: 0.414742, acc: 66.41%, op_acc: 41.41%] [G loss: 0.776881]\n",
      "epoch:31 step:24774[D loss: 0.420603, acc: 63.28%, op_acc: 39.06%] [G loss: 0.781139]\n",
      "epoch:31 step:24775[D loss: 0.372825, acc: 71.88%, op_acc: 48.44%] [G loss: 1.127895]\n",
      "epoch:31 step:24776[D loss: 0.422516, acc: 59.38%, op_acc: 42.97%] [G loss: 1.163314]\n",
      "epoch:31 step:24777[D loss: 0.395960, acc: 61.72%, op_acc: 46.88%] [G loss: 0.658522]\n",
      "epoch:31 step:24778[D loss: 0.411300, acc: 64.84%, op_acc: 43.75%] [G loss: 1.069346]\n",
      "epoch:31 step:24779[D loss: 0.383887, acc: 74.22%, op_acc: 46.88%] [G loss: 0.644397]\n",
      "epoch:31 step:24780[D loss: 0.344677, acc: 71.88%, op_acc: 49.22%] [G loss: 1.236050]\n",
      "epoch:31 step:24781[D loss: 0.375798, acc: 66.41%, op_acc: 50.00%] [G loss: 0.752075]\n",
      "epoch:31 step:24782[D loss: 0.406040, acc: 64.06%, op_acc: 45.31%] [G loss: 0.839125]\n",
      "epoch:31 step:24783[D loss: 0.370445, acc: 70.31%, op_acc: 42.19%] [G loss: 1.023741]\n",
      "epoch:31 step:24784[D loss: 0.386579, acc: 67.19%, op_acc: 45.31%] [G loss: 1.234530]\n",
      "epoch:31 step:24785[D loss: 0.420473, acc: 65.62%, op_acc: 35.94%] [G loss: 0.659933]\n",
      "epoch:31 step:24786[D loss: 0.440642, acc: 58.59%, op_acc: 35.94%] [G loss: 1.040107]\n",
      "epoch:31 step:24787[D loss: 0.411517, acc: 60.16%, op_acc: 39.84%] [G loss: 1.038530]\n",
      "epoch:31 step:24788[D loss: 0.403440, acc: 69.53%, op_acc: 42.97%] [G loss: 0.703740]\n",
      "epoch:31 step:24789[D loss: 0.443764, acc: 58.59%, op_acc: 42.19%] [G loss: 0.662010]\n",
      "epoch:31 step:24790[D loss: 0.389403, acc: 60.94%, op_acc: 47.66%] [G loss: 0.900203]\n",
      "epoch:31 step:24791[D loss: 0.426024, acc: 60.16%, op_acc: 38.28%] [G loss: 1.139577]\n",
      "epoch:31 step:24792[D loss: 0.398797, acc: 64.06%, op_acc: 39.84%] [G loss: 1.144412]\n",
      "epoch:31 step:24793[D loss: 0.378209, acc: 74.22%, op_acc: 42.97%] [G loss: 0.871819]\n",
      "epoch:31 step:24794[D loss: 0.357766, acc: 69.53%, op_acc: 46.09%] [G loss: 0.880312]\n",
      "epoch:31 step:24795[D loss: 0.438273, acc: 60.16%, op_acc: 31.25%] [G loss: 0.881236]\n",
      "epoch:31 step:24796[D loss: 0.390053, acc: 65.62%, op_acc: 42.19%] [G loss: 0.798158]\n",
      "epoch:31 step:24797[D loss: 0.425451, acc: 62.50%, op_acc: 42.97%] [G loss: 0.789802]\n",
      "epoch:31 step:24798[D loss: 0.368755, acc: 66.41%, op_acc: 46.88%] [G loss: 1.163657]\n",
      "epoch:31 step:24799[D loss: 0.408701, acc: 60.94%, op_acc: 45.31%] [G loss: 0.837824]\n",
      "epoch:31 step:24800[D loss: 0.348089, acc: 76.56%, op_acc: 51.56%] [G loss: 0.804247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24801[D loss: 0.361875, acc: 69.53%, op_acc: 42.19%] [G loss: 0.791490]\n",
      "epoch:31 step:24802[D loss: 0.374407, acc: 64.06%, op_acc: 50.78%] [G loss: 0.796998]\n",
      "epoch:31 step:24803[D loss: 0.404606, acc: 64.84%, op_acc: 46.09%] [G loss: 1.148500]\n",
      "epoch:31 step:24804[D loss: 0.400642, acc: 67.97%, op_acc: 40.62%] [G loss: 1.056297]\n",
      "epoch:31 step:24805[D loss: 0.397148, acc: 67.19%, op_acc: 43.75%] [G loss: 0.802700]\n",
      "epoch:31 step:24806[D loss: 0.367780, acc: 66.41%, op_acc: 50.00%] [G loss: 0.956490]\n",
      "epoch:31 step:24807[D loss: 0.422707, acc: 60.94%, op_acc: 39.06%] [G loss: 0.888652]\n",
      "epoch:31 step:24808[D loss: 0.340782, acc: 73.44%, op_acc: 49.22%] [G loss: 1.032458]\n",
      "epoch:31 step:24809[D loss: 0.348012, acc: 70.31%, op_acc: 47.66%] [G loss: 0.869925]\n",
      "epoch:31 step:24810[D loss: 0.349073, acc: 82.81%, op_acc: 44.53%] [G loss: 0.940218]\n",
      "epoch:31 step:24811[D loss: 0.359284, acc: 74.22%, op_acc: 44.53%] [G loss: 1.069218]\n",
      "epoch:31 step:24812[D loss: 0.379915, acc: 64.84%, op_acc: 47.66%] [G loss: 1.142631]\n",
      "epoch:31 step:24813[D loss: 0.366571, acc: 72.66%, op_acc: 44.53%] [G loss: 1.158789]\n",
      "epoch:31 step:24814[D loss: 0.375739, acc: 64.84%, op_acc: 48.44%] [G loss: 1.155562]\n",
      "epoch:31 step:24815[D loss: 0.398842, acc: 68.75%, op_acc: 42.19%] [G loss: 1.027646]\n",
      "epoch:31 step:24816[D loss: 0.403156, acc: 65.62%, op_acc: 46.09%] [G loss: 0.912671]\n",
      "epoch:31 step:24817[D loss: 0.358973, acc: 69.53%, op_acc: 45.31%] [G loss: 1.001047]\n",
      "epoch:31 step:24818[D loss: 0.344536, acc: 77.34%, op_acc: 53.12%] [G loss: 0.880039]\n",
      "epoch:31 step:24819[D loss: 0.346341, acc: 70.31%, op_acc: 44.53%] [G loss: 0.948746]\n",
      "epoch:31 step:24820[D loss: 0.359413, acc: 71.09%, op_acc: 53.12%] [G loss: 1.292322]\n",
      "epoch:31 step:24821[D loss: 0.320717, acc: 78.91%, op_acc: 40.62%] [G loss: 0.808934]\n",
      "epoch:31 step:24822[D loss: 0.374957, acc: 68.75%, op_acc: 46.88%] [G loss: 0.972716]\n",
      "epoch:31 step:24823[D loss: 0.359504, acc: 72.66%, op_acc: 47.66%] [G loss: 1.250925]\n",
      "epoch:31 step:24824[D loss: 0.380232, acc: 70.31%, op_acc: 44.53%] [G loss: 1.042574]\n",
      "epoch:31 step:24825[D loss: 0.302678, acc: 84.38%, op_acc: 48.44%] [G loss: 1.179371]\n",
      "epoch:31 step:24826[D loss: 0.339573, acc: 78.91%, op_acc: 53.91%] [G loss: 1.363624]\n",
      "epoch:31 step:24827[D loss: 0.328230, acc: 79.69%, op_acc: 46.09%] [G loss: 1.124311]\n",
      "epoch:31 step:24828[D loss: 0.349303, acc: 75.00%, op_acc: 50.78%] [G loss: 0.727681]\n",
      "epoch:31 step:24829[D loss: 0.339005, acc: 74.22%, op_acc: 49.22%] [G loss: 1.546754]\n",
      "epoch:31 step:24830[D loss: 0.336599, acc: 78.91%, op_acc: 43.75%] [G loss: 0.584897]\n",
      "epoch:31 step:24831[D loss: 0.407844, acc: 64.06%, op_acc: 39.06%] [G loss: 1.452026]\n",
      "epoch:31 step:24832[D loss: 0.409449, acc: 66.41%, op_acc: 42.97%] [G loss: 1.335839]\n",
      "epoch:31 step:24833[D loss: 0.407245, acc: 66.41%, op_acc: 39.06%] [G loss: 0.892821]\n",
      "epoch:31 step:24834[D loss: 0.393265, acc: 69.53%, op_acc: 39.06%] [G loss: 0.858686]\n",
      "epoch:31 step:24835[D loss: 0.424207, acc: 63.28%, op_acc: 39.06%] [G loss: 0.735398]\n",
      "epoch:31 step:24836[D loss: 0.498631, acc: 51.56%, op_acc: 37.50%] [G loss: 0.794099]\n",
      "epoch:31 step:24837[D loss: 0.395859, acc: 69.53%, op_acc: 46.09%] [G loss: 1.541208]\n",
      "epoch:31 step:24838[D loss: 0.469613, acc: 51.56%, op_acc: 37.50%] [G loss: 1.143376]\n",
      "epoch:31 step:24839[D loss: 0.481962, acc: 49.22%, op_acc: 36.72%] [G loss: 0.877332]\n",
      "epoch:31 step:24840[D loss: 0.351233, acc: 71.09%, op_acc: 49.22%] [G loss: 1.171008]\n",
      "epoch:31 step:24841[D loss: 0.404706, acc: 64.84%, op_acc: 45.31%] [G loss: 1.301490]\n",
      "epoch:31 step:24842[D loss: 0.422969, acc: 57.03%, op_acc: 37.50%] [G loss: 1.103142]\n",
      "epoch:31 step:24843[D loss: 0.417533, acc: 64.84%, op_acc: 38.28%] [G loss: 1.323038]\n",
      "epoch:31 step:24844[D loss: 0.394655, acc: 68.75%, op_acc: 44.53%] [G loss: 1.188853]\n",
      "epoch:31 step:24845[D loss: 0.411376, acc: 60.94%, op_acc: 44.53%] [G loss: 1.240606]\n",
      "epoch:31 step:24846[D loss: 0.393000, acc: 64.06%, op_acc: 46.09%] [G loss: 1.147626]\n",
      "epoch:31 step:24847[D loss: 0.356792, acc: 76.56%, op_acc: 42.19%] [G loss: 1.080728]\n",
      "epoch:31 step:24848[D loss: 0.372332, acc: 68.75%, op_acc: 39.84%] [G loss: 1.273061]\n",
      "epoch:31 step:24849[D loss: 0.381825, acc: 70.31%, op_acc: 39.84%] [G loss: 1.080679]\n",
      "epoch:31 step:24850[D loss: 0.393706, acc: 73.44%, op_acc: 44.53%] [G loss: 0.915847]\n",
      "epoch:31 step:24851[D loss: 0.387704, acc: 69.53%, op_acc: 45.31%] [G loss: 1.037518]\n",
      "epoch:31 step:24852[D loss: 0.420855, acc: 62.50%, op_acc: 38.28%] [G loss: 1.147143]\n",
      "epoch:31 step:24853[D loss: 0.413884, acc: 70.31%, op_acc: 42.19%] [G loss: 1.145965]\n",
      "epoch:31 step:24854[D loss: 0.383657, acc: 68.75%, op_acc: 42.97%] [G loss: 0.908141]\n",
      "epoch:31 step:24855[D loss: 0.355716, acc: 72.66%, op_acc: 49.22%] [G loss: 1.196177]\n",
      "epoch:31 step:24856[D loss: 0.328683, acc: 80.47%, op_acc: 43.75%] [G loss: 0.804777]\n",
      "epoch:31 step:24857[D loss: 0.424453, acc: 65.62%, op_acc: 33.59%] [G loss: 1.212846]\n",
      "epoch:31 step:24858[D loss: 0.340367, acc: 75.78%, op_acc: 46.09%] [G loss: 0.667275]\n",
      "epoch:31 step:24859[D loss: 0.376372, acc: 63.28%, op_acc: 47.66%] [G loss: 0.735592]\n",
      "epoch:31 step:24860[D loss: 0.418094, acc: 64.06%, op_acc: 42.19%] [G loss: 1.225461]\n",
      "epoch:31 step:24861[D loss: 0.408914, acc: 62.50%, op_acc: 46.09%] [G loss: 0.952438]\n",
      "epoch:31 step:24862[D loss: 0.424587, acc: 56.25%, op_acc: 41.41%] [G loss: 1.192835]\n",
      "epoch:31 step:24863[D loss: 0.398080, acc: 60.16%, op_acc: 49.22%] [G loss: 1.048558]\n",
      "epoch:31 step:24864[D loss: 0.380668, acc: 67.19%, op_acc: 48.44%] [G loss: 1.350217]\n",
      "epoch:31 step:24865[D loss: 0.446881, acc: 60.94%, op_acc: 35.94%] [G loss: 1.080121]\n",
      "epoch:31 step:24866[D loss: 0.449427, acc: 56.25%, op_acc: 39.06%] [G loss: 0.537919]\n",
      "epoch:31 step:24867[D loss: 0.377373, acc: 70.31%, op_acc: 46.09%] [G loss: 0.748106]\n",
      "epoch:31 step:24868[D loss: 0.454648, acc: 52.34%, op_acc: 36.72%] [G loss: 0.576581]\n",
      "epoch:31 step:24869[D loss: 0.415779, acc: 61.72%, op_acc: 41.41%] [G loss: 1.265620]\n",
      "epoch:31 step:24870[D loss: 0.417882, acc: 60.94%, op_acc: 35.16%] [G loss: 1.228631]\n",
      "epoch:31 step:24871[D loss: 0.337697, acc: 72.66%, op_acc: 53.91%] [G loss: 1.257171]\n",
      "epoch:31 step:24872[D loss: 0.337081, acc: 70.31%, op_acc: 55.47%] [G loss: 1.088494]\n",
      "epoch:31 step:24873[D loss: 0.393835, acc: 61.72%, op_acc: 47.66%] [G loss: 1.032019]\n",
      "epoch:31 step:24874[D loss: 0.360371, acc: 74.22%, op_acc: 45.31%] [G loss: 0.589516]\n",
      "epoch:31 step:24875[D loss: 0.410283, acc: 60.94%, op_acc: 44.53%] [G loss: 1.231449]\n",
      "epoch:31 step:24876[D loss: 0.410882, acc: 70.31%, op_acc: 34.38%] [G loss: 1.097281]\n",
      "epoch:31 step:24877[D loss: 0.417194, acc: 65.62%, op_acc: 46.88%] [G loss: 0.652861]\n",
      "epoch:31 step:24878[D loss: 0.374409, acc: 71.09%, op_acc: 42.19%] [G loss: 1.031277]\n",
      "epoch:31 step:24879[D loss: 0.361890, acc: 69.53%, op_acc: 51.56%] [G loss: 0.804297]\n",
      "epoch:31 step:24880[D loss: 0.382781, acc: 69.53%, op_acc: 44.53%] [G loss: 1.098626]\n",
      "epoch:31 step:24881[D loss: 0.386585, acc: 64.84%, op_acc: 44.53%] [G loss: 0.768928]\n",
      "epoch:31 step:24882[D loss: 0.388531, acc: 70.31%, op_acc: 41.41%] [G loss: 1.246737]\n",
      "epoch:31 step:24883[D loss: 0.386896, acc: 69.53%, op_acc: 39.84%] [G loss: 1.155076]\n",
      "epoch:31 step:24884[D loss: 0.470368, acc: 54.69%, op_acc: 34.38%] [G loss: 1.069368]\n",
      "epoch:31 step:24885[D loss: 0.427348, acc: 57.81%, op_acc: 47.66%] [G loss: 0.611444]\n",
      "epoch:31 step:24886[D loss: 0.409188, acc: 62.50%, op_acc: 42.97%] [G loss: 0.590273]\n",
      "epoch:31 step:24887[D loss: 0.400484, acc: 67.97%, op_acc: 42.19%] [G loss: 0.682384]\n",
      "epoch:31 step:24888[D loss: 0.466376, acc: 61.72%, op_acc: 36.72%] [G loss: 1.070517]\n",
      "epoch:31 step:24889[D loss: 0.414908, acc: 60.94%, op_acc: 40.62%] [G loss: 1.084766]\n",
      "epoch:31 step:24890[D loss: 0.453792, acc: 50.00%, op_acc: 39.06%] [G loss: 0.697911]\n",
      "epoch:31 step:24891[D loss: 0.381804, acc: 72.66%, op_acc: 44.53%] [G loss: 1.043950]\n",
      "epoch:31 step:24892[D loss: 0.407764, acc: 68.75%, op_acc: 40.62%] [G loss: 0.847457]\n",
      "epoch:31 step:24893[D loss: 0.362589, acc: 70.31%, op_acc: 48.44%] [G loss: 1.223826]\n",
      "epoch:31 step:24894[D loss: 0.439690, acc: 57.81%, op_acc: 42.19%] [G loss: 0.867929]\n",
      "epoch:31 step:24895[D loss: 0.357807, acc: 75.78%, op_acc: 44.53%] [G loss: 1.267222]\n",
      "epoch:31 step:24896[D loss: 0.386722, acc: 69.53%, op_acc: 43.75%] [G loss: 1.174754]\n",
      "epoch:31 step:24897[D loss: 0.374782, acc: 68.75%, op_acc: 45.31%] [G loss: 0.643894]\n",
      "epoch:31 step:24898[D loss: 0.404962, acc: 67.19%, op_acc: 43.75%] [G loss: 1.060357]\n",
      "epoch:31 step:24899[D loss: 0.367442, acc: 67.19%, op_acc: 43.75%] [G loss: 0.855376]\n",
      "epoch:31 step:24900[D loss: 0.397425, acc: 61.72%, op_acc: 45.31%] [G loss: 0.789830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:24901[D loss: 0.412247, acc: 59.38%, op_acc: 42.19%] [G loss: 1.171478]\n",
      "epoch:31 step:24902[D loss: 0.355374, acc: 73.44%, op_acc: 39.84%] [G loss: 0.755815]\n",
      "epoch:31 step:24903[D loss: 0.480320, acc: 60.94%, op_acc: 45.31%] [G loss: 0.626653]\n",
      "epoch:31 step:24904[D loss: 0.432856, acc: 59.38%, op_acc: 40.62%] [G loss: 0.888791]\n",
      "epoch:31 step:24905[D loss: 0.433448, acc: 64.06%, op_acc: 42.19%] [G loss: 0.795083]\n",
      "epoch:31 step:24906[D loss: 0.390929, acc: 63.28%, op_acc: 41.41%] [G loss: 0.655592]\n",
      "epoch:31 step:24907[D loss: 0.368714, acc: 73.44%, op_acc: 46.88%] [G loss: 0.773218]\n",
      "epoch:31 step:24908[D loss: 0.356912, acc: 67.97%, op_acc: 51.56%] [G loss: 0.881060]\n",
      "epoch:31 step:24909[D loss: 0.414003, acc: 65.62%, op_acc: 45.31%] [G loss: 1.149632]\n",
      "epoch:31 step:24910[D loss: 0.392726, acc: 64.84%, op_acc: 49.22%] [G loss: 1.211553]\n",
      "epoch:31 step:24911[D loss: 0.412433, acc: 64.84%, op_acc: 39.06%] [G loss: 1.097732]\n",
      "epoch:31 step:24912[D loss: 0.430839, acc: 62.50%, op_acc: 39.84%] [G loss: 1.143505]\n",
      "epoch:31 step:24913[D loss: 0.424096, acc: 60.94%, op_acc: 42.19%] [G loss: 0.677750]\n",
      "epoch:31 step:24914[D loss: 0.386546, acc: 67.97%, op_acc: 39.84%] [G loss: 0.972402]\n",
      "epoch:31 step:24915[D loss: 0.380317, acc: 57.81%, op_acc: 46.88%] [G loss: 1.018463]\n",
      "epoch:31 step:24916[D loss: 0.410073, acc: 65.62%, op_acc: 43.75%] [G loss: 1.251870]\n",
      "epoch:31 step:24917[D loss: 0.351218, acc: 77.34%, op_acc: 47.66%] [G loss: 1.224930]\n",
      "epoch:31 step:24918[D loss: 0.439027, acc: 63.28%, op_acc: 39.84%] [G loss: 0.801771]\n",
      "epoch:31 step:24919[D loss: 0.361675, acc: 70.31%, op_acc: 50.78%] [G loss: 1.043653]\n",
      "epoch:31 step:24920[D loss: 0.394814, acc: 67.97%, op_acc: 35.94%] [G loss: 0.883543]\n",
      "epoch:31 step:24921[D loss: 0.347443, acc: 74.22%, op_acc: 43.75%] [G loss: 1.020421]\n",
      "epoch:31 step:24922[D loss: 0.373955, acc: 70.31%, op_acc: 42.19%] [G loss: 0.973880]\n",
      "epoch:31 step:24923[D loss: 0.422644, acc: 57.03%, op_acc: 39.06%] [G loss: 1.063123]\n",
      "epoch:31 step:24924[D loss: 0.402431, acc: 55.47%, op_acc: 43.75%] [G loss: 0.871478]\n",
      "epoch:31 step:24925[D loss: 0.439690, acc: 66.41%, op_acc: 35.16%] [G loss: 0.964497]\n",
      "epoch:31 step:24926[D loss: 0.380039, acc: 67.97%, op_acc: 42.19%] [G loss: 1.084125]\n",
      "epoch:31 step:24927[D loss: 0.342158, acc: 74.22%, op_acc: 46.88%] [G loss: 0.970365]\n",
      "epoch:31 step:24928[D loss: 0.414543, acc: 59.38%, op_acc: 38.28%] [G loss: 1.074114]\n",
      "epoch:31 step:24929[D loss: 0.380235, acc: 69.53%, op_acc: 41.41%] [G loss: 1.257850]\n",
      "epoch:31 step:24930[D loss: 0.358122, acc: 71.88%, op_acc: 49.22%] [G loss: 1.056591]\n",
      "epoch:31 step:24931[D loss: 0.431658, acc: 60.16%, op_acc: 41.41%] [G loss: 1.237413]\n",
      "epoch:31 step:24932[D loss: 0.409332, acc: 66.41%, op_acc: 40.62%] [G loss: 1.240040]\n",
      "epoch:31 step:24933[D loss: 0.415501, acc: 60.94%, op_acc: 41.41%] [G loss: 1.267002]\n",
      "epoch:31 step:24934[D loss: 0.384012, acc: 64.06%, op_acc: 43.75%] [G loss: 0.895368]\n",
      "epoch:31 step:24935[D loss: 0.461137, acc: 64.84%, op_acc: 41.41%] [G loss: 1.001497]\n",
      "epoch:31 step:24936[D loss: 0.383640, acc: 67.19%, op_acc: 42.97%] [G loss: 1.017374]\n",
      "epoch:31 step:24937[D loss: 0.387262, acc: 68.75%, op_acc: 43.75%] [G loss: 1.051380]\n",
      "epoch:31 step:24938[D loss: 0.407915, acc: 62.50%, op_acc: 44.53%] [G loss: 1.268008]\n",
      "epoch:31 step:24939[D loss: 0.411282, acc: 71.88%, op_acc: 39.06%] [G loss: 1.069801]\n",
      "epoch:31 step:24940[D loss: 0.331890, acc: 74.22%, op_acc: 47.66%] [G loss: 0.865110]\n",
      "epoch:31 step:24941[D loss: 0.352418, acc: 77.34%, op_acc: 35.94%] [G loss: 0.940965]\n",
      "epoch:31 step:24942[D loss: 0.392483, acc: 68.75%, op_acc: 42.19%] [G loss: 1.069436]\n",
      "epoch:31 step:24943[D loss: 0.362067, acc: 71.09%, op_acc: 47.66%] [G loss: 1.208458]\n",
      "epoch:31 step:24944[D loss: 0.387043, acc: 68.75%, op_acc: 40.62%] [G loss: 1.126012]\n",
      "epoch:31 step:24945[D loss: 0.400017, acc: 70.31%, op_acc: 45.31%] [G loss: 1.159907]\n",
      "epoch:31 step:24946[D loss: 0.358000, acc: 71.09%, op_acc: 41.41%] [G loss: 1.051945]\n",
      "epoch:31 step:24947[D loss: 0.369954, acc: 71.09%, op_acc: 45.31%] [G loss: 1.079149]\n",
      "epoch:31 step:24948[D loss: 0.302482, acc: 79.69%, op_acc: 55.47%] [G loss: 1.094222]\n",
      "epoch:31 step:24949[D loss: 0.354662, acc: 68.75%, op_acc: 43.75%] [G loss: 0.907541]\n",
      "epoch:31 step:24950[D loss: 0.342101, acc: 71.09%, op_acc: 48.44%] [G loss: 0.918040]\n",
      "epoch:31 step:24951[D loss: 0.331130, acc: 75.00%, op_acc: 47.66%] [G loss: 1.170970]\n",
      "epoch:31 step:24952[D loss: 0.308912, acc: 80.47%, op_acc: 47.66%] [G loss: 1.117696]\n",
      "epoch:31 step:24953[D loss: 0.349491, acc: 75.00%, op_acc: 47.66%] [G loss: 1.279260]\n",
      "epoch:31 step:24954[D loss: 0.332759, acc: 78.12%, op_acc: 49.22%] [G loss: 1.210217]\n",
      "epoch:31 step:24955[D loss: 0.289433, acc: 85.94%, op_acc: 57.03%] [G loss: 0.725733]\n",
      "epoch:31 step:24956[D loss: 0.399136, acc: 64.06%, op_acc: 40.62%] [G loss: 0.995552]\n",
      "epoch:31 step:24957[D loss: 0.382031, acc: 71.88%, op_acc: 38.28%] [G loss: 1.506980]\n",
      "epoch:31 step:24958[D loss: 0.382416, acc: 67.19%, op_acc: 39.84%] [G loss: 1.314022]\n",
      "epoch:31 step:24959[D loss: 0.330809, acc: 80.47%, op_acc: 42.97%] [G loss: 1.357171]\n",
      "epoch:31 step:24960[D loss: 0.385001, acc: 69.53%, op_acc: 50.00%] [G loss: 1.213520]\n",
      "epoch:31 step:24961[D loss: 0.381262, acc: 67.97%, op_acc: 46.09%] [G loss: 1.247039]\n",
      "epoch:31 step:24962[D loss: 0.369232, acc: 73.44%, op_acc: 44.53%] [G loss: 1.292861]\n",
      "epoch:31 step:24963[D loss: 0.337226, acc: 78.91%, op_acc: 52.34%] [G loss: 0.873862]\n",
      "epoch:31 step:24964[D loss: 0.346770, acc: 74.22%, op_acc: 47.66%] [G loss: 1.524248]\n",
      "epoch:31 step:24965[D loss: 0.346200, acc: 75.78%, op_acc: 48.44%] [G loss: 0.946206]\n",
      "epoch:31 step:24966[D loss: 0.375859, acc: 66.41%, op_acc: 46.09%] [G loss: 1.740398]\n",
      "epoch:31 step:24967[D loss: 0.419793, acc: 58.59%, op_acc: 40.62%] [G loss: 1.502321]\n",
      "epoch:31 step:24968[D loss: 0.361054, acc: 75.00%, op_acc: 43.75%] [G loss: 1.622111]\n",
      "epoch:31 step:24969[D loss: 0.333914, acc: 71.88%, op_acc: 56.25%] [G loss: 1.246770]\n",
      "epoch:31 step:24970[D loss: 0.401724, acc: 67.97%, op_acc: 40.62%] [G loss: 1.400351]\n",
      "epoch:31 step:24971[D loss: 0.354704, acc: 67.97%, op_acc: 51.56%] [G loss: 1.341257]\n",
      "epoch:31 step:24972[D loss: 0.312623, acc: 82.03%, op_acc: 53.12%] [G loss: 1.659283]\n",
      "epoch:31 step:24973[D loss: 0.371031, acc: 66.41%, op_acc: 46.88%] [G loss: 0.918029]\n",
      "epoch:31 step:24974[D loss: 0.410414, acc: 64.06%, op_acc: 49.22%] [G loss: 1.250280]\n",
      "epoch:31 step:24975[D loss: 0.432677, acc: 59.38%, op_acc: 41.41%] [G loss: 1.329329]\n",
      "epoch:31 step:24976[D loss: 0.428359, acc: 60.94%, op_acc: 48.44%] [G loss: 0.885925]\n",
      "epoch:31 step:24977[D loss: 0.460068, acc: 57.03%, op_acc: 40.62%] [G loss: 0.932268]\n",
      "epoch:31 step:24978[D loss: 0.360258, acc: 72.66%, op_acc: 46.88%] [G loss: 1.373179]\n",
      "epoch:31 step:24979[D loss: 0.415559, acc: 62.50%, op_acc: 42.97%] [G loss: 1.003684]\n",
      "epoch:31 step:24980[D loss: 0.432271, acc: 59.38%, op_acc: 46.09%] [G loss: 1.040580]\n",
      "epoch:31 step:24981[D loss: 0.460184, acc: 50.78%, op_acc: 42.97%] [G loss: 1.356336]\n",
      "epoch:31 step:24982[D loss: 0.459546, acc: 54.69%, op_acc: 42.97%] [G loss: 1.154818]\n",
      "epoch:31 step:24983[D loss: 0.446972, acc: 61.72%, op_acc: 37.50%] [G loss: 1.193242]\n",
      "epoch:31 step:24984[D loss: 0.449810, acc: 56.25%, op_acc: 48.44%] [G loss: 1.117957]\n",
      "epoch:31 step:24985[D loss: 0.336123, acc: 76.56%, op_acc: 46.09%] [G loss: 0.980378]\n",
      "epoch:31 step:24986[D loss: 0.413729, acc: 64.84%, op_acc: 40.62%] [G loss: 1.022636]\n",
      "epoch:31 step:24987[D loss: 0.416628, acc: 61.72%, op_acc: 35.16%] [G loss: 1.070174]\n",
      "epoch:31 step:24988[D loss: 0.387297, acc: 75.78%, op_acc: 45.31%] [G loss: 1.166076]\n",
      "epoch:31 step:24989[D loss: 0.428902, acc: 56.25%, op_acc: 47.66%] [G loss: 0.953619]\n",
      "epoch:31 step:24990[D loss: 0.405984, acc: 60.16%, op_acc: 42.97%] [G loss: 1.111049]\n",
      "epoch:31 step:24991[D loss: 0.397873, acc: 62.50%, op_acc: 41.41%] [G loss: 1.049690]\n",
      "epoch:31 step:24992[D loss: 0.394155, acc: 73.44%, op_acc: 39.84%] [G loss: 0.996572]\n",
      "epoch:32 step:24993[D loss: 0.418795, acc: 64.06%, op_acc: 42.97%] [G loss: 1.085868]\n",
      "epoch:32 step:24994[D loss: 0.403831, acc: 64.06%, op_acc: 48.44%] [G loss: 0.950906]\n",
      "epoch:32 step:24995[D loss: 0.407566, acc: 57.03%, op_acc: 43.75%] [G loss: 0.812887]\n",
      "epoch:32 step:24996[D loss: 0.377973, acc: 71.09%, op_acc: 45.31%] [G loss: 1.386283]\n",
      "epoch:32 step:24997[D loss: 0.440041, acc: 58.59%, op_acc: 35.94%] [G loss: 1.019205]\n",
      "epoch:32 step:24998[D loss: 0.398365, acc: 70.31%, op_acc: 38.28%] [G loss: 0.918891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:24999[D loss: 0.373761, acc: 71.88%, op_acc: 42.19%] [G loss: 1.284700]\n",
      "epoch:32 step:25000[D loss: 0.425102, acc: 62.50%, op_acc: 41.41%] [G loss: 1.106464]\n",
      "epoch:32 step:25001[D loss: 0.426015, acc: 53.91%, op_acc: 42.97%] [G loss: 1.195629]\n",
      "epoch:32 step:25002[D loss: 0.413708, acc: 62.50%, op_acc: 34.38%] [G loss: 1.028790]\n",
      "epoch:32 step:25003[D loss: 0.465489, acc: 60.16%, op_acc: 40.62%] [G loss: 0.888471]\n",
      "epoch:32 step:25004[D loss: 0.466496, acc: 58.59%, op_acc: 39.84%] [G loss: 0.943189]\n",
      "epoch:32 step:25005[D loss: 0.423691, acc: 59.38%, op_acc: 39.06%] [G loss: 0.996783]\n",
      "epoch:32 step:25006[D loss: 0.381271, acc: 70.31%, op_acc: 42.97%] [G loss: 1.339349]\n",
      "epoch:32 step:25007[D loss: 0.391078, acc: 61.72%, op_acc: 47.66%] [G loss: 1.202283]\n",
      "epoch:32 step:25008[D loss: 0.346345, acc: 73.44%, op_acc: 47.66%] [G loss: 1.276473]\n",
      "epoch:32 step:25009[D loss: 0.420737, acc: 61.72%, op_acc: 43.75%] [G loss: 0.899976]\n",
      "epoch:32 step:25010[D loss: 0.406139, acc: 65.62%, op_acc: 42.97%] [G loss: 0.937319]\n",
      "epoch:32 step:25011[D loss: 0.371767, acc: 68.75%, op_acc: 45.31%] [G loss: 0.854853]\n",
      "epoch:32 step:25012[D loss: 0.369898, acc: 71.88%, op_acc: 50.78%] [G loss: 1.219925]\n",
      "epoch:32 step:25013[D loss: 0.391257, acc: 67.19%, op_acc: 46.88%] [G loss: 1.155191]\n",
      "epoch:32 step:25014[D loss: 0.370235, acc: 70.31%, op_acc: 51.56%] [G loss: 0.873755]\n",
      "epoch:32 step:25015[D loss: 0.387638, acc: 68.75%, op_acc: 46.09%] [G loss: 0.942831]\n",
      "epoch:32 step:25016[D loss: 0.446481, acc: 53.12%, op_acc: 41.41%] [G loss: 1.051220]\n",
      "epoch:32 step:25017[D loss: 0.440314, acc: 61.72%, op_acc: 39.84%] [G loss: 0.846413]\n",
      "epoch:32 step:25018[D loss: 0.362756, acc: 75.00%, op_acc: 41.41%] [G loss: 1.129877]\n",
      "epoch:32 step:25019[D loss: 0.377144, acc: 71.09%, op_acc: 46.09%] [G loss: 1.173305]\n",
      "epoch:32 step:25020[D loss: 0.420071, acc: 57.81%, op_acc: 46.88%] [G loss: 1.120873]\n",
      "epoch:32 step:25021[D loss: 0.372802, acc: 64.84%, op_acc: 49.22%] [G loss: 1.137845]\n",
      "epoch:32 step:25022[D loss: 0.364269, acc: 67.97%, op_acc: 46.88%] [G loss: 1.102801]\n",
      "epoch:32 step:25023[D loss: 0.403800, acc: 65.62%, op_acc: 41.41%] [G loss: 1.106506]\n",
      "epoch:32 step:25024[D loss: 0.442026, acc: 60.94%, op_acc: 39.06%] [G loss: 0.815860]\n",
      "epoch:32 step:25025[D loss: 0.445842, acc: 57.03%, op_acc: 47.66%] [G loss: 0.685911]\n",
      "epoch:32 step:25026[D loss: 0.373658, acc: 65.62%, op_acc: 46.88%] [G loss: 1.063531]\n",
      "epoch:32 step:25027[D loss: 0.390436, acc: 71.09%, op_acc: 44.53%] [G loss: 1.101135]\n",
      "epoch:32 step:25028[D loss: 0.379649, acc: 64.06%, op_acc: 44.53%] [G loss: 1.015931]\n",
      "epoch:32 step:25029[D loss: 0.404106, acc: 66.41%, op_acc: 39.84%] [G loss: 0.860311]\n",
      "epoch:32 step:25030[D loss: 0.454278, acc: 53.12%, op_acc: 38.28%] [G loss: 0.707796]\n",
      "epoch:32 step:25031[D loss: 0.347447, acc: 74.22%, op_acc: 43.75%] [G loss: 1.196290]\n",
      "epoch:32 step:25032[D loss: 0.440933, acc: 59.38%, op_acc: 38.28%] [G loss: 0.840009]\n",
      "epoch:32 step:25033[D loss: 0.363866, acc: 66.41%, op_acc: 48.44%] [G loss: 0.653952]\n",
      "epoch:32 step:25034[D loss: 0.361072, acc: 67.97%, op_acc: 48.44%] [G loss: 0.748573]\n",
      "epoch:32 step:25035[D loss: 0.418279, acc: 60.94%, op_acc: 41.41%] [G loss: 1.267519]\n",
      "epoch:32 step:25036[D loss: 0.400862, acc: 60.16%, op_acc: 46.88%] [G loss: 1.027263]\n",
      "epoch:32 step:25037[D loss: 0.366603, acc: 66.41%, op_acc: 47.66%] [G loss: 0.937765]\n",
      "epoch:32 step:25038[D loss: 0.362661, acc: 70.31%, op_acc: 46.88%] [G loss: 1.105169]\n",
      "epoch:32 step:25039[D loss: 0.412869, acc: 62.50%, op_acc: 42.19%] [G loss: 1.182236]\n",
      "epoch:32 step:25040[D loss: 0.412074, acc: 70.31%, op_acc: 36.72%] [G loss: 0.662030]\n",
      "epoch:32 step:25041[D loss: 0.345434, acc: 67.97%, op_acc: 42.19%] [G loss: 0.692144]\n",
      "epoch:32 step:25042[D loss: 0.384859, acc: 70.31%, op_acc: 42.19%] [G loss: 0.668618]\n",
      "epoch:32 step:25043[D loss: 0.361334, acc: 75.00%, op_acc: 49.22%] [G loss: 0.755357]\n",
      "epoch:32 step:25044[D loss: 0.408031, acc: 63.28%, op_acc: 42.97%] [G loss: 0.698207]\n",
      "epoch:32 step:25045[D loss: 0.417302, acc: 60.94%, op_acc: 40.62%] [G loss: 1.169163]\n",
      "epoch:32 step:25046[D loss: 0.427637, acc: 56.25%, op_acc: 39.06%] [G loss: 0.802118]\n",
      "epoch:32 step:25047[D loss: 0.366321, acc: 73.44%, op_acc: 42.19%] [G loss: 0.859258]\n",
      "epoch:32 step:25048[D loss: 0.421345, acc: 60.16%, op_acc: 39.84%] [G loss: 1.210324]\n",
      "epoch:32 step:25049[D loss: 0.425306, acc: 64.84%, op_acc: 43.75%] [G loss: 0.948947]\n",
      "epoch:32 step:25050[D loss: 0.396972, acc: 62.50%, op_acc: 45.31%] [G loss: 1.004010]\n",
      "epoch:32 step:25051[D loss: 0.373897, acc: 67.19%, op_acc: 47.66%] [G loss: 0.901594]\n",
      "epoch:32 step:25052[D loss: 0.382683, acc: 67.19%, op_acc: 47.66%] [G loss: 0.911464]\n",
      "epoch:32 step:25053[D loss: 0.405546, acc: 68.75%, op_acc: 48.44%] [G loss: 1.007357]\n",
      "epoch:32 step:25054[D loss: 0.422024, acc: 59.38%, op_acc: 39.84%] [G loss: 0.991753]\n",
      "epoch:32 step:25055[D loss: 0.409628, acc: 60.16%, op_acc: 39.84%] [G loss: 1.018095]\n",
      "epoch:32 step:25056[D loss: 0.429868, acc: 57.81%, op_acc: 42.97%] [G loss: 0.913784]\n",
      "epoch:32 step:25057[D loss: 0.380197, acc: 75.00%, op_acc: 40.62%] [G loss: 1.144428]\n",
      "epoch:32 step:25058[D loss: 0.379203, acc: 68.75%, op_acc: 47.66%] [G loss: 0.843208]\n",
      "epoch:32 step:25059[D loss: 0.371084, acc: 67.97%, op_acc: 47.66%] [G loss: 0.875264]\n",
      "epoch:32 step:25060[D loss: 0.395494, acc: 64.06%, op_acc: 40.62%] [G loss: 0.920940]\n",
      "epoch:32 step:25061[D loss: 0.360378, acc: 67.97%, op_acc: 50.00%] [G loss: 0.687094]\n",
      "epoch:32 step:25062[D loss: 0.404553, acc: 67.97%, op_acc: 39.84%] [G loss: 0.668618]\n",
      "epoch:32 step:25063[D loss: 0.430668, acc: 64.06%, op_acc: 35.94%] [G loss: 0.950353]\n",
      "epoch:32 step:25064[D loss: 0.325555, acc: 78.12%, op_acc: 48.44%] [G loss: 1.077731]\n",
      "epoch:32 step:25065[D loss: 0.415857, acc: 62.50%, op_acc: 44.53%] [G loss: 1.186343]\n",
      "epoch:32 step:25066[D loss: 0.350401, acc: 75.00%, op_acc: 49.22%] [G loss: 1.068850]\n",
      "epoch:32 step:25067[D loss: 0.369658, acc: 65.62%, op_acc: 42.19%] [G loss: 0.909142]\n",
      "epoch:32 step:25068[D loss: 0.445191, acc: 60.94%, op_acc: 37.50%] [G loss: 1.113479]\n",
      "epoch:32 step:25069[D loss: 0.428293, acc: 64.84%, op_acc: 39.84%] [G loss: 0.811324]\n",
      "epoch:32 step:25070[D loss: 0.407670, acc: 70.31%, op_acc: 31.25%] [G loss: 0.783458]\n",
      "epoch:32 step:25071[D loss: 0.447660, acc: 52.34%, op_acc: 44.53%] [G loss: 0.790570]\n",
      "epoch:32 step:25072[D loss: 0.398567, acc: 70.31%, op_acc: 40.62%] [G loss: 0.749899]\n",
      "epoch:32 step:25073[D loss: 0.423213, acc: 62.50%, op_acc: 38.28%] [G loss: 0.847033]\n",
      "epoch:32 step:25074[D loss: 0.389423, acc: 62.50%, op_acc: 45.31%] [G loss: 1.105759]\n",
      "epoch:32 step:25075[D loss: 0.375258, acc: 64.84%, op_acc: 44.53%] [G loss: 0.968368]\n",
      "epoch:32 step:25076[D loss: 0.355788, acc: 71.09%, op_acc: 48.44%] [G loss: 1.179959]\n",
      "epoch:32 step:25077[D loss: 0.365032, acc: 79.69%, op_acc: 46.88%] [G loss: 0.909870]\n",
      "epoch:32 step:25078[D loss: 0.417576, acc: 64.84%, op_acc: 43.75%] [G loss: 0.990643]\n",
      "epoch:32 step:25079[D loss: 0.373000, acc: 68.75%, op_acc: 47.66%] [G loss: 1.188310]\n",
      "epoch:32 step:25080[D loss: 0.412782, acc: 64.84%, op_acc: 39.06%] [G loss: 1.189579]\n",
      "epoch:32 step:25081[D loss: 0.372319, acc: 70.31%, op_acc: 47.66%] [G loss: 0.977015]\n",
      "epoch:32 step:25082[D loss: 0.380037, acc: 67.97%, op_acc: 46.88%] [G loss: 1.074962]\n",
      "epoch:32 step:25083[D loss: 0.320638, acc: 75.00%, op_acc: 48.44%] [G loss: 1.189898]\n",
      "epoch:32 step:25084[D loss: 0.376776, acc: 66.41%, op_acc: 45.31%] [G loss: 1.178599]\n",
      "epoch:32 step:25085[D loss: 0.323876, acc: 78.12%, op_acc: 54.69%] [G loss: 1.184642]\n",
      "epoch:32 step:25086[D loss: 0.310202, acc: 78.91%, op_acc: 50.78%] [G loss: 0.799500]\n",
      "epoch:32 step:25087[D loss: 0.384724, acc: 70.31%, op_acc: 38.28%] [G loss: 0.830667]\n",
      "epoch:32 step:25088[D loss: 0.418614, acc: 64.84%, op_acc: 35.94%] [G loss: 1.369432]\n",
      "epoch:32 step:25089[D loss: 0.367329, acc: 69.53%, op_acc: 48.44%] [G loss: 1.053753]\n",
      "epoch:32 step:25090[D loss: 0.340996, acc: 78.12%, op_acc: 42.97%] [G loss: 1.413722]\n",
      "epoch:32 step:25091[D loss: 0.402251, acc: 71.09%, op_acc: 41.41%] [G loss: 1.179076]\n",
      "epoch:32 step:25092[D loss: 0.356474, acc: 67.97%, op_acc: 48.44%] [G loss: 1.212843]\n",
      "epoch:32 step:25093[D loss: 0.382712, acc: 70.31%, op_acc: 44.53%] [G loss: 0.963479]\n",
      "epoch:32 step:25094[D loss: 0.372845, acc: 65.62%, op_acc: 42.97%] [G loss: 1.431069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25095[D loss: 0.343847, acc: 74.22%, op_acc: 45.31%] [G loss: 1.091489]\n",
      "epoch:32 step:25096[D loss: 0.298050, acc: 86.72%, op_acc: 50.78%] [G loss: 1.227299]\n",
      "epoch:32 step:25097[D loss: 0.358339, acc: 73.44%, op_acc: 42.97%] [G loss: 1.347255]\n",
      "epoch:32 step:25098[D loss: 0.320083, acc: 78.12%, op_acc: 53.91%] [G loss: 0.791884]\n",
      "epoch:32 step:25099[D loss: 0.376052, acc: 70.31%, op_acc: 44.53%] [G loss: 0.718914]\n",
      "epoch:32 step:25100[D loss: 0.469999, acc: 55.47%, op_acc: 40.62%] [G loss: 1.230456]\n",
      "epoch:32 step:25101[D loss: 0.362844, acc: 70.31%, op_acc: 35.94%] [G loss: 1.336150]\n",
      "epoch:32 step:25102[D loss: 0.352222, acc: 77.34%, op_acc: 51.56%] [G loss: 1.089055]\n",
      "epoch:32 step:25103[D loss: 0.380087, acc: 71.88%, op_acc: 43.75%] [G loss: 1.250116]\n",
      "epoch:32 step:25104[D loss: 0.375480, acc: 67.97%, op_acc: 46.09%] [G loss: 1.230918]\n",
      "epoch:32 step:25105[D loss: 0.352992, acc: 74.22%, op_acc: 50.78%] [G loss: 1.219280]\n",
      "epoch:32 step:25106[D loss: 0.352686, acc: 73.44%, op_acc: 53.12%] [G loss: 0.836786]\n",
      "epoch:32 step:25107[D loss: 0.373127, acc: 67.97%, op_acc: 42.97%] [G loss: 1.028906]\n",
      "epoch:32 step:25108[D loss: 0.402663, acc: 62.50%, op_acc: 44.53%] [G loss: 1.186147]\n",
      "epoch:32 step:25109[D loss: 0.388056, acc: 67.97%, op_acc: 46.09%] [G loss: 1.072061]\n",
      "epoch:32 step:25110[D loss: 0.376515, acc: 61.72%, op_acc: 48.44%] [G loss: 1.023686]\n",
      "epoch:32 step:25111[D loss: 0.375009, acc: 67.97%, op_acc: 46.09%] [G loss: 1.119857]\n",
      "epoch:32 step:25112[D loss: 0.406375, acc: 63.28%, op_acc: 45.31%] [G loss: 1.022805]\n",
      "epoch:32 step:25113[D loss: 0.459922, acc: 53.12%, op_acc: 40.62%] [G loss: 1.019827]\n",
      "epoch:32 step:25114[D loss: 0.392555, acc: 67.97%, op_acc: 44.53%] [G loss: 1.087553]\n",
      "epoch:32 step:25115[D loss: 0.460097, acc: 52.34%, op_acc: 37.50%] [G loss: 1.136757]\n",
      "epoch:32 step:25116[D loss: 0.375374, acc: 69.53%, op_acc: 45.31%] [G loss: 1.144837]\n",
      "epoch:32 step:25117[D loss: 0.391309, acc: 73.44%, op_acc: 35.94%] [G loss: 0.986405]\n",
      "epoch:32 step:25118[D loss: 0.344410, acc: 75.00%, op_acc: 50.78%] [G loss: 0.859629]\n",
      "epoch:32 step:25119[D loss: 0.408265, acc: 67.19%, op_acc: 42.19%] [G loss: 1.029595]\n",
      "epoch:32 step:25120[D loss: 0.389744, acc: 72.66%, op_acc: 46.09%] [G loss: 1.113081]\n",
      "epoch:32 step:25121[D loss: 0.417999, acc: 62.50%, op_acc: 40.62%] [G loss: 1.146592]\n",
      "epoch:32 step:25122[D loss: 0.335696, acc: 75.78%, op_acc: 53.12%] [G loss: 0.857275]\n",
      "epoch:32 step:25123[D loss: 0.401011, acc: 63.28%, op_acc: 38.28%] [G loss: 1.122966]\n",
      "epoch:32 step:25124[D loss: 0.355322, acc: 71.09%, op_acc: 48.44%] [G loss: 1.122787]\n",
      "epoch:32 step:25125[D loss: 0.429519, acc: 60.94%, op_acc: 42.19%] [G loss: 1.101333]\n",
      "epoch:32 step:25126[D loss: 0.397270, acc: 66.41%, op_acc: 46.09%] [G loss: 1.155467]\n",
      "epoch:32 step:25127[D loss: 0.406613, acc: 67.97%, op_acc: 48.44%] [G loss: 1.066873]\n",
      "epoch:32 step:25128[D loss: 0.400538, acc: 66.41%, op_acc: 44.53%] [G loss: 1.112913]\n",
      "epoch:32 step:25129[D loss: 0.443592, acc: 60.94%, op_acc: 38.28%] [G loss: 1.156488]\n",
      "epoch:32 step:25130[D loss: 0.427760, acc: 63.28%, op_acc: 42.19%] [G loss: 1.058751]\n",
      "epoch:32 step:25131[D loss: 0.411914, acc: 63.28%, op_acc: 37.50%] [G loss: 1.093457]\n",
      "epoch:32 step:25132[D loss: 0.431759, acc: 59.38%, op_acc: 40.62%] [G loss: 0.869754]\n",
      "epoch:32 step:25133[D loss: 0.453419, acc: 51.56%, op_acc: 35.94%] [G loss: 0.730304]\n",
      "epoch:32 step:25134[D loss: 0.383861, acc: 69.53%, op_acc: 43.75%] [G loss: 1.049267]\n",
      "epoch:32 step:25135[D loss: 0.388279, acc: 70.31%, op_acc: 43.75%] [G loss: 0.899610]\n",
      "epoch:32 step:25136[D loss: 0.391468, acc: 65.62%, op_acc: 40.62%] [G loss: 0.871414]\n",
      "epoch:32 step:25137[D loss: 0.404728, acc: 60.94%, op_acc: 44.53%] [G loss: 1.003678]\n",
      "epoch:32 step:25138[D loss: 0.381074, acc: 64.84%, op_acc: 47.66%] [G loss: 1.195899]\n",
      "epoch:32 step:25139[D loss: 0.372902, acc: 66.41%, op_acc: 47.66%] [G loss: 0.766290]\n",
      "epoch:32 step:25140[D loss: 0.456315, acc: 60.94%, op_acc: 36.72%] [G loss: 0.726607]\n",
      "epoch:32 step:25141[D loss: 0.425462, acc: 62.50%, op_acc: 46.09%] [G loss: 0.789910]\n",
      "epoch:32 step:25142[D loss: 0.416325, acc: 61.72%, op_acc: 42.97%] [G loss: 1.103464]\n",
      "epoch:32 step:25143[D loss: 0.376182, acc: 67.19%, op_acc: 44.53%] [G loss: 1.041670]\n",
      "epoch:32 step:25144[D loss: 0.381851, acc: 71.09%, op_acc: 42.19%] [G loss: 0.954422]\n",
      "epoch:32 step:25145[D loss: 0.430589, acc: 58.59%, op_acc: 43.75%] [G loss: 0.924891]\n",
      "epoch:32 step:25146[D loss: 0.417646, acc: 58.59%, op_acc: 39.84%] [G loss: 0.777853]\n",
      "epoch:32 step:25147[D loss: 0.382717, acc: 67.97%, op_acc: 41.41%] [G loss: 0.960893]\n",
      "epoch:32 step:25148[D loss: 0.433039, acc: 57.81%, op_acc: 40.62%] [G loss: 1.222808]\n",
      "epoch:32 step:25149[D loss: 0.388875, acc: 68.75%, op_acc: 43.75%] [G loss: 1.100148]\n",
      "epoch:32 step:25150[D loss: 0.375209, acc: 64.06%, op_acc: 44.53%] [G loss: 1.183197]\n",
      "epoch:32 step:25151[D loss: 0.373839, acc: 73.44%, op_acc: 42.97%] [G loss: 1.178971]\n",
      "epoch:32 step:25152[D loss: 0.376055, acc: 73.44%, op_acc: 44.53%] [G loss: 0.752553]\n",
      "epoch:32 step:25153[D loss: 0.394780, acc: 71.09%, op_acc: 42.97%] [G loss: 1.149352]\n",
      "epoch:32 step:25154[D loss: 0.364319, acc: 71.88%, op_acc: 47.66%] [G loss: 1.155573]\n",
      "epoch:32 step:25155[D loss: 0.357112, acc: 70.31%, op_acc: 50.00%] [G loss: 1.206395]\n",
      "epoch:32 step:25156[D loss: 0.366643, acc: 75.00%, op_acc: 40.62%] [G loss: 1.070674]\n",
      "epoch:32 step:25157[D loss: 0.353715, acc: 71.88%, op_acc: 48.44%] [G loss: 1.011930]\n",
      "epoch:32 step:25158[D loss: 0.346894, acc: 75.00%, op_acc: 43.75%] [G loss: 0.779278]\n",
      "epoch:32 step:25159[D loss: 0.467452, acc: 51.56%, op_acc: 39.06%] [G loss: 1.033348]\n",
      "epoch:32 step:25160[D loss: 0.376377, acc: 74.22%, op_acc: 48.44%] [G loss: 0.896129]\n",
      "epoch:32 step:25161[D loss: 0.431943, acc: 62.50%, op_acc: 44.53%] [G loss: 1.413106]\n",
      "epoch:32 step:25162[D loss: 0.434475, acc: 62.50%, op_acc: 42.19%] [G loss: 1.193448]\n",
      "epoch:32 step:25163[D loss: 0.430402, acc: 59.38%, op_acc: 42.97%] [G loss: 0.908977]\n",
      "epoch:32 step:25164[D loss: 0.374815, acc: 74.22%, op_acc: 44.53%] [G loss: 0.923136]\n",
      "epoch:32 step:25165[D loss: 0.399802, acc: 65.62%, op_acc: 45.31%] [G loss: 1.042351]\n",
      "epoch:32 step:25166[D loss: 0.474775, acc: 51.56%, op_acc: 39.84%] [G loss: 1.145439]\n",
      "epoch:32 step:25167[D loss: 0.384145, acc: 67.97%, op_acc: 49.22%] [G loss: 1.207480]\n",
      "epoch:32 step:25168[D loss: 0.341689, acc: 75.78%, op_acc: 50.00%] [G loss: 1.306189]\n",
      "epoch:32 step:25169[D loss: 0.346015, acc: 73.44%, op_acc: 53.12%] [G loss: 0.985460]\n",
      "epoch:32 step:25170[D loss: 0.434655, acc: 61.72%, op_acc: 42.97%] [G loss: 0.966227]\n",
      "epoch:32 step:25171[D loss: 0.366067, acc: 73.44%, op_acc: 46.09%] [G loss: 1.097664]\n",
      "epoch:32 step:25172[D loss: 0.409786, acc: 61.72%, op_acc: 38.28%] [G loss: 1.010168]\n",
      "epoch:32 step:25173[D loss: 0.377471, acc: 67.19%, op_acc: 46.09%] [G loss: 1.203226]\n",
      "epoch:32 step:25174[D loss: 0.401041, acc: 63.28%, op_acc: 47.66%] [G loss: 1.066036]\n",
      "epoch:32 step:25175[D loss: 0.395045, acc: 66.41%, op_acc: 43.75%] [G loss: 0.774791]\n",
      "epoch:32 step:25176[D loss: 0.364796, acc: 70.31%, op_acc: 43.75%] [G loss: 0.904067]\n",
      "epoch:32 step:25177[D loss: 0.426838, acc: 67.19%, op_acc: 40.62%] [G loss: 1.181340]\n",
      "epoch:32 step:25178[D loss: 0.415428, acc: 62.50%, op_acc: 41.41%] [G loss: 1.050706]\n",
      "epoch:32 step:25179[D loss: 0.376243, acc: 69.53%, op_acc: 49.22%] [G loss: 0.965993]\n",
      "epoch:32 step:25180[D loss: 0.398406, acc: 62.50%, op_acc: 41.41%] [G loss: 0.950890]\n",
      "epoch:32 step:25181[D loss: 0.357552, acc: 73.44%, op_acc: 40.62%] [G loss: 1.129701]\n",
      "epoch:32 step:25182[D loss: 0.446030, acc: 56.25%, op_acc: 36.72%] [G loss: 1.192732]\n",
      "epoch:32 step:25183[D loss: 0.387119, acc: 61.72%, op_acc: 40.62%] [G loss: 1.116574]\n",
      "epoch:32 step:25184[D loss: 0.373257, acc: 67.19%, op_acc: 45.31%] [G loss: 1.071871]\n",
      "epoch:32 step:25185[D loss: 0.419987, acc: 62.50%, op_acc: 42.19%] [G loss: 1.053700]\n",
      "epoch:32 step:25186[D loss: 0.420390, acc: 59.38%, op_acc: 44.53%] [G loss: 0.627711]\n",
      "epoch:32 step:25187[D loss: 0.407620, acc: 61.72%, op_acc: 42.97%] [G loss: 1.096825]\n",
      "epoch:32 step:25188[D loss: 0.399469, acc: 68.75%, op_acc: 45.31%] [G loss: 0.702007]\n",
      "epoch:32 step:25189[D loss: 0.453091, acc: 57.81%, op_acc: 39.84%] [G loss: 0.828795]\n",
      "epoch:32 step:25190[D loss: 0.407133, acc: 60.94%, op_acc: 40.62%] [G loss: 1.135757]\n",
      "epoch:32 step:25191[D loss: 0.392909, acc: 60.94%, op_acc: 43.75%] [G loss: 1.135917]\n",
      "epoch:32 step:25192[D loss: 0.377596, acc: 71.88%, op_acc: 48.44%] [G loss: 1.282124]\n",
      "epoch:32 step:25193[D loss: 0.388947, acc: 64.06%, op_acc: 45.31%] [G loss: 0.685644]\n",
      "epoch:32 step:25194[D loss: 0.389729, acc: 61.72%, op_acc: 45.31%] [G loss: 0.680945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25195[D loss: 0.401126, acc: 67.97%, op_acc: 36.72%] [G loss: 1.248619]\n",
      "epoch:32 step:25196[D loss: 0.394153, acc: 64.06%, op_acc: 41.41%] [G loss: 0.759432]\n",
      "epoch:32 step:25197[D loss: 0.413701, acc: 61.72%, op_acc: 41.41%] [G loss: 0.806032]\n",
      "epoch:32 step:25198[D loss: 0.427230, acc: 61.72%, op_acc: 42.97%] [G loss: 0.748600]\n",
      "epoch:32 step:25199[D loss: 0.360660, acc: 68.75%, op_acc: 50.78%] [G loss: 0.699647]\n",
      "epoch:32 step:25200[D loss: 0.369467, acc: 73.44%, op_acc: 44.53%] [G loss: 0.834517]\n",
      "epoch:32 step:25201[D loss: 0.371790, acc: 67.97%, op_acc: 48.44%] [G loss: 0.677403]\n",
      "epoch:32 step:25202[D loss: 0.424611, acc: 60.94%, op_acc: 40.62%] [G loss: 0.739022]\n",
      "epoch:32 step:25203[D loss: 0.399601, acc: 65.62%, op_acc: 46.88%] [G loss: 1.124418]\n",
      "epoch:32 step:25204[D loss: 0.407334, acc: 65.62%, op_acc: 41.41%] [G loss: 0.909420]\n",
      "epoch:32 step:25205[D loss: 0.389723, acc: 67.97%, op_acc: 49.22%] [G loss: 0.810324]\n",
      "epoch:32 step:25206[D loss: 0.396165, acc: 68.75%, op_acc: 38.28%] [G loss: 0.796683]\n",
      "epoch:32 step:25207[D loss: 0.424266, acc: 60.94%, op_acc: 42.97%] [G loss: 0.884131]\n",
      "epoch:32 step:25208[D loss: 0.359414, acc: 72.66%, op_acc: 46.09%] [G loss: 0.804683]\n",
      "epoch:32 step:25209[D loss: 0.367722, acc: 70.31%, op_acc: 46.88%] [G loss: 0.824097]\n",
      "epoch:32 step:25210[D loss: 0.411668, acc: 63.28%, op_acc: 49.22%] [G loss: 0.876656]\n",
      "epoch:32 step:25211[D loss: 0.351038, acc: 71.09%, op_acc: 46.88%] [G loss: 1.158281]\n",
      "epoch:32 step:25212[D loss: 0.396401, acc: 64.06%, op_acc: 43.75%] [G loss: 1.174254]\n",
      "epoch:32 step:25213[D loss: 0.374362, acc: 71.88%, op_acc: 49.22%] [G loss: 0.783077]\n",
      "epoch:32 step:25214[D loss: 0.354441, acc: 74.22%, op_acc: 49.22%] [G loss: 0.949522]\n",
      "epoch:32 step:25215[D loss: 0.418841, acc: 61.72%, op_acc: 41.41%] [G loss: 1.004861]\n",
      "epoch:32 step:25216[D loss: 0.347846, acc: 71.09%, op_acc: 46.09%] [G loss: 1.037506]\n",
      "epoch:32 step:25217[D loss: 0.353029, acc: 76.56%, op_acc: 43.75%] [G loss: 0.783069]\n",
      "epoch:32 step:25218[D loss: 0.328650, acc: 81.25%, op_acc: 50.78%] [G loss: 1.036396]\n",
      "epoch:32 step:25219[D loss: 0.325621, acc: 80.47%, op_acc: 45.31%] [G loss: 0.904925]\n",
      "epoch:32 step:25220[D loss: 0.303988, acc: 81.25%, op_acc: 56.25%] [G loss: 0.986747]\n",
      "epoch:32 step:25221[D loss: 0.357367, acc: 73.44%, op_acc: 48.44%] [G loss: 1.113973]\n",
      "epoch:32 step:25222[D loss: 0.398040, acc: 64.84%, op_acc: 42.19%] [G loss: 1.178752]\n",
      "epoch:32 step:25223[D loss: 0.316615, acc: 79.69%, op_acc: 50.78%] [G loss: 1.271404]\n",
      "epoch:32 step:25224[D loss: 0.316612, acc: 80.47%, op_acc: 53.91%] [G loss: 0.866811]\n",
      "epoch:32 step:25225[D loss: 0.318703, acc: 82.03%, op_acc: 48.44%] [G loss: 1.472490]\n",
      "epoch:32 step:25226[D loss: 0.367630, acc: 69.53%, op_acc: 44.53%] [G loss: 0.620436]\n",
      "epoch:32 step:25227[D loss: 0.439544, acc: 56.25%, op_acc: 43.75%] [G loss: 1.294140]\n",
      "epoch:32 step:25228[D loss: 0.381387, acc: 68.75%, op_acc: 44.53%] [G loss: 1.133410]\n",
      "epoch:32 step:25229[D loss: 0.331743, acc: 73.44%, op_acc: 50.78%] [G loss: 0.898723]\n",
      "epoch:32 step:25230[D loss: 0.433024, acc: 62.50%, op_acc: 41.41%] [G loss: 1.086709]\n",
      "epoch:32 step:25231[D loss: 0.363963, acc: 69.53%, op_acc: 52.34%] [G loss: 1.298209]\n",
      "epoch:32 step:25232[D loss: 0.341864, acc: 78.12%, op_acc: 42.97%] [G loss: 1.076757]\n",
      "epoch:32 step:25233[D loss: 0.348997, acc: 71.09%, op_acc: 57.03%] [G loss: 1.243587]\n",
      "epoch:32 step:25234[D loss: 0.349368, acc: 71.09%, op_acc: 47.66%] [G loss: 1.016226]\n",
      "epoch:32 step:25235[D loss: 0.355127, acc: 68.75%, op_acc: 45.31%] [G loss: 1.200047]\n",
      "epoch:32 step:25236[D loss: 0.353984, acc: 73.44%, op_acc: 46.09%] [G loss: 0.872723]\n",
      "epoch:32 step:25237[D loss: 0.449777, acc: 56.25%, op_acc: 36.72%] [G loss: 1.339057]\n",
      "epoch:32 step:25238[D loss: 0.354918, acc: 74.22%, op_acc: 50.78%] [G loss: 1.162750]\n",
      "epoch:32 step:25239[D loss: 0.378939, acc: 67.19%, op_acc: 46.88%] [G loss: 0.952887]\n",
      "epoch:32 step:25240[D loss: 0.389602, acc: 70.31%, op_acc: 46.09%] [G loss: 0.982171]\n",
      "epoch:32 step:25241[D loss: 0.335704, acc: 78.91%, op_acc: 49.22%] [G loss: 1.039338]\n",
      "epoch:32 step:25242[D loss: 0.403312, acc: 67.19%, op_acc: 45.31%] [G loss: 1.040629]\n",
      "epoch:32 step:25243[D loss: 0.364223, acc: 71.88%, op_acc: 47.66%] [G loss: 0.940753]\n",
      "epoch:32 step:25244[D loss: 0.374182, acc: 70.31%, op_acc: 41.41%] [G loss: 1.074080]\n",
      "epoch:32 step:25245[D loss: 0.393821, acc: 67.19%, op_acc: 38.28%] [G loss: 1.163963]\n",
      "epoch:32 step:25246[D loss: 0.402505, acc: 70.31%, op_acc: 38.28%] [G loss: 0.737613]\n",
      "epoch:32 step:25247[D loss: 0.355630, acc: 76.56%, op_acc: 49.22%] [G loss: 1.295266]\n",
      "epoch:32 step:25248[D loss: 0.390588, acc: 67.19%, op_acc: 50.00%] [G loss: 0.831177]\n",
      "epoch:32 step:25249[D loss: 0.438402, acc: 60.94%, op_acc: 42.97%] [G loss: 1.096607]\n",
      "epoch:32 step:25250[D loss: 0.387810, acc: 67.19%, op_acc: 43.75%] [G loss: 0.879038]\n",
      "epoch:32 step:25251[D loss: 0.408430, acc: 63.28%, op_acc: 42.19%] [G loss: 1.146535]\n",
      "epoch:32 step:25252[D loss: 0.397972, acc: 67.19%, op_acc: 42.97%] [G loss: 1.174686]\n",
      "epoch:32 step:25253[D loss: 0.378181, acc: 66.41%, op_acc: 42.97%] [G loss: 1.061037]\n",
      "epoch:32 step:25254[D loss: 0.356948, acc: 71.88%, op_acc: 50.78%] [G loss: 0.841368]\n",
      "epoch:32 step:25255[D loss: 0.360765, acc: 74.22%, op_acc: 50.78%] [G loss: 1.050271]\n",
      "epoch:32 step:25256[D loss: 0.373656, acc: 71.09%, op_acc: 40.62%] [G loss: 0.811414]\n",
      "epoch:32 step:25257[D loss: 0.365396, acc: 67.19%, op_acc: 41.41%] [G loss: 0.886021]\n",
      "epoch:32 step:25258[D loss: 0.316065, acc: 78.91%, op_acc: 53.12%] [G loss: 0.887905]\n",
      "epoch:32 step:25259[D loss: 0.464457, acc: 54.69%, op_acc: 42.19%] [G loss: 0.956595]\n",
      "epoch:32 step:25260[D loss: 0.376373, acc: 69.53%, op_acc: 50.00%] [G loss: 0.852312]\n",
      "epoch:32 step:25261[D loss: 0.394533, acc: 58.59%, op_acc: 47.66%] [G loss: 1.144154]\n",
      "epoch:32 step:25262[D loss: 0.412461, acc: 65.62%, op_acc: 39.06%] [G loss: 0.822404]\n",
      "epoch:32 step:25263[D loss: 0.375070, acc: 70.31%, op_acc: 41.41%] [G loss: 1.021394]\n",
      "epoch:32 step:25264[D loss: 0.354116, acc: 75.00%, op_acc: 43.75%] [G loss: 0.986233]\n",
      "epoch:32 step:25265[D loss: 0.395748, acc: 68.75%, op_acc: 41.41%] [G loss: 0.838404]\n",
      "epoch:32 step:25266[D loss: 0.397419, acc: 65.62%, op_acc: 42.19%] [G loss: 1.007327]\n",
      "epoch:32 step:25267[D loss: 0.375072, acc: 67.19%, op_acc: 44.53%] [G loss: 1.067995]\n",
      "epoch:32 step:25268[D loss: 0.425462, acc: 60.16%, op_acc: 39.06%] [G loss: 1.160370]\n",
      "epoch:32 step:25269[D loss: 0.395606, acc: 67.97%, op_acc: 42.97%] [G loss: 1.019033]\n",
      "epoch:32 step:25270[D loss: 0.385413, acc: 67.19%, op_acc: 40.62%] [G loss: 1.178054]\n",
      "epoch:32 step:25271[D loss: 0.367634, acc: 67.19%, op_acc: 46.09%] [G loss: 0.991335]\n",
      "epoch:32 step:25272[D loss: 0.388311, acc: 64.84%, op_acc: 43.75%] [G loss: 0.815776]\n",
      "epoch:32 step:25273[D loss: 0.435369, acc: 64.06%, op_acc: 39.06%] [G loss: 1.018836]\n",
      "epoch:32 step:25274[D loss: 0.402389, acc: 67.97%, op_acc: 39.06%] [G loss: 0.924130]\n",
      "epoch:32 step:25275[D loss: 0.361245, acc: 67.19%, op_acc: 47.66%] [G loss: 1.122785]\n",
      "epoch:32 step:25276[D loss: 0.387633, acc: 71.09%, op_acc: 43.75%] [G loss: 1.120400]\n",
      "epoch:32 step:25277[D loss: 0.373177, acc: 73.44%, op_acc: 48.44%] [G loss: 0.862137]\n",
      "epoch:32 step:25278[D loss: 0.430610, acc: 61.72%, op_acc: 44.53%] [G loss: 0.801877]\n",
      "epoch:32 step:25279[D loss: 0.329926, acc: 78.12%, op_acc: 51.56%] [G loss: 0.892040]\n",
      "epoch:32 step:25280[D loss: 0.376725, acc: 69.53%, op_acc: 46.09%] [G loss: 0.917922]\n",
      "epoch:32 step:25281[D loss: 0.359746, acc: 75.00%, op_acc: 48.44%] [G loss: 1.133425]\n",
      "epoch:32 step:25282[D loss: 0.341393, acc: 79.69%, op_acc: 46.09%] [G loss: 0.832215]\n",
      "epoch:32 step:25283[D loss: 0.433754, acc: 57.81%, op_acc: 42.97%] [G loss: 1.435651]\n",
      "epoch:32 step:25284[D loss: 0.416480, acc: 64.06%, op_acc: 36.72%] [G loss: 0.923133]\n",
      "epoch:32 step:25285[D loss: 0.401133, acc: 65.62%, op_acc: 46.88%] [G loss: 1.550401]\n",
      "epoch:32 step:25286[D loss: 0.378460, acc: 71.88%, op_acc: 45.31%] [G loss: 1.117108]\n",
      "epoch:32 step:25287[D loss: 0.396758, acc: 60.16%, op_acc: 43.75%] [G loss: 0.919900]\n",
      "epoch:32 step:25288[D loss: 0.400266, acc: 67.97%, op_acc: 43.75%] [G loss: 1.192540]\n",
      "epoch:32 step:25289[D loss: 0.453595, acc: 56.25%, op_acc: 37.50%] [G loss: 1.001181]\n",
      "epoch:32 step:25290[D loss: 0.389790, acc: 67.97%, op_acc: 45.31%] [G loss: 1.240277]\n",
      "epoch:32 step:25291[D loss: 0.373115, acc: 71.88%, op_acc: 42.97%] [G loss: 0.911935]\n",
      "epoch:32 step:25292[D loss: 0.371293, acc: 68.75%, op_acc: 42.97%] [G loss: 1.010973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25293[D loss: 0.372716, acc: 66.41%, op_acc: 47.66%] [G loss: 0.860246]\n",
      "epoch:32 step:25294[D loss: 0.332326, acc: 72.66%, op_acc: 50.00%] [G loss: 1.011216]\n",
      "epoch:32 step:25295[D loss: 0.370981, acc: 69.53%, op_acc: 42.19%] [G loss: 1.041705]\n",
      "epoch:32 step:25296[D loss: 0.319258, acc: 77.34%, op_acc: 50.00%] [G loss: 1.011587]\n",
      "epoch:32 step:25297[D loss: 0.344335, acc: 72.66%, op_acc: 53.91%] [G loss: 1.043312]\n",
      "epoch:32 step:25298[D loss: 0.389034, acc: 74.22%, op_acc: 46.09%] [G loss: 1.082636]\n",
      "epoch:32 step:25299[D loss: 0.303738, acc: 82.03%, op_acc: 44.53%] [G loss: 1.410731]\n",
      "epoch:32 step:25300[D loss: 0.418520, acc: 62.50%, op_acc: 40.62%] [G loss: 0.797590]\n",
      "epoch:32 step:25301[D loss: 0.425418, acc: 62.50%, op_acc: 43.75%] [G loss: 1.195035]\n",
      "epoch:32 step:25302[D loss: 0.359147, acc: 74.22%, op_acc: 39.84%] [G loss: 1.088576]\n",
      "epoch:32 step:25303[D loss: 0.399229, acc: 63.28%, op_acc: 42.97%] [G loss: 1.094308]\n",
      "epoch:32 step:25304[D loss: 0.387148, acc: 64.06%, op_acc: 42.19%] [G loss: 1.187734]\n",
      "epoch:32 step:25305[D loss: 0.334575, acc: 80.47%, op_acc: 43.75%] [G loss: 1.382821]\n",
      "epoch:32 step:25306[D loss: 0.413124, acc: 65.62%, op_acc: 38.28%] [G loss: 1.304238]\n",
      "epoch:32 step:25307[D loss: 0.376607, acc: 70.31%, op_acc: 49.22%] [G loss: 1.460078]\n",
      "epoch:32 step:25308[D loss: 0.358438, acc: 71.09%, op_acc: 43.75%] [G loss: 1.360578]\n",
      "epoch:32 step:25309[D loss: 0.375252, acc: 69.53%, op_acc: 50.00%] [G loss: 1.082957]\n",
      "epoch:32 step:25310[D loss: 0.414940, acc: 67.19%, op_acc: 41.41%] [G loss: 1.246011]\n",
      "epoch:32 step:25311[D loss: 0.326212, acc: 81.25%, op_acc: 47.66%] [G loss: 1.260242]\n",
      "epoch:32 step:25312[D loss: 0.334321, acc: 77.34%, op_acc: 43.75%] [G loss: 1.367637]\n",
      "epoch:32 step:25313[D loss: 0.300119, acc: 87.50%, op_acc: 53.12%] [G loss: 0.907364]\n",
      "epoch:32 step:25314[D loss: 0.415848, acc: 62.50%, op_acc: 44.53%] [G loss: 1.214926]\n",
      "epoch:32 step:25315[D loss: 0.330879, acc: 74.22%, op_acc: 50.00%] [G loss: 1.364163]\n",
      "epoch:32 step:25316[D loss: 0.306865, acc: 84.38%, op_acc: 42.19%] [G loss: 1.294750]\n",
      "epoch:32 step:25317[D loss: 0.341292, acc: 76.56%, op_acc: 49.22%] [G loss: 1.321821]\n",
      "epoch:32 step:25318[D loss: 0.338653, acc: 78.91%, op_acc: 48.44%] [G loss: 1.217402]\n",
      "epoch:32 step:25319[D loss: 0.373637, acc: 71.09%, op_acc: 50.78%] [G loss: 1.378043]\n",
      "epoch:32 step:25320[D loss: 0.310807, acc: 82.03%, op_acc: 55.47%] [G loss: 1.273517]\n",
      "epoch:32 step:25321[D loss: 0.321221, acc: 78.12%, op_acc: 49.22%] [G loss: 1.550595]\n",
      "epoch:32 step:25322[D loss: 0.334205, acc: 73.44%, op_acc: 54.69%] [G loss: 1.477395]\n",
      "epoch:32 step:25323[D loss: 0.279156, acc: 89.06%, op_acc: 51.56%] [G loss: 1.650360]\n",
      "epoch:32 step:25324[D loss: 0.290330, acc: 85.94%, op_acc: 55.47%] [G loss: 1.619435]\n",
      "epoch:32 step:25325[D loss: 0.282154, acc: 85.94%, op_acc: 56.25%] [G loss: 0.637120]\n",
      "epoch:32 step:25326[D loss: 0.403884, acc: 67.97%, op_acc: 42.97%] [G loss: 0.396047]\n",
      "epoch:32 step:25327[D loss: 0.479209, acc: 57.81%, op_acc: 32.81%] [G loss: 1.493899]\n",
      "epoch:32 step:25328[D loss: 0.496758, acc: 49.22%, op_acc: 35.94%] [G loss: 0.753037]\n",
      "epoch:32 step:25329[D loss: 0.468724, acc: 48.44%, op_acc: 39.06%] [G loss: 1.821062]\n",
      "epoch:32 step:25330[D loss: 0.437811, acc: 60.16%, op_acc: 49.22%] [G loss: 0.942362]\n",
      "epoch:32 step:25331[D loss: 0.467643, acc: 57.81%, op_acc: 41.41%] [G loss: 1.728114]\n",
      "epoch:32 step:25332[D loss: 0.476443, acc: 51.56%, op_acc: 33.59%] [G loss: 0.890049]\n",
      "epoch:32 step:25333[D loss: 0.433893, acc: 57.03%, op_acc: 42.97%] [G loss: 1.631374]\n",
      "epoch:32 step:25334[D loss: 0.439149, acc: 54.69%, op_acc: 37.50%] [G loss: 1.532410]\n",
      "epoch:32 step:25335[D loss: 0.415262, acc: 64.06%, op_acc: 39.06%] [G loss: 1.138625]\n",
      "epoch:32 step:25336[D loss: 0.426310, acc: 59.38%, op_acc: 39.06%] [G loss: 1.170128]\n",
      "epoch:32 step:25337[D loss: 0.440303, acc: 56.25%, op_acc: 42.97%] [G loss: 1.053558]\n",
      "epoch:32 step:25338[D loss: 0.464949, acc: 55.47%, op_acc: 41.41%] [G loss: 1.162234]\n",
      "epoch:32 step:25339[D loss: 0.405632, acc: 65.62%, op_acc: 46.09%] [G loss: 1.250717]\n",
      "epoch:32 step:25340[D loss: 0.418919, acc: 68.75%, op_acc: 36.72%] [G loss: 0.959904]\n",
      "epoch:32 step:25341[D loss: 0.385739, acc: 64.84%, op_acc: 46.88%] [G loss: 1.167163]\n",
      "epoch:32 step:25342[D loss: 0.376121, acc: 71.88%, op_acc: 42.97%] [G loss: 1.114924]\n",
      "epoch:32 step:25343[D loss: 0.416800, acc: 59.38%, op_acc: 45.31%] [G loss: 0.844985]\n",
      "epoch:32 step:25344[D loss: 0.385423, acc: 64.84%, op_acc: 40.62%] [G loss: 1.129802]\n",
      "epoch:32 step:25345[D loss: 0.366222, acc: 71.88%, op_acc: 48.44%] [G loss: 0.860724]\n",
      "epoch:32 step:25346[D loss: 0.426130, acc: 56.25%, op_acc: 39.84%] [G loss: 1.141302]\n",
      "epoch:32 step:25347[D loss: 0.408661, acc: 62.50%, op_acc: 49.22%] [G loss: 0.934871]\n",
      "epoch:32 step:25348[D loss: 0.411437, acc: 64.06%, op_acc: 40.62%] [G loss: 0.972641]\n",
      "epoch:32 step:25349[D loss: 0.405782, acc: 64.06%, op_acc: 41.41%] [G loss: 0.941576]\n",
      "epoch:32 step:25350[D loss: 0.373180, acc: 71.88%, op_acc: 45.31%] [G loss: 1.080747]\n",
      "epoch:32 step:25351[D loss: 0.422945, acc: 60.16%, op_acc: 37.50%] [G loss: 1.131851]\n",
      "epoch:32 step:25352[D loss: 0.409568, acc: 65.62%, op_acc: 37.50%] [G loss: 0.844687]\n",
      "epoch:32 step:25353[D loss: 0.375062, acc: 69.53%, op_acc: 47.66%] [G loss: 1.145240]\n",
      "epoch:32 step:25354[D loss: 0.384822, acc: 66.41%, op_acc: 42.97%] [G loss: 1.090195]\n",
      "epoch:32 step:25355[D loss: 0.432086, acc: 60.16%, op_acc: 39.84%] [G loss: 1.090402]\n",
      "epoch:32 step:25356[D loss: 0.381345, acc: 67.19%, op_acc: 39.06%] [G loss: 1.029727]\n",
      "epoch:32 step:25357[D loss: 0.337503, acc: 75.78%, op_acc: 49.22%] [G loss: 1.196183]\n",
      "epoch:32 step:25358[D loss: 0.434099, acc: 55.47%, op_acc: 44.53%] [G loss: 1.137381]\n",
      "epoch:32 step:25359[D loss: 0.378896, acc: 72.66%, op_acc: 36.72%] [G loss: 1.055605]\n",
      "epoch:32 step:25360[D loss: 0.375883, acc: 68.75%, op_acc: 42.19%] [G loss: 1.261613]\n",
      "epoch:32 step:25361[D loss: 0.382840, acc: 66.41%, op_acc: 43.75%] [G loss: 0.866854]\n",
      "epoch:32 step:25362[D loss: 0.369081, acc: 67.19%, op_acc: 42.97%] [G loss: 1.220927]\n",
      "epoch:32 step:25363[D loss: 0.343355, acc: 75.00%, op_acc: 54.69%] [G loss: 1.196427]\n",
      "epoch:32 step:25364[D loss: 0.385704, acc: 70.31%, op_acc: 43.75%] [G loss: 1.401639]\n",
      "epoch:32 step:25365[D loss: 0.377300, acc: 69.53%, op_acc: 51.56%] [G loss: 1.147165]\n",
      "epoch:32 step:25366[D loss: 0.389257, acc: 60.94%, op_acc: 42.97%] [G loss: 0.783885]\n",
      "epoch:32 step:25367[D loss: 0.408536, acc: 60.16%, op_acc: 46.88%] [G loss: 0.674810]\n",
      "epoch:32 step:25368[D loss: 0.352632, acc: 76.56%, op_acc: 42.97%] [G loss: 0.728406]\n",
      "epoch:32 step:25369[D loss: 0.389110, acc: 67.19%, op_acc: 46.88%] [G loss: 1.066590]\n",
      "epoch:32 step:25370[D loss: 0.365142, acc: 74.22%, op_acc: 41.41%] [G loss: 0.921728]\n",
      "epoch:32 step:25371[D loss: 0.335192, acc: 71.09%, op_acc: 47.66%] [G loss: 0.753942]\n",
      "epoch:32 step:25372[D loss: 0.337870, acc: 77.34%, op_acc: 51.56%] [G loss: 0.762321]\n",
      "epoch:32 step:25373[D loss: 0.309363, acc: 83.59%, op_acc: 50.78%] [G loss: 0.785808]\n",
      "epoch:32 step:25374[D loss: 0.437022, acc: 59.38%, op_acc: 40.62%] [G loss: 0.879413]\n",
      "epoch:32 step:25375[D loss: 0.387558, acc: 64.06%, op_acc: 48.44%] [G loss: 1.112129]\n",
      "epoch:32 step:25376[D loss: 0.359549, acc: 67.97%, op_acc: 46.09%] [G loss: 1.204213]\n",
      "epoch:32 step:25377[D loss: 0.357520, acc: 71.09%, op_acc: 50.78%] [G loss: 1.305587]\n",
      "epoch:32 step:25378[D loss: 0.332008, acc: 75.78%, op_acc: 55.47%] [G loss: 0.999928]\n",
      "epoch:32 step:25379[D loss: 0.382688, acc: 69.53%, op_acc: 51.56%] [G loss: 1.228081]\n",
      "epoch:32 step:25380[D loss: 0.394383, acc: 67.19%, op_acc: 40.62%] [G loss: 0.912515]\n",
      "epoch:32 step:25381[D loss: 0.453925, acc: 50.78%, op_acc: 39.84%] [G loss: 1.105128]\n",
      "epoch:32 step:25382[D loss: 0.398499, acc: 65.62%, op_acc: 37.50%] [G loss: 0.688465]\n",
      "epoch:32 step:25383[D loss: 0.404112, acc: 60.16%, op_acc: 50.00%] [G loss: 1.194670]\n",
      "epoch:32 step:25384[D loss: 0.411080, acc: 66.41%, op_acc: 43.75%] [G loss: 1.228190]\n",
      "epoch:32 step:25385[D loss: 0.373478, acc: 73.44%, op_acc: 42.19%] [G loss: 1.084766]\n",
      "epoch:32 step:25386[D loss: 0.408152, acc: 68.75%, op_acc: 41.41%] [G loss: 0.855140]\n",
      "epoch:32 step:25387[D loss: 0.417655, acc: 68.75%, op_acc: 40.62%] [G loss: 1.242460]\n",
      "epoch:32 step:25388[D loss: 0.399293, acc: 64.06%, op_acc: 48.44%] [G loss: 0.776354]\n",
      "epoch:32 step:25389[D loss: 0.375120, acc: 68.75%, op_acc: 50.78%] [G loss: 0.753639]\n",
      "epoch:32 step:25390[D loss: 0.409093, acc: 65.62%, op_acc: 39.84%] [G loss: 0.769907]\n",
      "epoch:32 step:25391[D loss: 0.397434, acc: 64.84%, op_acc: 42.19%] [G loss: 1.331671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25392[D loss: 0.408154, acc: 61.72%, op_acc: 51.56%] [G loss: 1.108196]\n",
      "epoch:32 step:25393[D loss: 0.346395, acc: 71.09%, op_acc: 47.66%] [G loss: 1.147239]\n",
      "epoch:32 step:25394[D loss: 0.374690, acc: 73.44%, op_acc: 39.06%] [G loss: 0.742446]\n",
      "epoch:32 step:25395[D loss: 0.373340, acc: 68.75%, op_acc: 37.50%] [G loss: 1.132283]\n",
      "epoch:32 step:25396[D loss: 0.426913, acc: 59.38%, op_acc: 46.88%] [G loss: 0.849269]\n",
      "epoch:32 step:25397[D loss: 0.441399, acc: 57.81%, op_acc: 44.53%] [G loss: 1.162649]\n",
      "epoch:32 step:25398[D loss: 0.446599, acc: 61.72%, op_acc: 39.84%] [G loss: 1.018641]\n",
      "epoch:32 step:25399[D loss: 0.321742, acc: 77.34%, op_acc: 43.75%] [G loss: 1.262131]\n",
      "epoch:32 step:25400[D loss: 0.371205, acc: 67.97%, op_acc: 50.78%] [G loss: 0.969390]\n",
      "epoch:32 step:25401[D loss: 0.432364, acc: 63.28%, op_acc: 46.88%] [G loss: 0.948380]\n",
      "epoch:32 step:25402[D loss: 0.402442, acc: 63.28%, op_acc: 48.44%] [G loss: 1.024965]\n",
      "epoch:32 step:25403[D loss: 0.506643, acc: 50.00%, op_acc: 39.84%] [G loss: 0.803834]\n",
      "epoch:32 step:25404[D loss: 0.387494, acc: 68.75%, op_acc: 47.66%] [G loss: 0.983322]\n",
      "epoch:32 step:25405[D loss: 0.401442, acc: 65.62%, op_acc: 42.19%] [G loss: 0.703936]\n",
      "epoch:32 step:25406[D loss: 0.454743, acc: 57.03%, op_acc: 45.31%] [G loss: 1.171950]\n",
      "epoch:32 step:25407[D loss: 0.439749, acc: 56.25%, op_acc: 41.41%] [G loss: 0.954859]\n",
      "epoch:32 step:25408[D loss: 0.439572, acc: 60.94%, op_acc: 39.84%] [G loss: 1.014299]\n",
      "epoch:32 step:25409[D loss: 0.444162, acc: 60.94%, op_acc: 43.75%] [G loss: 1.097306]\n",
      "epoch:32 step:25410[D loss: 0.369554, acc: 69.53%, op_acc: 44.53%] [G loss: 0.814938]\n",
      "epoch:32 step:25411[D loss: 0.378118, acc: 67.97%, op_acc: 45.31%] [G loss: 1.122264]\n",
      "epoch:32 step:25412[D loss: 0.413275, acc: 61.72%, op_acc: 49.22%] [G loss: 1.034781]\n",
      "epoch:32 step:25413[D loss: 0.476568, acc: 57.81%, op_acc: 37.50%] [G loss: 0.998921]\n",
      "epoch:32 step:25414[D loss: 0.393083, acc: 63.28%, op_acc: 49.22%] [G loss: 1.054885]\n",
      "epoch:32 step:25415[D loss: 0.470473, acc: 60.16%, op_acc: 40.62%] [G loss: 0.996374]\n",
      "epoch:32 step:25416[D loss: 0.397841, acc: 67.97%, op_acc: 42.19%] [G loss: 1.154315]\n",
      "epoch:32 step:25417[D loss: 0.386396, acc: 67.19%, op_acc: 45.31%] [G loss: 1.079648]\n",
      "epoch:32 step:25418[D loss: 0.429000, acc: 62.50%, op_acc: 41.41%] [G loss: 1.205126]\n",
      "epoch:32 step:25419[D loss: 0.383164, acc: 67.97%, op_acc: 42.97%] [G loss: 1.222350]\n",
      "epoch:32 step:25420[D loss: 0.427420, acc: 56.25%, op_acc: 42.97%] [G loss: 0.932715]\n",
      "epoch:32 step:25421[D loss: 0.392382, acc: 62.50%, op_acc: 39.06%] [G loss: 1.131504]\n",
      "epoch:32 step:25422[D loss: 0.372650, acc: 66.41%, op_acc: 45.31%] [G loss: 0.956267]\n",
      "epoch:32 step:25423[D loss: 0.423659, acc: 63.28%, op_acc: 43.75%] [G loss: 0.946316]\n",
      "epoch:32 step:25424[D loss: 0.392478, acc: 60.94%, op_acc: 46.09%] [G loss: 1.224967]\n",
      "epoch:32 step:25425[D loss: 0.369812, acc: 71.09%, op_acc: 42.19%] [G loss: 0.849042]\n",
      "epoch:32 step:25426[D loss: 0.376035, acc: 64.84%, op_acc: 48.44%] [G loss: 1.071315]\n",
      "epoch:32 step:25427[D loss: 0.418004, acc: 60.16%, op_acc: 48.44%] [G loss: 1.032640]\n",
      "epoch:32 step:25428[D loss: 0.476702, acc: 57.03%, op_acc: 36.72%] [G loss: 1.083830]\n",
      "epoch:32 step:25429[D loss: 0.432249, acc: 57.81%, op_acc: 40.62%] [G loss: 0.945063]\n",
      "epoch:32 step:25430[D loss: 0.398585, acc: 68.75%, op_acc: 42.97%] [G loss: 1.108941]\n",
      "epoch:32 step:25431[D loss: 0.440492, acc: 47.66%, op_acc: 46.88%] [G loss: 1.040235]\n",
      "epoch:32 step:25432[D loss: 0.460073, acc: 52.34%, op_acc: 41.41%] [G loss: 1.105971]\n",
      "epoch:32 step:25433[D loss: 0.356125, acc: 71.88%, op_acc: 40.62%] [G loss: 1.158433]\n",
      "epoch:32 step:25434[D loss: 0.385032, acc: 68.75%, op_acc: 44.53%] [G loss: 0.865919]\n",
      "epoch:32 step:25435[D loss: 0.421772, acc: 59.38%, op_acc: 39.84%] [G loss: 0.764545]\n",
      "epoch:32 step:25436[D loss: 0.377983, acc: 64.84%, op_acc: 43.75%] [G loss: 0.740570]\n",
      "epoch:32 step:25437[D loss: 0.426937, acc: 66.41%, op_acc: 38.28%] [G loss: 0.719741]\n",
      "epoch:32 step:25438[D loss: 0.387578, acc: 69.53%, op_acc: 46.88%] [G loss: 0.710779]\n",
      "epoch:32 step:25439[D loss: 0.485430, acc: 52.34%, op_acc: 35.16%] [G loss: 1.045247]\n",
      "epoch:32 step:25440[D loss: 0.368373, acc: 70.31%, op_acc: 48.44%] [G loss: 0.825665]\n",
      "epoch:32 step:25441[D loss: 0.321924, acc: 79.69%, op_acc: 43.75%] [G loss: 0.987823]\n",
      "epoch:32 step:25442[D loss: 0.389235, acc: 63.28%, op_acc: 43.75%] [G loss: 1.133251]\n",
      "epoch:32 step:25443[D loss: 0.386494, acc: 64.84%, op_acc: 47.66%] [G loss: 0.935840]\n",
      "epoch:32 step:25444[D loss: 0.347426, acc: 70.31%, op_acc: 49.22%] [G loss: 1.178966]\n",
      "epoch:32 step:25445[D loss: 0.377263, acc: 69.53%, op_acc: 46.88%] [G loss: 1.077269]\n",
      "epoch:32 step:25446[D loss: 0.432203, acc: 60.94%, op_acc: 35.16%] [G loss: 1.036968]\n",
      "epoch:32 step:25447[D loss: 0.422378, acc: 58.59%, op_acc: 44.53%] [G loss: 1.124318]\n",
      "epoch:32 step:25448[D loss: 0.365369, acc: 70.31%, op_acc: 41.41%] [G loss: 1.246964]\n",
      "epoch:32 step:25449[D loss: 0.375982, acc: 70.31%, op_acc: 50.00%] [G loss: 1.046753]\n",
      "epoch:32 step:25450[D loss: 0.362088, acc: 72.66%, op_acc: 49.22%] [G loss: 1.178763]\n",
      "epoch:32 step:25451[D loss: 0.330807, acc: 72.66%, op_acc: 53.91%] [G loss: 1.229462]\n",
      "epoch:32 step:25452[D loss: 0.321295, acc: 78.91%, op_acc: 47.66%] [G loss: 0.732922]\n",
      "epoch:32 step:25453[D loss: 0.375181, acc: 67.19%, op_acc: 46.88%] [G loss: 0.917127]\n",
      "epoch:32 step:25454[D loss: 0.356134, acc: 70.31%, op_acc: 46.88%] [G loss: 1.196327]\n",
      "epoch:32 step:25455[D loss: 0.362224, acc: 72.66%, op_acc: 43.75%] [G loss: 1.369133]\n",
      "epoch:32 step:25456[D loss: 0.428076, acc: 63.28%, op_acc: 41.41%] [G loss: 1.029446]\n",
      "epoch:32 step:25457[D loss: 0.353487, acc: 75.00%, op_acc: 42.19%] [G loss: 1.338905]\n",
      "epoch:32 step:25458[D loss: 0.370927, acc: 65.62%, op_acc: 40.62%] [G loss: 0.969614]\n",
      "epoch:32 step:25459[D loss: 0.398854, acc: 67.97%, op_acc: 40.62%] [G loss: 1.396061]\n",
      "epoch:32 step:25460[D loss: 0.393920, acc: 64.84%, op_acc: 42.19%] [G loss: 1.355847]\n",
      "epoch:32 step:25461[D loss: 0.381004, acc: 67.19%, op_acc: 42.19%] [G loss: 1.554447]\n",
      "epoch:32 step:25462[D loss: 0.311906, acc: 76.56%, op_acc: 50.78%] [G loss: 1.264250]\n",
      "epoch:32 step:25463[D loss: 0.384213, acc: 72.66%, op_acc: 45.31%] [G loss: 1.213532]\n",
      "epoch:32 step:25464[D loss: 0.335332, acc: 78.91%, op_acc: 46.88%] [G loss: 0.922695]\n",
      "epoch:32 step:25465[D loss: 0.318207, acc: 73.44%, op_acc: 50.00%] [G loss: 1.183550]\n",
      "epoch:32 step:25466[D loss: 0.391377, acc: 62.50%, op_acc: 40.62%] [G loss: 1.219548]\n",
      "epoch:32 step:25467[D loss: 0.375309, acc: 66.41%, op_acc: 45.31%] [G loss: 1.060682]\n",
      "epoch:32 step:25468[D loss: 0.374201, acc: 74.22%, op_acc: 37.50%] [G loss: 1.072323]\n",
      "epoch:32 step:25469[D loss: 0.402170, acc: 64.84%, op_acc: 47.66%] [G loss: 1.069053]\n",
      "epoch:32 step:25470[D loss: 0.380443, acc: 67.97%, op_acc: 47.66%] [G loss: 1.216563]\n",
      "epoch:32 step:25471[D loss: 0.391920, acc: 66.41%, op_acc: 40.62%] [G loss: 1.048014]\n",
      "epoch:32 step:25472[D loss: 0.469758, acc: 54.69%, op_acc: 31.25%] [G loss: 0.987572]\n",
      "epoch:32 step:25473[D loss: 0.411321, acc: 68.75%, op_acc: 39.06%] [G loss: 0.921336]\n",
      "epoch:32 step:25474[D loss: 0.390676, acc: 71.09%, op_acc: 42.19%] [G loss: 1.251349]\n",
      "epoch:32 step:25475[D loss: 0.363823, acc: 74.22%, op_acc: 47.66%] [G loss: 1.393507]\n",
      "epoch:32 step:25476[D loss: 0.363316, acc: 69.53%, op_acc: 47.66%] [G loss: 1.146736]\n",
      "epoch:32 step:25477[D loss: 0.395802, acc: 68.75%, op_acc: 41.41%] [G loss: 1.261760]\n",
      "epoch:32 step:25478[D loss: 0.374394, acc: 67.19%, op_acc: 50.78%] [G loss: 0.910947]\n",
      "epoch:32 step:25479[D loss: 0.366894, acc: 74.22%, op_acc: 53.12%] [G loss: 0.835238]\n",
      "epoch:32 step:25480[D loss: 0.495339, acc: 53.12%, op_acc: 33.59%] [G loss: 0.929654]\n",
      "epoch:32 step:25481[D loss: 0.421316, acc: 62.50%, op_acc: 48.44%] [G loss: 0.815974]\n",
      "epoch:32 step:25482[D loss: 0.343557, acc: 68.75%, op_acc: 41.41%] [G loss: 1.062718]\n",
      "epoch:32 step:25483[D loss: 0.466143, acc: 54.69%, op_acc: 42.19%] [G loss: 0.976582]\n",
      "epoch:32 step:25484[D loss: 0.379873, acc: 68.75%, op_acc: 43.75%] [G loss: 0.997329]\n",
      "epoch:32 step:25485[D loss: 0.380004, acc: 64.84%, op_acc: 47.66%] [G loss: 1.006072]\n",
      "epoch:32 step:25486[D loss: 0.384504, acc: 62.50%, op_acc: 41.41%] [G loss: 1.070183]\n",
      "epoch:32 step:25487[D loss: 0.333414, acc: 76.56%, op_acc: 47.66%] [G loss: 0.825003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25488[D loss: 0.324874, acc: 80.47%, op_acc: 46.88%] [G loss: 0.866937]\n",
      "epoch:32 step:25489[D loss: 0.339341, acc: 74.22%, op_acc: 49.22%] [G loss: 0.945085]\n",
      "epoch:32 step:25490[D loss: 0.417330, acc: 62.50%, op_acc: 45.31%] [G loss: 0.839468]\n",
      "epoch:32 step:25491[D loss: 0.407323, acc: 65.62%, op_acc: 42.19%] [G loss: 0.778216]\n",
      "epoch:32 step:25492[D loss: 0.396808, acc: 69.53%, op_acc: 44.53%] [G loss: 1.086073]\n",
      "epoch:32 step:25493[D loss: 0.348294, acc: 74.22%, op_acc: 42.19%] [G loss: 0.813205]\n",
      "epoch:32 step:25494[D loss: 0.349465, acc: 76.56%, op_acc: 48.44%] [G loss: 1.087197]\n",
      "epoch:32 step:25495[D loss: 0.322214, acc: 75.00%, op_acc: 49.22%] [G loss: 0.960312]\n",
      "epoch:32 step:25496[D loss: 0.442512, acc: 57.03%, op_acc: 43.75%] [G loss: 1.145986]\n",
      "epoch:32 step:25497[D loss: 0.337326, acc: 77.34%, op_acc: 47.66%] [G loss: 0.683730]\n",
      "epoch:32 step:25498[D loss: 0.412620, acc: 64.84%, op_acc: 42.97%] [G loss: 0.868679]\n",
      "epoch:32 step:25499[D loss: 0.325057, acc: 78.12%, op_acc: 46.88%] [G loss: 0.950191]\n",
      "epoch:32 step:25500[D loss: 0.413172, acc: 62.50%, op_acc: 46.88%] [G loss: 1.177364]\n",
      "epoch:32 step:25501[D loss: 0.408635, acc: 66.41%, op_acc: 44.53%] [G loss: 0.928132]\n",
      "epoch:32 step:25502[D loss: 0.352818, acc: 74.22%, op_acc: 46.09%] [G loss: 0.946112]\n",
      "epoch:32 step:25503[D loss: 0.396465, acc: 63.28%, op_acc: 45.31%] [G loss: 0.848532]\n",
      "epoch:32 step:25504[D loss: 0.454923, acc: 53.12%, op_acc: 36.72%] [G loss: 1.177340]\n",
      "epoch:32 step:25505[D loss: 0.381938, acc: 65.62%, op_acc: 42.19%] [G loss: 0.774866]\n",
      "epoch:32 step:25506[D loss: 0.432330, acc: 58.59%, op_acc: 42.97%] [G loss: 1.107851]\n",
      "epoch:32 step:25507[D loss: 0.399489, acc: 66.41%, op_acc: 39.06%] [G loss: 1.023279]\n",
      "epoch:32 step:25508[D loss: 0.361993, acc: 71.09%, op_acc: 39.06%] [G loss: 1.055995]\n",
      "epoch:32 step:25509[D loss: 0.405389, acc: 64.84%, op_acc: 44.53%] [G loss: 1.111317]\n",
      "epoch:32 step:25510[D loss: 0.347443, acc: 75.78%, op_acc: 43.75%] [G loss: 1.141373]\n",
      "epoch:32 step:25511[D loss: 0.311095, acc: 85.16%, op_acc: 43.75%] [G loss: 1.043039]\n",
      "epoch:32 step:25512[D loss: 0.335608, acc: 74.22%, op_acc: 48.44%] [G loss: 1.288531]\n",
      "epoch:32 step:25513[D loss: 0.364500, acc: 76.56%, op_acc: 42.97%] [G loss: 1.077854]\n",
      "epoch:32 step:25514[D loss: 0.450244, acc: 65.62%, op_acc: 43.75%] [G loss: 1.210239]\n",
      "epoch:32 step:25515[D loss: 0.330291, acc: 80.47%, op_acc: 45.31%] [G loss: 1.069761]\n",
      "epoch:32 step:25516[D loss: 0.326772, acc: 79.69%, op_acc: 44.53%] [G loss: 1.083200]\n",
      "epoch:32 step:25517[D loss: 0.315476, acc: 81.25%, op_acc: 49.22%] [G loss: 1.140642]\n",
      "epoch:32 step:25518[D loss: 0.390211, acc: 71.09%, op_acc: 38.28%] [G loss: 1.016170]\n",
      "epoch:32 step:25519[D loss: 0.347062, acc: 75.78%, op_acc: 46.88%] [G loss: 0.860985]\n",
      "epoch:32 step:25520[D loss: 0.441084, acc: 53.91%, op_acc: 39.06%] [G loss: 1.226589]\n",
      "epoch:32 step:25521[D loss: 0.343309, acc: 71.09%, op_acc: 49.22%] [G loss: 1.302961]\n",
      "epoch:32 step:25522[D loss: 0.358064, acc: 71.09%, op_acc: 44.53%] [G loss: 1.207591]\n",
      "epoch:32 step:25523[D loss: 0.363705, acc: 73.44%, op_acc: 49.22%] [G loss: 1.125136]\n",
      "epoch:32 step:25524[D loss: 0.339114, acc: 78.91%, op_acc: 51.56%] [G loss: 1.145178]\n",
      "epoch:32 step:25525[D loss: 0.306237, acc: 81.25%, op_acc: 53.12%] [G loss: 1.254462]\n",
      "epoch:32 step:25526[D loss: 0.302065, acc: 82.03%, op_acc: 50.00%] [G loss: 1.146210]\n",
      "epoch:32 step:25527[D loss: 0.364660, acc: 73.44%, op_acc: 41.41%] [G loss: 1.148073]\n",
      "epoch:32 step:25528[D loss: 0.373571, acc: 66.41%, op_acc: 43.75%] [G loss: 1.186922]\n",
      "epoch:32 step:25529[D loss: 0.383416, acc: 68.75%, op_acc: 44.53%] [G loss: 0.866904]\n",
      "epoch:32 step:25530[D loss: 0.355760, acc: 72.66%, op_acc: 48.44%] [G loss: 1.213972]\n",
      "epoch:32 step:25531[D loss: 0.364578, acc: 71.09%, op_acc: 45.31%] [G loss: 1.555609]\n",
      "epoch:32 step:25532[D loss: 0.359317, acc: 68.75%, op_acc: 45.31%] [G loss: 1.551396]\n",
      "epoch:32 step:25533[D loss: 0.280146, acc: 80.47%, op_acc: 57.81%] [G loss: 0.680317]\n",
      "epoch:32 step:25534[D loss: 0.436162, acc: 64.84%, op_acc: 35.94%] [G loss: 1.327699]\n",
      "epoch:32 step:25535[D loss: 0.440798, acc: 56.25%, op_acc: 37.50%] [G loss: 0.760925]\n",
      "epoch:32 step:25536[D loss: 0.420998, acc: 56.25%, op_acc: 42.97%] [G loss: 0.921583]\n",
      "epoch:32 step:25537[D loss: 0.331290, acc: 77.34%, op_acc: 44.53%] [G loss: 1.473949]\n",
      "epoch:32 step:25538[D loss: 0.459611, acc: 53.12%, op_acc: 39.84%] [G loss: 1.341831]\n",
      "epoch:32 step:25539[D loss: 0.415776, acc: 60.16%, op_acc: 42.97%] [G loss: 1.460060]\n",
      "epoch:32 step:25540[D loss: 0.430049, acc: 65.62%, op_acc: 36.72%] [G loss: 1.183541]\n",
      "epoch:32 step:25541[D loss: 0.390740, acc: 67.19%, op_acc: 42.19%] [G loss: 1.064938]\n",
      "epoch:32 step:25542[D loss: 0.425292, acc: 64.84%, op_acc: 40.62%] [G loss: 1.225921]\n",
      "epoch:32 step:25543[D loss: 0.414198, acc: 57.81%, op_acc: 50.00%] [G loss: 1.105921]\n",
      "epoch:32 step:25544[D loss: 0.430099, acc: 57.81%, op_acc: 39.84%] [G loss: 1.424526]\n",
      "epoch:32 step:25545[D loss: 0.361481, acc: 68.75%, op_acc: 46.88%] [G loss: 1.169767]\n",
      "epoch:32 step:25546[D loss: 0.392789, acc: 71.09%, op_acc: 39.84%] [G loss: 1.002667]\n",
      "epoch:32 step:25547[D loss: 0.375846, acc: 66.41%, op_acc: 42.97%] [G loss: 1.192333]\n",
      "epoch:32 step:25548[D loss: 0.419255, acc: 62.50%, op_acc: 39.06%] [G loss: 0.981095]\n",
      "epoch:32 step:25549[D loss: 0.384017, acc: 67.19%, op_acc: 39.06%] [G loss: 1.125086]\n",
      "epoch:32 step:25550[D loss: 0.440030, acc: 61.72%, op_acc: 45.31%] [G loss: 0.883931]\n",
      "epoch:32 step:25551[D loss: 0.428029, acc: 60.94%, op_acc: 45.31%] [G loss: 1.108049]\n",
      "epoch:32 step:25552[D loss: 0.388821, acc: 69.53%, op_acc: 43.75%] [G loss: 1.280686]\n",
      "epoch:32 step:25553[D loss: 0.354167, acc: 68.75%, op_acc: 50.00%] [G loss: 1.211124]\n",
      "epoch:32 step:25554[D loss: 0.442179, acc: 59.38%, op_acc: 42.19%] [G loss: 1.236049]\n",
      "epoch:32 step:25555[D loss: 0.363552, acc: 67.97%, op_acc: 45.31%] [G loss: 1.227286]\n",
      "epoch:32 step:25556[D loss: 0.425617, acc: 60.16%, op_acc: 41.41%] [G loss: 1.231466]\n",
      "epoch:32 step:25557[D loss: 0.409663, acc: 67.97%, op_acc: 50.78%] [G loss: 0.792059]\n",
      "epoch:32 step:25558[D loss: 0.402206, acc: 66.41%, op_acc: 46.88%] [G loss: 1.141116]\n",
      "epoch:32 step:25559[D loss: 0.356347, acc: 69.53%, op_acc: 46.88%] [G loss: 0.737956]\n",
      "epoch:32 step:25560[D loss: 0.385741, acc: 71.88%, op_acc: 43.75%] [G loss: 0.901216]\n",
      "epoch:32 step:25561[D loss: 0.321921, acc: 75.78%, op_acc: 51.56%] [G loss: 1.311964]\n",
      "epoch:32 step:25562[D loss: 0.391988, acc: 64.84%, op_acc: 46.88%] [G loss: 1.154151]\n",
      "epoch:32 step:25563[D loss: 0.409259, acc: 61.72%, op_acc: 41.41%] [G loss: 1.185961]\n",
      "epoch:32 step:25564[D loss: 0.359507, acc: 75.00%, op_acc: 45.31%] [G loss: 1.046630]\n",
      "epoch:32 step:25565[D loss: 0.432475, acc: 62.50%, op_acc: 40.62%] [G loss: 1.051958]\n",
      "epoch:32 step:25566[D loss: 0.383354, acc: 69.53%, op_acc: 39.84%] [G loss: 1.075821]\n",
      "epoch:32 step:25567[D loss: 0.393030, acc: 70.31%, op_acc: 46.09%] [G loss: 0.661255]\n",
      "epoch:32 step:25568[D loss: 0.339586, acc: 76.56%, op_acc: 48.44%] [G loss: 1.140230]\n",
      "epoch:32 step:25569[D loss: 0.354514, acc: 74.22%, op_acc: 46.88%] [G loss: 1.229982]\n",
      "epoch:32 step:25570[D loss: 0.395367, acc: 70.31%, op_acc: 39.84%] [G loss: 1.282614]\n",
      "epoch:32 step:25571[D loss: 0.346785, acc: 71.88%, op_acc: 50.00%] [G loss: 0.621795]\n",
      "epoch:32 step:25572[D loss: 0.409615, acc: 58.59%, op_acc: 41.41%] [G loss: 1.103229]\n",
      "epoch:32 step:25573[D loss: 0.338863, acc: 85.16%, op_acc: 40.62%] [G loss: 1.179540]\n",
      "epoch:32 step:25574[D loss: 0.354366, acc: 77.34%, op_acc: 45.31%] [G loss: 1.228521]\n",
      "epoch:32 step:25575[D loss: 0.373136, acc: 68.75%, op_acc: 36.72%] [G loss: 0.740024]\n",
      "epoch:32 step:25576[D loss: 0.389766, acc: 69.53%, op_acc: 39.84%] [G loss: 1.199960]\n",
      "epoch:32 step:25577[D loss: 0.376954, acc: 72.66%, op_acc: 47.66%] [G loss: 1.258268]\n",
      "epoch:32 step:25578[D loss: 0.384235, acc: 73.44%, op_acc: 42.19%] [G loss: 1.132130]\n",
      "epoch:32 step:25579[D loss: 0.368943, acc: 74.22%, op_acc: 42.97%] [G loss: 1.152732]\n",
      "epoch:32 step:25580[D loss: 0.369413, acc: 64.84%, op_acc: 50.00%] [G loss: 0.687263]\n",
      "epoch:32 step:25581[D loss: 0.347377, acc: 76.56%, op_acc: 46.88%] [G loss: 1.286838]\n",
      "epoch:32 step:25582[D loss: 0.325736, acc: 78.12%, op_acc: 52.34%] [G loss: 1.273737]\n",
      "epoch:32 step:25583[D loss: 0.397389, acc: 65.62%, op_acc: 42.97%] [G loss: 1.009925]\n",
      "epoch:32 step:25584[D loss: 0.402007, acc: 64.84%, op_acc: 42.19%] [G loss: 1.153288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25585[D loss: 0.435752, acc: 60.94%, op_acc: 39.84%] [G loss: 1.434555]\n",
      "epoch:32 step:25586[D loss: 0.377726, acc: 73.44%, op_acc: 41.41%] [G loss: 0.488895]\n",
      "epoch:32 step:25587[D loss: 0.275822, acc: 87.50%, op_acc: 52.34%] [G loss: 1.301470]\n",
      "epoch:32 step:25588[D loss: 0.395951, acc: 67.97%, op_acc: 39.84%] [G loss: 0.787895]\n",
      "epoch:32 step:25589[D loss: 0.383324, acc: 65.62%, op_acc: 45.31%] [G loss: 1.234203]\n",
      "epoch:32 step:25590[D loss: 0.390536, acc: 62.50%, op_acc: 42.97%] [G loss: 1.148245]\n",
      "epoch:32 step:25591[D loss: 0.371722, acc: 73.44%, op_acc: 40.62%] [G loss: 0.769379]\n",
      "epoch:32 step:25592[D loss: 0.384767, acc: 63.28%, op_acc: 42.97%] [G loss: 0.830559]\n",
      "epoch:32 step:25593[D loss: 0.425683, acc: 58.59%, op_acc: 45.31%] [G loss: 0.863356]\n",
      "epoch:32 step:25594[D loss: 0.391226, acc: 67.19%, op_acc: 51.56%] [G loss: 0.800607]\n",
      "epoch:32 step:25595[D loss: 0.360205, acc: 69.53%, op_acc: 50.78%] [G loss: 1.289458]\n",
      "epoch:32 step:25596[D loss: 0.428436, acc: 62.50%, op_acc: 41.41%] [G loss: 1.371188]\n",
      "epoch:32 step:25597[D loss: 0.414520, acc: 56.25%, op_acc: 38.28%] [G loss: 0.850492]\n",
      "epoch:32 step:25598[D loss: 0.388322, acc: 65.62%, op_acc: 45.31%] [G loss: 0.805913]\n",
      "epoch:32 step:25599[D loss: 0.358372, acc: 74.22%, op_acc: 47.66%] [G loss: 0.662548]\n",
      "epoch:32 step:25600[D loss: 0.392586, acc: 69.53%, op_acc: 42.97%] [G loss: 1.392527]\n",
      "epoch:32 step:25601[D loss: 0.464833, acc: 49.22%, op_acc: 41.41%] [G loss: 0.990817]\n",
      "epoch:32 step:25602[D loss: 0.391426, acc: 66.41%, op_acc: 47.66%] [G loss: 0.775973]\n",
      "epoch:32 step:25603[D loss: 0.400186, acc: 68.75%, op_acc: 42.19%] [G loss: 0.952102]\n",
      "epoch:32 step:25604[D loss: 0.386488, acc: 61.72%, op_acc: 39.84%] [G loss: 0.833761]\n",
      "epoch:32 step:25605[D loss: 0.430156, acc: 60.94%, op_acc: 40.62%] [G loss: 0.713464]\n",
      "epoch:32 step:25606[D loss: 0.445027, acc: 60.16%, op_acc: 41.41%] [G loss: 0.761607]\n",
      "epoch:32 step:25607[D loss: 0.387173, acc: 68.75%, op_acc: 40.62%] [G loss: 0.915389]\n",
      "epoch:32 step:25608[D loss: 0.464686, acc: 55.47%, op_acc: 40.62%] [G loss: 1.262864]\n",
      "epoch:32 step:25609[D loss: 0.417337, acc: 60.16%, op_acc: 42.97%] [G loss: 1.177582]\n",
      "epoch:32 step:25610[D loss: 0.346029, acc: 71.88%, op_acc: 53.91%] [G loss: 0.807032]\n",
      "epoch:32 step:25611[D loss: 0.419942, acc: 67.19%, op_acc: 38.28%] [G loss: 0.717377]\n",
      "epoch:32 step:25612[D loss: 0.370903, acc: 75.00%, op_acc: 42.97%] [G loss: 0.660363]\n",
      "epoch:32 step:25613[D loss: 0.459322, acc: 53.12%, op_acc: 39.84%] [G loss: 0.753233]\n",
      "epoch:32 step:25614[D loss: 0.436432, acc: 60.94%, op_acc: 42.19%] [G loss: 0.788097]\n",
      "epoch:32 step:25615[D loss: 0.396833, acc: 65.62%, op_acc: 55.47%] [G loss: 1.187255]\n",
      "epoch:32 step:25616[D loss: 0.408244, acc: 58.59%, op_acc: 46.88%] [G loss: 0.912046]\n",
      "epoch:32 step:25617[D loss: 0.441569, acc: 58.59%, op_acc: 42.97%] [G loss: 0.954955]\n",
      "epoch:32 step:25618[D loss: 0.451836, acc: 51.56%, op_acc: 42.19%] [G loss: 0.765659]\n",
      "epoch:32 step:25619[D loss: 0.407761, acc: 64.84%, op_acc: 42.97%] [G loss: 0.943850]\n",
      "epoch:32 step:25620[D loss: 0.422605, acc: 60.16%, op_acc: 40.62%] [G loss: 1.022510]\n",
      "epoch:32 step:25621[D loss: 0.403370, acc: 65.62%, op_acc: 39.84%] [G loss: 0.973153]\n",
      "epoch:32 step:25622[D loss: 0.309155, acc: 81.25%, op_acc: 49.22%] [G loss: 1.026913]\n",
      "epoch:32 step:25623[D loss: 0.419824, acc: 60.94%, op_acc: 40.62%] [G loss: 1.128520]\n",
      "epoch:32 step:25624[D loss: 0.342545, acc: 75.00%, op_acc: 49.22%] [G loss: 1.111904]\n",
      "epoch:32 step:25625[D loss: 0.354861, acc: 78.12%, op_acc: 39.84%] [G loss: 0.925829]\n",
      "epoch:32 step:25626[D loss: 0.424568, acc: 64.06%, op_acc: 42.19%] [G loss: 0.962800]\n",
      "epoch:32 step:25627[D loss: 0.364053, acc: 71.09%, op_acc: 42.19%] [G loss: 1.064933]\n",
      "epoch:32 step:25628[D loss: 0.353014, acc: 72.66%, op_acc: 49.22%] [G loss: 1.068023]\n",
      "epoch:32 step:25629[D loss: 0.350449, acc: 75.00%, op_acc: 54.69%] [G loss: 0.974739]\n",
      "epoch:32 step:25630[D loss: 0.390098, acc: 67.19%, op_acc: 42.97%] [G loss: 1.271874]\n",
      "epoch:32 step:25631[D loss: 0.436661, acc: 58.59%, op_acc: 39.06%] [G loss: 0.979598]\n",
      "epoch:32 step:25632[D loss: 0.359736, acc: 75.00%, op_acc: 42.19%] [G loss: 1.172122]\n",
      "epoch:32 step:25633[D loss: 0.392530, acc: 67.19%, op_acc: 42.97%] [G loss: 0.959158]\n",
      "epoch:32 step:25634[D loss: 0.354765, acc: 71.09%, op_acc: 47.66%] [G loss: 0.924535]\n",
      "epoch:32 step:25635[D loss: 0.362011, acc: 67.19%, op_acc: 42.19%] [G loss: 0.890142]\n",
      "epoch:32 step:25636[D loss: 0.307019, acc: 77.34%, op_acc: 44.53%] [G loss: 1.079428]\n",
      "epoch:32 step:25637[D loss: 0.369316, acc: 71.88%, op_acc: 42.19%] [G loss: 1.161704]\n",
      "epoch:32 step:25638[D loss: 0.395800, acc: 68.75%, op_acc: 46.88%] [G loss: 1.293517]\n",
      "epoch:32 step:25639[D loss: 0.346738, acc: 68.75%, op_acc: 56.25%] [G loss: 0.944436]\n",
      "epoch:32 step:25640[D loss: 0.348754, acc: 74.22%, op_acc: 42.19%] [G loss: 1.219010]\n",
      "epoch:32 step:25641[D loss: 0.376656, acc: 67.19%, op_acc: 39.06%] [G loss: 1.065879]\n",
      "epoch:32 step:25642[D loss: 0.397570, acc: 64.06%, op_acc: 36.72%] [G loss: 1.306295]\n",
      "epoch:32 step:25643[D loss: 0.404019, acc: 65.62%, op_acc: 38.28%] [G loss: 1.055421]\n",
      "epoch:32 step:25644[D loss: 0.368548, acc: 71.09%, op_acc: 48.44%] [G loss: 0.953292]\n",
      "epoch:32 step:25645[D loss: 0.383313, acc: 67.97%, op_acc: 45.31%] [G loss: 1.169213]\n",
      "epoch:32 step:25646[D loss: 0.400151, acc: 61.72%, op_acc: 40.62%] [G loss: 1.085590]\n",
      "epoch:32 step:25647[D loss: 0.349459, acc: 71.88%, op_acc: 45.31%] [G loss: 1.531311]\n",
      "epoch:32 step:25648[D loss: 0.423335, acc: 59.38%, op_acc: 46.09%] [G loss: 1.243667]\n",
      "epoch:32 step:25649[D loss: 0.334298, acc: 76.56%, op_acc: 46.88%] [G loss: 1.184462]\n",
      "epoch:32 step:25650[D loss: 0.385959, acc: 65.62%, op_acc: 41.41%] [G loss: 1.292790]\n",
      "epoch:32 step:25651[D loss: 0.413539, acc: 63.28%, op_acc: 42.97%] [G loss: 1.282180]\n",
      "epoch:32 step:25652[D loss: 0.390126, acc: 64.84%, op_acc: 45.31%] [G loss: 0.933737]\n",
      "epoch:32 step:25653[D loss: 0.377074, acc: 69.53%, op_acc: 43.75%] [G loss: 1.263876]\n",
      "epoch:32 step:25654[D loss: 0.387892, acc: 64.06%, op_acc: 46.09%] [G loss: 1.208212]\n",
      "epoch:32 step:25655[D loss: 0.430154, acc: 61.72%, op_acc: 37.50%] [G loss: 1.028713]\n",
      "epoch:32 step:25656[D loss: 0.392884, acc: 64.84%, op_acc: 46.09%] [G loss: 1.184330]\n",
      "epoch:32 step:25657[D loss: 0.406701, acc: 69.53%, op_acc: 36.72%] [G loss: 1.328169]\n",
      "epoch:32 step:25658[D loss: 0.407761, acc: 63.28%, op_acc: 44.53%] [G loss: 1.198343]\n",
      "epoch:32 step:25659[D loss: 0.439310, acc: 59.38%, op_acc: 43.75%] [G loss: 0.969586]\n",
      "epoch:32 step:25660[D loss: 0.364811, acc: 75.78%, op_acc: 51.56%] [G loss: 1.066074]\n",
      "epoch:32 step:25661[D loss: 0.355679, acc: 71.88%, op_acc: 49.22%] [G loss: 0.890555]\n",
      "epoch:32 step:25662[D loss: 0.372157, acc: 61.72%, op_acc: 47.66%] [G loss: 0.966001]\n",
      "epoch:32 step:25663[D loss: 0.382787, acc: 70.31%, op_acc: 45.31%] [G loss: 0.952068]\n",
      "epoch:32 step:25664[D loss: 0.409774, acc: 62.50%, op_acc: 39.06%] [G loss: 0.869060]\n",
      "epoch:32 step:25665[D loss: 0.385658, acc: 63.28%, op_acc: 44.53%] [G loss: 1.058200]\n",
      "epoch:32 step:25666[D loss: 0.423506, acc: 60.16%, op_acc: 43.75%] [G loss: 0.869639]\n",
      "epoch:32 step:25667[D loss: 0.416520, acc: 60.94%, op_acc: 41.41%] [G loss: 0.970179]\n",
      "epoch:32 step:25668[D loss: 0.436867, acc: 60.94%, op_acc: 34.38%] [G loss: 0.978251]\n",
      "epoch:32 step:25669[D loss: 0.456881, acc: 60.16%, op_acc: 33.59%] [G loss: 0.885497]\n",
      "epoch:32 step:25670[D loss: 0.375848, acc: 70.31%, op_acc: 45.31%] [G loss: 1.076143]\n",
      "epoch:32 step:25671[D loss: 0.363963, acc: 71.88%, op_acc: 47.66%] [G loss: 0.858817]\n",
      "epoch:32 step:25672[D loss: 0.412325, acc: 65.62%, op_acc: 40.62%] [G loss: 0.949802]\n",
      "epoch:32 step:25673[D loss: 0.374639, acc: 71.09%, op_acc: 45.31%] [G loss: 1.235883]\n",
      "epoch:32 step:25674[D loss: 0.336920, acc: 73.44%, op_acc: 48.44%] [G loss: 0.773344]\n",
      "epoch:32 step:25675[D loss: 0.410130, acc: 62.50%, op_acc: 42.97%] [G loss: 0.837540]\n",
      "epoch:32 step:25676[D loss: 0.413173, acc: 66.41%, op_acc: 43.75%] [G loss: 1.159413]\n",
      "epoch:32 step:25677[D loss: 0.402819, acc: 65.62%, op_acc: 37.50%] [G loss: 0.758844]\n",
      "epoch:32 step:25678[D loss: 0.430413, acc: 57.03%, op_acc: 42.97%] [G loss: 1.016008]\n",
      "epoch:32 step:25679[D loss: 0.348282, acc: 73.44%, op_acc: 43.75%] [G loss: 0.959438]\n",
      "epoch:32 step:25680[D loss: 0.443742, acc: 51.56%, op_acc: 40.62%] [G loss: 0.755506]\n",
      "epoch:32 step:25681[D loss: 0.392470, acc: 71.09%, op_acc: 42.19%] [G loss: 0.785073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:25682[D loss: 0.342394, acc: 71.09%, op_acc: 46.09%] [G loss: 0.947610]\n",
      "epoch:32 step:25683[D loss: 0.394493, acc: 65.62%, op_acc: 42.97%] [G loss: 0.948703]\n",
      "epoch:32 step:25684[D loss: 0.412509, acc: 60.94%, op_acc: 47.66%] [G loss: 0.797399]\n",
      "epoch:32 step:25685[D loss: 0.384037, acc: 67.97%, op_acc: 42.97%] [G loss: 0.810533]\n",
      "epoch:32 step:25686[D loss: 0.396986, acc: 64.06%, op_acc: 41.41%] [G loss: 1.058127]\n",
      "epoch:32 step:25687[D loss: 0.374284, acc: 68.75%, op_acc: 46.09%] [G loss: 0.924656]\n",
      "epoch:32 step:25688[D loss: 0.340258, acc: 82.81%, op_acc: 47.66%] [G loss: 1.020312]\n",
      "epoch:32 step:25689[D loss: 0.379539, acc: 65.62%, op_acc: 46.88%] [G loss: 1.070583]\n",
      "epoch:32 step:25690[D loss: 0.329714, acc: 77.34%, op_acc: 45.31%] [G loss: 1.218713]\n",
      "epoch:32 step:25691[D loss: 0.354903, acc: 71.09%, op_acc: 49.22%] [G loss: 1.404292]\n",
      "epoch:32 step:25692[D loss: 0.328134, acc: 79.69%, op_acc: 44.53%] [G loss: 1.120550]\n",
      "epoch:32 step:25693[D loss: 0.311619, acc: 82.81%, op_acc: 44.53%] [G loss: 1.092920]\n",
      "epoch:32 step:25694[D loss: 0.352037, acc: 73.44%, op_acc: 39.84%] [G loss: 0.715152]\n",
      "epoch:32 step:25695[D loss: 0.357167, acc: 70.31%, op_acc: 44.53%] [G loss: 1.259108]\n",
      "epoch:32 step:25696[D loss: 0.355030, acc: 64.84%, op_acc: 48.44%] [G loss: 1.395540]\n",
      "epoch:32 step:25697[D loss: 0.416669, acc: 68.75%, op_acc: 42.97%] [G loss: 0.860359]\n",
      "epoch:32 step:25698[D loss: 0.434871, acc: 58.59%, op_acc: 40.62%] [G loss: 0.645486]\n",
      "epoch:32 step:25699[D loss: 0.501553, acc: 46.88%, op_acc: 39.84%] [G loss: 0.742639]\n",
      "epoch:32 step:25700[D loss: 0.479135, acc: 52.34%, op_acc: 39.84%] [G loss: 0.972668]\n",
      "epoch:32 step:25701[D loss: 0.434529, acc: 60.94%, op_acc: 41.41%] [G loss: 1.415596]\n",
      "epoch:32 step:25702[D loss: 0.458545, acc: 50.78%, op_acc: 48.44%] [G loss: 1.093516]\n",
      "epoch:32 step:25703[D loss: 0.383080, acc: 66.41%, op_acc: 48.44%] [G loss: 1.058922]\n",
      "epoch:32 step:25704[D loss: 0.432112, acc: 60.16%, op_acc: 40.62%] [G loss: 1.193061]\n",
      "epoch:32 step:25705[D loss: 0.434397, acc: 60.94%, op_acc: 49.22%] [G loss: 1.119510]\n",
      "epoch:32 step:25706[D loss: 0.396440, acc: 67.97%, op_acc: 44.53%] [G loss: 1.041340]\n",
      "epoch:32 step:25707[D loss: 0.449634, acc: 53.12%, op_acc: 42.97%] [G loss: 1.010568]\n",
      "epoch:32 step:25708[D loss: 0.403781, acc: 60.16%, op_acc: 47.66%] [G loss: 1.025781]\n",
      "epoch:32 step:25709[D loss: 0.384434, acc: 69.53%, op_acc: 43.75%] [G loss: 1.107685]\n",
      "epoch:32 step:25710[D loss: 0.445945, acc: 61.72%, op_acc: 34.38%] [G loss: 0.987922]\n",
      "epoch:32 step:25711[D loss: 0.382236, acc: 65.62%, op_acc: 45.31%] [G loss: 1.019530]\n",
      "epoch:32 step:25712[D loss: 0.446516, acc: 58.59%, op_acc: 37.50%] [G loss: 0.853492]\n",
      "epoch:32 step:25713[D loss: 0.468226, acc: 46.88%, op_acc: 37.50%] [G loss: 0.844618]\n",
      "epoch:32 step:25714[D loss: 0.378715, acc: 67.19%, op_acc: 42.97%] [G loss: 0.891052]\n",
      "epoch:32 step:25715[D loss: 0.435033, acc: 58.59%, op_acc: 42.97%] [G loss: 0.812433]\n",
      "epoch:32 step:25716[D loss: 0.425635, acc: 60.16%, op_acc: 49.22%] [G loss: 1.085995]\n",
      "epoch:32 step:25717[D loss: 0.404629, acc: 65.62%, op_acc: 47.66%] [G loss: 1.167066]\n",
      "epoch:32 step:25718[D loss: 0.394236, acc: 66.41%, op_acc: 45.31%] [G loss: 1.087294]\n",
      "epoch:32 step:25719[D loss: 0.423566, acc: 63.28%, op_acc: 37.50%] [G loss: 0.948427]\n",
      "epoch:32 step:25720[D loss: 0.403659, acc: 68.75%, op_acc: 40.62%] [G loss: 0.929544]\n",
      "epoch:32 step:25721[D loss: 0.379203, acc: 64.84%, op_acc: 41.41%] [G loss: 1.150542]\n",
      "epoch:32 step:25722[D loss: 0.362580, acc: 72.66%, op_acc: 45.31%] [G loss: 1.190693]\n",
      "epoch:32 step:25723[D loss: 0.351455, acc: 71.09%, op_acc: 47.66%] [G loss: 0.865852]\n",
      "epoch:32 step:25724[D loss: 0.371442, acc: 66.41%, op_acc: 51.56%] [G loss: 1.118254]\n",
      "epoch:32 step:25725[D loss: 0.367991, acc: 69.53%, op_acc: 44.53%] [G loss: 0.619902]\n",
      "epoch:32 step:25726[D loss: 0.382111, acc: 67.97%, op_acc: 46.09%] [G loss: 1.051552]\n",
      "epoch:32 step:25727[D loss: 0.384049, acc: 59.38%, op_acc: 42.19%] [G loss: 0.819314]\n",
      "epoch:32 step:25728[D loss: 0.441293, acc: 59.38%, op_acc: 41.41%] [G loss: 1.158547]\n",
      "epoch:32 step:25729[D loss: 0.366134, acc: 71.09%, op_acc: 49.22%] [G loss: 0.745786]\n",
      "epoch:32 step:25730[D loss: 0.414807, acc: 61.72%, op_acc: 40.62%] [G loss: 0.814919]\n",
      "epoch:32 step:25731[D loss: 0.409965, acc: 58.59%, op_acc: 39.84%] [G loss: 0.834500]\n",
      "epoch:32 step:25732[D loss: 0.368613, acc: 67.97%, op_acc: 45.31%] [G loss: 1.103900]\n",
      "epoch:32 step:25733[D loss: 0.367338, acc: 69.53%, op_acc: 46.88%] [G loss: 1.128606]\n",
      "epoch:32 step:25734[D loss: 0.397277, acc: 64.84%, op_acc: 43.75%] [G loss: 1.016196]\n",
      "epoch:32 step:25735[D loss: 0.431724, acc: 60.16%, op_acc: 40.62%] [G loss: 0.915340]\n",
      "epoch:32 step:25736[D loss: 0.360975, acc: 72.66%, op_acc: 48.44%] [G loss: 0.859726]\n",
      "epoch:32 step:25737[D loss: 0.364983, acc: 75.00%, op_acc: 48.44%] [G loss: 0.877536]\n",
      "epoch:32 step:25738[D loss: 0.405311, acc: 65.62%, op_acc: 43.75%] [G loss: 0.964325]\n",
      "epoch:32 step:25739[D loss: 0.403345, acc: 58.59%, op_acc: 46.09%] [G loss: 1.053509]\n",
      "epoch:32 step:25740[D loss: 0.411588, acc: 68.75%, op_acc: 44.53%] [G loss: 1.093250]\n",
      "epoch:32 step:25741[D loss: 0.407522, acc: 64.84%, op_acc: 42.19%] [G loss: 1.040806]\n",
      "epoch:32 step:25742[D loss: 0.381223, acc: 64.84%, op_acc: 45.31%] [G loss: 1.210920]\n",
      "epoch:32 step:25743[D loss: 0.369399, acc: 73.44%, op_acc: 45.31%] [G loss: 1.017609]\n",
      "epoch:32 step:25744[D loss: 0.363876, acc: 70.31%, op_acc: 46.88%] [G loss: 0.843648]\n",
      "epoch:32 step:25745[D loss: 0.351284, acc: 71.09%, op_acc: 47.66%] [G loss: 1.290946]\n",
      "epoch:32 step:25746[D loss: 0.274902, acc: 85.94%, op_acc: 47.66%] [G loss: 1.172893]\n",
      "epoch:32 step:25747[D loss: 0.310571, acc: 80.47%, op_acc: 56.25%] [G loss: 0.958410]\n",
      "epoch:32 step:25748[D loss: 0.337755, acc: 75.78%, op_acc: 47.66%] [G loss: 1.037849]\n",
      "epoch:32 step:25749[D loss: 0.339773, acc: 75.00%, op_acc: 46.09%] [G loss: 1.374308]\n",
      "epoch:32 step:25750[D loss: 0.348822, acc: 68.75%, op_acc: 49.22%] [G loss: 1.178354]\n",
      "epoch:32 step:25751[D loss: 0.290891, acc: 78.12%, op_acc: 53.91%] [G loss: 0.940019]\n",
      "epoch:32 step:25752[D loss: 0.424556, acc: 57.81%, op_acc: 48.44%] [G loss: 0.882387]\n",
      "epoch:32 step:25753[D loss: 0.376314, acc: 67.97%, op_acc: 48.44%] [G loss: 1.311805]\n",
      "epoch:32 step:25754[D loss: 0.415748, acc: 59.38%, op_acc: 43.75%] [G loss: 1.240991]\n",
      "epoch:32 step:25755[D loss: 0.372525, acc: 71.09%, op_acc: 48.44%] [G loss: 1.027815]\n",
      "epoch:32 step:25756[D loss: 0.420285, acc: 58.59%, op_acc: 43.75%] [G loss: 1.019194]\n",
      "epoch:32 step:25757[D loss: 0.352571, acc: 71.09%, op_acc: 48.44%] [G loss: 1.024722]\n",
      "epoch:32 step:25758[D loss: 0.402715, acc: 67.19%, op_acc: 44.53%] [G loss: 1.101721]\n",
      "epoch:32 step:25759[D loss: 0.383686, acc: 65.62%, op_acc: 45.31%] [G loss: 1.260613]\n",
      "epoch:32 step:25760[D loss: 0.384096, acc: 64.06%, op_acc: 50.00%] [G loss: 1.243565]\n",
      "epoch:32 step:25761[D loss: 0.364047, acc: 66.41%, op_acc: 51.56%] [G loss: 1.187844]\n",
      "epoch:32 step:25762[D loss: 0.428870, acc: 53.91%, op_acc: 43.75%] [G loss: 0.975968]\n",
      "epoch:32 step:25763[D loss: 0.417580, acc: 61.72%, op_acc: 38.28%] [G loss: 1.359443]\n",
      "epoch:32 step:25764[D loss: 0.386487, acc: 71.88%, op_acc: 42.97%] [G loss: 1.073651]\n",
      "epoch:32 step:25765[D loss: 0.443500, acc: 54.69%, op_acc: 37.50%] [G loss: 0.987449]\n",
      "epoch:32 step:25766[D loss: 0.372321, acc: 67.97%, op_acc: 45.31%] [G loss: 1.093079]\n",
      "epoch:32 step:25767[D loss: 0.409478, acc: 64.06%, op_acc: 42.19%] [G loss: 1.116700]\n",
      "epoch:32 step:25768[D loss: 0.394087, acc: 67.19%, op_acc: 42.97%] [G loss: 1.068808]\n",
      "epoch:32 step:25769[D loss: 0.353478, acc: 75.00%, op_acc: 43.75%] [G loss: 1.101910]\n",
      "epoch:32 step:25770[D loss: 0.372135, acc: 67.19%, op_acc: 42.97%] [G loss: 1.137901]\n",
      "epoch:32 step:25771[D loss: 0.377785, acc: 64.06%, op_acc: 46.09%] [G loss: 1.237705]\n",
      "epoch:32 step:25772[D loss: 0.391841, acc: 64.84%, op_acc: 43.75%] [G loss: 1.079057]\n",
      "epoch:32 step:25773[D loss: 0.413066, acc: 65.62%, op_acc: 40.62%] [G loss: 0.880850]\n",
      "epoch:33 step:25774[D loss: 0.351519, acc: 70.31%, op_acc: 46.09%] [G loss: 1.103950]\n",
      "epoch:33 step:25775[D loss: 0.365939, acc: 70.31%, op_acc: 40.62%] [G loss: 1.132755]\n",
      "epoch:33 step:25776[D loss: 0.340381, acc: 72.66%, op_acc: 46.09%] [G loss: 1.093637]\n",
      "epoch:33 step:25777[D loss: 0.362944, acc: 69.53%, op_acc: 50.00%] [G loss: 0.833387]\n",
      "epoch:33 step:25778[D loss: 0.395291, acc: 64.84%, op_acc: 48.44%] [G loss: 0.796820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25779[D loss: 0.412994, acc: 62.50%, op_acc: 46.09%] [G loss: 1.309632]\n",
      "epoch:33 step:25780[D loss: 0.379194, acc: 67.97%, op_acc: 46.88%] [G loss: 0.945825]\n",
      "epoch:33 step:25781[D loss: 0.406482, acc: 63.28%, op_acc: 42.19%] [G loss: 0.831816]\n",
      "epoch:33 step:25782[D loss: 0.368030, acc: 68.75%, op_acc: 50.78%] [G loss: 0.693736]\n",
      "epoch:33 step:25783[D loss: 0.395929, acc: 71.09%, op_acc: 47.66%] [G loss: 1.157620]\n",
      "epoch:33 step:25784[D loss: 0.390436, acc: 65.62%, op_acc: 49.22%] [G loss: 1.179707]\n",
      "epoch:33 step:25785[D loss: 0.377056, acc: 67.97%, op_acc: 43.75%] [G loss: 0.881547]\n",
      "epoch:33 step:25786[D loss: 0.365558, acc: 70.31%, op_acc: 42.19%] [G loss: 1.279072]\n",
      "epoch:33 step:25787[D loss: 0.410746, acc: 63.28%, op_acc: 42.19%] [G loss: 0.791391]\n",
      "epoch:33 step:25788[D loss: 0.322259, acc: 75.00%, op_acc: 50.00%] [G loss: 1.097943]\n",
      "epoch:33 step:25789[D loss: 0.331684, acc: 67.97%, op_acc: 48.44%] [G loss: 0.856435]\n",
      "epoch:33 step:25790[D loss: 0.433748, acc: 58.59%, op_acc: 45.31%] [G loss: 0.928267]\n",
      "epoch:33 step:25791[D loss: 0.418403, acc: 61.72%, op_acc: 43.75%] [G loss: 1.074412]\n",
      "epoch:33 step:25792[D loss: 0.387308, acc: 67.19%, op_acc: 44.53%] [G loss: 1.260079]\n",
      "epoch:33 step:25793[D loss: 0.399028, acc: 64.06%, op_acc: 48.44%] [G loss: 1.154236]\n",
      "epoch:33 step:25794[D loss: 0.442956, acc: 60.94%, op_acc: 39.84%] [G loss: 0.947644]\n",
      "epoch:33 step:25795[D loss: 0.394568, acc: 67.19%, op_acc: 46.09%] [G loss: 1.135242]\n",
      "epoch:33 step:25796[D loss: 0.386296, acc: 63.28%, op_acc: 49.22%] [G loss: 1.257637]\n",
      "epoch:33 step:25797[D loss: 0.416564, acc: 66.41%, op_acc: 41.41%] [G loss: 1.071502]\n",
      "epoch:33 step:25798[D loss: 0.438276, acc: 55.47%, op_acc: 43.75%] [G loss: 0.760593]\n",
      "epoch:33 step:25799[D loss: 0.392865, acc: 61.72%, op_acc: 43.75%] [G loss: 0.812326]\n",
      "epoch:33 step:25800[D loss: 0.397397, acc: 71.88%, op_acc: 46.88%] [G loss: 1.134943]\n",
      "epoch:33 step:25801[D loss: 0.381515, acc: 67.97%, op_acc: 47.66%] [G loss: 0.727394]\n",
      "epoch:33 step:25802[D loss: 0.391888, acc: 62.50%, op_acc: 50.00%] [G loss: 0.714562]\n",
      "epoch:33 step:25803[D loss: 0.365079, acc: 66.41%, op_acc: 49.22%] [G loss: 0.728807]\n",
      "epoch:33 step:25804[D loss: 0.470131, acc: 59.38%, op_acc: 42.19%] [G loss: 0.675631]\n",
      "epoch:33 step:25805[D loss: 0.395824, acc: 63.28%, op_acc: 42.19%] [G loss: 1.251194]\n",
      "epoch:33 step:25806[D loss: 0.357214, acc: 71.88%, op_acc: 45.31%] [G loss: 1.111059]\n",
      "epoch:33 step:25807[D loss: 0.386651, acc: 63.28%, op_acc: 46.88%] [G loss: 0.696777]\n",
      "epoch:33 step:25808[D loss: 0.414009, acc: 60.16%, op_acc: 41.41%] [G loss: 1.126050]\n",
      "epoch:33 step:25809[D loss: 0.361350, acc: 72.66%, op_acc: 46.88%] [G loss: 0.717878]\n",
      "epoch:33 step:25810[D loss: 0.396243, acc: 66.41%, op_acc: 42.19%] [G loss: 0.756337]\n",
      "epoch:33 step:25811[D loss: 0.402944, acc: 65.62%, op_acc: 47.66%] [G loss: 1.155978]\n",
      "epoch:33 step:25812[D loss: 0.397123, acc: 62.50%, op_acc: 41.41%] [G loss: 0.642790]\n",
      "epoch:33 step:25813[D loss: 0.418958, acc: 60.94%, op_acc: 40.62%] [G loss: 1.155349]\n",
      "epoch:33 step:25814[D loss: 0.397847, acc: 61.72%, op_acc: 51.56%] [G loss: 0.804539]\n",
      "epoch:33 step:25815[D loss: 0.372524, acc: 67.19%, op_acc: 46.09%] [G loss: 0.641924]\n",
      "epoch:33 step:25816[D loss: 0.439852, acc: 59.38%, op_acc: 36.72%] [G loss: 0.763260]\n",
      "epoch:33 step:25817[D loss: 0.338781, acc: 76.56%, op_acc: 50.00%] [G loss: 0.728562]\n",
      "epoch:33 step:25818[D loss: 0.359097, acc: 75.00%, op_acc: 43.75%] [G loss: 0.881716]\n",
      "epoch:33 step:25819[D loss: 0.347571, acc: 72.66%, op_acc: 41.41%] [G loss: 1.188676]\n",
      "epoch:33 step:25820[D loss: 0.351753, acc: 73.44%, op_acc: 42.97%] [G loss: 0.774654]\n",
      "epoch:33 step:25821[D loss: 0.391965, acc: 70.31%, op_acc: 44.53%] [G loss: 1.083279]\n",
      "epoch:33 step:25822[D loss: 0.350640, acc: 73.44%, op_acc: 49.22%] [G loss: 0.801721]\n",
      "epoch:33 step:25823[D loss: 0.391754, acc: 68.75%, op_acc: 48.44%] [G loss: 0.981352]\n",
      "epoch:33 step:25824[D loss: 0.343442, acc: 76.56%, op_acc: 44.53%] [G loss: 0.992901]\n",
      "epoch:33 step:25825[D loss: 0.367223, acc: 73.44%, op_acc: 40.62%] [G loss: 1.223152]\n",
      "epoch:33 step:25826[D loss: 0.397482, acc: 71.09%, op_acc: 44.53%] [G loss: 0.974636]\n",
      "epoch:33 step:25827[D loss: 0.449820, acc: 61.72%, op_acc: 39.84%] [G loss: 0.884992]\n",
      "epoch:33 step:25828[D loss: 0.330505, acc: 76.56%, op_acc: 51.56%] [G loss: 0.933723]\n",
      "epoch:33 step:25829[D loss: 0.344919, acc: 73.44%, op_acc: 47.66%] [G loss: 0.992253]\n",
      "epoch:33 step:25830[D loss: 0.349239, acc: 75.00%, op_acc: 45.31%] [G loss: 0.969092]\n",
      "epoch:33 step:25831[D loss: 0.305878, acc: 78.91%, op_acc: 53.91%] [G loss: 1.180277]\n",
      "epoch:33 step:25832[D loss: 0.282805, acc: 82.81%, op_acc: 53.12%] [G loss: 1.083052]\n",
      "epoch:33 step:25833[D loss: 0.274248, acc: 83.59%, op_acc: 49.22%] [G loss: 1.254319]\n",
      "epoch:33 step:25834[D loss: 0.302295, acc: 81.25%, op_acc: 53.12%] [G loss: 1.605466]\n",
      "epoch:33 step:25835[D loss: 0.282686, acc: 85.94%, op_acc: 50.78%] [G loss: 1.168673]\n",
      "epoch:33 step:25836[D loss: 0.331972, acc: 74.22%, op_acc: 46.88%] [G loss: 0.687204]\n",
      "epoch:33 step:25837[D loss: 0.364853, acc: 69.53%, op_acc: 42.19%] [G loss: 1.317986]\n",
      "epoch:33 step:25838[D loss: 0.429058, acc: 59.38%, op_acc: 35.94%] [G loss: 0.820553]\n",
      "epoch:33 step:25839[D loss: 0.439017, acc: 55.47%, op_acc: 35.16%] [G loss: 1.401620]\n",
      "epoch:33 step:25840[D loss: 0.372469, acc: 71.88%, op_acc: 46.09%] [G loss: 1.295889]\n",
      "epoch:33 step:25841[D loss: 0.391078, acc: 69.53%, op_acc: 42.19%] [G loss: 1.421330]\n",
      "epoch:33 step:25842[D loss: 0.403807, acc: 67.97%, op_acc: 46.88%] [G loss: 1.147003]\n",
      "epoch:33 step:25843[D loss: 0.468669, acc: 53.91%, op_acc: 39.06%] [G loss: 1.162173]\n",
      "epoch:33 step:25844[D loss: 0.384862, acc: 67.19%, op_acc: 46.09%] [G loss: 0.907019]\n",
      "epoch:33 step:25845[D loss: 0.374878, acc: 71.09%, op_acc: 44.53%] [G loss: 1.137831]\n",
      "epoch:33 step:25846[D loss: 0.433984, acc: 62.50%, op_acc: 41.41%] [G loss: 0.926384]\n",
      "epoch:33 step:25847[D loss: 0.380326, acc: 58.59%, op_acc: 50.78%] [G loss: 1.034243]\n",
      "epoch:33 step:25848[D loss: 0.433484, acc: 62.50%, op_acc: 37.50%] [G loss: 1.068354]\n",
      "epoch:33 step:25849[D loss: 0.393779, acc: 66.41%, op_acc: 48.44%] [G loss: 1.069781]\n",
      "epoch:33 step:25850[D loss: 0.398566, acc: 65.62%, op_acc: 42.97%] [G loss: 0.912313]\n",
      "epoch:33 step:25851[D loss: 0.424163, acc: 67.97%, op_acc: 34.38%] [G loss: 1.137597]\n",
      "epoch:33 step:25852[D loss: 0.423246, acc: 64.06%, op_acc: 41.41%] [G loss: 0.938187]\n",
      "epoch:33 step:25853[D loss: 0.440319, acc: 67.19%, op_acc: 35.16%] [G loss: 1.138770]\n",
      "epoch:33 step:25854[D loss: 0.413526, acc: 63.28%, op_acc: 47.66%] [G loss: 1.095377]\n",
      "epoch:33 step:25855[D loss: 0.386152, acc: 65.62%, op_acc: 45.31%] [G loss: 1.031963]\n",
      "epoch:33 step:25856[D loss: 0.364088, acc: 73.44%, op_acc: 46.88%] [G loss: 1.309833]\n",
      "epoch:33 step:25857[D loss: 0.372966, acc: 69.53%, op_acc: 42.19%] [G loss: 1.283712]\n",
      "epoch:33 step:25858[D loss: 0.396008, acc: 68.75%, op_acc: 46.88%] [G loss: 1.502197]\n",
      "epoch:33 step:25859[D loss: 0.389030, acc: 71.88%, op_acc: 45.31%] [G loss: 1.070365]\n",
      "epoch:33 step:25860[D loss: 0.418524, acc: 65.62%, op_acc: 40.62%] [G loss: 0.909270]\n",
      "epoch:33 step:25861[D loss: 0.466581, acc: 60.94%, op_acc: 45.31%] [G loss: 1.262691]\n",
      "epoch:33 step:25862[D loss: 0.406734, acc: 64.06%, op_acc: 44.53%] [G loss: 0.995061]\n",
      "epoch:33 step:25863[D loss: 0.424061, acc: 61.72%, op_acc: 42.97%] [G loss: 1.047175]\n",
      "epoch:33 step:25864[D loss: 0.342282, acc: 72.66%, op_acc: 46.88%] [G loss: 1.083951]\n",
      "epoch:33 step:25865[D loss: 0.414491, acc: 67.19%, op_acc: 39.84%] [G loss: 0.985441]\n",
      "epoch:33 step:25866[D loss: 0.344550, acc: 71.09%, op_acc: 47.66%] [G loss: 1.127092]\n",
      "epoch:33 step:25867[D loss: 0.363278, acc: 65.62%, op_acc: 45.31%] [G loss: 0.974349]\n",
      "epoch:33 step:25868[D loss: 0.405138, acc: 60.16%, op_acc: 48.44%] [G loss: 1.086342]\n",
      "epoch:33 step:25869[D loss: 0.397807, acc: 68.75%, op_acc: 43.75%] [G loss: 1.052756]\n",
      "epoch:33 step:25870[D loss: 0.351269, acc: 75.00%, op_acc: 50.78%] [G loss: 1.233354]\n",
      "epoch:33 step:25871[D loss: 0.391120, acc: 68.75%, op_acc: 42.97%] [G loss: 1.054619]\n",
      "epoch:33 step:25872[D loss: 0.369169, acc: 70.31%, op_acc: 48.44%] [G loss: 1.138652]\n",
      "epoch:33 step:25873[D loss: 0.339468, acc: 76.56%, op_acc: 50.00%] [G loss: 1.033174]\n",
      "epoch:33 step:25874[D loss: 0.426932, acc: 57.81%, op_acc: 40.62%] [G loss: 1.049103]\n",
      "epoch:33 step:25875[D loss: 0.408867, acc: 64.06%, op_acc: 42.19%] [G loss: 1.269649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25876[D loss: 0.472918, acc: 47.66%, op_acc: 43.75%] [G loss: 0.972168]\n",
      "epoch:33 step:25877[D loss: 0.355551, acc: 67.19%, op_acc: 49.22%] [G loss: 1.067199]\n",
      "epoch:33 step:25878[D loss: 0.409957, acc: 64.06%, op_acc: 39.06%] [G loss: 1.056442]\n",
      "epoch:33 step:25879[D loss: 0.361867, acc: 67.97%, op_acc: 46.09%] [G loss: 1.301741]\n",
      "epoch:33 step:25880[D loss: 0.408681, acc: 64.84%, op_acc: 47.66%] [G loss: 1.278716]\n",
      "epoch:33 step:25881[D loss: 0.430006, acc: 65.62%, op_acc: 38.28%] [G loss: 0.911544]\n",
      "epoch:33 step:25882[D loss: 0.381506, acc: 67.97%, op_acc: 46.88%] [G loss: 0.771501]\n",
      "epoch:33 step:25883[D loss: 0.371165, acc: 72.66%, op_acc: 49.22%] [G loss: 0.940011]\n",
      "epoch:33 step:25884[D loss: 0.439881, acc: 62.50%, op_acc: 38.28%] [G loss: 0.874106]\n",
      "epoch:33 step:25885[D loss: 0.379743, acc: 67.19%, op_acc: 45.31%] [G loss: 0.948295]\n",
      "epoch:33 step:25886[D loss: 0.376369, acc: 74.22%, op_acc: 37.50%] [G loss: 1.038932]\n",
      "epoch:33 step:25887[D loss: 0.347118, acc: 74.22%, op_acc: 55.47%] [G loss: 1.215046]\n",
      "epoch:33 step:25888[D loss: 0.387491, acc: 64.84%, op_acc: 46.88%] [G loss: 1.094622]\n",
      "epoch:33 step:25889[D loss: 0.407250, acc: 68.75%, op_acc: 39.84%] [G loss: 0.872099]\n",
      "epoch:33 step:25890[D loss: 0.391665, acc: 67.19%, op_acc: 46.88%] [G loss: 1.077297]\n",
      "epoch:33 step:25891[D loss: 0.381672, acc: 74.22%, op_acc: 46.09%] [G loss: 1.191682]\n",
      "epoch:33 step:25892[D loss: 0.416658, acc: 66.41%, op_acc: 39.06%] [G loss: 0.840827]\n",
      "epoch:33 step:25893[D loss: 0.383264, acc: 67.19%, op_acc: 43.75%] [G loss: 0.986876]\n",
      "epoch:33 step:25894[D loss: 0.391136, acc: 67.97%, op_acc: 42.97%] [G loss: 0.962537]\n",
      "epoch:33 step:25895[D loss: 0.353412, acc: 66.41%, op_acc: 50.78%] [G loss: 0.875295]\n",
      "epoch:33 step:25896[D loss: 0.444757, acc: 55.47%, op_acc: 35.16%] [G loss: 1.070503]\n",
      "epoch:33 step:25897[D loss: 0.413925, acc: 59.38%, op_acc: 46.09%] [G loss: 0.912524]\n",
      "epoch:33 step:25898[D loss: 0.493541, acc: 49.22%, op_acc: 32.81%] [G loss: 0.962855]\n",
      "epoch:33 step:25899[D loss: 0.387886, acc: 69.53%, op_acc: 41.41%] [G loss: 0.920758]\n",
      "epoch:33 step:25900[D loss: 0.399462, acc: 66.41%, op_acc: 41.41%] [G loss: 1.202957]\n",
      "epoch:33 step:25901[D loss: 0.404848, acc: 73.44%, op_acc: 40.62%] [G loss: 1.113919]\n",
      "epoch:33 step:25902[D loss: 0.384614, acc: 72.66%, op_acc: 37.50%] [G loss: 0.832652]\n",
      "epoch:33 step:25903[D loss: 0.344363, acc: 74.22%, op_acc: 47.66%] [G loss: 1.015156]\n",
      "epoch:33 step:25904[D loss: 0.368560, acc: 71.09%, op_acc: 44.53%] [G loss: 0.915043]\n",
      "epoch:33 step:25905[D loss: 0.337310, acc: 75.00%, op_acc: 47.66%] [G loss: 0.957860]\n",
      "epoch:33 step:25906[D loss: 0.418946, acc: 61.72%, op_acc: 45.31%] [G loss: 0.924551]\n",
      "epoch:33 step:25907[D loss: 0.341783, acc: 74.22%, op_acc: 46.88%] [G loss: 1.030222]\n",
      "epoch:33 step:25908[D loss: 0.415111, acc: 64.06%, op_acc: 50.78%] [G loss: 1.140887]\n",
      "epoch:33 step:25909[D loss: 0.351674, acc: 70.31%, op_acc: 42.97%] [G loss: 0.909106]\n",
      "epoch:33 step:25910[D loss: 0.411903, acc: 65.62%, op_acc: 42.97%] [G loss: 1.018996]\n",
      "epoch:33 step:25911[D loss: 0.405960, acc: 67.19%, op_acc: 47.66%] [G loss: 1.025269]\n",
      "epoch:33 step:25912[D loss: 0.355279, acc: 70.31%, op_acc: 48.44%] [G loss: 1.065559]\n",
      "epoch:33 step:25913[D loss: 0.397653, acc: 67.97%, op_acc: 40.62%] [G loss: 0.992392]\n",
      "epoch:33 step:25914[D loss: 0.402300, acc: 69.53%, op_acc: 46.09%] [G loss: 1.159016]\n",
      "epoch:33 step:25915[D loss: 0.350383, acc: 71.09%, op_acc: 39.84%] [G loss: 1.017041]\n",
      "epoch:33 step:25916[D loss: 0.338424, acc: 71.88%, op_acc: 49.22%] [G loss: 1.142699]\n",
      "epoch:33 step:25917[D loss: 0.363022, acc: 75.78%, op_acc: 54.69%] [G loss: 1.219172]\n",
      "epoch:33 step:25918[D loss: 0.331125, acc: 77.34%, op_acc: 59.38%] [G loss: 0.874583]\n",
      "epoch:33 step:25919[D loss: 0.365436, acc: 69.53%, op_acc: 41.41%] [G loss: 1.136404]\n",
      "epoch:33 step:25920[D loss: 0.332581, acc: 71.88%, op_acc: 48.44%] [G loss: 1.089770]\n",
      "epoch:33 step:25921[D loss: 0.394681, acc: 64.06%, op_acc: 47.66%] [G loss: 1.195294]\n",
      "epoch:33 step:25922[D loss: 0.315285, acc: 78.91%, op_acc: 51.56%] [G loss: 1.394618]\n",
      "epoch:33 step:25923[D loss: 0.335989, acc: 78.12%, op_acc: 48.44%] [G loss: 1.117877]\n",
      "epoch:33 step:25924[D loss: 0.331443, acc: 75.78%, op_acc: 47.66%] [G loss: 0.843914]\n",
      "epoch:33 step:25925[D loss: 0.411150, acc: 60.94%, op_acc: 42.19%] [G loss: 1.337781]\n",
      "epoch:33 step:25926[D loss: 0.365657, acc: 69.53%, op_acc: 46.09%] [G loss: 1.009140]\n",
      "epoch:33 step:25927[D loss: 0.340107, acc: 78.12%, op_acc: 42.97%] [G loss: 1.272879]\n",
      "epoch:33 step:25928[D loss: 0.318330, acc: 77.34%, op_acc: 53.91%] [G loss: 1.075514]\n",
      "epoch:33 step:25929[D loss: 0.350095, acc: 73.44%, op_acc: 39.84%] [G loss: 0.803626]\n",
      "epoch:33 step:25930[D loss: 0.356734, acc: 71.88%, op_acc: 42.19%] [G loss: 1.173359]\n",
      "epoch:33 step:25931[D loss: 0.381038, acc: 64.84%, op_acc: 51.56%] [G loss: 1.471034]\n",
      "epoch:33 step:25932[D loss: 0.360361, acc: 75.78%, op_acc: 41.41%] [G loss: 1.098454]\n",
      "epoch:33 step:25933[D loss: 0.341520, acc: 78.91%, op_acc: 42.19%] [G loss: 1.266333]\n",
      "epoch:33 step:25934[D loss: 0.366287, acc: 71.09%, op_acc: 53.91%] [G loss: 0.954386]\n",
      "epoch:33 step:25935[D loss: 0.315593, acc: 76.56%, op_acc: 57.81%] [G loss: 1.235259]\n",
      "epoch:33 step:25936[D loss: 0.370658, acc: 71.88%, op_acc: 42.97%] [G loss: 0.878443]\n",
      "epoch:33 step:25937[D loss: 0.420416, acc: 64.84%, op_acc: 34.38%] [G loss: 1.351644]\n",
      "epoch:33 step:25938[D loss: 0.359091, acc: 73.44%, op_acc: 44.53%] [G loss: 1.313507]\n",
      "epoch:33 step:25939[D loss: 0.354797, acc: 74.22%, op_acc: 49.22%] [G loss: 0.914192]\n",
      "epoch:33 step:25940[D loss: 0.424544, acc: 62.50%, op_acc: 46.88%] [G loss: 1.033544]\n",
      "epoch:33 step:25941[D loss: 0.394123, acc: 65.62%, op_acc: 41.41%] [G loss: 1.147361]\n",
      "epoch:33 step:25942[D loss: 0.447958, acc: 53.12%, op_acc: 43.75%] [G loss: 1.465461]\n",
      "epoch:33 step:25943[D loss: 0.414819, acc: 64.06%, op_acc: 42.19%] [G loss: 1.042592]\n",
      "epoch:33 step:25944[D loss: 0.453392, acc: 55.47%, op_acc: 42.19%] [G loss: 0.839521]\n",
      "epoch:33 step:25945[D loss: 0.384267, acc: 69.53%, op_acc: 41.41%] [G loss: 0.999260]\n",
      "epoch:33 step:25946[D loss: 0.395169, acc: 67.19%, op_acc: 48.44%] [G loss: 1.203201]\n",
      "epoch:33 step:25947[D loss: 0.390702, acc: 68.75%, op_acc: 47.66%] [G loss: 0.938689]\n",
      "epoch:33 step:25948[D loss: 0.432078, acc: 55.47%, op_acc: 44.53%] [G loss: 1.078921]\n",
      "epoch:33 step:25949[D loss: 0.373031, acc: 69.53%, op_acc: 50.78%] [G loss: 1.039459]\n",
      "epoch:33 step:25950[D loss: 0.368580, acc: 65.62%, op_acc: 46.09%] [G loss: 0.977564]\n",
      "epoch:33 step:25951[D loss: 0.420971, acc: 61.72%, op_acc: 36.72%] [G loss: 1.040646]\n",
      "epoch:33 step:25952[D loss: 0.401881, acc: 60.16%, op_acc: 39.84%] [G loss: 1.111446]\n",
      "epoch:33 step:25953[D loss: 0.449884, acc: 60.94%, op_acc: 39.06%] [G loss: 1.067835]\n",
      "epoch:33 step:25954[D loss: 0.403066, acc: 64.84%, op_acc: 46.09%] [G loss: 0.879432]\n",
      "epoch:33 step:25955[D loss: 0.408698, acc: 59.38%, op_acc: 40.62%] [G loss: 0.880353]\n",
      "epoch:33 step:25956[D loss: 0.358329, acc: 75.00%, op_acc: 40.62%] [G loss: 1.161242]\n",
      "epoch:33 step:25957[D loss: 0.408159, acc: 62.50%, op_acc: 43.75%] [G loss: 1.111950]\n",
      "epoch:33 step:25958[D loss: 0.369552, acc: 71.09%, op_acc: 43.75%] [G loss: 0.848937]\n",
      "epoch:33 step:25959[D loss: 0.413058, acc: 59.38%, op_acc: 50.00%] [G loss: 1.204387]\n",
      "epoch:33 step:25960[D loss: 0.421089, acc: 60.16%, op_acc: 42.19%] [G loss: 0.933415]\n",
      "epoch:33 step:25961[D loss: 0.452287, acc: 54.69%, op_acc: 40.62%] [G loss: 1.112198]\n",
      "epoch:33 step:25962[D loss: 0.380553, acc: 67.97%, op_acc: 46.09%] [G loss: 0.812356]\n",
      "epoch:33 step:25963[D loss: 0.427693, acc: 62.50%, op_acc: 40.62%] [G loss: 1.287424]\n",
      "epoch:33 step:25964[D loss: 0.407409, acc: 65.62%, op_acc: 45.31%] [G loss: 0.667856]\n",
      "epoch:33 step:25965[D loss: 0.407163, acc: 62.50%, op_acc: 43.75%] [G loss: 1.216517]\n",
      "epoch:33 step:25966[D loss: 0.406099, acc: 71.88%, op_acc: 38.28%] [G loss: 1.203613]\n",
      "epoch:33 step:25967[D loss: 0.397919, acc: 62.50%, op_acc: 42.19%] [G loss: 1.169729]\n",
      "epoch:33 step:25968[D loss: 0.378156, acc: 71.88%, op_acc: 44.53%] [G loss: 0.917578]\n",
      "epoch:33 step:25969[D loss: 0.360971, acc: 72.66%, op_acc: 41.41%] [G loss: 1.108823]\n",
      "epoch:33 step:25970[D loss: 0.458246, acc: 51.56%, op_acc: 38.28%] [G loss: 0.768601]\n",
      "epoch:33 step:25971[D loss: 0.424800, acc: 60.94%, op_acc: 40.62%] [G loss: 0.743013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:25972[D loss: 0.392030, acc: 65.62%, op_acc: 46.09%] [G loss: 0.823404]\n",
      "epoch:33 step:25973[D loss: 0.404460, acc: 62.50%, op_acc: 40.62%] [G loss: 1.069688]\n",
      "epoch:33 step:25974[D loss: 0.355007, acc: 70.31%, op_acc: 51.56%] [G loss: 1.107766]\n",
      "epoch:33 step:25975[D loss: 0.424407, acc: 62.50%, op_acc: 40.62%] [G loss: 0.738586]\n",
      "epoch:33 step:25976[D loss: 0.414409, acc: 66.41%, op_acc: 38.28%] [G loss: 0.820803]\n",
      "epoch:33 step:25977[D loss: 0.383186, acc: 66.41%, op_acc: 46.88%] [G loss: 0.863031]\n",
      "epoch:33 step:25978[D loss: 0.406970, acc: 64.84%, op_acc: 39.06%] [G loss: 1.045940]\n",
      "epoch:33 step:25979[D loss: 0.345247, acc: 76.56%, op_acc: 42.19%] [G loss: 1.222367]\n",
      "epoch:33 step:25980[D loss: 0.349808, acc: 75.00%, op_acc: 49.22%] [G loss: 0.948142]\n",
      "epoch:33 step:25981[D loss: 0.379590, acc: 70.31%, op_acc: 41.41%] [G loss: 0.984831]\n",
      "epoch:33 step:25982[D loss: 0.373819, acc: 74.22%, op_acc: 43.75%] [G loss: 0.981263]\n",
      "epoch:33 step:25983[D loss: 0.356409, acc: 71.09%, op_acc: 42.19%] [G loss: 1.005017]\n",
      "epoch:33 step:25984[D loss: 0.351813, acc: 74.22%, op_acc: 46.09%] [G loss: 1.115435]\n",
      "epoch:33 step:25985[D loss: 0.405292, acc: 62.50%, op_acc: 44.53%] [G loss: 1.058410]\n",
      "epoch:33 step:25986[D loss: 0.339108, acc: 78.12%, op_acc: 48.44%] [G loss: 0.916995]\n",
      "epoch:33 step:25987[D loss: 0.362955, acc: 71.88%, op_acc: 42.19%] [G loss: 0.903478]\n",
      "epoch:33 step:25988[D loss: 0.374881, acc: 75.00%, op_acc: 42.97%] [G loss: 0.971388]\n",
      "epoch:33 step:25989[D loss: 0.459835, acc: 54.69%, op_acc: 35.16%] [G loss: 1.201250]\n",
      "epoch:33 step:25990[D loss: 0.405623, acc: 62.50%, op_acc: 47.66%] [G loss: 1.384987]\n",
      "epoch:33 step:25991[D loss: 0.369647, acc: 72.66%, op_acc: 46.88%] [G loss: 0.900942]\n",
      "epoch:33 step:25992[D loss: 0.393410, acc: 68.75%, op_acc: 42.19%] [G loss: 1.091344]\n",
      "epoch:33 step:25993[D loss: 0.423929, acc: 69.53%, op_acc: 40.62%] [G loss: 0.854158]\n",
      "epoch:33 step:25994[D loss: 0.334922, acc: 74.22%, op_acc: 46.88%] [G loss: 0.760595]\n",
      "epoch:33 step:25995[D loss: 0.441058, acc: 53.12%, op_acc: 41.41%] [G loss: 0.683136]\n",
      "epoch:33 step:25996[D loss: 0.390912, acc: 64.84%, op_acc: 42.19%] [G loss: 0.891551]\n",
      "epoch:33 step:25997[D loss: 0.351068, acc: 77.34%, op_acc: 39.84%] [G loss: 0.969966]\n",
      "epoch:33 step:25998[D loss: 0.328074, acc: 78.12%, op_acc: 46.88%] [G loss: 1.071931]\n",
      "epoch:33 step:25999[D loss: 0.339953, acc: 68.75%, op_acc: 45.31%] [G loss: 0.959512]\n",
      "epoch:33 step:26000[D loss: 0.333801, acc: 78.91%, op_acc: 49.22%] [G loss: 0.825351]\n",
      "epoch:33 step:26001[D loss: 0.377885, acc: 67.19%, op_acc: 50.78%] [G loss: 0.897902]\n",
      "epoch:33 step:26002[D loss: 0.375533, acc: 71.09%, op_acc: 46.09%] [G loss: 0.820251]\n",
      "epoch:33 step:26003[D loss: 0.357338, acc: 75.00%, op_acc: 48.44%] [G loss: 1.001756]\n",
      "epoch:33 step:26004[D loss: 0.372827, acc: 66.41%, op_acc: 46.88%] [G loss: 1.037135]\n",
      "epoch:33 step:26005[D loss: 0.381700, acc: 68.75%, op_acc: 43.75%] [G loss: 0.856409]\n",
      "epoch:33 step:26006[D loss: 0.297071, acc: 83.59%, op_acc: 48.44%] [G loss: 1.227837]\n",
      "epoch:33 step:26007[D loss: 0.373202, acc: 72.66%, op_acc: 50.78%] [G loss: 1.236074]\n",
      "epoch:33 step:26008[D loss: 0.386139, acc: 64.84%, op_acc: 49.22%] [G loss: 0.779505]\n",
      "epoch:33 step:26009[D loss: 0.405596, acc: 66.41%, op_acc: 43.75%] [G loss: 0.809528]\n",
      "epoch:33 step:26010[D loss: 0.407591, acc: 60.94%, op_acc: 43.75%] [G loss: 1.010849]\n",
      "epoch:33 step:26011[D loss: 0.425631, acc: 64.84%, op_acc: 41.41%] [G loss: 0.986008]\n",
      "epoch:33 step:26012[D loss: 0.431180, acc: 60.16%, op_acc: 39.84%] [G loss: 1.032980]\n",
      "epoch:33 step:26013[D loss: 0.468444, acc: 60.16%, op_acc: 33.59%] [G loss: 1.051556]\n",
      "epoch:33 step:26014[D loss: 0.395775, acc: 64.06%, op_acc: 46.88%] [G loss: 1.039322]\n",
      "epoch:33 step:26015[D loss: 0.364828, acc: 71.09%, op_acc: 46.09%] [G loss: 0.941843]\n",
      "epoch:33 step:26016[D loss: 0.357246, acc: 69.53%, op_acc: 46.88%] [G loss: 1.103338]\n",
      "epoch:33 step:26017[D loss: 0.371512, acc: 67.97%, op_acc: 53.91%] [G loss: 1.068380]\n",
      "epoch:33 step:26018[D loss: 0.392737, acc: 62.50%, op_acc: 47.66%] [G loss: 0.907435]\n",
      "epoch:33 step:26019[D loss: 0.398813, acc: 64.06%, op_acc: 44.53%] [G loss: 1.013292]\n",
      "epoch:33 step:26020[D loss: 0.376864, acc: 69.53%, op_acc: 40.62%] [G loss: 0.991581]\n",
      "epoch:33 step:26021[D loss: 0.381013, acc: 71.09%, op_acc: 48.44%] [G loss: 1.001802]\n",
      "epoch:33 step:26022[D loss: 0.336338, acc: 80.47%, op_acc: 42.97%] [G loss: 1.115155]\n",
      "epoch:33 step:26023[D loss: 0.413623, acc: 67.97%, op_acc: 42.97%] [G loss: 1.233867]\n",
      "epoch:33 step:26024[D loss: 0.319180, acc: 82.03%, op_acc: 53.12%] [G loss: 1.078331]\n",
      "epoch:33 step:26025[D loss: 0.341375, acc: 71.88%, op_acc: 50.00%] [G loss: 0.882939]\n",
      "epoch:33 step:26026[D loss: 0.357513, acc: 71.88%, op_acc: 54.69%] [G loss: 1.196921]\n",
      "epoch:33 step:26027[D loss: 0.263468, acc: 90.62%, op_acc: 54.69%] [G loss: 0.999047]\n",
      "epoch:33 step:26028[D loss: 0.330011, acc: 76.56%, op_acc: 47.66%] [G loss: 0.579371]\n",
      "epoch:33 step:26029[D loss: 0.399219, acc: 67.97%, op_acc: 42.97%] [G loss: 1.177993]\n",
      "epoch:33 step:26030[D loss: 0.378499, acc: 67.19%, op_acc: 46.09%] [G loss: 1.068616]\n",
      "epoch:33 step:26031[D loss: 0.394111, acc: 62.50%, op_acc: 41.41%] [G loss: 1.481561]\n",
      "epoch:33 step:26032[D loss: 0.418693, acc: 60.94%, op_acc: 38.28%] [G loss: 1.213213]\n",
      "epoch:33 step:26033[D loss: 0.334264, acc: 75.00%, op_acc: 50.78%] [G loss: 0.971357]\n",
      "epoch:33 step:26034[D loss: 0.331577, acc: 80.47%, op_acc: 47.66%] [G loss: 1.263202]\n",
      "epoch:33 step:26035[D loss: 0.326098, acc: 75.00%, op_acc: 51.56%] [G loss: 0.969080]\n",
      "epoch:33 step:26036[D loss: 0.343266, acc: 80.47%, op_acc: 50.78%] [G loss: 1.008169]\n",
      "epoch:33 step:26037[D loss: 0.289058, acc: 80.47%, op_acc: 51.56%] [G loss: 1.158881]\n",
      "epoch:33 step:26038[D loss: 0.325071, acc: 74.22%, op_acc: 56.25%] [G loss: 1.177315]\n",
      "epoch:33 step:26039[D loss: 0.273631, acc: 89.84%, op_acc: 57.03%] [G loss: 1.086741]\n",
      "epoch:33 step:26040[D loss: 0.346524, acc: 67.97%, op_acc: 60.16%] [G loss: 1.081893]\n",
      "epoch:33 step:26041[D loss: 0.294043, acc: 82.81%, op_acc: 59.38%] [G loss: 1.203566]\n",
      "epoch:33 step:26042[D loss: 0.279987, acc: 82.81%, op_acc: 57.81%] [G loss: 1.006555]\n",
      "epoch:33 step:26043[D loss: 0.266060, acc: 83.59%, op_acc: 53.12%] [G loss: 1.185692]\n",
      "epoch:33 step:26044[D loss: 0.371557, acc: 66.41%, op_acc: 42.19%] [G loss: 1.062454]\n",
      "epoch:33 step:26045[D loss: 0.299967, acc: 79.69%, op_acc: 56.25%] [G loss: 1.281010]\n",
      "epoch:33 step:26046[D loss: 0.254591, acc: 89.06%, op_acc: 63.28%] [G loss: 1.481998]\n",
      "epoch:33 step:26047[D loss: 0.292548, acc: 82.81%, op_acc: 56.25%] [G loss: 1.220885]\n",
      "epoch:33 step:26048[D loss: 0.251692, acc: 87.50%, op_acc: 57.81%] [G loss: 1.649031]\n",
      "epoch:33 step:26049[D loss: 0.284259, acc: 85.94%, op_acc: 46.88%] [G loss: 1.476799]\n",
      "epoch:33 step:26050[D loss: 0.292903, acc: 88.28%, op_acc: 57.03%] [G loss: 1.553091]\n",
      "epoch:33 step:26051[D loss: 0.237873, acc: 88.28%, op_acc: 64.84%] [G loss: 1.693298]\n",
      "epoch:33 step:26052[D loss: 0.266456, acc: 87.50%, op_acc: 64.84%] [G loss: 1.616174]\n",
      "epoch:33 step:26053[D loss: 0.243124, acc: 89.84%, op_acc: 64.84%] [G loss: 1.975007]\n",
      "epoch:33 step:26054[D loss: 0.251488, acc: 89.84%, op_acc: 57.03%] [G loss: 1.924611]\n",
      "epoch:33 step:26055[D loss: 0.238573, acc: 92.97%, op_acc: 60.94%] [G loss: 1.584892]\n",
      "epoch:33 step:26056[D loss: 0.228861, acc: 90.62%, op_acc: 60.16%] [G loss: 1.858106]\n",
      "epoch:33 step:26057[D loss: 0.194779, acc: 95.31%, op_acc: 64.84%] [G loss: 2.109848]\n",
      "epoch:33 step:26058[D loss: 0.199010, acc: 95.31%, op_acc: 67.97%] [G loss: 1.879248]\n",
      "epoch:33 step:26059[D loss: 0.247211, acc: 91.41%, op_acc: 61.72%] [G loss: 1.831008]\n",
      "epoch:33 step:26060[D loss: 0.287252, acc: 81.25%, op_acc: 66.41%] [G loss: 1.795927]\n",
      "epoch:33 step:26061[D loss: 0.191692, acc: 92.97%, op_acc: 71.88%] [G loss: 2.016080]\n",
      "epoch:33 step:26062[D loss: 0.226669, acc: 90.62%, op_acc: 67.97%] [G loss: 1.895826]\n",
      "epoch:33 step:26063[D loss: 0.199164, acc: 92.97%, op_acc: 66.41%] [G loss: 2.019809]\n",
      "epoch:33 step:26064[D loss: 0.235529, acc: 93.75%, op_acc: 63.28%] [G loss: 0.396144]\n",
      "epoch:33 step:26065[D loss: 0.485086, acc: 58.59%, op_acc: 34.38%] [G loss: 2.293829]\n",
      "epoch:33 step:26066[D loss: 0.322713, acc: 75.78%, op_acc: 45.31%] [G loss: 2.701407]\n",
      "epoch:33 step:26067[D loss: 0.331815, acc: 73.44%, op_acc: 52.34%] [G loss: 2.413559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26068[D loss: 0.304734, acc: 81.25%, op_acc: 52.34%] [G loss: 0.930474]\n",
      "epoch:33 step:26069[D loss: 0.370387, acc: 67.97%, op_acc: 46.88%] [G loss: 2.561280]\n",
      "epoch:33 step:26070[D loss: 0.432805, acc: 62.50%, op_acc: 41.41%] [G loss: 0.849902]\n",
      "epoch:33 step:26071[D loss: 0.397948, acc: 68.75%, op_acc: 39.06%] [G loss: 2.534463]\n",
      "epoch:33 step:26072[D loss: 0.378858, acc: 64.84%, op_acc: 46.09%] [G loss: 1.055987]\n",
      "epoch:33 step:26073[D loss: 0.477825, acc: 53.12%, op_acc: 36.72%] [G loss: 2.323657]\n",
      "epoch:33 step:26074[D loss: 0.474712, acc: 47.66%, op_acc: 39.84%] [G loss: 2.276659]\n",
      "epoch:33 step:26075[D loss: 0.445296, acc: 62.50%, op_acc: 42.19%] [G loss: 2.112749]\n",
      "epoch:33 step:26076[D loss: 0.412775, acc: 60.94%, op_acc: 42.97%] [G loss: 1.834825]\n",
      "epoch:33 step:26077[D loss: 0.417111, acc: 63.28%, op_acc: 44.53%] [G loss: 1.681845]\n",
      "epoch:33 step:26078[D loss: 0.464038, acc: 57.81%, op_acc: 45.31%] [G loss: 1.655809]\n",
      "epoch:33 step:26079[D loss: 0.532283, acc: 55.47%, op_acc: 35.16%] [G loss: 0.934065]\n",
      "epoch:33 step:26080[D loss: 0.346910, acc: 69.53%, op_acc: 39.84%] [G loss: 1.563836]\n",
      "epoch:33 step:26081[D loss: 0.458319, acc: 60.16%, op_acc: 42.97%] [G loss: 1.172575]\n",
      "epoch:33 step:26082[D loss: 0.443065, acc: 57.81%, op_acc: 40.62%] [G loss: 1.303163]\n",
      "epoch:33 step:26083[D loss: 0.328526, acc: 75.78%, op_acc: 43.75%] [G loss: 1.137511]\n",
      "epoch:33 step:26084[D loss: 0.328674, acc: 78.12%, op_acc: 53.12%] [G loss: 1.419705]\n",
      "epoch:33 step:26085[D loss: 0.363571, acc: 67.97%, op_acc: 52.34%] [G loss: 1.464558]\n",
      "epoch:33 step:26086[D loss: 0.406274, acc: 65.62%, op_acc: 48.44%] [G loss: 1.869016]\n",
      "epoch:33 step:26087[D loss: 0.383227, acc: 67.19%, op_acc: 49.22%] [G loss: 1.659294]\n",
      "epoch:33 step:26088[D loss: 0.324474, acc: 76.56%, op_acc: 52.34%] [G loss: 1.875578]\n",
      "epoch:33 step:26089[D loss: 0.365056, acc: 73.44%, op_acc: 46.09%] [G loss: 1.513811]\n",
      "epoch:33 step:26090[D loss: 0.382792, acc: 71.09%, op_acc: 49.22%] [G loss: 1.533649]\n",
      "epoch:33 step:26091[D loss: 0.333264, acc: 76.56%, op_acc: 48.44%] [G loss: 1.760232]\n",
      "epoch:33 step:26092[D loss: 0.303845, acc: 79.69%, op_acc: 51.56%] [G loss: 1.783934]\n",
      "epoch:33 step:26093[D loss: 0.241390, acc: 86.72%, op_acc: 57.03%] [G loss: 1.825808]\n",
      "epoch:33 step:26094[D loss: 0.294716, acc: 82.03%, op_acc: 52.34%] [G loss: 1.697862]\n",
      "epoch:33 step:26095[D loss: 0.370592, acc: 68.75%, op_acc: 51.56%] [G loss: 1.428480]\n",
      "epoch:33 step:26096[D loss: 0.289714, acc: 82.81%, op_acc: 53.91%] [G loss: 1.479826]\n",
      "epoch:33 step:26097[D loss: 0.294203, acc: 89.84%, op_acc: 50.00%] [G loss: 1.836621]\n",
      "epoch:33 step:26098[D loss: 0.285688, acc: 79.69%, op_acc: 51.56%] [G loss: 1.797751]\n",
      "epoch:33 step:26099[D loss: 0.275742, acc: 84.38%, op_acc: 53.12%] [G loss: 0.438230]\n",
      "epoch:33 step:26100[D loss: 0.574752, acc: 46.09%, op_acc: 31.25%] [G loss: 1.867167]\n",
      "epoch:33 step:26101[D loss: 0.518484, acc: 57.81%, op_acc: 35.16%] [G loss: 0.731166]\n",
      "epoch:33 step:26102[D loss: 0.439859, acc: 52.34%, op_acc: 40.62%] [G loss: 0.751813]\n",
      "epoch:33 step:26103[D loss: 0.488037, acc: 40.62%, op_acc: 35.94%] [G loss: 1.738429]\n",
      "epoch:33 step:26104[D loss: 0.406905, acc: 59.38%, op_acc: 42.97%] [G loss: 1.703597]\n",
      "epoch:33 step:26105[D loss: 0.337987, acc: 73.44%, op_acc: 49.22%] [G loss: 1.487201]\n",
      "epoch:33 step:26106[D loss: 0.402177, acc: 64.84%, op_acc: 46.09%] [G loss: 1.480664]\n",
      "epoch:33 step:26107[D loss: 0.341842, acc: 67.97%, op_acc: 53.12%] [G loss: 1.224628]\n",
      "epoch:33 step:26108[D loss: 0.443004, acc: 59.38%, op_acc: 41.41%] [G loss: 1.438290]\n",
      "epoch:33 step:26109[D loss: 0.371991, acc: 73.44%, op_acc: 40.62%] [G loss: 1.466914]\n",
      "epoch:33 step:26110[D loss: 0.412603, acc: 69.53%, op_acc: 40.62%] [G loss: 1.491928]\n",
      "epoch:33 step:26111[D loss: 0.405004, acc: 64.06%, op_acc: 46.88%] [G loss: 1.371740]\n",
      "epoch:33 step:26112[D loss: 0.388334, acc: 68.75%, op_acc: 46.88%] [G loss: 1.320035]\n",
      "epoch:33 step:26113[D loss: 0.363420, acc: 73.44%, op_acc: 50.00%] [G loss: 1.495309]\n",
      "epoch:33 step:26114[D loss: 0.379364, acc: 67.19%, op_acc: 50.00%] [G loss: 1.343090]\n",
      "epoch:33 step:26115[D loss: 0.407280, acc: 64.06%, op_acc: 39.84%] [G loss: 1.497566]\n",
      "epoch:33 step:26116[D loss: 0.323205, acc: 78.12%, op_acc: 47.66%] [G loss: 1.087983]\n",
      "epoch:33 step:26117[D loss: 0.371422, acc: 66.41%, op_acc: 44.53%] [G loss: 1.385946]\n",
      "epoch:33 step:26118[D loss: 0.380119, acc: 67.19%, op_acc: 45.31%] [G loss: 1.015160]\n",
      "epoch:33 step:26119[D loss: 0.449090, acc: 66.41%, op_acc: 35.16%] [G loss: 1.396359]\n",
      "epoch:33 step:26120[D loss: 0.417259, acc: 57.03%, op_acc: 44.53%] [G loss: 1.258139]\n",
      "epoch:33 step:26121[D loss: 0.340268, acc: 75.00%, op_acc: 43.75%] [G loss: 1.411812]\n",
      "epoch:33 step:26122[D loss: 0.386252, acc: 71.09%, op_acc: 44.53%] [G loss: 1.482572]\n",
      "epoch:33 step:26123[D loss: 0.365591, acc: 72.66%, op_acc: 44.53%] [G loss: 1.000442]\n",
      "epoch:33 step:26124[D loss: 0.414490, acc: 64.06%, op_acc: 42.19%] [G loss: 1.114165]\n",
      "epoch:33 step:26125[D loss: 0.426246, acc: 65.62%, op_acc: 39.06%] [G loss: 1.016383]\n",
      "epoch:33 step:26126[D loss: 0.321253, acc: 76.56%, op_acc: 55.47%] [G loss: 1.119158]\n",
      "epoch:33 step:26127[D loss: 0.403044, acc: 66.41%, op_acc: 41.41%] [G loss: 1.250443]\n",
      "epoch:33 step:26128[D loss: 0.394704, acc: 65.62%, op_acc: 38.28%] [G loss: 1.024117]\n",
      "epoch:33 step:26129[D loss: 0.422917, acc: 55.47%, op_acc: 40.62%] [G loss: 1.326874]\n",
      "epoch:33 step:26130[D loss: 0.341806, acc: 75.00%, op_acc: 40.62%] [G loss: 1.189750]\n",
      "epoch:33 step:26131[D loss: 0.374377, acc: 73.44%, op_acc: 48.44%] [G loss: 1.293954]\n",
      "epoch:33 step:26132[D loss: 0.343935, acc: 78.91%, op_acc: 42.19%] [G loss: 1.132595]\n",
      "epoch:33 step:26133[D loss: 0.366789, acc: 71.88%, op_acc: 48.44%] [G loss: 1.397207]\n",
      "epoch:33 step:26134[D loss: 0.437020, acc: 60.16%, op_acc: 42.19%] [G loss: 1.254176]\n",
      "epoch:33 step:26135[D loss: 0.377837, acc: 68.75%, op_acc: 50.00%] [G loss: 0.980400]\n",
      "epoch:33 step:26136[D loss: 0.352821, acc: 68.75%, op_acc: 45.31%] [G loss: 1.212349]\n",
      "epoch:33 step:26137[D loss: 0.396899, acc: 67.97%, op_acc: 37.50%] [G loss: 0.996827]\n",
      "epoch:33 step:26138[D loss: 0.436045, acc: 53.12%, op_acc: 44.53%] [G loss: 1.244177]\n",
      "epoch:33 step:26139[D loss: 0.309556, acc: 81.25%, op_acc: 50.78%] [G loss: 1.044875]\n",
      "epoch:33 step:26140[D loss: 0.399385, acc: 69.53%, op_acc: 42.97%] [G loss: 0.911621]\n",
      "epoch:33 step:26141[D loss: 0.393164, acc: 67.97%, op_acc: 43.75%] [G loss: 1.333730]\n",
      "epoch:33 step:26142[D loss: 0.365213, acc: 68.75%, op_acc: 39.06%] [G loss: 1.378988]\n",
      "epoch:33 step:26143[D loss: 0.407636, acc: 70.31%, op_acc: 47.66%] [G loss: 1.324171]\n",
      "epoch:33 step:26144[D loss: 0.437910, acc: 55.47%, op_acc: 49.22%] [G loss: 1.311867]\n",
      "epoch:33 step:26145[D loss: 0.385047, acc: 65.62%, op_acc: 53.91%] [G loss: 0.775723]\n",
      "epoch:33 step:26146[D loss: 0.437884, acc: 61.72%, op_acc: 45.31%] [G loss: 0.930501]\n",
      "epoch:33 step:26147[D loss: 0.408639, acc: 61.72%, op_acc: 50.00%] [G loss: 1.276229]\n",
      "epoch:33 step:26148[D loss: 0.393993, acc: 64.84%, op_acc: 50.78%] [G loss: 1.083089]\n",
      "epoch:33 step:26149[D loss: 0.362412, acc: 70.31%, op_acc: 49.22%] [G loss: 1.034750]\n",
      "epoch:33 step:26150[D loss: 0.391445, acc: 65.62%, op_acc: 46.09%] [G loss: 0.825503]\n",
      "epoch:33 step:26151[D loss: 0.423143, acc: 62.50%, op_acc: 42.19%] [G loss: 1.119103]\n",
      "epoch:33 step:26152[D loss: 0.323158, acc: 75.00%, op_acc: 50.78%] [G loss: 0.753765]\n",
      "epoch:33 step:26153[D loss: 0.337779, acc: 75.78%, op_acc: 49.22%] [G loss: 1.025925]\n",
      "epoch:33 step:26154[D loss: 0.365449, acc: 69.53%, op_acc: 46.88%] [G loss: 1.199619]\n",
      "epoch:33 step:26155[D loss: 0.452875, acc: 61.72%, op_acc: 36.72%] [G loss: 1.090929]\n",
      "epoch:33 step:26156[D loss: 0.374092, acc: 71.09%, op_acc: 48.44%] [G loss: 1.074183]\n",
      "epoch:33 step:26157[D loss: 0.347513, acc: 73.44%, op_acc: 49.22%] [G loss: 1.064635]\n",
      "epoch:33 step:26158[D loss: 0.355840, acc: 76.56%, op_acc: 46.09%] [G loss: 1.063722]\n",
      "epoch:33 step:26159[D loss: 0.382999, acc: 67.19%, op_acc: 45.31%] [G loss: 0.920543]\n",
      "epoch:33 step:26160[D loss: 0.434949, acc: 57.81%, op_acc: 47.66%] [G loss: 1.266568]\n",
      "epoch:33 step:26161[D loss: 0.430709, acc: 64.06%, op_acc: 41.41%] [G loss: 1.054672]\n",
      "epoch:33 step:26162[D loss: 0.421824, acc: 58.59%, op_acc: 40.62%] [G loss: 1.103170]\n",
      "epoch:33 step:26163[D loss: 0.385443, acc: 67.19%, op_acc: 43.75%] [G loss: 0.875849]\n",
      "epoch:33 step:26164[D loss: 0.400039, acc: 59.38%, op_acc: 50.78%] [G loss: 0.988536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26165[D loss: 0.376564, acc: 64.06%, op_acc: 50.00%] [G loss: 0.953097]\n",
      "epoch:33 step:26166[D loss: 0.387029, acc: 68.75%, op_acc: 46.09%] [G loss: 0.903659]\n",
      "epoch:33 step:26167[D loss: 0.362260, acc: 69.53%, op_acc: 48.44%] [G loss: 1.213003]\n",
      "epoch:33 step:26168[D loss: 0.452687, acc: 62.50%, op_acc: 39.06%] [G loss: 0.946647]\n",
      "epoch:33 step:26169[D loss: 0.353774, acc: 72.66%, op_acc: 44.53%] [G loss: 1.285528]\n",
      "epoch:33 step:26170[D loss: 0.422612, acc: 60.94%, op_acc: 40.62%] [G loss: 1.015309]\n",
      "epoch:33 step:26171[D loss: 0.483233, acc: 56.25%, op_acc: 37.50%] [G loss: 0.908142]\n",
      "epoch:33 step:26172[D loss: 0.418375, acc: 60.16%, op_acc: 42.19%] [G loss: 0.928825]\n",
      "epoch:33 step:26173[D loss: 0.370344, acc: 71.09%, op_acc: 47.66%] [G loss: 1.106867]\n",
      "epoch:33 step:26174[D loss: 0.359653, acc: 70.31%, op_acc: 43.75%] [G loss: 1.195889]\n",
      "epoch:33 step:26175[D loss: 0.361025, acc: 71.09%, op_acc: 38.28%] [G loss: 1.093610]\n",
      "epoch:33 step:26176[D loss: 0.366832, acc: 71.09%, op_acc: 41.41%] [G loss: 1.167186]\n",
      "epoch:33 step:26177[D loss: 0.375685, acc: 60.16%, op_acc: 48.44%] [G loss: 1.264238]\n",
      "epoch:33 step:26178[D loss: 0.456364, acc: 57.03%, op_acc: 38.28%] [G loss: 1.108718]\n",
      "epoch:33 step:26179[D loss: 0.429314, acc: 61.72%, op_acc: 39.06%] [G loss: 1.155336]\n",
      "epoch:33 step:26180[D loss: 0.347369, acc: 70.31%, op_acc: 42.97%] [G loss: 0.825216]\n",
      "epoch:33 step:26181[D loss: 0.408095, acc: 61.72%, op_acc: 48.44%] [G loss: 0.809626]\n",
      "epoch:33 step:26182[D loss: 0.417673, acc: 64.06%, op_acc: 47.66%] [G loss: 0.808502]\n",
      "epoch:33 step:26183[D loss: 0.321582, acc: 73.44%, op_acc: 46.09%] [G loss: 1.147245]\n",
      "epoch:33 step:26184[D loss: 0.428742, acc: 61.72%, op_acc: 43.75%] [G loss: 1.166175]\n",
      "epoch:33 step:26185[D loss: 0.397185, acc: 67.97%, op_acc: 46.09%] [G loss: 0.858175]\n",
      "epoch:33 step:26186[D loss: 0.431944, acc: 59.38%, op_acc: 41.41%] [G loss: 0.826683]\n",
      "epoch:33 step:26187[D loss: 0.368695, acc: 73.44%, op_acc: 48.44%] [G loss: 0.717190]\n",
      "epoch:33 step:26188[D loss: 0.392939, acc: 68.75%, op_acc: 42.97%] [G loss: 1.242492]\n",
      "epoch:33 step:26189[D loss: 0.353449, acc: 71.88%, op_acc: 53.12%] [G loss: 1.266654]\n",
      "epoch:33 step:26190[D loss: 0.373888, acc: 70.31%, op_acc: 45.31%] [G loss: 1.146129]\n",
      "epoch:33 step:26191[D loss: 0.378311, acc: 64.84%, op_acc: 52.34%] [G loss: 0.713498]\n",
      "epoch:33 step:26192[D loss: 0.390325, acc: 68.75%, op_acc: 42.97%] [G loss: 0.921230]\n",
      "epoch:33 step:26193[D loss: 0.439299, acc: 62.50%, op_acc: 43.75%] [G loss: 0.780140]\n",
      "epoch:33 step:26194[D loss: 0.442960, acc: 57.81%, op_acc: 41.41%] [G loss: 0.942103]\n",
      "epoch:33 step:26195[D loss: 0.310865, acc: 83.59%, op_acc: 52.34%] [G loss: 0.763490]\n",
      "epoch:33 step:26196[D loss: 0.386146, acc: 72.66%, op_acc: 38.28%] [G loss: 1.079108]\n",
      "epoch:33 step:26197[D loss: 0.387370, acc: 67.19%, op_acc: 42.19%] [G loss: 0.989409]\n",
      "epoch:33 step:26198[D loss: 0.409281, acc: 67.19%, op_acc: 45.31%] [G loss: 1.244906]\n",
      "epoch:33 step:26199[D loss: 0.404054, acc: 67.97%, op_acc: 45.31%] [G loss: 1.022751]\n",
      "epoch:33 step:26200[D loss: 0.407425, acc: 59.38%, op_acc: 36.72%] [G loss: 0.939393]\n",
      "epoch:33 step:26201[D loss: 0.397571, acc: 67.19%, op_acc: 43.75%] [G loss: 1.221245]\n",
      "epoch:33 step:26202[D loss: 0.385972, acc: 72.66%, op_acc: 46.09%] [G loss: 1.058238]\n",
      "epoch:33 step:26203[D loss: 0.359314, acc: 67.97%, op_acc: 42.97%] [G loss: 0.960785]\n",
      "epoch:33 step:26204[D loss: 0.369473, acc: 73.44%, op_acc: 46.88%] [G loss: 1.063430]\n",
      "epoch:33 step:26205[D loss: 0.328770, acc: 71.09%, op_acc: 53.12%] [G loss: 1.255841]\n",
      "epoch:33 step:26206[D loss: 0.348625, acc: 73.44%, op_acc: 52.34%] [G loss: 1.112230]\n",
      "epoch:33 step:26207[D loss: 0.341302, acc: 75.78%, op_acc: 49.22%] [G loss: 1.263590]\n",
      "epoch:33 step:26208[D loss: 0.428218, acc: 51.56%, op_acc: 42.19%] [G loss: 0.933569]\n",
      "epoch:33 step:26209[D loss: 0.433649, acc: 64.06%, op_acc: 40.62%] [G loss: 1.208773]\n",
      "epoch:33 step:26210[D loss: 0.396916, acc: 67.19%, op_acc: 40.62%] [G loss: 1.036483]\n",
      "epoch:33 step:26211[D loss: 0.333737, acc: 73.44%, op_acc: 44.53%] [G loss: 0.975527]\n",
      "epoch:33 step:26212[D loss: 0.404489, acc: 65.62%, op_acc: 46.09%] [G loss: 1.297570]\n",
      "epoch:33 step:26213[D loss: 0.401507, acc: 66.41%, op_acc: 43.75%] [G loss: 1.117317]\n",
      "epoch:33 step:26214[D loss: 0.383855, acc: 60.94%, op_acc: 43.75%] [G loss: 1.170427]\n",
      "epoch:33 step:26215[D loss: 0.348655, acc: 76.56%, op_acc: 39.84%] [G loss: 1.054821]\n",
      "epoch:33 step:26216[D loss: 0.356763, acc: 75.00%, op_acc: 42.19%] [G loss: 0.998290]\n",
      "epoch:33 step:26217[D loss: 0.339658, acc: 79.69%, op_acc: 47.66%] [G loss: 1.159896]\n",
      "epoch:33 step:26218[D loss: 0.364999, acc: 76.56%, op_acc: 44.53%] [G loss: 1.039627]\n",
      "epoch:33 step:26219[D loss: 0.357322, acc: 72.66%, op_acc: 49.22%] [G loss: 1.372352]\n",
      "epoch:33 step:26220[D loss: 0.380771, acc: 70.31%, op_acc: 42.97%] [G loss: 0.813224]\n",
      "epoch:33 step:26221[D loss: 0.404023, acc: 69.53%, op_acc: 42.19%] [G loss: 1.428098]\n",
      "epoch:33 step:26222[D loss: 0.330239, acc: 75.00%, op_acc: 46.09%] [G loss: 1.237806]\n",
      "epoch:33 step:26223[D loss: 0.416265, acc: 64.06%, op_acc: 42.19%] [G loss: 0.976498]\n",
      "epoch:33 step:26224[D loss: 0.373099, acc: 72.66%, op_acc: 42.19%] [G loss: 1.300787]\n",
      "epoch:33 step:26225[D loss: 0.338911, acc: 73.44%, op_acc: 50.78%] [G loss: 0.981410]\n",
      "epoch:33 step:26226[D loss: 0.411347, acc: 57.03%, op_acc: 41.41%] [G loss: 1.205450]\n",
      "epoch:33 step:26227[D loss: 0.416513, acc: 60.94%, op_acc: 46.09%] [G loss: 0.753076]\n",
      "epoch:33 step:26228[D loss: 0.435764, acc: 61.72%, op_acc: 49.22%] [G loss: 0.885007]\n",
      "epoch:33 step:26229[D loss: 0.361402, acc: 76.56%, op_acc: 39.84%] [G loss: 0.900379]\n",
      "epoch:33 step:26230[D loss: 0.335414, acc: 76.56%, op_acc: 46.09%] [G loss: 1.150461]\n",
      "epoch:33 step:26231[D loss: 0.341427, acc: 75.00%, op_acc: 46.09%] [G loss: 1.021603]\n",
      "epoch:33 step:26232[D loss: 0.360079, acc: 66.41%, op_acc: 46.88%] [G loss: 1.093653]\n",
      "epoch:33 step:26233[D loss: 0.341492, acc: 74.22%, op_acc: 53.91%] [G loss: 0.838836]\n",
      "epoch:33 step:26234[D loss: 0.430505, acc: 63.28%, op_acc: 39.06%] [G loss: 0.840853]\n",
      "epoch:33 step:26235[D loss: 0.356940, acc: 73.44%, op_acc: 42.19%] [G loss: 0.729047]\n",
      "epoch:33 step:26236[D loss: 0.361800, acc: 71.09%, op_acc: 51.56%] [G loss: 0.703485]\n",
      "epoch:33 step:26237[D loss: 0.417579, acc: 60.94%, op_acc: 41.41%] [G loss: 1.243798]\n",
      "epoch:33 step:26238[D loss: 0.376586, acc: 62.50%, op_acc: 44.53%] [G loss: 0.983779]\n",
      "epoch:33 step:26239[D loss: 0.341305, acc: 76.56%, op_acc: 49.22%] [G loss: 1.101735]\n",
      "epoch:33 step:26240[D loss: 0.347797, acc: 72.66%, op_acc: 48.44%] [G loss: 1.151743]\n",
      "epoch:33 step:26241[D loss: 0.337064, acc: 71.09%, op_acc: 50.78%] [G loss: 1.087059]\n",
      "epoch:33 step:26242[D loss: 0.308561, acc: 75.78%, op_acc: 56.25%] [G loss: 1.111671]\n",
      "epoch:33 step:26243[D loss: 0.368306, acc: 66.41%, op_acc: 50.78%] [G loss: 1.223548]\n",
      "epoch:33 step:26244[D loss: 0.354766, acc: 75.00%, op_acc: 42.97%] [G loss: 1.145165]\n",
      "epoch:33 step:26245[D loss: 0.368869, acc: 75.00%, op_acc: 42.97%] [G loss: 1.150541]\n",
      "epoch:33 step:26246[D loss: 0.357094, acc: 70.31%, op_acc: 49.22%] [G loss: 1.266378]\n",
      "epoch:33 step:26247[D loss: 0.321110, acc: 76.56%, op_acc: 56.25%] [G loss: 1.122260]\n",
      "epoch:33 step:26248[D loss: 0.341951, acc: 70.31%, op_acc: 52.34%] [G loss: 0.872998]\n",
      "epoch:33 step:26249[D loss: 0.383246, acc: 67.19%, op_acc: 42.97%] [G loss: 1.099857]\n",
      "epoch:33 step:26250[D loss: 0.336815, acc: 76.56%, op_acc: 53.12%] [G loss: 1.155682]\n",
      "epoch:33 step:26251[D loss: 0.359044, acc: 70.31%, op_acc: 46.09%] [G loss: 1.146210]\n",
      "epoch:33 step:26252[D loss: 0.324684, acc: 78.12%, op_acc: 53.91%] [G loss: 1.098875]\n",
      "epoch:33 step:26253[D loss: 0.310037, acc: 78.91%, op_acc: 48.44%] [G loss: 1.280193]\n",
      "epoch:33 step:26254[D loss: 0.391590, acc: 72.66%, op_acc: 49.22%] [G loss: 1.407600]\n",
      "epoch:33 step:26255[D loss: 0.341730, acc: 74.22%, op_acc: 50.78%] [G loss: 1.179869]\n",
      "epoch:33 step:26256[D loss: 0.288235, acc: 82.03%, op_acc: 55.47%] [G loss: 1.127030]\n",
      "epoch:33 step:26257[D loss: 0.303712, acc: 81.25%, op_acc: 57.81%] [G loss: 0.829910]\n",
      "epoch:33 step:26258[D loss: 0.393586, acc: 68.75%, op_acc: 44.53%] [G loss: 1.204683]\n",
      "epoch:33 step:26259[D loss: 0.379476, acc: 67.97%, op_acc: 44.53%] [G loss: 1.017357]\n",
      "epoch:33 step:26260[D loss: 0.360256, acc: 70.31%, op_acc: 46.88%] [G loss: 1.005651]\n",
      "epoch:33 step:26261[D loss: 0.347283, acc: 73.44%, op_acc: 38.28%] [G loss: 1.122946]\n",
      "epoch:33 step:26262[D loss: 0.396184, acc: 64.06%, op_acc: 50.78%] [G loss: 0.911187]\n",
      "epoch:33 step:26263[D loss: 0.370409, acc: 69.53%, op_acc: 45.31%] [G loss: 0.859692]\n",
      "epoch:33 step:26264[D loss: 0.433335, acc: 64.06%, op_acc: 39.06%] [G loss: 0.930239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26265[D loss: 0.356550, acc: 73.44%, op_acc: 48.44%] [G loss: 0.851523]\n",
      "epoch:33 step:26266[D loss: 0.400727, acc: 66.41%, op_acc: 43.75%] [G loss: 0.957049]\n",
      "epoch:33 step:26267[D loss: 0.248407, acc: 93.75%, op_acc: 59.38%] [G loss: 1.326446]\n",
      "epoch:33 step:26268[D loss: 0.293012, acc: 85.16%, op_acc: 56.25%] [G loss: 1.064645]\n",
      "epoch:33 step:26269[D loss: 0.312511, acc: 82.81%, op_acc: 44.53%] [G loss: 1.366941]\n",
      "epoch:33 step:26270[D loss: 0.319021, acc: 75.78%, op_acc: 54.69%] [G loss: 1.146648]\n",
      "epoch:33 step:26271[D loss: 0.402900, acc: 67.19%, op_acc: 42.19%] [G loss: 1.165056]\n",
      "epoch:33 step:26272[D loss: 0.432443, acc: 60.94%, op_acc: 46.88%] [G loss: 0.813712]\n",
      "epoch:33 step:26273[D loss: 0.308097, acc: 81.25%, op_acc: 50.00%] [G loss: 0.996648]\n",
      "epoch:33 step:26274[D loss: 0.444138, acc: 60.16%, op_acc: 43.75%] [G loss: 0.848956]\n",
      "epoch:33 step:26275[D loss: 0.347873, acc: 72.66%, op_acc: 51.56%] [G loss: 0.883223]\n",
      "epoch:33 step:26276[D loss: 0.338372, acc: 75.78%, op_acc: 47.66%] [G loss: 1.236889]\n",
      "epoch:33 step:26277[D loss: 0.404945, acc: 66.41%, op_acc: 44.53%] [G loss: 0.942737]\n",
      "epoch:33 step:26278[D loss: 0.375744, acc: 70.31%, op_acc: 41.41%] [G loss: 1.064759]\n",
      "epoch:33 step:26279[D loss: 0.362824, acc: 70.31%, op_acc: 47.66%] [G loss: 1.025321]\n",
      "epoch:33 step:26280[D loss: 0.371476, acc: 68.75%, op_acc: 48.44%] [G loss: 0.999168]\n",
      "epoch:33 step:26281[D loss: 0.357704, acc: 67.19%, op_acc: 51.56%] [G loss: 1.270582]\n",
      "epoch:33 step:26282[D loss: 0.396846, acc: 67.19%, op_acc: 46.88%] [G loss: 0.867402]\n",
      "epoch:33 step:26283[D loss: 0.364704, acc: 75.00%, op_acc: 50.78%] [G loss: 1.283570]\n",
      "epoch:33 step:26284[D loss: 0.368467, acc: 74.22%, op_acc: 43.75%] [G loss: 0.859984]\n",
      "epoch:33 step:26285[D loss: 0.403371, acc: 67.19%, op_acc: 47.66%] [G loss: 0.901575]\n",
      "epoch:33 step:26286[D loss: 0.527978, acc: 50.00%, op_acc: 35.94%] [G loss: 0.953110]\n",
      "epoch:33 step:26287[D loss: 0.361739, acc: 74.22%, op_acc: 42.97%] [G loss: 0.983687]\n",
      "epoch:33 step:26288[D loss: 0.351974, acc: 71.88%, op_acc: 43.75%] [G loss: 1.013911]\n",
      "epoch:33 step:26289[D loss: 0.317868, acc: 80.47%, op_acc: 47.66%] [G loss: 0.904249]\n",
      "epoch:33 step:26290[D loss: 0.381155, acc: 66.41%, op_acc: 44.53%] [G loss: 0.839851]\n",
      "epoch:33 step:26291[D loss: 0.412071, acc: 62.50%, op_acc: 46.88%] [G loss: 0.974526]\n",
      "epoch:33 step:26292[D loss: 0.379382, acc: 68.75%, op_acc: 48.44%] [G loss: 1.166496]\n",
      "epoch:33 step:26293[D loss: 0.295321, acc: 80.47%, op_acc: 57.03%] [G loss: 1.079148]\n",
      "epoch:33 step:26294[D loss: 0.320817, acc: 75.78%, op_acc: 47.66%] [G loss: 1.268225]\n",
      "epoch:33 step:26295[D loss: 0.377905, acc: 69.53%, op_acc: 42.97%] [G loss: 1.011502]\n",
      "epoch:33 step:26296[D loss: 0.347970, acc: 75.00%, op_acc: 57.03%] [G loss: 1.213451]\n",
      "epoch:33 step:26297[D loss: 0.315807, acc: 76.56%, op_acc: 53.91%] [G loss: 0.903299]\n",
      "epoch:33 step:26298[D loss: 0.265124, acc: 89.06%, op_acc: 47.66%] [G loss: 1.176580]\n",
      "epoch:33 step:26299[D loss: 0.389985, acc: 75.00%, op_acc: 49.22%] [G loss: 1.129931]\n",
      "epoch:33 step:26300[D loss: 0.368611, acc: 72.66%, op_acc: 51.56%] [G loss: 1.003980]\n",
      "epoch:33 step:26301[D loss: 0.302671, acc: 78.12%, op_acc: 53.91%] [G loss: 0.645427]\n",
      "epoch:33 step:26302[D loss: 0.424664, acc: 56.25%, op_acc: 45.31%] [G loss: 0.716653]\n",
      "epoch:33 step:26303[D loss: 0.396644, acc: 64.06%, op_acc: 37.50%] [G loss: 1.143336]\n",
      "epoch:33 step:26304[D loss: 0.359934, acc: 75.00%, op_acc: 43.75%] [G loss: 1.346887]\n",
      "epoch:33 step:26305[D loss: 0.387514, acc: 64.06%, op_acc: 50.00%] [G loss: 1.127649]\n",
      "epoch:33 step:26306[D loss: 0.293341, acc: 82.03%, op_acc: 50.00%] [G loss: 1.047797]\n",
      "epoch:33 step:26307[D loss: 0.350904, acc: 75.00%, op_acc: 60.16%] [G loss: 1.137036]\n",
      "epoch:33 step:26308[D loss: 0.313927, acc: 82.03%, op_acc: 48.44%] [G loss: 1.108744]\n",
      "epoch:33 step:26309[D loss: 0.310892, acc: 80.47%, op_acc: 56.25%] [G loss: 1.011703]\n",
      "epoch:33 step:26310[D loss: 0.368912, acc: 74.22%, op_acc: 45.31%] [G loss: 0.904178]\n",
      "epoch:33 step:26311[D loss: 0.304291, acc: 80.47%, op_acc: 57.81%] [G loss: 1.022976]\n",
      "epoch:33 step:26312[D loss: 0.343340, acc: 75.00%, op_acc: 45.31%] [G loss: 1.191278]\n",
      "epoch:33 step:26313[D loss: 0.271527, acc: 83.59%, op_acc: 57.03%] [G loss: 1.101393]\n",
      "epoch:33 step:26314[D loss: 0.262700, acc: 86.72%, op_acc: 54.69%] [G loss: 1.019121]\n",
      "epoch:33 step:26315[D loss: 0.278464, acc: 82.81%, op_acc: 60.94%] [G loss: 1.323161]\n",
      "epoch:33 step:26316[D loss: 0.271120, acc: 85.94%, op_acc: 53.91%] [G loss: 1.426791]\n",
      "epoch:33 step:26317[D loss: 0.259320, acc: 85.94%, op_acc: 58.59%] [G loss: 1.347841]\n",
      "epoch:33 step:26318[D loss: 0.255780, acc: 81.25%, op_acc: 55.47%] [G loss: 1.028109]\n",
      "epoch:33 step:26319[D loss: 0.322846, acc: 75.00%, op_acc: 56.25%] [G loss: 0.628554]\n",
      "epoch:33 step:26320[D loss: 0.455560, acc: 59.38%, op_acc: 39.84%] [G loss: 1.357488]\n",
      "epoch:33 step:26321[D loss: 0.364197, acc: 72.66%, op_acc: 45.31%] [G loss: 1.979268]\n",
      "epoch:33 step:26322[D loss: 0.294703, acc: 85.94%, op_acc: 60.16%] [G loss: 1.948007]\n",
      "epoch:33 step:26323[D loss: 0.353079, acc: 71.09%, op_acc: 46.88%] [G loss: 1.419782]\n",
      "epoch:33 step:26324[D loss: 0.372916, acc: 64.84%, op_acc: 56.25%] [G loss: 1.273899]\n",
      "epoch:33 step:26325[D loss: 0.393829, acc: 66.41%, op_acc: 47.66%] [G loss: 1.374193]\n",
      "epoch:33 step:26326[D loss: 0.304061, acc: 78.91%, op_acc: 46.88%] [G loss: 0.985752]\n",
      "epoch:33 step:26327[D loss: 0.288829, acc: 80.47%, op_acc: 59.38%] [G loss: 1.424959]\n",
      "epoch:33 step:26328[D loss: 0.267859, acc: 82.03%, op_acc: 59.38%] [G loss: 1.378495]\n",
      "epoch:33 step:26329[D loss: 0.345031, acc: 76.56%, op_acc: 48.44%] [G loss: 1.024080]\n",
      "epoch:33 step:26330[D loss: 0.300618, acc: 81.25%, op_acc: 58.59%] [G loss: 0.878908]\n",
      "epoch:33 step:26331[D loss: 0.337060, acc: 73.44%, op_acc: 46.88%] [G loss: 0.919241]\n",
      "epoch:33 step:26332[D loss: 0.376639, acc: 71.09%, op_acc: 41.41%] [G loss: 1.157648]\n",
      "epoch:33 step:26333[D loss: 0.362637, acc: 78.12%, op_acc: 46.88%] [G loss: 1.347227]\n",
      "epoch:33 step:26334[D loss: 0.339440, acc: 73.44%, op_acc: 44.53%] [G loss: 1.216316]\n",
      "epoch:33 step:26335[D loss: 0.324844, acc: 78.91%, op_acc: 50.78%] [G loss: 1.365705]\n",
      "epoch:33 step:26336[D loss: 0.405454, acc: 65.62%, op_acc: 45.31%] [G loss: 1.536040]\n",
      "epoch:33 step:26337[D loss: 0.359471, acc: 72.66%, op_acc: 55.47%] [G loss: 1.515215]\n",
      "epoch:33 step:26338[D loss: 0.310490, acc: 78.12%, op_acc: 51.56%] [G loss: 1.240161]\n",
      "epoch:33 step:26339[D loss: 0.296687, acc: 82.81%, op_acc: 55.47%] [G loss: 1.365366]\n",
      "epoch:33 step:26340[D loss: 0.314777, acc: 79.69%, op_acc: 49.22%] [G loss: 1.261873]\n",
      "epoch:33 step:26341[D loss: 0.273255, acc: 84.38%, op_acc: 60.94%] [G loss: 1.308315]\n",
      "epoch:33 step:26342[D loss: 0.292423, acc: 82.03%, op_acc: 58.59%] [G loss: 1.200251]\n",
      "epoch:33 step:26343[D loss: 0.307073, acc: 78.91%, op_acc: 49.22%] [G loss: 1.043708]\n",
      "epoch:33 step:26344[D loss: 0.373519, acc: 74.22%, op_acc: 56.25%] [G loss: 1.295519]\n",
      "epoch:33 step:26345[D loss: 0.305143, acc: 82.81%, op_acc: 49.22%] [G loss: 1.466354]\n",
      "epoch:33 step:26346[D loss: 0.296882, acc: 84.38%, op_acc: 57.03%] [G loss: 1.310546]\n",
      "epoch:33 step:26347[D loss: 0.282160, acc: 84.38%, op_acc: 60.16%] [G loss: 1.537675]\n",
      "epoch:33 step:26348[D loss: 0.201764, acc: 93.75%, op_acc: 64.06%] [G loss: 1.538021]\n",
      "epoch:33 step:26349[D loss: 0.225549, acc: 91.41%, op_acc: 61.72%] [G loss: 1.581700]\n",
      "epoch:33 step:26350[D loss: 0.288888, acc: 83.59%, op_acc: 62.50%] [G loss: 1.794647]\n",
      "epoch:33 step:26351[D loss: 0.346933, acc: 74.22%, op_acc: 51.56%] [G loss: 1.543523]\n",
      "epoch:33 step:26352[D loss: 0.241286, acc: 85.94%, op_acc: 57.03%] [G loss: 1.867355]\n",
      "epoch:33 step:26353[D loss: 0.248006, acc: 84.38%, op_acc: 66.41%] [G loss: 1.937257]\n",
      "epoch:33 step:26354[D loss: 0.306149, acc: 81.25%, op_acc: 60.94%] [G loss: 1.873541]\n",
      "epoch:33 step:26355[D loss: 0.201369, acc: 92.97%, op_acc: 62.50%] [G loss: 2.106436]\n",
      "epoch:33 step:26356[D loss: 0.216473, acc: 92.97%, op_acc: 66.41%] [G loss: 2.346060]\n",
      "epoch:33 step:26357[D loss: 0.190553, acc: 97.66%, op_acc: 62.50%] [G loss: 2.108596]\n",
      "epoch:33 step:26358[D loss: 0.188681, acc: 92.97%, op_acc: 73.44%] [G loss: 2.379273]\n",
      "epoch:33 step:26359[D loss: 0.186013, acc: 95.31%, op_acc: 64.06%] [G loss: 0.982684]\n",
      "epoch:33 step:26360[D loss: 0.240706, acc: 88.28%, op_acc: 51.56%] [G loss: 2.413867]\n",
      "epoch:33 step:26361[D loss: 0.213297, acc: 92.19%, op_acc: 69.53%] [G loss: 2.212619]\n",
      "epoch:33 step:26362[D loss: 0.202920, acc: 92.19%, op_acc: 63.28%] [G loss: 2.344102]\n",
      "epoch:33 step:26363[D loss: 0.258348, acc: 86.72%, op_acc: 62.50%] [G loss: 2.289290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26364[D loss: 0.263745, acc: 88.28%, op_acc: 65.62%] [G loss: 2.396342]\n",
      "epoch:33 step:26365[D loss: 0.265515, acc: 84.38%, op_acc: 59.38%] [G loss: 2.124334]\n",
      "epoch:33 step:26366[D loss: 0.309890, acc: 79.69%, op_acc: 53.12%] [G loss: 2.162595]\n",
      "epoch:33 step:26367[D loss: 0.360270, acc: 73.44%, op_acc: 51.56%] [G loss: 1.930638]\n",
      "epoch:33 step:26368[D loss: 0.312145, acc: 83.59%, op_acc: 50.78%] [G loss: 1.488796]\n",
      "epoch:33 step:26369[D loss: 0.336924, acc: 76.56%, op_acc: 46.88%] [G loss: 1.321239]\n",
      "epoch:33 step:26370[D loss: 0.393570, acc: 71.09%, op_acc: 52.34%] [G loss: 1.801791]\n",
      "epoch:33 step:26371[D loss: 0.328785, acc: 78.12%, op_acc: 51.56%] [G loss: 0.822520]\n",
      "epoch:33 step:26372[D loss: 0.346096, acc: 73.44%, op_acc: 39.06%] [G loss: 2.472998]\n",
      "epoch:33 step:26373[D loss: 0.368440, acc: 72.66%, op_acc: 42.97%] [G loss: 2.914315]\n",
      "epoch:33 step:26374[D loss: 0.383915, acc: 71.88%, op_acc: 50.78%] [G loss: 2.489577]\n",
      "epoch:33 step:26375[D loss: 0.284065, acc: 81.25%, op_acc: 64.06%] [G loss: 2.567286]\n",
      "epoch:33 step:26376[D loss: 0.267572, acc: 82.81%, op_acc: 67.19%] [G loss: 2.274711]\n",
      "epoch:33 step:26377[D loss: 0.386686, acc: 74.22%, op_acc: 42.97%] [G loss: 1.934350]\n",
      "epoch:33 step:26378[D loss: 0.283192, acc: 80.47%, op_acc: 54.69%] [G loss: 2.164693]\n",
      "epoch:33 step:26379[D loss: 0.356478, acc: 74.22%, op_acc: 50.00%] [G loss: 2.153920]\n",
      "epoch:33 step:26380[D loss: 0.241853, acc: 87.50%, op_acc: 60.16%] [G loss: 1.634979]\n",
      "epoch:33 step:26381[D loss: 0.383088, acc: 70.31%, op_acc: 46.88%] [G loss: 1.413207]\n",
      "epoch:33 step:26382[D loss: 0.359419, acc: 64.84%, op_acc: 45.31%] [G loss: 0.949084]\n",
      "epoch:33 step:26383[D loss: 0.325882, acc: 77.34%, op_acc: 46.09%] [G loss: 1.036702]\n",
      "epoch:33 step:26384[D loss: 0.443729, acc: 58.59%, op_acc: 42.19%] [G loss: 1.314071]\n",
      "epoch:33 step:26385[D loss: 0.495104, acc: 51.56%, op_acc: 42.19%] [G loss: 1.314296]\n",
      "epoch:33 step:26386[D loss: 0.435344, acc: 60.94%, op_acc: 42.19%] [G loss: 1.072009]\n",
      "epoch:33 step:26387[D loss: 0.505764, acc: 50.78%, op_acc: 40.62%] [G loss: 1.123567]\n",
      "epoch:33 step:26388[D loss: 0.441200, acc: 61.72%, op_acc: 37.50%] [G loss: 1.392966]\n",
      "epoch:33 step:26389[D loss: 0.448884, acc: 59.38%, op_acc: 40.62%] [G loss: 1.206194]\n",
      "epoch:33 step:26390[D loss: 0.476984, acc: 54.69%, op_acc: 40.62%] [G loss: 1.424687]\n",
      "epoch:33 step:26391[D loss: 0.381750, acc: 65.62%, op_acc: 52.34%] [G loss: 1.277902]\n",
      "epoch:33 step:26392[D loss: 0.532447, acc: 46.09%, op_acc: 39.84%] [G loss: 1.285562]\n",
      "epoch:33 step:26393[D loss: 0.391074, acc: 67.97%, op_acc: 40.62%] [G loss: 1.506793]\n",
      "epoch:33 step:26394[D loss: 0.378391, acc: 67.19%, op_acc: 50.78%] [G loss: 1.406855]\n",
      "epoch:33 step:26395[D loss: 0.433576, acc: 61.72%, op_acc: 38.28%] [G loss: 1.204003]\n",
      "epoch:33 step:26396[D loss: 0.445256, acc: 57.03%, op_acc: 46.88%] [G loss: 1.210540]\n",
      "epoch:33 step:26397[D loss: 0.506746, acc: 53.12%, op_acc: 42.19%] [G loss: 1.456676]\n",
      "epoch:33 step:26398[D loss: 0.340637, acc: 76.56%, op_acc: 46.88%] [G loss: 1.398384]\n",
      "epoch:33 step:26399[D loss: 0.319556, acc: 75.00%, op_acc: 55.47%] [G loss: 1.570286]\n",
      "epoch:33 step:26400[D loss: 0.384584, acc: 67.19%, op_acc: 50.78%] [G loss: 1.349292]\n",
      "epoch:33 step:26401[D loss: 0.470359, acc: 55.47%, op_acc: 46.88%] [G loss: 1.249590]\n",
      "epoch:33 step:26402[D loss: 0.418407, acc: 65.62%, op_acc: 40.62%] [G loss: 1.167276]\n",
      "epoch:33 step:26403[D loss: 0.351940, acc: 76.56%, op_acc: 50.78%] [G loss: 1.386790]\n",
      "epoch:33 step:26404[D loss: 0.382154, acc: 69.53%, op_acc: 44.53%] [G loss: 1.275002]\n",
      "epoch:33 step:26405[D loss: 0.381906, acc: 72.66%, op_acc: 42.97%] [G loss: 1.228165]\n",
      "epoch:33 step:26406[D loss: 0.364166, acc: 74.22%, op_acc: 40.62%] [G loss: 1.365782]\n",
      "epoch:33 step:26407[D loss: 0.413359, acc: 66.41%, op_acc: 42.97%] [G loss: 1.269245]\n",
      "epoch:33 step:26408[D loss: 0.430459, acc: 57.03%, op_acc: 42.97%] [G loss: 1.092862]\n",
      "epoch:33 step:26409[D loss: 0.407015, acc: 60.16%, op_acc: 40.62%] [G loss: 1.293241]\n",
      "epoch:33 step:26410[D loss: 0.406658, acc: 64.06%, op_acc: 41.41%] [G loss: 1.268557]\n",
      "epoch:33 step:26411[D loss: 0.380023, acc: 69.53%, op_acc: 48.44%] [G loss: 1.332089]\n",
      "epoch:33 step:26412[D loss: 0.510466, acc: 53.91%, op_acc: 35.16%] [G loss: 1.177773]\n",
      "epoch:33 step:26413[D loss: 0.408433, acc: 63.28%, op_acc: 42.97%] [G loss: 1.332223]\n",
      "epoch:33 step:26414[D loss: 0.408963, acc: 65.62%, op_acc: 39.06%] [G loss: 1.207856]\n",
      "epoch:33 step:26415[D loss: 0.400988, acc: 64.06%, op_acc: 44.53%] [G loss: 0.825561]\n",
      "epoch:33 step:26416[D loss: 0.416994, acc: 64.84%, op_acc: 39.06%] [G loss: 0.763185]\n",
      "epoch:33 step:26417[D loss: 0.395774, acc: 63.28%, op_acc: 46.09%] [G loss: 0.997218]\n",
      "epoch:33 step:26418[D loss: 0.446230, acc: 62.50%, op_acc: 36.72%] [G loss: 0.894564]\n",
      "epoch:33 step:26419[D loss: 0.397417, acc: 67.19%, op_acc: 44.53%] [G loss: 1.377393]\n",
      "epoch:33 step:26420[D loss: 0.430634, acc: 60.16%, op_acc: 41.41%] [G loss: 1.140791]\n",
      "epoch:33 step:26421[D loss: 0.435589, acc: 61.72%, op_acc: 43.75%] [G loss: 0.945695]\n",
      "epoch:33 step:26422[D loss: 0.396408, acc: 60.94%, op_acc: 43.75%] [G loss: 1.020133]\n",
      "epoch:33 step:26423[D loss: 0.422820, acc: 64.06%, op_acc: 42.97%] [G loss: 1.302532]\n",
      "epoch:33 step:26424[D loss: 0.382918, acc: 64.84%, op_acc: 50.00%] [G loss: 1.371874]\n",
      "epoch:33 step:26425[D loss: 0.415934, acc: 60.16%, op_acc: 46.09%] [G loss: 1.173947]\n",
      "epoch:33 step:26426[D loss: 0.375656, acc: 67.97%, op_acc: 46.88%] [G loss: 0.931890]\n",
      "epoch:33 step:26427[D loss: 0.394748, acc: 66.41%, op_acc: 49.22%] [G loss: 0.917065]\n",
      "epoch:33 step:26428[D loss: 0.441317, acc: 58.59%, op_acc: 42.19%] [G loss: 1.238771]\n",
      "epoch:33 step:26429[D loss: 0.400128, acc: 64.06%, op_acc: 46.09%] [G loss: 1.084033]\n",
      "epoch:33 step:26430[D loss: 0.421450, acc: 58.59%, op_acc: 49.22%] [G loss: 1.285635]\n",
      "epoch:33 step:26431[D loss: 0.358653, acc: 71.88%, op_acc: 45.31%] [G loss: 0.876935]\n",
      "epoch:33 step:26432[D loss: 0.340853, acc: 75.78%, op_acc: 50.78%] [G loss: 0.989388]\n",
      "epoch:33 step:26433[D loss: 0.431093, acc: 59.38%, op_acc: 47.66%] [G loss: 1.066206]\n",
      "epoch:33 step:26434[D loss: 0.454207, acc: 50.00%, op_acc: 42.97%] [G loss: 1.199611]\n",
      "epoch:33 step:26435[D loss: 0.440984, acc: 56.25%, op_acc: 49.22%] [G loss: 1.258385]\n",
      "epoch:33 step:26436[D loss: 0.360211, acc: 75.78%, op_acc: 46.88%] [G loss: 1.542470]\n",
      "epoch:33 step:26437[D loss: 0.405125, acc: 64.84%, op_acc: 46.09%] [G loss: 1.432887]\n",
      "epoch:33 step:26438[D loss: 0.425215, acc: 62.50%, op_acc: 42.97%] [G loss: 1.112728]\n",
      "epoch:33 step:26439[D loss: 0.463660, acc: 57.81%, op_acc: 38.28%] [G loss: 0.904377]\n",
      "epoch:33 step:26440[D loss: 0.361835, acc: 71.09%, op_acc: 45.31%] [G loss: 1.030064]\n",
      "epoch:33 step:26441[D loss: 0.398371, acc: 63.28%, op_acc: 45.31%] [G loss: 1.535171]\n",
      "epoch:33 step:26442[D loss: 0.345581, acc: 73.44%, op_acc: 45.31%] [G loss: 0.974309]\n",
      "epoch:33 step:26443[D loss: 0.376534, acc: 65.62%, op_acc: 50.78%] [G loss: 1.105977]\n",
      "epoch:33 step:26444[D loss: 0.467317, acc: 60.16%, op_acc: 37.50%] [G loss: 1.307713]\n",
      "epoch:33 step:26445[D loss: 0.383198, acc: 75.78%, op_acc: 39.06%] [G loss: 1.350055]\n",
      "epoch:33 step:26446[D loss: 0.375301, acc: 69.53%, op_acc: 46.88%] [G loss: 1.300308]\n",
      "epoch:33 step:26447[D loss: 0.414483, acc: 60.94%, op_acc: 50.00%] [G loss: 0.954492]\n",
      "epoch:33 step:26448[D loss: 0.333591, acc: 71.88%, op_acc: 52.34%] [G loss: 0.992517]\n",
      "epoch:33 step:26449[D loss: 0.373049, acc: 73.44%, op_acc: 42.97%] [G loss: 1.038062]\n",
      "epoch:33 step:26450[D loss: 0.399874, acc: 69.53%, op_acc: 39.84%] [G loss: 1.073239]\n",
      "epoch:33 step:26451[D loss: 0.419301, acc: 65.62%, op_acc: 39.06%] [G loss: 0.916822]\n",
      "epoch:33 step:26452[D loss: 0.315427, acc: 79.69%, op_acc: 52.34%] [G loss: 1.129214]\n",
      "epoch:33 step:26453[D loss: 0.330515, acc: 75.78%, op_acc: 44.53%] [G loss: 1.323001]\n",
      "epoch:33 step:26454[D loss: 0.472800, acc: 54.69%, op_acc: 35.16%] [G loss: 1.262178]\n",
      "epoch:33 step:26455[D loss: 0.314581, acc: 75.78%, op_acc: 53.12%] [G loss: 1.143170]\n",
      "epoch:33 step:26456[D loss: 0.328300, acc: 70.31%, op_acc: 46.09%] [G loss: 1.082647]\n",
      "epoch:33 step:26457[D loss: 0.345786, acc: 74.22%, op_acc: 46.09%] [G loss: 1.155164]\n",
      "epoch:33 step:26458[D loss: 0.337539, acc: 76.56%, op_acc: 45.31%] [G loss: 1.098266]\n",
      "epoch:33 step:26459[D loss: 0.454129, acc: 56.25%, op_acc: 45.31%] [G loss: 1.096248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:26460[D loss: 0.280700, acc: 85.16%, op_acc: 51.56%] [G loss: 1.200531]\n",
      "epoch:33 step:26461[D loss: 0.348726, acc: 68.75%, op_acc: 57.81%] [G loss: 0.974613]\n",
      "epoch:33 step:26462[D loss: 0.430341, acc: 56.25%, op_acc: 48.44%] [G loss: 1.173599]\n",
      "epoch:33 step:26463[D loss: 0.373934, acc: 67.97%, op_acc: 44.53%] [G loss: 1.333992]\n",
      "epoch:33 step:26464[D loss: 0.315817, acc: 78.12%, op_acc: 49.22%] [G loss: 1.814369]\n",
      "epoch:33 step:26465[D loss: 0.487931, acc: 54.69%, op_acc: 49.22%] [G loss: 1.184300]\n",
      "epoch:33 step:26466[D loss: 0.376833, acc: 71.88%, op_acc: 46.88%] [G loss: 1.039807]\n",
      "epoch:33 step:26467[D loss: 0.402112, acc: 67.97%, op_acc: 47.66%] [G loss: 1.005323]\n",
      "epoch:33 step:26468[D loss: 0.306931, acc: 78.91%, op_acc: 50.00%] [G loss: 1.205380]\n",
      "epoch:33 step:26469[D loss: 0.368163, acc: 73.44%, op_acc: 47.66%] [G loss: 1.475095]\n",
      "epoch:33 step:26470[D loss: 0.416594, acc: 67.19%, op_acc: 48.44%] [G loss: 1.247525]\n",
      "epoch:33 step:26471[D loss: 0.329892, acc: 82.03%, op_acc: 51.56%] [G loss: 1.189571]\n",
      "epoch:33 step:26472[D loss: 0.318339, acc: 81.25%, op_acc: 52.34%] [G loss: 1.536855]\n",
      "epoch:33 step:26473[D loss: 0.395063, acc: 70.31%, op_acc: 42.97%] [G loss: 1.284517]\n",
      "epoch:33 step:26474[D loss: 0.288788, acc: 83.59%, op_acc: 49.22%] [G loss: 1.198420]\n",
      "epoch:33 step:26475[D loss: 0.397154, acc: 64.84%, op_acc: 51.56%] [G loss: 1.470690]\n",
      "epoch:33 step:26476[D loss: 0.338127, acc: 71.88%, op_acc: 53.12%] [G loss: 1.213770]\n",
      "epoch:33 step:26477[D loss: 0.336137, acc: 76.56%, op_acc: 53.91%] [G loss: 1.358484]\n",
      "epoch:33 step:26478[D loss: 0.330234, acc: 74.22%, op_acc: 50.78%] [G loss: 0.643998]\n",
      "epoch:33 step:26479[D loss: 0.431339, acc: 60.94%, op_acc: 41.41%] [G loss: 1.654145]\n",
      "epoch:33 step:26480[D loss: 0.368171, acc: 69.53%, op_acc: 47.66%] [G loss: 1.545098]\n",
      "epoch:33 step:26481[D loss: 0.423616, acc: 63.28%, op_acc: 42.19%] [G loss: 1.075447]\n",
      "epoch:33 step:26482[D loss: 0.400412, acc: 68.75%, op_acc: 40.62%] [G loss: 1.521723]\n",
      "epoch:33 step:26483[D loss: 0.471305, acc: 55.47%, op_acc: 42.97%] [G loss: 1.392319]\n",
      "epoch:33 step:26484[D loss: 0.423183, acc: 64.84%, op_acc: 40.62%] [G loss: 1.375966]\n",
      "epoch:33 step:26485[D loss: 0.426022, acc: 58.59%, op_acc: 44.53%] [G loss: 1.585898]\n",
      "epoch:33 step:26486[D loss: 0.424383, acc: 63.28%, op_acc: 42.19%] [G loss: 1.055533]\n",
      "epoch:33 step:26487[D loss: 0.424059, acc: 67.19%, op_acc: 36.72%] [G loss: 1.661961]\n",
      "epoch:33 step:26488[D loss: 0.380174, acc: 64.84%, op_acc: 42.97%] [G loss: 1.544342]\n",
      "epoch:33 step:26489[D loss: 0.405792, acc: 61.72%, op_acc: 42.97%] [G loss: 1.216644]\n",
      "epoch:33 step:26490[D loss: 0.324274, acc: 76.56%, op_acc: 52.34%] [G loss: 1.523908]\n",
      "epoch:33 step:26491[D loss: 0.397504, acc: 65.62%, op_acc: 45.31%] [G loss: 1.422077]\n",
      "epoch:33 step:26492[D loss: 0.417184, acc: 66.41%, op_acc: 50.78%] [G loss: 1.494028]\n",
      "epoch:33 step:26493[D loss: 0.393999, acc: 71.09%, op_acc: 45.31%] [G loss: 1.129719]\n",
      "epoch:33 step:26494[D loss: 0.369277, acc: 67.97%, op_acc: 43.75%] [G loss: 1.198014]\n",
      "epoch:33 step:26495[D loss: 0.397830, acc: 65.62%, op_acc: 43.75%] [G loss: 1.035852]\n",
      "epoch:33 step:26496[D loss: 0.368851, acc: 71.09%, op_acc: 44.53%] [G loss: 1.018945]\n",
      "epoch:33 step:26497[D loss: 0.465742, acc: 55.47%, op_acc: 37.50%] [G loss: 1.272382]\n",
      "epoch:33 step:26498[D loss: 0.369888, acc: 72.66%, op_acc: 46.09%] [G loss: 1.415808]\n",
      "epoch:33 step:26499[D loss: 0.310932, acc: 78.91%, op_acc: 42.19%] [G loss: 1.146176]\n",
      "epoch:33 step:26500[D loss: 0.423607, acc: 64.06%, op_acc: 40.62%] [G loss: 1.482497]\n",
      "epoch:33 step:26501[D loss: 0.364050, acc: 69.53%, op_acc: 47.66%] [G loss: 1.058478]\n",
      "epoch:33 step:26502[D loss: 0.320301, acc: 71.88%, op_acc: 51.56%] [G loss: 1.186727]\n",
      "epoch:33 step:26503[D loss: 0.369336, acc: 64.84%, op_acc: 48.44%] [G loss: 1.131346]\n",
      "epoch:33 step:26504[D loss: 0.319586, acc: 73.44%, op_acc: 47.66%] [G loss: 1.085289]\n",
      "epoch:33 step:26505[D loss: 0.437177, acc: 58.59%, op_acc: 43.75%] [G loss: 1.072101]\n",
      "epoch:33 step:26506[D loss: 0.366188, acc: 72.66%, op_acc: 43.75%] [G loss: 1.094033]\n",
      "epoch:33 step:26507[D loss: 0.446816, acc: 64.06%, op_acc: 42.19%] [G loss: 1.119099]\n",
      "epoch:33 step:26508[D loss: 0.428264, acc: 64.84%, op_acc: 41.41%] [G loss: 1.260462]\n",
      "epoch:33 step:26509[D loss: 0.433678, acc: 63.28%, op_acc: 45.31%] [G loss: 1.209463]\n",
      "epoch:33 step:26510[D loss: 0.415540, acc: 58.59%, op_acc: 46.09%] [G loss: 1.347418]\n",
      "epoch:33 step:26511[D loss: 0.480239, acc: 57.03%, op_acc: 37.50%] [G loss: 0.991860]\n",
      "epoch:33 step:26512[D loss: 0.344445, acc: 74.22%, op_acc: 49.22%] [G loss: 1.238273]\n",
      "epoch:33 step:26513[D loss: 0.426598, acc: 60.94%, op_acc: 49.22%] [G loss: 0.840182]\n",
      "epoch:33 step:26514[D loss: 0.367195, acc: 75.78%, op_acc: 39.84%] [G loss: 1.009671]\n",
      "epoch:33 step:26515[D loss: 0.377720, acc: 68.75%, op_acc: 42.19%] [G loss: 1.275633]\n",
      "epoch:33 step:26516[D loss: 0.371120, acc: 72.66%, op_acc: 37.50%] [G loss: 0.840491]\n",
      "epoch:33 step:26517[D loss: 0.368543, acc: 67.19%, op_acc: 52.34%] [G loss: 0.854925]\n",
      "epoch:33 step:26518[D loss: 0.362638, acc: 75.78%, op_acc: 40.62%] [G loss: 0.742932]\n",
      "epoch:33 step:26519[D loss: 0.395294, acc: 67.97%, op_acc: 42.19%] [G loss: 1.154495]\n",
      "epoch:33 step:26520[D loss: 0.325784, acc: 78.12%, op_acc: 49.22%] [G loss: 0.947325]\n",
      "epoch:33 step:26521[D loss: 0.445951, acc: 67.97%, op_acc: 43.75%] [G loss: 1.129667]\n",
      "epoch:33 step:26522[D loss: 0.417662, acc: 64.06%, op_acc: 46.09%] [G loss: 1.474484]\n",
      "epoch:33 step:26523[D loss: 0.416317, acc: 60.94%, op_acc: 43.75%] [G loss: 1.192431]\n",
      "epoch:33 step:26524[D loss: 0.386255, acc: 72.66%, op_acc: 39.06%] [G loss: 0.860263]\n",
      "epoch:33 step:26525[D loss: 0.372166, acc: 67.97%, op_acc: 46.88%] [G loss: 0.849798]\n",
      "epoch:33 step:26526[D loss: 0.425532, acc: 60.94%, op_acc: 46.88%] [G loss: 0.889241]\n",
      "epoch:33 step:26527[D loss: 0.337614, acc: 74.22%, op_acc: 49.22%] [G loss: 1.084619]\n",
      "epoch:33 step:26528[D loss: 0.311734, acc: 79.69%, op_acc: 43.75%] [G loss: 1.158114]\n",
      "epoch:33 step:26529[D loss: 0.333636, acc: 71.09%, op_acc: 57.81%] [G loss: 1.013684]\n",
      "epoch:33 step:26530[D loss: 0.313061, acc: 80.47%, op_acc: 47.66%] [G loss: 1.034133]\n",
      "epoch:33 step:26531[D loss: 0.341499, acc: 71.88%, op_acc: 45.31%] [G loss: 1.284160]\n",
      "epoch:33 step:26532[D loss: 0.291413, acc: 82.03%, op_acc: 51.56%] [G loss: 1.257979]\n",
      "epoch:33 step:26533[D loss: 0.368356, acc: 74.22%, op_acc: 47.66%] [G loss: 1.190387]\n",
      "epoch:33 step:26534[D loss: 0.260909, acc: 89.84%, op_acc: 52.34%] [G loss: 0.762946]\n",
      "epoch:33 step:26535[D loss: 0.329140, acc: 74.22%, op_acc: 48.44%] [G loss: 1.184933]\n",
      "epoch:33 step:26536[D loss: 0.348704, acc: 75.00%, op_acc: 46.88%] [G loss: 1.097706]\n",
      "epoch:33 step:26537[D loss: 0.409020, acc: 66.41%, op_acc: 46.09%] [G loss: 0.909453]\n",
      "epoch:33 step:26538[D loss: 0.392581, acc: 66.41%, op_acc: 42.97%] [G loss: 1.034507]\n",
      "epoch:33 step:26539[D loss: 0.388219, acc: 62.50%, op_acc: 39.84%] [G loss: 1.081247]\n",
      "epoch:33 step:26540[D loss: 0.360702, acc: 64.06%, op_acc: 47.66%] [G loss: 1.143498]\n",
      "epoch:33 step:26541[D loss: 0.386007, acc: 68.75%, op_acc: 50.78%] [G loss: 1.141230]\n",
      "epoch:33 step:26542[D loss: 0.315270, acc: 75.00%, op_acc: 53.91%] [G loss: 1.171447]\n",
      "epoch:33 step:26543[D loss: 0.382609, acc: 68.75%, op_acc: 51.56%] [G loss: 1.108842]\n",
      "epoch:33 step:26544[D loss: 0.472008, acc: 63.28%, op_acc: 39.06%] [G loss: 0.784241]\n",
      "epoch:33 step:26545[D loss: 0.430694, acc: 62.50%, op_acc: 43.75%] [G loss: 1.103542]\n",
      "epoch:33 step:26546[D loss: 0.446993, acc: 54.69%, op_acc: 36.72%] [G loss: 1.143709]\n",
      "epoch:33 step:26547[D loss: 0.336745, acc: 71.88%, op_acc: 43.75%] [G loss: 1.247716]\n",
      "epoch:33 step:26548[D loss: 0.495927, acc: 57.81%, op_acc: 37.50%] [G loss: 1.268119]\n",
      "epoch:33 step:26549[D loss: 0.378693, acc: 67.19%, op_acc: 50.78%] [G loss: 1.268076]\n",
      "epoch:33 step:26550[D loss: 0.423923, acc: 62.50%, op_acc: 44.53%] [G loss: 0.928211]\n",
      "epoch:33 step:26551[D loss: 0.410538, acc: 62.50%, op_acc: 42.97%] [G loss: 1.204306]\n",
      "epoch:33 step:26552[D loss: 0.411453, acc: 60.16%, op_acc: 45.31%] [G loss: 1.094223]\n",
      "epoch:33 step:26553[D loss: 0.357385, acc: 70.31%, op_acc: 57.03%] [G loss: 1.112859]\n",
      "epoch:33 step:26554[D loss: 0.359314, acc: 72.66%, op_acc: 42.19%] [G loss: 1.367586]\n",
      "epoch:34 step:26555[D loss: 0.349659, acc: 75.00%, op_acc: 50.00%] [G loss: 1.114842]\n",
      "epoch:34 step:26556[D loss: 0.388614, acc: 63.28%, op_acc: 45.31%] [G loss: 1.123019]\n",
      "epoch:34 step:26557[D loss: 0.382782, acc: 69.53%, op_acc: 46.09%] [G loss: 0.942529]\n",
      "epoch:34 step:26558[D loss: 0.399594, acc: 63.28%, op_acc: 45.31%] [G loss: 0.892518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26559[D loss: 0.355165, acc: 72.66%, op_acc: 48.44%] [G loss: 1.037155]\n",
      "epoch:34 step:26560[D loss: 0.399417, acc: 64.06%, op_acc: 48.44%] [G loss: 0.872667]\n",
      "epoch:34 step:26561[D loss: 0.440821, acc: 60.16%, op_acc: 35.94%] [G loss: 1.407314]\n",
      "epoch:34 step:26562[D loss: 0.478221, acc: 51.56%, op_acc: 40.62%] [G loss: 1.147065]\n",
      "epoch:34 step:26563[D loss: 0.408382, acc: 60.94%, op_acc: 46.09%] [G loss: 1.271923]\n",
      "epoch:34 step:26564[D loss: 0.398898, acc: 69.53%, op_acc: 36.72%] [G loss: 0.843523]\n",
      "epoch:34 step:26565[D loss: 0.389336, acc: 68.75%, op_acc: 39.84%] [G loss: 1.258125]\n",
      "epoch:34 step:26566[D loss: 0.316534, acc: 79.69%, op_acc: 45.31%] [G loss: 1.308918]\n",
      "epoch:34 step:26567[D loss: 0.324324, acc: 77.34%, op_acc: 46.88%] [G loss: 0.934160]\n",
      "epoch:34 step:26568[D loss: 0.397263, acc: 70.31%, op_acc: 42.97%] [G loss: 1.091511]\n",
      "epoch:34 step:26569[D loss: 0.340639, acc: 73.44%, op_acc: 47.66%] [G loss: 0.963374]\n",
      "epoch:34 step:26570[D loss: 0.345484, acc: 67.19%, op_acc: 53.91%] [G loss: 0.766189]\n",
      "epoch:34 step:26571[D loss: 0.368760, acc: 72.66%, op_acc: 53.91%] [G loss: 0.997620]\n",
      "epoch:34 step:26572[D loss: 0.325398, acc: 78.12%, op_acc: 56.25%] [G loss: 1.158297]\n",
      "epoch:34 step:26573[D loss: 0.349434, acc: 74.22%, op_acc: 50.78%] [G loss: 0.799242]\n",
      "epoch:34 step:26574[D loss: 0.354009, acc: 75.78%, op_acc: 42.19%] [G loss: 0.730488]\n",
      "epoch:34 step:26575[D loss: 0.347275, acc: 78.91%, op_acc: 41.41%] [G loss: 0.921664]\n",
      "epoch:34 step:26576[D loss: 0.391716, acc: 64.06%, op_acc: 48.44%] [G loss: 0.854273]\n",
      "epoch:34 step:26577[D loss: 0.358724, acc: 71.88%, op_acc: 53.12%] [G loss: 1.194394]\n",
      "epoch:34 step:26578[D loss: 0.337348, acc: 75.78%, op_acc: 42.97%] [G loss: 0.996780]\n",
      "epoch:34 step:26579[D loss: 0.426563, acc: 57.03%, op_acc: 46.88%] [G loss: 1.178956]\n",
      "epoch:34 step:26580[D loss: 0.423220, acc: 60.94%, op_acc: 43.75%] [G loss: 1.119737]\n",
      "epoch:34 step:26581[D loss: 0.399561, acc: 64.06%, op_acc: 42.97%] [G loss: 0.998124]\n",
      "epoch:34 step:26582[D loss: 0.369616, acc: 73.44%, op_acc: 47.66%] [G loss: 1.124674]\n",
      "epoch:34 step:26583[D loss: 0.439969, acc: 57.81%, op_acc: 47.66%] [G loss: 0.960386]\n",
      "epoch:34 step:26584[D loss: 0.412775, acc: 64.06%, op_acc: 44.53%] [G loss: 1.304234]\n",
      "epoch:34 step:26585[D loss: 0.420525, acc: 63.28%, op_acc: 41.41%] [G loss: 0.851897]\n",
      "epoch:34 step:26586[D loss: 0.391096, acc: 66.41%, op_acc: 46.09%] [G loss: 1.282622]\n",
      "epoch:34 step:26587[D loss: 0.355812, acc: 69.53%, op_acc: 45.31%] [G loss: 0.864513]\n",
      "epoch:34 step:26588[D loss: 0.360472, acc: 71.09%, op_acc: 48.44%] [G loss: 1.089742]\n",
      "epoch:34 step:26589[D loss: 0.395900, acc: 65.62%, op_acc: 47.66%] [G loss: 0.847104]\n",
      "epoch:34 step:26590[D loss: 0.289473, acc: 81.25%, op_acc: 53.12%] [G loss: 0.868505]\n",
      "epoch:34 step:26591[D loss: 0.325405, acc: 70.31%, op_acc: 57.81%] [G loss: 1.018486]\n",
      "epoch:34 step:26592[D loss: 0.368679, acc: 75.78%, op_acc: 44.53%] [G loss: 0.901803]\n",
      "epoch:34 step:26593[D loss: 0.293744, acc: 81.25%, op_acc: 58.59%] [G loss: 1.046947]\n",
      "epoch:34 step:26594[D loss: 0.353036, acc: 75.78%, op_acc: 46.09%] [G loss: 0.873893]\n",
      "epoch:34 step:26595[D loss: 0.303245, acc: 78.91%, op_acc: 57.03%] [G loss: 1.260083]\n",
      "epoch:34 step:26596[D loss: 0.314382, acc: 75.00%, op_acc: 50.00%] [G loss: 1.041267]\n",
      "epoch:34 step:26597[D loss: 0.441254, acc: 63.28%, op_acc: 45.31%] [G loss: 1.160372]\n",
      "epoch:34 step:26598[D loss: 0.279852, acc: 82.81%, op_acc: 55.47%] [G loss: 0.959823]\n",
      "epoch:34 step:26599[D loss: 0.342157, acc: 76.56%, op_acc: 45.31%] [G loss: 1.010552]\n",
      "epoch:34 step:26600[D loss: 0.354368, acc: 75.78%, op_acc: 40.62%] [G loss: 1.237448]\n",
      "epoch:34 step:26601[D loss: 0.372403, acc: 66.41%, op_acc: 46.88%] [G loss: 1.447780]\n",
      "epoch:34 step:26602[D loss: 0.393232, acc: 67.19%, op_acc: 43.75%] [G loss: 1.164787]\n",
      "epoch:34 step:26603[D loss: 0.274611, acc: 85.16%, op_acc: 55.47%] [G loss: 0.970912]\n",
      "epoch:34 step:26604[D loss: 0.375464, acc: 74.22%, op_acc: 46.88%] [G loss: 1.295058]\n",
      "epoch:34 step:26605[D loss: 0.284238, acc: 81.25%, op_acc: 54.69%] [G loss: 1.173725]\n",
      "epoch:34 step:26606[D loss: 0.407790, acc: 67.19%, op_acc: 37.50%] [G loss: 1.047898]\n",
      "epoch:34 step:26607[D loss: 0.361402, acc: 69.53%, op_acc: 53.91%] [G loss: 1.235572]\n",
      "epoch:34 step:26608[D loss: 0.362808, acc: 75.00%, op_acc: 55.47%] [G loss: 1.104962]\n",
      "epoch:34 step:26609[D loss: 0.379563, acc: 66.41%, op_acc: 46.88%] [G loss: 1.239682]\n",
      "epoch:34 step:26610[D loss: 0.287815, acc: 84.38%, op_acc: 46.88%] [G loss: 1.157592]\n",
      "epoch:34 step:26611[D loss: 0.387299, acc: 67.97%, op_acc: 46.88%] [G loss: 1.069957]\n",
      "epoch:34 step:26612[D loss: 0.311463, acc: 77.34%, op_acc: 50.00%] [G loss: 1.296700]\n",
      "epoch:34 step:26613[D loss: 0.301684, acc: 82.81%, op_acc: 46.09%] [G loss: 1.124756]\n",
      "epoch:34 step:26614[D loss: 0.257798, acc: 88.28%, op_acc: 53.91%] [G loss: 1.461456]\n",
      "epoch:34 step:26615[D loss: 0.279705, acc: 85.16%, op_acc: 52.34%] [G loss: 1.325361]\n",
      "epoch:34 step:26616[D loss: 0.290659, acc: 84.38%, op_acc: 54.69%] [G loss: 1.345399]\n",
      "epoch:34 step:26617[D loss: 0.330945, acc: 76.56%, op_acc: 53.12%] [G loss: 0.836284]\n",
      "epoch:34 step:26618[D loss: 0.231742, acc: 89.06%, op_acc: 53.91%] [G loss: 1.041445]\n",
      "epoch:34 step:26619[D loss: 0.268238, acc: 86.72%, op_acc: 55.47%] [G loss: 0.655771]\n",
      "epoch:34 step:26620[D loss: 0.438635, acc: 58.59%, op_acc: 35.94%] [G loss: 1.380790]\n",
      "epoch:34 step:26621[D loss: 0.348719, acc: 72.66%, op_acc: 39.06%] [G loss: 1.245529]\n",
      "epoch:34 step:26622[D loss: 0.349915, acc: 71.09%, op_acc: 46.88%] [G loss: 1.127734]\n",
      "epoch:34 step:26623[D loss: 0.376606, acc: 64.84%, op_acc: 47.66%] [G loss: 1.268330]\n",
      "epoch:34 step:26624[D loss: 0.490980, acc: 55.47%, op_acc: 36.72%] [G loss: 1.367279]\n",
      "epoch:34 step:26625[D loss: 0.433456, acc: 60.94%, op_acc: 35.94%] [G loss: 1.424224]\n",
      "epoch:34 step:26626[D loss: 0.349009, acc: 74.22%, op_acc: 44.53%] [G loss: 1.287593]\n",
      "epoch:34 step:26627[D loss: 0.348662, acc: 73.44%, op_acc: 47.66%] [G loss: 1.410553]\n",
      "epoch:34 step:26628[D loss: 0.319980, acc: 78.91%, op_acc: 46.09%] [G loss: 1.424810]\n",
      "epoch:34 step:26629[D loss: 0.372182, acc: 71.09%, op_acc: 47.66%] [G loss: 1.377223]\n",
      "epoch:34 step:26630[D loss: 0.373456, acc: 68.75%, op_acc: 51.56%] [G loss: 1.195366]\n",
      "epoch:34 step:26631[D loss: 0.397932, acc: 67.19%, op_acc: 45.31%] [G loss: 1.280742]\n",
      "epoch:34 step:26632[D loss: 0.338183, acc: 75.00%, op_acc: 42.19%] [G loss: 0.917046]\n",
      "epoch:34 step:26633[D loss: 0.315125, acc: 74.22%, op_acc: 50.00%] [G loss: 1.300664]\n",
      "epoch:34 step:26634[D loss: 0.405601, acc: 69.53%, op_acc: 42.97%] [G loss: 1.354361]\n",
      "epoch:34 step:26635[D loss: 0.439158, acc: 60.94%, op_acc: 41.41%] [G loss: 1.222118]\n",
      "epoch:34 step:26636[D loss: 0.383279, acc: 64.06%, op_acc: 46.88%] [G loss: 1.378045]\n",
      "epoch:34 step:26637[D loss: 0.319744, acc: 80.47%, op_acc: 47.66%] [G loss: 1.266522]\n",
      "epoch:34 step:26638[D loss: 0.354741, acc: 71.88%, op_acc: 50.00%] [G loss: 1.223107]\n",
      "epoch:34 step:26639[D loss: 0.349966, acc: 79.69%, op_acc: 50.78%] [G loss: 1.242758]\n",
      "epoch:34 step:26640[D loss: 0.300983, acc: 79.69%, op_acc: 52.34%] [G loss: 1.413184]\n",
      "epoch:34 step:26641[D loss: 0.341109, acc: 71.88%, op_acc: 47.66%] [G loss: 1.249527]\n",
      "epoch:34 step:26642[D loss: 0.340603, acc: 78.12%, op_acc: 41.41%] [G loss: 1.518672]\n",
      "epoch:34 step:26643[D loss: 0.448204, acc: 62.50%, op_acc: 46.09%] [G loss: 1.180524]\n",
      "epoch:34 step:26644[D loss: 0.416783, acc: 64.06%, op_acc: 45.31%] [G loss: 1.116834]\n",
      "epoch:34 step:26645[D loss: 0.369643, acc: 70.31%, op_acc: 43.75%] [G loss: 1.183098]\n",
      "epoch:34 step:26646[D loss: 0.404129, acc: 67.97%, op_acc: 43.75%] [G loss: 1.146754]\n",
      "epoch:34 step:26647[D loss: 0.379503, acc: 67.97%, op_acc: 46.88%] [G loss: 1.082815]\n",
      "epoch:34 step:26648[D loss: 0.358961, acc: 68.75%, op_acc: 44.53%] [G loss: 1.313453]\n",
      "epoch:34 step:26649[D loss: 0.362970, acc: 71.09%, op_acc: 49.22%] [G loss: 1.407921]\n",
      "epoch:34 step:26650[D loss: 0.380550, acc: 71.09%, op_acc: 45.31%] [G loss: 1.163159]\n",
      "epoch:34 step:26651[D loss: 0.381095, acc: 63.28%, op_acc: 46.88%] [G loss: 1.223939]\n",
      "epoch:34 step:26652[D loss: 0.311188, acc: 80.47%, op_acc: 42.97%] [G loss: 1.283934]\n",
      "epoch:34 step:26653[D loss: 0.406876, acc: 60.16%, op_acc: 47.66%] [G loss: 0.867517]\n",
      "epoch:34 step:26654[D loss: 0.400932, acc: 65.62%, op_acc: 42.97%] [G loss: 0.726507]\n",
      "epoch:34 step:26655[D loss: 0.330408, acc: 76.56%, op_acc: 55.47%] [G loss: 1.337189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26656[D loss: 0.383569, acc: 68.75%, op_acc: 46.09%] [G loss: 0.918737]\n",
      "epoch:34 step:26657[D loss: 0.471539, acc: 52.34%, op_acc: 39.06%] [G loss: 1.047830]\n",
      "epoch:34 step:26658[D loss: 0.325084, acc: 78.12%, op_acc: 46.88%] [G loss: 1.059798]\n",
      "epoch:34 step:26659[D loss: 0.384038, acc: 67.19%, op_acc: 45.31%] [G loss: 1.303179]\n",
      "epoch:34 step:26660[D loss: 0.347322, acc: 72.66%, op_acc: 46.88%] [G loss: 0.867514]\n",
      "epoch:34 step:26661[D loss: 0.437185, acc: 59.38%, op_acc: 42.97%] [G loss: 1.465484]\n",
      "epoch:34 step:26662[D loss: 0.504631, acc: 60.94%, op_acc: 43.75%] [G loss: 1.526768]\n",
      "epoch:34 step:26663[D loss: 0.350868, acc: 69.53%, op_acc: 47.66%] [G loss: 1.058175]\n",
      "epoch:34 step:26664[D loss: 0.386405, acc: 66.41%, op_acc: 44.53%] [G loss: 1.126583]\n",
      "epoch:34 step:26665[D loss: 0.411204, acc: 64.84%, op_acc: 42.19%] [G loss: 1.366424]\n",
      "epoch:34 step:26666[D loss: 0.356120, acc: 71.88%, op_acc: 48.44%] [G loss: 1.000735]\n",
      "epoch:34 step:26667[D loss: 0.388140, acc: 63.28%, op_acc: 44.53%] [G loss: 1.052254]\n",
      "epoch:34 step:26668[D loss: 0.359079, acc: 67.97%, op_acc: 48.44%] [G loss: 1.073992]\n",
      "epoch:34 step:26669[D loss: 0.337029, acc: 72.66%, op_acc: 48.44%] [G loss: 0.917625]\n",
      "epoch:34 step:26670[D loss: 0.449509, acc: 57.81%, op_acc: 46.88%] [G loss: 0.673593]\n",
      "epoch:34 step:26671[D loss: 0.392740, acc: 67.19%, op_acc: 42.97%] [G loss: 1.024935]\n",
      "epoch:34 step:26672[D loss: 0.402328, acc: 61.72%, op_acc: 44.53%] [G loss: 1.084099]\n",
      "epoch:34 step:26673[D loss: 0.386771, acc: 67.97%, op_acc: 45.31%] [G loss: 1.246615]\n",
      "epoch:34 step:26674[D loss: 0.417457, acc: 70.31%, op_acc: 48.44%] [G loss: 1.122737]\n",
      "epoch:34 step:26675[D loss: 0.363620, acc: 71.09%, op_acc: 50.78%] [G loss: 1.402693]\n",
      "epoch:34 step:26676[D loss: 0.413271, acc: 66.41%, op_acc: 39.84%] [G loss: 1.124558]\n",
      "epoch:34 step:26677[D loss: 0.449710, acc: 60.94%, op_acc: 43.75%] [G loss: 0.934145]\n",
      "epoch:34 step:26678[D loss: 0.464858, acc: 53.91%, op_acc: 42.97%] [G loss: 0.891247]\n",
      "epoch:34 step:26679[D loss: 0.437043, acc: 60.16%, op_acc: 39.84%] [G loss: 1.155636]\n",
      "epoch:34 step:26680[D loss: 0.348061, acc: 74.22%, op_acc: 48.44%] [G loss: 1.156921]\n",
      "epoch:34 step:26681[D loss: 0.369104, acc: 70.31%, op_acc: 45.31%] [G loss: 0.864233]\n",
      "epoch:34 step:26682[D loss: 0.319793, acc: 78.91%, op_acc: 51.56%] [G loss: 1.028923]\n",
      "epoch:34 step:26683[D loss: 0.400936, acc: 66.41%, op_acc: 42.19%] [G loss: 1.114478]\n",
      "epoch:34 step:26684[D loss: 0.370525, acc: 73.44%, op_acc: 43.75%] [G loss: 1.120913]\n",
      "epoch:34 step:26685[D loss: 0.349222, acc: 72.66%, op_acc: 43.75%] [G loss: 0.999536]\n",
      "epoch:34 step:26686[D loss: 0.293325, acc: 79.69%, op_acc: 55.47%] [G loss: 0.944319]\n",
      "epoch:34 step:26687[D loss: 0.432428, acc: 60.94%, op_acc: 39.84%] [G loss: 1.246025]\n",
      "epoch:34 step:26688[D loss: 0.371319, acc: 71.88%, op_acc: 43.75%] [G loss: 1.012444]\n",
      "epoch:34 step:26689[D loss: 0.408724, acc: 60.16%, op_acc: 46.09%] [G loss: 0.880597]\n",
      "epoch:34 step:26690[D loss: 0.343958, acc: 75.78%, op_acc: 49.22%] [G loss: 1.184510]\n",
      "epoch:34 step:26691[D loss: 0.425121, acc: 59.38%, op_acc: 42.97%] [G loss: 0.996987]\n",
      "epoch:34 step:26692[D loss: 0.367336, acc: 71.09%, op_acc: 51.56%] [G loss: 0.878689]\n",
      "epoch:34 step:26693[D loss: 0.429992, acc: 59.38%, op_acc: 46.09%] [G loss: 0.837803]\n",
      "epoch:34 step:26694[D loss: 0.391056, acc: 64.84%, op_acc: 48.44%] [G loss: 0.710449]\n",
      "epoch:34 step:26695[D loss: 0.366263, acc: 75.78%, op_acc: 46.88%] [G loss: 1.108758]\n",
      "epoch:34 step:26696[D loss: 0.344174, acc: 75.00%, op_acc: 50.00%] [G loss: 1.164371]\n",
      "epoch:34 step:26697[D loss: 0.361831, acc: 71.09%, op_acc: 45.31%] [G loss: 0.825455]\n",
      "epoch:34 step:26698[D loss: 0.413327, acc: 63.28%, op_acc: 45.31%] [G loss: 0.718379]\n",
      "epoch:34 step:26699[D loss: 0.369941, acc: 75.00%, op_acc: 44.53%] [G loss: 1.150295]\n",
      "epoch:34 step:26700[D loss: 0.300717, acc: 85.16%, op_acc: 53.12%] [G loss: 0.764659]\n",
      "epoch:34 step:26701[D loss: 0.343473, acc: 71.88%, op_acc: 45.31%] [G loss: 1.080579]\n",
      "epoch:34 step:26702[D loss: 0.373949, acc: 70.31%, op_acc: 49.22%] [G loss: 0.903834]\n",
      "epoch:34 step:26703[D loss: 0.339894, acc: 72.66%, op_acc: 56.25%] [G loss: 0.597160]\n",
      "epoch:34 step:26704[D loss: 0.385369, acc: 67.19%, op_acc: 42.19%] [G loss: 0.854398]\n",
      "epoch:34 step:26705[D loss: 0.368664, acc: 71.88%, op_acc: 46.09%] [G loss: 1.032420]\n",
      "epoch:34 step:26706[D loss: 0.364194, acc: 70.31%, op_acc: 40.62%] [G loss: 0.865219]\n",
      "epoch:34 step:26707[D loss: 0.367199, acc: 65.62%, op_acc: 44.53%] [G loss: 1.430983]\n",
      "epoch:34 step:26708[D loss: 0.321965, acc: 81.25%, op_acc: 48.44%] [G loss: 1.232968]\n",
      "epoch:34 step:26709[D loss: 0.313566, acc: 80.47%, op_acc: 50.00%] [G loss: 0.835119]\n",
      "epoch:34 step:26710[D loss: 0.430603, acc: 58.59%, op_acc: 41.41%] [G loss: 1.340443]\n",
      "epoch:34 step:26711[D loss: 0.314825, acc: 78.91%, op_acc: 43.75%] [G loss: 1.207803]\n",
      "epoch:34 step:26712[D loss: 0.366903, acc: 64.84%, op_acc: 46.09%] [G loss: 1.569142]\n",
      "epoch:34 step:26713[D loss: 0.381189, acc: 64.06%, op_acc: 44.53%] [G loss: 0.679941]\n",
      "epoch:34 step:26714[D loss: 0.392898, acc: 67.97%, op_acc: 45.31%] [G loss: 1.398449]\n",
      "epoch:34 step:26715[D loss: 0.406480, acc: 70.31%, op_acc: 46.09%] [G loss: 0.617089]\n",
      "epoch:34 step:26716[D loss: 0.349884, acc: 67.19%, op_acc: 53.91%] [G loss: 0.868269]\n",
      "epoch:34 step:26717[D loss: 0.359632, acc: 71.88%, op_acc: 50.00%] [G loss: 0.752323]\n",
      "epoch:34 step:26718[D loss: 0.399756, acc: 64.84%, op_acc: 41.41%] [G loss: 1.303328]\n",
      "epoch:34 step:26719[D loss: 0.359609, acc: 69.53%, op_acc: 51.56%] [G loss: 0.550042]\n",
      "epoch:34 step:26720[D loss: 0.342955, acc: 73.44%, op_acc: 57.81%] [G loss: 0.742487]\n",
      "epoch:34 step:26721[D loss: 0.368711, acc: 68.75%, op_acc: 45.31%] [G loss: 0.709038]\n",
      "epoch:34 step:26722[D loss: 0.318820, acc: 80.47%, op_acc: 53.91%] [G loss: 0.803055]\n",
      "epoch:34 step:26723[D loss: 0.345521, acc: 75.78%, op_acc: 47.66%] [G loss: 1.204493]\n",
      "epoch:34 step:26724[D loss: 0.443220, acc: 58.59%, op_acc: 50.00%] [G loss: 1.439466]\n",
      "epoch:34 step:26725[D loss: 0.423085, acc: 57.03%, op_acc: 44.53%] [G loss: 1.076615]\n",
      "epoch:34 step:26726[D loss: 0.385515, acc: 67.97%, op_acc: 48.44%] [G loss: 1.244481]\n",
      "epoch:34 step:26727[D loss: 0.322060, acc: 80.47%, op_acc: 57.03%] [G loss: 1.409241]\n",
      "epoch:34 step:26728[D loss: 0.385003, acc: 71.09%, op_acc: 51.56%] [G loss: 1.425182]\n",
      "epoch:34 step:26729[D loss: 0.348500, acc: 72.66%, op_acc: 49.22%] [G loss: 0.774315]\n",
      "epoch:34 step:26730[D loss: 0.308013, acc: 80.47%, op_acc: 53.12%] [G loss: 1.561165]\n",
      "epoch:34 step:26731[D loss: 0.369642, acc: 69.53%, op_acc: 42.19%] [G loss: 0.935382]\n",
      "epoch:34 step:26732[D loss: 0.403999, acc: 68.75%, op_acc: 40.62%] [G loss: 1.174379]\n",
      "epoch:34 step:26733[D loss: 0.383604, acc: 67.19%, op_acc: 45.31%] [G loss: 1.370650]\n",
      "epoch:34 step:26734[D loss: 0.351678, acc: 73.44%, op_acc: 41.41%] [G loss: 0.977959]\n",
      "epoch:34 step:26735[D loss: 0.402737, acc: 63.28%, op_acc: 41.41%] [G loss: 1.209192]\n",
      "epoch:34 step:26736[D loss: 0.399970, acc: 68.75%, op_acc: 53.12%] [G loss: 1.559221]\n",
      "epoch:34 step:26737[D loss: 0.326956, acc: 71.88%, op_acc: 53.91%] [G loss: 1.413697]\n",
      "epoch:34 step:26738[D loss: 0.322966, acc: 74.22%, op_acc: 56.25%] [G loss: 1.183490]\n",
      "epoch:34 step:26739[D loss: 0.336864, acc: 79.69%, op_acc: 43.75%] [G loss: 1.141568]\n",
      "epoch:34 step:26740[D loss: 0.363736, acc: 68.75%, op_acc: 50.78%] [G loss: 1.173477]\n",
      "epoch:34 step:26741[D loss: 0.333208, acc: 78.91%, op_acc: 52.34%] [G loss: 1.139269]\n",
      "epoch:34 step:26742[D loss: 0.337835, acc: 75.78%, op_acc: 50.78%] [G loss: 1.152226]\n",
      "epoch:34 step:26743[D loss: 0.282837, acc: 85.94%, op_acc: 53.12%] [G loss: 1.636503]\n",
      "epoch:34 step:26744[D loss: 0.290123, acc: 84.38%, op_acc: 59.38%] [G loss: 1.363648]\n",
      "epoch:34 step:26745[D loss: 0.256250, acc: 86.72%, op_acc: 56.25%] [G loss: 1.282243]\n",
      "epoch:34 step:26746[D loss: 0.283630, acc: 86.72%, op_acc: 48.44%] [G loss: 0.634746]\n",
      "epoch:34 step:26747[D loss: 0.486433, acc: 56.25%, op_acc: 32.81%] [G loss: 1.851763]\n",
      "epoch:34 step:26748[D loss: 0.355229, acc: 74.22%, op_acc: 48.44%] [G loss: 1.657442]\n",
      "epoch:34 step:26749[D loss: 0.364064, acc: 71.88%, op_acc: 38.28%] [G loss: 1.788654]\n",
      "epoch:34 step:26750[D loss: 0.311703, acc: 79.69%, op_acc: 49.22%] [G loss: 1.771702]\n",
      "epoch:34 step:26751[D loss: 0.369527, acc: 71.09%, op_acc: 53.91%] [G loss: 1.464622]\n",
      "epoch:34 step:26752[D loss: 0.372835, acc: 73.44%, op_acc: 49.22%] [G loss: 1.792518]\n",
      "epoch:34 step:26753[D loss: 0.364664, acc: 70.31%, op_acc: 63.28%] [G loss: 1.298069]\n",
      "epoch:34 step:26754[D loss: 0.375561, acc: 71.88%, op_acc: 44.53%] [G loss: 1.287734]\n",
      "epoch:34 step:26755[D loss: 0.329859, acc: 75.00%, op_acc: 48.44%] [G loss: 1.537588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26756[D loss: 0.336249, acc: 69.53%, op_acc: 57.81%] [G loss: 1.401285]\n",
      "epoch:34 step:26757[D loss: 0.323704, acc: 78.12%, op_acc: 54.69%] [G loss: 1.082315]\n",
      "epoch:34 step:26758[D loss: 0.297410, acc: 82.03%, op_acc: 52.34%] [G loss: 1.289634]\n",
      "epoch:34 step:26759[D loss: 0.295087, acc: 83.59%, op_acc: 48.44%] [G loss: 1.442602]\n",
      "epoch:34 step:26760[D loss: 0.313686, acc: 81.25%, op_acc: 56.25%] [G loss: 0.658517]\n",
      "epoch:34 step:26761[D loss: 0.335967, acc: 74.22%, op_acc: 49.22%] [G loss: 1.397632]\n",
      "epoch:34 step:26762[D loss: 0.331952, acc: 81.25%, op_acc: 47.66%] [G loss: 1.476838]\n",
      "epoch:34 step:26763[D loss: 0.387925, acc: 62.50%, op_acc: 47.66%] [G loss: 1.454495]\n",
      "epoch:34 step:26764[D loss: 0.418694, acc: 64.84%, op_acc: 44.53%] [G loss: 0.910313]\n",
      "epoch:34 step:26765[D loss: 0.334859, acc: 77.34%, op_acc: 48.44%] [G loss: 1.527343]\n",
      "epoch:34 step:26766[D loss: 0.400590, acc: 65.62%, op_acc: 42.97%] [G loss: 1.469816]\n",
      "epoch:34 step:26767[D loss: 0.370441, acc: 69.53%, op_acc: 43.75%] [G loss: 1.293361]\n",
      "epoch:34 step:26768[D loss: 0.404565, acc: 66.41%, op_acc: 42.97%] [G loss: 1.318072]\n",
      "epoch:34 step:26769[D loss: 0.474478, acc: 60.16%, op_acc: 41.41%] [G loss: 1.111943]\n",
      "epoch:34 step:26770[D loss: 0.441381, acc: 64.06%, op_acc: 39.06%] [G loss: 1.061265]\n",
      "epoch:34 step:26771[D loss: 0.331570, acc: 78.12%, op_acc: 43.75%] [G loss: 1.228254]\n",
      "epoch:34 step:26772[D loss: 0.401168, acc: 60.94%, op_acc: 53.12%] [G loss: 1.242519]\n",
      "epoch:34 step:26773[D loss: 0.384231, acc: 68.75%, op_acc: 50.00%] [G loss: 1.194611]\n",
      "epoch:34 step:26774[D loss: 0.428806, acc: 61.72%, op_acc: 40.62%] [G loss: 1.331303]\n",
      "epoch:34 step:26775[D loss: 0.381032, acc: 69.53%, op_acc: 44.53%] [G loss: 1.227210]\n",
      "epoch:34 step:26776[D loss: 0.413910, acc: 64.84%, op_acc: 38.28%] [G loss: 1.301384]\n",
      "epoch:34 step:26777[D loss: 0.348344, acc: 75.78%, op_acc: 45.31%] [G loss: 1.207872]\n",
      "epoch:34 step:26778[D loss: 0.413051, acc: 63.28%, op_acc: 47.66%] [G loss: 1.310757]\n",
      "epoch:34 step:26779[D loss: 0.405428, acc: 68.75%, op_acc: 44.53%] [G loss: 1.444456]\n",
      "epoch:34 step:26780[D loss: 0.384741, acc: 64.84%, op_acc: 47.66%] [G loss: 1.350876]\n",
      "epoch:34 step:26781[D loss: 0.339883, acc: 76.56%, op_acc: 56.25%] [G loss: 1.184382]\n",
      "epoch:34 step:26782[D loss: 0.403975, acc: 60.16%, op_acc: 49.22%] [G loss: 1.098078]\n",
      "epoch:34 step:26783[D loss: 0.354519, acc: 71.88%, op_acc: 51.56%] [G loss: 0.879783]\n",
      "epoch:34 step:26784[D loss: 0.432791, acc: 56.25%, op_acc: 39.84%] [G loss: 1.125895]\n",
      "epoch:34 step:26785[D loss: 0.328302, acc: 74.22%, op_acc: 46.88%] [G loss: 1.329480]\n",
      "epoch:34 step:26786[D loss: 0.343434, acc: 71.88%, op_acc: 58.59%] [G loss: 1.076994]\n",
      "epoch:34 step:26787[D loss: 0.301291, acc: 82.03%, op_acc: 50.00%] [G loss: 1.069968]\n",
      "epoch:34 step:26788[D loss: 0.354429, acc: 71.88%, op_acc: 54.69%] [G loss: 1.282784]\n",
      "epoch:34 step:26789[D loss: 0.437281, acc: 56.25%, op_acc: 38.28%] [G loss: 1.210485]\n",
      "epoch:34 step:26790[D loss: 0.353045, acc: 74.22%, op_acc: 45.31%] [G loss: 1.040647]\n",
      "epoch:34 step:26791[D loss: 0.326284, acc: 76.56%, op_acc: 53.12%] [G loss: 1.405248]\n",
      "epoch:34 step:26792[D loss: 0.430592, acc: 61.72%, op_acc: 46.09%] [G loss: 1.346002]\n",
      "epoch:34 step:26793[D loss: 0.405697, acc: 65.62%, op_acc: 44.53%] [G loss: 0.935283]\n",
      "epoch:34 step:26794[D loss: 0.343073, acc: 78.12%, op_acc: 48.44%] [G loss: 0.969149]\n",
      "epoch:34 step:26795[D loss: 0.348812, acc: 72.66%, op_acc: 41.41%] [G loss: 1.367746]\n",
      "epoch:34 step:26796[D loss: 0.353044, acc: 74.22%, op_acc: 55.47%] [G loss: 1.264333]\n",
      "epoch:34 step:26797[D loss: 0.412139, acc: 64.84%, op_acc: 48.44%] [G loss: 1.289739]\n",
      "epoch:34 step:26798[D loss: 0.334531, acc: 83.59%, op_acc: 46.88%] [G loss: 1.082113]\n",
      "epoch:34 step:26799[D loss: 0.418715, acc: 64.06%, op_acc: 51.56%] [G loss: 0.954930]\n",
      "epoch:34 step:26800[D loss: 0.394502, acc: 67.19%, op_acc: 38.28%] [G loss: 1.008214]\n",
      "epoch:34 step:26801[D loss: 0.396339, acc: 64.06%, op_acc: 42.19%] [G loss: 1.273306]\n",
      "epoch:34 step:26802[D loss: 0.438682, acc: 61.72%, op_acc: 42.19%] [G loss: 1.249393]\n",
      "epoch:34 step:26803[D loss: 0.331040, acc: 82.03%, op_acc: 48.44%] [G loss: 1.213509]\n",
      "epoch:34 step:26804[D loss: 0.441782, acc: 59.38%, op_acc: 39.06%] [G loss: 1.058197]\n",
      "epoch:34 step:26805[D loss: 0.396435, acc: 67.19%, op_acc: 46.88%] [G loss: 1.269741]\n",
      "epoch:34 step:26806[D loss: 0.377233, acc: 71.88%, op_acc: 57.03%] [G loss: 0.972667]\n",
      "epoch:34 step:26807[D loss: 0.387044, acc: 69.53%, op_acc: 42.97%] [G loss: 0.953113]\n",
      "epoch:34 step:26808[D loss: 0.418500, acc: 65.62%, op_acc: 32.81%] [G loss: 1.113341]\n",
      "epoch:34 step:26809[D loss: 0.402020, acc: 63.28%, op_acc: 46.09%] [G loss: 1.388802]\n",
      "epoch:34 step:26810[D loss: 0.414580, acc: 64.84%, op_acc: 44.53%] [G loss: 1.275788]\n",
      "epoch:34 step:26811[D loss: 0.404942, acc: 71.09%, op_acc: 39.06%] [G loss: 1.458597]\n",
      "epoch:34 step:26812[D loss: 0.406813, acc: 63.28%, op_acc: 39.84%] [G loss: 1.115251]\n",
      "epoch:34 step:26813[D loss: 0.379603, acc: 64.84%, op_acc: 39.84%] [G loss: 1.065618]\n",
      "epoch:34 step:26814[D loss: 0.414510, acc: 59.38%, op_acc: 42.19%] [G loss: 1.132390]\n",
      "epoch:34 step:26815[D loss: 0.381348, acc: 65.62%, op_acc: 46.09%] [G loss: 1.370208]\n",
      "epoch:34 step:26816[D loss: 0.405692, acc: 64.84%, op_acc: 40.62%] [G loss: 1.180893]\n",
      "epoch:34 step:26817[D loss: 0.362368, acc: 68.75%, op_acc: 44.53%] [G loss: 1.253245]\n",
      "epoch:34 step:26818[D loss: 0.352701, acc: 71.88%, op_acc: 50.78%] [G loss: 0.961627]\n",
      "epoch:34 step:26819[D loss: 0.363364, acc: 69.53%, op_acc: 47.66%] [G loss: 0.664803]\n",
      "epoch:34 step:26820[D loss: 0.343696, acc: 75.00%, op_acc: 52.34%] [G loss: 0.844688]\n",
      "epoch:34 step:26821[D loss: 0.412322, acc: 61.72%, op_acc: 44.53%] [G loss: 1.229272]\n",
      "epoch:34 step:26822[D loss: 0.352787, acc: 67.19%, op_acc: 45.31%] [G loss: 0.607787]\n",
      "epoch:34 step:26823[D loss: 0.475999, acc: 53.91%, op_acc: 39.84%] [G loss: 1.044525]\n",
      "epoch:34 step:26824[D loss: 0.288059, acc: 84.38%, op_acc: 53.12%] [G loss: 1.277700]\n",
      "epoch:34 step:26825[D loss: 0.455687, acc: 58.59%, op_acc: 35.94%] [G loss: 0.685275]\n",
      "epoch:34 step:26826[D loss: 0.342773, acc: 73.44%, op_acc: 51.56%] [G loss: 1.469948]\n",
      "epoch:34 step:26827[D loss: 0.502074, acc: 49.22%, op_acc: 37.50%] [G loss: 0.771035]\n",
      "epoch:34 step:26828[D loss: 0.476975, acc: 52.34%, op_acc: 42.97%] [G loss: 1.349149]\n",
      "epoch:34 step:26829[D loss: 0.360670, acc: 68.75%, op_acc: 41.41%] [G loss: 1.320456]\n",
      "epoch:34 step:26830[D loss: 0.432514, acc: 57.03%, op_acc: 50.00%] [G loss: 1.171879]\n",
      "epoch:34 step:26831[D loss: 0.408477, acc: 66.41%, op_acc: 33.59%] [G loss: 1.429626]\n",
      "epoch:34 step:26832[D loss: 0.422880, acc: 64.06%, op_acc: 42.97%] [G loss: 0.610135]\n",
      "epoch:34 step:26833[D loss: 0.333270, acc: 75.78%, op_acc: 45.31%] [G loss: 0.774310]\n",
      "epoch:34 step:26834[D loss: 0.362220, acc: 71.09%, op_acc: 50.00%] [G loss: 0.629668]\n",
      "epoch:34 step:26835[D loss: 0.492165, acc: 55.47%, op_acc: 37.50%] [G loss: 0.677786]\n",
      "epoch:34 step:26836[D loss: 0.417544, acc: 71.88%, op_acc: 35.16%] [G loss: 1.373475]\n",
      "epoch:34 step:26837[D loss: 0.339830, acc: 68.75%, op_acc: 61.72%] [G loss: 0.925346]\n",
      "epoch:34 step:26838[D loss: 0.392029, acc: 67.19%, op_acc: 43.75%] [G loss: 1.381822]\n",
      "epoch:34 step:26839[D loss: 0.394725, acc: 70.31%, op_acc: 46.88%] [G loss: 0.802164]\n",
      "epoch:34 step:26840[D loss: 0.386845, acc: 71.88%, op_acc: 41.41%] [G loss: 1.143411]\n",
      "epoch:34 step:26841[D loss: 0.391537, acc: 65.62%, op_acc: 49.22%] [G loss: 0.611024]\n",
      "epoch:34 step:26842[D loss: 0.351031, acc: 71.88%, op_acc: 46.09%] [G loss: 1.134553]\n",
      "epoch:34 step:26843[D loss: 0.337127, acc: 75.78%, op_acc: 46.09%] [G loss: 0.789275]\n",
      "epoch:34 step:26844[D loss: 0.348584, acc: 73.44%, op_acc: 55.47%] [G loss: 0.679778]\n",
      "epoch:34 step:26845[D loss: 0.401515, acc: 65.62%, op_acc: 43.75%] [G loss: 0.557521]\n",
      "epoch:34 step:26846[D loss: 0.390918, acc: 65.62%, op_acc: 47.66%] [G loss: 0.583107]\n",
      "epoch:34 step:26847[D loss: 0.374119, acc: 69.53%, op_acc: 46.09%] [G loss: 0.724281]\n",
      "epoch:34 step:26848[D loss: 0.301060, acc: 83.59%, op_acc: 50.78%] [G loss: 1.432289]\n",
      "epoch:34 step:26849[D loss: 0.353089, acc: 70.31%, op_acc: 47.66%] [G loss: 0.764731]\n",
      "epoch:34 step:26850[D loss: 0.302685, acc: 83.59%, op_acc: 57.03%] [G loss: 1.333909]\n",
      "epoch:34 step:26851[D loss: 0.461305, acc: 52.34%, op_acc: 40.62%] [G loss: 0.700287]\n",
      "epoch:34 step:26852[D loss: 0.318912, acc: 80.47%, op_acc: 54.69%] [G loss: 0.819888]\n",
      "epoch:34 step:26853[D loss: 0.370251, acc: 68.75%, op_acc: 44.53%] [G loss: 1.228498]\n",
      "epoch:34 step:26854[D loss: 0.441978, acc: 63.28%, op_acc: 44.53%] [G loss: 0.784928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26855[D loss: 0.315705, acc: 81.25%, op_acc: 56.25%] [G loss: 0.589088]\n",
      "epoch:34 step:26856[D loss: 0.332341, acc: 76.56%, op_acc: 51.56%] [G loss: 0.778639]\n",
      "epoch:34 step:26857[D loss: 0.406681, acc: 68.75%, op_acc: 41.41%] [G loss: 1.292528]\n",
      "epoch:34 step:26858[D loss: 0.321385, acc: 82.03%, op_acc: 50.00%] [G loss: 0.705917]\n",
      "epoch:34 step:26859[D loss: 0.402094, acc: 60.16%, op_acc: 47.66%] [G loss: 0.937319]\n",
      "epoch:34 step:26860[D loss: 0.402733, acc: 68.75%, op_acc: 47.66%] [G loss: 0.889806]\n",
      "epoch:34 step:26861[D loss: 0.383294, acc: 68.75%, op_acc: 46.88%] [G loss: 1.457167]\n",
      "epoch:34 step:26862[D loss: 0.382216, acc: 75.78%, op_acc: 45.31%] [G loss: 1.399181]\n",
      "epoch:34 step:26863[D loss: 0.427065, acc: 66.41%, op_acc: 37.50%] [G loss: 0.879731]\n",
      "epoch:34 step:26864[D loss: 0.323576, acc: 79.69%, op_acc: 42.97%] [G loss: 0.638415]\n",
      "epoch:34 step:26865[D loss: 0.363108, acc: 76.56%, op_acc: 52.34%] [G loss: 0.640918]\n",
      "epoch:34 step:26866[D loss: 0.355233, acc: 72.66%, op_acc: 41.41%] [G loss: 0.757095]\n",
      "epoch:34 step:26867[D loss: 0.395694, acc: 61.72%, op_acc: 42.19%] [G loss: 1.280836]\n",
      "epoch:34 step:26868[D loss: 0.388318, acc: 67.97%, op_acc: 45.31%] [G loss: 0.893146]\n",
      "epoch:34 step:26869[D loss: 0.490177, acc: 56.25%, op_acc: 40.62%] [G loss: 0.599175]\n",
      "epoch:34 step:26870[D loss: 0.408817, acc: 68.75%, op_acc: 45.31%] [G loss: 0.596097]\n",
      "epoch:34 step:26871[D loss: 0.448990, acc: 55.47%, op_acc: 38.28%] [G loss: 1.367226]\n",
      "epoch:34 step:26872[D loss: 0.419550, acc: 64.06%, op_acc: 37.50%] [G loss: 1.135325]\n",
      "epoch:34 step:26873[D loss: 0.332049, acc: 76.56%, op_acc: 53.12%] [G loss: 1.232613]\n",
      "epoch:34 step:26874[D loss: 0.412065, acc: 60.94%, op_acc: 46.09%] [G loss: 1.172352]\n",
      "epoch:34 step:26875[D loss: 0.397167, acc: 67.19%, op_acc: 43.75%] [G loss: 1.215873]\n",
      "epoch:34 step:26876[D loss: 0.321573, acc: 73.44%, op_acc: 46.88%] [G loss: 0.609246]\n",
      "epoch:34 step:26877[D loss: 0.444362, acc: 64.84%, op_acc: 39.84%] [G loss: 1.477895]\n",
      "epoch:34 step:26878[D loss: 0.438041, acc: 60.16%, op_acc: 34.38%] [G loss: 0.980983]\n",
      "epoch:34 step:26879[D loss: 0.400876, acc: 65.62%, op_acc: 45.31%] [G loss: 0.818183]\n",
      "epoch:34 step:26880[D loss: 0.404043, acc: 67.19%, op_acc: 53.91%] [G loss: 1.367348]\n",
      "epoch:34 step:26881[D loss: 0.297862, acc: 82.03%, op_acc: 60.94%] [G loss: 1.246124]\n",
      "epoch:34 step:26882[D loss: 0.402958, acc: 67.19%, op_acc: 46.09%] [G loss: 1.116825]\n",
      "epoch:34 step:26883[D loss: 0.435231, acc: 58.59%, op_acc: 42.97%] [G loss: 0.544737]\n",
      "epoch:34 step:26884[D loss: 0.368352, acc: 66.41%, op_acc: 39.84%] [G loss: 1.320811]\n",
      "epoch:34 step:26885[D loss: 0.449739, acc: 60.16%, op_acc: 33.59%] [G loss: 0.962147]\n",
      "epoch:34 step:26886[D loss: 0.369035, acc: 70.31%, op_acc: 42.19%] [G loss: 0.907787]\n",
      "epoch:34 step:26887[D loss: 0.424598, acc: 63.28%, op_acc: 42.19%] [G loss: 1.373206]\n",
      "epoch:34 step:26888[D loss: 0.384911, acc: 68.75%, op_acc: 43.75%] [G loss: 0.941095]\n",
      "epoch:34 step:26889[D loss: 0.415040, acc: 60.16%, op_acc: 39.84%] [G loss: 0.950401]\n",
      "epoch:34 step:26890[D loss: 0.386978, acc: 67.97%, op_acc: 43.75%] [G loss: 1.539540]\n",
      "epoch:34 step:26891[D loss: 0.407316, acc: 68.75%, op_acc: 48.44%] [G loss: 0.695416]\n",
      "epoch:34 step:26892[D loss: 0.446202, acc: 57.81%, op_acc: 53.91%] [G loss: 0.619196]\n",
      "epoch:34 step:26893[D loss: 0.384709, acc: 71.09%, op_acc: 42.19%] [G loss: 0.741544]\n",
      "epoch:34 step:26894[D loss: 0.349438, acc: 71.09%, op_acc: 53.12%] [G loss: 0.749984]\n",
      "epoch:34 step:26895[D loss: 0.405011, acc: 60.94%, op_acc: 42.19%] [G loss: 1.242484]\n",
      "epoch:34 step:26896[D loss: 0.369070, acc: 65.62%, op_acc: 45.31%] [G loss: 1.126871]\n",
      "epoch:34 step:26897[D loss: 0.416045, acc: 71.09%, op_acc: 43.75%] [G loss: 0.891108]\n",
      "epoch:34 step:26898[D loss: 0.378683, acc: 69.53%, op_acc: 50.00%] [G loss: 0.741730]\n",
      "epoch:34 step:26899[D loss: 0.406654, acc: 67.97%, op_acc: 39.06%] [G loss: 0.856972]\n",
      "epoch:34 step:26900[D loss: 0.358260, acc: 73.44%, op_acc: 44.53%] [G loss: 0.916540]\n",
      "epoch:34 step:26901[D loss: 0.378398, acc: 67.97%, op_acc: 46.09%] [G loss: 0.818299]\n",
      "epoch:34 step:26902[D loss: 0.320080, acc: 81.25%, op_acc: 42.19%] [G loss: 1.253414]\n",
      "epoch:34 step:26903[D loss: 0.344972, acc: 73.44%, op_acc: 43.75%] [G loss: 0.978470]\n",
      "epoch:34 step:26904[D loss: 0.394095, acc: 71.09%, op_acc: 46.09%] [G loss: 0.994875]\n",
      "epoch:34 step:26905[D loss: 0.438111, acc: 66.41%, op_acc: 42.19%] [G loss: 1.154473]\n",
      "epoch:34 step:26906[D loss: 0.334014, acc: 78.12%, op_acc: 46.09%] [G loss: 1.098568]\n",
      "epoch:34 step:26907[D loss: 0.337711, acc: 71.09%, op_acc: 54.69%] [G loss: 1.079332]\n",
      "epoch:34 step:26908[D loss: 0.341334, acc: 71.88%, op_acc: 46.88%] [G loss: 1.300437]\n",
      "epoch:34 step:26909[D loss: 0.384858, acc: 67.97%, op_acc: 46.09%] [G loss: 1.050729]\n",
      "epoch:34 step:26910[D loss: 0.370805, acc: 71.88%, op_acc: 50.78%] [G loss: 1.355010]\n",
      "epoch:34 step:26911[D loss: 0.378614, acc: 74.22%, op_acc: 39.06%] [G loss: 1.336102]\n",
      "epoch:34 step:26912[D loss: 0.318002, acc: 80.47%, op_acc: 53.91%] [G loss: 1.114935]\n",
      "epoch:34 step:26913[D loss: 0.423934, acc: 64.84%, op_acc: 37.50%] [G loss: 1.116485]\n",
      "epoch:34 step:26914[D loss: 0.423529, acc: 60.94%, op_acc: 42.19%] [G loss: 1.333604]\n",
      "epoch:34 step:26915[D loss: 0.381464, acc: 64.06%, op_acc: 49.22%] [G loss: 1.413763]\n",
      "epoch:34 step:26916[D loss: 0.362080, acc: 69.53%, op_acc: 52.34%] [G loss: 1.482841]\n",
      "epoch:34 step:26917[D loss: 0.348803, acc: 75.00%, op_acc: 55.47%] [G loss: 0.999929]\n",
      "epoch:34 step:26918[D loss: 0.388830, acc: 69.53%, op_acc: 46.88%] [G loss: 1.252611]\n",
      "epoch:34 step:26919[D loss: 0.333039, acc: 73.44%, op_acc: 46.09%] [G loss: 0.915335]\n",
      "epoch:34 step:26920[D loss: 0.341823, acc: 73.44%, op_acc: 57.03%] [G loss: 1.441968]\n",
      "epoch:34 step:26921[D loss: 0.450458, acc: 60.94%, op_acc: 45.31%] [G loss: 1.083358]\n",
      "epoch:34 step:26922[D loss: 0.355632, acc: 73.44%, op_acc: 46.88%] [G loss: 1.054404]\n",
      "epoch:34 step:26923[D loss: 0.349852, acc: 71.09%, op_acc: 44.53%] [G loss: 1.252578]\n",
      "epoch:34 step:26924[D loss: 0.351504, acc: 75.00%, op_acc: 50.00%] [G loss: 1.273921]\n",
      "epoch:34 step:26925[D loss: 0.344355, acc: 71.09%, op_acc: 61.72%] [G loss: 1.025127]\n",
      "epoch:34 step:26926[D loss: 0.331609, acc: 78.91%, op_acc: 46.09%] [G loss: 1.027015]\n",
      "epoch:34 step:26927[D loss: 0.338235, acc: 77.34%, op_acc: 53.12%] [G loss: 1.000938]\n",
      "epoch:34 step:26928[D loss: 0.298686, acc: 82.03%, op_acc: 60.94%] [G loss: 0.805801]\n",
      "epoch:34 step:26929[D loss: 0.360404, acc: 67.97%, op_acc: 52.34%] [G loss: 1.101918]\n",
      "epoch:34 step:26930[D loss: 0.342596, acc: 78.12%, op_acc: 47.66%] [G loss: 1.106172]\n",
      "epoch:34 step:26931[D loss: 0.369034, acc: 71.09%, op_acc: 54.69%] [G loss: 0.956936]\n",
      "epoch:34 step:26932[D loss: 0.392911, acc: 64.84%, op_acc: 40.62%] [G loss: 1.416757]\n",
      "epoch:34 step:26933[D loss: 0.330147, acc: 75.78%, op_acc: 47.66%] [G loss: 1.098655]\n",
      "epoch:34 step:26934[D loss: 0.395164, acc: 66.41%, op_acc: 46.09%] [G loss: 1.259581]\n",
      "epoch:34 step:26935[D loss: 0.347221, acc: 74.22%, op_acc: 44.53%] [G loss: 0.940621]\n",
      "epoch:34 step:26936[D loss: 0.418202, acc: 63.28%, op_acc: 45.31%] [G loss: 1.127951]\n",
      "epoch:34 step:26937[D loss: 0.376384, acc: 66.41%, op_acc: 49.22%] [G loss: 1.257923]\n",
      "epoch:34 step:26938[D loss: 0.347227, acc: 73.44%, op_acc: 45.31%] [G loss: 1.029137]\n",
      "epoch:34 step:26939[D loss: 0.341677, acc: 71.88%, op_acc: 54.69%] [G loss: 0.911522]\n",
      "epoch:34 step:26940[D loss: 0.353048, acc: 71.88%, op_acc: 54.69%] [G loss: 0.904910]\n",
      "epoch:34 step:26941[D loss: 0.437427, acc: 59.38%, op_acc: 45.31%] [G loss: 1.104194]\n",
      "epoch:34 step:26942[D loss: 0.421001, acc: 64.84%, op_acc: 43.75%] [G loss: 0.827902]\n",
      "epoch:34 step:26943[D loss: 0.374363, acc: 73.44%, op_acc: 48.44%] [G loss: 0.869841]\n",
      "epoch:34 step:26944[D loss: 0.299088, acc: 79.69%, op_acc: 53.91%] [G loss: 1.080952]\n",
      "epoch:34 step:26945[D loss: 0.401924, acc: 61.72%, op_acc: 47.66%] [G loss: 0.979762]\n",
      "epoch:34 step:26946[D loss: 0.358600, acc: 75.78%, op_acc: 47.66%] [G loss: 0.914462]\n",
      "epoch:34 step:26947[D loss: 0.371296, acc: 74.22%, op_acc: 45.31%] [G loss: 0.839235]\n",
      "epoch:34 step:26948[D loss: 0.335912, acc: 78.12%, op_acc: 43.75%] [G loss: 1.451260]\n",
      "epoch:34 step:26949[D loss: 0.404671, acc: 65.62%, op_acc: 40.62%] [G loss: 0.848827]\n",
      "epoch:34 step:26950[D loss: 0.462998, acc: 57.03%, op_acc: 39.06%] [G loss: 0.900423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:26951[D loss: 0.338761, acc: 78.91%, op_acc: 50.78%] [G loss: 1.308065]\n",
      "epoch:34 step:26952[D loss: 0.381771, acc: 71.09%, op_acc: 50.00%] [G loss: 1.406683]\n",
      "epoch:34 step:26953[D loss: 0.353358, acc: 71.09%, op_acc: 46.09%] [G loss: 1.349081]\n",
      "epoch:34 step:26954[D loss: 0.395641, acc: 67.97%, op_acc: 50.78%] [G loss: 0.876112]\n",
      "epoch:34 step:26955[D loss: 0.342600, acc: 71.88%, op_acc: 46.09%] [G loss: 0.927721]\n",
      "epoch:34 step:26956[D loss: 0.375601, acc: 75.00%, op_acc: 44.53%] [G loss: 0.989262]\n",
      "epoch:34 step:26957[D loss: 0.350939, acc: 77.34%, op_acc: 46.09%] [G loss: 1.075962]\n",
      "epoch:34 step:26958[D loss: 0.275831, acc: 84.38%, op_acc: 55.47%] [G loss: 0.926701]\n",
      "epoch:34 step:26959[D loss: 0.380929, acc: 70.31%, op_acc: 47.66%] [G loss: 1.062181]\n",
      "epoch:34 step:26960[D loss: 0.328031, acc: 75.78%, op_acc: 48.44%] [G loss: 1.143983]\n",
      "epoch:34 step:26961[D loss: 0.317936, acc: 81.25%, op_acc: 45.31%] [G loss: 1.103785]\n",
      "epoch:34 step:26962[D loss: 0.411051, acc: 57.03%, op_acc: 42.19%] [G loss: 1.452788]\n",
      "epoch:34 step:26963[D loss: 0.391060, acc: 69.53%, op_acc: 46.09%] [G loss: 1.150505]\n",
      "epoch:34 step:26964[D loss: 0.341949, acc: 74.22%, op_acc: 53.12%] [G loss: 1.185577]\n",
      "epoch:34 step:26965[D loss: 0.369279, acc: 72.66%, op_acc: 47.66%] [G loss: 1.268820]\n",
      "epoch:34 step:26966[D loss: 0.401002, acc: 61.72%, op_acc: 52.34%] [G loss: 0.937104]\n",
      "epoch:34 step:26967[D loss: 0.394704, acc: 68.75%, op_acc: 39.84%] [G loss: 1.090617]\n",
      "epoch:34 step:26968[D loss: 0.405634, acc: 62.50%, op_acc: 46.88%] [G loss: 1.045153]\n",
      "epoch:34 step:26969[D loss: 0.347732, acc: 71.88%, op_acc: 48.44%] [G loss: 1.226224]\n",
      "epoch:34 step:26970[D loss: 0.306200, acc: 79.69%, op_acc: 51.56%] [G loss: 1.179993]\n",
      "epoch:34 step:26971[D loss: 0.394814, acc: 68.75%, op_acc: 46.88%] [G loss: 1.255401]\n",
      "epoch:34 step:26972[D loss: 0.353844, acc: 68.75%, op_acc: 55.47%] [G loss: 0.883997]\n",
      "epoch:34 step:26973[D loss: 0.490205, acc: 46.09%, op_acc: 42.97%] [G loss: 0.671310]\n",
      "epoch:34 step:26974[D loss: 0.325021, acc: 79.69%, op_acc: 46.88%] [G loss: 0.816565]\n",
      "epoch:34 step:26975[D loss: 0.359727, acc: 70.31%, op_acc: 52.34%] [G loss: 0.757041]\n",
      "epoch:34 step:26976[D loss: 0.349751, acc: 70.31%, op_acc: 47.66%] [G loss: 1.323764]\n",
      "epoch:34 step:26977[D loss: 0.358006, acc: 76.56%, op_acc: 49.22%] [G loss: 1.189582]\n",
      "epoch:34 step:26978[D loss: 0.397463, acc: 71.09%, op_acc: 43.75%] [G loss: 0.673216]\n",
      "epoch:34 step:26979[D loss: 0.373515, acc: 71.09%, op_acc: 48.44%] [G loss: 0.719185]\n",
      "epoch:34 step:26980[D loss: 0.350247, acc: 78.12%, op_acc: 46.88%] [G loss: 1.100353]\n",
      "epoch:34 step:26981[D loss: 0.311730, acc: 81.25%, op_acc: 50.78%] [G loss: 1.500929]\n",
      "epoch:34 step:26982[D loss: 0.392762, acc: 62.50%, op_acc: 45.31%] [G loss: 0.847124]\n",
      "epoch:34 step:26983[D loss: 0.318832, acc: 73.44%, op_acc: 51.56%] [G loss: 0.819352]\n",
      "epoch:34 step:26984[D loss: 0.360046, acc: 71.09%, op_acc: 48.44%] [G loss: 0.970182]\n",
      "epoch:34 step:26985[D loss: 0.293824, acc: 83.59%, op_acc: 50.00%] [G loss: 0.643592]\n",
      "epoch:34 step:26986[D loss: 0.372953, acc: 71.09%, op_acc: 51.56%] [G loss: 0.992631]\n",
      "epoch:34 step:26987[D loss: 0.328617, acc: 76.56%, op_acc: 53.91%] [G loss: 1.105247]\n",
      "epoch:34 step:26988[D loss: 0.410041, acc: 62.50%, op_acc: 45.31%] [G loss: 1.559744]\n",
      "epoch:34 step:26989[D loss: 0.365455, acc: 73.44%, op_acc: 46.88%] [G loss: 0.707644]\n",
      "epoch:34 step:26990[D loss: 0.413287, acc: 67.19%, op_acc: 42.97%] [G loss: 1.163898]\n",
      "epoch:34 step:26991[D loss: 0.429300, acc: 62.50%, op_acc: 39.06%] [G loss: 1.072251]\n",
      "epoch:34 step:26992[D loss: 0.290337, acc: 83.59%, op_acc: 50.78%] [G loss: 1.099367]\n",
      "epoch:34 step:26993[D loss: 0.331488, acc: 75.00%, op_acc: 51.56%] [G loss: 0.922442]\n",
      "epoch:34 step:26994[D loss: 0.324962, acc: 78.91%, op_acc: 43.75%] [G loss: 0.824798]\n",
      "epoch:34 step:26995[D loss: 0.311990, acc: 78.12%, op_acc: 50.78%] [G loss: 1.071473]\n",
      "epoch:34 step:26996[D loss: 0.258000, acc: 83.59%, op_acc: 66.41%] [G loss: 0.925634]\n",
      "epoch:34 step:26997[D loss: 0.321293, acc: 83.59%, op_acc: 46.88%] [G loss: 1.037631]\n",
      "epoch:34 step:26998[D loss: 0.248763, acc: 85.16%, op_acc: 62.50%] [G loss: 1.287228]\n",
      "epoch:34 step:26999[D loss: 0.307908, acc: 82.81%, op_acc: 55.47%] [G loss: 1.256445]\n",
      "epoch:34 step:27000[D loss: 0.323060, acc: 76.56%, op_acc: 48.44%] [G loss: 1.190463]\n",
      "epoch:34 step:27001[D loss: 0.268105, acc: 89.06%, op_acc: 57.81%] [G loss: 1.060191]\n",
      "epoch:34 step:27002[D loss: 0.219933, acc: 93.75%, op_acc: 60.16%] [G loss: 1.137610]\n",
      "epoch:34 step:27003[D loss: 0.272856, acc: 85.94%, op_acc: 45.31%] [G loss: 1.558939]\n",
      "epoch:34 step:27004[D loss: 0.304001, acc: 80.47%, op_acc: 58.59%] [G loss: 1.655467]\n",
      "epoch:34 step:27005[D loss: 0.274213, acc: 83.59%, op_acc: 61.72%] [G loss: 0.720230]\n",
      "epoch:34 step:27006[D loss: 0.254879, acc: 87.50%, op_acc: 50.00%] [G loss: 1.522850]\n",
      "epoch:34 step:27007[D loss: 0.306386, acc: 78.91%, op_acc: 53.12%] [G loss: 1.588754]\n",
      "epoch:34 step:27008[D loss: 0.290341, acc: 77.34%, op_acc: 57.81%] [G loss: 1.480926]\n",
      "epoch:34 step:27009[D loss: 0.336105, acc: 72.66%, op_acc: 55.47%] [G loss: 1.598833]\n",
      "epoch:34 step:27010[D loss: 0.323928, acc: 78.12%, op_acc: 48.44%] [G loss: 1.751325]\n",
      "epoch:34 step:27011[D loss: 0.260372, acc: 82.81%, op_acc: 62.50%] [G loss: 1.468567]\n",
      "epoch:34 step:27012[D loss: 0.272150, acc: 85.16%, op_acc: 60.16%] [G loss: 1.316186]\n",
      "epoch:34 step:27013[D loss: 0.200630, acc: 92.19%, op_acc: 67.19%] [G loss: 1.416613]\n",
      "epoch:34 step:27014[D loss: 0.214828, acc: 93.75%, op_acc: 57.03%] [G loss: 1.586776]\n",
      "epoch:34 step:27015[D loss: 0.251201, acc: 87.50%, op_acc: 58.59%] [G loss: 1.764578]\n",
      "epoch:34 step:27016[D loss: 0.189251, acc: 92.19%, op_acc: 73.44%] [G loss: 1.921400]\n",
      "epoch:34 step:27017[D loss: 0.256150, acc: 83.59%, op_acc: 60.94%] [G loss: 1.961063]\n",
      "epoch:34 step:27018[D loss: 0.295743, acc: 82.03%, op_acc: 47.66%] [G loss: 1.735098]\n",
      "epoch:34 step:27019[D loss: 0.249670, acc: 88.28%, op_acc: 57.81%] [G loss: 1.958516]\n",
      "epoch:34 step:27020[D loss: 0.222291, acc: 87.50%, op_acc: 66.41%] [G loss: 1.736512]\n",
      "epoch:34 step:27021[D loss: 0.283204, acc: 83.59%, op_acc: 53.12%] [G loss: 2.096364]\n",
      "epoch:34 step:27022[D loss: 0.173670, acc: 96.88%, op_acc: 71.88%] [G loss: 1.983465]\n",
      "epoch:34 step:27023[D loss: 0.239921, acc: 88.28%, op_acc: 62.50%] [G loss: 1.802748]\n",
      "epoch:34 step:27024[D loss: 0.238153, acc: 85.94%, op_acc: 60.16%] [G loss: 1.890738]\n",
      "epoch:34 step:27025[D loss: 0.238067, acc: 91.41%, op_acc: 66.41%] [G loss: 1.887424]\n",
      "epoch:34 step:27026[D loss: 0.330943, acc: 75.00%, op_acc: 53.12%] [G loss: 2.039965]\n",
      "epoch:34 step:27027[D loss: 0.242681, acc: 84.38%, op_acc: 60.16%] [G loss: 1.939125]\n",
      "epoch:34 step:27028[D loss: 0.218858, acc: 89.06%, op_acc: 64.84%] [G loss: 2.141583]\n",
      "epoch:34 step:27029[D loss: 0.209726, acc: 91.41%, op_acc: 64.84%] [G loss: 2.208433]\n",
      "epoch:34 step:27030[D loss: 0.343661, acc: 73.44%, op_acc: 48.44%] [G loss: 1.848775]\n",
      "epoch:34 step:27031[D loss: 0.273314, acc: 82.81%, op_acc: 63.28%] [G loss: 1.858910]\n",
      "epoch:34 step:27032[D loss: 0.262371, acc: 84.38%, op_acc: 59.38%] [G loss: 1.910315]\n",
      "epoch:34 step:27033[D loss: 0.256091, acc: 85.16%, op_acc: 65.62%] [G loss: 1.538410]\n",
      "epoch:34 step:27034[D loss: 0.312775, acc: 83.59%, op_acc: 52.34%] [G loss: 1.587212]\n",
      "epoch:34 step:27035[D loss: 0.324174, acc: 83.59%, op_acc: 51.56%] [G loss: 1.868122]\n",
      "epoch:34 step:27036[D loss: 0.407357, acc: 63.28%, op_acc: 39.84%] [G loss: 0.981553]\n",
      "epoch:34 step:27037[D loss: 0.295358, acc: 85.16%, op_acc: 53.91%] [G loss: 1.639195]\n",
      "epoch:34 step:27038[D loss: 0.277893, acc: 79.69%, op_acc: 56.25%] [G loss: 1.747891]\n",
      "epoch:34 step:27039[D loss: 0.334647, acc: 78.91%, op_acc: 50.78%] [G loss: 1.824982]\n",
      "epoch:34 step:27040[D loss: 0.286325, acc: 79.69%, op_acc: 57.81%] [G loss: 0.585844]\n",
      "epoch:34 step:27041[D loss: 0.548094, acc: 47.66%, op_acc: 35.94%] [G loss: 1.737122]\n",
      "epoch:34 step:27042[D loss: 0.418140, acc: 63.28%, op_acc: 40.62%] [G loss: 1.824220]\n",
      "epoch:34 step:27043[D loss: 0.453513, acc: 64.06%, op_acc: 42.19%] [G loss: 1.640586]\n",
      "epoch:34 step:27044[D loss: 0.378317, acc: 69.53%, op_acc: 46.88%] [G loss: 1.160247]\n",
      "epoch:34 step:27045[D loss: 0.434628, acc: 67.19%, op_acc: 42.19%] [G loss: 1.268085]\n",
      "epoch:34 step:27046[D loss: 0.389215, acc: 71.09%, op_acc: 34.38%] [G loss: 1.651541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27047[D loss: 0.412535, acc: 69.53%, op_acc: 38.28%] [G loss: 1.651421]\n",
      "epoch:34 step:27048[D loss: 0.434297, acc: 60.94%, op_acc: 46.88%] [G loss: 1.507459]\n",
      "epoch:34 step:27049[D loss: 0.390559, acc: 68.75%, op_acc: 49.22%] [G loss: 1.317616]\n",
      "epoch:34 step:27050[D loss: 0.428882, acc: 62.50%, op_acc: 43.75%] [G loss: 1.002527]\n",
      "epoch:34 step:27051[D loss: 0.384854, acc: 62.50%, op_acc: 45.31%] [G loss: 1.423995]\n",
      "epoch:34 step:27052[D loss: 0.381618, acc: 67.97%, op_acc: 43.75%] [G loss: 1.355013]\n",
      "epoch:34 step:27053[D loss: 0.337031, acc: 75.00%, op_acc: 57.03%] [G loss: 1.935061]\n",
      "epoch:34 step:27054[D loss: 0.303447, acc: 78.91%, op_acc: 52.34%] [G loss: 1.478377]\n",
      "epoch:34 step:27055[D loss: 0.442663, acc: 63.28%, op_acc: 40.62%] [G loss: 1.344149]\n",
      "epoch:34 step:27056[D loss: 0.398742, acc: 67.19%, op_acc: 46.88%] [G loss: 1.521980]\n",
      "epoch:34 step:27057[D loss: 0.392582, acc: 67.19%, op_acc: 41.41%] [G loss: 1.606710]\n",
      "epoch:34 step:27058[D loss: 0.431364, acc: 62.50%, op_acc: 36.72%] [G loss: 1.424416]\n",
      "epoch:34 step:27059[D loss: 0.386333, acc: 72.66%, op_acc: 42.19%] [G loss: 1.570328]\n",
      "epoch:34 step:27060[D loss: 0.373977, acc: 70.31%, op_acc: 45.31%] [G loss: 1.608482]\n",
      "epoch:34 step:27061[D loss: 0.384362, acc: 71.09%, op_acc: 46.88%] [G loss: 1.488387]\n",
      "epoch:34 step:27062[D loss: 0.410081, acc: 67.97%, op_acc: 39.06%] [G loss: 1.404428]\n",
      "epoch:34 step:27063[D loss: 0.449160, acc: 58.59%, op_acc: 46.09%] [G loss: 1.271559]\n",
      "epoch:34 step:27064[D loss: 0.383010, acc: 68.75%, op_acc: 46.09%] [G loss: 1.442103]\n",
      "epoch:34 step:27065[D loss: 0.353727, acc: 75.78%, op_acc: 50.00%] [G loss: 1.539182]\n",
      "epoch:34 step:27066[D loss: 0.372738, acc: 67.97%, op_acc: 52.34%] [G loss: 1.517426]\n",
      "epoch:34 step:27067[D loss: 0.375874, acc: 75.78%, op_acc: 40.62%] [G loss: 1.494908]\n",
      "epoch:34 step:27068[D loss: 0.362142, acc: 72.66%, op_acc: 46.88%] [G loss: 1.395061]\n",
      "epoch:34 step:27069[D loss: 0.371336, acc: 71.88%, op_acc: 43.75%] [G loss: 1.147650]\n",
      "epoch:34 step:27070[D loss: 0.337768, acc: 75.78%, op_acc: 50.00%] [G loss: 1.677751]\n",
      "epoch:34 step:27071[D loss: 0.359446, acc: 73.44%, op_acc: 42.19%] [G loss: 1.579938]\n",
      "epoch:34 step:27072[D loss: 0.356678, acc: 72.66%, op_acc: 52.34%] [G loss: 1.477409]\n",
      "epoch:34 step:27073[D loss: 0.390757, acc: 67.97%, op_acc: 46.88%] [G loss: 1.289454]\n",
      "epoch:34 step:27074[D loss: 0.337694, acc: 77.34%, op_acc: 45.31%] [G loss: 1.219613]\n",
      "epoch:34 step:27075[D loss: 0.419767, acc: 61.72%, op_acc: 39.84%] [G loss: 1.114422]\n",
      "epoch:34 step:27076[D loss: 0.474426, acc: 57.81%, op_acc: 35.94%] [G loss: 1.239132]\n",
      "epoch:34 step:27077[D loss: 0.426918, acc: 63.28%, op_acc: 45.31%] [G loss: 1.365066]\n",
      "epoch:34 step:27078[D loss: 0.362381, acc: 74.22%, op_acc: 46.88%] [G loss: 1.455414]\n",
      "epoch:34 step:27079[D loss: 0.426643, acc: 64.84%, op_acc: 40.62%] [G loss: 1.342552]\n",
      "epoch:34 step:27080[D loss: 0.494268, acc: 59.38%, op_acc: 36.72%] [G loss: 1.120866]\n",
      "epoch:34 step:27081[D loss: 0.429512, acc: 63.28%, op_acc: 44.53%] [G loss: 1.525074]\n",
      "epoch:34 step:27082[D loss: 0.416897, acc: 64.06%, op_acc: 43.75%] [G loss: 1.433788]\n",
      "epoch:34 step:27083[D loss: 0.462878, acc: 53.12%, op_acc: 42.97%] [G loss: 1.044268]\n",
      "epoch:34 step:27084[D loss: 0.544634, acc: 46.09%, op_acc: 33.59%] [G loss: 1.104113]\n",
      "epoch:34 step:27085[D loss: 0.406826, acc: 65.62%, op_acc: 40.62%] [G loss: 1.134038]\n",
      "epoch:34 step:27086[D loss: 0.430176, acc: 62.50%, op_acc: 33.59%] [G loss: 1.232062]\n",
      "epoch:34 step:27087[D loss: 0.410922, acc: 65.62%, op_acc: 46.88%] [G loss: 1.110598]\n",
      "epoch:34 step:27088[D loss: 0.400532, acc: 63.28%, op_acc: 46.09%] [G loss: 1.376877]\n",
      "epoch:34 step:27089[D loss: 0.485130, acc: 58.59%, op_acc: 34.38%] [G loss: 1.321882]\n",
      "epoch:34 step:27090[D loss: 0.413314, acc: 64.06%, op_acc: 46.88%] [G loss: 1.399022]\n",
      "epoch:34 step:27091[D loss: 0.449971, acc: 61.72%, op_acc: 39.84%] [G loss: 1.225847]\n",
      "epoch:34 step:27092[D loss: 0.358774, acc: 78.12%, op_acc: 44.53%] [G loss: 1.135858]\n",
      "epoch:34 step:27093[D loss: 0.408060, acc: 62.50%, op_acc: 50.00%] [G loss: 1.345535]\n",
      "epoch:34 step:27094[D loss: 0.384302, acc: 67.97%, op_acc: 42.19%] [G loss: 1.604708]\n",
      "epoch:34 step:27095[D loss: 0.341361, acc: 74.22%, op_acc: 48.44%] [G loss: 1.391743]\n",
      "epoch:34 step:27096[D loss: 0.397687, acc: 64.84%, op_acc: 43.75%] [G loss: 1.639117]\n",
      "epoch:34 step:27097[D loss: 0.371085, acc: 71.88%, op_acc: 41.41%] [G loss: 1.607129]\n",
      "epoch:34 step:27098[D loss: 0.374374, acc: 71.09%, op_acc: 50.00%] [G loss: 1.157919]\n",
      "epoch:34 step:27099[D loss: 0.347129, acc: 71.88%, op_acc: 44.53%] [G loss: 1.771976]\n",
      "epoch:34 step:27100[D loss: 0.352865, acc: 69.53%, op_acc: 51.56%] [G loss: 1.918073]\n",
      "epoch:34 step:27101[D loss: 0.392157, acc: 74.22%, op_acc: 43.75%] [G loss: 1.360122]\n",
      "epoch:34 step:27102[D loss: 0.426656, acc: 60.94%, op_acc: 44.53%] [G loss: 1.405099]\n",
      "epoch:34 step:27103[D loss: 0.353803, acc: 75.78%, op_acc: 46.88%] [G loss: 1.356084]\n",
      "epoch:34 step:27104[D loss: 0.334665, acc: 79.69%, op_acc: 42.97%] [G loss: 1.498232]\n",
      "epoch:34 step:27105[D loss: 0.443953, acc: 54.69%, op_acc: 46.88%] [G loss: 1.192883]\n",
      "epoch:34 step:27106[D loss: 0.482638, acc: 60.94%, op_acc: 40.62%] [G loss: 1.373804]\n",
      "epoch:34 step:27107[D loss: 0.358671, acc: 76.56%, op_acc: 41.41%] [G loss: 1.071038]\n",
      "epoch:34 step:27108[D loss: 0.439835, acc: 62.50%, op_acc: 39.06%] [G loss: 1.455403]\n",
      "epoch:34 step:27109[D loss: 0.404342, acc: 65.62%, op_acc: 48.44%] [G loss: 1.272767]\n",
      "epoch:34 step:27110[D loss: 0.492851, acc: 53.91%, op_acc: 32.03%] [G loss: 1.306897]\n",
      "epoch:34 step:27111[D loss: 0.356525, acc: 71.09%, op_acc: 37.50%] [G loss: 1.326210]\n",
      "epoch:34 step:27112[D loss: 0.314160, acc: 75.78%, op_acc: 55.47%] [G loss: 1.286633]\n",
      "epoch:34 step:27113[D loss: 0.334452, acc: 73.44%, op_acc: 46.88%] [G loss: 1.301076]\n",
      "epoch:34 step:27114[D loss: 0.377558, acc: 68.75%, op_acc: 43.75%] [G loss: 1.299607]\n",
      "epoch:34 step:27115[D loss: 0.424168, acc: 57.81%, op_acc: 42.97%] [G loss: 1.317403]\n",
      "epoch:34 step:27116[D loss: 0.399894, acc: 65.62%, op_acc: 39.84%] [G loss: 1.216049]\n",
      "epoch:34 step:27117[D loss: 0.380660, acc: 71.88%, op_acc: 38.28%] [G loss: 1.234995]\n",
      "epoch:34 step:27118[D loss: 0.428409, acc: 64.06%, op_acc: 50.00%] [G loss: 0.942555]\n",
      "epoch:34 step:27119[D loss: 0.372573, acc: 67.19%, op_acc: 47.66%] [G loss: 1.221887]\n",
      "epoch:34 step:27120[D loss: 0.357039, acc: 75.78%, op_acc: 42.19%] [G loss: 1.396109]\n",
      "epoch:34 step:27121[D loss: 0.364890, acc: 70.31%, op_acc: 46.88%] [G loss: 1.286718]\n",
      "epoch:34 step:27122[D loss: 0.358469, acc: 71.88%, op_acc: 47.66%] [G loss: 1.121362]\n",
      "epoch:34 step:27123[D loss: 0.302875, acc: 80.47%, op_acc: 58.59%] [G loss: 1.650209]\n",
      "epoch:34 step:27124[D loss: 0.341925, acc: 76.56%, op_acc: 43.75%] [G loss: 1.391858]\n",
      "epoch:34 step:27125[D loss: 0.385608, acc: 67.97%, op_acc: 49.22%] [G loss: 1.567934]\n",
      "epoch:34 step:27126[D loss: 0.363502, acc: 69.53%, op_acc: 50.78%] [G loss: 0.899729]\n",
      "epoch:34 step:27127[D loss: 0.471254, acc: 54.69%, op_acc: 46.09%] [G loss: 0.942452]\n",
      "epoch:34 step:27128[D loss: 0.472046, acc: 56.25%, op_acc: 35.94%] [G loss: 1.285058]\n",
      "epoch:34 step:27129[D loss: 0.390796, acc: 62.50%, op_acc: 45.31%] [G loss: 1.394939]\n",
      "epoch:34 step:27130[D loss: 0.363090, acc: 75.00%, op_acc: 46.09%] [G loss: 1.306003]\n",
      "epoch:34 step:27131[D loss: 0.455648, acc: 64.84%, op_acc: 37.50%] [G loss: 1.198456]\n",
      "epoch:34 step:27132[D loss: 0.369963, acc: 70.31%, op_acc: 44.53%] [G loss: 1.430578]\n",
      "epoch:34 step:27133[D loss: 0.361815, acc: 67.97%, op_acc: 50.78%] [G loss: 1.281838]\n",
      "epoch:34 step:27134[D loss: 0.415743, acc: 62.50%, op_acc: 41.41%] [G loss: 0.865540]\n",
      "epoch:34 step:27135[D loss: 0.339280, acc: 75.00%, op_acc: 42.97%] [G loss: 1.056031]\n",
      "epoch:34 step:27136[D loss: 0.376158, acc: 72.66%, op_acc: 40.62%] [G loss: 1.048858]\n",
      "epoch:34 step:27137[D loss: 0.380380, acc: 69.53%, op_acc: 45.31%] [G loss: 1.129640]\n",
      "epoch:34 step:27138[D loss: 0.458313, acc: 57.03%, op_acc: 42.19%] [G loss: 1.168994]\n",
      "epoch:34 step:27139[D loss: 0.373830, acc: 67.97%, op_acc: 48.44%] [G loss: 1.473723]\n",
      "epoch:34 step:27140[D loss: 0.380530, acc: 71.09%, op_acc: 45.31%] [G loss: 0.919355]\n",
      "epoch:34 step:27141[D loss: 0.339721, acc: 75.78%, op_acc: 45.31%] [G loss: 1.322663]\n",
      "epoch:34 step:27142[D loss: 0.336995, acc: 71.88%, op_acc: 51.56%] [G loss: 1.069265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27143[D loss: 0.352022, acc: 73.44%, op_acc: 47.66%] [G loss: 1.327636]\n",
      "epoch:34 step:27144[D loss: 0.344823, acc: 71.88%, op_acc: 50.78%] [G loss: 1.353500]\n",
      "epoch:34 step:27145[D loss: 0.363329, acc: 71.88%, op_acc: 54.69%] [G loss: 1.106140]\n",
      "epoch:34 step:27146[D loss: 0.401777, acc: 68.75%, op_acc: 45.31%] [G loss: 1.123004]\n",
      "epoch:34 step:27147[D loss: 0.396210, acc: 70.31%, op_acc: 44.53%] [G loss: 1.146656]\n",
      "epoch:34 step:27148[D loss: 0.362555, acc: 74.22%, op_acc: 41.41%] [G loss: 1.144817]\n",
      "epoch:34 step:27149[D loss: 0.357921, acc: 69.53%, op_acc: 45.31%] [G loss: 0.924243]\n",
      "epoch:34 step:27150[D loss: 0.445648, acc: 60.94%, op_acc: 42.97%] [G loss: 1.158127]\n",
      "epoch:34 step:27151[D loss: 0.344043, acc: 70.31%, op_acc: 51.56%] [G loss: 1.353816]\n",
      "epoch:34 step:27152[D loss: 0.303355, acc: 78.12%, op_acc: 47.66%] [G loss: 1.530196]\n",
      "epoch:34 step:27153[D loss: 0.363462, acc: 72.66%, op_acc: 44.53%] [G loss: 1.211463]\n",
      "epoch:34 step:27154[D loss: 0.348629, acc: 73.44%, op_acc: 43.75%] [G loss: 0.907872]\n",
      "epoch:34 step:27155[D loss: 0.371201, acc: 68.75%, op_acc: 49.22%] [G loss: 1.295394]\n",
      "epoch:34 step:27156[D loss: 0.355753, acc: 68.75%, op_acc: 51.56%] [G loss: 1.102192]\n",
      "epoch:34 step:27157[D loss: 0.382366, acc: 66.41%, op_acc: 46.88%] [G loss: 1.122995]\n",
      "epoch:34 step:27158[D loss: 0.425628, acc: 58.59%, op_acc: 46.88%] [G loss: 1.074943]\n",
      "epoch:34 step:27159[D loss: 0.379291, acc: 67.97%, op_acc: 46.88%] [G loss: 1.502342]\n",
      "epoch:34 step:27160[D loss: 0.389826, acc: 68.75%, op_acc: 51.56%] [G loss: 1.727522]\n",
      "epoch:34 step:27161[D loss: 0.340097, acc: 71.09%, op_acc: 62.50%] [G loss: 1.348459]\n",
      "epoch:34 step:27162[D loss: 0.317561, acc: 71.88%, op_acc: 57.81%] [G loss: 1.290542]\n",
      "epoch:34 step:27163[D loss: 0.421751, acc: 63.28%, op_acc: 50.00%] [G loss: 1.226446]\n",
      "epoch:34 step:27164[D loss: 0.325974, acc: 75.00%, op_acc: 50.78%] [G loss: 1.386322]\n",
      "epoch:34 step:27165[D loss: 0.370725, acc: 70.31%, op_acc: 51.56%] [G loss: 1.475652]\n",
      "epoch:34 step:27166[D loss: 0.309510, acc: 81.25%, op_acc: 51.56%] [G loss: 1.758310]\n",
      "epoch:34 step:27167[D loss: 0.374066, acc: 67.97%, op_acc: 51.56%] [G loss: 1.129813]\n",
      "epoch:34 step:27168[D loss: 0.329084, acc: 76.56%, op_acc: 47.66%] [G loss: 1.585483]\n",
      "epoch:34 step:27169[D loss: 0.357342, acc: 79.69%, op_acc: 50.00%] [G loss: 1.515791]\n",
      "epoch:34 step:27170[D loss: 0.420562, acc: 66.41%, op_acc: 45.31%] [G loss: 1.375768]\n",
      "epoch:34 step:27171[D loss: 0.394527, acc: 69.53%, op_acc: 49.22%] [G loss: 0.988889]\n",
      "epoch:34 step:27172[D loss: 0.338924, acc: 71.88%, op_acc: 46.09%] [G loss: 1.434027]\n",
      "epoch:34 step:27173[D loss: 0.464900, acc: 58.59%, op_acc: 39.06%] [G loss: 1.315657]\n",
      "epoch:34 step:27174[D loss: 0.402090, acc: 67.97%, op_acc: 39.84%] [G loss: 1.402356]\n",
      "epoch:34 step:27175[D loss: 0.384673, acc: 67.19%, op_acc: 50.00%] [G loss: 1.331903]\n",
      "epoch:34 step:27176[D loss: 0.385468, acc: 70.31%, op_acc: 49.22%] [G loss: 1.396494]\n",
      "epoch:34 step:27177[D loss: 0.371202, acc: 70.31%, op_acc: 49.22%] [G loss: 1.441901]\n",
      "epoch:34 step:27178[D loss: 0.343659, acc: 73.44%, op_acc: 46.09%] [G loss: 1.428730]\n",
      "epoch:34 step:27179[D loss: 0.422888, acc: 64.84%, op_acc: 47.66%] [G loss: 1.206360]\n",
      "epoch:34 step:27180[D loss: 0.394418, acc: 67.19%, op_acc: 50.00%] [G loss: 1.374649]\n",
      "epoch:34 step:27181[D loss: 0.391746, acc: 68.75%, op_acc: 43.75%] [G loss: 1.601349]\n",
      "epoch:34 step:27182[D loss: 0.380598, acc: 69.53%, op_acc: 46.09%] [G loss: 1.066331]\n",
      "epoch:34 step:27183[D loss: 0.404566, acc: 62.50%, op_acc: 42.19%] [G loss: 1.344398]\n",
      "epoch:34 step:27184[D loss: 0.328166, acc: 78.12%, op_acc: 50.78%] [G loss: 1.591406]\n",
      "epoch:34 step:27185[D loss: 0.491244, acc: 60.16%, op_acc: 35.16%] [G loss: 1.240705]\n",
      "epoch:34 step:27186[D loss: 0.392913, acc: 67.19%, op_acc: 44.53%] [G loss: 1.456895]\n",
      "epoch:34 step:27187[D loss: 0.366457, acc: 68.75%, op_acc: 46.88%] [G loss: 1.109456]\n",
      "epoch:34 step:27188[D loss: 0.409353, acc: 66.41%, op_acc: 53.91%] [G loss: 1.181208]\n",
      "epoch:34 step:27189[D loss: 0.429851, acc: 60.94%, op_acc: 42.19%] [G loss: 1.056007]\n",
      "epoch:34 step:27190[D loss: 0.358073, acc: 64.06%, op_acc: 49.22%] [G loss: 1.141745]\n",
      "epoch:34 step:27191[D loss: 0.379014, acc: 70.31%, op_acc: 50.00%] [G loss: 1.289785]\n",
      "epoch:34 step:27192[D loss: 0.398184, acc: 58.59%, op_acc: 48.44%] [G loss: 1.328097]\n",
      "epoch:34 step:27193[D loss: 0.355716, acc: 72.66%, op_acc: 55.47%] [G loss: 1.657212]\n",
      "epoch:34 step:27194[D loss: 0.386400, acc: 72.66%, op_acc: 43.75%] [G loss: 1.581855]\n",
      "epoch:34 step:27195[D loss: 0.337568, acc: 75.00%, op_acc: 46.09%] [G loss: 1.373573]\n",
      "epoch:34 step:27196[D loss: 0.409058, acc: 67.19%, op_acc: 43.75%] [G loss: 1.159716]\n",
      "epoch:34 step:27197[D loss: 0.423199, acc: 60.94%, op_acc: 37.50%] [G loss: 1.083756]\n",
      "epoch:34 step:27198[D loss: 0.358942, acc: 70.31%, op_acc: 50.00%] [G loss: 1.331275]\n",
      "epoch:34 step:27199[D loss: 0.338057, acc: 75.00%, op_acc: 47.66%] [G loss: 1.408345]\n",
      "epoch:34 step:27200[D loss: 0.370139, acc: 73.44%, op_acc: 49.22%] [G loss: 1.603542]\n",
      "epoch:34 step:27201[D loss: 0.402938, acc: 66.41%, op_acc: 46.88%] [G loss: 1.331157]\n",
      "epoch:34 step:27202[D loss: 0.369769, acc: 70.31%, op_acc: 42.19%] [G loss: 1.338325]\n",
      "epoch:34 step:27203[D loss: 0.338945, acc: 76.56%, op_acc: 42.19%] [G loss: 1.292440]\n",
      "epoch:34 step:27204[D loss: 0.392653, acc: 64.06%, op_acc: 42.97%] [G loss: 1.388866]\n",
      "epoch:34 step:27205[D loss: 0.422603, acc: 62.50%, op_acc: 50.78%] [G loss: 1.127169]\n",
      "epoch:34 step:27206[D loss: 0.451095, acc: 57.81%, op_acc: 49.22%] [G loss: 1.103598]\n",
      "epoch:34 step:27207[D loss: 0.406650, acc: 64.84%, op_acc: 46.88%] [G loss: 1.182339]\n",
      "epoch:34 step:27208[D loss: 0.403822, acc: 65.62%, op_acc: 49.22%] [G loss: 1.038411]\n",
      "epoch:34 step:27209[D loss: 0.410088, acc: 66.41%, op_acc: 47.66%] [G loss: 1.121339]\n",
      "epoch:34 step:27210[D loss: 0.414814, acc: 70.31%, op_acc: 45.31%] [G loss: 1.155662]\n",
      "epoch:34 step:27211[D loss: 0.417082, acc: 61.72%, op_acc: 46.88%] [G loss: 1.311217]\n",
      "epoch:34 step:27212[D loss: 0.358295, acc: 74.22%, op_acc: 41.41%] [G loss: 1.367976]\n",
      "epoch:34 step:27213[D loss: 0.291458, acc: 85.16%, op_acc: 52.34%] [G loss: 1.295595]\n",
      "epoch:34 step:27214[D loss: 0.380831, acc: 66.41%, op_acc: 46.88%] [G loss: 1.088289]\n",
      "epoch:34 step:27215[D loss: 0.437701, acc: 54.69%, op_acc: 46.88%] [G loss: 1.265658]\n",
      "epoch:34 step:27216[D loss: 0.413072, acc: 63.28%, op_acc: 44.53%] [G loss: 1.229239]\n",
      "epoch:34 step:27217[D loss: 0.403577, acc: 64.84%, op_acc: 45.31%] [G loss: 1.205053]\n",
      "epoch:34 step:27218[D loss: 0.444617, acc: 58.59%, op_acc: 34.38%] [G loss: 1.012457]\n",
      "epoch:34 step:27219[D loss: 0.420560, acc: 63.28%, op_acc: 42.97%] [G loss: 1.001509]\n",
      "epoch:34 step:27220[D loss: 0.416496, acc: 65.62%, op_acc: 44.53%] [G loss: 0.907955]\n",
      "epoch:34 step:27221[D loss: 0.343317, acc: 75.78%, op_acc: 43.75%] [G loss: 1.058721]\n",
      "epoch:34 step:27222[D loss: 0.363198, acc: 75.00%, op_acc: 44.53%] [G loss: 1.213166]\n",
      "epoch:34 step:27223[D loss: 0.413016, acc: 62.50%, op_acc: 46.09%] [G loss: 1.099006]\n",
      "epoch:34 step:27224[D loss: 0.430581, acc: 58.59%, op_acc: 43.75%] [G loss: 1.305328]\n",
      "epoch:34 step:27225[D loss: 0.386118, acc: 73.44%, op_acc: 52.34%] [G loss: 1.037109]\n",
      "epoch:34 step:27226[D loss: 0.415533, acc: 64.84%, op_acc: 42.19%] [G loss: 1.028019]\n",
      "epoch:34 step:27227[D loss: 0.430010, acc: 64.06%, op_acc: 42.19%] [G loss: 1.157644]\n",
      "epoch:34 step:27228[D loss: 0.463215, acc: 53.12%, op_acc: 46.88%] [G loss: 0.953719]\n",
      "epoch:34 step:27229[D loss: 0.290523, acc: 82.03%, op_acc: 50.00%] [G loss: 1.045139]\n",
      "epoch:34 step:27230[D loss: 0.456364, acc: 53.91%, op_acc: 42.97%] [G loss: 0.929577]\n",
      "epoch:34 step:27231[D loss: 0.398803, acc: 69.53%, op_acc: 32.03%] [G loss: 1.004751]\n",
      "epoch:34 step:27232[D loss: 0.355018, acc: 72.66%, op_acc: 46.09%] [G loss: 0.973514]\n",
      "epoch:34 step:27233[D loss: 0.366170, acc: 70.31%, op_acc: 41.41%] [G loss: 0.918746]\n",
      "epoch:34 step:27234[D loss: 0.362504, acc: 78.12%, op_acc: 41.41%] [G loss: 0.878472]\n",
      "epoch:34 step:27235[D loss: 0.420143, acc: 64.84%, op_acc: 40.62%] [G loss: 1.373132]\n",
      "epoch:34 step:27236[D loss: 0.349845, acc: 72.66%, op_acc: 53.12%] [G loss: 1.057870]\n",
      "epoch:34 step:27237[D loss: 0.384626, acc: 67.19%, op_acc: 49.22%] [G loss: 1.006162]\n",
      "epoch:34 step:27238[D loss: 0.440323, acc: 61.72%, op_acc: 42.19%] [G loss: 0.894561]\n",
      "epoch:34 step:27239[D loss: 0.395379, acc: 75.78%, op_acc: 39.84%] [G loss: 1.224019]\n",
      "epoch:34 step:27240[D loss: 0.445679, acc: 65.62%, op_acc: 39.84%] [G loss: 1.013775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:27241[D loss: 0.348289, acc: 72.66%, op_acc: 39.06%] [G loss: 1.258014]\n",
      "epoch:34 step:27242[D loss: 0.387105, acc: 67.19%, op_acc: 49.22%] [G loss: 1.001581]\n",
      "epoch:34 step:27243[D loss: 0.406745, acc: 60.16%, op_acc: 50.78%] [G loss: 1.106275]\n",
      "epoch:34 step:27244[D loss: 0.297854, acc: 85.16%, op_acc: 49.22%] [G loss: 1.427293]\n",
      "epoch:34 step:27245[D loss: 0.309774, acc: 76.56%, op_acc: 51.56%] [G loss: 1.554132]\n",
      "epoch:34 step:27246[D loss: 0.476491, acc: 63.28%, op_acc: 45.31%] [G loss: 1.178269]\n",
      "epoch:34 step:27247[D loss: 0.425875, acc: 65.62%, op_acc: 41.41%] [G loss: 1.135920]\n",
      "epoch:34 step:27248[D loss: 0.478365, acc: 53.12%, op_acc: 36.72%] [G loss: 1.393555]\n",
      "epoch:34 step:27249[D loss: 0.343435, acc: 75.00%, op_acc: 43.75%] [G loss: 1.352248]\n",
      "epoch:34 step:27250[D loss: 0.391704, acc: 64.84%, op_acc: 46.09%] [G loss: 1.190936]\n",
      "epoch:34 step:27251[D loss: 0.407722, acc: 60.94%, op_acc: 49.22%] [G loss: 1.216664]\n",
      "epoch:34 step:27252[D loss: 0.393387, acc: 68.75%, op_acc: 33.59%] [G loss: 1.308375]\n",
      "epoch:34 step:27253[D loss: 0.428843, acc: 63.28%, op_acc: 44.53%] [G loss: 1.144388]\n",
      "epoch:34 step:27254[D loss: 0.368581, acc: 75.00%, op_acc: 47.66%] [G loss: 1.245587]\n",
      "epoch:34 step:27255[D loss: 0.369203, acc: 73.44%, op_acc: 44.53%] [G loss: 1.236928]\n",
      "epoch:34 step:27256[D loss: 0.393565, acc: 64.06%, op_acc: 46.88%] [G loss: 1.317522]\n",
      "epoch:34 step:27257[D loss: 0.430674, acc: 57.03%, op_acc: 46.09%] [G loss: 1.079362]\n",
      "epoch:34 step:27258[D loss: 0.317404, acc: 75.00%, op_acc: 50.78%] [G loss: 1.148643]\n",
      "epoch:34 step:27259[D loss: 0.377802, acc: 73.44%, op_acc: 45.31%] [G loss: 1.140459]\n",
      "epoch:34 step:27260[D loss: 0.342144, acc: 75.00%, op_acc: 45.31%] [G loss: 1.191377]\n",
      "epoch:34 step:27261[D loss: 0.452824, acc: 59.38%, op_acc: 46.88%] [G loss: 1.256249]\n",
      "epoch:34 step:27262[D loss: 0.355325, acc: 73.44%, op_acc: 46.09%] [G loss: 1.087511]\n",
      "epoch:34 step:27263[D loss: 0.329926, acc: 74.22%, op_acc: 45.31%] [G loss: 1.166251]\n",
      "epoch:34 step:27264[D loss: 0.323366, acc: 79.69%, op_acc: 47.66%] [G loss: 1.344177]\n",
      "epoch:34 step:27265[D loss: 0.347197, acc: 76.56%, op_acc: 52.34%] [G loss: 1.498951]\n",
      "epoch:34 step:27266[D loss: 0.404176, acc: 64.06%, op_acc: 43.75%] [G loss: 1.407041]\n",
      "epoch:34 step:27267[D loss: 0.357594, acc: 74.22%, op_acc: 47.66%] [G loss: 1.266094]\n",
      "epoch:34 step:27268[D loss: 0.358421, acc: 75.00%, op_acc: 45.31%] [G loss: 1.332337]\n",
      "epoch:34 step:27269[D loss: 0.347342, acc: 77.34%, op_acc: 42.97%] [G loss: 1.372521]\n",
      "epoch:34 step:27270[D loss: 0.314621, acc: 79.69%, op_acc: 53.91%] [G loss: 0.980033]\n",
      "epoch:34 step:27271[D loss: 0.319499, acc: 76.56%, op_acc: 51.56%] [G loss: 1.449692]\n",
      "epoch:34 step:27272[D loss: 0.373737, acc: 68.75%, op_acc: 42.97%] [G loss: 1.406180]\n",
      "epoch:34 step:27273[D loss: 0.350277, acc: 75.00%, op_acc: 50.00%] [G loss: 1.022940]\n",
      "epoch:34 step:27274[D loss: 0.365287, acc: 71.09%, op_acc: 51.56%] [G loss: 0.853142]\n",
      "epoch:34 step:27275[D loss: 0.380569, acc: 70.31%, op_acc: 46.88%] [G loss: 1.123719]\n",
      "epoch:34 step:27276[D loss: 0.389375, acc: 65.62%, op_acc: 48.44%] [G loss: 0.932754]\n",
      "epoch:34 step:27277[D loss: 0.395567, acc: 65.62%, op_acc: 45.31%] [G loss: 1.291481]\n",
      "epoch:34 step:27278[D loss: 0.474873, acc: 62.50%, op_acc: 43.75%] [G loss: 1.370345]\n",
      "epoch:34 step:27279[D loss: 0.361909, acc: 68.75%, op_acc: 46.09%] [G loss: 1.481247]\n",
      "epoch:34 step:27280[D loss: 0.284056, acc: 81.25%, op_acc: 50.00%] [G loss: 1.515953]\n",
      "epoch:34 step:27281[D loss: 0.393443, acc: 73.44%, op_acc: 50.78%] [G loss: 1.194854]\n",
      "epoch:34 step:27282[D loss: 0.409451, acc: 67.19%, op_acc: 33.59%] [G loss: 0.966021]\n",
      "epoch:34 step:27283[D loss: 0.350343, acc: 71.09%, op_acc: 45.31%] [G loss: 1.183091]\n",
      "epoch:34 step:27284[D loss: 0.368091, acc: 70.31%, op_acc: 50.00%] [G loss: 1.591764]\n",
      "epoch:34 step:27285[D loss: 0.386243, acc: 71.09%, op_acc: 47.66%] [G loss: 1.183869]\n",
      "epoch:34 step:27286[D loss: 0.365054, acc: 69.53%, op_acc: 47.66%] [G loss: 1.458669]\n",
      "epoch:34 step:27287[D loss: 0.425350, acc: 62.50%, op_acc: 41.41%] [G loss: 1.317612]\n",
      "epoch:34 step:27288[D loss: 0.444818, acc: 59.38%, op_acc: 38.28%] [G loss: 1.088230]\n",
      "epoch:34 step:27289[D loss: 0.400557, acc: 67.19%, op_acc: 42.97%] [G loss: 1.312253]\n",
      "epoch:34 step:27290[D loss: 0.346809, acc: 77.34%, op_acc: 39.06%] [G loss: 1.315665]\n",
      "epoch:34 step:27291[D loss: 0.399058, acc: 66.41%, op_acc: 51.56%] [G loss: 1.327777]\n",
      "epoch:34 step:27292[D loss: 0.440728, acc: 67.19%, op_acc: 41.41%] [G loss: 1.421583]\n",
      "epoch:34 step:27293[D loss: 0.365323, acc: 68.75%, op_acc: 42.19%] [G loss: 1.249745]\n",
      "epoch:34 step:27294[D loss: 0.351867, acc: 74.22%, op_acc: 48.44%] [G loss: 1.448019]\n",
      "epoch:34 step:27295[D loss: 0.348900, acc: 78.91%, op_acc: 45.31%] [G loss: 1.185651]\n",
      "epoch:34 step:27296[D loss: 0.397448, acc: 68.75%, op_acc: 46.09%] [G loss: 1.132959]\n",
      "epoch:34 step:27297[D loss: 0.350804, acc: 76.56%, op_acc: 45.31%] [G loss: 1.008736]\n",
      "epoch:34 step:27298[D loss: 0.307669, acc: 78.91%, op_acc: 50.78%] [G loss: 1.238518]\n",
      "epoch:34 step:27299[D loss: 0.389630, acc: 67.97%, op_acc: 46.88%] [G loss: 1.143503]\n",
      "epoch:34 step:27300[D loss: 0.449115, acc: 57.03%, op_acc: 40.62%] [G loss: 1.421357]\n",
      "epoch:34 step:27301[D loss: 0.376741, acc: 73.44%, op_acc: 50.78%] [G loss: 1.242539]\n",
      "epoch:34 step:27302[D loss: 0.384879, acc: 65.62%, op_acc: 42.97%] [G loss: 1.073094]\n",
      "epoch:34 step:27303[D loss: 0.404870, acc: 65.62%, op_acc: 46.88%] [G loss: 1.037840]\n",
      "epoch:34 step:27304[D loss: 0.438295, acc: 61.72%, op_acc: 42.97%] [G loss: 0.972056]\n",
      "epoch:34 step:27305[D loss: 0.407586, acc: 64.06%, op_acc: 35.94%] [G loss: 1.182641]\n",
      "epoch:34 step:27306[D loss: 0.375807, acc: 71.88%, op_acc: 48.44%] [G loss: 1.294364]\n",
      "epoch:34 step:27307[D loss: 0.385115, acc: 64.84%, op_acc: 44.53%] [G loss: 1.241885]\n",
      "epoch:34 step:27308[D loss: 0.380809, acc: 73.44%, op_acc: 43.75%] [G loss: 0.794510]\n",
      "epoch:34 step:27309[D loss: 0.375321, acc: 65.62%, op_acc: 58.59%] [G loss: 1.121977]\n",
      "epoch:34 step:27310[D loss: 0.397876, acc: 64.84%, op_acc: 49.22%] [G loss: 1.085589]\n",
      "epoch:34 step:27311[D loss: 0.357887, acc: 69.53%, op_acc: 47.66%] [G loss: 1.058538]\n",
      "epoch:34 step:27312[D loss: 0.374786, acc: 60.16%, op_acc: 42.97%] [G loss: 0.949139]\n",
      "epoch:34 step:27313[D loss: 0.380875, acc: 67.97%, op_acc: 45.31%] [G loss: 1.041097]\n",
      "epoch:34 step:27314[D loss: 0.375266, acc: 71.88%, op_acc: 46.88%] [G loss: 1.193087]\n",
      "epoch:34 step:27315[D loss: 0.299532, acc: 81.25%, op_acc: 53.91%] [G loss: 1.105878]\n",
      "epoch:34 step:27316[D loss: 0.389775, acc: 67.19%, op_acc: 39.06%] [G loss: 1.216683]\n",
      "epoch:34 step:27317[D loss: 0.438239, acc: 59.38%, op_acc: 40.62%] [G loss: 0.963873]\n",
      "epoch:34 step:27318[D loss: 0.348808, acc: 69.53%, op_acc: 39.06%] [G loss: 1.046632]\n",
      "epoch:34 step:27319[D loss: 0.350041, acc: 74.22%, op_acc: 49.22%] [G loss: 1.063989]\n",
      "epoch:34 step:27320[D loss: 0.475959, acc: 56.25%, op_acc: 41.41%] [G loss: 0.844184]\n",
      "epoch:34 step:27321[D loss: 0.359539, acc: 75.00%, op_acc: 46.09%] [G loss: 1.265574]\n",
      "epoch:34 step:27322[D loss: 0.369123, acc: 73.44%, op_acc: 44.53%] [G loss: 1.053450]\n",
      "epoch:34 step:27323[D loss: 0.350227, acc: 74.22%, op_acc: 48.44%] [G loss: 0.838884]\n",
      "epoch:34 step:27324[D loss: 0.373049, acc: 71.09%, op_acc: 46.09%] [G loss: 1.036565]\n",
      "epoch:34 step:27325[D loss: 0.471450, acc: 55.47%, op_acc: 40.62%] [G loss: 1.154659]\n",
      "epoch:34 step:27326[D loss: 0.424433, acc: 65.62%, op_acc: 43.75%] [G loss: 1.163331]\n",
      "epoch:34 step:27327[D loss: 0.425532, acc: 63.28%, op_acc: 47.66%] [G loss: 1.242445]\n",
      "epoch:34 step:27328[D loss: 0.339053, acc: 72.66%, op_acc: 50.78%] [G loss: 1.374138]\n",
      "epoch:34 step:27329[D loss: 0.394712, acc: 66.41%, op_acc: 47.66%] [G loss: 0.999100]\n",
      "epoch:34 step:27330[D loss: 0.385761, acc: 71.09%, op_acc: 45.31%] [G loss: 0.933029]\n",
      "epoch:34 step:27331[D loss: 0.399129, acc: 63.28%, op_acc: 42.97%] [G loss: 0.999806]\n",
      "epoch:34 step:27332[D loss: 0.339060, acc: 76.56%, op_acc: 57.03%] [G loss: 0.961665]\n",
      "epoch:34 step:27333[D loss: 0.364555, acc: 68.75%, op_acc: 50.78%] [G loss: 0.954736]\n",
      "epoch:34 step:27334[D loss: 0.369295, acc: 71.09%, op_acc: 46.09%] [G loss: 0.906367]\n",
      "epoch:34 step:27335[D loss: 0.325020, acc: 79.69%, op_acc: 49.22%] [G loss: 1.348685]\n",
      "epoch:35 step:27336[D loss: 0.313357, acc: 78.91%, op_acc: 55.47%] [G loss: 1.033515]\n",
      "epoch:35 step:27337[D loss: 0.358238, acc: 75.78%, op_acc: 49.22%] [G loss: 1.370657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27338[D loss: 0.437337, acc: 57.81%, op_acc: 40.62%] [G loss: 0.827937]\n",
      "epoch:35 step:27339[D loss: 0.302397, acc: 82.81%, op_acc: 53.91%] [G loss: 0.991690]\n",
      "epoch:35 step:27340[D loss: 0.361388, acc: 72.66%, op_acc: 44.53%] [G loss: 1.095234]\n",
      "epoch:35 step:27341[D loss: 0.390980, acc: 67.19%, op_acc: 41.41%] [G loss: 1.128772]\n",
      "epoch:35 step:27342[D loss: 0.383329, acc: 67.19%, op_acc: 48.44%] [G loss: 1.178083]\n",
      "epoch:35 step:27343[D loss: 0.390346, acc: 71.09%, op_acc: 44.53%] [G loss: 1.372957]\n",
      "epoch:35 step:27344[D loss: 0.359773, acc: 67.19%, op_acc: 49.22%] [G loss: 1.357221]\n",
      "epoch:35 step:27345[D loss: 0.368255, acc: 68.75%, op_acc: 46.88%] [G loss: 1.126106]\n",
      "epoch:35 step:27346[D loss: 0.429643, acc: 65.62%, op_acc: 44.53%] [G loss: 0.912291]\n",
      "epoch:35 step:27347[D loss: 0.363687, acc: 75.00%, op_acc: 39.06%] [G loss: 1.032379]\n",
      "epoch:35 step:27348[D loss: 0.401177, acc: 65.62%, op_acc: 47.66%] [G loss: 1.337275]\n",
      "epoch:35 step:27349[D loss: 0.364091, acc: 73.44%, op_acc: 46.88%] [G loss: 0.995026]\n",
      "epoch:35 step:27350[D loss: 0.376867, acc: 67.19%, op_acc: 48.44%] [G loss: 0.923401]\n",
      "epoch:35 step:27351[D loss: 0.340468, acc: 73.44%, op_acc: 46.09%] [G loss: 1.175925]\n",
      "epoch:35 step:27352[D loss: 0.344395, acc: 68.75%, op_acc: 50.78%] [G loss: 0.872198]\n",
      "epoch:35 step:27353[D loss: 0.456852, acc: 56.25%, op_acc: 37.50%] [G loss: 0.912978]\n",
      "epoch:35 step:27354[D loss: 0.398980, acc: 65.62%, op_acc: 38.28%] [G loss: 1.263040]\n",
      "epoch:35 step:27355[D loss: 0.335298, acc: 78.12%, op_acc: 47.66%] [G loss: 1.233193]\n",
      "epoch:35 step:27356[D loss: 0.375281, acc: 72.66%, op_acc: 36.72%] [G loss: 1.061606]\n",
      "epoch:35 step:27357[D loss: 0.338171, acc: 71.88%, op_acc: 49.22%] [G loss: 1.234816]\n",
      "epoch:35 step:27358[D loss: 0.385849, acc: 67.97%, op_acc: 42.19%] [G loss: 0.935032]\n",
      "epoch:35 step:27359[D loss: 0.393978, acc: 68.75%, op_acc: 40.62%] [G loss: 1.230510]\n",
      "epoch:35 step:27360[D loss: 0.460339, acc: 57.81%, op_acc: 35.16%] [G loss: 0.900100]\n",
      "epoch:35 step:27361[D loss: 0.331423, acc: 77.34%, op_acc: 53.91%] [G loss: 1.024407]\n",
      "epoch:35 step:27362[D loss: 0.374105, acc: 69.53%, op_acc: 47.66%] [G loss: 1.495009]\n",
      "epoch:35 step:27363[D loss: 0.411806, acc: 64.84%, op_acc: 42.97%] [G loss: 0.769752]\n",
      "epoch:35 step:27364[D loss: 0.365837, acc: 71.09%, op_acc: 47.66%] [G loss: 0.806615]\n",
      "epoch:35 step:27365[D loss: 0.362683, acc: 71.09%, op_acc: 50.78%] [G loss: 0.618202]\n",
      "epoch:35 step:27366[D loss: 0.382573, acc: 73.44%, op_acc: 42.97%] [G loss: 0.895695]\n",
      "epoch:35 step:27367[D loss: 0.412306, acc: 64.84%, op_acc: 44.53%] [G loss: 0.855784]\n",
      "epoch:35 step:27368[D loss: 0.360773, acc: 71.09%, op_acc: 49.22%] [G loss: 1.252355]\n",
      "epoch:35 step:27369[D loss: 0.332887, acc: 75.78%, op_acc: 49.22%] [G loss: 1.292289]\n",
      "epoch:35 step:27370[D loss: 0.309094, acc: 82.03%, op_acc: 52.34%] [G loss: 1.629032]\n",
      "epoch:35 step:27371[D loss: 0.389361, acc: 72.66%, op_acc: 43.75%] [G loss: 1.046221]\n",
      "epoch:35 step:27372[D loss: 0.359340, acc: 71.88%, op_acc: 44.53%] [G loss: 0.884107]\n",
      "epoch:35 step:27373[D loss: 0.438229, acc: 57.81%, op_acc: 47.66%] [G loss: 1.238156]\n",
      "epoch:35 step:27374[D loss: 0.396166, acc: 61.72%, op_acc: 44.53%] [G loss: 1.417132]\n",
      "epoch:35 step:27375[D loss: 0.432025, acc: 63.28%, op_acc: 44.53%] [G loss: 0.661174]\n",
      "epoch:35 step:27376[D loss: 0.387301, acc: 67.19%, op_acc: 47.66%] [G loss: 1.017917]\n",
      "epoch:35 step:27377[D loss: 0.324395, acc: 74.22%, op_acc: 53.91%] [G loss: 1.151963]\n",
      "epoch:35 step:27378[D loss: 0.389762, acc: 65.62%, op_acc: 39.06%] [G loss: 1.299139]\n",
      "epoch:35 step:27379[D loss: 0.334724, acc: 75.00%, op_acc: 49.22%] [G loss: 1.087873]\n",
      "epoch:35 step:27380[D loss: 0.348816, acc: 69.53%, op_acc: 50.78%] [G loss: 0.705516]\n",
      "epoch:35 step:27381[D loss: 0.372835, acc: 68.75%, op_acc: 48.44%] [G loss: 0.960729]\n",
      "epoch:35 step:27382[D loss: 0.356948, acc: 73.44%, op_acc: 40.62%] [G loss: 0.917172]\n",
      "epoch:35 step:27383[D loss: 0.411930, acc: 58.59%, op_acc: 47.66%] [G loss: 1.213952]\n",
      "epoch:35 step:27384[D loss: 0.290042, acc: 83.59%, op_acc: 45.31%] [G loss: 0.954098]\n",
      "epoch:35 step:27385[D loss: 0.359946, acc: 75.00%, op_acc: 46.88%] [G loss: 0.795732]\n",
      "epoch:35 step:27386[D loss: 0.407324, acc: 68.75%, op_acc: 42.97%] [G loss: 1.075587]\n",
      "epoch:35 step:27387[D loss: 0.428037, acc: 60.16%, op_acc: 41.41%] [G loss: 1.113870]\n",
      "epoch:35 step:27388[D loss: 0.410683, acc: 67.97%, op_acc: 42.19%] [G loss: 0.884563]\n",
      "epoch:35 step:27389[D loss: 0.396420, acc: 64.84%, op_acc: 49.22%] [G loss: 0.775200]\n",
      "epoch:35 step:27390[D loss: 0.381529, acc: 64.84%, op_acc: 50.00%] [G loss: 0.742076]\n",
      "epoch:35 step:27391[D loss: 0.355979, acc: 70.31%, op_acc: 53.91%] [G loss: 0.873762]\n",
      "epoch:35 step:27392[D loss: 0.412319, acc: 63.28%, op_acc: 47.66%] [G loss: 1.115449]\n",
      "epoch:35 step:27393[D loss: 0.271795, acc: 85.94%, op_acc: 59.38%] [G loss: 1.171416]\n",
      "epoch:35 step:27394[D loss: 0.282498, acc: 80.47%, op_acc: 56.25%] [G loss: 1.355932]\n",
      "epoch:35 step:27395[D loss: 0.270617, acc: 85.94%, op_acc: 49.22%] [G loss: 1.363458]\n",
      "epoch:35 step:27396[D loss: 0.308529, acc: 82.81%, op_acc: 46.09%] [G loss: 1.445636]\n",
      "epoch:35 step:27397[D loss: 0.237403, acc: 90.62%, op_acc: 60.94%] [G loss: 1.447637]\n",
      "epoch:35 step:27398[D loss: 0.287376, acc: 81.25%, op_acc: 58.59%] [G loss: 1.559841]\n",
      "epoch:35 step:27399[D loss: 0.240578, acc: 88.28%, op_acc: 58.59%] [G loss: 1.444818]\n",
      "epoch:35 step:27400[D loss: 0.340977, acc: 68.75%, op_acc: 46.88%] [G loss: 1.129406]\n",
      "epoch:35 step:27401[D loss: 0.307658, acc: 79.69%, op_acc: 52.34%] [G loss: 1.474052]\n",
      "epoch:35 step:27402[D loss: 0.250822, acc: 90.62%, op_acc: 57.81%] [G loss: 1.720983]\n",
      "epoch:35 step:27403[D loss: 0.363017, acc: 71.09%, op_acc: 43.75%] [G loss: 1.210202]\n",
      "epoch:35 step:27404[D loss: 0.379999, acc: 68.75%, op_acc: 49.22%] [G loss: 1.143369]\n",
      "epoch:35 step:27405[D loss: 0.395236, acc: 65.62%, op_acc: 42.19%] [G loss: 0.934132]\n",
      "epoch:35 step:27406[D loss: 0.435679, acc: 60.94%, op_acc: 38.28%] [G loss: 1.901531]\n",
      "epoch:35 step:27407[D loss: 0.295691, acc: 80.47%, op_acc: 57.03%] [G loss: 0.793944]\n",
      "epoch:35 step:27408[D loss: 0.558050, acc: 44.53%, op_acc: 33.59%] [G loss: 1.704351]\n",
      "epoch:35 step:27409[D loss: 0.428619, acc: 57.81%, op_acc: 40.62%] [G loss: 0.757458]\n",
      "epoch:35 step:27410[D loss: 0.379849, acc: 68.75%, op_acc: 42.97%] [G loss: 1.363668]\n",
      "epoch:35 step:27411[D loss: 0.435664, acc: 60.94%, op_acc: 38.28%] [G loss: 2.029269]\n",
      "epoch:35 step:27412[D loss: 0.479572, acc: 58.59%, op_acc: 33.59%] [G loss: 1.137094]\n",
      "epoch:35 step:27413[D loss: 0.428320, acc: 67.19%, op_acc: 33.59%] [G loss: 1.838344]\n",
      "epoch:35 step:27414[D loss: 0.361855, acc: 73.44%, op_acc: 42.97%] [G loss: 1.565019]\n",
      "epoch:35 step:27415[D loss: 0.406561, acc: 66.41%, op_acc: 38.28%] [G loss: 1.209063]\n",
      "epoch:35 step:27416[D loss: 0.424937, acc: 62.50%, op_acc: 39.84%] [G loss: 1.243992]\n",
      "epoch:35 step:27417[D loss: 0.387368, acc: 67.97%, op_acc: 45.31%] [G loss: 1.413810]\n",
      "epoch:35 step:27418[D loss: 0.362382, acc: 63.28%, op_acc: 44.53%] [G loss: 1.426612]\n",
      "epoch:35 step:27419[D loss: 0.333413, acc: 75.78%, op_acc: 46.88%] [G loss: 1.357765]\n",
      "epoch:35 step:27420[D loss: 0.421181, acc: 64.84%, op_acc: 40.62%] [G loss: 1.452120]\n",
      "epoch:35 step:27421[D loss: 0.380483, acc: 64.84%, op_acc: 46.88%] [G loss: 1.522988]\n",
      "epoch:35 step:27422[D loss: 0.362698, acc: 77.34%, op_acc: 43.75%] [G loss: 1.531111]\n",
      "epoch:35 step:27423[D loss: 0.424707, acc: 58.59%, op_acc: 39.84%] [G loss: 1.039318]\n",
      "epoch:35 step:27424[D loss: 0.379239, acc: 71.88%, op_acc: 42.19%] [G loss: 1.511359]\n",
      "epoch:35 step:27425[D loss: 0.406747, acc: 67.97%, op_acc: 46.09%] [G loss: 1.488659]\n",
      "epoch:35 step:27426[D loss: 0.398242, acc: 60.16%, op_acc: 42.97%] [G loss: 1.573271]\n",
      "epoch:35 step:27427[D loss: 0.467691, acc: 55.47%, op_acc: 42.97%] [G loss: 1.390982]\n",
      "epoch:35 step:27428[D loss: 0.396192, acc: 64.06%, op_acc: 42.97%] [G loss: 1.194478]\n",
      "epoch:35 step:27429[D loss: 0.321230, acc: 76.56%, op_acc: 51.56%] [G loss: 1.249357]\n",
      "epoch:35 step:27430[D loss: 0.369234, acc: 68.75%, op_acc: 50.78%] [G loss: 1.502817]\n",
      "epoch:35 step:27431[D loss: 0.315256, acc: 78.91%, op_acc: 48.44%] [G loss: 1.501622]\n",
      "epoch:35 step:27432[D loss: 0.355713, acc: 75.00%, op_acc: 54.69%] [G loss: 1.251997]\n",
      "epoch:35 step:27433[D loss: 0.399273, acc: 67.97%, op_acc: 36.72%] [G loss: 1.362740]\n",
      "epoch:35 step:27434[D loss: 0.404249, acc: 60.94%, op_acc: 46.09%] [G loss: 1.316700]\n",
      "epoch:35 step:27435[D loss: 0.336526, acc: 75.00%, op_acc: 47.66%] [G loss: 1.353855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27436[D loss: 0.375025, acc: 67.19%, op_acc: 39.84%] [G loss: 1.251309]\n",
      "epoch:35 step:27437[D loss: 0.392513, acc: 65.62%, op_acc: 51.56%] [G loss: 1.023845]\n",
      "epoch:35 step:27438[D loss: 0.413350, acc: 65.62%, op_acc: 36.72%] [G loss: 1.239367]\n",
      "epoch:35 step:27439[D loss: 0.352369, acc: 72.66%, op_acc: 48.44%] [G loss: 1.124040]\n",
      "epoch:35 step:27440[D loss: 0.422672, acc: 57.81%, op_acc: 46.88%] [G loss: 1.205604]\n",
      "epoch:35 step:27441[D loss: 0.375977, acc: 67.97%, op_acc: 44.53%] [G loss: 0.873961]\n",
      "epoch:35 step:27442[D loss: 0.444403, acc: 64.84%, op_acc: 39.06%] [G loss: 1.080889]\n",
      "epoch:35 step:27443[D loss: 0.388048, acc: 66.41%, op_acc: 48.44%] [G loss: 1.335258]\n",
      "epoch:35 step:27444[D loss: 0.445041, acc: 57.03%, op_acc: 38.28%] [G loss: 1.083395]\n",
      "epoch:35 step:27445[D loss: 0.380476, acc: 67.19%, op_acc: 39.06%] [G loss: 0.905836]\n",
      "epoch:35 step:27446[D loss: 0.401578, acc: 71.88%, op_acc: 42.19%] [G loss: 1.314670]\n",
      "epoch:35 step:27447[D loss: 0.386416, acc: 67.97%, op_acc: 40.62%] [G loss: 1.024736]\n",
      "epoch:35 step:27448[D loss: 0.351612, acc: 71.09%, op_acc: 42.97%] [G loss: 1.202140]\n",
      "epoch:35 step:27449[D loss: 0.373973, acc: 67.97%, op_acc: 46.09%] [G loss: 0.834986]\n",
      "epoch:35 step:27450[D loss: 0.334983, acc: 69.53%, op_acc: 54.69%] [G loss: 0.922719]\n",
      "epoch:35 step:27451[D loss: 0.448073, acc: 64.84%, op_acc: 44.53%] [G loss: 1.078886]\n",
      "epoch:35 step:27452[D loss: 0.358540, acc: 71.09%, op_acc: 47.66%] [G loss: 1.185711]\n",
      "epoch:35 step:27453[D loss: 0.440738, acc: 58.59%, op_acc: 46.09%] [G loss: 1.222069]\n",
      "epoch:35 step:27454[D loss: 0.350244, acc: 73.44%, op_acc: 46.09%] [G loss: 1.190619]\n",
      "epoch:35 step:27455[D loss: 0.400020, acc: 67.19%, op_acc: 38.28%] [G loss: 1.292504]\n",
      "epoch:35 step:27456[D loss: 0.348695, acc: 73.44%, op_acc: 47.66%] [G loss: 1.334629]\n",
      "epoch:35 step:27457[D loss: 0.419051, acc: 64.06%, op_acc: 47.66%] [G loss: 1.231095]\n",
      "epoch:35 step:27458[D loss: 0.399100, acc: 67.97%, op_acc: 42.97%] [G loss: 0.936012]\n",
      "epoch:35 step:27459[D loss: 0.411173, acc: 60.16%, op_acc: 43.75%] [G loss: 0.953213]\n",
      "epoch:35 step:27460[D loss: 0.373403, acc: 68.75%, op_acc: 49.22%] [G loss: 1.271652]\n",
      "epoch:35 step:27461[D loss: 0.361513, acc: 73.44%, op_acc: 48.44%] [G loss: 0.742121]\n",
      "epoch:35 step:27462[D loss: 0.325346, acc: 77.34%, op_acc: 47.66%] [G loss: 1.198262]\n",
      "epoch:35 step:27463[D loss: 0.361394, acc: 71.88%, op_acc: 40.62%] [G loss: 1.192986]\n",
      "epoch:35 step:27464[D loss: 0.390104, acc: 64.84%, op_acc: 41.41%] [G loss: 1.299711]\n",
      "epoch:35 step:27465[D loss: 0.352945, acc: 76.56%, op_acc: 54.69%] [G loss: 1.007803]\n",
      "epoch:35 step:27466[D loss: 0.383992, acc: 66.41%, op_acc: 47.66%] [G loss: 0.805752]\n",
      "epoch:35 step:27467[D loss: 0.338015, acc: 71.88%, op_acc: 46.88%] [G loss: 0.888298]\n",
      "epoch:35 step:27468[D loss: 0.385646, acc: 67.97%, op_acc: 44.53%] [G loss: 1.158558]\n",
      "epoch:35 step:27469[D loss: 0.435559, acc: 58.59%, op_acc: 46.09%] [G loss: 1.034743]\n",
      "epoch:35 step:27470[D loss: 0.392367, acc: 67.97%, op_acc: 46.88%] [G loss: 1.111476]\n",
      "epoch:35 step:27471[D loss: 0.348385, acc: 72.66%, op_acc: 52.34%] [G loss: 1.620904]\n",
      "epoch:35 step:27472[D loss: 0.398998, acc: 69.53%, op_acc: 46.88%] [G loss: 1.167169]\n",
      "epoch:35 step:27473[D loss: 0.388769, acc: 69.53%, op_acc: 47.66%] [G loss: 1.263419]\n",
      "epoch:35 step:27474[D loss: 0.315905, acc: 82.81%, op_acc: 58.59%] [G loss: 1.281900]\n",
      "epoch:35 step:27475[D loss: 0.448198, acc: 62.50%, op_acc: 42.19%] [G loss: 1.053468]\n",
      "epoch:35 step:27476[D loss: 0.389029, acc: 69.53%, op_acc: 38.28%] [G loss: 1.283368]\n",
      "epoch:35 step:27477[D loss: 0.415271, acc: 60.16%, op_acc: 42.97%] [G loss: 1.160628]\n",
      "epoch:35 step:27478[D loss: 0.382534, acc: 64.84%, op_acc: 41.41%] [G loss: 0.852646]\n",
      "epoch:35 step:27479[D loss: 0.444169, acc: 60.16%, op_acc: 50.00%] [G loss: 1.207404]\n",
      "epoch:35 step:27480[D loss: 0.385918, acc: 66.41%, op_acc: 45.31%] [G loss: 1.086591]\n",
      "epoch:35 step:27481[D loss: 0.436941, acc: 68.75%, op_acc: 39.06%] [G loss: 0.888376]\n",
      "epoch:35 step:27482[D loss: 0.350862, acc: 73.44%, op_acc: 45.31%] [G loss: 0.846565]\n",
      "epoch:35 step:27483[D loss: 0.400868, acc: 67.19%, op_acc: 46.09%] [G loss: 1.137612]\n",
      "epoch:35 step:27484[D loss: 0.297933, acc: 77.34%, op_acc: 58.59%] [G loss: 1.031730]\n",
      "epoch:35 step:27485[D loss: 0.326022, acc: 76.56%, op_acc: 49.22%] [G loss: 1.412312]\n",
      "epoch:35 step:27486[D loss: 0.323860, acc: 73.44%, op_acc: 50.78%] [G loss: 1.022219]\n",
      "epoch:35 step:27487[D loss: 0.361031, acc: 68.75%, op_acc: 50.78%] [G loss: 1.462227]\n",
      "epoch:35 step:27488[D loss: 0.419021, acc: 61.72%, op_acc: 40.62%] [G loss: 0.845812]\n",
      "epoch:35 step:27489[D loss: 0.356893, acc: 75.00%, op_acc: 46.88%] [G loss: 0.797278]\n",
      "epoch:35 step:27490[D loss: 0.314162, acc: 77.34%, op_acc: 46.09%] [G loss: 1.421440]\n",
      "epoch:35 step:27491[D loss: 0.375342, acc: 70.31%, op_acc: 46.88%] [G loss: 0.932854]\n",
      "epoch:35 step:27492[D loss: 0.337414, acc: 78.91%, op_acc: 50.78%] [G loss: 0.949634]\n",
      "epoch:35 step:27493[D loss: 0.381101, acc: 71.09%, op_acc: 46.09%] [G loss: 1.024164]\n",
      "epoch:35 step:27494[D loss: 0.391845, acc: 67.97%, op_acc: 47.66%] [G loss: 0.849201]\n",
      "epoch:35 step:27495[D loss: 0.392889, acc: 64.84%, op_acc: 39.84%] [G loss: 1.014179]\n",
      "epoch:35 step:27496[D loss: 0.375223, acc: 69.53%, op_acc: 51.56%] [G loss: 0.876394]\n",
      "epoch:35 step:27497[D loss: 0.398785, acc: 64.84%, op_acc: 48.44%] [G loss: 1.258550]\n",
      "epoch:35 step:27498[D loss: 0.353952, acc: 75.00%, op_acc: 46.88%] [G loss: 1.269547]\n",
      "epoch:35 step:27499[D loss: 0.387775, acc: 73.44%, op_acc: 38.28%] [G loss: 1.183104]\n",
      "epoch:35 step:27500[D loss: 0.329573, acc: 75.78%, op_acc: 49.22%] [G loss: 1.105689]\n",
      "epoch:35 step:27501[D loss: 0.446068, acc: 61.72%, op_acc: 34.38%] [G loss: 1.263995]\n",
      "epoch:35 step:27502[D loss: 0.341447, acc: 78.91%, op_acc: 47.66%] [G loss: 1.609902]\n",
      "epoch:35 step:27503[D loss: 0.339837, acc: 70.31%, op_acc: 46.09%] [G loss: 1.159860]\n",
      "epoch:35 step:27504[D loss: 0.328730, acc: 75.78%, op_acc: 49.22%] [G loss: 1.266108]\n",
      "epoch:35 step:27505[D loss: 0.346125, acc: 75.78%, op_acc: 56.25%] [G loss: 1.057943]\n",
      "epoch:35 step:27506[D loss: 0.365801, acc: 72.66%, op_acc: 45.31%] [G loss: 1.219953]\n",
      "epoch:35 step:27507[D loss: 0.337060, acc: 77.34%, op_acc: 51.56%] [G loss: 1.123498]\n",
      "epoch:35 step:27508[D loss: 0.331063, acc: 78.91%, op_acc: 47.66%] [G loss: 1.112531]\n",
      "epoch:35 step:27509[D loss: 0.406217, acc: 65.62%, op_acc: 48.44%] [G loss: 0.956176]\n",
      "epoch:35 step:27510[D loss: 0.349942, acc: 78.12%, op_acc: 49.22%] [G loss: 1.299077]\n",
      "epoch:35 step:27511[D loss: 0.376940, acc: 62.50%, op_acc: 42.97%] [G loss: 1.367499]\n",
      "epoch:35 step:27512[D loss: 0.415359, acc: 65.62%, op_acc: 42.97%] [G loss: 1.260248]\n",
      "epoch:35 step:27513[D loss: 0.460635, acc: 59.38%, op_acc: 35.94%] [G loss: 1.004128]\n",
      "epoch:35 step:27514[D loss: 0.319586, acc: 75.78%, op_acc: 56.25%] [G loss: 1.165836]\n",
      "epoch:35 step:27515[D loss: 0.367602, acc: 73.44%, op_acc: 46.88%] [G loss: 1.079573]\n",
      "epoch:35 step:27516[D loss: 0.340147, acc: 73.44%, op_acc: 51.56%] [G loss: 0.882049]\n",
      "epoch:35 step:27517[D loss: 0.390959, acc: 65.62%, op_acc: 45.31%] [G loss: 1.140203]\n",
      "epoch:35 step:27518[D loss: 0.320534, acc: 80.47%, op_acc: 55.47%] [G loss: 1.011077]\n",
      "epoch:35 step:27519[D loss: 0.399575, acc: 61.72%, op_acc: 52.34%] [G loss: 1.092054]\n",
      "epoch:35 step:27520[D loss: 0.320952, acc: 80.47%, op_acc: 47.66%] [G loss: 1.036504]\n",
      "epoch:35 step:27521[D loss: 0.372350, acc: 68.75%, op_acc: 50.78%] [G loss: 1.096243]\n",
      "epoch:35 step:27522[D loss: 0.323834, acc: 78.12%, op_acc: 52.34%] [G loss: 1.086169]\n",
      "epoch:35 step:27523[D loss: 0.462630, acc: 52.34%, op_acc: 48.44%] [G loss: 1.071755]\n",
      "epoch:35 step:27524[D loss: 0.334852, acc: 76.56%, op_acc: 44.53%] [G loss: 1.197741]\n",
      "epoch:35 step:27525[D loss: 0.362235, acc: 77.34%, op_acc: 44.53%] [G loss: 1.060165]\n",
      "epoch:35 step:27526[D loss: 0.338110, acc: 70.31%, op_acc: 53.12%] [G loss: 1.141091]\n",
      "epoch:35 step:27527[D loss: 0.282903, acc: 86.72%, op_acc: 43.75%] [G loss: 1.253466]\n",
      "epoch:35 step:27528[D loss: 0.467908, acc: 60.94%, op_acc: 39.06%] [G loss: 1.100854]\n",
      "epoch:35 step:27529[D loss: 0.405422, acc: 61.72%, op_acc: 46.88%] [G loss: 1.078783]\n",
      "epoch:35 step:27530[D loss: 0.380842, acc: 66.41%, op_acc: 47.66%] [G loss: 1.317750]\n",
      "epoch:35 step:27531[D loss: 0.291727, acc: 82.81%, op_acc: 52.34%] [G loss: 1.168249]\n",
      "epoch:35 step:27532[D loss: 0.415958, acc: 63.28%, op_acc: 46.88%] [G loss: 1.141936]\n",
      "epoch:35 step:27533[D loss: 0.320743, acc: 84.38%, op_acc: 48.44%] [G loss: 1.136401]\n",
      "epoch:35 step:27534[D loss: 0.377640, acc: 72.66%, op_acc: 46.09%] [G loss: 0.891779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27535[D loss: 0.346182, acc: 69.53%, op_acc: 51.56%] [G loss: 1.211424]\n",
      "epoch:35 step:27536[D loss: 0.295164, acc: 83.59%, op_acc: 54.69%] [G loss: 1.187045]\n",
      "epoch:35 step:27537[D loss: 0.372051, acc: 68.75%, op_acc: 51.56%] [G loss: 1.177286]\n",
      "epoch:35 step:27538[D loss: 0.334712, acc: 76.56%, op_acc: 42.19%] [G loss: 1.007577]\n",
      "epoch:35 step:27539[D loss: 0.317266, acc: 79.69%, op_acc: 53.91%] [G loss: 1.018857]\n",
      "epoch:35 step:27540[D loss: 0.311959, acc: 81.25%, op_acc: 50.00%] [G loss: 1.419211]\n",
      "epoch:35 step:27541[D loss: 0.358455, acc: 67.97%, op_acc: 46.09%] [G loss: 1.296367]\n",
      "epoch:35 step:27542[D loss: 0.385127, acc: 64.84%, op_acc: 46.88%] [G loss: 1.190514]\n",
      "epoch:35 step:27543[D loss: 0.342621, acc: 75.78%, op_acc: 47.66%] [G loss: 1.092703]\n",
      "epoch:35 step:27544[D loss: 0.293288, acc: 83.59%, op_acc: 50.00%] [G loss: 0.846775]\n",
      "epoch:35 step:27545[D loss: 0.431528, acc: 64.06%, op_acc: 39.84%] [G loss: 1.216164]\n",
      "epoch:35 step:27546[D loss: 0.324187, acc: 78.12%, op_acc: 49.22%] [G loss: 1.517961]\n",
      "epoch:35 step:27547[D loss: 0.358971, acc: 70.31%, op_acc: 53.12%] [G loss: 1.437127]\n",
      "epoch:35 step:27548[D loss: 0.340702, acc: 67.97%, op_acc: 53.12%] [G loss: 1.482794]\n",
      "epoch:35 step:27549[D loss: 0.340966, acc: 77.34%, op_acc: 49.22%] [G loss: 1.125667]\n",
      "epoch:35 step:27550[D loss: 0.414803, acc: 67.97%, op_acc: 45.31%] [G loss: 1.638617]\n",
      "epoch:35 step:27551[D loss: 0.379118, acc: 74.22%, op_acc: 50.78%] [G loss: 1.837786]\n",
      "epoch:35 step:27552[D loss: 0.335807, acc: 75.00%, op_acc: 59.38%] [G loss: 1.258549]\n",
      "epoch:35 step:27553[D loss: 0.384272, acc: 69.53%, op_acc: 51.56%] [G loss: 1.282601]\n",
      "epoch:35 step:27554[D loss: 0.331526, acc: 78.12%, op_acc: 54.69%] [G loss: 1.214460]\n",
      "epoch:35 step:27555[D loss: 0.395327, acc: 67.97%, op_acc: 49.22%] [G loss: 1.042498]\n",
      "epoch:35 step:27556[D loss: 0.383795, acc: 63.28%, op_acc: 46.88%] [G loss: 1.226539]\n",
      "epoch:35 step:27557[D loss: 0.376157, acc: 70.31%, op_acc: 48.44%] [G loss: 1.306755]\n",
      "epoch:35 step:27558[D loss: 0.391491, acc: 67.97%, op_acc: 40.62%] [G loss: 1.215430]\n",
      "epoch:35 step:27559[D loss: 0.362675, acc: 71.09%, op_acc: 46.88%] [G loss: 1.207524]\n",
      "epoch:35 step:27560[D loss: 0.393989, acc: 64.84%, op_acc: 49.22%] [G loss: 1.180272]\n",
      "epoch:35 step:27561[D loss: 0.379224, acc: 65.62%, op_acc: 46.09%] [G loss: 1.142807]\n",
      "epoch:35 step:27562[D loss: 0.324429, acc: 74.22%, op_acc: 50.78%] [G loss: 1.005015]\n",
      "epoch:35 step:27563[D loss: 0.397889, acc: 68.75%, op_acc: 48.44%] [G loss: 1.162853]\n",
      "epoch:35 step:27564[D loss: 0.380370, acc: 72.66%, op_acc: 46.88%] [G loss: 0.883357]\n",
      "epoch:35 step:27565[D loss: 0.482161, acc: 53.91%, op_acc: 42.19%] [G loss: 1.074312]\n",
      "epoch:35 step:27566[D loss: 0.360888, acc: 69.53%, op_acc: 46.88%] [G loss: 1.033387]\n",
      "epoch:35 step:27567[D loss: 0.374006, acc: 65.62%, op_acc: 46.88%] [G loss: 1.226512]\n",
      "epoch:35 step:27568[D loss: 0.455876, acc: 53.91%, op_acc: 46.88%] [G loss: 1.326405]\n",
      "epoch:35 step:27569[D loss: 0.390784, acc: 71.09%, op_acc: 42.19%] [G loss: 1.489637]\n",
      "epoch:35 step:27570[D loss: 0.379828, acc: 66.41%, op_acc: 46.88%] [G loss: 1.242650]\n",
      "epoch:35 step:27571[D loss: 0.400029, acc: 68.75%, op_acc: 46.88%] [G loss: 0.943836]\n",
      "epoch:35 step:27572[D loss: 0.323676, acc: 76.56%, op_acc: 53.12%] [G loss: 1.119226]\n",
      "epoch:35 step:27573[D loss: 0.399988, acc: 65.62%, op_acc: 47.66%] [G loss: 0.987642]\n",
      "epoch:35 step:27574[D loss: 0.399321, acc: 63.28%, op_acc: 43.75%] [G loss: 1.049416]\n",
      "epoch:35 step:27575[D loss: 0.383281, acc: 68.75%, op_acc: 49.22%] [G loss: 0.783276]\n",
      "epoch:35 step:27576[D loss: 0.395737, acc: 60.16%, op_acc: 46.09%] [G loss: 0.961035]\n",
      "epoch:35 step:27577[D loss: 0.359739, acc: 71.88%, op_acc: 51.56%] [G loss: 0.958688]\n",
      "epoch:35 step:27578[D loss: 0.371792, acc: 74.22%, op_acc: 54.69%] [G loss: 0.909386]\n",
      "epoch:35 step:27579[D loss: 0.362818, acc: 73.44%, op_acc: 47.66%] [G loss: 0.959713]\n",
      "epoch:35 step:27580[D loss: 0.465422, acc: 56.25%, op_acc: 47.66%] [G loss: 1.203841]\n",
      "epoch:35 step:27581[D loss: 0.352816, acc: 74.22%, op_acc: 50.00%] [G loss: 0.897266]\n",
      "epoch:35 step:27582[D loss: 0.391941, acc: 65.62%, op_acc: 45.31%] [G loss: 1.302854]\n",
      "epoch:35 step:27583[D loss: 0.406047, acc: 68.75%, op_acc: 40.62%] [G loss: 0.786040]\n",
      "epoch:35 step:27584[D loss: 0.401667, acc: 68.75%, op_acc: 38.28%] [G loss: 0.520056]\n",
      "epoch:35 step:27585[D loss: 0.349963, acc: 79.69%, op_acc: 46.09%] [G loss: 0.826857]\n",
      "epoch:35 step:27586[D loss: 0.352733, acc: 77.34%, op_acc: 48.44%] [G loss: 0.715193]\n",
      "epoch:35 step:27587[D loss: 0.373812, acc: 67.19%, op_acc: 44.53%] [G loss: 1.377782]\n",
      "epoch:35 step:27588[D loss: 0.372732, acc: 73.44%, op_acc: 42.97%] [G loss: 0.859679]\n",
      "epoch:35 step:27589[D loss: 0.458187, acc: 64.84%, op_acc: 42.19%] [G loss: 1.164434]\n",
      "epoch:35 step:27590[D loss: 0.395199, acc: 62.50%, op_acc: 47.66%] [G loss: 0.677392]\n",
      "epoch:35 step:27591[D loss: 0.365153, acc: 69.53%, op_acc: 45.31%] [G loss: 0.501786]\n",
      "epoch:35 step:27592[D loss: 0.387509, acc: 69.53%, op_acc: 39.06%] [G loss: 0.463796]\n",
      "epoch:35 step:27593[D loss: 0.410485, acc: 64.84%, op_acc: 44.53%] [G loss: 0.726431]\n",
      "epoch:35 step:27594[D loss: 0.410889, acc: 64.06%, op_acc: 39.84%] [G loss: 1.315607]\n",
      "epoch:35 step:27595[D loss: 0.341533, acc: 76.56%, op_acc: 50.00%] [G loss: 1.488260]\n",
      "epoch:35 step:27596[D loss: 0.369573, acc: 71.88%, op_acc: 43.75%] [G loss: 0.626627]\n",
      "epoch:35 step:27597[D loss: 0.344390, acc: 73.44%, op_acc: 46.09%] [G loss: 0.766266]\n",
      "epoch:35 step:27598[D loss: 0.368635, acc: 67.97%, op_acc: 42.97%] [G loss: 0.729455]\n",
      "epoch:35 step:27599[D loss: 0.376868, acc: 70.31%, op_acc: 46.88%] [G loss: 0.724039]\n",
      "epoch:35 step:27600[D loss: 0.314611, acc: 75.78%, op_acc: 55.47%] [G loss: 0.835876]\n",
      "epoch:35 step:27601[D loss: 0.469534, acc: 54.69%, op_acc: 40.62%] [G loss: 0.740279]\n",
      "epoch:35 step:27602[D loss: 0.431362, acc: 57.03%, op_acc: 39.06%] [G loss: 0.842276]\n",
      "epoch:35 step:27603[D loss: 0.327906, acc: 78.12%, op_acc: 53.91%] [G loss: 0.993858]\n",
      "epoch:35 step:27604[D loss: 0.433572, acc: 56.25%, op_acc: 44.53%] [G loss: 0.937495]\n",
      "epoch:35 step:27605[D loss: 0.324118, acc: 75.00%, op_acc: 50.00%] [G loss: 0.951645]\n",
      "epoch:35 step:27606[D loss: 0.350179, acc: 75.00%, op_acc: 45.31%] [G loss: 1.235657]\n",
      "epoch:35 step:27607[D loss: 0.385466, acc: 66.41%, op_acc: 52.34%] [G loss: 1.169716]\n",
      "epoch:35 step:27608[D loss: 0.389598, acc: 62.50%, op_acc: 53.91%] [G loss: 0.982062]\n",
      "epoch:35 step:27609[D loss: 0.305391, acc: 81.25%, op_acc: 53.12%] [G loss: 1.240174]\n",
      "epoch:35 step:27610[D loss: 0.333831, acc: 74.22%, op_acc: 53.12%] [G loss: 1.366812]\n",
      "epoch:35 step:27611[D loss: 0.293921, acc: 80.47%, op_acc: 54.69%] [G loss: 0.787916]\n",
      "epoch:35 step:27612[D loss: 0.474523, acc: 61.72%, op_acc: 36.72%] [G loss: 1.473486]\n",
      "epoch:35 step:27613[D loss: 0.340009, acc: 75.78%, op_acc: 50.00%] [G loss: 1.431011]\n",
      "epoch:35 step:27614[D loss: 0.319759, acc: 81.25%, op_acc: 50.78%] [G loss: 1.339964]\n",
      "epoch:35 step:27615[D loss: 0.358237, acc: 72.66%, op_acc: 55.47%] [G loss: 1.351961]\n",
      "epoch:35 step:27616[D loss: 0.315970, acc: 80.47%, op_acc: 54.69%] [G loss: 1.331819]\n",
      "epoch:35 step:27617[D loss: 0.349014, acc: 75.00%, op_acc: 46.88%] [G loss: 1.135680]\n",
      "epoch:35 step:27618[D loss: 0.263775, acc: 85.16%, op_acc: 56.25%] [G loss: 0.991756]\n",
      "epoch:35 step:27619[D loss: 0.394218, acc: 67.97%, op_acc: 35.16%] [G loss: 1.049791]\n",
      "epoch:35 step:27620[D loss: 0.305899, acc: 78.12%, op_acc: 48.44%] [G loss: 1.336745]\n",
      "epoch:35 step:27621[D loss: 0.353784, acc: 72.66%, op_acc: 39.06%] [G loss: 1.504514]\n",
      "epoch:35 step:27622[D loss: 0.449003, acc: 61.72%, op_acc: 42.97%] [G loss: 1.126059]\n",
      "epoch:35 step:27623[D loss: 0.392864, acc: 65.62%, op_acc: 40.62%] [G loss: 1.045121]\n",
      "epoch:35 step:27624[D loss: 0.389903, acc: 67.19%, op_acc: 42.97%] [G loss: 1.618043]\n",
      "epoch:35 step:27625[D loss: 0.377017, acc: 67.97%, op_acc: 42.97%] [G loss: 1.486807]\n",
      "epoch:35 step:27626[D loss: 0.423064, acc: 63.28%, op_acc: 46.09%] [G loss: 1.263629]\n",
      "epoch:35 step:27627[D loss: 0.474273, acc: 55.47%, op_acc: 42.19%] [G loss: 1.168458]\n",
      "epoch:35 step:27628[D loss: 0.394603, acc: 65.62%, op_acc: 38.28%] [G loss: 1.195384]\n",
      "epoch:35 step:27629[D loss: 0.416600, acc: 69.53%, op_acc: 41.41%] [G loss: 0.667636]\n",
      "epoch:35 step:27630[D loss: 0.363705, acc: 74.22%, op_acc: 45.31%] [G loss: 0.663006]\n",
      "epoch:35 step:27631[D loss: 0.334486, acc: 73.44%, op_acc: 48.44%] [G loss: 0.514515]\n",
      "epoch:35 step:27632[D loss: 0.320814, acc: 78.91%, op_acc: 47.66%] [G loss: 0.537880]\n",
      "epoch:35 step:27633[D loss: 0.345107, acc: 75.78%, op_acc: 43.75%] [G loss: 1.185299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27634[D loss: 0.426154, acc: 61.72%, op_acc: 45.31%] [G loss: 1.283001]\n",
      "epoch:35 step:27635[D loss: 0.324788, acc: 81.25%, op_acc: 45.31%] [G loss: 0.505541]\n",
      "epoch:35 step:27636[D loss: 0.352073, acc: 72.66%, op_acc: 42.19%] [G loss: 0.480319]\n",
      "epoch:35 step:27637[D loss: 0.341246, acc: 75.00%, op_acc: 47.66%] [G loss: 0.582816]\n",
      "epoch:35 step:27638[D loss: 0.460846, acc: 57.03%, op_acc: 37.50%] [G loss: 1.469627]\n",
      "epoch:35 step:27639[D loss: 0.355022, acc: 72.66%, op_acc: 55.47%] [G loss: 0.977163]\n",
      "epoch:35 step:27640[D loss: 0.368438, acc: 71.09%, op_acc: 47.66%] [G loss: 1.132279]\n",
      "epoch:35 step:27641[D loss: 0.429145, acc: 60.16%, op_acc: 42.19%] [G loss: 0.639175]\n",
      "epoch:35 step:27642[D loss: 0.380199, acc: 65.62%, op_acc: 44.53%] [G loss: 0.844903]\n",
      "epoch:35 step:27643[D loss: 0.421538, acc: 63.28%, op_acc: 41.41%] [G loss: 0.971866]\n",
      "epoch:35 step:27644[D loss: 0.414462, acc: 68.75%, op_acc: 35.16%] [G loss: 1.240999]\n",
      "epoch:35 step:27645[D loss: 0.311615, acc: 78.91%, op_acc: 54.69%] [G loss: 1.729696]\n",
      "epoch:35 step:27646[D loss: 0.320388, acc: 77.34%, op_acc: 54.69%] [G loss: 1.412208]\n",
      "epoch:35 step:27647[D loss: 0.366052, acc: 70.31%, op_acc: 52.34%] [G loss: 0.937930]\n",
      "epoch:35 step:27648[D loss: 0.411238, acc: 65.62%, op_acc: 42.97%] [G loss: 1.143710]\n",
      "epoch:35 step:27649[D loss: 0.448938, acc: 53.12%, op_acc: 42.97%] [G loss: 0.936148]\n",
      "epoch:35 step:27650[D loss: 0.346811, acc: 80.47%, op_acc: 46.88%] [G loss: 1.073843]\n",
      "epoch:35 step:27651[D loss: 0.418997, acc: 63.28%, op_acc: 39.84%] [G loss: 0.678436]\n",
      "epoch:35 step:27652[D loss: 0.422646, acc: 64.06%, op_acc: 40.62%] [G loss: 0.794735]\n",
      "epoch:35 step:27653[D loss: 0.371139, acc: 67.97%, op_acc: 43.75%] [G loss: 0.769279]\n",
      "epoch:35 step:27654[D loss: 0.367859, acc: 70.31%, op_acc: 43.75%] [G loss: 1.231818]\n",
      "epoch:35 step:27655[D loss: 0.406160, acc: 67.97%, op_acc: 39.06%] [G loss: 1.079845]\n",
      "epoch:35 step:27656[D loss: 0.398968, acc: 67.97%, op_acc: 41.41%] [G loss: 1.154822]\n",
      "epoch:35 step:27657[D loss: 0.425423, acc: 59.38%, op_acc: 41.41%] [G loss: 0.706988]\n",
      "epoch:35 step:27658[D loss: 0.364393, acc: 67.19%, op_acc: 49.22%] [G loss: 1.426559]\n",
      "epoch:35 step:27659[D loss: 0.338886, acc: 80.47%, op_acc: 39.06%] [G loss: 1.126977]\n",
      "epoch:35 step:27660[D loss: 0.372134, acc: 71.88%, op_acc: 42.19%] [G loss: 0.887967]\n",
      "epoch:35 step:27661[D loss: 0.346120, acc: 71.88%, op_acc: 50.00%] [G loss: 1.374276]\n",
      "epoch:35 step:27662[D loss: 0.443834, acc: 60.94%, op_acc: 37.50%] [G loss: 1.197995]\n",
      "epoch:35 step:27663[D loss: 0.382322, acc: 73.44%, op_acc: 43.75%] [G loss: 1.096575]\n",
      "epoch:35 step:27664[D loss: 0.356871, acc: 68.75%, op_acc: 53.91%] [G loss: 1.069704]\n",
      "epoch:35 step:27665[D loss: 0.351960, acc: 71.09%, op_acc: 51.56%] [G loss: 0.979005]\n",
      "epoch:35 step:27666[D loss: 0.348250, acc: 76.56%, op_acc: 44.53%] [G loss: 1.097029]\n",
      "epoch:35 step:27667[D loss: 0.422328, acc: 64.06%, op_acc: 42.19%] [G loss: 1.142031]\n",
      "epoch:35 step:27668[D loss: 0.363228, acc: 75.00%, op_acc: 49.22%] [G loss: 0.944638]\n",
      "epoch:35 step:27669[D loss: 0.411173, acc: 57.03%, op_acc: 45.31%] [G loss: 0.976414]\n",
      "epoch:35 step:27670[D loss: 0.443940, acc: 55.47%, op_acc: 40.62%] [G loss: 0.869362]\n",
      "epoch:35 step:27671[D loss: 0.358894, acc: 75.00%, op_acc: 48.44%] [G loss: 1.197180]\n",
      "epoch:35 step:27672[D loss: 0.420944, acc: 68.75%, op_acc: 46.88%] [G loss: 1.075604]\n",
      "epoch:35 step:27673[D loss: 0.368585, acc: 69.53%, op_acc: 50.00%] [G loss: 1.087398]\n",
      "epoch:35 step:27674[D loss: 0.399281, acc: 65.62%, op_acc: 44.53%] [G loss: 1.090985]\n",
      "epoch:35 step:27675[D loss: 0.390110, acc: 64.06%, op_acc: 45.31%] [G loss: 1.058859]\n",
      "epoch:35 step:27676[D loss: 0.378828, acc: 69.53%, op_acc: 49.22%] [G loss: 1.004977]\n",
      "epoch:35 step:27677[D loss: 0.416530, acc: 63.28%, op_acc: 39.06%] [G loss: 1.108187]\n",
      "epoch:35 step:27678[D loss: 0.356937, acc: 69.53%, op_acc: 48.44%] [G loss: 1.016355]\n",
      "epoch:35 step:27679[D loss: 0.368010, acc: 69.53%, op_acc: 50.78%] [G loss: 1.158503]\n",
      "epoch:35 step:27680[D loss: 0.380695, acc: 67.19%, op_acc: 41.41%] [G loss: 1.158520]\n",
      "epoch:35 step:27681[D loss: 0.355098, acc: 78.12%, op_acc: 42.97%] [G loss: 0.525451]\n",
      "epoch:35 step:27682[D loss: 0.377905, acc: 70.31%, op_acc: 39.06%] [G loss: 0.518738]\n",
      "epoch:35 step:27683[D loss: 0.311396, acc: 75.00%, op_acc: 49.22%] [G loss: 1.177567]\n",
      "epoch:35 step:27684[D loss: 0.324022, acc: 78.91%, op_acc: 55.47%] [G loss: 1.002987]\n",
      "epoch:35 step:27685[D loss: 0.410098, acc: 67.97%, op_acc: 46.88%] [G loss: 0.781090]\n",
      "epoch:35 step:27686[D loss: 0.309323, acc: 83.59%, op_acc: 51.56%] [G loss: 1.125036]\n",
      "epoch:35 step:27687[D loss: 0.409752, acc: 64.84%, op_acc: 42.97%] [G loss: 0.829011]\n",
      "epoch:35 step:27688[D loss: 0.382458, acc: 63.28%, op_acc: 49.22%] [G loss: 1.086857]\n",
      "epoch:35 step:27689[D loss: 0.410755, acc: 67.19%, op_acc: 43.75%] [G loss: 0.826299]\n",
      "epoch:35 step:27690[D loss: 0.384533, acc: 69.53%, op_acc: 52.34%] [G loss: 0.763051]\n",
      "epoch:35 step:27691[D loss: 0.358935, acc: 64.84%, op_acc: 43.75%] [G loss: 0.709839]\n",
      "epoch:35 step:27692[D loss: 0.320222, acc: 77.34%, op_acc: 46.88%] [G loss: 0.852231]\n",
      "epoch:35 step:27693[D loss: 0.328873, acc: 79.69%, op_acc: 43.75%] [G loss: 0.846060]\n",
      "epoch:35 step:27694[D loss: 0.333026, acc: 78.12%, op_acc: 49.22%] [G loss: 0.771493]\n",
      "epoch:35 step:27695[D loss: 0.326953, acc: 81.25%, op_acc: 49.22%] [G loss: 1.439216]\n",
      "epoch:35 step:27696[D loss: 0.266707, acc: 86.72%, op_acc: 57.81%] [G loss: 1.267079]\n",
      "epoch:35 step:27697[D loss: 0.291752, acc: 81.25%, op_acc: 50.00%] [G loss: 0.863366]\n",
      "epoch:35 step:27698[D loss: 0.342781, acc: 69.53%, op_acc: 50.00%] [G loss: 1.270480]\n",
      "epoch:35 step:27699[D loss: 0.307853, acc: 77.34%, op_acc: 59.38%] [G loss: 1.710607]\n",
      "epoch:35 step:27700[D loss: 0.256119, acc: 84.38%, op_acc: 64.84%] [G loss: 0.697495]\n",
      "epoch:35 step:27701[D loss: 0.386889, acc: 62.50%, op_acc: 44.53%] [G loss: 0.839912]\n",
      "epoch:35 step:27702[D loss: 0.404070, acc: 65.62%, op_acc: 40.62%] [G loss: 1.169329]\n",
      "epoch:35 step:27703[D loss: 0.359491, acc: 74.22%, op_acc: 42.97%] [G loss: 1.082475]\n",
      "epoch:35 step:27704[D loss: 0.335260, acc: 72.66%, op_acc: 41.41%] [G loss: 1.042053]\n",
      "epoch:35 step:27705[D loss: 0.427207, acc: 62.50%, op_acc: 46.09%] [G loss: 0.992135]\n",
      "epoch:35 step:27706[D loss: 0.397331, acc: 67.19%, op_acc: 46.09%] [G loss: 1.029039]\n",
      "epoch:35 step:27707[D loss: 0.318526, acc: 78.12%, op_acc: 51.56%] [G loss: 1.277400]\n",
      "epoch:35 step:27708[D loss: 0.318254, acc: 75.78%, op_acc: 53.91%] [G loss: 1.117580]\n",
      "epoch:35 step:27709[D loss: 0.318276, acc: 78.91%, op_acc: 56.25%] [G loss: 0.886366]\n",
      "epoch:35 step:27710[D loss: 0.309845, acc: 78.12%, op_acc: 50.00%] [G loss: 0.863273]\n",
      "epoch:35 step:27711[D loss: 0.376934, acc: 75.00%, op_acc: 39.84%] [G loss: 0.722391]\n",
      "epoch:35 step:27712[D loss: 0.441559, acc: 61.72%, op_acc: 42.97%] [G loss: 0.887715]\n",
      "epoch:35 step:27713[D loss: 0.341950, acc: 76.56%, op_acc: 47.66%] [G loss: 1.787557]\n",
      "epoch:35 step:27714[D loss: 0.396873, acc: 69.53%, op_acc: 42.97%] [G loss: 1.099380]\n",
      "epoch:35 step:27715[D loss: 0.330931, acc: 75.78%, op_acc: 60.16%] [G loss: 1.274105]\n",
      "epoch:35 step:27716[D loss: 0.340129, acc: 74.22%, op_acc: 50.00%] [G loss: 0.931160]\n",
      "epoch:35 step:27717[D loss: 0.365226, acc: 71.09%, op_acc: 47.66%] [G loss: 1.015444]\n",
      "epoch:35 step:27718[D loss: 0.349701, acc: 72.66%, op_acc: 52.34%] [G loss: 1.456383]\n",
      "epoch:35 step:27719[D loss: 0.275892, acc: 85.16%, op_acc: 57.03%] [G loss: 0.719425]\n",
      "epoch:35 step:27720[D loss: 0.291597, acc: 82.81%, op_acc: 56.25%] [G loss: 1.493145]\n",
      "epoch:35 step:27721[D loss: 0.329212, acc: 73.44%, op_acc: 48.44%] [G loss: 1.072280]\n",
      "epoch:35 step:27722[D loss: 0.425271, acc: 64.06%, op_acc: 44.53%] [G loss: 1.096103]\n",
      "epoch:35 step:27723[D loss: 0.355451, acc: 75.00%, op_acc: 44.53%] [G loss: 1.258068]\n",
      "epoch:35 step:27724[D loss: 0.294702, acc: 82.03%, op_acc: 53.91%] [G loss: 0.942607]\n",
      "epoch:35 step:27725[D loss: 0.348715, acc: 71.88%, op_acc: 50.00%] [G loss: 0.979600]\n",
      "epoch:35 step:27726[D loss: 0.393043, acc: 66.41%, op_acc: 42.97%] [G loss: 1.111396]\n",
      "epoch:35 step:27727[D loss: 0.419201, acc: 63.28%, op_acc: 47.66%] [G loss: 1.164248]\n",
      "epoch:35 step:27728[D loss: 0.385003, acc: 70.31%, op_acc: 48.44%] [G loss: 1.209345]\n",
      "epoch:35 step:27729[D loss: 0.360158, acc: 68.75%, op_acc: 42.97%] [G loss: 1.163977]\n",
      "epoch:35 step:27730[D loss: 0.414295, acc: 67.97%, op_acc: 42.19%] [G loss: 0.955389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27731[D loss: 0.301408, acc: 82.03%, op_acc: 53.91%] [G loss: 1.031949]\n",
      "epoch:35 step:27732[D loss: 0.313053, acc: 79.69%, op_acc: 55.47%] [G loss: 0.964540]\n",
      "epoch:35 step:27733[D loss: 0.403283, acc: 73.44%, op_acc: 39.06%] [G loss: 1.071307]\n",
      "epoch:35 step:27734[D loss: 0.298612, acc: 83.59%, op_acc: 53.91%] [G loss: 1.043031]\n",
      "epoch:35 step:27735[D loss: 0.339181, acc: 71.09%, op_acc: 50.00%] [G loss: 0.862482]\n",
      "epoch:35 step:27736[D loss: 0.324180, acc: 80.47%, op_acc: 42.19%] [G loss: 1.208058]\n",
      "epoch:35 step:27737[D loss: 0.359872, acc: 72.66%, op_acc: 46.88%] [G loss: 1.069278]\n",
      "epoch:35 step:27738[D loss: 0.307191, acc: 80.47%, op_acc: 50.00%] [G loss: 1.251083]\n",
      "epoch:35 step:27739[D loss: 0.336099, acc: 71.88%, op_acc: 50.78%] [G loss: 1.050848]\n",
      "epoch:35 step:27740[D loss: 0.380767, acc: 71.09%, op_acc: 46.09%] [G loss: 1.151369]\n",
      "epoch:35 step:27741[D loss: 0.353584, acc: 74.22%, op_acc: 48.44%] [G loss: 1.227930]\n",
      "epoch:35 step:27742[D loss: 0.287152, acc: 82.81%, op_acc: 47.66%] [G loss: 1.280764]\n",
      "epoch:35 step:27743[D loss: 0.274803, acc: 87.50%, op_acc: 53.91%] [G loss: 1.262800]\n",
      "epoch:35 step:27744[D loss: 0.294223, acc: 80.47%, op_acc: 59.38%] [G loss: 0.740368]\n",
      "epoch:35 step:27745[D loss: 0.341762, acc: 74.22%, op_acc: 50.78%] [G loss: 1.161738]\n",
      "epoch:35 step:27746[D loss: 0.388419, acc: 68.75%, op_acc: 48.44%] [G loss: 1.111060]\n",
      "epoch:35 step:27747[D loss: 0.322762, acc: 79.69%, op_acc: 48.44%] [G loss: 1.116917]\n",
      "epoch:35 step:27748[D loss: 0.323764, acc: 80.47%, op_acc: 47.66%] [G loss: 1.459047]\n",
      "epoch:35 step:27749[D loss: 0.300027, acc: 82.03%, op_acc: 59.38%] [G loss: 1.316665]\n",
      "epoch:35 step:27750[D loss: 0.320689, acc: 78.91%, op_acc: 54.69%] [G loss: 1.245371]\n",
      "epoch:35 step:27751[D loss: 0.300819, acc: 76.56%, op_acc: 50.78%] [G loss: 1.268804]\n",
      "epoch:35 step:27752[D loss: 0.345539, acc: 74.22%, op_acc: 53.12%] [G loss: 1.311928]\n",
      "epoch:35 step:27753[D loss: 0.332134, acc: 78.12%, op_acc: 53.91%] [G loss: 1.298247]\n",
      "epoch:35 step:27754[D loss: 0.297099, acc: 84.38%, op_acc: 52.34%] [G loss: 1.144175]\n",
      "epoch:35 step:27755[D loss: 0.340232, acc: 77.34%, op_acc: 60.94%] [G loss: 1.064122]\n",
      "epoch:35 step:27756[D loss: 0.338714, acc: 78.91%, op_acc: 51.56%] [G loss: 1.323939]\n",
      "epoch:35 step:27757[D loss: 0.284116, acc: 80.47%, op_acc: 57.81%] [G loss: 1.597291]\n",
      "epoch:35 step:27758[D loss: 0.295323, acc: 85.94%, op_acc: 48.44%] [G loss: 1.560715]\n",
      "epoch:35 step:27759[D loss: 0.289859, acc: 88.28%, op_acc: 57.81%] [G loss: 0.615464]\n",
      "epoch:35 step:27760[D loss: 0.397151, acc: 67.97%, op_acc: 42.19%] [G loss: 1.448007]\n",
      "epoch:35 step:27761[D loss: 0.443323, acc: 58.59%, op_acc: 42.97%] [G loss: 1.704173]\n",
      "epoch:35 step:27762[D loss: 0.352617, acc: 78.12%, op_acc: 46.09%] [G loss: 1.428375]\n",
      "epoch:35 step:27763[D loss: 0.350848, acc: 71.88%, op_acc: 53.12%] [G loss: 1.548713]\n",
      "epoch:35 step:27764[D loss: 0.353087, acc: 71.88%, op_acc: 54.69%] [G loss: 1.388624]\n",
      "epoch:35 step:27765[D loss: 0.313985, acc: 81.25%, op_acc: 53.91%] [G loss: 1.462449]\n",
      "epoch:35 step:27766[D loss: 0.302709, acc: 81.25%, op_acc: 50.00%] [G loss: 1.488304]\n",
      "epoch:35 step:27767[D loss: 0.328608, acc: 78.91%, op_acc: 53.12%] [G loss: 1.137619]\n",
      "epoch:35 step:27768[D loss: 0.255019, acc: 85.16%, op_acc: 57.81%] [G loss: 1.317047]\n",
      "epoch:35 step:27769[D loss: 0.290884, acc: 75.78%, op_acc: 69.53%] [G loss: 1.433805]\n",
      "epoch:35 step:27770[D loss: 0.282479, acc: 78.12%, op_acc: 54.69%] [G loss: 1.479735]\n",
      "epoch:35 step:27771[D loss: 0.248111, acc: 90.62%, op_acc: 58.59%] [G loss: 1.739458]\n",
      "epoch:35 step:27772[D loss: 0.315139, acc: 78.12%, op_acc: 54.69%] [G loss: 0.824571]\n",
      "epoch:35 step:27773[D loss: 0.303047, acc: 81.25%, op_acc: 47.66%] [G loss: 1.332610]\n",
      "epoch:35 step:27774[D loss: 0.318023, acc: 78.12%, op_acc: 51.56%] [G loss: 1.621077]\n",
      "epoch:35 step:27775[D loss: 0.325772, acc: 76.56%, op_acc: 50.78%] [G loss: 1.476335]\n",
      "epoch:35 step:27776[D loss: 0.315070, acc: 82.03%, op_acc: 48.44%] [G loss: 1.706697]\n",
      "epoch:35 step:27777[D loss: 0.314153, acc: 75.78%, op_acc: 53.91%] [G loss: 2.089375]\n",
      "epoch:35 step:27778[D loss: 0.319419, acc: 82.81%, op_acc: 53.91%] [G loss: 1.529612]\n",
      "epoch:35 step:27779[D loss: 0.219151, acc: 91.41%, op_acc: 64.06%] [G loss: 1.677745]\n",
      "epoch:35 step:27780[D loss: 0.270220, acc: 89.84%, op_acc: 61.72%] [G loss: 1.495625]\n",
      "epoch:35 step:27781[D loss: 0.291579, acc: 83.59%, op_acc: 57.03%] [G loss: 1.662525]\n",
      "epoch:35 step:27782[D loss: 0.271219, acc: 89.06%, op_acc: 48.44%] [G loss: 1.512958]\n",
      "epoch:35 step:27783[D loss: 0.213641, acc: 93.75%, op_acc: 57.03%] [G loss: 1.716931]\n",
      "epoch:35 step:27784[D loss: 0.240848, acc: 91.41%, op_acc: 57.03%] [G loss: 2.028054]\n",
      "epoch:35 step:27785[D loss: 0.241939, acc: 89.84%, op_acc: 56.25%] [G loss: 2.026375]\n",
      "epoch:35 step:27786[D loss: 0.275723, acc: 85.16%, op_acc: 60.94%] [G loss: 1.749252]\n",
      "epoch:35 step:27787[D loss: 0.152546, acc: 98.44%, op_acc: 67.97%] [G loss: 2.214369]\n",
      "epoch:35 step:27788[D loss: 0.274301, acc: 84.38%, op_acc: 61.72%] [G loss: 1.664961]\n",
      "epoch:35 step:27789[D loss: 0.234560, acc: 89.84%, op_acc: 63.28%] [G loss: 1.670509]\n",
      "epoch:35 step:27790[D loss: 0.252305, acc: 89.06%, op_acc: 65.62%] [G loss: 1.723446]\n",
      "epoch:35 step:27791[D loss: 0.234847, acc: 91.41%, op_acc: 52.34%] [G loss: 1.864718]\n",
      "epoch:35 step:27792[D loss: 0.226459, acc: 89.06%, op_acc: 59.38%] [G loss: 1.942415]\n",
      "epoch:35 step:27793[D loss: 0.203299, acc: 92.97%, op_acc: 65.62%] [G loss: 2.274782]\n",
      "epoch:35 step:27794[D loss: 0.192159, acc: 92.97%, op_acc: 67.19%] [G loss: 2.000402]\n",
      "epoch:35 step:27795[D loss: 0.148779, acc: 97.66%, op_acc: 70.31%] [G loss: 1.890607]\n",
      "epoch:35 step:27796[D loss: 0.185454, acc: 96.09%, op_acc: 68.75%] [G loss: 2.589929]\n",
      "epoch:35 step:27797[D loss: 0.209065, acc: 91.41%, op_acc: 60.16%] [G loss: 2.134347]\n",
      "epoch:35 step:27798[D loss: 0.205738, acc: 92.19%, op_acc: 71.88%] [G loss: 2.402575]\n",
      "epoch:35 step:27799[D loss: 0.199218, acc: 95.31%, op_acc: 71.88%] [G loss: 2.190277]\n",
      "epoch:35 step:27800[D loss: 0.206952, acc: 92.97%, op_acc: 60.16%] [G loss: 2.237686]\n",
      "epoch:35 step:27801[D loss: 0.239934, acc: 85.94%, op_acc: 60.16%] [G loss: 1.759701]\n",
      "epoch:35 step:27802[D loss: 0.287453, acc: 82.81%, op_acc: 52.34%] [G loss: 0.400436]\n",
      "epoch:35 step:27803[D loss: 0.563671, acc: 52.34%, op_acc: 38.28%] [G loss: 1.834929]\n",
      "epoch:35 step:27804[D loss: 0.420062, acc: 67.19%, op_acc: 46.88%] [G loss: 2.153735]\n",
      "epoch:35 step:27805[D loss: 0.390888, acc: 69.53%, op_acc: 45.31%] [G loss: 1.785475]\n",
      "epoch:35 step:27806[D loss: 0.389679, acc: 70.31%, op_acc: 50.78%] [G loss: 2.074064]\n",
      "epoch:35 step:27807[D loss: 0.409569, acc: 68.75%, op_acc: 48.44%] [G loss: 2.127303]\n",
      "epoch:35 step:27808[D loss: 0.305348, acc: 74.22%, op_acc: 54.69%] [G loss: 1.881116]\n",
      "epoch:35 step:27809[D loss: 0.373813, acc: 73.44%, op_acc: 46.88%] [G loss: 1.672737]\n",
      "epoch:35 step:27810[D loss: 0.377570, acc: 69.53%, op_acc: 47.66%] [G loss: 1.385928]\n",
      "epoch:35 step:27811[D loss: 0.358742, acc: 72.66%, op_acc: 46.88%] [G loss: 1.667426]\n",
      "epoch:35 step:27812[D loss: 0.400236, acc: 68.75%, op_acc: 42.97%] [G loss: 1.319592]\n",
      "epoch:35 step:27813[D loss: 0.329044, acc: 74.22%, op_acc: 53.12%] [G loss: 1.407518]\n",
      "epoch:35 step:27814[D loss: 0.348769, acc: 71.88%, op_acc: 50.00%] [G loss: 1.510239]\n",
      "epoch:35 step:27815[D loss: 0.424107, acc: 62.50%, op_acc: 38.28%] [G loss: 1.371419]\n",
      "epoch:35 step:27816[D loss: 0.448964, acc: 60.16%, op_acc: 43.75%] [G loss: 1.203793]\n",
      "epoch:35 step:27817[D loss: 0.419254, acc: 67.97%, op_acc: 44.53%] [G loss: 1.457191]\n",
      "epoch:35 step:27818[D loss: 0.424272, acc: 61.72%, op_acc: 45.31%] [G loss: 1.319452]\n",
      "epoch:35 step:27819[D loss: 0.366539, acc: 67.19%, op_acc: 49.22%] [G loss: 1.261217]\n",
      "epoch:35 step:27820[D loss: 0.462213, acc: 58.59%, op_acc: 41.41%] [G loss: 1.414380]\n",
      "epoch:35 step:27821[D loss: 0.381484, acc: 69.53%, op_acc: 46.09%] [G loss: 1.502720]\n",
      "epoch:35 step:27822[D loss: 0.382853, acc: 75.00%, op_acc: 43.75%] [G loss: 1.369594]\n",
      "epoch:35 step:27823[D loss: 0.434994, acc: 58.59%, op_acc: 50.78%] [G loss: 1.529008]\n",
      "epoch:35 step:27824[D loss: 0.450231, acc: 52.34%, op_acc: 48.44%] [G loss: 1.185773]\n",
      "epoch:35 step:27825[D loss: 0.353044, acc: 69.53%, op_acc: 51.56%] [G loss: 1.237066]\n",
      "epoch:35 step:27826[D loss: 0.451087, acc: 63.28%, op_acc: 38.28%] [G loss: 1.232809]\n",
      "epoch:35 step:27827[D loss: 0.438600, acc: 64.06%, op_acc: 42.97%] [G loss: 1.322492]\n",
      "epoch:35 step:27828[D loss: 0.396196, acc: 70.31%, op_acc: 49.22%] [G loss: 1.623526]\n",
      "epoch:35 step:27829[D loss: 0.422348, acc: 57.81%, op_acc: 47.66%] [G loss: 1.246021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27830[D loss: 0.380796, acc: 68.75%, op_acc: 46.88%] [G loss: 1.680314]\n",
      "epoch:35 step:27831[D loss: 0.460781, acc: 60.16%, op_acc: 45.31%] [G loss: 1.414177]\n",
      "epoch:35 step:27832[D loss: 0.419230, acc: 63.28%, op_acc: 43.75%] [G loss: 1.562136]\n",
      "epoch:35 step:27833[D loss: 0.409932, acc: 66.41%, op_acc: 42.19%] [G loss: 1.448462]\n",
      "epoch:35 step:27834[D loss: 0.395372, acc: 71.88%, op_acc: 44.53%] [G loss: 1.884383]\n",
      "epoch:35 step:27835[D loss: 0.412929, acc: 61.72%, op_acc: 46.88%] [G loss: 1.260773]\n",
      "epoch:35 step:27836[D loss: 0.412386, acc: 67.97%, op_acc: 43.75%] [G loss: 1.519939]\n",
      "epoch:35 step:27837[D loss: 0.469927, acc: 53.91%, op_acc: 42.97%] [G loss: 1.266976]\n",
      "epoch:35 step:27838[D loss: 0.390201, acc: 64.84%, op_acc: 46.88%] [G loss: 1.232279]\n",
      "epoch:35 step:27839[D loss: 0.443260, acc: 60.16%, op_acc: 50.00%] [G loss: 1.031298]\n",
      "epoch:35 step:27840[D loss: 0.475994, acc: 61.72%, op_acc: 39.06%] [G loss: 1.314443]\n",
      "epoch:35 step:27841[D loss: 0.434851, acc: 65.62%, op_acc: 43.75%] [G loss: 1.379300]\n",
      "epoch:35 step:27842[D loss: 0.393559, acc: 62.50%, op_acc: 50.78%] [G loss: 1.029833]\n",
      "epoch:35 step:27843[D loss: 0.452731, acc: 60.94%, op_acc: 45.31%] [G loss: 1.310805]\n",
      "epoch:35 step:27844[D loss: 0.432043, acc: 63.28%, op_acc: 44.53%] [G loss: 1.096797]\n",
      "epoch:35 step:27845[D loss: 0.360425, acc: 72.66%, op_acc: 46.09%] [G loss: 1.391711]\n",
      "epoch:35 step:27846[D loss: 0.453599, acc: 57.03%, op_acc: 46.09%] [G loss: 1.363671]\n",
      "epoch:35 step:27847[D loss: 0.501911, acc: 52.34%, op_acc: 35.16%] [G loss: 1.352103]\n",
      "epoch:35 step:27848[D loss: 0.430207, acc: 64.06%, op_acc: 46.09%] [G loss: 0.974974]\n",
      "epoch:35 step:27849[D loss: 0.444154, acc: 62.50%, op_acc: 42.97%] [G loss: 1.003022]\n",
      "epoch:35 step:27850[D loss: 0.365115, acc: 69.53%, op_acc: 43.75%] [G loss: 1.201877]\n",
      "epoch:35 step:27851[D loss: 0.347102, acc: 71.88%, op_acc: 42.97%] [G loss: 1.285383]\n",
      "epoch:35 step:27852[D loss: 0.359414, acc: 76.56%, op_acc: 41.41%] [G loss: 1.295940]\n",
      "epoch:35 step:27853[D loss: 0.337639, acc: 75.78%, op_acc: 49.22%] [G loss: 1.268048]\n",
      "epoch:35 step:27854[D loss: 0.363389, acc: 67.19%, op_acc: 47.66%] [G loss: 1.229935]\n",
      "epoch:35 step:27855[D loss: 0.377891, acc: 68.75%, op_acc: 41.41%] [G loss: 1.384044]\n",
      "epoch:35 step:27856[D loss: 0.387577, acc: 67.97%, op_acc: 39.06%] [G loss: 1.542566]\n",
      "epoch:35 step:27857[D loss: 0.419853, acc: 56.25%, op_acc: 46.09%] [G loss: 1.456547]\n",
      "epoch:35 step:27858[D loss: 0.417689, acc: 60.94%, op_acc: 49.22%] [G loss: 1.225649]\n",
      "epoch:35 step:27859[D loss: 0.414905, acc: 67.19%, op_acc: 46.09%] [G loss: 1.340958]\n",
      "epoch:35 step:27860[D loss: 0.347271, acc: 71.88%, op_acc: 48.44%] [G loss: 1.597419]\n",
      "epoch:35 step:27861[D loss: 0.438936, acc: 61.72%, op_acc: 45.31%] [G loss: 1.275651]\n",
      "epoch:35 step:27862[D loss: 0.412705, acc: 58.59%, op_acc: 44.53%] [G loss: 1.271220]\n",
      "epoch:35 step:27863[D loss: 0.393577, acc: 59.38%, op_acc: 50.00%] [G loss: 1.238503]\n",
      "epoch:35 step:27864[D loss: 0.386925, acc: 66.41%, op_acc: 46.09%] [G loss: 0.819814]\n",
      "epoch:35 step:27865[D loss: 0.371946, acc: 69.53%, op_acc: 50.00%] [G loss: 1.246741]\n",
      "epoch:35 step:27866[D loss: 0.392505, acc: 69.53%, op_acc: 42.97%] [G loss: 1.293607]\n",
      "epoch:35 step:27867[D loss: 0.432395, acc: 57.81%, op_acc: 47.66%] [G loss: 1.040700]\n",
      "epoch:35 step:27868[D loss: 0.394032, acc: 67.19%, op_acc: 39.06%] [G loss: 1.082703]\n",
      "epoch:35 step:27869[D loss: 0.359243, acc: 71.09%, op_acc: 48.44%] [G loss: 1.484497]\n",
      "epoch:35 step:27870[D loss: 0.476991, acc: 53.91%, op_acc: 40.62%] [G loss: 1.199579]\n",
      "epoch:35 step:27871[D loss: 0.400198, acc: 59.38%, op_acc: 50.78%] [G loss: 1.277056]\n",
      "epoch:35 step:27872[D loss: 0.418406, acc: 64.06%, op_acc: 40.62%] [G loss: 1.361048]\n",
      "epoch:35 step:27873[D loss: 0.394468, acc: 64.84%, op_acc: 35.16%] [G loss: 1.430278]\n",
      "epoch:35 step:27874[D loss: 0.394701, acc: 68.75%, op_acc: 46.88%] [G loss: 1.355629]\n",
      "epoch:35 step:27875[D loss: 0.416001, acc: 56.25%, op_acc: 47.66%] [G loss: 1.347812]\n",
      "epoch:35 step:27876[D loss: 0.372768, acc: 68.75%, op_acc: 48.44%] [G loss: 1.371907]\n",
      "epoch:35 step:27877[D loss: 0.420361, acc: 59.38%, op_acc: 39.06%] [G loss: 1.567272]\n",
      "epoch:35 step:27878[D loss: 0.344316, acc: 71.09%, op_acc: 52.34%] [G loss: 1.478614]\n",
      "epoch:35 step:27879[D loss: 0.401658, acc: 65.62%, op_acc: 45.31%] [G loss: 1.453320]\n",
      "epoch:35 step:27880[D loss: 0.309124, acc: 75.78%, op_acc: 51.56%] [G loss: 1.726444]\n",
      "epoch:35 step:27881[D loss: 0.362186, acc: 72.66%, op_acc: 50.00%] [G loss: 1.693806]\n",
      "epoch:35 step:27882[D loss: 0.355462, acc: 77.34%, op_acc: 53.12%] [G loss: 1.530368]\n",
      "epoch:35 step:27883[D loss: 0.332946, acc: 80.47%, op_acc: 50.78%] [G loss: 1.433490]\n",
      "epoch:35 step:27884[D loss: 0.331131, acc: 78.91%, op_acc: 47.66%] [G loss: 1.645743]\n",
      "epoch:35 step:27885[D loss: 0.295325, acc: 80.47%, op_acc: 47.66%] [G loss: 1.725628]\n",
      "epoch:35 step:27886[D loss: 0.379014, acc: 72.66%, op_acc: 58.59%] [G loss: 1.604785]\n",
      "epoch:35 step:27887[D loss: 0.435013, acc: 65.62%, op_acc: 45.31%] [G loss: 1.410636]\n",
      "epoch:35 step:27888[D loss: 0.323005, acc: 75.00%, op_acc: 50.00%] [G loss: 1.615136]\n",
      "epoch:35 step:27889[D loss: 0.325953, acc: 78.91%, op_acc: 51.56%] [G loss: 1.481328]\n",
      "epoch:35 step:27890[D loss: 0.236180, acc: 86.72%, op_acc: 60.16%] [G loss: 1.514271]\n",
      "epoch:35 step:27891[D loss: 0.381293, acc: 64.06%, op_acc: 51.56%] [G loss: 0.690312]\n",
      "epoch:35 step:27892[D loss: 0.460303, acc: 56.25%, op_acc: 42.19%] [G loss: 1.416550]\n",
      "epoch:35 step:27893[D loss: 0.442111, acc: 57.03%, op_acc: 41.41%] [G loss: 1.635137]\n",
      "epoch:35 step:27894[D loss: 0.319690, acc: 81.25%, op_acc: 46.88%] [G loss: 1.528571]\n",
      "epoch:35 step:27895[D loss: 0.405086, acc: 63.28%, op_acc: 46.09%] [G loss: 1.355011]\n",
      "epoch:35 step:27896[D loss: 0.416356, acc: 63.28%, op_acc: 39.84%] [G loss: 1.483073]\n",
      "epoch:35 step:27897[D loss: 0.384513, acc: 67.19%, op_acc: 44.53%] [G loss: 1.583495]\n",
      "epoch:35 step:27898[D loss: 0.320952, acc: 78.91%, op_acc: 51.56%] [G loss: 1.404013]\n",
      "epoch:35 step:27899[D loss: 0.416726, acc: 60.16%, op_acc: 48.44%] [G loss: 1.361568]\n",
      "epoch:35 step:27900[D loss: 0.382434, acc: 71.88%, op_acc: 49.22%] [G loss: 1.167908]\n",
      "epoch:35 step:27901[D loss: 0.414060, acc: 61.72%, op_acc: 46.88%] [G loss: 1.145698]\n",
      "epoch:35 step:27902[D loss: 0.400930, acc: 62.50%, op_acc: 48.44%] [G loss: 1.296987]\n",
      "epoch:35 step:27903[D loss: 0.335153, acc: 75.78%, op_acc: 46.09%] [G loss: 1.337116]\n",
      "epoch:35 step:27904[D loss: 0.386002, acc: 66.41%, op_acc: 42.19%] [G loss: 1.353539]\n",
      "epoch:35 step:27905[D loss: 0.354386, acc: 70.31%, op_acc: 48.44%] [G loss: 1.339058]\n",
      "epoch:35 step:27906[D loss: 0.396501, acc: 64.06%, op_acc: 48.44%] [G loss: 1.296896]\n",
      "epoch:35 step:27907[D loss: 0.394636, acc: 69.53%, op_acc: 44.53%] [G loss: 1.058163]\n",
      "epoch:35 step:27908[D loss: 0.414884, acc: 64.84%, op_acc: 50.00%] [G loss: 1.269895]\n",
      "epoch:35 step:27909[D loss: 0.363008, acc: 72.66%, op_acc: 50.00%] [G loss: 1.296077]\n",
      "epoch:35 step:27910[D loss: 0.427737, acc: 64.84%, op_acc: 39.06%] [G loss: 1.167978]\n",
      "epoch:35 step:27911[D loss: 0.379258, acc: 68.75%, op_acc: 45.31%] [G loss: 1.285398]\n",
      "epoch:35 step:27912[D loss: 0.432174, acc: 64.84%, op_acc: 36.72%] [G loss: 1.092344]\n",
      "epoch:35 step:27913[D loss: 0.392222, acc: 73.44%, op_acc: 42.97%] [G loss: 1.158635]\n",
      "epoch:35 step:27914[D loss: 0.407366, acc: 62.50%, op_acc: 44.53%] [G loss: 1.471816]\n",
      "epoch:35 step:27915[D loss: 0.382260, acc: 68.75%, op_acc: 43.75%] [G loss: 1.238159]\n",
      "epoch:35 step:27916[D loss: 0.418770, acc: 61.72%, op_acc: 43.75%] [G loss: 1.527298]\n",
      "epoch:35 step:27917[D loss: 0.409416, acc: 64.84%, op_acc: 40.62%] [G loss: 1.230695]\n",
      "epoch:35 step:27918[D loss: 0.359232, acc: 68.75%, op_acc: 47.66%] [G loss: 1.374812]\n",
      "epoch:35 step:27919[D loss: 0.410079, acc: 68.75%, op_acc: 40.62%] [G loss: 1.363645]\n",
      "epoch:35 step:27920[D loss: 0.369422, acc: 72.66%, op_acc: 49.22%] [G loss: 1.119386]\n",
      "epoch:35 step:27921[D loss: 0.397990, acc: 67.19%, op_acc: 46.09%] [G loss: 1.333576]\n",
      "epoch:35 step:27922[D loss: 0.346455, acc: 76.56%, op_acc: 46.09%] [G loss: 1.478900]\n",
      "epoch:35 step:27923[D loss: 0.347021, acc: 68.75%, op_acc: 49.22%] [G loss: 1.067279]\n",
      "epoch:35 step:27924[D loss: 0.370478, acc: 73.44%, op_acc: 41.41%] [G loss: 1.313198]\n",
      "epoch:35 step:27925[D loss: 0.353330, acc: 74.22%, op_acc: 50.00%] [G loss: 1.474384]\n",
      "epoch:35 step:27926[D loss: 0.377090, acc: 72.66%, op_acc: 48.44%] [G loss: 1.417995]\n",
      "epoch:35 step:27927[D loss: 0.378541, acc: 71.88%, op_acc: 42.97%] [G loss: 1.250013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:27928[D loss: 0.468424, acc: 58.59%, op_acc: 41.41%] [G loss: 1.453885]\n",
      "epoch:35 step:27929[D loss: 0.430179, acc: 59.38%, op_acc: 45.31%] [G loss: 1.197247]\n",
      "epoch:35 step:27930[D loss: 0.354342, acc: 69.53%, op_acc: 48.44%] [G loss: 1.247591]\n",
      "epoch:35 step:27931[D loss: 0.364505, acc: 66.41%, op_acc: 37.50%] [G loss: 1.300118]\n",
      "epoch:35 step:27932[D loss: 0.355268, acc: 73.44%, op_acc: 48.44%] [G loss: 1.388996]\n",
      "epoch:35 step:27933[D loss: 0.350264, acc: 72.66%, op_acc: 42.19%] [G loss: 1.608601]\n",
      "epoch:35 step:27934[D loss: 0.320605, acc: 81.25%, op_acc: 43.75%] [G loss: 1.751760]\n",
      "epoch:35 step:27935[D loss: 0.391253, acc: 64.84%, op_acc: 46.09%] [G loss: 1.639793]\n",
      "epoch:35 step:27936[D loss: 0.299219, acc: 78.12%, op_acc: 52.34%] [G loss: 1.137962]\n",
      "epoch:35 step:27937[D loss: 0.359432, acc: 71.88%, op_acc: 50.78%] [G loss: 1.337241]\n",
      "epoch:35 step:27938[D loss: 0.326683, acc: 75.00%, op_acc: 49.22%] [G loss: 1.189939]\n",
      "epoch:35 step:27939[D loss: 0.400603, acc: 73.44%, op_acc: 39.06%] [G loss: 1.388165]\n",
      "epoch:35 step:27940[D loss: 0.382228, acc: 60.94%, op_acc: 37.50%] [G loss: 1.217694]\n",
      "epoch:35 step:27941[D loss: 0.362148, acc: 70.31%, op_acc: 52.34%] [G loss: 1.285631]\n",
      "epoch:35 step:27942[D loss: 0.443993, acc: 55.47%, op_acc: 47.66%] [G loss: 1.060821]\n",
      "epoch:35 step:27943[D loss: 0.369365, acc: 67.19%, op_acc: 50.00%] [G loss: 0.963795]\n",
      "epoch:35 step:27944[D loss: 0.383265, acc: 68.75%, op_acc: 46.88%] [G loss: 0.754190]\n",
      "epoch:35 step:27945[D loss: 0.397527, acc: 66.41%, op_acc: 44.53%] [G loss: 1.117890]\n",
      "epoch:35 step:27946[D loss: 0.348464, acc: 71.88%, op_acc: 47.66%] [G loss: 1.212279]\n",
      "epoch:35 step:27947[D loss: 0.407332, acc: 69.53%, op_acc: 42.97%] [G loss: 1.144344]\n",
      "epoch:35 step:27948[D loss: 0.408094, acc: 62.50%, op_acc: 44.53%] [G loss: 1.377010]\n",
      "epoch:35 step:27949[D loss: 0.367815, acc: 74.22%, op_acc: 45.31%] [G loss: 1.300677]\n",
      "epoch:35 step:27950[D loss: 0.384027, acc: 71.88%, op_acc: 53.12%] [G loss: 1.650194]\n",
      "epoch:35 step:27951[D loss: 0.434140, acc: 56.25%, op_acc: 42.19%] [G loss: 1.337929]\n",
      "epoch:35 step:27952[D loss: 0.370858, acc: 74.22%, op_acc: 43.75%] [G loss: 1.542680]\n",
      "epoch:35 step:27953[D loss: 0.320384, acc: 77.34%, op_acc: 53.12%] [G loss: 1.635939]\n",
      "epoch:35 step:27954[D loss: 0.343399, acc: 73.44%, op_acc: 49.22%] [G loss: 1.599979]\n",
      "epoch:35 step:27955[D loss: 0.326367, acc: 79.69%, op_acc: 46.09%] [G loss: 1.591550]\n",
      "epoch:35 step:27956[D loss: 0.264978, acc: 90.62%, op_acc: 53.12%] [G loss: 1.462337]\n",
      "epoch:35 step:27957[D loss: 0.419573, acc: 67.19%, op_acc: 45.31%] [G loss: 1.385919]\n",
      "epoch:35 step:27958[D loss: 0.264574, acc: 85.16%, op_acc: 56.25%] [G loss: 1.577660]\n",
      "epoch:35 step:27959[D loss: 0.335710, acc: 75.00%, op_acc: 53.12%] [G loss: 1.076476]\n",
      "epoch:35 step:27960[D loss: 0.423122, acc: 61.72%, op_acc: 42.97%] [G loss: 1.632868]\n",
      "epoch:35 step:27961[D loss: 0.429730, acc: 59.38%, op_acc: 42.97%] [G loss: 1.598880]\n",
      "epoch:35 step:27962[D loss: 0.352692, acc: 72.66%, op_acc: 53.12%] [G loss: 1.555167]\n",
      "epoch:35 step:27963[D loss: 0.374646, acc: 66.41%, op_acc: 49.22%] [G loss: 1.549642]\n",
      "epoch:35 step:27964[D loss: 0.409600, acc: 61.72%, op_acc: 48.44%] [G loss: 1.272288]\n",
      "epoch:35 step:27965[D loss: 0.309385, acc: 75.00%, op_acc: 57.03%] [G loss: 1.635336]\n",
      "epoch:35 step:27966[D loss: 0.362034, acc: 75.78%, op_acc: 49.22%] [G loss: 1.314479]\n",
      "epoch:35 step:27967[D loss: 0.377032, acc: 71.09%, op_acc: 42.97%] [G loss: 1.208322]\n",
      "epoch:35 step:27968[D loss: 0.338405, acc: 75.00%, op_acc: 44.53%] [G loss: 1.471920]\n",
      "epoch:35 step:27969[D loss: 0.337858, acc: 75.00%, op_acc: 50.00%] [G loss: 0.897818]\n",
      "epoch:35 step:27970[D loss: 0.381353, acc: 64.84%, op_acc: 42.19%] [G loss: 1.015869]\n",
      "epoch:35 step:27971[D loss: 0.402873, acc: 64.84%, op_acc: 39.84%] [G loss: 1.821776]\n",
      "epoch:35 step:27972[D loss: 0.338951, acc: 71.09%, op_acc: 43.75%] [G loss: 1.923979]\n",
      "epoch:35 step:27973[D loss: 0.417509, acc: 64.84%, op_acc: 43.75%] [G loss: 1.689533]\n",
      "epoch:35 step:27974[D loss: 0.431674, acc: 60.16%, op_acc: 39.06%] [G loss: 1.950055]\n",
      "epoch:35 step:27975[D loss: 0.471487, acc: 60.16%, op_acc: 39.84%] [G loss: 1.344881]\n",
      "epoch:35 step:27976[D loss: 0.429810, acc: 67.97%, op_acc: 42.97%] [G loss: 1.296764]\n",
      "epoch:35 step:27977[D loss: 0.356799, acc: 75.00%, op_acc: 44.53%] [G loss: 1.076948]\n",
      "epoch:35 step:27978[D loss: 0.448715, acc: 59.38%, op_acc: 32.81%] [G loss: 1.232268]\n",
      "epoch:35 step:27979[D loss: 0.311945, acc: 73.44%, op_acc: 52.34%] [G loss: 1.190440]\n",
      "epoch:35 step:27980[D loss: 0.352076, acc: 71.88%, op_acc: 49.22%] [G loss: 1.301389]\n",
      "epoch:35 step:27981[D loss: 0.365276, acc: 73.44%, op_acc: 43.75%] [G loss: 1.687986]\n",
      "epoch:35 step:27982[D loss: 0.402807, acc: 63.28%, op_acc: 45.31%] [G loss: 1.407219]\n",
      "epoch:35 step:27983[D loss: 0.359812, acc: 70.31%, op_acc: 35.94%] [G loss: 1.301365]\n",
      "epoch:35 step:27984[D loss: 0.358625, acc: 68.75%, op_acc: 50.00%] [G loss: 1.332610]\n",
      "epoch:35 step:27985[D loss: 0.351396, acc: 76.56%, op_acc: 44.53%] [G loss: 1.439561]\n",
      "epoch:35 step:27986[D loss: 0.364479, acc: 69.53%, op_acc: 47.66%] [G loss: 1.189365]\n",
      "epoch:35 step:27987[D loss: 0.377036, acc: 67.97%, op_acc: 48.44%] [G loss: 1.141408]\n",
      "epoch:35 step:27988[D loss: 0.371097, acc: 70.31%, op_acc: 46.88%] [G loss: 1.087324]\n",
      "epoch:35 step:27989[D loss: 0.372904, acc: 71.09%, op_acc: 49.22%] [G loss: 1.128550]\n",
      "epoch:35 step:27990[D loss: 0.385366, acc: 68.75%, op_acc: 46.09%] [G loss: 1.228912]\n",
      "epoch:35 step:27991[D loss: 0.389835, acc: 66.41%, op_acc: 51.56%] [G loss: 1.022195]\n",
      "epoch:35 step:27992[D loss: 0.358672, acc: 71.09%, op_acc: 43.75%] [G loss: 1.080226]\n",
      "epoch:35 step:27993[D loss: 0.332622, acc: 75.00%, op_acc: 50.78%] [G loss: 1.085499]\n",
      "epoch:35 step:27994[D loss: 0.390630, acc: 68.75%, op_acc: 50.00%] [G loss: 1.060641]\n",
      "epoch:35 step:27995[D loss: 0.409370, acc: 65.62%, op_acc: 47.66%] [G loss: 1.145734]\n",
      "epoch:35 step:27996[D loss: 0.347673, acc: 70.31%, op_acc: 51.56%] [G loss: 1.233334]\n",
      "epoch:35 step:27997[D loss: 0.379143, acc: 64.84%, op_acc: 48.44%] [G loss: 1.065618]\n",
      "epoch:35 step:27998[D loss: 0.385648, acc: 64.84%, op_acc: 42.97%] [G loss: 1.294648]\n",
      "epoch:35 step:27999[D loss: 0.337998, acc: 75.00%, op_acc: 47.66%] [G loss: 1.169341]\n",
      "epoch:35 step:28000[D loss: 0.438823, acc: 60.94%, op_acc: 38.28%] [G loss: 1.048921]\n",
      "epoch:35 step:28001[D loss: 0.437364, acc: 63.28%, op_acc: 45.31%] [G loss: 1.030990]\n",
      "epoch:35 step:28002[D loss: 0.353908, acc: 71.88%, op_acc: 48.44%] [G loss: 0.892303]\n",
      "epoch:35 step:28003[D loss: 0.382509, acc: 67.97%, op_acc: 49.22%] [G loss: 0.807351]\n",
      "epoch:35 step:28004[D loss: 0.373613, acc: 66.41%, op_acc: 46.09%] [G loss: 1.253702]\n",
      "epoch:35 step:28005[D loss: 0.374648, acc: 64.06%, op_acc: 42.97%] [G loss: 1.374655]\n",
      "epoch:35 step:28006[D loss: 0.391203, acc: 70.31%, op_acc: 45.31%] [G loss: 1.260257]\n",
      "epoch:35 step:28007[D loss: 0.374438, acc: 72.66%, op_acc: 42.97%] [G loss: 1.363063]\n",
      "epoch:35 step:28008[D loss: 0.419814, acc: 64.84%, op_acc: 42.19%] [G loss: 1.244063]\n",
      "epoch:35 step:28009[D loss: 0.359344, acc: 72.66%, op_acc: 48.44%] [G loss: 0.954471]\n",
      "epoch:35 step:28010[D loss: 0.359639, acc: 71.09%, op_acc: 53.12%] [G loss: 1.073357]\n",
      "epoch:35 step:28011[D loss: 0.370891, acc: 73.44%, op_acc: 43.75%] [G loss: 1.083580]\n",
      "epoch:35 step:28012[D loss: 0.450207, acc: 61.72%, op_acc: 42.19%] [G loss: 1.107086]\n",
      "epoch:35 step:28013[D loss: 0.350993, acc: 76.56%, op_acc: 48.44%] [G loss: 1.138947]\n",
      "epoch:35 step:28014[D loss: 0.348731, acc: 75.78%, op_acc: 54.69%] [G loss: 1.226779]\n",
      "epoch:35 step:28015[D loss: 0.292499, acc: 85.16%, op_acc: 47.66%] [G loss: 1.501598]\n",
      "epoch:35 step:28016[D loss: 0.396147, acc: 69.53%, op_acc: 45.31%] [G loss: 1.323697]\n",
      "epoch:35 step:28017[D loss: 0.335515, acc: 69.53%, op_acc: 60.16%] [G loss: 1.384104]\n",
      "epoch:35 step:28018[D loss: 0.338817, acc: 75.78%, op_acc: 53.12%] [G loss: 1.243509]\n",
      "epoch:35 step:28019[D loss: 0.362770, acc: 72.66%, op_acc: 42.19%] [G loss: 1.655966]\n",
      "epoch:35 step:28020[D loss: 0.397383, acc: 70.31%, op_acc: 43.75%] [G loss: 1.327915]\n",
      "epoch:35 step:28021[D loss: 0.419752, acc: 62.50%, op_acc: 49.22%] [G loss: 1.203750]\n",
      "epoch:35 step:28022[D loss: 0.327719, acc: 81.25%, op_acc: 52.34%] [G loss: 1.442488]\n",
      "epoch:35 step:28023[D loss: 0.389594, acc: 69.53%, op_acc: 50.00%] [G loss: 1.178387]\n",
      "epoch:35 step:28024[D loss: 0.372760, acc: 70.31%, op_acc: 47.66%] [G loss: 1.188011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:28025[D loss: 0.379286, acc: 67.19%, op_acc: 46.09%] [G loss: 1.302674]\n",
      "epoch:35 step:28026[D loss: 0.397014, acc: 64.84%, op_acc: 50.00%] [G loss: 1.276133]\n",
      "epoch:35 step:28027[D loss: 0.416876, acc: 65.62%, op_acc: 39.84%] [G loss: 0.907686]\n",
      "epoch:35 step:28028[D loss: 0.432727, acc: 67.19%, op_acc: 43.75%] [G loss: 0.933617]\n",
      "epoch:35 step:28029[D loss: 0.400205, acc: 64.06%, op_acc: 47.66%] [G loss: 0.965288]\n",
      "epoch:35 step:28030[D loss: 0.385247, acc: 67.97%, op_acc: 45.31%] [G loss: 1.175347]\n",
      "epoch:35 step:28031[D loss: 0.377521, acc: 69.53%, op_acc: 51.56%] [G loss: 1.253311]\n",
      "epoch:35 step:28032[D loss: 0.426157, acc: 61.72%, op_acc: 47.66%] [G loss: 1.247619]\n",
      "epoch:35 step:28033[D loss: 0.334657, acc: 75.00%, op_acc: 47.66%] [G loss: 1.102071]\n",
      "epoch:35 step:28034[D loss: 0.372528, acc: 69.53%, op_acc: 43.75%] [G loss: 1.234715]\n",
      "epoch:35 step:28035[D loss: 0.408968, acc: 61.72%, op_acc: 39.84%] [G loss: 1.313732]\n",
      "epoch:35 step:28036[D loss: 0.377417, acc: 68.75%, op_acc: 53.91%] [G loss: 1.253086]\n",
      "epoch:35 step:28037[D loss: 0.368839, acc: 67.19%, op_acc: 45.31%] [G loss: 0.959927]\n",
      "epoch:35 step:28038[D loss: 0.442929, acc: 62.50%, op_acc: 41.41%] [G loss: 1.438445]\n",
      "epoch:35 step:28039[D loss: 0.310134, acc: 76.56%, op_acc: 46.88%] [G loss: 1.366063]\n",
      "epoch:35 step:28040[D loss: 0.367645, acc: 73.44%, op_acc: 50.00%] [G loss: 1.142341]\n",
      "epoch:35 step:28041[D loss: 0.396578, acc: 67.97%, op_acc: 46.09%] [G loss: 1.163697]\n",
      "epoch:35 step:28042[D loss: 0.387810, acc: 70.31%, op_acc: 50.00%] [G loss: 1.188745]\n",
      "epoch:35 step:28043[D loss: 0.388740, acc: 70.31%, op_acc: 46.09%] [G loss: 1.182601]\n",
      "epoch:35 step:28044[D loss: 0.402813, acc: 69.53%, op_acc: 42.97%] [G loss: 1.261761]\n",
      "epoch:35 step:28045[D loss: 0.392113, acc: 66.41%, op_acc: 46.09%] [G loss: 1.115164]\n",
      "epoch:35 step:28046[D loss: 0.386129, acc: 67.19%, op_acc: 41.41%] [G loss: 1.250052]\n",
      "epoch:35 step:28047[D loss: 0.347369, acc: 70.31%, op_acc: 54.69%] [G loss: 1.364828]\n",
      "epoch:35 step:28048[D loss: 0.383991, acc: 66.41%, op_acc: 46.88%] [G loss: 1.310002]\n",
      "epoch:35 step:28049[D loss: 0.342729, acc: 76.56%, op_acc: 52.34%] [G loss: 1.339533]\n",
      "epoch:35 step:28050[D loss: 0.356084, acc: 72.66%, op_acc: 53.91%] [G loss: 1.509726]\n",
      "epoch:35 step:28051[D loss: 0.334163, acc: 77.34%, op_acc: 48.44%] [G loss: 1.167467]\n",
      "epoch:35 step:28052[D loss: 0.353108, acc: 69.53%, op_acc: 49.22%] [G loss: 1.429091]\n",
      "epoch:35 step:28053[D loss: 0.379749, acc: 64.84%, op_acc: 42.97%] [G loss: 1.380163]\n",
      "epoch:35 step:28054[D loss: 0.326742, acc: 75.00%, op_acc: 45.31%] [G loss: 1.229833]\n",
      "epoch:35 step:28055[D loss: 0.388424, acc: 67.97%, op_acc: 53.91%] [G loss: 1.605211]\n",
      "epoch:35 step:28056[D loss: 0.319331, acc: 78.91%, op_acc: 53.12%] [G loss: 1.512551]\n",
      "epoch:35 step:28057[D loss: 0.342238, acc: 76.56%, op_acc: 53.91%] [G loss: 1.283042]\n",
      "epoch:35 step:28058[D loss: 0.336866, acc: 75.00%, op_acc: 50.00%] [G loss: 1.126321]\n",
      "epoch:35 step:28059[D loss: 0.410365, acc: 67.19%, op_acc: 45.31%] [G loss: 1.246759]\n",
      "epoch:35 step:28060[D loss: 0.427341, acc: 64.84%, op_acc: 42.19%] [G loss: 1.185611]\n",
      "epoch:35 step:28061[D loss: 0.394550, acc: 68.75%, op_acc: 42.97%] [G loss: 1.465369]\n",
      "epoch:35 step:28062[D loss: 0.456797, acc: 57.81%, op_acc: 39.06%] [G loss: 1.300660]\n",
      "epoch:35 step:28063[D loss: 0.488415, acc: 57.03%, op_acc: 42.19%] [G loss: 1.383658]\n",
      "epoch:35 step:28064[D loss: 0.339593, acc: 69.53%, op_acc: 52.34%] [G loss: 1.435087]\n",
      "epoch:35 step:28065[D loss: 0.361010, acc: 74.22%, op_acc: 45.31%] [G loss: 1.322755]\n",
      "epoch:35 step:28066[D loss: 0.345011, acc: 72.66%, op_acc: 46.09%] [G loss: 1.336735]\n",
      "epoch:35 step:28067[D loss: 0.394843, acc: 64.84%, op_acc: 46.88%] [G loss: 1.157044]\n",
      "epoch:35 step:28068[D loss: 0.398111, acc: 65.62%, op_acc: 44.53%] [G loss: 1.273338]\n",
      "epoch:35 step:28069[D loss: 0.376954, acc: 71.09%, op_acc: 45.31%] [G loss: 1.401111]\n",
      "epoch:35 step:28070[D loss: 0.366699, acc: 71.88%, op_acc: 45.31%] [G loss: 1.400025]\n",
      "epoch:35 step:28071[D loss: 0.406956, acc: 63.28%, op_acc: 42.97%] [G loss: 1.353428]\n",
      "epoch:35 step:28072[D loss: 0.383795, acc: 67.19%, op_acc: 49.22%] [G loss: 1.127546]\n",
      "epoch:35 step:28073[D loss: 0.386965, acc: 67.97%, op_acc: 47.66%] [G loss: 1.264374]\n",
      "epoch:35 step:28074[D loss: 0.380462, acc: 68.75%, op_acc: 42.19%] [G loss: 1.271621]\n",
      "epoch:35 step:28075[D loss: 0.405706, acc: 64.06%, op_acc: 42.97%] [G loss: 1.196689]\n",
      "epoch:35 step:28076[D loss: 0.420156, acc: 63.28%, op_acc: 44.53%] [G loss: 1.250957]\n",
      "epoch:35 step:28077[D loss: 0.483231, acc: 55.47%, op_acc: 41.41%] [G loss: 1.058453]\n",
      "epoch:35 step:28078[D loss: 0.378944, acc: 68.75%, op_acc: 41.41%] [G loss: 1.324313]\n",
      "epoch:35 step:28079[D loss: 0.359458, acc: 68.75%, op_acc: 53.12%] [G loss: 1.395724]\n",
      "epoch:35 step:28080[D loss: 0.365515, acc: 67.19%, op_acc: 46.09%] [G loss: 1.152376]\n",
      "epoch:35 step:28081[D loss: 0.379562, acc: 70.31%, op_acc: 44.53%] [G loss: 1.017473]\n",
      "epoch:35 step:28082[D loss: 0.375816, acc: 71.09%, op_acc: 47.66%] [G loss: 1.234287]\n",
      "epoch:35 step:28083[D loss: 0.380523, acc: 66.41%, op_acc: 43.75%] [G loss: 1.209877]\n",
      "epoch:35 step:28084[D loss: 0.377187, acc: 68.75%, op_acc: 49.22%] [G loss: 1.184288]\n",
      "epoch:35 step:28085[D loss: 0.399268, acc: 63.28%, op_acc: 50.78%] [G loss: 1.172935]\n",
      "epoch:35 step:28086[D loss: 0.430224, acc: 68.75%, op_acc: 41.41%] [G loss: 1.047550]\n",
      "epoch:35 step:28087[D loss: 0.354602, acc: 75.00%, op_acc: 46.09%] [G loss: 1.343391]\n",
      "epoch:35 step:28088[D loss: 0.319428, acc: 75.78%, op_acc: 55.47%] [G loss: 1.065549]\n",
      "epoch:35 step:28089[D loss: 0.391368, acc: 70.31%, op_acc: 42.19%] [G loss: 1.299195]\n",
      "epoch:35 step:28090[D loss: 0.324382, acc: 80.47%, op_acc: 53.12%] [G loss: 1.333409]\n",
      "epoch:35 step:28091[D loss: 0.433445, acc: 60.94%, op_acc: 49.22%] [G loss: 1.059286]\n",
      "epoch:35 step:28092[D loss: 0.376343, acc: 71.09%, op_acc: 48.44%] [G loss: 1.459748]\n",
      "epoch:35 step:28093[D loss: 0.399571, acc: 66.41%, op_acc: 47.66%] [G loss: 0.956241]\n",
      "epoch:35 step:28094[D loss: 0.376744, acc: 67.97%, op_acc: 44.53%] [G loss: 1.276797]\n",
      "epoch:35 step:28095[D loss: 0.347193, acc: 73.44%, op_acc: 52.34%] [G loss: 1.048430]\n",
      "epoch:35 step:28096[D loss: 0.312960, acc: 83.59%, op_acc: 50.00%] [G loss: 1.185137]\n",
      "epoch:35 step:28097[D loss: 0.336042, acc: 78.12%, op_acc: 45.31%] [G loss: 1.026941]\n",
      "epoch:35 step:28098[D loss: 0.406363, acc: 66.41%, op_acc: 49.22%] [G loss: 1.337965]\n",
      "epoch:35 step:28099[D loss: 0.327434, acc: 75.00%, op_acc: 46.09%] [G loss: 1.398144]\n",
      "epoch:35 step:28100[D loss: 0.346547, acc: 69.53%, op_acc: 41.41%] [G loss: 1.398227]\n",
      "epoch:35 step:28101[D loss: 0.401807, acc: 65.62%, op_acc: 44.53%] [G loss: 1.362225]\n",
      "epoch:35 step:28102[D loss: 0.338552, acc: 76.56%, op_acc: 50.00%] [G loss: 1.222488]\n",
      "epoch:35 step:28103[D loss: 0.366140, acc: 68.75%, op_acc: 50.00%] [G loss: 1.259599]\n",
      "epoch:35 step:28104[D loss: 0.293293, acc: 86.72%, op_acc: 51.56%] [G loss: 1.503712]\n",
      "epoch:35 step:28105[D loss: 0.315078, acc: 79.69%, op_acc: 50.78%] [G loss: 1.538341]\n",
      "epoch:35 step:28106[D loss: 0.438445, acc: 63.28%, op_acc: 43.75%] [G loss: 0.727309]\n",
      "epoch:35 step:28107[D loss: 0.519335, acc: 53.91%, op_acc: 35.16%] [G loss: 1.363485]\n",
      "epoch:35 step:28108[D loss: 0.445392, acc: 61.72%, op_acc: 39.84%] [G loss: 1.049909]\n",
      "epoch:35 step:28109[D loss: 0.380073, acc: 64.84%, op_acc: 49.22%] [G loss: 1.639362]\n",
      "epoch:35 step:28110[D loss: 0.394798, acc: 60.16%, op_acc: 45.31%] [G loss: 1.474005]\n",
      "epoch:35 step:28111[D loss: 0.373457, acc: 67.19%, op_acc: 43.75%] [G loss: 1.416234]\n",
      "epoch:35 step:28112[D loss: 0.416924, acc: 64.84%, op_acc: 38.28%] [G loss: 1.255409]\n",
      "epoch:35 step:28113[D loss: 0.390042, acc: 70.31%, op_acc: 46.88%] [G loss: 1.558936]\n",
      "epoch:35 step:28114[D loss: 0.386180, acc: 68.75%, op_acc: 42.97%] [G loss: 1.360767]\n",
      "epoch:35 step:28115[D loss: 0.455412, acc: 53.12%, op_acc: 46.88%] [G loss: 1.147924]\n",
      "epoch:35 step:28116[D loss: 0.464172, acc: 60.94%, op_acc: 41.41%] [G loss: 1.134572]\n",
      "epoch:36 step:28117[D loss: 0.322617, acc: 79.69%, op_acc: 46.88%] [G loss: 1.400249]\n",
      "epoch:36 step:28118[D loss: 0.351939, acc: 67.97%, op_acc: 49.22%] [G loss: 1.406287]\n",
      "epoch:36 step:28119[D loss: 0.400162, acc: 58.59%, op_acc: 48.44%] [G loss: 1.131003]\n",
      "epoch:36 step:28120[D loss: 0.395337, acc: 66.41%, op_acc: 50.78%] [G loss: 1.185191]\n",
      "epoch:36 step:28121[D loss: 0.442605, acc: 60.16%, op_acc: 43.75%] [G loss: 1.283750]\n",
      "epoch:36 step:28122[D loss: 0.412609, acc: 63.28%, op_acc: 38.28%] [G loss: 1.180936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28123[D loss: 0.382242, acc: 69.53%, op_acc: 45.31%] [G loss: 1.365995]\n",
      "epoch:36 step:28124[D loss: 0.435313, acc: 57.03%, op_acc: 44.53%] [G loss: 1.076616]\n",
      "epoch:36 step:28125[D loss: 0.388098, acc: 70.31%, op_acc: 46.88%] [G loss: 1.364504]\n",
      "epoch:36 step:28126[D loss: 0.324745, acc: 77.34%, op_acc: 50.00%] [G loss: 1.433022]\n",
      "epoch:36 step:28127[D loss: 0.405097, acc: 67.19%, op_acc: 44.53%] [G loss: 1.135441]\n",
      "epoch:36 step:28128[D loss: 0.370306, acc: 73.44%, op_acc: 45.31%] [G loss: 0.987825]\n",
      "epoch:36 step:28129[D loss: 0.332303, acc: 77.34%, op_acc: 49.22%] [G loss: 1.048170]\n",
      "epoch:36 step:28130[D loss: 0.402045, acc: 67.19%, op_acc: 46.09%] [G loss: 1.107708]\n",
      "epoch:36 step:28131[D loss: 0.386949, acc: 65.62%, op_acc: 46.88%] [G loss: 1.098483]\n",
      "epoch:36 step:28132[D loss: 0.353932, acc: 72.66%, op_acc: 54.69%] [G loss: 1.167367]\n",
      "epoch:36 step:28133[D loss: 0.393615, acc: 66.41%, op_acc: 56.25%] [G loss: 1.005626]\n",
      "epoch:36 step:28134[D loss: 0.360158, acc: 70.31%, op_acc: 48.44%] [G loss: 1.035730]\n",
      "epoch:36 step:28135[D loss: 0.364318, acc: 67.97%, op_acc: 45.31%] [G loss: 0.984455]\n",
      "epoch:36 step:28136[D loss: 0.323658, acc: 78.12%, op_acc: 47.66%] [G loss: 1.173056]\n",
      "epoch:36 step:28137[D loss: 0.437235, acc: 62.50%, op_acc: 40.62%] [G loss: 1.274700]\n",
      "epoch:36 step:28138[D loss: 0.414650, acc: 64.06%, op_acc: 39.84%] [G loss: 1.005808]\n",
      "epoch:36 step:28139[D loss: 0.355015, acc: 71.88%, op_acc: 48.44%] [G loss: 1.258812]\n",
      "epoch:36 step:28140[D loss: 0.356276, acc: 79.69%, op_acc: 37.50%] [G loss: 0.945916]\n",
      "epoch:36 step:28141[D loss: 0.457634, acc: 60.16%, op_acc: 38.28%] [G loss: 1.000320]\n",
      "epoch:36 step:28142[D loss: 0.381909, acc: 67.19%, op_acc: 47.66%] [G loss: 0.840139]\n",
      "epoch:36 step:28143[D loss: 0.415263, acc: 64.06%, op_acc: 38.28%] [G loss: 1.140050]\n",
      "epoch:36 step:28144[D loss: 0.355647, acc: 77.34%, op_acc: 56.25%] [G loss: 0.905998]\n",
      "epoch:36 step:28145[D loss: 0.370256, acc: 63.28%, op_acc: 47.66%] [G loss: 1.449937]\n",
      "epoch:36 step:28146[D loss: 0.326164, acc: 75.78%, op_acc: 54.69%] [G loss: 1.140471]\n",
      "epoch:36 step:28147[D loss: 0.390379, acc: 67.97%, op_acc: 46.88%] [G loss: 1.307170]\n",
      "epoch:36 step:28148[D loss: 0.437892, acc: 64.06%, op_acc: 41.41%] [G loss: 0.984690]\n",
      "epoch:36 step:28149[D loss: 0.379246, acc: 64.06%, op_acc: 48.44%] [G loss: 0.694310]\n",
      "epoch:36 step:28150[D loss: 0.340522, acc: 75.00%, op_acc: 50.00%] [G loss: 1.216829]\n",
      "epoch:36 step:28151[D loss: 0.418676, acc: 62.50%, op_acc: 39.84%] [G loss: 0.804514]\n",
      "epoch:36 step:28152[D loss: 0.302789, acc: 75.00%, op_acc: 52.34%] [G loss: 1.065045]\n",
      "epoch:36 step:28153[D loss: 0.328623, acc: 74.22%, op_acc: 44.53%] [G loss: 1.040787]\n",
      "epoch:36 step:28154[D loss: 0.365847, acc: 74.22%, op_acc: 47.66%] [G loss: 0.698415]\n",
      "epoch:36 step:28155[D loss: 0.381961, acc: 64.84%, op_acc: 49.22%] [G loss: 0.740796]\n",
      "epoch:36 step:28156[D loss: 0.445032, acc: 55.47%, op_acc: 42.97%] [G loss: 0.820825]\n",
      "epoch:36 step:28157[D loss: 0.342983, acc: 67.97%, op_acc: 54.69%] [G loss: 0.946881]\n",
      "epoch:36 step:28158[D loss: 0.352082, acc: 70.31%, op_acc: 51.56%] [G loss: 1.026431]\n",
      "epoch:36 step:28159[D loss: 0.407531, acc: 67.19%, op_acc: 50.00%] [G loss: 1.122272]\n",
      "epoch:36 step:28160[D loss: 0.349035, acc: 71.88%, op_acc: 51.56%] [G loss: 1.074965]\n",
      "epoch:36 step:28161[D loss: 0.353577, acc: 76.56%, op_acc: 41.41%] [G loss: 1.233145]\n",
      "epoch:36 step:28162[D loss: 0.354255, acc: 71.88%, op_acc: 47.66%] [G loss: 1.006050]\n",
      "epoch:36 step:28163[D loss: 0.436668, acc: 66.41%, op_acc: 35.94%] [G loss: 0.938080]\n",
      "epoch:36 step:28164[D loss: 0.431976, acc: 63.28%, op_acc: 38.28%] [G loss: 1.187377]\n",
      "epoch:36 step:28165[D loss: 0.399123, acc: 60.16%, op_acc: 44.53%] [G loss: 1.175463]\n",
      "epoch:36 step:28166[D loss: 0.387637, acc: 69.53%, op_acc: 49.22%] [G loss: 1.415891]\n",
      "epoch:36 step:28167[D loss: 0.406075, acc: 68.75%, op_acc: 42.19%] [G loss: 0.904393]\n",
      "epoch:36 step:28168[D loss: 0.347311, acc: 76.56%, op_acc: 47.66%] [G loss: 1.041835]\n",
      "epoch:36 step:28169[D loss: 0.368895, acc: 69.53%, op_acc: 50.00%] [G loss: 0.999629]\n",
      "epoch:36 step:28170[D loss: 0.367598, acc: 74.22%, op_acc: 52.34%] [G loss: 1.157674]\n",
      "epoch:36 step:28171[D loss: 0.390835, acc: 67.19%, op_acc: 47.66%] [G loss: 0.803006]\n",
      "epoch:36 step:28172[D loss: 0.366435, acc: 72.66%, op_acc: 42.19%] [G loss: 0.868596]\n",
      "epoch:36 step:28173[D loss: 0.417959, acc: 60.16%, op_acc: 40.62%] [G loss: 0.844265]\n",
      "epoch:36 step:28174[D loss: 0.379347, acc: 65.62%, op_acc: 48.44%] [G loss: 0.929043]\n",
      "epoch:36 step:28175[D loss: 0.389332, acc: 67.97%, op_acc: 48.44%] [G loss: 1.335956]\n",
      "epoch:36 step:28176[D loss: 0.418995, acc: 64.84%, op_acc: 39.06%] [G loss: 0.927868]\n",
      "epoch:36 step:28177[D loss: 0.378170, acc: 72.66%, op_acc: 45.31%] [G loss: 1.028672]\n",
      "epoch:36 step:28178[D loss: 0.389164, acc: 62.50%, op_acc: 47.66%] [G loss: 0.582449]\n",
      "epoch:36 step:28179[D loss: 0.471305, acc: 55.47%, op_acc: 40.62%] [G loss: 1.369086]\n",
      "epoch:36 step:28180[D loss: 0.400076, acc: 60.94%, op_acc: 45.31%] [G loss: 0.937260]\n",
      "epoch:36 step:28181[D loss: 0.411451, acc: 64.06%, op_acc: 43.75%] [G loss: 1.050261]\n",
      "epoch:36 step:28182[D loss: 0.389330, acc: 64.84%, op_acc: 46.09%] [G loss: 1.305851]\n",
      "epoch:36 step:28183[D loss: 0.351655, acc: 75.78%, op_acc: 55.47%] [G loss: 1.301798]\n",
      "epoch:36 step:28184[D loss: 0.313032, acc: 79.69%, op_acc: 52.34%] [G loss: 1.386692]\n",
      "epoch:36 step:28185[D loss: 0.344482, acc: 70.31%, op_acc: 51.56%] [G loss: 0.637706]\n",
      "epoch:36 step:28186[D loss: 0.416473, acc: 67.19%, op_acc: 39.84%] [G loss: 0.642897]\n",
      "epoch:36 step:28187[D loss: 0.388995, acc: 70.31%, op_acc: 44.53%] [G loss: 0.804386]\n",
      "epoch:36 step:28188[D loss: 0.388026, acc: 66.41%, op_acc: 48.44%] [G loss: 0.903241]\n",
      "epoch:36 step:28189[D loss: 0.380574, acc: 74.22%, op_acc: 39.06%] [G loss: 0.920323]\n",
      "epoch:36 step:28190[D loss: 0.369769, acc: 70.31%, op_acc: 47.66%] [G loss: 1.118219]\n",
      "epoch:36 step:28191[D loss: 0.315732, acc: 78.91%, op_acc: 55.47%] [G loss: 1.107103]\n",
      "epoch:36 step:28192[D loss: 0.479310, acc: 53.91%, op_acc: 42.19%] [G loss: 0.768117]\n",
      "epoch:36 step:28193[D loss: 0.434960, acc: 56.25%, op_acc: 40.62%] [G loss: 1.259380]\n",
      "epoch:36 step:28194[D loss: 0.399690, acc: 71.09%, op_acc: 40.62%] [G loss: 0.967470]\n",
      "epoch:36 step:28195[D loss: 0.406257, acc: 59.38%, op_acc: 42.19%] [G loss: 1.292831]\n",
      "epoch:36 step:28196[D loss: 0.389008, acc: 65.62%, op_acc: 41.41%] [G loss: 1.114061]\n",
      "epoch:36 step:28197[D loss: 0.424519, acc: 64.06%, op_acc: 40.62%] [G loss: 1.123862]\n",
      "epoch:36 step:28198[D loss: 0.337276, acc: 70.31%, op_acc: 46.88%] [G loss: 1.493366]\n",
      "epoch:36 step:28199[D loss: 0.396307, acc: 65.62%, op_acc: 38.28%] [G loss: 1.044944]\n",
      "epoch:36 step:28200[D loss: 0.363740, acc: 76.56%, op_acc: 47.66%] [G loss: 1.564992]\n",
      "epoch:36 step:28201[D loss: 0.374807, acc: 77.34%, op_acc: 42.97%] [G loss: 0.946280]\n",
      "epoch:36 step:28202[D loss: 0.313961, acc: 79.69%, op_acc: 43.75%] [G loss: 1.341196]\n",
      "epoch:36 step:28203[D loss: 0.351003, acc: 71.88%, op_acc: 50.78%] [G loss: 0.968314]\n",
      "epoch:36 step:28204[D loss: 0.400933, acc: 69.53%, op_acc: 49.22%] [G loss: 0.963716]\n",
      "epoch:36 step:28205[D loss: 0.380795, acc: 65.62%, op_acc: 42.97%] [G loss: 0.865067]\n",
      "epoch:36 step:28206[D loss: 0.340037, acc: 78.91%, op_acc: 44.53%] [G loss: 1.142675]\n",
      "epoch:36 step:28207[D loss: 0.378986, acc: 69.53%, op_acc: 46.09%] [G loss: 1.179843]\n",
      "epoch:36 step:28208[D loss: 0.399971, acc: 60.94%, op_acc: 47.66%] [G loss: 1.101116]\n",
      "epoch:36 step:28209[D loss: 0.335746, acc: 74.22%, op_acc: 53.91%] [G loss: 1.032584]\n",
      "epoch:36 step:28210[D loss: 0.340227, acc: 76.56%, op_acc: 42.97%] [G loss: 1.104757]\n",
      "epoch:36 step:28211[D loss: 0.325834, acc: 73.44%, op_acc: 51.56%] [G loss: 1.240588]\n",
      "epoch:36 step:28212[D loss: 0.302708, acc: 82.03%, op_acc: 45.31%] [G loss: 1.476679]\n",
      "epoch:36 step:28213[D loss: 0.315497, acc: 80.47%, op_acc: 53.12%] [G loss: 1.652281]\n",
      "epoch:36 step:28214[D loss: 0.287785, acc: 85.16%, op_acc: 47.66%] [G loss: 1.505658]\n",
      "epoch:36 step:28215[D loss: 0.370548, acc: 66.41%, op_acc: 50.78%] [G loss: 1.373717]\n",
      "epoch:36 step:28216[D loss: 0.351684, acc: 74.22%, op_acc: 46.88%] [G loss: 1.310876]\n",
      "epoch:36 step:28217[D loss: 0.342839, acc: 78.12%, op_acc: 50.78%] [G loss: 1.655565]\n",
      "epoch:36 step:28218[D loss: 0.330917, acc: 74.22%, op_acc: 53.91%] [G loss: 1.553534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28219[D loss: 0.312219, acc: 77.34%, op_acc: 50.78%] [G loss: 1.608690]\n",
      "epoch:36 step:28220[D loss: 0.302653, acc: 76.56%, op_acc: 58.59%] [G loss: 1.663283]\n",
      "epoch:36 step:28221[D loss: 0.322030, acc: 82.03%, op_acc: 60.94%] [G loss: 1.673453]\n",
      "epoch:36 step:28222[D loss: 0.313715, acc: 77.34%, op_acc: 50.00%] [G loss: 1.688419]\n",
      "epoch:36 step:28223[D loss: 0.281979, acc: 82.81%, op_acc: 55.47%] [G loss: 1.679135]\n",
      "epoch:36 step:28224[D loss: 0.341349, acc: 73.44%, op_acc: 48.44%] [G loss: 0.844708]\n",
      "epoch:36 step:28225[D loss: 0.334504, acc: 74.22%, op_acc: 49.22%] [G loss: 1.833134]\n",
      "epoch:36 step:28226[D loss: 0.355079, acc: 73.44%, op_acc: 51.56%] [G loss: 1.579299]\n",
      "epoch:36 step:28227[D loss: 0.305444, acc: 81.25%, op_acc: 49.22%] [G loss: 1.847310]\n",
      "epoch:36 step:28228[D loss: 0.340463, acc: 77.34%, op_acc: 44.53%] [G loss: 1.756213]\n",
      "epoch:36 step:28229[D loss: 0.385261, acc: 65.62%, op_acc: 41.41%] [G loss: 1.881700]\n",
      "epoch:36 step:28230[D loss: 0.327524, acc: 78.12%, op_acc: 56.25%] [G loss: 0.647992]\n",
      "epoch:36 step:28231[D loss: 0.487639, acc: 48.44%, op_acc: 41.41%] [G loss: 1.719740]\n",
      "epoch:36 step:28232[D loss: 0.375760, acc: 71.09%, op_acc: 46.09%] [G loss: 1.329780]\n",
      "epoch:36 step:28233[D loss: 0.388570, acc: 67.19%, op_acc: 48.44%] [G loss: 1.616407]\n",
      "epoch:36 step:28234[D loss: 0.399657, acc: 66.41%, op_acc: 50.00%] [G loss: 1.353145]\n",
      "epoch:36 step:28235[D loss: 0.392919, acc: 69.53%, op_acc: 44.53%] [G loss: 1.422005]\n",
      "epoch:36 step:28236[D loss: 0.333006, acc: 75.78%, op_acc: 45.31%] [G loss: 1.699059]\n",
      "epoch:36 step:28237[D loss: 0.382279, acc: 67.97%, op_acc: 50.00%] [G loss: 1.161130]\n",
      "epoch:36 step:28238[D loss: 0.359620, acc: 71.88%, op_acc: 40.62%] [G loss: 1.319318]\n",
      "epoch:36 step:28239[D loss: 0.378830, acc: 67.97%, op_acc: 46.09%] [G loss: 1.318427]\n",
      "epoch:36 step:28240[D loss: 0.357356, acc: 72.66%, op_acc: 50.00%] [G loss: 0.948558]\n",
      "epoch:36 step:28241[D loss: 0.417748, acc: 65.62%, op_acc: 32.81%] [G loss: 1.081570]\n",
      "epoch:36 step:28242[D loss: 0.451528, acc: 57.03%, op_acc: 40.62%] [G loss: 1.394895]\n",
      "epoch:36 step:28243[D loss: 0.354206, acc: 76.56%, op_acc: 44.53%] [G loss: 1.285197]\n",
      "epoch:36 step:28244[D loss: 0.370882, acc: 76.56%, op_acc: 42.19%] [G loss: 1.413567]\n",
      "epoch:36 step:28245[D loss: 0.353584, acc: 75.78%, op_acc: 46.09%] [G loss: 1.470624]\n",
      "epoch:36 step:28246[D loss: 0.363759, acc: 74.22%, op_acc: 45.31%] [G loss: 1.384105]\n",
      "epoch:36 step:28247[D loss: 0.343888, acc: 78.12%, op_acc: 40.62%] [G loss: 1.001611]\n",
      "epoch:36 step:28248[D loss: 0.278808, acc: 83.59%, op_acc: 52.34%] [G loss: 1.190939]\n",
      "epoch:36 step:28249[D loss: 0.410703, acc: 72.66%, op_acc: 46.09%] [G loss: 1.162078]\n",
      "epoch:36 step:28250[D loss: 0.385968, acc: 69.53%, op_acc: 43.75%] [G loss: 1.235169]\n",
      "epoch:36 step:28251[D loss: 0.425510, acc: 57.81%, op_acc: 44.53%] [G loss: 0.891575]\n",
      "epoch:36 step:28252[D loss: 0.340229, acc: 75.00%, op_acc: 57.81%] [G loss: 0.973665]\n",
      "epoch:36 step:28253[D loss: 0.382685, acc: 69.53%, op_acc: 48.44%] [G loss: 1.356773]\n",
      "epoch:36 step:28254[D loss: 0.400583, acc: 64.84%, op_acc: 49.22%] [G loss: 1.250288]\n",
      "epoch:36 step:28255[D loss: 0.336708, acc: 76.56%, op_acc: 50.78%] [G loss: 1.303557]\n",
      "epoch:36 step:28256[D loss: 0.481054, acc: 60.94%, op_acc: 41.41%] [G loss: 1.475249]\n",
      "epoch:36 step:28257[D loss: 0.389749, acc: 70.31%, op_acc: 42.19%] [G loss: 1.260661]\n",
      "epoch:36 step:28258[D loss: 0.392652, acc: 72.66%, op_acc: 41.41%] [G loss: 1.568740]\n",
      "epoch:36 step:28259[D loss: 0.357118, acc: 72.66%, op_acc: 47.66%] [G loss: 1.458699]\n",
      "epoch:36 step:28260[D loss: 0.445851, acc: 58.59%, op_acc: 53.12%] [G loss: 0.759573]\n",
      "epoch:36 step:28261[D loss: 0.356646, acc: 69.53%, op_acc: 48.44%] [G loss: 0.886452]\n",
      "epoch:36 step:28262[D loss: 0.433812, acc: 58.59%, op_acc: 36.72%] [G loss: 1.607253]\n",
      "epoch:36 step:28263[D loss: 0.349467, acc: 75.00%, op_acc: 46.88%] [G loss: 1.129290]\n",
      "epoch:36 step:28264[D loss: 0.392780, acc: 73.44%, op_acc: 39.06%] [G loss: 1.492894]\n",
      "epoch:36 step:28265[D loss: 0.465435, acc: 59.38%, op_acc: 43.75%] [G loss: 0.836885]\n",
      "epoch:36 step:28266[D loss: 0.391147, acc: 63.28%, op_acc: 49.22%] [G loss: 1.014034]\n",
      "epoch:36 step:28267[D loss: 0.360881, acc: 69.53%, op_acc: 46.09%] [G loss: 1.084314]\n",
      "epoch:36 step:28268[D loss: 0.343896, acc: 71.88%, op_acc: 42.19%] [G loss: 1.133544]\n",
      "epoch:36 step:28269[D loss: 0.367223, acc: 72.66%, op_acc: 49.22%] [G loss: 1.141134]\n",
      "epoch:36 step:28270[D loss: 0.366555, acc: 67.97%, op_acc: 47.66%] [G loss: 1.133735]\n",
      "epoch:36 step:28271[D loss: 0.361292, acc: 69.53%, op_acc: 50.00%] [G loss: 1.317262]\n",
      "epoch:36 step:28272[D loss: 0.381952, acc: 64.06%, op_acc: 49.22%] [G loss: 0.819229]\n",
      "epoch:36 step:28273[D loss: 0.394709, acc: 67.19%, op_acc: 40.62%] [G loss: 0.960682]\n",
      "epoch:36 step:28274[D loss: 0.396170, acc: 67.19%, op_acc: 49.22%] [G loss: 1.053690]\n",
      "epoch:36 step:28275[D loss: 0.331869, acc: 78.91%, op_acc: 46.09%] [G loss: 1.206078]\n",
      "epoch:36 step:28276[D loss: 0.468208, acc: 55.47%, op_acc: 32.81%] [G loss: 1.399582]\n",
      "epoch:36 step:28277[D loss: 0.385008, acc: 64.84%, op_acc: 46.88%] [G loss: 1.484477]\n",
      "epoch:36 step:28278[D loss: 0.452821, acc: 60.16%, op_acc: 47.66%] [G loss: 1.024307]\n",
      "epoch:36 step:28279[D loss: 0.365194, acc: 71.88%, op_acc: 50.00%] [G loss: 1.088878]\n",
      "epoch:36 step:28280[D loss: 0.475689, acc: 54.69%, op_acc: 34.38%] [G loss: 1.011024]\n",
      "epoch:36 step:28281[D loss: 0.350063, acc: 75.00%, op_acc: 42.19%] [G loss: 1.369775]\n",
      "epoch:36 step:28282[D loss: 0.457197, acc: 63.28%, op_acc: 38.28%] [G loss: 1.261945]\n",
      "epoch:36 step:28283[D loss: 0.353997, acc: 75.78%, op_acc: 48.44%] [G loss: 1.325380]\n",
      "epoch:36 step:28284[D loss: 0.389275, acc: 61.72%, op_acc: 51.56%] [G loss: 1.142886]\n",
      "epoch:36 step:28285[D loss: 0.381525, acc: 70.31%, op_acc: 40.62%] [G loss: 1.285143]\n",
      "epoch:36 step:28286[D loss: 0.436105, acc: 56.25%, op_acc: 41.41%] [G loss: 0.851256]\n",
      "epoch:36 step:28287[D loss: 0.387307, acc: 66.41%, op_acc: 38.28%] [G loss: 0.803289]\n",
      "epoch:36 step:28288[D loss: 0.335227, acc: 80.47%, op_acc: 47.66%] [G loss: 0.665955]\n",
      "epoch:36 step:28289[D loss: 0.359838, acc: 70.31%, op_acc: 48.44%] [G loss: 0.658457]\n",
      "epoch:36 step:28290[D loss: 0.435446, acc: 61.72%, op_acc: 42.19%] [G loss: 1.137907]\n",
      "epoch:36 step:28291[D loss: 0.389975, acc: 71.09%, op_acc: 36.72%] [G loss: 0.589827]\n",
      "epoch:36 step:28292[D loss: 0.363651, acc: 71.88%, op_acc: 42.19%] [G loss: 1.184865]\n",
      "epoch:36 step:28293[D loss: 0.386527, acc: 67.19%, op_acc: 47.66%] [G loss: 0.605724]\n",
      "epoch:36 step:28294[D loss: 0.384189, acc: 67.97%, op_acc: 50.00%] [G loss: 0.646340]\n",
      "epoch:36 step:28295[D loss: 0.446823, acc: 54.69%, op_acc: 40.62%] [G loss: 0.708218]\n",
      "epoch:36 step:28296[D loss: 0.353903, acc: 69.53%, op_acc: 42.97%] [G loss: 0.852325]\n",
      "epoch:36 step:28297[D loss: 0.354871, acc: 71.88%, op_acc: 49.22%] [G loss: 1.177331]\n",
      "epoch:36 step:28298[D loss: 0.361170, acc: 67.97%, op_acc: 50.78%] [G loss: 1.295939]\n",
      "epoch:36 step:28299[D loss: 0.264284, acc: 87.50%, op_acc: 53.12%] [G loss: 1.330582]\n",
      "epoch:36 step:28300[D loss: 0.392158, acc: 63.28%, op_acc: 40.62%] [G loss: 1.456091]\n",
      "epoch:36 step:28301[D loss: 0.343827, acc: 71.88%, op_acc: 46.88%] [G loss: 1.114698]\n",
      "epoch:36 step:28302[D loss: 0.405975, acc: 59.38%, op_acc: 49.22%] [G loss: 1.045339]\n",
      "epoch:36 step:28303[D loss: 0.357272, acc: 71.88%, op_acc: 52.34%] [G loss: 0.995729]\n",
      "epoch:36 step:28304[D loss: 0.372293, acc: 68.75%, op_acc: 50.78%] [G loss: 0.823476]\n",
      "epoch:36 step:28305[D loss: 0.283804, acc: 86.72%, op_acc: 51.56%] [G loss: 1.433151]\n",
      "epoch:36 step:28306[D loss: 0.392599, acc: 68.75%, op_acc: 47.66%] [G loss: 0.899432]\n",
      "epoch:36 step:28307[D loss: 0.305190, acc: 82.81%, op_acc: 47.66%] [G loss: 0.722277]\n",
      "epoch:36 step:28308[D loss: 0.386915, acc: 68.75%, op_acc: 38.28%] [G loss: 0.804854]\n",
      "epoch:36 step:28309[D loss: 0.399190, acc: 73.44%, op_acc: 46.09%] [G loss: 0.762415]\n",
      "epoch:36 step:28310[D loss: 0.360395, acc: 75.78%, op_acc: 46.09%] [G loss: 1.289124]\n",
      "epoch:36 step:28311[D loss: 0.335945, acc: 75.78%, op_acc: 45.31%] [G loss: 1.617845]\n",
      "epoch:36 step:28312[D loss: 0.317521, acc: 81.25%, op_acc: 49.22%] [G loss: 1.312738]\n",
      "epoch:36 step:28313[D loss: 0.437941, acc: 73.44%, op_acc: 47.66%] [G loss: 1.135000]\n",
      "epoch:36 step:28314[D loss: 0.376525, acc: 69.53%, op_acc: 43.75%] [G loss: 1.350278]\n",
      "epoch:36 step:28315[D loss: 0.378882, acc: 68.75%, op_acc: 53.12%] [G loss: 1.053448]\n",
      "epoch:36 step:28316[D loss: 0.327115, acc: 78.12%, op_acc: 52.34%] [G loss: 1.377862]\n",
      "epoch:36 step:28317[D loss: 0.349904, acc: 72.66%, op_acc: 50.00%] [G loss: 1.393488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28318[D loss: 0.383285, acc: 67.19%, op_acc: 44.53%] [G loss: 0.997427]\n",
      "epoch:36 step:28319[D loss: 0.399532, acc: 68.75%, op_acc: 42.19%] [G loss: 0.998994]\n",
      "epoch:36 step:28320[D loss: 0.349100, acc: 71.88%, op_acc: 47.66%] [G loss: 1.248767]\n",
      "epoch:36 step:28321[D loss: 0.388744, acc: 70.31%, op_acc: 40.62%] [G loss: 1.479463]\n",
      "epoch:36 step:28322[D loss: 0.359178, acc: 72.66%, op_acc: 40.62%] [G loss: 1.346148]\n",
      "epoch:36 step:28323[D loss: 0.318348, acc: 77.34%, op_acc: 51.56%] [G loss: 1.019639]\n",
      "epoch:36 step:28324[D loss: 0.383486, acc: 71.09%, op_acc: 44.53%] [G loss: 1.299144]\n",
      "epoch:36 step:28325[D loss: 0.392582, acc: 66.41%, op_acc: 47.66%] [G loss: 0.948729]\n",
      "epoch:36 step:28326[D loss: 0.436187, acc: 59.38%, op_acc: 41.41%] [G loss: 1.385147]\n",
      "epoch:36 step:28327[D loss: 0.319180, acc: 78.91%, op_acc: 46.88%] [G loss: 0.982675]\n",
      "epoch:36 step:28328[D loss: 0.359159, acc: 75.00%, op_acc: 52.34%] [G loss: 1.151843]\n",
      "epoch:36 step:28329[D loss: 0.359824, acc: 73.44%, op_acc: 50.00%] [G loss: 1.096557]\n",
      "epoch:36 step:28330[D loss: 0.366812, acc: 72.66%, op_acc: 44.53%] [G loss: 1.120369]\n",
      "epoch:36 step:28331[D loss: 0.429553, acc: 63.28%, op_acc: 48.44%] [G loss: 1.164015]\n",
      "epoch:36 step:28332[D loss: 0.382261, acc: 67.19%, op_acc: 49.22%] [G loss: 1.050918]\n",
      "epoch:36 step:28333[D loss: 0.353589, acc: 72.66%, op_acc: 45.31%] [G loss: 1.069894]\n",
      "epoch:36 step:28334[D loss: 0.326950, acc: 79.69%, op_acc: 53.12%] [G loss: 1.266309]\n",
      "epoch:36 step:28335[D loss: 0.293932, acc: 85.94%, op_acc: 55.47%] [G loss: 1.202178]\n",
      "epoch:36 step:28336[D loss: 0.419233, acc: 64.84%, op_acc: 40.62%] [G loss: 1.049406]\n",
      "epoch:36 step:28337[D loss: 0.348604, acc: 72.66%, op_acc: 46.88%] [G loss: 1.100296]\n",
      "epoch:36 step:28338[D loss: 0.389929, acc: 66.41%, op_acc: 46.09%] [G loss: 1.263154]\n",
      "epoch:36 step:28339[D loss: 0.364146, acc: 69.53%, op_acc: 49.22%] [G loss: 1.106769]\n",
      "epoch:36 step:28340[D loss: 0.310380, acc: 80.47%, op_acc: 46.88%] [G loss: 1.302322]\n",
      "epoch:36 step:28341[D loss: 0.296622, acc: 81.25%, op_acc: 48.44%] [G loss: 1.172969]\n",
      "epoch:36 step:28342[D loss: 0.286430, acc: 85.16%, op_acc: 57.03%] [G loss: 1.478672]\n",
      "epoch:36 step:28343[D loss: 0.267271, acc: 87.50%, op_acc: 56.25%] [G loss: 1.544461]\n",
      "epoch:36 step:28344[D loss: 0.301884, acc: 77.34%, op_acc: 62.50%] [G loss: 0.697460]\n",
      "epoch:36 step:28345[D loss: 0.323809, acc: 82.03%, op_acc: 53.91%] [G loss: 1.353068]\n",
      "epoch:36 step:28346[D loss: 0.447254, acc: 59.38%, op_acc: 40.62%] [G loss: 1.136298]\n",
      "epoch:36 step:28347[D loss: 0.294357, acc: 78.12%, op_acc: 47.66%] [G loss: 1.432836]\n",
      "epoch:36 step:28348[D loss: 0.377725, acc: 68.75%, op_acc: 49.22%] [G loss: 1.506663]\n",
      "epoch:36 step:28349[D loss: 0.267701, acc: 84.38%, op_acc: 52.34%] [G loss: 1.630633]\n",
      "epoch:36 step:28350[D loss: 0.370251, acc: 72.66%, op_acc: 51.56%] [G loss: 1.496305]\n",
      "epoch:36 step:28351[D loss: 0.383699, acc: 67.19%, op_acc: 48.44%] [G loss: 1.566988]\n",
      "epoch:36 step:28352[D loss: 0.358095, acc: 73.44%, op_acc: 56.25%] [G loss: 1.022073]\n",
      "epoch:36 step:28353[D loss: 0.406855, acc: 61.72%, op_acc: 46.88%] [G loss: 0.967659]\n",
      "epoch:36 step:28354[D loss: 0.358277, acc: 72.66%, op_acc: 51.56%] [G loss: 1.262028]\n",
      "epoch:36 step:28355[D loss: 0.342906, acc: 68.75%, op_acc: 53.91%] [G loss: 1.325495]\n",
      "epoch:36 step:28356[D loss: 0.312191, acc: 78.91%, op_acc: 54.69%] [G loss: 0.987435]\n",
      "epoch:36 step:28357[D loss: 0.357657, acc: 71.09%, op_acc: 46.88%] [G loss: 1.134948]\n",
      "epoch:36 step:28358[D loss: 0.332933, acc: 75.00%, op_acc: 49.22%] [G loss: 1.379462]\n",
      "epoch:36 step:28359[D loss: 0.363654, acc: 72.66%, op_acc: 46.09%] [G loss: 1.180147]\n",
      "epoch:36 step:28360[D loss: 0.352484, acc: 75.00%, op_acc: 50.00%] [G loss: 1.329207]\n",
      "epoch:36 step:28361[D loss: 0.356968, acc: 71.88%, op_acc: 53.91%] [G loss: 1.437124]\n",
      "epoch:36 step:28362[D loss: 0.400502, acc: 69.53%, op_acc: 36.72%] [G loss: 1.307877]\n",
      "epoch:36 step:28363[D loss: 0.407906, acc: 61.72%, op_acc: 39.84%] [G loss: 1.536762]\n",
      "epoch:36 step:28364[D loss: 0.325891, acc: 74.22%, op_acc: 57.81%] [G loss: 0.868208]\n",
      "epoch:36 step:28365[D loss: 0.513308, acc: 57.03%, op_acc: 37.50%] [G loss: 0.753536]\n",
      "epoch:36 step:28366[D loss: 0.492550, acc: 57.03%, op_acc: 35.94%] [G loss: 0.958885]\n",
      "epoch:36 step:28367[D loss: 0.372101, acc: 67.19%, op_acc: 41.41%] [G loss: 1.496716]\n",
      "epoch:36 step:28368[D loss: 0.362236, acc: 72.66%, op_acc: 44.53%] [G loss: 1.300494]\n",
      "epoch:36 step:28369[D loss: 0.413582, acc: 66.41%, op_acc: 37.50%] [G loss: 1.292508]\n",
      "epoch:36 step:28370[D loss: 0.398409, acc: 66.41%, op_acc: 41.41%] [G loss: 1.185863]\n",
      "epoch:36 step:28371[D loss: 0.454096, acc: 60.16%, op_acc: 42.97%] [G loss: 0.988321]\n",
      "epoch:36 step:28372[D loss: 0.384412, acc: 75.00%, op_acc: 39.84%] [G loss: 1.150658]\n",
      "epoch:36 step:28373[D loss: 0.352850, acc: 74.22%, op_acc: 38.28%] [G loss: 0.901024]\n",
      "epoch:36 step:28374[D loss: 0.449961, acc: 60.16%, op_acc: 41.41%] [G loss: 1.211473]\n",
      "epoch:36 step:28375[D loss: 0.383972, acc: 68.75%, op_acc: 43.75%] [G loss: 0.956423]\n",
      "epoch:36 step:28376[D loss: 0.421013, acc: 66.41%, op_acc: 42.19%] [G loss: 0.797616]\n",
      "epoch:36 step:28377[D loss: 0.398733, acc: 67.19%, op_acc: 46.88%] [G loss: 1.284361]\n",
      "epoch:36 step:28378[D loss: 0.365053, acc: 71.88%, op_acc: 49.22%] [G loss: 0.890938]\n",
      "epoch:36 step:28379[D loss: 0.349398, acc: 75.78%, op_acc: 42.97%] [G loss: 1.346408]\n",
      "epoch:36 step:28380[D loss: 0.355461, acc: 75.78%, op_acc: 46.88%] [G loss: 0.915838]\n",
      "epoch:36 step:28381[D loss: 0.335811, acc: 78.91%, op_acc: 51.56%] [G loss: 0.780273]\n",
      "epoch:36 step:28382[D loss: 0.406945, acc: 65.62%, op_acc: 39.06%] [G loss: 1.279889]\n",
      "epoch:36 step:28383[D loss: 0.450430, acc: 57.81%, op_acc: 42.97%] [G loss: 1.292543]\n",
      "epoch:36 step:28384[D loss: 0.379399, acc: 66.41%, op_acc: 45.31%] [G loss: 0.883056]\n",
      "epoch:36 step:28385[D loss: 0.359081, acc: 73.44%, op_acc: 53.12%] [G loss: 1.002378]\n",
      "epoch:36 step:28386[D loss: 0.432670, acc: 61.72%, op_acc: 49.22%] [G loss: 0.776019]\n",
      "epoch:36 step:28387[D loss: 0.457288, acc: 56.25%, op_acc: 38.28%] [G loss: 0.781894]\n",
      "epoch:36 step:28388[D loss: 0.403110, acc: 70.31%, op_acc: 42.19%] [G loss: 0.904849]\n",
      "epoch:36 step:28389[D loss: 0.458946, acc: 58.59%, op_acc: 42.19%] [G loss: 1.020095]\n",
      "epoch:36 step:28390[D loss: 0.355984, acc: 71.88%, op_acc: 46.09%] [G loss: 0.899663]\n",
      "epoch:36 step:28391[D loss: 0.411326, acc: 67.97%, op_acc: 42.19%] [G loss: 0.897457]\n",
      "epoch:36 step:28392[D loss: 0.426883, acc: 68.75%, op_acc: 45.31%] [G loss: 0.962832]\n",
      "epoch:36 step:28393[D loss: 0.356662, acc: 75.00%, op_acc: 42.19%] [G loss: 1.480042]\n",
      "epoch:36 step:28394[D loss: 0.352543, acc: 73.44%, op_acc: 44.53%] [G loss: 1.243071]\n",
      "epoch:36 step:28395[D loss: 0.360159, acc: 73.44%, op_acc: 46.09%] [G loss: 1.136839]\n",
      "epoch:36 step:28396[D loss: 0.368685, acc: 71.88%, op_acc: 46.09%] [G loss: 1.487962]\n",
      "epoch:36 step:28397[D loss: 0.357326, acc: 72.66%, op_acc: 46.09%] [G loss: 1.223614]\n",
      "epoch:36 step:28398[D loss: 0.424802, acc: 67.19%, op_acc: 42.19%] [G loss: 1.182092]\n",
      "epoch:36 step:28399[D loss: 0.332499, acc: 78.91%, op_acc: 45.31%] [G loss: 1.261222]\n",
      "epoch:36 step:28400[D loss: 0.286168, acc: 88.28%, op_acc: 60.16%] [G loss: 1.145627]\n",
      "epoch:36 step:28401[D loss: 0.311780, acc: 82.03%, op_acc: 50.78%] [G loss: 1.368697]\n",
      "epoch:36 step:28402[D loss: 0.317852, acc: 84.38%, op_acc: 47.66%] [G loss: 1.358065]\n",
      "epoch:36 step:28403[D loss: 0.384201, acc: 70.31%, op_acc: 50.78%] [G loss: 1.308411]\n",
      "epoch:36 step:28404[D loss: 0.288519, acc: 84.38%, op_acc: 53.91%] [G loss: 1.503953]\n",
      "epoch:36 step:28405[D loss: 0.326013, acc: 80.47%, op_acc: 50.78%] [G loss: 1.465675]\n",
      "epoch:36 step:28406[D loss: 0.269590, acc: 85.94%, op_acc: 52.34%] [G loss: 1.517496]\n",
      "epoch:36 step:28407[D loss: 0.313362, acc: 82.81%, op_acc: 49.22%] [G loss: 0.927023]\n",
      "epoch:36 step:28408[D loss: 0.335585, acc: 76.56%, op_acc: 50.00%] [G loss: 1.474279]\n",
      "epoch:36 step:28409[D loss: 0.317279, acc: 78.91%, op_acc: 61.72%] [G loss: 1.644932]\n",
      "epoch:36 step:28410[D loss: 0.293394, acc: 82.03%, op_acc: 53.91%] [G loss: 1.906461]\n",
      "epoch:36 step:28411[D loss: 0.337366, acc: 77.34%, op_acc: 52.34%] [G loss: 0.823828]\n",
      "epoch:36 step:28412[D loss: 0.412978, acc: 60.94%, op_acc: 42.97%] [G loss: 1.125632]\n",
      "epoch:36 step:28413[D loss: 0.492639, acc: 53.91%, op_acc: 33.59%] [G loss: 1.268327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28414[D loss: 0.422273, acc: 65.62%, op_acc: 42.19%] [G loss: 1.279469]\n",
      "epoch:36 step:28415[D loss: 0.335140, acc: 76.56%, op_acc: 51.56%] [G loss: 1.301205]\n",
      "epoch:36 step:28416[D loss: 0.466365, acc: 60.94%, op_acc: 38.28%] [G loss: 1.187751]\n",
      "epoch:36 step:28417[D loss: 0.362696, acc: 74.22%, op_acc: 45.31%] [G loss: 1.127200]\n",
      "epoch:36 step:28418[D loss: 0.307355, acc: 79.69%, op_acc: 55.47%] [G loss: 1.313097]\n",
      "epoch:36 step:28419[D loss: 0.381992, acc: 67.97%, op_acc: 44.53%] [G loss: 1.058654]\n",
      "epoch:36 step:28420[D loss: 0.384651, acc: 64.84%, op_acc: 41.41%] [G loss: 1.253962]\n",
      "epoch:36 step:28421[D loss: 0.438557, acc: 60.16%, op_acc: 48.44%] [G loss: 1.837846]\n",
      "epoch:36 step:28422[D loss: 0.486315, acc: 56.25%, op_acc: 32.81%] [G loss: 1.255974]\n",
      "epoch:36 step:28423[D loss: 0.425169, acc: 64.06%, op_acc: 40.62%] [G loss: 1.750396]\n",
      "epoch:36 step:28424[D loss: 0.395543, acc: 67.19%, op_acc: 47.66%] [G loss: 1.286710]\n",
      "epoch:36 step:28425[D loss: 0.430040, acc: 60.94%, op_acc: 42.19%] [G loss: 1.103580]\n",
      "epoch:36 step:28426[D loss: 0.441840, acc: 52.34%, op_acc: 42.19%] [G loss: 1.058241]\n",
      "epoch:36 step:28427[D loss: 0.412331, acc: 60.94%, op_acc: 50.78%] [G loss: 1.045448]\n",
      "epoch:36 step:28428[D loss: 0.390623, acc: 61.72%, op_acc: 41.41%] [G loss: 0.962920]\n",
      "epoch:36 step:28429[D loss: 0.449085, acc: 60.94%, op_acc: 39.06%] [G loss: 1.213565]\n",
      "epoch:36 step:28430[D loss: 0.374249, acc: 70.31%, op_acc: 45.31%] [G loss: 1.302944]\n",
      "epoch:36 step:28431[D loss: 0.494842, acc: 53.12%, op_acc: 38.28%] [G loss: 1.245649]\n",
      "epoch:36 step:28432[D loss: 0.388877, acc: 70.31%, op_acc: 38.28%] [G loss: 1.081399]\n",
      "epoch:36 step:28433[D loss: 0.420839, acc: 64.84%, op_acc: 45.31%] [G loss: 1.289260]\n",
      "epoch:36 step:28434[D loss: 0.452506, acc: 54.69%, op_acc: 34.38%] [G loss: 0.853427]\n",
      "epoch:36 step:28435[D loss: 0.368388, acc: 71.09%, op_acc: 47.66%] [G loss: 1.442745]\n",
      "epoch:36 step:28436[D loss: 0.416778, acc: 61.72%, op_acc: 41.41%] [G loss: 0.863957]\n",
      "epoch:36 step:28437[D loss: 0.450256, acc: 64.06%, op_acc: 41.41%] [G loss: 1.105041]\n",
      "epoch:36 step:28438[D loss: 0.353259, acc: 68.75%, op_acc: 48.44%] [G loss: 1.513280]\n",
      "epoch:36 step:28439[D loss: 0.375689, acc: 67.19%, op_acc: 50.78%] [G loss: 1.135504]\n",
      "epoch:36 step:28440[D loss: 0.402328, acc: 67.19%, op_acc: 38.28%] [G loss: 0.712044]\n",
      "epoch:36 step:28441[D loss: 0.318830, acc: 76.56%, op_acc: 56.25%] [G loss: 1.129535]\n",
      "epoch:36 step:28442[D loss: 0.390900, acc: 63.28%, op_acc: 46.09%] [G loss: 0.778072]\n",
      "epoch:36 step:28443[D loss: 0.339919, acc: 75.00%, op_acc: 46.88%] [G loss: 0.658940]\n",
      "epoch:36 step:28444[D loss: 0.344459, acc: 73.44%, op_acc: 48.44%] [G loss: 0.758019]\n",
      "epoch:36 step:28445[D loss: 0.355529, acc: 66.41%, op_acc: 45.31%] [G loss: 1.035946]\n",
      "epoch:36 step:28446[D loss: 0.386876, acc: 67.19%, op_acc: 49.22%] [G loss: 0.762980]\n",
      "epoch:36 step:28447[D loss: 0.426350, acc: 60.94%, op_acc: 42.97%] [G loss: 0.781764]\n",
      "epoch:36 step:28448[D loss: 0.403168, acc: 66.41%, op_acc: 42.19%] [G loss: 0.622961]\n",
      "epoch:36 step:28449[D loss: 0.416130, acc: 67.97%, op_acc: 38.28%] [G loss: 0.801409]\n",
      "epoch:36 step:28450[D loss: 0.390790, acc: 60.94%, op_acc: 51.56%] [G loss: 0.921347]\n",
      "epoch:36 step:28451[D loss: 0.416757, acc: 64.84%, op_acc: 46.09%] [G loss: 1.205654]\n",
      "epoch:36 step:28452[D loss: 0.360759, acc: 74.22%, op_acc: 46.88%] [G loss: 1.162884]\n",
      "epoch:36 step:28453[D loss: 0.365880, acc: 75.00%, op_acc: 47.66%] [G loss: 1.193764]\n",
      "epoch:36 step:28454[D loss: 0.382696, acc: 63.28%, op_acc: 51.56%] [G loss: 1.309442]\n",
      "epoch:36 step:28455[D loss: 0.333144, acc: 76.56%, op_acc: 47.66%] [G loss: 1.372451]\n",
      "epoch:36 step:28456[D loss: 0.357153, acc: 71.09%, op_acc: 49.22%] [G loss: 1.167668]\n",
      "epoch:36 step:28457[D loss: 0.341427, acc: 73.44%, op_acc: 52.34%] [G loss: 1.506496]\n",
      "epoch:36 step:28458[D loss: 0.306952, acc: 82.03%, op_acc: 54.69%] [G loss: 0.764521]\n",
      "epoch:36 step:28459[D loss: 0.466655, acc: 51.56%, op_acc: 39.06%] [G loss: 1.248081]\n",
      "epoch:36 step:28460[D loss: 0.398940, acc: 64.06%, op_acc: 42.97%] [G loss: 1.295897]\n",
      "epoch:36 step:28461[D loss: 0.395428, acc: 72.66%, op_acc: 36.72%] [G loss: 1.133919]\n",
      "epoch:36 step:28462[D loss: 0.370749, acc: 72.66%, op_acc: 43.75%] [G loss: 1.212346]\n",
      "epoch:36 step:28463[D loss: 0.384699, acc: 66.41%, op_acc: 46.09%] [G loss: 1.225276]\n",
      "epoch:36 step:28464[D loss: 0.349793, acc: 70.31%, op_acc: 36.72%] [G loss: 1.714129]\n",
      "epoch:36 step:28465[D loss: 0.336690, acc: 72.66%, op_acc: 57.03%] [G loss: 1.643201]\n",
      "epoch:36 step:28466[D loss: 0.365526, acc: 71.09%, op_acc: 46.88%] [G loss: 1.435635]\n",
      "epoch:36 step:28467[D loss: 0.337775, acc: 75.00%, op_acc: 46.88%] [G loss: 0.962320]\n",
      "epoch:36 step:28468[D loss: 0.413769, acc: 67.97%, op_acc: 46.09%] [G loss: 1.358213]\n",
      "epoch:36 step:28469[D loss: 0.454500, acc: 59.38%, op_acc: 39.06%] [G loss: 0.834632]\n",
      "epoch:36 step:28470[D loss: 0.417642, acc: 60.16%, op_acc: 42.19%] [G loss: 1.084193]\n",
      "epoch:36 step:28471[D loss: 0.452949, acc: 57.81%, op_acc: 40.62%] [G loss: 1.016689]\n",
      "epoch:36 step:28472[D loss: 0.376607, acc: 68.75%, op_acc: 39.06%] [G loss: 0.529422]\n",
      "epoch:36 step:28473[D loss: 0.392266, acc: 70.31%, op_acc: 39.06%] [G loss: 0.542891]\n",
      "epoch:36 step:28474[D loss: 0.384335, acc: 76.56%, op_acc: 38.28%] [G loss: 0.676901]\n",
      "epoch:36 step:28475[D loss: 0.404001, acc: 60.16%, op_acc: 40.62%] [G loss: 0.592636]\n",
      "epoch:36 step:28476[D loss: 0.378308, acc: 71.09%, op_acc: 44.53%] [G loss: 0.581906]\n",
      "epoch:36 step:28477[D loss: 0.382241, acc: 64.06%, op_acc: 51.56%] [G loss: 1.465057]\n",
      "epoch:36 step:28478[D loss: 0.393714, acc: 64.84%, op_acc: 47.66%] [G loss: 0.557361]\n",
      "epoch:36 step:28479[D loss: 0.437955, acc: 60.16%, op_acc: 39.84%] [G loss: 0.535658]\n",
      "epoch:36 step:28480[D loss: 0.408317, acc: 64.84%, op_acc: 46.09%] [G loss: 0.411313]\n",
      "epoch:36 step:28481[D loss: 0.338265, acc: 71.88%, op_acc: 52.34%] [G loss: 0.699600]\n",
      "epoch:36 step:28482[D loss: 0.398733, acc: 63.28%, op_acc: 46.09%] [G loss: 0.800743]\n",
      "epoch:36 step:28483[D loss: 0.359115, acc: 78.91%, op_acc: 41.41%] [G loss: 0.694463]\n",
      "epoch:36 step:28484[D loss: 0.384050, acc: 71.09%, op_acc: 45.31%] [G loss: 0.960171]\n",
      "epoch:36 step:28485[D loss: 0.430843, acc: 62.50%, op_acc: 39.06%] [G loss: 0.832347]\n",
      "epoch:36 step:28486[D loss: 0.396205, acc: 64.06%, op_acc: 42.97%] [G loss: 1.001996]\n",
      "epoch:36 step:28487[D loss: 0.303184, acc: 73.44%, op_acc: 61.72%] [G loss: 1.046736]\n",
      "epoch:36 step:28488[D loss: 0.373419, acc: 67.97%, op_acc: 51.56%] [G loss: 1.443743]\n",
      "epoch:36 step:28489[D loss: 0.291614, acc: 82.81%, op_acc: 50.78%] [G loss: 1.211157]\n",
      "epoch:36 step:28490[D loss: 0.336250, acc: 76.56%, op_acc: 47.66%] [G loss: 1.021391]\n",
      "epoch:36 step:28491[D loss: 0.408404, acc: 64.84%, op_acc: 42.97%] [G loss: 1.290493]\n",
      "epoch:36 step:28492[D loss: 0.352250, acc: 71.88%, op_acc: 39.06%] [G loss: 1.202167]\n",
      "epoch:36 step:28493[D loss: 0.361368, acc: 67.19%, op_acc: 42.97%] [G loss: 0.812667]\n",
      "epoch:36 step:28494[D loss: 0.328281, acc: 75.00%, op_acc: 50.78%] [G loss: 1.370750]\n",
      "epoch:36 step:28495[D loss: 0.316997, acc: 76.56%, op_acc: 43.75%] [G loss: 1.127139]\n",
      "epoch:36 step:28496[D loss: 0.386546, acc: 63.28%, op_acc: 42.97%] [G loss: 1.090781]\n",
      "epoch:36 step:28497[D loss: 0.339368, acc: 79.69%, op_acc: 51.56%] [G loss: 0.946942]\n",
      "epoch:36 step:28498[D loss: 0.392523, acc: 66.41%, op_acc: 46.88%] [G loss: 1.237013]\n",
      "epoch:36 step:28499[D loss: 0.398762, acc: 61.72%, op_acc: 46.88%] [G loss: 0.717552]\n",
      "epoch:36 step:28500[D loss: 0.350494, acc: 72.66%, op_acc: 46.09%] [G loss: 0.825896]\n",
      "epoch:36 step:28501[D loss: 0.318429, acc: 73.44%, op_acc: 50.78%] [G loss: 0.824805]\n",
      "epoch:36 step:28502[D loss: 0.336050, acc: 75.00%, op_acc: 50.00%] [G loss: 1.651679]\n",
      "epoch:36 step:28503[D loss: 0.374663, acc: 70.31%, op_acc: 42.19%] [G loss: 0.563893]\n",
      "epoch:36 step:28504[D loss: 0.446531, acc: 61.72%, op_acc: 37.50%] [G loss: 1.215031]\n",
      "epoch:36 step:28505[D loss: 0.395761, acc: 65.62%, op_acc: 46.09%] [G loss: 0.678024]\n",
      "epoch:36 step:28506[D loss: 0.378255, acc: 65.62%, op_acc: 51.56%] [G loss: 0.784689]\n",
      "epoch:36 step:28507[D loss: 0.428749, acc: 57.03%, op_acc: 50.00%] [G loss: 1.200209]\n",
      "epoch:36 step:28508[D loss: 0.290276, acc: 78.91%, op_acc: 50.78%] [G loss: 0.562631]\n",
      "epoch:36 step:28509[D loss: 0.366143, acc: 68.75%, op_acc: 48.44%] [G loss: 0.639692]\n",
      "epoch:36 step:28510[D loss: 0.332309, acc: 76.56%, op_acc: 50.78%] [G loss: 1.459596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28511[D loss: 0.470182, acc: 54.69%, op_acc: 37.50%] [G loss: 0.574780]\n",
      "epoch:36 step:28512[D loss: 0.393907, acc: 67.19%, op_acc: 42.97%] [G loss: 0.522572]\n",
      "epoch:36 step:28513[D loss: 0.463178, acc: 57.03%, op_acc: 43.75%] [G loss: 1.118031]\n",
      "epoch:36 step:28514[D loss: 0.384684, acc: 71.88%, op_acc: 39.84%] [G loss: 0.565218]\n",
      "epoch:36 step:28515[D loss: 0.408651, acc: 65.62%, op_acc: 47.66%] [G loss: 0.993406]\n",
      "epoch:36 step:28516[D loss: 0.376253, acc: 65.62%, op_acc: 49.22%] [G loss: 1.310304]\n",
      "epoch:36 step:28517[D loss: 0.359206, acc: 75.78%, op_acc: 57.81%] [G loss: 0.903808]\n",
      "epoch:36 step:28518[D loss: 0.329060, acc: 78.91%, op_acc: 52.34%] [G loss: 1.042964]\n",
      "epoch:36 step:28519[D loss: 0.300752, acc: 78.12%, op_acc: 45.31%] [G loss: 0.929346]\n",
      "epoch:36 step:28520[D loss: 0.261039, acc: 86.72%, op_acc: 51.56%] [G loss: 0.873727]\n",
      "epoch:36 step:28521[D loss: 0.392404, acc: 66.41%, op_acc: 46.09%] [G loss: 0.989846]\n",
      "epoch:36 step:28522[D loss: 0.388242, acc: 64.06%, op_acc: 43.75%] [G loss: 1.067733]\n",
      "epoch:36 step:28523[D loss: 0.322371, acc: 79.69%, op_acc: 48.44%] [G loss: 1.668198]\n",
      "epoch:36 step:28524[D loss: 0.344709, acc: 71.88%, op_acc: 42.97%] [G loss: 1.141612]\n",
      "epoch:36 step:28525[D loss: 0.402229, acc: 60.94%, op_acc: 46.88%] [G loss: 0.999227]\n",
      "epoch:36 step:28526[D loss: 0.369518, acc: 72.66%, op_acc: 43.75%] [G loss: 0.732554]\n",
      "epoch:36 step:28527[D loss: 0.436671, acc: 59.38%, op_acc: 46.88%] [G loss: 0.727799]\n",
      "epoch:36 step:28528[D loss: 0.368096, acc: 73.44%, op_acc: 46.09%] [G loss: 0.807231]\n",
      "epoch:36 step:28529[D loss: 0.334438, acc: 80.47%, op_acc: 46.09%] [G loss: 0.852045]\n",
      "epoch:36 step:28530[D loss: 0.418900, acc: 63.28%, op_acc: 44.53%] [G loss: 1.314045]\n",
      "epoch:36 step:28531[D loss: 0.327619, acc: 75.78%, op_acc: 50.78%] [G loss: 1.287706]\n",
      "epoch:36 step:28532[D loss: 0.313774, acc: 78.12%, op_acc: 56.25%] [G loss: 0.867909]\n",
      "epoch:36 step:28533[D loss: 0.398488, acc: 64.06%, op_acc: 43.75%] [G loss: 0.930193]\n",
      "epoch:36 step:28534[D loss: 0.358230, acc: 71.09%, op_acc: 49.22%] [G loss: 1.254775]\n",
      "epoch:36 step:28535[D loss: 0.362768, acc: 72.66%, op_acc: 43.75%] [G loss: 0.830955]\n",
      "epoch:36 step:28536[D loss: 0.405199, acc: 60.16%, op_acc: 51.56%] [G loss: 0.821742]\n",
      "epoch:36 step:28537[D loss: 0.377636, acc: 68.75%, op_acc: 53.91%] [G loss: 0.732240]\n",
      "epoch:36 step:28538[D loss: 0.354801, acc: 71.09%, op_acc: 44.53%] [G loss: 0.774174]\n",
      "epoch:36 step:28539[D loss: 0.360974, acc: 69.53%, op_acc: 50.00%] [G loss: 1.301701]\n",
      "epoch:36 step:28540[D loss: 0.358985, acc: 73.44%, op_acc: 46.09%] [G loss: 0.670988]\n",
      "epoch:36 step:28541[D loss: 0.353851, acc: 68.75%, op_acc: 46.88%] [G loss: 1.177795]\n",
      "epoch:36 step:28542[D loss: 0.377964, acc: 71.09%, op_acc: 41.41%] [G loss: 0.525547]\n",
      "epoch:36 step:28543[D loss: 0.449752, acc: 59.38%, op_acc: 39.84%] [G loss: 0.725233]\n",
      "epoch:36 step:28544[D loss: 0.348965, acc: 73.44%, op_acc: 50.78%] [G loss: 0.959099]\n",
      "epoch:36 step:28545[D loss: 0.392319, acc: 64.06%, op_acc: 41.41%] [G loss: 1.081021]\n",
      "epoch:36 step:28546[D loss: 0.428142, acc: 62.50%, op_acc: 39.84%] [G loss: 1.127758]\n",
      "epoch:36 step:28547[D loss: 0.408607, acc: 61.72%, op_acc: 47.66%] [G loss: 1.285272]\n",
      "epoch:36 step:28548[D loss: 0.393441, acc: 69.53%, op_acc: 46.09%] [G loss: 0.750949]\n",
      "epoch:36 step:28549[D loss: 0.339754, acc: 77.34%, op_acc: 50.00%] [G loss: 0.632576]\n",
      "epoch:36 step:28550[D loss: 0.398803, acc: 63.28%, op_acc: 47.66%] [G loss: 1.294245]\n",
      "epoch:36 step:28551[D loss: 0.339307, acc: 71.88%, op_acc: 48.44%] [G loss: 0.703832]\n",
      "epoch:36 step:28552[D loss: 0.512028, acc: 47.66%, op_acc: 39.06%] [G loss: 0.565598]\n",
      "epoch:36 step:28553[D loss: 0.401890, acc: 65.62%, op_acc: 43.75%] [G loss: 0.870647]\n",
      "epoch:36 step:28554[D loss: 0.340971, acc: 73.44%, op_acc: 54.69%] [G loss: 1.419324]\n",
      "epoch:36 step:28555[D loss: 0.378535, acc: 60.94%, op_acc: 46.09%] [G loss: 0.838020]\n",
      "epoch:36 step:28556[D loss: 0.404974, acc: 69.53%, op_acc: 43.75%] [G loss: 0.841056]\n",
      "epoch:36 step:28557[D loss: 0.376547, acc: 66.41%, op_acc: 42.19%] [G loss: 0.914194]\n",
      "epoch:36 step:28558[D loss: 0.319925, acc: 77.34%, op_acc: 50.78%] [G loss: 1.449377]\n",
      "epoch:36 step:28559[D loss: 0.367378, acc: 71.09%, op_acc: 46.09%] [G loss: 1.401440]\n",
      "epoch:36 step:28560[D loss: 0.329030, acc: 73.44%, op_acc: 53.91%] [G loss: 1.372305]\n",
      "epoch:36 step:28561[D loss: 0.443982, acc: 57.03%, op_acc: 37.50%] [G loss: 1.156562]\n",
      "epoch:36 step:28562[D loss: 0.364556, acc: 69.53%, op_acc: 49.22%] [G loss: 1.408305]\n",
      "epoch:36 step:28563[D loss: 0.431593, acc: 63.28%, op_acc: 40.62%] [G loss: 1.355369]\n",
      "epoch:36 step:28564[D loss: 0.350036, acc: 75.00%, op_acc: 44.53%] [G loss: 0.876333]\n",
      "epoch:36 step:28565[D loss: 0.346424, acc: 70.31%, op_acc: 45.31%] [G loss: 0.996650]\n",
      "epoch:36 step:28566[D loss: 0.388316, acc: 68.75%, op_acc: 39.06%] [G loss: 0.881101]\n",
      "epoch:36 step:28567[D loss: 0.423980, acc: 60.94%, op_acc: 42.97%] [G loss: 1.358339]\n",
      "epoch:36 step:28568[D loss: 0.362452, acc: 68.75%, op_acc: 46.09%] [G loss: 0.883011]\n",
      "epoch:36 step:28569[D loss: 0.432034, acc: 60.94%, op_acc: 49.22%] [G loss: 0.851885]\n",
      "epoch:36 step:28570[D loss: 0.361110, acc: 73.44%, op_acc: 48.44%] [G loss: 1.393874]\n",
      "epoch:36 step:28571[D loss: 0.452779, acc: 56.25%, op_acc: 45.31%] [G loss: 1.113299]\n",
      "epoch:36 step:28572[D loss: 0.376586, acc: 72.66%, op_acc: 43.75%] [G loss: 0.805737]\n",
      "epoch:36 step:28573[D loss: 0.386607, acc: 63.28%, op_acc: 42.97%] [G loss: 0.718966]\n",
      "epoch:36 step:28574[D loss: 0.352729, acc: 72.66%, op_acc: 50.78%] [G loss: 1.100553]\n",
      "epoch:36 step:28575[D loss: 0.431951, acc: 57.81%, op_acc: 46.09%] [G loss: 0.805826]\n",
      "epoch:36 step:28576[D loss: 0.391519, acc: 63.28%, op_acc: 46.09%] [G loss: 0.680945]\n",
      "epoch:36 step:28577[D loss: 0.374819, acc: 71.88%, op_acc: 46.09%] [G loss: 0.709481]\n",
      "epoch:36 step:28578[D loss: 0.343048, acc: 74.22%, op_acc: 41.41%] [G loss: 0.832570]\n",
      "epoch:36 step:28579[D loss: 0.404351, acc: 64.84%, op_acc: 42.97%] [G loss: 0.704126]\n",
      "epoch:36 step:28580[D loss: 0.427781, acc: 64.84%, op_acc: 39.84%] [G loss: 1.286854]\n",
      "epoch:36 step:28581[D loss: 0.339568, acc: 78.12%, op_acc: 49.22%] [G loss: 0.860660]\n",
      "epoch:36 step:28582[D loss: 0.361865, acc: 71.09%, op_acc: 47.66%] [G loss: 1.320949]\n",
      "epoch:36 step:28583[D loss: 0.366577, acc: 68.75%, op_acc: 48.44%] [G loss: 1.218468]\n",
      "epoch:36 step:28584[D loss: 0.364086, acc: 71.88%, op_acc: 46.09%] [G loss: 0.919061]\n",
      "epoch:36 step:28585[D loss: 0.369962, acc: 69.53%, op_acc: 53.12%] [G loss: 0.923479]\n",
      "epoch:36 step:28586[D loss: 0.313890, acc: 75.00%, op_acc: 53.12%] [G loss: 0.946205]\n",
      "epoch:36 step:28587[D loss: 0.376393, acc: 73.44%, op_acc: 48.44%] [G loss: 1.208908]\n",
      "epoch:36 step:28588[D loss: 0.313127, acc: 73.44%, op_acc: 53.12%] [G loss: 0.999308]\n",
      "epoch:36 step:28589[D loss: 0.340099, acc: 72.66%, op_acc: 46.88%] [G loss: 0.716980]\n",
      "epoch:36 step:28590[D loss: 0.412571, acc: 63.28%, op_acc: 43.75%] [G loss: 0.998450]\n",
      "epoch:36 step:28591[D loss: 0.423884, acc: 60.94%, op_acc: 45.31%] [G loss: 0.920220]\n",
      "epoch:36 step:28592[D loss: 0.381746, acc: 66.41%, op_acc: 43.75%] [G loss: 0.906047]\n",
      "epoch:36 step:28593[D loss: 0.311381, acc: 83.59%, op_acc: 56.25%] [G loss: 1.099940]\n",
      "epoch:36 step:28594[D loss: 0.327191, acc: 78.91%, op_acc: 59.38%] [G loss: 1.462312]\n",
      "epoch:36 step:28595[D loss: 0.310710, acc: 81.25%, op_acc: 49.22%] [G loss: 1.110069]\n",
      "epoch:36 step:28596[D loss: 0.300514, acc: 84.38%, op_acc: 49.22%] [G loss: 1.141028]\n",
      "epoch:36 step:28597[D loss: 0.365992, acc: 78.91%, op_acc: 47.66%] [G loss: 1.109443]\n",
      "epoch:36 step:28598[D loss: 0.384167, acc: 68.75%, op_acc: 46.88%] [G loss: 1.124248]\n",
      "epoch:36 step:28599[D loss: 0.321260, acc: 75.00%, op_acc: 53.91%] [G loss: 1.048808]\n",
      "epoch:36 step:28600[D loss: 0.340205, acc: 77.34%, op_acc: 48.44%] [G loss: 1.149885]\n",
      "epoch:36 step:28601[D loss: 0.356525, acc: 74.22%, op_acc: 42.97%] [G loss: 1.064934]\n",
      "epoch:36 step:28602[D loss: 0.329164, acc: 73.44%, op_acc: 51.56%] [G loss: 0.824818]\n",
      "epoch:36 step:28603[D loss: 0.495316, acc: 49.22%, op_acc: 39.84%] [G loss: 1.158984]\n",
      "epoch:36 step:28604[D loss: 0.356924, acc: 73.44%, op_acc: 42.19%] [G loss: 1.184265]\n",
      "epoch:36 step:28605[D loss: 0.362997, acc: 65.62%, op_acc: 54.69%] [G loss: 1.317240]\n",
      "epoch:36 step:28606[D loss: 0.329342, acc: 78.12%, op_acc: 48.44%] [G loss: 1.105333]\n",
      "epoch:36 step:28607[D loss: 0.508146, acc: 54.69%, op_acc: 33.59%] [G loss: 0.900373]\n",
      "epoch:36 step:28608[D loss: 0.384242, acc: 66.41%, op_acc: 45.31%] [G loss: 1.084144]\n",
      "epoch:36 step:28609[D loss: 0.373449, acc: 71.09%, op_acc: 46.09%] [G loss: 0.917378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28610[D loss: 0.318683, acc: 80.47%, op_acc: 49.22%] [G loss: 0.949582]\n",
      "epoch:36 step:28611[D loss: 0.321634, acc: 79.69%, op_acc: 50.00%] [G loss: 0.859773]\n",
      "epoch:36 step:28612[D loss: 0.344744, acc: 76.56%, op_acc: 49.22%] [G loss: 1.108350]\n",
      "epoch:36 step:28613[D loss: 0.330702, acc: 77.34%, op_acc: 50.00%] [G loss: 1.336004]\n",
      "epoch:36 step:28614[D loss: 0.389030, acc: 66.41%, op_acc: 47.66%] [G loss: 1.529765]\n",
      "epoch:36 step:28615[D loss: 0.399948, acc: 71.88%, op_acc: 50.78%] [G loss: 1.517828]\n",
      "epoch:36 step:28616[D loss: 0.347564, acc: 71.09%, op_acc: 45.31%] [G loss: 1.073496]\n",
      "epoch:36 step:28617[D loss: 0.393345, acc: 67.19%, op_acc: 40.62%] [G loss: 0.919661]\n",
      "epoch:36 step:28618[D loss: 0.337612, acc: 76.56%, op_acc: 50.00%] [G loss: 1.545676]\n",
      "epoch:36 step:28619[D loss: 0.333142, acc: 74.22%, op_acc: 50.00%] [G loss: 1.093997]\n",
      "epoch:36 step:28620[D loss: 0.447218, acc: 57.03%, op_acc: 47.66%] [G loss: 0.962585]\n",
      "epoch:36 step:28621[D loss: 0.386409, acc: 68.75%, op_acc: 46.88%] [G loss: 1.169160]\n",
      "epoch:36 step:28622[D loss: 0.354561, acc: 72.66%, op_acc: 52.34%] [G loss: 0.950477]\n",
      "epoch:36 step:28623[D loss: 0.292854, acc: 82.81%, op_acc: 53.91%] [G loss: 0.971110]\n",
      "epoch:36 step:28624[D loss: 0.344335, acc: 71.88%, op_acc: 53.91%] [G loss: 0.872503]\n",
      "epoch:36 step:28625[D loss: 0.335475, acc: 78.91%, op_acc: 46.88%] [G loss: 0.981150]\n",
      "epoch:36 step:28626[D loss: 0.287955, acc: 85.16%, op_acc: 57.81%] [G loss: 0.997986]\n",
      "epoch:36 step:28627[D loss: 0.338697, acc: 73.44%, op_acc: 49.22%] [G loss: 1.050283]\n",
      "epoch:36 step:28628[D loss: 0.328355, acc: 76.56%, op_acc: 52.34%] [G loss: 1.084628]\n",
      "epoch:36 step:28629[D loss: 0.319892, acc: 76.56%, op_acc: 55.47%] [G loss: 1.225171]\n",
      "epoch:36 step:28630[D loss: 0.338197, acc: 73.44%, op_acc: 57.81%] [G loss: 1.258990]\n",
      "epoch:36 step:28631[D loss: 0.256393, acc: 86.72%, op_acc: 54.69%] [G loss: 1.303004]\n",
      "epoch:36 step:28632[D loss: 0.239811, acc: 88.28%, op_acc: 56.25%] [G loss: 1.382197]\n",
      "epoch:36 step:28633[D loss: 0.272305, acc: 85.94%, op_acc: 62.50%] [G loss: 1.420528]\n",
      "epoch:36 step:28634[D loss: 0.248903, acc: 89.06%, op_acc: 55.47%] [G loss: 1.543607]\n",
      "epoch:36 step:28635[D loss: 0.226819, acc: 89.84%, op_acc: 61.72%] [G loss: 1.837355]\n",
      "epoch:36 step:28636[D loss: 0.269236, acc: 83.59%, op_acc: 61.72%] [G loss: 1.622175]\n",
      "epoch:36 step:28637[D loss: 0.230668, acc: 90.62%, op_acc: 64.84%] [G loss: 1.727586]\n",
      "epoch:36 step:28638[D loss: 0.244019, acc: 89.84%, op_acc: 62.50%] [G loss: 1.839031]\n",
      "epoch:36 step:28639[D loss: 0.264902, acc: 85.16%, op_acc: 57.03%] [G loss: 2.047337]\n",
      "epoch:36 step:28640[D loss: 0.234059, acc: 92.19%, op_acc: 61.72%] [G loss: 2.024281]\n",
      "epoch:36 step:28641[D loss: 0.224209, acc: 92.19%, op_acc: 61.72%] [G loss: 1.886777]\n",
      "epoch:36 step:28642[D loss: 0.331714, acc: 76.56%, op_acc: 57.03%] [G loss: 1.932243]\n",
      "epoch:36 step:28643[D loss: 0.280040, acc: 82.81%, op_acc: 50.78%] [G loss: 1.811370]\n",
      "epoch:36 step:28644[D loss: 0.214945, acc: 90.62%, op_acc: 67.19%] [G loss: 1.990731]\n",
      "epoch:36 step:28645[D loss: 0.244237, acc: 89.84%, op_acc: 55.47%] [G loss: 1.314748]\n",
      "epoch:36 step:28646[D loss: 0.251273, acc: 87.50%, op_acc: 48.44%] [G loss: 1.886415]\n",
      "epoch:36 step:28647[D loss: 0.231106, acc: 92.19%, op_acc: 55.47%] [G loss: 2.089042]\n",
      "epoch:36 step:28648[D loss: 0.304874, acc: 78.12%, op_acc: 53.91%] [G loss: 0.441759]\n",
      "epoch:36 step:28649[D loss: 0.645108, acc: 52.34%, op_acc: 34.38%] [G loss: 1.814007]\n",
      "epoch:36 step:28650[D loss: 0.432616, acc: 60.94%, op_acc: 41.41%] [G loss: 0.894849]\n",
      "epoch:36 step:28651[D loss: 0.568790, acc: 39.84%, op_acc: 35.16%] [G loss: 1.987491]\n",
      "epoch:36 step:28652[D loss: 0.389347, acc: 62.50%, op_acc: 52.34%] [G loss: 2.407466]\n",
      "epoch:36 step:28653[D loss: 0.376753, acc: 72.66%, op_acc: 57.03%] [G loss: 2.168850]\n",
      "epoch:36 step:28654[D loss: 0.366037, acc: 70.31%, op_acc: 41.41%] [G loss: 1.977395]\n",
      "epoch:36 step:28655[D loss: 0.396977, acc: 68.75%, op_acc: 39.84%] [G loss: 2.135068]\n",
      "epoch:36 step:28656[D loss: 0.343221, acc: 77.34%, op_acc: 43.75%] [G loss: 1.904490]\n",
      "epoch:36 step:28657[D loss: 0.299104, acc: 80.47%, op_acc: 50.78%] [G loss: 1.290413]\n",
      "epoch:36 step:28658[D loss: 0.358679, acc: 72.66%, op_acc: 46.09%] [G loss: 1.916733]\n",
      "epoch:36 step:28659[D loss: 0.420016, acc: 63.28%, op_acc: 42.19%] [G loss: 1.438720]\n",
      "epoch:36 step:28660[D loss: 0.351061, acc: 73.44%, op_acc: 49.22%] [G loss: 1.361823]\n",
      "epoch:36 step:28661[D loss: 0.330564, acc: 76.56%, op_acc: 46.09%] [G loss: 1.798464]\n",
      "epoch:36 step:28662[D loss: 0.397152, acc: 65.62%, op_acc: 50.00%] [G loss: 1.517116]\n",
      "epoch:36 step:28663[D loss: 0.430380, acc: 63.28%, op_acc: 49.22%] [G loss: 1.519075]\n",
      "epoch:36 step:28664[D loss: 0.409139, acc: 70.31%, op_acc: 39.84%] [G loss: 1.732559]\n",
      "epoch:36 step:28665[D loss: 0.349156, acc: 77.34%, op_acc: 50.78%] [G loss: 1.146847]\n",
      "epoch:36 step:28666[D loss: 0.395044, acc: 63.28%, op_acc: 45.31%] [G loss: 1.104681]\n",
      "epoch:36 step:28667[D loss: 0.396653, acc: 67.19%, op_acc: 43.75%] [G loss: 1.074050]\n",
      "epoch:36 step:28668[D loss: 0.385233, acc: 70.31%, op_acc: 38.28%] [G loss: 1.379155]\n",
      "epoch:36 step:28669[D loss: 0.348555, acc: 75.00%, op_acc: 50.78%] [G loss: 1.400631]\n",
      "epoch:36 step:28670[D loss: 0.394046, acc: 69.53%, op_acc: 42.97%] [G loss: 1.339097]\n",
      "epoch:36 step:28671[D loss: 0.380280, acc: 67.19%, op_acc: 46.88%] [G loss: 1.607007]\n",
      "epoch:36 step:28672[D loss: 0.359114, acc: 71.88%, op_acc: 49.22%] [G loss: 1.175067]\n",
      "epoch:36 step:28673[D loss: 0.359556, acc: 74.22%, op_acc: 47.66%] [G loss: 1.618883]\n",
      "epoch:36 step:28674[D loss: 0.435712, acc: 59.38%, op_acc: 48.44%] [G loss: 1.150189]\n",
      "epoch:36 step:28675[D loss: 0.328763, acc: 79.69%, op_acc: 46.88%] [G loss: 1.483764]\n",
      "epoch:36 step:28676[D loss: 0.385489, acc: 70.31%, op_acc: 46.88%] [G loss: 1.226183]\n",
      "epoch:36 step:28677[D loss: 0.392376, acc: 65.62%, op_acc: 44.53%] [G loss: 1.310795]\n",
      "epoch:36 step:28678[D loss: 0.396513, acc: 62.50%, op_acc: 42.97%] [G loss: 1.222941]\n",
      "epoch:36 step:28679[D loss: 0.376118, acc: 68.75%, op_acc: 42.19%] [G loss: 1.188859]\n",
      "epoch:36 step:28680[D loss: 0.406722, acc: 62.50%, op_acc: 51.56%] [G loss: 1.397372]\n",
      "epoch:36 step:28681[D loss: 0.369198, acc: 67.19%, op_acc: 50.00%] [G loss: 1.077836]\n",
      "epoch:36 step:28682[D loss: 0.446888, acc: 64.06%, op_acc: 43.75%] [G loss: 1.147336]\n",
      "epoch:36 step:28683[D loss: 0.360866, acc: 71.88%, op_acc: 46.09%] [G loss: 1.114954]\n",
      "epoch:36 step:28684[D loss: 0.323932, acc: 76.56%, op_acc: 53.91%] [G loss: 1.437825]\n",
      "epoch:36 step:28685[D loss: 0.365499, acc: 69.53%, op_acc: 48.44%] [G loss: 1.394398]\n",
      "epoch:36 step:28686[D loss: 0.373777, acc: 68.75%, op_acc: 53.91%] [G loss: 1.082060]\n",
      "epoch:36 step:28687[D loss: 0.408966, acc: 58.59%, op_acc: 46.88%] [G loss: 1.001073]\n",
      "epoch:36 step:28688[D loss: 0.360684, acc: 70.31%, op_acc: 50.78%] [G loss: 1.320904]\n",
      "epoch:36 step:28689[D loss: 0.398382, acc: 64.06%, op_acc: 52.34%] [G loss: 1.409999]\n",
      "epoch:36 step:28690[D loss: 0.383589, acc: 73.44%, op_acc: 47.66%] [G loss: 1.248764]\n",
      "epoch:36 step:28691[D loss: 0.305282, acc: 78.91%, op_acc: 50.00%] [G loss: 1.103164]\n",
      "epoch:36 step:28692[D loss: 0.410439, acc: 60.16%, op_acc: 42.97%] [G loss: 1.267387]\n",
      "epoch:36 step:28693[D loss: 0.375126, acc: 70.31%, op_acc: 51.56%] [G loss: 1.156261]\n",
      "epoch:36 step:28694[D loss: 0.430834, acc: 67.19%, op_acc: 37.50%] [G loss: 1.461480]\n",
      "epoch:36 step:28695[D loss: 0.348153, acc: 70.31%, op_acc: 50.78%] [G loss: 1.493956]\n",
      "epoch:36 step:28696[D loss: 0.420723, acc: 64.06%, op_acc: 45.31%] [G loss: 1.450668]\n",
      "epoch:36 step:28697[D loss: 0.399697, acc: 67.19%, op_acc: 44.53%] [G loss: 1.100166]\n",
      "epoch:36 step:28698[D loss: 0.405020, acc: 70.31%, op_acc: 42.97%] [G loss: 0.992310]\n",
      "epoch:36 step:28699[D loss: 0.395513, acc: 66.41%, op_acc: 43.75%] [G loss: 0.944010]\n",
      "epoch:36 step:28700[D loss: 0.455327, acc: 60.16%, op_acc: 35.16%] [G loss: 1.156733]\n",
      "epoch:36 step:28701[D loss: 0.403358, acc: 67.97%, op_acc: 46.09%] [G loss: 1.092444]\n",
      "epoch:36 step:28702[D loss: 0.372078, acc: 71.09%, op_acc: 52.34%] [G loss: 1.101547]\n",
      "epoch:36 step:28703[D loss: 0.317017, acc: 81.25%, op_acc: 53.12%] [G loss: 0.998084]\n",
      "epoch:36 step:28704[D loss: 0.303468, acc: 79.69%, op_acc: 55.47%] [G loss: 1.114148]\n",
      "epoch:36 step:28705[D loss: 0.276509, acc: 79.69%, op_acc: 61.72%] [G loss: 1.538300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28706[D loss: 0.356611, acc: 75.78%, op_acc: 42.97%] [G loss: 1.449274]\n",
      "epoch:36 step:28707[D loss: 0.415120, acc: 67.19%, op_acc: 45.31%] [G loss: 1.036029]\n",
      "epoch:36 step:28708[D loss: 0.356934, acc: 72.66%, op_acc: 55.47%] [G loss: 1.756348]\n",
      "epoch:36 step:28709[D loss: 0.371945, acc: 75.00%, op_acc: 39.06%] [G loss: 1.201533]\n",
      "epoch:36 step:28710[D loss: 0.420420, acc: 60.94%, op_acc: 41.41%] [G loss: 1.106519]\n",
      "epoch:36 step:28711[D loss: 0.320583, acc: 82.81%, op_acc: 42.97%] [G loss: 1.197748]\n",
      "epoch:36 step:28712[D loss: 0.301818, acc: 78.12%, op_acc: 57.03%] [G loss: 1.175922]\n",
      "epoch:36 step:28713[D loss: 0.357273, acc: 71.09%, op_acc: 44.53%] [G loss: 1.094381]\n",
      "epoch:36 step:28714[D loss: 0.287190, acc: 82.81%, op_acc: 48.44%] [G loss: 1.407861]\n",
      "epoch:36 step:28715[D loss: 0.346776, acc: 73.44%, op_acc: 42.97%] [G loss: 1.141236]\n",
      "epoch:36 step:28716[D loss: 0.337856, acc: 79.69%, op_acc: 50.78%] [G loss: 1.386310]\n",
      "epoch:36 step:28717[D loss: 0.364904, acc: 66.41%, op_acc: 49.22%] [G loss: 1.370691]\n",
      "epoch:36 step:28718[D loss: 0.290096, acc: 82.81%, op_acc: 56.25%] [G loss: 1.634937]\n",
      "epoch:36 step:28719[D loss: 0.256270, acc: 82.03%, op_acc: 67.19%] [G loss: 1.515299]\n",
      "epoch:36 step:28720[D loss: 0.382061, acc: 75.00%, op_acc: 45.31%] [G loss: 1.485265]\n",
      "epoch:36 step:28721[D loss: 0.351230, acc: 76.56%, op_acc: 43.75%] [G loss: 1.526327]\n",
      "epoch:36 step:28722[D loss: 0.311646, acc: 81.25%, op_acc: 59.38%] [G loss: 1.489955]\n",
      "epoch:36 step:28723[D loss: 0.299926, acc: 77.34%, op_acc: 60.94%] [G loss: 1.326316]\n",
      "epoch:36 step:28724[D loss: 0.246994, acc: 88.28%, op_acc: 56.25%] [G loss: 1.507944]\n",
      "epoch:36 step:28725[D loss: 0.360752, acc: 67.19%, op_acc: 52.34%] [G loss: 1.596062]\n",
      "epoch:36 step:28726[D loss: 0.286068, acc: 84.38%, op_acc: 52.34%] [G loss: 1.576668]\n",
      "epoch:36 step:28727[D loss: 0.254211, acc: 90.62%, op_acc: 57.81%] [G loss: 2.045439]\n",
      "epoch:36 step:28728[D loss: 0.268001, acc: 86.72%, op_acc: 60.16%] [G loss: 1.558835]\n",
      "epoch:36 step:28729[D loss: 0.323398, acc: 79.69%, op_acc: 53.91%] [G loss: 1.571239]\n",
      "epoch:36 step:28730[D loss: 0.248970, acc: 88.28%, op_acc: 58.59%] [G loss: 1.647168]\n",
      "epoch:36 step:28731[D loss: 0.291265, acc: 82.03%, op_acc: 57.81%] [G loss: 0.634951]\n",
      "epoch:36 step:28732[D loss: 0.401350, acc: 66.41%, op_acc: 38.28%] [G loss: 1.620394]\n",
      "epoch:36 step:28733[D loss: 0.406389, acc: 67.19%, op_acc: 42.97%] [G loss: 1.370183]\n",
      "epoch:36 step:28734[D loss: 0.307474, acc: 76.56%, op_acc: 50.78%] [G loss: 1.862957]\n",
      "epoch:36 step:28735[D loss: 0.381987, acc: 67.97%, op_acc: 46.09%] [G loss: 1.557420]\n",
      "epoch:36 step:28736[D loss: 0.397804, acc: 64.06%, op_acc: 49.22%] [G loss: 1.589398]\n",
      "epoch:36 step:28737[D loss: 0.273491, acc: 83.59%, op_acc: 58.59%] [G loss: 1.537393]\n",
      "epoch:36 step:28738[D loss: 0.339669, acc: 78.12%, op_acc: 53.12%] [G loss: 1.372070]\n",
      "epoch:36 step:28739[D loss: 0.339320, acc: 75.78%, op_acc: 49.22%] [G loss: 1.465587]\n",
      "epoch:36 step:28740[D loss: 0.332236, acc: 79.69%, op_acc: 46.88%] [G loss: 1.540722]\n",
      "epoch:36 step:28741[D loss: 0.351031, acc: 74.22%, op_acc: 57.03%] [G loss: 1.688846]\n",
      "epoch:36 step:28742[D loss: 0.329418, acc: 72.66%, op_acc: 59.38%] [G loss: 1.563803]\n",
      "epoch:36 step:28743[D loss: 0.289397, acc: 85.16%, op_acc: 59.38%] [G loss: 1.363603]\n",
      "epoch:36 step:28744[D loss: 0.270026, acc: 92.19%, op_acc: 59.38%] [G loss: 1.470581]\n",
      "epoch:36 step:28745[D loss: 0.300509, acc: 78.91%, op_acc: 54.69%] [G loss: 0.833049]\n",
      "epoch:36 step:28746[D loss: 0.298355, acc: 79.69%, op_acc: 46.09%] [G loss: 1.468120]\n",
      "epoch:36 step:28747[D loss: 0.396646, acc: 66.41%, op_acc: 42.97%] [G loss: 1.631015]\n",
      "epoch:36 step:28748[D loss: 0.342250, acc: 77.34%, op_acc: 46.09%] [G loss: 1.448652]\n",
      "epoch:36 step:28749[D loss: 0.337337, acc: 70.31%, op_acc: 55.47%] [G loss: 1.655601]\n",
      "epoch:36 step:28750[D loss: 0.301916, acc: 78.91%, op_acc: 59.38%] [G loss: 1.561182]\n",
      "epoch:36 step:28751[D loss: 0.339971, acc: 80.47%, op_acc: 49.22%] [G loss: 1.952357]\n",
      "epoch:36 step:28752[D loss: 0.349705, acc: 70.31%, op_acc: 51.56%] [G loss: 1.288632]\n",
      "epoch:36 step:28753[D loss: 0.345097, acc: 74.22%, op_acc: 46.88%] [G loss: 1.241632]\n",
      "epoch:36 step:28754[D loss: 0.387299, acc: 72.66%, op_acc: 47.66%] [G loss: 0.878404]\n",
      "epoch:36 step:28755[D loss: 0.251177, acc: 86.72%, op_acc: 60.94%] [G loss: 1.333701]\n",
      "epoch:36 step:28756[D loss: 0.273958, acc: 85.94%, op_acc: 57.81%] [G loss: 1.383295]\n",
      "epoch:36 step:28757[D loss: 0.242208, acc: 90.62%, op_acc: 64.84%] [G loss: 1.362664]\n",
      "epoch:36 step:28758[D loss: 0.251126, acc: 89.06%, op_acc: 57.03%] [G loss: 0.731704]\n",
      "epoch:36 step:28759[D loss: 0.449875, acc: 57.03%, op_acc: 42.19%] [G loss: 1.558563]\n",
      "epoch:36 step:28760[D loss: 0.227033, acc: 89.06%, op_acc: 59.38%] [G loss: 1.469365]\n",
      "epoch:36 step:28761[D loss: 0.395892, acc: 65.62%, op_acc: 46.09%] [G loss: 1.459832]\n",
      "epoch:36 step:28762[D loss: 0.345139, acc: 75.78%, op_acc: 49.22%] [G loss: 1.545131]\n",
      "epoch:36 step:28763[D loss: 0.376764, acc: 71.09%, op_acc: 49.22%] [G loss: 1.192473]\n",
      "epoch:36 step:28764[D loss: 0.271635, acc: 83.59%, op_acc: 57.03%] [G loss: 1.536537]\n",
      "epoch:36 step:28765[D loss: 0.315444, acc: 80.47%, op_acc: 56.25%] [G loss: 1.445822]\n",
      "epoch:36 step:28766[D loss: 0.300215, acc: 82.03%, op_acc: 56.25%] [G loss: 1.351394]\n",
      "epoch:36 step:28767[D loss: 0.306593, acc: 77.34%, op_acc: 55.47%] [G loss: 1.455364]\n",
      "epoch:36 step:28768[D loss: 0.288632, acc: 78.91%, op_acc: 63.28%] [G loss: 1.252634]\n",
      "epoch:36 step:28769[D loss: 0.227795, acc: 93.75%, op_acc: 57.81%] [G loss: 1.113959]\n",
      "epoch:36 step:28770[D loss: 0.220929, acc: 91.41%, op_acc: 56.25%] [G loss: 1.284245]\n",
      "epoch:36 step:28771[D loss: 0.304053, acc: 81.25%, op_acc: 54.69%] [G loss: 1.223680]\n",
      "epoch:36 step:28772[D loss: 0.283980, acc: 82.03%, op_acc: 58.59%] [G loss: 1.586665]\n",
      "epoch:36 step:28773[D loss: 0.242629, acc: 87.50%, op_acc: 60.16%] [G loss: 1.138277]\n",
      "epoch:36 step:28774[D loss: 0.231346, acc: 89.06%, op_acc: 63.28%] [G loss: 1.010563]\n",
      "epoch:36 step:28775[D loss: 0.264183, acc: 90.62%, op_acc: 50.00%] [G loss: 1.830155]\n",
      "epoch:36 step:28776[D loss: 0.333767, acc: 73.44%, op_acc: 44.53%] [G loss: 1.667943]\n",
      "epoch:36 step:28777[D loss: 0.254663, acc: 85.16%, op_acc: 53.91%] [G loss: 1.203978]\n",
      "epoch:36 step:28778[D loss: 0.265404, acc: 83.59%, op_acc: 60.94%] [G loss: 0.644567]\n",
      "epoch:36 step:28779[D loss: 0.382748, acc: 67.97%, op_acc: 45.31%] [G loss: 1.827540]\n",
      "epoch:36 step:28780[D loss: 0.392654, acc: 64.84%, op_acc: 50.00%] [G loss: 1.653594]\n",
      "epoch:36 step:28781[D loss: 0.406046, acc: 71.09%, op_acc: 42.19%] [G loss: 1.673625]\n",
      "epoch:36 step:28782[D loss: 0.336326, acc: 79.69%, op_acc: 52.34%] [G loss: 1.632152]\n",
      "epoch:36 step:28783[D loss: 0.315145, acc: 76.56%, op_acc: 52.34%] [G loss: 1.800814]\n",
      "epoch:36 step:28784[D loss: 0.309776, acc: 76.56%, op_acc: 53.91%] [G loss: 1.212302]\n",
      "epoch:36 step:28785[D loss: 0.381975, acc: 77.34%, op_acc: 49.22%] [G loss: 1.458083]\n",
      "epoch:36 step:28786[D loss: 0.392498, acc: 59.38%, op_acc: 50.78%] [G loss: 1.417496]\n",
      "epoch:36 step:28787[D loss: 0.284477, acc: 84.38%, op_acc: 53.12%] [G loss: 1.319483]\n",
      "epoch:36 step:28788[D loss: 0.268280, acc: 91.41%, op_acc: 54.69%] [G loss: 1.310359]\n",
      "epoch:36 step:28789[D loss: 0.280823, acc: 84.38%, op_acc: 59.38%] [G loss: 1.199030]\n",
      "epoch:36 step:28790[D loss: 0.290440, acc: 80.47%, op_acc: 55.47%] [G loss: 1.468770]\n",
      "epoch:36 step:28791[D loss: 0.232270, acc: 90.62%, op_acc: 54.69%] [G loss: 1.053198]\n",
      "epoch:36 step:28792[D loss: 0.269989, acc: 85.94%, op_acc: 57.81%] [G loss: 1.311532]\n",
      "epoch:36 step:28793[D loss: 0.264107, acc: 89.06%, op_acc: 58.59%] [G loss: 1.337863]\n",
      "epoch:36 step:28794[D loss: 0.212710, acc: 91.41%, op_acc: 60.16%] [G loss: 1.721450]\n",
      "epoch:36 step:28795[D loss: 0.183827, acc: 92.19%, op_acc: 71.09%] [G loss: 1.666514]\n",
      "epoch:36 step:28796[D loss: 0.207492, acc: 90.62%, op_acc: 75.78%] [G loss: 1.739000]\n",
      "epoch:36 step:28797[D loss: 0.324402, acc: 80.47%, op_acc: 55.47%] [G loss: 0.560380]\n",
      "epoch:36 step:28798[D loss: 0.359909, acc: 71.09%, op_acc: 42.97%] [G loss: 1.942264]\n",
      "epoch:36 step:28799[D loss: 0.326811, acc: 77.34%, op_acc: 42.97%] [G loss: 0.981268]\n",
      "epoch:36 step:28800[D loss: 0.454904, acc: 54.69%, op_acc: 39.84%] [G loss: 2.055699]\n",
      "epoch:36 step:28801[D loss: 0.383226, acc: 69.53%, op_acc: 44.53%] [G loss: 2.192141]\n",
      "epoch:36 step:28802[D loss: 0.409714, acc: 57.81%, op_acc: 47.66%] [G loss: 1.283825]\n",
      "epoch:36 step:28803[D loss: 0.331588, acc: 76.56%, op_acc: 50.78%] [G loss: 0.972203]\n",
      "epoch:36 step:28804[D loss: 0.384571, acc: 67.97%, op_acc: 50.78%] [G loss: 1.293014]\n",
      "epoch:36 step:28805[D loss: 0.392917, acc: 64.84%, op_acc: 46.88%] [G loss: 1.656576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:28806[D loss: 0.313437, acc: 78.12%, op_acc: 53.12%] [G loss: 1.722791]\n",
      "epoch:36 step:28807[D loss: 0.262514, acc: 87.50%, op_acc: 64.06%] [G loss: 1.714148]\n",
      "epoch:36 step:28808[D loss: 0.451784, acc: 58.59%, op_acc: 38.28%] [G loss: 1.771503]\n",
      "epoch:36 step:28809[D loss: 0.292625, acc: 85.16%, op_acc: 54.69%] [G loss: 0.889723]\n",
      "epoch:36 step:28810[D loss: 0.555007, acc: 49.22%, op_acc: 37.50%] [G loss: 1.686681]\n",
      "epoch:36 step:28811[D loss: 0.324092, acc: 76.56%, op_acc: 44.53%] [G loss: 1.544224]\n",
      "epoch:36 step:28812[D loss: 0.337371, acc: 75.00%, op_acc: 42.19%] [G loss: 1.886511]\n",
      "epoch:36 step:28813[D loss: 0.387641, acc: 68.75%, op_acc: 51.56%] [G loss: 1.459911]\n",
      "epoch:36 step:28814[D loss: 0.348163, acc: 71.88%, op_acc: 46.88%] [G loss: 1.199439]\n",
      "epoch:36 step:28815[D loss: 0.309607, acc: 77.34%, op_acc: 53.91%] [G loss: 1.430105]\n",
      "epoch:36 step:28816[D loss: 0.285053, acc: 82.03%, op_acc: 58.59%] [G loss: 1.716313]\n",
      "epoch:36 step:28817[D loss: 0.354372, acc: 75.00%, op_acc: 51.56%] [G loss: 1.816436]\n",
      "epoch:36 step:28818[D loss: 0.398686, acc: 71.09%, op_acc: 42.97%] [G loss: 1.547446]\n",
      "epoch:36 step:28819[D loss: 0.373458, acc: 74.22%, op_acc: 50.78%] [G loss: 1.480777]\n",
      "epoch:36 step:28820[D loss: 0.213564, acc: 91.41%, op_acc: 61.72%] [G loss: 1.633020]\n",
      "epoch:36 step:28821[D loss: 0.250644, acc: 90.62%, op_acc: 54.69%] [G loss: 1.310627]\n",
      "epoch:36 step:28822[D loss: 0.254706, acc: 85.16%, op_acc: 60.94%] [G loss: 0.615422]\n",
      "epoch:36 step:28823[D loss: 0.478466, acc: 50.78%, op_acc: 39.84%] [G loss: 1.182979]\n",
      "epoch:36 step:28824[D loss: 0.413642, acc: 64.06%, op_acc: 46.09%] [G loss: 1.156698]\n",
      "epoch:36 step:28825[D loss: 0.332635, acc: 78.12%, op_acc: 44.53%] [G loss: 1.198600]\n",
      "epoch:36 step:28826[D loss: 0.297397, acc: 78.12%, op_acc: 57.03%] [G loss: 1.385274]\n",
      "epoch:36 step:28827[D loss: 0.385623, acc: 69.53%, op_acc: 46.09%] [G loss: 1.235823]\n",
      "epoch:36 step:28828[D loss: 0.270966, acc: 85.16%, op_acc: 50.00%] [G loss: 1.285051]\n",
      "epoch:36 step:28829[D loss: 0.308384, acc: 80.47%, op_acc: 51.56%] [G loss: 1.403216]\n",
      "epoch:36 step:28830[D loss: 0.295323, acc: 85.94%, op_acc: 50.00%] [G loss: 1.174517]\n",
      "epoch:36 step:28831[D loss: 0.322685, acc: 77.34%, op_acc: 60.16%] [G loss: 1.138547]\n",
      "epoch:36 step:28832[D loss: 0.273879, acc: 82.81%, op_acc: 61.72%] [G loss: 0.952372]\n",
      "epoch:36 step:28833[D loss: 0.197614, acc: 94.53%, op_acc: 59.38%] [G loss: 1.614545]\n",
      "epoch:36 step:28834[D loss: 0.267281, acc: 90.62%, op_acc: 66.41%] [G loss: 1.193888]\n",
      "epoch:36 step:28835[D loss: 0.267133, acc: 78.91%, op_acc: 57.03%] [G loss: 1.109108]\n",
      "epoch:36 step:28836[D loss: 0.300751, acc: 84.38%, op_acc: 53.12%] [G loss: 1.240520]\n",
      "epoch:36 step:28837[D loss: 0.347543, acc: 70.31%, op_acc: 50.78%] [G loss: 0.573325]\n",
      "epoch:36 step:28838[D loss: 0.436651, acc: 60.16%, op_acc: 39.84%] [G loss: 1.074454]\n",
      "epoch:36 step:28839[D loss: 0.394083, acc: 65.62%, op_acc: 47.66%] [G loss: 2.140852]\n",
      "epoch:36 step:28840[D loss: 0.394356, acc: 71.09%, op_acc: 46.88%] [G loss: 1.617735]\n",
      "epoch:36 step:28841[D loss: 0.400707, acc: 65.62%, op_acc: 50.00%] [G loss: 1.485584]\n",
      "epoch:36 step:28842[D loss: 0.271102, acc: 84.38%, op_acc: 53.12%] [G loss: 1.334536]\n",
      "epoch:36 step:28843[D loss: 0.363664, acc: 74.22%, op_acc: 46.88%] [G loss: 1.589843]\n",
      "epoch:36 step:28844[D loss: 0.355210, acc: 73.44%, op_acc: 46.88%] [G loss: 1.737039]\n",
      "epoch:36 step:28845[D loss: 0.277679, acc: 80.47%, op_acc: 57.03%] [G loss: 1.749213]\n",
      "epoch:36 step:28846[D loss: 0.292391, acc: 79.69%, op_acc: 52.34%] [G loss: 1.041539]\n",
      "epoch:36 step:28847[D loss: 0.362228, acc: 69.53%, op_acc: 47.66%] [G loss: 1.229266]\n",
      "epoch:36 step:28848[D loss: 0.453701, acc: 60.16%, op_acc: 39.84%] [G loss: 1.692268]\n",
      "epoch:36 step:28849[D loss: 0.418806, acc: 64.06%, op_acc: 45.31%] [G loss: 1.749845]\n",
      "epoch:36 step:28850[D loss: 0.331025, acc: 77.34%, op_acc: 53.91%] [G loss: 1.935276]\n",
      "epoch:36 step:28851[D loss: 0.459697, acc: 58.59%, op_acc: 42.97%] [G loss: 1.503327]\n",
      "epoch:36 step:28852[D loss: 0.343745, acc: 73.44%, op_acc: 53.12%] [G loss: 1.720497]\n",
      "epoch:36 step:28853[D loss: 0.307596, acc: 78.91%, op_acc: 55.47%] [G loss: 1.869903]\n",
      "epoch:36 step:28854[D loss: 0.390398, acc: 69.53%, op_acc: 48.44%] [G loss: 1.554851]\n",
      "epoch:36 step:28855[D loss: 0.453202, acc: 60.94%, op_acc: 42.19%] [G loss: 1.234665]\n",
      "epoch:36 step:28856[D loss: 0.397358, acc: 65.62%, op_acc: 53.12%] [G loss: 1.238199]\n",
      "epoch:36 step:28857[D loss: 0.331159, acc: 76.56%, op_acc: 51.56%] [G loss: 1.263698]\n",
      "epoch:36 step:28858[D loss: 0.408605, acc: 64.84%, op_acc: 44.53%] [G loss: 1.213205]\n",
      "epoch:36 step:28859[D loss: 0.360913, acc: 75.78%, op_acc: 44.53%] [G loss: 1.504504]\n",
      "epoch:36 step:28860[D loss: 0.416932, acc: 57.03%, op_acc: 50.00%] [G loss: 1.396473]\n",
      "epoch:36 step:28861[D loss: 0.331009, acc: 79.69%, op_acc: 47.66%] [G loss: 1.289391]\n",
      "epoch:36 step:28862[D loss: 0.366885, acc: 69.53%, op_acc: 42.19%] [G loss: 1.636862]\n",
      "epoch:36 step:28863[D loss: 0.343018, acc: 75.00%, op_acc: 48.44%] [G loss: 1.703548]\n",
      "epoch:36 step:28864[D loss: 0.414454, acc: 66.41%, op_acc: 38.28%] [G loss: 1.522780]\n",
      "epoch:36 step:28865[D loss: 0.384604, acc: 67.19%, op_acc: 48.44%] [G loss: 1.614143]\n",
      "epoch:36 step:28866[D loss: 0.397459, acc: 67.97%, op_acc: 52.34%] [G loss: 1.264185]\n",
      "epoch:36 step:28867[D loss: 0.370743, acc: 71.88%, op_acc: 51.56%] [G loss: 1.725182]\n",
      "epoch:36 step:28868[D loss: 0.391142, acc: 63.28%, op_acc: 46.09%] [G loss: 1.589634]\n",
      "epoch:36 step:28869[D loss: 0.374051, acc: 68.75%, op_acc: 47.66%] [G loss: 1.090262]\n",
      "epoch:36 step:28870[D loss: 0.355480, acc: 71.88%, op_acc: 42.97%] [G loss: 1.440238]\n",
      "epoch:36 step:28871[D loss: 0.345953, acc: 75.78%, op_acc: 46.88%] [G loss: 1.645072]\n",
      "epoch:36 step:28872[D loss: 0.337856, acc: 75.78%, op_acc: 57.81%] [G loss: 1.489336]\n",
      "epoch:36 step:28873[D loss: 0.355383, acc: 75.00%, op_acc: 44.53%] [G loss: 1.011458]\n",
      "epoch:36 step:28874[D loss: 0.407947, acc: 62.50%, op_acc: 44.53%] [G loss: 1.065961]\n",
      "epoch:36 step:28875[D loss: 0.387618, acc: 71.88%, op_acc: 49.22%] [G loss: 1.431945]\n",
      "epoch:36 step:28876[D loss: 0.439621, acc: 55.47%, op_acc: 43.75%] [G loss: 1.357184]\n",
      "epoch:36 step:28877[D loss: 0.426506, acc: 55.47%, op_acc: 45.31%] [G loss: 1.202881]\n",
      "epoch:36 step:28878[D loss: 0.423701, acc: 61.72%, op_acc: 39.06%] [G loss: 1.291282]\n",
      "epoch:36 step:28879[D loss: 0.418585, acc: 65.62%, op_acc: 48.44%] [G loss: 1.253398]\n",
      "epoch:36 step:28880[D loss: 0.334382, acc: 76.56%, op_acc: 50.78%] [G loss: 1.323799]\n",
      "epoch:36 step:28881[D loss: 0.425372, acc: 63.28%, op_acc: 46.88%] [G loss: 0.995662]\n",
      "epoch:36 step:28882[D loss: 0.404603, acc: 66.41%, op_acc: 39.06%] [G loss: 1.631338]\n",
      "epoch:36 step:28883[D loss: 0.440988, acc: 62.50%, op_acc: 42.97%] [G loss: 1.604390]\n",
      "epoch:36 step:28884[D loss: 0.338179, acc: 73.44%, op_acc: 53.91%] [G loss: 1.340032]\n",
      "epoch:36 step:28885[D loss: 0.362668, acc: 71.88%, op_acc: 48.44%] [G loss: 1.556091]\n",
      "epoch:36 step:28886[D loss: 0.389945, acc: 65.62%, op_acc: 46.09%] [G loss: 1.019384]\n",
      "epoch:36 step:28887[D loss: 0.435830, acc: 60.16%, op_acc: 39.06%] [G loss: 0.868109]\n",
      "epoch:36 step:28888[D loss: 0.390556, acc: 71.09%, op_acc: 43.75%] [G loss: 1.252904]\n",
      "epoch:36 step:28889[D loss: 0.380801, acc: 71.88%, op_acc: 43.75%] [G loss: 0.998542]\n",
      "epoch:36 step:28890[D loss: 0.352061, acc: 70.31%, op_acc: 46.88%] [G loss: 0.980207]\n",
      "epoch:36 step:28891[D loss: 0.441483, acc: 57.81%, op_acc: 35.16%] [G loss: 0.782252]\n",
      "epoch:36 step:28892[D loss: 0.351884, acc: 73.44%, op_acc: 50.00%] [G loss: 1.493797]\n",
      "epoch:36 step:28893[D loss: 0.491490, acc: 57.03%, op_acc: 41.41%] [G loss: 0.732646]\n",
      "epoch:36 step:28894[D loss: 0.333559, acc: 75.78%, op_acc: 53.91%] [G loss: 0.961930]\n",
      "epoch:36 step:28895[D loss: 0.393610, acc: 67.97%, op_acc: 44.53%] [G loss: 1.071332]\n",
      "epoch:36 step:28896[D loss: 0.414113, acc: 61.72%, op_acc: 46.09%] [G loss: 1.445916]\n",
      "epoch:36 step:28897[D loss: 0.352849, acc: 74.22%, op_acc: 42.19%] [G loss: 1.467523]\n",
      "epoch:37 step:28898[D loss: 0.347416, acc: 71.88%, op_acc: 46.88%] [G loss: 0.943199]\n",
      "epoch:37 step:28899[D loss: 0.440241, acc: 62.50%, op_acc: 50.78%] [G loss: 0.898742]\n",
      "epoch:37 step:28900[D loss: 0.398827, acc: 65.62%, op_acc: 39.06%] [G loss: 0.748014]\n",
      "epoch:37 step:28901[D loss: 0.396554, acc: 65.62%, op_acc: 46.88%] [G loss: 1.360818]\n",
      "epoch:37 step:28902[D loss: 0.356375, acc: 70.31%, op_acc: 48.44%] [G loss: 0.623231]\n",
      "epoch:37 step:28903[D loss: 0.299439, acc: 81.25%, op_acc: 52.34%] [G loss: 0.649783]\n",
      "epoch:37 step:28904[D loss: 0.345600, acc: 72.66%, op_acc: 42.97%] [G loss: 0.685536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:28905[D loss: 0.334818, acc: 73.44%, op_acc: 55.47%] [G loss: 0.647655]\n",
      "epoch:37 step:28906[D loss: 0.336859, acc: 72.66%, op_acc: 58.59%] [G loss: 0.827983]\n",
      "epoch:37 step:28907[D loss: 0.434016, acc: 65.62%, op_acc: 37.50%] [G loss: 1.372059]\n",
      "epoch:37 step:28908[D loss: 0.451338, acc: 62.50%, op_acc: 49.22%] [G loss: 0.626890]\n",
      "epoch:37 step:28909[D loss: 0.420130, acc: 60.94%, op_acc: 45.31%] [G loss: 1.203840]\n",
      "epoch:37 step:28910[D loss: 0.364823, acc: 72.66%, op_acc: 47.66%] [G loss: 0.613757]\n",
      "epoch:37 step:28911[D loss: 0.367891, acc: 71.88%, op_acc: 51.56%] [G loss: 1.716778]\n",
      "epoch:37 step:28912[D loss: 0.318187, acc: 79.69%, op_acc: 46.09%] [G loss: 0.757245]\n",
      "epoch:37 step:28913[D loss: 0.315472, acc: 78.91%, op_acc: 48.44%] [G loss: 1.209875]\n",
      "epoch:37 step:28914[D loss: 0.434081, acc: 59.38%, op_acc: 52.34%] [G loss: 0.809277]\n",
      "epoch:37 step:28915[D loss: 0.360988, acc: 73.44%, op_acc: 45.31%] [G loss: 0.973190]\n",
      "epoch:37 step:28916[D loss: 0.333445, acc: 75.00%, op_acc: 52.34%] [G loss: 1.125815]\n",
      "epoch:37 step:28917[D loss: 0.391584, acc: 67.19%, op_acc: 43.75%] [G loss: 0.982437]\n",
      "epoch:37 step:28918[D loss: 0.454012, acc: 60.94%, op_acc: 43.75%] [G loss: 0.611254]\n",
      "epoch:37 step:28919[D loss: 0.384415, acc: 67.97%, op_acc: 48.44%] [G loss: 1.168486]\n",
      "epoch:37 step:28920[D loss: 0.433634, acc: 60.16%, op_acc: 39.06%] [G loss: 0.869950]\n",
      "epoch:37 step:28921[D loss: 0.420142, acc: 69.53%, op_acc: 50.00%] [G loss: 1.442623]\n",
      "epoch:37 step:28922[D loss: 0.476447, acc: 55.47%, op_acc: 40.62%] [G loss: 0.788403]\n",
      "epoch:37 step:28923[D loss: 0.338551, acc: 73.44%, op_acc: 50.78%] [G loss: 1.375080]\n",
      "epoch:37 step:28924[D loss: 0.353577, acc: 72.66%, op_acc: 49.22%] [G loss: 0.689330]\n",
      "epoch:37 step:28925[D loss: 0.388268, acc: 68.75%, op_acc: 47.66%] [G loss: 0.561514]\n",
      "epoch:37 step:28926[D loss: 0.308523, acc: 75.78%, op_acc: 54.69%] [G loss: 0.482555]\n",
      "epoch:37 step:28927[D loss: 0.396055, acc: 64.84%, op_acc: 45.31%] [G loss: 1.074037]\n",
      "epoch:37 step:28928[D loss: 0.372713, acc: 68.75%, op_acc: 41.41%] [G loss: 0.959490]\n",
      "epoch:37 step:28929[D loss: 0.425406, acc: 64.06%, op_acc: 51.56%] [G loss: 1.565870]\n",
      "epoch:37 step:28930[D loss: 0.399423, acc: 65.62%, op_acc: 46.09%] [G loss: 0.868384]\n",
      "epoch:37 step:28931[D loss: 0.326058, acc: 78.91%, op_acc: 53.91%] [G loss: 0.795619]\n",
      "epoch:37 step:28932[D loss: 0.396372, acc: 74.22%, op_acc: 43.75%] [G loss: 1.364382]\n",
      "epoch:37 step:28933[D loss: 0.329954, acc: 70.31%, op_acc: 53.91%] [G loss: 0.858495]\n",
      "epoch:37 step:28934[D loss: 0.404382, acc: 67.19%, op_acc: 48.44%] [G loss: 0.880640]\n",
      "epoch:37 step:28935[D loss: 0.433860, acc: 58.59%, op_acc: 43.75%] [G loss: 1.227320]\n",
      "epoch:37 step:28936[D loss: 0.335928, acc: 75.78%, op_acc: 49.22%] [G loss: 0.845809]\n",
      "epoch:37 step:28937[D loss: 0.403295, acc: 60.94%, op_acc: 42.19%] [G loss: 0.972907]\n",
      "epoch:37 step:28938[D loss: 0.366055, acc: 66.41%, op_acc: 47.66%] [G loss: 1.112643]\n",
      "epoch:37 step:28939[D loss: 0.342555, acc: 71.88%, op_acc: 51.56%] [G loss: 0.778299]\n",
      "epoch:37 step:28940[D loss: 0.389831, acc: 70.31%, op_acc: 49.22%] [G loss: 0.912234]\n",
      "epoch:37 step:28941[D loss: 0.349232, acc: 72.66%, op_acc: 49.22%] [G loss: 1.181637]\n",
      "epoch:37 step:28942[D loss: 0.404130, acc: 64.06%, op_acc: 50.00%] [G loss: 1.217235]\n",
      "epoch:37 step:28943[D loss: 0.326255, acc: 78.12%, op_acc: 50.00%] [G loss: 0.910367]\n",
      "epoch:37 step:28944[D loss: 0.438293, acc: 60.16%, op_acc: 39.84%] [G loss: 0.861830]\n",
      "epoch:37 step:28945[D loss: 0.426638, acc: 58.59%, op_acc: 33.59%] [G loss: 0.793116]\n",
      "epoch:37 step:28946[D loss: 0.390707, acc: 67.19%, op_acc: 50.00%] [G loss: 0.642741]\n",
      "epoch:37 step:28947[D loss: 0.350862, acc: 73.44%, op_acc: 47.66%] [G loss: 0.596463]\n",
      "epoch:37 step:28948[D loss: 0.394751, acc: 63.28%, op_acc: 46.88%] [G loss: 0.867388]\n",
      "epoch:37 step:28949[D loss: 0.340688, acc: 77.34%, op_acc: 46.88%] [G loss: 1.568142]\n",
      "epoch:37 step:28950[D loss: 0.408018, acc: 67.19%, op_acc: 35.94%] [G loss: 0.880088]\n",
      "epoch:37 step:28951[D loss: 0.440553, acc: 61.72%, op_acc: 44.53%] [G loss: 0.717030]\n",
      "epoch:37 step:28952[D loss: 0.349079, acc: 68.75%, op_acc: 44.53%] [G loss: 0.887665]\n",
      "epoch:37 step:28953[D loss: 0.303051, acc: 82.81%, op_acc: 48.44%] [G loss: 1.059427]\n",
      "epoch:37 step:28954[D loss: 0.409623, acc: 67.19%, op_acc: 49.22%] [G loss: 1.065715]\n",
      "epoch:37 step:28955[D loss: 0.420563, acc: 65.62%, op_acc: 45.31%] [G loss: 1.265739]\n",
      "epoch:37 step:28956[D loss: 0.395950, acc: 65.62%, op_acc: 49.22%] [G loss: 1.349254]\n",
      "epoch:37 step:28957[D loss: 0.310498, acc: 82.03%, op_acc: 53.91%] [G loss: 1.461442]\n",
      "epoch:37 step:28958[D loss: 0.367230, acc: 74.22%, op_acc: 46.09%] [G loss: 1.153220]\n",
      "epoch:37 step:28959[D loss: 0.454943, acc: 57.81%, op_acc: 46.88%] [G loss: 0.994047]\n",
      "epoch:37 step:28960[D loss: 0.439269, acc: 63.28%, op_acc: 42.19%] [G loss: 0.848224]\n",
      "epoch:37 step:28961[D loss: 0.369261, acc: 71.88%, op_acc: 50.78%] [G loss: 0.877039]\n",
      "epoch:37 step:28962[D loss: 0.383760, acc: 69.53%, op_acc: 48.44%] [G loss: 0.975916]\n",
      "epoch:37 step:28963[D loss: 0.389025, acc: 67.19%, op_acc: 42.19%] [G loss: 1.051416]\n",
      "epoch:37 step:28964[D loss: 0.316328, acc: 76.56%, op_acc: 55.47%] [G loss: 0.933757]\n",
      "epoch:37 step:28965[D loss: 0.342086, acc: 78.91%, op_acc: 52.34%] [G loss: 1.095962]\n",
      "epoch:37 step:28966[D loss: 0.416623, acc: 59.38%, op_acc: 45.31%] [G loss: 1.102117]\n",
      "epoch:37 step:28967[D loss: 0.356932, acc: 67.97%, op_acc: 42.19%] [G loss: 0.952212]\n",
      "epoch:37 step:28968[D loss: 0.396243, acc: 67.97%, op_acc: 42.19%] [G loss: 1.000845]\n",
      "epoch:37 step:28969[D loss: 0.315332, acc: 81.25%, op_acc: 50.00%] [G loss: 0.948629]\n",
      "epoch:37 step:28970[D loss: 0.381220, acc: 66.41%, op_acc: 43.75%] [G loss: 0.892509]\n",
      "epoch:37 step:28971[D loss: 0.359897, acc: 71.88%, op_acc: 41.41%] [G loss: 0.941246]\n",
      "epoch:37 step:28972[D loss: 0.322153, acc: 81.25%, op_acc: 51.56%] [G loss: 1.221974]\n",
      "epoch:37 step:28973[D loss: 0.413191, acc: 64.84%, op_acc: 53.12%] [G loss: 0.961307]\n",
      "epoch:37 step:28974[D loss: 0.311232, acc: 78.12%, op_acc: 44.53%] [G loss: 0.871303]\n",
      "epoch:37 step:28975[D loss: 0.357942, acc: 75.00%, op_acc: 42.97%] [G loss: 0.919999]\n",
      "epoch:37 step:28976[D loss: 0.304495, acc: 78.12%, op_acc: 53.91%] [G loss: 0.862609]\n",
      "epoch:37 step:28977[D loss: 0.323454, acc: 78.12%, op_acc: 50.78%] [G loss: 0.819775]\n",
      "epoch:37 step:28978[D loss: 0.367987, acc: 71.09%, op_acc: 40.62%] [G loss: 1.223273]\n",
      "epoch:37 step:28979[D loss: 0.314236, acc: 78.12%, op_acc: 43.75%] [G loss: 0.676701]\n",
      "epoch:37 step:28980[D loss: 0.328776, acc: 79.69%, op_acc: 53.91%] [G loss: 0.664006]\n",
      "epoch:37 step:28981[D loss: 0.468625, acc: 57.81%, op_acc: 38.28%] [G loss: 0.942921]\n",
      "epoch:37 step:28982[D loss: 0.392429, acc: 67.19%, op_acc: 35.16%] [G loss: 1.455532]\n",
      "epoch:37 step:28983[D loss: 0.342519, acc: 71.88%, op_acc: 53.12%] [G loss: 1.432605]\n",
      "epoch:37 step:28984[D loss: 0.312663, acc: 80.47%, op_acc: 50.00%] [G loss: 1.473155]\n",
      "epoch:37 step:28985[D loss: 0.368735, acc: 71.09%, op_acc: 51.56%] [G loss: 1.062053]\n",
      "epoch:37 step:28986[D loss: 0.380015, acc: 67.97%, op_acc: 48.44%] [G loss: 0.928907]\n",
      "epoch:37 step:28987[D loss: 0.346286, acc: 75.00%, op_acc: 46.88%] [G loss: 1.035627]\n",
      "epoch:37 step:28988[D loss: 0.317192, acc: 73.44%, op_acc: 53.91%] [G loss: 0.980159]\n",
      "epoch:37 step:28989[D loss: 0.355603, acc: 75.78%, op_acc: 47.66%] [G loss: 1.057777]\n",
      "epoch:37 step:28990[D loss: 0.298410, acc: 79.69%, op_acc: 53.12%] [G loss: 1.358893]\n",
      "epoch:37 step:28991[D loss: 0.273808, acc: 82.81%, op_acc: 53.91%] [G loss: 0.907988]\n",
      "epoch:37 step:28992[D loss: 0.331897, acc: 78.91%, op_acc: 52.34%] [G loss: 1.106635]\n",
      "epoch:37 step:28993[D loss: 0.267162, acc: 89.06%, op_acc: 52.34%] [G loss: 1.270813]\n",
      "epoch:37 step:28994[D loss: 0.267952, acc: 85.94%, op_acc: 56.25%] [G loss: 1.329959]\n",
      "epoch:37 step:28995[D loss: 0.255606, acc: 90.62%, op_acc: 48.44%] [G loss: 1.480808]\n",
      "epoch:37 step:28996[D loss: 0.310099, acc: 79.69%, op_acc: 54.69%] [G loss: 1.434411]\n",
      "epoch:37 step:28997[D loss: 0.289053, acc: 86.72%, op_acc: 46.09%] [G loss: 0.888254]\n",
      "epoch:37 step:28998[D loss: 0.308931, acc: 78.12%, op_acc: 47.66%] [G loss: 1.169479]\n",
      "epoch:37 step:28999[D loss: 0.371101, acc: 67.19%, op_acc: 44.53%] [G loss: 1.499723]\n",
      "epoch:37 step:29000[D loss: 0.259910, acc: 83.59%, op_acc: 57.81%] [G loss: 1.473739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29001[D loss: 0.260658, acc: 83.59%, op_acc: 60.16%] [G loss: 0.701909]\n",
      "epoch:37 step:29002[D loss: 0.444085, acc: 63.28%, op_acc: 39.84%] [G loss: 1.532635]\n",
      "epoch:37 step:29003[D loss: 0.384953, acc: 65.62%, op_acc: 41.41%] [G loss: 1.440869]\n",
      "epoch:37 step:29004[D loss: 0.251378, acc: 84.38%, op_acc: 53.91%] [G loss: 1.483770]\n",
      "epoch:37 step:29005[D loss: 0.439448, acc: 60.94%, op_acc: 44.53%] [G loss: 1.698067]\n",
      "epoch:37 step:29006[D loss: 0.358517, acc: 66.41%, op_acc: 56.25%] [G loss: 1.444768]\n",
      "epoch:37 step:29007[D loss: 0.319412, acc: 71.88%, op_acc: 54.69%] [G loss: 1.755053]\n",
      "epoch:37 step:29008[D loss: 0.342447, acc: 78.91%, op_acc: 49.22%] [G loss: 1.341621]\n",
      "epoch:37 step:29009[D loss: 0.347513, acc: 74.22%, op_acc: 58.59%] [G loss: 1.259393]\n",
      "epoch:37 step:29010[D loss: 0.374520, acc: 71.09%, op_acc: 42.19%] [G loss: 0.986886]\n",
      "epoch:37 step:29011[D loss: 0.430738, acc: 60.94%, op_acc: 44.53%] [G loss: 1.272960]\n",
      "epoch:37 step:29012[D loss: 0.345103, acc: 71.88%, op_acc: 54.69%] [G loss: 0.955881]\n",
      "epoch:37 step:29013[D loss: 0.430600, acc: 62.50%, op_acc: 35.94%] [G loss: 1.043778]\n",
      "epoch:37 step:29014[D loss: 0.366170, acc: 64.84%, op_acc: 53.91%] [G loss: 1.077899]\n",
      "epoch:37 step:29015[D loss: 0.323820, acc: 77.34%, op_acc: 53.91%] [G loss: 1.171720]\n",
      "epoch:37 step:29016[D loss: 0.373970, acc: 67.97%, op_acc: 46.88%] [G loss: 1.113127]\n",
      "epoch:37 step:29017[D loss: 0.366830, acc: 70.31%, op_acc: 39.84%] [G loss: 1.441153]\n",
      "epoch:37 step:29018[D loss: 0.304292, acc: 78.12%, op_acc: 59.38%] [G loss: 1.062606]\n",
      "epoch:37 step:29019[D loss: 0.378323, acc: 67.97%, op_acc: 46.88%] [G loss: 1.119922]\n",
      "epoch:37 step:29020[D loss: 0.389449, acc: 67.97%, op_acc: 40.62%] [G loss: 0.995626]\n",
      "epoch:37 step:29021[D loss: 0.352059, acc: 69.53%, op_acc: 45.31%] [G loss: 1.202751]\n",
      "epoch:37 step:29022[D loss: 0.431243, acc: 61.72%, op_acc: 37.50%] [G loss: 0.881949]\n",
      "epoch:37 step:29023[D loss: 0.336097, acc: 70.31%, op_acc: 50.00%] [G loss: 0.751074]\n",
      "epoch:37 step:29024[D loss: 0.382150, acc: 66.41%, op_acc: 47.66%] [G loss: 0.601862]\n",
      "epoch:37 step:29025[D loss: 0.334761, acc: 78.91%, op_acc: 44.53%] [G loss: 0.975660]\n",
      "epoch:37 step:29026[D loss: 0.355418, acc: 70.31%, op_acc: 45.31%] [G loss: 1.074957]\n",
      "epoch:37 step:29027[D loss: 0.447122, acc: 59.38%, op_acc: 48.44%] [G loss: 1.063477]\n",
      "epoch:37 step:29028[D loss: 0.321448, acc: 76.56%, op_acc: 53.12%] [G loss: 1.198641]\n",
      "epoch:37 step:29029[D loss: 0.244048, acc: 85.16%, op_acc: 62.50%] [G loss: 1.098218]\n",
      "epoch:37 step:29030[D loss: 0.408374, acc: 69.53%, op_acc: 39.06%] [G loss: 1.116684]\n",
      "epoch:37 step:29031[D loss: 0.298478, acc: 84.38%, op_acc: 50.78%] [G loss: 1.210566]\n",
      "epoch:37 step:29032[D loss: 0.430975, acc: 60.94%, op_acc: 49.22%] [G loss: 1.045953]\n",
      "epoch:37 step:29033[D loss: 0.270555, acc: 83.59%, op_acc: 51.56%] [G loss: 0.822354]\n",
      "epoch:37 step:29034[D loss: 0.347003, acc: 72.66%, op_acc: 48.44%] [G loss: 1.015662]\n",
      "epoch:37 step:29035[D loss: 0.465465, acc: 54.69%, op_acc: 42.19%] [G loss: 1.320042]\n",
      "epoch:37 step:29036[D loss: 0.311081, acc: 82.81%, op_acc: 52.34%] [G loss: 1.593397]\n",
      "epoch:37 step:29037[D loss: 0.362919, acc: 76.56%, op_acc: 49.22%] [G loss: 0.883897]\n",
      "epoch:37 step:29038[D loss: 0.420844, acc: 64.84%, op_acc: 48.44%] [G loss: 0.910709]\n",
      "epoch:37 step:29039[D loss: 0.362925, acc: 72.66%, op_acc: 42.97%] [G loss: 0.962977]\n",
      "epoch:37 step:29040[D loss: 0.369033, acc: 67.97%, op_acc: 42.97%] [G loss: 1.143576]\n",
      "epoch:37 step:29041[D loss: 0.436687, acc: 65.62%, op_acc: 46.88%] [G loss: 0.774077]\n",
      "epoch:37 step:29042[D loss: 0.327465, acc: 76.56%, op_acc: 57.03%] [G loss: 0.958800]\n",
      "epoch:37 step:29043[D loss: 0.284612, acc: 82.81%, op_acc: 43.75%] [G loss: 1.041442]\n",
      "epoch:37 step:29044[D loss: 0.276379, acc: 80.47%, op_acc: 58.59%] [G loss: 1.140954]\n",
      "epoch:37 step:29045[D loss: 0.341337, acc: 74.22%, op_acc: 56.25%] [G loss: 1.046707]\n",
      "epoch:37 step:29046[D loss: 0.327275, acc: 74.22%, op_acc: 49.22%] [G loss: 0.823018]\n",
      "epoch:37 step:29047[D loss: 0.296346, acc: 79.69%, op_acc: 53.12%] [G loss: 1.282613]\n",
      "epoch:37 step:29048[D loss: 0.261940, acc: 89.84%, op_acc: 57.81%] [G loss: 1.345927]\n",
      "epoch:37 step:29049[D loss: 0.288079, acc: 79.69%, op_acc: 58.59%] [G loss: 1.138596]\n",
      "epoch:37 step:29050[D loss: 0.319964, acc: 79.69%, op_acc: 60.94%] [G loss: 1.094488]\n",
      "epoch:37 step:29051[D loss: 0.279517, acc: 80.47%, op_acc: 60.16%] [G loss: 1.094623]\n",
      "epoch:37 step:29052[D loss: 0.235679, acc: 87.50%, op_acc: 60.16%] [G loss: 1.149073]\n",
      "epoch:37 step:29053[D loss: 0.268806, acc: 85.94%, op_acc: 57.03%] [G loss: 0.713565]\n",
      "epoch:37 step:29054[D loss: 0.293152, acc: 85.94%, op_acc: 52.34%] [G loss: 0.785800]\n",
      "epoch:37 step:29055[D loss: 0.373217, acc: 67.19%, op_acc: 46.88%] [G loss: 1.548983]\n",
      "epoch:37 step:29056[D loss: 0.366983, acc: 71.88%, op_acc: 49.22%] [G loss: 0.713491]\n",
      "epoch:37 step:29057[D loss: 0.437869, acc: 67.97%, op_acc: 39.06%] [G loss: 1.774849]\n",
      "epoch:37 step:29058[D loss: 0.471455, acc: 53.12%, op_acc: 41.41%] [G loss: 1.830711]\n",
      "epoch:37 step:29059[D loss: 0.448877, acc: 57.03%, op_acc: 49.22%] [G loss: 1.051880]\n",
      "epoch:37 step:29060[D loss: 0.353224, acc: 82.81%, op_acc: 48.44%] [G loss: 1.254603]\n",
      "epoch:37 step:29061[D loss: 0.355762, acc: 78.91%, op_acc: 44.53%] [G loss: 0.968079]\n",
      "epoch:37 step:29062[D loss: 0.349104, acc: 75.00%, op_acc: 44.53%] [G loss: 1.096412]\n",
      "epoch:37 step:29063[D loss: 0.314471, acc: 77.34%, op_acc: 56.25%] [G loss: 0.809181]\n",
      "epoch:37 step:29064[D loss: 0.343518, acc: 72.66%, op_acc: 56.25%] [G loss: 1.117486]\n",
      "epoch:37 step:29065[D loss: 0.297467, acc: 78.91%, op_acc: 57.03%] [G loss: 1.524247]\n",
      "epoch:37 step:29066[D loss: 0.286652, acc: 83.59%, op_acc: 56.25%] [G loss: 1.433165]\n",
      "epoch:37 step:29067[D loss: 0.338196, acc: 78.12%, op_acc: 52.34%] [G loss: 0.932695]\n",
      "epoch:37 step:29068[D loss: 0.417801, acc: 60.16%, op_acc: 39.84%] [G loss: 0.833152]\n",
      "epoch:37 step:29069[D loss: 0.454146, acc: 60.94%, op_acc: 40.62%] [G loss: 0.800620]\n",
      "epoch:37 step:29070[D loss: 0.369993, acc: 71.09%, op_acc: 43.75%] [G loss: 1.123340]\n",
      "epoch:37 step:29071[D loss: 0.425335, acc: 63.28%, op_acc: 39.84%] [G loss: 1.205187]\n",
      "epoch:37 step:29072[D loss: 0.390950, acc: 70.31%, op_acc: 43.75%] [G loss: 0.827788]\n",
      "epoch:37 step:29073[D loss: 0.354991, acc: 77.34%, op_acc: 48.44%] [G loss: 0.793387]\n",
      "epoch:37 step:29074[D loss: 0.408535, acc: 61.72%, op_acc: 49.22%] [G loss: 0.829259]\n",
      "epoch:37 step:29075[D loss: 0.361294, acc: 72.66%, op_acc: 50.00%] [G loss: 0.665744]\n",
      "epoch:37 step:29076[D loss: 0.289399, acc: 79.69%, op_acc: 57.03%] [G loss: 0.590219]\n",
      "epoch:37 step:29077[D loss: 0.318456, acc: 79.69%, op_acc: 46.09%] [G loss: 0.610506]\n",
      "epoch:37 step:29078[D loss: 0.350409, acc: 72.66%, op_acc: 51.56%] [G loss: 0.758808]\n",
      "epoch:37 step:29079[D loss: 0.327760, acc: 72.66%, op_acc: 54.69%] [G loss: 1.036543]\n",
      "epoch:37 step:29080[D loss: 0.352590, acc: 69.53%, op_acc: 49.22%] [G loss: 1.022519]\n",
      "epoch:37 step:29081[D loss: 0.274157, acc: 84.38%, op_acc: 57.03%] [G loss: 0.931011]\n",
      "epoch:37 step:29082[D loss: 0.337501, acc: 77.34%, op_acc: 51.56%] [G loss: 1.101169]\n",
      "epoch:37 step:29083[D loss: 0.359037, acc: 71.88%, op_acc: 54.69%] [G loss: 0.949781]\n",
      "epoch:37 step:29084[D loss: 0.370284, acc: 75.00%, op_acc: 46.88%] [G loss: 1.029969]\n",
      "epoch:37 step:29085[D loss: 0.358088, acc: 76.56%, op_acc: 48.44%] [G loss: 0.942609]\n",
      "epoch:37 step:29086[D loss: 0.258600, acc: 90.62%, op_acc: 55.47%] [G loss: 1.342466]\n",
      "epoch:37 step:29087[D loss: 0.290550, acc: 78.91%, op_acc: 51.56%] [G loss: 1.232685]\n",
      "epoch:37 step:29088[D loss: 0.303655, acc: 77.34%, op_acc: 55.47%] [G loss: 1.361879]\n",
      "epoch:37 step:29089[D loss: 0.325225, acc: 78.12%, op_acc: 50.78%] [G loss: 1.785990]\n",
      "epoch:37 step:29090[D loss: 0.286339, acc: 84.38%, op_acc: 58.59%] [G loss: 0.819696]\n",
      "epoch:37 step:29091[D loss: 0.348217, acc: 74.22%, op_acc: 46.88%] [G loss: 1.879330]\n",
      "epoch:37 step:29092[D loss: 0.256395, acc: 88.28%, op_acc: 57.81%] [G loss: 1.083020]\n",
      "epoch:37 step:29093[D loss: 0.284207, acc: 82.03%, op_acc: 46.88%] [G loss: 1.509407]\n",
      "epoch:37 step:29094[D loss: 0.363463, acc: 75.78%, op_acc: 52.34%] [G loss: 1.380393]\n",
      "epoch:37 step:29095[D loss: 0.369067, acc: 67.19%, op_acc: 46.09%] [G loss: 0.762352]\n",
      "epoch:37 step:29096[D loss: 0.436626, acc: 60.94%, op_acc: 49.22%] [G loss: 1.285628]\n",
      "epoch:37 step:29097[D loss: 0.364448, acc: 67.19%, op_acc: 43.75%] [G loss: 1.423409]\n",
      "epoch:37 step:29098[D loss: 0.298250, acc: 76.56%, op_acc: 53.91%] [G loss: 1.510864]\n",
      "epoch:37 step:29099[D loss: 0.445747, acc: 55.47%, op_acc: 50.00%] [G loss: 1.414977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29100[D loss: 0.400562, acc: 66.41%, op_acc: 38.28%] [G loss: 1.556250]\n",
      "epoch:37 step:29101[D loss: 0.343422, acc: 75.00%, op_acc: 52.34%] [G loss: 1.904674]\n",
      "epoch:37 step:29102[D loss: 0.314171, acc: 84.38%, op_acc: 48.44%] [G loss: 1.304859]\n",
      "epoch:37 step:29103[D loss: 0.441176, acc: 60.94%, op_acc: 43.75%] [G loss: 1.134980]\n",
      "epoch:37 step:29104[D loss: 0.407655, acc: 67.19%, op_acc: 46.88%] [G loss: 1.195711]\n",
      "epoch:37 step:29105[D loss: 0.364282, acc: 74.22%, op_acc: 42.97%] [G loss: 1.356685]\n",
      "epoch:37 step:29106[D loss: 0.350814, acc: 67.19%, op_acc: 53.91%] [G loss: 1.105040]\n",
      "epoch:37 step:29107[D loss: 0.397505, acc: 63.28%, op_acc: 47.66%] [G loss: 0.878868]\n",
      "epoch:37 step:29108[D loss: 0.323014, acc: 80.47%, op_acc: 50.78%] [G loss: 1.125996]\n",
      "epoch:37 step:29109[D loss: 0.333731, acc: 73.44%, op_acc: 53.12%] [G loss: 0.601960]\n",
      "epoch:37 step:29110[D loss: 0.275843, acc: 85.16%, op_acc: 56.25%] [G loss: 0.772653]\n",
      "epoch:37 step:29111[D loss: 0.268022, acc: 88.28%, op_acc: 53.12%] [G loss: 0.962034]\n",
      "epoch:37 step:29112[D loss: 0.282910, acc: 82.81%, op_acc: 54.69%] [G loss: 0.818411]\n",
      "epoch:37 step:29113[D loss: 0.358976, acc: 78.91%, op_acc: 47.66%] [G loss: 0.830416]\n",
      "epoch:37 step:29114[D loss: 0.268833, acc: 85.16%, op_acc: 53.12%] [G loss: 0.782362]\n",
      "epoch:37 step:29115[D loss: 0.293858, acc: 79.69%, op_acc: 59.38%] [G loss: 1.042831]\n",
      "epoch:37 step:29116[D loss: 0.274831, acc: 86.72%, op_acc: 57.81%] [G loss: 0.763024]\n",
      "epoch:37 step:29117[D loss: 0.365043, acc: 78.12%, op_acc: 54.69%] [G loss: 0.807881]\n",
      "epoch:37 step:29118[D loss: 0.233816, acc: 90.62%, op_acc: 65.62%] [G loss: 1.186327]\n",
      "epoch:37 step:29119[D loss: 0.269143, acc: 85.16%, op_acc: 57.03%] [G loss: 0.931444]\n",
      "epoch:37 step:29120[D loss: 0.253767, acc: 89.84%, op_acc: 57.03%] [G loss: 1.032373]\n",
      "epoch:37 step:29121[D loss: 0.249951, acc: 86.72%, op_acc: 57.03%] [G loss: 1.078462]\n",
      "epoch:37 step:29122[D loss: 0.235957, acc: 90.62%, op_acc: 58.59%] [G loss: 1.242872]\n",
      "epoch:37 step:29123[D loss: 0.233066, acc: 94.53%, op_acc: 51.56%] [G loss: 1.293675]\n",
      "epoch:37 step:29124[D loss: 0.248332, acc: 89.06%, op_acc: 60.94%] [G loss: 1.589519]\n",
      "epoch:37 step:29125[D loss: 0.221847, acc: 90.62%, op_acc: 69.53%] [G loss: 1.125429]\n",
      "epoch:37 step:29126[D loss: 0.236571, acc: 88.28%, op_acc: 63.28%] [G loss: 1.595467]\n",
      "epoch:37 step:29127[D loss: 0.397263, acc: 67.19%, op_acc: 50.00%] [G loss: 1.433030]\n",
      "epoch:37 step:29128[D loss: 0.182169, acc: 95.31%, op_acc: 60.94%] [G loss: 1.519318]\n",
      "epoch:37 step:29129[D loss: 0.269397, acc: 87.50%, op_acc: 61.72%] [G loss: 1.676920]\n",
      "epoch:37 step:29130[D loss: 0.172693, acc: 96.88%, op_acc: 70.31%] [G loss: 1.935960]\n",
      "epoch:37 step:29131[D loss: 0.317970, acc: 78.12%, op_acc: 55.47%] [G loss: 0.537099]\n",
      "epoch:37 step:29132[D loss: 0.366872, acc: 68.75%, op_acc: 45.31%] [G loss: 1.973946]\n",
      "epoch:37 step:29133[D loss: 0.358436, acc: 71.88%, op_acc: 56.25%] [G loss: 1.463597]\n",
      "epoch:37 step:29134[D loss: 0.275461, acc: 82.03%, op_acc: 51.56%] [G loss: 2.209465]\n",
      "epoch:37 step:29135[D loss: 0.277456, acc: 82.81%, op_acc: 54.69%] [G loss: 1.359330]\n",
      "epoch:37 step:29136[D loss: 0.266944, acc: 83.59%, op_acc: 58.59%] [G loss: 1.522921]\n",
      "epoch:37 step:29137[D loss: 0.249593, acc: 86.72%, op_acc: 57.81%] [G loss: 0.521184]\n",
      "epoch:37 step:29138[D loss: 0.334277, acc: 71.09%, op_acc: 47.66%] [G loss: 1.748031]\n",
      "epoch:37 step:29139[D loss: 0.309444, acc: 78.12%, op_acc: 53.12%] [G loss: 1.610956]\n",
      "epoch:37 step:29140[D loss: 0.403961, acc: 66.41%, op_acc: 51.56%] [G loss: 1.223526]\n",
      "epoch:37 step:29141[D loss: 0.330694, acc: 78.12%, op_acc: 50.78%] [G loss: 1.228999]\n",
      "epoch:37 step:29142[D loss: 0.245886, acc: 93.75%, op_acc: 57.03%] [G loss: 1.746209]\n",
      "epoch:37 step:29143[D loss: 0.306391, acc: 83.59%, op_acc: 48.44%] [G loss: 1.418994]\n",
      "epoch:37 step:29144[D loss: 0.213734, acc: 92.19%, op_acc: 67.19%] [G loss: 1.658699]\n",
      "epoch:37 step:29145[D loss: 0.310020, acc: 84.38%, op_acc: 57.81%] [G loss: 1.577746]\n",
      "epoch:37 step:29146[D loss: 0.350609, acc: 76.56%, op_acc: 50.00%] [G loss: 1.423162]\n",
      "epoch:37 step:29147[D loss: 0.289893, acc: 86.72%, op_acc: 50.78%] [G loss: 1.569980]\n",
      "epoch:37 step:29148[D loss: 0.174236, acc: 94.53%, op_acc: 65.62%] [G loss: 1.971660]\n",
      "epoch:37 step:29149[D loss: 0.203707, acc: 93.75%, op_acc: 62.50%] [G loss: 1.154294]\n",
      "epoch:37 step:29150[D loss: 0.201771, acc: 94.53%, op_acc: 68.75%] [G loss: 2.056330]\n",
      "epoch:37 step:29151[D loss: 0.206459, acc: 92.97%, op_acc: 67.19%] [G loss: 2.156915]\n",
      "epoch:37 step:29152[D loss: 0.315738, acc: 78.91%, op_acc: 63.28%] [G loss: 1.924938]\n",
      "epoch:37 step:29153[D loss: 0.272858, acc: 85.16%, op_acc: 58.59%] [G loss: 1.399529]\n",
      "epoch:37 step:29154[D loss: 0.372447, acc: 71.88%, op_acc: 43.75%] [G loss: 0.343505]\n",
      "epoch:37 step:29155[D loss: 0.360159, acc: 69.53%, op_acc: 43.75%] [G loss: 2.394557]\n",
      "epoch:37 step:29156[D loss: 0.310781, acc: 82.03%, op_acc: 49.22%] [G loss: 0.951129]\n",
      "epoch:37 step:29157[D loss: 0.375910, acc: 67.97%, op_acc: 40.62%] [G loss: 2.338769]\n",
      "epoch:37 step:29158[D loss: 0.426277, acc: 59.38%, op_acc: 43.75%] [G loss: 2.333821]\n",
      "epoch:37 step:29159[D loss: 0.332411, acc: 73.44%, op_acc: 53.12%] [G loss: 1.622377]\n",
      "epoch:37 step:29160[D loss: 0.330155, acc: 73.44%, op_acc: 46.09%] [G loss: 1.786267]\n",
      "epoch:37 step:29161[D loss: 0.290849, acc: 79.69%, op_acc: 48.44%] [G loss: 1.389470]\n",
      "epoch:37 step:29162[D loss: 0.412651, acc: 67.97%, op_acc: 46.09%] [G loss: 0.917931]\n",
      "epoch:37 step:29163[D loss: 0.368440, acc: 67.97%, op_acc: 46.09%] [G loss: 1.549961]\n",
      "epoch:37 step:29164[D loss: 0.434799, acc: 62.50%, op_acc: 51.56%] [G loss: 0.681839]\n",
      "epoch:37 step:29165[D loss: 0.477468, acc: 54.69%, op_acc: 42.19%] [G loss: 1.402886]\n",
      "epoch:37 step:29166[D loss: 0.354169, acc: 67.19%, op_acc: 46.09%] [G loss: 0.881644]\n",
      "epoch:37 step:29167[D loss: 0.321727, acc: 75.00%, op_acc: 50.00%] [G loss: 0.806948]\n",
      "epoch:37 step:29168[D loss: 0.401682, acc: 66.41%, op_acc: 42.97%] [G loss: 1.581550]\n",
      "epoch:37 step:29169[D loss: 0.342570, acc: 75.00%, op_acc: 43.75%] [G loss: 0.894020]\n",
      "epoch:37 step:29170[D loss: 0.390962, acc: 64.84%, op_acc: 48.44%] [G loss: 1.516946]\n",
      "epoch:37 step:29171[D loss: 0.373450, acc: 69.53%, op_acc: 47.66%] [G loss: 0.891881]\n",
      "epoch:37 step:29172[D loss: 0.315671, acc: 75.78%, op_acc: 61.72%] [G loss: 0.887240]\n",
      "epoch:37 step:29173[D loss: 0.412936, acc: 64.06%, op_acc: 46.09%] [G loss: 1.108016]\n",
      "epoch:37 step:29174[D loss: 0.337826, acc: 75.78%, op_acc: 46.09%] [G loss: 0.800439]\n",
      "epoch:37 step:29175[D loss: 0.471761, acc: 54.69%, op_acc: 40.62%] [G loss: 1.820988]\n",
      "epoch:37 step:29176[D loss: 0.349661, acc: 71.88%, op_acc: 55.47%] [G loss: 1.867123]\n",
      "epoch:37 step:29177[D loss: 0.414841, acc: 64.06%, op_acc: 50.00%] [G loss: 0.764258]\n",
      "epoch:37 step:29178[D loss: 0.437720, acc: 59.38%, op_acc: 39.84%] [G loss: 1.140770]\n",
      "epoch:37 step:29179[D loss: 0.351520, acc: 71.88%, op_acc: 53.12%] [G loss: 0.747778]\n",
      "epoch:37 step:29180[D loss: 0.282297, acc: 82.03%, op_acc: 60.94%] [G loss: 1.100757]\n",
      "epoch:37 step:29181[D loss: 0.361423, acc: 71.09%, op_acc: 45.31%] [G loss: 0.943404]\n",
      "epoch:37 step:29182[D loss: 0.349093, acc: 72.66%, op_acc: 51.56%] [G loss: 1.436257]\n",
      "epoch:37 step:29183[D loss: 0.365676, acc: 74.22%, op_acc: 42.97%] [G loss: 1.414871]\n",
      "epoch:37 step:29184[D loss: 0.384036, acc: 70.31%, op_acc: 57.03%] [G loss: 1.226508]\n",
      "epoch:37 step:29185[D loss: 0.265525, acc: 85.94%, op_acc: 58.59%] [G loss: 1.023006]\n",
      "epoch:37 step:29186[D loss: 0.283676, acc: 85.16%, op_acc: 53.91%] [G loss: 1.151484]\n",
      "epoch:37 step:29187[D loss: 0.357223, acc: 76.56%, op_acc: 46.09%] [G loss: 0.974435]\n",
      "epoch:37 step:29188[D loss: 0.386448, acc: 66.41%, op_acc: 45.31%] [G loss: 1.197844]\n",
      "epoch:37 step:29189[D loss: 0.339958, acc: 80.47%, op_acc: 44.53%] [G loss: 0.754831]\n",
      "epoch:37 step:29190[D loss: 0.366002, acc: 67.19%, op_acc: 55.47%] [G loss: 0.764960]\n",
      "epoch:37 step:29191[D loss: 0.326942, acc: 72.66%, op_acc: 55.47%] [G loss: 0.730429]\n",
      "epoch:37 step:29192[D loss: 0.329896, acc: 75.78%, op_acc: 57.03%] [G loss: 1.281987]\n",
      "epoch:37 step:29193[D loss: 0.292522, acc: 78.91%, op_acc: 60.16%] [G loss: 1.087353]\n",
      "epoch:37 step:29194[D loss: 0.340150, acc: 76.56%, op_acc: 48.44%] [G loss: 0.784904]\n",
      "epoch:37 step:29195[D loss: 0.349884, acc: 74.22%, op_acc: 46.88%] [G loss: 0.792318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29196[D loss: 0.344077, acc: 77.34%, op_acc: 45.31%] [G loss: 0.710138]\n",
      "epoch:37 step:29197[D loss: 0.430242, acc: 67.19%, op_acc: 42.19%] [G loss: 0.578963]\n",
      "epoch:37 step:29198[D loss: 0.345015, acc: 77.34%, op_acc: 48.44%] [G loss: 0.720120]\n",
      "epoch:37 step:29199[D loss: 0.292945, acc: 82.03%, op_acc: 52.34%] [G loss: 0.966309]\n",
      "epoch:37 step:29200[D loss: 0.267444, acc: 84.38%, op_acc: 50.78%] [G loss: 1.247486]\n",
      "epoch:37 step:29201[D loss: 0.242102, acc: 86.72%, op_acc: 68.75%] [G loss: 1.214117]\n",
      "epoch:37 step:29202[D loss: 0.365725, acc: 66.41%, op_acc: 54.69%] [G loss: 1.169963]\n",
      "epoch:37 step:29203[D loss: 0.315005, acc: 81.25%, op_acc: 51.56%] [G loss: 0.634260]\n",
      "epoch:37 step:29204[D loss: 0.353268, acc: 69.53%, op_acc: 44.53%] [G loss: 1.042656]\n",
      "epoch:37 step:29205[D loss: 0.391781, acc: 69.53%, op_acc: 42.19%] [G loss: 1.223110]\n",
      "epoch:37 step:29206[D loss: 0.434533, acc: 62.50%, op_acc: 32.03%] [G loss: 2.078781]\n",
      "epoch:37 step:29207[D loss: 0.255723, acc: 87.50%, op_acc: 57.03%] [G loss: 1.304588]\n",
      "epoch:37 step:29208[D loss: 0.364254, acc: 72.66%, op_acc: 50.00%] [G loss: 1.216109]\n",
      "epoch:37 step:29209[D loss: 0.428493, acc: 62.50%, op_acc: 46.09%] [G loss: 1.201913]\n",
      "epoch:37 step:29210[D loss: 0.477701, acc: 60.16%, op_acc: 45.31%] [G loss: 1.083999]\n",
      "epoch:37 step:29211[D loss: 0.317335, acc: 77.34%, op_acc: 53.12%] [G loss: 0.849826]\n",
      "epoch:37 step:29212[D loss: 0.334757, acc: 71.88%, op_acc: 53.12%] [G loss: 0.665975]\n",
      "epoch:37 step:29213[D loss: 0.373545, acc: 71.09%, op_acc: 45.31%] [G loss: 0.970460]\n",
      "epoch:37 step:29214[D loss: 0.386704, acc: 70.31%, op_acc: 43.75%] [G loss: 0.951969]\n",
      "epoch:37 step:29215[D loss: 0.360081, acc: 74.22%, op_acc: 46.88%] [G loss: 0.996662]\n",
      "epoch:37 step:29216[D loss: 0.292544, acc: 84.38%, op_acc: 55.47%] [G loss: 1.311615]\n",
      "epoch:37 step:29217[D loss: 0.286450, acc: 82.81%, op_acc: 56.25%] [G loss: 1.275097]\n",
      "epoch:37 step:29218[D loss: 0.314464, acc: 77.34%, op_acc: 50.78%] [G loss: 1.080588]\n",
      "epoch:37 step:29219[D loss: 0.401494, acc: 72.66%, op_acc: 46.09%] [G loss: 1.573321]\n",
      "epoch:37 step:29220[D loss: 0.332521, acc: 75.00%, op_acc: 57.03%] [G loss: 0.549473]\n",
      "epoch:37 step:29221[D loss: 0.447676, acc: 59.38%, op_acc: 33.59%] [G loss: 0.903520]\n",
      "epoch:37 step:29222[D loss: 0.389456, acc: 67.97%, op_acc: 50.78%] [G loss: 0.773422]\n",
      "epoch:37 step:29223[D loss: 0.362714, acc: 73.44%, op_acc: 48.44%] [G loss: 1.313943]\n",
      "epoch:37 step:29224[D loss: 0.335506, acc: 76.56%, op_acc: 48.44%] [G loss: 1.005629]\n",
      "epoch:37 step:29225[D loss: 0.360007, acc: 68.75%, op_acc: 45.31%] [G loss: 1.419471]\n",
      "epoch:37 step:29226[D loss: 0.403049, acc: 67.19%, op_acc: 42.19%] [G loss: 0.780730]\n",
      "epoch:37 step:29227[D loss: 0.455956, acc: 55.47%, op_acc: 46.09%] [G loss: 1.363140]\n",
      "epoch:37 step:29228[D loss: 0.347589, acc: 71.88%, op_acc: 57.03%] [G loss: 0.775671]\n",
      "epoch:37 step:29229[D loss: 0.446802, acc: 62.50%, op_acc: 51.56%] [G loss: 0.535062]\n",
      "epoch:37 step:29230[D loss: 0.350584, acc: 74.22%, op_acc: 46.88%] [G loss: 1.338729]\n",
      "epoch:37 step:29231[D loss: 0.369078, acc: 67.19%, op_acc: 51.56%] [G loss: 1.618031]\n",
      "epoch:37 step:29232[D loss: 0.396106, acc: 67.19%, op_acc: 44.53%] [G loss: 0.454978]\n",
      "epoch:37 step:29233[D loss: 0.292184, acc: 82.03%, op_acc: 50.00%] [G loss: 0.955000]\n",
      "epoch:37 step:29234[D loss: 0.464852, acc: 58.59%, op_acc: 38.28%] [G loss: 0.541055]\n",
      "epoch:37 step:29235[D loss: 0.291911, acc: 75.00%, op_acc: 51.56%] [G loss: 1.632273]\n",
      "epoch:37 step:29236[D loss: 0.432821, acc: 60.16%, op_acc: 46.88%] [G loss: 1.547705]\n",
      "epoch:37 step:29237[D loss: 0.357941, acc: 73.44%, op_acc: 46.88%] [G loss: 0.482914]\n",
      "epoch:37 step:29238[D loss: 0.357221, acc: 71.88%, op_acc: 47.66%] [G loss: 1.438301]\n",
      "epoch:37 step:29239[D loss: 0.323785, acc: 76.56%, op_acc: 43.75%] [G loss: 0.279977]\n",
      "epoch:37 step:29240[D loss: 0.311835, acc: 81.25%, op_acc: 51.56%] [G loss: 1.546562]\n",
      "epoch:37 step:29241[D loss: 0.359920, acc: 70.31%, op_acc: 47.66%] [G loss: 1.273992]\n",
      "epoch:37 step:29242[D loss: 0.351220, acc: 75.00%, op_acc: 45.31%] [G loss: 0.415302]\n",
      "epoch:37 step:29243[D loss: 0.390642, acc: 70.31%, op_acc: 43.75%] [G loss: 1.381051]\n",
      "epoch:37 step:29244[D loss: 0.375179, acc: 67.19%, op_acc: 46.09%] [G loss: 0.401743]\n",
      "epoch:37 step:29245[D loss: 0.344831, acc: 73.44%, op_acc: 46.09%] [G loss: 0.326715]\n",
      "epoch:37 step:29246[D loss: 0.385859, acc: 71.88%, op_acc: 49.22%] [G loss: 0.428063]\n",
      "epoch:37 step:29247[D loss: 0.399914, acc: 67.19%, op_acc: 50.78%] [G loss: 1.209417]\n",
      "epoch:37 step:29248[D loss: 0.457773, acc: 57.81%, op_acc: 39.84%] [G loss: 0.572401]\n",
      "epoch:37 step:29249[D loss: 0.322260, acc: 75.78%, op_acc: 53.12%] [G loss: 0.437614]\n",
      "epoch:37 step:29250[D loss: 0.340425, acc: 70.31%, op_acc: 52.34%] [G loss: 0.483413]\n",
      "epoch:37 step:29251[D loss: 0.385525, acc: 67.97%, op_acc: 48.44%] [G loss: 0.325413]\n",
      "epoch:37 step:29252[D loss: 0.386416, acc: 66.41%, op_acc: 52.34%] [G loss: 0.619763]\n",
      "epoch:37 step:29253[D loss: 0.331044, acc: 79.69%, op_acc: 57.03%] [G loss: 0.583326]\n",
      "epoch:37 step:29254[D loss: 0.252993, acc: 85.94%, op_acc: 57.03%] [G loss: 0.874922]\n",
      "epoch:37 step:29255[D loss: 0.248523, acc: 89.06%, op_acc: 56.25%] [G loss: 1.806965]\n",
      "epoch:37 step:29256[D loss: 0.288083, acc: 84.38%, op_acc: 51.56%] [G loss: 1.040449]\n",
      "epoch:37 step:29257[D loss: 0.357070, acc: 74.22%, op_acc: 46.09%] [G loss: 0.591597]\n",
      "epoch:37 step:29258[D loss: 0.252492, acc: 85.16%, op_acc: 54.69%] [G loss: 1.815598]\n",
      "epoch:37 step:29259[D loss: 0.313722, acc: 82.81%, op_acc: 50.00%] [G loss: 1.695804]\n",
      "epoch:37 step:29260[D loss: 0.328045, acc: 72.66%, op_acc: 54.69%] [G loss: 1.064080]\n",
      "epoch:37 step:29261[D loss: 0.474165, acc: 52.34%, op_acc: 38.28%] [G loss: 0.863950]\n",
      "epoch:37 step:29262[D loss: 0.289894, acc: 78.91%, op_acc: 55.47%] [G loss: 0.690294]\n",
      "epoch:37 step:29263[D loss: 0.282380, acc: 83.59%, op_acc: 53.12%] [G loss: 0.726318]\n",
      "epoch:37 step:29264[D loss: 0.353474, acc: 76.56%, op_acc: 46.88%] [G loss: 0.739178]\n",
      "epoch:37 step:29265[D loss: 0.322825, acc: 75.78%, op_acc: 54.69%] [G loss: 0.618792]\n",
      "epoch:37 step:29266[D loss: 0.251742, acc: 82.81%, op_acc: 64.06%] [G loss: 0.530025]\n",
      "epoch:37 step:29267[D loss: 0.396595, acc: 69.53%, op_acc: 44.53%] [G loss: 0.709994]\n",
      "epoch:37 step:29268[D loss: 0.332874, acc: 74.22%, op_acc: 58.59%] [G loss: 0.668788]\n",
      "epoch:37 step:29269[D loss: 0.322434, acc: 75.00%, op_acc: 57.81%] [G loss: 0.702792]\n",
      "epoch:37 step:29270[D loss: 0.245781, acc: 84.38%, op_acc: 52.34%] [G loss: 1.240070]\n",
      "epoch:37 step:29271[D loss: 0.245411, acc: 86.72%, op_acc: 63.28%] [G loss: 1.683962]\n",
      "epoch:37 step:29272[D loss: 0.271853, acc: 82.81%, op_acc: 58.59%] [G loss: 1.266590]\n",
      "epoch:37 step:29273[D loss: 0.268133, acc: 84.38%, op_acc: 57.03%] [G loss: 1.336073]\n",
      "epoch:37 step:29274[D loss: 0.260644, acc: 85.16%, op_acc: 57.81%] [G loss: 1.153867]\n",
      "epoch:37 step:29275[D loss: 0.196020, acc: 92.19%, op_acc: 60.94%] [G loss: 1.441681]\n",
      "epoch:37 step:29276[D loss: 0.197801, acc: 94.53%, op_acc: 65.62%] [G loss: 1.623230]\n",
      "epoch:37 step:29277[D loss: 0.280422, acc: 82.81%, op_acc: 65.62%] [G loss: 0.777339]\n",
      "epoch:37 step:29278[D loss: 0.301896, acc: 84.38%, op_acc: 45.31%] [G loss: 1.081575]\n",
      "epoch:37 step:29279[D loss: 0.189426, acc: 96.09%, op_acc: 70.31%] [G loss: 1.899780]\n",
      "epoch:37 step:29280[D loss: 0.293608, acc: 82.03%, op_acc: 60.94%] [G loss: 1.729030]\n",
      "epoch:37 step:29281[D loss: 0.167226, acc: 95.31%, op_acc: 75.00%] [G loss: 1.242226]\n",
      "epoch:37 step:29282[D loss: 0.172896, acc: 95.31%, op_acc: 67.19%] [G loss: 2.178895]\n",
      "epoch:37 step:29283[D loss: 0.218602, acc: 91.41%, op_acc: 64.06%] [G loss: 1.834002]\n",
      "epoch:37 step:29284[D loss: 0.227778, acc: 94.53%, op_acc: 65.62%] [G loss: 1.896645]\n",
      "epoch:37 step:29285[D loss: 0.305722, acc: 83.59%, op_acc: 57.81%] [G loss: 1.281772]\n",
      "epoch:37 step:29286[D loss: 0.216558, acc: 92.19%, op_acc: 62.50%] [G loss: 1.402721]\n",
      "epoch:37 step:29287[D loss: 0.180777, acc: 95.31%, op_acc: 65.62%] [G loss: 1.864654]\n",
      "epoch:37 step:29288[D loss: 0.278890, acc: 80.47%, op_acc: 57.03%] [G loss: 1.542782]\n",
      "epoch:37 step:29289[D loss: 0.235224, acc: 87.50%, op_acc: 71.09%] [G loss: 2.218256]\n",
      "epoch:37 step:29290[D loss: 0.190060, acc: 94.53%, op_acc: 64.06%] [G loss: 1.928125]\n",
      "epoch:37 step:29291[D loss: 0.230199, acc: 89.84%, op_acc: 69.53%] [G loss: 2.079663]\n",
      "epoch:37 step:29292[D loss: 0.219180, acc: 90.62%, op_acc: 64.06%] [G loss: 2.687699]\n",
      "epoch:37 step:29293[D loss: 0.157607, acc: 99.22%, op_acc: 67.19%] [G loss: 0.336317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29294[D loss: 0.589409, acc: 52.34%, op_acc: 42.19%] [G loss: 2.324460]\n",
      "epoch:37 step:29295[D loss: 0.475865, acc: 57.03%, op_acc: 37.50%] [G loss: 2.561870]\n",
      "epoch:37 step:29296[D loss: 0.242497, acc: 85.94%, op_acc: 64.06%] [G loss: 2.567928]\n",
      "epoch:37 step:29297[D loss: 0.361642, acc: 64.84%, op_acc: 61.72%] [G loss: 1.221071]\n",
      "epoch:37 step:29298[D loss: 0.311581, acc: 81.25%, op_acc: 50.78%] [G loss: 1.895771]\n",
      "epoch:37 step:29299[D loss: 0.312879, acc: 82.03%, op_acc: 53.12%] [G loss: 1.456566]\n",
      "epoch:37 step:29300[D loss: 0.273613, acc: 80.47%, op_acc: 59.38%] [G loss: 1.677749]\n",
      "epoch:37 step:29301[D loss: 0.257182, acc: 86.72%, op_acc: 64.06%] [G loss: 2.131697]\n",
      "epoch:37 step:29302[D loss: 0.378243, acc: 70.31%, op_acc: 57.03%] [G loss: 1.543923]\n",
      "epoch:37 step:29303[D loss: 0.370647, acc: 67.97%, op_acc: 39.06%] [G loss: 1.643010]\n",
      "epoch:37 step:29304[D loss: 0.336883, acc: 78.12%, op_acc: 42.97%] [G loss: 1.950514]\n",
      "epoch:37 step:29305[D loss: 0.357495, acc: 69.53%, op_acc: 53.12%] [G loss: 1.239135]\n",
      "epoch:37 step:29306[D loss: 0.375377, acc: 67.19%, op_acc: 46.88%] [G loss: 1.336965]\n",
      "epoch:37 step:29307[D loss: 0.282122, acc: 81.25%, op_acc: 53.91%] [G loss: 1.424746]\n",
      "epoch:37 step:29308[D loss: 0.453141, acc: 60.94%, op_acc: 41.41%] [G loss: 1.093520]\n",
      "epoch:37 step:29309[D loss: 0.303357, acc: 76.56%, op_acc: 54.69%] [G loss: 1.281061]\n",
      "epoch:37 step:29310[D loss: 0.343587, acc: 75.78%, op_acc: 57.81%] [G loss: 1.551689]\n",
      "epoch:37 step:29311[D loss: 0.340010, acc: 71.09%, op_acc: 52.34%] [G loss: 1.807489]\n",
      "epoch:37 step:29312[D loss: 0.300684, acc: 81.25%, op_acc: 57.03%] [G loss: 0.573342]\n",
      "epoch:37 step:29313[D loss: 0.326381, acc: 79.69%, op_acc: 48.44%] [G loss: 0.740034]\n",
      "epoch:37 step:29314[D loss: 0.312767, acc: 80.47%, op_acc: 50.00%] [G loss: 1.774027]\n",
      "epoch:37 step:29315[D loss: 0.380066, acc: 71.09%, op_acc: 46.09%] [G loss: 1.540162]\n",
      "epoch:37 step:29316[D loss: 0.288601, acc: 78.91%, op_acc: 46.09%] [G loss: 0.928540]\n",
      "epoch:37 step:29317[D loss: 0.468613, acc: 66.41%, op_acc: 42.97%] [G loss: 0.463550]\n",
      "epoch:37 step:29318[D loss: 0.299041, acc: 81.25%, op_acc: 59.38%] [G loss: 0.624150]\n",
      "epoch:37 step:29319[D loss: 0.261665, acc: 82.81%, op_acc: 53.12%] [G loss: 1.697933]\n",
      "epoch:37 step:29320[D loss: 0.308779, acc: 83.59%, op_acc: 49.22%] [G loss: 0.388462]\n",
      "epoch:37 step:29321[D loss: 0.396601, acc: 67.97%, op_acc: 45.31%] [G loss: 0.354666]\n",
      "epoch:37 step:29322[D loss: 0.308749, acc: 82.81%, op_acc: 49.22%] [G loss: 0.596481]\n",
      "epoch:37 step:29323[D loss: 0.383178, acc: 71.09%, op_acc: 51.56%] [G loss: 0.451252]\n",
      "epoch:37 step:29324[D loss: 0.416160, acc: 64.84%, op_acc: 43.75%] [G loss: 1.250272]\n",
      "epoch:37 step:29325[D loss: 0.454459, acc: 57.03%, op_acc: 45.31%] [G loss: 0.708907]\n",
      "epoch:37 step:29326[D loss: 0.258359, acc: 86.72%, op_acc: 53.12%] [G loss: 0.748104]\n",
      "epoch:37 step:29327[D loss: 0.261579, acc: 84.38%, op_acc: 58.59%] [G loss: 0.965858]\n",
      "epoch:37 step:29328[D loss: 0.227954, acc: 89.06%, op_acc: 64.84%] [G loss: 0.742620]\n",
      "epoch:37 step:29329[D loss: 0.392187, acc: 64.84%, op_acc: 46.88%] [G loss: 1.635938]\n",
      "epoch:37 step:29330[D loss: 0.267796, acc: 87.50%, op_acc: 46.88%] [G loss: 1.058255]\n",
      "epoch:37 step:29331[D loss: 0.348607, acc: 68.75%, op_acc: 56.25%] [G loss: 0.599725]\n",
      "epoch:37 step:29332[D loss: 0.413900, acc: 62.50%, op_acc: 46.09%] [G loss: 1.117734]\n",
      "epoch:37 step:29333[D loss: 0.333037, acc: 77.34%, op_acc: 48.44%] [G loss: 1.738107]\n",
      "epoch:37 step:29334[D loss: 0.587827, acc: 47.66%, op_acc: 36.72%] [G loss: 0.615168]\n",
      "epoch:37 step:29335[D loss: 0.244003, acc: 85.94%, op_acc: 57.81%] [G loss: 0.620682]\n",
      "epoch:37 step:29336[D loss: 0.294650, acc: 78.12%, op_acc: 52.34%] [G loss: 0.487528]\n",
      "epoch:37 step:29337[D loss: 0.346952, acc: 73.44%, op_acc: 46.88%] [G loss: 0.885399]\n",
      "epoch:37 step:29338[D loss: 0.395343, acc: 67.19%, op_acc: 45.31%] [G loss: 0.789715]\n",
      "epoch:37 step:29339[D loss: 0.415896, acc: 58.59%, op_acc: 45.31%] [G loss: 1.104463]\n",
      "epoch:37 step:29340[D loss: 0.452927, acc: 59.38%, op_acc: 35.16%] [G loss: 0.825347]\n",
      "epoch:37 step:29341[D loss: 0.359596, acc: 74.22%, op_acc: 51.56%] [G loss: 0.726317]\n",
      "epoch:37 step:29342[D loss: 0.315968, acc: 82.81%, op_acc: 49.22%] [G loss: 0.930853]\n",
      "epoch:37 step:29343[D loss: 0.473905, acc: 50.78%, op_acc: 39.06%] [G loss: 0.473398]\n",
      "epoch:37 step:29344[D loss: 0.350126, acc: 75.78%, op_acc: 50.78%] [G loss: 0.505605]\n",
      "epoch:37 step:29345[D loss: 0.387771, acc: 65.62%, op_acc: 51.56%] [G loss: 0.410240]\n",
      "epoch:37 step:29346[D loss: 0.336474, acc: 71.88%, op_acc: 49.22%] [G loss: 1.392621]\n",
      "epoch:37 step:29347[D loss: 0.363645, acc: 75.78%, op_acc: 45.31%] [G loss: 1.484034]\n",
      "epoch:37 step:29348[D loss: 0.350918, acc: 73.44%, op_acc: 51.56%] [G loss: 1.403112]\n",
      "epoch:37 step:29349[D loss: 0.391784, acc: 64.06%, op_acc: 47.66%] [G loss: 1.778912]\n",
      "epoch:37 step:29350[D loss: 0.318832, acc: 73.44%, op_acc: 54.69%] [G loss: 1.790865]\n",
      "epoch:37 step:29351[D loss: 0.446854, acc: 64.06%, op_acc: 47.66%] [G loss: 0.290904]\n",
      "epoch:37 step:29352[D loss: 0.431797, acc: 61.72%, op_acc: 44.53%] [G loss: 0.311038]\n",
      "epoch:37 step:29353[D loss: 0.343903, acc: 75.00%, op_acc: 42.97%] [G loss: 1.470092]\n",
      "epoch:37 step:29354[D loss: 0.362855, acc: 72.66%, op_acc: 53.91%] [G loss: 0.235947]\n",
      "epoch:37 step:29355[D loss: 0.317889, acc: 77.34%, op_acc: 60.16%] [G loss: 1.628442]\n",
      "epoch:37 step:29356[D loss: 0.518256, acc: 51.56%, op_acc: 35.94%] [G loss: 0.427376]\n",
      "epoch:37 step:29357[D loss: 0.298999, acc: 78.91%, op_acc: 45.31%] [G loss: 0.391663]\n",
      "epoch:37 step:29358[D loss: 0.373344, acc: 70.31%, op_acc: 46.09%] [G loss: 0.279889]\n",
      "epoch:37 step:29359[D loss: 0.419000, acc: 62.50%, op_acc: 46.88%] [G loss: 0.272288]\n",
      "epoch:37 step:29360[D loss: 0.431490, acc: 54.69%, op_acc: 40.62%] [G loss: 0.463326]\n",
      "epoch:37 step:29361[D loss: 0.375600, acc: 73.44%, op_acc: 49.22%] [G loss: 0.302769]\n",
      "epoch:37 step:29362[D loss: 0.474857, acc: 55.47%, op_acc: 42.97%] [G loss: 0.560050]\n",
      "epoch:37 step:29363[D loss: 0.330271, acc: 78.91%, op_acc: 55.47%] [G loss: 0.516497]\n",
      "epoch:37 step:29364[D loss: 0.418337, acc: 57.81%, op_acc: 46.09%] [G loss: 0.412767]\n",
      "epoch:37 step:29365[D loss: 0.345178, acc: 72.66%, op_acc: 53.12%] [G loss: 0.398390]\n",
      "epoch:37 step:29366[D loss: 0.358080, acc: 71.88%, op_acc: 50.00%] [G loss: 0.408552]\n",
      "epoch:37 step:29367[D loss: 0.247348, acc: 88.28%, op_acc: 61.72%] [G loss: 0.483062]\n",
      "epoch:37 step:29368[D loss: 0.308539, acc: 82.03%, op_acc: 52.34%] [G loss: 0.709889]\n",
      "epoch:37 step:29369[D loss: 0.456606, acc: 61.72%, op_acc: 39.06%] [G loss: 1.623631]\n",
      "epoch:37 step:29370[D loss: 0.378538, acc: 67.97%, op_acc: 49.22%] [G loss: 0.545606]\n",
      "epoch:37 step:29371[D loss: 0.362516, acc: 70.31%, op_acc: 46.88%] [G loss: 0.594980]\n",
      "epoch:37 step:29372[D loss: 0.380377, acc: 68.75%, op_acc: 51.56%] [G loss: 0.414701]\n",
      "epoch:37 step:29373[D loss: 0.363916, acc: 69.53%, op_acc: 44.53%] [G loss: 0.682381]\n",
      "epoch:37 step:29374[D loss: 0.302118, acc: 82.03%, op_acc: 50.00%] [G loss: 1.068160]\n",
      "epoch:37 step:29375[D loss: 0.319289, acc: 78.91%, op_acc: 64.06%] [G loss: 1.140450]\n",
      "epoch:37 step:29376[D loss: 0.278617, acc: 86.72%, op_acc: 58.59%] [G loss: 1.238133]\n",
      "epoch:37 step:29377[D loss: 0.254082, acc: 93.75%, op_acc: 57.03%] [G loss: 1.231487]\n",
      "epoch:37 step:29378[D loss: 0.271739, acc: 85.16%, op_acc: 62.50%] [G loss: 1.039770]\n",
      "epoch:37 step:29379[D loss: 0.272210, acc: 83.59%, op_acc: 60.94%] [G loss: 1.995086]\n",
      "epoch:37 step:29380[D loss: 0.246990, acc: 88.28%, op_acc: 65.62%] [G loss: 1.208726]\n",
      "epoch:37 step:29381[D loss: 0.209365, acc: 87.50%, op_acc: 66.41%] [G loss: 0.948663]\n",
      "epoch:37 step:29382[D loss: 0.228884, acc: 89.84%, op_acc: 58.59%] [G loss: 1.151123]\n",
      "epoch:37 step:29383[D loss: 0.211358, acc: 91.41%, op_acc: 71.09%] [G loss: 1.108408]\n",
      "epoch:37 step:29384[D loss: 0.232695, acc: 89.84%, op_acc: 66.41%] [G loss: 1.395116]\n",
      "epoch:37 step:29385[D loss: 0.172798, acc: 94.53%, op_acc: 64.06%] [G loss: 1.723506]\n",
      "epoch:37 step:29386[D loss: 0.180012, acc: 93.75%, op_acc: 72.66%] [G loss: 1.567234]\n",
      "epoch:37 step:29387[D loss: 0.213270, acc: 89.84%, op_acc: 68.75%] [G loss: 1.568817]\n",
      "epoch:37 step:29388[D loss: 0.258745, acc: 87.50%, op_acc: 52.34%] [G loss: 0.273883]\n",
      "epoch:37 step:29389[D loss: 0.461745, acc: 63.28%, op_acc: 46.09%] [G loss: 2.344985]\n",
      "epoch:37 step:29390[D loss: 0.363279, acc: 71.88%, op_acc: 50.00%] [G loss: 2.202873]\n",
      "epoch:37 step:29391[D loss: 0.229806, acc: 90.62%, op_acc: 57.03%] [G loss: 2.096908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29392[D loss: 0.215251, acc: 92.19%, op_acc: 65.62%] [G loss: 1.893087]\n",
      "epoch:37 step:29393[D loss: 0.189274, acc: 92.19%, op_acc: 71.09%] [G loss: 1.750275]\n",
      "epoch:37 step:29394[D loss: 0.213348, acc: 87.50%, op_acc: 75.00%] [G loss: 0.705237]\n",
      "epoch:37 step:29395[D loss: 0.529465, acc: 54.69%, op_acc: 39.84%] [G loss: 0.578658]\n",
      "epoch:37 step:29396[D loss: 0.583482, acc: 46.88%, op_acc: 31.25%] [G loss: 1.436003]\n",
      "epoch:37 step:29397[D loss: 0.391241, acc: 61.72%, op_acc: 45.31%] [G loss: 1.758886]\n",
      "epoch:37 step:29398[D loss: 0.396498, acc: 67.19%, op_acc: 46.88%] [G loss: 3.027637]\n",
      "epoch:37 step:29399[D loss: 0.349696, acc: 71.09%, op_acc: 57.03%] [G loss: 1.573098]\n",
      "epoch:37 step:29400[D loss: 0.271866, acc: 84.38%, op_acc: 64.84%] [G loss: 1.110120]\n",
      "epoch:37 step:29401[D loss: 0.409315, acc: 68.75%, op_acc: 52.34%] [G loss: 1.444034]\n",
      "epoch:37 step:29402[D loss: 0.278328, acc: 81.25%, op_acc: 60.16%] [G loss: 1.177953]\n",
      "epoch:37 step:29403[D loss: 0.282588, acc: 83.59%, op_acc: 52.34%] [G loss: 0.856254]\n",
      "epoch:37 step:29404[D loss: 0.234853, acc: 87.50%, op_acc: 63.28%] [G loss: 1.066181]\n",
      "epoch:37 step:29405[D loss: 0.275417, acc: 84.38%, op_acc: 60.16%] [G loss: 1.185063]\n",
      "epoch:37 step:29406[D loss: 0.278236, acc: 81.25%, op_acc: 59.38%] [G loss: 1.202756]\n",
      "epoch:37 step:29407[D loss: 0.177693, acc: 96.88%, op_acc: 72.66%] [G loss: 1.405699]\n",
      "epoch:37 step:29408[D loss: 0.216925, acc: 89.06%, op_acc: 74.22%] [G loss: 1.053394]\n",
      "epoch:37 step:29409[D loss: 0.174014, acc: 96.09%, op_acc: 69.53%] [G loss: 1.176616]\n",
      "epoch:37 step:29410[D loss: 0.275276, acc: 82.81%, op_acc: 69.53%] [G loss: 1.397103]\n",
      "epoch:37 step:29411[D loss: 0.194478, acc: 92.97%, op_acc: 65.62%] [G loss: 0.983092]\n",
      "epoch:37 step:29412[D loss: 0.180110, acc: 94.53%, op_acc: 61.72%] [G loss: 1.446018]\n",
      "epoch:37 step:29413[D loss: 0.152112, acc: 97.66%, op_acc: 66.41%] [G loss: 1.480764]\n",
      "epoch:37 step:29414[D loss: 0.267763, acc: 89.84%, op_acc: 61.72%] [G loss: 1.452935]\n",
      "epoch:37 step:29415[D loss: 0.152409, acc: 96.09%, op_acc: 71.88%] [G loss: 1.754796]\n",
      "epoch:37 step:29416[D loss: 0.172549, acc: 95.31%, op_acc: 64.06%] [G loss: 1.480933]\n",
      "epoch:37 step:29417[D loss: 0.258947, acc: 85.16%, op_acc: 52.34%] [G loss: 2.124894]\n",
      "epoch:37 step:29418[D loss: 0.191360, acc: 95.31%, op_acc: 70.31%] [G loss: 1.493450]\n",
      "epoch:37 step:29419[D loss: 0.196555, acc: 95.31%, op_acc: 61.72%] [G loss: 2.494109]\n",
      "epoch:37 step:29420[D loss: 0.213841, acc: 92.19%, op_acc: 67.97%] [G loss: 2.351554]\n",
      "epoch:37 step:29421[D loss: 0.212945, acc: 93.75%, op_acc: 62.50%] [G loss: 2.594397]\n",
      "epoch:37 step:29422[D loss: 0.177635, acc: 96.88%, op_acc: 70.31%] [G loss: 2.502997]\n",
      "epoch:37 step:29423[D loss: 0.374697, acc: 70.31%, op_acc: 64.84%] [G loss: 2.024522]\n",
      "epoch:37 step:29424[D loss: 0.193466, acc: 92.19%, op_acc: 67.97%] [G loss: 2.096072]\n",
      "epoch:37 step:29425[D loss: 0.159248, acc: 96.88%, op_acc: 77.34%] [G loss: 1.751363]\n",
      "epoch:37 step:29426[D loss: 0.172471, acc: 95.31%, op_acc: 74.22%] [G loss: 2.191096]\n",
      "epoch:37 step:29427[D loss: 0.223161, acc: 90.62%, op_acc: 65.62%] [G loss: 1.987522]\n",
      "epoch:37 step:29428[D loss: 0.194823, acc: 94.53%, op_acc: 61.72%] [G loss: 2.356827]\n",
      "epoch:37 step:29429[D loss: 0.242679, acc: 89.84%, op_acc: 66.41%] [G loss: 2.558080]\n",
      "epoch:37 step:29430[D loss: 0.156419, acc: 92.97%, op_acc: 72.66%] [G loss: 2.238968]\n",
      "epoch:37 step:29431[D loss: 0.144625, acc: 96.09%, op_acc: 77.34%] [G loss: 2.654435]\n",
      "epoch:37 step:29432[D loss: 0.212117, acc: 92.19%, op_acc: 68.75%] [G loss: 2.133206]\n",
      "epoch:37 step:29433[D loss: 0.193915, acc: 90.62%, op_acc: 74.22%] [G loss: 2.659659]\n",
      "epoch:37 step:29434[D loss: 0.171614, acc: 93.75%, op_acc: 69.53%] [G loss: 2.890878]\n",
      "epoch:37 step:29435[D loss: 0.170945, acc: 93.75%, op_acc: 71.88%] [G loss: 2.801761]\n",
      "epoch:37 step:29436[D loss: 0.158392, acc: 97.66%, op_acc: 73.44%] [G loss: 3.491261]\n",
      "epoch:37 step:29437[D loss: 0.119491, acc: 97.66%, op_acc: 78.91%] [G loss: 2.877880]\n",
      "epoch:37 step:29438[D loss: 0.158188, acc: 94.53%, op_acc: 75.78%] [G loss: 2.609627]\n",
      "epoch:37 step:29439[D loss: 0.184069, acc: 93.75%, op_acc: 71.09%] [G loss: 2.990295]\n",
      "epoch:37 step:29440[D loss: 0.192945, acc: 92.19%, op_acc: 71.09%] [G loss: 2.879995]\n",
      "epoch:37 step:29441[D loss: 0.153555, acc: 96.09%, op_acc: 69.53%] [G loss: 2.532345]\n",
      "epoch:37 step:29442[D loss: 0.167637, acc: 94.53%, op_acc: 68.75%] [G loss: 2.805762]\n",
      "epoch:37 step:29443[D loss: 0.224500, acc: 88.28%, op_acc: 70.31%] [G loss: 2.625205]\n",
      "epoch:37 step:29444[D loss: 0.218887, acc: 91.41%, op_acc: 67.97%] [G loss: 3.068980]\n",
      "epoch:37 step:29445[D loss: 0.225477, acc: 90.62%, op_acc: 64.06%] [G loss: 2.596836]\n",
      "epoch:37 step:29446[D loss: 0.193210, acc: 92.19%, op_acc: 64.06%] [G loss: 0.891958]\n",
      "epoch:37 step:29447[D loss: 0.240247, acc: 87.50%, op_acc: 57.03%] [G loss: 2.861318]\n",
      "epoch:37 step:29448[D loss: 0.233421, acc: 86.72%, op_acc: 64.06%] [G loss: 1.816597]\n",
      "epoch:37 step:29449[D loss: 0.357785, acc: 78.91%, op_acc: 49.22%] [G loss: 3.219833]\n",
      "epoch:37 step:29450[D loss: 0.245787, acc: 85.16%, op_acc: 61.72%] [G loss: 3.111335]\n",
      "epoch:37 step:29451[D loss: 0.272200, acc: 85.94%, op_acc: 63.28%] [G loss: 3.543859]\n",
      "epoch:37 step:29452[D loss: 0.191226, acc: 92.19%, op_acc: 77.34%] [G loss: 2.565972]\n",
      "epoch:37 step:29453[D loss: 0.260898, acc: 86.72%, op_acc: 63.28%] [G loss: 2.892168]\n",
      "epoch:37 step:29454[D loss: 0.202049, acc: 93.75%, op_acc: 75.00%] [G loss: 1.189268]\n",
      "epoch:37 step:29455[D loss: 0.292166, acc: 78.91%, op_acc: 60.16%] [G loss: 2.424376]\n",
      "epoch:37 step:29456[D loss: 0.264177, acc: 84.38%, op_acc: 50.00%] [G loss: 1.347781]\n",
      "epoch:37 step:29457[D loss: 0.344258, acc: 79.69%, op_acc: 45.31%] [G loss: 3.051439]\n",
      "epoch:37 step:29458[D loss: 0.226586, acc: 88.28%, op_acc: 73.44%] [G loss: 3.296218]\n",
      "epoch:37 step:29459[D loss: 0.290453, acc: 81.25%, op_acc: 61.72%] [G loss: 3.184842]\n",
      "epoch:37 step:29460[D loss: 0.285345, acc: 85.94%, op_acc: 62.50%] [G loss: 3.042814]\n",
      "epoch:37 step:29461[D loss: 0.444164, acc: 60.94%, op_acc: 64.84%] [G loss: 1.298741]\n",
      "epoch:37 step:29462[D loss: 0.351467, acc: 75.78%, op_acc: 48.44%] [G loss: 2.134854]\n",
      "epoch:37 step:29463[D loss: 0.198653, acc: 93.75%, op_acc: 64.06%] [G loss: 2.102787]\n",
      "epoch:37 step:29464[D loss: 0.232139, acc: 89.06%, op_acc: 66.41%] [G loss: 2.064247]\n",
      "epoch:37 step:29465[D loss: 0.209885, acc: 91.41%, op_acc: 65.62%] [G loss: 1.954569]\n",
      "epoch:37 step:29466[D loss: 0.250448, acc: 87.50%, op_acc: 68.75%] [G loss: 2.310727]\n",
      "epoch:37 step:29467[D loss: 0.210833, acc: 89.84%, op_acc: 80.47%] [G loss: 1.533595]\n",
      "epoch:37 step:29468[D loss: 0.340119, acc: 75.00%, op_acc: 49.22%] [G loss: 1.067438]\n",
      "epoch:37 step:29469[D loss: 0.221897, acc: 89.06%, op_acc: 64.84%] [G loss: 1.628865]\n",
      "epoch:37 step:29470[D loss: 0.364589, acc: 67.97%, op_acc: 53.12%] [G loss: 2.127428]\n",
      "epoch:37 step:29471[D loss: 0.206343, acc: 91.41%, op_acc: 67.97%] [G loss: 2.128226]\n",
      "epoch:37 step:29472[D loss: 0.302037, acc: 82.81%, op_acc: 59.38%] [G loss: 2.130629]\n",
      "epoch:37 step:29473[D loss: 0.209125, acc: 89.84%, op_acc: 69.53%] [G loss: 1.641893]\n",
      "epoch:37 step:29474[D loss: 0.213356, acc: 92.19%, op_acc: 67.19%] [G loss: 1.679763]\n",
      "epoch:37 step:29475[D loss: 0.260315, acc: 88.28%, op_acc: 62.50%] [G loss: 1.889763]\n",
      "epoch:37 step:29476[D loss: 0.206363, acc: 87.50%, op_acc: 61.72%] [G loss: 0.629521]\n",
      "epoch:37 step:29477[D loss: 0.320020, acc: 79.69%, op_acc: 53.91%] [G loss: 1.908315]\n",
      "epoch:37 step:29478[D loss: 0.297742, acc: 82.81%, op_acc: 49.22%] [G loss: 1.444141]\n",
      "epoch:37 step:29479[D loss: 0.369895, acc: 72.66%, op_acc: 48.44%] [G loss: 1.635586]\n",
      "epoch:37 step:29480[D loss: 0.223223, acc: 86.72%, op_acc: 57.03%] [G loss: 1.860804]\n",
      "epoch:37 step:29481[D loss: 0.238473, acc: 87.50%, op_acc: 66.41%] [G loss: 2.379062]\n",
      "epoch:37 step:29482[D loss: 0.282101, acc: 83.59%, op_acc: 66.41%] [G loss: 1.008056]\n",
      "epoch:37 step:29483[D loss: 0.378179, acc: 74.22%, op_acc: 44.53%] [G loss: 1.846173]\n",
      "epoch:37 step:29484[D loss: 0.257568, acc: 85.94%, op_acc: 57.03%] [G loss: 1.996029]\n",
      "epoch:37 step:29485[D loss: 0.293928, acc: 78.91%, op_acc: 64.06%] [G loss: 1.685866]\n",
      "epoch:37 step:29486[D loss: 0.241569, acc: 85.94%, op_acc: 62.50%] [G loss: 1.491237]\n",
      "epoch:37 step:29487[D loss: 0.281962, acc: 89.06%, op_acc: 57.03%] [G loss: 1.336505]\n",
      "epoch:37 step:29488[D loss: 0.240545, acc: 83.59%, op_acc: 60.16%] [G loss: 1.733185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29489[D loss: 0.231198, acc: 91.41%, op_acc: 59.38%] [G loss: 1.372419]\n",
      "epoch:37 step:29490[D loss: 0.297089, acc: 80.47%, op_acc: 67.97%] [G loss: 1.964294]\n",
      "epoch:37 step:29491[D loss: 0.277992, acc: 82.81%, op_acc: 61.72%] [G loss: 1.600280]\n",
      "epoch:37 step:29492[D loss: 0.269162, acc: 85.94%, op_acc: 60.16%] [G loss: 1.391687]\n",
      "epoch:37 step:29493[D loss: 0.163116, acc: 92.97%, op_acc: 68.75%] [G loss: 2.213315]\n",
      "epoch:37 step:29494[D loss: 0.234254, acc: 91.41%, op_acc: 65.62%] [G loss: 0.454495]\n",
      "epoch:37 step:29495[D loss: 0.268405, acc: 84.38%, op_acc: 47.66%] [G loss: 2.216467]\n",
      "epoch:37 step:29496[D loss: 0.299707, acc: 85.16%, op_acc: 56.25%] [G loss: 2.654476]\n",
      "epoch:37 step:29497[D loss: 0.249571, acc: 87.50%, op_acc: 60.16%] [G loss: 2.762174]\n",
      "epoch:37 step:29498[D loss: 0.180729, acc: 93.75%, op_acc: 70.31%] [G loss: 2.206101]\n",
      "epoch:37 step:29499[D loss: 0.240347, acc: 88.28%, op_acc: 64.06%] [G loss: 1.105079]\n",
      "epoch:37 step:29500[D loss: 0.370040, acc: 67.97%, op_acc: 57.03%] [G loss: 2.250171]\n",
      "epoch:37 step:29501[D loss: 0.316029, acc: 77.34%, op_acc: 49.22%] [G loss: 2.211308]\n",
      "epoch:37 step:29502[D loss: 0.178937, acc: 95.31%, op_acc: 73.44%] [G loss: 1.581684]\n",
      "epoch:37 step:29503[D loss: 0.225045, acc: 88.28%, op_acc: 68.75%] [G loss: 1.739815]\n",
      "epoch:37 step:29504[D loss: 0.282567, acc: 78.12%, op_acc: 68.75%] [G loss: 1.558752]\n",
      "epoch:37 step:29505[D loss: 0.268228, acc: 85.94%, op_acc: 58.59%] [G loss: 1.352804]\n",
      "epoch:37 step:29506[D loss: 0.241345, acc: 82.81%, op_acc: 67.97%] [G loss: 1.435649]\n",
      "epoch:37 step:29507[D loss: 0.209612, acc: 93.75%, op_acc: 57.81%] [G loss: 1.837068]\n",
      "epoch:37 step:29508[D loss: 0.270882, acc: 84.38%, op_acc: 74.22%] [G loss: 1.385042]\n",
      "epoch:37 step:29509[D loss: 0.326505, acc: 78.91%, op_acc: 52.34%] [G loss: 1.918621]\n",
      "epoch:37 step:29510[D loss: 0.409262, acc: 67.19%, op_acc: 58.59%] [G loss: 2.168351]\n",
      "epoch:37 step:29511[D loss: 0.259965, acc: 85.94%, op_acc: 59.38%] [G loss: 1.628261]\n",
      "epoch:37 step:29512[D loss: 0.305739, acc: 86.72%, op_acc: 60.94%] [G loss: 1.281313]\n",
      "epoch:37 step:29513[D loss: 0.319295, acc: 80.47%, op_acc: 57.03%] [G loss: 2.190250]\n",
      "epoch:37 step:29514[D loss: 0.278967, acc: 87.50%, op_acc: 56.25%] [G loss: 1.241471]\n",
      "epoch:37 step:29515[D loss: 0.237231, acc: 83.59%, op_acc: 56.25%] [G loss: 0.748659]\n",
      "epoch:37 step:29516[D loss: 0.243526, acc: 87.50%, op_acc: 57.03%] [G loss: 1.437036]\n",
      "epoch:37 step:29517[D loss: 0.470841, acc: 59.38%, op_acc: 34.38%] [G loss: 2.235915]\n",
      "epoch:37 step:29518[D loss: 0.463625, acc: 64.84%, op_acc: 52.34%] [G loss: 1.499155]\n",
      "epoch:37 step:29519[D loss: 0.505931, acc: 55.47%, op_acc: 42.97%] [G loss: 1.790013]\n",
      "epoch:37 step:29520[D loss: 0.276518, acc: 78.91%, op_acc: 64.84%] [G loss: 1.365345]\n",
      "epoch:37 step:29521[D loss: 0.291004, acc: 80.47%, op_acc: 55.47%] [G loss: 1.569076]\n",
      "epoch:37 step:29522[D loss: 0.334952, acc: 76.56%, op_acc: 57.03%] [G loss: 1.411951]\n",
      "epoch:37 step:29523[D loss: 0.341443, acc: 71.09%, op_acc: 56.25%] [G loss: 1.032382]\n",
      "epoch:37 step:29524[D loss: 0.397131, acc: 68.75%, op_acc: 42.19%] [G loss: 1.309273]\n",
      "epoch:37 step:29525[D loss: 0.296168, acc: 82.03%, op_acc: 58.59%] [G loss: 1.257773]\n",
      "epoch:37 step:29526[D loss: 0.243234, acc: 85.16%, op_acc: 63.28%] [G loss: 1.436138]\n",
      "epoch:37 step:29527[D loss: 0.242184, acc: 88.28%, op_acc: 59.38%] [G loss: 1.108818]\n",
      "epoch:37 step:29528[D loss: 0.264107, acc: 84.38%, op_acc: 58.59%] [G loss: 0.906922]\n",
      "epoch:37 step:29529[D loss: 0.205442, acc: 90.62%, op_acc: 64.84%] [G loss: 0.983542]\n",
      "epoch:37 step:29530[D loss: 0.197416, acc: 93.75%, op_acc: 66.41%] [G loss: 1.408104]\n",
      "epoch:37 step:29531[D loss: 0.226872, acc: 85.94%, op_acc: 63.28%] [G loss: 1.064073]\n",
      "epoch:37 step:29532[D loss: 0.264271, acc: 82.03%, op_acc: 55.47%] [G loss: 2.497516]\n",
      "epoch:37 step:29533[D loss: 0.252830, acc: 81.25%, op_acc: 58.59%] [G loss: 1.596085]\n",
      "epoch:37 step:29534[D loss: 0.202236, acc: 89.84%, op_acc: 68.75%] [G loss: 0.638153]\n",
      "epoch:37 step:29535[D loss: 0.383739, acc: 68.75%, op_acc: 51.56%] [G loss: 1.629181]\n",
      "epoch:37 step:29536[D loss: 0.279364, acc: 82.03%, op_acc: 52.34%] [G loss: 1.253394]\n",
      "epoch:37 step:29537[D loss: 0.224161, acc: 88.28%, op_acc: 63.28%] [G loss: 1.027203]\n",
      "epoch:37 step:29538[D loss: 0.243430, acc: 85.16%, op_acc: 60.16%] [G loss: 1.096169]\n",
      "epoch:37 step:29539[D loss: 0.362745, acc: 75.78%, op_acc: 50.78%] [G loss: 1.337099]\n",
      "epoch:37 step:29540[D loss: 0.344196, acc: 73.44%, op_acc: 57.81%] [G loss: 1.309754]\n",
      "epoch:37 step:29541[D loss: 0.186243, acc: 92.97%, op_acc: 67.19%] [G loss: 1.382363]\n",
      "epoch:37 step:29542[D loss: 0.364093, acc: 75.78%, op_acc: 55.47%] [G loss: 1.057935]\n",
      "epoch:37 step:29543[D loss: 0.330091, acc: 78.12%, op_acc: 50.00%] [G loss: 1.114774]\n",
      "epoch:37 step:29544[D loss: 0.275954, acc: 85.16%, op_acc: 61.72%] [G loss: 1.317577]\n",
      "epoch:37 step:29545[D loss: 0.216094, acc: 94.53%, op_acc: 64.06%] [G loss: 0.999006]\n",
      "epoch:37 step:29546[D loss: 0.260570, acc: 84.38%, op_acc: 64.84%] [G loss: 1.781947]\n",
      "epoch:37 step:29547[D loss: 0.258144, acc: 84.38%, op_acc: 59.38%] [G loss: 2.425811]\n",
      "epoch:37 step:29548[D loss: 0.271498, acc: 83.59%, op_acc: 61.72%] [G loss: 1.049828]\n",
      "epoch:37 step:29549[D loss: 0.327039, acc: 73.44%, op_acc: 57.03%] [G loss: 1.032317]\n",
      "epoch:37 step:29550[D loss: 0.180631, acc: 90.62%, op_acc: 72.66%] [G loss: 2.139356]\n",
      "epoch:37 step:29551[D loss: 0.275148, acc: 81.25%, op_acc: 58.59%] [G loss: 1.140779]\n",
      "epoch:37 step:29552[D loss: 0.370865, acc: 68.75%, op_acc: 45.31%] [G loss: 2.100340]\n",
      "epoch:37 step:29553[D loss: 0.506001, acc: 54.69%, op_acc: 40.62%] [G loss: 1.003072]\n",
      "epoch:37 step:29554[D loss: 0.372557, acc: 75.00%, op_acc: 46.09%] [G loss: 1.468264]\n",
      "epoch:37 step:29555[D loss: 0.348326, acc: 75.78%, op_acc: 58.59%] [G loss: 1.219992]\n",
      "epoch:37 step:29556[D loss: 0.384407, acc: 71.88%, op_acc: 52.34%] [G loss: 1.515986]\n",
      "epoch:37 step:29557[D loss: 0.462876, acc: 58.59%, op_acc: 41.41%] [G loss: 2.080714]\n",
      "epoch:37 step:29558[D loss: 0.369345, acc: 71.88%, op_acc: 42.97%] [G loss: 1.608611]\n",
      "epoch:37 step:29559[D loss: 0.284543, acc: 77.34%, op_acc: 53.12%] [G loss: 1.498486]\n",
      "epoch:37 step:29560[D loss: 0.414489, acc: 65.62%, op_acc: 47.66%] [G loss: 2.095789]\n",
      "epoch:37 step:29561[D loss: 0.305303, acc: 77.34%, op_acc: 53.91%] [G loss: 1.042053]\n",
      "epoch:37 step:29562[D loss: 0.451726, acc: 64.84%, op_acc: 38.28%] [G loss: 0.890194]\n",
      "epoch:37 step:29563[D loss: 0.411956, acc: 67.19%, op_acc: 37.50%] [G loss: 1.920089]\n",
      "epoch:37 step:29564[D loss: 0.377877, acc: 70.31%, op_acc: 53.12%] [G loss: 1.263790]\n",
      "epoch:37 step:29565[D loss: 0.271545, acc: 82.81%, op_acc: 53.91%] [G loss: 1.316923]\n",
      "epoch:37 step:29566[D loss: 0.326128, acc: 79.69%, op_acc: 45.31%] [G loss: 1.073536]\n",
      "epoch:37 step:29567[D loss: 0.345013, acc: 73.44%, op_acc: 56.25%] [G loss: 2.000500]\n",
      "epoch:37 step:29568[D loss: 0.291813, acc: 79.69%, op_acc: 64.84%] [G loss: 1.188816]\n",
      "epoch:37 step:29569[D loss: 0.294713, acc: 83.59%, op_acc: 53.91%] [G loss: 0.949066]\n",
      "epoch:37 step:29570[D loss: 0.308827, acc: 82.81%, op_acc: 53.12%] [G loss: 1.298669]\n",
      "epoch:37 step:29571[D loss: 0.391542, acc: 64.06%, op_acc: 46.09%] [G loss: 1.120515]\n",
      "epoch:37 step:29572[D loss: 0.233630, acc: 89.06%, op_acc: 51.56%] [G loss: 1.357625]\n",
      "epoch:37 step:29573[D loss: 0.351462, acc: 74.22%, op_acc: 58.59%] [G loss: 1.546403]\n",
      "epoch:37 step:29574[D loss: 0.303825, acc: 84.38%, op_acc: 55.47%] [G loss: 1.603608]\n",
      "epoch:37 step:29575[D loss: 0.246169, acc: 87.50%, op_acc: 64.84%] [G loss: 1.543661]\n",
      "epoch:37 step:29576[D loss: 0.274268, acc: 79.69%, op_acc: 53.91%] [G loss: 1.235582]\n",
      "epoch:37 step:29577[D loss: 0.299459, acc: 79.69%, op_acc: 46.88%] [G loss: 1.663023]\n",
      "epoch:37 step:29578[D loss: 0.386637, acc: 71.09%, op_acc: 53.12%] [G loss: 1.398156]\n",
      "epoch:37 step:29579[D loss: 0.227698, acc: 90.62%, op_acc: 70.31%] [G loss: 1.085001]\n",
      "epoch:37 step:29580[D loss: 0.434683, acc: 62.50%, op_acc: 40.62%] [G loss: 1.668545]\n",
      "epoch:37 step:29581[D loss: 0.303656, acc: 76.56%, op_acc: 51.56%] [G loss: 1.236009]\n",
      "epoch:37 step:29582[D loss: 0.386873, acc: 72.66%, op_acc: 49.22%] [G loss: 1.523537]\n",
      "epoch:37 step:29583[D loss: 0.340890, acc: 75.00%, op_acc: 53.91%] [G loss: 2.098053]\n",
      "epoch:37 step:29584[D loss: 0.330333, acc: 75.78%, op_acc: 50.00%] [G loss: 1.291325]\n",
      "epoch:37 step:29585[D loss: 0.358587, acc: 75.78%, op_acc: 51.56%] [G loss: 1.118406]\n",
      "epoch:37 step:29586[D loss: 0.366708, acc: 67.19%, op_acc: 52.34%] [G loss: 1.311200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:29587[D loss: 0.378821, acc: 72.66%, op_acc: 51.56%] [G loss: 1.532157]\n",
      "epoch:37 step:29588[D loss: 0.305833, acc: 82.81%, op_acc: 48.44%] [G loss: 1.862934]\n",
      "epoch:37 step:29589[D loss: 0.485195, acc: 59.38%, op_acc: 51.56%] [G loss: 1.691711]\n",
      "epoch:37 step:29590[D loss: 0.381513, acc: 72.66%, op_acc: 48.44%] [G loss: 1.266531]\n",
      "epoch:37 step:29591[D loss: 0.304515, acc: 81.25%, op_acc: 56.25%] [G loss: 0.824668]\n",
      "epoch:37 step:29592[D loss: 0.297752, acc: 80.47%, op_acc: 55.47%] [G loss: 1.223182]\n",
      "epoch:37 step:29593[D loss: 0.338227, acc: 74.22%, op_acc: 56.25%] [G loss: 1.236471]\n",
      "epoch:37 step:29594[D loss: 0.297289, acc: 77.34%, op_acc: 55.47%] [G loss: 1.269881]\n",
      "epoch:37 step:29595[D loss: 0.265834, acc: 87.50%, op_acc: 58.59%] [G loss: 1.213246]\n",
      "epoch:37 step:29596[D loss: 0.309836, acc: 78.91%, op_acc: 56.25%] [G loss: 1.045235]\n",
      "epoch:37 step:29597[D loss: 0.264865, acc: 84.38%, op_acc: 59.38%] [G loss: 0.946785]\n",
      "epoch:37 step:29598[D loss: 0.255405, acc: 89.06%, op_acc: 56.25%] [G loss: 2.050932]\n",
      "epoch:37 step:29599[D loss: 0.341504, acc: 75.78%, op_acc: 57.03%] [G loss: 1.331056]\n",
      "epoch:37 step:29600[D loss: 0.331517, acc: 77.34%, op_acc: 51.56%] [G loss: 1.291716]\n",
      "epoch:37 step:29601[D loss: 0.286968, acc: 78.91%, op_acc: 55.47%] [G loss: 1.152368]\n",
      "epoch:37 step:29602[D loss: 0.454488, acc: 66.41%, op_acc: 42.19%] [G loss: 2.125270]\n",
      "epoch:37 step:29603[D loss: 0.413435, acc: 67.97%, op_acc: 48.44%] [G loss: 1.775203]\n",
      "epoch:37 step:29604[D loss: 0.547976, acc: 47.66%, op_acc: 46.09%] [G loss: 1.213539]\n",
      "epoch:37 step:29605[D loss: 0.325349, acc: 84.38%, op_acc: 55.47%] [G loss: 1.847437]\n",
      "epoch:37 step:29606[D loss: 0.312376, acc: 78.12%, op_acc: 56.25%] [G loss: 0.948492]\n",
      "epoch:37 step:29607[D loss: 0.357194, acc: 71.09%, op_acc: 64.06%] [G loss: 1.453387]\n",
      "epoch:37 step:29608[D loss: 0.307822, acc: 80.47%, op_acc: 59.38%] [G loss: 0.464818]\n",
      "epoch:37 step:29609[D loss: 0.402013, acc: 68.75%, op_acc: 48.44%] [G loss: 1.868204]\n",
      "epoch:37 step:29610[D loss: 0.341421, acc: 67.19%, op_acc: 56.25%] [G loss: 0.749167]\n",
      "epoch:37 step:29611[D loss: 0.380573, acc: 73.44%, op_acc: 51.56%] [G loss: 0.522291]\n",
      "epoch:37 step:29612[D loss: 0.314265, acc: 78.91%, op_acc: 62.50%] [G loss: 0.934452]\n",
      "epoch:37 step:29613[D loss: 0.322541, acc: 78.12%, op_acc: 61.72%] [G loss: 0.900850]\n",
      "epoch:37 step:29614[D loss: 0.277978, acc: 80.47%, op_acc: 55.47%] [G loss: 0.813291]\n",
      "epoch:37 step:29615[D loss: 0.290456, acc: 78.91%, op_acc: 51.56%] [G loss: 0.845781]\n",
      "epoch:37 step:29616[D loss: 0.574080, acc: 49.22%, op_acc: 42.97%] [G loss: 0.695879]\n",
      "epoch:37 step:29617[D loss: 0.518970, acc: 57.81%, op_acc: 42.97%] [G loss: 1.587625]\n",
      "epoch:37 step:29618[D loss: 0.496308, acc: 55.47%, op_acc: 46.09%] [G loss: 0.787899]\n",
      "epoch:37 step:29619[D loss: 0.313451, acc: 76.56%, op_acc: 53.91%] [G loss: 1.120527]\n",
      "epoch:37 step:29620[D loss: 0.236995, acc: 86.72%, op_acc: 65.62%] [G loss: 1.092004]\n",
      "epoch:37 step:29621[D loss: 0.415486, acc: 67.97%, op_acc: 54.69%] [G loss: 0.622463]\n",
      "epoch:37 step:29622[D loss: 0.415065, acc: 67.97%, op_acc: 52.34%] [G loss: 0.975180]\n",
      "epoch:37 step:29623[D loss: 0.304994, acc: 78.12%, op_acc: 46.09%] [G loss: 0.787843]\n",
      "epoch:37 step:29624[D loss: 0.296847, acc: 82.81%, op_acc: 56.25%] [G loss: 1.222741]\n",
      "epoch:37 step:29625[D loss: 0.318712, acc: 77.34%, op_acc: 52.34%] [G loss: 0.988834]\n",
      "epoch:37 step:29626[D loss: 0.254300, acc: 87.50%, op_acc: 54.69%] [G loss: 1.263176]\n",
      "epoch:37 step:29627[D loss: 0.284443, acc: 85.94%, op_acc: 61.72%] [G loss: 1.043678]\n",
      "epoch:37 step:29628[D loss: 0.288891, acc: 79.69%, op_acc: 62.50%] [G loss: 1.307920]\n",
      "epoch:37 step:29629[D loss: 0.221477, acc: 87.50%, op_acc: 64.06%] [G loss: 1.230270]\n",
      "epoch:37 step:29630[D loss: 0.250480, acc: 85.16%, op_acc: 64.84%] [G loss: 1.245452]\n",
      "epoch:37 step:29631[D loss: 0.263656, acc: 84.38%, op_acc: 51.56%] [G loss: 1.502415]\n",
      "epoch:37 step:29632[D loss: 0.194964, acc: 92.19%, op_acc: 64.06%] [G loss: 1.789059]\n",
      "epoch:37 step:29633[D loss: 0.221636, acc: 87.50%, op_acc: 67.19%] [G loss: 1.951702]\n",
      "epoch:37 step:29634[D loss: 0.182938, acc: 91.41%, op_acc: 72.66%] [G loss: 1.768640]\n",
      "epoch:37 step:29635[D loss: 0.293406, acc: 82.03%, op_acc: 52.34%] [G loss: 1.851699]\n",
      "epoch:37 step:29636[D loss: 0.202190, acc: 88.28%, op_acc: 63.28%] [G loss: 2.039861]\n",
      "epoch:37 step:29637[D loss: 0.309871, acc: 80.47%, op_acc: 62.50%] [G loss: 1.715636]\n",
      "epoch:37 step:29638[D loss: 0.300601, acc: 82.03%, op_acc: 49.22%] [G loss: 1.885752]\n",
      "epoch:37 step:29639[D loss: 0.377546, acc: 69.53%, op_acc: 50.00%] [G loss: 1.966560]\n",
      "epoch:37 step:29640[D loss: 0.360026, acc: 75.78%, op_acc: 47.66%] [G loss: 0.990606]\n",
      "epoch:37 step:29641[D loss: 0.411516, acc: 66.41%, op_acc: 44.53%] [G loss: 1.916394]\n",
      "epoch:37 step:29642[D loss: 0.308833, acc: 70.31%, op_acc: 51.56%] [G loss: 2.226514]\n",
      "epoch:37 step:29643[D loss: 0.420009, acc: 58.59%, op_acc: 44.53%] [G loss: 2.000098]\n",
      "epoch:37 step:29644[D loss: 0.388946, acc: 67.97%, op_acc: 54.69%] [G loss: 2.052110]\n",
      "epoch:37 step:29645[D loss: 0.319349, acc: 83.59%, op_acc: 51.56%] [G loss: 1.802456]\n",
      "epoch:37 step:29646[D loss: 0.319000, acc: 77.34%, op_acc: 64.06%] [G loss: 2.091121]\n",
      "epoch:37 step:29647[D loss: 0.281660, acc: 81.25%, op_acc: 57.81%] [G loss: 1.540401]\n",
      "epoch:37 step:29648[D loss: 0.299551, acc: 86.72%, op_acc: 52.34%] [G loss: 1.771815]\n",
      "epoch:37 step:29649[D loss: 0.290343, acc: 82.03%, op_acc: 64.06%] [G loss: 1.487749]\n",
      "epoch:37 step:29650[D loss: 0.278576, acc: 82.81%, op_acc: 61.72%] [G loss: 0.703831]\n",
      "epoch:37 step:29651[D loss: 0.264578, acc: 80.47%, op_acc: 53.91%] [G loss: 1.455647]\n",
      "epoch:37 step:29652[D loss: 0.246654, acc: 85.16%, op_acc: 55.47%] [G loss: 1.347822]\n",
      "epoch:37 step:29653[D loss: 0.282740, acc: 81.25%, op_acc: 62.50%] [G loss: 1.735671]\n",
      "epoch:37 step:29654[D loss: 0.241898, acc: 89.06%, op_acc: 57.81%] [G loss: 1.187904]\n",
      "epoch:37 step:29655[D loss: 0.276064, acc: 82.03%, op_acc: 53.91%] [G loss: 1.314909]\n",
      "epoch:37 step:29656[D loss: 0.339399, acc: 73.44%, op_acc: 50.78%] [G loss: 2.439217]\n",
      "epoch:37 step:29657[D loss: 0.333773, acc: 77.34%, op_acc: 53.91%] [G loss: 1.426031]\n",
      "epoch:37 step:29658[D loss: 0.224595, acc: 87.50%, op_acc: 67.19%] [G loss: 1.781263]\n",
      "epoch:37 step:29659[D loss: 0.384862, acc: 67.97%, op_acc: 58.59%] [G loss: 1.025081]\n",
      "epoch:37 step:29660[D loss: 0.322137, acc: 75.78%, op_acc: 53.91%] [G loss: 2.061047]\n",
      "epoch:37 step:29661[D loss: 0.392884, acc: 59.38%, op_acc: 50.78%] [G loss: 1.680441]\n",
      "epoch:37 step:29662[D loss: 0.285154, acc: 81.25%, op_acc: 53.91%] [G loss: 1.361219]\n",
      "epoch:37 step:29663[D loss: 0.371787, acc: 71.88%, op_acc: 56.25%] [G loss: 1.484361]\n",
      "epoch:37 step:29664[D loss: 0.224260, acc: 89.84%, op_acc: 57.03%] [G loss: 1.010630]\n",
      "epoch:37 step:29665[D loss: 0.301072, acc: 78.12%, op_acc: 52.34%] [G loss: 1.150357]\n",
      "epoch:37 step:29666[D loss: 0.225426, acc: 85.16%, op_acc: 63.28%] [G loss: 1.033092]\n",
      "epoch:37 step:29667[D loss: 0.388053, acc: 72.66%, op_acc: 45.31%] [G loss: 1.492534]\n",
      "epoch:37 step:29668[D loss: 0.344138, acc: 75.78%, op_acc: 55.47%] [G loss: 0.882451]\n",
      "epoch:37 step:29669[D loss: 0.269259, acc: 84.38%, op_acc: 55.47%] [G loss: 1.299784]\n",
      "epoch:37 step:29670[D loss: 0.285654, acc: 84.38%, op_acc: 58.59%] [G loss: 1.019862]\n",
      "epoch:37 step:29671[D loss: 0.237107, acc: 85.94%, op_acc: 60.16%] [G loss: 1.190898]\n",
      "epoch:37 step:29672[D loss: 0.321809, acc: 80.47%, op_acc: 61.72%] [G loss: 0.815019]\n",
      "epoch:37 step:29673[D loss: 0.321741, acc: 77.34%, op_acc: 61.72%] [G loss: 1.051990]\n",
      "epoch:37 step:29674[D loss: 0.372772, acc: 71.88%, op_acc: 44.53%] [G loss: 1.061725]\n",
      "epoch:37 step:29675[D loss: 0.269957, acc: 84.38%, op_acc: 60.94%] [G loss: 1.030820]\n",
      "epoch:37 step:29676[D loss: 0.312250, acc: 81.25%, op_acc: 57.03%] [G loss: 1.295615]\n",
      "epoch:37 step:29677[D loss: 0.301744, acc: 80.47%, op_acc: 53.91%] [G loss: 1.073989]\n",
      "epoch:37 step:29678[D loss: 0.301099, acc: 78.91%, op_acc: 60.16%] [G loss: 0.960831]\n",
      "epoch:38 step:29679[D loss: 0.246311, acc: 85.16%, op_acc: 64.84%] [G loss: 0.983493]\n",
      "epoch:38 step:29680[D loss: 0.222892, acc: 88.28%, op_acc: 64.06%] [G loss: 0.703199]\n",
      "epoch:38 step:29681[D loss: 0.300795, acc: 78.12%, op_acc: 60.94%] [G loss: 1.382064]\n",
      "epoch:38 step:29682[D loss: 0.226888, acc: 87.50%, op_acc: 64.06%] [G loss: 0.681381]\n",
      "epoch:38 step:29683[D loss: 0.346553, acc: 72.66%, op_acc: 52.34%] [G loss: 0.696460]\n",
      "epoch:38 step:29684[D loss: 0.283305, acc: 82.81%, op_acc: 64.84%] [G loss: 1.214852]\n",
      "epoch:38 step:29685[D loss: 0.346288, acc: 70.31%, op_acc: 55.47%] [G loss: 0.604987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29686[D loss: 0.298089, acc: 82.03%, op_acc: 53.12%] [G loss: 0.824446]\n",
      "epoch:38 step:29687[D loss: 0.224952, acc: 89.06%, op_acc: 57.81%] [G loss: 1.352082]\n",
      "epoch:38 step:29688[D loss: 0.194077, acc: 92.19%, op_acc: 73.44%] [G loss: 0.983425]\n",
      "epoch:38 step:29689[D loss: 0.316712, acc: 77.34%, op_acc: 48.44%] [G loss: 1.618185]\n",
      "epoch:38 step:29690[D loss: 0.244637, acc: 85.94%, op_acc: 61.72%] [G loss: 1.137424]\n",
      "epoch:38 step:29691[D loss: 0.247778, acc: 85.94%, op_acc: 53.91%] [G loss: 1.309700]\n",
      "epoch:38 step:29692[D loss: 0.311255, acc: 82.03%, op_acc: 46.88%] [G loss: 1.640986]\n",
      "epoch:38 step:29693[D loss: 0.257853, acc: 85.94%, op_acc: 63.28%] [G loss: 1.526706]\n",
      "epoch:38 step:29694[D loss: 0.257441, acc: 85.16%, op_acc: 62.50%] [G loss: 1.371935]\n",
      "epoch:38 step:29695[D loss: 0.303262, acc: 78.12%, op_acc: 61.72%] [G loss: 1.284689]\n",
      "epoch:38 step:29696[D loss: 0.296208, acc: 82.81%, op_acc: 58.59%] [G loss: 1.583012]\n",
      "epoch:38 step:29697[D loss: 0.215046, acc: 89.84%, op_acc: 66.41%] [G loss: 1.357828]\n",
      "epoch:38 step:29698[D loss: 0.224028, acc: 85.16%, op_acc: 67.97%] [G loss: 1.422122]\n",
      "epoch:38 step:29699[D loss: 0.259026, acc: 85.16%, op_acc: 62.50%] [G loss: 1.193260]\n",
      "epoch:38 step:29700[D loss: 0.246909, acc: 85.94%, op_acc: 69.53%] [G loss: 1.580758]\n",
      "epoch:38 step:29701[D loss: 0.194388, acc: 94.53%, op_acc: 70.31%] [G loss: 1.493155]\n",
      "epoch:38 step:29702[D loss: 0.204840, acc: 94.53%, op_acc: 67.19%] [G loss: 1.665766]\n",
      "epoch:38 step:29703[D loss: 0.464225, acc: 63.28%, op_acc: 39.06%] [G loss: 1.160458]\n",
      "epoch:38 step:29704[D loss: 0.221176, acc: 87.50%, op_acc: 59.38%] [G loss: 1.667110]\n",
      "epoch:38 step:29705[D loss: 0.250338, acc: 85.94%, op_acc: 64.06%] [G loss: 1.398868]\n",
      "epoch:38 step:29706[D loss: 0.349637, acc: 71.09%, op_acc: 66.41%] [G loss: 0.839895]\n",
      "epoch:38 step:29707[D loss: 0.315955, acc: 79.69%, op_acc: 56.25%] [G loss: 1.044245]\n",
      "epoch:38 step:29708[D loss: 0.381399, acc: 70.31%, op_acc: 52.34%] [G loss: 0.920692]\n",
      "epoch:38 step:29709[D loss: 0.414047, acc: 71.09%, op_acc: 47.66%] [G loss: 1.172080]\n",
      "epoch:38 step:29710[D loss: 0.378851, acc: 73.44%, op_acc: 50.78%] [G loss: 1.549700]\n",
      "epoch:38 step:29711[D loss: 0.284813, acc: 79.69%, op_acc: 54.69%] [G loss: 1.024843]\n",
      "epoch:38 step:29712[D loss: 0.258982, acc: 85.16%, op_acc: 56.25%] [G loss: 0.928719]\n",
      "epoch:38 step:29713[D loss: 0.276740, acc: 82.81%, op_acc: 67.19%] [G loss: 0.603089]\n",
      "epoch:38 step:29714[D loss: 0.326188, acc: 76.56%, op_acc: 57.03%] [G loss: 0.479512]\n",
      "epoch:38 step:29715[D loss: 0.203026, acc: 89.84%, op_acc: 69.53%] [G loss: 0.607217]\n",
      "epoch:38 step:29716[D loss: 0.317236, acc: 79.69%, op_acc: 50.78%] [G loss: 0.615344]\n",
      "epoch:38 step:29717[D loss: 0.217235, acc: 87.50%, op_acc: 63.28%] [G loss: 0.365139]\n",
      "epoch:38 step:29718[D loss: 0.229367, acc: 87.50%, op_acc: 60.16%] [G loss: 0.408020]\n",
      "epoch:38 step:29719[D loss: 0.193364, acc: 92.19%, op_acc: 60.94%] [G loss: 0.614422]\n",
      "epoch:38 step:29720[D loss: 0.162015, acc: 92.19%, op_acc: 71.88%] [G loss: 0.693174]\n",
      "epoch:38 step:29721[D loss: 0.285408, acc: 79.69%, op_acc: 52.34%] [G loss: 0.894158]\n",
      "epoch:38 step:29722[D loss: 0.227733, acc: 89.84%, op_acc: 62.50%] [G loss: 1.191292]\n",
      "epoch:38 step:29723[D loss: 0.295751, acc: 80.47%, op_acc: 63.28%] [G loss: 1.131311]\n",
      "epoch:38 step:29724[D loss: 0.287140, acc: 83.59%, op_acc: 57.03%] [G loss: 1.211076]\n",
      "epoch:38 step:29725[D loss: 0.360638, acc: 73.44%, op_acc: 51.56%] [G loss: 1.630115]\n",
      "epoch:38 step:29726[D loss: 0.320282, acc: 78.12%, op_acc: 53.91%] [G loss: 1.463997]\n",
      "epoch:38 step:29727[D loss: 0.318379, acc: 81.25%, op_acc: 57.03%] [G loss: 1.520312]\n",
      "epoch:38 step:29728[D loss: 0.284001, acc: 82.03%, op_acc: 58.59%] [G loss: 1.500837]\n",
      "epoch:38 step:29729[D loss: 0.208572, acc: 92.97%, op_acc: 59.38%] [G loss: 1.579190]\n",
      "epoch:38 step:29730[D loss: 0.239113, acc: 90.62%, op_acc: 64.84%] [G loss: 1.165764]\n",
      "epoch:38 step:29731[D loss: 0.253519, acc: 86.72%, op_acc: 59.38%] [G loss: 1.530622]\n",
      "epoch:38 step:29732[D loss: 0.302818, acc: 80.47%, op_acc: 68.75%] [G loss: 1.199003]\n",
      "epoch:38 step:29733[D loss: 0.252463, acc: 85.16%, op_acc: 58.59%] [G loss: 0.895964]\n",
      "epoch:38 step:29734[D loss: 0.205492, acc: 91.41%, op_acc: 62.50%] [G loss: 1.046541]\n",
      "epoch:38 step:29735[D loss: 0.239169, acc: 91.41%, op_acc: 64.06%] [G loss: 1.065866]\n",
      "epoch:38 step:29736[D loss: 0.223953, acc: 89.06%, op_acc: 57.03%] [G loss: 1.150203]\n",
      "epoch:38 step:29737[D loss: 0.223386, acc: 89.84%, op_acc: 63.28%] [G loss: 1.049036]\n",
      "epoch:38 step:29738[D loss: 0.323025, acc: 74.22%, op_acc: 44.53%] [G loss: 2.894497]\n",
      "epoch:38 step:29739[D loss: 0.275239, acc: 81.25%, op_acc: 59.38%] [G loss: 1.813949]\n",
      "epoch:38 step:29740[D loss: 0.299502, acc: 77.34%, op_acc: 62.50%] [G loss: 1.372052]\n",
      "epoch:38 step:29741[D loss: 0.260376, acc: 85.94%, op_acc: 68.75%] [G loss: 1.694544]\n",
      "epoch:38 step:29742[D loss: 0.197812, acc: 91.41%, op_acc: 66.41%] [G loss: 1.640782]\n",
      "epoch:38 step:29743[D loss: 0.233380, acc: 92.97%, op_acc: 69.53%] [G loss: 1.445209]\n",
      "epoch:38 step:29744[D loss: 0.442433, acc: 61.72%, op_acc: 42.19%] [G loss: 1.414848]\n",
      "epoch:38 step:29745[D loss: 0.244372, acc: 87.50%, op_acc: 58.59%] [G loss: 1.817070]\n",
      "epoch:38 step:29746[D loss: 0.277870, acc: 81.25%, op_acc: 63.28%] [G loss: 1.468906]\n",
      "epoch:38 step:29747[D loss: 0.281986, acc: 82.03%, op_acc: 53.12%] [G loss: 1.932245]\n",
      "epoch:38 step:29748[D loss: 0.319448, acc: 81.25%, op_acc: 53.91%] [G loss: 2.212700]\n",
      "epoch:38 step:29749[D loss: 0.292784, acc: 82.03%, op_acc: 62.50%] [G loss: 2.019468]\n",
      "epoch:38 step:29750[D loss: 0.281237, acc: 84.38%, op_acc: 60.16%] [G loss: 1.948760]\n",
      "epoch:38 step:29751[D loss: 0.293674, acc: 79.69%, op_acc: 63.28%] [G loss: 1.949209]\n",
      "epoch:38 step:29752[D loss: 0.225382, acc: 87.50%, op_acc: 60.94%] [G loss: 1.945119]\n",
      "epoch:38 step:29753[D loss: 0.175271, acc: 92.97%, op_acc: 70.31%] [G loss: 2.302616]\n",
      "epoch:38 step:29754[D loss: 0.326133, acc: 75.00%, op_acc: 52.34%] [G loss: 2.438962]\n",
      "epoch:38 step:29755[D loss: 0.285200, acc: 82.81%, op_acc: 67.19%] [G loss: 3.016980]\n",
      "epoch:38 step:29756[D loss: 0.231745, acc: 87.50%, op_acc: 69.53%] [G loss: 2.380810]\n",
      "epoch:38 step:29757[D loss: 0.224476, acc: 88.28%, op_acc: 66.41%] [G loss: 1.112177]\n",
      "epoch:38 step:29758[D loss: 0.268566, acc: 82.81%, op_acc: 51.56%] [G loss: 2.548400]\n",
      "epoch:38 step:29759[D loss: 0.256150, acc: 88.28%, op_acc: 61.72%] [G loss: 0.865166]\n",
      "epoch:38 step:29760[D loss: 0.484341, acc: 63.28%, op_acc: 40.62%] [G loss: 0.770120]\n",
      "epoch:38 step:29761[D loss: 0.340040, acc: 68.75%, op_acc: 47.66%] [G loss: 3.047696]\n",
      "epoch:38 step:29762[D loss: 0.355336, acc: 75.00%, op_acc: 52.34%] [G loss: 2.633087]\n",
      "epoch:38 step:29763[D loss: 0.433688, acc: 71.88%, op_acc: 39.84%] [G loss: 2.136427]\n",
      "epoch:38 step:29764[D loss: 0.303643, acc: 82.03%, op_acc: 62.50%] [G loss: 2.489195]\n",
      "epoch:38 step:29765[D loss: 0.252878, acc: 89.84%, op_acc: 60.16%] [G loss: 2.589889]\n",
      "epoch:38 step:29766[D loss: 0.285855, acc: 85.16%, op_acc: 58.59%] [G loss: 1.838861]\n",
      "epoch:38 step:29767[D loss: 0.321284, acc: 82.03%, op_acc: 57.81%] [G loss: 1.563833]\n",
      "epoch:38 step:29768[D loss: 0.266729, acc: 83.59%, op_acc: 59.38%] [G loss: 2.151138]\n",
      "epoch:38 step:29769[D loss: 0.356757, acc: 68.75%, op_acc: 53.12%] [G loss: 1.827541]\n",
      "epoch:38 step:29770[D loss: 0.328156, acc: 80.47%, op_acc: 45.31%] [G loss: 2.030266]\n",
      "epoch:38 step:29771[D loss: 0.243312, acc: 82.03%, op_acc: 61.72%] [G loss: 1.189573]\n",
      "epoch:38 step:29772[D loss: 0.219767, acc: 89.06%, op_acc: 66.41%] [G loss: 1.797881]\n",
      "epoch:38 step:29773[D loss: 0.233569, acc: 84.38%, op_acc: 68.75%] [G loss: 1.170733]\n",
      "epoch:38 step:29774[D loss: 0.345597, acc: 75.00%, op_acc: 46.09%] [G loss: 1.273226]\n",
      "epoch:38 step:29775[D loss: 0.340733, acc: 68.75%, op_acc: 47.66%] [G loss: 2.371703]\n",
      "epoch:38 step:29776[D loss: 0.318147, acc: 75.78%, op_acc: 60.16%] [G loss: 1.333234]\n",
      "epoch:38 step:29777[D loss: 0.499636, acc: 54.69%, op_acc: 38.28%] [G loss: 2.175024]\n",
      "epoch:38 step:29778[D loss: 0.328079, acc: 77.34%, op_acc: 51.56%] [G loss: 1.838901]\n",
      "epoch:38 step:29779[D loss: 0.364617, acc: 70.31%, op_acc: 46.88%] [G loss: 1.810327]\n",
      "epoch:38 step:29780[D loss: 0.397225, acc: 63.28%, op_acc: 52.34%] [G loss: 1.894738]\n",
      "epoch:38 step:29781[D loss: 0.383865, acc: 71.88%, op_acc: 48.44%] [G loss: 1.439519]\n",
      "epoch:38 step:29782[D loss: 0.257585, acc: 84.38%, op_acc: 57.03%] [G loss: 1.642264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29783[D loss: 0.356037, acc: 71.88%, op_acc: 48.44%] [G loss: 1.317054]\n",
      "epoch:38 step:29784[D loss: 0.268397, acc: 81.25%, op_acc: 59.38%] [G loss: 1.251123]\n",
      "epoch:38 step:29785[D loss: 0.278169, acc: 81.25%, op_acc: 64.06%] [G loss: 1.159904]\n",
      "epoch:38 step:29786[D loss: 0.327533, acc: 76.56%, op_acc: 58.59%] [G loss: 2.302739]\n",
      "epoch:38 step:29787[D loss: 0.366917, acc: 67.97%, op_acc: 46.88%] [G loss: 1.051528]\n",
      "epoch:38 step:29788[D loss: 0.221578, acc: 85.16%, op_acc: 65.62%] [G loss: 1.298481]\n",
      "epoch:38 step:29789[D loss: 0.323170, acc: 80.47%, op_acc: 63.28%] [G loss: 1.745295]\n",
      "epoch:38 step:29790[D loss: 0.287095, acc: 80.47%, op_acc: 55.47%] [G loss: 1.997852]\n",
      "epoch:38 step:29791[D loss: 0.394801, acc: 68.75%, op_acc: 64.84%] [G loss: 1.326209]\n",
      "epoch:38 step:29792[D loss: 0.245809, acc: 85.94%, op_acc: 70.31%] [G loss: 0.718575]\n",
      "epoch:38 step:29793[D loss: 0.215355, acc: 85.94%, op_acc: 62.50%] [G loss: 2.032117]\n",
      "epoch:38 step:29794[D loss: 0.299500, acc: 80.47%, op_acc: 55.47%] [G loss: 1.523319]\n",
      "epoch:38 step:29795[D loss: 0.371044, acc: 71.88%, op_acc: 52.34%] [G loss: 1.310142]\n",
      "epoch:38 step:29796[D loss: 0.313603, acc: 75.00%, op_acc: 57.03%] [G loss: 1.298457]\n",
      "epoch:38 step:29797[D loss: 0.242377, acc: 89.06%, op_acc: 69.53%] [G loss: 0.898864]\n",
      "epoch:38 step:29798[D loss: 0.268727, acc: 85.94%, op_acc: 52.34%] [G loss: 0.979580]\n",
      "epoch:38 step:29799[D loss: 0.323710, acc: 78.12%, op_acc: 57.81%] [G loss: 0.693574]\n",
      "epoch:38 step:29800[D loss: 0.274114, acc: 82.81%, op_acc: 67.97%] [G loss: 0.726081]\n",
      "epoch:38 step:29801[D loss: 0.405212, acc: 71.09%, op_acc: 39.84%] [G loss: 1.096974]\n",
      "epoch:38 step:29802[D loss: 0.318659, acc: 77.34%, op_acc: 54.69%] [G loss: 1.035011]\n",
      "epoch:38 step:29803[D loss: 0.312608, acc: 82.03%, op_acc: 47.66%] [G loss: 1.098171]\n",
      "epoch:38 step:29804[D loss: 0.410471, acc: 68.75%, op_acc: 53.12%] [G loss: 1.047874]\n",
      "epoch:38 step:29805[D loss: 0.352074, acc: 77.34%, op_acc: 40.62%] [G loss: 2.048071]\n",
      "epoch:38 step:29806[D loss: 0.271964, acc: 82.81%, op_acc: 57.81%] [G loss: 1.154824]\n",
      "epoch:38 step:29807[D loss: 0.339488, acc: 77.34%, op_acc: 64.06%] [G loss: 1.351581]\n",
      "epoch:38 step:29808[D loss: 0.399188, acc: 67.97%, op_acc: 54.69%] [G loss: 1.141073]\n",
      "epoch:38 step:29809[D loss: 0.329508, acc: 79.69%, op_acc: 48.44%] [G loss: 1.094422]\n",
      "epoch:38 step:29810[D loss: 0.271224, acc: 83.59%, op_acc: 63.28%] [G loss: 1.273559]\n",
      "epoch:38 step:29811[D loss: 0.312895, acc: 82.81%, op_acc: 54.69%] [G loss: 1.133434]\n",
      "epoch:38 step:29812[D loss: 0.262006, acc: 87.50%, op_acc: 60.94%] [G loss: 0.952027]\n",
      "epoch:38 step:29813[D loss: 0.337432, acc: 75.78%, op_acc: 57.81%] [G loss: 1.013852]\n",
      "epoch:38 step:29814[D loss: 0.307464, acc: 72.66%, op_acc: 51.56%] [G loss: 1.360148]\n",
      "epoch:38 step:29815[D loss: 0.280617, acc: 80.47%, op_acc: 58.59%] [G loss: 1.112754]\n",
      "epoch:38 step:29816[D loss: 0.341347, acc: 76.56%, op_acc: 50.00%] [G loss: 1.472759]\n",
      "epoch:38 step:29817[D loss: 0.276243, acc: 82.03%, op_acc: 63.28%] [G loss: 0.759216]\n",
      "epoch:38 step:29818[D loss: 0.357957, acc: 75.78%, op_acc: 55.47%] [G loss: 1.248268]\n",
      "epoch:38 step:29819[D loss: 0.347755, acc: 78.91%, op_acc: 51.56%] [G loss: 1.251350]\n",
      "epoch:38 step:29820[D loss: 0.236516, acc: 87.50%, op_acc: 62.50%] [G loss: 1.496327]\n",
      "epoch:38 step:29821[D loss: 0.172732, acc: 91.41%, op_acc: 76.56%] [G loss: 1.625914]\n",
      "epoch:38 step:29822[D loss: 0.235912, acc: 87.50%, op_acc: 67.97%] [G loss: 0.656489]\n",
      "epoch:38 step:29823[D loss: 0.221926, acc: 88.28%, op_acc: 59.38%] [G loss: 1.788586]\n",
      "epoch:38 step:29824[D loss: 0.321988, acc: 80.47%, op_acc: 50.78%] [G loss: 1.681322]\n",
      "epoch:38 step:29825[D loss: 0.211485, acc: 90.62%, op_acc: 60.94%] [G loss: 1.725055]\n",
      "epoch:38 step:29826[D loss: 0.354721, acc: 68.75%, op_acc: 57.03%] [G loss: 0.840084]\n",
      "epoch:38 step:29827[D loss: 0.337781, acc: 75.00%, op_acc: 51.56%] [G loss: 1.573952]\n",
      "epoch:38 step:29828[D loss: 0.375021, acc: 75.00%, op_acc: 46.88%] [G loss: 2.205024]\n",
      "epoch:38 step:29829[D loss: 0.258996, acc: 84.38%, op_acc: 65.62%] [G loss: 1.890725]\n",
      "epoch:38 step:29830[D loss: 0.300772, acc: 80.47%, op_acc: 64.84%] [G loss: 1.383474]\n",
      "epoch:38 step:29831[D loss: 0.381073, acc: 67.97%, op_acc: 49.22%] [G loss: 1.607621]\n",
      "epoch:38 step:29832[D loss: 0.301126, acc: 81.25%, op_acc: 48.44%] [G loss: 1.882525]\n",
      "epoch:38 step:29833[D loss: 0.272353, acc: 84.38%, op_acc: 58.59%] [G loss: 2.206078]\n",
      "epoch:38 step:29834[D loss: 0.358662, acc: 74.22%, op_acc: 59.38%] [G loss: 1.490592]\n",
      "epoch:38 step:29835[D loss: 0.252636, acc: 85.94%, op_acc: 53.91%] [G loss: 1.285149]\n",
      "epoch:38 step:29836[D loss: 0.219844, acc: 88.28%, op_acc: 70.31%] [G loss: 2.579264]\n",
      "epoch:38 step:29837[D loss: 0.330336, acc: 77.34%, op_acc: 56.25%] [G loss: 1.222196]\n",
      "epoch:38 step:29838[D loss: 0.297046, acc: 82.03%, op_acc: 55.47%] [G loss: 1.649443]\n",
      "epoch:38 step:29839[D loss: 0.319748, acc: 81.25%, op_acc: 56.25%] [G loss: 1.234285]\n",
      "epoch:38 step:29840[D loss: 0.391010, acc: 67.97%, op_acc: 52.34%] [G loss: 1.548174]\n",
      "epoch:38 step:29841[D loss: 0.321682, acc: 78.91%, op_acc: 48.44%] [G loss: 1.382431]\n",
      "epoch:38 step:29842[D loss: 0.325714, acc: 76.56%, op_acc: 55.47%] [G loss: 1.407814]\n",
      "epoch:38 step:29843[D loss: 0.309890, acc: 78.12%, op_acc: 55.47%] [G loss: 1.170205]\n",
      "epoch:38 step:29844[D loss: 0.290226, acc: 82.03%, op_acc: 57.03%] [G loss: 1.306115]\n",
      "epoch:38 step:29845[D loss: 0.256906, acc: 81.25%, op_acc: 62.50%] [G loss: 1.303432]\n",
      "epoch:38 step:29846[D loss: 0.269545, acc: 82.81%, op_acc: 57.03%] [G loss: 1.202120]\n",
      "epoch:38 step:29847[D loss: 0.295966, acc: 84.38%, op_acc: 54.69%] [G loss: 1.048857]\n",
      "epoch:38 step:29848[D loss: 0.282975, acc: 82.03%, op_acc: 59.38%] [G loss: 1.741234]\n",
      "epoch:38 step:29849[D loss: 0.385637, acc: 70.31%, op_acc: 51.56%] [G loss: 0.863438]\n",
      "epoch:38 step:29850[D loss: 0.248676, acc: 85.94%, op_acc: 64.84%] [G loss: 1.089833]\n",
      "epoch:38 step:29851[D loss: 0.276979, acc: 83.59%, op_acc: 57.81%] [G loss: 0.813208]\n",
      "epoch:38 step:29852[D loss: 0.326514, acc: 75.78%, op_acc: 51.56%] [G loss: 2.127347]\n",
      "epoch:38 step:29853[D loss: 0.280017, acc: 82.03%, op_acc: 53.91%] [G loss: 1.378160]\n",
      "epoch:38 step:29854[D loss: 0.341031, acc: 73.44%, op_acc: 53.12%] [G loss: 1.132287]\n",
      "epoch:38 step:29855[D loss: 0.274743, acc: 82.81%, op_acc: 55.47%] [G loss: 1.207501]\n",
      "epoch:38 step:29856[D loss: 0.375459, acc: 73.44%, op_acc: 46.88%] [G loss: 1.053041]\n",
      "epoch:38 step:29857[D loss: 0.273588, acc: 84.38%, op_acc: 65.62%] [G loss: 0.951312]\n",
      "epoch:38 step:29858[D loss: 0.294162, acc: 81.25%, op_acc: 52.34%] [G loss: 1.126897]\n",
      "epoch:38 step:29859[D loss: 0.241565, acc: 82.81%, op_acc: 63.28%] [G loss: 1.039856]\n",
      "epoch:38 step:29860[D loss: 0.241576, acc: 86.72%, op_acc: 63.28%] [G loss: 0.769629]\n",
      "epoch:38 step:29861[D loss: 0.229401, acc: 89.06%, op_acc: 63.28%] [G loss: 1.460368]\n",
      "epoch:38 step:29862[D loss: 0.279687, acc: 78.91%, op_acc: 58.59%] [G loss: 1.148626]\n",
      "epoch:38 step:29863[D loss: 0.280167, acc: 85.16%, op_acc: 59.38%] [G loss: 1.256717]\n",
      "epoch:38 step:29864[D loss: 0.220491, acc: 89.06%, op_acc: 67.97%] [G loss: 2.395095]\n",
      "epoch:38 step:29865[D loss: 0.297498, acc: 78.91%, op_acc: 64.84%] [G loss: 1.113647]\n",
      "epoch:38 step:29866[D loss: 0.450383, acc: 57.81%, op_acc: 46.88%] [G loss: 0.900442]\n",
      "epoch:38 step:29867[D loss: 0.322495, acc: 79.69%, op_acc: 53.12%] [G loss: 0.820189]\n",
      "epoch:38 step:29868[D loss: 0.376754, acc: 71.09%, op_acc: 47.66%] [G loss: 1.899562]\n",
      "epoch:38 step:29869[D loss: 0.311032, acc: 78.12%, op_acc: 54.69%] [G loss: 2.239976]\n",
      "epoch:38 step:29870[D loss: 0.328668, acc: 71.88%, op_acc: 50.00%] [G loss: 1.158100]\n",
      "epoch:38 step:29871[D loss: 0.298359, acc: 85.94%, op_acc: 57.81%] [G loss: 1.879250]\n",
      "epoch:38 step:29872[D loss: 0.386166, acc: 63.28%, op_acc: 50.78%] [G loss: 1.220816]\n",
      "epoch:38 step:29873[D loss: 0.351148, acc: 72.66%, op_acc: 46.09%] [G loss: 1.453479]\n",
      "epoch:38 step:29874[D loss: 0.324060, acc: 81.25%, op_acc: 46.88%] [G loss: 0.966455]\n",
      "epoch:38 step:29875[D loss: 0.484649, acc: 60.16%, op_acc: 42.19%] [G loss: 2.117951]\n",
      "epoch:38 step:29876[D loss: 0.269175, acc: 86.72%, op_acc: 63.28%] [G loss: 1.337451]\n",
      "epoch:38 step:29877[D loss: 0.371881, acc: 71.88%, op_acc: 51.56%] [G loss: 1.149615]\n",
      "epoch:38 step:29878[D loss: 0.330738, acc: 79.69%, op_acc: 57.03%] [G loss: 1.916048]\n",
      "epoch:38 step:29879[D loss: 0.370456, acc: 70.31%, op_acc: 46.09%] [G loss: 0.906242]\n",
      "epoch:38 step:29880[D loss: 0.262684, acc: 85.16%, op_acc: 61.72%] [G loss: 0.933718]\n",
      "epoch:38 step:29881[D loss: 0.345230, acc: 75.78%, op_acc: 62.50%] [G loss: 1.074309]\n",
      "epoch:38 step:29882[D loss: 0.371944, acc: 71.09%, op_acc: 50.78%] [G loss: 0.459337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29883[D loss: 0.289962, acc: 82.03%, op_acc: 48.44%] [G loss: 0.653297]\n",
      "epoch:38 step:29884[D loss: 0.270615, acc: 78.91%, op_acc: 66.41%] [G loss: 0.871860]\n",
      "epoch:38 step:29885[D loss: 0.289097, acc: 80.47%, op_acc: 64.84%] [G loss: 0.561769]\n",
      "epoch:38 step:29886[D loss: 0.241108, acc: 85.94%, op_acc: 57.81%] [G loss: 0.670824]\n",
      "epoch:38 step:29887[D loss: 0.347963, acc: 73.44%, op_acc: 51.56%] [G loss: 0.696788]\n",
      "epoch:38 step:29888[D loss: 0.345626, acc: 78.12%, op_acc: 51.56%] [G loss: 0.479470]\n",
      "epoch:38 step:29889[D loss: 0.206685, acc: 89.06%, op_acc: 69.53%] [G loss: 0.797888]\n",
      "epoch:38 step:29890[D loss: 0.282999, acc: 82.81%, op_acc: 60.16%] [G loss: 0.864051]\n",
      "epoch:38 step:29891[D loss: 0.290693, acc: 75.00%, op_acc: 56.25%] [G loss: 1.019056]\n",
      "epoch:38 step:29892[D loss: 0.360660, acc: 75.00%, op_acc: 43.75%] [G loss: 1.354859]\n",
      "epoch:38 step:29893[D loss: 0.353871, acc: 74.22%, op_acc: 55.47%] [G loss: 1.251219]\n",
      "epoch:38 step:29894[D loss: 0.369018, acc: 71.88%, op_acc: 42.97%] [G loss: 1.196176]\n",
      "epoch:38 step:29895[D loss: 0.324335, acc: 76.56%, op_acc: 56.25%] [G loss: 1.172384]\n",
      "epoch:38 step:29896[D loss: 0.256168, acc: 88.28%, op_acc: 64.06%] [G loss: 0.911151]\n",
      "epoch:38 step:29897[D loss: 0.226738, acc: 89.84%, op_acc: 58.59%] [G loss: 0.811285]\n",
      "epoch:38 step:29898[D loss: 0.251314, acc: 87.50%, op_acc: 60.16%] [G loss: 0.719741]\n",
      "epoch:38 step:29899[D loss: 0.262242, acc: 86.72%, op_acc: 60.94%] [G loss: 1.040835]\n",
      "epoch:38 step:29900[D loss: 0.249901, acc: 83.59%, op_acc: 67.97%] [G loss: 0.760948]\n",
      "epoch:38 step:29901[D loss: 0.308565, acc: 81.25%, op_acc: 53.91%] [G loss: 0.723668]\n",
      "epoch:38 step:29902[D loss: 0.274077, acc: 82.03%, op_acc: 63.28%] [G loss: 1.215033]\n",
      "epoch:38 step:29903[D loss: 0.307825, acc: 75.78%, op_acc: 60.16%] [G loss: 1.054357]\n",
      "epoch:38 step:29904[D loss: 0.324761, acc: 78.12%, op_acc: 51.56%] [G loss: 0.906454]\n",
      "epoch:38 step:29905[D loss: 0.329619, acc: 78.91%, op_acc: 55.47%] [G loss: 0.715441]\n",
      "epoch:38 step:29906[D loss: 0.317501, acc: 81.25%, op_acc: 59.38%] [G loss: 0.675849]\n",
      "epoch:38 step:29907[D loss: 0.286741, acc: 82.03%, op_acc: 57.03%] [G loss: 0.697990]\n",
      "epoch:38 step:29908[D loss: 0.308000, acc: 78.12%, op_acc: 54.69%] [G loss: 0.887808]\n",
      "epoch:38 step:29909[D loss: 0.208403, acc: 90.62%, op_acc: 74.22%] [G loss: 2.120479]\n",
      "epoch:38 step:29910[D loss: 0.244126, acc: 84.38%, op_acc: 57.03%] [G loss: 0.668553]\n",
      "epoch:38 step:29911[D loss: 0.235827, acc: 87.50%, op_acc: 59.38%] [G loss: 1.216583]\n",
      "epoch:38 step:29912[D loss: 0.259578, acc: 85.16%, op_acc: 67.19%] [G loss: 0.575836]\n",
      "epoch:38 step:29913[D loss: 0.280766, acc: 83.59%, op_acc: 63.28%] [G loss: 0.517335]\n",
      "epoch:38 step:29914[D loss: 0.349897, acc: 74.22%, op_acc: 58.59%] [G loss: 1.826357]\n",
      "epoch:38 step:29915[D loss: 0.273422, acc: 82.03%, op_acc: 59.38%] [G loss: 1.354772]\n",
      "epoch:38 step:29916[D loss: 0.312039, acc: 84.38%, op_acc: 58.59%] [G loss: 0.679517]\n",
      "epoch:38 step:29917[D loss: 0.228560, acc: 88.28%, op_acc: 63.28%] [G loss: 0.443173]\n",
      "epoch:38 step:29918[D loss: 0.280862, acc: 82.81%, op_acc: 58.59%] [G loss: 0.799664]\n",
      "epoch:38 step:29919[D loss: 0.248307, acc: 82.81%, op_acc: 64.84%] [G loss: 0.618788]\n",
      "epoch:38 step:29920[D loss: 0.282166, acc: 80.47%, op_acc: 57.03%] [G loss: 0.317279]\n",
      "epoch:38 step:29921[D loss: 0.277772, acc: 80.47%, op_acc: 62.50%] [G loss: 0.445366]\n",
      "epoch:38 step:29922[D loss: 0.226571, acc: 92.19%, op_acc: 63.28%] [G loss: 0.716909]\n",
      "epoch:38 step:29923[D loss: 0.251288, acc: 85.94%, op_acc: 66.41%] [G loss: 0.558038]\n",
      "epoch:38 step:29924[D loss: 0.200487, acc: 93.75%, op_acc: 66.41%] [G loss: 0.888988]\n",
      "epoch:38 step:29925[D loss: 0.189863, acc: 92.97%, op_acc: 67.19%] [G loss: 0.514825]\n",
      "epoch:38 step:29926[D loss: 0.269240, acc: 86.72%, op_acc: 55.47%] [G loss: 1.139678]\n",
      "epoch:38 step:29927[D loss: 0.315792, acc: 78.12%, op_acc: 56.25%] [G loss: 1.005897]\n",
      "epoch:38 step:29928[D loss: 0.418228, acc: 71.09%, op_acc: 53.91%] [G loss: 1.041782]\n",
      "epoch:38 step:29929[D loss: 0.188795, acc: 91.41%, op_acc: 68.75%] [G loss: 1.131725]\n",
      "epoch:38 step:29930[D loss: 0.179937, acc: 92.97%, op_acc: 73.44%] [G loss: 1.566087]\n",
      "epoch:38 step:29931[D loss: 0.239325, acc: 87.50%, op_acc: 54.69%] [G loss: 1.704445]\n",
      "epoch:38 step:29932[D loss: 0.302948, acc: 79.69%, op_acc: 46.88%] [G loss: 1.414891]\n",
      "epoch:38 step:29933[D loss: 0.388318, acc: 74.22%, op_acc: 51.56%] [G loss: 1.749322]\n",
      "epoch:38 step:29934[D loss: 0.358860, acc: 67.97%, op_acc: 50.00%] [G loss: 1.609102]\n",
      "epoch:38 step:29935[D loss: 0.365387, acc: 73.44%, op_acc: 62.50%] [G loss: 2.205573]\n",
      "epoch:38 step:29936[D loss: 0.291952, acc: 80.47%, op_acc: 57.81%] [G loss: 1.870126]\n",
      "epoch:38 step:29937[D loss: 0.261657, acc: 88.28%, op_acc: 55.47%] [G loss: 2.009267]\n",
      "epoch:38 step:29938[D loss: 0.241646, acc: 86.72%, op_acc: 66.41%] [G loss: 2.060306]\n",
      "epoch:38 step:29939[D loss: 0.215428, acc: 91.41%, op_acc: 64.84%] [G loss: 2.827528]\n",
      "epoch:38 step:29940[D loss: 0.285062, acc: 79.69%, op_acc: 57.81%] [G loss: 2.159532]\n",
      "epoch:38 step:29941[D loss: 0.256399, acc: 85.94%, op_acc: 58.59%] [G loss: 0.896412]\n",
      "epoch:38 step:29942[D loss: 0.280955, acc: 78.91%, op_acc: 57.81%] [G loss: 0.759865]\n",
      "epoch:38 step:29943[D loss: 0.338032, acc: 70.31%, op_acc: 56.25%] [G loss: 2.842962]\n",
      "epoch:38 step:29944[D loss: 0.251862, acc: 86.72%, op_acc: 59.38%] [G loss: 2.680557]\n",
      "epoch:38 step:29945[D loss: 0.365872, acc: 71.09%, op_acc: 55.47%] [G loss: 1.898030]\n",
      "epoch:38 step:29946[D loss: 0.414032, acc: 64.84%, op_acc: 43.75%] [G loss: 1.950424]\n",
      "epoch:38 step:29947[D loss: 0.430301, acc: 64.06%, op_acc: 44.53%] [G loss: 2.560040]\n",
      "epoch:38 step:29948[D loss: 0.295388, acc: 79.69%, op_acc: 65.62%] [G loss: 3.484477]\n",
      "epoch:38 step:29949[D loss: 0.345493, acc: 77.34%, op_acc: 62.50%] [G loss: 1.709682]\n",
      "epoch:38 step:29950[D loss: 0.302885, acc: 84.38%, op_acc: 57.03%] [G loss: 1.303167]\n",
      "epoch:38 step:29951[D loss: 0.188424, acc: 92.19%, op_acc: 73.44%] [G loss: 1.885812]\n",
      "epoch:38 step:29952[D loss: 0.254374, acc: 87.50%, op_acc: 61.72%] [G loss: 1.234277]\n",
      "epoch:38 step:29953[D loss: 0.282923, acc: 82.81%, op_acc: 56.25%] [G loss: 2.703996]\n",
      "epoch:38 step:29954[D loss: 0.276357, acc: 80.47%, op_acc: 55.47%] [G loss: 1.590346]\n",
      "epoch:38 step:29955[D loss: 0.304053, acc: 81.25%, op_acc: 57.81%] [G loss: 1.184733]\n",
      "epoch:38 step:29956[D loss: 0.286993, acc: 82.03%, op_acc: 58.59%] [G loss: 2.406759]\n",
      "epoch:38 step:29957[D loss: 0.299626, acc: 82.03%, op_acc: 55.47%] [G loss: 1.642849]\n",
      "epoch:38 step:29958[D loss: 0.270717, acc: 81.25%, op_acc: 61.72%] [G loss: 1.790662]\n",
      "epoch:38 step:29959[D loss: 0.308992, acc: 79.69%, op_acc: 57.03%] [G loss: 1.873048]\n",
      "epoch:38 step:29960[D loss: 0.290808, acc: 83.59%, op_acc: 61.72%] [G loss: 1.492777]\n",
      "epoch:38 step:29961[D loss: 0.278581, acc: 80.47%, op_acc: 57.81%] [G loss: 1.531127]\n",
      "epoch:38 step:29962[D loss: 0.215719, acc: 89.84%, op_acc: 60.94%] [G loss: 1.213291]\n",
      "epoch:38 step:29963[D loss: 0.206583, acc: 92.97%, op_acc: 62.50%] [G loss: 1.593614]\n",
      "epoch:38 step:29964[D loss: 0.205472, acc: 92.19%, op_acc: 62.50%] [G loss: 1.589602]\n",
      "epoch:38 step:29965[D loss: 0.235688, acc: 85.16%, op_acc: 68.75%] [G loss: 1.288703]\n",
      "epoch:38 step:29966[D loss: 0.208146, acc: 92.19%, op_acc: 67.19%] [G loss: 1.145658]\n",
      "epoch:38 step:29967[D loss: 0.234471, acc: 90.62%, op_acc: 64.84%] [G loss: 1.300557]\n",
      "epoch:38 step:29968[D loss: 0.207716, acc: 91.41%, op_acc: 63.28%] [G loss: 1.095643]\n",
      "epoch:38 step:29969[D loss: 0.337216, acc: 76.56%, op_acc: 47.66%] [G loss: 1.442939]\n",
      "epoch:38 step:29970[D loss: 0.317606, acc: 83.59%, op_acc: 67.97%] [G loss: 1.652184]\n",
      "epoch:38 step:29971[D loss: 0.250231, acc: 89.06%, op_acc: 52.34%] [G loss: 1.669075]\n",
      "epoch:38 step:29972[D loss: 0.216782, acc: 89.84%, op_acc: 63.28%] [G loss: 1.707714]\n",
      "epoch:38 step:29973[D loss: 0.215601, acc: 88.28%, op_acc: 74.22%] [G loss: 1.911329]\n",
      "epoch:38 step:29974[D loss: 0.261049, acc: 80.47%, op_acc: 61.72%] [G loss: 1.817573]\n",
      "epoch:38 step:29975[D loss: 0.243693, acc: 86.72%, op_acc: 67.97%] [G loss: 1.760230]\n",
      "epoch:38 step:29976[D loss: 0.206929, acc: 89.84%, op_acc: 71.09%] [G loss: 2.181998]\n",
      "epoch:38 step:29977[D loss: 0.191702, acc: 92.19%, op_acc: 67.97%] [G loss: 2.082958]\n",
      "epoch:38 step:29978[D loss: 0.282526, acc: 83.59%, op_acc: 61.72%] [G loss: 1.740360]\n",
      "epoch:38 step:29979[D loss: 0.247284, acc: 86.72%, op_acc: 59.38%] [G loss: 2.222337]\n",
      "epoch:38 step:29980[D loss: 0.149164, acc: 96.09%, op_acc: 73.44%] [G loss: 2.475925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:29981[D loss: 0.222496, acc: 92.97%, op_acc: 60.16%] [G loss: 2.085266]\n",
      "epoch:38 step:29982[D loss: 0.210717, acc: 89.06%, op_acc: 69.53%] [G loss: 2.537627]\n",
      "epoch:38 step:29983[D loss: 0.248664, acc: 85.16%, op_acc: 68.75%] [G loss: 2.199235]\n",
      "epoch:38 step:29984[D loss: 0.282643, acc: 85.94%, op_acc: 56.25%] [G loss: 2.303766]\n",
      "epoch:38 step:29985[D loss: 0.162735, acc: 96.88%, op_acc: 67.97%] [G loss: 2.681406]\n",
      "epoch:38 step:29986[D loss: 0.270714, acc: 82.81%, op_acc: 59.38%] [G loss: 2.295766]\n",
      "epoch:38 step:29987[D loss: 0.198258, acc: 94.53%, op_acc: 73.44%] [G loss: 2.871938]\n",
      "epoch:38 step:29988[D loss: 0.181605, acc: 95.31%, op_acc: 67.19%] [G loss: 2.734059]\n",
      "epoch:38 step:29989[D loss: 0.191931, acc: 92.97%, op_acc: 71.09%] [G loss: 2.933464]\n",
      "epoch:38 step:29990[D loss: 0.190154, acc: 90.62%, op_acc: 76.56%] [G loss: 2.624462]\n",
      "epoch:38 step:29991[D loss: 0.260049, acc: 85.16%, op_acc: 62.50%] [G loss: 2.802005]\n",
      "epoch:38 step:29992[D loss: 0.291448, acc: 78.91%, op_acc: 65.62%] [G loss: 2.922033]\n",
      "epoch:38 step:29993[D loss: 0.317560, acc: 77.34%, op_acc: 58.59%] [G loss: 0.920383]\n",
      "epoch:38 step:29994[D loss: 0.295020, acc: 80.47%, op_acc: 56.25%] [G loss: 3.350868]\n",
      "epoch:38 step:29995[D loss: 0.415349, acc: 62.50%, op_acc: 46.09%] [G loss: 2.774726]\n",
      "epoch:38 step:29996[D loss: 0.360737, acc: 72.66%, op_acc: 47.66%] [G loss: 2.816531]\n",
      "epoch:38 step:29997[D loss: 0.307179, acc: 80.47%, op_acc: 53.12%] [G loss: 2.216538]\n",
      "epoch:38 step:29998[D loss: 0.408675, acc: 70.31%, op_acc: 51.56%] [G loss: 1.739713]\n",
      "epoch:38 step:29999[D loss: 0.380545, acc: 70.31%, op_acc: 44.53%] [G loss: 2.301307]\n",
      "epoch:38 step:30000[D loss: 0.435965, acc: 65.62%, op_acc: 53.91%] [G loss: 2.445358]\n",
      "epoch:38 step:30001[D loss: 0.285971, acc: 81.25%, op_acc: 67.19%] [G loss: 2.196526]\n",
      "epoch:38 step:30002[D loss: 0.361371, acc: 74.22%, op_acc: 47.66%] [G loss: 1.999178]\n",
      "epoch:38 step:30003[D loss: 0.239660, acc: 85.16%, op_acc: 71.88%] [G loss: 2.240199]\n",
      "epoch:38 step:30004[D loss: 0.204510, acc: 89.84%, op_acc: 74.22%] [G loss: 1.916474]\n",
      "epoch:38 step:30005[D loss: 0.298947, acc: 78.91%, op_acc: 57.03%] [G loss: 2.039973]\n",
      "epoch:38 step:30006[D loss: 0.262453, acc: 85.16%, op_acc: 56.25%] [G loss: 1.797830]\n",
      "epoch:38 step:30007[D loss: 0.297125, acc: 82.03%, op_acc: 51.56%] [G loss: 2.422950]\n",
      "epoch:38 step:30008[D loss: 0.215071, acc: 87.50%, op_acc: 69.53%] [G loss: 2.260833]\n",
      "epoch:38 step:30009[D loss: 0.275274, acc: 84.38%, op_acc: 56.25%] [G loss: 2.146233]\n",
      "epoch:38 step:30010[D loss: 0.271262, acc: 84.38%, op_acc: 66.41%] [G loss: 2.438542]\n",
      "epoch:38 step:30011[D loss: 0.204659, acc: 91.41%, op_acc: 68.75%] [G loss: 2.368045]\n",
      "epoch:38 step:30012[D loss: 0.313946, acc: 73.44%, op_acc: 57.81%] [G loss: 2.375266]\n",
      "epoch:38 step:30013[D loss: 0.271955, acc: 82.81%, op_acc: 58.59%] [G loss: 1.974894]\n",
      "epoch:38 step:30014[D loss: 0.284187, acc: 85.16%, op_acc: 62.50%] [G loss: 0.631919]\n",
      "epoch:38 step:30015[D loss: 0.663561, acc: 46.88%, op_acc: 32.03%] [G loss: 0.763692]\n",
      "epoch:38 step:30016[D loss: 0.567603, acc: 43.75%, op_acc: 41.41%] [G loss: 2.390647]\n",
      "epoch:38 step:30017[D loss: 0.378070, acc: 70.31%, op_acc: 49.22%] [G loss: 2.451191]\n",
      "epoch:38 step:30018[D loss: 0.347070, acc: 68.75%, op_acc: 45.31%] [G loss: 1.891098]\n",
      "epoch:38 step:30019[D loss: 0.387065, acc: 65.62%, op_acc: 43.75%] [G loss: 2.232694]\n",
      "epoch:38 step:30020[D loss: 0.476445, acc: 60.94%, op_acc: 43.75%] [G loss: 1.827284]\n",
      "epoch:38 step:30021[D loss: 0.397169, acc: 69.53%, op_acc: 42.97%] [G loss: 1.663220]\n",
      "epoch:38 step:30022[D loss: 0.419822, acc: 69.53%, op_acc: 43.75%] [G loss: 1.095531]\n",
      "epoch:38 step:30023[D loss: 0.293173, acc: 79.69%, op_acc: 50.00%] [G loss: 1.906777]\n",
      "epoch:38 step:30024[D loss: 0.458356, acc: 55.47%, op_acc: 45.31%] [G loss: 1.698795]\n",
      "epoch:38 step:30025[D loss: 0.445513, acc: 60.94%, op_acc: 46.09%] [G loss: 1.934158]\n",
      "epoch:38 step:30026[D loss: 0.436350, acc: 67.97%, op_acc: 49.22%] [G loss: 1.268209]\n",
      "epoch:38 step:30027[D loss: 0.476486, acc: 54.69%, op_acc: 42.97%] [G loss: 1.061457]\n",
      "epoch:38 step:30028[D loss: 0.460066, acc: 60.94%, op_acc: 41.41%] [G loss: 1.547803]\n",
      "epoch:38 step:30029[D loss: 0.479882, acc: 53.91%, op_acc: 40.62%] [G loss: 1.708223]\n",
      "epoch:38 step:30030[D loss: 0.338365, acc: 76.56%, op_acc: 45.31%] [G loss: 1.251393]\n",
      "epoch:38 step:30031[D loss: 0.518327, acc: 48.44%, op_acc: 48.44%] [G loss: 1.341170]\n",
      "epoch:38 step:30032[D loss: 0.434889, acc: 66.41%, op_acc: 42.97%] [G loss: 1.525087]\n",
      "epoch:38 step:30033[D loss: 0.410143, acc: 67.19%, op_acc: 45.31%] [G loss: 1.518871]\n",
      "epoch:38 step:30034[D loss: 0.310406, acc: 80.47%, op_acc: 55.47%] [G loss: 1.261041]\n",
      "epoch:38 step:30035[D loss: 0.392233, acc: 71.09%, op_acc: 45.31%] [G loss: 1.455720]\n",
      "epoch:38 step:30036[D loss: 0.342974, acc: 74.22%, op_acc: 49.22%] [G loss: 2.061739]\n",
      "epoch:38 step:30037[D loss: 0.285304, acc: 84.38%, op_acc: 59.38%] [G loss: 1.818147]\n",
      "epoch:38 step:30038[D loss: 0.480906, acc: 58.59%, op_acc: 42.97%] [G loss: 1.523370]\n",
      "epoch:38 step:30039[D loss: 0.301786, acc: 78.12%, op_acc: 56.25%] [G loss: 1.599491]\n",
      "epoch:38 step:30040[D loss: 0.384221, acc: 72.66%, op_acc: 51.56%] [G loss: 1.452218]\n",
      "epoch:38 step:30041[D loss: 0.344779, acc: 75.00%, op_acc: 55.47%] [G loss: 1.373395]\n",
      "epoch:38 step:30042[D loss: 0.357715, acc: 71.88%, op_acc: 42.97%] [G loss: 1.189204]\n",
      "epoch:38 step:30043[D loss: 0.338606, acc: 73.44%, op_acc: 56.25%] [G loss: 1.632894]\n",
      "epoch:38 step:30044[D loss: 0.317843, acc: 78.91%, op_acc: 54.69%] [G loss: 1.406213]\n",
      "epoch:38 step:30045[D loss: 0.389977, acc: 72.66%, op_acc: 43.75%] [G loss: 1.458835]\n",
      "epoch:38 step:30046[D loss: 0.314458, acc: 75.78%, op_acc: 50.78%] [G loss: 1.847352]\n",
      "epoch:38 step:30047[D loss: 0.336340, acc: 73.44%, op_acc: 52.34%] [G loss: 1.825987]\n",
      "epoch:38 step:30048[D loss: 0.365428, acc: 73.44%, op_acc: 61.72%] [G loss: 1.478706]\n",
      "epoch:38 step:30049[D loss: 0.252159, acc: 83.59%, op_acc: 66.41%] [G loss: 1.887342]\n",
      "epoch:38 step:30050[D loss: 0.283525, acc: 80.47%, op_acc: 60.16%] [G loss: 2.070127]\n",
      "epoch:38 step:30051[D loss: 0.392542, acc: 67.97%, op_acc: 57.03%] [G loss: 1.659925]\n",
      "epoch:38 step:30052[D loss: 0.301820, acc: 75.78%, op_acc: 59.38%] [G loss: 1.810481]\n",
      "epoch:38 step:30053[D loss: 0.346215, acc: 74.22%, op_acc: 56.25%] [G loss: 1.866309]\n",
      "epoch:38 step:30054[D loss: 0.293243, acc: 80.47%, op_acc: 55.47%] [G loss: 1.805517]\n",
      "epoch:38 step:30055[D loss: 0.284155, acc: 82.81%, op_acc: 60.16%] [G loss: 2.106895]\n",
      "epoch:38 step:30056[D loss: 0.247804, acc: 89.06%, op_acc: 61.72%] [G loss: 2.123240]\n",
      "epoch:38 step:30057[D loss: 0.268847, acc: 82.03%, op_acc: 60.16%] [G loss: 1.835600]\n",
      "epoch:38 step:30058[D loss: 0.361346, acc: 75.78%, op_acc: 49.22%] [G loss: 1.776657]\n",
      "epoch:38 step:30059[D loss: 0.250825, acc: 85.94%, op_acc: 58.59%] [G loss: 2.464417]\n",
      "epoch:38 step:30060[D loss: 0.268290, acc: 82.03%, op_acc: 54.69%] [G loss: 1.978042]\n",
      "epoch:38 step:30061[D loss: 0.198417, acc: 88.28%, op_acc: 71.88%] [G loss: 1.586913]\n",
      "epoch:38 step:30062[D loss: 0.198890, acc: 93.75%, op_acc: 60.94%] [G loss: 1.633343]\n",
      "epoch:38 step:30063[D loss: 0.363916, acc: 69.53%, op_acc: 48.44%] [G loss: 1.734675]\n",
      "epoch:38 step:30064[D loss: 0.298852, acc: 78.91%, op_acc: 50.78%] [G loss: 2.090499]\n",
      "epoch:38 step:30065[D loss: 0.465346, acc: 58.59%, op_acc: 46.88%] [G loss: 2.140239]\n",
      "epoch:38 step:30066[D loss: 0.420127, acc: 67.97%, op_acc: 47.66%] [G loss: 1.007651]\n",
      "epoch:38 step:30067[D loss: 0.381655, acc: 70.31%, op_acc: 50.00%] [G loss: 2.112783]\n",
      "epoch:38 step:30068[D loss: 0.355695, acc: 70.31%, op_acc: 52.34%] [G loss: 2.135452]\n",
      "epoch:38 step:30069[D loss: 0.424542, acc: 65.62%, op_acc: 53.12%] [G loss: 2.078097]\n",
      "epoch:38 step:30070[D loss: 0.350048, acc: 71.09%, op_acc: 51.56%] [G loss: 2.006811]\n",
      "epoch:38 step:30071[D loss: 0.447208, acc: 62.50%, op_acc: 42.97%] [G loss: 2.097176]\n",
      "epoch:38 step:30072[D loss: 0.341418, acc: 76.56%, op_acc: 54.69%] [G loss: 1.862270]\n",
      "epoch:38 step:30073[D loss: 0.472847, acc: 60.16%, op_acc: 39.06%] [G loss: 1.695532]\n",
      "epoch:38 step:30074[D loss: 0.401113, acc: 69.53%, op_acc: 51.56%] [G loss: 1.099321]\n",
      "epoch:38 step:30075[D loss: 0.395857, acc: 67.19%, op_acc: 43.75%] [G loss: 1.418806]\n",
      "epoch:38 step:30076[D loss: 0.426644, acc: 66.41%, op_acc: 41.41%] [G loss: 2.049595]\n",
      "epoch:38 step:30077[D loss: 0.343984, acc: 72.66%, op_acc: 53.12%] [G loss: 1.568701]\n",
      "epoch:38 step:30078[D loss: 0.366040, acc: 75.78%, op_acc: 54.69%] [G loss: 1.741369]\n",
      "epoch:38 step:30079[D loss: 0.282614, acc: 78.91%, op_acc: 50.00%] [G loss: 1.634038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30080[D loss: 0.378638, acc: 70.31%, op_acc: 44.53%] [G loss: 1.697496]\n",
      "epoch:38 step:30081[D loss: 0.347668, acc: 71.88%, op_acc: 53.91%] [G loss: 1.454995]\n",
      "epoch:38 step:30082[D loss: 0.326693, acc: 76.56%, op_acc: 59.38%] [G loss: 1.653766]\n",
      "epoch:38 step:30083[D loss: 0.411378, acc: 64.84%, op_acc: 42.97%] [G loss: 1.327337]\n",
      "epoch:38 step:30084[D loss: 0.356251, acc: 79.69%, op_acc: 47.66%] [G loss: 1.532685]\n",
      "epoch:38 step:30085[D loss: 0.272943, acc: 83.59%, op_acc: 53.91%] [G loss: 1.830528]\n",
      "epoch:38 step:30086[D loss: 0.313353, acc: 75.00%, op_acc: 54.69%] [G loss: 1.718133]\n",
      "epoch:38 step:30087[D loss: 0.462180, acc: 60.94%, op_acc: 45.31%] [G loss: 1.420394]\n",
      "epoch:38 step:30088[D loss: 0.305650, acc: 75.78%, op_acc: 52.34%] [G loss: 1.485816]\n",
      "epoch:38 step:30089[D loss: 0.403566, acc: 65.62%, op_acc: 53.12%] [G loss: 1.156852]\n",
      "epoch:38 step:30090[D loss: 0.421301, acc: 61.72%, op_acc: 46.09%] [G loss: 1.488755]\n",
      "epoch:38 step:30091[D loss: 0.454314, acc: 57.81%, op_acc: 43.75%] [G loss: 1.664967]\n",
      "epoch:38 step:30092[D loss: 0.382807, acc: 67.19%, op_acc: 55.47%] [G loss: 2.181618]\n",
      "epoch:38 step:30093[D loss: 0.277274, acc: 85.16%, op_acc: 58.59%] [G loss: 1.945522]\n",
      "epoch:38 step:30094[D loss: 0.340570, acc: 75.00%, op_acc: 64.06%] [G loss: 2.161650]\n",
      "epoch:38 step:30095[D loss: 0.282747, acc: 83.59%, op_acc: 57.81%] [G loss: 2.147958]\n",
      "epoch:38 step:30096[D loss: 0.294557, acc: 81.25%, op_acc: 53.12%] [G loss: 1.629154]\n",
      "epoch:38 step:30097[D loss: 0.315535, acc: 78.12%, op_acc: 47.66%] [G loss: 1.931621]\n",
      "epoch:38 step:30098[D loss: 0.541039, acc: 51.56%, op_acc: 42.97%] [G loss: 1.393159]\n",
      "epoch:38 step:30099[D loss: 0.259436, acc: 84.38%, op_acc: 57.81%] [G loss: 1.939449]\n",
      "epoch:38 step:30100[D loss: 0.314927, acc: 76.56%, op_acc: 50.00%] [G loss: 1.337902]\n",
      "epoch:38 step:30101[D loss: 0.344115, acc: 72.66%, op_acc: 52.34%] [G loss: 1.594719]\n",
      "epoch:38 step:30102[D loss: 0.491825, acc: 60.16%, op_acc: 38.28%] [G loss: 1.725853]\n",
      "epoch:38 step:30103[D loss: 0.310884, acc: 82.81%, op_acc: 52.34%] [G loss: 2.003581]\n",
      "epoch:38 step:30104[D loss: 0.444220, acc: 67.97%, op_acc: 45.31%] [G loss: 1.658615]\n",
      "epoch:38 step:30105[D loss: 0.441881, acc: 64.06%, op_acc: 46.88%] [G loss: 1.247756]\n",
      "epoch:38 step:30106[D loss: 0.519907, acc: 53.12%, op_acc: 42.97%] [G loss: 1.700846]\n",
      "epoch:38 step:30107[D loss: 0.404048, acc: 66.41%, op_acc: 43.75%] [G loss: 1.334215]\n",
      "epoch:38 step:30108[D loss: 0.336186, acc: 70.31%, op_acc: 46.09%] [G loss: 1.329551]\n",
      "epoch:38 step:30109[D loss: 0.519923, acc: 57.03%, op_acc: 38.28%] [G loss: 1.814320]\n",
      "epoch:38 step:30110[D loss: 0.338338, acc: 79.69%, op_acc: 47.66%] [G loss: 2.184296]\n",
      "epoch:38 step:30111[D loss: 0.394970, acc: 64.06%, op_acc: 48.44%] [G loss: 1.843593]\n",
      "epoch:38 step:30112[D loss: 0.481860, acc: 55.47%, op_acc: 45.31%] [G loss: 1.551330]\n",
      "epoch:38 step:30113[D loss: 0.458890, acc: 60.16%, op_acc: 42.19%] [G loss: 1.478462]\n",
      "epoch:38 step:30114[D loss: 0.465117, acc: 62.50%, op_acc: 46.88%] [G loss: 1.258825]\n",
      "epoch:38 step:30115[D loss: 0.487750, acc: 59.38%, op_acc: 40.62%] [G loss: 1.214028]\n",
      "epoch:38 step:30116[D loss: 0.287069, acc: 84.38%, op_acc: 52.34%] [G loss: 1.348755]\n",
      "epoch:38 step:30117[D loss: 0.375789, acc: 67.97%, op_acc: 42.19%] [G loss: 1.160755]\n",
      "epoch:38 step:30118[D loss: 0.425479, acc: 64.84%, op_acc: 41.41%] [G loss: 1.385643]\n",
      "epoch:38 step:30119[D loss: 0.407311, acc: 67.19%, op_acc: 52.34%] [G loss: 1.533291]\n",
      "epoch:38 step:30120[D loss: 0.315190, acc: 75.00%, op_acc: 57.81%] [G loss: 1.292668]\n",
      "epoch:38 step:30121[D loss: 0.366278, acc: 68.75%, op_acc: 48.44%] [G loss: 1.545759]\n",
      "epoch:38 step:30122[D loss: 0.311100, acc: 76.56%, op_acc: 54.69%] [G loss: 1.728026]\n",
      "epoch:38 step:30123[D loss: 0.407608, acc: 65.62%, op_acc: 40.62%] [G loss: 1.006424]\n",
      "epoch:38 step:30124[D loss: 0.360511, acc: 73.44%, op_acc: 47.66%] [G loss: 1.454843]\n",
      "epoch:38 step:30125[D loss: 0.353668, acc: 75.00%, op_acc: 46.88%] [G loss: 1.506607]\n",
      "epoch:38 step:30126[D loss: 0.327897, acc: 75.00%, op_acc: 58.59%] [G loss: 1.579952]\n",
      "epoch:38 step:30127[D loss: 0.314545, acc: 78.91%, op_acc: 50.78%] [G loss: 1.569871]\n",
      "epoch:38 step:30128[D loss: 0.369900, acc: 73.44%, op_acc: 53.12%] [G loss: 1.681857]\n",
      "epoch:38 step:30129[D loss: 0.303032, acc: 76.56%, op_acc: 61.72%] [G loss: 1.397740]\n",
      "epoch:38 step:30130[D loss: 0.275130, acc: 82.81%, op_acc: 52.34%] [G loss: 1.561194]\n",
      "epoch:38 step:30131[D loss: 0.330358, acc: 72.66%, op_acc: 48.44%] [G loss: 1.550879]\n",
      "epoch:38 step:30132[D loss: 0.333068, acc: 76.56%, op_acc: 45.31%] [G loss: 1.101491]\n",
      "epoch:38 step:30133[D loss: 0.395939, acc: 70.31%, op_acc: 52.34%] [G loss: 1.536393]\n",
      "epoch:38 step:30134[D loss: 0.323770, acc: 78.91%, op_acc: 54.69%] [G loss: 1.650299]\n",
      "epoch:38 step:30135[D loss: 0.436676, acc: 64.06%, op_acc: 46.09%] [G loss: 1.308499]\n",
      "epoch:38 step:30136[D loss: 0.237362, acc: 88.28%, op_acc: 58.59%] [G loss: 1.450329]\n",
      "epoch:38 step:30137[D loss: 0.283745, acc: 78.12%, op_acc: 58.59%] [G loss: 1.518268]\n",
      "epoch:38 step:30138[D loss: 0.245261, acc: 88.28%, op_acc: 60.16%] [G loss: 1.898297]\n",
      "epoch:38 step:30139[D loss: 0.350002, acc: 72.66%, op_acc: 48.44%] [G loss: 1.894991]\n",
      "epoch:38 step:30140[D loss: 0.340598, acc: 71.09%, op_acc: 48.44%] [G loss: 1.429754]\n",
      "epoch:38 step:30141[D loss: 0.449932, acc: 61.72%, op_acc: 47.66%] [G loss: 1.493463]\n",
      "epoch:38 step:30142[D loss: 0.418617, acc: 68.75%, op_acc: 44.53%] [G loss: 1.618786]\n",
      "epoch:38 step:30143[D loss: 0.344388, acc: 71.88%, op_acc: 40.62%] [G loss: 0.924631]\n",
      "epoch:38 step:30144[D loss: 0.356023, acc: 74.22%, op_acc: 48.44%] [G loss: 2.296315]\n",
      "epoch:38 step:30145[D loss: 0.401297, acc: 70.31%, op_acc: 50.00%] [G loss: 1.676583]\n",
      "epoch:38 step:30146[D loss: 0.362452, acc: 67.97%, op_acc: 50.78%] [G loss: 1.644587]\n",
      "epoch:38 step:30147[D loss: 0.451616, acc: 62.50%, op_acc: 46.09%] [G loss: 1.897124]\n",
      "epoch:38 step:30148[D loss: 0.308317, acc: 78.91%, op_acc: 56.25%] [G loss: 1.783497]\n",
      "epoch:38 step:30149[D loss: 0.395012, acc: 67.97%, op_acc: 46.09%] [G loss: 1.258268]\n",
      "epoch:38 step:30150[D loss: 0.293871, acc: 80.47%, op_acc: 57.03%] [G loss: 2.061808]\n",
      "epoch:38 step:30151[D loss: 0.402870, acc: 64.84%, op_acc: 46.09%] [G loss: 1.621339]\n",
      "epoch:38 step:30152[D loss: 0.509171, acc: 53.91%, op_acc: 40.62%] [G loss: 1.581569]\n",
      "epoch:38 step:30153[D loss: 0.418127, acc: 65.62%, op_acc: 50.00%] [G loss: 1.773145]\n",
      "epoch:38 step:30154[D loss: 0.426640, acc: 64.84%, op_acc: 38.28%] [G loss: 1.567501]\n",
      "epoch:38 step:30155[D loss: 0.338869, acc: 78.12%, op_acc: 55.47%] [G loss: 2.109062]\n",
      "epoch:38 step:30156[D loss: 0.349672, acc: 73.44%, op_acc: 54.69%] [G loss: 1.670315]\n",
      "epoch:38 step:30157[D loss: 0.392573, acc: 67.19%, op_acc: 48.44%] [G loss: 1.522881]\n",
      "epoch:38 step:30158[D loss: 0.442963, acc: 64.06%, op_acc: 39.06%] [G loss: 1.746263]\n",
      "epoch:38 step:30159[D loss: 0.396675, acc: 67.19%, op_acc: 48.44%] [G loss: 1.636356]\n",
      "epoch:38 step:30160[D loss: 0.280243, acc: 84.38%, op_acc: 58.59%] [G loss: 1.434424]\n",
      "epoch:38 step:30161[D loss: 0.405723, acc: 67.19%, op_acc: 45.31%] [G loss: 1.775904]\n",
      "epoch:38 step:30162[D loss: 0.368021, acc: 67.19%, op_acc: 53.91%] [G loss: 1.422699]\n",
      "epoch:38 step:30163[D loss: 0.318233, acc: 78.12%, op_acc: 50.78%] [G loss: 2.023891]\n",
      "epoch:38 step:30164[D loss: 0.319002, acc: 80.47%, op_acc: 45.31%] [G loss: 1.610749]\n",
      "epoch:38 step:30165[D loss: 0.511895, acc: 53.12%, op_acc: 43.75%] [G loss: 1.818602]\n",
      "epoch:38 step:30166[D loss: 0.546322, acc: 47.66%, op_acc: 32.81%] [G loss: 1.158925]\n",
      "epoch:38 step:30167[D loss: 0.369417, acc: 74.22%, op_acc: 45.31%] [G loss: 1.805011]\n",
      "epoch:38 step:30168[D loss: 0.325615, acc: 75.00%, op_acc: 53.91%] [G loss: 1.598135]\n",
      "epoch:38 step:30169[D loss: 0.489647, acc: 60.94%, op_acc: 38.28%] [G loss: 1.469762]\n",
      "epoch:38 step:30170[D loss: 0.394854, acc: 70.31%, op_acc: 46.88%] [G loss: 1.390614]\n",
      "epoch:38 step:30171[D loss: 0.445735, acc: 58.59%, op_acc: 39.84%] [G loss: 1.755089]\n",
      "epoch:38 step:30172[D loss: 0.330548, acc: 71.88%, op_acc: 54.69%] [G loss: 1.879117]\n",
      "epoch:38 step:30173[D loss: 0.359795, acc: 73.44%, op_acc: 49.22%] [G loss: 1.500883]\n",
      "epoch:38 step:30174[D loss: 0.420340, acc: 65.62%, op_acc: 46.09%] [G loss: 1.383012]\n",
      "epoch:38 step:30175[D loss: 0.419485, acc: 66.41%, op_acc: 42.97%] [G loss: 1.422752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30176[D loss: 0.395364, acc: 76.56%, op_acc: 39.06%] [G loss: 1.295644]\n",
      "epoch:38 step:30177[D loss: 0.378084, acc: 71.88%, op_acc: 39.84%] [G loss: 1.163362]\n",
      "epoch:38 step:30178[D loss: 0.358151, acc: 72.66%, op_acc: 53.12%] [G loss: 2.304569]\n",
      "epoch:38 step:30179[D loss: 0.375157, acc: 70.31%, op_acc: 46.88%] [G loss: 1.706351]\n",
      "epoch:38 step:30180[D loss: 0.399355, acc: 69.53%, op_acc: 50.00%] [G loss: 1.732548]\n",
      "epoch:38 step:30181[D loss: 0.346762, acc: 75.00%, op_acc: 49.22%] [G loss: 1.574870]\n",
      "epoch:38 step:30182[D loss: 0.445242, acc: 62.50%, op_acc: 48.44%] [G loss: 1.495443]\n",
      "epoch:38 step:30183[D loss: 0.415317, acc: 62.50%, op_acc: 48.44%] [G loss: 1.438482]\n",
      "epoch:38 step:30184[D loss: 0.336884, acc: 74.22%, op_acc: 48.44%] [G loss: 1.308342]\n",
      "epoch:38 step:30185[D loss: 0.436613, acc: 63.28%, op_acc: 43.75%] [G loss: 1.975541]\n",
      "epoch:38 step:30186[D loss: 0.329230, acc: 80.47%, op_acc: 57.81%] [G loss: 1.533372]\n",
      "epoch:38 step:30187[D loss: 0.400240, acc: 67.19%, op_acc: 41.41%] [G loss: 1.616454]\n",
      "epoch:38 step:30188[D loss: 0.307873, acc: 82.81%, op_acc: 49.22%] [G loss: 1.587567]\n",
      "epoch:38 step:30189[D loss: 0.375719, acc: 67.19%, op_acc: 50.00%] [G loss: 1.245530]\n",
      "epoch:38 step:30190[D loss: 0.370999, acc: 71.09%, op_acc: 42.97%] [G loss: 1.425633]\n",
      "epoch:38 step:30191[D loss: 0.368651, acc: 68.75%, op_acc: 49.22%] [G loss: 1.493473]\n",
      "epoch:38 step:30192[D loss: 0.372771, acc: 72.66%, op_acc: 40.62%] [G loss: 1.248033]\n",
      "epoch:38 step:30193[D loss: 0.286800, acc: 83.59%, op_acc: 50.00%] [G loss: 1.213630]\n",
      "epoch:38 step:30194[D loss: 0.274416, acc: 80.47%, op_acc: 53.12%] [G loss: 1.482051]\n",
      "epoch:38 step:30195[D loss: 0.398650, acc: 67.97%, op_acc: 41.41%] [G loss: 1.305611]\n",
      "epoch:38 step:30196[D loss: 0.377330, acc: 67.19%, op_acc: 53.12%] [G loss: 1.427989]\n",
      "epoch:38 step:30197[D loss: 0.275560, acc: 82.03%, op_acc: 52.34%] [G loss: 1.266893]\n",
      "epoch:38 step:30198[D loss: 0.407992, acc: 71.88%, op_acc: 45.31%] [G loss: 1.295829]\n",
      "epoch:38 step:30199[D loss: 0.355245, acc: 76.56%, op_acc: 50.00%] [G loss: 1.478655]\n",
      "epoch:38 step:30200[D loss: 0.365996, acc: 73.44%, op_acc: 40.62%] [G loss: 1.310421]\n",
      "epoch:38 step:30201[D loss: 0.377395, acc: 71.88%, op_acc: 50.00%] [G loss: 1.535095]\n",
      "epoch:38 step:30202[D loss: 0.369324, acc: 71.88%, op_acc: 53.12%] [G loss: 1.415023]\n",
      "epoch:38 step:30203[D loss: 0.336710, acc: 74.22%, op_acc: 49.22%] [G loss: 1.459804]\n",
      "epoch:38 step:30204[D loss: 0.466317, acc: 63.28%, op_acc: 47.66%] [G loss: 1.206454]\n",
      "epoch:38 step:30205[D loss: 0.472625, acc: 57.81%, op_acc: 37.50%] [G loss: 1.369606]\n",
      "epoch:38 step:30206[D loss: 0.366786, acc: 69.53%, op_acc: 46.88%] [G loss: 1.360167]\n",
      "epoch:38 step:30207[D loss: 0.312379, acc: 75.00%, op_acc: 61.72%] [G loss: 1.656779]\n",
      "epoch:38 step:30208[D loss: 0.357842, acc: 75.00%, op_acc: 49.22%] [G loss: 1.482796]\n",
      "epoch:38 step:30209[D loss: 0.316812, acc: 80.47%, op_acc: 50.78%] [G loss: 1.474126]\n",
      "epoch:38 step:30210[D loss: 0.380889, acc: 68.75%, op_acc: 52.34%] [G loss: 1.085021]\n",
      "epoch:38 step:30211[D loss: 0.388532, acc: 64.84%, op_acc: 42.97%] [G loss: 1.430660]\n",
      "epoch:38 step:30212[D loss: 0.373218, acc: 71.09%, op_acc: 46.88%] [G loss: 1.478863]\n",
      "epoch:38 step:30213[D loss: 0.375891, acc: 71.88%, op_acc: 49.22%] [G loss: 1.390461]\n",
      "epoch:38 step:30214[D loss: 0.370865, acc: 71.88%, op_acc: 55.47%] [G loss: 1.860074]\n",
      "epoch:38 step:30215[D loss: 0.389121, acc: 72.66%, op_acc: 45.31%] [G loss: 1.498787]\n",
      "epoch:38 step:30216[D loss: 0.394958, acc: 68.75%, op_acc: 46.09%] [G loss: 1.452764]\n",
      "epoch:38 step:30217[D loss: 0.439926, acc: 60.16%, op_acc: 48.44%] [G loss: 1.299321]\n",
      "epoch:38 step:30218[D loss: 0.351749, acc: 75.78%, op_acc: 50.78%] [G loss: 1.626918]\n",
      "epoch:38 step:30219[D loss: 0.312458, acc: 78.12%, op_acc: 52.34%] [G loss: 1.503257]\n",
      "epoch:38 step:30220[D loss: 0.362416, acc: 75.00%, op_acc: 53.12%] [G loss: 1.574042]\n",
      "epoch:38 step:30221[D loss: 0.332190, acc: 71.09%, op_acc: 45.31%] [G loss: 1.827458]\n",
      "epoch:38 step:30222[D loss: 0.331113, acc: 79.69%, op_acc: 57.03%] [G loss: 1.624587]\n",
      "epoch:38 step:30223[D loss: 0.271611, acc: 85.16%, op_acc: 57.03%] [G loss: 1.231666]\n",
      "epoch:38 step:30224[D loss: 0.545626, acc: 47.66%, op_acc: 42.19%] [G loss: 1.473099]\n",
      "epoch:38 step:30225[D loss: 0.496954, acc: 58.59%, op_acc: 37.50%] [G loss: 1.818928]\n",
      "epoch:38 step:30226[D loss: 0.339935, acc: 80.47%, op_acc: 46.09%] [G loss: 1.476697]\n",
      "epoch:38 step:30227[D loss: 0.357171, acc: 75.78%, op_acc: 46.09%] [G loss: 1.562042]\n",
      "epoch:38 step:30228[D loss: 0.325740, acc: 74.22%, op_acc: 53.12%] [G loss: 1.248485]\n",
      "epoch:38 step:30229[D loss: 0.396907, acc: 71.09%, op_acc: 48.44%] [G loss: 1.568564]\n",
      "epoch:38 step:30230[D loss: 0.483141, acc: 55.47%, op_acc: 40.62%] [G loss: 1.881716]\n",
      "epoch:38 step:30231[D loss: 0.355225, acc: 71.88%, op_acc: 53.12%] [G loss: 1.763874]\n",
      "epoch:38 step:30232[D loss: 0.349903, acc: 72.66%, op_acc: 46.09%] [G loss: 1.392078]\n",
      "epoch:38 step:30233[D loss: 0.268830, acc: 79.69%, op_acc: 51.56%] [G loss: 1.697869]\n",
      "epoch:38 step:30234[D loss: 0.393338, acc: 66.41%, op_acc: 50.78%] [G loss: 1.244712]\n",
      "epoch:38 step:30235[D loss: 0.363267, acc: 72.66%, op_acc: 42.19%] [G loss: 1.487125]\n",
      "epoch:38 step:30236[D loss: 0.333833, acc: 75.78%, op_acc: 50.00%] [G loss: 1.334326]\n",
      "epoch:38 step:30237[D loss: 0.299682, acc: 78.91%, op_acc: 49.22%] [G loss: 1.705885]\n",
      "epoch:38 step:30238[D loss: 0.374472, acc: 71.88%, op_acc: 49.22%] [G loss: 1.503773]\n",
      "epoch:38 step:30239[D loss: 0.337001, acc: 71.09%, op_acc: 48.44%] [G loss: 1.436715]\n",
      "epoch:38 step:30240[D loss: 0.295401, acc: 77.34%, op_acc: 57.03%] [G loss: 1.726416]\n",
      "epoch:38 step:30241[D loss: 0.393070, acc: 69.53%, op_acc: 42.97%] [G loss: 1.424172]\n",
      "epoch:38 step:30242[D loss: 0.379305, acc: 72.66%, op_acc: 52.34%] [G loss: 1.126839]\n",
      "epoch:38 step:30243[D loss: 0.382502, acc: 68.75%, op_acc: 46.09%] [G loss: 1.495107]\n",
      "epoch:38 step:30244[D loss: 0.411024, acc: 68.75%, op_acc: 50.00%] [G loss: 1.448640]\n",
      "epoch:38 step:30245[D loss: 0.359503, acc: 67.19%, op_acc: 48.44%] [G loss: 1.579473]\n",
      "epoch:38 step:30246[D loss: 0.319415, acc: 79.69%, op_acc: 53.12%] [G loss: 1.543545]\n",
      "epoch:38 step:30247[D loss: 0.284264, acc: 78.91%, op_acc: 57.03%] [G loss: 1.783787]\n",
      "epoch:38 step:30248[D loss: 0.273937, acc: 82.03%, op_acc: 67.19%] [G loss: 1.609633]\n",
      "epoch:38 step:30249[D loss: 0.487434, acc: 57.03%, op_acc: 42.97%] [G loss: 1.520098]\n",
      "epoch:38 step:30250[D loss: 0.381265, acc: 67.97%, op_acc: 51.56%] [G loss: 1.380686]\n",
      "epoch:38 step:30251[D loss: 0.299302, acc: 78.12%, op_acc: 53.12%] [G loss: 1.463838]\n",
      "epoch:38 step:30252[D loss: 0.383351, acc: 71.09%, op_acc: 43.75%] [G loss: 1.178460]\n",
      "epoch:38 step:30253[D loss: 0.316493, acc: 78.91%, op_acc: 48.44%] [G loss: 1.365547]\n",
      "epoch:38 step:30254[D loss: 0.365091, acc: 65.62%, op_acc: 44.53%] [G loss: 1.453155]\n",
      "epoch:38 step:30255[D loss: 0.325978, acc: 82.81%, op_acc: 49.22%] [G loss: 1.571081]\n",
      "epoch:38 step:30256[D loss: 0.415133, acc: 64.06%, op_acc: 43.75%] [G loss: 1.915772]\n",
      "epoch:38 step:30257[D loss: 0.302732, acc: 81.25%, op_acc: 55.47%] [G loss: 1.284720]\n",
      "epoch:38 step:30258[D loss: 0.357254, acc: 71.09%, op_acc: 54.69%] [G loss: 2.086979]\n",
      "epoch:38 step:30259[D loss: 0.391879, acc: 68.75%, op_acc: 49.22%] [G loss: 1.926649]\n",
      "epoch:38 step:30260[D loss: 0.346846, acc: 74.22%, op_acc: 50.78%] [G loss: 1.920135]\n",
      "epoch:38 step:30261[D loss: 0.321708, acc: 75.78%, op_acc: 46.88%] [G loss: 1.853072]\n",
      "epoch:38 step:30262[D loss: 0.407779, acc: 69.53%, op_acc: 43.75%] [G loss: 2.182256]\n",
      "epoch:38 step:30263[D loss: 0.386698, acc: 70.31%, op_acc: 46.09%] [G loss: 1.811218]\n",
      "epoch:38 step:30264[D loss: 0.329245, acc: 75.00%, op_acc: 59.38%] [G loss: 1.703092]\n",
      "epoch:38 step:30265[D loss: 0.284893, acc: 82.03%, op_acc: 59.38%] [G loss: 1.571297]\n",
      "epoch:38 step:30266[D loss: 0.385250, acc: 67.19%, op_acc: 50.78%] [G loss: 1.527172]\n",
      "epoch:38 step:30267[D loss: 0.316870, acc: 78.12%, op_acc: 48.44%] [G loss: 1.737365]\n",
      "epoch:38 step:30268[D loss: 0.393191, acc: 70.31%, op_acc: 47.66%] [G loss: 2.025395]\n",
      "epoch:38 step:30269[D loss: 0.442375, acc: 65.62%, op_acc: 45.31%] [G loss: 1.564936]\n",
      "epoch:38 step:30270[D loss: 0.489036, acc: 54.69%, op_acc: 43.75%] [G loss: 1.814252]\n",
      "epoch:38 step:30271[D loss: 0.475778, acc: 57.81%, op_acc: 49.22%] [G loss: 1.478640]\n",
      "epoch:38 step:30272[D loss: 0.442313, acc: 56.25%, op_acc: 45.31%] [G loss: 1.755198]\n",
      "epoch:38 step:30273[D loss: 0.412554, acc: 65.62%, op_acc: 42.97%] [G loss: 1.486726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30274[D loss: 0.413606, acc: 60.16%, op_acc: 50.00%] [G loss: 1.534001]\n",
      "epoch:38 step:30275[D loss: 0.387240, acc: 67.97%, op_acc: 43.75%] [G loss: 1.875778]\n",
      "epoch:38 step:30276[D loss: 0.354599, acc: 74.22%, op_acc: 47.66%] [G loss: 1.963816]\n",
      "epoch:38 step:30277[D loss: 0.358905, acc: 69.53%, op_acc: 47.66%] [G loss: 1.659488]\n",
      "epoch:38 step:30278[D loss: 0.314537, acc: 78.12%, op_acc: 47.66%] [G loss: 1.771102]\n",
      "epoch:38 step:30279[D loss: 0.336076, acc: 73.44%, op_acc: 48.44%] [G loss: 1.620724]\n",
      "epoch:38 step:30280[D loss: 0.435598, acc: 60.94%, op_acc: 42.97%] [G loss: 1.420593]\n",
      "epoch:38 step:30281[D loss: 0.359246, acc: 69.53%, op_acc: 47.66%] [G loss: 1.785265]\n",
      "epoch:38 step:30282[D loss: 0.382983, acc: 72.66%, op_acc: 40.62%] [G loss: 1.366976]\n",
      "epoch:38 step:30283[D loss: 0.375878, acc: 67.19%, op_acc: 44.53%] [G loss: 1.679100]\n",
      "epoch:38 step:30284[D loss: 0.389733, acc: 67.97%, op_acc: 48.44%] [G loss: 1.721664]\n",
      "epoch:38 step:30285[D loss: 0.362132, acc: 70.31%, op_acc: 56.25%] [G loss: 1.687679]\n",
      "epoch:38 step:30286[D loss: 0.367126, acc: 63.28%, op_acc: 46.09%] [G loss: 1.275205]\n",
      "epoch:38 step:30287[D loss: 0.473109, acc: 57.81%, op_acc: 46.09%] [G loss: 1.572381]\n",
      "epoch:38 step:30288[D loss: 0.446038, acc: 59.38%, op_acc: 44.53%] [G loss: 1.267569]\n",
      "epoch:38 step:30289[D loss: 0.402966, acc: 68.75%, op_acc: 53.12%] [G loss: 1.567035]\n",
      "epoch:38 step:30290[D loss: 0.361836, acc: 69.53%, op_acc: 42.97%] [G loss: 1.582418]\n",
      "epoch:38 step:30291[D loss: 0.420144, acc: 65.62%, op_acc: 42.19%] [G loss: 1.482410]\n",
      "epoch:38 step:30292[D loss: 0.344164, acc: 75.00%, op_acc: 50.78%] [G loss: 1.341317]\n",
      "epoch:38 step:30293[D loss: 0.366790, acc: 75.00%, op_acc: 50.78%] [G loss: 1.448678]\n",
      "epoch:38 step:30294[D loss: 0.365427, acc: 71.88%, op_acc: 53.91%] [G loss: 1.432521]\n",
      "epoch:38 step:30295[D loss: 0.409794, acc: 66.41%, op_acc: 44.53%] [G loss: 1.015734]\n",
      "epoch:38 step:30296[D loss: 0.409457, acc: 62.50%, op_acc: 42.97%] [G loss: 1.561431]\n",
      "epoch:38 step:30297[D loss: 0.412610, acc: 63.28%, op_acc: 41.41%] [G loss: 1.307355]\n",
      "epoch:38 step:30298[D loss: 0.434909, acc: 64.84%, op_acc: 41.41%] [G loss: 1.378495]\n",
      "epoch:38 step:30299[D loss: 0.403083, acc: 67.97%, op_acc: 49.22%] [G loss: 1.508426]\n",
      "epoch:38 step:30300[D loss: 0.406074, acc: 72.66%, op_acc: 42.97%] [G loss: 1.671784]\n",
      "epoch:38 step:30301[D loss: 0.354173, acc: 74.22%, op_acc: 51.56%] [G loss: 1.204418]\n",
      "epoch:38 step:30302[D loss: 0.391248, acc: 67.19%, op_acc: 48.44%] [G loss: 1.423492]\n",
      "epoch:38 step:30303[D loss: 0.340831, acc: 72.66%, op_acc: 50.78%] [G loss: 1.396579]\n",
      "epoch:38 step:30304[D loss: 0.355481, acc: 69.53%, op_acc: 61.72%] [G loss: 1.521687]\n",
      "epoch:38 step:30305[D loss: 0.396743, acc: 67.19%, op_acc: 50.00%] [G loss: 1.291916]\n",
      "epoch:38 step:30306[D loss: 0.449293, acc: 60.94%, op_acc: 48.44%] [G loss: 1.390178]\n",
      "epoch:38 step:30307[D loss: 0.469167, acc: 55.47%, op_acc: 44.53%] [G loss: 1.264102]\n",
      "epoch:38 step:30308[D loss: 0.274879, acc: 79.69%, op_acc: 56.25%] [G loss: 1.265644]\n",
      "epoch:38 step:30309[D loss: 0.379585, acc: 75.78%, op_acc: 41.41%] [G loss: 1.486119]\n",
      "epoch:38 step:30310[D loss: 0.352366, acc: 76.56%, op_acc: 46.88%] [G loss: 1.535219]\n",
      "epoch:38 step:30311[D loss: 0.408428, acc: 69.53%, op_acc: 46.88%] [G loss: 1.169518]\n",
      "epoch:38 step:30312[D loss: 0.343455, acc: 72.66%, op_acc: 53.12%] [G loss: 1.313869]\n",
      "epoch:38 step:30313[D loss: 0.353466, acc: 72.66%, op_acc: 52.34%] [G loss: 1.376245]\n",
      "epoch:38 step:30314[D loss: 0.359162, acc: 70.31%, op_acc: 52.34%] [G loss: 1.581092]\n",
      "epoch:38 step:30315[D loss: 0.385073, acc: 66.41%, op_acc: 46.88%] [G loss: 1.629936]\n",
      "epoch:38 step:30316[D loss: 0.364327, acc: 70.31%, op_acc: 50.78%] [G loss: 1.402218]\n",
      "epoch:38 step:30317[D loss: 0.396295, acc: 66.41%, op_acc: 57.81%] [G loss: 1.302223]\n",
      "epoch:38 step:30318[D loss: 0.499392, acc: 50.78%, op_acc: 43.75%] [G loss: 1.381232]\n",
      "epoch:38 step:30319[D loss: 0.447418, acc: 63.28%, op_acc: 43.75%] [G loss: 1.593173]\n",
      "epoch:38 step:30320[D loss: 0.410717, acc: 62.50%, op_acc: 43.75%] [G loss: 1.383752]\n",
      "epoch:38 step:30321[D loss: 0.454531, acc: 62.50%, op_acc: 42.97%] [G loss: 1.569449]\n",
      "epoch:38 step:30322[D loss: 0.371813, acc: 68.75%, op_acc: 45.31%] [G loss: 1.325769]\n",
      "epoch:38 step:30323[D loss: 0.391996, acc: 71.88%, op_acc: 38.28%] [G loss: 1.595752]\n",
      "epoch:38 step:30324[D loss: 0.451959, acc: 66.41%, op_acc: 42.97%] [G loss: 1.615034]\n",
      "epoch:38 step:30325[D loss: 0.394522, acc: 66.41%, op_acc: 43.75%] [G loss: 1.861102]\n",
      "epoch:38 step:30326[D loss: 0.397216, acc: 67.97%, op_acc: 54.69%] [G loss: 1.473469]\n",
      "epoch:38 step:30327[D loss: 0.385697, acc: 70.31%, op_acc: 45.31%] [G loss: 1.612208]\n",
      "epoch:38 step:30328[D loss: 0.460847, acc: 61.72%, op_acc: 42.97%] [G loss: 1.488093]\n",
      "epoch:38 step:30329[D loss: 0.332008, acc: 71.09%, op_acc: 49.22%] [G loss: 1.097121]\n",
      "epoch:38 step:30330[D loss: 0.439714, acc: 60.16%, op_acc: 44.53%] [G loss: 1.203060]\n",
      "epoch:38 step:30331[D loss: 0.340002, acc: 73.44%, op_acc: 51.56%] [G loss: 1.075287]\n",
      "epoch:38 step:30332[D loss: 0.378329, acc: 66.41%, op_acc: 50.00%] [G loss: 1.206623]\n",
      "epoch:38 step:30333[D loss: 0.410252, acc: 70.31%, op_acc: 39.84%] [G loss: 2.089081]\n",
      "epoch:38 step:30334[D loss: 0.388389, acc: 72.66%, op_acc: 46.09%] [G loss: 1.940532]\n",
      "epoch:38 step:30335[D loss: 0.380507, acc: 67.97%, op_acc: 42.97%] [G loss: 0.898012]\n",
      "epoch:38 step:30336[D loss: 0.360694, acc: 73.44%, op_acc: 53.91%] [G loss: 0.916052]\n",
      "epoch:38 step:30337[D loss: 0.329487, acc: 78.12%, op_acc: 47.66%] [G loss: 1.102014]\n",
      "epoch:38 step:30338[D loss: 0.401149, acc: 67.97%, op_acc: 53.12%] [G loss: 1.302216]\n",
      "epoch:38 step:30339[D loss: 0.361921, acc: 68.75%, op_acc: 53.12%] [G loss: 1.293525]\n",
      "epoch:38 step:30340[D loss: 0.276948, acc: 79.69%, op_acc: 53.91%] [G loss: 1.018728]\n",
      "epoch:38 step:30341[D loss: 0.340812, acc: 72.66%, op_acc: 52.34%] [G loss: 0.953035]\n",
      "epoch:38 step:30342[D loss: 0.307481, acc: 82.81%, op_acc: 51.56%] [G loss: 1.094141]\n",
      "epoch:38 step:30343[D loss: 0.405604, acc: 65.62%, op_acc: 45.31%] [G loss: 1.179286]\n",
      "epoch:38 step:30344[D loss: 0.500364, acc: 53.91%, op_acc: 45.31%] [G loss: 1.521100]\n",
      "epoch:38 step:30345[D loss: 0.328158, acc: 75.00%, op_acc: 53.12%] [G loss: 1.155570]\n",
      "epoch:38 step:30346[D loss: 0.323814, acc: 76.56%, op_acc: 46.09%] [G loss: 1.546188]\n",
      "epoch:38 step:30347[D loss: 0.408690, acc: 67.19%, op_acc: 46.88%] [G loss: 1.121995]\n",
      "epoch:38 step:30348[D loss: 0.382396, acc: 72.66%, op_acc: 48.44%] [G loss: 1.667907]\n",
      "epoch:38 step:30349[D loss: 0.368512, acc: 69.53%, op_acc: 43.75%] [G loss: 1.323209]\n",
      "epoch:38 step:30350[D loss: 0.428495, acc: 70.31%, op_acc: 45.31%] [G loss: 1.208547]\n",
      "epoch:38 step:30351[D loss: 0.396411, acc: 72.66%, op_acc: 46.09%] [G loss: 1.446795]\n",
      "epoch:38 step:30352[D loss: 0.373812, acc: 66.41%, op_acc: 50.00%] [G loss: 1.012257]\n",
      "epoch:38 step:30353[D loss: 0.341299, acc: 76.56%, op_acc: 50.00%] [G loss: 1.143541]\n",
      "epoch:38 step:30354[D loss: 0.369871, acc: 72.66%, op_acc: 42.97%] [G loss: 1.145728]\n",
      "epoch:38 step:30355[D loss: 0.395390, acc: 71.88%, op_acc: 43.75%] [G loss: 0.901926]\n",
      "epoch:38 step:30356[D loss: 0.388389, acc: 69.53%, op_acc: 46.88%] [G loss: 0.950669]\n",
      "epoch:38 step:30357[D loss: 0.341486, acc: 68.75%, op_acc: 55.47%] [G loss: 1.672345]\n",
      "epoch:38 step:30358[D loss: 0.345529, acc: 73.44%, op_acc: 48.44%] [G loss: 1.088815]\n",
      "epoch:38 step:30359[D loss: 0.397057, acc: 69.53%, op_acc: 42.19%] [G loss: 1.172070]\n",
      "epoch:38 step:30360[D loss: 0.290428, acc: 79.69%, op_acc: 57.03%] [G loss: 1.656558]\n",
      "epoch:38 step:30361[D loss: 0.408313, acc: 65.62%, op_acc: 50.78%] [G loss: 1.203943]\n",
      "epoch:38 step:30362[D loss: 0.299683, acc: 78.91%, op_acc: 53.91%] [G loss: 0.997043]\n",
      "epoch:38 step:30363[D loss: 0.306378, acc: 83.59%, op_acc: 51.56%] [G loss: 1.065107]\n",
      "epoch:38 step:30364[D loss: 0.466307, acc: 55.47%, op_acc: 39.06%] [G loss: 1.243951]\n",
      "epoch:38 step:30365[D loss: 0.338390, acc: 74.22%, op_acc: 55.47%] [G loss: 1.228929]\n",
      "epoch:38 step:30366[D loss: 0.391734, acc: 68.75%, op_acc: 49.22%] [G loss: 1.787435]\n",
      "epoch:38 step:30367[D loss: 0.388501, acc: 62.50%, op_acc: 54.69%] [G loss: 1.304477]\n",
      "epoch:38 step:30368[D loss: 0.360378, acc: 71.09%, op_acc: 46.09%] [G loss: 1.267414]\n",
      "epoch:38 step:30369[D loss: 0.383234, acc: 66.41%, op_acc: 52.34%] [G loss: 0.977165]\n",
      "epoch:38 step:30370[D loss: 0.470872, acc: 57.81%, op_acc: 43.75%] [G loss: 1.126432]\n",
      "epoch:38 step:30371[D loss: 0.408360, acc: 69.53%, op_acc: 46.09%] [G loss: 1.257779]\n",
      "epoch:38 step:30372[D loss: 0.335629, acc: 74.22%, op_acc: 53.12%] [G loss: 1.254958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:30373[D loss: 0.392433, acc: 64.84%, op_acc: 49.22%] [G loss: 1.106702]\n",
      "epoch:38 step:30374[D loss: 0.391195, acc: 67.19%, op_acc: 49.22%] [G loss: 1.497437]\n",
      "epoch:38 step:30375[D loss: 0.356879, acc: 76.56%, op_acc: 49.22%] [G loss: 1.254765]\n",
      "epoch:38 step:30376[D loss: 0.388622, acc: 71.09%, op_acc: 44.53%] [G loss: 1.522714]\n",
      "epoch:38 step:30377[D loss: 0.315712, acc: 73.44%, op_acc: 59.38%] [G loss: 1.455979]\n",
      "epoch:38 step:30378[D loss: 0.316927, acc: 85.16%, op_acc: 50.00%] [G loss: 1.343408]\n",
      "epoch:38 step:30379[D loss: 0.402350, acc: 72.66%, op_acc: 35.94%] [G loss: 1.387173]\n",
      "epoch:38 step:30380[D loss: 0.353831, acc: 74.22%, op_acc: 55.47%] [G loss: 1.572120]\n",
      "epoch:38 step:30381[D loss: 0.414335, acc: 64.06%, op_acc: 45.31%] [G loss: 1.372351]\n",
      "epoch:38 step:30382[D loss: 0.270871, acc: 84.38%, op_acc: 53.12%] [G loss: 1.484265]\n",
      "epoch:38 step:30383[D loss: 0.375032, acc: 70.31%, op_acc: 46.09%] [G loss: 1.165722]\n",
      "epoch:38 step:30384[D loss: 0.315814, acc: 77.34%, op_acc: 49.22%] [G loss: 1.374716]\n",
      "epoch:38 step:30385[D loss: 0.369998, acc: 71.09%, op_acc: 46.09%] [G loss: 1.007409]\n",
      "epoch:38 step:30386[D loss: 0.349244, acc: 77.34%, op_acc: 51.56%] [G loss: 1.642587]\n",
      "epoch:38 step:30387[D loss: 0.296448, acc: 80.47%, op_acc: 48.44%] [G loss: 1.439802]\n",
      "epoch:38 step:30388[D loss: 0.388490, acc: 67.19%, op_acc: 44.53%] [G loss: 1.007345]\n",
      "epoch:38 step:30389[D loss: 0.374832, acc: 69.53%, op_acc: 48.44%] [G loss: 1.469822]\n",
      "epoch:38 step:30390[D loss: 0.376777, acc: 68.75%, op_acc: 49.22%] [G loss: 1.410190]\n",
      "epoch:38 step:30391[D loss: 0.347811, acc: 70.31%, op_acc: 57.03%] [G loss: 1.319820]\n",
      "epoch:38 step:30392[D loss: 0.259214, acc: 90.62%, op_acc: 56.25%] [G loss: 1.239704]\n",
      "epoch:38 step:30393[D loss: 0.406693, acc: 64.84%, op_acc: 46.09%] [G loss: 1.028420]\n",
      "epoch:38 step:30394[D loss: 0.352117, acc: 73.44%, op_acc: 50.78%] [G loss: 1.197884]\n",
      "epoch:38 step:30395[D loss: 0.400172, acc: 65.62%, op_acc: 44.53%] [G loss: 1.016469]\n",
      "epoch:38 step:30396[D loss: 0.339935, acc: 77.34%, op_acc: 46.88%] [G loss: 1.377074]\n",
      "epoch:38 step:30397[D loss: 0.342545, acc: 75.00%, op_acc: 51.56%] [G loss: 1.441498]\n",
      "epoch:38 step:30398[D loss: 0.334077, acc: 80.47%, op_acc: 52.34%] [G loss: 1.484527]\n",
      "epoch:38 step:30399[D loss: 0.311242, acc: 75.00%, op_acc: 57.81%] [G loss: 1.592319]\n",
      "epoch:38 step:30400[D loss: 0.308907, acc: 79.69%, op_acc: 52.34%] [G loss: 1.644650]\n",
      "epoch:38 step:30401[D loss: 0.312805, acc: 75.00%, op_acc: 51.56%] [G loss: 1.513495]\n",
      "epoch:38 step:30402[D loss: 0.375044, acc: 77.34%, op_acc: 49.22%] [G loss: 1.748353]\n",
      "epoch:38 step:30403[D loss: 0.299512, acc: 81.25%, op_acc: 54.69%] [G loss: 1.485986]\n",
      "epoch:38 step:30404[D loss: 0.306568, acc: 79.69%, op_acc: 46.09%] [G loss: 1.006725]\n",
      "epoch:38 step:30405[D loss: 0.404582, acc: 68.75%, op_acc: 39.84%] [G loss: 1.341831]\n",
      "epoch:38 step:30406[D loss: 0.421785, acc: 60.94%, op_acc: 39.84%] [G loss: 1.704367]\n",
      "epoch:38 step:30407[D loss: 0.398493, acc: 71.88%, op_acc: 44.53%] [G loss: 1.721755]\n",
      "epoch:38 step:30408[D loss: 0.252843, acc: 86.72%, op_acc: 57.03%] [G loss: 1.669216]\n",
      "epoch:38 step:30409[D loss: 0.352070, acc: 68.75%, op_acc: 50.78%] [G loss: 1.791131]\n",
      "epoch:38 step:30410[D loss: 0.352421, acc: 71.88%, op_acc: 53.12%] [G loss: 1.538007]\n",
      "epoch:38 step:30411[D loss: 0.387782, acc: 76.56%, op_acc: 52.34%] [G loss: 1.396194]\n",
      "epoch:38 step:30412[D loss: 0.316870, acc: 77.34%, op_acc: 51.56%] [G loss: 1.117776]\n",
      "epoch:38 step:30413[D loss: 0.321401, acc: 76.56%, op_acc: 45.31%] [G loss: 1.771385]\n",
      "epoch:38 step:30414[D loss: 0.334671, acc: 75.78%, op_acc: 48.44%] [G loss: 1.527842]\n",
      "epoch:38 step:30415[D loss: 0.434798, acc: 63.28%, op_acc: 52.34%] [G loss: 1.519077]\n",
      "epoch:38 step:30416[D loss: 0.383132, acc: 67.19%, op_acc: 47.66%] [G loss: 1.680083]\n",
      "epoch:38 step:30417[D loss: 0.431711, acc: 64.06%, op_acc: 42.97%] [G loss: 1.460360]\n",
      "epoch:38 step:30418[D loss: 0.393578, acc: 65.62%, op_acc: 44.53%] [G loss: 1.652074]\n",
      "epoch:38 step:30419[D loss: 0.341653, acc: 78.91%, op_acc: 48.44%] [G loss: 1.682109]\n",
      "epoch:38 step:30420[D loss: 0.373761, acc: 69.53%, op_acc: 49.22%] [G loss: 1.841697]\n",
      "epoch:38 step:30421[D loss: 0.402067, acc: 67.19%, op_acc: 46.09%] [G loss: 1.553182]\n",
      "epoch:38 step:30422[D loss: 0.325339, acc: 71.09%, op_acc: 52.34%] [G loss: 1.217193]\n",
      "epoch:38 step:30423[D loss: 0.398407, acc: 65.62%, op_acc: 48.44%] [G loss: 1.204489]\n",
      "epoch:38 step:30424[D loss: 0.383495, acc: 69.53%, op_acc: 42.97%] [G loss: 1.360722]\n",
      "epoch:38 step:30425[D loss: 0.328146, acc: 78.91%, op_acc: 51.56%] [G loss: 1.561695]\n",
      "epoch:38 step:30426[D loss: 0.387841, acc: 67.97%, op_acc: 46.88%] [G loss: 1.583935]\n",
      "epoch:38 step:30427[D loss: 0.383226, acc: 71.09%, op_acc: 45.31%] [G loss: 1.493433]\n",
      "epoch:38 step:30428[D loss: 0.548426, acc: 43.75%, op_acc: 39.06%] [G loss: 1.008201]\n",
      "epoch:38 step:30429[D loss: 0.435880, acc: 59.38%, op_acc: 42.19%] [G loss: 1.841039]\n",
      "epoch:38 step:30430[D loss: 0.429170, acc: 64.84%, op_acc: 39.84%] [G loss: 1.165104]\n",
      "epoch:38 step:30431[D loss: 0.428805, acc: 57.81%, op_acc: 44.53%] [G loss: 1.845251]\n",
      "epoch:38 step:30432[D loss: 0.370155, acc: 67.97%, op_acc: 44.53%] [G loss: 2.019579]\n",
      "epoch:38 step:30433[D loss: 0.414059, acc: 58.59%, op_acc: 47.66%] [G loss: 1.197674]\n",
      "epoch:38 step:30434[D loss: 0.372641, acc: 72.66%, op_acc: 55.47%] [G loss: 1.358239]\n",
      "epoch:38 step:30435[D loss: 0.393808, acc: 65.62%, op_acc: 42.19%] [G loss: 1.056391]\n",
      "epoch:38 step:30436[D loss: 0.352003, acc: 67.19%, op_acc: 46.09%] [G loss: 1.684914]\n",
      "epoch:38 step:30437[D loss: 0.478977, acc: 60.16%, op_acc: 46.88%] [G loss: 1.194323]\n",
      "epoch:38 step:30438[D loss: 0.418990, acc: 61.72%, op_acc: 48.44%] [G loss: 1.175634]\n",
      "epoch:38 step:30439[D loss: 0.377263, acc: 62.50%, op_acc: 49.22%] [G loss: 1.169849]\n",
      "epoch:38 step:30440[D loss: 0.387337, acc: 67.97%, op_acc: 51.56%] [G loss: 1.350325]\n",
      "epoch:38 step:30441[D loss: 0.373324, acc: 71.09%, op_acc: 50.78%] [G loss: 1.423589]\n",
      "epoch:38 step:30442[D loss: 0.418066, acc: 60.16%, op_acc: 45.31%] [G loss: 1.303268]\n",
      "epoch:38 step:30443[D loss: 0.386434, acc: 65.62%, op_acc: 50.78%] [G loss: 1.674627]\n",
      "epoch:38 step:30444[D loss: 0.542227, acc: 50.78%, op_acc: 43.75%] [G loss: 1.128980]\n",
      "epoch:38 step:30445[D loss: 0.374153, acc: 72.66%, op_acc: 43.75%] [G loss: 0.965296]\n",
      "epoch:38 step:30446[D loss: 0.375098, acc: 70.31%, op_acc: 38.28%] [G loss: 1.558937]\n",
      "epoch:38 step:30447[D loss: 0.370833, acc: 71.09%, op_acc: 49.22%] [G loss: 1.363143]\n",
      "epoch:38 step:30448[D loss: 0.366038, acc: 71.88%, op_acc: 50.00%] [G loss: 1.665567]\n",
      "epoch:38 step:30449[D loss: 0.386571, acc: 71.09%, op_acc: 44.53%] [G loss: 1.142905]\n",
      "epoch:38 step:30450[D loss: 0.400650, acc: 69.53%, op_acc: 43.75%] [G loss: 0.962221]\n",
      "epoch:38 step:30451[D loss: 0.408744, acc: 69.53%, op_acc: 40.62%] [G loss: 0.964573]\n",
      "epoch:38 step:30452[D loss: 0.347460, acc: 67.97%, op_acc: 42.97%] [G loss: 1.015383]\n",
      "epoch:38 step:30453[D loss: 0.411633, acc: 68.75%, op_acc: 44.53%] [G loss: 1.619572]\n",
      "epoch:38 step:30454[D loss: 0.415466, acc: 61.72%, op_acc: 45.31%] [G loss: 1.466300]\n",
      "epoch:38 step:30455[D loss: 0.378069, acc: 71.09%, op_acc: 41.41%] [G loss: 1.000810]\n",
      "epoch:38 step:30456[D loss: 0.393832, acc: 64.84%, op_acc: 50.00%] [G loss: 0.961740]\n",
      "epoch:38 step:30457[D loss: 0.410445, acc: 67.19%, op_acc: 46.09%] [G loss: 1.057121]\n",
      "epoch:38 step:30458[D loss: 0.355694, acc: 75.00%, op_acc: 53.91%] [G loss: 1.119892]\n",
      "epoch:38 step:30459[D loss: 0.356814, acc: 75.00%, op_acc: 48.44%] [G loss: 0.826683]\n",
      "epoch:39 step:30460[D loss: 0.320922, acc: 72.66%, op_acc: 50.00%] [G loss: 1.123736]\n",
      "epoch:39 step:30461[D loss: 0.387863, acc: 67.97%, op_acc: 53.91%] [G loss: 1.078819]\n",
      "epoch:39 step:30462[D loss: 0.395188, acc: 72.66%, op_acc: 45.31%] [G loss: 0.855219]\n",
      "epoch:39 step:30463[D loss: 0.424414, acc: 60.94%, op_acc: 46.09%] [G loss: 1.525487]\n",
      "epoch:39 step:30464[D loss: 0.407432, acc: 61.72%, op_acc: 47.66%] [G loss: 0.970919]\n",
      "epoch:39 step:30465[D loss: 0.411948, acc: 66.41%, op_acc: 44.53%] [G loss: 1.093298]\n",
      "epoch:39 step:30466[D loss: 0.327845, acc: 71.88%, op_acc: 50.00%] [G loss: 1.106894]\n",
      "epoch:39 step:30467[D loss: 0.452613, acc: 57.81%, op_acc: 42.97%] [G loss: 1.118124]\n",
      "epoch:39 step:30468[D loss: 0.379585, acc: 66.41%, op_acc: 47.66%] [G loss: 1.256065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30469[D loss: 0.382963, acc: 70.31%, op_acc: 49.22%] [G loss: 1.189892]\n",
      "epoch:39 step:30470[D loss: 0.342925, acc: 75.78%, op_acc: 48.44%] [G loss: 1.136184]\n",
      "epoch:39 step:30471[D loss: 0.348636, acc: 79.69%, op_acc: 42.97%] [G loss: 1.685134]\n",
      "epoch:39 step:30472[D loss: 0.264219, acc: 82.81%, op_acc: 59.38%] [G loss: 1.829207]\n",
      "epoch:39 step:30473[D loss: 0.392030, acc: 71.09%, op_acc: 50.00%] [G loss: 1.015840]\n",
      "epoch:39 step:30474[D loss: 0.322012, acc: 78.91%, op_acc: 49.22%] [G loss: 1.363857]\n",
      "epoch:39 step:30475[D loss: 0.366309, acc: 67.97%, op_acc: 53.12%] [G loss: 1.021157]\n",
      "epoch:39 step:30476[D loss: 0.391041, acc: 66.41%, op_acc: 47.66%] [G loss: 1.121096]\n",
      "epoch:39 step:30477[D loss: 0.341968, acc: 75.00%, op_acc: 46.09%] [G loss: 1.351556]\n",
      "epoch:39 step:30478[D loss: 0.362977, acc: 67.97%, op_acc: 43.75%] [G loss: 1.318659]\n",
      "epoch:39 step:30479[D loss: 0.337002, acc: 71.88%, op_acc: 57.81%] [G loss: 1.677450]\n",
      "epoch:39 step:30480[D loss: 0.367391, acc: 71.88%, op_acc: 36.72%] [G loss: 1.284741]\n",
      "epoch:39 step:30481[D loss: 0.384269, acc: 68.75%, op_acc: 45.31%] [G loss: 1.140445]\n",
      "epoch:39 step:30482[D loss: 0.425233, acc: 60.94%, op_acc: 46.09%] [G loss: 0.999502]\n",
      "epoch:39 step:30483[D loss: 0.384311, acc: 66.41%, op_acc: 46.88%] [G loss: 1.618675]\n",
      "epoch:39 step:30484[D loss: 0.376584, acc: 72.66%, op_acc: 52.34%] [G loss: 1.484932]\n",
      "epoch:39 step:30485[D loss: 0.367679, acc: 73.44%, op_acc: 51.56%] [G loss: 1.398302]\n",
      "epoch:39 step:30486[D loss: 0.330036, acc: 74.22%, op_acc: 49.22%] [G loss: 1.211806]\n",
      "epoch:39 step:30487[D loss: 0.424489, acc: 59.38%, op_acc: 57.81%] [G loss: 1.648826]\n",
      "epoch:39 step:30488[D loss: 0.350326, acc: 78.12%, op_acc: 50.78%] [G loss: 1.188886]\n",
      "epoch:39 step:30489[D loss: 0.348519, acc: 67.97%, op_acc: 56.25%] [G loss: 1.069471]\n",
      "epoch:39 step:30490[D loss: 0.362208, acc: 76.56%, op_acc: 49.22%] [G loss: 1.662989]\n",
      "epoch:39 step:30491[D loss: 0.431834, acc: 66.41%, op_acc: 39.84%] [G loss: 0.982184]\n",
      "epoch:39 step:30492[D loss: 0.358247, acc: 71.88%, op_acc: 53.91%] [G loss: 1.440440]\n",
      "epoch:39 step:30493[D loss: 0.230365, acc: 86.72%, op_acc: 60.94%] [G loss: 1.719751]\n",
      "epoch:39 step:30494[D loss: 0.317048, acc: 82.03%, op_acc: 57.03%] [G loss: 1.331442]\n",
      "epoch:39 step:30495[D loss: 0.423072, acc: 59.38%, op_acc: 48.44%] [G loss: 1.393777]\n",
      "epoch:39 step:30496[D loss: 0.297694, acc: 78.12%, op_acc: 59.38%] [G loss: 1.063565]\n",
      "epoch:39 step:30497[D loss: 0.344047, acc: 67.97%, op_acc: 47.66%] [G loss: 0.903349]\n",
      "epoch:39 step:30498[D loss: 0.300492, acc: 80.47%, op_acc: 54.69%] [G loss: 0.970748]\n",
      "epoch:39 step:30499[D loss: 0.348709, acc: 72.66%, op_acc: 42.19%] [G loss: 1.164937]\n",
      "epoch:39 step:30500[D loss: 0.307955, acc: 76.56%, op_acc: 53.91%] [G loss: 0.788638]\n",
      "epoch:39 step:30501[D loss: 0.295583, acc: 78.12%, op_acc: 60.16%] [G loss: 1.198346]\n",
      "epoch:39 step:30502[D loss: 0.349803, acc: 78.12%, op_acc: 51.56%] [G loss: 1.318105]\n",
      "epoch:39 step:30503[D loss: 0.381825, acc: 67.97%, op_acc: 53.12%] [G loss: 1.128305]\n",
      "epoch:39 step:30504[D loss: 0.384875, acc: 65.62%, op_acc: 43.75%] [G loss: 1.002722]\n",
      "epoch:39 step:30505[D loss: 0.406218, acc: 61.72%, op_acc: 48.44%] [G loss: 1.493416]\n",
      "epoch:39 step:30506[D loss: 0.402010, acc: 74.22%, op_acc: 36.72%] [G loss: 1.059462]\n",
      "epoch:39 step:30507[D loss: 0.391739, acc: 71.88%, op_acc: 49.22%] [G loss: 1.057418]\n",
      "epoch:39 step:30508[D loss: 0.337363, acc: 74.22%, op_acc: 46.88%] [G loss: 1.050689]\n",
      "epoch:39 step:30509[D loss: 0.504807, acc: 53.12%, op_acc: 35.94%] [G loss: 1.306082]\n",
      "epoch:39 step:30510[D loss: 0.435530, acc: 66.41%, op_acc: 42.19%] [G loss: 1.315169]\n",
      "epoch:39 step:30511[D loss: 0.365246, acc: 75.00%, op_acc: 48.44%] [G loss: 1.706250]\n",
      "epoch:39 step:30512[D loss: 0.418991, acc: 69.53%, op_acc: 44.53%] [G loss: 1.345479]\n",
      "epoch:39 step:30513[D loss: 0.443804, acc: 67.97%, op_acc: 44.53%] [G loss: 1.179500]\n",
      "epoch:39 step:30514[D loss: 0.369952, acc: 69.53%, op_acc: 45.31%] [G loss: 1.026951]\n",
      "epoch:39 step:30515[D loss: 0.487511, acc: 53.91%, op_acc: 41.41%] [G loss: 1.497482]\n",
      "epoch:39 step:30516[D loss: 0.399510, acc: 69.53%, op_acc: 39.84%] [G loss: 0.955589]\n",
      "epoch:39 step:30517[D loss: 0.339751, acc: 75.00%, op_acc: 49.22%] [G loss: 1.071189]\n",
      "epoch:39 step:30518[D loss: 0.375420, acc: 67.19%, op_acc: 45.31%] [G loss: 1.393056]\n",
      "epoch:39 step:30519[D loss: 0.332117, acc: 75.78%, op_acc: 45.31%] [G loss: 1.139457]\n",
      "epoch:39 step:30520[D loss: 0.332944, acc: 75.78%, op_acc: 50.00%] [G loss: 1.283121]\n",
      "epoch:39 step:30521[D loss: 0.391088, acc: 68.75%, op_acc: 46.88%] [G loss: 1.220078]\n",
      "epoch:39 step:30522[D loss: 0.507685, acc: 55.47%, op_acc: 39.84%] [G loss: 1.310839]\n",
      "epoch:39 step:30523[D loss: 0.393986, acc: 67.19%, op_acc: 49.22%] [G loss: 1.018617]\n",
      "epoch:39 step:30524[D loss: 0.371381, acc: 68.75%, op_acc: 53.12%] [G loss: 0.983443]\n",
      "epoch:39 step:30525[D loss: 0.404519, acc: 64.84%, op_acc: 44.53%] [G loss: 0.990137]\n",
      "epoch:39 step:30526[D loss: 0.308507, acc: 82.03%, op_acc: 50.00%] [G loss: 1.550998]\n",
      "epoch:39 step:30527[D loss: 0.386850, acc: 66.41%, op_acc: 39.84%] [G loss: 1.872846]\n",
      "epoch:39 step:30528[D loss: 0.376625, acc: 64.84%, op_acc: 46.09%] [G loss: 1.639553]\n",
      "epoch:39 step:30529[D loss: 0.416258, acc: 61.72%, op_acc: 39.84%] [G loss: 1.023023]\n",
      "epoch:39 step:30530[D loss: 0.457732, acc: 60.94%, op_acc: 38.28%] [G loss: 0.947127]\n",
      "epoch:39 step:30531[D loss: 0.379262, acc: 67.97%, op_acc: 51.56%] [G loss: 0.928697]\n",
      "epoch:39 step:30532[D loss: 0.366264, acc: 69.53%, op_acc: 46.09%] [G loss: 0.888474]\n",
      "epoch:39 step:30533[D loss: 0.264620, acc: 87.50%, op_acc: 57.81%] [G loss: 1.120011]\n",
      "epoch:39 step:30534[D loss: 0.408061, acc: 63.28%, op_acc: 50.78%] [G loss: 0.921018]\n",
      "epoch:39 step:30535[D loss: 0.336304, acc: 76.56%, op_acc: 53.91%] [G loss: 0.864246]\n",
      "epoch:39 step:30536[D loss: 0.389825, acc: 60.16%, op_acc: 42.97%] [G loss: 1.376513]\n",
      "epoch:39 step:30537[D loss: 0.365782, acc: 71.88%, op_acc: 50.00%] [G loss: 1.571516]\n",
      "epoch:39 step:30538[D loss: 0.476030, acc: 53.12%, op_acc: 39.06%] [G loss: 1.061117]\n",
      "epoch:39 step:30539[D loss: 0.366357, acc: 70.31%, op_acc: 45.31%] [G loss: 1.222056]\n",
      "epoch:39 step:30540[D loss: 0.526708, acc: 56.25%, op_acc: 42.97%] [G loss: 0.874050]\n",
      "epoch:39 step:30541[D loss: 0.457186, acc: 60.94%, op_acc: 38.28%] [G loss: 0.652742]\n",
      "epoch:39 step:30542[D loss: 0.418196, acc: 60.94%, op_acc: 43.75%] [G loss: 1.372724]\n",
      "epoch:39 step:30543[D loss: 0.457976, acc: 58.59%, op_acc: 46.09%] [G loss: 1.119478]\n",
      "epoch:39 step:30544[D loss: 0.402327, acc: 71.09%, op_acc: 49.22%] [G loss: 1.801058]\n",
      "epoch:39 step:30545[D loss: 0.350736, acc: 72.66%, op_acc: 41.41%] [G loss: 1.082054]\n",
      "epoch:39 step:30546[D loss: 0.326009, acc: 73.44%, op_acc: 57.03%] [G loss: 1.096635]\n",
      "epoch:39 step:30547[D loss: 0.310909, acc: 79.69%, op_acc: 51.56%] [G loss: 1.338615]\n",
      "epoch:39 step:30548[D loss: 0.443846, acc: 61.72%, op_acc: 40.62%] [G loss: 1.103028]\n",
      "epoch:39 step:30549[D loss: 0.411581, acc: 63.28%, op_acc: 41.41%] [G loss: 1.411348]\n",
      "epoch:39 step:30550[D loss: 0.280988, acc: 82.03%, op_acc: 55.47%] [G loss: 1.089323]\n",
      "epoch:39 step:30551[D loss: 0.323514, acc: 77.34%, op_acc: 51.56%] [G loss: 0.895275]\n",
      "epoch:39 step:30552[D loss: 0.357627, acc: 70.31%, op_acc: 44.53%] [G loss: 1.000531]\n",
      "epoch:39 step:30553[D loss: 0.319002, acc: 74.22%, op_acc: 50.78%] [G loss: 1.529092]\n",
      "epoch:39 step:30554[D loss: 0.418016, acc: 62.50%, op_acc: 51.56%] [G loss: 1.046108]\n",
      "epoch:39 step:30555[D loss: 0.359743, acc: 75.00%, op_acc: 43.75%] [G loss: 1.169442]\n",
      "epoch:39 step:30556[D loss: 0.313747, acc: 78.12%, op_acc: 52.34%] [G loss: 1.234218]\n",
      "epoch:39 step:30557[D loss: 0.358341, acc: 73.44%, op_acc: 46.09%] [G loss: 1.339603]\n",
      "epoch:39 step:30558[D loss: 0.457554, acc: 57.81%, op_acc: 39.06%] [G loss: 1.075454]\n",
      "epoch:39 step:30559[D loss: 0.413306, acc: 67.19%, op_acc: 46.09%] [G loss: 1.123132]\n",
      "epoch:39 step:30560[D loss: 0.328048, acc: 78.91%, op_acc: 52.34%] [G loss: 1.128783]\n",
      "epoch:39 step:30561[D loss: 0.386088, acc: 65.62%, op_acc: 49.22%] [G loss: 1.188612]\n",
      "epoch:39 step:30562[D loss: 0.392192, acc: 66.41%, op_acc: 47.66%] [G loss: 1.185137]\n",
      "epoch:39 step:30563[D loss: 0.292448, acc: 82.03%, op_acc: 49.22%] [G loss: 1.064904]\n",
      "epoch:39 step:30564[D loss: 0.319954, acc: 73.44%, op_acc: 50.78%] [G loss: 1.298220]\n",
      "epoch:39 step:30565[D loss: 0.341850, acc: 76.56%, op_acc: 53.91%] [G loss: 1.372678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30566[D loss: 0.279829, acc: 85.16%, op_acc: 53.12%] [G loss: 1.245671]\n",
      "epoch:39 step:30567[D loss: 0.362921, acc: 68.75%, op_acc: 43.75%] [G loss: 1.335606]\n",
      "epoch:39 step:30568[D loss: 0.287579, acc: 85.94%, op_acc: 57.81%] [G loss: 1.542911]\n",
      "epoch:39 step:30569[D loss: 0.298610, acc: 81.25%, op_acc: 51.56%] [G loss: 1.604209]\n",
      "epoch:39 step:30570[D loss: 0.322055, acc: 73.44%, op_acc: 44.53%] [G loss: 1.443405]\n",
      "epoch:39 step:30571[D loss: 0.323062, acc: 76.56%, op_acc: 58.59%] [G loss: 1.454714]\n",
      "epoch:39 step:30572[D loss: 0.302807, acc: 82.03%, op_acc: 57.03%] [G loss: 1.221649]\n",
      "epoch:39 step:30573[D loss: 0.310838, acc: 78.12%, op_acc: 63.28%] [G loss: 1.309216]\n",
      "epoch:39 step:30574[D loss: 0.273535, acc: 81.25%, op_acc: 57.03%] [G loss: 1.246265]\n",
      "epoch:39 step:30575[D loss: 0.363952, acc: 76.56%, op_acc: 43.75%] [G loss: 1.307601]\n",
      "epoch:39 step:30576[D loss: 0.251827, acc: 87.50%, op_acc: 59.38%] [G loss: 1.402930]\n",
      "epoch:39 step:30577[D loss: 0.312050, acc: 81.25%, op_acc: 52.34%] [G loss: 1.455092]\n",
      "epoch:39 step:30578[D loss: 0.343993, acc: 78.91%, op_acc: 45.31%] [G loss: 1.365516]\n",
      "epoch:39 step:30579[D loss: 0.254593, acc: 89.06%, op_acc: 55.47%] [G loss: 1.624239]\n",
      "epoch:39 step:30580[D loss: 0.347468, acc: 72.66%, op_acc: 50.78%] [G loss: 1.535828]\n",
      "epoch:39 step:30581[D loss: 0.315323, acc: 81.25%, op_acc: 53.91%] [G loss: 1.558547]\n",
      "epoch:39 step:30582[D loss: 0.294007, acc: 85.16%, op_acc: 53.12%] [G loss: 1.321392]\n",
      "epoch:39 step:30583[D loss: 0.389732, acc: 70.31%, op_acc: 43.75%] [G loss: 1.349599]\n",
      "epoch:39 step:30584[D loss: 0.349378, acc: 76.56%, op_acc: 42.97%] [G loss: 1.883551]\n",
      "epoch:39 step:30585[D loss: 0.338828, acc: 77.34%, op_acc: 50.78%] [G loss: 1.290882]\n",
      "epoch:39 step:30586[D loss: 0.294821, acc: 85.16%, op_acc: 50.00%] [G loss: 1.850061]\n",
      "epoch:39 step:30587[D loss: 0.298425, acc: 78.91%, op_acc: 49.22%] [G loss: 1.781050]\n",
      "epoch:39 step:30588[D loss: 0.411195, acc: 67.97%, op_acc: 51.56%] [G loss: 1.671456]\n",
      "epoch:39 step:30589[D loss: 0.360327, acc: 73.44%, op_acc: 48.44%] [G loss: 1.427489]\n",
      "epoch:39 step:30590[D loss: 0.359828, acc: 71.09%, op_acc: 42.97%] [G loss: 1.484167]\n",
      "epoch:39 step:30591[D loss: 0.301226, acc: 78.12%, op_acc: 53.91%] [G loss: 1.557591]\n",
      "epoch:39 step:30592[D loss: 0.319287, acc: 82.03%, op_acc: 53.12%] [G loss: 1.457482]\n",
      "epoch:39 step:30593[D loss: 0.400875, acc: 68.75%, op_acc: 47.66%] [G loss: 1.469438]\n",
      "epoch:39 step:30594[D loss: 0.372895, acc: 66.41%, op_acc: 49.22%] [G loss: 1.443585]\n",
      "epoch:39 step:30595[D loss: 0.407426, acc: 64.84%, op_acc: 45.31%] [G loss: 1.051828]\n",
      "epoch:39 step:30596[D loss: 0.417553, acc: 62.50%, op_acc: 50.00%] [G loss: 1.687854]\n",
      "epoch:39 step:30597[D loss: 0.405022, acc: 70.31%, op_acc: 42.19%] [G loss: 1.374448]\n",
      "epoch:39 step:30598[D loss: 0.412609, acc: 63.28%, op_acc: 41.41%] [G loss: 1.465495]\n",
      "epoch:39 step:30599[D loss: 0.427244, acc: 69.53%, op_acc: 42.19%] [G loss: 1.634124]\n",
      "epoch:39 step:30600[D loss: 0.461609, acc: 59.38%, op_acc: 39.84%] [G loss: 1.564065]\n",
      "epoch:39 step:30601[D loss: 0.324642, acc: 78.12%, op_acc: 50.00%] [G loss: 1.680924]\n",
      "epoch:39 step:30602[D loss: 0.418022, acc: 56.25%, op_acc: 50.00%] [G loss: 1.591098]\n",
      "epoch:39 step:30603[D loss: 0.369688, acc: 73.44%, op_acc: 49.22%] [G loss: 1.277022]\n",
      "epoch:39 step:30604[D loss: 0.351332, acc: 72.66%, op_acc: 53.91%] [G loss: 1.203136]\n",
      "epoch:39 step:30605[D loss: 0.376117, acc: 71.88%, op_acc: 49.22%] [G loss: 1.167547]\n",
      "epoch:39 step:30606[D loss: 0.319732, acc: 76.56%, op_acc: 48.44%] [G loss: 0.964110]\n",
      "epoch:39 step:30607[D loss: 0.375804, acc: 71.09%, op_acc: 44.53%] [G loss: 0.905468]\n",
      "epoch:39 step:30608[D loss: 0.331721, acc: 74.22%, op_acc: 53.12%] [G loss: 1.155791]\n",
      "epoch:39 step:30609[D loss: 0.492047, acc: 53.12%, op_acc: 43.75%] [G loss: 0.816903]\n",
      "epoch:39 step:30610[D loss: 0.325538, acc: 76.56%, op_acc: 48.44%] [G loss: 1.381769]\n",
      "epoch:39 step:30611[D loss: 0.403165, acc: 61.72%, op_acc: 53.12%] [G loss: 1.273624]\n",
      "epoch:39 step:30612[D loss: 0.437709, acc: 58.59%, op_acc: 42.19%] [G loss: 0.658279]\n",
      "epoch:39 step:30613[D loss: 0.303748, acc: 84.38%, op_acc: 52.34%] [G loss: 0.934033]\n",
      "epoch:39 step:30614[D loss: 0.415212, acc: 58.59%, op_acc: 47.66%] [G loss: 0.802052]\n",
      "epoch:39 step:30615[D loss: 0.396347, acc: 65.62%, op_acc: 51.56%] [G loss: 1.609184]\n",
      "epoch:39 step:30616[D loss: 0.436674, acc: 63.28%, op_acc: 39.84%] [G loss: 1.318502]\n",
      "epoch:39 step:30617[D loss: 0.261053, acc: 83.59%, op_acc: 57.81%] [G loss: 1.676795]\n",
      "epoch:39 step:30618[D loss: 0.352128, acc: 71.09%, op_acc: 58.59%] [G loss: 1.434831]\n",
      "epoch:39 step:30619[D loss: 0.437682, acc: 57.03%, op_acc: 46.09%] [G loss: 1.479900]\n",
      "epoch:39 step:30620[D loss: 0.364522, acc: 71.88%, op_acc: 53.91%] [G loss: 1.962698]\n",
      "epoch:39 step:30621[D loss: 0.384677, acc: 68.75%, op_acc: 49.22%] [G loss: 1.293269]\n",
      "epoch:39 step:30622[D loss: 0.397377, acc: 67.19%, op_acc: 46.09%] [G loss: 1.414001]\n",
      "epoch:39 step:30623[D loss: 0.406174, acc: 68.75%, op_acc: 38.28%] [G loss: 1.180952]\n",
      "epoch:39 step:30624[D loss: 0.380093, acc: 64.84%, op_acc: 50.78%] [G loss: 1.494023]\n",
      "epoch:39 step:30625[D loss: 0.559143, acc: 48.44%, op_acc: 35.16%] [G loss: 1.420767]\n",
      "epoch:39 step:30626[D loss: 0.390502, acc: 68.75%, op_acc: 46.09%] [G loss: 1.489752]\n",
      "epoch:39 step:30627[D loss: 0.373991, acc: 71.88%, op_acc: 50.00%] [G loss: 1.319310]\n",
      "epoch:39 step:30628[D loss: 0.419602, acc: 60.16%, op_acc: 50.00%] [G loss: 1.440306]\n",
      "epoch:39 step:30629[D loss: 0.378557, acc: 70.31%, op_acc: 44.53%] [G loss: 1.472646]\n",
      "epoch:39 step:30630[D loss: 0.325586, acc: 74.22%, op_acc: 58.59%] [G loss: 1.434377]\n",
      "epoch:39 step:30631[D loss: 0.336028, acc: 76.56%, op_acc: 53.91%] [G loss: 1.715948]\n",
      "epoch:39 step:30632[D loss: 0.359024, acc: 71.09%, op_acc: 46.88%] [G loss: 1.190195]\n",
      "epoch:39 step:30633[D loss: 0.430723, acc: 64.06%, op_acc: 43.75%] [G loss: 1.200352]\n",
      "epoch:39 step:30634[D loss: 0.310496, acc: 78.91%, op_acc: 50.78%] [G loss: 1.257835]\n",
      "epoch:39 step:30635[D loss: 0.356171, acc: 71.88%, op_acc: 48.44%] [G loss: 1.419516]\n",
      "epoch:39 step:30636[D loss: 0.357219, acc: 67.97%, op_acc: 53.12%] [G loss: 1.325835]\n",
      "epoch:39 step:30637[D loss: 0.438108, acc: 66.41%, op_acc: 48.44%] [G loss: 1.473474]\n",
      "epoch:39 step:30638[D loss: 0.366037, acc: 74.22%, op_acc: 44.53%] [G loss: 1.511435]\n",
      "epoch:39 step:30639[D loss: 0.408811, acc: 67.19%, op_acc: 37.50%] [G loss: 1.249201]\n",
      "epoch:39 step:30640[D loss: 0.324317, acc: 78.12%, op_acc: 52.34%] [G loss: 1.430925]\n",
      "epoch:39 step:30641[D loss: 0.317446, acc: 81.25%, op_acc: 46.09%] [G loss: 1.198087]\n",
      "epoch:39 step:30642[D loss: 0.325205, acc: 75.00%, op_acc: 46.88%] [G loss: 1.598275]\n",
      "epoch:39 step:30643[D loss: 0.316310, acc: 77.34%, op_acc: 50.78%] [G loss: 1.726495]\n",
      "epoch:39 step:30644[D loss: 0.330247, acc: 79.69%, op_acc: 48.44%] [G loss: 1.331180]\n",
      "epoch:39 step:30645[D loss: 0.427498, acc: 60.16%, op_acc: 53.12%] [G loss: 1.600272]\n",
      "epoch:39 step:30646[D loss: 0.342958, acc: 73.44%, op_acc: 43.75%] [G loss: 1.377919]\n",
      "epoch:39 step:30647[D loss: 0.369131, acc: 63.28%, op_acc: 51.56%] [G loss: 1.284113]\n",
      "epoch:39 step:30648[D loss: 0.292017, acc: 82.81%, op_acc: 50.78%] [G loss: 1.602309]\n",
      "epoch:39 step:30649[D loss: 0.346755, acc: 78.91%, op_acc: 54.69%] [G loss: 1.244665]\n",
      "epoch:39 step:30650[D loss: 0.387480, acc: 68.75%, op_acc: 47.66%] [G loss: 1.286266]\n",
      "epoch:39 step:30651[D loss: 0.307948, acc: 83.59%, op_acc: 53.12%] [G loss: 1.367081]\n",
      "epoch:39 step:30652[D loss: 0.436168, acc: 63.28%, op_acc: 39.84%] [G loss: 1.280890]\n",
      "epoch:39 step:30653[D loss: 0.381388, acc: 62.50%, op_acc: 57.03%] [G loss: 1.297112]\n",
      "epoch:39 step:30654[D loss: 0.411643, acc: 66.41%, op_acc: 43.75%] [G loss: 1.197822]\n",
      "epoch:39 step:30655[D loss: 0.361788, acc: 73.44%, op_acc: 44.53%] [G loss: 1.364074]\n",
      "epoch:39 step:30656[D loss: 0.393474, acc: 69.53%, op_acc: 42.97%] [G loss: 1.169198]\n",
      "epoch:39 step:30657[D loss: 0.416942, acc: 62.50%, op_acc: 48.44%] [G loss: 1.160369]\n",
      "epoch:39 step:30658[D loss: 0.428251, acc: 60.94%, op_acc: 41.41%] [G loss: 1.577485]\n",
      "epoch:39 step:30659[D loss: 0.365386, acc: 72.66%, op_acc: 45.31%] [G loss: 1.125717]\n",
      "epoch:39 step:30660[D loss: 0.359071, acc: 74.22%, op_acc: 49.22%] [G loss: 1.066147]\n",
      "epoch:39 step:30661[D loss: 0.407168, acc: 69.53%, op_acc: 40.62%] [G loss: 1.316881]\n",
      "epoch:39 step:30662[D loss: 0.454924, acc: 61.72%, op_acc: 36.72%] [G loss: 1.164966]\n",
      "epoch:39 step:30663[D loss: 0.408955, acc: 67.19%, op_acc: 44.53%] [G loss: 1.305284]\n",
      "epoch:39 step:30664[D loss: 0.371423, acc: 70.31%, op_acc: 42.97%] [G loss: 1.350087]\n",
      "epoch:39 step:30665[D loss: 0.374674, acc: 69.53%, op_acc: 50.00%] [G loss: 1.229748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30666[D loss: 0.440810, acc: 61.72%, op_acc: 44.53%] [G loss: 1.298195]\n",
      "epoch:39 step:30667[D loss: 0.354246, acc: 75.78%, op_acc: 42.97%] [G loss: 1.642998]\n",
      "epoch:39 step:30668[D loss: 0.428433, acc: 60.94%, op_acc: 47.66%] [G loss: 1.395082]\n",
      "epoch:39 step:30669[D loss: 0.439339, acc: 65.62%, op_acc: 38.28%] [G loss: 1.076238]\n",
      "epoch:39 step:30670[D loss: 0.385552, acc: 68.75%, op_acc: 47.66%] [G loss: 1.214737]\n",
      "epoch:39 step:30671[D loss: 0.303354, acc: 82.03%, op_acc: 51.56%] [G loss: 1.344558]\n",
      "epoch:39 step:30672[D loss: 0.323744, acc: 77.34%, op_acc: 42.97%] [G loss: 1.519851]\n",
      "epoch:39 step:30673[D loss: 0.355297, acc: 72.66%, op_acc: 53.91%] [G loss: 1.342024]\n",
      "epoch:39 step:30674[D loss: 0.415512, acc: 67.97%, op_acc: 45.31%] [G loss: 1.490806]\n",
      "epoch:39 step:30675[D loss: 0.408543, acc: 65.62%, op_acc: 42.97%] [G loss: 1.271471]\n",
      "epoch:39 step:30676[D loss: 0.358621, acc: 71.88%, op_acc: 45.31%] [G loss: 1.104296]\n",
      "epoch:39 step:30677[D loss: 0.450310, acc: 62.50%, op_acc: 46.88%] [G loss: 1.042539]\n",
      "epoch:39 step:30678[D loss: 0.366179, acc: 69.53%, op_acc: 46.09%] [G loss: 1.671540]\n",
      "epoch:39 step:30679[D loss: 0.448491, acc: 63.28%, op_acc: 47.66%] [G loss: 1.575901]\n",
      "epoch:39 step:30680[D loss: 0.388154, acc: 70.31%, op_acc: 48.44%] [G loss: 1.265710]\n",
      "epoch:39 step:30681[D loss: 0.396239, acc: 70.31%, op_acc: 43.75%] [G loss: 1.295215]\n",
      "epoch:39 step:30682[D loss: 0.492068, acc: 52.34%, op_acc: 44.53%] [G loss: 1.489851]\n",
      "epoch:39 step:30683[D loss: 0.377743, acc: 65.62%, op_acc: 48.44%] [G loss: 1.221211]\n",
      "epoch:39 step:30684[D loss: 0.323982, acc: 78.12%, op_acc: 53.12%] [G loss: 1.337707]\n",
      "epoch:39 step:30685[D loss: 0.418171, acc: 68.75%, op_acc: 46.88%] [G loss: 1.205292]\n",
      "epoch:39 step:30686[D loss: 0.383924, acc: 64.06%, op_acc: 44.53%] [G loss: 1.334685]\n",
      "epoch:39 step:30687[D loss: 0.379430, acc: 69.53%, op_acc: 48.44%] [G loss: 1.134374]\n",
      "epoch:39 step:30688[D loss: 0.436107, acc: 61.72%, op_acc: 46.09%] [G loss: 0.970820]\n",
      "epoch:39 step:30689[D loss: 0.452721, acc: 61.72%, op_acc: 42.97%] [G loss: 1.127818]\n",
      "epoch:39 step:30690[D loss: 0.305291, acc: 81.25%, op_acc: 52.34%] [G loss: 1.276819]\n",
      "epoch:39 step:30691[D loss: 0.352746, acc: 74.22%, op_acc: 50.00%] [G loss: 0.956559]\n",
      "epoch:39 step:30692[D loss: 0.287634, acc: 85.16%, op_acc: 51.56%] [G loss: 1.262579]\n",
      "epoch:39 step:30693[D loss: 0.312101, acc: 75.78%, op_acc: 44.53%] [G loss: 1.270252]\n",
      "epoch:39 step:30694[D loss: 0.318307, acc: 76.56%, op_acc: 57.03%] [G loss: 1.362620]\n",
      "epoch:39 step:30695[D loss: 0.334029, acc: 81.25%, op_acc: 42.97%] [G loss: 1.479083]\n",
      "epoch:39 step:30696[D loss: 0.342706, acc: 73.44%, op_acc: 51.56%] [G loss: 1.322576]\n",
      "epoch:39 step:30697[D loss: 0.420017, acc: 65.62%, op_acc: 42.97%] [G loss: 1.349427]\n",
      "epoch:39 step:30698[D loss: 0.367061, acc: 67.19%, op_acc: 42.97%] [G loss: 1.041519]\n",
      "epoch:39 step:30699[D loss: 0.378320, acc: 70.31%, op_acc: 47.66%] [G loss: 0.929889]\n",
      "epoch:39 step:30700[D loss: 0.407657, acc: 63.28%, op_acc: 44.53%] [G loss: 1.093206]\n",
      "epoch:39 step:30701[D loss: 0.327227, acc: 73.44%, op_acc: 53.91%] [G loss: 0.929532]\n",
      "epoch:39 step:30702[D loss: 0.374117, acc: 67.19%, op_acc: 48.44%] [G loss: 0.792181]\n",
      "epoch:39 step:30703[D loss: 0.386597, acc: 71.09%, op_acc: 44.53%] [G loss: 0.852864]\n",
      "epoch:39 step:30704[D loss: 0.342642, acc: 72.66%, op_acc: 47.66%] [G loss: 0.935901]\n",
      "epoch:39 step:30705[D loss: 0.408447, acc: 66.41%, op_acc: 42.97%] [G loss: 1.054820]\n",
      "epoch:39 step:30706[D loss: 0.393987, acc: 64.84%, op_acc: 50.78%] [G loss: 0.917497]\n",
      "epoch:39 step:30707[D loss: 0.342970, acc: 72.66%, op_acc: 51.56%] [G loss: 1.478810]\n",
      "epoch:39 step:30708[D loss: 0.349028, acc: 75.00%, op_acc: 45.31%] [G loss: 1.500844]\n",
      "epoch:39 step:30709[D loss: 0.431856, acc: 62.50%, op_acc: 45.31%] [G loss: 0.592760]\n",
      "epoch:39 step:30710[D loss: 0.415608, acc: 61.72%, op_acc: 42.97%] [G loss: 0.964033]\n",
      "epoch:39 step:30711[D loss: 0.426687, acc: 65.62%, op_acc: 41.41%] [G loss: 0.942472]\n",
      "epoch:39 step:30712[D loss: 0.458059, acc: 63.28%, op_acc: 38.28%] [G loss: 0.948418]\n",
      "epoch:39 step:30713[D loss: 0.321460, acc: 84.38%, op_acc: 50.00%] [G loss: 1.177412]\n",
      "epoch:39 step:30714[D loss: 0.343977, acc: 75.78%, op_acc: 57.03%] [G loss: 1.201535]\n",
      "epoch:39 step:30715[D loss: 0.355551, acc: 72.66%, op_acc: 46.09%] [G loss: 1.570807]\n",
      "epoch:39 step:30716[D loss: 0.352786, acc: 76.56%, op_acc: 47.66%] [G loss: 1.167636]\n",
      "epoch:39 step:30717[D loss: 0.333687, acc: 74.22%, op_acc: 42.97%] [G loss: 1.147512]\n",
      "epoch:39 step:30718[D loss: 0.327516, acc: 75.78%, op_acc: 46.09%] [G loss: 0.918237]\n",
      "epoch:39 step:30719[D loss: 0.332643, acc: 78.91%, op_acc: 46.09%] [G loss: 0.929502]\n",
      "epoch:39 step:30720[D loss: 0.306707, acc: 85.16%, op_acc: 50.78%] [G loss: 1.068276]\n",
      "epoch:39 step:30721[D loss: 0.348965, acc: 75.00%, op_acc: 41.41%] [G loss: 0.787669]\n",
      "epoch:39 step:30722[D loss: 0.282226, acc: 85.94%, op_acc: 53.91%] [G loss: 0.996718]\n",
      "epoch:39 step:30723[D loss: 0.356537, acc: 75.00%, op_acc: 42.19%] [G loss: 0.967597]\n",
      "epoch:39 step:30724[D loss: 0.294343, acc: 82.03%, op_acc: 63.28%] [G loss: 1.264021]\n",
      "epoch:39 step:30725[D loss: 0.335428, acc: 77.34%, op_acc: 49.22%] [G loss: 1.201153]\n",
      "epoch:39 step:30726[D loss: 0.457692, acc: 58.59%, op_acc: 43.75%] [G loss: 1.227950]\n",
      "epoch:39 step:30727[D loss: 0.376758, acc: 74.22%, op_acc: 43.75%] [G loss: 1.164615]\n",
      "epoch:39 step:30728[D loss: 0.386037, acc: 62.50%, op_acc: 46.09%] [G loss: 0.864076]\n",
      "epoch:39 step:30729[D loss: 0.402604, acc: 71.09%, op_acc: 48.44%] [G loss: 1.232677]\n",
      "epoch:39 step:30730[D loss: 0.387641, acc: 71.09%, op_acc: 39.06%] [G loss: 1.231021]\n",
      "epoch:39 step:30731[D loss: 0.406584, acc: 63.28%, op_acc: 44.53%] [G loss: 1.069867]\n",
      "epoch:39 step:30732[D loss: 0.425231, acc: 64.84%, op_acc: 42.19%] [G loss: 1.164658]\n",
      "epoch:39 step:30733[D loss: 0.415557, acc: 62.50%, op_acc: 48.44%] [G loss: 1.573226]\n",
      "epoch:39 step:30734[D loss: 0.452696, acc: 57.03%, op_acc: 49.22%] [G loss: 0.957965]\n",
      "epoch:39 step:30735[D loss: 0.324866, acc: 75.00%, op_acc: 53.91%] [G loss: 0.869268]\n",
      "epoch:39 step:30736[D loss: 0.383358, acc: 70.31%, op_acc: 40.62%] [G loss: 1.262597]\n",
      "epoch:39 step:30737[D loss: 0.370002, acc: 70.31%, op_acc: 49.22%] [G loss: 0.965484]\n",
      "epoch:39 step:30738[D loss: 0.347210, acc: 75.00%, op_acc: 56.25%] [G loss: 0.914384]\n",
      "epoch:39 step:30739[D loss: 0.388255, acc: 63.28%, op_acc: 48.44%] [G loss: 1.065669]\n",
      "epoch:39 step:30740[D loss: 0.388287, acc: 67.19%, op_acc: 45.31%] [G loss: 0.911758]\n",
      "epoch:39 step:30741[D loss: 0.387965, acc: 70.31%, op_acc: 49.22%] [G loss: 1.161054]\n",
      "epoch:39 step:30742[D loss: 0.276344, acc: 82.03%, op_acc: 56.25%] [G loss: 1.055997]\n",
      "epoch:39 step:30743[D loss: 0.388410, acc: 71.09%, op_acc: 42.19%] [G loss: 0.974972]\n",
      "epoch:39 step:30744[D loss: 0.313961, acc: 79.69%, op_acc: 56.25%] [G loss: 1.024415]\n",
      "epoch:39 step:30745[D loss: 0.334941, acc: 75.78%, op_acc: 47.66%] [G loss: 0.980596]\n",
      "epoch:39 step:30746[D loss: 0.372559, acc: 72.66%, op_acc: 50.78%] [G loss: 1.033477]\n",
      "epoch:39 step:30747[D loss: 0.302237, acc: 83.59%, op_acc: 50.00%] [G loss: 0.934823]\n",
      "epoch:39 step:30748[D loss: 0.364948, acc: 74.22%, op_acc: 47.66%] [G loss: 0.985449]\n",
      "epoch:39 step:30749[D loss: 0.351217, acc: 75.00%, op_acc: 46.88%] [G loss: 1.086974]\n",
      "epoch:39 step:30750[D loss: 0.303752, acc: 81.25%, op_acc: 48.44%] [G loss: 1.119745]\n",
      "epoch:39 step:30751[D loss: 0.377684, acc: 73.44%, op_acc: 51.56%] [G loss: 1.189886]\n",
      "epoch:39 step:30752[D loss: 0.333095, acc: 78.12%, op_acc: 53.12%] [G loss: 1.176028]\n",
      "epoch:39 step:30753[D loss: 0.279089, acc: 85.16%, op_acc: 52.34%] [G loss: 1.431630]\n",
      "epoch:39 step:30754[D loss: 0.360319, acc: 71.09%, op_acc: 45.31%] [G loss: 0.922663]\n",
      "epoch:39 step:30755[D loss: 0.358906, acc: 71.88%, op_acc: 49.22%] [G loss: 1.215105]\n",
      "epoch:39 step:30756[D loss: 0.292588, acc: 81.25%, op_acc: 49.22%] [G loss: 1.608121]\n",
      "epoch:39 step:30757[D loss: 0.283670, acc: 87.50%, op_acc: 50.78%] [G loss: 1.438104]\n",
      "epoch:39 step:30758[D loss: 0.274703, acc: 85.16%, op_acc: 57.81%] [G loss: 1.749068]\n",
      "epoch:39 step:30759[D loss: 0.421082, acc: 65.62%, op_acc: 45.31%] [G loss: 1.400255]\n",
      "epoch:39 step:30760[D loss: 0.288346, acc: 81.25%, op_acc: 55.47%] [G loss: 1.354210]\n",
      "epoch:39 step:30761[D loss: 0.265429, acc: 83.59%, op_acc: 58.59%] [G loss: 1.497454]\n",
      "epoch:39 step:30762[D loss: 0.329554, acc: 75.78%, op_acc: 52.34%] [G loss: 1.219664]\n",
      "epoch:39 step:30763[D loss: 0.264252, acc: 85.16%, op_acc: 53.91%] [G loss: 1.343077]\n",
      "epoch:39 step:30764[D loss: 0.380077, acc: 67.19%, op_acc: 50.78%] [G loss: 1.306848]\n",
      "epoch:39 step:30765[D loss: 0.302844, acc: 82.03%, op_acc: 55.47%] [G loss: 1.465887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30766[D loss: 0.275713, acc: 82.03%, op_acc: 58.59%] [G loss: 1.380104]\n",
      "epoch:39 step:30767[D loss: 0.313046, acc: 82.81%, op_acc: 50.00%] [G loss: 0.888044]\n",
      "epoch:39 step:30768[D loss: 0.408361, acc: 67.97%, op_acc: 38.28%] [G loss: 1.423033]\n",
      "epoch:39 step:30769[D loss: 0.336913, acc: 75.78%, op_acc: 42.19%] [G loss: 2.059154]\n",
      "epoch:39 step:30770[D loss: 0.432521, acc: 61.72%, op_acc: 44.53%] [G loss: 1.637358]\n",
      "epoch:39 step:30771[D loss: 0.382243, acc: 71.09%, op_acc: 37.50%] [G loss: 1.639786]\n",
      "epoch:39 step:30772[D loss: 0.435647, acc: 66.41%, op_acc: 40.62%] [G loss: 1.289237]\n",
      "epoch:39 step:30773[D loss: 0.336237, acc: 74.22%, op_acc: 50.00%] [G loss: 1.724444]\n",
      "epoch:39 step:30774[D loss: 0.367705, acc: 71.88%, op_acc: 52.34%] [G loss: 1.445213]\n",
      "epoch:39 step:30775[D loss: 0.369777, acc: 70.31%, op_acc: 43.75%] [G loss: 1.040367]\n",
      "epoch:39 step:30776[D loss: 0.468947, acc: 62.50%, op_acc: 38.28%] [G loss: 1.391719]\n",
      "epoch:39 step:30777[D loss: 0.349958, acc: 77.34%, op_acc: 41.41%] [G loss: 1.573519]\n",
      "epoch:39 step:30778[D loss: 0.313992, acc: 75.78%, op_acc: 53.12%] [G loss: 1.398954]\n",
      "epoch:39 step:30779[D loss: 0.398341, acc: 69.53%, op_acc: 45.31%] [G loss: 1.595081]\n",
      "epoch:39 step:30780[D loss: 0.359234, acc: 73.44%, op_acc: 50.78%] [G loss: 1.573871]\n",
      "epoch:39 step:30781[D loss: 0.353626, acc: 72.66%, op_acc: 49.22%] [G loss: 1.444630]\n",
      "epoch:39 step:30782[D loss: 0.335471, acc: 75.78%, op_acc: 46.09%] [G loss: 1.477165]\n",
      "epoch:39 step:30783[D loss: 0.347852, acc: 76.56%, op_acc: 48.44%] [G loss: 1.207433]\n",
      "epoch:39 step:30784[D loss: 0.341123, acc: 75.78%, op_acc: 43.75%] [G loss: 1.408364]\n",
      "epoch:39 step:30785[D loss: 0.387101, acc: 65.62%, op_acc: 46.09%] [G loss: 1.476065]\n",
      "epoch:39 step:30786[D loss: 0.387042, acc: 71.09%, op_acc: 41.41%] [G loss: 1.274529]\n",
      "epoch:39 step:30787[D loss: 0.296026, acc: 82.03%, op_acc: 57.03%] [G loss: 1.489185]\n",
      "epoch:39 step:30788[D loss: 0.394794, acc: 64.84%, op_acc: 48.44%] [G loss: 1.333571]\n",
      "epoch:39 step:30789[D loss: 0.359094, acc: 68.75%, op_acc: 41.41%] [G loss: 1.238175]\n",
      "epoch:39 step:30790[D loss: 0.396340, acc: 64.84%, op_acc: 43.75%] [G loss: 1.423418]\n",
      "epoch:39 step:30791[D loss: 0.374468, acc: 72.66%, op_acc: 49.22%] [G loss: 1.194669]\n",
      "epoch:39 step:30792[D loss: 0.273438, acc: 82.81%, op_acc: 50.00%] [G loss: 1.491602]\n",
      "epoch:39 step:30793[D loss: 0.368841, acc: 73.44%, op_acc: 42.97%] [G loss: 1.629667]\n",
      "epoch:39 step:30794[D loss: 0.326295, acc: 84.38%, op_acc: 58.59%] [G loss: 1.531536]\n",
      "epoch:39 step:30795[D loss: 0.352419, acc: 75.78%, op_acc: 46.88%] [G loss: 1.426144]\n",
      "epoch:39 step:30796[D loss: 0.380275, acc: 69.53%, op_acc: 39.84%] [G loss: 1.096484]\n",
      "epoch:39 step:30797[D loss: 0.333215, acc: 73.44%, op_acc: 53.91%] [G loss: 1.203193]\n",
      "epoch:39 step:30798[D loss: 0.391111, acc: 70.31%, op_acc: 46.09%] [G loss: 1.103555]\n",
      "epoch:39 step:30799[D loss: 0.524227, acc: 49.22%, op_acc: 42.97%] [G loss: 1.406431]\n",
      "epoch:39 step:30800[D loss: 0.408538, acc: 64.06%, op_acc: 47.66%] [G loss: 1.383136]\n",
      "epoch:39 step:30801[D loss: 0.465694, acc: 57.03%, op_acc: 40.62%] [G loss: 1.170201]\n",
      "epoch:39 step:30802[D loss: 0.355526, acc: 75.00%, op_acc: 44.53%] [G loss: 1.177930]\n",
      "epoch:39 step:30803[D loss: 0.329146, acc: 75.00%, op_acc: 48.44%] [G loss: 1.557449]\n",
      "epoch:39 step:30804[D loss: 0.369888, acc: 70.31%, op_acc: 46.88%] [G loss: 1.317693]\n",
      "epoch:39 step:30805[D loss: 0.311095, acc: 79.69%, op_acc: 50.00%] [G loss: 1.055191]\n",
      "epoch:39 step:30806[D loss: 0.426118, acc: 61.72%, op_acc: 46.88%] [G loss: 1.071180]\n",
      "epoch:39 step:30807[D loss: 0.258860, acc: 87.50%, op_acc: 57.81%] [G loss: 0.882538]\n",
      "epoch:39 step:30808[D loss: 0.354561, acc: 76.56%, op_acc: 51.56%] [G loss: 1.555863]\n",
      "epoch:39 step:30809[D loss: 0.354147, acc: 73.44%, op_acc: 46.88%] [G loss: 0.752838]\n",
      "epoch:39 step:30810[D loss: 0.348246, acc: 74.22%, op_acc: 52.34%] [G loss: 0.808338]\n",
      "epoch:39 step:30811[D loss: 0.355870, acc: 76.56%, op_acc: 43.75%] [G loss: 1.066197]\n",
      "epoch:39 step:30812[D loss: 0.307496, acc: 78.12%, op_acc: 56.25%] [G loss: 0.903149]\n",
      "epoch:39 step:30813[D loss: 0.317998, acc: 77.34%, op_acc: 54.69%] [G loss: 1.607227]\n",
      "epoch:39 step:30814[D loss: 0.359964, acc: 70.31%, op_acc: 51.56%] [G loss: 0.984132]\n",
      "epoch:39 step:30815[D loss: 0.398852, acc: 68.75%, op_acc: 46.88%] [G loss: 1.026342]\n",
      "epoch:39 step:30816[D loss: 0.346329, acc: 74.22%, op_acc: 50.78%] [G loss: 1.383354]\n",
      "epoch:39 step:30817[D loss: 0.391410, acc: 68.75%, op_acc: 46.09%] [G loss: 1.622864]\n",
      "epoch:39 step:30818[D loss: 0.381477, acc: 72.66%, op_acc: 49.22%] [G loss: 1.292703]\n",
      "epoch:39 step:30819[D loss: 0.354992, acc: 69.53%, op_acc: 51.56%] [G loss: 1.381267]\n",
      "epoch:39 step:30820[D loss: 0.379768, acc: 67.97%, op_acc: 42.97%] [G loss: 1.765711]\n",
      "epoch:39 step:30821[D loss: 0.340069, acc: 73.44%, op_acc: 49.22%] [G loss: 1.757306]\n",
      "epoch:39 step:30822[D loss: 0.338155, acc: 81.25%, op_acc: 46.09%] [G loss: 1.418011]\n",
      "epoch:39 step:30823[D loss: 0.442140, acc: 65.62%, op_acc: 49.22%] [G loss: 1.637570]\n",
      "epoch:39 step:30824[D loss: 0.334912, acc: 75.78%, op_acc: 58.59%] [G loss: 1.261207]\n",
      "epoch:39 step:30825[D loss: 0.465605, acc: 55.47%, op_acc: 48.44%] [G loss: 1.256877]\n",
      "epoch:39 step:30826[D loss: 0.425687, acc: 68.75%, op_acc: 46.88%] [G loss: 1.283108]\n",
      "epoch:39 step:30827[D loss: 0.336128, acc: 79.69%, op_acc: 47.66%] [G loss: 1.194438]\n",
      "epoch:39 step:30828[D loss: 0.401757, acc: 70.31%, op_acc: 45.31%] [G loss: 1.390456]\n",
      "epoch:39 step:30829[D loss: 0.399556, acc: 64.84%, op_acc: 46.09%] [G loss: 0.998419]\n",
      "epoch:39 step:30830[D loss: 0.317210, acc: 73.44%, op_acc: 58.59%] [G loss: 1.393335]\n",
      "epoch:39 step:30831[D loss: 0.349809, acc: 70.31%, op_acc: 51.56%] [G loss: 1.272434]\n",
      "epoch:39 step:30832[D loss: 0.345577, acc: 75.78%, op_acc: 53.12%] [G loss: 1.735213]\n",
      "epoch:39 step:30833[D loss: 0.336612, acc: 79.69%, op_acc: 52.34%] [G loss: 1.536620]\n",
      "epoch:39 step:30834[D loss: 0.329464, acc: 78.91%, op_acc: 47.66%] [G loss: 1.305109]\n",
      "epoch:39 step:30835[D loss: 0.328211, acc: 72.66%, op_acc: 46.09%] [G loss: 1.227319]\n",
      "epoch:39 step:30836[D loss: 0.283858, acc: 80.47%, op_acc: 51.56%] [G loss: 1.413904]\n",
      "epoch:39 step:30837[D loss: 0.330848, acc: 75.78%, op_acc: 53.12%] [G loss: 1.458431]\n",
      "epoch:39 step:30838[D loss: 0.317637, acc: 78.91%, op_acc: 47.66%] [G loss: 1.535940]\n",
      "epoch:39 step:30839[D loss: 0.306337, acc: 81.25%, op_acc: 51.56%] [G loss: 1.493718]\n",
      "epoch:39 step:30840[D loss: 0.283780, acc: 86.72%, op_acc: 52.34%] [G loss: 1.537985]\n",
      "epoch:39 step:30841[D loss: 0.285822, acc: 77.34%, op_acc: 60.94%] [G loss: 1.442088]\n",
      "epoch:39 step:30842[D loss: 0.319539, acc: 74.22%, op_acc: 64.84%] [G loss: 1.414588]\n",
      "epoch:39 step:30843[D loss: 0.422931, acc: 67.97%, op_acc: 42.19%] [G loss: 1.137790]\n",
      "epoch:39 step:30844[D loss: 0.345949, acc: 75.78%, op_acc: 48.44%] [G loss: 1.398115]\n",
      "epoch:39 step:30845[D loss: 0.412004, acc: 62.50%, op_acc: 44.53%] [G loss: 1.383214]\n",
      "epoch:39 step:30846[D loss: 0.343338, acc: 78.12%, op_acc: 59.38%] [G loss: 1.147745]\n",
      "epoch:39 step:30847[D loss: 0.379166, acc: 72.66%, op_acc: 53.12%] [G loss: 1.104003]\n",
      "epoch:39 step:30848[D loss: 0.383479, acc: 69.53%, op_acc: 49.22%] [G loss: 1.186048]\n",
      "epoch:39 step:30849[D loss: 0.339405, acc: 77.34%, op_acc: 49.22%] [G loss: 1.256716]\n",
      "epoch:39 step:30850[D loss: 0.382965, acc: 65.62%, op_acc: 53.12%] [G loss: 1.183512]\n",
      "epoch:39 step:30851[D loss: 0.311215, acc: 74.22%, op_acc: 53.12%] [G loss: 1.170069]\n",
      "epoch:39 step:30852[D loss: 0.310986, acc: 78.91%, op_acc: 55.47%] [G loss: 0.910007]\n",
      "epoch:39 step:30853[D loss: 0.309088, acc: 79.69%, op_acc: 49.22%] [G loss: 1.143064]\n",
      "epoch:39 step:30854[D loss: 0.333070, acc: 75.00%, op_acc: 52.34%] [G loss: 1.192091]\n",
      "epoch:39 step:30855[D loss: 0.329430, acc: 75.00%, op_acc: 50.00%] [G loss: 1.340728]\n",
      "epoch:39 step:30856[D loss: 0.415935, acc: 60.94%, op_acc: 47.66%] [G loss: 0.867807]\n",
      "epoch:39 step:30857[D loss: 0.378593, acc: 71.09%, op_acc: 49.22%] [G loss: 1.123071]\n",
      "epoch:39 step:30858[D loss: 0.340670, acc: 72.66%, op_acc: 49.22%] [G loss: 1.139685]\n",
      "epoch:39 step:30859[D loss: 0.318585, acc: 75.00%, op_acc: 59.38%] [G loss: 1.252104]\n",
      "epoch:39 step:30860[D loss: 0.382460, acc: 73.44%, op_acc: 50.00%] [G loss: 1.030040]\n",
      "epoch:39 step:30861[D loss: 0.340353, acc: 75.00%, op_acc: 47.66%] [G loss: 1.243619]\n",
      "epoch:39 step:30862[D loss: 0.321849, acc: 78.12%, op_acc: 56.25%] [G loss: 1.244953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30863[D loss: 0.256826, acc: 86.72%, op_acc: 56.25%] [G loss: 1.104363]\n",
      "epoch:39 step:30864[D loss: 0.394677, acc: 69.53%, op_acc: 52.34%] [G loss: 1.037793]\n",
      "epoch:39 step:30865[D loss: 0.377561, acc: 67.19%, op_acc: 50.00%] [G loss: 1.024457]\n",
      "epoch:39 step:30866[D loss: 0.282216, acc: 80.47%, op_acc: 55.47%] [G loss: 1.161290]\n",
      "epoch:39 step:30867[D loss: 0.374764, acc: 69.53%, op_acc: 46.88%] [G loss: 0.983082]\n",
      "epoch:39 step:30868[D loss: 0.328597, acc: 76.56%, op_acc: 49.22%] [G loss: 1.112544]\n",
      "epoch:39 step:30869[D loss: 0.389497, acc: 67.97%, op_acc: 44.53%] [G loss: 1.335747]\n",
      "epoch:39 step:30870[D loss: 0.389041, acc: 70.31%, op_acc: 46.88%] [G loss: 1.282222]\n",
      "epoch:39 step:30871[D loss: 0.363062, acc: 73.44%, op_acc: 46.88%] [G loss: 1.180053]\n",
      "epoch:39 step:30872[D loss: 0.423669, acc: 66.41%, op_acc: 38.28%] [G loss: 1.060769]\n",
      "epoch:39 step:30873[D loss: 0.387181, acc: 71.09%, op_acc: 39.84%] [G loss: 1.442158]\n",
      "epoch:39 step:30874[D loss: 0.372758, acc: 71.09%, op_acc: 48.44%] [G loss: 1.380167]\n",
      "epoch:39 step:30875[D loss: 0.360457, acc: 66.41%, op_acc: 42.19%] [G loss: 1.631554]\n",
      "epoch:39 step:30876[D loss: 0.324755, acc: 78.91%, op_acc: 54.69%] [G loss: 1.431614]\n",
      "epoch:39 step:30877[D loss: 0.391946, acc: 67.19%, op_acc: 50.78%] [G loss: 1.630056]\n",
      "epoch:39 step:30878[D loss: 0.329458, acc: 76.56%, op_acc: 53.12%] [G loss: 1.454171]\n",
      "epoch:39 step:30879[D loss: 0.408067, acc: 67.19%, op_acc: 46.88%] [G loss: 1.219853]\n",
      "epoch:39 step:30880[D loss: 0.463339, acc: 58.59%, op_acc: 43.75%] [G loss: 1.214923]\n",
      "epoch:39 step:30881[D loss: 0.353241, acc: 71.88%, op_acc: 41.41%] [G loss: 1.334910]\n",
      "epoch:39 step:30882[D loss: 0.448964, acc: 57.81%, op_acc: 48.44%] [G loss: 1.261688]\n",
      "epoch:39 step:30883[D loss: 0.324739, acc: 77.34%, op_acc: 50.78%] [G loss: 1.336290]\n",
      "epoch:39 step:30884[D loss: 0.446405, acc: 63.28%, op_acc: 37.50%] [G loss: 1.061182]\n",
      "epoch:39 step:30885[D loss: 0.391376, acc: 67.19%, op_acc: 46.88%] [G loss: 1.247044]\n",
      "epoch:39 step:30886[D loss: 0.347182, acc: 72.66%, op_acc: 46.09%] [G loss: 1.258873]\n",
      "epoch:39 step:30887[D loss: 0.439654, acc: 61.72%, op_acc: 45.31%] [G loss: 0.977665]\n",
      "epoch:39 step:30888[D loss: 0.338994, acc: 78.12%, op_acc: 46.88%] [G loss: 1.293482]\n",
      "epoch:39 step:30889[D loss: 0.316915, acc: 81.25%, op_acc: 48.44%] [G loss: 0.987175]\n",
      "epoch:39 step:30890[D loss: 0.339884, acc: 71.88%, op_acc: 53.91%] [G loss: 1.372312]\n",
      "epoch:39 step:30891[D loss: 0.394149, acc: 67.97%, op_acc: 53.12%] [G loss: 1.002008]\n",
      "epoch:39 step:30892[D loss: 0.347240, acc: 73.44%, op_acc: 43.75%] [G loss: 0.966948]\n",
      "epoch:39 step:30893[D loss: 0.321117, acc: 76.56%, op_acc: 62.50%] [G loss: 1.274002]\n",
      "epoch:39 step:30894[D loss: 0.334368, acc: 76.56%, op_acc: 54.69%] [G loss: 1.261956]\n",
      "epoch:39 step:30895[D loss: 0.383429, acc: 72.66%, op_acc: 42.97%] [G loss: 1.179200]\n",
      "epoch:39 step:30896[D loss: 0.370285, acc: 75.00%, op_acc: 45.31%] [G loss: 1.163171]\n",
      "epoch:39 step:30897[D loss: 0.287563, acc: 80.47%, op_acc: 52.34%] [G loss: 1.063695]\n",
      "epoch:39 step:30898[D loss: 0.361565, acc: 72.66%, op_acc: 50.00%] [G loss: 1.337209]\n",
      "epoch:39 step:30899[D loss: 0.354558, acc: 70.31%, op_acc: 51.56%] [G loss: 1.273046]\n",
      "epoch:39 step:30900[D loss: 0.378305, acc: 70.31%, op_acc: 45.31%] [G loss: 1.369875]\n",
      "epoch:39 step:30901[D loss: 0.273903, acc: 85.94%, op_acc: 51.56%] [G loss: 1.279671]\n",
      "epoch:39 step:30902[D loss: 0.311075, acc: 81.25%, op_acc: 50.00%] [G loss: 1.313166]\n",
      "epoch:39 step:30903[D loss: 0.286911, acc: 82.81%, op_acc: 56.25%] [G loss: 1.344774]\n",
      "epoch:39 step:30904[D loss: 0.318205, acc: 80.47%, op_acc: 50.78%] [G loss: 1.468576]\n",
      "epoch:39 step:30905[D loss: 0.349258, acc: 78.91%, op_acc: 51.56%] [G loss: 1.163683]\n",
      "epoch:39 step:30906[D loss: 0.324232, acc: 80.47%, op_acc: 46.09%] [G loss: 1.382796]\n",
      "epoch:39 step:30907[D loss: 0.277094, acc: 85.94%, op_acc: 49.22%] [G loss: 1.480547]\n",
      "epoch:39 step:30908[D loss: 0.281717, acc: 78.91%, op_acc: 46.88%] [G loss: 1.470760]\n",
      "epoch:39 step:30909[D loss: 0.376889, acc: 75.78%, op_acc: 45.31%] [G loss: 1.458457]\n",
      "epoch:39 step:30910[D loss: 0.361753, acc: 68.75%, op_acc: 57.03%] [G loss: 1.491744]\n",
      "epoch:39 step:30911[D loss: 0.288918, acc: 80.47%, op_acc: 53.91%] [G loss: 0.810940]\n",
      "epoch:39 step:30912[D loss: 0.414432, acc: 63.28%, op_acc: 35.94%] [G loss: 2.002613]\n",
      "epoch:39 step:30913[D loss: 0.363241, acc: 74.22%, op_acc: 51.56%] [G loss: 1.973929]\n",
      "epoch:39 step:30914[D loss: 0.428460, acc: 64.84%, op_acc: 51.56%] [G loss: 1.788703]\n",
      "epoch:39 step:30915[D loss: 0.318425, acc: 77.34%, op_acc: 52.34%] [G loss: 1.557360]\n",
      "epoch:39 step:30916[D loss: 0.402703, acc: 67.19%, op_acc: 48.44%] [G loss: 1.100767]\n",
      "epoch:39 step:30917[D loss: 0.369961, acc: 67.97%, op_acc: 50.00%] [G loss: 1.259145]\n",
      "epoch:39 step:30918[D loss: 0.339666, acc: 68.75%, op_acc: 52.34%] [G loss: 1.546072]\n",
      "epoch:39 step:30919[D loss: 0.274479, acc: 83.59%, op_acc: 56.25%] [G loss: 1.531612]\n",
      "epoch:39 step:30920[D loss: 0.323130, acc: 70.31%, op_acc: 53.12%] [G loss: 1.703636]\n",
      "epoch:39 step:30921[D loss: 0.360038, acc: 75.78%, op_acc: 48.44%] [G loss: 1.297163]\n",
      "epoch:39 step:30922[D loss: 0.337572, acc: 72.66%, op_acc: 53.91%] [G loss: 1.351105]\n",
      "epoch:39 step:30923[D loss: 0.398995, acc: 67.19%, op_acc: 41.41%] [G loss: 1.115617]\n",
      "epoch:39 step:30924[D loss: 0.312504, acc: 74.22%, op_acc: 44.53%] [G loss: 1.196750]\n",
      "epoch:39 step:30925[D loss: 0.281347, acc: 82.03%, op_acc: 61.72%] [G loss: 1.529921]\n",
      "epoch:39 step:30926[D loss: 0.312444, acc: 75.78%, op_acc: 53.12%] [G loss: 1.054368]\n",
      "epoch:39 step:30927[D loss: 0.373418, acc: 67.19%, op_acc: 47.66%] [G loss: 0.935600]\n",
      "epoch:39 step:30928[D loss: 0.345119, acc: 68.75%, op_acc: 50.00%] [G loss: 1.371296]\n",
      "epoch:39 step:30929[D loss: 0.330294, acc: 76.56%, op_acc: 50.78%] [G loss: 1.801976]\n",
      "epoch:39 step:30930[D loss: 0.306191, acc: 79.69%, op_acc: 52.34%] [G loss: 1.466608]\n",
      "epoch:39 step:30931[D loss: 0.366853, acc: 75.00%, op_acc: 45.31%] [G loss: 1.678374]\n",
      "epoch:39 step:30932[D loss: 0.381987, acc: 65.62%, op_acc: 50.00%] [G loss: 1.321304]\n",
      "epoch:39 step:30933[D loss: 0.347082, acc: 73.44%, op_acc: 44.53%] [G loss: 1.448407]\n",
      "epoch:39 step:30934[D loss: 0.365298, acc: 72.66%, op_acc: 48.44%] [G loss: 1.342273]\n",
      "epoch:39 step:30935[D loss: 0.365308, acc: 71.88%, op_acc: 47.66%] [G loss: 1.276386]\n",
      "epoch:39 step:30936[D loss: 0.335235, acc: 76.56%, op_acc: 46.09%] [G loss: 1.375794]\n",
      "epoch:39 step:30937[D loss: 0.325184, acc: 76.56%, op_acc: 53.12%] [G loss: 1.715486]\n",
      "epoch:39 step:30938[D loss: 0.345311, acc: 72.66%, op_acc: 51.56%] [G loss: 1.533788]\n",
      "epoch:39 step:30939[D loss: 0.394133, acc: 67.19%, op_acc: 39.84%] [G loss: 1.463883]\n",
      "epoch:39 step:30940[D loss: 0.399429, acc: 69.53%, op_acc: 39.06%] [G loss: 1.220263]\n",
      "epoch:39 step:30941[D loss: 0.287584, acc: 86.72%, op_acc: 59.38%] [G loss: 1.567686]\n",
      "epoch:39 step:30942[D loss: 0.374678, acc: 71.09%, op_acc: 50.00%] [G loss: 1.091882]\n",
      "epoch:39 step:30943[D loss: 0.245966, acc: 85.16%, op_acc: 60.94%] [G loss: 1.178992]\n",
      "epoch:39 step:30944[D loss: 0.332755, acc: 75.78%, op_acc: 47.66%] [G loss: 1.121226]\n",
      "epoch:39 step:30945[D loss: 0.323333, acc: 78.12%, op_acc: 51.56%] [G loss: 1.229718]\n",
      "epoch:39 step:30946[D loss: 0.335850, acc: 75.00%, op_acc: 48.44%] [G loss: 1.443489]\n",
      "epoch:39 step:30947[D loss: 0.371221, acc: 76.56%, op_acc: 48.44%] [G loss: 1.318440]\n",
      "epoch:39 step:30948[D loss: 0.259847, acc: 83.59%, op_acc: 58.59%] [G loss: 1.220710]\n",
      "epoch:39 step:30949[D loss: 0.321717, acc: 78.12%, op_acc: 61.72%] [G loss: 1.438870]\n",
      "epoch:39 step:30950[D loss: 0.416923, acc: 67.19%, op_acc: 43.75%] [G loss: 0.865425]\n",
      "epoch:39 step:30951[D loss: 0.300379, acc: 85.16%, op_acc: 49.22%] [G loss: 1.121931]\n",
      "epoch:39 step:30952[D loss: 0.337257, acc: 79.69%, op_acc: 50.78%] [G loss: 1.108281]\n",
      "epoch:39 step:30953[D loss: 0.230789, acc: 89.84%, op_acc: 61.72%] [G loss: 1.197815]\n",
      "epoch:39 step:30954[D loss: 0.310484, acc: 75.78%, op_acc: 50.00%] [G loss: 1.332126]\n",
      "epoch:39 step:30955[D loss: 0.268546, acc: 82.81%, op_acc: 54.69%] [G loss: 1.595266]\n",
      "epoch:39 step:30956[D loss: 0.341870, acc: 73.44%, op_acc: 57.03%] [G loss: 1.455163]\n",
      "epoch:39 step:30957[D loss: 0.353248, acc: 71.88%, op_acc: 43.75%] [G loss: 1.226591]\n",
      "epoch:39 step:30958[D loss: 0.403761, acc: 70.31%, op_acc: 46.09%] [G loss: 1.474799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:30959[D loss: 0.316293, acc: 78.12%, op_acc: 57.81%] [G loss: 1.357033]\n",
      "epoch:39 step:30960[D loss: 0.318962, acc: 73.44%, op_acc: 57.03%] [G loss: 1.440201]\n",
      "epoch:39 step:30961[D loss: 0.365586, acc: 71.09%, op_acc: 47.66%] [G loss: 1.418637]\n",
      "epoch:39 step:30962[D loss: 0.317225, acc: 78.12%, op_acc: 52.34%] [G loss: 1.590096]\n",
      "epoch:39 step:30963[D loss: 0.307853, acc: 74.22%, op_acc: 63.28%] [G loss: 0.857204]\n",
      "epoch:39 step:30964[D loss: 0.395542, acc: 63.28%, op_acc: 42.19%] [G loss: 1.315317]\n",
      "epoch:39 step:30965[D loss: 0.360516, acc: 68.75%, op_acc: 52.34%] [G loss: 1.713257]\n",
      "epoch:39 step:30966[D loss: 0.408940, acc: 64.06%, op_acc: 48.44%] [G loss: 1.731324]\n",
      "epoch:39 step:30967[D loss: 0.421301, acc: 64.84%, op_acc: 45.31%] [G loss: 1.186671]\n",
      "epoch:39 step:30968[D loss: 0.469621, acc: 55.47%, op_acc: 47.66%] [G loss: 1.630789]\n",
      "epoch:39 step:30969[D loss: 0.380981, acc: 65.62%, op_acc: 54.69%] [G loss: 1.579243]\n",
      "epoch:39 step:30970[D loss: 0.413644, acc: 60.94%, op_acc: 47.66%] [G loss: 1.462046]\n",
      "epoch:39 step:30971[D loss: 0.449473, acc: 60.16%, op_acc: 46.09%] [G loss: 1.149582]\n",
      "epoch:39 step:30972[D loss: 0.384436, acc: 74.22%, op_acc: 42.97%] [G loss: 1.247823]\n",
      "epoch:39 step:30973[D loss: 0.392325, acc: 70.31%, op_acc: 44.53%] [G loss: 1.209673]\n",
      "epoch:39 step:30974[D loss: 0.290097, acc: 80.47%, op_acc: 55.47%] [G loss: 1.717118]\n",
      "epoch:39 step:30975[D loss: 0.329399, acc: 76.56%, op_acc: 52.34%] [G loss: 1.288277]\n",
      "epoch:39 step:30976[D loss: 0.404184, acc: 66.41%, op_acc: 41.41%] [G loss: 0.829155]\n",
      "epoch:39 step:30977[D loss: 0.445162, acc: 64.06%, op_acc: 44.53%] [G loss: 1.321266]\n",
      "epoch:39 step:30978[D loss: 0.513562, acc: 57.81%, op_acc: 41.41%] [G loss: 1.176532]\n",
      "epoch:39 step:30979[D loss: 0.451951, acc: 61.72%, op_acc: 46.88%] [G loss: 1.404836]\n",
      "epoch:39 step:30980[D loss: 0.397319, acc: 71.09%, op_acc: 52.34%] [G loss: 1.284820]\n",
      "epoch:39 step:30981[D loss: 0.485170, acc: 51.56%, op_acc: 44.53%] [G loss: 1.324819]\n",
      "epoch:39 step:30982[D loss: 0.374441, acc: 69.53%, op_acc: 50.78%] [G loss: 1.526562]\n",
      "epoch:39 step:30983[D loss: 0.379373, acc: 69.53%, op_acc: 54.69%] [G loss: 0.814232]\n",
      "epoch:39 step:30984[D loss: 0.352242, acc: 73.44%, op_acc: 46.09%] [G loss: 0.850700]\n",
      "epoch:39 step:30985[D loss: 0.408289, acc: 67.97%, op_acc: 42.19%] [G loss: 0.855045]\n",
      "epoch:39 step:30986[D loss: 0.503781, acc: 53.12%, op_acc: 44.53%] [G loss: 0.703726]\n",
      "epoch:39 step:30987[D loss: 0.377200, acc: 71.88%, op_acc: 43.75%] [G loss: 1.189912]\n",
      "epoch:39 step:30988[D loss: 0.354640, acc: 71.88%, op_acc: 53.12%] [G loss: 1.158215]\n",
      "epoch:39 step:30989[D loss: 0.396207, acc: 66.41%, op_acc: 44.53%] [G loss: 1.221449]\n",
      "epoch:39 step:30990[D loss: 0.331805, acc: 77.34%, op_acc: 53.12%] [G loss: 1.183676]\n",
      "epoch:39 step:30991[D loss: 0.403268, acc: 72.66%, op_acc: 39.84%] [G loss: 1.266602]\n",
      "epoch:39 step:30992[D loss: 0.404827, acc: 68.75%, op_acc: 50.78%] [G loss: 0.987465]\n",
      "epoch:39 step:30993[D loss: 0.355923, acc: 74.22%, op_acc: 42.97%] [G loss: 0.860835]\n",
      "epoch:39 step:30994[D loss: 0.336007, acc: 75.00%, op_acc: 53.91%] [G loss: 1.009172]\n",
      "epoch:39 step:30995[D loss: 0.284733, acc: 78.91%, op_acc: 60.16%] [G loss: 1.129662]\n",
      "epoch:39 step:30996[D loss: 0.320553, acc: 74.22%, op_acc: 48.44%] [G loss: 1.194145]\n",
      "epoch:39 step:30997[D loss: 0.360289, acc: 75.00%, op_acc: 49.22%] [G loss: 1.064137]\n",
      "epoch:39 step:30998[D loss: 0.294786, acc: 81.25%, op_acc: 50.78%] [G loss: 1.061547]\n",
      "epoch:39 step:30999[D loss: 0.258062, acc: 85.16%, op_acc: 57.03%] [G loss: 1.073456]\n",
      "epoch:39 step:31000[D loss: 0.268018, acc: 85.94%, op_acc: 55.47%] [G loss: 1.255440]\n",
      "epoch:39 step:31001[D loss: 0.346471, acc: 71.09%, op_acc: 54.69%] [G loss: 1.224897]\n",
      "epoch:39 step:31002[D loss: 0.349407, acc: 75.00%, op_acc: 47.66%] [G loss: 1.207756]\n",
      "epoch:39 step:31003[D loss: 0.448554, acc: 62.50%, op_acc: 40.62%] [G loss: 1.748917]\n",
      "epoch:39 step:31004[D loss: 0.257986, acc: 86.72%, op_acc: 53.91%] [G loss: 1.221099]\n",
      "epoch:39 step:31005[D loss: 0.424530, acc: 59.38%, op_acc: 46.88%] [G loss: 0.970082]\n",
      "epoch:39 step:31006[D loss: 0.319329, acc: 81.25%, op_acc: 43.75%] [G loss: 1.739282]\n",
      "epoch:39 step:31007[D loss: 0.353480, acc: 78.12%, op_acc: 55.47%] [G loss: 1.300763]\n",
      "epoch:39 step:31008[D loss: 0.354646, acc: 74.22%, op_acc: 53.91%] [G loss: 1.198279]\n",
      "epoch:39 step:31009[D loss: 0.444157, acc: 57.81%, op_acc: 45.31%] [G loss: 1.045531]\n",
      "epoch:39 step:31010[D loss: 0.385671, acc: 72.66%, op_acc: 49.22%] [G loss: 0.696867]\n",
      "epoch:39 step:31011[D loss: 0.419671, acc: 65.62%, op_acc: 41.41%] [G loss: 1.249183]\n",
      "epoch:39 step:31012[D loss: 0.318868, acc: 77.34%, op_acc: 54.69%] [G loss: 0.909733]\n",
      "epoch:39 step:31013[D loss: 0.379573, acc: 71.09%, op_acc: 42.19%] [G loss: 1.043770]\n",
      "epoch:39 step:31014[D loss: 0.300737, acc: 80.47%, op_acc: 52.34%] [G loss: 1.252632]\n",
      "epoch:39 step:31015[D loss: 0.332425, acc: 72.66%, op_acc: 56.25%] [G loss: 0.855316]\n",
      "epoch:39 step:31016[D loss: 0.265747, acc: 87.50%, op_acc: 53.12%] [G loss: 0.911003]\n",
      "epoch:39 step:31017[D loss: 0.323175, acc: 76.56%, op_acc: 59.38%] [G loss: 1.082629]\n",
      "epoch:39 step:31018[D loss: 0.343844, acc: 77.34%, op_acc: 43.75%] [G loss: 1.099013]\n",
      "epoch:39 step:31019[D loss: 0.330798, acc: 78.12%, op_acc: 45.31%] [G loss: 0.919041]\n",
      "epoch:39 step:31020[D loss: 0.347077, acc: 71.88%, op_acc: 49.22%] [G loss: 0.929329]\n",
      "epoch:39 step:31021[D loss: 0.335152, acc: 78.12%, op_acc: 46.88%] [G loss: 2.060502]\n",
      "epoch:39 step:31022[D loss: 0.353065, acc: 75.00%, op_acc: 46.09%] [G loss: 1.235571]\n",
      "epoch:39 step:31023[D loss: 0.300061, acc: 80.47%, op_acc: 47.66%] [G loss: 1.085366]\n",
      "epoch:39 step:31024[D loss: 0.371354, acc: 69.53%, op_acc: 50.78%] [G loss: 0.934621]\n",
      "epoch:39 step:31025[D loss: 0.391519, acc: 66.41%, op_acc: 51.56%] [G loss: 0.931355]\n",
      "epoch:39 step:31026[D loss: 0.273022, acc: 84.38%, op_acc: 52.34%] [G loss: 0.974365]\n",
      "epoch:39 step:31027[D loss: 0.278389, acc: 82.81%, op_acc: 62.50%] [G loss: 0.901185]\n",
      "epoch:39 step:31028[D loss: 0.251904, acc: 86.72%, op_acc: 55.47%] [G loss: 0.976517]\n",
      "epoch:39 step:31029[D loss: 0.305429, acc: 78.12%, op_acc: 50.78%] [G loss: 0.922980]\n",
      "epoch:39 step:31030[D loss: 0.326541, acc: 73.44%, op_acc: 53.12%] [G loss: 1.226386]\n",
      "epoch:39 step:31031[D loss: 0.364789, acc: 67.19%, op_acc: 46.09%] [G loss: 0.937327]\n",
      "epoch:39 step:31032[D loss: 0.279437, acc: 82.81%, op_acc: 54.69%] [G loss: 0.987290]\n",
      "epoch:39 step:31033[D loss: 0.366595, acc: 71.88%, op_acc: 50.78%] [G loss: 0.804991]\n",
      "epoch:39 step:31034[D loss: 0.352612, acc: 73.44%, op_acc: 48.44%] [G loss: 0.972860]\n",
      "epoch:39 step:31035[D loss: 0.290500, acc: 80.47%, op_acc: 54.69%] [G loss: 1.205733]\n",
      "epoch:39 step:31036[D loss: 0.340629, acc: 77.34%, op_acc: 50.00%] [G loss: 1.088158]\n",
      "epoch:39 step:31037[D loss: 0.404831, acc: 65.62%, op_acc: 40.62%] [G loss: 1.108175]\n",
      "epoch:39 step:31038[D loss: 0.253313, acc: 88.28%, op_acc: 53.91%] [G loss: 1.206736]\n",
      "epoch:39 step:31039[D loss: 0.330135, acc: 77.34%, op_acc: 52.34%] [G loss: 1.095833]\n",
      "epoch:39 step:31040[D loss: 0.390866, acc: 70.31%, op_acc: 53.12%] [G loss: 0.767462]\n",
      "epoch:39 step:31041[D loss: 0.263546, acc: 85.94%, op_acc: 60.94%] [G loss: 0.882221]\n",
      "epoch:39 step:31042[D loss: 0.444653, acc: 64.06%, op_acc: 40.62%] [G loss: 0.663091]\n",
      "epoch:39 step:31043[D loss: 0.307502, acc: 78.12%, op_acc: 48.44%] [G loss: 0.894130]\n",
      "epoch:39 step:31044[D loss: 0.254876, acc: 88.28%, op_acc: 63.28%] [G loss: 0.869996]\n",
      "epoch:39 step:31045[D loss: 0.400898, acc: 67.97%, op_acc: 48.44%] [G loss: 0.961827]\n",
      "epoch:39 step:31046[D loss: 0.198382, acc: 97.66%, op_acc: 57.81%] [G loss: 1.361399]\n",
      "epoch:39 step:31047[D loss: 0.382285, acc: 64.84%, op_acc: 54.69%] [G loss: 0.977536]\n",
      "epoch:39 step:31048[D loss: 0.314376, acc: 78.91%, op_acc: 46.09%] [G loss: 1.069019]\n",
      "epoch:39 step:31049[D loss: 0.336009, acc: 75.00%, op_acc: 46.88%] [G loss: 1.774299]\n",
      "epoch:39 step:31050[D loss: 0.315521, acc: 82.03%, op_acc: 59.38%] [G loss: 0.985554]\n",
      "epoch:39 step:31051[D loss: 0.381630, acc: 72.66%, op_acc: 47.66%] [G loss: 1.802460]\n",
      "epoch:39 step:31052[D loss: 0.339017, acc: 76.56%, op_acc: 53.12%] [G loss: 0.896030]\n",
      "epoch:39 step:31053[D loss: 0.453030, acc: 62.50%, op_acc: 42.19%] [G loss: 0.844045]\n",
      "epoch:39 step:31054[D loss: 0.303852, acc: 85.16%, op_acc: 46.88%] [G loss: 0.949034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31055[D loss: 0.339477, acc: 74.22%, op_acc: 54.69%] [G loss: 1.078455]\n",
      "epoch:39 step:31056[D loss: 0.255497, acc: 87.50%, op_acc: 52.34%] [G loss: 1.483259]\n",
      "epoch:39 step:31057[D loss: 0.362720, acc: 69.53%, op_acc: 48.44%] [G loss: 0.763066]\n",
      "epoch:39 step:31058[D loss: 0.367577, acc: 71.09%, op_acc: 51.56%] [G loss: 0.849352]\n",
      "epoch:39 step:31059[D loss: 0.305335, acc: 78.91%, op_acc: 48.44%] [G loss: 1.497177]\n",
      "epoch:39 step:31060[D loss: 0.372509, acc: 67.97%, op_acc: 54.69%] [G loss: 0.759986]\n",
      "epoch:39 step:31061[D loss: 0.298987, acc: 81.25%, op_acc: 53.91%] [G loss: 0.855746]\n",
      "epoch:39 step:31062[D loss: 0.432587, acc: 65.62%, op_acc: 47.66%] [G loss: 0.863925]\n",
      "epoch:39 step:31063[D loss: 0.307179, acc: 79.69%, op_acc: 54.69%] [G loss: 0.684239]\n",
      "epoch:39 step:31064[D loss: 0.324983, acc: 76.56%, op_acc: 57.03%] [G loss: 0.696209]\n",
      "epoch:39 step:31065[D loss: 0.336478, acc: 76.56%, op_acc: 47.66%] [G loss: 0.722613]\n",
      "epoch:39 step:31066[D loss: 0.312688, acc: 81.25%, op_acc: 60.16%] [G loss: 0.769369]\n",
      "epoch:39 step:31067[D loss: 0.225194, acc: 88.28%, op_acc: 63.28%] [G loss: 0.982352]\n",
      "epoch:39 step:31068[D loss: 0.357621, acc: 71.09%, op_acc: 52.34%] [G loss: 0.811271]\n",
      "epoch:39 step:31069[D loss: 0.354026, acc: 74.22%, op_acc: 52.34%] [G loss: 0.783717]\n",
      "epoch:39 step:31070[D loss: 0.331678, acc: 75.00%, op_acc: 62.50%] [G loss: 1.006088]\n",
      "epoch:39 step:31071[D loss: 0.326308, acc: 80.47%, op_acc: 48.44%] [G loss: 0.875805]\n",
      "epoch:39 step:31072[D loss: 0.340116, acc: 73.44%, op_acc: 51.56%] [G loss: 0.922934]\n",
      "epoch:39 step:31073[D loss: 0.291627, acc: 84.38%, op_acc: 54.69%] [G loss: 0.790474]\n",
      "epoch:39 step:31074[D loss: 0.352356, acc: 78.12%, op_acc: 48.44%] [G loss: 0.884005]\n",
      "epoch:39 step:31075[D loss: 0.286172, acc: 84.38%, op_acc: 61.72%] [G loss: 0.945245]\n",
      "epoch:39 step:31076[D loss: 0.342622, acc: 74.22%, op_acc: 57.81%] [G loss: 1.667794]\n",
      "epoch:39 step:31077[D loss: 0.297072, acc: 78.91%, op_acc: 49.22%] [G loss: 1.288951]\n",
      "epoch:39 step:31078[D loss: 0.421014, acc: 64.06%, op_acc: 46.09%] [G loss: 1.139804]\n",
      "epoch:39 step:31079[D loss: 0.310965, acc: 80.47%, op_acc: 60.16%] [G loss: 0.939240]\n",
      "epoch:39 step:31080[D loss: 0.395907, acc: 61.72%, op_acc: 46.09%] [G loss: 1.086666]\n",
      "epoch:39 step:31081[D loss: 0.361966, acc: 78.91%, op_acc: 48.44%] [G loss: 0.901770]\n",
      "epoch:39 step:31082[D loss: 0.274796, acc: 85.16%, op_acc: 61.72%] [G loss: 1.399202]\n",
      "epoch:39 step:31083[D loss: 0.310818, acc: 78.91%, op_acc: 51.56%] [G loss: 0.831012]\n",
      "epoch:39 step:31084[D loss: 0.318260, acc: 78.91%, op_acc: 53.91%] [G loss: 0.666132]\n",
      "epoch:39 step:31085[D loss: 0.400858, acc: 64.84%, op_acc: 51.56%] [G loss: 0.730125]\n",
      "epoch:39 step:31086[D loss: 0.287006, acc: 82.03%, op_acc: 57.03%] [G loss: 0.696859]\n",
      "epoch:39 step:31087[D loss: 0.375645, acc: 67.97%, op_acc: 54.69%] [G loss: 0.772416]\n",
      "epoch:39 step:31088[D loss: 0.299377, acc: 81.25%, op_acc: 52.34%] [G loss: 0.937596]\n",
      "epoch:39 step:31089[D loss: 0.361278, acc: 69.53%, op_acc: 46.09%] [G loss: 0.964924]\n",
      "epoch:39 step:31090[D loss: 0.418230, acc: 63.28%, op_acc: 46.88%] [G loss: 0.882787]\n",
      "epoch:39 step:31091[D loss: 0.297482, acc: 79.69%, op_acc: 54.69%] [G loss: 0.855009]\n",
      "epoch:39 step:31092[D loss: 0.361887, acc: 75.00%, op_acc: 51.56%] [G loss: 0.872782]\n",
      "epoch:39 step:31093[D loss: 0.337437, acc: 75.00%, op_acc: 50.78%] [G loss: 0.770973]\n",
      "epoch:39 step:31094[D loss: 0.291356, acc: 82.81%, op_acc: 49.22%] [G loss: 0.877324]\n",
      "epoch:39 step:31095[D loss: 0.266210, acc: 85.94%, op_acc: 55.47%] [G loss: 0.978338]\n",
      "epoch:39 step:31096[D loss: 0.294228, acc: 84.38%, op_acc: 55.47%] [G loss: 0.819245]\n",
      "epoch:39 step:31097[D loss: 0.342626, acc: 71.88%, op_acc: 46.09%] [G loss: 0.851186]\n",
      "epoch:39 step:31098[D loss: 0.482143, acc: 55.47%, op_acc: 39.06%] [G loss: 0.947241]\n",
      "epoch:39 step:31099[D loss: 0.312315, acc: 81.25%, op_acc: 53.12%] [G loss: 0.779402]\n",
      "epoch:39 step:31100[D loss: 0.382290, acc: 69.53%, op_acc: 46.88%] [G loss: 0.883882]\n",
      "epoch:39 step:31101[D loss: 0.387636, acc: 75.00%, op_acc: 46.09%] [G loss: 1.206760]\n",
      "epoch:39 step:31102[D loss: 0.315146, acc: 75.78%, op_acc: 57.81%] [G loss: 1.052416]\n",
      "epoch:39 step:31103[D loss: 0.444803, acc: 63.28%, op_acc: 43.75%] [G loss: 0.941398]\n",
      "epoch:39 step:31104[D loss: 0.298164, acc: 82.03%, op_acc: 53.91%] [G loss: 0.924980]\n",
      "epoch:39 step:31105[D loss: 0.263131, acc: 85.16%, op_acc: 58.59%] [G loss: 1.115738]\n",
      "epoch:39 step:31106[D loss: 0.354492, acc: 71.09%, op_acc: 52.34%] [G loss: 1.226621]\n",
      "epoch:39 step:31107[D loss: 0.324197, acc: 76.56%, op_acc: 51.56%] [G loss: 1.245220]\n",
      "epoch:39 step:31108[D loss: 0.276415, acc: 82.03%, op_acc: 60.16%] [G loss: 1.338859]\n",
      "epoch:39 step:31109[D loss: 0.402650, acc: 71.09%, op_acc: 47.66%] [G loss: 0.964009]\n",
      "epoch:39 step:31110[D loss: 0.292809, acc: 79.69%, op_acc: 57.81%] [G loss: 1.006554]\n",
      "epoch:39 step:31111[D loss: 0.290923, acc: 79.69%, op_acc: 53.91%] [G loss: 0.703125]\n",
      "epoch:39 step:31112[D loss: 0.297015, acc: 80.47%, op_acc: 59.38%] [G loss: 0.682181]\n",
      "epoch:39 step:31113[D loss: 0.245926, acc: 89.06%, op_acc: 67.19%] [G loss: 0.888390]\n",
      "epoch:39 step:31114[D loss: 0.353899, acc: 76.56%, op_acc: 49.22%] [G loss: 0.947339]\n",
      "epoch:39 step:31115[D loss: 0.335513, acc: 77.34%, op_acc: 54.69%] [G loss: 1.096953]\n",
      "epoch:39 step:31116[D loss: 0.291925, acc: 79.69%, op_acc: 57.81%] [G loss: 1.411473]\n",
      "epoch:39 step:31117[D loss: 0.306931, acc: 80.47%, op_acc: 55.47%] [G loss: 1.176185]\n",
      "epoch:39 step:31118[D loss: 0.336956, acc: 74.22%, op_acc: 57.81%] [G loss: 1.031536]\n",
      "epoch:39 step:31119[D loss: 0.321167, acc: 82.03%, op_acc: 51.56%] [G loss: 1.146490]\n",
      "epoch:39 step:31120[D loss: 0.365693, acc: 72.66%, op_acc: 55.47%] [G loss: 1.003824]\n",
      "epoch:39 step:31121[D loss: 0.315509, acc: 80.47%, op_acc: 60.94%] [G loss: 1.165710]\n",
      "epoch:39 step:31122[D loss: 0.343159, acc: 70.31%, op_acc: 50.00%] [G loss: 0.838985]\n",
      "epoch:39 step:31123[D loss: 0.273800, acc: 82.03%, op_acc: 54.69%] [G loss: 0.945890]\n",
      "epoch:39 step:31124[D loss: 0.352170, acc: 75.78%, op_acc: 43.75%] [G loss: 0.979893]\n",
      "epoch:39 step:31125[D loss: 0.304717, acc: 79.69%, op_acc: 57.03%] [G loss: 1.227766]\n",
      "epoch:39 step:31126[D loss: 0.289583, acc: 81.25%, op_acc: 55.47%] [G loss: 1.256667]\n",
      "epoch:39 step:31127[D loss: 0.352262, acc: 71.88%, op_acc: 54.69%] [G loss: 0.690874]\n",
      "epoch:39 step:31128[D loss: 0.311335, acc: 78.91%, op_acc: 51.56%] [G loss: 1.108181]\n",
      "epoch:39 step:31129[D loss: 0.344716, acc: 72.66%, op_acc: 50.00%] [G loss: 0.920686]\n",
      "epoch:39 step:31130[D loss: 0.322725, acc: 76.56%, op_acc: 51.56%] [G loss: 1.015091]\n",
      "epoch:39 step:31131[D loss: 0.387454, acc: 70.31%, op_acc: 39.84%] [G loss: 0.965793]\n",
      "epoch:39 step:31132[D loss: 0.485694, acc: 60.94%, op_acc: 45.31%] [G loss: 0.927940]\n",
      "epoch:39 step:31133[D loss: 0.383030, acc: 69.53%, op_acc: 51.56%] [G loss: 0.793620]\n",
      "epoch:39 step:31134[D loss: 0.330406, acc: 79.69%, op_acc: 53.12%] [G loss: 1.706032]\n",
      "epoch:39 step:31135[D loss: 0.470506, acc: 59.38%, op_acc: 38.28%] [G loss: 1.744940]\n",
      "epoch:39 step:31136[D loss: 0.345591, acc: 78.12%, op_acc: 57.81%] [G loss: 1.179294]\n",
      "epoch:39 step:31137[D loss: 0.323138, acc: 75.00%, op_acc: 50.00%] [G loss: 1.108412]\n",
      "epoch:39 step:31138[D loss: 0.336595, acc: 75.78%, op_acc: 50.78%] [G loss: 1.303249]\n",
      "epoch:39 step:31139[D loss: 0.270011, acc: 85.94%, op_acc: 59.38%] [G loss: 1.141095]\n",
      "epoch:39 step:31140[D loss: 0.329314, acc: 80.47%, op_acc: 53.12%] [G loss: 0.947005]\n",
      "epoch:39 step:31141[D loss: 0.406749, acc: 67.19%, op_acc: 44.53%] [G loss: 1.169435]\n",
      "epoch:39 step:31142[D loss: 0.328373, acc: 76.56%, op_acc: 47.66%] [G loss: 1.135631]\n",
      "epoch:39 step:31143[D loss: 0.391141, acc: 67.19%, op_acc: 48.44%] [G loss: 1.012719]\n",
      "epoch:39 step:31144[D loss: 0.400927, acc: 65.62%, op_acc: 53.12%] [G loss: 0.931956]\n",
      "epoch:39 step:31145[D loss: 0.396330, acc: 71.09%, op_acc: 46.88%] [G loss: 0.680471]\n",
      "epoch:39 step:31146[D loss: 0.311049, acc: 76.56%, op_acc: 54.69%] [G loss: 0.840398]\n",
      "epoch:39 step:31147[D loss: 0.274838, acc: 85.94%, op_acc: 57.81%] [G loss: 0.770487]\n",
      "epoch:39 step:31148[D loss: 0.364743, acc: 66.41%, op_acc: 57.81%] [G loss: 0.833171]\n",
      "epoch:39 step:31149[D loss: 0.287239, acc: 85.16%, op_acc: 48.44%] [G loss: 0.770122]\n",
      "epoch:39 step:31150[D loss: 0.304927, acc: 81.25%, op_acc: 48.44%] [G loss: 1.000976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:31151[D loss: 0.391179, acc: 73.44%, op_acc: 49.22%] [G loss: 1.032109]\n",
      "epoch:39 step:31152[D loss: 0.304317, acc: 82.81%, op_acc: 46.88%] [G loss: 0.847718]\n",
      "epoch:39 step:31153[D loss: 0.278212, acc: 81.25%, op_acc: 58.59%] [G loss: 0.953163]\n",
      "epoch:39 step:31154[D loss: 0.329154, acc: 76.56%, op_acc: 50.78%] [G loss: 1.522185]\n",
      "epoch:39 step:31155[D loss: 0.309150, acc: 80.47%, op_acc: 56.25%] [G loss: 0.967895]\n",
      "epoch:39 step:31156[D loss: 0.316654, acc: 71.88%, op_acc: 55.47%] [G loss: 0.990317]\n",
      "epoch:39 step:31157[D loss: 0.263271, acc: 84.38%, op_acc: 54.69%] [G loss: 1.338308]\n",
      "epoch:39 step:31158[D loss: 0.405536, acc: 65.62%, op_acc: 46.09%] [G loss: 0.826129]\n",
      "epoch:39 step:31159[D loss: 0.372854, acc: 72.66%, op_acc: 41.41%] [G loss: 0.653382]\n",
      "epoch:39 step:31160[D loss: 0.278997, acc: 87.50%, op_acc: 58.59%] [G loss: 0.920163]\n",
      "epoch:39 step:31161[D loss: 0.342937, acc: 75.00%, op_acc: 50.00%] [G loss: 0.942549]\n",
      "epoch:39 step:31162[D loss: 0.400148, acc: 65.62%, op_acc: 37.50%] [G loss: 1.342371]\n",
      "epoch:39 step:31163[D loss: 0.316734, acc: 75.78%, op_acc: 53.12%] [G loss: 0.864060]\n",
      "epoch:39 step:31164[D loss: 0.308451, acc: 77.34%, op_acc: 57.81%] [G loss: 0.587015]\n",
      "epoch:39 step:31165[D loss: 0.326728, acc: 74.22%, op_acc: 52.34%] [G loss: 0.552459]\n",
      "epoch:39 step:31166[D loss: 0.311691, acc: 82.81%, op_acc: 49.22%] [G loss: 0.575767]\n",
      "epoch:39 step:31167[D loss: 0.283788, acc: 84.38%, op_acc: 64.06%] [G loss: 0.495913]\n",
      "epoch:39 step:31168[D loss: 0.267657, acc: 85.94%, op_acc: 50.78%] [G loss: 0.543779]\n",
      "epoch:39 step:31169[D loss: 0.360784, acc: 68.75%, op_acc: 54.69%] [G loss: 0.512201]\n",
      "epoch:39 step:31170[D loss: 0.310039, acc: 79.69%, op_acc: 57.03%] [G loss: 0.541886]\n",
      "epoch:39 step:31171[D loss: 0.336190, acc: 72.66%, op_acc: 62.50%] [G loss: 0.697975]\n",
      "epoch:39 step:31172[D loss: 0.314671, acc: 72.66%, op_acc: 56.25%] [G loss: 0.670453]\n",
      "epoch:39 step:31173[D loss: 0.424747, acc: 61.72%, op_acc: 40.62%] [G loss: 0.600282]\n",
      "epoch:39 step:31174[D loss: 0.294413, acc: 77.34%, op_acc: 60.16%] [G loss: 0.638155]\n",
      "epoch:39 step:31175[D loss: 0.315165, acc: 82.03%, op_acc: 55.47%] [G loss: 0.620089]\n",
      "epoch:39 step:31176[D loss: 0.243727, acc: 84.38%, op_acc: 64.06%] [G loss: 0.777109]\n",
      "epoch:39 step:31177[D loss: 0.262586, acc: 86.72%, op_acc: 57.81%] [G loss: 0.545974]\n",
      "epoch:39 step:31178[D loss: 0.326736, acc: 72.66%, op_acc: 50.78%] [G loss: 0.727885]\n",
      "epoch:39 step:31179[D loss: 0.334712, acc: 80.47%, op_acc: 46.88%] [G loss: 0.921006]\n",
      "epoch:39 step:31180[D loss: 0.351625, acc: 73.44%, op_acc: 50.00%] [G loss: 0.943513]\n",
      "epoch:39 step:31181[D loss: 0.306485, acc: 79.69%, op_acc: 56.25%] [G loss: 1.179544]\n",
      "epoch:39 step:31182[D loss: 0.380806, acc: 68.75%, op_acc: 56.25%] [G loss: 1.141650]\n",
      "epoch:39 step:31183[D loss: 0.318471, acc: 81.25%, op_acc: 53.12%] [G loss: 1.235188]\n",
      "epoch:39 step:31184[D loss: 0.348659, acc: 80.47%, op_acc: 51.56%] [G loss: 1.057654]\n",
      "epoch:39 step:31185[D loss: 0.284913, acc: 82.03%, op_acc: 50.78%] [G loss: 1.064132]\n",
      "epoch:39 step:31186[D loss: 0.317027, acc: 82.81%, op_acc: 53.91%] [G loss: 0.958910]\n",
      "epoch:39 step:31187[D loss: 0.342123, acc: 75.00%, op_acc: 37.50%] [G loss: 1.567718]\n",
      "epoch:39 step:31188[D loss: 0.305473, acc: 74.22%, op_acc: 53.91%] [G loss: 1.415260]\n",
      "epoch:39 step:31189[D loss: 0.289499, acc: 78.91%, op_acc: 51.56%] [G loss: 1.411635]\n",
      "epoch:39 step:31190[D loss: 0.348371, acc: 78.12%, op_acc: 47.66%] [G loss: 1.074889]\n",
      "epoch:39 step:31191[D loss: 0.415722, acc: 68.75%, op_acc: 39.84%] [G loss: 1.158679]\n",
      "epoch:39 step:31192[D loss: 0.326717, acc: 78.12%, op_acc: 60.16%] [G loss: 1.217852]\n",
      "epoch:39 step:31193[D loss: 0.418175, acc: 65.62%, op_acc: 42.97%] [G loss: 1.736662]\n",
      "epoch:39 step:31194[D loss: 0.401017, acc: 64.84%, op_acc: 45.31%] [G loss: 1.215278]\n",
      "epoch:39 step:31195[D loss: 0.380700, acc: 69.53%, op_acc: 44.53%] [G loss: 1.333467]\n",
      "epoch:39 step:31196[D loss: 0.329872, acc: 73.44%, op_acc: 61.72%] [G loss: 0.641938]\n",
      "epoch:39 step:31197[D loss: 0.452890, acc: 61.72%, op_acc: 35.94%] [G loss: 0.911841]\n",
      "epoch:39 step:31198[D loss: 0.264550, acc: 85.94%, op_acc: 52.34%] [G loss: 0.868000]\n",
      "epoch:39 step:31199[D loss: 0.329610, acc: 78.12%, op_acc: 53.12%] [G loss: 1.809234]\n",
      "epoch:39 step:31200[D loss: 0.322520, acc: 72.66%, op_acc: 50.00%] [G loss: 0.724541]\n",
      "epoch:39 step:31201[D loss: 0.354059, acc: 73.44%, op_acc: 48.44%] [G loss: 0.952624]\n",
      "epoch:39 step:31202[D loss: 0.375967, acc: 75.00%, op_acc: 47.66%] [G loss: 1.358519]\n",
      "epoch:39 step:31203[D loss: 0.323543, acc: 75.00%, op_acc: 46.88%] [G loss: 0.666190]\n",
      "epoch:39 step:31204[D loss: 0.318543, acc: 78.12%, op_acc: 57.03%] [G loss: 0.854948]\n",
      "epoch:39 step:31205[D loss: 0.412765, acc: 65.62%, op_acc: 51.56%] [G loss: 0.645998]\n",
      "epoch:39 step:31206[D loss: 0.347767, acc: 73.44%, op_acc: 43.75%] [G loss: 1.495240]\n",
      "epoch:39 step:31207[D loss: 0.445607, acc: 64.06%, op_acc: 45.31%] [G loss: 0.650712]\n",
      "epoch:39 step:31208[D loss: 0.323849, acc: 77.34%, op_acc: 57.03%] [G loss: 0.866017]\n",
      "epoch:39 step:31209[D loss: 0.437100, acc: 62.50%, op_acc: 49.22%] [G loss: 0.872703]\n",
      "epoch:39 step:31210[D loss: 0.422417, acc: 66.41%, op_acc: 42.19%] [G loss: 0.910243]\n",
      "epoch:39 step:31211[D loss: 0.380957, acc: 71.09%, op_acc: 53.91%] [G loss: 0.984832]\n",
      "epoch:39 step:31212[D loss: 0.263537, acc: 79.69%, op_acc: 61.72%] [G loss: 0.914254]\n",
      "epoch:39 step:31213[D loss: 0.236442, acc: 86.72%, op_acc: 61.72%] [G loss: 1.038061]\n",
      "epoch:39 step:31214[D loss: 0.263834, acc: 82.81%, op_acc: 55.47%] [G loss: 0.870899]\n",
      "epoch:39 step:31215[D loss: 0.299722, acc: 77.34%, op_acc: 53.91%] [G loss: 1.084321]\n",
      "epoch:39 step:31216[D loss: 0.299848, acc: 77.34%, op_acc: 58.59%] [G loss: 1.296983]\n",
      "epoch:39 step:31217[D loss: 0.303516, acc: 77.34%, op_acc: 60.16%] [G loss: 1.241851]\n",
      "epoch:39 step:31218[D loss: 0.427400, acc: 58.59%, op_acc: 48.44%] [G loss: 1.304525]\n",
      "epoch:39 step:31219[D loss: 0.294484, acc: 75.78%, op_acc: 52.34%] [G loss: 1.360657]\n",
      "epoch:39 step:31220[D loss: 0.252254, acc: 86.72%, op_acc: 69.53%] [G loss: 1.237602]\n",
      "epoch:39 step:31221[D loss: 0.327075, acc: 79.69%, op_acc: 63.28%] [G loss: 0.953111]\n",
      "epoch:39 step:31222[D loss: 0.412384, acc: 63.28%, op_acc: 51.56%] [G loss: 1.145434]\n",
      "epoch:39 step:31223[D loss: 0.255493, acc: 83.59%, op_acc: 57.81%] [G loss: 0.962251]\n",
      "epoch:39 step:31224[D loss: 0.252576, acc: 88.28%, op_acc: 64.06%] [G loss: 1.008851]\n",
      "epoch:39 step:31225[D loss: 0.338808, acc: 73.44%, op_acc: 49.22%] [G loss: 0.933751]\n",
      "epoch:39 step:31226[D loss: 0.244544, acc: 86.72%, op_acc: 64.06%] [G loss: 0.970587]\n",
      "epoch:39 step:31227[D loss: 0.336388, acc: 74.22%, op_acc: 48.44%] [G loss: 1.205664]\n",
      "epoch:39 step:31228[D loss: 0.287741, acc: 81.25%, op_acc: 65.62%] [G loss: 1.354742]\n",
      "epoch:39 step:31229[D loss: 0.309484, acc: 77.34%, op_acc: 58.59%] [G loss: 1.097950]\n",
      "epoch:39 step:31230[D loss: 0.358723, acc: 70.31%, op_acc: 50.00%] [G loss: 0.851965]\n",
      "epoch:39 step:31231[D loss: 0.477399, acc: 60.16%, op_acc: 38.28%] [G loss: 0.908390]\n",
      "epoch:39 step:31232[D loss: 0.374675, acc: 71.09%, op_acc: 44.53%] [G loss: 1.054186]\n",
      "epoch:39 step:31233[D loss: 0.291974, acc: 77.34%, op_acc: 62.50%] [G loss: 2.176817]\n",
      "epoch:39 step:31234[D loss: 0.296910, acc: 84.38%, op_acc: 50.78%] [G loss: 1.136275]\n",
      "epoch:39 step:31235[D loss: 0.265997, acc: 85.94%, op_acc: 55.47%] [G loss: 1.201149]\n",
      "epoch:39 step:31236[D loss: 0.407597, acc: 61.72%, op_acc: 41.41%] [G loss: 0.960383]\n",
      "epoch:39 step:31237[D loss: 0.322743, acc: 80.47%, op_acc: 52.34%] [G loss: 1.077728]\n",
      "epoch:39 step:31238[D loss: 0.348628, acc: 75.00%, op_acc: 52.34%] [G loss: 1.054726]\n",
      "epoch:39 step:31239[D loss: 0.311315, acc: 73.44%, op_acc: 67.97%] [G loss: 0.843415]\n",
      "epoch:39 step:31240[D loss: 0.299373, acc: 78.91%, op_acc: 59.38%] [G loss: 0.958008]\n",
      "epoch:40 step:31241[D loss: 0.278222, acc: 79.69%, op_acc: 59.38%] [G loss: 1.797523]\n",
      "epoch:40 step:31242[D loss: 0.337355, acc: 78.12%, op_acc: 53.91%] [G loss: 0.870434]\n",
      "epoch:40 step:31243[D loss: 0.405292, acc: 66.41%, op_acc: 50.00%] [G loss: 1.695422]\n",
      "epoch:40 step:31244[D loss: 0.386164, acc: 64.84%, op_acc: 57.81%] [G loss: 0.804212]\n",
      "epoch:40 step:31245[D loss: 0.356135, acc: 73.44%, op_acc: 50.78%] [G loss: 0.906591]\n",
      "epoch:40 step:31246[D loss: 0.292883, acc: 80.47%, op_acc: 55.47%] [G loss: 1.024028]\n",
      "epoch:40 step:31247[D loss: 0.278390, acc: 84.38%, op_acc: 55.47%] [G loss: 1.001431]\n",
      "epoch:40 step:31248[D loss: 0.299261, acc: 83.59%, op_acc: 55.47%] [G loss: 0.880957]\n",
      "epoch:40 step:31249[D loss: 0.292766, acc: 79.69%, op_acc: 57.03%] [G loss: 1.276072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31250[D loss: 0.379179, acc: 69.53%, op_acc: 49.22%] [G loss: 1.075026]\n",
      "epoch:40 step:31251[D loss: 0.346674, acc: 78.91%, op_acc: 45.31%] [G loss: 1.196150]\n",
      "epoch:40 step:31252[D loss: 0.284995, acc: 80.47%, op_acc: 50.78%] [G loss: 1.524547]\n",
      "epoch:40 step:31253[D loss: 0.275609, acc: 82.81%, op_acc: 60.94%] [G loss: 1.268883]\n",
      "epoch:40 step:31254[D loss: 0.380854, acc: 71.09%, op_acc: 50.00%] [G loss: 1.242857]\n",
      "epoch:40 step:31255[D loss: 0.272350, acc: 85.94%, op_acc: 56.25%] [G loss: 1.378897]\n",
      "epoch:40 step:31256[D loss: 0.295075, acc: 79.69%, op_acc: 58.59%] [G loss: 1.168402]\n",
      "epoch:40 step:31257[D loss: 0.283317, acc: 86.72%, op_acc: 57.81%] [G loss: 0.957771]\n",
      "epoch:40 step:31258[D loss: 0.280360, acc: 82.03%, op_acc: 57.81%] [G loss: 1.170955]\n",
      "epoch:40 step:31259[D loss: 0.291816, acc: 78.12%, op_acc: 57.03%] [G loss: 1.276885]\n",
      "epoch:40 step:31260[D loss: 0.236256, acc: 89.84%, op_acc: 63.28%] [G loss: 1.394331]\n",
      "epoch:40 step:31261[D loss: 0.352467, acc: 72.66%, op_acc: 53.91%] [G loss: 1.311464]\n",
      "epoch:40 step:31262[D loss: 0.277631, acc: 83.59%, op_acc: 55.47%] [G loss: 1.393740]\n",
      "epoch:40 step:31263[D loss: 0.321587, acc: 74.22%, op_acc: 58.59%] [G loss: 1.827044]\n",
      "epoch:40 step:31264[D loss: 0.264592, acc: 88.28%, op_acc: 57.03%] [G loss: 1.619729]\n",
      "epoch:40 step:31265[D loss: 0.334806, acc: 71.09%, op_acc: 50.00%] [G loss: 2.095614]\n",
      "epoch:40 step:31266[D loss: 0.265466, acc: 85.94%, op_acc: 64.84%] [G loss: 2.067251]\n",
      "epoch:40 step:31267[D loss: 0.202002, acc: 92.19%, op_acc: 62.50%] [G loss: 2.082658]\n",
      "epoch:40 step:31268[D loss: 0.267972, acc: 79.69%, op_acc: 63.28%] [G loss: 1.840982]\n",
      "epoch:40 step:31269[D loss: 0.220227, acc: 90.62%, op_acc: 61.72%] [G loss: 1.812156]\n",
      "epoch:40 step:31270[D loss: 0.203026, acc: 90.62%, op_acc: 62.50%] [G loss: 2.589999]\n",
      "epoch:40 step:31271[D loss: 0.260700, acc: 88.28%, op_acc: 64.84%] [G loss: 2.231586]\n",
      "epoch:40 step:31272[D loss: 0.220588, acc: 89.84%, op_acc: 62.50%] [G loss: 2.094474]\n",
      "epoch:40 step:31273[D loss: 0.243269, acc: 85.94%, op_acc: 65.62%] [G loss: 2.151146]\n",
      "epoch:40 step:31274[D loss: 0.187016, acc: 92.19%, op_acc: 70.31%] [G loss: 2.216559]\n",
      "epoch:40 step:31275[D loss: 0.250649, acc: 85.94%, op_acc: 60.16%] [G loss: 2.039310]\n",
      "epoch:40 step:31276[D loss: 0.257762, acc: 85.94%, op_acc: 58.59%] [G loss: 0.487035]\n",
      "epoch:40 step:31277[D loss: 0.521242, acc: 55.47%, op_acc: 40.62%] [G loss: 2.938029]\n",
      "epoch:40 step:31278[D loss: 0.516030, acc: 58.59%, op_acc: 43.75%] [G loss: 2.847121]\n",
      "epoch:40 step:31279[D loss: 0.353459, acc: 75.78%, op_acc: 60.94%] [G loss: 2.533258]\n",
      "epoch:40 step:31280[D loss: 0.410675, acc: 71.88%, op_acc: 50.78%] [G loss: 2.187162]\n",
      "epoch:40 step:31281[D loss: 0.508591, acc: 46.88%, op_acc: 46.09%] [G loss: 1.698935]\n",
      "epoch:40 step:31282[D loss: 0.403080, acc: 68.75%, op_acc: 55.47%] [G loss: 1.544341]\n",
      "epoch:40 step:31283[D loss: 0.440991, acc: 64.06%, op_acc: 46.88%] [G loss: 1.813161]\n",
      "epoch:40 step:31284[D loss: 0.401654, acc: 64.06%, op_acc: 50.78%] [G loss: 1.375169]\n",
      "epoch:40 step:31285[D loss: 0.385161, acc: 70.31%, op_acc: 46.09%] [G loss: 1.461575]\n",
      "epoch:40 step:31286[D loss: 0.307806, acc: 78.91%, op_acc: 51.56%] [G loss: 1.444737]\n",
      "epoch:40 step:31287[D loss: 0.409269, acc: 67.19%, op_acc: 42.19%] [G loss: 1.473515]\n",
      "epoch:40 step:31288[D loss: 0.311155, acc: 82.03%, op_acc: 46.88%] [G loss: 1.446264]\n",
      "epoch:40 step:31289[D loss: 0.318677, acc: 75.00%, op_acc: 51.56%] [G loss: 1.350128]\n",
      "epoch:40 step:31290[D loss: 0.359152, acc: 71.88%, op_acc: 44.53%] [G loss: 1.434127]\n",
      "epoch:40 step:31291[D loss: 0.378422, acc: 71.09%, op_acc: 46.88%] [G loss: 1.660362]\n",
      "epoch:40 step:31292[D loss: 0.359742, acc: 75.00%, op_acc: 46.88%] [G loss: 1.491516]\n",
      "epoch:40 step:31293[D loss: 0.405955, acc: 71.88%, op_acc: 43.75%] [G loss: 1.512936]\n",
      "epoch:40 step:31294[D loss: 0.491801, acc: 57.03%, op_acc: 46.88%] [G loss: 1.483364]\n",
      "epoch:40 step:31295[D loss: 0.406671, acc: 67.19%, op_acc: 52.34%] [G loss: 1.204915]\n",
      "epoch:40 step:31296[D loss: 0.349466, acc: 74.22%, op_acc: 46.88%] [G loss: 1.073784]\n",
      "epoch:40 step:31297[D loss: 0.362922, acc: 69.53%, op_acc: 50.00%] [G loss: 1.353878]\n",
      "epoch:40 step:31298[D loss: 0.381547, acc: 64.06%, op_acc: 56.25%] [G loss: 1.286861]\n",
      "epoch:40 step:31299[D loss: 0.373050, acc: 67.19%, op_acc: 52.34%] [G loss: 1.536727]\n",
      "epoch:40 step:31300[D loss: 0.305953, acc: 78.91%, op_acc: 53.12%] [G loss: 1.416857]\n",
      "epoch:40 step:31301[D loss: 0.325898, acc: 74.22%, op_acc: 60.16%] [G loss: 1.555002]\n",
      "epoch:40 step:31302[D loss: 0.361445, acc: 71.09%, op_acc: 46.88%] [G loss: 0.856495]\n",
      "epoch:40 step:31303[D loss: 0.529991, acc: 55.47%, op_acc: 36.72%] [G loss: 0.885850]\n",
      "epoch:40 step:31304[D loss: 0.391571, acc: 63.28%, op_acc: 46.09%] [G loss: 1.370511]\n",
      "epoch:40 step:31305[D loss: 0.373526, acc: 69.53%, op_acc: 52.34%] [G loss: 1.445526]\n",
      "epoch:40 step:31306[D loss: 0.419737, acc: 62.50%, op_acc: 48.44%] [G loss: 1.462360]\n",
      "epoch:40 step:31307[D loss: 0.363285, acc: 70.31%, op_acc: 57.81%] [G loss: 1.663371]\n",
      "epoch:40 step:31308[D loss: 0.353891, acc: 72.66%, op_acc: 49.22%] [G loss: 1.454115]\n",
      "epoch:40 step:31309[D loss: 0.348051, acc: 67.97%, op_acc: 56.25%] [G loss: 1.348058]\n",
      "epoch:40 step:31310[D loss: 0.473228, acc: 55.47%, op_acc: 44.53%] [G loss: 1.467988]\n",
      "epoch:40 step:31311[D loss: 0.422177, acc: 67.97%, op_acc: 49.22%] [G loss: 1.214331]\n",
      "epoch:40 step:31312[D loss: 0.365368, acc: 74.22%, op_acc: 50.00%] [G loss: 1.018628]\n",
      "epoch:40 step:31313[D loss: 0.387643, acc: 68.75%, op_acc: 44.53%] [G loss: 1.170373]\n",
      "epoch:40 step:31314[D loss: 0.418047, acc: 64.84%, op_acc: 42.97%] [G loss: 0.979482]\n",
      "epoch:40 step:31315[D loss: 0.300788, acc: 81.25%, op_acc: 56.25%] [G loss: 1.141331]\n",
      "epoch:40 step:31316[D loss: 0.313516, acc: 76.56%, op_acc: 60.94%] [G loss: 0.993548]\n",
      "epoch:40 step:31317[D loss: 0.438017, acc: 58.59%, op_acc: 42.97%] [G loss: 0.866773]\n",
      "epoch:40 step:31318[D loss: 0.408687, acc: 70.31%, op_acc: 40.62%] [G loss: 0.675729]\n",
      "epoch:40 step:31319[D loss: 0.359545, acc: 69.53%, op_acc: 46.88%] [G loss: 0.716545]\n",
      "epoch:40 step:31320[D loss: 0.354919, acc: 76.56%, op_acc: 44.53%] [G loss: 1.140424]\n",
      "epoch:40 step:31321[D loss: 0.350514, acc: 70.31%, op_acc: 56.25%] [G loss: 1.009270]\n",
      "epoch:40 step:31322[D loss: 0.332019, acc: 78.91%, op_acc: 47.66%] [G loss: 1.628928]\n",
      "epoch:40 step:31323[D loss: 0.437038, acc: 65.62%, op_acc: 46.09%] [G loss: 0.868664]\n",
      "epoch:40 step:31324[D loss: 0.366571, acc: 75.78%, op_acc: 49.22%] [G loss: 1.552578]\n",
      "epoch:40 step:31325[D loss: 0.296299, acc: 87.50%, op_acc: 51.56%] [G loss: 0.652609]\n",
      "epoch:40 step:31326[D loss: 0.436705, acc: 58.59%, op_acc: 43.75%] [G loss: 1.491520]\n",
      "epoch:40 step:31327[D loss: 0.379644, acc: 70.31%, op_acc: 42.19%] [G loss: 1.095330]\n",
      "epoch:40 step:31328[D loss: 0.358946, acc: 71.88%, op_acc: 49.22%] [G loss: 1.327983]\n",
      "epoch:40 step:31329[D loss: 0.394527, acc: 68.75%, op_acc: 44.53%] [G loss: 1.279791]\n",
      "epoch:40 step:31330[D loss: 0.383872, acc: 68.75%, op_acc: 42.97%] [G loss: 1.226186]\n",
      "epoch:40 step:31331[D loss: 0.409087, acc: 66.41%, op_acc: 44.53%] [G loss: 0.948497]\n",
      "epoch:40 step:31332[D loss: 0.444305, acc: 61.72%, op_acc: 42.19%] [G loss: 1.329089]\n",
      "epoch:40 step:31333[D loss: 0.280906, acc: 82.81%, op_acc: 57.03%] [G loss: 1.018597]\n",
      "epoch:40 step:31334[D loss: 0.370547, acc: 73.44%, op_acc: 46.88%] [G loss: 0.889557]\n",
      "epoch:40 step:31335[D loss: 0.354983, acc: 75.00%, op_acc: 46.88%] [G loss: 0.994819]\n",
      "epoch:40 step:31336[D loss: 0.335685, acc: 78.12%, op_acc: 46.09%] [G loss: 0.824203]\n",
      "epoch:40 step:31337[D loss: 0.320982, acc: 71.88%, op_acc: 51.56%] [G loss: 1.033490]\n",
      "epoch:40 step:31338[D loss: 0.366381, acc: 75.00%, op_acc: 49.22%] [G loss: 0.875975]\n",
      "epoch:40 step:31339[D loss: 0.404121, acc: 64.84%, op_acc: 45.31%] [G loss: 0.556350]\n",
      "epoch:40 step:31340[D loss: 0.246498, acc: 85.16%, op_acc: 54.69%] [G loss: 0.570702]\n",
      "epoch:40 step:31341[D loss: 0.321315, acc: 78.12%, op_acc: 49.22%] [G loss: 1.671366]\n",
      "epoch:40 step:31342[D loss: 0.364322, acc: 73.44%, op_acc: 48.44%] [G loss: 0.530933]\n",
      "epoch:40 step:31343[D loss: 0.341536, acc: 73.44%, op_acc: 50.78%] [G loss: 0.540460]\n",
      "epoch:40 step:31344[D loss: 0.389503, acc: 73.44%, op_acc: 40.62%] [G loss: 0.598699]\n",
      "epoch:40 step:31345[D loss: 0.344517, acc: 75.78%, op_acc: 44.53%] [G loss: 0.726369]\n",
      "epoch:40 step:31346[D loss: 0.382067, acc: 71.09%, op_acc: 42.19%] [G loss: 1.529904]\n",
      "epoch:40 step:31347[D loss: 0.333083, acc: 72.66%, op_acc: 57.03%] [G loss: 0.700554]\n",
      "epoch:40 step:31348[D loss: 0.434656, acc: 63.28%, op_acc: 46.09%] [G loss: 0.589419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31349[D loss: 0.272810, acc: 81.25%, op_acc: 51.56%] [G loss: 1.490985]\n",
      "epoch:40 step:31350[D loss: 0.321154, acc: 77.34%, op_acc: 55.47%] [G loss: 0.752775]\n",
      "epoch:40 step:31351[D loss: 0.359338, acc: 72.66%, op_acc: 54.69%] [G loss: 1.532975]\n",
      "epoch:40 step:31352[D loss: 0.283063, acc: 85.94%, op_acc: 52.34%] [G loss: 0.640118]\n",
      "epoch:40 step:31353[D loss: 0.463560, acc: 60.16%, op_acc: 37.50%] [G loss: 0.727203]\n",
      "epoch:40 step:31354[D loss: 0.338098, acc: 78.12%, op_acc: 49.22%] [G loss: 0.957986]\n",
      "epoch:40 step:31355[D loss: 0.333022, acc: 72.66%, op_acc: 50.78%] [G loss: 0.782431]\n",
      "epoch:40 step:31356[D loss: 0.339754, acc: 78.12%, op_acc: 50.78%] [G loss: 0.813026]\n",
      "epoch:40 step:31357[D loss: 0.380199, acc: 71.09%, op_acc: 46.88%] [G loss: 0.873750]\n",
      "epoch:40 step:31358[D loss: 0.382895, acc: 70.31%, op_acc: 45.31%] [G loss: 0.487000]\n",
      "epoch:40 step:31359[D loss: 0.346557, acc: 71.09%, op_acc: 53.91%] [G loss: 0.881640]\n",
      "epoch:40 step:31360[D loss: 0.295449, acc: 83.59%, op_acc: 53.12%] [G loss: 0.918261]\n",
      "epoch:40 step:31361[D loss: 0.266239, acc: 85.94%, op_acc: 60.94%] [G loss: 0.916138]\n",
      "epoch:40 step:31362[D loss: 0.399713, acc: 62.50%, op_acc: 51.56%] [G loss: 1.109381]\n",
      "epoch:40 step:31363[D loss: 0.367779, acc: 72.66%, op_acc: 49.22%] [G loss: 0.926261]\n",
      "epoch:40 step:31364[D loss: 0.373823, acc: 72.66%, op_acc: 50.78%] [G loss: 1.012477]\n",
      "epoch:40 step:31365[D loss: 0.309133, acc: 78.12%, op_acc: 57.03%] [G loss: 1.462562]\n",
      "epoch:40 step:31366[D loss: 0.359033, acc: 67.97%, op_acc: 50.78%] [G loss: 0.831261]\n",
      "epoch:40 step:31367[D loss: 0.343205, acc: 73.44%, op_acc: 46.09%] [G loss: 1.115372]\n",
      "epoch:40 step:31368[D loss: 0.291113, acc: 79.69%, op_acc: 51.56%] [G loss: 1.759313]\n",
      "epoch:40 step:31369[D loss: 0.457565, acc: 57.03%, op_acc: 53.91%] [G loss: 1.525017]\n",
      "epoch:40 step:31370[D loss: 0.389373, acc: 78.91%, op_acc: 49.22%] [G loss: 1.156492]\n",
      "epoch:40 step:31371[D loss: 0.267394, acc: 85.94%, op_acc: 49.22%] [G loss: 1.005420]\n",
      "epoch:40 step:31372[D loss: 0.245180, acc: 88.28%, op_acc: 59.38%] [G loss: 0.867223]\n",
      "epoch:40 step:31373[D loss: 0.348889, acc: 76.56%, op_acc: 45.31%] [G loss: 1.422381]\n",
      "epoch:40 step:31374[D loss: 0.401255, acc: 67.19%, op_acc: 42.97%] [G loss: 1.154119]\n",
      "epoch:40 step:31375[D loss: 0.429920, acc: 63.28%, op_acc: 48.44%] [G loss: 0.802053]\n",
      "epoch:40 step:31376[D loss: 0.335765, acc: 73.44%, op_acc: 51.56%] [G loss: 1.430478]\n",
      "epoch:40 step:31377[D loss: 0.348553, acc: 72.66%, op_acc: 45.31%] [G loss: 1.822400]\n",
      "epoch:40 step:31378[D loss: 0.393504, acc: 68.75%, op_acc: 49.22%] [G loss: 1.415745]\n",
      "epoch:40 step:31379[D loss: 0.311171, acc: 73.44%, op_acc: 58.59%] [G loss: 0.867277]\n",
      "epoch:40 step:31380[D loss: 0.363504, acc: 74.22%, op_acc: 45.31%] [G loss: 0.734384]\n",
      "epoch:40 step:31381[D loss: 0.378888, acc: 72.66%, op_acc: 43.75%] [G loss: 0.718754]\n",
      "epoch:40 step:31382[D loss: 0.357462, acc: 78.91%, op_acc: 49.22%] [G loss: 1.054495]\n",
      "epoch:40 step:31383[D loss: 0.440757, acc: 64.84%, op_acc: 43.75%] [G loss: 1.220365]\n",
      "epoch:40 step:31384[D loss: 0.340136, acc: 80.47%, op_acc: 57.81%] [G loss: 2.094073]\n",
      "epoch:40 step:31385[D loss: 0.345549, acc: 71.09%, op_acc: 46.88%] [G loss: 0.671240]\n",
      "epoch:40 step:31386[D loss: 0.390738, acc: 64.84%, op_acc: 43.75%] [G loss: 0.938304]\n",
      "epoch:40 step:31387[D loss: 0.338401, acc: 75.78%, op_acc: 52.34%] [G loss: 1.693578]\n",
      "epoch:40 step:31388[D loss: 0.346088, acc: 71.09%, op_acc: 57.03%] [G loss: 1.699066]\n",
      "epoch:40 step:31389[D loss: 0.304472, acc: 79.69%, op_acc: 50.78%] [G loss: 0.769149]\n",
      "epoch:40 step:31390[D loss: 0.349291, acc: 73.44%, op_acc: 57.81%] [G loss: 1.502666]\n",
      "epoch:40 step:31391[D loss: 0.333929, acc: 77.34%, op_acc: 53.91%] [G loss: 1.391076]\n",
      "epoch:40 step:31392[D loss: 0.398039, acc: 63.28%, op_acc: 46.88%] [G loss: 0.918057]\n",
      "epoch:40 step:31393[D loss: 0.449191, acc: 61.72%, op_acc: 52.34%] [G loss: 0.528690]\n",
      "epoch:40 step:31394[D loss: 0.323487, acc: 77.34%, op_acc: 50.78%] [G loss: 0.619985]\n",
      "epoch:40 step:31395[D loss: 0.354193, acc: 71.09%, op_acc: 55.47%] [G loss: 0.735569]\n",
      "epoch:40 step:31396[D loss: 0.357024, acc: 75.00%, op_acc: 52.34%] [G loss: 0.818783]\n",
      "epoch:40 step:31397[D loss: 0.423007, acc: 65.62%, op_acc: 48.44%] [G loss: 0.946869]\n",
      "epoch:40 step:31398[D loss: 0.286254, acc: 79.69%, op_acc: 50.78%] [G loss: 1.743682]\n",
      "epoch:40 step:31399[D loss: 0.317264, acc: 82.81%, op_acc: 53.12%] [G loss: 0.954723]\n",
      "epoch:40 step:31400[D loss: 0.466713, acc: 65.62%, op_acc: 45.31%] [G loss: 0.833716]\n",
      "epoch:40 step:31401[D loss: 0.338909, acc: 78.12%, op_acc: 48.44%] [G loss: 0.777561]\n",
      "epoch:40 step:31402[D loss: 0.286090, acc: 81.25%, op_acc: 58.59%] [G loss: 1.062473]\n",
      "epoch:40 step:31403[D loss: 0.383745, acc: 75.00%, op_acc: 45.31%] [G loss: 0.968244]\n",
      "epoch:40 step:31404[D loss: 0.399109, acc: 67.97%, op_acc: 46.09%] [G loss: 1.132077]\n",
      "epoch:40 step:31405[D loss: 0.415384, acc: 66.41%, op_acc: 46.09%] [G loss: 0.836812]\n",
      "epoch:40 step:31406[D loss: 0.413099, acc: 70.31%, op_acc: 37.50%] [G loss: 1.138839]\n",
      "epoch:40 step:31407[D loss: 0.408291, acc: 64.06%, op_acc: 45.31%] [G loss: 1.095974]\n",
      "epoch:40 step:31408[D loss: 0.428909, acc: 65.62%, op_acc: 53.12%] [G loss: 1.296889]\n",
      "epoch:40 step:31409[D loss: 0.346212, acc: 71.88%, op_acc: 53.12%] [G loss: 0.867137]\n",
      "epoch:40 step:31410[D loss: 0.367173, acc: 67.97%, op_acc: 44.53%] [G loss: 0.892358]\n",
      "epoch:40 step:31411[D loss: 0.359044, acc: 72.66%, op_acc: 49.22%] [G loss: 1.052803]\n",
      "epoch:40 step:31412[D loss: 0.306142, acc: 77.34%, op_acc: 59.38%] [G loss: 0.919391]\n",
      "epoch:40 step:31413[D loss: 0.338136, acc: 77.34%, op_acc: 49.22%] [G loss: 0.667969]\n",
      "epoch:40 step:31414[D loss: 0.445618, acc: 64.06%, op_acc: 39.84%] [G loss: 0.805027]\n",
      "epoch:40 step:31415[D loss: 0.319970, acc: 78.12%, op_acc: 48.44%] [G loss: 1.050598]\n",
      "epoch:40 step:31416[D loss: 0.270756, acc: 82.03%, op_acc: 55.47%] [G loss: 0.820377]\n",
      "epoch:40 step:31417[D loss: 0.300575, acc: 79.69%, op_acc: 52.34%] [G loss: 0.807616]\n",
      "epoch:40 step:31418[D loss: 0.416247, acc: 67.19%, op_acc: 42.97%] [G loss: 0.875728]\n",
      "epoch:40 step:31419[D loss: 0.273463, acc: 83.59%, op_acc: 57.03%] [G loss: 0.907332]\n",
      "epoch:40 step:31420[D loss: 0.292711, acc: 84.38%, op_acc: 51.56%] [G loss: 1.043715]\n",
      "epoch:40 step:31421[D loss: 0.284090, acc: 79.69%, op_acc: 54.69%] [G loss: 0.754207]\n",
      "epoch:40 step:31422[D loss: 0.323317, acc: 78.91%, op_acc: 53.91%] [G loss: 1.111235]\n",
      "epoch:40 step:31423[D loss: 0.301279, acc: 81.25%, op_acc: 50.00%] [G loss: 1.237714]\n",
      "epoch:40 step:31424[D loss: 0.243392, acc: 82.03%, op_acc: 70.31%] [G loss: 1.086652]\n",
      "epoch:40 step:31425[D loss: 0.243214, acc: 89.84%, op_acc: 66.41%] [G loss: 1.145025]\n",
      "epoch:40 step:31426[D loss: 0.262051, acc: 83.59%, op_acc: 60.94%] [G loss: 1.081523]\n",
      "epoch:40 step:31427[D loss: 0.251311, acc: 87.50%, op_acc: 63.28%] [G loss: 1.077300]\n",
      "epoch:40 step:31428[D loss: 0.377317, acc: 69.53%, op_acc: 53.12%] [G loss: 0.925786]\n",
      "epoch:40 step:31429[D loss: 0.392049, acc: 69.53%, op_acc: 42.97%] [G loss: 0.914699]\n",
      "epoch:40 step:31430[D loss: 0.368481, acc: 69.53%, op_acc: 49.22%] [G loss: 0.901997]\n",
      "epoch:40 step:31431[D loss: 0.349862, acc: 70.31%, op_acc: 52.34%] [G loss: 1.042347]\n",
      "epoch:40 step:31432[D loss: 0.281542, acc: 82.03%, op_acc: 54.69%] [G loss: 0.946466]\n",
      "epoch:40 step:31433[D loss: 0.363377, acc: 72.66%, op_acc: 50.78%] [G loss: 1.515638]\n",
      "epoch:40 step:31434[D loss: 0.324634, acc: 74.22%, op_acc: 57.03%] [G loss: 1.710682]\n",
      "epoch:40 step:31435[D loss: 0.389761, acc: 66.41%, op_acc: 49.22%] [G loss: 0.937746]\n",
      "epoch:40 step:31436[D loss: 0.304641, acc: 83.59%, op_acc: 46.09%] [G loss: 0.971107]\n",
      "epoch:40 step:31437[D loss: 0.427865, acc: 68.75%, op_acc: 41.41%] [G loss: 1.276341]\n",
      "epoch:40 step:31438[D loss: 0.405456, acc: 64.84%, op_acc: 46.09%] [G loss: 1.165324]\n",
      "epoch:40 step:31439[D loss: 0.371196, acc: 65.62%, op_acc: 50.00%] [G loss: 1.053282]\n",
      "epoch:40 step:31440[D loss: 0.348407, acc: 75.78%, op_acc: 55.47%] [G loss: 1.087247]\n",
      "epoch:40 step:31441[D loss: 0.357527, acc: 73.44%, op_acc: 52.34%] [G loss: 1.408723]\n",
      "epoch:40 step:31442[D loss: 0.374264, acc: 69.53%, op_acc: 46.09%] [G loss: 1.053664]\n",
      "epoch:40 step:31443[D loss: 0.327653, acc: 76.56%, op_acc: 54.69%] [G loss: 0.946702]\n",
      "epoch:40 step:31444[D loss: 0.323777, acc: 76.56%, op_acc: 53.91%] [G loss: 0.936771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31445[D loss: 0.326944, acc: 79.69%, op_acc: 46.09%] [G loss: 1.133417]\n",
      "epoch:40 step:31446[D loss: 0.361632, acc: 73.44%, op_acc: 48.44%] [G loss: 1.004727]\n",
      "epoch:40 step:31447[D loss: 0.294505, acc: 81.25%, op_acc: 53.91%] [G loss: 1.033835]\n",
      "epoch:40 step:31448[D loss: 0.315356, acc: 81.25%, op_acc: 48.44%] [G loss: 1.186785]\n",
      "epoch:40 step:31449[D loss: 0.340099, acc: 71.09%, op_acc: 60.94%] [G loss: 0.951834]\n",
      "epoch:40 step:31450[D loss: 0.404356, acc: 62.50%, op_acc: 46.09%] [G loss: 0.765843]\n",
      "epoch:40 step:31451[D loss: 0.425434, acc: 71.88%, op_acc: 47.66%] [G loss: 0.808958]\n",
      "epoch:40 step:31452[D loss: 0.301769, acc: 81.25%, op_acc: 54.69%] [G loss: 0.640356]\n",
      "epoch:40 step:31453[D loss: 0.312373, acc: 77.34%, op_acc: 49.22%] [G loss: 0.880763]\n",
      "epoch:40 step:31454[D loss: 0.346109, acc: 76.56%, op_acc: 47.66%] [G loss: 0.733517]\n",
      "epoch:40 step:31455[D loss: 0.316500, acc: 82.03%, op_acc: 46.88%] [G loss: 0.954641]\n",
      "epoch:40 step:31456[D loss: 0.276744, acc: 83.59%, op_acc: 59.38%] [G loss: 2.028324]\n",
      "epoch:40 step:31457[D loss: 0.318490, acc: 78.91%, op_acc: 51.56%] [G loss: 0.845885]\n",
      "epoch:40 step:31458[D loss: 0.351409, acc: 74.22%, op_acc: 53.91%] [G loss: 0.915909]\n",
      "epoch:40 step:31459[D loss: 0.394660, acc: 68.75%, op_acc: 43.75%] [G loss: 0.902594]\n",
      "epoch:40 step:31460[D loss: 0.313004, acc: 82.03%, op_acc: 53.12%] [G loss: 1.440087]\n",
      "epoch:40 step:31461[D loss: 0.319480, acc: 78.91%, op_acc: 49.22%] [G loss: 0.954833]\n",
      "epoch:40 step:31462[D loss: 0.321960, acc: 76.56%, op_acc: 53.12%] [G loss: 0.992004]\n",
      "epoch:40 step:31463[D loss: 0.416518, acc: 67.97%, op_acc: 44.53%] [G loss: 1.030444]\n",
      "epoch:40 step:31464[D loss: 0.294620, acc: 82.81%, op_acc: 71.09%] [G loss: 1.239292]\n",
      "epoch:40 step:31465[D loss: 0.296199, acc: 80.47%, op_acc: 52.34%] [G loss: 1.154574]\n",
      "epoch:40 step:31466[D loss: 0.285231, acc: 80.47%, op_acc: 54.69%] [G loss: 1.051614]\n",
      "epoch:40 step:31467[D loss: 0.298689, acc: 79.69%, op_acc: 57.81%] [G loss: 1.090117]\n",
      "epoch:40 step:31468[D loss: 0.348401, acc: 72.66%, op_acc: 42.19%] [G loss: 0.842747]\n",
      "epoch:40 step:31469[D loss: 0.340293, acc: 75.78%, op_acc: 49.22%] [G loss: 1.017613]\n",
      "epoch:40 step:31470[D loss: 0.428286, acc: 64.84%, op_acc: 43.75%] [G loss: 1.057637]\n",
      "epoch:40 step:31471[D loss: 0.244092, acc: 91.41%, op_acc: 56.25%] [G loss: 1.260158]\n",
      "epoch:40 step:31472[D loss: 0.339306, acc: 74.22%, op_acc: 52.34%] [G loss: 1.184570]\n",
      "epoch:40 step:31473[D loss: 0.233416, acc: 88.28%, op_acc: 56.25%] [G loss: 1.089188]\n",
      "epoch:40 step:31474[D loss: 0.304400, acc: 86.72%, op_acc: 50.78%] [G loss: 1.373039]\n",
      "epoch:40 step:31475[D loss: 0.310081, acc: 81.25%, op_acc: 59.38%] [G loss: 1.261004]\n",
      "epoch:40 step:31476[D loss: 0.321840, acc: 78.12%, op_acc: 51.56%] [G loss: 1.087543]\n",
      "epoch:40 step:31477[D loss: 0.270527, acc: 86.72%, op_acc: 60.16%] [G loss: 0.823991]\n",
      "epoch:40 step:31478[D loss: 0.275004, acc: 85.16%, op_acc: 65.62%] [G loss: 0.954531]\n",
      "epoch:40 step:31479[D loss: 0.301510, acc: 80.47%, op_acc: 58.59%] [G loss: 0.998990]\n",
      "epoch:40 step:31480[D loss: 0.301173, acc: 83.59%, op_acc: 60.94%] [G loss: 1.004670]\n",
      "epoch:40 step:31481[D loss: 0.270845, acc: 84.38%, op_acc: 52.34%] [G loss: 0.758331]\n",
      "epoch:40 step:31482[D loss: 0.306833, acc: 77.34%, op_acc: 54.69%] [G loss: 0.984294]\n",
      "epoch:40 step:31483[D loss: 0.304363, acc: 80.47%, op_acc: 48.44%] [G loss: 0.738253]\n",
      "epoch:40 step:31484[D loss: 0.337965, acc: 74.22%, op_acc: 46.09%] [G loss: 1.106994]\n",
      "epoch:40 step:31485[D loss: 0.295937, acc: 79.69%, op_acc: 64.84%] [G loss: 0.904496]\n",
      "epoch:40 step:31486[D loss: 0.383328, acc: 71.88%, op_acc: 44.53%] [G loss: 1.205725]\n",
      "epoch:40 step:31487[D loss: 0.303200, acc: 83.59%, op_acc: 56.25%] [G loss: 1.208431]\n",
      "epoch:40 step:31488[D loss: 0.309831, acc: 84.38%, op_acc: 53.12%] [G loss: 0.875533]\n",
      "epoch:40 step:31489[D loss: 0.337861, acc: 72.66%, op_acc: 58.59%] [G loss: 1.103913]\n",
      "epoch:40 step:31490[D loss: 0.283427, acc: 83.59%, op_acc: 60.94%] [G loss: 0.832770]\n",
      "epoch:40 step:31491[D loss: 0.276514, acc: 82.03%, op_acc: 60.94%] [G loss: 0.913979]\n",
      "epoch:40 step:31492[D loss: 0.269537, acc: 82.03%, op_acc: 60.94%] [G loss: 1.020483]\n",
      "epoch:40 step:31493[D loss: 0.259410, acc: 87.50%, op_acc: 56.25%] [G loss: 1.121723]\n",
      "epoch:40 step:31494[D loss: 0.319760, acc: 83.59%, op_acc: 53.91%] [G loss: 0.998792]\n",
      "epoch:40 step:31495[D loss: 0.344986, acc: 75.00%, op_acc: 60.16%] [G loss: 0.945922]\n",
      "epoch:40 step:31496[D loss: 0.305715, acc: 80.47%, op_acc: 55.47%] [G loss: 0.812155]\n",
      "epoch:40 step:31497[D loss: 0.364764, acc: 71.88%, op_acc: 50.78%] [G loss: 0.835241]\n",
      "epoch:40 step:31498[D loss: 0.290728, acc: 78.91%, op_acc: 58.59%] [G loss: 0.940329]\n",
      "epoch:40 step:31499[D loss: 0.295131, acc: 84.38%, op_acc: 57.81%] [G loss: 0.952390]\n",
      "epoch:40 step:31500[D loss: 0.354206, acc: 73.44%, op_acc: 50.78%] [G loss: 0.748655]\n",
      "epoch:40 step:31501[D loss: 0.231149, acc: 91.41%, op_acc: 57.03%] [G loss: 1.060659]\n",
      "epoch:40 step:31502[D loss: 0.321723, acc: 75.78%, op_acc: 59.38%] [G loss: 0.886403]\n",
      "epoch:40 step:31503[D loss: 0.353423, acc: 74.22%, op_acc: 40.62%] [G loss: 0.779808]\n",
      "epoch:40 step:31504[D loss: 0.242576, acc: 87.50%, op_acc: 55.47%] [G loss: 1.032452]\n",
      "epoch:40 step:31505[D loss: 0.304867, acc: 77.34%, op_acc: 57.81%] [G loss: 0.989702]\n",
      "epoch:40 step:31506[D loss: 0.271335, acc: 85.94%, op_acc: 57.03%] [G loss: 0.897851]\n",
      "epoch:40 step:31507[D loss: 0.452365, acc: 62.50%, op_acc: 42.97%] [G loss: 1.091760]\n",
      "epoch:40 step:31508[D loss: 0.297399, acc: 79.69%, op_acc: 53.91%] [G loss: 0.982137]\n",
      "epoch:40 step:31509[D loss: 0.290265, acc: 82.03%, op_acc: 57.81%] [G loss: 1.070520]\n",
      "epoch:40 step:31510[D loss: 0.296067, acc: 78.12%, op_acc: 53.91%] [G loss: 0.984489]\n",
      "epoch:40 step:31511[D loss: 0.365891, acc: 73.44%, op_acc: 55.47%] [G loss: 1.425747]\n",
      "epoch:40 step:31512[D loss: 0.347929, acc: 72.66%, op_acc: 52.34%] [G loss: 1.376379]\n",
      "epoch:40 step:31513[D loss: 0.337725, acc: 77.34%, op_acc: 60.16%] [G loss: 1.366193]\n",
      "epoch:40 step:31514[D loss: 0.434914, acc: 69.53%, op_acc: 46.09%] [G loss: 1.527226]\n",
      "epoch:40 step:31515[D loss: 0.369758, acc: 71.88%, op_acc: 53.12%] [G loss: 1.309861]\n",
      "epoch:40 step:31516[D loss: 0.304602, acc: 81.25%, op_acc: 54.69%] [G loss: 1.551253]\n",
      "epoch:40 step:31517[D loss: 0.303194, acc: 83.59%, op_acc: 57.81%] [G loss: 2.373808]\n",
      "epoch:40 step:31518[D loss: 0.326896, acc: 78.91%, op_acc: 53.91%] [G loss: 1.876825]\n",
      "epoch:40 step:31519[D loss: 0.357672, acc: 75.78%, op_acc: 44.53%] [G loss: 1.868253]\n",
      "epoch:40 step:31520[D loss: 0.311151, acc: 78.91%, op_acc: 53.12%] [G loss: 1.928675]\n",
      "epoch:40 step:31521[D loss: 0.310205, acc: 78.91%, op_acc: 55.47%] [G loss: 2.014764]\n",
      "epoch:40 step:31522[D loss: 0.301275, acc: 82.03%, op_acc: 62.50%] [G loss: 2.090098]\n",
      "epoch:40 step:31523[D loss: 0.260986, acc: 81.25%, op_acc: 58.59%] [G loss: 2.179945]\n",
      "epoch:40 step:31524[D loss: 0.235817, acc: 90.62%, op_acc: 57.81%] [G loss: 2.282258]\n",
      "epoch:40 step:31525[D loss: 0.243105, acc: 86.72%, op_acc: 55.47%] [G loss: 1.415959]\n",
      "epoch:40 step:31526[D loss: 0.338828, acc: 72.66%, op_acc: 50.00%] [G loss: 2.364106]\n",
      "epoch:40 step:31527[D loss: 0.325691, acc: 78.12%, op_acc: 57.03%] [G loss: 2.221961]\n",
      "epoch:40 step:31528[D loss: 0.314281, acc: 75.00%, op_acc: 49.22%] [G loss: 2.197818]\n",
      "epoch:40 step:31529[D loss: 0.372840, acc: 75.78%, op_acc: 53.12%] [G loss: 2.406076]\n",
      "epoch:40 step:31530[D loss: 0.286616, acc: 83.59%, op_acc: 56.25%] [G loss: 2.058335]\n",
      "epoch:40 step:31531[D loss: 0.332567, acc: 76.56%, op_acc: 59.38%] [G loss: 1.637450]\n",
      "epoch:40 step:31532[D loss: 0.403071, acc: 71.09%, op_acc: 42.97%] [G loss: 1.795271]\n",
      "epoch:40 step:31533[D loss: 0.354034, acc: 68.75%, op_acc: 54.69%] [G loss: 1.697213]\n",
      "epoch:40 step:31534[D loss: 0.276541, acc: 87.50%, op_acc: 57.03%] [G loss: 1.682568]\n",
      "epoch:40 step:31535[D loss: 0.299720, acc: 75.00%, op_acc: 57.81%] [G loss: 1.789879]\n",
      "epoch:40 step:31536[D loss: 0.396142, acc: 72.66%, op_acc: 53.12%] [G loss: 1.727109]\n",
      "epoch:40 step:31537[D loss: 0.292125, acc: 85.16%, op_acc: 48.44%] [G loss: 2.056479]\n",
      "epoch:40 step:31538[D loss: 0.234042, acc: 89.06%, op_acc: 67.19%] [G loss: 1.911862]\n",
      "epoch:40 step:31539[D loss: 0.359441, acc: 71.09%, op_acc: 47.66%] [G loss: 0.922292]\n",
      "epoch:40 step:31540[D loss: 0.459626, acc: 60.16%, op_acc: 40.62%] [G loss: 1.917712]\n",
      "epoch:40 step:31541[D loss: 0.330988, acc: 76.56%, op_acc: 47.66%] [G loss: 1.773841]\n",
      "epoch:40 step:31542[D loss: 0.358275, acc: 72.66%, op_acc: 56.25%] [G loss: 2.092607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31543[D loss: 0.307101, acc: 81.25%, op_acc: 51.56%] [G loss: 2.436781]\n",
      "epoch:40 step:31544[D loss: 0.320948, acc: 79.69%, op_acc: 56.25%] [G loss: 2.355944]\n",
      "epoch:40 step:31545[D loss: 0.339969, acc: 71.88%, op_acc: 52.34%] [G loss: 1.706873]\n",
      "epoch:40 step:31546[D loss: 0.398050, acc: 68.75%, op_acc: 46.09%] [G loss: 1.566384]\n",
      "epoch:40 step:31547[D loss: 0.407419, acc: 64.06%, op_acc: 46.09%] [G loss: 1.576514]\n",
      "epoch:40 step:31548[D loss: 0.324121, acc: 81.25%, op_acc: 53.91%] [G loss: 1.121543]\n",
      "epoch:40 step:31549[D loss: 0.525421, acc: 53.12%, op_acc: 37.50%] [G loss: 1.439255]\n",
      "epoch:40 step:31550[D loss: 0.358268, acc: 75.00%, op_acc: 43.75%] [G loss: 2.057896]\n",
      "epoch:40 step:31551[D loss: 0.372084, acc: 71.09%, op_acc: 44.53%] [G loss: 1.889446]\n",
      "epoch:40 step:31552[D loss: 0.363943, acc: 76.56%, op_acc: 56.25%] [G loss: 1.920610]\n",
      "epoch:40 step:31553[D loss: 0.275802, acc: 79.69%, op_acc: 61.72%] [G loss: 1.494184]\n",
      "epoch:40 step:31554[D loss: 0.439091, acc: 59.38%, op_acc: 47.66%] [G loss: 1.556724]\n",
      "epoch:40 step:31555[D loss: 0.366458, acc: 73.44%, op_acc: 38.28%] [G loss: 0.958272]\n",
      "epoch:40 step:31556[D loss: 0.295825, acc: 81.25%, op_acc: 53.12%] [G loss: 1.142226]\n",
      "epoch:40 step:31557[D loss: 0.423977, acc: 58.59%, op_acc: 45.31%] [G loss: 1.422404]\n",
      "epoch:40 step:31558[D loss: 0.324443, acc: 77.34%, op_acc: 46.88%] [G loss: 1.253759]\n",
      "epoch:40 step:31559[D loss: 0.416932, acc: 68.75%, op_acc: 50.00%] [G loss: 1.498309]\n",
      "epoch:40 step:31560[D loss: 0.387657, acc: 73.44%, op_acc: 46.09%] [G loss: 1.192395]\n",
      "epoch:40 step:31561[D loss: 0.360216, acc: 75.78%, op_acc: 52.34%] [G loss: 1.397612]\n",
      "epoch:40 step:31562[D loss: 0.349187, acc: 72.66%, op_acc: 54.69%] [G loss: 1.424292]\n",
      "epoch:40 step:31563[D loss: 0.368959, acc: 72.66%, op_acc: 51.56%] [G loss: 1.734256]\n",
      "epoch:40 step:31564[D loss: 0.412622, acc: 66.41%, op_acc: 49.22%] [G loss: 1.313709]\n",
      "epoch:40 step:31565[D loss: 0.318156, acc: 72.66%, op_acc: 58.59%] [G loss: 1.684824]\n",
      "epoch:40 step:31566[D loss: 0.353215, acc: 70.31%, op_acc: 46.88%] [G loss: 1.004335]\n",
      "epoch:40 step:31567[D loss: 0.359321, acc: 71.88%, op_acc: 42.19%] [G loss: 1.264735]\n",
      "epoch:40 step:31568[D loss: 0.297481, acc: 80.47%, op_acc: 57.81%] [G loss: 1.573448]\n",
      "epoch:40 step:31569[D loss: 0.469601, acc: 55.47%, op_acc: 48.44%] [G loss: 1.277749]\n",
      "epoch:40 step:31570[D loss: 0.263014, acc: 81.25%, op_acc: 49.22%] [G loss: 1.522882]\n",
      "epoch:40 step:31571[D loss: 0.277198, acc: 82.03%, op_acc: 60.16%] [G loss: 1.529907]\n",
      "epoch:40 step:31572[D loss: 0.500701, acc: 53.91%, op_acc: 50.00%] [G loss: 1.475007]\n",
      "epoch:40 step:31573[D loss: 0.276668, acc: 83.59%, op_acc: 62.50%] [G loss: 1.590399]\n",
      "epoch:40 step:31574[D loss: 0.291242, acc: 78.91%, op_acc: 63.28%] [G loss: 1.816902]\n",
      "epoch:40 step:31575[D loss: 0.442378, acc: 67.19%, op_acc: 46.88%] [G loss: 1.502598]\n",
      "epoch:40 step:31576[D loss: 0.266940, acc: 80.47%, op_acc: 52.34%] [G loss: 1.603746]\n",
      "epoch:40 step:31577[D loss: 0.394015, acc: 71.88%, op_acc: 41.41%] [G loss: 1.131846]\n",
      "epoch:40 step:31578[D loss: 0.414301, acc: 61.72%, op_acc: 46.09%] [G loss: 1.642112]\n",
      "epoch:40 step:31579[D loss: 0.449989, acc: 66.41%, op_acc: 46.09%] [G loss: 1.733540]\n",
      "epoch:40 step:31580[D loss: 0.413665, acc: 64.84%, op_acc: 43.75%] [G loss: 1.318483]\n",
      "epoch:40 step:31581[D loss: 0.446026, acc: 67.19%, op_acc: 42.19%] [G loss: 1.478611]\n",
      "epoch:40 step:31582[D loss: 0.429396, acc: 63.28%, op_acc: 42.19%] [G loss: 1.470582]\n",
      "epoch:40 step:31583[D loss: 0.419879, acc: 64.84%, op_acc: 41.41%] [G loss: 1.759411]\n",
      "epoch:40 step:31584[D loss: 0.383777, acc: 70.31%, op_acc: 45.31%] [G loss: 1.708597]\n",
      "epoch:40 step:31585[D loss: 0.433047, acc: 67.97%, op_acc: 43.75%] [G loss: 1.524482]\n",
      "epoch:40 step:31586[D loss: 0.444856, acc: 65.62%, op_acc: 40.62%] [G loss: 1.493741]\n",
      "epoch:40 step:31587[D loss: 0.392507, acc: 71.88%, op_acc: 51.56%] [G loss: 1.976635]\n",
      "epoch:40 step:31588[D loss: 0.363366, acc: 67.19%, op_acc: 50.00%] [G loss: 1.330963]\n",
      "epoch:40 step:31589[D loss: 0.397622, acc: 67.97%, op_acc: 46.88%] [G loss: 1.273074]\n",
      "epoch:40 step:31590[D loss: 0.429444, acc: 62.50%, op_acc: 46.09%] [G loss: 1.503995]\n",
      "epoch:40 step:31591[D loss: 0.443477, acc: 60.16%, op_acc: 44.53%] [G loss: 1.702559]\n",
      "epoch:40 step:31592[D loss: 0.308594, acc: 82.03%, op_acc: 53.12%] [G loss: 1.515507]\n",
      "epoch:40 step:31593[D loss: 0.352548, acc: 71.09%, op_acc: 53.12%] [G loss: 1.533270]\n",
      "epoch:40 step:31594[D loss: 0.405761, acc: 67.19%, op_acc: 49.22%] [G loss: 1.305583]\n",
      "epoch:40 step:31595[D loss: 0.408160, acc: 64.84%, op_acc: 43.75%] [G loss: 1.243862]\n",
      "epoch:40 step:31596[D loss: 0.324963, acc: 76.56%, op_acc: 55.47%] [G loss: 1.462792]\n",
      "epoch:40 step:31597[D loss: 0.330738, acc: 78.12%, op_acc: 49.22%] [G loss: 1.532195]\n",
      "epoch:40 step:31598[D loss: 0.302041, acc: 84.38%, op_acc: 54.69%] [G loss: 1.506154]\n",
      "epoch:40 step:31599[D loss: 0.408241, acc: 65.62%, op_acc: 42.19%] [G loss: 1.258891]\n",
      "epoch:40 step:31600[D loss: 0.384547, acc: 71.09%, op_acc: 49.22%] [G loss: 1.150010]\n",
      "epoch:40 step:31601[D loss: 0.382697, acc: 68.75%, op_acc: 48.44%] [G loss: 1.239879]\n",
      "epoch:40 step:31602[D loss: 0.331262, acc: 81.25%, op_acc: 51.56%] [G loss: 1.235389]\n",
      "epoch:40 step:31603[D loss: 0.394795, acc: 65.62%, op_acc: 42.97%] [G loss: 1.153692]\n",
      "epoch:40 step:31604[D loss: 0.315109, acc: 79.69%, op_acc: 52.34%] [G loss: 1.272329]\n",
      "epoch:40 step:31605[D loss: 0.250014, acc: 86.72%, op_acc: 56.25%] [G loss: 1.439303]\n",
      "epoch:40 step:31606[D loss: 0.328299, acc: 71.88%, op_acc: 52.34%] [G loss: 1.126360]\n",
      "epoch:40 step:31607[D loss: 0.357558, acc: 71.09%, op_acc: 48.44%] [G loss: 1.573270]\n",
      "epoch:40 step:31608[D loss: 0.333431, acc: 76.56%, op_acc: 50.00%] [G loss: 1.464909]\n",
      "epoch:40 step:31609[D loss: 0.332173, acc: 70.31%, op_acc: 53.91%] [G loss: 1.623419]\n",
      "epoch:40 step:31610[D loss: 0.312906, acc: 80.47%, op_acc: 53.12%] [G loss: 1.435301]\n",
      "epoch:40 step:31611[D loss: 0.279886, acc: 83.59%, op_acc: 58.59%] [G loss: 1.398323]\n",
      "epoch:40 step:31612[D loss: 0.387654, acc: 71.09%, op_acc: 48.44%] [G loss: 1.262698]\n",
      "epoch:40 step:31613[D loss: 0.327621, acc: 74.22%, op_acc: 48.44%] [G loss: 1.242620]\n",
      "epoch:40 step:31614[D loss: 0.303057, acc: 76.56%, op_acc: 53.91%] [G loss: 1.266045]\n",
      "epoch:40 step:31615[D loss: 0.284220, acc: 76.56%, op_acc: 50.00%] [G loss: 0.950888]\n",
      "epoch:40 step:31616[D loss: 0.262210, acc: 85.16%, op_acc: 53.12%] [G loss: 1.169499]\n",
      "epoch:40 step:31617[D loss: 0.293120, acc: 78.12%, op_acc: 55.47%] [G loss: 1.260352]\n",
      "epoch:40 step:31618[D loss: 0.285036, acc: 85.16%, op_acc: 50.78%] [G loss: 1.301514]\n",
      "epoch:40 step:31619[D loss: 0.379896, acc: 70.31%, op_acc: 46.88%] [G loss: 1.198890]\n",
      "epoch:40 step:31620[D loss: 0.292492, acc: 80.47%, op_acc: 57.03%] [G loss: 1.136429]\n",
      "epoch:40 step:31621[D loss: 0.209152, acc: 89.06%, op_acc: 64.06%] [G loss: 1.102818]\n",
      "epoch:40 step:31622[D loss: 0.339348, acc: 74.22%, op_acc: 56.25%] [G loss: 1.004021]\n",
      "epoch:40 step:31623[D loss: 0.279860, acc: 82.03%, op_acc: 59.38%] [G loss: 1.581168]\n",
      "epoch:40 step:31624[D loss: 0.318532, acc: 80.47%, op_acc: 46.88%] [G loss: 1.385243]\n",
      "epoch:40 step:31625[D loss: 0.236609, acc: 87.50%, op_acc: 59.38%] [G loss: 1.179862]\n",
      "epoch:40 step:31626[D loss: 0.242260, acc: 86.72%, op_acc: 61.72%] [G loss: 1.402415]\n",
      "epoch:40 step:31627[D loss: 0.271786, acc: 84.38%, op_acc: 54.69%] [G loss: 1.151166]\n",
      "epoch:40 step:31628[D loss: 0.352325, acc: 75.78%, op_acc: 48.44%] [G loss: 1.185343]\n",
      "epoch:40 step:31629[D loss: 0.458075, acc: 62.50%, op_acc: 40.62%] [G loss: 1.034985]\n",
      "epoch:40 step:31630[D loss: 0.505050, acc: 53.91%, op_acc: 35.94%] [G loss: 1.681113]\n",
      "epoch:40 step:31631[D loss: 0.404148, acc: 66.41%, op_acc: 52.34%] [G loss: 1.317538]\n",
      "epoch:40 step:31632[D loss: 0.369895, acc: 68.75%, op_acc: 55.47%] [G loss: 0.951284]\n",
      "epoch:40 step:31633[D loss: 0.463944, acc: 57.81%, op_acc: 40.62%] [G loss: 0.788402]\n",
      "epoch:40 step:31634[D loss: 0.343165, acc: 75.00%, op_acc: 42.19%] [G loss: 1.173495]\n",
      "epoch:40 step:31635[D loss: 0.298378, acc: 81.25%, op_acc: 57.81%] [G loss: 0.967975]\n",
      "epoch:40 step:31636[D loss: 0.285874, acc: 84.38%, op_acc: 51.56%] [G loss: 0.933300]\n",
      "epoch:40 step:31637[D loss: 0.381602, acc: 67.19%, op_acc: 49.22%] [G loss: 1.026661]\n",
      "epoch:40 step:31638[D loss: 0.337820, acc: 75.00%, op_acc: 48.44%] [G loss: 0.962123]\n",
      "epoch:40 step:31639[D loss: 0.377224, acc: 66.41%, op_acc: 47.66%] [G loss: 1.154174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31640[D loss: 0.309481, acc: 75.00%, op_acc: 56.25%] [G loss: 1.012444]\n",
      "epoch:40 step:31641[D loss: 0.272208, acc: 82.81%, op_acc: 53.12%] [G loss: 1.153195]\n",
      "epoch:40 step:31642[D loss: 0.278112, acc: 82.81%, op_acc: 53.12%] [G loss: 1.314238]\n",
      "epoch:40 step:31643[D loss: 0.286602, acc: 78.91%, op_acc: 58.59%] [G loss: 1.091724]\n",
      "epoch:40 step:31644[D loss: 0.272316, acc: 82.03%, op_acc: 56.25%] [G loss: 1.286309]\n",
      "epoch:40 step:31645[D loss: 0.380613, acc: 67.97%, op_acc: 46.88%] [G loss: 0.919101]\n",
      "epoch:40 step:31646[D loss: 0.357062, acc: 70.31%, op_acc: 57.81%] [G loss: 1.334419]\n",
      "epoch:40 step:31647[D loss: 0.276225, acc: 86.72%, op_acc: 49.22%] [G loss: 1.130093]\n",
      "epoch:40 step:31648[D loss: 0.326476, acc: 72.66%, op_acc: 53.91%] [G loss: 1.045074]\n",
      "epoch:40 step:31649[D loss: 0.347096, acc: 77.34%, op_acc: 53.12%] [G loss: 1.023379]\n",
      "epoch:40 step:31650[D loss: 0.285256, acc: 85.16%, op_acc: 50.00%] [G loss: 1.121864]\n",
      "epoch:40 step:31651[D loss: 0.292757, acc: 79.69%, op_acc: 63.28%] [G loss: 0.908609]\n",
      "epoch:40 step:31652[D loss: 0.334362, acc: 78.12%, op_acc: 55.47%] [G loss: 0.915211]\n",
      "epoch:40 step:31653[D loss: 0.366731, acc: 74.22%, op_acc: 44.53%] [G loss: 0.803379]\n",
      "epoch:40 step:31654[D loss: 0.271193, acc: 80.47%, op_acc: 62.50%] [G loss: 1.228521]\n",
      "epoch:40 step:31655[D loss: 0.345195, acc: 69.53%, op_acc: 48.44%] [G loss: 0.972601]\n",
      "epoch:40 step:31656[D loss: 0.284251, acc: 79.69%, op_acc: 56.25%] [G loss: 1.248484]\n",
      "epoch:40 step:31657[D loss: 0.370992, acc: 73.44%, op_acc: 41.41%] [G loss: 0.887575]\n",
      "epoch:40 step:31658[D loss: 0.276418, acc: 85.94%, op_acc: 57.81%] [G loss: 1.151113]\n",
      "epoch:40 step:31659[D loss: 0.317241, acc: 79.69%, op_acc: 47.66%] [G loss: 1.035000]\n",
      "epoch:40 step:31660[D loss: 0.347787, acc: 73.44%, op_acc: 55.47%] [G loss: 1.086758]\n",
      "epoch:40 step:31661[D loss: 0.412752, acc: 70.31%, op_acc: 47.66%] [G loss: 1.194798]\n",
      "epoch:40 step:31662[D loss: 0.344507, acc: 77.34%, op_acc: 51.56%] [G loss: 1.100865]\n",
      "epoch:40 step:31663[D loss: 0.338154, acc: 74.22%, op_acc: 52.34%] [G loss: 0.925162]\n",
      "epoch:40 step:31664[D loss: 0.321450, acc: 81.25%, op_acc: 54.69%] [G loss: 0.747761]\n",
      "epoch:40 step:31665[D loss: 0.347079, acc: 76.56%, op_acc: 50.00%] [G loss: 0.592503]\n",
      "epoch:40 step:31666[D loss: 0.331412, acc: 75.78%, op_acc: 50.00%] [G loss: 0.772722]\n",
      "epoch:40 step:31667[D loss: 0.269754, acc: 84.38%, op_acc: 54.69%] [G loss: 0.529271]\n",
      "epoch:40 step:31668[D loss: 0.422290, acc: 62.50%, op_acc: 45.31%] [G loss: 0.736437]\n",
      "epoch:40 step:31669[D loss: 0.254081, acc: 86.72%, op_acc: 65.62%] [G loss: 1.010059]\n",
      "epoch:40 step:31670[D loss: 0.322924, acc: 78.12%, op_acc: 49.22%] [G loss: 0.880262]\n",
      "epoch:40 step:31671[D loss: 0.322405, acc: 81.25%, op_acc: 60.16%] [G loss: 0.991288]\n",
      "epoch:40 step:31672[D loss: 0.308302, acc: 78.91%, op_acc: 51.56%] [G loss: 1.701442]\n",
      "epoch:40 step:31673[D loss: 0.286018, acc: 83.59%, op_acc: 53.12%] [G loss: 0.807257]\n",
      "epoch:40 step:31674[D loss: 0.345392, acc: 78.91%, op_acc: 55.47%] [G loss: 0.827129]\n",
      "epoch:40 step:31675[D loss: 0.330198, acc: 75.78%, op_acc: 63.28%] [G loss: 0.782421]\n",
      "epoch:40 step:31676[D loss: 0.340897, acc: 78.12%, op_acc: 47.66%] [G loss: 0.520958]\n",
      "epoch:40 step:31677[D loss: 0.403840, acc: 65.62%, op_acc: 48.44%] [G loss: 0.754691]\n",
      "epoch:40 step:31678[D loss: 0.275918, acc: 78.91%, op_acc: 50.78%] [G loss: 0.763635]\n",
      "epoch:40 step:31679[D loss: 0.296603, acc: 78.91%, op_acc: 59.38%] [G loss: 0.882691]\n",
      "epoch:40 step:31680[D loss: 0.391314, acc: 67.97%, op_acc: 50.00%] [G loss: 0.778757]\n",
      "epoch:40 step:31681[D loss: 0.379469, acc: 71.09%, op_acc: 50.00%] [G loss: 0.839721]\n",
      "epoch:40 step:31682[D loss: 0.313124, acc: 76.56%, op_acc: 53.12%] [G loss: 0.868828]\n",
      "epoch:40 step:31683[D loss: 0.293199, acc: 82.81%, op_acc: 55.47%] [G loss: 0.913186]\n",
      "epoch:40 step:31684[D loss: 0.331079, acc: 71.88%, op_acc: 48.44%] [G loss: 0.980297]\n",
      "epoch:40 step:31685[D loss: 0.389029, acc: 68.75%, op_acc: 41.41%] [G loss: 0.999839]\n",
      "epoch:40 step:31686[D loss: 0.376636, acc: 73.44%, op_acc: 46.09%] [G loss: 0.992238]\n",
      "epoch:40 step:31687[D loss: 0.340846, acc: 81.25%, op_acc: 58.59%] [G loss: 1.135591]\n",
      "epoch:40 step:31688[D loss: 0.394481, acc: 74.22%, op_acc: 41.41%] [G loss: 1.144428]\n",
      "epoch:40 step:31689[D loss: 0.314425, acc: 76.56%, op_acc: 53.91%] [G loss: 1.091023]\n",
      "epoch:40 step:31690[D loss: 0.379547, acc: 72.66%, op_acc: 46.09%] [G loss: 1.212683]\n",
      "epoch:40 step:31691[D loss: 0.384628, acc: 66.41%, op_acc: 43.75%] [G loss: 1.362037]\n",
      "epoch:40 step:31692[D loss: 0.289087, acc: 77.34%, op_acc: 62.50%] [G loss: 1.169918]\n",
      "epoch:40 step:31693[D loss: 0.343309, acc: 72.66%, op_acc: 55.47%] [G loss: 1.311539]\n",
      "epoch:40 step:31694[D loss: 0.330822, acc: 75.78%, op_acc: 47.66%] [G loss: 1.429963]\n",
      "epoch:40 step:31695[D loss: 0.405373, acc: 64.84%, op_acc: 42.19%] [G loss: 1.358636]\n",
      "epoch:40 step:31696[D loss: 0.377649, acc: 75.78%, op_acc: 50.00%] [G loss: 1.930194]\n",
      "epoch:40 step:31697[D loss: 0.311250, acc: 84.38%, op_acc: 54.69%] [G loss: 1.437201]\n",
      "epoch:40 step:31698[D loss: 0.271439, acc: 82.81%, op_acc: 55.47%] [G loss: 1.667736]\n",
      "epoch:40 step:31699[D loss: 0.327251, acc: 76.56%, op_acc: 50.78%] [G loss: 1.434777]\n",
      "epoch:40 step:31700[D loss: 0.209598, acc: 89.06%, op_acc: 63.28%] [G loss: 1.745464]\n",
      "epoch:40 step:31701[D loss: 0.316935, acc: 72.66%, op_acc: 53.12%] [G loss: 1.881461]\n",
      "epoch:40 step:31702[D loss: 0.325681, acc: 78.12%, op_acc: 55.47%] [G loss: 1.963122]\n",
      "epoch:40 step:31703[D loss: 0.285833, acc: 79.69%, op_acc: 55.47%] [G loss: 1.571306]\n",
      "epoch:40 step:31704[D loss: 0.299555, acc: 82.81%, op_acc: 55.47%] [G loss: 1.738741]\n",
      "epoch:40 step:31705[D loss: 0.291359, acc: 82.03%, op_acc: 51.56%] [G loss: 2.156297]\n",
      "epoch:40 step:31706[D loss: 0.250698, acc: 83.59%, op_acc: 55.47%] [G loss: 2.024773]\n",
      "epoch:40 step:31707[D loss: 0.287115, acc: 79.69%, op_acc: 56.25%] [G loss: 1.040935]\n",
      "epoch:40 step:31708[D loss: 0.289680, acc: 81.25%, op_acc: 53.12%] [G loss: 2.188814]\n",
      "epoch:40 step:31709[D loss: 0.327175, acc: 72.66%, op_acc: 50.00%] [G loss: 2.706183]\n",
      "epoch:40 step:31710[D loss: 0.233062, acc: 87.50%, op_acc: 57.03%] [G loss: 2.375038]\n",
      "epoch:40 step:31711[D loss: 0.298635, acc: 81.25%, op_acc: 54.69%] [G loss: 2.131277]\n",
      "epoch:40 step:31712[D loss: 0.317501, acc: 76.56%, op_acc: 50.00%] [G loss: 1.748911]\n",
      "epoch:40 step:31713[D loss: 0.402727, acc: 65.62%, op_acc: 50.78%] [G loss: 1.609477]\n",
      "epoch:40 step:31714[D loss: 0.298470, acc: 83.59%, op_acc: 51.56%] [G loss: 1.908199]\n",
      "epoch:40 step:31715[D loss: 0.366992, acc: 70.31%, op_acc: 48.44%] [G loss: 1.781628]\n",
      "epoch:40 step:31716[D loss: 0.361422, acc: 75.78%, op_acc: 45.31%] [G loss: 1.713614]\n",
      "epoch:40 step:31717[D loss: 0.453629, acc: 60.94%, op_acc: 43.75%] [G loss: 1.320723]\n",
      "epoch:40 step:31718[D loss: 0.368912, acc: 71.88%, op_acc: 53.91%] [G loss: 1.853447]\n",
      "epoch:40 step:31719[D loss: 0.385817, acc: 66.41%, op_acc: 41.41%] [G loss: 1.603173]\n",
      "epoch:40 step:31720[D loss: 0.448261, acc: 64.06%, op_acc: 42.19%] [G loss: 1.592807]\n",
      "epoch:40 step:31721[D loss: 0.468027, acc: 62.50%, op_acc: 40.62%] [G loss: 1.318339]\n",
      "epoch:40 step:31722[D loss: 0.380986, acc: 70.31%, op_acc: 43.75%] [G loss: 1.459999]\n",
      "epoch:40 step:31723[D loss: 0.378825, acc: 70.31%, op_acc: 52.34%] [G loss: 1.385138]\n",
      "epoch:40 step:31724[D loss: 0.350707, acc: 69.53%, op_acc: 57.03%] [G loss: 1.529537]\n",
      "epoch:40 step:31725[D loss: 0.498665, acc: 53.91%, op_acc: 49.22%] [G loss: 1.289255]\n",
      "epoch:40 step:31726[D loss: 0.358815, acc: 67.97%, op_acc: 48.44%] [G loss: 1.293002]\n",
      "epoch:40 step:31727[D loss: 0.447616, acc: 64.06%, op_acc: 38.28%] [G loss: 1.611555]\n",
      "epoch:40 step:31728[D loss: 0.450530, acc: 66.41%, op_acc: 41.41%] [G loss: 1.697801]\n",
      "epoch:40 step:31729[D loss: 0.346144, acc: 71.09%, op_acc: 46.09%] [G loss: 1.437398]\n",
      "epoch:40 step:31730[D loss: 0.341098, acc: 70.31%, op_acc: 51.56%] [G loss: 1.533497]\n",
      "epoch:40 step:31731[D loss: 0.521286, acc: 57.81%, op_acc: 32.81%] [G loss: 1.421919]\n",
      "epoch:40 step:31732[D loss: 0.418119, acc: 64.84%, op_acc: 42.97%] [G loss: 1.508165]\n",
      "epoch:40 step:31733[D loss: 0.375759, acc: 70.31%, op_acc: 54.69%] [G loss: 1.462223]\n",
      "epoch:40 step:31734[D loss: 0.397617, acc: 69.53%, op_acc: 41.41%] [G loss: 1.659380]\n",
      "epoch:40 step:31735[D loss: 0.345071, acc: 74.22%, op_acc: 42.19%] [G loss: 1.414613]\n",
      "epoch:40 step:31736[D loss: 0.359773, acc: 75.78%, op_acc: 46.88%] [G loss: 1.607333]\n",
      "epoch:40 step:31737[D loss: 0.389055, acc: 65.62%, op_acc: 45.31%] [G loss: 1.485707]\n",
      "epoch:40 step:31738[D loss: 0.377962, acc: 77.34%, op_acc: 47.66%] [G loss: 1.594125]\n",
      "epoch:40 step:31739[D loss: 0.387669, acc: 67.97%, op_acc: 52.34%] [G loss: 1.314441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31740[D loss: 0.303060, acc: 82.03%, op_acc: 53.91%] [G loss: 1.439333]\n",
      "epoch:40 step:31741[D loss: 0.392297, acc: 64.06%, op_acc: 47.66%] [G loss: 1.375067]\n",
      "epoch:40 step:31742[D loss: 0.414616, acc: 67.19%, op_acc: 50.00%] [G loss: 1.308165]\n",
      "epoch:40 step:31743[D loss: 0.434279, acc: 64.06%, op_acc: 45.31%] [G loss: 1.272877]\n",
      "epoch:40 step:31744[D loss: 0.353652, acc: 73.44%, op_acc: 50.00%] [G loss: 1.329755]\n",
      "epoch:40 step:31745[D loss: 0.382047, acc: 71.09%, op_acc: 47.66%] [G loss: 1.282277]\n",
      "epoch:40 step:31746[D loss: 0.391741, acc: 70.31%, op_acc: 47.66%] [G loss: 1.537452]\n",
      "epoch:40 step:31747[D loss: 0.320934, acc: 75.78%, op_acc: 57.03%] [G loss: 1.458162]\n",
      "epoch:40 step:31748[D loss: 0.330668, acc: 75.00%, op_acc: 61.72%] [G loss: 1.397079]\n",
      "epoch:40 step:31749[D loss: 0.344575, acc: 75.78%, op_acc: 52.34%] [G loss: 1.369298]\n",
      "epoch:40 step:31750[D loss: 0.328990, acc: 73.44%, op_acc: 49.22%] [G loss: 1.116251]\n",
      "epoch:40 step:31751[D loss: 0.413241, acc: 65.62%, op_acc: 44.53%] [G loss: 0.956204]\n",
      "epoch:40 step:31752[D loss: 0.456978, acc: 59.38%, op_acc: 40.62%] [G loss: 1.195364]\n",
      "epoch:40 step:31753[D loss: 0.468503, acc: 57.81%, op_acc: 43.75%] [G loss: 0.780303]\n",
      "epoch:40 step:31754[D loss: 0.490125, acc: 53.91%, op_acc: 42.97%] [G loss: 1.242364]\n",
      "epoch:40 step:31755[D loss: 0.330997, acc: 80.47%, op_acc: 43.75%] [G loss: 1.030118]\n",
      "epoch:40 step:31756[D loss: 0.376216, acc: 75.78%, op_acc: 41.41%] [G loss: 1.364696]\n",
      "epoch:40 step:31757[D loss: 0.413549, acc: 65.62%, op_acc: 43.75%] [G loss: 1.409832]\n",
      "epoch:40 step:31758[D loss: 0.265368, acc: 87.50%, op_acc: 56.25%] [G loss: 1.813504]\n",
      "epoch:40 step:31759[D loss: 0.372514, acc: 68.75%, op_acc: 46.09%] [G loss: 1.447802]\n",
      "epoch:40 step:31760[D loss: 0.380039, acc: 72.66%, op_acc: 44.53%] [G loss: 1.210426]\n",
      "epoch:40 step:31761[D loss: 0.340946, acc: 81.25%, op_acc: 54.69%] [G loss: 1.446116]\n",
      "epoch:40 step:31762[D loss: 0.393393, acc: 64.84%, op_acc: 50.00%] [G loss: 0.944599]\n",
      "epoch:40 step:31763[D loss: 0.318866, acc: 80.47%, op_acc: 52.34%] [G loss: 1.305748]\n",
      "epoch:40 step:31764[D loss: 0.252261, acc: 87.50%, op_acc: 60.16%] [G loss: 1.441550]\n",
      "epoch:40 step:31765[D loss: 0.271876, acc: 84.38%, op_acc: 53.12%] [G loss: 1.575949]\n",
      "epoch:40 step:31766[D loss: 0.416553, acc: 67.97%, op_acc: 47.66%] [G loss: 1.594192]\n",
      "epoch:40 step:31767[D loss: 0.420721, acc: 67.97%, op_acc: 46.88%] [G loss: 1.154099]\n",
      "epoch:40 step:31768[D loss: 0.333649, acc: 72.66%, op_acc: 47.66%] [G loss: 1.226820]\n",
      "epoch:40 step:31769[D loss: 0.323768, acc: 74.22%, op_acc: 53.12%] [G loss: 1.154655]\n",
      "epoch:40 step:31770[D loss: 0.330642, acc: 77.34%, op_acc: 53.12%] [G loss: 1.458265]\n",
      "epoch:40 step:31771[D loss: 0.306887, acc: 82.81%, op_acc: 49.22%] [G loss: 1.610813]\n",
      "epoch:40 step:31772[D loss: 0.354907, acc: 75.78%, op_acc: 50.78%] [G loss: 1.232848]\n",
      "epoch:40 step:31773[D loss: 0.426822, acc: 60.94%, op_acc: 48.44%] [G loss: 1.341326]\n",
      "epoch:40 step:31774[D loss: 0.337552, acc: 74.22%, op_acc: 53.12%] [G loss: 1.596052]\n",
      "epoch:40 step:31775[D loss: 0.320020, acc: 82.03%, op_acc: 50.78%] [G loss: 1.740600]\n",
      "epoch:40 step:31776[D loss: 0.241770, acc: 87.50%, op_acc: 60.16%] [G loss: 1.705720]\n",
      "epoch:40 step:31777[D loss: 0.385563, acc: 68.75%, op_acc: 50.00%] [G loss: 1.612402]\n",
      "epoch:40 step:31778[D loss: 0.314508, acc: 80.47%, op_acc: 50.78%] [G loss: 1.697098]\n",
      "epoch:40 step:31779[D loss: 0.394835, acc: 74.22%, op_acc: 53.91%] [G loss: 1.596944]\n",
      "epoch:40 step:31780[D loss: 0.389763, acc: 60.94%, op_acc: 52.34%] [G loss: 1.275176]\n",
      "epoch:40 step:31781[D loss: 0.221934, acc: 91.41%, op_acc: 60.94%] [G loss: 1.594738]\n",
      "epoch:40 step:31782[D loss: 0.320223, acc: 75.00%, op_acc: 47.66%] [G loss: 1.943912]\n",
      "epoch:40 step:31783[D loss: 0.380361, acc: 74.22%, op_acc: 48.44%] [G loss: 1.786019]\n",
      "epoch:40 step:31784[D loss: 0.347886, acc: 72.66%, op_acc: 52.34%] [G loss: 2.101121]\n",
      "epoch:40 step:31785[D loss: 0.308761, acc: 82.03%, op_acc: 50.00%] [G loss: 1.970921]\n",
      "epoch:40 step:31786[D loss: 0.394924, acc: 66.41%, op_acc: 46.09%] [G loss: 2.017306]\n",
      "epoch:40 step:31787[D loss: 0.278486, acc: 87.50%, op_acc: 56.25%] [G loss: 1.914408]\n",
      "epoch:40 step:31788[D loss: 0.421795, acc: 66.41%, op_acc: 46.88%] [G loss: 1.747241]\n",
      "epoch:40 step:31789[D loss: 0.330591, acc: 77.34%, op_acc: 55.47%] [G loss: 1.937820]\n",
      "epoch:40 step:31790[D loss: 0.306483, acc: 78.91%, op_acc: 53.12%] [G loss: 2.071816]\n",
      "epoch:40 step:31791[D loss: 0.322167, acc: 77.34%, op_acc: 49.22%] [G loss: 1.891178]\n",
      "epoch:40 step:31792[D loss: 0.387382, acc: 68.75%, op_acc: 42.19%] [G loss: 1.756361]\n",
      "epoch:40 step:31793[D loss: 0.361563, acc: 72.66%, op_acc: 43.75%] [G loss: 1.457544]\n",
      "epoch:40 step:31794[D loss: 0.298179, acc: 84.38%, op_acc: 45.31%] [G loss: 1.708109]\n",
      "epoch:40 step:31795[D loss: 0.248557, acc: 87.50%, op_acc: 55.47%] [G loss: 1.901229]\n",
      "epoch:40 step:31796[D loss: 0.399388, acc: 64.84%, op_acc: 55.47%] [G loss: 1.554204]\n",
      "epoch:40 step:31797[D loss: 0.289009, acc: 84.38%, op_acc: 57.03%] [G loss: 1.658171]\n",
      "epoch:40 step:31798[D loss: 0.276126, acc: 85.16%, op_acc: 58.59%] [G loss: 1.428241]\n",
      "epoch:40 step:31799[D loss: 0.235485, acc: 89.06%, op_acc: 55.47%] [G loss: 1.012435]\n",
      "epoch:40 step:31800[D loss: 0.429202, acc: 64.84%, op_acc: 39.84%] [G loss: 1.872191]\n",
      "epoch:40 step:31801[D loss: 0.334404, acc: 78.91%, op_acc: 53.12%] [G loss: 1.584583]\n",
      "epoch:40 step:31802[D loss: 0.393844, acc: 70.31%, op_acc: 46.88%] [G loss: 1.681561]\n",
      "epoch:40 step:31803[D loss: 0.353003, acc: 78.12%, op_acc: 55.47%] [G loss: 1.831589]\n",
      "epoch:40 step:31804[D loss: 0.342143, acc: 78.91%, op_acc: 50.78%] [G loss: 1.815750]\n",
      "epoch:40 step:31805[D loss: 0.411712, acc: 67.19%, op_acc: 46.09%] [G loss: 1.733413]\n",
      "epoch:40 step:31806[D loss: 0.388051, acc: 68.75%, op_acc: 45.31%] [G loss: 1.581104]\n",
      "epoch:40 step:31807[D loss: 0.329970, acc: 76.56%, op_acc: 48.44%] [G loss: 1.614972]\n",
      "epoch:40 step:31808[D loss: 0.339527, acc: 73.44%, op_acc: 46.88%] [G loss: 1.666038]\n",
      "epoch:40 step:31809[D loss: 0.373616, acc: 71.09%, op_acc: 51.56%] [G loss: 2.023885]\n",
      "epoch:40 step:31810[D loss: 0.311257, acc: 80.47%, op_acc: 55.47%] [G loss: 1.982546]\n",
      "epoch:40 step:31811[D loss: 0.449913, acc: 69.53%, op_acc: 57.03%] [G loss: 1.683593]\n",
      "epoch:40 step:31812[D loss: 0.386412, acc: 71.09%, op_acc: 46.88%] [G loss: 1.573729]\n",
      "epoch:40 step:31813[D loss: 0.338794, acc: 71.09%, op_acc: 46.88%] [G loss: 1.570183]\n",
      "epoch:40 step:31814[D loss: 0.426543, acc: 64.06%, op_acc: 46.88%] [G loss: 1.369390]\n",
      "epoch:40 step:31815[D loss: 0.362957, acc: 67.97%, op_acc: 57.03%] [G loss: 1.415224]\n",
      "epoch:40 step:31816[D loss: 0.393074, acc: 67.19%, op_acc: 44.53%] [G loss: 1.270504]\n",
      "epoch:40 step:31817[D loss: 0.423156, acc: 66.41%, op_acc: 39.06%] [G loss: 1.746677]\n",
      "epoch:40 step:31818[D loss: 0.371125, acc: 78.12%, op_acc: 42.19%] [G loss: 1.578435]\n",
      "epoch:40 step:31819[D loss: 0.326285, acc: 77.34%, op_acc: 52.34%] [G loss: 1.732846]\n",
      "epoch:40 step:31820[D loss: 0.399702, acc: 68.75%, op_acc: 58.59%] [G loss: 1.638114]\n",
      "epoch:40 step:31821[D loss: 0.378461, acc: 71.88%, op_acc: 42.19%] [G loss: 1.384768]\n",
      "epoch:40 step:31822[D loss: 0.459246, acc: 58.59%, op_acc: 38.28%] [G loss: 1.493114]\n",
      "epoch:40 step:31823[D loss: 0.325847, acc: 74.22%, op_acc: 53.12%] [G loss: 1.525860]\n",
      "epoch:40 step:31824[D loss: 0.453929, acc: 62.50%, op_acc: 38.28%] [G loss: 1.546563]\n",
      "epoch:40 step:31825[D loss: 0.455126, acc: 57.03%, op_acc: 41.41%] [G loss: 1.595450]\n",
      "epoch:40 step:31826[D loss: 0.383531, acc: 71.09%, op_acc: 50.78%] [G loss: 1.770804]\n",
      "epoch:40 step:31827[D loss: 0.334817, acc: 78.12%, op_acc: 46.09%] [G loss: 1.449724]\n",
      "epoch:40 step:31828[D loss: 0.372176, acc: 69.53%, op_acc: 57.81%] [G loss: 1.705726]\n",
      "epoch:40 step:31829[D loss: 0.303235, acc: 78.91%, op_acc: 52.34%] [G loss: 1.834480]\n",
      "epoch:40 step:31830[D loss: 0.242188, acc: 91.41%, op_acc: 53.91%] [G loss: 1.821217]\n",
      "epoch:40 step:31831[D loss: 0.295497, acc: 85.16%, op_acc: 52.34%] [G loss: 1.905459]\n",
      "epoch:40 step:31832[D loss: 0.406512, acc: 67.97%, op_acc: 45.31%] [G loss: 1.634204]\n",
      "epoch:40 step:31833[D loss: 0.319760, acc: 81.25%, op_acc: 53.12%] [G loss: 1.593291]\n",
      "epoch:40 step:31834[D loss: 0.349205, acc: 75.78%, op_acc: 57.81%] [G loss: 1.860128]\n",
      "epoch:40 step:31835[D loss: 0.271424, acc: 82.03%, op_acc: 45.31%] [G loss: 1.783870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31836[D loss: 0.410970, acc: 62.50%, op_acc: 40.62%] [G loss: 1.147484]\n",
      "epoch:40 step:31837[D loss: 0.243597, acc: 89.84%, op_acc: 62.50%] [G loss: 1.428657]\n",
      "epoch:40 step:31838[D loss: 0.506814, acc: 52.34%, op_acc: 46.09%] [G loss: 1.520447]\n",
      "epoch:40 step:31839[D loss: 0.344166, acc: 78.12%, op_acc: 47.66%] [G loss: 1.902048]\n",
      "epoch:40 step:31840[D loss: 0.368998, acc: 69.53%, op_acc: 47.66%] [G loss: 1.428510]\n",
      "epoch:40 step:31841[D loss: 0.373075, acc: 71.09%, op_acc: 53.12%] [G loss: 1.364167]\n",
      "epoch:40 step:31842[D loss: 0.333493, acc: 72.66%, op_acc: 54.69%] [G loss: 1.397658]\n",
      "epoch:40 step:31843[D loss: 0.338576, acc: 77.34%, op_acc: 54.69%] [G loss: 1.225659]\n",
      "epoch:40 step:31844[D loss: 0.343812, acc: 76.56%, op_acc: 43.75%] [G loss: 1.115513]\n",
      "epoch:40 step:31845[D loss: 0.404978, acc: 70.31%, op_acc: 44.53%] [G loss: 1.472708]\n",
      "epoch:40 step:31846[D loss: 0.312696, acc: 81.25%, op_acc: 46.88%] [G loss: 2.274087]\n",
      "epoch:40 step:31847[D loss: 0.335065, acc: 75.00%, op_acc: 60.16%] [G loss: 2.052703]\n",
      "epoch:40 step:31848[D loss: 0.281403, acc: 78.91%, op_acc: 47.66%] [G loss: 1.609453]\n",
      "epoch:40 step:31849[D loss: 0.470887, acc: 56.25%, op_acc: 49.22%] [G loss: 1.315498]\n",
      "epoch:40 step:31850[D loss: 0.323133, acc: 80.47%, op_acc: 50.00%] [G loss: 1.496151]\n",
      "epoch:40 step:31851[D loss: 0.412712, acc: 67.97%, op_acc: 52.34%] [G loss: 1.625383]\n",
      "epoch:40 step:31852[D loss: 0.374007, acc: 72.66%, op_acc: 47.66%] [G loss: 1.749612]\n",
      "epoch:40 step:31853[D loss: 0.376477, acc: 72.66%, op_acc: 47.66%] [G loss: 1.756666]\n",
      "epoch:40 step:31854[D loss: 0.304054, acc: 82.03%, op_acc: 54.69%] [G loss: 1.405440]\n",
      "epoch:40 step:31855[D loss: 0.339754, acc: 79.69%, op_acc: 47.66%] [G loss: 1.753498]\n",
      "epoch:40 step:31856[D loss: 0.415706, acc: 67.19%, op_acc: 42.97%] [G loss: 1.098050]\n",
      "epoch:40 step:31857[D loss: 0.374127, acc: 71.88%, op_acc: 54.69%] [G loss: 1.103101]\n",
      "epoch:40 step:31858[D loss: 0.315894, acc: 79.69%, op_acc: 52.34%] [G loss: 1.173709]\n",
      "epoch:40 step:31859[D loss: 0.395524, acc: 72.66%, op_acc: 40.62%] [G loss: 1.254903]\n",
      "epoch:40 step:31860[D loss: 0.306085, acc: 78.91%, op_acc: 50.00%] [G loss: 1.741899]\n",
      "epoch:40 step:31861[D loss: 0.358476, acc: 72.66%, op_acc: 49.22%] [G loss: 0.898834]\n",
      "epoch:40 step:31862[D loss: 0.338100, acc: 82.03%, op_acc: 53.91%] [G loss: 0.909117]\n",
      "epoch:40 step:31863[D loss: 0.369290, acc: 69.53%, op_acc: 49.22%] [G loss: 1.762164]\n",
      "epoch:40 step:31864[D loss: 0.379935, acc: 68.75%, op_acc: 53.12%] [G loss: 1.043005]\n",
      "epoch:40 step:31865[D loss: 0.394542, acc: 67.19%, op_acc: 44.53%] [G loss: 1.056467]\n",
      "epoch:40 step:31866[D loss: 0.337778, acc: 73.44%, op_acc: 54.69%] [G loss: 1.297807]\n",
      "epoch:40 step:31867[D loss: 0.346487, acc: 76.56%, op_acc: 42.19%] [G loss: 1.274639]\n",
      "epoch:40 step:31868[D loss: 0.293415, acc: 78.91%, op_acc: 56.25%] [G loss: 1.388627]\n",
      "epoch:40 step:31869[D loss: 0.384287, acc: 67.97%, op_acc: 46.88%] [G loss: 0.650130]\n",
      "epoch:40 step:31870[D loss: 0.380035, acc: 71.09%, op_acc: 45.31%] [G loss: 0.761374]\n",
      "epoch:40 step:31871[D loss: 0.351029, acc: 71.09%, op_acc: 46.88%] [G loss: 0.803702]\n",
      "epoch:40 step:31872[D loss: 0.383163, acc: 69.53%, op_acc: 46.09%] [G loss: 0.714641]\n",
      "epoch:40 step:31873[D loss: 0.349200, acc: 75.00%, op_acc: 52.34%] [G loss: 0.586142]\n",
      "epoch:40 step:31874[D loss: 0.360314, acc: 69.53%, op_acc: 52.34%] [G loss: 0.700405]\n",
      "epoch:40 step:31875[D loss: 0.404613, acc: 67.19%, op_acc: 42.19%] [G loss: 0.642801]\n",
      "epoch:40 step:31876[D loss: 0.333594, acc: 77.34%, op_acc: 47.66%] [G loss: 0.693839]\n",
      "epoch:40 step:31877[D loss: 0.344428, acc: 75.00%, op_acc: 50.78%] [G loss: 0.653723]\n",
      "epoch:40 step:31878[D loss: 0.410938, acc: 68.75%, op_acc: 39.84%] [G loss: 0.539325]\n",
      "epoch:40 step:31879[D loss: 0.376243, acc: 69.53%, op_acc: 45.31%] [G loss: 1.922273]\n",
      "epoch:40 step:31880[D loss: 0.309270, acc: 77.34%, op_acc: 59.38%] [G loss: 0.659440]\n",
      "epoch:40 step:31881[D loss: 0.349658, acc: 73.44%, op_acc: 49.22%] [G loss: 0.453484]\n",
      "epoch:40 step:31882[D loss: 0.339311, acc: 75.00%, op_acc: 51.56%] [G loss: 0.503454]\n",
      "epoch:40 step:31883[D loss: 0.410209, acc: 65.62%, op_acc: 48.44%] [G loss: 0.494659]\n",
      "epoch:40 step:31884[D loss: 0.410923, acc: 64.84%, op_acc: 50.78%] [G loss: 0.745883]\n",
      "epoch:40 step:31885[D loss: 0.261048, acc: 85.16%, op_acc: 56.25%] [G loss: 0.554366]\n",
      "epoch:40 step:31886[D loss: 0.353926, acc: 72.66%, op_acc: 57.81%] [G loss: 0.584553]\n",
      "epoch:40 step:31887[D loss: 0.289910, acc: 80.47%, op_acc: 54.69%] [G loss: 0.600283]\n",
      "epoch:40 step:31888[D loss: 0.299365, acc: 79.69%, op_acc: 56.25%] [G loss: 0.438222]\n",
      "epoch:40 step:31889[D loss: 0.316215, acc: 76.56%, op_acc: 51.56%] [G loss: 0.604571]\n",
      "epoch:40 step:31890[D loss: 0.350747, acc: 72.66%, op_acc: 52.34%] [G loss: 0.533856]\n",
      "epoch:40 step:31891[D loss: 0.325665, acc: 74.22%, op_acc: 58.59%] [G loss: 0.592860]\n",
      "epoch:40 step:31892[D loss: 0.368677, acc: 71.09%, op_acc: 52.34%] [G loss: 0.578450]\n",
      "epoch:40 step:31893[D loss: 0.356218, acc: 67.97%, op_acc: 50.78%] [G loss: 0.443493]\n",
      "epoch:40 step:31894[D loss: 0.305369, acc: 78.91%, op_acc: 56.25%] [G loss: 0.534947]\n",
      "epoch:40 step:31895[D loss: 0.347244, acc: 75.78%, op_acc: 43.75%] [G loss: 0.961360]\n",
      "epoch:40 step:31896[D loss: 0.329437, acc: 74.22%, op_acc: 55.47%] [G loss: 0.873783]\n",
      "epoch:40 step:31897[D loss: 0.393774, acc: 71.88%, op_acc: 49.22%] [G loss: 0.773916]\n",
      "epoch:40 step:31898[D loss: 0.265923, acc: 87.50%, op_acc: 55.47%] [G loss: 1.005972]\n",
      "epoch:40 step:31899[D loss: 0.314253, acc: 83.59%, op_acc: 44.53%] [G loss: 1.324930]\n",
      "epoch:40 step:31900[D loss: 0.282508, acc: 81.25%, op_acc: 60.94%] [G loss: 1.315064]\n",
      "epoch:40 step:31901[D loss: 0.318853, acc: 75.78%, op_acc: 52.34%] [G loss: 1.321679]\n",
      "epoch:40 step:31902[D loss: 0.283260, acc: 81.25%, op_acc: 60.16%] [G loss: 1.576399]\n",
      "epoch:40 step:31903[D loss: 0.335977, acc: 78.12%, op_acc: 50.00%] [G loss: 1.452636]\n",
      "epoch:40 step:31904[D loss: 0.417805, acc: 64.06%, op_acc: 47.66%] [G loss: 1.351883]\n",
      "epoch:40 step:31905[D loss: 0.321480, acc: 83.59%, op_acc: 52.34%] [G loss: 1.215195]\n",
      "epoch:40 step:31906[D loss: 0.362417, acc: 78.91%, op_acc: 50.00%] [G loss: 1.439595]\n",
      "epoch:40 step:31907[D loss: 0.280264, acc: 83.59%, op_acc: 53.91%] [G loss: 1.693276]\n",
      "epoch:40 step:31908[D loss: 0.355382, acc: 71.88%, op_acc: 55.47%] [G loss: 1.562810]\n",
      "epoch:40 step:31909[D loss: 0.332678, acc: 75.78%, op_acc: 51.56%] [G loss: 0.975127]\n",
      "epoch:40 step:31910[D loss: 0.336413, acc: 71.09%, op_acc: 52.34%] [G loss: 0.939924]\n",
      "epoch:40 step:31911[D loss: 0.333810, acc: 81.25%, op_acc: 49.22%] [G loss: 1.221509]\n",
      "epoch:40 step:31912[D loss: 0.321549, acc: 85.16%, op_acc: 46.88%] [G loss: 1.143455]\n",
      "epoch:40 step:31913[D loss: 0.400623, acc: 67.97%, op_acc: 50.78%] [G loss: 0.881424]\n",
      "epoch:40 step:31914[D loss: 0.331332, acc: 68.75%, op_acc: 58.59%] [G loss: 1.421824]\n",
      "epoch:40 step:31915[D loss: 0.313375, acc: 80.47%, op_acc: 53.91%] [G loss: 1.051900]\n",
      "epoch:40 step:31916[D loss: 0.287117, acc: 86.72%, op_acc: 57.81%] [G loss: 1.222379]\n",
      "epoch:40 step:31917[D loss: 0.309138, acc: 82.81%, op_acc: 52.34%] [G loss: 0.862777]\n",
      "epoch:40 step:31918[D loss: 0.326904, acc: 77.34%, op_acc: 54.69%] [G loss: 1.153781]\n",
      "epoch:40 step:31919[D loss: 0.283369, acc: 78.91%, op_acc: 58.59%] [G loss: 1.211541]\n",
      "epoch:40 step:31920[D loss: 0.287599, acc: 82.81%, op_acc: 55.47%] [G loss: 1.150816]\n",
      "epoch:40 step:31921[D loss: 0.398592, acc: 68.75%, op_acc: 49.22%] [G loss: 1.205163]\n",
      "epoch:40 step:31922[D loss: 0.318446, acc: 78.91%, op_acc: 56.25%] [G loss: 0.943200]\n",
      "epoch:40 step:31923[D loss: 0.330535, acc: 73.44%, op_acc: 46.88%] [G loss: 0.969705]\n",
      "epoch:40 step:31924[D loss: 0.369485, acc: 74.22%, op_acc: 41.41%] [G loss: 1.235636]\n",
      "epoch:40 step:31925[D loss: 0.322501, acc: 79.69%, op_acc: 57.81%] [G loss: 1.103461]\n",
      "epoch:40 step:31926[D loss: 0.382303, acc: 71.09%, op_acc: 64.06%] [G loss: 1.009157]\n",
      "epoch:40 step:31927[D loss: 0.267553, acc: 85.16%, op_acc: 58.59%] [G loss: 1.104807]\n",
      "epoch:40 step:31928[D loss: 0.379986, acc: 68.75%, op_acc: 44.53%] [G loss: 1.152693]\n",
      "epoch:40 step:31929[D loss: 0.274713, acc: 79.69%, op_acc: 65.62%] [G loss: 1.081167]\n",
      "epoch:40 step:31930[D loss: 0.282213, acc: 81.25%, op_acc: 50.78%] [G loss: 1.731108]\n",
      "epoch:40 step:31931[D loss: 0.295522, acc: 82.03%, op_acc: 62.50%] [G loss: 0.794060]\n",
      "epoch:40 step:31932[D loss: 0.454012, acc: 59.38%, op_acc: 47.66%] [G loss: 1.074859]\n",
      "epoch:40 step:31933[D loss: 0.244730, acc: 87.50%, op_acc: 59.38%] [G loss: 0.996000]\n",
      "epoch:40 step:31934[D loss: 0.298928, acc: 80.47%, op_acc: 53.12%] [G loss: 0.942740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40 step:31935[D loss: 0.362439, acc: 73.44%, op_acc: 51.56%] [G loss: 1.404058]\n",
      "epoch:40 step:31936[D loss: 0.309434, acc: 76.56%, op_acc: 56.25%] [G loss: 0.893353]\n",
      "epoch:40 step:31937[D loss: 0.340644, acc: 75.00%, op_acc: 51.56%] [G loss: 1.407556]\n",
      "epoch:40 step:31938[D loss: 0.303472, acc: 79.69%, op_acc: 51.56%] [G loss: 0.854256]\n",
      "epoch:40 step:31939[D loss: 0.334445, acc: 75.78%, op_acc: 53.12%] [G loss: 0.866238]\n",
      "epoch:40 step:31940[D loss: 0.370528, acc: 71.09%, op_acc: 47.66%] [G loss: 0.890344]\n",
      "epoch:40 step:31941[D loss: 0.350232, acc: 72.66%, op_acc: 50.78%] [G loss: 0.762414]\n",
      "epoch:40 step:31942[D loss: 0.306549, acc: 76.56%, op_acc: 51.56%] [G loss: 0.831013]\n",
      "epoch:40 step:31943[D loss: 0.334185, acc: 77.34%, op_acc: 53.12%] [G loss: 0.868129]\n",
      "epoch:40 step:31944[D loss: 0.272528, acc: 82.03%, op_acc: 55.47%] [G loss: 0.556116]\n",
      "epoch:40 step:31945[D loss: 0.415055, acc: 62.50%, op_acc: 52.34%] [G loss: 0.703986]\n",
      "epoch:40 step:31946[D loss: 0.350540, acc: 77.34%, op_acc: 53.12%] [G loss: 0.918671]\n",
      "epoch:40 step:31947[D loss: 0.401626, acc: 67.19%, op_acc: 39.84%] [G loss: 0.517817]\n",
      "epoch:40 step:31948[D loss: 0.314929, acc: 78.12%, op_acc: 55.47%] [G loss: 0.691490]\n",
      "epoch:40 step:31949[D loss: 0.287095, acc: 82.03%, op_acc: 46.88%] [G loss: 1.272038]\n",
      "epoch:40 step:31950[D loss: 0.289462, acc: 76.56%, op_acc: 51.56%] [G loss: 1.110116]\n",
      "epoch:40 step:31951[D loss: 0.278781, acc: 85.16%, op_acc: 52.34%] [G loss: 1.437414]\n",
      "epoch:40 step:31952[D loss: 0.373368, acc: 62.50%, op_acc: 49.22%] [G loss: 1.678355]\n",
      "epoch:40 step:31953[D loss: 0.362499, acc: 68.75%, op_acc: 57.81%] [G loss: 1.975890]\n",
      "epoch:40 step:31954[D loss: 0.344213, acc: 78.91%, op_acc: 44.53%] [G loss: 1.159452]\n",
      "epoch:40 step:31955[D loss: 0.373165, acc: 69.53%, op_acc: 50.00%] [G loss: 1.824444]\n",
      "epoch:40 step:31956[D loss: 0.367888, acc: 71.88%, op_acc: 51.56%] [G loss: 1.596768]\n",
      "epoch:40 step:31957[D loss: 0.267755, acc: 85.16%, op_acc: 60.94%] [G loss: 1.574760]\n",
      "epoch:40 step:31958[D loss: 0.334803, acc: 75.00%, op_acc: 53.12%] [G loss: 1.667361]\n",
      "epoch:40 step:31959[D loss: 0.280831, acc: 82.03%, op_acc: 57.81%] [G loss: 1.744120]\n",
      "epoch:40 step:31960[D loss: 0.306184, acc: 83.59%, op_acc: 56.25%] [G loss: 1.785396]\n",
      "epoch:40 step:31961[D loss: 0.353615, acc: 71.09%, op_acc: 57.03%] [G loss: 1.557323]\n",
      "epoch:40 step:31962[D loss: 0.331339, acc: 73.44%, op_acc: 57.03%] [G loss: 1.824665]\n",
      "epoch:40 step:31963[D loss: 0.303797, acc: 82.81%, op_acc: 60.16%] [G loss: 1.736174]\n",
      "epoch:40 step:31964[D loss: 0.339317, acc: 75.00%, op_acc: 47.66%] [G loss: 1.788388]\n",
      "epoch:40 step:31965[D loss: 0.286373, acc: 81.25%, op_acc: 53.12%] [G loss: 1.649973]\n",
      "epoch:40 step:31966[D loss: 0.289820, acc: 84.38%, op_acc: 55.47%] [G loss: 2.107373]\n",
      "epoch:40 step:31967[D loss: 0.376386, acc: 71.09%, op_acc: 52.34%] [G loss: 1.918809]\n",
      "epoch:40 step:31968[D loss: 0.291253, acc: 83.59%, op_acc: 53.12%] [G loss: 2.093475]\n",
      "epoch:40 step:31969[D loss: 0.330685, acc: 73.44%, op_acc: 53.12%] [G loss: 1.906285]\n",
      "epoch:40 step:31970[D loss: 0.301193, acc: 83.59%, op_acc: 50.78%] [G loss: 1.747555]\n",
      "epoch:40 step:31971[D loss: 0.312544, acc: 75.00%, op_acc: 56.25%] [G loss: 1.392331]\n",
      "epoch:40 step:31972[D loss: 0.308841, acc: 78.12%, op_acc: 59.38%] [G loss: 1.594537]\n",
      "epoch:40 step:31973[D loss: 0.286459, acc: 76.56%, op_acc: 56.25%] [G loss: 2.003289]\n",
      "epoch:40 step:31974[D loss: 0.355296, acc: 80.47%, op_acc: 46.88%] [G loss: 1.509309]\n",
      "epoch:40 step:31975[D loss: 0.359701, acc: 70.31%, op_acc: 52.34%] [G loss: 2.090333]\n",
      "epoch:40 step:31976[D loss: 0.259271, acc: 88.28%, op_acc: 57.81%] [G loss: 2.091114]\n",
      "epoch:40 step:31977[D loss: 0.380673, acc: 67.97%, op_acc: 56.25%] [G loss: 1.816556]\n",
      "epoch:40 step:31978[D loss: 0.335639, acc: 73.44%, op_acc: 55.47%] [G loss: 2.080048]\n",
      "epoch:40 step:31979[D loss: 0.345827, acc: 75.00%, op_acc: 43.75%] [G loss: 1.536319]\n",
      "epoch:40 step:31980[D loss: 0.268798, acc: 79.69%, op_acc: 57.81%] [G loss: 1.829137]\n",
      "epoch:40 step:31981[D loss: 0.364094, acc: 74.22%, op_acc: 50.78%] [G loss: 1.965487]\n",
      "epoch:40 step:31982[D loss: 0.344744, acc: 74.22%, op_acc: 53.12%] [G loss: 1.723841]\n",
      "epoch:40 step:31983[D loss: 0.357840, acc: 78.12%, op_acc: 47.66%] [G loss: 1.740964]\n",
      "epoch:40 step:31984[D loss: 0.368309, acc: 66.41%, op_acc: 54.69%] [G loss: 1.601875]\n",
      "epoch:40 step:31985[D loss: 0.303621, acc: 80.47%, op_acc: 56.25%] [G loss: 1.863874]\n",
      "epoch:40 step:31986[D loss: 0.329848, acc: 78.12%, op_acc: 53.12%] [G loss: 1.611456]\n",
      "epoch:40 step:31987[D loss: 0.381791, acc: 71.88%, op_acc: 46.09%] [G loss: 1.020732]\n",
      "epoch:40 step:31988[D loss: 0.467803, acc: 62.50%, op_acc: 41.41%] [G loss: 1.529834]\n",
      "epoch:40 step:31989[D loss: 0.505297, acc: 57.03%, op_acc: 40.62%] [G loss: 1.405922]\n",
      "epoch:40 step:31990[D loss: 0.370486, acc: 69.53%, op_acc: 53.91%] [G loss: 1.824744]\n",
      "epoch:40 step:31991[D loss: 0.507713, acc: 57.03%, op_acc: 35.94%] [G loss: 1.288548]\n",
      "epoch:40 step:31992[D loss: 0.428927, acc: 67.97%, op_acc: 37.50%] [G loss: 1.345847]\n",
      "epoch:40 step:31993[D loss: 0.358533, acc: 72.66%, op_acc: 45.31%] [G loss: 1.670256]\n",
      "epoch:40 step:31994[D loss: 0.277345, acc: 85.94%, op_acc: 57.03%] [G loss: 1.466588]\n",
      "epoch:40 step:31995[D loss: 0.344925, acc: 73.44%, op_acc: 44.53%] [G loss: 1.982322]\n",
      "epoch:40 step:31996[D loss: 0.311563, acc: 75.78%, op_acc: 59.38%] [G loss: 1.870410]\n",
      "epoch:40 step:31997[D loss: 0.434753, acc: 64.06%, op_acc: 50.00%] [G loss: 1.486852]\n",
      "epoch:40 step:31998[D loss: 0.320759, acc: 78.91%, op_acc: 56.25%] [G loss: 1.400340]\n",
      "epoch:40 step:31999[D loss: 0.451700, acc: 58.59%, op_acc: 40.62%] [G loss: 1.140513]\n",
      "epoch:40 step:32000[D loss: 0.464674, acc: 60.16%, op_acc: 41.41%] [G loss: 1.296957]\n",
      "epoch:40 step:32001[D loss: 0.323642, acc: 78.12%, op_acc: 59.38%] [G loss: 1.614175]\n",
      "epoch:40 step:32002[D loss: 0.324866, acc: 74.22%, op_acc: 50.78%] [G loss: 2.104184]\n",
      "epoch:40 step:32003[D loss: 0.355817, acc: 71.88%, op_acc: 49.22%] [G loss: 1.731626]\n",
      "epoch:40 step:32004[D loss: 0.315630, acc: 75.78%, op_acc: 48.44%] [G loss: 1.859481]\n",
      "epoch:40 step:32005[D loss: 0.365388, acc: 67.97%, op_acc: 53.12%] [G loss: 1.496271]\n",
      "epoch:40 step:32006[D loss: 0.396296, acc: 68.75%, op_acc: 44.53%] [G loss: 1.770522]\n",
      "epoch:40 step:32007[D loss: 0.329516, acc: 74.22%, op_acc: 57.03%] [G loss: 1.558205]\n",
      "epoch:40 step:32008[D loss: 0.355834, acc: 73.44%, op_acc: 46.09%] [G loss: 1.539942]\n",
      "epoch:40 step:32009[D loss: 0.324493, acc: 72.66%, op_acc: 49.22%] [G loss: 1.812906]\n",
      "epoch:40 step:32010[D loss: 0.292556, acc: 81.25%, op_acc: 61.72%] [G loss: 1.790871]\n",
      "epoch:40 step:32011[D loss: 0.494801, acc: 60.16%, op_acc: 35.16%] [G loss: 1.425020]\n",
      "epoch:40 step:32012[D loss: 0.356979, acc: 75.00%, op_acc: 44.53%] [G loss: 1.269638]\n",
      "epoch:40 step:32013[D loss: 0.344549, acc: 78.91%, op_acc: 43.75%] [G loss: 1.922346]\n",
      "epoch:40 step:32014[D loss: 0.277851, acc: 83.59%, op_acc: 56.25%] [G loss: 1.831244]\n",
      "epoch:40 step:32015[D loss: 0.352779, acc: 77.34%, op_acc: 44.53%] [G loss: 1.823955]\n",
      "epoch:40 step:32016[D loss: 0.321821, acc: 75.00%, op_acc: 50.00%] [G loss: 1.838222]\n",
      "epoch:40 step:32017[D loss: 0.350208, acc: 75.00%, op_acc: 50.78%] [G loss: 1.477696]\n",
      "epoch:40 step:32018[D loss: 0.358095, acc: 74.22%, op_acc: 49.22%] [G loss: 1.432240]\n",
      "epoch:40 step:32019[D loss: 0.490290, acc: 53.12%, op_acc: 45.31%] [G loss: 1.451509]\n",
      "epoch:40 step:32020[D loss: 0.273003, acc: 80.47%, op_acc: 57.03%] [G loss: 1.521272]\n",
      "epoch:40 step:32021[D loss: 0.407412, acc: 66.41%, op_acc: 43.75%] [G loss: 1.420367]\n",
      "epoch:41 step:32022[D loss: 0.435576, acc: 67.97%, op_acc: 46.88%] [G loss: 1.898873]\n",
      "epoch:41 step:32023[D loss: 0.367262, acc: 70.31%, op_acc: 42.97%] [G loss: 1.603706]\n",
      "epoch:41 step:32024[D loss: 0.276595, acc: 85.94%, op_acc: 57.03%] [G loss: 1.628191]\n",
      "epoch:41 step:32025[D loss: 0.393771, acc: 65.62%, op_acc: 45.31%] [G loss: 1.896159]\n",
      "epoch:41 step:32026[D loss: 0.349762, acc: 75.00%, op_acc: 55.47%] [G loss: 2.066954]\n",
      "epoch:41 step:32027[D loss: 0.487811, acc: 60.94%, op_acc: 48.44%] [G loss: 1.829658]\n",
      "epoch:41 step:32028[D loss: 0.354870, acc: 73.44%, op_acc: 46.88%] [G loss: 1.816991]\n",
      "epoch:41 step:32029[D loss: 0.449594, acc: 62.50%, op_acc: 38.28%] [G loss: 1.323026]\n",
      "epoch:41 step:32030[D loss: 0.314615, acc: 75.00%, op_acc: 51.56%] [G loss: 1.161324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32031[D loss: 0.505516, acc: 55.47%, op_acc: 34.38%] [G loss: 1.439886]\n",
      "epoch:41 step:32032[D loss: 0.386674, acc: 68.75%, op_acc: 49.22%] [G loss: 1.422242]\n",
      "epoch:41 step:32033[D loss: 0.375436, acc: 70.31%, op_acc: 44.53%] [G loss: 1.608792]\n",
      "epoch:41 step:32034[D loss: 0.419049, acc: 66.41%, op_acc: 45.31%] [G loss: 1.308687]\n",
      "epoch:41 step:32035[D loss: 0.357769, acc: 75.00%, op_acc: 53.91%] [G loss: 1.408759]\n",
      "epoch:41 step:32036[D loss: 0.322438, acc: 78.91%, op_acc: 50.78%] [G loss: 1.349405]\n",
      "epoch:41 step:32037[D loss: 0.395869, acc: 64.84%, op_acc: 45.31%] [G loss: 1.333390]\n",
      "epoch:41 step:32038[D loss: 0.368195, acc: 67.97%, op_acc: 45.31%] [G loss: 1.241281]\n",
      "epoch:41 step:32039[D loss: 0.289046, acc: 80.47%, op_acc: 52.34%] [G loss: 1.405585]\n",
      "epoch:41 step:32040[D loss: 0.369784, acc: 75.00%, op_acc: 51.56%] [G loss: 1.324617]\n",
      "epoch:41 step:32041[D loss: 0.416472, acc: 67.19%, op_acc: 44.53%] [G loss: 1.793779]\n",
      "epoch:41 step:32042[D loss: 0.509768, acc: 57.81%, op_acc: 35.16%] [G loss: 1.175495]\n",
      "epoch:41 step:32043[D loss: 0.311329, acc: 78.91%, op_acc: 50.00%] [G loss: 1.499673]\n",
      "epoch:41 step:32044[D loss: 0.309205, acc: 80.47%, op_acc: 46.88%] [G loss: 1.359764]\n",
      "epoch:41 step:32045[D loss: 0.416304, acc: 65.62%, op_acc: 39.84%] [G loss: 1.203743]\n",
      "epoch:41 step:32046[D loss: 0.353088, acc: 74.22%, op_acc: 52.34%] [G loss: 1.292273]\n",
      "epoch:41 step:32047[D loss: 0.378107, acc: 70.31%, op_acc: 45.31%] [G loss: 1.426742]\n",
      "epoch:41 step:32048[D loss: 0.368161, acc: 70.31%, op_acc: 58.59%] [G loss: 1.394796]\n",
      "epoch:41 step:32049[D loss: 0.412003, acc: 63.28%, op_acc: 50.00%] [G loss: 1.257572]\n",
      "epoch:41 step:32050[D loss: 0.479282, acc: 57.03%, op_acc: 39.84%] [G loss: 1.135658]\n",
      "epoch:41 step:32051[D loss: 0.310609, acc: 77.34%, op_acc: 51.56%] [G loss: 1.619308]\n",
      "epoch:41 step:32052[D loss: 0.431246, acc: 58.59%, op_acc: 48.44%] [G loss: 1.459787]\n",
      "epoch:41 step:32053[D loss: 0.384644, acc: 68.75%, op_acc: 46.09%] [G loss: 1.569014]\n",
      "epoch:41 step:32054[D loss: 0.367499, acc: 74.22%, op_acc: 51.56%] [G loss: 1.625939]\n",
      "epoch:41 step:32055[D loss: 0.299384, acc: 80.47%, op_acc: 48.44%] [G loss: 1.306515]\n",
      "epoch:41 step:32056[D loss: 0.361705, acc: 69.53%, op_acc: 52.34%] [G loss: 1.322205]\n",
      "epoch:41 step:32057[D loss: 0.329503, acc: 71.88%, op_acc: 48.44%] [G loss: 1.550059]\n",
      "epoch:41 step:32058[D loss: 0.323731, acc: 78.12%, op_acc: 47.66%] [G loss: 1.493691]\n",
      "epoch:41 step:32059[D loss: 0.330170, acc: 77.34%, op_acc: 56.25%] [G loss: 1.806538]\n",
      "epoch:41 step:32060[D loss: 0.412205, acc: 64.06%, op_acc: 43.75%] [G loss: 1.671365]\n",
      "epoch:41 step:32061[D loss: 0.462975, acc: 64.06%, op_acc: 40.62%] [G loss: 1.513367]\n",
      "epoch:41 step:32062[D loss: 0.316831, acc: 75.78%, op_acc: 55.47%] [G loss: 1.341616]\n",
      "epoch:41 step:32063[D loss: 0.338193, acc: 75.00%, op_acc: 45.31%] [G loss: 1.010925]\n",
      "epoch:41 step:32064[D loss: 0.393949, acc: 66.41%, op_acc: 38.28%] [G loss: 1.226456]\n",
      "epoch:41 step:32065[D loss: 0.428114, acc: 63.28%, op_acc: 48.44%] [G loss: 1.222731]\n",
      "epoch:41 step:32066[D loss: 0.463146, acc: 53.12%, op_acc: 43.75%] [G loss: 1.371498]\n",
      "epoch:41 step:32067[D loss: 0.328486, acc: 80.47%, op_acc: 49.22%] [G loss: 1.759219]\n",
      "epoch:41 step:32068[D loss: 0.340163, acc: 78.12%, op_acc: 40.62%] [G loss: 1.560181]\n",
      "epoch:41 step:32069[D loss: 0.423863, acc: 66.41%, op_acc: 41.41%] [G loss: 1.408013]\n",
      "epoch:41 step:32070[D loss: 0.291929, acc: 82.03%, op_acc: 42.19%] [G loss: 1.145025]\n",
      "epoch:41 step:32071[D loss: 0.358345, acc: 71.88%, op_acc: 48.44%] [G loss: 1.228587]\n",
      "epoch:41 step:32072[D loss: 0.335357, acc: 74.22%, op_acc: 39.84%] [G loss: 1.873897]\n",
      "epoch:41 step:32073[D loss: 0.381613, acc: 70.31%, op_acc: 46.09%] [G loss: 1.608428]\n",
      "epoch:41 step:32074[D loss: 0.386898, acc: 71.09%, op_acc: 41.41%] [G loss: 1.550783]\n",
      "epoch:41 step:32075[D loss: 0.412803, acc: 69.53%, op_acc: 43.75%] [G loss: 1.140119]\n",
      "epoch:41 step:32076[D loss: 0.410415, acc: 65.62%, op_acc: 42.97%] [G loss: 1.257752]\n",
      "epoch:41 step:32077[D loss: 0.357228, acc: 71.09%, op_acc: 48.44%] [G loss: 1.529552]\n",
      "epoch:41 step:32078[D loss: 0.321069, acc: 75.00%, op_acc: 47.66%] [G loss: 1.475391]\n",
      "epoch:41 step:32079[D loss: 0.366394, acc: 70.31%, op_acc: 47.66%] [G loss: 1.177531]\n",
      "epoch:41 step:32080[D loss: 0.417190, acc: 66.41%, op_acc: 44.53%] [G loss: 1.283393]\n",
      "epoch:41 step:32081[D loss: 0.293187, acc: 78.12%, op_acc: 49.22%] [G loss: 1.291696]\n",
      "epoch:41 step:32082[D loss: 0.360009, acc: 74.22%, op_acc: 44.53%] [G loss: 1.652101]\n",
      "epoch:41 step:32083[D loss: 0.412076, acc: 65.62%, op_acc: 50.00%] [G loss: 1.545135]\n",
      "epoch:41 step:32084[D loss: 0.458631, acc: 60.16%, op_acc: 40.62%] [G loss: 1.253672]\n",
      "epoch:41 step:32085[D loss: 0.358554, acc: 70.31%, op_acc: 49.22%] [G loss: 1.421031]\n",
      "epoch:41 step:32086[D loss: 0.452290, acc: 62.50%, op_acc: 38.28%] [G loss: 1.128269]\n",
      "epoch:41 step:32087[D loss: 0.530852, acc: 45.31%, op_acc: 38.28%] [G loss: 1.299356]\n",
      "epoch:41 step:32088[D loss: 0.331992, acc: 72.66%, op_acc: 50.00%] [G loss: 1.268905]\n",
      "epoch:41 step:32089[D loss: 0.390398, acc: 68.75%, op_acc: 49.22%] [G loss: 1.286490]\n",
      "epoch:41 step:32090[D loss: 0.360784, acc: 70.31%, op_acc: 59.38%] [G loss: 1.656433]\n",
      "epoch:41 step:32091[D loss: 0.365754, acc: 71.09%, op_acc: 50.00%] [G loss: 1.462858]\n",
      "epoch:41 step:32092[D loss: 0.356371, acc: 74.22%, op_acc: 46.88%] [G loss: 1.245163]\n",
      "epoch:41 step:32093[D loss: 0.314261, acc: 78.12%, op_acc: 46.09%] [G loss: 1.337602]\n",
      "epoch:41 step:32094[D loss: 0.372316, acc: 68.75%, op_acc: 51.56%] [G loss: 1.362298]\n",
      "epoch:41 step:32095[D loss: 0.452142, acc: 55.47%, op_acc: 39.84%] [G loss: 1.312343]\n",
      "epoch:41 step:32096[D loss: 0.245877, acc: 87.50%, op_acc: 62.50%] [G loss: 2.009635]\n",
      "epoch:41 step:32097[D loss: 0.434044, acc: 63.28%, op_acc: 42.19%] [G loss: 1.420962]\n",
      "epoch:41 step:32098[D loss: 0.391130, acc: 66.41%, op_acc: 42.97%] [G loss: 1.741955]\n",
      "epoch:41 step:32099[D loss: 0.404434, acc: 71.88%, op_acc: 46.09%] [G loss: 1.547239]\n",
      "epoch:41 step:32100[D loss: 0.308684, acc: 77.34%, op_acc: 57.81%] [G loss: 1.526179]\n",
      "epoch:41 step:32101[D loss: 0.314657, acc: 76.56%, op_acc: 46.09%] [G loss: 1.426842]\n",
      "epoch:41 step:32102[D loss: 0.432633, acc: 65.62%, op_acc: 39.84%] [G loss: 1.294448]\n",
      "epoch:41 step:32103[D loss: 0.313477, acc: 80.47%, op_acc: 46.09%] [G loss: 1.465449]\n",
      "epoch:41 step:32104[D loss: 0.384505, acc: 68.75%, op_acc: 50.00%] [G loss: 1.429829]\n",
      "epoch:41 step:32105[D loss: 0.437532, acc: 63.28%, op_acc: 50.78%] [G loss: 1.405885]\n",
      "epoch:41 step:32106[D loss: 0.331159, acc: 80.47%, op_acc: 46.88%] [G loss: 1.617571]\n",
      "epoch:41 step:32107[D loss: 0.297992, acc: 78.91%, op_acc: 51.56%] [G loss: 1.656645]\n",
      "epoch:41 step:32108[D loss: 0.326399, acc: 79.69%, op_acc: 60.16%] [G loss: 1.583641]\n",
      "epoch:41 step:32109[D loss: 0.412367, acc: 64.06%, op_acc: 53.91%] [G loss: 1.410383]\n",
      "epoch:41 step:32110[D loss: 0.397750, acc: 68.75%, op_acc: 46.09%] [G loss: 1.555351]\n",
      "epoch:41 step:32111[D loss: 0.476702, acc: 56.25%, op_acc: 39.84%] [G loss: 1.191809]\n",
      "epoch:41 step:32112[D loss: 0.357565, acc: 70.31%, op_acc: 43.75%] [G loss: 1.560577]\n",
      "epoch:41 step:32113[D loss: 0.357421, acc: 73.44%, op_acc: 41.41%] [G loss: 1.465264]\n",
      "epoch:41 step:32114[D loss: 0.393412, acc: 71.09%, op_acc: 53.12%] [G loss: 1.539145]\n",
      "epoch:41 step:32115[D loss: 0.349926, acc: 74.22%, op_acc: 47.66%] [G loss: 1.355788]\n",
      "epoch:41 step:32116[D loss: 0.377694, acc: 72.66%, op_acc: 50.78%] [G loss: 1.446180]\n",
      "epoch:41 step:32117[D loss: 0.437360, acc: 64.06%, op_acc: 41.41%] [G loss: 1.480551]\n",
      "epoch:41 step:32118[D loss: 0.319910, acc: 76.56%, op_acc: 50.00%] [G loss: 1.467470]\n",
      "epoch:41 step:32119[D loss: 0.345578, acc: 80.47%, op_acc: 42.19%] [G loss: 1.504526]\n",
      "epoch:41 step:32120[D loss: 0.362604, acc: 68.75%, op_acc: 48.44%] [G loss: 1.641392]\n",
      "epoch:41 step:32121[D loss: 0.319295, acc: 75.78%, op_acc: 46.88%] [G loss: 1.550648]\n",
      "epoch:41 step:32122[D loss: 0.300674, acc: 83.59%, op_acc: 53.91%] [G loss: 1.660345]\n",
      "epoch:41 step:32123[D loss: 0.396253, acc: 69.53%, op_acc: 45.31%] [G loss: 1.129904]\n",
      "epoch:41 step:32124[D loss: 0.387686, acc: 67.97%, op_acc: 51.56%] [G loss: 1.165458]\n",
      "epoch:41 step:32125[D loss: 0.366381, acc: 70.31%, op_acc: 46.09%] [G loss: 1.073953]\n",
      "epoch:41 step:32126[D loss: 0.326651, acc: 78.12%, op_acc: 43.75%] [G loss: 1.373314]\n",
      "epoch:41 step:32127[D loss: 0.290587, acc: 79.69%, op_acc: 52.34%] [G loss: 1.342347]\n",
      "epoch:41 step:32128[D loss: 0.345927, acc: 75.78%, op_acc: 46.09%] [G loss: 1.433182]\n",
      "epoch:41 step:32129[D loss: 0.409793, acc: 69.53%, op_acc: 41.41%] [G loss: 1.655542]\n",
      "epoch:41 step:32130[D loss: 0.479583, acc: 53.91%, op_acc: 42.97%] [G loss: 1.322707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32131[D loss: 0.361665, acc: 71.09%, op_acc: 44.53%] [G loss: 1.553288]\n",
      "epoch:41 step:32132[D loss: 0.302940, acc: 80.47%, op_acc: 53.12%] [G loss: 1.747965]\n",
      "epoch:41 step:32133[D loss: 0.400746, acc: 67.19%, op_acc: 53.12%] [G loss: 1.552235]\n",
      "epoch:41 step:32134[D loss: 0.392881, acc: 62.50%, op_acc: 40.62%] [G loss: 1.615258]\n",
      "epoch:41 step:32135[D loss: 0.395597, acc: 67.19%, op_acc: 51.56%] [G loss: 1.583314]\n",
      "epoch:41 step:32136[D loss: 0.508462, acc: 51.56%, op_acc: 39.06%] [G loss: 1.144654]\n",
      "epoch:41 step:32137[D loss: 0.457934, acc: 61.72%, op_acc: 34.38%] [G loss: 1.276585]\n",
      "epoch:41 step:32138[D loss: 0.346968, acc: 65.62%, op_acc: 46.88%] [G loss: 1.410215]\n",
      "epoch:41 step:32139[D loss: 0.352252, acc: 70.31%, op_acc: 44.53%] [G loss: 1.482118]\n",
      "epoch:41 step:32140[D loss: 0.359498, acc: 77.34%, op_acc: 45.31%] [G loss: 1.440722]\n",
      "epoch:41 step:32141[D loss: 0.492589, acc: 55.47%, op_acc: 47.66%] [G loss: 1.235086]\n",
      "epoch:41 step:32142[D loss: 0.389911, acc: 71.09%, op_acc: 44.53%] [G loss: 1.562766]\n",
      "epoch:41 step:32143[D loss: 0.464635, acc: 57.03%, op_acc: 39.84%] [G loss: 0.952896]\n",
      "epoch:41 step:32144[D loss: 0.469840, acc: 57.03%, op_acc: 40.62%] [G loss: 1.397331]\n",
      "epoch:41 step:32145[D loss: 0.439112, acc: 60.94%, op_acc: 47.66%] [G loss: 1.249822]\n",
      "epoch:41 step:32146[D loss: 0.370002, acc: 69.53%, op_acc: 45.31%] [G loss: 1.197839]\n",
      "epoch:41 step:32147[D loss: 0.365338, acc: 71.88%, op_acc: 47.66%] [G loss: 1.167683]\n",
      "epoch:41 step:32148[D loss: 0.333730, acc: 84.38%, op_acc: 46.88%] [G loss: 1.597634]\n",
      "epoch:41 step:32149[D loss: 0.326126, acc: 83.59%, op_acc: 42.19%] [G loss: 1.515047]\n",
      "epoch:41 step:32150[D loss: 0.404007, acc: 67.97%, op_acc: 45.31%] [G loss: 1.362281]\n",
      "epoch:41 step:32151[D loss: 0.379481, acc: 65.62%, op_acc: 50.78%] [G loss: 1.281569]\n",
      "epoch:41 step:32152[D loss: 0.328865, acc: 71.88%, op_acc: 50.78%] [G loss: 1.418797]\n",
      "epoch:41 step:32153[D loss: 0.235681, acc: 89.84%, op_acc: 49.22%] [G loss: 1.506920]\n",
      "epoch:41 step:32154[D loss: 0.374688, acc: 69.53%, op_acc: 45.31%] [G loss: 1.602968]\n",
      "epoch:41 step:32155[D loss: 0.392940, acc: 71.09%, op_acc: 50.00%] [G loss: 1.526733]\n",
      "epoch:41 step:32156[D loss: 0.471891, acc: 60.94%, op_acc: 35.94%] [G loss: 1.468578]\n",
      "epoch:41 step:32157[D loss: 0.306570, acc: 81.25%, op_acc: 49.22%] [G loss: 1.439345]\n",
      "epoch:41 step:32158[D loss: 0.396605, acc: 66.41%, op_acc: 39.06%] [G loss: 1.083462]\n",
      "epoch:41 step:32159[D loss: 0.360754, acc: 74.22%, op_acc: 43.75%] [G loss: 1.126718]\n",
      "epoch:41 step:32160[D loss: 0.401399, acc: 66.41%, op_acc: 41.41%] [G loss: 1.653501]\n",
      "epoch:41 step:32161[D loss: 0.477546, acc: 59.38%, op_acc: 44.53%] [G loss: 0.946770]\n",
      "epoch:41 step:32162[D loss: 0.400342, acc: 65.62%, op_acc: 41.41%] [G loss: 1.269080]\n",
      "epoch:41 step:32163[D loss: 0.345256, acc: 78.12%, op_acc: 44.53%] [G loss: 1.157823]\n",
      "epoch:41 step:32164[D loss: 0.297793, acc: 78.12%, op_acc: 50.00%] [G loss: 1.392140]\n",
      "epoch:41 step:32165[D loss: 0.406538, acc: 67.97%, op_acc: 44.53%] [G loss: 0.865373]\n",
      "epoch:41 step:32166[D loss: 0.402487, acc: 67.97%, op_acc: 46.09%] [G loss: 1.456829]\n",
      "epoch:41 step:32167[D loss: 0.299598, acc: 78.91%, op_acc: 50.78%] [G loss: 1.207438]\n",
      "epoch:41 step:32168[D loss: 0.367756, acc: 72.66%, op_acc: 47.66%] [G loss: 1.580910]\n",
      "epoch:41 step:32169[D loss: 0.406481, acc: 70.31%, op_acc: 50.00%] [G loss: 1.540176]\n",
      "epoch:41 step:32170[D loss: 0.367365, acc: 67.97%, op_acc: 49.22%] [G loss: 1.435823]\n",
      "epoch:41 step:32171[D loss: 0.348918, acc: 71.09%, op_acc: 50.78%] [G loss: 1.370396]\n",
      "epoch:41 step:32172[D loss: 0.277276, acc: 85.94%, op_acc: 57.81%] [G loss: 1.344539]\n",
      "epoch:41 step:32173[D loss: 0.401026, acc: 68.75%, op_acc: 42.19%] [G loss: 1.098861]\n",
      "epoch:41 step:32174[D loss: 0.454011, acc: 63.28%, op_acc: 40.62%] [G loss: 1.291379]\n",
      "epoch:41 step:32175[D loss: 0.359507, acc: 71.88%, op_acc: 46.09%] [G loss: 1.483278]\n",
      "epoch:41 step:32176[D loss: 0.316633, acc: 78.12%, op_acc: 51.56%] [G loss: 1.262799]\n",
      "epoch:41 step:32177[D loss: 0.467390, acc: 62.50%, op_acc: 42.97%] [G loss: 1.050893]\n",
      "epoch:41 step:32178[D loss: 0.365105, acc: 72.66%, op_acc: 45.31%] [G loss: 1.197876]\n",
      "epoch:41 step:32179[D loss: 0.414932, acc: 65.62%, op_acc: 45.31%] [G loss: 1.068967]\n",
      "epoch:41 step:32180[D loss: 0.303171, acc: 82.03%, op_acc: 55.47%] [G loss: 1.455682]\n",
      "epoch:41 step:32181[D loss: 0.333983, acc: 75.78%, op_acc: 49.22%] [G loss: 1.167242]\n",
      "epoch:41 step:32182[D loss: 0.436257, acc: 61.72%, op_acc: 40.62%] [G loss: 1.197307]\n",
      "epoch:41 step:32183[D loss: 0.368146, acc: 66.41%, op_acc: 50.78%] [G loss: 1.690268]\n",
      "epoch:41 step:32184[D loss: 0.319902, acc: 78.12%, op_acc: 46.09%] [G loss: 1.294063]\n",
      "epoch:41 step:32185[D loss: 0.312004, acc: 80.47%, op_acc: 47.66%] [G loss: 1.401029]\n",
      "epoch:41 step:32186[D loss: 0.381383, acc: 67.97%, op_acc: 55.47%] [G loss: 1.551030]\n",
      "epoch:41 step:32187[D loss: 0.366126, acc: 67.97%, op_acc: 56.25%] [G loss: 1.017705]\n",
      "epoch:41 step:32188[D loss: 0.388716, acc: 65.62%, op_acc: 53.12%] [G loss: 1.127685]\n",
      "epoch:41 step:32189[D loss: 0.362015, acc: 73.44%, op_acc: 47.66%] [G loss: 1.173815]\n",
      "epoch:41 step:32190[D loss: 0.406998, acc: 64.06%, op_acc: 41.41%] [G loss: 1.231367]\n",
      "epoch:41 step:32191[D loss: 0.362939, acc: 70.31%, op_acc: 46.88%] [G loss: 1.342895]\n",
      "epoch:41 step:32192[D loss: 0.334940, acc: 78.91%, op_acc: 57.03%] [G loss: 1.204526]\n",
      "epoch:41 step:32193[D loss: 0.382827, acc: 71.88%, op_acc: 47.66%] [G loss: 1.243997]\n",
      "epoch:41 step:32194[D loss: 0.363226, acc: 71.09%, op_acc: 50.00%] [G loss: 1.278979]\n",
      "epoch:41 step:32195[D loss: 0.346121, acc: 79.69%, op_acc: 50.00%] [G loss: 1.093143]\n",
      "epoch:41 step:32196[D loss: 0.290680, acc: 81.25%, op_acc: 46.88%] [G loss: 1.533187]\n",
      "epoch:41 step:32197[D loss: 0.365755, acc: 72.66%, op_acc: 45.31%] [G loss: 1.470116]\n",
      "epoch:41 step:32198[D loss: 0.335538, acc: 76.56%, op_acc: 60.16%] [G loss: 1.454581]\n",
      "epoch:41 step:32199[D loss: 0.500044, acc: 54.69%, op_acc: 39.84%] [G loss: 1.386809]\n",
      "epoch:41 step:32200[D loss: 0.285952, acc: 82.03%, op_acc: 53.12%] [G loss: 1.386350]\n",
      "epoch:41 step:32201[D loss: 0.337628, acc: 75.00%, op_acc: 57.03%] [G loss: 1.420719]\n",
      "epoch:41 step:32202[D loss: 0.275290, acc: 83.59%, op_acc: 57.03%] [G loss: 1.308744]\n",
      "epoch:41 step:32203[D loss: 0.337215, acc: 78.91%, op_acc: 47.66%] [G loss: 1.507976]\n",
      "epoch:41 step:32204[D loss: 0.331921, acc: 77.34%, op_acc: 45.31%] [G loss: 1.752235]\n",
      "epoch:41 step:32205[D loss: 0.353002, acc: 71.09%, op_acc: 53.12%] [G loss: 1.658465]\n",
      "epoch:41 step:32206[D loss: 0.277601, acc: 82.03%, op_acc: 57.81%] [G loss: 1.604652]\n",
      "epoch:41 step:32207[D loss: 0.332113, acc: 75.78%, op_acc: 46.88%] [G loss: 1.434957]\n",
      "epoch:41 step:32208[D loss: 0.317641, acc: 78.91%, op_acc: 48.44%] [G loss: 0.960897]\n",
      "epoch:41 step:32209[D loss: 0.497895, acc: 49.22%, op_acc: 40.62%] [G loss: 1.689419]\n",
      "epoch:41 step:32210[D loss: 0.326749, acc: 79.69%, op_acc: 43.75%] [G loss: 0.921202]\n",
      "epoch:41 step:32211[D loss: 0.438092, acc: 58.59%, op_acc: 39.84%] [G loss: 1.391862]\n",
      "epoch:41 step:32212[D loss: 0.415084, acc: 63.28%, op_acc: 44.53%] [G loss: 1.923951]\n",
      "epoch:41 step:32213[D loss: 0.378743, acc: 69.53%, op_acc: 48.44%] [G loss: 1.562333]\n",
      "epoch:41 step:32214[D loss: 0.393791, acc: 71.09%, op_acc: 40.62%] [G loss: 1.401386]\n",
      "epoch:41 step:32215[D loss: 0.373463, acc: 66.41%, op_acc: 50.00%] [G loss: 1.677469]\n",
      "epoch:41 step:32216[D loss: 0.376047, acc: 71.09%, op_acc: 52.34%] [G loss: 1.436580]\n",
      "epoch:41 step:32217[D loss: 0.402106, acc: 67.97%, op_acc: 43.75%] [G loss: 1.093399]\n",
      "epoch:41 step:32218[D loss: 0.407913, acc: 66.41%, op_acc: 46.09%] [G loss: 1.399706]\n",
      "epoch:41 step:32219[D loss: 0.372172, acc: 76.56%, op_acc: 51.56%] [G loss: 1.333264]\n",
      "epoch:41 step:32220[D loss: 0.381820, acc: 69.53%, op_acc: 39.84%] [G loss: 1.392823]\n",
      "epoch:41 step:32221[D loss: 0.305142, acc: 79.69%, op_acc: 45.31%] [G loss: 1.744832]\n",
      "epoch:41 step:32222[D loss: 0.302799, acc: 81.25%, op_acc: 52.34%] [G loss: 1.171165]\n",
      "epoch:41 step:32223[D loss: 0.277887, acc: 82.81%, op_acc: 51.56%] [G loss: 1.098424]\n",
      "epoch:41 step:32224[D loss: 0.446894, acc: 57.03%, op_acc: 44.53%] [G loss: 0.893858]\n",
      "epoch:41 step:32225[D loss: 0.417314, acc: 64.06%, op_acc: 42.19%] [G loss: 1.301346]\n",
      "epoch:41 step:32226[D loss: 0.315619, acc: 78.91%, op_acc: 46.09%] [G loss: 1.149386]\n",
      "epoch:41 step:32227[D loss: 0.307957, acc: 76.56%, op_acc: 60.16%] [G loss: 1.209726]\n",
      "epoch:41 step:32228[D loss: 0.362871, acc: 67.97%, op_acc: 51.56%] [G loss: 1.333145]\n",
      "epoch:41 step:32229[D loss: 0.319251, acc: 78.12%, op_acc: 56.25%] [G loss: 0.977047]\n",
      "epoch:41 step:32230[D loss: 0.321540, acc: 74.22%, op_acc: 55.47%] [G loss: 1.760909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32231[D loss: 0.348371, acc: 74.22%, op_acc: 49.22%] [G loss: 1.180171]\n",
      "epoch:41 step:32232[D loss: 0.264181, acc: 86.72%, op_acc: 54.69%] [G loss: 1.490872]\n",
      "epoch:41 step:32233[D loss: 0.263026, acc: 86.72%, op_acc: 50.00%] [G loss: 1.163490]\n",
      "epoch:41 step:32234[D loss: 0.294043, acc: 78.91%, op_acc: 64.84%] [G loss: 1.176854]\n",
      "epoch:41 step:32235[D loss: 0.264154, acc: 89.06%, op_acc: 62.50%] [G loss: 1.445172]\n",
      "epoch:41 step:32236[D loss: 0.345439, acc: 75.00%, op_acc: 48.44%] [G loss: 1.477468]\n",
      "epoch:41 step:32237[D loss: 0.354258, acc: 73.44%, op_acc: 46.09%] [G loss: 0.879003]\n",
      "epoch:41 step:32238[D loss: 0.373325, acc: 74.22%, op_acc: 46.88%] [G loss: 1.142792]\n",
      "epoch:41 step:32239[D loss: 0.405278, acc: 65.62%, op_acc: 49.22%] [G loss: 1.145540]\n",
      "epoch:41 step:32240[D loss: 0.312425, acc: 76.56%, op_acc: 52.34%] [G loss: 1.048240]\n",
      "epoch:41 step:32241[D loss: 0.436734, acc: 61.72%, op_acc: 43.75%] [G loss: 1.052953]\n",
      "epoch:41 step:32242[D loss: 0.333777, acc: 79.69%, op_acc: 52.34%] [G loss: 1.007979]\n",
      "epoch:41 step:32243[D loss: 0.316009, acc: 82.81%, op_acc: 50.78%] [G loss: 1.369133]\n",
      "epoch:41 step:32244[D loss: 0.350810, acc: 73.44%, op_acc: 53.12%] [G loss: 0.961962]\n",
      "epoch:41 step:32245[D loss: 0.305317, acc: 75.00%, op_acc: 55.47%] [G loss: 0.760273]\n",
      "epoch:41 step:32246[D loss: 0.350216, acc: 75.78%, op_acc: 48.44%] [G loss: 0.788989]\n",
      "epoch:41 step:32247[D loss: 0.310057, acc: 81.25%, op_acc: 53.12%] [G loss: 1.317709]\n",
      "epoch:41 step:32248[D loss: 0.329476, acc: 75.78%, op_acc: 53.12%] [G loss: 1.222907]\n",
      "epoch:41 step:32249[D loss: 0.391534, acc: 66.41%, op_acc: 46.09%] [G loss: 0.873038]\n",
      "epoch:41 step:32250[D loss: 0.384274, acc: 70.31%, op_acc: 49.22%] [G loss: 1.067193]\n",
      "epoch:41 step:32251[D loss: 0.462447, acc: 64.84%, op_acc: 37.50%] [G loss: 0.853650]\n",
      "epoch:41 step:32252[D loss: 0.269629, acc: 79.69%, op_acc: 60.16%] [G loss: 1.130752]\n",
      "epoch:41 step:32253[D loss: 0.353183, acc: 78.12%, op_acc: 53.91%] [G loss: 0.749863]\n",
      "epoch:41 step:32254[D loss: 0.316805, acc: 79.69%, op_acc: 53.91%] [G loss: 0.867144]\n",
      "epoch:41 step:32255[D loss: 0.321415, acc: 80.47%, op_acc: 50.78%] [G loss: 1.070605]\n",
      "epoch:41 step:32256[D loss: 0.316001, acc: 80.47%, op_acc: 57.03%] [G loss: 1.174871]\n",
      "epoch:41 step:32257[D loss: 0.364092, acc: 74.22%, op_acc: 51.56%] [G loss: 0.917553]\n",
      "epoch:41 step:32258[D loss: 0.357230, acc: 73.44%, op_acc: 45.31%] [G loss: 0.946059]\n",
      "epoch:41 step:32259[D loss: 0.330529, acc: 77.34%, op_acc: 49.22%] [G loss: 1.023451]\n",
      "epoch:41 step:32260[D loss: 0.287787, acc: 84.38%, op_acc: 57.03%] [G loss: 1.202286]\n",
      "epoch:41 step:32261[D loss: 0.364477, acc: 73.44%, op_acc: 42.97%] [G loss: 0.593912]\n",
      "epoch:41 step:32262[D loss: 0.272037, acc: 83.59%, op_acc: 62.50%] [G loss: 1.031807]\n",
      "epoch:41 step:32263[D loss: 0.301072, acc: 78.12%, op_acc: 54.69%] [G loss: 0.884251]\n",
      "epoch:41 step:32264[D loss: 0.390888, acc: 67.97%, op_acc: 45.31%] [G loss: 0.896364]\n",
      "epoch:41 step:32265[D loss: 0.339895, acc: 78.12%, op_acc: 45.31%] [G loss: 1.249734]\n",
      "epoch:41 step:32266[D loss: 0.311969, acc: 78.12%, op_acc: 60.16%] [G loss: 1.494526]\n",
      "epoch:41 step:32267[D loss: 0.296574, acc: 85.94%, op_acc: 49.22%] [G loss: 1.224673]\n",
      "epoch:41 step:32268[D loss: 0.336081, acc: 80.47%, op_acc: 56.25%] [G loss: 1.377438]\n",
      "epoch:41 step:32269[D loss: 0.322027, acc: 82.03%, op_acc: 53.12%] [G loss: 1.599742]\n",
      "epoch:41 step:32270[D loss: 0.277377, acc: 81.25%, op_acc: 53.91%] [G loss: 1.586051]\n",
      "epoch:41 step:32271[D loss: 0.300753, acc: 81.25%, op_acc: 48.44%] [G loss: 1.723758]\n",
      "epoch:41 step:32272[D loss: 0.209702, acc: 91.41%, op_acc: 62.50%] [G loss: 2.302544]\n",
      "epoch:41 step:32273[D loss: 0.287757, acc: 81.25%, op_acc: 56.25%] [G loss: 2.043615]\n",
      "epoch:41 step:32274[D loss: 0.298250, acc: 80.47%, op_acc: 56.25%] [G loss: 1.890033]\n",
      "epoch:41 step:32275[D loss: 0.230607, acc: 90.62%, op_acc: 63.28%] [G loss: 2.150691]\n",
      "epoch:41 step:32276[D loss: 0.281284, acc: 82.81%, op_acc: 53.91%] [G loss: 1.847203]\n",
      "epoch:41 step:32277[D loss: 0.267405, acc: 83.59%, op_acc: 55.47%] [G loss: 1.666651]\n",
      "epoch:41 step:32278[D loss: 0.256710, acc: 90.62%, op_acc: 54.69%] [G loss: 2.234008]\n",
      "epoch:41 step:32279[D loss: 0.302381, acc: 82.03%, op_acc: 54.69%] [G loss: 1.261986]\n",
      "epoch:41 step:32280[D loss: 0.312693, acc: 84.38%, op_acc: 47.66%] [G loss: 1.795271]\n",
      "epoch:41 step:32281[D loss: 0.327599, acc: 75.78%, op_acc: 57.81%] [G loss: 2.054773]\n",
      "epoch:41 step:32282[D loss: 0.284220, acc: 82.81%, op_acc: 57.03%] [G loss: 1.655395]\n",
      "epoch:41 step:32283[D loss: 0.335960, acc: 76.56%, op_acc: 56.25%] [G loss: 1.313088]\n",
      "epoch:41 step:32284[D loss: 0.344864, acc: 73.44%, op_acc: 50.00%] [G loss: 1.594430]\n",
      "epoch:41 step:32285[D loss: 0.293420, acc: 80.47%, op_acc: 59.38%] [G loss: 1.785652]\n",
      "epoch:41 step:32286[D loss: 0.420422, acc: 64.06%, op_acc: 48.44%] [G loss: 1.513635]\n",
      "epoch:41 step:32287[D loss: 0.417374, acc: 64.84%, op_acc: 50.00%] [G loss: 1.926824]\n",
      "epoch:41 step:32288[D loss: 0.499107, acc: 57.03%, op_acc: 48.44%] [G loss: 1.319537]\n",
      "epoch:41 step:32289[D loss: 0.381147, acc: 69.53%, op_acc: 46.09%] [G loss: 1.474838]\n",
      "epoch:41 step:32290[D loss: 0.391819, acc: 65.62%, op_acc: 50.00%] [G loss: 1.864314]\n",
      "epoch:41 step:32291[D loss: 0.429001, acc: 57.81%, op_acc: 44.53%] [G loss: 1.250502]\n",
      "epoch:41 step:32292[D loss: 0.419151, acc: 62.50%, op_acc: 45.31%] [G loss: 1.247216]\n",
      "epoch:41 step:32293[D loss: 0.402958, acc: 75.78%, op_acc: 42.97%] [G loss: 1.348967]\n",
      "epoch:41 step:32294[D loss: 0.316010, acc: 78.91%, op_acc: 54.69%] [G loss: 1.907649]\n",
      "epoch:41 step:32295[D loss: 0.406261, acc: 64.84%, op_acc: 46.88%] [G loss: 1.410250]\n",
      "epoch:41 step:32296[D loss: 0.408190, acc: 65.62%, op_acc: 48.44%] [G loss: 1.221898]\n",
      "epoch:41 step:32297[D loss: 0.306059, acc: 78.91%, op_acc: 48.44%] [G loss: 1.227146]\n",
      "epoch:41 step:32298[D loss: 0.348105, acc: 75.78%, op_acc: 43.75%] [G loss: 1.574440]\n",
      "epoch:41 step:32299[D loss: 0.454383, acc: 60.94%, op_acc: 42.19%] [G loss: 1.752055]\n",
      "epoch:41 step:32300[D loss: 0.440427, acc: 64.06%, op_acc: 52.34%] [G loss: 1.652869]\n",
      "epoch:41 step:32301[D loss: 0.357588, acc: 69.53%, op_acc: 60.16%] [G loss: 1.617911]\n",
      "epoch:41 step:32302[D loss: 0.277106, acc: 83.59%, op_acc: 50.00%] [G loss: 1.552726]\n",
      "epoch:41 step:32303[D loss: 0.338534, acc: 70.31%, op_acc: 55.47%] [G loss: 1.527117]\n",
      "epoch:41 step:32304[D loss: 0.300362, acc: 81.25%, op_acc: 51.56%] [G loss: 0.802147]\n",
      "epoch:41 step:32305[D loss: 0.489344, acc: 60.94%, op_acc: 39.06%] [G loss: 1.795061]\n",
      "epoch:41 step:32306[D loss: 0.335230, acc: 71.88%, op_acc: 45.31%] [G loss: 2.070551]\n",
      "epoch:41 step:32307[D loss: 0.360473, acc: 74.22%, op_acc: 46.88%] [G loss: 2.258053]\n",
      "epoch:41 step:32308[D loss: 0.437644, acc: 67.97%, op_acc: 50.78%] [G loss: 2.433009]\n",
      "epoch:41 step:32309[D loss: 0.422339, acc: 58.59%, op_acc: 46.88%] [G loss: 1.683667]\n",
      "epoch:41 step:32310[D loss: 0.390001, acc: 69.53%, op_acc: 46.88%] [G loss: 1.671194]\n",
      "epoch:41 step:32311[D loss: 0.391228, acc: 69.53%, op_acc: 42.19%] [G loss: 1.884801]\n",
      "epoch:41 step:32312[D loss: 0.429167, acc: 65.62%, op_acc: 48.44%] [G loss: 2.017879]\n",
      "epoch:41 step:32313[D loss: 0.408799, acc: 68.75%, op_acc: 47.66%] [G loss: 1.318280]\n",
      "epoch:41 step:32314[D loss: 0.434074, acc: 63.28%, op_acc: 42.19%] [G loss: 1.581386]\n",
      "epoch:41 step:32315[D loss: 0.429147, acc: 66.41%, op_acc: 46.09%] [G loss: 1.088084]\n",
      "epoch:41 step:32316[D loss: 0.333405, acc: 72.66%, op_acc: 50.00%] [G loss: 1.371443]\n",
      "epoch:41 step:32317[D loss: 0.365917, acc: 69.53%, op_acc: 50.78%] [G loss: 1.274011]\n",
      "epoch:41 step:32318[D loss: 0.371137, acc: 71.09%, op_acc: 46.09%] [G loss: 1.097425]\n",
      "epoch:41 step:32319[D loss: 0.328111, acc: 78.12%, op_acc: 50.00%] [G loss: 1.433841]\n",
      "epoch:41 step:32320[D loss: 0.342908, acc: 73.44%, op_acc: 42.19%] [G loss: 1.365296]\n",
      "epoch:41 step:32321[D loss: 0.362214, acc: 71.09%, op_acc: 50.00%] [G loss: 1.311160]\n",
      "epoch:41 step:32322[D loss: 0.380054, acc: 69.53%, op_acc: 50.78%] [G loss: 1.183236]\n",
      "epoch:41 step:32323[D loss: 0.337490, acc: 75.00%, op_acc: 52.34%] [G loss: 1.432344]\n",
      "epoch:41 step:32324[D loss: 0.383594, acc: 68.75%, op_acc: 44.53%] [G loss: 1.315403]\n",
      "epoch:41 step:32325[D loss: 0.415884, acc: 68.75%, op_acc: 44.53%] [G loss: 1.406544]\n",
      "epoch:41 step:32326[D loss: 0.381676, acc: 62.50%, op_acc: 44.53%] [G loss: 1.424574]\n",
      "epoch:41 step:32327[D loss: 0.386123, acc: 72.66%, op_acc: 39.06%] [G loss: 1.572237]\n",
      "epoch:41 step:32328[D loss: 0.458999, acc: 53.12%, op_acc: 34.38%] [G loss: 1.600625]\n",
      "epoch:41 step:32329[D loss: 0.383680, acc: 69.53%, op_acc: 50.00%] [G loss: 1.353687]\n",
      "epoch:41 step:32330[D loss: 0.393034, acc: 71.88%, op_acc: 39.06%] [G loss: 1.478891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32331[D loss: 0.269328, acc: 87.50%, op_acc: 53.12%] [G loss: 1.515577]\n",
      "epoch:41 step:32332[D loss: 0.396789, acc: 65.62%, op_acc: 49.22%] [G loss: 1.430397]\n",
      "epoch:41 step:32333[D loss: 0.391302, acc: 64.06%, op_acc: 41.41%] [G loss: 1.290911]\n",
      "epoch:41 step:32334[D loss: 0.365632, acc: 74.22%, op_acc: 48.44%] [G loss: 1.716017]\n",
      "epoch:41 step:32335[D loss: 0.482047, acc: 57.03%, op_acc: 40.62%] [G loss: 1.466392]\n",
      "epoch:41 step:32336[D loss: 0.459371, acc: 61.72%, op_acc: 41.41%] [G loss: 1.520991]\n",
      "epoch:41 step:32337[D loss: 0.343952, acc: 72.66%, op_acc: 49.22%] [G loss: 1.491171]\n",
      "epoch:41 step:32338[D loss: 0.461930, acc: 58.59%, op_acc: 43.75%] [G loss: 1.688859]\n",
      "epoch:41 step:32339[D loss: 0.492090, acc: 54.69%, op_acc: 37.50%] [G loss: 1.243854]\n",
      "epoch:41 step:32340[D loss: 0.390467, acc: 67.19%, op_acc: 46.09%] [G loss: 1.353303]\n",
      "epoch:41 step:32341[D loss: 0.379480, acc: 73.44%, op_acc: 50.00%] [G loss: 1.345978]\n",
      "epoch:41 step:32342[D loss: 0.367306, acc: 70.31%, op_acc: 50.78%] [G loss: 1.306139]\n",
      "epoch:41 step:32343[D loss: 0.386203, acc: 69.53%, op_acc: 50.78%] [G loss: 1.152576]\n",
      "epoch:41 step:32344[D loss: 0.396133, acc: 62.50%, op_acc: 46.09%] [G loss: 1.417891]\n",
      "epoch:41 step:32345[D loss: 0.367610, acc: 74.22%, op_acc: 49.22%] [G loss: 1.343524]\n",
      "epoch:41 step:32346[D loss: 0.345091, acc: 75.78%, op_acc: 53.91%] [G loss: 1.346592]\n",
      "epoch:41 step:32347[D loss: 0.424765, acc: 61.72%, op_acc: 46.09%] [G loss: 1.246400]\n",
      "epoch:41 step:32348[D loss: 0.291860, acc: 82.81%, op_acc: 50.00%] [G loss: 1.227124]\n",
      "epoch:41 step:32349[D loss: 0.360261, acc: 74.22%, op_acc: 54.69%] [G loss: 1.989821]\n",
      "epoch:41 step:32350[D loss: 0.387543, acc: 66.41%, op_acc: 46.88%] [G loss: 1.351079]\n",
      "epoch:41 step:32351[D loss: 0.369033, acc: 69.53%, op_acc: 47.66%] [G loss: 1.645411]\n",
      "epoch:41 step:32352[D loss: 0.283929, acc: 82.03%, op_acc: 58.59%] [G loss: 1.710295]\n",
      "epoch:41 step:32353[D loss: 0.380752, acc: 72.66%, op_acc: 46.09%] [G loss: 1.508773]\n",
      "epoch:41 step:32354[D loss: 0.393229, acc: 67.97%, op_acc: 52.34%] [G loss: 1.467553]\n",
      "epoch:41 step:32355[D loss: 0.349266, acc: 73.44%, op_acc: 50.78%] [G loss: 1.324518]\n",
      "epoch:41 step:32356[D loss: 0.332579, acc: 82.81%, op_acc: 47.66%] [G loss: 1.503810]\n",
      "epoch:41 step:32357[D loss: 0.411967, acc: 64.84%, op_acc: 43.75%] [G loss: 1.392317]\n",
      "epoch:41 step:32358[D loss: 0.351883, acc: 71.88%, op_acc: 51.56%] [G loss: 1.580388]\n",
      "epoch:41 step:32359[D loss: 0.352383, acc: 72.66%, op_acc: 46.88%] [G loss: 1.252826]\n",
      "epoch:41 step:32360[D loss: 0.372091, acc: 72.66%, op_acc: 48.44%] [G loss: 1.363812]\n",
      "epoch:41 step:32361[D loss: 0.331931, acc: 72.66%, op_acc: 45.31%] [G loss: 1.067423]\n",
      "epoch:41 step:32362[D loss: 0.406619, acc: 62.50%, op_acc: 46.09%] [G loss: 1.452036]\n",
      "epoch:41 step:32363[D loss: 0.344735, acc: 75.00%, op_acc: 43.75%] [G loss: 1.303933]\n",
      "epoch:41 step:32364[D loss: 0.357141, acc: 72.66%, op_acc: 44.53%] [G loss: 1.396215]\n",
      "epoch:41 step:32365[D loss: 0.379730, acc: 67.19%, op_acc: 49.22%] [G loss: 1.268313]\n",
      "epoch:41 step:32366[D loss: 0.292303, acc: 82.81%, op_acc: 52.34%] [G loss: 1.775763]\n",
      "epoch:41 step:32367[D loss: 0.308974, acc: 78.91%, op_acc: 42.97%] [G loss: 1.045838]\n",
      "epoch:41 step:32368[D loss: 0.313990, acc: 77.34%, op_acc: 59.38%] [G loss: 1.584121]\n",
      "epoch:41 step:32369[D loss: 0.331339, acc: 78.12%, op_acc: 53.91%] [G loss: 1.804593]\n",
      "epoch:41 step:32370[D loss: 0.277099, acc: 84.38%, op_acc: 53.12%] [G loss: 1.370221]\n",
      "epoch:41 step:32371[D loss: 0.318016, acc: 81.25%, op_acc: 53.12%] [G loss: 1.350459]\n",
      "epoch:41 step:32372[D loss: 0.232329, acc: 91.41%, op_acc: 61.72%] [G loss: 2.013490]\n",
      "epoch:41 step:32373[D loss: 0.318055, acc: 78.12%, op_acc: 50.00%] [G loss: 1.648795]\n",
      "epoch:41 step:32374[D loss: 0.282290, acc: 83.59%, op_acc: 52.34%] [G loss: 1.401159]\n",
      "epoch:41 step:32375[D loss: 0.364804, acc: 65.62%, op_acc: 49.22%] [G loss: 1.588171]\n",
      "epoch:41 step:32376[D loss: 0.239943, acc: 92.19%, op_acc: 54.69%] [G loss: 1.343614]\n",
      "epoch:41 step:32377[D loss: 0.402087, acc: 70.31%, op_acc: 41.41%] [G loss: 1.816318]\n",
      "epoch:41 step:32378[D loss: 0.327479, acc: 80.47%, op_acc: 49.22%] [G loss: 1.914755]\n",
      "epoch:41 step:32379[D loss: 0.399145, acc: 64.84%, op_acc: 45.31%] [G loss: 1.774523]\n",
      "epoch:41 step:32380[D loss: 0.437965, acc: 67.19%, op_acc: 40.62%] [G loss: 1.792617]\n",
      "epoch:41 step:32381[D loss: 0.308733, acc: 80.47%, op_acc: 52.34%] [G loss: 1.732757]\n",
      "epoch:41 step:32382[D loss: 0.288399, acc: 78.91%, op_acc: 57.81%] [G loss: 1.648795]\n",
      "epoch:41 step:32383[D loss: 0.331240, acc: 71.09%, op_acc: 58.59%] [G loss: 1.593660]\n",
      "epoch:41 step:32384[D loss: 0.372696, acc: 67.97%, op_acc: 47.66%] [G loss: 1.786531]\n",
      "epoch:41 step:32385[D loss: 0.319975, acc: 78.91%, op_acc: 53.12%] [G loss: 1.428443]\n",
      "epoch:41 step:32386[D loss: 0.364965, acc: 69.53%, op_acc: 60.94%] [G loss: 1.394083]\n",
      "epoch:41 step:32387[D loss: 0.397484, acc: 60.16%, op_acc: 51.56%] [G loss: 1.529042]\n",
      "epoch:41 step:32388[D loss: 0.347681, acc: 80.47%, op_acc: 34.38%] [G loss: 1.401131]\n",
      "epoch:41 step:32389[D loss: 0.324278, acc: 78.12%, op_acc: 48.44%] [G loss: 1.684297]\n",
      "epoch:41 step:32390[D loss: 0.355787, acc: 74.22%, op_acc: 51.56%] [G loss: 1.494303]\n",
      "epoch:41 step:32391[D loss: 0.378275, acc: 75.78%, op_acc: 40.62%] [G loss: 1.444516]\n",
      "epoch:41 step:32392[D loss: 0.372461, acc: 64.84%, op_acc: 48.44%] [G loss: 1.767841]\n",
      "epoch:41 step:32393[D loss: 0.368005, acc: 70.31%, op_acc: 53.12%] [G loss: 0.974710]\n",
      "epoch:41 step:32394[D loss: 0.400556, acc: 64.06%, op_acc: 50.00%] [G loss: 1.222005]\n",
      "epoch:41 step:32395[D loss: 0.320220, acc: 73.44%, op_acc: 57.81%] [G loss: 1.221163]\n",
      "epoch:41 step:32396[D loss: 0.427329, acc: 62.50%, op_acc: 44.53%] [G loss: 1.317933]\n",
      "epoch:41 step:32397[D loss: 0.291695, acc: 83.59%, op_acc: 53.91%] [G loss: 1.365116]\n",
      "epoch:41 step:32398[D loss: 0.315906, acc: 82.03%, op_acc: 51.56%] [G loss: 1.450674]\n",
      "epoch:41 step:32399[D loss: 0.433099, acc: 62.50%, op_acc: 39.06%] [G loss: 1.256873]\n",
      "epoch:41 step:32400[D loss: 0.286995, acc: 81.25%, op_acc: 52.34%] [G loss: 1.357494]\n",
      "epoch:41 step:32401[D loss: 0.331503, acc: 76.56%, op_acc: 57.81%] [G loss: 1.221051]\n",
      "epoch:41 step:32402[D loss: 0.351136, acc: 75.00%, op_acc: 50.00%] [G loss: 0.735817]\n",
      "epoch:41 step:32403[D loss: 0.291140, acc: 80.47%, op_acc: 57.03%] [G loss: 1.078473]\n",
      "epoch:41 step:32404[D loss: 0.281883, acc: 82.03%, op_acc: 64.06%] [G loss: 1.001131]\n",
      "epoch:41 step:32405[D loss: 0.298699, acc: 82.81%, op_acc: 48.44%] [G loss: 1.625871]\n",
      "epoch:41 step:32406[D loss: 0.245354, acc: 90.62%, op_acc: 55.47%] [G loss: 1.217131]\n",
      "epoch:41 step:32407[D loss: 0.335052, acc: 74.22%, op_acc: 57.03%] [G loss: 1.145040]\n",
      "epoch:41 step:32408[D loss: 0.331334, acc: 82.03%, op_acc: 49.22%] [G loss: 1.568702]\n",
      "epoch:41 step:32409[D loss: 0.373591, acc: 70.31%, op_acc: 46.88%] [G loss: 0.873933]\n",
      "epoch:41 step:32410[D loss: 0.374226, acc: 68.75%, op_acc: 49.22%] [G loss: 0.825844]\n",
      "epoch:41 step:32411[D loss: 0.255681, acc: 85.16%, op_acc: 58.59%] [G loss: 1.612633]\n",
      "epoch:41 step:32412[D loss: 0.343210, acc: 72.66%, op_acc: 52.34%] [G loss: 0.893146]\n",
      "epoch:41 step:32413[D loss: 0.347164, acc: 70.31%, op_acc: 52.34%] [G loss: 1.046023]\n",
      "epoch:41 step:32414[D loss: 0.253227, acc: 87.50%, op_acc: 58.59%] [G loss: 0.873452]\n",
      "epoch:41 step:32415[D loss: 0.340464, acc: 75.78%, op_acc: 52.34%] [G loss: 1.324520]\n",
      "epoch:41 step:32416[D loss: 0.436667, acc: 61.72%, op_acc: 36.72%] [G loss: 0.947019]\n",
      "epoch:41 step:32417[D loss: 0.354722, acc: 69.53%, op_acc: 50.00%] [G loss: 0.991066]\n",
      "epoch:41 step:32418[D loss: 0.274316, acc: 79.69%, op_acc: 57.03%] [G loss: 1.798758]\n",
      "epoch:41 step:32419[D loss: 0.384493, acc: 69.53%, op_acc: 49.22%] [G loss: 1.546984]\n",
      "epoch:41 step:32420[D loss: 0.301379, acc: 75.00%, op_acc: 51.56%] [G loss: 1.717775]\n",
      "epoch:41 step:32421[D loss: 0.293303, acc: 84.38%, op_acc: 50.00%] [G loss: 2.189913]\n",
      "epoch:41 step:32422[D loss: 0.215813, acc: 92.19%, op_acc: 62.50%] [G loss: 1.906404]\n",
      "epoch:41 step:32423[D loss: 0.308649, acc: 82.03%, op_acc: 55.47%] [G loss: 1.808374]\n",
      "epoch:41 step:32424[D loss: 0.333355, acc: 75.78%, op_acc: 55.47%] [G loss: 1.436848]\n",
      "epoch:41 step:32425[D loss: 0.302741, acc: 78.91%, op_acc: 54.69%] [G loss: 1.625873]\n",
      "epoch:41 step:32426[D loss: 0.453966, acc: 57.81%, op_acc: 39.06%] [G loss: 1.004463]\n",
      "epoch:41 step:32427[D loss: 0.455482, acc: 58.59%, op_acc: 39.84%] [G loss: 1.374965]\n",
      "epoch:41 step:32428[D loss: 0.323959, acc: 80.47%, op_acc: 41.41%] [G loss: 1.957446]\n",
      "epoch:41 step:32429[D loss: 0.372571, acc: 68.75%, op_acc: 56.25%] [G loss: 1.618418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32430[D loss: 0.382619, acc: 68.75%, op_acc: 57.81%] [G loss: 1.888685]\n",
      "epoch:41 step:32431[D loss: 0.449478, acc: 62.50%, op_acc: 40.62%] [G loss: 1.535615]\n",
      "epoch:41 step:32432[D loss: 0.324098, acc: 78.12%, op_acc: 48.44%] [G loss: 1.566684]\n",
      "epoch:41 step:32433[D loss: 0.286307, acc: 78.12%, op_acc: 61.72%] [G loss: 1.380726]\n",
      "epoch:41 step:32434[D loss: 0.318654, acc: 75.78%, op_acc: 50.00%] [G loss: 1.588987]\n",
      "epoch:41 step:32435[D loss: 0.287345, acc: 79.69%, op_acc: 53.91%] [G loss: 1.501393]\n",
      "epoch:41 step:32436[D loss: 0.309043, acc: 78.91%, op_acc: 58.59%] [G loss: 1.443228]\n",
      "epoch:41 step:32437[D loss: 0.287143, acc: 79.69%, op_acc: 60.16%] [G loss: 1.337014]\n",
      "epoch:41 step:32438[D loss: 0.331052, acc: 78.12%, op_acc: 50.00%] [G loss: 1.714121]\n",
      "epoch:41 step:32439[D loss: 0.314913, acc: 75.78%, op_acc: 59.38%] [G loss: 1.621032]\n",
      "epoch:41 step:32440[D loss: 0.350995, acc: 70.31%, op_acc: 53.91%] [G loss: 1.190202]\n",
      "epoch:41 step:32441[D loss: 0.439666, acc: 67.19%, op_acc: 45.31%] [G loss: 1.244139]\n",
      "epoch:41 step:32442[D loss: 0.302120, acc: 79.69%, op_acc: 46.88%] [G loss: 1.141810]\n",
      "epoch:41 step:32443[D loss: 0.335533, acc: 78.12%, op_acc: 51.56%] [G loss: 1.321303]\n",
      "epoch:41 step:32444[D loss: 0.392928, acc: 67.97%, op_acc: 43.75%] [G loss: 1.129342]\n",
      "epoch:41 step:32445[D loss: 0.351087, acc: 76.56%, op_acc: 49.22%] [G loss: 1.247610]\n",
      "epoch:41 step:32446[D loss: 0.328529, acc: 82.03%, op_acc: 58.59%] [G loss: 1.432570]\n",
      "epoch:41 step:32447[D loss: 0.395453, acc: 69.53%, op_acc: 42.19%] [G loss: 1.095750]\n",
      "epoch:41 step:32448[D loss: 0.382579, acc: 71.88%, op_acc: 43.75%] [G loss: 0.993178]\n",
      "epoch:41 step:32449[D loss: 0.329416, acc: 75.00%, op_acc: 50.00%] [G loss: 0.914623]\n",
      "epoch:41 step:32450[D loss: 0.345993, acc: 70.31%, op_acc: 43.75%] [G loss: 1.250978]\n",
      "epoch:41 step:32451[D loss: 0.361310, acc: 72.66%, op_acc: 47.66%] [G loss: 1.239031]\n",
      "epoch:41 step:32452[D loss: 0.305194, acc: 79.69%, op_acc: 57.03%] [G loss: 1.165352]\n",
      "epoch:41 step:32453[D loss: 0.355533, acc: 68.75%, op_acc: 52.34%] [G loss: 1.462795]\n",
      "epoch:41 step:32454[D loss: 0.372490, acc: 68.75%, op_acc: 46.09%] [G loss: 1.158076]\n",
      "epoch:41 step:32455[D loss: 0.429755, acc: 60.16%, op_acc: 47.66%] [G loss: 1.609136]\n",
      "epoch:41 step:32456[D loss: 0.398106, acc: 65.62%, op_acc: 46.09%] [G loss: 1.442223]\n",
      "epoch:41 step:32457[D loss: 0.434020, acc: 63.28%, op_acc: 44.53%] [G loss: 1.070869]\n",
      "epoch:41 step:32458[D loss: 0.434103, acc: 62.50%, op_acc: 40.62%] [G loss: 1.071902]\n",
      "epoch:41 step:32459[D loss: 0.349825, acc: 71.88%, op_acc: 47.66%] [G loss: 1.364961]\n",
      "epoch:41 step:32460[D loss: 0.501833, acc: 50.00%, op_acc: 37.50%] [G loss: 1.369256]\n",
      "epoch:41 step:32461[D loss: 0.355875, acc: 71.09%, op_acc: 45.31%] [G loss: 1.611709]\n",
      "epoch:41 step:32462[D loss: 0.440677, acc: 57.03%, op_acc: 39.84%] [G loss: 1.475460]\n",
      "epoch:41 step:32463[D loss: 0.280059, acc: 78.12%, op_acc: 53.12%] [G loss: 1.454066]\n",
      "epoch:41 step:32464[D loss: 0.266071, acc: 88.28%, op_acc: 55.47%] [G loss: 1.680188]\n",
      "epoch:41 step:32465[D loss: 0.398825, acc: 70.31%, op_acc: 49.22%] [G loss: 1.030503]\n",
      "epoch:41 step:32466[D loss: 0.460659, acc: 55.47%, op_acc: 44.53%] [G loss: 1.154119]\n",
      "epoch:41 step:32467[D loss: 0.339599, acc: 75.00%, op_acc: 50.78%] [G loss: 1.637643]\n",
      "epoch:41 step:32468[D loss: 0.365275, acc: 76.56%, op_acc: 40.62%] [G loss: 1.727148]\n",
      "epoch:41 step:32469[D loss: 0.297305, acc: 79.69%, op_acc: 48.44%] [G loss: 1.079569]\n",
      "epoch:41 step:32470[D loss: 0.301850, acc: 78.91%, op_acc: 52.34%] [G loss: 1.668670]\n",
      "epoch:41 step:32471[D loss: 0.420128, acc: 63.28%, op_acc: 43.75%] [G loss: 1.300858]\n",
      "epoch:41 step:32472[D loss: 0.369361, acc: 64.06%, op_acc: 53.91%] [G loss: 1.037786]\n",
      "epoch:41 step:32473[D loss: 0.303319, acc: 77.34%, op_acc: 52.34%] [G loss: 0.995794]\n",
      "epoch:41 step:32474[D loss: 0.298036, acc: 80.47%, op_acc: 55.47%] [G loss: 1.351472]\n",
      "epoch:41 step:32475[D loss: 0.344577, acc: 71.09%, op_acc: 46.88%] [G loss: 0.902661]\n",
      "epoch:41 step:32476[D loss: 0.383846, acc: 74.22%, op_acc: 48.44%] [G loss: 1.090276]\n",
      "epoch:41 step:32477[D loss: 0.333283, acc: 78.12%, op_acc: 48.44%] [G loss: 0.781594]\n",
      "epoch:41 step:32478[D loss: 0.305909, acc: 81.25%, op_acc: 40.62%] [G loss: 0.916479]\n",
      "epoch:41 step:32479[D loss: 0.296345, acc: 76.56%, op_acc: 49.22%] [G loss: 1.061198]\n",
      "epoch:41 step:32480[D loss: 0.283634, acc: 79.69%, op_acc: 60.16%] [G loss: 0.878527]\n",
      "epoch:41 step:32481[D loss: 0.379200, acc: 71.09%, op_acc: 48.44%] [G loss: 0.659653]\n",
      "epoch:41 step:32482[D loss: 0.323241, acc: 76.56%, op_acc: 56.25%] [G loss: 0.743051]\n",
      "epoch:41 step:32483[D loss: 0.389469, acc: 64.84%, op_acc: 45.31%] [G loss: 0.959209]\n",
      "epoch:41 step:32484[D loss: 0.426241, acc: 62.50%, op_acc: 48.44%] [G loss: 0.693617]\n",
      "epoch:41 step:32485[D loss: 0.293963, acc: 83.59%, op_acc: 50.00%] [G loss: 0.869515]\n",
      "epoch:41 step:32486[D loss: 0.316046, acc: 77.34%, op_acc: 44.53%] [G loss: 2.058513]\n",
      "epoch:41 step:32487[D loss: 0.305136, acc: 81.25%, op_acc: 52.34%] [G loss: 1.187474]\n",
      "epoch:41 step:32488[D loss: 0.268268, acc: 79.69%, op_acc: 67.19%] [G loss: 1.007813]\n",
      "epoch:41 step:32489[D loss: 0.349929, acc: 72.66%, op_acc: 50.78%] [G loss: 1.183064]\n",
      "epoch:41 step:32490[D loss: 0.308708, acc: 79.69%, op_acc: 54.69%] [G loss: 0.779047]\n",
      "epoch:41 step:32491[D loss: 0.307251, acc: 76.56%, op_acc: 57.03%] [G loss: 0.896117]\n",
      "epoch:41 step:32492[D loss: 0.371726, acc: 67.97%, op_acc: 48.44%] [G loss: 1.028448]\n",
      "epoch:41 step:32493[D loss: 0.274815, acc: 85.94%, op_acc: 51.56%] [G loss: 0.941165]\n",
      "epoch:41 step:32494[D loss: 0.294807, acc: 80.47%, op_acc: 58.59%] [G loss: 0.907847]\n",
      "epoch:41 step:32495[D loss: 0.374998, acc: 69.53%, op_acc: 46.09%] [G loss: 1.079464]\n",
      "epoch:41 step:32496[D loss: 0.357874, acc: 70.31%, op_acc: 48.44%] [G loss: 1.324304]\n",
      "epoch:41 step:32497[D loss: 0.331935, acc: 75.78%, op_acc: 52.34%] [G loss: 1.486269]\n",
      "epoch:41 step:32498[D loss: 0.348180, acc: 74.22%, op_acc: 49.22%] [G loss: 1.238819]\n",
      "epoch:41 step:32499[D loss: 0.365454, acc: 70.31%, op_acc: 52.34%] [G loss: 1.114517]\n",
      "epoch:41 step:32500[D loss: 0.284388, acc: 78.12%, op_acc: 61.72%] [G loss: 1.307062]\n",
      "epoch:41 step:32501[D loss: 0.350348, acc: 73.44%, op_acc: 42.97%] [G loss: 1.212931]\n",
      "epoch:41 step:32502[D loss: 0.284707, acc: 86.72%, op_acc: 50.78%] [G loss: 1.135318]\n",
      "epoch:41 step:32503[D loss: 0.333877, acc: 71.09%, op_acc: 53.12%] [G loss: 1.246066]\n",
      "epoch:41 step:32504[D loss: 0.269074, acc: 86.72%, op_acc: 56.25%] [G loss: 1.446701]\n",
      "epoch:41 step:32505[D loss: 0.291922, acc: 77.34%, op_acc: 52.34%] [G loss: 1.655023]\n",
      "epoch:41 step:32506[D loss: 0.338267, acc: 77.34%, op_acc: 39.06%] [G loss: 1.888150]\n",
      "epoch:41 step:32507[D loss: 0.251942, acc: 82.81%, op_acc: 69.53%] [G loss: 2.149343]\n",
      "epoch:41 step:32508[D loss: 0.352818, acc: 69.53%, op_acc: 64.06%] [G loss: 1.996147]\n",
      "epoch:41 step:32509[D loss: 0.304191, acc: 84.38%, op_acc: 49.22%] [G loss: 1.738883]\n",
      "epoch:41 step:32510[D loss: 0.274053, acc: 83.59%, op_acc: 56.25%] [G loss: 1.819447]\n",
      "epoch:41 step:32511[D loss: 0.287486, acc: 78.91%, op_acc: 56.25%] [G loss: 1.947470]\n",
      "epoch:41 step:32512[D loss: 0.321631, acc: 82.03%, op_acc: 45.31%] [G loss: 1.672539]\n",
      "epoch:41 step:32513[D loss: 0.255820, acc: 82.81%, op_acc: 51.56%] [G loss: 2.050130]\n",
      "epoch:41 step:32514[D loss: 0.261982, acc: 86.72%, op_acc: 61.72%] [G loss: 2.237246]\n",
      "epoch:41 step:32515[D loss: 0.314198, acc: 76.56%, op_acc: 52.34%] [G loss: 1.705274]\n",
      "epoch:41 step:32516[D loss: 0.278028, acc: 85.94%, op_acc: 56.25%] [G loss: 2.227738]\n",
      "epoch:41 step:32517[D loss: 0.364547, acc: 72.66%, op_acc: 46.88%] [G loss: 1.704065]\n",
      "epoch:41 step:32518[D loss: 0.323080, acc: 72.66%, op_acc: 60.94%] [G loss: 1.727348]\n",
      "epoch:41 step:32519[D loss: 0.352240, acc: 70.31%, op_acc: 50.78%] [G loss: 1.738955]\n",
      "epoch:41 step:32520[D loss: 0.416157, acc: 61.72%, op_acc: 41.41%] [G loss: 1.305300]\n",
      "epoch:41 step:32521[D loss: 0.247616, acc: 88.28%, op_acc: 58.59%] [G loss: 1.825699]\n",
      "epoch:41 step:32522[D loss: 0.336600, acc: 69.53%, op_acc: 48.44%] [G loss: 1.710358]\n",
      "epoch:41 step:32523[D loss: 0.349384, acc: 72.66%, op_acc: 50.78%] [G loss: 1.614355]\n",
      "epoch:41 step:32524[D loss: 0.374767, acc: 67.97%, op_acc: 38.28%] [G loss: 1.570845]\n",
      "epoch:41 step:32525[D loss: 0.425568, acc: 63.28%, op_acc: 54.69%] [G loss: 1.346176]\n",
      "epoch:41 step:32526[D loss: 0.376059, acc: 73.44%, op_acc: 46.09%] [G loss: 1.505648]\n",
      "epoch:41 step:32527[D loss: 0.353049, acc: 75.00%, op_acc: 50.00%] [G loss: 1.674467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32528[D loss: 0.245608, acc: 86.72%, op_acc: 57.81%] [G loss: 1.876789]\n",
      "epoch:41 step:32529[D loss: 0.432572, acc: 64.06%, op_acc: 49.22%] [G loss: 1.315487]\n",
      "epoch:41 step:32530[D loss: 0.372026, acc: 69.53%, op_acc: 44.53%] [G loss: 1.038252]\n",
      "epoch:41 step:32531[D loss: 0.348228, acc: 78.12%, op_acc: 47.66%] [G loss: 1.559880]\n",
      "epoch:41 step:32532[D loss: 0.443331, acc: 57.81%, op_acc: 40.62%] [G loss: 1.440226]\n",
      "epoch:41 step:32533[D loss: 0.420609, acc: 68.75%, op_acc: 51.56%] [G loss: 1.260303]\n",
      "epoch:41 step:32534[D loss: 0.375254, acc: 70.31%, op_acc: 46.09%] [G loss: 1.173152]\n",
      "epoch:41 step:32535[D loss: 0.376080, acc: 70.31%, op_acc: 42.19%] [G loss: 1.631298]\n",
      "epoch:41 step:32536[D loss: 0.534225, acc: 48.44%, op_acc: 34.38%] [G loss: 1.405888]\n",
      "epoch:41 step:32537[D loss: 0.430714, acc: 54.69%, op_acc: 42.19%] [G loss: 1.898297]\n",
      "epoch:41 step:32538[D loss: 0.472865, acc: 57.03%, op_acc: 39.84%] [G loss: 1.693087]\n",
      "epoch:41 step:32539[D loss: 0.468441, acc: 53.91%, op_acc: 46.09%] [G loss: 1.658318]\n",
      "epoch:41 step:32540[D loss: 0.536502, acc: 48.44%, op_acc: 48.44%] [G loss: 1.371426]\n",
      "epoch:41 step:32541[D loss: 0.371643, acc: 71.88%, op_acc: 46.09%] [G loss: 1.573310]\n",
      "epoch:41 step:32542[D loss: 0.482137, acc: 55.47%, op_acc: 42.97%] [G loss: 1.433978]\n",
      "epoch:41 step:32543[D loss: 0.516517, acc: 49.22%, op_acc: 47.66%] [G loss: 1.224084]\n",
      "epoch:41 step:32544[D loss: 0.391249, acc: 71.88%, op_acc: 41.41%] [G loss: 1.463569]\n",
      "epoch:41 step:32545[D loss: 0.363305, acc: 76.56%, op_acc: 43.75%] [G loss: 1.480494]\n",
      "epoch:41 step:32546[D loss: 0.456428, acc: 60.94%, op_acc: 42.19%] [G loss: 1.489486]\n",
      "epoch:41 step:32547[D loss: 0.534415, acc: 49.22%, op_acc: 35.16%] [G loss: 1.379928]\n",
      "epoch:41 step:32548[D loss: 0.414573, acc: 66.41%, op_acc: 46.09%] [G loss: 1.453117]\n",
      "epoch:41 step:32549[D loss: 0.354473, acc: 73.44%, op_acc: 50.00%] [G loss: 1.356217]\n",
      "epoch:41 step:32550[D loss: 0.345611, acc: 73.44%, op_acc: 52.34%] [G loss: 1.875318]\n",
      "epoch:41 step:32551[D loss: 0.437550, acc: 61.72%, op_acc: 44.53%] [G loss: 1.450470]\n",
      "epoch:41 step:32552[D loss: 0.382814, acc: 70.31%, op_acc: 44.53%] [G loss: 1.428245]\n",
      "epoch:41 step:32553[D loss: 0.426954, acc: 65.62%, op_acc: 48.44%] [G loss: 1.485984]\n",
      "epoch:41 step:32554[D loss: 0.377020, acc: 68.75%, op_acc: 48.44%] [G loss: 1.693549]\n",
      "epoch:41 step:32555[D loss: 0.356438, acc: 69.53%, op_acc: 49.22%] [G loss: 1.332529]\n",
      "epoch:41 step:32556[D loss: 0.374901, acc: 70.31%, op_acc: 48.44%] [G loss: 1.282827]\n",
      "epoch:41 step:32557[D loss: 0.252637, acc: 83.59%, op_acc: 53.91%] [G loss: 1.750827]\n",
      "epoch:41 step:32558[D loss: 0.431382, acc: 63.28%, op_acc: 42.97%] [G loss: 1.582706]\n",
      "epoch:41 step:32559[D loss: 0.341449, acc: 73.44%, op_acc: 50.78%] [G loss: 1.766548]\n",
      "epoch:41 step:32560[D loss: 0.427359, acc: 65.62%, op_acc: 51.56%] [G loss: 1.552392]\n",
      "epoch:41 step:32561[D loss: 0.398472, acc: 69.53%, op_acc: 47.66%] [G loss: 1.759695]\n",
      "epoch:41 step:32562[D loss: 0.294830, acc: 78.12%, op_acc: 54.69%] [G loss: 1.442731]\n",
      "epoch:41 step:32563[D loss: 0.366434, acc: 68.75%, op_acc: 47.66%] [G loss: 1.722035]\n",
      "epoch:41 step:32564[D loss: 0.387149, acc: 74.22%, op_acc: 46.09%] [G loss: 1.319663]\n",
      "epoch:41 step:32565[D loss: 0.303419, acc: 82.81%, op_acc: 49.22%] [G loss: 1.621910]\n",
      "epoch:41 step:32566[D loss: 0.197605, acc: 93.75%, op_acc: 66.41%] [G loss: 1.850353]\n",
      "epoch:41 step:32567[D loss: 0.390778, acc: 70.31%, op_acc: 46.88%] [G loss: 1.557026]\n",
      "epoch:41 step:32568[D loss: 0.353212, acc: 75.00%, op_acc: 45.31%] [G loss: 1.342955]\n",
      "epoch:41 step:32569[D loss: 0.350589, acc: 75.78%, op_acc: 49.22%] [G loss: 1.279770]\n",
      "epoch:41 step:32570[D loss: 0.419001, acc: 64.06%, op_acc: 45.31%] [G loss: 1.497401]\n",
      "epoch:41 step:32571[D loss: 0.408301, acc: 65.62%, op_acc: 47.66%] [G loss: 1.502342]\n",
      "epoch:41 step:32572[D loss: 0.533185, acc: 49.22%, op_acc: 39.06%] [G loss: 0.979703]\n",
      "epoch:41 step:32573[D loss: 0.437138, acc: 63.28%, op_acc: 39.06%] [G loss: 1.026037]\n",
      "epoch:41 step:32574[D loss: 0.356325, acc: 72.66%, op_acc: 42.97%] [G loss: 1.588019]\n",
      "epoch:41 step:32575[D loss: 0.315587, acc: 78.91%, op_acc: 49.22%] [G loss: 1.108873]\n",
      "epoch:41 step:32576[D loss: 0.403492, acc: 67.19%, op_acc: 44.53%] [G loss: 1.504482]\n",
      "epoch:41 step:32577[D loss: 0.538675, acc: 46.88%, op_acc: 34.38%] [G loss: 1.458746]\n",
      "epoch:41 step:32578[D loss: 0.359785, acc: 71.09%, op_acc: 39.06%] [G loss: 1.568014]\n",
      "epoch:41 step:32579[D loss: 0.361087, acc: 75.00%, op_acc: 47.66%] [G loss: 1.517184]\n",
      "epoch:41 step:32580[D loss: 0.343347, acc: 72.66%, op_acc: 53.91%] [G loss: 1.639032]\n",
      "epoch:41 step:32581[D loss: 0.461284, acc: 64.84%, op_acc: 37.50%] [G loss: 1.333771]\n",
      "epoch:41 step:32582[D loss: 0.517550, acc: 47.66%, op_acc: 40.62%] [G loss: 1.266784]\n",
      "epoch:41 step:32583[D loss: 0.404984, acc: 67.97%, op_acc: 39.84%] [G loss: 1.180669]\n",
      "epoch:41 step:32584[D loss: 0.397329, acc: 64.06%, op_acc: 39.84%] [G loss: 1.377287]\n",
      "epoch:41 step:32585[D loss: 0.352820, acc: 74.22%, op_acc: 50.00%] [G loss: 1.520540]\n",
      "epoch:41 step:32586[D loss: 0.351588, acc: 72.66%, op_acc: 49.22%] [G loss: 1.274153]\n",
      "epoch:41 step:32587[D loss: 0.436188, acc: 64.06%, op_acc: 37.50%] [G loss: 1.562310]\n",
      "epoch:41 step:32588[D loss: 0.396342, acc: 67.19%, op_acc: 49.22%] [G loss: 1.458285]\n",
      "epoch:41 step:32589[D loss: 0.349896, acc: 74.22%, op_acc: 46.09%] [G loss: 1.572386]\n",
      "epoch:41 step:32590[D loss: 0.397107, acc: 65.62%, op_acc: 44.53%] [G loss: 1.442864]\n",
      "epoch:41 step:32591[D loss: 0.359507, acc: 72.66%, op_acc: 46.09%] [G loss: 1.467020]\n",
      "epoch:41 step:32592[D loss: 0.405378, acc: 64.84%, op_acc: 57.03%] [G loss: 1.410560]\n",
      "epoch:41 step:32593[D loss: 0.389063, acc: 68.75%, op_acc: 40.62%] [G loss: 1.279457]\n",
      "epoch:41 step:32594[D loss: 0.450260, acc: 60.16%, op_acc: 39.06%] [G loss: 1.229701]\n",
      "epoch:41 step:32595[D loss: 0.444740, acc: 64.84%, op_acc: 41.41%] [G loss: 1.290043]\n",
      "epoch:41 step:32596[D loss: 0.444066, acc: 57.03%, op_acc: 46.09%] [G loss: 1.284516]\n",
      "epoch:41 step:32597[D loss: 0.387886, acc: 73.44%, op_acc: 44.53%] [G loss: 1.380789]\n",
      "epoch:41 step:32598[D loss: 0.348471, acc: 75.00%, op_acc: 52.34%] [G loss: 1.390935]\n",
      "epoch:41 step:32599[D loss: 0.462412, acc: 61.72%, op_acc: 35.16%] [G loss: 1.456668]\n",
      "epoch:41 step:32600[D loss: 0.320040, acc: 77.34%, op_acc: 51.56%] [G loss: 1.209938]\n",
      "epoch:41 step:32601[D loss: 0.396456, acc: 69.53%, op_acc: 48.44%] [G loss: 1.252157]\n",
      "epoch:41 step:32602[D loss: 0.398860, acc: 65.62%, op_acc: 42.97%] [G loss: 1.324247]\n",
      "epoch:41 step:32603[D loss: 0.360310, acc: 71.09%, op_acc: 53.91%] [G loss: 1.343848]\n",
      "epoch:41 step:32604[D loss: 0.340653, acc: 74.22%, op_acc: 46.88%] [G loss: 1.560240]\n",
      "epoch:41 step:32605[D loss: 0.482440, acc: 57.03%, op_acc: 35.16%] [G loss: 1.244294]\n",
      "epoch:41 step:32606[D loss: 0.323144, acc: 71.88%, op_acc: 46.88%] [G loss: 1.216089]\n",
      "epoch:41 step:32607[D loss: 0.397545, acc: 69.53%, op_acc: 51.56%] [G loss: 1.323180]\n",
      "epoch:41 step:32608[D loss: 0.278580, acc: 82.03%, op_acc: 50.00%] [G loss: 1.529816]\n",
      "epoch:41 step:32609[D loss: 0.287024, acc: 79.69%, op_acc: 54.69%] [G loss: 1.420837]\n",
      "epoch:41 step:32610[D loss: 0.359978, acc: 72.66%, op_acc: 48.44%] [G loss: 1.429789]\n",
      "epoch:41 step:32611[D loss: 0.426654, acc: 65.62%, op_acc: 42.97%] [G loss: 1.403623]\n",
      "epoch:41 step:32612[D loss: 0.498362, acc: 55.47%, op_acc: 42.97%] [G loss: 1.483107]\n",
      "epoch:41 step:32613[D loss: 0.464464, acc: 60.94%, op_acc: 48.44%] [G loss: 1.354912]\n",
      "epoch:41 step:32614[D loss: 0.410325, acc: 70.31%, op_acc: 35.94%] [G loss: 1.411674]\n",
      "epoch:41 step:32615[D loss: 0.444944, acc: 60.16%, op_acc: 40.62%] [G loss: 1.413473]\n",
      "epoch:41 step:32616[D loss: 0.334160, acc: 75.00%, op_acc: 43.75%] [G loss: 1.391675]\n",
      "epoch:41 step:32617[D loss: 0.392802, acc: 68.75%, op_acc: 45.31%] [G loss: 1.315078]\n",
      "epoch:41 step:32618[D loss: 0.385803, acc: 67.97%, op_acc: 43.75%] [G loss: 1.562687]\n",
      "epoch:41 step:32619[D loss: 0.410882, acc: 68.75%, op_acc: 46.09%] [G loss: 1.251092]\n",
      "epoch:41 step:32620[D loss: 0.401859, acc: 66.41%, op_acc: 40.62%] [G loss: 1.345804]\n",
      "epoch:41 step:32621[D loss: 0.384898, acc: 66.41%, op_acc: 41.41%] [G loss: 1.302335]\n",
      "epoch:41 step:32622[D loss: 0.437406, acc: 60.94%, op_acc: 40.62%] [G loss: 1.271123]\n",
      "epoch:41 step:32623[D loss: 0.277147, acc: 82.81%, op_acc: 54.69%] [G loss: 1.411822]\n",
      "epoch:41 step:32624[D loss: 0.484083, acc: 54.69%, op_acc: 45.31%] [G loss: 1.439660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32625[D loss: 0.430260, acc: 71.88%, op_acc: 35.94%] [G loss: 1.112691]\n",
      "epoch:41 step:32626[D loss: 0.419609, acc: 60.16%, op_acc: 50.00%] [G loss: 1.216996]\n",
      "epoch:41 step:32627[D loss: 0.499540, acc: 51.56%, op_acc: 39.84%] [G loss: 1.180225]\n",
      "epoch:41 step:32628[D loss: 0.277469, acc: 84.38%, op_acc: 56.25%] [G loss: 1.516698]\n",
      "epoch:41 step:32629[D loss: 0.396859, acc: 60.16%, op_acc: 54.69%] [G loss: 1.102914]\n",
      "epoch:41 step:32630[D loss: 0.406082, acc: 58.59%, op_acc: 48.44%] [G loss: 1.355432]\n",
      "epoch:41 step:32631[D loss: 0.408949, acc: 64.84%, op_acc: 44.53%] [G loss: 1.301168]\n",
      "epoch:41 step:32632[D loss: 0.421168, acc: 63.28%, op_acc: 43.75%] [G loss: 1.294595]\n",
      "epoch:41 step:32633[D loss: 0.351956, acc: 75.78%, op_acc: 42.97%] [G loss: 1.342988]\n",
      "epoch:41 step:32634[D loss: 0.425122, acc: 57.81%, op_acc: 42.19%] [G loss: 1.260798]\n",
      "epoch:41 step:32635[D loss: 0.306694, acc: 81.25%, op_acc: 50.00%] [G loss: 1.319688]\n",
      "epoch:41 step:32636[D loss: 0.412449, acc: 60.16%, op_acc: 42.97%] [G loss: 1.233032]\n",
      "epoch:41 step:32637[D loss: 0.463146, acc: 53.91%, op_acc: 45.31%] [G loss: 1.412753]\n",
      "epoch:41 step:32638[D loss: 0.410378, acc: 64.84%, op_acc: 43.75%] [G loss: 0.986838]\n",
      "epoch:41 step:32639[D loss: 0.348476, acc: 75.00%, op_acc: 57.81%] [G loss: 1.531497]\n",
      "epoch:41 step:32640[D loss: 0.427006, acc: 64.84%, op_acc: 45.31%] [G loss: 1.152185]\n",
      "epoch:41 step:32641[D loss: 0.327863, acc: 75.78%, op_acc: 42.97%] [G loss: 1.556108]\n",
      "epoch:41 step:32642[D loss: 0.368488, acc: 71.88%, op_acc: 52.34%] [G loss: 1.293923]\n",
      "epoch:41 step:32643[D loss: 0.354105, acc: 68.75%, op_acc: 50.00%] [G loss: 1.239192]\n",
      "epoch:41 step:32644[D loss: 0.404004, acc: 68.75%, op_acc: 40.62%] [G loss: 1.576912]\n",
      "epoch:41 step:32645[D loss: 0.393195, acc: 67.97%, op_acc: 50.78%] [G loss: 1.358801]\n",
      "epoch:41 step:32646[D loss: 0.411443, acc: 65.62%, op_acc: 45.31%] [G loss: 1.338045]\n",
      "epoch:41 step:32647[D loss: 0.391822, acc: 65.62%, op_acc: 48.44%] [G loss: 1.386969]\n",
      "epoch:41 step:32648[D loss: 0.375215, acc: 67.97%, op_acc: 46.88%] [G loss: 1.218333]\n",
      "epoch:41 step:32649[D loss: 0.368339, acc: 73.44%, op_acc: 46.88%] [G loss: 1.322731]\n",
      "epoch:41 step:32650[D loss: 0.423720, acc: 64.84%, op_acc: 42.19%] [G loss: 1.298088]\n",
      "epoch:41 step:32651[D loss: 0.312439, acc: 80.47%, op_acc: 46.88%] [G loss: 1.442956]\n",
      "epoch:41 step:32652[D loss: 0.477735, acc: 53.91%, op_acc: 42.97%] [G loss: 1.208796]\n",
      "epoch:41 step:32653[D loss: 0.346347, acc: 71.88%, op_acc: 48.44%] [G loss: 1.687593]\n",
      "epoch:41 step:32654[D loss: 0.407735, acc: 67.19%, op_acc: 49.22%] [G loss: 1.392011]\n",
      "epoch:41 step:32655[D loss: 0.410896, acc: 61.72%, op_acc: 53.12%] [G loss: 0.935506]\n",
      "epoch:41 step:32656[D loss: 0.379357, acc: 67.97%, op_acc: 42.19%] [G loss: 1.420415]\n",
      "epoch:41 step:32657[D loss: 0.437046, acc: 66.41%, op_acc: 45.31%] [G loss: 1.400460]\n",
      "epoch:41 step:32658[D loss: 0.359014, acc: 72.66%, op_acc: 50.78%] [G loss: 1.527448]\n",
      "epoch:41 step:32659[D loss: 0.472117, acc: 55.47%, op_acc: 45.31%] [G loss: 0.935997]\n",
      "epoch:41 step:32660[D loss: 0.409386, acc: 67.19%, op_acc: 45.31%] [G loss: 1.311420]\n",
      "epoch:41 step:32661[D loss: 0.389053, acc: 70.31%, op_acc: 47.66%] [G loss: 1.256160]\n",
      "epoch:41 step:32662[D loss: 0.338679, acc: 79.69%, op_acc: 40.62%] [G loss: 1.326016]\n",
      "epoch:41 step:32663[D loss: 0.348993, acc: 75.00%, op_acc: 50.78%] [G loss: 1.337999]\n",
      "epoch:41 step:32664[D loss: 0.415940, acc: 64.06%, op_acc: 42.19%] [G loss: 1.232328]\n",
      "epoch:41 step:32665[D loss: 0.442611, acc: 58.59%, op_acc: 45.31%] [G loss: 1.181318]\n",
      "epoch:41 step:32666[D loss: 0.367041, acc: 72.66%, op_acc: 46.88%] [G loss: 1.217621]\n",
      "epoch:41 step:32667[D loss: 0.360491, acc: 69.53%, op_acc: 46.09%] [G loss: 1.455325]\n",
      "epoch:41 step:32668[D loss: 0.351212, acc: 70.31%, op_acc: 48.44%] [G loss: 1.583052]\n",
      "epoch:41 step:32669[D loss: 0.315982, acc: 75.00%, op_acc: 52.34%] [G loss: 1.486390]\n",
      "epoch:41 step:32670[D loss: 0.342914, acc: 75.78%, op_acc: 51.56%] [G loss: 1.176861]\n",
      "epoch:41 step:32671[D loss: 0.471909, acc: 58.59%, op_acc: 44.53%] [G loss: 0.846121]\n",
      "epoch:41 step:32672[D loss: 0.380503, acc: 71.09%, op_acc: 52.34%] [G loss: 1.282007]\n",
      "epoch:41 step:32673[D loss: 0.407242, acc: 68.75%, op_acc: 44.53%] [G loss: 1.335677]\n",
      "epoch:41 step:32674[D loss: 0.357465, acc: 70.31%, op_acc: 50.00%] [G loss: 1.141431]\n",
      "epoch:41 step:32675[D loss: 0.362400, acc: 67.19%, op_acc: 49.22%] [G loss: 1.313061]\n",
      "epoch:41 step:32676[D loss: 0.372051, acc: 74.22%, op_acc: 45.31%] [G loss: 1.319154]\n",
      "epoch:41 step:32677[D loss: 0.385660, acc: 69.53%, op_acc: 42.19%] [G loss: 1.408159]\n",
      "epoch:41 step:32678[D loss: 0.389406, acc: 74.22%, op_acc: 51.56%] [G loss: 1.243569]\n",
      "epoch:41 step:32679[D loss: 0.358317, acc: 71.88%, op_acc: 43.75%] [G loss: 1.418784]\n",
      "epoch:41 step:32680[D loss: 0.315880, acc: 78.91%, op_acc: 50.00%] [G loss: 1.395865]\n",
      "epoch:41 step:32681[D loss: 0.340337, acc: 71.88%, op_acc: 53.12%] [G loss: 1.718934]\n",
      "epoch:41 step:32682[D loss: 0.381175, acc: 70.31%, op_acc: 45.31%] [G loss: 1.247326]\n",
      "epoch:41 step:32683[D loss: 0.369830, acc: 71.09%, op_acc: 51.56%] [G loss: 1.250446]\n",
      "epoch:41 step:32684[D loss: 0.383669, acc: 69.53%, op_acc: 44.53%] [G loss: 1.221894]\n",
      "epoch:41 step:32685[D loss: 0.351236, acc: 73.44%, op_acc: 54.69%] [G loss: 1.371982]\n",
      "epoch:41 step:32686[D loss: 0.361532, acc: 75.00%, op_acc: 40.62%] [G loss: 1.335495]\n",
      "epoch:41 step:32687[D loss: 0.426213, acc: 60.94%, op_acc: 40.62%] [G loss: 1.424434]\n",
      "epoch:41 step:32688[D loss: 0.367639, acc: 65.62%, op_acc: 41.41%] [G loss: 1.493975]\n",
      "epoch:41 step:32689[D loss: 0.366154, acc: 74.22%, op_acc: 50.78%] [G loss: 1.712527]\n",
      "epoch:41 step:32690[D loss: 0.446098, acc: 60.94%, op_acc: 46.88%] [G loss: 1.155178]\n",
      "epoch:41 step:32691[D loss: 0.440711, acc: 61.72%, op_acc: 37.50%] [G loss: 1.105839]\n",
      "epoch:41 step:32692[D loss: 0.482137, acc: 58.59%, op_acc: 40.62%] [G loss: 1.314056]\n",
      "epoch:41 step:32693[D loss: 0.361197, acc: 72.66%, op_acc: 47.66%] [G loss: 1.285500]\n",
      "epoch:41 step:32694[D loss: 0.397094, acc: 64.06%, op_acc: 46.88%] [G loss: 1.364598]\n",
      "epoch:41 step:32695[D loss: 0.422465, acc: 59.38%, op_acc: 50.00%] [G loss: 1.569742]\n",
      "epoch:41 step:32696[D loss: 0.380529, acc: 67.19%, op_acc: 44.53%] [G loss: 1.414350]\n",
      "epoch:41 step:32697[D loss: 0.472919, acc: 56.25%, op_acc: 35.94%] [G loss: 1.293067]\n",
      "epoch:41 step:32698[D loss: 0.425968, acc: 63.28%, op_acc: 38.28%] [G loss: 1.351477]\n",
      "epoch:41 step:32699[D loss: 0.347697, acc: 71.09%, op_acc: 55.47%] [G loss: 1.484516]\n",
      "epoch:41 step:32700[D loss: 0.407479, acc: 59.38%, op_acc: 45.31%] [G loss: 1.509235]\n",
      "epoch:41 step:32701[D loss: 0.386930, acc: 70.31%, op_acc: 40.62%] [G loss: 1.120608]\n",
      "epoch:41 step:32702[D loss: 0.455902, acc: 60.94%, op_acc: 40.62%] [G loss: 1.634885]\n",
      "epoch:41 step:32703[D loss: 0.354119, acc: 70.31%, op_acc: 51.56%] [G loss: 1.491597]\n",
      "epoch:41 step:32704[D loss: 0.463690, acc: 56.25%, op_acc: 39.84%] [G loss: 1.510273]\n",
      "epoch:41 step:32705[D loss: 0.369780, acc: 75.78%, op_acc: 46.88%] [G loss: 1.661163]\n",
      "epoch:41 step:32706[D loss: 0.348850, acc: 68.75%, op_acc: 46.09%] [G loss: 1.436744]\n",
      "epoch:41 step:32707[D loss: 0.500205, acc: 46.88%, op_acc: 40.62%] [G loss: 1.392046]\n",
      "epoch:41 step:32708[D loss: 0.364017, acc: 69.53%, op_acc: 47.66%] [G loss: 1.469326]\n",
      "epoch:41 step:32709[D loss: 0.370479, acc: 65.62%, op_acc: 49.22%] [G loss: 1.408315]\n",
      "epoch:41 step:32710[D loss: 0.477050, acc: 50.78%, op_acc: 45.31%] [G loss: 1.154646]\n",
      "epoch:41 step:32711[D loss: 0.391467, acc: 71.09%, op_acc: 37.50%] [G loss: 1.351204]\n",
      "epoch:41 step:32712[D loss: 0.361852, acc: 72.66%, op_acc: 46.88%] [G loss: 1.428323]\n",
      "epoch:41 step:32713[D loss: 0.416688, acc: 61.72%, op_acc: 45.31%] [G loss: 1.334488]\n",
      "epoch:41 step:32714[D loss: 0.358579, acc: 70.31%, op_acc: 41.41%] [G loss: 1.081970]\n",
      "epoch:41 step:32715[D loss: 0.328004, acc: 78.91%, op_acc: 50.78%] [G loss: 1.048284]\n",
      "epoch:41 step:32716[D loss: 0.346456, acc: 71.09%, op_acc: 44.53%] [G loss: 1.069366]\n",
      "epoch:41 step:32717[D loss: 0.415691, acc: 67.19%, op_acc: 39.84%] [G loss: 1.420283]\n",
      "epoch:41 step:32718[D loss: 0.410309, acc: 63.28%, op_acc: 48.44%] [G loss: 1.463768]\n",
      "epoch:41 step:32719[D loss: 0.351568, acc: 75.00%, op_acc: 47.66%] [G loss: 1.417546]\n",
      "epoch:41 step:32720[D loss: 0.448200, acc: 64.84%, op_acc: 45.31%] [G loss: 1.112248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41 step:32721[D loss: 0.386875, acc: 64.84%, op_acc: 36.72%] [G loss: 1.268337]\n",
      "epoch:41 step:32722[D loss: 0.389275, acc: 70.31%, op_acc: 43.75%] [G loss: 1.298385]\n",
      "epoch:41 step:32723[D loss: 0.447434, acc: 58.59%, op_acc: 40.62%] [G loss: 1.292968]\n",
      "epoch:41 step:32724[D loss: 0.354266, acc: 72.66%, op_acc: 42.97%] [G loss: 1.186176]\n",
      "epoch:41 step:32725[D loss: 0.405809, acc: 64.84%, op_acc: 50.00%] [G loss: 1.151417]\n",
      "epoch:41 step:32726[D loss: 0.379326, acc: 69.53%, op_acc: 42.97%] [G loss: 1.103530]\n",
      "epoch:41 step:32727[D loss: 0.346426, acc: 70.31%, op_acc: 53.12%] [G loss: 1.432738]\n",
      "epoch:41 step:32728[D loss: 0.417589, acc: 66.41%, op_acc: 53.12%] [G loss: 1.156693]\n",
      "epoch:41 step:32729[D loss: 0.424581, acc: 64.06%, op_acc: 41.41%] [G loss: 1.181893]\n",
      "epoch:41 step:32730[D loss: 0.487856, acc: 53.91%, op_acc: 43.75%] [G loss: 1.383717]\n",
      "epoch:41 step:32731[D loss: 0.373969, acc: 73.44%, op_acc: 59.38%] [G loss: 1.475210]\n",
      "epoch:41 step:32732[D loss: 0.386359, acc: 65.62%, op_acc: 49.22%] [G loss: 1.645919]\n",
      "epoch:41 step:32733[D loss: 0.391053, acc: 63.28%, op_acc: 46.88%] [G loss: 1.513810]\n",
      "epoch:41 step:32734[D loss: 0.438992, acc: 54.69%, op_acc: 50.00%] [G loss: 1.324796]\n",
      "epoch:41 step:32735[D loss: 0.388701, acc: 68.75%, op_acc: 45.31%] [G loss: 1.243514]\n",
      "epoch:41 step:32736[D loss: 0.291292, acc: 85.94%, op_acc: 54.69%] [G loss: 1.209757]\n",
      "epoch:41 step:32737[D loss: 0.360568, acc: 68.75%, op_acc: 46.88%] [G loss: 0.947385]\n",
      "epoch:41 step:32738[D loss: 0.477609, acc: 60.94%, op_acc: 45.31%] [G loss: 1.292757]\n",
      "epoch:41 step:32739[D loss: 0.360565, acc: 72.66%, op_acc: 44.53%] [G loss: 1.026023]\n",
      "epoch:41 step:32740[D loss: 0.466245, acc: 57.81%, op_acc: 42.19%] [G loss: 1.157638]\n",
      "epoch:41 step:32741[D loss: 0.457168, acc: 58.59%, op_acc: 40.62%] [G loss: 1.188881]\n",
      "epoch:41 step:32742[D loss: 0.419244, acc: 63.28%, op_acc: 47.66%] [G loss: 1.494899]\n",
      "epoch:41 step:32743[D loss: 0.460864, acc: 56.25%, op_acc: 43.75%] [G loss: 1.264733]\n",
      "epoch:41 step:32744[D loss: 0.411870, acc: 63.28%, op_acc: 42.19%] [G loss: 1.309263]\n",
      "epoch:41 step:32745[D loss: 0.435997, acc: 62.50%, op_acc: 39.84%] [G loss: 1.538076]\n",
      "epoch:41 step:32746[D loss: 0.452368, acc: 66.41%, op_acc: 42.19%] [G loss: 1.293224]\n",
      "epoch:41 step:32747[D loss: 0.375975, acc: 67.19%, op_acc: 50.00%] [G loss: 1.221350]\n",
      "epoch:41 step:32748[D loss: 0.430470, acc: 62.50%, op_acc: 34.38%] [G loss: 1.369953]\n",
      "epoch:41 step:32749[D loss: 0.444149, acc: 65.62%, op_acc: 35.16%] [G loss: 1.308576]\n",
      "epoch:41 step:32750[D loss: 0.378808, acc: 66.41%, op_acc: 44.53%] [G loss: 1.325209]\n",
      "epoch:41 step:32751[D loss: 0.346791, acc: 75.00%, op_acc: 48.44%] [G loss: 1.251600]\n",
      "epoch:41 step:32752[D loss: 0.419662, acc: 63.28%, op_acc: 48.44%] [G loss: 1.377259]\n",
      "epoch:41 step:32753[D loss: 0.419183, acc: 60.94%, op_acc: 43.75%] [G loss: 1.243448]\n",
      "epoch:41 step:32754[D loss: 0.435154, acc: 56.25%, op_acc: 38.28%] [G loss: 1.365716]\n",
      "epoch:41 step:32755[D loss: 0.418912, acc: 62.50%, op_acc: 42.97%] [G loss: 1.223780]\n",
      "epoch:41 step:32756[D loss: 0.474916, acc: 59.38%, op_acc: 41.41%] [G loss: 1.254261]\n",
      "epoch:41 step:32757[D loss: 0.365156, acc: 69.53%, op_acc: 50.78%] [G loss: 1.459229]\n",
      "epoch:41 step:32758[D loss: 0.399723, acc: 64.84%, op_acc: 50.00%] [G loss: 1.176465]\n",
      "epoch:41 step:32759[D loss: 0.341766, acc: 70.31%, op_acc: 52.34%] [G loss: 1.355652]\n",
      "epoch:41 step:32760[D loss: 0.380813, acc: 67.97%, op_acc: 44.53%] [G loss: 1.423961]\n",
      "epoch:41 step:32761[D loss: 0.379671, acc: 68.75%, op_acc: 53.12%] [G loss: 1.580353]\n",
      "epoch:41 step:32762[D loss: 0.292955, acc: 80.47%, op_acc: 57.81%] [G loss: 1.205748]\n",
      "epoch:41 step:32763[D loss: 0.434249, acc: 64.06%, op_acc: 40.62%] [G loss: 0.968294]\n",
      "epoch:41 step:32764[D loss: 0.410016, acc: 64.06%, op_acc: 43.75%] [G loss: 1.246604]\n",
      "epoch:41 step:32765[D loss: 0.332235, acc: 71.88%, op_acc: 53.12%] [G loss: 1.051665]\n",
      "epoch:41 step:32766[D loss: 0.436813, acc: 64.84%, op_acc: 43.75%] [G loss: 1.266047]\n",
      "epoch:41 step:32767[D loss: 0.449621, acc: 57.03%, op_acc: 45.31%] [G loss: 1.420809]\n",
      "epoch:41 step:32768[D loss: 0.377847, acc: 67.19%, op_acc: 52.34%] [G loss: 1.553423]\n",
      "epoch:41 step:32769[D loss: 0.431178, acc: 59.38%, op_acc: 49.22%] [G loss: 1.231132]\n",
      "epoch:41 step:32770[D loss: 0.337340, acc: 78.12%, op_acc: 45.31%] [G loss: 1.261699]\n",
      "epoch:41 step:32771[D loss: 0.393986, acc: 67.19%, op_acc: 46.09%] [G loss: 1.152703]\n",
      "epoch:41 step:32772[D loss: 0.400453, acc: 61.72%, op_acc: 46.88%] [G loss: 1.154243]\n",
      "epoch:41 step:32773[D loss: 0.346408, acc: 71.09%, op_acc: 49.22%] [G loss: 1.109176]\n",
      "epoch:41 step:32774[D loss: 0.407975, acc: 56.25%, op_acc: 46.09%] [G loss: 0.958766]\n",
      "epoch:41 step:32775[D loss: 0.318845, acc: 78.91%, op_acc: 49.22%] [G loss: 1.202411]\n",
      "epoch:41 step:32776[D loss: 0.419192, acc: 64.84%, op_acc: 38.28%] [G loss: 1.276261]\n",
      "epoch:41 step:32777[D loss: 0.403284, acc: 66.41%, op_acc: 44.53%] [G loss: 1.308324]\n",
      "epoch:41 step:32778[D loss: 0.380950, acc: 67.97%, op_acc: 42.19%] [G loss: 1.277840]\n",
      "epoch:41 step:32779[D loss: 0.399022, acc: 59.38%, op_acc: 55.47%] [G loss: 1.342779]\n",
      "epoch:41 step:32780[D loss: 0.412812, acc: 61.72%, op_acc: 43.75%] [G loss: 1.641683]\n",
      "epoch:41 step:32781[D loss: 0.397560, acc: 64.84%, op_acc: 45.31%] [G loss: 1.383893]\n",
      "epoch:41 step:32782[D loss: 0.346642, acc: 76.56%, op_acc: 48.44%] [G loss: 1.234502]\n",
      "epoch:41 step:32783[D loss: 0.461907, acc: 56.25%, op_acc: 47.66%] [G loss: 1.371295]\n",
      "epoch:41 step:32784[D loss: 0.442765, acc: 62.50%, op_acc: 39.06%] [G loss: 1.147848]\n",
      "epoch:41 step:32785[D loss: 0.401001, acc: 64.84%, op_acc: 46.88%] [G loss: 1.331861]\n",
      "epoch:41 step:32786[D loss: 0.347879, acc: 75.78%, op_acc: 46.09%] [G loss: 1.097592]\n",
      "epoch:41 step:32787[D loss: 0.394699, acc: 71.09%, op_acc: 46.09%] [G loss: 1.273966]\n",
      "epoch:41 step:32788[D loss: 0.367316, acc: 71.09%, op_acc: 45.31%] [G loss: 1.119969]\n",
      "epoch:41 step:32789[D loss: 0.330883, acc: 77.34%, op_acc: 46.09%] [G loss: 1.410478]\n",
      "epoch:41 step:32790[D loss: 0.407131, acc: 60.16%, op_acc: 43.75%] [G loss: 1.344622]\n",
      "epoch:41 step:32791[D loss: 0.369415, acc: 69.53%, op_acc: 52.34%] [G loss: 1.315489]\n",
      "epoch:41 step:32792[D loss: 0.408033, acc: 71.88%, op_acc: 42.97%] [G loss: 1.241668]\n",
      "epoch:41 step:32793[D loss: 0.419552, acc: 60.94%, op_acc: 40.62%] [G loss: 1.289848]\n",
      "epoch:41 step:32794[D loss: 0.364018, acc: 73.44%, op_acc: 42.97%] [G loss: 1.287369]\n",
      "epoch:41 step:32795[D loss: 0.374700, acc: 69.53%, op_acc: 50.00%] [G loss: 1.287228]\n",
      "epoch:41 step:32796[D loss: 0.371414, acc: 71.09%, op_acc: 42.97%] [G loss: 1.419694]\n",
      "epoch:41 step:32797[D loss: 0.455703, acc: 61.72%, op_acc: 39.06%] [G loss: 1.194607]\n",
      "epoch:41 step:32798[D loss: 0.486447, acc: 57.03%, op_acc: 42.97%] [G loss: 1.160544]\n",
      "epoch:41 step:32799[D loss: 0.378168, acc: 67.19%, op_acc: 50.78%] [G loss: 1.230207]\n",
      "epoch:41 step:32800[D loss: 0.432792, acc: 61.72%, op_acc: 42.19%] [G loss: 0.997643]\n",
      "epoch:41 step:32801[D loss: 0.365976, acc: 67.19%, op_acc: 53.12%] [G loss: 1.053442]\n",
      "epoch:41 step:32802[D loss: 0.451506, acc: 57.81%, op_acc: 42.97%] [G loss: 1.193676]\n",
      "epoch:42 step:32803[D loss: 0.354995, acc: 69.53%, op_acc: 54.69%] [G loss: 1.354420]\n",
      "epoch:42 step:32804[D loss: 0.368814, acc: 66.41%, op_acc: 47.66%] [G loss: 1.483618]\n",
      "epoch:42 step:32805[D loss: 0.378733, acc: 67.19%, op_acc: 43.75%] [G loss: 1.308576]\n",
      "epoch:42 step:32806[D loss: 0.318540, acc: 71.88%, op_acc: 50.78%] [G loss: 1.613008]\n",
      "epoch:42 step:32807[D loss: 0.386847, acc: 69.53%, op_acc: 53.12%] [G loss: 1.381317]\n",
      "epoch:42 step:32808[D loss: 0.394126, acc: 69.53%, op_acc: 45.31%] [G loss: 1.352801]\n",
      "epoch:42 step:32809[D loss: 0.330872, acc: 71.88%, op_acc: 50.00%] [G loss: 1.295937]\n",
      "epoch:42 step:32810[D loss: 0.370126, acc: 69.53%, op_acc: 52.34%] [G loss: 1.423711]\n",
      "epoch:42 step:32811[D loss: 0.397189, acc: 65.62%, op_acc: 48.44%] [G loss: 1.297152]\n",
      "epoch:42 step:32812[D loss: 0.382188, acc: 66.41%, op_acc: 46.88%] [G loss: 1.180779]\n",
      "epoch:42 step:32813[D loss: 0.336140, acc: 78.91%, op_acc: 49.22%] [G loss: 1.307059]\n",
      "epoch:42 step:32814[D loss: 0.326353, acc: 80.47%, op_acc: 37.50%] [G loss: 1.301689]\n",
      "epoch:42 step:32815[D loss: 0.360020, acc: 73.44%, op_acc: 41.41%] [G loss: 1.685948]\n",
      "epoch:42 step:32816[D loss: 0.471121, acc: 54.69%, op_acc: 39.06%] [G loss: 1.231319]\n",
      "epoch:42 step:32817[D loss: 0.438462, acc: 61.72%, op_acc: 39.06%] [G loss: 1.272643]\n",
      "epoch:42 step:32818[D loss: 0.373527, acc: 72.66%, op_acc: 41.41%] [G loss: 1.371308]\n",
      "epoch:42 step:32819[D loss: 0.426982, acc: 59.38%, op_acc: 46.88%] [G loss: 1.323710]\n",
      "epoch:42 step:32820[D loss: 0.390384, acc: 64.06%, op_acc: 45.31%] [G loss: 1.347100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32821[D loss: 0.359093, acc: 64.84%, op_acc: 50.78%] [G loss: 1.132321]\n",
      "epoch:42 step:32822[D loss: 0.380703, acc: 68.75%, op_acc: 42.97%] [G loss: 0.963396]\n",
      "epoch:42 step:32823[D loss: 0.429251, acc: 62.50%, op_acc: 42.97%] [G loss: 1.093690]\n",
      "epoch:42 step:32824[D loss: 0.389358, acc: 64.06%, op_acc: 48.44%] [G loss: 1.277036]\n",
      "epoch:42 step:32825[D loss: 0.401990, acc: 62.50%, op_acc: 47.66%] [G loss: 1.320806]\n",
      "epoch:42 step:32826[D loss: 0.416570, acc: 66.41%, op_acc: 44.53%] [G loss: 1.164017]\n",
      "epoch:42 step:32827[D loss: 0.492835, acc: 59.38%, op_acc: 44.53%] [G loss: 1.281981]\n",
      "epoch:42 step:32828[D loss: 0.372590, acc: 71.88%, op_acc: 44.53%] [G loss: 1.224600]\n",
      "epoch:42 step:32829[D loss: 0.392139, acc: 71.09%, op_acc: 41.41%] [G loss: 1.245005]\n",
      "epoch:42 step:32830[D loss: 0.438448, acc: 59.38%, op_acc: 46.88%] [G loss: 1.338931]\n",
      "epoch:42 step:32831[D loss: 0.364354, acc: 72.66%, op_acc: 50.78%] [G loss: 1.500290]\n",
      "epoch:42 step:32832[D loss: 0.372493, acc: 69.53%, op_acc: 48.44%] [G loss: 1.466457]\n",
      "epoch:42 step:32833[D loss: 0.400249, acc: 63.28%, op_acc: 40.62%] [G loss: 1.208107]\n",
      "epoch:42 step:32834[D loss: 0.447149, acc: 60.94%, op_acc: 48.44%] [G loss: 1.129712]\n",
      "epoch:42 step:32835[D loss: 0.344310, acc: 76.56%, op_acc: 47.66%] [G loss: 1.132924]\n",
      "epoch:42 step:32836[D loss: 0.349266, acc: 71.88%, op_acc: 48.44%] [G loss: 1.324414]\n",
      "epoch:42 step:32837[D loss: 0.357164, acc: 71.88%, op_acc: 41.41%] [G loss: 1.123948]\n",
      "epoch:42 step:32838[D loss: 0.384533, acc: 64.84%, op_acc: 46.88%] [G loss: 1.131333]\n",
      "epoch:42 step:32839[D loss: 0.363935, acc: 75.00%, op_acc: 46.09%] [G loss: 1.332279]\n",
      "epoch:42 step:32840[D loss: 0.444520, acc: 59.38%, op_acc: 42.19%] [G loss: 1.360672]\n",
      "epoch:42 step:32841[D loss: 0.358190, acc: 71.88%, op_acc: 42.97%] [G loss: 1.207457]\n",
      "epoch:42 step:32842[D loss: 0.382346, acc: 67.97%, op_acc: 46.88%] [G loss: 1.123252]\n",
      "epoch:42 step:32843[D loss: 0.360677, acc: 71.88%, op_acc: 49.22%] [G loss: 1.280838]\n",
      "epoch:42 step:32844[D loss: 0.354386, acc: 68.75%, op_acc: 50.00%] [G loss: 1.451331]\n",
      "epoch:42 step:32845[D loss: 0.500065, acc: 55.47%, op_acc: 32.03%] [G loss: 0.961527]\n",
      "epoch:42 step:32846[D loss: 0.410881, acc: 58.59%, op_acc: 47.66%] [G loss: 1.428983]\n",
      "epoch:42 step:32847[D loss: 0.377265, acc: 71.88%, op_acc: 42.19%] [G loss: 1.544785]\n",
      "epoch:42 step:32848[D loss: 0.390839, acc: 67.19%, op_acc: 48.44%] [G loss: 1.291581]\n",
      "epoch:42 step:32849[D loss: 0.467689, acc: 60.16%, op_acc: 35.16%] [G loss: 1.190014]\n",
      "epoch:42 step:32850[D loss: 0.403860, acc: 69.53%, op_acc: 39.06%] [G loss: 1.425645]\n",
      "epoch:42 step:32851[D loss: 0.353894, acc: 76.56%, op_acc: 48.44%] [G loss: 1.226157]\n",
      "epoch:42 step:32852[D loss: 0.343669, acc: 75.78%, op_acc: 44.53%] [G loss: 1.568042]\n",
      "epoch:42 step:32853[D loss: 0.335270, acc: 77.34%, op_acc: 43.75%] [G loss: 1.139749]\n",
      "epoch:42 step:32854[D loss: 0.368454, acc: 74.22%, op_acc: 39.06%] [G loss: 1.323767]\n",
      "epoch:42 step:32855[D loss: 0.478237, acc: 51.56%, op_acc: 35.16%] [G loss: 1.452226]\n",
      "epoch:42 step:32856[D loss: 0.417382, acc: 65.62%, op_acc: 46.09%] [G loss: 1.158133]\n",
      "epoch:42 step:32857[D loss: 0.410784, acc: 66.41%, op_acc: 47.66%] [G loss: 1.399526]\n",
      "epoch:42 step:32858[D loss: 0.369934, acc: 68.75%, op_acc: 41.41%] [G loss: 1.494911]\n",
      "epoch:42 step:32859[D loss: 0.403763, acc: 63.28%, op_acc: 47.66%] [G loss: 1.434968]\n",
      "epoch:42 step:32860[D loss: 0.361924, acc: 71.09%, op_acc: 49.22%] [G loss: 1.148493]\n",
      "epoch:42 step:32861[D loss: 0.411433, acc: 60.94%, op_acc: 45.31%] [G loss: 1.037781]\n",
      "epoch:42 step:32862[D loss: 0.356095, acc: 72.66%, op_acc: 42.97%] [G loss: 1.240346]\n",
      "epoch:42 step:32863[D loss: 0.420000, acc: 67.19%, op_acc: 42.97%] [G loss: 1.506596]\n",
      "epoch:42 step:32864[D loss: 0.375184, acc: 70.31%, op_acc: 51.56%] [G loss: 1.599135]\n",
      "epoch:42 step:32865[D loss: 0.420179, acc: 66.41%, op_acc: 48.44%] [G loss: 1.313827]\n",
      "epoch:42 step:32866[D loss: 0.448529, acc: 60.16%, op_acc: 46.88%] [G loss: 1.033718]\n",
      "epoch:42 step:32867[D loss: 0.450281, acc: 54.69%, op_acc: 45.31%] [G loss: 1.302197]\n",
      "epoch:42 step:32868[D loss: 0.372125, acc: 70.31%, op_acc: 41.41%] [G loss: 1.109737]\n",
      "epoch:42 step:32869[D loss: 0.328659, acc: 74.22%, op_acc: 47.66%] [G loss: 1.306640]\n",
      "epoch:42 step:32870[D loss: 0.347053, acc: 74.22%, op_acc: 46.88%] [G loss: 1.512611]\n",
      "epoch:42 step:32871[D loss: 0.326281, acc: 75.00%, op_acc: 52.34%] [G loss: 1.234591]\n",
      "epoch:42 step:32872[D loss: 0.435117, acc: 56.25%, op_acc: 42.97%] [G loss: 1.191060]\n",
      "epoch:42 step:32873[D loss: 0.402761, acc: 66.41%, op_acc: 39.06%] [G loss: 1.002218]\n",
      "epoch:42 step:32874[D loss: 0.346670, acc: 76.56%, op_acc: 51.56%] [G loss: 1.251755]\n",
      "epoch:42 step:32875[D loss: 0.415424, acc: 67.19%, op_acc: 46.09%] [G loss: 1.139942]\n",
      "epoch:42 step:32876[D loss: 0.386894, acc: 60.16%, op_acc: 48.44%] [G loss: 1.332181]\n",
      "epoch:42 step:32877[D loss: 0.388791, acc: 68.75%, op_acc: 42.97%] [G loss: 1.127809]\n",
      "epoch:42 step:32878[D loss: 0.367753, acc: 71.88%, op_acc: 51.56%] [G loss: 1.511344]\n",
      "epoch:42 step:32879[D loss: 0.419307, acc: 62.50%, op_acc: 42.19%] [G loss: 1.422880]\n",
      "epoch:42 step:32880[D loss: 0.332667, acc: 75.78%, op_acc: 48.44%] [G loss: 1.456811]\n",
      "epoch:42 step:32881[D loss: 0.454632, acc: 56.25%, op_acc: 46.88%] [G loss: 1.382943]\n",
      "epoch:42 step:32882[D loss: 0.447547, acc: 59.38%, op_acc: 31.25%] [G loss: 1.170595]\n",
      "epoch:42 step:32883[D loss: 0.423056, acc: 62.50%, op_acc: 42.97%] [G loss: 1.318947]\n",
      "epoch:42 step:32884[D loss: 0.376929, acc: 67.19%, op_acc: 44.53%] [G loss: 1.010432]\n",
      "epoch:42 step:32885[D loss: 0.298657, acc: 82.03%, op_acc: 49.22%] [G loss: 1.245898]\n",
      "epoch:42 step:32886[D loss: 0.393882, acc: 70.31%, op_acc: 43.75%] [G loss: 1.158538]\n",
      "epoch:42 step:32887[D loss: 0.402978, acc: 74.22%, op_acc: 33.59%] [G loss: 1.260665]\n",
      "epoch:42 step:32888[D loss: 0.361848, acc: 77.34%, op_acc: 44.53%] [G loss: 1.190270]\n",
      "epoch:42 step:32889[D loss: 0.415204, acc: 65.62%, op_acc: 40.62%] [G loss: 1.409761]\n",
      "epoch:42 step:32890[D loss: 0.375742, acc: 71.88%, op_acc: 45.31%] [G loss: 1.227943]\n",
      "epoch:42 step:32891[D loss: 0.394510, acc: 64.84%, op_acc: 40.62%] [G loss: 1.265203]\n",
      "epoch:42 step:32892[D loss: 0.355356, acc: 69.53%, op_acc: 47.66%] [G loss: 1.203695]\n",
      "epoch:42 step:32893[D loss: 0.335968, acc: 68.75%, op_acc: 56.25%] [G loss: 1.307927]\n",
      "epoch:42 step:32894[D loss: 0.423725, acc: 57.81%, op_acc: 39.06%] [G loss: 0.964579]\n",
      "epoch:42 step:32895[D loss: 0.370481, acc: 65.62%, op_acc: 47.66%] [G loss: 1.269499]\n",
      "epoch:42 step:32896[D loss: 0.331015, acc: 74.22%, op_acc: 50.00%] [G loss: 1.299602]\n",
      "epoch:42 step:32897[D loss: 0.465826, acc: 58.59%, op_acc: 40.62%] [G loss: 1.279460]\n",
      "epoch:42 step:32898[D loss: 0.313598, acc: 78.12%, op_acc: 38.28%] [G loss: 1.128576]\n",
      "epoch:42 step:32899[D loss: 0.376477, acc: 71.88%, op_acc: 48.44%] [G loss: 1.350795]\n",
      "epoch:42 step:32900[D loss: 0.370155, acc: 71.09%, op_acc: 50.78%] [G loss: 1.194576]\n",
      "epoch:42 step:32901[D loss: 0.344794, acc: 74.22%, op_acc: 46.09%] [G loss: 1.138626]\n",
      "epoch:42 step:32902[D loss: 0.339737, acc: 75.00%, op_acc: 42.19%] [G loss: 1.087388]\n",
      "epoch:42 step:32903[D loss: 0.396876, acc: 71.09%, op_acc: 43.75%] [G loss: 1.274607]\n",
      "epoch:42 step:32904[D loss: 0.417835, acc: 61.72%, op_acc: 40.62%] [G loss: 1.045159]\n",
      "epoch:42 step:32905[D loss: 0.414960, acc: 67.19%, op_acc: 47.66%] [G loss: 0.912681]\n",
      "epoch:42 step:32906[D loss: 0.356963, acc: 69.53%, op_acc: 46.88%] [G loss: 1.271632]\n",
      "epoch:42 step:32907[D loss: 0.385629, acc: 64.06%, op_acc: 45.31%] [G loss: 1.181673]\n",
      "epoch:42 step:32908[D loss: 0.403758, acc: 60.94%, op_acc: 45.31%] [G loss: 1.350866]\n",
      "epoch:42 step:32909[D loss: 0.327190, acc: 75.78%, op_acc: 53.12%] [G loss: 1.338377]\n",
      "epoch:42 step:32910[D loss: 0.450559, acc: 58.59%, op_acc: 41.41%] [G loss: 1.360092]\n",
      "epoch:42 step:32911[D loss: 0.404630, acc: 58.59%, op_acc: 49.22%] [G loss: 1.160686]\n",
      "epoch:42 step:32912[D loss: 0.339274, acc: 74.22%, op_acc: 46.88%] [G loss: 1.422605]\n",
      "epoch:42 step:32913[D loss: 0.435665, acc: 61.72%, op_acc: 44.53%] [G loss: 1.111435]\n",
      "epoch:42 step:32914[D loss: 0.413337, acc: 61.72%, op_acc: 46.09%] [G loss: 1.137817]\n",
      "epoch:42 step:32915[D loss: 0.401530, acc: 67.19%, op_acc: 35.94%] [G loss: 1.297422]\n",
      "epoch:42 step:32916[D loss: 0.391330, acc: 64.84%, op_acc: 47.66%] [G loss: 1.104294]\n",
      "epoch:42 step:32917[D loss: 0.380645, acc: 64.84%, op_acc: 48.44%] [G loss: 1.206066]\n",
      "epoch:42 step:32918[D loss: 0.374507, acc: 74.22%, op_acc: 45.31%] [G loss: 1.396984]\n",
      "epoch:42 step:32919[D loss: 0.395787, acc: 64.06%, op_acc: 52.34%] [G loss: 1.285360]\n",
      "epoch:42 step:32920[D loss: 0.411300, acc: 62.50%, op_acc: 46.88%] [G loss: 1.407223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:32921[D loss: 0.354259, acc: 72.66%, op_acc: 45.31%] [G loss: 1.110248]\n",
      "epoch:42 step:32922[D loss: 0.466547, acc: 53.91%, op_acc: 39.84%] [G loss: 1.012607]\n",
      "epoch:42 step:32923[D loss: 0.339973, acc: 74.22%, op_acc: 46.09%] [G loss: 1.215408]\n",
      "epoch:42 step:32924[D loss: 0.428067, acc: 63.28%, op_acc: 48.44%] [G loss: 1.185158]\n",
      "epoch:42 step:32925[D loss: 0.335002, acc: 78.12%, op_acc: 53.91%] [G loss: 1.322177]\n",
      "epoch:42 step:32926[D loss: 0.506047, acc: 54.69%, op_acc: 37.50%] [G loss: 0.956650]\n",
      "epoch:42 step:32927[D loss: 0.444639, acc: 56.25%, op_acc: 43.75%] [G loss: 1.063642]\n",
      "epoch:42 step:32928[D loss: 0.366439, acc: 73.44%, op_acc: 48.44%] [G loss: 1.236910]\n",
      "epoch:42 step:32929[D loss: 0.361992, acc: 71.88%, op_acc: 41.41%] [G loss: 1.296612]\n",
      "epoch:42 step:32930[D loss: 0.358063, acc: 70.31%, op_acc: 39.84%] [G loss: 1.315863]\n",
      "epoch:42 step:32931[D loss: 0.406349, acc: 64.84%, op_acc: 42.97%] [G loss: 1.260629]\n",
      "epoch:42 step:32932[D loss: 0.344064, acc: 68.75%, op_acc: 44.53%] [G loss: 1.140125]\n",
      "epoch:42 step:32933[D loss: 0.334055, acc: 76.56%, op_acc: 42.19%] [G loss: 1.126969]\n",
      "epoch:42 step:32934[D loss: 0.312231, acc: 76.56%, op_acc: 50.00%] [G loss: 1.332452]\n",
      "epoch:42 step:32935[D loss: 0.398379, acc: 71.88%, op_acc: 48.44%] [G loss: 1.033052]\n",
      "epoch:42 step:32936[D loss: 0.394745, acc: 73.44%, op_acc: 53.12%] [G loss: 1.457699]\n",
      "epoch:42 step:32937[D loss: 0.420777, acc: 64.06%, op_acc: 50.00%] [G loss: 1.262192]\n",
      "epoch:42 step:32938[D loss: 0.372745, acc: 70.31%, op_acc: 44.53%] [G loss: 1.145908]\n",
      "epoch:42 step:32939[D loss: 0.386047, acc: 66.41%, op_acc: 44.53%] [G loss: 1.122293]\n",
      "epoch:42 step:32940[D loss: 0.391445, acc: 67.19%, op_acc: 43.75%] [G loss: 1.281654]\n",
      "epoch:42 step:32941[D loss: 0.384855, acc: 71.09%, op_acc: 40.62%] [G loss: 1.233094]\n",
      "epoch:42 step:32942[D loss: 0.477729, acc: 54.69%, op_acc: 42.97%] [G loss: 1.320548]\n",
      "epoch:42 step:32943[D loss: 0.431758, acc: 61.72%, op_acc: 36.72%] [G loss: 1.401099]\n",
      "epoch:42 step:32944[D loss: 0.399269, acc: 67.97%, op_acc: 44.53%] [G loss: 1.157142]\n",
      "epoch:42 step:32945[D loss: 0.363782, acc: 71.88%, op_acc: 44.53%] [G loss: 1.215503]\n",
      "epoch:42 step:32946[D loss: 0.391177, acc: 67.19%, op_acc: 50.00%] [G loss: 1.237027]\n",
      "epoch:42 step:32947[D loss: 0.332209, acc: 77.34%, op_acc: 48.44%] [G loss: 1.220641]\n",
      "epoch:42 step:32948[D loss: 0.357509, acc: 73.44%, op_acc: 45.31%] [G loss: 1.151054]\n",
      "epoch:42 step:32949[D loss: 0.393976, acc: 61.72%, op_acc: 43.75%] [G loss: 1.334739]\n",
      "epoch:42 step:32950[D loss: 0.388324, acc: 69.53%, op_acc: 47.66%] [G loss: 1.286526]\n",
      "epoch:42 step:32951[D loss: 0.368442, acc: 68.75%, op_acc: 50.00%] [G loss: 1.195956]\n",
      "epoch:42 step:32952[D loss: 0.368646, acc: 69.53%, op_acc: 49.22%] [G loss: 1.041286]\n",
      "epoch:42 step:32953[D loss: 0.365085, acc: 71.09%, op_acc: 44.53%] [G loss: 1.420608]\n",
      "epoch:42 step:32954[D loss: 0.402368, acc: 65.62%, op_acc: 50.00%] [G loss: 1.301548]\n",
      "epoch:42 step:32955[D loss: 0.501919, acc: 50.78%, op_acc: 39.06%] [G loss: 1.321755]\n",
      "epoch:42 step:32956[D loss: 0.412580, acc: 64.84%, op_acc: 45.31%] [G loss: 1.365536]\n",
      "epoch:42 step:32957[D loss: 0.335878, acc: 78.91%, op_acc: 46.88%] [G loss: 1.443126]\n",
      "epoch:42 step:32958[D loss: 0.356385, acc: 68.75%, op_acc: 46.88%] [G loss: 1.355291]\n",
      "epoch:42 step:32959[D loss: 0.392503, acc: 62.50%, op_acc: 42.97%] [G loss: 1.298174]\n",
      "epoch:42 step:32960[D loss: 0.342074, acc: 73.44%, op_acc: 50.00%] [G loss: 1.426778]\n",
      "epoch:42 step:32961[D loss: 0.399321, acc: 71.88%, op_acc: 41.41%] [G loss: 1.377818]\n",
      "epoch:42 step:32962[D loss: 0.409463, acc: 65.62%, op_acc: 45.31%] [G loss: 1.164528]\n",
      "epoch:42 step:32963[D loss: 0.390720, acc: 71.88%, op_acc: 41.41%] [G loss: 1.179178]\n",
      "epoch:42 step:32964[D loss: 0.446512, acc: 52.34%, op_acc: 48.44%] [G loss: 1.330291]\n",
      "epoch:42 step:32965[D loss: 0.360632, acc: 74.22%, op_acc: 42.97%] [G loss: 0.865071]\n",
      "epoch:42 step:32966[D loss: 0.360017, acc: 71.88%, op_acc: 39.06%] [G loss: 1.239054]\n",
      "epoch:42 step:32967[D loss: 0.354491, acc: 73.44%, op_acc: 42.97%] [G loss: 1.052377]\n",
      "epoch:42 step:32968[D loss: 0.430513, acc: 64.06%, op_acc: 45.31%] [G loss: 1.195117]\n",
      "epoch:42 step:32969[D loss: 0.411901, acc: 60.94%, op_acc: 47.66%] [G loss: 1.214477]\n",
      "epoch:42 step:32970[D loss: 0.397160, acc: 60.16%, op_acc: 42.19%] [G loss: 1.289585]\n",
      "epoch:42 step:32971[D loss: 0.402745, acc: 64.84%, op_acc: 42.97%] [G loss: 1.037696]\n",
      "epoch:42 step:32972[D loss: 0.394434, acc: 67.97%, op_acc: 39.84%] [G loss: 1.132610]\n",
      "epoch:42 step:32973[D loss: 0.408000, acc: 67.97%, op_acc: 44.53%] [G loss: 1.116483]\n",
      "epoch:42 step:32974[D loss: 0.368918, acc: 70.31%, op_acc: 39.06%] [G loss: 1.090258]\n",
      "epoch:42 step:32975[D loss: 0.405686, acc: 60.16%, op_acc: 42.97%] [G loss: 0.965813]\n",
      "epoch:42 step:32976[D loss: 0.434161, acc: 65.62%, op_acc: 39.06%] [G loss: 1.064947]\n",
      "epoch:42 step:32977[D loss: 0.353439, acc: 73.44%, op_acc: 42.19%] [G loss: 1.294375]\n",
      "epoch:42 step:32978[D loss: 0.390572, acc: 69.53%, op_acc: 48.44%] [G loss: 1.206657]\n",
      "epoch:42 step:32979[D loss: 0.358889, acc: 70.31%, op_acc: 46.88%] [G loss: 1.287653]\n",
      "epoch:42 step:32980[D loss: 0.422228, acc: 61.72%, op_acc: 42.19%] [G loss: 1.279332]\n",
      "epoch:42 step:32981[D loss: 0.327768, acc: 78.12%, op_acc: 47.66%] [G loss: 1.160806]\n",
      "epoch:42 step:32982[D loss: 0.389875, acc: 70.31%, op_acc: 43.75%] [G loss: 1.187300]\n",
      "epoch:42 step:32983[D loss: 0.335601, acc: 78.12%, op_acc: 50.78%] [G loss: 1.197178]\n",
      "epoch:42 step:32984[D loss: 0.371032, acc: 66.41%, op_acc: 44.53%] [G loss: 1.126863]\n",
      "epoch:42 step:32985[D loss: 0.323663, acc: 80.47%, op_acc: 52.34%] [G loss: 1.360370]\n",
      "epoch:42 step:32986[D loss: 0.388451, acc: 68.75%, op_acc: 50.78%] [G loss: 1.373100]\n",
      "epoch:42 step:32987[D loss: 0.349269, acc: 79.69%, op_acc: 46.09%] [G loss: 1.476761]\n",
      "epoch:42 step:32988[D loss: 0.428758, acc: 63.28%, op_acc: 43.75%] [G loss: 1.262399]\n",
      "epoch:42 step:32989[D loss: 0.372933, acc: 70.31%, op_acc: 47.66%] [G loss: 1.248841]\n",
      "epoch:42 step:32990[D loss: 0.374320, acc: 67.19%, op_acc: 46.88%] [G loss: 1.299845]\n",
      "epoch:42 step:32991[D loss: 0.276940, acc: 86.72%, op_acc: 52.34%] [G loss: 1.457984]\n",
      "epoch:42 step:32992[D loss: 0.426621, acc: 63.28%, op_acc: 42.97%] [G loss: 1.326207]\n",
      "epoch:42 step:32993[D loss: 0.398117, acc: 61.72%, op_acc: 43.75%] [G loss: 1.362564]\n",
      "epoch:42 step:32994[D loss: 0.407202, acc: 69.53%, op_acc: 44.53%] [G loss: 1.366995]\n",
      "epoch:42 step:32995[D loss: 0.351492, acc: 75.00%, op_acc: 42.97%] [G loss: 1.225258]\n",
      "epoch:42 step:32996[D loss: 0.335192, acc: 78.91%, op_acc: 52.34%] [G loss: 1.282214]\n",
      "epoch:42 step:32997[D loss: 0.414516, acc: 62.50%, op_acc: 46.09%] [G loss: 1.206530]\n",
      "epoch:42 step:32998[D loss: 0.324659, acc: 78.12%, op_acc: 46.88%] [G loss: 1.270553]\n",
      "epoch:42 step:32999[D loss: 0.415750, acc: 67.97%, op_acc: 46.09%] [G loss: 1.202156]\n",
      "epoch:42 step:33000[D loss: 0.439197, acc: 60.16%, op_acc: 46.09%] [G loss: 1.214354]\n",
      "epoch:42 step:33001[D loss: 0.370813, acc: 69.53%, op_acc: 51.56%] [G loss: 1.240731]\n",
      "epoch:42 step:33002[D loss: 0.384020, acc: 62.50%, op_acc: 48.44%] [G loss: 1.433756]\n",
      "epoch:42 step:33003[D loss: 0.376353, acc: 60.94%, op_acc: 53.12%] [G loss: 1.349572]\n",
      "epoch:42 step:33004[D loss: 0.417180, acc: 68.75%, op_acc: 43.75%] [G loss: 1.288486]\n",
      "epoch:42 step:33005[D loss: 0.420896, acc: 64.84%, op_acc: 43.75%] [G loss: 1.019649]\n",
      "epoch:42 step:33006[D loss: 0.429140, acc: 60.94%, op_acc: 42.19%] [G loss: 1.228693]\n",
      "epoch:42 step:33007[D loss: 0.473641, acc: 59.38%, op_acc: 46.09%] [G loss: 1.175429]\n",
      "epoch:42 step:33008[D loss: 0.482654, acc: 52.34%, op_acc: 39.84%] [G loss: 1.070511]\n",
      "epoch:42 step:33009[D loss: 0.387926, acc: 64.84%, op_acc: 43.75%] [G loss: 1.240599]\n",
      "epoch:42 step:33010[D loss: 0.354063, acc: 77.34%, op_acc: 48.44%] [G loss: 1.307210]\n",
      "epoch:42 step:33011[D loss: 0.392182, acc: 69.53%, op_acc: 46.88%] [G loss: 1.254082]\n",
      "epoch:42 step:33012[D loss: 0.436375, acc: 66.41%, op_acc: 39.84%] [G loss: 1.318629]\n",
      "epoch:42 step:33013[D loss: 0.370407, acc: 67.97%, op_acc: 49.22%] [G loss: 1.214245]\n",
      "epoch:42 step:33014[D loss: 0.425725, acc: 59.38%, op_acc: 44.53%] [G loss: 1.326183]\n",
      "epoch:42 step:33015[D loss: 0.441071, acc: 53.91%, op_acc: 46.88%] [G loss: 1.261444]\n",
      "epoch:42 step:33016[D loss: 0.342865, acc: 76.56%, op_acc: 44.53%] [G loss: 1.294409]\n",
      "epoch:42 step:33017[D loss: 0.440883, acc: 58.59%, op_acc: 46.09%] [G loss: 1.332416]\n",
      "epoch:42 step:33018[D loss: 0.449312, acc: 61.72%, op_acc: 40.62%] [G loss: 1.253139]\n",
      "epoch:42 step:33019[D loss: 0.380023, acc: 67.97%, op_acc: 43.75%] [G loss: 1.340044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33020[D loss: 0.397095, acc: 68.75%, op_acc: 42.19%] [G loss: 1.042586]\n",
      "epoch:42 step:33021[D loss: 0.359490, acc: 69.53%, op_acc: 48.44%] [G loss: 1.254900]\n",
      "epoch:42 step:33022[D loss: 0.441906, acc: 59.38%, op_acc: 41.41%] [G loss: 1.178307]\n",
      "epoch:42 step:33023[D loss: 0.384155, acc: 68.75%, op_acc: 45.31%] [G loss: 1.261057]\n",
      "epoch:42 step:33024[D loss: 0.403253, acc: 64.84%, op_acc: 40.62%] [G loss: 1.138053]\n",
      "epoch:42 step:33025[D loss: 0.415262, acc: 66.41%, op_acc: 44.53%] [G loss: 1.509799]\n",
      "epoch:42 step:33026[D loss: 0.418553, acc: 62.50%, op_acc: 43.75%] [G loss: 1.448800]\n",
      "epoch:42 step:33027[D loss: 0.360625, acc: 71.88%, op_acc: 44.53%] [G loss: 1.394623]\n",
      "epoch:42 step:33028[D loss: 0.395065, acc: 69.53%, op_acc: 47.66%] [G loss: 1.224470]\n",
      "epoch:42 step:33029[D loss: 0.404189, acc: 65.62%, op_acc: 48.44%] [G loss: 1.289966]\n",
      "epoch:42 step:33030[D loss: 0.330220, acc: 72.66%, op_acc: 46.09%] [G loss: 1.268712]\n",
      "epoch:42 step:33031[D loss: 0.408897, acc: 60.94%, op_acc: 48.44%] [G loss: 1.277697]\n",
      "epoch:42 step:33032[D loss: 0.432955, acc: 66.41%, op_acc: 45.31%] [G loss: 1.154429]\n",
      "epoch:42 step:33033[D loss: 0.358379, acc: 72.66%, op_acc: 39.84%] [G loss: 1.090798]\n",
      "epoch:42 step:33034[D loss: 0.357305, acc: 72.66%, op_acc: 49.22%] [G loss: 1.292071]\n",
      "epoch:42 step:33035[D loss: 0.361768, acc: 69.53%, op_acc: 42.19%] [G loss: 1.240929]\n",
      "epoch:42 step:33036[D loss: 0.398432, acc: 67.97%, op_acc: 39.84%] [G loss: 1.510206]\n",
      "epoch:42 step:33037[D loss: 0.425475, acc: 58.59%, op_acc: 45.31%] [G loss: 1.302681]\n",
      "epoch:42 step:33038[D loss: 0.366622, acc: 71.09%, op_acc: 41.41%] [G loss: 1.316765]\n",
      "epoch:42 step:33039[D loss: 0.352741, acc: 75.00%, op_acc: 48.44%] [G loss: 1.533735]\n",
      "epoch:42 step:33040[D loss: 0.409763, acc: 61.72%, op_acc: 41.41%] [G loss: 1.338502]\n",
      "epoch:42 step:33041[D loss: 0.398039, acc: 63.28%, op_acc: 45.31%] [G loss: 1.160502]\n",
      "epoch:42 step:33042[D loss: 0.340320, acc: 75.78%, op_acc: 48.44%] [G loss: 1.367117]\n",
      "epoch:42 step:33043[D loss: 0.371874, acc: 69.53%, op_acc: 50.78%] [G loss: 1.368236]\n",
      "epoch:42 step:33044[D loss: 0.445384, acc: 64.84%, op_acc: 38.28%] [G loss: 1.164503]\n",
      "epoch:42 step:33045[D loss: 0.400765, acc: 63.28%, op_acc: 44.53%] [G loss: 1.043744]\n",
      "epoch:42 step:33046[D loss: 0.407956, acc: 58.59%, op_acc: 40.62%] [G loss: 1.184796]\n",
      "epoch:42 step:33047[D loss: 0.353477, acc: 69.53%, op_acc: 45.31%] [G loss: 1.392617]\n",
      "epoch:42 step:33048[D loss: 0.381959, acc: 71.88%, op_acc: 46.09%] [G loss: 1.320492]\n",
      "epoch:42 step:33049[D loss: 0.396788, acc: 66.41%, op_acc: 47.66%] [G loss: 1.100184]\n",
      "epoch:42 step:33050[D loss: 0.340279, acc: 75.78%, op_acc: 46.09%] [G loss: 1.300499]\n",
      "epoch:42 step:33051[D loss: 0.399210, acc: 69.53%, op_acc: 43.75%] [G loss: 1.272486]\n",
      "epoch:42 step:33052[D loss: 0.430412, acc: 62.50%, op_acc: 41.41%] [G loss: 1.139473]\n",
      "epoch:42 step:33053[D loss: 0.330375, acc: 71.88%, op_acc: 51.56%] [G loss: 1.185108]\n",
      "epoch:42 step:33054[D loss: 0.325815, acc: 71.09%, op_acc: 51.56%] [G loss: 1.360832]\n",
      "epoch:42 step:33055[D loss: 0.392548, acc: 67.19%, op_acc: 43.75%] [G loss: 1.275654]\n",
      "epoch:42 step:33056[D loss: 0.401887, acc: 67.97%, op_acc: 35.94%] [G loss: 1.286432]\n",
      "epoch:42 step:33057[D loss: 0.428507, acc: 58.59%, op_acc: 46.88%] [G loss: 1.123588]\n",
      "epoch:42 step:33058[D loss: 0.434033, acc: 60.94%, op_acc: 39.84%] [G loss: 1.314028]\n",
      "epoch:42 step:33059[D loss: 0.444404, acc: 58.59%, op_acc: 33.59%] [G loss: 1.121804]\n",
      "epoch:42 step:33060[D loss: 0.419909, acc: 67.97%, op_acc: 35.16%] [G loss: 1.178480]\n",
      "epoch:42 step:33061[D loss: 0.401390, acc: 68.75%, op_acc: 46.09%] [G loss: 1.265424]\n",
      "epoch:42 step:33062[D loss: 0.460205, acc: 57.03%, op_acc: 39.06%] [G loss: 1.033030]\n",
      "epoch:42 step:33063[D loss: 0.395252, acc: 65.62%, op_acc: 43.75%] [G loss: 1.182035]\n",
      "epoch:42 step:33064[D loss: 0.340311, acc: 71.09%, op_acc: 54.69%] [G loss: 1.350281]\n",
      "epoch:42 step:33065[D loss: 0.349729, acc: 76.56%, op_acc: 40.62%] [G loss: 1.281047]\n",
      "epoch:42 step:33066[D loss: 0.344956, acc: 73.44%, op_acc: 45.31%] [G loss: 1.304559]\n",
      "epoch:42 step:33067[D loss: 0.355042, acc: 76.56%, op_acc: 44.53%] [G loss: 1.063582]\n",
      "epoch:42 step:33068[D loss: 0.332506, acc: 79.69%, op_acc: 50.78%] [G loss: 1.263270]\n",
      "epoch:42 step:33069[D loss: 0.378708, acc: 72.66%, op_acc: 40.62%] [G loss: 1.268518]\n",
      "epoch:42 step:33070[D loss: 0.391161, acc: 64.84%, op_acc: 45.31%] [G loss: 1.171102]\n",
      "epoch:42 step:33071[D loss: 0.358124, acc: 70.31%, op_acc: 53.12%] [G loss: 1.270396]\n",
      "epoch:42 step:33072[D loss: 0.401100, acc: 64.84%, op_acc: 41.41%] [G loss: 0.923630]\n",
      "epoch:42 step:33073[D loss: 0.387500, acc: 67.19%, op_acc: 41.41%] [G loss: 1.042114]\n",
      "epoch:42 step:33074[D loss: 0.384499, acc: 63.28%, op_acc: 50.00%] [G loss: 1.276357]\n",
      "epoch:42 step:33075[D loss: 0.366387, acc: 70.31%, op_acc: 48.44%] [G loss: 1.403141]\n",
      "epoch:42 step:33076[D loss: 0.401774, acc: 62.50%, op_acc: 39.06%] [G loss: 1.118513]\n",
      "epoch:42 step:33077[D loss: 0.361912, acc: 75.78%, op_acc: 52.34%] [G loss: 1.391113]\n",
      "epoch:42 step:33078[D loss: 0.501484, acc: 53.91%, op_acc: 35.94%] [G loss: 1.198961]\n",
      "epoch:42 step:33079[D loss: 0.344727, acc: 76.56%, op_acc: 44.53%] [G loss: 1.378405]\n",
      "epoch:42 step:33080[D loss: 0.399576, acc: 64.06%, op_acc: 45.31%] [G loss: 1.123684]\n",
      "epoch:42 step:33081[D loss: 0.435220, acc: 65.62%, op_acc: 40.62%] [G loss: 1.124261]\n",
      "epoch:42 step:33082[D loss: 0.343662, acc: 72.66%, op_acc: 41.41%] [G loss: 1.239839]\n",
      "epoch:42 step:33083[D loss: 0.421219, acc: 59.38%, op_acc: 42.97%] [G loss: 1.349914]\n",
      "epoch:42 step:33084[D loss: 0.446156, acc: 60.94%, op_acc: 42.19%] [G loss: 1.071268]\n",
      "epoch:42 step:33085[D loss: 0.371382, acc: 71.09%, op_acc: 42.97%] [G loss: 1.159482]\n",
      "epoch:42 step:33086[D loss: 0.398827, acc: 72.66%, op_acc: 46.88%] [G loss: 1.211752]\n",
      "epoch:42 step:33087[D loss: 0.364941, acc: 71.09%, op_acc: 41.41%] [G loss: 1.449958]\n",
      "epoch:42 step:33088[D loss: 0.402657, acc: 69.53%, op_acc: 39.06%] [G loss: 1.073224]\n",
      "epoch:42 step:33089[D loss: 0.363683, acc: 75.00%, op_acc: 44.53%] [G loss: 1.195125]\n",
      "epoch:42 step:33090[D loss: 0.338992, acc: 71.09%, op_acc: 49.22%] [G loss: 1.047323]\n",
      "epoch:42 step:33091[D loss: 0.380536, acc: 67.97%, op_acc: 41.41%] [G loss: 1.200878]\n",
      "epoch:42 step:33092[D loss: 0.421481, acc: 60.16%, op_acc: 44.53%] [G loss: 1.504830]\n",
      "epoch:42 step:33093[D loss: 0.415823, acc: 62.50%, op_acc: 48.44%] [G loss: 1.244403]\n",
      "epoch:42 step:33094[D loss: 0.449840, acc: 59.38%, op_acc: 39.06%] [G loss: 1.115266]\n",
      "epoch:42 step:33095[D loss: 0.369211, acc: 68.75%, op_acc: 42.97%] [G loss: 1.153687]\n",
      "epoch:42 step:33096[D loss: 0.352745, acc: 73.44%, op_acc: 43.75%] [G loss: 1.418026]\n",
      "epoch:42 step:33097[D loss: 0.415826, acc: 63.28%, op_acc: 46.09%] [G loss: 1.215421]\n",
      "epoch:42 step:33098[D loss: 0.429964, acc: 57.81%, op_acc: 41.41%] [G loss: 1.357047]\n",
      "epoch:42 step:33099[D loss: 0.356501, acc: 74.22%, op_acc: 42.97%] [G loss: 1.385948]\n",
      "epoch:42 step:33100[D loss: 0.358388, acc: 81.25%, op_acc: 49.22%] [G loss: 1.407422]\n",
      "epoch:42 step:33101[D loss: 0.382454, acc: 69.53%, op_acc: 38.28%] [G loss: 1.150286]\n",
      "epoch:42 step:33102[D loss: 0.431087, acc: 61.72%, op_acc: 42.97%] [G loss: 1.290492]\n",
      "epoch:42 step:33103[D loss: 0.320623, acc: 81.25%, op_acc: 48.44%] [G loss: 1.203408]\n",
      "epoch:42 step:33104[D loss: 0.395480, acc: 67.19%, op_acc: 42.97%] [G loss: 1.072943]\n",
      "epoch:42 step:33105[D loss: 0.394050, acc: 66.41%, op_acc: 42.97%] [G loss: 1.171311]\n",
      "epoch:42 step:33106[D loss: 0.347921, acc: 73.44%, op_acc: 46.09%] [G loss: 1.412015]\n",
      "epoch:42 step:33107[D loss: 0.407907, acc: 64.84%, op_acc: 44.53%] [G loss: 1.302035]\n",
      "epoch:42 step:33108[D loss: 0.425682, acc: 66.41%, op_acc: 40.62%] [G loss: 1.279133]\n",
      "epoch:42 step:33109[D loss: 0.381193, acc: 70.31%, op_acc: 45.31%] [G loss: 1.272476]\n",
      "epoch:42 step:33110[D loss: 0.431254, acc: 60.16%, op_acc: 44.53%] [G loss: 1.305311]\n",
      "epoch:42 step:33111[D loss: 0.458150, acc: 62.50%, op_acc: 38.28%] [G loss: 1.038016]\n",
      "epoch:42 step:33112[D loss: 0.374872, acc: 67.19%, op_acc: 42.97%] [G loss: 1.299117]\n",
      "epoch:42 step:33113[D loss: 0.495186, acc: 46.88%, op_acc: 39.84%] [G loss: 1.227467]\n",
      "epoch:42 step:33114[D loss: 0.439995, acc: 59.38%, op_acc: 41.41%] [G loss: 1.076038]\n",
      "epoch:42 step:33115[D loss: 0.415146, acc: 65.62%, op_acc: 47.66%] [G loss: 1.069958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33116[D loss: 0.309573, acc: 78.12%, op_acc: 48.44%] [G loss: 1.204106]\n",
      "epoch:42 step:33117[D loss: 0.419103, acc: 67.19%, op_acc: 39.84%] [G loss: 1.530077]\n",
      "epoch:42 step:33118[D loss: 0.399064, acc: 66.41%, op_acc: 37.50%] [G loss: 1.361607]\n",
      "epoch:42 step:33119[D loss: 0.459211, acc: 57.81%, op_acc: 43.75%] [G loss: 1.348053]\n",
      "epoch:42 step:33120[D loss: 0.386292, acc: 72.66%, op_acc: 39.06%] [G loss: 1.127710]\n",
      "epoch:42 step:33121[D loss: 0.477935, acc: 55.47%, op_acc: 44.53%] [G loss: 1.270070]\n",
      "epoch:42 step:33122[D loss: 0.366495, acc: 70.31%, op_acc: 43.75%] [G loss: 1.332447]\n",
      "epoch:42 step:33123[D loss: 0.367356, acc: 71.88%, op_acc: 41.41%] [G loss: 1.432762]\n",
      "epoch:42 step:33124[D loss: 0.396823, acc: 62.50%, op_acc: 49.22%] [G loss: 1.296288]\n",
      "epoch:42 step:33125[D loss: 0.391495, acc: 64.84%, op_acc: 46.09%] [G loss: 1.303711]\n",
      "epoch:42 step:33126[D loss: 0.409238, acc: 67.97%, op_acc: 37.50%] [G loss: 1.073379]\n",
      "epoch:42 step:33127[D loss: 0.356722, acc: 75.78%, op_acc: 46.09%] [G loss: 1.196585]\n",
      "epoch:42 step:33128[D loss: 0.402211, acc: 66.41%, op_acc: 45.31%] [G loss: 1.130086]\n",
      "epoch:42 step:33129[D loss: 0.367061, acc: 71.88%, op_acc: 36.72%] [G loss: 1.183107]\n",
      "epoch:42 step:33130[D loss: 0.448827, acc: 53.91%, op_acc: 46.09%] [G loss: 1.178197]\n",
      "epoch:42 step:33131[D loss: 0.436740, acc: 63.28%, op_acc: 42.19%] [G loss: 1.457711]\n",
      "epoch:42 step:33132[D loss: 0.363782, acc: 64.84%, op_acc: 45.31%] [G loss: 1.293927]\n",
      "epoch:42 step:33133[D loss: 0.386034, acc: 71.09%, op_acc: 39.06%] [G loss: 1.301493]\n",
      "epoch:42 step:33134[D loss: 0.401565, acc: 67.97%, op_acc: 45.31%] [G loss: 1.207774]\n",
      "epoch:42 step:33135[D loss: 0.390200, acc: 73.44%, op_acc: 40.62%] [G loss: 1.288654]\n",
      "epoch:42 step:33136[D loss: 0.423892, acc: 57.03%, op_acc: 48.44%] [G loss: 1.156661]\n",
      "epoch:42 step:33137[D loss: 0.449877, acc: 60.16%, op_acc: 37.50%] [G loss: 1.205429]\n",
      "epoch:42 step:33138[D loss: 0.407142, acc: 65.62%, op_acc: 40.62%] [G loss: 1.377591]\n",
      "epoch:42 step:33139[D loss: 0.426731, acc: 64.06%, op_acc: 48.44%] [G loss: 1.045822]\n",
      "epoch:42 step:33140[D loss: 0.381917, acc: 64.06%, op_acc: 50.78%] [G loss: 1.282466]\n",
      "epoch:42 step:33141[D loss: 0.371572, acc: 74.22%, op_acc: 45.31%] [G loss: 1.096749]\n",
      "epoch:42 step:33142[D loss: 0.411349, acc: 65.62%, op_acc: 45.31%] [G loss: 1.133032]\n",
      "epoch:42 step:33143[D loss: 0.388747, acc: 64.84%, op_acc: 44.53%] [G loss: 1.185494]\n",
      "epoch:42 step:33144[D loss: 0.385263, acc: 67.19%, op_acc: 42.97%] [G loss: 1.143509]\n",
      "epoch:42 step:33145[D loss: 0.407234, acc: 66.41%, op_acc: 41.41%] [G loss: 1.152725]\n",
      "epoch:42 step:33146[D loss: 0.371301, acc: 71.88%, op_acc: 46.88%] [G loss: 1.242414]\n",
      "epoch:42 step:33147[D loss: 0.387407, acc: 67.19%, op_acc: 46.09%] [G loss: 1.286704]\n",
      "epoch:42 step:33148[D loss: 0.398024, acc: 64.84%, op_acc: 43.75%] [G loss: 1.249132]\n",
      "epoch:42 step:33149[D loss: 0.392499, acc: 61.72%, op_acc: 49.22%] [G loss: 1.380524]\n",
      "epoch:42 step:33150[D loss: 0.398798, acc: 67.19%, op_acc: 45.31%] [G loss: 1.103087]\n",
      "epoch:42 step:33151[D loss: 0.336921, acc: 73.44%, op_acc: 49.22%] [G loss: 1.191321]\n",
      "epoch:42 step:33152[D loss: 0.388237, acc: 68.75%, op_acc: 46.88%] [G loss: 1.236845]\n",
      "epoch:42 step:33153[D loss: 0.300398, acc: 87.50%, op_acc: 53.91%] [G loss: 1.487948]\n",
      "epoch:42 step:33154[D loss: 0.423007, acc: 62.50%, op_acc: 42.97%] [G loss: 1.253002]\n",
      "epoch:42 step:33155[D loss: 0.341929, acc: 75.00%, op_acc: 54.69%] [G loss: 1.172161]\n",
      "epoch:42 step:33156[D loss: 0.415500, acc: 61.72%, op_acc: 44.53%] [G loss: 1.412189]\n",
      "epoch:42 step:33157[D loss: 0.401877, acc: 61.72%, op_acc: 46.88%] [G loss: 1.185526]\n",
      "epoch:42 step:33158[D loss: 0.395472, acc: 64.84%, op_acc: 46.09%] [G loss: 1.243512]\n",
      "epoch:42 step:33159[D loss: 0.322169, acc: 82.03%, op_acc: 46.09%] [G loss: 1.401494]\n",
      "epoch:42 step:33160[D loss: 0.428575, acc: 58.59%, op_acc: 42.97%] [G loss: 1.101567]\n",
      "epoch:42 step:33161[D loss: 0.377968, acc: 68.75%, op_acc: 42.97%] [G loss: 1.169962]\n",
      "epoch:42 step:33162[D loss: 0.384477, acc: 70.31%, op_acc: 44.53%] [G loss: 1.278943]\n",
      "epoch:42 step:33163[D loss: 0.382910, acc: 70.31%, op_acc: 51.56%] [G loss: 1.331994]\n",
      "epoch:42 step:33164[D loss: 0.350613, acc: 71.88%, op_acc: 50.00%] [G loss: 1.457057]\n",
      "epoch:42 step:33165[D loss: 0.404494, acc: 56.25%, op_acc: 46.09%] [G loss: 1.303138]\n",
      "epoch:42 step:33166[D loss: 0.347171, acc: 74.22%, op_acc: 49.22%] [G loss: 1.595514]\n",
      "epoch:42 step:33167[D loss: 0.313721, acc: 79.69%, op_acc: 46.09%] [G loss: 1.275943]\n",
      "epoch:42 step:33168[D loss: 0.384966, acc: 67.19%, op_acc: 49.22%] [G loss: 1.616335]\n",
      "epoch:42 step:33169[D loss: 0.468947, acc: 59.38%, op_acc: 34.38%] [G loss: 1.158887]\n",
      "epoch:42 step:33170[D loss: 0.377474, acc: 71.88%, op_acc: 42.97%] [G loss: 1.128477]\n",
      "epoch:42 step:33171[D loss: 0.418764, acc: 63.28%, op_acc: 42.97%] [G loss: 1.115960]\n",
      "epoch:42 step:33172[D loss: 0.365743, acc: 71.88%, op_acc: 41.41%] [G loss: 1.112690]\n",
      "epoch:42 step:33173[D loss: 0.422621, acc: 60.16%, op_acc: 41.41%] [G loss: 1.186302]\n",
      "epoch:42 step:33174[D loss: 0.422359, acc: 57.81%, op_acc: 42.19%] [G loss: 1.194587]\n",
      "epoch:42 step:33175[D loss: 0.389606, acc: 64.06%, op_acc: 42.19%] [G loss: 1.320160]\n",
      "epoch:42 step:33176[D loss: 0.373998, acc: 69.53%, op_acc: 50.78%] [G loss: 1.163213]\n",
      "epoch:42 step:33177[D loss: 0.375140, acc: 74.22%, op_acc: 47.66%] [G loss: 1.166672]\n",
      "epoch:42 step:33178[D loss: 0.390687, acc: 68.75%, op_acc: 43.75%] [G loss: 1.421363]\n",
      "epoch:42 step:33179[D loss: 0.423633, acc: 60.16%, op_acc: 43.75%] [G loss: 1.278650]\n",
      "epoch:42 step:33180[D loss: 0.366280, acc: 71.09%, op_acc: 39.84%] [G loss: 1.164686]\n",
      "epoch:42 step:33181[D loss: 0.408450, acc: 60.94%, op_acc: 40.62%] [G loss: 1.241990]\n",
      "epoch:42 step:33182[D loss: 0.401202, acc: 60.16%, op_acc: 44.53%] [G loss: 1.521636]\n",
      "epoch:42 step:33183[D loss: 0.351236, acc: 72.66%, op_acc: 49.22%] [G loss: 1.233387]\n",
      "epoch:42 step:33184[D loss: 0.346574, acc: 71.09%, op_acc: 55.47%] [G loss: 1.495864]\n",
      "epoch:42 step:33185[D loss: 0.402076, acc: 64.84%, op_acc: 45.31%] [G loss: 1.360592]\n",
      "epoch:42 step:33186[D loss: 0.396277, acc: 65.62%, op_acc: 48.44%] [G loss: 1.454106]\n",
      "epoch:42 step:33187[D loss: 0.392099, acc: 63.28%, op_acc: 49.22%] [G loss: 1.107934]\n",
      "epoch:42 step:33188[D loss: 0.396900, acc: 65.62%, op_acc: 42.97%] [G loss: 1.238636]\n",
      "epoch:42 step:33189[D loss: 0.376583, acc: 66.41%, op_acc: 46.88%] [G loss: 1.150926]\n",
      "epoch:42 step:33190[D loss: 0.421713, acc: 62.50%, op_acc: 40.62%] [G loss: 1.234016]\n",
      "epoch:42 step:33191[D loss: 0.361050, acc: 70.31%, op_acc: 48.44%] [G loss: 1.582209]\n",
      "epoch:42 step:33192[D loss: 0.320609, acc: 74.22%, op_acc: 48.44%] [G loss: 1.232332]\n",
      "epoch:42 step:33193[D loss: 0.349410, acc: 71.09%, op_acc: 50.78%] [G loss: 1.177879]\n",
      "epoch:42 step:33194[D loss: 0.380000, acc: 67.97%, op_acc: 43.75%] [G loss: 1.174773]\n",
      "epoch:42 step:33195[D loss: 0.373514, acc: 68.75%, op_acc: 50.00%] [G loss: 1.269630]\n",
      "epoch:42 step:33196[D loss: 0.381542, acc: 71.09%, op_acc: 50.78%] [G loss: 1.329415]\n",
      "epoch:42 step:33197[D loss: 0.453746, acc: 55.47%, op_acc: 41.41%] [G loss: 1.281581]\n",
      "epoch:42 step:33198[D loss: 0.377469, acc: 70.31%, op_acc: 47.66%] [G loss: 1.149861]\n",
      "epoch:42 step:33199[D loss: 0.367697, acc: 71.88%, op_acc: 46.88%] [G loss: 1.053539]\n",
      "epoch:42 step:33200[D loss: 0.465493, acc: 57.03%, op_acc: 37.50%] [G loss: 1.353484]\n",
      "epoch:42 step:33201[D loss: 0.351159, acc: 71.88%, op_acc: 46.09%] [G loss: 1.141995]\n",
      "epoch:42 step:33202[D loss: 0.384905, acc: 67.97%, op_acc: 43.75%] [G loss: 1.277327]\n",
      "epoch:42 step:33203[D loss: 0.338793, acc: 77.34%, op_acc: 46.09%] [G loss: 1.129013]\n",
      "epoch:42 step:33204[D loss: 0.344288, acc: 75.00%, op_acc: 46.88%] [G loss: 1.394710]\n",
      "epoch:42 step:33205[D loss: 0.333801, acc: 77.34%, op_acc: 53.12%] [G loss: 1.337105]\n",
      "epoch:42 step:33206[D loss: 0.353879, acc: 72.66%, op_acc: 46.88%] [G loss: 1.305836]\n",
      "epoch:42 step:33207[D loss: 0.356730, acc: 70.31%, op_acc: 51.56%] [G loss: 1.237811]\n",
      "epoch:42 step:33208[D loss: 0.425779, acc: 60.16%, op_acc: 50.00%] [G loss: 1.097289]\n",
      "epoch:42 step:33209[D loss: 0.420790, acc: 65.62%, op_acc: 35.16%] [G loss: 1.110213]\n",
      "epoch:42 step:33210[D loss: 0.404811, acc: 62.50%, op_acc: 42.19%] [G loss: 1.236660]\n",
      "epoch:42 step:33211[D loss: 0.393731, acc: 65.62%, op_acc: 46.88%] [G loss: 1.128026]\n",
      "epoch:42 step:33212[D loss: 0.368482, acc: 67.97%, op_acc: 53.12%] [G loss: 1.339103]\n",
      "epoch:42 step:33213[D loss: 0.451486, acc: 55.47%, op_acc: 40.62%] [G loss: 0.951154]\n",
      "epoch:42 step:33214[D loss: 0.381423, acc: 64.06%, op_acc: 41.41%] [G loss: 1.242224]\n",
      "epoch:42 step:33215[D loss: 0.335195, acc: 73.44%, op_acc: 45.31%] [G loss: 1.231923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33216[D loss: 0.325961, acc: 72.66%, op_acc: 50.00%] [G loss: 1.311700]\n",
      "epoch:42 step:33217[D loss: 0.352336, acc: 75.00%, op_acc: 46.88%] [G loss: 1.369325]\n",
      "epoch:42 step:33218[D loss: 0.326150, acc: 75.78%, op_acc: 53.12%] [G loss: 1.577408]\n",
      "epoch:42 step:33219[D loss: 0.429829, acc: 60.94%, op_acc: 40.62%] [G loss: 1.151416]\n",
      "epoch:42 step:33220[D loss: 0.354426, acc: 74.22%, op_acc: 51.56%] [G loss: 1.512193]\n",
      "epoch:42 step:33221[D loss: 0.396415, acc: 64.84%, op_acc: 46.88%] [G loss: 1.249996]\n",
      "epoch:42 step:33222[D loss: 0.389029, acc: 66.41%, op_acc: 51.56%] [G loss: 1.294086]\n",
      "epoch:42 step:33223[D loss: 0.379130, acc: 67.97%, op_acc: 37.50%] [G loss: 1.241700]\n",
      "epoch:42 step:33224[D loss: 0.357058, acc: 69.53%, op_acc: 45.31%] [G loss: 1.351845]\n",
      "epoch:42 step:33225[D loss: 0.392577, acc: 67.19%, op_acc: 42.97%] [G loss: 1.233574]\n",
      "epoch:42 step:33226[D loss: 0.403190, acc: 67.97%, op_acc: 39.06%] [G loss: 1.264217]\n",
      "epoch:42 step:33227[D loss: 0.405270, acc: 62.50%, op_acc: 46.09%] [G loss: 1.276173]\n",
      "epoch:42 step:33228[D loss: 0.373958, acc: 70.31%, op_acc: 47.66%] [G loss: 1.228260]\n",
      "epoch:42 step:33229[D loss: 0.405321, acc: 62.50%, op_acc: 41.41%] [G loss: 1.155404]\n",
      "epoch:42 step:33230[D loss: 0.422790, acc: 59.38%, op_acc: 49.22%] [G loss: 1.011102]\n",
      "epoch:42 step:33231[D loss: 0.363168, acc: 67.97%, op_acc: 49.22%] [G loss: 1.092896]\n",
      "epoch:42 step:33232[D loss: 0.349698, acc: 71.09%, op_acc: 42.19%] [G loss: 1.247034]\n",
      "epoch:42 step:33233[D loss: 0.371511, acc: 60.94%, op_acc: 53.12%] [G loss: 1.169596]\n",
      "epoch:42 step:33234[D loss: 0.416154, acc: 57.81%, op_acc: 46.88%] [G loss: 0.956060]\n",
      "epoch:42 step:33235[D loss: 0.376211, acc: 71.88%, op_acc: 42.97%] [G loss: 1.159184]\n",
      "epoch:42 step:33236[D loss: 0.331220, acc: 71.88%, op_acc: 52.34%] [G loss: 1.218592]\n",
      "epoch:42 step:33237[D loss: 0.431552, acc: 60.16%, op_acc: 44.53%] [G loss: 1.104173]\n",
      "epoch:42 step:33238[D loss: 0.490606, acc: 53.12%, op_acc: 35.94%] [G loss: 1.061376]\n",
      "epoch:42 step:33239[D loss: 0.420026, acc: 65.62%, op_acc: 35.16%] [G loss: 1.003798]\n",
      "epoch:42 step:33240[D loss: 0.327808, acc: 75.00%, op_acc: 51.56%] [G loss: 1.215032]\n",
      "epoch:42 step:33241[D loss: 0.401915, acc: 67.19%, op_acc: 45.31%] [G loss: 1.314963]\n",
      "epoch:42 step:33242[D loss: 0.386930, acc: 63.28%, op_acc: 42.97%] [G loss: 1.089485]\n",
      "epoch:42 step:33243[D loss: 0.382858, acc: 67.97%, op_acc: 45.31%] [G loss: 1.227741]\n",
      "epoch:42 step:33244[D loss: 0.449965, acc: 57.81%, op_acc: 45.31%] [G loss: 1.148029]\n",
      "epoch:42 step:33245[D loss: 0.383613, acc: 71.09%, op_acc: 46.88%] [G loss: 1.311739]\n",
      "epoch:42 step:33246[D loss: 0.400715, acc: 58.59%, op_acc: 46.09%] [G loss: 1.437876]\n",
      "epoch:42 step:33247[D loss: 0.448298, acc: 57.81%, op_acc: 43.75%] [G loss: 1.125853]\n",
      "epoch:42 step:33248[D loss: 0.367668, acc: 71.09%, op_acc: 44.53%] [G loss: 1.289045]\n",
      "epoch:42 step:33249[D loss: 0.401880, acc: 64.84%, op_acc: 34.38%] [G loss: 1.263315]\n",
      "epoch:42 step:33250[D loss: 0.382876, acc: 67.97%, op_acc: 40.62%] [G loss: 1.012803]\n",
      "epoch:42 step:33251[D loss: 0.331087, acc: 79.69%, op_acc: 44.53%] [G loss: 1.272852]\n",
      "epoch:42 step:33252[D loss: 0.416607, acc: 67.97%, op_acc: 38.28%] [G loss: 1.324713]\n",
      "epoch:42 step:33253[D loss: 0.430741, acc: 57.03%, op_acc: 50.00%] [G loss: 1.319140]\n",
      "epoch:42 step:33254[D loss: 0.340033, acc: 71.88%, op_acc: 49.22%] [G loss: 1.355070]\n",
      "epoch:42 step:33255[D loss: 0.396588, acc: 65.62%, op_acc: 47.66%] [G loss: 1.236055]\n",
      "epoch:42 step:33256[D loss: 0.346752, acc: 75.78%, op_acc: 42.19%] [G loss: 1.316270]\n",
      "epoch:42 step:33257[D loss: 0.378935, acc: 70.31%, op_acc: 49.22%] [G loss: 1.366728]\n",
      "epoch:42 step:33258[D loss: 0.386772, acc: 69.53%, op_acc: 44.53%] [G loss: 1.224987]\n",
      "epoch:42 step:33259[D loss: 0.336058, acc: 75.78%, op_acc: 50.00%] [G loss: 1.131921]\n",
      "epoch:42 step:33260[D loss: 0.321981, acc: 76.56%, op_acc: 56.25%] [G loss: 1.342981]\n",
      "epoch:42 step:33261[D loss: 0.387149, acc: 64.06%, op_acc: 44.53%] [G loss: 1.225314]\n",
      "epoch:42 step:33262[D loss: 0.379968, acc: 68.75%, op_acc: 41.41%] [G loss: 1.243575]\n",
      "epoch:42 step:33263[D loss: 0.382437, acc: 67.97%, op_acc: 46.09%] [G loss: 1.229087]\n",
      "epoch:42 step:33264[D loss: 0.480360, acc: 47.66%, op_acc: 39.84%] [G loss: 1.357442]\n",
      "epoch:42 step:33265[D loss: 0.437906, acc: 57.03%, op_acc: 43.75%] [G loss: 1.270279]\n",
      "epoch:42 step:33266[D loss: 0.447803, acc: 59.38%, op_acc: 44.53%] [G loss: 1.127076]\n",
      "epoch:42 step:33267[D loss: 0.392452, acc: 65.62%, op_acc: 44.53%] [G loss: 1.221993]\n",
      "epoch:42 step:33268[D loss: 0.366873, acc: 64.84%, op_acc: 44.53%] [G loss: 1.116007]\n",
      "epoch:42 step:33269[D loss: 0.375839, acc: 71.09%, op_acc: 50.78%] [G loss: 1.230518]\n",
      "epoch:42 step:33270[D loss: 0.412299, acc: 65.62%, op_acc: 41.41%] [G loss: 1.145925]\n",
      "epoch:42 step:33271[D loss: 0.383753, acc: 66.41%, op_acc: 48.44%] [G loss: 1.268801]\n",
      "epoch:42 step:33272[D loss: 0.322517, acc: 80.47%, op_acc: 50.00%] [G loss: 1.364474]\n",
      "epoch:42 step:33273[D loss: 0.422752, acc: 68.75%, op_acc: 37.50%] [G loss: 1.338990]\n",
      "epoch:42 step:33274[D loss: 0.419540, acc: 67.19%, op_acc: 42.19%] [G loss: 1.198898]\n",
      "epoch:42 step:33275[D loss: 0.322076, acc: 75.78%, op_acc: 53.12%] [G loss: 1.267050]\n",
      "epoch:42 step:33276[D loss: 0.399840, acc: 67.19%, op_acc: 42.97%] [G loss: 1.065354]\n",
      "epoch:42 step:33277[D loss: 0.403881, acc: 69.53%, op_acc: 39.84%] [G loss: 1.031887]\n",
      "epoch:42 step:33278[D loss: 0.425403, acc: 60.16%, op_acc: 48.44%] [G loss: 1.275588]\n",
      "epoch:42 step:33279[D loss: 0.391176, acc: 72.66%, op_acc: 42.19%] [G loss: 1.385556]\n",
      "epoch:42 step:33280[D loss: 0.380123, acc: 64.84%, op_acc: 49.22%] [G loss: 1.374085]\n",
      "epoch:42 step:33281[D loss: 0.373425, acc: 71.88%, op_acc: 51.56%] [G loss: 1.253857]\n",
      "epoch:42 step:33282[D loss: 0.388059, acc: 66.41%, op_acc: 37.50%] [G loss: 1.269214]\n",
      "epoch:42 step:33283[D loss: 0.451359, acc: 53.12%, op_acc: 35.94%] [G loss: 1.258913]\n",
      "epoch:42 step:33284[D loss: 0.449144, acc: 57.81%, op_acc: 40.62%] [G loss: 1.236994]\n",
      "epoch:42 step:33285[D loss: 0.328671, acc: 77.34%, op_acc: 53.12%] [G loss: 1.236144]\n",
      "epoch:42 step:33286[D loss: 0.391007, acc: 65.62%, op_acc: 46.09%] [G loss: 1.178941]\n",
      "epoch:42 step:33287[D loss: 0.369385, acc: 68.75%, op_acc: 42.97%] [G loss: 1.219864]\n",
      "epoch:42 step:33288[D loss: 0.348319, acc: 71.88%, op_acc: 46.88%] [G loss: 1.340254]\n",
      "epoch:42 step:33289[D loss: 0.362911, acc: 69.53%, op_acc: 43.75%] [G loss: 1.094529]\n",
      "epoch:42 step:33290[D loss: 0.396172, acc: 66.41%, op_acc: 42.19%] [G loss: 1.268583]\n",
      "epoch:42 step:33291[D loss: 0.390639, acc: 68.75%, op_acc: 50.78%] [G loss: 1.061153]\n",
      "epoch:42 step:33292[D loss: 0.398539, acc: 63.28%, op_acc: 45.31%] [G loss: 1.115656]\n",
      "epoch:42 step:33293[D loss: 0.426167, acc: 64.06%, op_acc: 39.84%] [G loss: 1.208441]\n",
      "epoch:42 step:33294[D loss: 0.416777, acc: 60.94%, op_acc: 43.75%] [G loss: 1.138007]\n",
      "epoch:42 step:33295[D loss: 0.390979, acc: 69.53%, op_acc: 48.44%] [G loss: 1.162087]\n",
      "epoch:42 step:33296[D loss: 0.337069, acc: 74.22%, op_acc: 50.00%] [G loss: 1.336761]\n",
      "epoch:42 step:33297[D loss: 0.352438, acc: 73.44%, op_acc: 50.78%] [G loss: 1.454400]\n",
      "epoch:42 step:33298[D loss: 0.368282, acc: 64.84%, op_acc: 46.88%] [G loss: 1.315011]\n",
      "epoch:42 step:33299[D loss: 0.377406, acc: 65.62%, op_acc: 50.00%] [G loss: 1.175781]\n",
      "epoch:42 step:33300[D loss: 0.353416, acc: 71.88%, op_acc: 42.97%] [G loss: 1.257519]\n",
      "epoch:42 step:33301[D loss: 0.383449, acc: 71.09%, op_acc: 43.75%] [G loss: 1.145082]\n",
      "epoch:42 step:33302[D loss: 0.371382, acc: 71.09%, op_acc: 42.19%] [G loss: 1.260179]\n",
      "epoch:42 step:33303[D loss: 0.352551, acc: 75.78%, op_acc: 46.88%] [G loss: 1.441039]\n",
      "epoch:42 step:33304[D loss: 0.459881, acc: 59.38%, op_acc: 42.97%] [G loss: 1.149374]\n",
      "epoch:42 step:33305[D loss: 0.417760, acc: 66.41%, op_acc: 42.19%] [G loss: 1.157033]\n",
      "epoch:42 step:33306[D loss: 0.443401, acc: 64.06%, op_acc: 39.06%] [G loss: 1.081890]\n",
      "epoch:42 step:33307[D loss: 0.351116, acc: 74.22%, op_acc: 45.31%] [G loss: 0.991908]\n",
      "epoch:42 step:33308[D loss: 0.419264, acc: 64.84%, op_acc: 46.88%] [G loss: 0.954013]\n",
      "epoch:42 step:33309[D loss: 0.324793, acc: 76.56%, op_acc: 46.09%] [G loss: 1.217644]\n",
      "epoch:42 step:33310[D loss: 0.402074, acc: 64.06%, op_acc: 42.19%] [G loss: 1.336727]\n",
      "epoch:42 step:33311[D loss: 0.451098, acc: 60.94%, op_acc: 39.84%] [G loss: 1.011195]\n",
      "epoch:42 step:33312[D loss: 0.358533, acc: 76.56%, op_acc: 46.88%] [G loss: 1.323789]\n",
      "epoch:42 step:33313[D loss: 0.366757, acc: 72.66%, op_acc: 49.22%] [G loss: 1.295306]\n",
      "epoch:42 step:33314[D loss: 0.440922, acc: 55.47%, op_acc: 48.44%] [G loss: 1.164603]\n",
      "epoch:42 step:33315[D loss: 0.470434, acc: 57.03%, op_acc: 40.62%] [G loss: 1.179004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33316[D loss: 0.409186, acc: 64.06%, op_acc: 36.72%] [G loss: 1.240950]\n",
      "epoch:42 step:33317[D loss: 0.353257, acc: 77.34%, op_acc: 42.19%] [G loss: 1.350448]\n",
      "epoch:42 step:33318[D loss: 0.361624, acc: 71.88%, op_acc: 46.88%] [G loss: 1.304980]\n",
      "epoch:42 step:33319[D loss: 0.446565, acc: 61.72%, op_acc: 49.22%] [G loss: 0.966175]\n",
      "epoch:42 step:33320[D loss: 0.370476, acc: 71.88%, op_acc: 42.97%] [G loss: 0.975162]\n",
      "epoch:42 step:33321[D loss: 0.340526, acc: 69.53%, op_acc: 44.53%] [G loss: 1.106990]\n",
      "epoch:42 step:33322[D loss: 0.403060, acc: 66.41%, op_acc: 41.41%] [G loss: 1.221152]\n",
      "epoch:42 step:33323[D loss: 0.376621, acc: 69.53%, op_acc: 41.41%] [G loss: 1.062692]\n",
      "epoch:42 step:33324[D loss: 0.397543, acc: 65.62%, op_acc: 46.09%] [G loss: 1.198176]\n",
      "epoch:42 step:33325[D loss: 0.401764, acc: 64.84%, op_acc: 47.66%] [G loss: 1.359799]\n",
      "epoch:42 step:33326[D loss: 0.444086, acc: 58.59%, op_acc: 41.41%] [G loss: 1.238917]\n",
      "epoch:42 step:33327[D loss: 0.394269, acc: 73.44%, op_acc: 46.09%] [G loss: 1.364746]\n",
      "epoch:42 step:33328[D loss: 0.419743, acc: 67.19%, op_acc: 39.84%] [G loss: 1.154055]\n",
      "epoch:42 step:33329[D loss: 0.435332, acc: 60.94%, op_acc: 43.75%] [G loss: 1.202214]\n",
      "epoch:42 step:33330[D loss: 0.389808, acc: 66.41%, op_acc: 49.22%] [G loss: 0.960967]\n",
      "epoch:42 step:33331[D loss: 0.381628, acc: 65.62%, op_acc: 50.78%] [G loss: 1.227307]\n",
      "epoch:42 step:33332[D loss: 0.342062, acc: 68.75%, op_acc: 44.53%] [G loss: 1.419434]\n",
      "epoch:42 step:33333[D loss: 0.344549, acc: 75.78%, op_acc: 48.44%] [G loss: 1.462012]\n",
      "epoch:42 step:33334[D loss: 0.393653, acc: 65.62%, op_acc: 46.09%] [G loss: 1.319924]\n",
      "epoch:42 step:33335[D loss: 0.420759, acc: 62.50%, op_acc: 42.97%] [G loss: 1.527035]\n",
      "epoch:42 step:33336[D loss: 0.419359, acc: 60.94%, op_acc: 46.88%] [G loss: 1.254191]\n",
      "epoch:42 step:33337[D loss: 0.357197, acc: 78.91%, op_acc: 43.75%] [G loss: 1.187073]\n",
      "epoch:42 step:33338[D loss: 0.394198, acc: 64.06%, op_acc: 50.78%] [G loss: 1.300063]\n",
      "epoch:42 step:33339[D loss: 0.389022, acc: 68.75%, op_acc: 39.84%] [G loss: 0.984772]\n",
      "epoch:42 step:33340[D loss: 0.352077, acc: 71.09%, op_acc: 44.53%] [G loss: 1.169651]\n",
      "epoch:42 step:33341[D loss: 0.361739, acc: 73.44%, op_acc: 44.53%] [G loss: 1.188663]\n",
      "epoch:42 step:33342[D loss: 0.393202, acc: 64.06%, op_acc: 45.31%] [G loss: 1.273444]\n",
      "epoch:42 step:33343[D loss: 0.319325, acc: 77.34%, op_acc: 54.69%] [G loss: 1.365045]\n",
      "epoch:42 step:33344[D loss: 0.404794, acc: 65.62%, op_acc: 47.66%] [G loss: 1.192240]\n",
      "epoch:42 step:33345[D loss: 0.360638, acc: 71.88%, op_acc: 43.75%] [G loss: 1.237407]\n",
      "epoch:42 step:33346[D loss: 0.432311, acc: 62.50%, op_acc: 46.09%] [G loss: 1.557754]\n",
      "epoch:42 step:33347[D loss: 0.329681, acc: 74.22%, op_acc: 53.12%] [G loss: 1.310586]\n",
      "epoch:42 step:33348[D loss: 0.438609, acc: 57.81%, op_acc: 39.84%] [G loss: 1.168189]\n",
      "epoch:42 step:33349[D loss: 0.387099, acc: 68.75%, op_acc: 39.84%] [G loss: 1.337112]\n",
      "epoch:42 step:33350[D loss: 0.370659, acc: 71.09%, op_acc: 39.84%] [G loss: 1.211905]\n",
      "epoch:42 step:33351[D loss: 0.373891, acc: 66.41%, op_acc: 43.75%] [G loss: 1.329971]\n",
      "epoch:42 step:33352[D loss: 0.363693, acc: 71.88%, op_acc: 47.66%] [G loss: 1.415322]\n",
      "epoch:42 step:33353[D loss: 0.375320, acc: 71.88%, op_acc: 45.31%] [G loss: 1.389241]\n",
      "epoch:42 step:33354[D loss: 0.405433, acc: 70.31%, op_acc: 43.75%] [G loss: 1.193823]\n",
      "epoch:42 step:33355[D loss: 0.386355, acc: 67.97%, op_acc: 44.53%] [G loss: 1.253063]\n",
      "epoch:42 step:33356[D loss: 0.361524, acc: 74.22%, op_acc: 50.78%] [G loss: 1.397160]\n",
      "epoch:42 step:33357[D loss: 0.325443, acc: 74.22%, op_acc: 50.78%] [G loss: 1.125727]\n",
      "epoch:42 step:33358[D loss: 0.413438, acc: 63.28%, op_acc: 44.53%] [G loss: 1.124316]\n",
      "epoch:42 step:33359[D loss: 0.347703, acc: 69.53%, op_acc: 50.78%] [G loss: 1.245720]\n",
      "epoch:42 step:33360[D loss: 0.301033, acc: 81.25%, op_acc: 50.78%] [G loss: 1.482815]\n",
      "epoch:42 step:33361[D loss: 0.341491, acc: 73.44%, op_acc: 52.34%] [G loss: 1.452416]\n",
      "epoch:42 step:33362[D loss: 0.367935, acc: 74.22%, op_acc: 39.06%] [G loss: 1.254155]\n",
      "epoch:42 step:33363[D loss: 0.339182, acc: 72.66%, op_acc: 55.47%] [G loss: 1.375707]\n",
      "epoch:42 step:33364[D loss: 0.378388, acc: 71.88%, op_acc: 50.78%] [G loss: 1.264145]\n",
      "epoch:42 step:33365[D loss: 0.353459, acc: 74.22%, op_acc: 44.53%] [G loss: 1.286147]\n",
      "epoch:42 step:33366[D loss: 0.390215, acc: 69.53%, op_acc: 50.78%] [G loss: 1.280109]\n",
      "epoch:42 step:33367[D loss: 0.408113, acc: 64.84%, op_acc: 42.97%] [G loss: 1.150470]\n",
      "epoch:42 step:33368[D loss: 0.361810, acc: 70.31%, op_acc: 50.00%] [G loss: 1.313499]\n",
      "epoch:42 step:33369[D loss: 0.392549, acc: 70.31%, op_acc: 40.62%] [G loss: 1.097467]\n",
      "epoch:42 step:33370[D loss: 0.338811, acc: 70.31%, op_acc: 50.00%] [G loss: 1.291240]\n",
      "epoch:42 step:33371[D loss: 0.378777, acc: 68.75%, op_acc: 46.88%] [G loss: 1.153641]\n",
      "epoch:42 step:33372[D loss: 0.398724, acc: 65.62%, op_acc: 42.97%] [G loss: 1.313287]\n",
      "epoch:42 step:33373[D loss: 0.387193, acc: 63.28%, op_acc: 49.22%] [G loss: 1.169625]\n",
      "epoch:42 step:33374[D loss: 0.387251, acc: 69.53%, op_acc: 43.75%] [G loss: 1.337218]\n",
      "epoch:42 step:33375[D loss: 0.377593, acc: 67.97%, op_acc: 46.09%] [G loss: 1.486586]\n",
      "epoch:42 step:33376[D loss: 0.356539, acc: 74.22%, op_acc: 39.84%] [G loss: 1.250527]\n",
      "epoch:42 step:33377[D loss: 0.383475, acc: 68.75%, op_acc: 48.44%] [G loss: 1.386901]\n",
      "epoch:42 step:33378[D loss: 0.327657, acc: 78.12%, op_acc: 47.66%] [G loss: 1.223438]\n",
      "epoch:42 step:33379[D loss: 0.416257, acc: 61.72%, op_acc: 47.66%] [G loss: 1.482799]\n",
      "epoch:42 step:33380[D loss: 0.397293, acc: 70.31%, op_acc: 43.75%] [G loss: 1.455484]\n",
      "epoch:42 step:33381[D loss: 0.366558, acc: 71.09%, op_acc: 43.75%] [G loss: 1.092804]\n",
      "epoch:42 step:33382[D loss: 0.343476, acc: 74.22%, op_acc: 49.22%] [G loss: 1.342949]\n",
      "epoch:42 step:33383[D loss: 0.484693, acc: 54.69%, op_acc: 35.16%] [G loss: 1.017905]\n",
      "epoch:42 step:33384[D loss: 0.353746, acc: 75.78%, op_acc: 44.53%] [G loss: 1.388412]\n",
      "epoch:42 step:33385[D loss: 0.299209, acc: 78.12%, op_acc: 57.03%] [G loss: 1.352932]\n",
      "epoch:42 step:33386[D loss: 0.454665, acc: 60.16%, op_acc: 38.28%] [G loss: 1.276851]\n",
      "epoch:42 step:33387[D loss: 0.381715, acc: 64.06%, op_acc: 48.44%] [G loss: 1.357736]\n",
      "epoch:42 step:33388[D loss: 0.394662, acc: 66.41%, op_acc: 42.97%] [G loss: 1.254143]\n",
      "epoch:42 step:33389[D loss: 0.301443, acc: 78.12%, op_acc: 46.09%] [G loss: 1.388406]\n",
      "epoch:42 step:33390[D loss: 0.330373, acc: 71.88%, op_acc: 50.78%] [G loss: 1.536173]\n",
      "epoch:42 step:33391[D loss: 0.380938, acc: 68.75%, op_acc: 47.66%] [G loss: 1.449522]\n",
      "epoch:42 step:33392[D loss: 0.333341, acc: 75.00%, op_acc: 50.00%] [G loss: 1.473293]\n",
      "epoch:42 step:33393[D loss: 0.378596, acc: 67.19%, op_acc: 43.75%] [G loss: 1.203330]\n",
      "epoch:42 step:33394[D loss: 0.411699, acc: 63.28%, op_acc: 50.00%] [G loss: 1.367918]\n",
      "epoch:42 step:33395[D loss: 0.444176, acc: 61.72%, op_acc: 41.41%] [G loss: 1.164409]\n",
      "epoch:42 step:33396[D loss: 0.304212, acc: 82.03%, op_acc: 53.91%] [G loss: 1.055553]\n",
      "epoch:42 step:33397[D loss: 0.352587, acc: 75.00%, op_acc: 41.41%] [G loss: 1.146478]\n",
      "epoch:42 step:33398[D loss: 0.434924, acc: 58.59%, op_acc: 44.53%] [G loss: 1.179521]\n",
      "epoch:42 step:33399[D loss: 0.357011, acc: 68.75%, op_acc: 49.22%] [G loss: 1.020290]\n",
      "epoch:42 step:33400[D loss: 0.363889, acc: 70.31%, op_acc: 51.56%] [G loss: 1.325894]\n",
      "epoch:42 step:33401[D loss: 0.435783, acc: 63.28%, op_acc: 39.06%] [G loss: 1.148779]\n",
      "epoch:42 step:33402[D loss: 0.372359, acc: 71.88%, op_acc: 46.09%] [G loss: 1.183753]\n",
      "epoch:42 step:33403[D loss: 0.377462, acc: 64.84%, op_acc: 47.66%] [G loss: 1.247887]\n",
      "epoch:42 step:33404[D loss: 0.405310, acc: 63.28%, op_acc: 46.88%] [G loss: 1.365708]\n",
      "epoch:42 step:33405[D loss: 0.355301, acc: 65.62%, op_acc: 57.03%] [G loss: 1.326591]\n",
      "epoch:42 step:33406[D loss: 0.361410, acc: 78.91%, op_acc: 47.66%] [G loss: 1.236379]\n",
      "epoch:42 step:33407[D loss: 0.469466, acc: 57.81%, op_acc: 36.72%] [G loss: 0.921316]\n",
      "epoch:42 step:33408[D loss: 0.390846, acc: 68.75%, op_acc: 52.34%] [G loss: 1.307580]\n",
      "epoch:42 step:33409[D loss: 0.367105, acc: 67.19%, op_acc: 46.88%] [G loss: 1.219459]\n",
      "epoch:42 step:33410[D loss: 0.339095, acc: 75.78%, op_acc: 55.47%] [G loss: 1.394761]\n",
      "epoch:42 step:33411[D loss: 0.420608, acc: 63.28%, op_acc: 46.09%] [G loss: 1.183597]\n",
      "epoch:42 step:33412[D loss: 0.368977, acc: 74.22%, op_acc: 44.53%] [G loss: 1.245395]\n",
      "epoch:42 step:33413[D loss: 0.465840, acc: 54.69%, op_acc: 40.62%] [G loss: 1.046327]\n",
      "epoch:42 step:33414[D loss: 0.398658, acc: 66.41%, op_acc: 42.19%] [G loss: 1.352318]\n",
      "epoch:42 step:33415[D loss: 0.453720, acc: 53.91%, op_acc: 42.19%] [G loss: 1.343822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33416[D loss: 0.392701, acc: 63.28%, op_acc: 50.00%] [G loss: 1.309521]\n",
      "epoch:42 step:33417[D loss: 0.417718, acc: 64.06%, op_acc: 46.09%] [G loss: 1.251913]\n",
      "epoch:42 step:33418[D loss: 0.420414, acc: 65.62%, op_acc: 44.53%] [G loss: 1.128108]\n",
      "epoch:42 step:33419[D loss: 0.422873, acc: 59.38%, op_acc: 50.78%] [G loss: 1.248253]\n",
      "epoch:42 step:33420[D loss: 0.413867, acc: 60.16%, op_acc: 49.22%] [G loss: 1.291100]\n",
      "epoch:42 step:33421[D loss: 0.371325, acc: 73.44%, op_acc: 45.31%] [G loss: 1.419549]\n",
      "epoch:42 step:33422[D loss: 0.403752, acc: 67.97%, op_acc: 44.53%] [G loss: 1.197708]\n",
      "epoch:42 step:33423[D loss: 0.425275, acc: 60.16%, op_acc: 39.06%] [G loss: 1.299165]\n",
      "epoch:42 step:33424[D loss: 0.395366, acc: 73.44%, op_acc: 40.62%] [G loss: 1.289677]\n",
      "epoch:42 step:33425[D loss: 0.366917, acc: 68.75%, op_acc: 48.44%] [G loss: 1.355668]\n",
      "epoch:42 step:33426[D loss: 0.427636, acc: 56.25%, op_acc: 40.62%] [G loss: 1.192013]\n",
      "epoch:42 step:33427[D loss: 0.407054, acc: 64.84%, op_acc: 46.88%] [G loss: 1.119233]\n",
      "epoch:42 step:33428[D loss: 0.373513, acc: 67.97%, op_acc: 47.66%] [G loss: 1.291711]\n",
      "epoch:42 step:33429[D loss: 0.346769, acc: 78.12%, op_acc: 45.31%] [G loss: 1.203767]\n",
      "epoch:42 step:33430[D loss: 0.375300, acc: 75.78%, op_acc: 53.91%] [G loss: 1.190610]\n",
      "epoch:42 step:33431[D loss: 0.405739, acc: 64.84%, op_acc: 40.62%] [G loss: 1.165555]\n",
      "epoch:42 step:33432[D loss: 0.376255, acc: 64.84%, op_acc: 41.41%] [G loss: 1.247747]\n",
      "epoch:42 step:33433[D loss: 0.420000, acc: 62.50%, op_acc: 43.75%] [G loss: 1.127997]\n",
      "epoch:42 step:33434[D loss: 0.431014, acc: 62.50%, op_acc: 40.62%] [G loss: 1.129112]\n",
      "epoch:42 step:33435[D loss: 0.386434, acc: 70.31%, op_acc: 42.19%] [G loss: 1.182816]\n",
      "epoch:42 step:33436[D loss: 0.413662, acc: 64.06%, op_acc: 50.78%] [G loss: 1.143358]\n",
      "epoch:42 step:33437[D loss: 0.431550, acc: 61.72%, op_acc: 42.97%] [G loss: 1.054656]\n",
      "epoch:42 step:33438[D loss: 0.392046, acc: 67.97%, op_acc: 46.09%] [G loss: 1.228816]\n",
      "epoch:42 step:33439[D loss: 0.364840, acc: 67.19%, op_acc: 42.97%] [G loss: 1.087429]\n",
      "epoch:42 step:33440[D loss: 0.437345, acc: 60.94%, op_acc: 37.50%] [G loss: 1.098035]\n",
      "epoch:42 step:33441[D loss: 0.448035, acc: 57.81%, op_acc: 45.31%] [G loss: 1.109003]\n",
      "epoch:42 step:33442[D loss: 0.429198, acc: 64.06%, op_acc: 39.06%] [G loss: 1.232747]\n",
      "epoch:42 step:33443[D loss: 0.384008, acc: 67.19%, op_acc: 50.00%] [G loss: 1.356378]\n",
      "epoch:42 step:33444[D loss: 0.435528, acc: 57.81%, op_acc: 41.41%] [G loss: 1.100413]\n",
      "epoch:42 step:33445[D loss: 0.387653, acc: 64.84%, op_acc: 47.66%] [G loss: 1.229068]\n",
      "epoch:42 step:33446[D loss: 0.390383, acc: 62.50%, op_acc: 49.22%] [G loss: 1.158269]\n",
      "epoch:42 step:33447[D loss: 0.420595, acc: 61.72%, op_acc: 35.16%] [G loss: 1.329719]\n",
      "epoch:42 step:33448[D loss: 0.384658, acc: 73.44%, op_acc: 46.09%] [G loss: 1.117906]\n",
      "epoch:42 step:33449[D loss: 0.404764, acc: 63.28%, op_acc: 45.31%] [G loss: 1.504031]\n",
      "epoch:42 step:33450[D loss: 0.384355, acc: 66.41%, op_acc: 42.97%] [G loss: 1.343647]\n",
      "epoch:42 step:33451[D loss: 0.398344, acc: 73.44%, op_acc: 42.97%] [G loss: 1.257718]\n",
      "epoch:42 step:33452[D loss: 0.387906, acc: 70.31%, op_acc: 43.75%] [G loss: 1.093511]\n",
      "epoch:42 step:33453[D loss: 0.413674, acc: 58.59%, op_acc: 42.19%] [G loss: 1.287426]\n",
      "epoch:42 step:33454[D loss: 0.349452, acc: 75.78%, op_acc: 47.66%] [G loss: 1.205672]\n",
      "epoch:42 step:33455[D loss: 0.411936, acc: 60.16%, op_acc: 42.97%] [G loss: 1.161310]\n",
      "epoch:42 step:33456[D loss: 0.376150, acc: 67.97%, op_acc: 44.53%] [G loss: 1.284822]\n",
      "epoch:42 step:33457[D loss: 0.385551, acc: 66.41%, op_acc: 44.53%] [G loss: 1.248692]\n",
      "epoch:42 step:33458[D loss: 0.428451, acc: 62.50%, op_acc: 42.97%] [G loss: 1.197729]\n",
      "epoch:42 step:33459[D loss: 0.345323, acc: 71.09%, op_acc: 50.78%] [G loss: 1.256302]\n",
      "epoch:42 step:33460[D loss: 0.370618, acc: 72.66%, op_acc: 35.94%] [G loss: 1.164037]\n",
      "epoch:42 step:33461[D loss: 0.364058, acc: 72.66%, op_acc: 46.88%] [G loss: 1.210046]\n",
      "epoch:42 step:33462[D loss: 0.387044, acc: 68.75%, op_acc: 42.97%] [G loss: 1.209918]\n",
      "epoch:42 step:33463[D loss: 0.331486, acc: 78.91%, op_acc: 50.78%] [G loss: 1.149853]\n",
      "epoch:42 step:33464[D loss: 0.403282, acc: 61.72%, op_acc: 46.88%] [G loss: 1.043650]\n",
      "epoch:42 step:33465[D loss: 0.436984, acc: 58.59%, op_acc: 39.06%] [G loss: 1.115050]\n",
      "epoch:42 step:33466[D loss: 0.352457, acc: 67.97%, op_acc: 46.88%] [G loss: 1.325683]\n",
      "epoch:42 step:33467[D loss: 0.396390, acc: 75.00%, op_acc: 34.38%] [G loss: 1.098902]\n",
      "epoch:42 step:33468[D loss: 0.443548, acc: 57.03%, op_acc: 40.62%] [G loss: 1.024354]\n",
      "epoch:42 step:33469[D loss: 0.403320, acc: 64.06%, op_acc: 44.53%] [G loss: 1.130731]\n",
      "epoch:42 step:33470[D loss: 0.373520, acc: 71.09%, op_acc: 47.66%] [G loss: 1.211444]\n",
      "epoch:42 step:33471[D loss: 0.367543, acc: 68.75%, op_acc: 47.66%] [G loss: 1.218155]\n",
      "epoch:42 step:33472[D loss: 0.412516, acc: 63.28%, op_acc: 43.75%] [G loss: 1.326943]\n",
      "epoch:42 step:33473[D loss: 0.379615, acc: 64.84%, op_acc: 43.75%] [G loss: 1.228767]\n",
      "epoch:42 step:33474[D loss: 0.405554, acc: 69.53%, op_acc: 44.53%] [G loss: 1.137625]\n",
      "epoch:42 step:33475[D loss: 0.424009, acc: 65.62%, op_acc: 38.28%] [G loss: 1.073748]\n",
      "epoch:42 step:33476[D loss: 0.389898, acc: 63.28%, op_acc: 46.88%] [G loss: 1.126359]\n",
      "epoch:42 step:33477[D loss: 0.486808, acc: 53.12%, op_acc: 38.28%] [G loss: 1.142416]\n",
      "epoch:42 step:33478[D loss: 0.432331, acc: 64.06%, op_acc: 36.72%] [G loss: 1.084780]\n",
      "epoch:42 step:33479[D loss: 0.407824, acc: 74.22%, op_acc: 35.16%] [G loss: 1.173360]\n",
      "epoch:42 step:33480[D loss: 0.375479, acc: 73.44%, op_acc: 41.41%] [G loss: 1.238251]\n",
      "epoch:42 step:33481[D loss: 0.321987, acc: 76.56%, op_acc: 47.66%] [G loss: 1.177648]\n",
      "epoch:42 step:33482[D loss: 0.388140, acc: 70.31%, op_acc: 36.72%] [G loss: 1.111155]\n",
      "epoch:42 step:33483[D loss: 0.488412, acc: 58.59%, op_acc: 33.59%] [G loss: 1.095255]\n",
      "epoch:42 step:33484[D loss: 0.425843, acc: 61.72%, op_acc: 46.09%] [G loss: 1.128677]\n",
      "epoch:42 step:33485[D loss: 0.352963, acc: 69.53%, op_acc: 47.66%] [G loss: 1.263098]\n",
      "epoch:42 step:33486[D loss: 0.406885, acc: 67.97%, op_acc: 37.50%] [G loss: 1.202145]\n",
      "epoch:42 step:33487[D loss: 0.376933, acc: 71.88%, op_acc: 36.72%] [G loss: 1.009276]\n",
      "epoch:42 step:33488[D loss: 0.359316, acc: 71.09%, op_acc: 46.09%] [G loss: 1.146160]\n",
      "epoch:42 step:33489[D loss: 0.338211, acc: 77.34%, op_acc: 50.78%] [G loss: 1.400565]\n",
      "epoch:42 step:33490[D loss: 0.382357, acc: 69.53%, op_acc: 46.09%] [G loss: 1.353835]\n",
      "epoch:42 step:33491[D loss: 0.377940, acc: 68.75%, op_acc: 46.09%] [G loss: 1.142039]\n",
      "epoch:42 step:33492[D loss: 0.387233, acc: 71.09%, op_acc: 36.72%] [G loss: 1.017799]\n",
      "epoch:42 step:33493[D loss: 0.357228, acc: 74.22%, op_acc: 44.53%] [G loss: 1.298202]\n",
      "epoch:42 step:33494[D loss: 0.406172, acc: 66.41%, op_acc: 46.09%] [G loss: 1.118883]\n",
      "epoch:42 step:33495[D loss: 0.441214, acc: 61.72%, op_acc: 42.19%] [G loss: 1.092400]\n",
      "epoch:42 step:33496[D loss: 0.404693, acc: 68.75%, op_acc: 40.62%] [G loss: 1.111265]\n",
      "epoch:42 step:33497[D loss: 0.371671, acc: 74.22%, op_acc: 44.53%] [G loss: 1.139715]\n",
      "epoch:42 step:33498[D loss: 0.389618, acc: 73.44%, op_acc: 46.09%] [G loss: 1.134895]\n",
      "epoch:42 step:33499[D loss: 0.355925, acc: 71.88%, op_acc: 47.66%] [G loss: 1.135349]\n",
      "epoch:42 step:33500[D loss: 0.333311, acc: 75.00%, op_acc: 51.56%] [G loss: 1.129970]\n",
      "epoch:42 step:33501[D loss: 0.430626, acc: 60.94%, op_acc: 47.66%] [G loss: 1.078925]\n",
      "epoch:42 step:33502[D loss: 0.435491, acc: 56.25%, op_acc: 35.16%] [G loss: 1.006883]\n",
      "epoch:42 step:33503[D loss: 0.405276, acc: 63.28%, op_acc: 41.41%] [G loss: 1.154854]\n",
      "epoch:42 step:33504[D loss: 0.383689, acc: 60.94%, op_acc: 48.44%] [G loss: 1.152084]\n",
      "epoch:42 step:33505[D loss: 0.413890, acc: 67.19%, op_acc: 40.62%] [G loss: 1.446164]\n",
      "epoch:42 step:33506[D loss: 0.369792, acc: 61.72%, op_acc: 48.44%] [G loss: 1.119819]\n",
      "epoch:42 step:33507[D loss: 0.429242, acc: 60.94%, op_acc: 44.53%] [G loss: 1.210059]\n",
      "epoch:42 step:33508[D loss: 0.383843, acc: 67.19%, op_acc: 50.00%] [G loss: 1.211322]\n",
      "epoch:42 step:33509[D loss: 0.411204, acc: 62.50%, op_acc: 42.19%] [G loss: 1.203829]\n",
      "epoch:42 step:33510[D loss: 0.414656, acc: 63.28%, op_acc: 43.75%] [G loss: 1.044630]\n",
      "epoch:42 step:33511[D loss: 0.343390, acc: 74.22%, op_acc: 46.09%] [G loss: 1.074256]\n",
      "epoch:42 step:33512[D loss: 0.391894, acc: 60.94%, op_acc: 42.97%] [G loss: 1.082403]\n",
      "epoch:42 step:33513[D loss: 0.391936, acc: 63.28%, op_acc: 41.41%] [G loss: 1.201271]\n",
      "epoch:42 step:33514[D loss: 0.388607, acc: 63.28%, op_acc: 49.22%] [G loss: 1.037574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42 step:33515[D loss: 0.406192, acc: 60.16%, op_acc: 46.88%] [G loss: 1.179249]\n",
      "epoch:42 step:33516[D loss: 0.380901, acc: 71.09%, op_acc: 47.66%] [G loss: 1.047484]\n",
      "epoch:42 step:33517[D loss: 0.419786, acc: 61.72%, op_acc: 44.53%] [G loss: 1.306556]\n",
      "epoch:42 step:33518[D loss: 0.373506, acc: 67.19%, op_acc: 42.97%] [G loss: 1.096088]\n",
      "epoch:42 step:33519[D loss: 0.438441, acc: 61.72%, op_acc: 39.84%] [G loss: 1.214419]\n",
      "epoch:42 step:33520[D loss: 0.420055, acc: 61.72%, op_acc: 40.62%] [G loss: 1.304598]\n",
      "epoch:42 step:33521[D loss: 0.388613, acc: 67.97%, op_acc: 46.09%] [G loss: 1.283488]\n",
      "epoch:42 step:33522[D loss: 0.405569, acc: 61.72%, op_acc: 44.53%] [G loss: 1.152267]\n",
      "epoch:42 step:33523[D loss: 0.398074, acc: 64.84%, op_acc: 44.53%] [G loss: 1.182817]\n",
      "epoch:42 step:33524[D loss: 0.373598, acc: 67.97%, op_acc: 49.22%] [G loss: 1.329191]\n",
      "epoch:42 step:33525[D loss: 0.432888, acc: 60.16%, op_acc: 42.97%] [G loss: 0.973122]\n",
      "epoch:42 step:33526[D loss: 0.466385, acc: 60.16%, op_acc: 34.38%] [G loss: 1.201553]\n",
      "epoch:42 step:33527[D loss: 0.344540, acc: 73.44%, op_acc: 46.09%] [G loss: 1.205191]\n",
      "epoch:42 step:33528[D loss: 0.362360, acc: 67.97%, op_acc: 50.78%] [G loss: 1.141269]\n",
      "epoch:42 step:33529[D loss: 0.445219, acc: 56.25%, op_acc: 36.72%] [G loss: 1.097645]\n",
      "epoch:42 step:33530[D loss: 0.436430, acc: 64.84%, op_acc: 40.62%] [G loss: 1.312171]\n",
      "epoch:42 step:33531[D loss: 0.346174, acc: 71.09%, op_acc: 42.19%] [G loss: 0.980119]\n",
      "epoch:42 step:33532[D loss: 0.350923, acc: 71.88%, op_acc: 44.53%] [G loss: 1.264379]\n",
      "epoch:42 step:33533[D loss: 0.332889, acc: 74.22%, op_acc: 46.88%] [G loss: 1.234253]\n",
      "epoch:42 step:33534[D loss: 0.428138, acc: 58.59%, op_acc: 42.19%] [G loss: 1.098628]\n",
      "epoch:42 step:33535[D loss: 0.392240, acc: 69.53%, op_acc: 45.31%] [G loss: 1.282598]\n",
      "epoch:42 step:33536[D loss: 0.385342, acc: 63.28%, op_acc: 40.62%] [G loss: 1.254668]\n",
      "epoch:42 step:33537[D loss: 0.380507, acc: 71.09%, op_acc: 45.31%] [G loss: 1.271188]\n",
      "epoch:42 step:33538[D loss: 0.434492, acc: 62.50%, op_acc: 40.62%] [G loss: 1.408505]\n",
      "epoch:42 step:33539[D loss: 0.398577, acc: 60.94%, op_acc: 48.44%] [G loss: 1.019190]\n",
      "epoch:42 step:33540[D loss: 0.360733, acc: 73.44%, op_acc: 50.00%] [G loss: 1.148324]\n",
      "epoch:42 step:33541[D loss: 0.418870, acc: 62.50%, op_acc: 40.62%] [G loss: 1.209446]\n",
      "epoch:42 step:33542[D loss: 0.392973, acc: 64.06%, op_acc: 45.31%] [G loss: 1.307220]\n",
      "epoch:42 step:33543[D loss: 0.354958, acc: 75.00%, op_acc: 42.19%] [G loss: 1.374465]\n",
      "epoch:42 step:33544[D loss: 0.480936, acc: 55.47%, op_acc: 42.97%] [G loss: 1.113478]\n",
      "epoch:42 step:33545[D loss: 0.448862, acc: 59.38%, op_acc: 42.19%] [G loss: 1.097492]\n",
      "epoch:42 step:33546[D loss: 0.426778, acc: 57.81%, op_acc: 49.22%] [G loss: 1.189941]\n",
      "epoch:42 step:33547[D loss: 0.432167, acc: 60.94%, op_acc: 45.31%] [G loss: 1.300076]\n",
      "epoch:42 step:33548[D loss: 0.428106, acc: 65.62%, op_acc: 46.88%] [G loss: 1.220779]\n",
      "epoch:42 step:33549[D loss: 0.400591, acc: 63.28%, op_acc: 45.31%] [G loss: 1.264646]\n",
      "epoch:42 step:33550[D loss: 0.473625, acc: 58.59%, op_acc: 41.41%] [G loss: 1.074799]\n",
      "epoch:42 step:33551[D loss: 0.411636, acc: 64.84%, op_acc: 42.19%] [G loss: 1.081819]\n",
      "epoch:42 step:33552[D loss: 0.430250, acc: 58.59%, op_acc: 43.75%] [G loss: 1.154898]\n",
      "epoch:42 step:33553[D loss: 0.402461, acc: 65.62%, op_acc: 34.38%] [G loss: 1.175136]\n",
      "epoch:42 step:33554[D loss: 0.394155, acc: 64.84%, op_acc: 45.31%] [G loss: 0.970805]\n",
      "epoch:42 step:33555[D loss: 0.414859, acc: 60.94%, op_acc: 39.84%] [G loss: 1.125538]\n",
      "epoch:42 step:33556[D loss: 0.387688, acc: 67.19%, op_acc: 47.66%] [G loss: 1.390074]\n",
      "epoch:42 step:33557[D loss: 0.439052, acc: 58.59%, op_acc: 37.50%] [G loss: 1.181954]\n",
      "epoch:42 step:33558[D loss: 0.386213, acc: 67.19%, op_acc: 42.97%] [G loss: 1.126796]\n",
      "epoch:42 step:33559[D loss: 0.388926, acc: 65.62%, op_acc: 42.97%] [G loss: 1.200942]\n",
      "epoch:42 step:33560[D loss: 0.367152, acc: 68.75%, op_acc: 47.66%] [G loss: 1.105158]\n",
      "epoch:42 step:33561[D loss: 0.400054, acc: 65.62%, op_acc: 42.19%] [G loss: 1.227204]\n",
      "epoch:42 step:33562[D loss: 0.383929, acc: 64.06%, op_acc: 44.53%] [G loss: 1.468583]\n",
      "epoch:42 step:33563[D loss: 0.365547, acc: 64.84%, op_acc: 46.09%] [G loss: 1.181412]\n",
      "epoch:42 step:33564[D loss: 0.436228, acc: 64.84%, op_acc: 39.06%] [G loss: 1.106133]\n",
      "epoch:42 step:33565[D loss: 0.431679, acc: 61.72%, op_acc: 39.84%] [G loss: 1.247740]\n",
      "epoch:42 step:33566[D loss: 0.401668, acc: 65.62%, op_acc: 40.62%] [G loss: 1.188613]\n",
      "epoch:42 step:33567[D loss: 0.326471, acc: 75.78%, op_acc: 52.34%] [G loss: 1.350906]\n",
      "epoch:42 step:33568[D loss: 0.460748, acc: 55.47%, op_acc: 42.97%] [G loss: 1.399311]\n",
      "epoch:42 step:33569[D loss: 0.392589, acc: 64.06%, op_acc: 44.53%] [G loss: 1.232780]\n",
      "epoch:42 step:33570[D loss: 0.448747, acc: 57.03%, op_acc: 39.06%] [G loss: 1.246216]\n",
      "epoch:42 step:33571[D loss: 0.381690, acc: 62.50%, op_acc: 50.00%] [G loss: 1.182144]\n",
      "epoch:42 step:33572[D loss: 0.456011, acc: 60.16%, op_acc: 41.41%] [G loss: 1.074466]\n",
      "epoch:42 step:33573[D loss: 0.428297, acc: 60.16%, op_acc: 42.19%] [G loss: 1.239239]\n",
      "epoch:42 step:33574[D loss: 0.441875, acc: 61.72%, op_acc: 38.28%] [G loss: 1.146832]\n",
      "epoch:42 step:33575[D loss: 0.376025, acc: 74.22%, op_acc: 49.22%] [G loss: 1.103199]\n",
      "epoch:42 step:33576[D loss: 0.369952, acc: 67.19%, op_acc: 47.66%] [G loss: 1.139458]\n",
      "epoch:42 step:33577[D loss: 0.342760, acc: 81.25%, op_acc: 41.41%] [G loss: 1.114108]\n",
      "epoch:42 step:33578[D loss: 0.459146, acc: 57.81%, op_acc: 39.06%] [G loss: 1.120737]\n",
      "epoch:42 step:33579[D loss: 0.462308, acc: 59.38%, op_acc: 32.81%] [G loss: 1.122768]\n",
      "epoch:42 step:33580[D loss: 0.431291, acc: 61.72%, op_acc: 38.28%] [G loss: 1.034550]\n",
      "epoch:42 step:33581[D loss: 0.420000, acc: 60.94%, op_acc: 40.62%] [G loss: 1.137730]\n",
      "epoch:42 step:33582[D loss: 0.390173, acc: 67.19%, op_acc: 50.00%] [G loss: 1.115308]\n",
      "epoch:42 step:33583[D loss: 0.417908, acc: 59.38%, op_acc: 38.28%] [G loss: 1.158861]\n",
      "epoch:43 step:33584[D loss: 0.269583, acc: 85.94%, op_acc: 53.12%] [G loss: 1.142650]\n",
      "epoch:43 step:33585[D loss: 0.405405, acc: 61.72%, op_acc: 44.53%] [G loss: 1.402738]\n",
      "epoch:43 step:33586[D loss: 0.387343, acc: 64.84%, op_acc: 48.44%] [G loss: 1.253894]\n",
      "epoch:43 step:33587[D loss: 0.337178, acc: 71.88%, op_acc: 53.12%] [G loss: 1.119444]\n",
      "epoch:43 step:33588[D loss: 0.417944, acc: 57.81%, op_acc: 45.31%] [G loss: 1.085188]\n",
      "epoch:43 step:33589[D loss: 0.351775, acc: 76.56%, op_acc: 49.22%] [G loss: 1.181609]\n",
      "epoch:43 step:33590[D loss: 0.368407, acc: 72.66%, op_acc: 46.09%] [G loss: 1.235478]\n",
      "epoch:43 step:33591[D loss: 0.393423, acc: 66.41%, op_acc: 47.66%] [G loss: 1.174322]\n",
      "epoch:43 step:33592[D loss: 0.358215, acc: 71.09%, op_acc: 50.00%] [G loss: 1.161829]\n",
      "epoch:43 step:33593[D loss: 0.372225, acc: 70.31%, op_acc: 42.97%] [G loss: 0.993209]\n",
      "epoch:43 step:33594[D loss: 0.438820, acc: 59.38%, op_acc: 40.62%] [G loss: 1.180449]\n",
      "epoch:43 step:33595[D loss: 0.354267, acc: 69.53%, op_acc: 43.75%] [G loss: 1.173541]\n",
      "epoch:43 step:33596[D loss: 0.342995, acc: 76.56%, op_acc: 53.91%] [G loss: 1.243107]\n",
      "epoch:43 step:33597[D loss: 0.393846, acc: 65.62%, op_acc: 41.41%] [G loss: 1.235021]\n",
      "epoch:43 step:33598[D loss: 0.351984, acc: 71.88%, op_acc: 48.44%] [G loss: 1.229301]\n",
      "epoch:43 step:33599[D loss: 0.346963, acc: 75.00%, op_acc: 48.44%] [G loss: 1.144171]\n",
      "epoch:43 step:33600[D loss: 0.437573, acc: 57.03%, op_acc: 46.09%] [G loss: 1.205666]\n",
      "epoch:43 step:33601[D loss: 0.379134, acc: 69.53%, op_acc: 46.09%] [G loss: 1.127539]\n",
      "epoch:43 step:33602[D loss: 0.392465, acc: 61.72%, op_acc: 53.91%] [G loss: 0.916348]\n",
      "epoch:43 step:33603[D loss: 0.377835, acc: 73.44%, op_acc: 48.44%] [G loss: 1.224761]\n",
      "epoch:43 step:33604[D loss: 0.418028, acc: 63.28%, op_acc: 41.41%] [G loss: 1.082670]\n",
      "epoch:43 step:33605[D loss: 0.355936, acc: 71.09%, op_acc: 53.12%] [G loss: 1.106665]\n",
      "epoch:43 step:33606[D loss: 0.413845, acc: 65.62%, op_acc: 40.62%] [G loss: 1.265353]\n",
      "epoch:43 step:33607[D loss: 0.431729, acc: 60.94%, op_acc: 39.06%] [G loss: 1.145771]\n",
      "epoch:43 step:33608[D loss: 0.445548, acc: 59.38%, op_acc: 39.84%] [G loss: 1.266540]\n",
      "epoch:43 step:33609[D loss: 0.415202, acc: 56.25%, op_acc: 39.84%] [G loss: 1.155121]\n",
      "epoch:43 step:33610[D loss: 0.395347, acc: 68.75%, op_acc: 41.41%] [G loss: 1.339115]\n",
      "epoch:43 step:33611[D loss: 0.376984, acc: 64.84%, op_acc: 52.34%] [G loss: 1.330318]\n",
      "epoch:43 step:33612[D loss: 0.388083, acc: 66.41%, op_acc: 55.47%] [G loss: 1.169305]\n",
      "epoch:43 step:33613[D loss: 0.395260, acc: 63.28%, op_acc: 44.53%] [G loss: 1.032358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33614[D loss: 0.387413, acc: 71.09%, op_acc: 42.19%] [G loss: 1.185208]\n",
      "epoch:43 step:33615[D loss: 0.433633, acc: 57.03%, op_acc: 39.84%] [G loss: 1.034550]\n",
      "epoch:43 step:33616[D loss: 0.342656, acc: 71.09%, op_acc: 49.22%] [G loss: 1.157973]\n",
      "epoch:43 step:33617[D loss: 0.337851, acc: 76.56%, op_acc: 48.44%] [G loss: 1.030551]\n",
      "epoch:43 step:33618[D loss: 0.310191, acc: 83.59%, op_acc: 50.78%] [G loss: 1.243969]\n",
      "epoch:43 step:33619[D loss: 0.359826, acc: 69.53%, op_acc: 47.66%] [G loss: 0.986857]\n",
      "epoch:43 step:33620[D loss: 0.397203, acc: 65.62%, op_acc: 44.53%] [G loss: 1.061512]\n",
      "epoch:43 step:33621[D loss: 0.369159, acc: 65.62%, op_acc: 46.88%] [G loss: 1.109315]\n",
      "epoch:43 step:33622[D loss: 0.391887, acc: 61.72%, op_acc: 47.66%] [G loss: 1.294753]\n",
      "epoch:43 step:33623[D loss: 0.441184, acc: 60.16%, op_acc: 43.75%] [G loss: 1.216501]\n",
      "epoch:43 step:33624[D loss: 0.349611, acc: 71.88%, op_acc: 50.00%] [G loss: 1.129440]\n",
      "epoch:43 step:33625[D loss: 0.355674, acc: 68.75%, op_acc: 51.56%] [G loss: 1.069436]\n",
      "epoch:43 step:33626[D loss: 0.425575, acc: 57.81%, op_acc: 40.62%] [G loss: 1.144949]\n",
      "epoch:43 step:33627[D loss: 0.339110, acc: 77.34%, op_acc: 43.75%] [G loss: 1.368653]\n",
      "epoch:43 step:33628[D loss: 0.339943, acc: 74.22%, op_acc: 48.44%] [G loss: 1.153054]\n",
      "epoch:43 step:33629[D loss: 0.356246, acc: 78.12%, op_acc: 47.66%] [G loss: 1.463595]\n",
      "epoch:43 step:33630[D loss: 0.378704, acc: 70.31%, op_acc: 40.62%] [G loss: 1.054893]\n",
      "epoch:43 step:33631[D loss: 0.374109, acc: 70.31%, op_acc: 45.31%] [G loss: 1.424449]\n",
      "epoch:43 step:33632[D loss: 0.347608, acc: 76.56%, op_acc: 44.53%] [G loss: 1.109565]\n",
      "epoch:43 step:33633[D loss: 0.373190, acc: 71.09%, op_acc: 45.31%] [G loss: 1.090712]\n",
      "epoch:43 step:33634[D loss: 0.320533, acc: 75.00%, op_acc: 52.34%] [G loss: 1.153209]\n",
      "epoch:43 step:33635[D loss: 0.322765, acc: 81.25%, op_acc: 47.66%] [G loss: 1.271841]\n",
      "epoch:43 step:33636[D loss: 0.430099, acc: 66.41%, op_acc: 38.28%] [G loss: 1.152786]\n",
      "epoch:43 step:33637[D loss: 0.489694, acc: 54.69%, op_acc: 38.28%] [G loss: 1.225827]\n",
      "epoch:43 step:33638[D loss: 0.446456, acc: 55.47%, op_acc: 46.09%] [G loss: 1.206066]\n",
      "epoch:43 step:33639[D loss: 0.406191, acc: 64.06%, op_acc: 45.31%] [G loss: 1.262824]\n",
      "epoch:43 step:33640[D loss: 0.408328, acc: 70.31%, op_acc: 44.53%] [G loss: 1.067687]\n",
      "epoch:43 step:33641[D loss: 0.377323, acc: 62.50%, op_acc: 49.22%] [G loss: 1.107625]\n",
      "epoch:43 step:33642[D loss: 0.411715, acc: 61.72%, op_acc: 47.66%] [G loss: 1.054338]\n",
      "epoch:43 step:33643[D loss: 0.408395, acc: 64.84%, op_acc: 44.53%] [G loss: 1.087874]\n",
      "epoch:43 step:33644[D loss: 0.383606, acc: 75.78%, op_acc: 42.19%] [G loss: 1.220853]\n",
      "epoch:43 step:33645[D loss: 0.386206, acc: 63.28%, op_acc: 43.75%] [G loss: 1.231622]\n",
      "epoch:43 step:33646[D loss: 0.441905, acc: 61.72%, op_acc: 42.19%] [G loss: 1.013527]\n",
      "epoch:43 step:33647[D loss: 0.357450, acc: 69.53%, op_acc: 48.44%] [G loss: 1.300898]\n",
      "epoch:43 step:33648[D loss: 0.414377, acc: 65.62%, op_acc: 42.97%] [G loss: 1.172737]\n",
      "epoch:43 step:33649[D loss: 0.395858, acc: 66.41%, op_acc: 43.75%] [G loss: 1.190448]\n",
      "epoch:43 step:33650[D loss: 0.311039, acc: 81.25%, op_acc: 43.75%] [G loss: 1.091131]\n",
      "epoch:43 step:33651[D loss: 0.406532, acc: 64.84%, op_acc: 40.62%] [G loss: 1.164147]\n",
      "epoch:43 step:33652[D loss: 0.401133, acc: 60.94%, op_acc: 52.34%] [G loss: 0.981150]\n",
      "epoch:43 step:33653[D loss: 0.335787, acc: 75.00%, op_acc: 47.66%] [G loss: 1.033711]\n",
      "epoch:43 step:33654[D loss: 0.494000, acc: 50.00%, op_acc: 35.94%] [G loss: 1.195619]\n",
      "epoch:43 step:33655[D loss: 0.381806, acc: 70.31%, op_acc: 46.88%] [G loss: 1.153969]\n",
      "epoch:43 step:33656[D loss: 0.454706, acc: 56.25%, op_acc: 39.84%] [G loss: 1.035282]\n",
      "epoch:43 step:33657[D loss: 0.293050, acc: 82.03%, op_acc: 58.59%] [G loss: 1.300989]\n",
      "epoch:43 step:33658[D loss: 0.382712, acc: 71.09%, op_acc: 41.41%] [G loss: 1.111540]\n",
      "epoch:43 step:33659[D loss: 0.395623, acc: 64.84%, op_acc: 41.41%] [G loss: 1.167360]\n",
      "epoch:43 step:33660[D loss: 0.416334, acc: 65.62%, op_acc: 46.09%] [G loss: 1.106991]\n",
      "epoch:43 step:33661[D loss: 0.404129, acc: 66.41%, op_acc: 42.97%] [G loss: 1.164129]\n",
      "epoch:43 step:33662[D loss: 0.311804, acc: 80.47%, op_acc: 49.22%] [G loss: 1.487286]\n",
      "epoch:43 step:33663[D loss: 0.406879, acc: 66.41%, op_acc: 43.75%] [G loss: 1.515811]\n",
      "epoch:43 step:33664[D loss: 0.409819, acc: 65.62%, op_acc: 36.72%] [G loss: 1.165326]\n",
      "epoch:43 step:33665[D loss: 0.368890, acc: 67.97%, op_acc: 53.12%] [G loss: 1.230174]\n",
      "epoch:43 step:33666[D loss: 0.462418, acc: 51.56%, op_acc: 42.97%] [G loss: 1.124740]\n",
      "epoch:43 step:33667[D loss: 0.474014, acc: 54.69%, op_acc: 44.53%] [G loss: 0.951328]\n",
      "epoch:43 step:33668[D loss: 0.463466, acc: 60.94%, op_acc: 38.28%] [G loss: 1.100105]\n",
      "epoch:43 step:33669[D loss: 0.336101, acc: 71.88%, op_acc: 45.31%] [G loss: 1.332235]\n",
      "epoch:43 step:33670[D loss: 0.401089, acc: 68.75%, op_acc: 42.97%] [G loss: 1.402810]\n",
      "epoch:43 step:33671[D loss: 0.414684, acc: 60.16%, op_acc: 42.97%] [G loss: 1.400723]\n",
      "epoch:43 step:33672[D loss: 0.417607, acc: 57.81%, op_acc: 46.88%] [G loss: 1.258203]\n",
      "epoch:43 step:33673[D loss: 0.339406, acc: 75.00%, op_acc: 46.09%] [G loss: 1.187556]\n",
      "epoch:43 step:33674[D loss: 0.390246, acc: 66.41%, op_acc: 46.88%] [G loss: 1.186534]\n",
      "epoch:43 step:33675[D loss: 0.376937, acc: 72.66%, op_acc: 49.22%] [G loss: 1.155758]\n",
      "epoch:43 step:33676[D loss: 0.341087, acc: 71.88%, op_acc: 49.22%] [G loss: 1.327582]\n",
      "epoch:43 step:33677[D loss: 0.339955, acc: 75.00%, op_acc: 47.66%] [G loss: 1.204923]\n",
      "epoch:43 step:33678[D loss: 0.410332, acc: 64.06%, op_acc: 46.88%] [G loss: 1.450532]\n",
      "epoch:43 step:33679[D loss: 0.426152, acc: 63.28%, op_acc: 39.84%] [G loss: 1.251103]\n",
      "epoch:43 step:33680[D loss: 0.352866, acc: 73.44%, op_acc: 47.66%] [G loss: 1.137067]\n",
      "epoch:43 step:33681[D loss: 0.367019, acc: 72.66%, op_acc: 43.75%] [G loss: 1.132521]\n",
      "epoch:43 step:33682[D loss: 0.433756, acc: 60.94%, op_acc: 42.97%] [G loss: 1.243252]\n",
      "epoch:43 step:33683[D loss: 0.344079, acc: 75.78%, op_acc: 49.22%] [G loss: 1.080278]\n",
      "epoch:43 step:33684[D loss: 0.402063, acc: 66.41%, op_acc: 38.28%] [G loss: 1.089834]\n",
      "epoch:43 step:33685[D loss: 0.427485, acc: 60.16%, op_acc: 42.19%] [G loss: 1.140978]\n",
      "epoch:43 step:33686[D loss: 0.444927, acc: 55.47%, op_acc: 43.75%] [G loss: 1.170630]\n",
      "epoch:43 step:33687[D loss: 0.363993, acc: 67.97%, op_acc: 47.66%] [G loss: 1.250846]\n",
      "epoch:43 step:33688[D loss: 0.350264, acc: 74.22%, op_acc: 47.66%] [G loss: 1.333938]\n",
      "epoch:43 step:33689[D loss: 0.404559, acc: 63.28%, op_acc: 49.22%] [G loss: 1.346006]\n",
      "epoch:43 step:33690[D loss: 0.351069, acc: 76.56%, op_acc: 45.31%] [G loss: 1.148872]\n",
      "epoch:43 step:33691[D loss: 0.426145, acc: 61.72%, op_acc: 50.00%] [G loss: 1.325775]\n",
      "epoch:43 step:33692[D loss: 0.388354, acc: 66.41%, op_acc: 41.41%] [G loss: 1.420198]\n",
      "epoch:43 step:33693[D loss: 0.321518, acc: 81.25%, op_acc: 57.03%] [G loss: 1.215995]\n",
      "epoch:43 step:33694[D loss: 0.412359, acc: 69.53%, op_acc: 40.62%] [G loss: 1.121412]\n",
      "epoch:43 step:33695[D loss: 0.423038, acc: 57.81%, op_acc: 42.97%] [G loss: 1.126055]\n",
      "epoch:43 step:33696[D loss: 0.372612, acc: 71.88%, op_acc: 35.16%] [G loss: 1.094309]\n",
      "epoch:43 step:33697[D loss: 0.360419, acc: 69.53%, op_acc: 48.44%] [G loss: 1.141491]\n",
      "epoch:43 step:33698[D loss: 0.404279, acc: 61.72%, op_acc: 39.84%] [G loss: 1.188234]\n",
      "epoch:43 step:33699[D loss: 0.401664, acc: 61.72%, op_acc: 46.09%] [G loss: 1.063479]\n",
      "epoch:43 step:33700[D loss: 0.400564, acc: 58.59%, op_acc: 39.06%] [G loss: 1.126866]\n",
      "epoch:43 step:33701[D loss: 0.406722, acc: 63.28%, op_acc: 46.09%] [G loss: 1.130763]\n",
      "epoch:43 step:33702[D loss: 0.369216, acc: 67.97%, op_acc: 42.19%] [G loss: 1.077683]\n",
      "epoch:43 step:33703[D loss: 0.399354, acc: 63.28%, op_acc: 43.75%] [G loss: 1.218448]\n",
      "epoch:43 step:33704[D loss: 0.402019, acc: 67.19%, op_acc: 40.62%] [G loss: 1.045911]\n",
      "epoch:43 step:33705[D loss: 0.451300, acc: 57.03%, op_acc: 41.41%] [G loss: 1.117188]\n",
      "epoch:43 step:33706[D loss: 0.444118, acc: 64.06%, op_acc: 43.75%] [G loss: 1.265886]\n",
      "epoch:43 step:33707[D loss: 0.408061, acc: 70.31%, op_acc: 46.09%] [G loss: 1.067419]\n",
      "epoch:43 step:33708[D loss: 0.359256, acc: 72.66%, op_acc: 45.31%] [G loss: 1.113863]\n",
      "epoch:43 step:33709[D loss: 0.432540, acc: 57.03%, op_acc: 43.75%] [G loss: 1.107487]\n",
      "epoch:43 step:33710[D loss: 0.400111, acc: 67.97%, op_acc: 46.88%] [G loss: 1.050308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33711[D loss: 0.376562, acc: 67.97%, op_acc: 39.06%] [G loss: 1.123482]\n",
      "epoch:43 step:33712[D loss: 0.405487, acc: 66.41%, op_acc: 44.53%] [G loss: 1.134158]\n",
      "epoch:43 step:33713[D loss: 0.403843, acc: 60.16%, op_acc: 45.31%] [G loss: 1.321248]\n",
      "epoch:43 step:33714[D loss: 0.417063, acc: 66.41%, op_acc: 42.19%] [G loss: 1.215573]\n",
      "epoch:43 step:33715[D loss: 0.273962, acc: 81.25%, op_acc: 51.56%] [G loss: 1.114299]\n",
      "epoch:43 step:33716[D loss: 0.359843, acc: 71.88%, op_acc: 41.41%] [G loss: 1.173427]\n",
      "epoch:43 step:33717[D loss: 0.405009, acc: 64.06%, op_acc: 46.88%] [G loss: 1.122670]\n",
      "epoch:43 step:33718[D loss: 0.405887, acc: 61.72%, op_acc: 50.00%] [G loss: 1.258025]\n",
      "epoch:43 step:33719[D loss: 0.354588, acc: 72.66%, op_acc: 50.78%] [G loss: 1.197092]\n",
      "epoch:43 step:33720[D loss: 0.392585, acc: 66.41%, op_acc: 47.66%] [G loss: 1.116519]\n",
      "epoch:43 step:33721[D loss: 0.410045, acc: 68.75%, op_acc: 35.94%] [G loss: 1.306867]\n",
      "epoch:43 step:33722[D loss: 0.379677, acc: 67.19%, op_acc: 50.78%] [G loss: 1.214137]\n",
      "epoch:43 step:33723[D loss: 0.467860, acc: 58.59%, op_acc: 38.28%] [G loss: 1.142833]\n",
      "epoch:43 step:33724[D loss: 0.384985, acc: 73.44%, op_acc: 42.97%] [G loss: 1.286621]\n",
      "epoch:43 step:33725[D loss: 0.436005, acc: 61.72%, op_acc: 35.16%] [G loss: 1.207514]\n",
      "epoch:43 step:33726[D loss: 0.434600, acc: 63.28%, op_acc: 43.75%] [G loss: 1.204675]\n",
      "epoch:43 step:33727[D loss: 0.412953, acc: 61.72%, op_acc: 45.31%] [G loss: 0.977576]\n",
      "epoch:43 step:33728[D loss: 0.385549, acc: 65.62%, op_acc: 52.34%] [G loss: 1.111940]\n",
      "epoch:43 step:33729[D loss: 0.351378, acc: 71.09%, op_acc: 40.62%] [G loss: 1.208774]\n",
      "epoch:43 step:33730[D loss: 0.415537, acc: 63.28%, op_acc: 39.84%] [G loss: 1.250215]\n",
      "epoch:43 step:33731[D loss: 0.459245, acc: 55.47%, op_acc: 42.97%] [G loss: 1.341582]\n",
      "epoch:43 step:33732[D loss: 0.372863, acc: 67.19%, op_acc: 47.66%] [G loss: 1.383743]\n",
      "epoch:43 step:33733[D loss: 0.408360, acc: 61.72%, op_acc: 42.19%] [G loss: 1.191871]\n",
      "epoch:43 step:33734[D loss: 0.413913, acc: 62.50%, op_acc: 44.53%] [G loss: 1.255485]\n",
      "epoch:43 step:33735[D loss: 0.386279, acc: 67.19%, op_acc: 48.44%] [G loss: 1.484325]\n",
      "epoch:43 step:33736[D loss: 0.342718, acc: 75.78%, op_acc: 46.09%] [G loss: 1.268200]\n",
      "epoch:43 step:33737[D loss: 0.363236, acc: 64.84%, op_acc: 41.41%] [G loss: 1.132769]\n",
      "epoch:43 step:33738[D loss: 0.419847, acc: 62.50%, op_acc: 42.19%] [G loss: 1.019757]\n",
      "epoch:43 step:33739[D loss: 0.344319, acc: 75.00%, op_acc: 50.00%] [G loss: 1.197109]\n",
      "epoch:43 step:33740[D loss: 0.369470, acc: 68.75%, op_acc: 42.19%] [G loss: 1.110757]\n",
      "epoch:43 step:33741[D loss: 0.374881, acc: 63.28%, op_acc: 46.09%] [G loss: 1.220138]\n",
      "epoch:43 step:33742[D loss: 0.368280, acc: 67.97%, op_acc: 48.44%] [G loss: 1.207609]\n",
      "epoch:43 step:33743[D loss: 0.435643, acc: 60.16%, op_acc: 40.62%] [G loss: 1.345365]\n",
      "epoch:43 step:33744[D loss: 0.435924, acc: 65.62%, op_acc: 44.53%] [G loss: 1.327171]\n",
      "epoch:43 step:33745[D loss: 0.417965, acc: 60.16%, op_acc: 50.00%] [G loss: 1.323991]\n",
      "epoch:43 step:33746[D loss: 0.408544, acc: 65.62%, op_acc: 42.97%] [G loss: 1.382584]\n",
      "epoch:43 step:33747[D loss: 0.334154, acc: 78.91%, op_acc: 47.66%] [G loss: 1.346541]\n",
      "epoch:43 step:33748[D loss: 0.387918, acc: 61.72%, op_acc: 53.12%] [G loss: 1.228944]\n",
      "epoch:43 step:33749[D loss: 0.385861, acc: 69.53%, op_acc: 46.09%] [G loss: 1.216543]\n",
      "epoch:43 step:33750[D loss: 0.373528, acc: 71.88%, op_acc: 44.53%] [G loss: 1.170943]\n",
      "epoch:43 step:33751[D loss: 0.395345, acc: 64.84%, op_acc: 42.19%] [G loss: 1.103501]\n",
      "epoch:43 step:33752[D loss: 0.403954, acc: 67.97%, op_acc: 48.44%] [G loss: 1.297958]\n",
      "epoch:43 step:33753[D loss: 0.405411, acc: 69.53%, op_acc: 46.09%] [G loss: 0.966616]\n",
      "epoch:43 step:33754[D loss: 0.447784, acc: 64.06%, op_acc: 33.59%] [G loss: 0.996995]\n",
      "epoch:43 step:33755[D loss: 0.378733, acc: 65.62%, op_acc: 47.66%] [G loss: 1.082711]\n",
      "epoch:43 step:33756[D loss: 0.404973, acc: 67.97%, op_acc: 42.97%] [G loss: 0.949240]\n",
      "epoch:43 step:33757[D loss: 0.449579, acc: 59.38%, op_acc: 40.62%] [G loss: 1.116157]\n",
      "epoch:43 step:33758[D loss: 0.342186, acc: 77.34%, op_acc: 45.31%] [G loss: 1.343538]\n",
      "epoch:43 step:33759[D loss: 0.423986, acc: 57.81%, op_acc: 43.75%] [G loss: 0.987989]\n",
      "epoch:43 step:33760[D loss: 0.345829, acc: 75.00%, op_acc: 46.09%] [G loss: 1.264740]\n",
      "epoch:43 step:33761[D loss: 0.392004, acc: 68.75%, op_acc: 40.62%] [G loss: 1.199471]\n",
      "epoch:43 step:33762[D loss: 0.427650, acc: 62.50%, op_acc: 42.97%] [G loss: 1.128187]\n",
      "epoch:43 step:33763[D loss: 0.395134, acc: 67.19%, op_acc: 42.19%] [G loss: 1.027000]\n",
      "epoch:43 step:33764[D loss: 0.370909, acc: 65.62%, op_acc: 47.66%] [G loss: 1.252533]\n",
      "epoch:43 step:33765[D loss: 0.324014, acc: 78.91%, op_acc: 58.59%] [G loss: 1.352453]\n",
      "epoch:43 step:33766[D loss: 0.332301, acc: 75.78%, op_acc: 51.56%] [G loss: 1.328615]\n",
      "epoch:43 step:33767[D loss: 0.324378, acc: 78.91%, op_acc: 49.22%] [G loss: 1.462165]\n",
      "epoch:43 step:33768[D loss: 0.352811, acc: 76.56%, op_acc: 41.41%] [G loss: 1.387301]\n",
      "epoch:43 step:33769[D loss: 0.397675, acc: 69.53%, op_acc: 39.84%] [G loss: 1.154800]\n",
      "epoch:43 step:33770[D loss: 0.404942, acc: 67.97%, op_acc: 39.06%] [G loss: 1.061645]\n",
      "epoch:43 step:33771[D loss: 0.442039, acc: 59.38%, op_acc: 39.06%] [G loss: 1.198137]\n",
      "epoch:43 step:33772[D loss: 0.330646, acc: 78.12%, op_acc: 47.66%] [G loss: 1.080552]\n",
      "epoch:43 step:33773[D loss: 0.489899, acc: 52.34%, op_acc: 35.16%] [G loss: 0.997323]\n",
      "epoch:43 step:33774[D loss: 0.407066, acc: 64.84%, op_acc: 41.41%] [G loss: 1.084432]\n",
      "epoch:43 step:33775[D loss: 0.366158, acc: 72.66%, op_acc: 43.75%] [G loss: 1.061676]\n",
      "epoch:43 step:33776[D loss: 0.442173, acc: 62.50%, op_acc: 37.50%] [G loss: 1.174270]\n",
      "epoch:43 step:33777[D loss: 0.356316, acc: 68.75%, op_acc: 50.78%] [G loss: 1.111833]\n",
      "epoch:43 step:33778[D loss: 0.427091, acc: 60.16%, op_acc: 42.19%] [G loss: 1.261569]\n",
      "epoch:43 step:33779[D loss: 0.360916, acc: 72.66%, op_acc: 45.31%] [G loss: 1.101030]\n",
      "epoch:43 step:33780[D loss: 0.441754, acc: 60.94%, op_acc: 39.06%] [G loss: 1.076340]\n",
      "epoch:43 step:33781[D loss: 0.438465, acc: 60.94%, op_acc: 39.06%] [G loss: 1.202367]\n",
      "epoch:43 step:33782[D loss: 0.383681, acc: 73.44%, op_acc: 42.19%] [G loss: 1.131444]\n",
      "epoch:43 step:33783[D loss: 0.370877, acc: 68.75%, op_acc: 42.97%] [G loss: 1.011946]\n",
      "epoch:43 step:33784[D loss: 0.368132, acc: 72.66%, op_acc: 49.22%] [G loss: 1.216772]\n",
      "epoch:43 step:33785[D loss: 0.347894, acc: 77.34%, op_acc: 45.31%] [G loss: 1.364366]\n",
      "epoch:43 step:33786[D loss: 0.464459, acc: 55.47%, op_acc: 42.97%] [G loss: 1.177664]\n",
      "epoch:43 step:33787[D loss: 0.429347, acc: 62.50%, op_acc: 43.75%] [G loss: 1.128251]\n",
      "epoch:43 step:33788[D loss: 0.408367, acc: 65.62%, op_acc: 39.84%] [G loss: 1.226033]\n",
      "epoch:43 step:33789[D loss: 0.409686, acc: 61.72%, op_acc: 48.44%] [G loss: 1.222181]\n",
      "epoch:43 step:33790[D loss: 0.380162, acc: 67.19%, op_acc: 46.09%] [G loss: 1.392546]\n",
      "epoch:43 step:33791[D loss: 0.397648, acc: 67.19%, op_acc: 44.53%] [G loss: 1.231235]\n",
      "epoch:43 step:33792[D loss: 0.372072, acc: 73.44%, op_acc: 46.88%] [G loss: 1.408781]\n",
      "epoch:43 step:33793[D loss: 0.423343, acc: 64.84%, op_acc: 46.09%] [G loss: 1.034834]\n",
      "epoch:43 step:33794[D loss: 0.385934, acc: 69.53%, op_acc: 45.31%] [G loss: 1.163402]\n",
      "epoch:43 step:33795[D loss: 0.383855, acc: 70.31%, op_acc: 41.41%] [G loss: 1.232315]\n",
      "epoch:43 step:33796[D loss: 0.419093, acc: 58.59%, op_acc: 42.19%] [G loss: 1.338545]\n",
      "epoch:43 step:33797[D loss: 0.389588, acc: 64.84%, op_acc: 39.06%] [G loss: 1.257410]\n",
      "epoch:43 step:33798[D loss: 0.462935, acc: 52.34%, op_acc: 38.28%] [G loss: 1.139238]\n",
      "epoch:43 step:33799[D loss: 0.383935, acc: 67.19%, op_acc: 39.06%] [G loss: 1.088528]\n",
      "epoch:43 step:33800[D loss: 0.392848, acc: 64.84%, op_acc: 47.66%] [G loss: 1.308296]\n",
      "epoch:43 step:33801[D loss: 0.389544, acc: 67.97%, op_acc: 46.88%] [G loss: 1.487298]\n",
      "epoch:43 step:33802[D loss: 0.346420, acc: 75.78%, op_acc: 48.44%] [G loss: 1.263594]\n",
      "epoch:43 step:33803[D loss: 0.413961, acc: 66.41%, op_acc: 49.22%] [G loss: 1.268283]\n",
      "epoch:43 step:33804[D loss: 0.399375, acc: 63.28%, op_acc: 39.84%] [G loss: 1.066314]\n",
      "epoch:43 step:33805[D loss: 0.364378, acc: 68.75%, op_acc: 45.31%] [G loss: 1.066918]\n",
      "epoch:43 step:33806[D loss: 0.420547, acc: 57.81%, op_acc: 49.22%] [G loss: 1.363968]\n",
      "epoch:43 step:33807[D loss: 0.431524, acc: 59.38%, op_acc: 48.44%] [G loss: 1.286557]\n",
      "epoch:43 step:33808[D loss: 0.412756, acc: 67.97%, op_acc: 41.41%] [G loss: 1.314393]\n",
      "epoch:43 step:33809[D loss: 0.376176, acc: 73.44%, op_acc: 48.44%] [G loss: 1.120629]\n",
      "epoch:43 step:33810[D loss: 0.337294, acc: 78.91%, op_acc: 41.41%] [G loss: 1.420774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33811[D loss: 0.401075, acc: 60.16%, op_acc: 41.41%] [G loss: 1.347861]\n",
      "epoch:43 step:33812[D loss: 0.396871, acc: 63.28%, op_acc: 46.09%] [G loss: 1.193248]\n",
      "epoch:43 step:33813[D loss: 0.406885, acc: 65.62%, op_acc: 39.84%] [G loss: 1.073469]\n",
      "epoch:43 step:33814[D loss: 0.417853, acc: 65.62%, op_acc: 37.50%] [G loss: 1.100728]\n",
      "epoch:43 step:33815[D loss: 0.379204, acc: 67.19%, op_acc: 46.09%] [G loss: 1.120928]\n",
      "epoch:43 step:33816[D loss: 0.345936, acc: 70.31%, op_acc: 47.66%] [G loss: 1.261427]\n",
      "epoch:43 step:33817[D loss: 0.470416, acc: 57.81%, op_acc: 39.06%] [G loss: 1.195049]\n",
      "epoch:43 step:33818[D loss: 0.390189, acc: 65.62%, op_acc: 45.31%] [G loss: 1.047368]\n",
      "epoch:43 step:33819[D loss: 0.406696, acc: 65.62%, op_acc: 46.09%] [G loss: 1.250508]\n",
      "epoch:43 step:33820[D loss: 0.372243, acc: 66.41%, op_acc: 46.88%] [G loss: 1.222499]\n",
      "epoch:43 step:33821[D loss: 0.374154, acc: 71.09%, op_acc: 47.66%] [G loss: 1.385228]\n",
      "epoch:43 step:33822[D loss: 0.400160, acc: 68.75%, op_acc: 44.53%] [G loss: 1.176266]\n",
      "epoch:43 step:33823[D loss: 0.396940, acc: 60.16%, op_acc: 44.53%] [G loss: 1.206706]\n",
      "epoch:43 step:33824[D loss: 0.390988, acc: 67.19%, op_acc: 45.31%] [G loss: 1.001935]\n",
      "epoch:43 step:33825[D loss: 0.376354, acc: 71.09%, op_acc: 46.88%] [G loss: 1.190067]\n",
      "epoch:43 step:33826[D loss: 0.420770, acc: 59.38%, op_acc: 50.00%] [G loss: 1.130547]\n",
      "epoch:43 step:33827[D loss: 0.389243, acc: 70.31%, op_acc: 44.53%] [G loss: 1.205097]\n",
      "epoch:43 step:33828[D loss: 0.427528, acc: 57.81%, op_acc: 47.66%] [G loss: 1.043902]\n",
      "epoch:43 step:33829[D loss: 0.380138, acc: 71.09%, op_acc: 46.09%] [G loss: 1.113000]\n",
      "epoch:43 step:33830[D loss: 0.373998, acc: 64.84%, op_acc: 42.97%] [G loss: 0.977882]\n",
      "epoch:43 step:33831[D loss: 0.429756, acc: 64.84%, op_acc: 42.19%] [G loss: 1.150694]\n",
      "epoch:43 step:33832[D loss: 0.392037, acc: 67.97%, op_acc: 37.50%] [G loss: 1.045747]\n",
      "epoch:43 step:33833[D loss: 0.440521, acc: 59.38%, op_acc: 46.09%] [G loss: 1.177660]\n",
      "epoch:43 step:33834[D loss: 0.404266, acc: 61.72%, op_acc: 42.19%] [G loss: 1.160212]\n",
      "epoch:43 step:33835[D loss: 0.366097, acc: 70.31%, op_acc: 42.19%] [G loss: 1.247830]\n",
      "epoch:43 step:33836[D loss: 0.465795, acc: 52.34%, op_acc: 39.06%] [G loss: 1.272856]\n",
      "epoch:43 step:33837[D loss: 0.406952, acc: 67.19%, op_acc: 38.28%] [G loss: 1.089390]\n",
      "epoch:43 step:33838[D loss: 0.451436, acc: 62.50%, op_acc: 41.41%] [G loss: 1.313691]\n",
      "epoch:43 step:33839[D loss: 0.396350, acc: 63.28%, op_acc: 48.44%] [G loss: 1.220546]\n",
      "epoch:43 step:33840[D loss: 0.381144, acc: 68.75%, op_acc: 41.41%] [G loss: 1.033492]\n",
      "epoch:43 step:33841[D loss: 0.386763, acc: 63.28%, op_acc: 43.75%] [G loss: 1.061195]\n",
      "epoch:43 step:33842[D loss: 0.382790, acc: 71.88%, op_acc: 41.41%] [G loss: 1.190248]\n",
      "epoch:43 step:33843[D loss: 0.435630, acc: 55.47%, op_acc: 40.62%] [G loss: 1.188329]\n",
      "epoch:43 step:33844[D loss: 0.355132, acc: 69.53%, op_acc: 50.00%] [G loss: 1.113469]\n",
      "epoch:43 step:33845[D loss: 0.394157, acc: 67.97%, op_acc: 46.88%] [G loss: 1.136441]\n",
      "epoch:43 step:33846[D loss: 0.338377, acc: 78.12%, op_acc: 44.53%] [G loss: 1.266178]\n",
      "epoch:43 step:33847[D loss: 0.362868, acc: 67.97%, op_acc: 52.34%] [G loss: 1.217461]\n",
      "epoch:43 step:33848[D loss: 0.406853, acc: 65.62%, op_acc: 46.09%] [G loss: 1.287023]\n",
      "epoch:43 step:33849[D loss: 0.374024, acc: 63.28%, op_acc: 48.44%] [G loss: 1.343237]\n",
      "epoch:43 step:33850[D loss: 0.477189, acc: 57.81%, op_acc: 38.28%] [G loss: 1.343941]\n",
      "epoch:43 step:33851[D loss: 0.411861, acc: 63.28%, op_acc: 42.97%] [G loss: 1.314702]\n",
      "epoch:43 step:33852[D loss: 0.396129, acc: 61.72%, op_acc: 46.09%] [G loss: 0.907869]\n",
      "epoch:43 step:33853[D loss: 0.420738, acc: 61.72%, op_acc: 38.28%] [G loss: 1.125988]\n",
      "epoch:43 step:33854[D loss: 0.410168, acc: 68.75%, op_acc: 44.53%] [G loss: 1.184964]\n",
      "epoch:43 step:33855[D loss: 0.370214, acc: 72.66%, op_acc: 44.53%] [G loss: 1.116704]\n",
      "epoch:43 step:33856[D loss: 0.420382, acc: 66.41%, op_acc: 42.97%] [G loss: 1.213289]\n",
      "epoch:43 step:33857[D loss: 0.389728, acc: 61.72%, op_acc: 50.78%] [G loss: 1.135594]\n",
      "epoch:43 step:33858[D loss: 0.469274, acc: 54.69%, op_acc: 40.62%] [G loss: 1.070864]\n",
      "epoch:43 step:33859[D loss: 0.408678, acc: 64.84%, op_acc: 43.75%] [G loss: 1.214368]\n",
      "epoch:43 step:33860[D loss: 0.353238, acc: 72.66%, op_acc: 45.31%] [G loss: 1.199973]\n",
      "epoch:43 step:33861[D loss: 0.408277, acc: 63.28%, op_acc: 45.31%] [G loss: 1.104918]\n",
      "epoch:43 step:33862[D loss: 0.353207, acc: 75.00%, op_acc: 49.22%] [G loss: 1.401145]\n",
      "epoch:43 step:33863[D loss: 0.390576, acc: 66.41%, op_acc: 42.97%] [G loss: 1.137716]\n",
      "epoch:43 step:33864[D loss: 0.440778, acc: 58.59%, op_acc: 44.53%] [G loss: 1.225529]\n",
      "epoch:43 step:33865[D loss: 0.430335, acc: 67.19%, op_acc: 38.28%] [G loss: 1.134593]\n",
      "epoch:43 step:33866[D loss: 0.364138, acc: 70.31%, op_acc: 48.44%] [G loss: 1.083222]\n",
      "epoch:43 step:33867[D loss: 0.356745, acc: 74.22%, op_acc: 45.31%] [G loss: 1.231401]\n",
      "epoch:43 step:33868[D loss: 0.437293, acc: 58.59%, op_acc: 40.62%] [G loss: 1.146444]\n",
      "epoch:43 step:33869[D loss: 0.381088, acc: 71.09%, op_acc: 46.88%] [G loss: 1.179742]\n",
      "epoch:43 step:33870[D loss: 0.410719, acc: 67.97%, op_acc: 39.84%] [G loss: 1.057956]\n",
      "epoch:43 step:33871[D loss: 0.377332, acc: 66.41%, op_acc: 44.53%] [G loss: 1.021061]\n",
      "epoch:43 step:33872[D loss: 0.379334, acc: 66.41%, op_acc: 40.62%] [G loss: 1.117496]\n",
      "epoch:43 step:33873[D loss: 0.376121, acc: 70.31%, op_acc: 46.09%] [G loss: 0.955294]\n",
      "epoch:43 step:33874[D loss: 0.433541, acc: 57.03%, op_acc: 42.19%] [G loss: 1.170824]\n",
      "epoch:43 step:33875[D loss: 0.427841, acc: 61.72%, op_acc: 40.62%] [G loss: 1.316422]\n",
      "epoch:43 step:33876[D loss: 0.413821, acc: 60.16%, op_acc: 40.62%] [G loss: 1.082822]\n",
      "epoch:43 step:33877[D loss: 0.424594, acc: 69.53%, op_acc: 42.97%] [G loss: 1.154909]\n",
      "epoch:43 step:33878[D loss: 0.397625, acc: 64.06%, op_acc: 46.09%] [G loss: 1.046873]\n",
      "epoch:43 step:33879[D loss: 0.351836, acc: 66.41%, op_acc: 49.22%] [G loss: 1.091412]\n",
      "epoch:43 step:33880[D loss: 0.397340, acc: 63.28%, op_acc: 43.75%] [G loss: 1.003615]\n",
      "epoch:43 step:33881[D loss: 0.388100, acc: 67.97%, op_acc: 43.75%] [G loss: 1.113199]\n",
      "epoch:43 step:33882[D loss: 0.368087, acc: 75.00%, op_acc: 45.31%] [G loss: 1.148937]\n",
      "epoch:43 step:33883[D loss: 0.422813, acc: 64.06%, op_acc: 42.97%] [G loss: 1.239286]\n",
      "epoch:43 step:33884[D loss: 0.400724, acc: 65.62%, op_acc: 42.97%] [G loss: 1.131956]\n",
      "epoch:43 step:33885[D loss: 0.375476, acc: 69.53%, op_acc: 44.53%] [G loss: 1.269052]\n",
      "epoch:43 step:33886[D loss: 0.365080, acc: 68.75%, op_acc: 53.12%] [G loss: 1.184083]\n",
      "epoch:43 step:33887[D loss: 0.390361, acc: 64.84%, op_acc: 46.09%] [G loss: 1.011702]\n",
      "epoch:43 step:33888[D loss: 0.371647, acc: 70.31%, op_acc: 47.66%] [G loss: 1.064188]\n",
      "epoch:43 step:33889[D loss: 0.424172, acc: 65.62%, op_acc: 47.66%] [G loss: 1.224342]\n",
      "epoch:43 step:33890[D loss: 0.385140, acc: 67.19%, op_acc: 43.75%] [G loss: 1.219810]\n",
      "epoch:43 step:33891[D loss: 0.388785, acc: 68.75%, op_acc: 43.75%] [G loss: 1.176924]\n",
      "epoch:43 step:33892[D loss: 0.478001, acc: 56.25%, op_acc: 35.94%] [G loss: 1.041260]\n",
      "epoch:43 step:33893[D loss: 0.350026, acc: 71.88%, op_acc: 39.06%] [G loss: 1.264657]\n",
      "epoch:43 step:33894[D loss: 0.374566, acc: 72.66%, op_acc: 46.09%] [G loss: 1.199631]\n",
      "epoch:43 step:33895[D loss: 0.469196, acc: 53.91%, op_acc: 41.41%] [G loss: 1.091170]\n",
      "epoch:43 step:33896[D loss: 0.428195, acc: 59.38%, op_acc: 40.62%] [G loss: 1.192026]\n",
      "epoch:43 step:33897[D loss: 0.364351, acc: 73.44%, op_acc: 47.66%] [G loss: 1.180136]\n",
      "epoch:43 step:33898[D loss: 0.457104, acc: 56.25%, op_acc: 39.06%] [G loss: 0.979976]\n",
      "epoch:43 step:33899[D loss: 0.415337, acc: 65.62%, op_acc: 37.50%] [G loss: 1.131498]\n",
      "epoch:43 step:33900[D loss: 0.424929, acc: 60.94%, op_acc: 42.19%] [G loss: 1.153909]\n",
      "epoch:43 step:33901[D loss: 0.452980, acc: 53.91%, op_acc: 35.94%] [G loss: 1.082523]\n",
      "epoch:43 step:33902[D loss: 0.383106, acc: 67.19%, op_acc: 42.97%] [G loss: 1.080005]\n",
      "epoch:43 step:33903[D loss: 0.340899, acc: 75.78%, op_acc: 48.44%] [G loss: 1.491823]\n",
      "epoch:43 step:33904[D loss: 0.416628, acc: 58.59%, op_acc: 44.53%] [G loss: 1.212644]\n",
      "epoch:43 step:33905[D loss: 0.371212, acc: 68.75%, op_acc: 49.22%] [G loss: 1.155225]\n",
      "epoch:43 step:33906[D loss: 0.411562, acc: 62.50%, op_acc: 46.88%] [G loss: 1.178285]\n",
      "epoch:43 step:33907[D loss: 0.400403, acc: 66.41%, op_acc: 42.19%] [G loss: 1.298169]\n",
      "epoch:43 step:33908[D loss: 0.385412, acc: 66.41%, op_acc: 40.62%] [G loss: 1.086642]\n",
      "epoch:43 step:33909[D loss: 0.436624, acc: 58.59%, op_acc: 43.75%] [G loss: 1.259371]\n",
      "epoch:43 step:33910[D loss: 0.365296, acc: 71.09%, op_acc: 41.41%] [G loss: 1.253488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:33911[D loss: 0.413328, acc: 67.97%, op_acc: 41.41%] [G loss: 1.101964]\n",
      "epoch:43 step:33912[D loss: 0.373176, acc: 72.66%, op_acc: 53.12%] [G loss: 1.246014]\n",
      "epoch:43 step:33913[D loss: 0.367728, acc: 61.72%, op_acc: 44.53%] [G loss: 1.198766]\n",
      "epoch:43 step:33914[D loss: 0.369992, acc: 70.31%, op_acc: 53.12%] [G loss: 1.092285]\n",
      "epoch:43 step:33915[D loss: 0.385691, acc: 65.62%, op_acc: 40.62%] [G loss: 1.155728]\n",
      "epoch:43 step:33916[D loss: 0.320388, acc: 79.69%, op_acc: 46.88%] [G loss: 1.245585]\n",
      "epoch:43 step:33917[D loss: 0.366538, acc: 69.53%, op_acc: 50.78%] [G loss: 1.173732]\n",
      "epoch:43 step:33918[D loss: 0.492046, acc: 53.91%, op_acc: 35.16%] [G loss: 1.014825]\n",
      "epoch:43 step:33919[D loss: 0.373096, acc: 71.88%, op_acc: 48.44%] [G loss: 1.129146]\n",
      "epoch:43 step:33920[D loss: 0.448219, acc: 63.28%, op_acc: 37.50%] [G loss: 1.166170]\n",
      "epoch:43 step:33921[D loss: 0.338957, acc: 75.00%, op_acc: 47.66%] [G loss: 1.174259]\n",
      "epoch:43 step:33922[D loss: 0.339018, acc: 76.56%, op_acc: 53.91%] [G loss: 1.149971]\n",
      "epoch:43 step:33923[D loss: 0.372306, acc: 71.88%, op_acc: 43.75%] [G loss: 1.271655]\n",
      "epoch:43 step:33924[D loss: 0.368898, acc: 71.88%, op_acc: 43.75%] [G loss: 1.169921]\n",
      "epoch:43 step:33925[D loss: 0.322547, acc: 78.12%, op_acc: 46.09%] [G loss: 1.140600]\n",
      "epoch:43 step:33926[D loss: 0.412799, acc: 67.97%, op_acc: 45.31%] [G loss: 0.909470]\n",
      "epoch:43 step:33927[D loss: 0.394912, acc: 67.19%, op_acc: 42.97%] [G loss: 1.163818]\n",
      "epoch:43 step:33928[D loss: 0.356822, acc: 71.09%, op_acc: 45.31%] [G loss: 1.226541]\n",
      "epoch:43 step:33929[D loss: 0.419048, acc: 59.38%, op_acc: 41.41%] [G loss: 1.253257]\n",
      "epoch:43 step:33930[D loss: 0.446546, acc: 53.12%, op_acc: 49.22%] [G loss: 1.091610]\n",
      "epoch:43 step:33931[D loss: 0.418446, acc: 62.50%, op_acc: 36.72%] [G loss: 1.134687]\n",
      "epoch:43 step:33932[D loss: 0.415727, acc: 60.16%, op_acc: 45.31%] [G loss: 1.264919]\n",
      "epoch:43 step:33933[D loss: 0.340027, acc: 73.44%, op_acc: 46.88%] [G loss: 1.376402]\n",
      "epoch:43 step:33934[D loss: 0.381775, acc: 67.19%, op_acc: 42.19%] [G loss: 1.291600]\n",
      "epoch:43 step:33935[D loss: 0.386928, acc: 67.19%, op_acc: 42.97%] [G loss: 1.244087]\n",
      "epoch:43 step:33936[D loss: 0.363441, acc: 62.50%, op_acc: 59.38%] [G loss: 1.252598]\n",
      "epoch:43 step:33937[D loss: 0.455447, acc: 57.81%, op_acc: 39.84%] [G loss: 1.118408]\n",
      "epoch:43 step:33938[D loss: 0.386207, acc: 64.84%, op_acc: 42.97%] [G loss: 1.037492]\n",
      "epoch:43 step:33939[D loss: 0.393731, acc: 64.06%, op_acc: 36.72%] [G loss: 1.197996]\n",
      "epoch:43 step:33940[D loss: 0.420555, acc: 64.84%, op_acc: 40.62%] [G loss: 1.165967]\n",
      "epoch:43 step:33941[D loss: 0.371985, acc: 71.88%, op_acc: 45.31%] [G loss: 1.247374]\n",
      "epoch:43 step:33942[D loss: 0.361940, acc: 72.66%, op_acc: 41.41%] [G loss: 1.327730]\n",
      "epoch:43 step:33943[D loss: 0.411970, acc: 65.62%, op_acc: 47.66%] [G loss: 1.167413]\n",
      "epoch:43 step:33944[D loss: 0.409768, acc: 60.16%, op_acc: 48.44%] [G loss: 1.181762]\n",
      "epoch:43 step:33945[D loss: 0.382780, acc: 68.75%, op_acc: 44.53%] [G loss: 1.166375]\n",
      "epoch:43 step:33946[D loss: 0.351733, acc: 77.34%, op_acc: 53.12%] [G loss: 1.150821]\n",
      "epoch:43 step:33947[D loss: 0.379375, acc: 69.53%, op_acc: 47.66%] [G loss: 1.421359]\n",
      "epoch:43 step:33948[D loss: 0.308442, acc: 80.47%, op_acc: 50.00%] [G loss: 1.427787]\n",
      "epoch:43 step:33949[D loss: 0.367821, acc: 70.31%, op_acc: 44.53%] [G loss: 1.206053]\n",
      "epoch:43 step:33950[D loss: 0.413429, acc: 65.62%, op_acc: 37.50%] [G loss: 1.298872]\n",
      "epoch:43 step:33951[D loss: 0.341410, acc: 72.66%, op_acc: 51.56%] [G loss: 1.104349]\n",
      "epoch:43 step:33952[D loss: 0.416626, acc: 57.03%, op_acc: 46.88%] [G loss: 1.192341]\n",
      "epoch:43 step:33953[D loss: 0.400710, acc: 65.62%, op_acc: 41.41%] [G loss: 1.257836]\n",
      "epoch:43 step:33954[D loss: 0.394458, acc: 67.97%, op_acc: 50.78%] [G loss: 0.990968]\n",
      "epoch:43 step:33955[D loss: 0.382322, acc: 65.62%, op_acc: 52.34%] [G loss: 1.134293]\n",
      "epoch:43 step:33956[D loss: 0.413422, acc: 58.59%, op_acc: 43.75%] [G loss: 1.076713]\n",
      "epoch:43 step:33957[D loss: 0.404006, acc: 65.62%, op_acc: 45.31%] [G loss: 1.270037]\n",
      "epoch:43 step:33958[D loss: 0.382072, acc: 67.19%, op_acc: 43.75%] [G loss: 1.169694]\n",
      "epoch:43 step:33959[D loss: 0.362920, acc: 73.44%, op_acc: 46.09%] [G loss: 1.169677]\n",
      "epoch:43 step:33960[D loss: 0.396370, acc: 68.75%, op_acc: 49.22%] [G loss: 1.026926]\n",
      "epoch:43 step:33961[D loss: 0.410416, acc: 66.41%, op_acc: 41.41%] [G loss: 1.129350]\n",
      "epoch:43 step:33962[D loss: 0.377590, acc: 69.53%, op_acc: 42.19%] [G loss: 1.144331]\n",
      "epoch:43 step:33963[D loss: 0.365593, acc: 67.19%, op_acc: 49.22%] [G loss: 1.186308]\n",
      "epoch:43 step:33964[D loss: 0.352708, acc: 78.12%, op_acc: 46.09%] [G loss: 1.513245]\n",
      "epoch:43 step:33965[D loss: 0.403046, acc: 67.19%, op_acc: 40.62%] [G loss: 1.049570]\n",
      "epoch:43 step:33966[D loss: 0.356442, acc: 71.09%, op_acc: 43.75%] [G loss: 1.084575]\n",
      "epoch:43 step:33967[D loss: 0.411309, acc: 62.50%, op_acc: 48.44%] [G loss: 1.236869]\n",
      "epoch:43 step:33968[D loss: 0.381099, acc: 69.53%, op_acc: 46.88%] [G loss: 1.194124]\n",
      "epoch:43 step:33969[D loss: 0.379786, acc: 66.41%, op_acc: 47.66%] [G loss: 1.160876]\n",
      "epoch:43 step:33970[D loss: 0.428658, acc: 63.28%, op_acc: 44.53%] [G loss: 1.332914]\n",
      "epoch:43 step:33971[D loss: 0.409977, acc: 68.75%, op_acc: 44.53%] [G loss: 1.196782]\n",
      "epoch:43 step:33972[D loss: 0.405539, acc: 63.28%, op_acc: 48.44%] [G loss: 1.224013]\n",
      "epoch:43 step:33973[D loss: 0.364981, acc: 70.31%, op_acc: 42.19%] [G loss: 1.337331]\n",
      "epoch:43 step:33974[D loss: 0.374945, acc: 66.41%, op_acc: 50.78%] [G loss: 1.176971]\n",
      "epoch:43 step:33975[D loss: 0.340248, acc: 74.22%, op_acc: 49.22%] [G loss: 1.181043]\n",
      "epoch:43 step:33976[D loss: 0.436233, acc: 62.50%, op_acc: 46.88%] [G loss: 1.090597]\n",
      "epoch:43 step:33977[D loss: 0.389063, acc: 67.19%, op_acc: 44.53%] [G loss: 1.058348]\n",
      "epoch:43 step:33978[D loss: 0.417170, acc: 66.41%, op_acc: 39.06%] [G loss: 1.105171]\n",
      "epoch:43 step:33979[D loss: 0.355689, acc: 76.56%, op_acc: 50.00%] [G loss: 1.334531]\n",
      "epoch:43 step:33980[D loss: 0.481054, acc: 50.78%, op_acc: 39.84%] [G loss: 1.125048]\n",
      "epoch:43 step:33981[D loss: 0.394822, acc: 67.97%, op_acc: 51.56%] [G loss: 1.267689]\n",
      "epoch:43 step:33982[D loss: 0.365679, acc: 70.31%, op_acc: 43.75%] [G loss: 1.092518]\n",
      "epoch:43 step:33983[D loss: 0.344653, acc: 72.66%, op_acc: 43.75%] [G loss: 1.072385]\n",
      "epoch:43 step:33984[D loss: 0.443266, acc: 58.59%, op_acc: 41.41%] [G loss: 1.004173]\n",
      "epoch:43 step:33985[D loss: 0.308142, acc: 78.12%, op_acc: 47.66%] [G loss: 1.254190]\n",
      "epoch:43 step:33986[D loss: 0.417485, acc: 60.94%, op_acc: 42.19%] [G loss: 1.236979]\n",
      "epoch:43 step:33987[D loss: 0.379875, acc: 64.06%, op_acc: 51.56%] [G loss: 1.038753]\n",
      "epoch:43 step:33988[D loss: 0.407027, acc: 66.41%, op_acc: 50.78%] [G loss: 1.286251]\n",
      "epoch:43 step:33989[D loss: 0.371623, acc: 70.31%, op_acc: 48.44%] [G loss: 1.178924]\n",
      "epoch:43 step:33990[D loss: 0.373739, acc: 66.41%, op_acc: 51.56%] [G loss: 1.117238]\n",
      "epoch:43 step:33991[D loss: 0.372396, acc: 66.41%, op_acc: 50.78%] [G loss: 1.149475]\n",
      "epoch:43 step:33992[D loss: 0.414396, acc: 66.41%, op_acc: 44.53%] [G loss: 0.895261]\n",
      "epoch:43 step:33993[D loss: 0.448759, acc: 57.81%, op_acc: 39.06%] [G loss: 1.001163]\n",
      "epoch:43 step:33994[D loss: 0.421955, acc: 60.94%, op_acc: 39.84%] [G loss: 1.135026]\n",
      "epoch:43 step:33995[D loss: 0.343347, acc: 72.66%, op_acc: 49.22%] [G loss: 1.272040]\n",
      "epoch:43 step:33996[D loss: 0.395549, acc: 64.84%, op_acc: 39.84%] [G loss: 1.115903]\n",
      "epoch:43 step:33997[D loss: 0.350322, acc: 73.44%, op_acc: 41.41%] [G loss: 1.134501]\n",
      "epoch:43 step:33998[D loss: 0.370696, acc: 69.53%, op_acc: 46.09%] [G loss: 1.186685]\n",
      "epoch:43 step:33999[D loss: 0.393472, acc: 67.97%, op_acc: 44.53%] [G loss: 1.187937]\n",
      "epoch:43 step:34000[D loss: 0.408974, acc: 66.41%, op_acc: 43.75%] [G loss: 1.035380]\n",
      "epoch:43 step:34001[D loss: 0.343070, acc: 75.78%, op_acc: 40.62%] [G loss: 1.214285]\n",
      "epoch:43 step:34002[D loss: 0.395237, acc: 67.97%, op_acc: 38.28%] [G loss: 1.123968]\n",
      "epoch:43 step:34003[D loss: 0.419755, acc: 59.38%, op_acc: 44.53%] [G loss: 1.076026]\n",
      "epoch:43 step:34004[D loss: 0.468262, acc: 57.03%, op_acc: 39.84%] [G loss: 1.074048]\n",
      "epoch:43 step:34005[D loss: 0.357785, acc: 72.66%, op_acc: 46.88%] [G loss: 1.216380]\n",
      "epoch:43 step:34006[D loss: 0.435554, acc: 63.28%, op_acc: 39.06%] [G loss: 1.064926]\n",
      "epoch:43 step:34007[D loss: 0.363955, acc: 71.09%, op_acc: 47.66%] [G loss: 1.266898]\n",
      "epoch:43 step:34008[D loss: 0.392294, acc: 67.97%, op_acc: 41.41%] [G loss: 1.225734]\n",
      "epoch:43 step:34009[D loss: 0.484908, acc: 53.91%, op_acc: 37.50%] [G loss: 1.016044]\n",
      "epoch:43 step:34010[D loss: 0.401292, acc: 67.97%, op_acc: 41.41%] [G loss: 1.012027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34011[D loss: 0.411690, acc: 64.84%, op_acc: 45.31%] [G loss: 1.037599]\n",
      "epoch:43 step:34012[D loss: 0.395952, acc: 64.84%, op_acc: 49.22%] [G loss: 1.108749]\n",
      "epoch:43 step:34013[D loss: 0.423771, acc: 59.38%, op_acc: 39.06%] [G loss: 1.111449]\n",
      "epoch:43 step:34014[D loss: 0.432509, acc: 61.72%, op_acc: 39.06%] [G loss: 1.184805]\n",
      "epoch:43 step:34015[D loss: 0.394556, acc: 64.06%, op_acc: 46.88%] [G loss: 1.092491]\n",
      "epoch:43 step:34016[D loss: 0.375048, acc: 68.75%, op_acc: 39.84%] [G loss: 1.025282]\n",
      "epoch:43 step:34017[D loss: 0.365112, acc: 73.44%, op_acc: 45.31%] [G loss: 1.178795]\n",
      "epoch:43 step:34018[D loss: 0.363445, acc: 71.09%, op_acc: 48.44%] [G loss: 1.164067]\n",
      "epoch:43 step:34019[D loss: 0.494249, acc: 49.22%, op_acc: 39.06%] [G loss: 0.956011]\n",
      "epoch:43 step:34020[D loss: 0.427285, acc: 64.06%, op_acc: 39.84%] [G loss: 1.215319]\n",
      "epoch:43 step:34021[D loss: 0.347734, acc: 77.34%, op_acc: 49.22%] [G loss: 1.171431]\n",
      "epoch:43 step:34022[D loss: 0.387525, acc: 71.09%, op_acc: 46.88%] [G loss: 1.196169]\n",
      "epoch:43 step:34023[D loss: 0.372844, acc: 71.09%, op_acc: 45.31%] [G loss: 1.216914]\n",
      "epoch:43 step:34024[D loss: 0.408395, acc: 63.28%, op_acc: 47.66%] [G loss: 1.170819]\n",
      "epoch:43 step:34025[D loss: 0.371231, acc: 67.19%, op_acc: 42.19%] [G loss: 1.159043]\n",
      "epoch:43 step:34026[D loss: 0.399123, acc: 64.84%, op_acc: 41.41%] [G loss: 1.164546]\n",
      "epoch:43 step:34027[D loss: 0.401689, acc: 66.41%, op_acc: 43.75%] [G loss: 1.277486]\n",
      "epoch:43 step:34028[D loss: 0.442837, acc: 63.28%, op_acc: 40.62%] [G loss: 1.225134]\n",
      "epoch:43 step:34029[D loss: 0.344553, acc: 78.12%, op_acc: 44.53%] [G loss: 1.101935]\n",
      "epoch:43 step:34030[D loss: 0.468683, acc: 55.47%, op_acc: 37.50%] [G loss: 0.934046]\n",
      "epoch:43 step:34031[D loss: 0.339394, acc: 75.00%, op_acc: 45.31%] [G loss: 1.102467]\n",
      "epoch:43 step:34032[D loss: 0.346651, acc: 75.78%, op_acc: 47.66%] [G loss: 1.258412]\n",
      "epoch:43 step:34033[D loss: 0.409625, acc: 58.59%, op_acc: 45.31%] [G loss: 1.344523]\n",
      "epoch:43 step:34034[D loss: 0.369899, acc: 66.41%, op_acc: 49.22%] [G loss: 1.182812]\n",
      "epoch:43 step:34035[D loss: 0.349920, acc: 72.66%, op_acc: 48.44%] [G loss: 1.158933]\n",
      "epoch:43 step:34036[D loss: 0.454180, acc: 59.38%, op_acc: 42.19%] [G loss: 1.151730]\n",
      "epoch:43 step:34037[D loss: 0.410659, acc: 70.31%, op_acc: 43.75%] [G loss: 1.357211]\n",
      "epoch:43 step:34038[D loss: 0.405884, acc: 61.72%, op_acc: 47.66%] [G loss: 1.295411]\n",
      "epoch:43 step:34039[D loss: 0.392395, acc: 68.75%, op_acc: 44.53%] [G loss: 1.188363]\n",
      "epoch:43 step:34040[D loss: 0.423461, acc: 59.38%, op_acc: 39.06%] [G loss: 1.104216]\n",
      "epoch:43 step:34041[D loss: 0.376462, acc: 70.31%, op_acc: 48.44%] [G loss: 1.081019]\n",
      "epoch:43 step:34042[D loss: 0.404585, acc: 59.38%, op_acc: 41.41%] [G loss: 1.085726]\n",
      "epoch:43 step:34043[D loss: 0.413205, acc: 61.72%, op_acc: 41.41%] [G loss: 1.144080]\n",
      "epoch:43 step:34044[D loss: 0.388430, acc: 61.72%, op_acc: 50.00%] [G loss: 1.071854]\n",
      "epoch:43 step:34045[D loss: 0.404811, acc: 63.28%, op_acc: 46.88%] [G loss: 1.328741]\n",
      "epoch:43 step:34046[D loss: 0.349193, acc: 74.22%, op_acc: 57.03%] [G loss: 1.235595]\n",
      "epoch:43 step:34047[D loss: 0.427519, acc: 61.72%, op_acc: 37.50%] [G loss: 1.047240]\n",
      "epoch:43 step:34048[D loss: 0.406891, acc: 61.72%, op_acc: 45.31%] [G loss: 1.101398]\n",
      "epoch:43 step:34049[D loss: 0.375346, acc: 71.09%, op_acc: 40.62%] [G loss: 1.219428]\n",
      "epoch:43 step:34050[D loss: 0.386115, acc: 68.75%, op_acc: 45.31%] [G loss: 1.189458]\n",
      "epoch:43 step:34051[D loss: 0.335282, acc: 70.31%, op_acc: 50.78%] [G loss: 1.205086]\n",
      "epoch:43 step:34052[D loss: 0.350445, acc: 73.44%, op_acc: 47.66%] [G loss: 1.260554]\n",
      "epoch:43 step:34053[D loss: 0.365695, acc: 67.19%, op_acc: 52.34%] [G loss: 1.184027]\n",
      "epoch:43 step:34054[D loss: 0.384929, acc: 67.97%, op_acc: 39.84%] [G loss: 1.136513]\n",
      "epoch:43 step:34055[D loss: 0.425232, acc: 63.28%, op_acc: 34.38%] [G loss: 1.390067]\n",
      "epoch:43 step:34056[D loss: 0.388947, acc: 66.41%, op_acc: 42.97%] [G loss: 1.226971]\n",
      "epoch:43 step:34057[D loss: 0.454257, acc: 57.81%, op_acc: 39.06%] [G loss: 1.173706]\n",
      "epoch:43 step:34058[D loss: 0.408590, acc: 60.94%, op_acc: 50.78%] [G loss: 1.118305]\n",
      "epoch:43 step:34059[D loss: 0.406248, acc: 63.28%, op_acc: 40.62%] [G loss: 1.162169]\n",
      "epoch:43 step:34060[D loss: 0.348782, acc: 78.91%, op_acc: 45.31%] [G loss: 1.288995]\n",
      "epoch:43 step:34061[D loss: 0.351567, acc: 66.41%, op_acc: 50.78%] [G loss: 1.069894]\n",
      "epoch:43 step:34062[D loss: 0.397140, acc: 69.53%, op_acc: 45.31%] [G loss: 1.150966]\n",
      "epoch:43 step:34063[D loss: 0.430301, acc: 65.62%, op_acc: 40.62%] [G loss: 1.247675]\n",
      "epoch:43 step:34064[D loss: 0.408637, acc: 72.66%, op_acc: 41.41%] [G loss: 0.971691]\n",
      "epoch:43 step:34065[D loss: 0.374121, acc: 71.88%, op_acc: 46.88%] [G loss: 1.139201]\n",
      "epoch:43 step:34066[D loss: 0.334213, acc: 75.00%, op_acc: 51.56%] [G loss: 1.343946]\n",
      "epoch:43 step:34067[D loss: 0.403683, acc: 65.62%, op_acc: 50.78%] [G loss: 1.349723]\n",
      "epoch:43 step:34068[D loss: 0.388182, acc: 66.41%, op_acc: 42.97%] [G loss: 1.255899]\n",
      "epoch:43 step:34069[D loss: 0.356953, acc: 72.66%, op_acc: 52.34%] [G loss: 1.153043]\n",
      "epoch:43 step:34070[D loss: 0.401237, acc: 62.50%, op_acc: 45.31%] [G loss: 1.086521]\n",
      "epoch:43 step:34071[D loss: 0.431156, acc: 65.62%, op_acc: 37.50%] [G loss: 1.228680]\n",
      "epoch:43 step:34072[D loss: 0.413107, acc: 59.38%, op_acc: 47.66%] [G loss: 1.237942]\n",
      "epoch:43 step:34073[D loss: 0.359482, acc: 75.00%, op_acc: 42.97%] [G loss: 1.335621]\n",
      "epoch:43 step:34074[D loss: 0.376821, acc: 74.22%, op_acc: 42.97%] [G loss: 1.101577]\n",
      "epoch:43 step:34075[D loss: 0.358238, acc: 71.09%, op_acc: 50.78%] [G loss: 1.157530]\n",
      "epoch:43 step:34076[D loss: 0.390044, acc: 67.19%, op_acc: 44.53%] [G loss: 1.280965]\n",
      "epoch:43 step:34077[D loss: 0.390549, acc: 69.53%, op_acc: 42.97%] [G loss: 1.174952]\n",
      "epoch:43 step:34078[D loss: 0.361146, acc: 69.53%, op_acc: 45.31%] [G loss: 1.208996]\n",
      "epoch:43 step:34079[D loss: 0.388816, acc: 73.44%, op_acc: 41.41%] [G loss: 1.215456]\n",
      "epoch:43 step:34080[D loss: 0.408942, acc: 64.84%, op_acc: 48.44%] [G loss: 1.436373]\n",
      "epoch:43 step:34081[D loss: 0.411854, acc: 63.28%, op_acc: 46.09%] [G loss: 1.152415]\n",
      "epoch:43 step:34082[D loss: 0.372230, acc: 74.22%, op_acc: 47.66%] [G loss: 1.339643]\n",
      "epoch:43 step:34083[D loss: 0.407617, acc: 64.06%, op_acc: 47.66%] [G loss: 1.141559]\n",
      "epoch:43 step:34084[D loss: 0.401305, acc: 71.88%, op_acc: 42.19%] [G loss: 1.021078]\n",
      "epoch:43 step:34085[D loss: 0.404810, acc: 61.72%, op_acc: 40.62%] [G loss: 1.137061]\n",
      "epoch:43 step:34086[D loss: 0.429024, acc: 61.72%, op_acc: 42.19%] [G loss: 1.130678]\n",
      "epoch:43 step:34087[D loss: 0.461457, acc: 52.34%, op_acc: 39.84%] [G loss: 1.036510]\n",
      "epoch:43 step:34088[D loss: 0.409272, acc: 65.62%, op_acc: 42.97%] [G loss: 1.234246]\n",
      "epoch:43 step:34089[D loss: 0.379138, acc: 70.31%, op_acc: 48.44%] [G loss: 1.141849]\n",
      "epoch:43 step:34090[D loss: 0.414716, acc: 57.03%, op_acc: 43.75%] [G loss: 1.158663]\n",
      "epoch:43 step:34091[D loss: 0.376253, acc: 63.28%, op_acc: 46.09%] [G loss: 1.118834]\n",
      "epoch:43 step:34092[D loss: 0.403530, acc: 62.50%, op_acc: 43.75%] [G loss: 1.171602]\n",
      "epoch:43 step:34093[D loss: 0.397250, acc: 65.62%, op_acc: 37.50%] [G loss: 1.173861]\n",
      "epoch:43 step:34094[D loss: 0.398876, acc: 63.28%, op_acc: 45.31%] [G loss: 1.115677]\n",
      "epoch:43 step:34095[D loss: 0.446231, acc: 53.91%, op_acc: 40.62%] [G loss: 1.066024]\n",
      "epoch:43 step:34096[D loss: 0.401710, acc: 67.19%, op_acc: 42.97%] [G loss: 1.192010]\n",
      "epoch:43 step:34097[D loss: 0.389194, acc: 69.53%, op_acc: 46.09%] [G loss: 1.122723]\n",
      "epoch:43 step:34098[D loss: 0.368517, acc: 70.31%, op_acc: 46.88%] [G loss: 1.047199]\n",
      "epoch:43 step:34099[D loss: 0.428185, acc: 60.94%, op_acc: 35.94%] [G loss: 1.051109]\n",
      "epoch:43 step:34100[D loss: 0.428440, acc: 67.19%, op_acc: 38.28%] [G loss: 1.080856]\n",
      "epoch:43 step:34101[D loss: 0.358661, acc: 71.88%, op_acc: 40.62%] [G loss: 1.336553]\n",
      "epoch:43 step:34102[D loss: 0.356452, acc: 78.12%, op_acc: 40.62%] [G loss: 1.109881]\n",
      "epoch:43 step:34103[D loss: 0.393658, acc: 64.84%, op_acc: 44.53%] [G loss: 1.306683]\n",
      "epoch:43 step:34104[D loss: 0.344861, acc: 76.56%, op_acc: 45.31%] [G loss: 1.345098]\n",
      "epoch:43 step:34105[D loss: 0.417737, acc: 60.94%, op_acc: 40.62%] [G loss: 1.024056]\n",
      "epoch:43 step:34106[D loss: 0.364760, acc: 66.41%, op_acc: 45.31%] [G loss: 1.093799]\n",
      "epoch:43 step:34107[D loss: 0.411971, acc: 61.72%, op_acc: 47.66%] [G loss: 1.242097]\n",
      "epoch:43 step:34108[D loss: 0.387349, acc: 71.88%, op_acc: 42.19%] [G loss: 1.116466]\n",
      "epoch:43 step:34109[D loss: 0.409037, acc: 68.75%, op_acc: 42.19%] [G loss: 1.238452]\n",
      "epoch:43 step:34110[D loss: 0.409528, acc: 61.72%, op_acc: 43.75%] [G loss: 1.100959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34111[D loss: 0.379750, acc: 66.41%, op_acc: 43.75%] [G loss: 1.253406]\n",
      "epoch:43 step:34112[D loss: 0.441485, acc: 56.25%, op_acc: 37.50%] [G loss: 1.132174]\n",
      "epoch:43 step:34113[D loss: 0.435655, acc: 63.28%, op_acc: 39.06%] [G loss: 1.199939]\n",
      "epoch:43 step:34114[D loss: 0.404888, acc: 69.53%, op_acc: 41.41%] [G loss: 1.338248]\n",
      "epoch:43 step:34115[D loss: 0.419391, acc: 62.50%, op_acc: 41.41%] [G loss: 1.184032]\n",
      "epoch:43 step:34116[D loss: 0.383529, acc: 67.19%, op_acc: 43.75%] [G loss: 1.079480]\n",
      "epoch:43 step:34117[D loss: 0.331337, acc: 71.88%, op_acc: 48.44%] [G loss: 1.158265]\n",
      "epoch:43 step:34118[D loss: 0.342439, acc: 76.56%, op_acc: 50.00%] [G loss: 1.080447]\n",
      "epoch:43 step:34119[D loss: 0.408574, acc: 60.94%, op_acc: 41.41%] [G loss: 1.035345]\n",
      "epoch:43 step:34120[D loss: 0.406080, acc: 63.28%, op_acc: 47.66%] [G loss: 1.246266]\n",
      "epoch:43 step:34121[D loss: 0.444404, acc: 57.03%, op_acc: 37.50%] [G loss: 1.199122]\n",
      "epoch:43 step:34122[D loss: 0.442105, acc: 58.59%, op_acc: 48.44%] [G loss: 1.165594]\n",
      "epoch:43 step:34123[D loss: 0.390627, acc: 67.19%, op_acc: 41.41%] [G loss: 0.923691]\n",
      "epoch:43 step:34124[D loss: 0.345616, acc: 74.22%, op_acc: 46.09%] [G loss: 1.185809]\n",
      "epoch:43 step:34125[D loss: 0.369603, acc: 71.09%, op_acc: 50.00%] [G loss: 1.162285]\n",
      "epoch:43 step:34126[D loss: 0.425136, acc: 67.19%, op_acc: 41.41%] [G loss: 1.422348]\n",
      "epoch:43 step:34127[D loss: 0.366349, acc: 67.97%, op_acc: 39.06%] [G loss: 1.288297]\n",
      "epoch:43 step:34128[D loss: 0.338405, acc: 73.44%, op_acc: 46.88%] [G loss: 1.252651]\n",
      "epoch:43 step:34129[D loss: 0.476267, acc: 56.25%, op_acc: 46.09%] [G loss: 1.232372]\n",
      "epoch:43 step:34130[D loss: 0.350186, acc: 75.00%, op_acc: 41.41%] [G loss: 1.083297]\n",
      "epoch:43 step:34131[D loss: 0.447003, acc: 61.72%, op_acc: 37.50%] [G loss: 1.176073]\n",
      "epoch:43 step:34132[D loss: 0.432727, acc: 60.16%, op_acc: 43.75%] [G loss: 1.124073]\n",
      "epoch:43 step:34133[D loss: 0.421730, acc: 58.59%, op_acc: 42.19%] [G loss: 1.070449]\n",
      "epoch:43 step:34134[D loss: 0.394887, acc: 64.06%, op_acc: 46.09%] [G loss: 1.372424]\n",
      "epoch:43 step:34135[D loss: 0.443416, acc: 66.41%, op_acc: 45.31%] [G loss: 1.169446]\n",
      "epoch:43 step:34136[D loss: 0.389880, acc: 63.28%, op_acc: 47.66%] [G loss: 0.929713]\n",
      "epoch:43 step:34137[D loss: 0.391213, acc: 64.84%, op_acc: 43.75%] [G loss: 1.081524]\n",
      "epoch:43 step:34138[D loss: 0.322971, acc: 80.47%, op_acc: 42.97%] [G loss: 1.155536]\n",
      "epoch:43 step:34139[D loss: 0.495588, acc: 52.34%, op_acc: 35.16%] [G loss: 1.041276]\n",
      "epoch:43 step:34140[D loss: 0.393945, acc: 65.62%, op_acc: 42.97%] [G loss: 1.169796]\n",
      "epoch:43 step:34141[D loss: 0.369047, acc: 68.75%, op_acc: 49.22%] [G loss: 1.160849]\n",
      "epoch:43 step:34142[D loss: 0.374976, acc: 70.31%, op_acc: 40.62%] [G loss: 1.363461]\n",
      "epoch:43 step:34143[D loss: 0.375101, acc: 73.44%, op_acc: 39.84%] [G loss: 1.019857]\n",
      "epoch:43 step:34144[D loss: 0.381903, acc: 63.28%, op_acc: 48.44%] [G loss: 1.096610]\n",
      "epoch:43 step:34145[D loss: 0.390050, acc: 64.84%, op_acc: 47.66%] [G loss: 1.173517]\n",
      "epoch:43 step:34146[D loss: 0.381773, acc: 74.22%, op_acc: 37.50%] [G loss: 1.032820]\n",
      "epoch:43 step:34147[D loss: 0.408680, acc: 64.84%, op_acc: 45.31%] [G loss: 1.221666]\n",
      "epoch:43 step:34148[D loss: 0.400307, acc: 61.72%, op_acc: 49.22%] [G loss: 1.179658]\n",
      "epoch:43 step:34149[D loss: 0.373754, acc: 69.53%, op_acc: 43.75%] [G loss: 1.116778]\n",
      "epoch:43 step:34150[D loss: 0.358748, acc: 71.09%, op_acc: 48.44%] [G loss: 1.184002]\n",
      "epoch:43 step:34151[D loss: 0.470645, acc: 51.56%, op_acc: 40.62%] [G loss: 1.092674]\n",
      "epoch:43 step:34152[D loss: 0.325158, acc: 75.78%, op_acc: 48.44%] [G loss: 1.319018]\n",
      "epoch:43 step:34153[D loss: 0.406965, acc: 64.84%, op_acc: 36.72%] [G loss: 0.991053]\n",
      "epoch:43 step:34154[D loss: 0.367705, acc: 68.75%, op_acc: 51.56%] [G loss: 1.393805]\n",
      "epoch:43 step:34155[D loss: 0.397073, acc: 64.06%, op_acc: 51.56%] [G loss: 1.042874]\n",
      "epoch:43 step:34156[D loss: 0.404845, acc: 70.31%, op_acc: 42.19%] [G loss: 1.260895]\n",
      "epoch:43 step:34157[D loss: 0.435110, acc: 63.28%, op_acc: 37.50%] [G loss: 1.213668]\n",
      "epoch:43 step:34158[D loss: 0.413056, acc: 60.94%, op_acc: 50.78%] [G loss: 1.069627]\n",
      "epoch:43 step:34159[D loss: 0.363719, acc: 67.97%, op_acc: 51.56%] [G loss: 1.166963]\n",
      "epoch:43 step:34160[D loss: 0.411928, acc: 68.75%, op_acc: 42.19%] [G loss: 0.978225]\n",
      "epoch:43 step:34161[D loss: 0.426058, acc: 60.94%, op_acc: 36.72%] [G loss: 1.275089]\n",
      "epoch:43 step:34162[D loss: 0.397795, acc: 65.62%, op_acc: 39.84%] [G loss: 1.060023]\n",
      "epoch:43 step:34163[D loss: 0.403684, acc: 67.19%, op_acc: 47.66%] [G loss: 1.110479]\n",
      "epoch:43 step:34164[D loss: 0.498973, acc: 52.34%, op_acc: 34.38%] [G loss: 0.898339]\n",
      "epoch:43 step:34165[D loss: 0.382808, acc: 66.41%, op_acc: 44.53%] [G loss: 1.132571]\n",
      "epoch:43 step:34166[D loss: 0.369868, acc: 71.09%, op_acc: 45.31%] [G loss: 1.252602]\n",
      "epoch:43 step:34167[D loss: 0.422895, acc: 69.53%, op_acc: 40.62%] [G loss: 1.451797]\n",
      "epoch:43 step:34168[D loss: 0.386816, acc: 64.84%, op_acc: 46.09%] [G loss: 1.250326]\n",
      "epoch:43 step:34169[D loss: 0.464384, acc: 56.25%, op_acc: 37.50%] [G loss: 1.200246]\n",
      "epoch:43 step:34170[D loss: 0.341314, acc: 75.78%, op_acc: 43.75%] [G loss: 1.142753]\n",
      "epoch:43 step:34171[D loss: 0.382130, acc: 63.28%, op_acc: 47.66%] [G loss: 1.118031]\n",
      "epoch:43 step:34172[D loss: 0.403800, acc: 67.19%, op_acc: 42.19%] [G loss: 1.074099]\n",
      "epoch:43 step:34173[D loss: 0.424439, acc: 63.28%, op_acc: 42.97%] [G loss: 0.958230]\n",
      "epoch:43 step:34174[D loss: 0.411789, acc: 62.50%, op_acc: 38.28%] [G loss: 0.908275]\n",
      "epoch:43 step:34175[D loss: 0.420437, acc: 58.59%, op_acc: 37.50%] [G loss: 1.204202]\n",
      "epoch:43 step:34176[D loss: 0.389931, acc: 74.22%, op_acc: 39.84%] [G loss: 1.204747]\n",
      "epoch:43 step:34177[D loss: 0.404647, acc: 68.75%, op_acc: 48.44%] [G loss: 1.043507]\n",
      "epoch:43 step:34178[D loss: 0.343749, acc: 75.00%, op_acc: 49.22%] [G loss: 1.422103]\n",
      "epoch:43 step:34179[D loss: 0.410179, acc: 62.50%, op_acc: 50.00%] [G loss: 1.301256]\n",
      "epoch:43 step:34180[D loss: 0.318799, acc: 78.12%, op_acc: 42.97%] [G loss: 1.430110]\n",
      "epoch:43 step:34181[D loss: 0.412285, acc: 62.50%, op_acc: 42.19%] [G loss: 1.126041]\n",
      "epoch:43 step:34182[D loss: 0.402949, acc: 63.28%, op_acc: 43.75%] [G loss: 1.237952]\n",
      "epoch:43 step:34183[D loss: 0.338032, acc: 77.34%, op_acc: 46.09%] [G loss: 1.260568]\n",
      "epoch:43 step:34184[D loss: 0.443675, acc: 60.94%, op_acc: 39.06%] [G loss: 1.075846]\n",
      "epoch:43 step:34185[D loss: 0.364123, acc: 67.97%, op_acc: 42.19%] [G loss: 0.912559]\n",
      "epoch:43 step:34186[D loss: 0.366357, acc: 65.62%, op_acc: 50.00%] [G loss: 1.028883]\n",
      "epoch:43 step:34187[D loss: 0.468445, acc: 57.81%, op_acc: 33.59%] [G loss: 0.994114]\n",
      "epoch:43 step:34188[D loss: 0.419550, acc: 60.16%, op_acc: 42.97%] [G loss: 1.124604]\n",
      "epoch:43 step:34189[D loss: 0.388265, acc: 71.09%, op_acc: 50.78%] [G loss: 1.147541]\n",
      "epoch:43 step:34190[D loss: 0.367085, acc: 67.97%, op_acc: 44.53%] [G loss: 1.134867]\n",
      "epoch:43 step:34191[D loss: 0.343585, acc: 70.31%, op_acc: 50.00%] [G loss: 1.192939]\n",
      "epoch:43 step:34192[D loss: 0.451372, acc: 56.25%, op_acc: 42.19%] [G loss: 1.149912]\n",
      "epoch:43 step:34193[D loss: 0.420695, acc: 60.16%, op_acc: 39.84%] [G loss: 0.931907]\n",
      "epoch:43 step:34194[D loss: 0.409349, acc: 58.59%, op_acc: 43.75%] [G loss: 1.058549]\n",
      "epoch:43 step:34195[D loss: 0.416717, acc: 60.94%, op_acc: 44.53%] [G loss: 1.232065]\n",
      "epoch:43 step:34196[D loss: 0.328476, acc: 72.66%, op_acc: 46.88%] [G loss: 1.364089]\n",
      "epoch:43 step:34197[D loss: 0.342932, acc: 74.22%, op_acc: 46.09%] [G loss: 1.179501]\n",
      "epoch:43 step:34198[D loss: 0.415578, acc: 63.28%, op_acc: 43.75%] [G loss: 1.101507]\n",
      "epoch:43 step:34199[D loss: 0.456997, acc: 57.81%, op_acc: 38.28%] [G loss: 1.185266]\n",
      "epoch:43 step:34200[D loss: 0.426751, acc: 57.03%, op_acc: 48.44%] [G loss: 1.321844]\n",
      "epoch:43 step:34201[D loss: 0.365183, acc: 64.84%, op_acc: 50.78%] [G loss: 1.218561]\n",
      "epoch:43 step:34202[D loss: 0.423686, acc: 64.84%, op_acc: 40.62%] [G loss: 1.304085]\n",
      "epoch:43 step:34203[D loss: 0.403253, acc: 67.19%, op_acc: 38.28%] [G loss: 1.159913]\n",
      "epoch:43 step:34204[D loss: 0.378513, acc: 71.88%, op_acc: 47.66%] [G loss: 1.064719]\n",
      "epoch:43 step:34205[D loss: 0.407180, acc: 64.06%, op_acc: 40.62%] [G loss: 0.991796]\n",
      "epoch:43 step:34206[D loss: 0.376214, acc: 66.41%, op_acc: 44.53%] [G loss: 1.248379]\n",
      "epoch:43 step:34207[D loss: 0.417863, acc: 60.94%, op_acc: 41.41%] [G loss: 1.088070]\n",
      "epoch:43 step:34208[D loss: 0.428481, acc: 65.62%, op_acc: 39.84%] [G loss: 1.109096]\n",
      "epoch:43 step:34209[D loss: 0.384755, acc: 63.28%, op_acc: 46.88%] [G loss: 1.074960]\n",
      "epoch:43 step:34210[D loss: 0.413070, acc: 62.50%, op_acc: 45.31%] [G loss: 1.241201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34211[D loss: 0.359593, acc: 71.88%, op_acc: 48.44%] [G loss: 1.103887]\n",
      "epoch:43 step:34212[D loss: 0.414996, acc: 63.28%, op_acc: 44.53%] [G loss: 0.856985]\n",
      "epoch:43 step:34213[D loss: 0.322847, acc: 82.03%, op_acc: 50.78%] [G loss: 0.982478]\n",
      "epoch:43 step:34214[D loss: 0.408249, acc: 64.06%, op_acc: 38.28%] [G loss: 1.188889]\n",
      "epoch:43 step:34215[D loss: 0.406394, acc: 63.28%, op_acc: 38.28%] [G loss: 1.159016]\n",
      "epoch:43 step:34216[D loss: 0.393314, acc: 64.84%, op_acc: 42.97%] [G loss: 1.261482]\n",
      "epoch:43 step:34217[D loss: 0.443363, acc: 59.38%, op_acc: 43.75%] [G loss: 1.266530]\n",
      "epoch:43 step:34218[D loss: 0.429873, acc: 60.94%, op_acc: 46.09%] [G loss: 1.181442]\n",
      "epoch:43 step:34219[D loss: 0.424324, acc: 60.94%, op_acc: 39.84%] [G loss: 1.305342]\n",
      "epoch:43 step:34220[D loss: 0.460678, acc: 53.91%, op_acc: 42.19%] [G loss: 1.272106]\n",
      "epoch:43 step:34221[D loss: 0.378801, acc: 63.28%, op_acc: 45.31%] [G loss: 1.177852]\n",
      "epoch:43 step:34222[D loss: 0.418083, acc: 62.50%, op_acc: 42.97%] [G loss: 1.140546]\n",
      "epoch:43 step:34223[D loss: 0.406699, acc: 71.09%, op_acc: 38.28%] [G loss: 1.463206]\n",
      "epoch:43 step:34224[D loss: 0.394994, acc: 67.97%, op_acc: 42.97%] [G loss: 1.147263]\n",
      "epoch:43 step:34225[D loss: 0.405912, acc: 66.41%, op_acc: 44.53%] [G loss: 1.052678]\n",
      "epoch:43 step:34226[D loss: 0.389642, acc: 64.84%, op_acc: 43.75%] [G loss: 1.129720]\n",
      "epoch:43 step:34227[D loss: 0.358822, acc: 70.31%, op_acc: 50.00%] [G loss: 1.113839]\n",
      "epoch:43 step:34228[D loss: 0.359746, acc: 72.66%, op_acc: 44.53%] [G loss: 1.123365]\n",
      "epoch:43 step:34229[D loss: 0.359535, acc: 70.31%, op_acc: 40.62%] [G loss: 1.060000]\n",
      "epoch:43 step:34230[D loss: 0.358221, acc: 71.09%, op_acc: 43.75%] [G loss: 1.141168]\n",
      "epoch:43 step:34231[D loss: 0.346473, acc: 77.34%, op_acc: 44.53%] [G loss: 1.193352]\n",
      "epoch:43 step:34232[D loss: 0.383557, acc: 65.62%, op_acc: 46.09%] [G loss: 1.197216]\n",
      "epoch:43 step:34233[D loss: 0.418679, acc: 60.16%, op_acc: 39.06%] [G loss: 1.216751]\n",
      "epoch:43 step:34234[D loss: 0.396416, acc: 64.84%, op_acc: 45.31%] [G loss: 1.100853]\n",
      "epoch:43 step:34235[D loss: 0.384134, acc: 66.41%, op_acc: 46.09%] [G loss: 1.119905]\n",
      "epoch:43 step:34236[D loss: 0.452114, acc: 54.69%, op_acc: 42.97%] [G loss: 1.030483]\n",
      "epoch:43 step:34237[D loss: 0.402012, acc: 64.06%, op_acc: 40.62%] [G loss: 1.129906]\n",
      "epoch:43 step:34238[D loss: 0.385677, acc: 66.41%, op_acc: 42.97%] [G loss: 1.160473]\n",
      "epoch:43 step:34239[D loss: 0.394007, acc: 71.09%, op_acc: 41.41%] [G loss: 1.195592]\n",
      "epoch:43 step:34240[D loss: 0.432506, acc: 62.50%, op_acc: 44.53%] [G loss: 1.013694]\n",
      "epoch:43 step:34241[D loss: 0.374268, acc: 68.75%, op_acc: 43.75%] [G loss: 1.112689]\n",
      "epoch:43 step:34242[D loss: 0.404786, acc: 65.62%, op_acc: 38.28%] [G loss: 1.020913]\n",
      "epoch:43 step:34243[D loss: 0.381985, acc: 67.19%, op_acc: 48.44%] [G loss: 1.116125]\n",
      "epoch:43 step:34244[D loss: 0.377899, acc: 67.97%, op_acc: 48.44%] [G loss: 1.074954]\n",
      "epoch:43 step:34245[D loss: 0.376665, acc: 69.53%, op_acc: 50.00%] [G loss: 1.231419]\n",
      "epoch:43 step:34246[D loss: 0.388155, acc: 67.19%, op_acc: 46.09%] [G loss: 1.235821]\n",
      "epoch:43 step:34247[D loss: 0.363452, acc: 71.88%, op_acc: 51.56%] [G loss: 1.151709]\n",
      "epoch:43 step:34248[D loss: 0.366014, acc: 82.81%, op_acc: 42.19%] [G loss: 1.297661]\n",
      "epoch:43 step:34249[D loss: 0.437394, acc: 58.59%, op_acc: 40.62%] [G loss: 1.113444]\n",
      "epoch:43 step:34250[D loss: 0.366195, acc: 68.75%, op_acc: 42.97%] [G loss: 1.208893]\n",
      "epoch:43 step:34251[D loss: 0.403775, acc: 64.84%, op_acc: 36.72%] [G loss: 1.038298]\n",
      "epoch:43 step:34252[D loss: 0.400012, acc: 71.88%, op_acc: 41.41%] [G loss: 0.979950]\n",
      "epoch:43 step:34253[D loss: 0.359542, acc: 72.66%, op_acc: 44.53%] [G loss: 1.175376]\n",
      "epoch:43 step:34254[D loss: 0.453443, acc: 60.16%, op_acc: 39.06%] [G loss: 1.020702]\n",
      "epoch:43 step:34255[D loss: 0.389799, acc: 68.75%, op_acc: 50.00%] [G loss: 1.222080]\n",
      "epoch:43 step:34256[D loss: 0.464316, acc: 55.47%, op_acc: 38.28%] [G loss: 1.137008]\n",
      "epoch:43 step:34257[D loss: 0.390942, acc: 61.72%, op_acc: 46.88%] [G loss: 1.187697]\n",
      "epoch:43 step:34258[D loss: 0.362307, acc: 74.22%, op_acc: 46.09%] [G loss: 1.208563]\n",
      "epoch:43 step:34259[D loss: 0.414147, acc: 60.94%, op_acc: 43.75%] [G loss: 1.139882]\n",
      "epoch:43 step:34260[D loss: 0.403626, acc: 66.41%, op_acc: 46.09%] [G loss: 0.935973]\n",
      "epoch:43 step:34261[D loss: 0.368652, acc: 67.97%, op_acc: 46.88%] [G loss: 1.017465]\n",
      "epoch:43 step:34262[D loss: 0.376781, acc: 65.62%, op_acc: 44.53%] [G loss: 0.992130]\n",
      "epoch:43 step:34263[D loss: 0.380752, acc: 67.19%, op_acc: 39.06%] [G loss: 1.125427]\n",
      "epoch:43 step:34264[D loss: 0.438580, acc: 62.50%, op_acc: 39.84%] [G loss: 0.931790]\n",
      "epoch:43 step:34265[D loss: 0.362451, acc: 67.97%, op_acc: 47.66%] [G loss: 1.175276]\n",
      "epoch:43 step:34266[D loss: 0.435508, acc: 60.16%, op_acc: 41.41%] [G loss: 1.141181]\n",
      "epoch:43 step:34267[D loss: 0.389920, acc: 68.75%, op_acc: 46.09%] [G loss: 1.249608]\n",
      "epoch:43 step:34268[D loss: 0.341251, acc: 75.78%, op_acc: 45.31%] [G loss: 1.091023]\n",
      "epoch:43 step:34269[D loss: 0.436453, acc: 60.94%, op_acc: 39.06%] [G loss: 1.071653]\n",
      "epoch:43 step:34270[D loss: 0.383242, acc: 64.06%, op_acc: 42.19%] [G loss: 1.160087]\n",
      "epoch:43 step:34271[D loss: 0.387806, acc: 68.75%, op_acc: 47.66%] [G loss: 1.299132]\n",
      "epoch:43 step:34272[D loss: 0.340647, acc: 76.56%, op_acc: 50.00%] [G loss: 0.972928]\n",
      "epoch:43 step:34273[D loss: 0.369188, acc: 75.00%, op_acc: 44.53%] [G loss: 1.125302]\n",
      "epoch:43 step:34274[D loss: 0.349465, acc: 71.88%, op_acc: 49.22%] [G loss: 0.940838]\n",
      "epoch:43 step:34275[D loss: 0.403387, acc: 67.97%, op_acc: 41.41%] [G loss: 1.076244]\n",
      "epoch:43 step:34276[D loss: 0.358843, acc: 72.66%, op_acc: 46.88%] [G loss: 1.109388]\n",
      "epoch:43 step:34277[D loss: 0.424520, acc: 61.72%, op_acc: 39.06%] [G loss: 1.075870]\n",
      "epoch:43 step:34278[D loss: 0.390159, acc: 63.28%, op_acc: 46.09%] [G loss: 1.035390]\n",
      "epoch:43 step:34279[D loss: 0.384722, acc: 68.75%, op_acc: 46.09%] [G loss: 1.001059]\n",
      "epoch:43 step:34280[D loss: 0.431672, acc: 61.72%, op_acc: 44.53%] [G loss: 0.968655]\n",
      "epoch:43 step:34281[D loss: 0.432490, acc: 57.03%, op_acc: 42.97%] [G loss: 1.230621]\n",
      "epoch:43 step:34282[D loss: 0.420609, acc: 60.94%, op_acc: 42.19%] [G loss: 1.065190]\n",
      "epoch:43 step:34283[D loss: 0.439647, acc: 56.25%, op_acc: 42.19%] [G loss: 1.060589]\n",
      "epoch:43 step:34284[D loss: 0.409896, acc: 63.28%, op_acc: 48.44%] [G loss: 1.019874]\n",
      "epoch:43 step:34285[D loss: 0.377947, acc: 67.19%, op_acc: 43.75%] [G loss: 1.117194]\n",
      "epoch:43 step:34286[D loss: 0.459184, acc: 56.25%, op_acc: 41.41%] [G loss: 1.168124]\n",
      "epoch:43 step:34287[D loss: 0.354179, acc: 69.53%, op_acc: 51.56%] [G loss: 1.092927]\n",
      "epoch:43 step:34288[D loss: 0.455487, acc: 60.16%, op_acc: 36.72%] [G loss: 1.081668]\n",
      "epoch:43 step:34289[D loss: 0.455870, acc: 53.91%, op_acc: 42.19%] [G loss: 1.034523]\n",
      "epoch:43 step:34290[D loss: 0.425960, acc: 59.38%, op_acc: 40.62%] [G loss: 1.003644]\n",
      "epoch:43 step:34291[D loss: 0.434581, acc: 62.50%, op_acc: 39.06%] [G loss: 1.074873]\n",
      "epoch:43 step:34292[D loss: 0.402071, acc: 60.94%, op_acc: 39.84%] [G loss: 1.056433]\n",
      "epoch:43 step:34293[D loss: 0.326817, acc: 78.12%, op_acc: 46.88%] [G loss: 1.164570]\n",
      "epoch:43 step:34294[D loss: 0.368253, acc: 70.31%, op_acc: 45.31%] [G loss: 1.335842]\n",
      "epoch:43 step:34295[D loss: 0.455469, acc: 60.16%, op_acc: 48.44%] [G loss: 1.340614]\n",
      "epoch:43 step:34296[D loss: 0.354574, acc: 74.22%, op_acc: 51.56%] [G loss: 1.190108]\n",
      "epoch:43 step:34297[D loss: 0.384155, acc: 67.19%, op_acc: 48.44%] [G loss: 1.229341]\n",
      "epoch:43 step:34298[D loss: 0.360184, acc: 65.62%, op_acc: 45.31%] [G loss: 1.130320]\n",
      "epoch:43 step:34299[D loss: 0.382767, acc: 65.62%, op_acc: 47.66%] [G loss: 1.039362]\n",
      "epoch:43 step:34300[D loss: 0.452339, acc: 51.56%, op_acc: 44.53%] [G loss: 0.986642]\n",
      "epoch:43 step:34301[D loss: 0.374462, acc: 67.97%, op_acc: 39.84%] [G loss: 1.048694]\n",
      "epoch:43 step:34302[D loss: 0.403931, acc: 64.06%, op_acc: 39.84%] [G loss: 1.085484]\n",
      "epoch:43 step:34303[D loss: 0.386160, acc: 68.75%, op_acc: 39.06%] [G loss: 1.099638]\n",
      "epoch:43 step:34304[D loss: 0.486357, acc: 48.44%, op_acc: 39.84%] [G loss: 1.073482]\n",
      "epoch:43 step:34305[D loss: 0.384107, acc: 64.84%, op_acc: 47.66%] [G loss: 1.290720]\n",
      "epoch:43 step:34306[D loss: 0.352928, acc: 74.22%, op_acc: 48.44%] [G loss: 1.188199]\n",
      "epoch:43 step:34307[D loss: 0.491227, acc: 59.38%, op_acc: 38.28%] [G loss: 1.064913]\n",
      "epoch:43 step:34308[D loss: 0.403396, acc: 60.16%, op_acc: 41.41%] [G loss: 1.195149]\n",
      "epoch:43 step:34309[D loss: 0.409315, acc: 65.62%, op_acc: 48.44%] [G loss: 0.982205]\n",
      "epoch:43 step:34310[D loss: 0.425413, acc: 63.28%, op_acc: 36.72%] [G loss: 1.259924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43 step:34311[D loss: 0.464735, acc: 57.81%, op_acc: 35.16%] [G loss: 1.139003]\n",
      "epoch:43 step:34312[D loss: 0.412126, acc: 61.72%, op_acc: 47.66%] [G loss: 1.101550]\n",
      "epoch:43 step:34313[D loss: 0.427507, acc: 56.25%, op_acc: 42.19%] [G loss: 1.250120]\n",
      "epoch:43 step:34314[D loss: 0.384439, acc: 68.75%, op_acc: 40.62%] [G loss: 1.122056]\n",
      "epoch:43 step:34315[D loss: 0.387120, acc: 68.75%, op_acc: 42.97%] [G loss: 1.173129]\n",
      "epoch:43 step:34316[D loss: 0.425325, acc: 53.12%, op_acc: 39.84%] [G loss: 0.951688]\n",
      "epoch:43 step:34317[D loss: 0.404622, acc: 62.50%, op_acc: 44.53%] [G loss: 1.014634]\n",
      "epoch:43 step:34318[D loss: 0.393487, acc: 59.38%, op_acc: 53.12%] [G loss: 1.183476]\n",
      "epoch:43 step:34319[D loss: 0.437871, acc: 65.62%, op_acc: 41.41%] [G loss: 0.985421]\n",
      "epoch:43 step:34320[D loss: 0.385219, acc: 64.84%, op_acc: 44.53%] [G loss: 1.101185]\n",
      "epoch:43 step:34321[D loss: 0.414648, acc: 64.84%, op_acc: 41.41%] [G loss: 1.052432]\n",
      "epoch:43 step:34322[D loss: 0.370547, acc: 65.62%, op_acc: 53.91%] [G loss: 1.031497]\n",
      "epoch:43 step:34323[D loss: 0.366303, acc: 65.62%, op_acc: 48.44%] [G loss: 1.119004]\n",
      "epoch:43 step:34324[D loss: 0.367417, acc: 76.56%, op_acc: 49.22%] [G loss: 1.142648]\n",
      "epoch:43 step:34325[D loss: 0.409425, acc: 59.38%, op_acc: 40.62%] [G loss: 1.060826]\n",
      "epoch:43 step:34326[D loss: 0.428599, acc: 63.28%, op_acc: 41.41%] [G loss: 1.026229]\n",
      "epoch:43 step:34327[D loss: 0.319853, acc: 80.47%, op_acc: 55.47%] [G loss: 1.114526]\n",
      "epoch:43 step:34328[D loss: 0.434888, acc: 62.50%, op_acc: 41.41%] [G loss: 1.042026]\n",
      "epoch:43 step:34329[D loss: 0.399523, acc: 70.31%, op_acc: 45.31%] [G loss: 1.245013]\n",
      "epoch:43 step:34330[D loss: 0.410636, acc: 62.50%, op_acc: 46.09%] [G loss: 1.102978]\n",
      "epoch:43 step:34331[D loss: 0.416815, acc: 67.19%, op_acc: 39.84%] [G loss: 1.046288]\n",
      "epoch:43 step:34332[D loss: 0.393955, acc: 74.22%, op_acc: 42.97%] [G loss: 1.234000]\n",
      "epoch:43 step:34333[D loss: 0.422408, acc: 57.81%, op_acc: 45.31%] [G loss: 1.119473]\n",
      "epoch:43 step:34334[D loss: 0.435016, acc: 60.94%, op_acc: 42.97%] [G loss: 1.034208]\n",
      "epoch:43 step:34335[D loss: 0.391554, acc: 67.97%, op_acc: 46.88%] [G loss: 1.093141]\n",
      "epoch:43 step:34336[D loss: 0.392027, acc: 66.41%, op_acc: 42.97%] [G loss: 1.020454]\n",
      "epoch:43 step:34337[D loss: 0.331789, acc: 75.00%, op_acc: 46.09%] [G loss: 1.240014]\n",
      "epoch:43 step:34338[D loss: 0.370181, acc: 68.75%, op_acc: 47.66%] [G loss: 1.237089]\n",
      "epoch:43 step:34339[D loss: 0.383909, acc: 56.25%, op_acc: 46.88%] [G loss: 1.198283]\n",
      "epoch:43 step:34340[D loss: 0.351321, acc: 75.00%, op_acc: 46.09%] [G loss: 1.097204]\n",
      "epoch:43 step:34341[D loss: 0.344378, acc: 72.66%, op_acc: 51.56%] [G loss: 1.205093]\n",
      "epoch:43 step:34342[D loss: 0.380026, acc: 70.31%, op_acc: 47.66%] [G loss: 1.076069]\n",
      "epoch:43 step:34343[D loss: 0.380999, acc: 65.62%, op_acc: 47.66%] [G loss: 1.120409]\n",
      "epoch:43 step:34344[D loss: 0.359713, acc: 75.78%, op_acc: 50.78%] [G loss: 1.243977]\n",
      "epoch:43 step:34345[D loss: 0.435741, acc: 59.38%, op_acc: 42.97%] [G loss: 0.989154]\n",
      "epoch:43 step:34346[D loss: 0.349191, acc: 75.78%, op_acc: 52.34%] [G loss: 1.196379]\n",
      "epoch:43 step:34347[D loss: 0.362165, acc: 71.09%, op_acc: 42.19%] [G loss: 1.195714]\n",
      "epoch:43 step:34348[D loss: 0.345587, acc: 71.88%, op_acc: 54.69%] [G loss: 1.047071]\n",
      "epoch:43 step:34349[D loss: 0.468921, acc: 52.34%, op_acc: 35.16%] [G loss: 0.921303]\n",
      "epoch:43 step:34350[D loss: 0.340366, acc: 72.66%, op_acc: 50.00%] [G loss: 1.060192]\n",
      "epoch:43 step:34351[D loss: 0.360190, acc: 69.53%, op_acc: 45.31%] [G loss: 1.235299]\n",
      "epoch:43 step:34352[D loss: 0.356260, acc: 72.66%, op_acc: 46.09%] [G loss: 1.236795]\n",
      "epoch:43 step:34353[D loss: 0.396691, acc: 64.06%, op_acc: 46.09%] [G loss: 0.982759]\n",
      "epoch:43 step:34354[D loss: 0.451801, acc: 53.91%, op_acc: 42.97%] [G loss: 1.167862]\n",
      "epoch:43 step:34355[D loss: 0.411162, acc: 61.72%, op_acc: 39.06%] [G loss: 1.110148]\n",
      "epoch:43 step:34356[D loss: 0.400530, acc: 62.50%, op_acc: 38.28%] [G loss: 1.174969]\n",
      "epoch:43 step:34357[D loss: 0.348716, acc: 71.88%, op_acc: 44.53%] [G loss: 1.227691]\n",
      "epoch:43 step:34358[D loss: 0.308449, acc: 83.59%, op_acc: 50.00%] [G loss: 1.234921]\n",
      "epoch:43 step:34359[D loss: 0.447914, acc: 62.50%, op_acc: 42.19%] [G loss: 1.222334]\n",
      "epoch:43 step:34360[D loss: 0.401787, acc: 65.62%, op_acc: 42.19%] [G loss: 1.267279]\n",
      "epoch:43 step:34361[D loss: 0.370174, acc: 70.31%, op_acc: 47.66%] [G loss: 1.215388]\n",
      "epoch:43 step:34362[D loss: 0.377920, acc: 67.19%, op_acc: 49.22%] [G loss: 1.021064]\n",
      "epoch:43 step:34363[D loss: 0.391616, acc: 67.19%, op_acc: 45.31%] [G loss: 1.137521]\n",
      "epoch:43 step:34364[D loss: 0.405745, acc: 64.84%, op_acc: 41.41%] [G loss: 1.006746]\n",
      "epoch:44 step:34365[D loss: 0.380313, acc: 66.41%, op_acc: 47.66%] [G loss: 1.183764]\n",
      "epoch:44 step:34366[D loss: 0.405331, acc: 58.59%, op_acc: 45.31%] [G loss: 1.176757]\n",
      "epoch:44 step:34367[D loss: 0.461573, acc: 53.91%, op_acc: 44.53%] [G loss: 1.116511]\n",
      "epoch:44 step:34368[D loss: 0.379266, acc: 67.19%, op_acc: 42.97%] [G loss: 1.059570]\n",
      "epoch:44 step:34369[D loss: 0.381920, acc: 67.97%, op_acc: 46.09%] [G loss: 1.227716]\n",
      "epoch:44 step:34370[D loss: 0.416550, acc: 67.19%, op_acc: 46.09%] [G loss: 1.212591]\n",
      "epoch:44 step:34371[D loss: 0.424076, acc: 60.16%, op_acc: 42.97%] [G loss: 0.975216]\n",
      "epoch:44 step:34372[D loss: 0.402365, acc: 60.94%, op_acc: 44.53%] [G loss: 1.124336]\n",
      "epoch:44 step:34373[D loss: 0.379541, acc: 64.84%, op_acc: 48.44%] [G loss: 1.173428]\n",
      "epoch:44 step:34374[D loss: 0.425241, acc: 63.28%, op_acc: 40.62%] [G loss: 1.151784]\n",
      "epoch:44 step:34375[D loss: 0.425611, acc: 59.38%, op_acc: 47.66%] [G loss: 1.076318]\n",
      "epoch:44 step:34376[D loss: 0.445595, acc: 65.62%, op_acc: 35.16%] [G loss: 0.951926]\n",
      "epoch:44 step:34377[D loss: 0.361443, acc: 67.97%, op_acc: 37.50%] [G loss: 1.202054]\n",
      "epoch:44 step:34378[D loss: 0.418345, acc: 64.06%, op_acc: 45.31%] [G loss: 1.312513]\n",
      "epoch:44 step:34379[D loss: 0.382619, acc: 60.16%, op_acc: 48.44%] [G loss: 1.117913]\n",
      "epoch:44 step:34380[D loss: 0.336026, acc: 71.88%, op_acc: 46.09%] [G loss: 1.316322]\n",
      "epoch:44 step:34381[D loss: 0.417179, acc: 59.38%, op_acc: 40.62%] [G loss: 1.139536]\n",
      "epoch:44 step:34382[D loss: 0.404255, acc: 66.41%, op_acc: 45.31%] [G loss: 1.125757]\n",
      "epoch:44 step:34383[D loss: 0.393156, acc: 67.97%, op_acc: 42.97%] [G loss: 0.971319]\n",
      "epoch:44 step:34384[D loss: 0.373536, acc: 70.31%, op_acc: 45.31%] [G loss: 1.209262]\n",
      "epoch:44 step:34385[D loss: 0.411861, acc: 62.50%, op_acc: 44.53%] [G loss: 0.961737]\n",
      "epoch:44 step:34386[D loss: 0.404994, acc: 62.50%, op_acc: 46.09%] [G loss: 1.033053]\n",
      "epoch:44 step:34387[D loss: 0.419138, acc: 57.81%, op_acc: 45.31%] [G loss: 1.245089]\n",
      "epoch:44 step:34388[D loss: 0.391941, acc: 64.06%, op_acc: 43.75%] [G loss: 1.159781]\n",
      "epoch:44 step:34389[D loss: 0.419146, acc: 64.84%, op_acc: 48.44%] [G loss: 1.032706]\n",
      "epoch:44 step:34390[D loss: 0.372858, acc: 70.31%, op_acc: 42.19%] [G loss: 1.085366]\n",
      "epoch:44 step:34391[D loss: 0.412612, acc: 65.62%, op_acc: 42.97%] [G loss: 1.192894]\n",
      "epoch:44 step:34392[D loss: 0.377468, acc: 67.19%, op_acc: 42.97%] [G loss: 1.286761]\n",
      "epoch:44 step:34393[D loss: 0.364963, acc: 66.41%, op_acc: 50.00%] [G loss: 1.107412]\n",
      "epoch:44 step:34394[D loss: 0.363170, acc: 64.84%, op_acc: 46.88%] [G loss: 1.122199]\n",
      "epoch:44 step:34395[D loss: 0.417194, acc: 67.19%, op_acc: 39.84%] [G loss: 1.066989]\n",
      "epoch:44 step:34396[D loss: 0.447465, acc: 51.56%, op_acc: 42.19%] [G loss: 1.240108]\n",
      "epoch:44 step:34397[D loss: 0.376159, acc: 73.44%, op_acc: 44.53%] [G loss: 1.148781]\n",
      "epoch:44 step:34398[D loss: 0.353110, acc: 71.88%, op_acc: 46.88%] [G loss: 1.298060]\n",
      "epoch:44 step:34399[D loss: 0.379081, acc: 67.19%, op_acc: 49.22%] [G loss: 1.113626]\n",
      "epoch:44 step:34400[D loss: 0.394314, acc: 61.72%, op_acc: 49.22%] [G loss: 1.096060]\n",
      "epoch:44 step:34401[D loss: 0.345116, acc: 73.44%, op_acc: 43.75%] [G loss: 1.291965]\n",
      "epoch:44 step:34402[D loss: 0.413709, acc: 69.53%, op_acc: 43.75%] [G loss: 1.020222]\n",
      "epoch:44 step:34403[D loss: 0.409087, acc: 65.62%, op_acc: 43.75%] [G loss: 0.974344]\n",
      "epoch:44 step:34404[D loss: 0.465469, acc: 53.91%, op_acc: 39.84%] [G loss: 1.036686]\n",
      "epoch:44 step:34405[D loss: 0.322614, acc: 71.09%, op_acc: 53.91%] [G loss: 1.181936]\n",
      "epoch:44 step:34406[D loss: 0.354735, acc: 69.53%, op_acc: 50.78%] [G loss: 1.086523]\n",
      "epoch:44 step:34407[D loss: 0.392757, acc: 67.97%, op_acc: 42.19%] [G loss: 1.033472]\n",
      "epoch:44 step:34408[D loss: 0.362150, acc: 71.88%, op_acc: 49.22%] [G loss: 1.200222]\n",
      "epoch:44 step:34409[D loss: 0.430891, acc: 61.72%, op_acc: 43.75%] [G loss: 1.334639]\n",
      "epoch:44 step:34410[D loss: 0.366044, acc: 70.31%, op_acc: 40.62%] [G loss: 1.216732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34411[D loss: 0.393347, acc: 67.19%, op_acc: 44.53%] [G loss: 1.128438]\n",
      "epoch:44 step:34412[D loss: 0.444194, acc: 57.03%, op_acc: 44.53%] [G loss: 0.980811]\n",
      "epoch:44 step:34413[D loss: 0.332644, acc: 82.03%, op_acc: 48.44%] [G loss: 1.117373]\n",
      "epoch:44 step:34414[D loss: 0.357927, acc: 74.22%, op_acc: 40.62%] [G loss: 0.913460]\n",
      "epoch:44 step:34415[D loss: 0.330180, acc: 75.78%, op_acc: 46.09%] [G loss: 1.021187]\n",
      "epoch:44 step:34416[D loss: 0.387076, acc: 72.66%, op_acc: 42.19%] [G loss: 1.129615]\n",
      "epoch:44 step:34417[D loss: 0.461789, acc: 54.69%, op_acc: 39.06%] [G loss: 1.032062]\n",
      "epoch:44 step:34418[D loss: 0.423536, acc: 60.94%, op_acc: 43.75%] [G loss: 1.207792]\n",
      "epoch:44 step:34419[D loss: 0.420342, acc: 59.38%, op_acc: 35.94%] [G loss: 1.244363]\n",
      "epoch:44 step:34420[D loss: 0.395429, acc: 60.94%, op_acc: 42.19%] [G loss: 1.052766]\n",
      "epoch:44 step:34421[D loss: 0.430960, acc: 59.38%, op_acc: 37.50%] [G loss: 1.149820]\n",
      "epoch:44 step:34422[D loss: 0.347434, acc: 72.66%, op_acc: 50.78%] [G loss: 1.356944]\n",
      "epoch:44 step:34423[D loss: 0.436047, acc: 57.03%, op_acc: 43.75%] [G loss: 1.091025]\n",
      "epoch:44 step:34424[D loss: 0.427188, acc: 63.28%, op_acc: 33.59%] [G loss: 0.954097]\n",
      "epoch:44 step:34425[D loss: 0.335509, acc: 76.56%, op_acc: 40.62%] [G loss: 1.054929]\n",
      "epoch:44 step:34426[D loss: 0.403869, acc: 66.41%, op_acc: 37.50%] [G loss: 1.002305]\n",
      "epoch:44 step:34427[D loss: 0.382093, acc: 67.19%, op_acc: 42.19%] [G loss: 0.919592]\n",
      "epoch:44 step:34428[D loss: 0.374770, acc: 71.09%, op_acc: 46.09%] [G loss: 1.050852]\n",
      "epoch:44 step:34429[D loss: 0.410398, acc: 61.72%, op_acc: 42.19%] [G loss: 1.034165]\n",
      "epoch:44 step:34430[D loss: 0.370089, acc: 72.66%, op_acc: 39.84%] [G loss: 1.142001]\n",
      "epoch:44 step:34431[D loss: 0.352667, acc: 71.09%, op_acc: 47.66%] [G loss: 1.025711]\n",
      "epoch:44 step:34432[D loss: 0.409235, acc: 63.28%, op_acc: 43.75%] [G loss: 1.291761]\n",
      "epoch:44 step:34433[D loss: 0.366940, acc: 68.75%, op_acc: 50.78%] [G loss: 1.042505]\n",
      "epoch:44 step:34434[D loss: 0.419530, acc: 60.94%, op_acc: 42.19%] [G loss: 0.823637]\n",
      "epoch:44 step:34435[D loss: 0.427287, acc: 69.53%, op_acc: 42.19%] [G loss: 0.945989]\n",
      "epoch:44 step:34436[D loss: 0.338021, acc: 68.75%, op_acc: 45.31%] [G loss: 1.161532]\n",
      "epoch:44 step:34437[D loss: 0.417793, acc: 65.62%, op_acc: 39.06%] [G loss: 1.004296]\n",
      "epoch:44 step:34438[D loss: 0.395449, acc: 66.41%, op_acc: 42.97%] [G loss: 1.197760]\n",
      "epoch:44 step:34439[D loss: 0.394227, acc: 63.28%, op_acc: 43.75%] [G loss: 1.022883]\n",
      "epoch:44 step:34440[D loss: 0.410303, acc: 65.62%, op_acc: 47.66%] [G loss: 1.007535]\n",
      "epoch:44 step:34441[D loss: 0.406015, acc: 64.06%, op_acc: 44.53%] [G loss: 1.026917]\n",
      "epoch:44 step:34442[D loss: 0.417313, acc: 66.41%, op_acc: 39.84%] [G loss: 1.101469]\n",
      "epoch:44 step:34443[D loss: 0.353441, acc: 71.88%, op_acc: 48.44%] [G loss: 1.031305]\n",
      "epoch:44 step:34444[D loss: 0.401602, acc: 69.53%, op_acc: 46.09%] [G loss: 1.051147]\n",
      "epoch:44 step:34445[D loss: 0.417800, acc: 64.06%, op_acc: 41.41%] [G loss: 1.049267]\n",
      "epoch:44 step:34446[D loss: 0.447110, acc: 57.81%, op_acc: 42.97%] [G loss: 0.963652]\n",
      "epoch:44 step:34447[D loss: 0.401915, acc: 66.41%, op_acc: 42.19%] [G loss: 1.033061]\n",
      "epoch:44 step:34448[D loss: 0.363367, acc: 68.75%, op_acc: 46.88%] [G loss: 1.069788]\n",
      "epoch:44 step:34449[D loss: 0.431360, acc: 64.06%, op_acc: 42.19%] [G loss: 1.126845]\n",
      "epoch:44 step:34450[D loss: 0.400543, acc: 66.41%, op_acc: 42.97%] [G loss: 1.125324]\n",
      "epoch:44 step:34451[D loss: 0.340796, acc: 75.00%, op_acc: 51.56%] [G loss: 1.056026]\n",
      "epoch:44 step:34452[D loss: 0.391781, acc: 67.97%, op_acc: 44.53%] [G loss: 1.080177]\n",
      "epoch:44 step:34453[D loss: 0.379719, acc: 68.75%, op_acc: 42.97%] [G loss: 1.092484]\n",
      "epoch:44 step:34454[D loss: 0.394291, acc: 67.97%, op_acc: 44.53%] [G loss: 1.195929]\n",
      "epoch:44 step:34455[D loss: 0.352570, acc: 74.22%, op_acc: 47.66%] [G loss: 1.219210]\n",
      "epoch:44 step:34456[D loss: 0.414802, acc: 66.41%, op_acc: 46.88%] [G loss: 1.235680]\n",
      "epoch:44 step:34457[D loss: 0.404451, acc: 63.28%, op_acc: 44.53%] [G loss: 1.090014]\n",
      "epoch:44 step:34458[D loss: 0.388215, acc: 64.84%, op_acc: 44.53%] [G loss: 1.074406]\n",
      "epoch:44 step:34459[D loss: 0.450592, acc: 60.94%, op_acc: 45.31%] [G loss: 1.071681]\n",
      "epoch:44 step:34460[D loss: 0.425605, acc: 62.50%, op_acc: 36.72%] [G loss: 1.110681]\n",
      "epoch:44 step:34461[D loss: 0.368615, acc: 68.75%, op_acc: 42.97%] [G loss: 1.231611]\n",
      "epoch:44 step:34462[D loss: 0.400691, acc: 65.62%, op_acc: 50.00%] [G loss: 1.343325]\n",
      "epoch:44 step:34463[D loss: 0.424365, acc: 64.84%, op_acc: 42.97%] [G loss: 1.093044]\n",
      "epoch:44 step:34464[D loss: 0.418587, acc: 63.28%, op_acc: 41.41%] [G loss: 1.236321]\n",
      "epoch:44 step:34465[D loss: 0.390466, acc: 63.28%, op_acc: 40.62%] [G loss: 1.173229]\n",
      "epoch:44 step:34466[D loss: 0.375668, acc: 64.84%, op_acc: 46.88%] [G loss: 1.100868]\n",
      "epoch:44 step:34467[D loss: 0.463864, acc: 53.91%, op_acc: 33.59%] [G loss: 1.042631]\n",
      "epoch:44 step:34468[D loss: 0.387850, acc: 65.62%, op_acc: 39.84%] [G loss: 1.228978]\n",
      "epoch:44 step:34469[D loss: 0.418689, acc: 64.06%, op_acc: 40.62%] [G loss: 1.042287]\n",
      "epoch:44 step:34470[D loss: 0.417859, acc: 56.25%, op_acc: 48.44%] [G loss: 1.006279]\n",
      "epoch:44 step:34471[D loss: 0.332064, acc: 72.66%, op_acc: 53.12%] [G loss: 1.413992]\n",
      "epoch:44 step:34472[D loss: 0.450402, acc: 61.72%, op_acc: 36.72%] [G loss: 1.202927]\n",
      "epoch:44 step:34473[D loss: 0.398066, acc: 61.72%, op_acc: 42.97%] [G loss: 0.962942]\n",
      "epoch:44 step:34474[D loss: 0.364585, acc: 64.84%, op_acc: 48.44%] [G loss: 1.225427]\n",
      "epoch:44 step:34475[D loss: 0.392323, acc: 65.62%, op_acc: 50.00%] [G loss: 1.218311]\n",
      "epoch:44 step:34476[D loss: 0.414233, acc: 64.84%, op_acc: 39.06%] [G loss: 1.248062]\n",
      "epoch:44 step:34477[D loss: 0.364354, acc: 71.88%, op_acc: 46.88%] [G loss: 1.338523]\n",
      "epoch:44 step:34478[D loss: 0.413597, acc: 60.94%, op_acc: 45.31%] [G loss: 1.115590]\n",
      "epoch:44 step:34479[D loss: 0.397508, acc: 65.62%, op_acc: 51.56%] [G loss: 1.148747]\n",
      "epoch:44 step:34480[D loss: 0.462307, acc: 65.62%, op_acc: 43.75%] [G loss: 0.981398]\n",
      "epoch:44 step:34481[D loss: 0.349837, acc: 75.00%, op_acc: 48.44%] [G loss: 1.068072]\n",
      "epoch:44 step:34482[D loss: 0.422392, acc: 56.25%, op_acc: 40.62%] [G loss: 1.068472]\n",
      "epoch:44 step:34483[D loss: 0.333324, acc: 75.78%, op_acc: 49.22%] [G loss: 1.177608]\n",
      "epoch:44 step:34484[D loss: 0.369612, acc: 73.44%, op_acc: 46.09%] [G loss: 1.056672]\n",
      "epoch:44 step:34485[D loss: 0.402854, acc: 64.84%, op_acc: 49.22%] [G loss: 1.290530]\n",
      "epoch:44 step:34486[D loss: 0.440899, acc: 60.16%, op_acc: 41.41%] [G loss: 1.301093]\n",
      "epoch:44 step:34487[D loss: 0.391246, acc: 70.31%, op_acc: 42.19%] [G loss: 1.027138]\n",
      "epoch:44 step:34488[D loss: 0.396520, acc: 67.19%, op_acc: 45.31%] [G loss: 1.140341]\n",
      "epoch:44 step:34489[D loss: 0.402354, acc: 67.97%, op_acc: 43.75%] [G loss: 1.152740]\n",
      "epoch:44 step:34490[D loss: 0.440720, acc: 57.03%, op_acc: 45.31%] [G loss: 0.942204]\n",
      "epoch:44 step:34491[D loss: 0.388279, acc: 64.06%, op_acc: 41.41%] [G loss: 1.164022]\n",
      "epoch:44 step:34492[D loss: 0.377001, acc: 74.22%, op_acc: 39.84%] [G loss: 1.246336]\n",
      "epoch:44 step:34493[D loss: 0.410176, acc: 67.97%, op_acc: 39.06%] [G loss: 1.216421]\n",
      "epoch:44 step:34494[D loss: 0.358512, acc: 67.19%, op_acc: 47.66%] [G loss: 1.059002]\n",
      "epoch:44 step:34495[D loss: 0.393536, acc: 65.62%, op_acc: 45.31%] [G loss: 1.093193]\n",
      "epoch:44 step:34496[D loss: 0.387029, acc: 64.06%, op_acc: 49.22%] [G loss: 1.020712]\n",
      "epoch:44 step:34497[D loss: 0.430678, acc: 64.06%, op_acc: 39.84%] [G loss: 1.126476]\n",
      "epoch:44 step:34498[D loss: 0.460862, acc: 57.81%, op_acc: 37.50%] [G loss: 1.066116]\n",
      "epoch:44 step:34499[D loss: 0.483767, acc: 53.12%, op_acc: 39.84%] [G loss: 1.085640]\n",
      "epoch:44 step:34500[D loss: 0.379135, acc: 70.31%, op_acc: 45.31%] [G loss: 1.041938]\n",
      "epoch:44 step:34501[D loss: 0.441393, acc: 59.38%, op_acc: 45.31%] [G loss: 1.041021]\n",
      "epoch:44 step:34502[D loss: 0.389977, acc: 69.53%, op_acc: 43.75%] [G loss: 1.069369]\n",
      "epoch:44 step:34503[D loss: 0.402585, acc: 64.06%, op_acc: 41.41%] [G loss: 1.041795]\n",
      "epoch:44 step:34504[D loss: 0.492116, acc: 53.12%, op_acc: 39.84%] [G loss: 0.987734]\n",
      "epoch:44 step:34505[D loss: 0.413186, acc: 64.06%, op_acc: 38.28%] [G loss: 1.098466]\n",
      "epoch:44 step:34506[D loss: 0.411741, acc: 63.28%, op_acc: 37.50%] [G loss: 1.170195]\n",
      "epoch:44 step:34507[D loss: 0.347375, acc: 74.22%, op_acc: 44.53%] [G loss: 1.140491]\n",
      "epoch:44 step:34508[D loss: 0.407490, acc: 64.84%, op_acc: 38.28%] [G loss: 0.909808]\n",
      "epoch:44 step:34509[D loss: 0.433331, acc: 66.41%, op_acc: 35.94%] [G loss: 1.194746]\n",
      "epoch:44 step:34510[D loss: 0.354355, acc: 73.44%, op_acc: 48.44%] [G loss: 1.165312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34511[D loss: 0.401556, acc: 62.50%, op_acc: 46.09%] [G loss: 0.991201]\n",
      "epoch:44 step:34512[D loss: 0.393624, acc: 65.62%, op_acc: 43.75%] [G loss: 0.915289]\n",
      "epoch:44 step:34513[D loss: 0.386149, acc: 71.88%, op_acc: 45.31%] [G loss: 1.054008]\n",
      "epoch:44 step:34514[D loss: 0.361320, acc: 70.31%, op_acc: 48.44%] [G loss: 1.038948]\n",
      "epoch:44 step:34515[D loss: 0.407053, acc: 60.16%, op_acc: 42.97%] [G loss: 0.924006]\n",
      "epoch:44 step:34516[D loss: 0.361176, acc: 64.84%, op_acc: 43.75%] [G loss: 1.122298]\n",
      "epoch:44 step:34517[D loss: 0.421208, acc: 62.50%, op_acc: 40.62%] [G loss: 1.068953]\n",
      "epoch:44 step:34518[D loss: 0.357551, acc: 71.09%, op_acc: 42.19%] [G loss: 1.213806]\n",
      "epoch:44 step:34519[D loss: 0.360836, acc: 69.53%, op_acc: 44.53%] [G loss: 1.379174]\n",
      "epoch:44 step:34520[D loss: 0.436818, acc: 61.72%, op_acc: 41.41%] [G loss: 1.051087]\n",
      "epoch:44 step:34521[D loss: 0.380179, acc: 66.41%, op_acc: 46.88%] [G loss: 1.298718]\n",
      "epoch:44 step:34522[D loss: 0.358483, acc: 69.53%, op_acc: 46.09%] [G loss: 1.218083]\n",
      "epoch:44 step:34523[D loss: 0.358751, acc: 78.12%, op_acc: 43.75%] [G loss: 1.204729]\n",
      "epoch:44 step:34524[D loss: 0.419125, acc: 61.72%, op_acc: 35.16%] [G loss: 1.266048]\n",
      "epoch:44 step:34525[D loss: 0.418113, acc: 66.41%, op_acc: 37.50%] [G loss: 1.201720]\n",
      "epoch:44 step:34526[D loss: 0.399356, acc: 62.50%, op_acc: 47.66%] [G loss: 1.267184]\n",
      "epoch:44 step:34527[D loss: 0.405536, acc: 67.19%, op_acc: 41.41%] [G loss: 1.099484]\n",
      "epoch:44 step:34528[D loss: 0.420380, acc: 61.72%, op_acc: 35.16%] [G loss: 1.246605]\n",
      "epoch:44 step:34529[D loss: 0.339723, acc: 72.66%, op_acc: 53.91%] [G loss: 1.141012]\n",
      "epoch:44 step:34530[D loss: 0.441832, acc: 62.50%, op_acc: 40.62%] [G loss: 1.248229]\n",
      "epoch:44 step:34531[D loss: 0.393259, acc: 67.97%, op_acc: 43.75%] [G loss: 1.034835]\n",
      "epoch:44 step:34532[D loss: 0.420652, acc: 58.59%, op_acc: 36.72%] [G loss: 1.200167]\n",
      "epoch:44 step:34533[D loss: 0.373311, acc: 69.53%, op_acc: 47.66%] [G loss: 1.222313]\n",
      "epoch:44 step:34534[D loss: 0.452326, acc: 60.94%, op_acc: 42.19%] [G loss: 1.280330]\n",
      "epoch:44 step:34535[D loss: 0.433744, acc: 63.28%, op_acc: 43.75%] [G loss: 1.018919]\n",
      "epoch:44 step:34536[D loss: 0.429290, acc: 62.50%, op_acc: 40.62%] [G loss: 1.127047]\n",
      "epoch:44 step:34537[D loss: 0.437932, acc: 60.16%, op_acc: 50.78%] [G loss: 1.045794]\n",
      "epoch:44 step:34538[D loss: 0.451379, acc: 62.50%, op_acc: 43.75%] [G loss: 1.072880]\n",
      "epoch:44 step:34539[D loss: 0.394638, acc: 63.28%, op_acc: 41.41%] [G loss: 1.102860]\n",
      "epoch:44 step:34540[D loss: 0.398591, acc: 68.75%, op_acc: 46.88%] [G loss: 1.200548]\n",
      "epoch:44 step:34541[D loss: 0.349951, acc: 66.41%, op_acc: 47.66%] [G loss: 1.066254]\n",
      "epoch:44 step:34542[D loss: 0.436490, acc: 57.03%, op_acc: 42.19%] [G loss: 1.183330]\n",
      "epoch:44 step:34543[D loss: 0.389998, acc: 71.88%, op_acc: 42.19%] [G loss: 1.260072]\n",
      "epoch:44 step:34544[D loss: 0.422290, acc: 62.50%, op_acc: 42.19%] [G loss: 1.023173]\n",
      "epoch:44 step:34545[D loss: 0.369333, acc: 70.31%, op_acc: 46.09%] [G loss: 1.171231]\n",
      "epoch:44 step:34546[D loss: 0.384456, acc: 70.31%, op_acc: 46.88%] [G loss: 1.115172]\n",
      "epoch:44 step:34547[D loss: 0.363183, acc: 70.31%, op_acc: 49.22%] [G loss: 1.174869]\n",
      "epoch:44 step:34548[D loss: 0.368103, acc: 68.75%, op_acc: 46.09%] [G loss: 1.159394]\n",
      "epoch:44 step:34549[D loss: 0.388636, acc: 69.53%, op_acc: 43.75%] [G loss: 1.063648]\n",
      "epoch:44 step:34550[D loss: 0.399891, acc: 60.16%, op_acc: 45.31%] [G loss: 1.210095]\n",
      "epoch:44 step:34551[D loss: 0.426562, acc: 53.12%, op_acc: 42.19%] [G loss: 1.142353]\n",
      "epoch:44 step:34552[D loss: 0.424365, acc: 65.62%, op_acc: 38.28%] [G loss: 1.104439]\n",
      "epoch:44 step:34553[D loss: 0.479617, acc: 53.91%, op_acc: 35.94%] [G loss: 0.981151]\n",
      "epoch:44 step:34554[D loss: 0.417632, acc: 66.41%, op_acc: 44.53%] [G loss: 1.328022]\n",
      "epoch:44 step:34555[D loss: 0.410108, acc: 66.41%, op_acc: 42.97%] [G loss: 1.035820]\n",
      "epoch:44 step:34556[D loss: 0.331892, acc: 75.78%, op_acc: 44.53%] [G loss: 1.091249]\n",
      "epoch:44 step:34557[D loss: 0.396804, acc: 67.19%, op_acc: 46.09%] [G loss: 1.087430]\n",
      "epoch:44 step:34558[D loss: 0.417473, acc: 64.06%, op_acc: 42.97%] [G loss: 1.106664]\n",
      "epoch:44 step:34559[D loss: 0.398593, acc: 65.62%, op_acc: 41.41%] [G loss: 1.155665]\n",
      "epoch:44 step:34560[D loss: 0.339739, acc: 77.34%, op_acc: 43.75%] [G loss: 1.105402]\n",
      "epoch:44 step:34561[D loss: 0.452294, acc: 57.03%, op_acc: 43.75%] [G loss: 1.024164]\n",
      "epoch:44 step:34562[D loss: 0.394753, acc: 64.06%, op_acc: 47.66%] [G loss: 1.155941]\n",
      "epoch:44 step:34563[D loss: 0.418303, acc: 60.94%, op_acc: 39.06%] [G loss: 1.228284]\n",
      "epoch:44 step:34564[D loss: 0.408283, acc: 64.06%, op_acc: 43.75%] [G loss: 1.090289]\n",
      "epoch:44 step:34565[D loss: 0.357920, acc: 71.88%, op_acc: 52.34%] [G loss: 1.225022]\n",
      "epoch:44 step:34566[D loss: 0.366677, acc: 73.44%, op_acc: 38.28%] [G loss: 1.212618]\n",
      "epoch:44 step:34567[D loss: 0.434770, acc: 65.62%, op_acc: 36.72%] [G loss: 1.057376]\n",
      "epoch:44 step:34568[D loss: 0.395264, acc: 63.28%, op_acc: 45.31%] [G loss: 1.026678]\n",
      "epoch:44 step:34569[D loss: 0.420113, acc: 64.84%, op_acc: 39.06%] [G loss: 1.041467]\n",
      "epoch:44 step:34570[D loss: 0.406313, acc: 66.41%, op_acc: 41.41%] [G loss: 1.131206]\n",
      "epoch:44 step:34571[D loss: 0.298617, acc: 78.12%, op_acc: 54.69%] [G loss: 1.353261]\n",
      "epoch:44 step:34572[D loss: 0.377477, acc: 71.09%, op_acc: 46.88%] [G loss: 1.347049]\n",
      "epoch:44 step:34573[D loss: 0.369546, acc: 64.06%, op_acc: 50.00%] [G loss: 1.034337]\n",
      "epoch:44 step:34574[D loss: 0.438529, acc: 59.38%, op_acc: 39.84%] [G loss: 1.076392]\n",
      "epoch:44 step:34575[D loss: 0.362819, acc: 69.53%, op_acc: 46.88%] [G loss: 1.080964]\n",
      "epoch:44 step:34576[D loss: 0.357091, acc: 72.66%, op_acc: 47.66%] [G loss: 1.278999]\n",
      "epoch:44 step:34577[D loss: 0.363203, acc: 74.22%, op_acc: 43.75%] [G loss: 1.202435]\n",
      "epoch:44 step:34578[D loss: 0.388708, acc: 70.31%, op_acc: 41.41%] [G loss: 1.097250]\n",
      "epoch:44 step:34579[D loss: 0.439715, acc: 61.72%, op_acc: 44.53%] [G loss: 1.208189]\n",
      "epoch:44 step:34580[D loss: 0.397744, acc: 67.97%, op_acc: 38.28%] [G loss: 1.171470]\n",
      "epoch:44 step:34581[D loss: 0.369822, acc: 71.09%, op_acc: 53.12%] [G loss: 1.214405]\n",
      "epoch:44 step:34582[D loss: 0.409383, acc: 64.84%, op_acc: 52.34%] [G loss: 0.977898]\n",
      "epoch:44 step:34583[D loss: 0.325314, acc: 75.00%, op_acc: 53.12%] [G loss: 0.939867]\n",
      "epoch:44 step:34584[D loss: 0.441199, acc: 61.72%, op_acc: 42.97%] [G loss: 0.962822]\n",
      "epoch:44 step:34585[D loss: 0.390771, acc: 67.19%, op_acc: 41.41%] [G loss: 1.098002]\n",
      "epoch:44 step:34586[D loss: 0.350993, acc: 73.44%, op_acc: 48.44%] [G loss: 1.096529]\n",
      "epoch:44 step:34587[D loss: 0.377112, acc: 72.66%, op_acc: 42.97%] [G loss: 1.054009]\n",
      "epoch:44 step:34588[D loss: 0.371682, acc: 68.75%, op_acc: 49.22%] [G loss: 1.167994]\n",
      "epoch:44 step:34589[D loss: 0.352912, acc: 71.88%, op_acc: 43.75%] [G loss: 1.185588]\n",
      "epoch:44 step:34590[D loss: 0.363775, acc: 71.09%, op_acc: 53.12%] [G loss: 1.300485]\n",
      "epoch:44 step:34591[D loss: 0.345431, acc: 73.44%, op_acc: 54.69%] [G loss: 1.063559]\n",
      "epoch:44 step:34592[D loss: 0.413512, acc: 59.38%, op_acc: 39.84%] [G loss: 1.056224]\n",
      "epoch:44 step:34593[D loss: 0.391365, acc: 65.62%, op_acc: 49.22%] [G loss: 1.084642]\n",
      "epoch:44 step:34594[D loss: 0.404176, acc: 67.19%, op_acc: 39.84%] [G loss: 1.112429]\n",
      "epoch:44 step:34595[D loss: 0.356068, acc: 68.75%, op_acc: 46.88%] [G loss: 1.161646]\n",
      "epoch:44 step:34596[D loss: 0.359684, acc: 71.88%, op_acc: 45.31%] [G loss: 1.216863]\n",
      "epoch:44 step:34597[D loss: 0.411821, acc: 63.28%, op_acc: 50.00%] [G loss: 1.024194]\n",
      "epoch:44 step:34598[D loss: 0.467822, acc: 54.69%, op_acc: 43.75%] [G loss: 1.239524]\n",
      "epoch:44 step:34599[D loss: 0.405159, acc: 64.84%, op_acc: 45.31%] [G loss: 1.106064]\n",
      "epoch:44 step:34600[D loss: 0.392065, acc: 67.19%, op_acc: 39.06%] [G loss: 1.077498]\n",
      "epoch:44 step:34601[D loss: 0.414790, acc: 57.03%, op_acc: 42.19%] [G loss: 1.193817]\n",
      "epoch:44 step:34602[D loss: 0.414427, acc: 64.06%, op_acc: 45.31%] [G loss: 1.031555]\n",
      "epoch:44 step:34603[D loss: 0.352613, acc: 75.00%, op_acc: 49.22%] [G loss: 1.126729]\n",
      "epoch:44 step:34604[D loss: 0.374037, acc: 70.31%, op_acc: 47.66%] [G loss: 1.130460]\n",
      "epoch:44 step:34605[D loss: 0.374216, acc: 64.06%, op_acc: 46.09%] [G loss: 0.885008]\n",
      "epoch:44 step:34606[D loss: 0.349458, acc: 75.00%, op_acc: 51.56%] [G loss: 1.036266]\n",
      "epoch:44 step:34607[D loss: 0.458720, acc: 56.25%, op_acc: 37.50%] [G loss: 1.158311]\n",
      "epoch:44 step:34608[D loss: 0.405827, acc: 67.19%, op_acc: 42.19%] [G loss: 1.286559]\n",
      "epoch:44 step:34609[D loss: 0.419771, acc: 57.03%, op_acc: 44.53%] [G loss: 1.206697]\n",
      "epoch:44 step:34610[D loss: 0.467563, acc: 59.38%, op_acc: 38.28%] [G loss: 1.083086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34611[D loss: 0.367267, acc: 71.09%, op_acc: 44.53%] [G loss: 1.084350]\n",
      "epoch:44 step:34612[D loss: 0.449842, acc: 55.47%, op_acc: 39.84%] [G loss: 1.038835]\n",
      "epoch:44 step:34613[D loss: 0.357403, acc: 73.44%, op_acc: 46.88%] [G loss: 1.155271]\n",
      "epoch:44 step:34614[D loss: 0.459263, acc: 59.38%, op_acc: 37.50%] [G loss: 0.976775]\n",
      "epoch:44 step:34615[D loss: 0.334175, acc: 68.75%, op_acc: 50.78%] [G loss: 1.280061]\n",
      "epoch:44 step:34616[D loss: 0.344427, acc: 71.09%, op_acc: 52.34%] [G loss: 0.974481]\n",
      "epoch:44 step:34617[D loss: 0.382920, acc: 67.19%, op_acc: 48.44%] [G loss: 1.151636]\n",
      "epoch:44 step:34618[D loss: 0.387046, acc: 60.94%, op_acc: 44.53%] [G loss: 1.161835]\n",
      "epoch:44 step:34619[D loss: 0.398196, acc: 62.50%, op_acc: 42.19%] [G loss: 1.081980]\n",
      "epoch:44 step:34620[D loss: 0.421045, acc: 64.06%, op_acc: 43.75%] [G loss: 1.043957]\n",
      "epoch:44 step:34621[D loss: 0.384729, acc: 68.75%, op_acc: 38.28%] [G loss: 1.135396]\n",
      "epoch:44 step:34622[D loss: 0.416861, acc: 62.50%, op_acc: 38.28%] [G loss: 1.146667]\n",
      "epoch:44 step:34623[D loss: 0.407553, acc: 64.84%, op_acc: 41.41%] [G loss: 1.186301]\n",
      "epoch:44 step:34624[D loss: 0.419092, acc: 65.62%, op_acc: 42.97%] [G loss: 1.147446]\n",
      "epoch:44 step:34625[D loss: 0.412630, acc: 64.06%, op_acc: 39.84%] [G loss: 1.139002]\n",
      "epoch:44 step:34626[D loss: 0.390925, acc: 64.06%, op_acc: 41.41%] [G loss: 1.305280]\n",
      "epoch:44 step:34627[D loss: 0.370765, acc: 72.66%, op_acc: 53.12%] [G loss: 1.043023]\n",
      "epoch:44 step:34628[D loss: 0.355012, acc: 75.00%, op_acc: 43.75%] [G loss: 1.304045]\n",
      "epoch:44 step:34629[D loss: 0.341973, acc: 74.22%, op_acc: 50.78%] [G loss: 1.324278]\n",
      "epoch:44 step:34630[D loss: 0.389262, acc: 64.06%, op_acc: 50.78%] [G loss: 1.000449]\n",
      "epoch:44 step:34631[D loss: 0.446603, acc: 56.25%, op_acc: 49.22%] [G loss: 1.051041]\n",
      "epoch:44 step:34632[D loss: 0.399990, acc: 65.62%, op_acc: 46.88%] [G loss: 1.081671]\n",
      "epoch:44 step:34633[D loss: 0.452941, acc: 54.69%, op_acc: 46.09%] [G loss: 1.149435]\n",
      "epoch:44 step:34634[D loss: 0.426506, acc: 57.81%, op_acc: 43.75%] [G loss: 0.929121]\n",
      "epoch:44 step:34635[D loss: 0.440477, acc: 58.59%, op_acc: 39.06%] [G loss: 1.153886]\n",
      "epoch:44 step:34636[D loss: 0.394625, acc: 62.50%, op_acc: 42.19%] [G loss: 1.305115]\n",
      "epoch:44 step:34637[D loss: 0.408209, acc: 65.62%, op_acc: 47.66%] [G loss: 1.037550]\n",
      "epoch:44 step:34638[D loss: 0.398512, acc: 64.84%, op_acc: 42.97%] [G loss: 1.119544]\n",
      "epoch:44 step:34639[D loss: 0.416818, acc: 60.94%, op_acc: 46.88%] [G loss: 1.042969]\n",
      "epoch:44 step:34640[D loss: 0.412277, acc: 57.03%, op_acc: 39.06%] [G loss: 1.103692]\n",
      "epoch:44 step:34641[D loss: 0.380985, acc: 69.53%, op_acc: 41.41%] [G loss: 1.111336]\n",
      "epoch:44 step:34642[D loss: 0.406593, acc: 62.50%, op_acc: 45.31%] [G loss: 1.100051]\n",
      "epoch:44 step:34643[D loss: 0.447500, acc: 51.56%, op_acc: 44.53%] [G loss: 0.971190]\n",
      "epoch:44 step:34644[D loss: 0.393357, acc: 65.62%, op_acc: 51.56%] [G loss: 1.067423]\n",
      "epoch:44 step:34645[D loss: 0.449618, acc: 60.16%, op_acc: 38.28%] [G loss: 1.271880]\n",
      "epoch:44 step:34646[D loss: 0.434992, acc: 60.94%, op_acc: 42.19%] [G loss: 1.132194]\n",
      "epoch:44 step:34647[D loss: 0.384025, acc: 67.19%, op_acc: 46.88%] [G loss: 1.020549]\n",
      "epoch:44 step:34648[D loss: 0.410341, acc: 62.50%, op_acc: 44.53%] [G loss: 0.917701]\n",
      "epoch:44 step:34649[D loss: 0.432151, acc: 57.03%, op_acc: 41.41%] [G loss: 1.270385]\n",
      "epoch:44 step:34650[D loss: 0.375552, acc: 67.97%, op_acc: 46.88%] [G loss: 1.155910]\n",
      "epoch:44 step:34651[D loss: 0.438643, acc: 65.62%, op_acc: 49.22%] [G loss: 1.072641]\n",
      "epoch:44 step:34652[D loss: 0.386329, acc: 62.50%, op_acc: 41.41%] [G loss: 1.075620]\n",
      "epoch:44 step:34653[D loss: 0.416592, acc: 64.06%, op_acc: 39.06%] [G loss: 1.150592]\n",
      "epoch:44 step:34654[D loss: 0.365924, acc: 72.66%, op_acc: 38.28%] [G loss: 1.225290]\n",
      "epoch:44 step:34655[D loss: 0.468201, acc: 50.78%, op_acc: 41.41%] [G loss: 1.225914]\n",
      "epoch:44 step:34656[D loss: 0.414062, acc: 62.50%, op_acc: 43.75%] [G loss: 1.151165]\n",
      "epoch:44 step:34657[D loss: 0.409374, acc: 64.06%, op_acc: 42.97%] [G loss: 1.232021]\n",
      "epoch:44 step:34658[D loss: 0.410756, acc: 65.62%, op_acc: 39.84%] [G loss: 1.257236]\n",
      "epoch:44 step:34659[D loss: 0.412993, acc: 65.62%, op_acc: 42.97%] [G loss: 1.101839]\n",
      "epoch:44 step:34660[D loss: 0.411328, acc: 54.69%, op_acc: 49.22%] [G loss: 1.105038]\n",
      "epoch:44 step:34661[D loss: 0.429437, acc: 58.59%, op_acc: 35.16%] [G loss: 1.127286]\n",
      "epoch:44 step:34662[D loss: 0.388871, acc: 67.97%, op_acc: 43.75%] [G loss: 1.130794]\n",
      "epoch:44 step:34663[D loss: 0.378910, acc: 69.53%, op_acc: 43.75%] [G loss: 1.112552]\n",
      "epoch:44 step:34664[D loss: 0.376014, acc: 71.09%, op_acc: 46.88%] [G loss: 1.249340]\n",
      "epoch:44 step:34665[D loss: 0.412028, acc: 64.06%, op_acc: 36.72%] [G loss: 1.126522]\n",
      "epoch:44 step:34666[D loss: 0.334067, acc: 75.78%, op_acc: 51.56%] [G loss: 0.969856]\n",
      "epoch:44 step:34667[D loss: 0.393176, acc: 64.84%, op_acc: 43.75%] [G loss: 1.214409]\n",
      "epoch:44 step:34668[D loss: 0.396075, acc: 64.06%, op_acc: 47.66%] [G loss: 1.155243]\n",
      "epoch:44 step:34669[D loss: 0.404433, acc: 61.72%, op_acc: 42.19%] [G loss: 1.075580]\n",
      "epoch:44 step:34670[D loss: 0.392722, acc: 71.09%, op_acc: 45.31%] [G loss: 1.181527]\n",
      "epoch:44 step:34671[D loss: 0.401423, acc: 62.50%, op_acc: 43.75%] [G loss: 1.122788]\n",
      "epoch:44 step:34672[D loss: 0.412320, acc: 62.50%, op_acc: 39.84%] [G loss: 0.965961]\n",
      "epoch:44 step:34673[D loss: 0.460259, acc: 55.47%, op_acc: 39.84%] [G loss: 1.114116]\n",
      "epoch:44 step:34674[D loss: 0.353931, acc: 75.78%, op_acc: 46.09%] [G loss: 1.234542]\n",
      "epoch:44 step:34675[D loss: 0.412800, acc: 61.72%, op_acc: 46.88%] [G loss: 1.023242]\n",
      "epoch:44 step:34676[D loss: 0.384956, acc: 66.41%, op_acc: 41.41%] [G loss: 1.064615]\n",
      "epoch:44 step:34677[D loss: 0.440483, acc: 58.59%, op_acc: 42.19%] [G loss: 1.149720]\n",
      "epoch:44 step:34678[D loss: 0.382879, acc: 65.62%, op_acc: 42.19%] [G loss: 1.153153]\n",
      "epoch:44 step:34679[D loss: 0.429731, acc: 60.16%, op_acc: 42.97%] [G loss: 0.943011]\n",
      "epoch:44 step:34680[D loss: 0.394016, acc: 67.19%, op_acc: 42.97%] [G loss: 1.074661]\n",
      "epoch:44 step:34681[D loss: 0.396524, acc: 66.41%, op_acc: 46.88%] [G loss: 1.109128]\n",
      "epoch:44 step:34682[D loss: 0.428808, acc: 67.97%, op_acc: 44.53%] [G loss: 1.069156]\n",
      "epoch:44 step:34683[D loss: 0.361882, acc: 67.97%, op_acc: 46.88%] [G loss: 1.155717]\n",
      "epoch:44 step:34684[D loss: 0.379824, acc: 67.19%, op_acc: 39.06%] [G loss: 1.164412]\n",
      "epoch:44 step:34685[D loss: 0.341181, acc: 77.34%, op_acc: 42.97%] [G loss: 1.020123]\n",
      "epoch:44 step:34686[D loss: 0.441360, acc: 64.06%, op_acc: 37.50%] [G loss: 1.076584]\n",
      "epoch:44 step:34687[D loss: 0.400668, acc: 63.28%, op_acc: 39.84%] [G loss: 1.210719]\n",
      "epoch:44 step:34688[D loss: 0.427948, acc: 57.03%, op_acc: 42.19%] [G loss: 1.002042]\n",
      "epoch:44 step:34689[D loss: 0.399983, acc: 61.72%, op_acc: 45.31%] [G loss: 1.226873]\n",
      "epoch:44 step:34690[D loss: 0.415470, acc: 61.72%, op_acc: 47.66%] [G loss: 1.109376]\n",
      "epoch:44 step:34691[D loss: 0.430963, acc: 60.94%, op_acc: 41.41%] [G loss: 1.221927]\n",
      "epoch:44 step:34692[D loss: 0.371848, acc: 73.44%, op_acc: 42.97%] [G loss: 1.113535]\n",
      "epoch:44 step:34693[D loss: 0.391952, acc: 70.31%, op_acc: 42.19%] [G loss: 1.215054]\n",
      "epoch:44 step:34694[D loss: 0.371982, acc: 70.31%, op_acc: 44.53%] [G loss: 1.175682]\n",
      "epoch:44 step:34695[D loss: 0.400517, acc: 59.38%, op_acc: 43.75%] [G loss: 1.044578]\n",
      "epoch:44 step:34696[D loss: 0.383606, acc: 72.66%, op_acc: 50.00%] [G loss: 1.135984]\n",
      "epoch:44 step:34697[D loss: 0.386785, acc: 73.44%, op_acc: 46.88%] [G loss: 1.168838]\n",
      "epoch:44 step:34698[D loss: 0.388164, acc: 67.19%, op_acc: 44.53%] [G loss: 1.028712]\n",
      "epoch:44 step:34699[D loss: 0.433641, acc: 63.28%, op_acc: 41.41%] [G loss: 1.134829]\n",
      "epoch:44 step:34700[D loss: 0.411786, acc: 60.94%, op_acc: 41.41%] [G loss: 1.230551]\n",
      "epoch:44 step:34701[D loss: 0.453299, acc: 60.16%, op_acc: 37.50%] [G loss: 1.248329]\n",
      "epoch:44 step:34702[D loss: 0.412581, acc: 64.84%, op_acc: 39.06%] [G loss: 0.895747]\n",
      "epoch:44 step:34703[D loss: 0.423694, acc: 60.16%, op_acc: 39.84%] [G loss: 1.151529]\n",
      "epoch:44 step:34704[D loss: 0.420125, acc: 59.38%, op_acc: 47.66%] [G loss: 1.216482]\n",
      "epoch:44 step:34705[D loss: 0.374198, acc: 70.31%, op_acc: 45.31%] [G loss: 1.231657]\n",
      "epoch:44 step:34706[D loss: 0.470418, acc: 54.69%, op_acc: 34.38%] [G loss: 1.135694]\n",
      "epoch:44 step:34707[D loss: 0.425085, acc: 62.50%, op_acc: 39.84%] [G loss: 1.055696]\n",
      "epoch:44 step:34708[D loss: 0.420731, acc: 56.25%, op_acc: 42.19%] [G loss: 1.050382]\n",
      "epoch:44 step:34709[D loss: 0.416503, acc: 60.94%, op_acc: 39.06%] [G loss: 1.307571]\n",
      "epoch:44 step:34710[D loss: 0.394233, acc: 66.41%, op_acc: 39.06%] [G loss: 1.211830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34711[D loss: 0.390150, acc: 63.28%, op_acc: 45.31%] [G loss: 1.091427]\n",
      "epoch:44 step:34712[D loss: 0.372467, acc: 72.66%, op_acc: 37.50%] [G loss: 0.983770]\n",
      "epoch:44 step:34713[D loss: 0.406147, acc: 67.97%, op_acc: 46.09%] [G loss: 1.340131]\n",
      "epoch:44 step:34714[D loss: 0.401609, acc: 69.53%, op_acc: 45.31%] [G loss: 1.298537]\n",
      "epoch:44 step:34715[D loss: 0.334295, acc: 76.56%, op_acc: 50.00%] [G loss: 1.183742]\n",
      "epoch:44 step:34716[D loss: 0.394700, acc: 66.41%, op_acc: 40.62%] [G loss: 1.158662]\n",
      "epoch:44 step:34717[D loss: 0.363323, acc: 68.75%, op_acc: 49.22%] [G loss: 1.055716]\n",
      "epoch:44 step:34718[D loss: 0.393266, acc: 67.19%, op_acc: 46.09%] [G loss: 1.157463]\n",
      "epoch:44 step:34719[D loss: 0.413211, acc: 60.94%, op_acc: 45.31%] [G loss: 0.997949]\n",
      "epoch:44 step:34720[D loss: 0.416349, acc: 62.50%, op_acc: 39.84%] [G loss: 1.139953]\n",
      "epoch:44 step:34721[D loss: 0.356948, acc: 73.44%, op_acc: 42.97%] [G loss: 1.345021]\n",
      "epoch:44 step:34722[D loss: 0.374011, acc: 71.09%, op_acc: 46.09%] [G loss: 1.216632]\n",
      "epoch:44 step:34723[D loss: 0.425789, acc: 62.50%, op_acc: 44.53%] [G loss: 1.039860]\n",
      "epoch:44 step:34724[D loss: 0.431006, acc: 62.50%, op_acc: 42.19%] [G loss: 1.097392]\n",
      "epoch:44 step:34725[D loss: 0.363473, acc: 68.75%, op_acc: 43.75%] [G loss: 1.037592]\n",
      "epoch:44 step:34726[D loss: 0.385974, acc: 62.50%, op_acc: 44.53%] [G loss: 1.104300]\n",
      "epoch:44 step:34727[D loss: 0.394937, acc: 67.97%, op_acc: 39.06%] [G loss: 1.103809]\n",
      "epoch:44 step:34728[D loss: 0.367856, acc: 71.09%, op_acc: 42.97%] [G loss: 1.099369]\n",
      "epoch:44 step:34729[D loss: 0.322890, acc: 81.25%, op_acc: 48.44%] [G loss: 1.181391]\n",
      "epoch:44 step:34730[D loss: 0.410656, acc: 60.94%, op_acc: 42.19%] [G loss: 1.207338]\n",
      "epoch:44 step:34731[D loss: 0.398499, acc: 67.19%, op_acc: 42.97%] [G loss: 1.262639]\n",
      "epoch:44 step:34732[D loss: 0.436467, acc: 58.59%, op_acc: 38.28%] [G loss: 1.177670]\n",
      "epoch:44 step:34733[D loss: 0.379232, acc: 72.66%, op_acc: 39.84%] [G loss: 1.342977]\n",
      "epoch:44 step:34734[D loss: 0.412682, acc: 64.06%, op_acc: 37.50%] [G loss: 1.226155]\n",
      "epoch:44 step:34735[D loss: 0.379092, acc: 64.84%, op_acc: 46.09%] [G loss: 1.189731]\n",
      "epoch:44 step:34736[D loss: 0.377924, acc: 68.75%, op_acc: 47.66%] [G loss: 1.037805]\n",
      "epoch:44 step:34737[D loss: 0.410423, acc: 62.50%, op_acc: 46.09%] [G loss: 1.266941]\n",
      "epoch:44 step:34738[D loss: 0.402756, acc: 61.72%, op_acc: 46.88%] [G loss: 0.990916]\n",
      "epoch:44 step:34739[D loss: 0.396085, acc: 62.50%, op_acc: 39.84%] [G loss: 1.009387]\n",
      "epoch:44 step:34740[D loss: 0.390249, acc: 68.75%, op_acc: 40.62%] [G loss: 1.176913]\n",
      "epoch:44 step:34741[D loss: 0.377230, acc: 68.75%, op_acc: 46.88%] [G loss: 1.170124]\n",
      "epoch:44 step:34742[D loss: 0.406593, acc: 61.72%, op_acc: 46.09%] [G loss: 1.122999]\n",
      "epoch:44 step:34743[D loss: 0.406600, acc: 64.84%, op_acc: 42.19%] [G loss: 1.151029]\n",
      "epoch:44 step:34744[D loss: 0.354188, acc: 75.78%, op_acc: 44.53%] [G loss: 1.091346]\n",
      "epoch:44 step:34745[D loss: 0.334081, acc: 80.47%, op_acc: 42.19%] [G loss: 1.190239]\n",
      "epoch:44 step:34746[D loss: 0.376826, acc: 65.62%, op_acc: 49.22%] [G loss: 1.014116]\n",
      "epoch:44 step:34747[D loss: 0.379042, acc: 61.72%, op_acc: 45.31%] [G loss: 1.181957]\n",
      "epoch:44 step:34748[D loss: 0.404989, acc: 71.88%, op_acc: 43.75%] [G loss: 1.006966]\n",
      "epoch:44 step:34749[D loss: 0.359860, acc: 64.84%, op_acc: 51.56%] [G loss: 0.977809]\n",
      "epoch:44 step:34750[D loss: 0.388530, acc: 65.62%, op_acc: 46.88%] [G loss: 1.113400]\n",
      "epoch:44 step:34751[D loss: 0.364779, acc: 75.00%, op_acc: 44.53%] [G loss: 1.175860]\n",
      "epoch:44 step:34752[D loss: 0.373428, acc: 68.75%, op_acc: 41.41%] [G loss: 1.145200]\n",
      "epoch:44 step:34753[D loss: 0.429694, acc: 58.59%, op_acc: 41.41%] [G loss: 0.899043]\n",
      "epoch:44 step:34754[D loss: 0.395291, acc: 65.62%, op_acc: 45.31%] [G loss: 1.151361]\n",
      "epoch:44 step:34755[D loss: 0.367791, acc: 67.97%, op_acc: 49.22%] [G loss: 0.987486]\n",
      "epoch:44 step:34756[D loss: 0.408252, acc: 59.38%, op_acc: 48.44%] [G loss: 1.007826]\n",
      "epoch:44 step:34757[D loss: 0.383070, acc: 71.88%, op_acc: 41.41%] [G loss: 1.208960]\n",
      "epoch:44 step:34758[D loss: 0.366920, acc: 75.00%, op_acc: 38.28%] [G loss: 1.226130]\n",
      "epoch:44 step:34759[D loss: 0.457159, acc: 58.59%, op_acc: 36.72%] [G loss: 1.058083]\n",
      "epoch:44 step:34760[D loss: 0.354519, acc: 69.53%, op_acc: 50.00%] [G loss: 0.912413]\n",
      "epoch:44 step:34761[D loss: 0.403322, acc: 63.28%, op_acc: 39.84%] [G loss: 1.043124]\n",
      "epoch:44 step:34762[D loss: 0.458619, acc: 56.25%, op_acc: 38.28%] [G loss: 1.049051]\n",
      "epoch:44 step:34763[D loss: 0.416519, acc: 61.72%, op_acc: 42.19%] [G loss: 0.757471]\n",
      "epoch:44 step:34764[D loss: 0.402045, acc: 67.19%, op_acc: 42.19%] [G loss: 0.986794]\n",
      "epoch:44 step:34765[D loss: 0.406089, acc: 65.62%, op_acc: 42.19%] [G loss: 1.323598]\n",
      "epoch:44 step:34766[D loss: 0.386314, acc: 67.19%, op_acc: 40.62%] [G loss: 1.129415]\n",
      "epoch:44 step:34767[D loss: 0.391323, acc: 62.50%, op_acc: 42.97%] [G loss: 1.385574]\n",
      "epoch:44 step:34768[D loss: 0.346392, acc: 76.56%, op_acc: 50.78%] [G loss: 1.130964]\n",
      "epoch:44 step:34769[D loss: 0.402278, acc: 71.09%, op_acc: 42.19%] [G loss: 1.131090]\n",
      "epoch:44 step:34770[D loss: 0.361752, acc: 71.88%, op_acc: 44.53%] [G loss: 1.034468]\n",
      "epoch:44 step:34771[D loss: 0.394302, acc: 68.75%, op_acc: 42.97%] [G loss: 0.962887]\n",
      "epoch:44 step:34772[D loss: 0.369984, acc: 66.41%, op_acc: 48.44%] [G loss: 1.178453]\n",
      "epoch:44 step:34773[D loss: 0.429062, acc: 61.72%, op_acc: 41.41%] [G loss: 1.174086]\n",
      "epoch:44 step:34774[D loss: 0.423612, acc: 62.50%, op_acc: 42.97%] [G loss: 1.154925]\n",
      "epoch:44 step:34775[D loss: 0.427713, acc: 65.62%, op_acc: 37.50%] [G loss: 1.048067]\n",
      "epoch:44 step:34776[D loss: 0.340266, acc: 75.00%, op_acc: 48.44%] [G loss: 1.088755]\n",
      "epoch:44 step:34777[D loss: 0.389717, acc: 62.50%, op_acc: 49.22%] [G loss: 1.133956]\n",
      "epoch:44 step:34778[D loss: 0.474280, acc: 58.59%, op_acc: 36.72%] [G loss: 1.186456]\n",
      "epoch:44 step:34779[D loss: 0.370269, acc: 68.75%, op_acc: 44.53%] [G loss: 1.070113]\n",
      "epoch:44 step:34780[D loss: 0.437522, acc: 57.03%, op_acc: 44.53%] [G loss: 1.132990]\n",
      "epoch:44 step:34781[D loss: 0.421231, acc: 59.38%, op_acc: 43.75%] [G loss: 1.168625]\n",
      "epoch:44 step:34782[D loss: 0.439879, acc: 60.94%, op_acc: 42.19%] [G loss: 1.130941]\n",
      "epoch:44 step:34783[D loss: 0.411020, acc: 64.84%, op_acc: 43.75%] [G loss: 1.111629]\n",
      "epoch:44 step:34784[D loss: 0.403238, acc: 66.41%, op_acc: 43.75%] [G loss: 1.083686]\n",
      "epoch:44 step:34785[D loss: 0.405747, acc: 66.41%, op_acc: 40.62%] [G loss: 1.038169]\n",
      "epoch:44 step:34786[D loss: 0.337112, acc: 74.22%, op_acc: 53.91%] [G loss: 0.978738]\n",
      "epoch:44 step:34787[D loss: 0.403717, acc: 71.88%, op_acc: 44.53%] [G loss: 1.101437]\n",
      "epoch:44 step:34788[D loss: 0.409022, acc: 67.19%, op_acc: 44.53%] [G loss: 1.129826]\n",
      "epoch:44 step:34789[D loss: 0.416383, acc: 54.69%, op_acc: 42.19%] [G loss: 1.140376]\n",
      "epoch:44 step:34790[D loss: 0.463883, acc: 56.25%, op_acc: 37.50%] [G loss: 0.943465]\n",
      "epoch:44 step:34791[D loss: 0.369188, acc: 71.88%, op_acc: 45.31%] [G loss: 1.293959]\n",
      "epoch:44 step:34792[D loss: 0.376598, acc: 67.97%, op_acc: 48.44%] [G loss: 1.085927]\n",
      "epoch:44 step:34793[D loss: 0.407238, acc: 66.41%, op_acc: 39.84%] [G loss: 1.049962]\n",
      "epoch:44 step:34794[D loss: 0.395474, acc: 64.84%, op_acc: 46.09%] [G loss: 1.023365]\n",
      "epoch:44 step:34795[D loss: 0.464156, acc: 56.25%, op_acc: 35.94%] [G loss: 1.007524]\n",
      "epoch:44 step:34796[D loss: 0.338642, acc: 73.44%, op_acc: 50.78%] [G loss: 1.197642]\n",
      "epoch:44 step:34797[D loss: 0.408231, acc: 62.50%, op_acc: 42.97%] [G loss: 1.240273]\n",
      "epoch:44 step:34798[D loss: 0.361847, acc: 65.62%, op_acc: 51.56%] [G loss: 1.027625]\n",
      "epoch:44 step:34799[D loss: 0.414162, acc: 63.28%, op_acc: 42.97%] [G loss: 0.985363]\n",
      "epoch:44 step:34800[D loss: 0.395248, acc: 64.84%, op_acc: 48.44%] [G loss: 1.136348]\n",
      "epoch:44 step:34801[D loss: 0.388329, acc: 64.06%, op_acc: 47.66%] [G loss: 0.922523]\n",
      "epoch:44 step:34802[D loss: 0.400379, acc: 63.28%, op_acc: 43.75%] [G loss: 1.048557]\n",
      "epoch:44 step:34803[D loss: 0.434758, acc: 60.94%, op_acc: 50.00%] [G loss: 0.970131]\n",
      "epoch:44 step:34804[D loss: 0.395077, acc: 70.31%, op_acc: 35.94%] [G loss: 1.115052]\n",
      "epoch:44 step:34805[D loss: 0.446671, acc: 58.59%, op_acc: 36.72%] [G loss: 0.951516]\n",
      "epoch:44 step:34806[D loss: 0.431702, acc: 59.38%, op_acc: 44.53%] [G loss: 1.290600]\n",
      "epoch:44 step:34807[D loss: 0.392451, acc: 64.84%, op_acc: 37.50%] [G loss: 1.163789]\n",
      "epoch:44 step:34808[D loss: 0.390117, acc: 60.94%, op_acc: 42.97%] [G loss: 1.029663]\n",
      "epoch:44 step:34809[D loss: 0.432499, acc: 65.62%, op_acc: 35.16%] [G loss: 1.029207]\n",
      "epoch:44 step:34810[D loss: 0.405476, acc: 67.97%, op_acc: 45.31%] [G loss: 1.205899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34811[D loss: 0.398947, acc: 67.97%, op_acc: 45.31%] [G loss: 1.091936]\n",
      "epoch:44 step:34812[D loss: 0.318187, acc: 78.91%, op_acc: 50.78%] [G loss: 1.128569]\n",
      "epoch:44 step:34813[D loss: 0.355909, acc: 73.44%, op_acc: 46.09%] [G loss: 1.352937]\n",
      "epoch:44 step:34814[D loss: 0.451799, acc: 57.03%, op_acc: 38.28%] [G loss: 1.171335]\n",
      "epoch:44 step:34815[D loss: 0.373162, acc: 68.75%, op_acc: 47.66%] [G loss: 1.303979]\n",
      "epoch:44 step:34816[D loss: 0.402321, acc: 65.62%, op_acc: 48.44%] [G loss: 1.348320]\n",
      "epoch:44 step:34817[D loss: 0.375525, acc: 67.19%, op_acc: 46.09%] [G loss: 1.157252]\n",
      "epoch:44 step:34818[D loss: 0.378727, acc: 64.84%, op_acc: 46.88%] [G loss: 1.089121]\n",
      "epoch:44 step:34819[D loss: 0.400876, acc: 66.41%, op_acc: 45.31%] [G loss: 1.062283]\n",
      "epoch:44 step:34820[D loss: 0.420978, acc: 60.16%, op_acc: 42.97%] [G loss: 1.162419]\n",
      "epoch:44 step:34821[D loss: 0.380524, acc: 66.41%, op_acc: 43.75%] [G loss: 1.311439]\n",
      "epoch:44 step:34822[D loss: 0.366315, acc: 69.53%, op_acc: 52.34%] [G loss: 1.184421]\n",
      "epoch:44 step:34823[D loss: 0.439297, acc: 56.25%, op_acc: 40.62%] [G loss: 1.034497]\n",
      "epoch:44 step:34824[D loss: 0.358320, acc: 71.09%, op_acc: 46.09%] [G loss: 1.103729]\n",
      "epoch:44 step:34825[D loss: 0.419352, acc: 61.72%, op_acc: 40.62%] [G loss: 1.218795]\n",
      "epoch:44 step:34826[D loss: 0.402102, acc: 71.88%, op_acc: 50.78%] [G loss: 1.244000]\n",
      "epoch:44 step:34827[D loss: 0.419092, acc: 60.16%, op_acc: 50.78%] [G loss: 1.055196]\n",
      "epoch:44 step:34828[D loss: 0.428969, acc: 61.72%, op_acc: 40.62%] [G loss: 0.906055]\n",
      "epoch:44 step:34829[D loss: 0.408665, acc: 63.28%, op_acc: 41.41%] [G loss: 1.194095]\n",
      "epoch:44 step:34830[D loss: 0.351481, acc: 73.44%, op_acc: 42.97%] [G loss: 1.110727]\n",
      "epoch:44 step:34831[D loss: 0.379647, acc: 68.75%, op_acc: 46.88%] [G loss: 1.160355]\n",
      "epoch:44 step:34832[D loss: 0.408647, acc: 61.72%, op_acc: 40.62%] [G loss: 1.131763]\n",
      "epoch:44 step:34833[D loss: 0.351509, acc: 78.91%, op_acc: 46.09%] [G loss: 1.275668]\n",
      "epoch:44 step:34834[D loss: 0.382090, acc: 64.06%, op_acc: 46.09%] [G loss: 1.082795]\n",
      "epoch:44 step:34835[D loss: 0.382175, acc: 67.97%, op_acc: 42.97%] [G loss: 1.189411]\n",
      "epoch:44 step:34836[D loss: 0.393829, acc: 67.19%, op_acc: 38.28%] [G loss: 1.212744]\n",
      "epoch:44 step:34837[D loss: 0.403151, acc: 62.50%, op_acc: 46.09%] [G loss: 0.926970]\n",
      "epoch:44 step:34838[D loss: 0.449235, acc: 52.34%, op_acc: 35.16%] [G loss: 1.187493]\n",
      "epoch:44 step:34839[D loss: 0.419612, acc: 57.03%, op_acc: 41.41%] [G loss: 1.087865]\n",
      "epoch:44 step:34840[D loss: 0.383821, acc: 70.31%, op_acc: 42.97%] [G loss: 1.171470]\n",
      "epoch:44 step:34841[D loss: 0.405801, acc: 62.50%, op_acc: 39.06%] [G loss: 1.201981]\n",
      "epoch:44 step:34842[D loss: 0.354669, acc: 71.09%, op_acc: 46.09%] [G loss: 1.278865]\n",
      "epoch:44 step:34843[D loss: 0.369590, acc: 65.62%, op_acc: 50.00%] [G loss: 1.264839]\n",
      "epoch:44 step:34844[D loss: 0.442343, acc: 60.94%, op_acc: 36.72%] [G loss: 1.050156]\n",
      "epoch:44 step:34845[D loss: 0.467311, acc: 54.69%, op_acc: 38.28%] [G loss: 1.167436]\n",
      "epoch:44 step:34846[D loss: 0.389175, acc: 67.97%, op_acc: 40.62%] [G loss: 1.015041]\n",
      "epoch:44 step:34847[D loss: 0.403914, acc: 70.31%, op_acc: 35.94%] [G loss: 1.198067]\n",
      "epoch:44 step:34848[D loss: 0.363308, acc: 75.00%, op_acc: 53.12%] [G loss: 1.256844]\n",
      "epoch:44 step:34849[D loss: 0.448828, acc: 54.69%, op_acc: 42.97%] [G loss: 1.069034]\n",
      "epoch:44 step:34850[D loss: 0.355822, acc: 70.31%, op_acc: 47.66%] [G loss: 1.121148]\n",
      "epoch:44 step:34851[D loss: 0.357811, acc: 66.41%, op_acc: 47.66%] [G loss: 1.089901]\n",
      "epoch:44 step:34852[D loss: 0.404960, acc: 69.53%, op_acc: 40.62%] [G loss: 1.139632]\n",
      "epoch:44 step:34853[D loss: 0.378778, acc: 73.44%, op_acc: 42.97%] [G loss: 1.292325]\n",
      "epoch:44 step:34854[D loss: 0.402583, acc: 60.94%, op_acc: 50.00%] [G loss: 1.224840]\n",
      "epoch:44 step:34855[D loss: 0.445590, acc: 58.59%, op_acc: 38.28%] [G loss: 1.207211]\n",
      "epoch:44 step:34856[D loss: 0.390105, acc: 65.62%, op_acc: 45.31%] [G loss: 1.030578]\n",
      "epoch:44 step:34857[D loss: 0.404756, acc: 60.94%, op_acc: 47.66%] [G loss: 1.152132]\n",
      "epoch:44 step:34858[D loss: 0.324470, acc: 78.91%, op_acc: 47.66%] [G loss: 1.093699]\n",
      "epoch:44 step:34859[D loss: 0.359787, acc: 69.53%, op_acc: 46.88%] [G loss: 1.232912]\n",
      "epoch:44 step:34860[D loss: 0.348647, acc: 75.00%, op_acc: 43.75%] [G loss: 1.164616]\n",
      "epoch:44 step:34861[D loss: 0.426723, acc: 60.94%, op_acc: 38.28%] [G loss: 1.174659]\n",
      "epoch:44 step:34862[D loss: 0.412129, acc: 64.06%, op_acc: 44.53%] [G loss: 1.221429]\n",
      "epoch:44 step:34863[D loss: 0.379027, acc: 70.31%, op_acc: 41.41%] [G loss: 1.160606]\n",
      "epoch:44 step:34864[D loss: 0.416143, acc: 64.06%, op_acc: 42.97%] [G loss: 1.171105]\n",
      "epoch:44 step:34865[D loss: 0.458074, acc: 53.91%, op_acc: 36.72%] [G loss: 1.017047]\n",
      "epoch:44 step:34866[D loss: 0.337438, acc: 76.56%, op_acc: 47.66%] [G loss: 1.167820]\n",
      "epoch:44 step:34867[D loss: 0.368046, acc: 67.19%, op_acc: 41.41%] [G loss: 1.218267]\n",
      "epoch:44 step:34868[D loss: 0.441571, acc: 59.38%, op_acc: 38.28%] [G loss: 0.945341]\n",
      "epoch:44 step:34869[D loss: 0.415799, acc: 70.31%, op_acc: 35.94%] [G loss: 1.122361]\n",
      "epoch:44 step:34870[D loss: 0.397357, acc: 63.28%, op_acc: 39.84%] [G loss: 1.231405]\n",
      "epoch:44 step:34871[D loss: 0.361453, acc: 71.88%, op_acc: 46.88%] [G loss: 1.241111]\n",
      "epoch:44 step:34872[D loss: 0.462534, acc: 54.69%, op_acc: 39.06%] [G loss: 1.084460]\n",
      "epoch:44 step:34873[D loss: 0.375976, acc: 72.66%, op_acc: 46.09%] [G loss: 0.914190]\n",
      "epoch:44 step:34874[D loss: 0.440206, acc: 59.38%, op_acc: 32.81%] [G loss: 1.147996]\n",
      "epoch:44 step:34875[D loss: 0.419392, acc: 58.59%, op_acc: 46.09%] [G loss: 1.026110]\n",
      "epoch:44 step:34876[D loss: 0.428425, acc: 64.06%, op_acc: 42.19%] [G loss: 0.867579]\n",
      "epoch:44 step:34877[D loss: 0.457106, acc: 56.25%, op_acc: 40.62%] [G loss: 0.996203]\n",
      "epoch:44 step:34878[D loss: 0.441314, acc: 58.59%, op_acc: 42.97%] [G loss: 1.065288]\n",
      "epoch:44 step:34879[D loss: 0.364616, acc: 70.31%, op_acc: 46.09%] [G loss: 1.070169]\n",
      "epoch:44 step:34880[D loss: 0.392336, acc: 75.78%, op_acc: 39.06%] [G loss: 1.004161]\n",
      "epoch:44 step:34881[D loss: 0.463337, acc: 53.91%, op_acc: 40.62%] [G loss: 0.991082]\n",
      "epoch:44 step:34882[D loss: 0.393910, acc: 63.28%, op_acc: 41.41%] [G loss: 0.934101]\n",
      "epoch:44 step:34883[D loss: 0.340152, acc: 75.00%, op_acc: 45.31%] [G loss: 1.146972]\n",
      "epoch:44 step:34884[D loss: 0.398234, acc: 66.41%, op_acc: 44.53%] [G loss: 1.054507]\n",
      "epoch:44 step:34885[D loss: 0.343148, acc: 75.00%, op_acc: 42.97%] [G loss: 1.181690]\n",
      "epoch:44 step:34886[D loss: 0.364136, acc: 75.78%, op_acc: 46.09%] [G loss: 1.157195]\n",
      "epoch:44 step:34887[D loss: 0.346433, acc: 69.53%, op_acc: 46.09%] [G loss: 0.989752]\n",
      "epoch:44 step:34888[D loss: 0.433572, acc: 55.47%, op_acc: 42.97%] [G loss: 1.046431]\n",
      "epoch:44 step:34889[D loss: 0.363160, acc: 72.66%, op_acc: 45.31%] [G loss: 1.273765]\n",
      "epoch:44 step:34890[D loss: 0.438123, acc: 61.72%, op_acc: 42.19%] [G loss: 0.931349]\n",
      "epoch:44 step:34891[D loss: 0.462565, acc: 56.25%, op_acc: 39.06%] [G loss: 0.961036]\n",
      "epoch:44 step:34892[D loss: 0.393391, acc: 60.94%, op_acc: 43.75%] [G loss: 0.993998]\n",
      "epoch:44 step:34893[D loss: 0.369845, acc: 72.66%, op_acc: 50.00%] [G loss: 1.198927]\n",
      "epoch:44 step:34894[D loss: 0.359989, acc: 72.66%, op_acc: 44.53%] [G loss: 0.985514]\n",
      "epoch:44 step:34895[D loss: 0.440641, acc: 57.81%, op_acc: 35.94%] [G loss: 1.236547]\n",
      "epoch:44 step:34896[D loss: 0.381604, acc: 64.06%, op_acc: 50.78%] [G loss: 1.249067]\n",
      "epoch:44 step:34897[D loss: 0.421298, acc: 62.50%, op_acc: 50.00%] [G loss: 1.050160]\n",
      "epoch:44 step:34898[D loss: 0.353320, acc: 73.44%, op_acc: 48.44%] [G loss: 1.266731]\n",
      "epoch:44 step:34899[D loss: 0.382215, acc: 71.09%, op_acc: 47.66%] [G loss: 1.211983]\n",
      "epoch:44 step:34900[D loss: 0.376348, acc: 64.06%, op_acc: 46.88%] [G loss: 1.332930]\n",
      "epoch:44 step:34901[D loss: 0.434355, acc: 53.91%, op_acc: 42.19%] [G loss: 1.035140]\n",
      "epoch:44 step:34902[D loss: 0.399254, acc: 67.19%, op_acc: 33.59%] [G loss: 1.219022]\n",
      "epoch:44 step:34903[D loss: 0.448583, acc: 57.03%, op_acc: 40.62%] [G loss: 1.006630]\n",
      "epoch:44 step:34904[D loss: 0.399786, acc: 67.97%, op_acc: 41.41%] [G loss: 1.147032]\n",
      "epoch:44 step:34905[D loss: 0.385453, acc: 66.41%, op_acc: 44.53%] [G loss: 1.168687]\n",
      "epoch:44 step:34906[D loss: 0.358681, acc: 72.66%, op_acc: 42.19%] [G loss: 1.167122]\n",
      "epoch:44 step:34907[D loss: 0.408251, acc: 64.06%, op_acc: 45.31%] [G loss: 1.070369]\n",
      "epoch:44 step:34908[D loss: 0.407414, acc: 61.72%, op_acc: 45.31%] [G loss: 1.062486]\n",
      "epoch:44 step:34909[D loss: 0.378632, acc: 71.88%, op_acc: 42.97%] [G loss: 1.275113]\n",
      "epoch:44 step:34910[D loss: 0.390570, acc: 64.06%, op_acc: 45.31%] [G loss: 1.284161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:34911[D loss: 0.341214, acc: 80.47%, op_acc: 39.84%] [G loss: 1.303377]\n",
      "epoch:44 step:34912[D loss: 0.449162, acc: 64.06%, op_acc: 45.31%] [G loss: 1.137293]\n",
      "epoch:44 step:34913[D loss: 0.403540, acc: 64.84%, op_acc: 48.44%] [G loss: 0.955278]\n",
      "epoch:44 step:34914[D loss: 0.450878, acc: 63.28%, op_acc: 40.62%] [G loss: 1.189074]\n",
      "epoch:44 step:34915[D loss: 0.398884, acc: 62.50%, op_acc: 43.75%] [G loss: 1.199738]\n",
      "epoch:44 step:34916[D loss: 0.509811, acc: 46.88%, op_acc: 37.50%] [G loss: 0.861226]\n",
      "epoch:44 step:34917[D loss: 0.425611, acc: 65.62%, op_acc: 43.75%] [G loss: 1.018358]\n",
      "epoch:44 step:34918[D loss: 0.403006, acc: 68.75%, op_acc: 43.75%] [G loss: 1.105860]\n",
      "epoch:44 step:34919[D loss: 0.397364, acc: 66.41%, op_acc: 43.75%] [G loss: 1.085494]\n",
      "epoch:44 step:34920[D loss: 0.408650, acc: 61.72%, op_acc: 42.97%] [G loss: 1.145086]\n",
      "epoch:44 step:34921[D loss: 0.375696, acc: 69.53%, op_acc: 42.19%] [G loss: 1.016310]\n",
      "epoch:44 step:34922[D loss: 0.352949, acc: 71.09%, op_acc: 42.19%] [G loss: 1.134419]\n",
      "epoch:44 step:34923[D loss: 0.347264, acc: 73.44%, op_acc: 46.09%] [G loss: 1.171729]\n",
      "epoch:44 step:34924[D loss: 0.403368, acc: 66.41%, op_acc: 41.41%] [G loss: 1.124349]\n",
      "epoch:44 step:34925[D loss: 0.371804, acc: 70.31%, op_acc: 44.53%] [G loss: 1.096597]\n",
      "epoch:44 step:34926[D loss: 0.385139, acc: 66.41%, op_acc: 49.22%] [G loss: 1.101755]\n",
      "epoch:44 step:34927[D loss: 0.424869, acc: 60.94%, op_acc: 41.41%] [G loss: 1.194639]\n",
      "epoch:44 step:34928[D loss: 0.412507, acc: 59.38%, op_acc: 46.88%] [G loss: 1.203963]\n",
      "epoch:44 step:34929[D loss: 0.372419, acc: 71.88%, op_acc: 49.22%] [G loss: 1.271746]\n",
      "epoch:44 step:34930[D loss: 0.393994, acc: 64.84%, op_acc: 48.44%] [G loss: 1.221983]\n",
      "epoch:44 step:34931[D loss: 0.366613, acc: 71.88%, op_acc: 55.47%] [G loss: 1.134300]\n",
      "epoch:44 step:34932[D loss: 0.357110, acc: 67.19%, op_acc: 45.31%] [G loss: 1.279426]\n",
      "epoch:44 step:34933[D loss: 0.339518, acc: 72.66%, op_acc: 53.12%] [G loss: 1.272793]\n",
      "epoch:44 step:34934[D loss: 0.359695, acc: 73.44%, op_acc: 51.56%] [G loss: 1.221864]\n",
      "epoch:44 step:34935[D loss: 0.422181, acc: 64.06%, op_acc: 45.31%] [G loss: 1.100651]\n",
      "epoch:44 step:34936[D loss: 0.414654, acc: 60.16%, op_acc: 38.28%] [G loss: 1.190749]\n",
      "epoch:44 step:34937[D loss: 0.413217, acc: 62.50%, op_acc: 40.62%] [G loss: 1.129377]\n",
      "epoch:44 step:34938[D loss: 0.397369, acc: 66.41%, op_acc: 46.88%] [G loss: 1.204924]\n",
      "epoch:44 step:34939[D loss: 0.392484, acc: 62.50%, op_acc: 42.19%] [G loss: 1.097153]\n",
      "epoch:44 step:34940[D loss: 0.400707, acc: 65.62%, op_acc: 44.53%] [G loss: 1.183944]\n",
      "epoch:44 step:34941[D loss: 0.449366, acc: 59.38%, op_acc: 42.97%] [G loss: 1.083731]\n",
      "epoch:44 step:34942[D loss: 0.436979, acc: 63.28%, op_acc: 44.53%] [G loss: 1.115046]\n",
      "epoch:44 step:34943[D loss: 0.368768, acc: 72.66%, op_acc: 45.31%] [G loss: 1.060725]\n",
      "epoch:44 step:34944[D loss: 0.392362, acc: 65.62%, op_acc: 48.44%] [G loss: 1.245257]\n",
      "epoch:44 step:34945[D loss: 0.418906, acc: 65.62%, op_acc: 40.62%] [G loss: 1.133851]\n",
      "epoch:44 step:34946[D loss: 0.395902, acc: 66.41%, op_acc: 43.75%] [G loss: 1.028680]\n",
      "epoch:44 step:34947[D loss: 0.357453, acc: 73.44%, op_acc: 45.31%] [G loss: 1.175163]\n",
      "epoch:44 step:34948[D loss: 0.409903, acc: 65.62%, op_acc: 43.75%] [G loss: 0.945354]\n",
      "epoch:44 step:34949[D loss: 0.356045, acc: 72.66%, op_acc: 42.97%] [G loss: 0.964197]\n",
      "epoch:44 step:34950[D loss: 0.391971, acc: 72.66%, op_acc: 42.19%] [G loss: 1.146004]\n",
      "epoch:44 step:34951[D loss: 0.391954, acc: 71.09%, op_acc: 43.75%] [G loss: 1.155403]\n",
      "epoch:44 step:34952[D loss: 0.425046, acc: 58.59%, op_acc: 46.88%] [G loss: 1.189602]\n",
      "epoch:44 step:34953[D loss: 0.441789, acc: 57.81%, op_acc: 38.28%] [G loss: 1.108120]\n",
      "epoch:44 step:34954[D loss: 0.367451, acc: 66.41%, op_acc: 41.41%] [G loss: 1.091016]\n",
      "epoch:44 step:34955[D loss: 0.389950, acc: 67.97%, op_acc: 42.19%] [G loss: 1.266986]\n",
      "epoch:44 step:34956[D loss: 0.423943, acc: 55.47%, op_acc: 42.19%] [G loss: 1.209460]\n",
      "epoch:44 step:34957[D loss: 0.388966, acc: 69.53%, op_acc: 39.06%] [G loss: 1.114794]\n",
      "epoch:44 step:34958[D loss: 0.435711, acc: 61.72%, op_acc: 36.72%] [G loss: 1.182389]\n",
      "epoch:44 step:34959[D loss: 0.370630, acc: 68.75%, op_acc: 42.97%] [G loss: 1.279640]\n",
      "epoch:44 step:34960[D loss: 0.458369, acc: 54.69%, op_acc: 39.84%] [G loss: 1.472049]\n",
      "epoch:44 step:34961[D loss: 0.352213, acc: 72.66%, op_acc: 49.22%] [G loss: 1.408418]\n",
      "epoch:44 step:34962[D loss: 0.428956, acc: 57.03%, op_acc: 39.84%] [G loss: 1.130594]\n",
      "epoch:44 step:34963[D loss: 0.390622, acc: 67.97%, op_acc: 49.22%] [G loss: 1.067700]\n",
      "epoch:44 step:34964[D loss: 0.371234, acc: 67.19%, op_acc: 44.53%] [G loss: 1.184727]\n",
      "epoch:44 step:34965[D loss: 0.419783, acc: 61.72%, op_acc: 42.19%] [G loss: 1.141343]\n",
      "epoch:44 step:34966[D loss: 0.390543, acc: 71.09%, op_acc: 46.88%] [G loss: 1.215267]\n",
      "epoch:44 step:34967[D loss: 0.386179, acc: 65.62%, op_acc: 50.78%] [G loss: 1.171697]\n",
      "epoch:44 step:34968[D loss: 0.475029, acc: 53.91%, op_acc: 35.16%] [G loss: 1.050918]\n",
      "epoch:44 step:34969[D loss: 0.363062, acc: 73.44%, op_acc: 46.09%] [G loss: 1.212516]\n",
      "epoch:44 step:34970[D loss: 0.375625, acc: 68.75%, op_acc: 38.28%] [G loss: 1.114596]\n",
      "epoch:44 step:34971[D loss: 0.404184, acc: 65.62%, op_acc: 47.66%] [G loss: 1.087198]\n",
      "epoch:44 step:34972[D loss: 0.387845, acc: 64.06%, op_acc: 46.09%] [G loss: 1.142051]\n",
      "epoch:44 step:34973[D loss: 0.462050, acc: 54.69%, op_acc: 42.19%] [G loss: 1.146863]\n",
      "epoch:44 step:34974[D loss: 0.374212, acc: 67.19%, op_acc: 40.62%] [G loss: 1.077152]\n",
      "epoch:44 step:34975[D loss: 0.357469, acc: 69.53%, op_acc: 46.09%] [G loss: 1.039559]\n",
      "epoch:44 step:34976[D loss: 0.364116, acc: 69.53%, op_acc: 42.97%] [G loss: 0.930490]\n",
      "epoch:44 step:34977[D loss: 0.398423, acc: 68.75%, op_acc: 41.41%] [G loss: 1.055766]\n",
      "epoch:44 step:34978[D loss: 0.358120, acc: 74.22%, op_acc: 41.41%] [G loss: 1.110098]\n",
      "epoch:44 step:34979[D loss: 0.394496, acc: 65.62%, op_acc: 39.84%] [G loss: 1.060581]\n",
      "epoch:44 step:34980[D loss: 0.443143, acc: 57.03%, op_acc: 35.16%] [G loss: 1.069672]\n",
      "epoch:44 step:34981[D loss: 0.437531, acc: 64.84%, op_acc: 42.97%] [G loss: 1.267152]\n",
      "epoch:44 step:34982[D loss: 0.434925, acc: 57.03%, op_acc: 51.56%] [G loss: 1.025452]\n",
      "epoch:44 step:34983[D loss: 0.447198, acc: 61.72%, op_acc: 34.38%] [G loss: 0.941865]\n",
      "epoch:44 step:34984[D loss: 0.380075, acc: 68.75%, op_acc: 39.06%] [G loss: 1.016359]\n",
      "epoch:44 step:34985[D loss: 0.389039, acc: 70.31%, op_acc: 46.88%] [G loss: 0.998735]\n",
      "epoch:44 step:34986[D loss: 0.372783, acc: 76.56%, op_acc: 39.06%] [G loss: 1.082339]\n",
      "epoch:44 step:34987[D loss: 0.408805, acc: 64.06%, op_acc: 45.31%] [G loss: 1.236892]\n",
      "epoch:44 step:34988[D loss: 0.393113, acc: 64.06%, op_acc: 39.06%] [G loss: 1.299816]\n",
      "epoch:44 step:34989[D loss: 0.412909, acc: 66.41%, op_acc: 46.09%] [G loss: 0.918759]\n",
      "epoch:44 step:34990[D loss: 0.372811, acc: 71.09%, op_acc: 42.97%] [G loss: 1.229761]\n",
      "epoch:44 step:34991[D loss: 0.379663, acc: 65.62%, op_acc: 53.91%] [G loss: 1.287163]\n",
      "epoch:44 step:34992[D loss: 0.421469, acc: 57.03%, op_acc: 42.19%] [G loss: 1.140059]\n",
      "epoch:44 step:34993[D loss: 0.419720, acc: 64.06%, op_acc: 42.19%] [G loss: 1.017709]\n",
      "epoch:44 step:34994[D loss: 0.426177, acc: 53.91%, op_acc: 39.84%] [G loss: 1.055567]\n",
      "epoch:44 step:34995[D loss: 0.457517, acc: 56.25%, op_acc: 37.50%] [G loss: 0.992119]\n",
      "epoch:44 step:34996[D loss: 0.355775, acc: 73.44%, op_acc: 49.22%] [G loss: 1.184302]\n",
      "epoch:44 step:34997[D loss: 0.392184, acc: 63.28%, op_acc: 43.75%] [G loss: 1.003602]\n",
      "epoch:44 step:34998[D loss: 0.424772, acc: 63.28%, op_acc: 42.19%] [G loss: 1.215499]\n",
      "epoch:44 step:34999[D loss: 0.384467, acc: 66.41%, op_acc: 46.09%] [G loss: 1.076618]\n",
      "epoch:44 step:35000[D loss: 0.369281, acc: 65.62%, op_acc: 43.75%] [G loss: 1.111457]\n",
      "epoch:44 step:35001[D loss: 0.358050, acc: 75.00%, op_acc: 44.53%] [G loss: 1.260296]\n",
      "epoch:44 step:35002[D loss: 0.396707, acc: 64.06%, op_acc: 44.53%] [G loss: 1.212322]\n",
      "epoch:44 step:35003[D loss: 0.364165, acc: 71.88%, op_acc: 46.88%] [G loss: 1.181662]\n",
      "epoch:44 step:35004[D loss: 0.421403, acc: 61.72%, op_acc: 44.53%] [G loss: 1.134051]\n",
      "epoch:44 step:35005[D loss: 0.387734, acc: 64.06%, op_acc: 44.53%] [G loss: 0.987499]\n",
      "epoch:44 step:35006[D loss: 0.449972, acc: 60.94%, op_acc: 39.84%] [G loss: 1.258212]\n",
      "epoch:44 step:35007[D loss: 0.429441, acc: 62.50%, op_acc: 42.97%] [G loss: 1.078873]\n",
      "epoch:44 step:35008[D loss: 0.353538, acc: 72.66%, op_acc: 46.09%] [G loss: 1.151081]\n",
      "epoch:44 step:35009[D loss: 0.410886, acc: 60.16%, op_acc: 44.53%] [G loss: 1.104024]\n",
      "epoch:44 step:35010[D loss: 0.380271, acc: 72.66%, op_acc: 38.28%] [G loss: 1.165893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35011[D loss: 0.406726, acc: 65.62%, op_acc: 41.41%] [G loss: 1.130882]\n",
      "epoch:44 step:35012[D loss: 0.368061, acc: 74.22%, op_acc: 45.31%] [G loss: 1.120676]\n",
      "epoch:44 step:35013[D loss: 0.387596, acc: 67.97%, op_acc: 47.66%] [G loss: 1.203415]\n",
      "epoch:44 step:35014[D loss: 0.396205, acc: 66.41%, op_acc: 46.09%] [G loss: 1.203091]\n",
      "epoch:44 step:35015[D loss: 0.359557, acc: 67.97%, op_acc: 46.09%] [G loss: 1.093377]\n",
      "epoch:44 step:35016[D loss: 0.370425, acc: 69.53%, op_acc: 53.91%] [G loss: 1.031380]\n",
      "epoch:44 step:35017[D loss: 0.423075, acc: 57.81%, op_acc: 42.97%] [G loss: 0.944447]\n",
      "epoch:44 step:35018[D loss: 0.411975, acc: 63.28%, op_acc: 45.31%] [G loss: 1.194924]\n",
      "epoch:44 step:35019[D loss: 0.401723, acc: 67.97%, op_acc: 45.31%] [G loss: 1.147339]\n",
      "epoch:44 step:35020[D loss: 0.376852, acc: 70.31%, op_acc: 42.97%] [G loss: 1.258376]\n",
      "epoch:44 step:35021[D loss: 0.389672, acc: 63.28%, op_acc: 50.00%] [G loss: 1.135361]\n",
      "epoch:44 step:35022[D loss: 0.360939, acc: 73.44%, op_acc: 46.88%] [G loss: 1.229030]\n",
      "epoch:44 step:35023[D loss: 0.339721, acc: 77.34%, op_acc: 48.44%] [G loss: 1.166129]\n",
      "epoch:44 step:35024[D loss: 0.407756, acc: 66.41%, op_acc: 50.00%] [G loss: 1.162668]\n",
      "epoch:44 step:35025[D loss: 0.395549, acc: 66.41%, op_acc: 50.78%] [G loss: 1.123847]\n",
      "epoch:44 step:35026[D loss: 0.383330, acc: 67.97%, op_acc: 41.41%] [G loss: 1.007229]\n",
      "epoch:44 step:35027[D loss: 0.341969, acc: 75.78%, op_acc: 46.88%] [G loss: 1.200183]\n",
      "epoch:44 step:35028[D loss: 0.390885, acc: 68.75%, op_acc: 42.97%] [G loss: 1.015727]\n",
      "epoch:44 step:35029[D loss: 0.406284, acc: 70.31%, op_acc: 35.94%] [G loss: 1.054191]\n",
      "epoch:44 step:35030[D loss: 0.350241, acc: 71.09%, op_acc: 41.41%] [G loss: 1.135838]\n",
      "epoch:44 step:35031[D loss: 0.397640, acc: 64.06%, op_acc: 46.09%] [G loss: 1.025629]\n",
      "epoch:44 step:35032[D loss: 0.405661, acc: 61.72%, op_acc: 40.62%] [G loss: 1.120610]\n",
      "epoch:44 step:35033[D loss: 0.459304, acc: 60.16%, op_acc: 39.06%] [G loss: 1.022236]\n",
      "epoch:44 step:35034[D loss: 0.371946, acc: 65.62%, op_acc: 42.97%] [G loss: 1.027161]\n",
      "epoch:44 step:35035[D loss: 0.379438, acc: 68.75%, op_acc: 42.19%] [G loss: 1.177136]\n",
      "epoch:44 step:35036[D loss: 0.434757, acc: 58.59%, op_acc: 39.84%] [G loss: 1.096245]\n",
      "epoch:44 step:35037[D loss: 0.434211, acc: 56.25%, op_acc: 40.62%] [G loss: 1.141154]\n",
      "epoch:44 step:35038[D loss: 0.361384, acc: 67.97%, op_acc: 47.66%] [G loss: 1.110783]\n",
      "epoch:44 step:35039[D loss: 0.362480, acc: 69.53%, op_acc: 45.31%] [G loss: 0.920641]\n",
      "epoch:44 step:35040[D loss: 0.442839, acc: 64.06%, op_acc: 37.50%] [G loss: 1.047546]\n",
      "epoch:44 step:35041[D loss: 0.446484, acc: 56.25%, op_acc: 29.69%] [G loss: 1.093666]\n",
      "epoch:44 step:35042[D loss: 0.401931, acc: 65.62%, op_acc: 43.75%] [G loss: 1.072926]\n",
      "epoch:44 step:35043[D loss: 0.326190, acc: 75.78%, op_acc: 43.75%] [G loss: 1.222434]\n",
      "epoch:44 step:35044[D loss: 0.408987, acc: 64.06%, op_acc: 39.84%] [G loss: 1.160204]\n",
      "epoch:44 step:35045[D loss: 0.479033, acc: 56.25%, op_acc: 36.72%] [G loss: 1.180398]\n",
      "epoch:44 step:35046[D loss: 0.377637, acc: 66.41%, op_acc: 45.31%] [G loss: 1.066766]\n",
      "epoch:44 step:35047[D loss: 0.402451, acc: 64.84%, op_acc: 43.75%] [G loss: 1.109251]\n",
      "epoch:44 step:35048[D loss: 0.448283, acc: 61.72%, op_acc: 44.53%] [G loss: 1.015753]\n",
      "epoch:44 step:35049[D loss: 0.385463, acc: 67.97%, op_acc: 39.84%] [G loss: 1.100156]\n",
      "epoch:44 step:35050[D loss: 0.466900, acc: 54.69%, op_acc: 39.06%] [G loss: 0.982655]\n",
      "epoch:44 step:35051[D loss: 0.347622, acc: 67.19%, op_acc: 46.09%] [G loss: 1.134990]\n",
      "epoch:44 step:35052[D loss: 0.396148, acc: 68.75%, op_acc: 44.53%] [G loss: 1.297016]\n",
      "epoch:44 step:35053[D loss: 0.405187, acc: 64.06%, op_acc: 44.53%] [G loss: 1.185989]\n",
      "epoch:44 step:35054[D loss: 0.335486, acc: 78.12%, op_acc: 40.62%] [G loss: 1.093479]\n",
      "epoch:44 step:35055[D loss: 0.398863, acc: 64.84%, op_acc: 39.06%] [G loss: 1.183494]\n",
      "epoch:44 step:35056[D loss: 0.408729, acc: 67.19%, op_acc: 46.88%] [G loss: 1.185998]\n",
      "epoch:44 step:35057[D loss: 0.456647, acc: 56.25%, op_acc: 39.84%] [G loss: 1.073145]\n",
      "epoch:44 step:35058[D loss: 0.363034, acc: 74.22%, op_acc: 50.00%] [G loss: 1.222901]\n",
      "epoch:44 step:35059[D loss: 0.347174, acc: 70.31%, op_acc: 43.75%] [G loss: 1.239849]\n",
      "epoch:44 step:35060[D loss: 0.433924, acc: 58.59%, op_acc: 39.84%] [G loss: 1.174396]\n",
      "epoch:44 step:35061[D loss: 0.375335, acc: 69.53%, op_acc: 46.09%] [G loss: 1.241817]\n",
      "epoch:44 step:35062[D loss: 0.382933, acc: 67.97%, op_acc: 45.31%] [G loss: 1.208837]\n",
      "epoch:44 step:35063[D loss: 0.379457, acc: 65.62%, op_acc: 50.00%] [G loss: 1.164249]\n",
      "epoch:44 step:35064[D loss: 0.430715, acc: 60.94%, op_acc: 39.06%] [G loss: 1.026522]\n",
      "epoch:44 step:35065[D loss: 0.384156, acc: 68.75%, op_acc: 43.75%] [G loss: 1.015678]\n",
      "epoch:44 step:35066[D loss: 0.454299, acc: 57.81%, op_acc: 39.84%] [G loss: 0.914983]\n",
      "epoch:44 step:35067[D loss: 0.452829, acc: 53.91%, op_acc: 40.62%] [G loss: 0.958205]\n",
      "epoch:44 step:35068[D loss: 0.384449, acc: 60.94%, op_acc: 51.56%] [G loss: 1.217422]\n",
      "epoch:44 step:35069[D loss: 0.471163, acc: 57.81%, op_acc: 37.50%] [G loss: 0.987975]\n",
      "epoch:44 step:35070[D loss: 0.425215, acc: 62.50%, op_acc: 40.62%] [G loss: 1.067115]\n",
      "epoch:44 step:35071[D loss: 0.398859, acc: 62.50%, op_acc: 46.09%] [G loss: 1.113202]\n",
      "epoch:44 step:35072[D loss: 0.418868, acc: 61.72%, op_acc: 42.97%] [G loss: 1.166954]\n",
      "epoch:44 step:35073[D loss: 0.458079, acc: 52.34%, op_acc: 42.97%] [G loss: 1.075842]\n",
      "epoch:44 step:35074[D loss: 0.286570, acc: 84.38%, op_acc: 49.22%] [G loss: 1.058863]\n",
      "epoch:44 step:35075[D loss: 0.408093, acc: 68.75%, op_acc: 37.50%] [G loss: 0.926210]\n",
      "epoch:44 step:35076[D loss: 0.387281, acc: 67.97%, op_acc: 46.09%] [G loss: 1.137512]\n",
      "epoch:44 step:35077[D loss: 0.397927, acc: 62.50%, op_acc: 49.22%] [G loss: 0.999449]\n",
      "epoch:44 step:35078[D loss: 0.401714, acc: 62.50%, op_acc: 41.41%] [G loss: 1.022057]\n",
      "epoch:44 step:35079[D loss: 0.393291, acc: 63.28%, op_acc: 45.31%] [G loss: 1.173887]\n",
      "epoch:44 step:35080[D loss: 0.444946, acc: 58.59%, op_acc: 38.28%] [G loss: 1.075425]\n",
      "epoch:44 step:35081[D loss: 0.408553, acc: 60.16%, op_acc: 49.22%] [G loss: 1.191072]\n",
      "epoch:44 step:35082[D loss: 0.389805, acc: 67.19%, op_acc: 42.19%] [G loss: 1.277225]\n",
      "epoch:44 step:35083[D loss: 0.402128, acc: 63.28%, op_acc: 48.44%] [G loss: 1.225460]\n",
      "epoch:44 step:35084[D loss: 0.380143, acc: 67.19%, op_acc: 39.84%] [G loss: 1.134495]\n",
      "epoch:44 step:35085[D loss: 0.414120, acc: 60.94%, op_acc: 45.31%] [G loss: 1.259143]\n",
      "epoch:44 step:35086[D loss: 0.393292, acc: 67.19%, op_acc: 49.22%] [G loss: 0.977068]\n",
      "epoch:44 step:35087[D loss: 0.418257, acc: 53.91%, op_acc: 48.44%] [G loss: 0.990632]\n",
      "epoch:44 step:35088[D loss: 0.456111, acc: 64.06%, op_acc: 35.16%] [G loss: 1.207376]\n",
      "epoch:44 step:35089[D loss: 0.389593, acc: 61.72%, op_acc: 37.50%] [G loss: 1.015723]\n",
      "epoch:44 step:35090[D loss: 0.369756, acc: 66.41%, op_acc: 46.09%] [G loss: 1.005586]\n",
      "epoch:44 step:35091[D loss: 0.488413, acc: 58.59%, op_acc: 34.38%] [G loss: 1.061689]\n",
      "epoch:44 step:35092[D loss: 0.360490, acc: 68.75%, op_acc: 51.56%] [G loss: 1.225278]\n",
      "epoch:44 step:35093[D loss: 0.334498, acc: 74.22%, op_acc: 47.66%] [G loss: 1.027042]\n",
      "epoch:44 step:35094[D loss: 0.403988, acc: 65.62%, op_acc: 38.28%] [G loss: 1.039989]\n",
      "epoch:44 step:35095[D loss: 0.385928, acc: 63.28%, op_acc: 41.41%] [G loss: 1.196334]\n",
      "epoch:44 step:35096[D loss: 0.441271, acc: 63.28%, op_acc: 37.50%] [G loss: 1.042961]\n",
      "epoch:44 step:35097[D loss: 0.436846, acc: 57.81%, op_acc: 42.97%] [G loss: 1.101289]\n",
      "epoch:44 step:35098[D loss: 0.395896, acc: 66.41%, op_acc: 39.84%] [G loss: 1.030448]\n",
      "epoch:44 step:35099[D loss: 0.414725, acc: 64.06%, op_acc: 43.75%] [G loss: 1.107261]\n",
      "epoch:44 step:35100[D loss: 0.403914, acc: 59.38%, op_acc: 43.75%] [G loss: 1.317324]\n",
      "epoch:44 step:35101[D loss: 0.355011, acc: 74.22%, op_acc: 54.69%] [G loss: 1.142227]\n",
      "epoch:44 step:35102[D loss: 0.415864, acc: 59.38%, op_acc: 46.09%] [G loss: 1.111865]\n",
      "epoch:44 step:35103[D loss: 0.375899, acc: 62.50%, op_acc: 50.00%] [G loss: 0.922179]\n",
      "epoch:44 step:35104[D loss: 0.410455, acc: 62.50%, op_acc: 46.88%] [G loss: 0.986279]\n",
      "epoch:44 step:35105[D loss: 0.341964, acc: 82.03%, op_acc: 44.53%] [G loss: 0.940696]\n",
      "epoch:44 step:35106[D loss: 0.404842, acc: 67.19%, op_acc: 42.97%] [G loss: 1.064112]\n",
      "epoch:44 step:35107[D loss: 0.394142, acc: 64.06%, op_acc: 39.84%] [G loss: 1.155472]\n",
      "epoch:44 step:35108[D loss: 0.381537, acc: 64.06%, op_acc: 52.34%] [G loss: 0.994760]\n",
      "epoch:44 step:35109[D loss: 0.389384, acc: 64.06%, op_acc: 43.75%] [G loss: 1.160793]\n",
      "epoch:44 step:35110[D loss: 0.429705, acc: 61.72%, op_acc: 44.53%] [G loss: 1.114035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44 step:35111[D loss: 0.444312, acc: 60.94%, op_acc: 42.97%] [G loss: 1.015085]\n",
      "epoch:44 step:35112[D loss: 0.393417, acc: 71.88%, op_acc: 39.84%] [G loss: 0.878096]\n",
      "epoch:44 step:35113[D loss: 0.418860, acc: 62.50%, op_acc: 36.72%] [G loss: 1.000720]\n",
      "epoch:44 step:35114[D loss: 0.425306, acc: 63.28%, op_acc: 42.97%] [G loss: 1.018828]\n",
      "epoch:44 step:35115[D loss: 0.414793, acc: 67.19%, op_acc: 32.03%] [G loss: 0.922798]\n",
      "epoch:44 step:35116[D loss: 0.376897, acc: 75.00%, op_acc: 36.72%] [G loss: 1.115961]\n",
      "epoch:44 step:35117[D loss: 0.369478, acc: 68.75%, op_acc: 49.22%] [G loss: 1.029951]\n",
      "epoch:44 step:35118[D loss: 0.401032, acc: 67.19%, op_acc: 48.44%] [G loss: 1.230959]\n",
      "epoch:44 step:35119[D loss: 0.386013, acc: 66.41%, op_acc: 48.44%] [G loss: 1.056373]\n",
      "epoch:44 step:35120[D loss: 0.405017, acc: 58.59%, op_acc: 46.88%] [G loss: 1.046763]\n",
      "epoch:44 step:35121[D loss: 0.394770, acc: 60.94%, op_acc: 46.88%] [G loss: 0.997459]\n",
      "epoch:44 step:35122[D loss: 0.408633, acc: 56.25%, op_acc: 43.75%] [G loss: 1.108727]\n",
      "epoch:44 step:35123[D loss: 0.388894, acc: 66.41%, op_acc: 42.97%] [G loss: 1.070324]\n",
      "epoch:44 step:35124[D loss: 0.402342, acc: 60.16%, op_acc: 44.53%] [G loss: 1.027119]\n",
      "epoch:44 step:35125[D loss: 0.367398, acc: 64.06%, op_acc: 50.00%] [G loss: 1.292838]\n",
      "epoch:44 step:35126[D loss: 0.433154, acc: 60.94%, op_acc: 37.50%] [G loss: 1.093886]\n",
      "epoch:44 step:35127[D loss: 0.462975, acc: 51.56%, op_acc: 43.75%] [G loss: 1.010829]\n",
      "epoch:44 step:35128[D loss: 0.440923, acc: 59.38%, op_acc: 40.62%] [G loss: 0.993912]\n",
      "epoch:44 step:35129[D loss: 0.415364, acc: 57.81%, op_acc: 50.78%] [G loss: 0.990399]\n",
      "epoch:44 step:35130[D loss: 0.410951, acc: 70.31%, op_acc: 42.97%] [G loss: 1.088905]\n",
      "epoch:44 step:35131[D loss: 0.347281, acc: 71.88%, op_acc: 40.62%] [G loss: 1.034424]\n",
      "epoch:44 step:35132[D loss: 0.386720, acc: 64.84%, op_acc: 42.97%] [G loss: 0.954820]\n",
      "epoch:44 step:35133[D loss: 0.361662, acc: 67.97%, op_acc: 49.22%] [G loss: 0.971587]\n",
      "epoch:44 step:35134[D loss: 0.412275, acc: 61.72%, op_acc: 43.75%] [G loss: 1.051582]\n",
      "epoch:44 step:35135[D loss: 0.441292, acc: 54.69%, op_acc: 39.84%] [G loss: 0.867584]\n",
      "epoch:44 step:35136[D loss: 0.443505, acc: 57.81%, op_acc: 36.72%] [G loss: 0.878702]\n",
      "epoch:44 step:35137[D loss: 0.405598, acc: 63.28%, op_acc: 37.50%] [G loss: 0.948500]\n",
      "epoch:44 step:35138[D loss: 0.365968, acc: 66.41%, op_acc: 53.12%] [G loss: 0.972163]\n",
      "epoch:44 step:35139[D loss: 0.411813, acc: 67.19%, op_acc: 42.19%] [G loss: 1.005904]\n",
      "epoch:44 step:35140[D loss: 0.409728, acc: 60.94%, op_acc: 44.53%] [G loss: 1.045615]\n",
      "epoch:44 step:35141[D loss: 0.408830, acc: 62.50%, op_acc: 42.19%] [G loss: 0.983036]\n",
      "epoch:44 step:35142[D loss: 0.361749, acc: 71.88%, op_acc: 46.88%] [G loss: 1.058840]\n",
      "epoch:44 step:35143[D loss: 0.458379, acc: 57.03%, op_acc: 38.28%] [G loss: 1.023918]\n",
      "epoch:44 step:35144[D loss: 0.363396, acc: 68.75%, op_acc: 42.97%] [G loss: 1.091464]\n",
      "epoch:44 step:35145[D loss: 0.423405, acc: 58.59%, op_acc: 38.28%] [G loss: 1.092752]\n",
      "epoch:45 step:35146[D loss: 0.320846, acc: 75.78%, op_acc: 56.25%] [G loss: 1.022123]\n",
      "epoch:45 step:35147[D loss: 0.397457, acc: 64.06%, op_acc: 50.00%] [G loss: 1.083194]\n",
      "epoch:45 step:35148[D loss: 0.377096, acc: 67.19%, op_acc: 46.88%] [G loss: 1.091606]\n",
      "epoch:45 step:35149[D loss: 0.404225, acc: 64.84%, op_acc: 47.66%] [G loss: 1.159430]\n",
      "epoch:45 step:35150[D loss: 0.379453, acc: 65.62%, op_acc: 41.41%] [G loss: 1.133229]\n",
      "epoch:45 step:35151[D loss: 0.396977, acc: 68.75%, op_acc: 40.62%] [G loss: 0.982039]\n",
      "epoch:45 step:35152[D loss: 0.386490, acc: 69.53%, op_acc: 44.53%] [G loss: 1.099251]\n",
      "epoch:45 step:35153[D loss: 0.399178, acc: 65.62%, op_acc: 49.22%] [G loss: 1.166760]\n",
      "epoch:45 step:35154[D loss: 0.377988, acc: 67.19%, op_acc: 44.53%] [G loss: 0.942130]\n",
      "epoch:45 step:35155[D loss: 0.429703, acc: 59.38%, op_acc: 41.41%] [G loss: 0.915932]\n",
      "epoch:45 step:35156[D loss: 0.476717, acc: 53.12%, op_acc: 35.94%] [G loss: 0.955143]\n",
      "epoch:45 step:35157[D loss: 0.401414, acc: 60.94%, op_acc: 42.97%] [G loss: 1.008749]\n",
      "epoch:45 step:35158[D loss: 0.398720, acc: 64.84%, op_acc: 41.41%] [G loss: 0.946406]\n",
      "epoch:45 step:35159[D loss: 0.420128, acc: 66.41%, op_acc: 36.72%] [G loss: 0.995984]\n",
      "epoch:45 step:35160[D loss: 0.340761, acc: 71.09%, op_acc: 42.97%] [G loss: 1.157544]\n",
      "epoch:45 step:35161[D loss: 0.409955, acc: 60.94%, op_acc: 41.41%] [G loss: 1.096076]\n",
      "epoch:45 step:35162[D loss: 0.378716, acc: 67.97%, op_acc: 46.09%] [G loss: 0.913311]\n",
      "epoch:45 step:35163[D loss: 0.391018, acc: 66.41%, op_acc: 46.88%] [G loss: 1.053995]\n",
      "epoch:45 step:35164[D loss: 0.375847, acc: 71.09%, op_acc: 39.06%] [G loss: 1.083327]\n",
      "epoch:45 step:35165[D loss: 0.384419, acc: 62.50%, op_acc: 43.75%] [G loss: 0.850384]\n",
      "epoch:45 step:35166[D loss: 0.436959, acc: 53.91%, op_acc: 45.31%] [G loss: 0.993080]\n",
      "epoch:45 step:35167[D loss: 0.377047, acc: 67.19%, op_acc: 42.19%] [G loss: 0.915996]\n",
      "epoch:45 step:35168[D loss: 0.361943, acc: 71.88%, op_acc: 46.88%] [G loss: 0.939741]\n",
      "epoch:45 step:35169[D loss: 0.387306, acc: 71.09%, op_acc: 38.28%] [G loss: 1.116257]\n",
      "epoch:45 step:35170[D loss: 0.398022, acc: 60.94%, op_acc: 46.88%] [G loss: 1.131849]\n",
      "epoch:45 step:35171[D loss: 0.364080, acc: 71.88%, op_acc: 46.09%] [G loss: 1.141125]\n",
      "epoch:45 step:35172[D loss: 0.395485, acc: 66.41%, op_acc: 43.75%] [G loss: 1.095215]\n",
      "epoch:45 step:35173[D loss: 0.374398, acc: 65.62%, op_acc: 53.12%] [G loss: 1.010442]\n",
      "epoch:45 step:35174[D loss: 0.324811, acc: 81.25%, op_acc: 46.09%] [G loss: 1.135122]\n",
      "epoch:45 step:35175[D loss: 0.376119, acc: 69.53%, op_acc: 48.44%] [G loss: 0.997927]\n",
      "epoch:45 step:35176[D loss: 0.360535, acc: 75.00%, op_acc: 43.75%] [G loss: 1.230491]\n",
      "epoch:45 step:35177[D loss: 0.384561, acc: 68.75%, op_acc: 40.62%] [G loss: 1.026294]\n",
      "epoch:45 step:35178[D loss: 0.449132, acc: 55.47%, op_acc: 41.41%] [G loss: 1.079265]\n",
      "epoch:45 step:35179[D loss: 0.344452, acc: 75.00%, op_acc: 42.97%] [G loss: 1.067548]\n",
      "epoch:45 step:35180[D loss: 0.401985, acc: 68.75%, op_acc: 46.09%] [G loss: 1.053853]\n",
      "epoch:45 step:35181[D loss: 0.342470, acc: 74.22%, op_acc: 50.00%] [G loss: 1.113767]\n",
      "epoch:45 step:35182[D loss: 0.353249, acc: 72.66%, op_acc: 48.44%] [G loss: 1.049234]\n",
      "epoch:45 step:35183[D loss: 0.414447, acc: 60.94%, op_acc: 43.75%] [G loss: 0.975484]\n",
      "epoch:45 step:35184[D loss: 0.392709, acc: 67.97%, op_acc: 46.88%] [G loss: 1.028551]\n",
      "epoch:45 step:35185[D loss: 0.390450, acc: 66.41%, op_acc: 45.31%] [G loss: 1.126482]\n",
      "epoch:45 step:35186[D loss: 0.308148, acc: 75.00%, op_acc: 52.34%] [G loss: 1.030272]\n",
      "epoch:45 step:35187[D loss: 0.348288, acc: 69.53%, op_acc: 50.78%] [G loss: 0.924719]\n",
      "epoch:45 step:35188[D loss: 0.410857, acc: 60.94%, op_acc: 42.19%] [G loss: 0.913218]\n",
      "epoch:45 step:35189[D loss: 0.401959, acc: 63.28%, op_acc: 43.75%] [G loss: 1.107395]\n",
      "epoch:45 step:35190[D loss: 0.407547, acc: 57.03%, op_acc: 40.62%] [G loss: 1.276974]\n",
      "epoch:45 step:35191[D loss: 0.360542, acc: 67.97%, op_acc: 46.88%] [G loss: 1.025930]\n",
      "epoch:45 step:35192[D loss: 0.419521, acc: 66.41%, op_acc: 46.09%] [G loss: 1.095129]\n",
      "epoch:45 step:35193[D loss: 0.404631, acc: 67.19%, op_acc: 44.53%] [G loss: 1.158582]\n",
      "epoch:45 step:35194[D loss: 0.345017, acc: 75.00%, op_acc: 50.00%] [G loss: 1.097371]\n",
      "epoch:45 step:35195[D loss: 0.444198, acc: 57.81%, op_acc: 42.19%] [G loss: 1.100530]\n",
      "epoch:45 step:35196[D loss: 0.333293, acc: 77.34%, op_acc: 45.31%] [G loss: 1.116867]\n",
      "epoch:45 step:35197[D loss: 0.371660, acc: 69.53%, op_acc: 48.44%] [G loss: 1.123843]\n",
      "epoch:45 step:35198[D loss: 0.446646, acc: 60.16%, op_acc: 35.16%] [G loss: 1.085965]\n",
      "epoch:45 step:35199[D loss: 0.417844, acc: 66.41%, op_acc: 46.88%] [G loss: 1.111999]\n",
      "epoch:45 step:35200[D loss: 0.350770, acc: 70.31%, op_acc: 49.22%] [G loss: 0.917227]\n",
      "epoch:45 step:35201[D loss: 0.371619, acc: 66.41%, op_acc: 44.53%] [G loss: 1.048601]\n",
      "epoch:45 step:35202[D loss: 0.422306, acc: 60.94%, op_acc: 46.09%] [G loss: 0.973012]\n",
      "epoch:45 step:35203[D loss: 0.400345, acc: 60.94%, op_acc: 44.53%] [G loss: 0.982103]\n",
      "epoch:45 step:35204[D loss: 0.365135, acc: 64.84%, op_acc: 49.22%] [G loss: 1.177458]\n",
      "epoch:45 step:35205[D loss: 0.386094, acc: 64.84%, op_acc: 39.84%] [G loss: 0.811911]\n",
      "epoch:45 step:35206[D loss: 0.363642, acc: 67.97%, op_acc: 46.88%] [G loss: 1.032484]\n",
      "epoch:45 step:35207[D loss: 0.402512, acc: 67.19%, op_acc: 46.88%] [G loss: 1.093093]\n",
      "epoch:45 step:35208[D loss: 0.407362, acc: 67.19%, op_acc: 39.84%] [G loss: 1.212085]\n",
      "epoch:45 step:35209[D loss: 0.398736, acc: 59.38%, op_acc: 51.56%] [G loss: 1.096641]\n",
      "epoch:45 step:35210[D loss: 0.421256, acc: 62.50%, op_acc: 46.09%] [G loss: 1.073955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35211[D loss: 0.423876, acc: 67.19%, op_acc: 42.19%] [G loss: 1.247264]\n",
      "epoch:45 step:35212[D loss: 0.351614, acc: 69.53%, op_acc: 46.88%] [G loss: 1.175464]\n",
      "epoch:45 step:35213[D loss: 0.400091, acc: 67.19%, op_acc: 40.62%] [G loss: 1.131321]\n",
      "epoch:45 step:35214[D loss: 0.391508, acc: 60.94%, op_acc: 49.22%] [G loss: 0.996684]\n",
      "epoch:45 step:35215[D loss: 0.444707, acc: 53.91%, op_acc: 43.75%] [G loss: 1.167428]\n",
      "epoch:45 step:35216[D loss: 0.435150, acc: 61.72%, op_acc: 39.84%] [G loss: 1.168811]\n",
      "epoch:45 step:35217[D loss: 0.425908, acc: 60.94%, op_acc: 46.09%] [G loss: 1.156455]\n",
      "epoch:45 step:35218[D loss: 0.407354, acc: 62.50%, op_acc: 42.97%] [G loss: 1.009971]\n",
      "epoch:45 step:35219[D loss: 0.371421, acc: 66.41%, op_acc: 41.41%] [G loss: 0.863298]\n",
      "epoch:45 step:35220[D loss: 0.419366, acc: 67.97%, op_acc: 39.06%] [G loss: 0.911014]\n",
      "epoch:45 step:35221[D loss: 0.371301, acc: 67.19%, op_acc: 48.44%] [G loss: 1.029818]\n",
      "epoch:45 step:35222[D loss: 0.404844, acc: 57.03%, op_acc: 41.41%] [G loss: 1.076885]\n",
      "epoch:45 step:35223[D loss: 0.423496, acc: 64.84%, op_acc: 39.06%] [G loss: 0.961489]\n",
      "epoch:45 step:35224[D loss: 0.400510, acc: 66.41%, op_acc: 43.75%] [G loss: 1.038953]\n",
      "epoch:45 step:35225[D loss: 0.392119, acc: 71.09%, op_acc: 42.97%] [G loss: 1.190211]\n",
      "epoch:45 step:35226[D loss: 0.399896, acc: 68.75%, op_acc: 40.62%] [G loss: 1.037125]\n",
      "epoch:45 step:35227[D loss: 0.364498, acc: 70.31%, op_acc: 47.66%] [G loss: 1.144928]\n",
      "epoch:45 step:35228[D loss: 0.392286, acc: 64.84%, op_acc: 44.53%] [G loss: 0.950218]\n",
      "epoch:45 step:35229[D loss: 0.382745, acc: 63.28%, op_acc: 48.44%] [G loss: 1.059707]\n",
      "epoch:45 step:35230[D loss: 0.385387, acc: 75.00%, op_acc: 37.50%] [G loss: 1.159769]\n",
      "epoch:45 step:35231[D loss: 0.352297, acc: 71.88%, op_acc: 40.62%] [G loss: 1.142912]\n",
      "epoch:45 step:35232[D loss: 0.360556, acc: 75.00%, op_acc: 42.19%] [G loss: 1.115594]\n",
      "epoch:45 step:35233[D loss: 0.386118, acc: 71.88%, op_acc: 38.28%] [G loss: 1.047135]\n",
      "epoch:45 step:35234[D loss: 0.381306, acc: 67.97%, op_acc: 45.31%] [G loss: 1.068884]\n",
      "epoch:45 step:35235[D loss: 0.444479, acc: 57.81%, op_acc: 44.53%] [G loss: 1.022974]\n",
      "epoch:45 step:35236[D loss: 0.351141, acc: 72.66%, op_acc: 47.66%] [G loss: 1.093418]\n",
      "epoch:45 step:35237[D loss: 0.423585, acc: 60.94%, op_acc: 43.75%] [G loss: 0.872506]\n",
      "epoch:45 step:35238[D loss: 0.338663, acc: 77.34%, op_acc: 47.66%] [G loss: 1.037602]\n",
      "epoch:45 step:35239[D loss: 0.376862, acc: 74.22%, op_acc: 45.31%] [G loss: 1.216143]\n",
      "epoch:45 step:35240[D loss: 0.405049, acc: 59.38%, op_acc: 42.97%] [G loss: 1.063145]\n",
      "epoch:45 step:35241[D loss: 0.357031, acc: 71.09%, op_acc: 49.22%] [G loss: 1.165990]\n",
      "epoch:45 step:35242[D loss: 0.404987, acc: 63.28%, op_acc: 46.88%] [G loss: 1.217147]\n",
      "epoch:45 step:35243[D loss: 0.330704, acc: 74.22%, op_acc: 45.31%] [G loss: 1.057419]\n",
      "epoch:45 step:35244[D loss: 0.377731, acc: 66.41%, op_acc: 46.88%] [G loss: 1.269276]\n",
      "epoch:45 step:35245[D loss: 0.356491, acc: 72.66%, op_acc: 48.44%] [G loss: 1.150855]\n",
      "epoch:45 step:35246[D loss: 0.364792, acc: 71.88%, op_acc: 41.41%] [G loss: 1.359957]\n",
      "epoch:45 step:35247[D loss: 0.358486, acc: 66.41%, op_acc: 50.78%] [G loss: 1.174360]\n",
      "epoch:45 step:35248[D loss: 0.402383, acc: 59.38%, op_acc: 45.31%] [G loss: 1.204290]\n",
      "epoch:45 step:35249[D loss: 0.355572, acc: 73.44%, op_acc: 53.12%] [G loss: 1.093254]\n",
      "epoch:45 step:35250[D loss: 0.342953, acc: 71.09%, op_acc: 50.00%] [G loss: 1.025250]\n",
      "epoch:45 step:35251[D loss: 0.337419, acc: 78.12%, op_acc: 39.84%] [G loss: 1.051523]\n",
      "epoch:45 step:35252[D loss: 0.330437, acc: 75.78%, op_acc: 47.66%] [G loss: 1.167332]\n",
      "epoch:45 step:35253[D loss: 0.434672, acc: 65.62%, op_acc: 38.28%] [G loss: 1.069512]\n",
      "epoch:45 step:35254[D loss: 0.395122, acc: 73.44%, op_acc: 44.53%] [G loss: 1.078441]\n",
      "epoch:45 step:35255[D loss: 0.387785, acc: 67.19%, op_acc: 52.34%] [G loss: 1.224841]\n",
      "epoch:45 step:35256[D loss: 0.406555, acc: 59.38%, op_acc: 37.50%] [G loss: 1.189926]\n",
      "epoch:45 step:35257[D loss: 0.407065, acc: 58.59%, op_acc: 42.97%] [G loss: 1.031452]\n",
      "epoch:45 step:35258[D loss: 0.372853, acc: 72.66%, op_acc: 46.09%] [G loss: 1.172459]\n",
      "epoch:45 step:35259[D loss: 0.373392, acc: 65.62%, op_acc: 48.44%] [G loss: 1.233649]\n",
      "epoch:45 step:35260[D loss: 0.418193, acc: 57.81%, op_acc: 41.41%] [G loss: 0.966439]\n",
      "epoch:45 step:35261[D loss: 0.467439, acc: 57.03%, op_acc: 43.75%] [G loss: 1.000294]\n",
      "epoch:45 step:35262[D loss: 0.415989, acc: 60.94%, op_acc: 40.62%] [G loss: 1.170995]\n",
      "epoch:45 step:35263[D loss: 0.397893, acc: 64.84%, op_acc: 42.19%] [G loss: 1.089752]\n",
      "epoch:45 step:35264[D loss: 0.375461, acc: 75.00%, op_acc: 40.62%] [G loss: 1.352064]\n",
      "epoch:45 step:35265[D loss: 0.348825, acc: 74.22%, op_acc: 40.62%] [G loss: 1.267700]\n",
      "epoch:45 step:35266[D loss: 0.405511, acc: 63.28%, op_acc: 43.75%] [G loss: 1.266585]\n",
      "epoch:45 step:35267[D loss: 0.449615, acc: 59.38%, op_acc: 38.28%] [G loss: 1.359735]\n",
      "epoch:45 step:35268[D loss: 0.377325, acc: 68.75%, op_acc: 46.09%] [G loss: 1.182312]\n",
      "epoch:45 step:35269[D loss: 0.395536, acc: 62.50%, op_acc: 44.53%] [G loss: 0.893655]\n",
      "epoch:45 step:35270[D loss: 0.403912, acc: 68.75%, op_acc: 39.84%] [G loss: 1.107006]\n",
      "epoch:45 step:35271[D loss: 0.396179, acc: 63.28%, op_acc: 39.84%] [G loss: 1.118494]\n",
      "epoch:45 step:35272[D loss: 0.364121, acc: 72.66%, op_acc: 39.06%] [G loss: 1.114631]\n",
      "epoch:45 step:35273[D loss: 0.342187, acc: 78.12%, op_acc: 46.09%] [G loss: 1.216513]\n",
      "epoch:45 step:35274[D loss: 0.390169, acc: 66.41%, op_acc: 42.19%] [G loss: 1.086605]\n",
      "epoch:45 step:35275[D loss: 0.367623, acc: 64.84%, op_acc: 50.78%] [G loss: 1.117361]\n",
      "epoch:45 step:35276[D loss: 0.364266, acc: 70.31%, op_acc: 46.09%] [G loss: 1.214535]\n",
      "epoch:45 step:35277[D loss: 0.325763, acc: 71.88%, op_acc: 47.66%] [G loss: 1.194145]\n",
      "epoch:45 step:35278[D loss: 0.452984, acc: 64.84%, op_acc: 39.84%] [G loss: 1.169535]\n",
      "epoch:45 step:35279[D loss: 0.422008, acc: 60.16%, op_acc: 42.19%] [G loss: 1.063580]\n",
      "epoch:45 step:35280[D loss: 0.384775, acc: 64.84%, op_acc: 47.66%] [G loss: 1.164120]\n",
      "epoch:45 step:35281[D loss: 0.377330, acc: 66.41%, op_acc: 44.53%] [G loss: 1.257874]\n",
      "epoch:45 step:35282[D loss: 0.437359, acc: 55.47%, op_acc: 42.19%] [G loss: 1.049898]\n",
      "epoch:45 step:35283[D loss: 0.441768, acc: 57.03%, op_acc: 44.53%] [G loss: 1.176342]\n",
      "epoch:45 step:35284[D loss: 0.414335, acc: 58.59%, op_acc: 42.19%] [G loss: 1.012323]\n",
      "epoch:45 step:35285[D loss: 0.481943, acc: 54.69%, op_acc: 42.97%] [G loss: 1.100421]\n",
      "epoch:45 step:35286[D loss: 0.468936, acc: 51.56%, op_acc: 36.72%] [G loss: 1.066149]\n",
      "epoch:45 step:35287[D loss: 0.364704, acc: 71.88%, op_acc: 50.78%] [G loss: 0.973848]\n",
      "epoch:45 step:35288[D loss: 0.412253, acc: 65.62%, op_acc: 49.22%] [G loss: 0.930035]\n",
      "epoch:45 step:35289[D loss: 0.436374, acc: 58.59%, op_acc: 36.72%] [G loss: 1.135599]\n",
      "epoch:45 step:35290[D loss: 0.407045, acc: 70.31%, op_acc: 46.09%] [G loss: 1.054948]\n",
      "epoch:45 step:35291[D loss: 0.368298, acc: 73.44%, op_acc: 46.09%] [G loss: 0.936992]\n",
      "epoch:45 step:35292[D loss: 0.366839, acc: 68.75%, op_acc: 52.34%] [G loss: 0.963185]\n",
      "epoch:45 step:35293[D loss: 0.401980, acc: 64.84%, op_acc: 48.44%] [G loss: 1.156389]\n",
      "epoch:45 step:35294[D loss: 0.370192, acc: 71.09%, op_acc: 43.75%] [G loss: 0.974771]\n",
      "epoch:45 step:35295[D loss: 0.391120, acc: 60.94%, op_acc: 40.62%] [G loss: 0.956286]\n",
      "epoch:45 step:35296[D loss: 0.387136, acc: 63.28%, op_acc: 46.88%] [G loss: 1.039104]\n",
      "epoch:45 step:35297[D loss: 0.345314, acc: 75.00%, op_acc: 48.44%] [G loss: 0.998604]\n",
      "epoch:45 step:35298[D loss: 0.410322, acc: 67.19%, op_acc: 39.06%] [G loss: 1.119488]\n",
      "epoch:45 step:35299[D loss: 0.358785, acc: 70.31%, op_acc: 50.00%] [G loss: 1.080486]\n",
      "epoch:45 step:35300[D loss: 0.370699, acc: 70.31%, op_acc: 49.22%] [G loss: 1.169344]\n",
      "epoch:45 step:35301[D loss: 0.488867, acc: 46.09%, op_acc: 35.16%] [G loss: 0.918256]\n",
      "epoch:45 step:35302[D loss: 0.387401, acc: 70.31%, op_acc: 39.84%] [G loss: 1.125148]\n",
      "epoch:45 step:35303[D loss: 0.397682, acc: 66.41%, op_acc: 44.53%] [G loss: 1.204625]\n",
      "epoch:45 step:35304[D loss: 0.384018, acc: 64.06%, op_acc: 48.44%] [G loss: 1.115442]\n",
      "epoch:45 step:35305[D loss: 0.439652, acc: 63.28%, op_acc: 36.72%] [G loss: 1.151610]\n",
      "epoch:45 step:35306[D loss: 0.394165, acc: 71.09%, op_acc: 46.09%] [G loss: 1.157951]\n",
      "epoch:45 step:35307[D loss: 0.379502, acc: 69.53%, op_acc: 49.22%] [G loss: 1.259875]\n",
      "epoch:45 step:35308[D loss: 0.356770, acc: 72.66%, op_acc: 46.88%] [G loss: 1.269568]\n",
      "epoch:45 step:35309[D loss: 0.393684, acc: 72.66%, op_acc: 42.97%] [G loss: 1.085559]\n",
      "epoch:45 step:35310[D loss: 0.340985, acc: 78.91%, op_acc: 46.09%] [G loss: 1.357336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35311[D loss: 0.413553, acc: 62.50%, op_acc: 48.44%] [G loss: 1.456733]\n",
      "epoch:45 step:35312[D loss: 0.380643, acc: 68.75%, op_acc: 46.09%] [G loss: 1.120600]\n",
      "epoch:45 step:35313[D loss: 0.333020, acc: 74.22%, op_acc: 47.66%] [G loss: 1.249771]\n",
      "epoch:45 step:35314[D loss: 0.414113, acc: 63.28%, op_acc: 42.97%] [G loss: 0.894836]\n",
      "epoch:45 step:35315[D loss: 0.407000, acc: 67.19%, op_acc: 43.75%] [G loss: 1.010955]\n",
      "epoch:45 step:35316[D loss: 0.419970, acc: 64.06%, op_acc: 39.84%] [G loss: 1.299944]\n",
      "epoch:45 step:35317[D loss: 0.384361, acc: 62.50%, op_acc: 46.09%] [G loss: 1.286017]\n",
      "epoch:45 step:35318[D loss: 0.406328, acc: 66.41%, op_acc: 41.41%] [G loss: 1.203684]\n",
      "epoch:45 step:35319[D loss: 0.453683, acc: 57.03%, op_acc: 39.06%] [G loss: 1.085046]\n",
      "epoch:45 step:35320[D loss: 0.442099, acc: 62.50%, op_acc: 42.19%] [G loss: 1.211273]\n",
      "epoch:45 step:35321[D loss: 0.372406, acc: 66.41%, op_acc: 45.31%] [G loss: 1.230966]\n",
      "epoch:45 step:35322[D loss: 0.404317, acc: 64.84%, op_acc: 42.97%] [G loss: 1.139399]\n",
      "epoch:45 step:35323[D loss: 0.440044, acc: 64.84%, op_acc: 41.41%] [G loss: 1.142204]\n",
      "epoch:45 step:35324[D loss: 0.384003, acc: 64.06%, op_acc: 41.41%] [G loss: 1.186678]\n",
      "epoch:45 step:35325[D loss: 0.361809, acc: 75.78%, op_acc: 47.66%] [G loss: 1.178795]\n",
      "epoch:45 step:35326[D loss: 0.400848, acc: 64.84%, op_acc: 42.97%] [G loss: 1.121929]\n",
      "epoch:45 step:35327[D loss: 0.456691, acc: 50.78%, op_acc: 37.50%] [G loss: 1.335640]\n",
      "epoch:45 step:35328[D loss: 0.398219, acc: 66.41%, op_acc: 50.00%] [G loss: 1.289847]\n",
      "epoch:45 step:35329[D loss: 0.443657, acc: 57.03%, op_acc: 36.72%] [G loss: 1.409165]\n",
      "epoch:45 step:35330[D loss: 0.380599, acc: 72.66%, op_acc: 37.50%] [G loss: 1.132004]\n",
      "epoch:45 step:35331[D loss: 0.379816, acc: 63.28%, op_acc: 42.19%] [G loss: 1.324051]\n",
      "epoch:45 step:35332[D loss: 0.366527, acc: 71.09%, op_acc: 46.09%] [G loss: 1.393368]\n",
      "epoch:45 step:35333[D loss: 0.446118, acc: 57.03%, op_acc: 46.09%] [G loss: 1.250441]\n",
      "epoch:45 step:35334[D loss: 0.354944, acc: 76.56%, op_acc: 46.88%] [G loss: 1.209918]\n",
      "epoch:45 step:35335[D loss: 0.441438, acc: 60.94%, op_acc: 42.19%] [G loss: 1.233498]\n",
      "epoch:45 step:35336[D loss: 0.359641, acc: 67.97%, op_acc: 42.97%] [G loss: 1.005987]\n",
      "epoch:45 step:35337[D loss: 0.403713, acc: 64.06%, op_acc: 42.97%] [G loss: 1.067784]\n",
      "epoch:45 step:35338[D loss: 0.414813, acc: 60.16%, op_acc: 39.84%] [G loss: 1.047052]\n",
      "epoch:45 step:35339[D loss: 0.372418, acc: 74.22%, op_acc: 45.31%] [G loss: 1.169119]\n",
      "epoch:45 step:35340[D loss: 0.387384, acc: 71.09%, op_acc: 45.31%] [G loss: 1.143029]\n",
      "epoch:45 step:35341[D loss: 0.366727, acc: 75.00%, op_acc: 41.41%] [G loss: 1.298232]\n",
      "epoch:45 step:35342[D loss: 0.465347, acc: 55.47%, op_acc: 44.53%] [G loss: 1.067258]\n",
      "epoch:45 step:35343[D loss: 0.428485, acc: 57.81%, op_acc: 39.06%] [G loss: 1.170071]\n",
      "epoch:45 step:35344[D loss: 0.391675, acc: 63.28%, op_acc: 45.31%] [G loss: 1.316937]\n",
      "epoch:45 step:35345[D loss: 0.364910, acc: 67.19%, op_acc: 49.22%] [G loss: 1.215091]\n",
      "epoch:45 step:35346[D loss: 0.330925, acc: 74.22%, op_acc: 47.66%] [G loss: 1.288162]\n",
      "epoch:45 step:35347[D loss: 0.379126, acc: 66.41%, op_acc: 46.88%] [G loss: 1.052912]\n",
      "epoch:45 step:35348[D loss: 0.421697, acc: 60.94%, op_acc: 45.31%] [G loss: 1.054757]\n",
      "epoch:45 step:35349[D loss: 0.395391, acc: 63.28%, op_acc: 39.84%] [G loss: 1.181647]\n",
      "epoch:45 step:35350[D loss: 0.410864, acc: 61.72%, op_acc: 40.62%] [G loss: 1.178192]\n",
      "epoch:45 step:35351[D loss: 0.326037, acc: 76.56%, op_acc: 48.44%] [G loss: 1.154216]\n",
      "epoch:45 step:35352[D loss: 0.369784, acc: 70.31%, op_acc: 51.56%] [G loss: 1.068665]\n",
      "epoch:45 step:35353[D loss: 0.402161, acc: 67.19%, op_acc: 36.72%] [G loss: 1.280701]\n",
      "epoch:45 step:35354[D loss: 0.387025, acc: 62.50%, op_acc: 45.31%] [G loss: 1.097102]\n",
      "epoch:45 step:35355[D loss: 0.333133, acc: 82.03%, op_acc: 45.31%] [G loss: 1.159478]\n",
      "epoch:45 step:35356[D loss: 0.366178, acc: 67.19%, op_acc: 54.69%] [G loss: 1.029290]\n",
      "epoch:45 step:35357[D loss: 0.444634, acc: 54.69%, op_acc: 42.19%] [G loss: 0.940056]\n",
      "epoch:45 step:35358[D loss: 0.453559, acc: 52.34%, op_acc: 41.41%] [G loss: 0.998592]\n",
      "epoch:45 step:35359[D loss: 0.380826, acc: 72.66%, op_acc: 40.62%] [G loss: 1.118512]\n",
      "epoch:45 step:35360[D loss: 0.392198, acc: 64.84%, op_acc: 48.44%] [G loss: 1.349183]\n",
      "epoch:45 step:35361[D loss: 0.401958, acc: 66.41%, op_acc: 42.19%] [G loss: 1.156612]\n",
      "epoch:45 step:35362[D loss: 0.367828, acc: 71.88%, op_acc: 53.12%] [G loss: 1.096393]\n",
      "epoch:45 step:35363[D loss: 0.399778, acc: 64.84%, op_acc: 46.09%] [G loss: 1.283083]\n",
      "epoch:45 step:35364[D loss: 0.364713, acc: 73.44%, op_acc: 46.88%] [G loss: 1.156889]\n",
      "epoch:45 step:35365[D loss: 0.437169, acc: 60.94%, op_acc: 47.66%] [G loss: 1.043472]\n",
      "epoch:45 step:35366[D loss: 0.349065, acc: 72.66%, op_acc: 44.53%] [G loss: 1.185046]\n",
      "epoch:45 step:35367[D loss: 0.410262, acc: 64.84%, op_acc: 38.28%] [G loss: 1.125107]\n",
      "epoch:45 step:35368[D loss: 0.455143, acc: 53.12%, op_acc: 43.75%] [G loss: 1.136731]\n",
      "epoch:45 step:35369[D loss: 0.384036, acc: 66.41%, op_acc: 43.75%] [G loss: 1.193997]\n",
      "epoch:45 step:35370[D loss: 0.398002, acc: 69.53%, op_acc: 40.62%] [G loss: 1.022089]\n",
      "epoch:45 step:35371[D loss: 0.403900, acc: 65.62%, op_acc: 41.41%] [G loss: 1.137492]\n",
      "epoch:45 step:35372[D loss: 0.424204, acc: 59.38%, op_acc: 40.62%] [G loss: 1.213776]\n",
      "epoch:45 step:35373[D loss: 0.364935, acc: 68.75%, op_acc: 47.66%] [G loss: 1.087138]\n",
      "epoch:45 step:35374[D loss: 0.411945, acc: 64.84%, op_acc: 40.62%] [G loss: 1.179287]\n",
      "epoch:45 step:35375[D loss: 0.451665, acc: 53.12%, op_acc: 42.19%] [G loss: 1.166674]\n",
      "epoch:45 step:35376[D loss: 0.358651, acc: 69.53%, op_acc: 46.88%] [G loss: 1.230426]\n",
      "epoch:45 step:35377[D loss: 0.330230, acc: 73.44%, op_acc: 48.44%] [G loss: 1.089528]\n",
      "epoch:45 step:35378[D loss: 0.366480, acc: 72.66%, op_acc: 39.84%] [G loss: 1.237315]\n",
      "epoch:45 step:35379[D loss: 0.360264, acc: 77.34%, op_acc: 45.31%] [G loss: 1.353937]\n",
      "epoch:45 step:35380[D loss: 0.393754, acc: 64.84%, op_acc: 44.53%] [G loss: 1.039765]\n",
      "epoch:45 step:35381[D loss: 0.354567, acc: 71.88%, op_acc: 46.09%] [G loss: 1.230489]\n",
      "epoch:45 step:35382[D loss: 0.375526, acc: 63.28%, op_acc: 47.66%] [G loss: 1.187763]\n",
      "epoch:45 step:35383[D loss: 0.422803, acc: 55.47%, op_acc: 40.62%] [G loss: 0.774342]\n",
      "epoch:45 step:35384[D loss: 0.376385, acc: 69.53%, op_acc: 48.44%] [G loss: 1.249393]\n",
      "epoch:45 step:35385[D loss: 0.395676, acc: 64.84%, op_acc: 44.53%] [G loss: 1.150933]\n",
      "epoch:45 step:35386[D loss: 0.376939, acc: 64.84%, op_acc: 50.78%] [G loss: 1.029385]\n",
      "epoch:45 step:35387[D loss: 0.399720, acc: 63.28%, op_acc: 48.44%] [G loss: 1.041747]\n",
      "epoch:45 step:35388[D loss: 0.418339, acc: 59.38%, op_acc: 44.53%] [G loss: 1.209373]\n",
      "epoch:45 step:35389[D loss: 0.391984, acc: 67.19%, op_acc: 45.31%] [G loss: 1.096307]\n",
      "epoch:45 step:35390[D loss: 0.417449, acc: 60.94%, op_acc: 40.62%] [G loss: 0.978979]\n",
      "epoch:45 step:35391[D loss: 0.395184, acc: 71.09%, op_acc: 40.62%] [G loss: 1.073711]\n",
      "epoch:45 step:35392[D loss: 0.392296, acc: 65.62%, op_acc: 35.94%] [G loss: 1.108270]\n",
      "epoch:45 step:35393[D loss: 0.416924, acc: 64.06%, op_acc: 39.84%] [G loss: 1.236094]\n",
      "epoch:45 step:35394[D loss: 0.402988, acc: 64.84%, op_acc: 42.19%] [G loss: 1.053866]\n",
      "epoch:45 step:35395[D loss: 0.405652, acc: 67.19%, op_acc: 38.28%] [G loss: 0.965400]\n",
      "epoch:45 step:35396[D loss: 0.387063, acc: 70.31%, op_acc: 42.97%] [G loss: 0.931625]\n",
      "epoch:45 step:35397[D loss: 0.399351, acc: 65.62%, op_acc: 50.00%] [G loss: 1.022006]\n",
      "epoch:45 step:35398[D loss: 0.413656, acc: 62.50%, op_acc: 42.19%] [G loss: 1.064120]\n",
      "epoch:45 step:35399[D loss: 0.384342, acc: 69.53%, op_acc: 50.00%] [G loss: 1.057139]\n",
      "epoch:45 step:35400[D loss: 0.386241, acc: 67.19%, op_acc: 44.53%] [G loss: 0.982022]\n",
      "epoch:45 step:35401[D loss: 0.384990, acc: 66.41%, op_acc: 46.88%] [G loss: 1.266466]\n",
      "epoch:45 step:35402[D loss: 0.429454, acc: 60.94%, op_acc: 46.88%] [G loss: 1.069966]\n",
      "epoch:45 step:35403[D loss: 0.388386, acc: 66.41%, op_acc: 46.88%] [G loss: 0.997545]\n",
      "epoch:45 step:35404[D loss: 0.375351, acc: 71.09%, op_acc: 49.22%] [G loss: 1.151051]\n",
      "epoch:45 step:35405[D loss: 0.421592, acc: 60.16%, op_acc: 38.28%] [G loss: 0.917450]\n",
      "epoch:45 step:35406[D loss: 0.425968, acc: 60.16%, op_acc: 37.50%] [G loss: 1.132638]\n",
      "epoch:45 step:35407[D loss: 0.395331, acc: 66.41%, op_acc: 42.19%] [G loss: 0.964541]\n",
      "epoch:45 step:35408[D loss: 0.380108, acc: 67.19%, op_acc: 41.41%] [G loss: 1.026856]\n",
      "epoch:45 step:35409[D loss: 0.397385, acc: 69.53%, op_acc: 46.88%] [G loss: 1.128517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35410[D loss: 0.389413, acc: 62.50%, op_acc: 41.41%] [G loss: 1.112217]\n",
      "epoch:45 step:35411[D loss: 0.375670, acc: 72.66%, op_acc: 52.34%] [G loss: 1.070322]\n",
      "epoch:45 step:35412[D loss: 0.445398, acc: 59.38%, op_acc: 44.53%] [G loss: 1.275860]\n",
      "epoch:45 step:35413[D loss: 0.396362, acc: 67.97%, op_acc: 50.00%] [G loss: 1.147157]\n",
      "epoch:45 step:35414[D loss: 0.370942, acc: 65.62%, op_acc: 46.88%] [G loss: 1.163848]\n",
      "epoch:45 step:35415[D loss: 0.408160, acc: 61.72%, op_acc: 36.72%] [G loss: 0.917965]\n",
      "epoch:45 step:35416[D loss: 0.414886, acc: 67.97%, op_acc: 37.50%] [G loss: 1.088971]\n",
      "epoch:45 step:35417[D loss: 0.436778, acc: 57.03%, op_acc: 40.62%] [G loss: 1.051562]\n",
      "epoch:45 step:35418[D loss: 0.467173, acc: 53.91%, op_acc: 45.31%] [G loss: 1.258346]\n",
      "epoch:45 step:35419[D loss: 0.477785, acc: 50.78%, op_acc: 41.41%] [G loss: 1.018169]\n",
      "epoch:45 step:35420[D loss: 0.404133, acc: 71.09%, op_acc: 41.41%] [G loss: 1.076383]\n",
      "epoch:45 step:35421[D loss: 0.352660, acc: 67.97%, op_acc: 50.78%] [G loss: 1.131029]\n",
      "epoch:45 step:35422[D loss: 0.374410, acc: 71.09%, op_acc: 39.06%] [G loss: 1.141394]\n",
      "epoch:45 step:35423[D loss: 0.390696, acc: 64.06%, op_acc: 42.97%] [G loss: 1.191003]\n",
      "epoch:45 step:35424[D loss: 0.421752, acc: 63.28%, op_acc: 44.53%] [G loss: 1.138165]\n",
      "epoch:45 step:35425[D loss: 0.426115, acc: 53.91%, op_acc: 42.97%] [G loss: 1.135797]\n",
      "epoch:45 step:35426[D loss: 0.393979, acc: 62.50%, op_acc: 44.53%] [G loss: 1.153305]\n",
      "epoch:45 step:35427[D loss: 0.431953, acc: 64.06%, op_acc: 42.19%] [G loss: 1.092493]\n",
      "epoch:45 step:35428[D loss: 0.355885, acc: 68.75%, op_acc: 52.34%] [G loss: 1.043129]\n",
      "epoch:45 step:35429[D loss: 0.418473, acc: 67.19%, op_acc: 42.97%] [G loss: 0.929593]\n",
      "epoch:45 step:35430[D loss: 0.382835, acc: 71.09%, op_acc: 42.97%] [G loss: 1.000368]\n",
      "epoch:45 step:35431[D loss: 0.364706, acc: 73.44%, op_acc: 39.84%] [G loss: 1.133066]\n",
      "epoch:45 step:35432[D loss: 0.421624, acc: 59.38%, op_acc: 39.84%] [G loss: 1.000329]\n",
      "epoch:45 step:35433[D loss: 0.395149, acc: 66.41%, op_acc: 40.62%] [G loss: 1.004047]\n",
      "epoch:45 step:35434[D loss: 0.406679, acc: 64.84%, op_acc: 39.84%] [G loss: 1.093763]\n",
      "epoch:45 step:35435[D loss: 0.400269, acc: 60.16%, op_acc: 39.06%] [G loss: 1.112250]\n",
      "epoch:45 step:35436[D loss: 0.375711, acc: 72.66%, op_acc: 46.88%] [G loss: 1.255188]\n",
      "epoch:45 step:35437[D loss: 0.377217, acc: 71.88%, op_acc: 42.97%] [G loss: 1.036145]\n",
      "epoch:45 step:35438[D loss: 0.343922, acc: 72.66%, op_acc: 48.44%] [G loss: 1.099899]\n",
      "epoch:45 step:35439[D loss: 0.397096, acc: 67.19%, op_acc: 39.06%] [G loss: 0.975339]\n",
      "epoch:45 step:35440[D loss: 0.395459, acc: 63.28%, op_acc: 37.50%] [G loss: 0.804311]\n",
      "epoch:45 step:35441[D loss: 0.382003, acc: 65.62%, op_acc: 49.22%] [G loss: 1.182208]\n",
      "epoch:45 step:35442[D loss: 0.357641, acc: 73.44%, op_acc: 43.75%] [G loss: 1.057387]\n",
      "epoch:45 step:35443[D loss: 0.374390, acc: 67.19%, op_acc: 46.09%] [G loss: 1.110141]\n",
      "epoch:45 step:35444[D loss: 0.354795, acc: 69.53%, op_acc: 52.34%] [G loss: 0.978491]\n",
      "epoch:45 step:35445[D loss: 0.362058, acc: 72.66%, op_acc: 42.19%] [G loss: 1.118188]\n",
      "epoch:45 step:35446[D loss: 0.356647, acc: 74.22%, op_acc: 44.53%] [G loss: 1.222787]\n",
      "epoch:45 step:35447[D loss: 0.363220, acc: 69.53%, op_acc: 45.31%] [G loss: 1.071929]\n",
      "epoch:45 step:35448[D loss: 0.395966, acc: 64.84%, op_acc: 42.19%] [G loss: 0.879610]\n",
      "epoch:45 step:35449[D loss: 0.371508, acc: 71.09%, op_acc: 51.56%] [G loss: 1.007305]\n",
      "epoch:45 step:35450[D loss: 0.344004, acc: 73.44%, op_acc: 50.78%] [G loss: 0.991064]\n",
      "epoch:45 step:35451[D loss: 0.428296, acc: 67.19%, op_acc: 46.88%] [G loss: 0.935094]\n",
      "epoch:45 step:35452[D loss: 0.376233, acc: 71.09%, op_acc: 48.44%] [G loss: 0.823383]\n",
      "epoch:45 step:35453[D loss: 0.429236, acc: 57.03%, op_acc: 42.97%] [G loss: 0.994546]\n",
      "epoch:45 step:35454[D loss: 0.431762, acc: 65.62%, op_acc: 39.06%] [G loss: 0.982614]\n",
      "epoch:45 step:35455[D loss: 0.332671, acc: 77.34%, op_acc: 50.00%] [G loss: 1.070694]\n",
      "epoch:45 step:35456[D loss: 0.388358, acc: 71.09%, op_acc: 48.44%] [G loss: 1.044413]\n",
      "epoch:45 step:35457[D loss: 0.425045, acc: 64.06%, op_acc: 42.19%] [G loss: 1.123107]\n",
      "epoch:45 step:35458[D loss: 0.434131, acc: 62.50%, op_acc: 39.84%] [G loss: 1.113465]\n",
      "epoch:45 step:35459[D loss: 0.358541, acc: 71.09%, op_acc: 54.69%] [G loss: 0.975273]\n",
      "epoch:45 step:35460[D loss: 0.442411, acc: 57.81%, op_acc: 48.44%] [G loss: 1.204177]\n",
      "epoch:45 step:35461[D loss: 0.416231, acc: 66.41%, op_acc: 39.06%] [G loss: 0.931340]\n",
      "epoch:45 step:35462[D loss: 0.406991, acc: 61.72%, op_acc: 50.00%] [G loss: 1.136385]\n",
      "epoch:45 step:35463[D loss: 0.387376, acc: 67.97%, op_acc: 40.62%] [G loss: 1.084972]\n",
      "epoch:45 step:35464[D loss: 0.376774, acc: 71.88%, op_acc: 43.75%] [G loss: 0.986819]\n",
      "epoch:45 step:35465[D loss: 0.409845, acc: 60.94%, op_acc: 45.31%] [G loss: 1.035982]\n",
      "epoch:45 step:35466[D loss: 0.370065, acc: 71.09%, op_acc: 40.62%] [G loss: 1.060341]\n",
      "epoch:45 step:35467[D loss: 0.384566, acc: 64.84%, op_acc: 46.88%] [G loss: 1.044930]\n",
      "epoch:45 step:35468[D loss: 0.374560, acc: 72.66%, op_acc: 46.09%] [G loss: 0.970573]\n",
      "epoch:45 step:35469[D loss: 0.437272, acc: 64.84%, op_acc: 32.81%] [G loss: 0.871953]\n",
      "epoch:45 step:35470[D loss: 0.391845, acc: 66.41%, op_acc: 43.75%] [G loss: 0.924879]\n",
      "epoch:45 step:35471[D loss: 0.409757, acc: 63.28%, op_acc: 50.00%] [G loss: 0.895825]\n",
      "epoch:45 step:35472[D loss: 0.412695, acc: 69.53%, op_acc: 34.38%] [G loss: 1.039411]\n",
      "epoch:45 step:35473[D loss: 0.415744, acc: 60.16%, op_acc: 42.97%] [G loss: 1.048711]\n",
      "epoch:45 step:35474[D loss: 0.368224, acc: 71.09%, op_acc: 41.41%] [G loss: 0.965838]\n",
      "epoch:45 step:35475[D loss: 0.346171, acc: 68.75%, op_acc: 47.66%] [G loss: 0.898172]\n",
      "epoch:45 step:35476[D loss: 0.389146, acc: 67.19%, op_acc: 44.53%] [G loss: 1.017681]\n",
      "epoch:45 step:35477[D loss: 0.393226, acc: 62.50%, op_acc: 45.31%] [G loss: 0.843544]\n",
      "epoch:45 step:35478[D loss: 0.419008, acc: 66.41%, op_acc: 40.62%] [G loss: 1.086009]\n",
      "epoch:45 step:35479[D loss: 0.373491, acc: 70.31%, op_acc: 44.53%] [G loss: 1.141107]\n",
      "epoch:45 step:35480[D loss: 0.385495, acc: 68.75%, op_acc: 46.09%] [G loss: 1.428508]\n",
      "epoch:45 step:35481[D loss: 0.373296, acc: 72.66%, op_acc: 43.75%] [G loss: 1.024831]\n",
      "epoch:45 step:35482[D loss: 0.450408, acc: 53.91%, op_acc: 37.50%] [G loss: 1.024551]\n",
      "epoch:45 step:35483[D loss: 0.379902, acc: 61.72%, op_acc: 46.88%] [G loss: 1.066640]\n",
      "epoch:45 step:35484[D loss: 0.399046, acc: 68.75%, op_acc: 37.50%] [G loss: 0.930421]\n",
      "epoch:45 step:35485[D loss: 0.417102, acc: 61.72%, op_acc: 41.41%] [G loss: 1.183252]\n",
      "epoch:45 step:35486[D loss: 0.404031, acc: 62.50%, op_acc: 42.97%] [G loss: 0.827965]\n",
      "epoch:45 step:35487[D loss: 0.413194, acc: 60.94%, op_acc: 39.84%] [G loss: 1.017231]\n",
      "epoch:45 step:35488[D loss: 0.489287, acc: 53.91%, op_acc: 37.50%] [G loss: 0.937355]\n",
      "epoch:45 step:35489[D loss: 0.381495, acc: 70.31%, op_acc: 42.97%] [G loss: 1.152463]\n",
      "epoch:45 step:35490[D loss: 0.349963, acc: 71.09%, op_acc: 46.88%] [G loss: 0.906942]\n",
      "epoch:45 step:35491[D loss: 0.376831, acc: 67.97%, op_acc: 42.97%] [G loss: 0.980965]\n",
      "epoch:45 step:35492[D loss: 0.386055, acc: 63.28%, op_acc: 45.31%] [G loss: 0.983255]\n",
      "epoch:45 step:35493[D loss: 0.344858, acc: 75.00%, op_acc: 40.62%] [G loss: 0.988238]\n",
      "epoch:45 step:35494[D loss: 0.347669, acc: 74.22%, op_acc: 48.44%] [G loss: 1.255963]\n",
      "epoch:45 step:35495[D loss: 0.421330, acc: 64.84%, op_acc: 39.06%] [G loss: 1.115675]\n",
      "epoch:45 step:35496[D loss: 0.399304, acc: 71.09%, op_acc: 44.53%] [G loss: 1.025160]\n",
      "epoch:45 step:35497[D loss: 0.396645, acc: 68.75%, op_acc: 42.19%] [G loss: 0.863718]\n",
      "epoch:45 step:35498[D loss: 0.348969, acc: 71.09%, op_acc: 47.66%] [G loss: 1.193030]\n",
      "epoch:45 step:35499[D loss: 0.385019, acc: 67.19%, op_acc: 40.62%] [G loss: 1.051783]\n",
      "epoch:45 step:35500[D loss: 0.423198, acc: 61.72%, op_acc: 40.62%] [G loss: 0.830939]\n",
      "epoch:45 step:35501[D loss: 0.391450, acc: 67.97%, op_acc: 41.41%] [G loss: 1.138315]\n",
      "epoch:45 step:35502[D loss: 0.369730, acc: 75.78%, op_acc: 46.88%] [G loss: 1.024102]\n",
      "epoch:45 step:35503[D loss: 0.461023, acc: 58.59%, op_acc: 39.84%] [G loss: 0.922951]\n",
      "epoch:45 step:35504[D loss: 0.379329, acc: 72.66%, op_acc: 41.41%] [G loss: 0.888030]\n",
      "epoch:45 step:35505[D loss: 0.390648, acc: 67.97%, op_acc: 46.88%] [G loss: 1.080336]\n",
      "epoch:45 step:35506[D loss: 0.418936, acc: 66.41%, op_acc: 41.41%] [G loss: 0.791253]\n",
      "epoch:45 step:35507[D loss: 0.392234, acc: 60.94%, op_acc: 47.66%] [G loss: 1.251078]\n",
      "epoch:45 step:35508[D loss: 0.380254, acc: 65.62%, op_acc: 40.62%] [G loss: 1.158340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35509[D loss: 0.321656, acc: 79.69%, op_acc: 47.66%] [G loss: 1.206921]\n",
      "epoch:45 step:35510[D loss: 0.332867, acc: 84.38%, op_acc: 52.34%] [G loss: 1.164423]\n",
      "epoch:45 step:35511[D loss: 0.332744, acc: 75.78%, op_acc: 47.66%] [G loss: 1.096479]\n",
      "epoch:45 step:35512[D loss: 0.395355, acc: 68.75%, op_acc: 46.88%] [G loss: 1.231415]\n",
      "epoch:45 step:35513[D loss: 0.360871, acc: 70.31%, op_acc: 50.00%] [G loss: 1.168602]\n",
      "epoch:45 step:35514[D loss: 0.410972, acc: 63.28%, op_acc: 42.97%] [G loss: 1.071841]\n",
      "epoch:45 step:35515[D loss: 0.392377, acc: 68.75%, op_acc: 39.84%] [G loss: 1.255336]\n",
      "epoch:45 step:35516[D loss: 0.373021, acc: 65.62%, op_acc: 49.22%] [G loss: 1.024804]\n",
      "epoch:45 step:35517[D loss: 0.389934, acc: 69.53%, op_acc: 50.00%] [G loss: 1.184157]\n",
      "epoch:45 step:35518[D loss: 0.385705, acc: 67.19%, op_acc: 47.66%] [G loss: 0.990372]\n",
      "epoch:45 step:35519[D loss: 0.377311, acc: 63.28%, op_acc: 48.44%] [G loss: 1.016244]\n",
      "epoch:45 step:35520[D loss: 0.379020, acc: 64.84%, op_acc: 50.00%] [G loss: 1.043305]\n",
      "epoch:45 step:35521[D loss: 0.378723, acc: 73.44%, op_acc: 50.00%] [G loss: 1.190554]\n",
      "epoch:45 step:35522[D loss: 0.415781, acc: 62.50%, op_acc: 42.19%] [G loss: 1.120174]\n",
      "epoch:45 step:35523[D loss: 0.389865, acc: 71.09%, op_acc: 42.19%] [G loss: 0.995457]\n",
      "epoch:45 step:35524[D loss: 0.296900, acc: 85.16%, op_acc: 47.66%] [G loss: 1.069240]\n",
      "epoch:45 step:35525[D loss: 0.311869, acc: 85.16%, op_acc: 49.22%] [G loss: 1.034219]\n",
      "epoch:45 step:35526[D loss: 0.352516, acc: 73.44%, op_acc: 45.31%] [G loss: 1.083482]\n",
      "epoch:45 step:35527[D loss: 0.374296, acc: 71.09%, op_acc: 42.97%] [G loss: 0.913585]\n",
      "epoch:45 step:35528[D loss: 0.413385, acc: 57.81%, op_acc: 51.56%] [G loss: 0.971054]\n",
      "epoch:45 step:35529[D loss: 0.435427, acc: 63.28%, op_acc: 41.41%] [G loss: 1.084527]\n",
      "epoch:45 step:35530[D loss: 0.364896, acc: 64.06%, op_acc: 51.56%] [G loss: 1.106374]\n",
      "epoch:45 step:35531[D loss: 0.332213, acc: 75.78%, op_acc: 53.12%] [G loss: 1.087533]\n",
      "epoch:45 step:35532[D loss: 0.371761, acc: 75.00%, op_acc: 46.88%] [G loss: 1.053668]\n",
      "epoch:45 step:35533[D loss: 0.338251, acc: 77.34%, op_acc: 50.00%] [G loss: 0.994651]\n",
      "epoch:45 step:35534[D loss: 0.414078, acc: 64.06%, op_acc: 46.88%] [G loss: 1.047612]\n",
      "epoch:45 step:35535[D loss: 0.385075, acc: 67.97%, op_acc: 40.62%] [G loss: 0.983669]\n",
      "epoch:45 step:35536[D loss: 0.390667, acc: 64.06%, op_acc: 52.34%] [G loss: 0.997032]\n",
      "epoch:45 step:35537[D loss: 0.378709, acc: 63.28%, op_acc: 48.44%] [G loss: 0.952427]\n",
      "epoch:45 step:35538[D loss: 0.412710, acc: 66.41%, op_acc: 44.53%] [G loss: 0.982360]\n",
      "epoch:45 step:35539[D loss: 0.419043, acc: 56.25%, op_acc: 44.53%] [G loss: 1.131828]\n",
      "epoch:45 step:35540[D loss: 0.432482, acc: 59.38%, op_acc: 35.16%] [G loss: 0.961557]\n",
      "epoch:45 step:35541[D loss: 0.397909, acc: 62.50%, op_acc: 50.00%] [G loss: 0.894716]\n",
      "epoch:45 step:35542[D loss: 0.376865, acc: 73.44%, op_acc: 48.44%] [G loss: 0.925884]\n",
      "epoch:45 step:35543[D loss: 0.440782, acc: 60.94%, op_acc: 34.38%] [G loss: 1.136525]\n",
      "epoch:45 step:35544[D loss: 0.389344, acc: 68.75%, op_acc: 45.31%] [G loss: 1.007657]\n",
      "epoch:45 step:35545[D loss: 0.372093, acc: 70.31%, op_acc: 49.22%] [G loss: 0.873991]\n",
      "epoch:45 step:35546[D loss: 0.422918, acc: 55.47%, op_acc: 49.22%] [G loss: 0.997146]\n",
      "epoch:45 step:35547[D loss: 0.349629, acc: 73.44%, op_acc: 35.94%] [G loss: 1.120687]\n",
      "epoch:45 step:35548[D loss: 0.399371, acc: 61.72%, op_acc: 42.19%] [G loss: 0.899536]\n",
      "epoch:45 step:35549[D loss: 0.343302, acc: 74.22%, op_acc: 48.44%] [G loss: 1.088963]\n",
      "epoch:45 step:35550[D loss: 0.377298, acc: 70.31%, op_acc: 40.62%] [G loss: 1.167716]\n",
      "epoch:45 step:35551[D loss: 0.388676, acc: 67.19%, op_acc: 48.44%] [G loss: 1.025786]\n",
      "epoch:45 step:35552[D loss: 0.384811, acc: 74.22%, op_acc: 42.97%] [G loss: 0.938894]\n",
      "epoch:45 step:35553[D loss: 0.397030, acc: 60.16%, op_acc: 46.09%] [G loss: 0.991179]\n",
      "epoch:45 step:35554[D loss: 0.395497, acc: 67.19%, op_acc: 42.97%] [G loss: 1.118345]\n",
      "epoch:45 step:35555[D loss: 0.406150, acc: 62.50%, op_acc: 42.97%] [G loss: 0.976603]\n",
      "epoch:45 step:35556[D loss: 0.370381, acc: 75.00%, op_acc: 50.00%] [G loss: 0.838339]\n",
      "epoch:45 step:35557[D loss: 0.347386, acc: 71.09%, op_acc: 54.69%] [G loss: 1.031251]\n",
      "epoch:45 step:35558[D loss: 0.395324, acc: 66.41%, op_acc: 47.66%] [G loss: 1.051358]\n",
      "epoch:45 step:35559[D loss: 0.309171, acc: 81.25%, op_acc: 46.88%] [G loss: 1.043069]\n",
      "epoch:45 step:35560[D loss: 0.352284, acc: 75.00%, op_acc: 41.41%] [G loss: 1.209385]\n",
      "epoch:45 step:35561[D loss: 0.372921, acc: 71.09%, op_acc: 44.53%] [G loss: 1.173754]\n",
      "epoch:45 step:35562[D loss: 0.419005, acc: 60.16%, op_acc: 38.28%] [G loss: 0.831738]\n",
      "epoch:45 step:35563[D loss: 0.466755, acc: 58.59%, op_acc: 40.62%] [G loss: 0.914954]\n",
      "epoch:45 step:35564[D loss: 0.395717, acc: 65.62%, op_acc: 46.88%] [G loss: 0.910838]\n",
      "epoch:45 step:35565[D loss: 0.432257, acc: 59.38%, op_acc: 40.62%] [G loss: 1.055682]\n",
      "epoch:45 step:35566[D loss: 0.380677, acc: 67.19%, op_acc: 50.00%] [G loss: 1.064384]\n",
      "epoch:45 step:35567[D loss: 0.342607, acc: 70.31%, op_acc: 49.22%] [G loss: 1.167276]\n",
      "epoch:45 step:35568[D loss: 0.391733, acc: 66.41%, op_acc: 43.75%] [G loss: 1.202392]\n",
      "epoch:45 step:35569[D loss: 0.400593, acc: 69.53%, op_acc: 38.28%] [G loss: 1.075444]\n",
      "epoch:45 step:35570[D loss: 0.377531, acc: 66.41%, op_acc: 47.66%] [G loss: 0.909533]\n",
      "epoch:45 step:35571[D loss: 0.388302, acc: 68.75%, op_acc: 42.19%] [G loss: 0.947656]\n",
      "epoch:45 step:35572[D loss: 0.390168, acc: 65.62%, op_acc: 41.41%] [G loss: 0.913331]\n",
      "epoch:45 step:35573[D loss: 0.382620, acc: 68.75%, op_acc: 42.97%] [G loss: 0.932788]\n",
      "epoch:45 step:35574[D loss: 0.387644, acc: 71.09%, op_acc: 42.19%] [G loss: 0.917069]\n",
      "epoch:45 step:35575[D loss: 0.369622, acc: 65.62%, op_acc: 47.66%] [G loss: 0.948632]\n",
      "epoch:45 step:35576[D loss: 0.417184, acc: 62.50%, op_acc: 42.19%] [G loss: 0.908441]\n",
      "epoch:45 step:35577[D loss: 0.398189, acc: 59.38%, op_acc: 42.97%] [G loss: 0.792228]\n",
      "epoch:45 step:35578[D loss: 0.386865, acc: 67.97%, op_acc: 43.75%] [G loss: 1.014359]\n",
      "epoch:45 step:35579[D loss: 0.386178, acc: 64.84%, op_acc: 47.66%] [G loss: 1.165461]\n",
      "epoch:45 step:35580[D loss: 0.401883, acc: 67.19%, op_acc: 43.75%] [G loss: 1.064495]\n",
      "epoch:45 step:35581[D loss: 0.427935, acc: 66.41%, op_acc: 50.00%] [G loss: 0.991608]\n",
      "epoch:45 step:35582[D loss: 0.377492, acc: 71.09%, op_acc: 46.09%] [G loss: 1.009665]\n",
      "epoch:45 step:35583[D loss: 0.393015, acc: 61.72%, op_acc: 42.19%] [G loss: 1.068910]\n",
      "epoch:45 step:35584[D loss: 0.406132, acc: 58.59%, op_acc: 41.41%] [G loss: 1.148975]\n",
      "epoch:45 step:35585[D loss: 0.382520, acc: 69.53%, op_acc: 41.41%] [G loss: 1.053905]\n",
      "epoch:45 step:35586[D loss: 0.353340, acc: 72.66%, op_acc: 42.97%] [G loss: 1.196951]\n",
      "epoch:45 step:35587[D loss: 0.378477, acc: 64.84%, op_acc: 46.88%] [G loss: 1.223343]\n",
      "epoch:45 step:35588[D loss: 0.401591, acc: 66.41%, op_acc: 44.53%] [G loss: 1.150991]\n",
      "epoch:45 step:35589[D loss: 0.349954, acc: 72.66%, op_acc: 53.91%] [G loss: 1.214367]\n",
      "epoch:45 step:35590[D loss: 0.378935, acc: 71.09%, op_acc: 44.53%] [G loss: 1.319788]\n",
      "epoch:45 step:35591[D loss: 0.376536, acc: 64.06%, op_acc: 45.31%] [G loss: 1.016981]\n",
      "epoch:45 step:35592[D loss: 0.366981, acc: 75.78%, op_acc: 40.62%] [G loss: 1.029993]\n",
      "epoch:45 step:35593[D loss: 0.390867, acc: 63.28%, op_acc: 49.22%] [G loss: 1.211309]\n",
      "epoch:45 step:35594[D loss: 0.348537, acc: 77.34%, op_acc: 48.44%] [G loss: 1.022377]\n",
      "epoch:45 step:35595[D loss: 0.407230, acc: 60.16%, op_acc: 42.19%] [G loss: 1.384951]\n",
      "epoch:45 step:35596[D loss: 0.400254, acc: 62.50%, op_acc: 44.53%] [G loss: 1.412780]\n",
      "epoch:45 step:35597[D loss: 0.339421, acc: 69.53%, op_acc: 50.00%] [G loss: 1.335729]\n",
      "epoch:45 step:35598[D loss: 0.408728, acc: 62.50%, op_acc: 38.28%] [G loss: 1.175813]\n",
      "epoch:45 step:35599[D loss: 0.426706, acc: 59.38%, op_acc: 40.62%] [G loss: 1.207960]\n",
      "epoch:45 step:35600[D loss: 0.431895, acc: 60.16%, op_acc: 47.66%] [G loss: 1.355277]\n",
      "epoch:45 step:35601[D loss: 0.416531, acc: 60.94%, op_acc: 46.09%] [G loss: 1.084297]\n",
      "epoch:45 step:35602[D loss: 0.421277, acc: 62.50%, op_acc: 35.94%] [G loss: 1.145551]\n",
      "epoch:45 step:35603[D loss: 0.397691, acc: 62.50%, op_acc: 42.97%] [G loss: 0.940046]\n",
      "epoch:45 step:35604[D loss: 0.352816, acc: 67.97%, op_acc: 46.88%] [G loss: 0.941450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35605[D loss: 0.359835, acc: 69.53%, op_acc: 44.53%] [G loss: 1.207264]\n",
      "epoch:45 step:35606[D loss: 0.397151, acc: 64.84%, op_acc: 44.53%] [G loss: 1.190727]\n",
      "epoch:45 step:35607[D loss: 0.353389, acc: 74.22%, op_acc: 45.31%] [G loss: 1.147488]\n",
      "epoch:45 step:35608[D loss: 0.437831, acc: 61.72%, op_acc: 41.41%] [G loss: 1.020928]\n",
      "epoch:45 step:35609[D loss: 0.410915, acc: 65.62%, op_acc: 39.06%] [G loss: 1.176828]\n",
      "epoch:45 step:35610[D loss: 0.404909, acc: 64.84%, op_acc: 44.53%] [G loss: 0.935668]\n",
      "epoch:45 step:35611[D loss: 0.352016, acc: 72.66%, op_acc: 44.53%] [G loss: 1.247484]\n",
      "epoch:45 step:35612[D loss: 0.441152, acc: 60.94%, op_acc: 39.84%] [G loss: 1.293855]\n",
      "epoch:45 step:35613[D loss: 0.386973, acc: 68.75%, op_acc: 48.44%] [G loss: 1.114188]\n",
      "epoch:45 step:35614[D loss: 0.339200, acc: 79.69%, op_acc: 49.22%] [G loss: 1.156409]\n",
      "epoch:45 step:35615[D loss: 0.334647, acc: 73.44%, op_acc: 47.66%] [G loss: 1.114739]\n",
      "epoch:45 step:35616[D loss: 0.355201, acc: 69.53%, op_acc: 44.53%] [G loss: 1.166822]\n",
      "epoch:45 step:35617[D loss: 0.372813, acc: 67.97%, op_acc: 41.41%] [G loss: 1.129137]\n",
      "epoch:45 step:35618[D loss: 0.413287, acc: 57.03%, op_acc: 47.66%] [G loss: 0.947253]\n",
      "epoch:45 step:35619[D loss: 0.410952, acc: 62.50%, op_acc: 41.41%] [G loss: 1.095016]\n",
      "epoch:45 step:35620[D loss: 0.410092, acc: 58.59%, op_acc: 46.88%] [G loss: 1.099659]\n",
      "epoch:45 step:35621[D loss: 0.439308, acc: 63.28%, op_acc: 38.28%] [G loss: 1.205444]\n",
      "epoch:45 step:35622[D loss: 0.342747, acc: 74.22%, op_acc: 42.19%] [G loss: 1.250733]\n",
      "epoch:45 step:35623[D loss: 0.394646, acc: 67.97%, op_acc: 46.88%] [G loss: 1.221600]\n",
      "epoch:45 step:35624[D loss: 0.437466, acc: 59.38%, op_acc: 39.06%] [G loss: 1.234432]\n",
      "epoch:45 step:35625[D loss: 0.446898, acc: 65.62%, op_acc: 34.38%] [G loss: 1.103352]\n",
      "epoch:45 step:35626[D loss: 0.465018, acc: 60.94%, op_acc: 39.06%] [G loss: 1.010430]\n",
      "epoch:45 step:35627[D loss: 0.376753, acc: 70.31%, op_acc: 47.66%] [G loss: 1.320856]\n",
      "epoch:45 step:35628[D loss: 0.379358, acc: 69.53%, op_acc: 46.88%] [G loss: 1.139288]\n",
      "epoch:45 step:35629[D loss: 0.353182, acc: 71.88%, op_acc: 51.56%] [G loss: 1.004336]\n",
      "epoch:45 step:35630[D loss: 0.372048, acc: 70.31%, op_acc: 39.84%] [G loss: 1.083137]\n",
      "epoch:45 step:35631[D loss: 0.368092, acc: 67.19%, op_acc: 45.31%] [G loss: 1.168153]\n",
      "epoch:45 step:35632[D loss: 0.400296, acc: 63.28%, op_acc: 48.44%] [G loss: 1.180876]\n",
      "epoch:45 step:35633[D loss: 0.424888, acc: 61.72%, op_acc: 45.31%] [G loss: 1.122846]\n",
      "epoch:45 step:35634[D loss: 0.467942, acc: 60.16%, op_acc: 46.88%] [G loss: 1.018176]\n",
      "epoch:45 step:35635[D loss: 0.340673, acc: 78.91%, op_acc: 52.34%] [G loss: 1.018677]\n",
      "epoch:45 step:35636[D loss: 0.425564, acc: 63.28%, op_acc: 40.62%] [G loss: 0.986773]\n",
      "epoch:45 step:35637[D loss: 0.375749, acc: 69.53%, op_acc: 43.75%] [G loss: 1.103344]\n",
      "epoch:45 step:35638[D loss: 0.453744, acc: 54.69%, op_acc: 41.41%] [G loss: 0.860510]\n",
      "epoch:45 step:35639[D loss: 0.346164, acc: 74.22%, op_acc: 50.00%] [G loss: 1.059647]\n",
      "epoch:45 step:35640[D loss: 0.356904, acc: 76.56%, op_acc: 40.62%] [G loss: 1.273188]\n",
      "epoch:45 step:35641[D loss: 0.321832, acc: 82.81%, op_acc: 42.97%] [G loss: 1.136667]\n",
      "epoch:45 step:35642[D loss: 0.410877, acc: 61.72%, op_acc: 47.66%] [G loss: 1.201202]\n",
      "epoch:45 step:35643[D loss: 0.448273, acc: 58.59%, op_acc: 38.28%] [G loss: 1.055867]\n",
      "epoch:45 step:35644[D loss: 0.367401, acc: 75.00%, op_acc: 43.75%] [G loss: 1.219999]\n",
      "epoch:45 step:35645[D loss: 0.386072, acc: 67.97%, op_acc: 48.44%] [G loss: 1.221449]\n",
      "epoch:45 step:35646[D loss: 0.387617, acc: 67.97%, op_acc: 41.41%] [G loss: 1.033324]\n",
      "epoch:45 step:35647[D loss: 0.340047, acc: 75.78%, op_acc: 42.19%] [G loss: 1.083905]\n",
      "epoch:45 step:35648[D loss: 0.355507, acc: 74.22%, op_acc: 42.19%] [G loss: 1.195770]\n",
      "epoch:45 step:35649[D loss: 0.394235, acc: 67.19%, op_acc: 44.53%] [G loss: 1.328597]\n",
      "epoch:45 step:35650[D loss: 0.364162, acc: 73.44%, op_acc: 48.44%] [G loss: 1.134757]\n",
      "epoch:45 step:35651[D loss: 0.366593, acc: 71.09%, op_acc: 49.22%] [G loss: 1.121021]\n",
      "epoch:45 step:35652[D loss: 0.366655, acc: 67.97%, op_acc: 50.00%] [G loss: 1.035349]\n",
      "epoch:45 step:35653[D loss: 0.394947, acc: 69.53%, op_acc: 42.97%] [G loss: 1.046592]\n",
      "epoch:45 step:35654[D loss: 0.451035, acc: 57.03%, op_acc: 42.97%] [G loss: 1.026468]\n",
      "epoch:45 step:35655[D loss: 0.366084, acc: 65.62%, op_acc: 46.88%] [G loss: 1.067940]\n",
      "epoch:45 step:35656[D loss: 0.414275, acc: 64.06%, op_acc: 43.75%] [G loss: 1.173680]\n",
      "epoch:45 step:35657[D loss: 0.406572, acc: 67.19%, op_acc: 41.41%] [G loss: 1.171129]\n",
      "epoch:45 step:35658[D loss: 0.406463, acc: 64.06%, op_acc: 36.72%] [G loss: 1.281750]\n",
      "epoch:45 step:35659[D loss: 0.408382, acc: 60.16%, op_acc: 41.41%] [G loss: 1.210062]\n",
      "epoch:45 step:35660[D loss: 0.376183, acc: 68.75%, op_acc: 50.78%] [G loss: 1.305548]\n",
      "epoch:45 step:35661[D loss: 0.376518, acc: 69.53%, op_acc: 49.22%] [G loss: 1.193310]\n",
      "epoch:45 step:35662[D loss: 0.452483, acc: 60.94%, op_acc: 42.97%] [G loss: 1.049121]\n",
      "epoch:45 step:35663[D loss: 0.407096, acc: 64.84%, op_acc: 45.31%] [G loss: 1.341984]\n",
      "epoch:45 step:35664[D loss: 0.389740, acc: 59.38%, op_acc: 46.09%] [G loss: 1.259412]\n",
      "epoch:45 step:35665[D loss: 0.377163, acc: 67.19%, op_acc: 48.44%] [G loss: 1.355539]\n",
      "epoch:45 step:35666[D loss: 0.321400, acc: 78.12%, op_acc: 50.00%] [G loss: 1.179521]\n",
      "epoch:45 step:35667[D loss: 0.454946, acc: 53.12%, op_acc: 45.31%] [G loss: 1.281791]\n",
      "epoch:45 step:35668[D loss: 0.334091, acc: 74.22%, op_acc: 48.44%] [G loss: 1.200924]\n",
      "epoch:45 step:35669[D loss: 0.390218, acc: 71.09%, op_acc: 39.84%] [G loss: 1.203577]\n",
      "epoch:45 step:35670[D loss: 0.355323, acc: 71.88%, op_acc: 41.41%] [G loss: 1.169331]\n",
      "epoch:45 step:35671[D loss: 0.446449, acc: 53.12%, op_acc: 39.06%] [G loss: 1.259680]\n",
      "epoch:45 step:35672[D loss: 0.426188, acc: 62.50%, op_acc: 38.28%] [G loss: 1.157216]\n",
      "epoch:45 step:35673[D loss: 0.366262, acc: 71.88%, op_acc: 45.31%] [G loss: 1.008092]\n",
      "epoch:45 step:35674[D loss: 0.402198, acc: 64.84%, op_acc: 41.41%] [G loss: 1.239962]\n",
      "epoch:45 step:35675[D loss: 0.360252, acc: 73.44%, op_acc: 48.44%] [G loss: 1.517519]\n",
      "epoch:45 step:35676[D loss: 0.394800, acc: 64.84%, op_acc: 39.84%] [G loss: 1.211964]\n",
      "epoch:45 step:35677[D loss: 0.495202, acc: 52.34%, op_acc: 40.62%] [G loss: 0.922710]\n",
      "epoch:45 step:35678[D loss: 0.415461, acc: 60.94%, op_acc: 42.19%] [G loss: 1.078178]\n",
      "epoch:45 step:35679[D loss: 0.380662, acc: 69.53%, op_acc: 46.88%] [G loss: 0.968618]\n",
      "epoch:45 step:35680[D loss: 0.388034, acc: 69.53%, op_acc: 42.19%] [G loss: 1.224163]\n",
      "epoch:45 step:35681[D loss: 0.367400, acc: 68.75%, op_acc: 50.78%] [G loss: 1.362844]\n",
      "epoch:45 step:35682[D loss: 0.460372, acc: 58.59%, op_acc: 39.06%] [G loss: 1.254574]\n",
      "epoch:45 step:35683[D loss: 0.329122, acc: 82.03%, op_acc: 45.31%] [G loss: 1.235870]\n",
      "epoch:45 step:35684[D loss: 0.453113, acc: 50.78%, op_acc: 39.84%] [G loss: 1.022688]\n",
      "epoch:45 step:35685[D loss: 0.369290, acc: 64.84%, op_acc: 42.19%] [G loss: 1.204398]\n",
      "epoch:45 step:35686[D loss: 0.336847, acc: 79.69%, op_acc: 49.22%] [G loss: 1.333628]\n",
      "epoch:45 step:35687[D loss: 0.367988, acc: 69.53%, op_acc: 42.97%] [G loss: 1.234524]\n",
      "epoch:45 step:35688[D loss: 0.402351, acc: 68.75%, op_acc: 39.84%] [G loss: 0.903217]\n",
      "epoch:45 step:35689[D loss: 0.391185, acc: 64.84%, op_acc: 43.75%] [G loss: 1.117894]\n",
      "epoch:45 step:35690[D loss: 0.409047, acc: 67.19%, op_acc: 38.28%] [G loss: 1.211938]\n",
      "epoch:45 step:35691[D loss: 0.363315, acc: 68.75%, op_acc: 52.34%] [G loss: 1.192141]\n",
      "epoch:45 step:35692[D loss: 0.342402, acc: 75.00%, op_acc: 42.19%] [G loss: 1.284683]\n",
      "epoch:45 step:35693[D loss: 0.403170, acc: 65.62%, op_acc: 41.41%] [G loss: 1.126210]\n",
      "epoch:45 step:35694[D loss: 0.409479, acc: 67.19%, op_acc: 47.66%] [G loss: 1.032287]\n",
      "epoch:45 step:35695[D loss: 0.460523, acc: 48.44%, op_acc: 39.84%] [G loss: 1.011543]\n",
      "epoch:45 step:35696[D loss: 0.410575, acc: 60.94%, op_acc: 39.84%] [G loss: 1.120384]\n",
      "epoch:45 step:35697[D loss: 0.396594, acc: 71.09%, op_acc: 45.31%] [G loss: 1.143394]\n",
      "epoch:45 step:35698[D loss: 0.340500, acc: 75.00%, op_acc: 46.88%] [G loss: 1.165993]\n",
      "epoch:45 step:35699[D loss: 0.412053, acc: 62.50%, op_acc: 42.19%] [G loss: 1.071519]\n",
      "epoch:45 step:35700[D loss: 0.358726, acc: 74.22%, op_acc: 46.88%] [G loss: 1.130525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35701[D loss: 0.460999, acc: 53.12%, op_acc: 40.62%] [G loss: 1.128460]\n",
      "epoch:45 step:35702[D loss: 0.378407, acc: 69.53%, op_acc: 42.97%] [G loss: 0.921391]\n",
      "epoch:45 step:35703[D loss: 0.368632, acc: 67.19%, op_acc: 48.44%] [G loss: 1.107269]\n",
      "epoch:45 step:35704[D loss: 0.356222, acc: 72.66%, op_acc: 39.06%] [G loss: 1.136702]\n",
      "epoch:45 step:35705[D loss: 0.403993, acc: 61.72%, op_acc: 40.62%] [G loss: 1.170021]\n",
      "epoch:45 step:35706[D loss: 0.326970, acc: 77.34%, op_acc: 52.34%] [G loss: 1.191438]\n",
      "epoch:45 step:35707[D loss: 0.385143, acc: 67.19%, op_acc: 48.44%] [G loss: 1.215230]\n",
      "epoch:45 step:35708[D loss: 0.439770, acc: 58.59%, op_acc: 38.28%] [G loss: 0.994009]\n",
      "epoch:45 step:35709[D loss: 0.421227, acc: 64.06%, op_acc: 42.97%] [G loss: 0.858462]\n",
      "epoch:45 step:35710[D loss: 0.360964, acc: 70.31%, op_acc: 46.09%] [G loss: 0.999325]\n",
      "epoch:45 step:35711[D loss: 0.380468, acc: 69.53%, op_acc: 42.97%] [G loss: 1.004288]\n",
      "epoch:45 step:35712[D loss: 0.355333, acc: 71.88%, op_acc: 45.31%] [G loss: 1.175945]\n",
      "epoch:45 step:35713[D loss: 0.343872, acc: 73.44%, op_acc: 51.56%] [G loss: 1.178126]\n",
      "epoch:45 step:35714[D loss: 0.306818, acc: 80.47%, op_acc: 50.78%] [G loss: 1.196681]\n",
      "epoch:45 step:35715[D loss: 0.388404, acc: 70.31%, op_acc: 44.53%] [G loss: 1.310565]\n",
      "epoch:45 step:35716[D loss: 0.435761, acc: 64.06%, op_acc: 39.06%] [G loss: 1.019896]\n",
      "epoch:45 step:35717[D loss: 0.427590, acc: 58.59%, op_acc: 47.66%] [G loss: 1.096872]\n",
      "epoch:45 step:35718[D loss: 0.428091, acc: 60.16%, op_acc: 40.62%] [G loss: 1.280357]\n",
      "epoch:45 step:35719[D loss: 0.450743, acc: 53.12%, op_acc: 39.06%] [G loss: 1.259283]\n",
      "epoch:45 step:35720[D loss: 0.421562, acc: 60.16%, op_acc: 43.75%] [G loss: 1.131086]\n",
      "epoch:45 step:35721[D loss: 0.355133, acc: 68.75%, op_acc: 42.97%] [G loss: 1.162024]\n",
      "epoch:45 step:35722[D loss: 0.393949, acc: 69.53%, op_acc: 38.28%] [G loss: 1.046059]\n",
      "epoch:45 step:35723[D loss: 0.425676, acc: 65.62%, op_acc: 36.72%] [G loss: 1.204542]\n",
      "epoch:45 step:35724[D loss: 0.374735, acc: 73.44%, op_acc: 50.78%] [G loss: 1.196958]\n",
      "epoch:45 step:35725[D loss: 0.401317, acc: 64.84%, op_acc: 46.88%] [G loss: 1.076123]\n",
      "epoch:45 step:35726[D loss: 0.384554, acc: 67.19%, op_acc: 42.97%] [G loss: 1.177636]\n",
      "epoch:45 step:35727[D loss: 0.410675, acc: 65.62%, op_acc: 39.06%] [G loss: 1.324128]\n",
      "epoch:45 step:35728[D loss: 0.391699, acc: 67.19%, op_acc: 39.84%] [G loss: 1.165769]\n",
      "epoch:45 step:35729[D loss: 0.453979, acc: 58.59%, op_acc: 39.06%] [G loss: 1.148921]\n",
      "epoch:45 step:35730[D loss: 0.342475, acc: 76.56%, op_acc: 48.44%] [G loss: 1.097820]\n",
      "epoch:45 step:35731[D loss: 0.454952, acc: 60.94%, op_acc: 39.06%] [G loss: 0.988955]\n",
      "epoch:45 step:35732[D loss: 0.371627, acc: 68.75%, op_acc: 40.62%] [G loss: 1.046600]\n",
      "epoch:45 step:35733[D loss: 0.407461, acc: 60.94%, op_acc: 47.66%] [G loss: 1.006390]\n",
      "epoch:45 step:35734[D loss: 0.397582, acc: 67.19%, op_acc: 40.62%] [G loss: 1.120638]\n",
      "epoch:45 step:35735[D loss: 0.391332, acc: 62.50%, op_acc: 42.19%] [G loss: 1.090752]\n",
      "epoch:45 step:35736[D loss: 0.395133, acc: 67.97%, op_acc: 42.19%] [G loss: 1.133515]\n",
      "epoch:45 step:35737[D loss: 0.478758, acc: 51.56%, op_acc: 39.06%] [G loss: 1.088153]\n",
      "epoch:45 step:35738[D loss: 0.416250, acc: 60.94%, op_acc: 42.19%] [G loss: 1.303711]\n",
      "epoch:45 step:35739[D loss: 0.480439, acc: 53.91%, op_acc: 37.50%] [G loss: 0.843468]\n",
      "epoch:45 step:35740[D loss: 0.388242, acc: 64.06%, op_acc: 42.19%] [G loss: 1.037689]\n",
      "epoch:45 step:35741[D loss: 0.358788, acc: 75.00%, op_acc: 50.78%] [G loss: 1.158467]\n",
      "epoch:45 step:35742[D loss: 0.421965, acc: 57.03%, op_acc: 41.41%] [G loss: 1.020447]\n",
      "epoch:45 step:35743[D loss: 0.372659, acc: 72.66%, op_acc: 43.75%] [G loss: 1.153600]\n",
      "epoch:45 step:35744[D loss: 0.409196, acc: 64.84%, op_acc: 38.28%] [G loss: 1.042586]\n",
      "epoch:45 step:35745[D loss: 0.334566, acc: 78.12%, op_acc: 42.97%] [G loss: 1.241713]\n",
      "epoch:45 step:35746[D loss: 0.403566, acc: 62.50%, op_acc: 39.84%] [G loss: 1.090804]\n",
      "epoch:45 step:35747[D loss: 0.347356, acc: 73.44%, op_acc: 51.56%] [G loss: 1.125503]\n",
      "epoch:45 step:35748[D loss: 0.404122, acc: 60.94%, op_acc: 50.78%] [G loss: 1.081787]\n",
      "epoch:45 step:35749[D loss: 0.400943, acc: 68.75%, op_acc: 46.09%] [G loss: 1.104595]\n",
      "epoch:45 step:35750[D loss: 0.391202, acc: 65.62%, op_acc: 46.88%] [G loss: 1.112813]\n",
      "epoch:45 step:35751[D loss: 0.377572, acc: 65.62%, op_acc: 45.31%] [G loss: 1.076439]\n",
      "epoch:45 step:35752[D loss: 0.402324, acc: 64.84%, op_acc: 52.34%] [G loss: 0.930512]\n",
      "epoch:45 step:35753[D loss: 0.421131, acc: 56.25%, op_acc: 42.19%] [G loss: 0.975448]\n",
      "epoch:45 step:35754[D loss: 0.456230, acc: 58.59%, op_acc: 38.28%] [G loss: 0.945914]\n",
      "epoch:45 step:35755[D loss: 0.349790, acc: 75.78%, op_acc: 34.38%] [G loss: 1.174936]\n",
      "epoch:45 step:35756[D loss: 0.381339, acc: 67.97%, op_acc: 47.66%] [G loss: 1.270530]\n",
      "epoch:45 step:35757[D loss: 0.372984, acc: 75.78%, op_acc: 45.31%] [G loss: 1.325081]\n",
      "epoch:45 step:35758[D loss: 0.435485, acc: 60.94%, op_acc: 39.84%] [G loss: 1.149922]\n",
      "epoch:45 step:35759[D loss: 0.325445, acc: 80.47%, op_acc: 49.22%] [G loss: 0.978769]\n",
      "epoch:45 step:35760[D loss: 0.380349, acc: 71.88%, op_acc: 47.66%] [G loss: 1.016725]\n",
      "epoch:45 step:35761[D loss: 0.430774, acc: 62.50%, op_acc: 39.84%] [G loss: 0.999527]\n",
      "epoch:45 step:35762[D loss: 0.409103, acc: 63.28%, op_acc: 40.62%] [G loss: 1.272793]\n",
      "epoch:45 step:35763[D loss: 0.365098, acc: 65.62%, op_acc: 45.31%] [G loss: 1.075099]\n",
      "epoch:45 step:35764[D loss: 0.385840, acc: 71.88%, op_acc: 47.66%] [G loss: 1.118046]\n",
      "epoch:45 step:35765[D loss: 0.389748, acc: 66.41%, op_acc: 42.97%] [G loss: 1.004606]\n",
      "epoch:45 step:35766[D loss: 0.394176, acc: 70.31%, op_acc: 42.19%] [G loss: 1.029869]\n",
      "epoch:45 step:35767[D loss: 0.400789, acc: 67.19%, op_acc: 40.62%] [G loss: 0.894081]\n",
      "epoch:45 step:35768[D loss: 0.454045, acc: 51.56%, op_acc: 39.84%] [G loss: 1.082265]\n",
      "epoch:45 step:35769[D loss: 0.371441, acc: 73.44%, op_acc: 48.44%] [G loss: 1.158947]\n",
      "epoch:45 step:35770[D loss: 0.368074, acc: 71.88%, op_acc: 49.22%] [G loss: 1.086476]\n",
      "epoch:45 step:35771[D loss: 0.368731, acc: 65.62%, op_acc: 57.03%] [G loss: 1.121765]\n",
      "epoch:45 step:35772[D loss: 0.370181, acc: 71.09%, op_acc: 48.44%] [G loss: 1.021292]\n",
      "epoch:45 step:35773[D loss: 0.362450, acc: 71.09%, op_acc: 43.75%] [G loss: 1.074645]\n",
      "epoch:45 step:35774[D loss: 0.423108, acc: 57.81%, op_acc: 42.19%] [G loss: 0.974649]\n",
      "epoch:45 step:35775[D loss: 0.361461, acc: 73.44%, op_acc: 42.19%] [G loss: 1.063761]\n",
      "epoch:45 step:35776[D loss: 0.432423, acc: 59.38%, op_acc: 40.62%] [G loss: 0.940678]\n",
      "epoch:45 step:35777[D loss: 0.379923, acc: 68.75%, op_acc: 44.53%] [G loss: 0.951409]\n",
      "epoch:45 step:35778[D loss: 0.403987, acc: 65.62%, op_acc: 44.53%] [G loss: 1.016208]\n",
      "epoch:45 step:35779[D loss: 0.439184, acc: 48.44%, op_acc: 50.78%] [G loss: 1.156976]\n",
      "epoch:45 step:35780[D loss: 0.363076, acc: 65.62%, op_acc: 53.12%] [G loss: 1.030858]\n",
      "epoch:45 step:35781[D loss: 0.377841, acc: 64.84%, op_acc: 46.09%] [G loss: 0.935801]\n",
      "epoch:45 step:35782[D loss: 0.353975, acc: 71.88%, op_acc: 39.06%] [G loss: 1.059565]\n",
      "epoch:45 step:35783[D loss: 0.460897, acc: 57.03%, op_acc: 39.84%] [G loss: 1.260674]\n",
      "epoch:45 step:35784[D loss: 0.407336, acc: 59.38%, op_acc: 42.97%] [G loss: 1.024505]\n",
      "epoch:45 step:35785[D loss: 0.384526, acc: 67.97%, op_acc: 50.00%] [G loss: 0.941592]\n",
      "epoch:45 step:35786[D loss: 0.394516, acc: 64.06%, op_acc: 44.53%] [G loss: 1.130406]\n",
      "epoch:45 step:35787[D loss: 0.407810, acc: 59.38%, op_acc: 42.97%] [G loss: 1.131261]\n",
      "epoch:45 step:35788[D loss: 0.395915, acc: 64.06%, op_acc: 42.97%] [G loss: 1.062906]\n",
      "epoch:45 step:35789[D loss: 0.343747, acc: 69.53%, op_acc: 50.00%] [G loss: 0.991543]\n",
      "epoch:45 step:35790[D loss: 0.366306, acc: 63.28%, op_acc: 49.22%] [G loss: 1.050303]\n",
      "epoch:45 step:35791[D loss: 0.361719, acc: 82.03%, op_acc: 50.78%] [G loss: 1.194701]\n",
      "epoch:45 step:35792[D loss: 0.434412, acc: 57.03%, op_acc: 45.31%] [G loss: 1.086482]\n",
      "epoch:45 step:35793[D loss: 0.396613, acc: 65.62%, op_acc: 44.53%] [G loss: 0.965894]\n",
      "epoch:45 step:35794[D loss: 0.353587, acc: 75.78%, op_acc: 46.88%] [G loss: 1.068006]\n",
      "epoch:45 step:35795[D loss: 0.397443, acc: 67.97%, op_acc: 45.31%] [G loss: 1.206791]\n",
      "epoch:45 step:35796[D loss: 0.410557, acc: 60.94%, op_acc: 44.53%] [G loss: 1.037700]\n",
      "epoch:45 step:35797[D loss: 0.417715, acc: 65.62%, op_acc: 41.41%] [G loss: 1.114559]\n",
      "epoch:45 step:35798[D loss: 0.382885, acc: 63.28%, op_acc: 46.88%] [G loss: 1.054978]\n",
      "epoch:45 step:35799[D loss: 0.433517, acc: 58.59%, op_acc: 39.84%] [G loss: 1.199155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35800[D loss: 0.411086, acc: 63.28%, op_acc: 45.31%] [G loss: 1.052169]\n",
      "epoch:45 step:35801[D loss: 0.388723, acc: 63.28%, op_acc: 42.97%] [G loss: 1.169063]\n",
      "epoch:45 step:35802[D loss: 0.371437, acc: 71.88%, op_acc: 50.00%] [G loss: 1.002173]\n",
      "epoch:45 step:35803[D loss: 0.368831, acc: 69.53%, op_acc: 46.88%] [G loss: 1.088752]\n",
      "epoch:45 step:35804[D loss: 0.326365, acc: 74.22%, op_acc: 42.97%] [G loss: 1.191934]\n",
      "epoch:45 step:35805[D loss: 0.387530, acc: 67.97%, op_acc: 44.53%] [G loss: 0.914013]\n",
      "epoch:45 step:35806[D loss: 0.381605, acc: 70.31%, op_acc: 48.44%] [G loss: 1.169485]\n",
      "epoch:45 step:35807[D loss: 0.392579, acc: 57.03%, op_acc: 44.53%] [G loss: 1.134711]\n",
      "epoch:45 step:35808[D loss: 0.373897, acc: 68.75%, op_acc: 42.19%] [G loss: 0.997291]\n",
      "epoch:45 step:35809[D loss: 0.369885, acc: 70.31%, op_acc: 43.75%] [G loss: 1.355352]\n",
      "epoch:45 step:35810[D loss: 0.367212, acc: 73.44%, op_acc: 41.41%] [G loss: 1.349866]\n",
      "epoch:45 step:35811[D loss: 0.399486, acc: 66.41%, op_acc: 43.75%] [G loss: 1.123460]\n",
      "epoch:45 step:35812[D loss: 0.333859, acc: 72.66%, op_acc: 53.12%] [G loss: 1.233930]\n",
      "epoch:45 step:35813[D loss: 0.389759, acc: 64.84%, op_acc: 49.22%] [G loss: 1.316447]\n",
      "epoch:45 step:35814[D loss: 0.413452, acc: 67.19%, op_acc: 43.75%] [G loss: 1.158769]\n",
      "epoch:45 step:35815[D loss: 0.424993, acc: 54.69%, op_acc: 39.84%] [G loss: 1.078541]\n",
      "epoch:45 step:35816[D loss: 0.400418, acc: 64.06%, op_acc: 42.97%] [G loss: 1.338319]\n",
      "epoch:45 step:35817[D loss: 0.399766, acc: 76.56%, op_acc: 40.62%] [G loss: 0.792135]\n",
      "epoch:45 step:35818[D loss: 0.501504, acc: 46.88%, op_acc: 37.50%] [G loss: 1.027097]\n",
      "epoch:45 step:35819[D loss: 0.381971, acc: 64.84%, op_acc: 53.12%] [G loss: 1.181297]\n",
      "epoch:45 step:35820[D loss: 0.356324, acc: 70.31%, op_acc: 43.75%] [G loss: 1.032686]\n",
      "epoch:45 step:35821[D loss: 0.420349, acc: 66.41%, op_acc: 36.72%] [G loss: 1.058983]\n",
      "epoch:45 step:35822[D loss: 0.439355, acc: 62.50%, op_acc: 39.06%] [G loss: 1.021672]\n",
      "epoch:45 step:35823[D loss: 0.364759, acc: 71.09%, op_acc: 46.88%] [G loss: 1.038183]\n",
      "epoch:45 step:35824[D loss: 0.375762, acc: 67.19%, op_acc: 46.09%] [G loss: 0.950014]\n",
      "epoch:45 step:35825[D loss: 0.424746, acc: 67.19%, op_acc: 40.62%] [G loss: 1.062031]\n",
      "epoch:45 step:35826[D loss: 0.412301, acc: 71.09%, op_acc: 37.50%] [G loss: 1.171366]\n",
      "epoch:45 step:35827[D loss: 0.370262, acc: 65.62%, op_acc: 42.97%] [G loss: 1.012399]\n",
      "epoch:45 step:35828[D loss: 0.371905, acc: 68.75%, op_acc: 46.88%] [G loss: 0.991055]\n",
      "epoch:45 step:35829[D loss: 0.377252, acc: 71.88%, op_acc: 45.31%] [G loss: 1.237036]\n",
      "epoch:45 step:35830[D loss: 0.337954, acc: 76.56%, op_acc: 57.03%] [G loss: 1.204043]\n",
      "epoch:45 step:35831[D loss: 0.381273, acc: 75.78%, op_acc: 41.41%] [G loss: 1.219641]\n",
      "epoch:45 step:35832[D loss: 0.347972, acc: 71.09%, op_acc: 50.78%] [G loss: 0.865738]\n",
      "epoch:45 step:35833[D loss: 0.388894, acc: 63.28%, op_acc: 53.12%] [G loss: 0.965291]\n",
      "epoch:45 step:35834[D loss: 0.354027, acc: 71.09%, op_acc: 47.66%] [G loss: 1.001309]\n",
      "epoch:45 step:35835[D loss: 0.385284, acc: 63.28%, op_acc: 41.41%] [G loss: 0.924761]\n",
      "epoch:45 step:35836[D loss: 0.394679, acc: 67.19%, op_acc: 43.75%] [G loss: 1.226068]\n",
      "epoch:45 step:35837[D loss: 0.367772, acc: 71.88%, op_acc: 46.09%] [G loss: 1.121852]\n",
      "epoch:45 step:35838[D loss: 0.399005, acc: 66.41%, op_acc: 40.62%] [G loss: 1.215540]\n",
      "epoch:45 step:35839[D loss: 0.399673, acc: 65.62%, op_acc: 42.97%] [G loss: 1.131721]\n",
      "epoch:45 step:35840[D loss: 0.395318, acc: 70.31%, op_acc: 42.97%] [G loss: 1.075315]\n",
      "epoch:45 step:35841[D loss: 0.404053, acc: 65.62%, op_acc: 42.97%] [G loss: 1.139353]\n",
      "epoch:45 step:35842[D loss: 0.374651, acc: 65.62%, op_acc: 45.31%] [G loss: 0.939749]\n",
      "epoch:45 step:35843[D loss: 0.390137, acc: 67.97%, op_acc: 43.75%] [G loss: 1.044128]\n",
      "epoch:45 step:35844[D loss: 0.353974, acc: 71.88%, op_acc: 51.56%] [G loss: 1.075586]\n",
      "epoch:45 step:35845[D loss: 0.413028, acc: 60.94%, op_acc: 43.75%] [G loss: 0.967961]\n",
      "epoch:45 step:35846[D loss: 0.430147, acc: 64.84%, op_acc: 38.28%] [G loss: 1.067327]\n",
      "epoch:45 step:35847[D loss: 0.420298, acc: 60.94%, op_acc: 42.97%] [G loss: 1.067017]\n",
      "epoch:45 step:35848[D loss: 0.372336, acc: 71.09%, op_acc: 39.06%] [G loss: 1.023546]\n",
      "epoch:45 step:35849[D loss: 0.398320, acc: 65.62%, op_acc: 42.97%] [G loss: 1.043415]\n",
      "epoch:45 step:35850[D loss: 0.363990, acc: 72.66%, op_acc: 47.66%] [G loss: 1.229309]\n",
      "epoch:45 step:35851[D loss: 0.386569, acc: 60.94%, op_acc: 48.44%] [G loss: 1.165790]\n",
      "epoch:45 step:35852[D loss: 0.402300, acc: 65.62%, op_acc: 50.00%] [G loss: 1.122708]\n",
      "epoch:45 step:35853[D loss: 0.436227, acc: 58.59%, op_acc: 43.75%] [G loss: 1.108458]\n",
      "epoch:45 step:35854[D loss: 0.432521, acc: 57.81%, op_acc: 42.97%] [G loss: 0.944308]\n",
      "epoch:45 step:35855[D loss: 0.337445, acc: 76.56%, op_acc: 45.31%] [G loss: 1.242831]\n",
      "epoch:45 step:35856[D loss: 0.389948, acc: 67.19%, op_acc: 43.75%] [G loss: 1.083081]\n",
      "epoch:45 step:35857[D loss: 0.415994, acc: 64.06%, op_acc: 48.44%] [G loss: 1.032580]\n",
      "epoch:45 step:35858[D loss: 0.455048, acc: 51.56%, op_acc: 43.75%] [G loss: 1.071585]\n",
      "epoch:45 step:35859[D loss: 0.432348, acc: 57.81%, op_acc: 39.06%] [G loss: 1.149377]\n",
      "epoch:45 step:35860[D loss: 0.393254, acc: 63.28%, op_acc: 47.66%] [G loss: 1.071338]\n",
      "epoch:45 step:35861[D loss: 0.386130, acc: 70.31%, op_acc: 45.31%] [G loss: 1.139517]\n",
      "epoch:45 step:35862[D loss: 0.353885, acc: 73.44%, op_acc: 50.00%] [G loss: 1.133195]\n",
      "epoch:45 step:35863[D loss: 0.414783, acc: 62.50%, op_acc: 46.09%] [G loss: 0.972430]\n",
      "epoch:45 step:35864[D loss: 0.392713, acc: 64.84%, op_acc: 45.31%] [G loss: 1.066974]\n",
      "epoch:45 step:35865[D loss: 0.362690, acc: 69.53%, op_acc: 46.09%] [G loss: 1.222128]\n",
      "epoch:45 step:35866[D loss: 0.439463, acc: 61.72%, op_acc: 49.22%] [G loss: 1.063868]\n",
      "epoch:45 step:35867[D loss: 0.392045, acc: 69.53%, op_acc: 43.75%] [G loss: 1.230202]\n",
      "epoch:45 step:35868[D loss: 0.436599, acc: 57.81%, op_acc: 47.66%] [G loss: 1.188392]\n",
      "epoch:45 step:35869[D loss: 0.454409, acc: 61.72%, op_acc: 39.06%] [G loss: 1.183826]\n",
      "epoch:45 step:35870[D loss: 0.376534, acc: 67.19%, op_acc: 48.44%] [G loss: 1.229296]\n",
      "epoch:45 step:35871[D loss: 0.388639, acc: 66.41%, op_acc: 42.19%] [G loss: 1.094447]\n",
      "epoch:45 step:35872[D loss: 0.394287, acc: 60.94%, op_acc: 39.06%] [G loss: 1.031272]\n",
      "epoch:45 step:35873[D loss: 0.382293, acc: 68.75%, op_acc: 36.72%] [G loss: 1.027758]\n",
      "epoch:45 step:35874[D loss: 0.345870, acc: 75.78%, op_acc: 48.44%] [G loss: 1.020039]\n",
      "epoch:45 step:35875[D loss: 0.375722, acc: 71.88%, op_acc: 42.97%] [G loss: 1.143445]\n",
      "epoch:45 step:35876[D loss: 0.378712, acc: 65.62%, op_acc: 43.75%] [G loss: 1.113573]\n",
      "epoch:45 step:35877[D loss: 0.444086, acc: 57.81%, op_acc: 40.62%] [G loss: 1.072054]\n",
      "epoch:45 step:35878[D loss: 0.439497, acc: 59.38%, op_acc: 41.41%] [G loss: 1.112105]\n",
      "epoch:45 step:35879[D loss: 0.433610, acc: 58.59%, op_acc: 42.97%] [G loss: 1.284096]\n",
      "epoch:45 step:35880[D loss: 0.449292, acc: 62.50%, op_acc: 41.41%] [G loss: 1.213129]\n",
      "epoch:45 step:35881[D loss: 0.419833, acc: 66.41%, op_acc: 40.62%] [G loss: 1.229760]\n",
      "epoch:45 step:35882[D loss: 0.386432, acc: 63.28%, op_acc: 44.53%] [G loss: 1.172051]\n",
      "epoch:45 step:35883[D loss: 0.400712, acc: 61.72%, op_acc: 45.31%] [G loss: 0.979011]\n",
      "epoch:45 step:35884[D loss: 0.409845, acc: 64.06%, op_acc: 42.19%] [G loss: 1.411679]\n",
      "epoch:45 step:35885[D loss: 0.388890, acc: 60.16%, op_acc: 48.44%] [G loss: 1.003777]\n",
      "epoch:45 step:35886[D loss: 0.339026, acc: 71.09%, op_acc: 50.78%] [G loss: 1.053375]\n",
      "epoch:45 step:35887[D loss: 0.402052, acc: 67.97%, op_acc: 48.44%] [G loss: 1.048144]\n",
      "epoch:45 step:35888[D loss: 0.440504, acc: 61.72%, op_acc: 43.75%] [G loss: 1.149911]\n",
      "epoch:45 step:35889[D loss: 0.392198, acc: 60.16%, op_acc: 47.66%] [G loss: 1.115433]\n",
      "epoch:45 step:35890[D loss: 0.386462, acc: 69.53%, op_acc: 45.31%] [G loss: 1.093549]\n",
      "epoch:45 step:35891[D loss: 0.404484, acc: 65.62%, op_acc: 44.53%] [G loss: 1.181300]\n",
      "epoch:45 step:35892[D loss: 0.393432, acc: 67.97%, op_acc: 42.19%] [G loss: 1.208260]\n",
      "epoch:45 step:35893[D loss: 0.404632, acc: 64.84%, op_acc: 48.44%] [G loss: 1.118718]\n",
      "epoch:45 step:35894[D loss: 0.387093, acc: 68.75%, op_acc: 45.31%] [G loss: 1.135063]\n",
      "epoch:45 step:35895[D loss: 0.390660, acc: 66.41%, op_acc: 46.09%] [G loss: 0.912906]\n",
      "epoch:45 step:35896[D loss: 0.359393, acc: 75.78%, op_acc: 41.41%] [G loss: 1.122134]\n",
      "epoch:45 step:35897[D loss: 0.388673, acc: 67.97%, op_acc: 44.53%] [G loss: 1.026102]\n",
      "epoch:45 step:35898[D loss: 0.355766, acc: 69.53%, op_acc: 48.44%] [G loss: 1.235112]\n",
      "epoch:45 step:35899[D loss: 0.363015, acc: 73.44%, op_acc: 46.88%] [G loss: 1.136975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45 step:35900[D loss: 0.372966, acc: 73.44%, op_acc: 42.97%] [G loss: 1.204930]\n",
      "epoch:45 step:35901[D loss: 0.390623, acc: 68.75%, op_acc: 46.88%] [G loss: 1.181744]\n",
      "epoch:45 step:35902[D loss: 0.297254, acc: 82.03%, op_acc: 55.47%] [G loss: 1.215506]\n",
      "epoch:45 step:35903[D loss: 0.386193, acc: 64.84%, op_acc: 50.00%] [G loss: 1.122927]\n",
      "epoch:45 step:35904[D loss: 0.374969, acc: 71.88%, op_acc: 51.56%] [G loss: 1.071137]\n",
      "epoch:45 step:35905[D loss: 0.398284, acc: 61.72%, op_acc: 46.09%] [G loss: 1.316121]\n",
      "epoch:45 step:35906[D loss: 0.314732, acc: 77.34%, op_acc: 55.47%] [G loss: 1.233564]\n",
      "epoch:45 step:35907[D loss: 0.462458, acc: 57.03%, op_acc: 47.66%] [G loss: 1.153604]\n",
      "epoch:45 step:35908[D loss: 0.430410, acc: 61.72%, op_acc: 43.75%] [G loss: 1.072990]\n",
      "epoch:45 step:35909[D loss: 0.429908, acc: 55.47%, op_acc: 43.75%] [G loss: 1.136754]\n",
      "epoch:45 step:35910[D loss: 0.389688, acc: 64.06%, op_acc: 46.09%] [G loss: 1.323432]\n",
      "epoch:45 step:35911[D loss: 0.421236, acc: 60.94%, op_acc: 38.28%] [G loss: 1.096017]\n",
      "epoch:45 step:35912[D loss: 0.320597, acc: 82.03%, op_acc: 50.78%] [G loss: 1.132425]\n",
      "epoch:45 step:35913[D loss: 0.383639, acc: 67.97%, op_acc: 40.62%] [G loss: 1.314159]\n",
      "epoch:45 step:35914[D loss: 0.398227, acc: 61.72%, op_acc: 45.31%] [G loss: 1.114519]\n",
      "epoch:45 step:35915[D loss: 0.371904, acc: 64.06%, op_acc: 49.22%] [G loss: 1.185311]\n",
      "epoch:45 step:35916[D loss: 0.505931, acc: 47.66%, op_acc: 35.16%] [G loss: 1.103853]\n",
      "epoch:45 step:35917[D loss: 0.398110, acc: 69.53%, op_acc: 41.41%] [G loss: 1.098930]\n",
      "epoch:45 step:35918[D loss: 0.416254, acc: 66.41%, op_acc: 39.06%] [G loss: 1.127731]\n",
      "epoch:45 step:35919[D loss: 0.353000, acc: 71.88%, op_acc: 50.00%] [G loss: 0.985442]\n",
      "epoch:45 step:35920[D loss: 0.338508, acc: 70.31%, op_acc: 52.34%] [G loss: 1.013943]\n",
      "epoch:45 step:35921[D loss: 0.393437, acc: 64.06%, op_acc: 45.31%] [G loss: 1.044281]\n",
      "epoch:45 step:35922[D loss: 0.373037, acc: 70.31%, op_acc: 46.09%] [G loss: 1.036626]\n",
      "epoch:45 step:35923[D loss: 0.373454, acc: 67.19%, op_acc: 45.31%] [G loss: 1.153047]\n",
      "epoch:45 step:35924[D loss: 0.370052, acc: 64.84%, op_acc: 41.41%] [G loss: 1.073943]\n",
      "epoch:45 step:35925[D loss: 0.327840, acc: 79.69%, op_acc: 47.66%] [G loss: 1.174367]\n",
      "epoch:45 step:35926[D loss: 0.399599, acc: 63.28%, op_acc: 39.84%] [G loss: 1.048191]\n",
      "epoch:46 step:35927[D loss: 0.363707, acc: 73.44%, op_acc: 48.44%] [G loss: 1.204212]\n",
      "epoch:46 step:35928[D loss: 0.370609, acc: 69.53%, op_acc: 48.44%] [G loss: 1.044436]\n",
      "epoch:46 step:35929[D loss: 0.404762, acc: 66.41%, op_acc: 45.31%] [G loss: 0.976525]\n",
      "epoch:46 step:35930[D loss: 0.350073, acc: 71.09%, op_acc: 41.41%] [G loss: 1.261200]\n",
      "epoch:46 step:35931[D loss: 0.380427, acc: 69.53%, op_acc: 44.53%] [G loss: 1.078941]\n",
      "epoch:46 step:35932[D loss: 0.393226, acc: 65.62%, op_acc: 52.34%] [G loss: 1.145514]\n",
      "epoch:46 step:35933[D loss: 0.371125, acc: 69.53%, op_acc: 42.97%] [G loss: 0.999255]\n",
      "epoch:46 step:35934[D loss: 0.386884, acc: 64.84%, op_acc: 49.22%] [G loss: 1.115700]\n",
      "epoch:46 step:35935[D loss: 0.326089, acc: 78.12%, op_acc: 45.31%] [G loss: 1.057020]\n",
      "epoch:46 step:35936[D loss: 0.415190, acc: 62.50%, op_acc: 39.84%] [G loss: 1.018120]\n",
      "epoch:46 step:35937[D loss: 0.491235, acc: 50.78%, op_acc: 32.03%] [G loss: 0.953697]\n",
      "epoch:46 step:35938[D loss: 0.346304, acc: 72.66%, op_acc: 45.31%] [G loss: 1.084217]\n",
      "epoch:46 step:35939[D loss: 0.346955, acc: 76.56%, op_acc: 36.72%] [G loss: 1.018931]\n",
      "epoch:46 step:35940[D loss: 0.427070, acc: 60.16%, op_acc: 42.97%] [G loss: 0.999262]\n",
      "epoch:46 step:35941[D loss: 0.299889, acc: 84.38%, op_acc: 48.44%] [G loss: 1.068354]\n",
      "epoch:46 step:35942[D loss: 0.341662, acc: 75.78%, op_acc: 53.91%] [G loss: 1.043614]\n",
      "epoch:46 step:35943[D loss: 0.395608, acc: 66.41%, op_acc: 42.19%] [G loss: 1.008274]\n",
      "epoch:46 step:35944[D loss: 0.459317, acc: 47.66%, op_acc: 42.97%] [G loss: 0.986053]\n",
      "epoch:46 step:35945[D loss: 0.402411, acc: 60.16%, op_acc: 46.88%] [G loss: 1.002769]\n",
      "epoch:46 step:35946[D loss: 0.345478, acc: 75.00%, op_acc: 50.00%] [G loss: 1.152789]\n",
      "epoch:46 step:35947[D loss: 0.397784, acc: 70.31%, op_acc: 40.62%] [G loss: 1.101089]\n",
      "epoch:46 step:35948[D loss: 0.392644, acc: 68.75%, op_acc: 54.69%] [G loss: 1.292394]\n",
      "epoch:46 step:35949[D loss: 0.367931, acc: 67.19%, op_acc: 47.66%] [G loss: 0.885561]\n",
      "epoch:46 step:35950[D loss: 0.440620, acc: 62.50%, op_acc: 38.28%] [G loss: 1.028550]\n",
      "epoch:46 step:35951[D loss: 0.399777, acc: 65.62%, op_acc: 42.97%] [G loss: 1.176237]\n",
      "epoch:46 step:35952[D loss: 0.377348, acc: 65.62%, op_acc: 50.00%] [G loss: 1.092620]\n",
      "epoch:46 step:35953[D loss: 0.370652, acc: 68.75%, op_acc: 47.66%] [G loss: 1.019118]\n",
      "epoch:46 step:35954[D loss: 0.384863, acc: 64.06%, op_acc: 43.75%] [G loss: 0.943598]\n",
      "epoch:46 step:35955[D loss: 0.404876, acc: 60.94%, op_acc: 46.09%] [G loss: 1.063626]\n",
      "epoch:46 step:35956[D loss: 0.354598, acc: 71.09%, op_acc: 49.22%] [G loss: 1.083314]\n",
      "epoch:46 step:35957[D loss: 0.426803, acc: 63.28%, op_acc: 38.28%] [G loss: 1.086519]\n",
      "epoch:46 step:35958[D loss: 0.433046, acc: 61.72%, op_acc: 40.62%] [G loss: 1.012833]\n",
      "epoch:46 step:35959[D loss: 0.393227, acc: 64.84%, op_acc: 46.09%] [G loss: 1.043403]\n",
      "epoch:46 step:35960[D loss: 0.331462, acc: 78.91%, op_acc: 50.78%] [G loss: 0.901131]\n",
      "epoch:46 step:35961[D loss: 0.433944, acc: 57.81%, op_acc: 39.84%] [G loss: 1.258873]\n",
      "epoch:46 step:35962[D loss: 0.370521, acc: 72.66%, op_acc: 51.56%] [G loss: 1.189360]\n",
      "epoch:46 step:35963[D loss: 0.358935, acc: 71.09%, op_acc: 42.97%] [G loss: 1.155843]\n",
      "epoch:46 step:35964[D loss: 0.377464, acc: 70.31%, op_acc: 50.00%] [G loss: 1.173764]\n",
      "epoch:46 step:35965[D loss: 0.382734, acc: 67.19%, op_acc: 50.00%] [G loss: 1.046306]\n",
      "epoch:46 step:35966[D loss: 0.407767, acc: 70.31%, op_acc: 39.84%] [G loss: 1.084203]\n",
      "epoch:46 step:35967[D loss: 0.360213, acc: 71.88%, op_acc: 49.22%] [G loss: 1.055387]\n",
      "epoch:46 step:35968[D loss: 0.399890, acc: 58.59%, op_acc: 46.09%] [G loss: 0.960444]\n",
      "epoch:46 step:35969[D loss: 0.373493, acc: 68.75%, op_acc: 46.88%] [G loss: 1.202117]\n",
      "epoch:46 step:35970[D loss: 0.414246, acc: 55.47%, op_acc: 42.19%] [G loss: 1.218780]\n",
      "epoch:46 step:35971[D loss: 0.346403, acc: 76.56%, op_acc: 46.88%] [G loss: 1.025285]\n",
      "epoch:46 step:35972[D loss: 0.362107, acc: 74.22%, op_acc: 50.78%] [G loss: 1.144569]\n",
      "epoch:46 step:35973[D loss: 0.408702, acc: 62.50%, op_acc: 42.97%] [G loss: 0.981824]\n",
      "epoch:46 step:35974[D loss: 0.491230, acc: 50.78%, op_acc: 32.03%] [G loss: 0.820961]\n",
      "epoch:46 step:35975[D loss: 0.342881, acc: 76.56%, op_acc: 41.41%] [G loss: 0.915638]\n",
      "epoch:46 step:35976[D loss: 0.377326, acc: 69.53%, op_acc: 44.53%] [G loss: 0.838368]\n",
      "epoch:46 step:35977[D loss: 0.302597, acc: 84.38%, op_acc: 46.88%] [G loss: 0.864838]\n",
      "epoch:46 step:35978[D loss: 0.369896, acc: 70.31%, op_acc: 44.53%] [G loss: 0.997077]\n",
      "epoch:46 step:35979[D loss: 0.431495, acc: 56.25%, op_acc: 46.09%] [G loss: 1.156696]\n",
      "epoch:46 step:35980[D loss: 0.416246, acc: 64.06%, op_acc: 46.09%] [G loss: 1.199528]\n",
      "epoch:46 step:35981[D loss: 0.404202, acc: 57.81%, op_acc: 48.44%] [G loss: 1.055441]\n",
      "epoch:46 step:35982[D loss: 0.391375, acc: 65.62%, op_acc: 39.06%] [G loss: 0.868906]\n",
      "epoch:46 step:35983[D loss: 0.392221, acc: 66.41%, op_acc: 48.44%] [G loss: 1.291392]\n",
      "epoch:46 step:35984[D loss: 0.365513, acc: 68.75%, op_acc: 48.44%] [G loss: 0.898574]\n",
      "epoch:46 step:35985[D loss: 0.404984, acc: 67.19%, op_acc: 46.09%] [G loss: 1.098002]\n",
      "epoch:46 step:35986[D loss: 0.369928, acc: 75.00%, op_acc: 38.28%] [G loss: 0.814223]\n",
      "epoch:46 step:35987[D loss: 0.363385, acc: 77.34%, op_acc: 42.19%] [G loss: 1.175376]\n",
      "epoch:46 step:35988[D loss: 0.374714, acc: 73.44%, op_acc: 42.19%] [G loss: 1.039742]\n",
      "epoch:46 step:35989[D loss: 0.410410, acc: 67.97%, op_acc: 48.44%] [G loss: 1.139950]\n",
      "epoch:46 step:35990[D loss: 0.386601, acc: 71.09%, op_acc: 50.00%] [G loss: 1.158528]\n",
      "epoch:46 step:35991[D loss: 0.456397, acc: 58.59%, op_acc: 41.41%] [G loss: 0.892540]\n",
      "epoch:46 step:35992[D loss: 0.460540, acc: 50.78%, op_acc: 41.41%] [G loss: 0.891982]\n",
      "epoch:46 step:35993[D loss: 0.342472, acc: 74.22%, op_acc: 47.66%] [G loss: 1.103930]\n",
      "epoch:46 step:35994[D loss: 0.366894, acc: 72.66%, op_acc: 39.84%] [G loss: 1.049853]\n",
      "epoch:46 step:35995[D loss: 0.393308, acc: 59.38%, op_acc: 53.91%] [G loss: 0.914106]\n",
      "epoch:46 step:35996[D loss: 0.448864, acc: 64.84%, op_acc: 42.19%] [G loss: 0.891190]\n",
      "epoch:46 step:35997[D loss: 0.419727, acc: 66.41%, op_acc: 40.62%] [G loss: 1.167036]\n",
      "epoch:46 step:35998[D loss: 0.345130, acc: 74.22%, op_acc: 49.22%] [G loss: 1.165645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:35999[D loss: 0.481456, acc: 46.88%, op_acc: 39.06%] [G loss: 0.980787]\n",
      "epoch:46 step:36000[D loss: 0.341389, acc: 72.66%, op_acc: 42.97%] [G loss: 0.851516]\n",
      "epoch:46 step:36001[D loss: 0.373331, acc: 69.53%, op_acc: 43.75%] [G loss: 1.084192]\n",
      "epoch:46 step:36002[D loss: 0.385770, acc: 69.53%, op_acc: 44.53%] [G loss: 0.955176]\n",
      "epoch:46 step:36003[D loss: 0.380719, acc: 66.41%, op_acc: 45.31%] [G loss: 0.906843]\n",
      "epoch:46 step:36004[D loss: 0.432858, acc: 62.50%, op_acc: 34.38%] [G loss: 0.752080]\n",
      "epoch:46 step:36005[D loss: 0.408490, acc: 64.06%, op_acc: 44.53%] [G loss: 1.017759]\n",
      "epoch:46 step:36006[D loss: 0.424905, acc: 64.06%, op_acc: 36.72%] [G loss: 1.030852]\n",
      "epoch:46 step:36007[D loss: 0.404334, acc: 65.62%, op_acc: 40.62%] [G loss: 0.948020]\n",
      "epoch:46 step:36008[D loss: 0.378802, acc: 69.53%, op_acc: 42.19%] [G loss: 1.105314]\n",
      "epoch:46 step:36009[D loss: 0.417381, acc: 66.41%, op_acc: 46.88%] [G loss: 1.050243]\n",
      "epoch:46 step:36010[D loss: 0.344244, acc: 80.47%, op_acc: 52.34%] [G loss: 1.063707]\n",
      "epoch:46 step:36011[D loss: 0.382804, acc: 73.44%, op_acc: 39.06%] [G loss: 1.053979]\n",
      "epoch:46 step:36012[D loss: 0.346129, acc: 75.78%, op_acc: 43.75%] [G loss: 1.039423]\n",
      "epoch:46 step:36013[D loss: 0.354949, acc: 68.75%, op_acc: 45.31%] [G loss: 1.027112]\n",
      "epoch:46 step:36014[D loss: 0.390303, acc: 67.97%, op_acc: 49.22%] [G loss: 1.053728]\n",
      "epoch:46 step:36015[D loss: 0.429944, acc: 57.81%, op_acc: 35.94%] [G loss: 0.948167]\n",
      "epoch:46 step:36016[D loss: 0.344431, acc: 75.00%, op_acc: 44.53%] [G loss: 1.132592]\n",
      "epoch:46 step:36017[D loss: 0.365041, acc: 67.97%, op_acc: 52.34%] [G loss: 1.087276]\n",
      "epoch:46 step:36018[D loss: 0.444234, acc: 52.34%, op_acc: 40.62%] [G loss: 0.911070]\n",
      "epoch:46 step:36019[D loss: 0.349606, acc: 67.97%, op_acc: 46.88%] [G loss: 0.925402]\n",
      "epoch:46 step:36020[D loss: 0.417562, acc: 60.16%, op_acc: 46.88%] [G loss: 1.051914]\n",
      "epoch:46 step:36021[D loss: 0.386076, acc: 67.19%, op_acc: 42.19%] [G loss: 1.039760]\n",
      "epoch:46 step:36022[D loss: 0.389599, acc: 73.44%, op_acc: 42.97%] [G loss: 1.017219]\n",
      "epoch:46 step:36023[D loss: 0.345871, acc: 72.66%, op_acc: 47.66%] [G loss: 0.962198]\n",
      "epoch:46 step:36024[D loss: 0.370832, acc: 72.66%, op_acc: 39.06%] [G loss: 1.088124]\n",
      "epoch:46 step:36025[D loss: 0.392327, acc: 62.50%, op_acc: 45.31%] [G loss: 0.908705]\n",
      "epoch:46 step:36026[D loss: 0.353007, acc: 78.12%, op_acc: 42.19%] [G loss: 0.992893]\n",
      "epoch:46 step:36027[D loss: 0.408376, acc: 66.41%, op_acc: 36.72%] [G loss: 1.112809]\n",
      "epoch:46 step:36028[D loss: 0.406872, acc: 64.06%, op_acc: 46.88%] [G loss: 1.004656]\n",
      "epoch:46 step:36029[D loss: 0.409826, acc: 62.50%, op_acc: 42.19%] [G loss: 1.084509]\n",
      "epoch:46 step:36030[D loss: 0.358430, acc: 73.44%, op_acc: 46.88%] [G loss: 1.199035]\n",
      "epoch:46 step:36031[D loss: 0.336528, acc: 75.78%, op_acc: 52.34%] [G loss: 1.170619]\n",
      "epoch:46 step:36032[D loss: 0.305648, acc: 85.94%, op_acc: 55.47%] [G loss: 1.066346]\n",
      "epoch:46 step:36033[D loss: 0.353721, acc: 74.22%, op_acc: 50.78%] [G loss: 1.183127]\n",
      "epoch:46 step:36034[D loss: 0.407427, acc: 67.19%, op_acc: 42.97%] [G loss: 1.142464]\n",
      "epoch:46 step:36035[D loss: 0.370330, acc: 68.75%, op_acc: 46.88%] [G loss: 1.057876]\n",
      "epoch:46 step:36036[D loss: 0.360084, acc: 68.75%, op_acc: 56.25%] [G loss: 1.114648]\n",
      "epoch:46 step:36037[D loss: 0.379754, acc: 70.31%, op_acc: 41.41%] [G loss: 1.134533]\n",
      "epoch:46 step:36038[D loss: 0.365382, acc: 71.88%, op_acc: 49.22%] [G loss: 1.063123]\n",
      "epoch:46 step:36039[D loss: 0.403616, acc: 60.94%, op_acc: 43.75%] [G loss: 1.033733]\n",
      "epoch:46 step:36040[D loss: 0.407230, acc: 67.19%, op_acc: 48.44%] [G loss: 1.151506]\n",
      "epoch:46 step:36041[D loss: 0.408702, acc: 63.28%, op_acc: 42.19%] [G loss: 1.146566]\n",
      "epoch:46 step:36042[D loss: 0.400153, acc: 70.31%, op_acc: 39.06%] [G loss: 1.160630]\n",
      "epoch:46 step:36043[D loss: 0.343937, acc: 70.31%, op_acc: 50.78%] [G loss: 1.209282]\n",
      "epoch:46 step:36044[D loss: 0.388094, acc: 70.31%, op_acc: 42.97%] [G loss: 0.970019]\n",
      "epoch:46 step:36045[D loss: 0.348021, acc: 77.34%, op_acc: 46.09%] [G loss: 1.091981]\n",
      "epoch:46 step:36046[D loss: 0.325661, acc: 82.03%, op_acc: 43.75%] [G loss: 0.894264]\n",
      "epoch:46 step:36047[D loss: 0.410200, acc: 65.62%, op_acc: 39.06%] [G loss: 0.987241]\n",
      "epoch:46 step:36048[D loss: 0.390363, acc: 61.72%, op_acc: 39.84%] [G loss: 1.011437]\n",
      "epoch:46 step:36049[D loss: 0.402331, acc: 63.28%, op_acc: 40.62%] [G loss: 0.939656]\n",
      "epoch:46 step:36050[D loss: 0.326449, acc: 78.91%, op_acc: 50.00%] [G loss: 1.165166]\n",
      "epoch:46 step:36051[D loss: 0.441285, acc: 57.81%, op_acc: 39.06%] [G loss: 0.970771]\n",
      "epoch:46 step:36052[D loss: 0.445179, acc: 60.16%, op_acc: 44.53%] [G loss: 0.995236]\n",
      "epoch:46 step:36053[D loss: 0.402459, acc: 65.62%, op_acc: 45.31%] [G loss: 0.901213]\n",
      "epoch:46 step:36054[D loss: 0.349783, acc: 72.66%, op_acc: 47.66%] [G loss: 1.102932]\n",
      "epoch:46 step:36055[D loss: 0.390352, acc: 65.62%, op_acc: 45.31%] [G loss: 1.069433]\n",
      "epoch:46 step:36056[D loss: 0.385097, acc: 63.28%, op_acc: 40.62%] [G loss: 1.105332]\n",
      "epoch:46 step:36057[D loss: 0.367365, acc: 65.62%, op_acc: 42.97%] [G loss: 1.010313]\n",
      "epoch:46 step:36058[D loss: 0.352520, acc: 68.75%, op_acc: 50.78%] [G loss: 1.032513]\n",
      "epoch:46 step:36059[D loss: 0.414976, acc: 67.97%, op_acc: 42.19%] [G loss: 0.963869]\n",
      "epoch:46 step:36060[D loss: 0.392524, acc: 68.75%, op_acc: 46.88%] [G loss: 1.002424]\n",
      "epoch:46 step:36061[D loss: 0.391104, acc: 69.53%, op_acc: 39.84%] [G loss: 0.979423]\n",
      "epoch:46 step:36062[D loss: 0.369782, acc: 67.19%, op_acc: 49.22%] [G loss: 1.017601]\n",
      "epoch:46 step:36063[D loss: 0.443384, acc: 61.72%, op_acc: 37.50%] [G loss: 1.132075]\n",
      "epoch:46 step:36064[D loss: 0.410819, acc: 63.28%, op_acc: 41.41%] [G loss: 0.997922]\n",
      "epoch:46 step:36065[D loss: 0.360813, acc: 69.53%, op_acc: 46.88%] [G loss: 1.330466]\n",
      "epoch:46 step:36066[D loss: 0.436538, acc: 64.84%, op_acc: 38.28%] [G loss: 1.219816]\n",
      "epoch:46 step:36067[D loss: 0.360453, acc: 80.47%, op_acc: 45.31%] [G loss: 1.252903]\n",
      "epoch:46 step:36068[D loss: 0.361618, acc: 74.22%, op_acc: 45.31%] [G loss: 0.864937]\n",
      "epoch:46 step:36069[D loss: 0.354125, acc: 71.88%, op_acc: 47.66%] [G loss: 0.947915]\n",
      "epoch:46 step:36070[D loss: 0.428822, acc: 58.59%, op_acc: 39.84%] [G loss: 1.016933]\n",
      "epoch:46 step:36071[D loss: 0.338258, acc: 72.66%, op_acc: 52.34%] [G loss: 0.952454]\n",
      "epoch:46 step:36072[D loss: 0.395577, acc: 62.50%, op_acc: 45.31%] [G loss: 0.818576]\n",
      "epoch:46 step:36073[D loss: 0.332342, acc: 75.78%, op_acc: 50.00%] [G loss: 1.082564]\n",
      "epoch:46 step:36074[D loss: 0.382194, acc: 71.09%, op_acc: 45.31%] [G loss: 1.128384]\n",
      "epoch:46 step:36075[D loss: 0.441819, acc: 55.47%, op_acc: 46.88%] [G loss: 1.127850]\n",
      "epoch:46 step:36076[D loss: 0.348929, acc: 77.34%, op_acc: 47.66%] [G loss: 1.025832]\n",
      "epoch:46 step:36077[D loss: 0.387765, acc: 61.72%, op_acc: 50.00%] [G loss: 0.967102]\n",
      "epoch:46 step:36078[D loss: 0.348556, acc: 71.09%, op_acc: 45.31%] [G loss: 1.022288]\n",
      "epoch:46 step:36079[D loss: 0.323839, acc: 82.03%, op_acc: 47.66%] [G loss: 1.136607]\n",
      "epoch:46 step:36080[D loss: 0.304551, acc: 81.25%, op_acc: 50.78%] [G loss: 1.283954]\n",
      "epoch:46 step:36081[D loss: 0.369177, acc: 69.53%, op_acc: 48.44%] [G loss: 1.220446]\n",
      "epoch:46 step:36082[D loss: 0.418745, acc: 61.72%, op_acc: 41.41%] [G loss: 1.018741]\n",
      "epoch:46 step:36083[D loss: 0.330341, acc: 75.78%, op_acc: 49.22%] [G loss: 1.192603]\n",
      "epoch:46 step:36084[D loss: 0.349464, acc: 71.09%, op_acc: 49.22%] [G loss: 1.140680]\n",
      "epoch:46 step:36085[D loss: 0.366089, acc: 76.56%, op_acc: 46.88%] [G loss: 1.086808]\n",
      "epoch:46 step:36086[D loss: 0.350986, acc: 75.78%, op_acc: 46.88%] [G loss: 1.189406]\n",
      "epoch:46 step:36087[D loss: 0.376452, acc: 67.19%, op_acc: 46.88%] [G loss: 1.034659]\n",
      "epoch:46 step:36088[D loss: 0.364902, acc: 64.84%, op_acc: 59.38%] [G loss: 1.020491]\n",
      "epoch:46 step:36089[D loss: 0.386708, acc: 72.66%, op_acc: 42.97%] [G loss: 1.067422]\n",
      "epoch:46 step:36090[D loss: 0.383139, acc: 74.22%, op_acc: 42.19%] [G loss: 0.805811]\n",
      "epoch:46 step:36091[D loss: 0.404156, acc: 63.28%, op_acc: 39.84%] [G loss: 0.928801]\n",
      "epoch:46 step:36092[D loss: 0.416833, acc: 62.50%, op_acc: 37.50%] [G loss: 1.186382]\n",
      "epoch:46 step:36093[D loss: 0.399750, acc: 63.28%, op_acc: 48.44%] [G loss: 1.339620]\n",
      "epoch:46 step:36094[D loss: 0.400146, acc: 60.16%, op_acc: 50.78%] [G loss: 1.109040]\n",
      "epoch:46 step:36095[D loss: 0.326221, acc: 78.91%, op_acc: 55.47%] [G loss: 1.332003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36096[D loss: 0.467591, acc: 50.00%, op_acc: 42.97%] [G loss: 1.101876]\n",
      "epoch:46 step:36097[D loss: 0.398052, acc: 66.41%, op_acc: 39.84%] [G loss: 1.215756]\n",
      "epoch:46 step:36098[D loss: 0.332419, acc: 73.44%, op_acc: 50.00%] [G loss: 1.131099]\n",
      "epoch:46 step:36099[D loss: 0.416592, acc: 64.06%, op_acc: 38.28%] [G loss: 1.361319]\n",
      "epoch:46 step:36100[D loss: 0.425623, acc: 68.75%, op_acc: 35.94%] [G loss: 1.264792]\n",
      "epoch:46 step:36101[D loss: 0.345762, acc: 73.44%, op_acc: 46.09%] [G loss: 1.265627]\n",
      "epoch:46 step:36102[D loss: 0.390332, acc: 64.84%, op_acc: 45.31%] [G loss: 1.111974]\n",
      "epoch:46 step:36103[D loss: 0.422806, acc: 60.94%, op_acc: 39.06%] [G loss: 1.321270]\n",
      "epoch:46 step:36104[D loss: 0.465918, acc: 60.94%, op_acc: 39.84%] [G loss: 1.270711]\n",
      "epoch:46 step:36105[D loss: 0.310630, acc: 78.91%, op_acc: 54.69%] [G loss: 1.393936]\n",
      "epoch:46 step:36106[D loss: 0.331760, acc: 76.56%, op_acc: 50.00%] [G loss: 1.150969]\n",
      "epoch:46 step:36107[D loss: 0.339559, acc: 75.00%, op_acc: 46.88%] [G loss: 1.316751]\n",
      "epoch:46 step:36108[D loss: 0.392433, acc: 69.53%, op_acc: 47.66%] [G loss: 1.275831]\n",
      "epoch:46 step:36109[D loss: 0.332147, acc: 75.78%, op_acc: 45.31%] [G loss: 1.133162]\n",
      "epoch:46 step:36110[D loss: 0.373379, acc: 67.97%, op_acc: 40.62%] [G loss: 1.236435]\n",
      "epoch:46 step:36111[D loss: 0.344814, acc: 75.00%, op_acc: 40.62%] [G loss: 1.288719]\n",
      "epoch:46 step:36112[D loss: 0.381602, acc: 67.97%, op_acc: 45.31%] [G loss: 1.224353]\n",
      "epoch:46 step:36113[D loss: 0.316368, acc: 78.91%, op_acc: 51.56%] [G loss: 1.366294]\n",
      "epoch:46 step:36114[D loss: 0.377050, acc: 69.53%, op_acc: 49.22%] [G loss: 1.041269]\n",
      "epoch:46 step:36115[D loss: 0.375401, acc: 71.09%, op_acc: 44.53%] [G loss: 0.701444]\n",
      "epoch:46 step:36116[D loss: 0.436887, acc: 62.50%, op_acc: 36.72%] [G loss: 1.220689]\n",
      "epoch:46 step:36117[D loss: 0.393819, acc: 66.41%, op_acc: 45.31%] [G loss: 1.157855]\n",
      "epoch:46 step:36118[D loss: 0.374922, acc: 66.41%, op_acc: 46.09%] [G loss: 1.294620]\n",
      "epoch:46 step:36119[D loss: 0.463328, acc: 57.81%, op_acc: 37.50%] [G loss: 1.381954]\n",
      "epoch:46 step:36120[D loss: 0.372783, acc: 67.19%, op_acc: 46.88%] [G loss: 1.242003]\n",
      "epoch:46 step:36121[D loss: 0.411880, acc: 59.38%, op_acc: 42.19%] [G loss: 1.080416]\n",
      "epoch:46 step:36122[D loss: 0.398748, acc: 69.53%, op_acc: 41.41%] [G loss: 1.243518]\n",
      "epoch:46 step:36123[D loss: 0.427782, acc: 64.84%, op_acc: 49.22%] [G loss: 1.040288]\n",
      "epoch:46 step:36124[D loss: 0.383749, acc: 64.06%, op_acc: 43.75%] [G loss: 1.286856]\n",
      "epoch:46 step:36125[D loss: 0.393157, acc: 72.66%, op_acc: 43.75%] [G loss: 1.435462]\n",
      "epoch:46 step:36126[D loss: 0.354955, acc: 71.88%, op_acc: 50.00%] [G loss: 1.230575]\n",
      "epoch:46 step:36127[D loss: 0.374022, acc: 67.19%, op_acc: 41.41%] [G loss: 1.089960]\n",
      "epoch:46 step:36128[D loss: 0.354663, acc: 74.22%, op_acc: 46.88%] [G loss: 1.210032]\n",
      "epoch:46 step:36129[D loss: 0.462675, acc: 60.16%, op_acc: 43.75%] [G loss: 1.108891]\n",
      "epoch:46 step:36130[D loss: 0.396261, acc: 62.50%, op_acc: 42.19%] [G loss: 1.239399]\n",
      "epoch:46 step:36131[D loss: 0.452009, acc: 57.03%, op_acc: 40.62%] [G loss: 0.960779]\n",
      "epoch:46 step:36132[D loss: 0.423572, acc: 58.59%, op_acc: 38.28%] [G loss: 1.118876]\n",
      "epoch:46 step:36133[D loss: 0.343149, acc: 72.66%, op_acc: 42.19%] [G loss: 1.219944]\n",
      "epoch:46 step:36134[D loss: 0.401248, acc: 69.53%, op_acc: 42.19%] [G loss: 1.168846]\n",
      "epoch:46 step:36135[D loss: 0.356257, acc: 68.75%, op_acc: 52.34%] [G loss: 1.115346]\n",
      "epoch:46 step:36136[D loss: 0.381265, acc: 69.53%, op_acc: 44.53%] [G loss: 1.095675]\n",
      "epoch:46 step:36137[D loss: 0.410316, acc: 54.69%, op_acc: 47.66%] [G loss: 0.996494]\n",
      "epoch:46 step:36138[D loss: 0.384344, acc: 65.62%, op_acc: 43.75%] [G loss: 1.000237]\n",
      "epoch:46 step:36139[D loss: 0.350832, acc: 70.31%, op_acc: 49.22%] [G loss: 1.183990]\n",
      "epoch:46 step:36140[D loss: 0.362132, acc: 71.88%, op_acc: 51.56%] [G loss: 1.007685]\n",
      "epoch:46 step:36141[D loss: 0.407415, acc: 64.84%, op_acc: 46.09%] [G loss: 1.011683]\n",
      "epoch:46 step:36142[D loss: 0.381551, acc: 72.66%, op_acc: 40.62%] [G loss: 1.066372]\n",
      "epoch:46 step:36143[D loss: 0.366075, acc: 70.31%, op_acc: 54.69%] [G loss: 0.927902]\n",
      "epoch:46 step:36144[D loss: 0.395825, acc: 64.84%, op_acc: 46.09%] [G loss: 0.839640]\n",
      "epoch:46 step:36145[D loss: 0.349058, acc: 78.91%, op_acc: 49.22%] [G loss: 1.016294]\n",
      "epoch:46 step:36146[D loss: 0.430370, acc: 55.47%, op_acc: 42.19%] [G loss: 1.052430]\n",
      "epoch:46 step:36147[D loss: 0.369274, acc: 68.75%, op_acc: 41.41%] [G loss: 0.949869]\n",
      "epoch:46 step:36148[D loss: 0.370407, acc: 74.22%, op_acc: 46.88%] [G loss: 1.237481]\n",
      "epoch:46 step:36149[D loss: 0.436612, acc: 55.47%, op_acc: 44.53%] [G loss: 1.014827]\n",
      "epoch:46 step:36150[D loss: 0.348305, acc: 73.44%, op_acc: 46.88%] [G loss: 1.002094]\n",
      "epoch:46 step:36151[D loss: 0.353620, acc: 72.66%, op_acc: 49.22%] [G loss: 1.109913]\n",
      "epoch:46 step:36152[D loss: 0.332365, acc: 75.00%, op_acc: 44.53%] [G loss: 1.221411]\n",
      "epoch:46 step:36153[D loss: 0.351334, acc: 77.34%, op_acc: 48.44%] [G loss: 1.280109]\n",
      "epoch:46 step:36154[D loss: 0.398656, acc: 63.28%, op_acc: 53.91%] [G loss: 1.051569]\n",
      "epoch:46 step:36155[D loss: 0.428802, acc: 64.06%, op_acc: 45.31%] [G loss: 1.173773]\n",
      "epoch:46 step:36156[D loss: 0.353126, acc: 67.97%, op_acc: 46.88%] [G loss: 1.388450]\n",
      "epoch:46 step:36157[D loss: 0.366812, acc: 73.44%, op_acc: 39.84%] [G loss: 1.325883]\n",
      "epoch:46 step:36158[D loss: 0.371238, acc: 73.44%, op_acc: 46.09%] [G loss: 1.182650]\n",
      "epoch:46 step:36159[D loss: 0.355714, acc: 67.19%, op_acc: 50.78%] [G loss: 1.176207]\n",
      "epoch:46 step:36160[D loss: 0.371090, acc: 73.44%, op_acc: 42.97%] [G loss: 1.425480]\n",
      "epoch:46 step:36161[D loss: 0.402102, acc: 66.41%, op_acc: 50.00%] [G loss: 1.164442]\n",
      "epoch:46 step:36162[D loss: 0.428848, acc: 58.59%, op_acc: 40.62%] [G loss: 1.113242]\n",
      "epoch:46 step:36163[D loss: 0.361200, acc: 71.88%, op_acc: 50.00%] [G loss: 1.232987]\n",
      "epoch:46 step:36164[D loss: 0.394490, acc: 61.72%, op_acc: 46.09%] [G loss: 1.273947]\n",
      "epoch:46 step:36165[D loss: 0.351272, acc: 71.88%, op_acc: 50.00%] [G loss: 1.243313]\n",
      "epoch:46 step:36166[D loss: 0.374264, acc: 67.97%, op_acc: 43.75%] [G loss: 1.525636]\n",
      "epoch:46 step:36167[D loss: 0.378225, acc: 71.88%, op_acc: 46.09%] [G loss: 1.118625]\n",
      "epoch:46 step:36168[D loss: 0.384718, acc: 67.19%, op_acc: 42.19%] [G loss: 1.122662]\n",
      "epoch:46 step:36169[D loss: 0.383980, acc: 67.19%, op_acc: 49.22%] [G loss: 1.241648]\n",
      "epoch:46 step:36170[D loss: 0.379319, acc: 67.97%, op_acc: 48.44%] [G loss: 1.120781]\n",
      "epoch:46 step:36171[D loss: 0.369723, acc: 71.09%, op_acc: 48.44%] [G loss: 1.011672]\n",
      "epoch:46 step:36172[D loss: 0.311460, acc: 84.38%, op_acc: 44.53%] [G loss: 1.024050]\n",
      "epoch:46 step:36173[D loss: 0.354393, acc: 72.66%, op_acc: 42.97%] [G loss: 1.152798]\n",
      "epoch:46 step:36174[D loss: 0.415941, acc: 56.25%, op_acc: 46.88%] [G loss: 1.016891]\n",
      "epoch:46 step:36175[D loss: 0.318540, acc: 78.12%, op_acc: 47.66%] [G loss: 1.072796]\n",
      "epoch:46 step:36176[D loss: 0.388926, acc: 71.09%, op_acc: 46.09%] [G loss: 1.251385]\n",
      "epoch:46 step:36177[D loss: 0.349136, acc: 69.53%, op_acc: 48.44%] [G loss: 1.230433]\n",
      "epoch:46 step:36178[D loss: 0.399515, acc: 64.06%, op_acc: 48.44%] [G loss: 1.253355]\n",
      "epoch:46 step:36179[D loss: 0.386421, acc: 68.75%, op_acc: 45.31%] [G loss: 1.174132]\n",
      "epoch:46 step:36180[D loss: 0.314881, acc: 80.47%, op_acc: 45.31%] [G loss: 1.264150]\n",
      "epoch:46 step:36181[D loss: 0.395670, acc: 69.53%, op_acc: 49.22%] [G loss: 1.147931]\n",
      "epoch:46 step:36182[D loss: 0.399379, acc: 67.19%, op_acc: 42.19%] [G loss: 1.242661]\n",
      "epoch:46 step:36183[D loss: 0.382557, acc: 69.53%, op_acc: 46.88%] [G loss: 1.041852]\n",
      "epoch:46 step:36184[D loss: 0.397037, acc: 64.84%, op_acc: 42.19%] [G loss: 1.106369]\n",
      "epoch:46 step:36185[D loss: 0.358847, acc: 77.34%, op_acc: 39.84%] [G loss: 1.110198]\n",
      "epoch:46 step:36186[D loss: 0.423258, acc: 64.84%, op_acc: 43.75%] [G loss: 1.179163]\n",
      "epoch:46 step:36187[D loss: 0.328201, acc: 78.12%, op_acc: 48.44%] [G loss: 1.124120]\n",
      "epoch:46 step:36188[D loss: 0.326462, acc: 78.91%, op_acc: 53.91%] [G loss: 1.259415]\n",
      "epoch:46 step:36189[D loss: 0.325365, acc: 75.00%, op_acc: 46.88%] [G loss: 1.238655]\n",
      "epoch:46 step:36190[D loss: 0.306390, acc: 79.69%, op_acc: 50.00%] [G loss: 1.416151]\n",
      "epoch:46 step:36191[D loss: 0.377801, acc: 65.62%, op_acc: 48.44%] [G loss: 1.208320]\n",
      "epoch:46 step:36192[D loss: 0.338309, acc: 78.12%, op_acc: 41.41%] [G loss: 1.102493]\n",
      "epoch:46 step:36193[D loss: 0.356604, acc: 71.88%, op_acc: 54.69%] [G loss: 1.341028]\n",
      "epoch:46 step:36194[D loss: 0.399307, acc: 65.62%, op_acc: 45.31%] [G loss: 1.247620]\n",
      "epoch:46 step:36195[D loss: 0.389726, acc: 64.06%, op_acc: 42.97%] [G loss: 1.165460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36196[D loss: 0.371465, acc: 69.53%, op_acc: 55.47%] [G loss: 1.078244]\n",
      "epoch:46 step:36197[D loss: 0.465269, acc: 53.12%, op_acc: 41.41%] [G loss: 1.237340]\n",
      "epoch:46 step:36198[D loss: 0.360426, acc: 71.09%, op_acc: 47.66%] [G loss: 1.204254]\n",
      "epoch:46 step:36199[D loss: 0.349602, acc: 74.22%, op_acc: 46.09%] [G loss: 1.330986]\n",
      "epoch:46 step:36200[D loss: 0.395435, acc: 69.53%, op_acc: 45.31%] [G loss: 1.263070]\n",
      "epoch:46 step:36201[D loss: 0.374077, acc: 66.41%, op_acc: 45.31%] [G loss: 1.099748]\n",
      "epoch:46 step:36202[D loss: 0.342037, acc: 73.44%, op_acc: 45.31%] [G loss: 1.309468]\n",
      "epoch:46 step:36203[D loss: 0.392733, acc: 67.19%, op_acc: 46.88%] [G loss: 1.045125]\n",
      "epoch:46 step:36204[D loss: 0.443342, acc: 57.81%, op_acc: 38.28%] [G loss: 1.253067]\n",
      "epoch:46 step:36205[D loss: 0.407213, acc: 66.41%, op_acc: 42.19%] [G loss: 1.418349]\n",
      "epoch:46 step:36206[D loss: 0.393529, acc: 64.84%, op_acc: 42.97%] [G loss: 1.265787]\n",
      "epoch:46 step:36207[D loss: 0.438377, acc: 59.38%, op_acc: 40.62%] [G loss: 1.223407]\n",
      "epoch:46 step:36208[D loss: 0.442590, acc: 62.50%, op_acc: 39.06%] [G loss: 1.322172]\n",
      "epoch:46 step:36209[D loss: 0.334524, acc: 75.00%, op_acc: 47.66%] [G loss: 1.482860]\n",
      "epoch:46 step:36210[D loss: 0.380384, acc: 69.53%, op_acc: 44.53%] [G loss: 1.256833]\n",
      "epoch:46 step:36211[D loss: 0.379086, acc: 71.88%, op_acc: 49.22%] [G loss: 1.428852]\n",
      "epoch:46 step:36212[D loss: 0.410233, acc: 63.28%, op_acc: 39.06%] [G loss: 1.435948]\n",
      "epoch:46 step:36213[D loss: 0.396570, acc: 60.94%, op_acc: 50.00%] [G loss: 1.320019]\n",
      "epoch:46 step:36214[D loss: 0.413663, acc: 57.81%, op_acc: 45.31%] [G loss: 0.935840]\n",
      "epoch:46 step:36215[D loss: 0.399198, acc: 67.97%, op_acc: 45.31%] [G loss: 1.077399]\n",
      "epoch:46 step:36216[D loss: 0.344864, acc: 73.44%, op_acc: 46.88%] [G loss: 0.909429]\n",
      "epoch:46 step:36217[D loss: 0.453156, acc: 56.25%, op_acc: 45.31%] [G loss: 1.112741]\n",
      "epoch:46 step:36218[D loss: 0.473967, acc: 57.81%, op_acc: 33.59%] [G loss: 1.444319]\n",
      "epoch:46 step:36219[D loss: 0.433413, acc: 62.50%, op_acc: 39.84%] [G loss: 1.097651]\n",
      "epoch:46 step:36220[D loss: 0.361642, acc: 74.22%, op_acc: 40.62%] [G loss: 0.961879]\n",
      "epoch:46 step:36221[D loss: 0.439498, acc: 57.03%, op_acc: 38.28%] [G loss: 1.168976]\n",
      "epoch:46 step:36222[D loss: 0.455866, acc: 47.66%, op_acc: 42.97%] [G loss: 1.267219]\n",
      "epoch:46 step:36223[D loss: 0.449902, acc: 59.38%, op_acc: 32.03%] [G loss: 1.144435]\n",
      "epoch:46 step:36224[D loss: 0.352000, acc: 76.56%, op_acc: 44.53%] [G loss: 1.445694]\n",
      "epoch:46 step:36225[D loss: 0.425524, acc: 64.84%, op_acc: 45.31%] [G loss: 0.983081]\n",
      "epoch:46 step:36226[D loss: 0.433638, acc: 61.72%, op_acc: 39.06%] [G loss: 1.027814]\n",
      "epoch:46 step:36227[D loss: 0.350075, acc: 75.78%, op_acc: 42.19%] [G loss: 1.377096]\n",
      "epoch:46 step:36228[D loss: 0.385861, acc: 68.75%, op_acc: 47.66%] [G loss: 1.254426]\n",
      "epoch:46 step:36229[D loss: 0.374288, acc: 71.09%, op_acc: 45.31%] [G loss: 1.333756]\n",
      "epoch:46 step:36230[D loss: 0.341309, acc: 78.12%, op_acc: 53.12%] [G loss: 1.104872]\n",
      "epoch:46 step:36231[D loss: 0.397965, acc: 68.75%, op_acc: 46.88%] [G loss: 1.121388]\n",
      "epoch:46 step:36232[D loss: 0.435708, acc: 61.72%, op_acc: 46.09%] [G loss: 1.013969]\n",
      "epoch:46 step:36233[D loss: 0.405419, acc: 62.50%, op_acc: 44.53%] [G loss: 1.146218]\n",
      "epoch:46 step:36234[D loss: 0.454839, acc: 54.69%, op_acc: 37.50%] [G loss: 1.053662]\n",
      "epoch:46 step:36235[D loss: 0.419406, acc: 69.53%, op_acc: 41.41%] [G loss: 1.106265]\n",
      "epoch:46 step:36236[D loss: 0.407951, acc: 60.94%, op_acc: 47.66%] [G loss: 1.088400]\n",
      "epoch:46 step:36237[D loss: 0.398296, acc: 69.53%, op_acc: 48.44%] [G loss: 0.992878]\n",
      "epoch:46 step:36238[D loss: 0.425061, acc: 55.47%, op_acc: 39.06%] [G loss: 1.033420]\n",
      "epoch:46 step:36239[D loss: 0.342157, acc: 73.44%, op_acc: 44.53%] [G loss: 1.148887]\n",
      "epoch:46 step:36240[D loss: 0.362756, acc: 72.66%, op_acc: 43.75%] [G loss: 1.110678]\n",
      "epoch:46 step:36241[D loss: 0.477688, acc: 57.03%, op_acc: 36.72%] [G loss: 1.180214]\n",
      "epoch:46 step:36242[D loss: 0.358737, acc: 75.78%, op_acc: 44.53%] [G loss: 1.214695]\n",
      "epoch:46 step:36243[D loss: 0.475935, acc: 60.16%, op_acc: 36.72%] [G loss: 1.066163]\n",
      "epoch:46 step:36244[D loss: 0.399316, acc: 61.72%, op_acc: 39.84%] [G loss: 0.992660]\n",
      "epoch:46 step:36245[D loss: 0.423180, acc: 64.84%, op_acc: 43.75%] [G loss: 1.139277]\n",
      "epoch:46 step:36246[D loss: 0.412866, acc: 62.50%, op_acc: 43.75%] [G loss: 1.117063]\n",
      "epoch:46 step:36247[D loss: 0.452215, acc: 53.91%, op_acc: 46.09%] [G loss: 1.149030]\n",
      "epoch:46 step:36248[D loss: 0.363818, acc: 69.53%, op_acc: 43.75%] [G loss: 1.044322]\n",
      "epoch:46 step:36249[D loss: 0.427849, acc: 58.59%, op_acc: 40.62%] [G loss: 1.020108]\n",
      "epoch:46 step:36250[D loss: 0.398253, acc: 67.97%, op_acc: 33.59%] [G loss: 1.075550]\n",
      "epoch:46 step:36251[D loss: 0.444511, acc: 55.47%, op_acc: 39.06%] [G loss: 1.008432]\n",
      "epoch:46 step:36252[D loss: 0.398014, acc: 64.84%, op_acc: 44.53%] [G loss: 1.113957]\n",
      "epoch:46 step:36253[D loss: 0.363759, acc: 66.41%, op_acc: 50.78%] [G loss: 1.180068]\n",
      "epoch:46 step:36254[D loss: 0.386479, acc: 71.09%, op_acc: 47.66%] [G loss: 1.180383]\n",
      "epoch:46 step:36255[D loss: 0.385888, acc: 69.53%, op_acc: 43.75%] [G loss: 1.273375]\n",
      "epoch:46 step:36256[D loss: 0.403668, acc: 64.06%, op_acc: 48.44%] [G loss: 1.104887]\n",
      "epoch:46 step:36257[D loss: 0.442900, acc: 54.69%, op_acc: 39.84%] [G loss: 1.134205]\n",
      "epoch:46 step:36258[D loss: 0.400492, acc: 64.06%, op_acc: 53.12%] [G loss: 1.121368]\n",
      "epoch:46 step:36259[D loss: 0.391372, acc: 66.41%, op_acc: 43.75%] [G loss: 0.998302]\n",
      "epoch:46 step:36260[D loss: 0.389885, acc: 61.72%, op_acc: 46.88%] [G loss: 0.899246]\n",
      "epoch:46 step:36261[D loss: 0.422204, acc: 58.59%, op_acc: 42.19%] [G loss: 1.029029]\n",
      "epoch:46 step:36262[D loss: 0.406207, acc: 64.06%, op_acc: 39.84%] [G loss: 1.111299]\n",
      "epoch:46 step:36263[D loss: 0.355654, acc: 71.09%, op_acc: 40.62%] [G loss: 1.051723]\n",
      "epoch:46 step:36264[D loss: 0.417714, acc: 64.06%, op_acc: 42.97%] [G loss: 1.024115]\n",
      "epoch:46 step:36265[D loss: 0.424687, acc: 57.81%, op_acc: 39.06%] [G loss: 1.138525]\n",
      "epoch:46 step:36266[D loss: 0.400787, acc: 64.84%, op_acc: 41.41%] [G loss: 1.095807]\n",
      "epoch:46 step:36267[D loss: 0.403632, acc: 63.28%, op_acc: 42.97%] [G loss: 0.807464]\n",
      "epoch:46 step:36268[D loss: 0.418681, acc: 59.38%, op_acc: 35.16%] [G loss: 0.935763]\n",
      "epoch:46 step:36269[D loss: 0.371218, acc: 72.66%, op_acc: 46.88%] [G loss: 1.063412]\n",
      "epoch:46 step:36270[D loss: 0.381089, acc: 67.19%, op_acc: 42.97%] [G loss: 1.089990]\n",
      "epoch:46 step:36271[D loss: 0.422854, acc: 60.94%, op_acc: 47.66%] [G loss: 1.064425]\n",
      "epoch:46 step:36272[D loss: 0.376538, acc: 71.88%, op_acc: 52.34%] [G loss: 1.220664]\n",
      "epoch:46 step:36273[D loss: 0.342466, acc: 75.00%, op_acc: 49.22%] [G loss: 1.215780]\n",
      "epoch:46 step:36274[D loss: 0.393363, acc: 67.19%, op_acc: 45.31%] [G loss: 1.126945]\n",
      "epoch:46 step:36275[D loss: 0.405370, acc: 62.50%, op_acc: 47.66%] [G loss: 0.955256]\n",
      "epoch:46 step:36276[D loss: 0.398590, acc: 66.41%, op_acc: 46.09%] [G loss: 1.040499]\n",
      "epoch:46 step:36277[D loss: 0.366246, acc: 71.88%, op_acc: 46.88%] [G loss: 1.129617]\n",
      "epoch:46 step:36278[D loss: 0.383793, acc: 67.97%, op_acc: 41.41%] [G loss: 1.135845]\n",
      "epoch:46 step:36279[D loss: 0.357072, acc: 71.09%, op_acc: 45.31%] [G loss: 1.156567]\n",
      "epoch:46 step:36280[D loss: 0.370680, acc: 71.09%, op_acc: 51.56%] [G loss: 1.020914]\n",
      "epoch:46 step:36281[D loss: 0.411880, acc: 65.62%, op_acc: 42.19%] [G loss: 1.118129]\n",
      "epoch:46 step:36282[D loss: 0.363538, acc: 67.19%, op_acc: 43.75%] [G loss: 1.176222]\n",
      "epoch:46 step:36283[D loss: 0.363891, acc: 75.00%, op_acc: 35.94%] [G loss: 1.052105]\n",
      "epoch:46 step:36284[D loss: 0.403282, acc: 67.19%, op_acc: 41.41%] [G loss: 1.045892]\n",
      "epoch:46 step:36285[D loss: 0.396190, acc: 71.09%, op_acc: 42.97%] [G loss: 1.097515]\n",
      "epoch:46 step:36286[D loss: 0.529313, acc: 45.31%, op_acc: 41.41%] [G loss: 0.969782]\n",
      "epoch:46 step:36287[D loss: 0.389316, acc: 67.97%, op_acc: 43.75%] [G loss: 1.116258]\n",
      "epoch:46 step:36288[D loss: 0.423706, acc: 61.72%, op_acc: 44.53%] [G loss: 1.098599]\n",
      "epoch:46 step:36289[D loss: 0.392640, acc: 64.84%, op_acc: 47.66%] [G loss: 1.110480]\n",
      "epoch:46 step:36290[D loss: 0.454450, acc: 54.69%, op_acc: 39.84%] [G loss: 1.196733]\n",
      "epoch:46 step:36291[D loss: 0.393925, acc: 63.28%, op_acc: 40.62%] [G loss: 1.042862]\n",
      "epoch:46 step:36292[D loss: 0.375170, acc: 60.94%, op_acc: 46.09%] [G loss: 0.995080]\n",
      "epoch:46 step:36293[D loss: 0.423426, acc: 67.97%, op_acc: 35.94%] [G loss: 1.104150]\n",
      "epoch:46 step:36294[D loss: 0.352094, acc: 78.91%, op_acc: 42.97%] [G loss: 1.122856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36295[D loss: 0.378779, acc: 69.53%, op_acc: 42.97%] [G loss: 1.180668]\n",
      "epoch:46 step:36296[D loss: 0.375090, acc: 63.28%, op_acc: 49.22%] [G loss: 1.257047]\n",
      "epoch:46 step:36297[D loss: 0.339634, acc: 71.88%, op_acc: 46.88%] [G loss: 1.145132]\n",
      "epoch:46 step:36298[D loss: 0.432606, acc: 60.16%, op_acc: 41.41%] [G loss: 1.114443]\n",
      "epoch:46 step:36299[D loss: 0.408519, acc: 71.09%, op_acc: 43.75%] [G loss: 1.138477]\n",
      "epoch:46 step:36300[D loss: 0.396269, acc: 63.28%, op_acc: 47.66%] [G loss: 1.252514]\n",
      "epoch:46 step:36301[D loss: 0.402782, acc: 64.06%, op_acc: 48.44%] [G loss: 1.026174]\n",
      "epoch:46 step:36302[D loss: 0.390653, acc: 62.50%, op_acc: 47.66%] [G loss: 1.025525]\n",
      "epoch:46 step:36303[D loss: 0.333016, acc: 75.00%, op_acc: 50.00%] [G loss: 1.027970]\n",
      "epoch:46 step:36304[D loss: 0.352110, acc: 76.56%, op_acc: 48.44%] [G loss: 1.336892]\n",
      "epoch:46 step:36305[D loss: 0.408070, acc: 61.72%, op_acc: 47.66%] [G loss: 1.373214]\n",
      "epoch:46 step:36306[D loss: 0.356353, acc: 71.88%, op_acc: 48.44%] [G loss: 1.121749]\n",
      "epoch:46 step:36307[D loss: 0.338576, acc: 75.00%, op_acc: 48.44%] [G loss: 1.227824]\n",
      "epoch:46 step:36308[D loss: 0.382837, acc: 71.88%, op_acc: 43.75%] [G loss: 1.264665]\n",
      "epoch:46 step:36309[D loss: 0.372834, acc: 62.50%, op_acc: 48.44%] [G loss: 1.335093]\n",
      "epoch:46 step:36310[D loss: 0.366620, acc: 73.44%, op_acc: 42.97%] [G loss: 1.232539]\n",
      "epoch:46 step:36311[D loss: 0.379899, acc: 67.97%, op_acc: 45.31%] [G loss: 1.047177]\n",
      "epoch:46 step:36312[D loss: 0.385261, acc: 65.62%, op_acc: 45.31%] [G loss: 1.231125]\n",
      "epoch:46 step:36313[D loss: 0.477266, acc: 47.66%, op_acc: 43.75%] [G loss: 1.071332]\n",
      "epoch:46 step:36314[D loss: 0.392607, acc: 67.19%, op_acc: 42.19%] [G loss: 1.190765]\n",
      "epoch:46 step:36315[D loss: 0.407757, acc: 65.62%, op_acc: 35.94%] [G loss: 1.294357]\n",
      "epoch:46 step:36316[D loss: 0.401403, acc: 67.19%, op_acc: 47.66%] [G loss: 1.220205]\n",
      "epoch:46 step:36317[D loss: 0.399115, acc: 64.06%, op_acc: 46.09%] [G loss: 1.001721]\n",
      "epoch:46 step:36318[D loss: 0.363263, acc: 73.44%, op_acc: 50.00%] [G loss: 1.133899]\n",
      "epoch:46 step:36319[D loss: 0.390372, acc: 61.72%, op_acc: 44.53%] [G loss: 1.129783]\n",
      "epoch:46 step:36320[D loss: 0.447110, acc: 65.62%, op_acc: 40.62%] [G loss: 1.222826]\n",
      "epoch:46 step:36321[D loss: 0.387922, acc: 71.88%, op_acc: 37.50%] [G loss: 1.182961]\n",
      "epoch:46 step:36322[D loss: 0.322770, acc: 82.03%, op_acc: 50.78%] [G loss: 1.371420]\n",
      "epoch:46 step:36323[D loss: 0.404950, acc: 64.06%, op_acc: 46.88%] [G loss: 1.082423]\n",
      "epoch:46 step:36324[D loss: 0.442620, acc: 57.81%, op_acc: 41.41%] [G loss: 1.190517]\n",
      "epoch:46 step:36325[D loss: 0.381105, acc: 68.75%, op_acc: 49.22%] [G loss: 1.116349]\n",
      "epoch:46 step:36326[D loss: 0.336285, acc: 75.78%, op_acc: 47.66%] [G loss: 1.182472]\n",
      "epoch:46 step:36327[D loss: 0.375820, acc: 66.41%, op_acc: 41.41%] [G loss: 1.399086]\n",
      "epoch:46 step:36328[D loss: 0.380619, acc: 70.31%, op_acc: 39.06%] [G loss: 1.286631]\n",
      "epoch:46 step:36329[D loss: 0.328787, acc: 77.34%, op_acc: 53.91%] [G loss: 1.173624]\n",
      "epoch:46 step:36330[D loss: 0.358120, acc: 68.75%, op_acc: 53.91%] [G loss: 1.365827]\n",
      "epoch:46 step:36331[D loss: 0.392531, acc: 65.62%, op_acc: 46.09%] [G loss: 1.127824]\n",
      "epoch:46 step:36332[D loss: 0.397527, acc: 65.62%, op_acc: 42.19%] [G loss: 1.085807]\n",
      "epoch:46 step:36333[D loss: 0.348447, acc: 73.44%, op_acc: 42.97%] [G loss: 1.069034]\n",
      "epoch:46 step:36334[D loss: 0.358815, acc: 64.84%, op_acc: 52.34%] [G loss: 1.259137]\n",
      "epoch:46 step:36335[D loss: 0.352203, acc: 70.31%, op_acc: 47.66%] [G loss: 1.184255]\n",
      "epoch:46 step:36336[D loss: 0.391590, acc: 61.72%, op_acc: 55.47%] [G loss: 1.040899]\n",
      "epoch:46 step:36337[D loss: 0.354765, acc: 68.75%, op_acc: 45.31%] [G loss: 1.330632]\n",
      "epoch:46 step:36338[D loss: 0.372377, acc: 68.75%, op_acc: 46.09%] [G loss: 1.082918]\n",
      "epoch:46 step:36339[D loss: 0.396836, acc: 65.62%, op_acc: 45.31%] [G loss: 1.178527]\n",
      "epoch:46 step:36340[D loss: 0.403771, acc: 63.28%, op_acc: 45.31%] [G loss: 1.241138]\n",
      "epoch:46 step:36341[D loss: 0.375604, acc: 70.31%, op_acc: 45.31%] [G loss: 1.025327]\n",
      "epoch:46 step:36342[D loss: 0.431315, acc: 60.16%, op_acc: 42.97%] [G loss: 1.179631]\n",
      "epoch:46 step:36343[D loss: 0.393479, acc: 66.41%, op_acc: 39.84%] [G loss: 1.047971]\n",
      "epoch:46 step:36344[D loss: 0.411402, acc: 59.38%, op_acc: 42.19%] [G loss: 0.991714]\n",
      "epoch:46 step:36345[D loss: 0.375751, acc: 67.19%, op_acc: 42.19%] [G loss: 1.105585]\n",
      "epoch:46 step:36346[D loss: 0.414118, acc: 65.62%, op_acc: 39.06%] [G loss: 1.110157]\n",
      "epoch:46 step:36347[D loss: 0.395139, acc: 62.50%, op_acc: 52.34%] [G loss: 1.239265]\n",
      "epoch:46 step:36348[D loss: 0.336180, acc: 74.22%, op_acc: 50.78%] [G loss: 0.979419]\n",
      "epoch:46 step:36349[D loss: 0.444226, acc: 52.34%, op_acc: 38.28%] [G loss: 0.980825]\n",
      "epoch:46 step:36350[D loss: 0.435935, acc: 63.28%, op_acc: 35.94%] [G loss: 0.887672]\n",
      "epoch:46 step:36351[D loss: 0.433970, acc: 58.59%, op_acc: 42.97%] [G loss: 1.046012]\n",
      "epoch:46 step:36352[D loss: 0.409399, acc: 65.62%, op_acc: 43.75%] [G loss: 1.015753]\n",
      "epoch:46 step:36353[D loss: 0.405763, acc: 65.62%, op_acc: 42.19%] [G loss: 1.168147]\n",
      "epoch:46 step:36354[D loss: 0.368718, acc: 71.09%, op_acc: 46.09%] [G loss: 1.061109]\n",
      "epoch:46 step:36355[D loss: 0.406831, acc: 64.84%, op_acc: 42.19%] [G loss: 1.111876]\n",
      "epoch:46 step:36356[D loss: 0.401748, acc: 61.72%, op_acc: 42.97%] [G loss: 1.181504]\n",
      "epoch:46 step:36357[D loss: 0.421900, acc: 57.03%, op_acc: 47.66%] [G loss: 1.152080]\n",
      "epoch:46 step:36358[D loss: 0.388379, acc: 61.72%, op_acc: 47.66%] [G loss: 0.935377]\n",
      "epoch:46 step:36359[D loss: 0.409832, acc: 61.72%, op_acc: 42.97%] [G loss: 1.002171]\n",
      "epoch:46 step:36360[D loss: 0.390383, acc: 69.53%, op_acc: 50.00%] [G loss: 1.151852]\n",
      "epoch:46 step:36361[D loss: 0.409216, acc: 64.84%, op_acc: 45.31%] [G loss: 0.995179]\n",
      "epoch:46 step:36362[D loss: 0.473466, acc: 60.16%, op_acc: 39.06%] [G loss: 0.887232]\n",
      "epoch:46 step:36363[D loss: 0.506979, acc: 50.00%, op_acc: 35.16%] [G loss: 1.052835]\n",
      "epoch:46 step:36364[D loss: 0.344927, acc: 73.44%, op_acc: 46.88%] [G loss: 1.364599]\n",
      "epoch:46 step:36365[D loss: 0.416792, acc: 63.28%, op_acc: 46.88%] [G loss: 1.012366]\n",
      "epoch:46 step:36366[D loss: 0.373370, acc: 64.06%, op_acc: 48.44%] [G loss: 0.968726]\n",
      "epoch:46 step:36367[D loss: 0.341889, acc: 72.66%, op_acc: 39.06%] [G loss: 1.272931]\n",
      "epoch:46 step:36368[D loss: 0.347601, acc: 71.88%, op_acc: 53.91%] [G loss: 1.180952]\n",
      "epoch:46 step:36369[D loss: 0.358894, acc: 69.53%, op_acc: 46.09%] [G loss: 1.164844]\n",
      "epoch:46 step:36370[D loss: 0.419692, acc: 61.72%, op_acc: 35.94%] [G loss: 1.180007]\n",
      "epoch:46 step:36371[D loss: 0.365224, acc: 68.75%, op_acc: 45.31%] [G loss: 1.133903]\n",
      "epoch:46 step:36372[D loss: 0.371059, acc: 75.00%, op_acc: 49.22%] [G loss: 1.161046]\n",
      "epoch:46 step:36373[D loss: 0.457238, acc: 58.59%, op_acc: 36.72%] [G loss: 1.097922]\n",
      "epoch:46 step:36374[D loss: 0.298478, acc: 85.16%, op_acc: 52.34%] [G loss: 1.453067]\n",
      "epoch:46 step:36375[D loss: 0.327947, acc: 81.25%, op_acc: 44.53%] [G loss: 0.997807]\n",
      "epoch:46 step:36376[D loss: 0.453143, acc: 50.78%, op_acc: 45.31%] [G loss: 1.258549]\n",
      "epoch:46 step:36377[D loss: 0.400798, acc: 62.50%, op_acc: 48.44%] [G loss: 1.065208]\n",
      "epoch:46 step:36378[D loss: 0.344807, acc: 68.75%, op_acc: 49.22%] [G loss: 1.049245]\n",
      "epoch:46 step:36379[D loss: 0.416577, acc: 65.62%, op_acc: 40.62%] [G loss: 0.976196]\n",
      "epoch:46 step:36380[D loss: 0.380266, acc: 67.97%, op_acc: 46.88%] [G loss: 1.163455]\n",
      "epoch:46 step:36381[D loss: 0.422798, acc: 62.50%, op_acc: 48.44%] [G loss: 1.172079]\n",
      "epoch:46 step:36382[D loss: 0.360933, acc: 71.09%, op_acc: 46.88%] [G loss: 1.145783]\n",
      "epoch:46 step:36383[D loss: 0.416275, acc: 52.34%, op_acc: 42.97%] [G loss: 1.127358]\n",
      "epoch:46 step:36384[D loss: 0.336488, acc: 75.00%, op_acc: 52.34%] [G loss: 1.042556]\n",
      "epoch:46 step:36385[D loss: 0.350333, acc: 71.88%, op_acc: 46.88%] [G loss: 1.283432]\n",
      "epoch:46 step:36386[D loss: 0.310429, acc: 81.25%, op_acc: 58.59%] [G loss: 1.242182]\n",
      "epoch:46 step:36387[D loss: 0.406839, acc: 69.53%, op_acc: 39.06%] [G loss: 0.968395]\n",
      "epoch:46 step:36388[D loss: 0.408907, acc: 64.06%, op_acc: 41.41%] [G loss: 1.133398]\n",
      "epoch:46 step:36389[D loss: 0.377241, acc: 67.97%, op_acc: 46.09%] [G loss: 1.133748]\n",
      "epoch:46 step:36390[D loss: 0.439040, acc: 55.47%, op_acc: 44.53%] [G loss: 0.853792]\n",
      "epoch:46 step:36391[D loss: 0.390725, acc: 67.19%, op_acc: 43.75%] [G loss: 0.906619]\n",
      "epoch:46 step:36392[D loss: 0.351724, acc: 77.34%, op_acc: 47.66%] [G loss: 1.058108]\n",
      "epoch:46 step:36393[D loss: 0.377965, acc: 71.09%, op_acc: 42.97%] [G loss: 1.032574]\n",
      "epoch:46 step:36394[D loss: 0.452998, acc: 59.38%, op_acc: 44.53%] [G loss: 1.123164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36395[D loss: 0.317685, acc: 75.00%, op_acc: 54.69%] [G loss: 1.185286]\n",
      "epoch:46 step:36396[D loss: 0.311191, acc: 80.47%, op_acc: 50.78%] [G loss: 1.214312]\n",
      "epoch:46 step:36397[D loss: 0.384732, acc: 68.75%, op_acc: 45.31%] [G loss: 0.902817]\n",
      "epoch:46 step:36398[D loss: 0.432407, acc: 63.28%, op_acc: 38.28%] [G loss: 1.137069]\n",
      "epoch:46 step:36399[D loss: 0.351609, acc: 67.19%, op_acc: 48.44%] [G loss: 0.974604]\n",
      "epoch:46 step:36400[D loss: 0.436375, acc: 59.38%, op_acc: 43.75%] [G loss: 1.023701]\n",
      "epoch:46 step:36401[D loss: 0.356479, acc: 69.53%, op_acc: 48.44%] [G loss: 0.912309]\n",
      "epoch:46 step:36402[D loss: 0.409021, acc: 67.19%, op_acc: 46.09%] [G loss: 1.216014]\n",
      "epoch:46 step:36403[D loss: 0.393618, acc: 69.53%, op_acc: 41.41%] [G loss: 0.934351]\n",
      "epoch:46 step:36404[D loss: 0.387030, acc: 66.41%, op_acc: 45.31%] [G loss: 0.877524]\n",
      "epoch:46 step:36405[D loss: 0.371980, acc: 69.53%, op_acc: 43.75%] [G loss: 1.275676]\n",
      "epoch:46 step:36406[D loss: 0.417998, acc: 64.06%, op_acc: 34.38%] [G loss: 1.058647]\n",
      "epoch:46 step:36407[D loss: 0.431889, acc: 66.41%, op_acc: 41.41%] [G loss: 1.126891]\n",
      "epoch:46 step:36408[D loss: 0.395269, acc: 63.28%, op_acc: 47.66%] [G loss: 0.953250]\n",
      "epoch:46 step:36409[D loss: 0.403794, acc: 64.84%, op_acc: 41.41%] [G loss: 0.954408]\n",
      "epoch:46 step:36410[D loss: 0.364219, acc: 72.66%, op_acc: 47.66%] [G loss: 1.209000]\n",
      "epoch:46 step:36411[D loss: 0.451173, acc: 64.06%, op_acc: 43.75%] [G loss: 1.156526]\n",
      "epoch:46 step:36412[D loss: 0.336708, acc: 75.78%, op_acc: 46.88%] [G loss: 1.055242]\n",
      "epoch:46 step:36413[D loss: 0.402739, acc: 66.41%, op_acc: 44.53%] [G loss: 1.185593]\n",
      "epoch:46 step:36414[D loss: 0.394043, acc: 65.62%, op_acc: 41.41%] [G loss: 0.984265]\n",
      "epoch:46 step:36415[D loss: 0.439669, acc: 57.03%, op_acc: 45.31%] [G loss: 1.052621]\n",
      "epoch:46 step:36416[D loss: 0.414845, acc: 64.06%, op_acc: 41.41%] [G loss: 0.862190]\n",
      "epoch:46 step:36417[D loss: 0.418468, acc: 66.41%, op_acc: 35.94%] [G loss: 1.017889]\n",
      "epoch:46 step:36418[D loss: 0.348702, acc: 75.78%, op_acc: 45.31%] [G loss: 1.312729]\n",
      "epoch:46 step:36419[D loss: 0.413931, acc: 63.28%, op_acc: 42.19%] [G loss: 1.212855]\n",
      "epoch:46 step:36420[D loss: 0.356223, acc: 70.31%, op_acc: 40.62%] [G loss: 1.130335]\n",
      "epoch:46 step:36421[D loss: 0.407743, acc: 64.84%, op_acc: 38.28%] [G loss: 1.316694]\n",
      "epoch:46 step:36422[D loss: 0.326033, acc: 78.12%, op_acc: 46.09%] [G loss: 1.161204]\n",
      "epoch:46 step:36423[D loss: 0.376000, acc: 67.19%, op_acc: 42.19%] [G loss: 1.213966]\n",
      "epoch:46 step:36424[D loss: 0.429780, acc: 63.28%, op_acc: 41.41%] [G loss: 1.014964]\n",
      "epoch:46 step:36425[D loss: 0.355767, acc: 75.78%, op_acc: 53.12%] [G loss: 0.938555]\n",
      "epoch:46 step:36426[D loss: 0.382953, acc: 67.19%, op_acc: 49.22%] [G loss: 1.137889]\n",
      "epoch:46 step:36427[D loss: 0.398314, acc: 68.75%, op_acc: 42.19%] [G loss: 0.926723]\n",
      "epoch:46 step:36428[D loss: 0.402227, acc: 60.16%, op_acc: 46.09%] [G loss: 1.073848]\n",
      "epoch:46 step:36429[D loss: 0.375371, acc: 71.09%, op_acc: 42.19%] [G loss: 1.081774]\n",
      "epoch:46 step:36430[D loss: 0.446408, acc: 61.72%, op_acc: 42.97%] [G loss: 1.129415]\n",
      "epoch:46 step:36431[D loss: 0.366796, acc: 72.66%, op_acc: 38.28%] [G loss: 1.063948]\n",
      "epoch:46 step:36432[D loss: 0.419431, acc: 66.41%, op_acc: 40.62%] [G loss: 0.943106]\n",
      "epoch:46 step:36433[D loss: 0.400442, acc: 62.50%, op_acc: 48.44%] [G loss: 1.168196]\n",
      "epoch:46 step:36434[D loss: 0.453757, acc: 54.69%, op_acc: 36.72%] [G loss: 1.101042]\n",
      "epoch:46 step:36435[D loss: 0.379855, acc: 65.62%, op_acc: 43.75%] [G loss: 1.004630]\n",
      "epoch:46 step:36436[D loss: 0.365295, acc: 71.88%, op_acc: 41.41%] [G loss: 1.089696]\n",
      "epoch:46 step:36437[D loss: 0.413049, acc: 62.50%, op_acc: 50.78%] [G loss: 1.178594]\n",
      "epoch:46 step:36438[D loss: 0.462087, acc: 51.56%, op_acc: 46.88%] [G loss: 1.076845]\n",
      "epoch:46 step:36439[D loss: 0.450530, acc: 59.38%, op_acc: 42.97%] [G loss: 0.936364]\n",
      "epoch:46 step:36440[D loss: 0.427034, acc: 61.72%, op_acc: 44.53%] [G loss: 1.006836]\n",
      "epoch:46 step:36441[D loss: 0.402466, acc: 71.09%, op_acc: 42.19%] [G loss: 0.962985]\n",
      "epoch:46 step:36442[D loss: 0.361061, acc: 71.88%, op_acc: 36.72%] [G loss: 1.309272]\n",
      "epoch:46 step:36443[D loss: 0.462287, acc: 57.03%, op_acc: 40.62%] [G loss: 0.866563]\n",
      "epoch:46 step:36444[D loss: 0.374987, acc: 64.84%, op_acc: 39.84%] [G loss: 1.141387]\n",
      "epoch:46 step:36445[D loss: 0.341540, acc: 76.56%, op_acc: 50.00%] [G loss: 1.239263]\n",
      "epoch:46 step:36446[D loss: 0.344527, acc: 78.91%, op_acc: 54.69%] [G loss: 1.069057]\n",
      "epoch:46 step:36447[D loss: 0.416053, acc: 64.06%, op_acc: 40.62%] [G loss: 1.196986]\n",
      "epoch:46 step:36448[D loss: 0.347966, acc: 74.22%, op_acc: 54.69%] [G loss: 1.195793]\n",
      "epoch:46 step:36449[D loss: 0.471094, acc: 58.59%, op_acc: 40.62%] [G loss: 1.076309]\n",
      "epoch:46 step:36450[D loss: 0.351820, acc: 75.78%, op_acc: 48.44%] [G loss: 1.279135]\n",
      "epoch:46 step:36451[D loss: 0.395945, acc: 74.22%, op_acc: 37.50%] [G loss: 1.060794]\n",
      "epoch:46 step:36452[D loss: 0.417849, acc: 60.16%, op_acc: 48.44%] [G loss: 1.115758]\n",
      "epoch:46 step:36453[D loss: 0.428026, acc: 57.81%, op_acc: 46.88%] [G loss: 1.023593]\n",
      "epoch:46 step:36454[D loss: 0.342690, acc: 70.31%, op_acc: 46.88%] [G loss: 1.204908]\n",
      "epoch:46 step:36455[D loss: 0.385945, acc: 62.50%, op_acc: 44.53%] [G loss: 1.042066]\n",
      "epoch:46 step:36456[D loss: 0.455419, acc: 59.38%, op_acc: 37.50%] [G loss: 1.158668]\n",
      "epoch:46 step:36457[D loss: 0.432306, acc: 60.16%, op_acc: 42.19%] [G loss: 1.036484]\n",
      "epoch:46 step:36458[D loss: 0.385352, acc: 67.19%, op_acc: 43.75%] [G loss: 1.235149]\n",
      "epoch:46 step:36459[D loss: 0.421254, acc: 62.50%, op_acc: 43.75%] [G loss: 1.091263]\n",
      "epoch:46 step:36460[D loss: 0.306358, acc: 76.56%, op_acc: 51.56%] [G loss: 1.096699]\n",
      "epoch:46 step:36461[D loss: 0.384652, acc: 71.09%, op_acc: 42.19%] [G loss: 1.348369]\n",
      "epoch:46 step:36462[D loss: 0.361192, acc: 71.09%, op_acc: 50.78%] [G loss: 1.234993]\n",
      "epoch:46 step:36463[D loss: 0.418210, acc: 61.72%, op_acc: 48.44%] [G loss: 1.112995]\n",
      "epoch:46 step:36464[D loss: 0.371312, acc: 69.53%, op_acc: 45.31%] [G loss: 1.216191]\n",
      "epoch:46 step:36465[D loss: 0.411235, acc: 60.94%, op_acc: 44.53%] [G loss: 1.048645]\n",
      "epoch:46 step:36466[D loss: 0.359886, acc: 71.88%, op_acc: 47.66%] [G loss: 1.265446]\n",
      "epoch:46 step:36467[D loss: 0.387756, acc: 65.62%, op_acc: 42.97%] [G loss: 1.112753]\n",
      "epoch:46 step:36468[D loss: 0.386535, acc: 69.53%, op_acc: 43.75%] [G loss: 0.996145]\n",
      "epoch:46 step:36469[D loss: 0.421484, acc: 60.94%, op_acc: 43.75%] [G loss: 1.145581]\n",
      "epoch:46 step:36470[D loss: 0.394235, acc: 67.19%, op_acc: 46.88%] [G loss: 0.998615]\n",
      "epoch:46 step:36471[D loss: 0.367799, acc: 71.88%, op_acc: 47.66%] [G loss: 0.994477]\n",
      "epoch:46 step:36472[D loss: 0.367869, acc: 71.09%, op_acc: 50.78%] [G loss: 1.262522]\n",
      "epoch:46 step:36473[D loss: 0.423627, acc: 58.59%, op_acc: 41.41%] [G loss: 1.153633]\n",
      "epoch:46 step:36474[D loss: 0.434899, acc: 60.16%, op_acc: 39.84%] [G loss: 1.049821]\n",
      "epoch:46 step:36475[D loss: 0.417742, acc: 59.38%, op_acc: 39.84%] [G loss: 0.863575]\n",
      "epoch:46 step:36476[D loss: 0.407489, acc: 67.19%, op_acc: 39.84%] [G loss: 1.187212]\n",
      "epoch:46 step:36477[D loss: 0.394854, acc: 71.09%, op_acc: 41.41%] [G loss: 1.162640]\n",
      "epoch:46 step:36478[D loss: 0.457373, acc: 60.94%, op_acc: 39.06%] [G loss: 1.104486]\n",
      "epoch:46 step:36479[D loss: 0.366741, acc: 69.53%, op_acc: 39.84%] [G loss: 1.078118]\n",
      "epoch:46 step:36480[D loss: 0.388544, acc: 67.19%, op_acc: 36.72%] [G loss: 0.928544]\n",
      "epoch:46 step:36481[D loss: 0.307082, acc: 78.12%, op_acc: 47.66%] [G loss: 1.306102]\n",
      "epoch:46 step:36482[D loss: 0.426234, acc: 61.72%, op_acc: 47.66%] [G loss: 0.906393]\n",
      "epoch:46 step:36483[D loss: 0.382610, acc: 67.19%, op_acc: 45.31%] [G loss: 0.885910]\n",
      "epoch:46 step:36484[D loss: 0.361338, acc: 73.44%, op_acc: 42.97%] [G loss: 0.799807]\n",
      "epoch:46 step:36485[D loss: 0.396339, acc: 69.53%, op_acc: 42.19%] [G loss: 1.101858]\n",
      "epoch:46 step:36486[D loss: 0.388969, acc: 69.53%, op_acc: 46.09%] [G loss: 1.062073]\n",
      "epoch:46 step:36487[D loss: 0.337692, acc: 74.22%, op_acc: 45.31%] [G loss: 0.955179]\n",
      "epoch:46 step:36488[D loss: 0.379176, acc: 66.41%, op_acc: 37.50%] [G loss: 0.822686]\n",
      "epoch:46 step:36489[D loss: 0.400480, acc: 66.41%, op_acc: 43.75%] [G loss: 1.044025]\n",
      "epoch:46 step:36490[D loss: 0.434477, acc: 56.25%, op_acc: 44.53%] [G loss: 1.071992]\n",
      "epoch:46 step:36491[D loss: 0.388471, acc: 67.97%, op_acc: 42.97%] [G loss: 1.080409]\n",
      "epoch:46 step:36492[D loss: 0.419128, acc: 62.50%, op_acc: 39.06%] [G loss: 1.072988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36493[D loss: 0.389247, acc: 65.62%, op_acc: 46.88%] [G loss: 1.055270]\n",
      "epoch:46 step:36494[D loss: 0.393157, acc: 66.41%, op_acc: 42.97%] [G loss: 0.966741]\n",
      "epoch:46 step:36495[D loss: 0.368234, acc: 71.09%, op_acc: 46.09%] [G loss: 1.146784]\n",
      "epoch:46 step:36496[D loss: 0.378800, acc: 65.62%, op_acc: 44.53%] [G loss: 0.957962]\n",
      "epoch:46 step:36497[D loss: 0.401893, acc: 67.19%, op_acc: 44.53%] [G loss: 0.930461]\n",
      "epoch:46 step:36498[D loss: 0.377476, acc: 71.88%, op_acc: 42.97%] [G loss: 0.949232]\n",
      "epoch:46 step:36499[D loss: 0.380136, acc: 68.75%, op_acc: 45.31%] [G loss: 0.993355]\n",
      "epoch:46 step:36500[D loss: 0.423880, acc: 64.84%, op_acc: 41.41%] [G loss: 1.028454]\n",
      "epoch:46 step:36501[D loss: 0.427835, acc: 64.84%, op_acc: 38.28%] [G loss: 0.933512]\n",
      "epoch:46 step:36502[D loss: 0.336156, acc: 80.47%, op_acc: 52.34%] [G loss: 0.923492]\n",
      "epoch:46 step:36503[D loss: 0.411901, acc: 59.38%, op_acc: 48.44%] [G loss: 0.826537]\n",
      "epoch:46 step:36504[D loss: 0.444810, acc: 60.94%, op_acc: 37.50%] [G loss: 0.900373]\n",
      "epoch:46 step:36505[D loss: 0.327632, acc: 79.69%, op_acc: 48.44%] [G loss: 1.165544]\n",
      "epoch:46 step:36506[D loss: 0.347113, acc: 73.44%, op_acc: 52.34%] [G loss: 0.993108]\n",
      "epoch:46 step:36507[D loss: 0.439374, acc: 59.38%, op_acc: 37.50%] [G loss: 0.801349]\n",
      "epoch:46 step:36508[D loss: 0.371201, acc: 75.00%, op_acc: 44.53%] [G loss: 0.707357]\n",
      "epoch:46 step:36509[D loss: 0.362687, acc: 69.53%, op_acc: 55.47%] [G loss: 0.868403]\n",
      "epoch:46 step:36510[D loss: 0.437431, acc: 57.81%, op_acc: 43.75%] [G loss: 1.018862]\n",
      "epoch:46 step:36511[D loss: 0.353377, acc: 70.31%, op_acc: 47.66%] [G loss: 0.857150]\n",
      "epoch:46 step:36512[D loss: 0.370353, acc: 76.56%, op_acc: 43.75%] [G loss: 0.999798]\n",
      "epoch:46 step:36513[D loss: 0.339289, acc: 76.56%, op_acc: 42.97%] [G loss: 1.218227]\n",
      "epoch:46 step:36514[D loss: 0.341296, acc: 74.22%, op_acc: 46.88%] [G loss: 1.150320]\n",
      "epoch:46 step:36515[D loss: 0.412127, acc: 68.75%, op_acc: 46.88%] [G loss: 1.098465]\n",
      "epoch:46 step:36516[D loss: 0.370905, acc: 69.53%, op_acc: 45.31%] [G loss: 0.858328]\n",
      "epoch:46 step:36517[D loss: 0.426540, acc: 62.50%, op_acc: 41.41%] [G loss: 1.072531]\n",
      "epoch:46 step:36518[D loss: 0.378152, acc: 65.62%, op_acc: 52.34%] [G loss: 0.887122]\n",
      "epoch:46 step:36519[D loss: 0.413586, acc: 65.62%, op_acc: 41.41%] [G loss: 1.151674]\n",
      "epoch:46 step:36520[D loss: 0.367162, acc: 71.88%, op_acc: 41.41%] [G loss: 0.920799]\n",
      "epoch:46 step:36521[D loss: 0.389578, acc: 69.53%, op_acc: 46.09%] [G loss: 0.917895]\n",
      "epoch:46 step:36522[D loss: 0.411164, acc: 56.25%, op_acc: 43.75%] [G loss: 0.978378]\n",
      "epoch:46 step:36523[D loss: 0.351329, acc: 75.00%, op_acc: 46.09%] [G loss: 1.033497]\n",
      "epoch:46 step:36524[D loss: 0.380604, acc: 69.53%, op_acc: 42.97%] [G loss: 1.044755]\n",
      "epoch:46 step:36525[D loss: 0.362972, acc: 73.44%, op_acc: 48.44%] [G loss: 0.961023]\n",
      "epoch:46 step:36526[D loss: 0.342292, acc: 78.12%, op_acc: 47.66%] [G loss: 1.209075]\n",
      "epoch:46 step:36527[D loss: 0.424330, acc: 59.38%, op_acc: 34.38%] [G loss: 0.769071]\n",
      "epoch:46 step:36528[D loss: 0.332501, acc: 73.44%, op_acc: 50.78%] [G loss: 0.920621]\n",
      "epoch:46 step:36529[D loss: 0.317375, acc: 78.12%, op_acc: 49.22%] [G loss: 1.022655]\n",
      "epoch:46 step:36530[D loss: 0.447347, acc: 62.50%, op_acc: 33.59%] [G loss: 0.877357]\n",
      "epoch:46 step:36531[D loss: 0.375805, acc: 71.88%, op_acc: 48.44%] [G loss: 0.921212]\n",
      "epoch:46 step:36532[D loss: 0.386925, acc: 64.84%, op_acc: 48.44%] [G loss: 1.122995]\n",
      "epoch:46 step:36533[D loss: 0.364173, acc: 73.44%, op_acc: 41.41%] [G loss: 0.936544]\n",
      "epoch:46 step:36534[D loss: 0.302230, acc: 76.56%, op_acc: 52.34%] [G loss: 1.123429]\n",
      "epoch:46 step:36535[D loss: 0.383772, acc: 66.41%, op_acc: 48.44%] [G loss: 1.158434]\n",
      "epoch:46 step:36536[D loss: 0.334423, acc: 77.34%, op_acc: 50.00%] [G loss: 1.039545]\n",
      "epoch:46 step:36537[D loss: 0.386409, acc: 65.62%, op_acc: 42.19%] [G loss: 0.930568]\n",
      "epoch:46 step:36538[D loss: 0.359953, acc: 67.97%, op_acc: 46.09%] [G loss: 1.104228]\n",
      "epoch:46 step:36539[D loss: 0.402617, acc: 64.84%, op_acc: 42.19%] [G loss: 1.070878]\n",
      "epoch:46 step:36540[D loss: 0.380017, acc: 71.09%, op_acc: 42.97%] [G loss: 1.173760]\n",
      "epoch:46 step:36541[D loss: 0.349741, acc: 76.56%, op_acc: 47.66%] [G loss: 1.088330]\n",
      "epoch:46 step:36542[D loss: 0.426435, acc: 62.50%, op_acc: 40.62%] [G loss: 1.168085]\n",
      "epoch:46 step:36543[D loss: 0.453222, acc: 53.12%, op_acc: 39.84%] [G loss: 1.052558]\n",
      "epoch:46 step:36544[D loss: 0.327641, acc: 75.00%, op_acc: 50.00%] [G loss: 1.179559]\n",
      "epoch:46 step:36545[D loss: 0.428001, acc: 63.28%, op_acc: 39.06%] [G loss: 0.965166]\n",
      "epoch:46 step:36546[D loss: 0.387066, acc: 69.53%, op_acc: 38.28%] [G loss: 1.067337]\n",
      "epoch:46 step:36547[D loss: 0.394117, acc: 64.84%, op_acc: 40.62%] [G loss: 1.136257]\n",
      "epoch:46 step:36548[D loss: 0.403958, acc: 68.75%, op_acc: 39.06%] [G loss: 1.222113]\n",
      "epoch:46 step:36549[D loss: 0.373714, acc: 72.66%, op_acc: 45.31%] [G loss: 1.038630]\n",
      "epoch:46 step:36550[D loss: 0.379081, acc: 65.62%, op_acc: 45.31%] [G loss: 1.233282]\n",
      "epoch:46 step:36551[D loss: 0.338925, acc: 77.34%, op_acc: 51.56%] [G loss: 1.355644]\n",
      "epoch:46 step:36552[D loss: 0.448114, acc: 47.66%, op_acc: 48.44%] [G loss: 1.020100]\n",
      "epoch:46 step:36553[D loss: 0.396073, acc: 68.75%, op_acc: 44.53%] [G loss: 1.153958]\n",
      "epoch:46 step:36554[D loss: 0.381434, acc: 74.22%, op_acc: 46.09%] [G loss: 1.415832]\n",
      "epoch:46 step:36555[D loss: 0.395512, acc: 62.50%, op_acc: 47.66%] [G loss: 1.237926]\n",
      "epoch:46 step:36556[D loss: 0.387861, acc: 64.06%, op_acc: 45.31%] [G loss: 1.130928]\n",
      "epoch:46 step:36557[D loss: 0.385503, acc: 67.97%, op_acc: 49.22%] [G loss: 1.133912]\n",
      "epoch:46 step:36558[D loss: 0.390577, acc: 68.75%, op_acc: 51.56%] [G loss: 1.140625]\n",
      "epoch:46 step:36559[D loss: 0.361706, acc: 76.56%, op_acc: 48.44%] [G loss: 1.183328]\n",
      "epoch:46 step:36560[D loss: 0.348752, acc: 68.75%, op_acc: 53.91%] [G loss: 1.271301]\n",
      "epoch:46 step:36561[D loss: 0.399086, acc: 64.06%, op_acc: 44.53%] [G loss: 0.925087]\n",
      "epoch:46 step:36562[D loss: 0.389581, acc: 63.28%, op_acc: 45.31%] [G loss: 1.215297]\n",
      "epoch:46 step:36563[D loss: 0.295630, acc: 83.59%, op_acc: 50.00%] [G loss: 1.328727]\n",
      "epoch:46 step:36564[D loss: 0.350437, acc: 75.00%, op_acc: 46.09%] [G loss: 1.303033]\n",
      "epoch:46 step:36565[D loss: 0.341417, acc: 78.12%, op_acc: 53.12%] [G loss: 1.442756]\n",
      "epoch:46 step:36566[D loss: 0.394532, acc: 67.97%, op_acc: 42.19%] [G loss: 1.159489]\n",
      "epoch:46 step:36567[D loss: 0.377385, acc: 67.19%, op_acc: 47.66%] [G loss: 1.258506]\n",
      "epoch:46 step:36568[D loss: 0.357026, acc: 76.56%, op_acc: 45.31%] [G loss: 1.288521]\n",
      "epoch:46 step:36569[D loss: 0.364261, acc: 71.88%, op_acc: 45.31%] [G loss: 1.322467]\n",
      "epoch:46 step:36570[D loss: 0.371630, acc: 67.19%, op_acc: 45.31%] [G loss: 1.203964]\n",
      "epoch:46 step:36571[D loss: 0.328131, acc: 76.56%, op_acc: 48.44%] [G loss: 1.309863]\n",
      "epoch:46 step:36572[D loss: 0.389474, acc: 67.19%, op_acc: 45.31%] [G loss: 0.949126]\n",
      "epoch:46 step:36573[D loss: 0.384490, acc: 59.38%, op_acc: 42.19%] [G loss: 1.290439]\n",
      "epoch:46 step:36574[D loss: 0.332435, acc: 74.22%, op_acc: 45.31%] [G loss: 1.170323]\n",
      "epoch:46 step:36575[D loss: 0.424281, acc: 59.38%, op_acc: 39.06%] [G loss: 1.008591]\n",
      "epoch:46 step:36576[D loss: 0.498382, acc: 49.22%, op_acc: 35.94%] [G loss: 1.196502]\n",
      "epoch:46 step:36577[D loss: 0.396408, acc: 62.50%, op_acc: 46.88%] [G loss: 1.318449]\n",
      "epoch:46 step:36578[D loss: 0.397307, acc: 64.06%, op_acc: 50.00%] [G loss: 1.360970]\n",
      "epoch:46 step:36579[D loss: 0.461076, acc: 57.03%, op_acc: 42.97%] [G loss: 0.867415]\n",
      "epoch:46 step:36580[D loss: 0.382721, acc: 67.19%, op_acc: 43.75%] [G loss: 1.288114]\n",
      "epoch:46 step:36581[D loss: 0.362166, acc: 75.78%, op_acc: 46.09%] [G loss: 1.061415]\n",
      "epoch:46 step:36582[D loss: 0.364474, acc: 67.97%, op_acc: 48.44%] [G loss: 1.109543]\n",
      "epoch:46 step:36583[D loss: 0.414798, acc: 56.25%, op_acc: 35.16%] [G loss: 1.262927]\n",
      "epoch:46 step:36584[D loss: 0.398336, acc: 67.97%, op_acc: 39.84%] [G loss: 0.972046]\n",
      "epoch:46 step:36585[D loss: 0.362089, acc: 74.22%, op_acc: 38.28%] [G loss: 1.040377]\n",
      "epoch:46 step:36586[D loss: 0.376235, acc: 67.19%, op_acc: 42.97%] [G loss: 1.278205]\n",
      "epoch:46 step:36587[D loss: 0.372421, acc: 72.66%, op_acc: 46.09%] [G loss: 1.396913]\n",
      "epoch:46 step:36588[D loss: 0.379531, acc: 66.41%, op_acc: 47.66%] [G loss: 1.308367]\n",
      "epoch:46 step:36589[D loss: 0.339795, acc: 75.00%, op_acc: 50.00%] [G loss: 1.200999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36590[D loss: 0.429195, acc: 62.50%, op_acc: 41.41%] [G loss: 1.088350]\n",
      "epoch:46 step:36591[D loss: 0.415502, acc: 72.66%, op_acc: 39.84%] [G loss: 1.101567]\n",
      "epoch:46 step:36592[D loss: 0.371510, acc: 74.22%, op_acc: 41.41%] [G loss: 1.143412]\n",
      "epoch:46 step:36593[D loss: 0.378690, acc: 65.62%, op_acc: 45.31%] [G loss: 1.120917]\n",
      "epoch:46 step:36594[D loss: 0.487351, acc: 50.78%, op_acc: 40.62%] [G loss: 1.082037]\n",
      "epoch:46 step:36595[D loss: 0.395275, acc: 64.06%, op_acc: 44.53%] [G loss: 1.242701]\n",
      "epoch:46 step:36596[D loss: 0.378936, acc: 71.09%, op_acc: 50.00%] [G loss: 1.113001]\n",
      "epoch:46 step:36597[D loss: 0.408433, acc: 64.84%, op_acc: 39.06%] [G loss: 1.057914]\n",
      "epoch:46 step:36598[D loss: 0.386843, acc: 69.53%, op_acc: 39.06%] [G loss: 1.130224]\n",
      "epoch:46 step:36599[D loss: 0.439971, acc: 59.38%, op_acc: 38.28%] [G loss: 1.010811]\n",
      "epoch:46 step:36600[D loss: 0.376200, acc: 64.06%, op_acc: 48.44%] [G loss: 1.100049]\n",
      "epoch:46 step:36601[D loss: 0.348241, acc: 72.66%, op_acc: 47.66%] [G loss: 1.137905]\n",
      "epoch:46 step:36602[D loss: 0.423820, acc: 64.84%, op_acc: 42.19%] [G loss: 1.154156]\n",
      "epoch:46 step:36603[D loss: 0.457166, acc: 62.50%, op_acc: 38.28%] [G loss: 0.994192]\n",
      "epoch:46 step:36604[D loss: 0.352612, acc: 71.88%, op_acc: 42.19%] [G loss: 1.125942]\n",
      "epoch:46 step:36605[D loss: 0.379568, acc: 64.84%, op_acc: 48.44%] [G loss: 1.154732]\n",
      "epoch:46 step:36606[D loss: 0.413832, acc: 64.84%, op_acc: 33.59%] [G loss: 0.957317]\n",
      "epoch:46 step:36607[D loss: 0.404266, acc: 71.09%, op_acc: 39.06%] [G loss: 1.221938]\n",
      "epoch:46 step:36608[D loss: 0.394291, acc: 65.62%, op_acc: 45.31%] [G loss: 1.186630]\n",
      "epoch:46 step:36609[D loss: 0.395721, acc: 59.38%, op_acc: 44.53%] [G loss: 1.136149]\n",
      "epoch:46 step:36610[D loss: 0.397526, acc: 64.84%, op_acc: 45.31%] [G loss: 0.952200]\n",
      "epoch:46 step:36611[D loss: 0.398083, acc: 66.41%, op_acc: 41.41%] [G loss: 1.005893]\n",
      "epoch:46 step:36612[D loss: 0.380943, acc: 71.09%, op_acc: 41.41%] [G loss: 0.988382]\n",
      "epoch:46 step:36613[D loss: 0.381535, acc: 66.41%, op_acc: 48.44%] [G loss: 0.986268]\n",
      "epoch:46 step:36614[D loss: 0.407992, acc: 66.41%, op_acc: 42.97%] [G loss: 0.989871]\n",
      "epoch:46 step:36615[D loss: 0.419258, acc: 61.72%, op_acc: 46.09%] [G loss: 1.274234]\n",
      "epoch:46 step:36616[D loss: 0.393951, acc: 69.53%, op_acc: 42.19%] [G loss: 1.017699]\n",
      "epoch:46 step:36617[D loss: 0.335241, acc: 76.56%, op_acc: 47.66%] [G loss: 1.035870]\n",
      "epoch:46 step:36618[D loss: 0.441054, acc: 54.69%, op_acc: 46.09%] [G loss: 0.973978]\n",
      "epoch:46 step:36619[D loss: 0.399497, acc: 62.50%, op_acc: 40.62%] [G loss: 1.200591]\n",
      "epoch:46 step:36620[D loss: 0.355934, acc: 71.09%, op_acc: 46.09%] [G loss: 1.051447]\n",
      "epoch:46 step:36621[D loss: 0.399605, acc: 65.62%, op_acc: 45.31%] [G loss: 1.038976]\n",
      "epoch:46 step:36622[D loss: 0.408208, acc: 65.62%, op_acc: 42.19%] [G loss: 1.119082]\n",
      "epoch:46 step:36623[D loss: 0.412881, acc: 59.38%, op_acc: 48.44%] [G loss: 0.959090]\n",
      "epoch:46 step:36624[D loss: 0.434369, acc: 62.50%, op_acc: 42.97%] [G loss: 0.935310]\n",
      "epoch:46 step:36625[D loss: 0.398832, acc: 64.06%, op_acc: 49.22%] [G loss: 1.136529]\n",
      "epoch:46 step:36626[D loss: 0.356828, acc: 76.56%, op_acc: 49.22%] [G loss: 1.060383]\n",
      "epoch:46 step:36627[D loss: 0.422011, acc: 60.94%, op_acc: 36.72%] [G loss: 1.183587]\n",
      "epoch:46 step:36628[D loss: 0.376602, acc: 65.62%, op_acc: 47.66%] [G loss: 1.260443]\n",
      "epoch:46 step:36629[D loss: 0.475687, acc: 55.47%, op_acc: 35.94%] [G loss: 1.229125]\n",
      "epoch:46 step:36630[D loss: 0.354738, acc: 71.88%, op_acc: 42.97%] [G loss: 0.947300]\n",
      "epoch:46 step:36631[D loss: 0.466453, acc: 53.12%, op_acc: 35.94%] [G loss: 0.974211]\n",
      "epoch:46 step:36632[D loss: 0.417829, acc: 60.94%, op_acc: 52.34%] [G loss: 1.032332]\n",
      "epoch:46 step:36633[D loss: 0.474164, acc: 48.44%, op_acc: 41.41%] [G loss: 0.967050]\n",
      "epoch:46 step:36634[D loss: 0.362829, acc: 75.00%, op_acc: 40.62%] [G loss: 1.101563]\n",
      "epoch:46 step:36635[D loss: 0.376822, acc: 64.06%, op_acc: 43.75%] [G loss: 1.006969]\n",
      "epoch:46 step:36636[D loss: 0.301628, acc: 82.03%, op_acc: 47.66%] [G loss: 1.282527]\n",
      "epoch:46 step:36637[D loss: 0.372148, acc: 72.66%, op_acc: 48.44%] [G loss: 1.005496]\n",
      "epoch:46 step:36638[D loss: 0.435679, acc: 59.38%, op_acc: 47.66%] [G loss: 1.137630]\n",
      "epoch:46 step:36639[D loss: 0.409812, acc: 58.59%, op_acc: 45.31%] [G loss: 1.058670]\n",
      "epoch:46 step:36640[D loss: 0.449310, acc: 60.16%, op_acc: 40.62%] [G loss: 1.185191]\n",
      "epoch:46 step:36641[D loss: 0.376921, acc: 64.06%, op_acc: 45.31%] [G loss: 1.161054]\n",
      "epoch:46 step:36642[D loss: 0.368053, acc: 71.88%, op_acc: 43.75%] [G loss: 1.067987]\n",
      "epoch:46 step:36643[D loss: 0.375574, acc: 64.06%, op_acc: 47.66%] [G loss: 1.189621]\n",
      "epoch:46 step:36644[D loss: 0.392339, acc: 65.62%, op_acc: 39.84%] [G loss: 1.017421]\n",
      "epoch:46 step:36645[D loss: 0.357161, acc: 72.66%, op_acc: 47.66%] [G loss: 1.032958]\n",
      "epoch:46 step:36646[D loss: 0.402141, acc: 67.19%, op_acc: 42.19%] [G loss: 1.106845]\n",
      "epoch:46 step:36647[D loss: 0.386665, acc: 67.19%, op_acc: 47.66%] [G loss: 0.925067]\n",
      "epoch:46 step:36648[D loss: 0.403183, acc: 63.28%, op_acc: 42.97%] [G loss: 0.956231]\n",
      "epoch:46 step:36649[D loss: 0.392459, acc: 59.38%, op_acc: 42.19%] [G loss: 1.153595]\n",
      "epoch:46 step:36650[D loss: 0.442875, acc: 65.62%, op_acc: 37.50%] [G loss: 1.048552]\n",
      "epoch:46 step:36651[D loss: 0.423303, acc: 61.72%, op_acc: 47.66%] [G loss: 1.116137]\n",
      "epoch:46 step:36652[D loss: 0.362066, acc: 67.97%, op_acc: 51.56%] [G loss: 0.968048]\n",
      "epoch:46 step:36653[D loss: 0.405767, acc: 67.97%, op_acc: 35.94%] [G loss: 1.004733]\n",
      "epoch:46 step:36654[D loss: 0.414282, acc: 61.72%, op_acc: 42.19%] [G loss: 1.249493]\n",
      "epoch:46 step:36655[D loss: 0.376024, acc: 71.88%, op_acc: 48.44%] [G loss: 1.184280]\n",
      "epoch:46 step:36656[D loss: 0.386452, acc: 67.19%, op_acc: 41.41%] [G loss: 1.029886]\n",
      "epoch:46 step:36657[D loss: 0.396589, acc: 66.41%, op_acc: 50.00%] [G loss: 0.929519]\n",
      "epoch:46 step:36658[D loss: 0.393049, acc: 67.97%, op_acc: 37.50%] [G loss: 1.127669]\n",
      "epoch:46 step:36659[D loss: 0.421495, acc: 63.28%, op_acc: 45.31%] [G loss: 1.110857]\n",
      "epoch:46 step:36660[D loss: 0.349743, acc: 75.00%, op_acc: 48.44%] [G loss: 1.131424]\n",
      "epoch:46 step:36661[D loss: 0.410804, acc: 62.50%, op_acc: 42.19%] [G loss: 0.943954]\n",
      "epoch:46 step:36662[D loss: 0.372116, acc: 72.66%, op_acc: 41.41%] [G loss: 0.951835]\n",
      "epoch:46 step:36663[D loss: 0.396990, acc: 63.28%, op_acc: 46.09%] [G loss: 1.064495]\n",
      "epoch:46 step:36664[D loss: 0.397291, acc: 63.28%, op_acc: 49.22%] [G loss: 1.143448]\n",
      "epoch:46 step:36665[D loss: 0.379612, acc: 68.75%, op_acc: 46.09%] [G loss: 1.107538]\n",
      "epoch:46 step:36666[D loss: 0.387289, acc: 67.97%, op_acc: 44.53%] [G loss: 1.184887]\n",
      "epoch:46 step:36667[D loss: 0.342259, acc: 78.12%, op_acc: 46.88%] [G loss: 1.332930]\n",
      "epoch:46 step:36668[D loss: 0.372923, acc: 71.09%, op_acc: 41.41%] [G loss: 1.267621]\n",
      "epoch:46 step:36669[D loss: 0.393455, acc: 71.09%, op_acc: 39.84%] [G loss: 1.192116]\n",
      "epoch:46 step:36670[D loss: 0.349652, acc: 72.66%, op_acc: 43.75%] [G loss: 1.249366]\n",
      "epoch:46 step:36671[D loss: 0.348102, acc: 72.66%, op_acc: 46.09%] [G loss: 1.097709]\n",
      "epoch:46 step:36672[D loss: 0.430811, acc: 62.50%, op_acc: 43.75%] [G loss: 1.108393]\n",
      "epoch:46 step:36673[D loss: 0.392214, acc: 66.41%, op_acc: 42.19%] [G loss: 1.142789]\n",
      "epoch:46 step:36674[D loss: 0.378599, acc: 65.62%, op_acc: 45.31%] [G loss: 1.248905]\n",
      "epoch:46 step:36675[D loss: 0.338808, acc: 79.69%, op_acc: 44.53%] [G loss: 1.082673]\n",
      "epoch:46 step:36676[D loss: 0.370010, acc: 66.41%, op_acc: 46.09%] [G loss: 1.055709]\n",
      "epoch:46 step:36677[D loss: 0.392227, acc: 72.66%, op_acc: 39.06%] [G loss: 0.856675]\n",
      "epoch:46 step:36678[D loss: 0.405407, acc: 61.72%, op_acc: 40.62%] [G loss: 0.988868]\n",
      "epoch:46 step:36679[D loss: 0.376646, acc: 71.88%, op_acc: 42.19%] [G loss: 0.855955]\n",
      "epoch:46 step:36680[D loss: 0.370595, acc: 75.00%, op_acc: 45.31%] [G loss: 1.082020]\n",
      "epoch:46 step:36681[D loss: 0.351588, acc: 70.31%, op_acc: 42.19%] [G loss: 1.152126]\n",
      "epoch:46 step:36682[D loss: 0.455938, acc: 55.47%, op_acc: 39.06%] [G loss: 1.352557]\n",
      "epoch:46 step:36683[D loss: 0.348361, acc: 69.53%, op_acc: 52.34%] [G loss: 0.927536]\n",
      "epoch:46 step:36684[D loss: 0.380480, acc: 67.97%, op_acc: 50.78%] [G loss: 1.098912]\n",
      "epoch:46 step:36685[D loss: 0.394885, acc: 67.97%, op_acc: 46.09%] [G loss: 1.102596]\n",
      "epoch:46 step:36686[D loss: 0.403472, acc: 66.41%, op_acc: 39.84%] [G loss: 1.249493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46 step:36687[D loss: 0.410418, acc: 64.06%, op_acc: 45.31%] [G loss: 0.902103]\n",
      "epoch:46 step:36688[D loss: 0.412804, acc: 64.06%, op_acc: 42.19%] [G loss: 1.332596]\n",
      "epoch:46 step:36689[D loss: 0.456585, acc: 50.00%, op_acc: 41.41%] [G loss: 1.086978]\n",
      "epoch:46 step:36690[D loss: 0.398890, acc: 64.84%, op_acc: 45.31%] [G loss: 1.092251]\n",
      "epoch:46 step:36691[D loss: 0.375701, acc: 67.97%, op_acc: 43.75%] [G loss: 1.074624]\n",
      "epoch:46 step:36692[D loss: 0.463366, acc: 60.16%, op_acc: 39.06%] [G loss: 1.112285]\n",
      "epoch:46 step:36693[D loss: 0.405999, acc: 64.84%, op_acc: 42.19%] [G loss: 1.127154]\n",
      "epoch:46 step:36694[D loss: 0.374580, acc: 69.53%, op_acc: 42.97%] [G loss: 1.061496]\n",
      "epoch:46 step:36695[D loss: 0.374905, acc: 63.28%, op_acc: 43.75%] [G loss: 1.148879]\n",
      "epoch:46 step:36696[D loss: 0.379916, acc: 69.53%, op_acc: 46.88%] [G loss: 1.181272]\n",
      "epoch:46 step:36697[D loss: 0.499172, acc: 57.81%, op_acc: 32.81%] [G loss: 0.967461]\n",
      "epoch:46 step:36698[D loss: 0.422423, acc: 63.28%, op_acc: 36.72%] [G loss: 0.986417]\n",
      "epoch:46 step:36699[D loss: 0.422351, acc: 64.84%, op_acc: 39.06%] [G loss: 1.108164]\n",
      "epoch:46 step:36700[D loss: 0.340298, acc: 71.88%, op_acc: 47.66%] [G loss: 1.103866]\n",
      "epoch:46 step:36701[D loss: 0.349843, acc: 75.78%, op_acc: 46.09%] [G loss: 1.171204]\n",
      "epoch:46 step:36702[D loss: 0.414000, acc: 67.19%, op_acc: 46.88%] [G loss: 1.048822]\n",
      "epoch:46 step:36703[D loss: 0.468777, acc: 59.38%, op_acc: 35.16%] [G loss: 0.935292]\n",
      "epoch:46 step:36704[D loss: 0.373290, acc: 69.53%, op_acc: 50.00%] [G loss: 1.018398]\n",
      "epoch:46 step:36705[D loss: 0.325617, acc: 75.78%, op_acc: 50.00%] [G loss: 1.017845]\n",
      "epoch:46 step:36706[D loss: 0.387638, acc: 65.62%, op_acc: 42.97%] [G loss: 1.047022]\n",
      "epoch:46 step:36707[D loss: 0.402707, acc: 67.19%, op_acc: 43.75%] [G loss: 1.070590]\n",
      "epoch:47 step:36708[D loss: 0.341925, acc: 70.31%, op_acc: 48.44%] [G loss: 1.116284]\n",
      "epoch:47 step:36709[D loss: 0.332987, acc: 74.22%, op_acc: 52.34%] [G loss: 1.202920]\n",
      "epoch:47 step:36710[D loss: 0.370987, acc: 66.41%, op_acc: 41.41%] [G loss: 1.073948]\n",
      "epoch:47 step:36711[D loss: 0.378166, acc: 69.53%, op_acc: 42.19%] [G loss: 0.940732]\n",
      "epoch:47 step:36712[D loss: 0.401361, acc: 65.62%, op_acc: 46.88%] [G loss: 0.897534]\n",
      "epoch:47 step:36713[D loss: 0.402383, acc: 64.06%, op_acc: 44.53%] [G loss: 1.079421]\n",
      "epoch:47 step:36714[D loss: 0.382839, acc: 67.19%, op_acc: 42.97%] [G loss: 0.989235]\n",
      "epoch:47 step:36715[D loss: 0.429424, acc: 61.72%, op_acc: 38.28%] [G loss: 1.239250]\n",
      "epoch:47 step:36716[D loss: 0.326079, acc: 73.44%, op_acc: 50.00%] [G loss: 1.191541]\n",
      "epoch:47 step:36717[D loss: 0.400737, acc: 66.41%, op_acc: 42.97%] [G loss: 1.179701]\n",
      "epoch:47 step:36718[D loss: 0.447301, acc: 55.47%, op_acc: 44.53%] [G loss: 1.104259]\n",
      "epoch:47 step:36719[D loss: 0.422015, acc: 61.72%, op_acc: 33.59%] [G loss: 1.036855]\n",
      "epoch:47 step:36720[D loss: 0.373371, acc: 75.78%, op_acc: 46.09%] [G loss: 1.014491]\n",
      "epoch:47 step:36721[D loss: 0.369592, acc: 77.34%, op_acc: 50.00%] [G loss: 1.129037]\n",
      "epoch:47 step:36722[D loss: 0.355238, acc: 65.62%, op_acc: 40.62%] [G loss: 1.131014]\n",
      "epoch:47 step:36723[D loss: 0.359441, acc: 69.53%, op_acc: 48.44%] [G loss: 0.998744]\n",
      "epoch:47 step:36724[D loss: 0.360863, acc: 71.09%, op_acc: 50.78%] [G loss: 1.118502]\n",
      "epoch:47 step:36725[D loss: 0.394804, acc: 64.06%, op_acc: 46.88%] [G loss: 1.046006]\n",
      "epoch:47 step:36726[D loss: 0.387820, acc: 70.31%, op_acc: 39.84%] [G loss: 1.101750]\n",
      "epoch:47 step:36727[D loss: 0.335189, acc: 75.78%, op_acc: 47.66%] [G loss: 1.340982]\n",
      "epoch:47 step:36728[D loss: 0.401394, acc: 69.53%, op_acc: 38.28%] [G loss: 1.179823]\n",
      "epoch:47 step:36729[D loss: 0.374071, acc: 68.75%, op_acc: 43.75%] [G loss: 1.104681]\n",
      "epoch:47 step:36730[D loss: 0.390958, acc: 66.41%, op_acc: 52.34%] [G loss: 1.026724]\n",
      "epoch:47 step:36731[D loss: 0.405586, acc: 66.41%, op_acc: 45.31%] [G loss: 1.044712]\n",
      "epoch:47 step:36732[D loss: 0.475389, acc: 50.78%, op_acc: 40.62%] [G loss: 1.066356]\n",
      "epoch:47 step:36733[D loss: 0.342842, acc: 75.00%, op_acc: 48.44%] [G loss: 1.113201]\n",
      "epoch:47 step:36734[D loss: 0.412554, acc: 64.06%, op_acc: 39.84%] [G loss: 1.002257]\n",
      "epoch:47 step:36735[D loss: 0.359413, acc: 70.31%, op_acc: 44.53%] [G loss: 1.092534]\n",
      "epoch:47 step:36736[D loss: 0.370988, acc: 64.84%, op_acc: 53.91%] [G loss: 1.246285]\n",
      "epoch:47 step:36737[D loss: 0.406307, acc: 60.94%, op_acc: 43.75%] [G loss: 1.105878]\n",
      "epoch:47 step:36738[D loss: 0.430379, acc: 64.84%, op_acc: 42.19%] [G loss: 0.947519]\n",
      "epoch:47 step:36739[D loss: 0.422835, acc: 60.94%, op_acc: 45.31%] [G loss: 1.278107]\n",
      "epoch:47 step:36740[D loss: 0.354733, acc: 73.44%, op_acc: 49.22%] [G loss: 1.012430]\n",
      "epoch:47 step:36741[D loss: 0.376216, acc: 65.62%, op_acc: 50.00%] [G loss: 1.039596]\n",
      "epoch:47 step:36742[D loss: 0.423880, acc: 60.16%, op_acc: 42.19%] [G loss: 1.136764]\n",
      "epoch:47 step:36743[D loss: 0.359701, acc: 73.44%, op_acc: 42.97%] [G loss: 1.249357]\n",
      "epoch:47 step:36744[D loss: 0.342503, acc: 72.66%, op_acc: 51.56%] [G loss: 1.183278]\n",
      "epoch:47 step:36745[D loss: 0.374182, acc: 74.22%, op_acc: 46.09%] [G loss: 1.146567]\n",
      "epoch:47 step:36746[D loss: 0.427213, acc: 59.38%, op_acc: 46.88%] [G loss: 0.939853]\n",
      "epoch:47 step:36747[D loss: 0.454643, acc: 57.81%, op_acc: 41.41%] [G loss: 1.009856]\n",
      "epoch:47 step:36748[D loss: 0.369661, acc: 65.62%, op_acc: 49.22%] [G loss: 1.098393]\n",
      "epoch:47 step:36749[D loss: 0.330121, acc: 72.66%, op_acc: 49.22%] [G loss: 1.080955]\n",
      "epoch:47 step:36750[D loss: 0.357791, acc: 74.22%, op_acc: 42.19%] [G loss: 1.128434]\n",
      "epoch:47 step:36751[D loss: 0.359524, acc: 73.44%, op_acc: 51.56%] [G loss: 1.024995]\n",
      "epoch:47 step:36752[D loss: 0.348794, acc: 75.00%, op_acc: 49.22%] [G loss: 1.055020]\n",
      "epoch:47 step:36753[D loss: 0.434301, acc: 57.03%, op_acc: 40.62%] [G loss: 1.060821]\n",
      "epoch:47 step:36754[D loss: 0.396801, acc: 64.84%, op_acc: 38.28%] [G loss: 1.088472]\n",
      "epoch:47 step:36755[D loss: 0.404633, acc: 69.53%, op_acc: 38.28%] [G loss: 1.164587]\n",
      "epoch:47 step:36756[D loss: 0.392207, acc: 63.28%, op_acc: 41.41%] [G loss: 1.008266]\n",
      "epoch:47 step:36757[D loss: 0.368484, acc: 67.19%, op_acc: 47.66%] [G loss: 1.095594]\n",
      "epoch:47 step:36758[D loss: 0.345170, acc: 78.91%, op_acc: 44.53%] [G loss: 1.176180]\n",
      "epoch:47 step:36759[D loss: 0.401087, acc: 64.84%, op_acc: 44.53%] [G loss: 1.111356]\n",
      "epoch:47 step:36760[D loss: 0.414188, acc: 64.84%, op_acc: 36.72%] [G loss: 0.878049]\n",
      "epoch:47 step:36761[D loss: 0.419644, acc: 66.41%, op_acc: 47.66%] [G loss: 1.057644]\n",
      "epoch:47 step:36762[D loss: 0.357850, acc: 71.88%, op_acc: 50.00%] [G loss: 0.908001]\n",
      "epoch:47 step:36763[D loss: 0.372346, acc: 74.22%, op_acc: 44.53%] [G loss: 1.238611]\n",
      "epoch:47 step:36764[D loss: 0.413624, acc: 67.19%, op_acc: 42.19%] [G loss: 0.896620]\n",
      "epoch:47 step:36765[D loss: 0.331999, acc: 76.56%, op_acc: 53.91%] [G loss: 0.918301]\n",
      "epoch:47 step:36766[D loss: 0.399075, acc: 64.84%, op_acc: 48.44%] [G loss: 0.966366]\n",
      "epoch:47 step:36767[D loss: 0.417939, acc: 61.72%, op_acc: 40.62%] [G loss: 0.943907]\n",
      "epoch:47 step:36768[D loss: 0.390540, acc: 71.09%, op_acc: 47.66%] [G loss: 1.214673]\n",
      "epoch:47 step:36769[D loss: 0.333044, acc: 79.69%, op_acc: 50.00%] [G loss: 1.002125]\n",
      "epoch:47 step:36770[D loss: 0.376732, acc: 70.31%, op_acc: 43.75%] [G loss: 1.184912]\n",
      "epoch:47 step:36771[D loss: 0.387295, acc: 69.53%, op_acc: 48.44%] [G loss: 1.138140]\n",
      "epoch:47 step:36772[D loss: 0.426668, acc: 57.03%, op_acc: 44.53%] [G loss: 0.828141]\n",
      "epoch:47 step:36773[D loss: 0.426875, acc: 58.59%, op_acc: 39.84%] [G loss: 1.078082]\n",
      "epoch:47 step:36774[D loss: 0.316088, acc: 80.47%, op_acc: 45.31%] [G loss: 0.993346]\n",
      "epoch:47 step:36775[D loss: 0.360359, acc: 68.75%, op_acc: 40.62%] [G loss: 0.902032]\n",
      "epoch:47 step:36776[D loss: 0.367337, acc: 68.75%, op_acc: 49.22%] [G loss: 1.002614]\n",
      "epoch:47 step:36777[D loss: 0.412684, acc: 60.16%, op_acc: 47.66%] [G loss: 0.994333]\n",
      "epoch:47 step:36778[D loss: 0.444590, acc: 60.94%, op_acc: 32.81%] [G loss: 0.937497]\n",
      "epoch:47 step:36779[D loss: 0.433523, acc: 60.94%, op_acc: 49.22%] [G loss: 0.886855]\n",
      "epoch:47 step:36780[D loss: 0.442532, acc: 57.03%, op_acc: 43.75%] [G loss: 0.866612]\n",
      "epoch:47 step:36781[D loss: 0.358086, acc: 67.97%, op_acc: 45.31%] [G loss: 1.020081]\n",
      "epoch:47 step:36782[D loss: 0.345967, acc: 71.09%, op_acc: 44.53%] [G loss: 1.130447]\n",
      "epoch:47 step:36783[D loss: 0.374570, acc: 71.88%, op_acc: 39.84%] [G loss: 1.096380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36784[D loss: 0.356649, acc: 73.44%, op_acc: 46.88%] [G loss: 1.142977]\n",
      "epoch:47 step:36785[D loss: 0.427752, acc: 64.06%, op_acc: 37.50%] [G loss: 0.946784]\n",
      "epoch:47 step:36786[D loss: 0.359698, acc: 74.22%, op_acc: 47.66%] [G loss: 0.956354]\n",
      "epoch:47 step:36787[D loss: 0.490826, acc: 61.72%, op_acc: 32.03%] [G loss: 0.984720]\n",
      "epoch:47 step:36788[D loss: 0.395298, acc: 70.31%, op_acc: 42.19%] [G loss: 0.971753]\n",
      "epoch:47 step:36789[D loss: 0.343984, acc: 72.66%, op_acc: 44.53%] [G loss: 1.022992]\n",
      "epoch:47 step:36790[D loss: 0.394335, acc: 67.97%, op_acc: 39.06%] [G loss: 1.130300]\n",
      "epoch:47 step:36791[D loss: 0.401677, acc: 64.84%, op_acc: 42.19%] [G loss: 1.131069]\n",
      "epoch:47 step:36792[D loss: 0.424534, acc: 65.62%, op_acc: 44.53%] [G loss: 1.312631]\n",
      "epoch:47 step:36793[D loss: 0.414411, acc: 60.16%, op_acc: 46.88%] [G loss: 1.247027]\n",
      "epoch:47 step:36794[D loss: 0.426322, acc: 63.28%, op_acc: 38.28%] [G loss: 1.288669]\n",
      "epoch:47 step:36795[D loss: 0.389139, acc: 71.88%, op_acc: 39.06%] [G loss: 1.188205]\n",
      "epoch:47 step:36796[D loss: 0.452395, acc: 59.38%, op_acc: 40.62%] [G loss: 1.001997]\n",
      "epoch:47 step:36797[D loss: 0.420248, acc: 62.50%, op_acc: 42.97%] [G loss: 1.195010]\n",
      "epoch:47 step:36798[D loss: 0.379203, acc: 70.31%, op_acc: 46.88%] [G loss: 0.976840]\n",
      "epoch:47 step:36799[D loss: 0.418102, acc: 59.38%, op_acc: 42.97%] [G loss: 1.014120]\n",
      "epoch:47 step:36800[D loss: 0.362449, acc: 67.19%, op_acc: 49.22%] [G loss: 1.176356]\n",
      "epoch:47 step:36801[D loss: 0.380210, acc: 71.88%, op_acc: 44.53%] [G loss: 1.130503]\n",
      "epoch:47 step:36802[D loss: 0.379197, acc: 67.97%, op_acc: 47.66%] [G loss: 1.318771]\n",
      "epoch:47 step:36803[D loss: 0.343202, acc: 76.56%, op_acc: 48.44%] [G loss: 0.941247]\n",
      "epoch:47 step:36804[D loss: 0.334780, acc: 72.66%, op_acc: 45.31%] [G loss: 1.010370]\n",
      "epoch:47 step:36805[D loss: 0.339956, acc: 75.78%, op_acc: 42.97%] [G loss: 1.078630]\n",
      "epoch:47 step:36806[D loss: 0.384548, acc: 70.31%, op_acc: 46.09%] [G loss: 1.074851]\n",
      "epoch:47 step:36807[D loss: 0.364279, acc: 69.53%, op_acc: 46.09%] [G loss: 0.990097]\n",
      "epoch:47 step:36808[D loss: 0.392579, acc: 62.50%, op_acc: 39.06%] [G loss: 1.083972]\n",
      "epoch:47 step:36809[D loss: 0.391197, acc: 65.62%, op_acc: 39.06%] [G loss: 1.060065]\n",
      "epoch:47 step:36810[D loss: 0.399669, acc: 60.16%, op_acc: 46.88%] [G loss: 1.062089]\n",
      "epoch:47 step:36811[D loss: 0.354849, acc: 71.88%, op_acc: 48.44%] [G loss: 0.925089]\n",
      "epoch:47 step:36812[D loss: 0.372788, acc: 70.31%, op_acc: 50.00%] [G loss: 1.241268]\n",
      "epoch:47 step:36813[D loss: 0.337894, acc: 78.12%, op_acc: 49.22%] [G loss: 1.331537]\n",
      "epoch:47 step:36814[D loss: 0.370934, acc: 67.97%, op_acc: 46.09%] [G loss: 1.358299]\n",
      "epoch:47 step:36815[D loss: 0.372025, acc: 63.28%, op_acc: 53.91%] [G loss: 0.860909]\n",
      "epoch:47 step:36816[D loss: 0.456911, acc: 53.91%, op_acc: 38.28%] [G loss: 1.024912]\n",
      "epoch:47 step:36817[D loss: 0.393841, acc: 64.84%, op_acc: 45.31%] [G loss: 1.167456]\n",
      "epoch:47 step:36818[D loss: 0.439274, acc: 64.06%, op_acc: 37.50%] [G loss: 1.042230]\n",
      "epoch:47 step:36819[D loss: 0.409833, acc: 58.59%, op_acc: 45.31%] [G loss: 1.077899]\n",
      "epoch:47 step:36820[D loss: 0.445238, acc: 53.12%, op_acc: 38.28%] [G loss: 1.057494]\n",
      "epoch:47 step:36821[D loss: 0.346873, acc: 71.09%, op_acc: 50.78%] [G loss: 1.119054]\n",
      "epoch:47 step:36822[D loss: 0.359239, acc: 66.41%, op_acc: 50.00%] [G loss: 1.044300]\n",
      "epoch:47 step:36823[D loss: 0.415408, acc: 64.06%, op_acc: 42.19%] [G loss: 1.065895]\n",
      "epoch:47 step:36824[D loss: 0.390129, acc: 66.41%, op_acc: 43.75%] [G loss: 1.188804]\n",
      "epoch:47 step:36825[D loss: 0.393344, acc: 68.75%, op_acc: 44.53%] [G loss: 1.082633]\n",
      "epoch:47 step:36826[D loss: 0.388006, acc: 70.31%, op_acc: 42.19%] [G loss: 1.013508]\n",
      "epoch:47 step:36827[D loss: 0.395071, acc: 68.75%, op_acc: 40.62%] [G loss: 1.097513]\n",
      "epoch:47 step:36828[D loss: 0.378933, acc: 67.19%, op_acc: 50.00%] [G loss: 1.064979]\n",
      "epoch:47 step:36829[D loss: 0.397606, acc: 65.62%, op_acc: 44.53%] [G loss: 1.023053]\n",
      "epoch:47 step:36830[D loss: 0.402486, acc: 60.94%, op_acc: 41.41%] [G loss: 1.075881]\n",
      "epoch:47 step:36831[D loss: 0.381656, acc: 67.97%, op_acc: 49.22%] [G loss: 1.208577]\n",
      "epoch:47 step:36832[D loss: 0.403313, acc: 66.41%, op_acc: 39.06%] [G loss: 1.159320]\n",
      "epoch:47 step:36833[D loss: 0.401663, acc: 66.41%, op_acc: 38.28%] [G loss: 1.170455]\n",
      "epoch:47 step:36834[D loss: 0.337639, acc: 77.34%, op_acc: 44.53%] [G loss: 1.036123]\n",
      "epoch:47 step:36835[D loss: 0.370099, acc: 71.88%, op_acc: 46.09%] [G loss: 1.117589]\n",
      "epoch:47 step:36836[D loss: 0.387847, acc: 67.19%, op_acc: 46.88%] [G loss: 0.964637]\n",
      "epoch:47 step:36837[D loss: 0.369722, acc: 71.88%, op_acc: 46.88%] [G loss: 1.061161]\n",
      "epoch:47 step:36838[D loss: 0.347007, acc: 73.44%, op_acc: 46.09%] [G loss: 0.986903]\n",
      "epoch:47 step:36839[D loss: 0.322630, acc: 76.56%, op_acc: 49.22%] [G loss: 1.039903]\n",
      "epoch:47 step:36840[D loss: 0.446361, acc: 63.28%, op_acc: 42.97%] [G loss: 1.037781]\n",
      "epoch:47 step:36841[D loss: 0.368025, acc: 72.66%, op_acc: 47.66%] [G loss: 1.074379]\n",
      "epoch:47 step:36842[D loss: 0.415098, acc: 60.16%, op_acc: 44.53%] [G loss: 1.026446]\n",
      "epoch:47 step:36843[D loss: 0.356817, acc: 71.09%, op_acc: 41.41%] [G loss: 1.203001]\n",
      "epoch:47 step:36844[D loss: 0.367020, acc: 74.22%, op_acc: 50.78%] [G loss: 0.941559]\n",
      "epoch:47 step:36845[D loss: 0.404710, acc: 65.62%, op_acc: 46.09%] [G loss: 1.051364]\n",
      "epoch:47 step:36846[D loss: 0.402100, acc: 60.16%, op_acc: 40.62%] [G loss: 1.171589]\n",
      "epoch:47 step:36847[D loss: 0.436175, acc: 64.06%, op_acc: 36.72%] [G loss: 0.958246]\n",
      "epoch:47 step:36848[D loss: 0.372192, acc: 72.66%, op_acc: 40.62%] [G loss: 0.991112]\n",
      "epoch:47 step:36849[D loss: 0.370022, acc: 71.88%, op_acc: 48.44%] [G loss: 1.154806]\n",
      "epoch:47 step:36850[D loss: 0.401050, acc: 63.28%, op_acc: 45.31%] [G loss: 1.048209]\n",
      "epoch:47 step:36851[D loss: 0.424493, acc: 63.28%, op_acc: 39.06%] [G loss: 0.939471]\n",
      "epoch:47 step:36852[D loss: 0.378683, acc: 67.19%, op_acc: 46.09%] [G loss: 1.096096]\n",
      "epoch:47 step:36853[D loss: 0.365768, acc: 71.88%, op_acc: 48.44%] [G loss: 1.149970]\n",
      "epoch:47 step:36854[D loss: 0.385518, acc: 65.62%, op_acc: 45.31%] [G loss: 1.156580]\n",
      "epoch:47 step:36855[D loss: 0.387716, acc: 66.41%, op_acc: 44.53%] [G loss: 1.170807]\n",
      "epoch:47 step:36856[D loss: 0.376286, acc: 65.62%, op_acc: 48.44%] [G loss: 1.110078]\n",
      "epoch:47 step:36857[D loss: 0.354240, acc: 64.84%, op_acc: 51.56%] [G loss: 0.979337]\n",
      "epoch:47 step:36858[D loss: 0.338313, acc: 75.00%, op_acc: 50.78%] [G loss: 1.421548]\n",
      "epoch:47 step:36859[D loss: 0.347633, acc: 69.53%, op_acc: 46.88%] [G loss: 1.058830]\n",
      "epoch:47 step:36860[D loss: 0.350808, acc: 77.34%, op_acc: 44.53%] [G loss: 1.317996]\n",
      "epoch:47 step:36861[D loss: 0.355655, acc: 68.75%, op_acc: 48.44%] [G loss: 1.057260]\n",
      "epoch:47 step:36862[D loss: 0.330124, acc: 75.00%, op_acc: 46.88%] [G loss: 1.220602]\n",
      "epoch:47 step:36863[D loss: 0.385196, acc: 64.84%, op_acc: 44.53%] [G loss: 1.210908]\n",
      "epoch:47 step:36864[D loss: 0.380186, acc: 67.19%, op_acc: 46.09%] [G loss: 1.029844]\n",
      "epoch:47 step:36865[D loss: 0.350253, acc: 66.41%, op_acc: 52.34%] [G loss: 1.058824]\n",
      "epoch:47 step:36866[D loss: 0.336846, acc: 77.34%, op_acc: 48.44%] [G loss: 1.325877]\n",
      "epoch:47 step:36867[D loss: 0.413298, acc: 71.09%, op_acc: 43.75%] [G loss: 1.183067]\n",
      "epoch:47 step:36868[D loss: 0.382961, acc: 67.19%, op_acc: 39.84%] [G loss: 0.991092]\n",
      "epoch:47 step:36869[D loss: 0.390502, acc: 64.06%, op_acc: 49.22%] [G loss: 1.186620]\n",
      "epoch:47 step:36870[D loss: 0.359867, acc: 77.34%, op_acc: 50.78%] [G loss: 1.163257]\n",
      "epoch:47 step:36871[D loss: 0.380372, acc: 65.62%, op_acc: 42.97%] [G loss: 1.180690]\n",
      "epoch:47 step:36872[D loss: 0.361256, acc: 70.31%, op_acc: 53.12%] [G loss: 1.013119]\n",
      "epoch:47 step:36873[D loss: 0.391690, acc: 68.75%, op_acc: 50.00%] [G loss: 0.986474]\n",
      "epoch:47 step:36874[D loss: 0.357432, acc: 75.78%, op_acc: 50.00%] [G loss: 1.145800]\n",
      "epoch:47 step:36875[D loss: 0.425720, acc: 57.03%, op_acc: 45.31%] [G loss: 1.085019]\n",
      "epoch:47 step:36876[D loss: 0.400328, acc: 67.19%, op_acc: 44.53%] [G loss: 1.053256]\n",
      "epoch:47 step:36877[D loss: 0.359349, acc: 71.88%, op_acc: 50.00%] [G loss: 1.144279]\n",
      "epoch:47 step:36878[D loss: 0.438990, acc: 59.38%, op_acc: 40.62%] [G loss: 0.998506]\n",
      "epoch:47 step:36879[D loss: 0.380342, acc: 67.97%, op_acc: 46.09%] [G loss: 1.032440]\n",
      "epoch:47 step:36880[D loss: 0.412888, acc: 62.50%, op_acc: 39.06%] [G loss: 1.129873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36881[D loss: 0.381395, acc: 71.88%, op_acc: 44.53%] [G loss: 1.037510]\n",
      "epoch:47 step:36882[D loss: 0.341187, acc: 75.00%, op_acc: 53.12%] [G loss: 1.110501]\n",
      "epoch:47 step:36883[D loss: 0.382891, acc: 65.62%, op_acc: 43.75%] [G loss: 1.002611]\n",
      "epoch:47 step:36884[D loss: 0.360922, acc: 71.88%, op_acc: 46.09%] [G loss: 0.958912]\n",
      "epoch:47 step:36885[D loss: 0.435829, acc: 59.38%, op_acc: 42.97%] [G loss: 1.150906]\n",
      "epoch:47 step:36886[D loss: 0.371201, acc: 71.88%, op_acc: 46.09%] [G loss: 1.164895]\n",
      "epoch:47 step:36887[D loss: 0.331090, acc: 77.34%, op_acc: 48.44%] [G loss: 1.239200]\n",
      "epoch:47 step:36888[D loss: 0.415915, acc: 55.47%, op_acc: 50.78%] [G loss: 1.088692]\n",
      "epoch:47 step:36889[D loss: 0.368843, acc: 70.31%, op_acc: 44.53%] [G loss: 1.009713]\n",
      "epoch:47 step:36890[D loss: 0.366768, acc: 70.31%, op_acc: 49.22%] [G loss: 1.075397]\n",
      "epoch:47 step:36891[D loss: 0.335121, acc: 69.53%, op_acc: 50.78%] [G loss: 1.088850]\n",
      "epoch:47 step:36892[D loss: 0.388066, acc: 70.31%, op_acc: 42.19%] [G loss: 1.377521]\n",
      "epoch:47 step:36893[D loss: 0.384187, acc: 67.19%, op_acc: 46.88%] [G loss: 1.071780]\n",
      "epoch:47 step:36894[D loss: 0.458139, acc: 55.47%, op_acc: 40.62%] [G loss: 0.867798]\n",
      "epoch:47 step:36895[D loss: 0.469336, acc: 56.25%, op_acc: 40.62%] [G loss: 0.873393]\n",
      "epoch:47 step:36896[D loss: 0.472845, acc: 51.56%, op_acc: 46.09%] [G loss: 0.948386]\n",
      "epoch:47 step:36897[D loss: 0.386506, acc: 67.19%, op_acc: 48.44%] [G loss: 1.080887]\n",
      "epoch:47 step:36898[D loss: 0.380981, acc: 64.84%, op_acc: 47.66%] [G loss: 0.941167]\n",
      "epoch:47 step:36899[D loss: 0.371535, acc: 68.75%, op_acc: 43.75%] [G loss: 1.132192]\n",
      "epoch:47 step:36900[D loss: 0.434493, acc: 59.38%, op_acc: 40.62%] [G loss: 0.879105]\n",
      "epoch:47 step:36901[D loss: 0.401070, acc: 60.16%, op_acc: 50.78%] [G loss: 1.013055]\n",
      "epoch:47 step:36902[D loss: 0.390947, acc: 62.50%, op_acc: 39.06%] [G loss: 1.016912]\n",
      "epoch:47 step:36903[D loss: 0.409378, acc: 63.28%, op_acc: 41.41%] [G loss: 0.911723]\n",
      "epoch:47 step:36904[D loss: 0.393377, acc: 71.88%, op_acc: 42.97%] [G loss: 0.921958]\n",
      "epoch:47 step:36905[D loss: 0.379833, acc: 68.75%, op_acc: 39.84%] [G loss: 0.907119]\n",
      "epoch:47 step:36906[D loss: 0.351307, acc: 71.09%, op_acc: 46.09%] [G loss: 0.856337]\n",
      "epoch:47 step:36907[D loss: 0.372294, acc: 70.31%, op_acc: 46.09%] [G loss: 0.887615]\n",
      "epoch:47 step:36908[D loss: 0.344826, acc: 74.22%, op_acc: 47.66%] [G loss: 0.932323]\n",
      "epoch:47 step:36909[D loss: 0.358096, acc: 68.75%, op_acc: 46.09%] [G loss: 1.166955]\n",
      "epoch:47 step:36910[D loss: 0.456494, acc: 57.03%, op_acc: 42.97%] [G loss: 1.231010]\n",
      "epoch:47 step:36911[D loss: 0.420463, acc: 61.72%, op_acc: 43.75%] [G loss: 0.916057]\n",
      "epoch:47 step:36912[D loss: 0.344959, acc: 74.22%, op_acc: 41.41%] [G loss: 0.992441]\n",
      "epoch:47 step:36913[D loss: 0.373071, acc: 66.41%, op_acc: 39.84%] [G loss: 1.024517]\n",
      "epoch:47 step:36914[D loss: 0.443405, acc: 54.69%, op_acc: 41.41%] [G loss: 0.992337]\n",
      "epoch:47 step:36915[D loss: 0.402296, acc: 64.06%, op_acc: 39.06%] [G loss: 0.987916]\n",
      "epoch:47 step:36916[D loss: 0.372948, acc: 67.19%, op_acc: 46.09%] [G loss: 1.121429]\n",
      "epoch:47 step:36917[D loss: 0.356133, acc: 78.91%, op_acc: 50.00%] [G loss: 1.327270]\n",
      "epoch:47 step:36918[D loss: 0.337343, acc: 72.66%, op_acc: 44.53%] [G loss: 0.991788]\n",
      "epoch:47 step:36919[D loss: 0.405187, acc: 63.28%, op_acc: 40.62%] [G loss: 1.210653]\n",
      "epoch:47 step:36920[D loss: 0.331688, acc: 76.56%, op_acc: 45.31%] [G loss: 1.435987]\n",
      "epoch:47 step:36921[D loss: 0.348664, acc: 74.22%, op_acc: 49.22%] [G loss: 1.475306]\n",
      "epoch:47 step:36922[D loss: 0.437738, acc: 60.94%, op_acc: 39.84%] [G loss: 1.196412]\n",
      "epoch:47 step:36923[D loss: 0.455699, acc: 54.69%, op_acc: 38.28%] [G loss: 1.012522]\n",
      "epoch:47 step:36924[D loss: 0.340864, acc: 76.56%, op_acc: 53.91%] [G loss: 0.969027]\n",
      "epoch:47 step:36925[D loss: 0.368207, acc: 67.97%, op_acc: 47.66%] [G loss: 1.080069]\n",
      "epoch:47 step:36926[D loss: 0.329203, acc: 74.22%, op_acc: 50.78%] [G loss: 1.028142]\n",
      "epoch:47 step:36927[D loss: 0.415281, acc: 63.28%, op_acc: 46.09%] [G loss: 1.111524]\n",
      "epoch:47 step:36928[D loss: 0.410167, acc: 63.28%, op_acc: 39.84%] [G loss: 0.805056]\n",
      "epoch:47 step:36929[D loss: 0.353934, acc: 72.66%, op_acc: 43.75%] [G loss: 1.155493]\n",
      "epoch:47 step:36930[D loss: 0.403446, acc: 65.62%, op_acc: 48.44%] [G loss: 1.249593]\n",
      "epoch:47 step:36931[D loss: 0.393681, acc: 66.41%, op_acc: 48.44%] [G loss: 1.105810]\n",
      "epoch:47 step:36932[D loss: 0.316688, acc: 78.91%, op_acc: 47.66%] [G loss: 1.118164]\n",
      "epoch:47 step:36933[D loss: 0.374374, acc: 70.31%, op_acc: 47.66%] [G loss: 1.183504]\n",
      "epoch:47 step:36934[D loss: 0.364550, acc: 70.31%, op_acc: 46.88%] [G loss: 1.047728]\n",
      "epoch:47 step:36935[D loss: 0.401309, acc: 64.84%, op_acc: 42.19%] [G loss: 1.301750]\n",
      "epoch:47 step:36936[D loss: 0.388363, acc: 64.84%, op_acc: 42.19%] [G loss: 1.244304]\n",
      "epoch:47 step:36937[D loss: 0.421469, acc: 60.16%, op_acc: 44.53%] [G loss: 1.119872]\n",
      "epoch:47 step:36938[D loss: 0.333179, acc: 76.56%, op_acc: 46.88%] [G loss: 1.177485]\n",
      "epoch:47 step:36939[D loss: 0.389088, acc: 64.06%, op_acc: 44.53%] [G loss: 1.246295]\n",
      "epoch:47 step:36940[D loss: 0.318922, acc: 76.56%, op_acc: 45.31%] [G loss: 1.211384]\n",
      "epoch:47 step:36941[D loss: 0.344858, acc: 77.34%, op_acc: 52.34%] [G loss: 0.963354]\n",
      "epoch:47 step:36942[D loss: 0.402396, acc: 58.59%, op_acc: 43.75%] [G loss: 1.210571]\n",
      "epoch:47 step:36943[D loss: 0.340859, acc: 75.78%, op_acc: 43.75%] [G loss: 1.322710]\n",
      "epoch:47 step:36944[D loss: 0.346071, acc: 71.88%, op_acc: 40.62%] [G loss: 1.365520]\n",
      "epoch:47 step:36945[D loss: 0.365399, acc: 75.00%, op_acc: 43.75%] [G loss: 1.265978]\n",
      "epoch:47 step:36946[D loss: 0.374797, acc: 66.41%, op_acc: 46.88%] [G loss: 1.170282]\n",
      "epoch:47 step:36947[D loss: 0.369106, acc: 71.88%, op_acc: 43.75%] [G loss: 1.271410]\n",
      "epoch:47 step:36948[D loss: 0.338706, acc: 72.66%, op_acc: 49.22%] [G loss: 0.963548]\n",
      "epoch:47 step:36949[D loss: 0.397215, acc: 58.59%, op_acc: 49.22%] [G loss: 1.257463]\n",
      "epoch:47 step:36950[D loss: 0.466291, acc: 53.12%, op_acc: 41.41%] [G loss: 1.240685]\n",
      "epoch:47 step:36951[D loss: 0.416101, acc: 65.62%, op_acc: 42.97%] [G loss: 1.237585]\n",
      "epoch:47 step:36952[D loss: 0.359001, acc: 64.06%, op_acc: 53.12%] [G loss: 1.042574]\n",
      "epoch:47 step:36953[D loss: 0.334358, acc: 81.25%, op_acc: 44.53%] [G loss: 0.921591]\n",
      "epoch:47 step:36954[D loss: 0.385984, acc: 67.19%, op_acc: 43.75%] [G loss: 1.003400]\n",
      "epoch:47 step:36955[D loss: 0.389937, acc: 68.75%, op_acc: 40.62%] [G loss: 1.133415]\n",
      "epoch:47 step:36956[D loss: 0.334193, acc: 75.78%, op_acc: 42.97%] [G loss: 1.025309]\n",
      "epoch:47 step:36957[D loss: 0.446835, acc: 61.72%, op_acc: 38.28%] [G loss: 0.908294]\n",
      "epoch:47 step:36958[D loss: 0.364178, acc: 67.97%, op_acc: 48.44%] [G loss: 1.339820]\n",
      "epoch:47 step:36959[D loss: 0.381542, acc: 64.06%, op_acc: 50.00%] [G loss: 1.323952]\n",
      "epoch:47 step:36960[D loss: 0.374692, acc: 67.19%, op_acc: 44.53%] [G loss: 1.208681]\n",
      "epoch:47 step:36961[D loss: 0.414146, acc: 64.06%, op_acc: 38.28%] [G loss: 1.013506]\n",
      "epoch:47 step:36962[D loss: 0.435689, acc: 59.38%, op_acc: 37.50%] [G loss: 1.191633]\n",
      "epoch:47 step:36963[D loss: 0.359039, acc: 70.31%, op_acc: 50.78%] [G loss: 1.234744]\n",
      "epoch:47 step:36964[D loss: 0.390652, acc: 71.09%, op_acc: 47.66%] [G loss: 1.077412]\n",
      "epoch:47 step:36965[D loss: 0.395357, acc: 67.19%, op_acc: 43.75%] [G loss: 1.143451]\n",
      "epoch:47 step:36966[D loss: 0.339067, acc: 77.34%, op_acc: 49.22%] [G loss: 1.223959]\n",
      "epoch:47 step:36967[D loss: 0.378983, acc: 68.75%, op_acc: 43.75%] [G loss: 1.274398]\n",
      "epoch:47 step:36968[D loss: 0.384785, acc: 67.97%, op_acc: 41.41%] [G loss: 1.207288]\n",
      "epoch:47 step:36969[D loss: 0.344478, acc: 73.44%, op_acc: 53.12%] [G loss: 1.462478]\n",
      "epoch:47 step:36970[D loss: 0.340628, acc: 75.78%, op_acc: 43.75%] [G loss: 1.454958]\n",
      "epoch:47 step:36971[D loss: 0.330293, acc: 71.88%, op_acc: 52.34%] [G loss: 1.223302]\n",
      "epoch:47 step:36972[D loss: 0.399936, acc: 62.50%, op_acc: 47.66%] [G loss: 1.013704]\n",
      "epoch:47 step:36973[D loss: 0.314126, acc: 75.78%, op_acc: 60.94%] [G loss: 1.316352]\n",
      "epoch:47 step:36974[D loss: 0.455737, acc: 51.56%, op_acc: 40.62%] [G loss: 1.104465]\n",
      "epoch:47 step:36975[D loss: 0.424483, acc: 59.38%, op_acc: 42.97%] [G loss: 0.906961]\n",
      "epoch:47 step:36976[D loss: 0.343075, acc: 72.66%, op_acc: 48.44%] [G loss: 1.093309]\n",
      "epoch:47 step:36977[D loss: 0.363237, acc: 72.66%, op_acc: 46.88%] [G loss: 1.317591]\n",
      "epoch:47 step:36978[D loss: 0.366699, acc: 75.00%, op_acc: 46.88%] [G loss: 1.069006]\n",
      "epoch:47 step:36979[D loss: 0.403538, acc: 66.41%, op_acc: 45.31%] [G loss: 1.139454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:36980[D loss: 0.521608, acc: 52.34%, op_acc: 42.19%] [G loss: 1.190128]\n",
      "epoch:47 step:36981[D loss: 0.435030, acc: 62.50%, op_acc: 42.97%] [G loss: 1.147184]\n",
      "epoch:47 step:36982[D loss: 0.398221, acc: 64.06%, op_acc: 42.97%] [G loss: 0.989658]\n",
      "epoch:47 step:36983[D loss: 0.407219, acc: 65.62%, op_acc: 42.19%] [G loss: 1.161328]\n",
      "epoch:47 step:36984[D loss: 0.413669, acc: 60.16%, op_acc: 41.41%] [G loss: 1.121285]\n",
      "epoch:47 step:36985[D loss: 0.363205, acc: 71.88%, op_acc: 48.44%] [G loss: 0.972392]\n",
      "epoch:47 step:36986[D loss: 0.419455, acc: 60.16%, op_acc: 43.75%] [G loss: 0.995409]\n",
      "epoch:47 step:36987[D loss: 0.390385, acc: 65.62%, op_acc: 46.09%] [G loss: 1.500940]\n",
      "epoch:47 step:36988[D loss: 0.383290, acc: 67.97%, op_acc: 47.66%] [G loss: 1.396006]\n",
      "epoch:47 step:36989[D loss: 0.419607, acc: 62.50%, op_acc: 50.78%] [G loss: 1.241789]\n",
      "epoch:47 step:36990[D loss: 0.360675, acc: 70.31%, op_acc: 48.44%] [G loss: 1.051415]\n",
      "epoch:47 step:36991[D loss: 0.383840, acc: 69.53%, op_acc: 50.00%] [G loss: 1.130286]\n",
      "epoch:47 step:36992[D loss: 0.348451, acc: 75.00%, op_acc: 38.28%] [G loss: 1.054686]\n",
      "epoch:47 step:36993[D loss: 0.452549, acc: 56.25%, op_acc: 37.50%] [G loss: 0.850831]\n",
      "epoch:47 step:36994[D loss: 0.366433, acc: 75.00%, op_acc: 42.19%] [G loss: 1.009043]\n",
      "epoch:47 step:36995[D loss: 0.404170, acc: 60.94%, op_acc: 42.19%] [G loss: 1.389711]\n",
      "epoch:47 step:36996[D loss: 0.357313, acc: 75.00%, op_acc: 44.53%] [G loss: 0.955602]\n",
      "epoch:47 step:36997[D loss: 0.358849, acc: 73.44%, op_acc: 45.31%] [G loss: 1.098138]\n",
      "epoch:47 step:36998[D loss: 0.393013, acc: 67.19%, op_acc: 43.75%] [G loss: 0.989776]\n",
      "epoch:47 step:36999[D loss: 0.414117, acc: 66.41%, op_acc: 38.28%] [G loss: 1.177533]\n",
      "epoch:47 step:37000[D loss: 0.336068, acc: 73.44%, op_acc: 47.66%] [G loss: 0.723883]\n",
      "epoch:47 step:37001[D loss: 0.439121, acc: 59.38%, op_acc: 39.06%] [G loss: 0.821128]\n",
      "epoch:47 step:37002[D loss: 0.366943, acc: 70.31%, op_acc: 46.09%] [G loss: 0.881580]\n",
      "epoch:47 step:37003[D loss: 0.401312, acc: 59.38%, op_acc: 46.09%] [G loss: 0.985788]\n",
      "epoch:47 step:37004[D loss: 0.362681, acc: 72.66%, op_acc: 39.06%] [G loss: 1.354268]\n",
      "epoch:47 step:37005[D loss: 0.414005, acc: 60.94%, op_acc: 42.97%] [G loss: 1.073537]\n",
      "epoch:47 step:37006[D loss: 0.326847, acc: 75.78%, op_acc: 44.53%] [G loss: 0.868437]\n",
      "epoch:47 step:37007[D loss: 0.364927, acc: 74.22%, op_acc: 48.44%] [G loss: 0.817738]\n",
      "epoch:47 step:37008[D loss: 0.419643, acc: 57.81%, op_acc: 46.09%] [G loss: 0.908872]\n",
      "epoch:47 step:37009[D loss: 0.306975, acc: 79.69%, op_acc: 52.34%] [G loss: 0.831556]\n",
      "epoch:47 step:37010[D loss: 0.372717, acc: 71.88%, op_acc: 43.75%] [G loss: 0.993894]\n",
      "epoch:47 step:37011[D loss: 0.381047, acc: 67.97%, op_acc: 43.75%] [G loss: 1.049374]\n",
      "epoch:47 step:37012[D loss: 0.415146, acc: 60.16%, op_acc: 43.75%] [G loss: 1.007645]\n",
      "epoch:47 step:37013[D loss: 0.406238, acc: 59.38%, op_acc: 39.06%] [G loss: 1.005086]\n",
      "epoch:47 step:37014[D loss: 0.386142, acc: 68.75%, op_acc: 43.75%] [G loss: 1.074367]\n",
      "epoch:47 step:37015[D loss: 0.434918, acc: 60.16%, op_acc: 41.41%] [G loss: 1.234663]\n",
      "epoch:47 step:37016[D loss: 0.417682, acc: 63.28%, op_acc: 34.38%] [G loss: 0.862025]\n",
      "epoch:47 step:37017[D loss: 0.313563, acc: 81.25%, op_acc: 41.41%] [G loss: 1.041049]\n",
      "epoch:47 step:37018[D loss: 0.333490, acc: 76.56%, op_acc: 49.22%] [G loss: 1.131072]\n",
      "epoch:47 step:37019[D loss: 0.381825, acc: 68.75%, op_acc: 48.44%] [G loss: 1.262556]\n",
      "epoch:47 step:37020[D loss: 0.387018, acc: 70.31%, op_acc: 46.88%] [G loss: 1.400903]\n",
      "epoch:47 step:37021[D loss: 0.412735, acc: 60.16%, op_acc: 46.09%] [G loss: 1.254305]\n",
      "epoch:47 step:37022[D loss: 0.419316, acc: 60.94%, op_acc: 45.31%] [G loss: 0.983009]\n",
      "epoch:47 step:37023[D loss: 0.348306, acc: 74.22%, op_acc: 42.19%] [G loss: 1.091230]\n",
      "epoch:47 step:37024[D loss: 0.451427, acc: 56.25%, op_acc: 40.62%] [G loss: 0.807628]\n",
      "epoch:47 step:37025[D loss: 0.405304, acc: 62.50%, op_acc: 39.84%] [G loss: 0.907601]\n",
      "epoch:47 step:37026[D loss: 0.416584, acc: 60.16%, op_acc: 46.88%] [G loss: 0.932299]\n",
      "epoch:47 step:37027[D loss: 0.346316, acc: 73.44%, op_acc: 44.53%] [G loss: 1.100095]\n",
      "epoch:47 step:37028[D loss: 0.398031, acc: 71.88%, op_acc: 39.06%] [G loss: 1.083282]\n",
      "epoch:47 step:37029[D loss: 0.457016, acc: 56.25%, op_acc: 49.22%] [G loss: 0.991412]\n",
      "epoch:47 step:37030[D loss: 0.448919, acc: 57.03%, op_acc: 41.41%] [G loss: 0.924121]\n",
      "epoch:47 step:37031[D loss: 0.415325, acc: 66.41%, op_acc: 39.06%] [G loss: 0.777138]\n",
      "epoch:47 step:37032[D loss: 0.432691, acc: 61.72%, op_acc: 45.31%] [G loss: 0.921438]\n",
      "epoch:47 step:37033[D loss: 0.407299, acc: 60.16%, op_acc: 48.44%] [G loss: 0.870504]\n",
      "epoch:47 step:37034[D loss: 0.331060, acc: 74.22%, op_acc: 50.00%] [G loss: 1.024012]\n",
      "epoch:47 step:37035[D loss: 0.404893, acc: 68.75%, op_acc: 48.44%] [G loss: 1.305746]\n",
      "epoch:47 step:37036[D loss: 0.397901, acc: 66.41%, op_acc: 42.19%] [G loss: 0.898709]\n",
      "epoch:47 step:37037[D loss: 0.354547, acc: 69.53%, op_acc: 52.34%] [G loss: 1.164001]\n",
      "epoch:47 step:37038[D loss: 0.354180, acc: 68.75%, op_acc: 48.44%] [G loss: 0.945997]\n",
      "epoch:47 step:37039[D loss: 0.407582, acc: 60.16%, op_acc: 41.41%] [G loss: 0.764045]\n",
      "epoch:47 step:37040[D loss: 0.377814, acc: 70.31%, op_acc: 42.97%] [G loss: 1.019345]\n",
      "epoch:47 step:37041[D loss: 0.407683, acc: 61.72%, op_acc: 41.41%] [G loss: 1.034657]\n",
      "epoch:47 step:37042[D loss: 0.379188, acc: 71.88%, op_acc: 47.66%] [G loss: 1.024656]\n",
      "epoch:47 step:37043[D loss: 0.356718, acc: 68.75%, op_acc: 47.66%] [G loss: 0.903954]\n",
      "epoch:47 step:37044[D loss: 0.377819, acc: 71.88%, op_acc: 44.53%] [G loss: 0.911971]\n",
      "epoch:47 step:37045[D loss: 0.353538, acc: 71.09%, op_acc: 46.88%] [G loss: 0.968299]\n",
      "epoch:47 step:37046[D loss: 0.403025, acc: 65.62%, op_acc: 42.19%] [G loss: 0.978104]\n",
      "epoch:47 step:37047[D loss: 0.373411, acc: 71.09%, op_acc: 53.91%] [G loss: 1.008360]\n",
      "epoch:47 step:37048[D loss: 0.345656, acc: 70.31%, op_acc: 48.44%] [G loss: 1.120988]\n",
      "epoch:47 step:37049[D loss: 0.348283, acc: 69.53%, op_acc: 48.44%] [G loss: 1.002153]\n",
      "epoch:47 step:37050[D loss: 0.376700, acc: 71.09%, op_acc: 44.53%] [G loss: 1.037902]\n",
      "epoch:47 step:37051[D loss: 0.322690, acc: 78.12%, op_acc: 53.12%] [G loss: 0.944910]\n",
      "epoch:47 step:37052[D loss: 0.400164, acc: 68.75%, op_acc: 46.09%] [G loss: 1.303400]\n",
      "epoch:47 step:37053[D loss: 0.339611, acc: 83.59%, op_acc: 42.19%] [G loss: 0.858397]\n",
      "epoch:47 step:37054[D loss: 0.332827, acc: 74.22%, op_acc: 46.88%] [G loss: 0.933716]\n",
      "epoch:47 step:37055[D loss: 0.376614, acc: 69.53%, op_acc: 42.97%] [G loss: 0.946715]\n",
      "epoch:47 step:37056[D loss: 0.360651, acc: 75.78%, op_acc: 46.88%] [G loss: 1.007888]\n",
      "epoch:47 step:37057[D loss: 0.422611, acc: 63.28%, op_acc: 43.75%] [G loss: 1.275641]\n",
      "epoch:47 step:37058[D loss: 0.403919, acc: 66.41%, op_acc: 42.97%] [G loss: 0.948157]\n",
      "epoch:47 step:37059[D loss: 0.379279, acc: 71.88%, op_acc: 46.88%] [G loss: 1.091888]\n",
      "epoch:47 step:37060[D loss: 0.359966, acc: 67.97%, op_acc: 50.00%] [G loss: 1.195613]\n",
      "epoch:47 step:37061[D loss: 0.390860, acc: 63.28%, op_acc: 46.88%] [G loss: 1.144578]\n",
      "epoch:47 step:37062[D loss: 0.423343, acc: 62.50%, op_acc: 44.53%] [G loss: 1.069360]\n",
      "epoch:47 step:37063[D loss: 0.369851, acc: 70.31%, op_acc: 48.44%] [G loss: 1.301085]\n",
      "epoch:47 step:37064[D loss: 0.426223, acc: 64.06%, op_acc: 42.97%] [G loss: 1.113392]\n",
      "epoch:47 step:37065[D loss: 0.470680, acc: 54.69%, op_acc: 35.16%] [G loss: 1.168810]\n",
      "epoch:47 step:37066[D loss: 0.392080, acc: 68.75%, op_acc: 41.41%] [G loss: 1.181892]\n",
      "epoch:47 step:37067[D loss: 0.400284, acc: 68.75%, op_acc: 40.62%] [G loss: 1.087818]\n",
      "epoch:47 step:37068[D loss: 0.329688, acc: 75.00%, op_acc: 52.34%] [G loss: 1.220846]\n",
      "epoch:47 step:37069[D loss: 0.321638, acc: 77.34%, op_acc: 52.34%] [G loss: 1.182773]\n",
      "epoch:47 step:37070[D loss: 0.388129, acc: 64.84%, op_acc: 50.00%] [G loss: 1.023822]\n",
      "epoch:47 step:37071[D loss: 0.373240, acc: 71.88%, op_acc: 45.31%] [G loss: 1.199047]\n",
      "epoch:47 step:37072[D loss: 0.315612, acc: 75.00%, op_acc: 58.59%] [G loss: 1.183170]\n",
      "epoch:47 step:37073[D loss: 0.351608, acc: 75.00%, op_acc: 50.78%] [G loss: 1.206834]\n",
      "epoch:47 step:37074[D loss: 0.417956, acc: 63.28%, op_acc: 45.31%] [G loss: 1.038600]\n",
      "epoch:47 step:37075[D loss: 0.412351, acc: 67.19%, op_acc: 39.84%] [G loss: 1.031526]\n",
      "epoch:47 step:37076[D loss: 0.359298, acc: 73.44%, op_acc: 48.44%] [G loss: 1.470746]\n",
      "epoch:47 step:37077[D loss: 0.360851, acc: 75.78%, op_acc: 46.88%] [G loss: 1.121684]\n",
      "epoch:47 step:37078[D loss: 0.344594, acc: 73.44%, op_acc: 49.22%] [G loss: 1.187577]\n",
      "epoch:47 step:37079[D loss: 0.391387, acc: 64.06%, op_acc: 42.97%] [G loss: 1.041512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37080[D loss: 0.420121, acc: 55.47%, op_acc: 45.31%] [G loss: 1.166245]\n",
      "epoch:47 step:37081[D loss: 0.355811, acc: 73.44%, op_acc: 40.62%] [G loss: 0.933284]\n",
      "epoch:47 step:37082[D loss: 0.386417, acc: 65.62%, op_acc: 39.84%] [G loss: 1.011864]\n",
      "epoch:47 step:37083[D loss: 0.376155, acc: 71.09%, op_acc: 39.84%] [G loss: 1.087761]\n",
      "epoch:47 step:37084[D loss: 0.426874, acc: 61.72%, op_acc: 43.75%] [G loss: 0.875327]\n",
      "epoch:47 step:37085[D loss: 0.375322, acc: 71.88%, op_acc: 44.53%] [G loss: 1.093089]\n",
      "epoch:47 step:37086[D loss: 0.326964, acc: 78.12%, op_acc: 53.12%] [G loss: 1.196986]\n",
      "epoch:47 step:37087[D loss: 0.371708, acc: 71.09%, op_acc: 42.97%] [G loss: 0.838384]\n",
      "epoch:47 step:37088[D loss: 0.376461, acc: 75.78%, op_acc: 44.53%] [G loss: 1.038815]\n",
      "epoch:47 step:37089[D loss: 0.387648, acc: 68.75%, op_acc: 47.66%] [G loss: 1.148242]\n",
      "epoch:47 step:37090[D loss: 0.346877, acc: 71.88%, op_acc: 53.12%] [G loss: 1.091491]\n",
      "epoch:47 step:37091[D loss: 0.401362, acc: 66.41%, op_acc: 39.06%] [G loss: 1.003807]\n",
      "epoch:47 step:37092[D loss: 0.334680, acc: 75.00%, op_acc: 49.22%] [G loss: 1.156869]\n",
      "epoch:47 step:37093[D loss: 0.384998, acc: 62.50%, op_acc: 46.09%] [G loss: 0.918074]\n",
      "epoch:47 step:37094[D loss: 0.425794, acc: 59.38%, op_acc: 45.31%] [G loss: 0.856704]\n",
      "epoch:47 step:37095[D loss: 0.368184, acc: 73.44%, op_acc: 37.50%] [G loss: 0.788971]\n",
      "epoch:47 step:37096[D loss: 0.363748, acc: 70.31%, op_acc: 46.88%] [G loss: 1.279730]\n",
      "epoch:47 step:37097[D loss: 0.309841, acc: 83.59%, op_acc: 48.44%] [G loss: 0.980800]\n",
      "epoch:47 step:37098[D loss: 0.383253, acc: 61.72%, op_acc: 50.00%] [G loss: 1.297534]\n",
      "epoch:47 step:37099[D loss: 0.425316, acc: 60.94%, op_acc: 42.97%] [G loss: 1.029437]\n",
      "epoch:47 step:37100[D loss: 0.414705, acc: 59.38%, op_acc: 44.53%] [G loss: 0.971999]\n",
      "epoch:47 step:37101[D loss: 0.375521, acc: 73.44%, op_acc: 43.75%] [G loss: 1.284179]\n",
      "epoch:47 step:37102[D loss: 0.405273, acc: 68.75%, op_acc: 37.50%] [G loss: 1.061295]\n",
      "epoch:47 step:37103[D loss: 0.353755, acc: 68.75%, op_acc: 47.66%] [G loss: 0.970034]\n",
      "epoch:47 step:37104[D loss: 0.362299, acc: 70.31%, op_acc: 52.34%] [G loss: 1.126460]\n",
      "epoch:47 step:37105[D loss: 0.442775, acc: 60.16%, op_acc: 41.41%] [G loss: 0.949894]\n",
      "epoch:47 step:37106[D loss: 0.398436, acc: 64.06%, op_acc: 43.75%] [G loss: 1.056708]\n",
      "epoch:47 step:37107[D loss: 0.343556, acc: 71.09%, op_acc: 48.44%] [G loss: 1.355039]\n",
      "epoch:47 step:37108[D loss: 0.301632, acc: 76.56%, op_acc: 53.12%] [G loss: 1.198032]\n",
      "epoch:47 step:37109[D loss: 0.384541, acc: 69.53%, op_acc: 52.34%] [G loss: 1.363378]\n",
      "epoch:47 step:37110[D loss: 0.341750, acc: 74.22%, op_acc: 42.97%] [G loss: 1.577538]\n",
      "epoch:47 step:37111[D loss: 0.343177, acc: 71.09%, op_acc: 46.09%] [G loss: 1.270445]\n",
      "epoch:47 step:37112[D loss: 0.400905, acc: 71.09%, op_acc: 53.12%] [G loss: 1.104029]\n",
      "epoch:47 step:37113[D loss: 0.422095, acc: 58.59%, op_acc: 43.75%] [G loss: 1.035766]\n",
      "epoch:47 step:37114[D loss: 0.372551, acc: 68.75%, op_acc: 50.00%] [G loss: 1.152740]\n",
      "epoch:47 step:37115[D loss: 0.418152, acc: 59.38%, op_acc: 50.78%] [G loss: 1.126251]\n",
      "epoch:47 step:37116[D loss: 0.420774, acc: 61.72%, op_acc: 43.75%] [G loss: 1.136768]\n",
      "epoch:47 step:37117[D loss: 0.386023, acc: 64.06%, op_acc: 50.78%] [G loss: 1.060560]\n",
      "epoch:47 step:37118[D loss: 0.467344, acc: 52.34%, op_acc: 37.50%] [G loss: 1.090922]\n",
      "epoch:47 step:37119[D loss: 0.386848, acc: 68.75%, op_acc: 38.28%] [G loss: 1.135931]\n",
      "epoch:47 step:37120[D loss: 0.385596, acc: 69.53%, op_acc: 47.66%] [G loss: 1.109038]\n",
      "epoch:47 step:37121[D loss: 0.302970, acc: 81.25%, op_acc: 50.00%] [G loss: 1.195470]\n",
      "epoch:47 step:37122[D loss: 0.388365, acc: 66.41%, op_acc: 45.31%] [G loss: 1.201773]\n",
      "epoch:47 step:37123[D loss: 0.377618, acc: 71.09%, op_acc: 50.78%] [G loss: 1.184767]\n",
      "epoch:47 step:37124[D loss: 0.368848, acc: 75.78%, op_acc: 48.44%] [G loss: 1.056582]\n",
      "epoch:47 step:37125[D loss: 0.373265, acc: 72.66%, op_acc: 43.75%] [G loss: 1.210484]\n",
      "epoch:47 step:37126[D loss: 0.360731, acc: 75.78%, op_acc: 45.31%] [G loss: 0.999181]\n",
      "epoch:47 step:37127[D loss: 0.402156, acc: 65.62%, op_acc: 50.00%] [G loss: 0.954037]\n",
      "epoch:47 step:37128[D loss: 0.410559, acc: 61.72%, op_acc: 45.31%] [G loss: 1.191055]\n",
      "epoch:47 step:37129[D loss: 0.372490, acc: 68.75%, op_acc: 45.31%] [G loss: 1.099533]\n",
      "epoch:47 step:37130[D loss: 0.405584, acc: 65.62%, op_acc: 44.53%] [G loss: 0.993624]\n",
      "epoch:47 step:37131[D loss: 0.392770, acc: 67.97%, op_acc: 42.19%] [G loss: 1.050964]\n",
      "epoch:47 step:37132[D loss: 0.423840, acc: 57.81%, op_acc: 42.19%] [G loss: 0.997173]\n",
      "epoch:47 step:37133[D loss: 0.332278, acc: 78.12%, op_acc: 47.66%] [G loss: 0.837426]\n",
      "epoch:47 step:37134[D loss: 0.379013, acc: 65.62%, op_acc: 44.53%] [G loss: 1.136141]\n",
      "epoch:47 step:37135[D loss: 0.453055, acc: 53.91%, op_acc: 36.72%] [G loss: 0.958104]\n",
      "epoch:47 step:37136[D loss: 0.354432, acc: 71.88%, op_acc: 48.44%] [G loss: 0.979384]\n",
      "epoch:47 step:37137[D loss: 0.401052, acc: 65.62%, op_acc: 39.06%] [G loss: 1.127328]\n",
      "epoch:47 step:37138[D loss: 0.438812, acc: 59.38%, op_acc: 42.97%] [G loss: 1.310572]\n",
      "epoch:47 step:37139[D loss: 0.319770, acc: 75.00%, op_acc: 50.00%] [G loss: 0.973385]\n",
      "epoch:47 step:37140[D loss: 0.364138, acc: 69.53%, op_acc: 50.00%] [G loss: 1.054526]\n",
      "epoch:47 step:37141[D loss: 0.420156, acc: 59.38%, op_acc: 50.00%] [G loss: 1.153613]\n",
      "epoch:47 step:37142[D loss: 0.395329, acc: 66.41%, op_acc: 50.00%] [G loss: 1.383553]\n",
      "epoch:47 step:37143[D loss: 0.454111, acc: 58.59%, op_acc: 45.31%] [G loss: 1.180439]\n",
      "epoch:47 step:37144[D loss: 0.429846, acc: 53.12%, op_acc: 40.62%] [G loss: 1.275334]\n",
      "epoch:47 step:37145[D loss: 0.378836, acc: 67.19%, op_acc: 47.66%] [G loss: 1.249065]\n",
      "epoch:47 step:37146[D loss: 0.348902, acc: 75.00%, op_acc: 43.75%] [G loss: 1.152898]\n",
      "epoch:47 step:37147[D loss: 0.347442, acc: 76.56%, op_acc: 46.09%] [G loss: 1.024797]\n",
      "epoch:47 step:37148[D loss: 0.327015, acc: 81.25%, op_acc: 43.75%] [G loss: 1.084847]\n",
      "epoch:47 step:37149[D loss: 0.352779, acc: 75.00%, op_acc: 50.00%] [G loss: 0.843833]\n",
      "epoch:47 step:37150[D loss: 0.384605, acc: 69.53%, op_acc: 46.09%] [G loss: 1.341329]\n",
      "epoch:47 step:37151[D loss: 0.336131, acc: 68.75%, op_acc: 47.66%] [G loss: 1.114119]\n",
      "epoch:47 step:37152[D loss: 0.396060, acc: 62.50%, op_acc: 53.12%] [G loss: 1.036530]\n",
      "epoch:47 step:37153[D loss: 0.366166, acc: 72.66%, op_acc: 44.53%] [G loss: 0.873465]\n",
      "epoch:47 step:37154[D loss: 0.384230, acc: 71.88%, op_acc: 41.41%] [G loss: 0.962794]\n",
      "epoch:47 step:37155[D loss: 0.335709, acc: 77.34%, op_acc: 44.53%] [G loss: 1.044076]\n",
      "epoch:47 step:37156[D loss: 0.356115, acc: 70.31%, op_acc: 48.44%] [G loss: 1.027817]\n",
      "epoch:47 step:37157[D loss: 0.359560, acc: 70.31%, op_acc: 43.75%] [G loss: 1.101672]\n",
      "epoch:47 step:37158[D loss: 0.404383, acc: 61.72%, op_acc: 52.34%] [G loss: 0.990588]\n",
      "epoch:47 step:37159[D loss: 0.333743, acc: 78.12%, op_acc: 50.00%] [G loss: 1.209347]\n",
      "epoch:47 step:37160[D loss: 0.318901, acc: 76.56%, op_acc: 50.00%] [G loss: 1.249212]\n",
      "epoch:47 step:37161[D loss: 0.404033, acc: 63.28%, op_acc: 41.41%] [G loss: 1.088870]\n",
      "epoch:47 step:37162[D loss: 0.455598, acc: 59.38%, op_acc: 46.09%] [G loss: 1.115370]\n",
      "epoch:47 step:37163[D loss: 0.456031, acc: 56.25%, op_acc: 30.47%] [G loss: 1.179552]\n",
      "epoch:47 step:37164[D loss: 0.406110, acc: 66.41%, op_acc: 42.97%] [G loss: 0.939136]\n",
      "epoch:47 step:37165[D loss: 0.404258, acc: 60.16%, op_acc: 42.97%] [G loss: 1.177490]\n",
      "epoch:47 step:37166[D loss: 0.378070, acc: 67.19%, op_acc: 47.66%] [G loss: 0.978770]\n",
      "epoch:47 step:37167[D loss: 0.290450, acc: 81.25%, op_acc: 50.78%] [G loss: 1.096399]\n",
      "epoch:47 step:37168[D loss: 0.414940, acc: 60.94%, op_acc: 45.31%] [G loss: 1.059617]\n",
      "epoch:47 step:37169[D loss: 0.368428, acc: 70.31%, op_acc: 42.19%] [G loss: 1.197491]\n",
      "epoch:47 step:37170[D loss: 0.432472, acc: 57.03%, op_acc: 47.66%] [G loss: 1.141834]\n",
      "epoch:47 step:37171[D loss: 0.383909, acc: 68.75%, op_acc: 46.88%] [G loss: 1.158729]\n",
      "epoch:47 step:37172[D loss: 0.345293, acc: 71.88%, op_acc: 46.88%] [G loss: 1.137268]\n",
      "epoch:47 step:37173[D loss: 0.283133, acc: 84.38%, op_acc: 49.22%] [G loss: 1.422421]\n",
      "epoch:47 step:37174[D loss: 0.397064, acc: 67.19%, op_acc: 44.53%] [G loss: 1.236633]\n",
      "epoch:47 step:37175[D loss: 0.323774, acc: 74.22%, op_acc: 53.91%] [G loss: 1.204167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37176[D loss: 0.233091, acc: 90.62%, op_acc: 51.56%] [G loss: 1.274698]\n",
      "epoch:47 step:37177[D loss: 0.313620, acc: 78.12%, op_acc: 46.88%] [G loss: 1.379899]\n",
      "epoch:47 step:37178[D loss: 0.314614, acc: 79.69%, op_acc: 46.88%] [G loss: 1.389667]\n",
      "epoch:47 step:37179[D loss: 0.326276, acc: 75.00%, op_acc: 50.00%] [G loss: 1.397875]\n",
      "epoch:47 step:37180[D loss: 0.326825, acc: 78.91%, op_acc: 50.00%] [G loss: 1.155982]\n",
      "epoch:47 step:37181[D loss: 0.344915, acc: 71.09%, op_acc: 46.88%] [G loss: 1.405329]\n",
      "epoch:47 step:37182[D loss: 0.405475, acc: 65.62%, op_acc: 46.88%] [G loss: 0.931837]\n",
      "epoch:47 step:37183[D loss: 0.383965, acc: 71.88%, op_acc: 42.97%] [G loss: 1.326231]\n",
      "epoch:47 step:37184[D loss: 0.390617, acc: 71.88%, op_acc: 47.66%] [G loss: 1.322209]\n",
      "epoch:47 step:37185[D loss: 0.367929, acc: 69.53%, op_acc: 47.66%] [G loss: 1.318722]\n",
      "epoch:47 step:37186[D loss: 0.341498, acc: 73.44%, op_acc: 50.00%] [G loss: 1.484394]\n",
      "epoch:47 step:37187[D loss: 0.413457, acc: 66.41%, op_acc: 47.66%] [G loss: 1.481450]\n",
      "epoch:47 step:37188[D loss: 0.516576, acc: 54.69%, op_acc: 32.81%] [G loss: 1.256207]\n",
      "epoch:47 step:37189[D loss: 0.328437, acc: 75.00%, op_acc: 51.56%] [G loss: 0.994483]\n",
      "epoch:47 step:37190[D loss: 0.349757, acc: 73.44%, op_acc: 44.53%] [G loss: 1.611377]\n",
      "epoch:47 step:37191[D loss: 0.358301, acc: 64.84%, op_acc: 44.53%] [G loss: 1.380757]\n",
      "epoch:47 step:37192[D loss: 0.360712, acc: 76.56%, op_acc: 37.50%] [G loss: 1.502494]\n",
      "epoch:47 step:37193[D loss: 0.346219, acc: 69.53%, op_acc: 52.34%] [G loss: 1.483430]\n",
      "epoch:47 step:37194[D loss: 0.427386, acc: 67.19%, op_acc: 42.19%] [G loss: 1.290494]\n",
      "epoch:47 step:37195[D loss: 0.397060, acc: 67.97%, op_acc: 38.28%] [G loss: 1.265131]\n",
      "epoch:47 step:37196[D loss: 0.381772, acc: 66.41%, op_acc: 46.88%] [G loss: 1.427944]\n",
      "epoch:47 step:37197[D loss: 0.338926, acc: 77.34%, op_acc: 42.97%] [G loss: 1.294624]\n",
      "epoch:47 step:37198[D loss: 0.419637, acc: 64.06%, op_acc: 45.31%] [G loss: 1.352850]\n",
      "epoch:47 step:37199[D loss: 0.351841, acc: 71.09%, op_acc: 45.31%] [G loss: 1.342561]\n",
      "epoch:47 step:37200[D loss: 0.477895, acc: 51.56%, op_acc: 46.09%] [G loss: 0.705783]\n",
      "epoch:47 step:37201[D loss: 0.383175, acc: 67.19%, op_acc: 42.97%] [G loss: 1.200192]\n",
      "epoch:47 step:37202[D loss: 0.366289, acc: 68.75%, op_acc: 47.66%] [G loss: 1.301141]\n",
      "epoch:47 step:37203[D loss: 0.350022, acc: 73.44%, op_acc: 46.09%] [G loss: 1.060137]\n",
      "epoch:47 step:37204[D loss: 0.334717, acc: 76.56%, op_acc: 46.88%] [G loss: 1.419520]\n",
      "epoch:47 step:37205[D loss: 0.410575, acc: 61.72%, op_acc: 45.31%] [G loss: 1.066499]\n",
      "epoch:47 step:37206[D loss: 0.410079, acc: 64.84%, op_acc: 39.84%] [G loss: 1.149482]\n",
      "epoch:47 step:37207[D loss: 0.411831, acc: 62.50%, op_acc: 42.19%] [G loss: 1.355182]\n",
      "epoch:47 step:37208[D loss: 0.413636, acc: 60.94%, op_acc: 40.62%] [G loss: 1.202211]\n",
      "epoch:47 step:37209[D loss: 0.353276, acc: 71.88%, op_acc: 42.97%] [G loss: 1.063448]\n",
      "epoch:47 step:37210[D loss: 0.436942, acc: 62.50%, op_acc: 45.31%] [G loss: 1.159122]\n",
      "epoch:47 step:37211[D loss: 0.381846, acc: 74.22%, op_acc: 50.00%] [G loss: 1.406102]\n",
      "epoch:47 step:37212[D loss: 0.388244, acc: 68.75%, op_acc: 42.97%] [G loss: 1.149771]\n",
      "epoch:47 step:37213[D loss: 0.400031, acc: 61.72%, op_acc: 43.75%] [G loss: 1.066166]\n",
      "epoch:47 step:37214[D loss: 0.372025, acc: 66.41%, op_acc: 53.12%] [G loss: 1.163334]\n",
      "epoch:47 step:37215[D loss: 0.407536, acc: 66.41%, op_acc: 39.06%] [G loss: 0.946145]\n",
      "epoch:47 step:37216[D loss: 0.412712, acc: 63.28%, op_acc: 45.31%] [G loss: 1.150431]\n",
      "epoch:47 step:37217[D loss: 0.402029, acc: 69.53%, op_acc: 43.75%] [G loss: 1.123870]\n",
      "epoch:47 step:37218[D loss: 0.378705, acc: 69.53%, op_acc: 52.34%] [G loss: 1.325326]\n",
      "epoch:47 step:37219[D loss: 0.432601, acc: 62.50%, op_acc: 44.53%] [G loss: 0.943110]\n",
      "epoch:47 step:37220[D loss: 0.485326, acc: 57.81%, op_acc: 35.94%] [G loss: 1.139644]\n",
      "epoch:47 step:37221[D loss: 0.381220, acc: 68.75%, op_acc: 50.00%] [G loss: 1.018126]\n",
      "epoch:47 step:37222[D loss: 0.360007, acc: 68.75%, op_acc: 48.44%] [G loss: 1.157192]\n",
      "epoch:47 step:37223[D loss: 0.403918, acc: 63.28%, op_acc: 50.78%] [G loss: 1.290813]\n",
      "epoch:47 step:37224[D loss: 0.428859, acc: 67.97%, op_acc: 36.72%] [G loss: 1.153954]\n",
      "epoch:47 step:37225[D loss: 0.372019, acc: 72.66%, op_acc: 52.34%] [G loss: 1.084581]\n",
      "epoch:47 step:37226[D loss: 0.329299, acc: 75.78%, op_acc: 45.31%] [G loss: 1.085011]\n",
      "epoch:47 step:37227[D loss: 0.379875, acc: 64.06%, op_acc: 54.69%] [G loss: 1.115931]\n",
      "epoch:47 step:37228[D loss: 0.362380, acc: 70.31%, op_acc: 51.56%] [G loss: 1.116782]\n",
      "epoch:47 step:37229[D loss: 0.434977, acc: 53.91%, op_acc: 50.00%] [G loss: 1.066746]\n",
      "epoch:47 step:37230[D loss: 0.438565, acc: 59.38%, op_acc: 45.31%] [G loss: 1.005337]\n",
      "epoch:47 step:37231[D loss: 0.412301, acc: 69.53%, op_acc: 45.31%] [G loss: 1.134554]\n",
      "epoch:47 step:37232[D loss: 0.345402, acc: 78.12%, op_acc: 39.84%] [G loss: 1.083330]\n",
      "epoch:47 step:37233[D loss: 0.398720, acc: 68.75%, op_acc: 45.31%] [G loss: 1.052000]\n",
      "epoch:47 step:37234[D loss: 0.385960, acc: 67.19%, op_acc: 45.31%] [G loss: 1.318406]\n",
      "epoch:47 step:37235[D loss: 0.345382, acc: 76.56%, op_acc: 47.66%] [G loss: 1.080812]\n",
      "epoch:47 step:37236[D loss: 0.340523, acc: 69.53%, op_acc: 55.47%] [G loss: 0.992681]\n",
      "epoch:47 step:37237[D loss: 0.366705, acc: 70.31%, op_acc: 48.44%] [G loss: 1.386593]\n",
      "epoch:47 step:37238[D loss: 0.408917, acc: 66.41%, op_acc: 38.28%] [G loss: 0.966653]\n",
      "epoch:47 step:37239[D loss: 0.364943, acc: 70.31%, op_acc: 41.41%] [G loss: 0.837957]\n",
      "epoch:47 step:37240[D loss: 0.386160, acc: 72.66%, op_acc: 49.22%] [G loss: 1.042981]\n",
      "epoch:47 step:37241[D loss: 0.407128, acc: 65.62%, op_acc: 47.66%] [G loss: 1.043966]\n",
      "epoch:47 step:37242[D loss: 0.324576, acc: 77.34%, op_acc: 43.75%] [G loss: 1.323618]\n",
      "epoch:47 step:37243[D loss: 0.371527, acc: 67.19%, op_acc: 57.81%] [G loss: 1.146001]\n",
      "epoch:47 step:37244[D loss: 0.401898, acc: 71.09%, op_acc: 43.75%] [G loss: 1.117713]\n",
      "epoch:47 step:37245[D loss: 0.415152, acc: 64.06%, op_acc: 39.84%] [G loss: 1.082688]\n",
      "epoch:47 step:37246[D loss: 0.414475, acc: 65.62%, op_acc: 42.97%] [G loss: 1.060056]\n",
      "epoch:47 step:37247[D loss: 0.376069, acc: 64.84%, op_acc: 46.88%] [G loss: 0.819293]\n",
      "epoch:47 step:37248[D loss: 0.371332, acc: 67.19%, op_acc: 47.66%] [G loss: 1.144683]\n",
      "epoch:47 step:37249[D loss: 0.349181, acc: 72.66%, op_acc: 52.34%] [G loss: 0.929721]\n",
      "epoch:47 step:37250[D loss: 0.417111, acc: 65.62%, op_acc: 42.19%] [G loss: 1.542486]\n",
      "epoch:47 step:37251[D loss: 0.373897, acc: 69.53%, op_acc: 44.53%] [G loss: 1.165891]\n",
      "epoch:47 step:37252[D loss: 0.291282, acc: 81.25%, op_acc: 47.66%] [G loss: 1.389609]\n",
      "epoch:47 step:37253[D loss: 0.429362, acc: 61.72%, op_acc: 42.97%] [G loss: 1.417259]\n",
      "epoch:47 step:37254[D loss: 0.380310, acc: 66.41%, op_acc: 49.22%] [G loss: 1.270480]\n",
      "epoch:47 step:37255[D loss: 0.436051, acc: 62.50%, op_acc: 44.53%] [G loss: 1.169232]\n",
      "epoch:47 step:37256[D loss: 0.397858, acc: 64.84%, op_acc: 45.31%] [G loss: 1.104395]\n",
      "epoch:47 step:37257[D loss: 0.378746, acc: 72.66%, op_acc: 43.75%] [G loss: 1.251351]\n",
      "epoch:47 step:37258[D loss: 0.357837, acc: 70.31%, op_acc: 46.09%] [G loss: 1.151891]\n",
      "epoch:47 step:37259[D loss: 0.462195, acc: 53.12%, op_acc: 30.47%] [G loss: 1.231494]\n",
      "epoch:47 step:37260[D loss: 0.325016, acc: 82.03%, op_acc: 50.78%] [G loss: 1.198975]\n",
      "epoch:47 step:37261[D loss: 0.422955, acc: 64.06%, op_acc: 47.66%] [G loss: 1.122395]\n",
      "epoch:47 step:37262[D loss: 0.342862, acc: 75.00%, op_acc: 39.84%] [G loss: 1.145788]\n",
      "epoch:47 step:37263[D loss: 0.411052, acc: 64.84%, op_acc: 42.19%] [G loss: 1.103890]\n",
      "epoch:47 step:37264[D loss: 0.382122, acc: 66.41%, op_acc: 42.97%] [G loss: 1.111330]\n",
      "epoch:47 step:37265[D loss: 0.369756, acc: 67.19%, op_acc: 49.22%] [G loss: 0.971856]\n",
      "epoch:47 step:37266[D loss: 0.354351, acc: 75.78%, op_acc: 46.88%] [G loss: 1.128095]\n",
      "epoch:47 step:37267[D loss: 0.355026, acc: 75.78%, op_acc: 42.19%] [G loss: 1.219886]\n",
      "epoch:47 step:37268[D loss: 0.364011, acc: 74.22%, op_acc: 42.19%] [G loss: 1.461499]\n",
      "epoch:47 step:37269[D loss: 0.347064, acc: 72.66%, op_acc: 46.09%] [G loss: 1.192595]\n",
      "epoch:47 step:37270[D loss: 0.358028, acc: 72.66%, op_acc: 46.88%] [G loss: 1.241820]\n",
      "epoch:47 step:37271[D loss: 0.429193, acc: 60.94%, op_acc: 49.22%] [G loss: 0.978651]\n",
      "epoch:47 step:37272[D loss: 0.352744, acc: 69.53%, op_acc: 44.53%] [G loss: 1.288458]\n",
      "epoch:47 step:37273[D loss: 0.394792, acc: 65.62%, op_acc: 42.97%] [G loss: 1.225386]\n",
      "epoch:47 step:37274[D loss: 0.393382, acc: 63.28%, op_acc: 47.66%] [G loss: 1.335811]\n",
      "epoch:47 step:37275[D loss: 0.351985, acc: 70.31%, op_acc: 53.12%] [G loss: 1.040113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37276[D loss: 0.394596, acc: 63.28%, op_acc: 48.44%] [G loss: 1.132070]\n",
      "epoch:47 step:37277[D loss: 0.381583, acc: 67.19%, op_acc: 45.31%] [G loss: 1.127150]\n",
      "epoch:47 step:37278[D loss: 0.406902, acc: 64.84%, op_acc: 43.75%] [G loss: 1.031113]\n",
      "epoch:47 step:37279[D loss: 0.377714, acc: 69.53%, op_acc: 40.62%] [G loss: 1.150984]\n",
      "epoch:47 step:37280[D loss: 0.385493, acc: 66.41%, op_acc: 45.31%] [G loss: 1.069202]\n",
      "epoch:47 step:37281[D loss: 0.359315, acc: 74.22%, op_acc: 50.00%] [G loss: 1.139055]\n",
      "epoch:47 step:37282[D loss: 0.412406, acc: 64.06%, op_acc: 49.22%] [G loss: 1.177095]\n",
      "epoch:47 step:37283[D loss: 0.387466, acc: 67.97%, op_acc: 44.53%] [G loss: 1.285185]\n",
      "epoch:47 step:37284[D loss: 0.376452, acc: 69.53%, op_acc: 47.66%] [G loss: 1.244041]\n",
      "epoch:47 step:37285[D loss: 0.486733, acc: 57.03%, op_acc: 34.38%] [G loss: 1.170229]\n",
      "epoch:47 step:37286[D loss: 0.309600, acc: 74.22%, op_acc: 51.56%] [G loss: 1.194021]\n",
      "epoch:47 step:37287[D loss: 0.401423, acc: 68.75%, op_acc: 51.56%] [G loss: 1.217259]\n",
      "epoch:47 step:37288[D loss: 0.377119, acc: 67.19%, op_acc: 45.31%] [G loss: 1.243417]\n",
      "epoch:47 step:37289[D loss: 0.384357, acc: 69.53%, op_acc: 39.84%] [G loss: 1.040799]\n",
      "epoch:47 step:37290[D loss: 0.375332, acc: 68.75%, op_acc: 34.38%] [G loss: 1.168992]\n",
      "epoch:47 step:37291[D loss: 0.450859, acc: 59.38%, op_acc: 33.59%] [G loss: 0.996952]\n",
      "epoch:47 step:37292[D loss: 0.330173, acc: 76.56%, op_acc: 43.75%] [G loss: 1.040239]\n",
      "epoch:47 step:37293[D loss: 0.362042, acc: 72.66%, op_acc: 45.31%] [G loss: 1.115534]\n",
      "epoch:47 step:37294[D loss: 0.317435, acc: 82.81%, op_acc: 43.75%] [G loss: 0.998305]\n",
      "epoch:47 step:37295[D loss: 0.315898, acc: 75.00%, op_acc: 48.44%] [G loss: 1.226311]\n",
      "epoch:47 step:37296[D loss: 0.379203, acc: 68.75%, op_acc: 46.09%] [G loss: 0.969841]\n",
      "epoch:47 step:37297[D loss: 0.310433, acc: 81.25%, op_acc: 48.44%] [G loss: 0.852847]\n",
      "epoch:47 step:37298[D loss: 0.395269, acc: 64.84%, op_acc: 36.72%] [G loss: 1.009356]\n",
      "epoch:47 step:37299[D loss: 0.393526, acc: 74.22%, op_acc: 47.66%] [G loss: 1.042397]\n",
      "epoch:47 step:37300[D loss: 0.387206, acc: 73.44%, op_acc: 46.09%] [G loss: 1.107080]\n",
      "epoch:47 step:37301[D loss: 0.381761, acc: 63.28%, op_acc: 46.88%] [G loss: 0.988542]\n",
      "epoch:47 step:37302[D loss: 0.334755, acc: 78.91%, op_acc: 50.00%] [G loss: 1.312546]\n",
      "epoch:47 step:37303[D loss: 0.325357, acc: 77.34%, op_acc: 54.69%] [G loss: 1.072748]\n",
      "epoch:47 step:37304[D loss: 0.361300, acc: 70.31%, op_acc: 42.19%] [G loss: 0.854735]\n",
      "epoch:47 step:37305[D loss: 0.352084, acc: 75.00%, op_acc: 48.44%] [G loss: 1.184883]\n",
      "epoch:47 step:37306[D loss: 0.369826, acc: 71.88%, op_acc: 50.00%] [G loss: 1.052573]\n",
      "epoch:47 step:37307[D loss: 0.366555, acc: 78.91%, op_acc: 42.97%] [G loss: 1.437776]\n",
      "epoch:47 step:37308[D loss: 0.434354, acc: 59.38%, op_acc: 45.31%] [G loss: 1.093371]\n",
      "epoch:47 step:37309[D loss: 0.316962, acc: 77.34%, op_acc: 51.56%] [G loss: 1.254680]\n",
      "epoch:47 step:37310[D loss: 0.346283, acc: 71.09%, op_acc: 47.66%] [G loss: 1.042315]\n",
      "epoch:47 step:37311[D loss: 0.422819, acc: 67.19%, op_acc: 40.62%] [G loss: 0.971301]\n",
      "epoch:47 step:37312[D loss: 0.374610, acc: 74.22%, op_acc: 35.94%] [G loss: 1.204546]\n",
      "epoch:47 step:37313[D loss: 0.389336, acc: 67.19%, op_acc: 42.97%] [G loss: 1.258499]\n",
      "epoch:47 step:37314[D loss: 0.350471, acc: 77.34%, op_acc: 50.00%] [G loss: 1.169202]\n",
      "epoch:47 step:37315[D loss: 0.365192, acc: 71.09%, op_acc: 47.66%] [G loss: 1.134216]\n",
      "epoch:47 step:37316[D loss: 0.402842, acc: 65.62%, op_acc: 47.66%] [G loss: 1.297648]\n",
      "epoch:47 step:37317[D loss: 0.350094, acc: 71.88%, op_acc: 52.34%] [G loss: 1.207985]\n",
      "epoch:47 step:37318[D loss: 0.402820, acc: 65.62%, op_acc: 50.78%] [G loss: 1.236527]\n",
      "epoch:47 step:37319[D loss: 0.394798, acc: 68.75%, op_acc: 42.97%] [G loss: 0.997060]\n",
      "epoch:47 step:37320[D loss: 0.382572, acc: 69.53%, op_acc: 49.22%] [G loss: 0.921568]\n",
      "epoch:47 step:37321[D loss: 0.328477, acc: 75.78%, op_acc: 50.78%] [G loss: 1.082436]\n",
      "epoch:47 step:37322[D loss: 0.330267, acc: 82.03%, op_acc: 46.09%] [G loss: 1.257095]\n",
      "epoch:47 step:37323[D loss: 0.410257, acc: 58.59%, op_acc: 46.09%] [G loss: 1.270096]\n",
      "epoch:47 step:37324[D loss: 0.444567, acc: 58.59%, op_acc: 40.62%] [G loss: 1.217580]\n",
      "epoch:47 step:37325[D loss: 0.342550, acc: 78.91%, op_acc: 50.00%] [G loss: 1.084443]\n",
      "epoch:47 step:37326[D loss: 0.360043, acc: 73.44%, op_acc: 48.44%] [G loss: 1.206632]\n",
      "epoch:47 step:37327[D loss: 0.353032, acc: 69.53%, op_acc: 46.09%] [G loss: 0.887896]\n",
      "epoch:47 step:37328[D loss: 0.344457, acc: 80.47%, op_acc: 52.34%] [G loss: 1.251453]\n",
      "epoch:47 step:37329[D loss: 0.350476, acc: 72.66%, op_acc: 48.44%] [G loss: 1.260575]\n",
      "epoch:47 step:37330[D loss: 0.363955, acc: 70.31%, op_acc: 46.09%] [G loss: 1.339523]\n",
      "epoch:47 step:37331[D loss: 0.384586, acc: 71.88%, op_acc: 46.09%] [G loss: 1.277985]\n",
      "epoch:47 step:37332[D loss: 0.369252, acc: 71.88%, op_acc: 49.22%] [G loss: 0.865647]\n",
      "epoch:47 step:37333[D loss: 0.337065, acc: 74.22%, op_acc: 50.00%] [G loss: 1.274419]\n",
      "epoch:47 step:37334[D loss: 0.396541, acc: 67.97%, op_acc: 42.97%] [G loss: 0.815433]\n",
      "epoch:47 step:37335[D loss: 0.357752, acc: 73.44%, op_acc: 43.75%] [G loss: 1.036167]\n",
      "epoch:47 step:37336[D loss: 0.351279, acc: 75.78%, op_acc: 47.66%] [G loss: 0.952865]\n",
      "epoch:47 step:37337[D loss: 0.384169, acc: 64.84%, op_acc: 42.19%] [G loss: 1.207051]\n",
      "epoch:47 step:37338[D loss: 0.420646, acc: 64.06%, op_acc: 39.84%] [G loss: 1.015778]\n",
      "epoch:47 step:37339[D loss: 0.425825, acc: 60.16%, op_acc: 38.28%] [G loss: 1.021603]\n",
      "epoch:47 step:37340[D loss: 0.407045, acc: 59.38%, op_acc: 43.75%] [G loss: 1.038088]\n",
      "epoch:47 step:37341[D loss: 0.343755, acc: 69.53%, op_acc: 44.53%] [G loss: 1.067087]\n",
      "epoch:47 step:37342[D loss: 0.392364, acc: 66.41%, op_acc: 48.44%] [G loss: 1.155541]\n",
      "epoch:47 step:37343[D loss: 0.396403, acc: 66.41%, op_acc: 43.75%] [G loss: 1.227944]\n",
      "epoch:47 step:37344[D loss: 0.360514, acc: 71.88%, op_acc: 45.31%] [G loss: 1.310478]\n",
      "epoch:47 step:37345[D loss: 0.385524, acc: 68.75%, op_acc: 49.22%] [G loss: 1.107750]\n",
      "epoch:47 step:37346[D loss: 0.445363, acc: 67.19%, op_acc: 38.28%] [G loss: 1.118726]\n",
      "epoch:47 step:37347[D loss: 0.443659, acc: 56.25%, op_acc: 38.28%] [G loss: 1.154178]\n",
      "epoch:47 step:37348[D loss: 0.384044, acc: 69.53%, op_acc: 46.09%] [G loss: 1.210931]\n",
      "epoch:47 step:37349[D loss: 0.406580, acc: 61.72%, op_acc: 41.41%] [G loss: 1.233209]\n",
      "epoch:47 step:37350[D loss: 0.429834, acc: 59.38%, op_acc: 43.75%] [G loss: 1.393236]\n",
      "epoch:47 step:37351[D loss: 0.368133, acc: 67.97%, op_acc: 53.12%] [G loss: 1.253034]\n",
      "epoch:47 step:37352[D loss: 0.375793, acc: 67.19%, op_acc: 45.31%] [G loss: 1.414479]\n",
      "epoch:47 step:37353[D loss: 0.343926, acc: 74.22%, op_acc: 48.44%] [G loss: 1.478155]\n",
      "epoch:47 step:37354[D loss: 0.335747, acc: 70.31%, op_acc: 64.06%] [G loss: 1.590598]\n",
      "epoch:47 step:37355[D loss: 0.326409, acc: 75.00%, op_acc: 46.88%] [G loss: 1.182754]\n",
      "epoch:47 step:37356[D loss: 0.343687, acc: 82.03%, op_acc: 42.19%] [G loss: 1.545014]\n",
      "epoch:47 step:37357[D loss: 0.459177, acc: 54.69%, op_acc: 39.84%] [G loss: 1.119187]\n",
      "epoch:47 step:37358[D loss: 0.395020, acc: 62.50%, op_acc: 43.75%] [G loss: 1.145235]\n",
      "epoch:47 step:37359[D loss: 0.390837, acc: 67.19%, op_acc: 44.53%] [G loss: 1.397465]\n",
      "epoch:47 step:37360[D loss: 0.371296, acc: 66.41%, op_acc: 46.88%] [G loss: 1.126616]\n",
      "epoch:47 step:37361[D loss: 0.387564, acc: 70.31%, op_acc: 41.41%] [G loss: 1.380221]\n",
      "epoch:47 step:37362[D loss: 0.391222, acc: 68.75%, op_acc: 39.84%] [G loss: 1.055961]\n",
      "epoch:47 step:37363[D loss: 0.400544, acc: 67.97%, op_acc: 48.44%] [G loss: 1.189957]\n",
      "epoch:47 step:37364[D loss: 0.406766, acc: 60.94%, op_acc: 45.31%] [G loss: 1.183589]\n",
      "epoch:47 step:37365[D loss: 0.322842, acc: 79.69%, op_acc: 50.00%] [G loss: 1.157601]\n",
      "epoch:47 step:37366[D loss: 0.350233, acc: 75.00%, op_acc: 50.78%] [G loss: 1.271221]\n",
      "epoch:47 step:37367[D loss: 0.427326, acc: 59.38%, op_acc: 39.84%] [G loss: 1.231436]\n",
      "epoch:47 step:37368[D loss: 0.394612, acc: 62.50%, op_acc: 47.66%] [G loss: 1.137354]\n",
      "epoch:47 step:37369[D loss: 0.398508, acc: 64.84%, op_acc: 46.09%] [G loss: 1.433129]\n",
      "epoch:47 step:37370[D loss: 0.381145, acc: 69.53%, op_acc: 49.22%] [G loss: 0.876123]\n",
      "epoch:47 step:37371[D loss: 0.373853, acc: 62.50%, op_acc: 45.31%] [G loss: 0.919392]\n",
      "epoch:47 step:37372[D loss: 0.427290, acc: 68.75%, op_acc: 32.81%] [G loss: 1.380695]\n",
      "epoch:47 step:37373[D loss: 0.385831, acc: 68.75%, op_acc: 42.97%] [G loss: 1.255304]\n",
      "epoch:47 step:37374[D loss: 0.325016, acc: 81.25%, op_acc: 48.44%] [G loss: 0.977260]\n",
      "epoch:47 step:37375[D loss: 0.352965, acc: 71.88%, op_acc: 46.09%] [G loss: 1.191312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37376[D loss: 0.394856, acc: 67.19%, op_acc: 50.78%] [G loss: 1.174462]\n",
      "epoch:47 step:37377[D loss: 0.359330, acc: 67.97%, op_acc: 46.88%] [G loss: 1.102098]\n",
      "epoch:47 step:37378[D loss: 0.395864, acc: 67.97%, op_acc: 44.53%] [G loss: 0.842498]\n",
      "epoch:47 step:37379[D loss: 0.387983, acc: 75.78%, op_acc: 39.84%] [G loss: 1.145258]\n",
      "epoch:47 step:37380[D loss: 0.383682, acc: 65.62%, op_acc: 41.41%] [G loss: 1.050076]\n",
      "epoch:47 step:37381[D loss: 0.345485, acc: 71.88%, op_acc: 47.66%] [G loss: 1.046686]\n",
      "epoch:47 step:37382[D loss: 0.406922, acc: 66.41%, op_acc: 42.19%] [G loss: 1.101315]\n",
      "epoch:47 step:37383[D loss: 0.357402, acc: 77.34%, op_acc: 42.19%] [G loss: 0.956927]\n",
      "epoch:47 step:37384[D loss: 0.460010, acc: 55.47%, op_acc: 41.41%] [G loss: 1.067015]\n",
      "epoch:47 step:37385[D loss: 0.315057, acc: 80.47%, op_acc: 44.53%] [G loss: 1.275112]\n",
      "epoch:47 step:37386[D loss: 0.417666, acc: 64.06%, op_acc: 42.97%] [G loss: 0.915486]\n",
      "epoch:47 step:37387[D loss: 0.389598, acc: 68.75%, op_acc: 43.75%] [G loss: 0.959196]\n",
      "epoch:47 step:37388[D loss: 0.386734, acc: 75.00%, op_acc: 46.09%] [G loss: 1.229003]\n",
      "epoch:47 step:37389[D loss: 0.342832, acc: 73.44%, op_acc: 50.78%] [G loss: 0.939522]\n",
      "epoch:47 step:37390[D loss: 0.377425, acc: 68.75%, op_acc: 46.88%] [G loss: 1.157527]\n",
      "epoch:47 step:37391[D loss: 0.405322, acc: 69.53%, op_acc: 42.19%] [G loss: 1.043348]\n",
      "epoch:47 step:37392[D loss: 0.362746, acc: 72.66%, op_acc: 42.19%] [G loss: 1.280606]\n",
      "epoch:47 step:37393[D loss: 0.394659, acc: 60.94%, op_acc: 57.03%] [G loss: 0.985977]\n",
      "epoch:47 step:37394[D loss: 0.302407, acc: 82.03%, op_acc: 50.78%] [G loss: 0.838797]\n",
      "epoch:47 step:37395[D loss: 0.388598, acc: 68.75%, op_acc: 47.66%] [G loss: 1.120932]\n",
      "epoch:47 step:37396[D loss: 0.415258, acc: 58.59%, op_acc: 41.41%] [G loss: 1.135076]\n",
      "epoch:47 step:37397[D loss: 0.308019, acc: 80.47%, op_acc: 46.09%] [G loss: 1.347718]\n",
      "epoch:47 step:37398[D loss: 0.363604, acc: 79.69%, op_acc: 47.66%] [G loss: 1.121564]\n",
      "epoch:47 step:37399[D loss: 0.459057, acc: 56.25%, op_acc: 47.66%] [G loss: 1.130487]\n",
      "epoch:47 step:37400[D loss: 0.382941, acc: 67.19%, op_acc: 47.66%] [G loss: 1.390390]\n",
      "epoch:47 step:37401[D loss: 0.369995, acc: 66.41%, op_acc: 47.66%] [G loss: 0.861595]\n",
      "epoch:47 step:37402[D loss: 0.414605, acc: 65.62%, op_acc: 46.09%] [G loss: 1.200902]\n",
      "epoch:47 step:37403[D loss: 0.400994, acc: 67.19%, op_acc: 43.75%] [G loss: 0.811990]\n",
      "epoch:47 step:37404[D loss: 0.347453, acc: 74.22%, op_acc: 46.09%] [G loss: 0.886330]\n",
      "epoch:47 step:37405[D loss: 0.332043, acc: 79.69%, op_acc: 51.56%] [G loss: 0.966172]\n",
      "epoch:47 step:37406[D loss: 0.358591, acc: 72.66%, op_acc: 44.53%] [G loss: 1.067566]\n",
      "epoch:47 step:37407[D loss: 0.413641, acc: 67.97%, op_acc: 39.84%] [G loss: 1.362580]\n",
      "epoch:47 step:37408[D loss: 0.426807, acc: 66.41%, op_acc: 41.41%] [G loss: 1.053952]\n",
      "epoch:47 step:37409[D loss: 0.391328, acc: 68.75%, op_acc: 49.22%] [G loss: 1.406430]\n",
      "epoch:47 step:37410[D loss: 0.418422, acc: 70.31%, op_acc: 44.53%] [G loss: 0.954557]\n",
      "epoch:47 step:37411[D loss: 0.345983, acc: 67.19%, op_acc: 57.03%] [G loss: 0.716901]\n",
      "epoch:47 step:37412[D loss: 0.425993, acc: 57.81%, op_acc: 40.62%] [G loss: 0.623998]\n",
      "epoch:47 step:37413[D loss: 0.422556, acc: 69.53%, op_acc: 44.53%] [G loss: 0.618955]\n",
      "epoch:47 step:37414[D loss: 0.456109, acc: 56.25%, op_acc: 47.66%] [G loss: 0.777405]\n",
      "epoch:47 step:37415[D loss: 0.421790, acc: 63.28%, op_acc: 34.38%] [G loss: 0.811043]\n",
      "epoch:47 step:37416[D loss: 0.368954, acc: 71.09%, op_acc: 40.62%] [G loss: 0.709865]\n",
      "epoch:47 step:37417[D loss: 0.322804, acc: 82.81%, op_acc: 44.53%] [G loss: 0.962279]\n",
      "epoch:47 step:37418[D loss: 0.383375, acc: 70.31%, op_acc: 47.66%] [G loss: 1.134889]\n",
      "epoch:47 step:37419[D loss: 0.375210, acc: 67.97%, op_acc: 57.81%] [G loss: 1.074555]\n",
      "epoch:47 step:37420[D loss: 0.373288, acc: 63.28%, op_acc: 46.09%] [G loss: 0.871293]\n",
      "epoch:47 step:37421[D loss: 0.356830, acc: 75.00%, op_acc: 35.94%] [G loss: 1.172008]\n",
      "epoch:47 step:37422[D loss: 0.344545, acc: 68.75%, op_acc: 48.44%] [G loss: 1.031006]\n",
      "epoch:47 step:37423[D loss: 0.361637, acc: 64.84%, op_acc: 46.88%] [G loss: 0.964991]\n",
      "epoch:47 step:37424[D loss: 0.348424, acc: 73.44%, op_acc: 48.44%] [G loss: 1.121409]\n",
      "epoch:47 step:37425[D loss: 0.371285, acc: 70.31%, op_acc: 45.31%] [G loss: 1.054332]\n",
      "epoch:47 step:37426[D loss: 0.294841, acc: 82.03%, op_acc: 53.91%] [G loss: 1.150222]\n",
      "epoch:47 step:37427[D loss: 0.336377, acc: 78.91%, op_acc: 46.09%] [G loss: 1.082546]\n",
      "epoch:47 step:37428[D loss: 0.383344, acc: 66.41%, op_acc: 50.00%] [G loss: 1.070248]\n",
      "epoch:47 step:37429[D loss: 0.357343, acc: 69.53%, op_acc: 45.31%] [G loss: 0.975926]\n",
      "epoch:47 step:37430[D loss: 0.399954, acc: 66.41%, op_acc: 49.22%] [G loss: 0.969044]\n",
      "epoch:47 step:37431[D loss: 0.439862, acc: 56.25%, op_acc: 42.19%] [G loss: 0.918900]\n",
      "epoch:47 step:37432[D loss: 0.422698, acc: 60.16%, op_acc: 42.97%] [G loss: 0.780660]\n",
      "epoch:47 step:37433[D loss: 0.444866, acc: 55.47%, op_acc: 38.28%] [G loss: 1.373108]\n",
      "epoch:47 step:37434[D loss: 0.472068, acc: 53.91%, op_acc: 32.81%] [G loss: 0.717452]\n",
      "epoch:47 step:37435[D loss: 0.442188, acc: 66.41%, op_acc: 32.81%] [G loss: 0.756557]\n",
      "epoch:47 step:37436[D loss: 0.346974, acc: 72.66%, op_acc: 49.22%] [G loss: 0.792745]\n",
      "epoch:47 step:37437[D loss: 0.329716, acc: 75.78%, op_acc: 41.41%] [G loss: 0.777023]\n",
      "epoch:47 step:37438[D loss: 0.310181, acc: 75.78%, op_acc: 53.12%] [G loss: 0.916266]\n",
      "epoch:47 step:37439[D loss: 0.342092, acc: 71.09%, op_acc: 50.78%] [G loss: 0.870592]\n",
      "epoch:47 step:37440[D loss: 0.375054, acc: 68.75%, op_acc: 47.66%] [G loss: 0.936908]\n",
      "epoch:47 step:37441[D loss: 0.369228, acc: 74.22%, op_acc: 47.66%] [G loss: 1.222594]\n",
      "epoch:47 step:37442[D loss: 0.316974, acc: 78.12%, op_acc: 49.22%] [G loss: 1.203887]\n",
      "epoch:47 step:37443[D loss: 0.344589, acc: 77.34%, op_acc: 46.09%] [G loss: 0.831349]\n",
      "epoch:47 step:37444[D loss: 0.418024, acc: 57.81%, op_acc: 46.88%] [G loss: 0.686833]\n",
      "epoch:47 step:37445[D loss: 0.316063, acc: 75.78%, op_acc: 46.09%] [G loss: 0.760171]\n",
      "epoch:47 step:37446[D loss: 0.344061, acc: 74.22%, op_acc: 48.44%] [G loss: 0.724069]\n",
      "epoch:47 step:37447[D loss: 0.312177, acc: 77.34%, op_acc: 56.25%] [G loss: 0.905437]\n",
      "epoch:47 step:37448[D loss: 0.327002, acc: 77.34%, op_acc: 49.22%] [G loss: 0.665879]\n",
      "epoch:47 step:37449[D loss: 0.401302, acc: 64.84%, op_acc: 46.88%] [G loss: 0.777929]\n",
      "epoch:47 step:37450[D loss: 0.500656, acc: 53.91%, op_acc: 32.81%] [G loss: 0.758475]\n",
      "epoch:47 step:37451[D loss: 0.347560, acc: 75.00%, op_acc: 51.56%] [G loss: 0.908714]\n",
      "epoch:47 step:37452[D loss: 0.356186, acc: 71.88%, op_acc: 45.31%] [G loss: 0.963753]\n",
      "epoch:47 step:37453[D loss: 0.431301, acc: 57.81%, op_acc: 39.06%] [G loss: 1.029751]\n",
      "epoch:47 step:37454[D loss: 0.359012, acc: 71.09%, op_acc: 51.56%] [G loss: 1.004985]\n",
      "epoch:47 step:37455[D loss: 0.401193, acc: 66.41%, op_acc: 39.06%] [G loss: 1.363557]\n",
      "epoch:47 step:37456[D loss: 0.403951, acc: 64.84%, op_acc: 44.53%] [G loss: 1.232194]\n",
      "epoch:47 step:37457[D loss: 0.507194, acc: 47.66%, op_acc: 42.19%] [G loss: 1.016266]\n",
      "epoch:47 step:37458[D loss: 0.427910, acc: 68.75%, op_acc: 39.84%] [G loss: 1.084858]\n",
      "epoch:47 step:37459[D loss: 0.360267, acc: 67.19%, op_acc: 48.44%] [G loss: 0.841995]\n",
      "epoch:47 step:37460[D loss: 0.413012, acc: 65.62%, op_acc: 47.66%] [G loss: 0.897275]\n",
      "epoch:47 step:37461[D loss: 0.337769, acc: 76.56%, op_acc: 48.44%] [G loss: 1.338788]\n",
      "epoch:47 step:37462[D loss: 0.338899, acc: 68.75%, op_acc: 50.00%] [G loss: 0.927059]\n",
      "epoch:47 step:37463[D loss: 0.359447, acc: 67.19%, op_acc: 50.00%] [G loss: 0.943697]\n",
      "epoch:47 step:37464[D loss: 0.302301, acc: 78.91%, op_acc: 47.66%] [G loss: 1.135603]\n",
      "epoch:47 step:37465[D loss: 0.332140, acc: 74.22%, op_acc: 51.56%] [G loss: 1.011352]\n",
      "epoch:47 step:37466[D loss: 0.456877, acc: 54.69%, op_acc: 39.84%] [G loss: 0.851064]\n",
      "epoch:47 step:37467[D loss: 0.349539, acc: 73.44%, op_acc: 54.69%] [G loss: 0.884691]\n",
      "epoch:47 step:37468[D loss: 0.366276, acc: 69.53%, op_acc: 46.88%] [G loss: 0.888413]\n",
      "epoch:47 step:37469[D loss: 0.424559, acc: 64.06%, op_acc: 39.84%] [G loss: 0.921784]\n",
      "epoch:47 step:37470[D loss: 0.360695, acc: 67.97%, op_acc: 46.09%] [G loss: 0.934181]\n",
      "epoch:47 step:37471[D loss: 0.356177, acc: 75.78%, op_acc: 39.84%] [G loss: 1.009891]\n",
      "epoch:47 step:37472[D loss: 0.336749, acc: 74.22%, op_acc: 52.34%] [G loss: 1.155744]\n",
      "epoch:47 step:37473[D loss: 0.366814, acc: 68.75%, op_acc: 46.88%] [G loss: 0.969940]\n",
      "epoch:47 step:37474[D loss: 0.335160, acc: 78.91%, op_acc: 46.88%] [G loss: 1.120902]\n",
      "epoch:47 step:37475[D loss: 0.329872, acc: 77.34%, op_acc: 47.66%] [G loss: 1.063021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47 step:37476[D loss: 0.322846, acc: 78.91%, op_acc: 52.34%] [G loss: 1.022078]\n",
      "epoch:47 step:37477[D loss: 0.427954, acc: 59.38%, op_acc: 42.19%] [G loss: 1.095025]\n",
      "epoch:47 step:37478[D loss: 0.452550, acc: 60.94%, op_acc: 42.19%] [G loss: 0.944026]\n",
      "epoch:47 step:37479[D loss: 0.363931, acc: 71.09%, op_acc: 44.53%] [G loss: 1.077846]\n",
      "epoch:47 step:37480[D loss: 0.364285, acc: 71.88%, op_acc: 43.75%] [G loss: 1.154982]\n",
      "epoch:47 step:37481[D loss: 0.308072, acc: 82.81%, op_acc: 49.22%] [G loss: 1.410989]\n",
      "epoch:47 step:37482[D loss: 0.317404, acc: 81.25%, op_acc: 50.78%] [G loss: 1.297759]\n",
      "epoch:47 step:37483[D loss: 0.399894, acc: 67.97%, op_acc: 50.78%] [G loss: 1.077210]\n",
      "epoch:47 step:37484[D loss: 0.324363, acc: 79.69%, op_acc: 48.44%] [G loss: 0.965933]\n",
      "epoch:47 step:37485[D loss: 0.357416, acc: 70.31%, op_acc: 51.56%] [G loss: 1.212717]\n",
      "epoch:47 step:37486[D loss: 0.330027, acc: 73.44%, op_acc: 50.00%] [G loss: 1.215998]\n",
      "epoch:47 step:37487[D loss: 0.353990, acc: 74.22%, op_acc: 45.31%] [G loss: 1.143452]\n",
      "epoch:47 step:37488[D loss: 0.378512, acc: 70.31%, op_acc: 47.66%] [G loss: 1.254188]\n",
      "epoch:48 step:37489[D loss: 0.346653, acc: 72.66%, op_acc: 56.25%] [G loss: 1.374551]\n",
      "epoch:48 step:37490[D loss: 0.298770, acc: 80.47%, op_acc: 53.91%] [G loss: 1.163711]\n",
      "epoch:48 step:37491[D loss: 0.342762, acc: 71.09%, op_acc: 48.44%] [G loss: 1.340876]\n",
      "epoch:48 step:37492[D loss: 0.349140, acc: 72.66%, op_acc: 50.00%] [G loss: 1.214608]\n",
      "epoch:48 step:37493[D loss: 0.292524, acc: 78.91%, op_acc: 55.47%] [G loss: 1.219110]\n",
      "epoch:48 step:37494[D loss: 0.348043, acc: 73.44%, op_acc: 46.09%] [G loss: 1.505725]\n",
      "epoch:48 step:37495[D loss: 0.422450, acc: 60.94%, op_acc: 45.31%] [G loss: 1.599918]\n",
      "epoch:48 step:37496[D loss: 0.334926, acc: 76.56%, op_acc: 50.00%] [G loss: 1.161206]\n",
      "epoch:48 step:37497[D loss: 0.263630, acc: 86.72%, op_acc: 53.91%] [G loss: 1.268259]\n",
      "epoch:48 step:37498[D loss: 0.443648, acc: 55.47%, op_acc: 41.41%] [G loss: 1.439415]\n",
      "epoch:48 step:37499[D loss: 0.323738, acc: 80.47%, op_acc: 51.56%] [G loss: 1.555319]\n",
      "epoch:48 step:37500[D loss: 0.314196, acc: 79.69%, op_acc: 42.97%] [G loss: 1.481540]\n",
      "epoch:48 step:37501[D loss: 0.325608, acc: 77.34%, op_acc: 50.00%] [G loss: 1.401532]\n",
      "epoch:48 step:37502[D loss: 0.351005, acc: 82.03%, op_acc: 50.00%] [G loss: 0.775582]\n",
      "epoch:48 step:37503[D loss: 0.402645, acc: 62.50%, op_acc: 41.41%] [G loss: 2.065526]\n",
      "epoch:48 step:37504[D loss: 0.331943, acc: 77.34%, op_acc: 45.31%] [G loss: 1.301973]\n",
      "epoch:48 step:37505[D loss: 0.371601, acc: 67.97%, op_acc: 48.44%] [G loss: 0.978495]\n",
      "epoch:48 step:37506[D loss: 0.431080, acc: 60.94%, op_acc: 42.19%] [G loss: 1.506684]\n",
      "epoch:48 step:37507[D loss: 0.394312, acc: 68.75%, op_acc: 42.97%] [G loss: 1.320805]\n",
      "epoch:48 step:37508[D loss: 0.348897, acc: 71.09%, op_acc: 47.66%] [G loss: 1.536312]\n",
      "epoch:48 step:37509[D loss: 0.422359, acc: 64.84%, op_acc: 37.50%] [G loss: 1.209284]\n",
      "epoch:48 step:37510[D loss: 0.370889, acc: 67.19%, op_acc: 50.00%] [G loss: 1.143774]\n",
      "epoch:48 step:37511[D loss: 0.364306, acc: 71.09%, op_acc: 45.31%] [G loss: 1.112890]\n",
      "epoch:48 step:37512[D loss: 0.455615, acc: 58.59%, op_acc: 41.41%] [G loss: 1.338318]\n",
      "epoch:48 step:37513[D loss: 0.379260, acc: 67.97%, op_acc: 42.97%] [G loss: 1.235927]\n",
      "epoch:48 step:37514[D loss: 0.342249, acc: 74.22%, op_acc: 46.09%] [G loss: 1.162124]\n",
      "epoch:48 step:37515[D loss: 0.383268, acc: 71.09%, op_acc: 49.22%] [G loss: 1.166179]\n",
      "epoch:48 step:37516[D loss: 0.341422, acc: 69.53%, op_acc: 45.31%] [G loss: 1.277049]\n",
      "epoch:48 step:37517[D loss: 0.413144, acc: 60.94%, op_acc: 44.53%] [G loss: 1.168608]\n",
      "epoch:48 step:37518[D loss: 0.394382, acc: 64.06%, op_acc: 53.12%] [G loss: 1.264208]\n",
      "epoch:48 step:37519[D loss: 0.360508, acc: 73.44%, op_acc: 46.88%] [G loss: 1.372020]\n",
      "epoch:48 step:37520[D loss: 0.448379, acc: 60.94%, op_acc: 43.75%] [G loss: 1.183836]\n",
      "epoch:48 step:37521[D loss: 0.425104, acc: 63.28%, op_acc: 45.31%] [G loss: 1.200243]\n",
      "epoch:48 step:37522[D loss: 0.326366, acc: 74.22%, op_acc: 46.88%] [G loss: 1.171801]\n",
      "epoch:48 step:37523[D loss: 0.428945, acc: 62.50%, op_acc: 39.06%] [G loss: 1.194997]\n",
      "epoch:48 step:37524[D loss: 0.335832, acc: 72.66%, op_acc: 48.44%] [G loss: 1.232339]\n",
      "epoch:48 step:37525[D loss: 0.405359, acc: 65.62%, op_acc: 41.41%] [G loss: 1.106144]\n",
      "epoch:48 step:37526[D loss: 0.363593, acc: 71.88%, op_acc: 47.66%] [G loss: 1.086062]\n",
      "epoch:48 step:37527[D loss: 0.446219, acc: 57.03%, op_acc: 42.97%] [G loss: 0.965037]\n",
      "epoch:48 step:37528[D loss: 0.381917, acc: 70.31%, op_acc: 36.72%] [G loss: 1.313862]\n",
      "epoch:48 step:37529[D loss: 0.336016, acc: 70.31%, op_acc: 46.88%] [G loss: 1.304625]\n",
      "epoch:48 step:37530[D loss: 0.333254, acc: 78.12%, op_acc: 48.44%] [G loss: 0.994400]\n",
      "epoch:48 step:37531[D loss: 0.403068, acc: 65.62%, op_acc: 49.22%] [G loss: 1.117453]\n",
      "epoch:48 step:37532[D loss: 0.398113, acc: 66.41%, op_acc: 48.44%] [G loss: 0.949935]\n",
      "epoch:48 step:37533[D loss: 0.350699, acc: 73.44%, op_acc: 42.97%] [G loss: 1.154395]\n",
      "epoch:48 step:37534[D loss: 0.415109, acc: 58.59%, op_acc: 46.88%] [G loss: 1.224821]\n",
      "epoch:48 step:37535[D loss: 0.427519, acc: 62.50%, op_acc: 46.88%] [G loss: 1.167158]\n",
      "epoch:48 step:37536[D loss: 0.396866, acc: 67.97%, op_acc: 46.09%] [G loss: 0.822616]\n",
      "epoch:48 step:37537[D loss: 0.377349, acc: 71.88%, op_acc: 44.53%] [G loss: 0.948403]\n",
      "epoch:48 step:37538[D loss: 0.451513, acc: 52.34%, op_acc: 46.88%] [G loss: 1.114377]\n",
      "epoch:48 step:37539[D loss: 0.326526, acc: 76.56%, op_acc: 46.09%] [G loss: 1.415317]\n",
      "epoch:48 step:37540[D loss: 0.329883, acc: 76.56%, op_acc: 40.62%] [G loss: 1.250144]\n",
      "epoch:48 step:37541[D loss: 0.401555, acc: 63.28%, op_acc: 42.97%] [G loss: 1.384062]\n",
      "epoch:48 step:37542[D loss: 0.482255, acc: 56.25%, op_acc: 39.06%] [G loss: 1.335728]\n",
      "epoch:48 step:37543[D loss: 0.340876, acc: 72.66%, op_acc: 46.88%] [G loss: 1.256303]\n",
      "epoch:48 step:37544[D loss: 0.321252, acc: 82.03%, op_acc: 53.91%] [G loss: 1.384609]\n",
      "epoch:48 step:37545[D loss: 0.394782, acc: 74.22%, op_acc: 42.97%] [G loss: 1.188984]\n",
      "epoch:48 step:37546[D loss: 0.337260, acc: 75.78%, op_acc: 53.12%] [G loss: 1.058308]\n",
      "epoch:48 step:37547[D loss: 0.388715, acc: 64.84%, op_acc: 46.88%] [G loss: 0.961302]\n",
      "epoch:48 step:37548[D loss: 0.328701, acc: 78.12%, op_acc: 47.66%] [G loss: 1.246022]\n",
      "epoch:48 step:37549[D loss: 0.358293, acc: 73.44%, op_acc: 42.97%] [G loss: 1.143543]\n",
      "epoch:48 step:37550[D loss: 0.367562, acc: 66.41%, op_acc: 43.75%] [G loss: 1.129788]\n",
      "epoch:48 step:37551[D loss: 0.440880, acc: 60.16%, op_acc: 42.97%] [G loss: 1.379071]\n",
      "epoch:48 step:37552[D loss: 0.409491, acc: 63.28%, op_acc: 41.41%] [G loss: 1.403990]\n",
      "epoch:48 step:37553[D loss: 0.391923, acc: 65.62%, op_acc: 49.22%] [G loss: 1.442520]\n",
      "epoch:48 step:37554[D loss: 0.425607, acc: 61.72%, op_acc: 42.19%] [G loss: 1.101659]\n",
      "epoch:48 step:37555[D loss: 0.356146, acc: 74.22%, op_acc: 46.09%] [G loss: 1.546460]\n",
      "epoch:48 step:37556[D loss: 0.384153, acc: 60.94%, op_acc: 52.34%] [G loss: 1.132504]\n",
      "epoch:48 step:37557[D loss: 0.331677, acc: 72.66%, op_acc: 48.44%] [G loss: 1.219397]\n",
      "epoch:48 step:37558[D loss: 0.422931, acc: 63.28%, op_acc: 41.41%] [G loss: 1.097925]\n",
      "epoch:48 step:37559[D loss: 0.425148, acc: 61.72%, op_acc: 41.41%] [G loss: 1.070921]\n",
      "epoch:48 step:37560[D loss: 0.394970, acc: 64.84%, op_acc: 42.19%] [G loss: 0.916213]\n",
      "epoch:48 step:37561[D loss: 0.454180, acc: 58.59%, op_acc: 40.62%] [G loss: 1.048083]\n",
      "epoch:48 step:37562[D loss: 0.360612, acc: 68.75%, op_acc: 46.09%] [G loss: 1.181300]\n",
      "epoch:48 step:37563[D loss: 0.348403, acc: 72.66%, op_acc: 45.31%] [G loss: 1.203568]\n",
      "epoch:48 step:37564[D loss: 0.390564, acc: 67.97%, op_acc: 48.44%] [G loss: 1.057075]\n",
      "epoch:48 step:37565[D loss: 0.394126, acc: 66.41%, op_acc: 42.97%] [G loss: 0.863753]\n",
      "epoch:48 step:37566[D loss: 0.459874, acc: 61.72%, op_acc: 36.72%] [G loss: 0.869242]\n",
      "epoch:48 step:37567[D loss: 0.391660, acc: 71.88%, op_acc: 43.75%] [G loss: 1.154797]\n",
      "epoch:48 step:37568[D loss: 0.390702, acc: 71.88%, op_acc: 40.62%] [G loss: 1.170176]\n",
      "epoch:48 step:37569[D loss: 0.412494, acc: 63.28%, op_acc: 38.28%] [G loss: 1.128558]\n",
      "epoch:48 step:37570[D loss: 0.366246, acc: 71.09%, op_acc: 47.66%] [G loss: 1.309300]\n",
      "epoch:48 step:37571[D loss: 0.353127, acc: 69.53%, op_acc: 46.88%] [G loss: 1.085947]\n",
      "epoch:48 step:37572[D loss: 0.350984, acc: 75.78%, op_acc: 46.88%] [G loss: 1.240458]\n",
      "epoch:48 step:37573[D loss: 0.356210, acc: 77.34%, op_acc: 44.53%] [G loss: 1.045205]\n",
      "epoch:48 step:37574[D loss: 0.342952, acc: 74.22%, op_acc: 47.66%] [G loss: 1.276168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37575[D loss: 0.309048, acc: 78.12%, op_acc: 53.91%] [G loss: 1.030813]\n",
      "epoch:48 step:37576[D loss: 0.370195, acc: 70.31%, op_acc: 53.12%] [G loss: 0.950059]\n",
      "epoch:48 step:37577[D loss: 0.429893, acc: 63.28%, op_acc: 40.62%] [G loss: 0.832312]\n",
      "epoch:48 step:37578[D loss: 0.353703, acc: 72.66%, op_acc: 46.88%] [G loss: 1.163535]\n",
      "epoch:48 step:37579[D loss: 0.393950, acc: 63.28%, op_acc: 45.31%] [G loss: 1.283780]\n",
      "epoch:48 step:37580[D loss: 0.405077, acc: 63.28%, op_acc: 43.75%] [G loss: 1.090263]\n",
      "epoch:48 step:37581[D loss: 0.362141, acc: 68.75%, op_acc: 51.56%] [G loss: 1.143224]\n",
      "epoch:48 step:37582[D loss: 0.370810, acc: 70.31%, op_acc: 45.31%] [G loss: 0.896980]\n",
      "epoch:48 step:37583[D loss: 0.347659, acc: 72.66%, op_acc: 47.66%] [G loss: 0.891791]\n",
      "epoch:48 step:37584[D loss: 0.340658, acc: 76.56%, op_acc: 45.31%] [G loss: 1.071821]\n",
      "epoch:48 step:37585[D loss: 0.349267, acc: 70.31%, op_acc: 48.44%] [G loss: 1.278775]\n",
      "epoch:48 step:37586[D loss: 0.350987, acc: 75.78%, op_acc: 39.84%] [G loss: 1.100011]\n",
      "epoch:48 step:37587[D loss: 0.393391, acc: 64.84%, op_acc: 47.66%] [G loss: 1.090886]\n",
      "epoch:48 step:37588[D loss: 0.341744, acc: 68.75%, op_acc: 46.88%] [G loss: 1.074036]\n",
      "epoch:48 step:37589[D loss: 0.327636, acc: 78.91%, op_acc: 48.44%] [G loss: 0.753776]\n",
      "epoch:48 step:37590[D loss: 0.354550, acc: 75.00%, op_acc: 50.00%] [G loss: 1.040215]\n",
      "epoch:48 step:37591[D loss: 0.419027, acc: 60.94%, op_acc: 46.09%] [G loss: 0.929744]\n",
      "epoch:48 step:37592[D loss: 0.368548, acc: 68.75%, op_acc: 53.91%] [G loss: 1.013824]\n",
      "epoch:48 step:37593[D loss: 0.339874, acc: 73.44%, op_acc: 52.34%] [G loss: 1.116914]\n",
      "epoch:48 step:37594[D loss: 0.301416, acc: 82.03%, op_acc: 50.78%] [G loss: 1.183429]\n",
      "epoch:48 step:37595[D loss: 0.336915, acc: 74.22%, op_acc: 50.00%] [G loss: 1.110477]\n",
      "epoch:48 step:37596[D loss: 0.414981, acc: 66.41%, op_acc: 41.41%] [G loss: 0.779222]\n",
      "epoch:48 step:37597[D loss: 0.423765, acc: 55.47%, op_acc: 39.06%] [G loss: 0.932150]\n",
      "epoch:48 step:37598[D loss: 0.413233, acc: 64.84%, op_acc: 42.97%] [G loss: 1.285197]\n",
      "epoch:48 step:37599[D loss: 0.337631, acc: 78.91%, op_acc: 50.00%] [G loss: 1.159856]\n",
      "epoch:48 step:37600[D loss: 0.391941, acc: 68.75%, op_acc: 49.22%] [G loss: 1.253936]\n",
      "epoch:48 step:37601[D loss: 0.380783, acc: 73.44%, op_acc: 41.41%] [G loss: 1.139977]\n",
      "epoch:48 step:37602[D loss: 0.412017, acc: 66.41%, op_acc: 43.75%] [G loss: 0.992440]\n",
      "epoch:48 step:37603[D loss: 0.405048, acc: 67.19%, op_acc: 40.62%] [G loss: 1.077950]\n",
      "epoch:48 step:37604[D loss: 0.493126, acc: 52.34%, op_acc: 39.84%] [G loss: 0.755350]\n",
      "epoch:48 step:37605[D loss: 0.419511, acc: 59.38%, op_acc: 43.75%] [G loss: 0.828096]\n",
      "epoch:48 step:37606[D loss: 0.439090, acc: 60.16%, op_acc: 39.84%] [G loss: 1.158544]\n",
      "epoch:48 step:37607[D loss: 0.368210, acc: 67.97%, op_acc: 48.44%] [G loss: 1.092041]\n",
      "epoch:48 step:37608[D loss: 0.436757, acc: 60.94%, op_acc: 35.16%] [G loss: 0.654771]\n",
      "epoch:48 step:37609[D loss: 0.430491, acc: 60.94%, op_acc: 35.16%] [G loss: 1.133721]\n",
      "epoch:48 step:37610[D loss: 0.418580, acc: 64.06%, op_acc: 42.97%] [G loss: 0.688322]\n",
      "epoch:48 step:37611[D loss: 0.339089, acc: 75.78%, op_acc: 46.88%] [G loss: 0.800389]\n",
      "epoch:48 step:37612[D loss: 0.415027, acc: 64.84%, op_acc: 44.53%] [G loss: 0.748893]\n",
      "epoch:48 step:37613[D loss: 0.420338, acc: 68.75%, op_acc: 43.75%] [G loss: 1.222097]\n",
      "epoch:48 step:37614[D loss: 0.352107, acc: 67.97%, op_acc: 49.22%] [G loss: 0.679558]\n",
      "epoch:48 step:37615[D loss: 0.408561, acc: 62.50%, op_acc: 46.88%] [G loss: 0.709578]\n",
      "epoch:48 step:37616[D loss: 0.375062, acc: 71.88%, op_acc: 45.31%] [G loss: 0.771554]\n",
      "epoch:48 step:37617[D loss: 0.449694, acc: 57.81%, op_acc: 43.75%] [G loss: 1.010515]\n",
      "epoch:48 step:37618[D loss: 0.383886, acc: 71.09%, op_acc: 50.78%] [G loss: 1.054923]\n",
      "epoch:48 step:37619[D loss: 0.358227, acc: 71.09%, op_acc: 41.41%] [G loss: 1.174018]\n",
      "epoch:48 step:37620[D loss: 0.267467, acc: 83.59%, op_acc: 58.59%] [G loss: 1.144483]\n",
      "epoch:48 step:37621[D loss: 0.418614, acc: 64.06%, op_acc: 36.72%] [G loss: 0.995647]\n",
      "epoch:48 step:37622[D loss: 0.380183, acc: 71.09%, op_acc: 46.09%] [G loss: 1.023655]\n",
      "epoch:48 step:37623[D loss: 0.383157, acc: 67.19%, op_acc: 46.88%] [G loss: 0.817931]\n",
      "epoch:48 step:37624[D loss: 0.326122, acc: 75.78%, op_acc: 49.22%] [G loss: 1.319257]\n",
      "epoch:48 step:37625[D loss: 0.397731, acc: 71.09%, op_acc: 46.88%] [G loss: 0.971631]\n",
      "epoch:48 step:37626[D loss: 0.363035, acc: 74.22%, op_acc: 39.06%] [G loss: 1.168450]\n",
      "epoch:48 step:37627[D loss: 0.305536, acc: 78.91%, op_acc: 54.69%] [G loss: 1.032531]\n",
      "epoch:48 step:37628[D loss: 0.437962, acc: 62.50%, op_acc: 42.19%] [G loss: 0.932193]\n",
      "epoch:48 step:37629[D loss: 0.393466, acc: 73.44%, op_acc: 47.66%] [G loss: 1.298290]\n",
      "epoch:48 step:37630[D loss: 0.387782, acc: 71.88%, op_acc: 39.84%] [G loss: 1.351285]\n",
      "epoch:48 step:37631[D loss: 0.328351, acc: 77.34%, op_acc: 47.66%] [G loss: 0.744364]\n",
      "epoch:48 step:37632[D loss: 0.336587, acc: 76.56%, op_acc: 45.31%] [G loss: 1.000098]\n",
      "epoch:48 step:37633[D loss: 0.339075, acc: 75.00%, op_acc: 46.88%] [G loss: 1.193358]\n",
      "epoch:48 step:37634[D loss: 0.387795, acc: 68.75%, op_acc: 42.97%] [G loss: 1.170661]\n",
      "epoch:48 step:37635[D loss: 0.354691, acc: 70.31%, op_acc: 51.56%] [G loss: 1.189271]\n",
      "epoch:48 step:37636[D loss: 0.405222, acc: 66.41%, op_acc: 48.44%] [G loss: 0.817145]\n",
      "epoch:48 step:37637[D loss: 0.333818, acc: 76.56%, op_acc: 46.09%] [G loss: 0.785814]\n",
      "epoch:48 step:37638[D loss: 0.338647, acc: 71.88%, op_acc: 54.69%] [G loss: 0.786701]\n",
      "epoch:48 step:37639[D loss: 0.358354, acc: 69.53%, op_acc: 50.00%] [G loss: 0.996072]\n",
      "epoch:48 step:37640[D loss: 0.349787, acc: 69.53%, op_acc: 50.78%] [G loss: 0.957461]\n",
      "epoch:48 step:37641[D loss: 0.380043, acc: 70.31%, op_acc: 44.53%] [G loss: 0.710202]\n",
      "epoch:48 step:37642[D loss: 0.349050, acc: 72.66%, op_acc: 51.56%] [G loss: 1.017603]\n",
      "epoch:48 step:37643[D loss: 0.340996, acc: 75.00%, op_acc: 46.09%] [G loss: 0.981088]\n",
      "epoch:48 step:37644[D loss: 0.392773, acc: 64.84%, op_acc: 51.56%] [G loss: 1.270478]\n",
      "epoch:48 step:37645[D loss: 0.361298, acc: 75.78%, op_acc: 46.88%] [G loss: 1.042489]\n",
      "epoch:48 step:37646[D loss: 0.376300, acc: 63.28%, op_acc: 46.88%] [G loss: 0.966704]\n",
      "epoch:48 step:37647[D loss: 0.356125, acc: 75.78%, op_acc: 51.56%] [G loss: 1.282619]\n",
      "epoch:48 step:37648[D loss: 0.413698, acc: 66.41%, op_acc: 34.38%] [G loss: 1.060404]\n",
      "epoch:48 step:37649[D loss: 0.414568, acc: 67.19%, op_acc: 41.41%] [G loss: 0.980847]\n",
      "epoch:48 step:37650[D loss: 0.348191, acc: 70.31%, op_acc: 57.03%] [G loss: 0.972086]\n",
      "epoch:48 step:37651[D loss: 0.350512, acc: 80.47%, op_acc: 46.88%] [G loss: 1.086881]\n",
      "epoch:48 step:37652[D loss: 0.375777, acc: 71.09%, op_acc: 46.09%] [G loss: 0.933373]\n",
      "epoch:48 step:37653[D loss: 0.356760, acc: 70.31%, op_acc: 50.00%] [G loss: 0.979006]\n",
      "epoch:48 step:37654[D loss: 0.354077, acc: 71.09%, op_acc: 51.56%] [G loss: 1.344232]\n",
      "epoch:48 step:37655[D loss: 0.412987, acc: 64.06%, op_acc: 46.09%] [G loss: 1.093280]\n",
      "epoch:48 step:37656[D loss: 0.345042, acc: 71.09%, op_acc: 50.78%] [G loss: 0.958563]\n",
      "epoch:48 step:37657[D loss: 0.282443, acc: 84.38%, op_acc: 53.91%] [G loss: 1.264453]\n",
      "epoch:48 step:37658[D loss: 0.360209, acc: 70.31%, op_acc: 44.53%] [G loss: 1.494864]\n",
      "epoch:48 step:37659[D loss: 0.367048, acc: 72.66%, op_acc: 46.88%] [G loss: 0.991547]\n",
      "epoch:48 step:37660[D loss: 0.374911, acc: 71.09%, op_acc: 46.88%] [G loss: 1.019353]\n",
      "epoch:48 step:37661[D loss: 0.313139, acc: 81.25%, op_acc: 50.00%] [G loss: 1.170362]\n",
      "epoch:48 step:37662[D loss: 0.405760, acc: 68.75%, op_acc: 40.62%] [G loss: 1.289690]\n",
      "epoch:48 step:37663[D loss: 0.321514, acc: 75.00%, op_acc: 43.75%] [G loss: 1.142942]\n",
      "epoch:48 step:37664[D loss: 0.302202, acc: 81.25%, op_acc: 55.47%] [G loss: 0.915795]\n",
      "epoch:48 step:37665[D loss: 0.401503, acc: 69.53%, op_acc: 44.53%] [G loss: 0.811789]\n",
      "epoch:48 step:37666[D loss: 0.446493, acc: 64.06%, op_acc: 41.41%] [G loss: 0.887783]\n",
      "epoch:48 step:37667[D loss: 0.354307, acc: 75.00%, op_acc: 39.84%] [G loss: 0.935650]\n",
      "epoch:48 step:37668[D loss: 0.306004, acc: 80.47%, op_acc: 54.69%] [G loss: 1.178116]\n",
      "epoch:48 step:37669[D loss: 0.325268, acc: 77.34%, op_acc: 46.88%] [G loss: 1.127757]\n",
      "epoch:48 step:37670[D loss: 0.349695, acc: 71.88%, op_acc: 56.25%] [G loss: 0.897232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37671[D loss: 0.283330, acc: 83.59%, op_acc: 57.81%] [G loss: 0.977650]\n",
      "epoch:48 step:37672[D loss: 0.366317, acc: 71.09%, op_acc: 46.88%] [G loss: 1.136673]\n",
      "epoch:48 step:37673[D loss: 0.383551, acc: 71.88%, op_acc: 46.09%] [G loss: 0.855779]\n",
      "epoch:48 step:37674[D loss: 0.338804, acc: 72.66%, op_acc: 51.56%] [G loss: 1.083458]\n",
      "epoch:48 step:37675[D loss: 0.362103, acc: 70.31%, op_acc: 44.53%] [G loss: 1.043338]\n",
      "epoch:48 step:37676[D loss: 0.473350, acc: 57.81%, op_acc: 42.97%] [G loss: 1.158755]\n",
      "epoch:48 step:37677[D loss: 0.330556, acc: 78.91%, op_acc: 53.12%] [G loss: 1.274229]\n",
      "epoch:48 step:37678[D loss: 0.352143, acc: 75.78%, op_acc: 46.88%] [G loss: 0.998622]\n",
      "epoch:48 step:37679[D loss: 0.331392, acc: 78.91%, op_acc: 53.91%] [G loss: 1.048643]\n",
      "epoch:48 step:37680[D loss: 0.297572, acc: 82.03%, op_acc: 45.31%] [G loss: 0.932483]\n",
      "epoch:48 step:37681[D loss: 0.387727, acc: 66.41%, op_acc: 44.53%] [G loss: 0.986056]\n",
      "epoch:48 step:37682[D loss: 0.366123, acc: 70.31%, op_acc: 54.69%] [G loss: 1.409485]\n",
      "epoch:48 step:37683[D loss: 0.377455, acc: 67.19%, op_acc: 46.88%] [G loss: 1.165083]\n",
      "epoch:48 step:37684[D loss: 0.352379, acc: 75.00%, op_acc: 42.19%] [G loss: 0.750421]\n",
      "epoch:48 step:37685[D loss: 0.466927, acc: 50.78%, op_acc: 40.62%] [G loss: 0.775698]\n",
      "epoch:48 step:37686[D loss: 0.361000, acc: 77.34%, op_acc: 43.75%] [G loss: 1.038800]\n",
      "epoch:48 step:37687[D loss: 0.357743, acc: 71.09%, op_acc: 47.66%] [G loss: 0.989737]\n",
      "epoch:48 step:37688[D loss: 0.365173, acc: 73.44%, op_acc: 50.78%] [G loss: 0.892497]\n",
      "epoch:48 step:37689[D loss: 0.355148, acc: 61.72%, op_acc: 50.78%] [G loss: 1.120668]\n",
      "epoch:48 step:37690[D loss: 0.367419, acc: 72.66%, op_acc: 46.09%] [G loss: 0.959580]\n",
      "epoch:48 step:37691[D loss: 0.398395, acc: 58.59%, op_acc: 50.78%] [G loss: 1.385317]\n",
      "epoch:48 step:37692[D loss: 0.385768, acc: 67.97%, op_acc: 46.09%] [G loss: 0.882889]\n",
      "epoch:48 step:37693[D loss: 0.387794, acc: 73.44%, op_acc: 46.09%] [G loss: 0.853950]\n",
      "epoch:48 step:37694[D loss: 0.369102, acc: 75.00%, op_acc: 44.53%] [G loss: 1.212957]\n",
      "epoch:48 step:37695[D loss: 0.326968, acc: 76.56%, op_acc: 50.78%] [G loss: 1.034758]\n",
      "epoch:48 step:37696[D loss: 0.338389, acc: 75.00%, op_acc: 50.78%] [G loss: 0.837573]\n",
      "epoch:48 step:37697[D loss: 0.395270, acc: 64.84%, op_acc: 47.66%] [G loss: 0.886131]\n",
      "epoch:48 step:37698[D loss: 0.410968, acc: 65.62%, op_acc: 41.41%] [G loss: 0.779897]\n",
      "epoch:48 step:37699[D loss: 0.335109, acc: 75.00%, op_acc: 54.69%] [G loss: 0.994914]\n",
      "epoch:48 step:37700[D loss: 0.383287, acc: 68.75%, op_acc: 46.09%] [G loss: 0.953149]\n",
      "epoch:48 step:37701[D loss: 0.303374, acc: 82.81%, op_acc: 49.22%] [G loss: 1.025463]\n",
      "epoch:48 step:37702[D loss: 0.328971, acc: 75.78%, op_acc: 48.44%] [G loss: 1.194921]\n",
      "epoch:48 step:37703[D loss: 0.336239, acc: 79.69%, op_acc: 51.56%] [G loss: 1.047329]\n",
      "epoch:48 step:37704[D loss: 0.449741, acc: 58.59%, op_acc: 44.53%] [G loss: 1.092768]\n",
      "epoch:48 step:37705[D loss: 0.363183, acc: 74.22%, op_acc: 48.44%] [G loss: 0.964968]\n",
      "epoch:48 step:37706[D loss: 0.384516, acc: 64.84%, op_acc: 50.00%] [G loss: 1.187046]\n",
      "epoch:48 step:37707[D loss: 0.351970, acc: 73.44%, op_acc: 49.22%] [G loss: 1.147141]\n",
      "epoch:48 step:37708[D loss: 0.491538, acc: 50.00%, op_acc: 39.06%] [G loss: 1.086383]\n",
      "epoch:48 step:37709[D loss: 0.358850, acc: 72.66%, op_acc: 46.09%] [G loss: 1.067736]\n",
      "epoch:48 step:37710[D loss: 0.327336, acc: 79.69%, op_acc: 50.78%] [G loss: 1.081162]\n",
      "epoch:48 step:37711[D loss: 0.420925, acc: 62.50%, op_acc: 43.75%] [G loss: 0.935596]\n",
      "epoch:48 step:37712[D loss: 0.363890, acc: 72.66%, op_acc: 45.31%] [G loss: 1.066841]\n",
      "epoch:48 step:37713[D loss: 0.335324, acc: 76.56%, op_acc: 55.47%] [G loss: 0.919355]\n",
      "epoch:48 step:37714[D loss: 0.344582, acc: 74.22%, op_acc: 46.09%] [G loss: 1.169931]\n",
      "epoch:48 step:37715[D loss: 0.335199, acc: 75.78%, op_acc: 53.12%] [G loss: 1.012697]\n",
      "epoch:48 step:37716[D loss: 0.383718, acc: 67.97%, op_acc: 49.22%] [G loss: 1.051945]\n",
      "epoch:48 step:37717[D loss: 0.339944, acc: 71.88%, op_acc: 48.44%] [G loss: 1.090883]\n",
      "epoch:48 step:37718[D loss: 0.447376, acc: 57.81%, op_acc: 43.75%] [G loss: 1.103374]\n",
      "epoch:48 step:37719[D loss: 0.248950, acc: 84.38%, op_acc: 60.94%] [G loss: 1.017222]\n",
      "epoch:48 step:37720[D loss: 0.309901, acc: 79.69%, op_acc: 58.59%] [G loss: 1.332456]\n",
      "epoch:48 step:37721[D loss: 0.269334, acc: 82.81%, op_acc: 53.12%] [G loss: 1.278508]\n",
      "epoch:48 step:37722[D loss: 0.423889, acc: 64.06%, op_acc: 49.22%] [G loss: 1.085988]\n",
      "epoch:48 step:37723[D loss: 0.329390, acc: 75.00%, op_acc: 58.59%] [G loss: 1.054588]\n",
      "epoch:48 step:37724[D loss: 0.400666, acc: 67.19%, op_acc: 50.78%] [G loss: 1.087660]\n",
      "epoch:48 step:37725[D loss: 0.305404, acc: 79.69%, op_acc: 48.44%] [G loss: 0.810036]\n",
      "epoch:48 step:37726[D loss: 0.462864, acc: 59.38%, op_acc: 42.97%] [G loss: 0.957714]\n",
      "epoch:48 step:37727[D loss: 0.382793, acc: 66.41%, op_acc: 43.75%] [G loss: 1.138286]\n",
      "epoch:48 step:37728[D loss: 0.308002, acc: 81.25%, op_acc: 49.22%] [G loss: 1.274101]\n",
      "epoch:48 step:37729[D loss: 0.364101, acc: 69.53%, op_acc: 49.22%] [G loss: 1.122341]\n",
      "epoch:48 step:37730[D loss: 0.322362, acc: 76.56%, op_acc: 57.81%] [G loss: 0.913088]\n",
      "epoch:48 step:37731[D loss: 0.365245, acc: 67.97%, op_acc: 52.34%] [G loss: 1.026719]\n",
      "epoch:48 step:37732[D loss: 0.328950, acc: 75.00%, op_acc: 48.44%] [G loss: 0.924939]\n",
      "epoch:48 step:37733[D loss: 0.324379, acc: 75.00%, op_acc: 49.22%] [G loss: 0.928565]\n",
      "epoch:48 step:37734[D loss: 0.347130, acc: 80.47%, op_acc: 45.31%] [G loss: 1.162423]\n",
      "epoch:48 step:37735[D loss: 0.301515, acc: 81.25%, op_acc: 52.34%] [G loss: 1.264321]\n",
      "epoch:48 step:37736[D loss: 0.364808, acc: 72.66%, op_acc: 45.31%] [G loss: 1.098630]\n",
      "epoch:48 step:37737[D loss: 0.336397, acc: 80.47%, op_acc: 42.19%] [G loss: 1.130610]\n",
      "epoch:48 step:37738[D loss: 0.454869, acc: 54.69%, op_acc: 39.84%] [G loss: 1.087479]\n",
      "epoch:48 step:37739[D loss: 0.326073, acc: 75.00%, op_acc: 50.00%] [G loss: 1.214495]\n",
      "epoch:48 step:37740[D loss: 0.384705, acc: 66.41%, op_acc: 50.78%] [G loss: 1.268594]\n",
      "epoch:48 step:37741[D loss: 0.356588, acc: 75.78%, op_acc: 48.44%] [G loss: 0.754471]\n",
      "epoch:48 step:37742[D loss: 0.404610, acc: 68.75%, op_acc: 46.09%] [G loss: 0.933504]\n",
      "epoch:48 step:37743[D loss: 0.400773, acc: 64.84%, op_acc: 48.44%] [G loss: 1.129089]\n",
      "epoch:48 step:37744[D loss: 0.344254, acc: 71.09%, op_acc: 54.69%] [G loss: 1.169423]\n",
      "epoch:48 step:37745[D loss: 0.427934, acc: 64.06%, op_acc: 44.53%] [G loss: 1.118202]\n",
      "epoch:48 step:37746[D loss: 0.386015, acc: 66.41%, op_acc: 46.88%] [G loss: 1.379928]\n",
      "epoch:48 step:37747[D loss: 0.316580, acc: 78.91%, op_acc: 44.53%] [G loss: 1.286862]\n",
      "epoch:48 step:37748[D loss: 0.335104, acc: 79.69%, op_acc: 51.56%] [G loss: 1.232758]\n",
      "epoch:48 step:37749[D loss: 0.342352, acc: 74.22%, op_acc: 50.00%] [G loss: 1.386352]\n",
      "epoch:48 step:37750[D loss: 0.404949, acc: 64.06%, op_acc: 48.44%] [G loss: 1.260283]\n",
      "epoch:48 step:37751[D loss: 0.395526, acc: 65.62%, op_acc: 42.19%] [G loss: 1.025389]\n",
      "epoch:48 step:37752[D loss: 0.351840, acc: 72.66%, op_acc: 44.53%] [G loss: 1.429114]\n",
      "epoch:48 step:37753[D loss: 0.339962, acc: 73.44%, op_acc: 53.91%] [G loss: 1.260186]\n",
      "epoch:48 step:37754[D loss: 0.337265, acc: 78.12%, op_acc: 57.81%] [G loss: 1.299513]\n",
      "epoch:48 step:37755[D loss: 0.445001, acc: 60.94%, op_acc: 48.44%] [G loss: 1.213041]\n",
      "epoch:48 step:37756[D loss: 0.339779, acc: 74.22%, op_acc: 52.34%] [G loss: 1.073019]\n",
      "epoch:48 step:37757[D loss: 0.395413, acc: 62.50%, op_acc: 46.09%] [G loss: 1.056425]\n",
      "epoch:48 step:37758[D loss: 0.338089, acc: 72.66%, op_acc: 51.56%] [G loss: 1.024131]\n",
      "epoch:48 step:37759[D loss: 0.363750, acc: 71.88%, op_acc: 49.22%] [G loss: 1.027678]\n",
      "epoch:48 step:37760[D loss: 0.461673, acc: 55.47%, op_acc: 42.19%] [G loss: 0.962524]\n",
      "epoch:48 step:37761[D loss: 0.422938, acc: 64.84%, op_acc: 50.00%] [G loss: 0.959196]\n",
      "epoch:48 step:37762[D loss: 0.432449, acc: 55.47%, op_acc: 46.09%] [G loss: 1.137768]\n",
      "epoch:48 step:37763[D loss: 0.387244, acc: 70.31%, op_acc: 43.75%] [G loss: 1.042197]\n",
      "epoch:48 step:37764[D loss: 0.360264, acc: 74.22%, op_acc: 46.09%] [G loss: 0.992470]\n",
      "epoch:48 step:37765[D loss: 0.316085, acc: 79.69%, op_acc: 55.47%] [G loss: 1.324339]\n",
      "epoch:48 step:37766[D loss: 0.359199, acc: 75.78%, op_acc: 53.91%] [G loss: 1.141080]\n",
      "epoch:48 step:37767[D loss: 0.304975, acc: 81.25%, op_acc: 56.25%] [G loss: 1.110335]\n",
      "epoch:48 step:37768[D loss: 0.320204, acc: 76.56%, op_acc: 51.56%] [G loss: 1.200752]\n",
      "epoch:48 step:37769[D loss: 0.319842, acc: 74.22%, op_acc: 49.22%] [G loss: 1.424926]\n",
      "epoch:48 step:37770[D loss: 0.330325, acc: 78.91%, op_acc: 44.53%] [G loss: 1.160728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37771[D loss: 0.343443, acc: 72.66%, op_acc: 49.22%] [G loss: 1.111527]\n",
      "epoch:48 step:37772[D loss: 0.350442, acc: 67.19%, op_acc: 51.56%] [G loss: 1.336909]\n",
      "epoch:48 step:37773[D loss: 0.275902, acc: 85.16%, op_acc: 50.00%] [G loss: 1.196850]\n",
      "epoch:48 step:37774[D loss: 0.332891, acc: 74.22%, op_acc: 53.91%] [G loss: 1.226582]\n",
      "epoch:48 step:37775[D loss: 0.400229, acc: 66.41%, op_acc: 47.66%] [G loss: 1.336025]\n",
      "epoch:48 step:37776[D loss: 0.318626, acc: 77.34%, op_acc: 52.34%] [G loss: 0.841170]\n",
      "epoch:48 step:37777[D loss: 0.374268, acc: 71.09%, op_acc: 39.84%] [G loss: 0.898064]\n",
      "epoch:48 step:37778[D loss: 0.335862, acc: 70.31%, op_acc: 49.22%] [G loss: 1.362590]\n",
      "epoch:48 step:37779[D loss: 0.370643, acc: 69.53%, op_acc: 52.34%] [G loss: 1.123202]\n",
      "epoch:48 step:37780[D loss: 0.445735, acc: 60.16%, op_acc: 39.06%] [G loss: 1.065670]\n",
      "epoch:48 step:37781[D loss: 0.310526, acc: 75.78%, op_acc: 52.34%] [G loss: 1.458447]\n",
      "epoch:48 step:37782[D loss: 0.359410, acc: 71.88%, op_acc: 42.97%] [G loss: 1.473778]\n",
      "epoch:48 step:37783[D loss: 0.384269, acc: 62.50%, op_acc: 46.09%] [G loss: 1.198243]\n",
      "epoch:48 step:37784[D loss: 0.388061, acc: 69.53%, op_acc: 49.22%] [G loss: 1.450386]\n",
      "epoch:48 step:37785[D loss: 0.458228, acc: 58.59%, op_acc: 38.28%] [G loss: 1.533467]\n",
      "epoch:48 step:37786[D loss: 0.350967, acc: 76.56%, op_acc: 46.88%] [G loss: 1.322717]\n",
      "epoch:48 step:37787[D loss: 0.311430, acc: 80.47%, op_acc: 51.56%] [G loss: 1.181038]\n",
      "epoch:48 step:37788[D loss: 0.390882, acc: 65.62%, op_acc: 42.19%] [G loss: 1.266854]\n",
      "epoch:48 step:37789[D loss: 0.340988, acc: 73.44%, op_acc: 43.75%] [G loss: 1.002537]\n",
      "epoch:48 step:37790[D loss: 0.367735, acc: 70.31%, op_acc: 49.22%] [G loss: 1.296715]\n",
      "epoch:48 step:37791[D loss: 0.377688, acc: 69.53%, op_acc: 44.53%] [G loss: 1.261057]\n",
      "epoch:48 step:37792[D loss: 0.426859, acc: 57.81%, op_acc: 42.97%] [G loss: 1.268880]\n",
      "epoch:48 step:37793[D loss: 0.360572, acc: 71.88%, op_acc: 53.91%] [G loss: 1.338100]\n",
      "epoch:48 step:37794[D loss: 0.380290, acc: 75.00%, op_acc: 50.00%] [G loss: 1.483719]\n",
      "epoch:48 step:37795[D loss: 0.368861, acc: 68.75%, op_acc: 52.34%] [G loss: 1.505036]\n",
      "epoch:48 step:37796[D loss: 0.394051, acc: 64.84%, op_acc: 45.31%] [G loss: 1.285424]\n",
      "epoch:48 step:37797[D loss: 0.472575, acc: 59.38%, op_acc: 43.75%] [G loss: 1.005216]\n",
      "epoch:48 step:37798[D loss: 0.394760, acc: 66.41%, op_acc: 46.88%] [G loss: 1.034968]\n",
      "epoch:48 step:37799[D loss: 0.356760, acc: 78.12%, op_acc: 43.75%] [G loss: 1.173540]\n",
      "epoch:48 step:37800[D loss: 0.389567, acc: 66.41%, op_acc: 51.56%] [G loss: 1.141372]\n",
      "epoch:48 step:37801[D loss: 0.318310, acc: 78.12%, op_acc: 53.12%] [G loss: 1.200370]\n",
      "epoch:48 step:37802[D loss: 0.369048, acc: 68.75%, op_acc: 42.97%] [G loss: 1.163845]\n",
      "epoch:48 step:37803[D loss: 0.413467, acc: 60.16%, op_acc: 42.97%] [G loss: 0.857863]\n",
      "epoch:48 step:37804[D loss: 0.458879, acc: 59.38%, op_acc: 36.72%] [G loss: 0.904579]\n",
      "epoch:48 step:37805[D loss: 0.420868, acc: 64.06%, op_acc: 37.50%] [G loss: 1.138578]\n",
      "epoch:48 step:37806[D loss: 0.365260, acc: 75.00%, op_acc: 45.31%] [G loss: 0.978130]\n",
      "epoch:48 step:37807[D loss: 0.345888, acc: 72.66%, op_acc: 45.31%] [G loss: 1.511114]\n",
      "epoch:48 step:37808[D loss: 0.417688, acc: 62.50%, op_acc: 44.53%] [G loss: 1.076947]\n",
      "epoch:48 step:37809[D loss: 0.373423, acc: 70.31%, op_acc: 42.19%] [G loss: 1.012574]\n",
      "epoch:48 step:37810[D loss: 0.410102, acc: 60.94%, op_acc: 54.69%] [G loss: 1.040924]\n",
      "epoch:48 step:37811[D loss: 0.367355, acc: 71.88%, op_acc: 45.31%] [G loss: 1.244596]\n",
      "epoch:48 step:37812[D loss: 0.400646, acc: 74.22%, op_acc: 40.62%] [G loss: 0.742554]\n",
      "epoch:48 step:37813[D loss: 0.369910, acc: 66.41%, op_acc: 52.34%] [G loss: 0.967076]\n",
      "epoch:48 step:37814[D loss: 0.382618, acc: 64.06%, op_acc: 46.09%] [G loss: 1.196388]\n",
      "epoch:48 step:37815[D loss: 0.364167, acc: 75.00%, op_acc: 40.62%] [G loss: 1.084464]\n",
      "epoch:48 step:37816[D loss: 0.403517, acc: 64.06%, op_acc: 42.97%] [G loss: 0.972395]\n",
      "epoch:48 step:37817[D loss: 0.369087, acc: 71.88%, op_acc: 43.75%] [G loss: 1.356888]\n",
      "epoch:48 step:37818[D loss: 0.394792, acc: 70.31%, op_acc: 39.84%] [G loss: 1.187187]\n",
      "epoch:48 step:37819[D loss: 0.359784, acc: 75.78%, op_acc: 49.22%] [G loss: 0.674126]\n",
      "epoch:48 step:37820[D loss: 0.377309, acc: 69.53%, op_acc: 46.88%] [G loss: 0.906207]\n",
      "epoch:48 step:37821[D loss: 0.402436, acc: 64.06%, op_acc: 40.62%] [G loss: 1.312138]\n",
      "epoch:48 step:37822[D loss: 0.368215, acc: 71.88%, op_acc: 46.09%] [G loss: 1.065931]\n",
      "epoch:48 step:37823[D loss: 0.326045, acc: 77.34%, op_acc: 49.22%] [G loss: 0.909838]\n",
      "epoch:48 step:37824[D loss: 0.348624, acc: 75.78%, op_acc: 50.78%] [G loss: 0.867040]\n",
      "epoch:48 step:37825[D loss: 0.328491, acc: 79.69%, op_acc: 50.00%] [G loss: 0.961543]\n",
      "epoch:48 step:37826[D loss: 0.369278, acc: 67.19%, op_acc: 50.00%] [G loss: 1.180826]\n",
      "epoch:48 step:37827[D loss: 0.349029, acc: 73.44%, op_acc: 45.31%] [G loss: 0.847876]\n",
      "epoch:48 step:37828[D loss: 0.346562, acc: 69.53%, op_acc: 51.56%] [G loss: 1.009634]\n",
      "epoch:48 step:37829[D loss: 0.400080, acc: 64.06%, op_acc: 41.41%] [G loss: 1.183049]\n",
      "epoch:48 step:37830[D loss: 0.426271, acc: 59.38%, op_acc: 43.75%] [G loss: 1.001924]\n",
      "epoch:48 step:37831[D loss: 0.441117, acc: 60.94%, op_acc: 42.97%] [G loss: 1.002055]\n",
      "epoch:48 step:37832[D loss: 0.383453, acc: 69.53%, op_acc: 42.97%] [G loss: 0.950728]\n",
      "epoch:48 step:37833[D loss: 0.391743, acc: 65.62%, op_acc: 47.66%] [G loss: 0.929780]\n",
      "epoch:48 step:37834[D loss: 0.335315, acc: 74.22%, op_acc: 49.22%] [G loss: 0.895945]\n",
      "epoch:48 step:37835[D loss: 0.432206, acc: 57.81%, op_acc: 39.84%] [G loss: 1.066502]\n",
      "epoch:48 step:37836[D loss: 0.299137, acc: 82.03%, op_acc: 51.56%] [G loss: 1.096419]\n",
      "epoch:48 step:37837[D loss: 0.305945, acc: 80.47%, op_acc: 46.88%] [G loss: 0.816371]\n",
      "epoch:48 step:37838[D loss: 0.374660, acc: 69.53%, op_acc: 49.22%] [G loss: 0.912581]\n",
      "epoch:48 step:37839[D loss: 0.414988, acc: 60.94%, op_acc: 43.75%] [G loss: 1.251928]\n",
      "epoch:48 step:37840[D loss: 0.349629, acc: 75.78%, op_acc: 49.22%] [G loss: 1.195996]\n",
      "epoch:48 step:37841[D loss: 0.342041, acc: 72.66%, op_acc: 49.22%] [G loss: 1.291720]\n",
      "epoch:48 step:37842[D loss: 0.427415, acc: 58.59%, op_acc: 45.31%] [G loss: 0.923560]\n",
      "epoch:48 step:37843[D loss: 0.362033, acc: 66.41%, op_acc: 42.19%] [G loss: 1.173987]\n",
      "epoch:48 step:37844[D loss: 0.342614, acc: 75.78%, op_acc: 48.44%] [G loss: 0.895522]\n",
      "epoch:48 step:37845[D loss: 0.337194, acc: 77.34%, op_acc: 50.78%] [G loss: 1.434453]\n",
      "epoch:48 step:37846[D loss: 0.359348, acc: 74.22%, op_acc: 48.44%] [G loss: 1.090975]\n",
      "epoch:48 step:37847[D loss: 0.414935, acc: 66.41%, op_acc: 40.62%] [G loss: 1.148919]\n",
      "epoch:48 step:37848[D loss: 0.370506, acc: 67.19%, op_acc: 46.09%] [G loss: 0.921673]\n",
      "epoch:48 step:37849[D loss: 0.340984, acc: 75.78%, op_acc: 58.59%] [G loss: 1.040168]\n",
      "epoch:48 step:37850[D loss: 0.330949, acc: 67.19%, op_acc: 55.47%] [G loss: 1.223938]\n",
      "epoch:48 step:37851[D loss: 0.366952, acc: 71.88%, op_acc: 48.44%] [G loss: 0.965810]\n",
      "epoch:48 step:37852[D loss: 0.362548, acc: 70.31%, op_acc: 48.44%] [G loss: 0.895023]\n",
      "epoch:48 step:37853[D loss: 0.309679, acc: 79.69%, op_acc: 53.91%] [G loss: 1.146179]\n",
      "epoch:48 step:37854[D loss: 0.331294, acc: 73.44%, op_acc: 49.22%] [G loss: 1.066126]\n",
      "epoch:48 step:37855[D loss: 0.424029, acc: 64.84%, op_acc: 43.75%] [G loss: 0.941670]\n",
      "epoch:48 step:37856[D loss: 0.415447, acc: 63.28%, op_acc: 40.62%] [G loss: 1.107562]\n",
      "epoch:48 step:37857[D loss: 0.464902, acc: 53.12%, op_acc: 38.28%] [G loss: 0.992265]\n",
      "epoch:48 step:37858[D loss: 0.359671, acc: 75.78%, op_acc: 46.09%] [G loss: 0.904180]\n",
      "epoch:48 step:37859[D loss: 0.332799, acc: 72.66%, op_acc: 56.25%] [G loss: 0.698413]\n",
      "epoch:48 step:37860[D loss: 0.356361, acc: 74.22%, op_acc: 46.88%] [G loss: 0.864060]\n",
      "epoch:48 step:37861[D loss: 0.291213, acc: 80.47%, op_acc: 50.00%] [G loss: 0.902139]\n",
      "epoch:48 step:37862[D loss: 0.353204, acc: 75.78%, op_acc: 47.66%] [G loss: 0.981500]\n",
      "epoch:48 step:37863[D loss: 0.288903, acc: 81.25%, op_acc: 56.25%] [G loss: 1.045792]\n",
      "epoch:48 step:37864[D loss: 0.329772, acc: 71.09%, op_acc: 53.12%] [G loss: 0.817446]\n",
      "epoch:48 step:37865[D loss: 0.385725, acc: 68.75%, op_acc: 46.09%] [G loss: 0.728434]\n",
      "epoch:48 step:37866[D loss: 0.335262, acc: 76.56%, op_acc: 48.44%] [G loss: 0.778983]\n",
      "epoch:48 step:37867[D loss: 0.270493, acc: 87.50%, op_acc: 53.12%] [G loss: 1.070553]\n",
      "epoch:48 step:37868[D loss: 0.392919, acc: 68.75%, op_acc: 53.91%] [G loss: 0.868284]\n",
      "epoch:48 step:37869[D loss: 0.313067, acc: 84.38%, op_acc: 51.56%] [G loss: 1.096999]\n",
      "epoch:48 step:37870[D loss: 0.278035, acc: 80.47%, op_acc: 53.12%] [G loss: 0.836686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37871[D loss: 0.307483, acc: 80.47%, op_acc: 53.91%] [G loss: 1.155380]\n",
      "epoch:48 step:37872[D loss: 0.292580, acc: 82.03%, op_acc: 53.12%] [G loss: 1.262770]\n",
      "epoch:48 step:37873[D loss: 0.282144, acc: 83.59%, op_acc: 57.03%] [G loss: 1.080980]\n",
      "epoch:48 step:37874[D loss: 0.320621, acc: 74.22%, op_acc: 55.47%] [G loss: 1.142760]\n",
      "epoch:48 step:37875[D loss: 0.320236, acc: 80.47%, op_acc: 44.53%] [G loss: 1.252134]\n",
      "epoch:48 step:37876[D loss: 0.276314, acc: 88.28%, op_acc: 48.44%] [G loss: 1.447321]\n",
      "epoch:48 step:37877[D loss: 0.269486, acc: 88.28%, op_acc: 56.25%] [G loss: 0.605737]\n",
      "epoch:48 step:37878[D loss: 0.282619, acc: 79.69%, op_acc: 50.78%] [G loss: 1.174038]\n",
      "epoch:48 step:37879[D loss: 0.375975, acc: 62.50%, op_acc: 47.66%] [G loss: 1.073673]\n",
      "epoch:48 step:37880[D loss: 0.395793, acc: 62.50%, op_acc: 58.59%] [G loss: 0.902109]\n",
      "epoch:48 step:37881[D loss: 0.367836, acc: 71.09%, op_acc: 44.53%] [G loss: 1.081005]\n",
      "epoch:48 step:37882[D loss: 0.346794, acc: 75.78%, op_acc: 46.88%] [G loss: 1.016624]\n",
      "epoch:48 step:37883[D loss: 0.365826, acc: 74.22%, op_acc: 42.19%] [G loss: 1.090175]\n",
      "epoch:48 step:37884[D loss: 0.407774, acc: 60.16%, op_acc: 42.97%] [G loss: 1.443295]\n",
      "epoch:48 step:37885[D loss: 0.317003, acc: 77.34%, op_acc: 53.91%] [G loss: 1.091788]\n",
      "epoch:48 step:37886[D loss: 0.393067, acc: 71.88%, op_acc: 50.78%] [G loss: 0.890397]\n",
      "epoch:48 step:37887[D loss: 0.292511, acc: 80.47%, op_acc: 53.91%] [G loss: 1.217194]\n",
      "epoch:48 step:37888[D loss: 0.461004, acc: 52.34%, op_acc: 43.75%] [G loss: 1.033100]\n",
      "epoch:48 step:37889[D loss: 0.343877, acc: 75.78%, op_acc: 44.53%] [G loss: 0.873977]\n",
      "epoch:48 step:37890[D loss: 0.412901, acc: 65.62%, op_acc: 44.53%] [G loss: 1.032044]\n",
      "epoch:48 step:37891[D loss: 0.280755, acc: 83.59%, op_acc: 55.47%] [G loss: 1.208753]\n",
      "epoch:48 step:37892[D loss: 0.267743, acc: 85.94%, op_acc: 55.47%] [G loss: 1.237164]\n",
      "epoch:48 step:37893[D loss: 0.409755, acc: 64.84%, op_acc: 47.66%] [G loss: 1.179308]\n",
      "epoch:48 step:37894[D loss: 0.321382, acc: 75.78%, op_acc: 53.12%] [G loss: 0.943713]\n",
      "epoch:48 step:37895[D loss: 0.298845, acc: 78.91%, op_acc: 49.22%] [G loss: 1.517371]\n",
      "epoch:48 step:37896[D loss: 0.326348, acc: 76.56%, op_acc: 54.69%] [G loss: 1.090003]\n",
      "epoch:48 step:37897[D loss: 0.367495, acc: 71.09%, op_acc: 50.00%] [G loss: 1.070505]\n",
      "epoch:48 step:37898[D loss: 0.320459, acc: 74.22%, op_acc: 54.69%] [G loss: 1.160586]\n",
      "epoch:48 step:37899[D loss: 0.396950, acc: 71.09%, op_acc: 46.88%] [G loss: 1.238297]\n",
      "epoch:48 step:37900[D loss: 0.316702, acc: 76.56%, op_acc: 47.66%] [G loss: 1.336056]\n",
      "epoch:48 step:37901[D loss: 0.273822, acc: 85.94%, op_acc: 56.25%] [G loss: 1.549857]\n",
      "epoch:48 step:37902[D loss: 0.265262, acc: 82.03%, op_acc: 65.62%] [G loss: 1.515867]\n",
      "epoch:48 step:37903[D loss: 0.280223, acc: 85.16%, op_acc: 60.94%] [G loss: 0.997509]\n",
      "epoch:48 step:37904[D loss: 0.475973, acc: 52.34%, op_acc: 38.28%] [G loss: 1.301871]\n",
      "epoch:48 step:37905[D loss: 0.345429, acc: 76.56%, op_acc: 46.88%] [G loss: 1.883142]\n",
      "epoch:48 step:37906[D loss: 0.334977, acc: 75.78%, op_acc: 50.00%] [G loss: 1.727760]\n",
      "epoch:48 step:37907[D loss: 0.298127, acc: 82.81%, op_acc: 51.56%] [G loss: 1.524818]\n",
      "epoch:48 step:37908[D loss: 0.390905, acc: 67.19%, op_acc: 43.75%] [G loss: 1.156051]\n",
      "epoch:48 step:37909[D loss: 0.392334, acc: 69.53%, op_acc: 47.66%] [G loss: 1.096305]\n",
      "epoch:48 step:37910[D loss: 0.318746, acc: 78.91%, op_acc: 53.91%] [G loss: 1.273097]\n",
      "epoch:48 step:37911[D loss: 0.372648, acc: 68.75%, op_acc: 43.75%] [G loss: 1.339814]\n",
      "epoch:48 step:37912[D loss: 0.377803, acc: 72.66%, op_acc: 36.72%] [G loss: 1.055572]\n",
      "epoch:48 step:37913[D loss: 0.401778, acc: 64.06%, op_acc: 50.78%] [G loss: 1.269863]\n",
      "epoch:48 step:37914[D loss: 0.343192, acc: 76.56%, op_acc: 52.34%] [G loss: 1.332063]\n",
      "epoch:48 step:37915[D loss: 0.320734, acc: 77.34%, op_acc: 53.12%] [G loss: 1.412460]\n",
      "epoch:48 step:37916[D loss: 0.332868, acc: 72.66%, op_acc: 53.12%] [G loss: 1.215126]\n",
      "epoch:48 step:37917[D loss: 0.276089, acc: 84.38%, op_acc: 55.47%] [G loss: 1.424842]\n",
      "epoch:48 step:37918[D loss: 0.316647, acc: 75.78%, op_acc: 51.56%] [G loss: 1.465070]\n",
      "epoch:48 step:37919[D loss: 0.321388, acc: 77.34%, op_acc: 59.38%] [G loss: 1.622658]\n",
      "epoch:48 step:37920[D loss: 0.333776, acc: 71.09%, op_acc: 53.91%] [G loss: 1.282529]\n",
      "epoch:48 step:37921[D loss: 0.241229, acc: 89.06%, op_acc: 58.59%] [G loss: 1.445796]\n",
      "epoch:48 step:37922[D loss: 0.328986, acc: 74.22%, op_acc: 54.69%] [G loss: 0.818433]\n",
      "epoch:48 step:37923[D loss: 0.491431, acc: 46.88%, op_acc: 42.97%] [G loss: 1.935129]\n",
      "epoch:48 step:37924[D loss: 0.450935, acc: 60.16%, op_acc: 37.50%] [G loss: 1.453771]\n",
      "epoch:48 step:37925[D loss: 0.426406, acc: 61.72%, op_acc: 44.53%] [G loss: 1.810427]\n",
      "epoch:48 step:37926[D loss: 0.301906, acc: 79.69%, op_acc: 59.38%] [G loss: 1.499476]\n",
      "epoch:48 step:37927[D loss: 0.403784, acc: 64.84%, op_acc: 45.31%] [G loss: 1.330565]\n",
      "epoch:48 step:37928[D loss: 0.386519, acc: 67.19%, op_acc: 40.62%] [G loss: 1.272919]\n",
      "epoch:48 step:37929[D loss: 0.296163, acc: 81.25%, op_acc: 50.78%] [G loss: 1.356038]\n",
      "epoch:48 step:37930[D loss: 0.314417, acc: 79.69%, op_acc: 50.78%] [G loss: 1.560691]\n",
      "epoch:48 step:37931[D loss: 0.295789, acc: 82.03%, op_acc: 60.16%] [G loss: 1.334682]\n",
      "epoch:48 step:37932[D loss: 0.311459, acc: 77.34%, op_acc: 47.66%] [G loss: 1.011249]\n",
      "epoch:48 step:37933[D loss: 0.359077, acc: 72.66%, op_acc: 46.09%] [G loss: 0.887251]\n",
      "epoch:48 step:37934[D loss: 0.356420, acc: 71.09%, op_acc: 46.88%] [G loss: 1.152790]\n",
      "epoch:48 step:37935[D loss: 0.330183, acc: 78.91%, op_acc: 43.75%] [G loss: 1.129016]\n",
      "epoch:48 step:37936[D loss: 0.358292, acc: 70.31%, op_acc: 50.78%] [G loss: 0.969252]\n",
      "epoch:48 step:37937[D loss: 0.291634, acc: 85.16%, op_acc: 47.66%] [G loss: 1.189962]\n",
      "epoch:48 step:37938[D loss: 0.460932, acc: 57.81%, op_acc: 39.84%] [G loss: 0.861876]\n",
      "epoch:48 step:37939[D loss: 0.362982, acc: 73.44%, op_acc: 57.81%] [G loss: 1.169324]\n",
      "epoch:48 step:37940[D loss: 0.312854, acc: 75.00%, op_acc: 52.34%] [G loss: 1.199769]\n",
      "epoch:48 step:37941[D loss: 0.429299, acc: 55.47%, op_acc: 46.09%] [G loss: 1.243099]\n",
      "epoch:48 step:37942[D loss: 0.347926, acc: 69.53%, op_acc: 51.56%] [G loss: 1.550146]\n",
      "epoch:48 step:37943[D loss: 0.414409, acc: 61.72%, op_acc: 55.47%] [G loss: 1.228811]\n",
      "epoch:48 step:37944[D loss: 0.349521, acc: 71.88%, op_acc: 44.53%] [G loss: 1.517250]\n",
      "epoch:48 step:37945[D loss: 0.341356, acc: 75.00%, op_acc: 50.00%] [G loss: 1.009482]\n",
      "epoch:48 step:37946[D loss: 0.393217, acc: 65.62%, op_acc: 47.66%] [G loss: 0.973858]\n",
      "epoch:48 step:37947[D loss: 0.368508, acc: 67.19%, op_acc: 49.22%] [G loss: 1.187855]\n",
      "epoch:48 step:37948[D loss: 0.343501, acc: 73.44%, op_acc: 51.56%] [G loss: 1.247952]\n",
      "epoch:48 step:37949[D loss: 0.362809, acc: 71.88%, op_acc: 50.00%] [G loss: 1.196816]\n",
      "epoch:48 step:37950[D loss: 0.326404, acc: 73.44%, op_acc: 47.66%] [G loss: 1.303851]\n",
      "epoch:48 step:37951[D loss: 0.366150, acc: 70.31%, op_acc: 50.78%] [G loss: 0.996552]\n",
      "epoch:48 step:37952[D loss: 0.404759, acc: 67.97%, op_acc: 45.31%] [G loss: 1.135698]\n",
      "epoch:48 step:37953[D loss: 0.282131, acc: 85.94%, op_acc: 54.69%] [G loss: 1.381064]\n",
      "epoch:48 step:37954[D loss: 0.314751, acc: 83.59%, op_acc: 44.53%] [G loss: 1.116811]\n",
      "epoch:48 step:37955[D loss: 0.424848, acc: 62.50%, op_acc: 45.31%] [G loss: 1.329996]\n",
      "epoch:48 step:37956[D loss: 0.302169, acc: 84.38%, op_acc: 53.91%] [G loss: 1.463513]\n",
      "epoch:48 step:37957[D loss: 0.320138, acc: 76.56%, op_acc: 53.91%] [G loss: 0.908491]\n",
      "epoch:48 step:37958[D loss: 0.334596, acc: 72.66%, op_acc: 46.88%] [G loss: 1.185651]\n",
      "epoch:48 step:37959[D loss: 0.346434, acc: 75.00%, op_acc: 50.00%] [G loss: 1.564388]\n",
      "epoch:48 step:37960[D loss: 0.376263, acc: 71.88%, op_acc: 43.75%] [G loss: 1.412327]\n",
      "epoch:48 step:37961[D loss: 0.355369, acc: 69.53%, op_acc: 57.81%] [G loss: 1.279377]\n",
      "epoch:48 step:37962[D loss: 0.349667, acc: 75.78%, op_acc: 49.22%] [G loss: 1.096992]\n",
      "epoch:48 step:37963[D loss: 0.344828, acc: 67.19%, op_acc: 55.47%] [G loss: 0.909681]\n",
      "epoch:48 step:37964[D loss: 0.428291, acc: 64.84%, op_acc: 42.19%] [G loss: 0.872158]\n",
      "epoch:48 step:37965[D loss: 0.371094, acc: 72.66%, op_acc: 50.78%] [G loss: 1.217103]\n",
      "epoch:48 step:37966[D loss: 0.404826, acc: 61.72%, op_acc: 44.53%] [G loss: 1.080139]\n",
      "epoch:48 step:37967[D loss: 0.401815, acc: 69.53%, op_acc: 45.31%] [G loss: 1.359234]\n",
      "epoch:48 step:37968[D loss: 0.376851, acc: 66.41%, op_acc: 46.09%] [G loss: 1.287884]\n",
      "epoch:48 step:37969[D loss: 0.380153, acc: 69.53%, op_acc: 40.62%] [G loss: 1.124508]\n",
      "epoch:48 step:37970[D loss: 0.417733, acc: 64.84%, op_acc: 46.09%] [G loss: 1.371910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:37971[D loss: 0.363638, acc: 74.22%, op_acc: 48.44%] [G loss: 1.235284]\n",
      "epoch:48 step:37972[D loss: 0.334621, acc: 77.34%, op_acc: 51.56%] [G loss: 1.055564]\n",
      "epoch:48 step:37973[D loss: 0.402028, acc: 64.84%, op_acc: 45.31%] [G loss: 0.881584]\n",
      "epoch:48 step:37974[D loss: 0.339870, acc: 70.31%, op_acc: 49.22%] [G loss: 1.283659]\n",
      "epoch:48 step:37975[D loss: 0.338131, acc: 73.44%, op_acc: 46.88%] [G loss: 1.130733]\n",
      "epoch:48 step:37976[D loss: 0.349941, acc: 72.66%, op_acc: 47.66%] [G loss: 1.111524]\n",
      "epoch:48 step:37977[D loss: 0.352755, acc: 76.56%, op_acc: 51.56%] [G loss: 0.970715]\n",
      "epoch:48 step:37978[D loss: 0.295306, acc: 78.91%, op_acc: 50.78%] [G loss: 0.968094]\n",
      "epoch:48 step:37979[D loss: 0.459588, acc: 66.41%, op_acc: 41.41%] [G loss: 1.427736]\n",
      "epoch:48 step:37980[D loss: 0.345715, acc: 71.09%, op_acc: 50.78%] [G loss: 0.798535]\n",
      "epoch:48 step:37981[D loss: 0.355577, acc: 70.31%, op_acc: 50.78%] [G loss: 0.963176]\n",
      "epoch:48 step:37982[D loss: 0.341556, acc: 69.53%, op_acc: 56.25%] [G loss: 0.740223]\n",
      "epoch:48 step:37983[D loss: 0.399982, acc: 70.31%, op_acc: 47.66%] [G loss: 0.690656]\n",
      "epoch:48 step:37984[D loss: 0.302746, acc: 86.72%, op_acc: 48.44%] [G loss: 1.055114]\n",
      "epoch:48 step:37985[D loss: 0.298232, acc: 80.47%, op_acc: 51.56%] [G loss: 1.050870]\n",
      "epoch:48 step:37986[D loss: 0.388671, acc: 69.53%, op_acc: 48.44%] [G loss: 1.122228]\n",
      "epoch:48 step:37987[D loss: 0.378845, acc: 71.88%, op_acc: 47.66%] [G loss: 1.123043]\n",
      "epoch:48 step:37988[D loss: 0.337495, acc: 75.78%, op_acc: 48.44%] [G loss: 1.276046]\n",
      "epoch:48 step:37989[D loss: 0.395973, acc: 64.84%, op_acc: 43.75%] [G loss: 0.995815]\n",
      "epoch:48 step:37990[D loss: 0.313990, acc: 81.25%, op_acc: 54.69%] [G loss: 1.346345]\n",
      "epoch:48 step:37991[D loss: 0.265080, acc: 82.03%, op_acc: 55.47%] [G loss: 1.527181]\n",
      "epoch:48 step:37992[D loss: 0.362751, acc: 72.66%, op_acc: 54.69%] [G loss: 1.069424]\n",
      "epoch:48 step:37993[D loss: 0.335418, acc: 77.34%, op_acc: 52.34%] [G loss: 1.273313]\n",
      "epoch:48 step:37994[D loss: 0.358106, acc: 69.53%, op_acc: 46.88%] [G loss: 1.049208]\n",
      "epoch:48 step:37995[D loss: 0.353026, acc: 68.75%, op_acc: 50.78%] [G loss: 0.774221]\n",
      "epoch:48 step:37996[D loss: 0.414914, acc: 67.19%, op_acc: 38.28%] [G loss: 1.229351]\n",
      "epoch:48 step:37997[D loss: 0.329504, acc: 80.47%, op_acc: 50.78%] [G loss: 1.118030]\n",
      "epoch:48 step:37998[D loss: 0.297731, acc: 76.56%, op_acc: 51.56%] [G loss: 1.045121]\n",
      "epoch:48 step:37999[D loss: 0.396595, acc: 66.41%, op_acc: 48.44%] [G loss: 0.979231]\n",
      "epoch:48 step:38000[D loss: 0.428379, acc: 57.81%, op_acc: 41.41%] [G loss: 1.043226]\n",
      "epoch:48 step:38001[D loss: 0.414048, acc: 65.62%, op_acc: 41.41%] [G loss: 1.346200]\n",
      "epoch:48 step:38002[D loss: 0.503614, acc: 55.47%, op_acc: 37.50%] [G loss: 1.127844]\n",
      "epoch:48 step:38003[D loss: 0.432359, acc: 62.50%, op_acc: 37.50%] [G loss: 1.323260]\n",
      "epoch:48 step:38004[D loss: 0.368372, acc: 75.00%, op_acc: 46.88%] [G loss: 1.428720]\n",
      "epoch:48 step:38005[D loss: 0.381634, acc: 68.75%, op_acc: 50.78%] [G loss: 1.300829]\n",
      "epoch:48 step:38006[D loss: 0.389757, acc: 64.84%, op_acc: 50.78%] [G loss: 1.221069]\n",
      "epoch:48 step:38007[D loss: 0.252880, acc: 87.50%, op_acc: 55.47%] [G loss: 1.214893]\n",
      "epoch:48 step:38008[D loss: 0.366120, acc: 70.31%, op_acc: 53.12%] [G loss: 1.076779]\n",
      "epoch:48 step:38009[D loss: 0.318020, acc: 81.25%, op_acc: 40.62%] [G loss: 1.537830]\n",
      "epoch:48 step:38010[D loss: 0.394790, acc: 69.53%, op_acc: 45.31%] [G loss: 1.381567]\n",
      "epoch:48 step:38011[D loss: 0.399728, acc: 63.28%, op_acc: 50.00%] [G loss: 1.102292]\n",
      "epoch:48 step:38012[D loss: 0.309080, acc: 78.91%, op_acc: 50.00%] [G loss: 1.236290]\n",
      "epoch:48 step:38013[D loss: 0.355929, acc: 74.22%, op_acc: 50.00%] [G loss: 0.984905]\n",
      "epoch:48 step:38014[D loss: 0.394150, acc: 64.84%, op_acc: 47.66%] [G loss: 1.404714]\n",
      "epoch:48 step:38015[D loss: 0.455144, acc: 61.72%, op_acc: 40.62%] [G loss: 1.085150]\n",
      "epoch:48 step:38016[D loss: 0.383418, acc: 69.53%, op_acc: 41.41%] [G loss: 0.814645]\n",
      "epoch:48 step:38017[D loss: 0.323693, acc: 71.09%, op_acc: 55.47%] [G loss: 0.895290]\n",
      "epoch:48 step:38018[D loss: 0.356546, acc: 74.22%, op_acc: 45.31%] [G loss: 1.033827]\n",
      "epoch:48 step:38019[D loss: 0.319335, acc: 83.59%, op_acc: 53.12%] [G loss: 1.033794]\n",
      "epoch:48 step:38020[D loss: 0.438164, acc: 57.03%, op_acc: 44.53%] [G loss: 1.086446]\n",
      "epoch:48 step:38021[D loss: 0.329279, acc: 75.78%, op_acc: 50.00%] [G loss: 1.161069]\n",
      "epoch:48 step:38022[D loss: 0.354368, acc: 73.44%, op_acc: 54.69%] [G loss: 1.204945]\n",
      "epoch:48 step:38023[D loss: 0.360060, acc: 69.53%, op_acc: 46.88%] [G loss: 1.117552]\n",
      "epoch:48 step:38024[D loss: 0.320430, acc: 71.09%, op_acc: 54.69%] [G loss: 1.056179]\n",
      "epoch:48 step:38025[D loss: 0.399256, acc: 61.72%, op_acc: 48.44%] [G loss: 0.729158]\n",
      "epoch:48 step:38026[D loss: 0.341938, acc: 77.34%, op_acc: 45.31%] [G loss: 1.032907]\n",
      "epoch:48 step:38027[D loss: 0.320791, acc: 81.25%, op_acc: 58.59%] [G loss: 0.978121]\n",
      "epoch:48 step:38028[D loss: 0.386917, acc: 69.53%, op_acc: 44.53%] [G loss: 0.836640]\n",
      "epoch:48 step:38029[D loss: 0.430187, acc: 57.03%, op_acc: 46.88%] [G loss: 0.852556]\n",
      "epoch:48 step:38030[D loss: 0.342168, acc: 73.44%, op_acc: 50.00%] [G loss: 1.289699]\n",
      "epoch:48 step:38031[D loss: 0.360676, acc: 76.56%, op_acc: 46.09%] [G loss: 1.182665]\n",
      "epoch:48 step:38032[D loss: 0.295264, acc: 85.16%, op_acc: 53.91%] [G loss: 1.457992]\n",
      "epoch:48 step:38033[D loss: 0.265318, acc: 84.38%, op_acc: 51.56%] [G loss: 1.097528]\n",
      "epoch:48 step:38034[D loss: 0.399085, acc: 68.75%, op_acc: 50.78%] [G loss: 1.203446]\n",
      "epoch:48 step:38035[D loss: 0.350394, acc: 73.44%, op_acc: 53.12%] [G loss: 1.085813]\n",
      "epoch:48 step:38036[D loss: 0.329858, acc: 78.12%, op_acc: 45.31%] [G loss: 0.856393]\n",
      "epoch:48 step:38037[D loss: 0.330827, acc: 78.12%, op_acc: 46.09%] [G loss: 0.954319]\n",
      "epoch:48 step:38038[D loss: 0.289650, acc: 83.59%, op_acc: 47.66%] [G loss: 0.940699]\n",
      "epoch:48 step:38039[D loss: 0.368045, acc: 72.66%, op_acc: 49.22%] [G loss: 0.848007]\n",
      "epoch:48 step:38040[D loss: 0.405068, acc: 70.31%, op_acc: 41.41%] [G loss: 0.976004]\n",
      "epoch:48 step:38041[D loss: 0.311244, acc: 80.47%, op_acc: 42.97%] [G loss: 1.313656]\n",
      "epoch:48 step:38042[D loss: 0.286619, acc: 77.34%, op_acc: 55.47%] [G loss: 1.280885]\n",
      "epoch:48 step:38043[D loss: 0.332532, acc: 72.66%, op_acc: 56.25%] [G loss: 1.362480]\n",
      "epoch:48 step:38044[D loss: 0.412267, acc: 62.50%, op_acc: 57.03%] [G loss: 0.970672]\n",
      "epoch:48 step:38045[D loss: 0.372263, acc: 68.75%, op_acc: 42.19%] [G loss: 0.883368]\n",
      "epoch:48 step:38046[D loss: 0.346198, acc: 72.66%, op_acc: 51.56%] [G loss: 0.660474]\n",
      "epoch:48 step:38047[D loss: 0.280793, acc: 88.28%, op_acc: 47.66%] [G loss: 0.849728]\n",
      "epoch:48 step:38048[D loss: 0.456952, acc: 61.72%, op_acc: 39.84%] [G loss: 1.370931]\n",
      "epoch:48 step:38049[D loss: 0.391344, acc: 67.97%, op_acc: 46.09%] [G loss: 1.404251]\n",
      "epoch:48 step:38050[D loss: 0.388604, acc: 65.62%, op_acc: 47.66%] [G loss: 1.275684]\n",
      "epoch:48 step:38051[D loss: 0.343756, acc: 75.78%, op_acc: 47.66%] [G loss: 1.007893]\n",
      "epoch:48 step:38052[D loss: 0.397656, acc: 65.62%, op_acc: 43.75%] [G loss: 1.426308]\n",
      "epoch:48 step:38053[D loss: 0.395809, acc: 67.97%, op_acc: 48.44%] [G loss: 1.176300]\n",
      "epoch:48 step:38054[D loss: 0.336834, acc: 77.34%, op_acc: 53.91%] [G loss: 0.945166]\n",
      "epoch:48 step:38055[D loss: 0.409031, acc: 61.72%, op_acc: 47.66%] [G loss: 1.251865]\n",
      "epoch:48 step:38056[D loss: 0.412965, acc: 68.75%, op_acc: 46.09%] [G loss: 0.942954]\n",
      "epoch:48 step:38057[D loss: 0.316857, acc: 75.00%, op_acc: 53.12%] [G loss: 1.716578]\n",
      "epoch:48 step:38058[D loss: 0.337127, acc: 74.22%, op_acc: 45.31%] [G loss: 1.064734]\n",
      "epoch:48 step:38059[D loss: 0.412547, acc: 61.72%, op_acc: 49.22%] [G loss: 1.427225]\n",
      "epoch:48 step:38060[D loss: 0.365559, acc: 72.66%, op_acc: 49.22%] [G loss: 1.130660]\n",
      "epoch:48 step:38061[D loss: 0.348065, acc: 74.22%, op_acc: 50.78%] [G loss: 0.954548]\n",
      "epoch:48 step:38062[D loss: 0.395290, acc: 74.22%, op_acc: 40.62%] [G loss: 1.337794]\n",
      "epoch:48 step:38063[D loss: 0.364286, acc: 69.53%, op_acc: 45.31%] [G loss: 1.480685]\n",
      "epoch:48 step:38064[D loss: 0.353776, acc: 73.44%, op_acc: 53.12%] [G loss: 1.520952]\n",
      "epoch:48 step:38065[D loss: 0.416928, acc: 64.84%, op_acc: 43.75%] [G loss: 1.127488]\n",
      "epoch:48 step:38066[D loss: 0.471731, acc: 50.78%, op_acc: 38.28%] [G loss: 1.048054]\n",
      "epoch:48 step:38067[D loss: 0.327563, acc: 78.91%, op_acc: 52.34%] [G loss: 0.844652]\n",
      "epoch:48 step:38068[D loss: 0.396072, acc: 65.62%, op_acc: 40.62%] [G loss: 1.296842]\n",
      "epoch:48 step:38069[D loss: 0.399092, acc: 71.88%, op_acc: 48.44%] [G loss: 1.071811]\n",
      "epoch:48 step:38070[D loss: 0.352087, acc: 75.78%, op_acc: 46.88%] [G loss: 1.077275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38071[D loss: 0.344237, acc: 67.97%, op_acc: 49.22%] [G loss: 1.151877]\n",
      "epoch:48 step:38072[D loss: 0.385354, acc: 68.75%, op_acc: 46.88%] [G loss: 1.060413]\n",
      "epoch:48 step:38073[D loss: 0.360494, acc: 69.53%, op_acc: 47.66%] [G loss: 1.092440]\n",
      "epoch:48 step:38074[D loss: 0.348900, acc: 77.34%, op_acc: 42.97%] [G loss: 0.823249]\n",
      "epoch:48 step:38075[D loss: 0.355206, acc: 75.78%, op_acc: 47.66%] [G loss: 1.209474]\n",
      "epoch:48 step:38076[D loss: 0.351232, acc: 71.09%, op_acc: 58.59%] [G loss: 1.213605]\n",
      "epoch:48 step:38077[D loss: 0.292033, acc: 82.81%, op_acc: 53.91%] [G loss: 1.162590]\n",
      "epoch:48 step:38078[D loss: 0.314612, acc: 80.47%, op_acc: 50.78%] [G loss: 0.939306]\n",
      "epoch:48 step:38079[D loss: 0.355106, acc: 74.22%, op_acc: 52.34%] [G loss: 1.234686]\n",
      "epoch:48 step:38080[D loss: 0.338422, acc: 73.44%, op_acc: 53.91%] [G loss: 1.056731]\n",
      "epoch:48 step:38081[D loss: 0.398136, acc: 65.62%, op_acc: 44.53%] [G loss: 1.182186]\n",
      "epoch:48 step:38082[D loss: 0.426848, acc: 57.03%, op_acc: 41.41%] [G loss: 1.257420]\n",
      "epoch:48 step:38083[D loss: 0.407130, acc: 59.38%, op_acc: 49.22%] [G loss: 1.155774]\n",
      "epoch:48 step:38084[D loss: 0.303111, acc: 83.59%, op_acc: 53.12%] [G loss: 1.122785]\n",
      "epoch:48 step:38085[D loss: 0.416341, acc: 65.62%, op_acc: 46.88%] [G loss: 1.348414]\n",
      "epoch:48 step:38086[D loss: 0.281297, acc: 83.59%, op_acc: 51.56%] [G loss: 1.478878]\n",
      "epoch:48 step:38087[D loss: 0.293573, acc: 82.81%, op_acc: 48.44%] [G loss: 1.511511]\n",
      "epoch:48 step:38088[D loss: 0.327117, acc: 75.00%, op_acc: 49.22%] [G loss: 1.486045]\n",
      "epoch:48 step:38089[D loss: 0.344307, acc: 73.44%, op_acc: 46.88%] [G loss: 1.435209]\n",
      "epoch:48 step:38090[D loss: 0.290325, acc: 79.69%, op_acc: 59.38%] [G loss: 1.754558]\n",
      "epoch:48 step:38091[D loss: 0.325280, acc: 75.00%, op_acc: 53.12%] [G loss: 1.548659]\n",
      "epoch:48 step:38092[D loss: 0.335857, acc: 80.47%, op_acc: 51.56%] [G loss: 1.335669]\n",
      "epoch:48 step:38093[D loss: 0.280183, acc: 87.50%, op_acc: 58.59%] [G loss: 0.769305]\n",
      "epoch:48 step:38094[D loss: 0.506903, acc: 54.69%, op_acc: 39.84%] [G loss: 1.689150]\n",
      "epoch:48 step:38095[D loss: 0.541995, acc: 39.84%, op_acc: 41.41%] [G loss: 1.828439]\n",
      "epoch:48 step:38096[D loss: 0.310726, acc: 77.34%, op_acc: 47.66%] [G loss: 1.692036]\n",
      "epoch:48 step:38097[D loss: 0.429471, acc: 63.28%, op_acc: 42.97%] [G loss: 1.086755]\n",
      "epoch:48 step:38098[D loss: 0.336527, acc: 78.12%, op_acc: 45.31%] [G loss: 1.629365]\n",
      "epoch:48 step:38099[D loss: 0.343142, acc: 77.34%, op_acc: 53.12%] [G loss: 1.646563]\n",
      "epoch:48 step:38100[D loss: 0.417270, acc: 63.28%, op_acc: 39.06%] [G loss: 1.425311]\n",
      "epoch:48 step:38101[D loss: 0.384008, acc: 67.19%, op_acc: 47.66%] [G loss: 1.246311]\n",
      "epoch:48 step:38102[D loss: 0.386406, acc: 64.84%, op_acc: 45.31%] [G loss: 1.563165]\n",
      "epoch:48 step:38103[D loss: 0.397160, acc: 61.72%, op_acc: 46.09%] [G loss: 1.724378]\n",
      "epoch:48 step:38104[D loss: 0.383126, acc: 71.09%, op_acc: 39.84%] [G loss: 1.343443]\n",
      "epoch:48 step:38105[D loss: 0.383419, acc: 67.97%, op_acc: 51.56%] [G loss: 1.388520]\n",
      "epoch:48 step:38106[D loss: 0.362369, acc: 71.09%, op_acc: 50.00%] [G loss: 1.113017]\n",
      "epoch:48 step:38107[D loss: 0.420431, acc: 64.84%, op_acc: 42.19%] [G loss: 1.431423]\n",
      "epoch:48 step:38108[D loss: 0.371747, acc: 68.75%, op_acc: 40.62%] [G loss: 1.244182]\n",
      "epoch:48 step:38109[D loss: 0.395859, acc: 67.19%, op_acc: 51.56%] [G loss: 1.349096]\n",
      "epoch:48 step:38110[D loss: 0.340189, acc: 78.12%, op_acc: 45.31%] [G loss: 1.224556]\n",
      "epoch:48 step:38111[D loss: 0.324601, acc: 76.56%, op_acc: 54.69%] [G loss: 1.324751]\n",
      "epoch:48 step:38112[D loss: 0.371802, acc: 72.66%, op_acc: 42.19%] [G loss: 1.070095]\n",
      "epoch:48 step:38113[D loss: 0.489369, acc: 55.47%, op_acc: 39.84%] [G loss: 1.164820]\n",
      "epoch:48 step:38114[D loss: 0.384644, acc: 71.09%, op_acc: 50.78%] [G loss: 1.062005]\n",
      "epoch:48 step:38115[D loss: 0.321523, acc: 73.44%, op_acc: 46.88%] [G loss: 1.380152]\n",
      "epoch:48 step:38116[D loss: 0.319908, acc: 84.38%, op_acc: 48.44%] [G loss: 1.014296]\n",
      "epoch:48 step:38117[D loss: 0.359573, acc: 73.44%, op_acc: 46.88%] [G loss: 1.409817]\n",
      "epoch:48 step:38118[D loss: 0.324018, acc: 78.91%, op_acc: 57.81%] [G loss: 1.182396]\n",
      "epoch:48 step:38119[D loss: 0.399058, acc: 73.44%, op_acc: 47.66%] [G loss: 1.054680]\n",
      "epoch:48 step:38120[D loss: 0.323919, acc: 78.12%, op_acc: 46.88%] [G loss: 1.196758]\n",
      "epoch:48 step:38121[D loss: 0.408339, acc: 70.31%, op_acc: 42.97%] [G loss: 1.007873]\n",
      "epoch:48 step:38122[D loss: 0.314765, acc: 80.47%, op_acc: 50.78%] [G loss: 0.976258]\n",
      "epoch:48 step:38123[D loss: 0.359937, acc: 71.09%, op_acc: 50.00%] [G loss: 1.181522]\n",
      "epoch:48 step:38124[D loss: 0.318504, acc: 78.12%, op_acc: 50.78%] [G loss: 1.247893]\n",
      "epoch:48 step:38125[D loss: 0.368411, acc: 67.97%, op_acc: 46.88%] [G loss: 0.991907]\n",
      "epoch:48 step:38126[D loss: 0.401358, acc: 66.41%, op_acc: 49.22%] [G loss: 1.344383]\n",
      "epoch:48 step:38127[D loss: 0.355017, acc: 76.56%, op_acc: 46.09%] [G loss: 0.913274]\n",
      "epoch:48 step:38128[D loss: 0.378940, acc: 71.09%, op_acc: 46.88%] [G loss: 1.077995]\n",
      "epoch:48 step:38129[D loss: 0.338738, acc: 74.22%, op_acc: 46.09%] [G loss: 0.951087]\n",
      "epoch:48 step:38130[D loss: 0.327227, acc: 81.25%, op_acc: 45.31%] [G loss: 0.988823]\n",
      "epoch:48 step:38131[D loss: 0.348751, acc: 71.09%, op_acc: 46.88%] [G loss: 1.177808]\n",
      "epoch:48 step:38132[D loss: 0.307290, acc: 80.47%, op_acc: 53.91%] [G loss: 0.846553]\n",
      "epoch:48 step:38133[D loss: 0.348507, acc: 73.44%, op_acc: 42.19%] [G loss: 1.135950]\n",
      "epoch:48 step:38134[D loss: 0.323268, acc: 81.25%, op_acc: 50.78%] [G loss: 1.599243]\n",
      "epoch:48 step:38135[D loss: 0.371396, acc: 67.97%, op_acc: 49.22%] [G loss: 1.019260]\n",
      "epoch:48 step:38136[D loss: 0.270027, acc: 85.16%, op_acc: 53.12%] [G loss: 1.295039]\n",
      "epoch:48 step:38137[D loss: 0.333573, acc: 79.69%, op_acc: 47.66%] [G loss: 1.144299]\n",
      "epoch:48 step:38138[D loss: 0.325729, acc: 78.91%, op_acc: 53.12%] [G loss: 1.571679]\n",
      "epoch:48 step:38139[D loss: 0.341344, acc: 71.88%, op_acc: 55.47%] [G loss: 1.485923]\n",
      "epoch:48 step:38140[D loss: 0.364517, acc: 69.53%, op_acc: 42.19%] [G loss: 1.403708]\n",
      "epoch:48 step:38141[D loss: 0.327441, acc: 76.56%, op_acc: 50.00%] [G loss: 1.304278]\n",
      "epoch:48 step:38142[D loss: 0.328721, acc: 76.56%, op_acc: 45.31%] [G loss: 1.439337]\n",
      "epoch:48 step:38143[D loss: 0.341975, acc: 75.00%, op_acc: 50.00%] [G loss: 0.907744]\n",
      "epoch:48 step:38144[D loss: 0.425680, acc: 67.97%, op_acc: 39.06%] [G loss: 1.555243]\n",
      "epoch:48 step:38145[D loss: 0.386642, acc: 66.41%, op_acc: 51.56%] [G loss: 1.290203]\n",
      "epoch:48 step:38146[D loss: 0.338651, acc: 73.44%, op_acc: 52.34%] [G loss: 1.275193]\n",
      "epoch:48 step:38147[D loss: 0.320963, acc: 78.91%, op_acc: 49.22%] [G loss: 1.559633]\n",
      "epoch:48 step:38148[D loss: 0.333884, acc: 75.78%, op_acc: 50.00%] [G loss: 1.377228]\n",
      "epoch:48 step:38149[D loss: 0.361003, acc: 70.31%, op_acc: 42.97%] [G loss: 1.302707]\n",
      "epoch:48 step:38150[D loss: 0.330646, acc: 76.56%, op_acc: 51.56%] [G loss: 1.235689]\n",
      "epoch:48 step:38151[D loss: 0.376704, acc: 68.75%, op_acc: 48.44%] [G loss: 1.276619]\n",
      "epoch:48 step:38152[D loss: 0.289075, acc: 82.81%, op_acc: 53.91%] [G loss: 1.291063]\n",
      "epoch:48 step:38153[D loss: 0.345858, acc: 76.56%, op_acc: 46.88%] [G loss: 1.287114]\n",
      "epoch:48 step:38154[D loss: 0.390072, acc: 69.53%, op_acc: 39.84%] [G loss: 1.188041]\n",
      "epoch:48 step:38155[D loss: 0.311481, acc: 75.78%, op_acc: 57.81%] [G loss: 1.171504]\n",
      "epoch:48 step:38156[D loss: 0.448327, acc: 60.16%, op_acc: 45.31%] [G loss: 1.438903]\n",
      "epoch:48 step:38157[D loss: 0.381241, acc: 67.19%, op_acc: 46.88%] [G loss: 1.437195]\n",
      "epoch:48 step:38158[D loss: 0.334597, acc: 75.00%, op_acc: 53.12%] [G loss: 1.482982]\n",
      "epoch:48 step:38159[D loss: 0.345643, acc: 73.44%, op_acc: 47.66%] [G loss: 1.698149]\n",
      "epoch:48 step:38160[D loss: 0.340491, acc: 80.47%, op_acc: 42.97%] [G loss: 1.336515]\n",
      "epoch:48 step:38161[D loss: 0.407322, acc: 67.97%, op_acc: 39.84%] [G loss: 1.378600]\n",
      "epoch:48 step:38162[D loss: 0.423204, acc: 55.47%, op_acc: 47.66%] [G loss: 1.069712]\n",
      "epoch:48 step:38163[D loss: 0.360314, acc: 74.22%, op_acc: 46.09%] [G loss: 1.685632]\n",
      "epoch:48 step:38164[D loss: 0.399349, acc: 61.72%, op_acc: 50.00%] [G loss: 1.155516]\n",
      "epoch:48 step:38165[D loss: 0.409180, acc: 64.84%, op_acc: 41.41%] [G loss: 1.435536]\n",
      "epoch:48 step:38166[D loss: 0.356595, acc: 71.88%, op_acc: 43.75%] [G loss: 1.447502]\n",
      "epoch:48 step:38167[D loss: 0.343445, acc: 70.31%, op_acc: 55.47%] [G loss: 1.438273]\n",
      "epoch:48 step:38168[D loss: 0.414894, acc: 65.62%, op_acc: 42.19%] [G loss: 1.024069]\n",
      "epoch:48 step:38169[D loss: 0.374155, acc: 76.56%, op_acc: 53.91%] [G loss: 1.210213]\n",
      "epoch:48 step:38170[D loss: 0.378209, acc: 67.97%, op_acc: 46.88%] [G loss: 1.175822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48 step:38171[D loss: 0.340970, acc: 73.44%, op_acc: 53.12%] [G loss: 1.123692]\n",
      "epoch:48 step:38172[D loss: 0.402114, acc: 67.19%, op_acc: 45.31%] [G loss: 1.447354]\n",
      "epoch:48 step:38173[D loss: 0.380728, acc: 70.31%, op_acc: 42.19%] [G loss: 1.258685]\n",
      "epoch:48 step:38174[D loss: 0.432584, acc: 56.25%, op_acc: 47.66%] [G loss: 1.506896]\n",
      "epoch:48 step:38175[D loss: 0.262748, acc: 89.06%, op_acc: 52.34%] [G loss: 1.487741]\n",
      "epoch:48 step:38176[D loss: 0.445721, acc: 58.59%, op_acc: 50.00%] [G loss: 1.310340]\n",
      "epoch:48 step:38177[D loss: 0.327251, acc: 77.34%, op_acc: 57.81%] [G loss: 0.941331]\n",
      "epoch:48 step:38178[D loss: 0.394216, acc: 71.88%, op_acc: 33.59%] [G loss: 1.542174]\n",
      "epoch:48 step:38179[D loss: 0.343545, acc: 77.34%, op_acc: 39.06%] [G loss: 1.455734]\n",
      "epoch:48 step:38180[D loss: 0.530713, acc: 55.47%, op_acc: 47.66%] [G loss: 1.243719]\n",
      "epoch:48 step:38181[D loss: 0.400598, acc: 68.75%, op_acc: 46.09%] [G loss: 1.109452]\n",
      "epoch:48 step:38182[D loss: 0.377728, acc: 70.31%, op_acc: 46.09%] [G loss: 1.189364]\n",
      "epoch:48 step:38183[D loss: 0.282127, acc: 82.81%, op_acc: 53.91%] [G loss: 1.213491]\n",
      "epoch:48 step:38184[D loss: 0.425192, acc: 57.81%, op_acc: 39.06%] [G loss: 1.191565]\n",
      "epoch:48 step:38185[D loss: 0.362588, acc: 71.09%, op_acc: 51.56%] [G loss: 1.179796]\n",
      "epoch:48 step:38186[D loss: 0.352759, acc: 73.44%, op_acc: 46.09%] [G loss: 1.332139]\n",
      "epoch:48 step:38187[D loss: 0.296426, acc: 80.47%, op_acc: 60.16%] [G loss: 1.214822]\n",
      "epoch:48 step:38188[D loss: 0.372054, acc: 73.44%, op_acc: 43.75%] [G loss: 1.390996]\n",
      "epoch:48 step:38189[D loss: 0.383234, acc: 64.06%, op_acc: 47.66%] [G loss: 1.188396]\n",
      "epoch:48 step:38190[D loss: 0.325844, acc: 77.34%, op_acc: 44.53%] [G loss: 1.262502]\n",
      "epoch:48 step:38191[D loss: 0.375410, acc: 70.31%, op_acc: 50.78%] [G loss: 0.849729]\n",
      "epoch:48 step:38192[D loss: 0.354107, acc: 70.31%, op_acc: 50.00%] [G loss: 1.107933]\n",
      "epoch:48 step:38193[D loss: 0.371285, acc: 71.88%, op_acc: 49.22%] [G loss: 0.974832]\n",
      "epoch:48 step:38194[D loss: 0.336868, acc: 78.91%, op_acc: 50.78%] [G loss: 1.214191]\n",
      "epoch:48 step:38195[D loss: 0.457295, acc: 60.94%, op_acc: 44.53%] [G loss: 0.837738]\n",
      "epoch:48 step:38196[D loss: 0.371415, acc: 67.97%, op_acc: 45.31%] [G loss: 1.196731]\n",
      "epoch:48 step:38197[D loss: 0.329594, acc: 77.34%, op_acc: 47.66%] [G loss: 0.992504]\n",
      "epoch:48 step:38198[D loss: 0.281169, acc: 81.25%, op_acc: 53.91%] [G loss: 1.169992]\n",
      "epoch:48 step:38199[D loss: 0.384250, acc: 69.53%, op_acc: 42.19%] [G loss: 1.252562]\n",
      "epoch:48 step:38200[D loss: 0.355687, acc: 69.53%, op_acc: 51.56%] [G loss: 1.055434]\n",
      "epoch:48 step:38201[D loss: 0.402782, acc: 66.41%, op_acc: 50.00%] [G loss: 0.705943]\n",
      "epoch:48 step:38202[D loss: 0.333408, acc: 75.78%, op_acc: 45.31%] [G loss: 0.945226]\n",
      "epoch:48 step:38203[D loss: 0.338160, acc: 75.00%, op_acc: 46.88%] [G loss: 1.276306]\n",
      "epoch:48 step:38204[D loss: 0.387490, acc: 70.31%, op_acc: 46.09%] [G loss: 1.073566]\n",
      "epoch:48 step:38205[D loss: 0.284405, acc: 85.94%, op_acc: 60.16%] [G loss: 1.125698]\n",
      "epoch:48 step:38206[D loss: 0.335937, acc: 74.22%, op_acc: 56.25%] [G loss: 1.102482]\n",
      "epoch:48 step:38207[D loss: 0.264197, acc: 85.16%, op_acc: 55.47%] [G loss: 1.170774]\n",
      "epoch:48 step:38208[D loss: 0.287950, acc: 83.59%, op_acc: 50.78%] [G loss: 1.094097]\n",
      "epoch:48 step:38209[D loss: 0.375446, acc: 67.19%, op_acc: 46.88%] [G loss: 0.910222]\n",
      "epoch:48 step:38210[D loss: 0.387085, acc: 67.19%, op_acc: 45.31%] [G loss: 1.346874]\n",
      "epoch:48 step:38211[D loss: 0.400784, acc: 64.06%, op_acc: 46.88%] [G loss: 1.341449]\n",
      "epoch:48 step:38212[D loss: 0.429830, acc: 65.62%, op_acc: 31.25%] [G loss: 1.269382]\n",
      "epoch:48 step:38213[D loss: 0.347942, acc: 73.44%, op_acc: 39.06%] [G loss: 1.259352]\n",
      "epoch:48 step:38214[D loss: 0.311630, acc: 75.78%, op_acc: 57.81%] [G loss: 1.005519]\n",
      "epoch:48 step:38215[D loss: 0.380720, acc: 68.75%, op_acc: 49.22%] [G loss: 1.070563]\n",
      "epoch:48 step:38216[D loss: 0.395437, acc: 67.97%, op_acc: 46.09%] [G loss: 1.099252]\n",
      "epoch:48 step:38217[D loss: 0.290362, acc: 79.69%, op_acc: 51.56%] [G loss: 1.169382]\n",
      "epoch:48 step:38218[D loss: 0.339809, acc: 78.12%, op_acc: 52.34%] [G loss: 1.112338]\n",
      "epoch:48 step:38219[D loss: 0.301239, acc: 78.12%, op_acc: 54.69%] [G loss: 1.208567]\n",
      "epoch:48 step:38220[D loss: 0.353837, acc: 72.66%, op_acc: 46.88%] [G loss: 1.116141]\n",
      "epoch:48 step:38221[D loss: 0.343570, acc: 75.00%, op_acc: 46.09%] [G loss: 1.527966]\n",
      "epoch:48 step:38222[D loss: 0.312286, acc: 75.78%, op_acc: 49.22%] [G loss: 0.972481]\n",
      "epoch:48 step:38223[D loss: 0.390132, acc: 71.09%, op_acc: 42.19%] [G loss: 1.305487]\n",
      "epoch:48 step:38224[D loss: 0.419881, acc: 70.31%, op_acc: 48.44%] [G loss: 1.466851]\n",
      "epoch:48 step:38225[D loss: 0.386776, acc: 67.19%, op_acc: 44.53%] [G loss: 1.321347]\n",
      "epoch:48 step:38226[D loss: 0.374192, acc: 71.09%, op_acc: 52.34%] [G loss: 1.022730]\n",
      "epoch:48 step:38227[D loss: 0.394292, acc: 65.62%, op_acc: 48.44%] [G loss: 0.932775]\n",
      "epoch:48 step:38228[D loss: 0.389454, acc: 71.09%, op_acc: 43.75%] [G loss: 1.193007]\n",
      "epoch:48 step:38229[D loss: 0.401617, acc: 71.88%, op_acc: 47.66%] [G loss: 0.870051]\n",
      "epoch:48 step:38230[D loss: 0.420848, acc: 68.75%, op_acc: 38.28%] [G loss: 1.241314]\n",
      "epoch:48 step:38231[D loss: 0.365490, acc: 72.66%, op_acc: 45.31%] [G loss: 0.920617]\n",
      "epoch:48 step:38232[D loss: 0.267096, acc: 82.81%, op_acc: 55.47%] [G loss: 1.270364]\n",
      "epoch:48 step:38233[D loss: 0.402030, acc: 64.84%, op_acc: 41.41%] [G loss: 1.359862]\n",
      "epoch:48 step:38234[D loss: 0.321560, acc: 75.00%, op_acc: 59.38%] [G loss: 1.088594]\n",
      "epoch:48 step:38235[D loss: 0.335123, acc: 79.69%, op_acc: 53.12%] [G loss: 1.446589]\n",
      "epoch:48 step:38236[D loss: 0.381083, acc: 72.66%, op_acc: 46.88%] [G loss: 0.962434]\n",
      "epoch:48 step:38237[D loss: 0.377654, acc: 70.31%, op_acc: 50.78%] [G loss: 1.482026]\n",
      "epoch:48 step:38238[D loss: 0.428904, acc: 61.72%, op_acc: 46.88%] [G loss: 1.086923]\n",
      "epoch:48 step:38239[D loss: 0.420221, acc: 66.41%, op_acc: 37.50%] [G loss: 1.164415]\n",
      "epoch:48 step:38240[D loss: 0.403022, acc: 67.19%, op_acc: 47.66%] [G loss: 1.481788]\n",
      "epoch:48 step:38241[D loss: 0.368494, acc: 68.75%, op_acc: 50.78%] [G loss: 1.231908]\n",
      "epoch:48 step:38242[D loss: 0.371819, acc: 72.66%, op_acc: 45.31%] [G loss: 1.131584]\n",
      "epoch:48 step:38243[D loss: 0.321555, acc: 76.56%, op_acc: 53.12%] [G loss: 1.462888]\n",
      "epoch:48 step:38244[D loss: 0.386179, acc: 67.97%, op_acc: 42.97%] [G loss: 1.067936]\n",
      "epoch:48 step:38245[D loss: 0.307647, acc: 78.91%, op_acc: 53.91%] [G loss: 1.414513]\n",
      "epoch:48 step:38246[D loss: 0.401719, acc: 66.41%, op_acc: 56.25%] [G loss: 1.255445]\n",
      "epoch:48 step:38247[D loss: 0.399462, acc: 68.75%, op_acc: 44.53%] [G loss: 1.278255]\n",
      "epoch:48 step:38248[D loss: 0.386491, acc: 66.41%, op_acc: 52.34%] [G loss: 1.289910]\n",
      "epoch:48 step:38249[D loss: 0.351139, acc: 69.53%, op_acc: 49.22%] [G loss: 1.285920]\n",
      "epoch:48 step:38250[D loss: 0.426787, acc: 67.97%, op_acc: 41.41%] [G loss: 1.160301]\n",
      "epoch:48 step:38251[D loss: 0.402259, acc: 59.38%, op_acc: 49.22%] [G loss: 1.141984]\n",
      "epoch:48 step:38252[D loss: 0.395298, acc: 68.75%, op_acc: 41.41%] [G loss: 1.673943]\n",
      "epoch:48 step:38253[D loss: 0.310545, acc: 77.34%, op_acc: 49.22%] [G loss: 1.569994]\n",
      "epoch:48 step:38254[D loss: 0.442999, acc: 53.91%, op_acc: 46.88%] [G loss: 1.430213]\n",
      "epoch:48 step:38255[D loss: 0.313293, acc: 77.34%, op_acc: 50.78%] [G loss: 1.273828]\n",
      "epoch:48 step:38256[D loss: 0.324640, acc: 77.34%, op_acc: 51.56%] [G loss: 1.422651]\n",
      "epoch:48 step:38257[D loss: 0.376223, acc: 67.97%, op_acc: 48.44%] [G loss: 1.393538]\n",
      "epoch:48 step:38258[D loss: 0.371800, acc: 70.31%, op_acc: 47.66%] [G loss: 1.168903]\n",
      "epoch:48 step:38259[D loss: 0.580050, acc: 40.62%, op_acc: 32.81%] [G loss: 1.183594]\n",
      "epoch:48 step:38260[D loss: 0.460343, acc: 59.38%, op_acc: 38.28%] [G loss: 0.879594]\n",
      "epoch:48 step:38261[D loss: 0.355828, acc: 74.22%, op_acc: 44.53%] [G loss: 1.327693]\n",
      "epoch:48 step:38262[D loss: 0.304359, acc: 83.59%, op_acc: 51.56%] [G loss: 1.397380]\n",
      "epoch:48 step:38263[D loss: 0.380014, acc: 67.19%, op_acc: 49.22%] [G loss: 1.684153]\n",
      "epoch:48 step:38264[D loss: 0.376741, acc: 71.88%, op_acc: 47.66%] [G loss: 1.391419]\n",
      "epoch:48 step:38265[D loss: 0.370637, acc: 68.75%, op_acc: 54.69%] [G loss: 1.329722]\n",
      "epoch:48 step:38266[D loss: 0.329647, acc: 74.22%, op_acc: 53.91%] [G loss: 1.372693]\n",
      "epoch:48 step:38267[D loss: 0.347568, acc: 75.00%, op_acc: 46.09%] [G loss: 1.447962]\n",
      "epoch:48 step:38268[D loss: 0.245635, acc: 86.72%, op_acc: 64.06%] [G loss: 1.588145]\n",
      "epoch:48 step:38269[D loss: 0.366341, acc: 73.44%, op_acc: 47.66%] [G loss: 1.155746]\n",
      "epoch:49 step:38270[D loss: 0.456508, acc: 53.91%, op_acc: 45.31%] [G loss: 1.279590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38271[D loss: 0.352380, acc: 67.19%, op_acc: 47.66%] [G loss: 1.137660]\n",
      "epoch:49 step:38272[D loss: 0.379675, acc: 71.09%, op_acc: 42.97%] [G loss: 1.562540]\n",
      "epoch:49 step:38273[D loss: 0.315793, acc: 78.12%, op_acc: 52.34%] [G loss: 1.519015]\n",
      "epoch:49 step:38274[D loss: 0.298126, acc: 78.12%, op_acc: 50.78%] [G loss: 1.436794]\n",
      "epoch:49 step:38275[D loss: 0.469007, acc: 57.81%, op_acc: 39.84%] [G loss: 0.941680]\n",
      "epoch:49 step:38276[D loss: 0.401104, acc: 64.84%, op_acc: 46.09%] [G loss: 1.315428]\n",
      "epoch:49 step:38277[D loss: 0.328469, acc: 75.00%, op_acc: 42.97%] [G loss: 1.367253]\n",
      "epoch:49 step:38278[D loss: 0.343218, acc: 72.66%, op_acc: 45.31%] [G loss: 1.497931]\n",
      "epoch:49 step:38279[D loss: 0.372531, acc: 68.75%, op_acc: 46.88%] [G loss: 1.559354]\n",
      "epoch:49 step:38280[D loss: 0.401974, acc: 69.53%, op_acc: 39.06%] [G loss: 1.444934]\n",
      "epoch:49 step:38281[D loss: 0.371847, acc: 73.44%, op_acc: 47.66%] [G loss: 1.557609]\n",
      "epoch:49 step:38282[D loss: 0.323133, acc: 75.78%, op_acc: 43.75%] [G loss: 1.371260]\n",
      "epoch:49 step:38283[D loss: 0.355062, acc: 72.66%, op_acc: 42.19%] [G loss: 1.527757]\n",
      "epoch:49 step:38284[D loss: 0.362709, acc: 65.62%, op_acc: 46.88%] [G loss: 1.419633]\n",
      "epoch:49 step:38285[D loss: 0.419068, acc: 63.28%, op_acc: 46.09%] [G loss: 1.090996]\n",
      "epoch:49 step:38286[D loss: 0.361545, acc: 74.22%, op_acc: 46.09%] [G loss: 1.089903]\n",
      "epoch:49 step:38287[D loss: 0.383103, acc: 64.06%, op_acc: 44.53%] [G loss: 1.348405]\n",
      "epoch:49 step:38288[D loss: 0.384754, acc: 68.75%, op_acc: 46.09%] [G loss: 1.139852]\n",
      "epoch:49 step:38289[D loss: 0.363607, acc: 74.22%, op_acc: 50.00%] [G loss: 1.338714]\n",
      "epoch:49 step:38290[D loss: 0.434478, acc: 66.41%, op_acc: 41.41%] [G loss: 1.078159]\n",
      "epoch:49 step:38291[D loss: 0.335826, acc: 75.78%, op_acc: 46.09%] [G loss: 1.187650]\n",
      "epoch:49 step:38292[D loss: 0.371364, acc: 66.41%, op_acc: 50.78%] [G loss: 1.211746]\n",
      "epoch:49 step:38293[D loss: 0.430240, acc: 61.72%, op_acc: 42.97%] [G loss: 1.154422]\n",
      "epoch:49 step:38294[D loss: 0.417004, acc: 67.19%, op_acc: 40.62%] [G loss: 1.184108]\n",
      "epoch:49 step:38295[D loss: 0.344184, acc: 74.22%, op_acc: 43.75%] [G loss: 1.048683]\n",
      "epoch:49 step:38296[D loss: 0.379339, acc: 67.97%, op_acc: 50.00%] [G loss: 0.977415]\n",
      "epoch:49 step:38297[D loss: 0.349987, acc: 75.00%, op_acc: 49.22%] [G loss: 1.156220]\n",
      "epoch:49 step:38298[D loss: 0.404415, acc: 59.38%, op_acc: 45.31%] [G loss: 1.228277]\n",
      "epoch:49 step:38299[D loss: 0.361224, acc: 69.53%, op_acc: 46.88%] [G loss: 1.360981]\n",
      "epoch:49 step:38300[D loss: 0.310129, acc: 84.38%, op_acc: 45.31%] [G loss: 1.086244]\n",
      "epoch:49 step:38301[D loss: 0.420298, acc: 66.41%, op_acc: 41.41%] [G loss: 1.130673]\n",
      "epoch:49 step:38302[D loss: 0.421872, acc: 61.72%, op_acc: 44.53%] [G loss: 1.047117]\n",
      "epoch:49 step:38303[D loss: 0.422527, acc: 59.38%, op_acc: 41.41%] [G loss: 1.196324]\n",
      "epoch:49 step:38304[D loss: 0.385654, acc: 72.66%, op_acc: 47.66%] [G loss: 1.055450]\n",
      "epoch:49 step:38305[D loss: 0.285363, acc: 80.47%, op_acc: 56.25%] [G loss: 1.148268]\n",
      "epoch:49 step:38306[D loss: 0.343374, acc: 75.00%, op_acc: 46.88%] [G loss: 1.287815]\n",
      "epoch:49 step:38307[D loss: 0.342564, acc: 74.22%, op_acc: 42.19%] [G loss: 1.365679]\n",
      "epoch:49 step:38308[D loss: 0.313167, acc: 77.34%, op_acc: 57.81%] [G loss: 1.156850]\n",
      "epoch:49 step:38309[D loss: 0.351387, acc: 74.22%, op_acc: 41.41%] [G loss: 0.934028]\n",
      "epoch:49 step:38310[D loss: 0.266040, acc: 80.47%, op_acc: 56.25%] [G loss: 1.225677]\n",
      "epoch:49 step:38311[D loss: 0.354576, acc: 67.19%, op_acc: 48.44%] [G loss: 1.279866]\n",
      "epoch:49 step:38312[D loss: 0.343746, acc: 79.69%, op_acc: 49.22%] [G loss: 1.090376]\n",
      "epoch:49 step:38313[D loss: 0.317754, acc: 75.00%, op_acc: 55.47%] [G loss: 1.322296]\n",
      "epoch:49 step:38314[D loss: 0.385293, acc: 73.44%, op_acc: 39.06%] [G loss: 1.150353]\n",
      "epoch:49 step:38315[D loss: 0.374729, acc: 72.66%, op_acc: 41.41%] [G loss: 1.043552]\n",
      "epoch:49 step:38316[D loss: 0.395800, acc: 68.75%, op_acc: 46.88%] [G loss: 1.031973]\n",
      "epoch:49 step:38317[D loss: 0.371350, acc: 68.75%, op_acc: 47.66%] [G loss: 1.249537]\n",
      "epoch:49 step:38318[D loss: 0.357142, acc: 71.88%, op_acc: 48.44%] [G loss: 1.151012]\n",
      "epoch:49 step:38319[D loss: 0.400263, acc: 61.72%, op_acc: 46.88%] [G loss: 0.912824]\n",
      "epoch:49 step:38320[D loss: 0.303211, acc: 84.38%, op_acc: 54.69%] [G loss: 1.369978]\n",
      "epoch:49 step:38321[D loss: 0.401497, acc: 69.53%, op_acc: 47.66%] [G loss: 0.922560]\n",
      "epoch:49 step:38322[D loss: 0.404174, acc: 69.53%, op_acc: 37.50%] [G loss: 0.756936]\n",
      "epoch:49 step:38323[D loss: 0.451841, acc: 57.81%, op_acc: 36.72%] [G loss: 0.715446]\n",
      "epoch:49 step:38324[D loss: 0.308999, acc: 80.47%, op_acc: 53.12%] [G loss: 1.070381]\n",
      "epoch:49 step:38325[D loss: 0.350798, acc: 74.22%, op_acc: 49.22%] [G loss: 1.219937]\n",
      "epoch:49 step:38326[D loss: 0.355149, acc: 72.66%, op_acc: 53.12%] [G loss: 1.010972]\n",
      "epoch:49 step:38327[D loss: 0.291558, acc: 79.69%, op_acc: 57.03%] [G loss: 1.082321]\n",
      "epoch:49 step:38328[D loss: 0.238091, acc: 89.06%, op_acc: 60.16%] [G loss: 1.421660]\n",
      "epoch:49 step:38329[D loss: 0.332236, acc: 75.78%, op_acc: 47.66%] [G loss: 1.147804]\n",
      "epoch:49 step:38330[D loss: 0.285785, acc: 84.38%, op_acc: 56.25%] [G loss: 1.009676]\n",
      "epoch:49 step:38331[D loss: 0.406430, acc: 61.72%, op_acc: 42.97%] [G loss: 1.022146]\n",
      "epoch:49 step:38332[D loss: 0.399757, acc: 67.97%, op_acc: 46.88%] [G loss: 1.645679]\n",
      "epoch:49 step:38333[D loss: 0.320277, acc: 74.22%, op_acc: 47.66%] [G loss: 1.389349]\n",
      "epoch:49 step:38334[D loss: 0.319388, acc: 80.47%, op_acc: 50.78%] [G loss: 1.238398]\n",
      "epoch:49 step:38335[D loss: 0.348967, acc: 74.22%, op_acc: 59.38%] [G loss: 1.392835]\n",
      "epoch:49 step:38336[D loss: 0.270329, acc: 85.16%, op_acc: 54.69%] [G loss: 1.741459]\n",
      "epoch:49 step:38337[D loss: 0.369626, acc: 76.56%, op_acc: 44.53%] [G loss: 1.463696]\n",
      "epoch:49 step:38338[D loss: 0.321200, acc: 75.78%, op_acc: 53.12%] [G loss: 1.515008]\n",
      "epoch:49 step:38339[D loss: 0.408789, acc: 68.75%, op_acc: 46.09%] [G loss: 1.011880]\n",
      "epoch:49 step:38340[D loss: 0.325871, acc: 75.78%, op_acc: 49.22%] [G loss: 1.162775]\n",
      "epoch:49 step:38341[D loss: 0.339713, acc: 72.66%, op_acc: 47.66%] [G loss: 1.268884]\n",
      "epoch:49 step:38342[D loss: 0.300772, acc: 78.91%, op_acc: 55.47%] [G loss: 1.069849]\n",
      "epoch:49 step:38343[D loss: 0.254364, acc: 83.59%, op_acc: 55.47%] [G loss: 1.460395]\n",
      "epoch:49 step:38344[D loss: 0.348042, acc: 70.31%, op_acc: 50.78%] [G loss: 0.869481]\n",
      "epoch:49 step:38345[D loss: 0.309646, acc: 78.12%, op_acc: 57.81%] [G loss: 1.478006]\n",
      "epoch:49 step:38346[D loss: 0.333217, acc: 73.44%, op_acc: 48.44%] [G loss: 1.049777]\n",
      "epoch:49 step:38347[D loss: 0.305650, acc: 83.59%, op_acc: 44.53%] [G loss: 1.383402]\n",
      "epoch:49 step:38348[D loss: 0.312615, acc: 80.47%, op_acc: 50.78%] [G loss: 1.259211]\n",
      "epoch:49 step:38349[D loss: 0.413131, acc: 64.84%, op_acc: 44.53%] [G loss: 1.609103]\n",
      "epoch:49 step:38350[D loss: 0.370076, acc: 73.44%, op_acc: 51.56%] [G loss: 1.756335]\n",
      "epoch:49 step:38351[D loss: 0.331730, acc: 78.91%, op_acc: 53.12%] [G loss: 1.561408]\n",
      "epoch:49 step:38352[D loss: 0.333794, acc: 76.56%, op_acc: 50.00%] [G loss: 1.799925]\n",
      "epoch:49 step:38353[D loss: 0.326441, acc: 76.56%, op_acc: 59.38%] [G loss: 1.955641]\n",
      "epoch:49 step:38354[D loss: 0.303525, acc: 86.72%, op_acc: 46.09%] [G loss: 1.537450]\n",
      "epoch:49 step:38355[D loss: 0.346369, acc: 73.44%, op_acc: 53.91%] [G loss: 1.445313]\n",
      "epoch:49 step:38356[D loss: 0.282562, acc: 83.59%, op_acc: 54.69%] [G loss: 1.583310]\n",
      "epoch:49 step:38357[D loss: 0.278978, acc: 90.62%, op_acc: 48.44%] [G loss: 1.756307]\n",
      "epoch:49 step:38358[D loss: 0.325174, acc: 78.91%, op_acc: 50.78%] [G loss: 1.586340]\n",
      "epoch:49 step:38359[D loss: 0.251091, acc: 87.50%, op_acc: 58.59%] [G loss: 1.135425]\n",
      "epoch:49 step:38360[D loss: 0.347004, acc: 73.44%, op_acc: 50.78%] [G loss: 1.583069]\n",
      "epoch:49 step:38361[D loss: 0.265017, acc: 84.38%, op_acc: 58.59%] [G loss: 1.494302]\n",
      "epoch:49 step:38362[D loss: 0.394713, acc: 70.31%, op_acc: 48.44%] [G loss: 1.698170]\n",
      "epoch:49 step:38363[D loss: 0.236858, acc: 89.84%, op_acc: 57.81%] [G loss: 2.091048]\n",
      "epoch:49 step:38364[D loss: 0.309839, acc: 76.56%, op_acc: 52.34%] [G loss: 1.861994]\n",
      "epoch:49 step:38365[D loss: 0.463531, acc: 53.12%, op_acc: 43.75%] [G loss: 2.071781]\n",
      "epoch:49 step:38366[D loss: 0.351505, acc: 71.09%, op_acc: 54.69%] [G loss: 1.680104]\n",
      "epoch:49 step:38367[D loss: 0.358942, acc: 72.66%, op_acc: 40.62%] [G loss: 1.019579]\n",
      "epoch:49 step:38368[D loss: 0.545634, acc: 40.62%, op_acc: 42.19%] [G loss: 1.737225]\n",
      "epoch:49 step:38369[D loss: 0.414739, acc: 64.84%, op_acc: 42.19%] [G loss: 1.763250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38370[D loss: 0.426768, acc: 67.97%, op_acc: 44.53%] [G loss: 1.905060]\n",
      "epoch:49 step:38371[D loss: 0.401281, acc: 64.06%, op_acc: 42.97%] [G loss: 1.235775]\n",
      "epoch:49 step:38372[D loss: 0.457311, acc: 54.69%, op_acc: 42.97%] [G loss: 1.324342]\n",
      "epoch:49 step:38373[D loss: 0.416374, acc: 63.28%, op_acc: 44.53%] [G loss: 1.494756]\n",
      "epoch:49 step:38374[D loss: 0.390122, acc: 70.31%, op_acc: 47.66%] [G loss: 1.329611]\n",
      "epoch:49 step:38375[D loss: 0.331823, acc: 78.12%, op_acc: 46.88%] [G loss: 1.572801]\n",
      "epoch:49 step:38376[D loss: 0.364530, acc: 75.78%, op_acc: 49.22%] [G loss: 1.445996]\n",
      "epoch:49 step:38377[D loss: 0.417055, acc: 64.06%, op_acc: 47.66%] [G loss: 1.295835]\n",
      "epoch:49 step:38378[D loss: 0.296612, acc: 81.25%, op_acc: 48.44%] [G loss: 1.182201]\n",
      "epoch:49 step:38379[D loss: 0.260201, acc: 85.94%, op_acc: 55.47%] [G loss: 1.328113]\n",
      "epoch:49 step:38380[D loss: 0.456988, acc: 58.59%, op_acc: 39.84%] [G loss: 1.275322]\n",
      "epoch:49 step:38381[D loss: 0.355020, acc: 67.19%, op_acc: 46.09%] [G loss: 1.312087]\n",
      "epoch:49 step:38382[D loss: 0.354142, acc: 70.31%, op_acc: 53.12%] [G loss: 1.446186]\n",
      "epoch:49 step:38383[D loss: 0.391320, acc: 69.53%, op_acc: 50.00%] [G loss: 1.366579]\n",
      "epoch:49 step:38384[D loss: 0.336767, acc: 71.09%, op_acc: 52.34%] [G loss: 1.443226]\n",
      "epoch:49 step:38385[D loss: 0.404635, acc: 67.19%, op_acc: 41.41%] [G loss: 1.422628]\n",
      "epoch:49 step:38386[D loss: 0.352686, acc: 70.31%, op_acc: 50.00%] [G loss: 1.855181]\n",
      "epoch:49 step:38387[D loss: 0.416055, acc: 68.75%, op_acc: 53.12%] [G loss: 1.108366]\n",
      "epoch:49 step:38388[D loss: 0.449507, acc: 55.47%, op_acc: 38.28%] [G loss: 1.348710]\n",
      "epoch:49 step:38389[D loss: 0.355681, acc: 71.09%, op_acc: 48.44%] [G loss: 1.405251]\n",
      "epoch:49 step:38390[D loss: 0.386236, acc: 71.09%, op_acc: 42.97%] [G loss: 1.318115]\n",
      "epoch:49 step:38391[D loss: 0.417447, acc: 65.62%, op_acc: 42.97%] [G loss: 1.327522]\n",
      "epoch:49 step:38392[D loss: 0.437550, acc: 62.50%, op_acc: 46.09%] [G loss: 1.597775]\n",
      "epoch:49 step:38393[D loss: 0.367052, acc: 72.66%, op_acc: 42.19%] [G loss: 1.033710]\n",
      "epoch:49 step:38394[D loss: 0.367904, acc: 71.88%, op_acc: 36.72%] [G loss: 1.168479]\n",
      "epoch:49 step:38395[D loss: 0.367807, acc: 72.66%, op_acc: 42.97%] [G loss: 1.641695]\n",
      "epoch:49 step:38396[D loss: 0.319370, acc: 78.12%, op_acc: 57.03%] [G loss: 1.246474]\n",
      "epoch:49 step:38397[D loss: 0.308507, acc: 81.25%, op_acc: 51.56%] [G loss: 1.528916]\n",
      "epoch:49 step:38398[D loss: 0.319493, acc: 78.91%, op_acc: 50.78%] [G loss: 1.492135]\n",
      "epoch:49 step:38399[D loss: 0.346557, acc: 70.31%, op_acc: 51.56%] [G loss: 1.620972]\n",
      "epoch:49 step:38400[D loss: 0.388977, acc: 66.41%, op_acc: 44.53%] [G loss: 1.202216]\n",
      "epoch:49 step:38401[D loss: 0.342864, acc: 71.09%, op_acc: 51.56%] [G loss: 1.356359]\n",
      "epoch:49 step:38402[D loss: 0.288605, acc: 85.16%, op_acc: 49.22%] [G loss: 1.375759]\n",
      "epoch:49 step:38403[D loss: 0.349790, acc: 78.91%, op_acc: 40.62%] [G loss: 0.926429]\n",
      "epoch:49 step:38404[D loss: 0.561045, acc: 46.88%, op_acc: 39.84%] [G loss: 1.336220]\n",
      "epoch:49 step:38405[D loss: 0.379637, acc: 67.97%, op_acc: 45.31%] [G loss: 1.580782]\n",
      "epoch:49 step:38406[D loss: 0.403151, acc: 61.72%, op_acc: 53.12%] [G loss: 1.629342]\n",
      "epoch:49 step:38407[D loss: 0.504164, acc: 51.56%, op_acc: 38.28%] [G loss: 1.451525]\n",
      "epoch:49 step:38408[D loss: 0.391666, acc: 65.62%, op_acc: 47.66%] [G loss: 1.439527]\n",
      "epoch:49 step:38409[D loss: 0.375365, acc: 72.66%, op_acc: 46.09%] [G loss: 1.353050]\n",
      "epoch:49 step:38410[D loss: 0.460572, acc: 57.03%, op_acc: 42.97%] [G loss: 1.611990]\n",
      "epoch:49 step:38411[D loss: 0.348338, acc: 69.53%, op_acc: 42.97%] [G loss: 1.660715]\n",
      "epoch:49 step:38412[D loss: 0.408779, acc: 64.06%, op_acc: 46.09%] [G loss: 1.599445]\n",
      "epoch:49 step:38413[D loss: 0.447365, acc: 55.47%, op_acc: 40.62%] [G loss: 1.417916]\n",
      "epoch:49 step:38414[D loss: 0.405419, acc: 69.53%, op_acc: 49.22%] [G loss: 1.198195]\n",
      "epoch:49 step:38415[D loss: 0.400049, acc: 67.19%, op_acc: 46.88%] [G loss: 1.130552]\n",
      "epoch:49 step:38416[D loss: 0.353728, acc: 72.66%, op_acc: 46.88%] [G loss: 1.404780]\n",
      "epoch:49 step:38417[D loss: 0.380506, acc: 68.75%, op_acc: 53.12%] [G loss: 1.345342]\n",
      "epoch:49 step:38418[D loss: 0.393553, acc: 68.75%, op_acc: 46.88%] [G loss: 1.326539]\n",
      "epoch:49 step:38419[D loss: 0.381236, acc: 63.28%, op_acc: 49.22%] [G loss: 1.161706]\n",
      "epoch:49 step:38420[D loss: 0.325361, acc: 69.53%, op_acc: 58.59%] [G loss: 1.203984]\n",
      "epoch:49 step:38421[D loss: 0.420206, acc: 56.25%, op_acc: 42.97%] [G loss: 1.341907]\n",
      "epoch:49 step:38422[D loss: 0.375999, acc: 70.31%, op_acc: 44.53%] [G loss: 0.992681]\n",
      "epoch:49 step:38423[D loss: 0.352242, acc: 74.22%, op_acc: 45.31%] [G loss: 1.425266]\n",
      "epoch:49 step:38424[D loss: 0.358952, acc: 75.00%, op_acc: 41.41%] [G loss: 1.412888]\n",
      "epoch:49 step:38425[D loss: 0.394496, acc: 63.28%, op_acc: 42.19%] [G loss: 1.592773]\n",
      "epoch:49 step:38426[D loss: 0.379507, acc: 67.97%, op_acc: 53.12%] [G loss: 1.623991]\n",
      "epoch:49 step:38427[D loss: 0.311179, acc: 78.12%, op_acc: 55.47%] [G loss: 1.621198]\n",
      "epoch:49 step:38428[D loss: 0.349136, acc: 77.34%, op_acc: 53.12%] [G loss: 1.506635]\n",
      "epoch:49 step:38429[D loss: 0.364484, acc: 71.88%, op_acc: 42.97%] [G loss: 1.398695]\n",
      "epoch:49 step:38430[D loss: 0.334979, acc: 78.91%, op_acc: 53.91%] [G loss: 1.387051]\n",
      "epoch:49 step:38431[D loss: 0.344410, acc: 73.44%, op_acc: 51.56%] [G loss: 1.204839]\n",
      "epoch:49 step:38432[D loss: 0.399246, acc: 71.09%, op_acc: 46.09%] [G loss: 1.595972]\n",
      "epoch:49 step:38433[D loss: 0.431445, acc: 63.28%, op_acc: 39.84%] [G loss: 1.613513]\n",
      "epoch:49 step:38434[D loss: 0.363833, acc: 70.31%, op_acc: 57.03%] [G loss: 1.396004]\n",
      "epoch:49 step:38435[D loss: 0.457951, acc: 57.03%, op_acc: 42.97%] [G loss: 1.255679]\n",
      "epoch:49 step:38436[D loss: 0.417926, acc: 60.94%, op_acc: 40.62%] [G loss: 1.343470]\n",
      "epoch:49 step:38437[D loss: 0.340437, acc: 75.78%, op_acc: 51.56%] [G loss: 1.496826]\n",
      "epoch:49 step:38438[D loss: 0.349343, acc: 75.78%, op_acc: 50.78%] [G loss: 1.209824]\n",
      "epoch:49 step:38439[D loss: 0.382025, acc: 67.97%, op_acc: 42.19%] [G loss: 1.175242]\n",
      "epoch:49 step:38440[D loss: 0.393378, acc: 68.75%, op_acc: 35.16%] [G loss: 1.237170]\n",
      "epoch:49 step:38441[D loss: 0.379645, acc: 66.41%, op_acc: 46.09%] [G loss: 0.892676]\n",
      "epoch:49 step:38442[D loss: 0.444410, acc: 64.06%, op_acc: 45.31%] [G loss: 1.039364]\n",
      "epoch:49 step:38443[D loss: 0.419270, acc: 64.84%, op_acc: 43.75%] [G loss: 1.082846]\n",
      "epoch:49 step:38444[D loss: 0.472243, acc: 55.47%, op_acc: 37.50%] [G loss: 1.699155]\n",
      "epoch:49 step:38445[D loss: 0.337329, acc: 74.22%, op_acc: 44.53%] [G loss: 1.650259]\n",
      "epoch:49 step:38446[D loss: 0.348249, acc: 69.53%, op_acc: 57.81%] [G loss: 1.518890]\n",
      "epoch:49 step:38447[D loss: 0.497824, acc: 52.34%, op_acc: 37.50%] [G loss: 1.151351]\n",
      "epoch:49 step:38448[D loss: 0.374103, acc: 71.09%, op_acc: 54.69%] [G loss: 1.553577]\n",
      "epoch:49 step:38449[D loss: 0.426944, acc: 65.62%, op_acc: 37.50%] [G loss: 1.239258]\n",
      "epoch:49 step:38450[D loss: 0.341640, acc: 74.22%, op_acc: 49.22%] [G loss: 1.601008]\n",
      "epoch:49 step:38451[D loss: 0.412202, acc: 64.06%, op_acc: 42.19%] [G loss: 1.312775]\n",
      "epoch:49 step:38452[D loss: 0.436055, acc: 54.69%, op_acc: 50.78%] [G loss: 1.543539]\n",
      "epoch:49 step:38453[D loss: 0.374288, acc: 69.53%, op_acc: 48.44%] [G loss: 1.545982]\n",
      "epoch:49 step:38454[D loss: 0.378264, acc: 73.44%, op_acc: 41.41%] [G loss: 1.336715]\n",
      "epoch:49 step:38455[D loss: 0.393700, acc: 64.06%, op_acc: 50.78%] [G loss: 1.550277]\n",
      "epoch:49 step:38456[D loss: 0.409995, acc: 59.38%, op_acc: 49.22%] [G loss: 1.406129]\n",
      "epoch:49 step:38457[D loss: 0.449406, acc: 59.38%, op_acc: 40.62%] [G loss: 1.414716]\n",
      "epoch:49 step:38458[D loss: 0.321281, acc: 78.12%, op_acc: 47.66%] [G loss: 1.260844]\n",
      "epoch:49 step:38459[D loss: 0.493051, acc: 52.34%, op_acc: 40.62%] [G loss: 1.392115]\n",
      "epoch:49 step:38460[D loss: 0.458065, acc: 53.12%, op_acc: 43.75%] [G loss: 1.297772]\n",
      "epoch:49 step:38461[D loss: 0.390409, acc: 66.41%, op_acc: 41.41%] [G loss: 1.112074]\n",
      "epoch:49 step:38462[D loss: 0.382381, acc: 68.75%, op_acc: 44.53%] [G loss: 1.258371]\n",
      "epoch:49 step:38463[D loss: 0.387979, acc: 67.97%, op_acc: 45.31%] [G loss: 0.967891]\n",
      "epoch:49 step:38464[D loss: 0.433376, acc: 58.59%, op_acc: 41.41%] [G loss: 1.229907]\n",
      "epoch:49 step:38465[D loss: 0.345381, acc: 73.44%, op_acc: 38.28%] [G loss: 1.301250]\n",
      "epoch:49 step:38466[D loss: 0.466272, acc: 57.03%, op_acc: 44.53%] [G loss: 1.456564]\n",
      "epoch:49 step:38467[D loss: 0.384993, acc: 67.19%, op_acc: 42.97%] [G loss: 1.334510]\n",
      "epoch:49 step:38468[D loss: 0.358190, acc: 71.09%, op_acc: 49.22%] [G loss: 1.382441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38469[D loss: 0.388613, acc: 64.06%, op_acc: 44.53%] [G loss: 1.151355]\n",
      "epoch:49 step:38470[D loss: 0.386547, acc: 68.75%, op_acc: 41.41%] [G loss: 1.536239]\n",
      "epoch:49 step:38471[D loss: 0.424005, acc: 64.06%, op_acc: 48.44%] [G loss: 1.373342]\n",
      "epoch:49 step:38472[D loss: 0.391412, acc: 66.41%, op_acc: 39.84%] [G loss: 1.274648]\n",
      "epoch:49 step:38473[D loss: 0.370458, acc: 65.62%, op_acc: 42.19%] [G loss: 1.307703]\n",
      "epoch:49 step:38474[D loss: 0.352039, acc: 76.56%, op_acc: 42.97%] [G loss: 1.289586]\n",
      "epoch:49 step:38475[D loss: 0.367408, acc: 70.31%, op_acc: 42.19%] [G loss: 1.332715]\n",
      "epoch:49 step:38476[D loss: 0.364701, acc: 71.09%, op_acc: 44.53%] [G loss: 1.381957]\n",
      "epoch:49 step:38477[D loss: 0.344788, acc: 75.78%, op_acc: 50.00%] [G loss: 1.172135]\n",
      "epoch:49 step:38478[D loss: 0.401837, acc: 61.72%, op_acc: 42.97%] [G loss: 1.169328]\n",
      "epoch:49 step:38479[D loss: 0.460762, acc: 61.72%, op_acc: 36.72%] [G loss: 1.413834]\n",
      "epoch:49 step:38480[D loss: 0.419430, acc: 63.28%, op_acc: 50.00%] [G loss: 1.442263]\n",
      "epoch:49 step:38481[D loss: 0.379106, acc: 68.75%, op_acc: 46.88%] [G loss: 1.314010]\n",
      "epoch:49 step:38482[D loss: 0.345770, acc: 71.88%, op_acc: 47.66%] [G loss: 1.233351]\n",
      "epoch:49 step:38483[D loss: 0.393305, acc: 69.53%, op_acc: 47.66%] [G loss: 1.252004]\n",
      "epoch:49 step:38484[D loss: 0.364695, acc: 71.09%, op_acc: 48.44%] [G loss: 1.160777]\n",
      "epoch:49 step:38485[D loss: 0.381347, acc: 71.88%, op_acc: 42.19%] [G loss: 1.445415]\n",
      "epoch:49 step:38486[D loss: 0.398824, acc: 72.66%, op_acc: 45.31%] [G loss: 1.271818]\n",
      "epoch:49 step:38487[D loss: 0.379000, acc: 70.31%, op_acc: 47.66%] [G loss: 1.396867]\n",
      "epoch:49 step:38488[D loss: 0.400116, acc: 63.28%, op_acc: 42.19%] [G loss: 1.217004]\n",
      "epoch:49 step:38489[D loss: 0.444310, acc: 56.25%, op_acc: 39.84%] [G loss: 1.212046]\n",
      "epoch:49 step:38490[D loss: 0.361464, acc: 73.44%, op_acc: 43.75%] [G loss: 1.222277]\n",
      "epoch:49 step:38491[D loss: 0.397814, acc: 61.72%, op_acc: 40.62%] [G loss: 1.200770]\n",
      "epoch:49 step:38492[D loss: 0.468022, acc: 57.03%, op_acc: 42.97%] [G loss: 1.425209]\n",
      "epoch:49 step:38493[D loss: 0.377060, acc: 67.19%, op_acc: 45.31%] [G loss: 1.164052]\n",
      "epoch:49 step:38494[D loss: 0.412275, acc: 61.72%, op_acc: 42.19%] [G loss: 1.164693]\n",
      "epoch:49 step:38495[D loss: 0.373788, acc: 66.41%, op_acc: 53.12%] [G loss: 1.018652]\n",
      "epoch:49 step:38496[D loss: 0.356548, acc: 68.75%, op_acc: 49.22%] [G loss: 1.068103]\n",
      "epoch:49 step:38497[D loss: 0.385939, acc: 66.41%, op_acc: 53.91%] [G loss: 1.289629]\n",
      "epoch:49 step:38498[D loss: 0.451206, acc: 58.59%, op_acc: 44.53%] [G loss: 1.110326]\n",
      "epoch:49 step:38499[D loss: 0.382749, acc: 74.22%, op_acc: 45.31%] [G loss: 1.323053]\n",
      "epoch:49 step:38500[D loss: 0.344854, acc: 73.44%, op_acc: 42.97%] [G loss: 1.269117]\n",
      "epoch:49 step:38501[D loss: 0.368940, acc: 75.00%, op_acc: 46.88%] [G loss: 1.350985]\n",
      "epoch:49 step:38502[D loss: 0.370823, acc: 73.44%, op_acc: 43.75%] [G loss: 1.424256]\n",
      "epoch:49 step:38503[D loss: 0.414330, acc: 67.19%, op_acc: 42.97%] [G loss: 1.584155]\n",
      "epoch:49 step:38504[D loss: 0.357116, acc: 68.75%, op_acc: 54.69%] [G loss: 1.302680]\n",
      "epoch:49 step:38505[D loss: 0.338681, acc: 75.00%, op_acc: 46.09%] [G loss: 1.153206]\n",
      "epoch:49 step:38506[D loss: 0.344447, acc: 71.09%, op_acc: 49.22%] [G loss: 1.264814]\n",
      "epoch:49 step:38507[D loss: 0.404974, acc: 57.81%, op_acc: 47.66%] [G loss: 1.215922]\n",
      "epoch:49 step:38508[D loss: 0.347654, acc: 73.44%, op_acc: 51.56%] [G loss: 1.396206]\n",
      "epoch:49 step:38509[D loss: 0.391519, acc: 64.84%, op_acc: 50.00%] [G loss: 1.235086]\n",
      "epoch:49 step:38510[D loss: 0.417054, acc: 61.72%, op_acc: 44.53%] [G loss: 1.166394]\n",
      "epoch:49 step:38511[D loss: 0.352173, acc: 68.75%, op_acc: 43.75%] [G loss: 1.053137]\n",
      "epoch:49 step:38512[D loss: 0.456113, acc: 62.50%, op_acc: 42.19%] [G loss: 1.033482]\n",
      "epoch:49 step:38513[D loss: 0.411470, acc: 64.84%, op_acc: 46.09%] [G loss: 1.180977]\n",
      "epoch:49 step:38514[D loss: 0.385233, acc: 68.75%, op_acc: 43.75%] [G loss: 1.189040]\n",
      "epoch:49 step:38515[D loss: 0.448250, acc: 61.72%, op_acc: 36.72%] [G loss: 1.298906]\n",
      "epoch:49 step:38516[D loss: 0.422139, acc: 61.72%, op_acc: 41.41%] [G loss: 1.155185]\n",
      "epoch:49 step:38517[D loss: 0.543674, acc: 49.22%, op_acc: 32.81%] [G loss: 1.508134]\n",
      "epoch:49 step:38518[D loss: 0.376268, acc: 67.97%, op_acc: 46.09%] [G loss: 1.197834]\n",
      "epoch:49 step:38519[D loss: 0.436092, acc: 61.72%, op_acc: 42.97%] [G loss: 1.095738]\n",
      "epoch:49 step:38520[D loss: 0.362332, acc: 71.09%, op_acc: 51.56%] [G loss: 1.047905]\n",
      "epoch:49 step:38521[D loss: 0.405540, acc: 63.28%, op_acc: 47.66%] [G loss: 1.268101]\n",
      "epoch:49 step:38522[D loss: 0.368478, acc: 67.19%, op_acc: 46.09%] [G loss: 1.066448]\n",
      "epoch:49 step:38523[D loss: 0.396752, acc: 68.75%, op_acc: 39.84%] [G loss: 1.382278]\n",
      "epoch:49 step:38524[D loss: 0.375959, acc: 71.09%, op_acc: 45.31%] [G loss: 1.292603]\n",
      "epoch:49 step:38525[D loss: 0.469454, acc: 53.91%, op_acc: 42.97%] [G loss: 1.178567]\n",
      "epoch:49 step:38526[D loss: 0.430233, acc: 64.84%, op_acc: 44.53%] [G loss: 1.259372]\n",
      "epoch:49 step:38527[D loss: 0.396534, acc: 67.19%, op_acc: 43.75%] [G loss: 1.366936]\n",
      "epoch:49 step:38528[D loss: 0.400914, acc: 72.66%, op_acc: 42.19%] [G loss: 1.228345]\n",
      "epoch:49 step:38529[D loss: 0.394556, acc: 71.09%, op_acc: 50.78%] [G loss: 1.204302]\n",
      "epoch:49 step:38530[D loss: 0.413115, acc: 64.06%, op_acc: 41.41%] [G loss: 0.965242]\n",
      "epoch:49 step:38531[D loss: 0.351582, acc: 74.22%, op_acc: 46.09%] [G loss: 1.033149]\n",
      "epoch:49 step:38532[D loss: 0.336060, acc: 75.78%, op_acc: 50.78%] [G loss: 1.157212]\n",
      "epoch:49 step:38533[D loss: 0.329874, acc: 79.69%, op_acc: 49.22%] [G loss: 1.532673]\n",
      "epoch:49 step:38534[D loss: 0.350712, acc: 69.53%, op_acc: 51.56%] [G loss: 1.383293]\n",
      "epoch:49 step:38535[D loss: 0.392982, acc: 60.16%, op_acc: 45.31%] [G loss: 1.469285]\n",
      "epoch:49 step:38536[D loss: 0.507406, acc: 51.56%, op_acc: 41.41%] [G loss: 1.044989]\n",
      "epoch:49 step:38537[D loss: 0.354611, acc: 75.78%, op_acc: 52.34%] [G loss: 1.149385]\n",
      "epoch:49 step:38538[D loss: 0.420961, acc: 60.94%, op_acc: 44.53%] [G loss: 1.156271]\n",
      "epoch:49 step:38539[D loss: 0.390268, acc: 61.72%, op_acc: 43.75%] [G loss: 1.219527]\n",
      "epoch:49 step:38540[D loss: 0.430578, acc: 67.19%, op_acc: 40.62%] [G loss: 1.213982]\n",
      "epoch:49 step:38541[D loss: 0.384448, acc: 70.31%, op_acc: 42.19%] [G loss: 1.123243]\n",
      "epoch:49 step:38542[D loss: 0.414294, acc: 66.41%, op_acc: 45.31%] [G loss: 1.296091]\n",
      "epoch:49 step:38543[D loss: 0.403811, acc: 64.84%, op_acc: 41.41%] [G loss: 1.227250]\n",
      "epoch:49 step:38544[D loss: 0.506149, acc: 50.00%, op_acc: 35.94%] [G loss: 0.990276]\n",
      "epoch:49 step:38545[D loss: 0.425753, acc: 67.19%, op_acc: 40.62%] [G loss: 1.276568]\n",
      "epoch:49 step:38546[D loss: 0.323431, acc: 78.12%, op_acc: 51.56%] [G loss: 1.382578]\n",
      "epoch:49 step:38547[D loss: 0.375835, acc: 71.88%, op_acc: 39.84%] [G loss: 1.240847]\n",
      "epoch:49 step:38548[D loss: 0.365844, acc: 70.31%, op_acc: 42.97%] [G loss: 1.184122]\n",
      "epoch:49 step:38549[D loss: 0.393810, acc: 67.97%, op_acc: 48.44%] [G loss: 1.378457]\n",
      "epoch:49 step:38550[D loss: 0.396151, acc: 67.97%, op_acc: 47.66%] [G loss: 1.371298]\n",
      "epoch:49 step:38551[D loss: 0.448572, acc: 60.94%, op_acc: 41.41%] [G loss: 1.320912]\n",
      "epoch:49 step:38552[D loss: 0.353127, acc: 70.31%, op_acc: 51.56%] [G loss: 1.130928]\n",
      "epoch:49 step:38553[D loss: 0.466192, acc: 59.38%, op_acc: 43.75%] [G loss: 0.961063]\n",
      "epoch:49 step:38554[D loss: 0.356024, acc: 69.53%, op_acc: 45.31%] [G loss: 1.436196]\n",
      "epoch:49 step:38555[D loss: 0.418572, acc: 65.62%, op_acc: 42.19%] [G loss: 1.351816]\n",
      "epoch:49 step:38556[D loss: 0.440813, acc: 58.59%, op_acc: 45.31%] [G loss: 1.386439]\n",
      "epoch:49 step:38557[D loss: 0.327653, acc: 70.31%, op_acc: 53.12%] [G loss: 1.337077]\n",
      "epoch:49 step:38558[D loss: 0.378302, acc: 64.06%, op_acc: 46.88%] [G loss: 1.482406]\n",
      "epoch:49 step:38559[D loss: 0.406239, acc: 64.06%, op_acc: 49.22%] [G loss: 1.185253]\n",
      "epoch:49 step:38560[D loss: 0.372311, acc: 73.44%, op_acc: 42.97%] [G loss: 1.142576]\n",
      "epoch:49 step:38561[D loss: 0.496044, acc: 56.25%, op_acc: 39.06%] [G loss: 0.974238]\n",
      "epoch:49 step:38562[D loss: 0.403762, acc: 67.97%, op_acc: 46.88%] [G loss: 1.269050]\n",
      "epoch:49 step:38563[D loss: 0.341580, acc: 75.00%, op_acc: 44.53%] [G loss: 1.244781]\n",
      "epoch:49 step:38564[D loss: 0.385515, acc: 64.84%, op_acc: 49.22%] [G loss: 1.312475]\n",
      "epoch:49 step:38565[D loss: 0.379630, acc: 63.28%, op_acc: 47.66%] [G loss: 1.313608]\n",
      "epoch:49 step:38566[D loss: 0.367236, acc: 71.09%, op_acc: 43.75%] [G loss: 1.220580]\n",
      "epoch:49 step:38567[D loss: 0.386958, acc: 64.84%, op_acc: 46.09%] [G loss: 1.336332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38568[D loss: 0.378658, acc: 69.53%, op_acc: 46.88%] [G loss: 1.114824]\n",
      "epoch:49 step:38569[D loss: 0.448479, acc: 59.38%, op_acc: 45.31%] [G loss: 0.939643]\n",
      "epoch:49 step:38570[D loss: 0.420137, acc: 60.94%, op_acc: 41.41%] [G loss: 1.509796]\n",
      "epoch:49 step:38571[D loss: 0.348270, acc: 73.44%, op_acc: 41.41%] [G loss: 1.406307]\n",
      "epoch:49 step:38572[D loss: 0.327750, acc: 73.44%, op_acc: 46.88%] [G loss: 1.438907]\n",
      "epoch:49 step:38573[D loss: 0.305236, acc: 78.91%, op_acc: 54.69%] [G loss: 1.517604]\n",
      "epoch:49 step:38574[D loss: 0.460356, acc: 47.66%, op_acc: 47.66%] [G loss: 1.181477]\n",
      "epoch:49 step:38575[D loss: 0.386841, acc: 64.84%, op_acc: 44.53%] [G loss: 1.510636]\n",
      "epoch:49 step:38576[D loss: 0.382413, acc: 66.41%, op_acc: 48.44%] [G loss: 1.522270]\n",
      "epoch:49 step:38577[D loss: 0.461608, acc: 53.91%, op_acc: 39.84%] [G loss: 1.076920]\n",
      "epoch:49 step:38578[D loss: 0.501274, acc: 53.91%, op_acc: 37.50%] [G loss: 0.923514]\n",
      "epoch:49 step:38579[D loss: 0.478150, acc: 51.56%, op_acc: 44.53%] [G loss: 0.946802]\n",
      "epoch:49 step:38580[D loss: 0.428191, acc: 60.94%, op_acc: 47.66%] [G loss: 1.037534]\n",
      "epoch:49 step:38581[D loss: 0.422302, acc: 62.50%, op_acc: 43.75%] [G loss: 1.048039]\n",
      "epoch:49 step:38582[D loss: 0.357329, acc: 72.66%, op_acc: 50.78%] [G loss: 1.335880]\n",
      "epoch:49 step:38583[D loss: 0.342437, acc: 71.09%, op_acc: 46.88%] [G loss: 1.183313]\n",
      "epoch:49 step:38584[D loss: 0.401701, acc: 66.41%, op_acc: 45.31%] [G loss: 1.168280]\n",
      "epoch:49 step:38585[D loss: 0.429459, acc: 55.47%, op_acc: 41.41%] [G loss: 1.036580]\n",
      "epoch:49 step:38586[D loss: 0.447546, acc: 60.16%, op_acc: 39.06%] [G loss: 1.175378]\n",
      "epoch:49 step:38587[D loss: 0.432896, acc: 58.59%, op_acc: 39.06%] [G loss: 1.293896]\n",
      "epoch:49 step:38588[D loss: 0.463487, acc: 57.03%, op_acc: 46.88%] [G loss: 1.158251]\n",
      "epoch:49 step:38589[D loss: 0.440032, acc: 60.16%, op_acc: 39.84%] [G loss: 1.202221]\n",
      "epoch:49 step:38590[D loss: 0.385677, acc: 69.53%, op_acc: 46.88%] [G loss: 1.401586]\n",
      "epoch:49 step:38591[D loss: 0.402580, acc: 67.97%, op_acc: 44.53%] [G loss: 1.360888]\n",
      "epoch:49 step:38592[D loss: 0.365286, acc: 73.44%, op_acc: 48.44%] [G loss: 1.299295]\n",
      "epoch:49 step:38593[D loss: 0.386428, acc: 71.88%, op_acc: 36.72%] [G loss: 1.229936]\n",
      "epoch:49 step:38594[D loss: 0.363932, acc: 71.88%, op_acc: 44.53%] [G loss: 1.354282]\n",
      "epoch:49 step:38595[D loss: 0.361366, acc: 67.97%, op_acc: 43.75%] [G loss: 0.987970]\n",
      "epoch:49 step:38596[D loss: 0.407388, acc: 66.41%, op_acc: 51.56%] [G loss: 1.152847]\n",
      "epoch:49 step:38597[D loss: 0.383354, acc: 64.84%, op_acc: 45.31%] [G loss: 1.038098]\n",
      "epoch:49 step:38598[D loss: 0.448897, acc: 57.03%, op_acc: 42.19%] [G loss: 0.861070]\n",
      "epoch:49 step:38599[D loss: 0.375299, acc: 72.66%, op_acc: 46.88%] [G loss: 1.347858]\n",
      "epoch:49 step:38600[D loss: 0.410650, acc: 63.28%, op_acc: 46.88%] [G loss: 1.183455]\n",
      "epoch:49 step:38601[D loss: 0.381953, acc: 68.75%, op_acc: 50.78%] [G loss: 1.367782]\n",
      "epoch:49 step:38602[D loss: 0.341047, acc: 78.12%, op_acc: 46.88%] [G loss: 1.595448]\n",
      "epoch:49 step:38603[D loss: 0.414099, acc: 66.41%, op_acc: 45.31%] [G loss: 1.199402]\n",
      "epoch:49 step:38604[D loss: 0.387272, acc: 72.66%, op_acc: 41.41%] [G loss: 1.238590]\n",
      "epoch:49 step:38605[D loss: 0.460322, acc: 60.16%, op_acc: 38.28%] [G loss: 1.233299]\n",
      "epoch:49 step:38606[D loss: 0.355496, acc: 74.22%, op_acc: 45.31%] [G loss: 1.313576]\n",
      "epoch:49 step:38607[D loss: 0.389162, acc: 59.38%, op_acc: 44.53%] [G loss: 1.538087]\n",
      "epoch:49 step:38608[D loss: 0.363793, acc: 72.66%, op_acc: 45.31%] [G loss: 1.437986]\n",
      "epoch:49 step:38609[D loss: 0.414770, acc: 60.16%, op_acc: 43.75%] [G loss: 1.380967]\n",
      "epoch:49 step:38610[D loss: 0.408545, acc: 67.19%, op_acc: 46.88%] [G loss: 1.073671]\n",
      "epoch:49 step:38611[D loss: 0.346423, acc: 76.56%, op_acc: 45.31%] [G loss: 1.432621]\n",
      "epoch:49 step:38612[D loss: 0.404966, acc: 65.62%, op_acc: 46.09%] [G loss: 1.209716]\n",
      "epoch:49 step:38613[D loss: 0.390248, acc: 68.75%, op_acc: 46.09%] [G loss: 1.210594]\n",
      "epoch:49 step:38614[D loss: 0.361295, acc: 67.19%, op_acc: 52.34%] [G loss: 1.296031]\n",
      "epoch:49 step:38615[D loss: 0.410250, acc: 61.72%, op_acc: 46.09%] [G loss: 1.206928]\n",
      "epoch:49 step:38616[D loss: 0.414374, acc: 59.38%, op_acc: 45.31%] [G loss: 1.473897]\n",
      "epoch:49 step:38617[D loss: 0.306218, acc: 77.34%, op_acc: 52.34%] [G loss: 1.367292]\n",
      "epoch:49 step:38618[D loss: 0.281984, acc: 84.38%, op_acc: 54.69%] [G loss: 1.098049]\n",
      "epoch:49 step:38619[D loss: 0.451180, acc: 58.59%, op_acc: 38.28%] [G loss: 1.142410]\n",
      "epoch:49 step:38620[D loss: 0.434148, acc: 55.47%, op_acc: 46.09%] [G loss: 1.144242]\n",
      "epoch:49 step:38621[D loss: 0.364658, acc: 73.44%, op_acc: 47.66%] [G loss: 1.450889]\n",
      "epoch:49 step:38622[D loss: 0.399632, acc: 65.62%, op_acc: 45.31%] [G loss: 1.197263]\n",
      "epoch:49 step:38623[D loss: 0.380480, acc: 67.97%, op_acc: 37.50%] [G loss: 1.177621]\n",
      "epoch:49 step:38624[D loss: 0.342210, acc: 73.44%, op_acc: 50.78%] [G loss: 1.213494]\n",
      "epoch:49 step:38625[D loss: 0.414413, acc: 60.16%, op_acc: 46.09%] [G loss: 1.233167]\n",
      "epoch:49 step:38626[D loss: 0.376171, acc: 73.44%, op_acc: 39.84%] [G loss: 0.990318]\n",
      "epoch:49 step:38627[D loss: 0.496365, acc: 50.00%, op_acc: 39.06%] [G loss: 1.229800]\n",
      "epoch:49 step:38628[D loss: 0.359614, acc: 74.22%, op_acc: 45.31%] [G loss: 1.360263]\n",
      "epoch:49 step:38629[D loss: 0.407740, acc: 67.19%, op_acc: 49.22%] [G loss: 1.287673]\n",
      "epoch:49 step:38630[D loss: 0.384180, acc: 70.31%, op_acc: 47.66%] [G loss: 1.302328]\n",
      "epoch:49 step:38631[D loss: 0.366320, acc: 68.75%, op_acc: 53.12%] [G loss: 1.235710]\n",
      "epoch:49 step:38632[D loss: 0.427853, acc: 69.53%, op_acc: 40.62%] [G loss: 1.208948]\n",
      "epoch:49 step:38633[D loss: 0.309230, acc: 82.03%, op_acc: 52.34%] [G loss: 1.303140]\n",
      "epoch:49 step:38634[D loss: 0.337126, acc: 71.88%, op_acc: 53.91%] [G loss: 1.342321]\n",
      "epoch:49 step:38635[D loss: 0.403389, acc: 66.41%, op_acc: 50.00%] [G loss: 1.221839]\n",
      "epoch:49 step:38636[D loss: 0.486420, acc: 50.78%, op_acc: 34.38%] [G loss: 1.015728]\n",
      "epoch:49 step:38637[D loss: 0.362948, acc: 67.97%, op_acc: 47.66%] [G loss: 1.306731]\n",
      "epoch:49 step:38638[D loss: 0.347726, acc: 75.78%, op_acc: 50.78%] [G loss: 1.328318]\n",
      "epoch:49 step:38639[D loss: 0.370845, acc: 71.88%, op_acc: 38.28%] [G loss: 1.270736]\n",
      "epoch:49 step:38640[D loss: 0.338059, acc: 73.44%, op_acc: 55.47%] [G loss: 1.584384]\n",
      "epoch:49 step:38641[D loss: 0.418492, acc: 62.50%, op_acc: 50.78%] [G loss: 1.500521]\n",
      "epoch:49 step:38642[D loss: 0.423322, acc: 57.03%, op_acc: 42.97%] [G loss: 1.426702]\n",
      "epoch:49 step:38643[D loss: 0.361456, acc: 69.53%, op_acc: 50.78%] [G loss: 0.678047]\n",
      "epoch:49 step:38644[D loss: 0.486122, acc: 49.22%, op_acc: 38.28%] [G loss: 1.387468]\n",
      "epoch:49 step:38645[D loss: 0.316260, acc: 72.66%, op_acc: 46.88%] [G loss: 1.551167]\n",
      "epoch:49 step:38646[D loss: 0.402440, acc: 59.38%, op_acc: 40.62%] [G loss: 1.423639]\n",
      "epoch:49 step:38647[D loss: 0.405656, acc: 66.41%, op_acc: 45.31%] [G loss: 1.259656]\n",
      "epoch:49 step:38648[D loss: 0.380288, acc: 68.75%, op_acc: 42.19%] [G loss: 1.244563]\n",
      "epoch:49 step:38649[D loss: 0.321079, acc: 78.12%, op_acc: 45.31%] [G loss: 1.135562]\n",
      "epoch:49 step:38650[D loss: 0.311054, acc: 80.47%, op_acc: 45.31%] [G loss: 1.405061]\n",
      "epoch:49 step:38651[D loss: 0.444261, acc: 58.59%, op_acc: 36.72%] [G loss: 1.310798]\n",
      "epoch:49 step:38652[D loss: 0.423723, acc: 61.72%, op_acc: 49.22%] [G loss: 1.384686]\n",
      "epoch:49 step:38653[D loss: 0.416954, acc: 67.19%, op_acc: 38.28%] [G loss: 1.222499]\n",
      "epoch:49 step:38654[D loss: 0.351989, acc: 71.09%, op_acc: 46.09%] [G loss: 1.362074]\n",
      "epoch:49 step:38655[D loss: 0.442343, acc: 60.16%, op_acc: 40.62%] [G loss: 1.221711]\n",
      "epoch:49 step:38656[D loss: 0.325030, acc: 72.66%, op_acc: 50.00%] [G loss: 1.111267]\n",
      "epoch:49 step:38657[D loss: 0.343172, acc: 77.34%, op_acc: 42.19%] [G loss: 1.359213]\n",
      "epoch:49 step:38658[D loss: 0.436289, acc: 55.47%, op_acc: 40.62%] [G loss: 1.372515]\n",
      "epoch:49 step:38659[D loss: 0.382418, acc: 65.62%, op_acc: 47.66%] [G loss: 1.258761]\n",
      "epoch:49 step:38660[D loss: 0.352328, acc: 70.31%, op_acc: 47.66%] [G loss: 1.216514]\n",
      "epoch:49 step:38661[D loss: 0.401600, acc: 64.84%, op_acc: 51.56%] [G loss: 1.285167]\n",
      "epoch:49 step:38662[D loss: 0.416300, acc: 63.28%, op_acc: 39.84%] [G loss: 1.168947]\n",
      "epoch:49 step:38663[D loss: 0.402535, acc: 66.41%, op_acc: 41.41%] [G loss: 1.319431]\n",
      "epoch:49 step:38664[D loss: 0.380407, acc: 74.22%, op_acc: 42.97%] [G loss: 1.164816]\n",
      "epoch:49 step:38665[D loss: 0.312960, acc: 73.44%, op_acc: 50.00%] [G loss: 1.174569]\n",
      "epoch:49 step:38666[D loss: 0.368321, acc: 67.19%, op_acc: 47.66%] [G loss: 1.160275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38667[D loss: 0.413992, acc: 68.75%, op_acc: 43.75%] [G loss: 1.149073]\n",
      "epoch:49 step:38668[D loss: 0.357965, acc: 69.53%, op_acc: 47.66%] [G loss: 1.216363]\n",
      "epoch:49 step:38669[D loss: 0.360466, acc: 70.31%, op_acc: 45.31%] [G loss: 1.213098]\n",
      "epoch:49 step:38670[D loss: 0.382455, acc: 70.31%, op_acc: 47.66%] [G loss: 1.376348]\n",
      "epoch:49 step:38671[D loss: 0.419323, acc: 66.41%, op_acc: 43.75%] [G loss: 1.533941]\n",
      "epoch:49 step:38672[D loss: 0.321438, acc: 71.88%, op_acc: 51.56%] [G loss: 1.284014]\n",
      "epoch:49 step:38673[D loss: 0.398852, acc: 67.19%, op_acc: 42.19%] [G loss: 1.227160]\n",
      "epoch:49 step:38674[D loss: 0.430054, acc: 58.59%, op_acc: 44.53%] [G loss: 1.138017]\n",
      "epoch:49 step:38675[D loss: 0.442110, acc: 61.72%, op_acc: 49.22%] [G loss: 1.207495]\n",
      "epoch:49 step:38676[D loss: 0.400619, acc: 66.41%, op_acc: 42.19%] [G loss: 1.243005]\n",
      "epoch:49 step:38677[D loss: 0.391319, acc: 65.62%, op_acc: 46.09%] [G loss: 1.148653]\n",
      "epoch:49 step:38678[D loss: 0.363645, acc: 66.41%, op_acc: 51.56%] [G loss: 1.147257]\n",
      "epoch:49 step:38679[D loss: 0.362042, acc: 68.75%, op_acc: 46.09%] [G loss: 1.077952]\n",
      "epoch:49 step:38680[D loss: 0.429172, acc: 64.84%, op_acc: 39.84%] [G loss: 1.038927]\n",
      "epoch:49 step:38681[D loss: 0.430128, acc: 57.81%, op_acc: 40.62%] [G loss: 0.970043]\n",
      "epoch:49 step:38682[D loss: 0.399168, acc: 67.97%, op_acc: 51.56%] [G loss: 1.071354]\n",
      "epoch:49 step:38683[D loss: 0.371255, acc: 68.75%, op_acc: 53.12%] [G loss: 1.339941]\n",
      "epoch:49 step:38684[D loss: 0.340442, acc: 74.22%, op_acc: 49.22%] [G loss: 1.308663]\n",
      "epoch:49 step:38685[D loss: 0.398747, acc: 61.72%, op_acc: 40.62%] [G loss: 1.411184]\n",
      "epoch:49 step:38686[D loss: 0.415990, acc: 71.88%, op_acc: 50.78%] [G loss: 1.009862]\n",
      "epoch:49 step:38687[D loss: 0.403535, acc: 72.66%, op_acc: 42.19%] [G loss: 1.252388]\n",
      "epoch:49 step:38688[D loss: 0.309026, acc: 78.91%, op_acc: 50.78%] [G loss: 1.258749]\n",
      "epoch:49 step:38689[D loss: 0.448646, acc: 56.25%, op_acc: 50.00%] [G loss: 1.513360]\n",
      "epoch:49 step:38690[D loss: 0.415890, acc: 66.41%, op_acc: 49.22%] [G loss: 1.320732]\n",
      "epoch:49 step:38691[D loss: 0.355145, acc: 75.78%, op_acc: 48.44%] [G loss: 1.215054]\n",
      "epoch:49 step:38692[D loss: 0.412935, acc: 61.72%, op_acc: 42.19%] [G loss: 1.326136]\n",
      "epoch:49 step:38693[D loss: 0.398633, acc: 65.62%, op_acc: 41.41%] [G loss: 1.144376]\n",
      "epoch:49 step:38694[D loss: 0.365168, acc: 67.97%, op_acc: 46.09%] [G loss: 1.192710]\n",
      "epoch:49 step:38695[D loss: 0.427276, acc: 64.06%, op_acc: 42.97%] [G loss: 1.154788]\n",
      "epoch:49 step:38696[D loss: 0.440957, acc: 59.38%, op_acc: 39.06%] [G loss: 1.161702]\n",
      "epoch:49 step:38697[D loss: 0.398107, acc: 59.38%, op_acc: 48.44%] [G loss: 1.045303]\n",
      "epoch:49 step:38698[D loss: 0.335112, acc: 76.56%, op_acc: 47.66%] [G loss: 1.064259]\n",
      "epoch:49 step:38699[D loss: 0.379942, acc: 68.75%, op_acc: 47.66%] [G loss: 1.069418]\n",
      "epoch:49 step:38700[D loss: 0.399833, acc: 60.94%, op_acc: 39.84%] [G loss: 1.134837]\n",
      "epoch:49 step:38701[D loss: 0.374948, acc: 64.84%, op_acc: 43.75%] [G loss: 0.955733]\n",
      "epoch:49 step:38702[D loss: 0.329134, acc: 76.56%, op_acc: 58.59%] [G loss: 1.185875]\n",
      "epoch:49 step:38703[D loss: 0.341188, acc: 72.66%, op_acc: 46.88%] [G loss: 1.277514]\n",
      "epoch:49 step:38704[D loss: 0.380314, acc: 64.84%, op_acc: 47.66%] [G loss: 0.881930]\n",
      "epoch:49 step:38705[D loss: 0.459317, acc: 52.34%, op_acc: 39.06%] [G loss: 1.104084]\n",
      "epoch:49 step:38706[D loss: 0.493919, acc: 56.25%, op_acc: 43.75%] [G loss: 0.960976]\n",
      "epoch:49 step:38707[D loss: 0.415667, acc: 62.50%, op_acc: 41.41%] [G loss: 0.907714]\n",
      "epoch:49 step:38708[D loss: 0.406431, acc: 57.81%, op_acc: 39.84%] [G loss: 1.074457]\n",
      "epoch:49 step:38709[D loss: 0.391481, acc: 69.53%, op_acc: 39.84%] [G loss: 1.063097]\n",
      "epoch:49 step:38710[D loss: 0.396828, acc: 63.28%, op_acc: 46.88%] [G loss: 1.269612]\n",
      "epoch:49 step:38711[D loss: 0.345794, acc: 72.66%, op_acc: 54.69%] [G loss: 1.042028]\n",
      "epoch:49 step:38712[D loss: 0.452607, acc: 60.94%, op_acc: 38.28%] [G loss: 1.094868]\n",
      "epoch:49 step:38713[D loss: 0.343003, acc: 75.00%, op_acc: 46.88%] [G loss: 1.264811]\n",
      "epoch:49 step:38714[D loss: 0.462304, acc: 52.34%, op_acc: 41.41%] [G loss: 0.951265]\n",
      "epoch:49 step:38715[D loss: 0.434786, acc: 61.72%, op_acc: 38.28%] [G loss: 1.385185]\n",
      "epoch:49 step:38716[D loss: 0.361368, acc: 70.31%, op_acc: 35.94%] [G loss: 1.299393]\n",
      "epoch:49 step:38717[D loss: 0.305061, acc: 82.03%, op_acc: 54.69%] [G loss: 1.346450]\n",
      "epoch:49 step:38718[D loss: 0.330476, acc: 78.12%, op_acc: 46.88%] [G loss: 1.096169]\n",
      "epoch:49 step:38719[D loss: 0.442240, acc: 60.94%, op_acc: 39.84%] [G loss: 1.246218]\n",
      "epoch:49 step:38720[D loss: 0.394428, acc: 68.75%, op_acc: 46.09%] [G loss: 1.139593]\n",
      "epoch:49 step:38721[D loss: 0.386336, acc: 65.62%, op_acc: 45.31%] [G loss: 1.360619]\n",
      "epoch:49 step:38722[D loss: 0.390852, acc: 62.50%, op_acc: 49.22%] [G loss: 1.327547]\n",
      "epoch:49 step:38723[D loss: 0.376689, acc: 70.31%, op_acc: 48.44%] [G loss: 1.178407]\n",
      "epoch:49 step:38724[D loss: 0.465754, acc: 56.25%, op_acc: 49.22%] [G loss: 1.430290]\n",
      "epoch:49 step:38725[D loss: 0.397850, acc: 69.53%, op_acc: 42.19%] [G loss: 1.075158]\n",
      "epoch:49 step:38726[D loss: 0.374479, acc: 68.75%, op_acc: 42.19%] [G loss: 1.072815]\n",
      "epoch:49 step:38727[D loss: 0.302144, acc: 77.34%, op_acc: 49.22%] [G loss: 1.084438]\n",
      "epoch:49 step:38728[D loss: 0.425310, acc: 53.12%, op_acc: 39.84%] [G loss: 1.058062]\n",
      "epoch:49 step:38729[D loss: 0.368720, acc: 67.97%, op_acc: 45.31%] [G loss: 1.412416]\n",
      "epoch:49 step:38730[D loss: 0.428467, acc: 60.94%, op_acc: 39.84%] [G loss: 1.162764]\n",
      "epoch:49 step:38731[D loss: 0.355910, acc: 75.78%, op_acc: 46.88%] [G loss: 1.221727]\n",
      "epoch:49 step:38732[D loss: 0.458906, acc: 50.78%, op_acc: 46.09%] [G loss: 1.264336]\n",
      "epoch:49 step:38733[D loss: 0.457271, acc: 56.25%, op_acc: 41.41%] [G loss: 1.025322]\n",
      "epoch:49 step:38734[D loss: 0.331837, acc: 75.00%, op_acc: 44.53%] [G loss: 1.195819]\n",
      "epoch:49 step:38735[D loss: 0.303875, acc: 82.81%, op_acc: 46.09%] [G loss: 1.201244]\n",
      "epoch:49 step:38736[D loss: 0.397445, acc: 63.28%, op_acc: 48.44%] [G loss: 1.271846]\n",
      "epoch:49 step:38737[D loss: 0.305466, acc: 80.47%, op_acc: 51.56%] [G loss: 1.412194]\n",
      "epoch:49 step:38738[D loss: 0.398622, acc: 64.06%, op_acc: 45.31%] [G loss: 1.364124]\n",
      "epoch:49 step:38739[D loss: 0.278304, acc: 82.03%, op_acc: 49.22%] [G loss: 1.210682]\n",
      "epoch:49 step:38740[D loss: 0.366022, acc: 71.09%, op_acc: 48.44%] [G loss: 1.002228]\n",
      "epoch:49 step:38741[D loss: 0.374958, acc: 67.97%, op_acc: 50.78%] [G loss: 1.195038]\n",
      "epoch:49 step:38742[D loss: 0.356064, acc: 66.41%, op_acc: 54.69%] [G loss: 1.145346]\n",
      "epoch:49 step:38743[D loss: 0.395949, acc: 65.62%, op_acc: 49.22%] [G loss: 1.167046]\n",
      "epoch:49 step:38744[D loss: 0.382430, acc: 64.06%, op_acc: 46.09%] [G loss: 1.185388]\n",
      "epoch:49 step:38745[D loss: 0.350216, acc: 75.78%, op_acc: 43.75%] [G loss: 1.350547]\n",
      "epoch:49 step:38746[D loss: 0.400510, acc: 68.75%, op_acc: 53.12%] [G loss: 1.133569]\n",
      "epoch:49 step:38747[D loss: 0.355259, acc: 76.56%, op_acc: 45.31%] [G loss: 1.084608]\n",
      "epoch:49 step:38748[D loss: 0.321606, acc: 74.22%, op_acc: 46.88%] [G loss: 1.115882]\n",
      "epoch:49 step:38749[D loss: 0.348856, acc: 74.22%, op_acc: 52.34%] [G loss: 1.240543]\n",
      "epoch:49 step:38750[D loss: 0.401267, acc: 64.84%, op_acc: 42.97%] [G loss: 1.288445]\n",
      "epoch:49 step:38751[D loss: 0.464954, acc: 50.78%, op_acc: 41.41%] [G loss: 1.190371]\n",
      "epoch:49 step:38752[D loss: 0.364317, acc: 75.78%, op_acc: 49.22%] [G loss: 1.195302]\n",
      "epoch:49 step:38753[D loss: 0.339512, acc: 71.09%, op_acc: 48.44%] [G loss: 1.431311]\n",
      "epoch:49 step:38754[D loss: 0.402677, acc: 62.50%, op_acc: 51.56%] [G loss: 1.386658]\n",
      "epoch:49 step:38755[D loss: 0.330144, acc: 74.22%, op_acc: 50.78%] [G loss: 1.300589]\n",
      "epoch:49 step:38756[D loss: 0.415526, acc: 60.94%, op_acc: 44.53%] [G loss: 1.239337]\n",
      "epoch:49 step:38757[D loss: 0.367023, acc: 69.53%, op_acc: 46.09%] [G loss: 1.204214]\n",
      "epoch:49 step:38758[D loss: 0.398992, acc: 68.75%, op_acc: 45.31%] [G loss: 1.094181]\n",
      "epoch:49 step:38759[D loss: 0.359147, acc: 70.31%, op_acc: 48.44%] [G loss: 1.211708]\n",
      "epoch:49 step:38760[D loss: 0.454387, acc: 59.38%, op_acc: 39.06%] [G loss: 0.997242]\n",
      "epoch:49 step:38761[D loss: 0.367292, acc: 74.22%, op_acc: 44.53%] [G loss: 0.950907]\n",
      "epoch:49 step:38762[D loss: 0.368484, acc: 68.75%, op_acc: 49.22%] [G loss: 1.106079]\n",
      "epoch:49 step:38763[D loss: 0.332490, acc: 75.78%, op_acc: 50.78%] [G loss: 1.250602]\n",
      "epoch:49 step:38764[D loss: 0.322669, acc: 78.12%, op_acc: 53.12%] [G loss: 1.177622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38765[D loss: 0.372280, acc: 75.00%, op_acc: 44.53%] [G loss: 1.052266]\n",
      "epoch:49 step:38766[D loss: 0.391396, acc: 66.41%, op_acc: 46.88%] [G loss: 1.070060]\n",
      "epoch:49 step:38767[D loss: 0.371487, acc: 71.09%, op_acc: 42.19%] [G loss: 0.992642]\n",
      "epoch:49 step:38768[D loss: 0.381573, acc: 69.53%, op_acc: 44.53%] [G loss: 1.237370]\n",
      "epoch:49 step:38769[D loss: 0.312902, acc: 77.34%, op_acc: 47.66%] [G loss: 1.048307]\n",
      "epoch:49 step:38770[D loss: 0.357865, acc: 76.56%, op_acc: 48.44%] [G loss: 1.456851]\n",
      "epoch:49 step:38771[D loss: 0.464525, acc: 55.47%, op_acc: 39.06%] [G loss: 1.560595]\n",
      "epoch:49 step:38772[D loss: 0.409283, acc: 62.50%, op_acc: 41.41%] [G loss: 1.366531]\n",
      "epoch:49 step:38773[D loss: 0.432362, acc: 58.59%, op_acc: 52.34%] [G loss: 1.318504]\n",
      "epoch:49 step:38774[D loss: 0.421900, acc: 60.94%, op_acc: 39.06%] [G loss: 1.231101]\n",
      "epoch:49 step:38775[D loss: 0.434114, acc: 55.47%, op_acc: 39.84%] [G loss: 1.232686]\n",
      "epoch:49 step:38776[D loss: 0.408453, acc: 62.50%, op_acc: 46.88%] [G loss: 0.945634]\n",
      "epoch:49 step:38777[D loss: 0.438834, acc: 59.38%, op_acc: 41.41%] [G loss: 1.327097]\n",
      "epoch:49 step:38778[D loss: 0.394917, acc: 71.09%, op_acc: 48.44%] [G loss: 1.107640]\n",
      "epoch:49 step:38779[D loss: 0.319960, acc: 75.78%, op_acc: 53.91%] [G loss: 1.142401]\n",
      "epoch:49 step:38780[D loss: 0.475247, acc: 48.44%, op_acc: 43.75%] [G loss: 1.228271]\n",
      "epoch:49 step:38781[D loss: 0.414724, acc: 66.41%, op_acc: 40.62%] [G loss: 1.065522]\n",
      "epoch:49 step:38782[D loss: 0.475134, acc: 56.25%, op_acc: 35.94%] [G loss: 0.903739]\n",
      "epoch:49 step:38783[D loss: 0.475372, acc: 56.25%, op_acc: 42.19%] [G loss: 1.021845]\n",
      "epoch:49 step:38784[D loss: 0.362738, acc: 74.22%, op_acc: 42.19%] [G loss: 1.031909]\n",
      "epoch:49 step:38785[D loss: 0.379268, acc: 67.97%, op_acc: 40.62%] [G loss: 1.241215]\n",
      "epoch:49 step:38786[D loss: 0.406124, acc: 66.41%, op_acc: 42.19%] [G loss: 0.944709]\n",
      "epoch:49 step:38787[D loss: 0.380035, acc: 67.19%, op_acc: 44.53%] [G loss: 1.289088]\n",
      "epoch:49 step:38788[D loss: 0.329230, acc: 77.34%, op_acc: 54.69%] [G loss: 1.178480]\n",
      "epoch:49 step:38789[D loss: 0.364505, acc: 70.31%, op_acc: 51.56%] [G loss: 1.040509]\n",
      "epoch:49 step:38790[D loss: 0.355235, acc: 75.78%, op_acc: 45.31%] [G loss: 1.166772]\n",
      "epoch:49 step:38791[D loss: 0.374330, acc: 70.31%, op_acc: 45.31%] [G loss: 1.182472]\n",
      "epoch:49 step:38792[D loss: 0.440478, acc: 57.81%, op_acc: 41.41%] [G loss: 1.169442]\n",
      "epoch:49 step:38793[D loss: 0.368610, acc: 74.22%, op_acc: 46.88%] [G loss: 1.347453]\n",
      "epoch:49 step:38794[D loss: 0.351154, acc: 76.56%, op_acc: 48.44%] [G loss: 1.241584]\n",
      "epoch:49 step:38795[D loss: 0.420386, acc: 60.16%, op_acc: 47.66%] [G loss: 1.032062]\n",
      "epoch:49 step:38796[D loss: 0.414650, acc: 64.06%, op_acc: 39.84%] [G loss: 1.245431]\n",
      "epoch:49 step:38797[D loss: 0.344869, acc: 72.66%, op_acc: 52.34%] [G loss: 1.317403]\n",
      "epoch:49 step:38798[D loss: 0.406658, acc: 64.84%, op_acc: 41.41%] [G loss: 1.198794]\n",
      "epoch:49 step:38799[D loss: 0.424093, acc: 61.72%, op_acc: 43.75%] [G loss: 1.221545]\n",
      "epoch:49 step:38800[D loss: 0.312409, acc: 82.81%, op_acc: 53.91%] [G loss: 1.411807]\n",
      "epoch:49 step:38801[D loss: 0.439362, acc: 60.16%, op_acc: 39.84%] [G loss: 0.892470]\n",
      "epoch:49 step:38802[D loss: 0.435274, acc: 62.50%, op_acc: 46.88%] [G loss: 1.166950]\n",
      "epoch:49 step:38803[D loss: 0.340930, acc: 69.53%, op_acc: 49.22%] [G loss: 1.098901]\n",
      "epoch:49 step:38804[D loss: 0.413334, acc: 64.06%, op_acc: 41.41%] [G loss: 1.059792]\n",
      "epoch:49 step:38805[D loss: 0.376219, acc: 67.97%, op_acc: 44.53%] [G loss: 1.089317]\n",
      "epoch:49 step:38806[D loss: 0.334736, acc: 73.44%, op_acc: 51.56%] [G loss: 1.209633]\n",
      "epoch:49 step:38807[D loss: 0.382566, acc: 67.19%, op_acc: 46.09%] [G loss: 1.119456]\n",
      "epoch:49 step:38808[D loss: 0.403497, acc: 64.06%, op_acc: 42.97%] [G loss: 1.018737]\n",
      "epoch:49 step:38809[D loss: 0.326182, acc: 75.78%, op_acc: 50.78%] [G loss: 1.065064]\n",
      "epoch:49 step:38810[D loss: 0.356556, acc: 71.09%, op_acc: 50.78%] [G loss: 1.059469]\n",
      "epoch:49 step:38811[D loss: 0.418339, acc: 62.50%, op_acc: 39.06%] [G loss: 1.213518]\n",
      "epoch:49 step:38812[D loss: 0.373393, acc: 71.88%, op_acc: 46.09%] [G loss: 1.061478]\n",
      "epoch:49 step:38813[D loss: 0.386267, acc: 67.19%, op_acc: 35.16%] [G loss: 0.895039]\n",
      "epoch:49 step:38814[D loss: 0.335741, acc: 75.00%, op_acc: 42.97%] [G loss: 1.342799]\n",
      "epoch:49 step:38815[D loss: 0.395837, acc: 66.41%, op_acc: 51.56%] [G loss: 1.011084]\n",
      "epoch:49 step:38816[D loss: 0.434235, acc: 59.38%, op_acc: 42.19%] [G loss: 0.910235]\n",
      "epoch:49 step:38817[D loss: 0.456789, acc: 50.00%, op_acc: 41.41%] [G loss: 1.184407]\n",
      "epoch:49 step:38818[D loss: 0.387931, acc: 64.06%, op_acc: 46.09%] [G loss: 1.030092]\n",
      "epoch:49 step:38819[D loss: 0.399095, acc: 64.84%, op_acc: 42.97%] [G loss: 1.160118]\n",
      "epoch:49 step:38820[D loss: 0.384859, acc: 67.97%, op_acc: 46.09%] [G loss: 1.151037]\n",
      "epoch:49 step:38821[D loss: 0.448044, acc: 60.16%, op_acc: 32.03%] [G loss: 0.903919]\n",
      "epoch:49 step:38822[D loss: 0.352711, acc: 73.44%, op_acc: 42.97%] [G loss: 0.943185]\n",
      "epoch:49 step:38823[D loss: 0.408500, acc: 67.97%, op_acc: 47.66%] [G loss: 1.179569]\n",
      "epoch:49 step:38824[D loss: 0.331987, acc: 78.12%, op_acc: 53.91%] [G loss: 1.113776]\n",
      "epoch:49 step:38825[D loss: 0.411918, acc: 62.50%, op_acc: 45.31%] [G loss: 0.935691]\n",
      "epoch:49 step:38826[D loss: 0.388083, acc: 63.28%, op_acc: 46.88%] [G loss: 1.132751]\n",
      "epoch:49 step:38827[D loss: 0.320084, acc: 76.56%, op_acc: 47.66%] [G loss: 1.291472]\n",
      "epoch:49 step:38828[D loss: 0.371362, acc: 67.97%, op_acc: 40.62%] [G loss: 1.274726]\n",
      "epoch:49 step:38829[D loss: 0.400145, acc: 71.88%, op_acc: 42.19%] [G loss: 1.243849]\n",
      "epoch:49 step:38830[D loss: 0.410622, acc: 67.19%, op_acc: 42.97%] [G loss: 1.059193]\n",
      "epoch:49 step:38831[D loss: 0.359836, acc: 71.88%, op_acc: 49.22%] [G loss: 1.187527]\n",
      "epoch:49 step:38832[D loss: 0.316230, acc: 80.47%, op_acc: 48.44%] [G loss: 1.273109]\n",
      "epoch:49 step:38833[D loss: 0.335746, acc: 77.34%, op_acc: 50.78%] [G loss: 1.429615]\n",
      "epoch:49 step:38834[D loss: 0.357036, acc: 69.53%, op_acc: 51.56%] [G loss: 1.195817]\n",
      "epoch:49 step:38835[D loss: 0.364414, acc: 75.00%, op_acc: 43.75%] [G loss: 1.037787]\n",
      "epoch:49 step:38836[D loss: 0.396099, acc: 68.75%, op_acc: 44.53%] [G loss: 1.325807]\n",
      "epoch:49 step:38837[D loss: 0.355390, acc: 81.25%, op_acc: 41.41%] [G loss: 1.057750]\n",
      "epoch:49 step:38838[D loss: 0.366617, acc: 63.28%, op_acc: 51.56%] [G loss: 1.296138]\n",
      "epoch:49 step:38839[D loss: 0.333710, acc: 72.66%, op_acc: 52.34%] [G loss: 1.350541]\n",
      "epoch:49 step:38840[D loss: 0.445241, acc: 56.25%, op_acc: 42.19%] [G loss: 1.123686]\n",
      "epoch:49 step:38841[D loss: 0.457416, acc: 56.25%, op_acc: 39.84%] [G loss: 1.128091]\n",
      "epoch:49 step:38842[D loss: 0.399089, acc: 63.28%, op_acc: 46.09%] [G loss: 1.127476]\n",
      "epoch:49 step:38843[D loss: 0.451780, acc: 55.47%, op_acc: 37.50%] [G loss: 1.106950]\n",
      "epoch:49 step:38844[D loss: 0.390938, acc: 63.28%, op_acc: 41.41%] [G loss: 1.233265]\n",
      "epoch:49 step:38845[D loss: 0.382334, acc: 67.19%, op_acc: 47.66%] [G loss: 1.165061]\n",
      "epoch:49 step:38846[D loss: 0.407516, acc: 67.19%, op_acc: 45.31%] [G loss: 1.539561]\n",
      "epoch:49 step:38847[D loss: 0.441601, acc: 60.16%, op_acc: 39.06%] [G loss: 1.314923]\n",
      "epoch:49 step:38848[D loss: 0.320380, acc: 77.34%, op_acc: 57.03%] [G loss: 1.535085]\n",
      "epoch:49 step:38849[D loss: 0.420538, acc: 60.16%, op_acc: 45.31%] [G loss: 1.347442]\n",
      "epoch:49 step:38850[D loss: 0.455527, acc: 60.16%, op_acc: 33.59%] [G loss: 0.797083]\n",
      "epoch:49 step:38851[D loss: 0.397867, acc: 65.62%, op_acc: 44.53%] [G loss: 1.062383]\n",
      "epoch:49 step:38852[D loss: 0.344693, acc: 71.88%, op_acc: 36.72%] [G loss: 1.363807]\n",
      "epoch:49 step:38853[D loss: 0.419985, acc: 63.28%, op_acc: 43.75%] [G loss: 1.336433]\n",
      "epoch:49 step:38854[D loss: 0.346670, acc: 71.88%, op_acc: 45.31%] [G loss: 1.166904]\n",
      "epoch:49 step:38855[D loss: 0.371944, acc: 72.66%, op_acc: 37.50%] [G loss: 1.161251]\n",
      "epoch:49 step:38856[D loss: 0.317781, acc: 81.25%, op_acc: 41.41%] [G loss: 1.048196]\n",
      "epoch:49 step:38857[D loss: 0.376726, acc: 67.97%, op_acc: 48.44%] [G loss: 1.223809]\n",
      "epoch:49 step:38858[D loss: 0.378253, acc: 74.22%, op_acc: 40.62%] [G loss: 1.082716]\n",
      "epoch:49 step:38859[D loss: 0.328633, acc: 75.78%, op_acc: 45.31%] [G loss: 1.280799]\n",
      "epoch:49 step:38860[D loss: 0.376634, acc: 72.66%, op_acc: 41.41%] [G loss: 1.194257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38861[D loss: 0.409318, acc: 63.28%, op_acc: 50.00%] [G loss: 1.220460]\n",
      "epoch:49 step:38862[D loss: 0.477650, acc: 57.03%, op_acc: 34.38%] [G loss: 1.106472]\n",
      "epoch:49 step:38863[D loss: 0.400505, acc: 65.62%, op_acc: 45.31%] [G loss: 1.378250]\n",
      "epoch:49 step:38864[D loss: 0.353520, acc: 73.44%, op_acc: 42.97%] [G loss: 1.277050]\n",
      "epoch:49 step:38865[D loss: 0.411419, acc: 63.28%, op_acc: 42.97%] [G loss: 1.233280]\n",
      "epoch:49 step:38866[D loss: 0.346217, acc: 75.78%, op_acc: 45.31%] [G loss: 0.962394]\n",
      "epoch:49 step:38867[D loss: 0.428132, acc: 58.59%, op_acc: 45.31%] [G loss: 1.026289]\n",
      "epoch:49 step:38868[D loss: 0.372491, acc: 64.84%, op_acc: 42.97%] [G loss: 1.243267]\n",
      "epoch:49 step:38869[D loss: 0.357023, acc: 74.22%, op_acc: 50.00%] [G loss: 1.380694]\n",
      "epoch:49 step:38870[D loss: 0.382888, acc: 66.41%, op_acc: 50.78%] [G loss: 1.319686]\n",
      "epoch:49 step:38871[D loss: 0.302340, acc: 80.47%, op_acc: 51.56%] [G loss: 1.242775]\n",
      "epoch:49 step:38872[D loss: 0.336254, acc: 70.31%, op_acc: 57.81%] [G loss: 1.196195]\n",
      "epoch:49 step:38873[D loss: 0.408461, acc: 67.97%, op_acc: 45.31%] [G loss: 1.165336]\n",
      "epoch:49 step:38874[D loss: 0.351322, acc: 72.66%, op_acc: 44.53%] [G loss: 1.082042]\n",
      "epoch:49 step:38875[D loss: 0.396414, acc: 64.84%, op_acc: 46.88%] [G loss: 1.243114]\n",
      "epoch:49 step:38876[D loss: 0.403869, acc: 61.72%, op_acc: 47.66%] [G loss: 1.090223]\n",
      "epoch:49 step:38877[D loss: 0.310281, acc: 74.22%, op_acc: 54.69%] [G loss: 1.195832]\n",
      "epoch:49 step:38878[D loss: 0.465917, acc: 51.56%, op_acc: 41.41%] [G loss: 1.218772]\n",
      "epoch:49 step:38879[D loss: 0.402444, acc: 67.97%, op_acc: 46.09%] [G loss: 1.386265]\n",
      "epoch:49 step:38880[D loss: 0.395911, acc: 67.19%, op_acc: 47.66%] [G loss: 1.182249]\n",
      "epoch:49 step:38881[D loss: 0.391737, acc: 67.97%, op_acc: 46.88%] [G loss: 1.634248]\n",
      "epoch:49 step:38882[D loss: 0.377967, acc: 67.19%, op_acc: 49.22%] [G loss: 1.256055]\n",
      "epoch:49 step:38883[D loss: 0.314466, acc: 77.34%, op_acc: 53.12%] [G loss: 1.159641]\n",
      "epoch:49 step:38884[D loss: 0.320977, acc: 78.12%, op_acc: 52.34%] [G loss: 1.253176]\n",
      "epoch:49 step:38885[D loss: 0.433096, acc: 57.81%, op_acc: 41.41%] [G loss: 1.164505]\n",
      "epoch:49 step:38886[D loss: 0.389108, acc: 67.97%, op_acc: 43.75%] [G loss: 0.998119]\n",
      "epoch:49 step:38887[D loss: 0.392158, acc: 61.72%, op_acc: 40.62%] [G loss: 1.304456]\n",
      "epoch:49 step:38888[D loss: 0.371344, acc: 72.66%, op_acc: 55.47%] [G loss: 1.201216]\n",
      "epoch:49 step:38889[D loss: 0.430225, acc: 61.72%, op_acc: 50.78%] [G loss: 1.237900]\n",
      "epoch:49 step:38890[D loss: 0.385640, acc: 66.41%, op_acc: 42.97%] [G loss: 1.029297]\n",
      "epoch:49 step:38891[D loss: 0.359359, acc: 74.22%, op_acc: 50.00%] [G loss: 1.136640]\n",
      "epoch:49 step:38892[D loss: 0.323379, acc: 78.12%, op_acc: 50.00%] [G loss: 1.348000]\n",
      "epoch:49 step:38893[D loss: 0.466998, acc: 59.38%, op_acc: 45.31%] [G loss: 1.077883]\n",
      "epoch:49 step:38894[D loss: 0.327135, acc: 78.91%, op_acc: 46.09%] [G loss: 1.275577]\n",
      "epoch:49 step:38895[D loss: 0.341343, acc: 75.00%, op_acc: 50.78%] [G loss: 1.162718]\n",
      "epoch:49 step:38896[D loss: 0.422535, acc: 62.50%, op_acc: 39.06%] [G loss: 1.254138]\n",
      "epoch:49 step:38897[D loss: 0.453950, acc: 60.16%, op_acc: 40.62%] [G loss: 0.914799]\n",
      "epoch:49 step:38898[D loss: 0.351911, acc: 77.34%, op_acc: 45.31%] [G loss: 1.130288]\n",
      "epoch:49 step:38899[D loss: 0.445114, acc: 58.59%, op_acc: 40.62%] [G loss: 1.109063]\n",
      "epoch:49 step:38900[D loss: 0.421230, acc: 60.94%, op_acc: 44.53%] [G loss: 1.305428]\n",
      "epoch:49 step:38901[D loss: 0.401164, acc: 75.00%, op_acc: 42.97%] [G loss: 1.274754]\n",
      "epoch:49 step:38902[D loss: 0.373727, acc: 70.31%, op_acc: 52.34%] [G loss: 1.445756]\n",
      "epoch:49 step:38903[D loss: 0.385185, acc: 64.84%, op_acc: 44.53%] [G loss: 1.066093]\n",
      "epoch:49 step:38904[D loss: 0.367540, acc: 70.31%, op_acc: 43.75%] [G loss: 1.142014]\n",
      "epoch:49 step:38905[D loss: 0.372640, acc: 67.97%, op_acc: 50.00%] [G loss: 1.237985]\n",
      "epoch:49 step:38906[D loss: 0.373801, acc: 72.66%, op_acc: 44.53%] [G loss: 1.260058]\n",
      "epoch:49 step:38907[D loss: 0.404197, acc: 60.16%, op_acc: 48.44%] [G loss: 1.220911]\n",
      "epoch:49 step:38908[D loss: 0.362506, acc: 72.66%, op_acc: 50.00%] [G loss: 1.251555]\n",
      "epoch:49 step:38909[D loss: 0.444721, acc: 60.94%, op_acc: 47.66%] [G loss: 1.268222]\n",
      "epoch:49 step:38910[D loss: 0.390428, acc: 66.41%, op_acc: 49.22%] [G loss: 1.185900]\n",
      "epoch:49 step:38911[D loss: 0.380208, acc: 66.41%, op_acc: 44.53%] [G loss: 1.146102]\n",
      "epoch:49 step:38912[D loss: 0.375998, acc: 71.09%, op_acc: 45.31%] [G loss: 1.244694]\n",
      "epoch:49 step:38913[D loss: 0.441454, acc: 53.91%, op_acc: 42.97%] [G loss: 1.123137]\n",
      "epoch:49 step:38914[D loss: 0.418260, acc: 62.50%, op_acc: 41.41%] [G loss: 1.025087]\n",
      "epoch:49 step:38915[D loss: 0.351660, acc: 76.56%, op_acc: 42.97%] [G loss: 1.093103]\n",
      "epoch:49 step:38916[D loss: 0.335711, acc: 74.22%, op_acc: 52.34%] [G loss: 1.177169]\n",
      "epoch:49 step:38917[D loss: 0.323184, acc: 81.25%, op_acc: 39.84%] [G loss: 1.498107]\n",
      "epoch:49 step:38918[D loss: 0.366269, acc: 70.31%, op_acc: 48.44%] [G loss: 1.077535]\n",
      "epoch:49 step:38919[D loss: 0.361522, acc: 76.56%, op_acc: 46.09%] [G loss: 1.290626]\n",
      "epoch:49 step:38920[D loss: 0.346421, acc: 75.00%, op_acc: 43.75%] [G loss: 1.445104]\n",
      "epoch:49 step:38921[D loss: 0.382483, acc: 62.50%, op_acc: 44.53%] [G loss: 1.327705]\n",
      "epoch:49 step:38922[D loss: 0.393616, acc: 60.16%, op_acc: 52.34%] [G loss: 1.260246]\n",
      "epoch:49 step:38923[D loss: 0.383632, acc: 65.62%, op_acc: 48.44%] [G loss: 1.160862]\n",
      "epoch:49 step:38924[D loss: 0.384084, acc: 67.97%, op_acc: 45.31%] [G loss: 1.400948]\n",
      "epoch:49 step:38925[D loss: 0.394728, acc: 67.19%, op_acc: 41.41%] [G loss: 1.206449]\n",
      "epoch:49 step:38926[D loss: 0.397138, acc: 67.19%, op_acc: 43.75%] [G loss: 1.311980]\n",
      "epoch:49 step:38927[D loss: 0.387509, acc: 68.75%, op_acc: 42.97%] [G loss: 1.209638]\n",
      "epoch:49 step:38928[D loss: 0.406204, acc: 63.28%, op_acc: 39.84%] [G loss: 1.450823]\n",
      "epoch:49 step:38929[D loss: 0.452623, acc: 55.47%, op_acc: 43.75%] [G loss: 1.165153]\n",
      "epoch:49 step:38930[D loss: 0.354474, acc: 68.75%, op_acc: 48.44%] [G loss: 1.240633]\n",
      "epoch:49 step:38931[D loss: 0.382691, acc: 64.06%, op_acc: 41.41%] [G loss: 1.160315]\n",
      "epoch:49 step:38932[D loss: 0.379673, acc: 60.94%, op_acc: 50.78%] [G loss: 1.221398]\n",
      "epoch:49 step:38933[D loss: 0.404760, acc: 67.97%, op_acc: 46.09%] [G loss: 0.843883]\n",
      "epoch:49 step:38934[D loss: 0.449327, acc: 66.41%, op_acc: 33.59%] [G loss: 1.024046]\n",
      "epoch:49 step:38935[D loss: 0.419884, acc: 65.62%, op_acc: 39.84%] [G loss: 1.164623]\n",
      "epoch:49 step:38936[D loss: 0.406016, acc: 67.97%, op_acc: 46.09%] [G loss: 1.150045]\n",
      "epoch:49 step:38937[D loss: 0.418691, acc: 58.59%, op_acc: 40.62%] [G loss: 1.091230]\n",
      "epoch:49 step:38938[D loss: 0.379851, acc: 68.75%, op_acc: 45.31%] [G loss: 1.270281]\n",
      "epoch:49 step:38939[D loss: 0.373203, acc: 71.09%, op_acc: 47.66%] [G loss: 1.347646]\n",
      "epoch:49 step:38940[D loss: 0.422234, acc: 64.84%, op_acc: 46.88%] [G loss: 1.277423]\n",
      "epoch:49 step:38941[D loss: 0.384184, acc: 65.62%, op_acc: 47.66%] [G loss: 1.135258]\n",
      "epoch:49 step:38942[D loss: 0.432365, acc: 64.84%, op_acc: 44.53%] [G loss: 1.134853]\n",
      "epoch:49 step:38943[D loss: 0.333069, acc: 75.78%, op_acc: 46.09%] [G loss: 1.185448]\n",
      "epoch:49 step:38944[D loss: 0.288848, acc: 83.59%, op_acc: 56.25%] [G loss: 1.139454]\n",
      "epoch:49 step:38945[D loss: 0.363767, acc: 75.00%, op_acc: 50.78%] [G loss: 1.135296]\n",
      "epoch:49 step:38946[D loss: 0.482382, acc: 53.91%, op_acc: 33.59%] [G loss: 1.099223]\n",
      "epoch:49 step:38947[D loss: 0.355193, acc: 73.44%, op_acc: 42.19%] [G loss: 1.191558]\n",
      "epoch:49 step:38948[D loss: 0.380123, acc: 67.97%, op_acc: 45.31%] [G loss: 1.292105]\n",
      "epoch:49 step:38949[D loss: 0.373253, acc: 75.78%, op_acc: 39.84%] [G loss: 1.182203]\n",
      "epoch:49 step:38950[D loss: 0.362784, acc: 73.44%, op_acc: 45.31%] [G loss: 1.204317]\n",
      "epoch:49 step:38951[D loss: 0.363401, acc: 68.75%, op_acc: 54.69%] [G loss: 0.770895]\n",
      "epoch:49 step:38952[D loss: 0.390437, acc: 65.62%, op_acc: 43.75%] [G loss: 1.256018]\n",
      "epoch:49 step:38953[D loss: 0.387676, acc: 73.44%, op_acc: 44.53%] [G loss: 1.195059]\n",
      "epoch:49 step:38954[D loss: 0.352914, acc: 70.31%, op_acc: 44.53%] [G loss: 1.287074]\n",
      "epoch:49 step:38955[D loss: 0.440378, acc: 56.25%, op_acc: 43.75%] [G loss: 1.212930]\n",
      "epoch:49 step:38956[D loss: 0.347383, acc: 75.78%, op_acc: 42.97%] [G loss: 1.257448]\n",
      "epoch:49 step:38957[D loss: 0.361683, acc: 70.31%, op_acc: 49.22%] [G loss: 1.326099]\n",
      "epoch:49 step:38958[D loss: 0.427898, acc: 61.72%, op_acc: 39.06%] [G loss: 1.071632]\n",
      "epoch:49 step:38959[D loss: 0.372483, acc: 70.31%, op_acc: 49.22%] [G loss: 1.162087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49 step:38960[D loss: 0.310583, acc: 82.81%, op_acc: 49.22%] [G loss: 1.396968]\n",
      "epoch:49 step:38961[D loss: 0.469420, acc: 54.69%, op_acc: 43.75%] [G loss: 1.284338]\n",
      "epoch:49 step:38962[D loss: 0.386208, acc: 69.53%, op_acc: 49.22%] [G loss: 1.466094]\n",
      "epoch:49 step:38963[D loss: 0.351487, acc: 71.09%, op_acc: 49.22%] [G loss: 1.239733]\n",
      "epoch:49 step:38964[D loss: 0.405589, acc: 62.50%, op_acc: 45.31%] [G loss: 1.275372]\n",
      "epoch:49 step:38965[D loss: 0.404093, acc: 64.06%, op_acc: 47.66%] [G loss: 1.216494]\n",
      "epoch:49 step:38966[D loss: 0.351224, acc: 74.22%, op_acc: 47.66%] [G loss: 1.353677]\n",
      "epoch:49 step:38967[D loss: 0.407987, acc: 66.41%, op_acc: 42.19%] [G loss: 1.251539]\n",
      "epoch:49 step:38968[D loss: 0.392580, acc: 64.84%, op_acc: 43.75%] [G loss: 1.087839]\n",
      "epoch:49 step:38969[D loss: 0.419213, acc: 60.16%, op_acc: 39.06%] [G loss: 1.131809]\n",
      "epoch:49 step:38970[D loss: 0.434855, acc: 58.59%, op_acc: 41.41%] [G loss: 0.963742]\n",
      "epoch:49 step:38971[D loss: 0.412894, acc: 60.94%, op_acc: 45.31%] [G loss: 1.105889]\n",
      "epoch:49 step:38972[D loss: 0.393671, acc: 69.53%, op_acc: 35.94%] [G loss: 1.287065]\n",
      "epoch:49 step:38973[D loss: 0.364701, acc: 69.53%, op_acc: 44.53%] [G loss: 1.310605]\n",
      "epoch:49 step:38974[D loss: 0.427347, acc: 56.25%, op_acc: 43.75%] [G loss: 1.349108]\n",
      "epoch:49 step:38975[D loss: 0.408481, acc: 62.50%, op_acc: 46.88%] [G loss: 1.017414]\n",
      "epoch:49 step:38976[D loss: 0.450946, acc: 59.38%, op_acc: 39.84%] [G loss: 1.117450]\n",
      "epoch:49 step:38977[D loss: 0.396721, acc: 66.41%, op_acc: 44.53%] [G loss: 1.231255]\n",
      "epoch:49 step:38978[D loss: 0.371548, acc: 68.75%, op_acc: 43.75%] [G loss: 1.201804]\n",
      "epoch:49 step:38979[D loss: 0.304798, acc: 77.34%, op_acc: 46.88%] [G loss: 1.229745]\n",
      "epoch:49 step:38980[D loss: 0.396365, acc: 68.75%, op_acc: 39.84%] [G loss: 1.538550]\n",
      "epoch:49 step:38981[D loss: 0.411070, acc: 62.50%, op_acc: 45.31%] [G loss: 1.402588]\n",
      "epoch:49 step:38982[D loss: 0.402301, acc: 63.28%, op_acc: 45.31%] [G loss: 1.171162]\n",
      "epoch:49 step:38983[D loss: 0.363589, acc: 67.19%, op_acc: 44.53%] [G loss: 1.352882]\n",
      "epoch:49 step:38984[D loss: 0.359889, acc: 67.19%, op_acc: 48.44%] [G loss: 1.182228]\n",
      "epoch:49 step:38985[D loss: 0.466350, acc: 56.25%, op_acc: 37.50%] [G loss: 1.322673]\n",
      "epoch:49 step:38986[D loss: 0.396786, acc: 64.06%, op_acc: 45.31%] [G loss: 1.188589]\n",
      "epoch:49 step:38987[D loss: 0.402219, acc: 60.16%, op_acc: 39.06%] [G loss: 1.173668]\n",
      "epoch:49 step:38988[D loss: 0.369637, acc: 69.53%, op_acc: 50.00%] [G loss: 1.269840]\n",
      "epoch:49 step:38989[D loss: 0.374194, acc: 67.97%, op_acc: 43.75%] [G loss: 1.146465]\n",
      "epoch:49 step:38990[D loss: 0.464643, acc: 54.69%, op_acc: 39.84%] [G loss: 1.046843]\n",
      "epoch:49 step:38991[D loss: 0.374146, acc: 71.88%, op_acc: 47.66%] [G loss: 1.428222]\n",
      "epoch:49 step:38992[D loss: 0.376227, acc: 65.62%, op_acc: 40.62%] [G loss: 1.182112]\n",
      "epoch:49 step:38993[D loss: 0.462046, acc: 62.50%, op_acc: 33.59%] [G loss: 0.942924]\n",
      "epoch:49 step:38994[D loss: 0.402318, acc: 66.41%, op_acc: 42.97%] [G loss: 0.914211]\n",
      "epoch:49 step:38995[D loss: 0.372708, acc: 72.66%, op_acc: 43.75%] [G loss: 1.002629]\n",
      "epoch:49 step:38996[D loss: 0.403222, acc: 65.62%, op_acc: 41.41%] [G loss: 1.392236]\n",
      "epoch:49 step:38997[D loss: 0.395253, acc: 71.88%, op_acc: 41.41%] [G loss: 1.265515]\n",
      "epoch:49 step:38998[D loss: 0.358650, acc: 71.88%, op_acc: 43.75%] [G loss: 1.249398]\n",
      "epoch:49 step:38999[D loss: 0.320848, acc: 78.12%, op_acc: 39.84%] [G loss: 1.262627]\n",
      "epoch:49 step:39000[D loss: 0.336045, acc: 71.09%, op_acc: 50.00%] [G loss: 1.174068]\n",
      "epoch:49 step:39001[D loss: 0.362783, acc: 70.31%, op_acc: 49.22%] [G loss: 1.465594]\n",
      "epoch:49 step:39002[D loss: 0.407475, acc: 65.62%, op_acc: 50.78%] [G loss: 1.091199]\n",
      "epoch:49 step:39003[D loss: 0.348395, acc: 73.44%, op_acc: 47.66%] [G loss: 1.213721]\n",
      "epoch:49 step:39004[D loss: 0.361362, acc: 69.53%, op_acc: 47.66%] [G loss: 1.486634]\n",
      "epoch:49 step:39005[D loss: 0.467767, acc: 50.78%, op_acc: 40.62%] [G loss: 1.149081]\n",
      "epoch:49 step:39006[D loss: 0.355138, acc: 69.53%, op_acc: 50.78%] [G loss: 1.145645]\n",
      "epoch:49 step:39007[D loss: 0.393009, acc: 63.28%, op_acc: 46.09%] [G loss: 1.085252]\n",
      "epoch:49 step:39008[D loss: 0.357743, acc: 70.31%, op_acc: 55.47%] [G loss: 1.255448]\n",
      "epoch:49 step:39009[D loss: 0.359925, acc: 75.00%, op_acc: 47.66%] [G loss: 1.084339]\n",
      "epoch:49 step:39010[D loss: 0.385052, acc: 71.09%, op_acc: 50.00%] [G loss: 1.331052]\n",
      "epoch:49 step:39011[D loss: 0.385545, acc: 71.88%, op_acc: 45.31%] [G loss: 1.341362]\n",
      "epoch:49 step:39012[D loss: 0.382493, acc: 72.66%, op_acc: 39.84%] [G loss: 1.094949]\n",
      "epoch:49 step:39013[D loss: 0.347309, acc: 73.44%, op_acc: 50.78%] [G loss: 1.413720]\n",
      "epoch:49 step:39014[D loss: 0.416031, acc: 60.94%, op_acc: 44.53%] [G loss: 1.353051]\n",
      "epoch:49 step:39015[D loss: 0.449454, acc: 60.94%, op_acc: 43.75%] [G loss: 1.272820]\n",
      "epoch:49 step:39016[D loss: 0.358922, acc: 72.66%, op_acc: 46.09%] [G loss: 1.103797]\n",
      "epoch:49 step:39017[D loss: 0.422533, acc: 63.28%, op_acc: 39.84%] [G loss: 1.279328]\n",
      "epoch:49 step:39018[D loss: 0.383216, acc: 69.53%, op_acc: 47.66%] [G loss: 1.139599]\n",
      "epoch:49 step:39019[D loss: 0.429597, acc: 59.38%, op_acc: 41.41%] [G loss: 1.394854]\n",
      "epoch:49 step:39020[D loss: 0.376424, acc: 76.56%, op_acc: 39.06%] [G loss: 1.265437]\n",
      "epoch:49 step:39021[D loss: 0.380857, acc: 67.97%, op_acc: 49.22%] [G loss: 1.097861]\n",
      "epoch:49 step:39022[D loss: 0.332497, acc: 78.91%, op_acc: 48.44%] [G loss: 1.297817]\n",
      "epoch:49 step:39023[D loss: 0.370188, acc: 74.22%, op_acc: 42.97%] [G loss: 1.003916]\n",
      "epoch:49 step:39024[D loss: 0.393790, acc: 69.53%, op_acc: 50.78%] [G loss: 1.062251]\n",
      "epoch:49 step:39025[D loss: 0.326929, acc: 72.66%, op_acc: 53.91%] [G loss: 0.906368]\n",
      "epoch:49 step:39026[D loss: 0.380333, acc: 67.97%, op_acc: 39.06%] [G loss: 1.024412]\n",
      "epoch:49 step:39027[D loss: 0.359067, acc: 71.09%, op_acc: 47.66%] [G loss: 1.058936]\n",
      "epoch:49 step:39028[D loss: 0.325047, acc: 78.12%, op_acc: 54.69%] [G loss: 1.180795]\n",
      "epoch:49 step:39029[D loss: 0.409995, acc: 66.41%, op_acc: 42.19%] [G loss: 1.084709]\n",
      "epoch:49 step:39030[D loss: 0.328602, acc: 74.22%, op_acc: 53.91%] [G loss: 1.052101]\n",
      "epoch:49 step:39031[D loss: 0.372017, acc: 72.66%, op_acc: 51.56%] [G loss: 1.405947]\n",
      "epoch:49 step:39032[D loss: 0.390276, acc: 63.28%, op_acc: 47.66%] [G loss: 1.100279]\n",
      "epoch:49 step:39033[D loss: 0.408928, acc: 66.41%, op_acc: 43.75%] [G loss: 1.183357]\n",
      "epoch:49 step:39034[D loss: 0.391001, acc: 66.41%, op_acc: 56.25%] [G loss: 1.067211]\n",
      "epoch:49 step:39035[D loss: 0.385874, acc: 69.53%, op_acc: 40.62%] [G loss: 1.109067]\n",
      "epoch:49 step:39036[D loss: 0.398347, acc: 64.84%, op_acc: 40.62%] [G loss: 1.208845]\n",
      "epoch:49 step:39037[D loss: 0.405581, acc: 63.28%, op_acc: 44.53%] [G loss: 1.359306]\n",
      "epoch:49 step:39038[D loss: 0.399862, acc: 61.72%, op_acc: 46.09%] [G loss: 1.355889]\n",
      "epoch:49 step:39039[D loss: 0.394750, acc: 68.75%, op_acc: 41.41%] [G loss: 1.275956]\n",
      "epoch:49 step:39040[D loss: 0.491443, acc: 49.22%, op_acc: 42.19%] [G loss: 0.920673]\n",
      "epoch:49 step:39041[D loss: 0.455398, acc: 60.94%, op_acc: 35.94%] [G loss: 1.319686]\n",
      "epoch:49 step:39042[D loss: 0.419149, acc: 64.84%, op_acc: 44.53%] [G loss: 1.213495]\n",
      "epoch:49 step:39043[D loss: 0.326209, acc: 75.78%, op_acc: 53.12%] [G loss: 1.214124]\n",
      "epoch:49 step:39044[D loss: 0.403863, acc: 64.84%, op_acc: 41.41%] [G loss: 1.493803]\n",
      "epoch:49 step:39045[D loss: 0.369341, acc: 72.66%, op_acc: 46.09%] [G loss: 1.448621]\n",
      "epoch:49 step:39046[D loss: 0.429148, acc: 60.94%, op_acc: 43.75%] [G loss: 1.265841]\n",
      "epoch:49 step:39047[D loss: 0.408571, acc: 63.28%, op_acc: 45.31%] [G loss: 1.321007]\n",
      "epoch:49 step:39048[D loss: 0.314353, acc: 79.69%, op_acc: 49.22%] [G loss: 1.226555]\n",
      "epoch:49 step:39049[D loss: 0.403850, acc: 57.03%, op_acc: 44.53%] [G loss: 1.088331]\n",
      "epoch:49 step:39050[D loss: 0.435239, acc: 57.03%, op_acc: 39.06%] [G loss: 1.323498]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform=None):\n",
    "        # super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img)\n",
    "        img=img.reshape([3,32,32])\n",
    "        return img\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "import torch.nn.functional as F\n",
    "model = model.cifar10(128)\n",
    "model.load_state_dict(torch.load('./log/default/best-85.pth'))\n",
    "model.cuda()\n",
    "def get_mean_var(y_logit):\n",
    "    y_logit=np.abs(y_logit-0.1)\n",
    "    return np.mean(y_logit,axis=1)\n",
    "\n",
    "def get_possibility(images):\n",
    "    x_dataset = MyDataset(images)\n",
    "    # print(x_dataset[0].shape)\n",
    "    x_real_loader = Data.DataLoader(dataset=x_dataset, batch_size=100, shuffle=True)\n",
    "    y_logits = []\n",
    "    for i, data in enumerate(x_real_loader):\n",
    "        # indx_target = target.clone()\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        pred = F.softmax(output).cpu().detach().numpy()\n",
    "        y_logits += [i for i in pred]\n",
    "        y_logits=np.array(y_logits)\n",
    "    return y_logits\n",
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('sgan')):\n",
    "    os.mkdir('saved_models_{}'.format('sgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('sgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "import cv2\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class SGAN:\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "            loss_weights=[0.5, 0.5],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        noise = Input(shape=(100,))\n",
    "        img = self.generator(noise)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid, _ = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(noise, valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        features = model(img)\n",
    "        valid = Dense(1, activation=\"sigmoid\")(features)\n",
    "        label = Dense(self.num_classes+1, activation=\"softmax\")(features)\n",
    "\n",
    "        return Model(img, [valid, label])\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (X_test, _) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Class weights:\n",
    "        # To balance the difference in occurences of digit class labels.\n",
    "        # 50% of labels that the discriminator trains on are 'fake'.\n",
    "        # Weight = 1 / frequency\n",
    "        half_batch = batch_size // 2\n",
    "        cw1 = {0: 1, 1: 1}\n",
    "        cw2 = {i: self.num_classes / half_batch for i in range(self.num_classes)}\n",
    "        cw2[self.num_classes] = 1 / half_batch\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "        steps = []\n",
    "        values = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # One-hot encoding of labels\n",
    "                labels = to_categorical(y_train[index * batch_size:(index + 1) * batch_size], num_classes=self.num_classes + 1)\n",
    "                fake_labels = to_categorical(np.full((batch_size, 1), self.num_classes),\n",
    "                                             num_classes=self.num_classes + 1)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, [valid, labels], class_weight=[cw1, cw2])\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, fake_labels], class_weight=[cw1, cw2])\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid, class_weight=[cw1, cw2])\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d[D loss: %f, acc: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (\n",
    "                    epoch, global_step, d_loss[0], 100 * d_loss[3], 100 * d_loss[4], g_loss))\n",
    "\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.mode_drop(epoch, global_step)\n",
    "                   \n",
    "\n",
    "    def mode_drop(self, epoch, global_step):\n",
    "        r, c = 10, 1000\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        # sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        y_logits = get_possibility(gen_imgs)\n",
    "        metrics = get_mean_var(y_logits)\n",
    "\n",
    "\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('global_step:' + str(global_step))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in metrics)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sgan = SGAN()\n",
    "    sgan.train(epochs=50, batch_size=64, sample_interval=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
